Epoch: 1| Step: 0
Training loss: 6.112548628225535
Validation loss: 5.871393029864805

Epoch: 6| Step: 1
Training loss: 6.249585862744071
Validation loss: 5.869852340461383

Epoch: 6| Step: 2
Training loss: 5.572613726311539
Validation loss: 5.868409213733233

Epoch: 6| Step: 3
Training loss: 5.871456294943998
Validation loss: 5.866982664282166

Epoch: 6| Step: 4
Training loss: 6.38606946718763
Validation loss: 5.865574682362344

Epoch: 6| Step: 5
Training loss: 5.524180404148043
Validation loss: 5.864256647021463

Epoch: 6| Step: 6
Training loss: 6.714564523444685
Validation loss: 5.862861809753016

Epoch: 6| Step: 7
Training loss: 5.787056970632625
Validation loss: 5.861544384643049

Epoch: 6| Step: 8
Training loss: 5.946886212753815
Validation loss: 5.860286224718048

Epoch: 6| Step: 9
Training loss: 6.27898339516889
Validation loss: 5.858835478633114

Epoch: 6| Step: 10
Training loss: 5.894586581810381
Validation loss: 5.85737023538042

Epoch: 6| Step: 11
Training loss: 5.697266629349414
Validation loss: 5.855953916639347

Epoch: 6| Step: 12
Training loss: 5.470264334141082
Validation loss: 5.854356954973096

Epoch: 6| Step: 13
Training loss: 6.068597617627794
Validation loss: 5.852905228034856

Epoch: 2| Step: 0
Training loss: 5.24536436780842
Validation loss: 5.851157323359634

Epoch: 6| Step: 1
Training loss: 6.220266799356422
Validation loss: 5.849529624569398

Epoch: 6| Step: 2
Training loss: 6.407068711975896
Validation loss: 5.847793404213615

Epoch: 6| Step: 3
Training loss: 5.9827457929365835
Validation loss: 5.8459163736910655

Epoch: 6| Step: 4
Training loss: 4.882575775511659
Validation loss: 5.8440271267654085

Epoch: 6| Step: 5
Training loss: 5.874429228632092
Validation loss: 5.841992445426635

Epoch: 6| Step: 6
Training loss: 5.669982089867133
Validation loss: 5.839956946323153

Epoch: 6| Step: 7
Training loss: 5.6089900742754315
Validation loss: 5.837788224983976

Epoch: 6| Step: 8
Training loss: 5.579993696311753
Validation loss: 5.835482864340342

Epoch: 6| Step: 9
Training loss: 6.61613446969187
Validation loss: 5.832896525059395

Epoch: 6| Step: 10
Training loss: 6.570809761671104
Validation loss: 5.830628703587767

Epoch: 6| Step: 11
Training loss: 5.363637580342441
Validation loss: 5.827786242310508

Epoch: 6| Step: 12
Training loss: 7.06171838266815
Validation loss: 5.8248146071285225

Epoch: 6| Step: 13
Training loss: 5.882561221081799
Validation loss: 5.821891061976021

Epoch: 3| Step: 0
Training loss: 4.640773989151356
Validation loss: 5.818641207586571

Epoch: 6| Step: 1
Training loss: 6.372847848275183
Validation loss: 5.815381337479177

Epoch: 6| Step: 2
Training loss: 5.17101730195653
Validation loss: 5.811977021128383

Epoch: 6| Step: 3
Training loss: 5.622661697959619
Validation loss: 5.808135003635761

Epoch: 6| Step: 4
Training loss: 5.1318692947595705
Validation loss: 5.8042310738076495

Epoch: 6| Step: 5
Training loss: 6.214037158924945
Validation loss: 5.800137324187347

Epoch: 6| Step: 6
Training loss: 6.1904579567553375
Validation loss: 5.796056506286684

Epoch: 6| Step: 7
Training loss: 5.791360458219748
Validation loss: 5.791610150324473

Epoch: 6| Step: 8
Training loss: 5.834176284192917
Validation loss: 5.7865847606106815

Epoch: 6| Step: 9
Training loss: 6.169320575024601
Validation loss: 5.781845227091565

Epoch: 6| Step: 10
Training loss: 6.997268688853095
Validation loss: 5.776545326923477

Epoch: 6| Step: 11
Training loss: 5.896216857441767
Validation loss: 5.770933001193509

Epoch: 6| Step: 12
Training loss: 5.798771550540798
Validation loss: 5.765285409577035

Epoch: 6| Step: 13
Training loss: 6.459400146317314
Validation loss: 5.759167481145782

Epoch: 4| Step: 0
Training loss: 5.287624868086376
Validation loss: 5.752982927675123

Epoch: 6| Step: 1
Training loss: 6.44911405407902
Validation loss: 5.746250588709743

Epoch: 6| Step: 2
Training loss: 5.208154212414699
Validation loss: 5.739422841490781

Epoch: 6| Step: 3
Training loss: 7.0448563553925805
Validation loss: 5.732615853298071

Epoch: 6| Step: 4
Training loss: 6.3189754698661025
Validation loss: 5.725139279732753

Epoch: 6| Step: 5
Training loss: 5.396711280517392
Validation loss: 5.717520937840274

Epoch: 6| Step: 6
Training loss: 6.455427373305464
Validation loss: 5.709831913546758

Epoch: 6| Step: 7
Training loss: 5.844422327216539
Validation loss: 5.702032672664928

Epoch: 6| Step: 8
Training loss: 5.446939977716811
Validation loss: 5.693271461362053

Epoch: 6| Step: 9
Training loss: 5.905074714103996
Validation loss: 5.6849897944510595

Epoch: 6| Step: 10
Training loss: 5.289164915459688
Validation loss: 5.676136220152738

Epoch: 6| Step: 11
Training loss: 6.061843364588584
Validation loss: 5.6671139129216765

Epoch: 6| Step: 12
Training loss: 5.255097049357789
Validation loss: 5.658280993272438

Epoch: 6| Step: 13
Training loss: 5.129702387871519
Validation loss: 5.648995427760127

Epoch: 5| Step: 0
Training loss: 6.306096521027849
Validation loss: 5.640129257777129

Epoch: 6| Step: 1
Training loss: 4.952184353146974
Validation loss: 5.630961416896467

Epoch: 6| Step: 2
Training loss: 5.305237596891647
Validation loss: 5.621434727820788

Epoch: 6| Step: 3
Training loss: 5.073886264306692
Validation loss: 5.612371836036514

Epoch: 6| Step: 4
Training loss: 6.30618786360617
Validation loss: 5.603279138031038

Epoch: 6| Step: 5
Training loss: 6.232607636392552
Validation loss: 5.5942542845097645

Epoch: 6| Step: 6
Training loss: 5.551096682408027
Validation loss: 5.585176144801621

Epoch: 6| Step: 7
Training loss: 6.085671101959953
Validation loss: 5.5762286270736485

Epoch: 6| Step: 8
Training loss: 5.234538243723127
Validation loss: 5.5672291001371494

Epoch: 6| Step: 9
Training loss: 5.645070698973675
Validation loss: 5.558523978758065

Epoch: 6| Step: 10
Training loss: 6.20022784398951
Validation loss: 5.55004774880704

Epoch: 6| Step: 11
Training loss: 4.664858649464357
Validation loss: 5.541310387346956

Epoch: 6| Step: 12
Training loss: 6.552597858581668
Validation loss: 5.533528320293341

Epoch: 6| Step: 13
Training loss: 5.25911031182772
Validation loss: 5.525890735383111

Epoch: 6| Step: 0
Training loss: 6.451628948007136
Validation loss: 5.517743014682201

Epoch: 6| Step: 1
Training loss: 6.051531435499922
Validation loss: 5.509871467295821

Epoch: 6| Step: 2
Training loss: 5.461327447462139
Validation loss: 5.50223351412881

Epoch: 6| Step: 3
Training loss: 5.434908896264348
Validation loss: 5.494691772517131

Epoch: 6| Step: 4
Training loss: 5.513337522794953
Validation loss: 5.4870929413526275

Epoch: 6| Step: 5
Training loss: 4.904318265211218
Validation loss: 5.479494218016317

Epoch: 6| Step: 6
Training loss: 5.098322401697004
Validation loss: 5.471732091281123

Epoch: 6| Step: 7
Training loss: 5.8355593475835645
Validation loss: 5.464183797518078

Epoch: 6| Step: 8
Training loss: 5.513241693333987
Validation loss: 5.45685989449446

Epoch: 6| Step: 9
Training loss: 5.337916173500422
Validation loss: 5.4490694342315305

Epoch: 6| Step: 10
Training loss: 5.105400382695461
Validation loss: 5.4419832418908785

Epoch: 6| Step: 11
Training loss: 6.367230636356948
Validation loss: 5.435191779006597

Epoch: 6| Step: 12
Training loss: 6.027262738438076
Validation loss: 5.428325762245177

Epoch: 6| Step: 13
Training loss: 4.860975192152865
Validation loss: 5.421228639623469

Epoch: 7| Step: 0
Training loss: 5.987218913128257
Validation loss: 5.414568108183397

Epoch: 6| Step: 1
Training loss: 5.842874553200128
Validation loss: 5.407189583395015

Epoch: 6| Step: 2
Training loss: 5.880221055734779
Validation loss: 5.400369286566869

Epoch: 6| Step: 3
Training loss: 5.413982352231887
Validation loss: 5.393053268985338

Epoch: 6| Step: 4
Training loss: 5.624623264836312
Validation loss: 5.386070177380549

Epoch: 6| Step: 5
Training loss: 4.739243223402488
Validation loss: 5.378761483476505

Epoch: 6| Step: 6
Training loss: 6.527713676119867
Validation loss: 5.372164813899457

Epoch: 6| Step: 7
Training loss: 6.141710801744545
Validation loss: 5.365461387502213

Epoch: 6| Step: 8
Training loss: 6.334728723030274
Validation loss: 5.358872400263237

Epoch: 6| Step: 9
Training loss: 5.612657357029901
Validation loss: 5.352044522372549

Epoch: 6| Step: 10
Training loss: 5.047781564644535
Validation loss: 5.345510657491143

Epoch: 6| Step: 11
Training loss: 3.141643302149283
Validation loss: 5.339202046061547

Epoch: 6| Step: 12
Training loss: 4.26169972891894
Validation loss: 5.333566223463891

Epoch: 6| Step: 13
Training loss: 5.410835570505254
Validation loss: 5.327352398803213

Epoch: 8| Step: 0
Training loss: 5.79561335980141
Validation loss: 5.321292019607134

Epoch: 6| Step: 1
Training loss: 4.883700114635663
Validation loss: 5.315634816089846

Epoch: 6| Step: 2
Training loss: 4.973503286374223
Validation loss: 5.309896721371334

Epoch: 6| Step: 3
Training loss: 5.956852904604881
Validation loss: 5.304192094324878

Epoch: 6| Step: 4
Training loss: 5.458556697245254
Validation loss: 5.2982726527160455

Epoch: 6| Step: 5
Training loss: 5.815117359502313
Validation loss: 5.292223603183921

Epoch: 6| Step: 6
Training loss: 4.745529882270829
Validation loss: 5.286253295329731

Epoch: 6| Step: 7
Training loss: 5.844431465111951
Validation loss: 5.280642051240326

Epoch: 6| Step: 8
Training loss: 5.144671021853166
Validation loss: 5.274965689307985

Epoch: 6| Step: 9
Training loss: 5.6586908795854125
Validation loss: 5.268636082163971

Epoch: 6| Step: 10
Training loss: 5.634531719040287
Validation loss: 5.2622449763249275

Epoch: 6| Step: 11
Training loss: 4.809998890327437
Validation loss: 5.255760756141156

Epoch: 6| Step: 12
Training loss: 5.58042984048629
Validation loss: 5.249406024090114

Epoch: 6| Step: 13
Training loss: 5.1740640577104395
Validation loss: 5.2429581903283

Epoch: 9| Step: 0
Training loss: 6.1587804250892795
Validation loss: 5.236511280385802

Epoch: 6| Step: 1
Training loss: 5.820428178904969
Validation loss: 5.230019893669187

Epoch: 6| Step: 2
Training loss: 4.76496517428854
Validation loss: 5.223559327891467

Epoch: 6| Step: 3
Training loss: 4.8460280445151716
Validation loss: 5.2176792165540755

Epoch: 6| Step: 4
Training loss: 5.502798582205978
Validation loss: 5.2114889528924255

Epoch: 6| Step: 5
Training loss: 5.711972415526218
Validation loss: 5.205403238703265

Epoch: 6| Step: 6
Training loss: 6.163329106204432
Validation loss: 5.199350173401188

Epoch: 6| Step: 7
Training loss: 5.749021695711686
Validation loss: 5.192844380159212

Epoch: 6| Step: 8
Training loss: 3.767348025875933
Validation loss: 5.186586812850264

Epoch: 6| Step: 9
Training loss: 5.368581976609391
Validation loss: 5.180813137238221

Epoch: 6| Step: 10
Training loss: 4.732154652871291
Validation loss: 5.175150438170717

Epoch: 6| Step: 11
Training loss: 5.1048042781422724
Validation loss: 5.168824862853252

Epoch: 6| Step: 12
Training loss: 4.602119554567357
Validation loss: 5.162931733016939

Epoch: 6| Step: 13
Training loss: 5.645515498637953
Validation loss: 5.156891445758915

Epoch: 10| Step: 0
Training loss: 6.226593438697446
Validation loss: 5.151260520469502

Epoch: 6| Step: 1
Training loss: 4.427681389598056
Validation loss: 5.14543123514655

Epoch: 6| Step: 2
Training loss: 6.200129403025215
Validation loss: 5.139515734865717

Epoch: 6| Step: 3
Training loss: 5.257598827265808
Validation loss: 5.132894560817422

Epoch: 6| Step: 4
Training loss: 4.159722963791945
Validation loss: 5.126782549245772

Epoch: 6| Step: 5
Training loss: 5.183343899993102
Validation loss: 5.1203531738006784

Epoch: 6| Step: 6
Training loss: 5.5130329038847945
Validation loss: 5.113705136899517

Epoch: 6| Step: 7
Training loss: 5.667379484035321
Validation loss: 5.107489841803981

Epoch: 6| Step: 8
Training loss: 4.95587216797533
Validation loss: 5.101368205726174

Epoch: 6| Step: 9
Training loss: 4.9481370522122345
Validation loss: 5.094403152871634

Epoch: 6| Step: 10
Training loss: 5.750566537562164
Validation loss: 5.087987155694164

Epoch: 6| Step: 11
Training loss: 4.814007015335683
Validation loss: 5.081708909098225

Epoch: 6| Step: 12
Training loss: 5.238086443641843
Validation loss: 5.076190630927178

Epoch: 6| Step: 13
Training loss: 4.460751932162667
Validation loss: 5.069219266631226

Epoch: 11| Step: 0
Training loss: 5.352980822543962
Validation loss: 5.06271468598207

Epoch: 6| Step: 1
Training loss: 4.444161157056816
Validation loss: 5.056178883609225

Epoch: 6| Step: 2
Training loss: 5.431237835096776
Validation loss: 5.050218669324283

Epoch: 6| Step: 3
Training loss: 3.5725297783263903
Validation loss: 5.043765406248252

Epoch: 6| Step: 4
Training loss: 5.5253870004296175
Validation loss: 5.037366099506664

Epoch: 6| Step: 5
Training loss: 4.909012326661589
Validation loss: 5.030459008126212

Epoch: 6| Step: 6
Training loss: 5.853865899700786
Validation loss: 5.024192330151503

Epoch: 6| Step: 7
Training loss: 6.240511902083741
Validation loss: 5.017129737713956

Epoch: 6| Step: 8
Training loss: 5.0576772441344025
Validation loss: 5.01045418432495

Epoch: 6| Step: 9
Training loss: 4.440416264309214
Validation loss: 5.003906345292983

Epoch: 6| Step: 10
Training loss: 5.5409467798419625
Validation loss: 4.998937112368785

Epoch: 6| Step: 11
Training loss: 5.410485521342808
Validation loss: 4.993353017624754

Epoch: 6| Step: 12
Training loss: 4.480864849058966
Validation loss: 4.98576697481629

Epoch: 6| Step: 13
Training loss: 5.184519451536408
Validation loss: 4.97953272581884

Epoch: 12| Step: 0
Training loss: 5.4280755813272865
Validation loss: 4.974174529431716

Epoch: 6| Step: 1
Training loss: 4.248694724306698
Validation loss: 4.968128381387968

Epoch: 6| Step: 2
Training loss: 4.151538444222505
Validation loss: 4.962507136777779

Epoch: 6| Step: 3
Training loss: 5.077397408813051
Validation loss: 4.957269164363831

Epoch: 6| Step: 4
Training loss: 5.502811580226565
Validation loss: 4.951955823763924

Epoch: 6| Step: 5
Training loss: 5.6743205869544555
Validation loss: 4.944770546254559

Epoch: 6| Step: 6
Training loss: 5.6772049170490595
Validation loss: 4.940046112679308

Epoch: 6| Step: 7
Training loss: 4.486523688325763
Validation loss: 4.933873708015057

Epoch: 6| Step: 8
Training loss: 4.224165541728423
Validation loss: 4.928472805550216

Epoch: 6| Step: 9
Training loss: 5.395324958015772
Validation loss: 4.924425753890977

Epoch: 6| Step: 10
Training loss: 4.501356556189174
Validation loss: 4.91655237528404

Epoch: 6| Step: 11
Training loss: 5.1580572486827325
Validation loss: 4.909990508671823

Epoch: 6| Step: 12
Training loss: 5.256439074949621
Validation loss: 4.905375019945336

Epoch: 6| Step: 13
Training loss: 5.640978688487029
Validation loss: 4.900268861310227

Epoch: 13| Step: 0
Training loss: 5.399723236620974
Validation loss: 4.894852441233316

Epoch: 6| Step: 1
Training loss: 4.676479150479883
Validation loss: 4.889154020017517

Epoch: 6| Step: 2
Training loss: 6.165649364518035
Validation loss: 4.883436434745612

Epoch: 6| Step: 3
Training loss: 3.974594498590096
Validation loss: 4.879162372659976

Epoch: 6| Step: 4
Training loss: 4.049842953874855
Validation loss: 4.874706748554154

Epoch: 6| Step: 5
Training loss: 5.00878592089612
Validation loss: 4.869450858799149

Epoch: 6| Step: 6
Training loss: 4.607769599267268
Validation loss: 4.862680110521266

Epoch: 6| Step: 7
Training loss: 5.3056862611409805
Validation loss: 4.857635022988128

Epoch: 6| Step: 8
Training loss: 5.538282503592572
Validation loss: 4.8517889112305586

Epoch: 6| Step: 9
Training loss: 4.764621316246596
Validation loss: 4.846994523411731

Epoch: 6| Step: 10
Training loss: 4.928194185592549
Validation loss: 4.842013139961373

Epoch: 6| Step: 11
Training loss: 5.181995642815911
Validation loss: 4.836265606244121

Epoch: 6| Step: 12
Training loss: 4.81652782376471
Validation loss: 4.8316002511947715

Epoch: 6| Step: 13
Training loss: 4.961015163023986
Validation loss: 4.8261215184691615

Epoch: 14| Step: 0
Training loss: 5.072417540803591
Validation loss: 4.822017291959528

Epoch: 6| Step: 1
Training loss: 4.916926921271161
Validation loss: 4.8174442803130475

Epoch: 6| Step: 2
Training loss: 4.733685635274433
Validation loss: 4.810562371246949

Epoch: 6| Step: 3
Training loss: 4.5012775303137245
Validation loss: 4.806043959600848

Epoch: 6| Step: 4
Training loss: 5.308246121171716
Validation loss: 4.800721820228591

Epoch: 6| Step: 5
Training loss: 4.625388051842457
Validation loss: 4.796004457621747

Epoch: 6| Step: 6
Training loss: 5.664049366902878
Validation loss: 4.790606317817573

Epoch: 6| Step: 7
Training loss: 4.862660759864639
Validation loss: 4.786229949693982

Epoch: 6| Step: 8
Training loss: 5.272273815471151
Validation loss: 4.780620358963942

Epoch: 6| Step: 9
Training loss: 5.591123166606166
Validation loss: 4.7761951395528275

Epoch: 6| Step: 10
Training loss: 5.102916683843758
Validation loss: 4.770976979232319

Epoch: 6| Step: 11
Training loss: 4.635571743660646
Validation loss: 4.765496757741296

Epoch: 6| Step: 12
Training loss: 3.847491916303465
Validation loss: 4.760449142957408

Epoch: 6| Step: 13
Training loss: 4.3560579320524955
Validation loss: 4.755628831146364

Epoch: 15| Step: 0
Training loss: 5.334471382472674
Validation loss: 4.7506698504167915

Epoch: 6| Step: 1
Training loss: 4.302601386676083
Validation loss: 4.746461152349628

Epoch: 6| Step: 2
Training loss: 4.508098520497064
Validation loss: 4.741615022043961

Epoch: 6| Step: 3
Training loss: 5.145301060297506
Validation loss: 4.737892547958444

Epoch: 6| Step: 4
Training loss: 5.612324313874026
Validation loss: 4.732580686332446

Epoch: 6| Step: 5
Training loss: 5.1706563660583145
Validation loss: 4.728316254412939

Epoch: 6| Step: 6
Training loss: 5.1387104770975025
Validation loss: 4.722483961792653

Epoch: 6| Step: 7
Training loss: 4.554298030893369
Validation loss: 4.7178095202447

Epoch: 6| Step: 8
Training loss: 4.849562768792865
Validation loss: 4.711247051774855

Epoch: 6| Step: 9
Training loss: 4.078655339977162
Validation loss: 4.706541964055963

Epoch: 6| Step: 10
Training loss: 4.427323398438975
Validation loss: 4.700879140566567

Epoch: 6| Step: 11
Training loss: 3.7058013387136284
Validation loss: 4.69510870653648

Epoch: 6| Step: 12
Training loss: 5.291413588992585
Validation loss: 4.69004074751363

Epoch: 6| Step: 13
Training loss: 5.314824571845452
Validation loss: 4.684069925578432

Epoch: 16| Step: 0
Training loss: 4.93589621463523
Validation loss: 4.680175619932943

Epoch: 6| Step: 1
Training loss: 4.100450928244527
Validation loss: 4.6742189581091695

Epoch: 6| Step: 2
Training loss: 4.7465506628055785
Validation loss: 4.669093738381025

Epoch: 6| Step: 3
Training loss: 4.614960987260936
Validation loss: 4.663734224269431

Epoch: 6| Step: 4
Training loss: 5.1158471601620095
Validation loss: 4.659926087716953

Epoch: 6| Step: 5
Training loss: 4.495463309677029
Validation loss: 4.6551898201640975

Epoch: 6| Step: 6
Training loss: 5.121800796501935
Validation loss: 4.650351968385899

Epoch: 6| Step: 7
Training loss: 4.670649441114397
Validation loss: 4.644947457921456

Epoch: 6| Step: 8
Training loss: 4.9556146856713745
Validation loss: 4.640521047264869

Epoch: 6| Step: 9
Training loss: 4.776941689566409
Validation loss: 4.635797594970297

Epoch: 6| Step: 10
Training loss: 5.020240632631217
Validation loss: 4.6306937971242075

Epoch: 6| Step: 11
Training loss: 4.6358498817343685
Validation loss: 4.625750987623911

Epoch: 6| Step: 12
Training loss: 4.7957221519028765
Validation loss: 4.62041882283071

Epoch: 6| Step: 13
Training loss: 4.756174391196935
Validation loss: 4.615206961187803

Epoch: 17| Step: 0
Training loss: 4.357652330652236
Validation loss: 4.612724130590032

Epoch: 6| Step: 1
Training loss: 3.8475017071200246
Validation loss: 4.605854651342707

Epoch: 6| Step: 2
Training loss: 5.520768401525836
Validation loss: 4.600803107491894

Epoch: 6| Step: 3
Training loss: 4.431751234709329
Validation loss: 4.596717861868785

Epoch: 6| Step: 4
Training loss: 4.458082578268173
Validation loss: 4.591798173067793

Epoch: 6| Step: 5
Training loss: 4.4559634080408275
Validation loss: 4.587813384173345

Epoch: 6| Step: 6
Training loss: 4.746828727170161
Validation loss: 4.583314126870343

Epoch: 6| Step: 7
Training loss: 4.883375553473709
Validation loss: 4.578793664561417

Epoch: 6| Step: 8
Training loss: 4.829270310341582
Validation loss: 4.573572979219234

Epoch: 6| Step: 9
Training loss: 4.95409434367082
Validation loss: 4.568357983290368

Epoch: 6| Step: 10
Training loss: 4.776590308151184
Validation loss: 4.564052369949816

Epoch: 6| Step: 11
Training loss: 5.141741506731537
Validation loss: 4.558135727964304

Epoch: 6| Step: 12
Training loss: 4.496570976112007
Validation loss: 4.552917834621831

Epoch: 6| Step: 13
Training loss: 4.778918726419773
Validation loss: 4.547985802039198

Epoch: 18| Step: 0
Training loss: 4.513192230979036
Validation loss: 4.543473971945289

Epoch: 6| Step: 1
Training loss: 4.668597548522293
Validation loss: 4.538210484110629

Epoch: 6| Step: 2
Training loss: 4.567976082146288
Validation loss: 4.533085208067578

Epoch: 6| Step: 3
Training loss: 4.326339408437803
Validation loss: 4.528022634026175

Epoch: 6| Step: 4
Training loss: 4.589186704966045
Validation loss: 4.52407017281994

Epoch: 6| Step: 5
Training loss: 4.708202979159751
Validation loss: 4.519675491831555

Epoch: 6| Step: 6
Training loss: 5.645270550632959
Validation loss: 4.514923639619867

Epoch: 6| Step: 7
Training loss: 3.887989300418778
Validation loss: 4.508914964755191

Epoch: 6| Step: 8
Training loss: 4.740257511467537
Validation loss: 4.504712074892861

Epoch: 6| Step: 9
Training loss: 5.030326616364943
Validation loss: 4.501302707161905

Epoch: 6| Step: 10
Training loss: 4.403338830113259
Validation loss: 4.495159919420187

Epoch: 6| Step: 11
Training loss: 4.3748144927886345
Validation loss: 4.490468509560399

Epoch: 6| Step: 12
Training loss: 5.074223636569048
Validation loss: 4.486340985676223

Epoch: 6| Step: 13
Training loss: 4.190695838414835
Validation loss: 4.480964560043597

Epoch: 19| Step: 0
Training loss: 5.111182963285475
Validation loss: 4.477170431367658

Epoch: 6| Step: 1
Training loss: 4.100478837499024
Validation loss: 4.4713789847175285

Epoch: 6| Step: 2
Training loss: 4.414612538323764
Validation loss: 4.466147013702088

Epoch: 6| Step: 3
Training loss: 5.3519773447786045
Validation loss: 4.462625089685543

Epoch: 6| Step: 4
Training loss: 4.378636402047218
Validation loss: 4.457270569858012

Epoch: 6| Step: 5
Training loss: 4.103124702494277
Validation loss: 4.45233721987251

Epoch: 6| Step: 6
Training loss: 5.080426536735476
Validation loss: 4.447450808474085

Epoch: 6| Step: 7
Training loss: 4.7140513894440454
Validation loss: 4.442664923983168

Epoch: 6| Step: 8
Training loss: 4.278026174514259
Validation loss: 4.437130496262538

Epoch: 6| Step: 9
Training loss: 5.387423684272235
Validation loss: 4.433823078515095

Epoch: 6| Step: 10
Training loss: 4.457508593180317
Validation loss: 4.4299784928625705

Epoch: 6| Step: 11
Training loss: 4.438255138350622
Validation loss: 4.424444379963521

Epoch: 6| Step: 12
Training loss: 3.6806099093920217
Validation loss: 4.419151932468029

Epoch: 6| Step: 13
Training loss: 4.18446809695026
Validation loss: 4.415258519001103

Epoch: 20| Step: 0
Training loss: 4.232242061103019
Validation loss: 4.409875843379288

Epoch: 6| Step: 1
Training loss: 4.4768541384195855
Validation loss: 4.40594495795096

Epoch: 6| Step: 2
Training loss: 4.140805567996779
Validation loss: 4.4016510791687935

Epoch: 6| Step: 3
Training loss: 4.247110618808796
Validation loss: 4.398145323784053

Epoch: 6| Step: 4
Training loss: 4.593387926844888
Validation loss: 4.392747938221679

Epoch: 6| Step: 5
Training loss: 4.6244003319539475
Validation loss: 4.3888907305127445

Epoch: 6| Step: 6
Training loss: 4.244119278090011
Validation loss: 4.384714422231434

Epoch: 6| Step: 7
Training loss: 5.570587108632561
Validation loss: 4.38083272589397

Epoch: 6| Step: 8
Training loss: 4.795734083450617
Validation loss: 4.375883485507513

Epoch: 6| Step: 9
Training loss: 4.555134929580524
Validation loss: 4.372179266462657

Epoch: 6| Step: 10
Training loss: 4.5217499162711166
Validation loss: 4.366751388038541

Epoch: 6| Step: 11
Training loss: 4.944855824095759
Validation loss: 4.36181034805274

Epoch: 6| Step: 12
Training loss: 3.089945447866123
Validation loss: 4.357922164943188

Epoch: 6| Step: 13
Training loss: 4.713610142444024
Validation loss: 4.353407171469282

Epoch: 21| Step: 0
Training loss: 4.725466968531122
Validation loss: 4.348767481592678

Epoch: 6| Step: 1
Training loss: 4.93566976499165
Validation loss: 4.344201775711493

Epoch: 6| Step: 2
Training loss: 4.253269508704084
Validation loss: 4.338564002203567

Epoch: 6| Step: 3
Training loss: 4.338865319216625
Validation loss: 4.334293271380372

Epoch: 6| Step: 4
Training loss: 4.980181134464898
Validation loss: 4.330158807016898

Epoch: 6| Step: 5
Training loss: 3.812539522560256
Validation loss: 4.326300483209938

Epoch: 6| Step: 6
Training loss: 3.9478657231864593
Validation loss: 4.320503106491266

Epoch: 6| Step: 7
Training loss: 4.4432123516198185
Validation loss: 4.315929431384329

Epoch: 6| Step: 8
Training loss: 3.3329048040227947
Validation loss: 4.31373418203199

Epoch: 6| Step: 9
Training loss: 4.726707166239091
Validation loss: 4.309706405057139

Epoch: 6| Step: 10
Training loss: 4.551982724309497
Validation loss: 4.304820017727815

Epoch: 6| Step: 11
Training loss: 4.487014047136927
Validation loss: 4.299474773562625

Epoch: 6| Step: 12
Training loss: 4.958007716324847
Validation loss: 4.295434883846993

Epoch: 6| Step: 13
Training loss: 4.476080796986071
Validation loss: 4.291436136714475

Epoch: 22| Step: 0
Training loss: 3.2864423087445265
Validation loss: 4.286452146999241

Epoch: 6| Step: 1
Training loss: 4.159008516119942
Validation loss: 4.282143418401309

Epoch: 6| Step: 2
Training loss: 4.477942768230393
Validation loss: 4.278336510492999

Epoch: 6| Step: 3
Training loss: 4.274284097614376
Validation loss: 4.273994274702627

Epoch: 6| Step: 4
Training loss: 4.451255218408531
Validation loss: 4.270261989927078

Epoch: 6| Step: 5
Training loss: 4.739187281343341
Validation loss: 4.265869096378907

Epoch: 6| Step: 6
Training loss: 4.606957994809849
Validation loss: 4.261495414777073

Epoch: 6| Step: 7
Training loss: 4.78836587192214
Validation loss: 4.256813384723656

Epoch: 6| Step: 8
Training loss: 4.529424260080702
Validation loss: 4.252268242012299

Epoch: 6| Step: 9
Training loss: 5.151460584905694
Validation loss: 4.247465874121532

Epoch: 6| Step: 10
Training loss: 4.505862973083197
Validation loss: 4.243003977399477

Epoch: 6| Step: 11
Training loss: 3.8148548795563895
Validation loss: 4.238122761893664

Epoch: 6| Step: 12
Training loss: 4.523875582602293
Validation loss: 4.234226782575408

Epoch: 6| Step: 13
Training loss: 3.795098536723702
Validation loss: 4.2297149954180355

Epoch: 23| Step: 0
Training loss: 4.362466570444646
Validation loss: 4.224556851894566

Epoch: 6| Step: 1
Training loss: 4.391000751965293
Validation loss: 4.220413614676763

Epoch: 6| Step: 2
Training loss: 4.488777790541256
Validation loss: 4.2154492687776886

Epoch: 6| Step: 3
Training loss: 4.5116663281586575
Validation loss: 4.21102129511362

Epoch: 6| Step: 4
Training loss: 4.490516842871573
Validation loss: 4.206417538394038

Epoch: 6| Step: 5
Training loss: 4.199134265138489
Validation loss: 4.202357566003734

Epoch: 6| Step: 6
Training loss: 4.214393457323932
Validation loss: 4.1985273398206955

Epoch: 6| Step: 7
Training loss: 4.232340531564311
Validation loss: 4.193981108572438

Epoch: 6| Step: 8
Training loss: 4.4434568155524685
Validation loss: 4.189148839231315

Epoch: 6| Step: 9
Training loss: 4.855290797096012
Validation loss: 4.184970357342514

Epoch: 6| Step: 10
Training loss: 4.559037240102413
Validation loss: 4.179870677511083

Epoch: 6| Step: 11
Training loss: 4.596152164101638
Validation loss: 4.175567098085823

Epoch: 6| Step: 12
Training loss: 3.547121955239802
Validation loss: 4.171138950904889

Epoch: 6| Step: 13
Training loss: 3.4847636326849476
Validation loss: 4.166786700744977

Epoch: 24| Step: 0
Training loss: 4.063778720027896
Validation loss: 4.16261446683739

Epoch: 6| Step: 1
Training loss: 4.6167727314761295
Validation loss: 4.158929291080286

Epoch: 6| Step: 2
Training loss: 4.545903787087346
Validation loss: 4.154744728959576

Epoch: 6| Step: 3
Training loss: 4.1537959375633715
Validation loss: 4.1498742019399915

Epoch: 6| Step: 4
Training loss: 5.0927160418925395
Validation loss: 4.145801633525149

Epoch: 6| Step: 5
Training loss: 4.420496641539424
Validation loss: 4.14091603917708

Epoch: 6| Step: 6
Training loss: 4.92556982471516
Validation loss: 4.136102396934

Epoch: 6| Step: 7
Training loss: 3.191243684660075
Validation loss: 4.131982173088494

Epoch: 6| Step: 8
Training loss: 3.8561474358321672
Validation loss: 4.127386366175097

Epoch: 6| Step: 9
Training loss: 3.7999074623485383
Validation loss: 4.123201382704219

Epoch: 6| Step: 10
Training loss: 3.7612794993984715
Validation loss: 4.1190548256743575

Epoch: 6| Step: 11
Training loss: 3.8050659743415483
Validation loss: 4.114859591839185

Epoch: 6| Step: 12
Training loss: 4.496176472821753
Validation loss: 4.1105618618305835

Epoch: 6| Step: 13
Training loss: 4.593205010919812
Validation loss: 4.106240686012206

Epoch: 25| Step: 0
Training loss: 4.002128749882948
Validation loss: 4.10250609185702

Epoch: 6| Step: 1
Training loss: 4.753143475037032
Validation loss: 4.097995507639503

Epoch: 6| Step: 2
Training loss: 4.4710866514446534
Validation loss: 4.093620201169142

Epoch: 6| Step: 3
Training loss: 4.220003973068609
Validation loss: 4.089452550542285

Epoch: 6| Step: 4
Training loss: 3.9253561064881923
Validation loss: 4.08479292078168

Epoch: 6| Step: 5
Training loss: 4.078925627826983
Validation loss: 4.080695948397605

Epoch: 6| Step: 6
Training loss: 4.259307318952258
Validation loss: 4.076472058260995

Epoch: 6| Step: 7
Training loss: 4.31273550966135
Validation loss: 4.072429728689138

Epoch: 6| Step: 8
Training loss: 4.228002052746927
Validation loss: 4.0677268808929465

Epoch: 6| Step: 9
Training loss: 4.554589926458074
Validation loss: 4.063447968824635

Epoch: 6| Step: 10
Training loss: 4.533683807251641
Validation loss: 4.059015882982429

Epoch: 6| Step: 11
Training loss: 4.528857842766247
Validation loss: 4.054475125806858

Epoch: 6| Step: 12
Training loss: 3.676519305635687
Validation loss: 4.050081924112236

Epoch: 6| Step: 13
Training loss: 3.081082390178549
Validation loss: 4.045814993934958

Epoch: 26| Step: 0
Training loss: 3.843010932146455
Validation loss: 4.041314722579832

Epoch: 6| Step: 1
Training loss: 4.3881761774323245
Validation loss: 4.037506590878173

Epoch: 6| Step: 2
Training loss: 3.72014098238669
Validation loss: 4.032793444500154

Epoch: 6| Step: 3
Training loss: 4.401552983965352
Validation loss: 4.0286628642232865

Epoch: 6| Step: 4
Training loss: 4.137349456168881
Validation loss: 4.0246087699602615

Epoch: 6| Step: 5
Training loss: 4.012665960854868
Validation loss: 4.0202350599607035

Epoch: 6| Step: 6
Training loss: 3.776922350379459
Validation loss: 4.015960422068814

Epoch: 6| Step: 7
Training loss: 4.988499193799972
Validation loss: 4.011632891772835

Epoch: 6| Step: 8
Training loss: 4.464159762104376
Validation loss: 4.0080541348256356

Epoch: 6| Step: 9
Training loss: 4.615236647997219
Validation loss: 4.003127464911094

Epoch: 6| Step: 10
Training loss: 3.949827967893304
Validation loss: 3.9990085127990223

Epoch: 6| Step: 11
Training loss: 4.244460141706039
Validation loss: 3.994645906430919

Epoch: 6| Step: 12
Training loss: 3.890702702615763
Validation loss: 3.990099396292185

Epoch: 6| Step: 13
Training loss: 3.356632692480153
Validation loss: 3.985609753337122

Epoch: 27| Step: 0
Training loss: 3.3541335268140777
Validation loss: 3.9816335783762944

Epoch: 6| Step: 1
Training loss: 4.853586361406064
Validation loss: 3.9772356284256727

Epoch: 6| Step: 2
Training loss: 4.12347175725574
Validation loss: 3.973162083412978

Epoch: 6| Step: 3
Training loss: 4.329463600253265
Validation loss: 3.9688191645645445

Epoch: 6| Step: 4
Training loss: 3.680508596892462
Validation loss: 3.9648297990825987

Epoch: 6| Step: 5
Training loss: 4.356447611066138
Validation loss: 3.9600638705860147

Epoch: 6| Step: 6
Training loss: 4.137475539766137
Validation loss: 3.9559458844218844

Epoch: 6| Step: 7
Training loss: 3.9710996385733686
Validation loss: 3.9516431521441837

Epoch: 6| Step: 8
Training loss: 3.7295017766716865
Validation loss: 3.947191451941034

Epoch: 6| Step: 9
Training loss: 4.269885049384929
Validation loss: 3.9431332855129497

Epoch: 6| Step: 10
Training loss: 4.4382695350163335
Validation loss: 3.93871728558858

Epoch: 6| Step: 11
Training loss: 4.262635241737388
Validation loss: 3.9343332948461414

Epoch: 6| Step: 12
Training loss: 3.8100022435619727
Validation loss: 3.93022816391239

Epoch: 6| Step: 13
Training loss: 3.67527165868548
Validation loss: 3.9257094444679486

Epoch: 28| Step: 0
Training loss: 3.868810447997128
Validation loss: 3.9214327944109852

Epoch: 6| Step: 1
Training loss: 4.433315829670324
Validation loss: 3.917296331938085

Epoch: 6| Step: 2
Training loss: 3.9633495202360924
Validation loss: 3.9127286159685073

Epoch: 6| Step: 3
Training loss: 3.927367722039928
Validation loss: 3.908509559698062

Epoch: 6| Step: 4
Training loss: 4.268820212193098
Validation loss: 3.9041424978859096

Epoch: 6| Step: 5
Training loss: 3.370610526273277
Validation loss: 3.8999768761821465

Epoch: 6| Step: 6
Training loss: 3.984723004869612
Validation loss: 3.8957603298153853

Epoch: 6| Step: 7
Training loss: 3.8991796364310023
Validation loss: 3.891377694117646

Epoch: 6| Step: 8
Training loss: 3.587439926654655
Validation loss: 3.8874450925034303

Epoch: 6| Step: 9
Training loss: 4.4475000024016085
Validation loss: 3.8828869613579315

Epoch: 6| Step: 10
Training loss: 4.64580454910097
Validation loss: 3.8788693500875255

Epoch: 6| Step: 11
Training loss: 3.820916687788674
Validation loss: 3.874457003377967

Epoch: 6| Step: 12
Training loss: 3.8459637477552815
Validation loss: 3.8702032898007257

Epoch: 6| Step: 13
Training loss: 4.142609894238153
Validation loss: 3.86600938313216

Epoch: 29| Step: 0
Training loss: 3.81057177701211
Validation loss: 3.861500946021097

Epoch: 6| Step: 1
Training loss: 4.128199405851498
Validation loss: 3.8573674837937464

Epoch: 6| Step: 2
Training loss: 2.892140913742172
Validation loss: 3.8530568492479818

Epoch: 6| Step: 3
Training loss: 4.600290430271406
Validation loss: 3.848722224377419

Epoch: 6| Step: 4
Training loss: 4.695859651850026
Validation loss: 3.84496052606408

Epoch: 6| Step: 5
Training loss: 3.853798362386404
Validation loss: 3.8402775325089085

Epoch: 6| Step: 6
Training loss: 3.8221265234413484
Validation loss: 3.8356719899532763

Epoch: 6| Step: 7
Training loss: 3.9547881597024332
Validation loss: 3.8314853996241935

Epoch: 6| Step: 8
Training loss: 3.694908845884365
Validation loss: 3.8270298020480262

Epoch: 6| Step: 9
Training loss: 4.085020586052972
Validation loss: 3.822990700873659

Epoch: 6| Step: 10
Training loss: 3.9076572172298025
Validation loss: 3.8184168818599544

Epoch: 6| Step: 11
Training loss: 3.972247287401436
Validation loss: 3.814175034565852

Epoch: 6| Step: 12
Training loss: 4.116357708867575
Validation loss: 3.8099843256336765

Epoch: 6| Step: 13
Training loss: 3.7483289174186325
Validation loss: 3.805746945366219

Epoch: 30| Step: 0
Training loss: 3.6561722706414455
Validation loss: 3.80147172720445

Epoch: 6| Step: 1
Training loss: 4.663124488551377
Validation loss: 3.7971465716158797

Epoch: 6| Step: 2
Training loss: 2.9514849917653674
Validation loss: 3.7928283854008336

Epoch: 6| Step: 3
Training loss: 3.9832608927972433
Validation loss: 3.7887431950740353

Epoch: 6| Step: 4
Training loss: 3.2709876022080593
Validation loss: 3.7843341072323877

Epoch: 6| Step: 5
Training loss: 2.7659890317830422
Validation loss: 3.780622950493586

Epoch: 6| Step: 6
Training loss: 4.88307499294438
Validation loss: 3.7766890117818095

Epoch: 6| Step: 7
Training loss: 4.4032612938562545
Validation loss: 3.772362176068309

Epoch: 6| Step: 8
Training loss: 4.203380023919832
Validation loss: 3.768333315865473

Epoch: 6| Step: 9
Training loss: 3.8716934617213234
Validation loss: 3.763566252396465

Epoch: 6| Step: 10
Training loss: 4.392254618617371
Validation loss: 3.759694326806383

Epoch: 6| Step: 11
Training loss: 4.118492079026605
Validation loss: 3.755203853750886

Epoch: 6| Step: 12
Training loss: 3.595677928432224
Validation loss: 3.7506714537619716

Epoch: 6| Step: 13
Training loss: 3.3082946858362723
Validation loss: 3.7461897460178593

Epoch: 31| Step: 0
Training loss: 3.7745299090808513
Validation loss: 3.7421981609620016

Epoch: 6| Step: 1
Training loss: 4.39010410680698
Validation loss: 3.7380078892428124

Epoch: 6| Step: 2
Training loss: 4.680446760584091
Validation loss: 3.733613100099519

Epoch: 6| Step: 3
Training loss: 3.859174344796456
Validation loss: 3.7290055366243817

Epoch: 6| Step: 4
Training loss: 4.2342193687526075
Validation loss: 3.7248931707300876

Epoch: 6| Step: 5
Training loss: 4.188260365245332
Validation loss: 3.720418048393707

Epoch: 6| Step: 6
Training loss: 3.98891892972335
Validation loss: 3.7156325878924594

Epoch: 6| Step: 7
Training loss: 3.9959509144423087
Validation loss: 3.7109250359576866

Epoch: 6| Step: 8
Training loss: 3.8839529653700793
Validation loss: 3.7066647744059593

Epoch: 6| Step: 9
Training loss: 3.4147660776563167
Validation loss: 3.7022462598977666

Epoch: 6| Step: 10
Training loss: 3.958351509989448
Validation loss: 3.697713962783983

Epoch: 6| Step: 11
Training loss: 3.435657909305784
Validation loss: 3.693336802789686

Epoch: 6| Step: 12
Training loss: 2.9308825687556874
Validation loss: 3.6891339879081837

Epoch: 6| Step: 13
Training loss: 2.7194622466098117
Validation loss: 3.684791324423006

Epoch: 32| Step: 0
Training loss: 3.2863749852722592
Validation loss: 3.681008730086179

Epoch: 6| Step: 1
Training loss: 4.262040081549947
Validation loss: 3.6770405681309786

Epoch: 6| Step: 2
Training loss: 4.692257717342677
Validation loss: 3.6729292093467802

Epoch: 6| Step: 3
Training loss: 3.541540764459464
Validation loss: 3.6688120952075765

Epoch: 6| Step: 4
Training loss: 4.241748653636257
Validation loss: 3.664150147518296

Epoch: 6| Step: 5
Training loss: 4.034334171008785
Validation loss: 3.6599036977428394

Epoch: 6| Step: 6
Training loss: 3.021634296034139
Validation loss: 3.655808990051968

Epoch: 6| Step: 7
Training loss: 3.6960818757983405
Validation loss: 3.651010372591883

Epoch: 6| Step: 8
Training loss: 3.6454101026200303
Validation loss: 3.646685858460392

Epoch: 6| Step: 9
Training loss: 3.498756869119577
Validation loss: 3.641852852595962

Epoch: 6| Step: 10
Training loss: 4.207642803885316
Validation loss: 3.6379357967209427

Epoch: 6| Step: 11
Training loss: 3.359089684013963
Validation loss: 3.633612431880256

Epoch: 6| Step: 12
Training loss: 3.2642068658424046
Validation loss: 3.629060509957987

Epoch: 6| Step: 13
Training loss: 3.9470921496702203
Validation loss: 3.6255122951821144

Epoch: 33| Step: 0
Training loss: 3.7211087223563077
Validation loss: 3.6207664037268485

Epoch: 6| Step: 1
Training loss: 3.122029380303307
Validation loss: 3.6174378936645564

Epoch: 6| Step: 2
Training loss: 4.028880524493082
Validation loss: 3.612845531689107

Epoch: 6| Step: 3
Training loss: 3.2786494531023176
Validation loss: 3.608508139436681

Epoch: 6| Step: 4
Training loss: 3.8657391542865867
Validation loss: 3.6045766975736555

Epoch: 6| Step: 5
Training loss: 4.086099945982071
Validation loss: 3.600701207729173

Epoch: 6| Step: 6
Training loss: 4.127505148613513
Validation loss: 3.5961512407769147

Epoch: 6| Step: 7
Training loss: 3.2512449667663215
Validation loss: 3.5924786295262927

Epoch: 6| Step: 8
Training loss: 4.150440257056181
Validation loss: 3.5887452369090536

Epoch: 6| Step: 9
Training loss: 2.9471507520895486
Validation loss: 3.584114403579036

Epoch: 6| Step: 10
Training loss: 4.145485152507267
Validation loss: 3.5798232755605115

Epoch: 6| Step: 11
Training loss: 3.955714768397547
Validation loss: 3.5754397559738336

Epoch: 6| Step: 12
Training loss: 3.2058653483632056
Validation loss: 3.5715950652324056

Epoch: 6| Step: 13
Training loss: 4.018598235069331
Validation loss: 3.567399008305409

Epoch: 34| Step: 0
Training loss: 4.354256417598223
Validation loss: 3.5633180359481407

Epoch: 6| Step: 1
Training loss: 3.8529114749895883
Validation loss: 3.5592027094992957

Epoch: 6| Step: 2
Training loss: 3.8773193801338475
Validation loss: 3.555163743530901

Epoch: 6| Step: 3
Training loss: 3.548046842745376
Validation loss: 3.5506771843169873

Epoch: 6| Step: 4
Training loss: 3.8479340893499523
Validation loss: 3.5462526960231577

Epoch: 6| Step: 5
Training loss: 3.2120208026597137
Validation loss: 3.5421409214604864

Epoch: 6| Step: 6
Training loss: 4.181372871361208
Validation loss: 3.5381178784698855

Epoch: 6| Step: 7
Training loss: 3.752728296256917
Validation loss: 3.533715931553088

Epoch: 6| Step: 8
Training loss: 2.9873528927133846
Validation loss: 3.5295288482580838

Epoch: 6| Step: 9
Training loss: 3.7863372125716284
Validation loss: 3.5254273022604443

Epoch: 6| Step: 10
Training loss: 3.4166755366016406
Validation loss: 3.5216045024155553

Epoch: 6| Step: 11
Training loss: 3.121092527768847
Validation loss: 3.517413440318013

Epoch: 6| Step: 12
Training loss: 3.735988380152666
Validation loss: 3.513245564316913

Epoch: 6| Step: 13
Training loss: 3.5243606203952473
Validation loss: 3.5094785634830132

Epoch: 35| Step: 0
Training loss: 3.5860351017320635
Validation loss: 3.505374664547126

Epoch: 6| Step: 1
Training loss: 4.015475377957923
Validation loss: 3.5014869165440743

Epoch: 6| Step: 2
Training loss: 3.5983761409906525
Validation loss: 3.497927733436574

Epoch: 6| Step: 3
Training loss: 4.014970421783076
Validation loss: 3.494143308862743

Epoch: 6| Step: 4
Training loss: 3.8328713401262164
Validation loss: 3.4896286387373046

Epoch: 6| Step: 5
Training loss: 3.7489807015179477
Validation loss: 3.485468169791572

Epoch: 6| Step: 6
Training loss: 4.298030517569187
Validation loss: 3.481291930826768

Epoch: 6| Step: 7
Training loss: 3.123215432834017
Validation loss: 3.4771455540165026

Epoch: 6| Step: 8
Training loss: 3.560836001828979
Validation loss: 3.4728890545866173

Epoch: 6| Step: 9
Training loss: 3.289862093832437
Validation loss: 3.4688049518253377

Epoch: 6| Step: 10
Training loss: 3.0636722111875057
Validation loss: 3.4647062862842635

Epoch: 6| Step: 11
Training loss: 3.313101372021983
Validation loss: 3.4609006215262657

Epoch: 6| Step: 12
Training loss: 3.8660811874382266
Validation loss: 3.4570226177100616

Epoch: 6| Step: 13
Training loss: 3.0990770504221294
Validation loss: 3.45317577019792

Epoch: 36| Step: 0
Training loss: 3.679248435356366
Validation loss: 3.4494193145859997

Epoch: 6| Step: 1
Training loss: 3.6948017307714784
Validation loss: 3.445743363730773

Epoch: 6| Step: 2
Training loss: 2.7454948803283052
Validation loss: 3.4416917616796736

Epoch: 6| Step: 3
Training loss: 3.9227415548506817
Validation loss: 3.437841433127746

Epoch: 6| Step: 4
Training loss: 2.709007169576728
Validation loss: 3.4341573241848136

Epoch: 6| Step: 5
Training loss: 2.3833951644168505
Validation loss: 3.43037955587265

Epoch: 6| Step: 6
Training loss: 3.40662878887621
Validation loss: 3.426572272661789

Epoch: 6| Step: 7
Training loss: 3.9070143295193245
Validation loss: 3.4233448465804326

Epoch: 6| Step: 8
Training loss: 3.554264387164003
Validation loss: 3.4198414930900096

Epoch: 6| Step: 9
Training loss: 3.9216614927254225
Validation loss: 3.4159903826179883

Epoch: 6| Step: 10
Training loss: 4.724048999167262
Validation loss: 3.411939133791778

Epoch: 6| Step: 11
Training loss: 3.504749617619231
Validation loss: 3.4081236676096287

Epoch: 6| Step: 12
Training loss: 4.076882827238984
Validation loss: 3.4043092944468905

Epoch: 6| Step: 13
Training loss: 2.926217671785696
Validation loss: 3.40018667755763

Epoch: 37| Step: 0
Training loss: 3.806187140285538
Validation loss: 3.3961454766786794

Epoch: 6| Step: 1
Training loss: 2.8638156116417326
Validation loss: 3.3921581733849813

Epoch: 6| Step: 2
Training loss: 3.3854423326350807
Validation loss: 3.3883546180513155

Epoch: 6| Step: 3
Training loss: 3.317906412213141
Validation loss: 3.3844784810926316

Epoch: 6| Step: 4
Training loss: 3.4550158816909677
Validation loss: 3.381199558655097

Epoch: 6| Step: 5
Training loss: 3.9211004335810493
Validation loss: 3.3770910072749354

Epoch: 6| Step: 6
Training loss: 3.6619699192197115
Validation loss: 3.3734216649348028

Epoch: 6| Step: 7
Training loss: 3.7088073398951917
Validation loss: 3.3700956456112987

Epoch: 6| Step: 8
Training loss: 3.546867471426481
Validation loss: 3.3662471771133964

Epoch: 6| Step: 9
Training loss: 3.7394099429992638
Validation loss: 3.362597624579951

Epoch: 6| Step: 10
Training loss: 3.211028086180384
Validation loss: 3.3587402927006176

Epoch: 6| Step: 11
Training loss: 3.896894191520317
Validation loss: 3.354956389786639

Epoch: 6| Step: 12
Training loss: 3.52047205469011
Validation loss: 3.351232007025917

Epoch: 6| Step: 13
Training loss: 2.920625470465686
Validation loss: 3.347353007152092

Epoch: 38| Step: 0
Training loss: 3.7074052885257465
Validation loss: 3.3441391953088484

Epoch: 6| Step: 1
Training loss: 3.384521334681906
Validation loss: 3.339814291186479

Epoch: 6| Step: 2
Training loss: 3.426107915181915
Validation loss: 3.33612540056096

Epoch: 6| Step: 3
Training loss: 3.4303212894515793
Validation loss: 3.3320562220864125

Epoch: 6| Step: 4
Training loss: 3.650362148347327
Validation loss: 3.3283033487353895

Epoch: 6| Step: 5
Training loss: 3.5713677046902483
Validation loss: 3.3245601635619693

Epoch: 6| Step: 6
Training loss: 4.5196865519989675
Validation loss: 3.3203930654288136

Epoch: 6| Step: 7
Training loss: 3.5439056200846237
Validation loss: 3.3159881555907873

Epoch: 6| Step: 8
Training loss: 2.8152117054337373
Validation loss: 3.3122113180025465

Epoch: 6| Step: 9
Training loss: 3.3151354112773403
Validation loss: 3.3083091952758945

Epoch: 6| Step: 10
Training loss: 2.779315575800138
Validation loss: 3.304426166370854

Epoch: 6| Step: 11
Training loss: 3.4524898721710753
Validation loss: 3.300405940702334

Epoch: 6| Step: 12
Training loss: 3.5451750189401077
Validation loss: 3.297143259328629

Epoch: 6| Step: 13
Training loss: 2.970741487414613
Validation loss: 3.2935371677611585

Epoch: 39| Step: 0
Training loss: 3.1115362429413698
Validation loss: 3.28984898868972

Epoch: 6| Step: 1
Training loss: 3.42112270777665
Validation loss: 3.286526799685291

Epoch: 6| Step: 2
Training loss: 3.182612842558019
Validation loss: 3.2842067536278448

Epoch: 6| Step: 3
Training loss: 3.3153806432767947
Validation loss: 3.2804704254744497

Epoch: 6| Step: 4
Training loss: 3.7018144437263802
Validation loss: 3.2770142599895045

Epoch: 6| Step: 5
Training loss: 3.5443953530297803
Validation loss: 3.2736101613299393

Epoch: 6| Step: 6
Training loss: 3.8770402028948943
Validation loss: 3.2697550379141687

Epoch: 6| Step: 7
Training loss: 3.7918041888997918
Validation loss: 3.266457094230022

Epoch: 6| Step: 8
Training loss: 3.3392317718741755
Validation loss: 3.2628327620189257

Epoch: 6| Step: 9
Training loss: 3.214090474572138
Validation loss: 3.259293863585631

Epoch: 6| Step: 10
Training loss: 3.2709109222215758
Validation loss: 3.255884125815116

Epoch: 6| Step: 11
Training loss: 3.676562883901515
Validation loss: 3.2525131094744353

Epoch: 6| Step: 12
Training loss: 3.1187576507902617
Validation loss: 3.2484635854031216

Epoch: 6| Step: 13
Training loss: 3.0277387595117267
Validation loss: 3.245284425273954

Epoch: 40| Step: 0
Training loss: 3.7845282097570334
Validation loss: 3.241992132589563

Epoch: 6| Step: 1
Training loss: 2.6208916257875936
Validation loss: 3.2382766607027316

Epoch: 6| Step: 2
Training loss: 3.3271504439383444
Validation loss: 3.235145685884469

Epoch: 6| Step: 3
Training loss: 2.5365452891855402
Validation loss: 3.2316386861575155

Epoch: 6| Step: 4
Training loss: 3.502686967780977
Validation loss: 3.228304979760776

Epoch: 6| Step: 5
Training loss: 3.3533714410071402
Validation loss: 3.2254225200295585

Epoch: 6| Step: 6
Training loss: 4.011055925951829
Validation loss: 3.222057852626832

Epoch: 6| Step: 7
Training loss: 3.2847959704159315
Validation loss: 3.2184832070405265

Epoch: 6| Step: 8
Training loss: 3.4526800499000103
Validation loss: 3.2148951437122637

Epoch: 6| Step: 9
Training loss: 3.5886216433858613
Validation loss: 3.2121178900721685

Epoch: 6| Step: 10
Training loss: 3.060609506478646
Validation loss: 3.2085481712114046

Epoch: 6| Step: 11
Training loss: 3.736508067494589
Validation loss: 3.205484244036218

Epoch: 6| Step: 12
Training loss: 3.354180440617746
Validation loss: 3.20264717818034

Epoch: 6| Step: 13
Training loss: 3.1085352698244675
Validation loss: 3.1990427194684172

Epoch: 41| Step: 0
Training loss: 3.3822875287299206
Validation loss: 3.1956425801775987

Epoch: 6| Step: 1
Training loss: 2.954034897233319
Validation loss: 3.1935280291616

Epoch: 6| Step: 2
Training loss: 2.9762649988199446
Validation loss: 3.1895972937825117

Epoch: 6| Step: 3
Training loss: 3.412952513262979
Validation loss: 3.1858930838174895

Epoch: 6| Step: 4
Training loss: 3.819236931606377
Validation loss: 3.1816740336731684

Epoch: 6| Step: 5
Training loss: 2.3997037943204726
Validation loss: 3.1778631701996796

Epoch: 6| Step: 6
Training loss: 3.0479687414894334
Validation loss: 3.175020346488739

Epoch: 6| Step: 7
Training loss: 3.4761836499161456
Validation loss: 3.1725302083706777

Epoch: 6| Step: 8
Training loss: 3.7859734911748797
Validation loss: 3.169774880784228

Epoch: 6| Step: 9
Training loss: 3.935785798423768
Validation loss: 3.167025687963619

Epoch: 6| Step: 10
Training loss: 3.1177467093170077
Validation loss: 3.163746495420157

Epoch: 6| Step: 11
Training loss: 3.616232298917464
Validation loss: 3.160065211496407

Epoch: 6| Step: 12
Training loss: 2.896483551868983
Validation loss: 3.156679218680842

Epoch: 6| Step: 13
Training loss: 3.244270556361028
Validation loss: 3.1531974585039673

Epoch: 42| Step: 0
Training loss: 2.58925386042803
Validation loss: 3.1495421359415996

Epoch: 6| Step: 1
Training loss: 3.980630828282957
Validation loss: 3.1465231957972057

Epoch: 6| Step: 2
Training loss: 3.4594152818658856
Validation loss: 3.1429615344012842

Epoch: 6| Step: 3
Training loss: 2.9367187759793163
Validation loss: 3.139381352242953

Epoch: 6| Step: 4
Training loss: 3.223689317135807
Validation loss: 3.1360525498179923

Epoch: 6| Step: 5
Training loss: 3.5744072536101203
Validation loss: 3.1324787929311264

Epoch: 6| Step: 6
Training loss: 3.381235931423626
Validation loss: 3.129134964729433

Epoch: 6| Step: 7
Training loss: 3.2357846933606553
Validation loss: 3.125930863657847

Epoch: 6| Step: 8
Training loss: 3.1489590574905786
Validation loss: 3.1230336169704382

Epoch: 6| Step: 9
Training loss: 3.219118708260622
Validation loss: 3.1209644327440014

Epoch: 6| Step: 10
Training loss: 2.9211189801498
Validation loss: 3.117279433804485

Epoch: 6| Step: 11
Training loss: 3.084175166774836
Validation loss: 3.1148304835894045

Epoch: 6| Step: 12
Training loss: 3.4128886633796727
Validation loss: 3.1102829059746577

Epoch: 6| Step: 13
Training loss: 3.408262445758824
Validation loss: 3.1074761961978927

Epoch: 43| Step: 0
Training loss: 3.0020919499658576
Validation loss: 3.1043564441879754

Epoch: 6| Step: 1
Training loss: 3.0926615023555124
Validation loss: 3.1016233551947967

Epoch: 6| Step: 2
Training loss: 3.013047772382992
Validation loss: 3.0993143769366447

Epoch: 6| Step: 3
Training loss: 3.9672002695245454
Validation loss: 3.096705928720579

Epoch: 6| Step: 4
Training loss: 3.0782219731116
Validation loss: 3.093983792291926

Epoch: 6| Step: 5
Training loss: 2.9617550005715607
Validation loss: 3.0912726787882363

Epoch: 6| Step: 6
Training loss: 3.658817530909037
Validation loss: 3.088761967762273

Epoch: 6| Step: 7
Training loss: 3.266284930702641
Validation loss: 3.0852382849609543

Epoch: 6| Step: 8
Training loss: 2.857029354020768
Validation loss: 3.0829939311756904

Epoch: 6| Step: 9
Training loss: 2.8987248938864503
Validation loss: 3.0799843582978164

Epoch: 6| Step: 10
Training loss: 3.723670204949285
Validation loss: 3.076911403025587

Epoch: 6| Step: 11
Training loss: 3.605676514827368
Validation loss: 3.073801803266099

Epoch: 6| Step: 12
Training loss: 2.7463121829244215
Validation loss: 3.07021874566953

Epoch: 6| Step: 13
Training loss: 3.035007939587535
Validation loss: 3.0672480049455353

Epoch: 44| Step: 0
Training loss: 3.198942403071513
Validation loss: 3.0637495255518545

Epoch: 6| Step: 1
Training loss: 3.384009028519655
Validation loss: 3.060659075840659

Epoch: 6| Step: 2
Training loss: 3.5925973121667414
Validation loss: 3.0580779347506746

Epoch: 6| Step: 3
Training loss: 2.747148682866056
Validation loss: 3.054973988867127

Epoch: 6| Step: 4
Training loss: 3.279192760966366
Validation loss: 3.0521644520747815

Epoch: 6| Step: 5
Training loss: 3.4006842541768627
Validation loss: 3.049104263016001

Epoch: 6| Step: 6
Training loss: 2.9600068494356657
Validation loss: 3.0461900772631387

Epoch: 6| Step: 7
Training loss: 3.6030760127341246
Validation loss: 3.0434280851919446

Epoch: 6| Step: 8
Training loss: 2.944153737366316
Validation loss: 3.04018171633155

Epoch: 6| Step: 9
Training loss: 2.3338276702754763
Validation loss: 3.0375287942869003

Epoch: 6| Step: 10
Training loss: 3.5433494758656923
Validation loss: 3.0348283679787533

Epoch: 6| Step: 11
Training loss: 2.932495887018492
Validation loss: 3.032228370948535

Epoch: 6| Step: 12
Training loss: 3.340305586443797
Validation loss: 3.0293797232216755

Epoch: 6| Step: 13
Training loss: 3.0948422748267297
Validation loss: 3.0265996990763573

Epoch: 45| Step: 0
Training loss: 2.634460476792958
Validation loss: 3.02333979485721

Epoch: 6| Step: 1
Training loss: 3.4110090974291083
Validation loss: 3.0208842349970757

Epoch: 6| Step: 2
Training loss: 3.3711207666121212
Validation loss: 3.018023681667369

Epoch: 6| Step: 3
Training loss: 2.509111204806582
Validation loss: 3.0154566742560216

Epoch: 6| Step: 4
Training loss: 2.912387560855606
Validation loss: 3.012055625167164

Epoch: 6| Step: 5
Training loss: 3.4729956685222367
Validation loss: 3.009518041541957

Epoch: 6| Step: 6
Training loss: 3.554884014356838
Validation loss: 3.0061090839480746

Epoch: 6| Step: 7
Training loss: 3.290674824713307
Validation loss: 3.0040837017636415

Epoch: 6| Step: 8
Training loss: 3.3532445994696047
Validation loss: 3.002691968487142

Epoch: 6| Step: 9
Training loss: 2.950009433278664
Validation loss: 3.0014775134579876

Epoch: 6| Step: 10
Training loss: 3.539879845557457
Validation loss: 3.0524018851593198

Epoch: 6| Step: 11
Training loss: 2.635585965434455
Validation loss: 3.0054987806170588

Epoch: 6| Step: 12
Training loss: 3.1304819470920666
Validation loss: 2.9906189395281095

Epoch: 6| Step: 13
Training loss: 3.1621357643953654
Validation loss: 2.989681911283187

Epoch: 46| Step: 0
Training loss: 3.1194293916210194
Validation loss: 2.991281689354982

Epoch: 6| Step: 1
Training loss: 3.3784701556549774
Validation loss: 3.0003882527781736

Epoch: 6| Step: 2
Training loss: 2.4516447424237873
Validation loss: 3.0034635074516

Epoch: 6| Step: 3
Training loss: 2.8803194011958593
Validation loss: 3.0014706953877126

Epoch: 6| Step: 4
Training loss: 2.837017767844163
Validation loss: 2.9904700015515706

Epoch: 6| Step: 5
Training loss: 3.3928330786289025
Validation loss: 2.9827798571498145

Epoch: 6| Step: 6
Training loss: 2.5206913133028506
Validation loss: 2.976553355392333

Epoch: 6| Step: 7
Training loss: 2.9268659915985014
Validation loss: 2.9721158138332715

Epoch: 6| Step: 8
Training loss: 3.516846847136767
Validation loss: 2.9680099501850017

Epoch: 6| Step: 9
Training loss: 3.671126139145399
Validation loss: 2.9660643760921244

Epoch: 6| Step: 10
Training loss: 3.184137702762908
Validation loss: 2.963329788080018

Epoch: 6| Step: 11
Training loss: 3.119661272197203
Validation loss: 2.9609915695688804

Epoch: 6| Step: 12
Training loss: 3.414565828351033
Validation loss: 2.9579993359425494

Epoch: 6| Step: 13
Training loss: 2.946787335901141
Validation loss: 2.955570977412967

Epoch: 47| Step: 0
Training loss: 3.8672868812198655
Validation loss: 2.952556461189513

Epoch: 6| Step: 1
Training loss: 2.8420015766050835
Validation loss: 2.950048199491548

Epoch: 6| Step: 2
Training loss: 3.0751318926554294
Validation loss: 2.947059052788588

Epoch: 6| Step: 3
Training loss: 2.810213303802082
Validation loss: 2.9454875728742405

Epoch: 6| Step: 4
Training loss: 2.3875866699465274
Validation loss: 2.9419103345011224

Epoch: 6| Step: 5
Training loss: 3.0141947620851806
Validation loss: 2.940967893591023

Epoch: 6| Step: 6
Training loss: 3.2663332522469117
Validation loss: 2.9369969038617416

Epoch: 6| Step: 7
Training loss: 3.6182888652986427
Validation loss: 2.935060191298157

Epoch: 6| Step: 8
Training loss: 2.7914171724188512
Validation loss: 2.9325749930624627

Epoch: 6| Step: 9
Training loss: 3.2337477808392863
Validation loss: 2.9288964046931114

Epoch: 6| Step: 10
Training loss: 3.1265380126360225
Validation loss: 2.9264281049733096

Epoch: 6| Step: 11
Training loss: 2.83195548120626
Validation loss: 2.924104598060535

Epoch: 6| Step: 12
Training loss: 2.9286067342457622
Validation loss: 2.921210364705506

Epoch: 6| Step: 13
Training loss: 3.017039861479599
Validation loss: 2.9187101743977553

Epoch: 48| Step: 0
Training loss: 2.5985327138333396
Validation loss: 2.916473236936064

Epoch: 6| Step: 1
Training loss: 2.427761283350978
Validation loss: 2.9148583573945217

Epoch: 6| Step: 2
Training loss: 3.1253431513255623
Validation loss: 2.9117415033981096

Epoch: 6| Step: 3
Training loss: 2.9429368372058553
Validation loss: 2.909888147212312

Epoch: 6| Step: 4
Training loss: 3.0395017958527655
Validation loss: 2.907968129470926

Epoch: 6| Step: 5
Training loss: 3.3272930412790434
Validation loss: 2.9059521785712272

Epoch: 6| Step: 6
Training loss: 2.7491146743296735
Validation loss: 2.90356006353086

Epoch: 6| Step: 7
Training loss: 2.936363162559516
Validation loss: 2.9009589840368313

Epoch: 6| Step: 8
Training loss: 3.0634799868485802
Validation loss: 2.8991015719739077

Epoch: 6| Step: 9
Training loss: 3.514795909182086
Validation loss: 2.8962730284307545

Epoch: 6| Step: 10
Training loss: 3.149752283195554
Validation loss: 2.8939914792112704

Epoch: 6| Step: 11
Training loss: 2.94778637996907
Validation loss: 2.8908754669825547

Epoch: 6| Step: 12
Training loss: 3.3629615268417905
Validation loss: 2.8884735486408237

Epoch: 6| Step: 13
Training loss: 3.2485492109106193
Validation loss: 2.8871471618813858

Epoch: 49| Step: 0
Training loss: 2.502949595883807
Validation loss: 2.884919510483822

Epoch: 6| Step: 1
Training loss: 2.9545539749129355
Validation loss: 2.8818246170523096

Epoch: 6| Step: 2
Training loss: 3.1069057762510988
Validation loss: 2.8809238163696573

Epoch: 6| Step: 3
Training loss: 2.9030450356170503
Validation loss: 2.8791551831720743

Epoch: 6| Step: 4
Training loss: 3.3512951581986514
Validation loss: 2.8758943935674477

Epoch: 6| Step: 5
Training loss: 2.960208853493082
Validation loss: 2.875725267675955

Epoch: 6| Step: 6
Training loss: 2.736876732929567
Validation loss: 2.873330322501544

Epoch: 6| Step: 7
Training loss: 3.138374395225097
Validation loss: 2.8716552323748217

Epoch: 6| Step: 8
Training loss: 2.873734734798737
Validation loss: 2.8693941859935603

Epoch: 6| Step: 9
Training loss: 3.2544954460277453
Validation loss: 2.867275226300774

Epoch: 6| Step: 10
Training loss: 3.5117472646402117
Validation loss: 2.865153062980269

Epoch: 6| Step: 11
Training loss: 2.9641501679674933
Validation loss: 2.8629809435033553

Epoch: 6| Step: 12
Training loss: 3.234829783140237
Validation loss: 2.8602621512321487

Epoch: 6| Step: 13
Training loss: 2.493778306996394
Validation loss: 2.8586085808873056

Epoch: 50| Step: 0
Training loss: 3.0163211315508396
Validation loss: 2.8562821022639233

Epoch: 6| Step: 1
Training loss: 2.7773822078912613
Validation loss: 2.854013513136098

Epoch: 6| Step: 2
Training loss: 3.0836692489609363
Validation loss: 2.8520655915456428

Epoch: 6| Step: 3
Training loss: 2.7945856709202954
Validation loss: 2.849773748240032

Epoch: 6| Step: 4
Training loss: 3.3485406800080755
Validation loss: 2.8473276821754134

Epoch: 6| Step: 5
Training loss: 3.4792291936376296
Validation loss: 2.844954392816806

Epoch: 6| Step: 6
Training loss: 2.9604789761333286
Validation loss: 2.8442066370959638

Epoch: 6| Step: 7
Training loss: 2.919716430377011
Validation loss: 2.840674403467082

Epoch: 6| Step: 8
Training loss: 2.987245148199165
Validation loss: 2.83698957980697

Epoch: 6| Step: 9
Training loss: 2.75250217004564
Validation loss: 2.8368526695029805

Epoch: 6| Step: 10
Training loss: 2.446522666147882
Validation loss: 2.834356716872315

Epoch: 6| Step: 11
Training loss: 2.9864654409649756
Validation loss: 2.832614489601441

Epoch: 6| Step: 12
Training loss: 2.9135925077590263
Validation loss: 2.831161302267677

Epoch: 6| Step: 13
Training loss: 3.194208304112848
Validation loss: 2.829159345509678

Epoch: 51| Step: 0
Training loss: 3.059210743064851
Validation loss: 2.827847377575925

Epoch: 6| Step: 1
Training loss: 2.8529540964438973
Validation loss: 2.8246170332937623

Epoch: 6| Step: 2
Training loss: 2.883344399609213
Validation loss: 2.8237890793413993

Epoch: 6| Step: 3
Training loss: 1.9421913202176075
Validation loss: 2.8223246883913062

Epoch: 6| Step: 4
Training loss: 2.9934659373159893
Validation loss: 2.820858861074257

Epoch: 6| Step: 5
Training loss: 3.030293421874563
Validation loss: 2.8193870709808535

Epoch: 6| Step: 6
Training loss: 2.47879707295576
Validation loss: 2.818004153101261

Epoch: 6| Step: 7
Training loss: 3.365542972737501
Validation loss: 2.8158270054595853

Epoch: 6| Step: 8
Training loss: 2.822340809173733
Validation loss: 2.8141060517432472

Epoch: 6| Step: 9
Training loss: 3.146185208950445
Validation loss: 2.8116838825251262

Epoch: 6| Step: 10
Training loss: 2.7385478413714046
Validation loss: 2.810290577866366

Epoch: 6| Step: 11
Training loss: 2.9537711269222022
Validation loss: 2.808745131217473

Epoch: 6| Step: 12
Training loss: 3.193918833590479
Validation loss: 2.8058602264160837

Epoch: 6| Step: 13
Training loss: 3.604206298139825
Validation loss: 2.8050278197714857

Epoch: 52| Step: 0
Training loss: 2.969710345288259
Validation loss: 2.8020704522008155

Epoch: 6| Step: 1
Training loss: 2.786957873669014
Validation loss: 2.8009314929029934

Epoch: 6| Step: 2
Training loss: 3.1227674520284476
Validation loss: 2.802433932657394

Epoch: 6| Step: 3
Training loss: 3.1192707185123663
Validation loss: 2.797553322936973

Epoch: 6| Step: 4
Training loss: 2.735154133555888
Validation loss: 2.795480519038036

Epoch: 6| Step: 5
Training loss: 2.88273806592168
Validation loss: 2.794170300801507

Epoch: 6| Step: 6
Training loss: 2.2656710915974307
Validation loss: 2.791039970617445

Epoch: 6| Step: 7
Training loss: 2.757298321650455
Validation loss: 2.7897805537124807

Epoch: 6| Step: 8
Training loss: 3.2779360066673284
Validation loss: 2.7889579090841776

Epoch: 6| Step: 9
Training loss: 2.7747479848437644
Validation loss: 2.787692804896012

Epoch: 6| Step: 10
Training loss: 3.5500374698004675
Validation loss: 2.7860352001791666

Epoch: 6| Step: 11
Training loss: 2.863712543723803
Validation loss: 2.7837195558657544

Epoch: 6| Step: 12
Training loss: 3.011090125198087
Validation loss: 2.7825007394502337

Epoch: 6| Step: 13
Training loss: 2.759516894449674
Validation loss: 2.781885710225471

Epoch: 53| Step: 0
Training loss: 2.8591023299486285
Validation loss: 2.779412694980938

Epoch: 6| Step: 1
Training loss: 3.193089390345395
Validation loss: 2.778959910200254

Epoch: 6| Step: 2
Training loss: 3.031476513766126
Validation loss: 2.777260823359815

Epoch: 6| Step: 3
Training loss: 2.8436547567326595
Validation loss: 2.7752952120812027

Epoch: 6| Step: 4
Training loss: 2.5480444160015634
Validation loss: 2.7734774447864354

Epoch: 6| Step: 5
Training loss: 2.898603491130083
Validation loss: 2.7722726300875666

Epoch: 6| Step: 6
Training loss: 2.8577611152113063
Validation loss: 2.769197229528008

Epoch: 6| Step: 7
Training loss: 2.8249563095630243
Validation loss: 2.768797375034751

Epoch: 6| Step: 8
Training loss: 2.7665021119722417
Validation loss: 2.7700986294453234

Epoch: 6| Step: 9
Training loss: 2.742913739579843
Validation loss: 2.769480573426378

Epoch: 6| Step: 10
Training loss: 2.9868382379377247
Validation loss: 2.7686045916330126

Epoch: 6| Step: 11
Training loss: 3.2242473581614868
Validation loss: 2.7641481669829195

Epoch: 6| Step: 12
Training loss: 2.681321694009116
Validation loss: 2.7607521908856247

Epoch: 6| Step: 13
Training loss: 3.2212366665026484
Validation loss: 2.759635675659532

Epoch: 54| Step: 0
Training loss: 2.9158812055630894
Validation loss: 2.7585478208498335

Epoch: 6| Step: 1
Training loss: 2.454424665670781
Validation loss: 2.7569285877283183

Epoch: 6| Step: 2
Training loss: 2.950850645364824
Validation loss: 2.755947790207767

Epoch: 6| Step: 3
Training loss: 2.457199697375694
Validation loss: 2.7523781146169854

Epoch: 6| Step: 4
Training loss: 2.6527492117772304
Validation loss: 2.7511122939434736

Epoch: 6| Step: 5
Training loss: 3.190632048028378
Validation loss: 2.7503553074271867

Epoch: 6| Step: 6
Training loss: 3.354706967514544
Validation loss: 2.7479015204354678

Epoch: 6| Step: 7
Training loss: 3.137924627620608
Validation loss: 2.747910847536008

Epoch: 6| Step: 8
Training loss: 3.1032212287603516
Validation loss: 2.7473539858458893

Epoch: 6| Step: 9
Training loss: 2.132384316637208
Validation loss: 2.748110309764288

Epoch: 6| Step: 10
Training loss: 3.102601922118561
Validation loss: 2.7425676247191486

Epoch: 6| Step: 11
Training loss: 3.2496962772180784
Validation loss: 2.740238464308914

Epoch: 6| Step: 12
Training loss: 2.725066378423686
Validation loss: 2.740098119217977

Epoch: 6| Step: 13
Training loss: 2.753216856031404
Validation loss: 2.7400589059962313

Epoch: 55| Step: 0
Training loss: 2.496262617771769
Validation loss: 2.737665793799572

Epoch: 6| Step: 1
Training loss: 2.574448617214611
Validation loss: 2.738127830658899

Epoch: 6| Step: 2
Training loss: 2.9043517117175126
Validation loss: 2.737726537194336

Epoch: 6| Step: 3
Training loss: 3.0891973733280547
Validation loss: 2.7379958965019053

Epoch: 6| Step: 4
Training loss: 2.720616543960663
Validation loss: 2.73920331187891

Epoch: 6| Step: 5
Training loss: 3.032611659070684
Validation loss: 2.7373539274543175

Epoch: 6| Step: 6
Training loss: 2.677661541394138
Validation loss: 2.734971524519823

Epoch: 6| Step: 7
Training loss: 3.1523780868153946
Validation loss: 2.734022194036272

Epoch: 6| Step: 8
Training loss: 2.9374314969780104
Validation loss: 2.731495952807333

Epoch: 6| Step: 9
Training loss: 2.9712849284916683
Validation loss: 2.7286798805015042

Epoch: 6| Step: 10
Training loss: 2.7917795490577526
Validation loss: 2.7274565738306

Epoch: 6| Step: 11
Training loss: 2.9976288643849407
Validation loss: 2.7249696846538516

Epoch: 6| Step: 12
Training loss: 2.976719649364153
Validation loss: 2.7229689678917985

Epoch: 6| Step: 13
Training loss: 2.7863100291682903
Validation loss: 2.7206631794681027

Epoch: 56| Step: 0
Training loss: 3.1418321102167543
Validation loss: 2.7191476202284184

Epoch: 6| Step: 1
Training loss: 3.071892174239091
Validation loss: 2.7169811589412967

Epoch: 6| Step: 2
Training loss: 2.583051748208568
Validation loss: 2.715056515779281

Epoch: 6| Step: 3
Training loss: 2.6080925811061797
Validation loss: 2.713053556291176

Epoch: 6| Step: 4
Training loss: 2.87627482138695
Validation loss: 2.7121073226192034

Epoch: 6| Step: 5
Training loss: 2.61342575973762
Validation loss: 2.7111635287963898

Epoch: 6| Step: 6
Training loss: 2.7622273582450982
Validation loss: 2.71014467458488

Epoch: 6| Step: 7
Training loss: 2.724858929543525
Validation loss: 2.708740634124529

Epoch: 6| Step: 8
Training loss: 2.4756152149402877
Validation loss: 2.7067644025354194

Epoch: 6| Step: 9
Training loss: 2.669347627356967
Validation loss: 2.70523592308487

Epoch: 6| Step: 10
Training loss: 3.291641203061534
Validation loss: 2.7041343612582924

Epoch: 6| Step: 11
Training loss: 2.9311910204454166
Validation loss: 2.7021484227945054

Epoch: 6| Step: 12
Training loss: 3.091054802025279
Validation loss: 2.7007948105875967

Epoch: 6| Step: 13
Training loss: 2.923158577886627
Validation loss: 2.701553593582819

Epoch: 57| Step: 0
Training loss: 2.7329078443938988
Validation loss: 2.6988403378930514

Epoch: 6| Step: 1
Training loss: 2.855562430331031
Validation loss: 2.6986219498076425

Epoch: 6| Step: 2
Training loss: 3.126698147005917
Validation loss: 2.695724942260421

Epoch: 6| Step: 3
Training loss: 3.0877164324681736
Validation loss: 2.6951948204703347

Epoch: 6| Step: 4
Training loss: 2.3522755501805164
Validation loss: 2.6924254578118805

Epoch: 6| Step: 5
Training loss: 3.3057686410248674
Validation loss: 2.689977435474699

Epoch: 6| Step: 6
Training loss: 2.620926739393263
Validation loss: 2.6891935616176657

Epoch: 6| Step: 7
Training loss: 2.7916731383595015
Validation loss: 2.688044692442807

Epoch: 6| Step: 8
Training loss: 3.026204107567627
Validation loss: 2.6877930799259535

Epoch: 6| Step: 9
Training loss: 2.6753324034754433
Validation loss: 2.686950878850416

Epoch: 6| Step: 10
Training loss: 2.792805273433614
Validation loss: 2.706702054086814

Epoch: 6| Step: 11
Training loss: 2.2951082454244576
Validation loss: 2.699428242909591

Epoch: 6| Step: 12
Training loss: 3.243457370854862
Validation loss: 2.6834934887765294

Epoch: 6| Step: 13
Training loss: 2.590214169164139
Validation loss: 2.681518196261876

Epoch: 58| Step: 0
Training loss: 2.8145356334952227
Validation loss: 2.679439388611095

Epoch: 6| Step: 1
Training loss: 2.8045301472931996
Validation loss: 2.6802722526447047

Epoch: 6| Step: 2
Training loss: 2.5562437024773437
Validation loss: 2.682982070116968

Epoch: 6| Step: 3
Training loss: 3.3981563057158173
Validation loss: 2.6820373612128767

Epoch: 6| Step: 4
Training loss: 2.762970420864079
Validation loss: 2.6833163677492733

Epoch: 6| Step: 5
Training loss: 2.8141263709903073
Validation loss: 2.6839218272267744

Epoch: 6| Step: 6
Training loss: 1.84925408661976
Validation loss: 2.683784696475811

Epoch: 6| Step: 7
Training loss: 2.84001383737766
Validation loss: 2.6839420660780884

Epoch: 6| Step: 8
Training loss: 2.350971743369656
Validation loss: 2.683607209684109

Epoch: 6| Step: 9
Training loss: 2.9165708980277945
Validation loss: 2.6778252361527604

Epoch: 6| Step: 10
Training loss: 3.0624978201722155
Validation loss: 2.67644737101453

Epoch: 6| Step: 11
Training loss: 2.7894690294804607
Validation loss: 2.6746006943907394

Epoch: 6| Step: 12
Training loss: 2.929730142918823
Validation loss: 2.673312553370979

Epoch: 6| Step: 13
Training loss: 3.2558133877788573
Validation loss: 2.6723051710157573

Epoch: 59| Step: 0
Training loss: 2.7063609252467855
Validation loss: 2.668706982613583

Epoch: 6| Step: 1
Training loss: 2.781599558604932
Validation loss: 2.6699494083959645

Epoch: 6| Step: 2
Training loss: 2.6863217987079246
Validation loss: 2.6657454767165842

Epoch: 6| Step: 3
Training loss: 2.2195145270346335
Validation loss: 2.6636124694110337

Epoch: 6| Step: 4
Training loss: 3.709975718292812
Validation loss: 2.66230020564439

Epoch: 6| Step: 5
Training loss: 2.852417031367854
Validation loss: 2.6617253885577328

Epoch: 6| Step: 6
Training loss: 2.4513554112997458
Validation loss: 2.6596493529808707

Epoch: 6| Step: 7
Training loss: 3.282019969881755
Validation loss: 2.658552286544222

Epoch: 6| Step: 8
Training loss: 2.5487250413182423
Validation loss: 2.6568515619993858

Epoch: 6| Step: 9
Training loss: 2.638541217677915
Validation loss: 2.656351977616027

Epoch: 6| Step: 10
Training loss: 2.1080390372959585
Validation loss: 2.655649678328171

Epoch: 6| Step: 11
Training loss: 3.106270932409114
Validation loss: 2.653922658350569

Epoch: 6| Step: 12
Training loss: 2.7776097681311054
Validation loss: 2.653747531687876

Epoch: 6| Step: 13
Training loss: 2.9221839129503735
Validation loss: 2.6506701635680487

Epoch: 60| Step: 0
Training loss: 2.5921816392939228
Validation loss: 2.650586736850095

Epoch: 6| Step: 1
Training loss: 2.7815428161781766
Validation loss: 2.6485018051877796

Epoch: 6| Step: 2
Training loss: 2.910112009416241
Validation loss: 2.6486382272398363

Epoch: 6| Step: 3
Training loss: 2.4589778787952814
Validation loss: 2.646741280749117

Epoch: 6| Step: 4
Training loss: 2.9633383164365714
Validation loss: 2.644545539580693

Epoch: 6| Step: 5
Training loss: 3.1190577659039755
Validation loss: 2.644841801840653

Epoch: 6| Step: 6
Training loss: 2.9380297893263014
Validation loss: 2.6450405635259266

Epoch: 6| Step: 7
Training loss: 2.44603019151746
Validation loss: 2.641991045638029

Epoch: 6| Step: 8
Training loss: 2.935267472564987
Validation loss: 2.6445096727370903

Epoch: 6| Step: 9
Training loss: 3.2955950381188277
Validation loss: 2.643007140708165

Epoch: 6| Step: 10
Training loss: 2.5707128149272247
Validation loss: 2.6431147257768375

Epoch: 6| Step: 11
Training loss: 2.55308393727856
Validation loss: 2.6436478657454563

Epoch: 6| Step: 12
Training loss: 2.224372187990757
Validation loss: 2.6425618699601303

Epoch: 6| Step: 13
Training loss: 2.9569827117362935
Validation loss: 2.6422050609339665

Epoch: 61| Step: 0
Training loss: 2.6856818147916806
Validation loss: 2.642938762678476

Epoch: 6| Step: 1
Training loss: 2.8370604590561412
Validation loss: 2.6420277287599268

Epoch: 6| Step: 2
Training loss: 3.1042937353014355
Validation loss: 2.6399697538531304

Epoch: 6| Step: 3
Training loss: 2.8076496261713006
Validation loss: 2.6402920093539666

Epoch: 6| Step: 4
Training loss: 2.622357627996946
Validation loss: 2.6386730044438043

Epoch: 6| Step: 5
Training loss: 2.797357613465741
Validation loss: 2.6377165839533196

Epoch: 6| Step: 6
Training loss: 2.7489854501704847
Validation loss: 2.637015439519334

Epoch: 6| Step: 7
Training loss: 2.8716922473561457
Validation loss: 2.6352005268067447

Epoch: 6| Step: 8
Training loss: 2.4796377637330527
Validation loss: 2.6334082347341794

Epoch: 6| Step: 9
Training loss: 2.743244456508177
Validation loss: 2.632947893745834

Epoch: 6| Step: 10
Training loss: 3.0331793868296
Validation loss: 2.6301124832263767

Epoch: 6| Step: 11
Training loss: 2.4474581241629547
Validation loss: 2.628517375296735

Epoch: 6| Step: 12
Training loss: 2.858594443922436
Validation loss: 2.6272856283286106

Epoch: 6| Step: 13
Training loss: 2.724124375796217
Validation loss: 2.6264548281707776

Epoch: 62| Step: 0
Training loss: 2.6491656807410355
Validation loss: 2.623918772347859

Epoch: 6| Step: 1
Training loss: 3.0574733976889616
Validation loss: 2.623963242107634

Epoch: 6| Step: 2
Training loss: 2.928840535124435
Validation loss: 2.6235165718708275

Epoch: 6| Step: 3
Training loss: 3.0480227142749183
Validation loss: 2.6196758682009125

Epoch: 6| Step: 4
Training loss: 2.231675871910082
Validation loss: 2.619183984938518

Epoch: 6| Step: 5
Training loss: 2.652715508050268
Validation loss: 2.616437123085078

Epoch: 6| Step: 6
Training loss: 2.8039735188124832
Validation loss: 2.61556323307808

Epoch: 6| Step: 7
Training loss: 2.9039126605726926
Validation loss: 2.6184464648221875

Epoch: 6| Step: 8
Training loss: 2.294618497234685
Validation loss: 2.616522952302218

Epoch: 6| Step: 9
Training loss: 3.130003928282591
Validation loss: 2.6123286451150247

Epoch: 6| Step: 10
Training loss: 3.0989901159029785
Validation loss: 2.615413888473295

Epoch: 6| Step: 11
Training loss: 1.8521453326403507
Validation loss: 2.6112942062149456

Epoch: 6| Step: 12
Training loss: 3.1200216693614737
Validation loss: 2.6124469240628665

Epoch: 6| Step: 13
Training loss: 2.5194181668239413
Validation loss: 2.613031212857877

Epoch: 63| Step: 0
Training loss: 1.9241904600095079
Validation loss: 2.609882663218294

Epoch: 6| Step: 1
Training loss: 2.9918588801472272
Validation loss: 2.609073842347974

Epoch: 6| Step: 2
Training loss: 2.2780341906037256
Validation loss: 2.614096019869705

Epoch: 6| Step: 3
Training loss: 2.9152816390380036
Validation loss: 2.6191085824848312

Epoch: 6| Step: 4
Training loss: 2.998202580189175
Validation loss: 2.608568992165944

Epoch: 6| Step: 5
Training loss: 2.330661697405676
Validation loss: 2.6061754388305602

Epoch: 6| Step: 6
Training loss: 3.139637350534468
Validation loss: 2.606785599205937

Epoch: 6| Step: 7
Training loss: 2.7164023775912955
Validation loss: 2.6091209333617744

Epoch: 6| Step: 8
Training loss: 2.6863540157808328
Validation loss: 2.609221752791018

Epoch: 6| Step: 9
Training loss: 2.6515497246672206
Validation loss: 2.6083801565954303

Epoch: 6| Step: 10
Training loss: 2.4687040300555867
Validation loss: 2.609385477071656

Epoch: 6| Step: 11
Training loss: 3.1195524417989495
Validation loss: 2.6097794027145143

Epoch: 6| Step: 12
Training loss: 3.164659382599261
Validation loss: 2.609353314764558

Epoch: 6| Step: 13
Training loss: 2.7218349099081
Validation loss: 2.6100161710752157

Epoch: 64| Step: 0
Training loss: 2.5728201185225075
Validation loss: 2.609774317234689

Epoch: 6| Step: 1
Training loss: 2.5537733022977607
Validation loss: 2.609292308844838

Epoch: 6| Step: 2
Training loss: 3.119559167383063
Validation loss: 2.607395860635091

Epoch: 6| Step: 3
Training loss: 2.7270648132892124
Validation loss: 2.6053502762685117

Epoch: 6| Step: 4
Training loss: 2.128420713159936
Validation loss: 2.602618647462507

Epoch: 6| Step: 5
Training loss: 3.0629371798129434
Validation loss: 2.6036842331658963

Epoch: 6| Step: 6
Training loss: 2.7020902913478735
Validation loss: 2.598658929880185

Epoch: 6| Step: 7
Training loss: 2.8288971073537015
Validation loss: 2.6019832511409713

Epoch: 6| Step: 8
Training loss: 3.0996467573655515
Validation loss: 2.597086281258876

Epoch: 6| Step: 9
Training loss: 2.363448107164875
Validation loss: 2.5994162809031094

Epoch: 6| Step: 10
Training loss: 2.7313047774559167
Validation loss: 2.6051955110787803

Epoch: 6| Step: 11
Training loss: 3.0361580981075575
Validation loss: 2.5924985846500586

Epoch: 6| Step: 12
Training loss: 2.906088547682719
Validation loss: 2.592753942958727

Epoch: 6| Step: 13
Training loss: 2.3150523766015945
Validation loss: 2.597747709342116

Epoch: 65| Step: 0
Training loss: 2.5621494890862726
Validation loss: 2.596186829852833

Epoch: 6| Step: 1
Training loss: 2.667539950270943
Validation loss: 2.5993180774528994

Epoch: 6| Step: 2
Training loss: 3.012233586224434
Validation loss: 2.6033444034700866

Epoch: 6| Step: 3
Training loss: 3.290991862859319
Validation loss: 2.6081022710698796

Epoch: 6| Step: 4
Training loss: 2.7495940515693027
Validation loss: 2.6097185894711488

Epoch: 6| Step: 5
Training loss: 2.513876550221474
Validation loss: 2.603929651282837

Epoch: 6| Step: 6
Training loss: 2.772362557144068
Validation loss: 2.5999268209722772

Epoch: 6| Step: 7
Training loss: 2.598593452439375
Validation loss: 2.5987857972836013

Epoch: 6| Step: 8
Training loss: 2.875349935713498
Validation loss: 2.596330354990124

Epoch: 6| Step: 9
Training loss: 2.801748451916657
Validation loss: 2.594360900083349

Epoch: 6| Step: 10
Training loss: 2.801676629673
Validation loss: 2.589510075787892

Epoch: 6| Step: 11
Training loss: 2.9247119207429537
Validation loss: 2.587058862378019

Epoch: 6| Step: 12
Training loss: 2.6054986726109255
Validation loss: 2.5858055150212444

Epoch: 6| Step: 13
Training loss: 1.8126229869288648
Validation loss: 2.586987822822623

Epoch: 66| Step: 0
Training loss: 2.507209301240048
Validation loss: 2.5839686125343992

Epoch: 6| Step: 1
Training loss: 2.757526501746976
Validation loss: 2.5851549114932046

Epoch: 6| Step: 2
Training loss: 2.444744592599987
Validation loss: 2.583191442181992

Epoch: 6| Step: 3
Training loss: 3.4544283103245714
Validation loss: 2.585807466647017

Epoch: 6| Step: 4
Training loss: 1.8389434231409034
Validation loss: 2.5788443900686757

Epoch: 6| Step: 5
Training loss: 2.9425210448673607
Validation loss: 2.579034094004442

Epoch: 6| Step: 6
Training loss: 2.776337303083976
Validation loss: 2.578110820076219

Epoch: 6| Step: 7
Training loss: 3.028231976551432
Validation loss: 2.575519485910421

Epoch: 6| Step: 8
Training loss: 3.0531426545397
Validation loss: 2.5746728306546234

Epoch: 6| Step: 9
Training loss: 2.625987457559213
Validation loss: 2.57529199790254

Epoch: 6| Step: 10
Training loss: 2.2315416845299847
Validation loss: 2.5739148066159685

Epoch: 6| Step: 11
Training loss: 2.461722693747337
Validation loss: 2.5730795454807494

Epoch: 6| Step: 12
Training loss: 3.2726703190905213
Validation loss: 2.5686821525629018

Epoch: 6| Step: 13
Training loss: 2.1252219140360205
Validation loss: 2.5699538238622224

Epoch: 67| Step: 0
Training loss: 2.529930618601333
Validation loss: 2.568154214417577

Epoch: 6| Step: 1
Training loss: 2.924376370714408
Validation loss: 2.571981180192389

Epoch: 6| Step: 2
Training loss: 2.367455596346294
Validation loss: 2.5662088303717376

Epoch: 6| Step: 3
Training loss: 2.829884692966885
Validation loss: 2.570523965440527

Epoch: 6| Step: 4
Training loss: 2.3372220491196103
Validation loss: 2.5673149276934772

Epoch: 6| Step: 5
Training loss: 2.461459053115858
Validation loss: 2.570692302930522

Epoch: 6| Step: 6
Training loss: 2.9333310676334765
Validation loss: 2.5734409050454747

Epoch: 6| Step: 7
Training loss: 3.1842631940895525
Validation loss: 2.5618623234724565

Epoch: 6| Step: 8
Training loss: 2.4274656679532662
Validation loss: 2.565380524337405

Epoch: 6| Step: 9
Training loss: 2.0704209785112004
Validation loss: 2.562334311176145

Epoch: 6| Step: 10
Training loss: 3.18409367480092
Validation loss: 2.559755499334793

Epoch: 6| Step: 11
Training loss: 2.1814383307970355
Validation loss: 2.5609878482334185

Epoch: 6| Step: 12
Training loss: 2.888650085490842
Validation loss: 2.5651777434406604

Epoch: 6| Step: 13
Training loss: 3.0747575493730817
Validation loss: 2.5680967943690156

Epoch: 68| Step: 0
Training loss: 2.3274420434146372
Validation loss: 2.567399342317936

Epoch: 6| Step: 1
Training loss: 2.8621522517303233
Validation loss: 2.567237057616731

Epoch: 6| Step: 2
Training loss: 2.981437795550219
Validation loss: 2.569795365183354

Epoch: 6| Step: 3
Training loss: 2.501353374367703
Validation loss: 2.571074878055779

Epoch: 6| Step: 4
Training loss: 2.706081295261194
Validation loss: 2.5700823246972124

Epoch: 6| Step: 5
Training loss: 2.4205417039379697
Validation loss: 2.5701291483652393

Epoch: 6| Step: 6
Training loss: 2.8393802815580695
Validation loss: 2.570140434774764

Epoch: 6| Step: 7
Training loss: 3.052574109576704
Validation loss: 2.5716920530343943

Epoch: 6| Step: 8
Training loss: 2.116695783319732
Validation loss: 2.571775134261716

Epoch: 6| Step: 9
Training loss: 2.809321663321559
Validation loss: 2.5715880625198264

Epoch: 6| Step: 10
Training loss: 2.8023465303567283
Validation loss: 2.5717197110220087

Epoch: 6| Step: 11
Training loss: 2.9294438375235305
Validation loss: 2.570347376995517

Epoch: 6| Step: 12
Training loss: 2.8173866205834317
Validation loss: 2.56995519997306

Epoch: 6| Step: 13
Training loss: 2.5417329331394676
Validation loss: 2.5677301329847357

Epoch: 69| Step: 0
Training loss: 2.5696397266124604
Validation loss: 2.5642867488304932

Epoch: 6| Step: 1
Training loss: 2.4143492889417786
Validation loss: 2.5596220401066776

Epoch: 6| Step: 2
Training loss: 2.889723518636369
Validation loss: 2.559253807443391

Epoch: 6| Step: 3
Training loss: 2.635118510351789
Validation loss: 2.558786989636362

Epoch: 6| Step: 4
Training loss: 2.253985477952455
Validation loss: 2.5597632145153555

Epoch: 6| Step: 5
Training loss: 2.7118198157236884
Validation loss: 2.553378470704965

Epoch: 6| Step: 6
Training loss: 2.9059622017068674
Validation loss: 2.5524245261137812

Epoch: 6| Step: 7
Training loss: 2.647792861489266
Validation loss: 2.5523313492651876

Epoch: 6| Step: 8
Training loss: 2.1786063189247584
Validation loss: 2.551216209134265

Epoch: 6| Step: 9
Training loss: 2.8362065127230247
Validation loss: 2.545484728964493

Epoch: 6| Step: 10
Training loss: 2.4090581584163395
Validation loss: 2.546011967695047

Epoch: 6| Step: 11
Training loss: 2.497556636805807
Validation loss: 2.5439439066994676

Epoch: 6| Step: 12
Training loss: 3.397841688522111
Validation loss: 2.546061957458228

Epoch: 6| Step: 13
Training loss: 2.9428448040580535
Validation loss: 2.5418043776763373

Epoch: 70| Step: 0
Training loss: 2.6747414009376027
Validation loss: 2.543718312508984

Epoch: 6| Step: 1
Training loss: 2.9484501727730934
Validation loss: 2.546164587127355

Epoch: 6| Step: 2
Training loss: 2.898277586769546
Validation loss: 2.543607944955309

Epoch: 6| Step: 3
Training loss: 2.653758687073859
Validation loss: 2.5470886296893713

Epoch: 6| Step: 4
Training loss: 2.8619763157662286
Validation loss: 2.546034270461204

Epoch: 6| Step: 5
Training loss: 2.8314721969756462
Validation loss: 2.5446368019012837

Epoch: 6| Step: 6
Training loss: 2.0343531453589216
Validation loss: 2.5427346773722004

Epoch: 6| Step: 7
Training loss: 2.519450814789225
Validation loss: 2.539037999744074

Epoch: 6| Step: 8
Training loss: 2.7747143881966796
Validation loss: 2.5376980132717355

Epoch: 6| Step: 9
Training loss: 2.544503353950987
Validation loss: 2.536916520382844

Epoch: 6| Step: 10
Training loss: 2.4657154990099945
Validation loss: 2.535428683509236

Epoch: 6| Step: 11
Training loss: 2.6986000246230466
Validation loss: 2.541872646761223

Epoch: 6| Step: 12
Training loss: 2.5974377992028104
Validation loss: 2.5338739366273053

Epoch: 6| Step: 13
Training loss: 2.6851661661967756
Validation loss: 2.5369642772693166

Epoch: 71| Step: 0
Training loss: 2.5300351276899242
Validation loss: 2.5353214188559186

Epoch: 6| Step: 1
Training loss: 2.50677050277377
Validation loss: 2.536618133043869

Epoch: 6| Step: 2
Training loss: 2.941299902625963
Validation loss: 2.533728449735629

Epoch: 6| Step: 3
Training loss: 2.989570608787616
Validation loss: 2.5382861393202116

Epoch: 6| Step: 4
Training loss: 2.5230665377122232
Validation loss: 2.5337164051731333

Epoch: 6| Step: 5
Training loss: 2.50486567976597
Validation loss: 2.5342107811345103

Epoch: 6| Step: 6
Training loss: 2.527009402391568
Validation loss: 2.5365772624140592

Epoch: 6| Step: 7
Training loss: 2.974796442072152
Validation loss: 2.5317228997945644

Epoch: 6| Step: 8
Training loss: 2.543233690655588
Validation loss: 2.5305241537001013

Epoch: 6| Step: 9
Training loss: 2.439455666094053
Validation loss: 2.5323574641875086

Epoch: 6| Step: 10
Training loss: 2.337416674918856
Validation loss: 2.5283618352394552

Epoch: 6| Step: 11
Training loss: 2.9262331523190284
Validation loss: 2.533360029590218

Epoch: 6| Step: 12
Training loss: 2.7662407141183585
Validation loss: 2.533486826119917

Epoch: 6| Step: 13
Training loss: 2.541879259400918
Validation loss: 2.536753992999547

Epoch: 72| Step: 0
Training loss: 2.900698538211532
Validation loss: 2.536306283977108

Epoch: 6| Step: 1
Training loss: 2.6809063244354414
Validation loss: 2.5399170674779787

Epoch: 6| Step: 2
Training loss: 2.4701011919613847
Validation loss: 2.533992898141754

Epoch: 6| Step: 3
Training loss: 2.0896942940862946
Validation loss: 2.5378105637495563

Epoch: 6| Step: 4
Training loss: 2.650994790692645
Validation loss: 2.5354146331009955

Epoch: 6| Step: 5
Training loss: 3.0036881346568456
Validation loss: 2.536504699366802

Epoch: 6| Step: 6
Training loss: 2.3964493553879778
Validation loss: 2.533406645776469

Epoch: 6| Step: 7
Training loss: 2.186833525354581
Validation loss: 2.536692040007819

Epoch: 6| Step: 8
Training loss: 2.433674671670751
Validation loss: 2.5363988118691343

Epoch: 6| Step: 9
Training loss: 3.1366587023848456
Validation loss: 2.535649687048444

Epoch: 6| Step: 10
Training loss: 2.5870119380904035
Validation loss: 2.533620579856166

Epoch: 6| Step: 11
Training loss: 2.3384052624813223
Validation loss: 2.533486653590603

Epoch: 6| Step: 12
Training loss: 3.2204161840606207
Validation loss: 2.5302815409581743

Epoch: 6| Step: 13
Training loss: 2.92190062159764
Validation loss: 2.5300813810857528

Epoch: 73| Step: 0
Training loss: 2.7591488979930725
Validation loss: 2.5279490450127966

Epoch: 6| Step: 1
Training loss: 2.692184092231139
Validation loss: 2.5237429407407403

Epoch: 6| Step: 2
Training loss: 3.0300753175546165
Validation loss: 2.5234869134275275

Epoch: 6| Step: 3
Training loss: 2.76201950658585
Validation loss: 2.523884878271773

Epoch: 6| Step: 4
Training loss: 2.2817029111485247
Validation loss: 2.5239166182847796

Epoch: 6| Step: 5
Training loss: 2.9638972725511805
Validation loss: 2.518879256548603

Epoch: 6| Step: 6
Training loss: 2.2971357340319285
Validation loss: 2.5195860864157313

Epoch: 6| Step: 7
Training loss: 2.6051242949546736
Validation loss: 2.5179560505650023

Epoch: 6| Step: 8
Training loss: 2.1113534197143435
Validation loss: 2.5183315368063592

Epoch: 6| Step: 9
Training loss: 2.7853130708392353
Validation loss: 2.52114702800278

Epoch: 6| Step: 10
Training loss: 2.5458464622679307
Validation loss: 2.521597806751359

Epoch: 6| Step: 11
Training loss: 2.45032122316232
Validation loss: 2.514749741967326

Epoch: 6| Step: 12
Training loss: 3.1431152188248834
Validation loss: 2.51685137502468

Epoch: 6| Step: 13
Training loss: 2.555006841362978
Validation loss: 2.521741101989447

Epoch: 74| Step: 0
Training loss: 2.431929556598138
Validation loss: 2.5150329493392336

Epoch: 6| Step: 1
Training loss: 2.5063221148154304
Validation loss: 2.518465054078032

Epoch: 6| Step: 2
Training loss: 3.2241416143642168
Validation loss: 2.5207174579270606

Epoch: 6| Step: 3
Training loss: 2.989467250860883
Validation loss: 2.5222029997764857

Epoch: 6| Step: 4
Training loss: 2.3371154468833044
Validation loss: 2.526829930174888

Epoch: 6| Step: 5
Training loss: 2.7782349263296084
Validation loss: 2.5280244157332374

Epoch: 6| Step: 6
Training loss: 2.7434995289269084
Validation loss: 2.5250968870452994

Epoch: 6| Step: 7
Training loss: 2.700668630108496
Validation loss: 2.522965000192562

Epoch: 6| Step: 8
Training loss: 2.6083843612148265
Validation loss: 2.522457487581724

Epoch: 6| Step: 9
Training loss: 2.56688166704559
Validation loss: 2.51975680186918

Epoch: 6| Step: 10
Training loss: 2.8019662901152795
Validation loss: 2.5205128258437646

Epoch: 6| Step: 11
Training loss: 2.444917982165079
Validation loss: 2.5193560241171333

Epoch: 6| Step: 12
Training loss: 2.619044587311084
Validation loss: 2.5178202652477086

Epoch: 6| Step: 13
Training loss: 2.200830116582578
Validation loss: 2.5166534943478007

Epoch: 75| Step: 0
Training loss: 2.129789452690798
Validation loss: 2.5167417870819486

Epoch: 6| Step: 1
Training loss: 2.61844907501973
Validation loss: 2.519838709639822

Epoch: 6| Step: 2
Training loss: 2.5042185477046464
Validation loss: 2.5137797314975217

Epoch: 6| Step: 3
Training loss: 2.5141014081885236
Validation loss: 2.5227733954634926

Epoch: 6| Step: 4
Training loss: 2.3436981195429833
Validation loss: 2.520010511764925

Epoch: 6| Step: 5
Training loss: 2.554428600759746
Validation loss: 2.5284070819902604

Epoch: 6| Step: 6
Training loss: 3.080694065662557
Validation loss: 2.520977210570702

Epoch: 6| Step: 7
Training loss: 3.1832227244975058
Validation loss: 2.519919637074815

Epoch: 6| Step: 8
Training loss: 2.596871118278678
Validation loss: 2.521015465412168

Epoch: 6| Step: 9
Training loss: 2.6866730593217976
Validation loss: 2.5147124505151357

Epoch: 6| Step: 10
Training loss: 2.7256194399309206
Validation loss: 2.511163645263253

Epoch: 6| Step: 11
Training loss: 2.6103212388343446
Validation loss: 2.513380419579292

Epoch: 6| Step: 12
Training loss: 2.6541105742543305
Validation loss: 2.5145386271280725

Epoch: 6| Step: 13
Training loss: 2.7141377580801653
Validation loss: 2.5125744727944883

Epoch: 76| Step: 0
Training loss: 2.591614637026378
Validation loss: 2.518643473667162

Epoch: 6| Step: 1
Training loss: 2.0752202434164193
Validation loss: 2.522762401178979

Epoch: 6| Step: 2
Training loss: 2.932450519999629
Validation loss: 2.5287275265122293

Epoch: 6| Step: 3
Training loss: 2.523119927137339
Validation loss: 2.5302117184495536

Epoch: 6| Step: 4
Training loss: 2.3230201002508424
Validation loss: 2.5290905567597175

Epoch: 6| Step: 5
Training loss: 2.15886993463799
Validation loss: 2.537733197575951

Epoch: 6| Step: 6
Training loss: 2.7106133083014834
Validation loss: 2.5398629046910486

Epoch: 6| Step: 7
Training loss: 2.7251006746506086
Validation loss: 2.5303199142492536

Epoch: 6| Step: 8
Training loss: 3.2682887260613027
Validation loss: 2.529724729035072

Epoch: 6| Step: 9
Training loss: 2.528455628228844
Validation loss: 2.524278309736408

Epoch: 6| Step: 10
Training loss: 2.544377043949769
Validation loss: 2.5208302384875085

Epoch: 6| Step: 11
Training loss: 2.4110181061971816
Validation loss: 2.5181611507873023

Epoch: 6| Step: 12
Training loss: 3.2687166172168296
Validation loss: 2.5153996463402217

Epoch: 6| Step: 13
Training loss: 2.734197033131502
Validation loss: 2.5130638211119773

Epoch: 77| Step: 0
Training loss: 2.803209430694611
Validation loss: 2.513073861677735

Epoch: 6| Step: 1
Training loss: 1.96462180247286
Validation loss: 2.51233239634964

Epoch: 6| Step: 2
Training loss: 2.9072142611324394
Validation loss: 2.507533754126005

Epoch: 6| Step: 3
Training loss: 2.872794590809849
Validation loss: 2.511308493166367

Epoch: 6| Step: 4
Training loss: 2.5214821056825576
Validation loss: 2.505725297044076

Epoch: 6| Step: 5
Training loss: 2.5124119681503427
Validation loss: 2.5008053753908768

Epoch: 6| Step: 6
Training loss: 2.197617593337806
Validation loss: 2.501924838706019

Epoch: 6| Step: 7
Training loss: 2.7632100396745365
Validation loss: 2.4983813608942707

Epoch: 6| Step: 8
Training loss: 2.9213461983886546
Validation loss: 2.5088534150780095

Epoch: 6| Step: 9
Training loss: 2.9389727532628447
Validation loss: 2.5103318818734444

Epoch: 6| Step: 10
Training loss: 2.658744358905068
Validation loss: 2.5089172591869278

Epoch: 6| Step: 11
Training loss: 2.4422354060750417
Validation loss: 2.520994777606446

Epoch: 6| Step: 12
Training loss: 2.3709230062982716
Validation loss: 2.5036821587434157

Epoch: 6| Step: 13
Training loss: 2.7844740793258427
Validation loss: 2.502827475935586

Epoch: 78| Step: 0
Training loss: 2.35672737769991
Validation loss: 2.501195351611955

Epoch: 6| Step: 1
Training loss: 1.717146802008622
Validation loss: 2.5008573333629256

Epoch: 6| Step: 2
Training loss: 2.539392631783138
Validation loss: 2.5013944710398515

Epoch: 6| Step: 3
Training loss: 2.5432741887059658
Validation loss: 2.5050435054957982

Epoch: 6| Step: 4
Training loss: 1.9043016326062363
Validation loss: 2.506593703170185

Epoch: 6| Step: 5
Training loss: 2.584138826697779
Validation loss: 2.507242995707503

Epoch: 6| Step: 6
Training loss: 2.4984844382280285
Validation loss: 2.509951842607232

Epoch: 6| Step: 7
Training loss: 3.035884185652722
Validation loss: 2.508266182145303

Epoch: 6| Step: 8
Training loss: 2.96794679718454
Validation loss: 2.5105480988050752

Epoch: 6| Step: 9
Training loss: 2.4938243883553737
Validation loss: 2.509607482756806

Epoch: 6| Step: 10
Training loss: 2.729458121153691
Validation loss: 2.5104199379125363

Epoch: 6| Step: 11
Training loss: 2.8627736056637723
Validation loss: 2.5062591162537187

Epoch: 6| Step: 12
Training loss: 3.189066782326559
Validation loss: 2.5096225880831375

Epoch: 6| Step: 13
Training loss: 3.0094474807519562
Validation loss: 2.506764653510862

Epoch: 79| Step: 0
Training loss: 2.2776869029497124
Validation loss: 2.5062451718506638

Epoch: 6| Step: 1
Training loss: 1.8494899433251362
Validation loss: 2.5069719849045606

Epoch: 6| Step: 2
Training loss: 2.644316851941982
Validation loss: 2.507464756133199

Epoch: 6| Step: 3
Training loss: 2.490506648718202
Validation loss: 2.505466683139787

Epoch: 6| Step: 4
Training loss: 2.4474295814678504
Validation loss: 2.5038243923603605

Epoch: 6| Step: 5
Training loss: 2.633965576503065
Validation loss: 2.502431894671964

Epoch: 6| Step: 6
Training loss: 3.244506888753956
Validation loss: 2.500569056277878

Epoch: 6| Step: 7
Training loss: 2.976213890346887
Validation loss: 2.4987275541110656

Epoch: 6| Step: 8
Training loss: 2.77319524002448
Validation loss: 2.497660209550007

Epoch: 6| Step: 9
Training loss: 2.4906726406619346
Validation loss: 2.50406890991462

Epoch: 6| Step: 10
Training loss: 2.4673237604125426
Validation loss: 2.5015874749834555

Epoch: 6| Step: 11
Training loss: 2.721915320744873
Validation loss: 2.5008958959672065

Epoch: 6| Step: 12
Training loss: 2.649535815052856
Validation loss: 2.4989947841244358

Epoch: 6| Step: 13
Training loss: 2.897527587864613
Validation loss: 2.5003623223010285

Epoch: 80| Step: 0
Training loss: 2.889608998495224
Validation loss: 2.5024818340230315

Epoch: 6| Step: 1
Training loss: 2.721797243884343
Validation loss: 2.4939482397384487

Epoch: 6| Step: 2
Training loss: 2.407502282003904
Validation loss: 2.4931881289946114

Epoch: 6| Step: 3
Training loss: 2.7579218596909842
Validation loss: 2.4899705455370778

Epoch: 6| Step: 4
Training loss: 2.834097441317917
Validation loss: 2.4934504227845804

Epoch: 6| Step: 5
Training loss: 2.327810791113323
Validation loss: 2.493456526388593

Epoch: 6| Step: 6
Training loss: 2.3761479464493633
Validation loss: 2.499782187192221

Epoch: 6| Step: 7
Training loss: 2.696493581098248
Validation loss: 2.495875409227489

Epoch: 6| Step: 8
Training loss: 2.348265811535133
Validation loss: 2.5074460246094943

Epoch: 6| Step: 9
Training loss: 2.7804888423098326
Validation loss: 2.498506401850288

Epoch: 6| Step: 10
Training loss: 2.409180677125354
Validation loss: 2.494672996762045

Epoch: 6| Step: 11
Training loss: 2.787828701465242
Validation loss: 2.490140722171753

Epoch: 6| Step: 12
Training loss: 2.3693569804728725
Validation loss: 2.4915487094588253

Epoch: 6| Step: 13
Training loss: 2.9377236788384313
Validation loss: 2.4921913585413735

Epoch: 81| Step: 0
Training loss: 3.054730115042019
Validation loss: 2.4968655486996254

Epoch: 6| Step: 1
Training loss: 2.762864971648542
Validation loss: 2.4963008693197675

Epoch: 6| Step: 2
Training loss: 2.4541972544328567
Validation loss: 2.496950491033359

Epoch: 6| Step: 3
Training loss: 2.645843585938141
Validation loss: 2.4994081988828154

Epoch: 6| Step: 4
Training loss: 2.995198221668302
Validation loss: 2.5005435034919983

Epoch: 6| Step: 5
Training loss: 2.6069726907099393
Validation loss: 2.4982823034024184

Epoch: 6| Step: 6
Training loss: 2.2744896410599056
Validation loss: 2.4990052151360347

Epoch: 6| Step: 7
Training loss: 2.9167553116179565
Validation loss: 2.4977759163860127

Epoch: 6| Step: 8
Training loss: 2.7439833626534695
Validation loss: 2.4941446717024567

Epoch: 6| Step: 9
Training loss: 2.4101263752326942
Validation loss: 2.4954616759219888

Epoch: 6| Step: 10
Training loss: 2.5656328356828806
Validation loss: 2.4960035169487003

Epoch: 6| Step: 11
Training loss: 2.073906884033456
Validation loss: 2.4964427435383203

Epoch: 6| Step: 12
Training loss: 2.690992348435041
Validation loss: 2.4961883415562625

Epoch: 6| Step: 13
Training loss: 2.2677175395208047
Validation loss: 2.500168444998678

Epoch: 82| Step: 0
Training loss: 2.3196358769873
Validation loss: 2.495265721866178

Epoch: 6| Step: 1
Training loss: 2.191867065937442
Validation loss: 2.4945344307840664

Epoch: 6| Step: 2
Training loss: 2.200401624953088
Validation loss: 2.493002635662156

Epoch: 6| Step: 3
Training loss: 2.7859375273853755
Validation loss: 2.4930144465701547

Epoch: 6| Step: 4
Training loss: 2.3615928482583155
Validation loss: 2.496291382099102

Epoch: 6| Step: 5
Training loss: 2.3454317290047824
Validation loss: 2.4920035586344467

Epoch: 6| Step: 6
Training loss: 2.458630355305478
Validation loss: 2.4920629233033846

Epoch: 6| Step: 7
Training loss: 3.398166970194993
Validation loss: 2.4927125096767675

Epoch: 6| Step: 8
Training loss: 2.530577770498086
Validation loss: 2.4904565490146804

Epoch: 6| Step: 9
Training loss: 2.6542887908610333
Validation loss: 2.486276614566288

Epoch: 6| Step: 10
Training loss: 2.6930928253992734
Validation loss: 2.4869020273651454

Epoch: 6| Step: 11
Training loss: 3.0022504630722566
Validation loss: 2.479520168800119

Epoch: 6| Step: 12
Training loss: 2.5460613799985685
Validation loss: 2.485781241636392

Epoch: 6| Step: 13
Training loss: 2.677317291209172
Validation loss: 2.492327886471985

Epoch: 83| Step: 0
Training loss: 1.983456977494971
Validation loss: 2.484032581331692

Epoch: 6| Step: 1
Training loss: 2.8948048656629886
Validation loss: 2.4936086495094956

Epoch: 6| Step: 2
Training loss: 2.8271470881905243
Validation loss: 2.482041508636711

Epoch: 6| Step: 3
Training loss: 1.713038717586155
Validation loss: 2.4885301370674324

Epoch: 6| Step: 4
Training loss: 2.5177977283428445
Validation loss: 2.48304885881942

Epoch: 6| Step: 5
Training loss: 3.382523240194956
Validation loss: 2.4880030150584345

Epoch: 6| Step: 6
Training loss: 3.0261259521371944
Validation loss: 2.4818758440300455

Epoch: 6| Step: 7
Training loss: 2.249837233696029
Validation loss: 2.487233339007028

Epoch: 6| Step: 8
Training loss: 3.0869899065836948
Validation loss: 2.4943607146585984

Epoch: 6| Step: 9
Training loss: 2.2969369685318854
Validation loss: 2.4998358116275803

Epoch: 6| Step: 10
Training loss: 2.629198440706367
Validation loss: 2.4980052460360107

Epoch: 6| Step: 11
Training loss: 3.006442146743201
Validation loss: 2.4960342105615827

Epoch: 6| Step: 12
Training loss: 2.049364745174623
Validation loss: 2.499543641081479

Epoch: 6| Step: 13
Training loss: 2.488449306591768
Validation loss: 2.4943733634487755

Epoch: 84| Step: 0
Training loss: 2.3739867809734267
Validation loss: 2.4926658976399714

Epoch: 6| Step: 1
Training loss: 2.713553449979789
Validation loss: 2.4868329283108457

Epoch: 6| Step: 2
Training loss: 2.489471390467277
Validation loss: 2.4895617804665067

Epoch: 6| Step: 3
Training loss: 1.9788406572039583
Validation loss: 2.4942521618244924

Epoch: 6| Step: 4
Training loss: 2.483061629244523
Validation loss: 2.48337856439281

Epoch: 6| Step: 5
Training loss: 2.2780245618827326
Validation loss: 2.482036801817179

Epoch: 6| Step: 6
Training loss: 2.50369656974776
Validation loss: 2.481673621361567

Epoch: 6| Step: 7
Training loss: 2.865011860554962
Validation loss: 2.476855464257933

Epoch: 6| Step: 8
Training loss: 3.3160017685741683
Validation loss: 2.4803259300306344

Epoch: 6| Step: 9
Training loss: 2.516560540477407
Validation loss: 2.4855519591795114

Epoch: 6| Step: 10
Training loss: 2.7176028056557238
Validation loss: 2.483076143921127

Epoch: 6| Step: 11
Training loss: 2.7814095269218115
Validation loss: 2.478659543227079

Epoch: 6| Step: 12
Training loss: 2.5255606491549187
Validation loss: 2.4811271374421127

Epoch: 6| Step: 13
Training loss: 2.737570067602018
Validation loss: 2.4902138702944625

Epoch: 85| Step: 0
Training loss: 2.847566161019237
Validation loss: 2.493671433845243

Epoch: 6| Step: 1
Training loss: 2.1559127322708314
Validation loss: 2.4959244091078614

Epoch: 6| Step: 2
Training loss: 2.6406127207092456
Validation loss: 2.4956249578883405

Epoch: 6| Step: 3
Training loss: 2.880990463119235
Validation loss: 2.5034072545393165

Epoch: 6| Step: 4
Training loss: 2.5658541801211188
Validation loss: 2.501449784474239

Epoch: 6| Step: 5
Training loss: 2.4546002853896915
Validation loss: 2.5031946116216233

Epoch: 6| Step: 6
Training loss: 2.898245504348968
Validation loss: 2.5053566923776467

Epoch: 6| Step: 7
Training loss: 2.98377449425119
Validation loss: 2.5026874482068204

Epoch: 6| Step: 8
Training loss: 2.696715324333814
Validation loss: 2.497590206936819

Epoch: 6| Step: 9
Training loss: 2.9838350616463143
Validation loss: 2.4972283098653225

Epoch: 6| Step: 10
Training loss: 2.410003311028323
Validation loss: 2.4963656234133427

Epoch: 6| Step: 11
Training loss: 2.067597649700285
Validation loss: 2.498075189298259

Epoch: 6| Step: 12
Training loss: 2.589961306750564
Validation loss: 2.4990409283002926

Epoch: 6| Step: 13
Training loss: 2.2952851482758634
Validation loss: 2.4932875482499934

Epoch: 86| Step: 0
Training loss: 1.9060423691034212
Validation loss: 2.4932084817362323

Epoch: 6| Step: 1
Training loss: 2.4911670090268965
Validation loss: 2.4937657507938384

Epoch: 6| Step: 2
Training loss: 2.8724303994241764
Validation loss: 2.494543255654522

Epoch: 6| Step: 3
Training loss: 2.8232986829839
Validation loss: 2.488257742890009

Epoch: 6| Step: 4
Training loss: 2.4664837056257207
Validation loss: 2.49161938417241

Epoch: 6| Step: 5
Training loss: 2.813727471266941
Validation loss: 2.486383789590085

Epoch: 6| Step: 6
Training loss: 2.2535834916016277
Validation loss: 2.4872220678028594

Epoch: 6| Step: 7
Training loss: 2.9053533668101643
Validation loss: 2.4905445977750262

Epoch: 6| Step: 8
Training loss: 2.380473004629341
Validation loss: 2.490844013662999

Epoch: 6| Step: 9
Training loss: 2.7445975903996453
Validation loss: 2.4890251065861975

Epoch: 6| Step: 10
Training loss: 2.8669692951709695
Validation loss: 2.4863004600502077

Epoch: 6| Step: 11
Training loss: 2.6347609195426847
Validation loss: 2.4835985277867327

Epoch: 6| Step: 12
Training loss: 2.5812904114596362
Validation loss: 2.4831498121981777

Epoch: 6| Step: 13
Training loss: 2.5502170096414636
Validation loss: 2.4813104598128555

Epoch: 87| Step: 0
Training loss: 2.571679305537727
Validation loss: 2.479897492876976

Epoch: 6| Step: 1
Training loss: 2.6093877003983117
Validation loss: 2.4835226248170175

Epoch: 6| Step: 2
Training loss: 2.5598078286044768
Validation loss: 2.477508861501521

Epoch: 6| Step: 3
Training loss: 2.757361356236202
Validation loss: 2.4803719409063216

Epoch: 6| Step: 4
Training loss: 2.171676077755229
Validation loss: 2.481243935552788

Epoch: 6| Step: 5
Training loss: 2.453876647479188
Validation loss: 2.488566575392085

Epoch: 6| Step: 6
Training loss: 2.413930944913612
Validation loss: 2.477819049768976

Epoch: 6| Step: 7
Training loss: 2.9167092093135265
Validation loss: 2.483110005835694

Epoch: 6| Step: 8
Training loss: 3.3107365646706133
Validation loss: 2.487308601543061

Epoch: 6| Step: 9
Training loss: 2.1949713499593413
Validation loss: 2.48248446205811

Epoch: 6| Step: 10
Training loss: 2.455993239011374
Validation loss: 2.4846793014371276

Epoch: 6| Step: 11
Training loss: 2.460074137059016
Validation loss: 2.481848401635024

Epoch: 6| Step: 12
Training loss: 2.670721686336242
Validation loss: 2.4798641318998937

Epoch: 6| Step: 13
Training loss: 2.719159851751537
Validation loss: 2.4781765336350303

Epoch: 88| Step: 0
Training loss: 2.798807510119038
Validation loss: 2.4783295465614446

Epoch: 6| Step: 1
Training loss: 2.6944107979927345
Validation loss: 2.477036945132176

Epoch: 6| Step: 2
Training loss: 2.4457818211639073
Validation loss: 2.479352580774401

Epoch: 6| Step: 3
Training loss: 2.456625803379422
Validation loss: 2.47344021374314

Epoch: 6| Step: 4
Training loss: 3.0357747079942796
Validation loss: 2.480150770095888

Epoch: 6| Step: 5
Training loss: 2.903777845087431
Validation loss: 2.4753280274563503

Epoch: 6| Step: 6
Training loss: 2.515679589858002
Validation loss: 2.479992149402129

Epoch: 6| Step: 7
Training loss: 2.1048903652826243
Validation loss: 2.481070826392706

Epoch: 6| Step: 8
Training loss: 2.205487655034321
Validation loss: 2.477781154386028

Epoch: 6| Step: 9
Training loss: 2.1135540290823176
Validation loss: 2.4813180826040626

Epoch: 6| Step: 10
Training loss: 2.6668456633415705
Validation loss: 2.4798470266139168

Epoch: 6| Step: 11
Training loss: 1.984305493196292
Validation loss: 2.481393812801875

Epoch: 6| Step: 12
Training loss: 2.975472318197133
Validation loss: 2.48074132668185

Epoch: 6| Step: 13
Training loss: 3.035728057060741
Validation loss: 2.4726188379624303

Epoch: 89| Step: 0
Training loss: 2.4926156659774823
Validation loss: 2.4792206595388984

Epoch: 6| Step: 1
Training loss: 2.2006709722881075
Validation loss: 2.4737622528004035

Epoch: 6| Step: 2
Training loss: 2.5280589959165742
Validation loss: 2.483746159138915

Epoch: 6| Step: 3
Training loss: 2.8065461612060596
Validation loss: 2.4804543482244723

Epoch: 6| Step: 4
Training loss: 1.915597479219624
Validation loss: 2.484267114500033

Epoch: 6| Step: 5
Training loss: 2.9781224125693773
Validation loss: 2.4759898200496013

Epoch: 6| Step: 6
Training loss: 1.8894835249825335
Validation loss: 2.485380620980154

Epoch: 6| Step: 7
Training loss: 2.4087357995446608
Validation loss: 2.478702923867445

Epoch: 6| Step: 8
Training loss: 3.3065620318388023
Validation loss: 2.4742191431534857

Epoch: 6| Step: 9
Training loss: 1.8149070541501175
Validation loss: 2.475654026276411

Epoch: 6| Step: 10
Training loss: 2.759816508758838
Validation loss: 2.4783127433402123

Epoch: 6| Step: 11
Training loss: 3.2045774562770064
Validation loss: 2.480688851270721

Epoch: 6| Step: 12
Training loss: 2.894161720729314
Validation loss: 2.4785651003381326

Epoch: 6| Step: 13
Training loss: 2.5297440181495205
Validation loss: 2.481967343172154

Epoch: 90| Step: 0
Training loss: 3.0560218647878687
Validation loss: 2.480836263348847

Epoch: 6| Step: 1
Training loss: 3.0986235793078634
Validation loss: 2.4814821751226126

Epoch: 6| Step: 2
Training loss: 2.3742448710554593
Validation loss: 2.48337279604166

Epoch: 6| Step: 3
Training loss: 2.3561745467108057
Validation loss: 2.482732761863926

Epoch: 6| Step: 4
Training loss: 2.3522944024268044
Validation loss: 2.477166825136795

Epoch: 6| Step: 5
Training loss: 2.645188310550443
Validation loss: 2.4893735427462698

Epoch: 6| Step: 6
Training loss: 2.6407837227514714
Validation loss: 2.481928790664003

Epoch: 6| Step: 7
Training loss: 2.5945329518529405
Validation loss: 2.4876180310896805

Epoch: 6| Step: 8
Training loss: 2.3741889371817138
Validation loss: 2.465419728187653

Epoch: 6| Step: 9
Training loss: 2.4173792303742547
Validation loss: 2.4813365469571305

Epoch: 6| Step: 10
Training loss: 2.2984086709772136
Validation loss: 2.4808208385900783

Epoch: 6| Step: 11
Training loss: 2.1688552830890204
Validation loss: 2.4862618788378983

Epoch: 6| Step: 12
Training loss: 3.0453409098694055
Validation loss: 2.4803827706401584

Epoch: 6| Step: 13
Training loss: 2.7134023229121604
Validation loss: 2.4773648603877816

Epoch: 91| Step: 0
Training loss: 2.0763641010053724
Validation loss: 2.472251388887333

Epoch: 6| Step: 1
Training loss: 2.3518325802649525
Validation loss: 2.4756722439600853

Epoch: 6| Step: 2
Training loss: 2.4007372439044676
Validation loss: 2.475581683895713

Epoch: 6| Step: 3
Training loss: 2.650980760715336
Validation loss: 2.48377193272939

Epoch: 6| Step: 4
Training loss: 2.507555892032371
Validation loss: 2.474792762711361

Epoch: 6| Step: 5
Training loss: 2.9364998920842713
Validation loss: 2.475172388771366

Epoch: 6| Step: 6
Training loss: 3.0677482632605764
Validation loss: 2.47984765153979

Epoch: 6| Step: 7
Training loss: 2.5744043494596185
Validation loss: 2.476543149661934

Epoch: 6| Step: 8
Training loss: 2.839395395852655
Validation loss: 2.4846526816468977

Epoch: 6| Step: 9
Training loss: 2.7503849106956686
Validation loss: 2.4774808735242306

Epoch: 6| Step: 10
Training loss: 2.2365626582803495
Validation loss: 2.471410532966114

Epoch: 6| Step: 11
Training loss: 1.9800879358743555
Validation loss: 2.4812427504631365

Epoch: 6| Step: 12
Training loss: 3.0980783105240657
Validation loss: 2.4775620618451093

Epoch: 6| Step: 13
Training loss: 2.408559112349262
Validation loss: 2.4740703088951057

Epoch: 92| Step: 0
Training loss: 2.6637735965279727
Validation loss: 2.478676376159937

Epoch: 6| Step: 1
Training loss: 2.635767876866287
Validation loss: 2.4788871789249343

Epoch: 6| Step: 2
Training loss: 2.759136973361155
Validation loss: 2.4771365474142972

Epoch: 6| Step: 3
Training loss: 2.71933731224827
Validation loss: 2.4756741700509637

Epoch: 6| Step: 4
Training loss: 2.88821327020098
Validation loss: 2.4760514944542424

Epoch: 6| Step: 5
Training loss: 2.5527183106084053
Validation loss: 2.473016464567824

Epoch: 6| Step: 6
Training loss: 2.42153189905247
Validation loss: 2.4802293396601853

Epoch: 6| Step: 7
Training loss: 2.6936999818623373
Validation loss: 2.4764090890631647

Epoch: 6| Step: 8
Training loss: 2.4585643164100475
Validation loss: 2.4744737322493444

Epoch: 6| Step: 9
Training loss: 2.0901596258432336
Validation loss: 2.4774424035735714

Epoch: 6| Step: 10
Training loss: 2.6147405772146524
Validation loss: 2.479680245895047

Epoch: 6| Step: 11
Training loss: 2.7277546984163856
Validation loss: 2.4798479479789313

Epoch: 6| Step: 12
Training loss: 2.5059249286595544
Validation loss: 2.478854317315972

Epoch: 6| Step: 13
Training loss: 2.414770621232527
Validation loss: 2.4717716926884985

Epoch: 93| Step: 0
Training loss: 2.3629171295874105
Validation loss: 2.47245783760577

Epoch: 6| Step: 1
Training loss: 2.568726209544258
Validation loss: 2.472431624636772

Epoch: 6| Step: 2
Training loss: 2.683514500854047
Validation loss: 2.477427094019077

Epoch: 6| Step: 3
Training loss: 2.4749910681977605
Validation loss: 2.485390973231446

Epoch: 6| Step: 4
Training loss: 2.9878114418272887
Validation loss: 2.478596571013074

Epoch: 6| Step: 5
Training loss: 2.7007008525963854
Validation loss: 2.475050969353608

Epoch: 6| Step: 6
Training loss: 2.7005816716128526
Validation loss: 2.474347589220046

Epoch: 6| Step: 7
Training loss: 2.3228731251101267
Validation loss: 2.471240915665421

Epoch: 6| Step: 8
Training loss: 3.089500205597297
Validation loss: 2.471158168940801

Epoch: 6| Step: 9
Training loss: 2.373794651344747
Validation loss: 2.4753818525652806

Epoch: 6| Step: 10
Training loss: 2.252811688399066
Validation loss: 2.4710367452466695

Epoch: 6| Step: 11
Training loss: 2.917737346497202
Validation loss: 2.4734132561104976

Epoch: 6| Step: 12
Training loss: 2.3362451050994357
Validation loss: 2.474160201553664

Epoch: 6| Step: 13
Training loss: 2.229315518076834
Validation loss: 2.4754369125304514

Epoch: 94| Step: 0
Training loss: 2.5442436995112008
Validation loss: 2.4738059602627227

Epoch: 6| Step: 1
Training loss: 2.1170786023726818
Validation loss: 2.4732707838373273

Epoch: 6| Step: 2
Training loss: 2.40846576480557
Validation loss: 2.4722880832124

Epoch: 6| Step: 3
Training loss: 2.331712045980089
Validation loss: 2.4694732861955644

Epoch: 6| Step: 4
Training loss: 2.789695603777778
Validation loss: 2.4643377801411357

Epoch: 6| Step: 5
Training loss: 3.4372666713247324
Validation loss: 2.4638896209828482

Epoch: 6| Step: 6
Training loss: 2.2262941432990817
Validation loss: 2.4642652748673988

Epoch: 6| Step: 7
Training loss: 2.526008170518626
Validation loss: 2.4660970057991465

Epoch: 6| Step: 8
Training loss: 2.6381526410738596
Validation loss: 2.466804752050344

Epoch: 6| Step: 9
Training loss: 2.735060861945961
Validation loss: 2.4815564431571056

Epoch: 6| Step: 10
Training loss: 2.1479860143508103
Validation loss: 2.4784543806665242

Epoch: 6| Step: 11
Training loss: 3.002205038328176
Validation loss: 2.495393387150923

Epoch: 6| Step: 12
Training loss: 2.3682490319808065
Validation loss: 2.4919465844433817

Epoch: 6| Step: 13
Training loss: 2.639848673991736
Validation loss: 2.4892561842567744

Epoch: 95| Step: 0
Training loss: 2.3044735566747314
Validation loss: 2.481067751349794

Epoch: 6| Step: 1
Training loss: 2.6785573105212945
Validation loss: 2.4654496904587333

Epoch: 6| Step: 2
Training loss: 2.465800201031846
Validation loss: 2.461716479178636

Epoch: 6| Step: 3
Training loss: 2.5949114301851175
Validation loss: 2.469273234099808

Epoch: 6| Step: 4
Training loss: 2.428265121521274
Validation loss: 2.471234065769699

Epoch: 6| Step: 5
Training loss: 2.900765771719242
Validation loss: 2.471498625177475

Epoch: 6| Step: 6
Training loss: 2.6959503745880062
Validation loss: 2.4755076619851986

Epoch: 6| Step: 7
Training loss: 2.7652834234132673
Validation loss: 2.4745839877132285

Epoch: 6| Step: 8
Training loss: 2.6646216021174007
Validation loss: 2.473070123073446

Epoch: 6| Step: 9
Training loss: 2.431187500922612
Validation loss: 2.47754148433789

Epoch: 6| Step: 10
Training loss: 2.645362351517311
Validation loss: 2.480229828308945

Epoch: 6| Step: 11
Training loss: 2.732788672106133
Validation loss: 2.4784516230326576

Epoch: 6| Step: 12
Training loss: 2.5098139776774624
Validation loss: 2.4694472748685716

Epoch: 6| Step: 13
Training loss: 2.1378431970460907
Validation loss: 2.4673128411487286

Epoch: 96| Step: 0
Training loss: 3.0962024562790713
Validation loss: 2.46529138110591

Epoch: 6| Step: 1
Training loss: 2.6223392625684063
Validation loss: 2.463650180182221

Epoch: 6| Step: 2
Training loss: 2.400931487517181
Validation loss: 2.466487459382978

Epoch: 6| Step: 3
Training loss: 2.9688484577115006
Validation loss: 2.4675231975790664

Epoch: 6| Step: 4
Training loss: 2.545836441695776
Validation loss: 2.461679603057976

Epoch: 6| Step: 5
Training loss: 2.195369841889011
Validation loss: 2.467759146810641

Epoch: 6| Step: 6
Training loss: 2.285115142191686
Validation loss: 2.465975445692421

Epoch: 6| Step: 7
Training loss: 2.486430151824568
Validation loss: 2.4648720104372797

Epoch: 6| Step: 8
Training loss: 2.3374551289377434
Validation loss: 2.4663647665603823

Epoch: 6| Step: 9
Training loss: 2.927530293035101
Validation loss: 2.466630146254575

Epoch: 6| Step: 10
Training loss: 2.6743004927092944
Validation loss: 2.4633177775828297

Epoch: 6| Step: 11
Training loss: 2.6826359401362665
Validation loss: 2.463823206959208

Epoch: 6| Step: 12
Training loss: 2.344936833293432
Validation loss: 2.4605643337639904

Epoch: 6| Step: 13
Training loss: 2.095463862630674
Validation loss: 2.4581626385625537

Epoch: 97| Step: 0
Training loss: 2.4450072076609337
Validation loss: 2.467942665173974

Epoch: 6| Step: 1
Training loss: 2.5670273956691556
Validation loss: 2.464248512808649

Epoch: 6| Step: 2
Training loss: 2.179979092908925
Validation loss: 2.465960540309336

Epoch: 6| Step: 3
Training loss: 2.7693521847965634
Validation loss: 2.4668588919959755

Epoch: 6| Step: 4
Training loss: 2.9991940369398944
Validation loss: 2.462035193685766

Epoch: 6| Step: 5
Training loss: 2.5570168797514303
Validation loss: 2.464570430830403

Epoch: 6| Step: 6
Training loss: 2.7948210436148715
Validation loss: 2.46906579488684

Epoch: 6| Step: 7
Training loss: 2.646520410271272
Validation loss: 2.4684314683247366

Epoch: 6| Step: 8
Training loss: 2.166424835598581
Validation loss: 2.4636930347955515

Epoch: 6| Step: 9
Training loss: 2.254894760450427
Validation loss: 2.462755692143907

Epoch: 6| Step: 10
Training loss: 2.3998265919027593
Validation loss: 2.461235222140033

Epoch: 6| Step: 11
Training loss: 2.3514986251317653
Validation loss: 2.461242640716622

Epoch: 6| Step: 12
Training loss: 2.5661505770666864
Validation loss: 2.459437580273795

Epoch: 6| Step: 13
Training loss: 2.9813031269833896
Validation loss: 2.478844458748333

Epoch: 98| Step: 0
Training loss: 2.495439757157845
Validation loss: 2.4610927956643263

Epoch: 6| Step: 1
Training loss: 2.0355499531091796
Validation loss: 2.4648143607360837

Epoch: 6| Step: 2
Training loss: 2.7489670634206376
Validation loss: 2.4632317077190846

Epoch: 6| Step: 3
Training loss: 2.747064410765079
Validation loss: 2.4641753679452356

Epoch: 6| Step: 4
Training loss: 2.669402020960053
Validation loss: 2.465816654416635

Epoch: 6| Step: 5
Training loss: 2.5106807480145554
Validation loss: 2.4649930929895785

Epoch: 6| Step: 6
Training loss: 2.4035362695346425
Validation loss: 2.465228970063902

Epoch: 6| Step: 7
Training loss: 3.0813244298027462
Validation loss: 2.4670815121137633

Epoch: 6| Step: 8
Training loss: 2.5708436735945805
Validation loss: 2.4698070243015806

Epoch: 6| Step: 9
Training loss: 2.3242504470330747
Validation loss: 2.471576215752827

Epoch: 6| Step: 10
Training loss: 2.3991936600670356
Validation loss: 2.4734330646975557

Epoch: 6| Step: 11
Training loss: 2.7349340248867793
Validation loss: 2.468334323960989

Epoch: 6| Step: 12
Training loss: 2.7315316375849807
Validation loss: 2.4675501229381824

Epoch: 6| Step: 13
Training loss: 2.3844567801073584
Validation loss: 2.463272407984489

Epoch: 99| Step: 0
Training loss: 2.2030428607319297
Validation loss: 2.4691191288670606

Epoch: 6| Step: 1
Training loss: 1.963453282425341
Validation loss: 2.4638039339775832

Epoch: 6| Step: 2
Training loss: 2.6095405571777697
Validation loss: 2.4613781650535715

Epoch: 6| Step: 3
Training loss: 2.8644329424596666
Validation loss: 2.4656445733322077

Epoch: 6| Step: 4
Training loss: 2.057133716040692
Validation loss: 2.463012450288567

Epoch: 6| Step: 5
Training loss: 2.6597860697715303
Validation loss: 2.4593060368680772

Epoch: 6| Step: 6
Training loss: 3.0172405757809027
Validation loss: 2.4609815644048156

Epoch: 6| Step: 7
Training loss: 2.664834187629428
Validation loss: 2.45817507757083

Epoch: 6| Step: 8
Training loss: 2.5710280329727615
Validation loss: 2.4577066032099832

Epoch: 6| Step: 9
Training loss: 2.27264390445738
Validation loss: 2.4615607547209004

Epoch: 6| Step: 10
Training loss: 2.940039166299905
Validation loss: 2.4615363144330296

Epoch: 6| Step: 11
Training loss: 2.815069254265521
Validation loss: 2.4657984928386916

Epoch: 6| Step: 12
Training loss: 2.8536737020939276
Validation loss: 2.46833691581485

Epoch: 6| Step: 13
Training loss: 2.0429353729497457
Validation loss: 2.4604196800926244

Epoch: 100| Step: 0
Training loss: 2.6835208977329272
Validation loss: 2.460920594172462

Epoch: 6| Step: 1
Training loss: 2.512883178946589
Validation loss: 2.4639105705426396

Epoch: 6| Step: 2
Training loss: 2.9915598716552947
Validation loss: 2.4686608439253295

Epoch: 6| Step: 3
Training loss: 2.497224602316841
Validation loss: 2.4734296749181586

Epoch: 6| Step: 4
Training loss: 2.4689146542265767
Validation loss: 2.4779693586709266

Epoch: 6| Step: 5
Training loss: 2.572350896697841
Validation loss: 2.4761639263272026

Epoch: 6| Step: 6
Training loss: 2.6892795437470802
Validation loss: 2.4769887787974523

Epoch: 6| Step: 7
Training loss: 2.4441104164591745
Validation loss: 2.4729438281047273

Epoch: 6| Step: 8
Training loss: 2.4227026724896166
Validation loss: 2.4732489817065924

Epoch: 6| Step: 9
Training loss: 2.693266426457709
Validation loss: 2.466381498125391

Epoch: 6| Step: 10
Training loss: 2.8334664332224304
Validation loss: 2.455591035412046

Epoch: 6| Step: 11
Training loss: 1.861090373719232
Validation loss: 2.4620512687422997

Epoch: 6| Step: 12
Training loss: 2.330182900515218
Validation loss: 2.4724928895843576

Epoch: 6| Step: 13
Training loss: 2.6057502102705845
Validation loss: 2.4736238648375397

Epoch: 101| Step: 0
Training loss: 3.054026656608436
Validation loss: 2.4879018513290503

Epoch: 6| Step: 1
Training loss: 2.378952552081725
Validation loss: 2.504084461235982

Epoch: 6| Step: 2
Training loss: 2.5334295614270395
Validation loss: 2.5267739063804155

Epoch: 6| Step: 3
Training loss: 2.241486230369274
Validation loss: 2.50360499180007

Epoch: 6| Step: 4
Training loss: 2.7190639270760752
Validation loss: 2.470386429544427

Epoch: 6| Step: 5
Training loss: 2.435120325738335
Validation loss: 2.4665089185207947

Epoch: 6| Step: 6
Training loss: 2.8213725541470827
Validation loss: 2.461037883023138

Epoch: 6| Step: 7
Training loss: 1.8590152937499573
Validation loss: 2.466282428206662

Epoch: 6| Step: 8
Training loss: 2.5014100866450955
Validation loss: 2.478053200873409

Epoch: 6| Step: 9
Training loss: 2.7970024378209817
Validation loss: 2.4715397359452678

Epoch: 6| Step: 10
Training loss: 2.780250884200104
Validation loss: 2.479077078432071

Epoch: 6| Step: 11
Training loss: 2.4441868930538577
Validation loss: 2.4731943229038826

Epoch: 6| Step: 12
Training loss: 3.115146972960822
Validation loss: 2.4783796990099396

Epoch: 6| Step: 13
Training loss: 1.898615573647436
Validation loss: 2.4897645115599745

Epoch: 102| Step: 0
Training loss: 2.525339738254958
Validation loss: 2.4814466896538714

Epoch: 6| Step: 1
Training loss: 3.371728229598652
Validation loss: 2.4824335761786167

Epoch: 6| Step: 2
Training loss: 2.091736237887464
Validation loss: 2.4870412981883616

Epoch: 6| Step: 3
Training loss: 2.563494326575355
Validation loss: 2.490346533549593

Epoch: 6| Step: 4
Training loss: 2.759925702656829
Validation loss: 2.4807786802969845

Epoch: 6| Step: 5
Training loss: 2.4209502392728264
Validation loss: 2.4795157937379373

Epoch: 6| Step: 6
Training loss: 3.0358769605630815
Validation loss: 2.483482472423872

Epoch: 6| Step: 7
Training loss: 2.708541646917835
Validation loss: 2.4819523417067257

Epoch: 6| Step: 8
Training loss: 2.7208087185909267
Validation loss: 2.4794614173208886

Epoch: 6| Step: 9
Training loss: 2.3243272772062333
Validation loss: 2.4755086812762372

Epoch: 6| Step: 10
Training loss: 2.1703437511811385
Validation loss: 2.4780513167200415

Epoch: 6| Step: 11
Training loss: 2.1988619418380764
Validation loss: 2.472828027946511

Epoch: 6| Step: 12
Training loss: 2.4318315178271317
Validation loss: 2.4802722602775558

Epoch: 6| Step: 13
Training loss: 2.7537928348210614
Validation loss: 2.475209730105272

Epoch: 103| Step: 0
Training loss: 3.122843646891744
Validation loss: 2.481048340053447

Epoch: 6| Step: 1
Training loss: 2.243936634005435
Validation loss: 2.47653337816511

Epoch: 6| Step: 2
Training loss: 2.4417316189438583
Validation loss: 2.472182049109369

Epoch: 6| Step: 3
Training loss: 2.8270245513389676
Validation loss: 2.476239573446959

Epoch: 6| Step: 4
Training loss: 2.8969471022306497
Validation loss: 2.4734655163789405

Epoch: 6| Step: 5
Training loss: 2.5292449356696545
Validation loss: 2.4790757801054926

Epoch: 6| Step: 6
Training loss: 2.6053866669451686
Validation loss: 2.4642622030412116

Epoch: 6| Step: 7
Training loss: 2.1392748953656926
Validation loss: 2.4602835780450993

Epoch: 6| Step: 8
Training loss: 2.199312197934148
Validation loss: 2.4573454744388687

Epoch: 6| Step: 9
Training loss: 2.661097154290913
Validation loss: 2.4625190295211907

Epoch: 6| Step: 10
Training loss: 2.635251599194724
Validation loss: 2.4562236548281664

Epoch: 6| Step: 11
Training loss: 2.29782354789287
Validation loss: 2.457624807464461

Epoch: 6| Step: 12
Training loss: 2.3209597522906185
Validation loss: 2.4538754977526187

Epoch: 6| Step: 13
Training loss: 2.6313496043002855
Validation loss: 2.4599594837046617

Epoch: 104| Step: 0
Training loss: 2.5537960818740815
Validation loss: 2.4653499867306787

Epoch: 6| Step: 1
Training loss: 2.678292492466313
Validation loss: 2.4625429759656545

Epoch: 6| Step: 2
Training loss: 2.331534634720053
Validation loss: 2.4713124203681653

Epoch: 6| Step: 3
Training loss: 2.1487770505825754
Validation loss: 2.4624494963758217

Epoch: 6| Step: 4
Training loss: 2.7794991457821694
Validation loss: 2.4725662705219045

Epoch: 6| Step: 5
Training loss: 2.3874346819026404
Validation loss: 2.474606532792986

Epoch: 6| Step: 6
Training loss: 3.0978200323189724
Validation loss: 2.466101372441225

Epoch: 6| Step: 7
Training loss: 2.784744724511491
Validation loss: 2.466983694461026

Epoch: 6| Step: 8
Training loss: 2.5563489078702717
Validation loss: 2.4567493626751675

Epoch: 6| Step: 9
Training loss: 2.094384737734923
Validation loss: 2.4608637561547364

Epoch: 6| Step: 10
Training loss: 2.2160899375264655
Validation loss: 2.461247258143644

Epoch: 6| Step: 11
Training loss: 2.1787028395888277
Validation loss: 2.4708968256232824

Epoch: 6| Step: 12
Training loss: 2.9310431433853426
Validation loss: 2.4719950920476

Epoch: 6| Step: 13
Training loss: 2.749855384492086
Validation loss: 2.476270335520099

Epoch: 105| Step: 0
Training loss: 2.7296325538315167
Validation loss: 2.4794046357222514

Epoch: 6| Step: 1
Training loss: 2.7617976542940577
Validation loss: 2.4802905561865356

Epoch: 6| Step: 2
Training loss: 2.0961362990113983
Validation loss: 2.4871370807995996

Epoch: 6| Step: 3
Training loss: 2.7228159700282033
Validation loss: 2.485512910713056

Epoch: 6| Step: 4
Training loss: 2.1199161077490882
Validation loss: 2.4817166611055157

Epoch: 6| Step: 5
Training loss: 2.2820189760707987
Validation loss: 2.480995919184908

Epoch: 6| Step: 6
Training loss: 2.8788052130972765
Validation loss: 2.470329857575643

Epoch: 6| Step: 7
Training loss: 2.784112378888692
Validation loss: 2.467971711269179

Epoch: 6| Step: 8
Training loss: 2.9131098358473286
Validation loss: 2.4629361065006106

Epoch: 6| Step: 9
Training loss: 2.1096135887564733
Validation loss: 2.4601436242766583

Epoch: 6| Step: 10
Training loss: 2.4865473240840736
Validation loss: 2.4600996094724312

Epoch: 6| Step: 11
Training loss: 2.9131671256076594
Validation loss: 2.456542426862248

Epoch: 6| Step: 12
Training loss: 2.6712328044246854
Validation loss: 2.4596659609808293

Epoch: 6| Step: 13
Training loss: 2.330544360344477
Validation loss: 2.4601556252407795

Epoch: 106| Step: 0
Training loss: 2.688934120957251
Validation loss: 2.457424534634681

Epoch: 6| Step: 1
Training loss: 3.0321251303988896
Validation loss: 2.4555848700536616

Epoch: 6| Step: 2
Training loss: 2.2689180842576246
Validation loss: 2.4570116811517857

Epoch: 6| Step: 3
Training loss: 2.4026257853372996
Validation loss: 2.46068077564854

Epoch: 6| Step: 4
Training loss: 2.5369529998960645
Validation loss: 2.458588050857499

Epoch: 6| Step: 5
Training loss: 1.893984371576009
Validation loss: 2.4596177533499795

Epoch: 6| Step: 6
Training loss: 2.552707663223385
Validation loss: 2.4569521326731025

Epoch: 6| Step: 7
Training loss: 2.5105397258898328
Validation loss: 2.4546043810904967

Epoch: 6| Step: 8
Training loss: 3.385478671557582
Validation loss: 2.4587865885766225

Epoch: 6| Step: 9
Training loss: 2.527848866852257
Validation loss: 2.457849347161101

Epoch: 6| Step: 10
Training loss: 2.262997912842129
Validation loss: 2.455597253346392

Epoch: 6| Step: 11
Training loss: 2.344693617011359
Validation loss: 2.4599443964889827

Epoch: 6| Step: 12
Training loss: 2.556738167483693
Validation loss: 2.464710802300453

Epoch: 6| Step: 13
Training loss: 2.3891871497778943
Validation loss: 2.4584695702857986

Epoch: 107| Step: 0
Training loss: 1.8530256711125521
Validation loss: 2.461349033076609

Epoch: 6| Step: 1
Training loss: 2.384403885532663
Validation loss: 2.464719145497401

Epoch: 6| Step: 2
Training loss: 2.8102457125064073
Validation loss: 2.4565930645431604

Epoch: 6| Step: 3
Training loss: 2.9929048559766667
Validation loss: 2.455548363047442

Epoch: 6| Step: 4
Training loss: 2.2123624166178963
Validation loss: 2.4585676781979426

Epoch: 6| Step: 5
Training loss: 2.5588939694451573
Validation loss: 2.456381529440256

Epoch: 6| Step: 6
Training loss: 3.025050322058919
Validation loss: 2.452673504013267

Epoch: 6| Step: 7
Training loss: 2.3543704684552886
Validation loss: 2.457913255091531

Epoch: 6| Step: 8
Training loss: 2.64077397214075
Validation loss: 2.4518193133316397

Epoch: 6| Step: 9
Training loss: 2.1977638324071833
Validation loss: 2.452866040469766

Epoch: 6| Step: 10
Training loss: 2.966093139359002
Validation loss: 2.462090713516599

Epoch: 6| Step: 11
Training loss: 2.615616603094954
Validation loss: 2.4628949408577827

Epoch: 6| Step: 12
Training loss: 2.4059277603580544
Validation loss: 2.4622905584041757

Epoch: 6| Step: 13
Training loss: 2.4213506315526487
Validation loss: 2.453210574072841

Epoch: 108| Step: 0
Training loss: 2.1289255123841873
Validation loss: 2.4578890210377597

Epoch: 6| Step: 1
Training loss: 2.274671291875814
Validation loss: 2.464635615521152

Epoch: 6| Step: 2
Training loss: 2.9196199088738384
Validation loss: 2.4507838617144113

Epoch: 6| Step: 3
Training loss: 3.038214165517592
Validation loss: 2.452982726294307

Epoch: 6| Step: 4
Training loss: 2.527130825501125
Validation loss: 2.4512434463893205

Epoch: 6| Step: 5
Training loss: 2.1663448265879386
Validation loss: 2.4549223517357444

Epoch: 6| Step: 6
Training loss: 2.5497280125392288
Validation loss: 2.4541225956153236

Epoch: 6| Step: 7
Training loss: 2.5873919773128105
Validation loss: 2.464367126715416

Epoch: 6| Step: 8
Training loss: 2.5148263931267976
Validation loss: 2.4635308543015704

Epoch: 6| Step: 9
Training loss: 2.2723226533854888
Validation loss: 2.4736435592905863

Epoch: 6| Step: 10
Training loss: 2.28913020011075
Validation loss: 2.481852756574443

Epoch: 6| Step: 11
Training loss: 2.4519959785590246
Validation loss: 2.478061948136873

Epoch: 6| Step: 12
Training loss: 2.90445711351839
Validation loss: 2.472442730226543

Epoch: 6| Step: 13
Training loss: 2.8459501034939367
Validation loss: 2.470665554720935

Epoch: 109| Step: 0
Training loss: 2.575098839501724
Validation loss: 2.4685134935366304

Epoch: 6| Step: 1
Training loss: 2.506918108923024
Validation loss: 2.4641731748558415

Epoch: 6| Step: 2
Training loss: 2.2799067265689286
Validation loss: 2.457324844875912

Epoch: 6| Step: 3
Training loss: 2.3417048368589817
Validation loss: 2.4646125277942246

Epoch: 6| Step: 4
Training loss: 2.409646745489744
Validation loss: 2.4707345349874723

Epoch: 6| Step: 5
Training loss: 2.747053128001263
Validation loss: 2.4792274713405913

Epoch: 6| Step: 6
Training loss: 2.268436555253949
Validation loss: 2.4821372280403335

Epoch: 6| Step: 7
Training loss: 2.3761356048098494
Validation loss: 2.467500426741038

Epoch: 6| Step: 8
Training loss: 3.0334769651620803
Validation loss: 2.46248903159137

Epoch: 6| Step: 9
Training loss: 2.6055988696776655
Validation loss: 2.458032142378306

Epoch: 6| Step: 10
Training loss: 2.6181402038147334
Validation loss: 2.460704021378402

Epoch: 6| Step: 11
Training loss: 3.0418275938617576
Validation loss: 2.4655086630098686

Epoch: 6| Step: 12
Training loss: 2.601879936761546
Validation loss: 2.4753156987250526

Epoch: 6| Step: 13
Training loss: 2.3475118329254694
Validation loss: 2.475377919663762

Epoch: 110| Step: 0
Training loss: 2.4080439234177966
Validation loss: 2.474022654985518

Epoch: 6| Step: 1
Training loss: 2.255864448046244
Validation loss: 2.471856942735796

Epoch: 6| Step: 2
Training loss: 2.807471888223945
Validation loss: 2.4762017501759552

Epoch: 6| Step: 3
Training loss: 2.255190055602775
Validation loss: 2.476087859646577

Epoch: 6| Step: 4
Training loss: 2.19687572495515
Validation loss: 2.4770738813788347

Epoch: 6| Step: 5
Training loss: 3.0399504396514607
Validation loss: 2.4779657265404786

Epoch: 6| Step: 6
Training loss: 2.7314142382930315
Validation loss: 2.478469210912314

Epoch: 6| Step: 7
Training loss: 2.3615470134797234
Validation loss: 2.468032523411312

Epoch: 6| Step: 8
Training loss: 2.4543011998173836
Validation loss: 2.465560301111938

Epoch: 6| Step: 9
Training loss: 2.7878425558723734
Validation loss: 2.4684051723530915

Epoch: 6| Step: 10
Training loss: 2.9850204329054906
Validation loss: 2.466672715510435

Epoch: 6| Step: 11
Training loss: 2.854217547406358
Validation loss: 2.467442935076326

Epoch: 6| Step: 12
Training loss: 2.158422177620607
Validation loss: 2.4589561923358505

Epoch: 6| Step: 13
Training loss: 2.4491471032184093
Validation loss: 2.460523419132884

Epoch: 111| Step: 0
Training loss: 2.7183195628416352
Validation loss: 2.4542755215072254

Epoch: 6| Step: 1
Training loss: 2.2149244828622745
Validation loss: 2.463002399244649

Epoch: 6| Step: 2
Training loss: 1.937745663235078
Validation loss: 2.461399628375989

Epoch: 6| Step: 3
Training loss: 2.582528532448508
Validation loss: 2.453838884347316

Epoch: 6| Step: 4
Training loss: 2.7173559188197407
Validation loss: 2.454702352102097

Epoch: 6| Step: 5
Training loss: 2.9972185910493314
Validation loss: 2.4571201164860903

Epoch: 6| Step: 6
Training loss: 2.778817216520952
Validation loss: 2.4592128139532226

Epoch: 6| Step: 7
Training loss: 2.181184316263734
Validation loss: 2.4536004547239365

Epoch: 6| Step: 8
Training loss: 2.4211458154418017
Validation loss: 2.4480721985666887

Epoch: 6| Step: 9
Training loss: 2.9315391284062633
Validation loss: 2.454898039596856

Epoch: 6| Step: 10
Training loss: 2.616252310761417
Validation loss: 2.4588087290356797

Epoch: 6| Step: 11
Training loss: 2.3388622944886186
Validation loss: 2.4582450064184855

Epoch: 6| Step: 12
Training loss: 2.3689733636468895
Validation loss: 2.461458714103481

Epoch: 6| Step: 13
Training loss: 2.7089800624909346
Validation loss: 2.459678319688454

Epoch: 112| Step: 0
Training loss: 2.4328166278076435
Validation loss: 2.452620711601242

Epoch: 6| Step: 1
Training loss: 2.837427845848332
Validation loss: 2.460712192454625

Epoch: 6| Step: 2
Training loss: 2.039783569523504
Validation loss: 2.4575802463120904

Epoch: 6| Step: 3
Training loss: 2.7618463424711712
Validation loss: 2.460061812645103

Epoch: 6| Step: 4
Training loss: 3.122088181984754
Validation loss: 2.457860421636905

Epoch: 6| Step: 5
Training loss: 2.3765251884064624
Validation loss: 2.460473508337059

Epoch: 6| Step: 6
Training loss: 2.4059314269189755
Validation loss: 2.4534787613414792

Epoch: 6| Step: 7
Training loss: 2.630634074486624
Validation loss: 2.454448334916424

Epoch: 6| Step: 8
Training loss: 2.4375376576180128
Validation loss: 2.452653333347049

Epoch: 6| Step: 9
Training loss: 1.651520508202569
Validation loss: 2.4574962553976927

Epoch: 6| Step: 10
Training loss: 2.788142632277112
Validation loss: 2.4606241662506325

Epoch: 6| Step: 11
Training loss: 2.5288547438737545
Validation loss: 2.472543015782458

Epoch: 6| Step: 12
Training loss: 2.756381260520908
Validation loss: 2.4737715854766407

Epoch: 6| Step: 13
Training loss: 2.5317118658970315
Validation loss: 2.4772212679621766

Epoch: 113| Step: 0
Training loss: 1.7419339666935365
Validation loss: 2.4770162108630984

Epoch: 6| Step: 1
Training loss: 2.6170896597266857
Validation loss: 2.4813279153295635

Epoch: 6| Step: 2
Training loss: 2.510525005952236
Validation loss: 2.482551177164164

Epoch: 6| Step: 3
Training loss: 2.3978111617284563
Validation loss: 2.4824732093095334

Epoch: 6| Step: 4
Training loss: 2.8653941353721986
Validation loss: 2.479465487981084

Epoch: 6| Step: 5
Training loss: 2.1147027443930635
Validation loss: 2.4830922427906446

Epoch: 6| Step: 6
Training loss: 2.6306534695778447
Validation loss: 2.4901081606725115

Epoch: 6| Step: 7
Training loss: 2.116609614146527
Validation loss: 2.484168054050731

Epoch: 6| Step: 8
Training loss: 2.5684432911671236
Validation loss: 2.487153137406773

Epoch: 6| Step: 9
Training loss: 3.145735042291202
Validation loss: 2.48562943879325

Epoch: 6| Step: 10
Training loss: 2.1437680079646344
Validation loss: 2.4879720786235966

Epoch: 6| Step: 11
Training loss: 2.4193279039257716
Validation loss: 2.4849801276248367

Epoch: 6| Step: 12
Training loss: 3.222707741065915
Validation loss: 2.4900579173081643

Epoch: 6| Step: 13
Training loss: 2.994534122615942
Validation loss: 2.4810858652195504

Epoch: 114| Step: 0
Training loss: 2.6670530655183393
Validation loss: 2.473608210366393

Epoch: 6| Step: 1
Training loss: 1.6563727855153705
Validation loss: 2.4578285237780433

Epoch: 6| Step: 2
Training loss: 2.875576459064135
Validation loss: 2.459990538201576

Epoch: 6| Step: 3
Training loss: 2.443347177696124
Validation loss: 2.4600587274938186

Epoch: 6| Step: 4
Training loss: 2.6826348736391417
Validation loss: 2.459214445929951

Epoch: 6| Step: 5
Training loss: 2.4593029588474855
Validation loss: 2.4646941400052143

Epoch: 6| Step: 6
Training loss: 2.885828275735778
Validation loss: 2.464930271377281

Epoch: 6| Step: 7
Training loss: 2.483357443041756
Validation loss: 2.464930013445883

Epoch: 6| Step: 8
Training loss: 3.068718649399114
Validation loss: 2.4559366590934726

Epoch: 6| Step: 9
Training loss: 2.4108700676695154
Validation loss: 2.4624022792009543

Epoch: 6| Step: 10
Training loss: 2.442411316556981
Validation loss: 2.4641111789588552

Epoch: 6| Step: 11
Training loss: 2.2521433687868444
Validation loss: 2.461699917679977

Epoch: 6| Step: 12
Training loss: 2.2821325397833894
Validation loss: 2.4581290715159057

Epoch: 6| Step: 13
Training loss: 2.5942737096589177
Validation loss: 2.4644892014891013

Epoch: 115| Step: 0
Training loss: 2.9315290436168864
Validation loss: 2.4616567297390346

Epoch: 6| Step: 1
Training loss: 1.8425812977384837
Validation loss: 2.4599009596521992

Epoch: 6| Step: 2
Training loss: 2.1439811960007793
Validation loss: 2.4578865636687306

Epoch: 6| Step: 3
Training loss: 2.2216556489084125
Validation loss: 2.456087692372671

Epoch: 6| Step: 4
Training loss: 2.2727620278215275
Validation loss: 2.456726055264203

Epoch: 6| Step: 5
Training loss: 2.516368874453206
Validation loss: 2.4534626139219236

Epoch: 6| Step: 6
Training loss: 2.546836057025891
Validation loss: 2.45822294170564

Epoch: 6| Step: 7
Training loss: 2.2812209454084056
Validation loss: 2.461854842433447

Epoch: 6| Step: 8
Training loss: 2.71685321456006
Validation loss: 2.4631585003964642

Epoch: 6| Step: 9
Training loss: 2.3147156900445736
Validation loss: 2.462570205888256

Epoch: 6| Step: 10
Training loss: 2.3096710634737048
Validation loss: 2.458940468725165

Epoch: 6| Step: 11
Training loss: 2.8461605377277217
Validation loss: 2.4610764075741844

Epoch: 6| Step: 12
Training loss: 3.136086900285542
Validation loss: 2.4568272573172822

Epoch: 6| Step: 13
Training loss: 2.9887643859848905
Validation loss: 2.455887731056017

Epoch: 116| Step: 0
Training loss: 2.3090811536032643
Validation loss: 2.4628314445498516

Epoch: 6| Step: 1
Training loss: 2.90667918327973
Validation loss: 2.461527573016198

Epoch: 6| Step: 2
Training loss: 2.1671150794989518
Validation loss: 2.4600433016793612

Epoch: 6| Step: 3
Training loss: 2.5512383651655
Validation loss: 2.46638104701102

Epoch: 6| Step: 4
Training loss: 3.1844054515457016
Validation loss: 2.4649819538366353

Epoch: 6| Step: 5
Training loss: 2.3980567455943014
Validation loss: 2.45741462243584

Epoch: 6| Step: 6
Training loss: 2.4853035013464515
Validation loss: 2.458061467240472

Epoch: 6| Step: 7
Training loss: 2.505601330000913
Validation loss: 2.4568587153129657

Epoch: 6| Step: 8
Training loss: 2.5378178289400015
Validation loss: 2.46542836715847

Epoch: 6| Step: 9
Training loss: 2.2416191842913045
Validation loss: 2.4653442648457364

Epoch: 6| Step: 10
Training loss: 2.3997619153186056
Validation loss: 2.4732627506501323

Epoch: 6| Step: 11
Training loss: 2.4257475379161573
Validation loss: 2.4675444786213916

Epoch: 6| Step: 12
Training loss: 2.6881819458645775
Validation loss: 2.4653066290180545

Epoch: 6| Step: 13
Training loss: 2.468316341893735
Validation loss: 2.4616983115638007

Epoch: 117| Step: 0
Training loss: 2.3391863324469244
Validation loss: 2.4555554508863207

Epoch: 6| Step: 1
Training loss: 2.219765444212369
Validation loss: 2.4655082278527276

Epoch: 6| Step: 2
Training loss: 2.745788123106404
Validation loss: 2.4669242900482367

Epoch: 6| Step: 3
Training loss: 2.891446878250343
Validation loss: 2.4689083611925726

Epoch: 6| Step: 4
Training loss: 2.6286149338267317
Validation loss: 2.4703333642067644

Epoch: 6| Step: 5
Training loss: 2.7846244314965176
Validation loss: 2.4765105939012493

Epoch: 6| Step: 6
Training loss: 2.4680080989105044
Validation loss: 2.4679492826902574

Epoch: 6| Step: 7
Training loss: 1.6632934369186794
Validation loss: 2.4554578699365885

Epoch: 6| Step: 8
Training loss: 2.8166610454375327
Validation loss: 2.45541221755051

Epoch: 6| Step: 9
Training loss: 2.699928643025441
Validation loss: 2.457262280008026

Epoch: 6| Step: 10
Training loss: 2.4221447209938707
Validation loss: 2.4546973176659077

Epoch: 6| Step: 11
Training loss: 2.966704296202019
Validation loss: 2.4467939412935698

Epoch: 6| Step: 12
Training loss: 2.3545711698697778
Validation loss: 2.4492364017838124

Epoch: 6| Step: 13
Training loss: 2.2238559267526483
Validation loss: 2.461176889876183

Epoch: 118| Step: 0
Training loss: 2.819293569861561
Validation loss: 2.460827795742206

Epoch: 6| Step: 1
Training loss: 1.8307040028766752
Validation loss: 2.458736666766218

Epoch: 6| Step: 2
Training loss: 2.2742271493948616
Validation loss: 2.4607196368304884

Epoch: 6| Step: 3
Training loss: 2.2403447357638284
Validation loss: 2.4602352533044827

Epoch: 6| Step: 4
Training loss: 2.9662606493681962
Validation loss: 2.4679393000554817

Epoch: 6| Step: 5
Training loss: 1.9965075756285615
Validation loss: 2.4629411724972914

Epoch: 6| Step: 6
Training loss: 2.2138130171264656
Validation loss: 2.4769020609917907

Epoch: 6| Step: 7
Training loss: 2.9359730749324857
Validation loss: 2.4775835212925656

Epoch: 6| Step: 8
Training loss: 2.363973216749047
Validation loss: 2.479475937046738

Epoch: 6| Step: 9
Training loss: 2.9968874997702692
Validation loss: 2.4743581562540085

Epoch: 6| Step: 10
Training loss: 2.3587346502713324
Validation loss: 2.4743452044044676

Epoch: 6| Step: 11
Training loss: 3.0131746921583997
Validation loss: 2.479457939625586

Epoch: 6| Step: 12
Training loss: 1.9890957646011904
Validation loss: 2.476694033365865

Epoch: 6| Step: 13
Training loss: 3.1805454755583558
Validation loss: 2.47115120625481

Epoch: 119| Step: 0
Training loss: 2.1340583264746766
Validation loss: 2.467693545446266

Epoch: 6| Step: 1
Training loss: 2.5486614304326687
Validation loss: 2.452968746319514

Epoch: 6| Step: 2
Training loss: 2.3314332946227285
Validation loss: 2.4580260801387963

Epoch: 6| Step: 3
Training loss: 2.731434663513832
Validation loss: 2.4624489477193854

Epoch: 6| Step: 4
Training loss: 2.4825899440917283
Validation loss: 2.465986064715792

Epoch: 6| Step: 5
Training loss: 1.9561947312027752
Validation loss: 2.466678152401276

Epoch: 6| Step: 6
Training loss: 2.9560312976548206
Validation loss: 2.4701185175612426

Epoch: 6| Step: 7
Training loss: 2.874200295059585
Validation loss: 2.4866023285786483

Epoch: 6| Step: 8
Training loss: 2.320594642002923
Validation loss: 2.4832498253685578

Epoch: 6| Step: 9
Training loss: 2.4366920305837585
Validation loss: 2.48236185557043

Epoch: 6| Step: 10
Training loss: 2.581673971091523
Validation loss: 2.464142681035622

Epoch: 6| Step: 11
Training loss: 2.4480081635818993
Validation loss: 2.4617209665830644

Epoch: 6| Step: 12
Training loss: 2.9574482269785873
Validation loss: 2.4548543839734926

Epoch: 6| Step: 13
Training loss: 2.5493580702069676
Validation loss: 2.4575442459376537

Epoch: 120| Step: 0
Training loss: 2.6376469539543828
Validation loss: 2.4672529212309984

Epoch: 6| Step: 1
Training loss: 3.0329270590322737
Validation loss: 2.465407027556188

Epoch: 6| Step: 2
Training loss: 2.9399523947877393
Validation loss: 2.4738747324956005

Epoch: 6| Step: 3
Training loss: 2.0221289450170774
Validation loss: 2.470572929319329

Epoch: 6| Step: 4
Training loss: 1.868084105691414
Validation loss: 2.463851704890911

Epoch: 6| Step: 5
Training loss: 1.8601431021452017
Validation loss: 2.4699928519239482

Epoch: 6| Step: 6
Training loss: 2.402612885076809
Validation loss: 2.472692866001536

Epoch: 6| Step: 7
Training loss: 2.9459885041529885
Validation loss: 2.465240406296368

Epoch: 6| Step: 8
Training loss: 2.222668800251529
Validation loss: 2.464226904984125

Epoch: 6| Step: 9
Training loss: 2.6164527886649322
Validation loss: 2.468452322996245

Epoch: 6| Step: 10
Training loss: 2.8497328649775926
Validation loss: 2.4635140469207837

Epoch: 6| Step: 11
Training loss: 2.5177961185562063
Validation loss: 2.4552618548246206

Epoch: 6| Step: 12
Training loss: 3.0956193304905306
Validation loss: 2.459098686003403

Epoch: 6| Step: 13
Training loss: 2.3167191241063296
Validation loss: 2.4603937507055336

Epoch: 121| Step: 0
Training loss: 2.9680615078498427
Validation loss: 2.4629876694705537

Epoch: 6| Step: 1
Training loss: 2.152213257089478
Validation loss: 2.4593242625488636

Epoch: 6| Step: 2
Training loss: 2.636336416145838
Validation loss: 2.457324683169855

Epoch: 6| Step: 3
Training loss: 2.582837600724503
Validation loss: 2.456236694144592

Epoch: 6| Step: 4
Training loss: 2.2440915413610694
Validation loss: 2.461373297640016

Epoch: 6| Step: 5
Training loss: 3.0073944197567246
Validation loss: 2.457216661145905

Epoch: 6| Step: 6
Training loss: 2.7238000029919283
Validation loss: 2.467459152048477

Epoch: 6| Step: 7
Training loss: 2.358559574916991
Validation loss: 2.47388936532242

Epoch: 6| Step: 8
Training loss: 2.691135077248595
Validation loss: 2.478456400791712

Epoch: 6| Step: 9
Training loss: 2.4612680364580446
Validation loss: 2.4706832945257786

Epoch: 6| Step: 10
Training loss: 2.0135293164559434
Validation loss: 2.466673802889562

Epoch: 6| Step: 11
Training loss: 2.49224872573696
Validation loss: 2.4643515988737694

Epoch: 6| Step: 12
Training loss: 2.8524252226620956
Validation loss: 2.455432203722604

Epoch: 6| Step: 13
Training loss: 2.10447881920058
Validation loss: 2.4601828735112687

Epoch: 122| Step: 0
Training loss: 2.090470891954696
Validation loss: 2.460731909505085

Epoch: 6| Step: 1
Training loss: 1.8815641578118345
Validation loss: 2.45883807695734

Epoch: 6| Step: 2
Training loss: 2.6431412304812656
Validation loss: 2.457091378758415

Epoch: 6| Step: 3
Training loss: 2.7425678565394493
Validation loss: 2.4578764754964455

Epoch: 6| Step: 4
Training loss: 2.0248558935058396
Validation loss: 2.4534370726009764

Epoch: 6| Step: 5
Training loss: 2.5694216775887884
Validation loss: 2.4525504603689035

Epoch: 6| Step: 6
Training loss: 2.694624041659822
Validation loss: 2.4539552567316947

Epoch: 6| Step: 7
Training loss: 2.514378778017199
Validation loss: 2.461096363894117

Epoch: 6| Step: 8
Training loss: 2.469394937607113
Validation loss: 2.4525740018847273

Epoch: 6| Step: 9
Training loss: 2.8736429743605583
Validation loss: 2.447610679061812

Epoch: 6| Step: 10
Training loss: 2.39193809200793
Validation loss: 2.4516135741068563

Epoch: 6| Step: 11
Training loss: 2.5651631356575786
Validation loss: 2.4515538620902984

Epoch: 6| Step: 12
Training loss: 2.655202412190251
Validation loss: 2.4545048034397166

Epoch: 6| Step: 13
Training loss: 2.9470069119489195
Validation loss: 2.455728174224901

Epoch: 123| Step: 0
Training loss: 2.477053043147129
Validation loss: 2.4646178160636225

Epoch: 6| Step: 1
Training loss: 2.323471949513702
Validation loss: 2.451216828236736

Epoch: 6| Step: 2
Training loss: 2.901454291228686
Validation loss: 2.4662026006387965

Epoch: 6| Step: 3
Training loss: 2.8547322253569094
Validation loss: 2.456554356453016

Epoch: 6| Step: 4
Training loss: 2.6057482888308443
Validation loss: 2.462529324584476

Epoch: 6| Step: 5
Training loss: 2.434762444471892
Validation loss: 2.461445072852432

Epoch: 6| Step: 6
Training loss: 2.059360079211999
Validation loss: 2.456139269687539

Epoch: 6| Step: 7
Training loss: 2.505979920102081
Validation loss: 2.457978923487903

Epoch: 6| Step: 8
Training loss: 2.208994736381535
Validation loss: 2.4623261262856975

Epoch: 6| Step: 9
Training loss: 3.3319761533307446
Validation loss: 2.4592022222363483

Epoch: 6| Step: 10
Training loss: 1.8783084925735511
Validation loss: 2.4641217657011985

Epoch: 6| Step: 11
Training loss: 2.2701519168316433
Validation loss: 2.4594526544418622

Epoch: 6| Step: 12
Training loss: 2.590763440821803
Validation loss: 2.454616838130587

Epoch: 6| Step: 13
Training loss: 2.6572198331467987
Validation loss: 2.459391161596118

Epoch: 124| Step: 0
Training loss: 2.1064207511534567
Validation loss: 2.45641702111621

Epoch: 6| Step: 1
Training loss: 2.5118271491359097
Validation loss: 2.458157409149118

Epoch: 6| Step: 2
Training loss: 2.1739073102294952
Validation loss: 2.453397861216055

Epoch: 6| Step: 3
Training loss: 2.3930187333454143
Validation loss: 2.4531385741293597

Epoch: 6| Step: 4
Training loss: 2.306037016340727
Validation loss: 2.4556561833711896

Epoch: 6| Step: 5
Training loss: 2.503979757720736
Validation loss: 2.452841481146819

Epoch: 6| Step: 6
Training loss: 2.174330277209152
Validation loss: 2.4543733761254813

Epoch: 6| Step: 7
Training loss: 2.3759065203018594
Validation loss: 2.4577496988850362

Epoch: 6| Step: 8
Training loss: 2.596261887869803
Validation loss: 2.4532352916764224

Epoch: 6| Step: 9
Training loss: 3.023920853492372
Validation loss: 2.4583296829670673

Epoch: 6| Step: 10
Training loss: 2.9179167838620663
Validation loss: 2.4511710320176174

Epoch: 6| Step: 11
Training loss: 2.705071602823816
Validation loss: 2.45705368120702

Epoch: 6| Step: 12
Training loss: 2.9240182777804153
Validation loss: 2.455838818224152

Epoch: 6| Step: 13
Training loss: 2.2705561150776057
Validation loss: 2.448139932609791

Epoch: 125| Step: 0
Training loss: 2.4802633365672047
Validation loss: 2.4558687194028357

Epoch: 6| Step: 1
Training loss: 2.54414267918407
Validation loss: 2.4572091899860395

Epoch: 6| Step: 2
Training loss: 2.7781738242631695
Validation loss: 2.454929004349636

Epoch: 6| Step: 3
Training loss: 2.1469543886567912
Validation loss: 2.45286116426492

Epoch: 6| Step: 4
Training loss: 2.0874496865062566
Validation loss: 2.450882682610426

Epoch: 6| Step: 5
Training loss: 2.60525644515459
Validation loss: 2.4500950042314122

Epoch: 6| Step: 6
Training loss: 2.7598730931614313
Validation loss: 2.4512175171998716

Epoch: 6| Step: 7
Training loss: 2.3770437983424455
Validation loss: 2.455316006534677

Epoch: 6| Step: 8
Training loss: 2.0785083847335604
Validation loss: 2.459620952142956

Epoch: 6| Step: 9
Training loss: 2.3142898437590986
Validation loss: 2.4705320035154337

Epoch: 6| Step: 10
Training loss: 2.6560398691873295
Validation loss: 2.4822627671117985

Epoch: 6| Step: 11
Training loss: 3.270113110467132
Validation loss: 2.466405197625051

Epoch: 6| Step: 12
Training loss: 2.2205410028359935
Validation loss: 2.462629771806983

Epoch: 6| Step: 13
Training loss: 2.767826906381865
Validation loss: 2.454165827087708

Epoch: 126| Step: 0
Training loss: 2.470525561801309
Validation loss: 2.4636723575780075

Epoch: 6| Step: 1
Training loss: 2.540188302096406
Validation loss: 2.4613115137465256

Epoch: 6| Step: 2
Training loss: 3.05092723072234
Validation loss: 2.470341985994229

Epoch: 6| Step: 3
Training loss: 2.5393310404865908
Validation loss: 2.4724032898886814

Epoch: 6| Step: 4
Training loss: 2.5194761758152207
Validation loss: 2.4854786338872623

Epoch: 6| Step: 5
Training loss: 2.9465717891878844
Validation loss: 2.4839376228525163

Epoch: 6| Step: 6
Training loss: 2.610100559621305
Validation loss: 2.486125992766534

Epoch: 6| Step: 7
Training loss: 2.5520791086174905
Validation loss: 2.4800986667202336

Epoch: 6| Step: 8
Training loss: 2.771692377071755
Validation loss: 2.4701474737242735

Epoch: 6| Step: 9
Training loss: 1.932037281932431
Validation loss: 2.4779200157637664

Epoch: 6| Step: 10
Training loss: 2.660873428442466
Validation loss: 2.479595489173015

Epoch: 6| Step: 11
Training loss: 2.6794681737354673
Validation loss: 2.4676784169509354

Epoch: 6| Step: 12
Training loss: 1.992567796499035
Validation loss: 2.4637745484384403

Epoch: 6| Step: 13
Training loss: 2.3181318831887987
Validation loss: 2.463425007827612

Epoch: 127| Step: 0
Training loss: 2.7412325943491225
Validation loss: 2.4615102757351726

Epoch: 6| Step: 1
Training loss: 2.1345359909086508
Validation loss: 2.4522664213794494

Epoch: 6| Step: 2
Training loss: 2.4549338117017383
Validation loss: 2.4587861926322923

Epoch: 6| Step: 3
Training loss: 1.9756642588667306
Validation loss: 2.4536265449734778

Epoch: 6| Step: 4
Training loss: 2.704451571730026
Validation loss: 2.461135404187994

Epoch: 6| Step: 5
Training loss: 1.9308296560955744
Validation loss: 2.4565151139471255

Epoch: 6| Step: 6
Training loss: 1.9954425623003278
Validation loss: 2.4689555987926988

Epoch: 6| Step: 7
Training loss: 2.579386269665171
Validation loss: 2.473211916036587

Epoch: 6| Step: 8
Training loss: 2.570246826074928
Validation loss: 2.46993991487861

Epoch: 6| Step: 9
Training loss: 2.99892199539442
Validation loss: 2.477849888453139

Epoch: 6| Step: 10
Training loss: 3.121331617627276
Validation loss: 2.475887507442264

Epoch: 6| Step: 11
Training loss: 2.871978830944878
Validation loss: 2.473478866427233

Epoch: 6| Step: 12
Training loss: 2.495893730065402
Validation loss: 2.470692912245238

Epoch: 6| Step: 13
Training loss: 2.570435865972279
Validation loss: 2.4666488172125876

Epoch: 128| Step: 0
Training loss: 2.0516027930342027
Validation loss: 2.462190984968874

Epoch: 6| Step: 1
Training loss: 2.7032797884861357
Validation loss: 2.459324545304372

Epoch: 6| Step: 2
Training loss: 2.7790207233074944
Validation loss: 2.461574540615074

Epoch: 6| Step: 3
Training loss: 3.1538599615170537
Validation loss: 2.4648300629974833

Epoch: 6| Step: 4
Training loss: 2.4453437973798353
Validation loss: 2.4662239091888063

Epoch: 6| Step: 5
Training loss: 2.394088529946458
Validation loss: 2.4661614572955917

Epoch: 6| Step: 6
Training loss: 2.0630267077597253
Validation loss: 2.465129112333973

Epoch: 6| Step: 7
Training loss: 2.643453223342574
Validation loss: 2.4639166021765595

Epoch: 6| Step: 8
Training loss: 2.977598795881238
Validation loss: 2.4632167373373535

Epoch: 6| Step: 9
Training loss: 2.2851809769295204
Validation loss: 2.4681616939271596

Epoch: 6| Step: 10
Training loss: 2.2705722857109554
Validation loss: 2.4614935675601624

Epoch: 6| Step: 11
Training loss: 2.125104565011201
Validation loss: 2.4608676395894915

Epoch: 6| Step: 12
Training loss: 2.753754220648469
Validation loss: 2.460884432750316

Epoch: 6| Step: 13
Training loss: 2.3071777338583113
Validation loss: 2.4575895434261845

Epoch: 129| Step: 0
Training loss: 2.753665388680139
Validation loss: 2.455160410211975

Epoch: 6| Step: 1
Training loss: 2.052126140115731
Validation loss: 2.4607371253732544

Epoch: 6| Step: 2
Training loss: 3.0452388184951804
Validation loss: 2.4597826634778577

Epoch: 6| Step: 3
Training loss: 2.7924852926469743
Validation loss: 2.4636245186700236

Epoch: 6| Step: 4
Training loss: 2.3211888158044625
Validation loss: 2.4552088105615715

Epoch: 6| Step: 5
Training loss: 2.2748491551620416
Validation loss: 2.4556417978925356

Epoch: 6| Step: 6
Training loss: 2.805973363889947
Validation loss: 2.452290824423539

Epoch: 6| Step: 7
Training loss: 2.833608127806782
Validation loss: 2.4573330433590588

Epoch: 6| Step: 8
Training loss: 2.2840579792687254
Validation loss: 2.457197465717512

Epoch: 6| Step: 9
Training loss: 2.5995237134294675
Validation loss: 2.46205059088059

Epoch: 6| Step: 10
Training loss: 2.307659960789047
Validation loss: 2.452458503714281

Epoch: 6| Step: 11
Training loss: 2.889343472522689
Validation loss: 2.4586490546900373

Epoch: 6| Step: 12
Training loss: 1.7731507191290319
Validation loss: 2.4527656308146124

Epoch: 6| Step: 13
Training loss: 2.1825755685000083
Validation loss: 2.4547018502777314

Epoch: 130| Step: 0
Training loss: 2.8133904636903995
Validation loss: 2.456562508980706

Epoch: 6| Step: 1
Training loss: 2.3019226041123724
Validation loss: 2.4619921488157686

Epoch: 6| Step: 2
Training loss: 3.112277875580698
Validation loss: 2.4559842109048393

Epoch: 6| Step: 3
Training loss: 2.247734412676284
Validation loss: 2.451079826095763

Epoch: 6| Step: 4
Training loss: 2.725698689472972
Validation loss: 2.4524434270630056

Epoch: 6| Step: 5
Training loss: 1.5014048196843552
Validation loss: 2.4600761722773914

Epoch: 6| Step: 6
Training loss: 3.06210527017082
Validation loss: 2.453585263625275

Epoch: 6| Step: 7
Training loss: 2.5587793646889923
Validation loss: 2.456149364995071

Epoch: 6| Step: 8
Training loss: 2.2461885382512614
Validation loss: 2.460309968896429

Epoch: 6| Step: 9
Training loss: 2.3739262211429772
Validation loss: 2.4528740432567098

Epoch: 6| Step: 10
Training loss: 2.2717031043925693
Validation loss: 2.452363189526238

Epoch: 6| Step: 11
Training loss: 2.497393202689134
Validation loss: 2.4599447518634356

Epoch: 6| Step: 12
Training loss: 2.306906456289741
Validation loss: 2.464092206564227

Epoch: 6| Step: 13
Training loss: 2.7831111210122126
Validation loss: 2.4557447679063857

Epoch: 131| Step: 0
Training loss: 2.3063123244881507
Validation loss: 2.4604360725569947

Epoch: 6| Step: 1
Training loss: 1.9011645412362403
Validation loss: 2.4655920022449416

Epoch: 6| Step: 2
Training loss: 2.8436896349190595
Validation loss: 2.463164396747724

Epoch: 6| Step: 3
Training loss: 3.0073108601571503
Validation loss: 2.4648008992721864

Epoch: 6| Step: 4
Training loss: 2.3926899288290615
Validation loss: 2.461267713564058

Epoch: 6| Step: 5
Training loss: 2.5589274181583557
Validation loss: 2.449086909216093

Epoch: 6| Step: 6
Training loss: 2.72901976289509
Validation loss: 2.466927954542973

Epoch: 6| Step: 7
Training loss: 2.0919003643575893
Validation loss: 2.459937240528851

Epoch: 6| Step: 8
Training loss: 2.4085943518386372
Validation loss: 2.4506298099059736

Epoch: 6| Step: 9
Training loss: 2.5722466238561204
Validation loss: 2.4513734367347078

Epoch: 6| Step: 10
Training loss: 2.4002554399929137
Validation loss: 2.460703084771094

Epoch: 6| Step: 11
Training loss: 2.820417830172574
Validation loss: 2.458891762061762

Epoch: 6| Step: 12
Training loss: 2.3471935152584433
Validation loss: 2.457646651188528

Epoch: 6| Step: 13
Training loss: 2.4832010434477865
Validation loss: 2.458683366155422

Epoch: 132| Step: 0
Training loss: 2.356883166816702
Validation loss: 2.458342783850484

Epoch: 6| Step: 1
Training loss: 2.380886712985223
Validation loss: 2.460084603878441

Epoch: 6| Step: 2
Training loss: 2.305724864191959
Validation loss: 2.4597403223065943

Epoch: 6| Step: 3
Training loss: 2.6654323065496035
Validation loss: 2.4555632507218985

Epoch: 6| Step: 4
Training loss: 2.4746461788773613
Validation loss: 2.4646776307597933

Epoch: 6| Step: 5
Training loss: 2.2477299577058973
Validation loss: 2.4641850916930808

Epoch: 6| Step: 6
Training loss: 2.3357982785382947
Validation loss: 2.4726579373852604

Epoch: 6| Step: 7
Training loss: 2.47348322003751
Validation loss: 2.482295639626134

Epoch: 6| Step: 8
Training loss: 2.1404728522144105
Validation loss: 2.4751657745124773

Epoch: 6| Step: 9
Training loss: 3.010270815861367
Validation loss: 2.4759365217271205

Epoch: 6| Step: 10
Training loss: 3.1002222043047905
Validation loss: 2.4635089659721583

Epoch: 6| Step: 11
Training loss: 2.66945391267475
Validation loss: 2.4619026753778743

Epoch: 6| Step: 12
Training loss: 2.3756340585890685
Validation loss: 2.4579316365993837

Epoch: 6| Step: 13
Training loss: 2.4733224366077398
Validation loss: 2.4578522006621935

Epoch: 133| Step: 0
Training loss: 2.6730310270404636
Validation loss: 2.461252206530469

Epoch: 6| Step: 1
Training loss: 2.430854247374523
Validation loss: 2.4671879909096943

Epoch: 6| Step: 2
Training loss: 2.107755590395911
Validation loss: 2.4577916944123963

Epoch: 6| Step: 3
Training loss: 2.73579901535939
Validation loss: 2.468430252937058

Epoch: 6| Step: 4
Training loss: 2.6514215003645147
Validation loss: 2.459004396776734

Epoch: 6| Step: 5
Training loss: 2.6749908839275434
Validation loss: 2.4637258405708913

Epoch: 6| Step: 6
Training loss: 2.338616407484344
Validation loss: 2.464404083552458

Epoch: 6| Step: 7
Training loss: 1.9963945434637906
Validation loss: 2.4545584133370184

Epoch: 6| Step: 8
Training loss: 2.498236033873666
Validation loss: 2.458051800097443

Epoch: 6| Step: 9
Training loss: 2.613690673505107
Validation loss: 2.4578062289821445

Epoch: 6| Step: 10
Training loss: 2.572985155272554
Validation loss: 2.460144431880388

Epoch: 6| Step: 11
Training loss: 2.6225671847949727
Validation loss: 2.4586984530283273

Epoch: 6| Step: 12
Training loss: 2.250711540458815
Validation loss: 2.457135390847766

Epoch: 6| Step: 13
Training loss: 2.775811439304898
Validation loss: 2.4646722458843424

Epoch: 134| Step: 0
Training loss: 2.4081753050843933
Validation loss: 2.4537343039960406

Epoch: 6| Step: 1
Training loss: 1.9767928761957885
Validation loss: 2.4644388631062455

Epoch: 6| Step: 2
Training loss: 2.7950671442800683
Validation loss: 2.458256806513307

Epoch: 6| Step: 3
Training loss: 2.0821249191083546
Validation loss: 2.457893628598067

Epoch: 6| Step: 4
Training loss: 2.953162944893044
Validation loss: 2.457327674730188

Epoch: 6| Step: 5
Training loss: 2.784489320405388
Validation loss: 2.4583735920686136

Epoch: 6| Step: 6
Training loss: 1.8149940825857165
Validation loss: 2.4555524733491927

Epoch: 6| Step: 7
Training loss: 2.4035729713734595
Validation loss: 2.4577536034080194

Epoch: 6| Step: 8
Training loss: 2.9186398144330936
Validation loss: 2.4603101304062753

Epoch: 6| Step: 9
Training loss: 2.6125021829550352
Validation loss: 2.4603722140059285

Epoch: 6| Step: 10
Training loss: 2.2658359823974896
Validation loss: 2.463394165999977

Epoch: 6| Step: 11
Training loss: 2.9040374537383027
Validation loss: 2.4586619033636317

Epoch: 6| Step: 12
Training loss: 2.3894136638541554
Validation loss: 2.4624874017848244

Epoch: 6| Step: 13
Training loss: 2.436854448175561
Validation loss: 2.4633642271201226

Epoch: 135| Step: 0
Training loss: 2.771281605266281
Validation loss: 2.458201943674111

Epoch: 6| Step: 1
Training loss: 2.975551643837499
Validation loss: 2.4598281378271696

Epoch: 6| Step: 2
Training loss: 2.2521172204822024
Validation loss: 2.454242767509846

Epoch: 6| Step: 3
Training loss: 2.297612908611854
Validation loss: 2.452266834580424

Epoch: 6| Step: 4
Training loss: 2.782496141018038
Validation loss: 2.463137060466757

Epoch: 6| Step: 5
Training loss: 2.86884777426058
Validation loss: 2.463046071781059

Epoch: 6| Step: 6
Training loss: 2.6240370664537203
Validation loss: 2.4634367347182824

Epoch: 6| Step: 7
Training loss: 2.2583970101964055
Validation loss: 2.463131801283186

Epoch: 6| Step: 8
Training loss: 2.6398337719342906
Validation loss: 2.4600326004685265

Epoch: 6| Step: 9
Training loss: 2.7239716470561994
Validation loss: 2.456125776855951

Epoch: 6| Step: 10
Training loss: 2.5747095777563027
Validation loss: 2.4537290246591352

Epoch: 6| Step: 11
Training loss: 2.2071563415185977
Validation loss: 2.454796215736154

Epoch: 6| Step: 12
Training loss: 2.0799596045312834
Validation loss: 2.455461203611783

Epoch: 6| Step: 13
Training loss: 1.3763784954569538
Validation loss: 2.4688167241089176

Epoch: 136| Step: 0
Training loss: 2.2165428251315356
Validation loss: 2.4608588069868005

Epoch: 6| Step: 1
Training loss: 2.3729838798544485
Validation loss: 2.453621897010163

Epoch: 6| Step: 2
Training loss: 1.9693554144163556
Validation loss: 2.4545666777210227

Epoch: 6| Step: 3
Training loss: 2.204154673533511
Validation loss: 2.4469613233387757

Epoch: 6| Step: 4
Training loss: 3.4194668870759783
Validation loss: 2.4520676555364624

Epoch: 6| Step: 5
Training loss: 3.0479077276245228
Validation loss: 2.4476445689380744

Epoch: 6| Step: 6
Training loss: 2.700055976569991
Validation loss: 2.4572920991822547

Epoch: 6| Step: 7
Training loss: 2.3226941148922258
Validation loss: 2.4495838791527107

Epoch: 6| Step: 8
Training loss: 2.581756531013509
Validation loss: 2.4509038730532264

Epoch: 6| Step: 9
Training loss: 2.5254986261225474
Validation loss: 2.450705369628506

Epoch: 6| Step: 10
Training loss: 2.1801035494228374
Validation loss: 2.4505548640343178

Epoch: 6| Step: 11
Training loss: 2.540650232243726
Validation loss: 2.449595980515599

Epoch: 6| Step: 12
Training loss: 1.967245465576748
Validation loss: 2.4553282252999225

Epoch: 6| Step: 13
Training loss: 2.4812321967343824
Validation loss: 2.463267471721785

Epoch: 137| Step: 0
Training loss: 2.8121825992775946
Validation loss: 2.462172949965392

Epoch: 6| Step: 1
Training loss: 2.0155264660312
Validation loss: 2.4657756093823275

Epoch: 6| Step: 2
Training loss: 2.563421781408716
Validation loss: 2.4704242935959395

Epoch: 6| Step: 3
Training loss: 2.9910084764570284
Validation loss: 2.4761518103773597

Epoch: 6| Step: 4
Training loss: 1.743140605693893
Validation loss: 2.477272421312141

Epoch: 6| Step: 5
Training loss: 2.805120833135138
Validation loss: 2.472041539281961

Epoch: 6| Step: 6
Training loss: 3.3371321171804227
Validation loss: 2.46827543502

Epoch: 6| Step: 7
Training loss: 2.506060311994409
Validation loss: 2.460229002675456

Epoch: 6| Step: 8
Training loss: 1.9862489637656657
Validation loss: 2.4645196587749836

Epoch: 6| Step: 9
Training loss: 2.0302616942902327
Validation loss: 2.4624114612857095

Epoch: 6| Step: 10
Training loss: 2.894027274835653
Validation loss: 2.4652275677315334

Epoch: 6| Step: 11
Training loss: 2.4339971560083105
Validation loss: 2.4592954536315204

Epoch: 6| Step: 12
Training loss: 2.7209400695459185
Validation loss: 2.460905771202331

Epoch: 6| Step: 13
Training loss: 1.91811157440628
Validation loss: 2.4662352038540782

Epoch: 138| Step: 0
Training loss: 1.5063803398753706
Validation loss: 2.4638844762985053

Epoch: 6| Step: 1
Training loss: 2.600740503351206
Validation loss: 2.4657715483523903

Epoch: 6| Step: 2
Training loss: 3.2230879800773877
Validation loss: 2.46412947391758

Epoch: 6| Step: 3
Training loss: 2.212498306015142
Validation loss: 2.45571857880258

Epoch: 6| Step: 4
Training loss: 2.7488947294470085
Validation loss: 2.451226960028034

Epoch: 6| Step: 5
Training loss: 2.198494881841529
Validation loss: 2.4503401237986675

Epoch: 6| Step: 6
Training loss: 2.4291718846609127
Validation loss: 2.456893488464169

Epoch: 6| Step: 7
Training loss: 2.554174155825349
Validation loss: 2.4534062428844536

Epoch: 6| Step: 8
Training loss: 2.0155438547286617
Validation loss: 2.4530814991068426

Epoch: 6| Step: 9
Training loss: 2.8659484015197028
Validation loss: 2.452875225852566

Epoch: 6| Step: 10
Training loss: 2.676305120934793
Validation loss: 2.463271093261892

Epoch: 6| Step: 11
Training loss: 2.742304785847603
Validation loss: 2.4454352497333534

Epoch: 6| Step: 12
Training loss: 2.5561851288041963
Validation loss: 2.4508636969854054

Epoch: 6| Step: 13
Training loss: 2.1528226731517237
Validation loss: 2.4595644072094696

Epoch: 139| Step: 0
Training loss: 3.122235715873886
Validation loss: 2.448745276170854

Epoch: 6| Step: 1
Training loss: 2.6227743613675525
Validation loss: 2.459804439576671

Epoch: 6| Step: 2
Training loss: 2.462057191954541
Validation loss: 2.467520266690905

Epoch: 6| Step: 3
Training loss: 2.2134139678621896
Validation loss: 2.474076283638023

Epoch: 6| Step: 4
Training loss: 1.5749426755615366
Validation loss: 2.4781000797514783

Epoch: 6| Step: 5
Training loss: 2.6457709557897275
Validation loss: 2.4723470694441634

Epoch: 6| Step: 6
Training loss: 2.21739864835962
Validation loss: 2.4699818318454296

Epoch: 6| Step: 7
Training loss: 2.551435074249461
Validation loss: 2.460237708327561

Epoch: 6| Step: 8
Training loss: 3.2216628144450543
Validation loss: 2.4559221296391294

Epoch: 6| Step: 9
Training loss: 2.086992547036989
Validation loss: 2.456808576414574

Epoch: 6| Step: 10
Training loss: 2.8131504578234083
Validation loss: 2.4586385898402305

Epoch: 6| Step: 11
Training loss: 2.5938967008353457
Validation loss: 2.461027387965482

Epoch: 6| Step: 12
Training loss: 2.359522126517856
Validation loss: 2.457940301888743

Epoch: 6| Step: 13
Training loss: 1.9088809508924793
Validation loss: 2.4524472833243833

Epoch: 140| Step: 0
Training loss: 2.1238530373458433
Validation loss: 2.4486536634525575

Epoch: 6| Step: 1
Training loss: 2.297454449489532
Validation loss: 2.465833220495299

Epoch: 6| Step: 2
Training loss: 2.7682956365797255
Validation loss: 2.4615491641787015

Epoch: 6| Step: 3
Training loss: 2.5336796908604895
Validation loss: 2.4583559250736426

Epoch: 6| Step: 4
Training loss: 2.6344625582913146
Validation loss: 2.4600174248602897

Epoch: 6| Step: 5
Training loss: 2.693581376252287
Validation loss: 2.4604014948270274

Epoch: 6| Step: 6
Training loss: 2.89480881898092
Validation loss: 2.464197137476755

Epoch: 6| Step: 7
Training loss: 2.8198485270191433
Validation loss: 2.4538939418927344

Epoch: 6| Step: 8
Training loss: 2.037021477797198
Validation loss: 2.4685821315172367

Epoch: 6| Step: 9
Training loss: 2.712355712709538
Validation loss: 2.469307446216742

Epoch: 6| Step: 10
Training loss: 2.619277620537481
Validation loss: 2.467413061427561

Epoch: 6| Step: 11
Training loss: 2.5026726741457854
Validation loss: 2.4636636640626497

Epoch: 6| Step: 12
Training loss: 2.064689860849949
Validation loss: 2.4678210188607643

Epoch: 6| Step: 13
Training loss: 2.2322264257863726
Validation loss: 2.4662246181279484

Epoch: 141| Step: 0
Training loss: 2.667801635333992
Validation loss: 2.4666978056548814

Epoch: 6| Step: 1
Training loss: 2.139132013856339
Validation loss: 2.4629946875009616

Epoch: 6| Step: 2
Training loss: 2.6156046621609814
Validation loss: 2.4611733701990977

Epoch: 6| Step: 3
Training loss: 2.3401429967306924
Validation loss: 2.4639241175072546

Epoch: 6| Step: 4
Training loss: 2.6496500036045445
Validation loss: 2.4655067128606007

Epoch: 6| Step: 5
Training loss: 2.270417084880848
Validation loss: 2.4558830064716926

Epoch: 6| Step: 6
Training loss: 2.3495543767591642
Validation loss: 2.4618780690070987

Epoch: 6| Step: 7
Training loss: 2.014111445907208
Validation loss: 2.4544932767136554

Epoch: 6| Step: 8
Training loss: 2.285687037714262
Validation loss: 2.4552728600506772

Epoch: 6| Step: 9
Training loss: 2.7720874348016697
Validation loss: 2.4635384837177727

Epoch: 6| Step: 10
Training loss: 3.02412931033584
Validation loss: 2.4598813328641027

Epoch: 6| Step: 11
Training loss: 2.4710267590039123
Validation loss: 2.462011306861719

Epoch: 6| Step: 12
Training loss: 2.6359686794822554
Validation loss: 2.460532826247631

Epoch: 6| Step: 13
Training loss: 2.3088515084530528
Validation loss: 2.469649211476208

Epoch: 142| Step: 0
Training loss: 2.0836685928159255
Validation loss: 2.477225759361639

Epoch: 6| Step: 1
Training loss: 2.819368579597579
Validation loss: 2.4805380984246557

Epoch: 6| Step: 2
Training loss: 2.245937388409354
Validation loss: 2.4766698386821053

Epoch: 6| Step: 3
Training loss: 2.3531057167023013
Validation loss: 2.4834356711463186

Epoch: 6| Step: 4
Training loss: 2.1435146458389944
Validation loss: 2.4886804536930964

Epoch: 6| Step: 5
Training loss: 2.373298838861225
Validation loss: 2.4667237412662826

Epoch: 6| Step: 6
Training loss: 2.542437473004633
Validation loss: 2.4593349345270856

Epoch: 6| Step: 7
Training loss: 2.0617658291002425
Validation loss: 2.4589944586270613

Epoch: 6| Step: 8
Training loss: 2.4087727190974384
Validation loss: 2.4683899596796044

Epoch: 6| Step: 9
Training loss: 2.6726405067727277
Validation loss: 2.469104499956971

Epoch: 6| Step: 10
Training loss: 3.0279882126532125
Validation loss: 2.4608011682279

Epoch: 6| Step: 11
Training loss: 3.0603683215106092
Validation loss: 2.4690135380561884

Epoch: 6| Step: 12
Training loss: 2.3353658633756536
Validation loss: 2.4611456243115297

Epoch: 6| Step: 13
Training loss: 2.3789786091340304
Validation loss: 2.4641987500269944

Epoch: 143| Step: 0
Training loss: 2.538604882890271
Validation loss: 2.4612831962830484

Epoch: 6| Step: 1
Training loss: 2.2489409603444983
Validation loss: 2.462928071873041

Epoch: 6| Step: 2
Training loss: 2.8301239536489526
Validation loss: 2.457823883761044

Epoch: 6| Step: 3
Training loss: 2.41973181617826
Validation loss: 2.4578865960025498

Epoch: 6| Step: 4
Training loss: 2.560709723350533
Validation loss: 2.4486929508072195

Epoch: 6| Step: 5
Training loss: 2.089320151076677
Validation loss: 2.4629495942903694

Epoch: 6| Step: 6
Training loss: 2.3957134272106466
Validation loss: 2.4576083800799657

Epoch: 6| Step: 7
Training loss: 2.3671285791901338
Validation loss: 2.4679214761216883

Epoch: 6| Step: 8
Training loss: 2.6272587821712756
Validation loss: 2.4646968807872076

Epoch: 6| Step: 9
Training loss: 3.1523305899760157
Validation loss: 2.4699239635604497

Epoch: 6| Step: 10
Training loss: 1.681194817867638
Validation loss: 2.4758456021876625

Epoch: 6| Step: 11
Training loss: 2.043714573171067
Validation loss: 2.4635039737283018

Epoch: 6| Step: 12
Training loss: 2.453953888438915
Validation loss: 2.4686951932980143

Epoch: 6| Step: 13
Training loss: 2.8826988632010937
Validation loss: 2.4734036971654287

Epoch: 144| Step: 0
Training loss: 2.0956262181543304
Validation loss: 2.467239320068663

Epoch: 6| Step: 1
Training loss: 3.138114267227184
Validation loss: 2.466085807179877

Epoch: 6| Step: 2
Training loss: 3.1141406779182654
Validation loss: 2.461973571663386

Epoch: 6| Step: 3
Training loss: 2.233236596398959
Validation loss: 2.467878340703106

Epoch: 6| Step: 4
Training loss: 2.260881707189164
Validation loss: 2.4749563727081894

Epoch: 6| Step: 5
Training loss: 2.0798579283024616
Validation loss: 2.4738646613339923

Epoch: 6| Step: 6
Training loss: 2.247302769884928
Validation loss: 2.4728781393167774

Epoch: 6| Step: 7
Training loss: 2.4711409953518824
Validation loss: 2.463200831207072

Epoch: 6| Step: 8
Training loss: 2.2732471504357177
Validation loss: 2.4596551046530952

Epoch: 6| Step: 9
Training loss: 2.5419066477395966
Validation loss: 2.466487411051376

Epoch: 6| Step: 10
Training loss: 2.955266912446947
Validation loss: 2.4554625144245765

Epoch: 6| Step: 11
Training loss: 2.287855331255486
Validation loss: 2.4550114564181587

Epoch: 6| Step: 12
Training loss: 2.6454002947132214
Validation loss: 2.468764969019838

Epoch: 6| Step: 13
Training loss: 1.8793359213630003
Validation loss: 2.4700195814429877

Epoch: 145| Step: 0
Training loss: 2.5510894916288835
Validation loss: 2.4786002262667894

Epoch: 6| Step: 1
Training loss: 2.2012200743738495
Validation loss: 2.459698529676534

Epoch: 6| Step: 2
Training loss: 2.424944501418731
Validation loss: 2.4646843940822025

Epoch: 6| Step: 3
Training loss: 2.3844744780301075
Validation loss: 2.466636944497236

Epoch: 6| Step: 4
Training loss: 2.5973004778690636
Validation loss: 2.473702858566765

Epoch: 6| Step: 5
Training loss: 2.1242011195437103
Validation loss: 2.47377767338244

Epoch: 6| Step: 6
Training loss: 1.9888775424112681
Validation loss: 2.474024710852265

Epoch: 6| Step: 7
Training loss: 2.411918404004008
Validation loss: 2.4764132610164595

Epoch: 6| Step: 8
Training loss: 2.112941298579754
Validation loss: 2.4858664907899106

Epoch: 6| Step: 9
Training loss: 2.658888460113127
Validation loss: 2.4729288120716038

Epoch: 6| Step: 10
Training loss: 3.0838514013051976
Validation loss: 2.47361408180869

Epoch: 6| Step: 11
Training loss: 2.510621396233819
Validation loss: 2.4671460667409244

Epoch: 6| Step: 12
Training loss: 2.6103618834263322
Validation loss: 2.469141369794232

Epoch: 6| Step: 13
Training loss: 2.62887269405358
Validation loss: 2.4591335486708457

Epoch: 146| Step: 0
Training loss: 2.2898361408962304
Validation loss: 2.4537913233496322

Epoch: 6| Step: 1
Training loss: 3.135384053581339
Validation loss: 2.459813825209661

Epoch: 6| Step: 2
Training loss: 2.4195170090785596
Validation loss: 2.4593836485707836

Epoch: 6| Step: 3
Training loss: 2.3761836666057294
Validation loss: 2.4597842304587645

Epoch: 6| Step: 4
Training loss: 2.618352829852283
Validation loss: 2.4570639829977154

Epoch: 6| Step: 5
Training loss: 1.9827606963957483
Validation loss: 2.4579765470403445

Epoch: 6| Step: 6
Training loss: 2.055001586579316
Validation loss: 2.4591814991800884

Epoch: 6| Step: 7
Training loss: 2.4947844460740587
Validation loss: 2.459878481716838

Epoch: 6| Step: 8
Training loss: 2.1439265943031383
Validation loss: 2.4572921638655365

Epoch: 6| Step: 9
Training loss: 2.9365960211452733
Validation loss: 2.4636093813170294

Epoch: 6| Step: 10
Training loss: 1.8123943692701
Validation loss: 2.473039722889213

Epoch: 6| Step: 11
Training loss: 2.862821575908684
Validation loss: 2.485367966393557

Epoch: 6| Step: 12
Training loss: 2.633381677336712
Validation loss: 2.4887770673300817

Epoch: 6| Step: 13
Training loss: 2.567726573660069
Validation loss: 2.4675606224603204

Epoch: 147| Step: 0
Training loss: 2.368602971569163
Validation loss: 2.4681391543763906

Epoch: 6| Step: 1
Training loss: 2.4381224986681787
Validation loss: 2.4611249256918377

Epoch: 6| Step: 2
Training loss: 2.5062935765918226
Validation loss: 2.4551939773841194

Epoch: 6| Step: 3
Training loss: 1.941479441684962
Validation loss: 2.4623977123516743

Epoch: 6| Step: 4
Training loss: 3.3323208860781954
Validation loss: 2.4605978675892164

Epoch: 6| Step: 5
Training loss: 2.1047939712565666
Validation loss: 2.459446094847391

Epoch: 6| Step: 6
Training loss: 2.548604272826881
Validation loss: 2.4628288146331605

Epoch: 6| Step: 7
Training loss: 2.3792499863910264
Validation loss: 2.4619401937689527

Epoch: 6| Step: 8
Training loss: 2.8083587675518165
Validation loss: 2.460108929370091

Epoch: 6| Step: 9
Training loss: 2.8272420442728805
Validation loss: 2.4641158797038343

Epoch: 6| Step: 10
Training loss: 1.7106895092865997
Validation loss: 2.471061252376686

Epoch: 6| Step: 11
Training loss: 2.742939555187439
Validation loss: 2.466313088910846

Epoch: 6| Step: 12
Training loss: 2.525805233512022
Validation loss: 2.469144588435695

Epoch: 6| Step: 13
Training loss: 1.8696365575466969
Validation loss: 2.4712252862981234

Epoch: 148| Step: 0
Training loss: 2.6169378816362405
Validation loss: 2.4657393660651405

Epoch: 6| Step: 1
Training loss: 2.5319954987014364
Validation loss: 2.471733608132465

Epoch: 6| Step: 2
Training loss: 2.379330151002223
Validation loss: 2.4594891519645263

Epoch: 6| Step: 3
Training loss: 2.1436060732024234
Validation loss: 2.4611304152023217

Epoch: 6| Step: 4
Training loss: 2.303273740440089
Validation loss: 2.4587861683908003

Epoch: 6| Step: 5
Training loss: 2.4510965890455165
Validation loss: 2.4658186526654893

Epoch: 6| Step: 6
Training loss: 2.3424669950230284
Validation loss: 2.4646869333462527

Epoch: 6| Step: 7
Training loss: 2.566966838953869
Validation loss: 2.4599996727527103

Epoch: 6| Step: 8
Training loss: 2.9623961869089843
Validation loss: 2.4688319663431986

Epoch: 6| Step: 9
Training loss: 2.6971304691823397
Validation loss: 2.475360646928414

Epoch: 6| Step: 10
Training loss: 2.142804004373631
Validation loss: 2.4671093764689105

Epoch: 6| Step: 11
Training loss: 2.313727800375082
Validation loss: 2.4797651759871404

Epoch: 6| Step: 12
Training loss: 2.5021212161772532
Validation loss: 2.4793502568673165

Epoch: 6| Step: 13
Training loss: 2.480126064388173
Validation loss: 2.477781811907135

Epoch: 149| Step: 0
Training loss: 2.3969521163212693
Validation loss: 2.478032715639703

Epoch: 6| Step: 1
Training loss: 1.991984577689927
Validation loss: 2.4610259186538386

Epoch: 6| Step: 2
Training loss: 2.397159795241723
Validation loss: 2.4589581799999296

Epoch: 6| Step: 3
Training loss: 2.575775648162461
Validation loss: 2.4696549153421863

Epoch: 6| Step: 4
Training loss: 2.63399236938947
Validation loss: 2.4666978620369413

Epoch: 6| Step: 5
Training loss: 2.7273802309811743
Validation loss: 2.4642901153999026

Epoch: 6| Step: 6
Training loss: 2.1661021401934137
Validation loss: 2.473122245986918

Epoch: 6| Step: 7
Training loss: 2.5167058672178246
Validation loss: 2.4736918791114184

Epoch: 6| Step: 8
Training loss: 2.036143702196599
Validation loss: 2.463134721260727

Epoch: 6| Step: 9
Training loss: 2.1193589902254555
Validation loss: 2.472905721428636

Epoch: 6| Step: 10
Training loss: 2.906489700769
Validation loss: 2.4760372435182942

Epoch: 6| Step: 11
Training loss: 2.3151329104538267
Validation loss: 2.4681703876988768

Epoch: 6| Step: 12
Training loss: 2.448722046735891
Validation loss: 2.481666335914373

Epoch: 6| Step: 13
Training loss: 3.0848600027508972
Validation loss: 2.472812400575865

Epoch: 150| Step: 0
Training loss: 2.5545924924396846
Validation loss: 2.4843993755560283

Epoch: 6| Step: 1
Training loss: 2.3024904285277525
Validation loss: 2.473673662906827

Epoch: 6| Step: 2
Training loss: 2.132196917445287
Validation loss: 2.470057081111235

Epoch: 6| Step: 3
Training loss: 2.344931342903175
Validation loss: 2.4730724850171466

Epoch: 6| Step: 4
Training loss: 2.24952586794511
Validation loss: 2.4671878459560546

Epoch: 6| Step: 5
Training loss: 2.1146894406410808
Validation loss: 2.4693763678709537

Epoch: 6| Step: 6
Training loss: 2.522944351997798
Validation loss: 2.476663164244991

Epoch: 6| Step: 7
Training loss: 2.620225742748637
Validation loss: 2.465934274387985

Epoch: 6| Step: 8
Training loss: 2.845774171213331
Validation loss: 2.47020406595626

Epoch: 6| Step: 9
Training loss: 2.2434755672844306
Validation loss: 2.473422413384572

Epoch: 6| Step: 10
Training loss: 2.627173296128953
Validation loss: 2.482592457038477

Epoch: 6| Step: 11
Training loss: 2.1341794283226028
Validation loss: 2.4777098283469434

Epoch: 6| Step: 12
Training loss: 3.014044629207648
Validation loss: 2.4872125539401693

Epoch: 6| Step: 13
Training loss: 2.5260834890357646
Validation loss: 2.4860947133049756

Epoch: 151| Step: 0
Training loss: 2.7157230407787
Validation loss: 2.4826682123854784

Epoch: 6| Step: 1
Training loss: 2.8049941891424743
Validation loss: 2.4861238190404884

Epoch: 6| Step: 2
Training loss: 2.672480196759013
Validation loss: 2.485192786080777

Epoch: 6| Step: 3
Training loss: 2.1653260215923966
Validation loss: 2.4893370843085028

Epoch: 6| Step: 4
Training loss: 2.6658895274093926
Validation loss: 2.496045672809848

Epoch: 6| Step: 5
Training loss: 2.4309832193665586
Validation loss: 2.4851112634272035

Epoch: 6| Step: 6
Training loss: 2.1033254270006996
Validation loss: 2.47956470425026

Epoch: 6| Step: 7
Training loss: 2.299408637607208
Validation loss: 2.4674308085121086

Epoch: 6| Step: 8
Training loss: 2.4493486044498862
Validation loss: 2.477363914039568

Epoch: 6| Step: 9
Training loss: 1.9171733877444515
Validation loss: 2.4722895458308023

Epoch: 6| Step: 10
Training loss: 2.7878709486397555
Validation loss: 2.4806890114537623

Epoch: 6| Step: 11
Training loss: 2.645904770334794
Validation loss: 2.4768818389672385

Epoch: 6| Step: 12
Training loss: 2.3641585810185437
Validation loss: 2.470812921509425

Epoch: 6| Step: 13
Training loss: 2.5414335946536033
Validation loss: 2.487087767994304

Epoch: 152| Step: 0
Training loss: 2.7293940927419906
Validation loss: 2.5007872534038986

Epoch: 6| Step: 1
Training loss: 2.2038767729163524
Validation loss: 2.4922260054241523

Epoch: 6| Step: 2
Training loss: 2.5822055775114516
Validation loss: 2.489597916394116

Epoch: 6| Step: 3
Training loss: 2.391993411492042
Validation loss: 2.4921192729862653

Epoch: 6| Step: 4
Training loss: 2.3386923579294994
Validation loss: 2.471802960490233

Epoch: 6| Step: 5
Training loss: 2.7913708791085265
Validation loss: 2.4840508015547087

Epoch: 6| Step: 6
Training loss: 2.585424550977105
Validation loss: 2.471154583079565

Epoch: 6| Step: 7
Training loss: 2.6986465841376637
Validation loss: 2.4820456791275123

Epoch: 6| Step: 8
Training loss: 2.39127834592411
Validation loss: 2.486298829870252

Epoch: 6| Step: 9
Training loss: 1.9707226029218918
Validation loss: 2.4878386738190987

Epoch: 6| Step: 10
Training loss: 2.14705444207924
Validation loss: 2.482174264487622

Epoch: 6| Step: 11
Training loss: 2.5533622080545566
Validation loss: 2.487189124600063

Epoch: 6| Step: 12
Training loss: 2.6355422722558743
Validation loss: 2.486045451750501

Epoch: 6| Step: 13
Training loss: 2.3980626114600647
Validation loss: 2.4821757532980255

Epoch: 153| Step: 0
Training loss: 1.7205707962471877
Validation loss: 2.476321524560021

Epoch: 6| Step: 1
Training loss: 2.423897569323982
Validation loss: 2.478887643793351

Epoch: 6| Step: 2
Training loss: 2.379009275914597
Validation loss: 2.4732125747724587

Epoch: 6| Step: 3
Training loss: 2.4109771665918256
Validation loss: 2.4779852581991677

Epoch: 6| Step: 4
Training loss: 1.9462769963052653
Validation loss: 2.4875117079620614

Epoch: 6| Step: 5
Training loss: 1.9380868822745354
Validation loss: 2.475969317744263

Epoch: 6| Step: 6
Training loss: 2.6277659240071767
Validation loss: 2.475046939597399

Epoch: 6| Step: 7
Training loss: 2.7736891941249415
Validation loss: 2.4769694638742346

Epoch: 6| Step: 8
Training loss: 2.6405961074602784
Validation loss: 2.48020630096348

Epoch: 6| Step: 9
Training loss: 2.7379129246421194
Validation loss: 2.4715249766634364

Epoch: 6| Step: 10
Training loss: 3.001964720465976
Validation loss: 2.47041808483203

Epoch: 6| Step: 11
Training loss: 2.4589628501962
Validation loss: 2.483227542782948

Epoch: 6| Step: 12
Training loss: 2.73637744061333
Validation loss: 2.496898968979012

Epoch: 6| Step: 13
Training loss: 2.361660488266851
Validation loss: 2.5000451719653523

Epoch: 154| Step: 0
Training loss: 2.2808904495121594
Validation loss: 2.5138789528591254

Epoch: 6| Step: 1
Training loss: 2.7538740440271066
Validation loss: 2.522142564208394

Epoch: 6| Step: 2
Training loss: 2.6439706047490117
Validation loss: 2.516768438500375

Epoch: 6| Step: 3
Training loss: 2.6361804101765833
Validation loss: 2.516298602728068

Epoch: 6| Step: 4
Training loss: 2.2132418320980274
Validation loss: 2.5022456017781187

Epoch: 6| Step: 5
Training loss: 2.295623853741865
Validation loss: 2.499675125630017

Epoch: 6| Step: 6
Training loss: 1.6740454729619603
Validation loss: 2.483960003050156

Epoch: 6| Step: 7
Training loss: 2.4702390212266843
Validation loss: 2.490836914568722

Epoch: 6| Step: 8
Training loss: 2.638170715673385
Validation loss: 2.4822885160843713

Epoch: 6| Step: 9
Training loss: 3.0009945174678463
Validation loss: 2.475815220033308

Epoch: 6| Step: 10
Training loss: 2.192926488128689
Validation loss: 2.47624697114264

Epoch: 6| Step: 11
Training loss: 2.4370388670754166
Validation loss: 2.4731874141508814

Epoch: 6| Step: 12
Training loss: 2.753576900186239
Validation loss: 2.4717899229099274

Epoch: 6| Step: 13
Training loss: 2.3289653106438433
Validation loss: 2.46924096871043

Epoch: 155| Step: 0
Training loss: 2.2959575247939497
Validation loss: 2.4713469258327283

Epoch: 6| Step: 1
Training loss: 2.6905561413964407
Validation loss: 2.4752073220396826

Epoch: 6| Step: 2
Training loss: 2.7775062481306034
Validation loss: 2.4769863564191623

Epoch: 6| Step: 3
Training loss: 2.5584411109646292
Validation loss: 2.4799892172271365

Epoch: 6| Step: 4
Training loss: 2.2416885299278224
Validation loss: 2.477557170091536

Epoch: 6| Step: 5
Training loss: 2.8245621468488054
Validation loss: 2.4819120438314557

Epoch: 6| Step: 6
Training loss: 2.485174278426532
Validation loss: 2.501404081876588

Epoch: 6| Step: 7
Training loss: 2.3856772290199806
Validation loss: 2.4922719560461464

Epoch: 6| Step: 8
Training loss: 2.0084695297638313
Validation loss: 2.493104851559139

Epoch: 6| Step: 9
Training loss: 2.532142575978977
Validation loss: 2.4834206065474604

Epoch: 6| Step: 10
Training loss: 2.558300671280941
Validation loss: 2.468762313232619

Epoch: 6| Step: 11
Training loss: 2.7608811377583486
Validation loss: 2.4700888049677654

Epoch: 6| Step: 12
Training loss: 2.141986831403728
Validation loss: 2.4585761715406327

Epoch: 6| Step: 13
Training loss: 2.338831509057202
Validation loss: 2.459557815601193

Epoch: 156| Step: 0
Training loss: 2.3105119975046207
Validation loss: 2.4708853874277033

Epoch: 6| Step: 1
Training loss: 2.544610637565984
Validation loss: 2.467309225541138

Epoch: 6| Step: 2
Training loss: 2.1749293304888897
Validation loss: 2.4642426109888182

Epoch: 6| Step: 3
Training loss: 1.9829446638834387
Validation loss: 2.460026486623781

Epoch: 6| Step: 4
Training loss: 2.178462733788973
Validation loss: 2.476291092081229

Epoch: 6| Step: 5
Training loss: 3.3836037501114924
Validation loss: 2.470040205526608

Epoch: 6| Step: 6
Training loss: 3.1055614913431793
Validation loss: 2.468528633011367

Epoch: 6| Step: 7
Training loss: 2.2512483312758427
Validation loss: 2.4684294963378037

Epoch: 6| Step: 8
Training loss: 2.82374435809257
Validation loss: 2.4629040485029376

Epoch: 6| Step: 9
Training loss: 2.5429929389330557
Validation loss: 2.4679902271714074

Epoch: 6| Step: 10
Training loss: 1.958441494599355
Validation loss: 2.4731548945519544

Epoch: 6| Step: 11
Training loss: 2.0564229040295396
Validation loss: 2.4798038102042006

Epoch: 6| Step: 12
Training loss: 2.9970859043664158
Validation loss: 2.4758865284306197

Epoch: 6| Step: 13
Training loss: 1.7025950596020185
Validation loss: 2.484056480350192

Epoch: 157| Step: 0
Training loss: 2.5642997190288095
Validation loss: 2.4663191952273302

Epoch: 6| Step: 1
Training loss: 2.624285373597242
Validation loss: 2.4767398870981787

Epoch: 6| Step: 2
Training loss: 2.240311532325658
Validation loss: 2.4710811280595437

Epoch: 6| Step: 3
Training loss: 1.9773167916174261
Validation loss: 2.476495029882194

Epoch: 6| Step: 4
Training loss: 2.5838419095741663
Validation loss: 2.470315798830246

Epoch: 6| Step: 5
Training loss: 2.710406248603833
Validation loss: 2.4827289446404412

Epoch: 6| Step: 6
Training loss: 2.4843004323457087
Validation loss: 2.4787677850051564

Epoch: 6| Step: 7
Training loss: 2.514185523229112
Validation loss: 2.474815659128264

Epoch: 6| Step: 8
Training loss: 2.472328200432106
Validation loss: 2.478245962236565

Epoch: 6| Step: 9
Training loss: 1.4172538026821593
Validation loss: 2.4711173734320657

Epoch: 6| Step: 10
Training loss: 2.3847986167481414
Validation loss: 2.4746582540267696

Epoch: 6| Step: 11
Training loss: 2.484767858764815
Validation loss: 2.4753289424769283

Epoch: 6| Step: 12
Training loss: 2.6357951941571622
Validation loss: 2.485890963614524

Epoch: 6| Step: 13
Training loss: 2.729986887750122
Validation loss: 2.4837679971146267

Epoch: 158| Step: 0
Training loss: 2.743002745901994
Validation loss: 2.497412757431671

Epoch: 6| Step: 1
Training loss: 1.876103140250793
Validation loss: 2.505505761607781

Epoch: 6| Step: 2
Training loss: 2.5432998746351827
Validation loss: 2.521708601859029

Epoch: 6| Step: 3
Training loss: 2.144590394363158
Validation loss: 2.502929973267395

Epoch: 6| Step: 4
Training loss: 2.223514974267049
Validation loss: 2.502709494023959

Epoch: 6| Step: 5
Training loss: 2.815753496055597
Validation loss: 2.498236860974861

Epoch: 6| Step: 6
Training loss: 2.2544162642613093
Validation loss: 2.4926059734297494

Epoch: 6| Step: 7
Training loss: 2.4389019382371973
Validation loss: 2.5003660569813815

Epoch: 6| Step: 8
Training loss: 2.040721817407081
Validation loss: 2.513538940993116

Epoch: 6| Step: 9
Training loss: 2.8169241123560553
Validation loss: 2.5042050917772176

Epoch: 6| Step: 10
Training loss: 2.6835276499774245
Validation loss: 2.4975702240127142

Epoch: 6| Step: 11
Training loss: 2.880927402533676
Validation loss: 2.5135869365293186

Epoch: 6| Step: 12
Training loss: 2.2128645515757634
Validation loss: 2.505039682613329

Epoch: 6| Step: 13
Training loss: 2.2819811550702926
Validation loss: 2.5104738732833316

Epoch: 159| Step: 0
Training loss: 2.185875643767753
Validation loss: 2.5033346030447525

Epoch: 6| Step: 1
Training loss: 2.377098561761094
Validation loss: 2.505803477019885

Epoch: 6| Step: 2
Training loss: 2.2662761936262577
Validation loss: 2.5058189065727463

Epoch: 6| Step: 3
Training loss: 2.3604163088774404
Validation loss: 2.519091490384034

Epoch: 6| Step: 4
Training loss: 2.279742225999333
Validation loss: 2.51186264836145

Epoch: 6| Step: 5
Training loss: 2.319108335871945
Validation loss: 2.5066819697869995

Epoch: 6| Step: 6
Training loss: 2.839831660479769
Validation loss: 2.5102446775496166

Epoch: 6| Step: 7
Training loss: 2.2621559682377756
Validation loss: 2.5041246085885067

Epoch: 6| Step: 8
Training loss: 1.9580805662722516
Validation loss: 2.4941189097089214

Epoch: 6| Step: 9
Training loss: 2.1198521136039243
Validation loss: 2.4677672864754006

Epoch: 6| Step: 10
Training loss: 2.8402797778764275
Validation loss: 2.4760940220975645

Epoch: 6| Step: 11
Training loss: 2.658245279733253
Validation loss: 2.4685306693079023

Epoch: 6| Step: 12
Training loss: 2.8659410807801717
Validation loss: 2.473100394344351

Epoch: 6| Step: 13
Training loss: 2.599139026993482
Validation loss: 2.465572485225515

Epoch: 160| Step: 0
Training loss: 2.520744090957019
Validation loss: 2.47049774401897

Epoch: 6| Step: 1
Training loss: 2.372885616145108
Validation loss: 2.4722788574456107

Epoch: 6| Step: 2
Training loss: 2.5959705820635666
Validation loss: 2.471172029933957

Epoch: 6| Step: 3
Training loss: 2.799821122450237
Validation loss: 2.4731298779489395

Epoch: 6| Step: 4
Training loss: 2.174940182970445
Validation loss: 2.48919933874473

Epoch: 6| Step: 5
Training loss: 2.5792509452431336
Validation loss: 2.490588010723093

Epoch: 6| Step: 6
Training loss: 1.7595234999652412
Validation loss: 2.496789698920145

Epoch: 6| Step: 7
Training loss: 2.989760886490127
Validation loss: 2.4985844737281035

Epoch: 6| Step: 8
Training loss: 1.827649763887788
Validation loss: 2.5135371387713348

Epoch: 6| Step: 9
Training loss: 2.4292262580938595
Validation loss: 2.5079759998045237

Epoch: 6| Step: 10
Training loss: 2.644932140352393
Validation loss: 2.4973132637277917

Epoch: 6| Step: 11
Training loss: 2.1330759633304517
Validation loss: 2.4860320093462884

Epoch: 6| Step: 12
Training loss: 2.5253649457317766
Validation loss: 2.4801903275550905

Epoch: 6| Step: 13
Training loss: 2.5613477023448277
Validation loss: 2.471403185107393

Epoch: 161| Step: 0
Training loss: 2.4423406415041833
Validation loss: 2.467594326912776

Epoch: 6| Step: 1
Training loss: 2.6989293695503203
Validation loss: 2.476223494214397

Epoch: 6| Step: 2
Training loss: 2.0427187589787517
Validation loss: 2.470257656864751

Epoch: 6| Step: 3
Training loss: 2.340235605686853
Validation loss: 2.4758146903886415

Epoch: 6| Step: 4
Training loss: 2.6138519439446606
Validation loss: 2.4721986529004236

Epoch: 6| Step: 5
Training loss: 2.4730879902378113
Validation loss: 2.482127294462213

Epoch: 6| Step: 6
Training loss: 2.4483214564475726
Validation loss: 2.482268986269521

Epoch: 6| Step: 7
Training loss: 2.3650423408250565
Validation loss: 2.48796045140769

Epoch: 6| Step: 8
Training loss: 2.771469922663164
Validation loss: 2.494254949782921

Epoch: 6| Step: 9
Training loss: 2.3628758610853646
Validation loss: 2.4988994242148905

Epoch: 6| Step: 10
Training loss: 2.894763849670872
Validation loss: 2.4974143326239586

Epoch: 6| Step: 11
Training loss: 2.6905323043610805
Validation loss: 2.4857848063979864

Epoch: 6| Step: 12
Training loss: 1.908784963091468
Validation loss: 2.5092490766766242

Epoch: 6| Step: 13
Training loss: 2.022366391214139
Validation loss: 2.509175802505806

Epoch: 162| Step: 0
Training loss: 2.0252951559964263
Validation loss: 2.515442535543716

Epoch: 6| Step: 1
Training loss: 2.39528476129186
Validation loss: 2.485628471611885

Epoch: 6| Step: 2
Training loss: 2.3841382950347225
Validation loss: 2.4841314072416982

Epoch: 6| Step: 3
Training loss: 2.302304241461468
Validation loss: 2.481641357075904

Epoch: 6| Step: 4
Training loss: 2.6210411737345183
Validation loss: 2.4750115866341695

Epoch: 6| Step: 5
Training loss: 3.3877116401127143
Validation loss: 2.472101310983092

Epoch: 6| Step: 6
Training loss: 2.128241142879174
Validation loss: 2.47235676105281

Epoch: 6| Step: 7
Training loss: 2.734995918619573
Validation loss: 2.4666341897613537

Epoch: 6| Step: 8
Training loss: 2.805542881835244
Validation loss: 2.470165233336329

Epoch: 6| Step: 9
Training loss: 2.4728827350177123
Validation loss: 2.4743678399856264

Epoch: 6| Step: 10
Training loss: 1.8899743718221178
Validation loss: 2.4748573490095698

Epoch: 6| Step: 11
Training loss: 2.27204889316738
Validation loss: 2.4778314301916744

Epoch: 6| Step: 12
Training loss: 2.4819822484871685
Validation loss: 2.4771742842275084

Epoch: 6| Step: 13
Training loss: 1.83327189978349
Validation loss: 2.466703814364277

Epoch: 163| Step: 0
Training loss: 2.459109738694005
Validation loss: 2.475778273033663

Epoch: 6| Step: 1
Training loss: 2.36949000412297
Validation loss: 2.4791905110812666

Epoch: 6| Step: 2
Training loss: 2.562074579420493
Validation loss: 2.4822796796625872

Epoch: 6| Step: 3
Training loss: 1.8697550211284457
Validation loss: 2.468632353220797

Epoch: 6| Step: 4
Training loss: 1.8500102816115593
Validation loss: 2.4823847862212234

Epoch: 6| Step: 5
Training loss: 2.2916111216893973
Validation loss: 2.478012366539304

Epoch: 6| Step: 6
Training loss: 2.4492450329406155
Validation loss: 2.473595367039787

Epoch: 6| Step: 7
Training loss: 2.412770539763628
Validation loss: 2.478099101613945

Epoch: 6| Step: 8
Training loss: 2.7677473125553256
Validation loss: 2.48594205045893

Epoch: 6| Step: 9
Training loss: 2.8755837552736576
Validation loss: 2.4804481004871697

Epoch: 6| Step: 10
Training loss: 2.3141264479698607
Validation loss: 2.48206492252981

Epoch: 6| Step: 11
Training loss: 3.1866537728574165
Validation loss: 2.4825646064037215

Epoch: 6| Step: 12
Training loss: 2.0204748904172
Validation loss: 2.4781900186495673

Epoch: 6| Step: 13
Training loss: 2.1870379368649226
Validation loss: 2.48098103997703

Epoch: 164| Step: 0
Training loss: 2.679268851538961
Validation loss: 2.490102328121802

Epoch: 6| Step: 1
Training loss: 2.5532476351361075
Validation loss: 2.490447071441481

Epoch: 6| Step: 2
Training loss: 2.337479200627612
Validation loss: 2.490671093114164

Epoch: 6| Step: 3
Training loss: 2.539610724318394
Validation loss: 2.4920296135679236

Epoch: 6| Step: 4
Training loss: 2.711855422400083
Validation loss: 2.493588714355494

Epoch: 6| Step: 5
Training loss: 2.3868290302877204
Validation loss: 2.4915271709353104

Epoch: 6| Step: 6
Training loss: 2.230370835060764
Validation loss: 2.4903967312014954

Epoch: 6| Step: 7
Training loss: 2.5763941647960276
Validation loss: 2.4926673483013166

Epoch: 6| Step: 8
Training loss: 1.9249805697166456
Validation loss: 2.475100513947518

Epoch: 6| Step: 9
Training loss: 2.3893449136135487
Validation loss: 2.469873357864725

Epoch: 6| Step: 10
Training loss: 2.4500368932943477
Validation loss: 2.4804129366465104

Epoch: 6| Step: 11
Training loss: 2.627777356028327
Validation loss: 2.4736503061307746

Epoch: 6| Step: 12
Training loss: 2.3275551322528876
Validation loss: 2.476841410466016

Epoch: 6| Step: 13
Training loss: 2.678740219974154
Validation loss: 2.4652690893267857

Epoch: 165| Step: 0
Training loss: 2.2135496849962
Validation loss: 2.463851148482836

Epoch: 6| Step: 1
Training loss: 2.1716442397221645
Validation loss: 2.472407356097672

Epoch: 6| Step: 2
Training loss: 2.700642586994886
Validation loss: 2.4744483034241522

Epoch: 6| Step: 3
Training loss: 2.3977779512913058
Validation loss: 2.5170774906618756

Epoch: 6| Step: 4
Training loss: 2.363947397721518
Validation loss: 2.5100411626269934

Epoch: 6| Step: 5
Training loss: 2.401366095370075
Validation loss: 2.509000502749378

Epoch: 6| Step: 6
Training loss: 2.8454648391355737
Validation loss: 2.508953052990224

Epoch: 6| Step: 7
Training loss: 1.958040932544074
Validation loss: 2.4854788736987863

Epoch: 6| Step: 8
Training loss: 2.4113125739869923
Validation loss: 2.4813196840278104

Epoch: 6| Step: 9
Training loss: 2.974685998582226
Validation loss: 2.4644906687359605

Epoch: 6| Step: 10
Training loss: 2.416143711552665
Validation loss: 2.4701582437216407

Epoch: 6| Step: 11
Training loss: 2.7856337898976737
Validation loss: 2.4727829292554335

Epoch: 6| Step: 12
Training loss: 2.1550760805370266
Validation loss: 2.472078662685515

Epoch: 6| Step: 13
Training loss: 2.300804047398728
Validation loss: 2.4654635835453194

Epoch: 166| Step: 0
Training loss: 2.0924780099093865
Validation loss: 2.472182306284137

Epoch: 6| Step: 1
Training loss: 2.3202350231041176
Validation loss: 2.470008320170198

Epoch: 6| Step: 2
Training loss: 2.2855905495087394
Validation loss: 2.4713314257675205

Epoch: 6| Step: 3
Training loss: 2.420528505166533
Validation loss: 2.4692786411263072

Epoch: 6| Step: 4
Training loss: 2.256306182077307
Validation loss: 2.471513674016559

Epoch: 6| Step: 5
Training loss: 2.814720548781124
Validation loss: 2.465145618555791

Epoch: 6| Step: 6
Training loss: 2.839796231172673
Validation loss: 2.4759143578894136

Epoch: 6| Step: 7
Training loss: 2.1907507584154904
Validation loss: 2.469270594951621

Epoch: 6| Step: 8
Training loss: 2.4828561422498705
Validation loss: 2.4656968048689305

Epoch: 6| Step: 9
Training loss: 2.148124422323567
Validation loss: 2.4840208236980446

Epoch: 6| Step: 10
Training loss: 2.5387102557648893
Validation loss: 2.490879700264135

Epoch: 6| Step: 11
Training loss: 2.8637654934567656
Validation loss: 2.494783968239987

Epoch: 6| Step: 12
Training loss: 2.364690792201934
Validation loss: 2.5025393781634744

Epoch: 6| Step: 13
Training loss: 2.5105140846524403
Validation loss: 2.4854863877814832

Epoch: 167| Step: 0
Training loss: 2.9153729067103344
Validation loss: 2.489829786756447

Epoch: 6| Step: 1
Training loss: 2.2659772927879627
Validation loss: 2.4872570794627493

Epoch: 6| Step: 2
Training loss: 2.1812610483846155
Validation loss: 2.4855651084226724

Epoch: 6| Step: 3
Training loss: 2.423763597045973
Validation loss: 2.46582248800956

Epoch: 6| Step: 4
Training loss: 2.2490878905495233
Validation loss: 2.4845683504435776

Epoch: 6| Step: 5
Training loss: 2.4298078991659744
Validation loss: 2.4794557600536926

Epoch: 6| Step: 6
Training loss: 2.4436117967321778
Validation loss: 2.4740760105990107

Epoch: 6| Step: 7
Training loss: 2.2039206941463267
Validation loss: 2.468085944120361

Epoch: 6| Step: 8
Training loss: 2.843885481405265
Validation loss: 2.4762235503795624

Epoch: 6| Step: 9
Training loss: 2.080890163897783
Validation loss: 2.4673936393357523

Epoch: 6| Step: 10
Training loss: 2.4680932052546596
Validation loss: 2.4680578331861387

Epoch: 6| Step: 11
Training loss: 2.5597761610638883
Validation loss: 2.470387893288723

Epoch: 6| Step: 12
Training loss: 2.2686400247616816
Validation loss: 2.4651009999205233

Epoch: 6| Step: 13
Training loss: 2.5597903183657493
Validation loss: 2.467115045940791

Epoch: 168| Step: 0
Training loss: 2.362263812010716
Validation loss: 2.4696850193079927

Epoch: 6| Step: 1
Training loss: 2.5397910613382955
Validation loss: 2.470384837118329

Epoch: 6| Step: 2
Training loss: 2.4326942214192804
Validation loss: 2.4711453530809697

Epoch: 6| Step: 3
Training loss: 1.856484739315352
Validation loss: 2.4720195816395094

Epoch: 6| Step: 4
Training loss: 2.646746610479868
Validation loss: 2.4658871803407645

Epoch: 6| Step: 5
Training loss: 2.5143440729031816
Validation loss: 2.4768694217120775

Epoch: 6| Step: 6
Training loss: 2.328073180985286
Validation loss: 2.474302975925706

Epoch: 6| Step: 7
Training loss: 2.288010495448549
Validation loss: 2.4822447018509983

Epoch: 6| Step: 8
Training loss: 2.2043717556338205
Validation loss: 2.4876577892769522

Epoch: 6| Step: 9
Training loss: 2.57366650320401
Validation loss: 2.473165458648398

Epoch: 6| Step: 10
Training loss: 2.3096668311954147
Validation loss: 2.5022147699709616

Epoch: 6| Step: 11
Training loss: 2.4961395020687127
Validation loss: 2.4970884216789733

Epoch: 6| Step: 12
Training loss: 2.499759662519845
Validation loss: 2.49003562383434

Epoch: 6| Step: 13
Training loss: 2.8847624843944484
Validation loss: 2.4825261592094985

Epoch: 169| Step: 0
Training loss: 2.7853710204107447
Validation loss: 2.480227481191891

Epoch: 6| Step: 1
Training loss: 3.026830538656106
Validation loss: 2.4786480486729587

Epoch: 6| Step: 2
Training loss: 1.9112515731815027
Validation loss: 2.4746300732339863

Epoch: 6| Step: 3
Training loss: 2.5492151660759554
Validation loss: 2.4722658223749643

Epoch: 6| Step: 4
Training loss: 2.3987842023437755
Validation loss: 2.470121011021971

Epoch: 6| Step: 5
Training loss: 2.2174409040040377
Validation loss: 2.4823371958802656

Epoch: 6| Step: 6
Training loss: 2.5080679409857187
Validation loss: 2.479913043553715

Epoch: 6| Step: 7
Training loss: 2.531433098846491
Validation loss: 2.4865862843950577

Epoch: 6| Step: 8
Training loss: 2.8326001247072803
Validation loss: 2.4837632775683742

Epoch: 6| Step: 9
Training loss: 2.2999206902471663
Validation loss: 2.4781381145705925

Epoch: 6| Step: 10
Training loss: 2.4107429865990535
Validation loss: 2.474317614249719

Epoch: 6| Step: 11
Training loss: 2.204949996104457
Validation loss: 2.471011144363094

Epoch: 6| Step: 12
Training loss: 2.2430301372188843
Validation loss: 2.4856608919655767

Epoch: 6| Step: 13
Training loss: 1.6380210920939118
Validation loss: 2.4915622257640955

Epoch: 170| Step: 0
Training loss: 2.5750379170709365
Validation loss: 2.4782558552530998

Epoch: 6| Step: 1
Training loss: 2.234791963525746
Validation loss: 2.493261530368405

Epoch: 6| Step: 2
Training loss: 2.4620789802148253
Validation loss: 2.477526528248189

Epoch: 6| Step: 3
Training loss: 2.658549312160756
Validation loss: 2.488741166964352

Epoch: 6| Step: 4
Training loss: 2.18452742103485
Validation loss: 2.489927664424852

Epoch: 6| Step: 5
Training loss: 2.1895905450713653
Validation loss: 2.4958411752092546

Epoch: 6| Step: 6
Training loss: 2.342926694588591
Validation loss: 2.495873001199471

Epoch: 6| Step: 7
Training loss: 3.0728218365708484
Validation loss: 2.4937356188366606

Epoch: 6| Step: 8
Training loss: 2.3077480877957313
Validation loss: 2.499167669342067

Epoch: 6| Step: 9
Training loss: 2.2341978629795487
Validation loss: 2.4961992936960935

Epoch: 6| Step: 10
Training loss: 2.6742609090376606
Validation loss: 2.4976253357661395

Epoch: 6| Step: 11
Training loss: 2.303992215037439
Validation loss: 2.493315071924759

Epoch: 6| Step: 12
Training loss: 2.1240778773554996
Validation loss: 2.4947912313079983

Epoch: 6| Step: 13
Training loss: 2.337445132993684
Validation loss: 2.4920258823395725

Epoch: 171| Step: 0
Training loss: 2.231734202443025
Validation loss: 2.474741236970393

Epoch: 6| Step: 1
Training loss: 2.4418450777492064
Validation loss: 2.482338636569973

Epoch: 6| Step: 2
Training loss: 2.62133214920977
Validation loss: 2.4820620408318095

Epoch: 6| Step: 3
Training loss: 2.86431524698425
Validation loss: 2.4683212036652153

Epoch: 6| Step: 4
Training loss: 2.994656572473803
Validation loss: 2.47056506428329

Epoch: 6| Step: 5
Training loss: 1.5646828472052274
Validation loss: 2.4675244053616363

Epoch: 6| Step: 6
Training loss: 2.521058558551497
Validation loss: 2.4712872082422854

Epoch: 6| Step: 7
Training loss: 2.444597036001335
Validation loss: 2.480448709241753

Epoch: 6| Step: 8
Training loss: 2.9207346929926015
Validation loss: 2.4697773320943024

Epoch: 6| Step: 9
Training loss: 1.4132826535717187
Validation loss: 2.4933394875764967

Epoch: 6| Step: 10
Training loss: 1.8932655747247897
Validation loss: 2.4988026056163832

Epoch: 6| Step: 11
Training loss: 2.3344293018648634
Validation loss: 2.4926446318042297

Epoch: 6| Step: 12
Training loss: 2.6695455468710114
Validation loss: 2.4877042715266664

Epoch: 6| Step: 13
Training loss: 2.3103431747301033
Validation loss: 2.493974242489593

Epoch: 172| Step: 0
Training loss: 2.2716672107064295
Validation loss: 2.503699966161815

Epoch: 6| Step: 1
Training loss: 2.5501745650435037
Validation loss: 2.4968366636691965

Epoch: 6| Step: 2
Training loss: 2.8286068331992147
Validation loss: 2.5059101657571468

Epoch: 6| Step: 3
Training loss: 2.553503292824837
Validation loss: 2.5108925195608394

Epoch: 6| Step: 4
Training loss: 1.8810721937538744
Validation loss: 2.50751442093409

Epoch: 6| Step: 5
Training loss: 2.7449772655608724
Validation loss: 2.5283998211907313

Epoch: 6| Step: 6
Training loss: 1.8187101458086066
Validation loss: 2.538067510248572

Epoch: 6| Step: 7
Training loss: 1.9360834911802116
Validation loss: 2.5258489843336926

Epoch: 6| Step: 8
Training loss: 2.4170303619144424
Validation loss: 2.533521880695843

Epoch: 6| Step: 9
Training loss: 3.0485863207883503
Validation loss: 2.5355955898205034

Epoch: 6| Step: 10
Training loss: 2.08926400672898
Validation loss: 2.5242578297026688

Epoch: 6| Step: 11
Training loss: 2.009344206910728
Validation loss: 2.508163380066613

Epoch: 6| Step: 12
Training loss: 3.0696750590676074
Validation loss: 2.502745900555019

Epoch: 6| Step: 13
Training loss: 1.9765996514850894
Validation loss: 2.4960952782663552

Epoch: 173| Step: 0
Training loss: 2.5284083864174036
Validation loss: 2.4907705171163714

Epoch: 6| Step: 1
Training loss: 2.0176953469093033
Validation loss: 2.491093601766837

Epoch: 6| Step: 2
Training loss: 2.1033918509023426
Validation loss: 2.490866507288774

Epoch: 6| Step: 3
Training loss: 1.934585039755749
Validation loss: 2.4760264429232364

Epoch: 6| Step: 4
Training loss: 2.618030924615141
Validation loss: 2.4798887040175743

Epoch: 6| Step: 5
Training loss: 2.7006005643565887
Validation loss: 2.475315955574248

Epoch: 6| Step: 6
Training loss: 1.799221198825271
Validation loss: 2.474824650650606

Epoch: 6| Step: 7
Training loss: 2.5724205949426615
Validation loss: 2.4876340366717766

Epoch: 6| Step: 8
Training loss: 2.7613078760010943
Validation loss: 2.476974854100516

Epoch: 6| Step: 9
Training loss: 2.8495009403632174
Validation loss: 2.487004070590024

Epoch: 6| Step: 10
Training loss: 3.178837993092464
Validation loss: 2.4939161023852607

Epoch: 6| Step: 11
Training loss: 2.380833438672562
Validation loss: 2.516580862094118

Epoch: 6| Step: 12
Training loss: 2.1199988811417994
Validation loss: 2.517920542559391

Epoch: 6| Step: 13
Training loss: 2.4806738580922256
Validation loss: 2.52442418384798

Epoch: 174| Step: 0
Training loss: 2.0899923966921987
Validation loss: 2.5288372864353423

Epoch: 6| Step: 1
Training loss: 1.5762505304878667
Validation loss: 2.5259792883862775

Epoch: 6| Step: 2
Training loss: 3.210838000758409
Validation loss: 2.5141599823944314

Epoch: 6| Step: 3
Training loss: 2.7932247444690184
Validation loss: 2.499507330987309

Epoch: 6| Step: 4
Training loss: 2.570211762190509
Validation loss: 2.4980578348984634

Epoch: 6| Step: 5
Training loss: 2.6213503397890854
Validation loss: 2.495954283796411

Epoch: 6| Step: 6
Training loss: 2.129511363973433
Validation loss: 2.497566389691319

Epoch: 6| Step: 7
Training loss: 2.2407979347816003
Validation loss: 2.4947610320969194

Epoch: 6| Step: 8
Training loss: 2.547786806862029
Validation loss: 2.4965745346461135

Epoch: 6| Step: 9
Training loss: 1.9681184754879797
Validation loss: 2.494483758856826

Epoch: 6| Step: 10
Training loss: 2.25990109049993
Validation loss: 2.496793247964569

Epoch: 6| Step: 11
Training loss: 2.787535519223936
Validation loss: 2.4869687597779366

Epoch: 6| Step: 12
Training loss: 2.0244074672770043
Validation loss: 2.4956757738269837

Epoch: 6| Step: 13
Training loss: 2.413100955411584
Validation loss: 2.5066673540138087

Epoch: 175| Step: 0
Training loss: 2.461153632467141
Validation loss: 2.4963067590191543

Epoch: 6| Step: 1
Training loss: 2.804783641474361
Validation loss: 2.5090400804835746

Epoch: 6| Step: 2
Training loss: 1.7365565970325487
Validation loss: 2.485328443378473

Epoch: 6| Step: 3
Training loss: 2.944744510675637
Validation loss: 2.4977436532836017

Epoch: 6| Step: 4
Training loss: 1.8805376294607536
Validation loss: 2.4837276087076234

Epoch: 6| Step: 5
Training loss: 2.033524867974787
Validation loss: 2.49829400982319

Epoch: 6| Step: 6
Training loss: 2.6830933394431256
Validation loss: 2.49559552509096

Epoch: 6| Step: 7
Training loss: 2.250295937467528
Validation loss: 2.488723547894062

Epoch: 6| Step: 8
Training loss: 1.733653219061705
Validation loss: 2.477884832083308

Epoch: 6| Step: 9
Training loss: 2.2891202014511807
Validation loss: 2.4906016758329597

Epoch: 6| Step: 10
Training loss: 2.402080540077811
Validation loss: 2.4757508352764193

Epoch: 6| Step: 11
Training loss: 2.8674066859978677
Validation loss: 2.4875347428954675

Epoch: 6| Step: 12
Training loss: 2.3489515441209976
Validation loss: 2.4838107605944506

Epoch: 6| Step: 13
Training loss: 2.8940190365263416
Validation loss: 2.4859900992675352

Epoch: 176| Step: 0
Training loss: 2.3492227364630915
Validation loss: 2.492533262178175

Epoch: 6| Step: 1
Training loss: 2.3348290100224642
Validation loss: 2.4985297330174108

Epoch: 6| Step: 2
Training loss: 2.245276154693168
Validation loss: 2.491430632044397

Epoch: 6| Step: 3
Training loss: 2.454335879681208
Validation loss: 2.4976183036759108

Epoch: 6| Step: 4
Training loss: 2.560364368257414
Validation loss: 2.4990286847529415

Epoch: 6| Step: 5
Training loss: 2.1450864979836566
Validation loss: 2.4859889484087234

Epoch: 6| Step: 6
Training loss: 2.177189424354313
Validation loss: 2.501471849141689

Epoch: 6| Step: 7
Training loss: 2.1173593373963873
Validation loss: 2.4923655766211836

Epoch: 6| Step: 8
Training loss: 2.1249966340879825
Validation loss: 2.4963053502679977

Epoch: 6| Step: 9
Training loss: 2.344917820220497
Validation loss: 2.5099231556734285

Epoch: 6| Step: 10
Training loss: 2.96151220536764
Validation loss: 2.501900999194758

Epoch: 6| Step: 11
Training loss: 1.3067511039978816
Validation loss: 2.493879877658497

Epoch: 6| Step: 12
Training loss: 2.994056536245822
Validation loss: 2.495873932569261

Epoch: 6| Step: 13
Training loss: 3.0042562491666285
Validation loss: 2.5035053076977647

Epoch: 177| Step: 0
Training loss: 2.3737514627220144
Validation loss: 2.5116435069851826

Epoch: 6| Step: 1
Training loss: 2.753247943951878
Validation loss: 2.510551596744383

Epoch: 6| Step: 2
Training loss: 2.075413246828468
Validation loss: 2.5210702695443676

Epoch: 6| Step: 3
Training loss: 2.7120992935874577
Validation loss: 2.5114737114790833

Epoch: 6| Step: 4
Training loss: 2.5502364553887067
Validation loss: 2.5117896244536526

Epoch: 6| Step: 5
Training loss: 2.6795925646277734
Validation loss: 2.5124303305156923

Epoch: 6| Step: 6
Training loss: 2.463314978806903
Validation loss: 2.5153743389975323

Epoch: 6| Step: 7
Training loss: 2.5117863338982884
Validation loss: 2.512526473733025

Epoch: 6| Step: 8
Training loss: 2.2022307183907697
Validation loss: 2.514760289343416

Epoch: 6| Step: 9
Training loss: 2.597022692064539
Validation loss: 2.521395712509337

Epoch: 6| Step: 10
Training loss: 2.6370289711892356
Validation loss: 2.5040814303227634

Epoch: 6| Step: 11
Training loss: 1.638517133751816
Validation loss: 2.5103761397977777

Epoch: 6| Step: 12
Training loss: 2.187999123442368
Validation loss: 2.4954835069152494

Epoch: 6| Step: 13
Training loss: 1.9323613718900707
Validation loss: 2.4892642935360083

Epoch: 178| Step: 0
Training loss: 2.6458616981087273
Validation loss: 2.4926958193520004

Epoch: 6| Step: 1
Training loss: 1.8988140972838023
Validation loss: 2.4961022509697277

Epoch: 6| Step: 2
Training loss: 1.7839071298426503
Validation loss: 2.481102953956878

Epoch: 6| Step: 3
Training loss: 1.9492944003238482
Validation loss: 2.491926867210997

Epoch: 6| Step: 4
Training loss: 2.230037507225018
Validation loss: 2.4881286734009525

Epoch: 6| Step: 5
Training loss: 2.1963384545566087
Validation loss: 2.476114049957352

Epoch: 6| Step: 6
Training loss: 2.313783341079451
Validation loss: 2.4884505122019123

Epoch: 6| Step: 7
Training loss: 2.408612367333477
Validation loss: 2.486649405834573

Epoch: 6| Step: 8
Training loss: 2.3291846814309083
Validation loss: 2.481358334076471

Epoch: 6| Step: 9
Training loss: 2.7752242229705426
Validation loss: 2.4774988532296254

Epoch: 6| Step: 10
Training loss: 2.4625236122819496
Validation loss: 2.476297871824807

Epoch: 6| Step: 11
Training loss: 2.9272507770109533
Validation loss: 2.475669691887363

Epoch: 6| Step: 12
Training loss: 3.2003423746057647
Validation loss: 2.484567790678256

Epoch: 6| Step: 13
Training loss: 2.513533012627128
Validation loss: 2.4834157023327887

Epoch: 179| Step: 0
Training loss: 3.0783195627755098
Validation loss: 2.488883400264811

Epoch: 6| Step: 1
Training loss: 2.612232767701571
Validation loss: 2.4852746258352036

Epoch: 6| Step: 2
Training loss: 2.434735809344355
Validation loss: 2.5128160040728624

Epoch: 6| Step: 3
Training loss: 2.002400150167084
Validation loss: 2.5023118456044164

Epoch: 6| Step: 4
Training loss: 2.063407467119912
Validation loss: 2.5050719627860953

Epoch: 6| Step: 5
Training loss: 2.0694223469600534
Validation loss: 2.497485660744744

Epoch: 6| Step: 6
Training loss: 2.859076145584444
Validation loss: 2.490933572184364

Epoch: 6| Step: 7
Training loss: 2.4471593348139473
Validation loss: 2.4890857076830146

Epoch: 6| Step: 8
Training loss: 2.9778044104768977
Validation loss: 2.4909023849991474

Epoch: 6| Step: 9
Training loss: 1.824830175362846
Validation loss: 2.4896939836968843

Epoch: 6| Step: 10
Training loss: 2.664243272482042
Validation loss: 2.4936282897032087

Epoch: 6| Step: 11
Training loss: 2.4531370514980644
Validation loss: 2.501305715997465

Epoch: 6| Step: 12
Training loss: 1.7798540769191535
Validation loss: 2.500290225984688

Epoch: 6| Step: 13
Training loss: 2.0048497527565328
Validation loss: 2.5053773427778885

Epoch: 180| Step: 0
Training loss: 1.817543444947226
Validation loss: 2.4950182393082

Epoch: 6| Step: 1
Training loss: 2.658890432819719
Validation loss: 2.49517794321721

Epoch: 6| Step: 2
Training loss: 2.688978099218849
Validation loss: 2.5060021351609567

Epoch: 6| Step: 3
Training loss: 2.188554673032924
Validation loss: 2.5036124038660033

Epoch: 6| Step: 4
Training loss: 2.3429394146799005
Validation loss: 2.504089610606312

Epoch: 6| Step: 5
Training loss: 2.2894642968744017
Validation loss: 2.492943261491539

Epoch: 6| Step: 6
Training loss: 2.3399685681506197
Validation loss: 2.5021341115948226

Epoch: 6| Step: 7
Training loss: 2.1691935061028893
Validation loss: 2.4985415018943016

Epoch: 6| Step: 8
Training loss: 2.8978940551958003
Validation loss: 2.5006236093306384

Epoch: 6| Step: 9
Training loss: 2.164546981178285
Validation loss: 2.5053734252419235

Epoch: 6| Step: 10
Training loss: 2.71189225943252
Validation loss: 2.506117345861893

Epoch: 6| Step: 11
Training loss: 2.810221957471749
Validation loss: 2.4941561506002725

Epoch: 6| Step: 12
Training loss: 1.8624026868346912
Validation loss: 2.493721038726673

Epoch: 6| Step: 13
Training loss: 2.381159174431027
Validation loss: 2.4948772237889387

Epoch: 181| Step: 0
Training loss: 2.191569221950804
Validation loss: 2.4996699989591

Epoch: 6| Step: 1
Training loss: 2.0746513533398905
Validation loss: 2.497208745722274

Epoch: 6| Step: 2
Training loss: 2.710972238807277
Validation loss: 2.5077767691438617

Epoch: 6| Step: 3
Training loss: 2.413720757945887
Validation loss: 2.4993636434007214

Epoch: 6| Step: 4
Training loss: 1.966155507314432
Validation loss: 2.5012588351613303

Epoch: 6| Step: 5
Training loss: 1.9947209424528254
Validation loss: 2.497701613581325

Epoch: 6| Step: 6
Training loss: 2.972304936225611
Validation loss: 2.499077435976296

Epoch: 6| Step: 7
Training loss: 2.2512841268999653
Validation loss: 2.4916738301645176

Epoch: 6| Step: 8
Training loss: 2.520057516804029
Validation loss: 2.5030698366154875

Epoch: 6| Step: 9
Training loss: 2.601503755289975
Validation loss: 2.509218473449675

Epoch: 6| Step: 10
Training loss: 2.603745103411161
Validation loss: 2.4896928824313136

Epoch: 6| Step: 11
Training loss: 2.191459886299098
Validation loss: 2.4845619611147693

Epoch: 6| Step: 12
Training loss: 2.6366062620681077
Validation loss: 2.489196848431455

Epoch: 6| Step: 13
Training loss: 2.0620239170733496
Validation loss: 2.49621067559282

Epoch: 182| Step: 0
Training loss: 2.0153765858004737
Validation loss: 2.5043363950549784

Epoch: 6| Step: 1
Training loss: 2.559564723620377
Validation loss: 2.496713035146124

Epoch: 6| Step: 2
Training loss: 2.8722364993040825
Validation loss: 2.5015397178220877

Epoch: 6| Step: 3
Training loss: 2.501795981934456
Validation loss: 2.479900977967567

Epoch: 6| Step: 4
Training loss: 2.721221502012046
Validation loss: 2.472616652361979

Epoch: 6| Step: 5
Training loss: 2.5452317629585033
Validation loss: 2.469383448202772

Epoch: 6| Step: 6
Training loss: 2.2008605574407345
Validation loss: 2.4847836268356143

Epoch: 6| Step: 7
Training loss: 1.8924449641541217
Validation loss: 2.4762404399894615

Epoch: 6| Step: 8
Training loss: 2.6951779539278333
Validation loss: 2.4806378164270257

Epoch: 6| Step: 9
Training loss: 2.0308508847677884
Validation loss: 2.4914716691058625

Epoch: 6| Step: 10
Training loss: 2.5159629452619434
Validation loss: 2.5008619809270933

Epoch: 6| Step: 11
Training loss: 2.669738539991833
Validation loss: 2.492628977227501

Epoch: 6| Step: 12
Training loss: 1.9218948487288041
Validation loss: 2.509214680682229

Epoch: 6| Step: 13
Training loss: 2.3230854765675777
Validation loss: 2.499180262003832

Epoch: 183| Step: 0
Training loss: 2.439335058942325
Validation loss: 2.5333071696871183

Epoch: 6| Step: 1
Training loss: 2.64397673660409
Validation loss: 2.52182675062976

Epoch: 6| Step: 2
Training loss: 2.7807728218747827
Validation loss: 2.5062914203572797

Epoch: 6| Step: 3
Training loss: 2.697185893610216
Validation loss: 2.4904361259164416

Epoch: 6| Step: 4
Training loss: 2.983404830701006
Validation loss: 2.4950334727756447

Epoch: 6| Step: 5
Training loss: 2.4234405379826622
Validation loss: 2.490123535880933

Epoch: 6| Step: 6
Training loss: 2.0051249168847343
Validation loss: 2.4885554938546295

Epoch: 6| Step: 7
Training loss: 2.0843085740241265
Validation loss: 2.4974087160246916

Epoch: 6| Step: 8
Training loss: 2.0285768966485977
Validation loss: 2.489299587748755

Epoch: 6| Step: 9
Training loss: 2.1200328442890357
Validation loss: 2.489206777742625

Epoch: 6| Step: 10
Training loss: 2.7513772810074317
Validation loss: 2.4777077354439627

Epoch: 6| Step: 11
Training loss: 2.05647020639197
Validation loss: 2.477928915840775

Epoch: 6| Step: 12
Training loss: 2.3360530352646824
Validation loss: 2.500633922314047

Epoch: 6| Step: 13
Training loss: 2.2717763593371734
Validation loss: 2.487377391841449

Epoch: 184| Step: 0
Training loss: 1.7913457302113638
Validation loss: 2.4794586287545357

Epoch: 6| Step: 1
Training loss: 2.62112667785064
Validation loss: 2.5008331817793

Epoch: 6| Step: 2
Training loss: 2.3599523381091774
Validation loss: 2.5111934098633117

Epoch: 6| Step: 3
Training loss: 1.881748262747445
Validation loss: 2.511585048124836

Epoch: 6| Step: 4
Training loss: 3.34053640935064
Validation loss: 2.5115329719210395

Epoch: 6| Step: 5
Training loss: 2.233306736099756
Validation loss: 2.518723327268313

Epoch: 6| Step: 6
Training loss: 1.7749149705104508
Validation loss: 2.5094935565335503

Epoch: 6| Step: 7
Training loss: 2.7834264404652767
Validation loss: 2.516808620348308

Epoch: 6| Step: 8
Training loss: 2.1959359040694912
Validation loss: 2.4998212114617493

Epoch: 6| Step: 9
Training loss: 2.373555597477423
Validation loss: 2.5063747352768773

Epoch: 6| Step: 10
Training loss: 2.597267431544529
Validation loss: 2.482422867441367

Epoch: 6| Step: 11
Training loss: 2.7535729172713004
Validation loss: 2.503361365452995

Epoch: 6| Step: 12
Training loss: 2.099423933489505
Validation loss: 2.503853736362472

Epoch: 6| Step: 13
Training loss: 2.3364771599137937
Validation loss: 2.5137583123209875

Epoch: 185| Step: 0
Training loss: 1.7926664076724894
Validation loss: 2.5085889776836483

Epoch: 6| Step: 1
Training loss: 2.3603922690881163
Validation loss: 2.5479225391518847

Epoch: 6| Step: 2
Training loss: 2.5676814471856106
Validation loss: 2.513535834531082

Epoch: 6| Step: 3
Training loss: 2.259496780004906
Validation loss: 2.513388158540061

Epoch: 6| Step: 4
Training loss: 1.6021472886725583
Validation loss: 2.5115855702262273

Epoch: 6| Step: 5
Training loss: 2.891032257259024
Validation loss: 2.5016526164101465

Epoch: 6| Step: 6
Training loss: 2.909434061239687
Validation loss: 2.4933695605734987

Epoch: 6| Step: 7
Training loss: 2.5197889092756065
Validation loss: 2.487946029112458

Epoch: 6| Step: 8
Training loss: 2.4761319433008344
Validation loss: 2.48230221887913

Epoch: 6| Step: 9
Training loss: 2.342551369933297
Validation loss: 2.477971611711642

Epoch: 6| Step: 10
Training loss: 3.0683778680915497
Validation loss: 2.481441933665752

Epoch: 6| Step: 11
Training loss: 1.8231900110119248
Validation loss: 2.4688823358662635

Epoch: 6| Step: 12
Training loss: 2.5868869663430876
Validation loss: 2.4761283806902887

Epoch: 6| Step: 13
Training loss: 2.080648968948997
Validation loss: 2.476959645931939

Epoch: 186| Step: 0
Training loss: 2.342936463624869
Validation loss: 2.4825159150606178

Epoch: 6| Step: 1
Training loss: 2.301456889767915
Validation loss: 2.4750407905942042

Epoch: 6| Step: 2
Training loss: 2.3029182496562073
Validation loss: 2.486107963569491

Epoch: 6| Step: 3
Training loss: 2.278775793819953
Validation loss: 2.4970947709997326

Epoch: 6| Step: 4
Training loss: 2.5577324968338866
Validation loss: 2.4915282075956497

Epoch: 6| Step: 5
Training loss: 2.356204903168511
Validation loss: 2.491747156542096

Epoch: 6| Step: 6
Training loss: 2.503740183163013
Validation loss: 2.48718571362761

Epoch: 6| Step: 7
Training loss: 2.834075232218616
Validation loss: 2.5046581581508667

Epoch: 6| Step: 8
Training loss: 2.2030027098567606
Validation loss: 2.5009838393608343

Epoch: 6| Step: 9
Training loss: 2.729543810306776
Validation loss: 2.5054683325679643

Epoch: 6| Step: 10
Training loss: 2.573224027450151
Validation loss: 2.518506455301657

Epoch: 6| Step: 11
Training loss: 2.142979016698372
Validation loss: 2.530753420561573

Epoch: 6| Step: 12
Training loss: 1.8617295175641988
Validation loss: 2.5419821517341754

Epoch: 6| Step: 13
Training loss: 2.1812282572102557
Validation loss: 2.572809106429236

Epoch: 187| Step: 0
Training loss: 2.7034374784108683
Validation loss: 2.590910939571364

Epoch: 6| Step: 1
Training loss: 2.8447290768204647
Validation loss: 2.573159616920211

Epoch: 6| Step: 2
Training loss: 1.9099295077871818
Validation loss: 2.5859175697626595

Epoch: 6| Step: 3
Training loss: 2.231606428811495
Validation loss: 2.5824266862879743

Epoch: 6| Step: 4
Training loss: 2.4089898698402954
Validation loss: 2.5813500318010103

Epoch: 6| Step: 5
Training loss: 1.7864054976973647
Validation loss: 2.5727859855134145

Epoch: 6| Step: 6
Training loss: 2.2973806642042947
Validation loss: 2.5460179140779724

Epoch: 6| Step: 7
Training loss: 2.2367709458550267
Validation loss: 2.522020191927574

Epoch: 6| Step: 8
Training loss: 1.8877542943368857
Validation loss: 2.494018137450089

Epoch: 6| Step: 9
Training loss: 2.1128431278531448
Validation loss: 2.5087014085606216

Epoch: 6| Step: 10
Training loss: 2.603498958182305
Validation loss: 2.492042449588601

Epoch: 6| Step: 11
Training loss: 2.6086952100629017
Validation loss: 2.482910092234103

Epoch: 6| Step: 12
Training loss: 3.23013351896698
Validation loss: 2.4906322605181987

Epoch: 6| Step: 13
Training loss: 2.24632248750374
Validation loss: 2.4822287575683046

Epoch: 188| Step: 0
Training loss: 2.4126186559087848
Validation loss: 2.481377927107155

Epoch: 6| Step: 1
Training loss: 2.143060343054336
Validation loss: 2.494478756919476

Epoch: 6| Step: 2
Training loss: 2.2771213743540417
Validation loss: 2.479606178070337

Epoch: 6| Step: 3
Training loss: 2.385369701561723
Validation loss: 2.4873502497749165

Epoch: 6| Step: 4
Training loss: 2.40434338224846
Validation loss: 2.4818412928204365

Epoch: 6| Step: 5
Training loss: 2.4088989143683004
Validation loss: 2.4797647273075043

Epoch: 6| Step: 6
Training loss: 1.7602176741893498
Validation loss: 2.4786673745629195

Epoch: 6| Step: 7
Training loss: 2.7384712273056224
Validation loss: 2.4796842200472473

Epoch: 6| Step: 8
Training loss: 2.332337530269266
Validation loss: 2.4950758281746204

Epoch: 6| Step: 9
Training loss: 2.3329365824399875
Validation loss: 2.5007974783201923

Epoch: 6| Step: 10
Training loss: 2.778912794498505
Validation loss: 2.503183944077984

Epoch: 6| Step: 11
Training loss: 2.468364830391384
Validation loss: 2.4991044188766445

Epoch: 6| Step: 12
Training loss: 2.9206889800254308
Validation loss: 2.497385947188353

Epoch: 6| Step: 13
Training loss: 2.3893775427842434
Validation loss: 2.496076525099915

Epoch: 189| Step: 0
Training loss: 2.7967900950581597
Validation loss: 2.5038888725356183

Epoch: 6| Step: 1
Training loss: 2.3726772193120236
Validation loss: 2.505767210060586

Epoch: 6| Step: 2
Training loss: 2.507509777776456
Validation loss: 2.4966191160294113

Epoch: 6| Step: 3
Training loss: 2.3536770967040734
Validation loss: 2.506875343344922

Epoch: 6| Step: 4
Training loss: 2.6280081633407635
Validation loss: 2.497395295006167

Epoch: 6| Step: 5
Training loss: 2.482989518689246
Validation loss: 2.502423669271491

Epoch: 6| Step: 6
Training loss: 2.5310623664542247
Validation loss: 2.5085883599176575

Epoch: 6| Step: 7
Training loss: 2.0212686469657584
Validation loss: 2.5148385755634433

Epoch: 6| Step: 8
Training loss: 2.248610173236268
Validation loss: 2.511771676636571

Epoch: 6| Step: 9
Training loss: 2.325117793226909
Validation loss: 2.5013088773641434

Epoch: 6| Step: 10
Training loss: 1.7195643489828953
Validation loss: 2.5108362984178187

Epoch: 6| Step: 11
Training loss: 2.1928512514584635
Validation loss: 2.493410613533413

Epoch: 6| Step: 12
Training loss: 2.867662936090442
Validation loss: 2.500623227956014

Epoch: 6| Step: 13
Training loss: 2.0811375172321274
Validation loss: 2.5133930200813714

Epoch: 190| Step: 0
Training loss: 2.0310664167339705
Validation loss: 2.5139041646091673

Epoch: 6| Step: 1
Training loss: 2.4004170452802516
Validation loss: 2.5242914067961664

Epoch: 6| Step: 2
Training loss: 2.2259008662658073
Validation loss: 2.5245971455888485

Epoch: 6| Step: 3
Training loss: 1.8658825132707224
Validation loss: 2.5070042877475065

Epoch: 6| Step: 4
Training loss: 1.9751192636333537
Validation loss: 2.510635292589879

Epoch: 6| Step: 5
Training loss: 2.5670456924324765
Validation loss: 2.4963422879380075

Epoch: 6| Step: 6
Training loss: 2.7345502524753478
Validation loss: 2.504137557162557

Epoch: 6| Step: 7
Training loss: 3.0639403712294575
Validation loss: 2.5063960273039085

Epoch: 6| Step: 8
Training loss: 2.354182004175327
Validation loss: 2.5151600378396273

Epoch: 6| Step: 9
Training loss: 1.7270277958473612
Validation loss: 2.522922238869555

Epoch: 6| Step: 10
Training loss: 1.932494681524975
Validation loss: 2.504607389600344

Epoch: 6| Step: 11
Training loss: 2.8319650786989263
Validation loss: 2.5023167366048944

Epoch: 6| Step: 12
Training loss: 2.3865285444872315
Validation loss: 2.5024005173234656

Epoch: 6| Step: 13
Training loss: 2.775987768932298
Validation loss: 2.5020628365834616

Epoch: 191| Step: 0
Training loss: 1.8314461821059442
Validation loss: 2.495255657417293

Epoch: 6| Step: 1
Training loss: 2.641613566429519
Validation loss: 2.4899223501157453

Epoch: 6| Step: 2
Training loss: 1.9386226723903137
Validation loss: 2.4948358286305012

Epoch: 6| Step: 3
Training loss: 2.026786007169939
Validation loss: 2.4930512178242195

Epoch: 6| Step: 4
Training loss: 2.155133497347192
Validation loss: 2.4871536646368924

Epoch: 6| Step: 5
Training loss: 2.3078074915579116
Validation loss: 2.474023104706515

Epoch: 6| Step: 6
Training loss: 2.0581760742819313
Validation loss: 2.4912851866620036

Epoch: 6| Step: 7
Training loss: 2.672019820722287
Validation loss: 2.4880410102876294

Epoch: 6| Step: 8
Training loss: 2.604527888359085
Validation loss: 2.4895986027162875

Epoch: 6| Step: 9
Training loss: 2.442296517367938
Validation loss: 2.4913192878985972

Epoch: 6| Step: 10
Training loss: 3.110081271369989
Validation loss: 2.4992731786224636

Epoch: 6| Step: 11
Training loss: 2.409464781754525
Validation loss: 2.504488301580931

Epoch: 6| Step: 12
Training loss: 2.6743953484930953
Validation loss: 2.5157223321317628

Epoch: 6| Step: 13
Training loss: 2.089247117483669
Validation loss: 2.532042234169984

Epoch: 192| Step: 0
Training loss: 1.7826936459854823
Validation loss: 2.5166573627459945

Epoch: 6| Step: 1
Training loss: 2.457151667762878
Validation loss: 2.5131348473704525

Epoch: 6| Step: 2
Training loss: 2.4389329268588567
Validation loss: 2.51173330473848

Epoch: 6| Step: 3
Training loss: 2.0638879671889114
Validation loss: 2.5220861920837843

Epoch: 6| Step: 4
Training loss: 2.757871459676492
Validation loss: 2.519928089205735

Epoch: 6| Step: 5
Training loss: 2.8410537849338087
Validation loss: 2.5264020262936966

Epoch: 6| Step: 6
Training loss: 2.3621294730132454
Validation loss: 2.544475228342281

Epoch: 6| Step: 7
Training loss: 2.4401041449536973
Validation loss: 2.517703743487083

Epoch: 6| Step: 8
Training loss: 2.54555229055076
Validation loss: 2.502641220427121

Epoch: 6| Step: 9
Training loss: 2.345742561205758
Validation loss: 2.5249197890505792

Epoch: 6| Step: 10
Training loss: 2.1216311959385377
Validation loss: 2.51246276878493

Epoch: 6| Step: 11
Training loss: 2.228007921564344
Validation loss: 2.5060223679768407

Epoch: 6| Step: 12
Training loss: 1.8535230212370541
Validation loss: 2.509542405311292

Epoch: 6| Step: 13
Training loss: 2.944075347350829
Validation loss: 2.5103823130513954

Epoch: 193| Step: 0
Training loss: 2.2478655121374005
Validation loss: 2.5289731872895005

Epoch: 6| Step: 1
Training loss: 1.6964194204327425
Validation loss: 2.5309527187264305

Epoch: 6| Step: 2
Training loss: 2.6150695429757906
Validation loss: 2.516541497694632

Epoch: 6| Step: 3
Training loss: 2.5346903086239796
Validation loss: 2.523149141226549

Epoch: 6| Step: 4
Training loss: 2.5828696316713713
Validation loss: 2.5249987359877846

Epoch: 6| Step: 5
Training loss: 2.5408304954839087
Validation loss: 2.5161469196519115

Epoch: 6| Step: 6
Training loss: 2.7372745508174248
Validation loss: 2.5238755734601575

Epoch: 6| Step: 7
Training loss: 2.543684851259699
Validation loss: 2.519087625723771

Epoch: 6| Step: 8
Training loss: 2.0277852953883246
Validation loss: 2.523251639844832

Epoch: 6| Step: 9
Training loss: 2.502340460997536
Validation loss: 2.51814112596484

Epoch: 6| Step: 10
Training loss: 2.0216709511573385
Validation loss: 2.513195048932935

Epoch: 6| Step: 11
Training loss: 2.5112251045812095
Validation loss: 2.520824272097441

Epoch: 6| Step: 12
Training loss: 2.0243815572643635
Validation loss: 2.5427496640415788

Epoch: 6| Step: 13
Training loss: 2.5314455310040604
Validation loss: 2.5227633777506027

Epoch: 194| Step: 0
Training loss: 1.843000227209399
Validation loss: 2.521414576794845

Epoch: 6| Step: 1
Training loss: 1.945281614495028
Validation loss: 2.526459119982275

Epoch: 6| Step: 2
Training loss: 2.239146013958485
Validation loss: 2.515410988749508

Epoch: 6| Step: 3
Training loss: 2.3614565528040634
Validation loss: 2.514753534287418

Epoch: 6| Step: 4
Training loss: 2.6518545247334218
Validation loss: 2.5159295413093123

Epoch: 6| Step: 5
Training loss: 2.484115107155984
Validation loss: 2.5385965085957216

Epoch: 6| Step: 6
Training loss: 1.9094197544278322
Validation loss: 2.5170119354001437

Epoch: 6| Step: 7
Training loss: 1.6496518981641481
Validation loss: 2.5371569716384363

Epoch: 6| Step: 8
Training loss: 2.5915240192304867
Validation loss: 2.51979093568709

Epoch: 6| Step: 9
Training loss: 2.7194889862011458
Validation loss: 2.5291605359107368

Epoch: 6| Step: 10
Training loss: 2.752560897001049
Validation loss: 2.4978220830789444

Epoch: 6| Step: 11
Training loss: 2.916367342894021
Validation loss: 2.5060883137718326

Epoch: 6| Step: 12
Training loss: 2.2979463945980743
Validation loss: 2.4984680409301365

Epoch: 6| Step: 13
Training loss: 2.176178435365549
Validation loss: 2.4916323498900548

Epoch: 195| Step: 0
Training loss: 2.1631398351425677
Validation loss: 2.5008035639925614

Epoch: 6| Step: 1
Training loss: 2.2685071831014145
Validation loss: 2.491930271693725

Epoch: 6| Step: 2
Training loss: 2.7820262897107653
Validation loss: 2.4982709707077726

Epoch: 6| Step: 3
Training loss: 2.1532977252216714
Validation loss: 2.4936685655597945

Epoch: 6| Step: 4
Training loss: 2.2556005288115517
Validation loss: 2.5170672371580203

Epoch: 6| Step: 5
Training loss: 2.1144619109772664
Validation loss: 2.5229345475898546

Epoch: 6| Step: 6
Training loss: 2.1183884933977435
Validation loss: 2.5389583937992213

Epoch: 6| Step: 7
Training loss: 1.7192287818583416
Validation loss: 2.549198588491169

Epoch: 6| Step: 8
Training loss: 2.1994522539919643
Validation loss: 2.5638240401898846

Epoch: 6| Step: 9
Training loss: 2.8484613983608167
Validation loss: 2.593103535072118

Epoch: 6| Step: 10
Training loss: 2.8694568768757462
Validation loss: 2.5896536103766183

Epoch: 6| Step: 11
Training loss: 2.471557565940517
Validation loss: 2.562787264717618

Epoch: 6| Step: 12
Training loss: 2.6627622770693122
Validation loss: 2.565537830750655

Epoch: 6| Step: 13
Training loss: 2.4410472392285874
Validation loss: 2.541845086094204

Epoch: 196| Step: 0
Training loss: 2.719925111272624
Validation loss: 2.5217182298201153

Epoch: 6| Step: 1
Training loss: 2.048145511397604
Validation loss: 2.536460772022952

Epoch: 6| Step: 2
Training loss: 2.7299109067806517
Validation loss: 2.513214259370966

Epoch: 6| Step: 3
Training loss: 2.7466655803264706
Validation loss: 2.519568848637419

Epoch: 6| Step: 4
Training loss: 2.3900102809860453
Validation loss: 2.50473849727935

Epoch: 6| Step: 5
Training loss: 2.6335100557284847
Validation loss: 2.499816093038299

Epoch: 6| Step: 6
Training loss: 2.615026145206259
Validation loss: 2.501116122009117

Epoch: 6| Step: 7
Training loss: 1.6920587633358195
Validation loss: 2.4939437625217074

Epoch: 6| Step: 8
Training loss: 2.0730476018553228
Validation loss: 2.504297718822873

Epoch: 6| Step: 9
Training loss: 2.222296660554069
Validation loss: 2.5049686806320492

Epoch: 6| Step: 10
Training loss: 2.436960111639884
Validation loss: 2.506566848449905

Epoch: 6| Step: 11
Training loss: 2.2996644189907194
Validation loss: 2.5115268094065164

Epoch: 6| Step: 12
Training loss: 2.5500864949236126
Validation loss: 2.509116272595003

Epoch: 6| Step: 13
Training loss: 2.155683802474287
Validation loss: 2.4984132340497136

Epoch: 197| Step: 0
Training loss: 2.5080301065600024
Validation loss: 2.514939619569375

Epoch: 6| Step: 1
Training loss: 1.4831304854377165
Validation loss: 2.514185049082317

Epoch: 6| Step: 2
Training loss: 2.217129182485453
Validation loss: 2.525250141104141

Epoch: 6| Step: 3
Training loss: 2.4137661946492748
Validation loss: 2.5436377204528084

Epoch: 6| Step: 4
Training loss: 2.4670049559965173
Validation loss: 2.5339432897050362

Epoch: 6| Step: 5
Training loss: 2.0268556451946744
Validation loss: 2.5450176651347194

Epoch: 6| Step: 6
Training loss: 2.6502662129110908
Validation loss: 2.546175574000081

Epoch: 6| Step: 7
Training loss: 1.946209313978622
Validation loss: 2.5399226370116055

Epoch: 6| Step: 8
Training loss: 3.0723376402080964
Validation loss: 2.5348447070437103

Epoch: 6| Step: 9
Training loss: 2.3817587601849035
Validation loss: 2.5122663455704326

Epoch: 6| Step: 10
Training loss: 2.6994926435126936
Validation loss: 2.5062976353812236

Epoch: 6| Step: 11
Training loss: 1.9960816862633863
Validation loss: 2.5179656928747423

Epoch: 6| Step: 12
Training loss: 2.5105891082758367
Validation loss: 2.4940167672379587

Epoch: 6| Step: 13
Training loss: 2.43728587848465
Validation loss: 2.497922049657914

Epoch: 198| Step: 0
Training loss: 2.475914325791025
Validation loss: 2.4922595835817254

Epoch: 6| Step: 1
Training loss: 2.3863325290386395
Validation loss: 2.495756075708284

Epoch: 6| Step: 2
Training loss: 2.7394874082144685
Validation loss: 2.492559279690577

Epoch: 6| Step: 3
Training loss: 2.566443967034015
Validation loss: 2.489052533714264

Epoch: 6| Step: 4
Training loss: 3.1635352931724126
Validation loss: 2.488574144021871

Epoch: 6| Step: 5
Training loss: 2.621286399344821
Validation loss: 2.4854837498614217

Epoch: 6| Step: 6
Training loss: 1.8636474889224408
Validation loss: 2.5024498300798257

Epoch: 6| Step: 7
Training loss: 2.457638033369431
Validation loss: 2.5162433077651665

Epoch: 6| Step: 8
Training loss: 1.7718596308073589
Validation loss: 2.5184247566541647

Epoch: 6| Step: 9
Training loss: 2.2606295530797
Validation loss: 2.523435673353796

Epoch: 6| Step: 10
Training loss: 2.1143735083096367
Validation loss: 2.5258069955158895

Epoch: 6| Step: 11
Training loss: 2.0395227840840846
Validation loss: 2.517317113966873

Epoch: 6| Step: 12
Training loss: 2.406648974349206
Validation loss: 2.5349300932164387

Epoch: 6| Step: 13
Training loss: 1.661933360658536
Validation loss: 2.5105309889050247

Epoch: 199| Step: 0
Training loss: 1.6126622820670131
Validation loss: 2.5196512514068337

Epoch: 6| Step: 1
Training loss: 1.9151253999334072
Validation loss: 2.521238236709561

Epoch: 6| Step: 2
Training loss: 2.081062936251836
Validation loss: 2.5353313791123884

Epoch: 6| Step: 3
Training loss: 3.2036126486648704
Validation loss: 2.543210925843364

Epoch: 6| Step: 4
Training loss: 2.3757626162409466
Validation loss: 2.550598247013563

Epoch: 6| Step: 5
Training loss: 2.5048584459097505
Validation loss: 2.527893195352722

Epoch: 6| Step: 6
Training loss: 2.598901527614703
Validation loss: 2.516041454649888

Epoch: 6| Step: 7
Training loss: 2.3927834932587553
Validation loss: 2.5303691540164532

Epoch: 6| Step: 8
Training loss: 2.2508122779325563
Validation loss: 2.508702026298774

Epoch: 6| Step: 9
Training loss: 2.063639008409962
Validation loss: 2.4937543736724614

Epoch: 6| Step: 10
Training loss: 2.7345073558926756
Validation loss: 2.483388692976974

Epoch: 6| Step: 11
Training loss: 2.734778848525379
Validation loss: 2.479961209173262

Epoch: 6| Step: 12
Training loss: 2.6593086135772386
Validation loss: 2.492436331800192

Epoch: 6| Step: 13
Training loss: 1.7168247884622836
Validation loss: 2.488757652297774

Epoch: 200| Step: 0
Training loss: 2.6075305015996384
Validation loss: 2.4924577747825327

Epoch: 6| Step: 1
Training loss: 2.9431959080250056
Validation loss: 2.4827392919433238

Epoch: 6| Step: 2
Training loss: 2.500232876421781
Validation loss: 2.4793983532865362

Epoch: 6| Step: 3
Training loss: 1.84933827396293
Validation loss: 2.4877119386184323

Epoch: 6| Step: 4
Training loss: 2.3626590130289484
Validation loss: 2.486217239596213

Epoch: 6| Step: 5
Training loss: 2.9879304966739273
Validation loss: 2.477966231671522

Epoch: 6| Step: 6
Training loss: 1.8848840231594406
Validation loss: 2.491520647939586

Epoch: 6| Step: 7
Training loss: 2.172314276971021
Validation loss: 2.4949039256111827

Epoch: 6| Step: 8
Training loss: 2.251939467482165
Validation loss: 2.4817136268920703

Epoch: 6| Step: 9
Training loss: 2.2835283790129624
Validation loss: 2.4891970399941035

Epoch: 6| Step: 10
Training loss: 2.5789154690471108
Validation loss: 2.5039162320688395

Epoch: 6| Step: 11
Training loss: 2.497045965154327
Validation loss: 2.5246455211275998

Epoch: 6| Step: 12
Training loss: 1.752651793998066
Validation loss: 2.535451761116209

Epoch: 6| Step: 13
Training loss: 2.405839067519881
Validation loss: 2.5475103213868895

Epoch: 201| Step: 0
Training loss: 2.661129407968006
Validation loss: 2.5639303448807396

Epoch: 6| Step: 1
Training loss: 3.001601268670845
Validation loss: 2.5360448344877384

Epoch: 6| Step: 2
Training loss: 1.602243864683683
Validation loss: 2.5386895164999452

Epoch: 6| Step: 3
Training loss: 2.7707777567478806
Validation loss: 2.538732419199622

Epoch: 6| Step: 4
Training loss: 2.1967696922967717
Validation loss: 2.538928250407195

Epoch: 6| Step: 5
Training loss: 2.561977240110695
Validation loss: 2.5401023887162397

Epoch: 6| Step: 6
Training loss: 2.048158432539513
Validation loss: 2.51422465583636

Epoch: 6| Step: 7
Training loss: 2.2461681585840725
Validation loss: 2.5111975635872614

Epoch: 6| Step: 8
Training loss: 2.194409276248574
Validation loss: 2.511730267234805

Epoch: 6| Step: 9
Training loss: 1.9306518369064738
Validation loss: 2.4904351207127506

Epoch: 6| Step: 10
Training loss: 2.259221149023555
Validation loss: 2.5032570206032467

Epoch: 6| Step: 11
Training loss: 2.2575748938961677
Validation loss: 2.4998448959555555

Epoch: 6| Step: 12
Training loss: 2.0069858615683263
Validation loss: 2.505983313421462

Epoch: 6| Step: 13
Training loss: 3.039818990739409
Validation loss: 2.501727508687791

Epoch: 202| Step: 0
Training loss: 2.4394242931705414
Validation loss: 2.496030397760389

Epoch: 6| Step: 1
Training loss: 1.960472386129456
Validation loss: 2.4898338005665894

Epoch: 6| Step: 2
Training loss: 2.3370153689713615
Validation loss: 2.502198270073657

Epoch: 6| Step: 3
Training loss: 2.238409068667165
Validation loss: 2.5013825408423846

Epoch: 6| Step: 4
Training loss: 2.684187599897155
Validation loss: 2.514560956204858

Epoch: 6| Step: 5
Training loss: 2.488585928045212
Validation loss: 2.5171874981056748

Epoch: 6| Step: 6
Training loss: 2.593434877671248
Validation loss: 2.5439640642428096

Epoch: 6| Step: 7
Training loss: 2.056499422013461
Validation loss: 2.536752833842416

Epoch: 6| Step: 8
Training loss: 2.9776212156078037
Validation loss: 2.563201932213762

Epoch: 6| Step: 9
Training loss: 2.3581743027229147
Validation loss: 2.5400013288359284

Epoch: 6| Step: 10
Training loss: 2.0943274769162548
Validation loss: 2.549555298418931

Epoch: 6| Step: 11
Training loss: 2.056308701439659
Validation loss: 2.5458891819282194

Epoch: 6| Step: 12
Training loss: 2.302213731297595
Validation loss: 2.5326279080504475

Epoch: 6| Step: 13
Training loss: 2.4928206354060847
Validation loss: 2.545712227029739

Epoch: 203| Step: 0
Training loss: 2.528694746891234
Validation loss: 2.5303497126282033

Epoch: 6| Step: 1
Training loss: 2.3947409309321412
Validation loss: 2.5319511478586674

Epoch: 6| Step: 2
Training loss: 1.731183939751046
Validation loss: 2.535195090256448

Epoch: 6| Step: 3
Training loss: 1.9272885874820296
Validation loss: 2.5501000359803294

Epoch: 6| Step: 4
Training loss: 2.574182906646561
Validation loss: 2.552110124304664

Epoch: 6| Step: 5
Training loss: 1.9209770648109423
Validation loss: 2.5604043004787735

Epoch: 6| Step: 6
Training loss: 2.2970755353306624
Validation loss: 2.525907050147471

Epoch: 6| Step: 7
Training loss: 2.8342068017684294
Validation loss: 2.5254000343723746

Epoch: 6| Step: 8
Training loss: 1.919896169278893
Validation loss: 2.540429601158269

Epoch: 6| Step: 9
Training loss: 2.841321306319838
Validation loss: 2.522687810466292

Epoch: 6| Step: 10
Training loss: 2.697089629401414
Validation loss: 2.520164516619186

Epoch: 6| Step: 11
Training loss: 1.9502335164048716
Validation loss: 2.5163633633259046

Epoch: 6| Step: 12
Training loss: 2.343186781285732
Validation loss: 2.5017956245632944

Epoch: 6| Step: 13
Training loss: 2.6524691432700505
Validation loss: 2.5016888000640947

Epoch: 204| Step: 0
Training loss: 2.3099676133234577
Validation loss: 2.5028936011662077

Epoch: 6| Step: 1
Training loss: 2.271292077253675
Validation loss: 2.490119482643714

Epoch: 6| Step: 2
Training loss: 2.5829420921459687
Validation loss: 2.5007037284933213

Epoch: 6| Step: 3
Training loss: 2.470898043818145
Validation loss: 2.500743898340996

Epoch: 6| Step: 4
Training loss: 2.36638222270063
Validation loss: 2.509353101103522

Epoch: 6| Step: 5
Training loss: 2.165502626779038
Validation loss: 2.5095750867503455

Epoch: 6| Step: 6
Training loss: 3.2807901696028794
Validation loss: 2.5041792269966683

Epoch: 6| Step: 7
Training loss: 1.6023969755813616
Validation loss: 2.5143387469849086

Epoch: 6| Step: 8
Training loss: 2.987066523176107
Validation loss: 2.509142672439764

Epoch: 6| Step: 9
Training loss: 2.758470148878878
Validation loss: 2.537208482756014

Epoch: 6| Step: 10
Training loss: 2.035006175301295
Validation loss: 2.536767370261083

Epoch: 6| Step: 11
Training loss: 2.0057004514620007
Validation loss: 2.533294699608535

Epoch: 6| Step: 12
Training loss: 1.8998289934801431
Validation loss: 2.5218221889734753

Epoch: 6| Step: 13
Training loss: 1.7006096419959116
Validation loss: 2.5459541731238864

Epoch: 205| Step: 0
Training loss: 2.35022847302709
Validation loss: 2.535617263327049

Epoch: 6| Step: 1
Training loss: 2.9957147828592925
Validation loss: 2.5162276973579263

Epoch: 6| Step: 2
Training loss: 2.499294849130331
Validation loss: 2.5280791465143753

Epoch: 6| Step: 3
Training loss: 1.851287821422645
Validation loss: 2.528039387438859

Epoch: 6| Step: 4
Training loss: 1.6394335098674686
Validation loss: 2.5177592273303557

Epoch: 6| Step: 5
Training loss: 2.417802204072194
Validation loss: 2.5175065690617497

Epoch: 6| Step: 6
Training loss: 3.0784699687227155
Validation loss: 2.4990866900150155

Epoch: 6| Step: 7
Training loss: 1.541092671255991
Validation loss: 2.508280091549704

Epoch: 6| Step: 8
Training loss: 2.2650527757639223
Validation loss: 2.4968131336605186

Epoch: 6| Step: 9
Training loss: 2.0203308057435123
Validation loss: 2.5061320282654584

Epoch: 6| Step: 10
Training loss: 2.523666135274058
Validation loss: 2.5099080204923423

Epoch: 6| Step: 11
Training loss: 2.4128076940201333
Validation loss: 2.5180534030572894

Epoch: 6| Step: 12
Training loss: 2.2574085547428324
Validation loss: 2.529511046700738

Epoch: 6| Step: 13
Training loss: 2.5067556655924768
Validation loss: 2.5365692260648

Epoch: 206| Step: 0
Training loss: 2.327224762209605
Validation loss: 2.5343799627077535

Epoch: 6| Step: 1
Training loss: 2.3332326276936217
Validation loss: 2.551420668121023

Epoch: 6| Step: 2
Training loss: 1.3078685516049702
Validation loss: 2.5592672534164915

Epoch: 6| Step: 3
Training loss: 2.6193872118087014
Validation loss: 2.552321151759463

Epoch: 6| Step: 4
Training loss: 2.470804156623791
Validation loss: 2.5546786806846766

Epoch: 6| Step: 5
Training loss: 2.377304765806001
Validation loss: 2.536411533015341

Epoch: 6| Step: 6
Training loss: 2.6670510094552244
Validation loss: 2.5173400498017053

Epoch: 6| Step: 7
Training loss: 2.301280046937172
Validation loss: 2.510201034676702

Epoch: 6| Step: 8
Training loss: 2.811056147939795
Validation loss: 2.4898998000833608

Epoch: 6| Step: 9
Training loss: 2.848060443172488
Validation loss: 2.485008446892058

Epoch: 6| Step: 10
Training loss: 2.366354918655209
Validation loss: 2.47890570947429

Epoch: 6| Step: 11
Training loss: 2.4752307283379262
Validation loss: 2.480489495458482

Epoch: 6| Step: 12
Training loss: 2.2205596850662235
Validation loss: 2.4725623813547255

Epoch: 6| Step: 13
Training loss: 1.832142775664916
Validation loss: 2.4755792119864672

Epoch: 207| Step: 0
Training loss: 2.485495068916827
Validation loss: 2.4780379271633604

Epoch: 6| Step: 1
Training loss: 2.789536208841357
Validation loss: 2.473860043363404

Epoch: 6| Step: 2
Training loss: 1.9421962305119793
Validation loss: 2.4819291989266743

Epoch: 6| Step: 3
Training loss: 2.32093437929099
Validation loss: 2.462205622677713

Epoch: 6| Step: 4
Training loss: 2.5103188227874593
Validation loss: 2.484569805832823

Epoch: 6| Step: 5
Training loss: 2.3092187851863812
Validation loss: 2.4810387464606443

Epoch: 6| Step: 6
Training loss: 1.9442280270469268
Validation loss: 2.507319448454769

Epoch: 6| Step: 7
Training loss: 2.3620213704963375
Validation loss: 2.493443633901992

Epoch: 6| Step: 8
Training loss: 2.253338562133561
Validation loss: 2.495505926875849

Epoch: 6| Step: 9
Training loss: 2.2105017997701584
Validation loss: 2.5127774346368

Epoch: 6| Step: 10
Training loss: 2.565953137767427
Validation loss: 2.4992592826880236

Epoch: 6| Step: 11
Training loss: 2.765078905576646
Validation loss: 2.510016117880087

Epoch: 6| Step: 12
Training loss: 2.2978893298001273
Validation loss: 2.5240624188414524

Epoch: 6| Step: 13
Training loss: 2.6080114033923643
Validation loss: 2.523548623739427

Epoch: 208| Step: 0
Training loss: 2.049473867122741
Validation loss: 2.5496189805146927

Epoch: 6| Step: 1
Training loss: 2.6043532241119642
Validation loss: 2.5628142280512316

Epoch: 6| Step: 2
Training loss: 2.7410292393635904
Validation loss: 2.550382963731784

Epoch: 6| Step: 3
Training loss: 2.5993322945581543
Validation loss: 2.5442482287763815

Epoch: 6| Step: 4
Training loss: 2.317877625415407
Validation loss: 2.5497475009769697

Epoch: 6| Step: 5
Training loss: 2.0297090994703897
Validation loss: 2.529835545191971

Epoch: 6| Step: 6
Training loss: 2.6445361183831664
Validation loss: 2.5415476995256316

Epoch: 6| Step: 7
Training loss: 2.314565200345497
Validation loss: 2.5349170354475454

Epoch: 6| Step: 8
Training loss: 1.5706427687077418
Validation loss: 2.5351366885801556

Epoch: 6| Step: 9
Training loss: 2.076406930301442
Validation loss: 2.5188352742364866

Epoch: 6| Step: 10
Training loss: 2.2532564545482563
Validation loss: 2.544807093840682

Epoch: 6| Step: 11
Training loss: 1.805090921072233
Validation loss: 2.537542206862635

Epoch: 6| Step: 12
Training loss: 3.3758652602241086
Validation loss: 2.5367039999510017

Epoch: 6| Step: 13
Training loss: 1.9994085152509864
Validation loss: 2.5372188349705547

Epoch: 209| Step: 0
Training loss: 2.710603369093722
Validation loss: 2.5183099669965703

Epoch: 6| Step: 1
Training loss: 2.1692944022032083
Validation loss: 2.5215203528640884

Epoch: 6| Step: 2
Training loss: 1.8068111194889158
Validation loss: 2.522373223044236

Epoch: 6| Step: 3
Training loss: 1.7089717493953267
Validation loss: 2.505588944060641

Epoch: 6| Step: 4
Training loss: 2.0643102619900837
Validation loss: 2.501691039684826

Epoch: 6| Step: 5
Training loss: 2.371553530412823
Validation loss: 2.5022182080975583

Epoch: 6| Step: 6
Training loss: 2.307254099199194
Validation loss: 2.4997156458311047

Epoch: 6| Step: 7
Training loss: 2.5641303109844054
Validation loss: 2.5032389322387534

Epoch: 6| Step: 8
Training loss: 2.220248079271391
Validation loss: 2.495874609205215

Epoch: 6| Step: 9
Training loss: 2.6775718767650143
Validation loss: 2.4975209660584006

Epoch: 6| Step: 10
Training loss: 2.2034236624357195
Validation loss: 2.4886570940570207

Epoch: 6| Step: 11
Training loss: 2.4414097656224687
Validation loss: 2.515383722648681

Epoch: 6| Step: 12
Training loss: 3.0087095037761276
Validation loss: 2.490779977505432

Epoch: 6| Step: 13
Training loss: 2.0524553713668507
Validation loss: 2.5043795689248487

Epoch: 210| Step: 0
Training loss: 2.2841426329361387
Validation loss: 2.526218594257249

Epoch: 6| Step: 1
Training loss: 3.052862456326209
Validation loss: 2.520670583426153

Epoch: 6| Step: 2
Training loss: 2.4181165511357614
Validation loss: 2.526783082573291

Epoch: 6| Step: 3
Training loss: 1.966427598851755
Validation loss: 2.5444625162772008

Epoch: 6| Step: 4
Training loss: 2.1256212560524816
Validation loss: 2.5515056864636287

Epoch: 6| Step: 5
Training loss: 2.252677384143964
Validation loss: 2.558403182758835

Epoch: 6| Step: 6
Training loss: 2.5632131561098825
Validation loss: 2.556432876325454

Epoch: 6| Step: 7
Training loss: 2.378792996521617
Validation loss: 2.538104208058157

Epoch: 6| Step: 8
Training loss: 1.9527182193583044
Validation loss: 2.535347969004239

Epoch: 6| Step: 9
Training loss: 2.3373299725550623
Validation loss: 2.5497881215401232

Epoch: 6| Step: 10
Training loss: 2.3988183927501647
Validation loss: 2.5258332287763094

Epoch: 6| Step: 11
Training loss: 2.1285137969688424
Validation loss: 2.508897413995407

Epoch: 6| Step: 12
Training loss: 1.7971672815529782
Validation loss: 2.505969097919623

Epoch: 6| Step: 13
Training loss: 2.653296230797967
Validation loss: 2.5077766740721685

Epoch: 211| Step: 0
Training loss: 2.6681622146009176
Validation loss: 2.516515317580594

Epoch: 6| Step: 1
Training loss: 2.3210357669045085
Validation loss: 2.5265661160567623

Epoch: 6| Step: 2
Training loss: 2.2810668871821425
Validation loss: 2.510218020186781

Epoch: 6| Step: 3
Training loss: 1.9157014019464718
Validation loss: 2.5339671649155355

Epoch: 6| Step: 4
Training loss: 2.5269605295942874
Validation loss: 2.542175981948416

Epoch: 6| Step: 5
Training loss: 2.0409387601405493
Validation loss: 2.531030692501854

Epoch: 6| Step: 6
Training loss: 2.3997058807396368
Validation loss: 2.535059287828187

Epoch: 6| Step: 7
Training loss: 2.5155958091037345
Validation loss: 2.532802733477605

Epoch: 6| Step: 8
Training loss: 2.4227505977678296
Validation loss: 2.529472527609082

Epoch: 6| Step: 9
Training loss: 2.032658367485769
Validation loss: 2.5214167831348084

Epoch: 6| Step: 10
Training loss: 2.111371825945454
Validation loss: 2.5070572425871416

Epoch: 6| Step: 11
Training loss: 2.860979140940643
Validation loss: 2.485851576794971

Epoch: 6| Step: 12
Training loss: 2.1975003129874255
Validation loss: 2.4961003963598873

Epoch: 6| Step: 13
Training loss: 2.317756452310942
Validation loss: 2.4819764848958434

Epoch: 212| Step: 0
Training loss: 2.678456193170863
Validation loss: 2.4889132556924056

Epoch: 6| Step: 1
Training loss: 2.401133460374756
Validation loss: 2.4879171443417647

Epoch: 6| Step: 2
Training loss: 1.7983190953230508
Validation loss: 2.4882156387374232

Epoch: 6| Step: 3
Training loss: 2.0973727640292044
Validation loss: 2.47598420299653

Epoch: 6| Step: 4
Training loss: 2.6207975626709428
Validation loss: 2.49038958296447

Epoch: 6| Step: 5
Training loss: 2.157338185701387
Validation loss: 2.4765544774901276

Epoch: 6| Step: 6
Training loss: 2.3218697097327854
Validation loss: 2.496419949974372

Epoch: 6| Step: 7
Training loss: 2.2564174473726846
Validation loss: 2.503156084430421

Epoch: 6| Step: 8
Training loss: 2.5707920172126255
Validation loss: 2.5223003222598814

Epoch: 6| Step: 9
Training loss: 1.8829800859635057
Validation loss: 2.572954854540242

Epoch: 6| Step: 10
Training loss: 2.587491677680891
Validation loss: 2.5582050523271582

Epoch: 6| Step: 11
Training loss: 2.37539227910134
Validation loss: 2.540769064159138

Epoch: 6| Step: 12
Training loss: 3.079344067519808
Validation loss: 2.523535081927298

Epoch: 6| Step: 13
Training loss: 2.1377769513876506
Validation loss: 2.51937359457088

Epoch: 213| Step: 0
Training loss: 2.3752561732216875
Validation loss: 2.499005231036934

Epoch: 6| Step: 1
Training loss: 2.4991514673265853
Validation loss: 2.5026429987397796

Epoch: 6| Step: 2
Training loss: 2.5318718605521124
Validation loss: 2.4873355363825675

Epoch: 6| Step: 3
Training loss: 2.2476788309850457
Validation loss: 2.4771489232274435

Epoch: 6| Step: 4
Training loss: 2.3214515433380054
Validation loss: 2.4825803564562436

Epoch: 6| Step: 5
Training loss: 2.8935973685364678
Validation loss: 2.4730493475122803

Epoch: 6| Step: 6
Training loss: 1.8862982808602198
Validation loss: 2.4776189979385705

Epoch: 6| Step: 7
Training loss: 2.314552839360425
Validation loss: 2.485969064041796

Epoch: 6| Step: 8
Training loss: 1.6306527926327081
Validation loss: 2.488874188116724

Epoch: 6| Step: 9
Training loss: 2.651171508087587
Validation loss: 2.48849593373736

Epoch: 6| Step: 10
Training loss: 2.897021500423077
Validation loss: 2.499027834062683

Epoch: 6| Step: 11
Training loss: 2.3081293817019404
Validation loss: 2.50541226726099

Epoch: 6| Step: 12
Training loss: 1.8205808515398068
Validation loss: 2.5286433766304337

Epoch: 6| Step: 13
Training loss: 2.136069357763923
Validation loss: 2.4993834212042767

Epoch: 214| Step: 0
Training loss: 1.6492611964991943
Validation loss: 2.5282511273747503

Epoch: 6| Step: 1
Training loss: 2.2647169727056804
Validation loss: 2.5119713260265413

Epoch: 6| Step: 2
Training loss: 2.615079389428301
Validation loss: 2.5277226678432436

Epoch: 6| Step: 3
Training loss: 1.8940874661447762
Validation loss: 2.5139345132142843

Epoch: 6| Step: 4
Training loss: 1.754601967171445
Validation loss: 2.5319986845247087

Epoch: 6| Step: 5
Training loss: 2.80922066982812
Validation loss: 2.5189240426260437

Epoch: 6| Step: 6
Training loss: 1.8090459863775872
Validation loss: 2.510320294906004

Epoch: 6| Step: 7
Training loss: 2.2990387566457695
Validation loss: 2.507351097054489

Epoch: 6| Step: 8
Training loss: 2.2683084315666933
Validation loss: 2.4949084887034223

Epoch: 6| Step: 9
Training loss: 2.2430444867386212
Validation loss: 2.5114395199965913

Epoch: 6| Step: 10
Training loss: 3.2138744575559675
Validation loss: 2.4947367816746504

Epoch: 6| Step: 11
Training loss: 2.4319782803971015
Validation loss: 2.5091815352931057

Epoch: 6| Step: 12
Training loss: 2.512671590990339
Validation loss: 2.5027425822319955

Epoch: 6| Step: 13
Training loss: 2.461316857541461
Validation loss: 2.524073801037784

Epoch: 215| Step: 0
Training loss: 1.975268818873668
Validation loss: 2.533404230288563

Epoch: 6| Step: 1
Training loss: 2.644092878467657
Validation loss: 2.5254279947921066

Epoch: 6| Step: 2
Training loss: 2.0559516759900625
Validation loss: 2.5374008297137283

Epoch: 6| Step: 3
Training loss: 1.7533834990998893
Validation loss: 2.523137825728626

Epoch: 6| Step: 4
Training loss: 2.163014071887445
Validation loss: 2.5113677021277723

Epoch: 6| Step: 5
Training loss: 2.127177973580636
Validation loss: 2.505986246894794

Epoch: 6| Step: 6
Training loss: 2.501946073309247
Validation loss: 2.491671677226086

Epoch: 6| Step: 7
Training loss: 2.316983593273069
Validation loss: 2.5042746397364266

Epoch: 6| Step: 8
Training loss: 2.24133178119201
Validation loss: 2.5049250251529633

Epoch: 6| Step: 9
Training loss: 3.142031833732665
Validation loss: 2.506610776535184

Epoch: 6| Step: 10
Training loss: 1.9736970176615876
Validation loss: 2.5100123817270172

Epoch: 6| Step: 11
Training loss: 2.3147804769159075
Validation loss: 2.507418624353647

Epoch: 6| Step: 12
Training loss: 2.7320339971915253
Validation loss: 2.5221212239310042

Epoch: 6| Step: 13
Training loss: 2.460613992408198
Validation loss: 2.5162698302330084

Epoch: 216| Step: 0
Training loss: 3.130835158836869
Validation loss: 2.5556091139428623

Epoch: 6| Step: 1
Training loss: 2.3066223298848447
Validation loss: 2.556473445064793

Epoch: 6| Step: 2
Training loss: 1.892237141443915
Validation loss: 2.581696412136973

Epoch: 6| Step: 3
Training loss: 2.523533208112687
Validation loss: 2.565429331248587

Epoch: 6| Step: 4
Training loss: 2.245942165401226
Validation loss: 2.5573109912854344

Epoch: 6| Step: 5
Training loss: 3.004470038120024
Validation loss: 2.5378746501538636

Epoch: 6| Step: 6
Training loss: 2.451352979801071
Validation loss: 2.515835739375511

Epoch: 6| Step: 7
Training loss: 2.017554845241722
Validation loss: 2.5094744284548685

Epoch: 6| Step: 8
Training loss: 2.07870326206977
Validation loss: 2.506512805227487

Epoch: 6| Step: 9
Training loss: 1.8829751478673216
Validation loss: 2.508991617866098

Epoch: 6| Step: 10
Training loss: 1.7426003279187539
Validation loss: 2.501033505753868

Epoch: 6| Step: 11
Training loss: 2.318394340116491
Validation loss: 2.495392813889951

Epoch: 6| Step: 12
Training loss: 2.69626872473994
Validation loss: 2.4894945748653066

Epoch: 6| Step: 13
Training loss: 2.261959504538244
Validation loss: 2.4925720810997514

Epoch: 217| Step: 0
Training loss: 1.7135000330109895
Validation loss: 2.497564520258629

Epoch: 6| Step: 1
Training loss: 1.7159702363623033
Validation loss: 2.49438234819276

Epoch: 6| Step: 2
Training loss: 2.1017587563014795
Validation loss: 2.4927431800490623

Epoch: 6| Step: 3
Training loss: 2.531986929915504
Validation loss: 2.503367317907037

Epoch: 6| Step: 4
Training loss: 2.0630794058092072
Validation loss: 2.506093577944201

Epoch: 6| Step: 5
Training loss: 2.138018838476504
Validation loss: 2.5264052348988426

Epoch: 6| Step: 6
Training loss: 2.4348892511017035
Validation loss: 2.5225636294820726

Epoch: 6| Step: 7
Training loss: 2.011373842171363
Validation loss: 2.5213053132727152

Epoch: 6| Step: 8
Training loss: 2.613324859209659
Validation loss: 2.544879420158839

Epoch: 6| Step: 9
Training loss: 2.8638642304381854
Validation loss: 2.541183806240749

Epoch: 6| Step: 10
Training loss: 2.388748729152531
Validation loss: 2.524508080862239

Epoch: 6| Step: 11
Training loss: 2.762430965199655
Validation loss: 2.5141227770261803

Epoch: 6| Step: 12
Training loss: 2.6946094425278053
Validation loss: 2.510020455610149

Epoch: 6| Step: 13
Training loss: 2.2646861268559553
Validation loss: 2.512225055042953

Epoch: 218| Step: 0
Training loss: 2.055679603934719
Validation loss: 2.5085468742072186

Epoch: 6| Step: 1
Training loss: 1.9474306027115111
Validation loss: 2.508338880902447

Epoch: 6| Step: 2
Training loss: 2.510832777136146
Validation loss: 2.517580240000647

Epoch: 6| Step: 3
Training loss: 2.9466353868173507
Validation loss: 2.5064310485692385

Epoch: 6| Step: 4
Training loss: 2.000723707867883
Validation loss: 2.5235007704291523

Epoch: 6| Step: 5
Training loss: 2.340877960348241
Validation loss: 2.5008982395756174

Epoch: 6| Step: 6
Training loss: 2.244319526838771
Validation loss: 2.505064475726563

Epoch: 6| Step: 7
Training loss: 2.6967295584242956
Validation loss: 2.5174719149586537

Epoch: 6| Step: 8
Training loss: 2.2474072670820706
Validation loss: 2.5126663247848176

Epoch: 6| Step: 9
Training loss: 2.173257182119173
Validation loss: 2.5301278927735633

Epoch: 6| Step: 10
Training loss: 2.2735388035177833
Validation loss: 2.5220809455363247

Epoch: 6| Step: 11
Training loss: 1.7560741730233573
Validation loss: 2.5094729479228315

Epoch: 6| Step: 12
Training loss: 1.6573843760027773
Validation loss: 2.498876414533845

Epoch: 6| Step: 13
Training loss: 3.103888650686325
Validation loss: 2.499240235274779

Epoch: 219| Step: 0
Training loss: 2.512424968908674
Validation loss: 2.5042084557658533

Epoch: 6| Step: 1
Training loss: 2.5497255813442226
Validation loss: 2.4855928774772247

Epoch: 6| Step: 2
Training loss: 2.405273239253443
Validation loss: 2.501206607508934

Epoch: 6| Step: 3
Training loss: 2.775313911209976
Validation loss: 2.481636585448672

Epoch: 6| Step: 4
Training loss: 2.0160665102462696
Validation loss: 2.49768369180533

Epoch: 6| Step: 5
Training loss: 2.377869528884822
Validation loss: 2.5018340853489485

Epoch: 6| Step: 6
Training loss: 1.637679589593577
Validation loss: 2.4935259120011173

Epoch: 6| Step: 7
Training loss: 2.9921549902362514
Validation loss: 2.4986699380876964

Epoch: 6| Step: 8
Training loss: 2.104117389769211
Validation loss: 2.517517270619596

Epoch: 6| Step: 9
Training loss: 2.1505571486244004
Validation loss: 2.520844251961089

Epoch: 6| Step: 10
Training loss: 2.263072292385182
Validation loss: 2.535139368879779

Epoch: 6| Step: 11
Training loss: 1.7798602387926445
Validation loss: 2.514440996323418

Epoch: 6| Step: 12
Training loss: 2.662656351432756
Validation loss: 2.529089708325261

Epoch: 6| Step: 13
Training loss: 1.7997565343234527
Validation loss: 2.526050800949309

Epoch: 220| Step: 0
Training loss: 2.580818018200122
Validation loss: 2.5280211620280038

Epoch: 6| Step: 1
Training loss: 2.238683428091372
Validation loss: 2.518961461027687

Epoch: 6| Step: 2
Training loss: 2.390234722119347
Validation loss: 2.51594441915292

Epoch: 6| Step: 3
Training loss: 2.7399897884262145
Validation loss: 2.505056560357512

Epoch: 6| Step: 4
Training loss: 2.265792735237532
Validation loss: 2.50519054721115

Epoch: 6| Step: 5
Training loss: 1.60779234462965
Validation loss: 2.5235890912798356

Epoch: 6| Step: 6
Training loss: 2.2674900139669725
Validation loss: 2.545402819063535

Epoch: 6| Step: 7
Training loss: 2.0542434966889793
Validation loss: 2.5529097069027546

Epoch: 6| Step: 8
Training loss: 2.1617206337730654
Validation loss: 2.5464045552317547

Epoch: 6| Step: 9
Training loss: 3.0753210628961294
Validation loss: 2.5376184044384207

Epoch: 6| Step: 10
Training loss: 1.6733263792726822
Validation loss: 2.5519031279383455

Epoch: 6| Step: 11
Training loss: 2.3608215141965543
Validation loss: 2.5348812006965726

Epoch: 6| Step: 12
Training loss: 2.474720170356605
Validation loss: 2.5367651146153705

Epoch: 6| Step: 13
Training loss: 2.187303370766525
Validation loss: 2.5637474900234465

Epoch: 221| Step: 0
Training loss: 2.138469418214046
Validation loss: 2.5427837158014146

Epoch: 6| Step: 1
Training loss: 2.395363692540959
Validation loss: 2.5504567990019824

Epoch: 6| Step: 2
Training loss: 2.7866551029689397
Validation loss: 2.549376415848641

Epoch: 6| Step: 3
Training loss: 2.176880043674511
Validation loss: 2.5303605797230846

Epoch: 6| Step: 4
Training loss: 2.292825983597174
Validation loss: 2.552394090274158

Epoch: 6| Step: 5
Training loss: 2.4718476189062564
Validation loss: 2.5639646577735125

Epoch: 6| Step: 6
Training loss: 2.064876227929878
Validation loss: 2.5457517803342875

Epoch: 6| Step: 7
Training loss: 2.319062689496017
Validation loss: 2.5346921114824164

Epoch: 6| Step: 8
Training loss: 2.5649325292387553
Validation loss: 2.5082193997214595

Epoch: 6| Step: 9
Training loss: 2.303998527347571
Validation loss: 2.4975879079540877

Epoch: 6| Step: 10
Training loss: 2.257233436536377
Validation loss: 2.4952184249734586

Epoch: 6| Step: 11
Training loss: 2.4086242456080114
Validation loss: 2.489878239316474

Epoch: 6| Step: 12
Training loss: 2.3156741241310104
Validation loss: 2.50224404550749

Epoch: 6| Step: 13
Training loss: 2.169146023961181
Validation loss: 2.496358380843729

Epoch: 222| Step: 0
Training loss: 2.9697774614904007
Validation loss: 2.4942699409802422

Epoch: 6| Step: 1
Training loss: 1.9785069487099989
Validation loss: 2.5013551377099814

Epoch: 6| Step: 2
Training loss: 2.147346469244838
Validation loss: 2.521504909078174

Epoch: 6| Step: 3
Training loss: 1.861696220898751
Validation loss: 2.5165786199346716

Epoch: 6| Step: 4
Training loss: 2.4660667613537672
Validation loss: 2.505619686771607

Epoch: 6| Step: 5
Training loss: 2.085559139154917
Validation loss: 2.5188454337770794

Epoch: 6| Step: 6
Training loss: 2.6629376763597508
Validation loss: 2.534969179905343

Epoch: 6| Step: 7
Training loss: 1.9232480486511938
Validation loss: 2.5298917132286602

Epoch: 6| Step: 8
Training loss: 2.3550199014588156
Validation loss: 2.521053041914203

Epoch: 6| Step: 9
Training loss: 2.3726859614949047
Validation loss: 2.5649543886299724

Epoch: 6| Step: 10
Training loss: 1.8840492586957207
Validation loss: 2.535372356026549

Epoch: 6| Step: 11
Training loss: 2.2715768442660083
Validation loss: 2.5218175485236416

Epoch: 6| Step: 12
Training loss: 2.5994314452397043
Validation loss: 2.514546386228189

Epoch: 6| Step: 13
Training loss: 2.541194736463373
Validation loss: 2.5049348603926984

Epoch: 223| Step: 0
Training loss: 2.0157008193785626
Validation loss: 2.5230532295527768

Epoch: 6| Step: 1
Training loss: 2.2478091912183586
Validation loss: 2.489251954012043

Epoch: 6| Step: 2
Training loss: 1.7404325395949656
Validation loss: 2.498553827347832

Epoch: 6| Step: 3
Training loss: 2.2029843116371337
Validation loss: 2.4855188499564167

Epoch: 6| Step: 4
Training loss: 2.1973838943864776
Validation loss: 2.485673113433934

Epoch: 6| Step: 5
Training loss: 1.7130219464652678
Validation loss: 2.4909340028997895

Epoch: 6| Step: 6
Training loss: 2.0934008406831572
Validation loss: 2.4858694000475188

Epoch: 6| Step: 7
Training loss: 2.5334481949449303
Validation loss: 2.5005712810105605

Epoch: 6| Step: 8
Training loss: 3.145220227316414
Validation loss: 2.4960552087235026

Epoch: 6| Step: 9
Training loss: 2.312248010051117
Validation loss: 2.5086208320263848

Epoch: 6| Step: 10
Training loss: 1.9827597945522968
Validation loss: 2.505291718637113

Epoch: 6| Step: 11
Training loss: 2.487458816264073
Validation loss: 2.5051958608548155

Epoch: 6| Step: 12
Training loss: 2.5232286868785043
Validation loss: 2.512260951979443

Epoch: 6| Step: 13
Training loss: 2.520585754679236
Validation loss: 2.513637239167659

Epoch: 224| Step: 0
Training loss: 2.24095667641334
Validation loss: 2.5466189265478247

Epoch: 6| Step: 1
Training loss: 2.1943189877516267
Validation loss: 2.5594480840225935

Epoch: 6| Step: 2
Training loss: 1.8581781462232858
Validation loss: 2.5526195092639465

Epoch: 6| Step: 3
Training loss: 1.9722716305891184
Validation loss: 2.5582439853295926

Epoch: 6| Step: 4
Training loss: 2.3673832878500676
Validation loss: 2.5637651282275957

Epoch: 6| Step: 5
Training loss: 2.0966957208938077
Validation loss: 2.5371582245816473

Epoch: 6| Step: 6
Training loss: 2.677128317686306
Validation loss: 2.533983983278526

Epoch: 6| Step: 7
Training loss: 2.1000953289374746
Validation loss: 2.532726712649817

Epoch: 6| Step: 8
Training loss: 2.4213269013425847
Validation loss: 2.5136828932363815

Epoch: 6| Step: 9
Training loss: 2.692736735584589
Validation loss: 2.522534140818

Epoch: 6| Step: 10
Training loss: 1.951112183048231
Validation loss: 2.531110814667326

Epoch: 6| Step: 11
Training loss: 2.441091874290439
Validation loss: 2.515619250304797

Epoch: 6| Step: 12
Training loss: 1.9545713028801488
Validation loss: 2.496311884638123

Epoch: 6| Step: 13
Training loss: 2.7728638821418405
Validation loss: 2.5213607730212884

Epoch: 225| Step: 0
Training loss: 1.9864582330483336
Validation loss: 2.5166088652341374

Epoch: 6| Step: 1
Training loss: 1.9769283152170896
Validation loss: 2.52276170812792

Epoch: 6| Step: 2
Training loss: 2.5978141105699177
Validation loss: 2.513785975429757

Epoch: 6| Step: 3
Training loss: 1.804635117336195
Validation loss: 2.515982718929424

Epoch: 6| Step: 4
Training loss: 2.374609965371236
Validation loss: 2.5419120565889393

Epoch: 6| Step: 5
Training loss: 2.6400817673476045
Validation loss: 2.5382873134319492

Epoch: 6| Step: 6
Training loss: 1.5866185872756715
Validation loss: 2.5336789066959375

Epoch: 6| Step: 7
Training loss: 2.5400858064110086
Validation loss: 2.516228818594249

Epoch: 6| Step: 8
Training loss: 3.100568866832929
Validation loss: 2.532829035478099

Epoch: 6| Step: 9
Training loss: 1.5543322900196892
Validation loss: 2.5378653183471367

Epoch: 6| Step: 10
Training loss: 2.859834561131293
Validation loss: 2.5373497375070597

Epoch: 6| Step: 11
Training loss: 1.590368685652774
Validation loss: 2.541683608660489

Epoch: 6| Step: 12
Training loss: 1.8216053051515708
Validation loss: 2.5203946943098385

Epoch: 6| Step: 13
Training loss: 2.9142130385881786
Validation loss: 2.542159194335413

Epoch: 226| Step: 0
Training loss: 2.3910360543896267
Validation loss: 2.516763670317097

Epoch: 6| Step: 1
Training loss: 2.2606934643102754
Validation loss: 2.5091960097309323

Epoch: 6| Step: 2
Training loss: 2.039464216744642
Validation loss: 2.521159755180433

Epoch: 6| Step: 3
Training loss: 2.1096385649864127
Validation loss: 2.496782306387647

Epoch: 6| Step: 4
Training loss: 2.354970294092809
Validation loss: 2.5045867804482036

Epoch: 6| Step: 5
Training loss: 2.08634824673467
Validation loss: 2.50800827387206

Epoch: 6| Step: 6
Training loss: 2.095970570474142
Validation loss: 2.5087695964307

Epoch: 6| Step: 7
Training loss: 2.544252320726267
Validation loss: 2.5176377704934687

Epoch: 6| Step: 8
Training loss: 2.6054288526508618
Validation loss: 2.5309811594545817

Epoch: 6| Step: 9
Training loss: 2.2823249687946707
Validation loss: 2.5313835893708507

Epoch: 6| Step: 10
Training loss: 1.8652091938336233
Validation loss: 2.542514688217461

Epoch: 6| Step: 11
Training loss: 2.272403232709012
Validation loss: 2.5347604937400305

Epoch: 6| Step: 12
Training loss: 2.291033108149404
Validation loss: 2.535998407816663

Epoch: 6| Step: 13
Training loss: 2.800766438081911
Validation loss: 2.532509714015696

Epoch: 227| Step: 0
Training loss: 1.7587474455879277
Validation loss: 2.5297188228924417

Epoch: 6| Step: 1
Training loss: 1.9657765898601156
Validation loss: 2.551803578724163

Epoch: 6| Step: 2
Training loss: 2.704557711673294
Validation loss: 2.5337786347964095

Epoch: 6| Step: 3
Training loss: 2.253895777739157
Validation loss: 2.5472849884490603

Epoch: 6| Step: 4
Training loss: 2.2824952371804557
Validation loss: 2.540630892988802

Epoch: 6| Step: 5
Training loss: 2.49792489715145
Validation loss: 2.5297801769889636

Epoch: 6| Step: 6
Training loss: 2.1262313416753957
Validation loss: 2.497218667045366

Epoch: 6| Step: 7
Training loss: 2.5775013487226803
Validation loss: 2.5151187237220665

Epoch: 6| Step: 8
Training loss: 2.3199641418974437
Validation loss: 2.5114930616583306

Epoch: 6| Step: 9
Training loss: 3.0408688548396796
Validation loss: 2.4995808011505463

Epoch: 6| Step: 10
Training loss: 1.6607315323339902
Validation loss: 2.5245034689599564

Epoch: 6| Step: 11
Training loss: 2.223055892440747
Validation loss: 2.5223821395595785

Epoch: 6| Step: 12
Training loss: 2.1305919447931094
Validation loss: 2.5414956196830967

Epoch: 6| Step: 13
Training loss: 2.491021819433748
Validation loss: 2.5466054528012863

Epoch: 228| Step: 0
Training loss: 1.859805401907707
Validation loss: 2.5642985258352886

Epoch: 6| Step: 1
Training loss: 2.061949569773663
Validation loss: 2.5285555466242173

Epoch: 6| Step: 2
Training loss: 2.7952690415391865
Validation loss: 2.504502525487738

Epoch: 6| Step: 3
Training loss: 2.2697710708260295
Validation loss: 2.500960626418584

Epoch: 6| Step: 4
Training loss: 2.6025100219709487
Validation loss: 2.4928320646098086

Epoch: 6| Step: 5
Training loss: 2.367851743258382
Validation loss: 2.484662069373573

Epoch: 6| Step: 6
Training loss: 3.0061534715410003
Validation loss: 2.4763861111021366

Epoch: 6| Step: 7
Training loss: 1.990798046788811
Validation loss: 2.4821244208411453

Epoch: 6| Step: 8
Training loss: 2.7355469726144137
Validation loss: 2.481302516711389

Epoch: 6| Step: 9
Training loss: 2.3220423149110676
Validation loss: 2.4702165971478176

Epoch: 6| Step: 10
Training loss: 2.367703523196028
Validation loss: 2.495527431059317

Epoch: 6| Step: 11
Training loss: 2.070385049952283
Validation loss: 2.489810427811892

Epoch: 6| Step: 12
Training loss: 1.4679249820406934
Validation loss: 2.525115314532105

Epoch: 6| Step: 13
Training loss: 2.171076346454963
Validation loss: 2.5151559301566

Epoch: 229| Step: 0
Training loss: 2.4616617741554454
Validation loss: 2.547877794927321

Epoch: 6| Step: 1
Training loss: 2.596309272482557
Validation loss: 2.5335039692013157

Epoch: 6| Step: 2
Training loss: 2.4364251921575555
Validation loss: 2.5541140100258897

Epoch: 6| Step: 3
Training loss: 2.738131923113867
Validation loss: 2.546440181006364

Epoch: 6| Step: 4
Training loss: 2.9026020084037447
Validation loss: 2.569100926321474

Epoch: 6| Step: 5
Training loss: 2.1128653577160152
Validation loss: 2.5557974485505253

Epoch: 6| Step: 6
Training loss: 2.1928654944366
Validation loss: 2.5560042228156417

Epoch: 6| Step: 7
Training loss: 2.399897922888222
Validation loss: 2.5407170934748553

Epoch: 6| Step: 8
Training loss: 2.2539519465688276
Validation loss: 2.546422391588573

Epoch: 6| Step: 9
Training loss: 1.6650515200688665
Validation loss: 2.5064527047519256

Epoch: 6| Step: 10
Training loss: 2.602955121820378
Validation loss: 2.5029373397045367

Epoch: 6| Step: 11
Training loss: 2.1411334916556126
Validation loss: 2.477136747930233

Epoch: 6| Step: 12
Training loss: 1.6907763288253745
Validation loss: 2.490569511251752

Epoch: 6| Step: 13
Training loss: 1.736807963919424
Validation loss: 2.4826768073422216

Epoch: 230| Step: 0
Training loss: 2.3487238685896155
Validation loss: 2.487383670099535

Epoch: 6| Step: 1
Training loss: 3.043478613314401
Validation loss: 2.479779189172766

Epoch: 6| Step: 2
Training loss: 2.339684176854713
Validation loss: 2.50050541219397

Epoch: 6| Step: 3
Training loss: 2.664810478385221
Validation loss: 2.4954838014970036

Epoch: 6| Step: 4
Training loss: 2.2027176284221097
Validation loss: 2.4857651761675648

Epoch: 6| Step: 5
Training loss: 2.6871309248754285
Validation loss: 2.4989413165559515

Epoch: 6| Step: 6
Training loss: 1.3436435391148496
Validation loss: 2.5057145451243534

Epoch: 6| Step: 7
Training loss: 1.7807898345309243
Validation loss: 2.5097330885384914

Epoch: 6| Step: 8
Training loss: 1.8425937841969948
Validation loss: 2.5287583414827384

Epoch: 6| Step: 9
Training loss: 2.9261816588597114
Validation loss: 2.525737096508929

Epoch: 6| Step: 10
Training loss: 2.6601473770329718
Validation loss: 2.5426939831966506

Epoch: 6| Step: 11
Training loss: 2.1146496416290907
Validation loss: 2.505417247370146

Epoch: 6| Step: 12
Training loss: 2.0195048051943636
Validation loss: 2.5123907429234333

Epoch: 6| Step: 13
Training loss: 1.519664768344714
Validation loss: 2.5138970990219605

Epoch: 231| Step: 0
Training loss: 2.7843390465672484
Validation loss: 2.5013633189664524

Epoch: 6| Step: 1
Training loss: 1.5861261565650429
Validation loss: 2.49989208942216

Epoch: 6| Step: 2
Training loss: 1.6306043962351764
Validation loss: 2.5093971545997955

Epoch: 6| Step: 3
Training loss: 2.566498776514151
Validation loss: 2.5014938818443557

Epoch: 6| Step: 4
Training loss: 2.366056971750024
Validation loss: 2.492244947004558

Epoch: 6| Step: 5
Training loss: 1.8723986700369861
Validation loss: 2.4953347386862306

Epoch: 6| Step: 6
Training loss: 1.9267564513505708
Validation loss: 2.505278276404261

Epoch: 6| Step: 7
Training loss: 1.447374676960106
Validation loss: 2.50892516237592

Epoch: 6| Step: 8
Training loss: 2.102519558374468
Validation loss: 2.5029856337834686

Epoch: 6| Step: 9
Training loss: 2.2904300705636245
Validation loss: 2.5138989800191522

Epoch: 6| Step: 10
Training loss: 2.9648775242023926
Validation loss: 2.5076534422823613

Epoch: 6| Step: 11
Training loss: 2.3566761875994424
Validation loss: 2.5252347516002738

Epoch: 6| Step: 12
Training loss: 2.8031634171829185
Validation loss: 2.5364246614219907

Epoch: 6| Step: 13
Training loss: 2.4512352923818153
Validation loss: 2.5323041596778584

Epoch: 232| Step: 0
Training loss: 2.839468950937806
Validation loss: 2.552978535080917

Epoch: 6| Step: 1
Training loss: 1.9268798170793562
Validation loss: 2.552579501959827

Epoch: 6| Step: 2
Training loss: 2.8327214945479247
Validation loss: 2.52323570271301

Epoch: 6| Step: 3
Training loss: 2.236491874463445
Validation loss: 2.5313611104307028

Epoch: 6| Step: 4
Training loss: 2.8701460954651705
Validation loss: 2.549989220029198

Epoch: 6| Step: 5
Training loss: 1.9535151587845936
Validation loss: 2.5480137874863034

Epoch: 6| Step: 6
Training loss: 2.3849929588741756
Validation loss: 2.542469333062384

Epoch: 6| Step: 7
Training loss: 2.682715570723915
Validation loss: 2.560697960875962

Epoch: 6| Step: 8
Training loss: 2.7108713631161625
Validation loss: 2.5632955045186487

Epoch: 6| Step: 9
Training loss: 1.7113147476464068
Validation loss: 2.553437139884336

Epoch: 6| Step: 10
Training loss: 1.8221262789617942
Validation loss: 2.530104656668349

Epoch: 6| Step: 11
Training loss: 1.277912631497492
Validation loss: 2.5191860228600502

Epoch: 6| Step: 12
Training loss: 2.146843114002543
Validation loss: 2.5014786321212963

Epoch: 6| Step: 13
Training loss: 1.9802869604220688
Validation loss: 2.5062659021318594

Epoch: 233| Step: 0
Training loss: 2.718201768343195
Validation loss: 2.4942996363484604

Epoch: 6| Step: 1
Training loss: 2.5692077859942595
Validation loss: 2.5166446601671826

Epoch: 6| Step: 2
Training loss: 1.6650402796229056
Validation loss: 2.5245622740179523

Epoch: 6| Step: 3
Training loss: 1.8435502024871946
Validation loss: 2.5161652863454016

Epoch: 6| Step: 4
Training loss: 2.444837335117477
Validation loss: 2.5265705354649666

Epoch: 6| Step: 5
Training loss: 2.387671547363837
Validation loss: 2.529325452174267

Epoch: 6| Step: 6
Training loss: 1.899498286010258
Validation loss: 2.5267478873284075

Epoch: 6| Step: 7
Training loss: 2.376702351063708
Validation loss: 2.5388938417416527

Epoch: 6| Step: 8
Training loss: 2.537663940245163
Validation loss: 2.5432662047663595

Epoch: 6| Step: 9
Training loss: 2.2530707491667306
Validation loss: 2.543681016153759

Epoch: 6| Step: 10
Training loss: 2.418341242827458
Validation loss: 2.5580863313589526

Epoch: 6| Step: 11
Training loss: 2.140968128186271
Validation loss: 2.552780232677956

Epoch: 6| Step: 12
Training loss: 2.169378918309301
Validation loss: 2.5381892810588687

Epoch: 6| Step: 13
Training loss: 2.0489857979352566
Validation loss: 2.542391256846996

Epoch: 234| Step: 0
Training loss: 2.57693019114847
Validation loss: 2.5369590693219264

Epoch: 6| Step: 1
Training loss: 1.8847326720524396
Validation loss: 2.5424818675452068

Epoch: 6| Step: 2
Training loss: 2.336523894638633
Validation loss: 2.5529310777681946

Epoch: 6| Step: 3
Training loss: 2.527542790353483
Validation loss: 2.5442680012671888

Epoch: 6| Step: 4
Training loss: 1.8453127170598147
Validation loss: 2.556748036536604

Epoch: 6| Step: 5
Training loss: 2.7945146030679915
Validation loss: 2.572108312926637

Epoch: 6| Step: 6
Training loss: 2.427684878568243
Validation loss: 2.5642677582963325

Epoch: 6| Step: 7
Training loss: 1.824417397508594
Validation loss: 2.541447463250124

Epoch: 6| Step: 8
Training loss: 2.624887191528335
Validation loss: 2.563197591467276

Epoch: 6| Step: 9
Training loss: 2.246543136090846
Validation loss: 2.5730025139411024

Epoch: 6| Step: 10
Training loss: 2.019537152811127
Validation loss: 2.581571159980895

Epoch: 6| Step: 11
Training loss: 2.3850937226312228
Validation loss: 2.550477286781034

Epoch: 6| Step: 12
Training loss: 2.231067583764323
Validation loss: 2.5494403673803814

Epoch: 6| Step: 13
Training loss: 1.6012174653344604
Validation loss: 2.5474866354968926

Epoch: 235| Step: 0
Training loss: 1.8166208448084935
Validation loss: 2.53885836832171

Epoch: 6| Step: 1
Training loss: 2.5528287045621423
Validation loss: 2.547830616913753

Epoch: 6| Step: 2
Training loss: 2.0568292283164364
Validation loss: 2.519197632143651

Epoch: 6| Step: 3
Training loss: 2.2002315052643464
Validation loss: 2.5146236598698386

Epoch: 6| Step: 4
Training loss: 2.1453031113232286
Validation loss: 2.5110190422017684

Epoch: 6| Step: 5
Training loss: 2.5656216843243267
Validation loss: 2.52030460603175

Epoch: 6| Step: 6
Training loss: 2.946160232412906
Validation loss: 2.5258543489094345

Epoch: 6| Step: 7
Training loss: 1.9676995881187356
Validation loss: 2.5250796711504666

Epoch: 6| Step: 8
Training loss: 2.6479663711152703
Validation loss: 2.5244350134879716

Epoch: 6| Step: 9
Training loss: 1.4866169913222234
Validation loss: 2.5168298241061375

Epoch: 6| Step: 10
Training loss: 2.390832031859501
Validation loss: 2.5656804762188563

Epoch: 6| Step: 11
Training loss: 2.566584425595327
Validation loss: 2.554792567278903

Epoch: 6| Step: 12
Training loss: 2.0947109693111345
Validation loss: 2.5836100327576856

Epoch: 6| Step: 13
Training loss: 1.7813119040992424
Validation loss: 2.5440808905011103

Epoch: 236| Step: 0
Training loss: 3.093676941904895
Validation loss: 2.563240207977973

Epoch: 6| Step: 1
Training loss: 1.9402973531167749
Validation loss: 2.5532729950698587

Epoch: 6| Step: 2
Training loss: 1.8844623855395544
Validation loss: 2.579015235173503

Epoch: 6| Step: 3
Training loss: 2.4146802784567503
Validation loss: 2.5630770630544655

Epoch: 6| Step: 4
Training loss: 2.5826582385437526
Validation loss: 2.5341192553106713

Epoch: 6| Step: 5
Training loss: 2.2646943384201252
Validation loss: 2.5392169768462782

Epoch: 6| Step: 6
Training loss: 2.580865871120457
Validation loss: 2.545800479691498

Epoch: 6| Step: 7
Training loss: 1.8184111656410056
Validation loss: 2.550777106211141

Epoch: 6| Step: 8
Training loss: 2.24482725842458
Validation loss: 2.540457771556434

Epoch: 6| Step: 9
Training loss: 1.697514453202799
Validation loss: 2.553266015082532

Epoch: 6| Step: 10
Training loss: 2.3353540208520767
Validation loss: 2.5085368630433713

Epoch: 6| Step: 11
Training loss: 2.041839696078618
Validation loss: 2.5120623142487006

Epoch: 6| Step: 12
Training loss: 2.2774761809224677
Validation loss: 2.5327421115426945

Epoch: 6| Step: 13
Training loss: 2.2849901448711334
Validation loss: 2.5190509032683805

Epoch: 237| Step: 0
Training loss: 2.296563575029089
Validation loss: 2.516585993789558

Epoch: 6| Step: 1
Training loss: 2.37678741654821
Validation loss: 2.5401025295089337

Epoch: 6| Step: 2
Training loss: 1.9551549509599446
Validation loss: 2.5361293341752718

Epoch: 6| Step: 3
Training loss: 2.170235872941386
Validation loss: 2.5560580591145685

Epoch: 6| Step: 4
Training loss: 1.9135635036938459
Validation loss: 2.5777774460927523

Epoch: 6| Step: 5
Training loss: 2.5835402518640405
Validation loss: 2.5864481196135904

Epoch: 6| Step: 6
Training loss: 2.030749802257505
Validation loss: 2.596210155619049

Epoch: 6| Step: 7
Training loss: 1.5715303016530326
Validation loss: 2.591043323936422

Epoch: 6| Step: 8
Training loss: 2.8688863352041833
Validation loss: 2.6068700466019012

Epoch: 6| Step: 9
Training loss: 2.095908347797719
Validation loss: 2.5877211950727914

Epoch: 6| Step: 10
Training loss: 2.554130283447142
Validation loss: 2.5593926577799264

Epoch: 6| Step: 11
Training loss: 3.0938753044877614
Validation loss: 2.547623475601022

Epoch: 6| Step: 12
Training loss: 1.5474116617850735
Validation loss: 2.5180592418778565

Epoch: 6| Step: 13
Training loss: 2.3707096096622053
Validation loss: 2.485322119957502

Epoch: 238| Step: 0
Training loss: 1.8760308928518337
Validation loss: 2.5070359799506976

Epoch: 6| Step: 1
Training loss: 2.187097348893642
Validation loss: 2.4958107339624465

Epoch: 6| Step: 2
Training loss: 2.36095269612964
Validation loss: 2.505035859725026

Epoch: 6| Step: 3
Training loss: 2.1328597849540345
Validation loss: 2.495835817767792

Epoch: 6| Step: 4
Training loss: 2.602696260496383
Validation loss: 2.507574939666534

Epoch: 6| Step: 5
Training loss: 2.992527875141031
Validation loss: 2.5201320513434

Epoch: 6| Step: 6
Training loss: 1.9918477685010696
Validation loss: 2.5381895158902203

Epoch: 6| Step: 7
Training loss: 2.0095188593647433
Validation loss: 2.5305811308335953

Epoch: 6| Step: 8
Training loss: 1.838079428628332
Validation loss: 2.5189825599024283

Epoch: 6| Step: 9
Training loss: 2.0600190702500063
Validation loss: 2.5342761502193234

Epoch: 6| Step: 10
Training loss: 2.6867877105000213
Validation loss: 2.5283371920001922

Epoch: 6| Step: 11
Training loss: 2.701404531172634
Validation loss: 2.5524328083357104

Epoch: 6| Step: 12
Training loss: 2.050123941349947
Validation loss: 2.5127599287564677

Epoch: 6| Step: 13
Training loss: 1.886602741726602
Validation loss: 2.5087103974277154

Epoch: 239| Step: 0
Training loss: 2.1431483411477394
Validation loss: 2.4995790762996735

Epoch: 6| Step: 1
Training loss: 1.2137244854964926
Validation loss: 2.493313095712723

Epoch: 6| Step: 2
Training loss: 3.515704751699586
Validation loss: 2.501628393083331

Epoch: 6| Step: 3
Training loss: 1.7987073760453345
Validation loss: 2.504419330750068

Epoch: 6| Step: 4
Training loss: 1.6048174277119007
Validation loss: 2.480834141048684

Epoch: 6| Step: 5
Training loss: 2.2648704587763606
Validation loss: 2.481597451354316

Epoch: 6| Step: 6
Training loss: 1.9585362051995967
Validation loss: 2.4948275304033616

Epoch: 6| Step: 7
Training loss: 2.664027238987229
Validation loss: 2.49998284969805

Epoch: 6| Step: 8
Training loss: 2.32911220844003
Validation loss: 2.494696937201361

Epoch: 6| Step: 9
Training loss: 2.2588585143208344
Validation loss: 2.496175542773826

Epoch: 6| Step: 10
Training loss: 2.438992556852688
Validation loss: 2.5218259470225157

Epoch: 6| Step: 11
Training loss: 2.2042498591491024
Validation loss: 2.5167685805984137

Epoch: 6| Step: 12
Training loss: 2.044604607484304
Validation loss: 2.539301699595141

Epoch: 6| Step: 13
Training loss: 2.4834911765642063
Validation loss: 2.5480677458252283

Epoch: 240| Step: 0
Training loss: 2.3211706353559447
Validation loss: 2.5501591545502764

Epoch: 6| Step: 1
Training loss: 2.138276419810093
Validation loss: 2.5651520829477588

Epoch: 6| Step: 2
Training loss: 2.633312687209433
Validation loss: 2.593929989249637

Epoch: 6| Step: 3
Training loss: 1.901676507445719
Validation loss: 2.606325617729242

Epoch: 6| Step: 4
Training loss: 2.461512132192062
Validation loss: 2.6249133807226466

Epoch: 6| Step: 5
Training loss: 2.392323109017817
Validation loss: 2.649937852694571

Epoch: 6| Step: 6
Training loss: 2.7387771483920864
Validation loss: 2.5985489996260687

Epoch: 6| Step: 7
Training loss: 1.985967522731118
Validation loss: 2.5528558197747917

Epoch: 6| Step: 8
Training loss: 1.9528356719294275
Validation loss: 2.520239647137329

Epoch: 6| Step: 9
Training loss: 2.5206641673765358
Validation loss: 2.5257462686023238

Epoch: 6| Step: 10
Training loss: 1.2899436482238116
Validation loss: 2.5049427920095177

Epoch: 6| Step: 11
Training loss: 2.8325935594774907
Validation loss: 2.5053210771745418

Epoch: 6| Step: 12
Training loss: 2.211728443163588
Validation loss: 2.4715930486953495

Epoch: 6| Step: 13
Training loss: 2.286561921596519
Validation loss: 2.4722454418801663

Epoch: 241| Step: 0
Training loss: 2.7172727408044084
Validation loss: 2.4815245296319683

Epoch: 6| Step: 1
Training loss: 2.2569500288934985
Validation loss: 2.4809697804094943

Epoch: 6| Step: 2
Training loss: 1.8880567525318857
Validation loss: 2.4626692718574006

Epoch: 6| Step: 3
Training loss: 2.4616504423639487
Validation loss: 2.4810425903086255

Epoch: 6| Step: 4
Training loss: 2.6170850135892167
Validation loss: 2.473374321251769

Epoch: 6| Step: 5
Training loss: 2.3690481395862353
Validation loss: 2.4570186677336654

Epoch: 6| Step: 6
Training loss: 2.156337017570191
Validation loss: 2.4795633420767063

Epoch: 6| Step: 7
Training loss: 1.9885446789896712
Validation loss: 2.4942995089012836

Epoch: 6| Step: 8
Training loss: 2.4491609265378194
Validation loss: 2.5185098790766483

Epoch: 6| Step: 9
Training loss: 2.3089471278689846
Validation loss: 2.540576925288168

Epoch: 6| Step: 10
Training loss: 1.933907531555397
Validation loss: 2.555071662848393

Epoch: 6| Step: 11
Training loss: 1.785560345145127
Validation loss: 2.5505034454627546

Epoch: 6| Step: 12
Training loss: 2.8282959607123574
Validation loss: 2.565432893760487

Epoch: 6| Step: 13
Training loss: 2.2452049022529295
Validation loss: 2.56876019540018

Epoch: 242| Step: 0
Training loss: 2.0524523511366892
Validation loss: 2.5317923196428755

Epoch: 6| Step: 1
Training loss: 2.376340086471944
Validation loss: 2.538906839930065

Epoch: 6| Step: 2
Training loss: 2.936799310754889
Validation loss: 2.5363687163911464

Epoch: 6| Step: 3
Training loss: 2.0746844499866968
Validation loss: 2.540662150093788

Epoch: 6| Step: 4
Training loss: 2.496233104940899
Validation loss: 2.5266522380782583

Epoch: 6| Step: 5
Training loss: 1.8331557606906979
Validation loss: 2.5142347470823765

Epoch: 6| Step: 6
Training loss: 1.902909149807703
Validation loss: 2.51308202850203

Epoch: 6| Step: 7
Training loss: 1.8116739297959281
Validation loss: 2.495660074574911

Epoch: 6| Step: 8
Training loss: 1.673732474408405
Validation loss: 2.4880824226697738

Epoch: 6| Step: 9
Training loss: 2.407293118375051
Validation loss: 2.510794129756126

Epoch: 6| Step: 10
Training loss: 2.4059802808326114
Validation loss: 2.4969434490855646

Epoch: 6| Step: 11
Training loss: 3.1410601110478322
Validation loss: 2.4877159638321498

Epoch: 6| Step: 12
Training loss: 1.866613068265261
Validation loss: 2.5089090708867032

Epoch: 6| Step: 13
Training loss: 2.037973866034031
Validation loss: 2.4840636468115966

Epoch: 243| Step: 0
Training loss: 2.059883423071385
Validation loss: 2.489300681206875

Epoch: 6| Step: 1
Training loss: 2.3678174077789045
Validation loss: 2.4834241186952464

Epoch: 6| Step: 2
Training loss: 1.9646667036676333
Validation loss: 2.495173754862688

Epoch: 6| Step: 3
Training loss: 3.037454449347406
Validation loss: 2.491218960663245

Epoch: 6| Step: 4
Training loss: 2.0357399248119563
Validation loss: 2.507103919900502

Epoch: 6| Step: 5
Training loss: 2.262197177074237
Validation loss: 2.5024824056600727

Epoch: 6| Step: 6
Training loss: 1.6841136722573047
Validation loss: 2.5152451759592664

Epoch: 6| Step: 7
Training loss: 2.0869924327967224
Validation loss: 2.5053247013677584

Epoch: 6| Step: 8
Training loss: 1.346738552607818
Validation loss: 2.511555098308779

Epoch: 6| Step: 9
Training loss: 2.12113803655712
Validation loss: 2.505348262461036

Epoch: 6| Step: 10
Training loss: 2.714573688933971
Validation loss: 2.52920892628825

Epoch: 6| Step: 11
Training loss: 2.1081243127436666
Validation loss: 2.513266506276331

Epoch: 6| Step: 12
Training loss: 2.081793050398502
Validation loss: 2.539225067411871

Epoch: 6| Step: 13
Training loss: 3.138375914600999
Validation loss: 2.504836886990663

Epoch: 244| Step: 0
Training loss: 2.5924068788083727
Validation loss: 2.5156611564359883

Epoch: 6| Step: 1
Training loss: 1.582395685864846
Validation loss: 2.5458907115191316

Epoch: 6| Step: 2
Training loss: 1.9385224382559585
Validation loss: 2.502984792375868

Epoch: 6| Step: 3
Training loss: 2.355475025579845
Validation loss: 2.5085648371763702

Epoch: 6| Step: 4
Training loss: 1.812060730419585
Validation loss: 2.4921348191516044

Epoch: 6| Step: 5
Training loss: 2.0912255398265516
Validation loss: 2.488413856601935

Epoch: 6| Step: 6
Training loss: 2.9343840935091894
Validation loss: 2.5260945475178618

Epoch: 6| Step: 7
Training loss: 2.3875413341838763
Validation loss: 2.5193675064383028

Epoch: 6| Step: 8
Training loss: 2.1000712609688894
Validation loss: 2.519111775809646

Epoch: 6| Step: 9
Training loss: 2.4497531143668536
Validation loss: 2.491778062054829

Epoch: 6| Step: 10
Training loss: 2.5931487707968763
Validation loss: 2.5196711538343584

Epoch: 6| Step: 11
Training loss: 1.9956645466810394
Validation loss: 2.5417039639180516

Epoch: 6| Step: 12
Training loss: 2.1441377650523488
Validation loss: 2.5472161936252387

Epoch: 6| Step: 13
Training loss: 1.8153276419931537
Validation loss: 2.5575454233808737

Epoch: 245| Step: 0
Training loss: 1.776425973549687
Validation loss: 2.5443837047413322

Epoch: 6| Step: 1
Training loss: 1.9707946453638812
Validation loss: 2.552957709382908

Epoch: 6| Step: 2
Training loss: 1.8465972510809132
Validation loss: 2.5102996218503875

Epoch: 6| Step: 3
Training loss: 2.8532071322164914
Validation loss: 2.4966215511909313

Epoch: 6| Step: 4
Training loss: 1.5705806066794652
Validation loss: 2.502716321281206

Epoch: 6| Step: 5
Training loss: 1.7777105937952185
Validation loss: 2.5131744548640587

Epoch: 6| Step: 6
Training loss: 2.2090863677341006
Validation loss: 2.4992443055188533

Epoch: 6| Step: 7
Training loss: 2.4427094178241417
Validation loss: 2.5030336252997696

Epoch: 6| Step: 8
Training loss: 1.6874145203592645
Validation loss: 2.515868670744083

Epoch: 6| Step: 9
Training loss: 2.864378506822497
Validation loss: 2.5114079703860273

Epoch: 6| Step: 10
Training loss: 2.7934837880125882
Validation loss: 2.519559922166071

Epoch: 6| Step: 11
Training loss: 2.217246177278639
Validation loss: 2.507754094442953

Epoch: 6| Step: 12
Training loss: 2.449021424249262
Validation loss: 2.5020103080780096

Epoch: 6| Step: 13
Training loss: 2.407222996954763
Validation loss: 2.5272061262831538

Epoch: 246| Step: 0
Training loss: 1.7111562649987957
Validation loss: 2.53226129714244

Epoch: 6| Step: 1
Training loss: 1.9283813503994378
Validation loss: 2.547611980254417

Epoch: 6| Step: 2
Training loss: 2.3727593141742145
Validation loss: 2.566577071529343

Epoch: 6| Step: 3
Training loss: 2.100164920143887
Validation loss: 2.5737245555161548

Epoch: 6| Step: 4
Training loss: 1.6192616600381278
Validation loss: 2.5194961900267776

Epoch: 6| Step: 5
Training loss: 2.49578215515277
Validation loss: 2.554352422393089

Epoch: 6| Step: 6
Training loss: 2.2593717371915734
Validation loss: 2.5420630620141815

Epoch: 6| Step: 7
Training loss: 2.9703127311694413
Validation loss: 2.5562128768501053

Epoch: 6| Step: 8
Training loss: 2.1004261220295284
Validation loss: 2.5434964790197387

Epoch: 6| Step: 9
Training loss: 2.3708487923044945
Validation loss: 2.5409389975915615

Epoch: 6| Step: 10
Training loss: 2.1108673468057026
Validation loss: 2.516203519591166

Epoch: 6| Step: 11
Training loss: 1.9356183174567303
Validation loss: 2.5413120965709095

Epoch: 6| Step: 12
Training loss: 2.5588806457412527
Validation loss: 2.5275785719333337

Epoch: 6| Step: 13
Training loss: 2.450428543758252
Validation loss: 2.5473907978135744

Epoch: 247| Step: 0
Training loss: 2.788937605938526
Validation loss: 2.511785210678884

Epoch: 6| Step: 1
Training loss: 2.067071875973812
Validation loss: 2.5280544376467455

Epoch: 6| Step: 2
Training loss: 2.3643630901281742
Validation loss: 2.5339543922939596

Epoch: 6| Step: 3
Training loss: 1.6896846193684483
Validation loss: 2.543476091238897

Epoch: 6| Step: 4
Training loss: 1.8776231853846355
Validation loss: 2.5290555036102287

Epoch: 6| Step: 5
Training loss: 2.1324577735217343
Validation loss: 2.5179015731885186

Epoch: 6| Step: 6
Training loss: 2.0186781123444484
Validation loss: 2.524566476575381

Epoch: 6| Step: 7
Training loss: 2.052915788323465
Validation loss: 2.5102083322864472

Epoch: 6| Step: 8
Training loss: 2.430721737463593
Validation loss: 2.528428534230698

Epoch: 6| Step: 9
Training loss: 2.40182524257066
Validation loss: 2.5030861720178383

Epoch: 6| Step: 10
Training loss: 2.0785831720753594
Validation loss: 2.5250435708948062

Epoch: 6| Step: 11
Training loss: 2.04687965916693
Validation loss: 2.519657275771534

Epoch: 6| Step: 12
Training loss: 2.161495076675332
Validation loss: 2.5202193392559296

Epoch: 6| Step: 13
Training loss: 2.6098921029307762
Validation loss: 2.5153565352399627

Epoch: 248| Step: 0
Training loss: 1.6714506947796413
Validation loss: 2.5211964075170132

Epoch: 6| Step: 1
Training loss: 2.153996713846546
Validation loss: 2.5304661388723324

Epoch: 6| Step: 2
Training loss: 2.240149871376473
Validation loss: 2.5339174697250275

Epoch: 6| Step: 3
Training loss: 1.7280984666108394
Validation loss: 2.5355909980849227

Epoch: 6| Step: 4
Training loss: 2.1627532634276148
Validation loss: 2.5439674928055775

Epoch: 6| Step: 5
Training loss: 2.2089263071915792
Validation loss: 2.548016703760998

Epoch: 6| Step: 6
Training loss: 2.7200674613833233
Validation loss: 2.5081035488696473

Epoch: 6| Step: 7
Training loss: 2.1090427843495827
Validation loss: 2.5544589345800435

Epoch: 6| Step: 8
Training loss: 2.1650588843815206
Validation loss: 2.5401619276861007

Epoch: 6| Step: 9
Training loss: 2.608572282500016
Validation loss: 2.528108932010246

Epoch: 6| Step: 10
Training loss: 1.8640396845813048
Validation loss: 2.5243768508500115

Epoch: 6| Step: 11
Training loss: 2.4872400809360653
Validation loss: 2.5260403557737954

Epoch: 6| Step: 12
Training loss: 1.6349599488045408
Validation loss: 2.526639231891031

Epoch: 6| Step: 13
Training loss: 2.9232982086484114
Validation loss: 2.5530688245018043

Epoch: 249| Step: 0
Training loss: 2.737521557309348
Validation loss: 2.5607106699325493

Epoch: 6| Step: 1
Training loss: 2.687718582135751
Validation loss: 2.5670203524640787

Epoch: 6| Step: 2
Training loss: 1.690248934791296
Validation loss: 2.5839906799593177

Epoch: 6| Step: 3
Training loss: 2.271045383270342
Validation loss: 2.5564663261525093

Epoch: 6| Step: 4
Training loss: 2.465930535902816
Validation loss: 2.5769736291041605

Epoch: 6| Step: 5
Training loss: 2.259118886864747
Validation loss: 2.5543848260887

Epoch: 6| Step: 6
Training loss: 2.240245868949372
Validation loss: 2.5569849445405533

Epoch: 6| Step: 7
Training loss: 1.8323713365171173
Validation loss: 2.5466862552032596

Epoch: 6| Step: 8
Training loss: 1.8035912424965852
Validation loss: 2.55853119984819

Epoch: 6| Step: 9
Training loss: 1.2737045008176493
Validation loss: 2.5303480637152203

Epoch: 6| Step: 10
Training loss: 2.346733127577636
Validation loss: 2.521449389462459

Epoch: 6| Step: 11
Training loss: 2.1487331117650936
Validation loss: 2.537826644218583

Epoch: 6| Step: 12
Training loss: 2.6644448819750903
Validation loss: 2.5339617155851686

Epoch: 6| Step: 13
Training loss: 2.3686589366952413
Validation loss: 2.540892722900704

Epoch: 250| Step: 0
Training loss: 2.1801154697529896
Validation loss: 2.5237162055237015

Epoch: 6| Step: 1
Training loss: 1.7525534393390856
Validation loss: 2.538919626764511

Epoch: 6| Step: 2
Training loss: 2.464770235878758
Validation loss: 2.5438907043883017

Epoch: 6| Step: 3
Training loss: 2.023625898979902
Validation loss: 2.5363198829374785

Epoch: 6| Step: 4
Training loss: 1.8192082276826738
Validation loss: 2.525098334811726

Epoch: 6| Step: 5
Training loss: 2.285193288127992
Validation loss: 2.4927523300766525

Epoch: 6| Step: 6
Training loss: 2.8657642126848257
Validation loss: 2.5619768446040436

Epoch: 6| Step: 7
Training loss: 2.3277044748535882
Validation loss: 2.542808304982817

Epoch: 6| Step: 8
Training loss: 1.20234208828797
Validation loss: 2.5388434525905454

Epoch: 6| Step: 9
Training loss: 1.897302107512246
Validation loss: 2.5245225776060174

Epoch: 6| Step: 10
Training loss: 1.9407758399219073
Validation loss: 2.549041824833753

Epoch: 6| Step: 11
Training loss: 1.7257220263700015
Validation loss: 2.538552382650965

Epoch: 6| Step: 12
Training loss: 2.506539660526779
Validation loss: 2.5258395766337665

Epoch: 6| Step: 13
Training loss: 3.0490161121777195
Validation loss: 2.5601125000036555

Epoch: 251| Step: 0
Training loss: 2.8261370337077922
Validation loss: 2.565505536945945

Epoch: 6| Step: 1
Training loss: 1.7993458221391285
Validation loss: 2.5435300833501113

Epoch: 6| Step: 2
Training loss: 1.5262183216253475
Validation loss: 2.621184452191156

Epoch: 6| Step: 3
Training loss: 2.6679837629976575
Validation loss: 2.602938344551812

Epoch: 6| Step: 4
Training loss: 1.8272943810508864
Validation loss: 2.6271658394119766

Epoch: 6| Step: 5
Training loss: 2.2819753042517985
Validation loss: 2.62771561345003

Epoch: 6| Step: 6
Training loss: 2.297794702866424
Validation loss: 2.6273852818904633

Epoch: 6| Step: 7
Training loss: 2.095538386174228
Validation loss: 2.5225289267074515

Epoch: 6| Step: 8
Training loss: 2.261124554260099
Validation loss: 2.522071255938001

Epoch: 6| Step: 9
Training loss: 2.949329823808611
Validation loss: 2.5508489361243956

Epoch: 6| Step: 10
Training loss: 2.2749741856713874
Validation loss: 2.5337103044549196

Epoch: 6| Step: 11
Training loss: 2.1902772983939416
Validation loss: 2.5381537273415407

Epoch: 6| Step: 12
Training loss: 1.8008748524598848
Validation loss: 2.521135632592917

Epoch: 6| Step: 13
Training loss: 1.9094447895787567
Validation loss: 2.569139237935409

Epoch: 252| Step: 0
Training loss: 2.2527759170472277
Validation loss: 2.518783198059755

Epoch: 6| Step: 1
Training loss: 2.222112874148783
Validation loss: 2.546731761500712

Epoch: 6| Step: 2
Training loss: 2.339564133177792
Validation loss: 2.5016621150670675

Epoch: 6| Step: 3
Training loss: 1.9966901571243167
Validation loss: 2.4776227508632735

Epoch: 6| Step: 4
Training loss: 3.047496712661735
Validation loss: 2.47414394820068

Epoch: 6| Step: 5
Training loss: 1.9200612635573893
Validation loss: 2.4925971735840338

Epoch: 6| Step: 6
Training loss: 1.858957516259172
Validation loss: 2.5134942802919085

Epoch: 6| Step: 7
Training loss: 2.267545110049818
Validation loss: 2.4567300867666138

Epoch: 6| Step: 8
Training loss: 2.2121688594967712
Validation loss: 2.500233321428303

Epoch: 6| Step: 9
Training loss: 1.957564534454784
Validation loss: 2.5318870527698913

Epoch: 6| Step: 10
Training loss: 2.105499097502766
Validation loss: 2.5729192715733324

Epoch: 6| Step: 11
Training loss: 2.4449448964281024
Validation loss: 2.5751713334646293

Epoch: 6| Step: 12
Training loss: 2.1653057617223594
Validation loss: 2.5652058279479166

Epoch: 6| Step: 13
Training loss: 1.829639557325159
Validation loss: 2.559273541636019

Epoch: 253| Step: 0
Training loss: 1.9025052293863498
Validation loss: 2.5477692296021104

Epoch: 6| Step: 1
Training loss: 2.035679257600627
Validation loss: 2.56929718030877

Epoch: 6| Step: 2
Training loss: 2.2993874853800444
Validation loss: 2.5391212965197516

Epoch: 6| Step: 3
Training loss: 1.9440472636187613
Validation loss: 2.525062817084876

Epoch: 6| Step: 4
Training loss: 1.7432309434386097
Validation loss: 2.5519679659763175

Epoch: 6| Step: 5
Training loss: 2.288817096353818
Validation loss: 2.5505802061682212

Epoch: 6| Step: 6
Training loss: 2.7451541861500792
Validation loss: 2.551830362251404

Epoch: 6| Step: 7
Training loss: 2.270872471556687
Validation loss: 2.559851308741347

Epoch: 6| Step: 8
Training loss: 2.410434601721699
Validation loss: 2.5697451876573516

Epoch: 6| Step: 9
Training loss: 2.4289118764572275
Validation loss: 2.5588691543791353

Epoch: 6| Step: 10
Training loss: 1.6705396078529955
Validation loss: 2.5321192249714892

Epoch: 6| Step: 11
Training loss: 1.9938345888184832
Validation loss: 2.5167719120056846

Epoch: 6| Step: 12
Training loss: 2.4729159973537844
Validation loss: 2.5210655646634597

Epoch: 6| Step: 13
Training loss: 2.289732330537308
Validation loss: 2.5267975662649285

Epoch: 254| Step: 0
Training loss: 2.156915202709858
Validation loss: 2.513595204442527

Epoch: 6| Step: 1
Training loss: 2.817843637843304
Validation loss: 2.532893271455582

Epoch: 6| Step: 2
Training loss: 2.2828573547593716
Validation loss: 2.5253965255302537

Epoch: 6| Step: 3
Training loss: 1.8303113074328912
Validation loss: 2.5112273989910916

Epoch: 6| Step: 4
Training loss: 2.7294195121138687
Validation loss: 2.533590937575729

Epoch: 6| Step: 5
Training loss: 1.8038384888661165
Validation loss: 2.515279489487725

Epoch: 6| Step: 6
Training loss: 2.0721406746171533
Validation loss: 2.524886818354072

Epoch: 6| Step: 7
Training loss: 2.6357609118163645
Validation loss: 2.5200748458474997

Epoch: 6| Step: 8
Training loss: 1.8692098861824733
Validation loss: 2.539681547945024

Epoch: 6| Step: 9
Training loss: 2.5268077724212246
Validation loss: 2.5899068710590485

Epoch: 6| Step: 10
Training loss: 1.9532169167824467
Validation loss: 2.5727768575595804

Epoch: 6| Step: 11
Training loss: 1.812767140663221
Validation loss: 2.587938638877509

Epoch: 6| Step: 12
Training loss: 1.7419578503525237
Validation loss: 2.588989116800536

Epoch: 6| Step: 13
Training loss: 2.2864353349668796
Validation loss: 2.616004289224007

Epoch: 255| Step: 0
Training loss: 2.3484592175320254
Validation loss: 2.6067390300221986

Epoch: 6| Step: 1
Training loss: 2.2764528602899006
Validation loss: 2.5981679617925675

Epoch: 6| Step: 2
Training loss: 1.5571550120058038
Validation loss: 2.584807641787672

Epoch: 6| Step: 3
Training loss: 2.4352497571187888
Validation loss: 2.579781295023159

Epoch: 6| Step: 4
Training loss: 1.9227364943033352
Validation loss: 2.5914394857632708

Epoch: 6| Step: 5
Training loss: 2.574371750124079
Validation loss: 2.602351583535658

Epoch: 6| Step: 6
Training loss: 2.18269954927097
Validation loss: 2.5773319296148074

Epoch: 6| Step: 7
Training loss: 2.1235581162352406
Validation loss: 2.562933660269049

Epoch: 6| Step: 8
Training loss: 2.3353080794594896
Validation loss: 2.5458348652470333

Epoch: 6| Step: 9
Training loss: 1.8871154999835915
Validation loss: 2.588294991624568

Epoch: 6| Step: 10
Training loss: 2.3202981145650448
Validation loss: 2.5537436294165

Epoch: 6| Step: 11
Training loss: 1.7691406088281767
Validation loss: 2.593474576490227

Epoch: 6| Step: 12
Training loss: 2.3492350165130946
Validation loss: 2.558400355982244

Epoch: 6| Step: 13
Training loss: 2.1959715156097506
Validation loss: 2.55752110795415

Epoch: 256| Step: 0
Training loss: 3.0095568070203655
Validation loss: 2.532888831702976

Epoch: 6| Step: 1
Training loss: 2.3173471119313382
Validation loss: 2.549466341874178

Epoch: 6| Step: 2
Training loss: 2.756154369676137
Validation loss: 2.5340305644648105

Epoch: 6| Step: 3
Training loss: 1.9185636572796592
Validation loss: 2.5468409717369465

Epoch: 6| Step: 4
Training loss: 1.6737841819594634
Validation loss: 2.54949336036625

Epoch: 6| Step: 5
Training loss: 2.2814397863584515
Validation loss: 2.587807185909197

Epoch: 6| Step: 6
Training loss: 2.0933546006080093
Validation loss: 2.5596995208896365

Epoch: 6| Step: 7
Training loss: 2.5386002809449097
Validation loss: 2.565933756926431

Epoch: 6| Step: 8
Training loss: 1.405759768337263
Validation loss: 2.527539488864088

Epoch: 6| Step: 9
Training loss: 2.6529874624451417
Validation loss: 2.525827203409863

Epoch: 6| Step: 10
Training loss: 1.7088577659574453
Validation loss: 2.551672553394719

Epoch: 6| Step: 11
Training loss: 2.419445172541037
Validation loss: 2.5472430721868524

Epoch: 6| Step: 12
Training loss: 2.184360212677114
Validation loss: 2.5508539677254447

Epoch: 6| Step: 13
Training loss: 1.4056232327203764
Validation loss: 2.5759827469935095

Epoch: 257| Step: 0
Training loss: 2.7766468659969936
Validation loss: 2.6175673935019392

Epoch: 6| Step: 1
Training loss: 2.543795262339412
Validation loss: 2.619966631305571

Epoch: 6| Step: 2
Training loss: 1.58618162183628
Validation loss: 2.5961445016230895

Epoch: 6| Step: 3
Training loss: 2.1622585669012713
Validation loss: 2.600961182285695

Epoch: 6| Step: 4
Training loss: 1.3167614103988574
Validation loss: 2.599541399320427

Epoch: 6| Step: 5
Training loss: 1.8949023325770917
Validation loss: 2.642430367371882

Epoch: 6| Step: 6
Training loss: 2.2833998491757463
Validation loss: 2.5955291222815067

Epoch: 6| Step: 7
Training loss: 1.7729619266576724
Validation loss: 2.5937181953410553

Epoch: 6| Step: 8
Training loss: 2.188146659092296
Validation loss: 2.5643602147622517

Epoch: 6| Step: 9
Training loss: 2.0181131309049203
Validation loss: 2.5240643237492555

Epoch: 6| Step: 10
Training loss: 1.656932762057204
Validation loss: 2.5253986025136226

Epoch: 6| Step: 11
Training loss: 3.0345104811935704
Validation loss: 2.497102528606567

Epoch: 6| Step: 12
Training loss: 2.677477489700936
Validation loss: 2.501820346585695

Epoch: 6| Step: 13
Training loss: 1.929829704203286
Validation loss: 2.4804934282652176

Epoch: 258| Step: 0
Training loss: 2.425970146945265
Validation loss: 2.4970617352595568

Epoch: 6| Step: 1
Training loss: 2.590968651520435
Validation loss: 2.486395424178989

Epoch: 6| Step: 2
Training loss: 1.814622754071354
Validation loss: 2.502333219841302

Epoch: 6| Step: 3
Training loss: 2.406944471935114
Validation loss: 2.5008386317951934

Epoch: 6| Step: 4
Training loss: 1.7766400966959701
Validation loss: 2.5101541141802093

Epoch: 6| Step: 5
Training loss: 2.4056247047350796
Validation loss: 2.5493877941327097

Epoch: 6| Step: 6
Training loss: 2.7025676880439966
Validation loss: 2.578271264445143

Epoch: 6| Step: 7
Training loss: 1.5173125949128454
Validation loss: 2.5780080980711837

Epoch: 6| Step: 8
Training loss: 2.537221669684567
Validation loss: 2.594696760694415

Epoch: 6| Step: 9
Training loss: 2.0367542516894135
Validation loss: 2.595302951832692

Epoch: 6| Step: 10
Training loss: 2.3452847351423243
Validation loss: 2.588295575014085

Epoch: 6| Step: 11
Training loss: 2.3822601178383036
Validation loss: 2.5874328745859434

Epoch: 6| Step: 12
Training loss: 1.6156402410087152
Validation loss: 2.559405761459363

Epoch: 6| Step: 13
Training loss: 2.0841796554695553
Validation loss: 2.56087875252279

Epoch: 259| Step: 0
Training loss: 2.339241064845701
Validation loss: 2.559371014825981

Epoch: 6| Step: 1
Training loss: 2.544813948690015
Validation loss: 2.541571401676399

Epoch: 6| Step: 2
Training loss: 2.0279019272770693
Validation loss: 2.537959292457847

Epoch: 6| Step: 3
Training loss: 2.4099560226290144
Validation loss: 2.5564894703166297

Epoch: 6| Step: 4
Training loss: 1.8249866903159382
Validation loss: 2.53751920307579

Epoch: 6| Step: 5
Training loss: 1.803543587001668
Validation loss: 2.5432788134422974

Epoch: 6| Step: 6
Training loss: 1.7022132883067091
Validation loss: 2.5295627135172234

Epoch: 6| Step: 7
Training loss: 1.9846538437896895
Validation loss: 2.5202477119066344

Epoch: 6| Step: 8
Training loss: 2.141341263607126
Validation loss: 2.517926760441872

Epoch: 6| Step: 9
Training loss: 2.3318864787035727
Validation loss: 2.5527210347129348

Epoch: 6| Step: 10
Training loss: 2.689197093159848
Validation loss: 2.552776387887308

Epoch: 6| Step: 11
Training loss: 2.0319232705189956
Validation loss: 2.559936667990105

Epoch: 6| Step: 12
Training loss: 1.695324594480908
Validation loss: 2.5440235831239226

Epoch: 6| Step: 13
Training loss: 2.5588782232421803
Validation loss: 2.5450809143134183

Epoch: 260| Step: 0
Training loss: 2.6101322560033897
Validation loss: 2.5401885210998527

Epoch: 6| Step: 1
Training loss: 2.1490240232776627
Validation loss: 2.5527151039444904

Epoch: 6| Step: 2
Training loss: 2.033322963792385
Validation loss: 2.5597767199062353

Epoch: 6| Step: 3
Training loss: 2.690752412302463
Validation loss: 2.5537626204114243

Epoch: 6| Step: 4
Training loss: 2.3222754809504895
Validation loss: 2.5598041185550304

Epoch: 6| Step: 5
Training loss: 2.038936216455873
Validation loss: 2.580200161623858

Epoch: 6| Step: 6
Training loss: 2.5590535689810783
Validation loss: 2.5644407598890298

Epoch: 6| Step: 7
Training loss: 2.4505140660537426
Validation loss: 2.542943279492339

Epoch: 6| Step: 8
Training loss: 2.28314402090149
Validation loss: 2.565395285776629

Epoch: 6| Step: 9
Training loss: 2.0474629031070646
Validation loss: 2.5889304244602878

Epoch: 6| Step: 10
Training loss: 1.4288055534609425
Validation loss: 2.5207059581091786

Epoch: 6| Step: 11
Training loss: 1.8547174800001984
Validation loss: 2.554891004632599

Epoch: 6| Step: 12
Training loss: 2.1765174921315675
Validation loss: 2.553514434859304

Epoch: 6| Step: 13
Training loss: 1.6294694471184195
Validation loss: 2.5443427948681054

Epoch: 261| Step: 0
Training loss: 1.796303500637684
Validation loss: 2.5685430463476284

Epoch: 6| Step: 1
Training loss: 2.231727151580489
Validation loss: 2.5481798538767326

Epoch: 6| Step: 2
Training loss: 2.309078675540092
Validation loss: 2.566290114904174

Epoch: 6| Step: 3
Training loss: 2.0582696706628143
Validation loss: 2.537450378383784

Epoch: 6| Step: 4
Training loss: 1.7675236983376434
Validation loss: 2.5319247975031534

Epoch: 6| Step: 5
Training loss: 1.9825295104323435
Validation loss: 2.535396554742274

Epoch: 6| Step: 6
Training loss: 2.3088866175539513
Validation loss: 2.5239778142962614

Epoch: 6| Step: 7
Training loss: 1.9750223303389571
Validation loss: 2.5227665279790696

Epoch: 6| Step: 8
Training loss: 2.385707110140462
Validation loss: 2.51658023050011

Epoch: 6| Step: 9
Training loss: 2.665757431550817
Validation loss: 2.560535251446531

Epoch: 6| Step: 10
Training loss: 1.5614241901895156
Validation loss: 2.523859545802354

Epoch: 6| Step: 11
Training loss: 2.509353496986695
Validation loss: 2.5466817146708833

Epoch: 6| Step: 12
Training loss: 2.2366672308741546
Validation loss: 2.598169934720253

Epoch: 6| Step: 13
Training loss: 2.0026373163926365
Validation loss: 2.6567630945444587

Epoch: 262| Step: 0
Training loss: 2.7866136073882046
Validation loss: 2.668818981104032

Epoch: 6| Step: 1
Training loss: 2.0080979437479067
Validation loss: 2.640147826289747

Epoch: 6| Step: 2
Training loss: 2.3785973459514915
Validation loss: 2.6261330081882295

Epoch: 6| Step: 3
Training loss: 2.0113867624654973
Validation loss: 2.5590207585641522

Epoch: 6| Step: 4
Training loss: 2.4169923847853454
Validation loss: 2.5507884470909663

Epoch: 6| Step: 5
Training loss: 2.32168928715443
Validation loss: 2.505844128057607

Epoch: 6| Step: 6
Training loss: 2.320313322022161
Validation loss: 2.513462361237264

Epoch: 6| Step: 7
Training loss: 1.6943689348597024
Validation loss: 2.498947335192919

Epoch: 6| Step: 8
Training loss: 2.143722631874774
Validation loss: 2.503252107629067

Epoch: 6| Step: 9
Training loss: 1.9707344589540063
Validation loss: 2.4872007474336004

Epoch: 6| Step: 10
Training loss: 2.2611348875994626
Validation loss: 2.4687015110195385

Epoch: 6| Step: 11
Training loss: 1.7560304552013688
Validation loss: 2.463738453097859

Epoch: 6| Step: 12
Training loss: 1.8728258879673318
Validation loss: 2.4797955898674884

Epoch: 6| Step: 13
Training loss: 2.0606338844188783
Validation loss: 2.4940282865560373

Epoch: 263| Step: 0
Training loss: 2.575524330458213
Validation loss: 2.5272169911721387

Epoch: 6| Step: 1
Training loss: 1.9836829473055688
Validation loss: 2.5019433098033956

Epoch: 6| Step: 2
Training loss: 2.2695115001561064
Validation loss: 2.513606918590396

Epoch: 6| Step: 3
Training loss: 1.5383757787423376
Validation loss: 2.5429861573044925

Epoch: 6| Step: 4
Training loss: 1.8701959737810046
Validation loss: 2.571971446840385

Epoch: 6| Step: 5
Training loss: 2.1369725831503956
Validation loss: 2.58730187202708

Epoch: 6| Step: 6
Training loss: 2.1566464709240862
Validation loss: 2.5885216285549135

Epoch: 6| Step: 7
Training loss: 2.0104324524676422
Validation loss: 2.6300090349184826

Epoch: 6| Step: 8
Training loss: 2.1325087558079128
Validation loss: 2.6236471292709083

Epoch: 6| Step: 9
Training loss: 1.8767234510884214
Validation loss: 2.5999093516760103

Epoch: 6| Step: 10
Training loss: 2.167802903988735
Validation loss: 2.57300323979035

Epoch: 6| Step: 11
Training loss: 1.92416146580701
Validation loss: 2.5371886865730766

Epoch: 6| Step: 12
Training loss: 2.2246550303288113
Validation loss: 2.5245252376943705

Epoch: 6| Step: 13
Training loss: 2.7097743284567684
Validation loss: 2.491281637745972

Epoch: 264| Step: 0
Training loss: 2.1725028248934275
Validation loss: 2.510290045070904

Epoch: 6| Step: 1
Training loss: 1.6982781273152183
Validation loss: 2.4943686321078173

Epoch: 6| Step: 2
Training loss: 1.8383805922137024
Validation loss: 2.518098124921423

Epoch: 6| Step: 3
Training loss: 2.581519464277928
Validation loss: 2.5040557546908375

Epoch: 6| Step: 4
Training loss: 1.5525250755656121
Validation loss: 2.509284849910937

Epoch: 6| Step: 5
Training loss: 2.3832327050082003
Validation loss: 2.4992746890454645

Epoch: 6| Step: 6
Training loss: 1.9860487359781225
Validation loss: 2.510817869003519

Epoch: 6| Step: 7
Training loss: 2.079391667098865
Validation loss: 2.51264371793032

Epoch: 6| Step: 8
Training loss: 2.034388186738716
Validation loss: 2.516201687693426

Epoch: 6| Step: 9
Training loss: 1.4162319675789103
Validation loss: 2.5199238473749177

Epoch: 6| Step: 10
Training loss: 1.8515620493184117
Validation loss: 2.5402008791209054

Epoch: 6| Step: 11
Training loss: 2.3654246801021435
Validation loss: 2.5705600762293717

Epoch: 6| Step: 12
Training loss: 2.4092305537166663
Validation loss: 2.5682193693769544

Epoch: 6| Step: 13
Training loss: 2.813095199335583
Validation loss: 2.5653838235961444

Epoch: 265| Step: 0
Training loss: 1.9862161340341116
Validation loss: 2.6169852714789776

Epoch: 6| Step: 1
Training loss: 1.8755836849880387
Validation loss: 2.6219227176851008

Epoch: 6| Step: 2
Training loss: 2.110210225086894
Validation loss: 2.5589734598919933

Epoch: 6| Step: 3
Training loss: 1.9172602508346492
Validation loss: 2.5277586197971313

Epoch: 6| Step: 4
Training loss: 1.4416514449152051
Validation loss: 2.511748333999488

Epoch: 6| Step: 5
Training loss: 1.9841695363764844
Validation loss: 2.5033612860868457

Epoch: 6| Step: 6
Training loss: 2.4611744600079075
Validation loss: 2.5278040031032183

Epoch: 6| Step: 7
Training loss: 2.664017752442192
Validation loss: 2.527840645559094

Epoch: 6| Step: 8
Training loss: 1.5455497690688653
Validation loss: 2.52453902603642

Epoch: 6| Step: 9
Training loss: 2.322392209182744
Validation loss: 2.5199132585356026

Epoch: 6| Step: 10
Training loss: 2.35247399797167
Validation loss: 2.5312612399883867

Epoch: 6| Step: 11
Training loss: 2.552708597206304
Validation loss: 2.543619708349329

Epoch: 6| Step: 12
Training loss: 2.8967138548044766
Validation loss: 2.5238469188332684

Epoch: 6| Step: 13
Training loss: 1.6876650129100803
Validation loss: 2.5307988208188195

Epoch: 266| Step: 0
Training loss: 3.019160594619961
Validation loss: 2.560249161938078

Epoch: 6| Step: 1
Training loss: 1.6835315099837105
Validation loss: 2.5956624651944638

Epoch: 6| Step: 2
Training loss: 2.2442419761300956
Validation loss: 2.5508112299560812

Epoch: 6| Step: 3
Training loss: 1.9815274931747162
Validation loss: 2.5674674260921777

Epoch: 6| Step: 4
Training loss: 1.9758070757389652
Validation loss: 2.5719776576502027

Epoch: 6| Step: 5
Training loss: 1.3939775922580644
Validation loss: 2.568058776670061

Epoch: 6| Step: 6
Training loss: 2.1912377168579873
Validation loss: 2.5443074052278276

Epoch: 6| Step: 7
Training loss: 2.2827370382443757
Validation loss: 2.5065232366589085

Epoch: 6| Step: 8
Training loss: 2.1689247566633423
Validation loss: 2.489051296466742

Epoch: 6| Step: 9
Training loss: 2.047710219177419
Validation loss: 2.4700043626249966

Epoch: 6| Step: 10
Training loss: 2.6197266061842983
Validation loss: 2.474211418189976

Epoch: 6| Step: 11
Training loss: 2.1339343128480532
Validation loss: 2.468492180604625

Epoch: 6| Step: 12
Training loss: 2.2848190189200435
Validation loss: 2.4606250544412296

Epoch: 6| Step: 13
Training loss: 1.8716975056300595
Validation loss: 2.4531826328383737

Epoch: 267| Step: 0
Training loss: 2.49361185250499
Validation loss: 2.474703519255249

Epoch: 6| Step: 1
Training loss: 2.425081259555646
Validation loss: 2.492118364130522

Epoch: 6| Step: 2
Training loss: 1.9981181112438555
Validation loss: 2.492959009731499

Epoch: 6| Step: 3
Training loss: 2.448623706623912
Validation loss: 2.5158511389900102

Epoch: 6| Step: 4
Training loss: 2.0119091943760274
Validation loss: 2.539156367205205

Epoch: 6| Step: 5
Training loss: 2.261704413544804
Validation loss: 2.5524923710424163

Epoch: 6| Step: 6
Training loss: 1.760627154645864
Validation loss: 2.540683889860006

Epoch: 6| Step: 7
Training loss: 1.6132133414174854
Validation loss: 2.548357089621979

Epoch: 6| Step: 8
Training loss: 1.6355894285013852
Validation loss: 2.526150153802919

Epoch: 6| Step: 9
Training loss: 2.356608101019508
Validation loss: 2.519752173385644

Epoch: 6| Step: 10
Training loss: 1.755306644874765
Validation loss: 2.5192259137750272

Epoch: 6| Step: 11
Training loss: 1.9632297203991675
Validation loss: 2.4986689202933934

Epoch: 6| Step: 12
Training loss: 2.3413305382997924
Validation loss: 2.5325117537842985

Epoch: 6| Step: 13
Training loss: 2.3512003166632036
Validation loss: 2.5138922621655766

Epoch: 268| Step: 0
Training loss: 2.207533949594171
Validation loss: 2.5098840351596605

Epoch: 6| Step: 1
Training loss: 2.1901646324879604
Validation loss: 2.523927174584581

Epoch: 6| Step: 2
Training loss: 2.1456406022217673
Validation loss: 2.5637852151734615

Epoch: 6| Step: 3
Training loss: 2.602504800137977
Validation loss: 2.592124076988668

Epoch: 6| Step: 4
Training loss: 2.651417813599307
Validation loss: 2.6210820159422052

Epoch: 6| Step: 5
Training loss: 2.0380631259579287
Validation loss: 2.6566074504817987

Epoch: 6| Step: 6
Training loss: 1.7912845721638675
Validation loss: 2.6850576318088306

Epoch: 6| Step: 7
Training loss: 1.8668675487715705
Validation loss: 2.6713001606976507

Epoch: 6| Step: 8
Training loss: 1.9967028739185202
Validation loss: 2.6574970833399627

Epoch: 6| Step: 9
Training loss: 2.225490807395364
Validation loss: 2.62770725094666

Epoch: 6| Step: 10
Training loss: 1.8833494568306195
Validation loss: 2.603369321191767

Epoch: 6| Step: 11
Training loss: 1.5749531209114918
Validation loss: 2.5578976836998977

Epoch: 6| Step: 12
Training loss: 2.117501210974625
Validation loss: 2.571135059829649

Epoch: 6| Step: 13
Training loss: 2.2312542656181873
Validation loss: 2.5285883437646173

Epoch: 269| Step: 0
Training loss: 1.932147168894294
Validation loss: 2.5080561217498714

Epoch: 6| Step: 1
Training loss: 2.7675160984580756
Validation loss: 2.5294295463967633

Epoch: 6| Step: 2
Training loss: 1.7026757163900372
Validation loss: 2.5106568491995835

Epoch: 6| Step: 3
Training loss: 2.0413431443257504
Validation loss: 2.5178931931630295

Epoch: 6| Step: 4
Training loss: 2.3016936949133475
Validation loss: 2.4969033294967606

Epoch: 6| Step: 5
Training loss: 2.0573467263366583
Validation loss: 2.508295062291717

Epoch: 6| Step: 6
Training loss: 1.993425889412699
Validation loss: 2.5058058794693556

Epoch: 6| Step: 7
Training loss: 2.0655587374725557
Validation loss: 2.5242870306227005

Epoch: 6| Step: 8
Training loss: 2.1137680085428507
Validation loss: 2.523761614287357

Epoch: 6| Step: 9
Training loss: 2.028893145143228
Validation loss: 2.53097658289749

Epoch: 6| Step: 10
Training loss: 1.439057542955971
Validation loss: 2.542420921558773

Epoch: 6| Step: 11
Training loss: 1.6546476278283035
Validation loss: 2.527388456834568

Epoch: 6| Step: 12
Training loss: 2.3571976473662066
Validation loss: 2.5354029883645515

Epoch: 6| Step: 13
Training loss: 2.8111134820190133
Validation loss: 2.5540891485186514

Epoch: 270| Step: 0
Training loss: 2.0941810733508595
Validation loss: 2.566514228240828

Epoch: 6| Step: 1
Training loss: 1.7435904699931062
Validation loss: 2.5637343930358845

Epoch: 6| Step: 2
Training loss: 2.4141488167846075
Validation loss: 2.610393683192055

Epoch: 6| Step: 3
Training loss: 2.2424958445702945
Validation loss: 2.6325866723109823

Epoch: 6| Step: 4
Training loss: 1.9082697190033404
Validation loss: 2.6298777205659567

Epoch: 6| Step: 5
Training loss: 1.648497232376381
Validation loss: 2.5986320785183104

Epoch: 6| Step: 6
Training loss: 2.142271202449912
Validation loss: 2.548931220102303

Epoch: 6| Step: 7
Training loss: 2.184104463908523
Validation loss: 2.5182652962323995

Epoch: 6| Step: 8
Training loss: 2.0867133251535273
Validation loss: 2.5325553887483783

Epoch: 6| Step: 9
Training loss: 2.3462479567684
Validation loss: 2.4706540551420426

Epoch: 6| Step: 10
Training loss: 2.136969124527673
Validation loss: 2.50022233133334

Epoch: 6| Step: 11
Training loss: 2.2364042444059553
Validation loss: 2.4924237608656603

Epoch: 6| Step: 12
Training loss: 2.152320487836521
Validation loss: 2.476372375571101

Epoch: 6| Step: 13
Training loss: 2.2805953458205104
Validation loss: 2.4783725321461083

Epoch: 271| Step: 0
Training loss: 2.2460481058541544
Validation loss: 2.4580507169870764

Epoch: 6| Step: 1
Training loss: 2.3685241551293914
Validation loss: 2.4983628634624067

Epoch: 6| Step: 2
Training loss: 1.8089441738550545
Validation loss: 2.5486882157980926

Epoch: 6| Step: 3
Training loss: 1.740372058289731
Validation loss: 2.5846589337999823

Epoch: 6| Step: 4
Training loss: 2.280479614608305
Validation loss: 2.5862143407729135

Epoch: 6| Step: 5
Training loss: 1.9025123098529075
Validation loss: 2.589311931583864

Epoch: 6| Step: 6
Training loss: 2.70027089349465
Validation loss: 2.548388400093063

Epoch: 6| Step: 7
Training loss: 2.4785646835053194
Validation loss: 2.5947078942969846

Epoch: 6| Step: 8
Training loss: 1.9404983086012222
Validation loss: 2.5713298450041138

Epoch: 6| Step: 9
Training loss: 2.0238401976966927
Validation loss: 2.5931995068108087

Epoch: 6| Step: 10
Training loss: 2.3950204769525403
Validation loss: 2.557894460226793

Epoch: 6| Step: 11
Training loss: 1.9550055643768345
Validation loss: 2.521223689559662

Epoch: 6| Step: 12
Training loss: 1.9494258793498611
Validation loss: 2.535405676218963

Epoch: 6| Step: 13
Training loss: 2.0584285894223937
Validation loss: 2.557388650851113

Epoch: 272| Step: 0
Training loss: 2.644679731654879
Validation loss: 2.572921835293128

Epoch: 6| Step: 1
Training loss: 2.3569556962884044
Validation loss: 2.569448323862624

Epoch: 6| Step: 2
Training loss: 2.324405027986917
Validation loss: 2.5437642546183272

Epoch: 6| Step: 3
Training loss: 1.7393935855773084
Validation loss: 2.5972065854296007

Epoch: 6| Step: 4
Training loss: 1.7835900178419943
Validation loss: 2.5701752754537086

Epoch: 6| Step: 5
Training loss: 1.6807046338980118
Validation loss: 2.5720477985906216

Epoch: 6| Step: 6
Training loss: 2.553788053030205
Validation loss: 2.567613307182359

Epoch: 6| Step: 7
Training loss: 2.5098687889181477
Validation loss: 2.570371802978328

Epoch: 6| Step: 8
Training loss: 2.011145530438932
Validation loss: 2.5238180198402187

Epoch: 6| Step: 9
Training loss: 1.3718457021169947
Validation loss: 2.5253008723013894

Epoch: 6| Step: 10
Training loss: 1.7879001889713746
Validation loss: 2.531677210042704

Epoch: 6| Step: 11
Training loss: 2.2075181812129525
Validation loss: 2.508030835369239

Epoch: 6| Step: 12
Training loss: 1.9138306769290836
Validation loss: 2.5522191277531663

Epoch: 6| Step: 13
Training loss: 2.1483355133818978
Validation loss: 2.561785621619513

Epoch: 273| Step: 0
Training loss: 1.5865303021556831
Validation loss: 2.545035417531406

Epoch: 6| Step: 1
Training loss: 1.8940746897720746
Validation loss: 2.560985908725734

Epoch: 6| Step: 2
Training loss: 2.140682136162947
Validation loss: 2.549184847797339

Epoch: 6| Step: 3
Training loss: 2.7889641923435153
Validation loss: 2.540952196436445

Epoch: 6| Step: 4
Training loss: 2.4264358399022945
Validation loss: 2.5691019084793902

Epoch: 6| Step: 5
Training loss: 2.0882991608758887
Validation loss: 2.573753735572163

Epoch: 6| Step: 6
Training loss: 2.480660306487541
Validation loss: 2.56152864979931

Epoch: 6| Step: 7
Training loss: 1.9855173982709569
Validation loss: 2.535536821245811

Epoch: 6| Step: 8
Training loss: 2.376695128382344
Validation loss: 2.527414076237905

Epoch: 6| Step: 9
Training loss: 1.616150085594426
Validation loss: 2.502636798456684

Epoch: 6| Step: 10
Training loss: 1.3464683715471308
Validation loss: 2.4991059294016416

Epoch: 6| Step: 11
Training loss: 1.7598736694903154
Validation loss: 2.494455093159516

Epoch: 6| Step: 12
Training loss: 2.4679017360050337
Validation loss: 2.511001634837026

Epoch: 6| Step: 13
Training loss: 2.05824163852987
Validation loss: 2.521528263827992

Epoch: 274| Step: 0
Training loss: 2.354910865117341
Validation loss: 2.533037425837358

Epoch: 6| Step: 1
Training loss: 2.809569633624353
Validation loss: 2.5383870952904943

Epoch: 6| Step: 2
Training loss: 1.4813025549727836
Validation loss: 2.576275958122164

Epoch: 6| Step: 3
Training loss: 2.0333369171652973
Validation loss: 2.601767943311256

Epoch: 6| Step: 4
Training loss: 2.1738368991287436
Validation loss: 2.5573496970580316

Epoch: 6| Step: 5
Training loss: 1.7731649718755929
Validation loss: 2.5730251696072495

Epoch: 6| Step: 6
Training loss: 2.3938022020190717
Validation loss: 2.53415304670988

Epoch: 6| Step: 7
Training loss: 2.5630065603362033
Validation loss: 2.527605203413081

Epoch: 6| Step: 8
Training loss: 1.5926185780548352
Validation loss: 2.526628144338777

Epoch: 6| Step: 9
Training loss: 1.7309091666293
Validation loss: 2.518731964841882

Epoch: 6| Step: 10
Training loss: 1.729076712539756
Validation loss: 2.5283260961775613

Epoch: 6| Step: 11
Training loss: 2.1360606517324454
Validation loss: 2.5291345649789374

Epoch: 6| Step: 12
Training loss: 1.8942122043294192
Validation loss: 2.5301557616835235

Epoch: 6| Step: 13
Training loss: 1.930115687011165
Validation loss: 2.565989312880856

Epoch: 275| Step: 0
Training loss: 1.992542908324966
Validation loss: 2.5650867958577965

Epoch: 6| Step: 1
Training loss: 2.239906985531544
Validation loss: 2.5915097286221584

Epoch: 6| Step: 2
Training loss: 2.0442861244617867
Validation loss: 2.5720838570873625

Epoch: 6| Step: 3
Training loss: 1.9760035150357693
Validation loss: 2.585814873591271

Epoch: 6| Step: 4
Training loss: 1.7131798390208883
Validation loss: 2.5688749736200376

Epoch: 6| Step: 5
Training loss: 2.395874940814972
Validation loss: 2.568920419427809

Epoch: 6| Step: 6
Training loss: 1.8077397152979133
Validation loss: 2.6044599266233104

Epoch: 6| Step: 7
Training loss: 2.2080425814793463
Validation loss: 2.5907311393612997

Epoch: 6| Step: 8
Training loss: 1.8869813219044613
Validation loss: 2.545076058655823

Epoch: 6| Step: 9
Training loss: 2.0940531041535544
Validation loss: 2.5973477670401013

Epoch: 6| Step: 10
Training loss: 1.8638902224848461
Validation loss: 2.5727955922251122

Epoch: 6| Step: 11
Training loss: 2.053308640719645
Validation loss: 2.546363123842027

Epoch: 6| Step: 12
Training loss: 2.657278243364569
Validation loss: 2.578082691192259

Epoch: 6| Step: 13
Training loss: 1.332742271943335
Validation loss: 2.50953380736199

Epoch: 276| Step: 0
Training loss: 2.020585454570935
Validation loss: 2.5280994855664414

Epoch: 6| Step: 1
Training loss: 2.3475051298075273
Validation loss: 2.515496813428419

Epoch: 6| Step: 2
Training loss: 1.7519723812478185
Validation loss: 2.5139471899710664

Epoch: 6| Step: 3
Training loss: 1.7141668074105068
Validation loss: 2.51986323099015

Epoch: 6| Step: 4
Training loss: 1.4919334315158659
Validation loss: 2.482180788031967

Epoch: 6| Step: 5
Training loss: 1.6357824884261136
Validation loss: 2.4940579370041798

Epoch: 6| Step: 6
Training loss: 1.8954425311159997
Validation loss: 2.4963357456885142

Epoch: 6| Step: 7
Training loss: 2.360910888360321
Validation loss: 2.488660016019396

Epoch: 6| Step: 8
Training loss: 2.6643143252381902
Validation loss: 2.529240300983081

Epoch: 6| Step: 9
Training loss: 1.970733612096935
Validation loss: 2.5595270449384517

Epoch: 6| Step: 10
Training loss: 2.282473510387921
Validation loss: 2.561580865283864

Epoch: 6| Step: 11
Training loss: 1.9996685707137059
Validation loss: 2.583921216912263

Epoch: 6| Step: 12
Training loss: 2.1582455453975844
Validation loss: 2.586473975951731

Epoch: 6| Step: 13
Training loss: 2.221183194866252
Validation loss: 2.6405855962157094

Epoch: 277| Step: 0
Training loss: 2.319896519424917
Validation loss: 2.590117266036496

Epoch: 6| Step: 1
Training loss: 2.4928179574260865
Validation loss: 2.5220032071247727

Epoch: 6| Step: 2
Training loss: 1.58218413191182
Validation loss: 2.5819209657663706

Epoch: 6| Step: 3
Training loss: 1.5712760132887293
Validation loss: 2.578965868757196

Epoch: 6| Step: 4
Training loss: 2.0022101111733175
Validation loss: 2.583288658945335

Epoch: 6| Step: 5
Training loss: 1.9582088985544437
Validation loss: 2.6152647480567204

Epoch: 6| Step: 6
Training loss: 1.8192086863794348
Validation loss: 2.534714310051633

Epoch: 6| Step: 7
Training loss: 2.1866132846379527
Validation loss: 2.54423351644418

Epoch: 6| Step: 8
Training loss: 2.3039604462632504
Validation loss: 2.5378318738720447

Epoch: 6| Step: 9
Training loss: 1.7876832801383078
Validation loss: 2.5680681689663083

Epoch: 6| Step: 10
Training loss: 2.381121326083837
Validation loss: 2.5498424475124

Epoch: 6| Step: 11
Training loss: 1.7115420314253733
Validation loss: 2.5874926298223873

Epoch: 6| Step: 12
Training loss: 2.195128735219092
Validation loss: 2.5826562691523387

Epoch: 6| Step: 13
Training loss: 1.9168144528453877
Validation loss: 2.575122140253016

Epoch: 278| Step: 0
Training loss: 1.518418245226836
Validation loss: 2.6094980572524364

Epoch: 6| Step: 1
Training loss: 2.013535473678019
Validation loss: 2.563909623638643

Epoch: 6| Step: 2
Training loss: 1.4171473117837463
Validation loss: 2.5571729291916987

Epoch: 6| Step: 3
Training loss: 2.069333402768032
Validation loss: 2.5338098744947852

Epoch: 6| Step: 4
Training loss: 2.2402705594560293
Validation loss: 2.5460364086447576

Epoch: 6| Step: 5
Training loss: 2.545922036714559
Validation loss: 2.5198230978519467

Epoch: 6| Step: 6
Training loss: 2.231335686926982
Validation loss: 2.527328027345157

Epoch: 6| Step: 7
Training loss: 2.2091652604708614
Validation loss: 2.5038609731213786

Epoch: 6| Step: 8
Training loss: 1.679111683641853
Validation loss: 2.526011127929661

Epoch: 6| Step: 9
Training loss: 1.5408093758029433
Validation loss: 2.5589285206850985

Epoch: 6| Step: 10
Training loss: 1.4598848354956484
Validation loss: 2.5571088136353777

Epoch: 6| Step: 11
Training loss: 2.4404742361630225
Validation loss: 2.5401397376157244

Epoch: 6| Step: 12
Training loss: 2.448786306457716
Validation loss: 2.5048173426152105

Epoch: 6| Step: 13
Training loss: 2.3177572752396376
Validation loss: 2.539075333000422

Epoch: 279| Step: 0
Training loss: 1.9307820540220657
Validation loss: 2.5580089104521817

Epoch: 6| Step: 1
Training loss: 1.8425888025630706
Validation loss: 2.5318213551894018

Epoch: 6| Step: 2
Training loss: 2.162475003665821
Validation loss: 2.545858496267412

Epoch: 6| Step: 3
Training loss: 2.0484270806996885
Validation loss: 2.507272323472504

Epoch: 6| Step: 4
Training loss: 1.9301799192222593
Validation loss: 2.5204053993706887

Epoch: 6| Step: 5
Training loss: 2.294246700880163
Validation loss: 2.5157704281679325

Epoch: 6| Step: 6
Training loss: 1.8600825398086835
Validation loss: 2.475645631651061

Epoch: 6| Step: 7
Training loss: 1.9494882523446155
Validation loss: 2.469759786896966

Epoch: 6| Step: 8
Training loss: 2.400580526713148
Validation loss: 2.494301994120058

Epoch: 6| Step: 9
Training loss: 1.8889299470827292
Validation loss: 2.496670715479842

Epoch: 6| Step: 10
Training loss: 1.697089885221678
Validation loss: 2.5451742785325004

Epoch: 6| Step: 11
Training loss: 1.3855865584681784
Validation loss: 2.514539211826879

Epoch: 6| Step: 12
Training loss: 2.2388960974140515
Validation loss: 2.554079735932418

Epoch: 6| Step: 13
Training loss: 2.9381643315133092
Validation loss: 2.5271494111188133

Epoch: 280| Step: 0
Training loss: 1.9517472557653497
Validation loss: 2.5263393633057

Epoch: 6| Step: 1
Training loss: 2.642472472972284
Validation loss: 2.5371823201254076

Epoch: 6| Step: 2
Training loss: 1.9322395900347682
Validation loss: 2.5321542592483373

Epoch: 6| Step: 3
Training loss: 1.5627056749398647
Validation loss: 2.5614758437526315

Epoch: 6| Step: 4
Training loss: 1.8982763025739158
Validation loss: 2.522321692529818

Epoch: 6| Step: 5
Training loss: 1.8386311351703069
Validation loss: 2.544394238595327

Epoch: 6| Step: 6
Training loss: 2.271348130788804
Validation loss: 2.5348462589752114

Epoch: 6| Step: 7
Training loss: 1.822554619576355
Validation loss: 2.5758826551607625

Epoch: 6| Step: 8
Training loss: 2.033059942387238
Validation loss: 2.548637279707613

Epoch: 6| Step: 9
Training loss: 1.9923195589463873
Validation loss: 2.578844313025581

Epoch: 6| Step: 10
Training loss: 1.4798489282159166
Validation loss: 2.5946941572316264

Epoch: 6| Step: 11
Training loss: 2.087414622131286
Validation loss: 2.5821852183640637

Epoch: 6| Step: 12
Training loss: 2.7354976420293875
Validation loss: 2.617765478584888

Epoch: 6| Step: 13
Training loss: 2.1883443020470423
Validation loss: 2.596932018157495

Epoch: 281| Step: 0
Training loss: 1.8232256454918772
Validation loss: 2.6008079053040527

Epoch: 6| Step: 1
Training loss: 1.7207326377736498
Validation loss: 2.6381321714403634

Epoch: 6| Step: 2
Training loss: 1.952684581691775
Validation loss: 2.6118543499339233

Epoch: 6| Step: 3
Training loss: 2.764164080782963
Validation loss: 2.6459528578145872

Epoch: 6| Step: 4
Training loss: 2.2777668738168795
Validation loss: 2.621025164143179

Epoch: 6| Step: 5
Training loss: 1.9876760824644617
Validation loss: 2.630777751861903

Epoch: 6| Step: 6
Training loss: 1.943648212380363
Validation loss: 2.6662719901397627

Epoch: 6| Step: 7
Training loss: 2.4131436373868516
Validation loss: 2.605368639439626

Epoch: 6| Step: 8
Training loss: 1.6989188795656143
Validation loss: 2.585703459844731

Epoch: 6| Step: 9
Training loss: 2.0461002659994327
Validation loss: 2.543130434895606

Epoch: 6| Step: 10
Training loss: 1.6988066074800627
Validation loss: 2.5234777173753535

Epoch: 6| Step: 11
Training loss: 1.850577563264364
Validation loss: 2.56251773983157

Epoch: 6| Step: 12
Training loss: 2.0193381005011872
Validation loss: 2.5233788576978933

Epoch: 6| Step: 13
Training loss: 2.274794969646861
Validation loss: 2.5163130678098686

Epoch: 282| Step: 0
Training loss: 2.5812534655531554
Validation loss: 2.4910486901959956

Epoch: 6| Step: 1
Training loss: 1.8722726695618437
Validation loss: 2.5115065734694224

Epoch: 6| Step: 2
Training loss: 2.11362035713586
Validation loss: 2.5469342870384115

Epoch: 6| Step: 3
Training loss: 2.2012287393179
Validation loss: 2.6352506492301995

Epoch: 6| Step: 4
Training loss: 1.9925049173636646
Validation loss: 2.618910310704652

Epoch: 6| Step: 5
Training loss: 2.1845336419865893
Validation loss: 2.598486646660362

Epoch: 6| Step: 6
Training loss: 1.905923909296634
Validation loss: 2.5405385896159016

Epoch: 6| Step: 7
Training loss: 1.9566648829428728
Validation loss: 2.4751772932650273

Epoch: 6| Step: 8
Training loss: 1.9015778991527064
Validation loss: 2.4703344580172883

Epoch: 6| Step: 9
Training loss: 1.9611255813919695
Validation loss: 2.4800851760614218

Epoch: 6| Step: 10
Training loss: 2.3867838799163845
Validation loss: 2.5063340769908415

Epoch: 6| Step: 11
Training loss: 1.9612609474941496
Validation loss: 2.5050783949772084

Epoch: 6| Step: 12
Training loss: 1.49316941154924
Validation loss: 2.530026143910221

Epoch: 6| Step: 13
Training loss: 2.790571985029519
Validation loss: 2.5205700529292243

Epoch: 283| Step: 0
Training loss: 1.2157076496182007
Validation loss: 2.524371971109035

Epoch: 6| Step: 1
Training loss: 1.9350040725546866
Validation loss: 2.5207340651794183

Epoch: 6| Step: 2
Training loss: 1.7504293732460776
Validation loss: 2.562281451946339

Epoch: 6| Step: 3
Training loss: 2.0804368547035237
Validation loss: 2.5228106622662847

Epoch: 6| Step: 4
Training loss: 2.2713587325191
Validation loss: 2.547656510785996

Epoch: 6| Step: 5
Training loss: 1.6376214280860777
Validation loss: 2.586067665104835

Epoch: 6| Step: 6
Training loss: 2.1620284343617615
Validation loss: 2.6117008526221452

Epoch: 6| Step: 7
Training loss: 2.5405665241939603
Validation loss: 2.5989221074720947

Epoch: 6| Step: 8
Training loss: 2.133695314910003
Validation loss: 2.642183389478148

Epoch: 6| Step: 9
Training loss: 2.0349493525620423
Validation loss: 2.6246903403363273

Epoch: 6| Step: 10
Training loss: 1.9593592519902994
Validation loss: 2.5918555790860647

Epoch: 6| Step: 11
Training loss: 2.252513541160806
Validation loss: 2.5983220291707427

Epoch: 6| Step: 12
Training loss: 1.6140465941480917
Validation loss: 2.574344429340263

Epoch: 6| Step: 13
Training loss: 2.647761345806707
Validation loss: 2.5535941238868323

Epoch: 284| Step: 0
Training loss: 2.468286591507344
Validation loss: 2.552499890229375

Epoch: 6| Step: 1
Training loss: 2.076885570828688
Validation loss: 2.5868971811974752

Epoch: 6| Step: 2
Training loss: 2.1559188146150543
Validation loss: 2.598739757532948

Epoch: 6| Step: 3
Training loss: 1.6686951531815837
Validation loss: 2.6009300616398336

Epoch: 6| Step: 4
Training loss: 1.8760912580641154
Validation loss: 2.564310132330516

Epoch: 6| Step: 5
Training loss: 2.0395156532205005
Validation loss: 2.6077653256266076

Epoch: 6| Step: 6
Training loss: 1.5568417140445303
Validation loss: 2.5976304743738026

Epoch: 6| Step: 7
Training loss: 1.6687805915914513
Validation loss: 2.5855514145952627

Epoch: 6| Step: 8
Training loss: 2.290533953388593
Validation loss: 2.562295316259391

Epoch: 6| Step: 9
Training loss: 2.3496904493948336
Validation loss: 2.526151522315577

Epoch: 6| Step: 10
Training loss: 2.1263282215188326
Validation loss: 2.5279423487775348

Epoch: 6| Step: 11
Training loss: 1.8473387882992343
Validation loss: 2.5437625519163984

Epoch: 6| Step: 12
Training loss: 2.238229481363043
Validation loss: 2.5227582743721375

Epoch: 6| Step: 13
Training loss: 1.3582836023053826
Validation loss: 2.5337214707968885

Epoch: 285| Step: 0
Training loss: 2.1210424933378684
Validation loss: 2.5244346671920628

Epoch: 6| Step: 1
Training loss: 2.2393739705957745
Validation loss: 2.5607392689586406

Epoch: 6| Step: 2
Training loss: 1.5319226402989792
Validation loss: 2.5798522403702013

Epoch: 6| Step: 3
Training loss: 1.9462997198889724
Validation loss: 2.5804451030033073

Epoch: 6| Step: 4
Training loss: 1.75560978525372
Validation loss: 2.5578673595898533

Epoch: 6| Step: 5
Training loss: 1.3475078998680896
Validation loss: 2.604477037372158

Epoch: 6| Step: 6
Training loss: 1.6420320562516235
Validation loss: 2.5566956601826094

Epoch: 6| Step: 7
Training loss: 2.0701551845449035
Validation loss: 2.529735206121184

Epoch: 6| Step: 8
Training loss: 1.5673866913649435
Validation loss: 2.5323393640036724

Epoch: 6| Step: 9
Training loss: 2.777541441930148
Validation loss: 2.5690418414852254

Epoch: 6| Step: 10
Training loss: 2.3133702058446137
Validation loss: 2.5405966012266066

Epoch: 6| Step: 11
Training loss: 2.23136250615641
Validation loss: 2.53164395064944

Epoch: 6| Step: 12
Training loss: 2.058351679834721
Validation loss: 2.553287102834369

Epoch: 6| Step: 13
Training loss: 1.89779149747848
Validation loss: 2.546179662852542

Epoch: 286| Step: 0
Training loss: 1.1789875606660407
Validation loss: 2.5529279647617824

Epoch: 6| Step: 1
Training loss: 2.1768201337324133
Validation loss: 2.5945713780229136

Epoch: 6| Step: 2
Training loss: 1.5292610173997043
Validation loss: 2.596377868442127

Epoch: 6| Step: 3
Training loss: 1.886674268367986
Validation loss: 2.5902238032831377

Epoch: 6| Step: 4
Training loss: 1.8906980137873948
Validation loss: 2.556638417972771

Epoch: 6| Step: 5
Training loss: 2.1370445435468852
Validation loss: 2.5600406195726064

Epoch: 6| Step: 6
Training loss: 2.608519819456723
Validation loss: 2.495922832975274

Epoch: 6| Step: 7
Training loss: 1.3853249866104422
Validation loss: 2.495792058264818

Epoch: 6| Step: 8
Training loss: 2.190708967441658
Validation loss: 2.5165168334450474

Epoch: 6| Step: 9
Training loss: 2.2173954227048283
Validation loss: 2.5117191613307237

Epoch: 6| Step: 10
Training loss: 1.9535193083418898
Validation loss: 2.528205296294747

Epoch: 6| Step: 11
Training loss: 2.531890976365043
Validation loss: 2.5376981541978254

Epoch: 6| Step: 12
Training loss: 1.3638324661566017
Validation loss: 2.5387553180818565

Epoch: 6| Step: 13
Training loss: 2.3986726825731264
Validation loss: 2.605563625760607

Epoch: 287| Step: 0
Training loss: 1.7748566045731342
Validation loss: 2.5698853884768913

Epoch: 6| Step: 1
Training loss: 1.8319821869679629
Validation loss: 2.5510030263516192

Epoch: 6| Step: 2
Training loss: 2.270252526811047
Validation loss: 2.551954512686016

Epoch: 6| Step: 3
Training loss: 2.3593215431068972
Validation loss: 2.5447849520827495

Epoch: 6| Step: 4
Training loss: 1.2951583071091881
Validation loss: 2.5548651708324277

Epoch: 6| Step: 5
Training loss: 2.3994655331908192
Validation loss: 2.5235768881015535

Epoch: 6| Step: 6
Training loss: 1.8324808898803648
Validation loss: 2.514016120693058

Epoch: 6| Step: 7
Training loss: 2.338507931698897
Validation loss: 2.522717383967

Epoch: 6| Step: 8
Training loss: 1.4728501897951434
Validation loss: 2.5696163142919555

Epoch: 6| Step: 9
Training loss: 1.761586051053977
Validation loss: 2.5785841715962885

Epoch: 6| Step: 10
Training loss: 1.950162792746516
Validation loss: 2.640095358556876

Epoch: 6| Step: 11
Training loss: 2.4534785507940646
Validation loss: 2.641400089913013

Epoch: 6| Step: 12
Training loss: 2.2952966781704522
Validation loss: 2.6467380678921555

Epoch: 6| Step: 13
Training loss: 1.700066436142595
Validation loss: 2.5740892670038455

Epoch: 288| Step: 0
Training loss: 2.1738285637072785
Validation loss: 2.5844145993601146

Epoch: 6| Step: 1
Training loss: 1.4517146824291258
Validation loss: 2.56168278014212

Epoch: 6| Step: 2
Training loss: 2.3153375279858777
Validation loss: 2.5076497659934742

Epoch: 6| Step: 3
Training loss: 1.6689307411410415
Validation loss: 2.52146771753208

Epoch: 6| Step: 4
Training loss: 1.614344433573756
Validation loss: 2.487540030357015

Epoch: 6| Step: 5
Training loss: 1.9395471648037568
Validation loss: 2.5009001224051906

Epoch: 6| Step: 6
Training loss: 2.489838261234684
Validation loss: 2.5003995337712692

Epoch: 6| Step: 7
Training loss: 2.119412087487503
Validation loss: 2.5258219095708236

Epoch: 6| Step: 8
Training loss: 2.8121900599620946
Validation loss: 2.548513310698601

Epoch: 6| Step: 9
Training loss: 1.9386468999861548
Validation loss: 2.6210830620037537

Epoch: 6| Step: 10
Training loss: 1.8745451693420692
Validation loss: 2.639865216682234

Epoch: 6| Step: 11
Training loss: 2.3993866375111557
Validation loss: 2.6627548677842103

Epoch: 6| Step: 12
Training loss: 1.8948029313496226
Validation loss: 2.65339261619756

Epoch: 6| Step: 13
Training loss: 1.5553667127938318
Validation loss: 2.6335138279185037

Epoch: 289| Step: 0
Training loss: 1.5932136830025094
Validation loss: 2.5954070715349986

Epoch: 6| Step: 1
Training loss: 1.352799615655435
Validation loss: 2.5796660470330433

Epoch: 6| Step: 2
Training loss: 2.2317118746352405
Validation loss: 2.559710449667279

Epoch: 6| Step: 3
Training loss: 2.201016979978752
Validation loss: 2.534201482876328

Epoch: 6| Step: 4
Training loss: 1.6803336386674965
Validation loss: 2.539862935981265

Epoch: 6| Step: 5
Training loss: 2.809067729911557
Validation loss: 2.499523944033681

Epoch: 6| Step: 6
Training loss: 2.0328696029583
Validation loss: 2.486938241884865

Epoch: 6| Step: 7
Training loss: 2.180326525356152
Validation loss: 2.4910654314356018

Epoch: 6| Step: 8
Training loss: 1.6808457750128838
Validation loss: 2.4907066545618686

Epoch: 6| Step: 9
Training loss: 1.7047776769183471
Validation loss: 2.5043886288376047

Epoch: 6| Step: 10
Training loss: 1.702409226382501
Validation loss: 2.551454759897775

Epoch: 6| Step: 11
Training loss: 2.400608633274101
Validation loss: 2.598924890174331

Epoch: 6| Step: 12
Training loss: 1.85568852779384
Validation loss: 2.6164069990428676

Epoch: 6| Step: 13
Training loss: 2.0725242460555875
Validation loss: 2.6349135862316553

Epoch: 290| Step: 0
Training loss: 1.7835147581182325
Validation loss: 2.645455390990024

Epoch: 6| Step: 1
Training loss: 2.161893011913054
Validation loss: 2.638242139254341

Epoch: 6| Step: 2
Training loss: 2.6235909994725604
Validation loss: 2.562959738327959

Epoch: 6| Step: 3
Training loss: 2.0838410203959685
Validation loss: 2.524732952033796

Epoch: 6| Step: 4
Training loss: 2.07345020833609
Validation loss: 2.5040762730012625

Epoch: 6| Step: 5
Training loss: 1.6847640570198332
Validation loss: 2.5187202193122205

Epoch: 6| Step: 6
Training loss: 1.6220680342445244
Validation loss: 2.4646156153065473

Epoch: 6| Step: 7
Training loss: 2.208663795744902
Validation loss: 2.4897718451300936

Epoch: 6| Step: 8
Training loss: 1.979844756831751
Validation loss: 2.4874814363486615

Epoch: 6| Step: 9
Training loss: 1.4916774816849132
Validation loss: 2.4899677846987265

Epoch: 6| Step: 10
Training loss: 2.1307256640922447
Validation loss: 2.4970072794390434

Epoch: 6| Step: 11
Training loss: 1.6802360171335171
Validation loss: 2.484740496286833

Epoch: 6| Step: 12
Training loss: 2.2040734380128555
Validation loss: 2.504636470586596

Epoch: 6| Step: 13
Training loss: 1.4819436489310847
Validation loss: 2.527302391346675

Epoch: 291| Step: 0
Training loss: 1.8880460189367214
Validation loss: 2.5206944345927114

Epoch: 6| Step: 1
Training loss: 2.071375390483526
Validation loss: 2.5572833017703194

Epoch: 6| Step: 2
Training loss: 2.186279610400068
Validation loss: 2.5238756443091064

Epoch: 6| Step: 3
Training loss: 1.565964862536466
Validation loss: 2.5220650246400615

Epoch: 6| Step: 4
Training loss: 1.984752649130821
Validation loss: 2.583931105168661

Epoch: 6| Step: 5
Training loss: 2.427734964237157
Validation loss: 2.5338926060823157

Epoch: 6| Step: 6
Training loss: 2.1237093427963876
Validation loss: 2.5429799850692274

Epoch: 6| Step: 7
Training loss: 1.3227849979907633
Validation loss: 2.509175264066547

Epoch: 6| Step: 8
Training loss: 1.4691225756201065
Validation loss: 2.5324904145853013

Epoch: 6| Step: 9
Training loss: 2.1838909349561604
Validation loss: 2.525309621126913

Epoch: 6| Step: 10
Training loss: 1.8375377417600374
Validation loss: 2.5359269328983287

Epoch: 6| Step: 11
Training loss: 1.7838564090761073
Validation loss: 2.5526430152085617

Epoch: 6| Step: 12
Training loss: 2.4895635202382906
Validation loss: 2.536913794970931

Epoch: 6| Step: 13
Training loss: 1.4408271267111723
Validation loss: 2.5642668905084656

Epoch: 292| Step: 0
Training loss: 1.8803920779348795
Validation loss: 2.596403916678469

Epoch: 6| Step: 1
Training loss: 2.012291569312041
Validation loss: 2.5989846105272822

Epoch: 6| Step: 2
Training loss: 1.221731597992857
Validation loss: 2.620075420284175

Epoch: 6| Step: 3
Training loss: 2.126516137889527
Validation loss: 2.592850004264155

Epoch: 6| Step: 4
Training loss: 1.8923861285159047
Validation loss: 2.5566561518489794

Epoch: 6| Step: 5
Training loss: 2.3929980100311794
Validation loss: 2.5816706618673573

Epoch: 6| Step: 6
Training loss: 2.4394761902182203
Validation loss: 2.541141320222158

Epoch: 6| Step: 7
Training loss: 1.7347325136958396
Validation loss: 2.5531600601111144

Epoch: 6| Step: 8
Training loss: 1.8301724437074378
Validation loss: 2.560688650171764

Epoch: 6| Step: 9
Training loss: 1.3681451549761958
Validation loss: 2.580470488229417

Epoch: 6| Step: 10
Training loss: 2.1240633976126126
Validation loss: 2.5103770895300914

Epoch: 6| Step: 11
Training loss: 2.167835568298015
Validation loss: 2.522593873907647

Epoch: 6| Step: 12
Training loss: 1.960658566519253
Validation loss: 2.5194914427774266

Epoch: 6| Step: 13
Training loss: 2.015778291772692
Validation loss: 2.534016106433659

Epoch: 293| Step: 0
Training loss: 2.4494159625172043
Validation loss: 2.501110148309882

Epoch: 6| Step: 1
Training loss: 2.268819621885806
Validation loss: 2.536443006611497

Epoch: 6| Step: 2
Training loss: 1.3540491591112624
Validation loss: 2.542539389401134

Epoch: 6| Step: 3
Training loss: 1.8077445951351188
Validation loss: 2.5871035279796324

Epoch: 6| Step: 4
Training loss: 1.2542384768149246
Validation loss: 2.535359582647589

Epoch: 6| Step: 5
Training loss: 2.2532293668534678
Validation loss: 2.594157665648399

Epoch: 6| Step: 6
Training loss: 1.7464360321937582
Validation loss: 2.565502826416267

Epoch: 6| Step: 7
Training loss: 2.3478376220106476
Validation loss: 2.5541243559510236

Epoch: 6| Step: 8
Training loss: 1.489651267185427
Validation loss: 2.5535188854349022

Epoch: 6| Step: 9
Training loss: 1.9265561044158341
Validation loss: 2.594451556637328

Epoch: 6| Step: 10
Training loss: 1.5728170434926707
Validation loss: 2.587114375552775

Epoch: 6| Step: 11
Training loss: 1.8173690377215077
Validation loss: 2.564824097087766

Epoch: 6| Step: 12
Training loss: 1.6161771557553337
Validation loss: 2.576460746204053

Epoch: 6| Step: 13
Training loss: 2.4592715482753706
Validation loss: 2.57184903520693

Epoch: 294| Step: 0
Training loss: 2.145163076466167
Validation loss: 2.5996274577294565

Epoch: 6| Step: 1
Training loss: 1.530255286541803
Validation loss: 2.6036738476152608

Epoch: 6| Step: 2
Training loss: 1.6878432172082378
Validation loss: 2.6126755115501754

Epoch: 6| Step: 3
Training loss: 1.974351754820013
Validation loss: 2.622182635998101

Epoch: 6| Step: 4
Training loss: 1.9042764672384045
Validation loss: 2.5566742586158258

Epoch: 6| Step: 5
Training loss: 1.5945490161853602
Validation loss: 2.5363639850549924

Epoch: 6| Step: 6
Training loss: 1.6169570537518856
Validation loss: 2.5005971354373595

Epoch: 6| Step: 7
Training loss: 1.8719151233072981
Validation loss: 2.508099390021625

Epoch: 6| Step: 8
Training loss: 2.3391154943870434
Validation loss: 2.5379347110955015

Epoch: 6| Step: 9
Training loss: 1.8267464942381648
Validation loss: 2.5470430439623186

Epoch: 6| Step: 10
Training loss: 1.8075243958532383
Validation loss: 2.548002792944742

Epoch: 6| Step: 11
Training loss: 2.0067910293789195
Validation loss: 2.559158301737795

Epoch: 6| Step: 12
Training loss: 1.9917466816597404
Validation loss: 2.5679247586318144

Epoch: 6| Step: 13
Training loss: 2.819705971884888
Validation loss: 2.6027767948360028

Epoch: 295| Step: 0
Training loss: 2.768055855082753
Validation loss: 2.579076926457852

Epoch: 6| Step: 1
Training loss: 2.2201211480428955
Validation loss: 2.6317001845641417

Epoch: 6| Step: 2
Training loss: 1.698251032134458
Validation loss: 2.634409916994404

Epoch: 6| Step: 3
Training loss: 1.4521354669582978
Validation loss: 2.6644178807894914

Epoch: 6| Step: 4
Training loss: 2.3965284472503607
Validation loss: 2.649986481782034

Epoch: 6| Step: 5
Training loss: 2.028096142109492
Validation loss: 2.6451969482756916

Epoch: 6| Step: 6
Training loss: 1.7042455224382231
Validation loss: 2.664276934781774

Epoch: 6| Step: 7
Training loss: 1.2474697730887923
Validation loss: 2.616296857671536

Epoch: 6| Step: 8
Training loss: 2.556495330155702
Validation loss: 2.5779710665899978

Epoch: 6| Step: 9
Training loss: 2.578326685559268
Validation loss: 2.5360198428483796

Epoch: 6| Step: 10
Training loss: 1.5670610614557463
Validation loss: 2.5038008566033745

Epoch: 6| Step: 11
Training loss: 1.8479489503926905
Validation loss: 2.4942123494381474

Epoch: 6| Step: 12
Training loss: 1.943876050192178
Validation loss: 2.530220167609523

Epoch: 6| Step: 13
Training loss: 1.61420286884717
Validation loss: 2.547144370470702

Epoch: 296| Step: 0
Training loss: 1.581748051668248
Validation loss: 2.5988039316144205

Epoch: 6| Step: 1
Training loss: 1.691700123548472
Validation loss: 2.539793548979641

Epoch: 6| Step: 2
Training loss: 1.3210672331889122
Validation loss: 2.5663597764636727

Epoch: 6| Step: 3
Training loss: 1.579983740252114
Validation loss: 2.573294643999048

Epoch: 6| Step: 4
Training loss: 2.0297042834239214
Validation loss: 2.573978843180137

Epoch: 6| Step: 5
Training loss: 2.109723662771515
Validation loss: 2.520766916792501

Epoch: 6| Step: 6
Training loss: 1.2298649350884758
Validation loss: 2.5435631170208572

Epoch: 6| Step: 7
Training loss: 2.0694253424232945
Validation loss: 2.5060928564995453

Epoch: 6| Step: 8
Training loss: 2.391196188911982
Validation loss: 2.543626753862062

Epoch: 6| Step: 9
Training loss: 2.3034590211058807
Validation loss: 2.525954228621521

Epoch: 6| Step: 10
Training loss: 2.1812541622788904
Validation loss: 2.556392120414922

Epoch: 6| Step: 11
Training loss: 1.7170809878498594
Validation loss: 2.578812031766431

Epoch: 6| Step: 12
Training loss: 2.261578333157363
Validation loss: 2.59148269585032

Epoch: 6| Step: 13
Training loss: 1.9308374970508781
Validation loss: 2.5950067684940374

Epoch: 297| Step: 0
Training loss: 1.69968304484296
Validation loss: 2.6126798917658407

Epoch: 6| Step: 1
Training loss: 1.8004706853478611
Validation loss: 2.6134870492806366

Epoch: 6| Step: 2
Training loss: 1.6744716835942421
Validation loss: 2.6072177916630337

Epoch: 6| Step: 3
Training loss: 1.2942568076567937
Validation loss: 2.5828334314413945

Epoch: 6| Step: 4
Training loss: 2.331853556292849
Validation loss: 2.557326793753119

Epoch: 6| Step: 5
Training loss: 1.926027108180919
Validation loss: 2.5272794437236037

Epoch: 6| Step: 6
Training loss: 2.163348248767816
Validation loss: 2.5483453480961424

Epoch: 6| Step: 7
Training loss: 2.0188898658131906
Validation loss: 2.583480097590732

Epoch: 6| Step: 8
Training loss: 1.2202418073626509
Validation loss: 2.536226145765475

Epoch: 6| Step: 9
Training loss: 2.401487914436805
Validation loss: 2.4966997615859983

Epoch: 6| Step: 10
Training loss: 2.318089405978576
Validation loss: 2.4773305189440413

Epoch: 6| Step: 11
Training loss: 2.4635389353526636
Validation loss: 2.467903635957876

Epoch: 6| Step: 12
Training loss: 1.8299274525046214
Validation loss: 2.4687091164080797

Epoch: 6| Step: 13
Training loss: 2.0659767670853006
Validation loss: 2.4603350997010227

Epoch: 298| Step: 0
Training loss: 2.017974076096037
Validation loss: 2.482676487232634

Epoch: 6| Step: 1
Training loss: 2.159349397764233
Validation loss: 2.5437434159677137

Epoch: 6| Step: 2
Training loss: 2.0037867936190783
Validation loss: 2.5981836992903284

Epoch: 6| Step: 3
Training loss: 1.6265133633186286
Validation loss: 2.660130616903391

Epoch: 6| Step: 4
Training loss: 1.5540781024860717
Validation loss: 2.68581134765445

Epoch: 6| Step: 5
Training loss: 2.016743667435602
Validation loss: 2.6393868668042764

Epoch: 6| Step: 6
Training loss: 1.694618469779459
Validation loss: 2.6005258260768516

Epoch: 6| Step: 7
Training loss: 2.5635515242015963
Validation loss: 2.5518340216068442

Epoch: 6| Step: 8
Training loss: 1.8338382488044904
Validation loss: 2.5816289498874254

Epoch: 6| Step: 9
Training loss: 2.25797701437564
Validation loss: 2.5655013394959125

Epoch: 6| Step: 10
Training loss: 1.2841915695743071
Validation loss: 2.5166367733255774

Epoch: 6| Step: 11
Training loss: 1.6266908651777268
Validation loss: 2.5111610026687377

Epoch: 6| Step: 12
Training loss: 1.836478555372886
Validation loss: 2.4933434240201597

Epoch: 6| Step: 13
Training loss: 2.068976665883336
Validation loss: 2.507644314934514

Epoch: 299| Step: 0
Training loss: 1.6392844399887436
Validation loss: 2.523414367632742

Epoch: 6| Step: 1
Training loss: 1.3720424662849344
Validation loss: 2.5287921102364317

Epoch: 6| Step: 2
Training loss: 2.7140991067915734
Validation loss: 2.513379597461528

Epoch: 6| Step: 3
Training loss: 2.5133524990447214
Validation loss: 2.517648597758845

Epoch: 6| Step: 4
Training loss: 1.7211144569456938
Validation loss: 2.5301354862770604

Epoch: 6| Step: 5
Training loss: 1.3597927547774071
Validation loss: 2.515982489922184

Epoch: 6| Step: 6
Training loss: 2.064076023793875
Validation loss: 2.542811485072485

Epoch: 6| Step: 7
Training loss: 2.3271131941047196
Validation loss: 2.526275817925402

Epoch: 6| Step: 8
Training loss: 1.7971761699883853
Validation loss: 2.537794811993669

Epoch: 6| Step: 9
Training loss: 1.7293175168094759
Validation loss: 2.577339946786033

Epoch: 6| Step: 10
Training loss: 1.5968946959592891
Validation loss: 2.5781194051046064

Epoch: 6| Step: 11
Training loss: 1.6571543401874638
Validation loss: 2.5477597624739845

Epoch: 6| Step: 12
Training loss: 1.258849954131147
Validation loss: 2.609791476882908

Epoch: 6| Step: 13
Training loss: 2.032774367916758
Validation loss: 2.5490974917279607

Epoch: 300| Step: 0
Training loss: 1.5579153319675592
Validation loss: 2.551445594565379

Epoch: 6| Step: 1
Training loss: 1.7145727547388372
Validation loss: 2.5533672813901065

Epoch: 6| Step: 2
Training loss: 2.0702491606614015
Validation loss: 2.5684338693004825

Epoch: 6| Step: 3
Training loss: 1.9095749545872478
Validation loss: 2.545533027564041

Epoch: 6| Step: 4
Training loss: 1.863329872760505
Validation loss: 2.5159541481410783

Epoch: 6| Step: 5
Training loss: 2.07994126420354
Validation loss: 2.577507407458046

Epoch: 6| Step: 6
Training loss: 1.472723111929191
Validation loss: 2.5884538989983157

Epoch: 6| Step: 7
Training loss: 2.0429394575830813
Validation loss: 2.565206889049857

Epoch: 6| Step: 8
Training loss: 1.9377131191066463
Validation loss: 2.5737115324584594

Epoch: 6| Step: 9
Training loss: 1.7151014964151163
Validation loss: 2.5831257880322203

Epoch: 6| Step: 10
Training loss: 1.847980172472024
Validation loss: 2.5114466399642206

Epoch: 6| Step: 11
Training loss: 2.6269759960667955
Validation loss: 2.6155902448538084

Epoch: 6| Step: 12
Training loss: 1.7332245731466747
Validation loss: 2.5288258156856283

Epoch: 6| Step: 13
Training loss: 2.0179525731376495
Validation loss: 2.5548432873307534

Epoch: 301| Step: 0
Training loss: 2.6490620914669067
Validation loss: 2.5444226618236505

Epoch: 6| Step: 1
Training loss: 1.3884156496405127
Validation loss: 2.5514619862368937

Epoch: 6| Step: 2
Training loss: 2.2833085896434477
Validation loss: 2.506786750654681

Epoch: 6| Step: 3
Training loss: 1.8461763612890352
Validation loss: 2.5161767358500313

Epoch: 6| Step: 4
Training loss: 2.0619857609402428
Validation loss: 2.5444462669172614

Epoch: 6| Step: 5
Training loss: 1.3524219668823938
Validation loss: 2.4948596719433764

Epoch: 6| Step: 6
Training loss: 1.630253589071024
Validation loss: 2.54853529532948

Epoch: 6| Step: 7
Training loss: 2.2718664030098688
Validation loss: 2.513687951807927

Epoch: 6| Step: 8
Training loss: 2.1391410417536503
Validation loss: 2.5265724227543713

Epoch: 6| Step: 9
Training loss: 2.5262189245790085
Validation loss: 2.5078102737686243

Epoch: 6| Step: 10
Training loss: 1.4638767153052592
Validation loss: 2.517872361340406

Epoch: 6| Step: 11
Training loss: 2.5065452725187383
Validation loss: 2.509044815832924

Epoch: 6| Step: 12
Training loss: 1.3976525602510557
Validation loss: 2.531463041092132

Epoch: 6| Step: 13
Training loss: 2.131590999943479
Validation loss: 2.560587595817827

Epoch: 302| Step: 0
Training loss: 1.7383455757497586
Validation loss: 2.5592953872563773

Epoch: 6| Step: 1
Training loss: 1.5860891786399895
Validation loss: 2.6005888864994935

Epoch: 6| Step: 2
Training loss: 1.5507641846609053
Validation loss: 2.5396621230819494

Epoch: 6| Step: 3
Training loss: 2.252194711740591
Validation loss: 2.5660272528414487

Epoch: 6| Step: 4
Training loss: 1.3335024408547684
Validation loss: 2.6231796522660322

Epoch: 6| Step: 5
Training loss: 2.444157239148123
Validation loss: 2.6433230128172984

Epoch: 6| Step: 6
Training loss: 2.057551371604012
Validation loss: 2.5975158806450924

Epoch: 6| Step: 7
Training loss: 2.6095843202614555
Validation loss: 2.560733449866355

Epoch: 6| Step: 8
Training loss: 1.84590210825953
Validation loss: 2.5885738982273354

Epoch: 6| Step: 9
Training loss: 1.4875436792452024
Validation loss: 2.57167313263633

Epoch: 6| Step: 10
Training loss: 2.023440092225053
Validation loss: 2.5987401856712182

Epoch: 6| Step: 11
Training loss: 2.0813922867808814
Validation loss: 2.589953274949769

Epoch: 6| Step: 12
Training loss: 1.7033980264465716
Validation loss: 2.549654171749178

Epoch: 6| Step: 13
Training loss: 2.2267359615820057
Validation loss: 2.5680691747291093

Epoch: 303| Step: 0
Training loss: 1.0511427473769483
Validation loss: 2.4962453940369262

Epoch: 6| Step: 1
Training loss: 2.184318626887921
Validation loss: 2.528917721641903

Epoch: 6| Step: 2
Training loss: 1.7266969930472282
Validation loss: 2.5044123494697015

Epoch: 6| Step: 3
Training loss: 2.4422976888154846
Validation loss: 2.5026081626349446

Epoch: 6| Step: 4
Training loss: 2.107776742777517
Validation loss: 2.521580787586388

Epoch: 6| Step: 5
Training loss: 1.6147491205889004
Validation loss: 2.552677277459346

Epoch: 6| Step: 6
Training loss: 2.5291492551636843
Validation loss: 2.5222613385771453

Epoch: 6| Step: 7
Training loss: 2.0855918340700903
Validation loss: 2.580424660669731

Epoch: 6| Step: 8
Training loss: 1.2324633704694636
Validation loss: 2.606346276179857

Epoch: 6| Step: 9
Training loss: 2.138169265284401
Validation loss: 2.551541552483934

Epoch: 6| Step: 10
Training loss: 2.02157271187574
Validation loss: 2.646642881481935

Epoch: 6| Step: 11
Training loss: 1.9788420427691324
Validation loss: 2.6444749924776834

Epoch: 6| Step: 12
Training loss: 1.980385803050648
Validation loss: 2.650169983696242

Epoch: 6| Step: 13
Training loss: 1.660497293784243
Validation loss: 2.6250880998632136

Epoch: 304| Step: 0
Training loss: 1.5988751450891154
Validation loss: 2.601341138859621

Epoch: 6| Step: 1
Training loss: 1.8216078573833976
Validation loss: 2.572722567960312

Epoch: 6| Step: 2
Training loss: 2.32337549123001
Validation loss: 2.566089225399139

Epoch: 6| Step: 3
Training loss: 1.7835152928343985
Validation loss: 2.5476321633658743

Epoch: 6| Step: 4
Training loss: 2.302548828932655
Validation loss: 2.5408007809247017

Epoch: 6| Step: 5
Training loss: 1.9526579031304268
Validation loss: 2.537515382140693

Epoch: 6| Step: 6
Training loss: 1.6783562641162024
Validation loss: 2.529887896480423

Epoch: 6| Step: 7
Training loss: 1.7663301393290822
Validation loss: 2.5454853377760727

Epoch: 6| Step: 8
Training loss: 2.04945641730809
Validation loss: 2.584573468571746

Epoch: 6| Step: 9
Training loss: 2.0347429027815584
Validation loss: 2.586364295981939

Epoch: 6| Step: 10
Training loss: 1.6931015575161819
Validation loss: 2.5508900454162484

Epoch: 6| Step: 11
Training loss: 1.7647393630161543
Validation loss: 2.643819753629971

Epoch: 6| Step: 12
Training loss: 1.9749106036850397
Validation loss: 2.612272698037194

Epoch: 6| Step: 13
Training loss: 1.4595249303222113
Validation loss: 2.594774985875546

Epoch: 305| Step: 0
Training loss: 1.9032533574156747
Validation loss: 2.5997781295132505

Epoch: 6| Step: 1
Training loss: 1.6813660507139814
Validation loss: 2.5266941499431574

Epoch: 6| Step: 2
Training loss: 2.0518716874039233
Validation loss: 2.526978456019659

Epoch: 6| Step: 3
Training loss: 1.517211162724402
Validation loss: 2.522290562610842

Epoch: 6| Step: 4
Training loss: 2.133689839655273
Validation loss: 2.481522784224125

Epoch: 6| Step: 5
Training loss: 1.4426196607017094
Validation loss: 2.5158585070799155

Epoch: 6| Step: 6
Training loss: 1.3391528781227695
Validation loss: 2.5026151171923345

Epoch: 6| Step: 7
Training loss: 1.62953565407649
Validation loss: 2.530273406091197

Epoch: 6| Step: 8
Training loss: 1.6816807475160565
Validation loss: 2.5266037515525492

Epoch: 6| Step: 9
Training loss: 1.9949706738450952
Validation loss: 2.5434338466119515

Epoch: 6| Step: 10
Training loss: 1.8881404724800372
Validation loss: 2.58158666772031

Epoch: 6| Step: 11
Training loss: 2.7499960119045124
Validation loss: 2.633493563650269

Epoch: 6| Step: 12
Training loss: 1.5718717662254726
Validation loss: 2.538323601044273

Epoch: 6| Step: 13
Training loss: 2.1230441797935975
Validation loss: 2.5944868978974656

Epoch: 306| Step: 0
Training loss: 1.7550630896115518
Validation loss: 2.6717363883011718

Epoch: 6| Step: 1
Training loss: 1.898014979183793
Validation loss: 2.655313783100374

Epoch: 6| Step: 2
Training loss: 1.7150988551973805
Validation loss: 2.638284838847878

Epoch: 6| Step: 3
Training loss: 2.6991217633059565
Validation loss: 2.6982003336552896

Epoch: 6| Step: 4
Training loss: 1.3516168307811858
Validation loss: 2.692287660618553

Epoch: 6| Step: 5
Training loss: 2.0545201686705634
Validation loss: 2.6592262050124367

Epoch: 6| Step: 6
Training loss: 1.9655071981332697
Validation loss: 2.6490938466749356

Epoch: 6| Step: 7
Training loss: 1.911030949376406
Validation loss: 2.5818872224051646

Epoch: 6| Step: 8
Training loss: 2.0728153862164604
Validation loss: 2.5985236304454493

Epoch: 6| Step: 9
Training loss: 2.4898324200719824
Validation loss: 2.5841878790191353

Epoch: 6| Step: 10
Training loss: 1.5895379449539688
Validation loss: 2.5347010003396138

Epoch: 6| Step: 11
Training loss: 1.461641030052325
Validation loss: 2.5284074906060647

Epoch: 6| Step: 12
Training loss: 1.6027366985887144
Validation loss: 2.5202151452165573

Epoch: 6| Step: 13
Training loss: 1.422682815630519
Validation loss: 2.478299419330941

Epoch: 307| Step: 0
Training loss: 1.386117638339208
Validation loss: 2.544337125686997

Epoch: 6| Step: 1
Training loss: 1.3907219499375005
Validation loss: 2.53322423858981

Epoch: 6| Step: 2
Training loss: 2.8787982563275887
Validation loss: 2.518612747933259

Epoch: 6| Step: 3
Training loss: 1.26012071439962
Validation loss: 2.5543163313792863

Epoch: 6| Step: 4
Training loss: 1.945074105113619
Validation loss: 2.547670228528485

Epoch: 6| Step: 5
Training loss: 1.4856876391861342
Validation loss: 2.5383579783037438

Epoch: 6| Step: 6
Training loss: 1.66190251678032
Validation loss: 2.5810198782128624

Epoch: 6| Step: 7
Training loss: 2.201775969747938
Validation loss: 2.526696705522187

Epoch: 6| Step: 8
Training loss: 1.6533420874507447
Validation loss: 2.5681479479427547

Epoch: 6| Step: 9
Training loss: 1.9048221431017085
Validation loss: 2.574263128998899

Epoch: 6| Step: 10
Training loss: 1.5230137162220225
Validation loss: 2.5230959886557596

Epoch: 6| Step: 11
Training loss: 2.0017651874437274
Validation loss: 2.521313051549001

Epoch: 6| Step: 12
Training loss: 2.335343403366089
Validation loss: 2.571430801713572

Epoch: 6| Step: 13
Training loss: 2.1898233337212747
Validation loss: 2.523063970581605

Epoch: 308| Step: 0
Training loss: 1.623916778456914
Validation loss: 2.517561031310157

Epoch: 6| Step: 1
Training loss: 1.507169991806183
Validation loss: 2.5107367748081972

Epoch: 6| Step: 2
Training loss: 1.9606527296494243
Validation loss: 2.5053013541755744

Epoch: 6| Step: 3
Training loss: 1.5148309416915566
Validation loss: 2.4981707794980514

Epoch: 6| Step: 4
Training loss: 1.300003231484725
Validation loss: 2.518731152359055

Epoch: 6| Step: 5
Training loss: 2.4425337240337117
Validation loss: 2.469622477948535

Epoch: 6| Step: 6
Training loss: 2.3371180992467324
Validation loss: 2.4892853567865014

Epoch: 6| Step: 7
Training loss: 2.6156727520994365
Validation loss: 2.5015784049258203

Epoch: 6| Step: 8
Training loss: 1.569265595469663
Validation loss: 2.5151074431911433

Epoch: 6| Step: 9
Training loss: 1.9799027395924906
Validation loss: 2.5662054237821157

Epoch: 6| Step: 10
Training loss: 1.6692454970446038
Validation loss: 2.611389661590289

Epoch: 6| Step: 11
Training loss: 1.9650363713943593
Validation loss: 2.650092119139279

Epoch: 6| Step: 12
Training loss: 1.2814480233101995
Validation loss: 2.6433107610927746

Epoch: 6| Step: 13
Training loss: 1.9990468137983473
Validation loss: 2.684364382182902

Epoch: 309| Step: 0
Training loss: 1.7400881173852256
Validation loss: 2.6332677641886013

Epoch: 6| Step: 1
Training loss: 1.578668481892324
Validation loss: 2.643978284594668

Epoch: 6| Step: 2
Training loss: 1.231141502905739
Validation loss: 2.603649688268134

Epoch: 6| Step: 3
Training loss: 2.548952343716357
Validation loss: 2.56859652701952

Epoch: 6| Step: 4
Training loss: 1.5562404371833374
Validation loss: 2.578992231527173

Epoch: 6| Step: 5
Training loss: 2.401921726777828
Validation loss: 2.5560713508937067

Epoch: 6| Step: 6
Training loss: 1.5911138836222622
Validation loss: 2.5586876150681412

Epoch: 6| Step: 7
Training loss: 2.5484239981344508
Validation loss: 2.539364183549803

Epoch: 6| Step: 8
Training loss: 1.9243972478697433
Validation loss: 2.5225712693842213

Epoch: 6| Step: 9
Training loss: 1.2312439913530466
Validation loss: 2.5071414513170636

Epoch: 6| Step: 10
Training loss: 2.0128185043873192
Validation loss: 2.522229688015315

Epoch: 6| Step: 11
Training loss: 1.7350105289722397
Validation loss: 2.509844898203903

Epoch: 6| Step: 12
Training loss: 1.847097300206972
Validation loss: 2.5121069687717266

Epoch: 6| Step: 13
Training loss: 1.5272888017609423
Validation loss: 2.5431404114427565

Epoch: 310| Step: 0
Training loss: 1.713717079653307
Validation loss: 2.53512725264899

Epoch: 6| Step: 1
Training loss: 2.178391047119112
Validation loss: 2.5517766547672274

Epoch: 6| Step: 2
Training loss: 1.590569033134642
Validation loss: 2.5522912751684483

Epoch: 6| Step: 3
Training loss: 1.6393614489991148
Validation loss: 2.5864518452159815

Epoch: 6| Step: 4
Training loss: 1.3435579207002
Validation loss: 2.5792318337937634

Epoch: 6| Step: 5
Training loss: 1.482135890872099
Validation loss: 2.542474584424305

Epoch: 6| Step: 6
Training loss: 1.786082555398573
Validation loss: 2.5574544529791545

Epoch: 6| Step: 7
Training loss: 2.086625917826975
Validation loss: 2.552475853661616

Epoch: 6| Step: 8
Training loss: 1.2179870173446703
Validation loss: 2.5494449341722416

Epoch: 6| Step: 9
Training loss: 1.974295058170153
Validation loss: 2.5112332062122533

Epoch: 6| Step: 10
Training loss: 1.8598378350722176
Validation loss: 2.5396043561190984

Epoch: 6| Step: 11
Training loss: 2.389506259019999
Validation loss: 2.5445663348223

Epoch: 6| Step: 12
Training loss: 2.0160030040113077
Validation loss: 2.545356890917922

Epoch: 6| Step: 13
Training loss: 2.22009537431826
Validation loss: 2.530796544152309

Epoch: 311| Step: 0
Training loss: 1.4927950915271244
Validation loss: 2.5556711836470174

Epoch: 6| Step: 1
Training loss: 1.7783600636731316
Validation loss: 2.558230479613502

Epoch: 6| Step: 2
Training loss: 1.3883892045259945
Validation loss: 2.539444488743855

Epoch: 6| Step: 3
Training loss: 1.9757192871224314
Validation loss: 2.51711869369732

Epoch: 6| Step: 4
Training loss: 1.9103814052820607
Validation loss: 2.578383677442559

Epoch: 6| Step: 5
Training loss: 1.8173431933315822
Validation loss: 2.6199987619096197

Epoch: 6| Step: 6
Training loss: 1.8241666014444622
Validation loss: 2.647630866889474

Epoch: 6| Step: 7
Training loss: 2.1131438318162044
Validation loss: 2.630382197207746

Epoch: 6| Step: 8
Training loss: 2.207672944082399
Validation loss: 2.670745105049875

Epoch: 6| Step: 9
Training loss: 1.4913868778463324
Validation loss: 2.6435072328225524

Epoch: 6| Step: 10
Training loss: 1.7753575891625248
Validation loss: 2.6847345184695386

Epoch: 6| Step: 11
Training loss: 2.074292197785947
Validation loss: 2.709699731100484

Epoch: 6| Step: 12
Training loss: 2.1279937748495272
Validation loss: 2.6757223229521165

Epoch: 6| Step: 13
Training loss: 1.8234086453623548
Validation loss: 2.6266805174102545

Epoch: 312| Step: 0
Training loss: 1.994830005831762
Validation loss: 2.5720656038883747

Epoch: 6| Step: 1
Training loss: 2.1118777650948806
Validation loss: 2.5688087060659837

Epoch: 6| Step: 2
Training loss: 2.252742790998888
Validation loss: 2.5062768181612993

Epoch: 6| Step: 3
Training loss: 1.7077663069862175
Validation loss: 2.5235414276924946

Epoch: 6| Step: 4
Training loss: 1.797984966278874
Validation loss: 2.487267144325108

Epoch: 6| Step: 5
Training loss: 1.2742040000637187
Validation loss: 2.4701546564088384

Epoch: 6| Step: 6
Training loss: 1.545850626530875
Validation loss: 2.4648078315322373

Epoch: 6| Step: 7
Training loss: 1.6999920368008072
Validation loss: 2.47452678908927

Epoch: 6| Step: 8
Training loss: 1.5175008275439852
Validation loss: 2.4878569699865705

Epoch: 6| Step: 9
Training loss: 2.6926319005707846
Validation loss: 2.4504560461341143

Epoch: 6| Step: 10
Training loss: 1.6981648300829384
Validation loss: 2.505473233266431

Epoch: 6| Step: 11
Training loss: 1.5988494222952798
Validation loss: 2.4958244262009917

Epoch: 6| Step: 12
Training loss: 1.8997895877175708
Validation loss: 2.510983072123304

Epoch: 6| Step: 13
Training loss: 1.3124109419626122
Validation loss: 2.5107885430872803

Epoch: 313| Step: 0
Training loss: 1.6473464609474961
Validation loss: 2.509044657460181

Epoch: 6| Step: 1
Training loss: 1.5169479259538021
Validation loss: 2.4968786861056675

Epoch: 6| Step: 2
Training loss: 1.7652773219415714
Validation loss: 2.4953365699787162

Epoch: 6| Step: 3
Training loss: 1.5298045595791094
Validation loss: 2.4942205700549755

Epoch: 6| Step: 4
Training loss: 2.5023605646240794
Validation loss: 2.49724216936476

Epoch: 6| Step: 5
Training loss: 2.0466223407919832
Validation loss: 2.493007656500329

Epoch: 6| Step: 6
Training loss: 2.7592909526877505
Validation loss: 2.486268671348278

Epoch: 6| Step: 7
Training loss: 1.3467129709447518
Validation loss: 2.5064849825803055

Epoch: 6| Step: 8
Training loss: 1.5877226755959117
Validation loss: 2.551618562274413

Epoch: 6| Step: 9
Training loss: 1.5476029349805303
Validation loss: 2.616288458670133

Epoch: 6| Step: 10
Training loss: 1.9850986392786671
Validation loss: 2.628181875417071

Epoch: 6| Step: 11
Training loss: 1.809095012499816
Validation loss: 2.6403327343758694

Epoch: 6| Step: 12
Training loss: 1.7273911778888893
Validation loss: 2.665616325313619

Epoch: 6| Step: 13
Training loss: 1.777742915341494
Validation loss: 2.731572820701198

Epoch: 314| Step: 0
Training loss: 1.754767803144761
Validation loss: 2.7119871630378896

Epoch: 6| Step: 1
Training loss: 2.490650336736177
Validation loss: 2.695631323492327

Epoch: 6| Step: 2
Training loss: 1.9768611395871893
Validation loss: 2.705290189984988

Epoch: 6| Step: 3
Training loss: 1.6511106105653652
Validation loss: 2.6917926748993364

Epoch: 6| Step: 4
Training loss: 1.4453591828926198
Validation loss: 2.6689173816420255

Epoch: 6| Step: 5
Training loss: 1.4826248291365445
Validation loss: 2.6044298166197684

Epoch: 6| Step: 6
Training loss: 1.8405036147915579
Validation loss: 2.5893230116088772

Epoch: 6| Step: 7
Training loss: 1.9031223842057916
Validation loss: 2.5599432805354327

Epoch: 6| Step: 8
Training loss: 2.1391032580776135
Validation loss: 2.5047606757554854

Epoch: 6| Step: 9
Training loss: 1.6224556590929247
Validation loss: 2.5536884839327176

Epoch: 6| Step: 10
Training loss: 1.4441328028373412
Validation loss: 2.531620500866493

Epoch: 6| Step: 11
Training loss: 1.889882911506613
Validation loss: 2.531897983890857

Epoch: 6| Step: 12
Training loss: 1.4335194082499705
Validation loss: 2.5243760637956534

Epoch: 6| Step: 13
Training loss: 1.935024525883712
Validation loss: 2.5201041898431904

Epoch: 315| Step: 0
Training loss: 1.5692491869399423
Validation loss: 2.553340000421105

Epoch: 6| Step: 1
Training loss: 2.4672220064616606
Validation loss: 2.5286259727339755

Epoch: 6| Step: 2
Training loss: 1.3342021803425075
Validation loss: 2.5662410843575545

Epoch: 6| Step: 3
Training loss: 1.9802651686307167
Validation loss: 2.5526510320871916

Epoch: 6| Step: 4
Training loss: 1.3062581641567208
Validation loss: 2.5444944368705023

Epoch: 6| Step: 5
Training loss: 2.6291405855347216
Validation loss: 2.5853215893014223

Epoch: 6| Step: 6
Training loss: 2.3653065475931263
Validation loss: 2.6235767017821052

Epoch: 6| Step: 7
Training loss: 1.6894939086930696
Validation loss: 2.5831459551709703

Epoch: 6| Step: 8
Training loss: 1.5968626704925115
Validation loss: 2.557588196219088

Epoch: 6| Step: 9
Training loss: 1.5389789229418964
Validation loss: 2.586951949025862

Epoch: 6| Step: 10
Training loss: 2.050681498690088
Validation loss: 2.526668531103461

Epoch: 6| Step: 11
Training loss: 1.3542478048029687
Validation loss: 2.5640502210311817

Epoch: 6| Step: 12
Training loss: 1.7021312089005456
Validation loss: 2.505945320667426

Epoch: 6| Step: 13
Training loss: 1.4487189487555965
Validation loss: 2.5563974364401

Epoch: 316| Step: 0
Training loss: 1.6870779286708861
Validation loss: 2.50957673347826

Epoch: 6| Step: 1
Training loss: 1.6506783680375263
Validation loss: 2.5763984678855243

Epoch: 6| Step: 2
Training loss: 2.1605736327527434
Validation loss: 2.5822867816747017

Epoch: 6| Step: 3
Training loss: 2.032305868527056
Validation loss: 2.5920210594991633

Epoch: 6| Step: 4
Training loss: 1.9109779883873153
Validation loss: 2.602652534268006

Epoch: 6| Step: 5
Training loss: 1.8066806768153318
Validation loss: 2.6619758078003435

Epoch: 6| Step: 6
Training loss: 1.7210717905022859
Validation loss: 2.63265694933164

Epoch: 6| Step: 7
Training loss: 2.4161838728869283
Validation loss: 2.7077529334230066

Epoch: 6| Step: 8
Training loss: 1.8537095895942577
Validation loss: 2.6640943448875287

Epoch: 6| Step: 9
Training loss: 2.344292336341084
Validation loss: 2.6484104931559966

Epoch: 6| Step: 10
Training loss: 1.246194865270746
Validation loss: 2.619503382045259

Epoch: 6| Step: 11
Training loss: 1.3505706675915072
Validation loss: 2.5715933162276596

Epoch: 6| Step: 12
Training loss: 1.0103373283358428
Validation loss: 2.5246324337746295

Epoch: 6| Step: 13
Training loss: 1.9405492967468922
Validation loss: 2.531778806229022

Epoch: 317| Step: 0
Training loss: 1.9133122433464829
Validation loss: 2.5464684565620486

Epoch: 6| Step: 1
Training loss: 2.1264517817659967
Validation loss: 2.5499439432801765

Epoch: 6| Step: 2
Training loss: 1.884009143240219
Validation loss: 2.534276040462139

Epoch: 6| Step: 3
Training loss: 1.8675502281124075
Validation loss: 2.5147689563302085

Epoch: 6| Step: 4
Training loss: 1.3417972303720418
Validation loss: 2.5539120927387726

Epoch: 6| Step: 5
Training loss: 1.420990889120726
Validation loss: 2.548060322722687

Epoch: 6| Step: 6
Training loss: 1.355272130419932
Validation loss: 2.5142511442829893

Epoch: 6| Step: 7
Training loss: 1.9403789419556712
Validation loss: 2.54886876800989

Epoch: 6| Step: 8
Training loss: 1.2081314554056812
Validation loss: 2.48279829395312

Epoch: 6| Step: 9
Training loss: 1.954183673039055
Validation loss: 2.55190389093156

Epoch: 6| Step: 10
Training loss: 1.7338225713501771
Validation loss: 2.5612579374871447

Epoch: 6| Step: 11
Training loss: 2.0780811735422096
Validation loss: 2.6014425041927107

Epoch: 6| Step: 12
Training loss: 1.7869163200455054
Validation loss: 2.6081965787419876

Epoch: 6| Step: 13
Training loss: 2.2539731020739904
Validation loss: 2.661451415608493

Epoch: 318| Step: 0
Training loss: 1.7708344702623495
Validation loss: 2.6815078972932476

Epoch: 6| Step: 1
Training loss: 1.45104741709004
Validation loss: 2.7046232830367205

Epoch: 6| Step: 2
Training loss: 2.211491923017973
Validation loss: 2.6444417242451133

Epoch: 6| Step: 3
Training loss: 1.742440859585961
Validation loss: 2.595043579843041

Epoch: 6| Step: 4
Training loss: 1.5847130168469494
Validation loss: 2.5396761421684078

Epoch: 6| Step: 5
Training loss: 1.7644029287140555
Validation loss: 2.52001661411238

Epoch: 6| Step: 6
Training loss: 1.316108330314457
Validation loss: 2.5196457001470285

Epoch: 6| Step: 7
Training loss: 2.199476643647513
Validation loss: 2.511869672212933

Epoch: 6| Step: 8
Training loss: 1.5273058171939957
Validation loss: 2.559085012549542

Epoch: 6| Step: 9
Training loss: 1.7763206136091434
Validation loss: 2.5106022688343335

Epoch: 6| Step: 10
Training loss: 1.4697619259657513
Validation loss: 2.5353321314197066

Epoch: 6| Step: 11
Training loss: 2.4115586613546314
Validation loss: 2.565147443428885

Epoch: 6| Step: 12
Training loss: 1.7601059934821044
Validation loss: 2.5411426493869818

Epoch: 6| Step: 13
Training loss: 1.9812519398387956
Validation loss: 2.598593788852676

Epoch: 319| Step: 0
Training loss: 1.9328987490900833
Validation loss: 2.6219857939270566

Epoch: 6| Step: 1
Training loss: 1.8674071114966762
Validation loss: 2.6221339458982125

Epoch: 6| Step: 2
Training loss: 1.2900231683114352
Validation loss: 2.6629416306941636

Epoch: 6| Step: 3
Training loss: 2.304834393491406
Validation loss: 2.6470781436747

Epoch: 6| Step: 4
Training loss: 1.917100511736625
Validation loss: 2.6353926198915216

Epoch: 6| Step: 5
Training loss: 2.01698765787898
Validation loss: 2.649625648592157

Epoch: 6| Step: 6
Training loss: 1.7636302381228581
Validation loss: 2.62325990616127

Epoch: 6| Step: 7
Training loss: 1.6802303412884725
Validation loss: 2.5830156582170543

Epoch: 6| Step: 8
Training loss: 1.6749893131199858
Validation loss: 2.5747059046130745

Epoch: 6| Step: 9
Training loss: 1.9058106963705475
Validation loss: 2.5844453346186764

Epoch: 6| Step: 10
Training loss: 1.626697387379165
Validation loss: 2.6409522762298234

Epoch: 6| Step: 11
Training loss: 1.2171882012381143
Validation loss: 2.594735781694276

Epoch: 6| Step: 12
Training loss: 1.5896630336767688
Validation loss: 2.6227534990004617

Epoch: 6| Step: 13
Training loss: 1.7293471583037066
Validation loss: 2.5830916373695576

Epoch: 320| Step: 0
Training loss: 1.9469170138753311
Validation loss: 2.555032619297956

Epoch: 6| Step: 1
Training loss: 1.7574222385790217
Validation loss: 2.590580409225705

Epoch: 6| Step: 2
Training loss: 1.4794016190306893
Validation loss: 2.564033933081719

Epoch: 6| Step: 3
Training loss: 1.7005583996053002
Validation loss: 2.526503378499385

Epoch: 6| Step: 4
Training loss: 1.6410761621573877
Validation loss: 2.557389179139402

Epoch: 6| Step: 5
Training loss: 1.9469362399295653
Validation loss: 2.537965821352926

Epoch: 6| Step: 6
Training loss: 1.6999600602114413
Validation loss: 2.5339421371029753

Epoch: 6| Step: 7
Training loss: 1.6236185657615434
Validation loss: 2.579899448904575

Epoch: 6| Step: 8
Training loss: 1.6162034141157977
Validation loss: 2.580228775635429

Epoch: 6| Step: 9
Training loss: 1.7256557102917853
Validation loss: 2.584907856890905

Epoch: 6| Step: 10
Training loss: 1.6134192751753416
Validation loss: 2.549819367686819

Epoch: 6| Step: 11
Training loss: 1.6982381161448465
Validation loss: 2.6117915539032484

Epoch: 6| Step: 12
Training loss: 1.462333705609595
Validation loss: 2.6717732728030366

Epoch: 6| Step: 13
Training loss: 2.5780259546848177
Validation loss: 2.6509330792225128

Epoch: 321| Step: 0
Training loss: 1.8417675545908154
Validation loss: 2.5859576605772525

Epoch: 6| Step: 1
Training loss: 1.758216913114537
Validation loss: 2.562362837803411

Epoch: 6| Step: 2
Training loss: 1.39577849361054
Validation loss: 2.5813284805842702

Epoch: 6| Step: 3
Training loss: 1.6925655206932462
Validation loss: 2.5264576572675144

Epoch: 6| Step: 4
Training loss: 2.5523187230345346
Validation loss: 2.5695535917268644

Epoch: 6| Step: 5
Training loss: 2.1321318382166496
Validation loss: 2.490048709505303

Epoch: 6| Step: 6
Training loss: 1.4942781671783074
Validation loss: 2.527951402837892

Epoch: 6| Step: 7
Training loss: 2.19221707335663
Validation loss: 2.504204187307804

Epoch: 6| Step: 8
Training loss: 1.4447645643681386
Validation loss: 2.500584669092229

Epoch: 6| Step: 9
Training loss: 1.60176874088894
Validation loss: 2.5151080119586195

Epoch: 6| Step: 10
Training loss: 1.9716071936934483
Validation loss: 2.492786299658798

Epoch: 6| Step: 11
Training loss: 1.6450933007910205
Validation loss: 2.5675218887163704

Epoch: 6| Step: 12
Training loss: 1.3170526654974157
Validation loss: 2.567354411300251

Epoch: 6| Step: 13
Training loss: 1.4947137668350536
Validation loss: 2.5506891192105896

Epoch: 322| Step: 0
Training loss: 1.4395356070542509
Validation loss: 2.5944020321156884

Epoch: 6| Step: 1
Training loss: 1.816640531136101
Validation loss: 2.5621592287328556

Epoch: 6| Step: 2
Training loss: 1.4248105441856156
Validation loss: 2.6185643156829745

Epoch: 6| Step: 3
Training loss: 1.8342969991551583
Validation loss: 2.5919077355315445

Epoch: 6| Step: 4
Training loss: 1.8665821578560016
Validation loss: 2.5817289343758505

Epoch: 6| Step: 5
Training loss: 1.1637151827249297
Validation loss: 2.571540423261516

Epoch: 6| Step: 6
Training loss: 1.599583216862013
Validation loss: 2.5751034996688493

Epoch: 6| Step: 7
Training loss: 1.7928428190133523
Validation loss: 2.516898660093097

Epoch: 6| Step: 8
Training loss: 1.7726789019950135
Validation loss: 2.5857251897439966

Epoch: 6| Step: 9
Training loss: 1.4307210552854492
Validation loss: 2.553784863269333

Epoch: 6| Step: 10
Training loss: 1.304624635929365
Validation loss: 2.5380947205353754

Epoch: 6| Step: 11
Training loss: 2.107123748932808
Validation loss: 2.565833551849359

Epoch: 6| Step: 12
Training loss: 1.6591140168268421
Validation loss: 2.5435268182347412

Epoch: 6| Step: 13
Training loss: 2.343768208750882
Validation loss: 2.528626349885146

Epoch: 323| Step: 0
Training loss: 1.8495705750533749
Validation loss: 2.559193423905688

Epoch: 6| Step: 1
Training loss: 2.2661579426049054
Validation loss: 2.5704165112013104

Epoch: 6| Step: 2
Training loss: 2.184260121655096
Validation loss: 2.570070837036651

Epoch: 6| Step: 3
Training loss: 1.1880295225386193
Validation loss: 2.6109517144075554

Epoch: 6| Step: 4
Training loss: 1.977449301107135
Validation loss: 2.626122703850356

Epoch: 6| Step: 5
Training loss: 1.3390904747478964
Validation loss: 2.575922169415874

Epoch: 6| Step: 6
Training loss: 1.639971939172495
Validation loss: 2.53203553306612

Epoch: 6| Step: 7
Training loss: 1.6785687646583822
Validation loss: 2.50240583689152

Epoch: 6| Step: 8
Training loss: 1.7655995459958294
Validation loss: 2.512253407259423

Epoch: 6| Step: 9
Training loss: 1.6086038760533032
Validation loss: 2.4734606807841053

Epoch: 6| Step: 10
Training loss: 1.5691750425553126
Validation loss: 2.476612944946616

Epoch: 6| Step: 11
Training loss: 2.1442355037135594
Validation loss: 2.4763785292909795

Epoch: 6| Step: 12
Training loss: 1.8063806295182447
Validation loss: 2.480219454515419

Epoch: 6| Step: 13
Training loss: 1.3194520844132382
Validation loss: 2.515530776002728

Epoch: 324| Step: 0
Training loss: 1.152033980808827
Validation loss: 2.5318299402304563

Epoch: 6| Step: 1
Training loss: 1.1754392208805409
Validation loss: 2.611652819149047

Epoch: 6| Step: 2
Training loss: 1.7824672087104922
Validation loss: 2.574790246685678

Epoch: 6| Step: 3
Training loss: 2.120018674300376
Validation loss: 2.632422836249948

Epoch: 6| Step: 4
Training loss: 1.5560598019726182
Validation loss: 2.6129879104966234

Epoch: 6| Step: 5
Training loss: 1.399148515209052
Validation loss: 2.524278325478107

Epoch: 6| Step: 6
Training loss: 1.706900515231185
Validation loss: 2.55972269791518

Epoch: 6| Step: 7
Training loss: 1.8262881971225065
Validation loss: 2.569098235052188

Epoch: 6| Step: 8
Training loss: 2.028336768710326
Validation loss: 2.547138177110792

Epoch: 6| Step: 9
Training loss: 1.8669379797810963
Validation loss: 2.511734633645183

Epoch: 6| Step: 10
Training loss: 2.303869794193016
Validation loss: 2.557809320229193

Epoch: 6| Step: 11
Training loss: 1.2497709541281106
Validation loss: 2.556216444434155

Epoch: 6| Step: 12
Training loss: 1.5738495424526584
Validation loss: 2.513970923153699

Epoch: 6| Step: 13
Training loss: 1.761940276096083
Validation loss: 2.5468598035737364

Epoch: 325| Step: 0
Training loss: 1.3964715703630617
Validation loss: 2.5731072966552135

Epoch: 6| Step: 1
Training loss: 2.269738612985393
Validation loss: 2.5562140582728254

Epoch: 6| Step: 2
Training loss: 1.932151179249149
Validation loss: 2.537309638213255

Epoch: 6| Step: 3
Training loss: 1.7793723801170493
Validation loss: 2.5045552397084023

Epoch: 6| Step: 4
Training loss: 1.8548897251346987
Validation loss: 2.5211245523593866

Epoch: 6| Step: 5
Training loss: 1.6254280700257506
Validation loss: 2.5121059564215145

Epoch: 6| Step: 6
Training loss: 1.7291048414215846
Validation loss: 2.5024920361367053

Epoch: 6| Step: 7
Training loss: 1.646244633462395
Validation loss: 2.515253928165233

Epoch: 6| Step: 8
Training loss: 1.8571687319283994
Validation loss: 2.5641795756011265

Epoch: 6| Step: 9
Training loss: 1.7198346270304263
Validation loss: 2.515883880626348

Epoch: 6| Step: 10
Training loss: 1.8406961009568854
Validation loss: 2.559042357896815

Epoch: 6| Step: 11
Training loss: 1.6390168073629128
Validation loss: 2.5267311859280897

Epoch: 6| Step: 12
Training loss: 1.3181403536239251
Validation loss: 2.5999937014625747

Epoch: 6| Step: 13
Training loss: 1.19084699668725
Validation loss: 2.576590711486604

Epoch: 326| Step: 0
Training loss: 1.3451946388568836
Validation loss: 2.59523589686996

Epoch: 6| Step: 1
Training loss: 1.5628853894837014
Validation loss: 2.5610864508685824

Epoch: 6| Step: 2
Training loss: 2.0090044691492768
Validation loss: 2.5591788751262734

Epoch: 6| Step: 3
Training loss: 1.350506761592588
Validation loss: 2.5512421966986634

Epoch: 6| Step: 4
Training loss: 1.5401304770595892
Validation loss: 2.5522299951464413

Epoch: 6| Step: 5
Training loss: 1.662111024597999
Validation loss: 2.514496085974448

Epoch: 6| Step: 6
Training loss: 1.6441352711828519
Validation loss: 2.516159379959884

Epoch: 6| Step: 7
Training loss: 1.7150657701253655
Validation loss: 2.5690305734505197

Epoch: 6| Step: 8
Training loss: 1.376317693308423
Validation loss: 2.517582126137785

Epoch: 6| Step: 9
Training loss: 1.8949837370403633
Validation loss: 2.5527282574674452

Epoch: 6| Step: 10
Training loss: 1.6970261733015444
Validation loss: 2.5340396751774295

Epoch: 6| Step: 11
Training loss: 2.2413455033472096
Validation loss: 2.5571506147984953

Epoch: 6| Step: 12
Training loss: 2.013471532377435
Validation loss: 2.5875013680078203

Epoch: 6| Step: 13
Training loss: 1.3294186742842318
Validation loss: 2.6223743567902122

Epoch: 327| Step: 0
Training loss: 1.354889187874105
Validation loss: 2.614037055184156

Epoch: 6| Step: 1
Training loss: 1.6940852350772275
Validation loss: 2.702684105581446

Epoch: 6| Step: 2
Training loss: 1.802642853005876
Validation loss: 2.7014797841535416

Epoch: 6| Step: 3
Training loss: 2.1323596068272277
Validation loss: 2.6203742216965833

Epoch: 6| Step: 4
Training loss: 1.8997504321375316
Validation loss: 2.5729378816499606

Epoch: 6| Step: 5
Training loss: 1.7132375228875043
Validation loss: 2.510522236061857

Epoch: 6| Step: 6
Training loss: 1.5688718193750797
Validation loss: 2.495109686494963

Epoch: 6| Step: 7
Training loss: 1.679602048607649
Validation loss: 2.527790987122318

Epoch: 6| Step: 8
Training loss: 1.5606017216484354
Validation loss: 2.5279339155827727

Epoch: 6| Step: 9
Training loss: 2.234198716685615
Validation loss: 2.5407037761091478

Epoch: 6| Step: 10
Training loss: 2.116496518823188
Validation loss: 2.535902747078479

Epoch: 6| Step: 11
Training loss: 1.3587338919856038
Validation loss: 2.516290809551822

Epoch: 6| Step: 12
Training loss: 1.5197626638837105
Validation loss: 2.556808042666693

Epoch: 6| Step: 13
Training loss: 1.9173130382919215
Validation loss: 2.5231256124933377

Epoch: 328| Step: 0
Training loss: 1.80506760858949
Validation loss: 2.594056168835589

Epoch: 6| Step: 1
Training loss: 1.7196985574984092
Validation loss: 2.548156868151576

Epoch: 6| Step: 2
Training loss: 2.1060119947216873
Validation loss: 2.6257145681089025

Epoch: 6| Step: 3
Training loss: 1.678096638871397
Validation loss: 2.7558606726996855

Epoch: 6| Step: 4
Training loss: 1.4633556080269154
Validation loss: 2.647342811987623

Epoch: 6| Step: 5
Training loss: 2.137700442904419
Validation loss: 2.626434191720965

Epoch: 6| Step: 6
Training loss: 1.7560607319455115
Validation loss: 2.615921853196079

Epoch: 6| Step: 7
Training loss: 1.7340858149649687
Validation loss: 2.584643190822232

Epoch: 6| Step: 8
Training loss: 1.2632293633897327
Validation loss: 2.58276615274319

Epoch: 6| Step: 9
Training loss: 1.7285328664835726
Validation loss: 2.5581031231846074

Epoch: 6| Step: 10
Training loss: 1.8278057113002242
Validation loss: 2.5435467056906473

Epoch: 6| Step: 11
Training loss: 1.6271138014568112
Validation loss: 2.563987315809602

Epoch: 6| Step: 12
Training loss: 1.6881081933290425
Validation loss: 2.5642380673874476

Epoch: 6| Step: 13
Training loss: 1.8944041415961848
Validation loss: 2.5503785622159025

Epoch: 329| Step: 0
Training loss: 1.6883532874587313
Validation loss: 2.5430131274529653

Epoch: 6| Step: 1
Training loss: 1.864355005815019
Validation loss: 2.532178473025157

Epoch: 6| Step: 2
Training loss: 1.4841584700212245
Validation loss: 2.5585580138994097

Epoch: 6| Step: 3
Training loss: 1.570526943462675
Validation loss: 2.5263095176237944

Epoch: 6| Step: 4
Training loss: 1.677274025763596
Validation loss: 2.5788565320316144

Epoch: 6| Step: 5
Training loss: 1.3207441448260235
Validation loss: 2.555053964630985

Epoch: 6| Step: 6
Training loss: 1.254367636529268
Validation loss: 2.540617543890328

Epoch: 6| Step: 7
Training loss: 1.5474032646350855
Validation loss: 2.5516260840363305

Epoch: 6| Step: 8
Training loss: 1.8909371488788653
Validation loss: 2.570296730990287

Epoch: 6| Step: 9
Training loss: 1.484804753784265
Validation loss: 2.537345391685684

Epoch: 6| Step: 10
Training loss: 1.5585528299031903
Validation loss: 2.537575388948868

Epoch: 6| Step: 11
Training loss: 1.472568903996418
Validation loss: 2.541337215980347

Epoch: 6| Step: 12
Training loss: 2.7595924922471076
Validation loss: 2.5824603995197855

Epoch: 6| Step: 13
Training loss: 1.498171804856324
Validation loss: 2.646556279893599

Epoch: 330| Step: 0
Training loss: 1.46223335117587
Validation loss: 2.5561965234163604

Epoch: 6| Step: 1
Training loss: 1.4891015543024186
Validation loss: 2.621313625006775

Epoch: 6| Step: 2
Training loss: 2.567309820008887
Validation loss: 2.6135947092227494

Epoch: 6| Step: 3
Training loss: 1.3107591619118626
Validation loss: 2.561345863949899

Epoch: 6| Step: 4
Training loss: 1.3743588513322904
Validation loss: 2.544207980506371

Epoch: 6| Step: 5
Training loss: 1.630316327532735
Validation loss: 2.482165043448457

Epoch: 6| Step: 6
Training loss: 1.1548874533508564
Validation loss: 2.520901030164791

Epoch: 6| Step: 7
Training loss: 1.7655947522298434
Validation loss: 2.5129008737239755

Epoch: 6| Step: 8
Training loss: 1.8220275527135394
Validation loss: 2.4967663992386524

Epoch: 6| Step: 9
Training loss: 1.5897812139785437
Validation loss: 2.5322375313859276

Epoch: 6| Step: 10
Training loss: 2.0161162967894923
Validation loss: 2.5234697337891845

Epoch: 6| Step: 11
Training loss: 1.921317787339593
Validation loss: 2.595107539085723

Epoch: 6| Step: 12
Training loss: 1.796327457762157
Validation loss: 2.6410559879990054

Epoch: 6| Step: 13
Training loss: 2.268326615270588
Validation loss: 2.7369469163750715

Epoch: 331| Step: 0
Training loss: 1.8627163652540486
Validation loss: 2.724938113708504

Epoch: 6| Step: 1
Training loss: 2.0422112134448347
Validation loss: 2.6610295098928822

Epoch: 6| Step: 2
Training loss: 1.853987060020251
Validation loss: 2.601067252460401

Epoch: 6| Step: 3
Training loss: 1.0153465476158232
Validation loss: 2.5875979467948644

Epoch: 6| Step: 4
Training loss: 1.2396864754643977
Validation loss: 2.5803663818060723

Epoch: 6| Step: 5
Training loss: 1.4143304728984714
Validation loss: 2.569513971802815

Epoch: 6| Step: 6
Training loss: 1.6031866258819079
Validation loss: 2.586710204572435

Epoch: 6| Step: 7
Training loss: 1.9965374895679686
Validation loss: 2.631261970812946

Epoch: 6| Step: 8
Training loss: 1.125457511696399
Validation loss: 2.585762732555498

Epoch: 6| Step: 9
Training loss: 1.1616574217995375
Validation loss: 2.5966038917018133

Epoch: 6| Step: 10
Training loss: 2.216631670606275
Validation loss: 2.5978958210622483

Epoch: 6| Step: 11
Training loss: 1.7272390705689888
Validation loss: 2.5347667330197003

Epoch: 6| Step: 12
Training loss: 2.2465552345208275
Validation loss: 2.5285392971886287

Epoch: 6| Step: 13
Training loss: 1.330516188487556
Validation loss: 2.5258932378099206

Epoch: 332| Step: 0
Training loss: 2.5680506995772814
Validation loss: 2.5302431278236575

Epoch: 6| Step: 1
Training loss: 1.731505554838025
Validation loss: 2.538994319685053

Epoch: 6| Step: 2
Training loss: 1.7554907491381002
Validation loss: 2.550157674265438

Epoch: 6| Step: 3
Training loss: 1.7240506365480082
Validation loss: 2.5378172652621767

Epoch: 6| Step: 4
Training loss: 1.0671862868920687
Validation loss: 2.5765078009634075

Epoch: 6| Step: 5
Training loss: 1.9028461897247182
Validation loss: 2.5792920024124255

Epoch: 6| Step: 6
Training loss: 1.6654419531806153
Validation loss: 2.589418125995045

Epoch: 6| Step: 7
Training loss: 2.0529809399001993
Validation loss: 2.5918689862443602

Epoch: 6| Step: 8
Training loss: 1.5882770588937263
Validation loss: 2.5030585494093094

Epoch: 6| Step: 9
Training loss: 1.6216900199993758
Validation loss: 2.487117077796703

Epoch: 6| Step: 10
Training loss: 1.2315931239043643
Validation loss: 2.440042441342939

Epoch: 6| Step: 11
Training loss: 1.3141966253497102
Validation loss: 2.489266225073033

Epoch: 6| Step: 12
Training loss: 1.3082927300698841
Validation loss: 2.5311256346743147

Epoch: 6| Step: 13
Training loss: 1.9115894768098987
Validation loss: 2.508662063078754

Epoch: 333| Step: 0
Training loss: 1.6827962097116216
Validation loss: 2.5190771043533395

Epoch: 6| Step: 1
Training loss: 1.4531711037818138
Validation loss: 2.524511559458728

Epoch: 6| Step: 2
Training loss: 2.075966423828909
Validation loss: 2.5206148404938906

Epoch: 6| Step: 3
Training loss: 1.7911617839251281
Validation loss: 2.540001829452056

Epoch: 6| Step: 4
Training loss: 0.986682156014863
Validation loss: 2.5093697756486844

Epoch: 6| Step: 5
Training loss: 1.1897239940387758
Validation loss: 2.5594842113502962

Epoch: 6| Step: 6
Training loss: 1.6878879242522076
Validation loss: 2.5802719270592367

Epoch: 6| Step: 7
Training loss: 1.8524116468273886
Validation loss: 2.567201116784656

Epoch: 6| Step: 8
Training loss: 1.5226038290114206
Validation loss: 2.6188828931545713

Epoch: 6| Step: 9
Training loss: 1.3620554925114032
Validation loss: 2.617174731171238

Epoch: 6| Step: 10
Training loss: 1.8284214790097426
Validation loss: 2.6286667539458035

Epoch: 6| Step: 11
Training loss: 1.6808688954928785
Validation loss: 2.584173517087902

Epoch: 6| Step: 12
Training loss: 1.8646646478351296
Validation loss: 2.5108768679742814

Epoch: 6| Step: 13
Training loss: 1.6656741365839443
Validation loss: 2.5493392957921244

Epoch: 334| Step: 0
Training loss: 1.3791163989507407
Validation loss: 2.5352703396008525

Epoch: 6| Step: 1
Training loss: 1.7086370322244553
Validation loss: 2.499297901747302

Epoch: 6| Step: 2
Training loss: 1.7367385018856134
Validation loss: 2.514329959985293

Epoch: 6| Step: 3
Training loss: 1.5820044244446354
Validation loss: 2.523858884541201

Epoch: 6| Step: 4
Training loss: 1.5176351529161887
Validation loss: 2.539963641544749

Epoch: 6| Step: 5
Training loss: 1.6164932603680813
Validation loss: 2.5358352418011285

Epoch: 6| Step: 6
Training loss: 1.1855905138308065
Validation loss: 2.5229982322488107

Epoch: 6| Step: 7
Training loss: 2.4303623255865308
Validation loss: 2.5889151448945356

Epoch: 6| Step: 8
Training loss: 1.4354980460445614
Validation loss: 2.5565928781828737

Epoch: 6| Step: 9
Training loss: 1.399943217760889
Validation loss: 2.615687487975073

Epoch: 6| Step: 10
Training loss: 1.3317344536236426
Validation loss: 2.546556230500579

Epoch: 6| Step: 11
Training loss: 2.0040632933712175
Validation loss: 2.626466129735502

Epoch: 6| Step: 12
Training loss: 1.851404625966537
Validation loss: 2.602339085475773

Epoch: 6| Step: 13
Training loss: 1.1473432245140323
Validation loss: 2.5765209564012124

Epoch: 335| Step: 0
Training loss: 1.5407453137941909
Validation loss: 2.564433113014251

Epoch: 6| Step: 1
Training loss: 1.9420540724670212
Validation loss: 2.595308073324447

Epoch: 6| Step: 2
Training loss: 1.5331851642309853
Validation loss: 2.5618299523132873

Epoch: 6| Step: 3
Training loss: 1.3585459494010172
Validation loss: 2.555986406684154

Epoch: 6| Step: 4
Training loss: 1.4147990294981894
Validation loss: 2.519946712177734

Epoch: 6| Step: 5
Training loss: 1.63856973432044
Validation loss: 2.537420138776377

Epoch: 6| Step: 6
Training loss: 1.397101120707094
Validation loss: 2.5378051305008675

Epoch: 6| Step: 7
Training loss: 1.2714226820550638
Validation loss: 2.5544042867760153

Epoch: 6| Step: 8
Training loss: 2.5317073455951093
Validation loss: 2.6118654408264375

Epoch: 6| Step: 9
Training loss: 1.3495888825777793
Validation loss: 2.5661121898624173

Epoch: 6| Step: 10
Training loss: 1.5818275603103047
Validation loss: 2.5313012859659043

Epoch: 6| Step: 11
Training loss: 1.0695977713473945
Validation loss: 2.513058263206754

Epoch: 6| Step: 12
Training loss: 1.7190400312377263
Validation loss: 2.5555736470849055

Epoch: 6| Step: 13
Training loss: 1.9732671112899995
Validation loss: 2.502704746687593

Epoch: 336| Step: 0
Training loss: 1.5896103896225322
Validation loss: 2.4911569599209122

Epoch: 6| Step: 1
Training loss: 1.6110050871737365
Validation loss: 2.4891426196457056

Epoch: 6| Step: 2
Training loss: 1.4966303806678156
Validation loss: 2.56650628563142

Epoch: 6| Step: 3
Training loss: 1.8741645859225766
Validation loss: 2.571633583996591

Epoch: 6| Step: 4
Training loss: 1.7440807507395113
Validation loss: 2.556885064788357

Epoch: 6| Step: 5
Training loss: 1.36199742068524
Validation loss: 2.522911812241848

Epoch: 6| Step: 6
Training loss: 1.194368525736542
Validation loss: 2.5321258630822183

Epoch: 6| Step: 7
Training loss: 1.6770060582651476
Validation loss: 2.513254071152831

Epoch: 6| Step: 8
Training loss: 1.3824974175234193
Validation loss: 2.527519994267366

Epoch: 6| Step: 9
Training loss: 1.750496249001218
Validation loss: 2.5593956076662194

Epoch: 6| Step: 10
Training loss: 1.4791134390410217
Validation loss: 2.5468246361369067

Epoch: 6| Step: 11
Training loss: 1.7484709326553582
Validation loss: 2.5241840939084432

Epoch: 6| Step: 12
Training loss: 1.780538918960831
Validation loss: 2.5570999405124626

Epoch: 6| Step: 13
Training loss: 1.8026948967906125
Validation loss: 2.5056865312407064

Epoch: 337| Step: 0
Training loss: 1.2708619640856529
Validation loss: 2.547913322124225

Epoch: 6| Step: 1
Training loss: 1.4359163600291165
Validation loss: 2.537370699139141

Epoch: 6| Step: 2
Training loss: 1.7462354768928723
Validation loss: 2.502238884398987

Epoch: 6| Step: 3
Training loss: 1.6713009142770288
Validation loss: 2.5396598387145466

Epoch: 6| Step: 4
Training loss: 1.3482995308567185
Validation loss: 2.5388174711496645

Epoch: 6| Step: 5
Training loss: 1.539898872646878
Validation loss: 2.55742435667874

Epoch: 6| Step: 6
Training loss: 1.8807166373181405
Validation loss: 2.5598237243203092

Epoch: 6| Step: 7
Training loss: 1.5271534520696382
Validation loss: 2.5136112185068207

Epoch: 6| Step: 8
Training loss: 1.275508951069742
Validation loss: 2.514792057614905

Epoch: 6| Step: 9
Training loss: 1.275719125686933
Validation loss: 2.5294639188575037

Epoch: 6| Step: 10
Training loss: 1.570306654582365
Validation loss: 2.591845138472224

Epoch: 6| Step: 11
Training loss: 1.439963510368873
Validation loss: 2.5346178012979017

Epoch: 6| Step: 12
Training loss: 2.0003337581621143
Validation loss: 2.599154391694465

Epoch: 6| Step: 13
Training loss: 2.274392048854931
Validation loss: 2.573427378718151

Epoch: 338| Step: 0
Training loss: 1.7446513864481912
Validation loss: 2.597370944692084

Epoch: 6| Step: 1
Training loss: 1.4106160521149527
Validation loss: 2.549936510056119

Epoch: 6| Step: 2
Training loss: 1.2797552554273592
Validation loss: 2.5282250999497715

Epoch: 6| Step: 3
Training loss: 1.8306487180163824
Validation loss: 2.531386289341854

Epoch: 6| Step: 4
Training loss: 1.6422110021417529
Validation loss: 2.519162701603525

Epoch: 6| Step: 5
Training loss: 1.421533229121494
Validation loss: 2.511329838300271

Epoch: 6| Step: 6
Training loss: 1.467589386487352
Validation loss: 2.522939036359666

Epoch: 6| Step: 7
Training loss: 1.5388084240628517
Validation loss: 2.5771440277312436

Epoch: 6| Step: 8
Training loss: 1.563223709351453
Validation loss: 2.5346401102593568

Epoch: 6| Step: 9
Training loss: 1.1636296433964575
Validation loss: 2.560200395961115

Epoch: 6| Step: 10
Training loss: 1.7309464942600654
Validation loss: 2.5519413240328146

Epoch: 6| Step: 11
Training loss: 1.8732470901611242
Validation loss: 2.5622355782147053

Epoch: 6| Step: 12
Training loss: 1.949455781946377
Validation loss: 2.5489009140358823

Epoch: 6| Step: 13
Training loss: 1.2975954559434755
Validation loss: 2.591696665632142

Epoch: 339| Step: 0
Training loss: 1.2348448909236325
Validation loss: 2.5874681504603703

Epoch: 6| Step: 1
Training loss: 1.4696878725960267
Validation loss: 2.6074952075947126

Epoch: 6| Step: 2
Training loss: 1.621683477658953
Validation loss: 2.6198931321098873

Epoch: 6| Step: 3
Training loss: 1.5238923005273592
Validation loss: 2.585344844028502

Epoch: 6| Step: 4
Training loss: 1.2737866256584338
Validation loss: 2.5346223791190754

Epoch: 6| Step: 5
Training loss: 1.4332587658906684
Validation loss: 2.56158471237194

Epoch: 6| Step: 6
Training loss: 1.0167504750295917
Validation loss: 2.526905963288757

Epoch: 6| Step: 7
Training loss: 1.4339446176344717
Validation loss: 2.5523409006324527

Epoch: 6| Step: 8
Training loss: 1.9996783474717048
Validation loss: 2.549784131979613

Epoch: 6| Step: 9
Training loss: 1.043363803524215
Validation loss: 2.526007855900227

Epoch: 6| Step: 10
Training loss: 2.0858302856780693
Validation loss: 2.5404604384213627

Epoch: 6| Step: 11
Training loss: 2.183895083468
Validation loss: 2.5529584253663766

Epoch: 6| Step: 12
Training loss: 1.4483338813795334
Validation loss: 2.535896197202248

Epoch: 6| Step: 13
Training loss: 1.5217673512323937
Validation loss: 2.552803192339624

Epoch: 340| Step: 0
Training loss: 1.2835351058741926
Validation loss: 2.5640210545251176

Epoch: 6| Step: 1
Training loss: 2.075299285079178
Validation loss: 2.5857290009097693

Epoch: 6| Step: 2
Training loss: 1.4533920862996863
Validation loss: 2.566976529362704

Epoch: 6| Step: 3
Training loss: 1.424989245190107
Validation loss: 2.5483932572357584

Epoch: 6| Step: 4
Training loss: 1.7062659741446893
Validation loss: 2.5639470829345807

Epoch: 6| Step: 5
Training loss: 1.3678236435071751
Validation loss: 2.612195361930613

Epoch: 6| Step: 6
Training loss: 1.6405861986204078
Validation loss: 2.626311564897258

Epoch: 6| Step: 7
Training loss: 1.7983804118676294
Validation loss: 2.5829602146390336

Epoch: 6| Step: 8
Training loss: 1.444325042745421
Validation loss: 2.562683688147254

Epoch: 6| Step: 9
Training loss: 1.1671518894875939
Validation loss: 2.6338860863191034

Epoch: 6| Step: 10
Training loss: 1.2924226373950292
Validation loss: 2.5184101932526968

Epoch: 6| Step: 11
Training loss: 0.8911711707973098
Validation loss: 2.5442438713110618

Epoch: 6| Step: 12
Training loss: 2.3517228892432303
Validation loss: 2.5215320932298906

Epoch: 6| Step: 13
Training loss: 1.6754749080335256
Validation loss: 2.531665579507011

Epoch: 341| Step: 0
Training loss: 1.2265568143870762
Validation loss: 2.5533444046132403

Epoch: 6| Step: 1
Training loss: 1.7464862698054333
Validation loss: 2.532104520631144

Epoch: 6| Step: 2
Training loss: 1.7174103804837346
Validation loss: 2.5675535381050514

Epoch: 6| Step: 3
Training loss: 1.9151169966772041
Validation loss: 2.5697754798464927

Epoch: 6| Step: 4
Training loss: 1.2816383424579882
Validation loss: 2.5224008389337373

Epoch: 6| Step: 5
Training loss: 1.2561483807053826
Validation loss: 2.5603028391363987

Epoch: 6| Step: 6
Training loss: 1.7205083695695615
Validation loss: 2.537301243982882

Epoch: 6| Step: 7
Training loss: 1.7124340183884412
Validation loss: 2.635101530711599

Epoch: 6| Step: 8
Training loss: 1.3955282285890673
Validation loss: 2.600308181764611

Epoch: 6| Step: 9
Training loss: 1.5767902735243227
Validation loss: 2.5294502359092106

Epoch: 6| Step: 10
Training loss: 1.74277674542038
Validation loss: 2.5681720544461184

Epoch: 6| Step: 11
Training loss: 1.4456387538230897
Validation loss: 2.554244256720947

Epoch: 6| Step: 12
Training loss: 1.9475925060235375
Validation loss: 2.535398576515711

Epoch: 6| Step: 13
Training loss: 1.7022062150666264
Validation loss: 2.531246044014559

Epoch: 342| Step: 0
Training loss: 1.3867888526927306
Validation loss: 2.5058411706316215

Epoch: 6| Step: 1
Training loss: 1.3491258652195754
Validation loss: 2.593343940417344

Epoch: 6| Step: 2
Training loss: 1.1378817033139668
Validation loss: 2.57193027280895

Epoch: 6| Step: 3
Training loss: 1.5510408198668366
Validation loss: 2.614035200640376

Epoch: 6| Step: 4
Training loss: 1.5534096838778804
Validation loss: 2.6360320225990974

Epoch: 6| Step: 5
Training loss: 2.083558515458903
Validation loss: 2.6098648418615737

Epoch: 6| Step: 6
Training loss: 1.1050526944710275
Validation loss: 2.569689797953183

Epoch: 6| Step: 7
Training loss: 1.5635095767956035
Validation loss: 2.6259125455479952

Epoch: 6| Step: 8
Training loss: 1.408483088542473
Validation loss: 2.5430877548319173

Epoch: 6| Step: 9
Training loss: 1.6806328530658323
Validation loss: 2.5605056802058046

Epoch: 6| Step: 10
Training loss: 1.8629774569725712
Validation loss: 2.5660848275958066

Epoch: 6| Step: 11
Training loss: 1.85235945535258
Validation loss: 2.539844294766716

Epoch: 6| Step: 12
Training loss: 1.3299744239298346
Validation loss: 2.5133603408569885

Epoch: 6| Step: 13
Training loss: 1.774113060084779
Validation loss: 2.543832080588409

Epoch: 343| Step: 0
Training loss: 1.9405778618092449
Validation loss: 2.4767861892008756

Epoch: 6| Step: 1
Training loss: 1.28419166240258
Validation loss: 2.487235399930403

Epoch: 6| Step: 2
Training loss: 1.2007509067650317
Validation loss: 2.4775512197815472

Epoch: 6| Step: 3
Training loss: 1.219554928751946
Validation loss: 2.4506900389761954

Epoch: 6| Step: 4
Training loss: 1.3870513087424368
Validation loss: 2.4967225366799997

Epoch: 6| Step: 5
Training loss: 1.277418175258555
Validation loss: 2.5257376314175204

Epoch: 6| Step: 6
Training loss: 1.2456141299219898
Validation loss: 2.502494616431239

Epoch: 6| Step: 7
Training loss: 1.8723256430028525
Validation loss: 2.595741549155581

Epoch: 6| Step: 8
Training loss: 1.831468442836101
Validation loss: 2.5758120709959607

Epoch: 6| Step: 9
Training loss: 1.431713732092712
Validation loss: 2.6062462298200555

Epoch: 6| Step: 10
Training loss: 1.8483183563607113
Validation loss: 2.6338897976242

Epoch: 6| Step: 11
Training loss: 1.7839351960502
Validation loss: 2.6578922954214814

Epoch: 6| Step: 12
Training loss: 1.8376782544925845
Validation loss: 2.6892306942957376

Epoch: 6| Step: 13
Training loss: 1.634054341415316
Validation loss: 2.6388724867550812

Epoch: 344| Step: 0
Training loss: 1.5254881530921862
Validation loss: 2.5756994994818916

Epoch: 6| Step: 1
Training loss: 1.457470702307081
Validation loss: 2.58371819941503

Epoch: 6| Step: 2
Training loss: 1.1935618427045285
Validation loss: 2.5989255934942053

Epoch: 6| Step: 3
Training loss: 1.517253826353384
Validation loss: 2.515460559848935

Epoch: 6| Step: 4
Training loss: 1.523920383706598
Validation loss: 2.5551924677927897

Epoch: 6| Step: 5
Training loss: 2.0294296324025467
Validation loss: 2.523698932974347

Epoch: 6| Step: 6
Training loss: 1.0637216276874424
Validation loss: 2.565387029913953

Epoch: 6| Step: 7
Training loss: 2.1175346512194295
Validation loss: 2.5815744154594755

Epoch: 6| Step: 8
Training loss: 1.8957744491431268
Validation loss: 2.602119974123222

Epoch: 6| Step: 9
Training loss: 1.21905577320628
Validation loss: 2.60938949733217

Epoch: 6| Step: 10
Training loss: 1.485685232030357
Validation loss: 2.736894010361794

Epoch: 6| Step: 11
Training loss: 1.45950916661948
Validation loss: 2.6951671469006264

Epoch: 6| Step: 12
Training loss: 1.5996086297598233
Validation loss: 2.6751749284536794

Epoch: 6| Step: 13
Training loss: 2.0586898752314227
Validation loss: 2.6640178270220805

Epoch: 345| Step: 0
Training loss: 1.1542206559940733
Validation loss: 2.5467950539240283

Epoch: 6| Step: 1
Training loss: 1.0253235422625138
Validation loss: 2.5558091558410085

Epoch: 6| Step: 2
Training loss: 1.2544170064312206
Validation loss: 2.5480288210805324

Epoch: 6| Step: 3
Training loss: 1.5935486311013727
Validation loss: 2.4995645143775835

Epoch: 6| Step: 4
Training loss: 1.473007848238318
Validation loss: 2.524159756215777

Epoch: 6| Step: 5
Training loss: 1.689889346568837
Validation loss: 2.498712541949216

Epoch: 6| Step: 6
Training loss: 1.6150821120466148
Validation loss: 2.5225443484714978

Epoch: 6| Step: 7
Training loss: 1.121360933053379
Validation loss: 2.4869486755312757

Epoch: 6| Step: 8
Training loss: 1.544519113928081
Validation loss: 2.515775972183934

Epoch: 6| Step: 9
Training loss: 2.0256210975880093
Validation loss: 2.4998090194234237

Epoch: 6| Step: 10
Training loss: 1.5807863965638367
Validation loss: 2.538092544349407

Epoch: 6| Step: 11
Training loss: 2.0845095429470817
Validation loss: 2.611676691454368

Epoch: 6| Step: 12
Training loss: 1.139224407478655
Validation loss: 2.602799038668441

Epoch: 6| Step: 13
Training loss: 1.6335767207815626
Validation loss: 2.620797365565445

Epoch: 346| Step: 0
Training loss: 1.453787375811822
Validation loss: 2.6340329956955983

Epoch: 6| Step: 1
Training loss: 1.4449946698417167
Validation loss: 2.5742028042459073

Epoch: 6| Step: 2
Training loss: 1.0302431798170912
Validation loss: 2.5630951012063843

Epoch: 6| Step: 3
Training loss: 1.7659691669282507
Validation loss: 2.6061139925834156

Epoch: 6| Step: 4
Training loss: 1.1240298538621436
Validation loss: 2.589285750616164

Epoch: 6| Step: 5
Training loss: 1.3765155502782291
Validation loss: 2.6065967182821623

Epoch: 6| Step: 6
Training loss: 1.5601277462910896
Validation loss: 2.6398944784759855

Epoch: 6| Step: 7
Training loss: 1.8478948265714636
Validation loss: 2.6220733737276514

Epoch: 6| Step: 8
Training loss: 1.6349498139124794
Validation loss: 2.601095102230046

Epoch: 6| Step: 9
Training loss: 1.865983391208472
Validation loss: 2.5856892215903478

Epoch: 6| Step: 10
Training loss: 1.2204370803836193
Validation loss: 2.5673991488515813

Epoch: 6| Step: 11
Training loss: 1.539597316707692
Validation loss: 2.6141776622540567

Epoch: 6| Step: 12
Training loss: 1.7171034815802682
Validation loss: 2.569604994652305

Epoch: 6| Step: 13
Training loss: 2.255191958561066
Validation loss: 2.6160244307441713

Epoch: 347| Step: 0
Training loss: 1.1657482971761441
Validation loss: 2.5917142439478953

Epoch: 6| Step: 1
Training loss: 1.3329131040359556
Validation loss: 2.6233754050513722

Epoch: 6| Step: 2
Training loss: 1.917694320779469
Validation loss: 2.6146784356034103

Epoch: 6| Step: 3
Training loss: 1.3223549659106402
Validation loss: 2.58375574831976

Epoch: 6| Step: 4
Training loss: 1.2486976992143184
Validation loss: 2.6065897286403104

Epoch: 6| Step: 5
Training loss: 1.6215773263350144
Validation loss: 2.555977358653599

Epoch: 6| Step: 6
Training loss: 1.3884835202671535
Validation loss: 2.5721635269606944

Epoch: 6| Step: 7
Training loss: 1.3500786723066314
Validation loss: 2.6028504414990827

Epoch: 6| Step: 8
Training loss: 1.441519962777251
Validation loss: 2.576463013365556

Epoch: 6| Step: 9
Training loss: 2.405695269166147
Validation loss: 2.6227678011785036

Epoch: 6| Step: 10
Training loss: 1.7502912551470506
Validation loss: 2.6155457314861623

Epoch: 6| Step: 11
Training loss: 1.188762244914595
Validation loss: 2.586642297006461

Epoch: 6| Step: 12
Training loss: 1.7826731166798997
Validation loss: 2.5652051618545033

Epoch: 6| Step: 13
Training loss: 1.2953424245509102
Validation loss: 2.5063626860972983

Epoch: 348| Step: 0
Training loss: 0.984476114559693
Validation loss: 2.5896046922763962

Epoch: 6| Step: 1
Training loss: 1.2643086216200614
Validation loss: 2.5455568330977005

Epoch: 6| Step: 2
Training loss: 1.5111985210930456
Validation loss: 2.5131536234557177

Epoch: 6| Step: 3
Training loss: 1.379464962941928
Validation loss: 2.4544893589096057

Epoch: 6| Step: 4
Training loss: 1.583001712737901
Validation loss: 2.499865989272198

Epoch: 6| Step: 5
Training loss: 1.552016988612133
Validation loss: 2.497641388585711

Epoch: 6| Step: 6
Training loss: 1.0034931683728332
Validation loss: 2.4934148446909754

Epoch: 6| Step: 7
Training loss: 2.5835142277376946
Validation loss: 2.5259797288570067

Epoch: 6| Step: 8
Training loss: 1.463801061194085
Validation loss: 2.4624633741156194

Epoch: 6| Step: 9
Training loss: 1.4132724472792384
Validation loss: 2.4655713893024194

Epoch: 6| Step: 10
Training loss: 1.2178184176705753
Validation loss: 2.4651326424825006

Epoch: 6| Step: 11
Training loss: 1.4188460901464273
Validation loss: 2.490565378966416

Epoch: 6| Step: 12
Training loss: 1.010112592162334
Validation loss: 2.547826187594232

Epoch: 6| Step: 13
Training loss: 1.8000424539010038
Validation loss: 2.5156138481066708

Epoch: 349| Step: 0
Training loss: 1.3163909911225022
Validation loss: 2.5470245411038404

Epoch: 6| Step: 1
Training loss: 1.3532810640968096
Validation loss: 2.5936301483285087

Epoch: 6| Step: 2
Training loss: 1.4822042554261767
Validation loss: 2.544031970792887

Epoch: 6| Step: 3
Training loss: 1.3266997824582087
Validation loss: 2.584470496052749

Epoch: 6| Step: 4
Training loss: 1.133983716921824
Validation loss: 2.5519791925682207

Epoch: 6| Step: 5
Training loss: 1.3171939474108683
Validation loss: 2.5202257879720245

Epoch: 6| Step: 6
Training loss: 1.5364834627154698
Validation loss: 2.5680264990935733

Epoch: 6| Step: 7
Training loss: 1.664842736088602
Validation loss: 2.5491465636357824

Epoch: 6| Step: 8
Training loss: 2.0828709152741136
Validation loss: 2.5193947136524946

Epoch: 6| Step: 9
Training loss: 1.211693656853405
Validation loss: 2.524782450277458

Epoch: 6| Step: 10
Training loss: 1.2298071641875552
Validation loss: 2.489756324110143

Epoch: 6| Step: 11
Training loss: 1.4141788329434897
Validation loss: 2.547089440926954

Epoch: 6| Step: 12
Training loss: 1.4197870371522197
Validation loss: 2.5258754452683454

Epoch: 6| Step: 13
Training loss: 1.7203560001649272
Validation loss: 2.5533310208256195

Epoch: 350| Step: 0
Training loss: 1.2015814850377593
Validation loss: 2.515355887540994

Epoch: 6| Step: 1
Training loss: 1.5658936077872
Validation loss: 2.551574490221751

Epoch: 6| Step: 2
Training loss: 1.5998897842354798
Validation loss: 2.542735419675422

Epoch: 6| Step: 3
Training loss: 1.7862527430562019
Validation loss: 2.5576691798824176

Epoch: 6| Step: 4
Training loss: 1.727641118271347
Validation loss: 2.5091307949195047

Epoch: 6| Step: 5
Training loss: 1.1278405885060463
Validation loss: 2.5186530896799137

Epoch: 6| Step: 6
Training loss: 1.9936821809433016
Validation loss: 2.5272150571938696

Epoch: 6| Step: 7
Training loss: 1.5395263127912069
Validation loss: 2.51118173192831

Epoch: 6| Step: 8
Training loss: 1.0561504813718843
Validation loss: 2.545022520903724

Epoch: 6| Step: 9
Training loss: 1.29742116802548
Validation loss: 2.5302060647208067

Epoch: 6| Step: 10
Training loss: 1.7322146733695685
Validation loss: 2.555647021421341

Epoch: 6| Step: 11
Training loss: 1.1052551063086578
Validation loss: 2.524824566301905

Epoch: 6| Step: 12
Training loss: 0.9724134885264354
Validation loss: 2.4970869417597847

Epoch: 6| Step: 13
Training loss: 1.5590400534837774
Validation loss: 2.5397165561329897

Epoch: 351| Step: 0
Training loss: 1.4660523985050307
Validation loss: 2.581337793810724

Epoch: 6| Step: 1
Training loss: 2.042325970859289
Validation loss: 2.564071932970386

Epoch: 6| Step: 2
Training loss: 1.7809387738232827
Validation loss: 2.542746772980848

Epoch: 6| Step: 3
Training loss: 1.0217417288852155
Validation loss: 2.558457799507679

Epoch: 6| Step: 4
Training loss: 2.2729867180210914
Validation loss: 2.539818800748226

Epoch: 6| Step: 5
Training loss: 1.2932817247423751
Validation loss: 2.531650903923515

Epoch: 6| Step: 6
Training loss: 0.9656435473984819
Validation loss: 2.551863887979738

Epoch: 6| Step: 7
Training loss: 1.4259533921927225
Validation loss: 2.6175537764044856

Epoch: 6| Step: 8
Training loss: 1.8022414636048625
Validation loss: 2.6714368464650406

Epoch: 6| Step: 9
Training loss: 1.5109434678000278
Validation loss: 2.5911338358590155

Epoch: 6| Step: 10
Training loss: 1.6298395863098494
Validation loss: 2.5634617900119987

Epoch: 6| Step: 11
Training loss: 1.0878390123598867
Validation loss: 2.5381034409165437

Epoch: 6| Step: 12
Training loss: 1.6798788272210314
Validation loss: 2.553341914611553

Epoch: 6| Step: 13
Training loss: 1.2971527078034242
Validation loss: 2.5579452663508198

Epoch: 352| Step: 0
Training loss: 1.2786716476704065
Validation loss: 2.490578031077097

Epoch: 6| Step: 1
Training loss: 1.0306013552681415
Validation loss: 2.5036510351349324

Epoch: 6| Step: 2
Training loss: 1.1140808446371615
Validation loss: 2.5287347078010263

Epoch: 6| Step: 3
Training loss: 1.2706362566282787
Validation loss: 2.538476674893222

Epoch: 6| Step: 4
Training loss: 1.795911182152984
Validation loss: 2.524385390374023

Epoch: 6| Step: 5
Training loss: 1.210805479667017
Validation loss: 2.5307641210586946

Epoch: 6| Step: 6
Training loss: 2.056826330424577
Validation loss: 2.52570001448134

Epoch: 6| Step: 7
Training loss: 1.2679008461003534
Validation loss: 2.5410141550265575

Epoch: 6| Step: 8
Training loss: 1.686004399765627
Validation loss: 2.500945158948336

Epoch: 6| Step: 9
Training loss: 1.2575831233738883
Validation loss: 2.4792646073515003

Epoch: 6| Step: 10
Training loss: 1.3257720749132376
Validation loss: 2.5154139744169868

Epoch: 6| Step: 11
Training loss: 1.0885012982684459
Validation loss: 2.520153329627477

Epoch: 6| Step: 12
Training loss: 1.8819916388055329
Validation loss: 2.54802907060002

Epoch: 6| Step: 13
Training loss: 1.7576953085934897
Validation loss: 2.5178263886856067

Epoch: 353| Step: 0
Training loss: 1.4962987535225347
Validation loss: 2.5627789229272766

Epoch: 6| Step: 1
Training loss: 1.7201807482694715
Validation loss: 2.5284299329418856

Epoch: 6| Step: 2
Training loss: 1.6104471283565356
Validation loss: 2.5625817045506594

Epoch: 6| Step: 3
Training loss: 0.8477011110590783
Validation loss: 2.533670484753347

Epoch: 6| Step: 4
Training loss: 0.8982956484060192
Validation loss: 2.5753748087023896

Epoch: 6| Step: 5
Training loss: 1.2837669492529404
Validation loss: 2.5878029325010705

Epoch: 6| Step: 6
Training loss: 1.8760565641900047
Validation loss: 2.544645866832053

Epoch: 6| Step: 7
Training loss: 1.3797373225892322
Validation loss: 2.5261233182209977

Epoch: 6| Step: 8
Training loss: 2.0512316981120393
Validation loss: 2.5195467689686786

Epoch: 6| Step: 9
Training loss: 1.3501979576779113
Validation loss: 2.5266225219089353

Epoch: 6| Step: 10
Training loss: 1.1456079723801333
Validation loss: 2.5299148020767035

Epoch: 6| Step: 11
Training loss: 1.8790253345716328
Validation loss: 2.5078729798500015

Epoch: 6| Step: 12
Training loss: 1.2297066402278667
Validation loss: 2.4901756529024097

Epoch: 6| Step: 13
Training loss: 1.2237181515781945
Validation loss: 2.468384325332298

Epoch: 354| Step: 0
Training loss: 1.4797964053977908
Validation loss: 2.4767889326454937

Epoch: 6| Step: 1
Training loss: 1.3936847928107834
Validation loss: 2.486100946851964

Epoch: 6| Step: 2
Training loss: 1.696911668469089
Validation loss: 2.5056051123789205

Epoch: 6| Step: 3
Training loss: 2.104940656065596
Validation loss: 2.5079561946973623

Epoch: 6| Step: 4
Training loss: 1.70454046942242
Validation loss: 2.4682515441906188

Epoch: 6| Step: 5
Training loss: 1.37640621064483
Validation loss: 2.5235919413039407

Epoch: 6| Step: 6
Training loss: 1.4770549780415585
Validation loss: 2.5809926585935865

Epoch: 6| Step: 7
Training loss: 1.1816993383527925
Validation loss: 2.5590405566654013

Epoch: 6| Step: 8
Training loss: 1.712220568726605
Validation loss: 2.6242441269833474

Epoch: 6| Step: 9
Training loss: 1.1111772967865203
Validation loss: 2.548927291558465

Epoch: 6| Step: 10
Training loss: 1.3491309901125448
Validation loss: 2.561057545406782

Epoch: 6| Step: 11
Training loss: 1.2508537238126025
Validation loss: 2.571674453746636

Epoch: 6| Step: 12
Training loss: 1.3974051047847067
Validation loss: 2.5496293290946475

Epoch: 6| Step: 13
Training loss: 1.5948648480402356
Validation loss: 2.6087844241225437

Epoch: 355| Step: 0
Training loss: 1.4402149932691155
Validation loss: 2.578458167232809

Epoch: 6| Step: 1
Training loss: 1.5570359631441697
Validation loss: 2.6241240175120244

Epoch: 6| Step: 2
Training loss: 0.9592824189188637
Validation loss: 2.571739921251683

Epoch: 6| Step: 3
Training loss: 1.3187775125390695
Validation loss: 2.5443038443718056

Epoch: 6| Step: 4
Training loss: 1.981863399821738
Validation loss: 2.5301651690400155

Epoch: 6| Step: 5
Training loss: 1.0225797363753515
Validation loss: 2.4763601964559085

Epoch: 6| Step: 6
Training loss: 1.359861878646045
Validation loss: 2.476696143169591

Epoch: 6| Step: 7
Training loss: 1.9009196063705676
Validation loss: 2.5105608401442567

Epoch: 6| Step: 8
Training loss: 1.302477718389666
Validation loss: 2.5217063642588804

Epoch: 6| Step: 9
Training loss: 1.6157852211462493
Validation loss: 2.51487156739127

Epoch: 6| Step: 10
Training loss: 1.7875550428332123
Validation loss: 2.5726572490265056

Epoch: 6| Step: 11
Training loss: 1.5508312150030958
Validation loss: 2.579816028605527

Epoch: 6| Step: 12
Training loss: 1.7587319915001334
Validation loss: 2.537747931934935

Epoch: 6| Step: 13
Training loss: 1.1456891865082384
Validation loss: 2.4958130743852878

Epoch: 356| Step: 0
Training loss: 1.4430050137459831
Validation loss: 2.467940749150132

Epoch: 6| Step: 1
Training loss: 1.7534614117816856
Validation loss: 2.512827990681487

Epoch: 6| Step: 2
Training loss: 1.3384199668489378
Validation loss: 2.5557799497049394

Epoch: 6| Step: 3
Training loss: 1.3308321122315374
Validation loss: 2.563606504023128

Epoch: 6| Step: 4
Training loss: 1.3239327180887088
Validation loss: 2.5844288676996903

Epoch: 6| Step: 5
Training loss: 1.5837879364841385
Validation loss: 2.5497811086366307

Epoch: 6| Step: 6
Training loss: 1.9890275615011916
Validation loss: 2.560375170039059

Epoch: 6| Step: 7
Training loss: 1.0666883605499382
Validation loss: 2.5388789027421343

Epoch: 6| Step: 8
Training loss: 1.3431185636015583
Validation loss: 2.6323417295509053

Epoch: 6| Step: 9
Training loss: 1.4391584366454662
Validation loss: 2.5516554700862013

Epoch: 6| Step: 10
Training loss: 1.184322875393204
Validation loss: 2.5593444499458107

Epoch: 6| Step: 11
Training loss: 1.7054461139988875
Validation loss: 2.544419733621117

Epoch: 6| Step: 12
Training loss: 1.2956087295975396
Validation loss: 2.552443223347321

Epoch: 6| Step: 13
Training loss: 1.4407229574334142
Validation loss: 2.5616801276150096

Epoch: 357| Step: 0
Training loss: 1.3593095785600093
Validation loss: 2.5772039752703573

Epoch: 6| Step: 1
Training loss: 1.7626477686844766
Validation loss: 2.5260068333901597

Epoch: 6| Step: 2
Training loss: 1.279191759755956
Validation loss: 2.4798427242353607

Epoch: 6| Step: 3
Training loss: 1.7196652836363653
Validation loss: 2.541164267764291

Epoch: 6| Step: 4
Training loss: 1.0006810491757927
Validation loss: 2.5475586985675314

Epoch: 6| Step: 5
Training loss: 1.133759885111891
Validation loss: 2.4965884693982154

Epoch: 6| Step: 6
Training loss: 1.211524771751593
Validation loss: 2.5448113410388

Epoch: 6| Step: 7
Training loss: 1.43478502052215
Validation loss: 2.529557553166602

Epoch: 6| Step: 8
Training loss: 1.4402915552147166
Validation loss: 2.5164427918737102

Epoch: 6| Step: 9
Training loss: 0.8598717727545117
Validation loss: 2.506860807954517

Epoch: 6| Step: 10
Training loss: 1.3516868578198071
Validation loss: 2.523875400273829

Epoch: 6| Step: 11
Training loss: 1.6620547221754207
Validation loss: 2.5846783510320708

Epoch: 6| Step: 12
Training loss: 1.5454736392223745
Validation loss: 2.5547783667282413

Epoch: 6| Step: 13
Training loss: 1.3666585716535051
Validation loss: 2.5302974808243928

Epoch: 358| Step: 0
Training loss: 1.4357307990967443
Validation loss: 2.5485221825334605

Epoch: 6| Step: 1
Training loss: 1.1380614645169358
Validation loss: 2.537948395271816

Epoch: 6| Step: 2
Training loss: 1.099705910383581
Validation loss: 2.580095851778579

Epoch: 6| Step: 3
Training loss: 1.2974081207555193
Validation loss: 2.5737389139977562

Epoch: 6| Step: 4
Training loss: 1.1000869283140364
Validation loss: 2.5676782282572663

Epoch: 6| Step: 5
Training loss: 1.3741013451282804
Validation loss: 2.5639946928014

Epoch: 6| Step: 6
Training loss: 0.8456937159483986
Validation loss: 2.504599520382897

Epoch: 6| Step: 7
Training loss: 1.3751869074625975
Validation loss: 2.571212456403903

Epoch: 6| Step: 8
Training loss: 1.232769852010554
Validation loss: 2.521920235191521

Epoch: 6| Step: 9
Training loss: 1.5865326314432222
Validation loss: 2.4877572857884203

Epoch: 6| Step: 10
Training loss: 1.1697429335450646
Validation loss: 2.5413054668191934

Epoch: 6| Step: 11
Training loss: 1.4267468670706527
Validation loss: 2.5541677461490147

Epoch: 6| Step: 12
Training loss: 1.5492770108547131
Validation loss: 2.5943699444383292

Epoch: 6| Step: 13
Training loss: 2.057662840247581
Validation loss: 2.6193248315143873

Epoch: 359| Step: 0
Training loss: 1.8317068500062288
Validation loss: 2.565272637787618

Epoch: 6| Step: 1
Training loss: 1.0701788937232026
Validation loss: 2.580817864231765

Epoch: 6| Step: 2
Training loss: 1.5078747988465693
Validation loss: 2.6099355403935087

Epoch: 6| Step: 3
Training loss: 1.699051982544689
Validation loss: 2.5689003107624746

Epoch: 6| Step: 4
Training loss: 1.4634332401752077
Validation loss: 2.5837908513998706

Epoch: 6| Step: 5
Training loss: 1.034496284127879
Validation loss: 2.5307570868411773

Epoch: 6| Step: 6
Training loss: 0.9013310153435729
Validation loss: 2.5416079238190137

Epoch: 6| Step: 7
Training loss: 1.479733971708908
Validation loss: 2.541546949058145

Epoch: 6| Step: 8
Training loss: 1.1449621125162157
Validation loss: 2.5638864689635645

Epoch: 6| Step: 9
Training loss: 1.557009702266386
Validation loss: 2.587733103438539

Epoch: 6| Step: 10
Training loss: 1.4178387711066698
Validation loss: 2.573664959241662

Epoch: 6| Step: 11
Training loss: 1.3842447482245925
Validation loss: 2.58977422913403

Epoch: 6| Step: 12
Training loss: 1.396987930955683
Validation loss: 2.550935219698227

Epoch: 6| Step: 13
Training loss: 1.8554151667838634
Validation loss: 2.616792882519649

Epoch: 360| Step: 0
Training loss: 1.7551289058413901
Validation loss: 2.639332396620876

Epoch: 6| Step: 1
Training loss: 1.4148476459990877
Validation loss: 2.702597314856908

Epoch: 6| Step: 2
Training loss: 1.3980167544483806
Validation loss: 2.6803682758175973

Epoch: 6| Step: 3
Training loss: 1.4861184572571071
Validation loss: 2.6674301624064145

Epoch: 6| Step: 4
Training loss: 1.3996817738031992
Validation loss: 2.6233325157947873

Epoch: 6| Step: 5
Training loss: 1.2407276524274653
Validation loss: 2.613773499159257

Epoch: 6| Step: 6
Training loss: 2.145349565312202
Validation loss: 2.6064607865851

Epoch: 6| Step: 7
Training loss: 1.0168343606341437
Validation loss: 2.5968684710907524

Epoch: 6| Step: 8
Training loss: 1.0702653860595932
Validation loss: 2.527803987383475

Epoch: 6| Step: 9
Training loss: 1.198445670486709
Validation loss: 2.53067634895343

Epoch: 6| Step: 10
Training loss: 1.1024034685359918
Validation loss: 2.4846566478458

Epoch: 6| Step: 11
Training loss: 1.8356486641147882
Validation loss: 2.526361886928106

Epoch: 6| Step: 12
Training loss: 1.1914211584940686
Validation loss: 2.487960147949405

Epoch: 6| Step: 13
Training loss: 1.6610728168361648
Validation loss: 2.478107135158315

Epoch: 361| Step: 0
Training loss: 1.3117371113112888
Validation loss: 2.4852995841456025

Epoch: 6| Step: 1
Training loss: 1.4205844597794752
Validation loss: 2.5220677267092

Epoch: 6| Step: 2
Training loss: 1.7777901895738826
Validation loss: 2.5487367031417216

Epoch: 6| Step: 3
Training loss: 1.5487937971546555
Validation loss: 2.5047189362715336

Epoch: 6| Step: 4
Training loss: 1.1509329743080121
Validation loss: 2.526430683397285

Epoch: 6| Step: 5
Training loss: 1.4920729348506454
Validation loss: 2.5511605806830326

Epoch: 6| Step: 6
Training loss: 1.0789491019277884
Validation loss: 2.5131166640804903

Epoch: 6| Step: 7
Training loss: 1.882226116627269
Validation loss: 2.5629425597078006

Epoch: 6| Step: 8
Training loss: 1.2691988465822968
Validation loss: 2.5264734482509006

Epoch: 6| Step: 9
Training loss: 1.3700820363675137
Validation loss: 2.548628049673486

Epoch: 6| Step: 10
Training loss: 1.3146303689384022
Validation loss: 2.5381041610903097

Epoch: 6| Step: 11
Training loss: 0.8718952887577458
Validation loss: 2.49000749738808

Epoch: 6| Step: 12
Training loss: 1.3608857452677552
Validation loss: 2.524985516698613

Epoch: 6| Step: 13
Training loss: 1.1988419428501689
Validation loss: 2.514340335279224

Epoch: 362| Step: 0
Training loss: 1.0731760964423405
Validation loss: 2.4997666170539694

Epoch: 6| Step: 1
Training loss: 1.2333761592251402
Validation loss: 2.530576828347142

Epoch: 6| Step: 2
Training loss: 1.1812571005633048
Validation loss: 2.502424431471899

Epoch: 6| Step: 3
Training loss: 1.4836015794496211
Validation loss: 2.5101661451603565

Epoch: 6| Step: 4
Training loss: 0.9392742851210538
Validation loss: 2.591565196288386

Epoch: 6| Step: 5
Training loss: 1.4568041095154065
Validation loss: 2.5798414585282865

Epoch: 6| Step: 6
Training loss: 0.9982440552146365
Validation loss: 2.5361378967994095

Epoch: 6| Step: 7
Training loss: 1.84777470344068
Validation loss: 2.538066429972247

Epoch: 6| Step: 8
Training loss: 0.934320462271472
Validation loss: 2.5454918317571957

Epoch: 6| Step: 9
Training loss: 2.0048241845954764
Validation loss: 2.566291934273241

Epoch: 6| Step: 10
Training loss: 1.2394801933057131
Validation loss: 2.558842335823817

Epoch: 6| Step: 11
Training loss: 1.2962639989437261
Validation loss: 2.585634119652284

Epoch: 6| Step: 12
Training loss: 1.8392330379059119
Validation loss: 2.6336751594284213

Epoch: 6| Step: 13
Training loss: 1.1086118517870303
Validation loss: 2.596560284778169

Epoch: 363| Step: 0
Training loss: 1.3618638942312948
Validation loss: 2.5594035412909086

Epoch: 6| Step: 1
Training loss: 1.1313199437895827
Validation loss: 2.542019480830954

Epoch: 6| Step: 2
Training loss: 1.3600633128239017
Validation loss: 2.5443497915259976

Epoch: 6| Step: 3
Training loss: 1.3265691732321891
Validation loss: 2.565537846239193

Epoch: 6| Step: 4
Training loss: 1.6629500991619852
Validation loss: 2.54293138795938

Epoch: 6| Step: 5
Training loss: 1.3819428203750004
Validation loss: 2.6132242893156192

Epoch: 6| Step: 6
Training loss: 1.8492431278015975
Validation loss: 2.537170605193488

Epoch: 6| Step: 7
Training loss: 1.1167729815835534
Validation loss: 2.58101042527807

Epoch: 6| Step: 8
Training loss: 1.6400863489818758
Validation loss: 2.466253184983365

Epoch: 6| Step: 9
Training loss: 1.3753326187101114
Validation loss: 2.494976973901985

Epoch: 6| Step: 10
Training loss: 0.8940064669146888
Validation loss: 2.565858531859969

Epoch: 6| Step: 11
Training loss: 1.6300017334630443
Validation loss: 2.50072940676149

Epoch: 6| Step: 12
Training loss: 1.138906987881222
Validation loss: 2.559427404119485

Epoch: 6| Step: 13
Training loss: 1.077218932735393
Validation loss: 2.488054745284442

Epoch: 364| Step: 0
Training loss: 1.0249521244312334
Validation loss: 2.5287371041784166

Epoch: 6| Step: 1
Training loss: 1.504225025823666
Validation loss: 2.4971567675289434

Epoch: 6| Step: 2
Training loss: 2.1047548913397036
Validation loss: 2.5156922578212155

Epoch: 6| Step: 3
Training loss: 0.8996146410226015
Validation loss: 2.5117135846295993

Epoch: 6| Step: 4
Training loss: 1.1140987138894656
Validation loss: 2.526809580903788

Epoch: 6| Step: 5
Training loss: 1.0225357276065579
Validation loss: 2.4475172379808523

Epoch: 6| Step: 6
Training loss: 1.3864209782215662
Validation loss: 2.5112517512536736

Epoch: 6| Step: 7
Training loss: 1.2758644240411814
Validation loss: 2.4399746860822193

Epoch: 6| Step: 8
Training loss: 1.1715527409279087
Validation loss: 2.4883514346490423

Epoch: 6| Step: 9
Training loss: 1.1885617177856074
Validation loss: 2.517891851725098

Epoch: 6| Step: 10
Training loss: 1.5659051792917849
Validation loss: 2.4590056249030106

Epoch: 6| Step: 11
Training loss: 1.0635304222795297
Validation loss: 2.48132924450608

Epoch: 6| Step: 12
Training loss: 1.3328775530878947
Validation loss: 2.5272953710784902

Epoch: 6| Step: 13
Training loss: 1.279416330598908
Validation loss: 2.533922433015222

Epoch: 365| Step: 0
Training loss: 1.1053437071264731
Validation loss: 2.5488709194054713

Epoch: 6| Step: 1
Training loss: 0.9801879115853895
Validation loss: 2.5605799296767575

Epoch: 6| Step: 2
Training loss: 1.582289234366273
Validation loss: 2.5270087262299716

Epoch: 6| Step: 3
Training loss: 1.2948890555294943
Validation loss: 2.52714911236631

Epoch: 6| Step: 4
Training loss: 1.152914442568721
Validation loss: 2.5292927431443486

Epoch: 6| Step: 5
Training loss: 1.620526391445037
Validation loss: 2.5316275405329844

Epoch: 6| Step: 6
Training loss: 1.2964097532822934
Validation loss: 2.556358817286335

Epoch: 6| Step: 7
Training loss: 1.0662832783093106
Validation loss: 2.5155505214746756

Epoch: 6| Step: 8
Training loss: 1.2946123814871637
Validation loss: 2.5088864301766707

Epoch: 6| Step: 9
Training loss: 1.4023438350071789
Validation loss: 2.552217477399997

Epoch: 6| Step: 10
Training loss: 1.0609154947552226
Validation loss: 2.5732135112402394

Epoch: 6| Step: 11
Training loss: 1.4396989009563905
Validation loss: 2.54086209419048

Epoch: 6| Step: 12
Training loss: 1.6448953909498223
Validation loss: 2.575170430774574

Epoch: 6| Step: 13
Training loss: 1.241614395466533
Validation loss: 2.627399664722557

Epoch: 366| Step: 0
Training loss: 0.8313721387805607
Validation loss: 2.5740896220567318

Epoch: 6| Step: 1
Training loss: 1.3863630671436034
Validation loss: 2.5883238078390582

Epoch: 6| Step: 2
Training loss: 1.6384458329132359
Validation loss: 2.550521432322008

Epoch: 6| Step: 3
Training loss: 1.0691808579400743
Validation loss: 2.599437437574134

Epoch: 6| Step: 4
Training loss: 1.4923442338845443
Validation loss: 2.599606333176008

Epoch: 6| Step: 5
Training loss: 1.269372173026321
Validation loss: 2.6278094440547832

Epoch: 6| Step: 6
Training loss: 0.8981821775453233
Validation loss: 2.6589772902378863

Epoch: 6| Step: 7
Training loss: 1.321131796263626
Validation loss: 2.5967753587466795

Epoch: 6| Step: 8
Training loss: 1.4191207199737754
Validation loss: 2.605587279346473

Epoch: 6| Step: 9
Training loss: 1.6486094597530834
Validation loss: 2.5738549368538624

Epoch: 6| Step: 10
Training loss: 1.6112331293020414
Validation loss: 2.601386597942324

Epoch: 6| Step: 11
Training loss: 1.7036292353347975
Validation loss: 2.532152227038131

Epoch: 6| Step: 12
Training loss: 1.4465916102725782
Validation loss: 2.5702245633466103

Epoch: 6| Step: 13
Training loss: 1.5336335762437685
Validation loss: 2.546355914243204

Epoch: 367| Step: 0
Training loss: 1.166528023701607
Validation loss: 2.537307821553813

Epoch: 6| Step: 1
Training loss: 1.0752296823383802
Validation loss: 2.569404248332734

Epoch: 6| Step: 2
Training loss: 1.5016729244789084
Validation loss: 2.569502048591331

Epoch: 6| Step: 3
Training loss: 1.1674198659805404
Validation loss: 2.572242051202168

Epoch: 6| Step: 4
Training loss: 1.6449239447731725
Validation loss: 2.55687471449291

Epoch: 6| Step: 5
Training loss: 1.4273666972971089
Validation loss: 2.5936020958336017

Epoch: 6| Step: 6
Training loss: 1.1607272095013148
Validation loss: 2.5428817116901112

Epoch: 6| Step: 7
Training loss: 1.233140835474252
Validation loss: 2.5307799950803993

Epoch: 6| Step: 8
Training loss: 1.0243620445637838
Validation loss: 2.4690332773308583

Epoch: 6| Step: 9
Training loss: 1.4790214771777328
Validation loss: 2.4802935681095772

Epoch: 6| Step: 10
Training loss: 1.423764744147233
Validation loss: 2.487083845615148

Epoch: 6| Step: 11
Training loss: 0.9042626986214424
Validation loss: 2.511546420231423

Epoch: 6| Step: 12
Training loss: 1.3661345432564926
Validation loss: 2.5084676391874354

Epoch: 6| Step: 13
Training loss: 1.2449804612430482
Validation loss: 2.5326128614858474

Epoch: 368| Step: 0
Training loss: 1.3002280585446095
Validation loss: 2.5689034817547696

Epoch: 6| Step: 1
Training loss: 1.181000540898754
Validation loss: 2.5658392277379694

Epoch: 6| Step: 2
Training loss: 1.0022639039869532
Validation loss: 2.587921841031267

Epoch: 6| Step: 3
Training loss: 1.3224488079352543
Validation loss: 2.5218568463245257

Epoch: 6| Step: 4
Training loss: 0.916979707383125
Validation loss: 2.5607565864990485

Epoch: 6| Step: 5
Training loss: 1.3128531752843218
Validation loss: 2.5690965182065155

Epoch: 6| Step: 6
Training loss: 1.1435040235494491
Validation loss: 2.572064290703596

Epoch: 6| Step: 7
Training loss: 1.6330837042777728
Validation loss: 2.5914784944753224

Epoch: 6| Step: 8
Training loss: 2.062867103042378
Validation loss: 2.5596802479386596

Epoch: 6| Step: 9
Training loss: 1.352503674867048
Validation loss: 2.5789628488084233

Epoch: 6| Step: 10
Training loss: 1.6411056541077225
Validation loss: 2.5311841288971246

Epoch: 6| Step: 11
Training loss: 1.063218827275675
Validation loss: 2.5554224292891887

Epoch: 6| Step: 12
Training loss: 1.5896361119352223
Validation loss: 2.5813942651097346

Epoch: 6| Step: 13
Training loss: 1.1107348851513412
Validation loss: 2.536646110795589

Epoch: 369| Step: 0
Training loss: 1.2243948083806753
Validation loss: 2.5368392209260673

Epoch: 6| Step: 1
Training loss: 1.1439137534395798
Validation loss: 2.5629852114670126

Epoch: 6| Step: 2
Training loss: 1.1426765073495684
Validation loss: 2.5574852791788563

Epoch: 6| Step: 3
Training loss: 0.9677354976480935
Validation loss: 2.595513935145521

Epoch: 6| Step: 4
Training loss: 1.2602592033620756
Validation loss: 2.5739002175423393

Epoch: 6| Step: 5
Training loss: 0.9895799268697366
Validation loss: 2.5416961157504976

Epoch: 6| Step: 6
Training loss: 1.2625983511508065
Validation loss: 2.5971204927028992

Epoch: 6| Step: 7
Training loss: 1.432730349782536
Validation loss: 2.563459526853117

Epoch: 6| Step: 8
Training loss: 1.212766386048404
Validation loss: 2.5214137100179026

Epoch: 6| Step: 9
Training loss: 1.4843487385886223
Validation loss: 2.529899331001137

Epoch: 6| Step: 10
Training loss: 1.7930862288539933
Validation loss: 2.55787227640773

Epoch: 6| Step: 11
Training loss: 1.5761767910829854
Validation loss: 2.486461123425107

Epoch: 6| Step: 12
Training loss: 1.7023200136291914
Validation loss: 2.5660062233325855

Epoch: 6| Step: 13
Training loss: 1.1466084661702522
Validation loss: 2.5272375887350527

Epoch: 370| Step: 0
Training loss: 0.9824285488015738
Validation loss: 2.562607863722438

Epoch: 6| Step: 1
Training loss: 1.0188292209270378
Validation loss: 2.5320061861025915

Epoch: 6| Step: 2
Training loss: 1.4409710813872738
Validation loss: 2.5691315818450757

Epoch: 6| Step: 3
Training loss: 1.1918280183267025
Validation loss: 2.55736383671646

Epoch: 6| Step: 4
Training loss: 1.9851017619840372
Validation loss: 2.6208598927505036

Epoch: 6| Step: 5
Training loss: 1.038022546277098
Validation loss: 2.635554635478576

Epoch: 6| Step: 6
Training loss: 1.2500376695678994
Validation loss: 2.557913839841247

Epoch: 6| Step: 7
Training loss: 1.1257904242963057
Validation loss: 2.558460385484367

Epoch: 6| Step: 8
Training loss: 1.606175770510166
Validation loss: 2.5762553361778515

Epoch: 6| Step: 9
Training loss: 1.533413118207849
Validation loss: 2.578303298179337

Epoch: 6| Step: 10
Training loss: 1.2101503336338844
Validation loss: 2.579654047514391

Epoch: 6| Step: 11
Training loss: 1.265973266909897
Validation loss: 2.580024805319366

Epoch: 6| Step: 12
Training loss: 0.9451863858928293
Validation loss: 2.5856070100820676

Epoch: 6| Step: 13
Training loss: 1.1437760813923477
Validation loss: 2.5400837883683605

Epoch: 371| Step: 0
Training loss: 1.2131633851131458
Validation loss: 2.569634151901597

Epoch: 6| Step: 1
Training loss: 1.299595885555063
Validation loss: 2.5532758897747247

Epoch: 6| Step: 2
Training loss: 1.0454115816380112
Validation loss: 2.5523505142382277

Epoch: 6| Step: 3
Training loss: 1.2893646810824135
Validation loss: 2.568931773020095

Epoch: 6| Step: 4
Training loss: 1.3877269679518631
Validation loss: 2.52881715759214

Epoch: 6| Step: 5
Training loss: 1.7496114026905532
Validation loss: 2.5033730639959124

Epoch: 6| Step: 6
Training loss: 1.4175035959026603
Validation loss: 2.55389732716362

Epoch: 6| Step: 7
Training loss: 0.9617346581786498
Validation loss: 2.5838229628031257

Epoch: 6| Step: 8
Training loss: 1.0181415777103757
Validation loss: 2.538227918351675

Epoch: 6| Step: 9
Training loss: 1.800757683126023
Validation loss: 2.673509034909597

Epoch: 6| Step: 10
Training loss: 1.2725235169041942
Validation loss: 2.6150750132317624

Epoch: 6| Step: 11
Training loss: 1.0697057075968013
Validation loss: 2.569617381304597

Epoch: 6| Step: 12
Training loss: 1.5009053200348323
Validation loss: 2.519368784001022

Epoch: 6| Step: 13
Training loss: 1.151024376694753
Validation loss: 2.47972714208762

Epoch: 372| Step: 0
Training loss: 0.9414751652862323
Validation loss: 2.56627725541199

Epoch: 6| Step: 1
Training loss: 1.4172527092143845
Validation loss: 2.5506264297367927

Epoch: 6| Step: 2
Training loss: 1.2140017225451245
Validation loss: 2.544012891539313

Epoch: 6| Step: 3
Training loss: 1.2245802685748042
Validation loss: 2.5853436912875396

Epoch: 6| Step: 4
Training loss: 1.9005538384193994
Validation loss: 2.5611240212751114

Epoch: 6| Step: 5
Training loss: 1.9142604180598404
Validation loss: 2.591276743791177

Epoch: 6| Step: 6
Training loss: 0.9605120205382703
Validation loss: 2.5820154910008246

Epoch: 6| Step: 7
Training loss: 0.9952137968506846
Validation loss: 2.60178517103696

Epoch: 6| Step: 8
Training loss: 1.1043309803227686
Validation loss: 2.571975541032621

Epoch: 6| Step: 9
Training loss: 1.2958888705374063
Validation loss: 2.5934727302251646

Epoch: 6| Step: 10
Training loss: 1.412362230384468
Validation loss: 2.6131408075856473

Epoch: 6| Step: 11
Training loss: 1.2364456578895575
Validation loss: 2.5839805843280295

Epoch: 6| Step: 12
Training loss: 1.5155492547368183
Validation loss: 2.6025522390369615

Epoch: 6| Step: 13
Training loss: 1.1603455051995364
Validation loss: 2.581990821202533

Epoch: 373| Step: 0
Training loss: 0.8560455676878289
Validation loss: 2.58906909525094

Epoch: 6| Step: 1
Training loss: 1.3114864886682636
Validation loss: 2.533246936286889

Epoch: 6| Step: 2
Training loss: 1.0073950442601403
Validation loss: 2.531963844269171

Epoch: 6| Step: 3
Training loss: 1.2410828098822042
Validation loss: 2.5319779687548727

Epoch: 6| Step: 4
Training loss: 1.0085513341658747
Validation loss: 2.507517574473109

Epoch: 6| Step: 5
Training loss: 1.2843564220115096
Validation loss: 2.549564104285628

Epoch: 6| Step: 6
Training loss: 1.3659762875633767
Validation loss: 2.4725198733228906

Epoch: 6| Step: 7
Training loss: 1.1549804522358798
Validation loss: 2.5507996321400883

Epoch: 6| Step: 8
Training loss: 1.2053514167609267
Validation loss: 2.52709252171577

Epoch: 6| Step: 9
Training loss: 1.0598442883653945
Validation loss: 2.532077646149193

Epoch: 6| Step: 10
Training loss: 1.4575257472124572
Validation loss: 2.5370012573040595

Epoch: 6| Step: 11
Training loss: 0.9224759099239143
Validation loss: 2.555636557272022

Epoch: 6| Step: 12
Training loss: 1.9231896594821611
Validation loss: 2.503210755719511

Epoch: 6| Step: 13
Training loss: 1.2870254141899977
Validation loss: 2.5203519445597484

Epoch: 374| Step: 0
Training loss: 1.7353527303078864
Validation loss: 2.5402108437092874

Epoch: 6| Step: 1
Training loss: 0.923178898316802
Validation loss: 2.5487375294453716

Epoch: 6| Step: 2
Training loss: 0.9706710718032242
Validation loss: 2.567108058338773

Epoch: 6| Step: 3
Training loss: 1.3665504933424495
Validation loss: 2.50939184985238

Epoch: 6| Step: 4
Training loss: 1.0087892988413325
Validation loss: 2.5261274238003604

Epoch: 6| Step: 5
Training loss: 1.0716262328517794
Validation loss: 2.5588492617775893

Epoch: 6| Step: 6
Training loss: 1.5006878388390046
Validation loss: 2.5397731001825674

Epoch: 6| Step: 7
Training loss: 1.719432487233947
Validation loss: 2.5366921574928005

Epoch: 6| Step: 8
Training loss: 0.9518536703183353
Validation loss: 2.585330550004242

Epoch: 6| Step: 9
Training loss: 1.1459605695422053
Validation loss: 2.546441538614723

Epoch: 6| Step: 10
Training loss: 0.9093477644889253
Validation loss: 2.561812952249884

Epoch: 6| Step: 11
Training loss: 1.4682679704254584
Validation loss: 2.5250815752908604

Epoch: 6| Step: 12
Training loss: 1.123230390067208
Validation loss: 2.5164253588644434

Epoch: 6| Step: 13
Training loss: 1.5842032886882753
Validation loss: 2.514474467460099

Epoch: 375| Step: 0
Training loss: 1.1109602978133675
Validation loss: 2.602104443682598

Epoch: 6| Step: 1
Training loss: 1.1894732193275204
Validation loss: 2.5465765936219604

Epoch: 6| Step: 2
Training loss: 1.5731385266128264
Validation loss: 2.595691926777501

Epoch: 6| Step: 3
Training loss: 0.9010794894414778
Validation loss: 2.5877411728415627

Epoch: 6| Step: 4
Training loss: 1.1091221265975961
Validation loss: 2.572586491412551

Epoch: 6| Step: 5
Training loss: 1.5010772651441422
Validation loss: 2.6088599117309976

Epoch: 6| Step: 6
Training loss: 1.0876715557663843
Validation loss: 2.588294822748631

Epoch: 6| Step: 7
Training loss: 1.0719484509806212
Validation loss: 2.540353433156664

Epoch: 6| Step: 8
Training loss: 1.6237250975592659
Validation loss: 2.598746760642935

Epoch: 6| Step: 9
Training loss: 1.5062682787787272
Validation loss: 2.6035504845557913

Epoch: 6| Step: 10
Training loss: 1.1764321284108417
Validation loss: 2.5878880146901144

Epoch: 6| Step: 11
Training loss: 0.7318964179575619
Validation loss: 2.607983071348815

Epoch: 6| Step: 12
Training loss: 0.9761674005437169
Validation loss: 2.592770157768249

Epoch: 6| Step: 13
Training loss: 0.815144051417952
Validation loss: 2.5221370026769394

Epoch: 376| Step: 0
Training loss: 1.0223393846197384
Validation loss: 2.557727960375199

Epoch: 6| Step: 1
Training loss: 1.8519271298402324
Validation loss: 2.4916899851172483

Epoch: 6| Step: 2
Training loss: 0.9632804035266582
Validation loss: 2.5604741842474077

Epoch: 6| Step: 3
Training loss: 1.097843249265247
Validation loss: 2.521994013540477

Epoch: 6| Step: 4
Training loss: 1.1201623111006946
Validation loss: 2.5574671004669254

Epoch: 6| Step: 5
Training loss: 0.6392734505861546
Validation loss: 2.4929812451843154

Epoch: 6| Step: 6
Training loss: 1.2675994730181817
Validation loss: 2.5880817616251757

Epoch: 6| Step: 7
Training loss: 0.7775087421085217
Validation loss: 2.543356924905848

Epoch: 6| Step: 8
Training loss: 1.3229019684863643
Validation loss: 2.5809990786314674

Epoch: 6| Step: 9
Training loss: 1.101901117319312
Validation loss: 2.545863397257385

Epoch: 6| Step: 10
Training loss: 1.0207730619323154
Validation loss: 2.472556539556993

Epoch: 6| Step: 11
Training loss: 1.5333789894659746
Validation loss: 2.579715091982131

Epoch: 6| Step: 12
Training loss: 1.0662221225613744
Validation loss: 2.5372331337995417

Epoch: 6| Step: 13
Training loss: 1.4612153141026447
Validation loss: 2.504987787596374

Epoch: 377| Step: 0
Training loss: 0.9554840036766934
Validation loss: 2.511109099649882

Epoch: 6| Step: 1
Training loss: 1.138641618748698
Validation loss: 2.5303370552305307

Epoch: 6| Step: 2
Training loss: 1.9386544018706837
Validation loss: 2.5224492250870365

Epoch: 6| Step: 3
Training loss: 1.2651024198722898
Validation loss: 2.550000790365259

Epoch: 6| Step: 4
Training loss: 1.3806412455758703
Validation loss: 2.5111507012707532

Epoch: 6| Step: 5
Training loss: 1.2612662906558727
Validation loss: 2.58861021773652

Epoch: 6| Step: 6
Training loss: 1.0213625891826312
Validation loss: 2.5942970066758058

Epoch: 6| Step: 7
Training loss: 0.9413844695678047
Validation loss: 2.5923471755350276

Epoch: 6| Step: 8
Training loss: 1.3093013842880796
Validation loss: 2.6065239625862673

Epoch: 6| Step: 9
Training loss: 1.169832968159664
Validation loss: 2.61714773574911

Epoch: 6| Step: 10
Training loss: 1.2321336412183876
Validation loss: 2.574296887398065

Epoch: 6| Step: 11
Training loss: 0.6788486917237977
Validation loss: 2.541389166165445

Epoch: 6| Step: 12
Training loss: 1.0522426383897734
Validation loss: 2.58428452781985

Epoch: 6| Step: 13
Training loss: 0.9464711741346722
Validation loss: 2.554266464270939

Epoch: 378| Step: 0
Training loss: 1.1328784265736802
Validation loss: 2.585182978796521

Epoch: 6| Step: 1
Training loss: 1.661926331173865
Validation loss: 2.6286350845370103

Epoch: 6| Step: 2
Training loss: 1.4912990301726206
Validation loss: 2.5690961469964892

Epoch: 6| Step: 3
Training loss: 0.8869564729222644
Validation loss: 2.517335211668115

Epoch: 6| Step: 4
Training loss: 0.9127990271890757
Validation loss: 2.5974117766332676

Epoch: 6| Step: 5
Training loss: 1.095399920012823
Validation loss: 2.6307265397529926

Epoch: 6| Step: 6
Training loss: 1.2244613533666004
Validation loss: 2.5848565891803807

Epoch: 6| Step: 7
Training loss: 1.1612317786619577
Validation loss: 2.642293444343668

Epoch: 6| Step: 8
Training loss: 1.3913805334337401
Validation loss: 2.614283211391957

Epoch: 6| Step: 9
Training loss: 1.2320150680301738
Validation loss: 2.5580135706853997

Epoch: 6| Step: 10
Training loss: 1.1172754213108913
Validation loss: 2.5740269776199907

Epoch: 6| Step: 11
Training loss: 1.8260016866928952
Validation loss: 2.5444324224744235

Epoch: 6| Step: 12
Training loss: 0.8009194603718018
Validation loss: 2.5387591528027103

Epoch: 6| Step: 13
Training loss: 0.8508234579302166
Validation loss: 2.523205552596879

Epoch: 379| Step: 0
Training loss: 1.3439544699597636
Validation loss: 2.5741073437646502

Epoch: 6| Step: 1
Training loss: 0.9521354478781417
Validation loss: 2.5582999412602323

Epoch: 6| Step: 2
Training loss: 0.9099710300571183
Validation loss: 2.58009595958659

Epoch: 6| Step: 3
Training loss: 0.9593656135621782
Validation loss: 2.5803218151810032

Epoch: 6| Step: 4
Training loss: 1.0858890330524462
Validation loss: 2.5607182192995483

Epoch: 6| Step: 5
Training loss: 1.5458706764721508
Validation loss: 2.644554434843246

Epoch: 6| Step: 6
Training loss: 0.9380105535751272
Validation loss: 2.553939834363015

Epoch: 6| Step: 7
Training loss: 1.5180221163429
Validation loss: 2.6290192487671487

Epoch: 6| Step: 8
Training loss: 1.258431892240433
Validation loss: 2.577152615980216

Epoch: 6| Step: 9
Training loss: 1.0895959716025008
Validation loss: 2.5794401725322684

Epoch: 6| Step: 10
Training loss: 1.4384682752858702
Validation loss: 2.5509844276005755

Epoch: 6| Step: 11
Training loss: 1.6939376670781865
Validation loss: 2.6265578415719864

Epoch: 6| Step: 12
Training loss: 0.858429683598336
Validation loss: 2.6271765934128757

Epoch: 6| Step: 13
Training loss: 1.0932743673201983
Validation loss: 2.5749400492976156

Epoch: 380| Step: 0
Training loss: 1.503582332456342
Validation loss: 2.5733188567059075

Epoch: 6| Step: 1
Training loss: 1.2296867671125813
Validation loss: 2.6025129535217095

Epoch: 6| Step: 2
Training loss: 1.1957834849230173
Validation loss: 2.5289968344549316

Epoch: 6| Step: 3
Training loss: 0.9991771769878898
Validation loss: 2.6316979800876505

Epoch: 6| Step: 4
Training loss: 1.5600794544526642
Validation loss: 2.5614094080421013

Epoch: 6| Step: 5
Training loss: 1.104950584584016
Validation loss: 2.6211174453596646

Epoch: 6| Step: 6
Training loss: 0.997230210592517
Validation loss: 2.5679228088893056

Epoch: 6| Step: 7
Training loss: 0.9052666557905702
Validation loss: 2.573057353591643

Epoch: 6| Step: 8
Training loss: 1.0427741394212084
Validation loss: 2.6126727282843225

Epoch: 6| Step: 9
Training loss: 1.1895864127008473
Validation loss: 2.5742299412979497

Epoch: 6| Step: 10
Training loss: 1.4664841075911401
Validation loss: 2.5753223482849457

Epoch: 6| Step: 11
Training loss: 0.9729078649140436
Validation loss: 2.6162695798036433

Epoch: 6| Step: 12
Training loss: 1.2777910761670999
Validation loss: 2.609545315725389

Epoch: 6| Step: 13
Training loss: 0.7886607214189532
Validation loss: 2.5961993651823807

Epoch: 381| Step: 0
Training loss: 1.123780225065131
Validation loss: 2.590832766433348

Epoch: 6| Step: 1
Training loss: 1.1994393111694268
Validation loss: 2.61629991046645

Epoch: 6| Step: 2
Training loss: 0.9010507145833466
Validation loss: 2.594395515056293

Epoch: 6| Step: 3
Training loss: 0.9338994822417271
Validation loss: 2.548919948906723

Epoch: 6| Step: 4
Training loss: 1.4858323823188024
Validation loss: 2.582694495079084

Epoch: 6| Step: 5
Training loss: 1.3591348720989467
Validation loss: 2.602403208972275

Epoch: 6| Step: 6
Training loss: 1.29532843604138
Validation loss: 2.5971149846296484

Epoch: 6| Step: 7
Training loss: 1.0121077448818163
Validation loss: 2.58919069275535

Epoch: 6| Step: 8
Training loss: 0.6812195228618825
Validation loss: 2.5561284814380865

Epoch: 6| Step: 9
Training loss: 1.3257313419405223
Validation loss: 2.52352267378448

Epoch: 6| Step: 10
Training loss: 0.9566521029798197
Validation loss: 2.5700423263893892

Epoch: 6| Step: 11
Training loss: 1.7135151297728093
Validation loss: 2.61030301706461

Epoch: 6| Step: 12
Training loss: 1.4173697054823216
Validation loss: 2.560181693295129

Epoch: 6| Step: 13
Training loss: 1.1942987069715847
Validation loss: 2.555946413214212

Epoch: 382| Step: 0
Training loss: 1.1009050395770186
Validation loss: 2.525968654141078

Epoch: 6| Step: 1
Training loss: 1.3463981616310812
Validation loss: 2.5256918491250784

Epoch: 6| Step: 2
Training loss: 0.9984761488811292
Validation loss: 2.4741258798716945

Epoch: 6| Step: 3
Training loss: 0.9786475543781364
Validation loss: 2.504364923847702

Epoch: 6| Step: 4
Training loss: 0.8247443959166296
Validation loss: 2.5153719219908095

Epoch: 6| Step: 5
Training loss: 1.1843752657203075
Validation loss: 2.546030431090608

Epoch: 6| Step: 6
Training loss: 1.0443625976629662
Validation loss: 2.551888911308759

Epoch: 6| Step: 7
Training loss: 1.1377507928901245
Validation loss: 2.6359569814912187

Epoch: 6| Step: 8
Training loss: 1.0920134791845306
Validation loss: 2.6124479583716096

Epoch: 6| Step: 9
Training loss: 0.8597568357261903
Validation loss: 2.539462264452882

Epoch: 6| Step: 10
Training loss: 1.4577917819171051
Validation loss: 2.567509894347325

Epoch: 6| Step: 11
Training loss: 1.7896659532984784
Validation loss: 2.5687292105892343

Epoch: 6| Step: 12
Training loss: 0.996362029205955
Validation loss: 2.5233776766493454

Epoch: 6| Step: 13
Training loss: 0.8479572939375656
Validation loss: 2.5602243755279903

Epoch: 383| Step: 0
Training loss: 1.4911867950423716
Validation loss: 2.525198543409909

Epoch: 6| Step: 1
Training loss: 0.8883185050888599
Validation loss: 2.5239732643994626

Epoch: 6| Step: 2
Training loss: 1.2897476687305822
Validation loss: 2.498826752972819

Epoch: 6| Step: 3
Training loss: 1.652707035178473
Validation loss: 2.6131717371933285

Epoch: 6| Step: 4
Training loss: 1.0540904297734681
Validation loss: 2.567730721046597

Epoch: 6| Step: 5
Training loss: 0.9916852746280871
Validation loss: 2.5521243864118093

Epoch: 6| Step: 6
Training loss: 1.4392363800469876
Validation loss: 2.577347755795184

Epoch: 6| Step: 7
Training loss: 0.9248553446477776
Validation loss: 2.567167094809912

Epoch: 6| Step: 8
Training loss: 0.9765370174897942
Validation loss: 2.5513305462076983

Epoch: 6| Step: 9
Training loss: 0.7478461730874418
Validation loss: 2.5684163405140934

Epoch: 6| Step: 10
Training loss: 1.1226450325572042
Validation loss: 2.5395028069997565

Epoch: 6| Step: 11
Training loss: 1.1150665424146
Validation loss: 2.566901048469748

Epoch: 6| Step: 12
Training loss: 0.9004374262299424
Validation loss: 2.5289408979457253

Epoch: 6| Step: 13
Training loss: 1.6518444271772932
Validation loss: 2.5474937717035915

Epoch: 384| Step: 0
Training loss: 1.4123301142251556
Validation loss: 2.592322450773001

Epoch: 6| Step: 1
Training loss: 1.3708613706850206
Validation loss: 2.6233435202921447

Epoch: 6| Step: 2
Training loss: 0.9468254403719423
Validation loss: 2.5846211135942534

Epoch: 6| Step: 3
Training loss: 1.2890059950032888
Validation loss: 2.5825272168906834

Epoch: 6| Step: 4
Training loss: 1.033456464835105
Validation loss: 2.5812774958466145

Epoch: 6| Step: 5
Training loss: 0.9535534005376951
Validation loss: 2.568528674290808

Epoch: 6| Step: 6
Training loss: 1.0998107834113382
Validation loss: 2.615686872715947

Epoch: 6| Step: 7
Training loss: 1.1564491719028658
Validation loss: 2.513799617182176

Epoch: 6| Step: 8
Training loss: 0.8245744705944711
Validation loss: 2.5640722506669182

Epoch: 6| Step: 9
Training loss: 1.2276110206944597
Validation loss: 2.498825146866793

Epoch: 6| Step: 10
Training loss: 1.3156850859995128
Validation loss: 2.5175086762304977

Epoch: 6| Step: 11
Training loss: 1.0538810189678947
Validation loss: 2.5404159225263396

Epoch: 6| Step: 12
Training loss: 1.3673941319856249
Validation loss: 2.545088002620092

Epoch: 6| Step: 13
Training loss: 1.1915740348363655
Validation loss: 2.5675967787418976

Epoch: 385| Step: 0
Training loss: 1.1464202187050938
Validation loss: 2.5029291874069806

Epoch: 6| Step: 1
Training loss: 1.136870383934309
Validation loss: 2.5616082911726332

Epoch: 6| Step: 2
Training loss: 1.2041304709374474
Validation loss: 2.5366882334914798

Epoch: 6| Step: 3
Training loss: 1.2839876096549516
Validation loss: 2.579570881152107

Epoch: 6| Step: 4
Training loss: 1.7726526750416725
Validation loss: 2.5779784112736124

Epoch: 6| Step: 5
Training loss: 0.9761446860115381
Validation loss: 2.568663658615392

Epoch: 6| Step: 6
Training loss: 1.176082483782223
Validation loss: 2.6101022875559923

Epoch: 6| Step: 7
Training loss: 1.5023473016515398
Validation loss: 2.573953671813309

Epoch: 6| Step: 8
Training loss: 1.280889972252674
Validation loss: 2.635378544548044

Epoch: 6| Step: 9
Training loss: 1.3152121723001593
Validation loss: 2.649563710267569

Epoch: 6| Step: 10
Training loss: 1.5458643530572074
Validation loss: 2.609755848028503

Epoch: 6| Step: 11
Training loss: 0.7664257455381879
Validation loss: 2.587059207971088

Epoch: 6| Step: 12
Training loss: 1.095512169502668
Validation loss: 2.5431137238961345

Epoch: 6| Step: 13
Training loss: 0.9984723582025716
Validation loss: 2.5900085304738374

Epoch: 386| Step: 0
Training loss: 0.9281696141883965
Validation loss: 2.5810556574114947

Epoch: 6| Step: 1
Training loss: 1.2881481280001963
Validation loss: 2.5482048977890153

Epoch: 6| Step: 2
Training loss: 1.371389503859194
Validation loss: 2.5702636621351624

Epoch: 6| Step: 3
Training loss: 1.5088508469853759
Validation loss: 2.5760583474163816

Epoch: 6| Step: 4
Training loss: 0.5598539528967051
Validation loss: 2.5605653887752777

Epoch: 6| Step: 5
Training loss: 1.0865281509003688
Validation loss: 2.560917094042484

Epoch: 6| Step: 6
Training loss: 1.0363944080262288
Validation loss: 2.5568703163817097

Epoch: 6| Step: 7
Training loss: 0.9570948676938136
Validation loss: 2.5704290485336356

Epoch: 6| Step: 8
Training loss: 0.9703061925219271
Validation loss: 2.5200371128457686

Epoch: 6| Step: 9
Training loss: 1.030650802853758
Validation loss: 2.5785985646583063

Epoch: 6| Step: 10
Training loss: 0.927797528175339
Validation loss: 2.605889846348359

Epoch: 6| Step: 11
Training loss: 1.5837776999395867
Validation loss: 2.6082495815086997

Epoch: 6| Step: 12
Training loss: 0.8205397518182558
Validation loss: 2.5581847817681758

Epoch: 6| Step: 13
Training loss: 1.610196542767855
Validation loss: 2.551608953697433

Epoch: 387| Step: 0
Training loss: 0.9731975106509694
Validation loss: 2.521157840197437

Epoch: 6| Step: 1
Training loss: 1.5908582295300933
Validation loss: 2.5295768199927493

Epoch: 6| Step: 2
Training loss: 0.7485466226494562
Validation loss: 2.516519217771663

Epoch: 6| Step: 3
Training loss: 1.2410153790918863
Validation loss: 2.5607185218944726

Epoch: 6| Step: 4
Training loss: 1.3674161011450225
Validation loss: 2.5471581299720762

Epoch: 6| Step: 5
Training loss: 1.7991855527173093
Validation loss: 2.5808314749990524

Epoch: 6| Step: 6
Training loss: 1.1046081536055126
Validation loss: 2.5526774409083273

Epoch: 6| Step: 7
Training loss: 0.9980037851605849
Validation loss: 2.5508287628873973

Epoch: 6| Step: 8
Training loss: 0.8486657525837009
Validation loss: 2.531004026416041

Epoch: 6| Step: 9
Training loss: 1.0224535922685662
Validation loss: 2.5728978659577417

Epoch: 6| Step: 10
Training loss: 1.0002958932848918
Validation loss: 2.5707897759637026

Epoch: 6| Step: 11
Training loss: 1.1783757274362818
Validation loss: 2.5483604343096777

Epoch: 6| Step: 12
Training loss: 0.8399746460153658
Validation loss: 2.5682799120311963

Epoch: 6| Step: 13
Training loss: 0.9521113774838936
Validation loss: 2.575570414920577

Epoch: 388| Step: 0
Training loss: 1.0727799090783456
Validation loss: 2.5800878893744232

Epoch: 6| Step: 1
Training loss: 0.6714175907319773
Validation loss: 2.6203311544174

Epoch: 6| Step: 2
Training loss: 1.2179092050106939
Validation loss: 2.6137504213497893

Epoch: 6| Step: 3
Training loss: 0.9620060755682559
Validation loss: 2.590276836318958

Epoch: 6| Step: 4
Training loss: 0.8716605356801925
Validation loss: 2.527079517794562

Epoch: 6| Step: 5
Training loss: 0.8436359752326029
Validation loss: 2.574950789935054

Epoch: 6| Step: 6
Training loss: 1.208705296759836
Validation loss: 2.5463906512134065

Epoch: 6| Step: 7
Training loss: 1.8098444723256106
Validation loss: 2.559486710901594

Epoch: 6| Step: 8
Training loss: 0.9013357766610197
Validation loss: 2.576221109864054

Epoch: 6| Step: 9
Training loss: 1.34798487098139
Validation loss: 2.559894322459233

Epoch: 6| Step: 10
Training loss: 0.8531560424075617
Validation loss: 2.6014977295290285

Epoch: 6| Step: 11
Training loss: 1.2428670499904753
Validation loss: 2.566991080387135

Epoch: 6| Step: 12
Training loss: 1.1898759863851671
Validation loss: 2.566289921354197

Epoch: 6| Step: 13
Training loss: 1.061517597873772
Validation loss: 2.594878728614014

Epoch: 389| Step: 0
Training loss: 0.9681140288783505
Validation loss: 2.6211288760579836

Epoch: 6| Step: 1
Training loss: 1.1382899486285305
Validation loss: 2.5374207808432514

Epoch: 6| Step: 2
Training loss: 1.0996214085084788
Validation loss: 2.5208605194727602

Epoch: 6| Step: 3
Training loss: 1.3235530924392698
Validation loss: 2.5851645029827197

Epoch: 6| Step: 4
Training loss: 1.5253787461525308
Validation loss: 2.5706886317759396

Epoch: 6| Step: 5
Training loss: 1.579049472268162
Validation loss: 2.572728267263671

Epoch: 6| Step: 6
Training loss: 0.9905203682790101
Validation loss: 2.6285634679394874

Epoch: 6| Step: 7
Training loss: 1.0335979320300233
Validation loss: 2.529013190936341

Epoch: 6| Step: 8
Training loss: 0.9229115623063155
Validation loss: 2.6352314990786616

Epoch: 6| Step: 9
Training loss: 1.0024476494759615
Validation loss: 2.6458528823330587

Epoch: 6| Step: 10
Training loss: 0.9315511792508229
Validation loss: 2.6824306316241135

Epoch: 6| Step: 11
Training loss: 0.7391653267619974
Validation loss: 2.7488367192315306

Epoch: 6| Step: 12
Training loss: 1.2323404759822676
Validation loss: 2.679557255878198

Epoch: 6| Step: 13
Training loss: 1.1113760188665152
Validation loss: 2.675657179431848

Epoch: 390| Step: 0
Training loss: 1.647836729378318
Validation loss: 2.6887844623915016

Epoch: 6| Step: 1
Training loss: 0.9551036495862331
Validation loss: 2.5979434588370527

Epoch: 6| Step: 2
Training loss: 0.6092084021128525
Validation loss: 2.599946796655393

Epoch: 6| Step: 3
Training loss: 0.6505343762330116
Validation loss: 2.5570824428103247

Epoch: 6| Step: 4
Training loss: 1.3547148353080298
Validation loss: 2.5877693119045264

Epoch: 6| Step: 5
Training loss: 1.1949183992433206
Validation loss: 2.6476612585160515

Epoch: 6| Step: 6
Training loss: 1.1112237489086298
Validation loss: 2.566558430812955

Epoch: 6| Step: 7
Training loss: 1.323298626924245
Validation loss: 2.524229352577144

Epoch: 6| Step: 8
Training loss: 1.0332017981479251
Validation loss: 2.5622410061838723

Epoch: 6| Step: 9
Training loss: 1.0266249430113104
Validation loss: 2.531039099678783

Epoch: 6| Step: 10
Training loss: 1.3094312123179592
Validation loss: 2.616017018196715

Epoch: 6| Step: 11
Training loss: 0.9520719996361356
Validation loss: 2.5947353988380226

Epoch: 6| Step: 12
Training loss: 1.4198322084179649
Validation loss: 2.706078204251594

Epoch: 6| Step: 13
Training loss: 1.9198926921500945
Validation loss: 2.755366861052943

Epoch: 391| Step: 0
Training loss: 0.6911118737400885
Validation loss: 2.6387083557905067

Epoch: 6| Step: 1
Training loss: 1.0402699388877288
Validation loss: 2.6448515074066217

Epoch: 6| Step: 2
Training loss: 1.9152046377140195
Validation loss: 2.5579810731489347

Epoch: 6| Step: 3
Training loss: 1.5250332031387577
Validation loss: 2.5637704599631377

Epoch: 6| Step: 4
Training loss: 1.0864988563907256
Validation loss: 2.644928654872498

Epoch: 6| Step: 5
Training loss: 1.2902592045944057
Validation loss: 2.6166270856435165

Epoch: 6| Step: 6
Training loss: 0.547944848045386
Validation loss: 2.585587369297513

Epoch: 6| Step: 7
Training loss: 0.8334992402547521
Validation loss: 2.61435045418497

Epoch: 6| Step: 8
Training loss: 0.8606380544211216
Validation loss: 2.5570225674405753

Epoch: 6| Step: 9
Training loss: 0.7337447363487569
Validation loss: 2.6013227014312954

Epoch: 6| Step: 10
Training loss: 0.8789236109396468
Validation loss: 2.5775416321079345

Epoch: 6| Step: 11
Training loss: 1.3327979960217013
Validation loss: 2.556653626216803

Epoch: 6| Step: 12
Training loss: 1.0214749220926735
Validation loss: 2.532817088614623

Epoch: 6| Step: 13
Training loss: 0.8407476130124684
Validation loss: 2.5282221058356917

Epoch: 392| Step: 0
Training loss: 0.8981963787769479
Validation loss: 2.6137232233272516

Epoch: 6| Step: 1
Training loss: 1.157025721380302
Validation loss: 2.6345479737221154

Epoch: 6| Step: 2
Training loss: 0.8944852725544298
Validation loss: 2.5497489737077146

Epoch: 6| Step: 3
Training loss: 1.5213605759366056
Validation loss: 2.640304666384812

Epoch: 6| Step: 4
Training loss: 1.2242837135201938
Validation loss: 2.6510914096524796

Epoch: 6| Step: 5
Training loss: 1.0696709930991788
Validation loss: 2.5854760302773516

Epoch: 6| Step: 6
Training loss: 0.9210676116729039
Validation loss: 2.5239753425540354

Epoch: 6| Step: 7
Training loss: 0.8974471231254532
Validation loss: 2.5305414032171054

Epoch: 6| Step: 8
Training loss: 1.5421944135918677
Validation loss: 2.5127720658635213

Epoch: 6| Step: 9
Training loss: 1.2776050358720206
Validation loss: 2.578011943765796

Epoch: 6| Step: 10
Training loss: 0.6651353136226166
Validation loss: 2.49655987561678

Epoch: 6| Step: 11
Training loss: 0.7974715524341172
Validation loss: 2.5689898549858747

Epoch: 6| Step: 12
Training loss: 1.2478102577623054
Validation loss: 2.6296957341120204

Epoch: 6| Step: 13
Training loss: 0.8324748186650425
Validation loss: 2.577870643475778

Epoch: 393| Step: 0
Training loss: 0.8480119090908452
Validation loss: 2.6175819365445143

Epoch: 6| Step: 1
Training loss: 1.7677318190043103
Validation loss: 2.607611404750449

Epoch: 6| Step: 2
Training loss: 0.6330758006193523
Validation loss: 2.578338421551698

Epoch: 6| Step: 3
Training loss: 0.9979414613599379
Validation loss: 2.5487138159832092

Epoch: 6| Step: 4
Training loss: 0.7734562650003267
Validation loss: 2.5665892870084304

Epoch: 6| Step: 5
Training loss: 1.0745281536839262
Validation loss: 2.587110408994136

Epoch: 6| Step: 6
Training loss: 0.8003425699146143
Validation loss: 2.6065486593518896

Epoch: 6| Step: 7
Training loss: 1.214898209409111
Validation loss: 2.582800046164197

Epoch: 6| Step: 8
Training loss: 1.1171544210165076
Validation loss: 2.5801926769592165

Epoch: 6| Step: 9
Training loss: 0.9634675005987918
Validation loss: 2.600616023249781

Epoch: 6| Step: 10
Training loss: 1.356519528165103
Validation loss: 2.630245916016237

Epoch: 6| Step: 11
Training loss: 1.2493085856339385
Validation loss: 2.6358974958006085

Epoch: 6| Step: 12
Training loss: 0.9621265776904893
Validation loss: 2.6410044711574776

Epoch: 6| Step: 13
Training loss: 0.7476187494294425
Validation loss: 2.5968450747287064

Epoch: 394| Step: 0
Training loss: 1.1055304304512874
Validation loss: 2.650301701987343

Epoch: 6| Step: 1
Training loss: 0.9712368209906995
Validation loss: 2.648016270660755

Epoch: 6| Step: 2
Training loss: 1.014074109779518
Validation loss: 2.590168820823345

Epoch: 6| Step: 3
Training loss: 1.0657241372449735
Validation loss: 2.669335777919284

Epoch: 6| Step: 4
Training loss: 1.4040698635944895
Validation loss: 2.659884699901563

Epoch: 6| Step: 5
Training loss: 1.0499268642567852
Validation loss: 2.5968345776658524

Epoch: 6| Step: 6
Training loss: 1.149786332225135
Validation loss: 2.5990158309131473

Epoch: 6| Step: 7
Training loss: 0.9221177508904507
Validation loss: 2.614569087705267

Epoch: 6| Step: 8
Training loss: 0.7773779090008651
Validation loss: 2.6067900045619155

Epoch: 6| Step: 9
Training loss: 1.0302004241382612
Validation loss: 2.545593797576936

Epoch: 6| Step: 10
Training loss: 1.400156679922829
Validation loss: 2.581978524689783

Epoch: 6| Step: 11
Training loss: 1.104531581725895
Validation loss: 2.5544420876873986

Epoch: 6| Step: 12
Training loss: 0.9756352409299397
Validation loss: 2.6226843656567507

Epoch: 6| Step: 13
Training loss: 0.9785817441854042
Validation loss: 2.5754475571893045

Epoch: 395| Step: 0
Training loss: 0.7815370413848467
Validation loss: 2.5715839986149343

Epoch: 6| Step: 1
Training loss: 1.627564534022675
Validation loss: 2.574864261716104

Epoch: 6| Step: 2
Training loss: 0.8081239081638687
Validation loss: 2.609091113213052

Epoch: 6| Step: 3
Training loss: 0.7237853019551195
Validation loss: 2.6162526449040366

Epoch: 6| Step: 4
Training loss: 0.7054358127209144
Validation loss: 2.5138780518702752

Epoch: 6| Step: 5
Training loss: 1.1107487299514986
Validation loss: 2.651005058310609

Epoch: 6| Step: 6
Training loss: 1.0920438265407177
Validation loss: 2.5624931769551567

Epoch: 6| Step: 7
Training loss: 1.0188519198682116
Validation loss: 2.59222916747228

Epoch: 6| Step: 8
Training loss: 0.7853759913616611
Validation loss: 2.5738901209286804

Epoch: 6| Step: 9
Training loss: 1.4017568226024528
Validation loss: 2.5878815580005274

Epoch: 6| Step: 10
Training loss: 0.8703386600747278
Validation loss: 2.52456216383845

Epoch: 6| Step: 11
Training loss: 1.1170619547267453
Validation loss: 2.5907080250110646

Epoch: 6| Step: 12
Training loss: 1.3383129038187713
Validation loss: 2.536512657591639

Epoch: 6| Step: 13
Training loss: 0.8928301432478213
Validation loss: 2.579950168236806

Epoch: 396| Step: 0
Training loss: 0.5887178703012783
Validation loss: 2.6453242575633324

Epoch: 6| Step: 1
Training loss: 1.133379301139367
Validation loss: 2.6003159982047785

Epoch: 6| Step: 2
Training loss: 1.2023606287395512
Validation loss: 2.616403870435794

Epoch: 6| Step: 3
Training loss: 1.0329061560937896
Validation loss: 2.640756005643375

Epoch: 6| Step: 4
Training loss: 0.9328752570072062
Validation loss: 2.5968057258262545

Epoch: 6| Step: 5
Training loss: 0.8146815357055777
Validation loss: 2.613572025135423

Epoch: 6| Step: 6
Training loss: 0.9195669019815802
Validation loss: 2.6136706052203236

Epoch: 6| Step: 7
Training loss: 1.2480492629146267
Validation loss: 2.5435492209037665

Epoch: 6| Step: 8
Training loss: 0.7361283170340646
Validation loss: 2.5950243167313642

Epoch: 6| Step: 9
Training loss: 1.7080910053352907
Validation loss: 2.556044720628125

Epoch: 6| Step: 10
Training loss: 1.2056009651505493
Validation loss: 2.602011167463674

Epoch: 6| Step: 11
Training loss: 0.8949930256832891
Validation loss: 2.612040469869166

Epoch: 6| Step: 12
Training loss: 0.7852852938304007
Validation loss: 2.599757418870176

Epoch: 6| Step: 13
Training loss: 0.8940129673505948
Validation loss: 2.6123982122203997

Epoch: 397| Step: 0
Training loss: 1.0115322692332331
Validation loss: 2.5997676060816497

Epoch: 6| Step: 1
Training loss: 0.8742297051691892
Validation loss: 2.5911498691137633

Epoch: 6| Step: 2
Training loss: 0.9977584989602015
Validation loss: 2.5961481367811006

Epoch: 6| Step: 3
Training loss: 1.1762020333996253
Validation loss: 2.5615609859846633

Epoch: 6| Step: 4
Training loss: 0.7752141487445432
Validation loss: 2.578665690126336

Epoch: 6| Step: 5
Training loss: 0.6933189272835821
Validation loss: 2.5755694892280756

Epoch: 6| Step: 6
Training loss: 1.0164210794174844
Validation loss: 2.594240854535944

Epoch: 6| Step: 7
Training loss: 0.8083462543700196
Validation loss: 2.568083905240692

Epoch: 6| Step: 8
Training loss: 0.9439715498015376
Validation loss: 2.5235585753503895

Epoch: 6| Step: 9
Training loss: 1.5652127939654297
Validation loss: 2.6143283694348756

Epoch: 6| Step: 10
Training loss: 1.506697484576143
Validation loss: 2.6289447934639667

Epoch: 6| Step: 11
Training loss: 1.0318651387640527
Validation loss: 2.5680974132931174

Epoch: 6| Step: 12
Training loss: 0.8256962626887875
Validation loss: 2.5676249141696506

Epoch: 6| Step: 13
Training loss: 0.9820859725381517
Validation loss: 2.588628423351161

Epoch: 398| Step: 0
Training loss: 1.670339360391379
Validation loss: 2.5844426132023277

Epoch: 6| Step: 1
Training loss: 1.2210582491253061
Validation loss: 2.5968718604089127

Epoch: 6| Step: 2
Training loss: 0.5625101724340609
Validation loss: 2.580607627267551

Epoch: 6| Step: 3
Training loss: 1.2063492017680641
Validation loss: 2.643869261760856

Epoch: 6| Step: 4
Training loss: 0.6151204806066644
Validation loss: 2.5995864007337324

Epoch: 6| Step: 5
Training loss: 0.8431282578413157
Validation loss: 2.6164050094922007

Epoch: 6| Step: 6
Training loss: 1.0447996834586513
Validation loss: 2.5928341117890903

Epoch: 6| Step: 7
Training loss: 1.0941285704357595
Validation loss: 2.6424579917289828

Epoch: 6| Step: 8
Training loss: 0.8137063827193057
Validation loss: 2.6248442891274752

Epoch: 6| Step: 9
Training loss: 0.7205412975047021
Validation loss: 2.627246228662731

Epoch: 6| Step: 10
Training loss: 0.8594304847145234
Validation loss: 2.584266768268344

Epoch: 6| Step: 11
Training loss: 0.9642863961121505
Validation loss: 2.607028980156971

Epoch: 6| Step: 12
Training loss: 0.7380180091418006
Validation loss: 2.5650865170150774

Epoch: 6| Step: 13
Training loss: 1.36127838525523
Validation loss: 2.5970053409408393

Epoch: 399| Step: 0
Training loss: 0.8108077399307383
Validation loss: 2.62654361298242

Epoch: 6| Step: 1
Training loss: 1.2254860400335112
Validation loss: 2.682496699425669

Epoch: 6| Step: 2
Training loss: 0.7999594588736166
Validation loss: 2.590017827830578

Epoch: 6| Step: 3
Training loss: 0.9185939526545532
Validation loss: 2.6291117481555535

Epoch: 6| Step: 4
Training loss: 1.2614996279890953
Validation loss: 2.5946653658219017

Epoch: 6| Step: 5
Training loss: 0.9390375245084711
Validation loss: 2.579901944078767

Epoch: 6| Step: 6
Training loss: 1.6610301152530216
Validation loss: 2.5658768292149823

Epoch: 6| Step: 7
Training loss: 0.692493209323571
Validation loss: 2.5799237844510943

Epoch: 6| Step: 8
Training loss: 1.0384318223190183
Validation loss: 2.602975043732238

Epoch: 6| Step: 9
Training loss: 0.8019141766082922
Validation loss: 2.6463220600497173

Epoch: 6| Step: 10
Training loss: 1.1150668096840202
Validation loss: 2.6218246449063107

Epoch: 6| Step: 11
Training loss: 0.7686100592049013
Validation loss: 2.5723309538782746

Epoch: 6| Step: 12
Training loss: 0.9307159057139269
Validation loss: 2.5231148638524434

Epoch: 6| Step: 13
Training loss: 0.669986955245266
Validation loss: 2.603822736281196

Epoch: 400| Step: 0
Training loss: 0.7901898253211352
Validation loss: 2.586204230774861

Epoch: 6| Step: 1
Training loss: 1.513225504370795
Validation loss: 2.6514384654131415

Epoch: 6| Step: 2
Training loss: 0.954945592129287
Validation loss: 2.565918495282217

Epoch: 6| Step: 3
Training loss: 1.0110413629162092
Validation loss: 2.5463966747368487

Epoch: 6| Step: 4
Training loss: 0.816211366892946
Validation loss: 2.516305393115251

Epoch: 6| Step: 5
Training loss: 0.5815865782970472
Validation loss: 2.591625860532856

Epoch: 6| Step: 6
Training loss: 1.3308127638903864
Validation loss: 2.5716742219729474

Epoch: 6| Step: 7
Training loss: 0.731512945127118
Validation loss: 2.6323069342676284

Epoch: 6| Step: 8
Training loss: 1.1341771817660025
Validation loss: 2.6472147216526056

Epoch: 6| Step: 9
Training loss: 0.7803565065855816
Validation loss: 2.58027320526671

Epoch: 6| Step: 10
Training loss: 0.7049521970436929
Validation loss: 2.5544859702660276

Epoch: 6| Step: 11
Training loss: 1.0299560636575136
Validation loss: 2.5822612450333557

Epoch: 6| Step: 12
Training loss: 1.383445250147155
Validation loss: 2.5783198273380425

Epoch: 6| Step: 13
Training loss: 0.9947964167190242
Validation loss: 2.563991794700011

Epoch: 401| Step: 0
Training loss: 0.7698654765738386
Validation loss: 2.5347966202104626

Epoch: 6| Step: 1
Training loss: 1.0983874508998688
Validation loss: 2.614434718028228

Epoch: 6| Step: 2
Training loss: 0.9980538623662267
Validation loss: 2.5675489725693947

Epoch: 6| Step: 3
Training loss: 0.9216763557168536
Validation loss: 2.5698308677038884

Epoch: 6| Step: 4
Training loss: 0.9261140506862748
Validation loss: 2.5706577861416173

Epoch: 6| Step: 5
Training loss: 0.8742139555362413
Validation loss: 2.566511332984495

Epoch: 6| Step: 6
Training loss: 1.4607072128513727
Validation loss: 2.5823259286478475

Epoch: 6| Step: 7
Training loss: 1.0847781462559722
Validation loss: 2.5876692613658046

Epoch: 6| Step: 8
Training loss: 0.74286965592818
Validation loss: 2.5741773958024776

Epoch: 6| Step: 9
Training loss: 1.0199821322876972
Validation loss: 2.623220794433722

Epoch: 6| Step: 10
Training loss: 1.1577078418045323
Validation loss: 2.5658417598151955

Epoch: 6| Step: 11
Training loss: 0.8054006064863363
Validation loss: 2.6258416567369567

Epoch: 6| Step: 12
Training loss: 1.0141740852174483
Validation loss: 2.5997158671672995

Epoch: 6| Step: 13
Training loss: 1.178445225105872
Validation loss: 2.6074518666346282

Epoch: 402| Step: 0
Training loss: 1.4229350906601663
Validation loss: 2.5794922719180233

Epoch: 6| Step: 1
Training loss: 1.0448098381087527
Validation loss: 2.597330127407944

Epoch: 6| Step: 2
Training loss: 0.6701368871031946
Validation loss: 2.62962719127928

Epoch: 6| Step: 3
Training loss: 0.9274004204651005
Validation loss: 2.631428597279501

Epoch: 6| Step: 4
Training loss: 0.8549788304546875
Validation loss: 2.626953208195379

Epoch: 6| Step: 5
Training loss: 0.805044002633488
Validation loss: 2.594796854200554

Epoch: 6| Step: 6
Training loss: 0.7261134575077287
Validation loss: 2.5721731514457717

Epoch: 6| Step: 7
Training loss: 1.85149554038998
Validation loss: 2.5951186096780083

Epoch: 6| Step: 8
Training loss: 0.843210330318421
Validation loss: 2.5487275670118112

Epoch: 6| Step: 9
Training loss: 0.9428392955094083
Validation loss: 2.554437700943658

Epoch: 6| Step: 10
Training loss: 1.048536377293488
Validation loss: 2.550982044333731

Epoch: 6| Step: 11
Training loss: 1.0278490223692094
Validation loss: 2.5763252064208233

Epoch: 6| Step: 12
Training loss: 0.8388138955078159
Validation loss: 2.5759769623360067

Epoch: 6| Step: 13
Training loss: 0.9305788463473993
Validation loss: 2.6119942986356506

Epoch: 403| Step: 0
Training loss: 0.798230159585833
Validation loss: 2.5957849631744776

Epoch: 6| Step: 1
Training loss: 1.113569684058282
Validation loss: 2.677025290922506

Epoch: 6| Step: 2
Training loss: 0.874759641059454
Validation loss: 2.578062792711467

Epoch: 6| Step: 3
Training loss: 0.6967840374823558
Validation loss: 2.611487076343371

Epoch: 6| Step: 4
Training loss: 0.8351083725711568
Validation loss: 2.639947130825015

Epoch: 6| Step: 5
Training loss: 0.9324363013798752
Validation loss: 2.5651677364211394

Epoch: 6| Step: 6
Training loss: 1.1193920871574219
Validation loss: 2.6009215213483885

Epoch: 6| Step: 7
Training loss: 1.574093342748317
Validation loss: 2.572485317463892

Epoch: 6| Step: 8
Training loss: 1.1904508167923353
Validation loss: 2.5866885904811907

Epoch: 6| Step: 9
Training loss: 1.0220048501110515
Validation loss: 2.588657466107108

Epoch: 6| Step: 10
Training loss: 1.0936938680141544
Validation loss: 2.5681565817485303

Epoch: 6| Step: 11
Training loss: 0.7202739730097297
Validation loss: 2.5688838679445354

Epoch: 6| Step: 12
Training loss: 0.7614687387057282
Validation loss: 2.586375941729625

Epoch: 6| Step: 13
Training loss: 0.897413781787865
Validation loss: 2.576099802531739

Epoch: 404| Step: 0
Training loss: 0.8709766668485678
Validation loss: 2.584733127441395

Epoch: 6| Step: 1
Training loss: 0.9053280185347762
Validation loss: 2.630290860433063

Epoch: 6| Step: 2
Training loss: 1.1169324463691603
Validation loss: 2.572786927652322

Epoch: 6| Step: 3
Training loss: 1.185305877272803
Validation loss: 2.6189249828451495

Epoch: 6| Step: 4
Training loss: 0.916780652559726
Validation loss: 2.5250793406796737

Epoch: 6| Step: 5
Training loss: 0.7634486972332784
Validation loss: 2.5660800271680717

Epoch: 6| Step: 6
Training loss: 0.7736547916240054
Validation loss: 2.5796511053902575

Epoch: 6| Step: 7
Training loss: 1.0558136755466436
Validation loss: 2.59849653301212

Epoch: 6| Step: 8
Training loss: 0.7094052749424767
Validation loss: 2.6348555398486604

Epoch: 6| Step: 9
Training loss: 0.7920929530678478
Validation loss: 2.615661092468904

Epoch: 6| Step: 10
Training loss: 0.9612778471843115
Validation loss: 2.5784218511282617

Epoch: 6| Step: 11
Training loss: 1.719638872050031
Validation loss: 2.5897853608834986

Epoch: 6| Step: 12
Training loss: 0.903855020164294
Validation loss: 2.6263206429583015

Epoch: 6| Step: 13
Training loss: 0.9066721163321784
Validation loss: 2.5798257169581715

Epoch: 405| Step: 0
Training loss: 0.9424553245358
Validation loss: 2.5853108302690107

Epoch: 6| Step: 1
Training loss: 0.9851104774096819
Validation loss: 2.5520340324362865

Epoch: 6| Step: 2
Training loss: 0.5269773552642212
Validation loss: 2.572195258272728

Epoch: 6| Step: 3
Training loss: 0.7287677400238955
Validation loss: 2.565572896560754

Epoch: 6| Step: 4
Training loss: 0.6684235034277987
Validation loss: 2.476741435328698

Epoch: 6| Step: 5
Training loss: 0.9601828860878655
Validation loss: 2.6107344598085724

Epoch: 6| Step: 6
Training loss: 0.8294338463587887
Validation loss: 2.619760370288778

Epoch: 6| Step: 7
Training loss: 0.9643515748536892
Validation loss: 2.61833689488056

Epoch: 6| Step: 8
Training loss: 1.6244143384314271
Validation loss: 2.5538178498722517

Epoch: 6| Step: 9
Training loss: 1.153595842206872
Validation loss: 2.579643603728721

Epoch: 6| Step: 10
Training loss: 0.9200639230351637
Validation loss: 2.582834796843892

Epoch: 6| Step: 11
Training loss: 0.7605277899104504
Validation loss: 2.6785048385698893

Epoch: 6| Step: 12
Training loss: 1.3309271479157234
Validation loss: 2.5800954359476354

Epoch: 6| Step: 13
Training loss: 0.8288469586393148
Validation loss: 2.6021675040256067

Epoch: 406| Step: 0
Training loss: 1.0800707301185029
Validation loss: 2.631753076347108

Epoch: 6| Step: 1
Training loss: 0.8887517872187461
Validation loss: 2.6310951072546955

Epoch: 6| Step: 2
Training loss: 0.6716017721984887
Validation loss: 2.612358839002599

Epoch: 6| Step: 3
Training loss: 0.9680817668169085
Validation loss: 2.564744230212892

Epoch: 6| Step: 4
Training loss: 1.0640643328456245
Validation loss: 2.536467962749357

Epoch: 6| Step: 5
Training loss: 0.7393637496853324
Validation loss: 2.5776675039944714

Epoch: 6| Step: 6
Training loss: 0.6482556559194208
Validation loss: 2.577709079677476

Epoch: 6| Step: 7
Training loss: 0.5190400691413452
Validation loss: 2.5785150560412013

Epoch: 6| Step: 8
Training loss: 1.3436972585574194
Validation loss: 2.5753653041883773

Epoch: 6| Step: 9
Training loss: 0.7141707958011559
Validation loss: 2.6211199012963995

Epoch: 6| Step: 10
Training loss: 0.7896838998957799
Validation loss: 2.576261382419466

Epoch: 6| Step: 11
Training loss: 0.8708745569452764
Validation loss: 2.636005974019468

Epoch: 6| Step: 12
Training loss: 1.6726735427297508
Validation loss: 2.6012924176334837

Epoch: 6| Step: 13
Training loss: 1.033210451500341
Validation loss: 2.5464619650715123

Epoch: 407| Step: 0
Training loss: 1.011494026117414
Validation loss: 2.5955087604760667

Epoch: 6| Step: 1
Training loss: 0.9114236479926049
Validation loss: 2.556739099994259

Epoch: 6| Step: 2
Training loss: 0.7696786342393672
Validation loss: 2.6067527036134868

Epoch: 6| Step: 3
Training loss: 0.711360763479742
Validation loss: 2.5786471136823597

Epoch: 6| Step: 4
Training loss: 0.7176937552098683
Validation loss: 2.63694999528502

Epoch: 6| Step: 5
Training loss: 1.0397948932132686
Validation loss: 2.62780359958716

Epoch: 6| Step: 6
Training loss: 0.9660972452755994
Validation loss: 2.567307041733759

Epoch: 6| Step: 7
Training loss: 0.6473615060811572
Validation loss: 2.6377378552351

Epoch: 6| Step: 8
Training loss: 1.5239475276804688
Validation loss: 2.619443371007202

Epoch: 6| Step: 9
Training loss: 0.5764750571996448
Validation loss: 2.604075717609419

Epoch: 6| Step: 10
Training loss: 1.0380631423701077
Validation loss: 2.5500218583709744

Epoch: 6| Step: 11
Training loss: 0.6647230117128243
Validation loss: 2.577309049704399

Epoch: 6| Step: 12
Training loss: 0.818501098305834
Validation loss: 2.5837591087009733

Epoch: 6| Step: 13
Training loss: 1.5446477711959277
Validation loss: 2.586342233445454

Epoch: 408| Step: 0
Training loss: 0.8888898980280658
Validation loss: 2.601721437045921

Epoch: 6| Step: 1
Training loss: 0.8730133528108812
Validation loss: 2.6290777262915537

Epoch: 6| Step: 2
Training loss: 1.151856917654875
Validation loss: 2.5787139374033825

Epoch: 6| Step: 3
Training loss: 1.3117003048207116
Validation loss: 2.5730026529335275

Epoch: 6| Step: 4
Training loss: 1.0158457589478287
Validation loss: 2.6034488273535668

Epoch: 6| Step: 5
Training loss: 0.8194949117482775
Validation loss: 2.598038548228834

Epoch: 6| Step: 6
Training loss: 1.0441818326217573
Validation loss: 2.5935717908313167

Epoch: 6| Step: 7
Training loss: 1.1657560689016768
Validation loss: 2.585655496669633

Epoch: 6| Step: 8
Training loss: 0.9437971659109929
Validation loss: 2.5280110079258065

Epoch: 6| Step: 9
Training loss: 0.8208564408110903
Validation loss: 2.6042102555759565

Epoch: 6| Step: 10
Training loss: 0.7797027525241277
Validation loss: 2.5409893842823434

Epoch: 6| Step: 11
Training loss: 0.4598088428081729
Validation loss: 2.578922495174002

Epoch: 6| Step: 12
Training loss: 0.6501075197204791
Validation loss: 2.5671698345397664

Epoch: 6| Step: 13
Training loss: 1.607862335707998
Validation loss: 2.550490420685142

Epoch: 409| Step: 0
Training loss: 1.0372318978503374
Validation loss: 2.5131512359360286

Epoch: 6| Step: 1
Training loss: 0.9774844890837046
Validation loss: 2.5166519469868587

Epoch: 6| Step: 2
Training loss: 1.0233984204467785
Validation loss: 2.6350787980291237

Epoch: 6| Step: 3
Training loss: 0.6725328019803439
Validation loss: 2.594483130228086

Epoch: 6| Step: 4
Training loss: 1.1968479641482825
Validation loss: 2.6240585394838476

Epoch: 6| Step: 5
Training loss: 0.8576363749259177
Validation loss: 2.6172922369653135

Epoch: 6| Step: 6
Training loss: 0.5938080207182792
Validation loss: 2.599943495405418

Epoch: 6| Step: 7
Training loss: 1.4679586835498801
Validation loss: 2.5873987346988025

Epoch: 6| Step: 8
Training loss: 0.9416981478017152
Validation loss: 2.6101185544445324

Epoch: 6| Step: 9
Training loss: 1.0697933525114263
Validation loss: 2.5741470782307627

Epoch: 6| Step: 10
Training loss: 0.7914455799448574
Validation loss: 2.5287187030846145

Epoch: 6| Step: 11
Training loss: 0.7857387526529758
Validation loss: 2.608611217804742

Epoch: 6| Step: 12
Training loss: 0.6186679515962301
Validation loss: 2.550951918402705

Epoch: 6| Step: 13
Training loss: 0.8488928217662238
Validation loss: 2.565004783809333

Epoch: 410| Step: 0
Training loss: 0.982587917849602
Validation loss: 2.5431224817548066

Epoch: 6| Step: 1
Training loss: 0.7922138698786154
Validation loss: 2.577896092588991

Epoch: 6| Step: 2
Training loss: 1.2819971836731634
Validation loss: 2.566362385445113

Epoch: 6| Step: 3
Training loss: 0.6769283459635889
Validation loss: 2.5593482072395837

Epoch: 6| Step: 4
Training loss: 0.8156113839017765
Validation loss: 2.5529992360921896

Epoch: 6| Step: 5
Training loss: 0.7976505768786228
Validation loss: 2.628797176492219

Epoch: 6| Step: 6
Training loss: 0.7875977697685713
Validation loss: 2.5754693890490783

Epoch: 6| Step: 7
Training loss: 1.0449300890448179
Validation loss: 2.534003694728314

Epoch: 6| Step: 8
Training loss: 0.743382986859383
Validation loss: 2.5660836507175797

Epoch: 6| Step: 9
Training loss: 1.2190668721182973
Validation loss: 2.5846501706308405

Epoch: 6| Step: 10
Training loss: 1.4052391657782348
Validation loss: 2.5373572624161995

Epoch: 6| Step: 11
Training loss: 0.8669061633987634
Validation loss: 2.6035447764118

Epoch: 6| Step: 12
Training loss: 0.7791632439713262
Validation loss: 2.5409363546866572

Epoch: 6| Step: 13
Training loss: 0.9374380727023932
Validation loss: 2.586843049690077

Epoch: 411| Step: 0
Training loss: 0.4939959468810416
Validation loss: 2.56972462154697

Epoch: 6| Step: 1
Training loss: 0.9029389107192046
Validation loss: 2.5727626636042595

Epoch: 6| Step: 2
Training loss: 1.0425504495685711
Validation loss: 2.6020792466053404

Epoch: 6| Step: 3
Training loss: 0.5748386799453158
Validation loss: 2.5978468440221665

Epoch: 6| Step: 4
Training loss: 0.95575014900368
Validation loss: 2.591357847706094

Epoch: 6| Step: 5
Training loss: 0.9263680123686009
Validation loss: 2.611063321557784

Epoch: 6| Step: 6
Training loss: 0.8680603171323942
Validation loss: 2.5856118895183178

Epoch: 6| Step: 7
Training loss: 0.9248451941057245
Validation loss: 2.5534553006011227

Epoch: 6| Step: 8
Training loss: 0.9955554480005057
Validation loss: 2.59404074330074

Epoch: 6| Step: 9
Training loss: 1.3953424653427144
Validation loss: 2.562528858177387

Epoch: 6| Step: 10
Training loss: 0.8831294343247149
Validation loss: 2.600738944903889

Epoch: 6| Step: 11
Training loss: 0.9909916076035342
Validation loss: 2.5622458913462904

Epoch: 6| Step: 12
Training loss: 0.7987357461579841
Validation loss: 2.618443596637004

Epoch: 6| Step: 13
Training loss: 0.7216872858826989
Validation loss: 2.604349989478397

Epoch: 412| Step: 0
Training loss: 0.6810747874963907
Validation loss: 2.5499628924493494

Epoch: 6| Step: 1
Training loss: 0.879168933184506
Validation loss: 2.602998873497036

Epoch: 6| Step: 2
Training loss: 0.8793517954353339
Validation loss: 2.614525772818812

Epoch: 6| Step: 3
Training loss: 0.6205613835701537
Validation loss: 2.5308694357165935

Epoch: 6| Step: 4
Training loss: 0.5814283948339366
Validation loss: 2.618667404280395

Epoch: 6| Step: 5
Training loss: 1.6351132769526389
Validation loss: 2.5680562235687674

Epoch: 6| Step: 6
Training loss: 0.9432756848855909
Validation loss: 2.5257442233699754

Epoch: 6| Step: 7
Training loss: 0.9452658082134028
Validation loss: 2.606954300731448

Epoch: 6| Step: 8
Training loss: 0.7439984764037375
Validation loss: 2.5527317287408975

Epoch: 6| Step: 9
Training loss: 1.0348270684587788
Validation loss: 2.5824459202714993

Epoch: 6| Step: 10
Training loss: 1.0321028679508397
Validation loss: 2.582341716528047

Epoch: 6| Step: 11
Training loss: 0.6474689005596524
Validation loss: 2.5793733753285193

Epoch: 6| Step: 12
Training loss: 0.751243434756721
Validation loss: 2.6130453249385686

Epoch: 6| Step: 13
Training loss: 0.8594390845246362
Validation loss: 2.635421878573324

Epoch: 413| Step: 0
Training loss: 0.4807733950067786
Validation loss: 2.5291604730654886

Epoch: 6| Step: 1
Training loss: 0.8866064866038442
Validation loss: 2.5762760660900246

Epoch: 6| Step: 2
Training loss: 0.6657497065318224
Validation loss: 2.565646805788675

Epoch: 6| Step: 3
Training loss: 0.8909456779990417
Validation loss: 2.5922974651880573

Epoch: 6| Step: 4
Training loss: 0.7467233288359758
Validation loss: 2.5878817652904553

Epoch: 6| Step: 5
Training loss: 0.9518387041291627
Validation loss: 2.606134332518934

Epoch: 6| Step: 6
Training loss: 1.4862346043282613
Validation loss: 2.5730074867765262

Epoch: 6| Step: 7
Training loss: 1.0602075866548668
Validation loss: 2.557589237176449

Epoch: 6| Step: 8
Training loss: 0.6632324865813394
Validation loss: 2.594898995826869

Epoch: 6| Step: 9
Training loss: 0.7483307620969352
Validation loss: 2.6387543833624068

Epoch: 6| Step: 10
Training loss: 1.369001699846437
Validation loss: 2.6423761103089203

Epoch: 6| Step: 11
Training loss: 0.7014838244666172
Validation loss: 2.6497233372345685

Epoch: 6| Step: 12
Training loss: 0.618504362766295
Validation loss: 2.6111369018994424

Epoch: 6| Step: 13
Training loss: 1.2052717007018863
Validation loss: 2.6009832583158365

Epoch: 414| Step: 0
Training loss: 1.1102427997179543
Validation loss: 2.637605449261955

Epoch: 6| Step: 1
Training loss: 0.7306773657914578
Validation loss: 2.60728533097972

Epoch: 6| Step: 2
Training loss: 0.9481183490758789
Validation loss: 2.607865847008985

Epoch: 6| Step: 3
Training loss: 0.9619617430976989
Validation loss: 2.5959631581751115

Epoch: 6| Step: 4
Training loss: 0.9822717934975084
Validation loss: 2.5327646409819202

Epoch: 6| Step: 5
Training loss: 0.9537796211392499
Validation loss: 2.575294219803371

Epoch: 6| Step: 6
Training loss: 0.5468799590839607
Validation loss: 2.608516011122725

Epoch: 6| Step: 7
Training loss: 0.9236883658571481
Validation loss: 2.652120843958178

Epoch: 6| Step: 8
Training loss: 1.4482058046572048
Validation loss: 2.651455310460031

Epoch: 6| Step: 9
Training loss: 0.9187915766644181
Validation loss: 2.6478533255271617

Epoch: 6| Step: 10
Training loss: 0.8801737144629637
Validation loss: 2.6700294471097936

Epoch: 6| Step: 11
Training loss: 0.8877751783443787
Validation loss: 2.609882526189958

Epoch: 6| Step: 12
Training loss: 0.9284403794949208
Validation loss: 2.5954897917030686

Epoch: 6| Step: 13
Training loss: 0.8190167320181833
Validation loss: 2.6280713203261175

Epoch: 415| Step: 0
Training loss: 0.8163888737777785
Validation loss: 2.6543096598658096

Epoch: 6| Step: 1
Training loss: 0.8242047927904079
Validation loss: 2.643514808792725

Epoch: 6| Step: 2
Training loss: 0.7846685004811126
Validation loss: 2.6392954050344977

Epoch: 6| Step: 3
Training loss: 0.5822874951653914
Validation loss: 2.629609541512813

Epoch: 6| Step: 4
Training loss: 0.996370135091444
Validation loss: 2.685008483556017

Epoch: 6| Step: 5
Training loss: 0.7448985327677642
Validation loss: 2.589139034081634

Epoch: 6| Step: 6
Training loss: 1.5430786866244457
Validation loss: 2.62152605428632

Epoch: 6| Step: 7
Training loss: 0.938846574735206
Validation loss: 2.562413532069777

Epoch: 6| Step: 8
Training loss: 0.8843744689077124
Validation loss: 2.626055853287235

Epoch: 6| Step: 9
Training loss: 0.9617417234377498
Validation loss: 2.5971726046178545

Epoch: 6| Step: 10
Training loss: 0.5649966886305194
Validation loss: 2.5930314351736317

Epoch: 6| Step: 11
Training loss: 1.3404477373497865
Validation loss: 2.617603826859179

Epoch: 6| Step: 12
Training loss: 0.7319825749616277
Validation loss: 2.566879724250993

Epoch: 6| Step: 13
Training loss: 0.9183637702476503
Validation loss: 2.668821646259459

Epoch: 416| Step: 0
Training loss: 0.8478867880940825
Validation loss: 2.6015574290061

Epoch: 6| Step: 1
Training loss: 0.7799426393325065
Validation loss: 2.650914492051776

Epoch: 6| Step: 2
Training loss: 0.8935007881626438
Validation loss: 2.64268132187077

Epoch: 6| Step: 3
Training loss: 0.9361250649634415
Validation loss: 2.5784833023317697

Epoch: 6| Step: 4
Training loss: 0.8299553275438286
Validation loss: 2.5947216772326125

Epoch: 6| Step: 5
Training loss: 0.7883188501469887
Validation loss: 2.5619879730522013

Epoch: 6| Step: 6
Training loss: 0.709728512504889
Validation loss: 2.5878118692566288

Epoch: 6| Step: 7
Training loss: 0.9880483903328073
Validation loss: 2.603047234578422

Epoch: 6| Step: 8
Training loss: 1.159688836160937
Validation loss: 2.552854652363418

Epoch: 6| Step: 9
Training loss: 1.464291969644829
Validation loss: 2.593105986893144

Epoch: 6| Step: 10
Training loss: 0.7503808167356205
Validation loss: 2.550207052987522

Epoch: 6| Step: 11
Training loss: 0.7910161524641374
Validation loss: 2.5638409494244208

Epoch: 6| Step: 12
Training loss: 1.0442700215603662
Validation loss: 2.5811635308487926

Epoch: 6| Step: 13
Training loss: 1.0625884636347327
Validation loss: 2.5344820620073287

Epoch: 417| Step: 0
Training loss: 0.8781381259901049
Validation loss: 2.58921827125096

Epoch: 6| Step: 1
Training loss: 1.000468204086467
Validation loss: 2.576210667585856

Epoch: 6| Step: 2
Training loss: 0.6802310743128062
Validation loss: 2.6032355564021663

Epoch: 6| Step: 3
Training loss: 0.7914374839591722
Validation loss: 2.564058806645106

Epoch: 6| Step: 4
Training loss: 0.6743584577636873
Validation loss: 2.5791044128086376

Epoch: 6| Step: 5
Training loss: 1.3166147400881716
Validation loss: 2.606865062147459

Epoch: 6| Step: 6
Training loss: 0.9288338981921946
Validation loss: 2.5852751176454563

Epoch: 6| Step: 7
Training loss: 0.9432881646300174
Validation loss: 2.651405179645503

Epoch: 6| Step: 8
Training loss: 1.5836139062277153
Validation loss: 2.6998081474665625

Epoch: 6| Step: 9
Training loss: 1.044393930132353
Validation loss: 2.6139931842303565

Epoch: 6| Step: 10
Training loss: 0.7885107623099351
Validation loss: 2.5965321415107296

Epoch: 6| Step: 11
Training loss: 1.0727881876243262
Validation loss: 2.5586674881033136

Epoch: 6| Step: 12
Training loss: 0.7955853367078978
Validation loss: 2.650885501801137

Epoch: 6| Step: 13
Training loss: 0.9507275117154995
Validation loss: 2.671483581902809

Epoch: 418| Step: 0
Training loss: 0.6886869501377746
Validation loss: 2.625036027449164

Epoch: 6| Step: 1
Training loss: 0.8090465217860234
Validation loss: 2.6575672249531643

Epoch: 6| Step: 2
Training loss: 1.5546322913407198
Validation loss: 2.643798892002714

Epoch: 6| Step: 3
Training loss: 0.9932100328517125
Validation loss: 2.6742563919447937

Epoch: 6| Step: 4
Training loss: 1.1470612044762805
Validation loss: 2.6774484902397973

Epoch: 6| Step: 5
Training loss: 0.7659091033091723
Validation loss: 2.736514571393352

Epoch: 6| Step: 6
Training loss: 1.3536910566775238
Validation loss: 2.7388871085457973

Epoch: 6| Step: 7
Training loss: 1.0707347064977923
Validation loss: 2.6810681314743383

Epoch: 6| Step: 8
Training loss: 0.912061473560664
Validation loss: 2.608698256521261

Epoch: 6| Step: 9
Training loss: 1.0967942515155114
Validation loss: 2.627429186335255

Epoch: 6| Step: 10
Training loss: 0.9615679587828192
Validation loss: 2.656912373253231

Epoch: 6| Step: 11
Training loss: 0.9730973985955738
Validation loss: 2.6335449105585718

Epoch: 6| Step: 12
Training loss: 0.5709579682087195
Validation loss: 2.5742431701211927

Epoch: 6| Step: 13
Training loss: 0.9309820570563716
Validation loss: 2.6560562960736727

Epoch: 419| Step: 0
Training loss: 1.189881496619695
Validation loss: 2.6160865100045836

Epoch: 6| Step: 1
Training loss: 0.8831299742648345
Validation loss: 2.646813674090217

Epoch: 6| Step: 2
Training loss: 0.7706459994831074
Validation loss: 2.6099834075488015

Epoch: 6| Step: 3
Training loss: 0.9691396052867564
Validation loss: 2.663795554769369

Epoch: 6| Step: 4
Training loss: 1.4830913414172082
Validation loss: 2.642045310608682

Epoch: 6| Step: 5
Training loss: 1.0050497111082148
Validation loss: 2.574012929496116

Epoch: 6| Step: 6
Training loss: 0.937399954225992
Validation loss: 2.637085251944339

Epoch: 6| Step: 7
Training loss: 0.9441627256799945
Validation loss: 2.6084163221943175

Epoch: 6| Step: 8
Training loss: 0.6296030295535419
Validation loss: 2.5496444934288607

Epoch: 6| Step: 9
Training loss: 0.9490472772135454
Validation loss: 2.6003306148084357

Epoch: 6| Step: 10
Training loss: 0.8759868710526907
Validation loss: 2.634925643250582

Epoch: 6| Step: 11
Training loss: 0.6549959917164236
Validation loss: 2.615747159826854

Epoch: 6| Step: 12
Training loss: 0.9261602599703992
Validation loss: 2.6696196438283932

Epoch: 6| Step: 13
Training loss: 1.0844230795103706
Validation loss: 2.679152009804256

Epoch: 420| Step: 0
Training loss: 0.884748816593669
Validation loss: 2.675188579032367

Epoch: 6| Step: 1
Training loss: 1.0158700500645563
Validation loss: 2.6677229299348286

Epoch: 6| Step: 2
Training loss: 0.729431435788693
Validation loss: 2.6627216563244542

Epoch: 6| Step: 3
Training loss: 1.0336427384327342
Validation loss: 2.6582607886202703

Epoch: 6| Step: 4
Training loss: 0.7836527687126555
Validation loss: 2.6409449336493087

Epoch: 6| Step: 5
Training loss: 1.0328887865110614
Validation loss: 2.6567324480729932

Epoch: 6| Step: 6
Training loss: 0.6091790984781689
Validation loss: 2.62208060245401

Epoch: 6| Step: 7
Training loss: 1.657601003431878
Validation loss: 2.6503393345824335

Epoch: 6| Step: 8
Training loss: 0.6578463031483135
Validation loss: 2.654881936613408

Epoch: 6| Step: 9
Training loss: 0.9811941556164764
Validation loss: 2.6752449333500135

Epoch: 6| Step: 10
Training loss: 0.6628150442776909
Validation loss: 2.6428629704513025

Epoch: 6| Step: 11
Training loss: 1.0640482001106968
Validation loss: 2.648825265410027

Epoch: 6| Step: 12
Training loss: 1.3078390649720413
Validation loss: 2.649260821505726

Epoch: 6| Step: 13
Training loss: 1.0311412175919772
Validation loss: 2.5976636843467396

Epoch: 421| Step: 0
Training loss: 0.6273766391441638
Validation loss: 2.559204525640107

Epoch: 6| Step: 1
Training loss: 1.0069931603117028
Validation loss: 2.5703477944035016

Epoch: 6| Step: 2
Training loss: 0.5796674565554271
Validation loss: 2.5926067023297006

Epoch: 6| Step: 3
Training loss: 0.8803965500860634
Validation loss: 2.6506068104727967

Epoch: 6| Step: 4
Training loss: 1.0373171725677284
Validation loss: 2.6513044955228233

Epoch: 6| Step: 5
Training loss: 1.3555706766376077
Validation loss: 2.6986909783726403

Epoch: 6| Step: 6
Training loss: 0.7016660176392707
Validation loss: 2.6970182172305934

Epoch: 6| Step: 7
Training loss: 1.059924538463441
Validation loss: 2.573288343716543

Epoch: 6| Step: 8
Training loss: 0.7847731685323338
Validation loss: 2.6031685912904274

Epoch: 6| Step: 9
Training loss: 0.7861272397051117
Validation loss: 2.6923199243756724

Epoch: 6| Step: 10
Training loss: 0.8532185332059052
Validation loss: 2.5646111390511996

Epoch: 6| Step: 11
Training loss: 0.6628915223636521
Validation loss: 2.623289625836988

Epoch: 6| Step: 12
Training loss: 1.4234860693541702
Validation loss: 2.6327874836171827

Epoch: 6| Step: 13
Training loss: 0.5323433004320831
Validation loss: 2.591739426804799

Epoch: 422| Step: 0
Training loss: 0.8493249877622472
Validation loss: 2.6579344401343628

Epoch: 6| Step: 1
Training loss: 0.681669349393097
Validation loss: 2.623278234849188

Epoch: 6| Step: 2
Training loss: 0.9252789579352333
Validation loss: 2.5947273129007584

Epoch: 6| Step: 3
Training loss: 0.9832573252467368
Validation loss: 2.6644360232898423

Epoch: 6| Step: 4
Training loss: 1.137169450373967
Validation loss: 2.624033833369437

Epoch: 6| Step: 5
Training loss: 0.8367385947387903
Validation loss: 2.62282422129815

Epoch: 6| Step: 6
Training loss: 0.6769596035708414
Validation loss: 2.619919712484178

Epoch: 6| Step: 7
Training loss: 0.876120871200118
Validation loss: 2.5933117170666944

Epoch: 6| Step: 8
Training loss: 1.3575047748966438
Validation loss: 2.687415823985883

Epoch: 6| Step: 9
Training loss: 1.0267869143745565
Validation loss: 2.626771994849422

Epoch: 6| Step: 10
Training loss: 0.7241437706512206
Validation loss: 2.608303200199322

Epoch: 6| Step: 11
Training loss: 0.48360320098959775
Validation loss: 2.6407159341959083

Epoch: 6| Step: 12
Training loss: 0.8549381857829589
Validation loss: 2.654402176146241

Epoch: 6| Step: 13
Training loss: 0.895729827815551
Validation loss: 2.5988453679325283

Epoch: 423| Step: 0
Training loss: 0.5372815775087337
Validation loss: 2.5826265742403907

Epoch: 6| Step: 1
Training loss: 0.5254512595885136
Validation loss: 2.6214239876069665

Epoch: 6| Step: 2
Training loss: 0.48641521179687897
Validation loss: 2.582141098632897

Epoch: 6| Step: 3
Training loss: 1.086721672311963
Validation loss: 2.5987901244583522

Epoch: 6| Step: 4
Training loss: 1.5851510639585262
Validation loss: 2.649301078684835

Epoch: 6| Step: 5
Training loss: 0.7341112515438307
Validation loss: 2.6226093062660696

Epoch: 6| Step: 6
Training loss: 0.9506948790740035
Validation loss: 2.6016175471411263

Epoch: 6| Step: 7
Training loss: 1.0706586626041874
Validation loss: 2.561624454935615

Epoch: 6| Step: 8
Training loss: 0.9247341108934581
Validation loss: 2.644560670524663

Epoch: 6| Step: 9
Training loss: 0.854594267061155
Validation loss: 2.637068239762433

Epoch: 6| Step: 10
Training loss: 0.6157683704174371
Validation loss: 2.6466408546047457

Epoch: 6| Step: 11
Training loss: 1.085942988759173
Validation loss: 2.589267365464214

Epoch: 6| Step: 12
Training loss: 0.7567622979547632
Validation loss: 2.6634731591735745

Epoch: 6| Step: 13
Training loss: 1.0080126777979428
Validation loss: 2.580333172505639

Epoch: 424| Step: 0
Training loss: 0.8841901848913313
Validation loss: 2.678359834397088

Epoch: 6| Step: 1
Training loss: 0.8481912638472725
Validation loss: 2.565373894828141

Epoch: 6| Step: 2
Training loss: 0.8692022751791995
Validation loss: 2.5920824259163804

Epoch: 6| Step: 3
Training loss: 1.041750249688247
Validation loss: 2.6656917538321205

Epoch: 6| Step: 4
Training loss: 0.6558449039828056
Validation loss: 2.6624638747509115

Epoch: 6| Step: 5
Training loss: 0.5546093737963204
Validation loss: 2.605629431303762

Epoch: 6| Step: 6
Training loss: 0.982390264833004
Validation loss: 2.644821211199255

Epoch: 6| Step: 7
Training loss: 0.7703505671072899
Validation loss: 2.579314741486509

Epoch: 6| Step: 8
Training loss: 1.3452498471228613
Validation loss: 2.633910375660015

Epoch: 6| Step: 9
Training loss: 0.4436284563677498
Validation loss: 2.551294980933672

Epoch: 6| Step: 10
Training loss: 0.9262051798778411
Validation loss: 2.6029674566312915

Epoch: 6| Step: 11
Training loss: 0.7070693959436261
Validation loss: 2.617859514037492

Epoch: 6| Step: 12
Training loss: 0.9198202413150383
Validation loss: 2.662694331734894

Epoch: 6| Step: 13
Training loss: 0.6588568907268034
Validation loss: 2.560806847048568

Epoch: 425| Step: 0
Training loss: 0.7586274631602938
Validation loss: 2.5944702037110656

Epoch: 6| Step: 1
Training loss: 0.5536670431941155
Validation loss: 2.582538025986274

Epoch: 6| Step: 2
Training loss: 0.7401978979458629
Validation loss: 2.569983750241236

Epoch: 6| Step: 3
Training loss: 0.7401931469389531
Validation loss: 2.6375618573327935

Epoch: 6| Step: 4
Training loss: 1.0345359239125536
Validation loss: 2.624082026355788

Epoch: 6| Step: 5
Training loss: 0.8141424011732361
Validation loss: 2.673024880073792

Epoch: 6| Step: 6
Training loss: 0.7790451216796457
Validation loss: 2.620219782790899

Epoch: 6| Step: 7
Training loss: 0.7123635211534498
Validation loss: 2.64296683276531

Epoch: 6| Step: 8
Training loss: 1.0008610951884769
Validation loss: 2.6174882554668546

Epoch: 6| Step: 9
Training loss: 0.8627128283203859
Validation loss: 2.6450609796966655

Epoch: 6| Step: 10
Training loss: 0.8087978381906251
Validation loss: 2.639381748039983

Epoch: 6| Step: 11
Training loss: 0.7785511703530432
Validation loss: 2.649990830315614

Epoch: 6| Step: 12
Training loss: 1.611826390764478
Validation loss: 2.63882552009479

Epoch: 6| Step: 13
Training loss: 0.4722342696086737
Validation loss: 2.6264403947764428

Epoch: 426| Step: 0
Training loss: 0.590265035180074
Validation loss: 2.6638862350188997

Epoch: 6| Step: 1
Training loss: 0.5934058245922976
Validation loss: 2.6341558362993007

Epoch: 6| Step: 2
Training loss: 0.7923404102108362
Validation loss: 2.636657292156056

Epoch: 6| Step: 3
Training loss: 1.4281983671812846
Validation loss: 2.6500789915463736

Epoch: 6| Step: 4
Training loss: 0.9171266304886534
Validation loss: 2.6247959360398356

Epoch: 6| Step: 5
Training loss: 0.9514219671997581
Validation loss: 2.5924015599846126

Epoch: 6| Step: 6
Training loss: 0.6685231679740709
Validation loss: 2.628393356526432

Epoch: 6| Step: 7
Training loss: 0.9429914179418502
Validation loss: 2.6257516299552646

Epoch: 6| Step: 8
Training loss: 0.6579325088524737
Validation loss: 2.59547774286243

Epoch: 6| Step: 9
Training loss: 0.8895733966019299
Validation loss: 2.5884705245273008

Epoch: 6| Step: 10
Training loss: 0.4208072289154153
Validation loss: 2.642684223895576

Epoch: 6| Step: 11
Training loss: 0.7577870944768887
Validation loss: 2.617203016851934

Epoch: 6| Step: 12
Training loss: 0.5989926673889328
Validation loss: 2.585843809645249

Epoch: 6| Step: 13
Training loss: 1.177845407189719
Validation loss: 2.632053360129511

Epoch: 427| Step: 0
Training loss: 0.7631395831265098
Validation loss: 2.665494382996545

Epoch: 6| Step: 1
Training loss: 0.950907927124426
Validation loss: 2.5813447132853162

Epoch: 6| Step: 2
Training loss: 0.4993634940911851
Validation loss: 2.601465416243313

Epoch: 6| Step: 3
Training loss: 1.1161204757812349
Validation loss: 2.6469016183763006

Epoch: 6| Step: 4
Training loss: 1.4626674099824373
Validation loss: 2.6189349968752316

Epoch: 6| Step: 5
Training loss: 0.6670912840744863
Validation loss: 2.6923436791683772

Epoch: 6| Step: 6
Training loss: 0.9166183603447611
Validation loss: 2.6374694509077905

Epoch: 6| Step: 7
Training loss: 0.6236864114123588
Validation loss: 2.6348086523978105

Epoch: 6| Step: 8
Training loss: 0.5945558600526627
Validation loss: 2.6677791589532736

Epoch: 6| Step: 9
Training loss: 0.7996548802295748
Validation loss: 2.603380501653996

Epoch: 6| Step: 10
Training loss: 0.5102577026810023
Validation loss: 2.6437043663276953

Epoch: 6| Step: 11
Training loss: 0.7882976791136684
Validation loss: 2.631092962681767

Epoch: 6| Step: 12
Training loss: 1.0217776634217997
Validation loss: 2.593952944679005

Epoch: 6| Step: 13
Training loss: 0.45187168426141366
Validation loss: 2.640105683614827

Epoch: 428| Step: 0
Training loss: 0.698272789771368
Validation loss: 2.6482472609290295

Epoch: 6| Step: 1
Training loss: 1.34663241651308
Validation loss: 2.596765366377286

Epoch: 6| Step: 2
Training loss: 0.5323612147792617
Validation loss: 2.6007461030586136

Epoch: 6| Step: 3
Training loss: 0.5772539226354096
Validation loss: 2.6301154897688996

Epoch: 6| Step: 4
Training loss: 1.3999237176003905
Validation loss: 2.5724920985598208

Epoch: 6| Step: 5
Training loss: 0.7575412146683731
Validation loss: 2.5658186303196837

Epoch: 6| Step: 6
Training loss: 0.7831683448432022
Validation loss: 2.6681955296063333

Epoch: 6| Step: 7
Training loss: 0.6648378221760833
Validation loss: 2.626838320429822

Epoch: 6| Step: 8
Training loss: 0.8507676570986957
Validation loss: 2.655248991898264

Epoch: 6| Step: 9
Training loss: 0.7580542031462423
Validation loss: 2.6232041467786447

Epoch: 6| Step: 10
Training loss: 0.6863493176283814
Validation loss: 2.609543465603106

Epoch: 6| Step: 11
Training loss: 0.6540548303904451
Validation loss: 2.66139252961411

Epoch: 6| Step: 12
Training loss: 0.6872916772970951
Validation loss: 2.5987451551281207

Epoch: 6| Step: 13
Training loss: 0.8283975980251381
Validation loss: 2.6279618039077075

Epoch: 429| Step: 0
Training loss: 1.4433529328446388
Validation loss: 2.644512137001648

Epoch: 6| Step: 1
Training loss: 0.5542743917560203
Validation loss: 2.590695371082343

Epoch: 6| Step: 2
Training loss: 0.7628086215947755
Validation loss: 2.586663151063529

Epoch: 6| Step: 3
Training loss: 0.6393218626387869
Validation loss: 2.6119835429790395

Epoch: 6| Step: 4
Training loss: 1.0366599623247648
Validation loss: 2.6107644438297317

Epoch: 6| Step: 5
Training loss: 0.44340535064139336
Validation loss: 2.6330532941117566

Epoch: 6| Step: 6
Training loss: 0.8862157394824541
Validation loss: 2.5952280880963

Epoch: 6| Step: 7
Training loss: 0.5455947331426716
Validation loss: 2.6092406978803817

Epoch: 6| Step: 8
Training loss: 0.8986447302615237
Validation loss: 2.6261214479591284

Epoch: 6| Step: 9
Training loss: 0.7106739855333363
Validation loss: 2.5941706396755237

Epoch: 6| Step: 10
Training loss: 0.7766349282826606
Validation loss: 2.5837420222321192

Epoch: 6| Step: 11
Training loss: 0.796798964220067
Validation loss: 2.624621575946915

Epoch: 6| Step: 12
Training loss: 0.7075021345423118
Validation loss: 2.606541494264972

Epoch: 6| Step: 13
Training loss: 0.6699201177902087
Validation loss: 2.697778651611624

Epoch: 430| Step: 0
Training loss: 0.7757819507054049
Validation loss: 2.698716996147052

Epoch: 6| Step: 1
Training loss: 0.5871980966826887
Validation loss: 2.693068509144217

Epoch: 6| Step: 2
Training loss: 1.4248864279211009
Validation loss: 2.6768848380235264

Epoch: 6| Step: 3
Training loss: 0.5852670775964606
Validation loss: 2.6597014200333877

Epoch: 6| Step: 4
Training loss: 0.6724009562168436
Validation loss: 2.6076679927953075

Epoch: 6| Step: 5
Training loss: 0.6575231463923433
Validation loss: 2.6654390748011187

Epoch: 6| Step: 6
Training loss: 0.9939088982275597
Validation loss: 2.6707831488629177

Epoch: 6| Step: 7
Training loss: 0.8121250461169114
Validation loss: 2.637285261165732

Epoch: 6| Step: 8
Training loss: 0.6528677748693529
Validation loss: 2.639439694882909

Epoch: 6| Step: 9
Training loss: 0.8359000295636979
Validation loss: 2.6290454572576154

Epoch: 6| Step: 10
Training loss: 0.7665621024502806
Validation loss: 2.6412326331830647

Epoch: 6| Step: 11
Training loss: 0.5726513913144945
Validation loss: 2.637460230426557

Epoch: 6| Step: 12
Training loss: 0.7598662322050438
Validation loss: 2.5809682946354675

Epoch: 6| Step: 13
Training loss: 1.085101457589819
Validation loss: 2.640329423421938

Epoch: 431| Step: 0
Training loss: 0.6133903357806375
Validation loss: 2.6816664377532096

Epoch: 6| Step: 1
Training loss: 0.7531361179401743
Validation loss: 2.625736330089442

Epoch: 6| Step: 2
Training loss: 0.5337710866403285
Validation loss: 2.6371787943814806

Epoch: 6| Step: 3
Training loss: 0.9729984401560999
Validation loss: 2.585685786878281

Epoch: 6| Step: 4
Training loss: 0.504338337961458
Validation loss: 2.6470502522897017

Epoch: 6| Step: 5
Training loss: 0.8742984956943276
Validation loss: 2.6914262111091545

Epoch: 6| Step: 6
Training loss: 0.6291206894637276
Validation loss: 2.64986809396245

Epoch: 6| Step: 7
Training loss: 0.6159602167516649
Validation loss: 2.7150963389034235

Epoch: 6| Step: 8
Training loss: 0.9405614457569074
Validation loss: 2.618060369737304

Epoch: 6| Step: 9
Training loss: 0.8466324490543751
Validation loss: 2.6418736832988974

Epoch: 6| Step: 10
Training loss: 1.544577539702544
Validation loss: 2.6597996200530654

Epoch: 6| Step: 11
Training loss: 0.5912565276126341
Validation loss: 2.6383075966205265

Epoch: 6| Step: 12
Training loss: 0.5731906640262145
Validation loss: 2.622111835778449

Epoch: 6| Step: 13
Training loss: 1.128773295351185
Validation loss: 2.6398834601843117

Epoch: 432| Step: 0
Training loss: 0.524036491763196
Validation loss: 2.6574816671883283

Epoch: 6| Step: 1
Training loss: 0.749727199532111
Validation loss: 2.7215315303163927

Epoch: 6| Step: 2
Training loss: 1.262404028389067
Validation loss: 2.702656655724793

Epoch: 6| Step: 3
Training loss: 0.8183311876345264
Validation loss: 2.699318750997649

Epoch: 6| Step: 4
Training loss: 0.844280747095194
Validation loss: 2.6343544237834866

Epoch: 6| Step: 5
Training loss: 0.6165975092651045
Validation loss: 2.691750307427192

Epoch: 6| Step: 6
Training loss: 1.3945334725669438
Validation loss: 2.622632897024658

Epoch: 6| Step: 7
Training loss: 0.7604581917350572
Validation loss: 2.5420131968253967

Epoch: 6| Step: 8
Training loss: 0.9142446417981405
Validation loss: 2.6086617140186354

Epoch: 6| Step: 9
Training loss: 0.5695104315240284
Validation loss: 2.624498758446682

Epoch: 6| Step: 10
Training loss: 0.8491543658572588
Validation loss: 2.6204091754292085

Epoch: 6| Step: 11
Training loss: 0.7660871006495983
Validation loss: 2.6128163743900026

Epoch: 6| Step: 12
Training loss: 1.0441740693552741
Validation loss: 2.59332446548724

Epoch: 6| Step: 13
Training loss: 0.5022890028480114
Validation loss: 2.6327420837463964

Epoch: 433| Step: 0
Training loss: 0.7009341971412698
Validation loss: 2.6235258792230627

Epoch: 6| Step: 1
Training loss: 0.7330101803935242
Validation loss: 2.6100928105433074

Epoch: 6| Step: 2
Training loss: 0.9353984165464534
Validation loss: 2.5959154228305517

Epoch: 6| Step: 3
Training loss: 0.85351904687261
Validation loss: 2.5946252410903754

Epoch: 6| Step: 4
Training loss: 0.6400816404156952
Validation loss: 2.6332233836563232

Epoch: 6| Step: 5
Training loss: 0.6951416320018355
Validation loss: 2.672947108946974

Epoch: 6| Step: 6
Training loss: 0.8827035887387139
Validation loss: 2.6036428166251357

Epoch: 6| Step: 7
Training loss: 1.4181952177428403
Validation loss: 2.643144560463624

Epoch: 6| Step: 8
Training loss: 0.6713392206209778
Validation loss: 2.641108143263648

Epoch: 6| Step: 9
Training loss: 1.116503953228865
Validation loss: 2.592639578161404

Epoch: 6| Step: 10
Training loss: 0.6125260581098211
Validation loss: 2.588796642699263

Epoch: 6| Step: 11
Training loss: 0.839469648920156
Validation loss: 2.6663851490037134

Epoch: 6| Step: 12
Training loss: 0.6903864780917479
Validation loss: 2.617274541973179

Epoch: 6| Step: 13
Training loss: 0.7698716703213775
Validation loss: 2.598650733821925

Epoch: 434| Step: 0
Training loss: 0.8366723796629169
Validation loss: 2.583281752368793

Epoch: 6| Step: 1
Training loss: 0.6527458139692224
Validation loss: 2.598819420618032

Epoch: 6| Step: 2
Training loss: 0.4285513683006617
Validation loss: 2.601851316501999

Epoch: 6| Step: 3
Training loss: 1.0417122004411647
Validation loss: 2.620121024469369

Epoch: 6| Step: 4
Training loss: 0.7752098814502797
Validation loss: 2.6472131230172464

Epoch: 6| Step: 5
Training loss: 1.4831144903673066
Validation loss: 2.674958841951981

Epoch: 6| Step: 6
Training loss: 0.6325759445554249
Validation loss: 2.6595731255751125

Epoch: 6| Step: 7
Training loss: 0.5815498614283093
Validation loss: 2.6274768557801065

Epoch: 6| Step: 8
Training loss: 0.8554593090076397
Validation loss: 2.632045162379672

Epoch: 6| Step: 9
Training loss: 0.6929684678757705
Validation loss: 2.663423254558382

Epoch: 6| Step: 10
Training loss: 0.7687390892681173
Validation loss: 2.6662933838371856

Epoch: 6| Step: 11
Training loss: 0.7830279147164676
Validation loss: 2.6488929739471843

Epoch: 6| Step: 12
Training loss: 0.7155252761987965
Validation loss: 2.5892371555216163

Epoch: 6| Step: 13
Training loss: 1.067537483254085
Validation loss: 2.6258229373527144

Epoch: 435| Step: 0
Training loss: 0.8429647252903298
Validation loss: 2.6110441842418703

Epoch: 6| Step: 1
Training loss: 1.4072332123937474
Validation loss: 2.592434683663306

Epoch: 6| Step: 2
Training loss: 1.0350216184191965
Validation loss: 2.6055083493450515

Epoch: 6| Step: 3
Training loss: 0.6090594477256521
Validation loss: 2.6654314418818723

Epoch: 6| Step: 4
Training loss: 0.7918809090554174
Validation loss: 2.710905648373274

Epoch: 6| Step: 5
Training loss: 0.5651308366895567
Validation loss: 2.677958368958304

Epoch: 6| Step: 6
Training loss: 0.9306040501334039
Validation loss: 2.6283970604691578

Epoch: 6| Step: 7
Training loss: 0.43814335930160414
Validation loss: 2.6358739936081252

Epoch: 6| Step: 8
Training loss: 0.6764187314262551
Validation loss: 2.646284543008521

Epoch: 6| Step: 9
Training loss: 0.6134348877332804
Validation loss: 2.637940631838536

Epoch: 6| Step: 10
Training loss: 0.697588207519343
Validation loss: 2.6413790286494083

Epoch: 6| Step: 11
Training loss: 0.8085168626875144
Validation loss: 2.6429677799563986

Epoch: 6| Step: 12
Training loss: 1.1182710954504376
Validation loss: 2.603327720292504

Epoch: 6| Step: 13
Training loss: 0.7036131965377724
Validation loss: 2.63314420306591

Epoch: 436| Step: 0
Training loss: 0.8800580763617949
Validation loss: 2.6613065274436005

Epoch: 6| Step: 1
Training loss: 0.49807110895774676
Validation loss: 2.673163878341195

Epoch: 6| Step: 2
Training loss: 0.5706467367588489
Validation loss: 2.6019561439217553

Epoch: 6| Step: 3
Training loss: 0.9223225363945114
Validation loss: 2.6284541761169926

Epoch: 6| Step: 4
Training loss: 0.8364489051664376
Validation loss: 2.615330066406922

Epoch: 6| Step: 5
Training loss: 0.6188056593242245
Validation loss: 2.6372194318709945

Epoch: 6| Step: 6
Training loss: 0.6257400899202175
Validation loss: 2.660659062856987

Epoch: 6| Step: 7
Training loss: 0.6604069341028643
Validation loss: 2.639012056677557

Epoch: 6| Step: 8
Training loss: 1.0184514550244677
Validation loss: 2.6141521863340755

Epoch: 6| Step: 9
Training loss: 0.8602361352674043
Validation loss: 2.6248949574843063

Epoch: 6| Step: 10
Training loss: 0.7657354236302691
Validation loss: 2.582827615972534

Epoch: 6| Step: 11
Training loss: 0.48228077234222166
Validation loss: 2.5966962450601137

Epoch: 6| Step: 12
Training loss: 0.7929354881489012
Validation loss: 2.6451633886772403

Epoch: 6| Step: 13
Training loss: 1.3870335611107332
Validation loss: 2.6101482334525756

Epoch: 437| Step: 0
Training loss: 0.6184256242842607
Validation loss: 2.61227055322325

Epoch: 6| Step: 1
Training loss: 0.6167009584669642
Validation loss: 2.661694590215649

Epoch: 6| Step: 2
Training loss: 0.8358043671593602
Validation loss: 2.5818160097685547

Epoch: 6| Step: 3
Training loss: 0.7141675408564603
Validation loss: 2.582292240589525

Epoch: 6| Step: 4
Training loss: 0.992598651191845
Validation loss: 2.6071999139881537

Epoch: 6| Step: 5
Training loss: 0.7306454694636308
Validation loss: 2.6260060698474654

Epoch: 6| Step: 6
Training loss: 0.5533690835374954
Validation loss: 2.652600927155561

Epoch: 6| Step: 7
Training loss: 1.3223986424940495
Validation loss: 2.6163661142321404

Epoch: 6| Step: 8
Training loss: 1.1002260582730163
Validation loss: 2.565400722549736

Epoch: 6| Step: 9
Training loss: 0.5921610854002424
Validation loss: 2.6044047488417754

Epoch: 6| Step: 10
Training loss: 0.6140168024972998
Validation loss: 2.59971193894179

Epoch: 6| Step: 11
Training loss: 0.7848902769003869
Validation loss: 2.599553100679981

Epoch: 6| Step: 12
Training loss: 0.43603443859079727
Validation loss: 2.635464382619208

Epoch: 6| Step: 13
Training loss: 0.7318891291634925
Validation loss: 2.631739970517651

Epoch: 438| Step: 0
Training loss: 1.3511370391634014
Validation loss: 2.6403033871395043

Epoch: 6| Step: 1
Training loss: 0.7217337829385246
Validation loss: 2.651969797161875

Epoch: 6| Step: 2
Training loss: 0.7818255402604822
Validation loss: 2.6118168626728897

Epoch: 6| Step: 3
Training loss: 0.8594475455441537
Validation loss: 2.6188326395450185

Epoch: 6| Step: 4
Training loss: 1.152358543171731
Validation loss: 2.6211714147970766

Epoch: 6| Step: 5
Training loss: 0.7296801303270816
Validation loss: 2.6177582227631015

Epoch: 6| Step: 6
Training loss: 0.5187585577201457
Validation loss: 2.5960401283257357

Epoch: 6| Step: 7
Training loss: 0.7409903659245752
Validation loss: 2.653451365244959

Epoch: 6| Step: 8
Training loss: 0.8116289751856454
Validation loss: 2.6612185813777645

Epoch: 6| Step: 9
Training loss: 0.5642052340413813
Validation loss: 2.6055080367009333

Epoch: 6| Step: 10
Training loss: 0.9115351762622639
Validation loss: 2.622309895799067

Epoch: 6| Step: 11
Training loss: 0.7203316079871777
Validation loss: 2.644089977988922

Epoch: 6| Step: 12
Training loss: 0.5153698145244455
Validation loss: 2.650070857054403

Epoch: 6| Step: 13
Training loss: 0.5603325995836251
Validation loss: 2.6634260892252493

Epoch: 439| Step: 0
Training loss: 0.7486217471090446
Validation loss: 2.6460722767826126

Epoch: 6| Step: 1
Training loss: 1.05480532517852
Validation loss: 2.6573390747610577

Epoch: 6| Step: 2
Training loss: 0.5578312771839732
Validation loss: 2.703846520946564

Epoch: 6| Step: 3
Training loss: 0.4704280381845705
Validation loss: 2.625692367070853

Epoch: 6| Step: 4
Training loss: 0.7391103700776641
Validation loss: 2.605036389395095

Epoch: 6| Step: 5
Training loss: 1.0015599481368622
Validation loss: 2.613287567906519

Epoch: 6| Step: 6
Training loss: 1.450177310099751
Validation loss: 2.60246763626384

Epoch: 6| Step: 7
Training loss: 0.8546212932600578
Validation loss: 2.5555652972970946

Epoch: 6| Step: 8
Training loss: 0.9343695190677197
Validation loss: 2.648115695543579

Epoch: 6| Step: 9
Training loss: 0.8184552921722291
Validation loss: 2.6210582292995293

Epoch: 6| Step: 10
Training loss: 0.615131090970843
Validation loss: 2.613745465219201

Epoch: 6| Step: 11
Training loss: 0.4445854576325842
Validation loss: 2.6058906087831963

Epoch: 6| Step: 12
Training loss: 0.5830783002660795
Validation loss: 2.6168509954981327

Epoch: 6| Step: 13
Training loss: 0.6434130823987199
Validation loss: 2.601184806098424

Epoch: 440| Step: 0
Training loss: 0.7860455387551584
Validation loss: 2.6542108375391105

Epoch: 6| Step: 1
Training loss: 0.46096067855230555
Validation loss: 2.677745066889687

Epoch: 6| Step: 2
Training loss: 0.8535952323608822
Validation loss: 2.6414468603614347

Epoch: 6| Step: 3
Training loss: 0.989157819448583
Validation loss: 2.692095855965592

Epoch: 6| Step: 4
Training loss: 0.8270235474035186
Validation loss: 2.70537024067213

Epoch: 6| Step: 5
Training loss: 1.322457777117287
Validation loss: 2.7358505482112183

Epoch: 6| Step: 6
Training loss: 0.6604002778058475
Validation loss: 2.662323407389599

Epoch: 6| Step: 7
Training loss: 0.6969460147545862
Validation loss: 2.686381395551479

Epoch: 6| Step: 8
Training loss: 0.7871804027835609
Validation loss: 2.6379543093960716

Epoch: 6| Step: 9
Training loss: 0.46259005159614475
Validation loss: 2.6129750070905873

Epoch: 6| Step: 10
Training loss: 0.6204532463617155
Validation loss: 2.5958033710503794

Epoch: 6| Step: 11
Training loss: 0.8454660695699185
Validation loss: 2.6369078617801467

Epoch: 6| Step: 12
Training loss: 0.6346848891339303
Validation loss: 2.6398970072577503

Epoch: 6| Step: 13
Training loss: 0.8726062046546509
Validation loss: 2.717573137723349

Epoch: 441| Step: 0
Training loss: 0.8778816863485279
Validation loss: 2.6714189076934907

Epoch: 6| Step: 1
Training loss: 0.6859250669286705
Validation loss: 2.693132397864382

Epoch: 6| Step: 2
Training loss: 0.7382883545871782
Validation loss: 2.7058599597696595

Epoch: 6| Step: 3
Training loss: 0.6187313423811661
Validation loss: 2.6910402725529945

Epoch: 6| Step: 4
Training loss: 0.8728567168074418
Validation loss: 2.732376865382545

Epoch: 6| Step: 5
Training loss: 0.5307641331987114
Validation loss: 2.692014606080526

Epoch: 6| Step: 6
Training loss: 0.7089316188215529
Validation loss: 2.7433912889964542

Epoch: 6| Step: 7
Training loss: 0.6448294903246369
Validation loss: 2.6827649683473287

Epoch: 6| Step: 8
Training loss: 0.7852501125123078
Validation loss: 2.703551793445584

Epoch: 6| Step: 9
Training loss: 0.5563218123982222
Validation loss: 2.6350535166431293

Epoch: 6| Step: 10
Training loss: 1.3561266091465798
Validation loss: 2.6575686155057627

Epoch: 6| Step: 11
Training loss: 0.9411882963384259
Validation loss: 2.6588410848257746

Epoch: 6| Step: 12
Training loss: 0.9934100331279992
Validation loss: 2.680160910676963

Epoch: 6| Step: 13
Training loss: 0.5567217851331759
Validation loss: 2.595216864856927

Epoch: 442| Step: 0
Training loss: 0.9950019986884971
Validation loss: 2.667420598582005

Epoch: 6| Step: 1
Training loss: 0.7751650157725798
Validation loss: 2.6588240922851636

Epoch: 6| Step: 2
Training loss: 0.9117868903029079
Validation loss: 2.6507204132189393

Epoch: 6| Step: 3
Training loss: 0.6153469406571375
Validation loss: 2.6297788716318014

Epoch: 6| Step: 4
Training loss: 0.7230047262097974
Validation loss: 2.6585896229943127

Epoch: 6| Step: 5
Training loss: 0.7003580114512499
Validation loss: 2.7090818740105607

Epoch: 6| Step: 6
Training loss: 0.776835980221846
Validation loss: 2.6367247932270637

Epoch: 6| Step: 7
Training loss: 0.5714514085983097
Validation loss: 2.7018100796436695

Epoch: 6| Step: 8
Training loss: 1.2860512443287595
Validation loss: 2.614736914715059

Epoch: 6| Step: 9
Training loss: 0.6608006870083782
Validation loss: 2.6616818408219016

Epoch: 6| Step: 10
Training loss: 0.4550238155325891
Validation loss: 2.67586536136049

Epoch: 6| Step: 11
Training loss: 0.5880153688413959
Validation loss: 2.581876179727103

Epoch: 6| Step: 12
Training loss: 0.46300884942193127
Validation loss: 2.650855342010527

Epoch: 6| Step: 13
Training loss: 1.3731435033621961
Validation loss: 2.602329801600132

Epoch: 443| Step: 0
Training loss: 0.8623450886473553
Validation loss: 2.661659312762582

Epoch: 6| Step: 1
Training loss: 0.7366257933530317
Validation loss: 2.6943383119486715

Epoch: 6| Step: 2
Training loss: 0.5883366613140844
Validation loss: 2.637647345647099

Epoch: 6| Step: 3
Training loss: 0.7883118562077999
Validation loss: 2.6368525266266074

Epoch: 6| Step: 4
Training loss: 0.9134456476767586
Validation loss: 2.635263858230004

Epoch: 6| Step: 5
Training loss: 1.0470618465560215
Validation loss: 2.6836377639529747

Epoch: 6| Step: 6
Training loss: 0.9097910791081747
Validation loss: 2.6650618751027566

Epoch: 6| Step: 7
Training loss: 0.6289305593400851
Validation loss: 2.7109598897253058

Epoch: 6| Step: 8
Training loss: 0.6178606442731056
Validation loss: 2.6471025821709078

Epoch: 6| Step: 9
Training loss: 0.8101329435934072
Validation loss: 2.6631067823306025

Epoch: 6| Step: 10
Training loss: 0.7446916597532693
Validation loss: 2.6303339006017827

Epoch: 6| Step: 11
Training loss: 0.9152778305828084
Validation loss: 2.565351125121461

Epoch: 6| Step: 12
Training loss: 1.3502785201102152
Validation loss: 2.602075703724003

Epoch: 6| Step: 13
Training loss: 0.670316307572797
Validation loss: 2.6898912688382786

Epoch: 444| Step: 0
Training loss: 0.7146353913039291
Validation loss: 2.72800265427849

Epoch: 6| Step: 1
Training loss: 0.986701879409975
Validation loss: 2.656459643000863

Epoch: 6| Step: 2
Training loss: 0.9848232762349414
Validation loss: 2.6606457708454703

Epoch: 6| Step: 3
Training loss: 0.6027664670478763
Validation loss: 2.651824990330744

Epoch: 6| Step: 4
Training loss: 0.8863688379304043
Validation loss: 2.648089900879203

Epoch: 6| Step: 5
Training loss: 0.6202720148437914
Validation loss: 2.6237538573909305

Epoch: 6| Step: 6
Training loss: 1.3243292028223648
Validation loss: 2.659394919428802

Epoch: 6| Step: 7
Training loss: 0.4833801111928189
Validation loss: 2.631914885686822

Epoch: 6| Step: 8
Training loss: 0.6332057155059595
Validation loss: 2.626129195133993

Epoch: 6| Step: 9
Training loss: 0.5112987862512696
Validation loss: 2.716656927859709

Epoch: 6| Step: 10
Training loss: 0.7438367087845824
Validation loss: 2.693085034778352

Epoch: 6| Step: 11
Training loss: 1.149883112979454
Validation loss: 2.6820881195365422

Epoch: 6| Step: 12
Training loss: 0.5941210641343345
Validation loss: 2.6654029822305123

Epoch: 6| Step: 13
Training loss: 1.091145274936773
Validation loss: 2.6189720939711894

Epoch: 445| Step: 0
Training loss: 0.3663639613557674
Validation loss: 2.6504860816057123

Epoch: 6| Step: 1
Training loss: 0.9969777392118534
Validation loss: 2.6844606586448023

Epoch: 6| Step: 2
Training loss: 1.2731042905760814
Validation loss: 2.630774685658399

Epoch: 6| Step: 3
Training loss: 0.7533792027150047
Validation loss: 2.657871200388731

Epoch: 6| Step: 4
Training loss: 0.7645200424261624
Validation loss: 2.6936895229457365

Epoch: 6| Step: 5
Training loss: 0.7044300683334952
Validation loss: 2.689699559220708

Epoch: 6| Step: 6
Training loss: 0.6248209219919484
Validation loss: 2.645767591565804

Epoch: 6| Step: 7
Training loss: 0.6057057562841885
Validation loss: 2.662454069215996

Epoch: 6| Step: 8
Training loss: 0.9274807874535345
Validation loss: 2.555627095964915

Epoch: 6| Step: 9
Training loss: 0.4627037314876456
Validation loss: 2.6149589653758563

Epoch: 6| Step: 10
Training loss: 0.7675948590111934
Validation loss: 2.613747122331395

Epoch: 6| Step: 11
Training loss: 1.0151936715550294
Validation loss: 2.6090598610877476

Epoch: 6| Step: 12
Training loss: 0.5949569281046685
Validation loss: 2.6743375350064564

Epoch: 6| Step: 13
Training loss: 0.6120974297931183
Validation loss: 2.6491632958033033

Epoch: 446| Step: 0
Training loss: 0.7920806120441639
Validation loss: 2.684306191275636

Epoch: 6| Step: 1
Training loss: 0.8296894195591907
Validation loss: 2.634749683721195

Epoch: 6| Step: 2
Training loss: 1.0153334565963053
Validation loss: 2.612342137338648

Epoch: 6| Step: 3
Training loss: 0.5343952755121012
Validation loss: 2.622020392768522

Epoch: 6| Step: 4
Training loss: 0.7310945818464842
Validation loss: 2.6460551722083046

Epoch: 6| Step: 5
Training loss: 0.42624355730797936
Validation loss: 2.596940005422598

Epoch: 6| Step: 6
Training loss: 0.6216160719211389
Validation loss: 2.659686016658596

Epoch: 6| Step: 7
Training loss: 0.9579028461903446
Validation loss: 2.6037221503756136

Epoch: 6| Step: 8
Training loss: 0.6753515740793459
Validation loss: 2.703405244445455

Epoch: 6| Step: 9
Training loss: 0.5969424004971174
Validation loss: 2.6626732001287348

Epoch: 6| Step: 10
Training loss: 1.4362208438633008
Validation loss: 2.6851124767042625

Epoch: 6| Step: 11
Training loss: 0.650721216810173
Validation loss: 2.6923711529962295

Epoch: 6| Step: 12
Training loss: 0.6579075724202917
Validation loss: 2.7428870110432424

Epoch: 6| Step: 13
Training loss: 0.6627969238379074
Validation loss: 2.753547778595531

Epoch: 447| Step: 0
Training loss: 0.8796035035382346
Validation loss: 2.7065933115497747

Epoch: 6| Step: 1
Training loss: 0.7309759490496177
Validation loss: 2.7334848026625136

Epoch: 6| Step: 2
Training loss: 0.5242439150277461
Validation loss: 2.675443901830772

Epoch: 6| Step: 3
Training loss: 0.4225847137891012
Validation loss: 2.6484338991033782

Epoch: 6| Step: 4
Training loss: 1.5141395289428579
Validation loss: 2.670646236212344

Epoch: 6| Step: 5
Training loss: 0.5656663468565493
Validation loss: 2.655628700149028

Epoch: 6| Step: 6
Training loss: 0.6166892877716939
Validation loss: 2.6983886855701655

Epoch: 6| Step: 7
Training loss: 0.7298401764749742
Validation loss: 2.678352164119411

Epoch: 6| Step: 8
Training loss: 0.6949279879236279
Validation loss: 2.679460491800533

Epoch: 6| Step: 9
Training loss: 0.8437143247621062
Validation loss: 2.6451644101932343

Epoch: 6| Step: 10
Training loss: 0.6557000898883869
Validation loss: 2.6832595905888534

Epoch: 6| Step: 11
Training loss: 0.45518220685389943
Validation loss: 2.7035183849999496

Epoch: 6| Step: 12
Training loss: 0.9331526412498067
Validation loss: 2.6778370480245637

Epoch: 6| Step: 13
Training loss: 0.4623857634168949
Validation loss: 2.6886689283207126

Epoch: 448| Step: 0
Training loss: 0.36089364813417757
Validation loss: 2.723804875580108

Epoch: 6| Step: 1
Training loss: 0.8436622574006603
Validation loss: 2.6808179986017318

Epoch: 6| Step: 2
Training loss: 0.6247293840100243
Validation loss: 2.7209568932261536

Epoch: 6| Step: 3
Training loss: 1.5567551861467257
Validation loss: 2.586381933584653

Epoch: 6| Step: 4
Training loss: 0.9516353848611122
Validation loss: 2.7256058523976106

Epoch: 6| Step: 5
Training loss: 0.6779423375379563
Validation loss: 2.637778423854331

Epoch: 6| Step: 6
Training loss: 0.8720809064437359
Validation loss: 2.647902450603398

Epoch: 6| Step: 7
Training loss: 0.7501172133087518
Validation loss: 2.7028858027532006

Epoch: 6| Step: 8
Training loss: 0.8582130205836666
Validation loss: 2.640410871683481

Epoch: 6| Step: 9
Training loss: 0.5123492426227367
Validation loss: 2.6662370713223478

Epoch: 6| Step: 10
Training loss: 0.5474089604287942
Validation loss: 2.6180337173625925

Epoch: 6| Step: 11
Training loss: 0.4577186175744855
Validation loss: 2.7304290637623527

Epoch: 6| Step: 12
Training loss: 0.815945399409392
Validation loss: 2.6477340919425667

Epoch: 6| Step: 13
Training loss: 0.8270429343503208
Validation loss: 2.669781435379942

Epoch: 449| Step: 0
Training loss: 0.5733822289213454
Validation loss: 2.689763631374436

Epoch: 6| Step: 1
Training loss: 1.0802170179576487
Validation loss: 2.7665158720937186

Epoch: 6| Step: 2
Training loss: 0.7156318947405775
Validation loss: 2.7200720192687076

Epoch: 6| Step: 3
Training loss: 0.49160271675904915
Validation loss: 2.6845683438620087

Epoch: 6| Step: 4
Training loss: 0.6347681133514929
Validation loss: 2.700206084686921

Epoch: 6| Step: 5
Training loss: 0.9068964264097986
Validation loss: 2.641449553134636

Epoch: 6| Step: 6
Training loss: 0.5765656241148792
Validation loss: 2.682298031895069

Epoch: 6| Step: 7
Training loss: 0.7321267716039683
Validation loss: 2.6146427821560327

Epoch: 6| Step: 8
Training loss: 1.269340852985294
Validation loss: 2.6120120370051043

Epoch: 6| Step: 9
Training loss: 0.9480341674305107
Validation loss: 2.681556457695286

Epoch: 6| Step: 10
Training loss: 0.7011654994324088
Validation loss: 2.6823505259355107

Epoch: 6| Step: 11
Training loss: 0.4576763425813898
Validation loss: 2.644848953313767

Epoch: 6| Step: 12
Training loss: 0.6255507903240347
Validation loss: 2.716917772526075

Epoch: 6| Step: 13
Training loss: 0.8904008081249981
Validation loss: 2.659750632545742

Epoch: 450| Step: 0
Training loss: 0.5960610236987303
Validation loss: 2.7207933544670375

Epoch: 6| Step: 1
Training loss: 0.7479318475555102
Validation loss: 2.693488759931989

Epoch: 6| Step: 2
Training loss: 0.698083478056536
Validation loss: 2.7137961728950115

Epoch: 6| Step: 3
Training loss: 1.3145705648165875
Validation loss: 2.6504168620412085

Epoch: 6| Step: 4
Training loss: 0.4741253366486742
Validation loss: 2.70229184903258

Epoch: 6| Step: 5
Training loss: 0.7504249402073218
Validation loss: 2.6225939426136216

Epoch: 6| Step: 6
Training loss: 0.27031056067151427
Validation loss: 2.622024226952813

Epoch: 6| Step: 7
Training loss: 0.9139413997929814
Validation loss: 2.6997418556904176

Epoch: 6| Step: 8
Training loss: 0.8522083038487737
Validation loss: 2.6564994694863437

Epoch: 6| Step: 9
Training loss: 0.6803274978155043
Validation loss: 2.6938685285626125

Epoch: 6| Step: 10
Training loss: 1.029277765143702
Validation loss: 2.679274635650886

Epoch: 6| Step: 11
Training loss: 0.5615277895551457
Validation loss: 2.6995562477203388

Epoch: 6| Step: 12
Training loss: 0.8050427809892279
Validation loss: 2.72645810573209

Epoch: 6| Step: 13
Training loss: 0.4412721413306516
Validation loss: 2.7229722367336575

Epoch: 451| Step: 0
Training loss: 0.510748139268321
Validation loss: 2.685294466121266

Epoch: 6| Step: 1
Training loss: 0.7663410497340243
Validation loss: 2.687908496417526

Epoch: 6| Step: 2
Training loss: 0.5248637056545952
Validation loss: 2.656837966769729

Epoch: 6| Step: 3
Training loss: 0.8449527503803785
Validation loss: 2.6813592172710985

Epoch: 6| Step: 4
Training loss: 1.3488541738390478
Validation loss: 2.657143894953215

Epoch: 6| Step: 5
Training loss: 0.5750451920206432
Validation loss: 2.7304709620505467

Epoch: 6| Step: 6
Training loss: 0.9775295809687059
Validation loss: 2.605923865973729

Epoch: 6| Step: 7
Training loss: 0.5514698458647873
Validation loss: 2.6179756458160917

Epoch: 6| Step: 8
Training loss: 0.5269825015917965
Validation loss: 2.680805340155232

Epoch: 6| Step: 9
Training loss: 0.8694371435578612
Validation loss: 2.709112426987726

Epoch: 6| Step: 10
Training loss: 0.5651822248653721
Validation loss: 2.7173425970549774

Epoch: 6| Step: 11
Training loss: 0.5682859340555445
Validation loss: 2.629616462411385

Epoch: 6| Step: 12
Training loss: 0.609461875982775
Validation loss: 2.7031519011994596

Epoch: 6| Step: 13
Training loss: 1.057724374004937
Validation loss: 2.6555399974285665

Epoch: 452| Step: 0
Training loss: 0.7732121303003487
Validation loss: 2.7105578798945773

Epoch: 6| Step: 1
Training loss: 0.5138014133279502
Validation loss: 2.649948649238792

Epoch: 6| Step: 2
Training loss: 0.5833336001350156
Validation loss: 2.6632063935990047

Epoch: 6| Step: 3
Training loss: 0.5064299028305317
Validation loss: 2.6855142265416014

Epoch: 6| Step: 4
Training loss: 0.8439569572664141
Validation loss: 2.6761680453403973

Epoch: 6| Step: 5
Training loss: 0.6912151438942677
Validation loss: 2.593775584389617

Epoch: 6| Step: 6
Training loss: 1.0285831416216242
Validation loss: 2.646764431219963

Epoch: 6| Step: 7
Training loss: 0.38296892901524965
Validation loss: 2.626765293369083

Epoch: 6| Step: 8
Training loss: 0.9150538489125145
Validation loss: 2.6696804023942144

Epoch: 6| Step: 9
Training loss: 0.7606706108140898
Validation loss: 2.6415232197255283

Epoch: 6| Step: 10
Training loss: 1.350499479294429
Validation loss: 2.6453465942661216

Epoch: 6| Step: 11
Training loss: 0.5151148208375188
Validation loss: 2.6666768615249623

Epoch: 6| Step: 12
Training loss: 0.5870012926220675
Validation loss: 2.6677531075633327

Epoch: 6| Step: 13
Training loss: 0.7073425113641011
Validation loss: 2.62525119790597

Epoch: 453| Step: 0
Training loss: 0.5898566339361457
Validation loss: 2.662702591819255

Epoch: 6| Step: 1
Training loss: 0.7767175040026908
Validation loss: 2.6633196976336095

Epoch: 6| Step: 2
Training loss: 0.4220990186653216
Validation loss: 2.669818599910873

Epoch: 6| Step: 3
Training loss: 0.44865136180855086
Validation loss: 2.6581450191353575

Epoch: 6| Step: 4
Training loss: 0.6652015789950286
Validation loss: 2.6509390450771053

Epoch: 6| Step: 5
Training loss: 0.6707104637530987
Validation loss: 2.612324804305817

Epoch: 6| Step: 6
Training loss: 0.7382802811873603
Validation loss: 2.627785612457116

Epoch: 6| Step: 7
Training loss: 0.8283146335197552
Validation loss: 2.60261363196406

Epoch: 6| Step: 8
Training loss: 0.6903074552905148
Validation loss: 2.6763930018213626

Epoch: 6| Step: 9
Training loss: 1.4108420102069872
Validation loss: 2.658118514546306

Epoch: 6| Step: 10
Training loss: 0.7059274983636877
Validation loss: 2.6378321653923362

Epoch: 6| Step: 11
Training loss: 0.8775910773654793
Validation loss: 2.650909118236595

Epoch: 6| Step: 12
Training loss: 0.6961722469917462
Validation loss: 2.655341063921178

Epoch: 6| Step: 13
Training loss: 1.116189898061502
Validation loss: 2.658834643514894

Epoch: 454| Step: 0
Training loss: 0.9823234311601345
Validation loss: 2.6452188804600265

Epoch: 6| Step: 1
Training loss: 0.2850794754142693
Validation loss: 2.6506668355444094

Epoch: 6| Step: 2
Training loss: 0.7106570854089842
Validation loss: 2.6578123546781955

Epoch: 6| Step: 3
Training loss: 0.7865876771446108
Validation loss: 2.6820354944260916

Epoch: 6| Step: 4
Training loss: 0.6405898293865973
Validation loss: 2.6698182873559015

Epoch: 6| Step: 5
Training loss: 0.8160246180672922
Validation loss: 2.73436793735137

Epoch: 6| Step: 6
Training loss: 1.281948224993516
Validation loss: 2.696110261807414

Epoch: 6| Step: 7
Training loss: 0.6700900564591384
Validation loss: 2.657210860649354

Epoch: 6| Step: 8
Training loss: 0.7943207063286283
Validation loss: 2.655160927502105

Epoch: 6| Step: 9
Training loss: 0.6536967699688584
Validation loss: 2.6560504539185406

Epoch: 6| Step: 10
Training loss: 0.9273934792069511
Validation loss: 2.6546064340878317

Epoch: 6| Step: 11
Training loss: 1.051416765064909
Validation loss: 2.6348455109207967

Epoch: 6| Step: 12
Training loss: 0.6296426951178897
Validation loss: 2.6411849412008044

Epoch: 6| Step: 13
Training loss: 0.6359579303280888
Validation loss: 2.673963552147162

Epoch: 455| Step: 0
Training loss: 0.8769843217020299
Validation loss: 2.721052035606058

Epoch: 6| Step: 1
Training loss: 1.3283312469108657
Validation loss: 2.643782043262843

Epoch: 6| Step: 2
Training loss: 0.6361992946198123
Validation loss: 2.6937551818467385

Epoch: 6| Step: 3
Training loss: 0.4267153162278562
Validation loss: 2.6511628148864763

Epoch: 6| Step: 4
Training loss: 0.944476238507182
Validation loss: 2.6091227913985766

Epoch: 6| Step: 5
Training loss: 0.7168195757272627
Validation loss: 2.6280205695669654

Epoch: 6| Step: 6
Training loss: 0.6047439913520185
Validation loss: 2.663279876156586

Epoch: 6| Step: 7
Training loss: 0.47476032195739765
Validation loss: 2.6973120749615305

Epoch: 6| Step: 8
Training loss: 0.8532485369433096
Validation loss: 2.683891194761365

Epoch: 6| Step: 9
Training loss: 0.7618606826400793
Validation loss: 2.639612293360533

Epoch: 6| Step: 10
Training loss: 0.6566866375779621
Validation loss: 2.6666366058880504

Epoch: 6| Step: 11
Training loss: 0.646750726602837
Validation loss: 2.7160874333356024

Epoch: 6| Step: 12
Training loss: 0.763206242416252
Validation loss: 2.6209506560984277

Epoch: 6| Step: 13
Training loss: 0.5453062445164267
Validation loss: 2.601284329164777

Epoch: 456| Step: 0
Training loss: 0.8084425854016095
Validation loss: 2.674438837794173

Epoch: 6| Step: 1
Training loss: 0.31730007560409285
Validation loss: 2.5832439273826964

Epoch: 6| Step: 2
Training loss: 0.6387276348072958
Validation loss: 2.626802030280955

Epoch: 6| Step: 3
Training loss: 0.6918294010453421
Validation loss: 2.646831524404441

Epoch: 6| Step: 4
Training loss: 0.8900394857412726
Validation loss: 2.6297227064961666

Epoch: 6| Step: 5
Training loss: 0.6794121721726437
Validation loss: 2.618379797673964

Epoch: 6| Step: 6
Training loss: 0.5921052941104814
Validation loss: 2.6459837192439157

Epoch: 6| Step: 7
Training loss: 0.3822689089467383
Validation loss: 2.6044958033785126

Epoch: 6| Step: 8
Training loss: 1.5089644543080643
Validation loss: 2.6691255086400694

Epoch: 6| Step: 9
Training loss: 0.6469179986861973
Validation loss: 2.6855551017866417

Epoch: 6| Step: 10
Training loss: 0.7261917645058085
Validation loss: 2.6936150259616056

Epoch: 6| Step: 11
Training loss: 0.6469495776396706
Validation loss: 2.724914810762248

Epoch: 6| Step: 12
Training loss: 0.918877237293611
Validation loss: 2.7198393966672985

Epoch: 6| Step: 13
Training loss: 0.8685672540358202
Validation loss: 2.658103445829617

Epoch: 457| Step: 0
Training loss: 1.247788857786089
Validation loss: 2.6862184440850396

Epoch: 6| Step: 1
Training loss: 0.5334306448086468
Validation loss: 2.673337866841925

Epoch: 6| Step: 2
Training loss: 0.4840865506870635
Validation loss: 2.6925264859114377

Epoch: 6| Step: 3
Training loss: 0.8136822828487019
Validation loss: 2.718163642646626

Epoch: 6| Step: 4
Training loss: 0.7332693664511254
Validation loss: 2.6669390410160267

Epoch: 6| Step: 5
Training loss: 0.5331255119204998
Validation loss: 2.726999125821018

Epoch: 6| Step: 6
Training loss: 0.5962501890554068
Validation loss: 2.689367872413849

Epoch: 6| Step: 7
Training loss: 0.6555825426811254
Validation loss: 2.7206811586813653

Epoch: 6| Step: 8
Training loss: 0.7504831188572854
Validation loss: 2.735753567458773

Epoch: 6| Step: 9
Training loss: 0.6305871618316057
Validation loss: 2.6975871784593326

Epoch: 6| Step: 10
Training loss: 0.5491622233705499
Validation loss: 2.728893504170786

Epoch: 6| Step: 11
Training loss: 0.49767022944148354
Validation loss: 2.66913925714996

Epoch: 6| Step: 12
Training loss: 0.7860046661374341
Validation loss: 2.70152751487376

Epoch: 6| Step: 13
Training loss: 1.0618015686474809
Validation loss: 2.6694047897345055

Epoch: 458| Step: 0
Training loss: 0.667211851082095
Validation loss: 2.6797597373071116

Epoch: 6| Step: 1
Training loss: 0.5387122633566898
Validation loss: 2.65891606292764

Epoch: 6| Step: 2
Training loss: 0.5746459669213432
Validation loss: 2.7050692084173518

Epoch: 6| Step: 3
Training loss: 1.228989065669486
Validation loss: 2.661150387580534

Epoch: 6| Step: 4
Training loss: 0.6646176878401524
Validation loss: 2.7394950523705437

Epoch: 6| Step: 5
Training loss: 0.7559623155309392
Validation loss: 2.7183530378845666

Epoch: 6| Step: 6
Training loss: 0.6890405387579303
Validation loss: 2.7316025256931153

Epoch: 6| Step: 7
Training loss: 0.8092327081213426
Validation loss: 2.6680465992209013

Epoch: 6| Step: 8
Training loss: 0.5960450738753698
Validation loss: 2.627147991605876

Epoch: 6| Step: 9
Training loss: 0.5996034106228195
Validation loss: 2.6640979246168937

Epoch: 6| Step: 10
Training loss: 0.7415110667734649
Validation loss: 2.6728532127010114

Epoch: 6| Step: 11
Training loss: 1.275438012824416
Validation loss: 2.655625019224614

Epoch: 6| Step: 12
Training loss: 0.8392395685142505
Validation loss: 2.62543922867066

Epoch: 6| Step: 13
Training loss: 0.6921065496293808
Validation loss: 2.6696739574673694

Epoch: 459| Step: 0
Training loss: 0.42670452562144395
Validation loss: 2.760780905438691

Epoch: 6| Step: 1
Training loss: 0.7917742446955072
Validation loss: 2.7017042068079133

Epoch: 6| Step: 2
Training loss: 0.7875148211704208
Validation loss: 2.7101864172806183

Epoch: 6| Step: 3
Training loss: 0.6654082182569044
Validation loss: 2.7095455660107346

Epoch: 6| Step: 4
Training loss: 0.7396794556670648
Validation loss: 2.6388307152297847

Epoch: 6| Step: 5
Training loss: 0.5246881376152412
Validation loss: 2.674262536080755

Epoch: 6| Step: 6
Training loss: 0.5428416425824248
Validation loss: 2.656376861833932

Epoch: 6| Step: 7
Training loss: 0.6989482590867958
Validation loss: 2.694732898552549

Epoch: 6| Step: 8
Training loss: 1.1555050692676123
Validation loss: 2.6445611964248332

Epoch: 6| Step: 9
Training loss: 0.5305010340534023
Validation loss: 2.657660689401725

Epoch: 6| Step: 10
Training loss: 0.9224205019535092
Validation loss: 2.636821264464028

Epoch: 6| Step: 11
Training loss: 0.6591332991490099
Validation loss: 2.6832803379377825

Epoch: 6| Step: 12
Training loss: 0.6308521943525162
Validation loss: 2.661821005957988

Epoch: 6| Step: 13
Training loss: 0.9887322162133247
Validation loss: 2.7278132152348853

Epoch: 460| Step: 0
Training loss: 0.5833531160633176
Validation loss: 2.664360514479211

Epoch: 6| Step: 1
Training loss: 0.7995845132977749
Validation loss: 2.725570469093326

Epoch: 6| Step: 2
Training loss: 1.0415448816951323
Validation loss: 2.7262090911197974

Epoch: 6| Step: 3
Training loss: 0.6279001421822382
Validation loss: 2.703102391025316

Epoch: 6| Step: 4
Training loss: 0.7791777785081753
Validation loss: 2.636108493591481

Epoch: 6| Step: 5
Training loss: 1.0730213496918555
Validation loss: 2.6414830771789948

Epoch: 6| Step: 6
Training loss: 0.6665582320322141
Validation loss: 2.7026252799178283

Epoch: 6| Step: 7
Training loss: 0.644901978193323
Validation loss: 2.658913507400271

Epoch: 6| Step: 8
Training loss: 0.47877078357334024
Validation loss: 2.6217451049006257

Epoch: 6| Step: 9
Training loss: 0.5650397291815761
Validation loss: 2.670890686284266

Epoch: 6| Step: 10
Training loss: 0.4971338167825902
Validation loss: 2.6705020849889594

Epoch: 6| Step: 11
Training loss: 0.6291029249411618
Validation loss: 2.6241953237096847

Epoch: 6| Step: 12
Training loss: 0.5210786019429768
Validation loss: 2.6302363982764896

Epoch: 6| Step: 13
Training loss: 0.690841789224532
Validation loss: 2.651076405915267

Epoch: 461| Step: 0
Training loss: 0.6323481139156651
Validation loss: 2.6324734870442565

Epoch: 6| Step: 1
Training loss: 0.876236994887637
Validation loss: 2.6637631245311697

Epoch: 6| Step: 2
Training loss: 0.6421907874995451
Validation loss: 2.690941543951139

Epoch: 6| Step: 3
Training loss: 0.5600580616210964
Validation loss: 2.665969717820565

Epoch: 6| Step: 4
Training loss: 0.49877429274384166
Validation loss: 2.6941397432924368

Epoch: 6| Step: 5
Training loss: 1.0043570252325171
Validation loss: 2.6368488797701466

Epoch: 6| Step: 6
Training loss: 0.8916113895739586
Validation loss: 2.615506899410913

Epoch: 6| Step: 7
Training loss: 0.46816582836570847
Validation loss: 2.6779939955515135

Epoch: 6| Step: 8
Training loss: 0.675086066269186
Validation loss: 2.6340319849484604

Epoch: 6| Step: 9
Training loss: 0.8756945782395039
Validation loss: 2.6448556690702834

Epoch: 6| Step: 10
Training loss: 0.8063202376414647
Validation loss: 2.6391782841749443

Epoch: 6| Step: 11
Training loss: 0.9042334318048482
Validation loss: 2.624237676463083

Epoch: 6| Step: 12
Training loss: 0.7949630014339247
Validation loss: 2.625313709829226

Epoch: 6| Step: 13
Training loss: 0.6995812866774751
Validation loss: 2.622719955238795

Epoch: 462| Step: 0
Training loss: 0.7509997380404771
Validation loss: 2.7064592235055622

Epoch: 6| Step: 1
Training loss: 0.6205533153550798
Validation loss: 2.6895503864786905

Epoch: 6| Step: 2
Training loss: 1.063828087079942
Validation loss: 2.655234842229195

Epoch: 6| Step: 3
Training loss: 0.7653463985588403
Validation loss: 2.661804002583961

Epoch: 6| Step: 4
Training loss: 1.0351117394432543
Validation loss: 2.6808124401577604

Epoch: 6| Step: 5
Training loss: 0.515295038708182
Validation loss: 2.701605661995026

Epoch: 6| Step: 6
Training loss: 0.7922994109490875
Validation loss: 2.6868074101325288

Epoch: 6| Step: 7
Training loss: 0.81841865998527
Validation loss: 2.7355924384730166

Epoch: 6| Step: 8
Training loss: 0.48691743741661875
Validation loss: 2.68445928202231

Epoch: 6| Step: 9
Training loss: 0.6615412702654342
Validation loss: 2.6662160572169302

Epoch: 6| Step: 10
Training loss: 0.9280648696892795
Validation loss: 2.6433687044842187

Epoch: 6| Step: 11
Training loss: 0.723534334099635
Validation loss: 2.698723769267324

Epoch: 6| Step: 12
Training loss: 0.7144192962396373
Validation loss: 2.6383758386387797

Epoch: 6| Step: 13
Training loss: 0.6570383060180767
Validation loss: 2.694803892053084

Epoch: 463| Step: 0
Training loss: 0.819557423714584
Validation loss: 2.6697187441778065

Epoch: 6| Step: 1
Training loss: 0.9956887712188569
Validation loss: 2.7389998497537547

Epoch: 6| Step: 2
Training loss: 0.9475218750735948
Validation loss: 2.7337271803985064

Epoch: 6| Step: 3
Training loss: 0.5720165348530798
Validation loss: 2.6655917136889355

Epoch: 6| Step: 4
Training loss: 0.5784864584443222
Validation loss: 2.683693844604976

Epoch: 6| Step: 5
Training loss: 0.8031218769888514
Validation loss: 2.6746646528296654

Epoch: 6| Step: 6
Training loss: 0.4858986670380605
Validation loss: 2.6759021295498693

Epoch: 6| Step: 7
Training loss: 0.5407339526514391
Validation loss: 2.7024005367432853

Epoch: 6| Step: 8
Training loss: 0.476241676027539
Validation loss: 2.6438696074427854

Epoch: 6| Step: 9
Training loss: 0.5256155163774634
Validation loss: 2.7056073383786727

Epoch: 6| Step: 10
Training loss: 0.6596462830678718
Validation loss: 2.7184375568791426

Epoch: 6| Step: 11
Training loss: 0.7889019642300015
Validation loss: 2.7323326112619735

Epoch: 6| Step: 12
Training loss: 1.3090143694923113
Validation loss: 2.684893305000622

Epoch: 6| Step: 13
Training loss: 0.5199172228254664
Validation loss: 2.725536732791592

Epoch: 464| Step: 0
Training loss: 0.6419477298245704
Validation loss: 2.689114344509183

Epoch: 6| Step: 1
Training loss: 0.567619497598887
Validation loss: 2.7139079651497813

Epoch: 6| Step: 2
Training loss: 0.5883393966895482
Validation loss: 2.7108371067421517

Epoch: 6| Step: 3
Training loss: 0.838856991227414
Validation loss: 2.7118705441064

Epoch: 6| Step: 4
Training loss: 0.6100342436856194
Validation loss: 2.7457029988022064

Epoch: 6| Step: 5
Training loss: 0.6598961673325253
Validation loss: 2.791981840609289

Epoch: 6| Step: 6
Training loss: 0.5921481509459317
Validation loss: 2.7267509766938303

Epoch: 6| Step: 7
Training loss: 1.260326550417444
Validation loss: 2.7497821490378387

Epoch: 6| Step: 8
Training loss: 0.4584877086518599
Validation loss: 2.748278664341499

Epoch: 6| Step: 9
Training loss: 0.5022331673747921
Validation loss: 2.719723698850228

Epoch: 6| Step: 10
Training loss: 0.5905361027901493
Validation loss: 2.781293861529069

Epoch: 6| Step: 11
Training loss: 0.8961090432469232
Validation loss: 2.644712095402053

Epoch: 6| Step: 12
Training loss: 0.8047194243088993
Validation loss: 2.7384202516459437

Epoch: 6| Step: 13
Training loss: 0.5638999472266137
Validation loss: 2.7456441251622845

Epoch: 465| Step: 0
Training loss: 0.8984974716736848
Validation loss: 2.7512569733709977

Epoch: 6| Step: 1
Training loss: 0.7737483931418452
Validation loss: 2.7477615812053697

Epoch: 6| Step: 2
Training loss: 0.395378864130753
Validation loss: 2.772362858138243

Epoch: 6| Step: 3
Training loss: 0.5476544139357846
Validation loss: 2.772465581241708

Epoch: 6| Step: 4
Training loss: 0.5026957736427089
Validation loss: 2.714630038039439

Epoch: 6| Step: 5
Training loss: 1.0925656582199843
Validation loss: 2.747523536546605

Epoch: 6| Step: 6
Training loss: 0.8582929908814696
Validation loss: 2.7461441201826386

Epoch: 6| Step: 7
Training loss: 0.7154838322826117
Validation loss: 2.815384904035773

Epoch: 6| Step: 8
Training loss: 0.7311390947537824
Validation loss: 2.779774835396409

Epoch: 6| Step: 9
Training loss: 0.5267534696395005
Validation loss: 2.716004655386915

Epoch: 6| Step: 10
Training loss: 0.6971524144008633
Validation loss: 2.7417582930430795

Epoch: 6| Step: 11
Training loss: 0.8071413864213973
Validation loss: 2.688300523630642

Epoch: 6| Step: 12
Training loss: 0.557877835419749
Validation loss: 2.679286092604951

Epoch: 6| Step: 13
Training loss: 0.6787383369019823
Validation loss: 2.6992098287829687

Epoch: 466| Step: 0
Training loss: 0.7103748820108601
Validation loss: 2.6587060232610127

Epoch: 6| Step: 1
Training loss: 0.6119611832161088
Validation loss: 2.673485670133243

Epoch: 6| Step: 2
Training loss: 0.6931915294958999
Validation loss: 2.662813134203977

Epoch: 6| Step: 3
Training loss: 0.6812856673606683
Validation loss: 2.7418524527479544

Epoch: 6| Step: 4
Training loss: 0.599110299334171
Validation loss: 2.6678845088350616

Epoch: 6| Step: 5
Training loss: 0.9677297695866728
Validation loss: 2.6791996488622383

Epoch: 6| Step: 6
Training loss: 0.7235296384333525
Validation loss: 2.7182063293569714

Epoch: 6| Step: 7
Training loss: 0.4673523889404454
Validation loss: 2.6897856285869115

Epoch: 6| Step: 8
Training loss: 0.47523639217602676
Validation loss: 2.6259471607465596

Epoch: 6| Step: 9
Training loss: 0.5195261445906043
Validation loss: 2.7004471526337794

Epoch: 6| Step: 10
Training loss: 0.5065177550842531
Validation loss: 2.7596183534182086

Epoch: 6| Step: 11
Training loss: 0.89613228991908
Validation loss: 2.749565711552903

Epoch: 6| Step: 12
Training loss: 1.3883217586173744
Validation loss: 2.733209459669016

Epoch: 6| Step: 13
Training loss: 0.5751784731823859
Validation loss: 2.6764684384088118

Epoch: 467| Step: 0
Training loss: 0.9637988219901297
Validation loss: 2.7422427382887586

Epoch: 6| Step: 1
Training loss: 0.7443420457952183
Validation loss: 2.671935796510735

Epoch: 6| Step: 2
Training loss: 0.8658274389757188
Validation loss: 2.731820008181064

Epoch: 6| Step: 3
Training loss: 0.5512808569664606
Validation loss: 2.722398115387865

Epoch: 6| Step: 4
Training loss: 0.5208028275774887
Validation loss: 2.721451772493897

Epoch: 6| Step: 5
Training loss: 0.8792557085213648
Validation loss: 2.6848521976766886

Epoch: 6| Step: 6
Training loss: 0.5704833519434774
Validation loss: 2.778457096534023

Epoch: 6| Step: 7
Training loss: 0.8471757080428189
Validation loss: 2.6736507946773957

Epoch: 6| Step: 8
Training loss: 0.6914492663779088
Validation loss: 2.7251041742413316

Epoch: 6| Step: 9
Training loss: 0.6616571733272536
Validation loss: 2.7062662061010756

Epoch: 6| Step: 10
Training loss: 0.5676281081977494
Validation loss: 2.705566993726625

Epoch: 6| Step: 11
Training loss: 0.6289703146960107
Validation loss: 2.741757611869819

Epoch: 6| Step: 12
Training loss: 0.4811366951071827
Validation loss: 2.706983469531766

Epoch: 6| Step: 13
Training loss: 0.7983000485828896
Validation loss: 2.694915992946779

Epoch: 468| Step: 0
Training loss: 0.8565507778185347
Validation loss: 2.7035583266371326

Epoch: 6| Step: 1
Training loss: 0.6655433748011922
Validation loss: 2.7208784475476007

Epoch: 6| Step: 2
Training loss: 0.8581634998506352
Validation loss: 2.7336162422667036

Epoch: 6| Step: 3
Training loss: 0.5722802586686199
Validation loss: 2.680502483081907

Epoch: 6| Step: 4
Training loss: 0.45384845858172734
Validation loss: 2.623971192521623

Epoch: 6| Step: 5
Training loss: 0.6795183607095185
Validation loss: 2.656290270930177

Epoch: 6| Step: 6
Training loss: 0.570369351832447
Validation loss: 2.6988242597612553

Epoch: 6| Step: 7
Training loss: 1.0925522376694115
Validation loss: 2.689428894037237

Epoch: 6| Step: 8
Training loss: 0.47454872842754386
Validation loss: 2.6360878724187247

Epoch: 6| Step: 9
Training loss: 0.8463836469162087
Validation loss: 2.7017906732435355

Epoch: 6| Step: 10
Training loss: 0.6307063433809454
Validation loss: 2.7928961470977596

Epoch: 6| Step: 11
Training loss: 0.6995016836223832
Validation loss: 2.7408110958120093

Epoch: 6| Step: 12
Training loss: 0.9600342017280159
Validation loss: 2.8084924756547465

Epoch: 6| Step: 13
Training loss: 1.0055299682476238
Validation loss: 2.695312426286042

Epoch: 469| Step: 0
Training loss: 0.5468729291604207
Validation loss: 2.705894991382977

Epoch: 6| Step: 1
Training loss: 0.9530963893410942
Validation loss: 2.655110163250055

Epoch: 6| Step: 2
Training loss: 0.6736551698606222
Validation loss: 2.7253001149884732

Epoch: 6| Step: 3
Training loss: 0.5996580818597966
Validation loss: 2.681304221505335

Epoch: 6| Step: 4
Training loss: 0.884700915936582
Validation loss: 2.6926680708825885

Epoch: 6| Step: 5
Training loss: 0.7607292987089127
Validation loss: 2.7200593681962246

Epoch: 6| Step: 6
Training loss: 0.7613158896859074
Validation loss: 2.7232210658016567

Epoch: 6| Step: 7
Training loss: 1.0388099535591904
Validation loss: 2.6164917433841888

Epoch: 6| Step: 8
Training loss: 0.8661232681378218
Validation loss: 2.7143829906093337

Epoch: 6| Step: 9
Training loss: 0.7406291864976984
Validation loss: 2.674528042879994

Epoch: 6| Step: 10
Training loss: 0.5934327683503724
Validation loss: 2.685893680258704

Epoch: 6| Step: 11
Training loss: 0.5565233073499148
Validation loss: 2.6520282331098266

Epoch: 6| Step: 12
Training loss: 1.0690424825650329
Validation loss: 2.7153816403825513

Epoch: 6| Step: 13
Training loss: 0.7161360352741782
Validation loss: 2.7149335887507275

Epoch: 470| Step: 0
Training loss: 0.8972092567178913
Validation loss: 2.6595659539309633

Epoch: 6| Step: 1
Training loss: 0.7208796339287938
Validation loss: 2.6885522955756174

Epoch: 6| Step: 2
Training loss: 0.6916763941720413
Validation loss: 2.6347891672419697

Epoch: 6| Step: 3
Training loss: 0.40863543529378044
Validation loss: 2.6897043606224593

Epoch: 6| Step: 4
Training loss: 0.8560969167150534
Validation loss: 2.692610575944685

Epoch: 6| Step: 5
Training loss: 0.700561789316332
Validation loss: 2.6742592299875843

Epoch: 6| Step: 6
Training loss: 0.7288204915418449
Validation loss: 2.682334452661289

Epoch: 6| Step: 7
Training loss: 1.2235443010155156
Validation loss: 2.730943644878614

Epoch: 6| Step: 8
Training loss: 0.5806800467982112
Validation loss: 2.6697423354130914

Epoch: 6| Step: 9
Training loss: 0.7001166306131468
Validation loss: 2.7039169885921246

Epoch: 6| Step: 10
Training loss: 1.0403638449018944
Validation loss: 2.6953214488595023

Epoch: 6| Step: 11
Training loss: 0.7088524141273631
Validation loss: 2.655426810370065

Epoch: 6| Step: 12
Training loss: 0.6240179452669348
Validation loss: 2.6280339358682285

Epoch: 6| Step: 13
Training loss: 0.8197729607030928
Validation loss: 2.6712809417222596

Epoch: 471| Step: 0
Training loss: 1.2555004217951533
Validation loss: 2.6974609584180897

Epoch: 6| Step: 1
Training loss: 0.5223871767259265
Validation loss: 2.769672915660484

Epoch: 6| Step: 2
Training loss: 0.6139520026420902
Validation loss: 2.7102200001102306

Epoch: 6| Step: 3
Training loss: 0.521421164349913
Validation loss: 2.6805276693585722

Epoch: 6| Step: 4
Training loss: 0.7119564676933635
Validation loss: 2.6951055032606894

Epoch: 6| Step: 5
Training loss: 0.7975122484324872
Validation loss: 2.66156134558466

Epoch: 6| Step: 6
Training loss: 0.5350430222619804
Validation loss: 2.7116452263459463

Epoch: 6| Step: 7
Training loss: 0.9502172987022285
Validation loss: 2.71658091048956

Epoch: 6| Step: 8
Training loss: 0.6990847325956909
Validation loss: 2.687297103674841

Epoch: 6| Step: 9
Training loss: 0.42396072212064884
Validation loss: 2.6754716605896323

Epoch: 6| Step: 10
Training loss: 0.49653629778804403
Validation loss: 2.6928981564067755

Epoch: 6| Step: 11
Training loss: 0.805275785344208
Validation loss: 2.713149298027674

Epoch: 6| Step: 12
Training loss: 0.9040086587643116
Validation loss: 2.737428453459794

Epoch: 6| Step: 13
Training loss: 0.6902495369058207
Validation loss: 2.759270445649041

Epoch: 472| Step: 0
Training loss: 0.6036615041081629
Validation loss: 2.688450150014229

Epoch: 6| Step: 1
Training loss: 0.7814375461534726
Validation loss: 2.7718267357031516

Epoch: 6| Step: 2
Training loss: 0.5250183545037655
Validation loss: 2.770100996331489

Epoch: 6| Step: 3
Training loss: 0.6258326229577366
Validation loss: 2.6855289860909877

Epoch: 6| Step: 4
Training loss: 0.7808043162336025
Validation loss: 2.73356082965848

Epoch: 6| Step: 5
Training loss: 0.6117576089844908
Validation loss: 2.755821193517987

Epoch: 6| Step: 6
Training loss: 0.8748497493352191
Validation loss: 2.8161100177993137

Epoch: 6| Step: 7
Training loss: 0.6842027839423364
Validation loss: 2.7145216350516517

Epoch: 6| Step: 8
Training loss: 0.6176761189938553
Validation loss: 2.7253437105449083

Epoch: 6| Step: 9
Training loss: 0.5145944353468451
Validation loss: 2.6897017161591705

Epoch: 6| Step: 10
Training loss: 0.39810638132679926
Validation loss: 2.6955906378937105

Epoch: 6| Step: 11
Training loss: 0.6074187839834184
Validation loss: 2.6558714353782524

Epoch: 6| Step: 12
Training loss: 0.6246828705166234
Validation loss: 2.7452760928842297

Epoch: 6| Step: 13
Training loss: 1.1410476737531459
Validation loss: 2.7546710311908003

Epoch: 473| Step: 0
Training loss: 0.6880895081253378
Validation loss: 2.694353480349343

Epoch: 6| Step: 1
Training loss: 0.659196257206386
Validation loss: 2.717388718451776

Epoch: 6| Step: 2
Training loss: 0.6338740969188639
Validation loss: 2.765950343649162

Epoch: 6| Step: 3
Training loss: 1.0407701385367647
Validation loss: 2.8076863952067983

Epoch: 6| Step: 4
Training loss: 0.9229974540559615
Validation loss: 2.731494949029839

Epoch: 6| Step: 5
Training loss: 0.6712472555789928
Validation loss: 2.7462604267730972

Epoch: 6| Step: 6
Training loss: 0.724039846172094
Validation loss: 2.7069048170809333

Epoch: 6| Step: 7
Training loss: 0.4777728641504386
Validation loss: 2.679827316684858

Epoch: 6| Step: 8
Training loss: 1.170501972745971
Validation loss: 2.7082893857080133

Epoch: 6| Step: 9
Training loss: 0.5625531383422456
Validation loss: 2.68596211870209

Epoch: 6| Step: 10
Training loss: 0.7947346609794693
Validation loss: 2.6840376174524874

Epoch: 6| Step: 11
Training loss: 1.3020918375373327
Validation loss: 2.6748859327720265

Epoch: 6| Step: 12
Training loss: 0.6348594713529496
Validation loss: 2.72888716996719

Epoch: 6| Step: 13
Training loss: 0.7336592737414961
Validation loss: 2.6563545206486894

Epoch: 474| Step: 0
Training loss: 0.701177740470984
Validation loss: 2.6871090316273154

Epoch: 6| Step: 1
Training loss: 0.7350037906185677
Validation loss: 2.8211051834340983

Epoch: 6| Step: 2
Training loss: 0.7773583568945033
Validation loss: 2.815594743628874

Epoch: 6| Step: 3
Training loss: 0.8686018742035407
Validation loss: 2.728514663816268

Epoch: 6| Step: 4
Training loss: 0.7970473533189667
Validation loss: 2.7098499062276913

Epoch: 6| Step: 5
Training loss: 0.8763130417809806
Validation loss: 2.6450934890060647

Epoch: 6| Step: 6
Training loss: 0.7421006402837831
Validation loss: 2.679199070435419

Epoch: 6| Step: 7
Training loss: 0.5885656796398155
Validation loss: 2.6569747833559973

Epoch: 6| Step: 8
Training loss: 0.7805654196683447
Validation loss: 2.71222964520159

Epoch: 6| Step: 9
Training loss: 0.9059984581536317
Validation loss: 2.657005651362464

Epoch: 6| Step: 10
Training loss: 0.8782291771396267
Validation loss: 2.6376763759414894

Epoch: 6| Step: 11
Training loss: 0.9541770569403581
Validation loss: 2.7033430978039723

Epoch: 6| Step: 12
Training loss: 0.9637539225992016
Validation loss: 2.7524846152355806

Epoch: 6| Step: 13
Training loss: 0.8027047478993193
Validation loss: 2.8356681674818627

Epoch: 475| Step: 0
Training loss: 0.576876761949355
Validation loss: 2.807337551178395

Epoch: 6| Step: 1
Training loss: 0.9704548078723022
Validation loss: 2.848520211535835

Epoch: 6| Step: 2
Training loss: 0.8148581689160506
Validation loss: 2.7536495007891637

Epoch: 6| Step: 3
Training loss: 0.7435893822990791
Validation loss: 2.7236073099417073

Epoch: 6| Step: 4
Training loss: 0.8054577742530866
Validation loss: 2.7144324121413703

Epoch: 6| Step: 5
Training loss: 0.9998961037069366
Validation loss: 2.6411065108412943

Epoch: 6| Step: 6
Training loss: 0.8218611132242702
Validation loss: 2.617332234342399

Epoch: 6| Step: 7
Training loss: 0.5645589234352739
Validation loss: 2.708819467979619

Epoch: 6| Step: 8
Training loss: 0.8412985333390796
Validation loss: 2.65474837998426

Epoch: 6| Step: 9
Training loss: 0.4806188023419356
Validation loss: 2.6569631479387894

Epoch: 6| Step: 10
Training loss: 0.788696355189427
Validation loss: 2.697342658134115

Epoch: 6| Step: 11
Training loss: 0.7657252654770779
Validation loss: 2.6660358209275876

Epoch: 6| Step: 12
Training loss: 1.0428626760197894
Validation loss: 2.6765211135921794

Epoch: 6| Step: 13
Training loss: 0.48981314872298626
Validation loss: 2.7303276698639354

Epoch: 476| Step: 0
Training loss: 0.4877137357495952
Validation loss: 2.7168979840783267

Epoch: 6| Step: 1
Training loss: 0.6479076380780353
Validation loss: 2.7443248682403145

Epoch: 6| Step: 2
Training loss: 0.8425905950947219
Validation loss: 2.7193294214643076

Epoch: 6| Step: 3
Training loss: 0.6602421541018644
Validation loss: 2.807227780966363

Epoch: 6| Step: 4
Training loss: 0.8492675795286717
Validation loss: 2.747565940664974

Epoch: 6| Step: 5
Training loss: 0.639840273445941
Validation loss: 2.7931100378334985

Epoch: 6| Step: 6
Training loss: 0.8999212866376451
Validation loss: 2.757826188209287

Epoch: 6| Step: 7
Training loss: 0.7243128990035966
Validation loss: 2.6963102843469438

Epoch: 6| Step: 8
Training loss: 1.1072140991564592
Validation loss: 2.7045364370018454

Epoch: 6| Step: 9
Training loss: 0.6243676324358127
Validation loss: 2.7469293472532317

Epoch: 6| Step: 10
Training loss: 0.7645790195256775
Validation loss: 2.7255695506083586

Epoch: 6| Step: 11
Training loss: 0.5717709847999836
Validation loss: 2.710661449907083

Epoch: 6| Step: 12
Training loss: 1.0671615441043638
Validation loss: 2.6585248593142703

Epoch: 6| Step: 13
Training loss: 0.6104444265291921
Validation loss: 2.713053878511651

Epoch: 477| Step: 0
Training loss: 0.5299406183913402
Validation loss: 2.6698902931010537

Epoch: 6| Step: 1
Training loss: 0.5612726596939294
Validation loss: 2.7085588703636603

Epoch: 6| Step: 2
Training loss: 0.5767894990654279
Validation loss: 2.6875423309777506

Epoch: 6| Step: 3
Training loss: 0.7853379300330542
Validation loss: 2.6783741957089915

Epoch: 6| Step: 4
Training loss: 0.5221268485897071
Validation loss: 2.6998407776120406

Epoch: 6| Step: 5
Training loss: 0.9477208567560782
Validation loss: 2.6873002976141103

Epoch: 6| Step: 6
Training loss: 0.7815463457722164
Validation loss: 2.742178993900217

Epoch: 6| Step: 7
Training loss: 0.986920652777076
Validation loss: 2.692066423553637

Epoch: 6| Step: 8
Training loss: 0.7896251372155606
Validation loss: 2.669908316558516

Epoch: 6| Step: 9
Training loss: 0.6382167489414984
Validation loss: 2.6938484085411085

Epoch: 6| Step: 10
Training loss: 0.8028284839124395
Validation loss: 2.647145439062677

Epoch: 6| Step: 11
Training loss: 0.8701647264914031
Validation loss: 2.749357437432659

Epoch: 6| Step: 12
Training loss: 0.4110074429766234
Validation loss: 2.6846410196909263

Epoch: 6| Step: 13
Training loss: 0.5095380370042798
Validation loss: 2.622357476467534

Epoch: 478| Step: 0
Training loss: 0.4654237830859666
Validation loss: 2.649706316215014

Epoch: 6| Step: 1
Training loss: 0.610449015657461
Validation loss: 2.6536924203982957

Epoch: 6| Step: 2
Training loss: 0.36587270757610596
Validation loss: 2.678974423746705

Epoch: 6| Step: 3
Training loss: 1.1666883512025767
Validation loss: 2.688561074798857

Epoch: 6| Step: 4
Training loss: 0.6214064284859857
Validation loss: 2.6631597441781

Epoch: 6| Step: 5
Training loss: 0.7133997940880232
Validation loss: 2.7195768743171125

Epoch: 6| Step: 6
Training loss: 0.49099399030391083
Validation loss: 2.681757462029169

Epoch: 6| Step: 7
Training loss: 0.9106237823331569
Validation loss: 2.711001495280241

Epoch: 6| Step: 8
Training loss: 0.68966861631592
Validation loss: 2.6703380677985944

Epoch: 6| Step: 9
Training loss: 0.7999572980928249
Validation loss: 2.7221188774301037

Epoch: 6| Step: 10
Training loss: 0.9509586040299937
Validation loss: 2.7090740266948465

Epoch: 6| Step: 11
Training loss: 0.5123645696571829
Validation loss: 2.7038309428667238

Epoch: 6| Step: 12
Training loss: 0.6856469410086642
Validation loss: 2.7377121243674263

Epoch: 6| Step: 13
Training loss: 0.5065668233208074
Validation loss: 2.688116416914493

Epoch: 479| Step: 0
Training loss: 1.202915767955191
Validation loss: 2.674349065115386

Epoch: 6| Step: 1
Training loss: 0.6260922662742633
Validation loss: 2.6766232690186937

Epoch: 6| Step: 2
Training loss: 0.6330206493381394
Validation loss: 2.6681267099083854

Epoch: 6| Step: 3
Training loss: 0.6351988267880518
Validation loss: 2.638487437871036

Epoch: 6| Step: 4
Training loss: 0.5074325901042507
Validation loss: 2.6706981483879177

Epoch: 6| Step: 5
Training loss: 0.5885724141238978
Validation loss: 2.6312340476910907

Epoch: 6| Step: 6
Training loss: 0.6735589194534024
Validation loss: 2.639399016302134

Epoch: 6| Step: 7
Training loss: 0.7952310771519608
Validation loss: 2.6839271571512144

Epoch: 6| Step: 8
Training loss: 0.5199873220292067
Validation loss: 2.6406837772847758

Epoch: 6| Step: 9
Training loss: 0.8550164058851345
Validation loss: 2.642808917733565

Epoch: 6| Step: 10
Training loss: 0.62528136595733
Validation loss: 2.6542281216064665

Epoch: 6| Step: 11
Training loss: 0.5086834115073702
Validation loss: 2.734363112650872

Epoch: 6| Step: 12
Training loss: 0.4879963921282633
Validation loss: 2.6715420372352154

Epoch: 6| Step: 13
Training loss: 0.8166147358271338
Validation loss: 2.6527291693458714

Epoch: 480| Step: 0
Training loss: 0.5027582857956269
Validation loss: 2.6701445152996186

Epoch: 6| Step: 1
Training loss: 0.717835217366766
Validation loss: 2.6305726708599813

Epoch: 6| Step: 2
Training loss: 0.5589908708772086
Validation loss: 2.6211247070424886

Epoch: 6| Step: 3
Training loss: 0.4407670786248529
Validation loss: 2.6297174858125913

Epoch: 6| Step: 4
Training loss: 0.7231619637685062
Validation loss: 2.6375277034154303

Epoch: 6| Step: 5
Training loss: 0.6106990953936888
Validation loss: 2.627326199535986

Epoch: 6| Step: 6
Training loss: 0.45405640736513775
Validation loss: 2.608274543778114

Epoch: 6| Step: 7
Training loss: 0.8487558571974353
Validation loss: 2.6700170649293913

Epoch: 6| Step: 8
Training loss: 0.768856081582702
Validation loss: 2.6745184301498584

Epoch: 6| Step: 9
Training loss: 0.7265945755636113
Validation loss: 2.654269733154513

Epoch: 6| Step: 10
Training loss: 0.9477583085694381
Validation loss: 2.7513551118683695

Epoch: 6| Step: 11
Training loss: 0.4637312197931205
Validation loss: 2.6409932844675317

Epoch: 6| Step: 12
Training loss: 0.5672154401302523
Validation loss: 2.7117443661224896

Epoch: 6| Step: 13
Training loss: 0.6668823062314163
Validation loss: 2.686470795733529

Epoch: 481| Step: 0
Training loss: 0.6264536166058465
Validation loss: 2.580623533446041

Epoch: 6| Step: 1
Training loss: 0.7180971829809456
Validation loss: 2.677968444165382

Epoch: 6| Step: 2
Training loss: 0.5698450341300417
Validation loss: 2.656513724605337

Epoch: 6| Step: 3
Training loss: 0.5632813113737668
Validation loss: 2.70515342267908

Epoch: 6| Step: 4
Training loss: 0.427714761083992
Validation loss: 2.634300845102922

Epoch: 6| Step: 5
Training loss: 0.5265162722164208
Validation loss: 2.680700824163536

Epoch: 6| Step: 6
Training loss: 0.7778910718063936
Validation loss: 2.7300448327348152

Epoch: 6| Step: 7
Training loss: 0.7036043864104237
Validation loss: 2.6059105997450347

Epoch: 6| Step: 8
Training loss: 0.500204759632941
Validation loss: 2.613790009245743

Epoch: 6| Step: 9
Training loss: 0.5602392754947522
Validation loss: 2.6739031286798562

Epoch: 6| Step: 10
Training loss: 0.9317076077163642
Validation loss: 2.663513611809998

Epoch: 6| Step: 11
Training loss: 0.49099488559766824
Validation loss: 2.6466558985006645

Epoch: 6| Step: 12
Training loss: 0.5545557967165301
Validation loss: 2.7414722143705434

Epoch: 6| Step: 13
Training loss: 0.9077412404966992
Validation loss: 2.703909332029682

Epoch: 482| Step: 0
Training loss: 0.6496697861686423
Validation loss: 2.685290263544956

Epoch: 6| Step: 1
Training loss: 0.8367100292217942
Validation loss: 2.6366990604371905

Epoch: 6| Step: 2
Training loss: 0.5659315553602556
Validation loss: 2.66443563553527

Epoch: 6| Step: 3
Training loss: 0.6770086883088837
Validation loss: 2.673082699652466

Epoch: 6| Step: 4
Training loss: 0.5278225455900674
Validation loss: 2.728774564303082

Epoch: 6| Step: 5
Training loss: 0.6323524026959758
Validation loss: 2.684544535069437

Epoch: 6| Step: 6
Training loss: 0.7840038591747279
Validation loss: 2.6808718926768704

Epoch: 6| Step: 7
Training loss: 0.7741234560002039
Validation loss: 2.706323454978115

Epoch: 6| Step: 8
Training loss: 0.3028424716049009
Validation loss: 2.742519304247562

Epoch: 6| Step: 9
Training loss: 0.5414230795442286
Validation loss: 2.7028182338924736

Epoch: 6| Step: 10
Training loss: 0.5938232778204068
Validation loss: 2.6293093564527803

Epoch: 6| Step: 11
Training loss: 0.4761091796558116
Validation loss: 2.7118764784739224

Epoch: 6| Step: 12
Training loss: 0.4371948881254425
Validation loss: 2.6817943050157247

Epoch: 6| Step: 13
Training loss: 0.45653771382127795
Validation loss: 2.6714324584682037

Epoch: 483| Step: 0
Training loss: 0.6958824564865083
Validation loss: 2.682839988785396

Epoch: 6| Step: 1
Training loss: 0.5586046337854679
Validation loss: 2.6967820662439226

Epoch: 6| Step: 2
Training loss: 0.5247633923097893
Validation loss: 2.6718769185020297

Epoch: 6| Step: 3
Training loss: 0.679552832230243
Validation loss: 2.7403022538376853

Epoch: 6| Step: 4
Training loss: 0.4477879834701449
Validation loss: 2.6480743849449353

Epoch: 6| Step: 5
Training loss: 0.8096488666040966
Validation loss: 2.6906121147694937

Epoch: 6| Step: 6
Training loss: 0.7851373470934652
Validation loss: 2.673611513498339

Epoch: 6| Step: 7
Training loss: 0.5379914133226893
Validation loss: 2.6403540748793164

Epoch: 6| Step: 8
Training loss: 0.6258567183536634
Validation loss: 2.6533736943245483

Epoch: 6| Step: 9
Training loss: 0.5879347521674217
Validation loss: 2.689153798201295

Epoch: 6| Step: 10
Training loss: 0.6343980399772556
Validation loss: 2.6948015106418524

Epoch: 6| Step: 11
Training loss: 0.6769263647989975
Validation loss: 2.6949880800944928

Epoch: 6| Step: 12
Training loss: 0.5075178905678545
Validation loss: 2.6869260707419684

Epoch: 6| Step: 13
Training loss: 0.7728534766909301
Validation loss: 2.6631006348384694

Epoch: 484| Step: 0
Training loss: 0.47040215838449656
Validation loss: 2.6960331050272193

Epoch: 6| Step: 1
Training loss: 0.8494162855296847
Validation loss: 2.6737313616463987

Epoch: 6| Step: 2
Training loss: 0.4863320775618277
Validation loss: 2.664350641353875

Epoch: 6| Step: 3
Training loss: 0.4350249922906329
Validation loss: 2.6714450274568478

Epoch: 6| Step: 4
Training loss: 0.559904361630331
Validation loss: 2.652149019129601

Epoch: 6| Step: 5
Training loss: 0.4200502421210043
Validation loss: 2.6760589826733154

Epoch: 6| Step: 6
Training loss: 0.5766678824944809
Validation loss: 2.6974943461342695

Epoch: 6| Step: 7
Training loss: 0.5376014258922105
Validation loss: 2.6357378606865574

Epoch: 6| Step: 8
Training loss: 0.8777325740943432
Validation loss: 2.716876221007067

Epoch: 6| Step: 9
Training loss: 0.6104927815144126
Validation loss: 2.6386562434481013

Epoch: 6| Step: 10
Training loss: 0.47412733236936494
Validation loss: 2.6447123958992425

Epoch: 6| Step: 11
Training loss: 0.9306859337077065
Validation loss: 2.6751626740663634

Epoch: 6| Step: 12
Training loss: 0.5883022907440728
Validation loss: 2.635917832037952

Epoch: 6| Step: 13
Training loss: 0.3632275121177285
Validation loss: 2.7231938813254355

Epoch: 485| Step: 0
Training loss: 0.5823754438573386
Validation loss: 2.703879278710333

Epoch: 6| Step: 1
Training loss: 0.5624619312119967
Validation loss: 2.6740408107598226

Epoch: 6| Step: 2
Training loss: 0.6941401853543909
Validation loss: 2.747456515878952

Epoch: 6| Step: 3
Training loss: 0.5676394225360895
Validation loss: 2.739609610621302

Epoch: 6| Step: 4
Training loss: 0.794940957630003
Validation loss: 2.687017456617912

Epoch: 6| Step: 5
Training loss: 0.4865997811981741
Validation loss: 2.67149058768568

Epoch: 6| Step: 6
Training loss: 0.4210199415247895
Validation loss: 2.6395480199999315

Epoch: 6| Step: 7
Training loss: 0.5413613161759142
Validation loss: 2.70251113889306

Epoch: 6| Step: 8
Training loss: 0.5410937036023518
Validation loss: 2.6947677872736038

Epoch: 6| Step: 9
Training loss: 0.8037825746001434
Validation loss: 2.6909129627771664

Epoch: 6| Step: 10
Training loss: 0.3207417612348239
Validation loss: 2.71047336441855

Epoch: 6| Step: 11
Training loss: 0.7918911833039045
Validation loss: 2.719738353107858

Epoch: 6| Step: 12
Training loss: 0.5799928339153756
Validation loss: 2.6825128606065505

Epoch: 6| Step: 13
Training loss: 0.3729526340820682
Validation loss: 2.775099135681482

Epoch: 486| Step: 0
Training loss: 0.4586836458702562
Validation loss: 2.7624366039521884

Epoch: 6| Step: 1
Training loss: 0.8771300615260037
Validation loss: 2.713387839459531

Epoch: 6| Step: 2
Training loss: 0.5762820898128207
Validation loss: 2.6776789560479592

Epoch: 6| Step: 3
Training loss: 0.5666362952994322
Validation loss: 2.6595971579124913

Epoch: 6| Step: 4
Training loss: 0.46501098958226944
Validation loss: 2.697649310401632

Epoch: 6| Step: 5
Training loss: 0.5136877717433851
Validation loss: 2.692392331930827

Epoch: 6| Step: 6
Training loss: 0.5235514445618195
Validation loss: 2.661290237483312

Epoch: 6| Step: 7
Training loss: 0.6660907960236077
Validation loss: 2.7320818195238954

Epoch: 6| Step: 8
Training loss: 0.7655237091947541
Validation loss: 2.704032201808469

Epoch: 6| Step: 9
Training loss: 0.43821365188737554
Validation loss: 2.665231830301812

Epoch: 6| Step: 10
Training loss: 0.982967035852677
Validation loss: 2.7264521010819203

Epoch: 6| Step: 11
Training loss: 0.6674338535866863
Validation loss: 2.7195393523567044

Epoch: 6| Step: 12
Training loss: 0.7008049730178889
Validation loss: 2.7556699908073323

Epoch: 6| Step: 13
Training loss: 0.5474408900346173
Validation loss: 2.754377147193893

Epoch: 487| Step: 0
Training loss: 0.5325925635985075
Validation loss: 2.7187070733551013

Epoch: 6| Step: 1
Training loss: 0.5502268388441423
Validation loss: 2.6757274910011755

Epoch: 6| Step: 2
Training loss: 0.8477477274813351
Validation loss: 2.684381879176724

Epoch: 6| Step: 3
Training loss: 0.5236528722157052
Validation loss: 2.706381304626512

Epoch: 6| Step: 4
Training loss: 0.5126382850538458
Validation loss: 2.7412957809250456

Epoch: 6| Step: 5
Training loss: 0.5195314220915774
Validation loss: 2.749272452550172

Epoch: 6| Step: 6
Training loss: 0.3857659441235755
Validation loss: 2.7773390714925212

Epoch: 6| Step: 7
Training loss: 0.33720129181070285
Validation loss: 2.7149506545573376

Epoch: 6| Step: 8
Training loss: 0.5272513414585636
Validation loss: 2.720338788344642

Epoch: 6| Step: 9
Training loss: 0.6419075478656303
Validation loss: 2.728132894183401

Epoch: 6| Step: 10
Training loss: 0.6127347515766037
Validation loss: 2.7604269111491186

Epoch: 6| Step: 11
Training loss: 0.955986043864097
Validation loss: 2.731424625497055

Epoch: 6| Step: 12
Training loss: 0.7994167705297096
Validation loss: 2.6862944627066954

Epoch: 6| Step: 13
Training loss: 0.5302067498693698
Validation loss: 2.734681350258784

Epoch: 488| Step: 0
Training loss: 0.45665379775262144
Validation loss: 2.71522486364954

Epoch: 6| Step: 1
Training loss: 0.7907012691575904
Validation loss: 2.6979652508420076

Epoch: 6| Step: 2
Training loss: 0.5360122294916808
Validation loss: 2.696032485995412

Epoch: 6| Step: 3
Training loss: 0.4894423450887291
Validation loss: 2.73319314756122

Epoch: 6| Step: 4
Training loss: 0.6594322794401276
Validation loss: 2.8236961039431465

Epoch: 6| Step: 5
Training loss: 0.4329029973301054
Validation loss: 2.7263887599617482

Epoch: 6| Step: 6
Training loss: 0.7801502498164478
Validation loss: 2.7190243958892455

Epoch: 6| Step: 7
Training loss: 0.6304906942904495
Validation loss: 2.729682165095898

Epoch: 6| Step: 8
Training loss: 0.3785944176580231
Validation loss: 2.752165101016022

Epoch: 6| Step: 9
Training loss: 0.49041088315826387
Validation loss: 2.7512501129330618

Epoch: 6| Step: 10
Training loss: 0.473226723160489
Validation loss: 2.7372530223386

Epoch: 6| Step: 11
Training loss: 0.5957263629320628
Validation loss: 2.71392554986461

Epoch: 6| Step: 12
Training loss: 0.4141019766360809
Validation loss: 2.757086163798434

Epoch: 6| Step: 13
Training loss: 0.6428790561786158
Validation loss: 2.7183378352960776

Epoch: 489| Step: 0
Training loss: 0.8126566442464097
Validation loss: 2.7455298476501713

Epoch: 6| Step: 1
Training loss: 0.8175064048166221
Validation loss: 2.7058569859899424

Epoch: 6| Step: 2
Training loss: 0.5577061944530324
Validation loss: 2.7302406663276657

Epoch: 6| Step: 3
Training loss: 0.6213454450286705
Validation loss: 2.6626321825458565

Epoch: 6| Step: 4
Training loss: 0.6528711984849831
Validation loss: 2.659341531461503

Epoch: 6| Step: 5
Training loss: 0.6214177707969075
Validation loss: 2.63369915650472

Epoch: 6| Step: 6
Training loss: 0.3712550164214537
Validation loss: 2.6539728314471134

Epoch: 6| Step: 7
Training loss: 0.5696379709397233
Validation loss: 2.6957435300119026

Epoch: 6| Step: 8
Training loss: 0.5188946085758034
Validation loss: 2.7332285775680565

Epoch: 6| Step: 9
Training loss: 0.5188918804417828
Validation loss: 2.7503946483531885

Epoch: 6| Step: 10
Training loss: 0.6637957317596656
Validation loss: 2.683179198650022

Epoch: 6| Step: 11
Training loss: 0.5590438096753438
Validation loss: 2.712430683838314

Epoch: 6| Step: 12
Training loss: 0.547545213095326
Validation loss: 2.7044850200727892

Epoch: 6| Step: 13
Training loss: 0.42548407236696245
Validation loss: 2.659681945431634

Epoch: 490| Step: 0
Training loss: 0.42756332391359225
Validation loss: 2.7117187810656227

Epoch: 6| Step: 1
Training loss: 0.6721198279075559
Validation loss: 2.719168649061507

Epoch: 6| Step: 2
Training loss: 0.9029090728815979
Validation loss: 2.692952516995825

Epoch: 6| Step: 3
Training loss: 0.6829896055592326
Validation loss: 2.686364133459543

Epoch: 6| Step: 4
Training loss: 0.7985932767415459
Validation loss: 2.6983156142459044

Epoch: 6| Step: 5
Training loss: 0.5155488160234548
Validation loss: 2.6611260631604012

Epoch: 6| Step: 6
Training loss: 0.5629936277560799
Validation loss: 2.6765065047951544

Epoch: 6| Step: 7
Training loss: 0.6626294549383157
Validation loss: 2.7000644387691297

Epoch: 6| Step: 8
Training loss: 0.4894724240041247
Validation loss: 2.6680228142685127

Epoch: 6| Step: 9
Training loss: 0.6488706681590657
Validation loss: 2.6973091580512336

Epoch: 6| Step: 10
Training loss: 0.4340282874634187
Validation loss: 2.671442290546014

Epoch: 6| Step: 11
Training loss: 0.311622914661908
Validation loss: 2.7414242804459694

Epoch: 6| Step: 12
Training loss: 0.37931583329661245
Validation loss: 2.7556418286383098

Epoch: 6| Step: 13
Training loss: 0.45091223573925193
Validation loss: 2.700722819578932

Epoch: 491| Step: 0
Training loss: 0.669857277828122
Validation loss: 2.7457278040827275

Epoch: 6| Step: 1
Training loss: 0.5062281615645006
Validation loss: 2.7383023785888376

Epoch: 6| Step: 2
Training loss: 0.31516518146604383
Validation loss: 2.693495221639072

Epoch: 6| Step: 3
Training loss: 0.4480783665971623
Validation loss: 2.7401369258331694

Epoch: 6| Step: 4
Training loss: 0.4603208846437647
Validation loss: 2.707110610686703

Epoch: 6| Step: 5
Training loss: 0.6777429057966797
Validation loss: 2.6937377604879895

Epoch: 6| Step: 6
Training loss: 0.605801201886118
Validation loss: 2.7421482876748113

Epoch: 6| Step: 7
Training loss: 0.28542777420390425
Validation loss: 2.701831677280915

Epoch: 6| Step: 8
Training loss: 0.708418523116133
Validation loss: 2.711406289792028

Epoch: 6| Step: 9
Training loss: 0.5984186035041328
Validation loss: 2.8063050885588345

Epoch: 6| Step: 10
Training loss: 0.6032138304445307
Validation loss: 2.7142907766424025

Epoch: 6| Step: 11
Training loss: 0.7501973846097066
Validation loss: 2.7819965803526197

Epoch: 6| Step: 12
Training loss: 0.7940421520449926
Validation loss: 2.7499219276443174

Epoch: 6| Step: 13
Training loss: 0.5107329971332703
Validation loss: 2.7673732741878476

Epoch: 492| Step: 0
Training loss: 0.4314072612459074
Validation loss: 2.6962466330426915

Epoch: 6| Step: 1
Training loss: 0.5842045907821944
Validation loss: 2.6830705468609994

Epoch: 6| Step: 2
Training loss: 0.5249523050350817
Validation loss: 2.7211890187262426

Epoch: 6| Step: 3
Training loss: 0.887401469228017
Validation loss: 2.696888589069642

Epoch: 6| Step: 4
Training loss: 0.6275485529866122
Validation loss: 2.7337084729866743

Epoch: 6| Step: 5
Training loss: 0.48919228059697345
Validation loss: 2.7416761742130373

Epoch: 6| Step: 6
Training loss: 0.4012780380554202
Validation loss: 2.7550911448794984

Epoch: 6| Step: 7
Training loss: 0.7038488688562887
Validation loss: 2.699209077986131

Epoch: 6| Step: 8
Training loss: 0.42120010646481815
Validation loss: 2.7173399356188446

Epoch: 6| Step: 9
Training loss: 0.37116698496107875
Validation loss: 2.7229746591764323

Epoch: 6| Step: 10
Training loss: 0.40398383806495786
Validation loss: 2.7226960349402956

Epoch: 6| Step: 11
Training loss: 0.6809836558174572
Validation loss: 2.729387097277663

Epoch: 6| Step: 12
Training loss: 0.4414956331479906
Validation loss: 2.721083637035852

Epoch: 6| Step: 13
Training loss: 0.8434086568337914
Validation loss: 2.7466917512806828

Epoch: 493| Step: 0
Training loss: 0.7501635373156279
Validation loss: 2.6954228033079577

Epoch: 6| Step: 1
Training loss: 0.8371202889147968
Validation loss: 2.6986760331312984

Epoch: 6| Step: 2
Training loss: 0.5801503300281293
Validation loss: 2.6372611083788997

Epoch: 6| Step: 3
Training loss: 0.6028887261210879
Validation loss: 2.666280783111762

Epoch: 6| Step: 4
Training loss: 0.5998907267883118
Validation loss: 2.6732456045509125

Epoch: 6| Step: 5
Training loss: 0.41814351216206785
Validation loss: 2.715661812530215

Epoch: 6| Step: 6
Training loss: 0.5494741798162533
Validation loss: 2.6998170814247153

Epoch: 6| Step: 7
Training loss: 0.7841888085163826
Validation loss: 2.689017481023453

Epoch: 6| Step: 8
Training loss: 0.5448025535191058
Validation loss: 2.7018596649734814

Epoch: 6| Step: 9
Training loss: 0.624711351497489
Validation loss: 2.6507136223760837

Epoch: 6| Step: 10
Training loss: 0.37750867315775166
Validation loss: 2.7333619775279145

Epoch: 6| Step: 11
Training loss: 0.5374011824947277
Validation loss: 2.672468718062272

Epoch: 6| Step: 12
Training loss: 0.8728082317899423
Validation loss: 2.665117220945718

Epoch: 6| Step: 13
Training loss: 0.4484493798998389
Validation loss: 2.701821499866283

Epoch: 494| Step: 0
Training loss: 0.5317411396380646
Validation loss: 2.7127546656727275

Epoch: 6| Step: 1
Training loss: 0.518675479362135
Validation loss: 2.7056372403245184

Epoch: 6| Step: 2
Training loss: 0.42027569435946793
Validation loss: 2.6810395117407757

Epoch: 6| Step: 3
Training loss: 0.5346780297016448
Validation loss: 2.7364193276910913

Epoch: 6| Step: 4
Training loss: 0.7160388149870255
Validation loss: 2.7217989082080276

Epoch: 6| Step: 5
Training loss: 0.3655453342471311
Validation loss: 2.7542184062104957

Epoch: 6| Step: 6
Training loss: 0.5893575420200949
Validation loss: 2.6886160994794794

Epoch: 6| Step: 7
Training loss: 0.5052611595404993
Validation loss: 2.7631437014850233

Epoch: 6| Step: 8
Training loss: 0.599126316784614
Validation loss: 2.7737072737321093

Epoch: 6| Step: 9
Training loss: 0.6044879475631292
Validation loss: 2.734058776008807

Epoch: 6| Step: 10
Training loss: 0.7658757947317127
Validation loss: 2.7405993870372374

Epoch: 6| Step: 11
Training loss: 0.5359476183055704
Validation loss: 2.7093239855335955

Epoch: 6| Step: 12
Training loss: 0.5866869647360002
Validation loss: 2.669592642885229

Epoch: 6| Step: 13
Training loss: 0.877930977452299
Validation loss: 2.6759499304106757

Epoch: 495| Step: 0
Training loss: 0.5236423433226864
Validation loss: 2.727231516550797

Epoch: 6| Step: 1
Training loss: 0.41135472993223693
Validation loss: 2.6950130720181287

Epoch: 6| Step: 2
Training loss: 0.6492335477352139
Validation loss: 2.734094165730973

Epoch: 6| Step: 3
Training loss: 0.7140760207617753
Validation loss: 2.6669966721983

Epoch: 6| Step: 4
Training loss: 0.6500189466649469
Validation loss: 2.673138711873491

Epoch: 6| Step: 5
Training loss: 0.3504156692723532
Validation loss: 2.7025286801369357

Epoch: 6| Step: 6
Training loss: 0.8372319262180633
Validation loss: 2.708301945039842

Epoch: 6| Step: 7
Training loss: 0.470709962913896
Validation loss: 2.767330254595845

Epoch: 6| Step: 8
Training loss: 0.5233814721938397
Validation loss: 2.7323281465442153

Epoch: 6| Step: 9
Training loss: 0.5769706749232361
Validation loss: 2.7821279990100694

Epoch: 6| Step: 10
Training loss: 0.4312945743689177
Validation loss: 2.774868820572368

Epoch: 6| Step: 11
Training loss: 0.8023512916990523
Validation loss: 2.6850418855228546

Epoch: 6| Step: 12
Training loss: 0.4827076918535027
Validation loss: 2.754541894588236

Epoch: 6| Step: 13
Training loss: 0.47982531006242096
Validation loss: 2.6527606110297532

Epoch: 496| Step: 0
Training loss: 0.5953028350205715
Validation loss: 2.6950494757683376

Epoch: 6| Step: 1
Training loss: 0.44222254934344074
Validation loss: 2.6837717114799093

Epoch: 6| Step: 2
Training loss: 0.5428159210501363
Validation loss: 2.6431092985187004

Epoch: 6| Step: 3
Training loss: 0.6895317270574209
Validation loss: 2.6420725253953483

Epoch: 6| Step: 4
Training loss: 0.7932654516312361
Validation loss: 2.668865419939823

Epoch: 6| Step: 5
Training loss: 0.5894340962042813
Validation loss: 2.7342401089774944

Epoch: 6| Step: 6
Training loss: 0.36805994802928876
Validation loss: 2.6787656304939866

Epoch: 6| Step: 7
Training loss: 0.5383098434139981
Validation loss: 2.7375000307730524

Epoch: 6| Step: 8
Training loss: 0.5777018261265695
Validation loss: 2.7213342303894947

Epoch: 6| Step: 9
Training loss: 0.5899475208477709
Validation loss: 2.728505168467869

Epoch: 6| Step: 10
Training loss: 0.7740719437590994
Validation loss: 2.713411168177865

Epoch: 6| Step: 11
Training loss: 0.6024273192226854
Validation loss: 2.735244264033734

Epoch: 6| Step: 12
Training loss: 0.6461509928317177
Validation loss: 2.71514627431453

Epoch: 6| Step: 13
Training loss: 0.5804767715906143
Validation loss: 2.679590043648897

Epoch: 497| Step: 0
Training loss: 0.6458462103718702
Validation loss: 2.6423078663346513

Epoch: 6| Step: 1
Training loss: 1.0176002075376538
Validation loss: 2.633890386001357

Epoch: 6| Step: 2
Training loss: 0.5340221388885243
Validation loss: 2.6676694554111724

Epoch: 6| Step: 3
Training loss: 0.4760931705712954
Validation loss: 2.660389154800279

Epoch: 6| Step: 4
Training loss: 0.4720095947763358
Validation loss: 2.6295123750093574

Epoch: 6| Step: 5
Training loss: 0.48787727429316535
Validation loss: 2.724120160189465

Epoch: 6| Step: 6
Training loss: 0.6835186726350344
Validation loss: 2.7127334406379564

Epoch: 6| Step: 7
Training loss: 0.6122531169486466
Validation loss: 2.722631395063238

Epoch: 6| Step: 8
Training loss: 0.5756664580948715
Validation loss: 2.717704476913888

Epoch: 6| Step: 9
Training loss: 0.7236187685119781
Validation loss: 2.7515441865038994

Epoch: 6| Step: 10
Training loss: 0.42525454850205935
Validation loss: 2.676059606325436

Epoch: 6| Step: 11
Training loss: 0.7251111783908549
Validation loss: 2.7602629972666164

Epoch: 6| Step: 12
Training loss: 0.976723619521236
Validation loss: 2.680920464599072

Epoch: 6| Step: 13
Training loss: 0.44014319598550633
Validation loss: 2.7430050637363816

Epoch: 498| Step: 0
Training loss: 0.7189324603477412
Validation loss: 2.6807770585389044

Epoch: 6| Step: 1
Training loss: 0.3926501801063749
Validation loss: 2.758853604172202

Epoch: 6| Step: 2
Training loss: 0.354966007237182
Validation loss: 2.732216097191103

Epoch: 6| Step: 3
Training loss: 0.810392838514323
Validation loss: 2.7352273974825807

Epoch: 6| Step: 4
Training loss: 0.5437603675467767
Validation loss: 2.776774173210854

Epoch: 6| Step: 5
Training loss: 0.8082491375310599
Validation loss: 2.771142645950204

Epoch: 6| Step: 6
Training loss: 0.6655963237835731
Validation loss: 2.7730248659167476

Epoch: 6| Step: 7
Training loss: 0.497209990236695
Validation loss: 2.739794216573002

Epoch: 6| Step: 8
Training loss: 0.5062004912857451
Validation loss: 2.7204303298897656

Epoch: 6| Step: 9
Training loss: 0.607612310161285
Validation loss: 2.7137161950469193

Epoch: 6| Step: 10
Training loss: 0.7334953884039596
Validation loss: 2.73015216088948

Epoch: 6| Step: 11
Training loss: 0.6892620826993192
Validation loss: 2.659653103037941

Epoch: 6| Step: 12
Training loss: 0.5798741762386062
Validation loss: 2.7043584607668203

Epoch: 6| Step: 13
Training loss: 0.3692219155232791
Validation loss: 2.7453857058942037

Epoch: 499| Step: 0
Training loss: 0.4471678647809513
Validation loss: 2.7145227914901375

Epoch: 6| Step: 1
Training loss: 0.5277707666912972
Validation loss: 2.77750476025283

Epoch: 6| Step: 2
Training loss: 0.634856560869123
Validation loss: 2.7875963590699895

Epoch: 6| Step: 3
Training loss: 0.5969391054410038
Validation loss: 2.8059173692702726

Epoch: 6| Step: 4
Training loss: 0.6940428038597314
Validation loss: 2.811726923057391

Epoch: 6| Step: 5
Training loss: 0.4899438247788248
Validation loss: 2.737469576894474

Epoch: 6| Step: 6
Training loss: 0.5273776008196432
Validation loss: 2.6961200923216797

Epoch: 6| Step: 7
Training loss: 0.5525635903646177
Validation loss: 2.71156762501624

Epoch: 6| Step: 8
Training loss: 0.37904184412517894
Validation loss: 2.7133172516576654

Epoch: 6| Step: 9
Training loss: 0.5639694411845888
Validation loss: 2.7028857586487507

Epoch: 6| Step: 10
Training loss: 0.7013223428180817
Validation loss: 2.7316337723193502

Epoch: 6| Step: 11
Training loss: 0.4605973653643032
Validation loss: 2.609427750410232

Epoch: 6| Step: 12
Training loss: 0.6973463380403592
Validation loss: 2.679855489701599

Epoch: 6| Step: 13
Training loss: 0.9371129190521836
Validation loss: 2.67673142540892

Epoch: 500| Step: 0
Training loss: 0.839377056241446
Validation loss: 2.653103749040702

Epoch: 6| Step: 1
Training loss: 0.4847250873052286
Validation loss: 2.689819296235333

Epoch: 6| Step: 2
Training loss: 0.411757314276568
Validation loss: 2.7420402697447193

Epoch: 6| Step: 3
Training loss: 0.8572154915495194
Validation loss: 2.697329208062877

Epoch: 6| Step: 4
Training loss: 0.6232608439714392
Validation loss: 2.7365979123587723

Epoch: 6| Step: 5
Training loss: 0.45605739943945744
Validation loss: 2.7624169545759285

Epoch: 6| Step: 6
Training loss: 0.4975968066395164
Validation loss: 2.7163194044374497

Epoch: 6| Step: 7
Training loss: 0.41174189739558353
Validation loss: 2.6911530617824244

Epoch: 6| Step: 8
Training loss: 0.6028060939640258
Validation loss: 2.704353009481221

Epoch: 6| Step: 9
Training loss: 0.549864770780695
Validation loss: 2.6495590310907624

Epoch: 6| Step: 10
Training loss: 0.6587164034953441
Validation loss: 2.698507050437215

Epoch: 6| Step: 11
Training loss: 0.8981937243581923
Validation loss: 2.630516598202757

Epoch: 6| Step: 12
Training loss: 0.5531284289065185
Validation loss: 2.6441357240290038

Epoch: 6| Step: 13
Training loss: 0.5555581258343474
Validation loss: 2.6362929614976713

Testing loss: 2.581170863624084
