Epoch: 1| Step: 0
Training loss: 6.02178908773287
Validation loss: 5.883570027475566

Epoch: 6| Step: 1
Training loss: 5.5774503241104645
Validation loss: 5.881721169073379

Epoch: 6| Step: 2
Training loss: 6.1555073091626085
Validation loss: 5.880021945194458

Epoch: 6| Step: 3
Training loss: 6.504507995811684
Validation loss: 5.878260390922675

Epoch: 6| Step: 4
Training loss: 5.479753160695146
Validation loss: 5.876537257151038

Epoch: 6| Step: 5
Training loss: 4.936045565241832
Validation loss: 5.874910475677821

Epoch: 6| Step: 6
Training loss: 5.407510423090286
Validation loss: 5.873297830287451

Epoch: 6| Step: 7
Training loss: 6.048114501716953
Validation loss: 5.871665008022057

Epoch: 6| Step: 8
Training loss: 5.846049300120004
Validation loss: 5.870101184915178

Epoch: 6| Step: 9
Training loss: 6.644341790729255
Validation loss: 5.868528250992973

Epoch: 6| Step: 10
Training loss: 6.269526686622171
Validation loss: 5.866964810916229

Epoch: 6| Step: 11
Training loss: 6.361201593383904
Validation loss: 5.865314182886447

Epoch: 6| Step: 12
Training loss: 6.370914721005471
Validation loss: 5.863613619904769

Epoch: 6| Step: 13
Training loss: 5.981081701320514
Validation loss: 5.861877422446825

Epoch: 2| Step: 0
Training loss: 6.34504152878081
Validation loss: 5.859982309021789

Epoch: 6| Step: 1
Training loss: 6.957847654406756
Validation loss: 5.858084601832737

Epoch: 6| Step: 2
Training loss: 5.480579421325544
Validation loss: 5.85604221079853

Epoch: 6| Step: 3
Training loss: 6.3550215682797475
Validation loss: 5.8539638371021265

Epoch: 6| Step: 4
Training loss: 5.68421019262272
Validation loss: 5.8518527289594235

Epoch: 6| Step: 5
Training loss: 4.790010691334175
Validation loss: 5.849467154903701

Epoch: 6| Step: 6
Training loss: 6.070282964254078
Validation loss: 5.847139378572674

Epoch: 6| Step: 7
Training loss: 5.409435061645276
Validation loss: 5.84468351309508

Epoch: 6| Step: 8
Training loss: 4.7923302011353375
Validation loss: 5.841988826834617

Epoch: 6| Step: 9
Training loss: 6.293238799198727
Validation loss: 5.839151487284005

Epoch: 6| Step: 10
Training loss: 7.135005150133505
Validation loss: 5.836341690712557

Epoch: 6| Step: 11
Training loss: 6.600794206864577
Validation loss: 5.8333052044144855

Epoch: 6| Step: 12
Training loss: 4.853332098517068
Validation loss: 5.829865060360254

Epoch: 6| Step: 13
Training loss: 6.041205693340365
Validation loss: 5.8263879391297255

Epoch: 3| Step: 0
Training loss: 6.018109965137746
Validation loss: 5.8228722458602595

Epoch: 6| Step: 1
Training loss: 6.35519894412321
Validation loss: 5.819069871807145

Epoch: 6| Step: 2
Training loss: 4.922671686513648
Validation loss: 5.814937968996084

Epoch: 6| Step: 3
Training loss: 5.13898977690402
Validation loss: 5.810857233045475

Epoch: 6| Step: 4
Training loss: 5.303397604702522
Validation loss: 5.806327577859025

Epoch: 6| Step: 5
Training loss: 6.952093497926092
Validation loss: 5.801593214207668

Epoch: 6| Step: 6
Training loss: 6.4202234228123345
Validation loss: 5.796681691362865

Epoch: 6| Step: 7
Training loss: 6.1447249452941595
Validation loss: 5.791265853441862

Epoch: 6| Step: 8
Training loss: 5.425522690304843
Validation loss: 5.786161353876513

Epoch: 6| Step: 9
Training loss: 5.877673575605995
Validation loss: 5.780208349465651

Epoch: 6| Step: 10
Training loss: 6.06676403987557
Validation loss: 5.773769260728667

Epoch: 6| Step: 11
Training loss: 6.321375282438607
Validation loss: 5.767390393539993

Epoch: 6| Step: 12
Training loss: 5.905811434816835
Validation loss: 5.760359429827554

Epoch: 6| Step: 13
Training loss: 5.512198705073048
Validation loss: 5.7533743259182195

Epoch: 4| Step: 0
Training loss: 5.870045297373172
Validation loss: 5.7458071694482635

Epoch: 6| Step: 1
Training loss: 5.619691675219926
Validation loss: 5.738073751646409

Epoch: 6| Step: 2
Training loss: 6.39202940042965
Validation loss: 5.729966217660431

Epoch: 6| Step: 3
Training loss: 5.481877728384233
Validation loss: 5.721178383457111

Epoch: 6| Step: 4
Training loss: 4.899927816053933
Validation loss: 5.712539858578136

Epoch: 6| Step: 5
Training loss: 6.078160146106612
Validation loss: 5.703539996093672

Epoch: 6| Step: 6
Training loss: 5.665111365709298
Validation loss: 5.694100235664521

Epoch: 6| Step: 7
Training loss: 6.38176473097708
Validation loss: 5.684568103588229

Epoch: 6| Step: 8
Training loss: 5.6669887376400405
Validation loss: 5.674885128836021

Epoch: 6| Step: 9
Training loss: 5.0876386993771865
Validation loss: 5.6648705197716565

Epoch: 6| Step: 10
Training loss: 6.1196689371558834
Validation loss: 5.654576203205872

Epoch: 6| Step: 11
Training loss: 5.283205291127097
Validation loss: 5.643646614420455

Epoch: 6| Step: 12
Training loss: 5.766939504412942
Validation loss: 5.633374063167764

Epoch: 6| Step: 13
Training loss: 6.641801940740143
Validation loss: 5.622088462928839

Epoch: 5| Step: 0
Training loss: 5.726837609566702
Validation loss: 5.611181848329819

Epoch: 6| Step: 1
Training loss: 5.229633609344758
Validation loss: 5.5999302598607015

Epoch: 6| Step: 2
Training loss: 5.494465384053974
Validation loss: 5.589179446708811

Epoch: 6| Step: 3
Training loss: 5.708713082632062
Validation loss: 5.5772478427309675

Epoch: 6| Step: 4
Training loss: 5.317881114019632
Validation loss: 5.565867801077296

Epoch: 6| Step: 5
Training loss: 5.976428460506717
Validation loss: 5.554774859993779

Epoch: 6| Step: 6
Training loss: 6.065753496352751
Validation loss: 5.542542247390385

Epoch: 6| Step: 7
Training loss: 6.614596853968301
Validation loss: 5.531289166960184

Epoch: 6| Step: 8
Training loss: 6.098005950694623
Validation loss: 5.519409149540016

Epoch: 6| Step: 9
Training loss: 5.848409661510354
Validation loss: 5.50826636353996

Epoch: 6| Step: 10
Training loss: 5.0902705566207
Validation loss: 5.497013408226079

Epoch: 6| Step: 11
Training loss: 5.066291048950482
Validation loss: 5.48699543689065

Epoch: 6| Step: 12
Training loss: 5.495065035656426
Validation loss: 5.476708831500967

Epoch: 6| Step: 13
Training loss: 5.228693643075177
Validation loss: 5.466190487583976

Epoch: 6| Step: 0
Training loss: 5.031021965972195
Validation loss: 5.455926767441343

Epoch: 6| Step: 1
Training loss: 6.240587394650718
Validation loss: 5.445979204780475

Epoch: 6| Step: 2
Training loss: 6.1418707362950435
Validation loss: 5.436087735519524

Epoch: 6| Step: 3
Training loss: 5.824121485920745
Validation loss: 5.426389692597365

Epoch: 6| Step: 4
Training loss: 5.215441540233648
Validation loss: 5.41613738579661

Epoch: 6| Step: 5
Training loss: 6.668428982817239
Validation loss: 5.406463324834448

Epoch: 6| Step: 6
Training loss: 5.922265354466223
Validation loss: 5.396514859356759

Epoch: 6| Step: 7
Training loss: 4.694191594183219
Validation loss: 5.3869001262577605

Epoch: 6| Step: 8
Training loss: 4.623785117109585
Validation loss: 5.37732675743568

Epoch: 6| Step: 9
Training loss: 5.193657954349453
Validation loss: 5.36848939582133

Epoch: 6| Step: 10
Training loss: 5.7236817153952915
Validation loss: 5.359197674812192

Epoch: 6| Step: 11
Training loss: 4.032689037302781
Validation loss: 5.350069024184417

Epoch: 6| Step: 12
Training loss: 5.786630137514292
Validation loss: 5.341682286867026

Epoch: 6| Step: 13
Training loss: 5.524551732446934
Validation loss: 5.333349744453612

Epoch: 7| Step: 0
Training loss: 5.954435589721219
Validation loss: 5.32530807654616

Epoch: 6| Step: 1
Training loss: 6.301814033071896
Validation loss: 5.317677118232815

Epoch: 6| Step: 2
Training loss: 6.135093935221705
Validation loss: 5.309884987284192

Epoch: 6| Step: 3
Training loss: 4.853808781388004
Validation loss: 5.302214895038883

Epoch: 6| Step: 4
Training loss: 5.453721677823333
Validation loss: 5.295129388963971

Epoch: 6| Step: 5
Training loss: 5.240283876257065
Validation loss: 5.287398481784766

Epoch: 6| Step: 6
Training loss: 4.650605127481564
Validation loss: 5.280627558216907

Epoch: 6| Step: 7
Training loss: 5.451716287531508
Validation loss: 5.274000530562593

Epoch: 6| Step: 8
Training loss: 5.795775933967583
Validation loss: 5.2675531405831295

Epoch: 6| Step: 9
Training loss: 4.3218984607382485
Validation loss: 5.260529509992749

Epoch: 6| Step: 10
Training loss: 5.542466681917539
Validation loss: 5.253727240744962

Epoch: 6| Step: 11
Training loss: 5.0233737116867605
Validation loss: 5.24770162620612

Epoch: 6| Step: 12
Training loss: 5.34790395158842
Validation loss: 5.240842825833021

Epoch: 6| Step: 13
Training loss: 5.20639091383429
Validation loss: 5.234399140715087

Epoch: 8| Step: 0
Training loss: 6.295611763603863
Validation loss: 5.228199184124745

Epoch: 6| Step: 1
Training loss: 5.805604187164962
Validation loss: 5.2215386590366375

Epoch: 6| Step: 2
Training loss: 5.566429207737745
Validation loss: 5.2150720362992775

Epoch: 6| Step: 3
Training loss: 4.931153286564483
Validation loss: 5.208191445007404

Epoch: 6| Step: 4
Training loss: 5.184701003573877
Validation loss: 5.202042231195592

Epoch: 6| Step: 5
Training loss: 4.690029834904563
Validation loss: 5.195245284408158

Epoch: 6| Step: 6
Training loss: 4.878266242925373
Validation loss: 5.188877122081963

Epoch: 6| Step: 7
Training loss: 5.295907351348989
Validation loss: 5.1825012266897055

Epoch: 6| Step: 8
Training loss: 5.3115010837057195
Validation loss: 5.1766334609428

Epoch: 6| Step: 9
Training loss: 5.83664994187122
Validation loss: 5.1703922724014495

Epoch: 6| Step: 10
Training loss: 4.8223476966866725
Validation loss: 5.164623174273889

Epoch: 6| Step: 11
Training loss: 5.2059058470622155
Validation loss: 5.158433240047286

Epoch: 6| Step: 12
Training loss: 5.423487882344398
Validation loss: 5.153396495038873

Epoch: 6| Step: 13
Training loss: 4.862412855451033
Validation loss: 5.14788244223967

Epoch: 9| Step: 0
Training loss: 4.20342721526184
Validation loss: 5.142917944912027

Epoch: 6| Step: 1
Training loss: 5.015431813355064
Validation loss: 5.13735081563576

Epoch: 6| Step: 2
Training loss: 4.920627399542354
Validation loss: 5.1315292697480475

Epoch: 6| Step: 3
Training loss: 5.461194906867087
Validation loss: 5.126880486836625

Epoch: 6| Step: 4
Training loss: 4.899042752243101
Validation loss: 5.121305452108196

Epoch: 6| Step: 5
Training loss: 5.933892690173635
Validation loss: 5.116377143662517

Epoch: 6| Step: 6
Training loss: 5.824617941446319
Validation loss: 5.112018457444071

Epoch: 6| Step: 7
Training loss: 5.825095363376606
Validation loss: 5.1065019157085105

Epoch: 6| Step: 8
Training loss: 5.638087666198379
Validation loss: 5.1014487471465575

Epoch: 6| Step: 9
Training loss: 4.99680970455257
Validation loss: 5.096238228699563

Epoch: 6| Step: 10
Training loss: 4.892441287382842
Validation loss: 5.091520043658914

Epoch: 6| Step: 11
Training loss: 4.532553018469213
Validation loss: 5.087077039027918

Epoch: 6| Step: 12
Training loss: 5.534331072434276
Validation loss: 5.0826360609935035

Epoch: 6| Step: 13
Training loss: 5.270514959839743
Validation loss: 5.078054887336497

Epoch: 10| Step: 0
Training loss: 5.663996160710645
Validation loss: 5.073419168742868

Epoch: 6| Step: 1
Training loss: 5.428194699803481
Validation loss: 5.068520439396499

Epoch: 6| Step: 2
Training loss: 4.889612842671769
Validation loss: 5.06477013069158

Epoch: 6| Step: 3
Training loss: 4.547006716573708
Validation loss: 5.060612880168854

Epoch: 6| Step: 4
Training loss: 5.122569554584177
Validation loss: 5.0558220731376045

Epoch: 6| Step: 5
Training loss: 4.923637534738552
Validation loss: 5.051909589893268

Epoch: 6| Step: 6
Training loss: 4.522259230986885
Validation loss: 5.046831506752333

Epoch: 6| Step: 7
Training loss: 5.77551645058657
Validation loss: 5.042441799803213

Epoch: 6| Step: 8
Training loss: 4.105291738423515
Validation loss: 5.037366919893407

Epoch: 6| Step: 9
Training loss: 4.953209716842548
Validation loss: 5.0329259762331935

Epoch: 6| Step: 10
Training loss: 5.522239630706045
Validation loss: 5.028809739504817

Epoch: 6| Step: 11
Training loss: 5.773609287870489
Validation loss: 5.024606302758591

Epoch: 6| Step: 12
Training loss: 5.682127374732596
Validation loss: 5.0206363317481335

Epoch: 6| Step: 13
Training loss: 5.128963891407818
Validation loss: 5.016563890149981

Epoch: 11| Step: 0
Training loss: 4.916011939125059
Validation loss: 5.012119260361049

Epoch: 6| Step: 1
Training loss: 5.141697548516436
Validation loss: 5.008271020299583

Epoch: 6| Step: 2
Training loss: 4.3809275118001505
Validation loss: 5.003913396968696

Epoch: 6| Step: 3
Training loss: 5.061359041470945
Validation loss: 4.999767107308033

Epoch: 6| Step: 4
Training loss: 4.654338265001653
Validation loss: 4.9958358272560055

Epoch: 6| Step: 5
Training loss: 4.907435960240075
Validation loss: 4.99168617147075

Epoch: 6| Step: 6
Training loss: 5.395032059766033
Validation loss: 4.987715396038253

Epoch: 6| Step: 7
Training loss: 5.786579706502541
Validation loss: 4.983734376690069

Epoch: 6| Step: 8
Training loss: 4.991066390399842
Validation loss: 4.979774767826478

Epoch: 6| Step: 9
Training loss: 5.408364295968806
Validation loss: 4.975663212159582

Epoch: 6| Step: 10
Training loss: 5.451010745054553
Validation loss: 4.971837042458439

Epoch: 6| Step: 11
Training loss: 5.070229175511884
Validation loss: 4.967610482438488

Epoch: 6| Step: 12
Training loss: 5.028305993103276
Validation loss: 4.963987871456981

Epoch: 6| Step: 13
Training loss: 5.2203143853118785
Validation loss: 4.959889731309443

Epoch: 12| Step: 0
Training loss: 4.833140314567017
Validation loss: 4.955883232871703

Epoch: 6| Step: 1
Training loss: 5.8018132894008545
Validation loss: 4.952029647611036

Epoch: 6| Step: 2
Training loss: 5.933656753697767
Validation loss: 4.948114084688918

Epoch: 6| Step: 3
Training loss: 5.649066219979621
Validation loss: 4.943841169941733

Epoch: 6| Step: 4
Training loss: 5.147643148127962
Validation loss: 4.9396600625868174

Epoch: 6| Step: 5
Training loss: 5.241892776504599
Validation loss: 4.935627739277456

Epoch: 6| Step: 6
Training loss: 4.3052683471267486
Validation loss: 4.930996245030598

Epoch: 6| Step: 7
Training loss: 4.906791511343336
Validation loss: 4.926994478850655

Epoch: 6| Step: 8
Training loss: 4.57081911588467
Validation loss: 4.923057906483944

Epoch: 6| Step: 9
Training loss: 5.275673173373326
Validation loss: 4.919240514911892

Epoch: 6| Step: 10
Training loss: 5.178295011612888
Validation loss: 4.914927848630419

Epoch: 6| Step: 11
Training loss: 4.408936892020827
Validation loss: 4.9110749123007835

Epoch: 6| Step: 12
Training loss: 5.3270389647035365
Validation loss: 4.906754842325251

Epoch: 6| Step: 13
Training loss: 3.7543898002087666
Validation loss: 4.902925762264144

Epoch: 13| Step: 0
Training loss: 5.482132760345264
Validation loss: 4.898797824551871

Epoch: 6| Step: 1
Training loss: 4.700670381176573
Validation loss: 4.894921622371305

Epoch: 6| Step: 2
Training loss: 4.5830755450260705
Validation loss: 4.89131346580405

Epoch: 6| Step: 3
Training loss: 5.893503472359284
Validation loss: 4.887460320483195

Epoch: 6| Step: 4
Training loss: 4.990014595820728
Validation loss: 4.883456988716552

Epoch: 6| Step: 5
Training loss: 4.32932262170342
Validation loss: 4.879168106109294

Epoch: 6| Step: 6
Training loss: 4.96512610760334
Validation loss: 4.875048319259236

Epoch: 6| Step: 7
Training loss: 5.185738137951086
Validation loss: 4.871464988187232

Epoch: 6| Step: 8
Training loss: 5.154341095810211
Validation loss: 4.867106478339731

Epoch: 6| Step: 9
Training loss: 5.178320058349907
Validation loss: 4.863010399973273

Epoch: 6| Step: 10
Training loss: 5.208243936407265
Validation loss: 4.859303530119437

Epoch: 6| Step: 11
Training loss: 5.5473962673203445
Validation loss: 4.854958411004885

Epoch: 6| Step: 12
Training loss: 4.318227309575999
Validation loss: 4.85068771494122

Epoch: 6| Step: 13
Training loss: 4.1434061175270696
Validation loss: 4.846694346737603

Epoch: 14| Step: 0
Training loss: 4.70236149163614
Validation loss: 4.84278978243864

Epoch: 6| Step: 1
Training loss: 5.356361186810895
Validation loss: 4.8386423561068534

Epoch: 6| Step: 2
Training loss: 4.801923350595075
Validation loss: 4.834366567382823

Epoch: 6| Step: 3
Training loss: 5.088093431058788
Validation loss: 4.83030476997966

Epoch: 6| Step: 4
Training loss: 5.196658219743918
Validation loss: 4.826338354100773

Epoch: 6| Step: 5
Training loss: 4.96996441281509
Validation loss: 4.822271030567714

Epoch: 6| Step: 6
Training loss: 5.754019949126973
Validation loss: 4.818158971657086

Epoch: 6| Step: 7
Training loss: 4.743860392737254
Validation loss: 4.81368148634764

Epoch: 6| Step: 8
Training loss: 5.095323939633739
Validation loss: 4.809033288810991

Epoch: 6| Step: 9
Training loss: 4.567461216620457
Validation loss: 4.804603422923117

Epoch: 6| Step: 10
Training loss: 4.983468765578851
Validation loss: 4.800190991999385

Epoch: 6| Step: 11
Training loss: 5.683747783028728
Validation loss: 4.796339570522174

Epoch: 6| Step: 12
Training loss: 2.8757744450943328
Validation loss: 4.791615289606173

Epoch: 6| Step: 13
Training loss: 4.790305743245365
Validation loss: 4.787831980696317

Epoch: 15| Step: 0
Training loss: 5.543394560316158
Validation loss: 4.783285302021815

Epoch: 6| Step: 1
Training loss: 4.411787516965049
Validation loss: 4.7790831931334345

Epoch: 6| Step: 2
Training loss: 5.321211549863286
Validation loss: 4.775025049113934

Epoch: 6| Step: 3
Training loss: 4.930881555134599
Validation loss: 4.77079847342514

Epoch: 6| Step: 4
Training loss: 5.403898223743045
Validation loss: 4.766602562871233

Epoch: 6| Step: 5
Training loss: 3.77145896203731
Validation loss: 4.7615202689484

Epoch: 6| Step: 6
Training loss: 4.966409575872431
Validation loss: 4.757006146231132

Epoch: 6| Step: 7
Training loss: 5.3968459348884394
Validation loss: 4.7527680613506815

Epoch: 6| Step: 8
Training loss: 4.477809872024492
Validation loss: 4.748765818559582

Epoch: 6| Step: 9
Training loss: 5.275001214917662
Validation loss: 4.744079681587168

Epoch: 6| Step: 10
Training loss: 4.6878293748212
Validation loss: 4.738953595367508

Epoch: 6| Step: 11
Training loss: 4.315366151906975
Validation loss: 4.7336287209301435

Epoch: 6| Step: 12
Training loss: 5.442679207707157
Validation loss: 4.729061086319146

Epoch: 6| Step: 13
Training loss: 3.979550421353059
Validation loss: 4.7243353858993

Epoch: 16| Step: 0
Training loss: 4.822522514611069
Validation loss: 4.71989891768371

Epoch: 6| Step: 1
Training loss: 4.276053065828036
Validation loss: 4.715179473546377

Epoch: 6| Step: 2
Training loss: 5.27117573024288
Validation loss: 4.709666015705592

Epoch: 6| Step: 3
Training loss: 4.1104894947084345
Validation loss: 4.705282770322075

Epoch: 6| Step: 4
Training loss: 4.716942851649006
Validation loss: 4.700710821847214

Epoch: 6| Step: 5
Training loss: 5.393249757273988
Validation loss: 4.696102234599982

Epoch: 6| Step: 6
Training loss: 5.28195781591832
Validation loss: 4.690796909151327

Epoch: 6| Step: 7
Training loss: 4.932091563541994
Validation loss: 4.686490234121718

Epoch: 6| Step: 8
Training loss: 4.852549969957805
Validation loss: 4.681388651921278

Epoch: 6| Step: 9
Training loss: 4.996198162452247
Validation loss: 4.677092242781119

Epoch: 6| Step: 10
Training loss: 4.825078206589716
Validation loss: 4.671666271433347

Epoch: 6| Step: 11
Training loss: 4.312845409768875
Validation loss: 4.666591995640942

Epoch: 6| Step: 12
Training loss: 4.971693786349337
Validation loss: 4.662173844589417

Epoch: 6| Step: 13
Training loss: 4.468849020974599
Validation loss: 4.65647614546473

Epoch: 17| Step: 0
Training loss: 5.085829866972647
Validation loss: 4.651782493356591

Epoch: 6| Step: 1
Training loss: 4.162857654316042
Validation loss: 4.64716875301798

Epoch: 6| Step: 2
Training loss: 5.055699431406366
Validation loss: 4.642430186639477

Epoch: 6| Step: 3
Training loss: 3.4380198692471065
Validation loss: 4.636985507609261

Epoch: 6| Step: 4
Training loss: 5.539765952223967
Validation loss: 4.632072814250501

Epoch: 6| Step: 5
Training loss: 4.813810492100559
Validation loss: 4.627030313603992

Epoch: 6| Step: 6
Training loss: 5.578102090398508
Validation loss: 4.62208257195734

Epoch: 6| Step: 7
Training loss: 5.317440832012438
Validation loss: 4.61682017285753

Epoch: 6| Step: 8
Training loss: 4.345410804775063
Validation loss: 4.611439457020264

Epoch: 6| Step: 9
Training loss: 4.172746317308696
Validation loss: 4.606360498256367

Epoch: 6| Step: 10
Training loss: 3.839543343451494
Validation loss: 4.6018270126162495

Epoch: 6| Step: 11
Training loss: 5.226806087548213
Validation loss: 4.596899151214564

Epoch: 6| Step: 12
Training loss: 4.4746196052371054
Validation loss: 4.59163487325878

Epoch: 6| Step: 13
Training loss: 4.852288184203262
Validation loss: 4.586869257252694

Epoch: 18| Step: 0
Training loss: 5.39102021026361
Validation loss: 4.581665891719201

Epoch: 6| Step: 1
Training loss: 4.428855965961901
Validation loss: 4.5761715102999485

Epoch: 6| Step: 2
Training loss: 4.5893234412533515
Validation loss: 4.5707465419451925

Epoch: 6| Step: 3
Training loss: 4.250528414918582
Validation loss: 4.565932319702053

Epoch: 6| Step: 4
Training loss: 4.6890720020313585
Validation loss: 4.561060395283428

Epoch: 6| Step: 5
Training loss: 5.411875009022404
Validation loss: 4.555107921741365

Epoch: 6| Step: 6
Training loss: 4.844965825230994
Validation loss: 4.550121917767999

Epoch: 6| Step: 7
Training loss: 3.941304745231913
Validation loss: 4.545237784997165

Epoch: 6| Step: 8
Training loss: 4.790737338406841
Validation loss: 4.540055342013456

Epoch: 6| Step: 9
Training loss: 4.214790350970819
Validation loss: 4.5343606553835585

Epoch: 6| Step: 10
Training loss: 4.63320360253665
Validation loss: 4.529208668382738

Epoch: 6| Step: 11
Training loss: 4.773388551751387
Validation loss: 4.524471816960864

Epoch: 6| Step: 12
Training loss: 4.348460764793586
Validation loss: 4.519352607416594

Epoch: 6| Step: 13
Training loss: 4.94009254090894
Validation loss: 4.514316479245828

Epoch: 19| Step: 0
Training loss: 4.190196521311027
Validation loss: 4.5086061339890495

Epoch: 6| Step: 1
Training loss: 4.538523761864833
Validation loss: 4.50367410220862

Epoch: 6| Step: 2
Training loss: 4.860228239751757
Validation loss: 4.498564561853832

Epoch: 6| Step: 3
Training loss: 4.3541486578512645
Validation loss: 4.493695611319527

Epoch: 6| Step: 4
Training loss: 4.923941042375908
Validation loss: 4.488182002586829

Epoch: 6| Step: 5
Training loss: 5.190640521499972
Validation loss: 4.48366405420641

Epoch: 6| Step: 6
Training loss: 5.132416360046318
Validation loss: 4.477623832008361

Epoch: 6| Step: 7
Training loss: 4.294398478439789
Validation loss: 4.473138144129427

Epoch: 6| Step: 8
Training loss: 4.262025984643268
Validation loss: 4.467580753472512

Epoch: 6| Step: 9
Training loss: 4.896695303282457
Validation loss: 4.462168063401426

Epoch: 6| Step: 10
Training loss: 4.312855581468218
Validation loss: 4.456804791870535

Epoch: 6| Step: 11
Training loss: 4.89624052045351
Validation loss: 4.451349450999795

Epoch: 6| Step: 12
Training loss: 3.791560091190678
Validation loss: 4.446173541498649

Epoch: 6| Step: 13
Training loss: 4.609841740140395
Validation loss: 4.44078914545664

Epoch: 20| Step: 0
Training loss: 4.004613361721688
Validation loss: 4.435388841925491

Epoch: 6| Step: 1
Training loss: 4.975388225187358
Validation loss: 4.429732872463148

Epoch: 6| Step: 2
Training loss: 4.404305536299687
Validation loss: 4.425555024477557

Epoch: 6| Step: 3
Training loss: 4.390106713599011
Validation loss: 4.420177497838321

Epoch: 6| Step: 4
Training loss: 5.331291622522621
Validation loss: 4.414397154418537

Epoch: 6| Step: 5
Training loss: 4.624416005148312
Validation loss: 4.410018968317899

Epoch: 6| Step: 6
Training loss: 4.8505988154462125
Validation loss: 4.403897787143168

Epoch: 6| Step: 7
Training loss: 3.943785721364694
Validation loss: 4.398106799163678

Epoch: 6| Step: 8
Training loss: 3.7488842893882666
Validation loss: 4.3925282255136855

Epoch: 6| Step: 9
Training loss: 4.739074187825597
Validation loss: 4.387691418275082

Epoch: 6| Step: 10
Training loss: 4.780963963947077
Validation loss: 4.382320782191666

Epoch: 6| Step: 11
Training loss: 4.8900930097038735
Validation loss: 4.376659986651151

Epoch: 6| Step: 12
Training loss: 4.405487210958394
Validation loss: 4.3715747685625805

Epoch: 6| Step: 13
Training loss: 4.068736996021966
Validation loss: 4.366952433711495

Epoch: 21| Step: 0
Training loss: 4.930201677449135
Validation loss: 4.3608161613252125

Epoch: 6| Step: 1
Training loss: 4.159343744012915
Validation loss: 4.355710730794374

Epoch: 6| Step: 2
Training loss: 4.932987517187385
Validation loss: 4.350314095363959

Epoch: 6| Step: 3
Training loss: 4.715438388092302
Validation loss: 4.345183540743312

Epoch: 6| Step: 4
Training loss: 4.495782571293314
Validation loss: 4.339229710834432

Epoch: 6| Step: 5
Training loss: 4.149410270245678
Validation loss: 4.333868482752739

Epoch: 6| Step: 6
Training loss: 4.970811716028977
Validation loss: 4.32829513858066

Epoch: 6| Step: 7
Training loss: 3.8762789430740203
Validation loss: 4.322371734222232

Epoch: 6| Step: 8
Training loss: 3.2728667205424924
Validation loss: 4.317059212342246

Epoch: 6| Step: 9
Training loss: 3.845584090653982
Validation loss: 4.312053233422598

Epoch: 6| Step: 10
Training loss: 4.390352179579923
Validation loss: 4.306516209287989

Epoch: 6| Step: 11
Training loss: 4.768603385381334
Validation loss: 4.302266995232704

Epoch: 6| Step: 12
Training loss: 4.366904043098596
Validation loss: 4.296433896629706

Epoch: 6| Step: 13
Training loss: 5.124497551828023
Validation loss: 4.291608359425321

Epoch: 22| Step: 0
Training loss: 5.234536786212409
Validation loss: 4.286389294327527

Epoch: 6| Step: 1
Training loss: 4.634836819275151
Validation loss: 4.280276074047119

Epoch: 6| Step: 2
Training loss: 4.944974625602397
Validation loss: 4.275210722252826

Epoch: 6| Step: 3
Training loss: 4.527311731444155
Validation loss: 4.2695517439145325

Epoch: 6| Step: 4
Training loss: 4.534895068787382
Validation loss: 4.264136309629659

Epoch: 6| Step: 5
Training loss: 3.6445909108862744
Validation loss: 4.25800605357325

Epoch: 6| Step: 6
Training loss: 4.709170691824233
Validation loss: 4.252794674563559

Epoch: 6| Step: 7
Training loss: 3.2817189199440957
Validation loss: 4.247176560153063

Epoch: 6| Step: 8
Training loss: 4.424185105629844
Validation loss: 4.241979941670046

Epoch: 6| Step: 9
Training loss: 2.6703916302469235
Validation loss: 4.236984987573391

Epoch: 6| Step: 10
Training loss: 4.703678542097937
Validation loss: 4.231615300376975

Epoch: 6| Step: 11
Training loss: 4.284414416687641
Validation loss: 4.227228907746149

Epoch: 6| Step: 12
Training loss: 4.7015457289939535
Validation loss: 4.221620445003452

Epoch: 6| Step: 13
Training loss: 4.382022562084675
Validation loss: 4.215490197924218

Epoch: 23| Step: 0
Training loss: 3.667428688859023
Validation loss: 4.212775136714363

Epoch: 6| Step: 1
Training loss: 4.5442386075892935
Validation loss: 4.212222137493657

Epoch: 6| Step: 2
Training loss: 3.726515667699043
Validation loss: 4.20953464672594

Epoch: 6| Step: 3
Training loss: 5.581650931213804
Validation loss: 4.1999688949644165

Epoch: 6| Step: 4
Training loss: 4.499572309726668
Validation loss: 4.191952478107905

Epoch: 6| Step: 5
Training loss: 4.10271282232152
Validation loss: 4.1868182903723286

Epoch: 6| Step: 6
Training loss: 4.688027314090251
Validation loss: 4.184429029515225

Epoch: 6| Step: 7
Training loss: 4.540247330839512
Validation loss: 4.178211614699607

Epoch: 6| Step: 8
Training loss: 3.98348665993105
Validation loss: 4.171427422944499

Epoch: 6| Step: 9
Training loss: 4.5241561608653065
Validation loss: 4.163465217281037

Epoch: 6| Step: 10
Training loss: 3.8243072780068563
Validation loss: 4.158431090363381

Epoch: 6| Step: 11
Training loss: 3.950545966165453
Validation loss: 4.154562662598812

Epoch: 6| Step: 12
Training loss: 4.20006214277525
Validation loss: 4.150227152877462

Epoch: 6| Step: 13
Training loss: 4.170699850582914
Validation loss: 4.144144560919037

Epoch: 24| Step: 0
Training loss: 4.484218049708777
Validation loss: 4.136921273407978

Epoch: 6| Step: 1
Training loss: 4.800106190460506
Validation loss: 4.131775637614679

Epoch: 6| Step: 2
Training loss: 4.14796160538358
Validation loss: 4.126772759716648

Epoch: 6| Step: 3
Training loss: 3.366600605030104
Validation loss: 4.122984576842625

Epoch: 6| Step: 4
Training loss: 3.9441166340061553
Validation loss: 4.119445760539085

Epoch: 6| Step: 5
Training loss: 4.210282934834359
Validation loss: 4.111151095072734

Epoch: 6| Step: 6
Training loss: 4.482597823003738
Validation loss: 4.1054063012490944

Epoch: 6| Step: 7
Training loss: 4.860967148359639
Validation loss: 4.101128274850739

Epoch: 6| Step: 8
Training loss: 4.62516495694005
Validation loss: 4.095050653680775

Epoch: 6| Step: 9
Training loss: 3.1259619186044065
Validation loss: 4.090356385980202

Epoch: 6| Step: 10
Training loss: 4.5428335574789696
Validation loss: 4.084444744640262

Epoch: 6| Step: 11
Training loss: 4.245589716806963
Validation loss: 4.078292609384174

Epoch: 6| Step: 12
Training loss: 4.119938837727003
Validation loss: 4.074388490129751

Epoch: 6| Step: 13
Training loss: 3.9711877740073915
Validation loss: 4.068526761620223

Epoch: 25| Step: 0
Training loss: 4.201433827113463
Validation loss: 4.063517633774653

Epoch: 6| Step: 1
Training loss: 3.736102099843052
Validation loss: 4.057729140052045

Epoch: 6| Step: 2
Training loss: 3.8264557605091674
Validation loss: 4.0521783237388185

Epoch: 6| Step: 3
Training loss: 2.8646911230903918
Validation loss: 4.046841143806457

Epoch: 6| Step: 4
Training loss: 4.6679765134611175
Validation loss: 4.042745184130434

Epoch: 6| Step: 5
Training loss: 4.04798903283605
Validation loss: 4.037203254463257

Epoch: 6| Step: 6
Training loss: 4.638129902549078
Validation loss: 4.032145142050782

Epoch: 6| Step: 7
Training loss: 4.3841130847964225
Validation loss: 4.026486778904224

Epoch: 6| Step: 8
Training loss: 4.3010655169735355
Validation loss: 4.0214288827217946

Epoch: 6| Step: 9
Training loss: 4.824682693721192
Validation loss: 4.016541778369332

Epoch: 6| Step: 10
Training loss: 4.553098005373177
Validation loss: 4.011609594438081

Epoch: 6| Step: 11
Training loss: 4.13165532373059
Validation loss: 4.005808269014159

Epoch: 6| Step: 12
Training loss: 4.2650125923283895
Validation loss: 3.999702720721419

Epoch: 6| Step: 13
Training loss: 3.364113238457432
Validation loss: 3.9948793656107404

Epoch: 26| Step: 0
Training loss: 4.3176579244299305
Validation loss: 3.988965649841732

Epoch: 6| Step: 1
Training loss: 3.8164927102859787
Validation loss: 3.9840480296292333

Epoch: 6| Step: 2
Training loss: 4.28815076688212
Validation loss: 3.9787010732685184

Epoch: 6| Step: 3
Training loss: 3.5628853305090993
Validation loss: 3.9726285830334214

Epoch: 6| Step: 4
Training loss: 4.630671760816232
Validation loss: 3.967457297948052

Epoch: 6| Step: 5
Training loss: 3.675297996220572
Validation loss: 3.962570866894718

Epoch: 6| Step: 6
Training loss: 3.8268162572732902
Validation loss: 3.9568492047936212

Epoch: 6| Step: 7
Training loss: 4.812329177797225
Validation loss: 3.9517116709033844

Epoch: 6| Step: 8
Training loss: 3.9940683969248654
Validation loss: 3.9466353914808736

Epoch: 6| Step: 9
Training loss: 4.351205259825692
Validation loss: 3.9419835011017454

Epoch: 6| Step: 10
Training loss: 4.4321527634882445
Validation loss: 3.935890252189545

Epoch: 6| Step: 11
Training loss: 4.027177986707453
Validation loss: 3.9300658673953857

Epoch: 6| Step: 12
Training loss: 3.9694292583550297
Validation loss: 3.924648585857224

Epoch: 6| Step: 13
Training loss: 3.2471640024077493
Validation loss: 3.9202385638104067

Epoch: 27| Step: 0
Training loss: 3.518032216230897
Validation loss: 3.914813854717724

Epoch: 6| Step: 1
Training loss: 4.020989186061538
Validation loss: 3.9096319080143

Epoch: 6| Step: 2
Training loss: 4.061800852549456
Validation loss: 3.9040933173965957

Epoch: 6| Step: 3
Training loss: 3.7985666533167404
Validation loss: 3.8989926479961996

Epoch: 6| Step: 4
Training loss: 4.189771576984785
Validation loss: 3.893824026874666

Epoch: 6| Step: 5
Training loss: 3.961727627830962
Validation loss: 3.888942758247629

Epoch: 6| Step: 6
Training loss: 4.5232089549885135
Validation loss: 3.8839403608505476

Epoch: 6| Step: 7
Training loss: 4.0714086422157605
Validation loss: 3.8784791852812086

Epoch: 6| Step: 8
Training loss: 4.1114357542325335
Validation loss: 3.874379180070682

Epoch: 6| Step: 9
Training loss: 3.582553039285933
Validation loss: 3.868587561562519

Epoch: 6| Step: 10
Training loss: 4.067854184683453
Validation loss: 3.8636368091943387

Epoch: 6| Step: 11
Training loss: 4.635375679206372
Validation loss: 3.8578743430241116

Epoch: 6| Step: 12
Training loss: 3.5191163761617386
Validation loss: 3.852668299116915

Epoch: 6| Step: 13
Training loss: 3.983049957751269
Validation loss: 3.8475817264885306

Epoch: 28| Step: 0
Training loss: 3.821462633620307
Validation loss: 3.843522765516523

Epoch: 6| Step: 1
Training loss: 3.4106770715273935
Validation loss: 3.837469122780039

Epoch: 6| Step: 2
Training loss: 4.573419333299031
Validation loss: 3.83363591257712

Epoch: 6| Step: 3
Training loss: 4.082413913732549
Validation loss: 3.827583949461776

Epoch: 6| Step: 4
Training loss: 3.331318786941516
Validation loss: 3.8228347658675026

Epoch: 6| Step: 5
Training loss: 4.505100750235825
Validation loss: 3.8176152251349014

Epoch: 6| Step: 6
Training loss: 3.6384708432959374
Validation loss: 3.8130287262382807

Epoch: 6| Step: 7
Training loss: 4.440280097168262
Validation loss: 3.807869365957828

Epoch: 6| Step: 8
Training loss: 3.859661138019994
Validation loss: 3.8032365835345145

Epoch: 6| Step: 9
Training loss: 4.2659961133779145
Validation loss: 3.7979377128002594

Epoch: 6| Step: 10
Training loss: 3.26797721874463
Validation loss: 3.792797604650226

Epoch: 6| Step: 11
Training loss: 4.335573693211497
Validation loss: 3.7876080949757585

Epoch: 6| Step: 12
Training loss: 3.388920931499591
Validation loss: 3.7825550107785935

Epoch: 6| Step: 13
Training loss: 3.9607557145939305
Validation loss: 3.777492148144832

Epoch: 29| Step: 0
Training loss: 3.1269796585968255
Validation loss: 3.772306073873124

Epoch: 6| Step: 1
Training loss: 4.20840292895088
Validation loss: 3.7670442853254795

Epoch: 6| Step: 2
Training loss: 4.191001680585432
Validation loss: 3.7624188039473747

Epoch: 6| Step: 3
Training loss: 3.646439652661611
Validation loss: 3.7573441539398322

Epoch: 6| Step: 4
Training loss: 4.119224898379273
Validation loss: 3.752260056901321

Epoch: 6| Step: 5
Training loss: 3.83550103029335
Validation loss: 3.747315314697893

Epoch: 6| Step: 6
Training loss: 4.089965935077902
Validation loss: 3.7429545020666515

Epoch: 6| Step: 7
Training loss: 3.783788412231207
Validation loss: 3.7375442272618695

Epoch: 6| Step: 8
Training loss: 3.4761592331071394
Validation loss: 3.7326485701245677

Epoch: 6| Step: 9
Training loss: 4.3265047311284155
Validation loss: 3.727364443815695

Epoch: 6| Step: 10
Training loss: 3.6673965739077166
Validation loss: 3.722151901915699

Epoch: 6| Step: 11
Training loss: 3.478333577142502
Validation loss: 3.7173257873391066

Epoch: 6| Step: 12
Training loss: 3.873054754467527
Validation loss: 3.712436306425246

Epoch: 6| Step: 13
Training loss: 4.226277734890555
Validation loss: 3.706980054720909

Epoch: 30| Step: 0
Training loss: 4.051673195029591
Validation loss: 3.7022770636507394

Epoch: 6| Step: 1
Training loss: 4.28966947335967
Validation loss: 3.6966402600041492

Epoch: 6| Step: 2
Training loss: 4.70937401177308
Validation loss: 3.692323062887151

Epoch: 6| Step: 3
Training loss: 3.9722133153239043
Validation loss: 3.6864537624486373

Epoch: 6| Step: 4
Training loss: 3.434695122527878
Validation loss: 3.682266087782676

Epoch: 6| Step: 5
Training loss: 3.5622186382347327
Validation loss: 3.678387800457837

Epoch: 6| Step: 6
Training loss: 4.414035277156098
Validation loss: 3.6735703254331358

Epoch: 6| Step: 7
Training loss: 3.5537275757888875
Validation loss: 3.6672211285612146

Epoch: 6| Step: 8
Training loss: 3.9813287796059194
Validation loss: 3.66057836920488

Epoch: 6| Step: 9
Training loss: 3.2385646939903245
Validation loss: 3.6552886568500504

Epoch: 6| Step: 10
Training loss: 3.216503655712506
Validation loss: 3.6508682289594936

Epoch: 6| Step: 11
Training loss: 4.299980012714153
Validation loss: 3.6462530421315273

Epoch: 6| Step: 12
Training loss: 3.514646538100348
Validation loss: 3.6423498169067594

Epoch: 6| Step: 13
Training loss: 2.5209179278174654
Validation loss: 3.636013248027787

Epoch: 31| Step: 0
Training loss: 3.4991148783143182
Validation loss: 3.6321127815857213

Epoch: 6| Step: 1
Training loss: 3.4716409544252804
Validation loss: 3.62651216821835

Epoch: 6| Step: 2
Training loss: 4.0132232489542945
Validation loss: 3.6222615257099298

Epoch: 6| Step: 3
Training loss: 4.1462065306700175
Validation loss: 3.618090078238397

Epoch: 6| Step: 4
Training loss: 3.9354121409939293
Validation loss: 3.6138559685107747

Epoch: 6| Step: 5
Training loss: 3.483497680242781
Validation loss: 3.608679524143029

Epoch: 6| Step: 6
Training loss: 3.490094746175277
Validation loss: 3.6042160662902103

Epoch: 6| Step: 7
Training loss: 3.282002535310518
Validation loss: 3.5993278008300895

Epoch: 6| Step: 8
Training loss: 3.9931456727994257
Validation loss: 3.594407350432941

Epoch: 6| Step: 9
Training loss: 4.278401339002469
Validation loss: 3.59040351629459

Epoch: 6| Step: 10
Training loss: 4.056783086840098
Validation loss: 3.58561799309622

Epoch: 6| Step: 11
Training loss: 2.916088228541898
Validation loss: 3.5809184446304165

Epoch: 6| Step: 12
Training loss: 3.9011007320616438
Validation loss: 3.5762996320892704

Epoch: 6| Step: 13
Training loss: 3.631653828579983
Validation loss: 3.571130593448561

Epoch: 32| Step: 0
Training loss: 4.278284758433356
Validation loss: 3.5658404878879018

Epoch: 6| Step: 1
Training loss: 3.265402024245077
Validation loss: 3.5618127751196145

Epoch: 6| Step: 2
Training loss: 3.931684286270236
Validation loss: 3.5568921305569514

Epoch: 6| Step: 3
Training loss: 3.745241324743495
Validation loss: 3.552536858088483

Epoch: 6| Step: 4
Training loss: 3.013441174639501
Validation loss: 3.5475236968883714

Epoch: 6| Step: 5
Training loss: 3.743085844962847
Validation loss: 3.543132762764729

Epoch: 6| Step: 6
Training loss: 3.6283033381355247
Validation loss: 3.538248626789937

Epoch: 6| Step: 7
Training loss: 3.257300759792699
Validation loss: 3.533917817470459

Epoch: 6| Step: 8
Training loss: 3.9951924997866577
Validation loss: 3.52959412317147

Epoch: 6| Step: 9
Training loss: 3.6958090063510833
Validation loss: 3.5255462358532355

Epoch: 6| Step: 10
Training loss: 3.3800037167319905
Validation loss: 3.51978785700995

Epoch: 6| Step: 11
Training loss: 3.9126641674760654
Validation loss: 3.515757715051423

Epoch: 6| Step: 12
Training loss: 3.3734488984869957
Validation loss: 3.511005831366013

Epoch: 6| Step: 13
Training loss: 3.9863483404145064
Validation loss: 3.505972988090614

Epoch: 33| Step: 0
Training loss: 3.5735731198388083
Validation loss: 3.50119813211726

Epoch: 6| Step: 1
Training loss: 3.4949264538275444
Validation loss: 3.4972131851385213

Epoch: 6| Step: 2
Training loss: 3.094493583944982
Validation loss: 3.4933665743610063

Epoch: 6| Step: 3
Training loss: 4.201453801994373
Validation loss: 3.4883366345789257

Epoch: 6| Step: 4
Training loss: 3.780988952200871
Validation loss: 3.4840879678464

Epoch: 6| Step: 5
Training loss: 3.1122270089047257
Validation loss: 3.479437758492628

Epoch: 6| Step: 6
Training loss: 4.232183022794233
Validation loss: 3.4758127725694705

Epoch: 6| Step: 7
Training loss: 3.120334652290545
Validation loss: 3.4713029373559308

Epoch: 6| Step: 8
Training loss: 3.554140019438035
Validation loss: 3.4670849948129217

Epoch: 6| Step: 9
Training loss: 4.355140297312745
Validation loss: 3.462202864107047

Epoch: 6| Step: 10
Training loss: 4.090252262907357
Validation loss: 3.4568123211118515

Epoch: 6| Step: 11
Training loss: 2.838589019847042
Validation loss: 3.4526259232819254

Epoch: 6| Step: 12
Training loss: 3.239878225039629
Validation loss: 3.447599728741421

Epoch: 6| Step: 13
Training loss: 3.442263683665634
Validation loss: 3.4435045453687763

Epoch: 34| Step: 0
Training loss: 3.8703314437679803
Validation loss: 3.4393020992419756

Epoch: 6| Step: 1
Training loss: 2.3457565873252877
Validation loss: 3.4351427954950413

Epoch: 6| Step: 2
Training loss: 2.3143943038741113
Validation loss: 3.4311437042577775

Epoch: 6| Step: 3
Training loss: 3.57272104037304
Validation loss: 3.4280331270419255

Epoch: 6| Step: 4
Training loss: 3.809371164646987
Validation loss: 3.4239891175426918

Epoch: 6| Step: 5
Training loss: 4.287793136674175
Validation loss: 3.419706078181743

Epoch: 6| Step: 6
Training loss: 3.7917692289349634
Validation loss: 3.4153665689726087

Epoch: 6| Step: 7
Training loss: 3.341047959989091
Validation loss: 3.410541735487838

Epoch: 6| Step: 8
Training loss: 4.100163917056062
Validation loss: 3.4071161294703565

Epoch: 6| Step: 9
Training loss: 3.3729394344498385
Validation loss: 3.4030012100633087

Epoch: 6| Step: 10
Training loss: 3.5395954732853236
Validation loss: 3.399119435142999

Epoch: 6| Step: 11
Training loss: 3.3328583060978443
Validation loss: 3.3962993341091297

Epoch: 6| Step: 12
Training loss: 3.6676809179698333
Validation loss: 3.3908005770037604

Epoch: 6| Step: 13
Training loss: 3.7538043751622574
Validation loss: 3.385793850745448

Epoch: 35| Step: 0
Training loss: 4.150606152492124
Validation loss: 3.3818862269458476

Epoch: 6| Step: 1
Training loss: 3.181871418693354
Validation loss: 3.3768037756008193

Epoch: 6| Step: 2
Training loss: 3.246537197777086
Validation loss: 3.3726240201165165

Epoch: 6| Step: 3
Training loss: 4.01719260881263
Validation loss: 3.369055917753076

Epoch: 6| Step: 4
Training loss: 2.784936754477636
Validation loss: 3.3641719428824177

Epoch: 6| Step: 5
Training loss: 3.2940993353591175
Validation loss: 3.359777263835121

Epoch: 6| Step: 6
Training loss: 3.7692057572797015
Validation loss: 3.3553097753498027

Epoch: 6| Step: 7
Training loss: 3.9198224901374057
Validation loss: 3.3516018619908383

Epoch: 6| Step: 8
Training loss: 3.049762316338312
Validation loss: 3.347233096026376

Epoch: 6| Step: 9
Training loss: 2.9207521616875405
Validation loss: 3.343128990427221

Epoch: 6| Step: 10
Training loss: 3.6096851826606597
Validation loss: 3.3406887480146144

Epoch: 6| Step: 11
Training loss: 3.40581824689871
Validation loss: 3.33607433791852

Epoch: 6| Step: 12
Training loss: 3.759663782102805
Validation loss: 3.3321032797692745

Epoch: 6| Step: 13
Training loss: 3.4894582849368545
Validation loss: 3.327709213814288

Epoch: 36| Step: 0
Training loss: 3.564744610299273
Validation loss: 3.323999346116756

Epoch: 6| Step: 1
Training loss: 3.283246985783025
Validation loss: 3.319706449361518

Epoch: 6| Step: 2
Training loss: 3.150604638092709
Validation loss: 3.3157490564760246

Epoch: 6| Step: 3
Training loss: 3.982759155538762
Validation loss: 3.3123401387344917

Epoch: 6| Step: 4
Training loss: 3.3331730486162106
Validation loss: 3.3080520997194114

Epoch: 6| Step: 5
Training loss: 3.264243239698519
Validation loss: 3.303880501309511

Epoch: 6| Step: 6
Training loss: 4.052649424937987
Validation loss: 3.3002186914671574

Epoch: 6| Step: 7
Training loss: 2.8155224983618474
Validation loss: 3.2960563957133284

Epoch: 6| Step: 8
Training loss: 2.907848451813364
Validation loss: 3.292369011098374

Epoch: 6| Step: 9
Training loss: 3.1853061680977364
Validation loss: 3.2899605437930357

Epoch: 6| Step: 10
Training loss: 3.2550884906324966
Validation loss: 3.2859229343422216

Epoch: 6| Step: 11
Training loss: 3.5316796505593206
Validation loss: 3.2818632249167474

Epoch: 6| Step: 12
Training loss: 4.5618716290586
Validation loss: 3.2790366079542506

Epoch: 6| Step: 13
Training loss: 2.7616875847726607
Validation loss: 3.27395747143577

Epoch: 37| Step: 0
Training loss: 3.245228859893918
Validation loss: 3.27008805419859

Epoch: 6| Step: 1
Training loss: 4.117153681520263
Validation loss: 3.266242813003172

Epoch: 6| Step: 2
Training loss: 3.3648003349753886
Validation loss: 3.263462476178466

Epoch: 6| Step: 3
Training loss: 3.959010872660462
Validation loss: 3.258625444422566

Epoch: 6| Step: 4
Training loss: 4.080738618600785
Validation loss: 3.2542818668568723

Epoch: 6| Step: 5
Training loss: 3.364179147982711
Validation loss: 3.250093874431442

Epoch: 6| Step: 6
Training loss: 2.912276060475207
Validation loss: 3.2464691446940255

Epoch: 6| Step: 7
Training loss: 2.2761983461086244
Validation loss: 3.243570447985949

Epoch: 6| Step: 8
Training loss: 3.6409194237840916
Validation loss: 3.2400997686527444

Epoch: 6| Step: 9
Training loss: 3.5189665109483186
Validation loss: 3.2367010920376935

Epoch: 6| Step: 10
Training loss: 3.013084487880072
Validation loss: 3.232943108859365

Epoch: 6| Step: 11
Training loss: 3.3081727463753823
Validation loss: 3.228527625235279

Epoch: 6| Step: 12
Training loss: 3.2798473448236396
Validation loss: 3.225144044483287

Epoch: 6| Step: 13
Training loss: 2.861478438351303
Validation loss: 3.2218319850236883

Epoch: 38| Step: 0
Training loss: 3.3042140468232564
Validation loss: 3.218552790158823

Epoch: 6| Step: 1
Training loss: 3.4317456719479655
Validation loss: 3.2158344483569263

Epoch: 6| Step: 2
Training loss: 2.9713942145887025
Validation loss: 3.2132050488877795

Epoch: 6| Step: 3
Training loss: 3.1401688733217066
Validation loss: 3.2094999562037807

Epoch: 6| Step: 4
Training loss: 3.510402886941882
Validation loss: 3.2052480469331184

Epoch: 6| Step: 5
Training loss: 4.1950210668969214
Validation loss: 3.201574443387141

Epoch: 6| Step: 6
Training loss: 3.416440087845875
Validation loss: 3.1980924444111483

Epoch: 6| Step: 7
Training loss: 3.603587080084232
Validation loss: 3.1940717829912844

Epoch: 6| Step: 8
Training loss: 3.218282573055346
Validation loss: 3.19046882050374

Epoch: 6| Step: 9
Training loss: 2.7714453191068587
Validation loss: 3.1873895214606787

Epoch: 6| Step: 10
Training loss: 3.380384741335028
Validation loss: 3.1846190254566746

Epoch: 6| Step: 11
Training loss: 3.0183836025501387
Validation loss: 3.181489151295026

Epoch: 6| Step: 12
Training loss: 3.6023342935756113
Validation loss: 3.178448284839604

Epoch: 6| Step: 13
Training loss: 2.9016556058786427
Validation loss: 3.1737891499009145

Epoch: 39| Step: 0
Training loss: 3.181703720263343
Validation loss: 3.170613205462495

Epoch: 6| Step: 1
Training loss: 3.3091915090552733
Validation loss: 3.1673851118400704

Epoch: 6| Step: 2
Training loss: 3.3576848946204736
Validation loss: 3.1633354450563136

Epoch: 6| Step: 3
Training loss: 3.515643446132163
Validation loss: 3.1604978473440553

Epoch: 6| Step: 4
Training loss: 2.5666763883464383
Validation loss: 3.1567601965556307

Epoch: 6| Step: 5
Training loss: 3.4162414720403014
Validation loss: 3.15388883898193

Epoch: 6| Step: 6
Training loss: 3.1155418698652246
Validation loss: 3.1509353661800295

Epoch: 6| Step: 7
Training loss: 3.0982155986357505
Validation loss: 3.147372511346415

Epoch: 6| Step: 8
Training loss: 3.6957037236747743
Validation loss: 3.1440254768224265

Epoch: 6| Step: 9
Training loss: 3.2677946777091216
Validation loss: 3.1402768626927147

Epoch: 6| Step: 10
Training loss: 3.3747349387740693
Validation loss: 3.1374671711413695

Epoch: 6| Step: 11
Training loss: 3.0123928320092683
Validation loss: 3.134450977098065

Epoch: 6| Step: 12
Training loss: 3.237001688544605
Validation loss: 3.1308348542298505

Epoch: 6| Step: 13
Training loss: 3.7526838235477022
Validation loss: 3.127339161559706

Epoch: 40| Step: 0
Training loss: 2.8804432300071365
Validation loss: 3.1242795876763054

Epoch: 6| Step: 1
Training loss: 3.3319058858670347
Validation loss: 3.1213741375476136

Epoch: 6| Step: 2
Training loss: 3.46007256646767
Validation loss: 3.1193457758732053

Epoch: 6| Step: 3
Training loss: 2.960259755052386
Validation loss: 3.114839566682995

Epoch: 6| Step: 4
Training loss: 3.603219600603513
Validation loss: 3.1119906926706444

Epoch: 6| Step: 5
Training loss: 3.3810037971030718
Validation loss: 3.109085555159025

Epoch: 6| Step: 6
Training loss: 3.2195386198274663
Validation loss: 3.106226952081598

Epoch: 6| Step: 7
Training loss: 3.4772608366392923
Validation loss: 3.1024256097039866

Epoch: 6| Step: 8
Training loss: 2.72203672084102
Validation loss: 3.0992548867457113

Epoch: 6| Step: 9
Training loss: 2.737615615981224
Validation loss: 3.0965772098750466

Epoch: 6| Step: 10
Training loss: 3.2922110449442825
Validation loss: 3.093214765803047

Epoch: 6| Step: 11
Training loss: 2.9713629216235957
Validation loss: 3.0906402680084515

Epoch: 6| Step: 12
Training loss: 3.2029007996040857
Validation loss: 3.0878141853382743

Epoch: 6| Step: 13
Training loss: 3.9574674495821127
Validation loss: 3.0845729466762006

Epoch: 41| Step: 0
Training loss: 3.0543955787822523
Validation loss: 3.081759622560016

Epoch: 6| Step: 1
Training loss: 3.6562248294322566
Validation loss: 3.0788954337026135

Epoch: 6| Step: 2
Training loss: 3.6572783238576716
Validation loss: 3.0757924389831466

Epoch: 6| Step: 3
Training loss: 3.265488325115379
Validation loss: 3.0716723665324945

Epoch: 6| Step: 4
Training loss: 2.3245137516303394
Validation loss: 3.0686338978938466

Epoch: 6| Step: 5
Training loss: 3.0145046544610903
Validation loss: 3.066161451671996

Epoch: 6| Step: 6
Training loss: 3.2193480000949464
Validation loss: 3.0629592732781377

Epoch: 6| Step: 7
Training loss: 2.6541076098648357
Validation loss: 3.0618352752494444

Epoch: 6| Step: 8
Training loss: 3.0081171847506845
Validation loss: 3.0574861602178856

Epoch: 6| Step: 9
Training loss: 2.997703149829801
Validation loss: 3.055298727011697

Epoch: 6| Step: 10
Training loss: 2.8574495763993877
Validation loss: 3.0531794735471776

Epoch: 6| Step: 11
Training loss: 2.9465387761367308
Validation loss: 3.050233343193081

Epoch: 6| Step: 12
Training loss: 3.543572320806455
Validation loss: 3.048016195873308

Epoch: 6| Step: 13
Training loss: 4.175859584376924
Validation loss: 3.0450205188471213

Epoch: 42| Step: 0
Training loss: 3.1372641425370653
Validation loss: 3.0419632666913743

Epoch: 6| Step: 1
Training loss: 3.331554096935192
Validation loss: 3.0381512293088506

Epoch: 6| Step: 2
Training loss: 3.373445647434363
Validation loss: 3.03460361026804

Epoch: 6| Step: 3
Training loss: 3.799866553523289
Validation loss: 3.0306683011697415

Epoch: 6| Step: 4
Training loss: 3.1635618214011796
Validation loss: 3.031364242131303

Epoch: 6| Step: 5
Training loss: 2.9548618920804963
Validation loss: 3.0326922678973416

Epoch: 6| Step: 6
Training loss: 2.3567134168736894
Validation loss: 3.0390059229692734

Epoch: 6| Step: 7
Training loss: 2.96907571712371
Validation loss: 3.0217547140603593

Epoch: 6| Step: 8
Training loss: 3.520846274688833
Validation loss: 3.0172584603050074

Epoch: 6| Step: 9
Training loss: 3.4359951540076796
Validation loss: 3.014226665017449

Epoch: 6| Step: 10
Training loss: 3.3607453146324877
Validation loss: 3.0110270047572607

Epoch: 6| Step: 11
Training loss: 2.594531022106001
Validation loss: 3.01022437690386

Epoch: 6| Step: 12
Training loss: 2.806092061991173
Validation loss: 3.014579235848307

Epoch: 6| Step: 13
Training loss: 3.2288160236267274
Validation loss: 3.022356903142739

Epoch: 43| Step: 0
Training loss: 3.9735453313130833
Validation loss: 3.007478994400265

Epoch: 6| Step: 1
Training loss: 2.886381095991801
Validation loss: 2.9986804205775663

Epoch: 6| Step: 2
Training loss: 2.9056072549817595
Validation loss: 2.997752036177457

Epoch: 6| Step: 3
Training loss: 3.107700836492429
Validation loss: 2.999418652685747

Epoch: 6| Step: 4
Training loss: 2.881268840074487
Validation loss: 3.0011910484886837

Epoch: 6| Step: 5
Training loss: 3.0024313610912015
Validation loss: 3.000080650623032

Epoch: 6| Step: 6
Training loss: 2.3138819508819344
Validation loss: 2.994069250574529

Epoch: 6| Step: 7
Training loss: 3.062316266212006
Validation loss: 2.989877458164241

Epoch: 6| Step: 8
Training loss: 3.2854244744097802
Validation loss: 2.9852448904945055

Epoch: 6| Step: 9
Training loss: 3.5287715349881434
Validation loss: 2.9806578756566937

Epoch: 6| Step: 10
Training loss: 2.85489524582322
Validation loss: 2.978906611227365

Epoch: 6| Step: 11
Training loss: 3.411810998912068
Validation loss: 2.976711426327562

Epoch: 6| Step: 12
Training loss: 2.9596698231451652
Validation loss: 2.9740503879247173

Epoch: 6| Step: 13
Training loss: 3.3323454982602554
Validation loss: 2.9709782720648876

Epoch: 44| Step: 0
Training loss: 2.767084286281807
Validation loss: 2.9670571302419284

Epoch: 6| Step: 1
Training loss: 2.8159269858940723
Validation loss: 2.963395788337732

Epoch: 6| Step: 2
Training loss: 3.4307995776768276
Validation loss: 2.961496050515419

Epoch: 6| Step: 3
Training loss: 2.375579161047434
Validation loss: 2.958484005561003

Epoch: 6| Step: 4
Training loss: 3.3895337858293018
Validation loss: 2.955499841249389

Epoch: 6| Step: 5
Training loss: 2.9369957673740767
Validation loss: 2.9522395076284758

Epoch: 6| Step: 6
Training loss: 3.592552051737845
Validation loss: 2.950031981860577

Epoch: 6| Step: 7
Training loss: 3.180169896079788
Validation loss: 2.9474982828572593

Epoch: 6| Step: 8
Training loss: 3.4228983703111906
Validation loss: 2.9448395340039

Epoch: 6| Step: 9
Training loss: 3.2051044581585044
Validation loss: 2.9409764192369328

Epoch: 6| Step: 10
Training loss: 2.1216598514028897
Validation loss: 2.939069977689455

Epoch: 6| Step: 11
Training loss: 3.5255195234832306
Validation loss: 2.941605100626842

Epoch: 6| Step: 12
Training loss: 3.175330473754458
Validation loss: 2.9419529353210265

Epoch: 6| Step: 13
Training loss: 2.9595464090819332
Validation loss: 2.9441295376410674

Epoch: 45| Step: 0
Training loss: 3.0600942387748624
Validation loss: 2.938393625999293

Epoch: 6| Step: 1
Training loss: 2.9395794914179043
Validation loss: 2.928453041246829

Epoch: 6| Step: 2
Training loss: 2.2978741814521046
Validation loss: 2.925332089670184

Epoch: 6| Step: 3
Training loss: 3.170658874390922
Validation loss: 2.9226265551008477

Epoch: 6| Step: 4
Training loss: 3.2304669787253304
Validation loss: 2.9198547151426717

Epoch: 6| Step: 5
Training loss: 3.2387901062802853
Validation loss: 2.9183315611579204

Epoch: 6| Step: 6
Training loss: 3.1807394701012774
Validation loss: 2.916255436017567

Epoch: 6| Step: 7
Training loss: 2.9347648061068003
Validation loss: 2.9148194094510425

Epoch: 6| Step: 8
Training loss: 3.271582612797421
Validation loss: 2.913017665170854

Epoch: 6| Step: 9
Training loss: 2.9147133598926867
Validation loss: 2.911115490830826

Epoch: 6| Step: 10
Training loss: 3.3741427145161427
Validation loss: 2.9089196771788317

Epoch: 6| Step: 11
Training loss: 3.177899431984072
Validation loss: 2.906370399743041

Epoch: 6| Step: 12
Training loss: 2.8745188103068844
Validation loss: 2.9042978190540456

Epoch: 6| Step: 13
Training loss: 2.9657765806991487
Validation loss: 2.902068517409326

Epoch: 46| Step: 0
Training loss: 3.1955446937717173
Validation loss: 2.897922713499436

Epoch: 6| Step: 1
Training loss: 2.531862067173321
Validation loss: 2.8968574899242343

Epoch: 6| Step: 2
Training loss: 2.9686613370806283
Validation loss: 2.8975402183473324

Epoch: 6| Step: 3
Training loss: 2.780516967183866
Validation loss: 2.893774402974156

Epoch: 6| Step: 4
Training loss: 3.077609256196388
Validation loss: 2.8890141027979364

Epoch: 6| Step: 5
Training loss: 3.182645354566213
Validation loss: 2.8879745979609677

Epoch: 6| Step: 6
Training loss: 2.3971762058835897
Validation loss: 2.885640109301284

Epoch: 6| Step: 7
Training loss: 3.386827724511901
Validation loss: 2.8876412603440835

Epoch: 6| Step: 8
Training loss: 2.90292545614221
Validation loss: 2.8850274953958874

Epoch: 6| Step: 9
Training loss: 2.7551368074321165
Validation loss: 2.8769710528990653

Epoch: 6| Step: 10
Training loss: 3.1623008816121096
Validation loss: 2.8760402704769965

Epoch: 6| Step: 11
Training loss: 3.50490349194582
Validation loss: 2.8736893803974275

Epoch: 6| Step: 12
Training loss: 2.9145566301483656
Validation loss: 2.872406992655727

Epoch: 6| Step: 13
Training loss: 3.3662701483405764
Validation loss: 2.8729793524225347

Epoch: 47| Step: 0
Training loss: 2.9229890871943778
Validation loss: 2.879288239587519

Epoch: 6| Step: 1
Training loss: 2.77234432543594
Validation loss: 2.880319773683555

Epoch: 6| Step: 2
Training loss: 2.778448172310547
Validation loss: 2.8751438906500564

Epoch: 6| Step: 3
Training loss: 2.991666026279165
Validation loss: 2.862008693682753

Epoch: 6| Step: 4
Training loss: 3.7576277403904133
Validation loss: 2.8583288172323806

Epoch: 6| Step: 5
Training loss: 3.2021563298069102
Validation loss: 2.8564308031371173

Epoch: 6| Step: 6
Training loss: 3.1079846824946054
Validation loss: 2.8563168819062192

Epoch: 6| Step: 7
Training loss: 2.685935429987795
Validation loss: 2.8518010705933157

Epoch: 6| Step: 8
Training loss: 3.1946140262722613
Validation loss: 2.85168912423538

Epoch: 6| Step: 9
Training loss: 3.0082764899324617
Validation loss: 2.849744870662214

Epoch: 6| Step: 10
Training loss: 3.3641731949173472
Validation loss: 2.8489383973441718

Epoch: 6| Step: 11
Training loss: 2.809684021856077
Validation loss: 2.8476651387365917

Epoch: 6| Step: 12
Training loss: 1.7901506071825002
Validation loss: 2.845671483171359

Epoch: 6| Step: 13
Training loss: 3.1754061581802695
Validation loss: 2.8422150713824257

Epoch: 48| Step: 0
Training loss: 3.040842824349437
Validation loss: 2.8422437039089514

Epoch: 6| Step: 1
Training loss: 2.8727418074991897
Validation loss: 2.8386490314488912

Epoch: 6| Step: 2
Training loss: 3.2648128978168818
Validation loss: 2.836130771408991

Epoch: 6| Step: 3
Training loss: 2.879765582875956
Validation loss: 2.8325988481360125

Epoch: 6| Step: 4
Training loss: 2.9062112785138883
Validation loss: 2.831357903069955

Epoch: 6| Step: 5
Training loss: 2.704803122302975
Validation loss: 2.832557338213935

Epoch: 6| Step: 6
Training loss: 3.3778919968896823
Validation loss: 2.835073698567141

Epoch: 6| Step: 7
Training loss: 2.97566782403941
Validation loss: 2.82666963114523

Epoch: 6| Step: 8
Training loss: 3.6892535679223424
Validation loss: 2.8224463452267354

Epoch: 6| Step: 9
Training loss: 3.167748835182533
Validation loss: 2.8191726226773794

Epoch: 6| Step: 10
Training loss: 2.4707142222762144
Validation loss: 2.820845873160126

Epoch: 6| Step: 11
Training loss: 2.2381035699273792
Validation loss: 2.8191325501142237

Epoch: 6| Step: 12
Training loss: 2.6766760450731715
Validation loss: 2.8204844977995314

Epoch: 6| Step: 13
Training loss: 3.0030282948749143
Validation loss: 2.818729551682379

Epoch: 49| Step: 0
Training loss: 3.7113926016166707
Validation loss: 2.82075129342246

Epoch: 6| Step: 1
Training loss: 2.405299903268677
Validation loss: 2.8196761099270953

Epoch: 6| Step: 2
Training loss: 3.1354050409010656
Validation loss: 2.820972397126626

Epoch: 6| Step: 3
Training loss: 2.7194255121195723
Validation loss: 2.8186214939324405

Epoch: 6| Step: 4
Training loss: 2.889725168749326
Validation loss: 2.8136538646424682

Epoch: 6| Step: 5
Training loss: 3.0636918220614824
Validation loss: 2.8106549462913115

Epoch: 6| Step: 6
Training loss: 2.9912823535589848
Validation loss: 2.8046450102553098

Epoch: 6| Step: 7
Training loss: 3.334850268112495
Validation loss: 2.80097365594088

Epoch: 6| Step: 8
Training loss: 2.6384916999343693
Validation loss: 2.799415315594813

Epoch: 6| Step: 9
Training loss: 2.7965871993161424
Validation loss: 2.797160100347041

Epoch: 6| Step: 10
Training loss: 3.0959201483963668
Validation loss: 2.798335242945747

Epoch: 6| Step: 11
Training loss: 3.2787643463716765
Validation loss: 2.7961668684449013

Epoch: 6| Step: 12
Training loss: 1.920550440425067
Validation loss: 2.796415038975934

Epoch: 6| Step: 13
Training loss: 2.8282536429974625
Validation loss: 2.792989265704444

Epoch: 50| Step: 0
Training loss: 2.9746600301415747
Validation loss: 2.7873347440124654

Epoch: 6| Step: 1
Training loss: 2.596038544096856
Validation loss: 2.789354211135882

Epoch: 6| Step: 2
Training loss: 2.7247551554302007
Validation loss: 2.785121509108838

Epoch: 6| Step: 3
Training loss: 2.842414794020586
Validation loss: 2.7841592781481137

Epoch: 6| Step: 4
Training loss: 3.0307632527409725
Validation loss: 2.7825743561732277

Epoch: 6| Step: 5
Training loss: 2.916283954761155
Validation loss: 2.78174622355845

Epoch: 6| Step: 6
Training loss: 2.946900766690854
Validation loss: 2.780387173090389

Epoch: 6| Step: 7
Training loss: 3.097957947555812
Validation loss: 2.780384171833998

Epoch: 6| Step: 8
Training loss: 2.938669174945589
Validation loss: 2.781677027576945

Epoch: 6| Step: 9
Training loss: 2.6571895957094194
Validation loss: 2.7796878356533123

Epoch: 6| Step: 10
Training loss: 2.9220920420934418
Validation loss: 2.777030186718129

Epoch: 6| Step: 11
Training loss: 3.13509721279762
Validation loss: 2.7748517366272134

Epoch: 6| Step: 12
Training loss: 3.0708563325418377
Validation loss: 2.7730626815615516

Epoch: 6| Step: 13
Training loss: 2.977765018125814
Validation loss: 2.770993526866469

Epoch: 51| Step: 0
Training loss: 2.934158534961697
Validation loss: 2.768013449033504

Epoch: 6| Step: 1
Training loss: 3.4199037491488533
Validation loss: 2.7645917927301875

Epoch: 6| Step: 2
Training loss: 2.8265642949526155
Validation loss: 2.7626215400253558

Epoch: 6| Step: 3
Training loss: 2.036164076311239
Validation loss: 2.760454203992208

Epoch: 6| Step: 4
Training loss: 2.7386936633584944
Validation loss: 2.7571344883968467

Epoch: 6| Step: 5
Training loss: 3.4731217062747284
Validation loss: 2.7568391229437923

Epoch: 6| Step: 6
Training loss: 3.096541869321633
Validation loss: 2.754196404216235

Epoch: 6| Step: 7
Training loss: 2.2911219787627686
Validation loss: 2.751883324269667

Epoch: 6| Step: 8
Training loss: 2.827600419936781
Validation loss: 2.751191877958328

Epoch: 6| Step: 9
Training loss: 3.1912947860545606
Validation loss: 2.7488984589430263

Epoch: 6| Step: 10
Training loss: 2.6441822356991884
Validation loss: 2.7498495465361006

Epoch: 6| Step: 11
Training loss: 2.84292926053314
Validation loss: 2.7483952203664543

Epoch: 6| Step: 12
Training loss: 3.0736873026779343
Validation loss: 2.752702930787449

Epoch: 6| Step: 13
Training loss: 2.800381130437071
Validation loss: 2.7523379502391894

Epoch: 52| Step: 0
Training loss: 2.5110103385344815
Validation loss: 2.7545962359852743

Epoch: 6| Step: 1
Training loss: 2.4776255735721255
Validation loss: 2.7478350874268442

Epoch: 6| Step: 2
Training loss: 3.0968576871540066
Validation loss: 2.7417316112150347

Epoch: 6| Step: 3
Training loss: 2.882129288430603
Validation loss: 2.7393175922110804

Epoch: 6| Step: 4
Training loss: 2.2904565101263707
Validation loss: 2.7406673583262813

Epoch: 6| Step: 5
Training loss: 3.212108092393031
Validation loss: 2.751162586686654

Epoch: 6| Step: 6
Training loss: 2.8163248968345305
Validation loss: 2.746318578221232

Epoch: 6| Step: 7
Training loss: 3.0541990235936187
Validation loss: 2.7487139729233103

Epoch: 6| Step: 8
Training loss: 3.0339745930140363
Validation loss: 2.7445196104974716

Epoch: 6| Step: 9
Training loss: 2.8645043564515453
Validation loss: 2.7361534220806805

Epoch: 6| Step: 10
Training loss: 3.1435213161283975
Validation loss: 2.733032536431738

Epoch: 6| Step: 11
Training loss: 2.984853656191029
Validation loss: 2.7316309211522594

Epoch: 6| Step: 12
Training loss: 2.835757583501752
Validation loss: 2.7308088171794274

Epoch: 6| Step: 13
Training loss: 3.0524724163336887
Validation loss: 2.7262136824642043

Epoch: 53| Step: 0
Training loss: 3.237571132276147
Validation loss: 2.7250048570268843

Epoch: 6| Step: 1
Training loss: 3.1989734075835576
Validation loss: 2.719630789311801

Epoch: 6| Step: 2
Training loss: 2.539995603031948
Validation loss: 2.7199385372631975

Epoch: 6| Step: 3
Training loss: 3.2439865819839326
Validation loss: 2.7203228518840303

Epoch: 6| Step: 4
Training loss: 3.490586564578987
Validation loss: 2.7175843089295943

Epoch: 6| Step: 5
Training loss: 2.3684544965267795
Validation loss: 2.7182789390808355

Epoch: 6| Step: 6
Training loss: 2.7100248092135124
Validation loss: 2.717908882606779

Epoch: 6| Step: 7
Training loss: 2.4306374805509625
Validation loss: 2.7118992047835255

Epoch: 6| Step: 8
Training loss: 2.4842793188323795
Validation loss: 2.713623328758748

Epoch: 6| Step: 9
Training loss: 3.2108448321482017
Validation loss: 2.709196427564238

Epoch: 6| Step: 10
Training loss: 2.46452375411452
Validation loss: 2.7120422398926447

Epoch: 6| Step: 11
Training loss: 2.7536475526763318
Validation loss: 2.711404091498502

Epoch: 6| Step: 12
Training loss: 3.012716679675038
Validation loss: 2.707016864571415

Epoch: 6| Step: 13
Training loss: 2.4800301231585236
Validation loss: 2.716094506943977

Epoch: 54| Step: 0
Training loss: 2.527748983403159
Validation loss: 2.7152046530899687

Epoch: 6| Step: 1
Training loss: 2.784190134746709
Validation loss: 2.7251658246276214

Epoch: 6| Step: 2
Training loss: 2.4099561215596887
Validation loss: 2.7240332501371163

Epoch: 6| Step: 3
Training loss: 3.3852986633079984
Validation loss: 2.7046802728542807

Epoch: 6| Step: 4
Training loss: 2.9907975516770082
Validation loss: 2.6992544051307497

Epoch: 6| Step: 5
Training loss: 2.7165458777162783
Validation loss: 2.701238455311567

Epoch: 6| Step: 6
Training loss: 2.5300201442353805
Validation loss: 2.705689773542049

Epoch: 6| Step: 7
Training loss: 3.025550123902444
Validation loss: 2.7153740307809513

Epoch: 6| Step: 8
Training loss: 2.960179053123357
Validation loss: 2.7312150261892643

Epoch: 6| Step: 9
Training loss: 2.792705560834837
Validation loss: 2.732700481848956

Epoch: 6| Step: 10
Training loss: 3.2088848151970413
Validation loss: 2.7118176617245644

Epoch: 6| Step: 11
Training loss: 3.3861103149307423
Validation loss: 2.705244273604435

Epoch: 6| Step: 12
Training loss: 2.543747649320599
Validation loss: 2.6999998163293846

Epoch: 6| Step: 13
Training loss: 2.346554108687366
Validation loss: 2.6965995037861257

Epoch: 55| Step: 0
Training loss: 2.199085943030141
Validation loss: 2.6928281972586317

Epoch: 6| Step: 1
Training loss: 2.64220692578376
Validation loss: 2.6914943317086952

Epoch: 6| Step: 2
Training loss: 3.0356685250303372
Validation loss: 2.687223065324252

Epoch: 6| Step: 3
Training loss: 2.0890814130521833
Validation loss: 2.6895261120686644

Epoch: 6| Step: 4
Training loss: 2.814171951088666
Validation loss: 2.696251894390612

Epoch: 6| Step: 5
Training loss: 3.0426597193450027
Validation loss: 2.710727078849003

Epoch: 6| Step: 6
Training loss: 3.0798697392054804
Validation loss: 2.7171795354093553

Epoch: 6| Step: 7
Training loss: 2.6114356761345623
Validation loss: 2.6861157437858445

Epoch: 6| Step: 8
Training loss: 2.8302236957902975
Validation loss: 2.6821997666896045

Epoch: 6| Step: 9
Training loss: 2.971940745239193
Validation loss: 2.6838366506370037

Epoch: 6| Step: 10
Training loss: 3.1738753001301685
Validation loss: 2.6877707707229344

Epoch: 6| Step: 11
Training loss: 3.267116662255886
Validation loss: 2.692325031046527

Epoch: 6| Step: 12
Training loss: 2.654030175245199
Validation loss: 2.704533219340144

Epoch: 6| Step: 13
Training loss: 3.012630893506985
Validation loss: 2.7142597402797417

Epoch: 56| Step: 0
Training loss: 2.9952896013812382
Validation loss: 2.708152417718283

Epoch: 6| Step: 1
Training loss: 2.716414665360536
Validation loss: 2.695742748768782

Epoch: 6| Step: 2
Training loss: 2.925188602985645
Validation loss: 2.690238474139359

Epoch: 6| Step: 3
Training loss: 3.035855913464823
Validation loss: 2.683890232401785

Epoch: 6| Step: 4
Training loss: 3.085931319218494
Validation loss: 2.682220818531428

Epoch: 6| Step: 5
Training loss: 2.7239277961337014
Validation loss: 2.677832833744622

Epoch: 6| Step: 6
Training loss: 2.7158826418256594
Validation loss: 2.676460569704486

Epoch: 6| Step: 7
Training loss: 2.6724851926530766
Validation loss: 2.675094375252767

Epoch: 6| Step: 8
Training loss: 2.5799021751132925
Validation loss: 2.6733511700673307

Epoch: 6| Step: 9
Training loss: 2.9651948220895665
Validation loss: 2.6702351138719025

Epoch: 6| Step: 10
Training loss: 3.0273772994612775
Validation loss: 2.66932272263621

Epoch: 6| Step: 11
Training loss: 2.829261509275205
Validation loss: 2.6665311172923376

Epoch: 6| Step: 12
Training loss: 2.7246500648003322
Validation loss: 2.6654539678755444

Epoch: 6| Step: 13
Training loss: 2.3688180677150683
Validation loss: 2.6629007142405423

Epoch: 57| Step: 0
Training loss: 2.5552652154918647
Validation loss: 2.6603743902047188

Epoch: 6| Step: 1
Training loss: 3.142296493362341
Validation loss: 2.658687864078793

Epoch: 6| Step: 2
Training loss: 2.5877039658508796
Validation loss: 2.65894770045193

Epoch: 6| Step: 3
Training loss: 2.177732185396881
Validation loss: 2.6576722918618803

Epoch: 6| Step: 4
Training loss: 2.661971807248884
Validation loss: 2.6570778248656897

Epoch: 6| Step: 5
Training loss: 2.7229256845532626
Validation loss: 2.658029506225844

Epoch: 6| Step: 6
Training loss: 2.983502485143497
Validation loss: 2.653261470692124

Epoch: 6| Step: 7
Training loss: 2.5050460435058333
Validation loss: 2.65628207318259

Epoch: 6| Step: 8
Training loss: 3.095021920812132
Validation loss: 2.650830083671368

Epoch: 6| Step: 9
Training loss: 2.933977328035406
Validation loss: 2.6515489154168717

Epoch: 6| Step: 10
Training loss: 2.7153031872934155
Validation loss: 2.6490550113686284

Epoch: 6| Step: 11
Training loss: 2.647414828651411
Validation loss: 2.645363958781699

Epoch: 6| Step: 12
Training loss: 2.908311010528269
Validation loss: 2.6459389662994797

Epoch: 6| Step: 13
Training loss: 3.266669293486908
Validation loss: 2.64517023883577

Epoch: 58| Step: 0
Training loss: 2.8133588539189365
Validation loss: 2.642166876341138

Epoch: 6| Step: 1
Training loss: 2.780742298892352
Validation loss: 2.6418935147868465

Epoch: 6| Step: 2
Training loss: 2.48431166082289
Validation loss: 2.640720914945904

Epoch: 6| Step: 3
Training loss: 2.613314276288413
Validation loss: 2.6402785395577064

Epoch: 6| Step: 4
Training loss: 2.8216441384272573
Validation loss: 2.6368252504292102

Epoch: 6| Step: 5
Training loss: 2.7096603859235677
Validation loss: 2.6468578117379997

Epoch: 6| Step: 6
Training loss: 3.1335603577635247
Validation loss: 2.6582488822876065

Epoch: 6| Step: 7
Training loss: 2.8588071165396305
Validation loss: 2.6519643131068236

Epoch: 6| Step: 8
Training loss: 2.8629315046883517
Validation loss: 2.6331636853035705

Epoch: 6| Step: 9
Training loss: 3.1320726848172784
Validation loss: 2.632964396787907

Epoch: 6| Step: 10
Training loss: 2.3567348639059933
Validation loss: 2.6336450665895828

Epoch: 6| Step: 11
Training loss: 2.943905603139359
Validation loss: 2.6367339861394283

Epoch: 6| Step: 12
Training loss: 2.762275520973962
Validation loss: 2.6380889647793526

Epoch: 6| Step: 13
Training loss: 2.539564253307974
Validation loss: 2.6404779607701454

Epoch: 59| Step: 0
Training loss: 2.604049364627005
Validation loss: 2.641124986493443

Epoch: 6| Step: 1
Training loss: 2.64780708844593
Validation loss: 2.6409377114190513

Epoch: 6| Step: 2
Training loss: 2.7708354940382103
Validation loss: 2.6448111374268417

Epoch: 6| Step: 3
Training loss: 2.3127140255423777
Validation loss: 2.6478369678075304

Epoch: 6| Step: 4
Training loss: 3.0506311982945125
Validation loss: 2.6499943841118956

Epoch: 6| Step: 5
Training loss: 2.564134867110101
Validation loss: 2.6536086020261527

Epoch: 6| Step: 6
Training loss: 3.2076797480179855
Validation loss: 2.6536000665543336

Epoch: 6| Step: 7
Training loss: 2.5497105265850597
Validation loss: 2.650627048848134

Epoch: 6| Step: 8
Training loss: 2.720192011619423
Validation loss: 2.6440119494083025

Epoch: 6| Step: 9
Training loss: 2.567751922134276
Validation loss: 2.6392961578192016

Epoch: 6| Step: 10
Training loss: 2.976637791760187
Validation loss: 2.636063165991291

Epoch: 6| Step: 11
Training loss: 2.830214429354336
Validation loss: 2.6350932368866524

Epoch: 6| Step: 12
Training loss: 2.68516723168852
Validation loss: 2.6351132023410337

Epoch: 6| Step: 13
Training loss: 3.2410916234347686
Validation loss: 2.630886124000794

Epoch: 60| Step: 0
Training loss: 2.885884454773564
Validation loss: 2.6296957341120204

Epoch: 6| Step: 1
Training loss: 2.536148511906308
Validation loss: 2.6285245938600887

Epoch: 6| Step: 2
Training loss: 2.9169908797494557
Validation loss: 2.6272801834963415

Epoch: 6| Step: 3
Training loss: 2.7291527279408085
Validation loss: 2.625922979335669

Epoch: 6| Step: 4
Training loss: 2.8294254916813193
Validation loss: 2.6244316545442716

Epoch: 6| Step: 5
Training loss: 2.7082469241711906
Validation loss: 2.623005154434823

Epoch: 6| Step: 6
Training loss: 3.196893053945386
Validation loss: 2.619844353956883

Epoch: 6| Step: 7
Training loss: 2.5053697138864113
Validation loss: 2.61659829258931

Epoch: 6| Step: 8
Training loss: 2.8875694828013008
Validation loss: 2.617317644366003

Epoch: 6| Step: 9
Training loss: 2.129631380949667
Validation loss: 2.613559360274479

Epoch: 6| Step: 10
Training loss: 2.7182498340268078
Validation loss: 2.6148811464548523

Epoch: 6| Step: 11
Training loss: 2.6238655181941697
Validation loss: 2.6114993556396344

Epoch: 6| Step: 12
Training loss: 2.754273388786415
Validation loss: 2.6099172702554223

Epoch: 6| Step: 13
Training loss: 3.0187861027740532
Validation loss: 2.6075723478448682

Epoch: 61| Step: 0
Training loss: 2.534048158617044
Validation loss: 2.6107041101491597

Epoch: 6| Step: 1
Training loss: 3.1202311941221517
Validation loss: 2.608642871352688

Epoch: 6| Step: 2
Training loss: 2.8073769428462674
Validation loss: 2.6086674414309488

Epoch: 6| Step: 3
Training loss: 2.9446049252647724
Validation loss: 2.6068952126162577

Epoch: 6| Step: 4
Training loss: 2.874286397193366
Validation loss: 2.6074245267133054

Epoch: 6| Step: 5
Training loss: 2.9315131030725974
Validation loss: 2.603915909456332

Epoch: 6| Step: 6
Training loss: 2.549484881562532
Validation loss: 2.6031921139934693

Epoch: 6| Step: 7
Training loss: 2.4210575816236997
Validation loss: 2.605018496749726

Epoch: 6| Step: 8
Training loss: 2.805875308843801
Validation loss: 2.6039857470927554

Epoch: 6| Step: 9
Training loss: 2.432034355673812
Validation loss: 2.600976826495256

Epoch: 6| Step: 10
Training loss: 3.131075332247063
Validation loss: 2.5994124133716547

Epoch: 6| Step: 11
Training loss: 2.724020748748404
Validation loss: 2.600462809966581

Epoch: 6| Step: 12
Training loss: 2.3575322110351142
Validation loss: 2.598474068842156

Epoch: 6| Step: 13
Training loss: 2.5381705727580237
Validation loss: 2.5976071307669995

Epoch: 62| Step: 0
Training loss: 2.3271371678676975
Validation loss: 2.598621481634565

Epoch: 6| Step: 1
Training loss: 2.42324652445056
Validation loss: 2.5990600616992814

Epoch: 6| Step: 2
Training loss: 2.710466591338331
Validation loss: 2.595618130584256

Epoch: 6| Step: 3
Training loss: 3.2159429365191268
Validation loss: 2.5967663380718626

Epoch: 6| Step: 4
Training loss: 2.5655296837667994
Validation loss: 2.589989444706248

Epoch: 6| Step: 5
Training loss: 2.758828988925685
Validation loss: 2.595960953964967

Epoch: 6| Step: 6
Training loss: 3.0304717018406127
Validation loss: 2.5961048512848524

Epoch: 6| Step: 7
Training loss: 3.0232163774719547
Validation loss: 2.593701143838745

Epoch: 6| Step: 8
Training loss: 2.4260025783440207
Validation loss: 2.589351110462499

Epoch: 6| Step: 9
Training loss: 2.523168212883432
Validation loss: 2.597598059439867

Epoch: 6| Step: 10
Training loss: 2.3112122326617945
Validation loss: 2.5905304348891787

Epoch: 6| Step: 11
Training loss: 2.6482273794897226
Validation loss: 2.601444276065157

Epoch: 6| Step: 12
Training loss: 2.772621228084765
Validation loss: 2.5950581113008706

Epoch: 6| Step: 13
Training loss: 3.127977402412761
Validation loss: 2.5976765796755

Epoch: 63| Step: 0
Training loss: 2.099871440767035
Validation loss: 2.5891572973668904

Epoch: 6| Step: 1
Training loss: 2.5023799058753764
Validation loss: 2.593219948041172

Epoch: 6| Step: 2
Training loss: 2.4148088307665163
Validation loss: 2.591615572320441

Epoch: 6| Step: 3
Training loss: 2.5945607951847394
Validation loss: 2.602779558150168

Epoch: 6| Step: 4
Training loss: 2.690058000924858
Validation loss: 2.5958276416926394

Epoch: 6| Step: 5
Training loss: 2.8360699919549903
Validation loss: 2.6128087550331363

Epoch: 6| Step: 6
Training loss: 2.8896096585666786
Validation loss: 2.602765420942944

Epoch: 6| Step: 7
Training loss: 3.225440617705545
Validation loss: 2.5920859824566

Epoch: 6| Step: 8
Training loss: 2.7708014197172854
Validation loss: 2.591015918228836

Epoch: 6| Step: 9
Training loss: 2.917000524395937
Validation loss: 2.5913759420127382

Epoch: 6| Step: 10
Training loss: 3.067580388266388
Validation loss: 2.582960906921901

Epoch: 6| Step: 11
Training loss: 2.483701794660012
Validation loss: 2.5833692445617524

Epoch: 6| Step: 12
Training loss: 2.8963760489478823
Validation loss: 2.580767408306407

Epoch: 6| Step: 13
Training loss: 2.305684329908804
Validation loss: 2.5797676016996363

Epoch: 64| Step: 0
Training loss: 2.8654157689044926
Validation loss: 2.5802944572981836

Epoch: 6| Step: 1
Training loss: 2.605809316724728
Validation loss: 2.582301215651321

Epoch: 6| Step: 2
Training loss: 3.00963967051707
Validation loss: 2.584103305470016

Epoch: 6| Step: 3
Training loss: 3.0799883319584183
Validation loss: 2.5805428774845844

Epoch: 6| Step: 4
Training loss: 2.558291258657531
Validation loss: 2.5817895603994963

Epoch: 6| Step: 5
Training loss: 2.911702117995244
Validation loss: 2.584565888950242

Epoch: 6| Step: 6
Training loss: 2.8959101019547404
Validation loss: 2.5797027076043424

Epoch: 6| Step: 7
Training loss: 2.7950298680328625
Validation loss: 2.5812840999047313

Epoch: 6| Step: 8
Training loss: 2.785013716850539
Validation loss: 2.5790907312984497

Epoch: 6| Step: 9
Training loss: 2.7159809612342847
Validation loss: 2.5772279816484778

Epoch: 6| Step: 10
Training loss: 2.7767035367455675
Validation loss: 2.576648188998092

Epoch: 6| Step: 11
Training loss: 1.8171624691158488
Validation loss: 2.579324524156572

Epoch: 6| Step: 12
Training loss: 2.4621656471635425
Validation loss: 2.577143148860345

Epoch: 6| Step: 13
Training loss: 2.4998341505351678
Validation loss: 2.575030818618986

Epoch: 65| Step: 0
Training loss: 2.5568109022865317
Validation loss: 2.571134797097694

Epoch: 6| Step: 1
Training loss: 2.872450319927936
Validation loss: 2.569405454620457

Epoch: 6| Step: 2
Training loss: 2.672816595839055
Validation loss: 2.569872245458182

Epoch: 6| Step: 3
Training loss: 2.8608616367284165
Validation loss: 2.5669383944514754

Epoch: 6| Step: 4
Training loss: 2.929979965870557
Validation loss: 2.57171847491718

Epoch: 6| Step: 5
Training loss: 2.538444185531098
Validation loss: 2.5708111991321045

Epoch: 6| Step: 6
Training loss: 3.0424713394206835
Validation loss: 2.573639723045789

Epoch: 6| Step: 7
Training loss: 2.4407122060359496
Validation loss: 2.56911838856921

Epoch: 6| Step: 8
Training loss: 2.5430603479626916
Validation loss: 2.567305099261062

Epoch: 6| Step: 9
Training loss: 3.1518336454148623
Validation loss: 2.5699038813635084

Epoch: 6| Step: 10
Training loss: 2.3372229672038767
Validation loss: 2.5763353628977366

Epoch: 6| Step: 11
Training loss: 2.394683882810023
Validation loss: 2.5724019347820897

Epoch: 6| Step: 12
Training loss: 2.7067064142675523
Validation loss: 2.567923443329491

Epoch: 6| Step: 13
Training loss: 2.612659146512789
Validation loss: 2.560374588047675

Epoch: 66| Step: 0
Training loss: 2.6770824526378405
Validation loss: 2.56269215429349

Epoch: 6| Step: 1
Training loss: 2.349827021461843
Validation loss: 2.560289786609105

Epoch: 6| Step: 2
Training loss: 2.799639992049515
Validation loss: 2.5609219196645507

Epoch: 6| Step: 3
Training loss: 2.779667178889719
Validation loss: 2.561682485417021

Epoch: 6| Step: 4
Training loss: 3.136008746407437
Validation loss: 2.56091076330907

Epoch: 6| Step: 5
Training loss: 2.5847325586213303
Validation loss: 2.5626283318864016

Epoch: 6| Step: 6
Training loss: 2.369352452304935
Validation loss: 2.5596727731304583

Epoch: 6| Step: 7
Training loss: 2.346778235745456
Validation loss: 2.556185284256273

Epoch: 6| Step: 8
Training loss: 2.6333554214645685
Validation loss: 2.560754398536697

Epoch: 6| Step: 9
Training loss: 2.544900514947774
Validation loss: 2.5580116755249156

Epoch: 6| Step: 10
Training loss: 2.6544091521622133
Validation loss: 2.5583854609924632

Epoch: 6| Step: 11
Training loss: 2.7954889198101376
Validation loss: 2.5522434158461973

Epoch: 6| Step: 12
Training loss: 2.922936884039095
Validation loss: 2.553101049938885

Epoch: 6| Step: 13
Training loss: 2.9379385762814936
Validation loss: 2.5560731231257026

Epoch: 67| Step: 0
Training loss: 2.6756484841035904
Validation loss: 2.5615813151452675

Epoch: 6| Step: 1
Training loss: 2.4974601241432848
Validation loss: 2.552561459550208

Epoch: 6| Step: 2
Training loss: 2.6872720843525646
Validation loss: 2.5560688790943966

Epoch: 6| Step: 3
Training loss: 2.6219724725693863
Validation loss: 2.553653815112606

Epoch: 6| Step: 4
Training loss: 2.9102339151758985
Validation loss: 2.549853200364527

Epoch: 6| Step: 5
Training loss: 2.541080928494063
Validation loss: 2.5496330539497425

Epoch: 6| Step: 6
Training loss: 2.654138062071953
Validation loss: 2.5509388180290475

Epoch: 6| Step: 7
Training loss: 2.754043380894291
Validation loss: 2.5515666568408437

Epoch: 6| Step: 8
Training loss: 2.481142063819993
Validation loss: 2.5534329537196467

Epoch: 6| Step: 9
Training loss: 2.1746191897204192
Validation loss: 2.5500060418001294

Epoch: 6| Step: 10
Training loss: 2.7792363109946363
Validation loss: 2.546754190586979

Epoch: 6| Step: 11
Training loss: 2.2143022255347846
Validation loss: 2.547203370439034

Epoch: 6| Step: 12
Training loss: 3.337546610417446
Validation loss: 2.548950909498654

Epoch: 6| Step: 13
Training loss: 2.9756062891595616
Validation loss: 2.5477586863072754

Epoch: 68| Step: 0
Training loss: 1.966545444998323
Validation loss: 2.5476548418799374

Epoch: 6| Step: 1
Training loss: 2.7381150308134523
Validation loss: 2.544298831052906

Epoch: 6| Step: 2
Training loss: 2.529940796411965
Validation loss: 2.5484343437706984

Epoch: 6| Step: 3
Training loss: 3.3644651661879617
Validation loss: 2.553936146907051

Epoch: 6| Step: 4
Training loss: 2.823367675188068
Validation loss: 2.5678726102470644

Epoch: 6| Step: 5
Training loss: 2.7679590408624346
Validation loss: 2.5757040042882062

Epoch: 6| Step: 6
Training loss: 3.316926122386085
Validation loss: 2.5597745000595244

Epoch: 6| Step: 7
Training loss: 2.9158406495769937
Validation loss: 2.551168088219466

Epoch: 6| Step: 8
Training loss: 2.154608059885517
Validation loss: 2.546575907051938

Epoch: 6| Step: 9
Training loss: 2.388345267174404
Validation loss: 2.5460423081491914

Epoch: 6| Step: 10
Training loss: 2.8147820433396915
Validation loss: 2.550236642366326

Epoch: 6| Step: 11
Training loss: 2.6218991811589762
Validation loss: 2.553214252083845

Epoch: 6| Step: 12
Training loss: 2.474147449426057
Validation loss: 2.5566641561437

Epoch: 6| Step: 13
Training loss: 2.2947568923409487
Validation loss: 2.5600216829106857

Epoch: 69| Step: 0
Training loss: 2.3934843628107396
Validation loss: 2.5603658116015646

Epoch: 6| Step: 1
Training loss: 3.021876363349615
Validation loss: 2.5649823516476515

Epoch: 6| Step: 2
Training loss: 2.7127401641141464
Validation loss: 2.5633399486167017

Epoch: 6| Step: 3
Training loss: 2.618734966954166
Validation loss: 2.5614130149287653

Epoch: 6| Step: 4
Training loss: 2.702152672679189
Validation loss: 2.5586918858157794

Epoch: 6| Step: 5
Training loss: 3.3622615743859496
Validation loss: 2.5551472910201434

Epoch: 6| Step: 6
Training loss: 2.562519910781545
Validation loss: 2.5521231096762085

Epoch: 6| Step: 7
Training loss: 2.330231193893041
Validation loss: 2.55114241920685

Epoch: 6| Step: 8
Training loss: 2.5922933877629952
Validation loss: 2.545636864889036

Epoch: 6| Step: 9
Training loss: 2.0177369401433727
Validation loss: 2.5419329102529535

Epoch: 6| Step: 10
Training loss: 2.815110753863612
Validation loss: 2.5414253391284216

Epoch: 6| Step: 11
Training loss: 2.671894274190349
Validation loss: 2.5379054166896977

Epoch: 6| Step: 12
Training loss: 2.8354843239953795
Validation loss: 2.5364737435146267

Epoch: 6| Step: 13
Training loss: 2.6583881523993327
Validation loss: 2.533238073699584

Epoch: 70| Step: 0
Training loss: 1.9478549505510492
Validation loss: 2.5359485017228764

Epoch: 6| Step: 1
Training loss: 2.3322988896487384
Validation loss: 2.5356830584447274

Epoch: 6| Step: 2
Training loss: 2.7048445507800034
Validation loss: 2.5348522942553497

Epoch: 6| Step: 3
Training loss: 3.2524533915130656
Validation loss: 2.535148303191392

Epoch: 6| Step: 4
Training loss: 2.296490695488517
Validation loss: 2.5391913435107965

Epoch: 6| Step: 5
Training loss: 2.747389160919524
Validation loss: 2.5372715820583354

Epoch: 6| Step: 6
Training loss: 2.580947348375765
Validation loss: 2.5393429019347433

Epoch: 6| Step: 7
Training loss: 2.595970031012782
Validation loss: 2.529560262941072

Epoch: 6| Step: 8
Training loss: 2.8316880853511615
Validation loss: 2.5362861517417645

Epoch: 6| Step: 9
Training loss: 2.7301732505068617
Validation loss: 2.55091961129539

Epoch: 6| Step: 10
Training loss: 3.399160303881589
Validation loss: 2.5470707745967625

Epoch: 6| Step: 11
Training loss: 2.1807005794216323
Validation loss: 2.5486260383947226

Epoch: 6| Step: 12
Training loss: 2.411686885760407
Validation loss: 2.544291490661619

Epoch: 6| Step: 13
Training loss: 2.862603704581272
Validation loss: 2.531972554378

Epoch: 71| Step: 0
Training loss: 2.5580884594687663
Validation loss: 2.5369600482602217

Epoch: 6| Step: 1
Training loss: 3.013231345394698
Validation loss: 2.5333927645320897

Epoch: 6| Step: 2
Training loss: 2.600824749789934
Validation loss: 2.5280645129838897

Epoch: 6| Step: 3
Training loss: 2.5178271777873458
Validation loss: 2.531470913136188

Epoch: 6| Step: 4
Training loss: 2.4156833380086202
Validation loss: 2.533456115717001

Epoch: 6| Step: 5
Training loss: 2.764340980867266
Validation loss: 2.534796949414378

Epoch: 6| Step: 6
Training loss: 2.619927910257045
Validation loss: 2.5359322526508854

Epoch: 6| Step: 7
Training loss: 2.0654435394039052
Validation loss: 2.5356867019258287

Epoch: 6| Step: 8
Training loss: 2.9220137129715775
Validation loss: 2.5360123531429775

Epoch: 6| Step: 9
Training loss: 2.573640749790921
Validation loss: 2.536600298240973

Epoch: 6| Step: 10
Training loss: 2.910857455370888
Validation loss: 2.5391193246596

Epoch: 6| Step: 11
Training loss: 2.5151402735032393
Validation loss: 2.53595534917912

Epoch: 6| Step: 12
Training loss: 2.8744045138435372
Validation loss: 2.5328289021253703

Epoch: 6| Step: 13
Training loss: 2.771725924331151
Validation loss: 2.531753136822074

Epoch: 72| Step: 0
Training loss: 2.66314359238103
Validation loss: 2.533013604613148

Epoch: 6| Step: 1
Training loss: 2.066433709868941
Validation loss: 2.5276543702985967

Epoch: 6| Step: 2
Training loss: 2.4319143608474567
Validation loss: 2.530708930188563

Epoch: 6| Step: 3
Training loss: 2.2852646500397795
Validation loss: 2.5267439557469302

Epoch: 6| Step: 4
Training loss: 2.655363406150952
Validation loss: 2.5255156503536207

Epoch: 6| Step: 5
Training loss: 3.04227824572942
Validation loss: 2.5207610054253826

Epoch: 6| Step: 6
Training loss: 2.359289407756497
Validation loss: 2.521885696886358

Epoch: 6| Step: 7
Training loss: 2.9092019788714616
Validation loss: 2.5218310522877125

Epoch: 6| Step: 8
Training loss: 2.7686261633740896
Validation loss: 2.5216660083266476

Epoch: 6| Step: 9
Training loss: 2.749849315329668
Validation loss: 2.528337553478014

Epoch: 6| Step: 10
Training loss: 2.6224921826590655
Validation loss: 2.532345099273151

Epoch: 6| Step: 11
Training loss: 2.710356988232751
Validation loss: 2.527323153302295

Epoch: 6| Step: 12
Training loss: 2.6111197663111887
Validation loss: 2.5266118510531372

Epoch: 6| Step: 13
Training loss: 3.191791114339741
Validation loss: 2.5324016980758963

Epoch: 73| Step: 0
Training loss: 2.714909614477564
Validation loss: 2.536925597236465

Epoch: 6| Step: 1
Training loss: 2.87244235174301
Validation loss: 2.550107406398702

Epoch: 6| Step: 2
Training loss: 2.783591666958244
Validation loss: 2.551343761380251

Epoch: 6| Step: 3
Training loss: 2.3703318444847583
Validation loss: 2.5303594647487353

Epoch: 6| Step: 4
Training loss: 2.371020546903356
Validation loss: 2.536871143459369

Epoch: 6| Step: 5
Training loss: 2.4202247165351882
Validation loss: 2.52564804838193

Epoch: 6| Step: 6
Training loss: 2.705324281585551
Validation loss: 2.518388482109966

Epoch: 6| Step: 7
Training loss: 3.0358799448413216
Validation loss: 2.523729037833421

Epoch: 6| Step: 8
Training loss: 2.0868920131834137
Validation loss: 2.5177617446311857

Epoch: 6| Step: 9
Training loss: 2.8315368641752827
Validation loss: 2.522689818797552

Epoch: 6| Step: 10
Training loss: 2.640853420513008
Validation loss: 2.5215292723953113

Epoch: 6| Step: 11
Training loss: 2.5705202708577546
Validation loss: 2.522941705992661

Epoch: 6| Step: 12
Training loss: 2.800730344344303
Validation loss: 2.5227093822231237

Epoch: 6| Step: 13
Training loss: 2.679514086926007
Validation loss: 2.530640642578338

Epoch: 74| Step: 0
Training loss: 3.1541677726095285
Validation loss: 2.528415128566247

Epoch: 6| Step: 1
Training loss: 3.0728392165601632
Validation loss: 2.529057389045245

Epoch: 6| Step: 2
Training loss: 2.6577334581179155
Validation loss: 2.5266932377974007

Epoch: 6| Step: 3
Training loss: 2.987615613416129
Validation loss: 2.5273527118694954

Epoch: 6| Step: 4
Training loss: 2.4696232663624604
Validation loss: 2.5238445256848743

Epoch: 6| Step: 5
Training loss: 2.359418754929803
Validation loss: 2.5227230859815974

Epoch: 6| Step: 6
Training loss: 2.776860834944591
Validation loss: 2.52045874268906

Epoch: 6| Step: 7
Training loss: 2.3008557552068125
Validation loss: 2.5175793324446167

Epoch: 6| Step: 8
Training loss: 2.6710164436339747
Validation loss: 2.5175318155106114

Epoch: 6| Step: 9
Training loss: 2.6847159581035385
Validation loss: 2.514912016551246

Epoch: 6| Step: 10
Training loss: 3.037460885757597
Validation loss: 2.514909393695754

Epoch: 6| Step: 11
Training loss: 2.599042250221939
Validation loss: 2.515949015156884

Epoch: 6| Step: 12
Training loss: 2.160507421938528
Validation loss: 2.5133388074348124

Epoch: 6| Step: 13
Training loss: 1.8201988741402706
Validation loss: 2.5105854204581353

Epoch: 75| Step: 0
Training loss: 2.121259089255431
Validation loss: 2.512886974083602

Epoch: 6| Step: 1
Training loss: 2.7001510754457265
Validation loss: 2.511788263936092

Epoch: 6| Step: 2
Training loss: 2.3621464298219133
Validation loss: 2.514195361754931

Epoch: 6| Step: 3
Training loss: 2.4726074599624606
Validation loss: 2.512595190392736

Epoch: 6| Step: 4
Training loss: 2.5938308887048165
Validation loss: 2.515428428788799

Epoch: 6| Step: 5
Training loss: 2.1784366860810236
Validation loss: 2.5215515710853316

Epoch: 6| Step: 6
Training loss: 3.0196825312806777
Validation loss: 2.5187793013743343

Epoch: 6| Step: 7
Training loss: 2.517830397319877
Validation loss: 2.517675665718574

Epoch: 6| Step: 8
Training loss: 2.7761384089481576
Validation loss: 2.5098168908411127

Epoch: 6| Step: 9
Training loss: 2.593857728490407
Validation loss: 2.5086105043573874

Epoch: 6| Step: 10
Training loss: 2.4586700165795423
Validation loss: 2.5115176170268425

Epoch: 6| Step: 11
Training loss: 2.955640901880528
Validation loss: 2.50970189747136

Epoch: 6| Step: 12
Training loss: 3.2176630351413187
Validation loss: 2.5094535900840094

Epoch: 6| Step: 13
Training loss: 2.5240301139050736
Validation loss: 2.5130550296545318

Epoch: 76| Step: 0
Training loss: 2.793235243241155
Validation loss: 2.5116625710825025

Epoch: 6| Step: 1
Training loss: 2.4220553423278397
Validation loss: 2.508994658685307

Epoch: 6| Step: 2
Training loss: 2.863352026591567
Validation loss: 2.512903024287177

Epoch: 6| Step: 3
Training loss: 2.463381954981389
Validation loss: 2.513529297510649

Epoch: 6| Step: 4
Training loss: 2.6042148026150187
Validation loss: 2.511496763965087

Epoch: 6| Step: 5
Training loss: 2.418148200504777
Validation loss: 2.509082698305992

Epoch: 6| Step: 6
Training loss: 2.280998738704535
Validation loss: 2.513449492320983

Epoch: 6| Step: 7
Training loss: 2.7025080511518422
Validation loss: 2.5088677013481684

Epoch: 6| Step: 8
Training loss: 2.773830504175328
Validation loss: 2.507049381059382

Epoch: 6| Step: 9
Training loss: 2.8173377074758164
Validation loss: 2.510244155169335

Epoch: 6| Step: 10
Training loss: 3.0625488900155293
Validation loss: 2.5104206976851606

Epoch: 6| Step: 11
Training loss: 2.369832691773728
Validation loss: 2.5125630701350876

Epoch: 6| Step: 12
Training loss: 3.097137446210254
Validation loss: 2.511751213279227

Epoch: 6| Step: 13
Training loss: 2.037998784335357
Validation loss: 2.51277071378479

Epoch: 77| Step: 0
Training loss: 2.57421745334992
Validation loss: 2.5058310693701653

Epoch: 6| Step: 1
Training loss: 1.872878845760835
Validation loss: 2.5084685658809596

Epoch: 6| Step: 2
Training loss: 2.5309613852145723
Validation loss: 2.5107152821916694

Epoch: 6| Step: 3
Training loss: 3.288775578757858
Validation loss: 2.5083452017451586

Epoch: 6| Step: 4
Training loss: 2.541797186413411
Validation loss: 2.510369285885593

Epoch: 6| Step: 5
Training loss: 2.128269373271983
Validation loss: 2.5015516710970283

Epoch: 6| Step: 6
Training loss: 3.0947199370294336
Validation loss: 2.5087349879524163

Epoch: 6| Step: 7
Training loss: 2.3543408984860665
Validation loss: 2.502297378985358

Epoch: 6| Step: 8
Training loss: 2.3843115921888733
Validation loss: 2.5040605470722808

Epoch: 6| Step: 9
Training loss: 2.2890964544596684
Validation loss: 2.501416035799679

Epoch: 6| Step: 10
Training loss: 2.9927362879983184
Validation loss: 2.4987286672974416

Epoch: 6| Step: 11
Training loss: 2.794612032965385
Validation loss: 2.5066975841576977

Epoch: 6| Step: 12
Training loss: 3.301761422977544
Validation loss: 2.5085100924880854

Epoch: 6| Step: 13
Training loss: 2.11816428761813
Validation loss: 2.5069511415832992

Epoch: 78| Step: 0
Training loss: 3.279235075867586
Validation loss: 2.5096577226571717

Epoch: 6| Step: 1
Training loss: 2.2404883988158186
Validation loss: 2.506761261249155

Epoch: 6| Step: 2
Training loss: 2.829353697881777
Validation loss: 2.508610741957612

Epoch: 6| Step: 3
Training loss: 2.7664133446168027
Validation loss: 2.5100750169650983

Epoch: 6| Step: 4
Training loss: 2.458069889586601
Validation loss: 2.507470429443565

Epoch: 6| Step: 5
Training loss: 2.9489095967931256
Validation loss: 2.5081178948619973

Epoch: 6| Step: 6
Training loss: 2.3693441003280373
Validation loss: 2.497129652193228

Epoch: 6| Step: 7
Training loss: 2.015961138471824
Validation loss: 2.4971737940270557

Epoch: 6| Step: 8
Training loss: 2.379444180508191
Validation loss: 2.498798463092867

Epoch: 6| Step: 9
Training loss: 2.6798769158239457
Validation loss: 2.498690707362146

Epoch: 6| Step: 10
Training loss: 2.760117990901829
Validation loss: 2.5093406545047126

Epoch: 6| Step: 11
Training loss: 2.33864974442641
Validation loss: 2.4982057013387378

Epoch: 6| Step: 12
Training loss: 2.736371167298429
Validation loss: 2.4988013652453787

Epoch: 6| Step: 13
Training loss: 2.422767720737979
Validation loss: 2.498236654199588

Epoch: 79| Step: 0
Training loss: 2.840413578168494
Validation loss: 2.4975734219277155

Epoch: 6| Step: 1
Training loss: 2.192665214446853
Validation loss: 2.4984839133889287

Epoch: 6| Step: 2
Training loss: 2.2530238706879357
Validation loss: 2.498721224841961

Epoch: 6| Step: 3
Training loss: 2.514168643548138
Validation loss: 2.4982143382752793

Epoch: 6| Step: 4
Training loss: 2.7750611616388174
Validation loss: 2.502105605010158

Epoch: 6| Step: 5
Training loss: 2.6553208465103793
Validation loss: 2.504704737390771

Epoch: 6| Step: 6
Training loss: 2.9309657042366806
Validation loss: 2.5012975822115657

Epoch: 6| Step: 7
Training loss: 2.342725606209829
Validation loss: 2.4982975249198054

Epoch: 6| Step: 8
Training loss: 2.704204894874713
Validation loss: 2.50120089616034

Epoch: 6| Step: 9
Training loss: 3.1163429894556995
Validation loss: 2.4994504006578553

Epoch: 6| Step: 10
Training loss: 2.8168536080918662
Validation loss: 2.4959721861495954

Epoch: 6| Step: 11
Training loss: 2.321242842737687
Validation loss: 2.4922752564225408

Epoch: 6| Step: 12
Training loss: 2.3916589832071726
Validation loss: 2.4907013100070383

Epoch: 6| Step: 13
Training loss: 2.355270048398911
Validation loss: 2.497908273470164

Epoch: 80| Step: 0
Training loss: 2.711294189205576
Validation loss: 2.4907014695461545

Epoch: 6| Step: 1
Training loss: 2.5936732453169387
Validation loss: 2.492600186578184

Epoch: 6| Step: 2
Training loss: 2.360494284996414
Validation loss: 2.4921081833290604

Epoch: 6| Step: 3
Training loss: 2.2264304674052107
Validation loss: 2.4911833267745447

Epoch: 6| Step: 4
Training loss: 2.582627774352261
Validation loss: 2.485366639376953

Epoch: 6| Step: 5
Training loss: 2.7913872783025795
Validation loss: 2.4870281327837964

Epoch: 6| Step: 6
Training loss: 2.824674239829653
Validation loss: 2.488593177267621

Epoch: 6| Step: 7
Training loss: 2.872049227173111
Validation loss: 2.488580930220989

Epoch: 6| Step: 8
Training loss: 3.1593345450840165
Validation loss: 2.4895483251262336

Epoch: 6| Step: 9
Training loss: 2.4970645837341405
Validation loss: 2.49780470305779

Epoch: 6| Step: 10
Training loss: 2.425822726031794
Validation loss: 2.4913799767371367

Epoch: 6| Step: 11
Training loss: 2.590331525020568
Validation loss: 2.491978874761969

Epoch: 6| Step: 12
Training loss: 2.434343201181065
Validation loss: 2.49223383399041

Epoch: 6| Step: 13
Training loss: 2.2042757099872166
Validation loss: 2.49318234349427

Epoch: 81| Step: 0
Training loss: 2.697044457408297
Validation loss: 2.4880698217517905

Epoch: 6| Step: 1
Training loss: 1.5655077404950533
Validation loss: 2.491037563869229

Epoch: 6| Step: 2
Training loss: 2.9830140211112792
Validation loss: 2.490210104431358

Epoch: 6| Step: 3
Training loss: 2.88938968140645
Validation loss: 2.487477586475909

Epoch: 6| Step: 4
Training loss: 2.573849641446859
Validation loss: 2.4998463265553776

Epoch: 6| Step: 5
Training loss: 2.102973322620688
Validation loss: 2.4859396687739337

Epoch: 6| Step: 6
Training loss: 2.3030832688007146
Validation loss: 2.4950695055681247

Epoch: 6| Step: 7
Training loss: 2.541633501513951
Validation loss: 2.4980187194525976

Epoch: 6| Step: 8
Training loss: 2.2676449945728128
Validation loss: 2.486862760419271

Epoch: 6| Step: 9
Training loss: 2.6257502074195704
Validation loss: 2.490214005929256

Epoch: 6| Step: 10
Training loss: 2.6344836446819477
Validation loss: 2.4914933436743287

Epoch: 6| Step: 11
Training loss: 3.500062124518404
Validation loss: 2.4917319587990048

Epoch: 6| Step: 12
Training loss: 2.650582224386722
Validation loss: 2.4971199373842308

Epoch: 6| Step: 13
Training loss: 2.452289998029604
Validation loss: 2.494724349757583

Epoch: 82| Step: 0
Training loss: 2.3305074291491406
Validation loss: 2.4984900206007192

Epoch: 6| Step: 1
Training loss: 3.1293376572812988
Validation loss: 2.491180439673506

Epoch: 6| Step: 2
Training loss: 2.7800124769136656
Validation loss: 2.5004589136444237

Epoch: 6| Step: 3
Training loss: 2.3819357337705886
Validation loss: 2.4991214162052615

Epoch: 6| Step: 4
Training loss: 2.0390458964990916
Validation loss: 2.5013369323325683

Epoch: 6| Step: 5
Training loss: 2.4979031352190204
Validation loss: 2.4988119401835482

Epoch: 6| Step: 6
Training loss: 2.43916752825549
Validation loss: 2.4977926363998937

Epoch: 6| Step: 7
Training loss: 2.2671425834007968
Validation loss: 2.4963532234846455

Epoch: 6| Step: 8
Training loss: 3.0471945570604944
Validation loss: 2.4931458610630317

Epoch: 6| Step: 9
Training loss: 2.7610754318626993
Validation loss: 2.4914854410113465

Epoch: 6| Step: 10
Training loss: 2.862831236485768
Validation loss: 2.4901377301380068

Epoch: 6| Step: 11
Training loss: 2.3810465287713454
Validation loss: 2.49066435249539

Epoch: 6| Step: 12
Training loss: 2.7120832061494053
Validation loss: 2.4845620650714397

Epoch: 6| Step: 13
Training loss: 2.4695238276813285
Validation loss: 2.4856577426696833

Epoch: 83| Step: 0
Training loss: 2.337379444297818
Validation loss: 2.4942628357056025

Epoch: 6| Step: 1
Training loss: 2.2619885957330914
Validation loss: 2.5000681549954584

Epoch: 6| Step: 2
Training loss: 2.5090246390649127
Validation loss: 2.5015513216333223

Epoch: 6| Step: 3
Training loss: 3.2000744691766734
Validation loss: 2.4856349541178093

Epoch: 6| Step: 4
Training loss: 3.1831169660711405
Validation loss: 2.4888928518613795

Epoch: 6| Step: 5
Training loss: 2.756279624727858
Validation loss: 2.4949791399148062

Epoch: 6| Step: 6
Training loss: 2.250540562438534
Validation loss: 2.4896239166995437

Epoch: 6| Step: 7
Training loss: 2.6892612807166794
Validation loss: 2.4987368253481748

Epoch: 6| Step: 8
Training loss: 2.75945701952441
Validation loss: 2.4966567175233605

Epoch: 6| Step: 9
Training loss: 2.5689899787276755
Validation loss: 2.492685744526897

Epoch: 6| Step: 10
Training loss: 2.1703375994094
Validation loss: 2.4929588503368563

Epoch: 6| Step: 11
Training loss: 2.3582289988305405
Validation loss: 2.4897486473539723

Epoch: 6| Step: 12
Training loss: 2.2445908269998465
Validation loss: 2.498937118607716

Epoch: 6| Step: 13
Training loss: 3.004993891654257
Validation loss: 2.491299669377039

Epoch: 84| Step: 0
Training loss: 2.703152871401651
Validation loss: 2.490690955896542

Epoch: 6| Step: 1
Training loss: 2.8847256233474043
Validation loss: 2.4857875479039864

Epoch: 6| Step: 2
Training loss: 2.6198323564548427
Validation loss: 2.4896806886756244

Epoch: 6| Step: 3
Training loss: 2.5820638449684794
Validation loss: 2.4890276449652227

Epoch: 6| Step: 4
Training loss: 2.6792529229200417
Validation loss: 2.4875505094016774

Epoch: 6| Step: 5
Training loss: 2.3468650970046867
Validation loss: 2.488152525090845

Epoch: 6| Step: 6
Training loss: 2.224990878997281
Validation loss: 2.4899157191826213

Epoch: 6| Step: 7
Training loss: 2.870398446313784
Validation loss: 2.4846345617947683

Epoch: 6| Step: 8
Training loss: 2.609902699728628
Validation loss: 2.4893554732195105

Epoch: 6| Step: 9
Training loss: 1.9179048546988056
Validation loss: 2.487057658982353

Epoch: 6| Step: 10
Training loss: 2.6335478980939717
Validation loss: 2.4916123829757892

Epoch: 6| Step: 11
Training loss: 2.593263879285604
Validation loss: 2.4926899211207263

Epoch: 6| Step: 12
Training loss: 2.754424610457215
Validation loss: 2.4960006991032904

Epoch: 6| Step: 13
Training loss: 2.9411813921045753
Validation loss: 2.492417567046447

Epoch: 85| Step: 0
Training loss: 3.1121553038651486
Validation loss: 2.4898146411481714

Epoch: 6| Step: 1
Training loss: 2.416137790906387
Validation loss: 2.490967135859477

Epoch: 6| Step: 2
Training loss: 1.9506078139614147
Validation loss: 2.489752254315121

Epoch: 6| Step: 3
Training loss: 2.3923801137768987
Validation loss: 2.48655358845746

Epoch: 6| Step: 4
Training loss: 2.662833817021399
Validation loss: 2.4865964478540517

Epoch: 6| Step: 5
Training loss: 1.9494575552965892
Validation loss: 2.491854431154201

Epoch: 6| Step: 6
Training loss: 2.684510098167464
Validation loss: 2.482624837010119

Epoch: 6| Step: 7
Training loss: 2.514524704935256
Validation loss: 2.4792128379646945

Epoch: 6| Step: 8
Training loss: 2.6918553391538618
Validation loss: 2.4851097603856336

Epoch: 6| Step: 9
Training loss: 2.663271431360696
Validation loss: 2.49025955486657

Epoch: 6| Step: 10
Training loss: 2.4945311811849153
Validation loss: 2.4849761619422313

Epoch: 6| Step: 11
Training loss: 2.47776981612876
Validation loss: 2.480269224297117

Epoch: 6| Step: 12
Training loss: 3.1461330717332525
Validation loss: 2.490144408352385

Epoch: 6| Step: 13
Training loss: 2.693584120172427
Validation loss: 2.475452338732553

Epoch: 86| Step: 0
Training loss: 2.351021840748978
Validation loss: 2.4843698337589184

Epoch: 6| Step: 1
Training loss: 2.5370332561113083
Validation loss: 2.4822363455228404

Epoch: 6| Step: 2
Training loss: 2.5168766675156857
Validation loss: 2.4895121565557283

Epoch: 6| Step: 3
Training loss: 2.93042406105538
Validation loss: 2.4933503087973747

Epoch: 6| Step: 4
Training loss: 2.266761547328053
Validation loss: 2.4916210826374177

Epoch: 6| Step: 5
Training loss: 2.5866747954657074
Validation loss: 2.4892618192508538

Epoch: 6| Step: 6
Training loss: 2.8658079731639896
Validation loss: 2.4837831315990697

Epoch: 6| Step: 7
Training loss: 2.2263525077442283
Validation loss: 2.4839095313397737

Epoch: 6| Step: 8
Training loss: 2.3305157157009586
Validation loss: 2.48676016011356

Epoch: 6| Step: 9
Training loss: 2.5630741871706384
Validation loss: 2.486217703094068

Epoch: 6| Step: 10
Training loss: 2.3829452727801335
Validation loss: 2.4802631763566714

Epoch: 6| Step: 11
Training loss: 3.216380311807151
Validation loss: 2.4792797693263795

Epoch: 6| Step: 12
Training loss: 2.598731714636623
Validation loss: 2.4831563091760622

Epoch: 6| Step: 13
Training loss: 2.4829417959052176
Validation loss: 2.481615769517863

Epoch: 87| Step: 0
Training loss: 2.3968041042700183
Validation loss: 2.481106109034216

Epoch: 6| Step: 1
Training loss: 2.265665409122395
Validation loss: 2.4759348044781397

Epoch: 6| Step: 2
Training loss: 2.478043363171743
Validation loss: 2.47531886117891

Epoch: 6| Step: 3
Training loss: 2.603876316414684
Validation loss: 2.4730228515897847

Epoch: 6| Step: 4
Training loss: 2.273763626670165
Validation loss: 2.4787006795070403

Epoch: 6| Step: 5
Training loss: 2.847903226547693
Validation loss: 2.4819799910821607

Epoch: 6| Step: 6
Training loss: 3.1098506697837585
Validation loss: 2.4732813233393554

Epoch: 6| Step: 7
Training loss: 2.5859323369000573
Validation loss: 2.4739314241786277

Epoch: 6| Step: 8
Training loss: 2.368613641281549
Validation loss: 2.4800642990421484

Epoch: 6| Step: 9
Training loss: 2.684293208802413
Validation loss: 2.485896526313097

Epoch: 6| Step: 10
Training loss: 2.434267884469952
Validation loss: 2.481770539792428

Epoch: 6| Step: 11
Training loss: 3.12403763257755
Validation loss: 2.4861997624674754

Epoch: 6| Step: 12
Training loss: 2.253268411122442
Validation loss: 2.4791236253950433

Epoch: 6| Step: 13
Training loss: 2.222827871230066
Validation loss: 2.4822040405260224

Epoch: 88| Step: 0
Training loss: 3.0518620294705046
Validation loss: 2.4826766873011312

Epoch: 6| Step: 1
Training loss: 2.3604331769868048
Validation loss: 2.4832549059301035

Epoch: 6| Step: 2
Training loss: 2.430094694011489
Validation loss: 2.4813321911117217

Epoch: 6| Step: 3
Training loss: 2.593886222479401
Validation loss: 2.475519066784629

Epoch: 6| Step: 4
Training loss: 2.836072177684075
Validation loss: 2.473435603012736

Epoch: 6| Step: 5
Training loss: 2.654703924477406
Validation loss: 2.474202392318482

Epoch: 6| Step: 6
Training loss: 2.4239892406539583
Validation loss: 2.473237221008004

Epoch: 6| Step: 7
Training loss: 2.770282164707185
Validation loss: 2.4739267179911777

Epoch: 6| Step: 8
Training loss: 2.122534499679933
Validation loss: 2.467116406934232

Epoch: 6| Step: 9
Training loss: 2.7114136027689986
Validation loss: 2.4755484734283053

Epoch: 6| Step: 10
Training loss: 2.9059444800138303
Validation loss: 2.475203709936906

Epoch: 6| Step: 11
Training loss: 2.3714117751289967
Validation loss: 2.481681747412051

Epoch: 6| Step: 12
Training loss: 2.1611910612631386
Validation loss: 2.4791945180744324

Epoch: 6| Step: 13
Training loss: 2.47442438387075
Validation loss: 2.4811641649442144

Epoch: 89| Step: 0
Training loss: 2.1344103295011942
Validation loss: 2.48474008848608

Epoch: 6| Step: 1
Training loss: 2.488465402636659
Validation loss: 2.4782244924910857

Epoch: 6| Step: 2
Training loss: 2.814341980369604
Validation loss: 2.4749224152911564

Epoch: 6| Step: 3
Training loss: 2.628498380176146
Validation loss: 2.4758642838977827

Epoch: 6| Step: 4
Training loss: 2.0923010523936694
Validation loss: 2.4687298802066975

Epoch: 6| Step: 5
Training loss: 2.8946215246128384
Validation loss: 2.466886291735791

Epoch: 6| Step: 6
Training loss: 2.8961811177010874
Validation loss: 2.474314587022509

Epoch: 6| Step: 7
Training loss: 2.710554640061069
Validation loss: 2.467894506510085

Epoch: 6| Step: 8
Training loss: 2.5186448068163227
Validation loss: 2.4662907499751494

Epoch: 6| Step: 9
Training loss: 2.9342895170360404
Validation loss: 2.4682385361485495

Epoch: 6| Step: 10
Training loss: 2.8179749499602575
Validation loss: 2.4754500914250137

Epoch: 6| Step: 11
Training loss: 2.3299958565474577
Validation loss: 2.4837103540423757

Epoch: 6| Step: 12
Training loss: 2.405345994642532
Validation loss: 2.48428989160656

Epoch: 6| Step: 13
Training loss: 2.1223479158261886
Validation loss: 2.4807753486080175

Epoch: 90| Step: 0
Training loss: 2.3213958779851964
Validation loss: 2.4842968014739952

Epoch: 6| Step: 1
Training loss: 2.913230470402512
Validation loss: 2.474190555849913

Epoch: 6| Step: 2
Training loss: 2.5678382722012296
Validation loss: 2.476063434364456

Epoch: 6| Step: 3
Training loss: 2.2980175679782815
Validation loss: 2.4741050489322105

Epoch: 6| Step: 4
Training loss: 2.783244414441538
Validation loss: 2.4773984715547224

Epoch: 6| Step: 5
Training loss: 2.0535624509816564
Validation loss: 2.475858393717454

Epoch: 6| Step: 6
Training loss: 2.2302052464137896
Validation loss: 2.482201639245844

Epoch: 6| Step: 7
Training loss: 3.151178648101916
Validation loss: 2.4787950851692924

Epoch: 6| Step: 8
Training loss: 2.391212241656867
Validation loss: 2.4747691917046506

Epoch: 6| Step: 9
Training loss: 2.2105904566271772
Validation loss: 2.4720069551030557

Epoch: 6| Step: 10
Training loss: 2.950152803763181
Validation loss: 2.474155945498231

Epoch: 6| Step: 11
Training loss: 2.5692018468846314
Validation loss: 2.48123543172126

Epoch: 6| Step: 12
Training loss: 2.7579331844388655
Validation loss: 2.4845197943312645

Epoch: 6| Step: 13
Training loss: 2.4101528866340995
Validation loss: 2.482826133964272

Epoch: 91| Step: 0
Training loss: 1.9510595768562853
Validation loss: 2.490635180163349

Epoch: 6| Step: 1
Training loss: 2.867687545536592
Validation loss: 2.482035352947465

Epoch: 6| Step: 2
Training loss: 2.636325744727311
Validation loss: 2.482736202961828

Epoch: 6| Step: 3
Training loss: 2.8914275833658074
Validation loss: 2.4799961551000673

Epoch: 6| Step: 4
Training loss: 2.4935675838743814
Validation loss: 2.485588832838611

Epoch: 6| Step: 5
Training loss: 2.539917881006124
Validation loss: 2.4837080182138536

Epoch: 6| Step: 6
Training loss: 2.8561401412838325
Validation loss: 2.483633942512337

Epoch: 6| Step: 7
Training loss: 2.4058407522187792
Validation loss: 2.48441442622284

Epoch: 6| Step: 8
Training loss: 2.6545880672340973
Validation loss: 2.4850484547026137

Epoch: 6| Step: 9
Training loss: 2.7577360753176507
Validation loss: 2.4834022136924037

Epoch: 6| Step: 10
Training loss: 2.210350578775075
Validation loss: 2.485935656668545

Epoch: 6| Step: 11
Training loss: 2.847913774899566
Validation loss: 2.482529536568067

Epoch: 6| Step: 12
Training loss: 2.3308967629527175
Validation loss: 2.484238402891952

Epoch: 6| Step: 13
Training loss: 2.853367565995451
Validation loss: 2.4864083052674864

Epoch: 92| Step: 0
Training loss: 2.2169444299735663
Validation loss: 2.4847908471713476

Epoch: 6| Step: 1
Training loss: 2.7477968233672816
Validation loss: 2.4852200556389676

Epoch: 6| Step: 2
Training loss: 2.6813133356754566
Validation loss: 2.48501650607117

Epoch: 6| Step: 3
Training loss: 2.023864229782537
Validation loss: 2.4814598366308434

Epoch: 6| Step: 4
Training loss: 2.3735855307507987
Validation loss: 2.486483768566897

Epoch: 6| Step: 5
Training loss: 2.8882162419567434
Validation loss: 2.481003478877437

Epoch: 6| Step: 6
Training loss: 2.75079100243341
Validation loss: 2.4794665136581893

Epoch: 6| Step: 7
Training loss: 2.184898355245366
Validation loss: 2.479660807712076

Epoch: 6| Step: 8
Training loss: 2.5155042536408976
Validation loss: 2.481281313630526

Epoch: 6| Step: 9
Training loss: 3.330038031283565
Validation loss: 2.4762862860742425

Epoch: 6| Step: 10
Training loss: 2.019340579921095
Validation loss: 2.470914334603936

Epoch: 6| Step: 11
Training loss: 2.754967278149473
Validation loss: 2.471370706345443

Epoch: 6| Step: 12
Training loss: 2.414890381909834
Validation loss: 2.4833728600456295

Epoch: 6| Step: 13
Training loss: 2.405471279419241
Validation loss: 2.4904479170849996

Epoch: 93| Step: 0
Training loss: 2.18884432220702
Validation loss: 2.5421098703115272

Epoch: 6| Step: 1
Training loss: 2.222461014739321
Validation loss: 2.5744563501020816

Epoch: 6| Step: 2
Training loss: 2.328329397356133
Validation loss: 2.5878676848924287

Epoch: 6| Step: 3
Training loss: 3.1633827515397592
Validation loss: 2.6333775277191642

Epoch: 6| Step: 4
Training loss: 2.418120889391527
Validation loss: 2.5325406869404707

Epoch: 6| Step: 5
Training loss: 2.11613646597592
Validation loss: 2.481661388202875

Epoch: 6| Step: 6
Training loss: 2.4672994094216496
Validation loss: 2.473904439774139

Epoch: 6| Step: 7
Training loss: 3.075839515775594
Validation loss: 2.4841030299871845

Epoch: 6| Step: 8
Training loss: 2.4613669368927025
Validation loss: 2.4805451068489615

Epoch: 6| Step: 9
Training loss: 2.7807458999358006
Validation loss: 2.4863455932355154

Epoch: 6| Step: 10
Training loss: 2.4506136923589663
Validation loss: 2.4945632309680037

Epoch: 6| Step: 11
Training loss: 3.170954528444071
Validation loss: 2.5082117794742858

Epoch: 6| Step: 12
Training loss: 3.2631289054994825
Validation loss: 2.514581325586039

Epoch: 6| Step: 13
Training loss: 2.240920822215548
Validation loss: 2.5283019869560057

Epoch: 94| Step: 0
Training loss: 2.8358892431435754
Validation loss: 2.5329434965954714

Epoch: 6| Step: 1
Training loss: 2.849702411306804
Validation loss: 2.5315419487895396

Epoch: 6| Step: 2
Training loss: 3.166004931592444
Validation loss: 2.527747207032886

Epoch: 6| Step: 3
Training loss: 3.027816085884175
Validation loss: 2.531442548547584

Epoch: 6| Step: 4
Training loss: 2.525196702301613
Validation loss: 2.5272827612756914

Epoch: 6| Step: 5
Training loss: 1.8587152288246374
Validation loss: 2.528932837329909

Epoch: 6| Step: 6
Training loss: 2.7199861193751533
Validation loss: 2.5237373984810914

Epoch: 6| Step: 7
Training loss: 2.8587255522062476
Validation loss: 2.521899720251606

Epoch: 6| Step: 8
Training loss: 2.88199974119356
Validation loss: 2.5212025857986293

Epoch: 6| Step: 9
Training loss: 2.749456958906281
Validation loss: 2.5161365281184804

Epoch: 6| Step: 10
Training loss: 2.6328802354741825
Validation loss: 2.5184005999801515

Epoch: 6| Step: 11
Training loss: 1.7306988220891473
Validation loss: 2.5119557286186147

Epoch: 6| Step: 12
Training loss: 1.8181110216575758
Validation loss: 2.514936048732345

Epoch: 6| Step: 13
Training loss: 2.913678427741408
Validation loss: 2.513084250063389

Epoch: 95| Step: 0
Training loss: 3.1579627498195806
Validation loss: 2.5075666043635643

Epoch: 6| Step: 1
Training loss: 2.9224790876829787
Validation loss: 2.507463108018284

Epoch: 6| Step: 2
Training loss: 2.662715806408608
Validation loss: 2.507373965573723

Epoch: 6| Step: 3
Training loss: 2.155955418906093
Validation loss: 2.504645006022011

Epoch: 6| Step: 4
Training loss: 2.483636038421088
Validation loss: 2.5050734855751258

Epoch: 6| Step: 5
Training loss: 3.0578108719795583
Validation loss: 2.5000983695704226

Epoch: 6| Step: 6
Training loss: 2.8460528094069346
Validation loss: 2.4932243558030938

Epoch: 6| Step: 7
Training loss: 2.1656602820843025
Validation loss: 2.491031454338198

Epoch: 6| Step: 8
Training loss: 2.5323194905275503
Validation loss: 2.4880542342161514

Epoch: 6| Step: 9
Training loss: 2.6686195931299226
Validation loss: 2.4891306307261276

Epoch: 6| Step: 10
Training loss: 3.2527191817770693
Validation loss: 2.490659063689426

Epoch: 6| Step: 11
Training loss: 2.1684282795289063
Validation loss: 2.484454923419808

Epoch: 6| Step: 12
Training loss: 1.8535473321387392
Validation loss: 2.4874676822115696

Epoch: 6| Step: 13
Training loss: 2.3134666690639025
Validation loss: 2.482915477565688

Epoch: 96| Step: 0
Training loss: 2.6038049879050202
Validation loss: 2.4864766250617265

Epoch: 6| Step: 1
Training loss: 2.9023657652891477
Validation loss: 2.4836442780452157

Epoch: 6| Step: 2
Training loss: 2.425859090689494
Validation loss: 2.480273269600045

Epoch: 6| Step: 3
Training loss: 2.5576106621599655
Validation loss: 2.47862584495514

Epoch: 6| Step: 4
Training loss: 3.0163535389398572
Validation loss: 2.4790168417742824

Epoch: 6| Step: 5
Training loss: 2.5609728286475524
Validation loss: 2.478440015284371

Epoch: 6| Step: 6
Training loss: 2.019448963016222
Validation loss: 2.480784478706536

Epoch: 6| Step: 7
Training loss: 2.5428523023813385
Validation loss: 2.4736009413248157

Epoch: 6| Step: 8
Training loss: 2.907991113357923
Validation loss: 2.4795508340833847

Epoch: 6| Step: 9
Training loss: 2.524239332988272
Validation loss: 2.4738468479668945

Epoch: 6| Step: 10
Training loss: 2.8077771693550515
Validation loss: 2.479255696041817

Epoch: 6| Step: 11
Training loss: 2.9060043723381317
Validation loss: 2.47715197105269

Epoch: 6| Step: 12
Training loss: 2.4162920190085195
Validation loss: 2.48021988709146

Epoch: 6| Step: 13
Training loss: 1.6113020831228921
Validation loss: 2.4836923873048087

Epoch: 97| Step: 0
Training loss: 2.9208688890702836
Validation loss: 2.476735089983999

Epoch: 6| Step: 1
Training loss: 2.3787980078514868
Validation loss: 2.470431467433255

Epoch: 6| Step: 2
Training loss: 2.9487013205034964
Validation loss: 2.4781508621976496

Epoch: 6| Step: 3
Training loss: 1.831541992447587
Validation loss: 2.476413806579063

Epoch: 6| Step: 4
Training loss: 2.649008630256808
Validation loss: 2.475061099906971

Epoch: 6| Step: 5
Training loss: 2.458220807964665
Validation loss: 2.481550070092559

Epoch: 6| Step: 6
Training loss: 2.2587398749643364
Validation loss: 2.4808602412102227

Epoch: 6| Step: 7
Training loss: 2.2387162296851435
Validation loss: 2.4756648926994584

Epoch: 6| Step: 8
Training loss: 2.5066426718692942
Validation loss: 2.4760230566942822

Epoch: 6| Step: 9
Training loss: 2.3295179462711832
Validation loss: 2.475104768378723

Epoch: 6| Step: 10
Training loss: 2.7111893682528603
Validation loss: 2.4789761675778665

Epoch: 6| Step: 11
Training loss: 2.8599252640356077
Validation loss: 2.476951576580949

Epoch: 6| Step: 12
Training loss: 2.862272368463052
Validation loss: 2.472107049376146

Epoch: 6| Step: 13
Training loss: 2.8246691754836943
Validation loss: 2.4738774068880858

Epoch: 98| Step: 0
Training loss: 2.380201265977068
Validation loss: 2.476945945666375

Epoch: 6| Step: 1
Training loss: 2.64228597014219
Validation loss: 2.47873296603892

Epoch: 6| Step: 2
Training loss: 2.8231217613649235
Validation loss: 2.4783557131829337

Epoch: 6| Step: 3
Training loss: 2.295284213417007
Validation loss: 2.47563842477026

Epoch: 6| Step: 4
Training loss: 2.79041639960177
Validation loss: 2.4754173126074317

Epoch: 6| Step: 5
Training loss: 2.452169244298922
Validation loss: 2.4758972654388076

Epoch: 6| Step: 6
Training loss: 2.187296394681909
Validation loss: 2.4754228988420897

Epoch: 6| Step: 7
Training loss: 2.7571573749078135
Validation loss: 2.476172768526026

Epoch: 6| Step: 8
Training loss: 2.7961481098135987
Validation loss: 2.472157022661798

Epoch: 6| Step: 9
Training loss: 2.4848620818950975
Validation loss: 2.4780739745715197

Epoch: 6| Step: 10
Training loss: 2.567222151983875
Validation loss: 2.474027120068935

Epoch: 6| Step: 11
Training loss: 2.0525065984399182
Validation loss: 2.48340905402631

Epoch: 6| Step: 12
Training loss: 2.5464209403411124
Validation loss: 2.4794722670578366

Epoch: 6| Step: 13
Training loss: 2.9852970955634044
Validation loss: 2.478679742732791

Epoch: 99| Step: 0
Training loss: 2.31505175868397
Validation loss: 2.4811232777096155

Epoch: 6| Step: 1
Training loss: 2.378199079164303
Validation loss: 2.4787428410808725

Epoch: 6| Step: 2
Training loss: 2.5023062558778784
Validation loss: 2.4835857841217552

Epoch: 6| Step: 3
Training loss: 1.6081264059666263
Validation loss: 2.4811928000210837

Epoch: 6| Step: 4
Training loss: 2.9915611468082637
Validation loss: 2.4719415950686088

Epoch: 6| Step: 5
Training loss: 2.3147184710762985
Validation loss: 2.4776377785432713

Epoch: 6| Step: 6
Training loss: 2.354022896576714
Validation loss: 2.482535346894568

Epoch: 6| Step: 7
Training loss: 2.6881777773662647
Validation loss: 2.480299864298589

Epoch: 6| Step: 8
Training loss: 2.7110450569385107
Validation loss: 2.485018025159544

Epoch: 6| Step: 9
Training loss: 2.5469373449640185
Validation loss: 2.4817183103070453

Epoch: 6| Step: 10
Training loss: 2.7103642893799793
Validation loss: 2.487630314824051

Epoch: 6| Step: 11
Training loss: 3.1460630488786347
Validation loss: 2.4789655080229225

Epoch: 6| Step: 12
Training loss: 2.8147534138087646
Validation loss: 2.485978526718561

Epoch: 6| Step: 13
Training loss: 2.6424766233451407
Validation loss: 2.4911686838739526

Epoch: 100| Step: 0
Training loss: 2.342206421229183
Validation loss: 2.484634577787635

Epoch: 6| Step: 1
Training loss: 2.5091921615023285
Validation loss: 2.482901786157434

Epoch: 6| Step: 2
Training loss: 2.492350414535779
Validation loss: 2.4863302506015477

Epoch: 6| Step: 3
Training loss: 2.4432748708283696
Validation loss: 2.488777913541039

Epoch: 6| Step: 4
Training loss: 2.944543388991461
Validation loss: 2.4836048875950776

Epoch: 6| Step: 5
Training loss: 1.8307993962657585
Validation loss: 2.4857571194157475

Epoch: 6| Step: 6
Training loss: 2.822400448228623
Validation loss: 2.4821052339322036

Epoch: 6| Step: 7
Training loss: 3.160801542246101
Validation loss: 2.4764744595543626

Epoch: 6| Step: 8
Training loss: 2.381492774582401
Validation loss: 2.4694851452744397

Epoch: 6| Step: 9
Training loss: 2.6336972705431068
Validation loss: 2.4676322660132266

Epoch: 6| Step: 10
Training loss: 2.712260426431904
Validation loss: 2.467501908301247

Epoch: 6| Step: 11
Training loss: 2.4709102016111935
Validation loss: 2.4710916929812314

Epoch: 6| Step: 12
Training loss: 2.7253223648478886
Validation loss: 2.484134486490237

Epoch: 6| Step: 13
Training loss: 2.452426689522129
Validation loss: 2.4728526057039355

Epoch: 101| Step: 0
Training loss: 3.0595221541553803
Validation loss: 2.4693691426932385

Epoch: 6| Step: 1
Training loss: 1.7507514021651467
Validation loss: 2.469637039430429

Epoch: 6| Step: 2
Training loss: 2.760263537112267
Validation loss: 2.471706053132129

Epoch: 6| Step: 3
Training loss: 2.5311307525803
Validation loss: 2.4702341310575435

Epoch: 6| Step: 4
Training loss: 2.3860046017547254
Validation loss: 2.4627527555820032

Epoch: 6| Step: 5
Training loss: 2.4399302178707107
Validation loss: 2.4766215930069992

Epoch: 6| Step: 6
Training loss: 2.7507949027037117
Validation loss: 2.47507526013553

Epoch: 6| Step: 7
Training loss: 2.866373138777142
Validation loss: 2.474916795815511

Epoch: 6| Step: 8
Training loss: 2.7278720804018897
Validation loss: 2.480572107119112

Epoch: 6| Step: 9
Training loss: 2.113332243637301
Validation loss: 2.4729914385303795

Epoch: 6| Step: 10
Training loss: 2.277966579376302
Validation loss: 2.476727870229425

Epoch: 6| Step: 11
Training loss: 1.8826539538731433
Validation loss: 2.4678534638311245

Epoch: 6| Step: 12
Training loss: 3.157697591149038
Validation loss: 2.467166940330829

Epoch: 6| Step: 13
Training loss: 2.5664064357995557
Validation loss: 2.470819756490407

Epoch: 102| Step: 0
Training loss: 2.6526321007195057
Validation loss: 2.4745743851168838

Epoch: 6| Step: 1
Training loss: 2.3930220211624276
Validation loss: 2.4731712026058537

Epoch: 6| Step: 2
Training loss: 2.774358891841895
Validation loss: 2.470531979389195

Epoch: 6| Step: 3
Training loss: 2.2839162217122353
Validation loss: 2.477389168581119

Epoch: 6| Step: 4
Training loss: 2.223182656111846
Validation loss: 2.4633104620436574

Epoch: 6| Step: 5
Training loss: 2.5378969304865295
Validation loss: 2.4694927402041293

Epoch: 6| Step: 6
Training loss: 2.367998947207758
Validation loss: 2.465598045881893

Epoch: 6| Step: 7
Training loss: 2.3651904252471225
Validation loss: 2.4703903221372348

Epoch: 6| Step: 8
Training loss: 2.945330146716449
Validation loss: 2.4650457090894666

Epoch: 6| Step: 9
Training loss: 2.6192147218149504
Validation loss: 2.458926352941744

Epoch: 6| Step: 10
Training loss: 2.4965085444610717
Validation loss: 2.457788291144213

Epoch: 6| Step: 11
Training loss: 2.4484164978957255
Validation loss: 2.4594043456883248

Epoch: 6| Step: 12
Training loss: 2.526380399559577
Validation loss: 2.4642526892245247

Epoch: 6| Step: 13
Training loss: 2.808284058030088
Validation loss: 2.4570515787954483

Epoch: 103| Step: 0
Training loss: 2.8162194982401614
Validation loss: 2.4615980765416916

Epoch: 6| Step: 1
Training loss: 2.166248525716959
Validation loss: 2.4633670419710367

Epoch: 6| Step: 2
Training loss: 2.71727089822461
Validation loss: 2.4664632612423456

Epoch: 6| Step: 3
Training loss: 2.7625422133590685
Validation loss: 2.467553939487441

Epoch: 6| Step: 4
Training loss: 2.9243020162261786
Validation loss: 2.472711418866224

Epoch: 6| Step: 5
Training loss: 2.9562242180181912
Validation loss: 2.472373508320163

Epoch: 6| Step: 6
Training loss: 2.1839211752434
Validation loss: 2.478537717479766

Epoch: 6| Step: 7
Training loss: 2.8605537694722663
Validation loss: 2.4800091335169463

Epoch: 6| Step: 8
Training loss: 1.9636292846990393
Validation loss: 2.477796694289426

Epoch: 6| Step: 9
Training loss: 2.320223719892451
Validation loss: 2.4718485352152006

Epoch: 6| Step: 10
Training loss: 1.8965913563656172
Validation loss: 2.4712152043389928

Epoch: 6| Step: 11
Training loss: 2.333253881827477
Validation loss: 2.4644377505551005

Epoch: 6| Step: 12
Training loss: 2.9048962465230947
Validation loss: 2.4604441233972882

Epoch: 6| Step: 13
Training loss: 2.6065689806508314
Validation loss: 2.4753588811215415

Epoch: 104| Step: 0
Training loss: 2.675392646137131
Validation loss: 2.4622244724325753

Epoch: 6| Step: 1
Training loss: 2.988647278951365
Validation loss: 2.458652707275777

Epoch: 6| Step: 2
Training loss: 2.29134809418268
Validation loss: 2.4625822353670617

Epoch: 6| Step: 3
Training loss: 2.2673245073771264
Validation loss: 2.4654777505448724

Epoch: 6| Step: 4
Training loss: 2.4473702544597846
Validation loss: 2.4633792772598415

Epoch: 6| Step: 5
Training loss: 2.5713339402179365
Validation loss: 2.4575246407511124

Epoch: 6| Step: 6
Training loss: 2.8112243302438236
Validation loss: 2.462570084867044

Epoch: 6| Step: 7
Training loss: 2.078818872243316
Validation loss: 2.4657435883020287

Epoch: 6| Step: 8
Training loss: 2.3975400954345494
Validation loss: 2.4642853101752396

Epoch: 6| Step: 9
Training loss: 2.8025009430229515
Validation loss: 2.4678753297293508

Epoch: 6| Step: 10
Training loss: 2.611562942298522
Validation loss: 2.473707508957813

Epoch: 6| Step: 11
Training loss: 2.0305829640197146
Validation loss: 2.4719846113604547

Epoch: 6| Step: 12
Training loss: 2.5979420440176697
Validation loss: 2.4742040866794315

Epoch: 6| Step: 13
Training loss: 2.681500413845186
Validation loss: 2.470271965271766

Epoch: 105| Step: 0
Training loss: 2.6662462519008154
Validation loss: 2.4695724855556627

Epoch: 6| Step: 1
Training loss: 2.507614745902406
Validation loss: 2.462773521194587

Epoch: 6| Step: 2
Training loss: 2.2916389001262343
Validation loss: 2.458731753720056

Epoch: 6| Step: 3
Training loss: 2.093099692400403
Validation loss: 2.459381806664296

Epoch: 6| Step: 4
Training loss: 2.3378758378226485
Validation loss: 2.4627377661537753

Epoch: 6| Step: 5
Training loss: 2.8536085339511903
Validation loss: 2.460458157798122

Epoch: 6| Step: 6
Training loss: 2.632713700882922
Validation loss: 2.472872065265375

Epoch: 6| Step: 7
Training loss: 2.87884860970961
Validation loss: 2.457478865063355

Epoch: 6| Step: 8
Training loss: 2.2964652597767667
Validation loss: 2.458783130121949

Epoch: 6| Step: 9
Training loss: 2.8408297121922526
Validation loss: 2.4610657835126166

Epoch: 6| Step: 10
Training loss: 1.9886784784390585
Validation loss: 2.4709149939523334

Epoch: 6| Step: 11
Training loss: 3.0851216843408205
Validation loss: 2.4676661466183756

Epoch: 6| Step: 12
Training loss: 2.671713127006719
Validation loss: 2.4713137227732935

Epoch: 6| Step: 13
Training loss: 2.03147053621761
Validation loss: 2.466696388048386

Epoch: 106| Step: 0
Training loss: 2.2048705200101355
Validation loss: 2.476885929909763

Epoch: 6| Step: 1
Training loss: 2.6015690067427544
Validation loss: 2.4702971877593276

Epoch: 6| Step: 2
Training loss: 2.2227376644730565
Validation loss: 2.469677803078115

Epoch: 6| Step: 3
Training loss: 2.2493158995889835
Validation loss: 2.470946256513427

Epoch: 6| Step: 4
Training loss: 2.6530045373031634
Validation loss: 2.4721679848235154

Epoch: 6| Step: 5
Training loss: 2.712994325659302
Validation loss: 2.4765109709664768

Epoch: 6| Step: 6
Training loss: 2.786239092511561
Validation loss: 2.468511046744119

Epoch: 6| Step: 7
Training loss: 2.1648573534623115
Validation loss: 2.469087424738869

Epoch: 6| Step: 8
Training loss: 2.5120962283478985
Validation loss: 2.4710002976775907

Epoch: 6| Step: 9
Training loss: 2.9485337832467287
Validation loss: 2.4577846130224694

Epoch: 6| Step: 10
Training loss: 2.3228587555330904
Validation loss: 2.4668524004198455

Epoch: 6| Step: 11
Training loss: 2.635413630990151
Validation loss: 2.4641375852573164

Epoch: 6| Step: 12
Training loss: 2.8680408673427316
Validation loss: 2.4646704643585866

Epoch: 6| Step: 13
Training loss: 2.31178437578466
Validation loss: 2.4680141567566634

Epoch: 107| Step: 0
Training loss: 2.6343089754964866
Validation loss: 2.479747629348027

Epoch: 6| Step: 1
Training loss: 2.9930485614440188
Validation loss: 2.4793811726667583

Epoch: 6| Step: 2
Training loss: 2.224687610084476
Validation loss: 2.4870195848199743

Epoch: 6| Step: 3
Training loss: 2.4791396537612727
Validation loss: 2.4938015947605483

Epoch: 6| Step: 4
Training loss: 2.6196490654076383
Validation loss: 2.4775425268501596

Epoch: 6| Step: 5
Training loss: 2.523863104014153
Validation loss: 2.464747262266205

Epoch: 6| Step: 6
Training loss: 2.745423931189987
Validation loss: 2.462791769618679

Epoch: 6| Step: 7
Training loss: 2.361962926459007
Validation loss: 2.4686136167816457

Epoch: 6| Step: 8
Training loss: 1.8528208902818544
Validation loss: 2.473681662632241

Epoch: 6| Step: 9
Training loss: 2.6788140922707733
Validation loss: 2.474359151929654

Epoch: 6| Step: 10
Training loss: 2.886894169124595
Validation loss: 2.482217311559244

Epoch: 6| Step: 11
Training loss: 2.4339705125061624
Validation loss: 2.479926342870167

Epoch: 6| Step: 12
Training loss: 2.721528135637478
Validation loss: 2.4842562057275823

Epoch: 6| Step: 13
Training loss: 2.6499048179950906
Validation loss: 2.483785499353621

Epoch: 108| Step: 0
Training loss: 2.3884587664607593
Validation loss: 2.4760460059278118

Epoch: 6| Step: 1
Training loss: 2.2792513727583774
Validation loss: 2.4787058415329333

Epoch: 6| Step: 2
Training loss: 2.748238432822483
Validation loss: 2.4750472606937515

Epoch: 6| Step: 3
Training loss: 2.8484851692969353
Validation loss: 2.4811615864898657

Epoch: 6| Step: 4
Training loss: 2.5635081843287737
Validation loss: 2.4774478168297596

Epoch: 6| Step: 5
Training loss: 2.5249603683836224
Validation loss: 2.4855489136609914

Epoch: 6| Step: 6
Training loss: 2.6211095772505564
Validation loss: 2.4837557422742425

Epoch: 6| Step: 7
Training loss: 2.729007357153056
Validation loss: 2.479438131092963

Epoch: 6| Step: 8
Training loss: 2.516229497652624
Validation loss: 2.479437698380533

Epoch: 6| Step: 9
Training loss: 2.296234352918214
Validation loss: 2.4779532746268087

Epoch: 6| Step: 10
Training loss: 2.5410342028889468
Validation loss: 2.4738779128539066

Epoch: 6| Step: 11
Training loss: 2.9218123322156577
Validation loss: 2.472056030254684

Epoch: 6| Step: 12
Training loss: 1.6768633854222446
Validation loss: 2.470805620120619

Epoch: 6| Step: 13
Training loss: 2.7460380103584683
Validation loss: 2.4600016595736647

Epoch: 109| Step: 0
Training loss: 2.0647547563765274
Validation loss: 2.4782397249659716

Epoch: 6| Step: 1
Training loss: 2.381605299027109
Validation loss: 2.4880977065873084

Epoch: 6| Step: 2
Training loss: 2.3964925329043094
Validation loss: 2.509209961489678

Epoch: 6| Step: 3
Training loss: 2.737076389510863
Validation loss: 2.50278532316609

Epoch: 6| Step: 4
Training loss: 2.5057151318822246
Validation loss: 2.516003834886767

Epoch: 6| Step: 5
Training loss: 2.29391330064935
Validation loss: 2.4986461470374435

Epoch: 6| Step: 6
Training loss: 2.6685969002827554
Validation loss: 2.4882154550841444

Epoch: 6| Step: 7
Training loss: 2.902337013945329
Validation loss: 2.4583777784651

Epoch: 6| Step: 8
Training loss: 2.8914641940627375
Validation loss: 2.4590832218485263

Epoch: 6| Step: 9
Training loss: 2.2612207157564717
Validation loss: 2.472998187149685

Epoch: 6| Step: 10
Training loss: 2.338016669142979
Validation loss: 2.469491927612132

Epoch: 6| Step: 11
Training loss: 2.6745873676663234
Validation loss: 2.4734692595405443

Epoch: 6| Step: 12
Training loss: 2.7687436209232734
Validation loss: 2.4672685516038246

Epoch: 6| Step: 13
Training loss: 2.676126410505012
Validation loss: 2.473076558159658

Epoch: 110| Step: 0
Training loss: 2.350675295124601
Validation loss: 2.4759643907461717

Epoch: 6| Step: 1
Training loss: 2.6233635297279037
Validation loss: 2.477938778050934

Epoch: 6| Step: 2
Training loss: 2.858536727682669
Validation loss: 2.4799222248966717

Epoch: 6| Step: 3
Training loss: 2.778705590322665
Validation loss: 2.4761067000083936

Epoch: 6| Step: 4
Training loss: 2.5838896142216807
Validation loss: 2.4776549231383806

Epoch: 6| Step: 5
Training loss: 2.5712988911581047
Validation loss: 2.474109289014294

Epoch: 6| Step: 6
Training loss: 1.9938689073841775
Validation loss: 2.477626038677253

Epoch: 6| Step: 7
Training loss: 2.678356051187439
Validation loss: 2.4751359940745092

Epoch: 6| Step: 8
Training loss: 2.6111230534309735
Validation loss: 2.467890046432482

Epoch: 6| Step: 9
Training loss: 2.37254306798339
Validation loss: 2.473081900634241

Epoch: 6| Step: 10
Training loss: 2.526618582268822
Validation loss: 2.470142647720674

Epoch: 6| Step: 11
Training loss: 2.496975022318998
Validation loss: 2.471930664053048

Epoch: 6| Step: 12
Training loss: 2.5498402190170837
Validation loss: 2.4636086151725562

Epoch: 6| Step: 13
Training loss: 2.6347299719024924
Validation loss: 2.461203246931074

Epoch: 111| Step: 0
Training loss: 2.8031778762236104
Validation loss: 2.464403535331176

Epoch: 6| Step: 1
Training loss: 2.3950897610912376
Validation loss: 2.4627311023635996

Epoch: 6| Step: 2
Training loss: 2.534677139879984
Validation loss: 2.4672634300706218

Epoch: 6| Step: 3
Training loss: 1.9033731734097388
Validation loss: 2.469401374224838

Epoch: 6| Step: 4
Training loss: 2.2643332120117683
Validation loss: 2.4841026140836373

Epoch: 6| Step: 5
Training loss: 2.440236047677312
Validation loss: 2.500176590404706

Epoch: 6| Step: 6
Training loss: 2.8027571727078033
Validation loss: 2.4917600338856527

Epoch: 6| Step: 7
Training loss: 2.32462985466109
Validation loss: 2.4703227316998175

Epoch: 6| Step: 8
Training loss: 2.52578314543068
Validation loss: 2.4636200831207087

Epoch: 6| Step: 9
Training loss: 3.036194848242474
Validation loss: 2.45797408975882

Epoch: 6| Step: 10
Training loss: 2.506073155430598
Validation loss: 2.4655683432783158

Epoch: 6| Step: 11
Training loss: 3.035564380438683
Validation loss: 2.4695300226028483

Epoch: 6| Step: 12
Training loss: 2.1286439506560395
Validation loss: 2.471286147011958

Epoch: 6| Step: 13
Training loss: 2.607770597876643
Validation loss: 2.4677433263171693

Epoch: 112| Step: 0
Training loss: 2.554609105018488
Validation loss: 2.477827902098244

Epoch: 6| Step: 1
Training loss: 2.569120461139893
Validation loss: 2.472363736415953

Epoch: 6| Step: 2
Training loss: 3.1458817703526476
Validation loss: 2.4787722655870703

Epoch: 6| Step: 3
Training loss: 2.334109200048589
Validation loss: 2.480429629520494

Epoch: 6| Step: 4
Training loss: 2.7084508919266512
Validation loss: 2.476202231595847

Epoch: 6| Step: 5
Training loss: 2.184944840352566
Validation loss: 2.475952803435146

Epoch: 6| Step: 6
Training loss: 2.2494790215803913
Validation loss: 2.4742934846567257

Epoch: 6| Step: 7
Training loss: 2.177970620243543
Validation loss: 2.4800444793301537

Epoch: 6| Step: 8
Training loss: 2.6826918417670154
Validation loss: 2.4750382218155

Epoch: 6| Step: 9
Training loss: 2.477520104720285
Validation loss: 2.475077491728786

Epoch: 6| Step: 10
Training loss: 2.7287882379918624
Validation loss: 2.4713278240786978

Epoch: 6| Step: 11
Training loss: 2.769392819839066
Validation loss: 2.4733549941683317

Epoch: 6| Step: 12
Training loss: 2.5103362982035144
Validation loss: 2.468450278586218

Epoch: 6| Step: 13
Training loss: 2.778141298879178
Validation loss: 2.468715329470007

Epoch: 113| Step: 0
Training loss: 2.3621177646695517
Validation loss: 2.4631539430154366

Epoch: 6| Step: 1
Training loss: 2.716098588707542
Validation loss: 2.461020412763944

Epoch: 6| Step: 2
Training loss: 3.4480293616617934
Validation loss: 2.461897179519081

Epoch: 6| Step: 3
Training loss: 2.1946158067241597
Validation loss: 2.4638174815285248

Epoch: 6| Step: 4
Training loss: 3.0108486160438073
Validation loss: 2.4526295090653623

Epoch: 6| Step: 5
Training loss: 1.823425251086885
Validation loss: 2.4586845459570688

Epoch: 6| Step: 6
Training loss: 2.482502453544457
Validation loss: 2.4574130701139665

Epoch: 6| Step: 7
Training loss: 1.954236073132379
Validation loss: 2.450272028930622

Epoch: 6| Step: 8
Training loss: 2.2037356997938518
Validation loss: 2.4525498689927474

Epoch: 6| Step: 9
Training loss: 2.68306508194411
Validation loss: 2.4637991923171545

Epoch: 6| Step: 10
Training loss: 2.70136816893419
Validation loss: 2.4690893237793294

Epoch: 6| Step: 11
Training loss: 2.2684581011845544
Validation loss: 2.459603181018221

Epoch: 6| Step: 12
Training loss: 2.747904152271695
Validation loss: 2.460886136280901

Epoch: 6| Step: 13
Training loss: 2.4137369572165093
Validation loss: 2.46561730483949

Epoch: 114| Step: 0
Training loss: 2.6839873845618314
Validation loss: 2.4700255659842068

Epoch: 6| Step: 1
Training loss: 2.433197528062876
Validation loss: 2.4626698285325053

Epoch: 6| Step: 2
Training loss: 1.9919700952721087
Validation loss: 2.4654406002761844

Epoch: 6| Step: 3
Training loss: 2.6484068021992586
Validation loss: 2.461249574926316

Epoch: 6| Step: 4
Training loss: 2.7357170081489675
Validation loss: 2.459815335630902

Epoch: 6| Step: 5
Training loss: 2.921556424811846
Validation loss: 2.4604121863582518

Epoch: 6| Step: 6
Training loss: 2.9504374228278336
Validation loss: 2.462836994794265

Epoch: 6| Step: 7
Training loss: 2.036162085745806
Validation loss: 2.466216739224667

Epoch: 6| Step: 8
Training loss: 2.6725870711699216
Validation loss: 2.463431831045894

Epoch: 6| Step: 9
Training loss: 2.132709654399938
Validation loss: 2.4660777828142186

Epoch: 6| Step: 10
Training loss: 2.406170930430287
Validation loss: 2.473525615125883

Epoch: 6| Step: 11
Training loss: 2.849128081142353
Validation loss: 2.4738857914511905

Epoch: 6| Step: 12
Training loss: 2.4236038436222023
Validation loss: 2.4738145940416514

Epoch: 6| Step: 13
Training loss: 2.5823024313023843
Validation loss: 2.471316777794975

Epoch: 115| Step: 0
Training loss: 2.173629162124035
Validation loss: 2.4728640468519187

Epoch: 6| Step: 1
Training loss: 1.7103843317293754
Validation loss: 2.4688395069491245

Epoch: 6| Step: 2
Training loss: 3.068828661001773
Validation loss: 2.4606798309581053

Epoch: 6| Step: 3
Training loss: 2.504106582030789
Validation loss: 2.4654356361197927

Epoch: 6| Step: 4
Training loss: 1.8905722870847523
Validation loss: 2.4600562884447768

Epoch: 6| Step: 5
Training loss: 3.313747818757976
Validation loss: 2.457604216626001

Epoch: 6| Step: 6
Training loss: 2.7027914028819677
Validation loss: 2.461887479015913

Epoch: 6| Step: 7
Training loss: 2.075737750796812
Validation loss: 2.4582563054145417

Epoch: 6| Step: 8
Training loss: 2.86751244805851
Validation loss: 2.4610587922738296

Epoch: 6| Step: 9
Training loss: 2.0908764150576746
Validation loss: 2.4682533714286605

Epoch: 6| Step: 10
Training loss: 2.484758935207794
Validation loss: 2.462959040539337

Epoch: 6| Step: 11
Training loss: 2.328038668471947
Validation loss: 2.460880387869652

Epoch: 6| Step: 12
Training loss: 2.76155350985288
Validation loss: 2.474233693642954

Epoch: 6| Step: 13
Training loss: 2.9198800686806496
Validation loss: 2.4699736029518147

Epoch: 116| Step: 0
Training loss: 2.6038613916121793
Validation loss: 2.4669908299816234

Epoch: 6| Step: 1
Training loss: 2.2932916832993446
Validation loss: 2.470662627560477

Epoch: 6| Step: 2
Training loss: 2.990253510716041
Validation loss: 2.469698985106594

Epoch: 6| Step: 3
Training loss: 3.0486961204206575
Validation loss: 2.4637940797002775

Epoch: 6| Step: 4
Training loss: 2.0546743878428457
Validation loss: 2.4635290396906444

Epoch: 6| Step: 5
Training loss: 2.438623707295759
Validation loss: 2.474948890877599

Epoch: 6| Step: 6
Training loss: 2.4069412031357937
Validation loss: 2.4564442461518055

Epoch: 6| Step: 7
Training loss: 2.6315669614117363
Validation loss: 2.458816760963152

Epoch: 6| Step: 8
Training loss: 2.75998487634247
Validation loss: 2.4599758469292707

Epoch: 6| Step: 9
Training loss: 1.9539808915686658
Validation loss: 2.461906605595361

Epoch: 6| Step: 10
Training loss: 2.275657592305352
Validation loss: 2.462964905100954

Epoch: 6| Step: 11
Training loss: 2.3799373102346566
Validation loss: 2.4656395773543336

Epoch: 6| Step: 12
Training loss: 2.410075923625976
Validation loss: 2.4701621768904523

Epoch: 6| Step: 13
Training loss: 2.8548643461424725
Validation loss: 2.4722526586518745

Epoch: 117| Step: 0
Training loss: 2.8213094286053164
Validation loss: 2.471806127438324

Epoch: 6| Step: 1
Training loss: 2.8179910251211897
Validation loss: 2.4719710121204073

Epoch: 6| Step: 2
Training loss: 2.2684788061055365
Validation loss: 2.475052366120165

Epoch: 6| Step: 3
Training loss: 2.830187135312121
Validation loss: 2.4736886744184825

Epoch: 6| Step: 4
Training loss: 2.7555716166318756
Validation loss: 2.469909057873518

Epoch: 6| Step: 5
Training loss: 1.7923584275355107
Validation loss: 2.4678696620040808

Epoch: 6| Step: 6
Training loss: 2.2389922552277235
Validation loss: 2.470120930587793

Epoch: 6| Step: 7
Training loss: 2.646127058731252
Validation loss: 2.469915605768656

Epoch: 6| Step: 8
Training loss: 2.627933679391245
Validation loss: 2.471752843398418

Epoch: 6| Step: 9
Training loss: 2.7928774091816644
Validation loss: 2.467934357026218

Epoch: 6| Step: 10
Training loss: 2.600706033945398
Validation loss: 2.470365583157904

Epoch: 6| Step: 11
Training loss: 2.55786923932229
Validation loss: 2.4693721679372596

Epoch: 6| Step: 12
Training loss: 2.037071922594356
Validation loss: 2.4641501634251766

Epoch: 6| Step: 13
Training loss: 2.3889549256100837
Validation loss: 2.466772414101534

Epoch: 118| Step: 0
Training loss: 1.69867530989781
Validation loss: 2.482602268710665

Epoch: 6| Step: 1
Training loss: 2.6578034290336094
Validation loss: 2.5025606075522426

Epoch: 6| Step: 2
Training loss: 2.6001146658041043
Validation loss: 2.509873111070786

Epoch: 6| Step: 3
Training loss: 3.0160819384425572
Validation loss: 2.478585557123892

Epoch: 6| Step: 4
Training loss: 2.3365764445773562
Validation loss: 2.4580726054233457

Epoch: 6| Step: 5
Training loss: 2.81555704760928
Validation loss: 2.4630392474941303

Epoch: 6| Step: 6
Training loss: 1.8855345743590903
Validation loss: 2.457217760795223

Epoch: 6| Step: 7
Training loss: 2.7558851558525683
Validation loss: 2.4633819953084983

Epoch: 6| Step: 8
Training loss: 2.3278332213801916
Validation loss: 2.4704939561440664

Epoch: 6| Step: 9
Training loss: 2.7861236561418505
Validation loss: 2.4732572398686274

Epoch: 6| Step: 10
Training loss: 3.191318095190823
Validation loss: 2.473145784488824

Epoch: 6| Step: 11
Training loss: 2.470926411908871
Validation loss: 2.47415525489232

Epoch: 6| Step: 12
Training loss: 2.6400814061184965
Validation loss: 2.4717656802226693

Epoch: 6| Step: 13
Training loss: 2.40964912012955
Validation loss: 2.4732798773737477

Epoch: 119| Step: 0
Training loss: 2.4711782368036017
Validation loss: 2.468886737819211

Epoch: 6| Step: 1
Training loss: 2.8984473708979492
Validation loss: 2.469740463706429

Epoch: 6| Step: 2
Training loss: 2.462426113821049
Validation loss: 2.4595157452145435

Epoch: 6| Step: 3
Training loss: 2.502538441335139
Validation loss: 2.464056680301945

Epoch: 6| Step: 4
Training loss: 2.2989902228520434
Validation loss: 2.4591716910138235

Epoch: 6| Step: 5
Training loss: 2.4084387398678606
Validation loss: 2.4646067235830436

Epoch: 6| Step: 6
Training loss: 2.2185281991909567
Validation loss: 2.4622013136809517

Epoch: 6| Step: 7
Training loss: 2.1601419017239345
Validation loss: 2.4621347411435344

Epoch: 6| Step: 8
Training loss: 2.446762483818501
Validation loss: 2.461448366131797

Epoch: 6| Step: 9
Training loss: 2.2609680722060532
Validation loss: 2.464940427404623

Epoch: 6| Step: 10
Training loss: 2.8243957717310644
Validation loss: 2.464097302436376

Epoch: 6| Step: 11
Training loss: 3.0569310839431005
Validation loss: 2.465694258587025

Epoch: 6| Step: 12
Training loss: 2.8135709630878436
Validation loss: 2.466820038933123

Epoch: 6| Step: 13
Training loss: 2.5696447368831947
Validation loss: 2.4695684388146364

Epoch: 120| Step: 0
Training loss: 2.317817245381849
Validation loss: 2.462142294191032

Epoch: 6| Step: 1
Training loss: 2.741615866177868
Validation loss: 2.4555383947280074

Epoch: 6| Step: 2
Training loss: 2.489424653895328
Validation loss: 2.466910534050194

Epoch: 6| Step: 3
Training loss: 2.532109055917049
Validation loss: 2.4578828129428447

Epoch: 6| Step: 4
Training loss: 2.6814812976157207
Validation loss: 2.4655334346064075

Epoch: 6| Step: 5
Training loss: 3.0008699427346075
Validation loss: 2.458472431148539

Epoch: 6| Step: 6
Training loss: 2.0631494366603556
Validation loss: 2.4672850113020686

Epoch: 6| Step: 7
Training loss: 2.346387269481274
Validation loss: 2.4597017606744203

Epoch: 6| Step: 8
Training loss: 2.253319093595276
Validation loss: 2.463054364151549

Epoch: 6| Step: 9
Training loss: 2.0919762684951224
Validation loss: 2.462145828621967

Epoch: 6| Step: 10
Training loss: 2.6848520052736924
Validation loss: 2.462932363464522

Epoch: 6| Step: 11
Training loss: 2.4960832431434774
Validation loss: 2.460746854633405

Epoch: 6| Step: 12
Training loss: 2.542359356736455
Validation loss: 2.4636741801478386

Epoch: 6| Step: 13
Training loss: 2.729528000379992
Validation loss: 2.46079041379538

Epoch: 121| Step: 0
Training loss: 2.7736692519809867
Validation loss: 2.4651973932142175

Epoch: 6| Step: 1
Training loss: 2.0428032598334647
Validation loss: 2.457953275515797

Epoch: 6| Step: 2
Training loss: 2.756410755823917
Validation loss: 2.4601725201731477

Epoch: 6| Step: 3
Training loss: 2.5728662668663826
Validation loss: 2.4630534768369743

Epoch: 6| Step: 4
Training loss: 1.9671017241013864
Validation loss: 2.46023866126349

Epoch: 6| Step: 5
Training loss: 1.6463053143244792
Validation loss: 2.4645362496950605

Epoch: 6| Step: 6
Training loss: 2.965946359376997
Validation loss: 2.467061491460828

Epoch: 6| Step: 7
Training loss: 2.8644600766569814
Validation loss: 2.4609121815827235

Epoch: 6| Step: 8
Training loss: 2.0292926454178732
Validation loss: 2.4640432146987177

Epoch: 6| Step: 9
Training loss: 2.6058010821597946
Validation loss: 2.464817520542105

Epoch: 6| Step: 10
Training loss: 2.8439233748016424
Validation loss: 2.4603174064138633

Epoch: 6| Step: 11
Training loss: 2.629031672893816
Validation loss: 2.463119234047521

Epoch: 6| Step: 12
Training loss: 2.4337091556329047
Validation loss: 2.464108590723229

Epoch: 6| Step: 13
Training loss: 2.561888924286547
Validation loss: 2.462500617709784

Epoch: 122| Step: 0
Training loss: 2.8618136986662885
Validation loss: 2.470609149980129

Epoch: 6| Step: 1
Training loss: 1.7486856838393994
Validation loss: 2.471089932164087

Epoch: 6| Step: 2
Training loss: 2.5440990086728497
Validation loss: 2.476956950803717

Epoch: 6| Step: 3
Training loss: 2.181041228788398
Validation loss: 2.480700432477975

Epoch: 6| Step: 4
Training loss: 2.9932983567446523
Validation loss: 2.4717277402614033

Epoch: 6| Step: 5
Training loss: 2.7160600531038797
Validation loss: 2.4805224795792515

Epoch: 6| Step: 6
Training loss: 3.0504670707902397
Validation loss: 2.4799729379848907

Epoch: 6| Step: 7
Training loss: 3.0494086270707497
Validation loss: 2.483483976450301

Epoch: 6| Step: 8
Training loss: 2.6889828871313326
Validation loss: 2.4765082994179894

Epoch: 6| Step: 9
Training loss: 2.575884961396876
Validation loss: 2.47596131738572

Epoch: 6| Step: 10
Training loss: 2.3119015305877086
Validation loss: 2.477116551883663

Epoch: 6| Step: 11
Training loss: 2.611465530375446
Validation loss: 2.474036210825375

Epoch: 6| Step: 12
Training loss: 1.789788977368939
Validation loss: 2.477313307943324

Epoch: 6| Step: 13
Training loss: 2.115882161455829
Validation loss: 2.473682530070792

Epoch: 123| Step: 0
Training loss: 2.406357899017784
Validation loss: 2.4590164517791755

Epoch: 6| Step: 1
Training loss: 2.391425503613076
Validation loss: 2.467332610134413

Epoch: 6| Step: 2
Training loss: 2.4587594217993574
Validation loss: 2.4749666481468164

Epoch: 6| Step: 3
Training loss: 2.1566884797460744
Validation loss: 2.4631685669356473

Epoch: 6| Step: 4
Training loss: 2.9759487210131996
Validation loss: 2.478746728566304

Epoch: 6| Step: 5
Training loss: 2.8122131201345035
Validation loss: 2.4778447968091704

Epoch: 6| Step: 6
Training loss: 3.002058753275438
Validation loss: 2.4744942549754882

Epoch: 6| Step: 7
Training loss: 2.082828562303266
Validation loss: 2.461898648310738

Epoch: 6| Step: 8
Training loss: 2.1929945468234666
Validation loss: 2.4557599537370134

Epoch: 6| Step: 9
Training loss: 2.3536380973385453
Validation loss: 2.4605020935146844

Epoch: 6| Step: 10
Training loss: 2.598978678305785
Validation loss: 2.4619257481666006

Epoch: 6| Step: 11
Training loss: 2.5588436557940315
Validation loss: 2.458869848596595

Epoch: 6| Step: 12
Training loss: 2.5231347625823255
Validation loss: 2.467678038536079

Epoch: 6| Step: 13
Training loss: 2.632644240438937
Validation loss: 2.4624679247062926

Epoch: 124| Step: 0
Training loss: 2.6425382465925806
Validation loss: 2.457079799477702

Epoch: 6| Step: 1
Training loss: 2.3688200806892263
Validation loss: 2.4635061916084853

Epoch: 6| Step: 2
Training loss: 2.4723611809280537
Validation loss: 2.4630277607084223

Epoch: 6| Step: 3
Training loss: 2.621400363231333
Validation loss: 2.4618329553434894

Epoch: 6| Step: 4
Training loss: 2.293958408128329
Validation loss: 2.463006077641082

Epoch: 6| Step: 5
Training loss: 2.0754305932798554
Validation loss: 2.466111974809371

Epoch: 6| Step: 6
Training loss: 3.1651214711290234
Validation loss: 2.4605180493903167

Epoch: 6| Step: 7
Training loss: 2.3745265287972495
Validation loss: 2.4640172831261538

Epoch: 6| Step: 8
Training loss: 2.8047434341676154
Validation loss: 2.4649704438630597

Epoch: 6| Step: 9
Training loss: 2.7380092338813133
Validation loss: 2.470251520068949

Epoch: 6| Step: 10
Training loss: 2.5740982513705144
Validation loss: 2.464564142826937

Epoch: 6| Step: 11
Training loss: 2.2932141252333857
Validation loss: 2.463531805963655

Epoch: 6| Step: 12
Training loss: 2.3255353003746415
Validation loss: 2.470476810106891

Epoch: 6| Step: 13
Training loss: 2.0024670643663707
Validation loss: 2.4635565813082207

Epoch: 125| Step: 0
Training loss: 2.2098670767601027
Validation loss: 2.4658507533444864

Epoch: 6| Step: 1
Training loss: 2.650074140843107
Validation loss: 2.4687102109382586

Epoch: 6| Step: 2
Training loss: 2.504858255544831
Validation loss: 2.465335561107965

Epoch: 6| Step: 3
Training loss: 2.5936783010845046
Validation loss: 2.4710795360811266

Epoch: 6| Step: 4
Training loss: 2.9484373964957586
Validation loss: 2.4726178897977658

Epoch: 6| Step: 5
Training loss: 2.488553929022598
Validation loss: 2.462427195006876

Epoch: 6| Step: 6
Training loss: 2.2839521316749867
Validation loss: 2.4608023147186846

Epoch: 6| Step: 7
Training loss: 2.6005934551501366
Validation loss: 2.465491288898412

Epoch: 6| Step: 8
Training loss: 2.489300529559427
Validation loss: 2.463778362772179

Epoch: 6| Step: 9
Training loss: 2.5730325979042568
Validation loss: 2.4687836399281275

Epoch: 6| Step: 10
Training loss: 2.4467320815790847
Validation loss: 2.471202581732494

Epoch: 6| Step: 11
Training loss: 2.4724325407292778
Validation loss: 2.4730888498508277

Epoch: 6| Step: 12
Training loss: 2.386805755977297
Validation loss: 2.4710748083816005

Epoch: 6| Step: 13
Training loss: 2.43538613236351
Validation loss: 2.475464939669179

Epoch: 126| Step: 0
Training loss: 1.5199271424299547
Validation loss: 2.4743384032511204

Epoch: 6| Step: 1
Training loss: 2.7158606950431703
Validation loss: 2.4779982391301902

Epoch: 6| Step: 2
Training loss: 2.360734661485118
Validation loss: 2.473986387930295

Epoch: 6| Step: 3
Training loss: 1.849872961064196
Validation loss: 2.4731565012615473

Epoch: 6| Step: 4
Training loss: 2.360409743413062
Validation loss: 2.4752742814437085

Epoch: 6| Step: 5
Training loss: 3.0676654149903047
Validation loss: 2.470649455295499

Epoch: 6| Step: 6
Training loss: 2.4545313211798363
Validation loss: 2.4648937012718912

Epoch: 6| Step: 7
Training loss: 2.7490983698712936
Validation loss: 2.4611981612119846

Epoch: 6| Step: 8
Training loss: 1.9712949984971437
Validation loss: 2.467694229809216

Epoch: 6| Step: 9
Training loss: 2.7041022678538265
Validation loss: 2.461151856467137

Epoch: 6| Step: 10
Training loss: 2.7386258462180866
Validation loss: 2.4588180538262896

Epoch: 6| Step: 11
Training loss: 2.8443733622027185
Validation loss: 2.4592065122507387

Epoch: 6| Step: 12
Training loss: 2.479114264781234
Validation loss: 2.464374431055687

Epoch: 6| Step: 13
Training loss: 2.79059496753419
Validation loss: 2.4647330749458893

Epoch: 127| Step: 0
Training loss: 2.577405794569961
Validation loss: 2.4641063330699953

Epoch: 6| Step: 1
Training loss: 2.8435152397089474
Validation loss: 2.4714253894014715

Epoch: 6| Step: 2
Training loss: 2.247823722362678
Validation loss: 2.4688158630083965

Epoch: 6| Step: 3
Training loss: 2.561645272222894
Validation loss: 2.470495419824654

Epoch: 6| Step: 4
Training loss: 2.3973728264740575
Validation loss: 2.4681179187113123

Epoch: 6| Step: 5
Training loss: 2.413436956745162
Validation loss: 2.4651378329200133

Epoch: 6| Step: 6
Training loss: 2.160516029459121
Validation loss: 2.462783395690194

Epoch: 6| Step: 7
Training loss: 2.7016652305578814
Validation loss: 2.4648799420020624

Epoch: 6| Step: 8
Training loss: 2.4829333459001885
Validation loss: 2.4574132318142077

Epoch: 6| Step: 9
Training loss: 2.748170157177148
Validation loss: 2.455146952463211

Epoch: 6| Step: 10
Training loss: 1.7511072742970921
Validation loss: 2.4616704343854323

Epoch: 6| Step: 11
Training loss: 2.9625445913829918
Validation loss: 2.4624023114754774

Epoch: 6| Step: 12
Training loss: 2.4821819486607595
Validation loss: 2.4581873144545248

Epoch: 6| Step: 13
Training loss: 2.436403076623863
Validation loss: 2.4602401148938577

Epoch: 128| Step: 0
Training loss: 2.696231320545925
Validation loss: 2.463275231006099

Epoch: 6| Step: 1
Training loss: 2.3016053360878166
Validation loss: 2.464361668601544

Epoch: 6| Step: 2
Training loss: 2.7449684062035957
Validation loss: 2.4639773208773765

Epoch: 6| Step: 3
Training loss: 2.1844647739719596
Validation loss: 2.4667649557747224

Epoch: 6| Step: 4
Training loss: 2.4821629302888235
Validation loss: 2.4678112128279635

Epoch: 6| Step: 5
Training loss: 2.4575059004719586
Validation loss: 2.468448137588075

Epoch: 6| Step: 6
Training loss: 2.402849147327146
Validation loss: 2.4726643815793263

Epoch: 6| Step: 7
Training loss: 2.139391467125494
Validation loss: 2.4740281961849564

Epoch: 6| Step: 8
Training loss: 2.6325243330915002
Validation loss: 2.465656354130276

Epoch: 6| Step: 9
Training loss: 2.8279756116665262
Validation loss: 2.4719574288804296

Epoch: 6| Step: 10
Training loss: 2.263679879596503
Validation loss: 2.465929069512689

Epoch: 6| Step: 11
Training loss: 2.570576755656203
Validation loss: 2.4691980655496355

Epoch: 6| Step: 12
Training loss: 3.154572900558255
Validation loss: 2.4766175176724734

Epoch: 6| Step: 13
Training loss: 1.9310454868310827
Validation loss: 2.4797522283421576

Epoch: 129| Step: 0
Training loss: 2.4262592624839296
Validation loss: 2.4799681311015873

Epoch: 6| Step: 1
Training loss: 3.0326253386128945
Validation loss: 2.4833875089108153

Epoch: 6| Step: 2
Training loss: 3.130731743051174
Validation loss: 2.479747997908847

Epoch: 6| Step: 3
Training loss: 1.8223141646385603
Validation loss: 2.479992245538955

Epoch: 6| Step: 4
Training loss: 2.1747473515188456
Validation loss: 2.4770924736177284

Epoch: 6| Step: 5
Training loss: 2.6767232531515845
Validation loss: 2.4766777966413107

Epoch: 6| Step: 6
Training loss: 2.777854132132704
Validation loss: 2.4825904242728325

Epoch: 6| Step: 7
Training loss: 2.009005774573709
Validation loss: 2.476227008546598

Epoch: 6| Step: 8
Training loss: 1.9022492496901602
Validation loss: 2.465373502732448

Epoch: 6| Step: 9
Training loss: 2.756111636332736
Validation loss: 2.4663139106060292

Epoch: 6| Step: 10
Training loss: 2.759882509384537
Validation loss: 2.4703594064170025

Epoch: 6| Step: 11
Training loss: 2.0113258348467857
Validation loss: 2.464645708272388

Epoch: 6| Step: 12
Training loss: 2.3791407577609314
Validation loss: 2.468454930823901

Epoch: 6| Step: 13
Training loss: 2.936339453466906
Validation loss: 2.460521069367278

Epoch: 130| Step: 0
Training loss: 1.9071862469937344
Validation loss: 2.4669200698321694

Epoch: 6| Step: 1
Training loss: 2.904019884498553
Validation loss: 2.468185110692433

Epoch: 6| Step: 2
Training loss: 2.3988445321798353
Validation loss: 2.4686395000724906

Epoch: 6| Step: 3
Training loss: 2.337379444297818
Validation loss: 2.4707298548764065

Epoch: 6| Step: 4
Training loss: 2.67722494342081
Validation loss: 2.4666740445293027

Epoch: 6| Step: 5
Training loss: 2.55581145686922
Validation loss: 2.4770738653371533

Epoch: 6| Step: 6
Training loss: 2.85246082944329
Validation loss: 2.4689418863013666

Epoch: 6| Step: 7
Training loss: 2.4919616214191045
Validation loss: 2.4622411917861586

Epoch: 6| Step: 8
Training loss: 2.353000340699618
Validation loss: 2.4713556405569865

Epoch: 6| Step: 9
Training loss: 2.9575360974570084
Validation loss: 2.472638620772751

Epoch: 6| Step: 10
Training loss: 2.375458923973914
Validation loss: 2.462938720168989

Epoch: 6| Step: 11
Training loss: 2.3838076655229665
Validation loss: 2.466131938719286

Epoch: 6| Step: 12
Training loss: 2.257315927564943
Validation loss: 2.471709075515893

Epoch: 6| Step: 13
Training loss: 2.49769753286867
Validation loss: 2.46505571956219

Epoch: 131| Step: 0
Training loss: 2.215162573847947
Validation loss: 2.469455199783794

Epoch: 6| Step: 1
Training loss: 2.2470860155361794
Validation loss: 2.46773785151718

Epoch: 6| Step: 2
Training loss: 2.193157835589833
Validation loss: 2.459158764211052

Epoch: 6| Step: 3
Training loss: 3.216316117734956
Validation loss: 2.462422934809224

Epoch: 6| Step: 4
Training loss: 2.5927075968570565
Validation loss: 2.4636940831677934

Epoch: 6| Step: 5
Training loss: 2.1994793535925456
Validation loss: 2.4593630482222877

Epoch: 6| Step: 6
Training loss: 2.203020999699269
Validation loss: 2.4571287037778706

Epoch: 6| Step: 7
Training loss: 2.356816300152041
Validation loss: 2.4635780498460584

Epoch: 6| Step: 8
Training loss: 2.7824706067283316
Validation loss: 2.4576401757006408

Epoch: 6| Step: 9
Training loss: 2.6447523917704725
Validation loss: 2.4550869622143554

Epoch: 6| Step: 10
Training loss: 2.947320956550686
Validation loss: 2.4616545424768663

Epoch: 6| Step: 11
Training loss: 1.8668768077595108
Validation loss: 2.464408743428428

Epoch: 6| Step: 12
Training loss: 2.755349158646408
Validation loss: 2.459772373073288

Epoch: 6| Step: 13
Training loss: 2.3105872207949916
Validation loss: 2.4626189285450546

Epoch: 132| Step: 0
Training loss: 3.026580044799431
Validation loss: 2.4692810227889854

Epoch: 6| Step: 1
Training loss: 2.316910121210062
Validation loss: 2.458716650890035

Epoch: 6| Step: 2
Training loss: 1.9046429598375172
Validation loss: 2.4567983059010556

Epoch: 6| Step: 3
Training loss: 2.655530495527589
Validation loss: 2.4627163225612376

Epoch: 6| Step: 4
Training loss: 2.8297139967505127
Validation loss: 2.4592542755212845

Epoch: 6| Step: 5
Training loss: 2.294351657882744
Validation loss: 2.461807500865068

Epoch: 6| Step: 6
Training loss: 2.4965495139708342
Validation loss: 2.4577612992612448

Epoch: 6| Step: 7
Training loss: 2.425028661184927
Validation loss: 2.464112170711973

Epoch: 6| Step: 8
Training loss: 2.7068014556540363
Validation loss: 2.470249991899865

Epoch: 6| Step: 9
Training loss: 2.4227300303620933
Validation loss: 2.4652227804529554

Epoch: 6| Step: 10
Training loss: 2.035438444814329
Validation loss: 2.4709147688089983

Epoch: 6| Step: 11
Training loss: 2.9869841509342043
Validation loss: 2.463369259974506

Epoch: 6| Step: 12
Training loss: 1.8455906102031325
Validation loss: 2.4637247760835637

Epoch: 6| Step: 13
Training loss: 2.6228435377895427
Validation loss: 2.4627133536819428

Epoch: 133| Step: 0
Training loss: 2.1743023158965467
Validation loss: 2.4603006982134685

Epoch: 6| Step: 1
Training loss: 2.4126220158372282
Validation loss: 2.4686311459802925

Epoch: 6| Step: 2
Training loss: 2.330341384993103
Validation loss: 2.4671882486050327

Epoch: 6| Step: 3
Training loss: 2.7980144033927017
Validation loss: 2.4617906655771615

Epoch: 6| Step: 4
Training loss: 2.587747176891044
Validation loss: 2.467766900023081

Epoch: 6| Step: 5
Training loss: 2.3958064755026234
Validation loss: 2.4639702653282844

Epoch: 6| Step: 6
Training loss: 2.46168627776554
Validation loss: 2.4765428608497726

Epoch: 6| Step: 7
Training loss: 2.6277935059417024
Validation loss: 2.479918619661344

Epoch: 6| Step: 8
Training loss: 2.488880510495858
Validation loss: 2.4881136771427315

Epoch: 6| Step: 9
Training loss: 2.9180146689931963
Validation loss: 2.488458919519989

Epoch: 6| Step: 10
Training loss: 2.454380564497548
Validation loss: 2.4950260192977054

Epoch: 6| Step: 11
Training loss: 2.3615264178269797
Validation loss: 2.499039163325089

Epoch: 6| Step: 12
Training loss: 2.720875577808017
Validation loss: 2.4722283401365934

Epoch: 6| Step: 13
Training loss: 2.293078340319255
Validation loss: 2.4611045013761874

Epoch: 134| Step: 0
Training loss: 1.6736398099106842
Validation loss: 2.4586793257345363

Epoch: 6| Step: 1
Training loss: 2.6250468658623283
Validation loss: 2.4654021036262623

Epoch: 6| Step: 2
Training loss: 1.955519223447654
Validation loss: 2.464374818039998

Epoch: 6| Step: 3
Training loss: 2.580363371196175
Validation loss: 2.465735530591777

Epoch: 6| Step: 4
Training loss: 2.697728409452477
Validation loss: 2.470746806164426

Epoch: 6| Step: 5
Training loss: 2.7619130715040034
Validation loss: 2.464608940470872

Epoch: 6| Step: 6
Training loss: 2.29046348429087
Validation loss: 2.461217672556453

Epoch: 6| Step: 7
Training loss: 2.5809188039157696
Validation loss: 2.4666874716070355

Epoch: 6| Step: 8
Training loss: 2.4709262189297623
Validation loss: 2.466456269192121

Epoch: 6| Step: 9
Training loss: 3.0341081810350192
Validation loss: 2.467092061949987

Epoch: 6| Step: 10
Training loss: 2.745556449147258
Validation loss: 2.4673135497749854

Epoch: 6| Step: 11
Training loss: 2.6412378085388077
Validation loss: 2.461947844254749

Epoch: 6| Step: 12
Training loss: 1.9795055567737352
Validation loss: 2.4568610604944543

Epoch: 6| Step: 13
Training loss: 2.628766763282689
Validation loss: 2.4572671313083068

Epoch: 135| Step: 0
Training loss: 2.99045650123094
Validation loss: 2.4707872700592253

Epoch: 6| Step: 1
Training loss: 2.2810842375429914
Validation loss: 2.4604018178346934

Epoch: 6| Step: 2
Training loss: 2.2764951718231217
Validation loss: 2.4531947812402892

Epoch: 6| Step: 3
Training loss: 2.832718296241583
Validation loss: 2.4615413510247537

Epoch: 6| Step: 4
Training loss: 2.249308691846684
Validation loss: 2.46410457532426

Epoch: 6| Step: 5
Training loss: 2.5761111630450335
Validation loss: 2.463648841467577

Epoch: 6| Step: 6
Training loss: 3.050601812304636
Validation loss: 2.463114458803808

Epoch: 6| Step: 7
Training loss: 2.5792050960144928
Validation loss: 2.458321754514506

Epoch: 6| Step: 8
Training loss: 2.547596179917248
Validation loss: 2.4630706906826707

Epoch: 6| Step: 9
Training loss: 2.1981975020447106
Validation loss: 2.457834424832305

Epoch: 6| Step: 10
Training loss: 2.185649961438649
Validation loss: 2.461445912316218

Epoch: 6| Step: 11
Training loss: 2.198328085144272
Validation loss: 2.4605798209088614

Epoch: 6| Step: 12
Training loss: 2.511706599892852
Validation loss: 2.473520137059474

Epoch: 6| Step: 13
Training loss: 2.172232948281077
Validation loss: 2.474237283071735

Epoch: 136| Step: 0
Training loss: 2.5093603378380607
Validation loss: 2.474906969730293

Epoch: 6| Step: 1
Training loss: 1.7279046827050495
Validation loss: 2.46914075825188

Epoch: 6| Step: 2
Training loss: 2.490741178514373
Validation loss: 2.464720548119042

Epoch: 6| Step: 3
Training loss: 2.254808057072056
Validation loss: 2.4656740171639147

Epoch: 6| Step: 4
Training loss: 2.224532851995433
Validation loss: 2.4675432466931855

Epoch: 6| Step: 5
Training loss: 2.4150842769599854
Validation loss: 2.4744263591094975

Epoch: 6| Step: 6
Training loss: 2.80363916553033
Validation loss: 2.483883487216134

Epoch: 6| Step: 7
Training loss: 2.994422973936444
Validation loss: 2.4742657654461615

Epoch: 6| Step: 8
Training loss: 2.409342772271998
Validation loss: 2.4819469783006043

Epoch: 6| Step: 9
Training loss: 2.322886365570278
Validation loss: 2.4704198059158164

Epoch: 6| Step: 10
Training loss: 2.8436569366318425
Validation loss: 2.47863976037701

Epoch: 6| Step: 11
Training loss: 2.024612144720033
Validation loss: 2.482546471310945

Epoch: 6| Step: 12
Training loss: 2.766432132508299
Validation loss: 2.4698803080646163

Epoch: 6| Step: 13
Training loss: 2.585498323055292
Validation loss: 2.476931122342874

Epoch: 137| Step: 0
Training loss: 2.143488840816664
Validation loss: 2.4733029323913334

Epoch: 6| Step: 1
Training loss: 1.7899196520412723
Validation loss: 2.4751695391838417

Epoch: 6| Step: 2
Training loss: 2.667373523806317
Validation loss: 2.47019364201549

Epoch: 6| Step: 3
Training loss: 2.626143887467304
Validation loss: 2.472864512852611

Epoch: 6| Step: 4
Training loss: 1.8902702944599097
Validation loss: 2.477482405252656

Epoch: 6| Step: 5
Training loss: 2.743940787318765
Validation loss: 2.4637101312718177

Epoch: 6| Step: 6
Training loss: 2.795471180079012
Validation loss: 2.4632594543067046

Epoch: 6| Step: 7
Training loss: 2.7802427375258856
Validation loss: 2.475927534242624

Epoch: 6| Step: 8
Training loss: 2.435272274735108
Validation loss: 2.4617885833523445

Epoch: 6| Step: 9
Training loss: 2.56209802963832
Validation loss: 2.4686775035917328

Epoch: 6| Step: 10
Training loss: 2.5463134521009185
Validation loss: 2.459409281626231

Epoch: 6| Step: 11
Training loss: 2.7955404326220727
Validation loss: 2.4806225826590924

Epoch: 6| Step: 12
Training loss: 2.400844000391339
Validation loss: 2.4708500392492723

Epoch: 6| Step: 13
Training loss: 2.167478213789236
Validation loss: 2.4720914817438726

Epoch: 138| Step: 0
Training loss: 3.1345929725137394
Validation loss: 2.4659277320352193

Epoch: 6| Step: 1
Training loss: 2.925052811887598
Validation loss: 2.481472935498432

Epoch: 6| Step: 2
Training loss: 2.488461953492947
Validation loss: 2.4732282879809944

Epoch: 6| Step: 3
Training loss: 2.619883682930401
Validation loss: 2.483161813991311

Epoch: 6| Step: 4
Training loss: 2.2488300672678125
Validation loss: 2.476514613253165

Epoch: 6| Step: 5
Training loss: 2.2345272625881645
Validation loss: 2.4766368353404666

Epoch: 6| Step: 6
Training loss: 3.119268425489205
Validation loss: 2.474912701618078

Epoch: 6| Step: 7
Training loss: 2.3409140149946013
Validation loss: 2.4791081579233794

Epoch: 6| Step: 8
Training loss: 1.8448322158857422
Validation loss: 2.4748221137601107

Epoch: 6| Step: 9
Training loss: 2.2739499487891965
Validation loss: 2.4784597035325198

Epoch: 6| Step: 10
Training loss: 2.1382344952657517
Validation loss: 2.481816163638096

Epoch: 6| Step: 11
Training loss: 1.9068459376618283
Validation loss: 2.4836167111954848

Epoch: 6| Step: 12
Training loss: 2.289479813276188
Validation loss: 2.482743117153425

Epoch: 6| Step: 13
Training loss: 2.5541030261858237
Validation loss: 2.477046690579734

Epoch: 139| Step: 0
Training loss: 2.9996388535877325
Validation loss: 2.465513111278459

Epoch: 6| Step: 1
Training loss: 2.7939547845599226
Validation loss: 2.476516033262163

Epoch: 6| Step: 2
Training loss: 1.808926776190585
Validation loss: 2.4761055204839857

Epoch: 6| Step: 3
Training loss: 2.661699785501443
Validation loss: 2.4817133626991676

Epoch: 6| Step: 4
Training loss: 2.3758402893899406
Validation loss: 2.4706327285086016

Epoch: 6| Step: 5
Training loss: 2.0815678809095974
Validation loss: 2.4843846766765245

Epoch: 6| Step: 6
Training loss: 2.3364108317344354
Validation loss: 2.4722936925903602

Epoch: 6| Step: 7
Training loss: 2.200834991481416
Validation loss: 2.476786429854034

Epoch: 6| Step: 8
Training loss: 2.165004043399127
Validation loss: 2.470605868911947

Epoch: 6| Step: 9
Training loss: 2.629249312305424
Validation loss: 2.47215089861774

Epoch: 6| Step: 10
Training loss: 2.247936786305845
Validation loss: 2.470557536986086

Epoch: 6| Step: 11
Training loss: 2.890749047169425
Validation loss: 2.4755755201693623

Epoch: 6| Step: 12
Training loss: 2.6394994018345894
Validation loss: 2.4684879308741245

Epoch: 6| Step: 13
Training loss: 2.692008030112818
Validation loss: 2.4691041619943275

Epoch: 140| Step: 0
Training loss: 1.7597730765571287
Validation loss: 2.480223123398706

Epoch: 6| Step: 1
Training loss: 2.6161823221302742
Validation loss: 2.4812335820139326

Epoch: 6| Step: 2
Training loss: 2.824105457022675
Validation loss: 2.4991850955339205

Epoch: 6| Step: 3
Training loss: 2.429695644549
Validation loss: 2.49405811226102

Epoch: 6| Step: 4
Training loss: 2.253919366702518
Validation loss: 2.493486103955158

Epoch: 6| Step: 5
Training loss: 3.2104848278086977
Validation loss: 2.4935004304628348

Epoch: 6| Step: 6
Training loss: 2.4071351442136657
Validation loss: 2.485128452401793

Epoch: 6| Step: 7
Training loss: 1.8490456645560833
Validation loss: 2.4921231156884645

Epoch: 6| Step: 8
Training loss: 2.8105209169123535
Validation loss: 2.480983554553411

Epoch: 6| Step: 9
Training loss: 2.55866419571437
Validation loss: 2.477694600633168

Epoch: 6| Step: 10
Training loss: 2.8515021330831978
Validation loss: 2.475616964513201

Epoch: 6| Step: 11
Training loss: 2.1000946477723454
Validation loss: 2.4754558702117073

Epoch: 6| Step: 12
Training loss: 2.002014576038571
Validation loss: 2.4697305365797324

Epoch: 6| Step: 13
Training loss: 2.4220761123340466
Validation loss: 2.471347247409815

Epoch: 141| Step: 0
Training loss: 2.215980735812132
Validation loss: 2.472990827940105

Epoch: 6| Step: 1
Training loss: 2.8253340464554024
Validation loss: 2.4890469780689597

Epoch: 6| Step: 2
Training loss: 2.509446606974214
Validation loss: 2.473764051873261

Epoch: 6| Step: 3
Training loss: 2.516827597956784
Validation loss: 2.4883581735487237

Epoch: 6| Step: 4
Training loss: 2.365577880712617
Validation loss: 2.4737773039321196

Epoch: 6| Step: 5
Training loss: 2.043858525839061
Validation loss: 2.4810261418006907

Epoch: 6| Step: 6
Training loss: 2.6722845466344247
Validation loss: 2.4808600810382364

Epoch: 6| Step: 7
Training loss: 2.3184695133313324
Validation loss: 2.474648571431592

Epoch: 6| Step: 8
Training loss: 2.820926166248384
Validation loss: 2.477435017467159

Epoch: 6| Step: 9
Training loss: 2.8372957534213477
Validation loss: 2.4784332894992653

Epoch: 6| Step: 10
Training loss: 1.9836793416064407
Validation loss: 2.478764787258889

Epoch: 6| Step: 11
Training loss: 2.677471167429631
Validation loss: 2.476860373440427

Epoch: 6| Step: 12
Training loss: 2.670621254327113
Validation loss: 2.483350002523029

Epoch: 6| Step: 13
Training loss: 2.0570830678009218
Validation loss: 2.486886280715231

Epoch: 142| Step: 0
Training loss: 1.7811778539134515
Validation loss: 2.485293220679633

Epoch: 6| Step: 1
Training loss: 2.1561042625822826
Validation loss: 2.506981661535872

Epoch: 6| Step: 2
Training loss: 2.783358000076849
Validation loss: 2.49426796552475

Epoch: 6| Step: 3
Training loss: 2.03442955588511
Validation loss: 2.47850295941118

Epoch: 6| Step: 4
Training loss: 2.4105319282143762
Validation loss: 2.472691042044136

Epoch: 6| Step: 5
Training loss: 2.52260195477872
Validation loss: 2.4782678647128096

Epoch: 6| Step: 6
Training loss: 3.1485335191042276
Validation loss: 2.484428101298004

Epoch: 6| Step: 7
Training loss: 2.0220074994922568
Validation loss: 2.466161280056286

Epoch: 6| Step: 8
Training loss: 2.4709806384412967
Validation loss: 2.477341297813701

Epoch: 6| Step: 9
Training loss: 2.5787864992385052
Validation loss: 2.4774019922399306

Epoch: 6| Step: 10
Training loss: 2.7189334500562827
Validation loss: 2.474994166845775

Epoch: 6| Step: 11
Training loss: 2.354691258498991
Validation loss: 2.471030795316231

Epoch: 6| Step: 12
Training loss: 2.643154219643795
Validation loss: 2.4746628544505054

Epoch: 6| Step: 13
Training loss: 2.8292433071476975
Validation loss: 2.47951821364508

Epoch: 143| Step: 0
Training loss: 2.1437750144811427
Validation loss: 2.478415885744147

Epoch: 6| Step: 1
Training loss: 2.955102490553465
Validation loss: 2.485243351647226

Epoch: 6| Step: 2
Training loss: 2.651314672016747
Validation loss: 2.480929234331524

Epoch: 6| Step: 3
Training loss: 2.6438542771572666
Validation loss: 2.4837653733679863

Epoch: 6| Step: 4
Training loss: 1.8955249186180727
Validation loss: 2.4821552940833342

Epoch: 6| Step: 5
Training loss: 1.7925961840799105
Validation loss: 2.486211469839817

Epoch: 6| Step: 6
Training loss: 2.4928680734320587
Validation loss: 2.4733526485602315

Epoch: 6| Step: 7
Training loss: 3.3216047577193626
Validation loss: 2.4742284259259644

Epoch: 6| Step: 8
Training loss: 2.7436040713491234
Validation loss: 2.4787766660075783

Epoch: 6| Step: 9
Training loss: 2.0169812747840745
Validation loss: 2.490323117738111

Epoch: 6| Step: 10
Training loss: 2.4912662537346484
Validation loss: 2.491734606051583

Epoch: 6| Step: 11
Training loss: 2.252406634598426
Validation loss: 2.5059217572592827

Epoch: 6| Step: 12
Training loss: 2.2033765933262117
Validation loss: 2.4936590045844724

Epoch: 6| Step: 13
Training loss: 2.267047409261894
Validation loss: 2.495929073817668

Epoch: 144| Step: 0
Training loss: 2.6897150714108653
Validation loss: 2.474319565484393

Epoch: 6| Step: 1
Training loss: 2.332098111674984
Validation loss: 2.482283105380563

Epoch: 6| Step: 2
Training loss: 1.927104936083431
Validation loss: 2.4741075062533944

Epoch: 6| Step: 3
Training loss: 2.645135582259472
Validation loss: 2.4715247033425713

Epoch: 6| Step: 4
Training loss: 2.571997186068928
Validation loss: 2.4732742862987767

Epoch: 6| Step: 5
Training loss: 2.1589925159503087
Validation loss: 2.4662361222482674

Epoch: 6| Step: 6
Training loss: 2.2744058860281324
Validation loss: 2.484656168064011

Epoch: 6| Step: 7
Training loss: 2.3211877886642736
Validation loss: 2.478384813604789

Epoch: 6| Step: 8
Training loss: 1.90196941852152
Validation loss: 2.4871394453611946

Epoch: 6| Step: 9
Training loss: 2.5913549188700027
Validation loss: 2.4929584279410033

Epoch: 6| Step: 10
Training loss: 2.482626917764987
Validation loss: 2.4741106622211384

Epoch: 6| Step: 11
Training loss: 2.329686914619152
Validation loss: 2.487527706241143

Epoch: 6| Step: 12
Training loss: 3.1632332174244415
Validation loss: 2.490041799641278

Epoch: 6| Step: 13
Training loss: 2.7797137528842124
Validation loss: 2.479697544628007

Epoch: 145| Step: 0
Training loss: 2.3625284304245335
Validation loss: 2.479814562299393

Epoch: 6| Step: 1
Training loss: 2.4097785344599703
Validation loss: 2.4848682385774548

Epoch: 6| Step: 2
Training loss: 2.3657571733001763
Validation loss: 2.488713265388514

Epoch: 6| Step: 3
Training loss: 2.2561912127415416
Validation loss: 2.4896799864156245

Epoch: 6| Step: 4
Training loss: 2.7422342758319105
Validation loss: 2.4945064745352763

Epoch: 6| Step: 5
Training loss: 2.823897262995438
Validation loss: 2.5038999496912333

Epoch: 6| Step: 6
Training loss: 2.3201809727031533
Validation loss: 2.480610408392437

Epoch: 6| Step: 7
Training loss: 2.725263838288185
Validation loss: 2.48128166594906

Epoch: 6| Step: 8
Training loss: 2.3841231946860852
Validation loss: 2.4780500499267597

Epoch: 6| Step: 9
Training loss: 2.5877453342174928
Validation loss: 2.4844223113923274

Epoch: 6| Step: 10
Training loss: 2.1322541676329734
Validation loss: 2.4728151484291705

Epoch: 6| Step: 11
Training loss: 2.3051260837982444
Validation loss: 2.4806655925832812

Epoch: 6| Step: 12
Training loss: 2.0367850377365575
Validation loss: 2.4753841320400354

Epoch: 6| Step: 13
Training loss: 2.730057539420842
Validation loss: 2.4721305975442918

Epoch: 146| Step: 0
Training loss: 2.628962296544557
Validation loss: 2.478210542668794

Epoch: 6| Step: 1
Training loss: 2.999794317188192
Validation loss: 2.477546825203809

Epoch: 6| Step: 2
Training loss: 2.2330118569496196
Validation loss: 2.4792039104410315

Epoch: 6| Step: 3
Training loss: 2.9381468040502807
Validation loss: 2.4761834240557956

Epoch: 6| Step: 4
Training loss: 2.5819228433771664
Validation loss: 2.4814644324516735

Epoch: 6| Step: 5
Training loss: 2.5712095973466553
Validation loss: 2.4822336561238867

Epoch: 6| Step: 6
Training loss: 1.8368672066309373
Validation loss: 2.482821404625377

Epoch: 6| Step: 7
Training loss: 2.254885350123085
Validation loss: 2.4820341202068215

Epoch: 6| Step: 8
Training loss: 2.3309446324041025
Validation loss: 2.4800324464285417

Epoch: 6| Step: 9
Training loss: 2.1494995821171328
Validation loss: 2.477569551822848

Epoch: 6| Step: 10
Training loss: 2.439016506193956
Validation loss: 2.4810081876573276

Epoch: 6| Step: 11
Training loss: 1.8756795287603358
Validation loss: 2.483491864573998

Epoch: 6| Step: 12
Training loss: 2.675257632959854
Validation loss: 2.4820156930626633

Epoch: 6| Step: 13
Training loss: 2.503273156361752
Validation loss: 2.488623882440285

Epoch: 147| Step: 0
Training loss: 2.3242585507359
Validation loss: 2.494053013875186

Epoch: 6| Step: 1
Training loss: 2.345997965734564
Validation loss: 2.4896766107767245

Epoch: 6| Step: 2
Training loss: 2.5108539522296973
Validation loss: 2.4781669128901536

Epoch: 6| Step: 3
Training loss: 2.35604309873554
Validation loss: 2.4863739608770916

Epoch: 6| Step: 4
Training loss: 2.6481942484275556
Validation loss: 2.4786021981777395

Epoch: 6| Step: 5
Training loss: 2.7649796589660203
Validation loss: 2.4760830933653737

Epoch: 6| Step: 6
Training loss: 2.2513801792087955
Validation loss: 2.4720551461711495

Epoch: 6| Step: 7
Training loss: 2.7787000131851487
Validation loss: 2.4768677371959233

Epoch: 6| Step: 8
Training loss: 1.6805295740786674
Validation loss: 2.478799180969506

Epoch: 6| Step: 9
Training loss: 2.3213773910414015
Validation loss: 2.479228048339404

Epoch: 6| Step: 10
Training loss: 2.5934095044296446
Validation loss: 2.4851001025223676

Epoch: 6| Step: 11
Training loss: 2.810256062851559
Validation loss: 2.4895190439475883

Epoch: 6| Step: 12
Training loss: 2.557487796221093
Validation loss: 2.4769341223083616

Epoch: 6| Step: 13
Training loss: 2.18249287432614
Validation loss: 2.477180716672647

Epoch: 148| Step: 0
Training loss: 2.426761152852329
Validation loss: 2.4789944329793636

Epoch: 6| Step: 1
Training loss: 2.5537970154589407
Validation loss: 2.478685225427366

Epoch: 6| Step: 2
Training loss: 2.619247764313372
Validation loss: 2.4831492121069982

Epoch: 6| Step: 3
Training loss: 2.2664841699996243
Validation loss: 2.4780644576577213

Epoch: 6| Step: 4
Training loss: 3.283045831347028
Validation loss: 2.475575407809625

Epoch: 6| Step: 5
Training loss: 2.2702856074064286
Validation loss: 2.4823177144717885

Epoch: 6| Step: 6
Training loss: 2.103209236804678
Validation loss: 2.4815549860005746

Epoch: 6| Step: 7
Training loss: 2.610842902925667
Validation loss: 2.4950898827777634

Epoch: 6| Step: 8
Training loss: 1.9340201476072343
Validation loss: 2.486336099991915

Epoch: 6| Step: 9
Training loss: 2.65712983762537
Validation loss: 2.4916612314613626

Epoch: 6| Step: 10
Training loss: 2.4724483553253394
Validation loss: 2.4992554271089973

Epoch: 6| Step: 11
Training loss: 2.2634870241407103
Validation loss: 2.484495803806945

Epoch: 6| Step: 12
Training loss: 1.9008417799562825
Validation loss: 2.4837979780227464

Epoch: 6| Step: 13
Training loss: 2.476903560992588
Validation loss: 2.4869300291523073

Epoch: 149| Step: 0
Training loss: 2.9122452784141495
Validation loss: 2.4847961804512684

Epoch: 6| Step: 1
Training loss: 2.3816417381880908
Validation loss: 2.480714640607211

Epoch: 6| Step: 2
Training loss: 2.8572846990526566
Validation loss: 2.4803587881630307

Epoch: 6| Step: 3
Training loss: 3.1800539897438136
Validation loss: 2.4775988699761715

Epoch: 6| Step: 4
Training loss: 2.805116243452707
Validation loss: 2.4817580189062176

Epoch: 6| Step: 5
Training loss: 2.0645348885476054
Validation loss: 2.477948159141244

Epoch: 6| Step: 6
Training loss: 2.151547597973425
Validation loss: 2.4775489423006265

Epoch: 6| Step: 7
Training loss: 2.444883851332981
Validation loss: 2.4791842922150478

Epoch: 6| Step: 8
Training loss: 2.076114686050901
Validation loss: 2.478047227701423

Epoch: 6| Step: 9
Training loss: 2.27532356392594
Validation loss: 2.4783169762234714

Epoch: 6| Step: 10
Training loss: 2.3238958054262113
Validation loss: 2.4870443818228036

Epoch: 6| Step: 11
Training loss: 2.336245819463607
Validation loss: 2.4868844991245127

Epoch: 6| Step: 12
Training loss: 1.8938232357354976
Validation loss: 2.48748613286586

Epoch: 6| Step: 13
Training loss: 2.254274863738981
Validation loss: 2.4933487788485253

Epoch: 150| Step: 0
Training loss: 2.2486916022698935
Validation loss: 2.515319189592855

Epoch: 6| Step: 1
Training loss: 2.160655289962621
Validation loss: 2.513529724354098

Epoch: 6| Step: 2
Training loss: 3.070957727556815
Validation loss: 2.5088647554055474

Epoch: 6| Step: 3
Training loss: 2.3288806482627096
Validation loss: 2.4999193973263334

Epoch: 6| Step: 4
Training loss: 2.153282666904489
Validation loss: 2.4884792231159376

Epoch: 6| Step: 5
Training loss: 1.995333831123437
Validation loss: 2.4844589059284092

Epoch: 6| Step: 6
Training loss: 2.5796232551694134
Validation loss: 2.490289760796454

Epoch: 6| Step: 7
Training loss: 2.747484790874451
Validation loss: 2.4894757639950296

Epoch: 6| Step: 8
Training loss: 2.754843001972188
Validation loss: 2.4856474714611863

Epoch: 6| Step: 9
Training loss: 1.8452174279305138
Validation loss: 2.478246707821845

Epoch: 6| Step: 10
Training loss: 2.0778630600674393
Validation loss: 2.4741531188309547

Epoch: 6| Step: 11
Training loss: 3.0584874238183937
Validation loss: 2.4847320444026524

Epoch: 6| Step: 12
Training loss: 2.3882548232483574
Validation loss: 2.4790760205363918

Epoch: 6| Step: 13
Training loss: 2.7550873083829384
Validation loss: 2.481285269203921

Epoch: 151| Step: 0
Training loss: 2.296944442010698
Validation loss: 2.4769992703952775

Epoch: 6| Step: 1
Training loss: 1.714596254741174
Validation loss: 2.4842557738543736

Epoch: 6| Step: 2
Training loss: 2.362772938942406
Validation loss: 2.4891180830067756

Epoch: 6| Step: 3
Training loss: 2.0778122286510246
Validation loss: 2.4902545763580117

Epoch: 6| Step: 4
Training loss: 2.130402149688404
Validation loss: 2.4849910172287957

Epoch: 6| Step: 5
Training loss: 1.766565258186599
Validation loss: 2.4943528688717542

Epoch: 6| Step: 6
Training loss: 1.7082548666200412
Validation loss: 2.4985632344111313

Epoch: 6| Step: 7
Training loss: 2.648693151147476
Validation loss: 2.511142140476221

Epoch: 6| Step: 8
Training loss: 3.3648435572723128
Validation loss: 2.513571443999223

Epoch: 6| Step: 9
Training loss: 2.8648509137574054
Validation loss: 2.526198790602336

Epoch: 6| Step: 10
Training loss: 2.605283075719905
Validation loss: 2.511626665593769

Epoch: 6| Step: 11
Training loss: 2.616061477976994
Validation loss: 2.509521440830769

Epoch: 6| Step: 12
Training loss: 3.3840019830648327
Validation loss: 2.5061787862323786

Epoch: 6| Step: 13
Training loss: 2.184451895084828
Validation loss: 2.493652184399675

Epoch: 152| Step: 0
Training loss: 2.739327789881576
Validation loss: 2.4935748106465536

Epoch: 6| Step: 1
Training loss: 1.9829396741408294
Validation loss: 2.4869995009837607

Epoch: 6| Step: 2
Training loss: 1.7164766015075619
Validation loss: 2.479785366486736

Epoch: 6| Step: 3
Training loss: 2.5140516206210766
Validation loss: 2.4772438211215446

Epoch: 6| Step: 4
Training loss: 1.9999537462608021
Validation loss: 2.4752348862237223

Epoch: 6| Step: 5
Training loss: 2.7610076463614877
Validation loss: 2.485326700642062

Epoch: 6| Step: 6
Training loss: 3.0252456187005374
Validation loss: 2.475501088751806

Epoch: 6| Step: 7
Training loss: 2.36747191077128
Validation loss: 2.480196752178054

Epoch: 6| Step: 8
Training loss: 1.9461709698242395
Validation loss: 2.481735634862717

Epoch: 6| Step: 9
Training loss: 2.629620436630935
Validation loss: 2.4787228023994636

Epoch: 6| Step: 10
Training loss: 2.829609012621115
Validation loss: 2.4750923261536775

Epoch: 6| Step: 11
Training loss: 2.5378658350420307
Validation loss: 2.48183165426003

Epoch: 6| Step: 12
Training loss: 2.6724082013200046
Validation loss: 2.474307312026322

Epoch: 6| Step: 13
Training loss: 2.1167968164314788
Validation loss: 2.4901819719772256

Epoch: 153| Step: 0
Training loss: 2.0122339866589645
Validation loss: 2.480079440105869

Epoch: 6| Step: 1
Training loss: 2.6455249356334924
Validation loss: 2.4899926959674956

Epoch: 6| Step: 2
Training loss: 2.8555806316787056
Validation loss: 2.500493350623197

Epoch: 6| Step: 3
Training loss: 2.8477691083817382
Validation loss: 2.5024123553318818

Epoch: 6| Step: 4
Training loss: 2.6300927668698892
Validation loss: 2.500111132376924

Epoch: 6| Step: 5
Training loss: 2.3901249979762413
Validation loss: 2.4970366160287742

Epoch: 6| Step: 6
Training loss: 2.233183429678543
Validation loss: 2.485026675950368

Epoch: 6| Step: 7
Training loss: 2.427836605506707
Validation loss: 2.492998953707736

Epoch: 6| Step: 8
Training loss: 2.052039931817825
Validation loss: 2.487637231386413

Epoch: 6| Step: 9
Training loss: 1.8905802319483398
Validation loss: 2.472236931205835

Epoch: 6| Step: 10
Training loss: 2.134638301755426
Validation loss: 2.4706715537807074

Epoch: 6| Step: 11
Training loss: 2.483580264246573
Validation loss: 2.4754938493463587

Epoch: 6| Step: 12
Training loss: 2.885441932613508
Validation loss: 2.475276416537557

Epoch: 6| Step: 13
Training loss: 2.3271363482559466
Validation loss: 2.4882196072419167

Epoch: 154| Step: 0
Training loss: 3.023524872062001
Validation loss: 2.474468577453356

Epoch: 6| Step: 1
Training loss: 2.2332864523944274
Validation loss: 2.4926791926804928

Epoch: 6| Step: 2
Training loss: 2.0460422365186317
Validation loss: 2.480783261362008

Epoch: 6| Step: 3
Training loss: 2.342342717153502
Validation loss: 2.487450828896928

Epoch: 6| Step: 4
Training loss: 2.5076790176946755
Validation loss: 2.4903601521162013

Epoch: 6| Step: 5
Training loss: 2.512344116385525
Validation loss: 2.4926683286928464

Epoch: 6| Step: 6
Training loss: 2.379869588596826
Validation loss: 2.48904263571687

Epoch: 6| Step: 7
Training loss: 2.1146101801127957
Validation loss: 2.5093987776919136

Epoch: 6| Step: 8
Training loss: 2.908002755542903
Validation loss: 2.5072162588835485

Epoch: 6| Step: 9
Training loss: 1.8030953918882204
Validation loss: 2.4950746496547254

Epoch: 6| Step: 10
Training loss: 2.091814541497235
Validation loss: 2.509824086657486

Epoch: 6| Step: 11
Training loss: 2.542078568481655
Validation loss: 2.4980365115684697

Epoch: 6| Step: 12
Training loss: 2.583919602185618
Validation loss: 2.4987012986714725

Epoch: 6| Step: 13
Training loss: 2.9574848265593205
Validation loss: 2.483532376814523

Epoch: 155| Step: 0
Training loss: 2.8475855856501555
Validation loss: 2.4887937360363255

Epoch: 6| Step: 1
Training loss: 2.6876845185566447
Validation loss: 2.4824268612135003

Epoch: 6| Step: 2
Training loss: 1.986752265050453
Validation loss: 2.4778942133778528

Epoch: 6| Step: 3
Training loss: 2.503190293811817
Validation loss: 2.4790091638194363

Epoch: 6| Step: 4
Training loss: 2.6977311491545812
Validation loss: 2.4802313903822037

Epoch: 6| Step: 5
Training loss: 2.4274179339851862
Validation loss: 2.4833211362995784

Epoch: 6| Step: 6
Training loss: 2.6223109868304353
Validation loss: 2.4796840758240934

Epoch: 6| Step: 7
Training loss: 2.0325912742249534
Validation loss: 2.4739192491087576

Epoch: 6| Step: 8
Training loss: 2.4685920954556946
Validation loss: 2.4812385385858753

Epoch: 6| Step: 9
Training loss: 1.9437223009300826
Validation loss: 2.4842188724106946

Epoch: 6| Step: 10
Training loss: 2.4903680264379586
Validation loss: 2.49074139388873

Epoch: 6| Step: 11
Training loss: 2.3563645716974646
Validation loss: 2.4958949718813974

Epoch: 6| Step: 12
Training loss: 2.3307549899640216
Validation loss: 2.498993551799306

Epoch: 6| Step: 13
Training loss: 2.5266733120484473
Validation loss: 2.4850472874175034

Epoch: 156| Step: 0
Training loss: 2.6677732158627006
Validation loss: 2.482526687422279

Epoch: 6| Step: 1
Training loss: 2.690665930814362
Validation loss: 2.4899545390155082

Epoch: 6| Step: 2
Training loss: 2.368859937225323
Validation loss: 2.4957348362035527

Epoch: 6| Step: 3
Training loss: 2.7396766056868023
Validation loss: 2.4805493439324517

Epoch: 6| Step: 4
Training loss: 2.2700339727338275
Validation loss: 2.5012040099987423

Epoch: 6| Step: 5
Training loss: 2.255084121725203
Validation loss: 2.4871688743788907

Epoch: 6| Step: 6
Training loss: 2.6884167903930347
Validation loss: 2.4970833931327805

Epoch: 6| Step: 7
Training loss: 2.2708236507477655
Validation loss: 2.4882676120705702

Epoch: 6| Step: 8
Training loss: 2.119907560312482
Validation loss: 2.474178398115647

Epoch: 6| Step: 9
Training loss: 2.3809156528546533
Validation loss: 2.4795598484987593

Epoch: 6| Step: 10
Training loss: 2.000246152035216
Validation loss: 2.494545007881403

Epoch: 6| Step: 11
Training loss: 2.5748687525512812
Validation loss: 2.479969108501947

Epoch: 6| Step: 12
Training loss: 2.2692648227329837
Validation loss: 2.4880706522325067

Epoch: 6| Step: 13
Training loss: 2.4769142454639654
Validation loss: 2.480750633102552

Epoch: 157| Step: 0
Training loss: 2.662383235466426
Validation loss: 2.485288296177197

Epoch: 6| Step: 1
Training loss: 2.169490905320657
Validation loss: 2.4798673927068284

Epoch: 6| Step: 2
Training loss: 2.7983859791744137
Validation loss: 2.4746175162189727

Epoch: 6| Step: 3
Training loss: 2.382351489887336
Validation loss: 2.489833744708441

Epoch: 6| Step: 4
Training loss: 1.7387908531452094
Validation loss: 2.488672118974557

Epoch: 6| Step: 5
Training loss: 2.6747969327482055
Validation loss: 2.5033660639245623

Epoch: 6| Step: 6
Training loss: 2.3379034744712675
Validation loss: 2.5034281035574586

Epoch: 6| Step: 7
Training loss: 2.1232991985449785
Validation loss: 2.5039583658001026

Epoch: 6| Step: 8
Training loss: 2.570822065216381
Validation loss: 2.497066413757996

Epoch: 6| Step: 9
Training loss: 2.720193852220545
Validation loss: 2.4947740770541493

Epoch: 6| Step: 10
Training loss: 2.6884996196341464
Validation loss: 2.491960441426411

Epoch: 6| Step: 11
Training loss: 2.697948460532728
Validation loss: 2.4987242304516504

Epoch: 6| Step: 12
Training loss: 2.1451341792467566
Validation loss: 2.4986472761632643

Epoch: 6| Step: 13
Training loss: 1.9714316013166786
Validation loss: 2.5115724978822085

Epoch: 158| Step: 0
Training loss: 2.4815151620617266
Validation loss: 2.5025099234776444

Epoch: 6| Step: 1
Training loss: 2.137548979259402
Validation loss: 2.4990820868505543

Epoch: 6| Step: 2
Training loss: 2.4784435745720836
Validation loss: 2.4936276283929146

Epoch: 6| Step: 3
Training loss: 2.737902126650028
Validation loss: 2.504163327164626

Epoch: 6| Step: 4
Training loss: 2.114976918340317
Validation loss: 2.4967342026679518

Epoch: 6| Step: 5
Training loss: 2.5014042725043812
Validation loss: 2.510657371493998

Epoch: 6| Step: 6
Training loss: 2.6475057847893675
Validation loss: 2.49075392545351

Epoch: 6| Step: 7
Training loss: 2.5490701962394926
Validation loss: 2.4950006884546547

Epoch: 6| Step: 8
Training loss: 2.6497451119829964
Validation loss: 2.4854604561063955

Epoch: 6| Step: 9
Training loss: 2.2599690311976968
Validation loss: 2.4890518312770364

Epoch: 6| Step: 10
Training loss: 2.61603577736937
Validation loss: 2.500779944191802

Epoch: 6| Step: 11
Training loss: 2.267226501592085
Validation loss: 2.507968933360235

Epoch: 6| Step: 12
Training loss: 2.3601658992323853
Validation loss: 2.5059716191355363

Epoch: 6| Step: 13
Training loss: 2.0949723959768027
Validation loss: 2.5155785597785414

Epoch: 159| Step: 0
Training loss: 2.3754254010337736
Validation loss: 2.5069131951983668

Epoch: 6| Step: 1
Training loss: 2.381392158810512
Validation loss: 2.497033218508093

Epoch: 6| Step: 2
Training loss: 3.301437475217575
Validation loss: 2.493467394910185

Epoch: 6| Step: 3
Training loss: 1.40401174650957
Validation loss: 2.488517139218667

Epoch: 6| Step: 4
Training loss: 2.4294643483612792
Validation loss: 2.493497745244917

Epoch: 6| Step: 5
Training loss: 2.8557172215766347
Validation loss: 2.485668789167173

Epoch: 6| Step: 6
Training loss: 2.0979568578613597
Validation loss: 2.4815559787886334

Epoch: 6| Step: 7
Training loss: 2.026261410078037
Validation loss: 2.490558893338734

Epoch: 6| Step: 8
Training loss: 2.945002289076532
Validation loss: 2.493642344497383

Epoch: 6| Step: 9
Training loss: 2.1826112887923648
Validation loss: 2.5061524027326545

Epoch: 6| Step: 10
Training loss: 2.7233085562404926
Validation loss: 2.520331235541251

Epoch: 6| Step: 11
Training loss: 1.9098346338036578
Validation loss: 2.5255594219255184

Epoch: 6| Step: 12
Training loss: 2.722629541515116
Validation loss: 2.537159884730449

Epoch: 6| Step: 13
Training loss: 2.658912849837276
Validation loss: 2.5340793165887003

Epoch: 160| Step: 0
Training loss: 2.2368934150101936
Validation loss: 2.4884626081918895

Epoch: 6| Step: 1
Training loss: 2.062415612546247
Validation loss: 2.4879993336907664

Epoch: 6| Step: 2
Training loss: 2.164207150689363
Validation loss: 2.475666048357597

Epoch: 6| Step: 3
Training loss: 2.991672879976782
Validation loss: 2.4811935847584707

Epoch: 6| Step: 4
Training loss: 2.597097787125767
Validation loss: 2.482806240271553

Epoch: 6| Step: 5
Training loss: 2.397531344434601
Validation loss: 2.479142009922372

Epoch: 6| Step: 6
Training loss: 2.3325237731703368
Validation loss: 2.4636553576139364

Epoch: 6| Step: 7
Training loss: 2.407597746483933
Validation loss: 2.4626992353210984

Epoch: 6| Step: 8
Training loss: 2.5078223872955405
Validation loss: 2.4586572487575578

Epoch: 6| Step: 9
Training loss: 2.707487081706471
Validation loss: 2.4693680484551264

Epoch: 6| Step: 10
Training loss: 2.4521272416074176
Validation loss: 2.4604478217684522

Epoch: 6| Step: 11
Training loss: 2.9178636728591543
Validation loss: 2.466597040800378

Epoch: 6| Step: 12
Training loss: 2.2989687556549216
Validation loss: 2.4645289780810593

Epoch: 6| Step: 13
Training loss: 2.7696977358171284
Validation loss: 2.465778155580226

Epoch: 161| Step: 0
Training loss: 2.641328977387078
Validation loss: 2.464766818063642

Epoch: 6| Step: 1
Training loss: 2.6677143204599623
Validation loss: 2.4717549734959725

Epoch: 6| Step: 2
Training loss: 1.7268033097055833
Validation loss: 2.4649119581809518

Epoch: 6| Step: 3
Training loss: 1.9661613278483698
Validation loss: 2.4732914290087256

Epoch: 6| Step: 4
Training loss: 2.522712154483718
Validation loss: 2.472590320545873

Epoch: 6| Step: 5
Training loss: 2.4399052026187644
Validation loss: 2.472298522431387

Epoch: 6| Step: 6
Training loss: 2.7893898822542122
Validation loss: 2.4795861463659534

Epoch: 6| Step: 7
Training loss: 2.591951964969354
Validation loss: 2.494423384484321

Epoch: 6| Step: 8
Training loss: 2.739830373400168
Validation loss: 2.474016824666623

Epoch: 6| Step: 9
Training loss: 2.5556470836152654
Validation loss: 2.4967933752844544

Epoch: 6| Step: 10
Training loss: 1.9099887392201436
Validation loss: 2.491155173408938

Epoch: 6| Step: 11
Training loss: 2.056412005782016
Validation loss: 2.4952479657304143

Epoch: 6| Step: 12
Training loss: 2.4874980178901787
Validation loss: 2.492142823395836

Epoch: 6| Step: 13
Training loss: 2.918061404308341
Validation loss: 2.5018696628360835

Epoch: 162| Step: 0
Training loss: 2.9333270036744694
Validation loss: 2.498501201212789

Epoch: 6| Step: 1
Training loss: 2.552413254776103
Validation loss: 2.497807749541635

Epoch: 6| Step: 2
Training loss: 2.388267102260445
Validation loss: 2.502114117316804

Epoch: 6| Step: 3
Training loss: 2.472298498322387
Validation loss: 2.4997054562307435

Epoch: 6| Step: 4
Training loss: 1.877557663114588
Validation loss: 2.5085863165367583

Epoch: 6| Step: 5
Training loss: 2.3070413239824603
Validation loss: 2.4937257394271826

Epoch: 6| Step: 6
Training loss: 2.0468293396028368
Validation loss: 2.487852641529594

Epoch: 6| Step: 7
Training loss: 2.755520135342523
Validation loss: 2.48438627612356

Epoch: 6| Step: 8
Training loss: 2.744887975828415
Validation loss: 2.4746247180441996

Epoch: 6| Step: 9
Training loss: 2.5051915623558854
Validation loss: 2.4767236586962045

Epoch: 6| Step: 10
Training loss: 1.931215800751028
Validation loss: 2.471776161838114

Epoch: 6| Step: 11
Training loss: 2.39727596027744
Validation loss: 2.483121975816008

Epoch: 6| Step: 12
Training loss: 2.5101321891536204
Validation loss: 2.4842060919389444

Epoch: 6| Step: 13
Training loss: 2.767363093710625
Validation loss: 2.4873165893669325

Epoch: 163| Step: 0
Training loss: 2.8994583018581017
Validation loss: 2.4855741569799927

Epoch: 6| Step: 1
Training loss: 2.787458626478577
Validation loss: 2.4942794040275924

Epoch: 6| Step: 2
Training loss: 1.95859445359621
Validation loss: 2.5387366687343875

Epoch: 6| Step: 3
Training loss: 2.331246555520139
Validation loss: 2.5392105920103587

Epoch: 6| Step: 4
Training loss: 2.518467310336031
Validation loss: 2.5480545136620223

Epoch: 6| Step: 5
Training loss: 2.7626694225987323
Validation loss: 2.5741368976829886

Epoch: 6| Step: 6
Training loss: 2.4405097963542524
Validation loss: 2.5447727880871986

Epoch: 6| Step: 7
Training loss: 2.5108739876919093
Validation loss: 2.5254371365391703

Epoch: 6| Step: 8
Training loss: 1.689573638674968
Validation loss: 2.5009456753266472

Epoch: 6| Step: 9
Training loss: 2.1505323150271596
Validation loss: 2.493412725128951

Epoch: 6| Step: 10
Training loss: 2.458079685983606
Validation loss: 2.4890586959959866

Epoch: 6| Step: 11
Training loss: 1.784832146603619
Validation loss: 2.4854450280702247

Epoch: 6| Step: 12
Training loss: 2.4946579124151644
Validation loss: 2.4834463115142364

Epoch: 6| Step: 13
Training loss: 3.3166155889466222
Validation loss: 2.4917327242699185

Epoch: 164| Step: 0
Training loss: 2.520456637986646
Validation loss: 2.4870319034650414

Epoch: 6| Step: 1
Training loss: 2.6064858345892286
Validation loss: 2.481643222491438

Epoch: 6| Step: 2
Training loss: 2.141802498731617
Validation loss: 2.485724156798049

Epoch: 6| Step: 3
Training loss: 2.407397207281995
Validation loss: 2.4806377683711225

Epoch: 6| Step: 4
Training loss: 2.727042519361366
Validation loss: 2.4937572737279377

Epoch: 6| Step: 5
Training loss: 1.8668571403371974
Validation loss: 2.4913449592184667

Epoch: 6| Step: 6
Training loss: 2.359685309005809
Validation loss: 2.4997960961157935

Epoch: 6| Step: 7
Training loss: 2.702191583077346
Validation loss: 2.5104462449057947

Epoch: 6| Step: 8
Training loss: 2.098688479005205
Validation loss: 2.5294726532840706

Epoch: 6| Step: 9
Training loss: 2.5020177328089677
Validation loss: 2.5383963469082986

Epoch: 6| Step: 10
Training loss: 2.1897357958975237
Validation loss: 2.539486565022795

Epoch: 6| Step: 11
Training loss: 2.754836597616169
Validation loss: 2.5581195886975503

Epoch: 6| Step: 12
Training loss: 2.810258438335232
Validation loss: 2.5532871884300548

Epoch: 6| Step: 13
Training loss: 2.23124625154923
Validation loss: 2.5277862711706685

Epoch: 165| Step: 0
Training loss: 2.537066147269345
Validation loss: 2.5170350792468303

Epoch: 6| Step: 1
Training loss: 2.153993393245897
Validation loss: 2.5105874068155534

Epoch: 6| Step: 2
Training loss: 2.64137456063118
Validation loss: 2.5005433286897034

Epoch: 6| Step: 3
Training loss: 2.3802421339265853
Validation loss: 2.4927111546879983

Epoch: 6| Step: 4
Training loss: 2.4887257991823093
Validation loss: 2.490608105508453

Epoch: 6| Step: 5
Training loss: 1.9399844207334755
Validation loss: 2.486412028944407

Epoch: 6| Step: 6
Training loss: 2.8359761721493753
Validation loss: 2.47994050736492

Epoch: 6| Step: 7
Training loss: 2.421607414968207
Validation loss: 2.4812436152583435

Epoch: 6| Step: 8
Training loss: 2.535638654567256
Validation loss: 2.4787378314257076

Epoch: 6| Step: 9
Training loss: 2.109444398091625
Validation loss: 2.476809676838896

Epoch: 6| Step: 10
Training loss: 2.0255893179420497
Validation loss: 2.480271827710649

Epoch: 6| Step: 11
Training loss: 2.7550718181131733
Validation loss: 2.4911943806719017

Epoch: 6| Step: 12
Training loss: 2.2786541108480605
Validation loss: 2.4970214186521145

Epoch: 6| Step: 13
Training loss: 2.625411773355809
Validation loss: 2.5005989628759733

Epoch: 166| Step: 0
Training loss: 2.4646657646713415
Validation loss: 2.509470422307341

Epoch: 6| Step: 1
Training loss: 2.49242187163286
Validation loss: 2.5111362539240454

Epoch: 6| Step: 2
Training loss: 2.616900892364199
Validation loss: 2.548066264325398

Epoch: 6| Step: 3
Training loss: 2.3566771992722773
Validation loss: 2.5329689813745992

Epoch: 6| Step: 4
Training loss: 2.478511392456
Validation loss: 2.5529953605020985

Epoch: 6| Step: 5
Training loss: 3.065608412827036
Validation loss: 2.5451178076407186

Epoch: 6| Step: 6
Training loss: 2.8152531182438096
Validation loss: 2.5265124534442442

Epoch: 6| Step: 7
Training loss: 2.3910597860854015
Validation loss: 2.52104014869768

Epoch: 6| Step: 8
Training loss: 2.1250790973976788
Validation loss: 2.503999562540717

Epoch: 6| Step: 9
Training loss: 2.0754748203309723
Validation loss: 2.4970049083082473

Epoch: 6| Step: 10
Training loss: 2.4947019705579097
Validation loss: 2.4897638731632945

Epoch: 6| Step: 11
Training loss: 1.7820011362142827
Validation loss: 2.4805681664275756

Epoch: 6| Step: 12
Training loss: 2.678130562241252
Validation loss: 2.4805391476871548

Epoch: 6| Step: 13
Training loss: 2.232695688725212
Validation loss: 2.4872275316672474

Epoch: 167| Step: 0
Training loss: 2.2293714506496944
Validation loss: 2.4781128195567113

Epoch: 6| Step: 1
Training loss: 2.4903511767950817
Validation loss: 2.4771811497793257

Epoch: 6| Step: 2
Training loss: 2.4063484865320843
Validation loss: 2.4795206014981575

Epoch: 6| Step: 3
Training loss: 2.0977416065545045
Validation loss: 2.4855033343526878

Epoch: 6| Step: 4
Training loss: 2.552366923450911
Validation loss: 2.485178131867416

Epoch: 6| Step: 5
Training loss: 2.2358562121486725
Validation loss: 2.4909225809396047

Epoch: 6| Step: 6
Training loss: 1.982296433261814
Validation loss: 2.4914122106018888

Epoch: 6| Step: 7
Training loss: 2.3706711922049193
Validation loss: 2.491461477687304

Epoch: 6| Step: 8
Training loss: 3.1326873830416218
Validation loss: 2.5037494358386505

Epoch: 6| Step: 9
Training loss: 2.9310055628775493
Validation loss: 2.5053841786255706

Epoch: 6| Step: 10
Training loss: 1.824763149412174
Validation loss: 2.515761282884069

Epoch: 6| Step: 11
Training loss: 2.2121889057308537
Validation loss: 2.525203264194278

Epoch: 6| Step: 12
Training loss: 2.8273525131439734
Validation loss: 2.5131603670007343

Epoch: 6| Step: 13
Training loss: 2.325313022010067
Validation loss: 2.5027356915375956

Epoch: 168| Step: 0
Training loss: 2.182488067699206
Validation loss: 2.5189563420591012

Epoch: 6| Step: 1
Training loss: 1.5893307919791297
Validation loss: 2.513350744119674

Epoch: 6| Step: 2
Training loss: 2.765274284237538
Validation loss: 2.534510737498919

Epoch: 6| Step: 3
Training loss: 2.419118875768886
Validation loss: 2.500468830017344

Epoch: 6| Step: 4
Training loss: 1.3958428036192942
Validation loss: 2.5163689849914523

Epoch: 6| Step: 5
Training loss: 2.5057832582944655
Validation loss: 2.4980128496968077

Epoch: 6| Step: 6
Training loss: 2.67540806305001
Validation loss: 2.501520123858485

Epoch: 6| Step: 7
Training loss: 2.7592365165340222
Validation loss: 2.5010962943567407

Epoch: 6| Step: 8
Training loss: 2.5459473213445567
Validation loss: 2.504492950340174

Epoch: 6| Step: 9
Training loss: 2.4929429586397958
Validation loss: 2.5072208233407784

Epoch: 6| Step: 10
Training loss: 2.875762506624432
Validation loss: 2.5033322855273754

Epoch: 6| Step: 11
Training loss: 2.139440389709848
Validation loss: 2.5064506517031035

Epoch: 6| Step: 12
Training loss: 2.4340961849983427
Validation loss: 2.515196761807674

Epoch: 6| Step: 13
Training loss: 2.3492892103471976
Validation loss: 2.5142303613069776

Epoch: 169| Step: 0
Training loss: 2.2772137194197595
Validation loss: 2.535069664493873

Epoch: 6| Step: 1
Training loss: 2.181653192632501
Validation loss: 2.513012415949242

Epoch: 6| Step: 2
Training loss: 2.3542975555312604
Validation loss: 2.5423360526790293

Epoch: 6| Step: 3
Training loss: 2.574354616785078
Validation loss: 2.5220890359285213

Epoch: 6| Step: 4
Training loss: 2.2836845680054503
Validation loss: 2.507863821611696

Epoch: 6| Step: 5
Training loss: 2.8838051014940866
Validation loss: 2.514612708964426

Epoch: 6| Step: 6
Training loss: 2.635077252350392
Validation loss: 2.5012178156947606

Epoch: 6| Step: 7
Training loss: 2.5832356055037797
Validation loss: 2.498246865696479

Epoch: 6| Step: 8
Training loss: 2.810930789178256
Validation loss: 2.5059972513533384

Epoch: 6| Step: 9
Training loss: 1.9529926102591706
Validation loss: 2.499246483732686

Epoch: 6| Step: 10
Training loss: 1.7757850603296876
Validation loss: 2.506378017082857

Epoch: 6| Step: 11
Training loss: 2.5621255740645092
Validation loss: 2.4960616323109126

Epoch: 6| Step: 12
Training loss: 2.3250566783272366
Validation loss: 2.5107113334177424

Epoch: 6| Step: 13
Training loss: 2.2509805873743844
Validation loss: 2.5012245040425305

Epoch: 170| Step: 0
Training loss: 1.9655767025494952
Validation loss: 2.507319638632826

Epoch: 6| Step: 1
Training loss: 3.0354767265652907
Validation loss: 2.5193757474950704

Epoch: 6| Step: 2
Training loss: 1.7554112287875228
Validation loss: 2.5126339998460607

Epoch: 6| Step: 3
Training loss: 2.1499880102843494
Validation loss: 2.5167349505055534

Epoch: 6| Step: 4
Training loss: 2.530789933957249
Validation loss: 2.5085640293207314

Epoch: 6| Step: 5
Training loss: 2.491421477162721
Validation loss: 2.5038709315657224

Epoch: 6| Step: 6
Training loss: 2.343991381613084
Validation loss: 2.512061697336873

Epoch: 6| Step: 7
Training loss: 2.1209994412807682
Validation loss: 2.502645459795392

Epoch: 6| Step: 8
Training loss: 2.5097024516307576
Validation loss: 2.50452664962017

Epoch: 6| Step: 9
Training loss: 2.4543399596329705
Validation loss: 2.502248984281352

Epoch: 6| Step: 10
Training loss: 2.7303931317206978
Validation loss: 2.5133343489498983

Epoch: 6| Step: 11
Training loss: 2.7352197704550156
Validation loss: 2.5102005597772847

Epoch: 6| Step: 12
Training loss: 2.4364627685332545
Validation loss: 2.5148939251128466

Epoch: 6| Step: 13
Training loss: 1.95269801240852
Validation loss: 2.5178386355167266

Epoch: 171| Step: 0
Training loss: 2.2823966293074744
Validation loss: 2.5193043135922983

Epoch: 6| Step: 1
Training loss: 2.571089514071355
Validation loss: 2.520387962237975

Epoch: 6| Step: 2
Training loss: 2.1416781542676495
Validation loss: 2.5207748774116503

Epoch: 6| Step: 3
Training loss: 1.5690887389413664
Validation loss: 2.51541863457872

Epoch: 6| Step: 4
Training loss: 2.4101647573163265
Validation loss: 2.505908572119624

Epoch: 6| Step: 5
Training loss: 3.133429031398671
Validation loss: 2.512062171884446

Epoch: 6| Step: 6
Training loss: 2.815160806646585
Validation loss: 2.5102809589686594

Epoch: 6| Step: 7
Training loss: 2.0415778886865255
Validation loss: 2.510997868500411

Epoch: 6| Step: 8
Training loss: 2.338882274220653
Validation loss: 2.515222426400574

Epoch: 6| Step: 9
Training loss: 2.0130241232808523
Validation loss: 2.5166676731823387

Epoch: 6| Step: 10
Training loss: 2.4618067583715755
Validation loss: 2.518724392176244

Epoch: 6| Step: 11
Training loss: 2.462120232126179
Validation loss: 2.5166475891080715

Epoch: 6| Step: 12
Training loss: 2.349885564412131
Validation loss: 2.5307804190143317

Epoch: 6| Step: 13
Training loss: 2.6621646329612116
Validation loss: 2.5311357134854267

Epoch: 172| Step: 0
Training loss: 1.8863051693724806
Validation loss: 2.5289623456580017

Epoch: 6| Step: 1
Training loss: 2.3140828669422544
Validation loss: 2.525337905117148

Epoch: 6| Step: 2
Training loss: 1.9769664246134966
Validation loss: 2.506687058338794

Epoch: 6| Step: 3
Training loss: 2.7328082146237485
Validation loss: 2.501244799335137

Epoch: 6| Step: 4
Training loss: 2.554741628464219
Validation loss: 2.5051485928228274

Epoch: 6| Step: 5
Training loss: 2.6700215296645213
Validation loss: 2.514290623562012

Epoch: 6| Step: 6
Training loss: 2.5580016870739155
Validation loss: 2.5052169408405813

Epoch: 6| Step: 7
Training loss: 2.4502095191273074
Validation loss: 2.499991893755168

Epoch: 6| Step: 8
Training loss: 1.9513004172811128
Validation loss: 2.5019872078917955

Epoch: 6| Step: 9
Training loss: 1.9693338648580783
Validation loss: 2.509443820058757

Epoch: 6| Step: 10
Training loss: 3.031166940711273
Validation loss: 2.523364826805417

Epoch: 6| Step: 11
Training loss: 2.430484358940657
Validation loss: 2.5183485621512154

Epoch: 6| Step: 12
Training loss: 2.6049655960359175
Validation loss: 2.52171518858597

Epoch: 6| Step: 13
Training loss: 2.1132830551055135
Validation loss: 2.499977826973815

Epoch: 173| Step: 0
Training loss: 2.3296765783247095
Validation loss: 2.5140836744442168

Epoch: 6| Step: 1
Training loss: 2.0153190912939536
Validation loss: 2.509749143078784

Epoch: 6| Step: 2
Training loss: 2.4910173210053324
Validation loss: 2.5086277857550248

Epoch: 6| Step: 3
Training loss: 2.308548205550903
Validation loss: 2.5164134130777636

Epoch: 6| Step: 4
Training loss: 2.489084254934256
Validation loss: 2.4990823492073058

Epoch: 6| Step: 5
Training loss: 2.3920305894535185
Validation loss: 2.507652887670159

Epoch: 6| Step: 6
Training loss: 2.6950234078432866
Validation loss: 2.5036188001279602

Epoch: 6| Step: 7
Training loss: 2.2047203185885103
Validation loss: 2.5057647124260107

Epoch: 6| Step: 8
Training loss: 2.2403604859406245
Validation loss: 2.505528567672306

Epoch: 6| Step: 9
Training loss: 2.75130379720846
Validation loss: 2.4985518791350296

Epoch: 6| Step: 10
Training loss: 2.281328173826452
Validation loss: 2.499478794444182

Epoch: 6| Step: 11
Training loss: 2.6365471225971464
Validation loss: 2.5046411666661856

Epoch: 6| Step: 12
Training loss: 2.6204459332116543
Validation loss: 2.5066575097194104

Epoch: 6| Step: 13
Training loss: 1.9955382049925376
Validation loss: 2.5125554630616893

Epoch: 174| Step: 0
Training loss: 2.023349480205798
Validation loss: 2.505812119484117

Epoch: 6| Step: 1
Training loss: 1.988513625679784
Validation loss: 2.5366519381496144

Epoch: 6| Step: 2
Training loss: 2.472748620596445
Validation loss: 2.5456245644769844

Epoch: 6| Step: 3
Training loss: 2.581095238726803
Validation loss: 2.531213446145186

Epoch: 6| Step: 4
Training loss: 2.1511681421766005
Validation loss: 2.547817828012466

Epoch: 6| Step: 5
Training loss: 2.7278659623293553
Validation loss: 2.5373356037724424

Epoch: 6| Step: 6
Training loss: 2.1280060991185485
Validation loss: 2.532597987421718

Epoch: 6| Step: 7
Training loss: 2.298480452415621
Validation loss: 2.521502214285429

Epoch: 6| Step: 8
Training loss: 1.9331913076499352
Validation loss: 2.512841463687836

Epoch: 6| Step: 9
Training loss: 2.4633583393126806
Validation loss: 2.4968851632749676

Epoch: 6| Step: 10
Training loss: 2.9859388158806297
Validation loss: 2.494550997302175

Epoch: 6| Step: 11
Training loss: 2.581276741535871
Validation loss: 2.491269635194739

Epoch: 6| Step: 12
Training loss: 2.428739405681064
Validation loss: 2.485403235996876

Epoch: 6| Step: 13
Training loss: 2.4403954938956054
Validation loss: 2.4896251776037075

Epoch: 175| Step: 0
Training loss: 2.5225510117785817
Validation loss: 2.481399193417352

Epoch: 6| Step: 1
Training loss: 2.3838282687015533
Validation loss: 2.491490903500543

Epoch: 6| Step: 2
Training loss: 2.2197774737754807
Validation loss: 2.491590454271368

Epoch: 6| Step: 3
Training loss: 2.1815525402567957
Validation loss: 2.4868842035241356

Epoch: 6| Step: 4
Training loss: 2.3245959064065898
Validation loss: 2.483823879060216

Epoch: 6| Step: 5
Training loss: 2.339372132014464
Validation loss: 2.4926662324080486

Epoch: 6| Step: 6
Training loss: 2.2835593879716716
Validation loss: 2.4755290670088756

Epoch: 6| Step: 7
Training loss: 2.759508254569526
Validation loss: 2.484184609721263

Epoch: 6| Step: 8
Training loss: 2.081333752112598
Validation loss: 2.4884383043741947

Epoch: 6| Step: 9
Training loss: 2.5550214916601894
Validation loss: 2.5098100828990386

Epoch: 6| Step: 10
Training loss: 1.937532363129093
Validation loss: 2.5095735825267873

Epoch: 6| Step: 11
Training loss: 2.49710048378331
Validation loss: 2.5446638248252174

Epoch: 6| Step: 12
Training loss: 2.854441738563774
Validation loss: 2.535701980983115

Epoch: 6| Step: 13
Training loss: 2.719070591056876
Validation loss: 2.5392190112269

Epoch: 176| Step: 0
Training loss: 2.266079245445084
Validation loss: 2.5665844875242145

Epoch: 6| Step: 1
Training loss: 2.0883027001052423
Validation loss: 2.5552747947694905

Epoch: 6| Step: 2
Training loss: 2.1024549213162675
Validation loss: 2.562787574820825

Epoch: 6| Step: 3
Training loss: 2.672140721721468
Validation loss: 2.553268769728639

Epoch: 6| Step: 4
Training loss: 3.0963438315682925
Validation loss: 2.542164180611929

Epoch: 6| Step: 5
Training loss: 2.1702856382131652
Validation loss: 2.5313345027680096

Epoch: 6| Step: 6
Training loss: 2.7753492187160225
Validation loss: 2.503984193188823

Epoch: 6| Step: 7
Training loss: 2.0911170004206467
Validation loss: 2.494930547513313

Epoch: 6| Step: 8
Training loss: 2.180320839151753
Validation loss: 2.4978450229308713

Epoch: 6| Step: 9
Training loss: 2.4942213028993465
Validation loss: 2.4979134355725114

Epoch: 6| Step: 10
Training loss: 2.971797944523027
Validation loss: 2.4896859635995185

Epoch: 6| Step: 11
Training loss: 2.2405770396442644
Validation loss: 2.4866991987307716

Epoch: 6| Step: 12
Training loss: 2.4064200205000534
Validation loss: 2.484529678359903

Epoch: 6| Step: 13
Training loss: 2.599289092661962
Validation loss: 2.483207556293689

Epoch: 177| Step: 0
Training loss: 2.197365449121331
Validation loss: 2.481811864673164

Epoch: 6| Step: 1
Training loss: 2.127137623641138
Validation loss: 2.4861197512906874

Epoch: 6| Step: 2
Training loss: 2.33621663240675
Validation loss: 2.494387390149277

Epoch: 6| Step: 3
Training loss: 1.786719374496024
Validation loss: 2.498642044012559

Epoch: 6| Step: 4
Training loss: 2.2794416393081263
Validation loss: 2.5000640225159985

Epoch: 6| Step: 5
Training loss: 2.5431387239481027
Validation loss: 2.514851974595522

Epoch: 6| Step: 6
Training loss: 2.6820117001886348
Validation loss: 2.51093537497297

Epoch: 6| Step: 7
Training loss: 2.197525592260007
Validation loss: 2.5297827687191172

Epoch: 6| Step: 8
Training loss: 2.3811596750665087
Validation loss: 2.5214977229577875

Epoch: 6| Step: 9
Training loss: 2.227959766654747
Validation loss: 2.524742725849737

Epoch: 6| Step: 10
Training loss: 3.1752701051215335
Validation loss: 2.5348956694693374

Epoch: 6| Step: 11
Training loss: 2.7990265993501438
Validation loss: 2.534070676444712

Epoch: 6| Step: 12
Training loss: 2.3048427723449407
Validation loss: 2.5191994066557917

Epoch: 6| Step: 13
Training loss: 2.6001776597873607
Validation loss: 2.516781085194387

Epoch: 178| Step: 0
Training loss: 2.3429381935541316
Validation loss: 2.51503900056585

Epoch: 6| Step: 1
Training loss: 2.2809475214840345
Validation loss: 2.510789160311928

Epoch: 6| Step: 2
Training loss: 1.7715107538347457
Validation loss: 2.5090669879183483

Epoch: 6| Step: 3
Training loss: 2.035595046640832
Validation loss: 2.4950446449877353

Epoch: 6| Step: 4
Training loss: 1.9820223100255367
Validation loss: 2.4907908736594355

Epoch: 6| Step: 5
Training loss: 2.2143320505066812
Validation loss: 2.5003581108462787

Epoch: 6| Step: 6
Training loss: 2.7118955123206487
Validation loss: 2.502148896776288

Epoch: 6| Step: 7
Training loss: 3.291626426998074
Validation loss: 2.5032854743916957

Epoch: 6| Step: 8
Training loss: 2.5949855757001887
Validation loss: 2.4928116769140916

Epoch: 6| Step: 9
Training loss: 2.443163039798631
Validation loss: 2.497879265279055

Epoch: 6| Step: 10
Training loss: 2.1783222038064505
Validation loss: 2.4956461664836027

Epoch: 6| Step: 11
Training loss: 1.8596425224638178
Validation loss: 2.5027024920966

Epoch: 6| Step: 12
Training loss: 2.485113645906128
Validation loss: 2.5173541458442763

Epoch: 6| Step: 13
Training loss: 2.6422849775907054
Validation loss: 2.521655403165839

Epoch: 179| Step: 0
Training loss: 2.220646007813177
Validation loss: 2.5302358251789663

Epoch: 6| Step: 1
Training loss: 1.7561701583361784
Validation loss: 2.5436754939034802

Epoch: 6| Step: 2
Training loss: 3.0514885818740365
Validation loss: 2.537570581566367

Epoch: 6| Step: 3
Training loss: 2.7197951138690173
Validation loss: 2.527500515241913

Epoch: 6| Step: 4
Training loss: 2.171855459880063
Validation loss: 2.5426776209540094

Epoch: 6| Step: 5
Training loss: 2.169277476605474
Validation loss: 2.5589582266141497

Epoch: 6| Step: 6
Training loss: 2.48403026180293
Validation loss: 2.5634234245484615

Epoch: 6| Step: 7
Training loss: 2.668282932978586
Validation loss: 2.5506594805547276

Epoch: 6| Step: 8
Training loss: 2.704724582746266
Validation loss: 2.5528451418322007

Epoch: 6| Step: 9
Training loss: 1.7192516635156183
Validation loss: 2.520154236256561

Epoch: 6| Step: 10
Training loss: 2.7821573213347834
Validation loss: 2.5141801337552736

Epoch: 6| Step: 11
Training loss: 2.3408087012775227
Validation loss: 2.5148458755166585

Epoch: 6| Step: 12
Training loss: 2.429233619024642
Validation loss: 2.5153615272556853

Epoch: 6| Step: 13
Training loss: 1.9680788016204578
Validation loss: 2.4958379989563433

Epoch: 180| Step: 0
Training loss: 2.8669929126536142
Validation loss: 2.5043544516923526

Epoch: 6| Step: 1
Training loss: 2.417825574441393
Validation loss: 2.5065586841774405

Epoch: 6| Step: 2
Training loss: 1.8790089029991446
Validation loss: 2.505692803269606

Epoch: 6| Step: 3
Training loss: 1.8109503073317612
Validation loss: 2.5053175084890085

Epoch: 6| Step: 4
Training loss: 2.5092233272334723
Validation loss: 2.4961490057857287

Epoch: 6| Step: 5
Training loss: 3.234949917766732
Validation loss: 2.503487157637484

Epoch: 6| Step: 6
Training loss: 2.235866022466991
Validation loss: 2.5108525120757808

Epoch: 6| Step: 7
Training loss: 1.8934392869320447
Validation loss: 2.504011575484206

Epoch: 6| Step: 8
Training loss: 2.5023862894082636
Validation loss: 2.501514111411641

Epoch: 6| Step: 9
Training loss: 2.751173549284907
Validation loss: 2.5135175988101213

Epoch: 6| Step: 10
Training loss: 1.8544063698918407
Validation loss: 2.5210377528849004

Epoch: 6| Step: 11
Training loss: 2.0530408635892123
Validation loss: 2.5004905378374573

Epoch: 6| Step: 12
Training loss: 2.6477608055345927
Validation loss: 2.51609085539888

Epoch: 6| Step: 13
Training loss: 2.1549962033550334
Validation loss: 2.509509770949645

Epoch: 181| Step: 0
Training loss: 2.069191683268356
Validation loss: 2.5162455265354717

Epoch: 6| Step: 1
Training loss: 2.755138451616042
Validation loss: 2.5123480467766797

Epoch: 6| Step: 2
Training loss: 2.2846685427073705
Validation loss: 2.515476009150615

Epoch: 6| Step: 3
Training loss: 2.3055616886818235
Validation loss: 2.5171729433320356

Epoch: 6| Step: 4
Training loss: 2.5118974826752902
Validation loss: 2.507283773965831

Epoch: 6| Step: 5
Training loss: 1.66800176869214
Validation loss: 2.503275489807645

Epoch: 6| Step: 6
Training loss: 2.9596701453683596
Validation loss: 2.493216291279748

Epoch: 6| Step: 7
Training loss: 2.471754346524053
Validation loss: 2.497456249875952

Epoch: 6| Step: 8
Training loss: 2.172494923329979
Validation loss: 2.4950913559185515

Epoch: 6| Step: 9
Training loss: 2.074310358183329
Validation loss: 2.504344614173195

Epoch: 6| Step: 10
Training loss: 2.536708268548372
Validation loss: 2.497093195605862

Epoch: 6| Step: 11
Training loss: 2.3365373638617823
Validation loss: 2.5039022984228034

Epoch: 6| Step: 12
Training loss: 2.3446814148610517
Validation loss: 2.527711097713468

Epoch: 6| Step: 13
Training loss: 2.871960567490561
Validation loss: 2.5054509659379733

Epoch: 182| Step: 0
Training loss: 2.109666253221511
Validation loss: 2.525069284904861

Epoch: 6| Step: 1
Training loss: 2.599738779150343
Validation loss: 2.534617958072736

Epoch: 6| Step: 2
Training loss: 1.846322673175701
Validation loss: 2.5489003372193957

Epoch: 6| Step: 3
Training loss: 2.7424925718667654
Validation loss: 2.529598662882324

Epoch: 6| Step: 4
Training loss: 2.392050822792957
Validation loss: 2.5187895242447045

Epoch: 6| Step: 5
Training loss: 2.0076296236937274
Validation loss: 2.529498699290699

Epoch: 6| Step: 6
Training loss: 1.4131464230154884
Validation loss: 2.510807550371563

Epoch: 6| Step: 7
Training loss: 2.5605220138774487
Validation loss: 2.5141460422997133

Epoch: 6| Step: 8
Training loss: 2.8860931337996236
Validation loss: 2.513765820909182

Epoch: 6| Step: 9
Training loss: 2.0922927339966337
Validation loss: 2.5168091255776757

Epoch: 6| Step: 10
Training loss: 2.8993963007834203
Validation loss: 2.501852747709976

Epoch: 6| Step: 11
Training loss: 2.76584783830907
Validation loss: 2.511211369725115

Epoch: 6| Step: 12
Training loss: 2.3645127295709836
Validation loss: 2.521195430338432

Epoch: 6| Step: 13
Training loss: 2.0889655719146094
Validation loss: 2.518308223415726

Epoch: 183| Step: 0
Training loss: 2.3440441709919897
Validation loss: 2.5198494328320256

Epoch: 6| Step: 1
Training loss: 2.4769604480528673
Validation loss: 2.5154038326114425

Epoch: 6| Step: 2
Training loss: 2.942640959832077
Validation loss: 2.524126822819487

Epoch: 6| Step: 3
Training loss: 1.8851573477724866
Validation loss: 2.5264709317661356

Epoch: 6| Step: 4
Training loss: 2.082551758707993
Validation loss: 2.511120682977571

Epoch: 6| Step: 5
Training loss: 2.125431017079081
Validation loss: 2.5235112497361007

Epoch: 6| Step: 6
Training loss: 2.7744783409484546
Validation loss: 2.52142007688159

Epoch: 6| Step: 7
Training loss: 2.5707534365446927
Validation loss: 2.523205536848487

Epoch: 6| Step: 8
Training loss: 2.570001739916973
Validation loss: 2.530287555717519

Epoch: 6| Step: 9
Training loss: 2.362912185477246
Validation loss: 2.5339652282483875

Epoch: 6| Step: 10
Training loss: 2.7322226636470055
Validation loss: 2.526397103278859

Epoch: 6| Step: 11
Training loss: 1.8935733221749393
Validation loss: 2.5130670151230734

Epoch: 6| Step: 12
Training loss: 2.36280704501193
Validation loss: 2.519320583161171

Epoch: 6| Step: 13
Training loss: 2.0148235768213882
Validation loss: 2.513767053896258

Epoch: 184| Step: 0
Training loss: 2.143203741380901
Validation loss: 2.515723801088352

Epoch: 6| Step: 1
Training loss: 1.6349439808525927
Validation loss: 2.530488735684188

Epoch: 6| Step: 2
Training loss: 2.675657216559577
Validation loss: 2.520504320495228

Epoch: 6| Step: 3
Training loss: 2.540794181117546
Validation loss: 2.5234984399387472

Epoch: 6| Step: 4
Training loss: 2.230917222454115
Validation loss: 2.523114903224838

Epoch: 6| Step: 5
Training loss: 2.7490097343685997
Validation loss: 2.5261344630444675

Epoch: 6| Step: 6
Training loss: 1.7658870806337172
Validation loss: 2.51915557189662

Epoch: 6| Step: 7
Training loss: 2.368469294118076
Validation loss: 2.516264168866347

Epoch: 6| Step: 8
Training loss: 2.370862871018446
Validation loss: 2.5249190415097247

Epoch: 6| Step: 9
Training loss: 2.699193487863424
Validation loss: 2.5259147035343346

Epoch: 6| Step: 10
Training loss: 1.6160710853389626
Validation loss: 2.5123144524100867

Epoch: 6| Step: 11
Training loss: 2.913611655860223
Validation loss: 2.528560261141111

Epoch: 6| Step: 12
Training loss: 2.947753056994763
Validation loss: 2.5205583711421156

Epoch: 6| Step: 13
Training loss: 1.811306659241404
Validation loss: 2.524447889365762

Epoch: 185| Step: 0
Training loss: 2.621565433818409
Validation loss: 2.5330815537299793

Epoch: 6| Step: 1
Training loss: 2.5873694013725475
Validation loss: 2.5235896502627178

Epoch: 6| Step: 2
Training loss: 2.7682491288612225
Validation loss: 2.5315356623205667

Epoch: 6| Step: 3
Training loss: 2.0824034968223333
Validation loss: 2.5264232045851864

Epoch: 6| Step: 4
Training loss: 2.5851782292030863
Validation loss: 2.535346480071757

Epoch: 6| Step: 5
Training loss: 2.769980669883734
Validation loss: 2.525974663438985

Epoch: 6| Step: 6
Training loss: 1.7414610849392145
Validation loss: 2.5300627934474935

Epoch: 6| Step: 7
Training loss: 1.9154514800448499
Validation loss: 2.513994545469636

Epoch: 6| Step: 8
Training loss: 2.0770398511961754
Validation loss: 2.519635748852389

Epoch: 6| Step: 9
Training loss: 2.4167408328898103
Validation loss: 2.5145188104989527

Epoch: 6| Step: 10
Training loss: 2.223047956065235
Validation loss: 2.5163317649103027

Epoch: 6| Step: 11
Training loss: 2.549749706176657
Validation loss: 2.521661107581802

Epoch: 6| Step: 12
Training loss: 1.958392433194583
Validation loss: 2.520497974966273

Epoch: 6| Step: 13
Training loss: 2.5953195258314743
Validation loss: 2.5262959748818754

Epoch: 186| Step: 0
Training loss: 2.5132472013729052
Validation loss: 2.5465045339675187

Epoch: 6| Step: 1
Training loss: 2.5796509821598543
Validation loss: 2.5456315263926284

Epoch: 6| Step: 2
Training loss: 2.5695040744586626
Validation loss: 2.5855684814226563

Epoch: 6| Step: 3
Training loss: 2.7506165246848098
Validation loss: 2.5841841424644083

Epoch: 6| Step: 4
Training loss: 1.8576924380688016
Validation loss: 2.5725736479478094

Epoch: 6| Step: 5
Training loss: 2.213179566928809
Validation loss: 2.5498358321482355

Epoch: 6| Step: 6
Training loss: 2.219732255168954
Validation loss: 2.5394456232008333

Epoch: 6| Step: 7
Training loss: 2.941829331811226
Validation loss: 2.535250159955218

Epoch: 6| Step: 8
Training loss: 1.8100454876911205
Validation loss: 2.5087206692478623

Epoch: 6| Step: 9
Training loss: 2.399789634068112
Validation loss: 2.5100732993255517

Epoch: 6| Step: 10
Training loss: 2.4897782210891717
Validation loss: 2.508549361151536

Epoch: 6| Step: 11
Training loss: 2.2693188251086878
Validation loss: 2.5066787042311853

Epoch: 6| Step: 12
Training loss: 2.749235914024461
Validation loss: 2.504787351537983

Epoch: 6| Step: 13
Training loss: 1.8836288898216982
Validation loss: 2.5116222752641586

Epoch: 187| Step: 0
Training loss: 2.6998781318005274
Validation loss: 2.5068564806082687

Epoch: 6| Step: 1
Training loss: 2.478880943267747
Validation loss: 2.5131622643606657

Epoch: 6| Step: 2
Training loss: 1.8386993412635102
Validation loss: 2.514301955170114

Epoch: 6| Step: 3
Training loss: 2.61076299790768
Validation loss: 2.520235689636012

Epoch: 6| Step: 4
Training loss: 2.2193668206552166
Validation loss: 2.5316679652622787

Epoch: 6| Step: 5
Training loss: 2.5128691368898024
Validation loss: 2.5343577298517856

Epoch: 6| Step: 6
Training loss: 2.864709099985383
Validation loss: 2.5480654689935545

Epoch: 6| Step: 7
Training loss: 2.3919862349825403
Validation loss: 2.5725719411446013

Epoch: 6| Step: 8
Training loss: 2.3787943996950447
Validation loss: 2.589748390402246

Epoch: 6| Step: 9
Training loss: 2.892243133454997
Validation loss: 2.5640620766096367

Epoch: 6| Step: 10
Training loss: 2.0893524448045713
Validation loss: 2.567134945332085

Epoch: 6| Step: 11
Training loss: 2.4185437333823847
Validation loss: 2.56253580518069

Epoch: 6| Step: 12
Training loss: 1.9536194442503076
Validation loss: 2.531021217713432

Epoch: 6| Step: 13
Training loss: 1.9778217028920444
Validation loss: 2.5212390405041294

Epoch: 188| Step: 0
Training loss: 2.086547305234756
Validation loss: 2.5198762721512917

Epoch: 6| Step: 1
Training loss: 2.476278487325194
Validation loss: 2.5086211013055286

Epoch: 6| Step: 2
Training loss: 2.3191352709245296
Validation loss: 2.513154358684834

Epoch: 6| Step: 3
Training loss: 2.748880852208082
Validation loss: 2.513197112283318

Epoch: 6| Step: 4
Training loss: 2.133443773907759
Validation loss: 2.5149249411847445

Epoch: 6| Step: 5
Training loss: 2.4669189422923035
Validation loss: 2.5035851679869934

Epoch: 6| Step: 6
Training loss: 2.772273633433903
Validation loss: 2.505236291762411

Epoch: 6| Step: 7
Training loss: 3.2037738422008215
Validation loss: 2.514364523060213

Epoch: 6| Step: 8
Training loss: 1.766113618740464
Validation loss: 2.5115731821548537

Epoch: 6| Step: 9
Training loss: 1.9022995710628219
Validation loss: 2.5139485809330058

Epoch: 6| Step: 10
Training loss: 1.755334625077536
Validation loss: 2.5130826846929564

Epoch: 6| Step: 11
Training loss: 2.480453178777405
Validation loss: 2.5243866732677613

Epoch: 6| Step: 12
Training loss: 2.374565486310979
Validation loss: 2.52601496626648

Epoch: 6| Step: 13
Training loss: 2.6773379510305233
Validation loss: 2.536083629798623

Epoch: 189| Step: 0
Training loss: 2.3504244563093057
Validation loss: 2.5424045575587795

Epoch: 6| Step: 1
Training loss: 2.17812387036769
Validation loss: 2.569540524333092

Epoch: 6| Step: 2
Training loss: 2.0642057359016794
Validation loss: 2.590328549003118

Epoch: 6| Step: 3
Training loss: 3.07901065691014
Validation loss: 2.558957450195929

Epoch: 6| Step: 4
Training loss: 2.6078878950644864
Validation loss: 2.552941817611179

Epoch: 6| Step: 5
Training loss: 2.445737954077388
Validation loss: 2.5566809573099483

Epoch: 6| Step: 6
Training loss: 2.6992339424997556
Validation loss: 2.5468210163909117

Epoch: 6| Step: 7
Training loss: 2.7237605259531312
Validation loss: 2.519181472195565

Epoch: 6| Step: 8
Training loss: 2.195258088981792
Validation loss: 2.515244970582226

Epoch: 6| Step: 9
Training loss: 2.09544508910636
Validation loss: 2.5122562385092144

Epoch: 6| Step: 10
Training loss: 2.1712541310255142
Validation loss: 2.5042554717944596

Epoch: 6| Step: 11
Training loss: 1.8745138809736162
Validation loss: 2.501023194418144

Epoch: 6| Step: 12
Training loss: 2.118386467548146
Validation loss: 2.499023135385101

Epoch: 6| Step: 13
Training loss: 2.566524694487815
Validation loss: 2.5077121829431475

Epoch: 190| Step: 0
Training loss: 2.64122237270943
Validation loss: 2.497762378024455

Epoch: 6| Step: 1
Training loss: 1.9559455342149872
Validation loss: 2.503923770170764

Epoch: 6| Step: 2
Training loss: 2.4460256103459965
Validation loss: 2.5120938240051984

Epoch: 6| Step: 3
Training loss: 2.294208873615026
Validation loss: 2.5107146332953785

Epoch: 6| Step: 4
Training loss: 1.9898819091876299
Validation loss: 2.544882074583052

Epoch: 6| Step: 5
Training loss: 2.3435736017602853
Validation loss: 2.54239346842728

Epoch: 6| Step: 6
Training loss: 2.099365333746109
Validation loss: 2.559829739519063

Epoch: 6| Step: 7
Training loss: 2.7460760384608416
Validation loss: 2.55634629644129

Epoch: 6| Step: 8
Training loss: 2.8453746807713407
Validation loss: 2.557545516602512

Epoch: 6| Step: 9
Training loss: 2.6120514078441217
Validation loss: 2.5268922507638947

Epoch: 6| Step: 10
Training loss: 2.560423684375686
Validation loss: 2.5426940613350926

Epoch: 6| Step: 11
Training loss: 2.650471044457442
Validation loss: 2.5197867803590626

Epoch: 6| Step: 12
Training loss: 2.3150238492326314
Validation loss: 2.513599441144684

Epoch: 6| Step: 13
Training loss: 1.991808148337416
Validation loss: 2.5134714832670078

Epoch: 191| Step: 0
Training loss: 2.2071981451346834
Validation loss: 2.5032237487059583

Epoch: 6| Step: 1
Training loss: 2.9325280825415843
Validation loss: 2.508679185725406

Epoch: 6| Step: 2
Training loss: 2.1623186597699147
Validation loss: 2.501595655480087

Epoch: 6| Step: 3
Training loss: 2.876452866702382
Validation loss: 2.5130550612785347

Epoch: 6| Step: 4
Training loss: 2.5654582184307575
Validation loss: 2.508322460894504

Epoch: 6| Step: 5
Training loss: 1.6150866144533176
Validation loss: 2.5011238909742795

Epoch: 6| Step: 6
Training loss: 1.9782283834286079
Validation loss: 2.507775350990731

Epoch: 6| Step: 7
Training loss: 2.2645631603850327
Validation loss: 2.5105741828686448

Epoch: 6| Step: 8
Training loss: 1.9738667918965807
Validation loss: 2.531273013665717

Epoch: 6| Step: 9
Training loss: 2.418814712959863
Validation loss: 2.540581046612214

Epoch: 6| Step: 10
Training loss: 2.2290225710301512
Validation loss: 2.546928093167642

Epoch: 6| Step: 11
Training loss: 2.558821293853753
Validation loss: 2.5442202252938544

Epoch: 6| Step: 12
Training loss: 2.434937132350849
Validation loss: 2.55961272548877

Epoch: 6| Step: 13
Training loss: 2.6686934775591498
Validation loss: 2.5722369996459533

Epoch: 192| Step: 0
Training loss: 2.5766967516381016
Validation loss: 2.5440285188877794

Epoch: 6| Step: 1
Training loss: 1.8470206266200473
Validation loss: 2.558079776148256

Epoch: 6| Step: 2
Training loss: 2.9288967031677897
Validation loss: 2.553709179188966

Epoch: 6| Step: 3
Training loss: 2.1704668928010307
Validation loss: 2.532339136475614

Epoch: 6| Step: 4
Training loss: 2.3959200193783206
Validation loss: 2.5401503594642225

Epoch: 6| Step: 5
Training loss: 2.2740766013671347
Validation loss: 2.5427140490696756

Epoch: 6| Step: 6
Training loss: 2.0278924041586226
Validation loss: 2.5303705516549257

Epoch: 6| Step: 7
Training loss: 2.7748631211622894
Validation loss: 2.52222081822465

Epoch: 6| Step: 8
Training loss: 2.4346549229430923
Validation loss: 2.5139730332859638

Epoch: 6| Step: 9
Training loss: 2.3369647672949374
Validation loss: 2.5028542120135224

Epoch: 6| Step: 10
Training loss: 2.6381906879618433
Validation loss: 2.5183055646498524

Epoch: 6| Step: 11
Training loss: 1.8347094385300298
Validation loss: 2.5151221047116765

Epoch: 6| Step: 12
Training loss: 2.3681804727202045
Validation loss: 2.5143876280606965

Epoch: 6| Step: 13
Training loss: 2.1235606985163393
Validation loss: 2.5144498777543878

Epoch: 193| Step: 0
Training loss: 2.3407230412687685
Validation loss: 2.521180851419463

Epoch: 6| Step: 1
Training loss: 2.4863535362077815
Validation loss: 2.5234884093575034

Epoch: 6| Step: 2
Training loss: 1.5252354893452926
Validation loss: 2.5414943219730026

Epoch: 6| Step: 3
Training loss: 2.575646891400234
Validation loss: 2.529050491488642

Epoch: 6| Step: 4
Training loss: 2.3057578494730304
Validation loss: 2.5288225630115146

Epoch: 6| Step: 5
Training loss: 2.3496124191454717
Validation loss: 2.5301430797577678

Epoch: 6| Step: 6
Training loss: 2.1745023136087136
Validation loss: 2.5128287655394437

Epoch: 6| Step: 7
Training loss: 2.760776645052694
Validation loss: 2.509732217727157

Epoch: 6| Step: 8
Training loss: 1.9822523523769693
Validation loss: 2.526449321350028

Epoch: 6| Step: 9
Training loss: 2.0843035409737056
Validation loss: 2.5210710418690376

Epoch: 6| Step: 10
Training loss: 2.699759532675316
Validation loss: 2.5275085018177217

Epoch: 6| Step: 11
Training loss: 2.3610276251101348
Validation loss: 2.5251463152099087

Epoch: 6| Step: 12
Training loss: 2.4663052586253684
Validation loss: 2.524287896413017

Epoch: 6| Step: 13
Training loss: 2.6525832055476632
Validation loss: 2.525248048263011

Epoch: 194| Step: 0
Training loss: 2.3185096184270026
Validation loss: 2.520462786550563

Epoch: 6| Step: 1
Training loss: 1.7843795856477034
Validation loss: 2.517872345558657

Epoch: 6| Step: 2
Training loss: 2.3068490963755055
Validation loss: 2.5314369995994728

Epoch: 6| Step: 3
Training loss: 2.740597342652814
Validation loss: 2.5292337338533244

Epoch: 6| Step: 4
Training loss: 2.54710733489024
Validation loss: 2.5407291986885823

Epoch: 6| Step: 5
Training loss: 1.8597188679699146
Validation loss: 2.5247749114979037

Epoch: 6| Step: 6
Training loss: 3.153853006695429
Validation loss: 2.5227142336771644

Epoch: 6| Step: 7
Training loss: 2.472775424779129
Validation loss: 2.5174076564183543

Epoch: 6| Step: 8
Training loss: 2.457882295600894
Validation loss: 2.5024133795432575

Epoch: 6| Step: 9
Training loss: 2.623268464614128
Validation loss: 2.5174458076581603

Epoch: 6| Step: 10
Training loss: 2.387591862534
Validation loss: 2.5092805109092517

Epoch: 6| Step: 11
Training loss: 1.5350186429460375
Validation loss: 2.527172029725488

Epoch: 6| Step: 12
Training loss: 1.6325319039935369
Validation loss: 2.514549847000357

Epoch: 6| Step: 13
Training loss: 2.629646185801428
Validation loss: 2.5420328538308756

Epoch: 195| Step: 0
Training loss: 2.216138350357948
Validation loss: 2.5263491309068358

Epoch: 6| Step: 1
Training loss: 2.084510572333917
Validation loss: 2.527382254368632

Epoch: 6| Step: 2
Training loss: 2.3029385412300125
Validation loss: 2.543252814815294

Epoch: 6| Step: 3
Training loss: 2.2496594065265825
Validation loss: 2.5531247771257966

Epoch: 6| Step: 4
Training loss: 2.1099719297883155
Validation loss: 2.5329110774523294

Epoch: 6| Step: 5
Training loss: 3.0442697194893884
Validation loss: 2.5470828730152557

Epoch: 6| Step: 6
Training loss: 2.492175637339518
Validation loss: 2.5238204130137465

Epoch: 6| Step: 7
Training loss: 1.7554022646962943
Validation loss: 2.5272941289685393

Epoch: 6| Step: 8
Training loss: 1.8557022108471546
Validation loss: 2.536159510833672

Epoch: 6| Step: 9
Training loss: 2.8521776345831458
Validation loss: 2.518886860299449

Epoch: 6| Step: 10
Training loss: 2.3439497798968967
Validation loss: 2.513811543775289

Epoch: 6| Step: 11
Training loss: 2.3189124819027485
Validation loss: 2.5122622806070374

Epoch: 6| Step: 12
Training loss: 2.1726184917133216
Validation loss: 2.5041487284275443

Epoch: 6| Step: 13
Training loss: 2.8097676037840156
Validation loss: 2.5091615179898654

Epoch: 196| Step: 0
Training loss: 2.3711862561752945
Validation loss: 2.508409296408445

Epoch: 6| Step: 1
Training loss: 2.059656900147615
Validation loss: 2.504987866910991

Epoch: 6| Step: 2
Training loss: 2.6329108426435672
Validation loss: 2.51445819023965

Epoch: 6| Step: 3
Training loss: 2.235037005329364
Validation loss: 2.506773831616486

Epoch: 6| Step: 4
Training loss: 1.9799777594193855
Validation loss: 2.51246776655027

Epoch: 6| Step: 5
Training loss: 2.7476288369736266
Validation loss: 2.5156910415731515

Epoch: 6| Step: 6
Training loss: 2.439531018103142
Validation loss: 2.503822837071041

Epoch: 6| Step: 7
Training loss: 2.5091286886333766
Validation loss: 2.521658286891544

Epoch: 6| Step: 8
Training loss: 1.8568629758709387
Validation loss: 2.515352333092465

Epoch: 6| Step: 9
Training loss: 2.099458343041719
Validation loss: 2.5216419930100833

Epoch: 6| Step: 10
Training loss: 2.8102190729181538
Validation loss: 2.517021336626833

Epoch: 6| Step: 11
Training loss: 2.1937539212009782
Validation loss: 2.5258820525928436

Epoch: 6| Step: 12
Training loss: 2.2940172336000875
Validation loss: 2.523862820616937

Epoch: 6| Step: 13
Training loss: 2.505499608058286
Validation loss: 2.5409464727751634

Epoch: 197| Step: 0
Training loss: 2.0955936797930494
Validation loss: 2.5180875678557424

Epoch: 6| Step: 1
Training loss: 2.0945678935390304
Validation loss: 2.5313904962676776

Epoch: 6| Step: 2
Training loss: 2.2566138653045984
Validation loss: 2.5320299147967544

Epoch: 6| Step: 3
Training loss: 2.8460571655301186
Validation loss: 2.5558361694706604

Epoch: 6| Step: 4
Training loss: 1.8007578817245642
Validation loss: 2.547891472488902

Epoch: 6| Step: 5
Training loss: 2.477111370504428
Validation loss: 2.553024512888871

Epoch: 6| Step: 6
Training loss: 2.0559880886994515
Validation loss: 2.576793658280131

Epoch: 6| Step: 7
Training loss: 2.2931272071792406
Validation loss: 2.5748029016164806

Epoch: 6| Step: 8
Training loss: 2.4744152303047504
Validation loss: 2.541138818262958

Epoch: 6| Step: 9
Training loss: 2.1876601024348825
Validation loss: 2.540187738944599

Epoch: 6| Step: 10
Training loss: 2.808139387578252
Validation loss: 2.532405762094287

Epoch: 6| Step: 11
Training loss: 2.493294879426404
Validation loss: 2.5188924605576974

Epoch: 6| Step: 12
Training loss: 2.5633223539926684
Validation loss: 2.5173559295484047

Epoch: 6| Step: 13
Training loss: 2.395752637305804
Validation loss: 2.516124178246343

Epoch: 198| Step: 0
Training loss: 2.8922480794784997
Validation loss: 2.5099752731929046

Epoch: 6| Step: 1
Training loss: 2.38861448229932
Validation loss: 2.4938980657715963

Epoch: 6| Step: 2
Training loss: 2.7633398928255732
Validation loss: 2.502530398887628

Epoch: 6| Step: 3
Training loss: 2.189000840989845
Validation loss: 2.5113666420116614

Epoch: 6| Step: 4
Training loss: 2.279247502410849
Validation loss: 2.51615849558011

Epoch: 6| Step: 5
Training loss: 2.262054787347538
Validation loss: 2.5119035414553093

Epoch: 6| Step: 6
Training loss: 2.554080249347107
Validation loss: 2.5319468163122116

Epoch: 6| Step: 7
Training loss: 2.506782962133815
Validation loss: 2.5269337183435683

Epoch: 6| Step: 8
Training loss: 2.658796817311746
Validation loss: 2.536546996732184

Epoch: 6| Step: 9
Training loss: 2.218404178801713
Validation loss: 2.545498856477737

Epoch: 6| Step: 10
Training loss: 2.312315546875896
Validation loss: 2.5387897051472517

Epoch: 6| Step: 11
Training loss: 1.638106456594875
Validation loss: 2.5180107634760986

Epoch: 6| Step: 12
Training loss: 2.5555225372484998
Validation loss: 2.519156447337382

Epoch: 6| Step: 13
Training loss: 1.8068437121917504
Validation loss: 2.4931562209164775

Epoch: 199| Step: 0
Training loss: 2.568638404222741
Validation loss: 2.516427190599356

Epoch: 6| Step: 1
Training loss: 2.233719949803007
Validation loss: 2.506776050842507

Epoch: 6| Step: 2
Training loss: 2.4651074155110004
Validation loss: 2.5019270542919645

Epoch: 6| Step: 3
Training loss: 1.595329549102397
Validation loss: 2.516291370155985

Epoch: 6| Step: 4
Training loss: 3.201325594997414
Validation loss: 2.514634247279946

Epoch: 6| Step: 5
Training loss: 2.8024201220274305
Validation loss: 2.512957578399923

Epoch: 6| Step: 6
Training loss: 1.7175801544142761
Validation loss: 2.5255378981129324

Epoch: 6| Step: 7
Training loss: 2.7729304320244257
Validation loss: 2.547202606037818

Epoch: 6| Step: 8
Training loss: 1.6960815232449888
Validation loss: 2.5612222851032103

Epoch: 6| Step: 9
Training loss: 2.3634192560428176
Validation loss: 2.5953711992822144

Epoch: 6| Step: 10
Training loss: 2.369034352006388
Validation loss: 2.601011995068143

Epoch: 6| Step: 11
Training loss: 2.253618086404641
Validation loss: 2.5503493562127804

Epoch: 6| Step: 12
Training loss: 2.8478965291611464
Validation loss: 2.5323927226917107

Epoch: 6| Step: 13
Training loss: 1.9899718286446766
Validation loss: 2.5328696998885003

Epoch: 200| Step: 0
Training loss: 2.161328733917432
Validation loss: 2.50817920701333

Epoch: 6| Step: 1
Training loss: 1.773947218186087
Validation loss: 2.5045757856579476

Epoch: 6| Step: 2
Training loss: 2.1788838316652153
Validation loss: 2.497027855667447

Epoch: 6| Step: 3
Training loss: 2.5218480067362483
Validation loss: 2.4928123782918505

Epoch: 6| Step: 4
Training loss: 2.4690238704153233
Validation loss: 2.4893493914853306

Epoch: 6| Step: 5
Training loss: 2.4123304752222055
Validation loss: 2.4964150792556468

Epoch: 6| Step: 6
Training loss: 2.413371064258215
Validation loss: 2.503983256901044

Epoch: 6| Step: 7
Training loss: 2.6120385378437954
Validation loss: 2.507252370169554

Epoch: 6| Step: 8
Training loss: 2.82715821997444
Validation loss: 2.522316351948551

Epoch: 6| Step: 9
Training loss: 2.5140175748406506
Validation loss: 2.524887377049651

Epoch: 6| Step: 10
Training loss: 2.0983112811363203
Validation loss: 2.5569834992879996

Epoch: 6| Step: 11
Training loss: 2.7660577295420246
Validation loss: 2.579227204195241

Epoch: 6| Step: 12
Training loss: 2.005729455649858
Validation loss: 2.570097878567641

Epoch: 6| Step: 13
Training loss: 2.455204173685941
Validation loss: 2.5712847817676656

Epoch: 201| Step: 0
Training loss: 2.1986684974715223
Validation loss: 2.562517553750058

Epoch: 6| Step: 1
Training loss: 2.525735381654153
Validation loss: 2.5445072424754245

Epoch: 6| Step: 2
Training loss: 2.25895382238628
Validation loss: 2.532079411634863

Epoch: 6| Step: 3
Training loss: 2.5923111383110014
Validation loss: 2.530801882539518

Epoch: 6| Step: 4
Training loss: 1.9691693903769265
Validation loss: 2.5231635827834507

Epoch: 6| Step: 5
Training loss: 2.957289247331551
Validation loss: 2.525738874292927

Epoch: 6| Step: 6
Training loss: 2.233531766113488
Validation loss: 2.521317385603755

Epoch: 6| Step: 7
Training loss: 2.1050077085738943
Validation loss: 2.521297685294842

Epoch: 6| Step: 8
Training loss: 2.356513302609076
Validation loss: 2.5265222675593635

Epoch: 6| Step: 9
Training loss: 2.5416940989863956
Validation loss: 2.5129716199625136

Epoch: 6| Step: 10
Training loss: 2.4681191906023856
Validation loss: 2.5235592996749716

Epoch: 6| Step: 11
Training loss: 2.4528678224691185
Validation loss: 2.528853125412436

Epoch: 6| Step: 12
Training loss: 2.0738680268237624
Validation loss: 2.5193082488975533

Epoch: 6| Step: 13
Training loss: 2.1796101655537856
Validation loss: 2.534923744609712

Epoch: 202| Step: 0
Training loss: 2.7651340889450897
Validation loss: 2.5449399403428346

Epoch: 6| Step: 1
Training loss: 2.737208701882473
Validation loss: 2.5468133088111786

Epoch: 6| Step: 2
Training loss: 2.1655370873336324
Validation loss: 2.5444664829480597

Epoch: 6| Step: 3
Training loss: 2.2557693265306633
Validation loss: 2.546521495789035

Epoch: 6| Step: 4
Training loss: 2.6201318377164498
Validation loss: 2.5410138500851516

Epoch: 6| Step: 5
Training loss: 2.6986402231128346
Validation loss: 2.5342144659322763

Epoch: 6| Step: 6
Training loss: 1.8915738333667118
Validation loss: 2.557874738696859

Epoch: 6| Step: 7
Training loss: 2.3758010517212123
Validation loss: 2.55697641287656

Epoch: 6| Step: 8
Training loss: 2.1929835662504367
Validation loss: 2.549692650891198

Epoch: 6| Step: 9
Training loss: 2.3636739609469086
Validation loss: 2.5440812809803104

Epoch: 6| Step: 10
Training loss: 1.6586783978230335
Validation loss: 2.5306034439762928

Epoch: 6| Step: 11
Training loss: 2.642049010452458
Validation loss: 2.512149645289258

Epoch: 6| Step: 12
Training loss: 1.9463250768901994
Validation loss: 2.5149515170561654

Epoch: 6| Step: 13
Training loss: 2.25178457061092
Validation loss: 2.497646527375329

Epoch: 203| Step: 0
Training loss: 1.9403209454227768
Validation loss: 2.500833952409091

Epoch: 6| Step: 1
Training loss: 2.1567860918227675
Validation loss: 2.4945262191662794

Epoch: 6| Step: 2
Training loss: 2.506659031545225
Validation loss: 2.498337868649686

Epoch: 6| Step: 3
Training loss: 2.4970865439318963
Validation loss: 2.4895792100518426

Epoch: 6| Step: 4
Training loss: 2.8917689353894778
Validation loss: 2.4978494613383693

Epoch: 6| Step: 5
Training loss: 2.0883046409704056
Validation loss: 2.4893204112591856

Epoch: 6| Step: 6
Training loss: 2.3136188790188186
Validation loss: 2.5054486503782125

Epoch: 6| Step: 7
Training loss: 2.260729637687899
Validation loss: 2.5036865391896344

Epoch: 6| Step: 8
Training loss: 1.8496088593914275
Validation loss: 2.5143904885145227

Epoch: 6| Step: 9
Training loss: 2.1335138418402573
Validation loss: 2.5260134089092117

Epoch: 6| Step: 10
Training loss: 2.3849053869134536
Validation loss: 2.535823693016332

Epoch: 6| Step: 11
Training loss: 2.9028099784302146
Validation loss: 2.5576723570309405

Epoch: 6| Step: 12
Training loss: 2.2884947818149035
Validation loss: 2.5542139670227524

Epoch: 6| Step: 13
Training loss: 2.4668703287262588
Validation loss: 2.5876885561955985

Epoch: 204| Step: 0
Training loss: 2.56459425038902
Validation loss: 2.559412561683624

Epoch: 6| Step: 1
Training loss: 1.8454730501028742
Validation loss: 2.563085613169804

Epoch: 6| Step: 2
Training loss: 2.280345162482775
Validation loss: 2.5600631105571208

Epoch: 6| Step: 3
Training loss: 2.426281273948365
Validation loss: 2.5507605933014568

Epoch: 6| Step: 4
Training loss: 2.0336611009334145
Validation loss: 2.5570467322083155

Epoch: 6| Step: 5
Training loss: 2.51325156514783
Validation loss: 2.532014174160046

Epoch: 6| Step: 6
Training loss: 1.9226283636012254
Validation loss: 2.5295187598741338

Epoch: 6| Step: 7
Training loss: 2.298263545296517
Validation loss: 2.5157788310592055

Epoch: 6| Step: 8
Training loss: 2.5390215591651195
Validation loss: 2.5139494186710754

Epoch: 6| Step: 9
Training loss: 2.7731513936934187
Validation loss: 2.5245462507198235

Epoch: 6| Step: 10
Training loss: 1.9309217698752514
Validation loss: 2.5052041723226037

Epoch: 6| Step: 11
Training loss: 2.5768738456166504
Validation loss: 2.5021011979743513

Epoch: 6| Step: 12
Training loss: 2.414011143011561
Validation loss: 2.506352174726226

Epoch: 6| Step: 13
Training loss: 2.7310698670229567
Validation loss: 2.5255998887139484

Epoch: 205| Step: 0
Training loss: 1.8160214252342373
Validation loss: 2.530833315991136

Epoch: 6| Step: 1
Training loss: 2.4786823237688824
Validation loss: 2.530657726430158

Epoch: 6| Step: 2
Training loss: 1.8385591010833102
Validation loss: 2.5445797178614304

Epoch: 6| Step: 3
Training loss: 2.5822833193548798
Validation loss: 2.5641410504105964

Epoch: 6| Step: 4
Training loss: 2.3758501237935823
Validation loss: 2.5861380845996567

Epoch: 6| Step: 5
Training loss: 2.764225233774536
Validation loss: 2.606458210118192

Epoch: 6| Step: 6
Training loss: 1.593229919546481
Validation loss: 2.590262155312434

Epoch: 6| Step: 7
Training loss: 2.0305792067727935
Validation loss: 2.5666062863996872

Epoch: 6| Step: 8
Training loss: 2.6497201879792818
Validation loss: 2.5385693193405388

Epoch: 6| Step: 9
Training loss: 2.844898369286218
Validation loss: 2.535026668455959

Epoch: 6| Step: 10
Training loss: 2.954044098098114
Validation loss: 2.5269574396318015

Epoch: 6| Step: 11
Training loss: 2.4636796478492413
Validation loss: 2.514739407866049

Epoch: 6| Step: 12
Training loss: 2.0344989322819864
Validation loss: 2.516784163967955

Epoch: 6| Step: 13
Training loss: 2.4433338093811376
Validation loss: 2.507636360170234

Epoch: 206| Step: 0
Training loss: 2.5159170798630432
Validation loss: 2.507139882236155

Epoch: 6| Step: 1
Training loss: 3.1545196926912897
Validation loss: 2.5008338809073676

Epoch: 6| Step: 2
Training loss: 1.7123408723951976
Validation loss: 2.503266695721299

Epoch: 6| Step: 3
Training loss: 2.305793419278691
Validation loss: 2.505720396838597

Epoch: 6| Step: 4
Training loss: 1.7909160490653393
Validation loss: 2.5069901018103264

Epoch: 6| Step: 5
Training loss: 2.573041122659427
Validation loss: 2.5095316539115116

Epoch: 6| Step: 6
Training loss: 2.455896937497305
Validation loss: 2.510953732311271

Epoch: 6| Step: 7
Training loss: 2.5379708628383533
Validation loss: 2.5098104628776876

Epoch: 6| Step: 8
Training loss: 2.4095614547919184
Validation loss: 2.5256533661850806

Epoch: 6| Step: 9
Training loss: 2.366360560845401
Validation loss: 2.5308926490998185

Epoch: 6| Step: 10
Training loss: 2.5079680302482066
Validation loss: 2.528983070417429

Epoch: 6| Step: 11
Training loss: 1.7264238534900442
Validation loss: 2.557710000891278

Epoch: 6| Step: 12
Training loss: 2.561467404612555
Validation loss: 2.5446910114241463

Epoch: 6| Step: 13
Training loss: 2.0252390025817015
Validation loss: 2.5429932670759143

Epoch: 207| Step: 0
Training loss: 1.7847512618430588
Validation loss: 2.5250685767501957

Epoch: 6| Step: 1
Training loss: 1.9033441752488527
Validation loss: 2.5313140955215645

Epoch: 6| Step: 2
Training loss: 2.2600203018626943
Validation loss: 2.5185731155216344

Epoch: 6| Step: 3
Training loss: 2.215571315959727
Validation loss: 2.5233890934288215

Epoch: 6| Step: 4
Training loss: 1.9572879828444958
Validation loss: 2.5189052858909458

Epoch: 6| Step: 5
Training loss: 2.0657907301169707
Validation loss: 2.5210858263242515

Epoch: 6| Step: 6
Training loss: 3.2765876707202595
Validation loss: 2.5265962103437083

Epoch: 6| Step: 7
Training loss: 1.9070719213340825
Validation loss: 2.521262460758835

Epoch: 6| Step: 8
Training loss: 2.1937890247666862
Validation loss: 2.5140891115413293

Epoch: 6| Step: 9
Training loss: 2.471972908945613
Validation loss: 2.515576285133425

Epoch: 6| Step: 10
Training loss: 2.4925910838175422
Validation loss: 2.522067285555253

Epoch: 6| Step: 11
Training loss: 2.4182933287550887
Validation loss: 2.5352507633877277

Epoch: 6| Step: 12
Training loss: 2.4477156752730775
Validation loss: 2.5390426400214885

Epoch: 6| Step: 13
Training loss: 2.6554970964499565
Validation loss: 2.5412486128608607

Epoch: 208| Step: 0
Training loss: 1.7918644581522232
Validation loss: 2.562714622007514

Epoch: 6| Step: 1
Training loss: 1.771086222224987
Validation loss: 2.5729597965800597

Epoch: 6| Step: 2
Training loss: 1.9539666155459179
Validation loss: 2.559305246448278

Epoch: 6| Step: 3
Training loss: 2.1731008459531114
Validation loss: 2.5839765937363155

Epoch: 6| Step: 4
Training loss: 2.3842830935222756
Validation loss: 2.533902540591341

Epoch: 6| Step: 5
Training loss: 2.2730289891849265
Validation loss: 2.5332833902137466

Epoch: 6| Step: 6
Training loss: 2.131596592439092
Validation loss: 2.5243072742967616

Epoch: 6| Step: 7
Training loss: 2.5338592267876203
Validation loss: 2.5232262773954868

Epoch: 6| Step: 8
Training loss: 1.8583985657924942
Validation loss: 2.5120574105863964

Epoch: 6| Step: 9
Training loss: 3.3252925371248914
Validation loss: 2.5293492845680143

Epoch: 6| Step: 10
Training loss: 2.33860865938082
Validation loss: 2.523696303505691

Epoch: 6| Step: 11
Training loss: 2.7709430491205924
Validation loss: 2.5196499897579523

Epoch: 6| Step: 12
Training loss: 2.702300458629143
Validation loss: 2.5239521836287113

Epoch: 6| Step: 13
Training loss: 2.230616683196267
Validation loss: 2.513140033536868

Epoch: 209| Step: 0
Training loss: 2.5427730736987506
Validation loss: 2.520104599805245

Epoch: 6| Step: 1
Training loss: 1.3763692713722118
Validation loss: 2.5196202935149636

Epoch: 6| Step: 2
Training loss: 2.1382483215361123
Validation loss: 2.519510163605843

Epoch: 6| Step: 3
Training loss: 2.3012133259003322
Validation loss: 2.522625157603832

Epoch: 6| Step: 4
Training loss: 2.460187622141636
Validation loss: 2.525083306326336

Epoch: 6| Step: 5
Training loss: 2.774984696492105
Validation loss: 2.53531027523385

Epoch: 6| Step: 6
Training loss: 2.641590551328714
Validation loss: 2.537925473451926

Epoch: 6| Step: 7
Training loss: 2.1070647975696493
Validation loss: 2.5487093570169623

Epoch: 6| Step: 8
Training loss: 2.5005910174809762
Validation loss: 2.565662154231845

Epoch: 6| Step: 9
Training loss: 2.3858808929183515
Validation loss: 2.5555981209799037

Epoch: 6| Step: 10
Training loss: 2.3839202807237894
Validation loss: 2.5700150059658977

Epoch: 6| Step: 11
Training loss: 2.5163245324335364
Validation loss: 2.5501678180948355

Epoch: 6| Step: 12
Training loss: 1.9834185720874553
Validation loss: 2.559146532132504

Epoch: 6| Step: 13
Training loss: 2.180895070927138
Validation loss: 2.5226466905167215

Epoch: 210| Step: 0
Training loss: 2.3934633446909417
Validation loss: 2.5524143523325806

Epoch: 6| Step: 1
Training loss: 2.347518332900347
Validation loss: 2.5239577254167225

Epoch: 6| Step: 2
Training loss: 2.144773153478664
Validation loss: 2.512827966961342

Epoch: 6| Step: 3
Training loss: 1.9251097462073758
Validation loss: 2.529745117687444

Epoch: 6| Step: 4
Training loss: 2.4080199630644863
Validation loss: 2.509089729939562

Epoch: 6| Step: 5
Training loss: 2.5418137888201278
Validation loss: 2.5139279377142665

Epoch: 6| Step: 6
Training loss: 2.4728577638684976
Validation loss: 2.520099333364543

Epoch: 6| Step: 7
Training loss: 2.6271328208753566
Validation loss: 2.5144068767977488

Epoch: 6| Step: 8
Training loss: 1.7971123580068735
Validation loss: 2.5214599639711643

Epoch: 6| Step: 9
Training loss: 1.9120631772501075
Validation loss: 2.52523893730284

Epoch: 6| Step: 10
Training loss: 2.2453790472969235
Validation loss: 2.528180510073017

Epoch: 6| Step: 11
Training loss: 3.105076411193152
Validation loss: 2.53619099539125

Epoch: 6| Step: 12
Training loss: 2.487478465078099
Validation loss: 2.543817928197666

Epoch: 6| Step: 13
Training loss: 1.9090856504574305
Validation loss: 2.5692468847899472

Epoch: 211| Step: 0
Training loss: 3.1108068495272923
Validation loss: 2.554274546059953

Epoch: 6| Step: 1
Training loss: 2.1534499633233537
Validation loss: 2.564930515252871

Epoch: 6| Step: 2
Training loss: 2.286121653546292
Validation loss: 2.542797233239113

Epoch: 6| Step: 3
Training loss: 1.8305168480930034
Validation loss: 2.561042200399432

Epoch: 6| Step: 4
Training loss: 2.7672866743205904
Validation loss: 2.5450696260662227

Epoch: 6| Step: 5
Training loss: 1.712832163875505
Validation loss: 2.5585448437547202

Epoch: 6| Step: 6
Training loss: 2.3892537092256108
Validation loss: 2.556242334530008

Epoch: 6| Step: 7
Training loss: 2.1548882206296
Validation loss: 2.57051530866919

Epoch: 6| Step: 8
Training loss: 2.083341776512839
Validation loss: 2.5681722865358725

Epoch: 6| Step: 9
Training loss: 2.1154482971956345
Validation loss: 2.5772997681733982

Epoch: 6| Step: 10
Training loss: 2.565146777320311
Validation loss: 2.5642399656943624

Epoch: 6| Step: 11
Training loss: 2.610656058336992
Validation loss: 2.5553982647114486

Epoch: 6| Step: 12
Training loss: 2.234347790105573
Validation loss: 2.54340814641242

Epoch: 6| Step: 13
Training loss: 1.8971431385547277
Validation loss: 2.535700445246134

Epoch: 212| Step: 0
Training loss: 2.3655059179773446
Validation loss: 2.534520677424109

Epoch: 6| Step: 1
Training loss: 2.986645698502142
Validation loss: 2.5261654354855128

Epoch: 6| Step: 2
Training loss: 1.793536725806418
Validation loss: 2.5342476445508515

Epoch: 6| Step: 3
Training loss: 1.8532083013380318
Validation loss: 2.536750139583254

Epoch: 6| Step: 4
Training loss: 1.8177181633480357
Validation loss: 2.543735605335044

Epoch: 6| Step: 5
Training loss: 2.1201648680439895
Validation loss: 2.546016400170776

Epoch: 6| Step: 6
Training loss: 2.8310231907419188
Validation loss: 2.545823830078502

Epoch: 6| Step: 7
Training loss: 2.1518009006617844
Validation loss: 2.551505281546931

Epoch: 6| Step: 8
Training loss: 2.933791396471094
Validation loss: 2.571289680655705

Epoch: 6| Step: 9
Training loss: 2.2118937981963582
Validation loss: 2.550126541338925

Epoch: 6| Step: 10
Training loss: 2.112018200709206
Validation loss: 2.52631227806925

Epoch: 6| Step: 11
Training loss: 1.7566075242791852
Validation loss: 2.526761537731804

Epoch: 6| Step: 12
Training loss: 2.387696011471012
Validation loss: 2.536098577429654

Epoch: 6| Step: 13
Training loss: 2.584991005267611
Validation loss: 2.5340339280621818

Epoch: 213| Step: 0
Training loss: 2.3034225872024385
Validation loss: 2.5258810143001384

Epoch: 6| Step: 1
Training loss: 2.5803584741352323
Validation loss: 2.5378706105504656

Epoch: 6| Step: 2
Training loss: 1.873671378839568
Validation loss: 2.53438885265975

Epoch: 6| Step: 3
Training loss: 2.313723472471996
Validation loss: 2.5490873904047886

Epoch: 6| Step: 4
Training loss: 2.090852240969432
Validation loss: 2.550609884693239

Epoch: 6| Step: 5
Training loss: 1.5646358388056152
Validation loss: 2.570049152584546

Epoch: 6| Step: 6
Training loss: 2.570567387984021
Validation loss: 2.5666392630398134

Epoch: 6| Step: 7
Training loss: 1.9629529345287544
Validation loss: 2.5377727030023958

Epoch: 6| Step: 8
Training loss: 2.062907554356187
Validation loss: 2.542568560088188

Epoch: 6| Step: 9
Training loss: 1.6878523282184845
Validation loss: 2.5492571590241133

Epoch: 6| Step: 10
Training loss: 2.458760973271221
Validation loss: 2.563553275761882

Epoch: 6| Step: 11
Training loss: 3.1758584251270072
Validation loss: 2.562120952328988

Epoch: 6| Step: 12
Training loss: 2.7107521015719525
Validation loss: 2.5752181263234846

Epoch: 6| Step: 13
Training loss: 2.2874901484709844
Validation loss: 2.6053680293695747

Epoch: 214| Step: 0
Training loss: 1.8047645189108419
Validation loss: 2.6260077192227445

Epoch: 6| Step: 1
Training loss: 1.6936773333850201
Validation loss: 2.6223667197456555

Epoch: 6| Step: 2
Training loss: 2.007263821097105
Validation loss: 2.5842214155092096

Epoch: 6| Step: 3
Training loss: 2.553084777739317
Validation loss: 2.600153666625791

Epoch: 6| Step: 4
Training loss: 2.3112124389765287
Validation loss: 2.5929519927090703

Epoch: 6| Step: 5
Training loss: 2.3950881683749246
Validation loss: 2.555541927075558

Epoch: 6| Step: 6
Training loss: 2.0085489429059438
Validation loss: 2.541652653348053

Epoch: 6| Step: 7
Training loss: 1.6451464157107647
Validation loss: 2.5377214851870575

Epoch: 6| Step: 8
Training loss: 2.509940792160518
Validation loss: 2.5323398896718667

Epoch: 6| Step: 9
Training loss: 2.545479796024273
Validation loss: 2.5325665601824876

Epoch: 6| Step: 10
Training loss: 3.100264654860256
Validation loss: 2.5351046031360025

Epoch: 6| Step: 11
Training loss: 1.837235012539901
Validation loss: 2.531155604105489

Epoch: 6| Step: 12
Training loss: 2.731422094165261
Validation loss: 2.5285107975636762

Epoch: 6| Step: 13
Training loss: 2.6431332024252843
Validation loss: 2.4995768347866227

Epoch: 215| Step: 0
Training loss: 2.512121948343593
Validation loss: 2.516948722881842

Epoch: 6| Step: 1
Training loss: 2.259536982173519
Validation loss: 2.5242207416859905

Epoch: 6| Step: 2
Training loss: 2.3711462376423866
Validation loss: 2.5422642166951106

Epoch: 6| Step: 3
Training loss: 2.361113659227779
Validation loss: 2.5212403013578375

Epoch: 6| Step: 4
Training loss: 2.606028712549953
Validation loss: 2.5250099093806138

Epoch: 6| Step: 5
Training loss: 2.61869108365958
Validation loss: 2.5433911794514477

Epoch: 6| Step: 6
Training loss: 2.2586436078464494
Validation loss: 2.545404848500205

Epoch: 6| Step: 7
Training loss: 1.3886569380459854
Validation loss: 2.5586658884997804

Epoch: 6| Step: 8
Training loss: 2.368700003788318
Validation loss: 2.5552476274714286

Epoch: 6| Step: 9
Training loss: 2.0857658172706324
Validation loss: 2.5736791945394106

Epoch: 6| Step: 10
Training loss: 3.000567700395744
Validation loss: 2.6078869351322953

Epoch: 6| Step: 11
Training loss: 1.9360491950547116
Validation loss: 2.6289496907106917

Epoch: 6| Step: 12
Training loss: 2.159004000689646
Validation loss: 2.6178742376039614

Epoch: 6| Step: 13
Training loss: 2.164743694965429
Validation loss: 2.561780316775515

Epoch: 216| Step: 0
Training loss: 2.014130859161929
Validation loss: 2.556510072954014

Epoch: 6| Step: 1
Training loss: 1.9153586845039143
Validation loss: 2.527892767004797

Epoch: 6| Step: 2
Training loss: 2.7259613511164758
Validation loss: 2.538221476234513

Epoch: 6| Step: 3
Training loss: 2.2167523484652656
Validation loss: 2.5224359215472996

Epoch: 6| Step: 4
Training loss: 1.8114796759159937
Validation loss: 2.5078230844751648

Epoch: 6| Step: 5
Training loss: 2.523699484060245
Validation loss: 2.5054693000205246

Epoch: 6| Step: 6
Training loss: 2.8533037278015003
Validation loss: 2.5116054258198135

Epoch: 6| Step: 7
Training loss: 2.383763358084223
Validation loss: 2.5110930538043994

Epoch: 6| Step: 8
Training loss: 2.238682789094513
Validation loss: 2.520972292724498

Epoch: 6| Step: 9
Training loss: 2.4931562209164775
Validation loss: 2.503938132175833

Epoch: 6| Step: 10
Training loss: 2.4378695085635105
Validation loss: 2.524819939239401

Epoch: 6| Step: 11
Training loss: 2.2788543663879812
Validation loss: 2.5291472441060003

Epoch: 6| Step: 12
Training loss: 2.0170426225825513
Validation loss: 2.532791814105786

Epoch: 6| Step: 13
Training loss: 2.1615032390541096
Validation loss: 2.5724783509890954

Epoch: 217| Step: 0
Training loss: 2.8854468902951353
Validation loss: 2.595248054011991

Epoch: 6| Step: 1
Training loss: 2.5978223704519157
Validation loss: 2.6294832696937944

Epoch: 6| Step: 2
Training loss: 2.0941698023566033
Validation loss: 2.6625894779219865

Epoch: 6| Step: 3
Training loss: 2.827314144674157
Validation loss: 2.7148650609924956

Epoch: 6| Step: 4
Training loss: 1.4814575436212292
Validation loss: 2.6332371309871894

Epoch: 6| Step: 5
Training loss: 1.874383189153892
Validation loss: 2.569570138508834

Epoch: 6| Step: 6
Training loss: 2.5948985670548326
Validation loss: 2.5129225374015234

Epoch: 6| Step: 7
Training loss: 2.1244374820940077
Validation loss: 2.5109198819080234

Epoch: 6| Step: 8
Training loss: 2.455116386995502
Validation loss: 2.4988472347096318

Epoch: 6| Step: 9
Training loss: 2.939058255765975
Validation loss: 2.491481988074042

Epoch: 6| Step: 10
Training loss: 2.109651674563429
Validation loss: 2.499744553231026

Epoch: 6| Step: 11
Training loss: 2.6455108766478195
Validation loss: 2.4948056697784295

Epoch: 6| Step: 12
Training loss: 1.992728604899735
Validation loss: 2.496797847391317

Epoch: 6| Step: 13
Training loss: 2.5296891663082257
Validation loss: 2.5022365896873264

Epoch: 218| Step: 0
Training loss: 3.0160582236176996
Validation loss: 2.5026113223563367

Epoch: 6| Step: 1
Training loss: 2.4148287745208576
Validation loss: 2.4921737399463804

Epoch: 6| Step: 2
Training loss: 3.0420901556756648
Validation loss: 2.497147188083646

Epoch: 6| Step: 3
Training loss: 1.7060675443133186
Validation loss: 2.492490935313922

Epoch: 6| Step: 4
Training loss: 2.422773428367803
Validation loss: 2.498038937394747

Epoch: 6| Step: 5
Training loss: 2.2853348621436
Validation loss: 2.497787672906027

Epoch: 6| Step: 6
Training loss: 2.369216301347
Validation loss: 2.4866280885453285

Epoch: 6| Step: 7
Training loss: 2.1119230351512783
Validation loss: 2.4967049818914453

Epoch: 6| Step: 8
Training loss: 2.3805206783929327
Validation loss: 2.493383425585087

Epoch: 6| Step: 9
Training loss: 2.1979536683160465
Validation loss: 2.498699008662449

Epoch: 6| Step: 10
Training loss: 2.2065095267955677
Validation loss: 2.5098489037537033

Epoch: 6| Step: 11
Training loss: 2.400307190626858
Validation loss: 2.5046558577231792

Epoch: 6| Step: 12
Training loss: 1.9266666752354358
Validation loss: 2.535838595169764

Epoch: 6| Step: 13
Training loss: 2.421902564107255
Validation loss: 2.528446795994523

Epoch: 219| Step: 0
Training loss: 2.3455610271931953
Validation loss: 2.543407302754051

Epoch: 6| Step: 1
Training loss: 2.02565134663972
Validation loss: 2.5374757474294656

Epoch: 6| Step: 2
Training loss: 1.788170471359919
Validation loss: 2.568533284496482

Epoch: 6| Step: 3
Training loss: 2.817687273681312
Validation loss: 2.558296710527786

Epoch: 6| Step: 4
Training loss: 2.6433392180785793
Validation loss: 2.562289903913446

Epoch: 6| Step: 5
Training loss: 2.544765886282097
Validation loss: 2.5563494208292226

Epoch: 6| Step: 6
Training loss: 2.2208439791521437
Validation loss: 2.5696721230978152

Epoch: 6| Step: 7
Training loss: 2.2952542977325554
Validation loss: 2.5495888384777103

Epoch: 6| Step: 8
Training loss: 2.521943491557528
Validation loss: 2.5487275670118112

Epoch: 6| Step: 9
Training loss: 2.120063433148001
Validation loss: 2.5293088934771166

Epoch: 6| Step: 10
Training loss: 1.8572152039825134
Validation loss: 2.512815988259357

Epoch: 6| Step: 11
Training loss: 2.701017760143904
Validation loss: 2.527867596524504

Epoch: 6| Step: 12
Training loss: 2.5459014342377837
Validation loss: 2.5077816653311893

Epoch: 6| Step: 13
Training loss: 1.4926811320490045
Validation loss: 2.5060749313079524

Epoch: 220| Step: 0
Training loss: 2.3542239314403495
Validation loss: 2.514055587857048

Epoch: 6| Step: 1
Training loss: 3.1684460074670495
Validation loss: 2.513612404144247

Epoch: 6| Step: 2
Training loss: 2.1915309278954664
Validation loss: 2.5166277417168446

Epoch: 6| Step: 3
Training loss: 1.6166792361108384
Validation loss: 2.52086745520163

Epoch: 6| Step: 4
Training loss: 1.7899530851087295
Validation loss: 2.5237777527808425

Epoch: 6| Step: 5
Training loss: 1.9075210586125368
Validation loss: 2.5341062639266037

Epoch: 6| Step: 6
Training loss: 1.5292814407446733
Validation loss: 2.5248300983059804

Epoch: 6| Step: 7
Training loss: 3.0125395649571356
Validation loss: 2.5538015277809483

Epoch: 6| Step: 8
Training loss: 2.132949992348822
Validation loss: 2.517845516442095

Epoch: 6| Step: 9
Training loss: 2.4418146142847674
Validation loss: 2.5240287442422016

Epoch: 6| Step: 10
Training loss: 2.1817630197314233
Validation loss: 2.516356178313733

Epoch: 6| Step: 11
Training loss: 2.5616268438132397
Validation loss: 2.532583583972567

Epoch: 6| Step: 12
Training loss: 2.4469336842482354
Validation loss: 2.5300167674487812

Epoch: 6| Step: 13
Training loss: 2.201296649635679
Validation loss: 2.585934349895606

Epoch: 221| Step: 0
Training loss: 2.617620722656486
Validation loss: 2.600240025689496

Epoch: 6| Step: 1
Training loss: 2.2768353112212196
Validation loss: 2.615148404726098

Epoch: 6| Step: 2
Training loss: 2.6447088500302303
Validation loss: 2.5808684269464544

Epoch: 6| Step: 3
Training loss: 1.6842184301868492
Validation loss: 2.553153289924563

Epoch: 6| Step: 4
Training loss: 2.5057897283043498
Validation loss: 2.5446879586068647

Epoch: 6| Step: 5
Training loss: 2.569184122272708
Validation loss: 2.52238436080673

Epoch: 6| Step: 6
Training loss: 2.603144717284926
Validation loss: 2.530315619170704

Epoch: 6| Step: 7
Training loss: 2.607777729111176
Validation loss: 2.526371937557946

Epoch: 6| Step: 8
Training loss: 1.744373814286171
Validation loss: 2.52618788987457

Epoch: 6| Step: 9
Training loss: 1.8729125801129538
Validation loss: 2.5546130248247003

Epoch: 6| Step: 10
Training loss: 2.664400588254315
Validation loss: 2.5614156987594177

Epoch: 6| Step: 11
Training loss: 2.464501310280444
Validation loss: 2.5893755413315427

Epoch: 6| Step: 12
Training loss: 1.5703925117112036
Validation loss: 2.607790178249511

Epoch: 6| Step: 13
Training loss: 2.069180160931163
Validation loss: 2.6250719787175125

Epoch: 222| Step: 0
Training loss: 2.04055322401107
Validation loss: 2.611415423139742

Epoch: 6| Step: 1
Training loss: 2.377106585599248
Validation loss: 2.6528974132179695

Epoch: 6| Step: 2
Training loss: 2.543306155461614
Validation loss: 2.6256301668439086

Epoch: 6| Step: 3
Training loss: 3.009656623188425
Validation loss: 2.6005923855670936

Epoch: 6| Step: 4
Training loss: 1.4554175883385883
Validation loss: 2.581068266227761

Epoch: 6| Step: 5
Training loss: 2.1909994199918312
Validation loss: 2.527174820676132

Epoch: 6| Step: 6
Training loss: 2.120517940590163
Validation loss: 2.5198893132449416

Epoch: 6| Step: 7
Training loss: 2.3306037968565922
Validation loss: 2.4992839741520707

Epoch: 6| Step: 8
Training loss: 1.794264780005739
Validation loss: 2.508427505900965

Epoch: 6| Step: 9
Training loss: 2.2212946094848527
Validation loss: 2.521188463989831

Epoch: 6| Step: 10
Training loss: 2.801772363890193
Validation loss: 2.524840414713635

Epoch: 6| Step: 11
Training loss: 2.1788656674801747
Validation loss: 2.526350043176833

Epoch: 6| Step: 12
Training loss: 2.7009999295643894
Validation loss: 2.5373855452258036

Epoch: 6| Step: 13
Training loss: 2.3482114925502593
Validation loss: 2.546905267765729

Epoch: 223| Step: 0
Training loss: 2.466837468119092
Validation loss: 2.584311535942818

Epoch: 6| Step: 1
Training loss: 2.2258768732612846
Validation loss: 2.608406587695327

Epoch: 6| Step: 2
Training loss: 2.3241654077387213
Validation loss: 2.6141585705378128

Epoch: 6| Step: 3
Training loss: 2.32383927525192
Validation loss: 2.6135608806691906

Epoch: 6| Step: 4
Training loss: 2.722290802651855
Validation loss: 2.5763445168027594

Epoch: 6| Step: 5
Training loss: 1.9403426943257576
Validation loss: 2.5922495013872457

Epoch: 6| Step: 6
Training loss: 1.6970214668134531
Validation loss: 2.5617911591203892

Epoch: 6| Step: 7
Training loss: 1.8399647148522291
Validation loss: 2.5483381441053043

Epoch: 6| Step: 8
Training loss: 2.56122240922029
Validation loss: 2.535480903641339

Epoch: 6| Step: 9
Training loss: 3.0945977484827574
Validation loss: 2.540656746403607

Epoch: 6| Step: 10
Training loss: 2.062765046631283
Validation loss: 2.523818484304995

Epoch: 6| Step: 11
Training loss: 2.226799132505193
Validation loss: 2.5181887181901854

Epoch: 6| Step: 12
Training loss: 1.89413567572081
Validation loss: 2.5234107300526323

Epoch: 6| Step: 13
Training loss: 2.6259188179314874
Validation loss: 2.5150566011787836

Epoch: 224| Step: 0
Training loss: 2.280757485093614
Validation loss: 2.5446736938596737

Epoch: 6| Step: 1
Training loss: 1.9203647789539429
Validation loss: 2.6040903207396133

Epoch: 6| Step: 2
Training loss: 2.7074728161124337
Validation loss: 2.5976719294101125

Epoch: 6| Step: 3
Training loss: 2.6888108715932852
Validation loss: 2.6665920058368617

Epoch: 6| Step: 4
Training loss: 2.735043689162646
Validation loss: 2.672127129926337

Epoch: 6| Step: 5
Training loss: 2.5101458665933993
Validation loss: 2.6450256456503154

Epoch: 6| Step: 6
Training loss: 2.3004538751665504
Validation loss: 2.610329687481411

Epoch: 6| Step: 7
Training loss: 2.923917168922159
Validation loss: 2.593026025684885

Epoch: 6| Step: 8
Training loss: 1.8413686082477971
Validation loss: 2.5119713734830103

Epoch: 6| Step: 9
Training loss: 2.1287518086540524
Validation loss: 2.5034077307274316

Epoch: 6| Step: 10
Training loss: 1.6444306331489844
Validation loss: 2.499913357186959

Epoch: 6| Step: 11
Training loss: 2.2755963015612948
Validation loss: 2.493490231400182

Epoch: 6| Step: 12
Training loss: 2.6820319682697296
Validation loss: 2.5129138561400257

Epoch: 6| Step: 13
Training loss: 2.053394679643488
Validation loss: 2.5061414703056757

Epoch: 225| Step: 0
Training loss: 2.5615538734550456
Validation loss: 2.5190196777181924

Epoch: 6| Step: 1
Training loss: 3.2461577958859325
Validation loss: 2.510815051957899

Epoch: 6| Step: 2
Training loss: 2.153006283791209
Validation loss: 2.510259541597529

Epoch: 6| Step: 3
Training loss: 3.123665639189262
Validation loss: 2.513800423355263

Epoch: 6| Step: 4
Training loss: 1.6775103986847033
Validation loss: 2.5047661965473447

Epoch: 6| Step: 5
Training loss: 2.132403994833103
Validation loss: 2.503210517606729

Epoch: 6| Step: 6
Training loss: 1.9152888514944197
Validation loss: 2.509494981632914

Epoch: 6| Step: 7
Training loss: 2.0881057499966196
Validation loss: 2.519203610272898

Epoch: 6| Step: 8
Training loss: 2.274295395948967
Validation loss: 2.5033630162683345

Epoch: 6| Step: 9
Training loss: 2.822316986989383
Validation loss: 2.523275206772772

Epoch: 6| Step: 10
Training loss: 2.3870252047271996
Validation loss: 2.5276054077858077

Epoch: 6| Step: 11
Training loss: 2.16270608085405
Validation loss: 2.5540273048586264

Epoch: 6| Step: 12
Training loss: 2.4370976629524534
Validation loss: 2.5545193055884914

Epoch: 6| Step: 13
Training loss: 1.8598249516101546
Validation loss: 2.5573059102352556

Epoch: 226| Step: 0
Training loss: 2.4227973412224393
Validation loss: 2.572470411347367

Epoch: 6| Step: 1
Training loss: 2.1830900153746002
Validation loss: 2.563980496722676

Epoch: 6| Step: 2
Training loss: 2.592669526225199
Validation loss: 2.584912822195367

Epoch: 6| Step: 3
Training loss: 2.9766656652479493
Validation loss: 2.5607437069774686

Epoch: 6| Step: 4
Training loss: 2.339689373852731
Validation loss: 2.581206020075999

Epoch: 6| Step: 5
Training loss: 2.0351368030050954
Validation loss: 2.541271270160066

Epoch: 6| Step: 6
Training loss: 2.9634519182413803
Validation loss: 2.5333415836484314

Epoch: 6| Step: 7
Training loss: 1.624728767060232
Validation loss: 2.5220932977507804

Epoch: 6| Step: 8
Training loss: 1.6860413781832055
Validation loss: 2.515974158782546

Epoch: 6| Step: 9
Training loss: 2.294643745613032
Validation loss: 2.516200882289687

Epoch: 6| Step: 10
Training loss: 2.169561017896472
Validation loss: 2.5321225989542944

Epoch: 6| Step: 11
Training loss: 2.197856691334658
Validation loss: 2.5432884534906566

Epoch: 6| Step: 12
Training loss: 1.6106982670477743
Validation loss: 2.5327230021537357

Epoch: 6| Step: 13
Training loss: 2.3770383821116012
Validation loss: 2.5345184276179564

Epoch: 227| Step: 0
Training loss: 1.9935894988219698
Validation loss: 2.5583002829720796

Epoch: 6| Step: 1
Training loss: 2.4435042743118585
Validation loss: 2.5655664069438786

Epoch: 6| Step: 2
Training loss: 2.5569105829053522
Validation loss: 2.5633475910016785

Epoch: 6| Step: 3
Training loss: 2.5034123973661675
Validation loss: 2.556984058740698

Epoch: 6| Step: 4
Training loss: 2.1389434224012094
Validation loss: 2.546775644310748

Epoch: 6| Step: 5
Training loss: 2.3223267106860246
Validation loss: 2.5426080450846045

Epoch: 6| Step: 6
Training loss: 2.838278568685511
Validation loss: 2.5374500965040743

Epoch: 6| Step: 7
Training loss: 1.6559076495196805
Validation loss: 2.5278381147158546

Epoch: 6| Step: 8
Training loss: 1.6158412176251018
Validation loss: 2.543230956388978

Epoch: 6| Step: 9
Training loss: 2.598464633527013
Validation loss: 2.5387472181932593

Epoch: 6| Step: 10
Training loss: 2.6384850131605546
Validation loss: 2.5564255707752523

Epoch: 6| Step: 11
Training loss: 1.7011342444128383
Validation loss: 2.5515321304996346

Epoch: 6| Step: 12
Training loss: 2.626145430838432
Validation loss: 2.568857695339908

Epoch: 6| Step: 13
Training loss: 1.799881782888267
Validation loss: 2.565380137100185

Epoch: 228| Step: 0
Training loss: 1.9860945932847034
Validation loss: 2.612584574789077

Epoch: 6| Step: 1
Training loss: 2.529500662941364
Validation loss: 2.5845497610406594

Epoch: 6| Step: 2
Training loss: 2.0372711146692106
Validation loss: 2.6165219196043163

Epoch: 6| Step: 3
Training loss: 2.1893847384223983
Validation loss: 2.5978552108711117

Epoch: 6| Step: 4
Training loss: 2.0623512214405655
Validation loss: 2.6065914817692533

Epoch: 6| Step: 5
Training loss: 1.8486611857304909
Validation loss: 2.574138850437123

Epoch: 6| Step: 6
Training loss: 1.4861356232108063
Validation loss: 2.5942782358215712

Epoch: 6| Step: 7
Training loss: 2.5784101848660343
Validation loss: 2.567557569698432

Epoch: 6| Step: 8
Training loss: 2.8492368646814135
Validation loss: 2.5597571448279703

Epoch: 6| Step: 9
Training loss: 3.3402500552381635
Validation loss: 2.5481541235735214

Epoch: 6| Step: 10
Training loss: 1.982803503426417
Validation loss: 2.539428778418564

Epoch: 6| Step: 11
Training loss: 1.9961588451424108
Validation loss: 2.528030640201146

Epoch: 6| Step: 12
Training loss: 2.6033544469051275
Validation loss: 2.5427738081771643

Epoch: 6| Step: 13
Training loss: 1.725663309138358
Validation loss: 2.5367465054617124

Epoch: 229| Step: 0
Training loss: 2.6839590476446533
Validation loss: 2.520049317397071

Epoch: 6| Step: 1
Training loss: 2.9157631337438246
Validation loss: 2.5446578908936694

Epoch: 6| Step: 2
Training loss: 2.3762006234582937
Validation loss: 2.5372818087272435

Epoch: 6| Step: 3
Training loss: 1.980429082770432
Validation loss: 2.546591854153314

Epoch: 6| Step: 4
Training loss: 1.9681545749839553
Validation loss: 2.5403809083342037

Epoch: 6| Step: 5
Training loss: 1.8755319476537642
Validation loss: 2.533979788499138

Epoch: 6| Step: 6
Training loss: 2.285321299795357
Validation loss: 2.530328001854522

Epoch: 6| Step: 7
Training loss: 2.602409247905718
Validation loss: 2.5468532818763427

Epoch: 6| Step: 8
Training loss: 2.193414376606126
Validation loss: 2.5506710166927293

Epoch: 6| Step: 9
Training loss: 1.8555865119907655
Validation loss: 2.54864655648188

Epoch: 6| Step: 10
Training loss: 2.45570713868009
Validation loss: 2.545162155428977

Epoch: 6| Step: 11
Training loss: 2.1620262288523713
Validation loss: 2.546085008916592

Epoch: 6| Step: 12
Training loss: 2.263418135685915
Validation loss: 2.5336385062098605

Epoch: 6| Step: 13
Training loss: 1.8575569047592984
Validation loss: 2.557649969313506

Epoch: 230| Step: 0
Training loss: 1.682364667916707
Validation loss: 2.568327410635616

Epoch: 6| Step: 1
Training loss: 2.2191834362206726
Validation loss: 2.5772412259193684

Epoch: 6| Step: 2
Training loss: 2.6213547964617656
Validation loss: 2.570706431030194

Epoch: 6| Step: 3
Training loss: 2.6402067496520427
Validation loss: 2.5631785075982036

Epoch: 6| Step: 4
Training loss: 1.6824285099207819
Validation loss: 2.5773214147485897

Epoch: 6| Step: 5
Training loss: 1.8100346866466437
Validation loss: 2.572150519172432

Epoch: 6| Step: 6
Training loss: 2.5178187501679923
Validation loss: 2.5784412690962952

Epoch: 6| Step: 7
Training loss: 2.407418796995994
Validation loss: 2.5586275132453435

Epoch: 6| Step: 8
Training loss: 1.8446771908923882
Validation loss: 2.5597672971870096

Epoch: 6| Step: 9
Training loss: 1.9643694872146138
Validation loss: 2.573955038066768

Epoch: 6| Step: 10
Training loss: 3.18843184669066
Validation loss: 2.566136749067745

Epoch: 6| Step: 11
Training loss: 2.419992318101781
Validation loss: 2.563471044140886

Epoch: 6| Step: 12
Training loss: 2.1065768296767757
Validation loss: 2.5767519290367

Epoch: 6| Step: 13
Training loss: 1.9269837499783604
Validation loss: 2.5599666416210116

Epoch: 231| Step: 0
Training loss: 1.7777803324972445
Validation loss: 2.5710633793747526

Epoch: 6| Step: 1
Training loss: 2.364223727359112
Validation loss: 2.560680813636159

Epoch: 6| Step: 2
Training loss: 1.6028142735766533
Validation loss: 2.5602326014765397

Epoch: 6| Step: 3
Training loss: 2.7287915581104296
Validation loss: 2.5595179628493403

Epoch: 6| Step: 4
Training loss: 2.289053125980699
Validation loss: 2.5336687752681

Epoch: 6| Step: 5
Training loss: 2.4024775273981898
Validation loss: 2.52624448506041

Epoch: 6| Step: 6
Training loss: 1.587192658838284
Validation loss: 2.5245435591735212

Epoch: 6| Step: 7
Training loss: 3.046287753904717
Validation loss: 2.525293319334113

Epoch: 6| Step: 8
Training loss: 1.8413285987999386
Validation loss: 2.5226866054667685

Epoch: 6| Step: 9
Training loss: 1.9173141574448938
Validation loss: 2.542637238426055

Epoch: 6| Step: 10
Training loss: 2.2087730353837576
Validation loss: 2.5464756814467213

Epoch: 6| Step: 11
Training loss: 2.3742499924035427
Validation loss: 2.543507461794869

Epoch: 6| Step: 12
Training loss: 2.443215345350238
Validation loss: 2.571088385849253

Epoch: 6| Step: 13
Training loss: 2.5616535556567723
Validation loss: 2.6028886685474393

Epoch: 232| Step: 0
Training loss: 2.169003791140967
Validation loss: 2.6170940173709987

Epoch: 6| Step: 1
Training loss: 2.6261514227412737
Validation loss: 2.6912952062457314

Epoch: 6| Step: 2
Training loss: 2.1862765569366207
Validation loss: 2.7051920402035217

Epoch: 6| Step: 3
Training loss: 2.2451456473837745
Validation loss: 2.664103055553928

Epoch: 6| Step: 4
Training loss: 3.1416964245372587
Validation loss: 2.600049064552307

Epoch: 6| Step: 5
Training loss: 2.091423450124219
Validation loss: 2.5795343727522546

Epoch: 6| Step: 6
Training loss: 2.554260124832402
Validation loss: 2.5646881902244534

Epoch: 6| Step: 7
Training loss: 1.8625423477786154
Validation loss: 2.5705750397980105

Epoch: 6| Step: 8
Training loss: 1.8364611589046154
Validation loss: 2.5451671124035906

Epoch: 6| Step: 9
Training loss: 1.9999030208917137
Validation loss: 2.5150023137935764

Epoch: 6| Step: 10
Training loss: 1.9934571054023464
Validation loss: 2.5256812923344065

Epoch: 6| Step: 11
Training loss: 2.643100638936934
Validation loss: 2.5315624405294606

Epoch: 6| Step: 12
Training loss: 1.9726911787207808
Validation loss: 2.533341238570009

Epoch: 6| Step: 13
Training loss: 2.468009451361169
Validation loss: 2.53496913287941

Epoch: 233| Step: 0
Training loss: 1.8457937389917773
Validation loss: 2.547871509774629

Epoch: 6| Step: 1
Training loss: 2.1840946394148992
Validation loss: 2.5539497220087406

Epoch: 6| Step: 2
Training loss: 1.834679615001859
Validation loss: 2.5726815140687775

Epoch: 6| Step: 3
Training loss: 2.819284352067471
Validation loss: 2.57795169132211

Epoch: 6| Step: 4
Training loss: 2.6726203458861546
Validation loss: 2.6027577110945517

Epoch: 6| Step: 5
Training loss: 1.9374619141803888
Validation loss: 2.6064919631573598

Epoch: 6| Step: 6
Training loss: 2.1376731177825086
Validation loss: 2.625997913747144

Epoch: 6| Step: 7
Training loss: 1.687737977943553
Validation loss: 2.6806920710792963

Epoch: 6| Step: 8
Training loss: 2.1942724839234558
Validation loss: 2.681890977479862

Epoch: 6| Step: 9
Training loss: 2.106957074119598
Validation loss: 2.618338442853495

Epoch: 6| Step: 10
Training loss: 2.0705295664876324
Validation loss: 2.611999790545071

Epoch: 6| Step: 11
Training loss: 2.790146219120472
Validation loss: 2.592261074709007

Epoch: 6| Step: 12
Training loss: 3.000960037478908
Validation loss: 2.5742849863394177

Epoch: 6| Step: 13
Training loss: 1.6369645473577095
Validation loss: 2.560685732810816

Epoch: 234| Step: 0
Training loss: 2.1775933600644715
Validation loss: 2.5632880014975723

Epoch: 6| Step: 1
Training loss: 2.2914083393034073
Validation loss: 2.5505609188366427

Epoch: 6| Step: 2
Training loss: 1.6845778136155458
Validation loss: 2.543312420648646

Epoch: 6| Step: 3
Training loss: 2.6359488712556205
Validation loss: 2.528791984527622

Epoch: 6| Step: 4
Training loss: 1.7420336736671969
Validation loss: 2.55711456327827

Epoch: 6| Step: 5
Training loss: 3.293595839191706
Validation loss: 2.5915547621712016

Epoch: 6| Step: 6
Training loss: 1.5489962127028503
Validation loss: 2.59045407567699

Epoch: 6| Step: 7
Training loss: 2.258023050911949
Validation loss: 2.604760984632486

Epoch: 6| Step: 8
Training loss: 1.8035936880289316
Validation loss: 2.586905936754847

Epoch: 6| Step: 9
Training loss: 1.904495056794898
Validation loss: 2.583825438809506

Epoch: 6| Step: 10
Training loss: 1.9918512397165302
Validation loss: 2.5592503294896574

Epoch: 6| Step: 11
Training loss: 2.5387154209894285
Validation loss: 2.5715273273328094

Epoch: 6| Step: 12
Training loss: 2.5036887611521776
Validation loss: 2.5857497163416086

Epoch: 6| Step: 13
Training loss: 2.375673098299282
Validation loss: 2.5845226708459217

Epoch: 235| Step: 0
Training loss: 2.594518984128404
Validation loss: 2.6301152480369643

Epoch: 6| Step: 1
Training loss: 2.447202591872051
Validation loss: 2.6291203782429666

Epoch: 6| Step: 2
Training loss: 2.3498609095865817
Validation loss: 2.618262666986637

Epoch: 6| Step: 3
Training loss: 2.4727261549964967
Validation loss: 2.5779558993282303

Epoch: 6| Step: 4
Training loss: 2.355396883296791
Validation loss: 2.5495597247344883

Epoch: 6| Step: 5
Training loss: 2.3715605676884155
Validation loss: 2.533001093870605

Epoch: 6| Step: 6
Training loss: 2.3779665840310007
Validation loss: 2.5171717909439764

Epoch: 6| Step: 7
Training loss: 2.3057927988798053
Validation loss: 2.5041956821057614

Epoch: 6| Step: 8
Training loss: 2.270611556769638
Validation loss: 2.512398461208511

Epoch: 6| Step: 9
Training loss: 2.1884072738362024
Validation loss: 2.5276708533713386

Epoch: 6| Step: 10
Training loss: 1.7532654677094541
Validation loss: 2.5104680880481216

Epoch: 6| Step: 11
Training loss: 2.650444867922041
Validation loss: 2.5297815906602854

Epoch: 6| Step: 12
Training loss: 2.127689678912547
Validation loss: 2.5282330685195737

Epoch: 6| Step: 13
Training loss: 2.2892272681607055
Validation loss: 2.5389653426924186

Epoch: 236| Step: 0
Training loss: 1.823757007002361
Validation loss: 2.5542931675245977

Epoch: 6| Step: 1
Training loss: 3.0256821927167503
Validation loss: 2.5814624800525747

Epoch: 6| Step: 2
Training loss: 2.13869450526697
Validation loss: 2.597294924280028

Epoch: 6| Step: 3
Training loss: 1.8528690154897651
Validation loss: 2.6354556225296144

Epoch: 6| Step: 4
Training loss: 1.5730657022702699
Validation loss: 2.659540449614784

Epoch: 6| Step: 5
Training loss: 2.4478763874608895
Validation loss: 2.6531910355268735

Epoch: 6| Step: 6
Training loss: 2.3359019809433774
Validation loss: 2.6543663826085417

Epoch: 6| Step: 7
Training loss: 2.512379892998988
Validation loss: 2.652174062642777

Epoch: 6| Step: 8
Training loss: 2.2304443785610286
Validation loss: 2.614078022024734

Epoch: 6| Step: 9
Training loss: 2.129479791219766
Validation loss: 2.5681381536440737

Epoch: 6| Step: 10
Training loss: 2.32195267682148
Validation loss: 2.5449231709623126

Epoch: 6| Step: 11
Training loss: 2.855546900649093
Validation loss: 2.5307236583393573

Epoch: 6| Step: 12
Training loss: 1.9225204748444915
Validation loss: 2.512062875796515

Epoch: 6| Step: 13
Training loss: 2.5054301416832074
Validation loss: 2.5127537613441007

Epoch: 237| Step: 0
Training loss: 1.9045385588820922
Validation loss: 2.520405919644947

Epoch: 6| Step: 1
Training loss: 2.631770892923036
Validation loss: 2.5175930404517195

Epoch: 6| Step: 2
Training loss: 1.9422050690105646
Validation loss: 2.5464386673502144

Epoch: 6| Step: 3
Training loss: 1.8623619770905893
Validation loss: 2.56551961616546

Epoch: 6| Step: 4
Training loss: 2.0449915949641753
Validation loss: 2.590757520451303

Epoch: 6| Step: 5
Training loss: 1.9825044962385838
Validation loss: 2.627513295402245

Epoch: 6| Step: 6
Training loss: 2.4111580273780278
Validation loss: 2.6176359029743543

Epoch: 6| Step: 7
Training loss: 3.361742046256864
Validation loss: 2.653647909765707

Epoch: 6| Step: 8
Training loss: 2.264320892689908
Validation loss: 2.644298518809009

Epoch: 6| Step: 9
Training loss: 2.225482129784792
Validation loss: 2.5903886132707497

Epoch: 6| Step: 10
Training loss: 2.143797034812519
Validation loss: 2.562054835783633

Epoch: 6| Step: 11
Training loss: 1.9013643034534495
Validation loss: 2.5433499801994213

Epoch: 6| Step: 12
Training loss: 1.9535149757156864
Validation loss: 2.534626267125086

Epoch: 6| Step: 13
Training loss: 2.5397944407750015
Validation loss: 2.5447275044090603

Epoch: 238| Step: 0
Training loss: 2.347120176225126
Validation loss: 2.5388568970992367

Epoch: 6| Step: 1
Training loss: 2.442273478785335
Validation loss: 2.53297658989238

Epoch: 6| Step: 2
Training loss: 2.5240203845595945
Validation loss: 2.5424858920075715

Epoch: 6| Step: 3
Training loss: 2.529437888202325
Validation loss: 2.572271232627833

Epoch: 6| Step: 4
Training loss: 2.7181973827458084
Validation loss: 2.582367567819368

Epoch: 6| Step: 5
Training loss: 1.6726739703419702
Validation loss: 2.5925709139457465

Epoch: 6| Step: 6
Training loss: 2.405688926380602
Validation loss: 2.631591559053618

Epoch: 6| Step: 7
Training loss: 1.6732446639567073
Validation loss: 2.6213736387050424

Epoch: 6| Step: 8
Training loss: 2.4915811883389867
Validation loss: 2.6065746211933396

Epoch: 6| Step: 9
Training loss: 1.8474766198357813
Validation loss: 2.6179863768549274

Epoch: 6| Step: 10
Training loss: 2.446789962440645
Validation loss: 2.5973651464737917

Epoch: 6| Step: 11
Training loss: 1.3331201303413682
Validation loss: 2.614329357400841

Epoch: 6| Step: 12
Training loss: 2.3875922619633374
Validation loss: 2.580233934747992

Epoch: 6| Step: 13
Training loss: 1.8240812523462688
Validation loss: 2.6183667311388876

Epoch: 239| Step: 0
Training loss: 1.874834561996652
Validation loss: 2.607927541479022

Epoch: 6| Step: 1
Training loss: 2.26167869202976
Validation loss: 2.621090035736742

Epoch: 6| Step: 2
Training loss: 2.4003631118426787
Validation loss: 2.581423258412435

Epoch: 6| Step: 3
Training loss: 1.6855194337098502
Validation loss: 2.63613719413653

Epoch: 6| Step: 4
Training loss: 2.1982902341969925
Validation loss: 2.618096295373404

Epoch: 6| Step: 5
Training loss: 2.162997538049772
Validation loss: 2.619512923612957

Epoch: 6| Step: 6
Training loss: 3.1358343376369593
Validation loss: 2.594845322205168

Epoch: 6| Step: 7
Training loss: 2.112144855690172
Validation loss: 2.601003500877761

Epoch: 6| Step: 8
Training loss: 1.8875037035368907
Validation loss: 2.611182281750672

Epoch: 6| Step: 9
Training loss: 2.104469755898433
Validation loss: 2.5840404117089366

Epoch: 6| Step: 10
Training loss: 2.7318651287918994
Validation loss: 2.583336081554633

Epoch: 6| Step: 11
Training loss: 2.489496099201984
Validation loss: 2.5794372686768807

Epoch: 6| Step: 12
Training loss: 1.4507783379266177
Validation loss: 2.6154065197750898

Epoch: 6| Step: 13
Training loss: 1.8870755760531501
Validation loss: 2.64605940706492

Epoch: 240| Step: 0
Training loss: 2.525816183087572
Validation loss: 2.6832873573471403

Epoch: 6| Step: 1
Training loss: 2.7249994470438264
Validation loss: 2.6864434168740345

Epoch: 6| Step: 2
Training loss: 2.5796281536260657
Validation loss: 2.746658708420431

Epoch: 6| Step: 3
Training loss: 1.818648072627784
Validation loss: 2.743174970149527

Epoch: 6| Step: 4
Training loss: 1.9640449128619155
Validation loss: 2.714559489858102

Epoch: 6| Step: 5
Training loss: 2.245065576491926
Validation loss: 2.6711940009067185

Epoch: 6| Step: 6
Training loss: 1.390550632845719
Validation loss: 2.6094565616736287

Epoch: 6| Step: 7
Training loss: 2.931383623603446
Validation loss: 2.5486244402844958

Epoch: 6| Step: 8
Training loss: 1.939740085789354
Validation loss: 2.5334126217463915

Epoch: 6| Step: 9
Training loss: 2.3545810931083766
Validation loss: 2.5124176302893693

Epoch: 6| Step: 10
Training loss: 1.9266028208972226
Validation loss: 2.5121561305379534

Epoch: 6| Step: 11
Training loss: 2.4534236458899956
Validation loss: 2.4922651480095355

Epoch: 6| Step: 12
Training loss: 2.795333011012472
Validation loss: 2.5127814671393773

Epoch: 6| Step: 13
Training loss: 2.5110501219602006
Validation loss: 2.498054160395048

Epoch: 241| Step: 0
Training loss: 1.5105839691461003
Validation loss: 2.5101067653811993

Epoch: 6| Step: 1
Training loss: 2.1503610219139135
Validation loss: 2.4967927227699724

Epoch: 6| Step: 2
Training loss: 2.3818907909325313
Validation loss: 2.5168173039639545

Epoch: 6| Step: 3
Training loss: 2.7228503821627434
Validation loss: 2.5186548882409796

Epoch: 6| Step: 4
Training loss: 2.748556191558229
Validation loss: 2.5319710477667243

Epoch: 6| Step: 5
Training loss: 2.1625145840015247
Validation loss: 2.533786899553279

Epoch: 6| Step: 6
Training loss: 1.6887893695887048
Validation loss: 2.5275625048718253

Epoch: 6| Step: 7
Training loss: 2.307597350343217
Validation loss: 2.5253854639915683

Epoch: 6| Step: 8
Training loss: 1.6798946519019125
Validation loss: 2.5224959247607863

Epoch: 6| Step: 9
Training loss: 2.9253434590894956
Validation loss: 2.5377109001473843

Epoch: 6| Step: 10
Training loss: 2.635821877992453
Validation loss: 2.529762670960297

Epoch: 6| Step: 11
Training loss: 2.2082895118636023
Validation loss: 2.5406504824878713

Epoch: 6| Step: 12
Training loss: 2.2138101093353315
Validation loss: 2.524219025801062

Epoch: 6| Step: 13
Training loss: 1.928824042371902
Validation loss: 2.5440803282109576

Epoch: 242| Step: 0
Training loss: 1.942514513862422
Validation loss: 2.552607756210467

Epoch: 6| Step: 1
Training loss: 2.4076758779770033
Validation loss: 2.572900607307344

Epoch: 6| Step: 2
Training loss: 1.501960744454015
Validation loss: 2.559194076036873

Epoch: 6| Step: 3
Training loss: 2.357524423968272
Validation loss: 2.5714825688853695

Epoch: 6| Step: 4
Training loss: 2.214598411683373
Validation loss: 2.541505266495193

Epoch: 6| Step: 5
Training loss: 1.976416058449281
Validation loss: 2.553645801382099

Epoch: 6| Step: 6
Training loss: 2.4714024454967713
Validation loss: 2.526694401569515

Epoch: 6| Step: 7
Training loss: 3.223582667504185
Validation loss: 2.551447222056713

Epoch: 6| Step: 8
Training loss: 2.8245029754920123
Validation loss: 2.5424662463192886

Epoch: 6| Step: 9
Training loss: 2.4851854070196016
Validation loss: 2.5703879889289416

Epoch: 6| Step: 10
Training loss: 1.2877996558937623
Validation loss: 2.6111636551063535

Epoch: 6| Step: 11
Training loss: 2.2577086956092756
Validation loss: 2.6770411882657816

Epoch: 6| Step: 12
Training loss: 1.9924927720689043
Validation loss: 2.6963132023378362

Epoch: 6| Step: 13
Training loss: 1.6397244116043868
Validation loss: 2.69802164489664

Epoch: 243| Step: 0
Training loss: 1.7028136362459505
Validation loss: 2.7425043225551353

Epoch: 6| Step: 1
Training loss: 2.2731142633586785
Validation loss: 2.678887117038863

Epoch: 6| Step: 2
Training loss: 1.452940160008761
Validation loss: 2.6380768318421106

Epoch: 6| Step: 3
Training loss: 1.3651187613108648
Validation loss: 2.670822873345502

Epoch: 6| Step: 4
Training loss: 2.70403525841879
Validation loss: 2.634182446231502

Epoch: 6| Step: 5
Training loss: 1.9682342216976596
Validation loss: 2.5952472118944168

Epoch: 6| Step: 6
Training loss: 1.9626232667345218
Validation loss: 2.5705513113713376

Epoch: 6| Step: 7
Training loss: 2.6801275220109813
Validation loss: 2.568146833901186

Epoch: 6| Step: 8
Training loss: 3.2264049574696854
Validation loss: 2.5803219691789594

Epoch: 6| Step: 9
Training loss: 2.5347346115390144
Validation loss: 2.606089886352327

Epoch: 6| Step: 10
Training loss: 1.7041948090757946
Validation loss: 2.605214866763198

Epoch: 6| Step: 11
Training loss: 2.4326889290906504
Validation loss: 2.5901919629970007

Epoch: 6| Step: 12
Training loss: 2.3319280911477387
Validation loss: 2.588493505345843

Epoch: 6| Step: 13
Training loss: 1.9219999195221915
Validation loss: 2.561245510407052

Epoch: 244| Step: 0
Training loss: 2.418965813523339
Validation loss: 2.5612008127578525

Epoch: 6| Step: 1
Training loss: 1.8953752348502892
Validation loss: 2.566890475394678

Epoch: 6| Step: 2
Training loss: 1.9455472505783014
Validation loss: 2.580521319526897

Epoch: 6| Step: 3
Training loss: 2.872365656832837
Validation loss: 2.5499757796739217

Epoch: 6| Step: 4
Training loss: 2.35594018169169
Validation loss: 2.5607894212272484

Epoch: 6| Step: 5
Training loss: 2.8255152173433293
Validation loss: 2.580002280426496

Epoch: 6| Step: 6
Training loss: 2.7701188124642697
Validation loss: 2.6015037400155667

Epoch: 6| Step: 7
Training loss: 2.0614040815460104
Validation loss: 2.6419600774071896

Epoch: 6| Step: 8
Training loss: 2.291926340360853
Validation loss: 2.609023323649828

Epoch: 6| Step: 9
Training loss: 2.262156179026573
Validation loss: 2.59651581246042

Epoch: 6| Step: 10
Training loss: 2.1012560539453404
Validation loss: 2.565930404173205

Epoch: 6| Step: 11
Training loss: 1.5765245839484856
Validation loss: 2.5691575505922595

Epoch: 6| Step: 12
Training loss: 1.769661399652879
Validation loss: 2.5489921741138484

Epoch: 6| Step: 13
Training loss: 1.7663420849854639
Validation loss: 2.5392449416124943

Epoch: 245| Step: 0
Training loss: 2.3668217643994267
Validation loss: 2.5401785251375757

Epoch: 6| Step: 1
Training loss: 2.185362943625963
Validation loss: 2.545899288136865

Epoch: 6| Step: 2
Training loss: 2.4128454405778226
Validation loss: 2.591436986364298

Epoch: 6| Step: 3
Training loss: 1.667032018989016
Validation loss: 2.6074600350281893

Epoch: 6| Step: 4
Training loss: 2.544288866857043
Validation loss: 2.6666871209154865

Epoch: 6| Step: 5
Training loss: 2.639696759378969
Validation loss: 2.6503792155541928

Epoch: 6| Step: 6
Training loss: 2.5496893001586978
Validation loss: 2.6222953941306804

Epoch: 6| Step: 7
Training loss: 1.762089793849722
Validation loss: 2.599856217088865

Epoch: 6| Step: 8
Training loss: 1.5252455716884012
Validation loss: 2.577727608927883

Epoch: 6| Step: 9
Training loss: 2.3945400119639855
Validation loss: 2.5605892252578095

Epoch: 6| Step: 10
Training loss: 2.1930208564876317
Validation loss: 2.5407088043417483

Epoch: 6| Step: 11
Training loss: 2.035149103836722
Validation loss: 2.537816435402929

Epoch: 6| Step: 12
Training loss: 2.59231601279255
Validation loss: 2.533331811636752

Epoch: 6| Step: 13
Training loss: 2.1794201539954616
Validation loss: 2.5343844860822866

Epoch: 246| Step: 0
Training loss: 1.7952406375005003
Validation loss: 2.544491016826088

Epoch: 6| Step: 1
Training loss: 2.0364861710020565
Validation loss: 2.556621810808889

Epoch: 6| Step: 2
Training loss: 2.473500859309954
Validation loss: 2.5835364220888475

Epoch: 6| Step: 3
Training loss: 1.9570528131998801
Validation loss: 2.5487710490845688

Epoch: 6| Step: 4
Training loss: 2.4387373106923067
Validation loss: 2.5698060345463896

Epoch: 6| Step: 5
Training loss: 2.098338096235514
Validation loss: 2.599567614572698

Epoch: 6| Step: 6
Training loss: 1.8418744779805458
Validation loss: 2.5992785443192217

Epoch: 6| Step: 7
Training loss: 2.396542474591162
Validation loss: 2.585703183225317

Epoch: 6| Step: 8
Training loss: 2.738326264146103
Validation loss: 2.6010482631157177

Epoch: 6| Step: 9
Training loss: 2.2281057263325867
Validation loss: 2.5754806674850568

Epoch: 6| Step: 10
Training loss: 1.5145716201909991
Validation loss: 2.593335543691221

Epoch: 6| Step: 11
Training loss: 2.651464662112462
Validation loss: 2.594627660843675

Epoch: 6| Step: 12
Training loss: 1.8647230156376653
Validation loss: 2.5783461813019914

Epoch: 6| Step: 13
Training loss: 2.362004513728959
Validation loss: 2.5749060909961425

Epoch: 247| Step: 0
Training loss: 1.7273619859165028
Validation loss: 2.5699191811887583

Epoch: 6| Step: 1
Training loss: 2.0852648618502596
Validation loss: 2.5704792900040174

Epoch: 6| Step: 2
Training loss: 1.9620388631208936
Validation loss: 2.56865099664313

Epoch: 6| Step: 3
Training loss: 2.347947088369999
Validation loss: 2.5803617542431176

Epoch: 6| Step: 4
Training loss: 2.0774474222482286
Validation loss: 2.5787406340475356

Epoch: 6| Step: 5
Training loss: 2.1697598044012074
Validation loss: 2.5846822098628777

Epoch: 6| Step: 6
Training loss: 1.6128690252985
Validation loss: 2.6065622577180054

Epoch: 6| Step: 7
Training loss: 2.295202983115788
Validation loss: 2.6063253432985376

Epoch: 6| Step: 8
Training loss: 2.261435377325718
Validation loss: 2.6264342824974922

Epoch: 6| Step: 9
Training loss: 2.457127507057275
Validation loss: 2.6196573626230912

Epoch: 6| Step: 10
Training loss: 2.916690572004899
Validation loss: 2.6453608644213524

Epoch: 6| Step: 11
Training loss: 2.40108371347502
Validation loss: 2.6558274924153484

Epoch: 6| Step: 12
Training loss: 1.7698191562229297
Validation loss: 2.656643445664524

Epoch: 6| Step: 13
Training loss: 2.3062835856320785
Validation loss: 2.643165975983553

Epoch: 248| Step: 0
Training loss: 2.0883427728965795
Validation loss: 2.6503218827203168

Epoch: 6| Step: 1
Training loss: 2.1697943072242682
Validation loss: 2.624736008160842

Epoch: 6| Step: 2
Training loss: 2.8056963537995556
Validation loss: 2.6289809557884083

Epoch: 6| Step: 3
Training loss: 1.3647838280226123
Validation loss: 2.6201030073470566

Epoch: 6| Step: 4
Training loss: 1.9203073574459786
Validation loss: 2.6588005835165065

Epoch: 6| Step: 5
Training loss: 2.701370110619487
Validation loss: 2.6301072859789354

Epoch: 6| Step: 6
Training loss: 2.6192441232871495
Validation loss: 2.6230088205386766

Epoch: 6| Step: 7
Training loss: 1.6807849935837635
Validation loss: 2.5662308182505047

Epoch: 6| Step: 8
Training loss: 2.0892708536814286
Validation loss: 2.54121610420915

Epoch: 6| Step: 9
Training loss: 2.7940481380993343
Validation loss: 2.5524592894702303

Epoch: 6| Step: 10
Training loss: 2.4193261300711444
Validation loss: 2.539164677055672

Epoch: 6| Step: 11
Training loss: 1.9922958045391814
Validation loss: 2.5607385551506985

Epoch: 6| Step: 12
Training loss: 1.9248149064488056
Validation loss: 2.5367468735733985

Epoch: 6| Step: 13
Training loss: 1.6442290184674055
Validation loss: 2.544954695432633

Epoch: 249| Step: 0
Training loss: 2.4464316442667227
Validation loss: 2.563128479591903

Epoch: 6| Step: 1
Training loss: 2.0886770253700293
Validation loss: 2.5917307642362735

Epoch: 6| Step: 2
Training loss: 2.178282472891834
Validation loss: 2.6402398078668035

Epoch: 6| Step: 3
Training loss: 2.078255556064036
Validation loss: 2.6645585807344543

Epoch: 6| Step: 4
Training loss: 1.930793723121431
Validation loss: 2.6629111747066294

Epoch: 6| Step: 5
Training loss: 2.844675605126335
Validation loss: 2.749948428855299

Epoch: 6| Step: 6
Training loss: 1.256917125388629
Validation loss: 2.749729461078069

Epoch: 6| Step: 7
Training loss: 2.1886715612729564
Validation loss: 2.7183184664904627

Epoch: 6| Step: 8
Training loss: 2.2452464222061335
Validation loss: 2.7131923858328406

Epoch: 6| Step: 9
Training loss: 2.0884044218433373
Validation loss: 2.658774518879026

Epoch: 6| Step: 10
Training loss: 1.795237450155663
Validation loss: 2.5792028004503704

Epoch: 6| Step: 11
Training loss: 2.929038665130772
Validation loss: 2.5545694088643205

Epoch: 6| Step: 12
Training loss: 1.8964886493418618
Validation loss: 2.516140539444982

Epoch: 6| Step: 13
Training loss: 2.7719647002731738
Validation loss: 2.5097728130470185

Epoch: 250| Step: 0
Training loss: 1.8043030168255771
Validation loss: 2.519632626251041

Epoch: 6| Step: 1
Training loss: 1.995497224362784
Validation loss: 2.5136413493324645

Epoch: 6| Step: 2
Training loss: 1.7478733765155963
Validation loss: 2.5202483346981075

Epoch: 6| Step: 3
Training loss: 1.968960523702681
Validation loss: 2.522530982423018

Epoch: 6| Step: 4
Training loss: 2.8539442175243583
Validation loss: 2.52238121010097

Epoch: 6| Step: 5
Training loss: 2.2591745037007183
Validation loss: 2.533793643073068

Epoch: 6| Step: 6
Training loss: 3.077413253987093
Validation loss: 2.5308530362789683

Epoch: 6| Step: 7
Training loss: 2.0690270229767087
Validation loss: 2.5756828378010344

Epoch: 6| Step: 8
Training loss: 1.8377922915544544
Validation loss: 2.6024538790829914

Epoch: 6| Step: 9
Training loss: 2.396037836607161
Validation loss: 2.6560584952939146

Epoch: 6| Step: 10
Training loss: 2.107224109551705
Validation loss: 2.6600925402450644

Epoch: 6| Step: 11
Training loss: 1.8925960764314078
Validation loss: 2.6828336643398027

Epoch: 6| Step: 12
Training loss: 2.205272628815114
Validation loss: 2.6347275286522582

Epoch: 6| Step: 13
Training loss: 3.3932038094233534
Validation loss: 2.633654526746946

Epoch: 251| Step: 0
Training loss: 1.610464079415131
Validation loss: 2.5888994815193134

Epoch: 6| Step: 1
Training loss: 1.9126075664513802
Validation loss: 2.5928802717268953

Epoch: 6| Step: 2
Training loss: 2.8926188422923382
Validation loss: 2.5745084886053493

Epoch: 6| Step: 3
Training loss: 2.1286491028757717
Validation loss: 2.5622596395391066

Epoch: 6| Step: 4
Training loss: 2.0565355931602687
Validation loss: 2.5412150252712995

Epoch: 6| Step: 5
Training loss: 2.4972703336673994
Validation loss: 2.5360177588949133

Epoch: 6| Step: 6
Training loss: 2.5621393461665596
Validation loss: 2.5288674401169056

Epoch: 6| Step: 7
Training loss: 2.0517596717328557
Validation loss: 2.552154311665774

Epoch: 6| Step: 8
Training loss: 2.3131236704523883
Validation loss: 2.554423840650632

Epoch: 6| Step: 9
Training loss: 2.3498469079655475
Validation loss: 2.5800211089401777

Epoch: 6| Step: 10
Training loss: 2.123420689441196
Validation loss: 2.5639423249989104

Epoch: 6| Step: 11
Training loss: 2.633769147357039
Validation loss: 2.605978622761639

Epoch: 6| Step: 12
Training loss: 1.4792591477975634
Validation loss: 2.607287060780152

Epoch: 6| Step: 13
Training loss: 2.093413824165921
Validation loss: 2.6123317329694213

Epoch: 252| Step: 0
Training loss: 2.6070314950917157
Validation loss: 2.6296539905911644

Epoch: 6| Step: 1
Training loss: 2.358374478236217
Validation loss: 2.628943055241485

Epoch: 6| Step: 2
Training loss: 3.238324541232794
Validation loss: 2.6199135091570414

Epoch: 6| Step: 3
Training loss: 2.321979784237624
Validation loss: 2.6185803099699596

Epoch: 6| Step: 4
Training loss: 1.6443848170962834
Validation loss: 2.5964672761624503

Epoch: 6| Step: 5
Training loss: 1.7272311335670822
Validation loss: 2.5865976388027017

Epoch: 6| Step: 6
Training loss: 1.7055645191041306
Validation loss: 2.589070714439878

Epoch: 6| Step: 7
Training loss: 1.835498643733817
Validation loss: 2.5794167798430414

Epoch: 6| Step: 8
Training loss: 1.812702167680107
Validation loss: 2.574336186741771

Epoch: 6| Step: 9
Training loss: 1.7234114118384374
Validation loss: 2.570854755932681

Epoch: 6| Step: 10
Training loss: 2.063015728829982
Validation loss: 2.59102133191425

Epoch: 6| Step: 11
Training loss: 2.228567726268418
Validation loss: 2.5646579773919886

Epoch: 6| Step: 12
Training loss: 2.1952513553887587
Validation loss: 2.5842065617117282

Epoch: 6| Step: 13
Training loss: 2.650632865478532
Validation loss: 2.5954080820138126

Epoch: 253| Step: 0
Training loss: 2.3698250457313272
Validation loss: 2.5851480329591814

Epoch: 6| Step: 1
Training loss: 1.7319976734559817
Validation loss: 2.5844309741181486

Epoch: 6| Step: 2
Training loss: 1.5272848991119568
Validation loss: 2.5758904223089383

Epoch: 6| Step: 3
Training loss: 1.8590241429739842
Validation loss: 2.577943660639352

Epoch: 6| Step: 4
Training loss: 2.847375256734021
Validation loss: 2.597449640074076

Epoch: 6| Step: 5
Training loss: 1.9874011417010577
Validation loss: 2.613547972489969

Epoch: 6| Step: 6
Training loss: 2.057705827061156
Validation loss: 2.609385477071656

Epoch: 6| Step: 7
Training loss: 2.074927372408259
Validation loss: 2.6767601728515906

Epoch: 6| Step: 8
Training loss: 3.013825507212925
Validation loss: 2.6627822738285136

Epoch: 6| Step: 9
Training loss: 1.849764308865335
Validation loss: 2.7013731408225405

Epoch: 6| Step: 10
Training loss: 2.4159372697858954
Validation loss: 2.7342523456493786

Epoch: 6| Step: 11
Training loss: 2.157706832784546
Validation loss: 2.676342254264934

Epoch: 6| Step: 12
Training loss: 2.5833161773932343
Validation loss: 2.6303685709170113

Epoch: 6| Step: 13
Training loss: 1.5552327335774605
Validation loss: 2.5849019999715246

Epoch: 254| Step: 0
Training loss: 2.290280691710094
Validation loss: 2.5772298164234773

Epoch: 6| Step: 1
Training loss: 1.4537432596143887
Validation loss: 2.57288183479567

Epoch: 6| Step: 2
Training loss: 2.6862128080595373
Validation loss: 2.5383140360682503

Epoch: 6| Step: 3
Training loss: 2.237508856899697
Validation loss: 2.5639994041464

Epoch: 6| Step: 4
Training loss: 2.498925550361595
Validation loss: 2.564468790487305

Epoch: 6| Step: 5
Training loss: 1.9144152257904452
Validation loss: 2.5832929966966627

Epoch: 6| Step: 6
Training loss: 2.5739754314361596
Validation loss: 2.6166963790210924

Epoch: 6| Step: 7
Training loss: 3.0791717143828263
Validation loss: 2.6557951294619215

Epoch: 6| Step: 8
Training loss: 1.7320512205219205
Validation loss: 2.674736513251129

Epoch: 6| Step: 9
Training loss: 2.2391664575373906
Validation loss: 2.696426706785618

Epoch: 6| Step: 10
Training loss: 1.7359794549825
Validation loss: 2.7091474092100842

Epoch: 6| Step: 11
Training loss: 2.5418437103979463
Validation loss: 2.6724300588764116

Epoch: 6| Step: 12
Training loss: 1.6597206890714509
Validation loss: 2.6537538206360756

Epoch: 6| Step: 13
Training loss: 1.9316179141106766
Validation loss: 2.6416242616140035

Epoch: 255| Step: 0
Training loss: 1.870447863633544
Validation loss: 2.595409980488096

Epoch: 6| Step: 1
Training loss: 1.5437941263046837
Validation loss: 2.54438223671374

Epoch: 6| Step: 2
Training loss: 2.709410751441286
Validation loss: 2.5444622976416196

Epoch: 6| Step: 3
Training loss: 2.21799703367016
Validation loss: 2.5496405971542706

Epoch: 6| Step: 4
Training loss: 2.792447298896482
Validation loss: 2.573296373485665

Epoch: 6| Step: 5
Training loss: 2.2560784567927477
Validation loss: 2.557123451889949

Epoch: 6| Step: 6
Training loss: 2.5373289792913356
Validation loss: 2.5988003689776287

Epoch: 6| Step: 7
Training loss: 1.5890459688090082
Validation loss: 2.6135259113670566

Epoch: 6| Step: 8
Training loss: 2.726054496768956
Validation loss: 2.5953875661547388

Epoch: 6| Step: 9
Training loss: 2.189230534096603
Validation loss: 2.6091799786874947

Epoch: 6| Step: 10
Training loss: 2.1728952330583398
Validation loss: 2.6296362050055837

Epoch: 6| Step: 11
Training loss: 2.1730745145448096
Validation loss: 2.6075312178374523

Epoch: 6| Step: 12
Training loss: 1.6555572356500712
Validation loss: 2.582831477568397

Epoch: 6| Step: 13
Training loss: 1.7646395878868095
Validation loss: 2.6057521927069267

Epoch: 256| Step: 0
Training loss: 2.781226168755432
Validation loss: 2.6198227629639326

Epoch: 6| Step: 1
Training loss: 2.4152419286193645
Validation loss: 2.5896481631432984

Epoch: 6| Step: 2
Training loss: 2.1504833121770903
Validation loss: 2.5908185947113918

Epoch: 6| Step: 3
Training loss: 1.854166638092155
Validation loss: 2.5926797872657485

Epoch: 6| Step: 4
Training loss: 1.7615322513361935
Validation loss: 2.598389929700898

Epoch: 6| Step: 5
Training loss: 2.471144468671629
Validation loss: 2.5990262580103867

Epoch: 6| Step: 6
Training loss: 1.6201951811207063
Validation loss: 2.612954895290598

Epoch: 6| Step: 7
Training loss: 2.3223384143147197
Validation loss: 2.630531953347477

Epoch: 6| Step: 8
Training loss: 2.0574754721383504
Validation loss: 2.6371330632727217

Epoch: 6| Step: 9
Training loss: 1.5785070277949653
Validation loss: 2.616764379811036

Epoch: 6| Step: 10
Training loss: 2.2364629846414052
Validation loss: 2.669570598362539

Epoch: 6| Step: 11
Training loss: 1.9784851975657272
Validation loss: 2.6106667585795034

Epoch: 6| Step: 12
Training loss: 1.9364051186355047
Validation loss: 2.6296126846305796

Epoch: 6| Step: 13
Training loss: 2.7655339630143647
Validation loss: 2.5966193632225263

Epoch: 257| Step: 0
Training loss: 1.9442341584831533
Validation loss: 2.595290894469148

Epoch: 6| Step: 1
Training loss: 1.9955455527424244
Validation loss: 2.6038455816053814

Epoch: 6| Step: 2
Training loss: 1.9978754561081897
Validation loss: 2.58932617293696

Epoch: 6| Step: 3
Training loss: 2.2581799482031535
Validation loss: 2.6162813430393475

Epoch: 6| Step: 4
Training loss: 1.9506033526401658
Validation loss: 2.5802384085372516

Epoch: 6| Step: 5
Training loss: 2.363407352330384
Validation loss: 2.6014378912087857

Epoch: 6| Step: 6
Training loss: 3.022743796083733
Validation loss: 2.6064403043650954

Epoch: 6| Step: 7
Training loss: 1.5183979898051552
Validation loss: 2.6279933151051713

Epoch: 6| Step: 8
Training loss: 2.196475769492857
Validation loss: 2.6425063825305863

Epoch: 6| Step: 9
Training loss: 2.8217450252437395
Validation loss: 2.646194243158277

Epoch: 6| Step: 10
Training loss: 2.294874189165476
Validation loss: 2.6151807084867347

Epoch: 6| Step: 11
Training loss: 1.7275457559976672
Validation loss: 2.627154797986912

Epoch: 6| Step: 12
Training loss: 1.4487272596179068
Validation loss: 2.5949560525023423

Epoch: 6| Step: 13
Training loss: 2.3367242923366027
Validation loss: 2.591789745789578

Epoch: 258| Step: 0
Training loss: 1.9104380643499765
Validation loss: 2.5749428887808348

Epoch: 6| Step: 1
Training loss: 2.500082396103114
Validation loss: 2.5960341358027113

Epoch: 6| Step: 2
Training loss: 2.623711769439753
Validation loss: 2.572050811209317

Epoch: 6| Step: 3
Training loss: 2.1406718896338606
Validation loss: 2.6107300611084834

Epoch: 6| Step: 4
Training loss: 1.5743845812061914
Validation loss: 2.606037739283088

Epoch: 6| Step: 5
Training loss: 2.0492523597814456
Validation loss: 2.5967969194862475

Epoch: 6| Step: 6
Training loss: 2.8849190146254133
Validation loss: 2.570261613676426

Epoch: 6| Step: 7
Training loss: 2.4482797772717584
Validation loss: 2.5889039403339615

Epoch: 6| Step: 8
Training loss: 1.5171180528486559
Validation loss: 2.590194302515809

Epoch: 6| Step: 9
Training loss: 2.0119013731200526
Validation loss: 2.618353057494034

Epoch: 6| Step: 10
Training loss: 2.136504056141523
Validation loss: 2.5767107080229965

Epoch: 6| Step: 11
Training loss: 1.8689559159649305
Validation loss: 2.6334377342565936

Epoch: 6| Step: 12
Training loss: 2.6653465241809786
Validation loss: 2.588707660799746

Epoch: 6| Step: 13
Training loss: 1.5699055462263536
Validation loss: 2.6127369403624052

Epoch: 259| Step: 0
Training loss: 2.5264315484529862
Validation loss: 2.597457549256467

Epoch: 6| Step: 1
Training loss: 2.254120550430163
Validation loss: 2.6292319773820774

Epoch: 6| Step: 2
Training loss: 2.413882449450852
Validation loss: 2.6175597424324906

Epoch: 6| Step: 3
Training loss: 2.278461685732466
Validation loss: 2.6144149290363243

Epoch: 6| Step: 4
Training loss: 2.197658818986234
Validation loss: 2.601503831662014

Epoch: 6| Step: 5
Training loss: 2.4249351610776952
Validation loss: 2.599107487029165

Epoch: 6| Step: 6
Training loss: 2.634921533766276
Validation loss: 2.6054049459763458

Epoch: 6| Step: 7
Training loss: 2.1789256306002103
Validation loss: 2.6075150491018695

Epoch: 6| Step: 8
Training loss: 1.8516867551678162
Validation loss: 2.6008292263560415

Epoch: 6| Step: 9
Training loss: 1.3119509320503988
Validation loss: 2.5933315138659268

Epoch: 6| Step: 10
Training loss: 2.1001486861861367
Validation loss: 2.5884068311321813

Epoch: 6| Step: 11
Training loss: 2.0345283462225963
Validation loss: 2.5692797502081612

Epoch: 6| Step: 12
Training loss: 1.9217464745197534
Validation loss: 2.590369338552814

Epoch: 6| Step: 13
Training loss: 1.5305435730976074
Validation loss: 2.6050142409361885

Epoch: 260| Step: 0
Training loss: 1.400202229062766
Validation loss: 2.6184826583176366

Epoch: 6| Step: 1
Training loss: 2.559961783153662
Validation loss: 2.687503297197552

Epoch: 6| Step: 2
Training loss: 2.524188800847797
Validation loss: 2.6454475276739338

Epoch: 6| Step: 3
Training loss: 2.034582837060663
Validation loss: 2.6179702271560057

Epoch: 6| Step: 4
Training loss: 1.4478677791694348
Validation loss: 2.598370232612693

Epoch: 6| Step: 5
Training loss: 2.984282007815758
Validation loss: 2.601855898208257

Epoch: 6| Step: 6
Training loss: 1.7324729318417096
Validation loss: 2.5829760909461266

Epoch: 6| Step: 7
Training loss: 2.151727550107154
Validation loss: 2.5535099998374426

Epoch: 6| Step: 8
Training loss: 2.0244669412790586
Validation loss: 2.5742871087760872

Epoch: 6| Step: 9
Training loss: 1.984310479504416
Validation loss: 2.558222122964503

Epoch: 6| Step: 10
Training loss: 2.4316563127003996
Validation loss: 2.5728750701713023

Epoch: 6| Step: 11
Training loss: 2.5357862727118827
Validation loss: 2.5762680610321023

Epoch: 6| Step: 12
Training loss: 2.1461546820845867
Validation loss: 2.6230440269941413

Epoch: 6| Step: 13
Training loss: 1.9226057942701444
Validation loss: 2.65467750527976

Epoch: 261| Step: 0
Training loss: 2.772420175433441
Validation loss: 2.7126730750867525

Epoch: 6| Step: 1
Training loss: 1.7522968478140017
Validation loss: 2.7047232017460034

Epoch: 6| Step: 2
Training loss: 2.47455888920975
Validation loss: 2.6393634182658348

Epoch: 6| Step: 3
Training loss: 2.2686555784980005
Validation loss: 2.595757546295686

Epoch: 6| Step: 4
Training loss: 1.7429143646660337
Validation loss: 2.5674109967042527

Epoch: 6| Step: 5
Training loss: 2.6187109313818264
Validation loss: 2.5616007056479324

Epoch: 6| Step: 6
Training loss: 2.462415656954517
Validation loss: 2.554771694153082

Epoch: 6| Step: 7
Training loss: 1.8490901488119036
Validation loss: 2.5411880751315747

Epoch: 6| Step: 8
Training loss: 1.82537217199238
Validation loss: 2.5745361626394847

Epoch: 6| Step: 9
Training loss: 2.0731015402496094
Validation loss: 2.577407074198829

Epoch: 6| Step: 10
Training loss: 1.7941390728751723
Validation loss: 2.6110172700139143

Epoch: 6| Step: 11
Training loss: 1.9907782862405952
Validation loss: 2.656428521832964

Epoch: 6| Step: 12
Training loss: 2.1656704103847417
Validation loss: 2.6440845527325907

Epoch: 6| Step: 13
Training loss: 2.7092820095485046
Validation loss: 2.693698182164489

Epoch: 262| Step: 0
Training loss: 2.7490916052272003
Validation loss: 2.6665586707976083

Epoch: 6| Step: 1
Training loss: 2.588204856364643
Validation loss: 2.6463563106843258

Epoch: 6| Step: 2
Training loss: 1.5441123104804648
Validation loss: 2.6040330369360576

Epoch: 6| Step: 3
Training loss: 2.5522124173482506
Validation loss: 2.588082705872775

Epoch: 6| Step: 4
Training loss: 1.686885721936519
Validation loss: 2.5481909334212114

Epoch: 6| Step: 5
Training loss: 2.194665670980241
Validation loss: 2.530809466170222

Epoch: 6| Step: 6
Training loss: 1.8466376628158818
Validation loss: 2.53424098063822

Epoch: 6| Step: 7
Training loss: 2.658937777338869
Validation loss: 2.5530344196439376

Epoch: 6| Step: 8
Training loss: 1.7054585560080275
Validation loss: 2.556575858838149

Epoch: 6| Step: 9
Training loss: 2.6692559863662297
Validation loss: 2.5618813240821336

Epoch: 6| Step: 10
Training loss: 2.03355769602836
Validation loss: 2.5968334147233336

Epoch: 6| Step: 11
Training loss: 1.604172454757487
Validation loss: 2.622202578523123

Epoch: 6| Step: 12
Training loss: 2.3083298688878617
Validation loss: 2.688321838102066

Epoch: 6| Step: 13
Training loss: 1.9845573762003337
Validation loss: 2.7028543266946876

Epoch: 263| Step: 0
Training loss: 1.4787159712190194
Validation loss: 2.659672540500018

Epoch: 6| Step: 1
Training loss: 2.0680885894143346
Validation loss: 2.6643563683675895

Epoch: 6| Step: 2
Training loss: 2.3167119202436295
Validation loss: 2.6384026017999167

Epoch: 6| Step: 3
Training loss: 2.0706768363085546
Validation loss: 2.661938190437157

Epoch: 6| Step: 4
Training loss: 1.5101315547149448
Validation loss: 2.65553573280005

Epoch: 6| Step: 5
Training loss: 1.8208945984939553
Validation loss: 2.644227123569207

Epoch: 6| Step: 6
Training loss: 2.5074200189372315
Validation loss: 2.588093921665471

Epoch: 6| Step: 7
Training loss: 1.8453181435468846
Validation loss: 2.5853078023618155

Epoch: 6| Step: 8
Training loss: 2.798581332754812
Validation loss: 2.6312331264797497

Epoch: 6| Step: 9
Training loss: 2.7828839249523685
Validation loss: 2.6410019058211995

Epoch: 6| Step: 10
Training loss: 2.2958996836449193
Validation loss: 2.650925524452708

Epoch: 6| Step: 11
Training loss: 2.1142645785111136
Validation loss: 2.6937784888228062

Epoch: 6| Step: 12
Training loss: 1.746434530503774
Validation loss: 2.6772104423617193

Epoch: 6| Step: 13
Training loss: 1.8960220606281004
Validation loss: 2.6653827815078297

Epoch: 264| Step: 0
Training loss: 2.2822890332298345
Validation loss: 2.622595063829961

Epoch: 6| Step: 1
Training loss: 1.6794613708160222
Validation loss: 2.5838850160364366

Epoch: 6| Step: 2
Training loss: 1.9887860150196144
Validation loss: 2.579663844301453

Epoch: 6| Step: 3
Training loss: 1.9267088105147432
Validation loss: 2.591641829413556

Epoch: 6| Step: 4
Training loss: 2.761671268211434
Validation loss: 2.6126712530001273

Epoch: 6| Step: 5
Training loss: 2.300658451035071
Validation loss: 2.6388800609730967

Epoch: 6| Step: 6
Training loss: 3.0467422847698633
Validation loss: 2.7094385141850053

Epoch: 6| Step: 7
Training loss: 1.585576960730976
Validation loss: 2.6854719893678505

Epoch: 6| Step: 8
Training loss: 1.959263790205233
Validation loss: 2.742746135037292

Epoch: 6| Step: 9
Training loss: 1.9728389844199818
Validation loss: 2.682744157765284

Epoch: 6| Step: 10
Training loss: 1.8222691575779666
Validation loss: 2.656338215279382

Epoch: 6| Step: 11
Training loss: 2.053651033363141
Validation loss: 2.61179756352209

Epoch: 6| Step: 12
Training loss: 2.5502395405176697
Validation loss: 2.5625749127362525

Epoch: 6| Step: 13
Training loss: 2.160323897025021
Validation loss: 2.5340612679059555

Epoch: 265| Step: 0
Training loss: 1.484648348083903
Validation loss: 2.5543251597239567

Epoch: 6| Step: 1
Training loss: 2.226357326758473
Validation loss: 2.54773566558881

Epoch: 6| Step: 2
Training loss: 1.8679645788767603
Validation loss: 2.5640291753072115

Epoch: 6| Step: 3
Training loss: 2.3123410144487884
Validation loss: 2.598532056282757

Epoch: 6| Step: 4
Training loss: 2.070898815120097
Validation loss: 2.631010954109721

Epoch: 6| Step: 5
Training loss: 2.4477604809438183
Validation loss: 2.6543672808211634

Epoch: 6| Step: 6
Training loss: 2.7995365202004048
Validation loss: 2.6362471095105926

Epoch: 6| Step: 7
Training loss: 1.3904536709630657
Validation loss: 2.656876748137616

Epoch: 6| Step: 8
Training loss: 1.8445030872694503
Validation loss: 2.651787019184642

Epoch: 6| Step: 9
Training loss: 1.899806906274406
Validation loss: 2.6441456726359664

Epoch: 6| Step: 10
Training loss: 2.6298318624961556
Validation loss: 2.6067049753035922

Epoch: 6| Step: 11
Training loss: 2.2076905472665853
Validation loss: 2.568514193859441

Epoch: 6| Step: 12
Training loss: 1.9862990175588244
Validation loss: 2.619164155972433

Epoch: 6| Step: 13
Training loss: 2.4131405745850656
Validation loss: 2.6269689018220093

Epoch: 266| Step: 0
Training loss: 1.6002765237749275
Validation loss: 2.706785806498617

Epoch: 6| Step: 1
Training loss: 1.9487587915482816
Validation loss: 2.7270303669082594

Epoch: 6| Step: 2
Training loss: 2.7880488244574546
Validation loss: 2.7560121244746107

Epoch: 6| Step: 3
Training loss: 1.7289067574770494
Validation loss: 2.7373007389747355

Epoch: 6| Step: 4
Training loss: 2.961722800760963
Validation loss: 2.6678613629006516

Epoch: 6| Step: 5
Training loss: 1.399802963832743
Validation loss: 2.5831620610794537

Epoch: 6| Step: 6
Training loss: 2.0431223240855547
Validation loss: 2.5453998997941025

Epoch: 6| Step: 7
Training loss: 2.0391960246481746
Validation loss: 2.5344827988884298

Epoch: 6| Step: 8
Training loss: 2.222972880841122
Validation loss: 2.519634684329637

Epoch: 6| Step: 9
Training loss: 2.4779884252639657
Validation loss: 2.5138537803736756

Epoch: 6| Step: 10
Training loss: 2.6243170803553117
Validation loss: 2.5298358279201105

Epoch: 6| Step: 11
Training loss: 2.6120699368821607
Validation loss: 2.5537307923264163

Epoch: 6| Step: 12
Training loss: 1.6998968766293785
Validation loss: 2.551073198810271

Epoch: 6| Step: 13
Training loss: 2.331163816929974
Validation loss: 2.5911906227317445

Epoch: 267| Step: 0
Training loss: 2.1910234684768906
Validation loss: 2.68392104254256

Epoch: 6| Step: 1
Training loss: 2.217607445764083
Validation loss: 2.724063402025287

Epoch: 6| Step: 2
Training loss: 2.156925482610983
Validation loss: 2.7676846580847125

Epoch: 6| Step: 3
Training loss: 2.021147503633842
Validation loss: 2.782360283907521

Epoch: 6| Step: 4
Training loss: 2.181828148414505
Validation loss: 2.7746803042259818

Epoch: 6| Step: 5
Training loss: 1.795416663113719
Validation loss: 2.7474921379867774

Epoch: 6| Step: 6
Training loss: 3.2107855767834397
Validation loss: 2.696417827909607

Epoch: 6| Step: 7
Training loss: 2.413030113522388
Validation loss: 2.6100520856393197

Epoch: 6| Step: 8
Training loss: 1.7392153169815525
Validation loss: 2.5642546717141963

Epoch: 6| Step: 9
Training loss: 2.5504381962676446
Validation loss: 2.5461718128742716

Epoch: 6| Step: 10
Training loss: 1.8812214947438743
Validation loss: 2.543600368238457

Epoch: 6| Step: 11
Training loss: 1.52837717358781
Validation loss: 2.553547790645321

Epoch: 6| Step: 12
Training loss: 2.7611021138519445
Validation loss: 2.5622232179105833

Epoch: 6| Step: 13
Training loss: 1.7984736752952433
Validation loss: 2.572746786051109

Epoch: 268| Step: 0
Training loss: 2.1068271649864876
Validation loss: 2.577633789739133

Epoch: 6| Step: 1
Training loss: 1.8625228265989253
Validation loss: 2.619167827452612

Epoch: 6| Step: 2
Training loss: 1.83400738491456
Validation loss: 2.6298900424250204

Epoch: 6| Step: 3
Training loss: 2.5734960441670123
Validation loss: 2.652856641421562

Epoch: 6| Step: 4
Training loss: 2.993132359895322
Validation loss: 2.623020947428344

Epoch: 6| Step: 5
Training loss: 1.8502319319427472
Validation loss: 2.629697018517539

Epoch: 6| Step: 6
Training loss: 2.529644775029825
Validation loss: 2.61522759837193

Epoch: 6| Step: 7
Training loss: 1.3863947530145295
Validation loss: 2.6145422325601975

Epoch: 6| Step: 8
Training loss: 1.65253910866771
Validation loss: 2.581113389582054

Epoch: 6| Step: 9
Training loss: 2.448969145350331
Validation loss: 2.601987046129126

Epoch: 6| Step: 10
Training loss: 1.7108049733294555
Validation loss: 2.5947229942648513

Epoch: 6| Step: 11
Training loss: 1.9406580260287665
Validation loss: 2.5851425839175604

Epoch: 6| Step: 12
Training loss: 1.9414134956086497
Validation loss: 2.62174833322909

Epoch: 6| Step: 13
Training loss: 2.6751210978540008
Validation loss: 2.6009602045194726

Epoch: 269| Step: 0
Training loss: 1.736525293747602
Validation loss: 2.602997087417167

Epoch: 6| Step: 1
Training loss: 2.5423763305834632
Validation loss: 2.6200563184615904

Epoch: 6| Step: 2
Training loss: 2.249381934152882
Validation loss: 2.607594306949612

Epoch: 6| Step: 3
Training loss: 1.9196084776679827
Validation loss: 2.6205678261529886

Epoch: 6| Step: 4
Training loss: 2.1851805242691094
Validation loss: 2.601559292444766

Epoch: 6| Step: 5
Training loss: 2.227091194426815
Validation loss: 2.6423051443590637

Epoch: 6| Step: 6
Training loss: 1.4922813665615122
Validation loss: 2.691707348786761

Epoch: 6| Step: 7
Training loss: 2.548714377251135
Validation loss: 2.724596190790981

Epoch: 6| Step: 8
Training loss: 1.9576831577012828
Validation loss: 2.724843471592782

Epoch: 6| Step: 9
Training loss: 2.5251297605805876
Validation loss: 2.7274322288524777

Epoch: 6| Step: 10
Training loss: 2.0647902055625558
Validation loss: 2.718573305081009

Epoch: 6| Step: 11
Training loss: 2.0691727866016865
Validation loss: 2.6735216535874797

Epoch: 6| Step: 12
Training loss: 2.158437089623147
Validation loss: 2.637163063572261

Epoch: 6| Step: 13
Training loss: 1.9341267169123058
Validation loss: 2.57395559383068

Epoch: 270| Step: 0
Training loss: 2.38348769330512
Validation loss: 2.5409735584026736

Epoch: 6| Step: 1
Training loss: 1.6894780328050105
Validation loss: 2.565639929160739

Epoch: 6| Step: 2
Training loss: 2.024260482446233
Validation loss: 2.516178678312544

Epoch: 6| Step: 3
Training loss: 2.8609911410992246
Validation loss: 2.534146100301267

Epoch: 6| Step: 4
Training loss: 2.4107863037008936
Validation loss: 2.525675990323042

Epoch: 6| Step: 5
Training loss: 1.6241248048124428
Validation loss: 2.5539146522001785

Epoch: 6| Step: 6
Training loss: 2.1531810205089768
Validation loss: 2.578765542961514

Epoch: 6| Step: 7
Training loss: 1.8866930973686333
Validation loss: 2.651735246284196

Epoch: 6| Step: 8
Training loss: 2.190309192134119
Validation loss: 2.7382631541627833

Epoch: 6| Step: 9
Training loss: 2.9241924377447983
Validation loss: 2.7577969385848142

Epoch: 6| Step: 10
Training loss: 2.0383389530223983
Validation loss: 2.780720635373826

Epoch: 6| Step: 11
Training loss: 2.711663316639818
Validation loss: 2.7495350733687425

Epoch: 6| Step: 12
Training loss: 1.949730876544642
Validation loss: 2.7042497709305406

Epoch: 6| Step: 13
Training loss: 1.5885620199264976
Validation loss: 2.6407436667720323

Epoch: 271| Step: 0
Training loss: 2.2708784559707267
Validation loss: 2.5975718243104224

Epoch: 6| Step: 1
Training loss: 2.313868761935503
Validation loss: 2.5451148724315518

Epoch: 6| Step: 2
Training loss: 2.2117604587601285
Validation loss: 2.5577577889971717

Epoch: 6| Step: 3
Training loss: 1.8671521937651485
Validation loss: 2.5402871958749955

Epoch: 6| Step: 4
Training loss: 2.8411316607594115
Validation loss: 2.546112258374096

Epoch: 6| Step: 5
Training loss: 1.942376797965487
Validation loss: 2.5520075936010147

Epoch: 6| Step: 6
Training loss: 1.7310707302441197
Validation loss: 2.5695449780794997

Epoch: 6| Step: 7
Training loss: 1.5786354070470383
Validation loss: 2.590473480149729

Epoch: 6| Step: 8
Training loss: 2.173602398363011
Validation loss: 2.6118740061885624

Epoch: 6| Step: 9
Training loss: 2.327329358853207
Validation loss: 2.646540875083964

Epoch: 6| Step: 10
Training loss: 2.6114200641479197
Validation loss: 2.6850194646649546

Epoch: 6| Step: 11
Training loss: 2.1927501345264626
Validation loss: 2.7345818141654235

Epoch: 6| Step: 12
Training loss: 2.2168281721014833
Validation loss: 2.7125754854214277

Epoch: 6| Step: 13
Training loss: 2.1134437033215185
Validation loss: 2.675264510033354

Epoch: 272| Step: 0
Training loss: 2.115316204485395
Validation loss: 2.676636051162825

Epoch: 6| Step: 1
Training loss: 2.8530139312350524
Validation loss: 2.643699045494359

Epoch: 6| Step: 2
Training loss: 1.950257171887601
Validation loss: 2.6422375151481554

Epoch: 6| Step: 3
Training loss: 2.4975375445868866
Validation loss: 2.6425575317572854

Epoch: 6| Step: 4
Training loss: 2.1979238380447716
Validation loss: 2.6311929855149954

Epoch: 6| Step: 5
Training loss: 1.918132207862534
Validation loss: 2.6252885387422866

Epoch: 6| Step: 6
Training loss: 1.2690285964040413
Validation loss: 2.6351697502012836

Epoch: 6| Step: 7
Training loss: 1.712318455338456
Validation loss: 2.628842478220022

Epoch: 6| Step: 8
Training loss: 2.172008592627233
Validation loss: 2.6231845224053405

Epoch: 6| Step: 9
Training loss: 2.716632412965599
Validation loss: 2.62119603419383

Epoch: 6| Step: 10
Training loss: 1.5217606143145685
Validation loss: 2.603375090774176

Epoch: 6| Step: 11
Training loss: 2.2553577212102205
Validation loss: 2.6033807458683347

Epoch: 6| Step: 12
Training loss: 1.4103688425871095
Validation loss: 2.6157747013909454

Epoch: 6| Step: 13
Training loss: 2.4997449744801896
Validation loss: 2.624502710134733

Epoch: 273| Step: 0
Training loss: 2.131911649945327
Validation loss: 2.6477814858718727

Epoch: 6| Step: 1
Training loss: 2.552373649018039
Validation loss: 2.697225936387719

Epoch: 6| Step: 2
Training loss: 2.085729924421413
Validation loss: 2.675526003949857

Epoch: 6| Step: 3
Training loss: 2.0837991448037907
Validation loss: 2.6392868684409363

Epoch: 6| Step: 4
Training loss: 1.8778613827444064
Validation loss: 2.646329567898834

Epoch: 6| Step: 5
Training loss: 1.442365869669237
Validation loss: 2.604667345871783

Epoch: 6| Step: 6
Training loss: 1.616393626971804
Validation loss: 2.573908878367452

Epoch: 6| Step: 7
Training loss: 2.790044873331366
Validation loss: 2.577824415158639

Epoch: 6| Step: 8
Training loss: 1.9246818700708994
Validation loss: 2.568202519915193

Epoch: 6| Step: 9
Training loss: 1.448304661787817
Validation loss: 2.572870915632909

Epoch: 6| Step: 10
Training loss: 1.4684875740821794
Validation loss: 2.623604236883453

Epoch: 6| Step: 11
Training loss: 2.180909173346679
Validation loss: 2.6981326253661146

Epoch: 6| Step: 12
Training loss: 3.4722539027146317
Validation loss: 2.7101264348630156

Epoch: 6| Step: 13
Training loss: 1.6304464034343618
Validation loss: 2.7013483548385318

Epoch: 274| Step: 0
Training loss: 2.0554129476595437
Validation loss: 2.7463855398464694

Epoch: 6| Step: 1
Training loss: 2.611740775875564
Validation loss: 2.7171245115034344

Epoch: 6| Step: 2
Training loss: 2.371519550131108
Validation loss: 2.6658464203402303

Epoch: 6| Step: 3
Training loss: 2.3606230611593713
Validation loss: 2.604206028958702

Epoch: 6| Step: 4
Training loss: 1.986616895722135
Validation loss: 2.610338760232316

Epoch: 6| Step: 5
Training loss: 2.525090387822742
Validation loss: 2.6052168801121853

Epoch: 6| Step: 6
Training loss: 2.7467752970197825
Validation loss: 2.588532481698538

Epoch: 6| Step: 7
Training loss: 2.0656771608539257
Validation loss: 2.591854766528787

Epoch: 6| Step: 8
Training loss: 1.815645251267862
Validation loss: 2.588155941588241

Epoch: 6| Step: 9
Training loss: 2.477092313202114
Validation loss: 2.597027833115965

Epoch: 6| Step: 10
Training loss: 2.1377289944953852
Validation loss: 2.645501218562019

Epoch: 6| Step: 11
Training loss: 1.6795796204455493
Validation loss: 2.6628339513248833

Epoch: 6| Step: 12
Training loss: 1.2852045763199624
Validation loss: 2.619679918174689

Epoch: 6| Step: 13
Training loss: 1.3368164205178428
Validation loss: 2.662666648699831

Epoch: 275| Step: 0
Training loss: 2.479555361327203
Validation loss: 2.61914523714794

Epoch: 6| Step: 1
Training loss: 2.219143684813504
Validation loss: 2.634341134803583

Epoch: 6| Step: 2
Training loss: 2.5891859965548747
Validation loss: 2.5866990519082473

Epoch: 6| Step: 3
Training loss: 2.0122235599941445
Validation loss: 2.590971657475651

Epoch: 6| Step: 4
Training loss: 2.4122970693358474
Validation loss: 2.571040397313809

Epoch: 6| Step: 5
Training loss: 2.6835195650510846
Validation loss: 2.5978515169182725

Epoch: 6| Step: 6
Training loss: 2.3011619369507224
Validation loss: 2.5695132604324753

Epoch: 6| Step: 7
Training loss: 1.929898887515596
Validation loss: 2.5797634120518214

Epoch: 6| Step: 8
Training loss: 1.184582841497143
Validation loss: 2.6472992528128896

Epoch: 6| Step: 9
Training loss: 1.3297312279939855
Validation loss: 2.6296837966660163

Epoch: 6| Step: 10
Training loss: 1.7521855466997427
Validation loss: 2.6423438532952597

Epoch: 6| Step: 11
Training loss: 2.028802776672617
Validation loss: 2.672396930482964

Epoch: 6| Step: 12
Training loss: 1.7798668025039857
Validation loss: 2.7093529518107373

Epoch: 6| Step: 13
Training loss: 2.025359430321188
Validation loss: 2.73150359023271

Epoch: 276| Step: 0
Training loss: 2.886708343445806
Validation loss: 2.773203479045265

Epoch: 6| Step: 1
Training loss: 1.7002086343084493
Validation loss: 2.6769739022258783

Epoch: 6| Step: 2
Training loss: 1.5327451763086506
Validation loss: 2.6411001165504695

Epoch: 6| Step: 3
Training loss: 2.2659728736836238
Validation loss: 2.5816750023372568

Epoch: 6| Step: 4
Training loss: 1.621044774062512
Validation loss: 2.5442697192488657

Epoch: 6| Step: 5
Training loss: 2.5325282130877533
Validation loss: 2.555697506841375

Epoch: 6| Step: 6
Training loss: 2.099862698199061
Validation loss: 2.558965618103817

Epoch: 6| Step: 7
Training loss: 2.1744788499173295
Validation loss: 2.5489618064151034

Epoch: 6| Step: 8
Training loss: 2.1254484040129835
Validation loss: 2.55904836716831

Epoch: 6| Step: 9
Training loss: 2.672235832611481
Validation loss: 2.597844993216475

Epoch: 6| Step: 10
Training loss: 2.456644437146728
Validation loss: 2.565298521679378

Epoch: 6| Step: 11
Training loss: 1.7793557652464544
Validation loss: 2.58788354644767

Epoch: 6| Step: 12
Training loss: 2.137893604825029
Validation loss: 2.632922124042541

Epoch: 6| Step: 13
Training loss: 1.767969178837325
Validation loss: 2.6610753380404644

Epoch: 277| Step: 0
Training loss: 2.1657174182895074
Validation loss: 2.7061208099469534

Epoch: 6| Step: 1
Training loss: 2.2301965871469216
Validation loss: 2.690016846964479

Epoch: 6| Step: 2
Training loss: 1.6327615392297912
Validation loss: 2.726384445832849

Epoch: 6| Step: 3
Training loss: 1.406303235211978
Validation loss: 2.7126587488742167

Epoch: 6| Step: 4
Training loss: 2.302231543647686
Validation loss: 2.7260830374758473

Epoch: 6| Step: 5
Training loss: 2.236516180002525
Validation loss: 2.7030839567798695

Epoch: 6| Step: 6
Training loss: 2.2797435855568167
Validation loss: 2.656578312947824

Epoch: 6| Step: 7
Training loss: 2.3581440727216822
Validation loss: 2.662122794043085

Epoch: 6| Step: 8
Training loss: 2.375659951321987
Validation loss: 2.6655389417834017

Epoch: 6| Step: 9
Training loss: 2.76690557972649
Validation loss: 2.6709733449228827

Epoch: 6| Step: 10
Training loss: 1.5963526399572974
Validation loss: 2.6484151743620212

Epoch: 6| Step: 11
Training loss: 1.8915357681671947
Validation loss: 2.6250686636527436

Epoch: 6| Step: 12
Training loss: 2.2794357819712445
Validation loss: 2.610490404464173

Epoch: 6| Step: 13
Training loss: 1.6666427451642254
Validation loss: 2.6218475758660778

Epoch: 278| Step: 0
Training loss: 1.91123086544261
Validation loss: 2.6417755238901126

Epoch: 6| Step: 1
Training loss: 2.1284824334446415
Validation loss: 2.61734709751256

Epoch: 6| Step: 2
Training loss: 2.123508827746217
Validation loss: 2.6074202900666217

Epoch: 6| Step: 3
Training loss: 2.041635928279417
Validation loss: 2.661642741304984

Epoch: 6| Step: 4
Training loss: 1.8336458228851558
Validation loss: 2.6772450547903635

Epoch: 6| Step: 5
Training loss: 2.020357711769948
Validation loss: 2.6877535175542575

Epoch: 6| Step: 6
Training loss: 2.075816198477616
Validation loss: 2.691786829113569

Epoch: 6| Step: 7
Training loss: 2.276107007331967
Validation loss: 2.7038015206258086

Epoch: 6| Step: 8
Training loss: 2.6949524569873886
Validation loss: 2.7333564387096985

Epoch: 6| Step: 9
Training loss: 2.522062417101209
Validation loss: 2.6986917219514517

Epoch: 6| Step: 10
Training loss: 1.864175897620033
Validation loss: 2.6877307127462

Epoch: 6| Step: 11
Training loss: 2.1414601722449857
Validation loss: 2.648607179200614

Epoch: 6| Step: 12
Training loss: 1.5984768054414114
Validation loss: 2.6214749721797483

Epoch: 6| Step: 13
Training loss: 1.7991146559424862
Validation loss: 2.6238940346292905

Epoch: 279| Step: 0
Training loss: 2.768195385635595
Validation loss: 2.595545074802443

Epoch: 6| Step: 1
Training loss: 2.2648000333316416
Validation loss: 2.594733101699317

Epoch: 6| Step: 2
Training loss: 1.2118174647365734
Validation loss: 2.590789606856851

Epoch: 6| Step: 3
Training loss: 2.148367807818507
Validation loss: 2.622393903886274

Epoch: 6| Step: 4
Training loss: 1.6217777877221724
Validation loss: 2.6046275888077313

Epoch: 6| Step: 5
Training loss: 1.7212117684965753
Validation loss: 2.6486307559401427

Epoch: 6| Step: 6
Training loss: 2.3347330209498836
Validation loss: 2.6624211301151166

Epoch: 6| Step: 7
Training loss: 1.746474051823627
Validation loss: 2.6556210988848705

Epoch: 6| Step: 8
Training loss: 2.0968608236046844
Validation loss: 2.627582581465763

Epoch: 6| Step: 9
Training loss: 1.7059630799004768
Validation loss: 2.6338766043634316

Epoch: 6| Step: 10
Training loss: 2.8619498244711643
Validation loss: 2.6265982803004477

Epoch: 6| Step: 11
Training loss: 1.6522156144909108
Validation loss: 2.6009088101650057

Epoch: 6| Step: 12
Training loss: 1.7771423225704295
Validation loss: 2.5980223433581426

Epoch: 6| Step: 13
Training loss: 2.785930937771602
Validation loss: 2.6141325320089708

Epoch: 280| Step: 0
Training loss: 1.5822144955602377
Validation loss: 2.647915934140644

Epoch: 6| Step: 1
Training loss: 2.2933505258728952
Validation loss: 2.6045534431606954

Epoch: 6| Step: 2
Training loss: 2.440000767316854
Validation loss: 2.689903958389386

Epoch: 6| Step: 3
Training loss: 1.6164853695680224
Validation loss: 2.6345123176791128

Epoch: 6| Step: 4
Training loss: 2.255244183567413
Validation loss: 2.644351759679003

Epoch: 6| Step: 5
Training loss: 2.581156387663658
Validation loss: 2.619265658366599

Epoch: 6| Step: 6
Training loss: 2.2937536504648874
Validation loss: 2.6290312194595686

Epoch: 6| Step: 7
Training loss: 2.2132183482088124
Validation loss: 2.6364685241269155

Epoch: 6| Step: 8
Training loss: 2.2434648337892926
Validation loss: 2.653010760612248

Epoch: 6| Step: 9
Training loss: 1.7953989351745148
Validation loss: 2.6396135729407675

Epoch: 6| Step: 10
Training loss: 2.121943014007116
Validation loss: 2.643365434914286

Epoch: 6| Step: 11
Training loss: 2.1068896310049863
Validation loss: 2.659860184635211

Epoch: 6| Step: 12
Training loss: 1.839802865062083
Validation loss: 2.6479546585979103

Epoch: 6| Step: 13
Training loss: 1.4588652412768668
Validation loss: 2.6715152937075137

Epoch: 281| Step: 0
Training loss: 2.8094730618922203
Validation loss: 2.6963832184349754

Epoch: 6| Step: 1
Training loss: 1.8818462630871038
Validation loss: 2.692901535530752

Epoch: 6| Step: 2
Training loss: 2.11910709758904
Validation loss: 2.696473878547803

Epoch: 6| Step: 3
Training loss: 2.752800209380865
Validation loss: 2.6709580735006027

Epoch: 6| Step: 4
Training loss: 1.6574586021351327
Validation loss: 2.6798943160816853

Epoch: 6| Step: 5
Training loss: 2.5529327432250666
Validation loss: 2.6864887819096768

Epoch: 6| Step: 6
Training loss: 1.8928983277726958
Validation loss: 2.693927161932446

Epoch: 6| Step: 7
Training loss: 1.895149869301863
Validation loss: 2.683552363639696

Epoch: 6| Step: 8
Training loss: 1.5938486554895464
Validation loss: 2.71947212421625

Epoch: 6| Step: 9
Training loss: 2.2501915744180607
Validation loss: 2.697893464174002

Epoch: 6| Step: 10
Training loss: 1.5388374745027364
Validation loss: 2.7171373371088063

Epoch: 6| Step: 11
Training loss: 2.169751563199875
Validation loss: 2.6867670863681306

Epoch: 6| Step: 12
Training loss: 1.5525927976925493
Validation loss: 2.662061892837239

Epoch: 6| Step: 13
Training loss: 2.0359182853114053
Validation loss: 2.6228120707734224

Epoch: 282| Step: 0
Training loss: 2.6544632231492225
Validation loss: 2.563997978345537

Epoch: 6| Step: 1
Training loss: 1.856806158627705
Validation loss: 2.5624711725117644

Epoch: 6| Step: 2
Training loss: 2.9998029008332625
Validation loss: 2.5781855566445877

Epoch: 6| Step: 3
Training loss: 2.338200624288649
Validation loss: 2.578020012769713

Epoch: 6| Step: 4
Training loss: 2.0763209263436044
Validation loss: 2.5847088218021366

Epoch: 6| Step: 5
Training loss: 1.5312455624885877
Validation loss: 2.593019114395308

Epoch: 6| Step: 6
Training loss: 2.0636681225417806
Validation loss: 2.605032995445806

Epoch: 6| Step: 7
Training loss: 2.0987255134539997
Validation loss: 2.617546823611689

Epoch: 6| Step: 8
Training loss: 1.9913103753256338
Validation loss: 2.6102988916504617

Epoch: 6| Step: 9
Training loss: 1.5663425499195105
Validation loss: 2.670357286119712

Epoch: 6| Step: 10
Training loss: 2.1664505875263713
Validation loss: 2.6314771456017434

Epoch: 6| Step: 11
Training loss: 2.21415923236388
Validation loss: 2.624463314112738

Epoch: 6| Step: 12
Training loss: 2.0583939572980587
Validation loss: 2.6024903866031193

Epoch: 6| Step: 13
Training loss: 1.3732592227222609
Validation loss: 2.5847666568570524

Epoch: 283| Step: 0
Training loss: 2.10811232462651
Validation loss: 2.6000403761785287

Epoch: 6| Step: 1
Training loss: 2.1867374726012194
Validation loss: 2.6115142443991077

Epoch: 6| Step: 2
Training loss: 1.32246746737122
Validation loss: 2.6080869895541414

Epoch: 6| Step: 3
Training loss: 1.716560425603458
Validation loss: 2.6261347936641037

Epoch: 6| Step: 4
Training loss: 1.9436403004395324
Validation loss: 2.6182215834999085

Epoch: 6| Step: 5
Training loss: 1.518225493734725
Validation loss: 2.6215677832329183

Epoch: 6| Step: 6
Training loss: 1.5144374953853985
Validation loss: 2.614144327661876

Epoch: 6| Step: 7
Training loss: 2.0236465169403726
Validation loss: 2.6297363059126773

Epoch: 6| Step: 8
Training loss: 2.1788301046312473
Validation loss: 2.613312482053263

Epoch: 6| Step: 9
Training loss: 2.4562296082715487
Validation loss: 2.6210866853151655

Epoch: 6| Step: 10
Training loss: 2.719991466284436
Validation loss: 2.6400116879753552

Epoch: 6| Step: 11
Training loss: 2.726071201427333
Validation loss: 2.6554346216890563

Epoch: 6| Step: 12
Training loss: 1.911211841569082
Validation loss: 2.703047359873018

Epoch: 6| Step: 13
Training loss: 2.300388892094249
Validation loss: 2.720398151204014

Epoch: 284| Step: 0
Training loss: 1.8993922215164583
Validation loss: 2.738249353648411

Epoch: 6| Step: 1
Training loss: 2.1765584601962464
Validation loss: 2.7716436468037435

Epoch: 6| Step: 2
Training loss: 2.5054886648530323
Validation loss: 2.7427966101600023

Epoch: 6| Step: 3
Training loss: 1.693490310411465
Validation loss: 2.7321781161514846

Epoch: 6| Step: 4
Training loss: 2.4525818436058278
Validation loss: 2.687959291704295

Epoch: 6| Step: 5
Training loss: 2.326288100252937
Validation loss: 2.6457687179805403

Epoch: 6| Step: 6
Training loss: 1.9704019790890381
Validation loss: 2.644535712684912

Epoch: 6| Step: 7
Training loss: 2.3319823804683733
Validation loss: 2.6036682007885656

Epoch: 6| Step: 8
Training loss: 1.8156276551849333
Validation loss: 2.611116753114417

Epoch: 6| Step: 9
Training loss: 2.7000067039689086
Validation loss: 2.5979374707043386

Epoch: 6| Step: 10
Training loss: 1.2827373338578438
Validation loss: 2.622833675034065

Epoch: 6| Step: 11
Training loss: 2.093135572778671
Validation loss: 2.648765146099074

Epoch: 6| Step: 12
Training loss: 1.938634478769257
Validation loss: 2.694743633591753

Epoch: 6| Step: 13
Training loss: 1.8799441954264176
Validation loss: 2.719072622398653

Epoch: 285| Step: 0
Training loss: 1.647587055111733
Validation loss: 2.664887711590957

Epoch: 6| Step: 1
Training loss: 2.2195806963044227
Validation loss: 2.667224830585202

Epoch: 6| Step: 2
Training loss: 2.1998272828014738
Validation loss: 2.6835678817486928

Epoch: 6| Step: 3
Training loss: 2.0690741524183145
Validation loss: 2.6245099473104485

Epoch: 6| Step: 4
Training loss: 2.061844924008986
Validation loss: 2.5770895063305264

Epoch: 6| Step: 5
Training loss: 1.5634818997312867
Validation loss: 2.5718059587694344

Epoch: 6| Step: 6
Training loss: 3.018937105497271
Validation loss: 2.565844950074076

Epoch: 6| Step: 7
Training loss: 2.524845450930893
Validation loss: 2.578226322533511

Epoch: 6| Step: 8
Training loss: 1.8956940218983798
Validation loss: 2.599739879654119

Epoch: 6| Step: 9
Training loss: 1.3882850075897903
Validation loss: 2.6448199116021356

Epoch: 6| Step: 10
Training loss: 2.8692695895114007
Validation loss: 2.72255081563698

Epoch: 6| Step: 11
Training loss: 1.6160356040422206
Validation loss: 2.716880945129419

Epoch: 6| Step: 12
Training loss: 2.2899132927883468
Validation loss: 2.7606114492730818

Epoch: 6| Step: 13
Training loss: 1.684296640473691
Validation loss: 2.7385044124870235

Epoch: 286| Step: 0
Training loss: 1.6521808372609976
Validation loss: 2.692109989017959

Epoch: 6| Step: 1
Training loss: 2.746665753932295
Validation loss: 2.6618339935366246

Epoch: 6| Step: 2
Training loss: 2.3933727953251127
Validation loss: 2.587924635561694

Epoch: 6| Step: 3
Training loss: 1.7030097852460504
Validation loss: 2.5427309736665733

Epoch: 6| Step: 4
Training loss: 2.403357811255099
Validation loss: 2.552718917694809

Epoch: 6| Step: 5
Training loss: 1.3387720921507438
Validation loss: 2.5382137660241915

Epoch: 6| Step: 6
Training loss: 2.3875247574566134
Validation loss: 2.539553949771805

Epoch: 6| Step: 7
Training loss: 2.590327199055931
Validation loss: 2.548172166001233

Epoch: 6| Step: 8
Training loss: 2.0339837092044473
Validation loss: 2.5400234184286923

Epoch: 6| Step: 9
Training loss: 2.1389945844926803
Validation loss: 2.565511174838502

Epoch: 6| Step: 10
Training loss: 1.8755670325865685
Validation loss: 2.625264850758144

Epoch: 6| Step: 11
Training loss: 1.5014850100271744
Validation loss: 2.684908674760086

Epoch: 6| Step: 12
Training loss: 2.4694697622520603
Validation loss: 2.7128883546728635

Epoch: 6| Step: 13
Training loss: 1.8264350579070565
Validation loss: 2.7449116737918438

Epoch: 287| Step: 0
Training loss: 1.7436896036825127
Validation loss: 2.779811086868195

Epoch: 6| Step: 1
Training loss: 2.363093597276101
Validation loss: 2.7524092120108787

Epoch: 6| Step: 2
Training loss: 1.884147076083814
Validation loss: 2.7321208708988873

Epoch: 6| Step: 3
Training loss: 1.7276397382470363
Validation loss: 2.716264472825731

Epoch: 6| Step: 4
Training loss: 2.0696486074395257
Validation loss: 2.6898909364569152

Epoch: 6| Step: 5
Training loss: 1.962321488346573
Validation loss: 2.634564791019926

Epoch: 6| Step: 6
Training loss: 2.5789726944447096
Validation loss: 2.6094377628171657

Epoch: 6| Step: 7
Training loss: 2.0085274577468315
Validation loss: 2.556187880304555

Epoch: 6| Step: 8
Training loss: 2.5665557213952344
Validation loss: 2.5472545379988616

Epoch: 6| Step: 9
Training loss: 2.243960433910339
Validation loss: 2.5704842677208477

Epoch: 6| Step: 10
Training loss: 2.053826793644249
Validation loss: 2.5541462300547653

Epoch: 6| Step: 11
Training loss: 2.532548736073195
Validation loss: 2.583653835185859

Epoch: 6| Step: 12
Training loss: 1.4146659785732523
Validation loss: 2.609160728565608

Epoch: 6| Step: 13
Training loss: 1.910115621871898
Validation loss: 2.599852373138023

Epoch: 288| Step: 0
Training loss: 1.8850722938051219
Validation loss: 2.642580170030312

Epoch: 6| Step: 1
Training loss: 2.1076745985659033
Validation loss: 2.6793175934144706

Epoch: 6| Step: 2
Training loss: 2.046059598925392
Validation loss: 2.6604047557431745

Epoch: 6| Step: 3
Training loss: 2.188843886509332
Validation loss: 2.709559608045484

Epoch: 6| Step: 4
Training loss: 2.2421132783202156
Validation loss: 2.684387622665908

Epoch: 6| Step: 5
Training loss: 1.473892623820587
Validation loss: 2.691010865511695

Epoch: 6| Step: 6
Training loss: 2.797531562333951
Validation loss: 2.613194409549319

Epoch: 6| Step: 7
Training loss: 1.7208664088114767
Validation loss: 2.6040865059277154

Epoch: 6| Step: 8
Training loss: 1.8176605160024593
Validation loss: 2.579440526848617

Epoch: 6| Step: 9
Training loss: 1.9625621008310872
Validation loss: 2.5475970533836585

Epoch: 6| Step: 10
Training loss: 1.6403527896850987
Validation loss: 2.546184703680699

Epoch: 6| Step: 11
Training loss: 2.5649776111242857
Validation loss: 2.5217038430168977

Epoch: 6| Step: 12
Training loss: 2.453629168558639
Validation loss: 2.568985988051593

Epoch: 6| Step: 13
Training loss: 2.170545431755225
Validation loss: 2.57707589121931

Epoch: 289| Step: 0
Training loss: 1.4495615592272229
Validation loss: 2.600721419946727

Epoch: 6| Step: 1
Training loss: 2.7941929408460378
Validation loss: 2.6516521078301896

Epoch: 6| Step: 2
Training loss: 2.2562066409522967
Validation loss: 2.661879897401593

Epoch: 6| Step: 3
Training loss: 2.138767968374874
Validation loss: 2.7234399179435846

Epoch: 6| Step: 4
Training loss: 2.0660733565964318
Validation loss: 2.7796937681902607

Epoch: 6| Step: 5
Training loss: 1.2815823937941446
Validation loss: 2.740004914388403

Epoch: 6| Step: 6
Training loss: 2.571920894616567
Validation loss: 2.708046998268838

Epoch: 6| Step: 7
Training loss: 1.651981250868985
Validation loss: 2.6388367686785283

Epoch: 6| Step: 8
Training loss: 1.9433295626246587
Validation loss: 2.577754207881053

Epoch: 6| Step: 9
Training loss: 1.5992912749378347
Validation loss: 2.569661855234496

Epoch: 6| Step: 10
Training loss: 2.3288513688995467
Validation loss: 2.5396008199622253

Epoch: 6| Step: 11
Training loss: 2.965125189931746
Validation loss: 2.529620089309198

Epoch: 6| Step: 12
Training loss: 2.4173985611660798
Validation loss: 2.538426606194317

Epoch: 6| Step: 13
Training loss: 1.9277939869360767
Validation loss: 2.5253571647990185

Epoch: 290| Step: 0
Training loss: 2.3175567805999773
Validation loss: 2.5552335227557217

Epoch: 6| Step: 1
Training loss: 1.5390842649208578
Validation loss: 2.5484889870562144

Epoch: 6| Step: 2
Training loss: 2.262424708004049
Validation loss: 2.5561386793002727

Epoch: 6| Step: 3
Training loss: 2.5895226280931105
Validation loss: 2.5782496104325663

Epoch: 6| Step: 4
Training loss: 2.651355317652988
Validation loss: 2.6045401546951497

Epoch: 6| Step: 5
Training loss: 1.9316281587296795
Validation loss: 2.6179545630671397

Epoch: 6| Step: 6
Training loss: 2.157346916381519
Validation loss: 2.6644206398295687

Epoch: 6| Step: 7
Training loss: 2.2164441874245373
Validation loss: 2.6651094529158694

Epoch: 6| Step: 8
Training loss: 1.6495693714115947
Validation loss: 2.6324196210124073

Epoch: 6| Step: 9
Training loss: 2.3694934252076014
Validation loss: 2.6150765023550178

Epoch: 6| Step: 10
Training loss: 1.8828211740634284
Validation loss: 2.6152357880614883

Epoch: 6| Step: 11
Training loss: 2.4038818397807504
Validation loss: 2.6285576704999967

Epoch: 6| Step: 12
Training loss: 1.4043760741585807
Validation loss: 2.6071915618866064

Epoch: 6| Step: 13
Training loss: 1.7602790312223884
Validation loss: 2.676202893971748

Epoch: 291| Step: 0
Training loss: 1.5992088328744933
Validation loss: 2.6951827750569617

Epoch: 6| Step: 1
Training loss: 2.3297311247867314
Validation loss: 2.746808034683097

Epoch: 6| Step: 2
Training loss: 2.4284953538215213
Validation loss: 2.7343683587856478

Epoch: 6| Step: 3
Training loss: 2.1182142632507843
Validation loss: 2.6807985662313247

Epoch: 6| Step: 4
Training loss: 2.0406997363204513
Validation loss: 2.6582764170023547

Epoch: 6| Step: 5
Training loss: 1.5167196194693506
Validation loss: 2.646308200504294

Epoch: 6| Step: 6
Training loss: 1.716766461308037
Validation loss: 2.6303589327663084

Epoch: 6| Step: 7
Training loss: 2.087251513647933
Validation loss: 2.6306213256104556

Epoch: 6| Step: 8
Training loss: 2.390450664471547
Validation loss: 2.597516324282945

Epoch: 6| Step: 9
Training loss: 1.7908216598127906
Validation loss: 2.5964812793180467

Epoch: 6| Step: 10
Training loss: 1.5665215428414643
Validation loss: 2.6241390087826044

Epoch: 6| Step: 11
Training loss: 1.9274108058612676
Validation loss: 2.667845887482426

Epoch: 6| Step: 12
Training loss: 2.224761662951719
Validation loss: 2.6751843457265143

Epoch: 6| Step: 13
Training loss: 3.1188097869707745
Validation loss: 2.6799633599618704

Epoch: 292| Step: 0
Training loss: 1.6105549014805374
Validation loss: 2.694954182123872

Epoch: 6| Step: 1
Training loss: 1.9318864779716047
Validation loss: 2.7570871294339545

Epoch: 6| Step: 2
Training loss: 1.958716422683579
Validation loss: 2.736992489642895

Epoch: 6| Step: 3
Training loss: 1.5364470745471583
Validation loss: 2.7595223663597763

Epoch: 6| Step: 4
Training loss: 2.1444088426686223
Validation loss: 2.7290426376541945

Epoch: 6| Step: 5
Training loss: 2.466256149601411
Validation loss: 2.7190983282400993

Epoch: 6| Step: 6
Training loss: 1.7148053766706
Validation loss: 2.665740095533054

Epoch: 6| Step: 7
Training loss: 3.0261026311741994
Validation loss: 2.6685282621797244

Epoch: 6| Step: 8
Training loss: 2.192432510050585
Validation loss: 2.620073843005171

Epoch: 6| Step: 9
Training loss: 2.176571714405018
Validation loss: 2.616376722778027

Epoch: 6| Step: 10
Training loss: 1.4295165579905298
Validation loss: 2.5866561306004754

Epoch: 6| Step: 11
Training loss: 1.643010612095966
Validation loss: 2.5697939580611546

Epoch: 6| Step: 12
Training loss: 2.8827529528910976
Validation loss: 2.560200566690217

Epoch: 6| Step: 13
Training loss: 1.4957331529115172
Validation loss: 2.573144954072483

Epoch: 293| Step: 0
Training loss: 2.485127556979075
Validation loss: 2.549166352690916

Epoch: 6| Step: 1
Training loss: 2.9241004669213084
Validation loss: 2.573588115065357

Epoch: 6| Step: 2
Training loss: 2.0257484465744575
Validation loss: 2.597181968127691

Epoch: 6| Step: 3
Training loss: 1.3978872655210857
Validation loss: 2.6258915794867157

Epoch: 6| Step: 4
Training loss: 1.6609519577473708
Validation loss: 2.5894139059245185

Epoch: 6| Step: 5
Training loss: 2.0907465330645034
Validation loss: 2.636442268852166

Epoch: 6| Step: 6
Training loss: 2.109195955943024
Validation loss: 2.636280270133336

Epoch: 6| Step: 7
Training loss: 1.9365886267511965
Validation loss: 2.692129981809708

Epoch: 6| Step: 8
Training loss: 1.3377624450315733
Validation loss: 2.6874036180231733

Epoch: 6| Step: 9
Training loss: 2.0099143815665452
Validation loss: 2.691550949924037

Epoch: 6| Step: 10
Training loss: 2.6266821058500534
Validation loss: 2.7283390673431684

Epoch: 6| Step: 11
Training loss: 2.3504090379269833
Validation loss: 2.68652868830802

Epoch: 6| Step: 12
Training loss: 1.5736283551167556
Validation loss: 2.609430354401131

Epoch: 6| Step: 13
Training loss: 1.8851888388999625
Validation loss: 2.559566462384234

Epoch: 294| Step: 0
Training loss: 1.6306575444674125
Validation loss: 2.541320907546718

Epoch: 6| Step: 1
Training loss: 1.7830982992190123
Validation loss: 2.543187778023364

Epoch: 6| Step: 2
Training loss: 2.160600337206924
Validation loss: 2.529219044159246

Epoch: 6| Step: 3
Training loss: 2.265730651496739
Validation loss: 2.535648041581995

Epoch: 6| Step: 4
Training loss: 1.9952793438217096
Validation loss: 2.5467006022961747

Epoch: 6| Step: 5
Training loss: 1.415837727914643
Validation loss: 2.5474215118126855

Epoch: 6| Step: 6
Training loss: 1.5039679180233878
Validation loss: 2.535345335944098

Epoch: 6| Step: 7
Training loss: 1.9757241140892867
Validation loss: 2.5330383513858354

Epoch: 6| Step: 8
Training loss: 2.317676215360033
Validation loss: 2.5451787905292407

Epoch: 6| Step: 9
Training loss: 2.6510261780012194
Validation loss: 2.548712818173258

Epoch: 6| Step: 10
Training loss: 1.5461683104021362
Validation loss: 2.579019765003322

Epoch: 6| Step: 11
Training loss: 2.884917692335907
Validation loss: 2.608176422477595

Epoch: 6| Step: 12
Training loss: 2.2043203803862057
Validation loss: 2.6004190461825774

Epoch: 6| Step: 13
Training loss: 2.579284499706464
Validation loss: 2.644591938864462

Epoch: 295| Step: 0
Training loss: 2.033423566640061
Validation loss: 2.697099662608357

Epoch: 6| Step: 1
Training loss: 2.143727302987195
Validation loss: 2.6996021283718092

Epoch: 6| Step: 2
Training loss: 1.6308530887322708
Validation loss: 2.7262322372471197

Epoch: 6| Step: 3
Training loss: 1.9202853816253862
Validation loss: 2.6833037803238766

Epoch: 6| Step: 4
Training loss: 2.189269957422375
Validation loss: 2.622038123929521

Epoch: 6| Step: 5
Training loss: 2.276190804513595
Validation loss: 2.5843139653530804

Epoch: 6| Step: 6
Training loss: 1.6504653823444044
Validation loss: 2.575724206396344

Epoch: 6| Step: 7
Training loss: 1.8210507970823326
Validation loss: 2.569439075796573

Epoch: 6| Step: 8
Training loss: 2.206705741171418
Validation loss: 2.5637099890622332

Epoch: 6| Step: 9
Training loss: 2.354552133335805
Validation loss: 2.567369494156351

Epoch: 6| Step: 10
Training loss: 1.4992077642677395
Validation loss: 2.579986470529533

Epoch: 6| Step: 11
Training loss: 1.8417344148467587
Validation loss: 2.6424691646993965

Epoch: 6| Step: 12
Training loss: 2.4379118546972105
Validation loss: 2.6211729156166745

Epoch: 6| Step: 13
Training loss: 2.9829833296010446
Validation loss: 2.6943512902646813

Epoch: 296| Step: 0
Training loss: 1.3060654541776662
Validation loss: 2.69194415899141

Epoch: 6| Step: 1
Training loss: 1.943094544121415
Validation loss: 2.7061229244289238

Epoch: 6| Step: 2
Training loss: 1.0893667948025905
Validation loss: 2.7244020663459545

Epoch: 6| Step: 3
Training loss: 2.1491407318542315
Validation loss: 2.6846319020166547

Epoch: 6| Step: 4
Training loss: 2.0309689840918943
Validation loss: 2.6323189956782103

Epoch: 6| Step: 5
Training loss: 2.1555112596048307
Validation loss: 2.6369795606686828

Epoch: 6| Step: 6
Training loss: 2.454926430712823
Validation loss: 2.6216612124361056

Epoch: 6| Step: 7
Training loss: 3.06736524613921
Validation loss: 2.6034435234569453

Epoch: 6| Step: 8
Training loss: 2.2620240105957583
Validation loss: 2.5720619037954298

Epoch: 6| Step: 9
Training loss: 1.4746077581737824
Validation loss: 2.566841169923408

Epoch: 6| Step: 10
Training loss: 2.227028674129066
Validation loss: 2.5664729666590125

Epoch: 6| Step: 11
Training loss: 1.657845574281843
Validation loss: 2.580096683440265

Epoch: 6| Step: 12
Training loss: 2.632803172652478
Validation loss: 2.6421959472136214

Epoch: 6| Step: 13
Training loss: 1.8222949321062378
Validation loss: 2.680686831073616

Epoch: 297| Step: 0
Training loss: 1.9422457010351952
Validation loss: 2.7402184962426386

Epoch: 6| Step: 1
Training loss: 2.272888536800741
Validation loss: 2.7354068661988973

Epoch: 6| Step: 2
Training loss: 1.9634847320747926
Validation loss: 2.7539135944097177

Epoch: 6| Step: 3
Training loss: 1.9025390023483206
Validation loss: 2.669476888503341

Epoch: 6| Step: 4
Training loss: 1.8698554351331866
Validation loss: 2.616487491045374

Epoch: 6| Step: 5
Training loss: 1.9600456002828068
Validation loss: 2.597835815648111

Epoch: 6| Step: 6
Training loss: 1.1389670144915491
Validation loss: 2.5585115298195955

Epoch: 6| Step: 7
Training loss: 2.0698583716625287
Validation loss: 2.5500813215665055

Epoch: 6| Step: 8
Training loss: 1.7144214570707519
Validation loss: 2.553938589652736

Epoch: 6| Step: 9
Training loss: 2.6249329694636483
Validation loss: 2.571052367484837

Epoch: 6| Step: 10
Training loss: 1.7562676995631066
Validation loss: 2.5978358309440854

Epoch: 6| Step: 11
Training loss: 3.273513975137782
Validation loss: 2.590921276592171

Epoch: 6| Step: 12
Training loss: 2.097567821038209
Validation loss: 2.695183961908528

Epoch: 6| Step: 13
Training loss: 2.285508453093131
Validation loss: 2.7304620701785915

Epoch: 298| Step: 0
Training loss: 2.4312978234772706
Validation loss: 2.752308931039331

Epoch: 6| Step: 1
Training loss: 2.5052807348711155
Validation loss: 2.7422691688077454

Epoch: 6| Step: 2
Training loss: 1.7622877331332152
Validation loss: 2.683198206522135

Epoch: 6| Step: 3
Training loss: 2.792477181664987
Validation loss: 2.659189983286815

Epoch: 6| Step: 4
Training loss: 2.298748886829997
Validation loss: 2.590327628584658

Epoch: 6| Step: 5
Training loss: 2.1851248789701554
Validation loss: 2.5723290538184593

Epoch: 6| Step: 6
Training loss: 1.6093195933461544
Validation loss: 2.5469876441930452

Epoch: 6| Step: 7
Training loss: 1.3166009775909406
Validation loss: 2.5650122663168684

Epoch: 6| Step: 8
Training loss: 2.175098031125798
Validation loss: 2.558715475744303

Epoch: 6| Step: 9
Training loss: 2.3486950396187325
Validation loss: 2.5840051966852107

Epoch: 6| Step: 10
Training loss: 2.29801673798072
Validation loss: 2.630040536696217

Epoch: 6| Step: 11
Training loss: 1.7064762566314895
Validation loss: 2.684204624321757

Epoch: 6| Step: 12
Training loss: 1.8829741349229139
Validation loss: 2.6928764059614423

Epoch: 6| Step: 13
Training loss: 1.5113135294974827
Validation loss: 2.7144164263651267

Epoch: 299| Step: 0
Training loss: 2.1977236935721867
Validation loss: 2.730494130261752

Epoch: 6| Step: 1
Training loss: 2.8236546883069127
Validation loss: 2.7228230188596285

Epoch: 6| Step: 2
Training loss: 2.1641348816372767
Validation loss: 2.6747175083853314

Epoch: 6| Step: 3
Training loss: 1.672158119258646
Validation loss: 2.6563055294440825

Epoch: 6| Step: 4
Training loss: 1.3419504757937353
Validation loss: 2.625755201424462

Epoch: 6| Step: 5
Training loss: 2.09137830633648
Validation loss: 2.5970618846743463

Epoch: 6| Step: 6
Training loss: 2.0215118553763176
Validation loss: 2.5798725717209274

Epoch: 6| Step: 7
Training loss: 1.73095703125
Validation loss: 2.5398209128736253

Epoch: 6| Step: 8
Training loss: 2.4749928021567134
Validation loss: 2.5616243463502153

Epoch: 6| Step: 9
Training loss: 2.4805821670674892
Validation loss: 2.568047032383094

Epoch: 6| Step: 10
Training loss: 1.7784380216569258
Validation loss: 2.54336794734247

Epoch: 6| Step: 11
Training loss: 2.2642866719997286
Validation loss: 2.587657467877307

Epoch: 6| Step: 12
Training loss: 1.875030771638771
Validation loss: 2.6127476472915503

Epoch: 6| Step: 13
Training loss: 2.0219636358204065
Validation loss: 2.655377802049384

Epoch: 300| Step: 0
Training loss: 1.9211411974842938
Validation loss: 2.664155483021519

Epoch: 6| Step: 1
Training loss: 2.0872784708310776
Validation loss: 2.723647591619286

Epoch: 6| Step: 2
Training loss: 2.2416484330959032
Validation loss: 2.711090024968609

Epoch: 6| Step: 3
Training loss: 2.2003035639356714
Validation loss: 2.7637044628365253

Epoch: 6| Step: 4
Training loss: 2.0579820335723515
Validation loss: 2.7254534691119776

Epoch: 6| Step: 5
Training loss: 1.600361741419626
Validation loss: 2.6911713710365874

Epoch: 6| Step: 6
Training loss: 1.4896616703944663
Validation loss: 2.673189274976416

Epoch: 6| Step: 7
Training loss: 2.2537549792852
Validation loss: 2.6172665712169194

Epoch: 6| Step: 8
Training loss: 2.8794743095215027
Validation loss: 2.5484516591688937

Epoch: 6| Step: 9
Training loss: 1.7311106711830382
Validation loss: 2.5504278587598876

Epoch: 6| Step: 10
Training loss: 2.20161819333416
Validation loss: 2.539374041884568

Epoch: 6| Step: 11
Training loss: 1.8860237942526554
Validation loss: 2.5391102478232797

Epoch: 6| Step: 12
Training loss: 1.7331811043331509
Validation loss: 2.53198418350362

Epoch: 6| Step: 13
Training loss: 2.973511100495592
Validation loss: 2.5377508443485826

Epoch: 301| Step: 0
Training loss: 2.1719419619988707
Validation loss: 2.550565078556193

Epoch: 6| Step: 1
Training loss: 1.8640173651578098
Validation loss: 2.529868891187427

Epoch: 6| Step: 2
Training loss: 1.7989698058091845
Validation loss: 2.630254270448298

Epoch: 6| Step: 3
Training loss: 2.4330544647254224
Validation loss: 2.648614958122601

Epoch: 6| Step: 4
Training loss: 1.3904968374107305
Validation loss: 2.6956411704941874

Epoch: 6| Step: 5
Training loss: 2.2083928322124184
Validation loss: 2.717184354061143

Epoch: 6| Step: 6
Training loss: 2.3506989271633643
Validation loss: 2.759925457896857

Epoch: 6| Step: 7
Training loss: 2.083025782454426
Validation loss: 2.761254084019816

Epoch: 6| Step: 8
Training loss: 2.085188141711493
Validation loss: 2.7188373566255173

Epoch: 6| Step: 9
Training loss: 2.2132532507798115
Validation loss: 2.7143278441350405

Epoch: 6| Step: 10
Training loss: 2.1634544868028276
Validation loss: 2.6961462159653884

Epoch: 6| Step: 11
Training loss: 2.2189342798348757
Validation loss: 2.6988976559479787

Epoch: 6| Step: 12
Training loss: 1.8557633657959525
Validation loss: 2.6719203000755183

Epoch: 6| Step: 13
Training loss: 2.0986751873412115
Validation loss: 2.647422663610052

Epoch: 302| Step: 0
Training loss: 2.5037409449626415
Validation loss: 2.626157989608989

Epoch: 6| Step: 1
Training loss: 1.3425320273047452
Validation loss: 2.613948430842468

Epoch: 6| Step: 2
Training loss: 2.1990661026064706
Validation loss: 2.621349687962174

Epoch: 6| Step: 3
Training loss: 1.24755754265489
Validation loss: 2.657812743399054

Epoch: 6| Step: 4
Training loss: 1.5115878420588906
Validation loss: 2.675955795943663

Epoch: 6| Step: 5
Training loss: 2.1525714843789343
Validation loss: 2.6999741494153966

Epoch: 6| Step: 6
Training loss: 2.6824796049083974
Validation loss: 2.649956926559572

Epoch: 6| Step: 7
Training loss: 2.093890740518124
Validation loss: 2.6754589174391414

Epoch: 6| Step: 8
Training loss: 2.0187574782100146
Validation loss: 2.653431103484913

Epoch: 6| Step: 9
Training loss: 2.0387548455719284
Validation loss: 2.6727833830342678

Epoch: 6| Step: 10
Training loss: 1.9986887448045527
Validation loss: 2.6338912006772035

Epoch: 6| Step: 11
Training loss: 1.5625600421813406
Validation loss: 2.6372485271453

Epoch: 6| Step: 12
Training loss: 2.688059903748906
Validation loss: 2.6139119009297045

Epoch: 6| Step: 13
Training loss: 1.8449887785531545
Validation loss: 2.605091485157838

Epoch: 303| Step: 0
Training loss: 1.5893550937259542
Validation loss: 2.5772388052602726

Epoch: 6| Step: 1
Training loss: 1.6566658217788066
Validation loss: 2.5789026185813

Epoch: 6| Step: 2
Training loss: 2.498770029771073
Validation loss: 2.604300630302691

Epoch: 6| Step: 3
Training loss: 1.5616688615884626
Validation loss: 2.6272008691602364

Epoch: 6| Step: 4
Training loss: 2.318078092304637
Validation loss: 2.665550942266127

Epoch: 6| Step: 5
Training loss: 2.0594903198740773
Validation loss: 2.703757636508748

Epoch: 6| Step: 6
Training loss: 2.9115756880709323
Validation loss: 2.6852991274218034

Epoch: 6| Step: 7
Training loss: 1.546575498004094
Validation loss: 2.664970280575204

Epoch: 6| Step: 8
Training loss: 2.493939683626861
Validation loss: 2.663377854719509

Epoch: 6| Step: 9
Training loss: 2.1982785208778215
Validation loss: 2.655251244165443

Epoch: 6| Step: 10
Training loss: 2.358951555868015
Validation loss: 2.615866301969748

Epoch: 6| Step: 11
Training loss: 1.4997334243410372
Validation loss: 2.709975204659328

Epoch: 6| Step: 12
Training loss: 1.602614936218012
Validation loss: 2.7173832640598046

Epoch: 6| Step: 13
Training loss: 2.079685285124255
Validation loss: 2.718045636718131

Epoch: 304| Step: 0
Training loss: 1.8040728162123305
Validation loss: 2.7321570856416635

Epoch: 6| Step: 1
Training loss: 1.739657904878738
Validation loss: 2.6751206076697223

Epoch: 6| Step: 2
Training loss: 1.5795438072889583
Validation loss: 2.677627602156636

Epoch: 6| Step: 3
Training loss: 0.9948505497360494
Validation loss: 2.657052879914701

Epoch: 6| Step: 4
Training loss: 1.92880006222086
Validation loss: 2.644961916980473

Epoch: 6| Step: 5
Training loss: 2.38039678471713
Validation loss: 2.641883535137457

Epoch: 6| Step: 6
Training loss: 1.9943454200131412
Validation loss: 2.620180519524374

Epoch: 6| Step: 7
Training loss: 1.3890853244893013
Validation loss: 2.6512763188704596

Epoch: 6| Step: 8
Training loss: 1.8982906834224074
Validation loss: 2.6641148984348213

Epoch: 6| Step: 9
Training loss: 1.738829931181176
Validation loss: 2.6698515965798566

Epoch: 6| Step: 10
Training loss: 2.2230743390419354
Validation loss: 2.691108395538969

Epoch: 6| Step: 11
Training loss: 1.9978546318577337
Validation loss: 2.7046260965606614

Epoch: 6| Step: 12
Training loss: 2.5636289017234835
Validation loss: 2.6786574746495244

Epoch: 6| Step: 13
Training loss: 3.176506081758883
Validation loss: 2.6752541424298237

Epoch: 305| Step: 0
Training loss: 2.4502118544554197
Validation loss: 2.6451882504618203

Epoch: 6| Step: 1
Training loss: 1.7065617594414337
Validation loss: 2.6378936259913894

Epoch: 6| Step: 2
Training loss: 2.0248033781315096
Validation loss: 2.62276146823217

Epoch: 6| Step: 3
Training loss: 1.6968400814615512
Validation loss: 2.5857151393040927

Epoch: 6| Step: 4
Training loss: 1.503733122137138
Validation loss: 2.5671504861025007

Epoch: 6| Step: 5
Training loss: 2.283908183649052
Validation loss: 2.5844927206293

Epoch: 6| Step: 6
Training loss: 1.9449596774474176
Validation loss: 2.5780475335090594

Epoch: 6| Step: 7
Training loss: 2.474674504001857
Validation loss: 2.574084435192309

Epoch: 6| Step: 8
Training loss: 1.6916568561639052
Validation loss: 2.6204804234920145

Epoch: 6| Step: 9
Training loss: 2.1572100948259525
Validation loss: 2.6373706605122433

Epoch: 6| Step: 10
Training loss: 1.6997244948246422
Validation loss: 2.664515437219776

Epoch: 6| Step: 11
Training loss: 1.7117295892077153
Validation loss: 2.6572657344743584

Epoch: 6| Step: 12
Training loss: 2.8172186368976577
Validation loss: 2.6396954497322294

Epoch: 6| Step: 13
Training loss: 1.9763098996354223
Validation loss: 2.6098149551185283

Epoch: 306| Step: 0
Training loss: 2.1477016229093286
Validation loss: 2.6141346524943128

Epoch: 6| Step: 1
Training loss: 2.4194514792634827
Validation loss: 2.6200959399908372

Epoch: 6| Step: 2
Training loss: 2.034558931582357
Validation loss: 2.6372723937697105

Epoch: 6| Step: 3
Training loss: 2.3585586651381374
Validation loss: 2.642237139174833

Epoch: 6| Step: 4
Training loss: 1.6391760831302864
Validation loss: 2.735736326398971

Epoch: 6| Step: 5
Training loss: 1.9692468773058107
Validation loss: 2.7782941105237806

Epoch: 6| Step: 6
Training loss: 2.1298961332902446
Validation loss: 2.7299825501961377

Epoch: 6| Step: 7
Training loss: 2.5485757403181455
Validation loss: 2.6823838498962833

Epoch: 6| Step: 8
Training loss: 2.0510497871058644
Validation loss: 2.6919917635647597

Epoch: 6| Step: 9
Training loss: 1.9448882716628504
Validation loss: 2.680549816483419

Epoch: 6| Step: 10
Training loss: 1.6281079868006176
Validation loss: 2.6856155886095676

Epoch: 6| Step: 11
Training loss: 1.5390085898315173
Validation loss: 2.641532847227028

Epoch: 6| Step: 12
Training loss: 1.8913490863467168
Validation loss: 2.5975463538000576

Epoch: 6| Step: 13
Training loss: 1.729435804019863
Validation loss: 2.614147276566786

Epoch: 307| Step: 0
Training loss: 1.4106215874221215
Validation loss: 2.5938684214326457

Epoch: 6| Step: 1
Training loss: 2.391727367875798
Validation loss: 2.6038600639415557

Epoch: 6| Step: 2
Training loss: 1.5977501130453948
Validation loss: 2.6585397163883977

Epoch: 6| Step: 3
Training loss: 2.491095133100742
Validation loss: 2.654689599766611

Epoch: 6| Step: 4
Training loss: 2.5182497535871318
Validation loss: 2.6736200668273042

Epoch: 6| Step: 5
Training loss: 2.367157687260699
Validation loss: 2.6969062994904744

Epoch: 6| Step: 6
Training loss: 1.9008909470544026
Validation loss: 2.7107749985536627

Epoch: 6| Step: 7
Training loss: 1.8636794074727259
Validation loss: 2.7184324992615845

Epoch: 6| Step: 8
Training loss: 1.5633563937266999
Validation loss: 2.689063098175201

Epoch: 6| Step: 9
Training loss: 2.0242106606466477
Validation loss: 2.642435961440297

Epoch: 6| Step: 10
Training loss: 2.1520909543439477
Validation loss: 2.618124768404428

Epoch: 6| Step: 11
Training loss: 1.8586233847822293
Validation loss: 2.6639925890686773

Epoch: 6| Step: 12
Training loss: 2.0671408488689154
Validation loss: 2.6177706547969257

Epoch: 6| Step: 13
Training loss: 1.8004095724163673
Validation loss: 2.6783517635433776

Epoch: 308| Step: 0
Training loss: 2.726531545031571
Validation loss: 2.6802940757212816

Epoch: 6| Step: 1
Training loss: 1.9259932519313212
Validation loss: 2.7013316149770477

Epoch: 6| Step: 2
Training loss: 1.6734299603460665
Validation loss: 2.7232296165255137

Epoch: 6| Step: 3
Training loss: 1.7654892185630664
Validation loss: 2.6944250590051997

Epoch: 6| Step: 4
Training loss: 1.4479045821675853
Validation loss: 2.725511816646377

Epoch: 6| Step: 5
Training loss: 1.9404765614423696
Validation loss: 2.7008224117815836

Epoch: 6| Step: 6
Training loss: 1.5111516633077642
Validation loss: 2.6322277261093108

Epoch: 6| Step: 7
Training loss: 1.7547113486594477
Validation loss: 2.64523270064717

Epoch: 6| Step: 8
Training loss: 2.0229138024333104
Validation loss: 2.569025198495484

Epoch: 6| Step: 9
Training loss: 1.70257888577576
Validation loss: 2.5619859257315696

Epoch: 6| Step: 10
Training loss: 2.3175300329540067
Validation loss: 2.5706030653384007

Epoch: 6| Step: 11
Training loss: 1.7844572138510875
Validation loss: 2.5606881458409867

Epoch: 6| Step: 12
Training loss: 2.2243064828230863
Validation loss: 2.5831614149990982

Epoch: 6| Step: 13
Training loss: 2.6939119542551966
Validation loss: 2.5972687166872297

Epoch: 309| Step: 0
Training loss: 1.9803750281193968
Validation loss: 2.5973215752795022

Epoch: 6| Step: 1
Training loss: 1.5800729192735243
Validation loss: 2.5952840198329863

Epoch: 6| Step: 2
Training loss: 1.2026874687957245
Validation loss: 2.6190587276784627

Epoch: 6| Step: 3
Training loss: 2.387014517431137
Validation loss: 2.6249146674682335

Epoch: 6| Step: 4
Training loss: 1.7670107779268616
Validation loss: 2.6292462443194675

Epoch: 6| Step: 5
Training loss: 1.654485518363595
Validation loss: 2.674738058295843

Epoch: 6| Step: 6
Training loss: 1.8405359347026513
Validation loss: 2.683495443395332

Epoch: 6| Step: 7
Training loss: 2.940770702421178
Validation loss: 2.680382315045288

Epoch: 6| Step: 8
Training loss: 1.9061304273781365
Validation loss: 2.680564788666297

Epoch: 6| Step: 9
Training loss: 2.0992859489267603
Validation loss: 2.681026854340149

Epoch: 6| Step: 10
Training loss: 1.1997671457708137
Validation loss: 2.695958156928837

Epoch: 6| Step: 11
Training loss: 1.606805398116898
Validation loss: 2.653173497583875

Epoch: 6| Step: 12
Training loss: 2.19654957950801
Validation loss: 2.67044891907759

Epoch: 6| Step: 13
Training loss: 2.872013365159243
Validation loss: 2.653577993996401

Epoch: 310| Step: 0
Training loss: 2.811397675553247
Validation loss: 2.632589962814723

Epoch: 6| Step: 1
Training loss: 1.5370001748059483
Validation loss: 2.6535496018880016

Epoch: 6| Step: 2
Training loss: 2.1729816937858266
Validation loss: 2.6473115386140993

Epoch: 6| Step: 3
Training loss: 1.840195413661665
Validation loss: 2.677455836601777

Epoch: 6| Step: 4
Training loss: 1.6172368875969432
Validation loss: 2.702176921893334

Epoch: 6| Step: 5
Training loss: 1.6810963954030735
Validation loss: 2.7137778259331413

Epoch: 6| Step: 6
Training loss: 1.9905627038810596
Validation loss: 2.736557298566542

Epoch: 6| Step: 7
Training loss: 2.0143848714607326
Validation loss: 2.7163879393914114

Epoch: 6| Step: 8
Training loss: 1.8523638315129902
Validation loss: 2.6815502932254796

Epoch: 6| Step: 9
Training loss: 2.760698402470483
Validation loss: 2.6702982691398094

Epoch: 6| Step: 10
Training loss: 1.6475428463077741
Validation loss: 2.66574918838532

Epoch: 6| Step: 11
Training loss: 1.969978131109935
Validation loss: 2.624524467023302

Epoch: 6| Step: 12
Training loss: 1.647106265889424
Validation loss: 2.64743314020434

Epoch: 6| Step: 13
Training loss: 2.0291596440605613
Validation loss: 2.661518168414443

Epoch: 311| Step: 0
Training loss: 2.015677754502827
Validation loss: 2.632804998883316

Epoch: 6| Step: 1
Training loss: 1.8377974807859816
Validation loss: 2.663647541979813

Epoch: 6| Step: 2
Training loss: 1.1607244365374036
Validation loss: 2.6666208998408485

Epoch: 6| Step: 3
Training loss: 2.8430552210266913
Validation loss: 2.655847870549838

Epoch: 6| Step: 4
Training loss: 1.3382991863057567
Validation loss: 2.638250837375741

Epoch: 6| Step: 5
Training loss: 1.9206278406253146
Validation loss: 2.650079283937786

Epoch: 6| Step: 6
Training loss: 1.867089049485127
Validation loss: 2.644466487630587

Epoch: 6| Step: 7
Training loss: 1.9238995069244498
Validation loss: 2.6753328045035643

Epoch: 6| Step: 8
Training loss: 2.2648856173300724
Validation loss: 2.7279220878469905

Epoch: 6| Step: 9
Training loss: 1.5056037339497639
Validation loss: 2.7132336129867913

Epoch: 6| Step: 10
Training loss: 2.2288202985202066
Validation loss: 2.7262132743450147

Epoch: 6| Step: 11
Training loss: 2.2707843833570465
Validation loss: 2.7285964069136166

Epoch: 6| Step: 12
Training loss: 1.4309647488254145
Validation loss: 2.693854412111642

Epoch: 6| Step: 13
Training loss: 2.5626154617720798
Validation loss: 2.692979313234204

Epoch: 312| Step: 0
Training loss: 1.4882498510057223
Validation loss: 2.657160771125698

Epoch: 6| Step: 1
Training loss: 2.1423734777565233
Validation loss: 2.5813058516130427

Epoch: 6| Step: 2
Training loss: 1.577105882383506
Validation loss: 2.5494485346064737

Epoch: 6| Step: 3
Training loss: 2.25443170461893
Validation loss: 2.5680384446293796

Epoch: 6| Step: 4
Training loss: 2.166344166253686
Validation loss: 2.567500577392315

Epoch: 6| Step: 5
Training loss: 1.5677037371022047
Validation loss: 2.5880465401759527

Epoch: 6| Step: 6
Training loss: 1.4426462685723018
Validation loss: 2.563347870033559

Epoch: 6| Step: 7
Training loss: 2.2788960056120446
Validation loss: 2.595559833093425

Epoch: 6| Step: 8
Training loss: 2.124836859331081
Validation loss: 2.644182370950025

Epoch: 6| Step: 9
Training loss: 2.5574250558740435
Validation loss: 2.7549621000873468

Epoch: 6| Step: 10
Training loss: 2.254843373240789
Validation loss: 2.8082310668330623

Epoch: 6| Step: 11
Training loss: 1.9022108967662779
Validation loss: 2.8233278029101303

Epoch: 6| Step: 12
Training loss: 2.7246250384574404
Validation loss: 2.848814391708033

Epoch: 6| Step: 13
Training loss: 1.6866676255677002
Validation loss: 2.790515368089096

Epoch: 313| Step: 0
Training loss: 1.5705696768377537
Validation loss: 2.778017344210781

Epoch: 6| Step: 1
Training loss: 2.0259924116905728
Validation loss: 2.7351248739259466

Epoch: 6| Step: 2
Training loss: 1.7163143586540806
Validation loss: 2.6749594212956977

Epoch: 6| Step: 3
Training loss: 1.8999288219370545
Validation loss: 2.6142620228659985

Epoch: 6| Step: 4
Training loss: 1.6956371928141176
Validation loss: 2.614355735954062

Epoch: 6| Step: 5
Training loss: 1.9758710292511525
Validation loss: 2.577885564609572

Epoch: 6| Step: 6
Training loss: 2.7071850225196625
Validation loss: 2.5945059812119915

Epoch: 6| Step: 7
Training loss: 2.1030696867290843
Validation loss: 2.594631504877505

Epoch: 6| Step: 8
Training loss: 2.603240425692322
Validation loss: 2.586364004069384

Epoch: 6| Step: 9
Training loss: 2.8463454925507317
Validation loss: 2.6603516867719548

Epoch: 6| Step: 10
Training loss: 1.5091055430113263
Validation loss: 2.7069393434101876

Epoch: 6| Step: 11
Training loss: 2.2071389501169363
Validation loss: 2.7740064297120037

Epoch: 6| Step: 12
Training loss: 1.6515933377681036
Validation loss: 2.797255974933933

Epoch: 6| Step: 13
Training loss: 2.28691714005846
Validation loss: 2.7577595187853365

Epoch: 314| Step: 0
Training loss: 1.6132833189870208
Validation loss: 2.7606911192917014

Epoch: 6| Step: 1
Training loss: 1.7854481130862683
Validation loss: 2.7014540577545736

Epoch: 6| Step: 2
Training loss: 2.8688737032280183
Validation loss: 2.6345115936935457

Epoch: 6| Step: 3
Training loss: 2.1914203935734533
Validation loss: 2.633160486061422

Epoch: 6| Step: 4
Training loss: 2.1115571214563085
Validation loss: 2.629187150886486

Epoch: 6| Step: 5
Training loss: 1.5034215368939063
Validation loss: 2.6519721795757003

Epoch: 6| Step: 6
Training loss: 1.8078183186403631
Validation loss: 2.6265366310360094

Epoch: 6| Step: 7
Training loss: 1.6096902186749027
Validation loss: 2.6574906985819005

Epoch: 6| Step: 8
Training loss: 1.4588622995803828
Validation loss: 2.634988898338949

Epoch: 6| Step: 9
Training loss: 3.115647014207269
Validation loss: 2.652387466032945

Epoch: 6| Step: 10
Training loss: 2.236187393224724
Validation loss: 2.6837951569769887

Epoch: 6| Step: 11
Training loss: 1.7385414186008552
Validation loss: 2.6421366019885704

Epoch: 6| Step: 12
Training loss: 1.737388124226035
Validation loss: 2.7160008587767974

Epoch: 6| Step: 13
Training loss: 1.8336875602217415
Validation loss: 2.6966114986640877

Epoch: 315| Step: 0
Training loss: 2.2751158716226043
Validation loss: 2.6953182496824994

Epoch: 6| Step: 1
Training loss: 1.768562910881282
Validation loss: 2.687013552502933

Epoch: 6| Step: 2
Training loss: 2.333786806818518
Validation loss: 2.698068155481196

Epoch: 6| Step: 3
Training loss: 1.966256757895563
Validation loss: 2.718725935146186

Epoch: 6| Step: 4
Training loss: 2.2340562499707675
Validation loss: 2.669671799232038

Epoch: 6| Step: 5
Training loss: 2.0530100890449163
Validation loss: 2.6358944958531327

Epoch: 6| Step: 6
Training loss: 2.3745813502700415
Validation loss: 2.6302281042180553

Epoch: 6| Step: 7
Training loss: 1.89865776636595
Validation loss: 2.6412064102217925

Epoch: 6| Step: 8
Training loss: 2.070413032825905
Validation loss: 2.591604272105641

Epoch: 6| Step: 9
Training loss: 1.7570727338765941
Validation loss: 2.6266797610100125

Epoch: 6| Step: 10
Training loss: 1.766779496830471
Validation loss: 2.63157958490799

Epoch: 6| Step: 11
Training loss: 2.1689137641573764
Validation loss: 2.6406316061144177

Epoch: 6| Step: 12
Training loss: 1.4728034069898361
Validation loss: 2.6427566682281967

Epoch: 6| Step: 13
Training loss: 1.490704103686142
Validation loss: 2.7100521551136385

Epoch: 316| Step: 0
Training loss: 1.8886260507383636
Validation loss: 2.6642121005447454

Epoch: 6| Step: 1
Training loss: 2.2933598823267407
Validation loss: 2.6664606600900114

Epoch: 6| Step: 2
Training loss: 2.4038023947620912
Validation loss: 2.6551179306026915

Epoch: 6| Step: 3
Training loss: 1.2562935228542296
Validation loss: 2.6168340795460954

Epoch: 6| Step: 4
Training loss: 1.8557418461645798
Validation loss: 2.685101333188292

Epoch: 6| Step: 5
Training loss: 2.607182752524229
Validation loss: 2.6375532925300442

Epoch: 6| Step: 6
Training loss: 1.982620003857687
Validation loss: 2.635152574859508

Epoch: 6| Step: 7
Training loss: 1.4905415189706694
Validation loss: 2.6453817587939796

Epoch: 6| Step: 8
Training loss: 2.2639062083803334
Validation loss: 2.6317737390343736

Epoch: 6| Step: 9
Training loss: 1.730488107542866
Validation loss: 2.6099326933054026

Epoch: 6| Step: 10
Training loss: 1.3844796599701834
Validation loss: 2.620917172650088

Epoch: 6| Step: 11
Training loss: 1.8645093537328985
Validation loss: 2.6265070388750944

Epoch: 6| Step: 12
Training loss: 1.44719017336637
Validation loss: 2.6576833111618057

Epoch: 6| Step: 13
Training loss: 2.731001074858838
Validation loss: 2.654061511684952

Epoch: 317| Step: 0
Training loss: 1.8018787539863448
Validation loss: 2.635337260461042

Epoch: 6| Step: 1
Training loss: 2.060939429617001
Validation loss: 2.713395015295067

Epoch: 6| Step: 2
Training loss: 1.809771292447249
Validation loss: 2.7541615469265057

Epoch: 6| Step: 3
Training loss: 1.8905310489230636
Validation loss: 2.747606391732773

Epoch: 6| Step: 4
Training loss: 2.160534789321084
Validation loss: 2.7084799995812996

Epoch: 6| Step: 5
Training loss: 1.131798968233864
Validation loss: 2.7022833055800115

Epoch: 6| Step: 6
Training loss: 1.9182566253853943
Validation loss: 2.672743301141049

Epoch: 6| Step: 7
Training loss: 1.9854363434154425
Validation loss: 2.685071158149931

Epoch: 6| Step: 8
Training loss: 1.5140262312034005
Validation loss: 2.6585838985045736

Epoch: 6| Step: 9
Training loss: 2.2064912658698344
Validation loss: 2.6899741708538842

Epoch: 6| Step: 10
Training loss: 1.9722261772056409
Validation loss: 2.657457025084182

Epoch: 6| Step: 11
Training loss: 2.1958554502624406
Validation loss: 2.6342258301024

Epoch: 6| Step: 12
Training loss: 2.4073658127193713
Validation loss: 2.6805288404627947

Epoch: 6| Step: 13
Training loss: 2.2519666765637356
Validation loss: 2.6945320363134377

Epoch: 318| Step: 0
Training loss: 1.234979988275782
Validation loss: 2.707844959144463

Epoch: 6| Step: 1
Training loss: 2.0991287603990316
Validation loss: 2.74046787636553

Epoch: 6| Step: 2
Training loss: 1.4985781924772914
Validation loss: 2.7363225631421364

Epoch: 6| Step: 3
Training loss: 2.042203508239907
Validation loss: 2.691289152671778

Epoch: 6| Step: 4
Training loss: 2.0701544935282477
Validation loss: 2.6448300679741763

Epoch: 6| Step: 5
Training loss: 1.574565234047015
Validation loss: 2.657281548154182

Epoch: 6| Step: 6
Training loss: 1.395078236563388
Validation loss: 2.67009355969281

Epoch: 6| Step: 7
Training loss: 2.692255647386821
Validation loss: 2.608886231352113

Epoch: 6| Step: 8
Training loss: 1.971778538395458
Validation loss: 2.6110406002597575

Epoch: 6| Step: 9
Training loss: 1.9109464231892543
Validation loss: 2.6453675638571497

Epoch: 6| Step: 10
Training loss: 2.3499640928731163
Validation loss: 2.6825965683363027

Epoch: 6| Step: 11
Training loss: 2.0603307240005773
Validation loss: 2.75355300261019

Epoch: 6| Step: 12
Training loss: 2.2536989113364245
Validation loss: 2.7642170973708446

Epoch: 6| Step: 13
Training loss: 2.316271824659284
Validation loss: 2.8004341140912654

Epoch: 319| Step: 0
Training loss: 1.7809073804646829
Validation loss: 2.797594713068508

Epoch: 6| Step: 1
Training loss: 1.8211065696942597
Validation loss: 2.748468969879504

Epoch: 6| Step: 2
Training loss: 1.9038229954251382
Validation loss: 2.6855299330668254

Epoch: 6| Step: 3
Training loss: 1.699704436245685
Validation loss: 2.6705671236275133

Epoch: 6| Step: 4
Training loss: 1.606694331478358
Validation loss: 2.6121539548364487

Epoch: 6| Step: 5
Training loss: 2.870220357696147
Validation loss: 2.587650050851151

Epoch: 6| Step: 6
Training loss: 2.3164282760730837
Validation loss: 2.5890294363166393

Epoch: 6| Step: 7
Training loss: 1.7695870969603722
Validation loss: 2.57375021545597

Epoch: 6| Step: 8
Training loss: 2.1314355226912536
Validation loss: 2.5674614674797764

Epoch: 6| Step: 9
Training loss: 2.1556359121522584
Validation loss: 2.5929708114758347

Epoch: 6| Step: 10
Training loss: 2.4487215599133805
Validation loss: 2.6452067201378173

Epoch: 6| Step: 11
Training loss: 1.4025797950769958
Validation loss: 2.7190720086120894

Epoch: 6| Step: 12
Training loss: 2.100596606565769
Validation loss: 2.7939691205895354

Epoch: 6| Step: 13
Training loss: 1.9999105910343462
Validation loss: 2.8164287818434186

Epoch: 320| Step: 0
Training loss: 2.2919385113016015
Validation loss: 2.766881107920731

Epoch: 6| Step: 1
Training loss: 2.0763593931736293
Validation loss: 2.798496380187781

Epoch: 6| Step: 2
Training loss: 1.2996070304553637
Validation loss: 2.7343183529753605

Epoch: 6| Step: 3
Training loss: 2.0459519263219645
Validation loss: 2.7066838352084805

Epoch: 6| Step: 4
Training loss: 1.8010879884245299
Validation loss: 2.598100361349705

Epoch: 6| Step: 5
Training loss: 2.2510121506134686
Validation loss: 2.569227289067592

Epoch: 6| Step: 6
Training loss: 2.107425042716572
Validation loss: 2.5972373988024895

Epoch: 6| Step: 7
Training loss: 2.0542499961226297
Validation loss: 2.554103936321675

Epoch: 6| Step: 8
Training loss: 2.6938266362664365
Validation loss: 2.5591441098851213

Epoch: 6| Step: 9
Training loss: 1.6698309265712323
Validation loss: 2.569237744262443

Epoch: 6| Step: 10
Training loss: 1.5899277273582773
Validation loss: 2.5738910317868897

Epoch: 6| Step: 11
Training loss: 1.9717288415005008
Validation loss: 2.584027386819405

Epoch: 6| Step: 12
Training loss: 2.432389207690749
Validation loss: 2.6321889287908578

Epoch: 6| Step: 13
Training loss: 1.689686665352216
Validation loss: 2.6615690194620747

Epoch: 321| Step: 0
Training loss: 1.7204463563652936
Validation loss: 2.6880810870862004

Epoch: 6| Step: 1
Training loss: 2.5098938667989956
Validation loss: 2.707943320925062

Epoch: 6| Step: 2
Training loss: 2.6770494115043415
Validation loss: 2.712768537293089

Epoch: 6| Step: 3
Training loss: 2.3602291354782587
Validation loss: 2.678189139560674

Epoch: 6| Step: 4
Training loss: 1.1400895102813429
Validation loss: 2.672359325987541

Epoch: 6| Step: 5
Training loss: 1.5945756307029968
Validation loss: 2.6599637567350354

Epoch: 6| Step: 6
Training loss: 2.1979306719244867
Validation loss: 2.6317791670206736

Epoch: 6| Step: 7
Training loss: 1.5326590769412392
Validation loss: 2.5948262796705692

Epoch: 6| Step: 8
Training loss: 2.135739061783264
Validation loss: 2.6294243327098683

Epoch: 6| Step: 9
Training loss: 1.5444539708286624
Validation loss: 2.6553974653437975

Epoch: 6| Step: 10
Training loss: 2.379055676206831
Validation loss: 2.654904604501295

Epoch: 6| Step: 11
Training loss: 1.5777443908388602
Validation loss: 2.6780256302632437

Epoch: 6| Step: 12
Training loss: 1.2824143957082053
Validation loss: 2.668091234529798

Epoch: 6| Step: 13
Training loss: 2.279919589113771
Validation loss: 2.648505691055541

Epoch: 322| Step: 0
Training loss: 1.8055757260622347
Validation loss: 2.6682341161132594

Epoch: 6| Step: 1
Training loss: 1.1577403798981463
Validation loss: 2.6449603094717755

Epoch: 6| Step: 2
Training loss: 1.9174657344616286
Validation loss: 2.6137304447414915

Epoch: 6| Step: 3
Training loss: 1.533773328359662
Validation loss: 2.6184761329025945

Epoch: 6| Step: 4
Training loss: 1.648365760435402
Validation loss: 2.6421211112517566

Epoch: 6| Step: 5
Training loss: 1.8173353218707715
Validation loss: 2.5947731788208377

Epoch: 6| Step: 6
Training loss: 1.9592356192676905
Validation loss: 2.624858806990878

Epoch: 6| Step: 7
Training loss: 2.3120092953887776
Validation loss: 2.6150661544503797

Epoch: 6| Step: 8
Training loss: 2.594030525939669
Validation loss: 2.632894905226985

Epoch: 6| Step: 9
Training loss: 2.4810476033180864
Validation loss: 2.6091187402674527

Epoch: 6| Step: 10
Training loss: 1.9294547739889563
Validation loss: 2.630950480589687

Epoch: 6| Step: 11
Training loss: 2.1686502571145736
Validation loss: 2.667051739506802

Epoch: 6| Step: 12
Training loss: 1.8465149400996546
Validation loss: 2.6675321743999154

Epoch: 6| Step: 13
Training loss: 1.65546384183292
Validation loss: 2.6844644036465057

Epoch: 323| Step: 0
Training loss: 2.5309713704793335
Validation loss: 2.6298582290952828

Epoch: 6| Step: 1
Training loss: 1.045392253211076
Validation loss: 2.655614739542827

Epoch: 6| Step: 2
Training loss: 1.7191574307352488
Validation loss: 2.659655082647609

Epoch: 6| Step: 3
Training loss: 2.048001045152278
Validation loss: 2.646071480874233

Epoch: 6| Step: 4
Training loss: 1.365801037369129
Validation loss: 2.6383966377199863

Epoch: 6| Step: 5
Training loss: 2.1306984733161785
Validation loss: 2.610638706499155

Epoch: 6| Step: 6
Training loss: 1.486164500068767
Validation loss: 2.594797298303284

Epoch: 6| Step: 7
Training loss: 1.9344024508351088
Validation loss: 2.6047049360296186

Epoch: 6| Step: 8
Training loss: 3.039877657185285
Validation loss: 2.5987104451843726

Epoch: 6| Step: 9
Training loss: 1.8426855861826092
Validation loss: 2.6200327120866977

Epoch: 6| Step: 10
Training loss: 1.6252271053366352
Validation loss: 2.6403091512634664

Epoch: 6| Step: 11
Training loss: 1.8354303836490355
Validation loss: 2.6384618502860016

Epoch: 6| Step: 12
Training loss: 1.4744276326331076
Validation loss: 2.6843325409142174

Epoch: 6| Step: 13
Training loss: 2.425324377014389
Validation loss: 2.653667136653684

Epoch: 324| Step: 0
Training loss: 2.579094721746418
Validation loss: 2.6616541472562365

Epoch: 6| Step: 1
Training loss: 1.2534176834278503
Validation loss: 2.677185402988803

Epoch: 6| Step: 2
Training loss: 1.4017311394492296
Validation loss: 2.6981018375983954

Epoch: 6| Step: 3
Training loss: 2.1246096308561278
Validation loss: 2.6927731701087168

Epoch: 6| Step: 4
Training loss: 1.4539696484353335
Validation loss: 2.7059075911983954

Epoch: 6| Step: 5
Training loss: 1.7413415608428333
Validation loss: 2.700999326382661

Epoch: 6| Step: 6
Training loss: 1.3174869617779736
Validation loss: 2.644819340680656

Epoch: 6| Step: 7
Training loss: 2.2245185974194266
Validation loss: 2.6392596324578537

Epoch: 6| Step: 8
Training loss: 2.23647012717826
Validation loss: 2.6071732877608924

Epoch: 6| Step: 9
Training loss: 2.762740015158397
Validation loss: 2.619726682025093

Epoch: 6| Step: 10
Training loss: 1.9560270797906631
Validation loss: 2.60721058269209

Epoch: 6| Step: 11
Training loss: 1.7285957619576813
Validation loss: 2.609174739744339

Epoch: 6| Step: 12
Training loss: 1.5213424753560219
Validation loss: 2.6189315981784054

Epoch: 6| Step: 13
Training loss: 2.3434119425793005
Validation loss: 2.6014998603130115

Epoch: 325| Step: 0
Training loss: 1.5312842540412948
Validation loss: 2.6375141517054606

Epoch: 6| Step: 1
Training loss: 2.1591600324891247
Validation loss: 2.676377828135585

Epoch: 6| Step: 2
Training loss: 1.5107410827908856
Validation loss: 2.7306930166108763

Epoch: 6| Step: 3
Training loss: 2.4004253884662323
Validation loss: 2.7512601075022145

Epoch: 6| Step: 4
Training loss: 1.721212738121356
Validation loss: 2.746718073887739

Epoch: 6| Step: 5
Training loss: 2.3601513526358078
Validation loss: 2.7002395635454444

Epoch: 6| Step: 6
Training loss: 1.9518966474257944
Validation loss: 2.712183567933149

Epoch: 6| Step: 7
Training loss: 1.6796833126991775
Validation loss: 2.685606119138193

Epoch: 6| Step: 8
Training loss: 1.991602613570963
Validation loss: 2.6475089441832167

Epoch: 6| Step: 9
Training loss: 2.163273746784681
Validation loss: 2.6119477158260156

Epoch: 6| Step: 10
Training loss: 1.5091217365594551
Validation loss: 2.5972641115896087

Epoch: 6| Step: 11
Training loss: 2.240985401914577
Validation loss: 2.623673361134057

Epoch: 6| Step: 12
Training loss: 2.0754466759529433
Validation loss: 2.593239469725447

Epoch: 6| Step: 13
Training loss: 1.962439581068544
Validation loss: 2.5880181124012607

Epoch: 326| Step: 0
Training loss: 1.6711992698622187
Validation loss: 2.623587515932277

Epoch: 6| Step: 1
Training loss: 2.0831369180278303
Validation loss: 2.6207997687353073

Epoch: 6| Step: 2
Training loss: 1.4198051730003538
Validation loss: 2.658748244748465

Epoch: 6| Step: 3
Training loss: 2.1820898455855944
Validation loss: 2.66953549941531

Epoch: 6| Step: 4
Training loss: 1.8849068544277656
Validation loss: 2.6698640539442415

Epoch: 6| Step: 5
Training loss: 1.6127413014686038
Validation loss: 2.709952102967488

Epoch: 6| Step: 6
Training loss: 1.7459031242071281
Validation loss: 2.7113061337297526

Epoch: 6| Step: 7
Training loss: 2.5172136870146224
Validation loss: 2.6357753544751543

Epoch: 6| Step: 8
Training loss: 1.7472007707021222
Validation loss: 2.666876789596335

Epoch: 6| Step: 9
Training loss: 2.679806987445125
Validation loss: 2.6238172833698257

Epoch: 6| Step: 10
Training loss: 1.629583350682029
Validation loss: 2.631469368870091

Epoch: 6| Step: 11
Training loss: 2.515946456557775
Validation loss: 2.6200388392998484

Epoch: 6| Step: 12
Training loss: 2.0175065122969604
Validation loss: 2.5860086606041217

Epoch: 6| Step: 13
Training loss: 1.8862065158935712
Validation loss: 2.631139297150016

Epoch: 327| Step: 0
Training loss: 1.59400369457549
Validation loss: 2.6152678096534228

Epoch: 6| Step: 1
Training loss: 2.0234617725227326
Validation loss: 2.650101610550868

Epoch: 6| Step: 2
Training loss: 2.4025920460481607
Validation loss: 2.6522010161806544

Epoch: 6| Step: 3
Training loss: 1.3338646674447276
Validation loss: 2.673709440418582

Epoch: 6| Step: 4
Training loss: 1.6468194188505376
Validation loss: 2.6594965672751427

Epoch: 6| Step: 5
Training loss: 2.1947479065049613
Validation loss: 2.698927970861693

Epoch: 6| Step: 6
Training loss: 2.192330503795519
Validation loss: 2.6788809167601007

Epoch: 6| Step: 7
Training loss: 2.1415961074585677
Validation loss: 2.725981467348439

Epoch: 6| Step: 8
Training loss: 2.3413063025438476
Validation loss: 2.696511220432267

Epoch: 6| Step: 9
Training loss: 2.1543524312164393
Validation loss: 2.712582809895238

Epoch: 6| Step: 10
Training loss: 1.4139083862625796
Validation loss: 2.7288265356053225

Epoch: 6| Step: 11
Training loss: 1.4480192664956424
Validation loss: 2.6922749970620194

Epoch: 6| Step: 12
Training loss: 1.8143708669291487
Validation loss: 2.6761414965259025

Epoch: 6| Step: 13
Training loss: 2.154620785195582
Validation loss: 2.6542680863706214

Epoch: 328| Step: 0
Training loss: 1.8814046194213463
Validation loss: 2.6472107062990493

Epoch: 6| Step: 1
Training loss: 1.5716717658797896
Validation loss: 2.678271929027721

Epoch: 6| Step: 2
Training loss: 1.9014353375008952
Validation loss: 2.643057731493439

Epoch: 6| Step: 3
Training loss: 2.476217059282691
Validation loss: 2.640534393742438

Epoch: 6| Step: 4
Training loss: 1.6571529014640038
Validation loss: 2.6681607104267995

Epoch: 6| Step: 5
Training loss: 1.693729347018628
Validation loss: 2.63837707363587

Epoch: 6| Step: 6
Training loss: 2.8437486585676783
Validation loss: 2.646100734104175

Epoch: 6| Step: 7
Training loss: 1.5370465548134247
Validation loss: 2.66518519396848

Epoch: 6| Step: 8
Training loss: 1.6533827524849167
Validation loss: 2.6313396526174126

Epoch: 6| Step: 9
Training loss: 1.9465825481181587
Validation loss: 2.614400322779554

Epoch: 6| Step: 10
Training loss: 1.8543607917346752
Validation loss: 2.599205943042516

Epoch: 6| Step: 11
Training loss: 2.3892108998385786
Validation loss: 2.6270594994847585

Epoch: 6| Step: 12
Training loss: 1.5083833710746488
Validation loss: 2.6165084944945014

Epoch: 6| Step: 13
Training loss: 1.4618511912676908
Validation loss: 2.6348361304454477

Epoch: 329| Step: 0
Training loss: 1.6101804773098847
Validation loss: 2.6280538339916895

Epoch: 6| Step: 1
Training loss: 1.9014465597599115
Validation loss: 2.6290704034471655

Epoch: 6| Step: 2
Training loss: 1.88652944306167
Validation loss: 2.634252001876483

Epoch: 6| Step: 3
Training loss: 2.2628630541783417
Validation loss: 2.642847574184775

Epoch: 6| Step: 4
Training loss: 1.9550877588970306
Validation loss: 2.677354766701335

Epoch: 6| Step: 5
Training loss: 1.9544758512108327
Validation loss: 2.6325903779009123

Epoch: 6| Step: 6
Training loss: 1.5698460887376282
Validation loss: 2.6640975144398142

Epoch: 6| Step: 7
Training loss: 2.231302135723943
Validation loss: 2.6463931885572447

Epoch: 6| Step: 8
Training loss: 1.6576905373770312
Validation loss: 2.6493980743754446

Epoch: 6| Step: 9
Training loss: 2.312726396355482
Validation loss: 2.644885025890742

Epoch: 6| Step: 10
Training loss: 1.6974890312773048
Validation loss: 2.6243036345562634

Epoch: 6| Step: 11
Training loss: 2.3726765159165986
Validation loss: 2.6301519985901507

Epoch: 6| Step: 12
Training loss: 1.8600055042308459
Validation loss: 2.622087224980373

Epoch: 6| Step: 13
Training loss: 1.7011607330693177
Validation loss: 2.6298043019403377

Epoch: 330| Step: 0
Training loss: 1.5646767521925826
Validation loss: 2.640603932554335

Epoch: 6| Step: 1
Training loss: 1.790866458717225
Validation loss: 2.6496547126143644

Epoch: 6| Step: 2
Training loss: 1.569656234937152
Validation loss: 2.633833772956135

Epoch: 6| Step: 3
Training loss: 1.7849480906186048
Validation loss: 2.6796312687704376

Epoch: 6| Step: 4
Training loss: 1.8476015369145438
Validation loss: 2.6545404430519652

Epoch: 6| Step: 5
Training loss: 1.6846880620079114
Validation loss: 2.647138909248316

Epoch: 6| Step: 6
Training loss: 1.916171535171987
Validation loss: 2.627214406006052

Epoch: 6| Step: 7
Training loss: 1.932103794832236
Validation loss: 2.677005593523089

Epoch: 6| Step: 8
Training loss: 2.500549828148641
Validation loss: 2.661467182022783

Epoch: 6| Step: 9
Training loss: 2.2046849565065503
Validation loss: 2.6435283071937112

Epoch: 6| Step: 10
Training loss: 1.8822955929648892
Validation loss: 2.6620912091798496

Epoch: 6| Step: 11
Training loss: 1.7075364262282553
Validation loss: 2.674861748114486

Epoch: 6| Step: 12
Training loss: 2.035878468826551
Validation loss: 2.6437337659934093

Epoch: 6| Step: 13
Training loss: 2.401516407491408
Validation loss: 2.6455745019741186

Epoch: 331| Step: 0
Training loss: 1.1507626824004349
Validation loss: 2.6487529045450304

Epoch: 6| Step: 1
Training loss: 1.6822602905874808
Validation loss: 2.6584814684101614

Epoch: 6| Step: 2
Training loss: 1.2855389613624026
Validation loss: 2.6657793287328397

Epoch: 6| Step: 3
Training loss: 2.005299699031187
Validation loss: 2.639574763749043

Epoch: 6| Step: 4
Training loss: 1.318644626981605
Validation loss: 2.6677114754543743

Epoch: 6| Step: 5
Training loss: 3.009922308188463
Validation loss: 2.6584956381666767

Epoch: 6| Step: 6
Training loss: 2.165698152878162
Validation loss: 2.6543444062450363

Epoch: 6| Step: 7
Training loss: 2.21471586312333
Validation loss: 2.6739533875472534

Epoch: 6| Step: 8
Training loss: 2.2309267338820122
Validation loss: 2.674969225554944

Epoch: 6| Step: 9
Training loss: 2.01734696990802
Validation loss: 2.6218222502538704

Epoch: 6| Step: 10
Training loss: 1.8594636014456745
Validation loss: 2.650120623260459

Epoch: 6| Step: 11
Training loss: 1.9273499450460327
Validation loss: 2.620899009387086

Epoch: 6| Step: 12
Training loss: 1.7948379912092651
Validation loss: 2.608534352008171

Epoch: 6| Step: 13
Training loss: 1.552861737479989
Validation loss: 2.631970007600893

Epoch: 332| Step: 0
Training loss: 2.0015187457481627
Validation loss: 2.5972841995469316

Epoch: 6| Step: 1
Training loss: 1.878797627122634
Validation loss: 2.616258006368416

Epoch: 6| Step: 2
Training loss: 2.5067157188986418
Validation loss: 2.600722848533096

Epoch: 6| Step: 3
Training loss: 1.5920536512842476
Validation loss: 2.62496297295508

Epoch: 6| Step: 4
Training loss: 2.174947089066876
Validation loss: 2.6142414497677557

Epoch: 6| Step: 5
Training loss: 1.8048589715785546
Validation loss: 2.6164410337936324

Epoch: 6| Step: 6
Training loss: 1.1106752110145353
Validation loss: 2.6003179695026946

Epoch: 6| Step: 7
Training loss: 2.142464286123732
Validation loss: 2.623612960815675

Epoch: 6| Step: 8
Training loss: 1.534218227356471
Validation loss: 2.6212624932826527

Epoch: 6| Step: 9
Training loss: 2.0051508379203047
Validation loss: 2.637608575318701

Epoch: 6| Step: 10
Training loss: 1.8630240400793474
Validation loss: 2.616874790013981

Epoch: 6| Step: 11
Training loss: 1.2232198665360319
Validation loss: 2.629274415248151

Epoch: 6| Step: 12
Training loss: 1.6894679427186172
Validation loss: 2.613690339034956

Epoch: 6| Step: 13
Training loss: 2.5357127467866523
Validation loss: 2.6790012411380717

Epoch: 333| Step: 0
Training loss: 1.737641291739623
Validation loss: 2.643294856315371

Epoch: 6| Step: 1
Training loss: 1.562334128158581
Validation loss: 2.7054246737864336

Epoch: 6| Step: 2
Training loss: 1.8319322766733896
Validation loss: 2.617230269808529

Epoch: 6| Step: 3
Training loss: 2.498794551144969
Validation loss: 2.6633124241785975

Epoch: 6| Step: 4
Training loss: 2.353126690016668
Validation loss: 2.6886319430680445

Epoch: 6| Step: 5
Training loss: 2.037232728992355
Validation loss: 2.6730526193566995

Epoch: 6| Step: 6
Training loss: 1.31901179241725
Validation loss: 2.6767267269206942

Epoch: 6| Step: 7
Training loss: 1.9850138439397154
Validation loss: 2.6218850864220933

Epoch: 6| Step: 8
Training loss: 1.5459228822145419
Validation loss: 2.5956986472476546

Epoch: 6| Step: 9
Training loss: 1.8005871450939654
Validation loss: 2.6149305642454044

Epoch: 6| Step: 10
Training loss: 1.6303138414391674
Validation loss: 2.598310429319384

Epoch: 6| Step: 11
Training loss: 2.3770388836149756
Validation loss: 2.639060314923638

Epoch: 6| Step: 12
Training loss: 1.6779869520068822
Validation loss: 2.650261295080188

Epoch: 6| Step: 13
Training loss: 2.2048744127835174
Validation loss: 2.6175499508526556

Epoch: 334| Step: 0
Training loss: 1.7147838260547237
Validation loss: 2.6589259562326557

Epoch: 6| Step: 1
Training loss: 2.1163139089362963
Validation loss: 2.6823622808451293

Epoch: 6| Step: 2
Training loss: 1.7294664774124795
Validation loss: 2.741392551118649

Epoch: 6| Step: 3
Training loss: 2.1320309726691145
Validation loss: 2.684513073391129

Epoch: 6| Step: 4
Training loss: 1.9266246627839991
Validation loss: 2.7087635481090278

Epoch: 6| Step: 5
Training loss: 1.2734353001113332
Validation loss: 2.6796609267389906

Epoch: 6| Step: 6
Training loss: 2.660569123928545
Validation loss: 2.6263379365777633

Epoch: 6| Step: 7
Training loss: 1.5116861029359947
Validation loss: 2.614305418120436

Epoch: 6| Step: 8
Training loss: 2.106942363557212
Validation loss: 2.573144205099082

Epoch: 6| Step: 9
Training loss: 1.3915741071167713
Validation loss: 2.5644650871809413

Epoch: 6| Step: 10
Training loss: 1.9408802571021886
Validation loss: 2.5859499159838513

Epoch: 6| Step: 11
Training loss: 2.0224337057935506
Validation loss: 2.6013712311504253

Epoch: 6| Step: 12
Training loss: 1.623325512192911
Validation loss: 2.5911487266230444

Epoch: 6| Step: 13
Training loss: 2.334313481961639
Validation loss: 2.6094871238024866

Epoch: 335| Step: 0
Training loss: 1.430522737260351
Validation loss: 2.6826287708974377

Epoch: 6| Step: 1
Training loss: 1.721794483773905
Validation loss: 2.6917150105326604

Epoch: 6| Step: 2
Training loss: 1.7011738370934437
Validation loss: 2.6803137415412754

Epoch: 6| Step: 3
Training loss: 1.6301036797062318
Validation loss: 2.6463821898154563

Epoch: 6| Step: 4
Training loss: 1.6190118496881183
Validation loss: 2.64645694282081

Epoch: 6| Step: 5
Training loss: 2.169687830185841
Validation loss: 2.64590618203466

Epoch: 6| Step: 6
Training loss: 2.789236880709307
Validation loss: 2.653120853104812

Epoch: 6| Step: 7
Training loss: 1.6764212855499352
Validation loss: 2.630815996030952

Epoch: 6| Step: 8
Training loss: 1.85668738250316
Validation loss: 2.645220412701725

Epoch: 6| Step: 9
Training loss: 1.9600356258346467
Validation loss: 2.6554657170950935

Epoch: 6| Step: 10
Training loss: 1.8384975035409004
Validation loss: 2.6356532225659337

Epoch: 6| Step: 11
Training loss: 2.3813945616247607
Validation loss: 2.6592709883698142

Epoch: 6| Step: 12
Training loss: 1.4776240977988115
Validation loss: 2.644426622673518

Epoch: 6| Step: 13
Training loss: 2.1237038417961935
Validation loss: 2.6240760448706353

Epoch: 336| Step: 0
Training loss: 1.5993013376473064
Validation loss: 2.649762462670278

Epoch: 6| Step: 1
Training loss: 2.095453394989378
Validation loss: 2.6584071058442573

Epoch: 6| Step: 2
Training loss: 2.1912286859880408
Validation loss: 2.6412116608527842

Epoch: 6| Step: 3
Training loss: 1.8899299668148346
Validation loss: 2.6248700094583257

Epoch: 6| Step: 4
Training loss: 1.6290161681195412
Validation loss: 2.663350581621346

Epoch: 6| Step: 5
Training loss: 1.0366762912912666
Validation loss: 2.6609013914688666

Epoch: 6| Step: 6
Training loss: 1.4520290713066586
Validation loss: 2.6157206357960354

Epoch: 6| Step: 7
Training loss: 1.6342364950919004
Validation loss: 2.6480722841344684

Epoch: 6| Step: 8
Training loss: 1.9848388370073835
Validation loss: 2.627989141858883

Epoch: 6| Step: 9
Training loss: 1.5377059612489308
Validation loss: 2.6389865946388884

Epoch: 6| Step: 10
Training loss: 2.1213504642935352
Validation loss: 2.6048762359311115

Epoch: 6| Step: 11
Training loss: 2.200085972059807
Validation loss: 2.6507666594454817

Epoch: 6| Step: 12
Training loss: 1.877327936163824
Validation loss: 2.6416507361460186

Epoch: 6| Step: 13
Training loss: 2.64923857780198
Validation loss: 2.6208933845113314

Epoch: 337| Step: 0
Training loss: 2.4577123428764294
Validation loss: 2.665262036135978

Epoch: 6| Step: 1
Training loss: 2.0320300438454586
Validation loss: 2.638247576524931

Epoch: 6| Step: 2
Training loss: 1.3992250664939565
Validation loss: 2.612247469741852

Epoch: 6| Step: 3
Training loss: 2.0652595323675804
Validation loss: 2.66222211375614

Epoch: 6| Step: 4
Training loss: 1.7876894817092581
Validation loss: 2.7117838862084263

Epoch: 6| Step: 5
Training loss: 1.8577452497445952
Validation loss: 2.651815310287518

Epoch: 6| Step: 6
Training loss: 2.232410767962308
Validation loss: 2.604302659616454

Epoch: 6| Step: 7
Training loss: 1.501223303742513
Validation loss: 2.613699719386123

Epoch: 6| Step: 8
Training loss: 1.9731338980241204
Validation loss: 2.577843806797744

Epoch: 6| Step: 9
Training loss: 1.393620597066655
Validation loss: 2.5995974063956027

Epoch: 6| Step: 10
Training loss: 2.0956867427132293
Validation loss: 2.5698128381750505

Epoch: 6| Step: 11
Training loss: 1.4455009543786186
Validation loss: 2.5909597179849873

Epoch: 6| Step: 12
Training loss: 1.9959226411762396
Validation loss: 2.583661548212098

Epoch: 6| Step: 13
Training loss: 1.647208094344184
Validation loss: 2.5851907717998532

Epoch: 338| Step: 0
Training loss: 2.022485103858817
Validation loss: 2.5989139886919483

Epoch: 6| Step: 1
Training loss: 2.616441307163332
Validation loss: 2.633199631238256

Epoch: 6| Step: 2
Training loss: 1.608705992671039
Validation loss: 2.675901015819727

Epoch: 6| Step: 3
Training loss: 1.820177392488865
Validation loss: 2.7668091561113415

Epoch: 6| Step: 4
Training loss: 1.544013874189272
Validation loss: 2.736226688295582

Epoch: 6| Step: 5
Training loss: 1.8939647338790366
Validation loss: 2.7435974090248783

Epoch: 6| Step: 6
Training loss: 1.8139985565297567
Validation loss: 2.771716060905572

Epoch: 6| Step: 7
Training loss: 2.232107118592943
Validation loss: 2.6909437811110775

Epoch: 6| Step: 8
Training loss: 1.2258337978480582
Validation loss: 2.665407559051943

Epoch: 6| Step: 9
Training loss: 2.150588079355656
Validation loss: 2.6643294781417124

Epoch: 6| Step: 10
Training loss: 1.4802302266523488
Validation loss: 2.6027614667859282

Epoch: 6| Step: 11
Training loss: 2.003410054841334
Validation loss: 2.605562985234986

Epoch: 6| Step: 12
Training loss: 1.99851046168777
Validation loss: 2.5868651233161053

Epoch: 6| Step: 13
Training loss: 2.401161957635439
Validation loss: 2.5729357967103117

Epoch: 339| Step: 0
Training loss: 1.8551665049882904
Validation loss: 2.5936462963774933

Epoch: 6| Step: 1
Training loss: 1.4048089166938276
Validation loss: 2.5651938227494013

Epoch: 6| Step: 2
Training loss: 1.3522190417742794
Validation loss: 2.636445162672537

Epoch: 6| Step: 3
Training loss: 1.7367225773915456
Validation loss: 2.624094610144594

Epoch: 6| Step: 4
Training loss: 2.1990169886565556
Validation loss: 2.6238057886607575

Epoch: 6| Step: 5
Training loss: 1.4399631792235283
Validation loss: 2.6556224455671145

Epoch: 6| Step: 6
Training loss: 1.837605339715795
Validation loss: 2.641194840743026

Epoch: 6| Step: 7
Training loss: 1.2171314936669646
Validation loss: 2.6780867174365786

Epoch: 6| Step: 8
Training loss: 2.452858296857544
Validation loss: 2.683160442405814

Epoch: 6| Step: 9
Training loss: 1.3317580404352192
Validation loss: 2.6296952656816166

Epoch: 6| Step: 10
Training loss: 1.918158434405245
Validation loss: 2.638735085461329

Epoch: 6| Step: 11
Training loss: 2.2405444781147827
Validation loss: 2.6655653576813996

Epoch: 6| Step: 12
Training loss: 2.7062827832921137
Validation loss: 2.6397801990955894

Epoch: 6| Step: 13
Training loss: 2.1041858281940677
Validation loss: 2.641573011581306

Epoch: 340| Step: 0
Training loss: 1.2639862565669617
Validation loss: 2.627267327597598

Epoch: 6| Step: 1
Training loss: 2.4198060088787012
Validation loss: 2.607006741931442

Epoch: 6| Step: 2
Training loss: 1.6759262200096314
Validation loss: 2.615910521267016

Epoch: 6| Step: 3
Training loss: 1.6459860268112132
Validation loss: 2.621780866373629

Epoch: 6| Step: 4
Training loss: 1.8684726266833664
Validation loss: 2.6429242689550683

Epoch: 6| Step: 5
Training loss: 1.5074974086606352
Validation loss: 2.6625802026527903

Epoch: 6| Step: 6
Training loss: 1.9092338847006822
Validation loss: 2.6303147297606855

Epoch: 6| Step: 7
Training loss: 1.8762924825902303
Validation loss: 2.6273294134445524

Epoch: 6| Step: 8
Training loss: 1.90884423003965
Validation loss: 2.624802142966916

Epoch: 6| Step: 9
Training loss: 2.123684195250609
Validation loss: 2.621622425473199

Epoch: 6| Step: 10
Training loss: 2.169057871488385
Validation loss: 2.630641566688345

Epoch: 6| Step: 11
Training loss: 2.1826748629124637
Validation loss: 2.6265904891235947

Epoch: 6| Step: 12
Training loss: 2.183337256255763
Validation loss: 2.575981019310496

Epoch: 6| Step: 13
Training loss: 1.2390045075476968
Validation loss: 2.60703074823256

Epoch: 341| Step: 0
Training loss: 1.8816659055741525
Validation loss: 2.6475708180130417

Epoch: 6| Step: 1
Training loss: 1.505290714460261
Validation loss: 2.679170059945512

Epoch: 6| Step: 2
Training loss: 1.8259621892484361
Validation loss: 2.7022726960742065

Epoch: 6| Step: 3
Training loss: 2.294646654873346
Validation loss: 2.6695541653251045

Epoch: 6| Step: 4
Training loss: 1.9034510215788802
Validation loss: 2.7073258996031844

Epoch: 6| Step: 5
Training loss: 1.2249139288423083
Validation loss: 2.683322320840482

Epoch: 6| Step: 6
Training loss: 1.8308482956596843
Validation loss: 2.7046561856571767

Epoch: 6| Step: 7
Training loss: 2.457742609290181
Validation loss: 2.6391115535244833

Epoch: 6| Step: 8
Training loss: 1.7554973360593917
Validation loss: 2.6353158190182473

Epoch: 6| Step: 9
Training loss: 1.4166426750096326
Validation loss: 2.611520094889947

Epoch: 6| Step: 10
Training loss: 2.532079019304821
Validation loss: 2.617763034680633

Epoch: 6| Step: 11
Training loss: 2.1216869332703303
Validation loss: 2.5978675393050943

Epoch: 6| Step: 12
Training loss: 1.9191470751119217
Validation loss: 2.6188112450526386

Epoch: 6| Step: 13
Training loss: 1.7465732266036462
Validation loss: 2.651312828560509

Epoch: 342| Step: 0
Training loss: 1.9473472279674684
Validation loss: 2.6135185221415953

Epoch: 6| Step: 1
Training loss: 2.0005909523514225
Validation loss: 2.6368452781176996

Epoch: 6| Step: 2
Training loss: 1.6878034530761632
Validation loss: 2.6319128474673734

Epoch: 6| Step: 3
Training loss: 1.5122446333262916
Validation loss: 2.6621716334152277

Epoch: 6| Step: 4
Training loss: 1.681228782207939
Validation loss: 2.6345046102392122

Epoch: 6| Step: 5
Training loss: 2.030012135023105
Validation loss: 2.612139670605774

Epoch: 6| Step: 6
Training loss: 1.8211880653338839
Validation loss: 2.6642356808811476

Epoch: 6| Step: 7
Training loss: 2.421020455495772
Validation loss: 2.593332724346426

Epoch: 6| Step: 8
Training loss: 1.7785417815827238
Validation loss: 2.583960200720725

Epoch: 6| Step: 9
Training loss: 2.202928466688309
Validation loss: 2.589737987324615

Epoch: 6| Step: 10
Training loss: 1.2191342457241081
Validation loss: 2.6010049369478674

Epoch: 6| Step: 11
Training loss: 1.7317746575870212
Validation loss: 2.58955420040112

Epoch: 6| Step: 12
Training loss: 2.0715777291776676
Validation loss: 2.5929847875399687

Epoch: 6| Step: 13
Training loss: 1.8076489743035116
Validation loss: 2.612433485617191

Epoch: 343| Step: 0
Training loss: 2.128932903717897
Validation loss: 2.6401426939499535

Epoch: 6| Step: 1
Training loss: 2.000318501860821
Validation loss: 2.6473466695367796

Epoch: 6| Step: 2
Training loss: 2.0552408031818854
Validation loss: 2.684089403869263

Epoch: 6| Step: 3
Training loss: 1.846749081006305
Validation loss: 2.6848460259737146

Epoch: 6| Step: 4
Training loss: 1.16995814908811
Validation loss: 2.6967749419792475

Epoch: 6| Step: 5
Training loss: 2.1853317413944935
Validation loss: 2.7113307993720452

Epoch: 6| Step: 6
Training loss: 1.580092233186977
Validation loss: 2.7375714465475034

Epoch: 6| Step: 7
Training loss: 1.2968974743469857
Validation loss: 2.657670153783468

Epoch: 6| Step: 8
Training loss: 2.265878597404607
Validation loss: 2.6671031256963733

Epoch: 6| Step: 9
Training loss: 2.3502671231978125
Validation loss: 2.6088948674199353

Epoch: 6| Step: 10
Training loss: 1.2105009214893285
Validation loss: 2.59240900940042

Epoch: 6| Step: 11
Training loss: 1.9499308598316452
Validation loss: 2.5866959488168235

Epoch: 6| Step: 12
Training loss: 2.0935140448318474
Validation loss: 2.581610417854284

Epoch: 6| Step: 13
Training loss: 1.7270918505021096
Validation loss: 2.5872959130190867

Epoch: 344| Step: 0
Training loss: 1.5448197862771451
Validation loss: 2.609120217560358

Epoch: 6| Step: 1
Training loss: 2.0540717184886277
Validation loss: 2.615971843734195

Epoch: 6| Step: 2
Training loss: 1.447537333611502
Validation loss: 2.642591395113365

Epoch: 6| Step: 3
Training loss: 1.5717265277006072
Validation loss: 2.623698971782059

Epoch: 6| Step: 4
Training loss: 2.251071356972255
Validation loss: 2.6116404644987194

Epoch: 6| Step: 5
Training loss: 1.7863595859235473
Validation loss: 2.611497263446396

Epoch: 6| Step: 6
Training loss: 2.1918620623186884
Validation loss: 2.6110583907637577

Epoch: 6| Step: 7
Training loss: 2.167568850364236
Validation loss: 2.6180300974149167

Epoch: 6| Step: 8
Training loss: 1.7278348627435398
Validation loss: 2.5909323037246903

Epoch: 6| Step: 9
Training loss: 2.235200529383253
Validation loss: 2.5948561948401747

Epoch: 6| Step: 10
Training loss: 2.259033717632905
Validation loss: 2.5699100353213504

Epoch: 6| Step: 11
Training loss: 1.5533630250104071
Validation loss: 2.6325797818620726

Epoch: 6| Step: 12
Training loss: 1.6154146658893456
Validation loss: 2.5836723064226037

Epoch: 6| Step: 13
Training loss: 1.5337797016230728
Validation loss: 2.6196166953981095

Epoch: 345| Step: 0
Training loss: 1.9723499022451865
Validation loss: 2.624513126816483

Epoch: 6| Step: 1
Training loss: 1.955126659846487
Validation loss: 2.627513181978183

Epoch: 6| Step: 2
Training loss: 2.0712766309740096
Validation loss: 2.6221237016164154

Epoch: 6| Step: 3
Training loss: 2.5173460954824862
Validation loss: 2.6516503545218213

Epoch: 6| Step: 4
Training loss: 0.9884787200138385
Validation loss: 2.6496959235916044

Epoch: 6| Step: 5
Training loss: 1.3195692148387836
Validation loss: 2.622165178587263

Epoch: 6| Step: 6
Training loss: 1.6938221089120913
Validation loss: 2.6401280644691627

Epoch: 6| Step: 7
Training loss: 2.0055204734774845
Validation loss: 2.6163635930824825

Epoch: 6| Step: 8
Training loss: 1.7214455015235237
Validation loss: 2.607780136660312

Epoch: 6| Step: 9
Training loss: 2.3201766568373854
Validation loss: 2.6626531876267587

Epoch: 6| Step: 10
Training loss: 2.0696184254448737
Validation loss: 2.6524194960342733

Epoch: 6| Step: 11
Training loss: 1.8527878839019227
Validation loss: 2.6514187277976617

Epoch: 6| Step: 12
Training loss: 1.7510700360446532
Validation loss: 2.6476605981584904

Epoch: 6| Step: 13
Training loss: 1.2890260633463095
Validation loss: 2.67548741864401

Epoch: 346| Step: 0
Training loss: 1.2856012750716612
Validation loss: 2.683137383819325

Epoch: 6| Step: 1
Training loss: 2.1967343107622455
Validation loss: 2.672068464328121

Epoch: 6| Step: 2
Training loss: 1.8558378796064272
Validation loss: 2.646975283353743

Epoch: 6| Step: 3
Training loss: 1.9739166161415882
Validation loss: 2.6958254708397034

Epoch: 6| Step: 4
Training loss: 1.3014520971544608
Validation loss: 2.673469558425508

Epoch: 6| Step: 5
Training loss: 2.4298712854086664
Validation loss: 2.645426716435179

Epoch: 6| Step: 6
Training loss: 1.663630469748095
Validation loss: 2.62075868711518

Epoch: 6| Step: 7
Training loss: 1.812104346401361
Validation loss: 2.6557108013931776

Epoch: 6| Step: 8
Training loss: 1.3805820127178345
Validation loss: 2.6296011245876003

Epoch: 6| Step: 9
Training loss: 1.166728966048662
Validation loss: 2.650304220839079

Epoch: 6| Step: 10
Training loss: 2.660830956933975
Validation loss: 2.620792119521371

Epoch: 6| Step: 11
Training loss: 1.7944670091489083
Validation loss: 2.6104308407807917

Epoch: 6| Step: 12
Training loss: 2.07140439587847
Validation loss: 2.6328725458951805

Epoch: 6| Step: 13
Training loss: 1.7864656883807533
Validation loss: 2.6478518248231486

Epoch: 347| Step: 0
Training loss: 1.7791264909887972
Validation loss: 2.6640747308683372

Epoch: 6| Step: 1
Training loss: 2.09775024430791
Validation loss: 2.6928244786451505

Epoch: 6| Step: 2
Training loss: 2.291028737374561
Validation loss: 2.700275999844592

Epoch: 6| Step: 3
Training loss: 1.7475112520655143
Validation loss: 2.701346236619261

Epoch: 6| Step: 4
Training loss: 1.2440277479579018
Validation loss: 2.6849520233717445

Epoch: 6| Step: 5
Training loss: 2.2174168194606096
Validation loss: 2.6556511895886

Epoch: 6| Step: 6
Training loss: 1.388050482208431
Validation loss: 2.6214760029264563

Epoch: 6| Step: 7
Training loss: 1.51084010886293
Validation loss: 2.6303513491182016

Epoch: 6| Step: 8
Training loss: 1.8156983667674627
Validation loss: 2.5911859454911217

Epoch: 6| Step: 9
Training loss: 2.126376211287916
Validation loss: 2.5941756332034998

Epoch: 6| Step: 10
Training loss: 1.7812582316961316
Validation loss: 2.5718208532863875

Epoch: 6| Step: 11
Training loss: 2.223978035070507
Validation loss: 2.59394130997059

Epoch: 6| Step: 12
Training loss: 1.5192601763805194
Validation loss: 2.543841866936181

Epoch: 6| Step: 13
Training loss: 1.9468055724964606
Validation loss: 2.5824357801332387

Epoch: 348| Step: 0
Training loss: 1.4545810746578156
Validation loss: 2.6337485380429686

Epoch: 6| Step: 1
Training loss: 2.0404387174347907
Validation loss: 2.6358829935103127

Epoch: 6| Step: 2
Training loss: 1.5789721641768615
Validation loss: 2.6669499922284565

Epoch: 6| Step: 3
Training loss: 1.569226017196071
Validation loss: 2.64597497896324

Epoch: 6| Step: 4
Training loss: 1.8608758462963024
Validation loss: 2.6490197905985275

Epoch: 6| Step: 5
Training loss: 2.1460961363021975
Validation loss: 2.6200037896272077

Epoch: 6| Step: 6
Training loss: 1.661321325442932
Validation loss: 2.6433329644830295

Epoch: 6| Step: 7
Training loss: 1.8377871023082746
Validation loss: 2.6081263891722672

Epoch: 6| Step: 8
Training loss: 1.9456425275788178
Validation loss: 2.581586352179146

Epoch: 6| Step: 9
Training loss: 1.9806433004470938
Validation loss: 2.5717631983568685

Epoch: 6| Step: 10
Training loss: 1.8610405394552396
Validation loss: 2.5497938253540737

Epoch: 6| Step: 11
Training loss: 1.8840180016161785
Validation loss: 2.568452357167092

Epoch: 6| Step: 12
Training loss: 2.2677368844483263
Validation loss: 2.5825331176623534

Epoch: 6| Step: 13
Training loss: 1.831385712265566
Validation loss: 2.575954108955397

Epoch: 349| Step: 0
Training loss: 1.673962653328006
Validation loss: 2.558403198290566

Epoch: 6| Step: 1
Training loss: 1.6087083639523492
Validation loss: 2.5885667908419556

Epoch: 6| Step: 2
Training loss: 1.7198669965463393
Validation loss: 2.6203915697245463

Epoch: 6| Step: 3
Training loss: 1.5238082825777697
Validation loss: 2.6136543528373744

Epoch: 6| Step: 4
Training loss: 2.236525134608233
Validation loss: 2.6635495136629257

Epoch: 6| Step: 5
Training loss: 1.6806881784840098
Validation loss: 2.669027033891305

Epoch: 6| Step: 6
Training loss: 2.2138633105391725
Validation loss: 2.6625762253955214

Epoch: 6| Step: 7
Training loss: 1.9479058073288513
Validation loss: 2.65569405815248

Epoch: 6| Step: 8
Training loss: 1.9840244974885066
Validation loss: 2.6499650389086553

Epoch: 6| Step: 9
Training loss: 1.9235336465612254
Validation loss: 2.6354089568456325

Epoch: 6| Step: 10
Training loss: 2.3145280141826494
Validation loss: 2.6178280326495083

Epoch: 6| Step: 11
Training loss: 2.0062884175552886
Validation loss: 2.5553779874377165

Epoch: 6| Step: 12
Training loss: 1.2791465146758543
Validation loss: 2.5344315067487657

Epoch: 6| Step: 13
Training loss: 1.3769504411820033
Validation loss: 2.5558791186105383

Epoch: 350| Step: 0
Training loss: 2.2976413408539575
Validation loss: 2.5547888266157672

Epoch: 6| Step: 1
Training loss: 1.241819603139906
Validation loss: 2.5740125435575645

Epoch: 6| Step: 2
Training loss: 1.6156133832089614
Validation loss: 2.563872442770199

Epoch: 6| Step: 3
Training loss: 2.001826882452519
Validation loss: 2.5530979682677306

Epoch: 6| Step: 4
Training loss: 1.2846181838836639
Validation loss: 2.597176307186237

Epoch: 6| Step: 5
Training loss: 1.6868551929691888
Validation loss: 2.582341116405711

Epoch: 6| Step: 6
Training loss: 1.8474561006236898
Validation loss: 2.5622049487446037

Epoch: 6| Step: 7
Training loss: 1.6993341516353353
Validation loss: 2.591680137460255

Epoch: 6| Step: 8
Training loss: 1.0723690129033032
Validation loss: 2.656796425359175

Epoch: 6| Step: 9
Training loss: 1.5122119976155532
Validation loss: 2.608012584204922

Epoch: 6| Step: 10
Training loss: 2.517998564825035
Validation loss: 2.5994139267542136

Epoch: 6| Step: 11
Training loss: 1.7196350593203351
Validation loss: 2.6555110726383933

Epoch: 6| Step: 12
Training loss: 2.443932872281133
Validation loss: 2.606161259055959

Epoch: 6| Step: 13
Training loss: 2.171277958981459
Validation loss: 2.616114154319841

Epoch: 351| Step: 0
Training loss: 1.5479829461688648
Validation loss: 2.5854330041345106

Epoch: 6| Step: 1
Training loss: 1.3463084239555345
Validation loss: 2.5916855957550213

Epoch: 6| Step: 2
Training loss: 2.8828743615271524
Validation loss: 2.5775791707846736

Epoch: 6| Step: 3
Training loss: 2.128386547804463
Validation loss: 2.560143426128294

Epoch: 6| Step: 4
Training loss: 1.2735830586564636
Validation loss: 2.5884864130909455

Epoch: 6| Step: 5
Training loss: 1.539155521583102
Validation loss: 2.600143427438484

Epoch: 6| Step: 6
Training loss: 1.9559480330461991
Validation loss: 2.621186862585982

Epoch: 6| Step: 7
Training loss: 2.167745932736132
Validation loss: 2.6237296406206045

Epoch: 6| Step: 8
Training loss: 1.4326306675937888
Validation loss: 2.647175881294971

Epoch: 6| Step: 9
Training loss: 2.0137516749615987
Validation loss: 2.7175688827099407

Epoch: 6| Step: 10
Training loss: 1.8461541487620179
Validation loss: 2.7016850717456147

Epoch: 6| Step: 11
Training loss: 1.8994566767994379
Validation loss: 2.668104087334799

Epoch: 6| Step: 12
Training loss: 1.9142920531592922
Validation loss: 2.6459358726115907

Epoch: 6| Step: 13
Training loss: 1.2470567384367943
Validation loss: 2.660338691956805

Epoch: 352| Step: 0
Training loss: 2.1513742800893074
Validation loss: 2.6150542717839738

Epoch: 6| Step: 1
Training loss: 1.3371138273672631
Validation loss: 2.576110607746159

Epoch: 6| Step: 2
Training loss: 1.5469640841022914
Validation loss: 2.6053711102218737

Epoch: 6| Step: 3
Training loss: 1.3589826872777588
Validation loss: 2.595706615345189

Epoch: 6| Step: 4
Training loss: 2.2409092253344323
Validation loss: 2.5794249060729286

Epoch: 6| Step: 5
Training loss: 1.1619892475004934
Validation loss: 2.6141185018009665

Epoch: 6| Step: 6
Training loss: 1.479381232302922
Validation loss: 2.582311356317985

Epoch: 6| Step: 7
Training loss: 1.8052404308015286
Validation loss: 2.605036145335968

Epoch: 6| Step: 8
Training loss: 2.9645550452835434
Validation loss: 2.6419499400832644

Epoch: 6| Step: 9
Training loss: 1.2395784340555946
Validation loss: 2.6530943058127026

Epoch: 6| Step: 10
Training loss: 1.7252772453974834
Validation loss: 2.7256862686153394

Epoch: 6| Step: 11
Training loss: 1.8850824751885364
Validation loss: 2.6780644460781406

Epoch: 6| Step: 12
Training loss: 2.400129187603763
Validation loss: 2.671177555542432

Epoch: 6| Step: 13
Training loss: 2.432106604605014
Validation loss: 2.689043814050954

Epoch: 353| Step: 0
Training loss: 1.9998881189524145
Validation loss: 2.7057741153472668

Epoch: 6| Step: 1
Training loss: 1.5679134433269526
Validation loss: 2.6767998828571735

Epoch: 6| Step: 2
Training loss: 1.2962052327797224
Validation loss: 2.6442623630939273

Epoch: 6| Step: 3
Training loss: 1.9569761835753277
Validation loss: 2.6295300556512378

Epoch: 6| Step: 4
Training loss: 2.3214155972296378
Validation loss: 2.6365938736343306

Epoch: 6| Step: 5
Training loss: 1.6260487033545927
Validation loss: 2.648495593788861

Epoch: 6| Step: 6
Training loss: 1.8396033516727446
Validation loss: 2.6376519103694624

Epoch: 6| Step: 7
Training loss: 2.0047887453958264
Validation loss: 2.6193973606022634

Epoch: 6| Step: 8
Training loss: 1.4836175692686615
Validation loss: 2.610850345382844

Epoch: 6| Step: 9
Training loss: 2.0912060441928717
Validation loss: 2.643266023024999

Epoch: 6| Step: 10
Training loss: 2.054762922287893
Validation loss: 2.6467373622641697

Epoch: 6| Step: 11
Training loss: 1.5640240675008565
Validation loss: 2.6675429146296006

Epoch: 6| Step: 12
Training loss: 2.2385891740839647
Validation loss: 2.6668731241969814

Epoch: 6| Step: 13
Training loss: 1.6984303015422144
Validation loss: 2.638504802347439

Epoch: 354| Step: 0
Training loss: 2.127172369468142
Validation loss: 2.6873973708554564

Epoch: 6| Step: 1
Training loss: 1.4473930436645435
Validation loss: 2.6973566826714723

Epoch: 6| Step: 2
Training loss: 1.7629031917327822
Validation loss: 2.623574278437018

Epoch: 6| Step: 3
Training loss: 1.2754696037292428
Validation loss: 2.6448881208077912

Epoch: 6| Step: 4
Training loss: 1.1351072023826114
Validation loss: 2.583427678713217

Epoch: 6| Step: 5
Training loss: 2.3470685734265837
Validation loss: 2.6181132942351457

Epoch: 6| Step: 6
Training loss: 2.345981400346969
Validation loss: 2.6161737253073163

Epoch: 6| Step: 7
Training loss: 2.1694829927873718
Validation loss: 2.6216905864716473

Epoch: 6| Step: 8
Training loss: 2.0128147139801373
Validation loss: 2.5947255287843136

Epoch: 6| Step: 9
Training loss: 1.045082151295846
Validation loss: 2.611053749112725

Epoch: 6| Step: 10
Training loss: 1.9148415361980713
Validation loss: 2.6269060700278097

Epoch: 6| Step: 11
Training loss: 1.8265959385012982
Validation loss: 2.6335917752436853

Epoch: 6| Step: 12
Training loss: 1.9582455459830432
Validation loss: 2.6582055018272115

Epoch: 6| Step: 13
Training loss: 1.4882340711589934
Validation loss: 2.6580132260812754

Epoch: 355| Step: 0
Training loss: 2.062210293855004
Validation loss: 2.662211620730373

Epoch: 6| Step: 1
Training loss: 1.6542356225285832
Validation loss: 2.6664143134955585

Epoch: 6| Step: 2
Training loss: 1.265469152957067
Validation loss: 2.666905926362008

Epoch: 6| Step: 3
Training loss: 1.3973180030004244
Validation loss: 2.6483019378686516

Epoch: 6| Step: 4
Training loss: 1.4104621111687268
Validation loss: 2.6483595244895257

Epoch: 6| Step: 5
Training loss: 1.3835843189850752
Validation loss: 2.642953526949851

Epoch: 6| Step: 6
Training loss: 1.7384072933147603
Validation loss: 2.5957913313192877

Epoch: 6| Step: 7
Training loss: 2.117156306526145
Validation loss: 2.6126793062166023

Epoch: 6| Step: 8
Training loss: 1.9580974910300182
Validation loss: 2.5935097089019075

Epoch: 6| Step: 9
Training loss: 1.8850120264777677
Validation loss: 2.6451341701483395

Epoch: 6| Step: 10
Training loss: 1.4056987529723326
Validation loss: 2.6552095507238227

Epoch: 6| Step: 11
Training loss: 1.6794144519392604
Validation loss: 2.6309668979889502

Epoch: 6| Step: 12
Training loss: 2.6575296349007993
Validation loss: 2.6356599014476507

Epoch: 6| Step: 13
Training loss: 2.193012811417215
Validation loss: 2.631343518526004

Epoch: 356| Step: 0
Training loss: 2.5428717106881
Validation loss: 2.690503268380913

Epoch: 6| Step: 1
Training loss: 1.4154186174126404
Validation loss: 2.676329441022907

Epoch: 6| Step: 2
Training loss: 2.040638749220885
Validation loss: 2.724536977738114

Epoch: 6| Step: 3
Training loss: 1.7073687955119536
Validation loss: 2.689874605402018

Epoch: 6| Step: 4
Training loss: 1.5732146058840772
Validation loss: 2.6802365525548226

Epoch: 6| Step: 5
Training loss: 1.6060932364946827
Validation loss: 2.67990845417127

Epoch: 6| Step: 6
Training loss: 1.4157764311715721
Validation loss: 2.650522512229367

Epoch: 6| Step: 7
Training loss: 1.0037255031689043
Validation loss: 2.6094622416578908

Epoch: 6| Step: 8
Training loss: 1.6777173930719784
Validation loss: 2.610774420670063

Epoch: 6| Step: 9
Training loss: 1.803324130746391
Validation loss: 2.6017620708910965

Epoch: 6| Step: 10
Training loss: 2.4611763974446
Validation loss: 2.6156839027593644

Epoch: 6| Step: 11
Training loss: 1.7188880171414345
Validation loss: 2.629817220986841

Epoch: 6| Step: 12
Training loss: 1.7286102441440256
Validation loss: 2.6137202283348606

Epoch: 6| Step: 13
Training loss: 2.1459550421805913
Validation loss: 2.602608219489901

Epoch: 357| Step: 0
Training loss: 1.8780854587549958
Validation loss: 2.635157174062091

Epoch: 6| Step: 1
Training loss: 1.8160419057682755
Validation loss: 2.6085344281743703

Epoch: 6| Step: 2
Training loss: 1.0371134554967691
Validation loss: 2.6045181240701756

Epoch: 6| Step: 3
Training loss: 2.244201287494668
Validation loss: 2.6108825196877636

Epoch: 6| Step: 4
Training loss: 1.4690736454628328
Validation loss: 2.6227614833827775

Epoch: 6| Step: 5
Training loss: 1.7884422459756848
Validation loss: 2.626050920380617

Epoch: 6| Step: 6
Training loss: 2.2005819157957838
Validation loss: 2.6032539650186446

Epoch: 6| Step: 7
Training loss: 1.746978945019496
Validation loss: 2.6171063614599257

Epoch: 6| Step: 8
Training loss: 2.1169390655815423
Validation loss: 2.581213301674082

Epoch: 6| Step: 9
Training loss: 1.5425846442642455
Validation loss: 2.623053086065881

Epoch: 6| Step: 10
Training loss: 1.7687748856697811
Validation loss: 2.5975921699440767

Epoch: 6| Step: 11
Training loss: 1.4659500217167243
Validation loss: 2.6148673634051294

Epoch: 6| Step: 12
Training loss: 1.6918600059608648
Validation loss: 2.5988939592011993

Epoch: 6| Step: 13
Training loss: 1.7768511749827895
Validation loss: 2.6184666937850847

Epoch: 358| Step: 0
Training loss: 2.098347981376312
Validation loss: 2.6404427911317727

Epoch: 6| Step: 1
Training loss: 1.2232414039732342
Validation loss: 2.668473843320591

Epoch: 6| Step: 2
Training loss: 2.0237459514688165
Validation loss: 2.6453881126934062

Epoch: 6| Step: 3
Training loss: 2.296406393191952
Validation loss: 2.658743761082503

Epoch: 6| Step: 4
Training loss: 0.9424176303578514
Validation loss: 2.6837227913872463

Epoch: 6| Step: 5
Training loss: 1.5280533725045118
Validation loss: 2.6464764471744724

Epoch: 6| Step: 6
Training loss: 1.449536723087197
Validation loss: 2.6376250793303715

Epoch: 6| Step: 7
Training loss: 1.7039717223100062
Validation loss: 2.6136584349468053

Epoch: 6| Step: 8
Training loss: 1.7968722799529344
Validation loss: 2.610506813540673

Epoch: 6| Step: 9
Training loss: 2.0879141482392134
Validation loss: 2.642685712497737

Epoch: 6| Step: 10
Training loss: 2.250394680587009
Validation loss: 2.638885256000717

Epoch: 6| Step: 11
Training loss: 1.7311083298430805
Validation loss: 2.675036294637432

Epoch: 6| Step: 12
Training loss: 1.7078838532419442
Validation loss: 2.650407581654605

Epoch: 6| Step: 13
Training loss: 1.9555315374154143
Validation loss: 2.6547238771589265

Epoch: 359| Step: 0
Training loss: 1.444534257191426
Validation loss: 2.647676071493514

Epoch: 6| Step: 1
Training loss: 1.7391303228295332
Validation loss: 2.632217853227264

Epoch: 6| Step: 2
Training loss: 1.184291319293981
Validation loss: 2.6325929061517406

Epoch: 6| Step: 3
Training loss: 2.1723464344389183
Validation loss: 2.6117950303553275

Epoch: 6| Step: 4
Training loss: 1.6160834040269587
Validation loss: 2.608533826461338

Epoch: 6| Step: 5
Training loss: 1.7256321536547623
Validation loss: 2.6212720890839583

Epoch: 6| Step: 6
Training loss: 1.6214218359171724
Validation loss: 2.635382902107514

Epoch: 6| Step: 7
Training loss: 2.110915575118318
Validation loss: 2.6386646164296135

Epoch: 6| Step: 8
Training loss: 2.039511444830293
Validation loss: 2.607242466615662

Epoch: 6| Step: 9
Training loss: 1.947997052443074
Validation loss: 2.621643743974598

Epoch: 6| Step: 10
Training loss: 2.1330436609219734
Validation loss: 2.58456952501891

Epoch: 6| Step: 11
Training loss: 1.9003972742448552
Validation loss: 2.6299213567610735

Epoch: 6| Step: 12
Training loss: 1.8337636861569953
Validation loss: 2.640783105815749

Epoch: 6| Step: 13
Training loss: 1.2382864485670648
Validation loss: 2.650319498823014

Epoch: 360| Step: 0
Training loss: 1.9468706623843446
Validation loss: 2.674613070208017

Epoch: 6| Step: 1
Training loss: 1.4891403001793229
Validation loss: 2.6640212129468113

Epoch: 6| Step: 2
Training loss: 1.5390096742500687
Validation loss: 2.6913426525056043

Epoch: 6| Step: 3
Training loss: 1.8344791545250223
Validation loss: 2.6462136143012

Epoch: 6| Step: 4
Training loss: 1.436247238276045
Validation loss: 2.636328457803913

Epoch: 6| Step: 5
Training loss: 2.123369376666628
Validation loss: 2.637509827798911

Epoch: 6| Step: 6
Training loss: 1.9092996935189694
Validation loss: 2.6325966494679114

Epoch: 6| Step: 7
Training loss: 1.5825205105240336
Validation loss: 2.617917041728954

Epoch: 6| Step: 8
Training loss: 1.272499066335639
Validation loss: 2.6542840002485457

Epoch: 6| Step: 9
Training loss: 2.039669487302205
Validation loss: 2.5900114685035427

Epoch: 6| Step: 10
Training loss: 1.6904938595831487
Validation loss: 2.6200634086739987

Epoch: 6| Step: 11
Training loss: 2.4171607619559365
Validation loss: 2.58979199694846

Epoch: 6| Step: 12
Training loss: 1.593439034436735
Validation loss: 2.593362020866698

Epoch: 6| Step: 13
Training loss: 1.7700200700430215
Validation loss: 2.6119605710605946

Epoch: 361| Step: 0
Training loss: 2.167194289985477
Validation loss: 2.6171796048932534

Epoch: 6| Step: 1
Training loss: 2.1611742928407334
Validation loss: 2.6132735407648573

Epoch: 6| Step: 2
Training loss: 1.6739239837724071
Validation loss: 2.655874951382344

Epoch: 6| Step: 3
Training loss: 2.4565902823689765
Validation loss: 2.7078431394985705

Epoch: 6| Step: 4
Training loss: 1.5393695041002367
Validation loss: 2.7394570489551886

Epoch: 6| Step: 5
Training loss: 2.304550115078897
Validation loss: 2.754548299629443

Epoch: 6| Step: 6
Training loss: 1.2081628328370326
Validation loss: 2.6845405015415413

Epoch: 6| Step: 7
Training loss: 2.0798508210972244
Validation loss: 2.6810646485091087

Epoch: 6| Step: 8
Training loss: 1.2608788118566696
Validation loss: 2.671157919153946

Epoch: 6| Step: 9
Training loss: 1.7946364016982763
Validation loss: 2.6287329032319007

Epoch: 6| Step: 10
Training loss: 1.7831104668132962
Validation loss: 2.5942035263225387

Epoch: 6| Step: 11
Training loss: 1.1669984186876006
Validation loss: 2.6071363733314272

Epoch: 6| Step: 12
Training loss: 1.866564786492248
Validation loss: 2.625989908941307

Epoch: 6| Step: 13
Training loss: 1.3907451792017473
Validation loss: 2.6015760022367647

Epoch: 362| Step: 0
Training loss: 1.59730223671815
Validation loss: 2.6215420153457902

Epoch: 6| Step: 1
Training loss: 1.336682652800389
Validation loss: 2.60815617464474

Epoch: 6| Step: 2
Training loss: 1.7175923697163102
Validation loss: 2.668043024789497

Epoch: 6| Step: 3
Training loss: 2.0077614388114498
Validation loss: 2.655795279083511

Epoch: 6| Step: 4
Training loss: 1.5997029744059497
Validation loss: 2.6182419204375993

Epoch: 6| Step: 5
Training loss: 1.658972607690563
Validation loss: 2.6963684519835813

Epoch: 6| Step: 6
Training loss: 1.645108300676089
Validation loss: 2.6518970051467634

Epoch: 6| Step: 7
Training loss: 1.3305927462989178
Validation loss: 2.6720546342276243

Epoch: 6| Step: 8
Training loss: 2.480843775475971
Validation loss: 2.6986391334913367

Epoch: 6| Step: 9
Training loss: 2.017266839415105
Validation loss: 2.6794566211647415

Epoch: 6| Step: 10
Training loss: 1.234784408469912
Validation loss: 2.6937616429147373

Epoch: 6| Step: 11
Training loss: 1.948087864932763
Validation loss: 2.6733583047307787

Epoch: 6| Step: 12
Training loss: 1.6875965655919165
Validation loss: 2.715076742077033

Epoch: 6| Step: 13
Training loss: 1.9824538054502099
Validation loss: 2.71977994856154

Epoch: 363| Step: 0
Training loss: 1.850094176807892
Validation loss: 2.736509757737975

Epoch: 6| Step: 1
Training loss: 2.562413283951001
Validation loss: 2.7120888396938976

Epoch: 6| Step: 2
Training loss: 1.478979806335302
Validation loss: 2.697505261684468

Epoch: 6| Step: 3
Training loss: 1.4401514230692578
Validation loss: 2.7034333628324925

Epoch: 6| Step: 4
Training loss: 1.2933308996017079
Validation loss: 2.647732876317642

Epoch: 6| Step: 5
Training loss: 1.4503929132001208
Validation loss: 2.62190189400824

Epoch: 6| Step: 6
Training loss: 1.683804315202129
Validation loss: 2.63516313039449

Epoch: 6| Step: 7
Training loss: 1.4797996277102474
Validation loss: 2.599600402373266

Epoch: 6| Step: 8
Training loss: 2.0574072181667744
Validation loss: 2.6259061974872044

Epoch: 6| Step: 9
Training loss: 1.8836988206984762
Validation loss: 2.6496986904628574

Epoch: 6| Step: 10
Training loss: 1.774407814531343
Validation loss: 2.6223081228721252

Epoch: 6| Step: 11
Training loss: 1.9125242942314198
Validation loss: 2.616944593098364

Epoch: 6| Step: 12
Training loss: 1.7417911369467045
Validation loss: 2.6613367181054395

Epoch: 6| Step: 13
Training loss: 1.9991782407543515
Validation loss: 2.7030649049874005

Epoch: 364| Step: 0
Training loss: 1.9181029977838577
Validation loss: 2.6737828423859535

Epoch: 6| Step: 1
Training loss: 1.5346941458702474
Validation loss: 2.7114355708918207

Epoch: 6| Step: 2
Training loss: 1.6905644460611404
Validation loss: 2.706794115536119

Epoch: 6| Step: 3
Training loss: 1.5795605616972899
Validation loss: 2.7196687921658422

Epoch: 6| Step: 4
Training loss: 2.1362833140785082
Validation loss: 2.6767508501929322

Epoch: 6| Step: 5
Training loss: 1.5796650085961057
Validation loss: 2.6635858849614666

Epoch: 6| Step: 6
Training loss: 1.8950295333775269
Validation loss: 2.653229390948671

Epoch: 6| Step: 7
Training loss: 2.201300440421026
Validation loss: 2.6171587131112735

Epoch: 6| Step: 8
Training loss: 2.0816191932919303
Validation loss: 2.6238460274943582

Epoch: 6| Step: 9
Training loss: 1.5353191570787545
Validation loss: 2.6041679128008086

Epoch: 6| Step: 10
Training loss: 1.8900018090537158
Validation loss: 2.6011968896085738

Epoch: 6| Step: 11
Training loss: 1.7466756717192529
Validation loss: 2.5815755544912005

Epoch: 6| Step: 12
Training loss: 1.594270882850039
Validation loss: 2.616211507070265

Epoch: 6| Step: 13
Training loss: 1.2378062591742112
Validation loss: 2.6283040974873155

Epoch: 365| Step: 0
Training loss: 1.9980440111782996
Validation loss: 2.6411340738189057

Epoch: 6| Step: 1
Training loss: 1.277509486094153
Validation loss: 2.647590614331489

Epoch: 6| Step: 2
Training loss: 1.1116203902610222
Validation loss: 2.670392656992627

Epoch: 6| Step: 3
Training loss: 1.3901082911262865
Validation loss: 2.676504842000195

Epoch: 6| Step: 4
Training loss: 2.1147285624525867
Validation loss: 2.671507098056722

Epoch: 6| Step: 5
Training loss: 1.520295174197107
Validation loss: 2.62604406574346

Epoch: 6| Step: 6
Training loss: 1.9201307367477907
Validation loss: 2.643319901034977

Epoch: 6| Step: 7
Training loss: 1.243771676492856
Validation loss: 2.644715656291554

Epoch: 6| Step: 8
Training loss: 1.4619740771332004
Validation loss: 2.6559546212911984

Epoch: 6| Step: 9
Training loss: 2.122382290724783
Validation loss: 2.668423421682402

Epoch: 6| Step: 10
Training loss: 1.9226337578801398
Validation loss: 2.7055763052140995

Epoch: 6| Step: 11
Training loss: 2.660259855384234
Validation loss: 2.664120208324022

Epoch: 6| Step: 12
Training loss: 1.5871765858574822
Validation loss: 2.738925293965699

Epoch: 6| Step: 13
Training loss: 1.6828076149135514
Validation loss: 2.7439850207611336

Epoch: 366| Step: 0
Training loss: 1.58989053793254
Validation loss: 2.7616224834205227

Epoch: 6| Step: 1
Training loss: 1.3394357043246206
Validation loss: 2.746433879106148

Epoch: 6| Step: 2
Training loss: 1.576037773468729
Validation loss: 2.654206960023917

Epoch: 6| Step: 3
Training loss: 1.4064182180881428
Validation loss: 2.635325001767215

Epoch: 6| Step: 4
Training loss: 2.4063595833534466
Validation loss: 2.593423263621661

Epoch: 6| Step: 5
Training loss: 1.498083081858532
Validation loss: 2.5901562026137137

Epoch: 6| Step: 6
Training loss: 2.0048392876881698
Validation loss: 2.5842175713669118

Epoch: 6| Step: 7
Training loss: 2.139270883222646
Validation loss: 2.602960709130583

Epoch: 6| Step: 8
Training loss: 1.8771338718171884
Validation loss: 2.593125187636392

Epoch: 6| Step: 9
Training loss: 1.3010323771788272
Validation loss: 2.6204471008390335

Epoch: 6| Step: 10
Training loss: 1.4316199744844207
Validation loss: 2.620332276601966

Epoch: 6| Step: 11
Training loss: 1.5818479832120997
Validation loss: 2.706195300388576

Epoch: 6| Step: 12
Training loss: 2.230845618268191
Validation loss: 2.753636296886316

Epoch: 6| Step: 13
Training loss: 2.320719159900314
Validation loss: 2.79615622435819

Epoch: 367| Step: 0
Training loss: 1.6478584321057326
Validation loss: 2.834697049261906

Epoch: 6| Step: 1
Training loss: 2.1279420121401924
Validation loss: 2.8593659809018948

Epoch: 6| Step: 2
Training loss: 2.4317219058014303
Validation loss: 2.7537593576921915

Epoch: 6| Step: 3
Training loss: 1.532325678209545
Validation loss: 2.7249857980900525

Epoch: 6| Step: 4
Training loss: 1.7504319611537782
Validation loss: 2.6466121478515117

Epoch: 6| Step: 5
Training loss: 1.5637042173518667
Validation loss: 2.5780030501066227

Epoch: 6| Step: 6
Training loss: 1.752762385383215
Validation loss: 2.5429159023186463

Epoch: 6| Step: 7
Training loss: 1.9120378646493017
Validation loss: 2.5789946813559346

Epoch: 6| Step: 8
Training loss: 2.1587348662675914
Validation loss: 2.5820852361547617

Epoch: 6| Step: 9
Training loss: 1.9128107454254175
Validation loss: 2.614989569566006

Epoch: 6| Step: 10
Training loss: 2.169219444982061
Validation loss: 2.602508136310251

Epoch: 6| Step: 11
Training loss: 1.350689468222078
Validation loss: 2.5885507492632693

Epoch: 6| Step: 12
Training loss: 1.3441433885186191
Validation loss: 2.6318193896356705

Epoch: 6| Step: 13
Training loss: 1.9553307247181315
Validation loss: 2.6643089411641214

Epoch: 368| Step: 0
Training loss: 1.6014329811386467
Validation loss: 2.7012047828845125

Epoch: 6| Step: 1
Training loss: 2.0540473433909945
Validation loss: 2.6862778213359633

Epoch: 6| Step: 2
Training loss: 1.7394508113370253
Validation loss: 2.688723426142487

Epoch: 6| Step: 3
Training loss: 1.749230760717963
Validation loss: 2.637852765397277

Epoch: 6| Step: 4
Training loss: 1.616090706677906
Validation loss: 2.5993721173261206

Epoch: 6| Step: 5
Training loss: 2.016220241452366
Validation loss: 2.567824035472538

Epoch: 6| Step: 6
Training loss: 1.7713897578869886
Validation loss: 2.557145611126496

Epoch: 6| Step: 7
Training loss: 1.5868624540887
Validation loss: 2.5337673824512623

Epoch: 6| Step: 8
Training loss: 1.805705126248526
Validation loss: 2.5624948439507444

Epoch: 6| Step: 9
Training loss: 2.0123522307362887
Validation loss: 2.588203505309787

Epoch: 6| Step: 10
Training loss: 1.8308743400767873
Validation loss: 2.583898195428446

Epoch: 6| Step: 11
Training loss: 1.9892611683820491
Validation loss: 2.6377073040769314

Epoch: 6| Step: 12
Training loss: 1.9288393697349455
Validation loss: 2.6668505394148125

Epoch: 6| Step: 13
Training loss: 1.3952784313045363
Validation loss: 2.7015756198203387

Epoch: 369| Step: 0
Training loss: 1.996549729673439
Validation loss: 2.729786843652217

Epoch: 6| Step: 1
Training loss: 1.4704589641076393
Validation loss: 2.7201828524191334

Epoch: 6| Step: 2
Training loss: 1.510238277380335
Validation loss: 2.710246999494444

Epoch: 6| Step: 3
Training loss: 2.1513633087303323
Validation loss: 2.6825131716824044

Epoch: 6| Step: 4
Training loss: 1.976879592007355
Validation loss: 2.6120862751859657

Epoch: 6| Step: 5
Training loss: 1.121356042889013
Validation loss: 2.63348217153227

Epoch: 6| Step: 6
Training loss: 1.3923718057519265
Validation loss: 2.560015559509299

Epoch: 6| Step: 7
Training loss: 2.2302104847194006
Validation loss: 2.6010461777930707

Epoch: 6| Step: 8
Training loss: 2.1941212310124056
Validation loss: 2.583722890174303

Epoch: 6| Step: 9
Training loss: 1.7150137780083707
Validation loss: 2.599921716220677

Epoch: 6| Step: 10
Training loss: 1.037162822488433
Validation loss: 2.614680851995935

Epoch: 6| Step: 11
Training loss: 1.772568409921824
Validation loss: 2.629312968427989

Epoch: 6| Step: 12
Training loss: 1.609354333837465
Validation loss: 2.6680960450306923

Epoch: 6| Step: 13
Training loss: 1.8458312620864625
Validation loss: 2.7301635062214924

Epoch: 370| Step: 0
Training loss: 1.6776869814909992
Validation loss: 2.714549418715969

Epoch: 6| Step: 1
Training loss: 1.7058377141605858
Validation loss: 2.71589534161612

Epoch: 6| Step: 2
Training loss: 1.3611099747028061
Validation loss: 2.7159780643740272

Epoch: 6| Step: 3
Training loss: 1.3706553918588769
Validation loss: 2.731665265880301

Epoch: 6| Step: 4
Training loss: 2.374511467731454
Validation loss: 2.6985441138597723

Epoch: 6| Step: 5
Training loss: 1.2109829309616653
Validation loss: 2.679766803009159

Epoch: 6| Step: 6
Training loss: 1.754665558729624
Validation loss: 2.62532875484954

Epoch: 6| Step: 7
Training loss: 2.039386708877438
Validation loss: 2.636097248439786

Epoch: 6| Step: 8
Training loss: 1.8447902137352858
Validation loss: 2.6128892210115766

Epoch: 6| Step: 9
Training loss: 1.0154638309245159
Validation loss: 2.611910138623701

Epoch: 6| Step: 10
Training loss: 1.6395885281640061
Validation loss: 2.6431219946771343

Epoch: 6| Step: 11
Training loss: 2.0092386012554364
Validation loss: 2.622434815941301

Epoch: 6| Step: 12
Training loss: 2.1577240701354277
Validation loss: 2.6423848023412875

Epoch: 6| Step: 13
Training loss: 1.606710209210303
Validation loss: 2.625994857094487

Epoch: 371| Step: 0
Training loss: 1.881742624563595
Validation loss: 2.660196708263237

Epoch: 6| Step: 1
Training loss: 2.5676209058959705
Validation loss: 2.633397762701479

Epoch: 6| Step: 2
Training loss: 1.5141981034627376
Validation loss: 2.645950995604903

Epoch: 6| Step: 3
Training loss: 1.4623155265601027
Validation loss: 2.668132160743391

Epoch: 6| Step: 4
Training loss: 1.3752195009678583
Validation loss: 2.6961847782750143

Epoch: 6| Step: 5
Training loss: 1.4388655106270771
Validation loss: 2.689972265258908

Epoch: 6| Step: 6
Training loss: 1.9536316481539455
Validation loss: 2.631209235279542

Epoch: 6| Step: 7
Training loss: 1.4007578518599937
Validation loss: 2.671097357837598

Epoch: 6| Step: 8
Training loss: 1.534193363043759
Validation loss: 2.616969039681379

Epoch: 6| Step: 9
Training loss: 1.1753101101977539
Validation loss: 2.624116324988418

Epoch: 6| Step: 10
Training loss: 2.6871405072744077
Validation loss: 2.6397075677031148

Epoch: 6| Step: 11
Training loss: 1.3459442764157696
Validation loss: 2.5817061396077303

Epoch: 6| Step: 12
Training loss: 1.7712789161922364
Validation loss: 2.601629873020063

Epoch: 6| Step: 13
Training loss: 1.5166932107188567
Validation loss: 2.5545702021712473

Epoch: 372| Step: 0
Training loss: 2.5326599150438214
Validation loss: 2.5540354418584412

Epoch: 6| Step: 1
Training loss: 0.9689455757840488
Validation loss: 2.604925111315317

Epoch: 6| Step: 2
Training loss: 1.357551842923719
Validation loss: 2.6332631767762003

Epoch: 6| Step: 3
Training loss: 1.2036117956063346
Validation loss: 2.67048001821385

Epoch: 6| Step: 4
Training loss: 2.1650476520042736
Validation loss: 2.732181664852255

Epoch: 6| Step: 5
Training loss: 1.444406751401721
Validation loss: 2.7366041125521763

Epoch: 6| Step: 6
Training loss: 1.6476539810765554
Validation loss: 2.7109217721151215

Epoch: 6| Step: 7
Training loss: 1.646870813237755
Validation loss: 2.7541342927200607

Epoch: 6| Step: 8
Training loss: 1.9263999827104548
Validation loss: 2.659714343261558

Epoch: 6| Step: 9
Training loss: 1.8748920409593417
Validation loss: 2.664838273352091

Epoch: 6| Step: 10
Training loss: 2.3177284725614373
Validation loss: 2.5853803866225986

Epoch: 6| Step: 11
Training loss: 1.662250732435483
Validation loss: 2.5798545199538645

Epoch: 6| Step: 12
Training loss: 1.7187319667910508
Validation loss: 2.544417305162593

Epoch: 6| Step: 13
Training loss: 1.2278263359814574
Validation loss: 2.5470887388944456

Epoch: 373| Step: 0
Training loss: 1.795243692033993
Validation loss: 2.5840681528132707

Epoch: 6| Step: 1
Training loss: 1.5288581072557328
Validation loss: 2.60610441720649

Epoch: 6| Step: 2
Training loss: 1.227556057055938
Validation loss: 2.606192545939814

Epoch: 6| Step: 3
Training loss: 1.9801512093074614
Validation loss: 2.6533122403617933

Epoch: 6| Step: 4
Training loss: 2.32734697898085
Validation loss: 2.6422314168542638

Epoch: 6| Step: 5
Training loss: 2.049388943293477
Validation loss: 2.674615536450476

Epoch: 6| Step: 6
Training loss: 1.119968128346909
Validation loss: 2.631561887836374

Epoch: 6| Step: 7
Training loss: 1.310732605191002
Validation loss: 2.7044091674818573

Epoch: 6| Step: 8
Training loss: 1.530010500229851
Validation loss: 2.724694808295053

Epoch: 6| Step: 9
Training loss: 1.680190893635719
Validation loss: 2.701327444705432

Epoch: 6| Step: 10
Training loss: 2.3585324835741015
Validation loss: 2.6709967316760204

Epoch: 6| Step: 11
Training loss: 1.5094467556721662
Validation loss: 2.6740093815300616

Epoch: 6| Step: 12
Training loss: 1.1496725901709817
Validation loss: 2.692179014812846

Epoch: 6| Step: 13
Training loss: 1.8812361960680877
Validation loss: 2.6720273009797624

Epoch: 374| Step: 0
Training loss: 1.5480243766895905
Validation loss: 2.677711314207091

Epoch: 6| Step: 1
Training loss: 1.8908711422933644
Validation loss: 2.641083070047753

Epoch: 6| Step: 2
Training loss: 1.4559922182535414
Validation loss: 2.6750433059704553

Epoch: 6| Step: 3
Training loss: 2.6324324970339563
Validation loss: 2.623196603038466

Epoch: 6| Step: 4
Training loss: 1.4812549124205692
Validation loss: 2.6710807854277436

Epoch: 6| Step: 5
Training loss: 1.0528482860304313
Validation loss: 2.696354304409386

Epoch: 6| Step: 6
Training loss: 1.8019771948926229
Validation loss: 2.702869190026286

Epoch: 6| Step: 7
Training loss: 1.1728120236557182
Validation loss: 2.681077305731309

Epoch: 6| Step: 8
Training loss: 0.8684147579019735
Validation loss: 2.6647911455026017

Epoch: 6| Step: 9
Training loss: 1.8330406547778697
Validation loss: 2.694210700801973

Epoch: 6| Step: 10
Training loss: 1.9365120491620191
Validation loss: 2.6598548363630456

Epoch: 6| Step: 11
Training loss: 1.613154667282577
Validation loss: 2.6073523351418584

Epoch: 6| Step: 12
Training loss: 1.9849492240964783
Validation loss: 2.649656587217855

Epoch: 6| Step: 13
Training loss: 1.7216492215824026
Validation loss: 2.621468044945032

Epoch: 375| Step: 0
Training loss: 1.283522149641248
Validation loss: 2.6693612333047088

Epoch: 6| Step: 1
Training loss: 1.1372095470801926
Validation loss: 2.6436814145209246

Epoch: 6| Step: 2
Training loss: 0.9241504066717773
Validation loss: 2.672885696180172

Epoch: 6| Step: 3
Training loss: 1.952715777441946
Validation loss: 2.6804981395741305

Epoch: 6| Step: 4
Training loss: 1.4807798516714803
Validation loss: 2.6662398731905563

Epoch: 6| Step: 5
Training loss: 2.1813621514024875
Validation loss: 2.708598554291713

Epoch: 6| Step: 6
Training loss: 2.1336762073273543
Validation loss: 2.612792162704082

Epoch: 6| Step: 7
Training loss: 1.640128287554617
Validation loss: 2.5991035655284205

Epoch: 6| Step: 8
Training loss: 1.400259823190361
Validation loss: 2.6208950371041126

Epoch: 6| Step: 9
Training loss: 1.6632007642115774
Validation loss: 2.6168100265139795

Epoch: 6| Step: 10
Training loss: 2.514034550370974
Validation loss: 2.5867850536811248

Epoch: 6| Step: 11
Training loss: 1.5471186590472366
Validation loss: 2.598662087496479

Epoch: 6| Step: 12
Training loss: 1.6018033474581774
Validation loss: 2.613034733281693

Epoch: 6| Step: 13
Training loss: 1.7318635920489938
Validation loss: 2.6643478449559868

Epoch: 376| Step: 0
Training loss: 1.2645165098446673
Validation loss: 2.6430444261355897

Epoch: 6| Step: 1
Training loss: 1.8001733775880675
Validation loss: 2.597362713972026

Epoch: 6| Step: 2
Training loss: 1.620270890204676
Validation loss: 2.630941176847846

Epoch: 6| Step: 3
Training loss: 1.598286175766404
Validation loss: 2.6010203517355683

Epoch: 6| Step: 4
Training loss: 1.8293476417823455
Validation loss: 2.6360750971595026

Epoch: 6| Step: 5
Training loss: 2.016491252847093
Validation loss: 2.6285818579073945

Epoch: 6| Step: 6
Training loss: 1.4080663183372926
Validation loss: 2.60846594624699

Epoch: 6| Step: 7
Training loss: 2.1858184891125316
Validation loss: 2.6358360941853647

Epoch: 6| Step: 8
Training loss: 1.4686925349255358
Validation loss: 2.634481027746361

Epoch: 6| Step: 9
Training loss: 1.5266779158037576
Validation loss: 2.5804072441357344

Epoch: 6| Step: 10
Training loss: 1.7834745202668072
Validation loss: 2.591970223765003

Epoch: 6| Step: 11
Training loss: 1.7574218315875745
Validation loss: 2.5928599657465954

Epoch: 6| Step: 12
Training loss: 2.006530114699575
Validation loss: 2.542521181971694

Epoch: 6| Step: 13
Training loss: 1.3160310657712964
Validation loss: 2.5323401642746117

Epoch: 377| Step: 0
Training loss: 2.3655032974442727
Validation loss: 2.606369831187594

Epoch: 6| Step: 1
Training loss: 1.283099212387351
Validation loss: 2.6163560448066328

Epoch: 6| Step: 2
Training loss: 2.39320862228215
Validation loss: 2.6511441094191537

Epoch: 6| Step: 3
Training loss: 1.3941756364055389
Validation loss: 2.670706688729431

Epoch: 6| Step: 4
Training loss: 1.5469878955064205
Validation loss: 2.619967556478344

Epoch: 6| Step: 5
Training loss: 1.4454249982611151
Validation loss: 2.7058432404767823

Epoch: 6| Step: 6
Training loss: 1.5208971018899844
Validation loss: 2.6567943688368283

Epoch: 6| Step: 7
Training loss: 1.7633379412027785
Validation loss: 2.6427878827331828

Epoch: 6| Step: 8
Training loss: 2.182876059522242
Validation loss: 2.61716174971785

Epoch: 6| Step: 9
Training loss: 1.1414328026995777
Validation loss: 2.6817898376546165

Epoch: 6| Step: 10
Training loss: 1.5819550672484635
Validation loss: 2.6330798548213163

Epoch: 6| Step: 11
Training loss: 1.5017850903392627
Validation loss: 2.723407716455103

Epoch: 6| Step: 12
Training loss: 1.238387623739623
Validation loss: 2.65824342613492

Epoch: 6| Step: 13
Training loss: 1.6769221763500737
Validation loss: 2.6983823092113606

Epoch: 378| Step: 0
Training loss: 2.2425173207850584
Validation loss: 2.661092808973979

Epoch: 6| Step: 1
Training loss: 1.4864872409902996
Validation loss: 2.6430442006204724

Epoch: 6| Step: 2
Training loss: 2.2775797124620363
Validation loss: 2.5981748135039893

Epoch: 6| Step: 3
Training loss: 1.7765780298096105
Validation loss: 2.61263837067639

Epoch: 6| Step: 4
Training loss: 1.9063818839055635
Validation loss: 2.6229709473180307

Epoch: 6| Step: 5
Training loss: 1.5913844785479192
Validation loss: 2.6740341088604915

Epoch: 6| Step: 6
Training loss: 1.7023193133536079
Validation loss: 2.7408830487142137

Epoch: 6| Step: 7
Training loss: 1.4984999944962458
Validation loss: 2.7586663268927833

Epoch: 6| Step: 8
Training loss: 1.518482464118519
Validation loss: 2.783671093241935

Epoch: 6| Step: 9
Training loss: 1.7150967700226107
Validation loss: 2.753139625420983

Epoch: 6| Step: 10
Training loss: 1.2120375528057354
Validation loss: 2.759007469691615

Epoch: 6| Step: 11
Training loss: 1.5579006403530369
Validation loss: 2.7316923369605144

Epoch: 6| Step: 12
Training loss: 1.5241687291324122
Validation loss: 2.7093090402801248

Epoch: 6| Step: 13
Training loss: 1.6336850841791417
Validation loss: 2.6715245007697943

Epoch: 379| Step: 0
Training loss: 1.2405157295745832
Validation loss: 2.6675246964336004

Epoch: 6| Step: 1
Training loss: 1.8743700240712453
Validation loss: 2.6362913336301275

Epoch: 6| Step: 2
Training loss: 1.6196968402479157
Validation loss: 2.6116049065151428

Epoch: 6| Step: 3
Training loss: 2.175793084432582
Validation loss: 2.6234894750951177

Epoch: 6| Step: 4
Training loss: 1.9863244640875495
Validation loss: 2.6380492971729272

Epoch: 6| Step: 5
Training loss: 2.020818126922759
Validation loss: 2.63195119592432

Epoch: 6| Step: 6
Training loss: 1.3832453680603807
Validation loss: 2.6258353917355843

Epoch: 6| Step: 7
Training loss: 1.949096125413127
Validation loss: 2.623384311508696

Epoch: 6| Step: 8
Training loss: 1.591359908150663
Validation loss: 2.687535367038061

Epoch: 6| Step: 9
Training loss: 1.9901475222937477
Validation loss: 2.7231789392325942

Epoch: 6| Step: 10
Training loss: 2.055029082823404
Validation loss: 2.7846051241977077

Epoch: 6| Step: 11
Training loss: 1.3202405379508335
Validation loss: 2.7907470403045758

Epoch: 6| Step: 12
Training loss: 1.0498012808811006
Validation loss: 2.760030573108901

Epoch: 6| Step: 13
Training loss: 1.768651613120846
Validation loss: 2.8485290557270444

Epoch: 380| Step: 0
Training loss: 1.4102264978553254
Validation loss: 2.7419380733880705

Epoch: 6| Step: 1
Training loss: 1.595833482402001
Validation loss: 2.645233181348032

Epoch: 6| Step: 2
Training loss: 1.6742467011910087
Validation loss: 2.6010526018036324

Epoch: 6| Step: 3
Training loss: 1.42646701990425
Validation loss: 2.6172489899201485

Epoch: 6| Step: 4
Training loss: 2.0399090993487814
Validation loss: 2.590009918942599

Epoch: 6| Step: 5
Training loss: 2.1459259334200826
Validation loss: 2.596861631234313

Epoch: 6| Step: 6
Training loss: 2.2961269899332977
Validation loss: 2.572786448860461

Epoch: 6| Step: 7
Training loss: 1.8462881947197263
Validation loss: 2.5940025084117484

Epoch: 6| Step: 8
Training loss: 1.5267213299528128
Validation loss: 2.6586189253133825

Epoch: 6| Step: 9
Training loss: 1.62873967551694
Validation loss: 2.709260566638488

Epoch: 6| Step: 10
Training loss: 1.6978241908939848
Validation loss: 2.6699856925133347

Epoch: 6| Step: 11
Training loss: 1.5484510927344706
Validation loss: 2.7197233481990284

Epoch: 6| Step: 12
Training loss: 1.6430010347554622
Validation loss: 2.694597600951517

Epoch: 6| Step: 13
Training loss: 1.4743599585994467
Validation loss: 2.690829469456108

Epoch: 381| Step: 0
Training loss: 1.8351252930402344
Validation loss: 2.6631407275716907

Epoch: 6| Step: 1
Training loss: 1.7187078297383491
Validation loss: 2.6273287026039376

Epoch: 6| Step: 2
Training loss: 1.4117938225971591
Validation loss: 2.7015058486143717

Epoch: 6| Step: 3
Training loss: 1.4043878730078676
Validation loss: 2.6670955869320387

Epoch: 6| Step: 4
Training loss: 1.4436551050483468
Validation loss: 2.645883144200146

Epoch: 6| Step: 5
Training loss: 1.9177968866919528
Validation loss: 2.686587230424634

Epoch: 6| Step: 6
Training loss: 2.143150677331071
Validation loss: 2.6389077074372618

Epoch: 6| Step: 7
Training loss: 1.6463901768863083
Validation loss: 2.659013709133502

Epoch: 6| Step: 8
Training loss: 1.7666832107393091
Validation loss: 2.668032584443683

Epoch: 6| Step: 9
Training loss: 2.192930836990249
Validation loss: 2.6448569310897385

Epoch: 6| Step: 10
Training loss: 1.4253357073553266
Validation loss: 2.6373236972406513

Epoch: 6| Step: 11
Training loss: 2.0019316881474225
Validation loss: 2.6429777329596966

Epoch: 6| Step: 12
Training loss: 1.46395008547173
Validation loss: 2.6350847620785602

Epoch: 6| Step: 13
Training loss: 1.4170063210011887
Validation loss: 2.614503947923444

Epoch: 382| Step: 0
Training loss: 1.1881352281606767
Validation loss: 2.6584123075547206

Epoch: 6| Step: 1
Training loss: 1.4070061663944595
Validation loss: 2.60900661586392

Epoch: 6| Step: 2
Training loss: 1.9062557533052267
Validation loss: 2.620946031966429

Epoch: 6| Step: 3
Training loss: 1.71666480067377
Validation loss: 2.609082995616104

Epoch: 6| Step: 4
Training loss: 1.5270468186631214
Validation loss: 2.625641033072502

Epoch: 6| Step: 5
Training loss: 1.8456319482390295
Validation loss: 2.6248769428534158

Epoch: 6| Step: 6
Training loss: 1.6238013761995445
Validation loss: 2.650156369184266

Epoch: 6| Step: 7
Training loss: 1.6014739221408256
Validation loss: 2.654650531980658

Epoch: 6| Step: 8
Training loss: 2.2436461273206865
Validation loss: 2.6880596228800884

Epoch: 6| Step: 9
Training loss: 2.056976783573208
Validation loss: 2.666166427501965

Epoch: 6| Step: 10
Training loss: 1.8712212314063361
Validation loss: 2.683580660429473

Epoch: 6| Step: 11
Training loss: 1.8639177238986766
Validation loss: 2.697777841499212

Epoch: 6| Step: 12
Training loss: 1.5891054580868404
Validation loss: 2.7389761151482537

Epoch: 6| Step: 13
Training loss: 1.5112496370199948
Validation loss: 2.695759877103753

Epoch: 383| Step: 0
Training loss: 1.2927843406068775
Validation loss: 2.68887401912543

Epoch: 6| Step: 1
Training loss: 1.4586086376637948
Validation loss: 2.6705120990485995

Epoch: 6| Step: 2
Training loss: 1.3651914576168473
Validation loss: 2.6720209286345065

Epoch: 6| Step: 3
Training loss: 1.5839547226243478
Validation loss: 2.639831468881544

Epoch: 6| Step: 4
Training loss: 1.1108356584742585
Validation loss: 2.6454212788994123

Epoch: 6| Step: 5
Training loss: 1.8474961709484845
Validation loss: 2.6524793602382792

Epoch: 6| Step: 6
Training loss: 2.130771093174386
Validation loss: 2.6528973832609646

Epoch: 6| Step: 7
Training loss: 1.1207160978207964
Validation loss: 2.6506784461312636

Epoch: 6| Step: 8
Training loss: 1.9320541880256696
Validation loss: 2.6306473217723534

Epoch: 6| Step: 9
Training loss: 1.3444691884747433
Validation loss: 2.651060367860515

Epoch: 6| Step: 10
Training loss: 1.9978037935207766
Validation loss: 2.664271908581488

Epoch: 6| Step: 11
Training loss: 2.015576975642153
Validation loss: 2.6721331971694675

Epoch: 6| Step: 12
Training loss: 1.7470537998363718
Validation loss: 2.6741654541101636

Epoch: 6| Step: 13
Training loss: 2.183196057185173
Validation loss: 2.654080945182212

Epoch: 384| Step: 0
Training loss: 1.9353078315391514
Validation loss: 2.6457970133613933

Epoch: 6| Step: 1
Training loss: 1.3355954719531822
Validation loss: 2.650623660804958

Epoch: 6| Step: 2
Training loss: 2.3256093200958747
Validation loss: 2.7146777058784752

Epoch: 6| Step: 3
Training loss: 1.465394997189316
Validation loss: 2.7207361325655395

Epoch: 6| Step: 4
Training loss: 2.023173075597647
Validation loss: 2.6641304999330693

Epoch: 6| Step: 5
Training loss: 1.544701098691493
Validation loss: 2.7108687539595597

Epoch: 6| Step: 6
Training loss: 1.7570558402926106
Validation loss: 2.732874125968494

Epoch: 6| Step: 7
Training loss: 1.4881519651953872
Validation loss: 2.6596893483369413

Epoch: 6| Step: 8
Training loss: 1.2255811713988503
Validation loss: 2.6693782927429472

Epoch: 6| Step: 9
Training loss: 1.2464537384562298
Validation loss: 2.6834660351165516

Epoch: 6| Step: 10
Training loss: 1.7656145348702925
Validation loss: 2.7103617896922287

Epoch: 6| Step: 11
Training loss: 0.9904081353919574
Validation loss: 2.6917351169759907

Epoch: 6| Step: 12
Training loss: 2.499709684681489
Validation loss: 2.656483344506129

Epoch: 6| Step: 13
Training loss: 1.8212150333689774
Validation loss: 2.6916715346332696

Epoch: 385| Step: 0
Training loss: 1.3663644111382836
Validation loss: 2.652969473813563

Epoch: 6| Step: 1
Training loss: 1.7867465959054565
Validation loss: 2.676284126492959

Epoch: 6| Step: 2
Training loss: 1.704237898042879
Validation loss: 2.702632190272102

Epoch: 6| Step: 3
Training loss: 1.5192726523207887
Validation loss: 2.7001137103166477

Epoch: 6| Step: 4
Training loss: 1.7751034209518817
Validation loss: 2.7182159191558464

Epoch: 6| Step: 5
Training loss: 1.8962633532542412
Validation loss: 2.727429183893785

Epoch: 6| Step: 6
Training loss: 1.483137638956094
Validation loss: 2.731006822155468

Epoch: 6| Step: 7
Training loss: 1.8419226950329752
Validation loss: 2.7238631271344658

Epoch: 6| Step: 8
Training loss: 1.6797283788630268
Validation loss: 2.6979607587080965

Epoch: 6| Step: 9
Training loss: 2.329587745705537
Validation loss: 2.687744632203105

Epoch: 6| Step: 10
Training loss: 1.4977418273132286
Validation loss: 2.6705611867413017

Epoch: 6| Step: 11
Training loss: 1.2902598051405587
Validation loss: 2.7133895382304747

Epoch: 6| Step: 12
Training loss: 1.4457547722542616
Validation loss: 2.6908298534072705

Epoch: 6| Step: 13
Training loss: 1.094221667359791
Validation loss: 2.6837258119030585

Epoch: 386| Step: 0
Training loss: 1.837264210630329
Validation loss: 2.6606111216942963

Epoch: 6| Step: 1
Training loss: 2.0835177784969794
Validation loss: 2.626201158033377

Epoch: 6| Step: 2
Training loss: 1.333654360072657
Validation loss: 2.6786843693855396

Epoch: 6| Step: 3
Training loss: 1.301576205361187
Validation loss: 2.6428487018440587

Epoch: 6| Step: 4
Training loss: 1.0029823415690775
Validation loss: 2.6519455833251033

Epoch: 6| Step: 5
Training loss: 2.0316378883324315
Validation loss: 2.6599398995065697

Epoch: 6| Step: 6
Training loss: 1.6705012872274783
Validation loss: 2.6802408668351307

Epoch: 6| Step: 7
Training loss: 1.6402727748067072
Validation loss: 2.6420722621975936

Epoch: 6| Step: 8
Training loss: 1.2822172654127912
Validation loss: 2.6668998919263207

Epoch: 6| Step: 9
Training loss: 1.9992258838736472
Validation loss: 2.687286250167661

Epoch: 6| Step: 10
Training loss: 1.0671205468908749
Validation loss: 2.6552061984588753

Epoch: 6| Step: 11
Training loss: 1.7585322284147689
Validation loss: 2.64195198559983

Epoch: 6| Step: 12
Training loss: 1.400861631641269
Validation loss: 2.64833002613198

Epoch: 6| Step: 13
Training loss: 1.844899675799874
Validation loss: 2.637899342658142

Epoch: 387| Step: 0
Training loss: 1.9518987849994487
Validation loss: 2.678290148301633

Epoch: 6| Step: 1
Training loss: 1.168681102904706
Validation loss: 2.658453547192113

Epoch: 6| Step: 2
Training loss: 1.3363333667695811
Validation loss: 2.677074986505422

Epoch: 6| Step: 3
Training loss: 1.6452972005656263
Validation loss: 2.6375739173113244

Epoch: 6| Step: 4
Training loss: 1.973093116654905
Validation loss: 2.684142536464247

Epoch: 6| Step: 5
Training loss: 2.2697554196922116
Validation loss: 2.641830334772774

Epoch: 6| Step: 6
Training loss: 0.9745528638582649
Validation loss: 2.691950417749273

Epoch: 6| Step: 7
Training loss: 1.2521799628895103
Validation loss: 2.6323422126058307

Epoch: 6| Step: 8
Training loss: 2.043169350923098
Validation loss: 2.6873222558438243

Epoch: 6| Step: 9
Training loss: 1.6979846901714517
Validation loss: 2.6532870653166354

Epoch: 6| Step: 10
Training loss: 2.0284623016923944
Validation loss: 2.7123773142761123

Epoch: 6| Step: 11
Training loss: 1.3025378946953172
Validation loss: 2.6752213015179014

Epoch: 6| Step: 12
Training loss: 1.5826508992161452
Validation loss: 2.7047073348838824

Epoch: 6| Step: 13
Training loss: 1.1510174894023262
Validation loss: 2.708723507188147

Epoch: 388| Step: 0
Training loss: 1.4830316990546766
Validation loss: 2.6989361863066215

Epoch: 6| Step: 1
Training loss: 1.6428276171903937
Validation loss: 2.6896182295596187

Epoch: 6| Step: 2
Training loss: 1.2650266575171947
Validation loss: 2.6598906008612473

Epoch: 6| Step: 3
Training loss: 1.8558680696952188
Validation loss: 2.629606368168949

Epoch: 6| Step: 4
Training loss: 1.2958197839320904
Validation loss: 2.6818063438871347

Epoch: 6| Step: 5
Training loss: 2.2453019579252995
Validation loss: 2.647448562336114

Epoch: 6| Step: 6
Training loss: 1.536506660692778
Validation loss: 2.6647266891208585

Epoch: 6| Step: 7
Training loss: 1.6215030750877166
Validation loss: 2.6480259158219477

Epoch: 6| Step: 8
Training loss: 1.3648575466006763
Validation loss: 2.688983936333238

Epoch: 6| Step: 9
Training loss: 2.039035022301989
Validation loss: 2.6785911934744027

Epoch: 6| Step: 10
Training loss: 1.1698347005064835
Validation loss: 2.644813293412681

Epoch: 6| Step: 11
Training loss: 1.7367770769944368
Validation loss: 2.664520895442396

Epoch: 6| Step: 12
Training loss: 1.7322620890147777
Validation loss: 2.7265982347713487

Epoch: 6| Step: 13
Training loss: 1.1267925921630293
Validation loss: 2.7201862268649335

Epoch: 389| Step: 0
Training loss: 1.6819822737477528
Validation loss: 2.740811936699067

Epoch: 6| Step: 1
Training loss: 1.5419202888062893
Validation loss: 2.7299483444115036

Epoch: 6| Step: 2
Training loss: 1.7387066609886523
Validation loss: 2.6754544023689273

Epoch: 6| Step: 3
Training loss: 1.5152548898486773
Validation loss: 2.7351106362569535

Epoch: 6| Step: 4
Training loss: 1.437750753010828
Validation loss: 2.7156096039142814

Epoch: 6| Step: 5
Training loss: 1.2653656211022346
Validation loss: 2.702676710173481

Epoch: 6| Step: 6
Training loss: 1.7803042393968658
Validation loss: 2.6852295178252956

Epoch: 6| Step: 7
Training loss: 1.2776802389722957
Validation loss: 2.689401190687328

Epoch: 6| Step: 8
Training loss: 1.7755348474321198
Validation loss: 2.6665017752530322

Epoch: 6| Step: 9
Training loss: 2.101776906247486
Validation loss: 2.673502703253732

Epoch: 6| Step: 10
Training loss: 2.1828183894258864
Validation loss: 2.671135262747567

Epoch: 6| Step: 11
Training loss: 1.1272674598179242
Validation loss: 2.6398484632561567

Epoch: 6| Step: 12
Training loss: 1.5349426897514882
Validation loss: 2.6645616677133908

Epoch: 6| Step: 13
Training loss: 1.342871356514955
Validation loss: 2.647354909963425

Epoch: 390| Step: 0
Training loss: 1.2600827313313596
Validation loss: 2.638766791770487

Epoch: 6| Step: 1
Training loss: 1.8660263217733628
Validation loss: 2.6312497988449346

Epoch: 6| Step: 2
Training loss: 1.576391041773345
Validation loss: 2.630346242984251

Epoch: 6| Step: 3
Training loss: 1.338321143166467
Validation loss: 2.667833331326409

Epoch: 6| Step: 4
Training loss: 1.7395271551080065
Validation loss: 2.683106964545951

Epoch: 6| Step: 5
Training loss: 1.3495023163262891
Validation loss: 2.668663891274906

Epoch: 6| Step: 6
Training loss: 1.1732881290946873
Validation loss: 2.7290597462761252

Epoch: 6| Step: 7
Training loss: 1.8746359789662215
Validation loss: 2.7073353518143697

Epoch: 6| Step: 8
Training loss: 2.010062415449198
Validation loss: 2.6591517437267393

Epoch: 6| Step: 9
Training loss: 1.8361894799861325
Validation loss: 2.6325175858767897

Epoch: 6| Step: 10
Training loss: 1.6204888743507408
Validation loss: 2.6863310289831803

Epoch: 6| Step: 11
Training loss: 1.315489724423951
Validation loss: 2.6721305501876387

Epoch: 6| Step: 12
Training loss: 1.6233948335740904
Validation loss: 2.7146463372703415

Epoch: 6| Step: 13
Training loss: 1.7131204831475406
Validation loss: 2.650235656240785

Epoch: 391| Step: 0
Training loss: 1.5314262444411373
Validation loss: 2.656087960181318

Epoch: 6| Step: 1
Training loss: 1.7554006348566074
Validation loss: 2.64763139217981

Epoch: 6| Step: 2
Training loss: 1.0878286018703127
Validation loss: 2.6365270625007873

Epoch: 6| Step: 3
Training loss: 2.1565754962657233
Validation loss: 2.6190169284104012

Epoch: 6| Step: 4
Training loss: 1.8163308404835488
Validation loss: 2.6229542374792203

Epoch: 6| Step: 5
Training loss: 1.4576455628874996
Validation loss: 2.575528619572538

Epoch: 6| Step: 6
Training loss: 1.195409234813743
Validation loss: 2.624019984820486

Epoch: 6| Step: 7
Training loss: 1.5279485183251758
Validation loss: 2.60530072251386

Epoch: 6| Step: 8
Training loss: 1.9352987151515049
Validation loss: 2.6147356989464248

Epoch: 6| Step: 9
Training loss: 1.6103079600818908
Validation loss: 2.637302904764774

Epoch: 6| Step: 10
Training loss: 1.5609142649222423
Validation loss: 2.611006776661859

Epoch: 6| Step: 11
Training loss: 1.1669289543865005
Validation loss: 2.6403311541483747

Epoch: 6| Step: 12
Training loss: 1.7581258536891715
Validation loss: 2.6587639823561453

Epoch: 6| Step: 13
Training loss: 1.6229212743312604
Validation loss: 2.70703016375602

Epoch: 392| Step: 0
Training loss: 1.4202715877268166
Validation loss: 2.6881146726075076

Epoch: 6| Step: 1
Training loss: 2.327250271520866
Validation loss: 2.6940738798950643

Epoch: 6| Step: 2
Training loss: 1.2262372600115266
Validation loss: 2.679161591077617

Epoch: 6| Step: 3
Training loss: 1.9401366228977364
Validation loss: 2.6675378349979266

Epoch: 6| Step: 4
Training loss: 1.3838889463526678
Validation loss: 2.643287430044377

Epoch: 6| Step: 5
Training loss: 1.2481195133186054
Validation loss: 2.626672681093188

Epoch: 6| Step: 6
Training loss: 1.4581123820452613
Validation loss: 2.6321049162951176

Epoch: 6| Step: 7
Training loss: 1.4588815839270954
Validation loss: 2.6144703363163346

Epoch: 6| Step: 8
Training loss: 1.0334547345824034
Validation loss: 2.6255485476197933

Epoch: 6| Step: 9
Training loss: 1.649591412673414
Validation loss: 2.6495465382480994

Epoch: 6| Step: 10
Training loss: 1.2061005000629659
Validation loss: 2.681366715932695

Epoch: 6| Step: 11
Training loss: 1.5435583605717162
Validation loss: 2.66713880044926

Epoch: 6| Step: 12
Training loss: 1.648664558284865
Validation loss: 2.6941691604289644

Epoch: 6| Step: 13
Training loss: 2.0687717678618975
Validation loss: 2.644979148811403

Epoch: 393| Step: 0
Training loss: 1.4403628162443771
Validation loss: 2.6959133492042437

Epoch: 6| Step: 1
Training loss: 1.6424071305727312
Validation loss: 2.716575381338666

Epoch: 6| Step: 2
Training loss: 1.2390810913384465
Validation loss: 2.6633788319506118

Epoch: 6| Step: 3
Training loss: 1.4466518485428117
Validation loss: 2.6650326659900565

Epoch: 6| Step: 4
Training loss: 1.2780542293439354
Validation loss: 2.6592352603667515

Epoch: 6| Step: 5
Training loss: 2.0201363164399355
Validation loss: 2.652436874170611

Epoch: 6| Step: 6
Training loss: 2.0463019580804294
Validation loss: 2.6605207330777323

Epoch: 6| Step: 7
Training loss: 1.7802289077287123
Validation loss: 2.6468105063599765

Epoch: 6| Step: 8
Training loss: 1.3478872792235543
Validation loss: 2.6537028722401153

Epoch: 6| Step: 9
Training loss: 1.8825454205913863
Validation loss: 2.659831844645974

Epoch: 6| Step: 10
Training loss: 1.165115341157947
Validation loss: 2.7024999494902553

Epoch: 6| Step: 11
Training loss: 1.4272438386004678
Validation loss: 2.6791702675881717

Epoch: 6| Step: 12
Training loss: 1.9129615575793382
Validation loss: 2.672891999564718

Epoch: 6| Step: 13
Training loss: 1.1130696948972008
Validation loss: 2.7221999075574015

Epoch: 394| Step: 0
Training loss: 1.5433596345268386
Validation loss: 2.737651046812721

Epoch: 6| Step: 1
Training loss: 1.580173711160655
Validation loss: 2.6743439389777337

Epoch: 6| Step: 2
Training loss: 1.2920445022890603
Validation loss: 2.6873235570666205

Epoch: 6| Step: 3
Training loss: 1.0614868270049465
Validation loss: 2.6829771233899837

Epoch: 6| Step: 4
Training loss: 1.5153330098890392
Validation loss: 2.6751871679311603

Epoch: 6| Step: 5
Training loss: 1.7711536641329106
Validation loss: 2.6081953142190204

Epoch: 6| Step: 6
Training loss: 1.802994102870376
Validation loss: 2.6222542222902745

Epoch: 6| Step: 7
Training loss: 1.9376123457300327
Validation loss: 2.6521470189345338

Epoch: 6| Step: 8
Training loss: 1.233037972953782
Validation loss: 2.6750101653764515

Epoch: 6| Step: 9
Training loss: 1.2332058935221932
Validation loss: 2.679100291100803

Epoch: 6| Step: 10
Training loss: 1.4189534616991129
Validation loss: 2.668579567820686

Epoch: 6| Step: 11
Training loss: 1.7432619211633684
Validation loss: 2.690355484268615

Epoch: 6| Step: 12
Training loss: 2.0769620236932043
Validation loss: 2.706150236339216

Epoch: 6| Step: 13
Training loss: 1.4919943959179476
Validation loss: 2.7387540357412865

Epoch: 395| Step: 0
Training loss: 2.139855016627879
Validation loss: 2.707469528557472

Epoch: 6| Step: 1
Training loss: 1.365539473031194
Validation loss: 2.6301385675122693

Epoch: 6| Step: 2
Training loss: 1.3557755620489138
Validation loss: 2.679628273297363

Epoch: 6| Step: 3
Training loss: 1.6506061480946719
Validation loss: 2.670133978998052

Epoch: 6| Step: 4
Training loss: 1.2213408490439748
Validation loss: 2.643004231520638

Epoch: 6| Step: 5
Training loss: 1.2167690512719744
Validation loss: 2.6541618067658477

Epoch: 6| Step: 6
Training loss: 1.1923337234277454
Validation loss: 2.669071235947641

Epoch: 6| Step: 7
Training loss: 1.2712280202520228
Validation loss: 2.6828266733662005

Epoch: 6| Step: 8
Training loss: 2.112460331290421
Validation loss: 2.692644075454587

Epoch: 6| Step: 9
Training loss: 1.010198917063131
Validation loss: 2.6836676959900245

Epoch: 6| Step: 10
Training loss: 1.9902325780858547
Validation loss: 2.673567951288895

Epoch: 6| Step: 11
Training loss: 1.7391111300267754
Validation loss: 2.6802990274000655

Epoch: 6| Step: 12
Training loss: 1.3413575631816774
Validation loss: 2.64298952767112

Epoch: 6| Step: 13
Training loss: 1.6198301975128178
Validation loss: 2.616694556733539

Epoch: 396| Step: 0
Training loss: 1.1225079910401687
Validation loss: 2.6533772735415835

Epoch: 6| Step: 1
Training loss: 1.283365178435588
Validation loss: 2.680028109687738

Epoch: 6| Step: 2
Training loss: 2.114176844220392
Validation loss: 2.6198458403692397

Epoch: 6| Step: 3
Training loss: 1.1117637598358412
Validation loss: 2.6712004198522807

Epoch: 6| Step: 4
Training loss: 1.773845205621697
Validation loss: 2.6385456980240107

Epoch: 6| Step: 5
Training loss: 1.5357453669447567
Validation loss: 2.7016678265406924

Epoch: 6| Step: 6
Training loss: 1.559398319169406
Validation loss: 2.681604142946868

Epoch: 6| Step: 7
Training loss: 1.9382322834907133
Validation loss: 2.655403076987871

Epoch: 6| Step: 8
Training loss: 1.69313725441363
Validation loss: 2.6549239345413422

Epoch: 6| Step: 9
Training loss: 1.4551918343783092
Validation loss: 2.671399258204325

Epoch: 6| Step: 10
Training loss: 2.1090636977320787
Validation loss: 2.699260558611027

Epoch: 6| Step: 11
Training loss: 1.0350314083033019
Validation loss: 2.6420288116487742

Epoch: 6| Step: 12
Training loss: 1.374934715108298
Validation loss: 2.6379574275077418

Epoch: 6| Step: 13
Training loss: 1.134626317624332
Validation loss: 2.695930329061198

Epoch: 397| Step: 0
Training loss: 2.5793759172279422
Validation loss: 2.6858924966991644

Epoch: 6| Step: 1
Training loss: 1.0552300082230965
Validation loss: 2.6717479593811686

Epoch: 6| Step: 2
Training loss: 1.2264279820245352
Validation loss: 2.6459689568630202

Epoch: 6| Step: 3
Training loss: 1.618254231419564
Validation loss: 2.6611009247062145

Epoch: 6| Step: 4
Training loss: 1.2760733256662042
Validation loss: 2.6977521534449433

Epoch: 6| Step: 5
Training loss: 1.3625224715313347
Validation loss: 2.6974087289778264

Epoch: 6| Step: 6
Training loss: 1.9363953302266834
Validation loss: 2.6772129062114844

Epoch: 6| Step: 7
Training loss: 1.3209792039549655
Validation loss: 2.6819115872518493

Epoch: 6| Step: 8
Training loss: 1.263878311676555
Validation loss: 2.64384142670239

Epoch: 6| Step: 9
Training loss: 1.4114299738476008
Validation loss: 2.7368877817874546

Epoch: 6| Step: 10
Training loss: 1.561603288833485
Validation loss: 2.6906190485930925

Epoch: 6| Step: 11
Training loss: 1.9018154154760225
Validation loss: 2.6341319263520275

Epoch: 6| Step: 12
Training loss: 1.0900166145423347
Validation loss: 2.6811672532859596

Epoch: 6| Step: 13
Training loss: 1.5223190505764705
Validation loss: 2.6775189848012184

Epoch: 398| Step: 0
Training loss: 1.4457931131857191
Validation loss: 2.681824272444695

Epoch: 6| Step: 1
Training loss: 1.2902388782520802
Validation loss: 2.649090651671228

Epoch: 6| Step: 2
Training loss: 1.8928354755611287
Validation loss: 2.6615259469259502

Epoch: 6| Step: 3
Training loss: 1.0206291163140175
Validation loss: 2.7269602488189877

Epoch: 6| Step: 4
Training loss: 1.7075988384588692
Validation loss: 2.6757111106274527

Epoch: 6| Step: 5
Training loss: 1.9977809993862663
Validation loss: 2.688270931414403

Epoch: 6| Step: 6
Training loss: 1.276905089484561
Validation loss: 2.7120653311063143

Epoch: 6| Step: 7
Training loss: 1.686245770063814
Validation loss: 2.693264523192138

Epoch: 6| Step: 8
Training loss: 1.1711259100775389
Validation loss: 2.7156474655035683

Epoch: 6| Step: 9
Training loss: 1.5943792260389498
Validation loss: 2.6730213940610184

Epoch: 6| Step: 10
Training loss: 1.4022453082287218
Validation loss: 2.7003298808131766

Epoch: 6| Step: 11
Training loss: 1.4743815467110208
Validation loss: 2.7329210175855057

Epoch: 6| Step: 12
Training loss: 1.7716517931845257
Validation loss: 2.713489375766855

Epoch: 6| Step: 13
Training loss: 1.595761843176462
Validation loss: 2.755279530480861

Epoch: 399| Step: 0
Training loss: 2.0986749601325485
Validation loss: 2.7380544266512388

Epoch: 6| Step: 1
Training loss: 1.2394079623934415
Validation loss: 2.6822991059332835

Epoch: 6| Step: 2
Training loss: 2.168401121721398
Validation loss: 2.7088506840264985

Epoch: 6| Step: 3
Training loss: 1.338861711687038
Validation loss: 2.6618861223525716

Epoch: 6| Step: 4
Training loss: 0.8477481844923941
Validation loss: 2.6501049542786066

Epoch: 6| Step: 5
Training loss: 1.385174474365007
Validation loss: 2.6027601080201617

Epoch: 6| Step: 6
Training loss: 1.6661341134227858
Validation loss: 2.6083734230966265

Epoch: 6| Step: 7
Training loss: 1.610255768877986
Validation loss: 2.5947140200551915

Epoch: 6| Step: 8
Training loss: 1.8947475034639667
Validation loss: 2.595718953983982

Epoch: 6| Step: 9
Training loss: 1.9683892055703092
Validation loss: 2.7206710517783774

Epoch: 6| Step: 10
Training loss: 1.4474066332285693
Validation loss: 2.697836301532081

Epoch: 6| Step: 11
Training loss: 1.3325010573076987
Validation loss: 2.6788569610027744

Epoch: 6| Step: 12
Training loss: 1.2796569783316907
Validation loss: 2.6959234310072087

Epoch: 6| Step: 13
Training loss: 1.3712761477791473
Validation loss: 2.6646478779849123

Epoch: 400| Step: 0
Training loss: 1.5364363674166936
Validation loss: 2.6664565768532777

Epoch: 6| Step: 1
Training loss: 1.4092145824275581
Validation loss: 2.6328482847111796

Epoch: 6| Step: 2
Training loss: 1.7748018637737868
Validation loss: 2.620354712610102

Epoch: 6| Step: 3
Training loss: 2.0748078682433495
Validation loss: 2.6188525013676656

Epoch: 6| Step: 4
Training loss: 1.485846181925563
Validation loss: 2.643150611549496

Epoch: 6| Step: 5
Training loss: 1.1334871585086566
Validation loss: 2.6112665565249493

Epoch: 6| Step: 6
Training loss: 1.1740653866165573
Validation loss: 2.590138076774008

Epoch: 6| Step: 7
Training loss: 1.2882452946463523
Validation loss: 2.596201829385344

Epoch: 6| Step: 8
Training loss: 1.1750978023326386
Validation loss: 2.651753408122984

Epoch: 6| Step: 9
Training loss: 1.0971936102783633
Validation loss: 2.6888635783825783

Epoch: 6| Step: 10
Training loss: 2.1245419625698654
Validation loss: 2.667603869455223

Epoch: 6| Step: 11
Training loss: 1.2868009206339892
Validation loss: 2.716754122264446

Epoch: 6| Step: 12
Training loss: 2.4330403539130896
Validation loss: 2.690131518116275

Epoch: 6| Step: 13
Training loss: 1.7073691446142616
Validation loss: 2.676734980815539

Epoch: 401| Step: 0
Training loss: 1.3334039679334784
Validation loss: 2.672567757371152

Epoch: 6| Step: 1
Training loss: 1.3406524441984409
Validation loss: 2.608468833020076

Epoch: 6| Step: 2
Training loss: 1.5844947002270495
Validation loss: 2.6285428404857702

Epoch: 6| Step: 3
Training loss: 1.8579442907097568
Validation loss: 2.615835480176181

Epoch: 6| Step: 4
Training loss: 1.164748584894654
Validation loss: 2.6619766586631246

Epoch: 6| Step: 5
Training loss: 1.7051729960227955
Validation loss: 2.658410483967728

Epoch: 6| Step: 6
Training loss: 1.0189694431541352
Validation loss: 2.6821460622630817

Epoch: 6| Step: 7
Training loss: 1.9148338165087802
Validation loss: 2.7422803843128314

Epoch: 6| Step: 8
Training loss: 1.276966097472058
Validation loss: 2.7220006780154065

Epoch: 6| Step: 9
Training loss: 1.7615825321289467
Validation loss: 2.742811401918651

Epoch: 6| Step: 10
Training loss: 1.4949789251162533
Validation loss: 2.7105896329899695

Epoch: 6| Step: 11
Training loss: 1.1039094205407185
Validation loss: 2.75303545953094

Epoch: 6| Step: 12
Training loss: 1.9305947831130312
Validation loss: 2.7046383276424706

Epoch: 6| Step: 13
Training loss: 1.4673083108353986
Validation loss: 2.661182655544305

Epoch: 402| Step: 0
Training loss: 1.0841204033807728
Validation loss: 2.6479234674838112

Epoch: 6| Step: 1
Training loss: 1.530782667196174
Validation loss: 2.6732976743487256

Epoch: 6| Step: 2
Training loss: 1.8775664249459267
Validation loss: 2.6915566485884765

Epoch: 6| Step: 3
Training loss: 0.9863484899854585
Validation loss: 2.684147036919936

Epoch: 6| Step: 4
Training loss: 1.65602232609778
Validation loss: 2.7492549782920936

Epoch: 6| Step: 5
Training loss: 1.0791976126476885
Validation loss: 2.704106161991431

Epoch: 6| Step: 6
Training loss: 0.9463564885134951
Validation loss: 2.7353088963921883

Epoch: 6| Step: 7
Training loss: 1.4132101957342618
Validation loss: 2.746455943286381

Epoch: 6| Step: 8
Training loss: 1.4336378210294212
Validation loss: 2.7135158666944985

Epoch: 6| Step: 9
Training loss: 2.24855132620068
Validation loss: 2.7297759261763517

Epoch: 6| Step: 10
Training loss: 1.4205525714688931
Validation loss: 2.699694063961932

Epoch: 6| Step: 11
Training loss: 2.0688300817381045
Validation loss: 2.687527146313207

Epoch: 6| Step: 12
Training loss: 1.2931682513430873
Validation loss: 2.687737033060846

Epoch: 6| Step: 13
Training loss: 1.331260928256889
Validation loss: 2.6821929814724417

Epoch: 403| Step: 0
Training loss: 1.5920839764572852
Validation loss: 2.624450981915911

Epoch: 6| Step: 1
Training loss: 1.7240601093717494
Validation loss: 2.632183916799839

Epoch: 6| Step: 2
Training loss: 1.1770472506953864
Validation loss: 2.6121128665457105

Epoch: 6| Step: 3
Training loss: 1.3735302525991164
Validation loss: 2.652850335367707

Epoch: 6| Step: 4
Training loss: 1.6452303236448615
Validation loss: 2.677044438971408

Epoch: 6| Step: 5
Training loss: 1.4667032468453325
Validation loss: 2.6230858226847165

Epoch: 6| Step: 6
Training loss: 0.7495281006454838
Validation loss: 2.6729852254811024

Epoch: 6| Step: 7
Training loss: 2.026536490480079
Validation loss: 2.661015376028302

Epoch: 6| Step: 8
Training loss: 1.4126263486003252
Validation loss: 2.6451808745730703

Epoch: 6| Step: 9
Training loss: 1.4223312651949438
Validation loss: 2.69188396198761

Epoch: 6| Step: 10
Training loss: 1.8217615736762158
Validation loss: 2.676165149928793

Epoch: 6| Step: 11
Training loss: 1.4168417579308572
Validation loss: 2.6437406048258323

Epoch: 6| Step: 12
Training loss: 1.7951617490524998
Validation loss: 2.6705955133670916

Epoch: 6| Step: 13
Training loss: 1.013007444213146
Validation loss: 2.6689784241832486

Epoch: 404| Step: 0
Training loss: 1.1693356785567663
Validation loss: 2.6432383169131697

Epoch: 6| Step: 1
Training loss: 1.2139857166021912
Validation loss: 2.6175321741079003

Epoch: 6| Step: 2
Training loss: 1.2881859775937878
Validation loss: 2.644933432382567

Epoch: 6| Step: 3
Training loss: 1.3942737501890756
Validation loss: 2.5971046416605357

Epoch: 6| Step: 4
Training loss: 1.4342020599561098
Validation loss: 2.609591811989265

Epoch: 6| Step: 5
Training loss: 1.3744412934333894
Validation loss: 2.642901415619761

Epoch: 6| Step: 6
Training loss: 1.3219175796324476
Validation loss: 2.6603747412102177

Epoch: 6| Step: 7
Training loss: 1.7333601310688098
Validation loss: 2.673385713552444

Epoch: 6| Step: 8
Training loss: 1.5065506314575903
Validation loss: 2.674388342890418

Epoch: 6| Step: 9
Training loss: 0.9683865819188935
Validation loss: 2.6640218394169946

Epoch: 6| Step: 10
Training loss: 2.1985122331769524
Validation loss: 2.677870020084463

Epoch: 6| Step: 11
Training loss: 1.4866987009545827
Validation loss: 2.7744357609395465

Epoch: 6| Step: 12
Training loss: 1.3013139613369478
Validation loss: 2.722202316090297

Epoch: 6| Step: 13
Training loss: 1.8833992704591191
Validation loss: 2.7254047139923414

Epoch: 405| Step: 0
Training loss: 1.8576807589778743
Validation loss: 2.6965722867091313

Epoch: 6| Step: 1
Training loss: 1.3425948922489588
Validation loss: 2.702537737432035

Epoch: 6| Step: 2
Training loss: 1.9565700817585767
Validation loss: 2.6324737662964184

Epoch: 6| Step: 3
Training loss: 1.4021664988248135
Validation loss: 2.624401917519024

Epoch: 6| Step: 4
Training loss: 1.3950684952412893
Validation loss: 2.648506126152349

Epoch: 6| Step: 5
Training loss: 1.2434295107193438
Validation loss: 2.616963801147101

Epoch: 6| Step: 6
Training loss: 1.5073837698543664
Validation loss: 2.658991696458935

Epoch: 6| Step: 7
Training loss: 1.2998825497023299
Validation loss: 2.66610883799006

Epoch: 6| Step: 8
Training loss: 1.223427428768014
Validation loss: 2.671279498805988

Epoch: 6| Step: 9
Training loss: 1.53686769711007
Validation loss: 2.6073698383906083

Epoch: 6| Step: 10
Training loss: 1.9452019472382682
Validation loss: 2.6501038447012597

Epoch: 6| Step: 11
Training loss: 1.1570366941088266
Validation loss: 2.6653291184016887

Epoch: 6| Step: 12
Training loss: 1.1566604195150334
Validation loss: 2.69426193034271

Epoch: 6| Step: 13
Training loss: 1.2165989600028353
Validation loss: 2.683687448138335

Epoch: 406| Step: 0
Training loss: 0.9059122376934763
Validation loss: 2.655236473448195

Epoch: 6| Step: 1
Training loss: 1.5843300777289224
Validation loss: 2.637778039713258

Epoch: 6| Step: 2
Training loss: 1.8669763549427083
Validation loss: 2.658124404477823

Epoch: 6| Step: 3
Training loss: 1.462600169867682
Validation loss: 2.660763649255511

Epoch: 6| Step: 4
Training loss: 1.5629429761475122
Validation loss: 2.6286872065879465

Epoch: 6| Step: 5
Training loss: 1.2752486379197727
Validation loss: 2.687838791776776

Epoch: 6| Step: 6
Training loss: 1.5302726584933404
Validation loss: 2.6539685044105092

Epoch: 6| Step: 7
Training loss: 1.0876626780938838
Validation loss: 2.705165790923027

Epoch: 6| Step: 8
Training loss: 1.582993504378968
Validation loss: 2.670667989158525

Epoch: 6| Step: 9
Training loss: 1.2017986368170004
Validation loss: 2.6207708016735425

Epoch: 6| Step: 10
Training loss: 1.4161208541180437
Validation loss: 2.6340062786520835

Epoch: 6| Step: 11
Training loss: 2.158042936292133
Validation loss: 2.632843153234598

Epoch: 6| Step: 12
Training loss: 1.0667259100515432
Validation loss: 2.611769789838787

Epoch: 6| Step: 13
Training loss: 1.5502264534205206
Validation loss: 2.6246763211464272

Epoch: 407| Step: 0
Training loss: 1.1703417093174084
Validation loss: 2.6317140832929193

Epoch: 6| Step: 1
Training loss: 1.0352969092045214
Validation loss: 2.700434416979575

Epoch: 6| Step: 2
Training loss: 1.9811643323217332
Validation loss: 2.714280558105581

Epoch: 6| Step: 3
Training loss: 1.3753179702702008
Validation loss: 2.7366225097646777

Epoch: 6| Step: 4
Training loss: 1.8504922083165227
Validation loss: 2.6738557816443502

Epoch: 6| Step: 5
Training loss: 1.1173438116240828
Validation loss: 2.7444305882144886

Epoch: 6| Step: 6
Training loss: 1.243522550402189
Validation loss: 2.7117774680801383

Epoch: 6| Step: 7
Training loss: 1.5398150313131636
Validation loss: 2.7009289003119283

Epoch: 6| Step: 8
Training loss: 1.6313222993343222
Validation loss: 2.704756242718485

Epoch: 6| Step: 9
Training loss: 1.180105728892306
Validation loss: 2.6587692580955165

Epoch: 6| Step: 10
Training loss: 1.092007147615397
Validation loss: 2.6633643674017127

Epoch: 6| Step: 11
Training loss: 1.2064386289490785
Validation loss: 2.600563292739609

Epoch: 6| Step: 12
Training loss: 1.9288592704036167
Validation loss: 2.6170457184757714

Epoch: 6| Step: 13
Training loss: 1.819147875285839
Validation loss: 2.62971206868134

Epoch: 408| Step: 0
Training loss: 1.4837801092574916
Validation loss: 2.6249303808516973

Epoch: 6| Step: 1
Training loss: 1.2292103948196444
Validation loss: 2.641455059019899

Epoch: 6| Step: 2
Training loss: 1.9101184302956524
Validation loss: 2.6813628332291106

Epoch: 6| Step: 3
Training loss: 1.0309549545378462
Validation loss: 2.7076159529719965

Epoch: 6| Step: 4
Training loss: 1.0615655492380014
Validation loss: 2.71418422674164

Epoch: 6| Step: 5
Training loss: 1.542798614779447
Validation loss: 2.716736789882692

Epoch: 6| Step: 6
Training loss: 1.959638370414527
Validation loss: 2.6931274255172255

Epoch: 6| Step: 7
Training loss: 1.4448209184336251
Validation loss: 2.723149842773569

Epoch: 6| Step: 8
Training loss: 0.9472979982487636
Validation loss: 2.7087318322863814

Epoch: 6| Step: 9
Training loss: 1.9191399939015983
Validation loss: 2.705427288193393

Epoch: 6| Step: 10
Training loss: 1.3996764933244275
Validation loss: 2.6884752766155433

Epoch: 6| Step: 11
Training loss: 1.3493386644398189
Validation loss: 2.674783161323225

Epoch: 6| Step: 12
Training loss: 1.883260080156349
Validation loss: 2.677189826084155

Epoch: 6| Step: 13
Training loss: 0.6891534602534674
Validation loss: 2.6571358419080107

Epoch: 409| Step: 0
Training loss: 1.505672220556119
Validation loss: 2.670302644119541

Epoch: 6| Step: 1
Training loss: 1.2683429027318351
Validation loss: 2.6528606107826906

Epoch: 6| Step: 2
Training loss: 1.482833704580751
Validation loss: 2.7008040134690696

Epoch: 6| Step: 3
Training loss: 1.232312180946782
Validation loss: 2.6811766643320776

Epoch: 6| Step: 4
Training loss: 1.208366716954136
Validation loss: 2.7288118864676045

Epoch: 6| Step: 5
Training loss: 1.057455654612314
Validation loss: 2.6731731614822527

Epoch: 6| Step: 6
Training loss: 1.2529545199519387
Validation loss: 2.676184556550805

Epoch: 6| Step: 7
Training loss: 1.0837548365149545
Validation loss: 2.7133194044663234

Epoch: 6| Step: 8
Training loss: 2.547099191358455
Validation loss: 2.6355035237309448

Epoch: 6| Step: 9
Training loss: 1.1268640545796382
Validation loss: 2.6512130851759577

Epoch: 6| Step: 10
Training loss: 1.7932762264650997
Validation loss: 2.6538704928958676

Epoch: 6| Step: 11
Training loss: 1.3403081950863212
Validation loss: 2.689072924897968

Epoch: 6| Step: 12
Training loss: 1.1949569073492787
Validation loss: 2.645753969418957

Epoch: 6| Step: 13
Training loss: 1.7124117417807763
Validation loss: 2.6755414572236416

Epoch: 410| Step: 0
Training loss: 1.6938218273965795
Validation loss: 2.6224359448019188

Epoch: 6| Step: 1
Training loss: 1.8927202200914346
Validation loss: 2.671863778966352

Epoch: 6| Step: 2
Training loss: 1.0902060176669988
Validation loss: 2.7232167612462104

Epoch: 6| Step: 3
Training loss: 0.9749538447385984
Validation loss: 2.7671736783113796

Epoch: 6| Step: 4
Training loss: 1.2531821753950154
Validation loss: 2.672140595321066

Epoch: 6| Step: 5
Training loss: 1.657933081754707
Validation loss: 2.7285438923883594

Epoch: 6| Step: 6
Training loss: 1.4339796996761327
Validation loss: 2.7061346715208967

Epoch: 6| Step: 7
Training loss: 1.3838543173211182
Validation loss: 2.6563939074260654

Epoch: 6| Step: 8
Training loss: 1.6092610735521884
Validation loss: 2.683647736400128

Epoch: 6| Step: 9
Training loss: 1.0057332672767798
Validation loss: 2.68206965197391

Epoch: 6| Step: 10
Training loss: 1.48367935745227
Validation loss: 2.672461610761596

Epoch: 6| Step: 11
Training loss: 1.1134354334021659
Validation loss: 2.6670693053814416

Epoch: 6| Step: 12
Training loss: 1.6438523293324907
Validation loss: 2.7053617289730747

Epoch: 6| Step: 13
Training loss: 1.9121394247590884
Validation loss: 2.713916691633663

Epoch: 411| Step: 0
Training loss: 1.1064887311855465
Validation loss: 2.6911203410631455

Epoch: 6| Step: 1
Training loss: 1.1520680243157333
Validation loss: 2.666296006807432

Epoch: 6| Step: 2
Training loss: 1.9429450892229863
Validation loss: 2.708728810315355

Epoch: 6| Step: 3
Training loss: 1.5482924161472367
Validation loss: 2.660928980869134

Epoch: 6| Step: 4
Training loss: 1.27063114350537
Validation loss: 2.7072438518494164

Epoch: 6| Step: 5
Training loss: 1.3583589461706524
Validation loss: 2.6928731005866653

Epoch: 6| Step: 6
Training loss: 1.1660475734506333
Validation loss: 2.6269687656849285

Epoch: 6| Step: 7
Training loss: 1.456148836608638
Validation loss: 2.614667295853019

Epoch: 6| Step: 8
Training loss: 1.8791662976024235
Validation loss: 2.6071973230106096

Epoch: 6| Step: 9
Training loss: 1.6653408817357398
Validation loss: 2.5520814908598393

Epoch: 6| Step: 10
Training loss: 1.3698798998516988
Validation loss: 2.5679321397864743

Epoch: 6| Step: 11
Training loss: 1.6344026552271176
Validation loss: 2.596396019590942

Epoch: 6| Step: 12
Training loss: 1.115026504731873
Validation loss: 2.5897298244084817

Epoch: 6| Step: 13
Training loss: 0.9362545323485004
Validation loss: 2.608017056051505

Epoch: 412| Step: 0
Training loss: 1.3274158604137463
Validation loss: 2.686350724568652

Epoch: 6| Step: 1
Training loss: 1.8575961796336025
Validation loss: 2.6673037741460592

Epoch: 6| Step: 2
Training loss: 1.4667617651423812
Validation loss: 2.7383857014207633

Epoch: 6| Step: 3
Training loss: 1.3215058931904162
Validation loss: 2.769703101532736

Epoch: 6| Step: 4
Training loss: 1.5277085124796494
Validation loss: 2.7265594103485062

Epoch: 6| Step: 5
Training loss: 1.435124632311115
Validation loss: 2.7163029762716047

Epoch: 6| Step: 6
Training loss: 1.2324457181386383
Validation loss: 2.7223742068501915

Epoch: 6| Step: 7
Training loss: 1.2054962471516315
Validation loss: 2.6386523430753406

Epoch: 6| Step: 8
Training loss: 0.9894819843527741
Validation loss: 2.589264833275295

Epoch: 6| Step: 9
Training loss: 1.2487067208031106
Validation loss: 2.5751468295607522

Epoch: 6| Step: 10
Training loss: 1.7744737194154203
Validation loss: 2.6058434136462774

Epoch: 6| Step: 11
Training loss: 2.1023394768542834
Validation loss: 2.5860998250640144

Epoch: 6| Step: 12
Training loss: 1.7957767613374018
Validation loss: 2.5869898196367718

Epoch: 6| Step: 13
Training loss: 0.9001187722989645
Validation loss: 2.5855793776992786

Epoch: 413| Step: 0
Training loss: 1.2161644138438865
Validation loss: 2.615899736141484

Epoch: 6| Step: 1
Training loss: 1.5518435435922857
Validation loss: 2.594837175355842

Epoch: 6| Step: 2
Training loss: 1.3419515417875496
Validation loss: 2.6534428741936176

Epoch: 6| Step: 3
Training loss: 1.6668896367017234
Validation loss: 2.679925995084878

Epoch: 6| Step: 4
Training loss: 1.1673719227234887
Validation loss: 2.743385509707049

Epoch: 6| Step: 5
Training loss: 1.0186738834146272
Validation loss: 2.7927865206795737

Epoch: 6| Step: 6
Training loss: 2.1549695400908764
Validation loss: 2.7299232501931234

Epoch: 6| Step: 7
Training loss: 1.2918366146059919
Validation loss: 2.7506116562531

Epoch: 6| Step: 8
Training loss: 1.4879696337052237
Validation loss: 2.7002668025214467

Epoch: 6| Step: 9
Training loss: 1.205922280892934
Validation loss: 2.723030418543635

Epoch: 6| Step: 10
Training loss: 1.102341180551023
Validation loss: 2.6729837834848285

Epoch: 6| Step: 11
Training loss: 1.654510304128102
Validation loss: 2.6171518351843504

Epoch: 6| Step: 12
Training loss: 1.348376007269252
Validation loss: 2.644152269954383

Epoch: 6| Step: 13
Training loss: 1.2805541405126366
Validation loss: 2.633569021984948

Epoch: 414| Step: 0
Training loss: 1.676612985496103
Validation loss: 2.6046691918296996

Epoch: 6| Step: 1
Training loss: 1.53140655028721
Validation loss: 2.612225207489304

Epoch: 6| Step: 2
Training loss: 0.9428974545002569
Validation loss: 2.6371805573111495

Epoch: 6| Step: 3
Training loss: 1.078950648737415
Validation loss: 2.633739742071389

Epoch: 6| Step: 4
Training loss: 1.7859650830852987
Validation loss: 2.639245811105203

Epoch: 6| Step: 5
Training loss: 1.2877037516727765
Validation loss: 2.62786463696314

Epoch: 6| Step: 6
Training loss: 1.494591738348707
Validation loss: 2.6073456904298045

Epoch: 6| Step: 7
Training loss: 1.600800272361736
Validation loss: 2.645450997449531

Epoch: 6| Step: 8
Training loss: 1.1742279844244548
Validation loss: 2.6611481179080116

Epoch: 6| Step: 9
Training loss: 0.9804969874719447
Validation loss: 2.7129847759902828

Epoch: 6| Step: 10
Training loss: 1.656783180066892
Validation loss: 2.7447022792055304

Epoch: 6| Step: 11
Training loss: 1.8027658511438176
Validation loss: 2.6999982268716147

Epoch: 6| Step: 12
Training loss: 1.4892144268782828
Validation loss: 2.673470844095788

Epoch: 6| Step: 13
Training loss: 1.1301653746894893
Validation loss: 2.5978325728995375

Epoch: 415| Step: 0
Training loss: 0.8218647394156258
Validation loss: 2.5781677704933537

Epoch: 6| Step: 1
Training loss: 1.0897820568056025
Validation loss: 2.55490669764436

Epoch: 6| Step: 2
Training loss: 1.075852306847737
Validation loss: 2.5757528701312555

Epoch: 6| Step: 3
Training loss: 2.0168006484657464
Validation loss: 2.603417515128333

Epoch: 6| Step: 4
Training loss: 0.9085298340244193
Validation loss: 2.595263809215868

Epoch: 6| Step: 5
Training loss: 1.3088191051874816
Validation loss: 2.6250258701805644

Epoch: 6| Step: 6
Training loss: 1.0247557209429405
Validation loss: 2.6861742431268056

Epoch: 6| Step: 7
Training loss: 1.543261613696763
Validation loss: 2.718959347202961

Epoch: 6| Step: 8
Training loss: 1.3223205284541693
Validation loss: 2.6616231465429427

Epoch: 6| Step: 9
Training loss: 2.40193661597077
Validation loss: 2.71504237777112

Epoch: 6| Step: 10
Training loss: 1.3044006580558176
Validation loss: 2.7055335661037825

Epoch: 6| Step: 11
Training loss: 1.380011701672464
Validation loss: 2.676035744103787

Epoch: 6| Step: 12
Training loss: 1.460514272492751
Validation loss: 2.669549729578459

Epoch: 6| Step: 13
Training loss: 1.8275227655122592
Validation loss: 2.623278401473036

Epoch: 416| Step: 0
Training loss: 1.1761793305494253
Validation loss: 2.6153443332126063

Epoch: 6| Step: 1
Training loss: 0.8599150607945596
Validation loss: 2.519896913947957

Epoch: 6| Step: 2
Training loss: 1.045106903521749
Validation loss: 2.577542171682109

Epoch: 6| Step: 3
Training loss: 1.5835320782991165
Validation loss: 2.5397245042934755

Epoch: 6| Step: 4
Training loss: 1.604091303983125
Validation loss: 2.6115429489574296

Epoch: 6| Step: 5
Training loss: 1.533497154081457
Validation loss: 2.6196998494150794

Epoch: 6| Step: 6
Training loss: 1.796566082480882
Validation loss: 2.614254985319026

Epoch: 6| Step: 7
Training loss: 1.117115365213807
Validation loss: 2.6378719115830362

Epoch: 6| Step: 8
Training loss: 1.2869331574973697
Validation loss: 2.681017976338479

Epoch: 6| Step: 9
Training loss: 1.4150944943098067
Validation loss: 2.7372432088962504

Epoch: 6| Step: 10
Training loss: 1.9772248496514253
Validation loss: 2.848414916121445

Epoch: 6| Step: 11
Training loss: 2.00946890936361
Validation loss: 2.8824346720341674

Epoch: 6| Step: 12
Training loss: 1.8869004566842043
Validation loss: 2.879118043311383

Epoch: 6| Step: 13
Training loss: 1.46201680344137
Validation loss: 2.751762417822295

Epoch: 417| Step: 0
Training loss: 1.2968451255206968
Validation loss: 2.6177650459684627

Epoch: 6| Step: 1
Training loss: 1.1699454634745063
Validation loss: 2.624717598816817

Epoch: 6| Step: 2
Training loss: 1.4258068343701988
Validation loss: 2.5800696234956453

Epoch: 6| Step: 3
Training loss: 1.5296201790480142
Validation loss: 2.6072795624298966

Epoch: 6| Step: 4
Training loss: 1.1396274123422059
Validation loss: 2.633365833307258

Epoch: 6| Step: 5
Training loss: 1.5727965791178045
Validation loss: 2.6349018835563944

Epoch: 6| Step: 6
Training loss: 1.6932144895035004
Validation loss: 2.625204653558109

Epoch: 6| Step: 7
Training loss: 2.067700966566465
Validation loss: 2.631597100663732

Epoch: 6| Step: 8
Training loss: 0.9838165030970217
Validation loss: 2.613327398496169

Epoch: 6| Step: 9
Training loss: 1.0873454455463725
Validation loss: 2.611581307432065

Epoch: 6| Step: 10
Training loss: 1.133449874991275
Validation loss: 2.6498980100666687

Epoch: 6| Step: 11
Training loss: 1.1782237186103013
Validation loss: 2.694214041407731

Epoch: 6| Step: 12
Training loss: 1.9931924117977164
Validation loss: 2.7466077400417164

Epoch: 6| Step: 13
Training loss: 1.593863090541845
Validation loss: 2.7491027784444895

Epoch: 418| Step: 0
Training loss: 1.034572220639051
Validation loss: 2.7472019916629957

Epoch: 6| Step: 1
Training loss: 0.9207163496204653
Validation loss: 2.6720484627080676

Epoch: 6| Step: 2
Training loss: 1.7616001266838048
Validation loss: 2.650281993389181

Epoch: 6| Step: 3
Training loss: 1.564093120934489
Validation loss: 2.6181712413112215

Epoch: 6| Step: 4
Training loss: 1.7502226006758408
Validation loss: 2.5980769301974886

Epoch: 6| Step: 5
Training loss: 1.2548497533339928
Validation loss: 2.550171448672203

Epoch: 6| Step: 6
Training loss: 1.39924057219851
Validation loss: 2.599047891810374

Epoch: 6| Step: 7
Training loss: 1.347029565142609
Validation loss: 2.6009646961300206

Epoch: 6| Step: 8
Training loss: 1.2014168838345902
Validation loss: 2.5837129703618675

Epoch: 6| Step: 9
Training loss: 1.8666100666570495
Validation loss: 2.6211663665793954

Epoch: 6| Step: 10
Training loss: 1.2210565894507566
Validation loss: 2.651787963225252

Epoch: 6| Step: 11
Training loss: 0.9163671278672012
Validation loss: 2.6352356005401503

Epoch: 6| Step: 12
Training loss: 0.8784980334551387
Validation loss: 2.6533494708354826

Epoch: 6| Step: 13
Training loss: 1.5110624401740844
Validation loss: 2.666272407434004

Epoch: 419| Step: 0
Training loss: 1.3349328976458108
Validation loss: 2.6207232907536633

Epoch: 6| Step: 1
Training loss: 1.217792721911512
Validation loss: 2.704360841109107

Epoch: 6| Step: 2
Training loss: 1.4320921972846012
Validation loss: 2.6330841860025247

Epoch: 6| Step: 3
Training loss: 1.3042146659687501
Validation loss: 2.6241365708141293

Epoch: 6| Step: 4
Training loss: 1.1105569265409192
Validation loss: 2.603172422712098

Epoch: 6| Step: 5
Training loss: 1.1191952144497315
Validation loss: 2.6409286459874917

Epoch: 6| Step: 6
Training loss: 1.1427367010684264
Validation loss: 2.5922478458614977

Epoch: 6| Step: 7
Training loss: 1.3094764579122047
Validation loss: 2.5792180065988135

Epoch: 6| Step: 8
Training loss: 1.5362433935136646
Validation loss: 2.615862458759516

Epoch: 6| Step: 9
Training loss: 0.8939207900861305
Validation loss: 2.616966435599708

Epoch: 6| Step: 10
Training loss: 1.226636653529522
Validation loss: 2.633558150746503

Epoch: 6| Step: 11
Training loss: 1.3078282180990095
Validation loss: 2.6361332146678507

Epoch: 6| Step: 12
Training loss: 1.6264814079950587
Validation loss: 2.6550267114151684

Epoch: 6| Step: 13
Training loss: 1.7729773911843543
Validation loss: 2.655112004069786

Epoch: 420| Step: 0
Training loss: 1.1336749772691923
Validation loss: 2.646308650978201

Epoch: 6| Step: 1
Training loss: 1.2712797360613641
Validation loss: 2.676540740326073

Epoch: 6| Step: 2
Training loss: 1.9625013582261361
Validation loss: 2.6482580943750196

Epoch: 6| Step: 3
Training loss: 1.1150522166799417
Validation loss: 2.644987682056649

Epoch: 6| Step: 4
Training loss: 1.0732606256235788
Validation loss: 2.644533383675207

Epoch: 6| Step: 5
Training loss: 2.030379593034042
Validation loss: 2.6119036652494434

Epoch: 6| Step: 6
Training loss: 1.4509678898787204
Validation loss: 2.626369391609425

Epoch: 6| Step: 7
Training loss: 1.232146460565388
Validation loss: 2.607080162411806

Epoch: 6| Step: 8
Training loss: 1.388389462110708
Validation loss: 2.6010642428953075

Epoch: 6| Step: 9
Training loss: 1.2069647316982952
Validation loss: 2.5423621231999127

Epoch: 6| Step: 10
Training loss: 1.3006329609427005
Validation loss: 2.5960422329761337

Epoch: 6| Step: 11
Training loss: 1.0767500582505232
Validation loss: 2.5898887434743476

Epoch: 6| Step: 12
Training loss: 1.023214068302197
Validation loss: 2.5610109515360002

Epoch: 6| Step: 13
Training loss: 1.1563797955218211
Validation loss: 2.5578492923390415

Epoch: 421| Step: 0
Training loss: 1.905798811750695
Validation loss: 2.6338662926036007

Epoch: 6| Step: 1
Training loss: 0.9809278955685142
Validation loss: 2.6641011911157415

Epoch: 6| Step: 2
Training loss: 0.7951973102842622
Validation loss: 2.649949788871449

Epoch: 6| Step: 3
Training loss: 1.2132623812257726
Validation loss: 2.624570705490228

Epoch: 6| Step: 4
Training loss: 1.0270916879764211
Validation loss: 2.704098175329583

Epoch: 6| Step: 5
Training loss: 2.037735196446035
Validation loss: 2.7212923812544805

Epoch: 6| Step: 6
Training loss: 1.3680914805816577
Validation loss: 2.7124208465137367

Epoch: 6| Step: 7
Training loss: 0.9457865070453412
Validation loss: 2.6132699978542946

Epoch: 6| Step: 8
Training loss: 0.9527969421137465
Validation loss: 2.613535908074013

Epoch: 6| Step: 9
Training loss: 1.3611409347320307
Validation loss: 2.632458626258079

Epoch: 6| Step: 10
Training loss: 1.2431926379399438
Validation loss: 2.665050260083009

Epoch: 6| Step: 11
Training loss: 1.1558666109127387
Validation loss: 2.6557612549171856

Epoch: 6| Step: 12
Training loss: 2.117300445809694
Validation loss: 2.6867241589742354

Epoch: 6| Step: 13
Training loss: 0.9063919219338016
Validation loss: 2.7089715254629465

Epoch: 422| Step: 0
Training loss: 0.8695069987436014
Validation loss: 2.717267564029418

Epoch: 6| Step: 1
Training loss: 1.417729633441298
Validation loss: 2.689087775741675

Epoch: 6| Step: 2
Training loss: 1.5922110363958593
Validation loss: 2.724049208652643

Epoch: 6| Step: 3
Training loss: 1.233260508698411
Validation loss: 2.7395311261171615

Epoch: 6| Step: 4
Training loss: 1.243801483928987
Validation loss: 2.7665355210838225

Epoch: 6| Step: 5
Training loss: 1.7416763582218542
Validation loss: 2.7746510604182424

Epoch: 6| Step: 6
Training loss: 0.9702595670209234
Validation loss: 2.725265179718176

Epoch: 6| Step: 7
Training loss: 1.4819900627626756
Validation loss: 2.6854124463277307

Epoch: 6| Step: 8
Training loss: 1.4523442129346777
Validation loss: 2.687083256369

Epoch: 6| Step: 9
Training loss: 1.4023999811231238
Validation loss: 2.6138551136117947

Epoch: 6| Step: 10
Training loss: 0.8880604411639668
Validation loss: 2.597048381919286

Epoch: 6| Step: 11
Training loss: 1.3601693649579965
Validation loss: 2.5459302464429405

Epoch: 6| Step: 12
Training loss: 1.2986372040129162
Validation loss: 2.569724822569898

Epoch: 6| Step: 13
Training loss: 1.296912135316405
Validation loss: 2.581631551133922

Epoch: 423| Step: 0
Training loss: 1.0619475667585347
Validation loss: 2.5999291364476176

Epoch: 6| Step: 1
Training loss: 1.0495214461652003
Validation loss: 2.6169921042916355

Epoch: 6| Step: 2
Training loss: 1.6448155970540825
Validation loss: 2.6328265815154537

Epoch: 6| Step: 3
Training loss: 1.030141176529777
Validation loss: 2.645355006156414

Epoch: 6| Step: 4
Training loss: 1.4553595968321056
Validation loss: 2.6405752805584903

Epoch: 6| Step: 5
Training loss: 1.7788203215755647
Validation loss: 2.6669920385065717

Epoch: 6| Step: 6
Training loss: 1.0345901380774263
Validation loss: 2.6909985060416575

Epoch: 6| Step: 7
Training loss: 1.1204958926546462
Validation loss: 2.6229053950553616

Epoch: 6| Step: 8
Training loss: 1.0079861868297901
Validation loss: 2.6898751076702228

Epoch: 6| Step: 9
Training loss: 1.0044429546694928
Validation loss: 2.6246581838976333

Epoch: 6| Step: 10
Training loss: 1.307253250631616
Validation loss: 2.604590500991748

Epoch: 6| Step: 11
Training loss: 1.4195544411544656
Validation loss: 2.5187719654927117

Epoch: 6| Step: 12
Training loss: 1.218479322061571
Validation loss: 2.5643694191621775

Epoch: 6| Step: 13
Training loss: 1.2886111307296062
Validation loss: 2.55062094589244

Epoch: 424| Step: 0
Training loss: 1.0551432437284365
Validation loss: 2.5761236341007203

Epoch: 6| Step: 1
Training loss: 1.1561338005444493
Validation loss: 2.6057771865249735

Epoch: 6| Step: 2
Training loss: 1.7437715043686894
Validation loss: 2.6171474169038778

Epoch: 6| Step: 3
Training loss: 1.7403140408383586
Validation loss: 2.640206659349045

Epoch: 6| Step: 4
Training loss: 1.0922465208857774
Validation loss: 2.717883764950199

Epoch: 6| Step: 5
Training loss: 1.3724031635163463
Validation loss: 2.6924729210505185

Epoch: 6| Step: 6
Training loss: 1.4670224682960216
Validation loss: 2.769094327780959

Epoch: 6| Step: 7
Training loss: 1.3381545203354468
Validation loss: 2.749012191686219

Epoch: 6| Step: 8
Training loss: 1.5960162636446908
Validation loss: 2.7114390881197723

Epoch: 6| Step: 9
Training loss: 1.257363091025313
Validation loss: 2.686897890523329

Epoch: 6| Step: 10
Training loss: 0.9717197122429541
Validation loss: 2.6220789506084436

Epoch: 6| Step: 11
Training loss: 0.9553987865768498
Validation loss: 2.6289302981647964

Epoch: 6| Step: 12
Training loss: 1.1298162363231894
Validation loss: 2.6851007116362386

Epoch: 6| Step: 13
Training loss: 1.0972634695377548
Validation loss: 2.7125550939821648

Epoch: 425| Step: 0
Training loss: 1.3239712104001065
Validation loss: 2.724064627348954

Epoch: 6| Step: 1
Training loss: 1.5875055237921785
Validation loss: 2.739547835628927

Epoch: 6| Step: 2
Training loss: 1.3417454339040866
Validation loss: 2.715239220226467

Epoch: 6| Step: 3
Training loss: 1.622487840650987
Validation loss: 2.708078509349216

Epoch: 6| Step: 4
Training loss: 1.115386150875097
Validation loss: 2.670598176749607

Epoch: 6| Step: 5
Training loss: 2.1176986921784913
Validation loss: 2.6897486808493047

Epoch: 6| Step: 6
Training loss: 1.3847986817281477
Validation loss: 2.6889449087022452

Epoch: 6| Step: 7
Training loss: 1.1503263756729425
Validation loss: 2.7787447014725393

Epoch: 6| Step: 8
Training loss: 1.4138649649720496
Validation loss: 2.8364337105207063

Epoch: 6| Step: 9
Training loss: 1.8398415470312581
Validation loss: 2.8726880272795365

Epoch: 6| Step: 10
Training loss: 1.3716721578111892
Validation loss: 2.790712340534162

Epoch: 6| Step: 11
Training loss: 1.5681152153698135
Validation loss: 2.740447358971692

Epoch: 6| Step: 12
Training loss: 1.6060849234810424
Validation loss: 2.6344934185740083

Epoch: 6| Step: 13
Training loss: 1.3155273763721602
Validation loss: 2.6096181242287115

Epoch: 426| Step: 0
Training loss: 2.298520698830903
Validation loss: 2.633093406716491

Epoch: 6| Step: 1
Training loss: 1.144689607568832
Validation loss: 2.626795548223684

Epoch: 6| Step: 2
Training loss: 1.3364034810433927
Validation loss: 2.696901496176518

Epoch: 6| Step: 3
Training loss: 1.3187406313595036
Validation loss: 2.701181554696518

Epoch: 6| Step: 4
Training loss: 1.4272916135990725
Validation loss: 2.6828636275647906

Epoch: 6| Step: 5
Training loss: 1.5943061008019128
Validation loss: 2.698580234377342

Epoch: 6| Step: 6
Training loss: 0.96708107826554
Validation loss: 2.6583799013306177

Epoch: 6| Step: 7
Training loss: 0.8617523255987745
Validation loss: 2.6435327264770527

Epoch: 6| Step: 8
Training loss: 1.5987983482751242
Validation loss: 2.750206000386289

Epoch: 6| Step: 9
Training loss: 1.2124940282143684
Validation loss: 2.7603011101101527

Epoch: 6| Step: 10
Training loss: 1.229744543669512
Validation loss: 2.7606945881598812

Epoch: 6| Step: 11
Training loss: 1.0191061368628531
Validation loss: 2.7580014777342092

Epoch: 6| Step: 12
Training loss: 1.1652483436394283
Validation loss: 2.7541720214730137

Epoch: 6| Step: 13
Training loss: 1.4204549720069939
Validation loss: 2.706900948988978

Epoch: 427| Step: 0
Training loss: 1.2656944161675827
Validation loss: 2.64474243042109

Epoch: 6| Step: 1
Training loss: 1.2841160051344014
Validation loss: 2.6598481435380363

Epoch: 6| Step: 2
Training loss: 1.7938684271553202
Validation loss: 2.6355348995259504

Epoch: 6| Step: 3
Training loss: 1.378888224627116
Validation loss: 2.634735582320381

Epoch: 6| Step: 4
Training loss: 1.4671304579951223
Validation loss: 2.6062797492850427

Epoch: 6| Step: 5
Training loss: 0.7353570337585927
Validation loss: 2.6207090911365194

Epoch: 6| Step: 6
Training loss: 0.910071831582448
Validation loss: 2.6949850500844583

Epoch: 6| Step: 7
Training loss: 1.452592895872593
Validation loss: 2.672734157746639

Epoch: 6| Step: 8
Training loss: 1.1971384699695888
Validation loss: 2.710330891601954

Epoch: 6| Step: 9
Training loss: 1.4356441127516226
Validation loss: 2.723199119793652

Epoch: 6| Step: 10
Training loss: 1.5161706001393136
Validation loss: 2.715641100403731

Epoch: 6| Step: 11
Training loss: 1.2316012544688135
Validation loss: 2.656411827992083

Epoch: 6| Step: 12
Training loss: 1.08844456703505
Validation loss: 2.6138295661373565

Epoch: 6| Step: 13
Training loss: 1.0715700544311837
Validation loss: 2.597911376662223

Epoch: 428| Step: 0
Training loss: 1.3486032006219106
Validation loss: 2.5931218087449555

Epoch: 6| Step: 1
Training loss: 1.2541175735513816
Validation loss: 2.5966504131081045

Epoch: 6| Step: 2
Training loss: 1.0443220752247642
Validation loss: 2.6128033256575005

Epoch: 6| Step: 3
Training loss: 1.6381329456123548
Validation loss: 2.6146313914914074

Epoch: 6| Step: 4
Training loss: 1.3623965652821242
Validation loss: 2.604986799161513

Epoch: 6| Step: 5
Training loss: 1.2996207435966018
Validation loss: 2.618173017039502

Epoch: 6| Step: 6
Training loss: 1.1386771095639758
Validation loss: 2.6891620435065207

Epoch: 6| Step: 7
Training loss: 1.6793474429800923
Validation loss: 2.6772857668641974

Epoch: 6| Step: 8
Training loss: 1.2736274249965125
Validation loss: 2.7657497255753385

Epoch: 6| Step: 9
Training loss: 1.0642547142528367
Validation loss: 2.791327645701987

Epoch: 6| Step: 10
Training loss: 1.5616932884533754
Validation loss: 2.8068352483362276

Epoch: 6| Step: 11
Training loss: 1.249894042292633
Validation loss: 2.7171317359681826

Epoch: 6| Step: 12
Training loss: 1.156844630571814
Validation loss: 2.711001099528455

Epoch: 6| Step: 13
Training loss: 1.3775973497112712
Validation loss: 2.648682979583753

Epoch: 429| Step: 0
Training loss: 1.0705355669337617
Validation loss: 2.687588475863157

Epoch: 6| Step: 1
Training loss: 1.3441696842315032
Validation loss: 2.6508039706427846

Epoch: 6| Step: 2
Training loss: 1.4664715077142214
Validation loss: 2.633515804543917

Epoch: 6| Step: 3
Training loss: 1.2132249454322122
Validation loss: 2.617725829371982

Epoch: 6| Step: 4
Training loss: 1.6279402322318957
Validation loss: 2.6443092031339237

Epoch: 6| Step: 5
Training loss: 1.2297890375234055
Validation loss: 2.6316598091334105

Epoch: 6| Step: 6
Training loss: 0.8701202700781886
Validation loss: 2.6856311613785593

Epoch: 6| Step: 7
Training loss: 1.269829676838684
Validation loss: 2.6480729744009484

Epoch: 6| Step: 8
Training loss: 1.3024029860729411
Validation loss: 2.655452039949807

Epoch: 6| Step: 9
Training loss: 0.8669805193805756
Validation loss: 2.6968063416476897

Epoch: 6| Step: 10
Training loss: 1.5165198918819875
Validation loss: 2.679049802478854

Epoch: 6| Step: 11
Training loss: 1.0279096198075588
Validation loss: 2.707181741954286

Epoch: 6| Step: 12
Training loss: 1.2013912837911758
Validation loss: 2.7253363693353214

Epoch: 6| Step: 13
Training loss: 1.1368917222179915
Validation loss: 2.7034536025986475

Epoch: 430| Step: 0
Training loss: 1.413709058902381
Validation loss: 2.704196401549164

Epoch: 6| Step: 1
Training loss: 0.8024651663044441
Validation loss: 2.677054962918257

Epoch: 6| Step: 2
Training loss: 1.3855428948895074
Validation loss: 2.689781359162159

Epoch: 6| Step: 3
Training loss: 0.6560936014820721
Validation loss: 2.6350254828990063

Epoch: 6| Step: 4
Training loss: 1.1361759108759135
Validation loss: 2.604484894700217

Epoch: 6| Step: 5
Training loss: 1.2188372458505519
Validation loss: 2.617588236480464

Epoch: 6| Step: 6
Training loss: 0.9618474172364045
Validation loss: 2.5461819257642495

Epoch: 6| Step: 7
Training loss: 1.364787758616011
Validation loss: 2.6024349151251336

Epoch: 6| Step: 8
Training loss: 1.46935081367918
Validation loss: 2.586567843194592

Epoch: 6| Step: 9
Training loss: 1.3776793816939072
Validation loss: 2.6384365787253734

Epoch: 6| Step: 10
Training loss: 1.811506459447056
Validation loss: 2.604037874215917

Epoch: 6| Step: 11
Training loss: 1.1400933267639495
Validation loss: 2.636997929616247

Epoch: 6| Step: 12
Training loss: 1.0862367615589938
Validation loss: 2.620361422903029

Epoch: 6| Step: 13
Training loss: 1.0824258683790746
Validation loss: 2.5848220616874857

Epoch: 431| Step: 0
Training loss: 1.151776034925984
Validation loss: 2.6163795704476605

Epoch: 6| Step: 1
Training loss: 1.4365775424251872
Validation loss: 2.675772696154211

Epoch: 6| Step: 2
Training loss: 0.9589470819187106
Validation loss: 2.630835691863211

Epoch: 6| Step: 3
Training loss: 0.8892030239507691
Validation loss: 2.6898038585111657

Epoch: 6| Step: 4
Training loss: 1.3487284500055035
Validation loss: 2.7233440710701955

Epoch: 6| Step: 5
Training loss: 1.4250943135957082
Validation loss: 2.750655211797258

Epoch: 6| Step: 6
Training loss: 1.3065849258115023
Validation loss: 2.7230123672848925

Epoch: 6| Step: 7
Training loss: 0.950050460579542
Validation loss: 2.7140467363455016

Epoch: 6| Step: 8
Training loss: 1.0770851317242502
Validation loss: 2.6514345388832727

Epoch: 6| Step: 9
Training loss: 1.161166075927035
Validation loss: 2.6743670436654305

Epoch: 6| Step: 10
Training loss: 1.4637300453813036
Validation loss: 2.688672586175197

Epoch: 6| Step: 11
Training loss: 1.4476933844590485
Validation loss: 2.6818072477263764

Epoch: 6| Step: 12
Training loss: 1.0381762518222604
Validation loss: 2.7208015769129523

Epoch: 6| Step: 13
Training loss: 1.4659839312621235
Validation loss: 2.729073141888219

Epoch: 432| Step: 0
Training loss: 1.0918586727116002
Validation loss: 2.730764130208386

Epoch: 6| Step: 1
Training loss: 0.9741980653722071
Validation loss: 2.7125837620753805

Epoch: 6| Step: 2
Training loss: 1.5428485292365808
Validation loss: 2.7403494968643693

Epoch: 6| Step: 3
Training loss: 1.182614365061661
Validation loss: 2.7250877990343882

Epoch: 6| Step: 4
Training loss: 0.8428592218299515
Validation loss: 2.6916589419920376

Epoch: 6| Step: 5
Training loss: 1.4385347373992559
Validation loss: 2.754511427161278

Epoch: 6| Step: 6
Training loss: 1.0251321521328594
Validation loss: 2.7178106037010608

Epoch: 6| Step: 7
Training loss: 1.1674644376578676
Validation loss: 2.745117259876563

Epoch: 6| Step: 8
Training loss: 1.2016238470997582
Validation loss: 2.7389024001874334

Epoch: 6| Step: 9
Training loss: 1.6244429587238391
Validation loss: 2.6960924282492624

Epoch: 6| Step: 10
Training loss: 1.292788951162298
Validation loss: 2.7082162147043136

Epoch: 6| Step: 11
Training loss: 1.4481061175699557
Validation loss: 2.7162400421648205

Epoch: 6| Step: 12
Training loss: 1.0195548102334917
Validation loss: 2.7123361693332235

Epoch: 6| Step: 13
Training loss: 1.034947212273647
Validation loss: 2.643433501264656

Epoch: 433| Step: 0
Training loss: 1.2212653002371074
Validation loss: 2.642630227668521

Epoch: 6| Step: 1
Training loss: 1.3286807972928132
Validation loss: 2.664701957438242

Epoch: 6| Step: 2
Training loss: 1.471352321207245
Validation loss: 2.6624252717779746

Epoch: 6| Step: 3
Training loss: 1.1342965238134346
Validation loss: 2.6973953823558907

Epoch: 6| Step: 4
Training loss: 1.2915015986805944
Validation loss: 2.7078417454141968

Epoch: 6| Step: 5
Training loss: 0.8465049061664013
Validation loss: 2.6594954765574443

Epoch: 6| Step: 6
Training loss: 1.1119969505775957
Validation loss: 2.681625688459859

Epoch: 6| Step: 7
Training loss: 1.4900858993859476
Validation loss: 2.702833141527861

Epoch: 6| Step: 8
Training loss: 0.9944405993121473
Validation loss: 2.675174720500908

Epoch: 6| Step: 9
Training loss: 0.8717657670262688
Validation loss: 2.6665494540402177

Epoch: 6| Step: 10
Training loss: 1.442181965165351
Validation loss: 2.6335115419719974

Epoch: 6| Step: 11
Training loss: 1.1872648709061278
Validation loss: 2.653452967609625

Epoch: 6| Step: 12
Training loss: 1.1177032453996527
Validation loss: 2.6290750737465616

Epoch: 6| Step: 13
Training loss: 0.9962391466724598
Validation loss: 2.6406235704286454

Epoch: 434| Step: 0
Training loss: 1.1567503903142842
Validation loss: 2.625713902231828

Epoch: 6| Step: 1
Training loss: 1.6022019017083617
Validation loss: 2.654076086821237

Epoch: 6| Step: 2
Training loss: 1.3692567697148377
Validation loss: 2.6489949047720764

Epoch: 6| Step: 3
Training loss: 0.8885957454728081
Validation loss: 2.689985102147821

Epoch: 6| Step: 4
Training loss: 1.0871931542021718
Validation loss: 2.623852085225424

Epoch: 6| Step: 5
Training loss: 1.2537029255998622
Validation loss: 2.6964782257945723

Epoch: 6| Step: 6
Training loss: 0.9441900919785681
Validation loss: 2.6710465096685496

Epoch: 6| Step: 7
Training loss: 0.9967669437404447
Validation loss: 2.6537727472854997

Epoch: 6| Step: 8
Training loss: 1.3663723068427132
Validation loss: 2.723809646039732

Epoch: 6| Step: 9
Training loss: 1.1384383889717613
Validation loss: 2.6995245562022547

Epoch: 6| Step: 10
Training loss: 0.9822879646908421
Validation loss: 2.6780854414010573

Epoch: 6| Step: 11
Training loss: 1.262629224754481
Validation loss: 2.6549821857350446

Epoch: 6| Step: 12
Training loss: 0.9054548129176734
Validation loss: 2.68221838891139

Epoch: 6| Step: 13
Training loss: 0.9329503607674569
Validation loss: 2.6434763274494446

Epoch: 435| Step: 0
Training loss: 0.8668049492616806
Validation loss: 2.6422205662176306

Epoch: 6| Step: 1
Training loss: 1.1360503653556988
Validation loss: 2.6057546173770176

Epoch: 6| Step: 2
Training loss: 1.2820275901170337
Validation loss: 2.655932388764548

Epoch: 6| Step: 3
Training loss: 0.8996311385536421
Validation loss: 2.6574108055699512

Epoch: 6| Step: 4
Training loss: 0.9459814431828208
Validation loss: 2.67337049307012

Epoch: 6| Step: 5
Training loss: 0.9749414035110784
Validation loss: 2.667131805583348

Epoch: 6| Step: 6
Training loss: 1.4353452372207207
Validation loss: 2.738934375981882

Epoch: 6| Step: 7
Training loss: 1.522803619753416
Validation loss: 2.7709395070396936

Epoch: 6| Step: 8
Training loss: 1.192273834022281
Validation loss: 2.778997988255045

Epoch: 6| Step: 9
Training loss: 1.3513508007976338
Validation loss: 2.7480949609124137

Epoch: 6| Step: 10
Training loss: 1.1823704507040333
Validation loss: 2.779962291576137

Epoch: 6| Step: 11
Training loss: 1.1061657975905028
Validation loss: 2.7660260242011137

Epoch: 6| Step: 12
Training loss: 0.9734012554150416
Validation loss: 2.7206631794681027

Epoch: 6| Step: 13
Training loss: 1.084525143565354
Validation loss: 2.692244518677681

Epoch: 436| Step: 0
Training loss: 1.0206881569116337
Validation loss: 2.631628613630722

Epoch: 6| Step: 1
Training loss: 1.1906507754602118
Validation loss: 2.654963731679667

Epoch: 6| Step: 2
Training loss: 1.18507830992818
Validation loss: 2.666694973755639

Epoch: 6| Step: 3
Training loss: 0.8427231509521356
Validation loss: 2.648491557872094

Epoch: 6| Step: 4
Training loss: 1.4856881206168215
Validation loss: 2.6656139103732204

Epoch: 6| Step: 5
Training loss: 1.2023544816696383
Validation loss: 2.6998224682781125

Epoch: 6| Step: 6
Training loss: 0.8641707037007113
Validation loss: 2.666536407468219

Epoch: 6| Step: 7
Training loss: 0.8753079145066947
Validation loss: 2.651820315144

Epoch: 6| Step: 8
Training loss: 1.2325314625714987
Validation loss: 2.659614646026465

Epoch: 6| Step: 9
Training loss: 1.2470714118014683
Validation loss: 2.704419438010466

Epoch: 6| Step: 10
Training loss: 1.0548237465346317
Validation loss: 2.709549386331311

Epoch: 6| Step: 11
Training loss: 1.1317260267525933
Validation loss: 2.7443560568887584

Epoch: 6| Step: 12
Training loss: 1.4054739612187992
Validation loss: 2.7097721874958074

Epoch: 6| Step: 13
Training loss: 1.0074817203349558
Validation loss: 2.650815992861261

Epoch: 437| Step: 0
Training loss: 1.0828283245477144
Validation loss: 2.591482925852404

Epoch: 6| Step: 1
Training loss: 0.9839784943820221
Validation loss: 2.6262402405058944

Epoch: 6| Step: 2
Training loss: 0.9367599427342268
Validation loss: 2.6200527013084036

Epoch: 6| Step: 3
Training loss: 1.052096766521444
Validation loss: 2.637980534558593

Epoch: 6| Step: 4
Training loss: 0.9470112252521781
Validation loss: 2.6269130245206442

Epoch: 6| Step: 5
Training loss: 1.2729830720919193
Validation loss: 2.613648666759981

Epoch: 6| Step: 6
Training loss: 1.0114888404988636
Validation loss: 2.6409684508997193

Epoch: 6| Step: 7
Training loss: 1.0538112249722444
Validation loss: 2.6474313690924585

Epoch: 6| Step: 8
Training loss: 0.8903715542682819
Validation loss: 2.714162280866128

Epoch: 6| Step: 9
Training loss: 1.1707016729448316
Validation loss: 2.7143820536995613

Epoch: 6| Step: 10
Training loss: 1.0981685759616113
Validation loss: 2.709824985152577

Epoch: 6| Step: 11
Training loss: 1.079687230597323
Validation loss: 2.7540987420951937

Epoch: 6| Step: 12
Training loss: 1.36929320438877
Validation loss: 2.693440753978914

Epoch: 6| Step: 13
Training loss: 1.1366253057395752
Validation loss: 2.7023554829348924

Epoch: 438| Step: 0
Training loss: 1.0012773461959115
Validation loss: 2.700339350155406

Epoch: 6| Step: 1
Training loss: 0.8836143363085773
Validation loss: 2.6669200439082092

Epoch: 6| Step: 2
Training loss: 0.9740193019830401
Validation loss: 2.7151394104452304

Epoch: 6| Step: 3
Training loss: 0.9391789026205135
Validation loss: 2.6987784100571837

Epoch: 6| Step: 4
Training loss: 0.9886463681973411
Validation loss: 2.760532266367559

Epoch: 6| Step: 5
Training loss: 0.7414035471474005
Validation loss: 2.733702745905709

Epoch: 6| Step: 6
Training loss: 1.1536058658654416
Validation loss: 2.686210470806648

Epoch: 6| Step: 7
Training loss: 1.0714873388613082
Validation loss: 2.7149667396404924

Epoch: 6| Step: 8
Training loss: 1.0281675683574791
Validation loss: 2.7201550240376675

Epoch: 6| Step: 9
Training loss: 0.9542834948906735
Validation loss: 2.7444759720584284

Epoch: 6| Step: 10
Training loss: 0.905731546151339
Validation loss: 2.734296001928041

Epoch: 6| Step: 11
Training loss: 1.3099559014301632
Validation loss: 2.692898215430812

Epoch: 6| Step: 12
Training loss: 1.404081495213004
Validation loss: 2.687451783568315

Epoch: 6| Step: 13
Training loss: 1.3018153207242804
Validation loss: 2.7130694182809356

Epoch: 439| Step: 0
Training loss: 1.0432890210984176
Validation loss: 2.6728768952032977

Epoch: 6| Step: 1
Training loss: 1.1534200523460352
Validation loss: 2.7061792219037977

Epoch: 6| Step: 2
Training loss: 1.422970611681631
Validation loss: 2.7023218685402743

Epoch: 6| Step: 3
Training loss: 0.8004842067687875
Validation loss: 2.716554610353811

Epoch: 6| Step: 4
Training loss: 0.9317400417425198
Validation loss: 2.6575958806562143

Epoch: 6| Step: 5
Training loss: 1.0270039972043647
Validation loss: 2.69876395118998

Epoch: 6| Step: 6
Training loss: 1.0252498275730646
Validation loss: 2.6652698782659705

Epoch: 6| Step: 7
Training loss: 1.1729816043871497
Validation loss: 2.625193936888946

Epoch: 6| Step: 8
Training loss: 0.9560271308831885
Validation loss: 2.677625776815975

Epoch: 6| Step: 9
Training loss: 0.9654939753948456
Validation loss: 2.683029789272398

Epoch: 6| Step: 10
Training loss: 1.2731208641648006
Validation loss: 2.6276709425537876

Epoch: 6| Step: 11
Training loss: 0.8610264602365647
Validation loss: 2.70213201141236

Epoch: 6| Step: 12
Training loss: 0.9257632869474668
Validation loss: 2.6904130717074253

Epoch: 6| Step: 13
Training loss: 1.17348070128622
Validation loss: 2.6998223946872915

Epoch: 440| Step: 0
Training loss: 0.8564239464490297
Validation loss: 2.646300587483668

Epoch: 6| Step: 1
Training loss: 1.3422705912155397
Validation loss: 2.6224010862710134

Epoch: 6| Step: 2
Training loss: 1.1904569251908543
Validation loss: 2.6619974524707675

Epoch: 6| Step: 3
Training loss: 0.8398677024087102
Validation loss: 2.622346778468901

Epoch: 6| Step: 4
Training loss: 1.1337179840176992
Validation loss: 2.7165202501154138

Epoch: 6| Step: 5
Training loss: 0.6385252431361906
Validation loss: 2.6627607101527317

Epoch: 6| Step: 6
Training loss: 1.0016713480488264
Validation loss: 2.69386469337949

Epoch: 6| Step: 7
Training loss: 1.2194213974111292
Validation loss: 2.6620181565528926

Epoch: 6| Step: 8
Training loss: 1.1748144287314344
Validation loss: 2.65180974349743

Epoch: 6| Step: 9
Training loss: 1.0959422892565651
Validation loss: 2.6951199375233195

Epoch: 6| Step: 10
Training loss: 1.087384309863229
Validation loss: 2.6326971132554995

Epoch: 6| Step: 11
Training loss: 1.0035157390399896
Validation loss: 2.676799912546677

Epoch: 6| Step: 12
Training loss: 0.9495337320797186
Validation loss: 2.685500628448869

Epoch: 6| Step: 13
Training loss: 1.0333407045429617
Validation loss: 2.7561298600797772

Epoch: 441| Step: 0
Training loss: 1.505610701515645
Validation loss: 2.6925586139859914

Epoch: 6| Step: 1
Training loss: 0.6330566641634323
Validation loss: 2.785502294129186

Epoch: 6| Step: 2
Training loss: 1.0224598881844544
Validation loss: 2.7464713881070772

Epoch: 6| Step: 3
Training loss: 1.1083408962555799
Validation loss: 2.6892638812852154

Epoch: 6| Step: 4
Training loss: 1.1569040871234653
Validation loss: 2.6664525383173654

Epoch: 6| Step: 5
Training loss: 0.9934360728054109
Validation loss: 2.664684457975154

Epoch: 6| Step: 6
Training loss: 0.9955443419156557
Validation loss: 2.6507664495778807

Epoch: 6| Step: 7
Training loss: 1.2805240714578574
Validation loss: 2.617276196850959

Epoch: 6| Step: 8
Training loss: 0.730297007235209
Validation loss: 2.698830296433691

Epoch: 6| Step: 9
Training loss: 1.264851133385091
Validation loss: 2.70960927886797

Epoch: 6| Step: 10
Training loss: 1.3990382177628484
Validation loss: 2.707188765441747

Epoch: 6| Step: 11
Training loss: 0.7041939980283352
Validation loss: 2.685255059311147

Epoch: 6| Step: 12
Training loss: 1.1110228000090243
Validation loss: 2.6973289355251433

Epoch: 6| Step: 13
Training loss: 0.7934566180888347
Validation loss: 2.6630693599985578

Epoch: 442| Step: 0
Training loss: 0.9371416678674476
Validation loss: 2.741861735209602

Epoch: 6| Step: 1
Training loss: 0.70297703775615
Validation loss: 2.7382454064853468

Epoch: 6| Step: 2
Training loss: 1.2429986380694686
Validation loss: 2.7645309353203373

Epoch: 6| Step: 3
Training loss: 1.2760989221715848
Validation loss: 2.7384993266337627

Epoch: 6| Step: 4
Training loss: 1.179402399032919
Validation loss: 2.774500941172069

Epoch: 6| Step: 5
Training loss: 0.8477653046522697
Validation loss: 2.773260821951892

Epoch: 6| Step: 6
Training loss: 1.147369303189523
Validation loss: 2.7516161475655165

Epoch: 6| Step: 7
Training loss: 1.371523797824842
Validation loss: 2.7167304565881882

Epoch: 6| Step: 8
Training loss: 1.1344814765497322
Validation loss: 2.72915016538179

Epoch: 6| Step: 9
Training loss: 1.0487877750982009
Validation loss: 2.7355872818401448

Epoch: 6| Step: 10
Training loss: 1.1630323319209075
Validation loss: 2.751370305330166

Epoch: 6| Step: 11
Training loss: 0.8686839414771096
Validation loss: 2.6679011681236755

Epoch: 6| Step: 12
Training loss: 0.9311138079090056
Validation loss: 2.696493640043583

Epoch: 6| Step: 13
Training loss: 0.9027502952370258
Validation loss: 2.66489281118519

Epoch: 443| Step: 0
Training loss: 0.9384918687983387
Validation loss: 2.639232576866367

Epoch: 6| Step: 1
Training loss: 1.0556184968810165
Validation loss: 2.633803998758399

Epoch: 6| Step: 2
Training loss: 0.8221283206788533
Validation loss: 2.64355085448039

Epoch: 6| Step: 3
Training loss: 0.9176747602079759
Validation loss: 2.6169626927022716

Epoch: 6| Step: 4
Training loss: 1.1810574692544655
Validation loss: 2.6397012904506068

Epoch: 6| Step: 5
Training loss: 1.1006585057458793
Validation loss: 2.598315606055756

Epoch: 6| Step: 6
Training loss: 1.015680399630876
Validation loss: 2.61265263697128

Epoch: 6| Step: 7
Training loss: 1.0248743701332224
Validation loss: 2.5968763361383056

Epoch: 6| Step: 8
Training loss: 0.8249559043890778
Validation loss: 2.6455196635226206

Epoch: 6| Step: 9
Training loss: 0.9242782947645101
Validation loss: 2.698047639669867

Epoch: 6| Step: 10
Training loss: 1.1195588453875582
Validation loss: 2.6705624366131797

Epoch: 6| Step: 11
Training loss: 1.175139293124798
Validation loss: 2.6968381093118494

Epoch: 6| Step: 12
Training loss: 1.0337727063786164
Validation loss: 2.718999142394001

Epoch: 6| Step: 13
Training loss: 0.8416631109962015
Validation loss: 2.6739533281050347

Epoch: 444| Step: 0
Training loss: 1.0470816564843781
Validation loss: 2.7171945178054817

Epoch: 6| Step: 1
Training loss: 0.5638134773870923
Validation loss: 2.749076326899266

Epoch: 6| Step: 2
Training loss: 1.0321279891918944
Validation loss: 2.677209195593504

Epoch: 6| Step: 3
Training loss: 1.1825732877412762
Validation loss: 2.6507028589294714

Epoch: 6| Step: 4
Training loss: 1.0075210031445219
Validation loss: 2.6763613775062596

Epoch: 6| Step: 5
Training loss: 0.9225747313894531
Validation loss: 2.642609326577123

Epoch: 6| Step: 6
Training loss: 1.1951827433848092
Validation loss: 2.64721126169411

Epoch: 6| Step: 7
Training loss: 1.22221517681249
Validation loss: 2.699059525397221

Epoch: 6| Step: 8
Training loss: 0.952447118617841
Validation loss: 2.6203083542525802

Epoch: 6| Step: 9
Training loss: 1.0287936462562104
Validation loss: 2.6357045123251

Epoch: 6| Step: 10
Training loss: 0.8150823344433934
Validation loss: 2.7061702355309625

Epoch: 6| Step: 11
Training loss: 0.8528991148657941
Validation loss: 2.653992617443293

Epoch: 6| Step: 12
Training loss: 0.9216052485059093
Validation loss: 2.7026792390230145

Epoch: 6| Step: 13
Training loss: 1.0964702565881386
Validation loss: 2.746369971558957

Epoch: 445| Step: 0
Training loss: 1.2439386751845665
Validation loss: 2.7978447453014677

Epoch: 6| Step: 1
Training loss: 1.0593908483169376
Validation loss: 2.7747081371132376

Epoch: 6| Step: 2
Training loss: 0.9095351428833476
Validation loss: 2.661225554457149

Epoch: 6| Step: 3
Training loss: 1.0424608572694247
Validation loss: 2.6212670865378978

Epoch: 6| Step: 4
Training loss: 0.964095222993571
Validation loss: 2.706164978782693

Epoch: 6| Step: 5
Training loss: 1.046414402085098
Validation loss: 2.657656009529105

Epoch: 6| Step: 6
Training loss: 1.4255437783831524
Validation loss: 2.691363876444752

Epoch: 6| Step: 7
Training loss: 1.1169581144431833
Validation loss: 2.6891295940947626

Epoch: 6| Step: 8
Training loss: 1.1434497605943852
Validation loss: 2.7006773258040626

Epoch: 6| Step: 9
Training loss: 1.1972201215799838
Validation loss: 2.702059423673714

Epoch: 6| Step: 10
Training loss: 0.5630492601678918
Validation loss: 2.7004614994859852

Epoch: 6| Step: 11
Training loss: 0.9663560266789705
Validation loss: 2.6579245281885613

Epoch: 6| Step: 12
Training loss: 1.136278729301148
Validation loss: 2.766807245987912

Epoch: 6| Step: 13
Training loss: 1.068060238539526
Validation loss: 2.7495733276900403

Epoch: 446| Step: 0
Training loss: 1.365643965111513
Validation loss: 2.757979707628951

Epoch: 6| Step: 1
Training loss: 1.1516514654485848
Validation loss: 2.739510862796452

Epoch: 6| Step: 2
Training loss: 1.018564226027215
Validation loss: 2.7265908313579996

Epoch: 6| Step: 3
Training loss: 0.8538028050592613
Validation loss: 2.7024202107882256

Epoch: 6| Step: 4
Training loss: 0.7219119801482754
Validation loss: 2.6987707389163083

Epoch: 6| Step: 5
Training loss: 1.0323689487962133
Validation loss: 2.736422064959172

Epoch: 6| Step: 6
Training loss: 0.6828257142627994
Validation loss: 2.747931164598914

Epoch: 6| Step: 7
Training loss: 0.8512360183194964
Validation loss: 2.7446523313727855

Epoch: 6| Step: 8
Training loss: 0.7006232365255086
Validation loss: 2.776045082953798

Epoch: 6| Step: 9
Training loss: 0.9043657840978898
Validation loss: 2.7923547883557607

Epoch: 6| Step: 10
Training loss: 1.1847456057825843
Validation loss: 2.733170830928058

Epoch: 6| Step: 11
Training loss: 1.2266938934898124
Validation loss: 2.7743303751137

Epoch: 6| Step: 12
Training loss: 0.8049581498468807
Validation loss: 2.749330294587349

Epoch: 6| Step: 13
Training loss: 1.002350012862991
Validation loss: 2.726616918099125

Epoch: 447| Step: 0
Training loss: 0.789729525704935
Validation loss: 2.7442484661374977

Epoch: 6| Step: 1
Training loss: 1.1072957607898164
Validation loss: 2.7105540096857736

Epoch: 6| Step: 2
Training loss: 1.2154414923461057
Validation loss: 2.715412415149969

Epoch: 6| Step: 3
Training loss: 1.1699113288111107
Validation loss: 2.6787393892700786

Epoch: 6| Step: 4
Training loss: 1.006184171809867
Validation loss: 2.6781849258347687

Epoch: 6| Step: 5
Training loss: 1.0911486071033167
Validation loss: 2.7284649148141273

Epoch: 6| Step: 6
Training loss: 0.8883906663592424
Validation loss: 2.8096171686664957

Epoch: 6| Step: 7
Training loss: 0.8754599588454208
Validation loss: 2.8301154029555087

Epoch: 6| Step: 8
Training loss: 0.8661812451422553
Validation loss: 2.852155956368202

Epoch: 6| Step: 9
Training loss: 1.0924463404695994
Validation loss: 2.7923711248500407

Epoch: 6| Step: 10
Training loss: 1.075707475602318
Validation loss: 2.8116796922033394

Epoch: 6| Step: 11
Training loss: 1.0932851621048878
Validation loss: 2.7310944705678977

Epoch: 6| Step: 12
Training loss: 0.9267498052188822
Validation loss: 2.71364251142812

Epoch: 6| Step: 13
Training loss: 0.8186298733593999
Validation loss: 2.654552351048744

Epoch: 448| Step: 0
Training loss: 0.8492941085100844
Validation loss: 2.6977638707041653

Epoch: 6| Step: 1
Training loss: 0.9622179819589454
Validation loss: 2.719249182581249

Epoch: 6| Step: 2
Training loss: 0.8644754081987889
Validation loss: 2.707226047598842

Epoch: 6| Step: 3
Training loss: 1.5036981612075346
Validation loss: 2.704676012249488

Epoch: 6| Step: 4
Training loss: 1.0361183733567718
Validation loss: 2.7009838054406408

Epoch: 6| Step: 5
Training loss: 0.8307902075525138
Validation loss: 2.746664799100124

Epoch: 6| Step: 6
Training loss: 0.7092701149590108
Validation loss: 2.7653389619370246

Epoch: 6| Step: 7
Training loss: 0.9317059124157028
Validation loss: 2.7095583175012012

Epoch: 6| Step: 8
Training loss: 0.675668916571807
Validation loss: 2.7632760886677175

Epoch: 6| Step: 9
Training loss: 0.8877944806964837
Validation loss: 2.7876909803532657

Epoch: 6| Step: 10
Training loss: 0.9023114483488903
Validation loss: 2.7502453723446996

Epoch: 6| Step: 11
Training loss: 0.9031875760267998
Validation loss: 2.7609545177718915

Epoch: 6| Step: 12
Training loss: 1.127033197741595
Validation loss: 2.8066720414355624

Epoch: 6| Step: 13
Training loss: 1.0065348014822184
Validation loss: 2.7475395321742675

Epoch: 449| Step: 0
Training loss: 0.8940525023172404
Validation loss: 2.683317470997273

Epoch: 6| Step: 1
Training loss: 0.9467972059364977
Validation loss: 2.699202997996202

Epoch: 6| Step: 2
Training loss: 1.0796304778790096
Validation loss: 2.7080246725014954

Epoch: 6| Step: 3
Training loss: 1.1019313546416616
Validation loss: 2.694721780074004

Epoch: 6| Step: 4
Training loss: 1.0202405077551817
Validation loss: 2.675096246883337

Epoch: 6| Step: 5
Training loss: 0.7454832685116607
Validation loss: 2.6995455023796757

Epoch: 6| Step: 6
Training loss: 0.8713447653899256
Validation loss: 2.751238674017451

Epoch: 6| Step: 7
Training loss: 0.8688402664163579
Validation loss: 2.7452042406506205

Epoch: 6| Step: 8
Training loss: 0.9273963071332093
Validation loss: 2.765115823946894

Epoch: 6| Step: 9
Training loss: 1.0914346438669087
Validation loss: 2.7138675974758297

Epoch: 6| Step: 10
Training loss: 1.115839645295717
Validation loss: 2.779215936829307

Epoch: 6| Step: 11
Training loss: 1.0542592627426204
Validation loss: 2.805532315811577

Epoch: 6| Step: 12
Training loss: 1.1254062978546258
Validation loss: 2.780464861628518

Epoch: 6| Step: 13
Training loss: 0.8350249684192719
Validation loss: 2.7730707776822205

Epoch: 450| Step: 0
Training loss: 0.8283346018855041
Validation loss: 2.7519397541242037

Epoch: 6| Step: 1
Training loss: 0.8536487187508831
Validation loss: 2.7885771256934158

Epoch: 6| Step: 2
Training loss: 1.0777990428939423
Validation loss: 2.7976494113043495

Epoch: 6| Step: 3
Training loss: 0.8521366808419314
Validation loss: 2.6825500265092033

Epoch: 6| Step: 4
Training loss: 0.8626509216508854
Validation loss: 2.7172531304267262

Epoch: 6| Step: 5
Training loss: 1.3292563164033417
Validation loss: 2.7292181888599476

Epoch: 6| Step: 6
Training loss: 1.0257864633095042
Validation loss: 2.684476127096323

Epoch: 6| Step: 7
Training loss: 0.9286136034673007
Validation loss: 2.7239537625003973

Epoch: 6| Step: 8
Training loss: 1.2906848755033462
Validation loss: 2.706651199473581

Epoch: 6| Step: 9
Training loss: 0.9890068315746389
Validation loss: 2.6962084621719122

Epoch: 6| Step: 10
Training loss: 1.3845150913285327
Validation loss: 2.7419475004803284

Epoch: 6| Step: 11
Training loss: 1.204708988774836
Validation loss: 2.768215482049362

Epoch: 6| Step: 12
Training loss: 0.9580266641517704
Validation loss: 2.737165469511287

Epoch: 6| Step: 13
Training loss: 1.0948988194510052
Validation loss: 2.701900520895405

Epoch: 451| Step: 0
Training loss: 0.8703008558497691
Validation loss: 2.6311789707675746

Epoch: 6| Step: 1
Training loss: 0.9393139139238763
Validation loss: 2.6967464447323395

Epoch: 6| Step: 2
Training loss: 1.1460899181340913
Validation loss: 2.7589304875946095

Epoch: 6| Step: 3
Training loss: 1.2176240463824857
Validation loss: 2.670690485863142

Epoch: 6| Step: 4
Training loss: 1.1549903606656597
Validation loss: 2.6625821203901006

Epoch: 6| Step: 5
Training loss: 0.9853655357617688
Validation loss: 2.6631676447212205

Epoch: 6| Step: 6
Training loss: 0.7605931499649202
Validation loss: 2.671925832402437

Epoch: 6| Step: 7
Training loss: 0.9136177350297022
Validation loss: 2.6832888382328446

Epoch: 6| Step: 8
Training loss: 1.209729582779618
Validation loss: 2.71886218778574

Epoch: 6| Step: 9
Training loss: 0.9939812792947408
Validation loss: 2.8673432989520116

Epoch: 6| Step: 10
Training loss: 1.0147781362605914
Validation loss: 2.837086272361183

Epoch: 6| Step: 11
Training loss: 0.9629992564981825
Validation loss: 2.8664904725094815

Epoch: 6| Step: 12
Training loss: 0.6684506780351733
Validation loss: 2.845918994990148

Epoch: 6| Step: 13
Training loss: 1.3096047666427981
Validation loss: 2.8300846679836518

Epoch: 452| Step: 0
Training loss: 1.2217410626382141
Validation loss: 2.8436289611321084

Epoch: 6| Step: 1
Training loss: 0.949383725244886
Validation loss: 2.7564586165433327

Epoch: 6| Step: 2
Training loss: 0.9871129303457935
Validation loss: 2.7363190343335044

Epoch: 6| Step: 3
Training loss: 0.7986271239255592
Validation loss: 2.7653999739945814

Epoch: 6| Step: 4
Training loss: 1.3371193994920292
Validation loss: 2.7709860843248

Epoch: 6| Step: 5
Training loss: 0.7097634062997407
Validation loss: 2.724341463432595

Epoch: 6| Step: 6
Training loss: 0.9426238231117905
Validation loss: 2.720218349626398

Epoch: 6| Step: 7
Training loss: 0.6799320570227069
Validation loss: 2.7532445955947673

Epoch: 6| Step: 8
Training loss: 0.9140242544144703
Validation loss: 2.7849601829965285

Epoch: 6| Step: 9
Training loss: 1.1174785528322408
Validation loss: 2.722683965249113

Epoch: 6| Step: 10
Training loss: 0.7105085315393459
Validation loss: 2.794720222810216

Epoch: 6| Step: 11
Training loss: 0.7146674183641698
Validation loss: 2.8120618266936854

Epoch: 6| Step: 12
Training loss: 0.9926613104385181
Validation loss: 2.7547676993625196

Epoch: 6| Step: 13
Training loss: 1.0521586299931525
Validation loss: 2.7328681208753935

Epoch: 453| Step: 0
Training loss: 0.9186901098959485
Validation loss: 2.7403302546372

Epoch: 6| Step: 1
Training loss: 1.0655869351297786
Validation loss: 2.731707952531472

Epoch: 6| Step: 2
Training loss: 0.8182410471001289
Validation loss: 2.7246210715568084

Epoch: 6| Step: 3
Training loss: 0.7567122032170617
Validation loss: 2.7147920964950853

Epoch: 6| Step: 4
Training loss: 0.8428748501864214
Validation loss: 2.640905211138473

Epoch: 6| Step: 5
Training loss: 1.1630793778677324
Validation loss: 2.6637680025177084

Epoch: 6| Step: 6
Training loss: 0.8585083492941699
Validation loss: 2.6468986309006994

Epoch: 6| Step: 7
Training loss: 0.8220094113982931
Validation loss: 2.696803998841314

Epoch: 6| Step: 8
Training loss: 1.0489685987458277
Validation loss: 2.6442967455976034

Epoch: 6| Step: 9
Training loss: 0.8771008067682183
Validation loss: 2.6134603958802503

Epoch: 6| Step: 10
Training loss: 0.7138189255124858
Validation loss: 2.7651115127574153

Epoch: 6| Step: 11
Training loss: 0.8722357000401673
Validation loss: 2.6981495249840304

Epoch: 6| Step: 12
Training loss: 1.11400508438402
Validation loss: 2.696607048482175

Epoch: 6| Step: 13
Training loss: 0.934444024333741
Validation loss: 2.7218315083079854

Epoch: 454| Step: 0
Training loss: 0.9324039554991542
Validation loss: 2.6722090960272986

Epoch: 6| Step: 1
Training loss: 0.681102573121469
Validation loss: 2.705106563854721

Epoch: 6| Step: 2
Training loss: 0.797495058456944
Validation loss: 2.719409906386427

Epoch: 6| Step: 3
Training loss: 1.048533364474114
Validation loss: 2.7155940713646634

Epoch: 6| Step: 4
Training loss: 1.0231830193177576
Validation loss: 2.713835062772787

Epoch: 6| Step: 5
Training loss: 0.7998705640032865
Validation loss: 2.6711102928742023

Epoch: 6| Step: 6
Training loss: 0.8281183062588774
Validation loss: 2.698479837874397

Epoch: 6| Step: 7
Training loss: 0.9124457904965027
Validation loss: 2.6704055061609075

Epoch: 6| Step: 8
Training loss: 0.8765520567790374
Validation loss: 2.7109537847874456

Epoch: 6| Step: 9
Training loss: 0.9025761028548795
Validation loss: 2.754717688810686

Epoch: 6| Step: 10
Training loss: 0.6508403746638786
Validation loss: 2.700756041909669

Epoch: 6| Step: 11
Training loss: 0.9880137326486939
Validation loss: 2.7674576457848037

Epoch: 6| Step: 12
Training loss: 0.830932823417619
Validation loss: 2.7869695794578613

Epoch: 6| Step: 13
Training loss: 0.7539594167037675
Validation loss: 2.802435081176944

Epoch: 455| Step: 0
Training loss: 0.6586302551433456
Validation loss: 2.777321616440938

Epoch: 6| Step: 1
Training loss: 0.8045901637789143
Validation loss: 2.7967765691332933

Epoch: 6| Step: 2
Training loss: 0.990270158771978
Validation loss: 2.822352438606765

Epoch: 6| Step: 3
Training loss: 0.45039373232984636
Validation loss: 2.765676451238573

Epoch: 6| Step: 4
Training loss: 0.8313637505049679
Validation loss: 2.7337713392669363

Epoch: 6| Step: 5
Training loss: 0.9255809969749053
Validation loss: 2.7517279051542354

Epoch: 6| Step: 6
Training loss: 0.9789494144942377
Validation loss: 2.766775692855937

Epoch: 6| Step: 7
Training loss: 1.0287510041501973
Validation loss: 2.7394179716111666

Epoch: 6| Step: 8
Training loss: 0.8051149288614248
Validation loss: 2.724937617903212

Epoch: 6| Step: 9
Training loss: 0.9413782962431871
Validation loss: 2.8074062279213483

Epoch: 6| Step: 10
Training loss: 0.8277994991677007
Validation loss: 2.757382122458832

Epoch: 6| Step: 11
Training loss: 0.6477999252887552
Validation loss: 2.775157212624008

Epoch: 6| Step: 12
Training loss: 1.0875894071285497
Validation loss: 2.726173978011164

Epoch: 6| Step: 13
Training loss: 0.8332649361833729
Validation loss: 2.7369327607774374

Epoch: 456| Step: 0
Training loss: 0.8155863171754753
Validation loss: 2.7172569325990072

Epoch: 6| Step: 1
Training loss: 0.7616785283351063
Validation loss: 2.706130310418953

Epoch: 6| Step: 2
Training loss: 0.6414252609427842
Validation loss: 2.751868379116938

Epoch: 6| Step: 3
Training loss: 0.9930416545621161
Validation loss: 2.710711950763865

Epoch: 6| Step: 4
Training loss: 0.9135481536588519
Validation loss: 2.7140721091256084

Epoch: 6| Step: 5
Training loss: 0.6363392266323153
Validation loss: 2.724589416357883

Epoch: 6| Step: 6
Training loss: 0.7772055268200602
Validation loss: 2.732344551073947

Epoch: 6| Step: 7
Training loss: 0.9829404156381429
Validation loss: 2.7085546452013984

Epoch: 6| Step: 8
Training loss: 1.0149350096655991
Validation loss: 2.7772408782463964

Epoch: 6| Step: 9
Training loss: 0.8062458319149657
Validation loss: 2.7584144432458655

Epoch: 6| Step: 10
Training loss: 0.9389865533517976
Validation loss: 2.7475248960339513

Epoch: 6| Step: 11
Training loss: 0.968139332910856
Validation loss: 2.7401310381683235

Epoch: 6| Step: 12
Training loss: 0.5137894644511265
Validation loss: 2.779072412687429

Epoch: 6| Step: 13
Training loss: 0.7350374845431161
Validation loss: 2.7725974373282476

Epoch: 457| Step: 0
Training loss: 0.7475770914391728
Validation loss: 2.729923315694574

Epoch: 6| Step: 1
Training loss: 0.8141780910321639
Validation loss: 2.765616925186467

Epoch: 6| Step: 2
Training loss: 0.7596916417676282
Validation loss: 2.749763507499898

Epoch: 6| Step: 3
Training loss: 1.0626723205849957
Validation loss: 2.8262548427886167

Epoch: 6| Step: 4
Training loss: 0.595699122681227
Validation loss: 2.7576132207955837

Epoch: 6| Step: 5
Training loss: 0.6103828605256642
Validation loss: 2.7935662330762776

Epoch: 6| Step: 6
Training loss: 0.6312935342034901
Validation loss: 2.7536290960426744

Epoch: 6| Step: 7
Training loss: 0.7147328858836739
Validation loss: 2.768977129068333

Epoch: 6| Step: 8
Training loss: 0.9577291629748083
Validation loss: 2.8197301120660407

Epoch: 6| Step: 9
Training loss: 0.7947836340968709
Validation loss: 2.747767944206079

Epoch: 6| Step: 10
Training loss: 0.7700898132954246
Validation loss: 2.7651692965083456

Epoch: 6| Step: 11
Training loss: 1.2071074921561993
Validation loss: 2.7746081536664624

Epoch: 6| Step: 12
Training loss: 0.7871886182703645
Validation loss: 2.7771166115264796

Epoch: 6| Step: 13
Training loss: 0.5928421609121389
Validation loss: 2.8042304783249556

Epoch: 458| Step: 0
Training loss: 0.8184204078803474
Validation loss: 2.8252151300443105

Epoch: 6| Step: 1
Training loss: 0.5533594162760677
Validation loss: 2.884714810133266

Epoch: 6| Step: 2
Training loss: 0.8837906136683557
Validation loss: 2.782469364282082

Epoch: 6| Step: 3
Training loss: 0.6010617488060289
Validation loss: 2.8096257110285694

Epoch: 6| Step: 4
Training loss: 0.8998215339463105
Validation loss: 2.794410927215283

Epoch: 6| Step: 5
Training loss: 0.9500169890541035
Validation loss: 2.8007097718407725

Epoch: 6| Step: 6
Training loss: 0.9341307177221254
Validation loss: 2.8088731480871982

Epoch: 6| Step: 7
Training loss: 0.7033833135191853
Validation loss: 2.759563815726411

Epoch: 6| Step: 8
Training loss: 1.0991602466579893
Validation loss: 2.81196651344022

Epoch: 6| Step: 9
Training loss: 0.8029762516239176
Validation loss: 2.78452635245612

Epoch: 6| Step: 10
Training loss: 0.8467211509680403
Validation loss: 2.7857647516875126

Epoch: 6| Step: 11
Training loss: 0.7068835783959861
Validation loss: 2.7932823449703292

Epoch: 6| Step: 12
Training loss: 0.8262194175658362
Validation loss: 2.7822529702379963

Epoch: 6| Step: 13
Training loss: 0.681176582370037
Validation loss: 2.8103051416331937

Epoch: 459| Step: 0
Training loss: 0.7476681380487739
Validation loss: 2.768845172334228

Epoch: 6| Step: 1
Training loss: 1.0050198208576646
Validation loss: 2.8155057316625043

Epoch: 6| Step: 2
Training loss: 0.9336390145154357
Validation loss: 2.8456081286379233

Epoch: 6| Step: 3
Training loss: 0.9753717105178871
Validation loss: 2.774799281241434

Epoch: 6| Step: 4
Training loss: 0.78808192898512
Validation loss: 2.7982442051058896

Epoch: 6| Step: 5
Training loss: 0.9875651543285052
Validation loss: 2.866363178219646

Epoch: 6| Step: 6
Training loss: 0.7287330609769029
Validation loss: 2.802185628694746

Epoch: 6| Step: 7
Training loss: 0.5241573849277243
Validation loss: 2.776574237020856

Epoch: 6| Step: 8
Training loss: 0.7030550604050302
Validation loss: 2.826157899166017

Epoch: 6| Step: 9
Training loss: 0.5999507864001365
Validation loss: 2.8170745804410955

Epoch: 6| Step: 10
Training loss: 0.7160540897674255
Validation loss: 2.805809625340965

Epoch: 6| Step: 11
Training loss: 0.7113754684052561
Validation loss: 2.783464129072047

Epoch: 6| Step: 12
Training loss: 0.7237460605072696
Validation loss: 2.858186971811595

Epoch: 6| Step: 13
Training loss: 0.7000981134388436
Validation loss: 2.8459897984562903

Epoch: 460| Step: 0
Training loss: 0.6120267294940047
Validation loss: 2.8421129817746293

Epoch: 6| Step: 1
Training loss: 0.9488426059765881
Validation loss: 2.8186890780906197

Epoch: 6| Step: 2
Training loss: 0.8430978939486625
Validation loss: 2.7670655315393105

Epoch: 6| Step: 3
Training loss: 0.6456743218931972
Validation loss: 2.818234580791525

Epoch: 6| Step: 4
Training loss: 0.6446958851789018
Validation loss: 2.8162188068575107

Epoch: 6| Step: 5
Training loss: 0.6955738862170269
Validation loss: 2.8020844347265035

Epoch: 6| Step: 6
Training loss: 0.817973699254144
Validation loss: 2.8375104565084657

Epoch: 6| Step: 7
Training loss: 0.80054563452069
Validation loss: 2.848382076771198

Epoch: 6| Step: 8
Training loss: 0.8632201781613743
Validation loss: 2.826662827217745

Epoch: 6| Step: 9
Training loss: 0.654498464929341
Validation loss: 2.8758564101952935

Epoch: 6| Step: 10
Training loss: 0.7195567703277396
Validation loss: 2.8932112937304235

Epoch: 6| Step: 11
Training loss: 0.9566083635503335
Validation loss: 2.8981512841787853

Epoch: 6| Step: 12
Training loss: 0.7859164301510861
Validation loss: 2.817465263407558

Epoch: 6| Step: 13
Training loss: 0.7701757994523541
Validation loss: 2.773138382949387

Epoch: 461| Step: 0
Training loss: 0.7587544201340358
Validation loss: 2.7872943990518984

Epoch: 6| Step: 1
Training loss: 0.8831035843052575
Validation loss: 2.823181172796564

Epoch: 6| Step: 2
Training loss: 0.5723641997445337
Validation loss: 2.7971468674355764

Epoch: 6| Step: 3
Training loss: 0.9276328904711147
Validation loss: 2.818049092350916

Epoch: 6| Step: 4
Training loss: 0.7268543272612963
Validation loss: 2.8357339020533647

Epoch: 6| Step: 5
Training loss: 0.8611790534530687
Validation loss: 2.8640695885714313

Epoch: 6| Step: 6
Training loss: 0.6329140287356457
Validation loss: 2.826333505981934

Epoch: 6| Step: 7
Training loss: 1.007780739926975
Validation loss: 2.8313561487685064

Epoch: 6| Step: 8
Training loss: 0.8816517313273298
Validation loss: 2.85709178771063

Epoch: 6| Step: 9
Training loss: 0.6979378844115185
Validation loss: 2.8678513814210778

Epoch: 6| Step: 10
Training loss: 0.5601781502968836
Validation loss: 2.8439611279709984

Epoch: 6| Step: 11
Training loss: 0.557326927733267
Validation loss: 2.8762983486461553

Epoch: 6| Step: 12
Training loss: 0.9911860119922548
Validation loss: 2.8456926522360053

Epoch: 6| Step: 13
Training loss: 0.769877902729541
Validation loss: 2.8716408552123056

Epoch: 462| Step: 0
Training loss: 0.6925074111459276
Validation loss: 2.800692490821025

Epoch: 6| Step: 1
Training loss: 0.8725010746727914
Validation loss: 2.7323641985681455

Epoch: 6| Step: 2
Training loss: 0.9605121756759435
Validation loss: 2.7605525049339583

Epoch: 6| Step: 3
Training loss: 0.8715280724500045
Validation loss: 2.75883814945268

Epoch: 6| Step: 4
Training loss: 0.7538550957436868
Validation loss: 2.7449454325409754

Epoch: 6| Step: 5
Training loss: 0.9492201314531485
Validation loss: 2.7137678104602783

Epoch: 6| Step: 6
Training loss: 0.8106844865653098
Validation loss: 2.8274569064768076

Epoch: 6| Step: 7
Training loss: 0.9492457507653481
Validation loss: 2.8412581065250095

Epoch: 6| Step: 8
Training loss: 1.0224932325740792
Validation loss: 2.7882243089249625

Epoch: 6| Step: 9
Training loss: 0.8218068634914488
Validation loss: 2.825469538959925

Epoch: 6| Step: 10
Training loss: 0.5655361464033877
Validation loss: 2.8053855204490405

Epoch: 6| Step: 11
Training loss: 0.7013462030580078
Validation loss: 2.7128848539711687

Epoch: 6| Step: 12
Training loss: 0.8696806183850123
Validation loss: 2.7823453882063736

Epoch: 6| Step: 13
Training loss: 0.8670903400600597
Validation loss: 2.794444173299255

Epoch: 463| Step: 0
Training loss: 0.7707861722661016
Validation loss: 2.697372887403245

Epoch: 6| Step: 1
Training loss: 0.7238443865856224
Validation loss: 2.7862177854911585

Epoch: 6| Step: 2
Training loss: 0.7295133493155069
Validation loss: 2.806508088793035

Epoch: 6| Step: 3
Training loss: 1.000625533914513
Validation loss: 2.7818609988116574

Epoch: 6| Step: 4
Training loss: 0.7598284227165538
Validation loss: 2.7470800040469965

Epoch: 6| Step: 5
Training loss: 0.7292756317101412
Validation loss: 2.8105347584279228

Epoch: 6| Step: 6
Training loss: 0.7944034319815975
Validation loss: 2.792831097391849

Epoch: 6| Step: 7
Training loss: 1.0630343720270008
Validation loss: 2.7958966751617162

Epoch: 6| Step: 8
Training loss: 0.8701840427458503
Validation loss: 2.887521896169192

Epoch: 6| Step: 9
Training loss: 0.8780628820420245
Validation loss: 2.8368520671922988

Epoch: 6| Step: 10
Training loss: 0.7312891224234083
Validation loss: 2.907307258180538

Epoch: 6| Step: 11
Training loss: 0.9483593476475611
Validation loss: 2.851979557004213

Epoch: 6| Step: 12
Training loss: 0.828563070489981
Validation loss: 2.885782436686139

Epoch: 6| Step: 13
Training loss: 0.8351373140420436
Validation loss: 2.8212168081187707

Epoch: 464| Step: 0
Training loss: 0.8901258040034677
Validation loss: 2.853862736987495

Epoch: 6| Step: 1
Training loss: 0.7893947241849187
Validation loss: 2.8962152124082

Epoch: 6| Step: 2
Training loss: 0.9300675456836437
Validation loss: 2.816481336632357

Epoch: 6| Step: 3
Training loss: 0.9065588063240743
Validation loss: 2.8134257029409957

Epoch: 6| Step: 4
Training loss: 0.7962328997921179
Validation loss: 2.823855864381163

Epoch: 6| Step: 5
Training loss: 0.8308856222851925
Validation loss: 2.8207681698130393

Epoch: 6| Step: 6
Training loss: 0.8680675955043392
Validation loss: 2.757334753338038

Epoch: 6| Step: 7
Training loss: 0.9730305391990162
Validation loss: 2.7905652354847565

Epoch: 6| Step: 8
Training loss: 0.8114498394255103
Validation loss: 2.8237000864544735

Epoch: 6| Step: 9
Training loss: 0.7729556191252303
Validation loss: 2.842919071074797

Epoch: 6| Step: 10
Training loss: 0.9818778380238234
Validation loss: 2.8814012334691093

Epoch: 6| Step: 11
Training loss: 0.7803393587952288
Validation loss: 2.869936104593774

Epoch: 6| Step: 12
Training loss: 0.733362839567576
Validation loss: 2.8711809555961527

Epoch: 6| Step: 13
Training loss: 0.8479864646308233
Validation loss: 2.7707788466830325

Epoch: 465| Step: 0
Training loss: 0.5457911786940864
Validation loss: 2.751698706232607

Epoch: 6| Step: 1
Training loss: 0.5467052741296442
Validation loss: 2.769828748126012

Epoch: 6| Step: 2
Training loss: 0.8318633505609562
Validation loss: 2.7456297611340306

Epoch: 6| Step: 3
Training loss: 0.6420187326948518
Validation loss: 2.7194233056964454

Epoch: 6| Step: 4
Training loss: 0.8240952602640392
Validation loss: 2.7731508635211215

Epoch: 6| Step: 5
Training loss: 0.766648911878689
Validation loss: 2.780392518177081

Epoch: 6| Step: 6
Training loss: 0.8751623139378201
Validation loss: 2.8131780019096673

Epoch: 6| Step: 7
Training loss: 0.5785204334046327
Validation loss: 2.813141417654264

Epoch: 6| Step: 8
Training loss: 0.8853159155276494
Validation loss: 2.8549467167110483

Epoch: 6| Step: 9
Training loss: 0.9810008698575269
Validation loss: 2.859946515165634

Epoch: 6| Step: 10
Training loss: 0.8618727019945344
Validation loss: 2.8188983756948955

Epoch: 6| Step: 11
Training loss: 0.6073752872963316
Validation loss: 2.790642142305483

Epoch: 6| Step: 12
Training loss: 0.702688675179568
Validation loss: 2.7999111155752545

Epoch: 6| Step: 13
Training loss: 0.8523618813324874
Validation loss: 2.7977806344176352

Epoch: 466| Step: 0
Training loss: 0.7810197490901114
Validation loss: 2.8346464582983706

Epoch: 6| Step: 1
Training loss: 0.7828798839935078
Validation loss: 2.785791539540442

Epoch: 6| Step: 2
Training loss: 0.682985220217214
Validation loss: 2.7902850864969344

Epoch: 6| Step: 3
Training loss: 0.7177771328162743
Validation loss: 2.8102694956197105

Epoch: 6| Step: 4
Training loss: 0.9521377328124215
Validation loss: 2.8082307626083503

Epoch: 6| Step: 5
Training loss: 0.5600046333053195
Validation loss: 2.7910328805121765

Epoch: 6| Step: 6
Training loss: 0.578765797533332
Validation loss: 2.8163129603243178

Epoch: 6| Step: 7
Training loss: 0.5226505398972957
Validation loss: 2.8459106034549038

Epoch: 6| Step: 8
Training loss: 0.7561523894692168
Validation loss: 2.841928254856113

Epoch: 6| Step: 9
Training loss: 0.6685914377492141
Validation loss: 2.8861122853612566

Epoch: 6| Step: 10
Training loss: 0.9771486278154796
Validation loss: 2.794680226185108

Epoch: 6| Step: 11
Training loss: 0.9196381667992376
Validation loss: 2.8963520811242973

Epoch: 6| Step: 12
Training loss: 0.8743365701842617
Validation loss: 2.9058931466603406

Epoch: 6| Step: 13
Training loss: 1.00500060522716
Validation loss: 2.8491050129196642

Epoch: 467| Step: 0
Training loss: 0.719497002232863
Validation loss: 2.8235966308088187

Epoch: 6| Step: 1
Training loss: 0.776567963364109
Validation loss: 2.828603974418183

Epoch: 6| Step: 2
Training loss: 1.079893127381104
Validation loss: 2.7806695625322413

Epoch: 6| Step: 3
Training loss: 0.6508732972185994
Validation loss: 2.710649832378033

Epoch: 6| Step: 4
Training loss: 0.934268085397578
Validation loss: 2.773238268936175

Epoch: 6| Step: 5
Training loss: 0.7104761492157433
Validation loss: 2.8299746146709164

Epoch: 6| Step: 6
Training loss: 0.8336861499318162
Validation loss: 2.792761542896979

Epoch: 6| Step: 7
Training loss: 0.7773643759286578
Validation loss: 2.8358038948751383

Epoch: 6| Step: 8
Training loss: 0.5605276283920865
Validation loss: 2.7920084122582964

Epoch: 6| Step: 9
Training loss: 0.5989500515130277
Validation loss: 2.837093625538575

Epoch: 6| Step: 10
Training loss: 0.6357301631792378
Validation loss: 2.8150449894211653

Epoch: 6| Step: 11
Training loss: 0.7087375011384818
Validation loss: 2.832579895894909

Epoch: 6| Step: 12
Training loss: 0.9598659650792453
Validation loss: 2.8391296384378797

Epoch: 6| Step: 13
Training loss: 0.6594546048532238
Validation loss: 2.852425069423814

Epoch: 468| Step: 0
Training loss: 0.8626845701350716
Validation loss: 2.9177896290604846

Epoch: 6| Step: 1
Training loss: 0.8205248603239312
Validation loss: 2.8478654837782056

Epoch: 6| Step: 2
Training loss: 0.5799316837920703
Validation loss: 2.8587214099881653

Epoch: 6| Step: 3
Training loss: 0.7676524352000818
Validation loss: 2.8828409774186974

Epoch: 6| Step: 4
Training loss: 0.746666014733484
Validation loss: 2.85894766638617

Epoch: 6| Step: 5
Training loss: 0.8800496441753008
Validation loss: 2.8909331836172703

Epoch: 6| Step: 6
Training loss: 0.8192578757090565
Validation loss: 2.846850427269574

Epoch: 6| Step: 7
Training loss: 0.7376409105072765
Validation loss: 2.86922365210858

Epoch: 6| Step: 8
Training loss: 0.7384248220523391
Validation loss: 2.8375548067555547

Epoch: 6| Step: 9
Training loss: 0.5915875458088
Validation loss: 2.823194853716727

Epoch: 6| Step: 10
Training loss: 0.45374472759535966
Validation loss: 2.793899004189224

Epoch: 6| Step: 11
Training loss: 0.6446391622198175
Validation loss: 2.8618963690673147

Epoch: 6| Step: 12
Training loss: 0.5966714212247703
Validation loss: 2.8677473084756913

Epoch: 6| Step: 13
Training loss: 0.8257625278165865
Validation loss: 2.8394092645466276

Epoch: 469| Step: 0
Training loss: 0.6924984382102238
Validation loss: 2.815041262864587

Epoch: 6| Step: 1
Training loss: 0.9326071533941559
Validation loss: 2.858010207801103

Epoch: 6| Step: 2
Training loss: 0.6433117513627244
Validation loss: 2.7883006675145996

Epoch: 6| Step: 3
Training loss: 0.8280057641326292
Validation loss: 2.8356650705906636

Epoch: 6| Step: 4
Training loss: 0.5532407833405565
Validation loss: 2.8349875127931115

Epoch: 6| Step: 5
Training loss: 0.49929267801554134
Validation loss: 2.832817007216585

Epoch: 6| Step: 6
Training loss: 0.7600804635167894
Validation loss: 2.7905180594133245

Epoch: 6| Step: 7
Training loss: 0.9913696162051535
Validation loss: 2.783781521131533

Epoch: 6| Step: 8
Training loss: 0.5821423008604343
Validation loss: 2.7942652683018956

Epoch: 6| Step: 9
Training loss: 0.71524111850295
Validation loss: 2.769844198906359

Epoch: 6| Step: 10
Training loss: 0.7561475416403195
Validation loss: 2.7644111857589087

Epoch: 6| Step: 11
Training loss: 0.8282744434755621
Validation loss: 2.7697905727086387

Epoch: 6| Step: 12
Training loss: 0.7259333357771591
Validation loss: 2.8434764744488783

Epoch: 6| Step: 13
Training loss: 0.6914213793117614
Validation loss: 2.8292963401804108

Epoch: 470| Step: 0
Training loss: 0.717036568378169
Validation loss: 2.8407984776781694

Epoch: 6| Step: 1
Training loss: 0.9149199482550019
Validation loss: 2.7926505807902178

Epoch: 6| Step: 2
Training loss: 0.8060663132306335
Validation loss: 2.8068347528403956

Epoch: 6| Step: 3
Training loss: 0.926945304596485
Validation loss: 2.7908019724196618

Epoch: 6| Step: 4
Training loss: 0.6235332205196437
Validation loss: 2.780174647546772

Epoch: 6| Step: 5
Training loss: 0.8068180951205121
Validation loss: 2.790728615449431

Epoch: 6| Step: 6
Training loss: 0.6290259632352925
Validation loss: 2.81864850523387

Epoch: 6| Step: 7
Training loss: 0.642715068474777
Validation loss: 2.7597927660011314

Epoch: 6| Step: 8
Training loss: 0.7554864480944675
Validation loss: 2.8344661654524805

Epoch: 6| Step: 9
Training loss: 0.7613668949595767
Validation loss: 2.7527836380515627

Epoch: 6| Step: 10
Training loss: 0.7905749188268859
Validation loss: 2.81184677732783

Epoch: 6| Step: 11
Training loss: 0.7370637411558184
Validation loss: 2.8078328438462155

Epoch: 6| Step: 12
Training loss: 0.48838097126231844
Validation loss: 2.8376817479792793

Epoch: 6| Step: 13
Training loss: 0.7932356211515954
Validation loss: 2.8525229870078674

Epoch: 471| Step: 0
Training loss: 0.7079540574286279
Validation loss: 2.84724178359179

Epoch: 6| Step: 1
Training loss: 0.7071940619231257
Validation loss: 2.8786438917734745

Epoch: 6| Step: 2
Training loss: 0.8649407226449539
Validation loss: 2.8548534128645193

Epoch: 6| Step: 3
Training loss: 0.8536411079677826
Validation loss: 2.82828015486703

Epoch: 6| Step: 4
Training loss: 0.5502057145949643
Validation loss: 2.831833741765822

Epoch: 6| Step: 5
Training loss: 0.46064846222336264
Validation loss: 2.8770820293566275

Epoch: 6| Step: 6
Training loss: 0.8883436330397396
Validation loss: 2.861226772904574

Epoch: 6| Step: 7
Training loss: 0.5441570862787917
Validation loss: 2.8633415489907876

Epoch: 6| Step: 8
Training loss: 0.8751677624776655
Validation loss: 2.8396805511274286

Epoch: 6| Step: 9
Training loss: 0.8704503167713165
Validation loss: 2.847921623350312

Epoch: 6| Step: 10
Training loss: 0.7493737705783765
Validation loss: 2.8835008827950293

Epoch: 6| Step: 11
Training loss: 1.158952801682234
Validation loss: 2.847170760043721

Epoch: 6| Step: 12
Training loss: 0.8853536171997652
Validation loss: 2.80992303693093

Epoch: 6| Step: 13
Training loss: 0.7402609465568154
Validation loss: 2.873572520378009

Epoch: 472| Step: 0
Training loss: 0.8493075130506283
Validation loss: 2.873388640482903

Epoch: 6| Step: 1
Training loss: 0.828551704308208
Validation loss: 2.8474078844112083

Epoch: 6| Step: 2
Training loss: 0.6994290808050888
Validation loss: 2.8586759007942932

Epoch: 6| Step: 3
Training loss: 0.6153492653762153
Validation loss: 2.863489786128856

Epoch: 6| Step: 4
Training loss: 0.9261109614040002
Validation loss: 2.8806148653741164

Epoch: 6| Step: 5
Training loss: 0.59638727643137
Validation loss: 2.871147947599993

Epoch: 6| Step: 6
Training loss: 0.7084423336609592
Validation loss: 2.846093228947699

Epoch: 6| Step: 7
Training loss: 0.6214370258739619
Validation loss: 2.781177462657013

Epoch: 6| Step: 8
Training loss: 0.8761753975078441
Validation loss: 2.8235992132001786

Epoch: 6| Step: 9
Training loss: 0.6076595417933075
Validation loss: 2.8103122113957046

Epoch: 6| Step: 10
Training loss: 0.7365262602289452
Validation loss: 2.784995839054782

Epoch: 6| Step: 11
Training loss: 0.8920184160606605
Validation loss: 2.8381780595656227

Epoch: 6| Step: 12
Training loss: 0.8916930436900311
Validation loss: 2.870633707363445

Epoch: 6| Step: 13
Training loss: 0.9434452373216424
Validation loss: 2.882031273714753

Epoch: 473| Step: 0
Training loss: 0.7046899757426347
Validation loss: 2.908707184978501

Epoch: 6| Step: 1
Training loss: 0.9106950597576916
Validation loss: 2.8881692988648426

Epoch: 6| Step: 2
Training loss: 0.9407139048589549
Validation loss: 2.856082180666257

Epoch: 6| Step: 3
Training loss: 0.7214457916203647
Validation loss: 2.8553819830184417

Epoch: 6| Step: 4
Training loss: 0.9885531869316854
Validation loss: 2.8405259549115054

Epoch: 6| Step: 5
Training loss: 0.8312535837999688
Validation loss: 2.8869250700867894

Epoch: 6| Step: 6
Training loss: 0.9707077302574045
Validation loss: 2.871884537695875

Epoch: 6| Step: 7
Training loss: 0.9347836879669994
Validation loss: 2.901398098666573

Epoch: 6| Step: 8
Training loss: 0.7212527280653427
Validation loss: 2.8773230413913353

Epoch: 6| Step: 9
Training loss: 0.8787733867675059
Validation loss: 2.805111200459649

Epoch: 6| Step: 10
Training loss: 0.5781866762408779
Validation loss: 2.8801254389298294

Epoch: 6| Step: 11
Training loss: 0.7639206971183254
Validation loss: 2.85208721471782

Epoch: 6| Step: 12
Training loss: 0.8495187645310937
Validation loss: 2.9103357588258687

Epoch: 6| Step: 13
Training loss: 0.6835837663193948
Validation loss: 2.8839280090376476

Epoch: 474| Step: 0
Training loss: 1.0107910144456336
Validation loss: 2.9278725660817466

Epoch: 6| Step: 1
Training loss: 0.756721261473416
Validation loss: 2.907507525232296

Epoch: 6| Step: 2
Training loss: 1.073420779613
Validation loss: 2.8573882769584324

Epoch: 6| Step: 3
Training loss: 0.848151910252335
Validation loss: 2.8341403868287873

Epoch: 6| Step: 4
Training loss: 0.8360398844828187
Validation loss: 2.8110662125866446

Epoch: 6| Step: 5
Training loss: 0.7282407922316522
Validation loss: 2.8233910733240846

Epoch: 6| Step: 6
Training loss: 0.7751998858942867
Validation loss: 2.8124643111613694

Epoch: 6| Step: 7
Training loss: 0.8651602478651478
Validation loss: 2.864403116741739

Epoch: 6| Step: 8
Training loss: 0.8595024014451064
Validation loss: 2.8086249606644818

Epoch: 6| Step: 9
Training loss: 0.583926552043671
Validation loss: 2.867843358890617

Epoch: 6| Step: 10
Training loss: 0.6540961114127193
Validation loss: 2.9481090217800534

Epoch: 6| Step: 11
Training loss: 0.9462704179342297
Validation loss: 2.9164603887002523

Epoch: 6| Step: 12
Training loss: 1.0514472637547432
Validation loss: 2.874778628464988

Epoch: 6| Step: 13
Training loss: 0.7138200110255833
Validation loss: 2.7913610708639562

Epoch: 475| Step: 0
Training loss: 0.762249649097816
Validation loss: 2.8373996128692114

Epoch: 6| Step: 1
Training loss: 0.5487851163363977
Validation loss: 2.8090722707004945

Epoch: 6| Step: 2
Training loss: 0.6493683533608314
Validation loss: 2.83568537548538

Epoch: 6| Step: 3
Training loss: 0.5742203070171812
Validation loss: 2.8414491560875152

Epoch: 6| Step: 4
Training loss: 0.7046084120663801
Validation loss: 2.8647286719241145

Epoch: 6| Step: 5
Training loss: 0.8524591817061197
Validation loss: 2.8932586906476403

Epoch: 6| Step: 6
Training loss: 0.8184641040441326
Validation loss: 2.9019101325110337

Epoch: 6| Step: 7
Training loss: 0.7859789964403033
Validation loss: 2.914921856285889

Epoch: 6| Step: 8
Training loss: 0.8580592052577902
Validation loss: 2.8906383617195406

Epoch: 6| Step: 9
Training loss: 0.6421833390892351
Validation loss: 2.923594181518186

Epoch: 6| Step: 10
Training loss: 0.7621944409344119
Validation loss: 2.9101436333094797

Epoch: 6| Step: 11
Training loss: 0.7869873709580252
Validation loss: 2.929210261151187

Epoch: 6| Step: 12
Training loss: 0.6594562317768583
Validation loss: 2.9142520900820377

Epoch: 6| Step: 13
Training loss: 0.8795632174631333
Validation loss: 2.8986984231452797

Epoch: 476| Step: 0
Training loss: 0.8388903506970108
Validation loss: 2.867915221396869

Epoch: 6| Step: 1
Training loss: 0.671549829263206
Validation loss: 2.877818785153911

Epoch: 6| Step: 2
Training loss: 0.678146303079585
Validation loss: 2.873375309182466

Epoch: 6| Step: 3
Training loss: 0.6684894874333926
Validation loss: 2.904888264744503

Epoch: 6| Step: 4
Training loss: 0.6111595725823389
Validation loss: 2.8909462002841946

Epoch: 6| Step: 5
Training loss: 0.916832825744531
Validation loss: 2.8338637743684605

Epoch: 6| Step: 6
Training loss: 0.9601845931858548
Validation loss: 2.903811987440915

Epoch: 6| Step: 7
Training loss: 0.6748227946478472
Validation loss: 2.8707555039647144

Epoch: 6| Step: 8
Training loss: 0.7692886977208095
Validation loss: 2.8281056032867977

Epoch: 6| Step: 9
Training loss: 0.7420344546279579
Validation loss: 2.8245618373489756

Epoch: 6| Step: 10
Training loss: 0.8301863296892262
Validation loss: 2.856798258220626

Epoch: 6| Step: 11
Training loss: 0.706808023357458
Validation loss: 2.8592310523538007

Epoch: 6| Step: 12
Training loss: 0.7671930643101302
Validation loss: 2.867081421042678

Epoch: 6| Step: 13
Training loss: 0.6272662560282442
Validation loss: 2.843362649100878

Epoch: 477| Step: 0
Training loss: 0.9330687383412144
Validation loss: 2.8568823394759004

Epoch: 6| Step: 1
Training loss: 0.6529268867781785
Validation loss: 2.7875032313717303

Epoch: 6| Step: 2
Training loss: 0.7910149468313065
Validation loss: 2.8498193438197554

Epoch: 6| Step: 3
Training loss: 0.73272251316812
Validation loss: 2.8461371662222144

Epoch: 6| Step: 4
Training loss: 0.7346659956315721
Validation loss: 2.7993214738774337

Epoch: 6| Step: 5
Training loss: 0.5668595440407255
Validation loss: 2.810017330641151

Epoch: 6| Step: 6
Training loss: 0.6761523424100792
Validation loss: 2.833141416239421

Epoch: 6| Step: 7
Training loss: 0.9191370246190906
Validation loss: 2.8134612524712157

Epoch: 6| Step: 8
Training loss: 0.7617333043982119
Validation loss: 2.8734980682079803

Epoch: 6| Step: 9
Training loss: 0.7058782924361172
Validation loss: 2.823750208623461

Epoch: 6| Step: 10
Training loss: 0.6273445974987951
Validation loss: 2.7659345981564147

Epoch: 6| Step: 11
Training loss: 0.8278893189376287
Validation loss: 2.856176063476581

Epoch: 6| Step: 12
Training loss: 0.8453927472677262
Validation loss: 2.8140012478485628

Epoch: 6| Step: 13
Training loss: 0.7043206539360773
Validation loss: 2.835729705231675

Epoch: 478| Step: 0
Training loss: 0.505948298234789
Validation loss: 2.8495674714146517

Epoch: 6| Step: 1
Training loss: 0.620507065169497
Validation loss: 2.805443140385917

Epoch: 6| Step: 2
Training loss: 0.6821652118084223
Validation loss: 2.8438195160693676

Epoch: 6| Step: 3
Training loss: 1.0060653327522369
Validation loss: 2.8887567617286902

Epoch: 6| Step: 4
Training loss: 0.7428341106758504
Validation loss: 2.904606699798708

Epoch: 6| Step: 5
Training loss: 0.6068530347642137
Validation loss: 2.8860903663815747

Epoch: 6| Step: 6
Training loss: 0.625104204074134
Validation loss: 2.924517043908148

Epoch: 6| Step: 7
Training loss: 0.5758726215715023
Validation loss: 2.8984744471468336

Epoch: 6| Step: 8
Training loss: 0.6259870126598831
Validation loss: 2.8696908442699907

Epoch: 6| Step: 9
Training loss: 0.8762124720984253
Validation loss: 2.863096792430057

Epoch: 6| Step: 10
Training loss: 0.6935341413285793
Validation loss: 2.8767146926560367

Epoch: 6| Step: 11
Training loss: 0.7270675462540935
Validation loss: 2.8454580661854574

Epoch: 6| Step: 12
Training loss: 0.6372492166052666
Validation loss: 2.8608626228949605

Epoch: 6| Step: 13
Training loss: 0.8447041238439583
Validation loss: 2.868112115299724

Epoch: 479| Step: 0
Training loss: 0.7795314196848115
Validation loss: 2.844442409017533

Epoch: 6| Step: 1
Training loss: 0.9268434764314127
Validation loss: 2.8441311926594297

Epoch: 6| Step: 2
Training loss: 0.518890272271851
Validation loss: 2.874092649939277

Epoch: 6| Step: 3
Training loss: 0.6309562821259072
Validation loss: 2.888859252492384

Epoch: 6| Step: 4
Training loss: 0.6264902230144535
Validation loss: 2.841887818025064

Epoch: 6| Step: 5
Training loss: 0.5632276067705696
Validation loss: 2.8751228002223557

Epoch: 6| Step: 6
Training loss: 0.547544233372976
Validation loss: 2.883407421115723

Epoch: 6| Step: 7
Training loss: 0.4957744592152864
Validation loss: 2.8581314857176308

Epoch: 6| Step: 8
Training loss: 0.7108824572372425
Validation loss: 2.851148629310451

Epoch: 6| Step: 9
Training loss: 0.45539327686458475
Validation loss: 2.8485934194082287

Epoch: 6| Step: 10
Training loss: 0.5151221973849293
Validation loss: 2.8736745570964284

Epoch: 6| Step: 11
Training loss: 0.9014099044844748
Validation loss: 2.897761619985359

Epoch: 6| Step: 12
Training loss: 0.5152721931975183
Validation loss: 2.873356819506762

Epoch: 6| Step: 13
Training loss: 0.7764291414696692
Validation loss: 2.8283524114459486

Epoch: 480| Step: 0
Training loss: 0.7846196556766193
Validation loss: 2.932427172242958

Epoch: 6| Step: 1
Training loss: 0.6050596023788081
Validation loss: 2.8692851695608934

Epoch: 6| Step: 2
Training loss: 0.9001133423537571
Validation loss: 2.8940881689446587

Epoch: 6| Step: 3
Training loss: 0.5207539561501855
Validation loss: 2.8700922389166745

Epoch: 6| Step: 4
Training loss: 0.6634518901470001
Validation loss: 2.89538022253933

Epoch: 6| Step: 5
Training loss: 0.5336320988961881
Validation loss: 2.9442481049468423

Epoch: 6| Step: 6
Training loss: 0.5128427638597115
Validation loss: 2.9789377048958348

Epoch: 6| Step: 7
Training loss: 0.7344043401173311
Validation loss: 2.945088493537442

Epoch: 6| Step: 8
Training loss: 0.6711326312524537
Validation loss: 2.8734082915920283

Epoch: 6| Step: 9
Training loss: 0.6576258224586574
Validation loss: 2.947384126816011

Epoch: 6| Step: 10
Training loss: 0.7358581095189602
Validation loss: 2.8739331795417917

Epoch: 6| Step: 11
Training loss: 0.7135651206364104
Validation loss: 2.8786841297771386

Epoch: 6| Step: 12
Training loss: 0.7701091242539103
Validation loss: 2.8286086173018834

Epoch: 6| Step: 13
Training loss: 0.6300838415805338
Validation loss: 2.9326165642082946

Epoch: 481| Step: 0
Training loss: 0.6459008663513639
Validation loss: 2.908430027014714

Epoch: 6| Step: 1
Training loss: 0.5628683420677436
Validation loss: 2.7950157506973228

Epoch: 6| Step: 2
Training loss: 0.6598365957823933
Validation loss: 2.8880767449945357

Epoch: 6| Step: 3
Training loss: 0.6588911315037453
Validation loss: 2.848957373266157

Epoch: 6| Step: 4
Training loss: 0.6490564953779262
Validation loss: 2.8631402467128653

Epoch: 6| Step: 5
Training loss: 0.6096866006614822
Validation loss: 2.9254322395585746

Epoch: 6| Step: 6
Training loss: 0.6592718441439558
Validation loss: 2.896742799136675

Epoch: 6| Step: 7
Training loss: 0.7443484519240803
Validation loss: 2.91439979653387

Epoch: 6| Step: 8
Training loss: 0.7138206790328229
Validation loss: 2.874052541215798

Epoch: 6| Step: 9
Training loss: 0.5970372004588068
Validation loss: 2.862672318626063

Epoch: 6| Step: 10
Training loss: 0.6270187201009677
Validation loss: 2.8185213835061123

Epoch: 6| Step: 11
Training loss: 0.581730041394321
Validation loss: 2.8550078876384175

Epoch: 6| Step: 12
Training loss: 0.7606244173572726
Validation loss: 2.8486732512297603

Epoch: 6| Step: 13
Training loss: 0.8764404633512809
Validation loss: 2.868075255007411

Epoch: 482| Step: 0
Training loss: 0.5955067044976906
Validation loss: 2.8356969501912173

Epoch: 6| Step: 1
Training loss: 0.9635435293368644
Validation loss: 2.8090416874257595

Epoch: 6| Step: 2
Training loss: 0.6266597405982605
Validation loss: 2.8466826188610552

Epoch: 6| Step: 3
Training loss: 0.7728380905338406
Validation loss: 2.907350188353917

Epoch: 6| Step: 4
Training loss: 0.6452218488518221
Validation loss: 2.8539353622676797

Epoch: 6| Step: 5
Training loss: 0.535571834948061
Validation loss: 2.8386448809322427

Epoch: 6| Step: 6
Training loss: 0.7345390542400226
Validation loss: 2.817331755476854

Epoch: 6| Step: 7
Training loss: 0.5484283729076328
Validation loss: 2.863238769327144

Epoch: 6| Step: 8
Training loss: 0.5024660806927211
Validation loss: 2.810750516079894

Epoch: 6| Step: 9
Training loss: 0.4688392872014749
Validation loss: 2.7887011809545146

Epoch: 6| Step: 10
Training loss: 0.6148640077930241
Validation loss: 2.8025820452579113

Epoch: 6| Step: 11
Training loss: 0.6356069066371021
Validation loss: 2.866830441505853

Epoch: 6| Step: 12
Training loss: 0.6651136717768098
Validation loss: 2.846104077203419

Epoch: 6| Step: 13
Training loss: 0.48169205167507395
Validation loss: 2.8095646834844694

Epoch: 483| Step: 0
Training loss: 0.598334058979873
Validation loss: 2.8835471577455754

Epoch: 6| Step: 1
Training loss: 0.8486015568674206
Validation loss: 2.7937524580749122

Epoch: 6| Step: 2
Training loss: 0.6496978139861387
Validation loss: 2.8540318218222374

Epoch: 6| Step: 3
Training loss: 0.7043741997254775
Validation loss: 2.8154551416349753

Epoch: 6| Step: 4
Training loss: 0.3603026400802619
Validation loss: 2.877376265440926

Epoch: 6| Step: 5
Training loss: 0.6448192530961783
Validation loss: 2.843305196663864

Epoch: 6| Step: 6
Training loss: 0.8103793051442171
Validation loss: 2.8396425731260875

Epoch: 6| Step: 7
Training loss: 0.8217463722671171
Validation loss: 2.8574270481732906

Epoch: 6| Step: 8
Training loss: 0.6793549699822347
Validation loss: 2.8400905524624243

Epoch: 6| Step: 9
Training loss: 0.5972250086943607
Validation loss: 2.827392370827164

Epoch: 6| Step: 10
Training loss: 0.5747571743438148
Validation loss: 2.853741138414974

Epoch: 6| Step: 11
Training loss: 0.5922976348644245
Validation loss: 2.8086644899021964

Epoch: 6| Step: 12
Training loss: 0.8334767138793024
Validation loss: 2.8552874200095277

Epoch: 6| Step: 13
Training loss: 0.966407497099902
Validation loss: 2.879127621604468

Epoch: 484| Step: 0
Training loss: 0.6548323532492641
Validation loss: 2.92134580392786

Epoch: 6| Step: 1
Training loss: 0.7831860014834386
Validation loss: 2.896711454195216

Epoch: 6| Step: 2
Training loss: 0.6339425252380343
Validation loss: 2.888834713362665

Epoch: 6| Step: 3
Training loss: 0.5766838256216152
Validation loss: 2.881234499544167

Epoch: 6| Step: 4
Training loss: 0.9054218652022706
Validation loss: 2.8859421610730034

Epoch: 6| Step: 5
Training loss: 0.7118963964125389
Validation loss: 2.8354424779325833

Epoch: 6| Step: 6
Training loss: 0.6921341507375485
Validation loss: 2.8383326648913716

Epoch: 6| Step: 7
Training loss: 0.5910046250554468
Validation loss: 2.829771668958567

Epoch: 6| Step: 8
Training loss: 0.8360716453657185
Validation loss: 2.857984736421161

Epoch: 6| Step: 9
Training loss: 0.4552708982890248
Validation loss: 2.879519710802958

Epoch: 6| Step: 10
Training loss: 0.3794183318578244
Validation loss: 2.8913797303970914

Epoch: 6| Step: 11
Training loss: 0.752960521101291
Validation loss: 2.914213379472896

Epoch: 6| Step: 12
Training loss: 0.8521138427482946
Validation loss: 2.8754520613706647

Epoch: 6| Step: 13
Training loss: 0.6805446963406196
Validation loss: 2.9401949971812735

Epoch: 485| Step: 0
Training loss: 0.7535072812675926
Validation loss: 2.9761472130310365

Epoch: 6| Step: 1
Training loss: 0.4999639676939062
Validation loss: 2.9413112643619526

Epoch: 6| Step: 2
Training loss: 0.650726071476515
Validation loss: 2.9384776443237732

Epoch: 6| Step: 3
Training loss: 0.6778379465605396
Validation loss: 2.9179227621939128

Epoch: 6| Step: 4
Training loss: 0.7005440071177431
Validation loss: 2.843568048490108

Epoch: 6| Step: 5
Training loss: 0.6448821528659733
Validation loss: 2.8717222464377055

Epoch: 6| Step: 6
Training loss: 0.5710597955757224
Validation loss: 2.8917764655676117

Epoch: 6| Step: 7
Training loss: 0.7508669452009769
Validation loss: 2.8538152566545327

Epoch: 6| Step: 8
Training loss: 0.7712405821535897
Validation loss: 2.8441626280845256

Epoch: 6| Step: 9
Training loss: 0.6650182689939451
Validation loss: 2.8839010717899347

Epoch: 6| Step: 10
Training loss: 0.47134556595628835
Validation loss: 2.8484471970848406

Epoch: 6| Step: 11
Training loss: 0.698400754196649
Validation loss: 2.969504919606968

Epoch: 6| Step: 12
Training loss: 0.9280474004190851
Validation loss: 2.919018074593034

Epoch: 6| Step: 13
Training loss: 0.7856305336283145
Validation loss: 2.9049401835303463

Epoch: 486| Step: 0
Training loss: 0.39100247264772914
Validation loss: 2.9002217150481915

Epoch: 6| Step: 1
Training loss: 0.8079562784182946
Validation loss: 2.874310410767793

Epoch: 6| Step: 2
Training loss: 0.5306263797593797
Validation loss: 2.9149191435019417

Epoch: 6| Step: 3
Training loss: 0.46967172600000023
Validation loss: 2.8933669960756268

Epoch: 6| Step: 4
Training loss: 0.773838055088159
Validation loss: 2.9135843247714166

Epoch: 6| Step: 5
Training loss: 0.8746809377693295
Validation loss: 2.8775076089024303

Epoch: 6| Step: 6
Training loss: 0.8544275226648084
Validation loss: 2.824168421576945

Epoch: 6| Step: 7
Training loss: 0.9586224776287173
Validation loss: 2.884590751428657

Epoch: 6| Step: 8
Training loss: 0.7881734390559378
Validation loss: 2.9246737425908176

Epoch: 6| Step: 9
Training loss: 0.7679363317622776
Validation loss: 2.9633742934944465

Epoch: 6| Step: 10
Training loss: 0.850475036889408
Validation loss: 2.910473274184707

Epoch: 6| Step: 11
Training loss: 0.7620744706005771
Validation loss: 2.944602212837713

Epoch: 6| Step: 12
Training loss: 0.9162796388336574
Validation loss: 2.8942863851562692

Epoch: 6| Step: 13
Training loss: 0.7754760233937484
Validation loss: 2.8346310243001587

Epoch: 487| Step: 0
Training loss: 0.5596559735252263
Validation loss: 2.819742076387458

Epoch: 6| Step: 1
Training loss: 0.48548488205846446
Validation loss: 2.7927308592598696

Epoch: 6| Step: 2
Training loss: 0.9708736891538146
Validation loss: 2.7691661197670614

Epoch: 6| Step: 3
Training loss: 0.8834216961359593
Validation loss: 2.800478632923922

Epoch: 6| Step: 4
Training loss: 0.820477750573002
Validation loss: 2.8114165515110585

Epoch: 6| Step: 5
Training loss: 0.6601590940876929
Validation loss: 2.817400075770334

Epoch: 6| Step: 6
Training loss: 0.7255046485762469
Validation loss: 2.8841691378678656

Epoch: 6| Step: 7
Training loss: 0.5144804765502212
Validation loss: 2.869948233448817

Epoch: 6| Step: 8
Training loss: 0.9490367573653006
Validation loss: 2.919607265028264

Epoch: 6| Step: 9
Training loss: 0.953330596261886
Validation loss: 2.91713865185108

Epoch: 6| Step: 10
Training loss: 0.5194785299297883
Validation loss: 2.8909032051994545

Epoch: 6| Step: 11
Training loss: 0.8409993582506486
Validation loss: 2.9009889133298064

Epoch: 6| Step: 12
Training loss: 0.7213797765562766
Validation loss: 2.904878039554794

Epoch: 6| Step: 13
Training loss: 0.5983934530676491
Validation loss: 2.8711714338315923

Epoch: 488| Step: 0
Training loss: 0.7880015274846333
Validation loss: 2.880833553909707

Epoch: 6| Step: 1
Training loss: 0.7751722052204122
Validation loss: 2.8514849787238465

Epoch: 6| Step: 2
Training loss: 0.6913269773394646
Validation loss: 2.9199080757146754

Epoch: 6| Step: 3
Training loss: 1.0004014759004025
Validation loss: 2.8450703891656977

Epoch: 6| Step: 4
Training loss: 0.6615775118617062
Validation loss: 2.8586656284600243

Epoch: 6| Step: 5
Training loss: 0.7342120050581998
Validation loss: 2.8899639989113113

Epoch: 6| Step: 6
Training loss: 0.6542817071323753
Validation loss: 2.8869475057674543

Epoch: 6| Step: 7
Training loss: 0.46862600593937165
Validation loss: 2.9070069752607197

Epoch: 6| Step: 8
Training loss: 0.6904524997681676
Validation loss: 2.9022995272416714

Epoch: 6| Step: 9
Training loss: 0.7451649421797646
Validation loss: 2.904385970458667

Epoch: 6| Step: 10
Training loss: 0.5833714818968949
Validation loss: 2.878654451715663

Epoch: 6| Step: 11
Training loss: 0.6350469582008105
Validation loss: 2.8934450295052287

Epoch: 6| Step: 12
Training loss: 0.7545408039195166
Validation loss: 2.8057290271178097

Epoch: 6| Step: 13
Training loss: 0.9411609694180839
Validation loss: 2.867878074532283

Epoch: 489| Step: 0
Training loss: 0.48858965480101985
Validation loss: 2.9378130590398204

Epoch: 6| Step: 1
Training loss: 0.5300195693955656
Validation loss: 2.861167054313538

Epoch: 6| Step: 2
Training loss: 0.507542758606117
Validation loss: 2.8401273911967246

Epoch: 6| Step: 3
Training loss: 0.5845301702591897
Validation loss: 2.870445693872424

Epoch: 6| Step: 4
Training loss: 0.8691981264445288
Validation loss: 2.850871506671151

Epoch: 6| Step: 5
Training loss: 0.5705246204275833
Validation loss: 2.8491188064561657

Epoch: 6| Step: 6
Training loss: 0.8444022377415492
Validation loss: 2.8800828203902626

Epoch: 6| Step: 7
Training loss: 0.8165992983129973
Validation loss: 2.8781495050801547

Epoch: 6| Step: 8
Training loss: 0.7302565240852599
Validation loss: 2.951112589649835

Epoch: 6| Step: 9
Training loss: 0.7099425511557025
Validation loss: 2.9153277911780444

Epoch: 6| Step: 10
Training loss: 0.6730094469747923
Validation loss: 2.9221114472649075

Epoch: 6| Step: 11
Training loss: 0.6648063532602596
Validation loss: 3.0057465298898687

Epoch: 6| Step: 12
Training loss: 0.6162301860045883
Validation loss: 2.8754498088411617

Epoch: 6| Step: 13
Training loss: 0.6094542231780301
Validation loss: 2.8832023928977755

Epoch: 490| Step: 0
Training loss: 0.7290594203735137
Validation loss: 2.91052877273497

Epoch: 6| Step: 1
Training loss: 0.5322923532121963
Validation loss: 2.882468253846163

Epoch: 6| Step: 2
Training loss: 0.6488117838345651
Validation loss: 2.8722791097563007

Epoch: 6| Step: 3
Training loss: 0.5801293450036438
Validation loss: 2.829574845597654

Epoch: 6| Step: 4
Training loss: 0.8188973709146228
Validation loss: 2.8963606557834543

Epoch: 6| Step: 5
Training loss: 0.4740694687745399
Validation loss: 2.841821540646822

Epoch: 6| Step: 6
Training loss: 0.7330214830765838
Validation loss: 2.8639551942115817

Epoch: 6| Step: 7
Training loss: 0.6325411273567111
Validation loss: 2.9275173168718083

Epoch: 6| Step: 8
Training loss: 0.3993595151331981
Validation loss: 2.8686569425938315

Epoch: 6| Step: 9
Training loss: 0.6083070003567016
Validation loss: 2.8720727890472646

Epoch: 6| Step: 10
Training loss: 0.6252037669846288
Validation loss: 2.825909204937227

Epoch: 6| Step: 11
Training loss: 0.7531784576817806
Validation loss: 2.822482682167358

Epoch: 6| Step: 12
Training loss: 0.47720657662742494
Validation loss: 2.8330501433572635

Epoch: 6| Step: 13
Training loss: 0.9015063739409526
Validation loss: 2.8724484800538654

Epoch: 491| Step: 0
Training loss: 0.6760446553294025
Validation loss: 2.82431222876144

Epoch: 6| Step: 1
Training loss: 0.5818538011239729
Validation loss: 2.7917055060878013

Epoch: 6| Step: 2
Training loss: 0.6023440053026423
Validation loss: 2.8089674628946684

Epoch: 6| Step: 3
Training loss: 0.4710602731023209
Validation loss: 2.796877869901126

Epoch: 6| Step: 4
Training loss: 0.9607749119113891
Validation loss: 2.8567873392987337

Epoch: 6| Step: 5
Training loss: 0.7406510360583826
Validation loss: 2.889052504609366

Epoch: 6| Step: 6
Training loss: 0.6572908367226303
Validation loss: 2.839308445574721

Epoch: 6| Step: 7
Training loss: 0.5231857833278183
Validation loss: 2.8529648350428096

Epoch: 6| Step: 8
Training loss: 0.5594448195204392
Validation loss: 2.8355268561155835

Epoch: 6| Step: 9
Training loss: 0.6632247577239295
Validation loss: 2.849796378797849

Epoch: 6| Step: 10
Training loss: 0.6105748126861681
Validation loss: 2.8459088022735646

Epoch: 6| Step: 11
Training loss: 0.5288217812370534
Validation loss: 2.8367581751983457

Epoch: 6| Step: 12
Training loss: 0.58284336754922
Validation loss: 2.8439444311277837

Epoch: 6| Step: 13
Training loss: 0.712111583042959
Validation loss: 2.897723744980132

Epoch: 492| Step: 0
Training loss: 0.7430276231675227
Validation loss: 2.8630487851592012

Epoch: 6| Step: 1
Training loss: 0.5844721463487229
Validation loss: 2.8845723198667534

Epoch: 6| Step: 2
Training loss: 0.7406357052186291
Validation loss: 2.879418557424597

Epoch: 6| Step: 3
Training loss: 0.7518400032859894
Validation loss: 2.8769485532297416

Epoch: 6| Step: 4
Training loss: 0.5797924018806769
Validation loss: 2.8452508200828137

Epoch: 6| Step: 5
Training loss: 0.48884441705238907
Validation loss: 2.8920175445757854

Epoch: 6| Step: 6
Training loss: 0.6402463957220746
Validation loss: 2.8558828016289133

Epoch: 6| Step: 7
Training loss: 0.6483134415311789
Validation loss: 2.9061369378305515

Epoch: 6| Step: 8
Training loss: 0.856070041540559
Validation loss: 2.8700700314491927

Epoch: 6| Step: 9
Training loss: 0.6743890390357804
Validation loss: 2.8690814450788755

Epoch: 6| Step: 10
Training loss: 0.7139026304283901
Validation loss: 2.8733165207287636

Epoch: 6| Step: 11
Training loss: 0.5618046064909767
Validation loss: 2.866273018696992

Epoch: 6| Step: 12
Training loss: 0.5438421346720118
Validation loss: 2.837161539984691

Epoch: 6| Step: 13
Training loss: 0.5163757176686279
Validation loss: 2.873505286723475

Epoch: 493| Step: 0
Training loss: 0.4807159749208682
Validation loss: 2.8810484329516757

Epoch: 6| Step: 1
Training loss: 0.510655178733091
Validation loss: 2.7883768957565436

Epoch: 6| Step: 2
Training loss: 0.5348908817565995
Validation loss: 2.8463226181659818

Epoch: 6| Step: 3
Training loss: 0.7702652968980481
Validation loss: 2.85104129853047

Epoch: 6| Step: 4
Training loss: 0.6686429865056868
Validation loss: 2.8218587650298153

Epoch: 6| Step: 5
Training loss: 0.5729710524205619
Validation loss: 2.8215312209032564

Epoch: 6| Step: 6
Training loss: 0.6325225165660213
Validation loss: 2.856841349303765

Epoch: 6| Step: 7
Training loss: 0.5984413126931111
Validation loss: 2.8643335314406966

Epoch: 6| Step: 8
Training loss: 0.7671561986438458
Validation loss: 2.840077372670062

Epoch: 6| Step: 9
Training loss: 0.8070120706707254
Validation loss: 2.888200805303217

Epoch: 6| Step: 10
Training loss: 0.6365586998235712
Validation loss: 2.843582204262911

Epoch: 6| Step: 11
Training loss: 0.602993637563817
Validation loss: 2.849209418149477

Epoch: 6| Step: 12
Training loss: 0.5946870737480203
Validation loss: 2.837501073828675

Epoch: 6| Step: 13
Training loss: 0.5969573528338278
Validation loss: 2.866378392835976

Epoch: 494| Step: 0
Training loss: 0.5550641137971496
Validation loss: 2.8723775540851304

Epoch: 6| Step: 1
Training loss: 0.7652598308167309
Validation loss: 2.903401896860263

Epoch: 6| Step: 2
Training loss: 0.7517427224408613
Validation loss: 2.8838136721227423

Epoch: 6| Step: 3
Training loss: 0.42742375630888735
Validation loss: 2.9344086579764657

Epoch: 6| Step: 4
Training loss: 0.7239602361054881
Validation loss: 2.88671690545477

Epoch: 6| Step: 5
Training loss: 0.5188598309723202
Validation loss: 2.956302581599069

Epoch: 6| Step: 6
Training loss: 0.45467784779584364
Validation loss: 2.875435657940608

Epoch: 6| Step: 7
Training loss: 0.5175690560176135
Validation loss: 2.85082040824142

Epoch: 6| Step: 8
Training loss: 0.6504928462714902
Validation loss: 2.8838915920234696

Epoch: 6| Step: 9
Training loss: 0.5676903736411774
Validation loss: 2.8724016527870324

Epoch: 6| Step: 10
Training loss: 0.5816377679410081
Validation loss: 2.820872736382831

Epoch: 6| Step: 11
Training loss: 0.6156165253109159
Validation loss: 2.8443176625188635

Epoch: 6| Step: 12
Training loss: 0.700854024861349
Validation loss: 2.8200427601776084

Epoch: 6| Step: 13
Training loss: 0.9108713639659088
Validation loss: 2.7957350967097785

Epoch: 495| Step: 0
Training loss: 0.5879333075050193
Validation loss: 2.8562445049942546

Epoch: 6| Step: 1
Training loss: 0.40861154958783713
Validation loss: 2.8570270730581706

Epoch: 6| Step: 2
Training loss: 0.43096741871921734
Validation loss: 2.9151270799325313

Epoch: 6| Step: 3
Training loss: 0.8794247602470304
Validation loss: 2.9066213418404407

Epoch: 6| Step: 4
Training loss: 0.8105823187374797
Validation loss: 2.8445647752744208

Epoch: 6| Step: 5
Training loss: 0.7678558390786898
Validation loss: 2.8582361868391626

Epoch: 6| Step: 6
Training loss: 0.841505243540048
Validation loss: 2.8214344389051393

Epoch: 6| Step: 7
Training loss: 0.5596999306206237
Validation loss: 2.9022879990930193

Epoch: 6| Step: 8
Training loss: 0.7069679358359259
Validation loss: 2.809898840779182

Epoch: 6| Step: 9
Training loss: 0.6367040527145269
Validation loss: 2.874750914356814

Epoch: 6| Step: 10
Training loss: 0.6175766454458157
Validation loss: 2.829893258399104

Epoch: 6| Step: 11
Training loss: 0.5653633777166861
Validation loss: 2.878394320765348

Epoch: 6| Step: 12
Training loss: 0.6098957037878076
Validation loss: 2.8465143259307664

Epoch: 6| Step: 13
Training loss: 0.6715787633716798
Validation loss: 2.8065884805860146

Epoch: 496| Step: 0
Training loss: 0.7515389230563194
Validation loss: 2.9302562924413436

Epoch: 6| Step: 1
Training loss: 0.4981560082638128
Validation loss: 2.881685679409596

Epoch: 6| Step: 2
Training loss: 0.406469615849426
Validation loss: 2.898356310589004

Epoch: 6| Step: 3
Training loss: 0.6098493294994537
Validation loss: 2.9172790611049413

Epoch: 6| Step: 4
Training loss: 0.5885045087669162
Validation loss: 2.9143045306154836

Epoch: 6| Step: 5
Training loss: 0.4445612912343278
Validation loss: 2.9270049703477845

Epoch: 6| Step: 6
Training loss: 0.5087567866479598
Validation loss: 2.8714443970126418

Epoch: 6| Step: 7
Training loss: 0.5814341868552516
Validation loss: 2.943286769134282

Epoch: 6| Step: 8
Training loss: 0.5789506789647823
Validation loss: 2.869556498137334

Epoch: 6| Step: 9
Training loss: 0.6275394823183946
Validation loss: 2.829182464001185

Epoch: 6| Step: 10
Training loss: 0.5764681555413588
Validation loss: 2.8487896680448337

Epoch: 6| Step: 11
Training loss: 0.5668201907072866
Validation loss: 2.8534193429580537

Epoch: 6| Step: 12
Training loss: 0.9335990809843056
Validation loss: 2.8261620891114267

Epoch: 6| Step: 13
Training loss: 0.7596987030446043
Validation loss: 2.8837564606271067

Epoch: 497| Step: 0
Training loss: 0.4396505293929818
Validation loss: 2.833028613328318

Epoch: 6| Step: 1
Training loss: 0.46255952928813554
Validation loss: 2.8158234492799528

Epoch: 6| Step: 2
Training loss: 0.5510835021158272
Validation loss: 2.8337536995528048

Epoch: 6| Step: 3
Training loss: 0.6194064174501949
Validation loss: 2.8987375465685945

Epoch: 6| Step: 4
Training loss: 1.0061453107313887
Validation loss: 2.90500507557831

Epoch: 6| Step: 5
Training loss: 0.8143165894740255
Validation loss: 2.9378560303629886

Epoch: 6| Step: 6
Training loss: 0.5547840679086177
Validation loss: 2.864605051594102

Epoch: 6| Step: 7
Training loss: 0.5702944713512507
Validation loss: 2.8873147654603186

Epoch: 6| Step: 8
Training loss: 0.5285524996844098
Validation loss: 2.826148535037377

Epoch: 6| Step: 9
Training loss: 0.7038074572265391
Validation loss: 2.963759889708169

Epoch: 6| Step: 10
Training loss: 0.5498412748532034
Validation loss: 2.855029780805428

Epoch: 6| Step: 11
Training loss: 0.4560326483096053
Validation loss: 2.9170351794726868

Epoch: 6| Step: 12
Training loss: 0.45278842527680796
Validation loss: 2.877072119685222

Epoch: 6| Step: 13
Training loss: 0.5586498472415828
Validation loss: 2.900678976091437

Epoch: 498| Step: 0
Training loss: 0.9413749088119647
Validation loss: 2.920937998189272

Epoch: 6| Step: 1
Training loss: 0.5558685838120169
Validation loss: 2.9519619543678743

Epoch: 6| Step: 2
Training loss: 0.7724857832702258
Validation loss: 2.8916969854724064

Epoch: 6| Step: 3
Training loss: 0.643858818930635
Validation loss: 2.911556007962415

Epoch: 6| Step: 4
Training loss: 0.5369079767120253
Validation loss: 2.9494436418290286

Epoch: 6| Step: 5
Training loss: 0.472907165258247
Validation loss: 2.9919682116120274

Epoch: 6| Step: 6
Training loss: 0.4347137900107842
Validation loss: 2.9233837074483615

Epoch: 6| Step: 7
Training loss: 0.6896987347882583
Validation loss: 2.9374540744735596

Epoch: 6| Step: 8
Training loss: 0.4864082883160432
Validation loss: 2.933586421979411

Epoch: 6| Step: 9
Training loss: 0.5564665137255821
Validation loss: 2.9099413764702913

Epoch: 6| Step: 10
Training loss: 0.5452093097802897
Validation loss: 2.9335470860440256

Epoch: 6| Step: 11
Training loss: 0.4042053671952392
Validation loss: 2.9396115147361526

Epoch: 6| Step: 12
Training loss: 0.8746432530808844
Validation loss: 2.861304870441535

Epoch: 6| Step: 13
Training loss: 0.6820591513398507
Validation loss: 2.8903758173583705

Epoch: 499| Step: 0
Training loss: 0.5467217366850267
Validation loss: 2.8261533295875987

Epoch: 6| Step: 1
Training loss: 1.1132975794615183
Validation loss: 2.84353245612217

Epoch: 6| Step: 2
Training loss: 0.5187924517071381
Validation loss: 2.8750747035175768

Epoch: 6| Step: 3
Training loss: 0.59579256980901
Validation loss: 2.913136155175937

Epoch: 6| Step: 4
Training loss: 0.557845194309915
Validation loss: 2.913791606403639

Epoch: 6| Step: 5
Training loss: 0.5862774435017059
Validation loss: 2.9320678264133235

Epoch: 6| Step: 6
Training loss: 0.8150597744066784
Validation loss: 2.994817681683316

Epoch: 6| Step: 7
Training loss: 0.6447029809761862
Validation loss: 2.944828847068608

Epoch: 6| Step: 8
Training loss: 0.8936466023849828
Validation loss: 2.957628855753305

Epoch: 6| Step: 9
Training loss: 0.5591591061432972
Validation loss: 2.9279729954997697

Epoch: 6| Step: 10
Training loss: 0.6227468168666596
Validation loss: 2.914852904441116

Epoch: 6| Step: 11
Training loss: 0.5068865623989804
Validation loss: 2.8794577496054177

Epoch: 6| Step: 12
Training loss: 0.7651326289551473
Validation loss: 2.871989138676535

Epoch: 6| Step: 13
Training loss: 0.6464915203149078
Validation loss: 2.8890804528847167

Epoch: 500| Step: 0
Training loss: 0.484381429568041
Validation loss: 2.9036271897246317

Epoch: 6| Step: 1
Training loss: 0.9622505954771313
Validation loss: 2.870805237129228

Epoch: 6| Step: 2
Training loss: 0.4507596002467217
Validation loss: 2.8379020786951275

Epoch: 6| Step: 3
Training loss: 0.6361802286964938
Validation loss: 2.8531114247149887

Epoch: 6| Step: 4
Training loss: 0.6104139128309327
Validation loss: 2.8671214471150184

Epoch: 6| Step: 5
Training loss: 0.42973242438161824
Validation loss: 2.886510019838823

Epoch: 6| Step: 6
Training loss: 0.5046176472322622
Validation loss: 2.8710967533156415

Epoch: 6| Step: 7
Training loss: 0.7158190634847987
Validation loss: 2.9221551254274596

Epoch: 6| Step: 8
Training loss: 0.41474940346047773
Validation loss: 2.895206154800089

Epoch: 6| Step: 9
Training loss: 0.6160930151938638
Validation loss: 2.8399143131519886

Epoch: 6| Step: 10
Training loss: 0.5923346666239837
Validation loss: 2.8435980647933485

Epoch: 6| Step: 11
Training loss: 0.7717611468282146
Validation loss: 2.8792700777008795

Epoch: 6| Step: 12
Training loss: 0.6853880521681868
Validation loss: 2.871333285695821

Epoch: 6| Step: 13
Training loss: 0.8418599611792661
Validation loss: 2.831736231378438

Epoch: 501| Step: 0
Training loss: 0.4533778504586255
Validation loss: 2.8463899424620576

Epoch: 6| Step: 1
Training loss: 0.6813669830463673
Validation loss: 2.8621879874015668

Epoch: 6| Step: 2
Training loss: 0.6704725887959451
Validation loss: 2.8665084658447326

Epoch: 6| Step: 3
Training loss: 0.6496360456780221
Validation loss: 2.914847874082553

Epoch: 6| Step: 4
Training loss: 0.754324288168886
Validation loss: 2.8234108683475907

Epoch: 6| Step: 5
Training loss: 0.7877617113507354
Validation loss: 2.8907967731197948

Epoch: 6| Step: 6
Training loss: 0.5028290583110915
Validation loss: 2.886885057062796

Epoch: 6| Step: 7
Training loss: 0.740583594086253
Validation loss: 2.8892408751566747

Epoch: 6| Step: 8
Training loss: 0.5153605621114186
Validation loss: 2.8248331009392085

Epoch: 6| Step: 9
Training loss: 0.7526062346081334
Validation loss: 2.955724376164838

Epoch: 6| Step: 10
Training loss: 0.43822024867754933
Validation loss: 2.8449408444700097

Epoch: 6| Step: 11
Training loss: 0.7446189004194544
Validation loss: 2.8917467020118823

Epoch: 6| Step: 12
Training loss: 0.5313825161531774
Validation loss: 2.874247272747748

Epoch: 6| Step: 13
Training loss: 0.4458927924475161
Validation loss: 2.921067723017742

Epoch: 502| Step: 0
Training loss: 0.5288608909100805
Validation loss: 2.8716208875803777

Epoch: 6| Step: 1
Training loss: 0.6367870598407385
Validation loss: 2.886197887570837

Epoch: 6| Step: 2
Training loss: 0.7896115498462353
Validation loss: 2.814334101810762

Epoch: 6| Step: 3
Training loss: 0.7563837484831906
Validation loss: 2.8526709923407925

Epoch: 6| Step: 4
Training loss: 0.6600275083430125
Validation loss: 2.8735202076970636

Epoch: 6| Step: 5
Training loss: 0.9561072112044596
Validation loss: 2.8882107799773604

Epoch: 6| Step: 6
Training loss: 0.6598089986471386
Validation loss: 2.847048708169542

Epoch: 6| Step: 7
Training loss: 0.48112955629783516
Validation loss: 2.803926936799856

Epoch: 6| Step: 8
Training loss: 0.5934712608982907
Validation loss: 2.8022082748825636

Epoch: 6| Step: 9
Training loss: 0.6253640545091712
Validation loss: 2.825577995788547

Epoch: 6| Step: 10
Training loss: 0.9375022888155654
Validation loss: 2.8103462591228814

Epoch: 6| Step: 11
Training loss: 0.4773676746073061
Validation loss: 2.8802503107931248

Epoch: 6| Step: 12
Training loss: 0.5840031292305681
Validation loss: 2.77822673083553

Epoch: 6| Step: 13
Training loss: 0.4609303231407974
Validation loss: 2.8883989715455303

Epoch: 503| Step: 0
Training loss: 0.7340970426432585
Validation loss: 2.893455631561715

Epoch: 6| Step: 1
Training loss: 0.6521100750722083
Validation loss: 2.8887180396039294

Epoch: 6| Step: 2
Training loss: 0.6461146700699915
Validation loss: 2.916130034716248

Epoch: 6| Step: 3
Training loss: 0.5014453798730705
Validation loss: 2.931274635195153

Epoch: 6| Step: 4
Training loss: 0.5908877247585534
Validation loss: 2.8670269941122037

Epoch: 6| Step: 5
Training loss: 0.6656841672649699
Validation loss: 2.8558655066153245

Epoch: 6| Step: 6
Training loss: 0.4835275959130017
Validation loss: 2.8835297530493396

Epoch: 6| Step: 7
Training loss: 0.7673328968881492
Validation loss: 2.8784947370797243

Epoch: 6| Step: 8
Training loss: 0.5215098628412606
Validation loss: 2.835460247869924

Epoch: 6| Step: 9
Training loss: 0.6875937571318177
Validation loss: 2.883393695140669

Epoch: 6| Step: 10
Training loss: 1.0583570152296393
Validation loss: 2.893876935730304

Epoch: 6| Step: 11
Training loss: 0.6640095857968165
Validation loss: 2.8469126445181048

Epoch: 6| Step: 12
Training loss: 0.7780129317505785
Validation loss: 2.9035746384632364

Epoch: 6| Step: 13
Training loss: 0.45405064779356596
Validation loss: 2.8845715208875653

Epoch: 504| Step: 0
Training loss: 0.8447656523199067
Validation loss: 2.907445982816396

Epoch: 6| Step: 1
Training loss: 0.6799786262098269
Validation loss: 2.8692328064100265

Epoch: 6| Step: 2
Training loss: 0.8483212231506752
Validation loss: 2.8445063971893836

Epoch: 6| Step: 3
Training loss: 0.6564366438525117
Validation loss: 2.842229303797388

Epoch: 6| Step: 4
Training loss: 0.6882337859087116
Validation loss: 2.864834768646867

Epoch: 6| Step: 5
Training loss: 0.575557834132032
Validation loss: 2.8465231205157453

Epoch: 6| Step: 6
Training loss: 0.8983218574734576
Validation loss: 2.9363577766066524

Epoch: 6| Step: 7
Training loss: 0.5512282269042346
Validation loss: 2.8702880836186204

Epoch: 6| Step: 8
Training loss: 0.5368094421789956
Validation loss: 2.886425383668957

Epoch: 6| Step: 9
Training loss: 0.511310006469794
Validation loss: 2.8847537512891077

Epoch: 6| Step: 10
Training loss: 0.5395802209339688
Validation loss: 2.889545424656649

Epoch: 6| Step: 11
Training loss: 0.6360449707173672
Validation loss: 3.0052205068428743

Epoch: 6| Step: 12
Training loss: 0.673899328920206
Validation loss: 2.984442718429931

Epoch: 6| Step: 13
Training loss: 0.7996432522230184
Validation loss: 2.9456865391898552

Epoch: 505| Step: 0
Training loss: 0.7148684304568006
Validation loss: 2.9157382077681833

Epoch: 6| Step: 1
Training loss: 0.7689846053002503
Validation loss: 2.9320430390476466

Epoch: 6| Step: 2
Training loss: 0.4745606762426353
Validation loss: 2.870510687412091

Epoch: 6| Step: 3
Training loss: 0.7526911297002451
Validation loss: 2.8731621106046714

Epoch: 6| Step: 4
Training loss: 0.469271830332971
Validation loss: 2.9073886076563924

Epoch: 6| Step: 5
Training loss: 0.6464150843985954
Validation loss: 2.9308431965308834

Epoch: 6| Step: 6
Training loss: 0.7191530424472604
Validation loss: 2.8701810947574873

Epoch: 6| Step: 7
Training loss: 0.2690267125253414
Validation loss: 2.908543245961653

Epoch: 6| Step: 8
Training loss: 0.5832500880879427
Validation loss: 2.8858457698401665

Epoch: 6| Step: 9
Training loss: 0.4659818293299166
Validation loss: 2.824349062258082

Epoch: 6| Step: 10
Training loss: 0.39442491514740946
Validation loss: 2.8552249051132366

Epoch: 6| Step: 11
Training loss: 0.859185145821027
Validation loss: 2.8706257618208837

Epoch: 6| Step: 12
Training loss: 0.5136128090669413
Validation loss: 2.8333754863595266

Epoch: 6| Step: 13
Training loss: 0.4381479846078712
Validation loss: 2.8562788607796867

Epoch: 506| Step: 0
Training loss: 0.4092048509822037
Validation loss: 2.9206547084358343

Epoch: 6| Step: 1
Training loss: 0.5147111771215053
Validation loss: 2.892787790952894

Epoch: 6| Step: 2
Training loss: 0.644326472263477
Validation loss: 2.9189297865089587

Epoch: 6| Step: 3
Training loss: 0.7072561338447931
Validation loss: 2.8699922347323716

Epoch: 6| Step: 4
Training loss: 0.7133408888152288
Validation loss: 2.877822596112208

Epoch: 6| Step: 5
Training loss: 0.595555221457095
Validation loss: 2.909077898993444

Epoch: 6| Step: 6
Training loss: 0.7709925761997221
Validation loss: 2.8620663815585607

Epoch: 6| Step: 7
Training loss: 0.6173407448879161
Validation loss: 2.870655176829253

Epoch: 6| Step: 8
Training loss: 0.6616473090689673
Validation loss: 2.8528122066470214

Epoch: 6| Step: 9
Training loss: 0.5902133314318511
Validation loss: 2.876612501315923

Epoch: 6| Step: 10
Training loss: 0.5873912325067402
Validation loss: 2.890009854133816

Epoch: 6| Step: 11
Training loss: 0.4845140626695109
Validation loss: 2.8731050189384737

Epoch: 6| Step: 12
Training loss: 0.5945258342080191
Validation loss: 2.892443371951768

Epoch: 6| Step: 13
Training loss: 0.5012546533382869
Validation loss: 2.8732026466586156

Epoch: 507| Step: 0
Training loss: 0.33617805030251935
Validation loss: 2.8419018563262166

Epoch: 6| Step: 1
Training loss: 0.5389155864929885
Validation loss: 2.8686659463329978

Epoch: 6| Step: 2
Training loss: 0.7215721452877062
Validation loss: 2.8663955828292402

Epoch: 6| Step: 3
Training loss: 0.6054401514005724
Validation loss: 2.8851091149828028

Epoch: 6| Step: 4
Training loss: 0.5158536577406195
Validation loss: 2.9370539441538956

Epoch: 6| Step: 5
Training loss: 0.713840593711536
Validation loss: 2.8703881744005786

Epoch: 6| Step: 6
Training loss: 0.533863204011174
Validation loss: 2.884913835654718

Epoch: 6| Step: 7
Training loss: 0.6089185325552554
Validation loss: 2.894660799230811

Epoch: 6| Step: 8
Training loss: 0.47024716655358206
Validation loss: 2.8769110464837433

Epoch: 6| Step: 9
Training loss: 0.6666772414401911
Validation loss: 2.922704405542116

Epoch: 6| Step: 10
Training loss: 0.5072370937166326
Validation loss: 2.943257728986659

Epoch: 6| Step: 11
Training loss: 0.3430818436447972
Validation loss: 2.92473958260873

Epoch: 6| Step: 12
Training loss: 0.7468501545751846
Validation loss: 2.8939371327257164

Epoch: 6| Step: 13
Training loss: 0.4072050093474785
Validation loss: 2.9471076735937642

Epoch: 508| Step: 0
Training loss: 0.5645463067989146
Validation loss: 2.869195510412001

Epoch: 6| Step: 1
Training loss: 0.388580963390687
Validation loss: 2.883859707812832

Epoch: 6| Step: 2
Training loss: 0.7793495714923221
Validation loss: 2.883991004012738

Epoch: 6| Step: 3
Training loss: 0.6100377611291857
Validation loss: 2.8998005995763685

Epoch: 6| Step: 4
Training loss: 0.44092810736370874
Validation loss: 2.9466781216034827

Epoch: 6| Step: 5
Training loss: 0.4476593483489766
Validation loss: 2.9315097685600233

Epoch: 6| Step: 6
Training loss: 0.7224991086274558
Validation loss: 2.9184845005151234

Epoch: 6| Step: 7
Training loss: 0.37019272891410315
Validation loss: 2.902433726857172

Epoch: 6| Step: 8
Training loss: 0.5021247421959122
Validation loss: 2.9251126118253885

Epoch: 6| Step: 9
Training loss: 0.440283249830396
Validation loss: 2.901652483553973

Epoch: 6| Step: 10
Training loss: 0.7737344499298056
Validation loss: 2.858573815226821

Epoch: 6| Step: 11
Training loss: 0.3724932932089914
Validation loss: 2.904231802941017

Epoch: 6| Step: 12
Training loss: 0.628736840408062
Validation loss: 2.888111210547783

Epoch: 6| Step: 13
Training loss: 0.7338666576859332
Validation loss: 2.909264822682375

Epoch: 509| Step: 0
Training loss: 0.6139199642320498
Validation loss: 2.9044064516296797

Epoch: 6| Step: 1
Training loss: 0.6201025292774202
Validation loss: 2.8644123419388294

Epoch: 6| Step: 2
Training loss: 0.5958695726333538
Validation loss: 2.9077784166451566

Epoch: 6| Step: 3
Training loss: 0.4328185187792336
Validation loss: 2.8924600086398446

Epoch: 6| Step: 4
Training loss: 0.761603830912015
Validation loss: 2.840642558744052

Epoch: 6| Step: 5
Training loss: 0.604369217254209
Validation loss: 2.9171245397207306

Epoch: 6| Step: 6
Training loss: 0.43981257678832597
Validation loss: 2.8737063192438583

Epoch: 6| Step: 7
Training loss: 0.4531073731249583
Validation loss: 2.898654103646987

Epoch: 6| Step: 8
Training loss: 0.4576426923468679
Validation loss: 2.942355086918376

Epoch: 6| Step: 9
Training loss: 0.617278466582957
Validation loss: 2.941312831494507

Epoch: 6| Step: 10
Training loss: 0.46787558696566306
Validation loss: 2.847039719808667

Epoch: 6| Step: 11
Training loss: 0.713378154276426
Validation loss: 2.921618581253927

Epoch: 6| Step: 12
Training loss: 0.38552106482969456
Validation loss: 2.9267320229793476

Epoch: 6| Step: 13
Training loss: 0.475580266335139
Validation loss: 2.89146477812603

Epoch: 510| Step: 0
Training loss: 0.6445319898196512
Validation loss: 2.8740362127540564

Epoch: 6| Step: 1
Training loss: 0.6412247199936935
Validation loss: 2.9480896259876217

Epoch: 6| Step: 2
Training loss: 0.4894305017697056
Validation loss: 2.926974682584501

Epoch: 6| Step: 3
Training loss: 0.6696988504705521
Validation loss: 2.9474898839274917

Epoch: 6| Step: 4
Training loss: 0.3485865308457785
Validation loss: 2.969062253358257

Epoch: 6| Step: 5
Training loss: 0.4432030456801111
Validation loss: 2.9091554836851206

Epoch: 6| Step: 6
Training loss: 0.46747450544842273
Validation loss: 2.985893023213053

Epoch: 6| Step: 7
Training loss: 0.5813517091835063
Validation loss: 2.909729559764447

Epoch: 6| Step: 8
Training loss: 0.5658062618092499
Validation loss: 2.8820700443173406

Epoch: 6| Step: 9
Training loss: 0.5274620771109731
Validation loss: 2.868268549791732

Epoch: 6| Step: 10
Training loss: 0.44478177350705667
Validation loss: 2.9152048307705063

Epoch: 6| Step: 11
Training loss: 0.6088181665859961
Validation loss: 2.889377448501556

Epoch: 6| Step: 12
Training loss: 0.9620904596152094
Validation loss: 2.909756845123091

Epoch: 6| Step: 13
Training loss: 0.6636752177351304
Validation loss: 2.863133765390909

Epoch: 511| Step: 0
Training loss: 0.5029244135607881
Validation loss: 2.9083512343007887

Epoch: 6| Step: 1
Training loss: 0.5892670192890657
Validation loss: 2.8577193450622875

Epoch: 6| Step: 2
Training loss: 0.5230087688031871
Validation loss: 2.9194366290028895

Epoch: 6| Step: 3
Training loss: 0.4640895591578985
Validation loss: 2.895415129526429

Epoch: 6| Step: 4
Training loss: 0.4920933799972398
Validation loss: 2.989740737510683

Epoch: 6| Step: 5
Training loss: 0.5035988513239577
Validation loss: 2.9619458040992757

Epoch: 6| Step: 6
Training loss: 0.8583081298819094
Validation loss: 2.9093197296607167

Epoch: 6| Step: 7
Training loss: 0.8088862309402014
Validation loss: 2.8892941684791196

Epoch: 6| Step: 8
Training loss: 0.4621457250878393
Validation loss: 2.9248403641483662

Epoch: 6| Step: 9
Training loss: 0.5830819547656074
Validation loss: 2.859495942106401

Epoch: 6| Step: 10
Training loss: 0.7019746695360904
Validation loss: 2.8679456410091397

Epoch: 6| Step: 11
Training loss: 0.6937357351194011
Validation loss: 2.8637037325490122

Epoch: 6| Step: 12
Training loss: 0.5625923928569317
Validation loss: 2.8675561610727756

Epoch: 6| Step: 13
Training loss: 0.6009640379633643
Validation loss: 2.87275850295415

Epoch: 512| Step: 0
Training loss: 0.5987983213449569
Validation loss: 2.9183526933406587

Epoch: 6| Step: 1
Training loss: 0.5328539588884963
Validation loss: 2.8964448644473113

Epoch: 6| Step: 2
Training loss: 0.5957928199154869
Validation loss: 2.913459354056664

Epoch: 6| Step: 3
Training loss: 0.524166737916797
Validation loss: 2.967763489228178

Epoch: 6| Step: 4
Training loss: 0.644221468375478
Validation loss: 2.9169836871109824

Epoch: 6| Step: 5
Training loss: 0.49822602883234185
Validation loss: 2.855010378986295

Epoch: 6| Step: 6
Training loss: 0.7378117920590616
Validation loss: 2.8799533328717044

Epoch: 6| Step: 7
Training loss: 0.7256215473129048
Validation loss: 2.9675292332705583

Epoch: 6| Step: 8
Training loss: 0.4586461708222978
Validation loss: 2.895710830475817

Epoch: 6| Step: 9
Training loss: 0.6000021229150091
Validation loss: 2.8828333411975304

Epoch: 6| Step: 10
Training loss: 0.47379350590798275
Validation loss: 2.93871082214349

Epoch: 6| Step: 11
Training loss: 0.4477005888332834
Validation loss: 2.890411705876918

Epoch: 6| Step: 12
Training loss: 0.59106732714024
Validation loss: 2.890936248793321

Epoch: 6| Step: 13
Training loss: 0.7116148520047125
Validation loss: 2.914151774139211

Epoch: 513| Step: 0
Training loss: 0.4698870854489092
Validation loss: 2.9173460895656373

Epoch: 6| Step: 1
Training loss: 0.47767526443365516
Validation loss: 2.875525440354478

Epoch: 6| Step: 2
Training loss: 0.5159578982687186
Validation loss: 2.932157487436159

Epoch: 6| Step: 3
Training loss: 0.5925575127031139
Validation loss: 2.907381131581465

Epoch: 6| Step: 4
Training loss: 0.545364091066788
Validation loss: 2.8892049789712546

Epoch: 6| Step: 5
Training loss: 0.563798571099199
Validation loss: 2.9307186634740323

Epoch: 6| Step: 6
Training loss: 0.3288711511001766
Validation loss: 2.9126035636422003

Epoch: 6| Step: 7
Training loss: 0.7913846885703879
Validation loss: 2.8921370117353105

Epoch: 6| Step: 8
Training loss: 0.6582277559375048
Validation loss: 2.868952596764557

Epoch: 6| Step: 9
Training loss: 0.4078328949662599
Validation loss: 2.853487356238669

Epoch: 6| Step: 10
Training loss: 0.8490262540705165
Validation loss: 2.9145547895872084

Epoch: 6| Step: 11
Training loss: 0.5616476701057662
Validation loss: 2.9109830428564036

Epoch: 6| Step: 12
Training loss: 0.5727417563266003
Validation loss: 2.902249977784128

Epoch: 6| Step: 13
Training loss: 0.5931529757833031
Validation loss: 2.848508200689609

Epoch: 514| Step: 0
Training loss: 0.5497281714091722
Validation loss: 2.91720686859964

Epoch: 6| Step: 1
Training loss: 0.6142098752285305
Validation loss: 2.975188851973985

Epoch: 6| Step: 2
Training loss: 0.8137095691229351
Validation loss: 2.9792906106273054

Epoch: 6| Step: 3
Training loss: 0.7974865007005392
Validation loss: 2.9680070047707168

Epoch: 6| Step: 4
Training loss: 0.4867710409960585
Validation loss: 2.969282457219307

Epoch: 6| Step: 5
Training loss: 0.44581522087786757
Validation loss: 2.929610893095645

Epoch: 6| Step: 6
Training loss: 0.5573167409039248
Validation loss: 2.9368068743073596

Epoch: 6| Step: 7
Training loss: 0.5617267273825868
Validation loss: 2.8628842580381573

Epoch: 6| Step: 8
Training loss: 0.7685017937147245
Validation loss: 2.913200789636535

Epoch: 6| Step: 9
Training loss: 0.41457493580247934
Validation loss: 2.9306553170297076

Epoch: 6| Step: 10
Training loss: 0.5808372282976701
Validation loss: 2.8819330350555536

Epoch: 6| Step: 11
Training loss: 0.4648734011128956
Validation loss: 2.8408310969657147

Epoch: 6| Step: 12
Training loss: 0.567624537965292
Validation loss: 2.8836928817809153

Epoch: 6| Step: 13
Training loss: 0.5224949335464077
Validation loss: 2.851064741333723

Epoch: 515| Step: 0
Training loss: 0.5941305948447878
Validation loss: 2.929687377929685

Epoch: 6| Step: 1
Training loss: 0.7202841929006082
Validation loss: 2.899663893635794

Epoch: 6| Step: 2
Training loss: 0.4338111676007567
Validation loss: 2.924351463802007

Epoch: 6| Step: 3
Training loss: 0.7181046947666294
Validation loss: 2.9256781240300267

Epoch: 6| Step: 4
Training loss: 0.6685772851038577
Validation loss: 2.939204539859057

Epoch: 6| Step: 5
Training loss: 0.5060136184311002
Validation loss: 2.9716384354978183

Epoch: 6| Step: 6
Training loss: 0.6844559599834347
Validation loss: 2.930084744118654

Epoch: 6| Step: 7
Training loss: 0.3512180336222711
Validation loss: 2.8994321804352103

Epoch: 6| Step: 8
Training loss: 0.36107601959131047
Validation loss: 2.8761651677289133

Epoch: 6| Step: 9
Training loss: 0.5742822988209632
Validation loss: 2.8429378565498444

Epoch: 6| Step: 10
Training loss: 0.44010070558650466
Validation loss: 2.8913174049094668

Epoch: 6| Step: 11
Training loss: 0.6690919590058778
Validation loss: 2.957513270193829

Epoch: 6| Step: 12
Training loss: 0.7213401976700652
Validation loss: 2.8721622476971174

Epoch: 6| Step: 13
Training loss: 0.8782820455957788
Validation loss: 2.898283578190787

Epoch: 516| Step: 0
Training loss: 0.5636661679936614
Validation loss: 2.8669279363876203

Epoch: 6| Step: 1
Training loss: 0.5149765561147209
Validation loss: 2.8655327258269514

Epoch: 6| Step: 2
Training loss: 0.6296282823229796
Validation loss: 2.866200525805372

Epoch: 6| Step: 3
Training loss: 0.45776809893692616
Validation loss: 2.907522285378206

Epoch: 6| Step: 4
Training loss: 0.45837260930520046
Validation loss: 2.9280680338428575

Epoch: 6| Step: 5
Training loss: 0.6770219163671664
Validation loss: 2.8887274897760404

Epoch: 6| Step: 6
Training loss: 0.8510037960434016
Validation loss: 2.884273582651073

Epoch: 6| Step: 7
Training loss: 0.5377231489542408
Validation loss: 2.912230337535844

Epoch: 6| Step: 8
Training loss: 0.7171412999516724
Validation loss: 2.8648040177851595

Epoch: 6| Step: 9
Training loss: 0.467266979282536
Validation loss: 2.9057451308699007

Epoch: 6| Step: 10
Training loss: 0.5036236465863875
Validation loss: 2.9105303291366225

Epoch: 6| Step: 11
Training loss: 0.6199427562098135
Validation loss: 2.858165575522604

Epoch: 6| Step: 12
Training loss: 0.8896124923596495
Validation loss: 2.8924449243470236

Epoch: 6| Step: 13
Training loss: 0.6113950308850816
Validation loss: 2.9049729306682783

Epoch: 517| Step: 0
Training loss: 0.4483459452299288
Validation loss: 2.9220134001948335

Epoch: 6| Step: 1
Training loss: 0.4511347173276841
Validation loss: 2.869229025590125

Epoch: 6| Step: 2
Training loss: 0.5800327835601203
Validation loss: 2.9167505910697398

Epoch: 6| Step: 3
Training loss: 1.1283304930800993
Validation loss: 2.8853553783825583

Epoch: 6| Step: 4
Training loss: 0.6371362639552809
Validation loss: 2.889102266655863

Epoch: 6| Step: 5
Training loss: 0.38752043116451423
Validation loss: 2.9522366810779057

Epoch: 6| Step: 6
Training loss: 0.5417801175761079
Validation loss: 2.932388349241244

Epoch: 6| Step: 7
Training loss: 0.5283176048336345
Validation loss: 2.8935139421780036

Epoch: 6| Step: 8
Training loss: 0.5110594309401756
Validation loss: 2.8900819697959585

Epoch: 6| Step: 9
Training loss: 0.7608887674443845
Validation loss: 2.869903788421547

Epoch: 6| Step: 10
Training loss: 0.5340755437839524
Validation loss: 2.8690902535881753

Epoch: 6| Step: 11
Training loss: 0.6784978518357141
Validation loss: 2.848101587624136

Epoch: 6| Step: 12
Training loss: 0.7410479179106501
Validation loss: 2.8298275707002043

Epoch: 6| Step: 13
Training loss: 0.629779730353611
Validation loss: 2.852643049521977

Epoch: 518| Step: 0
Training loss: 0.6965112960156838
Validation loss: 2.859309072377203

Epoch: 6| Step: 1
Training loss: 0.4568468846856063
Validation loss: 2.8887226752817394

Epoch: 6| Step: 2
Training loss: 0.4640884032549904
Validation loss: 2.8810295235770593

Epoch: 6| Step: 3
Training loss: 0.8941334335417919
Validation loss: 2.9384803488814644

Epoch: 6| Step: 4
Training loss: 0.7077172255235812
Validation loss: 2.9296461721260374

Epoch: 6| Step: 5
Training loss: 0.39146002211653946
Validation loss: 2.8790058479351273

Epoch: 6| Step: 6
Training loss: 0.577205338876239
Validation loss: 2.907666766849953

Epoch: 6| Step: 7
Training loss: 0.3676216723989627
Validation loss: 2.9184801231501676

Epoch: 6| Step: 8
Training loss: 0.4791111257401869
Validation loss: 2.901570096790871

Epoch: 6| Step: 9
Training loss: 0.3442898542581222
Validation loss: 2.8896347549215955

Epoch: 6| Step: 10
Training loss: 0.8758220217331525
Validation loss: 2.906084035421026

Epoch: 6| Step: 11
Training loss: 0.5899152396628008
Validation loss: 2.88182854681081

Epoch: 6| Step: 12
Training loss: 0.743044629318699
Validation loss: 2.9343798549667457

Epoch: 6| Step: 13
Training loss: 0.5870002010562819
Validation loss: 2.8655777655882146

Epoch: 519| Step: 0
Training loss: 0.6965346578695815
Validation loss: 2.9338246206841774

Epoch: 6| Step: 1
Training loss: 0.5774501263769528
Validation loss: 2.9296591252966198

Epoch: 6| Step: 2
Training loss: 0.4398261966217872
Validation loss: 2.900061920754592

Epoch: 6| Step: 3
Training loss: 0.6710697049861477
Validation loss: 2.9465536779070076

Epoch: 6| Step: 4
Training loss: 0.48650917451917275
Validation loss: 2.90274169712874

Epoch: 6| Step: 5
Training loss: 0.5967686363637441
Validation loss: 2.9116863964382587

Epoch: 6| Step: 6
Training loss: 0.5965077953324881
Validation loss: 2.9900585864567137

Epoch: 6| Step: 7
Training loss: 0.33730406371800586
Validation loss: 2.9181563297086974

Epoch: 6| Step: 8
Training loss: 0.6147195024018878
Validation loss: 2.949024306870532

Epoch: 6| Step: 9
Training loss: 0.33085708572334316
Validation loss: 2.963182763936205

Epoch: 6| Step: 10
Training loss: 0.6571728938098974
Validation loss: 2.8538366159401902

Epoch: 6| Step: 11
Training loss: 0.6728557702806338
Validation loss: 2.8996838600115837

Epoch: 6| Step: 12
Training loss: 0.5836076829260758
Validation loss: 2.8716296744625383

Epoch: 6| Step: 13
Training loss: 0.46652159294984547
Validation loss: 2.860275529758462

Epoch: 520| Step: 0
Training loss: 0.6969929437088591
Validation loss: 2.92429658088242

Epoch: 6| Step: 1
Training loss: 0.4836717545760739
Validation loss: 2.9207128705820478

Epoch: 6| Step: 2
Training loss: 0.6678582931119602
Validation loss: 2.882558023994195

Epoch: 6| Step: 3
Training loss: 0.6272135161139227
Validation loss: 2.870744665813133

Epoch: 6| Step: 4
Training loss: 0.8047706042588323
Validation loss: 2.9614806738051165

Epoch: 6| Step: 5
Training loss: 0.35889734784430055
Validation loss: 2.8929484609176916

Epoch: 6| Step: 6
Training loss: 0.5157168624428239
Validation loss: 2.9433291745255477

Epoch: 6| Step: 7
Training loss: 0.601086366160382
Validation loss: 2.90131884106296

Epoch: 6| Step: 8
Training loss: 0.5322757803181768
Validation loss: 2.9319562341824574

Epoch: 6| Step: 9
Training loss: 0.5227056482802822
Validation loss: 2.8633583547663153

Epoch: 6| Step: 10
Training loss: 0.5166317042191048
Validation loss: 2.8977591105416005

Epoch: 6| Step: 11
Training loss: 0.5276071526410586
Validation loss: 2.8932568502718348

Epoch: 6| Step: 12
Training loss: 0.4803709225189965
Validation loss: 2.908695149436627

Epoch: 6| Step: 13
Training loss: 0.7055160134875204
Validation loss: 2.9073117002049575

Epoch: 521| Step: 0
Training loss: 0.5486331742782188
Validation loss: 2.9495681791477133

Epoch: 6| Step: 1
Training loss: 0.47625710129136817
Validation loss: 2.9620123047325175

Epoch: 6| Step: 2
Training loss: 0.6497828992166735
Validation loss: 2.9509778568053657

Epoch: 6| Step: 3
Training loss: 0.44807635462259837
Validation loss: 3.0184803623118626

Epoch: 6| Step: 4
Training loss: 0.39948624609186995
Validation loss: 2.953823740271844

Epoch: 6| Step: 5
Training loss: 0.6320256651453604
Validation loss: 2.9469365264197784

Epoch: 6| Step: 6
Training loss: 0.47615188356387705
Validation loss: 2.93494915963135

Epoch: 6| Step: 7
Training loss: 0.47008762242881136
Validation loss: 2.931131615650965

Epoch: 6| Step: 8
Training loss: 0.4581366156579599
Validation loss: 2.898417291973509

Epoch: 6| Step: 9
Training loss: 0.4294321168227078
Validation loss: 2.9343065597141567

Epoch: 6| Step: 10
Training loss: 0.988880021315069
Validation loss: 2.8773092311501354

Epoch: 6| Step: 11
Training loss: 0.4116399541224227
Validation loss: 2.8751614704951582

Epoch: 6| Step: 12
Training loss: 0.6456194390115605
Validation loss: 2.927299143119873

Epoch: 6| Step: 13
Training loss: 0.5851540477594105
Validation loss: 2.8886173458940805

Epoch: 522| Step: 0
Training loss: 0.5118554493264409
Validation loss: 2.8787783176356125

Epoch: 6| Step: 1
Training loss: 0.5742409370962714
Validation loss: 2.9038700353625346

Epoch: 6| Step: 2
Training loss: 0.4588163352320668
Validation loss: 2.88058280694869

Epoch: 6| Step: 3
Training loss: 0.7163580608904604
Validation loss: 2.9336227639054995

Epoch: 6| Step: 4
Training loss: 0.567611411917623
Validation loss: 2.9246140559614897

Epoch: 6| Step: 5
Training loss: 0.6473168029995724
Validation loss: 2.9654046735529516

Epoch: 6| Step: 6
Training loss: 0.6246914101764992
Validation loss: 2.9492836648226293

Epoch: 6| Step: 7
Training loss: 0.7125761827932363
Validation loss: 2.972431189379856

Epoch: 6| Step: 8
Training loss: 0.6155868247341848
Validation loss: 2.967771897729288

Epoch: 6| Step: 9
Training loss: 0.3838225100164996
Validation loss: 2.928607629758273

Epoch: 6| Step: 10
Training loss: 0.6207402980997259
Validation loss: 2.896632877726378

Epoch: 6| Step: 11
Training loss: 0.6459325411698041
Validation loss: 2.8733916275707845

Epoch: 6| Step: 12
Training loss: 0.5219761676152795
Validation loss: 2.8807043898105538

Epoch: 6| Step: 13
Training loss: 0.6717425149217356
Validation loss: 2.9508443432264704

Epoch: 523| Step: 0
Training loss: 0.5183325685125435
Validation loss: 2.907842835396721

Epoch: 6| Step: 1
Training loss: 0.3977205520532708
Validation loss: 2.8695922316100337

Epoch: 6| Step: 2
Training loss: 0.46660158230001886
Validation loss: 2.8982095140314286

Epoch: 6| Step: 3
Training loss: 0.5443383651038692
Validation loss: 2.9603649246737413

Epoch: 6| Step: 4
Training loss: 0.7193435208668968
Validation loss: 2.9583964318723464

Epoch: 6| Step: 5
Training loss: 0.6798256919950746
Validation loss: 2.940808644575296

Epoch: 6| Step: 6
Training loss: 0.8801280028274774
Validation loss: 3.040470493386136

Epoch: 6| Step: 7
Training loss: 0.712410124748674
Validation loss: 3.0258485707290093

Epoch: 6| Step: 8
Training loss: 0.7221306616462314
Validation loss: 3.0135413500278774

Epoch: 6| Step: 9
Training loss: 0.5804337204725601
Validation loss: 2.882395299756335

Epoch: 6| Step: 10
Training loss: 0.6571289715573418
Validation loss: 2.9864228630465384

Epoch: 6| Step: 11
Training loss: 0.3506098449546119
Validation loss: 2.9179941607777016

Epoch: 6| Step: 12
Training loss: 0.4282783985286565
Validation loss: 2.914204366467557

Epoch: 6| Step: 13
Training loss: 0.7285364061106944
Validation loss: 2.906796639829189

Epoch: 524| Step: 0
Training loss: 0.7378760946770713
Validation loss: 2.9251715683137367

Epoch: 6| Step: 1
Training loss: 0.6227912498022357
Validation loss: 2.912510885783141

Epoch: 6| Step: 2
Training loss: 0.4635336550188112
Validation loss: 2.8963332305043594

Epoch: 6| Step: 3
Training loss: 0.4564228083327501
Validation loss: 2.8845181127596584

Epoch: 6| Step: 4
Training loss: 0.743324452961562
Validation loss: 2.9285575891847837

Epoch: 6| Step: 5
Training loss: 0.8821424456397399
Validation loss: 2.938546704424669

Epoch: 6| Step: 6
Training loss: 0.7158100705110141
Validation loss: 2.9470124941775566

Epoch: 6| Step: 7
Training loss: 0.5901980567528493
Validation loss: 2.952779773266097

Epoch: 6| Step: 8
Training loss: 0.8751196779422462
Validation loss: 2.9076678191385374

Epoch: 6| Step: 9
Training loss: 0.4718943674016112
Validation loss: 2.886851237572899

Epoch: 6| Step: 10
Training loss: 0.6400378723412845
Validation loss: 2.9104873776066302

Epoch: 6| Step: 11
Training loss: 0.5301021910610804
Validation loss: 2.901165688475883

Epoch: 6| Step: 12
Training loss: 0.4358518584704646
Validation loss: 2.874920954516032

Epoch: 6| Step: 13
Training loss: 0.6031164435535734
Validation loss: 2.838853120194872

Epoch: 525| Step: 0
Training loss: 0.46540857508099137
Validation loss: 2.9103266791975164

Epoch: 6| Step: 1
Training loss: 0.5866312624623278
Validation loss: 2.864496796196733

Epoch: 6| Step: 2
Training loss: 0.7437591375863524
Validation loss: 2.8345351662151477

Epoch: 6| Step: 3
Training loss: 0.4815097169955259
Validation loss: 2.8564048307761793

Epoch: 6| Step: 4
Training loss: 0.5737347541811362
Validation loss: 2.8654787409685003

Epoch: 6| Step: 5
Training loss: 0.8312549461848592
Validation loss: 2.869403228964349

Epoch: 6| Step: 6
Training loss: 0.32433439972724404
Validation loss: 2.861395603117699

Epoch: 6| Step: 7
Training loss: 0.5639960474406729
Validation loss: 2.876539481597754

Epoch: 6| Step: 8
Training loss: 0.2785419852902386
Validation loss: 2.8680116749121956

Epoch: 6| Step: 9
Training loss: 0.7132322146220261
Validation loss: 2.8940153086836715

Epoch: 6| Step: 10
Training loss: 0.5835145827680037
Validation loss: 2.9611885011383667

Epoch: 6| Step: 11
Training loss: 0.5156305197218024
Validation loss: 2.939583749498482

Epoch: 6| Step: 12
Training loss: 0.5047289025298439
Validation loss: 2.8998505745680747

Epoch: 6| Step: 13
Training loss: 0.4491517390151566
Validation loss: 2.951763909143732

Epoch: 526| Step: 0
Training loss: 0.6759348127053324
Validation loss: 2.9005528328659596

Epoch: 6| Step: 1
Training loss: 0.6479407556436751
Validation loss: 2.9209942909837037

Epoch: 6| Step: 2
Training loss: 0.5321296253644033
Validation loss: 2.9379343293417883

Epoch: 6| Step: 3
Training loss: 0.468008249236625
Validation loss: 2.996077370464143

Epoch: 6| Step: 4
Training loss: 0.3467408032342501
Validation loss: 2.908632354794354

Epoch: 6| Step: 5
Training loss: 0.7454013907408068
Validation loss: 2.9338839032312722

Epoch: 6| Step: 6
Training loss: 0.42747350253699506
Validation loss: 2.924204368735996

Epoch: 6| Step: 7
Training loss: 0.6329680122214871
Validation loss: 2.964400736229034

Epoch: 6| Step: 8
Training loss: 0.5191875841244691
Validation loss: 2.9499280064090065

Epoch: 6| Step: 9
Training loss: 0.43897950823669823
Validation loss: 2.9920924929416794

Epoch: 6| Step: 10
Training loss: 0.4445932335035794
Validation loss: 3.0055768444328175

Epoch: 6| Step: 11
Training loss: 0.6174843472647497
Validation loss: 2.9680520960656187

Epoch: 6| Step: 12
Training loss: 0.5267052918114892
Validation loss: 2.974468065037508

Epoch: 6| Step: 13
Training loss: 0.6602683790336203
Validation loss: 2.9660823146504045

Epoch: 527| Step: 0
Training loss: 0.5864715177184402
Validation loss: 2.9782995193545783

Epoch: 6| Step: 1
Training loss: 0.49210438707787985
Validation loss: 2.9160276575813295

Epoch: 6| Step: 2
Training loss: 0.3420374541332079
Validation loss: 2.94290930587782

Epoch: 6| Step: 3
Training loss: 0.6311670267698223
Validation loss: 2.944861312562591

Epoch: 6| Step: 4
Training loss: 0.5072138852667676
Validation loss: 2.9549664738706296

Epoch: 6| Step: 5
Training loss: 0.5274559466782643
Validation loss: 2.856542466296514

Epoch: 6| Step: 6
Training loss: 0.514685960592482
Validation loss: 2.93728319003762

Epoch: 6| Step: 7
Training loss: 0.5281855892660969
Validation loss: 2.8900401443060404

Epoch: 6| Step: 8
Training loss: 0.6184781739370477
Validation loss: 2.9127475475060525

Epoch: 6| Step: 9
Training loss: 0.7076786512592994
Validation loss: 2.9088386437330027

Epoch: 6| Step: 10
Training loss: 0.6804570850725805
Validation loss: 2.8970884489331308

Epoch: 6| Step: 11
Training loss: 0.38615623175415775
Validation loss: 2.9530391512440386

Epoch: 6| Step: 12
Training loss: 0.4351048300478299
Validation loss: 2.9126847788380807

Epoch: 6| Step: 13
Training loss: 0.49687178868629556
Validation loss: 2.8916385557657023

Epoch: 528| Step: 0
Training loss: 0.647963752957281
Validation loss: 2.9232862195865725

Epoch: 6| Step: 1
Training loss: 0.5170281421133354
Validation loss: 2.892743765522758

Epoch: 6| Step: 2
Training loss: 0.5232221530497652
Validation loss: 2.896317823392726

Epoch: 6| Step: 3
Training loss: 0.45944505663362917
Validation loss: 2.8706665828502245

Epoch: 6| Step: 4
Training loss: 0.5717059318062594
Validation loss: 2.8819680566599195

Epoch: 6| Step: 5
Training loss: 0.6678384129482023
Validation loss: 2.9107634523224974

Epoch: 6| Step: 6
Training loss: 0.6979944389813082
Validation loss: 2.918926253840981

Epoch: 6| Step: 7
Training loss: 0.584304186156419
Validation loss: 2.9303240546519786

Epoch: 6| Step: 8
Training loss: 0.5457765719576123
Validation loss: 2.871440729812732

Epoch: 6| Step: 9
Training loss: 0.40199010547280034
Validation loss: 2.8931968726076325

Epoch: 6| Step: 10
Training loss: 0.6373100811294303
Validation loss: 2.983469041653812

Epoch: 6| Step: 11
Training loss: 0.47735840358187653
Validation loss: 2.899029598440708

Epoch: 6| Step: 12
Training loss: 0.5044491231498769
Validation loss: 2.944809483646396

Epoch: 6| Step: 13
Training loss: 0.6524564908308969
Validation loss: 2.9524529380288396

Epoch: 529| Step: 0
Training loss: 0.6084821468953403
Validation loss: 2.9233718682565395

Epoch: 6| Step: 1
Training loss: 0.5264379563468323
Validation loss: 2.920855216698471

Epoch: 6| Step: 2
Training loss: 0.5704283400688618
Validation loss: 2.838245010039614

Epoch: 6| Step: 3
Training loss: 0.548247277725774
Validation loss: 2.9109082916536217

Epoch: 6| Step: 4
Training loss: 0.5663858344246346
Validation loss: 2.8873338263449657

Epoch: 6| Step: 5
Training loss: 0.4571575577135892
Validation loss: 2.9082393195652094

Epoch: 6| Step: 6
Training loss: 0.4865761549545855
Validation loss: 2.9218903131474705

Epoch: 6| Step: 7
Training loss: 0.8293788342937042
Validation loss: 2.881172878642721

Epoch: 6| Step: 8
Training loss: 0.501465022041564
Validation loss: 2.982031896009967

Epoch: 6| Step: 9
Training loss: 0.3246694098454783
Validation loss: 2.8710176834098653

Epoch: 6| Step: 10
Training loss: 0.5651570982395395
Validation loss: 2.9228853325083053

Epoch: 6| Step: 11
Training loss: 0.4083395187078131
Validation loss: 2.8834910296349157

Epoch: 6| Step: 12
Training loss: 0.48889449710440913
Validation loss: 2.939793617915255

Epoch: 6| Step: 13
Training loss: 0.3763403779534226
Validation loss: 2.9294501043140797

Epoch: 530| Step: 0
Training loss: 0.48343960365178
Validation loss: 2.9221446410961835

Epoch: 6| Step: 1
Training loss: 0.49695968146242714
Validation loss: 2.966802152118757

Epoch: 6| Step: 2
Training loss: 0.4569620096298731
Validation loss: 2.9341900283423716

Epoch: 6| Step: 3
Training loss: 0.6512367769974683
Validation loss: 2.8808455817113297

Epoch: 6| Step: 4
Training loss: 0.5501251100081959
Validation loss: 2.9633963649283865

Epoch: 6| Step: 5
Training loss: 0.5449004903993099
Validation loss: 2.9132417506510873

Epoch: 6| Step: 6
Training loss: 0.45660357557484965
Validation loss: 2.9149349839433922

Epoch: 6| Step: 7
Training loss: 0.5252035155246215
Validation loss: 2.8718448824128275

Epoch: 6| Step: 8
Training loss: 0.5121420063531227
Validation loss: 2.950263384467546

Epoch: 6| Step: 9
Training loss: 0.5035106081597979
Validation loss: 2.941394875121529

Epoch: 6| Step: 10
Training loss: 0.4728489317539149
Validation loss: 2.995866669923435

Epoch: 6| Step: 11
Training loss: 0.3909847891402558
Validation loss: 2.980272959106575

Epoch: 6| Step: 12
Training loss: 0.570043160577971
Validation loss: 2.9711203364719854

Epoch: 6| Step: 13
Training loss: 0.777195096778324
Validation loss: 2.931027044291017

Epoch: 531| Step: 0
Training loss: 0.447106078897445
Validation loss: 2.9623810563172235

Epoch: 6| Step: 1
Training loss: 0.4671110747734364
Validation loss: 2.9434151309849166

Epoch: 6| Step: 2
Training loss: 0.5545926617421307
Validation loss: 2.9460243154196926

Epoch: 6| Step: 3
Training loss: 0.6270311728885469
Validation loss: 2.9166084261029455

Epoch: 6| Step: 4
Training loss: 0.48245171211421994
Validation loss: 2.9957572817710347

Epoch: 6| Step: 5
Training loss: 0.31445167967659643
Validation loss: 2.926678752881455

Epoch: 6| Step: 6
Training loss: 0.5889251832254015
Validation loss: 2.8728407339158726

Epoch: 6| Step: 7
Training loss: 0.8474542755125333
Validation loss: 2.906439279388044

Epoch: 6| Step: 8
Training loss: 0.7228035441634194
Validation loss: 2.876541180715551

Epoch: 6| Step: 9
Training loss: 0.5493291285419105
Validation loss: 2.954762282451455

Epoch: 6| Step: 10
Training loss: 0.3841956704969581
Validation loss: 2.8591641485576904

Epoch: 6| Step: 11
Training loss: 0.5596876836847785
Validation loss: 2.849308394568228

Epoch: 6| Step: 12
Training loss: 0.5518601314230918
Validation loss: 2.8794825066447265

Epoch: 6| Step: 13
Training loss: 0.42991172835396385
Validation loss: 2.8976246258602516

Epoch: 532| Step: 0
Training loss: 0.47848686598946016
Validation loss: 2.858430883746707

Epoch: 6| Step: 1
Training loss: 0.6483216469462466
Validation loss: 2.9214866638514665

Epoch: 6| Step: 2
Training loss: 0.5849103953540762
Validation loss: 2.91262170867496

Epoch: 6| Step: 3
Training loss: 0.42122334908191267
Validation loss: 2.966614969388878

Epoch: 6| Step: 4
Training loss: 0.42691930862066974
Validation loss: 2.935901761679153

Epoch: 6| Step: 5
Training loss: 0.7253639425815069
Validation loss: 2.9490016293129355

Epoch: 6| Step: 6
Training loss: 0.4583175197676519
Validation loss: 2.90537843658739

Epoch: 6| Step: 7
Training loss: 0.5891272633211823
Validation loss: 2.925120409364615

Epoch: 6| Step: 8
Training loss: 0.5871450061861526
Validation loss: 2.8909894833729193

Epoch: 6| Step: 9
Training loss: 0.8234181063429402
Validation loss: 2.8835500240671053

Epoch: 6| Step: 10
Training loss: 0.32461102435889944
Validation loss: 2.813002915805897

Epoch: 6| Step: 11
Training loss: 0.8016949534894616
Validation loss: 2.9161880145820867

Epoch: 6| Step: 12
Training loss: 0.6440443106891108
Validation loss: 2.882055553658849

Epoch: 6| Step: 13
Training loss: 0.42580653474258423
Validation loss: 2.861830055209909

Epoch: 533| Step: 0
Training loss: 0.7061698260416328
Validation loss: 2.9133037434987705

Epoch: 6| Step: 1
Training loss: 0.46425057077757914
Validation loss: 2.854273708220428

Epoch: 6| Step: 2
Training loss: 0.6324059628704972
Validation loss: 2.787443430145515

Epoch: 6| Step: 3
Training loss: 0.4203858407284806
Validation loss: 2.8763099533302645

Epoch: 6| Step: 4
Training loss: 0.3208394948978702
Validation loss: 2.912799946916477

Epoch: 6| Step: 5
Training loss: 0.576454093480025
Validation loss: 2.834268013737565

Epoch: 6| Step: 6
Training loss: 0.4999738775820465
Validation loss: 2.901955374484359

Epoch: 6| Step: 7
Training loss: 0.371305866854483
Validation loss: 2.8609948494713833

Epoch: 6| Step: 8
Training loss: 0.7138329118048562
Validation loss: 2.8785802690274895

Epoch: 6| Step: 9
Training loss: 0.46651415063998325
Validation loss: 2.9103938950831294

Epoch: 6| Step: 10
Training loss: 0.5395664126518225
Validation loss: 2.8084617021315204

Epoch: 6| Step: 11
Training loss: 0.3866515823757104
Validation loss: 2.849965579399478

Epoch: 6| Step: 12
Training loss: 0.6272324269715419
Validation loss: 2.845111590824439

Epoch: 6| Step: 13
Training loss: 0.48255506213676025
Validation loss: 2.862143116432733

Epoch: 534| Step: 0
Training loss: 0.49990504078362
Validation loss: 2.8570948752847496

Epoch: 6| Step: 1
Training loss: 0.35342847687783263
Validation loss: 2.879376853046355

Epoch: 6| Step: 2
Training loss: 0.4585023987227897
Validation loss: 2.842612727314009

Epoch: 6| Step: 3
Training loss: 0.7194471709822838
Validation loss: 2.8426869819447793

Epoch: 6| Step: 4
Training loss: 0.48093207434951785
Validation loss: 2.859294494162634

Epoch: 6| Step: 5
Training loss: 0.5283062099189293
Validation loss: 2.912352795898867

Epoch: 6| Step: 6
Training loss: 0.7694390333660961
Validation loss: 2.852625874164019

Epoch: 6| Step: 7
Training loss: 0.5006801032935555
Validation loss: 2.860054074445346

Epoch: 6| Step: 8
Training loss: 0.44128385889403104
Validation loss: 2.9200104120582733

Epoch: 6| Step: 9
Training loss: 0.43710854592470527
Validation loss: 2.965920100052705

Epoch: 6| Step: 10
Training loss: 0.4535882653441261
Validation loss: 2.9122617064694905

Epoch: 6| Step: 11
Training loss: 0.5026328386683588
Validation loss: 2.9541854434544277

Epoch: 6| Step: 12
Training loss: 0.6120067400841654
Validation loss: 2.9135906665888176

Epoch: 6| Step: 13
Training loss: 0.8454998379915286
Validation loss: 2.8910476100708706

Epoch: 535| Step: 0
Training loss: 0.43196911632337687
Validation loss: 2.887156837405982

Epoch: 6| Step: 1
Training loss: 0.6177363068249013
Validation loss: 2.9169919695416167

Epoch: 6| Step: 2
Training loss: 0.6871365973895855
Validation loss: 2.8970788751578205

Epoch: 6| Step: 3
Training loss: 0.5308101460000297
Validation loss: 2.844898075966401

Epoch: 6| Step: 4
Training loss: 0.38579788771605295
Validation loss: 2.842937590982238

Epoch: 6| Step: 5
Training loss: 0.7338158934345544
Validation loss: 2.9617123894139747

Epoch: 6| Step: 6
Training loss: 0.4098196010477616
Validation loss: 2.8879673743338015

Epoch: 6| Step: 7
Training loss: 0.2570155425910231
Validation loss: 2.8524375095593526

Epoch: 6| Step: 8
Training loss: 0.541550795070377
Validation loss: 2.9079284059989314

Epoch: 6| Step: 9
Training loss: 0.5631267711429496
Validation loss: 2.887314201201166

Epoch: 6| Step: 10
Training loss: 0.5076570419629401
Validation loss: 2.8915253207998752

Epoch: 6| Step: 11
Training loss: 0.5304009159633299
Validation loss: 2.9323811672683595

Epoch: 6| Step: 12
Training loss: 0.4177925237475205
Validation loss: 2.972716696379867

Epoch: 6| Step: 13
Training loss: 0.4569411881874162
Validation loss: 2.90057599880653

Epoch: 536| Step: 0
Training loss: 0.429817509489833
Validation loss: 2.8938065075008748

Epoch: 6| Step: 1
Training loss: 0.48375282013241133
Validation loss: 2.9044450877274133

Epoch: 6| Step: 2
Training loss: 0.3343596330124112
Validation loss: 2.9206634022197346

Epoch: 6| Step: 3
Training loss: 0.3604044061387192
Validation loss: 2.876131512321865

Epoch: 6| Step: 4
Training loss: 0.5420452469981112
Validation loss: 2.865287185664184

Epoch: 6| Step: 5
Training loss: 0.7527152026852219
Validation loss: 2.9171466614082053

Epoch: 6| Step: 6
Training loss: 0.5107971511937626
Validation loss: 2.907900775524016

Epoch: 6| Step: 7
Training loss: 0.6451215872641982
Validation loss: 2.8972801783823954

Epoch: 6| Step: 8
Training loss: 0.45942394229426525
Validation loss: 2.886233318639157

Epoch: 6| Step: 9
Training loss: 0.5068248828424726
Validation loss: 2.8482958193593366

Epoch: 6| Step: 10
Training loss: 0.4351353261906429
Validation loss: 2.906462548799985

Epoch: 6| Step: 11
Training loss: 0.45295738540188557
Validation loss: 2.8871522680299857

Epoch: 6| Step: 12
Training loss: 0.3147150690149259
Validation loss: 2.8731592754106154

Epoch: 6| Step: 13
Training loss: 0.5731866344977372
Validation loss: 2.917245662077389

Epoch: 537| Step: 0
Training loss: 0.5473037946025493
Validation loss: 2.8651648653626935

Epoch: 6| Step: 1
Training loss: 0.45892361177846586
Validation loss: 2.839841007474461

Epoch: 6| Step: 2
Training loss: 0.4878388193326177
Validation loss: 2.89229740186126

Epoch: 6| Step: 3
Training loss: 0.7107023751602
Validation loss: 2.9071207553692404

Epoch: 6| Step: 4
Training loss: 0.48532812111812396
Validation loss: 2.9123566298881607

Epoch: 6| Step: 5
Training loss: 0.41152348384847864
Validation loss: 2.904578367375049

Epoch: 6| Step: 6
Training loss: 0.4379927380865599
Validation loss: 2.977430268866275

Epoch: 6| Step: 7
Training loss: 0.4184907167423696
Validation loss: 2.882895188493954

Epoch: 6| Step: 8
Training loss: 0.6567432956433219
Validation loss: 2.879909373398377

Epoch: 6| Step: 9
Training loss: 0.37619222425519727
Validation loss: 2.8819240314010934

Epoch: 6| Step: 10
Training loss: 0.5105647404295028
Validation loss: 2.9133336687269678

Epoch: 6| Step: 11
Training loss: 0.45902427337598944
Validation loss: 2.931667638658887

Epoch: 6| Step: 12
Training loss: 0.5336105411060278
Validation loss: 2.9304447805993425

Epoch: 6| Step: 13
Training loss: 0.5382130882834959
Validation loss: 2.8638531442042203

Epoch: 538| Step: 0
Training loss: 0.418416042390221
Validation loss: 2.9177930609646676

Epoch: 6| Step: 1
Training loss: 0.45189686114244
Validation loss: 2.9099643311166155

Epoch: 6| Step: 2
Training loss: 0.353882741252561
Validation loss: 2.907986836346335

Epoch: 6| Step: 3
Training loss: 0.4086711336164508
Validation loss: 2.9217009467032304

Epoch: 6| Step: 4
Training loss: 0.40178385915782083
Validation loss: 2.892994804515672

Epoch: 6| Step: 5
Training loss: 0.4065189938207514
Validation loss: 2.916823455592708

Epoch: 6| Step: 6
Training loss: 0.48327542676109086
Validation loss: 2.910001650806496

Epoch: 6| Step: 7
Training loss: 0.4822210133118548
Validation loss: 2.918293490164192

Epoch: 6| Step: 8
Training loss: 0.7552761222844907
Validation loss: 2.8667148404915936

Epoch: 6| Step: 9
Training loss: 0.6139692104615718
Validation loss: 2.8779441575108464

Epoch: 6| Step: 10
Training loss: 0.5983341835019474
Validation loss: 2.9090294621491224

Epoch: 6| Step: 11
Training loss: 0.437196660467326
Validation loss: 2.919761464487506

Epoch: 6| Step: 12
Training loss: 0.5935323466859884
Validation loss: 2.911442032679111

Epoch: 6| Step: 13
Training loss: 0.465242006894282
Validation loss: 2.8635414633271523

Epoch: 539| Step: 0
Training loss: 0.28529775061196955
Validation loss: 2.87331758559736

Epoch: 6| Step: 1
Training loss: 0.4881604159569164
Validation loss: 2.9487783882183636

Epoch: 6| Step: 2
Training loss: 0.44892878918307033
Validation loss: 2.90711441310653

Epoch: 6| Step: 3
Training loss: 0.5300452652980905
Validation loss: 2.868796912912983

Epoch: 6| Step: 4
Training loss: 0.3298554657012418
Validation loss: 2.9073981338154202

Epoch: 6| Step: 5
Training loss: 0.43138512001116136
Validation loss: 2.931939523442693

Epoch: 6| Step: 6
Training loss: 0.6874364043212394
Validation loss: 2.9675680116413576

Epoch: 6| Step: 7
Training loss: 0.6537230523283017
Validation loss: 2.9760295026933594

Epoch: 6| Step: 8
Training loss: 0.641621721435827
Validation loss: 3.0064635847939853

Epoch: 6| Step: 9
Training loss: 0.358977263570089
Validation loss: 2.9370712887289763

Epoch: 6| Step: 10
Training loss: 0.604944211105797
Validation loss: 2.895494226227611

Epoch: 6| Step: 11
Training loss: 0.48362255103111634
Validation loss: 2.915513387372042

Epoch: 6| Step: 12
Training loss: 0.6080777224582924
Validation loss: 2.913623712007528

Epoch: 6| Step: 13
Training loss: 0.4572165024085327
Validation loss: 2.9251738233078997

Epoch: 540| Step: 0
Training loss: 0.6027053776587351
Validation loss: 2.91233234332266

Epoch: 6| Step: 1
Training loss: 0.5941837884496729
Validation loss: 2.834296369040229

Epoch: 6| Step: 2
Training loss: 0.6872189771061974
Validation loss: 2.890137406198882

Epoch: 6| Step: 3
Training loss: 0.4537846269347257
Validation loss: 2.896100647112627

Epoch: 6| Step: 4
Training loss: 0.5501933646582322
Validation loss: 2.902202590788684

Epoch: 6| Step: 5
Training loss: 0.5283210176191719
Validation loss: 2.876713242277173

Epoch: 6| Step: 6
Training loss: 0.5972482373118586
Validation loss: 2.906339801234968

Epoch: 6| Step: 7
Training loss: 0.5618406776239403
Validation loss: 2.931900178964771

Epoch: 6| Step: 8
Training loss: 0.5397788830000022
Validation loss: 2.8847397975501536

Epoch: 6| Step: 9
Training loss: 0.3981875215122335
Validation loss: 2.880357780971135

Epoch: 6| Step: 10
Training loss: 0.4542080005886808
Validation loss: 2.8611209312649026

Epoch: 6| Step: 11
Training loss: 0.6198551856010901
Validation loss: 2.9208403198622994

Epoch: 6| Step: 12
Training loss: 0.5188407037327686
Validation loss: 2.8894776000187528

Epoch: 6| Step: 13
Training loss: 0.5722505482845588
Validation loss: 2.911154215334215

Epoch: 541| Step: 0
Training loss: 0.6637558621796039
Validation loss: 2.939227806741022

Epoch: 6| Step: 1
Training loss: 0.46735715560536606
Validation loss: 2.8620330462997057

Epoch: 6| Step: 2
Training loss: 0.48943617990057814
Validation loss: 2.93561498208056

Epoch: 6| Step: 3
Training loss: 0.565881657196585
Validation loss: 2.9281587944129766

Epoch: 6| Step: 4
Training loss: 0.6167607824143038
Validation loss: 2.8787571641129155

Epoch: 6| Step: 5
Training loss: 0.4191571391497301
Validation loss: 2.8575911107838836

Epoch: 6| Step: 6
Training loss: 0.5597599899743082
Validation loss: 2.8499607412523216

Epoch: 6| Step: 7
Training loss: 0.619096507717863
Validation loss: 2.8541831041591332

Epoch: 6| Step: 8
Training loss: 0.45668179446360757
Validation loss: 2.8631342789008927

Epoch: 6| Step: 9
Training loss: 0.523475531719449
Validation loss: 2.894634359962545

Epoch: 6| Step: 10
Training loss: 0.4275090220542245
Validation loss: 2.887539717165781

Epoch: 6| Step: 11
Training loss: 0.4613809553706121
Validation loss: 2.873849915167818

Epoch: 6| Step: 12
Training loss: 0.5347289446893961
Validation loss: 2.891916484833381

Epoch: 6| Step: 13
Training loss: 0.4741002244216204
Validation loss: 2.9219807080409432

Epoch: 542| Step: 0
Training loss: 0.5006931388098416
Validation loss: 2.891984829361179

Epoch: 6| Step: 1
Training loss: 0.4163801002522183
Validation loss: 2.863879645643376

Epoch: 6| Step: 2
Training loss: 0.33211428781993246
Validation loss: 2.8430409228626408

Epoch: 6| Step: 3
Training loss: 0.6264495015216884
Validation loss: 2.8907506004745693

Epoch: 6| Step: 4
Training loss: 0.5321187041297543
Validation loss: 2.8749740571772717

Epoch: 6| Step: 5
Training loss: 0.5479068830170214
Validation loss: 2.8933887637962377

Epoch: 6| Step: 6
Training loss: 0.5190821836484036
Validation loss: 2.8960705849772674

Epoch: 6| Step: 7
Training loss: 0.6200471613236145
Validation loss: 2.8615206257682617

Epoch: 6| Step: 8
Training loss: 0.6440860713623
Validation loss: 2.8718331766663328

Epoch: 6| Step: 9
Training loss: 0.49261823607328553
Validation loss: 2.854097342287349

Epoch: 6| Step: 10
Training loss: 0.4771405138567204
Validation loss: 2.8829611694264945

Epoch: 6| Step: 11
Training loss: 0.7016080599394204
Validation loss: 2.8625044521424874

Epoch: 6| Step: 12
Training loss: 0.5712417452526711
Validation loss: 2.922416215298752

Epoch: 6| Step: 13
Training loss: 0.5647532051505452
Validation loss: 2.9818806235189026

Epoch: 543| Step: 0
Training loss: 0.6378493772814214
Validation loss: 2.9685010839144073

Epoch: 6| Step: 1
Training loss: 0.38828323333049486
Validation loss: 2.9396567577237303

Epoch: 6| Step: 2
Training loss: 0.4762624984512936
Validation loss: 2.9435425557707955

Epoch: 6| Step: 3
Training loss: 0.5926307871080768
Validation loss: 2.9637129230773085

Epoch: 6| Step: 4
Training loss: 0.37899460696356574
Validation loss: 2.9104067974064325

Epoch: 6| Step: 5
Training loss: 0.6688183295021995
Validation loss: 2.909032480938225

Epoch: 6| Step: 6
Training loss: 0.6193114324874832
Validation loss: 2.940888067485417

Epoch: 6| Step: 7
Training loss: 0.5942815860463099
Validation loss: 3.017894951279082

Epoch: 6| Step: 8
Training loss: 0.43898463390238834
Validation loss: 2.884507794696805

Epoch: 6| Step: 9
Training loss: 0.5283494190370628
Validation loss: 2.863991295872325

Epoch: 6| Step: 10
Training loss: 0.4235361913273015
Validation loss: 2.9399929425420845

Epoch: 6| Step: 11
Training loss: 0.43912310606224736
Validation loss: 2.9520289625833604

Epoch: 6| Step: 12
Training loss: 0.4606277427177606
Validation loss: 2.9211413844576803

Epoch: 6| Step: 13
Training loss: 0.3765413476218612
Validation loss: 2.871065211424561

Epoch: 544| Step: 0
Training loss: 0.5653262661448681
Validation loss: 2.9235379251928117

Epoch: 6| Step: 1
Training loss: 0.4829601574383012
Validation loss: 2.9188594386449536

Epoch: 6| Step: 2
Training loss: 0.44146545823261246
Validation loss: 2.8555455230119393

Epoch: 6| Step: 3
Training loss: 0.4126576396972182
Validation loss: 2.9260589372761885

Epoch: 6| Step: 4
Training loss: 0.3803566769572116
Validation loss: 3.011627275040067

Epoch: 6| Step: 5
Training loss: 0.4671260838025193
Validation loss: 2.984006542741525

Epoch: 6| Step: 6
Training loss: 0.6100036117571859
Validation loss: 2.9663514201941017

Epoch: 6| Step: 7
Training loss: 0.5931048150441628
Validation loss: 2.9264887729692077

Epoch: 6| Step: 8
Training loss: 0.6746744783813708
Validation loss: 2.9363127805088918

Epoch: 6| Step: 9
Training loss: 0.37092751242891087
Validation loss: 2.901234171225799

Epoch: 6| Step: 10
Training loss: 0.7263404753066743
Validation loss: 2.8708835239387667

Epoch: 6| Step: 11
Training loss: 0.4289240383496493
Validation loss: 2.901497540819273

Epoch: 6| Step: 12
Training loss: 0.5939433887153236
Validation loss: 2.9068261672654625

Epoch: 6| Step: 13
Training loss: 0.46137611081452906
Validation loss: 2.8532330779781514

Epoch: 545| Step: 0
Training loss: 0.4471778450329469
Validation loss: 2.867691286819033

Epoch: 6| Step: 1
Training loss: 0.7877757845974296
Validation loss: 2.8608242871565284

Epoch: 6| Step: 2
Training loss: 0.3780471461516431
Validation loss: 2.843593425422674

Epoch: 6| Step: 3
Training loss: 0.7635730962455979
Validation loss: 2.8236558000495604

Epoch: 6| Step: 4
Training loss: 0.4811425949976545
Validation loss: 2.8804473685786824

Epoch: 6| Step: 5
Training loss: 0.6167294214725327
Validation loss: 2.8504761599253223

Epoch: 6| Step: 6
Training loss: 0.39975844927906684
Validation loss: 2.900911274598668

Epoch: 6| Step: 7
Training loss: 0.541376344809913
Validation loss: 2.8504707859431218

Epoch: 6| Step: 8
Training loss: 0.4149589191923817
Validation loss: 2.8410415606969464

Epoch: 6| Step: 9
Training loss: 0.5028545434609023
Validation loss: 2.9000424776583706

Epoch: 6| Step: 10
Training loss: 0.5886349449395021
Validation loss: 2.924454038698304

Epoch: 6| Step: 11
Training loss: 0.630719124997312
Validation loss: 2.88934904238267

Epoch: 6| Step: 12
Training loss: 0.5438760545562992
Validation loss: 2.9070018561446633

Epoch: 6| Step: 13
Training loss: 0.565444919730196
Validation loss: 2.861023474609327

Epoch: 546| Step: 0
Training loss: 0.44004679951170883
Validation loss: 2.905713568508422

Epoch: 6| Step: 1
Training loss: 0.551372211040188
Validation loss: 2.850538737145982

Epoch: 6| Step: 2
Training loss: 0.6107264717698004
Validation loss: 2.93304847360053

Epoch: 6| Step: 3
Training loss: 0.45040526221544236
Validation loss: 2.9139184038331947

Epoch: 6| Step: 4
Training loss: 0.45625233910888546
Validation loss: 2.8750680556051478

Epoch: 6| Step: 5
Training loss: 0.7221479948323818
Validation loss: 2.9038242690109777

Epoch: 6| Step: 6
Training loss: 0.5860108647511055
Validation loss: 2.9326726328320905

Epoch: 6| Step: 7
Training loss: 0.5891261504008464
Validation loss: 2.895928186926016

Epoch: 6| Step: 8
Training loss: 0.6210783230767012
Validation loss: 2.9479338889186195

Epoch: 6| Step: 9
Training loss: 0.3268971175302133
Validation loss: 2.929531435730386

Epoch: 6| Step: 10
Training loss: 0.49244026475351266
Validation loss: 2.9224256244873015

Epoch: 6| Step: 11
Training loss: 0.4234298557562763
Validation loss: 2.9314939634610253

Epoch: 6| Step: 12
Training loss: 0.547470912509046
Validation loss: 2.874957181086468

Epoch: 6| Step: 13
Training loss: 0.628957142162764
Validation loss: 2.885838726771932

Epoch: 547| Step: 0
Training loss: 0.3946579833482348
Validation loss: 2.9006513176586965

Epoch: 6| Step: 1
Training loss: 0.4366992366027624
Validation loss: 2.9227149286525878

Epoch: 6| Step: 2
Training loss: 0.40389978562278755
Validation loss: 2.8666621808822783

Epoch: 6| Step: 3
Training loss: 0.6573014691362977
Validation loss: 2.890056368598185

Epoch: 6| Step: 4
Training loss: 0.5005252582567483
Validation loss: 2.9055780638942754

Epoch: 6| Step: 5
Training loss: 0.38629435361744385
Validation loss: 2.8936601255451553

Epoch: 6| Step: 6
Training loss: 0.5487020218714773
Validation loss: 2.9660193215647785

Epoch: 6| Step: 7
Training loss: 0.6385790556208036
Validation loss: 2.894822669277886

Epoch: 6| Step: 8
Training loss: 0.6106264517697556
Validation loss: 2.948701091413039

Epoch: 6| Step: 9
Training loss: 0.5698664501659174
Validation loss: 2.8799292283722777

Epoch: 6| Step: 10
Training loss: 0.2948035072109948
Validation loss: 2.8978379855705954

Epoch: 6| Step: 11
Training loss: 0.3424144832501706
Validation loss: 2.8660648791797585

Epoch: 6| Step: 12
Training loss: 0.454805873917465
Validation loss: 2.9037770377082817

Epoch: 6| Step: 13
Training loss: 0.5589352877407918
Validation loss: 2.867866899896445

Epoch: 548| Step: 0
Training loss: 0.4812909975795516
Validation loss: 2.9140783587340406

Epoch: 6| Step: 1
Training loss: 0.6786616245715137
Validation loss: 2.8452266729748446

Epoch: 6| Step: 2
Training loss: 0.5751141683598608
Validation loss: 2.847354058312251

Epoch: 6| Step: 3
Training loss: 0.4981547220186448
Validation loss: 2.9211756095288655

Epoch: 6| Step: 4
Training loss: 0.2807293417133264
Validation loss: 2.93967041023634

Epoch: 6| Step: 5
Training loss: 0.5669483615968982
Validation loss: 2.95114749045894

Epoch: 6| Step: 6
Training loss: 0.5339939554690323
Validation loss: 2.9283160988335437

Epoch: 6| Step: 7
Training loss: 0.5425456202789986
Validation loss: 2.8846670248837913

Epoch: 6| Step: 8
Training loss: 0.3549436526510028
Validation loss: 2.8853655832407434

Epoch: 6| Step: 9
Training loss: 0.6035625846888805
Validation loss: 2.9027242843184915

Epoch: 6| Step: 10
Training loss: 0.3814576755908995
Validation loss: 2.900784004498472

Epoch: 6| Step: 11
Training loss: 0.5080730356763437
Validation loss: 2.9173694899132814

Epoch: 6| Step: 12
Training loss: 0.5363260556686056
Validation loss: 2.9037247081130793

Epoch: 6| Step: 13
Training loss: 0.674782649120611
Validation loss: 2.9417910921476174

Epoch: 549| Step: 0
Training loss: 0.45087902258296636
Validation loss: 2.879356428444866

Epoch: 6| Step: 1
Training loss: 0.3559653198784205
Validation loss: 2.9248435704061913

Epoch: 6| Step: 2
Training loss: 0.377733598647163
Validation loss: 2.8621772139905493

Epoch: 6| Step: 3
Training loss: 0.22794583189076503
Validation loss: 2.910466365804017

Epoch: 6| Step: 4
Training loss: 0.37338377434427034
Validation loss: 2.912879710624402

Epoch: 6| Step: 5
Training loss: 0.5227403125531199
Validation loss: 2.8719991558192364

Epoch: 6| Step: 6
Training loss: 0.7601598976729912
Validation loss: 2.918396945160597

Epoch: 6| Step: 7
Training loss: 0.40455910107572524
Validation loss: 2.9157075440285314

Epoch: 6| Step: 8
Training loss: 0.42425413739328655
Validation loss: 2.948987932414859

Epoch: 6| Step: 9
Training loss: 0.4086599394831624
Validation loss: 2.9278553027321164

Epoch: 6| Step: 10
Training loss: 0.6232672992023851
Validation loss: 2.9564516414078885

Epoch: 6| Step: 11
Training loss: 0.3789211545549383
Validation loss: 2.8657603579591373

Epoch: 6| Step: 12
Training loss: 0.4997392212782107
Validation loss: 2.9520443077621734

Epoch: 6| Step: 13
Training loss: 0.6010456589732033
Validation loss: 2.9595140375482303

Epoch: 550| Step: 0
Training loss: 0.621120308362193
Validation loss: 2.934550705356018

Epoch: 6| Step: 1
Training loss: 0.4376859950751013
Validation loss: 2.874196009240514

Epoch: 6| Step: 2
Training loss: 0.41331558517580574
Validation loss: 2.9266160386064985

Epoch: 6| Step: 3
Training loss: 0.6178898255770735
Validation loss: 2.935559856278648

Epoch: 6| Step: 4
Training loss: 0.3359631040707421
Validation loss: 2.916361484001779

Epoch: 6| Step: 5
Training loss: 0.3847225959070612
Validation loss: 2.9311473684773355

Epoch: 6| Step: 6
Training loss: 0.5267713477828888
Validation loss: 2.9050061972240675

Epoch: 6| Step: 7
Training loss: 0.47786253912243354
Validation loss: 2.872877069707077

Epoch: 6| Step: 8
Training loss: 0.6837821700776529
Validation loss: 2.8789693824612534

Epoch: 6| Step: 9
Training loss: 0.4507702778186641
Validation loss: 2.8667561191826088

Epoch: 6| Step: 10
Training loss: 0.5527030477643724
Validation loss: 2.913337160438218

Epoch: 6| Step: 11
Training loss: 0.35764160072919865
Validation loss: 2.938332554677715

Epoch: 6| Step: 12
Training loss: 0.380904209725814
Validation loss: 2.83871766457618

Epoch: 6| Step: 13
Training loss: 0.5523327018355859
Validation loss: 2.8654946051064067

Testing loss: 2.599103384760991
