Epoch: 1| Step: 0
Training loss: 6.051004424144443
Validation loss: 5.971624963550702

Epoch: 6| Step: 1
Training loss: 6.147037332133788
Validation loss: 5.970000929840373

Epoch: 6| Step: 2
Training loss: 5.325499483421701
Validation loss: 5.968328677447876

Epoch: 6| Step: 3
Training loss: 6.022357611328845
Validation loss: 5.966738430138616

Epoch: 6| Step: 4
Training loss: 6.505632161204208
Validation loss: 5.965138699330483

Epoch: 6| Step: 5
Training loss: 5.417163219678065
Validation loss: 5.963640752466156

Epoch: 6| Step: 6
Training loss: 5.568929321278946
Validation loss: 5.962243706548403

Epoch: 6| Step: 7
Training loss: 6.133589346697884
Validation loss: 5.9607986294030235

Epoch: 6| Step: 8
Training loss: 6.504580717655828
Validation loss: 5.9594573803551825

Epoch: 6| Step: 9
Training loss: 5.488167953679349
Validation loss: 5.958101316972047

Epoch: 6| Step: 10
Training loss: 7.439948953022728
Validation loss: 5.956657663106206

Epoch: 6| Step: 11
Training loss: 6.788389324004466
Validation loss: 5.955222760616129

Epoch: 6| Step: 12
Training loss: 5.411146471315779
Validation loss: 5.953703070447665

Epoch: 6| Step: 13
Training loss: 5.895115605354002
Validation loss: 5.952088860747438

Epoch: 2| Step: 0
Training loss: 6.400022578199615
Validation loss: 5.95042915078839

Epoch: 6| Step: 1
Training loss: 6.760074303122728
Validation loss: 5.948741323442431

Epoch: 6| Step: 2
Training loss: 5.815905813973583
Validation loss: 5.946938063981555

Epoch: 6| Step: 3
Training loss: 6.155419308148784
Validation loss: 5.945056162858432

Epoch: 6| Step: 4
Training loss: 6.238701946522134
Validation loss: 5.943191290267167

Epoch: 6| Step: 5
Training loss: 5.83145398338208
Validation loss: 5.941178477358604

Epoch: 6| Step: 6
Training loss: 5.621077632284484
Validation loss: 5.939090288246592

Epoch: 6| Step: 7
Training loss: 6.680317667186306
Validation loss: 5.9369262418092745

Epoch: 6| Step: 8
Training loss: 5.416783649452918
Validation loss: 5.934634136095082

Epoch: 6| Step: 9
Training loss: 6.6550991155865775
Validation loss: 5.932155465786069

Epoch: 6| Step: 10
Training loss: 5.272559605745826
Validation loss: 5.929552642133101

Epoch: 6| Step: 11
Training loss: 6.516120288054728
Validation loss: 5.926950016321352

Epoch: 6| Step: 12
Training loss: 5.760511989621093
Validation loss: 5.924308256821076

Epoch: 6| Step: 13
Training loss: 5.331981706214424
Validation loss: 5.921207011182684

Epoch: 3| Step: 0
Training loss: 6.859013506633421
Validation loss: 5.918006593018787

Epoch: 6| Step: 1
Training loss: 5.0657609397726
Validation loss: 5.914621814666649

Epoch: 6| Step: 2
Training loss: 6.317460632080791
Validation loss: 5.911185918460507

Epoch: 6| Step: 3
Training loss: 5.993049410387967
Validation loss: 5.907635373245943

Epoch: 6| Step: 4
Training loss: 6.313318784885636
Validation loss: 5.903449469353238

Epoch: 6| Step: 5
Training loss: 5.588649534219605
Validation loss: 5.899742888112442

Epoch: 6| Step: 6
Training loss: 5.619847799120393
Validation loss: 5.8951534333023865

Epoch: 6| Step: 7
Training loss: 6.132468516427987
Validation loss: 5.890635658207298

Epoch: 6| Step: 8
Training loss: 6.819799309963148
Validation loss: 5.885929357652844

Epoch: 6| Step: 9
Training loss: 6.616517016098153
Validation loss: 5.880685368512958

Epoch: 6| Step: 10
Training loss: 5.164336735402328
Validation loss: 5.875396471646457

Epoch: 6| Step: 11
Training loss: 5.636721457033307
Validation loss: 5.869701458142738

Epoch: 6| Step: 12
Training loss: 5.914614612603682
Validation loss: 5.863717791668698

Epoch: 6| Step: 13
Training loss: 5.719315631180229
Validation loss: 5.857619610101279

Epoch: 4| Step: 0
Training loss: 6.369927875583579
Validation loss: 5.851485438193825

Epoch: 6| Step: 1
Training loss: 6.250957873375631
Validation loss: 5.844717860182188

Epoch: 6| Step: 2
Training loss: 6.035108211782925
Validation loss: 5.83809196199005

Epoch: 6| Step: 3
Training loss: 6.295913812243714
Validation loss: 5.830845011460042

Epoch: 6| Step: 4
Training loss: 5.264682040127645
Validation loss: 5.823246582002296

Epoch: 6| Step: 5
Training loss: 3.683551031615369
Validation loss: 5.815760309967351

Epoch: 6| Step: 6
Training loss: 6.138975431466112
Validation loss: 5.808226405527301

Epoch: 6| Step: 7
Training loss: 6.574878462331726
Validation loss: 5.800394393402793

Epoch: 6| Step: 8
Training loss: 5.733659164278024
Validation loss: 5.792420436558018

Epoch: 6| Step: 9
Training loss: 5.351572657665999
Validation loss: 5.7840923848246515

Epoch: 6| Step: 10
Training loss: 5.552808913389086
Validation loss: 5.775676315581068

Epoch: 6| Step: 11
Training loss: 6.36863720076139
Validation loss: 5.767527968337899

Epoch: 6| Step: 12
Training loss: 6.223302660340188
Validation loss: 5.758443990141931

Epoch: 6| Step: 13
Training loss: 6.386529706204491
Validation loss: 5.750001465064705

Epoch: 5| Step: 0
Training loss: 5.720863493719242
Validation loss: 5.741054127227878

Epoch: 6| Step: 1
Training loss: 5.319616599931209
Validation loss: 5.732097980938731

Epoch: 6| Step: 2
Training loss: 5.30618377392602
Validation loss: 5.723086965624147

Epoch: 6| Step: 3
Training loss: 5.63277931573963
Validation loss: 5.714475552493615

Epoch: 6| Step: 4
Training loss: 5.992756285647692
Validation loss: 5.705651518796687

Epoch: 6| Step: 5
Training loss: 6.460628995714246
Validation loss: 5.697223972241964

Epoch: 6| Step: 6
Training loss: 6.318156210508777
Validation loss: 5.6885874061536175

Epoch: 6| Step: 7
Training loss: 6.114253679148299
Validation loss: 5.6799039873775

Epoch: 6| Step: 8
Training loss: 5.7946424272231845
Validation loss: 5.671500425694595

Epoch: 6| Step: 9
Training loss: 5.031100253133511
Validation loss: 5.663172972535977

Epoch: 6| Step: 10
Training loss: 5.770449225063262
Validation loss: 5.655158849183378

Epoch: 6| Step: 11
Training loss: 5.4018692172283345
Validation loss: 5.647328937625327

Epoch: 6| Step: 12
Training loss: 6.680144070196689
Validation loss: 5.639910708187292

Epoch: 6| Step: 13
Training loss: 5.4289114637647655
Validation loss: 5.63216841953053

Epoch: 6| Step: 0
Training loss: 4.632422599660539
Validation loss: 5.62501376115034

Epoch: 6| Step: 1
Training loss: 5.697639230765237
Validation loss: 5.617499967540271

Epoch: 6| Step: 2
Training loss: 6.03517584442612
Validation loss: 5.610595400352797

Epoch: 6| Step: 3
Training loss: 5.862879811165822
Validation loss: 5.603570653521772

Epoch: 6| Step: 4
Training loss: 6.405151868533983
Validation loss: 5.5966136855040585

Epoch: 6| Step: 5
Training loss: 6.068269481551757
Validation loss: 5.589985182577022

Epoch: 6| Step: 6
Training loss: 5.524609216186892
Validation loss: 5.583314506536977

Epoch: 6| Step: 7
Training loss: 5.073164268680986
Validation loss: 5.576776592648001

Epoch: 6| Step: 8
Training loss: 6.2875495559832615
Validation loss: 5.57058608144345

Epoch: 6| Step: 9
Training loss: 4.3708419659107784
Validation loss: 5.564150961708589

Epoch: 6| Step: 10
Training loss: 5.6225444944257115
Validation loss: 5.557996920233028

Epoch: 6| Step: 11
Training loss: 5.404559979308796
Validation loss: 5.551826953038026

Epoch: 6| Step: 12
Training loss: 6.078408673489561
Validation loss: 5.545872700716534

Epoch: 6| Step: 13
Training loss: 6.312380345787381
Validation loss: 5.539358370563484

Epoch: 7| Step: 0
Training loss: 5.369360338185935
Validation loss: 5.533563334882175

Epoch: 6| Step: 1
Training loss: 4.717336278681233
Validation loss: 5.527607093531578

Epoch: 6| Step: 2
Training loss: 4.976501943558174
Validation loss: 5.521418452895441

Epoch: 6| Step: 3
Training loss: 5.309138232919267
Validation loss: 5.515125630280187

Epoch: 6| Step: 4
Training loss: 6.2196108734972
Validation loss: 5.509063304523323

Epoch: 6| Step: 5
Training loss: 5.415675771995847
Validation loss: 5.502642170283927

Epoch: 6| Step: 6
Training loss: 5.5151766413796866
Validation loss: 5.496906971364083

Epoch: 6| Step: 7
Training loss: 6.30669718008476
Validation loss: 5.4905875033735825

Epoch: 6| Step: 8
Training loss: 5.273762287451984
Validation loss: 5.484130969872099

Epoch: 6| Step: 9
Training loss: 5.343367356548795
Validation loss: 5.4781644168008

Epoch: 6| Step: 10
Training loss: 6.541233736845736
Validation loss: 5.472138029291015

Epoch: 6| Step: 11
Training loss: 5.790300532893821
Validation loss: 5.46560383714985

Epoch: 6| Step: 12
Training loss: 5.097248023046089
Validation loss: 5.459841347602994

Epoch: 6| Step: 13
Training loss: 6.34060786561263
Validation loss: 5.453751317648561

Epoch: 8| Step: 0
Training loss: 5.543251939008922
Validation loss: 5.447311873505789

Epoch: 6| Step: 1
Training loss: 6.318418542033635
Validation loss: 5.4413737679247065

Epoch: 6| Step: 2
Training loss: 5.659261839486763
Validation loss: 5.435310800012895

Epoch: 6| Step: 3
Training loss: 5.250295721535523
Validation loss: 5.428871441082358

Epoch: 6| Step: 4
Training loss: 5.826070387567307
Validation loss: 5.422749649428413

Epoch: 6| Step: 5
Training loss: 5.597865801533868
Validation loss: 5.41647116479435

Epoch: 6| Step: 6
Training loss: 4.914294602775773
Validation loss: 5.409742575941643

Epoch: 6| Step: 7
Training loss: 5.201265753236515
Validation loss: 5.403807277489128

Epoch: 6| Step: 8
Training loss: 5.811712396235941
Validation loss: 5.39787840903871

Epoch: 6| Step: 9
Training loss: 4.982717782642807
Validation loss: 5.391382519851669

Epoch: 6| Step: 10
Training loss: 5.204169091294607
Validation loss: 5.384678458623399

Epoch: 6| Step: 11
Training loss: 5.757607113450132
Validation loss: 5.378050921511976

Epoch: 6| Step: 12
Training loss: 5.300637678255568
Validation loss: 5.371307997620876

Epoch: 6| Step: 13
Training loss: 5.865542327184434
Validation loss: 5.365053081006924

Epoch: 9| Step: 0
Training loss: 5.1439048252467
Validation loss: 5.358471051824823

Epoch: 6| Step: 1
Training loss: 4.642894870479011
Validation loss: 5.351713734367023

Epoch: 6| Step: 2
Training loss: 5.8058032764269845
Validation loss: 5.3454180042002415

Epoch: 6| Step: 3
Training loss: 6.068555187237476
Validation loss: 5.3387550968832675

Epoch: 6| Step: 4
Training loss: 5.359240293895205
Validation loss: 5.332193352141384

Epoch: 6| Step: 5
Training loss: 5.569869742111731
Validation loss: 5.325619344258754

Epoch: 6| Step: 6
Training loss: 5.07045375350959
Validation loss: 5.319129935656761

Epoch: 6| Step: 7
Training loss: 4.702288683169429
Validation loss: 5.312298849448978

Epoch: 6| Step: 8
Training loss: 6.60977554009436
Validation loss: 5.306064941869639

Epoch: 6| Step: 9
Training loss: 5.278480842118341
Validation loss: 5.299968944914422

Epoch: 6| Step: 10
Training loss: 6.081154350320494
Validation loss: 5.293994821939601

Epoch: 6| Step: 11
Training loss: 4.994260927496086
Validation loss: 5.287466059005417

Epoch: 6| Step: 12
Training loss: 5.518857878411483
Validation loss: 5.281535876359942

Epoch: 6| Step: 13
Training loss: 4.926367462391708
Validation loss: 5.275413433102382

Epoch: 10| Step: 0
Training loss: 4.8702529879113845
Validation loss: 5.270104891935373

Epoch: 6| Step: 1
Training loss: 5.31112455626151
Validation loss: 5.2644570825995025

Epoch: 6| Step: 2
Training loss: 5.894228371940295
Validation loss: 5.258709600964577

Epoch: 6| Step: 3
Training loss: 6.674312816208386
Validation loss: 5.253150781632122

Epoch: 6| Step: 4
Training loss: 5.530732211430569
Validation loss: 5.24759612982983

Epoch: 6| Step: 5
Training loss: 4.355485828862255
Validation loss: 5.2415873624122185

Epoch: 6| Step: 6
Training loss: 4.893501971160127
Validation loss: 5.23610811151924

Epoch: 6| Step: 7
Training loss: 4.730425606868703
Validation loss: 5.230648646395997

Epoch: 6| Step: 8
Training loss: 5.95155902601057
Validation loss: 5.225575017849349

Epoch: 6| Step: 9
Training loss: 4.6876259341807245
Validation loss: 5.220361335203989

Epoch: 6| Step: 10
Training loss: 5.918431551623285
Validation loss: 5.214717624391593

Epoch: 6| Step: 11
Training loss: 4.902528359634098
Validation loss: 5.211046117654288

Epoch: 6| Step: 12
Training loss: 5.911131763820533
Validation loss: 5.2062645834496815

Epoch: 6| Step: 13
Training loss: 4.858080332707866
Validation loss: 5.200130452451538

Epoch: 11| Step: 0
Training loss: 5.194775179274654
Validation loss: 5.194744367774908

Epoch: 6| Step: 1
Training loss: 5.39550913815029
Validation loss: 5.1894648557431555

Epoch: 6| Step: 2
Training loss: 5.469926805581849
Validation loss: 5.184500872904494

Epoch: 6| Step: 3
Training loss: 5.069692517950423
Validation loss: 5.179186060719022

Epoch: 6| Step: 4
Training loss: 5.338879244916191
Validation loss: 5.174114990729965

Epoch: 6| Step: 5
Training loss: 4.9386682214823745
Validation loss: 5.168879107054834

Epoch: 6| Step: 6
Training loss: 5.139807731802568
Validation loss: 5.164389457105326

Epoch: 6| Step: 7
Training loss: 5.9178063096518025
Validation loss: 5.1600299581993685

Epoch: 6| Step: 8
Training loss: 4.9532534224651865
Validation loss: 5.154174541116845

Epoch: 6| Step: 9
Training loss: 5.5670204225319395
Validation loss: 5.148952892479892

Epoch: 6| Step: 10
Training loss: 4.690898426277667
Validation loss: 5.143951638256922

Epoch: 6| Step: 11
Training loss: 3.4902298665244382
Validation loss: 5.13881827068207

Epoch: 6| Step: 12
Training loss: 6.111899866392335
Validation loss: 5.134785869409027

Epoch: 6| Step: 13
Training loss: 6.175267622241066
Validation loss: 5.129499739557943

Epoch: 12| Step: 0
Training loss: 4.710458506561863
Validation loss: 5.124406516594729

Epoch: 6| Step: 1
Training loss: 4.82420293519675
Validation loss: 5.119900872691515

Epoch: 6| Step: 2
Training loss: 5.9526097833153715
Validation loss: 5.115666908522826

Epoch: 6| Step: 3
Training loss: 5.231225367115504
Validation loss: 5.109552969443255

Epoch: 6| Step: 4
Training loss: 6.220274158580967
Validation loss: 5.104755580429818

Epoch: 6| Step: 5
Training loss: 5.899632536226303
Validation loss: 5.09939190972996

Epoch: 6| Step: 6
Training loss: 4.8803704830930705
Validation loss: 5.0947792869931705

Epoch: 6| Step: 7
Training loss: 4.132595582977048
Validation loss: 5.089186857533362

Epoch: 6| Step: 8
Training loss: 4.730037502599845
Validation loss: 5.084577199787426

Epoch: 6| Step: 9
Training loss: 4.522171923966637
Validation loss: 5.079316986254614

Epoch: 6| Step: 10
Training loss: 5.782079028924502
Validation loss: 5.073885481150924

Epoch: 6| Step: 11
Training loss: 5.434104473099551
Validation loss: 5.069683613934293

Epoch: 6| Step: 12
Training loss: 4.910859876183675
Validation loss: 5.0649381817945605

Epoch: 6| Step: 13
Training loss: 5.351930480334457
Validation loss: 5.059467679094391

Epoch: 13| Step: 0
Training loss: 5.639065090907118
Validation loss: 5.053897220047036

Epoch: 6| Step: 1
Training loss: 6.033184156452862
Validation loss: 5.050002885572157

Epoch: 6| Step: 2
Training loss: 5.0991711934138095
Validation loss: 5.045503223224987

Epoch: 6| Step: 3
Training loss: 5.230696111271585
Validation loss: 5.039284335041568

Epoch: 6| Step: 4
Training loss: 4.211889042681601
Validation loss: 5.033680299248404

Epoch: 6| Step: 5
Training loss: 5.956533342408864
Validation loss: 5.028341048684342

Epoch: 6| Step: 6
Training loss: 5.337579387994574
Validation loss: 5.024587164474399

Epoch: 6| Step: 7
Training loss: 4.5814434432215245
Validation loss: 5.019366238624052

Epoch: 6| Step: 8
Training loss: 4.3843849883506145
Validation loss: 5.013534474666574

Epoch: 6| Step: 9
Training loss: 5.679218005225623
Validation loss: 5.007888547386376

Epoch: 6| Step: 10
Training loss: 5.1527276232330115
Validation loss: 5.003033957287418

Epoch: 6| Step: 11
Training loss: 4.7016023217717855
Validation loss: 4.9977574723673985

Epoch: 6| Step: 12
Training loss: 3.6561890947534756
Validation loss: 4.993174599101032

Epoch: 6| Step: 13
Training loss: 5.775191147848654
Validation loss: 4.987631791109618

Epoch: 14| Step: 0
Training loss: 4.654510377892626
Validation loss: 4.982551743487054

Epoch: 6| Step: 1
Training loss: 4.379654506486945
Validation loss: 4.977443072205682

Epoch: 6| Step: 2
Training loss: 4.8727903004223
Validation loss: 4.973069846270225

Epoch: 6| Step: 3
Training loss: 5.478329709412286
Validation loss: 4.96838131222512

Epoch: 6| Step: 4
Training loss: 5.561941568868099
Validation loss: 4.963391435503841

Epoch: 6| Step: 5
Training loss: 5.562498456976173
Validation loss: 4.957629541194522

Epoch: 6| Step: 6
Training loss: 4.602122041266925
Validation loss: 4.953126058969475

Epoch: 6| Step: 7
Training loss: 5.748343851167047
Validation loss: 4.948429131990133

Epoch: 6| Step: 8
Training loss: 6.2984223464257365
Validation loss: 4.9426290212953345

Epoch: 6| Step: 9
Training loss: 4.177879783949718
Validation loss: 4.937532191433166

Epoch: 6| Step: 10
Training loss: 5.1721357297147375
Validation loss: 4.9328024041522935

Epoch: 6| Step: 11
Training loss: 5.297103831881843
Validation loss: 4.928091299602558

Epoch: 6| Step: 12
Training loss: 4.2636190875110636
Validation loss: 4.923313620899557

Epoch: 6| Step: 13
Training loss: 4.487015109841649
Validation loss: 4.918107236609611

Epoch: 15| Step: 0
Training loss: 5.460604808971324
Validation loss: 4.913040612833817

Epoch: 6| Step: 1
Training loss: 5.159746314030031
Validation loss: 4.908140332627005

Epoch: 6| Step: 2
Training loss: 5.141175956536058
Validation loss: 4.902641346119541

Epoch: 6| Step: 3
Training loss: 5.006571647226621
Validation loss: 4.897224921095151

Epoch: 6| Step: 4
Training loss: 5.138491109396576
Validation loss: 4.892770672306877

Epoch: 6| Step: 5
Training loss: 5.432495971622018
Validation loss: 4.887989150445763

Epoch: 6| Step: 6
Training loss: 4.744647574164739
Validation loss: 4.882924461607

Epoch: 6| Step: 7
Training loss: 3.7502324350165805
Validation loss: 4.8776849379185006

Epoch: 6| Step: 8
Training loss: 4.787336477171236
Validation loss: 4.87185893795293

Epoch: 6| Step: 9
Training loss: 5.2604230320454475
Validation loss: 4.867289028261983

Epoch: 6| Step: 10
Training loss: 4.969946183463994
Validation loss: 4.86242741822348

Epoch: 6| Step: 11
Training loss: 3.8597456410460804
Validation loss: 4.858441720127553

Epoch: 6| Step: 12
Training loss: 5.339184511759296
Validation loss: 4.853478618969419

Epoch: 6| Step: 13
Training loss: 5.656852563618188
Validation loss: 4.847946580445648

Epoch: 16| Step: 0
Training loss: 5.00388452315248
Validation loss: 4.8431079069754785

Epoch: 6| Step: 1
Training loss: 5.078798971200589
Validation loss: 4.838547667248814

Epoch: 6| Step: 2
Training loss: 4.848000513435563
Validation loss: 4.8329108590707985

Epoch: 6| Step: 3
Training loss: 5.069588678592888
Validation loss: 4.828543536862636

Epoch: 6| Step: 4
Training loss: 4.3043418787067855
Validation loss: 4.824362612907439

Epoch: 6| Step: 5
Training loss: 4.167432841747845
Validation loss: 4.820770489220703

Epoch: 6| Step: 6
Training loss: 5.099815642072749
Validation loss: 4.815240665837176

Epoch: 6| Step: 7
Training loss: 4.3659666262236625
Validation loss: 4.808362891747093

Epoch: 6| Step: 8
Training loss: 5.492525744162968
Validation loss: 4.805237049629193

Epoch: 6| Step: 9
Training loss: 5.592562927792441
Validation loss: 4.800690300630647

Epoch: 6| Step: 10
Training loss: 4.2216289728115655
Validation loss: 4.794212604799702

Epoch: 6| Step: 11
Training loss: 5.3625542911368855
Validation loss: 4.788042450427985

Epoch: 6| Step: 12
Training loss: 5.115625507072745
Validation loss: 4.783383493902573

Epoch: 6| Step: 13
Training loss: 5.118168627615547
Validation loss: 4.779218487290941

Epoch: 17| Step: 0
Training loss: 5.5148883792375365
Validation loss: 4.773088058442612

Epoch: 6| Step: 1
Training loss: 4.664452004582292
Validation loss: 4.76796684050497

Epoch: 6| Step: 2
Training loss: 5.2250426952315125
Validation loss: 4.762410164533956

Epoch: 6| Step: 3
Training loss: 4.0346287015988995
Validation loss: 4.757475742392506

Epoch: 6| Step: 4
Training loss: 5.044404077485094
Validation loss: 4.751438425006517

Epoch: 6| Step: 5
Training loss: 4.9137414969926505
Validation loss: 4.747547855199617

Epoch: 6| Step: 6
Training loss: 4.896760547033158
Validation loss: 4.741999933009775

Epoch: 6| Step: 7
Training loss: 4.616289958434877
Validation loss: 4.737121356202294

Epoch: 6| Step: 8
Training loss: 5.6744584014171835
Validation loss: 4.731747358645664

Epoch: 6| Step: 9
Training loss: 4.625304340968498
Validation loss: 4.727768824462143

Epoch: 6| Step: 10
Training loss: 4.2639129892027805
Validation loss: 4.7214160318278875

Epoch: 6| Step: 11
Training loss: 4.6991637520810094
Validation loss: 4.716893081263083

Epoch: 6| Step: 12
Training loss: 4.2732317385050385
Validation loss: 4.7114405323912125

Epoch: 6| Step: 13
Training loss: 5.390679135258065
Validation loss: 4.707408521630803

Epoch: 18| Step: 0
Training loss: 4.903587055985139
Validation loss: 4.702208572272536

Epoch: 6| Step: 1
Training loss: 4.856531617628711
Validation loss: 4.696455187552043

Epoch: 6| Step: 2
Training loss: 3.987342118632474
Validation loss: 4.692143458819096

Epoch: 6| Step: 3
Training loss: 4.302987928014971
Validation loss: 4.690366182381183

Epoch: 6| Step: 4
Training loss: 5.698195576742742
Validation loss: 4.68377836201353

Epoch: 6| Step: 5
Training loss: 4.393181650401874
Validation loss: 4.676753870086909

Epoch: 6| Step: 6
Training loss: 4.856978730225639
Validation loss: 4.671047737085084

Epoch: 6| Step: 7
Training loss: 3.96695278054808
Validation loss: 4.66640057259276

Epoch: 6| Step: 8
Training loss: 4.143929713798292
Validation loss: 4.661866864535997

Epoch: 6| Step: 9
Training loss: 5.240156118382307
Validation loss: 4.656845259540118

Epoch: 6| Step: 10
Training loss: 5.323812131964752
Validation loss: 4.651610347872033

Epoch: 6| Step: 11
Training loss: 5.154006007329055
Validation loss: 4.646621203936721

Epoch: 6| Step: 12
Training loss: 5.3477101069010065
Validation loss: 4.642331855178948

Epoch: 6| Step: 13
Training loss: 4.582660602558539
Validation loss: 4.637239019379926

Epoch: 19| Step: 0
Training loss: 4.630324520660078
Validation loss: 4.6320253232001285

Epoch: 6| Step: 1
Training loss: 5.1238725864313235
Validation loss: 4.626528478770258

Epoch: 6| Step: 2
Training loss: 5.617486640700382
Validation loss: 4.621125359533251

Epoch: 6| Step: 3
Training loss: 5.542663694862839
Validation loss: 4.615371527714391

Epoch: 6| Step: 4
Training loss: 4.117756118452112
Validation loss: 4.610784696543886

Epoch: 6| Step: 5
Training loss: 4.430623919292743
Validation loss: 4.606076921638692

Epoch: 6| Step: 6
Training loss: 4.404029882081922
Validation loss: 4.600069573470585

Epoch: 6| Step: 7
Training loss: 4.734007767639105
Validation loss: 4.5949347734993164

Epoch: 6| Step: 8
Training loss: 5.23452804113958
Validation loss: 4.589903659294299

Epoch: 6| Step: 9
Training loss: 4.3561588578835355
Validation loss: 4.585233583424847

Epoch: 6| Step: 10
Training loss: 4.5784207922255895
Validation loss: 4.580046665975603

Epoch: 6| Step: 11
Training loss: 4.853079394379851
Validation loss: 4.5750200594269455

Epoch: 6| Step: 12
Training loss: 3.91849375104485
Validation loss: 4.56958172381626

Epoch: 6| Step: 13
Training loss: 4.293315953245189
Validation loss: 4.564728040445741

Epoch: 20| Step: 0
Training loss: 4.876568664136204
Validation loss: 4.5598313352277735

Epoch: 6| Step: 1
Training loss: 5.685853153786667
Validation loss: 4.555219441448386

Epoch: 6| Step: 2
Training loss: 3.076733579669139
Validation loss: 4.550180900387055

Epoch: 6| Step: 3
Training loss: 4.562968399878103
Validation loss: 4.544990892026957

Epoch: 6| Step: 4
Training loss: 4.619953804941131
Validation loss: 4.539856202793324

Epoch: 6| Step: 5
Training loss: 4.577001231931187
Validation loss: 4.53573824586894

Epoch: 6| Step: 6
Training loss: 4.044763669724215
Validation loss: 4.5304920483401405

Epoch: 6| Step: 7
Training loss: 5.084120559187357
Validation loss: 4.526021321568857

Epoch: 6| Step: 8
Training loss: 4.798295497252652
Validation loss: 4.52060744018604

Epoch: 6| Step: 9
Training loss: 5.298416858521518
Validation loss: 4.5157203180269345

Epoch: 6| Step: 10
Training loss: 3.6817702698078696
Validation loss: 4.511407204532554

Epoch: 6| Step: 11
Training loss: 4.903745753208396
Validation loss: 4.5065199984059445

Epoch: 6| Step: 12
Training loss: 4.33890092636134
Validation loss: 4.501375341403192

Epoch: 6| Step: 13
Training loss: 5.027048951511082
Validation loss: 4.496729138880372

Epoch: 21| Step: 0
Training loss: 4.609236996411327
Validation loss: 4.491965450382722

Epoch: 6| Step: 1
Training loss: 4.054061341493947
Validation loss: 4.486311650526184

Epoch: 6| Step: 2
Training loss: 4.637578201662812
Validation loss: 4.481754046565139

Epoch: 6| Step: 3
Training loss: 4.982158682349288
Validation loss: 4.476788011943363

Epoch: 6| Step: 4
Training loss: 4.294714478138269
Validation loss: 4.471990446372795

Epoch: 6| Step: 5
Training loss: 4.201579323788486
Validation loss: 4.466976124923071

Epoch: 6| Step: 6
Training loss: 4.2830352402403395
Validation loss: 4.461907294169376

Epoch: 6| Step: 7
Training loss: 4.490856842660921
Validation loss: 4.4570353511041425

Epoch: 6| Step: 8
Training loss: 5.121231182008881
Validation loss: 4.451747783939186

Epoch: 6| Step: 9
Training loss: 5.211833642314491
Validation loss: 4.44730681527482

Epoch: 6| Step: 10
Training loss: 5.0666874650896405
Validation loss: 4.4416729643719215

Epoch: 6| Step: 11
Training loss: 3.9699637892294395
Validation loss: 4.437113731658191

Epoch: 6| Step: 12
Training loss: 4.845231943158946
Validation loss: 4.431712284912584

Epoch: 6| Step: 13
Training loss: 4.243607594231394
Validation loss: 4.427042176298425

Epoch: 22| Step: 0
Training loss: 3.7766118884063076
Validation loss: 4.4217606384801575

Epoch: 6| Step: 1
Training loss: 5.118985065656765
Validation loss: 4.417159190996348

Epoch: 6| Step: 2
Training loss: 4.390336105236518
Validation loss: 4.412109194875587

Epoch: 6| Step: 3
Training loss: 4.839910745349465
Validation loss: 4.406874465881035

Epoch: 6| Step: 4
Training loss: 4.461360343494118
Validation loss: 4.402302680603916

Epoch: 6| Step: 5
Training loss: 4.603786585152581
Validation loss: 4.397226242499496

Epoch: 6| Step: 6
Training loss: 4.040782923610496
Validation loss: 4.392717236274717

Epoch: 6| Step: 7
Training loss: 4.623680132616226
Validation loss: 4.386789784998517

Epoch: 6| Step: 8
Training loss: 4.321946343903978
Validation loss: 4.382063005431735

Epoch: 6| Step: 9
Training loss: 4.273961008982046
Validation loss: 4.377120512281381

Epoch: 6| Step: 10
Training loss: 4.394942038092024
Validation loss: 4.372019942641546

Epoch: 6| Step: 11
Training loss: 4.597533037192465
Validation loss: 4.367362667749405

Epoch: 6| Step: 12
Training loss: 5.474019503652429
Validation loss: 4.36205957442991

Epoch: 6| Step: 13
Training loss: 4.08536888819562
Validation loss: 4.357735748362836

Epoch: 23| Step: 0
Training loss: 4.23860660833541
Validation loss: 4.351297969756432

Epoch: 6| Step: 1
Training loss: 4.42671289427492
Validation loss: 4.346600390896322

Epoch: 6| Step: 2
Training loss: 3.569848495816182
Validation loss: 4.341502882247168

Epoch: 6| Step: 3
Training loss: 3.917550792060522
Validation loss: 4.337059906721484

Epoch: 6| Step: 4
Training loss: 3.9688011826946923
Validation loss: 4.332853321241272

Epoch: 6| Step: 5
Training loss: 4.236332627360447
Validation loss: 4.327450384086612

Epoch: 6| Step: 6
Training loss: 4.868143982688027
Validation loss: 4.322751598960071

Epoch: 6| Step: 7
Training loss: 5.275684742529966
Validation loss: 4.316718245287736

Epoch: 6| Step: 8
Training loss: 3.869002099520463
Validation loss: 4.311747794039949

Epoch: 6| Step: 9
Training loss: 4.784062574315455
Validation loss: 4.306746971564651

Epoch: 6| Step: 10
Training loss: 4.776476103625544
Validation loss: 4.302802086642374

Epoch: 6| Step: 11
Training loss: 4.977003811562496
Validation loss: 4.2975877575275545

Epoch: 6| Step: 12
Training loss: 3.681304770614347
Validation loss: 4.292240302010246

Epoch: 6| Step: 13
Training loss: 5.221419331309641
Validation loss: 4.286787141755264

Epoch: 24| Step: 0
Training loss: 4.675820818154426
Validation loss: 4.281946965495695

Epoch: 6| Step: 1
Training loss: 3.3983614507475153
Validation loss: 4.2758239554376285

Epoch: 6| Step: 2
Training loss: 4.268581385933721
Validation loss: 4.270775337135594

Epoch: 6| Step: 3
Training loss: 3.486956679157947
Validation loss: 4.265883143326012

Epoch: 6| Step: 4
Training loss: 4.126840354292185
Validation loss: 4.260842722486933

Epoch: 6| Step: 5
Training loss: 4.566427134522388
Validation loss: 4.255791812831379

Epoch: 6| Step: 6
Training loss: 3.850627917322838
Validation loss: 4.250942144496311

Epoch: 6| Step: 7
Training loss: 4.4398142193254015
Validation loss: 4.2471816872180925

Epoch: 6| Step: 8
Training loss: 4.66643664383518
Validation loss: 4.243094762332055

Epoch: 6| Step: 9
Training loss: 5.514530581212505
Validation loss: 4.235196304905933

Epoch: 6| Step: 10
Training loss: 4.998929099794814
Validation loss: 4.230721919033078

Epoch: 6| Step: 11
Training loss: 3.946051983413085
Validation loss: 4.225825538715829

Epoch: 6| Step: 12
Training loss: 4.342363314588473
Validation loss: 4.221141410547743

Epoch: 6| Step: 13
Training loss: 4.535359801095237
Validation loss: 4.214194072422809

Epoch: 25| Step: 0
Training loss: 4.340550403764158
Validation loss: 4.208837548193097

Epoch: 6| Step: 1
Training loss: 4.254179526274421
Validation loss: 4.205593325032251

Epoch: 6| Step: 2
Training loss: 4.138238643853968
Validation loss: 4.199114033184395

Epoch: 6| Step: 3
Training loss: 4.1526397857931
Validation loss: 4.192632632628501

Epoch: 6| Step: 4
Training loss: 4.904698995362246
Validation loss: 4.1864990632308885

Epoch: 6| Step: 5
Training loss: 4.679496748512166
Validation loss: 4.182489994551659

Epoch: 6| Step: 6
Training loss: 4.295328645755622
Validation loss: 4.177011763545398

Epoch: 6| Step: 7
Training loss: 4.679340228663218
Validation loss: 4.170794324409816

Epoch: 6| Step: 8
Training loss: 4.093471837967426
Validation loss: 4.164104296848452

Epoch: 6| Step: 9
Training loss: 4.326648666940013
Validation loss: 4.158960553239536

Epoch: 6| Step: 10
Training loss: 4.261997119403154
Validation loss: 4.153912319456091

Epoch: 6| Step: 11
Training loss: 4.277193026739416
Validation loss: 4.148423955767134

Epoch: 6| Step: 12
Training loss: 3.5226911951270417
Validation loss: 4.1425902495206035

Epoch: 6| Step: 13
Training loss: 4.204245265582615
Validation loss: 4.136339150393454

Epoch: 26| Step: 0
Training loss: 3.5689205736860123
Validation loss: 4.134063935057201

Epoch: 6| Step: 1
Training loss: 4.709095760944153
Validation loss: 4.127962416576346

Epoch: 6| Step: 2
Training loss: 4.526124357193177
Validation loss: 4.121274710926211

Epoch: 6| Step: 3
Training loss: 4.674503875355425
Validation loss: 4.1154825443223135

Epoch: 6| Step: 4
Training loss: 4.386124337092994
Validation loss: 4.110089122768113

Epoch: 6| Step: 5
Training loss: 4.206159552725431
Validation loss: 4.104643560028424

Epoch: 6| Step: 6
Training loss: 4.093228838412092
Validation loss: 4.099362784389436

Epoch: 6| Step: 7
Training loss: 3.9861251278467256
Validation loss: 4.094277345504729

Epoch: 6| Step: 8
Training loss: 4.582393388023082
Validation loss: 4.089021198636013

Epoch: 6| Step: 9
Training loss: 5.016174096208839
Validation loss: 4.083832878904156

Epoch: 6| Step: 10
Training loss: 4.100258349210868
Validation loss: 4.077458235797499

Epoch: 6| Step: 11
Training loss: 4.181929797918277
Validation loss: 4.072604890225472

Epoch: 6| Step: 12
Training loss: 4.148991492111225
Validation loss: 4.066946638090048

Epoch: 6| Step: 13
Training loss: 2.4786022943684776
Validation loss: 4.061305941651118

Epoch: 27| Step: 0
Training loss: 5.082228285116777
Validation loss: 4.055818687826886

Epoch: 6| Step: 1
Training loss: 4.139330391658607
Validation loss: 4.050569357705411

Epoch: 6| Step: 2
Training loss: 3.4263415862475552
Validation loss: 4.04475775557194

Epoch: 6| Step: 3
Training loss: 4.067744464526567
Validation loss: 4.040467303887381

Epoch: 6| Step: 4
Training loss: 4.504647292408575
Validation loss: 4.034531512032853

Epoch: 6| Step: 5
Training loss: 3.5264260079298837
Validation loss: 4.0292630683440995

Epoch: 6| Step: 6
Training loss: 3.2603495208033655
Validation loss: 4.0239917558543885

Epoch: 6| Step: 7
Training loss: 5.145594088080317
Validation loss: 4.019758380568544

Epoch: 6| Step: 8
Training loss: 4.576071425087244
Validation loss: 4.015054328237354

Epoch: 6| Step: 9
Training loss: 4.1300260961414725
Validation loss: 4.009406552942589

Epoch: 6| Step: 10
Training loss: 3.541407197909646
Validation loss: 4.0035110799655875

Epoch: 6| Step: 11
Training loss: 4.463047470575389
Validation loss: 3.999121350901196

Epoch: 6| Step: 12
Training loss: 3.899774050891956
Validation loss: 3.9938271297674146

Epoch: 6| Step: 13
Training loss: 3.8967137013499062
Validation loss: 3.9894296734387433

Epoch: 28| Step: 0
Training loss: 3.6703656929614463
Validation loss: 3.9829761318366694

Epoch: 6| Step: 1
Training loss: 3.9671508691215136
Validation loss: 3.9772030377578425

Epoch: 6| Step: 2
Training loss: 4.590978915475843
Validation loss: 3.972903603724165

Epoch: 6| Step: 3
Training loss: 4.026756917266295
Validation loss: 3.9679159454459345

Epoch: 6| Step: 4
Training loss: 3.9533534530547954
Validation loss: 3.963182704609512

Epoch: 6| Step: 5
Training loss: 4.3590558116373925
Validation loss: 3.9568528401560656

Epoch: 6| Step: 6
Training loss: 5.191607951428718
Validation loss: 3.951554440004559

Epoch: 6| Step: 7
Training loss: 3.4673904641472633
Validation loss: 3.9461856895525638

Epoch: 6| Step: 8
Training loss: 4.015436427813364
Validation loss: 3.941856718958963

Epoch: 6| Step: 9
Training loss: 4.3591501048060355
Validation loss: 3.9365984777756835

Epoch: 6| Step: 10
Training loss: 4.0369787393444305
Validation loss: 3.9305178786869464

Epoch: 6| Step: 11
Training loss: 3.2020899146928
Validation loss: 3.9260780336162067

Epoch: 6| Step: 12
Training loss: 2.937458930844472
Validation loss: 3.9219272807614693

Epoch: 6| Step: 13
Training loss: 4.81734232843951
Validation loss: 3.917358797210898

Epoch: 29| Step: 0
Training loss: 3.8164747187115564
Validation loss: 3.9120404267071733

Epoch: 6| Step: 1
Training loss: 4.021767515985567
Validation loss: 3.9067194948975206

Epoch: 6| Step: 2
Training loss: 4.608701288158798
Validation loss: 3.901872017687317

Epoch: 6| Step: 3
Training loss: 3.563076708777036
Validation loss: 3.897456757356764

Epoch: 6| Step: 4
Training loss: 5.0780074355381615
Validation loss: 3.8919541260269113

Epoch: 6| Step: 5
Training loss: 4.295702077128862
Validation loss: 3.8852872784354164

Epoch: 6| Step: 6
Training loss: 2.786304809524103
Validation loss: 3.8789401582719307

Epoch: 6| Step: 7
Training loss: 3.7623546534247634
Validation loss: 3.874502744866603

Epoch: 6| Step: 8
Training loss: 4.204232335908871
Validation loss: 3.8701852398944685

Epoch: 6| Step: 9
Training loss: 4.700479263868589
Validation loss: 3.8654442348376423

Epoch: 6| Step: 10
Training loss: 3.731909796112221
Validation loss: 3.86009285823362

Epoch: 6| Step: 11
Training loss: 4.0867179285747595
Validation loss: 3.8551404118148462

Epoch: 6| Step: 12
Training loss: 3.555612297068941
Validation loss: 3.849786499841303

Epoch: 6| Step: 13
Training loss: 3.4195902961581672
Validation loss: 3.844252556095554

Epoch: 30| Step: 0
Training loss: 4.182514924218274
Validation loss: 3.8393868387619245

Epoch: 6| Step: 1
Training loss: 3.465682314234564
Validation loss: 3.835639936892436

Epoch: 6| Step: 2
Training loss: 3.7102250549658162
Validation loss: 3.832322177349026

Epoch: 6| Step: 3
Training loss: 3.866071196996266
Validation loss: 3.826079090467479

Epoch: 6| Step: 4
Training loss: 4.57392998361312
Validation loss: 3.8199441286231943

Epoch: 6| Step: 5
Training loss: 4.188702766427634
Validation loss: 3.8153725105494734

Epoch: 6| Step: 6
Training loss: 3.58633347529486
Validation loss: 3.811733961013099

Epoch: 6| Step: 7
Training loss: 4.001887591352766
Validation loss: 3.8084848241635134

Epoch: 6| Step: 8
Training loss: 3.0587427875167186
Validation loss: 3.8004580468464115

Epoch: 6| Step: 9
Training loss: 4.183421867821834
Validation loss: 3.795724503471112

Epoch: 6| Step: 10
Training loss: 3.368788761064547
Validation loss: 3.7923917740777857

Epoch: 6| Step: 11
Training loss: 4.38937414413459
Validation loss: 3.7884643082495013

Epoch: 6| Step: 12
Training loss: 4.3081795985366105
Validation loss: 3.782238287283337

Epoch: 6| Step: 13
Training loss: 4.0135915632171795
Validation loss: 3.775893692098809

Epoch: 31| Step: 0
Training loss: 3.8023906566139902
Validation loss: 3.769904737137461

Epoch: 6| Step: 1
Training loss: 3.3221282661474465
Validation loss: 3.7667464489772295

Epoch: 6| Step: 2
Training loss: 4.494896219687039
Validation loss: 3.7618111572324073

Epoch: 6| Step: 3
Training loss: 4.111872041292137
Validation loss: 3.7554021283573045

Epoch: 6| Step: 4
Training loss: 4.454553635966585
Validation loss: 3.7508549881175615

Epoch: 6| Step: 5
Training loss: 3.4970684035529556
Validation loss: 3.746524132385146

Epoch: 6| Step: 6
Training loss: 3.9152364892772153
Validation loss: 3.7411189348855114

Epoch: 6| Step: 7
Training loss: 3.1884536812444693
Validation loss: 3.7358393225592423

Epoch: 6| Step: 8
Training loss: 3.8458282310862533
Validation loss: 3.729891097530388

Epoch: 6| Step: 9
Training loss: 3.535244733008682
Validation loss: 3.7250891117983502

Epoch: 6| Step: 10
Training loss: 3.5745645324542243
Validation loss: 3.720345184383401

Epoch: 6| Step: 11
Training loss: 3.908462508180991
Validation loss: 3.715901499332086

Epoch: 6| Step: 12
Training loss: 4.090241071316503
Validation loss: 3.7107511988939894

Epoch: 6| Step: 13
Training loss: 4.235456828189497
Validation loss: 3.707040597135432

Epoch: 32| Step: 0
Training loss: 4.471026500974033
Validation loss: 3.7017400219957297

Epoch: 6| Step: 1
Training loss: 4.02608733091658
Validation loss: 3.6959889863333153

Epoch: 6| Step: 2
Training loss: 3.8215083023534118
Validation loss: 3.690067905776414

Epoch: 6| Step: 3
Training loss: 3.6702186257418217
Validation loss: 3.685860069833982

Epoch: 6| Step: 4
Training loss: 3.8795703884090833
Validation loss: 3.6811461584603657

Epoch: 6| Step: 5
Training loss: 3.6154647910348126
Validation loss: 3.676922471343417

Epoch: 6| Step: 6
Training loss: 3.264075390693041
Validation loss: 3.6713768370861883

Epoch: 6| Step: 7
Training loss: 3.848609891337796
Validation loss: 3.6665476577403324

Epoch: 6| Step: 8
Training loss: 3.433552087524542
Validation loss: 3.662228405183626

Epoch: 6| Step: 9
Training loss: 3.832845587729493
Validation loss: 3.6564720934065447

Epoch: 6| Step: 10
Training loss: 3.1172333907571264
Validation loss: 3.653023972975734

Epoch: 6| Step: 11
Training loss: 3.5298915714545096
Validation loss: 3.647706802027674

Epoch: 6| Step: 12
Training loss: 4.069070520389435
Validation loss: 3.643327160440598

Epoch: 6| Step: 13
Training loss: 4.45229762907383
Validation loss: 3.6386321893733453

Epoch: 33| Step: 0
Training loss: 3.7466397807377274
Validation loss: 3.6332665381868336

Epoch: 6| Step: 1
Training loss: 3.905850321349768
Validation loss: 3.629421387823719

Epoch: 6| Step: 2
Training loss: 3.662162499614672
Validation loss: 3.6237588928260918

Epoch: 6| Step: 3
Training loss: 3.3857572570060515
Validation loss: 3.6192684243659388

Epoch: 6| Step: 4
Training loss: 4.091038162430163
Validation loss: 3.6148737736671115

Epoch: 6| Step: 5
Training loss: 3.499296117575854
Validation loss: 3.6109874475937587

Epoch: 6| Step: 6
Training loss: 3.6874397402220085
Validation loss: 3.606442624065362

Epoch: 6| Step: 7
Training loss: 3.999912261000624
Validation loss: 3.6010314594036226

Epoch: 6| Step: 8
Training loss: 3.783503719867921
Validation loss: 3.594893851200863

Epoch: 6| Step: 9
Training loss: 3.557459025358135
Validation loss: 3.591581945607585

Epoch: 6| Step: 10
Training loss: 3.550637958854149
Validation loss: 3.5866949739958116

Epoch: 6| Step: 11
Training loss: 4.053770340107702
Validation loss: 3.5827589387878658

Epoch: 6| Step: 12
Training loss: 3.757870235515087
Validation loss: 3.577809615582588

Epoch: 6| Step: 13
Training loss: 3.609105880414494
Validation loss: 3.573812693058994

Epoch: 34| Step: 0
Training loss: 3.869690241282442
Validation loss: 3.5685849117613504

Epoch: 6| Step: 1
Training loss: 4.072808904108412
Validation loss: 3.5641021918071614

Epoch: 6| Step: 2
Training loss: 3.7461599397828165
Validation loss: 3.5594700649606867

Epoch: 6| Step: 3
Training loss: 3.5573928096275433
Validation loss: 3.5550582748265205

Epoch: 6| Step: 4
Training loss: 3.463745906611281
Validation loss: 3.549608989010436

Epoch: 6| Step: 5
Training loss: 3.4035939351536983
Validation loss: 3.544886385877508

Epoch: 6| Step: 6
Training loss: 3.6300723662926453
Validation loss: 3.5405081181707185

Epoch: 6| Step: 7
Training loss: 3.772653944591861
Validation loss: 3.5370663591644838

Epoch: 6| Step: 8
Training loss: 3.0682474816485352
Validation loss: 3.532458455857681

Epoch: 6| Step: 9
Training loss: 3.6153371209991083
Validation loss: 3.5269512917140684

Epoch: 6| Step: 10
Training loss: 3.6416765912675086
Validation loss: 3.5235275178111465

Epoch: 6| Step: 11
Training loss: 2.950140196491529
Validation loss: 3.51918116672596

Epoch: 6| Step: 12
Training loss: 4.510268892447294
Validation loss: 3.515267835770723

Epoch: 6| Step: 13
Training loss: 3.9042673190946076
Validation loss: 3.5104516288910426

Epoch: 35| Step: 0
Training loss: 4.110023360360021
Validation loss: 3.5052020605219147

Epoch: 6| Step: 1
Training loss: 3.519394409364627
Validation loss: 3.5009267352117255

Epoch: 6| Step: 2
Training loss: 3.9493474590333086
Validation loss: 3.497816210620713

Epoch: 6| Step: 3
Training loss: 4.197538499229596
Validation loss: 3.4917543784135687

Epoch: 6| Step: 4
Training loss: 3.818581280516449
Validation loss: 3.48751238202047

Epoch: 6| Step: 5
Training loss: 3.2798328063965454
Validation loss: 3.4834589873165913

Epoch: 6| Step: 6
Training loss: 3.524841976005527
Validation loss: 3.478300698758912

Epoch: 6| Step: 7
Training loss: 3.8132017146473323
Validation loss: 3.4739197019214405

Epoch: 6| Step: 8
Training loss: 3.7866019213429043
Validation loss: 3.4694486149366726

Epoch: 6| Step: 9
Training loss: 3.0259264575520786
Validation loss: 3.4647100939627133

Epoch: 6| Step: 10
Training loss: 3.2803878378105047
Validation loss: 3.4602088591761473

Epoch: 6| Step: 11
Training loss: 3.621227405966134
Validation loss: 3.4566109669414913

Epoch: 6| Step: 12
Training loss: 3.6929402711212833
Validation loss: 3.4526915472373694

Epoch: 6| Step: 13
Training loss: 2.7122295719474128
Validation loss: 3.4482108199080113

Epoch: 36| Step: 0
Training loss: 3.4679289524848143
Validation loss: 3.443427852787082

Epoch: 6| Step: 1
Training loss: 3.5726142658942477
Validation loss: 3.439280239701282

Epoch: 6| Step: 2
Training loss: 3.716709506781542
Validation loss: 3.4359304601791774

Epoch: 6| Step: 3
Training loss: 4.086287124292443
Validation loss: 3.431666308071519

Epoch: 6| Step: 4
Training loss: 2.8091166172719837
Validation loss: 3.428004310173432

Epoch: 6| Step: 5
Training loss: 3.8697809327885007
Validation loss: 3.4238365276238643

Epoch: 6| Step: 6
Training loss: 3.596264299636749
Validation loss: 3.419770404998625

Epoch: 6| Step: 7
Training loss: 3.1593087360138017
Validation loss: 3.4156991627730986

Epoch: 6| Step: 8
Training loss: 2.722555632079772
Validation loss: 3.4113695361202065

Epoch: 6| Step: 9
Training loss: 4.129372562288212
Validation loss: 3.407123115465601

Epoch: 6| Step: 10
Training loss: 4.033131241792832
Validation loss: 3.403563276874027

Epoch: 6| Step: 11
Training loss: 3.806349749581309
Validation loss: 3.3993422316089172

Epoch: 6| Step: 12
Training loss: 2.9634274604303075
Validation loss: 3.3946083332260426

Epoch: 6| Step: 13
Training loss: 3.4725722140774007
Validation loss: 3.3919117678871884

Epoch: 37| Step: 0
Training loss: 4.04900407201817
Validation loss: 3.3883311398097673

Epoch: 6| Step: 1
Training loss: 3.4535395170640295
Validation loss: 3.384644902610219

Epoch: 6| Step: 2
Training loss: 2.8129312820367542
Validation loss: 3.3801507851865016

Epoch: 6| Step: 3
Training loss: 3.500658926926252
Validation loss: 3.376244256754885

Epoch: 6| Step: 4
Training loss: 3.0225585921724054
Validation loss: 3.3729913644763987

Epoch: 6| Step: 5
Training loss: 3.192260179705226
Validation loss: 3.3690035024556613

Epoch: 6| Step: 6
Training loss: 3.7613870032762553
Validation loss: 3.3654564274821874

Epoch: 6| Step: 7
Training loss: 3.335092191780212
Validation loss: 3.3624408187290618

Epoch: 6| Step: 8
Training loss: 2.744563885284902
Validation loss: 3.356999371988122

Epoch: 6| Step: 9
Training loss: 3.9942715872860335
Validation loss: 3.3539535423159443

Epoch: 6| Step: 10
Training loss: 4.185777224398121
Validation loss: 3.349980749482978

Epoch: 6| Step: 11
Training loss: 3.620532209358716
Validation loss: 3.3462135770285815

Epoch: 6| Step: 12
Training loss: 3.34109448665769
Validation loss: 3.3428454735427646

Epoch: 6| Step: 13
Training loss: 3.6575916143743417
Validation loss: 3.3387688823791075

Epoch: 38| Step: 0
Training loss: 2.9781089630175503
Validation loss: 3.334987436601651

Epoch: 6| Step: 1
Training loss: 2.632520348161413
Validation loss: 3.330936682914817

Epoch: 6| Step: 2
Training loss: 3.236673616374995
Validation loss: 3.3272155330973807

Epoch: 6| Step: 3
Training loss: 2.6974043095739026
Validation loss: 3.3239864592446615

Epoch: 6| Step: 4
Training loss: 3.5386484337571504
Validation loss: 3.32237023112831

Epoch: 6| Step: 5
Training loss: 3.9341063634227207
Validation loss: 3.318142841018344

Epoch: 6| Step: 6
Training loss: 3.738881221446589
Validation loss: 3.313216749656482

Epoch: 6| Step: 7
Training loss: 3.8681135205609953
Validation loss: 3.310243413739566

Epoch: 6| Step: 8
Training loss: 2.9181780759192675
Validation loss: 3.3064827037277946

Epoch: 6| Step: 9
Training loss: 2.5850186746833983
Validation loss: 3.3033495299490436

Epoch: 6| Step: 10
Training loss: 4.049682585911007
Validation loss: 3.3004103834081735

Epoch: 6| Step: 11
Training loss: 3.6243622317469955
Validation loss: 3.2959581519474788

Epoch: 6| Step: 12
Training loss: 4.133474718772624
Validation loss: 3.29230130190084

Epoch: 6| Step: 13
Training loss: 3.7679913315480946
Validation loss: 3.287820468266032

Epoch: 39| Step: 0
Training loss: 3.506939411894122
Validation loss: 3.283033195241798

Epoch: 6| Step: 1
Training loss: 3.4816481521817826
Validation loss: 3.2803536538070106

Epoch: 6| Step: 2
Training loss: 3.7480891127440277
Validation loss: 3.2764350319369715

Epoch: 6| Step: 3
Training loss: 3.5339350661835813
Validation loss: 3.2729678063593046

Epoch: 6| Step: 4
Training loss: 3.236023119019865
Validation loss: 3.267552149384948

Epoch: 6| Step: 5
Training loss: 2.8881361685798814
Validation loss: 3.263049203435264

Epoch: 6| Step: 6
Training loss: 3.9422629477303834
Validation loss: 3.2599221403969443

Epoch: 6| Step: 7
Training loss: 3.295424589780308
Validation loss: 3.2561699670095186

Epoch: 6| Step: 8
Training loss: 3.4211723268087035
Validation loss: 3.2532439303881753

Epoch: 6| Step: 9
Training loss: 3.2436824431394564
Validation loss: 3.2500463995922524

Epoch: 6| Step: 10
Training loss: 3.229952825195861
Validation loss: 3.245720197267189

Epoch: 6| Step: 11
Training loss: 2.7918116593546554
Validation loss: 3.2419693593862515

Epoch: 6| Step: 12
Training loss: 3.3371328316218807
Validation loss: 3.238049592803689

Epoch: 6| Step: 13
Training loss: 3.754309276337662
Validation loss: 3.234947976976933

Epoch: 40| Step: 0
Training loss: 3.4769777885739117
Validation loss: 3.230701614960195

Epoch: 6| Step: 1
Training loss: 2.7550352122692563
Validation loss: 3.2270490696670135

Epoch: 6| Step: 2
Training loss: 3.542062325909848
Validation loss: 3.2239646028243047

Epoch: 6| Step: 3
Training loss: 3.942378337291552
Validation loss: 3.2205492194551013

Epoch: 6| Step: 4
Training loss: 3.286979686334253
Validation loss: 3.2163714413399767

Epoch: 6| Step: 5
Training loss: 3.4704723034528318
Validation loss: 3.213283625319815

Epoch: 6| Step: 6
Training loss: 3.5530617150514505
Validation loss: 3.2099291230534126

Epoch: 6| Step: 7
Training loss: 3.430507692182463
Validation loss: 3.206406030954341

Epoch: 6| Step: 8
Training loss: 2.826300438182416
Validation loss: 3.2031367728164306

Epoch: 6| Step: 9
Training loss: 3.2409984936214857
Validation loss: 3.199458807639794

Epoch: 6| Step: 10
Training loss: 2.9488195288054433
Validation loss: 3.1957805760159905

Epoch: 6| Step: 11
Training loss: 3.7130330483352534
Validation loss: 3.1931041246101284

Epoch: 6| Step: 12
Training loss: 3.400783246646841
Validation loss: 3.189867150461215

Epoch: 6| Step: 13
Training loss: 3.0807301297459047
Validation loss: 3.186653087027065

Epoch: 41| Step: 0
Training loss: 3.192412237695148
Validation loss: 3.183123220296797

Epoch: 6| Step: 1
Training loss: 3.4788300737821296
Validation loss: 3.180097074006672

Epoch: 6| Step: 2
Training loss: 3.6892184116711864
Validation loss: 3.1767084035970266

Epoch: 6| Step: 3
Training loss: 3.2930832884791785
Validation loss: 3.1721207847640867

Epoch: 6| Step: 4
Training loss: 3.0359064890818392
Validation loss: 3.1690984139393126

Epoch: 6| Step: 5
Training loss: 3.656395803299438
Validation loss: 3.1674732678416166

Epoch: 6| Step: 6
Training loss: 2.9479025221486435
Validation loss: 3.1640352475597835

Epoch: 6| Step: 7
Training loss: 2.853026633431475
Validation loss: 3.160287006378074

Epoch: 6| Step: 8
Training loss: 3.7028419611802956
Validation loss: 3.1580558369769385

Epoch: 6| Step: 9
Training loss: 3.5444659820056414
Validation loss: 3.155594937171313

Epoch: 6| Step: 10
Training loss: 3.2634173510304865
Validation loss: 3.1518998966094824

Epoch: 6| Step: 11
Training loss: 2.613559953228522
Validation loss: 3.1481507883081608

Epoch: 6| Step: 12
Training loss: 3.3013830234545205
Validation loss: 3.144301734272441

Epoch: 6| Step: 13
Training loss: 3.4571308358714177
Validation loss: 3.1407157416701645

Epoch: 42| Step: 0
Training loss: 2.3113385969875373
Validation loss: 3.13780931364025

Epoch: 6| Step: 1
Training loss: 3.6326026117543213
Validation loss: 3.135992717526051

Epoch: 6| Step: 2
Training loss: 3.324966579642163
Validation loss: 3.136167497600078

Epoch: 6| Step: 3
Training loss: 3.692118968480971
Validation loss: 3.1292422682107466

Epoch: 6| Step: 4
Training loss: 3.2221811025195466
Validation loss: 3.1254337264114405

Epoch: 6| Step: 5
Training loss: 3.008406939535071
Validation loss: 3.1225531344630735

Epoch: 6| Step: 6
Training loss: 3.763458008324249
Validation loss: 3.1203400263163545

Epoch: 6| Step: 7
Training loss: 3.1345204099963353
Validation loss: 3.120139678412353

Epoch: 6| Step: 8
Training loss: 2.407417113401404
Validation loss: 3.1184954277520043

Epoch: 6| Step: 9
Training loss: 3.447450696607856
Validation loss: 3.1155616899216225

Epoch: 6| Step: 10
Training loss: 3.75661063851178
Validation loss: 3.1111193162000026

Epoch: 6| Step: 11
Training loss: 2.6733026984434223
Validation loss: 3.104354152948649

Epoch: 6| Step: 12
Training loss: 3.767219933805708
Validation loss: 3.100012416712187

Epoch: 6| Step: 13
Training loss: 3.0178827718386523
Validation loss: 3.0976449229420964

Epoch: 43| Step: 0
Training loss: 2.525071692629237
Validation loss: 3.095498307088115

Epoch: 6| Step: 1
Training loss: 2.9927358100037837
Validation loss: 3.0947382083993493

Epoch: 6| Step: 2
Training loss: 3.5095963392152947
Validation loss: 3.088218444756883

Epoch: 6| Step: 3
Training loss: 3.768967786983764
Validation loss: 3.085669899456002

Epoch: 6| Step: 4
Training loss: 3.4107954861569567
Validation loss: 3.083114285463648

Epoch: 6| Step: 5
Training loss: 3.235243823430608
Validation loss: 3.0815907700639733

Epoch: 6| Step: 6
Training loss: 3.4543072502017518
Validation loss: 3.0777985323846155

Epoch: 6| Step: 7
Training loss: 2.78459395073303
Validation loss: 3.075904096624647

Epoch: 6| Step: 8
Training loss: 3.215998686643114
Validation loss: 3.0724320024084877

Epoch: 6| Step: 9
Training loss: 3.3579875121165594
Validation loss: 3.0707850072432024

Epoch: 6| Step: 10
Training loss: 3.1361905956153824
Validation loss: 3.0665521866397465

Epoch: 6| Step: 11
Training loss: 3.4997403184740623
Validation loss: 3.0638834235529853

Epoch: 6| Step: 12
Training loss: 2.9268324304385276
Validation loss: 3.0604125713392833

Epoch: 6| Step: 13
Training loss: 3.0602231027888758
Validation loss: 3.058355654254781

Epoch: 44| Step: 0
Training loss: 3.302786350123263
Validation loss: 3.053212283607074

Epoch: 6| Step: 1
Training loss: 2.7947369293718025
Validation loss: 3.0515892531574367

Epoch: 6| Step: 2
Training loss: 3.9648619101723885
Validation loss: 3.049590245848124

Epoch: 6| Step: 3
Training loss: 2.114979060184358
Validation loss: 3.0459530209788084

Epoch: 6| Step: 4
Training loss: 3.032369505235828
Validation loss: 3.0429760496601244

Epoch: 6| Step: 5
Training loss: 2.503227820409885
Validation loss: 3.0393260851310133

Epoch: 6| Step: 6
Training loss: 3.5669543878127077
Validation loss: 3.036727923840732

Epoch: 6| Step: 7
Training loss: 3.5529873649357473
Validation loss: 3.0332388236095835

Epoch: 6| Step: 8
Training loss: 3.651802161549775
Validation loss: 3.0321368594781335

Epoch: 6| Step: 9
Training loss: 3.28993514347791
Validation loss: 3.0325912968792004

Epoch: 6| Step: 10
Training loss: 3.244381082110582
Validation loss: 3.034567757484081

Epoch: 6| Step: 11
Training loss: 3.017264597385315
Validation loss: 3.031601429915973

Epoch: 6| Step: 12
Training loss: 3.0171956927970074
Validation loss: 3.0259051836567776

Epoch: 6| Step: 13
Training loss: 3.0423719729315954
Validation loss: 3.021096492135075

Epoch: 45| Step: 0
Training loss: 3.2527984895018727
Validation loss: 3.019176914732223

Epoch: 6| Step: 1
Training loss: 3.2223324884716296
Validation loss: 3.016768968192854

Epoch: 6| Step: 2
Training loss: 3.5539830442506055
Validation loss: 3.012511271538759

Epoch: 6| Step: 3
Training loss: 2.3441129276296544
Validation loss: 3.010140209417625

Epoch: 6| Step: 4
Training loss: 3.8278295286162476
Validation loss: 3.0065035395201476

Epoch: 6| Step: 5
Training loss: 2.95472746468502
Validation loss: 3.0035081061324798

Epoch: 6| Step: 6
Training loss: 3.1939766103596336
Validation loss: 3.0008438036297322

Epoch: 6| Step: 7
Training loss: 2.879489710157993
Validation loss: 2.9990477507655435

Epoch: 6| Step: 8
Training loss: 3.0430729545801185
Validation loss: 2.9968675047800946

Epoch: 6| Step: 9
Training loss: 3.41726290144757
Validation loss: 2.99335176212299

Epoch: 6| Step: 10
Training loss: 2.6488465299924653
Validation loss: 2.990054566375581

Epoch: 6| Step: 11
Training loss: 3.240307807665119
Validation loss: 2.9868464730057833

Epoch: 6| Step: 12
Training loss: 3.362492308200136
Validation loss: 2.9844979998155323

Epoch: 6| Step: 13
Training loss: 2.7498751525282357
Validation loss: 2.9816781153138363

Epoch: 46| Step: 0
Training loss: 3.099898268968532
Validation loss: 2.9785043384775913

Epoch: 6| Step: 1
Training loss: 3.7311451243832616
Validation loss: 2.976229938608761

Epoch: 6| Step: 2
Training loss: 3.109106311019721
Validation loss: 2.9742309570061995

Epoch: 6| Step: 3
Training loss: 2.8079977663254074
Validation loss: 2.9719699864495697

Epoch: 6| Step: 4
Training loss: 2.7994101345806794
Validation loss: 2.967185829755391

Epoch: 6| Step: 5
Training loss: 2.8844378265118156
Validation loss: 2.9671226993908695

Epoch: 6| Step: 6
Training loss: 3.6252163789559497
Validation loss: 2.9666001951793106

Epoch: 6| Step: 7
Training loss: 3.1079185563638445
Validation loss: 2.963516105626541

Epoch: 6| Step: 8
Training loss: 3.5149155642703844
Validation loss: 2.961558925133684

Epoch: 6| Step: 9
Training loss: 2.563230270906595
Validation loss: 2.955749905999422

Epoch: 6| Step: 10
Training loss: 2.6826012787626663
Validation loss: 2.95587487666839

Epoch: 6| Step: 11
Training loss: 2.9536663548220727
Validation loss: 2.9537517010456127

Epoch: 6| Step: 12
Training loss: 3.4447739368340433
Validation loss: 2.95271912061251

Epoch: 6| Step: 13
Training loss: 2.922357040054426
Validation loss: 2.948991927630756

Epoch: 47| Step: 0
Training loss: 2.8479285090399546
Validation loss: 2.9456820740955303

Epoch: 6| Step: 1
Training loss: 3.249865015601249
Validation loss: 2.942449944328872

Epoch: 6| Step: 2
Training loss: 3.498031471342062
Validation loss: 2.9408822979791314

Epoch: 6| Step: 3
Training loss: 3.135267708282675
Validation loss: 2.9382774460516123

Epoch: 6| Step: 4
Training loss: 2.7522971355855623
Validation loss: 2.9352139580077723

Epoch: 6| Step: 5
Training loss: 3.5476318089714955
Validation loss: 2.930390838967737

Epoch: 6| Step: 6
Training loss: 2.9837016199773836
Validation loss: 2.9275723565832488

Epoch: 6| Step: 7
Training loss: 2.987102121329626
Validation loss: 2.928158930117464

Epoch: 6| Step: 8
Training loss: 3.079011276378097
Validation loss: 2.9255132208619794

Epoch: 6| Step: 9
Training loss: 3.1156350766002734
Validation loss: 2.921460304138989

Epoch: 6| Step: 10
Training loss: 3.215530118293155
Validation loss: 2.9193106973848817

Epoch: 6| Step: 11
Training loss: 2.7840508063547444
Validation loss: 2.9163675608990864

Epoch: 6| Step: 12
Training loss: 2.6378641537039007
Validation loss: 2.9146402994678056

Epoch: 6| Step: 13
Training loss: 3.0093253158318305
Validation loss: 2.918255799935819

Epoch: 48| Step: 0
Training loss: 2.9929346491405187
Validation loss: 2.9479342663422683

Epoch: 6| Step: 1
Training loss: 2.470104377178275
Validation loss: 2.9094878451066193

Epoch: 6| Step: 2
Training loss: 2.836104290894135
Validation loss: 2.9076462129809864

Epoch: 6| Step: 3
Training loss: 3.5587840191655857
Validation loss: 2.9281660545942394

Epoch: 6| Step: 4
Training loss: 3.752070935935057
Validation loss: 2.952320722692211

Epoch: 6| Step: 5
Training loss: 3.3496811216805935
Validation loss: 2.947830526937848

Epoch: 6| Step: 6
Training loss: 3.186008777728444
Validation loss: 2.9367469606958325

Epoch: 6| Step: 7
Training loss: 2.808243646142306
Validation loss: 2.907043089035628

Epoch: 6| Step: 8
Training loss: 3.1757323013793863
Validation loss: 2.8990183999603936

Epoch: 6| Step: 9
Training loss: 3.2846606739201922
Validation loss: 2.896637706509396

Epoch: 6| Step: 10
Training loss: 2.6467015701638084
Validation loss: 2.894381280292421

Epoch: 6| Step: 11
Training loss: 2.8642181903584056
Validation loss: 2.897976011705685

Epoch: 6| Step: 12
Training loss: 2.9736255965121807
Validation loss: 2.9017131491729873

Epoch: 6| Step: 13
Training loss: 2.7091734145694626
Validation loss: 2.905054044587376

Epoch: 49| Step: 0
Training loss: 2.7933914398243553
Validation loss: 2.894235888472632

Epoch: 6| Step: 1
Training loss: 2.749122479621267
Validation loss: 2.8850512680619924

Epoch: 6| Step: 2
Training loss: 3.395650347750735
Validation loss: 2.8811139320797476

Epoch: 6| Step: 3
Training loss: 2.984278173024301
Validation loss: 2.8806543999289884

Epoch: 6| Step: 4
Training loss: 2.8270624177328174
Validation loss: 2.881687830539675

Epoch: 6| Step: 5
Training loss: 3.194175611231822
Validation loss: 2.8839538024221554

Epoch: 6| Step: 6
Training loss: 2.793382990068731
Validation loss: 2.877302643641733

Epoch: 6| Step: 7
Training loss: 3.174216322413236
Validation loss: 2.8748143730498885

Epoch: 6| Step: 8
Training loss: 2.6486974717998923
Validation loss: 2.87139229465751

Epoch: 6| Step: 9
Training loss: 3.2252793242858093
Validation loss: 2.8688569159104618

Epoch: 6| Step: 10
Training loss: 3.173186233167119
Validation loss: 2.8666880603110276

Epoch: 6| Step: 11
Training loss: 3.056246542587353
Validation loss: 2.863204046009129

Epoch: 6| Step: 12
Training loss: 3.2031851413942385
Validation loss: 2.860343032707849

Epoch: 6| Step: 13
Training loss: 2.970241292534407
Validation loss: 2.8595697027458984

Epoch: 50| Step: 0
Training loss: 2.769033024016153
Validation loss: 2.8570940268975984

Epoch: 6| Step: 1
Training loss: 3.7571400379748443
Validation loss: 2.8559954740611313

Epoch: 6| Step: 2
Training loss: 3.0106241931245026
Validation loss: 2.8541906638888515

Epoch: 6| Step: 3
Training loss: 2.979138318618315
Validation loss: 2.8532352923397974

Epoch: 6| Step: 4
Training loss: 3.49944628013892
Validation loss: 2.8494264170475816

Epoch: 6| Step: 5
Training loss: 2.3262800036201403
Validation loss: 2.848488252250057

Epoch: 6| Step: 6
Training loss: 2.976586529492081
Validation loss: 2.847061450936872

Epoch: 6| Step: 7
Training loss: 3.167622840143293
Validation loss: 2.843500231159778

Epoch: 6| Step: 8
Training loss: 2.8821193616452647
Validation loss: 2.839812210796393

Epoch: 6| Step: 9
Training loss: 2.7465826822915895
Validation loss: 2.8372145510592373

Epoch: 6| Step: 10
Training loss: 3.0624165426287795
Validation loss: 2.8356546168062526

Epoch: 6| Step: 11
Training loss: 2.630420356488874
Validation loss: 2.830619407474774

Epoch: 6| Step: 12
Training loss: 2.6093678731307053
Validation loss: 2.8282073765905893

Epoch: 6| Step: 13
Training loss: 3.1082006949453236
Validation loss: 2.8276902315976913

Epoch: 51| Step: 0
Training loss: 2.923557062522835
Validation loss: 2.82689471382792

Epoch: 6| Step: 1
Training loss: 2.7997858680861665
Validation loss: 2.823405041742927

Epoch: 6| Step: 2
Training loss: 3.2619134719196667
Validation loss: 2.820658908186271

Epoch: 6| Step: 3
Training loss: 3.295953992587342
Validation loss: 2.820544345163799

Epoch: 6| Step: 4
Training loss: 2.7728630223137847
Validation loss: 2.817556399458155

Epoch: 6| Step: 5
Training loss: 3.1294918583832443
Validation loss: 2.814197367179788

Epoch: 6| Step: 6
Training loss: 2.952110802615303
Validation loss: 2.8122076518386647

Epoch: 6| Step: 7
Training loss: 2.7409094633495825
Validation loss: 2.8111490042481724

Epoch: 6| Step: 8
Training loss: 2.9372217574132327
Validation loss: 2.8097131414597225

Epoch: 6| Step: 9
Training loss: 2.5635133925925695
Validation loss: 2.8098488073977523

Epoch: 6| Step: 10
Training loss: 2.7668455200141397
Validation loss: 2.806642083274057

Epoch: 6| Step: 11
Training loss: 3.0925879559849108
Validation loss: 2.8081139166566764

Epoch: 6| Step: 12
Training loss: 2.986377942684538
Validation loss: 2.8049480065770243

Epoch: 6| Step: 13
Training loss: 3.081933468426694
Validation loss: 2.800793933706679

Epoch: 52| Step: 0
Training loss: 2.861385618289708
Validation loss: 2.7989840236706223

Epoch: 6| Step: 1
Training loss: 3.1493094398804504
Validation loss: 2.797158154125664

Epoch: 6| Step: 2
Training loss: 2.8885031670857915
Validation loss: 2.794253813498297

Epoch: 6| Step: 3
Training loss: 2.883350022401819
Validation loss: 2.7931899758958223

Epoch: 6| Step: 4
Training loss: 3.098015205203151
Validation loss: 2.7888338224978657

Epoch: 6| Step: 5
Training loss: 2.9630690981699677
Validation loss: 2.789318219027984

Epoch: 6| Step: 6
Training loss: 3.393566631049126
Validation loss: 2.788248123110396

Epoch: 6| Step: 7
Training loss: 2.737219763917436
Validation loss: 2.784487008561611

Epoch: 6| Step: 8
Training loss: 3.184524044483348
Validation loss: 2.782326250755162

Epoch: 6| Step: 9
Training loss: 2.6184645540447122
Validation loss: 2.793433787793674

Epoch: 6| Step: 10
Training loss: 3.1465613594322095
Validation loss: 2.793723335679354

Epoch: 6| Step: 11
Training loss: 3.053580705569651
Validation loss: 2.7820926632700202

Epoch: 6| Step: 12
Training loss: 2.8683377902675877
Validation loss: 2.7776093103397073

Epoch: 6| Step: 13
Training loss: 1.9062244225959197
Validation loss: 2.7728314951009545

Epoch: 53| Step: 0
Training loss: 2.981244907334814
Validation loss: 2.7760830721650973

Epoch: 6| Step: 1
Training loss: 2.7221157243445093
Validation loss: 2.7761434473174873

Epoch: 6| Step: 2
Training loss: 2.4551336726760944
Validation loss: 2.7781954075202004

Epoch: 6| Step: 3
Training loss: 2.427477355757129
Validation loss: 2.778520537783715

Epoch: 6| Step: 4
Training loss: 2.852830913048445
Validation loss: 2.7759637493676212

Epoch: 6| Step: 5
Training loss: 3.019886543719561
Validation loss: 2.7716610946033446

Epoch: 6| Step: 6
Training loss: 3.4632243916985597
Validation loss: 2.768604562927989

Epoch: 6| Step: 7
Training loss: 3.160608586967809
Validation loss: 2.771387064011513

Epoch: 6| Step: 8
Training loss: 3.194549693341003
Validation loss: 2.772069315960667

Epoch: 6| Step: 9
Training loss: 2.5990386726229278
Validation loss: 2.761678217869668

Epoch: 6| Step: 10
Training loss: 3.2175582605406143
Validation loss: 2.7616067204466197

Epoch: 6| Step: 11
Training loss: 2.561780130640438
Validation loss: 2.756104153604237

Epoch: 6| Step: 12
Training loss: 3.218491034599121
Validation loss: 2.7543320058420635

Epoch: 6| Step: 13
Training loss: 2.6117176801044306
Validation loss: 2.750468445384751

Epoch: 54| Step: 0
Training loss: 3.347090861450021
Validation loss: 2.7516529288623865

Epoch: 6| Step: 1
Training loss: 2.3487047846625653
Validation loss: 2.750537068490586

Epoch: 6| Step: 2
Training loss: 2.846159532505628
Validation loss: 2.746979948027342

Epoch: 6| Step: 3
Training loss: 2.8551551239574273
Validation loss: 2.7462213738902443

Epoch: 6| Step: 4
Training loss: 1.983924033517983
Validation loss: 2.745333802009025

Epoch: 6| Step: 5
Training loss: 3.4734168748333323
Validation loss: 2.744265704398443

Epoch: 6| Step: 6
Training loss: 3.0620688310059054
Validation loss: 2.7421621700033523

Epoch: 6| Step: 7
Training loss: 2.7643693562777107
Validation loss: 2.741460343301292

Epoch: 6| Step: 8
Training loss: 2.6254152242049837
Validation loss: 2.7421656043472726

Epoch: 6| Step: 9
Training loss: 2.9427001052786426
Validation loss: 2.740049972728178

Epoch: 6| Step: 10
Training loss: 3.488747355215122
Validation loss: 2.738383031414616

Epoch: 6| Step: 11
Training loss: 2.7887928722852973
Validation loss: 2.743177157468448

Epoch: 6| Step: 12
Training loss: 3.0022674574676778
Validation loss: 2.7389221167037254

Epoch: 6| Step: 13
Training loss: 2.418713481144393
Validation loss: 2.7343009284749744

Epoch: 55| Step: 0
Training loss: 2.2978050788169164
Validation loss: 2.759186961418993

Epoch: 6| Step: 1
Training loss: 2.6839387941161257
Validation loss: 2.744341635440776

Epoch: 6| Step: 2
Training loss: 2.7186985230231273
Validation loss: 2.7407742995015676

Epoch: 6| Step: 3
Training loss: 3.1340886511031614
Validation loss: 2.7289736196562218

Epoch: 6| Step: 4
Training loss: 2.9123877245828345
Validation loss: 2.7298357679644734

Epoch: 6| Step: 5
Training loss: 3.016827911648017
Validation loss: 2.726488449417329

Epoch: 6| Step: 6
Training loss: 3.2730663152841935
Validation loss: 2.7220155097908223

Epoch: 6| Step: 7
Training loss: 2.994759432854156
Validation loss: 2.7209933441764855

Epoch: 6| Step: 8
Training loss: 2.8112240758152596
Validation loss: 2.7219116710669984

Epoch: 6| Step: 9
Training loss: 2.181070743398187
Validation loss: 2.7222348675682833

Epoch: 6| Step: 10
Training loss: 2.8614087819263356
Validation loss: 2.7254488035880278

Epoch: 6| Step: 11
Training loss: 3.0227516835622663
Validation loss: 2.7232536926515314

Epoch: 6| Step: 12
Training loss: 3.1060788880773718
Validation loss: 2.723641814204117

Epoch: 6| Step: 13
Training loss: 2.8236854229044694
Validation loss: 2.72833750895944

Epoch: 56| Step: 0
Training loss: 3.232893747421449
Validation loss: 2.7235820843502188

Epoch: 6| Step: 1
Training loss: 2.919601780113747
Validation loss: 2.720614469954606

Epoch: 6| Step: 2
Training loss: 2.9908708907779245
Validation loss: 2.7166083659213642

Epoch: 6| Step: 3
Training loss: 2.8614359448009195
Validation loss: 2.7127950499076308

Epoch: 6| Step: 4
Training loss: 2.613198956161751
Validation loss: 2.70898248277748

Epoch: 6| Step: 5
Training loss: 2.691563041117388
Validation loss: 2.7077640277437083

Epoch: 6| Step: 6
Training loss: 2.387573488712225
Validation loss: 2.7043732423646603

Epoch: 6| Step: 7
Training loss: 2.4365176642278796
Validation loss: 2.704105956263547

Epoch: 6| Step: 8
Training loss: 3.1271742314278006
Validation loss: 2.7071868719641627

Epoch: 6| Step: 9
Training loss: 2.929066665989949
Validation loss: 2.7053776213731013

Epoch: 6| Step: 10
Training loss: 2.962000834586614
Validation loss: 2.7116165410031514

Epoch: 6| Step: 11
Training loss: 2.879123218905984
Validation loss: 2.712444373994603

Epoch: 6| Step: 12
Training loss: 3.072704519071666
Validation loss: 2.6977825990649857

Epoch: 6| Step: 13
Training loss: 2.6198101510722362
Validation loss: 2.6926660048639905

Epoch: 57| Step: 0
Training loss: 3.15309272197614
Validation loss: 2.6934296744256874

Epoch: 6| Step: 1
Training loss: 2.8529922036627013
Validation loss: 2.691919300950947

Epoch: 6| Step: 2
Training loss: 2.8911110958998876
Validation loss: 2.6916390416604563

Epoch: 6| Step: 3
Training loss: 2.691624514916015
Validation loss: 2.6888932010214974

Epoch: 6| Step: 4
Training loss: 2.9012638100587544
Validation loss: 2.689890648393034

Epoch: 6| Step: 5
Training loss: 2.9530142304167697
Validation loss: 2.688669585995926

Epoch: 6| Step: 6
Training loss: 2.7915108670462674
Validation loss: 2.6881911549709145

Epoch: 6| Step: 7
Training loss: 2.4129612457034204
Validation loss: 2.6895403103350874

Epoch: 6| Step: 8
Training loss: 2.561635127306709
Validation loss: 2.685893931765039

Epoch: 6| Step: 9
Training loss: 2.9980551455504814
Validation loss: 2.684901259990626

Epoch: 6| Step: 10
Training loss: 2.4376377164621386
Validation loss: 2.68211558730062

Epoch: 6| Step: 11
Training loss: 2.6807736344864908
Validation loss: 2.6850754054661756

Epoch: 6| Step: 12
Training loss: 3.3257112301675265
Validation loss: 2.681820857137806

Epoch: 6| Step: 13
Training loss: 2.781871769015532
Validation loss: 2.678641675905941

Epoch: 58| Step: 0
Training loss: 3.0318764894537256
Validation loss: 2.678161453479708

Epoch: 6| Step: 1
Training loss: 2.903791310496426
Validation loss: 2.6765441401012082

Epoch: 6| Step: 2
Training loss: 2.5955427477613506
Validation loss: 2.672423219116074

Epoch: 6| Step: 3
Training loss: 2.967794324745517
Validation loss: 2.673475340221096

Epoch: 6| Step: 4
Training loss: 2.856395064996084
Validation loss: 2.6738090876701985

Epoch: 6| Step: 5
Training loss: 2.7667268616282796
Validation loss: 2.668685094563751

Epoch: 6| Step: 6
Training loss: 2.8963403235103926
Validation loss: 2.674954266617711

Epoch: 6| Step: 7
Training loss: 2.5707532510593136
Validation loss: 2.6778556115519736

Epoch: 6| Step: 8
Training loss: 2.549211237969701
Validation loss: 2.675119300511207

Epoch: 6| Step: 9
Training loss: 2.9186759204163057
Validation loss: 2.685350697143365

Epoch: 6| Step: 10
Training loss: 3.1381926725620386
Validation loss: 2.6845967261535733

Epoch: 6| Step: 11
Training loss: 2.7021233792206383
Validation loss: 2.6673415541969896

Epoch: 6| Step: 12
Training loss: 2.8926664824452386
Validation loss: 2.6631340877673635

Epoch: 6| Step: 13
Training loss: 2.449213882757823
Validation loss: 2.66786313534417

Epoch: 59| Step: 0
Training loss: 2.833541825047231
Validation loss: 2.681484542938699

Epoch: 6| Step: 1
Training loss: 2.8212875413742005
Validation loss: 2.701393337186165

Epoch: 6| Step: 2
Training loss: 2.845237426772935
Validation loss: 2.7113088890235657

Epoch: 6| Step: 3
Training loss: 3.5499044915904516
Validation loss: 2.714425400077118

Epoch: 6| Step: 4
Training loss: 2.624358780064236
Validation loss: 2.705523872603391

Epoch: 6| Step: 5
Training loss: 2.8021355284943033
Validation loss: 2.6958231124409027

Epoch: 6| Step: 6
Training loss: 3.5139579380842054
Validation loss: 2.6802052108048655

Epoch: 6| Step: 7
Training loss: 3.228756655022722
Validation loss: 2.670992223939915

Epoch: 6| Step: 8
Training loss: 1.75858761122457
Validation loss: 2.665684539022664

Epoch: 6| Step: 9
Training loss: 2.861304960710416
Validation loss: 2.6594373839876346

Epoch: 6| Step: 10
Training loss: 2.6680731243309923
Validation loss: 2.6551194571317516

Epoch: 6| Step: 11
Training loss: 2.3902729248888175
Validation loss: 2.654578487080661

Epoch: 6| Step: 12
Training loss: 2.50703812761989
Validation loss: 2.654131324888088

Epoch: 6| Step: 13
Training loss: 2.5632460833889494
Validation loss: 2.6536177514224746

Epoch: 60| Step: 0
Training loss: 3.4069816433541074
Validation loss: 2.658193199107417

Epoch: 6| Step: 1
Training loss: 2.973663440164521
Validation loss: 2.660469010648937

Epoch: 6| Step: 2
Training loss: 2.585605381039884
Validation loss: 2.648694696381615

Epoch: 6| Step: 3
Training loss: 2.3811800007781767
Validation loss: 2.649818922849867

Epoch: 6| Step: 4
Training loss: 2.8356543365434055
Validation loss: 2.6475000963700337

Epoch: 6| Step: 5
Training loss: 3.0341411842282615
Validation loss: 2.645876446069813

Epoch: 6| Step: 6
Training loss: 2.769399104442825
Validation loss: 2.645550034342037

Epoch: 6| Step: 7
Training loss: 2.8870216799147617
Validation loss: 2.6416183198501915

Epoch: 6| Step: 8
Training loss: 2.552918080941264
Validation loss: 2.640366370422519

Epoch: 6| Step: 9
Training loss: 2.865953559302235
Validation loss: 2.6385871201576085

Epoch: 6| Step: 10
Training loss: 2.363870443244009
Validation loss: 2.6383718926685904

Epoch: 6| Step: 11
Training loss: 2.5387346730974003
Validation loss: 2.6359519314403856

Epoch: 6| Step: 12
Training loss: 2.8903650115344157
Validation loss: 2.63530105719217

Epoch: 6| Step: 13
Training loss: 2.687309613248629
Validation loss: 2.632276380459584

Epoch: 61| Step: 0
Training loss: 2.727791495546584
Validation loss: 2.634535620858296

Epoch: 6| Step: 1
Training loss: 2.633787885700284
Validation loss: 2.6314545703657983

Epoch: 6| Step: 2
Training loss: 2.042339629247263
Validation loss: 2.6331153340784375

Epoch: 6| Step: 3
Training loss: 2.5360462289982917
Validation loss: 2.631665124109584

Epoch: 6| Step: 4
Training loss: 2.4534698049624137
Validation loss: 2.6327853932480383

Epoch: 6| Step: 5
Training loss: 3.0812374586736087
Validation loss: 2.6261881758058063

Epoch: 6| Step: 6
Training loss: 2.7993533273255267
Validation loss: 2.628708256166187

Epoch: 6| Step: 7
Training loss: 2.7917862102667264
Validation loss: 2.62620540977461

Epoch: 6| Step: 8
Training loss: 2.5770742413651595
Validation loss: 2.6294750034836447

Epoch: 6| Step: 9
Training loss: 2.915904590411576
Validation loss: 2.630250221649094

Epoch: 6| Step: 10
Training loss: 2.8848621556293503
Validation loss: 2.6284955683121702

Epoch: 6| Step: 11
Training loss: 3.300534933255834
Validation loss: 2.624961095854674

Epoch: 6| Step: 12
Training loss: 2.6037126882940815
Validation loss: 2.622949571430875

Epoch: 6| Step: 13
Training loss: 3.1743446094179535
Validation loss: 2.621931810941895

Epoch: 62| Step: 0
Training loss: 2.7931210349655093
Validation loss: 2.622537866033569

Epoch: 6| Step: 1
Training loss: 2.163963343142362
Validation loss: 2.6189406563025703

Epoch: 6| Step: 2
Training loss: 2.4388148356177433
Validation loss: 2.617212445344233

Epoch: 6| Step: 3
Training loss: 2.9041384337561174
Validation loss: 2.6184049441206896

Epoch: 6| Step: 4
Training loss: 2.414145854017063
Validation loss: 2.6170094595555824

Epoch: 6| Step: 5
Training loss: 2.7544008933543127
Validation loss: 2.613044473349653

Epoch: 6| Step: 6
Training loss: 2.7721023139512133
Validation loss: 2.613943155851229

Epoch: 6| Step: 7
Training loss: 3.1424295735263112
Validation loss: 2.609368451808853

Epoch: 6| Step: 8
Training loss: 2.585228399225041
Validation loss: 2.609783270108706

Epoch: 6| Step: 9
Training loss: 2.6874893543121274
Validation loss: 2.6098526538410067

Epoch: 6| Step: 10
Training loss: 2.9381508613426894
Validation loss: 2.606904175377965

Epoch: 6| Step: 11
Training loss: 3.2234711327695846
Validation loss: 2.6091749986458463

Epoch: 6| Step: 12
Training loss: 2.7762496230989533
Validation loss: 2.6074422199727105

Epoch: 6| Step: 13
Training loss: 2.7213700046108853
Validation loss: 2.605328122852032

Epoch: 63| Step: 0
Training loss: 2.976771550083943
Validation loss: 2.6066357059623853

Epoch: 6| Step: 1
Training loss: 2.5721867461626906
Validation loss: 2.601565226418839

Epoch: 6| Step: 2
Training loss: 2.4123838446132946
Validation loss: 2.606393553685732

Epoch: 6| Step: 3
Training loss: 2.8280464287902976
Validation loss: 2.6054557102225933

Epoch: 6| Step: 4
Training loss: 2.2723342997924902
Validation loss: 2.605660282322226

Epoch: 6| Step: 5
Training loss: 2.4087351066790115
Validation loss: 2.6053933624082686

Epoch: 6| Step: 6
Training loss: 3.1098164767365186
Validation loss: 2.6082718700768233

Epoch: 6| Step: 7
Training loss: 2.3142353454369813
Validation loss: 2.617677739474762

Epoch: 6| Step: 8
Training loss: 2.787927904343456
Validation loss: 2.638602225031257

Epoch: 6| Step: 9
Training loss: 3.106086870971965
Validation loss: 2.6397018850590985

Epoch: 6| Step: 10
Training loss: 2.658219269444912
Validation loss: 2.6364323816085995

Epoch: 6| Step: 11
Training loss: 3.3723068795077347
Validation loss: 2.679203920317962

Epoch: 6| Step: 12
Training loss: 2.8113992020300227
Validation loss: 2.6344715931817864

Epoch: 6| Step: 13
Training loss: 2.621146052331886
Validation loss: 2.6044465232520038

Epoch: 64| Step: 0
Training loss: 3.118757803683561
Validation loss: 2.5957829272018076

Epoch: 6| Step: 1
Training loss: 2.7813079485053334
Validation loss: 2.600888925899575

Epoch: 6| Step: 2
Training loss: 3.0064281894590503
Validation loss: 2.608920196674433

Epoch: 6| Step: 3
Training loss: 2.3502056478246005
Validation loss: 2.622490121964045

Epoch: 6| Step: 4
Training loss: 2.776703107426062
Validation loss: 2.6414165401474556

Epoch: 6| Step: 5
Training loss: 2.9412665061633434
Validation loss: 2.652680455719967

Epoch: 6| Step: 6
Training loss: 2.8875352997707013
Validation loss: 2.6544906474370427

Epoch: 6| Step: 7
Training loss: 3.434889200747403
Validation loss: 2.653945761150568

Epoch: 6| Step: 8
Training loss: 3.106366566364779
Validation loss: 2.6351491066030714

Epoch: 6| Step: 9
Training loss: 2.785709534805215
Validation loss: 2.625187367609667

Epoch: 6| Step: 10
Training loss: 2.1790726864487904
Validation loss: 2.6124865469213523

Epoch: 6| Step: 11
Training loss: 1.842868012072002
Validation loss: 2.6026259836612433

Epoch: 6| Step: 12
Training loss: 2.978601113014984
Validation loss: 2.598351269436393

Epoch: 6| Step: 13
Training loss: 1.985272602513235
Validation loss: 2.5935580017848516

Epoch: 65| Step: 0
Training loss: 3.141850929691652
Validation loss: 2.590630091166354

Epoch: 6| Step: 1
Training loss: 2.7278671859449597
Validation loss: 2.594611656737234

Epoch: 6| Step: 2
Training loss: 3.2173322499612356
Validation loss: 2.5955332711711456

Epoch: 6| Step: 3
Training loss: 2.735909516405469
Validation loss: 2.6026331442598387

Epoch: 6| Step: 4
Training loss: 2.3145464528256063
Validation loss: 2.5974931632261895

Epoch: 6| Step: 5
Training loss: 2.4448512803231917
Validation loss: 2.6026895428274934

Epoch: 6| Step: 6
Training loss: 3.0212853630625744
Validation loss: 2.613207638800972

Epoch: 6| Step: 7
Training loss: 2.3772179135588143
Validation loss: 2.596786452833045

Epoch: 6| Step: 8
Training loss: 2.8040525945065276
Validation loss: 2.583281813897396

Epoch: 6| Step: 9
Training loss: 2.578131658372084
Validation loss: 2.58120394181485

Epoch: 6| Step: 10
Training loss: 2.6870865614718804
Validation loss: 2.5779767851177637

Epoch: 6| Step: 11
Training loss: 2.5954168088599268
Validation loss: 2.5826364059096676

Epoch: 6| Step: 12
Training loss: 2.4887419892378078
Validation loss: 2.5822902747659957

Epoch: 6| Step: 13
Training loss: 2.946563859616212
Validation loss: 2.580620561631176

Epoch: 66| Step: 0
Training loss: 2.7150243026741636
Validation loss: 2.5808167864530076

Epoch: 6| Step: 1
Training loss: 2.8010280186519365
Validation loss: 2.5791838196002788

Epoch: 6| Step: 2
Training loss: 2.503633338469044
Validation loss: 2.5773941545432546

Epoch: 6| Step: 3
Training loss: 1.9750522075464687
Validation loss: 2.578216628170705

Epoch: 6| Step: 4
Training loss: 2.9394748623573332
Validation loss: 2.5724568335764184

Epoch: 6| Step: 5
Training loss: 2.6644173215242626
Validation loss: 2.5784081968187267

Epoch: 6| Step: 6
Training loss: 2.6689411139568606
Validation loss: 2.574955296051213

Epoch: 6| Step: 7
Training loss: 2.400966342453387
Validation loss: 2.5712336905998687

Epoch: 6| Step: 8
Training loss: 2.8151735949475554
Validation loss: 2.5726460972243976

Epoch: 6| Step: 9
Training loss: 2.4276654332653793
Validation loss: 2.5730696309652195

Epoch: 6| Step: 10
Training loss: 2.5996238656503534
Validation loss: 2.575390839775605

Epoch: 6| Step: 11
Training loss: 3.1090507913381082
Validation loss: 2.5771908233190666

Epoch: 6| Step: 12
Training loss: 2.8094318184713365
Validation loss: 2.5719242163854905

Epoch: 6| Step: 13
Training loss: 3.2368499574578253
Validation loss: 2.563813221941004

Epoch: 67| Step: 0
Training loss: 2.8219750911497394
Validation loss: 2.56912949381648

Epoch: 6| Step: 1
Training loss: 2.5902653461756833
Validation loss: 2.568547671997895

Epoch: 6| Step: 2
Training loss: 2.8449694355963717
Validation loss: 2.568512213623165

Epoch: 6| Step: 3
Training loss: 2.9490166399083027
Validation loss: 2.5668675643358694

Epoch: 6| Step: 4
Training loss: 2.7420028233085807
Validation loss: 2.569535297356976

Epoch: 6| Step: 5
Training loss: 2.7945376384641825
Validation loss: 2.5715902335386294

Epoch: 6| Step: 6
Training loss: 2.6771486227383754
Validation loss: 2.5729423295155645

Epoch: 6| Step: 7
Training loss: 2.3181368199569325
Validation loss: 2.5755853339521644

Epoch: 6| Step: 8
Training loss: 3.1225527526944
Validation loss: 2.576257989122348

Epoch: 6| Step: 9
Training loss: 2.86049592606845
Validation loss: 2.578642020739256

Epoch: 6| Step: 10
Training loss: 2.375427308040065
Validation loss: 2.576989064282351

Epoch: 6| Step: 11
Training loss: 2.09326348417015
Validation loss: 2.5738731542058257

Epoch: 6| Step: 12
Training loss: 3.10716007647574
Validation loss: 2.5731971423111055

Epoch: 6| Step: 13
Training loss: 2.4497092210692575
Validation loss: 2.5704780223851484

Epoch: 68| Step: 0
Training loss: 2.612487581214409
Validation loss: 2.5703110467815833

Epoch: 6| Step: 1
Training loss: 2.3543793798800348
Validation loss: 2.5626263626080372

Epoch: 6| Step: 2
Training loss: 1.907700846386133
Validation loss: 2.564407615519289

Epoch: 6| Step: 3
Training loss: 2.351008555920413
Validation loss: 2.565961531182505

Epoch: 6| Step: 4
Training loss: 2.9666420931994923
Validation loss: 2.564328510465177

Epoch: 6| Step: 5
Training loss: 2.3783239895432793
Validation loss: 2.5596929698102158

Epoch: 6| Step: 6
Training loss: 3.4442999426634926
Validation loss: 2.5632572760871066

Epoch: 6| Step: 7
Training loss: 2.3712347199264907
Validation loss: 2.559190147720314

Epoch: 6| Step: 8
Training loss: 2.998898939891868
Validation loss: 2.5609712149677972

Epoch: 6| Step: 9
Training loss: 2.900446193175601
Validation loss: 2.5541610797574132

Epoch: 6| Step: 10
Training loss: 2.9792998135208237
Validation loss: 2.5520196608301253

Epoch: 6| Step: 11
Training loss: 3.169577983599112
Validation loss: 2.554744179317569

Epoch: 6| Step: 12
Training loss: 2.4649555646439034
Validation loss: 2.558259448083182

Epoch: 6| Step: 13
Training loss: 2.330235491136643
Validation loss: 2.5609858311453957

Epoch: 69| Step: 0
Training loss: 2.548461607088711
Validation loss: 2.5565998568585964

Epoch: 6| Step: 1
Training loss: 2.1886648074159716
Validation loss: 2.556822915763197

Epoch: 6| Step: 2
Training loss: 2.873500432896088
Validation loss: 2.5555952755518017

Epoch: 6| Step: 3
Training loss: 2.6391763720159784
Validation loss: 2.5533269434252164

Epoch: 6| Step: 4
Training loss: 2.1176374457022686
Validation loss: 2.5560097728417053

Epoch: 6| Step: 5
Training loss: 3.066298017596275
Validation loss: 2.5546927106922763

Epoch: 6| Step: 6
Training loss: 2.789739104620822
Validation loss: 2.553148869839059

Epoch: 6| Step: 7
Training loss: 2.298421741174838
Validation loss: 2.5575564079738813

Epoch: 6| Step: 8
Training loss: 2.5960847388956894
Validation loss: 2.5616282399095214

Epoch: 6| Step: 9
Training loss: 2.701864488886997
Validation loss: 2.5585131916438884

Epoch: 6| Step: 10
Training loss: 3.1725733697582195
Validation loss: 2.5540067055309734

Epoch: 6| Step: 11
Training loss: 2.5932208521098588
Validation loss: 2.5508168613816316

Epoch: 6| Step: 12
Training loss: 2.831879878767126
Validation loss: 2.549282005305426

Epoch: 6| Step: 13
Training loss: 2.9437279119290585
Validation loss: 2.5534460724209875

Epoch: 70| Step: 0
Training loss: 2.2380001297678835
Validation loss: 2.5516238726717737

Epoch: 6| Step: 1
Training loss: 2.7220911126342147
Validation loss: 2.5550743844438855

Epoch: 6| Step: 2
Training loss: 2.9994334639622076
Validation loss: 2.5598925916794166

Epoch: 6| Step: 3
Training loss: 2.750080801036843
Validation loss: 2.559754164311249

Epoch: 6| Step: 4
Training loss: 2.727694563320428
Validation loss: 2.5606954780248192

Epoch: 6| Step: 5
Training loss: 2.35441988593105
Validation loss: 2.5652856030012354

Epoch: 6| Step: 6
Training loss: 2.570661805137744
Validation loss: 2.561567772731153

Epoch: 6| Step: 7
Training loss: 2.2302903406304573
Validation loss: 2.5562035964447456

Epoch: 6| Step: 8
Training loss: 2.8126839471638654
Validation loss: 2.556025847639111

Epoch: 6| Step: 9
Training loss: 2.796610558651357
Validation loss: 2.5501695632657175

Epoch: 6| Step: 10
Training loss: 3.041807371743318
Validation loss: 2.546826383598649

Epoch: 6| Step: 11
Training loss: 3.096946221234201
Validation loss: 2.547371860709308

Epoch: 6| Step: 12
Training loss: 2.7736881626382535
Validation loss: 2.5416455241923837

Epoch: 6| Step: 13
Training loss: 2.355478467019758
Validation loss: 2.5419252503812535

Epoch: 71| Step: 0
Training loss: 1.8932334623502318
Validation loss: 2.5433813366874056

Epoch: 6| Step: 1
Training loss: 2.9283900121661546
Validation loss: 2.5459831720222064

Epoch: 6| Step: 2
Training loss: 2.3547995962737125
Validation loss: 2.5424636440747292

Epoch: 6| Step: 3
Training loss: 2.732335752557392
Validation loss: 2.5412173786061665

Epoch: 6| Step: 4
Training loss: 2.671826724681526
Validation loss: 2.541512474219067

Epoch: 6| Step: 5
Training loss: 3.225761406491703
Validation loss: 2.5424536179844566

Epoch: 6| Step: 6
Training loss: 2.425151651104168
Validation loss: 2.5401579386500246

Epoch: 6| Step: 7
Training loss: 2.668678647233212
Validation loss: 2.5424167016261596

Epoch: 6| Step: 8
Training loss: 2.881181953603081
Validation loss: 2.538715233163266

Epoch: 6| Step: 9
Training loss: 2.731615777913906
Validation loss: 2.543691396702102

Epoch: 6| Step: 10
Training loss: 2.8109400343658235
Validation loss: 2.538032596737531

Epoch: 6| Step: 11
Training loss: 2.2732986460227327
Validation loss: 2.5433101395598925

Epoch: 6| Step: 12
Training loss: 2.9447113152089175
Validation loss: 2.539993459763204

Epoch: 6| Step: 13
Training loss: 2.487053440975449
Validation loss: 2.538660684727118

Epoch: 72| Step: 0
Training loss: 2.184978666921566
Validation loss: 2.5370080392680325

Epoch: 6| Step: 1
Training loss: 2.013753924469584
Validation loss: 2.5350791476632826

Epoch: 6| Step: 2
Training loss: 2.50206976089375
Validation loss: 2.5380066069959613

Epoch: 6| Step: 3
Training loss: 2.813139609616949
Validation loss: 2.537146399905457

Epoch: 6| Step: 4
Training loss: 3.1978841939430973
Validation loss: 2.5339793651004587

Epoch: 6| Step: 5
Training loss: 3.0599980936480797
Validation loss: 2.534825268629277

Epoch: 6| Step: 6
Training loss: 2.734589835310373
Validation loss: 2.5319731507447156

Epoch: 6| Step: 7
Training loss: 3.134365391359976
Validation loss: 2.5315764573804977

Epoch: 6| Step: 8
Training loss: 2.8675031358324246
Validation loss: 2.5329790528509712

Epoch: 6| Step: 9
Training loss: 2.428739013018767
Validation loss: 2.53198799709189

Epoch: 6| Step: 10
Training loss: 2.054742964659539
Validation loss: 2.532009371912417

Epoch: 6| Step: 11
Training loss: 2.5373555710754028
Validation loss: 2.5308198602606873

Epoch: 6| Step: 12
Training loss: 2.2999310566064413
Validation loss: 2.527426811162266

Epoch: 6| Step: 13
Training loss: 2.983928866768374
Validation loss: 2.5269593187697432

Epoch: 73| Step: 0
Training loss: 2.8275147512035947
Validation loss: 2.527106704876392

Epoch: 6| Step: 1
Training loss: 2.481702218536555
Validation loss: 2.5312322451121863

Epoch: 6| Step: 2
Training loss: 2.7141771115539424
Validation loss: 2.536249443293536

Epoch: 6| Step: 3
Training loss: 2.6959806194684184
Validation loss: 2.5307907661205222

Epoch: 6| Step: 4
Training loss: 2.2537932739504085
Validation loss: 2.531664041321502

Epoch: 6| Step: 5
Training loss: 2.136069692610579
Validation loss: 2.5314443851133035

Epoch: 6| Step: 6
Training loss: 3.012211740718579
Validation loss: 2.5260835362271137

Epoch: 6| Step: 7
Training loss: 2.04630615250541
Validation loss: 2.5262326250291998

Epoch: 6| Step: 8
Training loss: 3.007166092015581
Validation loss: 2.528303574336855

Epoch: 6| Step: 9
Training loss: 2.8685379382107015
Validation loss: 2.522217147414059

Epoch: 6| Step: 10
Training loss: 2.8625793845817142
Validation loss: 2.525493685612563

Epoch: 6| Step: 11
Training loss: 2.4737671681213644
Validation loss: 2.5237695024809685

Epoch: 6| Step: 12
Training loss: 2.447545016598544
Validation loss: 2.5179232490761145

Epoch: 6| Step: 13
Training loss: 3.1241340963423307
Validation loss: 2.5244452921585365

Epoch: 74| Step: 0
Training loss: 2.0610061784454534
Validation loss: 2.520730061162756

Epoch: 6| Step: 1
Training loss: 2.5973719850042865
Validation loss: 2.519143986079862

Epoch: 6| Step: 2
Training loss: 2.8398177238856404
Validation loss: 2.5271123026429336

Epoch: 6| Step: 3
Training loss: 2.368673229734886
Validation loss: 2.5254113948053485

Epoch: 6| Step: 4
Training loss: 2.417152871079268
Validation loss: 2.5196069040694713

Epoch: 6| Step: 5
Training loss: 2.8812019790983676
Validation loss: 2.521392536928599

Epoch: 6| Step: 6
Training loss: 2.5746497573428972
Validation loss: 2.515416028048645

Epoch: 6| Step: 7
Training loss: 2.953778875712677
Validation loss: 2.5165692723188355

Epoch: 6| Step: 8
Training loss: 3.0990490470025702
Validation loss: 2.517627669212649

Epoch: 6| Step: 9
Training loss: 2.6616253486281574
Validation loss: 2.5248661150546603

Epoch: 6| Step: 10
Training loss: 2.1122737605370014
Validation loss: 2.521633846029871

Epoch: 6| Step: 11
Training loss: 2.6280981581833336
Validation loss: 2.52466643871625

Epoch: 6| Step: 12
Training loss: 2.868306869157186
Validation loss: 2.5222100578505846

Epoch: 6| Step: 13
Training loss: 2.7043112208244726
Validation loss: 2.525825496482291

Epoch: 75| Step: 0
Training loss: 2.7938941116201597
Validation loss: 2.5226394761450206

Epoch: 6| Step: 1
Training loss: 2.4432155405181097
Validation loss: 2.526908911786389

Epoch: 6| Step: 2
Training loss: 2.6568915097359236
Validation loss: 2.525496863903535

Epoch: 6| Step: 3
Training loss: 2.7831135196650325
Validation loss: 2.5217393922960545

Epoch: 6| Step: 4
Training loss: 2.7947101419515503
Validation loss: 2.521109342571184

Epoch: 6| Step: 5
Training loss: 3.04578117886068
Validation loss: 2.524070495010944

Epoch: 6| Step: 6
Training loss: 2.7039614579484224
Validation loss: 2.521702535121626

Epoch: 6| Step: 7
Training loss: 2.5545924924396846
Validation loss: 2.5235942559620335

Epoch: 6| Step: 8
Training loss: 2.2665094162118224
Validation loss: 2.5205213075158555

Epoch: 6| Step: 9
Training loss: 2.7478884479808103
Validation loss: 2.5228340994325578

Epoch: 6| Step: 10
Training loss: 2.6088877697013837
Validation loss: 2.5208320670216637

Epoch: 6| Step: 11
Training loss: 2.3252563212216204
Validation loss: 2.5185818403855307

Epoch: 6| Step: 12
Training loss: 2.4985230851678555
Validation loss: 2.5178584733629044

Epoch: 6| Step: 13
Training loss: 2.747200234246619
Validation loss: 2.517018597566091

Epoch: 76| Step: 0
Training loss: 2.3151946992340253
Validation loss: 2.5182580140811037

Epoch: 6| Step: 1
Training loss: 2.1520699051631627
Validation loss: 2.5194655535508876

Epoch: 6| Step: 2
Training loss: 1.980982486221868
Validation loss: 2.520784445884963

Epoch: 6| Step: 3
Training loss: 2.94588620697297
Validation loss: 2.539381490378786

Epoch: 6| Step: 4
Training loss: 2.9299221911205264
Validation loss: 2.5668718369542405

Epoch: 6| Step: 5
Training loss: 2.747931048914995
Validation loss: 2.574272359734553

Epoch: 6| Step: 6
Training loss: 2.7869505165341755
Validation loss: 2.5335606205354666

Epoch: 6| Step: 7
Training loss: 2.7349376862451624
Validation loss: 2.5120742569991066

Epoch: 6| Step: 8
Training loss: 2.4493205704886902
Validation loss: 2.5158768205989746

Epoch: 6| Step: 9
Training loss: 2.5736394528496334
Validation loss: 2.5116910324821737

Epoch: 6| Step: 10
Training loss: 3.102874555210232
Validation loss: 2.5192563086824378

Epoch: 6| Step: 11
Training loss: 2.785810781561239
Validation loss: 2.515897416238638

Epoch: 6| Step: 12
Training loss: 2.459675880262195
Validation loss: 2.5201127044260225

Epoch: 6| Step: 13
Training loss: 3.039231636420517
Validation loss: 2.522935642220422

Epoch: 77| Step: 0
Training loss: 2.5332836882428285
Validation loss: 2.521581213066912

Epoch: 6| Step: 1
Training loss: 2.9074427300386487
Validation loss: 2.526696729112136

Epoch: 6| Step: 2
Training loss: 2.5284730725867712
Validation loss: 2.52728854732768

Epoch: 6| Step: 3
Training loss: 2.95268722599486
Validation loss: 2.5238914750632873

Epoch: 6| Step: 4
Training loss: 2.8001075689906454
Validation loss: 2.523541805603566

Epoch: 6| Step: 5
Training loss: 2.0421120942721314
Validation loss: 2.52002240107939

Epoch: 6| Step: 6
Training loss: 3.157467899838917
Validation loss: 2.518087851902932

Epoch: 6| Step: 7
Training loss: 2.6368532951783585
Validation loss: 2.5148771765909794

Epoch: 6| Step: 8
Training loss: 2.4272096025313434
Validation loss: 2.51546303995795

Epoch: 6| Step: 9
Training loss: 2.9549290227998974
Validation loss: 2.5098728735900653

Epoch: 6| Step: 10
Training loss: 2.517890810137505
Validation loss: 2.512069416632937

Epoch: 6| Step: 11
Training loss: 2.1469985859710343
Validation loss: 2.5102034487473497

Epoch: 6| Step: 12
Training loss: 2.630716185436093
Validation loss: 2.513194282093472

Epoch: 6| Step: 13
Training loss: 2.500254332003232
Validation loss: 2.50746694305324

Epoch: 78| Step: 0
Training loss: 2.1701451280292257
Validation loss: 2.504666011319123

Epoch: 6| Step: 1
Training loss: 2.901329880008793
Validation loss: 2.5098766257828293

Epoch: 6| Step: 2
Training loss: 2.3548849467299258
Validation loss: 2.519706574089105

Epoch: 6| Step: 3
Training loss: 2.5431660049743945
Validation loss: 2.5145014115594644

Epoch: 6| Step: 4
Training loss: 2.365357248530862
Validation loss: 2.5165070276807127

Epoch: 6| Step: 5
Training loss: 2.471907130055484
Validation loss: 2.5136192966387436

Epoch: 6| Step: 6
Training loss: 3.3113931210074514
Validation loss: 2.5117777910902

Epoch: 6| Step: 7
Training loss: 2.4217974250428824
Validation loss: 2.5025940946812284

Epoch: 6| Step: 8
Training loss: 2.3448531542838733
Validation loss: 2.5053304429672862

Epoch: 6| Step: 9
Training loss: 2.771001299210419
Validation loss: 2.5035034109551644

Epoch: 6| Step: 10
Training loss: 3.0811956745179248
Validation loss: 2.503265743291321

Epoch: 6| Step: 11
Training loss: 2.2250472417380958
Validation loss: 2.5044389575635635

Epoch: 6| Step: 12
Training loss: 2.7183241236577667
Validation loss: 2.503221550141825

Epoch: 6| Step: 13
Training loss: 2.95061374034321
Validation loss: 2.508307846759402

Epoch: 79| Step: 0
Training loss: 2.7287206115398264
Validation loss: 2.506534072301962

Epoch: 6| Step: 1
Training loss: 3.2175490722233793
Validation loss: 2.5037033625712635

Epoch: 6| Step: 2
Training loss: 2.4231959524484195
Validation loss: 2.5032965304069026

Epoch: 6| Step: 3
Training loss: 2.7543318182925582
Validation loss: 2.5030513897064344

Epoch: 6| Step: 4
Training loss: 2.476067815526748
Validation loss: 2.501953649111357

Epoch: 6| Step: 5
Training loss: 2.0675382632274713
Validation loss: 2.503779828177527

Epoch: 6| Step: 6
Training loss: 2.6066207512261266
Validation loss: 2.5005438530965525

Epoch: 6| Step: 7
Training loss: 2.2178372937058612
Validation loss: 2.4987790146085067

Epoch: 6| Step: 8
Training loss: 2.739656590012911
Validation loss: 2.5032056283526054

Epoch: 6| Step: 9
Training loss: 2.5729282600254897
Validation loss: 2.497320750158306

Epoch: 6| Step: 10
Training loss: 3.033806735256016
Validation loss: 2.5057234336984613

Epoch: 6| Step: 11
Training loss: 2.550949488374148
Validation loss: 2.5008885394058598

Epoch: 6| Step: 12
Training loss: 2.220507288528503
Validation loss: 2.4998550214055757

Epoch: 6| Step: 13
Training loss: 2.706345596563216
Validation loss: 2.4862544310287182

Epoch: 80| Step: 0
Training loss: 2.821817435081932
Validation loss: 2.4983198719115824

Epoch: 6| Step: 1
Training loss: 2.6962681941876245
Validation loss: 2.501777398566375

Epoch: 6| Step: 2
Training loss: 2.451221188964844
Validation loss: 2.5006617147185963

Epoch: 6| Step: 3
Training loss: 2.7973308511413286
Validation loss: 2.501478695662002

Epoch: 6| Step: 4
Training loss: 2.5614424593447693
Validation loss: 2.5022103710676875

Epoch: 6| Step: 5
Training loss: 2.6334374475620583
Validation loss: 2.5036356557077486

Epoch: 6| Step: 6
Training loss: 2.5668889118762204
Validation loss: 2.5023941497062387

Epoch: 6| Step: 7
Training loss: 2.470916087505385
Validation loss: 2.5017169460739397

Epoch: 6| Step: 8
Training loss: 2.1659899779745704
Validation loss: 2.50369839492411

Epoch: 6| Step: 9
Training loss: 2.530112493675302
Validation loss: 2.5032928874036964

Epoch: 6| Step: 10
Training loss: 2.7228044992200413
Validation loss: 2.502569388241546

Epoch: 6| Step: 11
Training loss: 2.302540855915039
Validation loss: 2.501330228399303

Epoch: 6| Step: 12
Training loss: 2.615755059257135
Validation loss: 2.5025481748056526

Epoch: 6| Step: 13
Training loss: 3.197601617625545
Validation loss: 2.5008775601347466

Epoch: 81| Step: 0
Training loss: 2.406728523530255
Validation loss: 2.4989158345836144

Epoch: 6| Step: 1
Training loss: 2.8185869258559255
Validation loss: 2.497783202571378

Epoch: 6| Step: 2
Training loss: 2.431612779082529
Validation loss: 2.498797604373121

Epoch: 6| Step: 3
Training loss: 2.739133868073812
Validation loss: 2.5033437937261023

Epoch: 6| Step: 4
Training loss: 2.6983798499650242
Validation loss: 2.4942075540658184

Epoch: 6| Step: 5
Training loss: 2.3487036680450104
Validation loss: 2.497850845356299

Epoch: 6| Step: 6
Training loss: 2.820646313807173
Validation loss: 2.5003142318334985

Epoch: 6| Step: 7
Training loss: 2.2861643075708575
Validation loss: 2.508939448237539

Epoch: 6| Step: 8
Training loss: 2.3297308177745717
Validation loss: 2.501625406847129

Epoch: 6| Step: 9
Training loss: 2.983466684213274
Validation loss: 2.4987252164180624

Epoch: 6| Step: 10
Training loss: 2.4573528036932033
Validation loss: 2.4916233871256477

Epoch: 6| Step: 11
Training loss: 2.6166454152339673
Validation loss: 2.496045203177099

Epoch: 6| Step: 12
Training loss: 2.778540673928018
Validation loss: 2.496109366927745

Epoch: 6| Step: 13
Training loss: 2.8048483289760195
Validation loss: 2.497267883226565

Epoch: 82| Step: 0
Training loss: 2.566445081814764
Validation loss: 2.498740816899356

Epoch: 6| Step: 1
Training loss: 2.6487720019446996
Validation loss: 2.500138469675972

Epoch: 6| Step: 2
Training loss: 2.76825274615624
Validation loss: 2.4980878272339755

Epoch: 6| Step: 3
Training loss: 2.5938086445624577
Validation loss: 2.495838874615444

Epoch: 6| Step: 4
Training loss: 2.4389943164041323
Validation loss: 2.4979640458815267

Epoch: 6| Step: 5
Training loss: 2.3856197642747863
Validation loss: 2.4902670704808285

Epoch: 6| Step: 6
Training loss: 2.0033350794187395
Validation loss: 2.4955057756054826

Epoch: 6| Step: 7
Training loss: 3.2946935008103906
Validation loss: 2.4938039609700517

Epoch: 6| Step: 8
Training loss: 2.4778083050514685
Validation loss: 2.4945703114932765

Epoch: 6| Step: 9
Training loss: 2.6315076180879995
Validation loss: 2.495595692278509

Epoch: 6| Step: 10
Training loss: 3.0816435092560024
Validation loss: 2.4957196388607814

Epoch: 6| Step: 11
Training loss: 2.35452499588299
Validation loss: 2.4984216316996357

Epoch: 6| Step: 12
Training loss: 2.32733263702659
Validation loss: 2.4953115846635816

Epoch: 6| Step: 13
Training loss: 2.564084935249958
Validation loss: 2.496684196098256

Epoch: 83| Step: 0
Training loss: 2.5586237548932442
Validation loss: 2.4995268532926413

Epoch: 6| Step: 1
Training loss: 2.447468060449694
Validation loss: 2.4977807049076097

Epoch: 6| Step: 2
Training loss: 2.9259580754831167
Validation loss: 2.496474116182983

Epoch: 6| Step: 3
Training loss: 2.3143500067679703
Validation loss: 2.4956334843385055

Epoch: 6| Step: 4
Training loss: 3.107017351694462
Validation loss: 2.494155967384414

Epoch: 6| Step: 5
Training loss: 2.5058820192736615
Validation loss: 2.4946148888719346

Epoch: 6| Step: 6
Training loss: 2.628812110881804
Validation loss: 2.4930891201790586

Epoch: 6| Step: 7
Training loss: 2.653136998521253
Validation loss: 2.488639705914884

Epoch: 6| Step: 8
Training loss: 3.0569674283664297
Validation loss: 2.4906566067440723

Epoch: 6| Step: 9
Training loss: 2.5572987314866027
Validation loss: 2.4934981994214445

Epoch: 6| Step: 10
Training loss: 2.2270307082074714
Validation loss: 2.492799323068942

Epoch: 6| Step: 11
Training loss: 2.241630458421187
Validation loss: 2.4922397811332697

Epoch: 6| Step: 12
Training loss: 2.575261230550915
Validation loss: 2.4937890147740083

Epoch: 6| Step: 13
Training loss: 2.5533266321730097
Validation loss: 2.5014965505363334

Epoch: 84| Step: 0
Training loss: 2.6652423114370514
Validation loss: 2.494985956472296

Epoch: 6| Step: 1
Training loss: 2.7632587892473155
Validation loss: 2.4965396934464255

Epoch: 6| Step: 2
Training loss: 2.550577479777213
Validation loss: 2.49291598874754

Epoch: 6| Step: 3
Training loss: 2.6216780214575093
Validation loss: 2.4942722987799097

Epoch: 6| Step: 4
Training loss: 2.3423585957745092
Validation loss: 2.490354527585417

Epoch: 6| Step: 5
Training loss: 2.7863716373444705
Validation loss: 2.491858664954149

Epoch: 6| Step: 6
Training loss: 1.8564527612784545
Validation loss: 2.4959183752211533

Epoch: 6| Step: 7
Training loss: 2.4885878441412936
Validation loss: 2.496259943484319

Epoch: 6| Step: 8
Training loss: 2.4720031936526117
Validation loss: 2.490863651726262

Epoch: 6| Step: 9
Training loss: 2.27870517035837
Validation loss: 2.4916655533021546

Epoch: 6| Step: 10
Training loss: 3.008628199560138
Validation loss: 2.4936463601383116

Epoch: 6| Step: 11
Training loss: 2.640264001130664
Validation loss: 2.491744286041582

Epoch: 6| Step: 12
Training loss: 2.818255236863518
Validation loss: 2.4892366931448886

Epoch: 6| Step: 13
Training loss: 2.8953054116126804
Validation loss: 2.4896339081504633

Epoch: 85| Step: 0
Training loss: 2.9256595031098898
Validation loss: 2.485418344536018

Epoch: 6| Step: 1
Training loss: 2.5472607466755255
Validation loss: 2.482923983645126

Epoch: 6| Step: 2
Training loss: 2.376238650516093
Validation loss: 2.492377605781052

Epoch: 6| Step: 3
Training loss: 2.5222718939275706
Validation loss: 2.482039787606795

Epoch: 6| Step: 4
Training loss: 3.145762933275972
Validation loss: 2.483314063703631

Epoch: 6| Step: 5
Training loss: 2.210873875865132
Validation loss: 2.481459996764116

Epoch: 6| Step: 6
Training loss: 2.368489628072315
Validation loss: 2.483973856595401

Epoch: 6| Step: 7
Training loss: 2.6733356967005504
Validation loss: 2.493125938146948

Epoch: 6| Step: 8
Training loss: 2.4093338662283976
Validation loss: 2.4870879197766724

Epoch: 6| Step: 9
Training loss: 2.3257339795645526
Validation loss: 2.486894469624763

Epoch: 6| Step: 10
Training loss: 2.4459811627901726
Validation loss: 2.489016741092343

Epoch: 6| Step: 11
Training loss: 3.1612584628545837
Validation loss: 2.4888788261262187

Epoch: 6| Step: 12
Training loss: 2.412058767181656
Validation loss: 2.487242892730453

Epoch: 6| Step: 13
Training loss: 2.517075209477948
Validation loss: 2.4835105607671153

Epoch: 86| Step: 0
Training loss: 2.659192419004135
Validation loss: 2.4844938365736744

Epoch: 6| Step: 1
Training loss: 2.5064682254295367
Validation loss: 2.48195921005167

Epoch: 6| Step: 2
Training loss: 2.628480057653599
Validation loss: 2.4823301845117527

Epoch: 6| Step: 3
Training loss: 2.5693492069865917
Validation loss: 2.4840581040034153

Epoch: 6| Step: 4
Training loss: 1.5329217154414627
Validation loss: 2.4834540557533495

Epoch: 6| Step: 5
Training loss: 2.829554581113862
Validation loss: 2.4846868419266523

Epoch: 6| Step: 6
Training loss: 2.4576747033547313
Validation loss: 2.479359456321228

Epoch: 6| Step: 7
Training loss: 2.6277820739908115
Validation loss: 2.486056464557812

Epoch: 6| Step: 8
Training loss: 2.9438142481958436
Validation loss: 2.4925464622735536

Epoch: 6| Step: 9
Training loss: 2.781957386367852
Validation loss: 2.4812422219770283

Epoch: 6| Step: 10
Training loss: 1.9668670611468293
Validation loss: 2.48800521908506

Epoch: 6| Step: 11
Training loss: 2.5582922837964146
Validation loss: 2.476505154528389

Epoch: 6| Step: 12
Training loss: 3.097679032269627
Validation loss: 2.4886802141900795

Epoch: 6| Step: 13
Training loss: 2.703530165455859
Validation loss: 2.486110776644305

Epoch: 87| Step: 0
Training loss: 2.8673198783728524
Validation loss: 2.481896753842637

Epoch: 6| Step: 1
Training loss: 2.122290960111869
Validation loss: 2.4887029828404823

Epoch: 6| Step: 2
Training loss: 2.4781515997941894
Validation loss: 2.4869903138128917

Epoch: 6| Step: 3
Training loss: 2.851614839256397
Validation loss: 2.490343485916405

Epoch: 6| Step: 4
Training loss: 2.8001761108600034
Validation loss: 2.492057996233186

Epoch: 6| Step: 5
Training loss: 2.607060027999644
Validation loss: 2.4956425361962977

Epoch: 6| Step: 6
Training loss: 2.2182169529140543
Validation loss: 2.494048042938963

Epoch: 6| Step: 7
Training loss: 2.4247787295982715
Validation loss: 2.4913063046016197

Epoch: 6| Step: 8
Training loss: 2.715479846231249
Validation loss: 2.487034731472223

Epoch: 6| Step: 9
Training loss: 2.778906531410321
Validation loss: 2.4886342930524528

Epoch: 6| Step: 10
Training loss: 2.291304288013924
Validation loss: 2.490429743663895

Epoch: 6| Step: 11
Training loss: 3.219057531387232
Validation loss: 2.4865825929397616

Epoch: 6| Step: 12
Training loss: 2.1013290105394415
Validation loss: 2.481454616280481

Epoch: 6| Step: 13
Training loss: 2.4846971410948835
Validation loss: 2.483446119508001

Epoch: 88| Step: 0
Training loss: 2.9472646542617684
Validation loss: 2.4827461421061936

Epoch: 6| Step: 1
Training loss: 2.833661976622107
Validation loss: 2.479635904821377

Epoch: 6| Step: 2
Training loss: 2.5946249347923285
Validation loss: 2.479408722502245

Epoch: 6| Step: 3
Training loss: 2.299788204061152
Validation loss: 2.4870924412892963

Epoch: 6| Step: 4
Training loss: 2.7016080447627586
Validation loss: 2.481017036615767

Epoch: 6| Step: 5
Training loss: 2.7738462334984444
Validation loss: 2.4870734764445315

Epoch: 6| Step: 6
Training loss: 1.9062052236832643
Validation loss: 2.493602283344543

Epoch: 6| Step: 7
Training loss: 2.836073018348659
Validation loss: 2.478330252037707

Epoch: 6| Step: 8
Training loss: 1.8950823110252792
Validation loss: 2.482736547071356

Epoch: 6| Step: 9
Training loss: 2.124048132040355
Validation loss: 2.485249163623487

Epoch: 6| Step: 10
Training loss: 2.5517822918482356
Validation loss: 2.4741995897947446

Epoch: 6| Step: 11
Training loss: 3.336460474549336
Validation loss: 2.4827638756176023

Epoch: 6| Step: 12
Training loss: 2.7780626871438976
Validation loss: 2.4810081716410846

Epoch: 6| Step: 13
Training loss: 2.0904070228788627
Validation loss: 2.4825962184508326

Epoch: 89| Step: 0
Training loss: 2.275573251623564
Validation loss: 2.4849070493122105

Epoch: 6| Step: 1
Training loss: 3.020221586877011
Validation loss: 2.481382683217954

Epoch: 6| Step: 2
Training loss: 2.2727129328882216
Validation loss: 2.4848982621799856

Epoch: 6| Step: 3
Training loss: 2.146814350454217
Validation loss: 2.4879299935941344

Epoch: 6| Step: 4
Training loss: 2.7120821512321007
Validation loss: 2.481052712413153

Epoch: 6| Step: 5
Training loss: 2.9897993233487234
Validation loss: 2.482416944801523

Epoch: 6| Step: 6
Training loss: 2.2917450168971993
Validation loss: 2.4907454700443457

Epoch: 6| Step: 7
Training loss: 2.695896605073908
Validation loss: 2.4855966503357703

Epoch: 6| Step: 8
Training loss: 2.4563911222728874
Validation loss: 2.483419062480917

Epoch: 6| Step: 9
Training loss: 2.281324097984582
Validation loss: 2.4849182110841372

Epoch: 6| Step: 10
Training loss: 2.5785331634170054
Validation loss: 2.4878307435746367

Epoch: 6| Step: 11
Training loss: 2.814010384101931
Validation loss: 2.488606789461896

Epoch: 6| Step: 12
Training loss: 2.3974177774246437
Validation loss: 2.4833281608715425

Epoch: 6| Step: 13
Training loss: 2.887853334945401
Validation loss: 2.471593305931404

Epoch: 90| Step: 0
Training loss: 2.713606254604617
Validation loss: 2.4738575536713365

Epoch: 6| Step: 1
Training loss: 2.409795749604014
Validation loss: 2.4756492110072243

Epoch: 6| Step: 2
Training loss: 2.188000866905473
Validation loss: 2.475200338636226

Epoch: 6| Step: 3
Training loss: 2.588964252530132
Validation loss: 2.4742983828626914

Epoch: 6| Step: 4
Training loss: 2.661078877033697
Validation loss: 2.4766864605194367

Epoch: 6| Step: 5
Training loss: 2.365199094299731
Validation loss: 2.4834871925037585

Epoch: 6| Step: 6
Training loss: 2.3567300079912434
Validation loss: 2.473374409612984

Epoch: 6| Step: 7
Training loss: 2.447450720628962
Validation loss: 2.4724862520859747

Epoch: 6| Step: 8
Training loss: 2.819442149778872
Validation loss: 2.4704819571474355

Epoch: 6| Step: 9
Training loss: 2.507484580969065
Validation loss: 2.4732651124098757

Epoch: 6| Step: 10
Training loss: 2.9952924669020677
Validation loss: 2.4720509186400594

Epoch: 6| Step: 11
Training loss: 2.911497239800884
Validation loss: 2.473508891723846

Epoch: 6| Step: 12
Training loss: 2.450845716441482
Validation loss: 2.4727221375214876

Epoch: 6| Step: 13
Training loss: 2.4944944795358954
Validation loss: 2.4847862495070556

Epoch: 91| Step: 0
Training loss: 2.3208448011387794
Validation loss: 2.4824688554585608

Epoch: 6| Step: 1
Training loss: 2.429874523361193
Validation loss: 2.4867887147741974

Epoch: 6| Step: 2
Training loss: 3.031624682364504
Validation loss: 2.474182059896587

Epoch: 6| Step: 3
Training loss: 2.8177148580328706
Validation loss: 2.4780370933203115

Epoch: 6| Step: 4
Training loss: 2.300931397802594
Validation loss: 2.4777766960675778

Epoch: 6| Step: 5
Training loss: 2.78061968915436
Validation loss: 2.4777505233313

Epoch: 6| Step: 6
Training loss: 2.2240014053450063
Validation loss: 2.4809862132747105

Epoch: 6| Step: 7
Training loss: 2.552086488890481
Validation loss: 2.4782339206023716

Epoch: 6| Step: 8
Training loss: 2.875229867784929
Validation loss: 2.4793404002716755

Epoch: 6| Step: 9
Training loss: 2.1433099767777817
Validation loss: 2.4783451792269906

Epoch: 6| Step: 10
Training loss: 2.455394205581553
Validation loss: 2.4796297030973444

Epoch: 6| Step: 11
Training loss: 2.656599403289266
Validation loss: 2.4732723422726215

Epoch: 6| Step: 12
Training loss: 2.490573946670082
Validation loss: 2.47777567770954

Epoch: 6| Step: 13
Training loss: 2.8428749163332867
Validation loss: 2.4800215030066095

Epoch: 92| Step: 0
Training loss: 2.6642325338653974
Validation loss: 2.4800520579452785

Epoch: 6| Step: 1
Training loss: 2.2086460923697877
Validation loss: 2.4880276585203744

Epoch: 6| Step: 2
Training loss: 2.1999107342729913
Validation loss: 2.4861630576997618

Epoch: 6| Step: 3
Training loss: 2.7360942558204018
Validation loss: 2.4818786779123627

Epoch: 6| Step: 4
Training loss: 2.8319578384881736
Validation loss: 2.4893867436338786

Epoch: 6| Step: 5
Training loss: 2.4894367212089983
Validation loss: 2.4873420224272724

Epoch: 6| Step: 6
Training loss: 2.760176296685003
Validation loss: 2.487264763908957

Epoch: 6| Step: 7
Training loss: 2.29348359184974
Validation loss: 2.4903073927203505

Epoch: 6| Step: 8
Training loss: 3.24624416769427
Validation loss: 2.4816015345231115

Epoch: 6| Step: 9
Training loss: 2.592477509300798
Validation loss: 2.4773745002871186

Epoch: 6| Step: 10
Training loss: 2.27135348414395
Validation loss: 2.48186811087709

Epoch: 6| Step: 11
Training loss: 2.4883946942349953
Validation loss: 2.4798179433509886

Epoch: 6| Step: 12
Training loss: 2.5024740375159062
Validation loss: 2.4769419992057964

Epoch: 6| Step: 13
Training loss: 2.5397501322478417
Validation loss: 2.476087699165878

Epoch: 93| Step: 0
Training loss: 2.9797504804463433
Validation loss: 2.4743597782415487

Epoch: 6| Step: 1
Training loss: 2.5349151073439185
Validation loss: 2.4726325300624725

Epoch: 6| Step: 2
Training loss: 2.881321136192244
Validation loss: 2.474451041431461

Epoch: 6| Step: 3
Training loss: 2.675723332801568
Validation loss: 2.479615080107828

Epoch: 6| Step: 4
Training loss: 2.7122996313389
Validation loss: 2.4795308259705653

Epoch: 6| Step: 5
Training loss: 2.0016880064543288
Validation loss: 2.4688069461741273

Epoch: 6| Step: 6
Training loss: 2.146790473084681
Validation loss: 2.4719283492435506

Epoch: 6| Step: 7
Training loss: 2.8014371521582766
Validation loss: 2.4819347785097836

Epoch: 6| Step: 8
Training loss: 2.069396309289234
Validation loss: 2.473894368733468

Epoch: 6| Step: 9
Training loss: 2.8612211344118235
Validation loss: 2.477678659145332

Epoch: 6| Step: 10
Training loss: 2.7593639645728425
Validation loss: 2.4798998403063495

Epoch: 6| Step: 11
Training loss: 2.648092872005181
Validation loss: 2.4792073884926724

Epoch: 6| Step: 12
Training loss: 2.2636135248492333
Validation loss: 2.4795268996499407

Epoch: 6| Step: 13
Training loss: 2.2847349120782563
Validation loss: 2.4846982925520327

Epoch: 94| Step: 0
Training loss: 2.800122895268559
Validation loss: 2.481672772728159

Epoch: 6| Step: 1
Training loss: 2.426236857752555
Validation loss: 2.4866792081852407

Epoch: 6| Step: 2
Training loss: 2.412010629462865
Validation loss: 2.485893529171016

Epoch: 6| Step: 3
Training loss: 2.9907965950681583
Validation loss: 2.4937502307302166

Epoch: 6| Step: 4
Training loss: 2.101427719161976
Validation loss: 2.4916193363283083

Epoch: 6| Step: 5
Training loss: 2.4738273077282322
Validation loss: 2.4891672518252372

Epoch: 6| Step: 6
Training loss: 2.4692819722349535
Validation loss: 2.4895922502387275

Epoch: 6| Step: 7
Training loss: 2.535341981923053
Validation loss: 2.4869322021736773

Epoch: 6| Step: 8
Training loss: 2.377360325510117
Validation loss: 2.4824623806917976

Epoch: 6| Step: 9
Training loss: 2.4916540071129676
Validation loss: 2.487952713209846

Epoch: 6| Step: 10
Training loss: 2.4228430997307866
Validation loss: 2.481990445571777

Epoch: 6| Step: 11
Training loss: 2.962727109034415
Validation loss: 2.4884012733309455

Epoch: 6| Step: 12
Training loss: 2.961323010956374
Validation loss: 2.4849992203791196

Epoch: 6| Step: 13
Training loss: 2.549312805629161
Validation loss: 2.4724060381966764

Epoch: 95| Step: 0
Training loss: 3.0884363028880926
Validation loss: 2.473962584374774

Epoch: 6| Step: 1
Training loss: 2.54477122659447
Validation loss: 2.485033839613876

Epoch: 6| Step: 2
Training loss: 2.812045844815391
Validation loss: 2.473409994827508

Epoch: 6| Step: 3
Training loss: 2.503028751575455
Validation loss: 2.4817829805592564

Epoch: 6| Step: 4
Training loss: 2.789891480417054
Validation loss: 2.49178546146024

Epoch: 6| Step: 5
Training loss: 2.6761953659930904
Validation loss: 2.4924601661817682

Epoch: 6| Step: 6
Training loss: 2.7843684169635807
Validation loss: 2.4835523926894476

Epoch: 6| Step: 7
Training loss: 2.165203358391751
Validation loss: 2.487187423108534

Epoch: 6| Step: 8
Training loss: 2.323457481026433
Validation loss: 2.4864857022638724

Epoch: 6| Step: 9
Training loss: 2.8388493828991037
Validation loss: 2.4816821717272566

Epoch: 6| Step: 10
Training loss: 2.682605900305022
Validation loss: 2.4801935959439145

Epoch: 6| Step: 11
Training loss: 1.867748670963289
Validation loss: 2.4764507440969696

Epoch: 6| Step: 12
Training loss: 1.6870346840649237
Validation loss: 2.474575525226426

Epoch: 6| Step: 13
Training loss: 2.768122865077884
Validation loss: 2.477829545869672

Epoch: 96| Step: 0
Training loss: 2.7042401609930353
Validation loss: 2.4774447693684714

Epoch: 6| Step: 1
Training loss: 2.393349086564409
Validation loss: 2.4783969988039076

Epoch: 6| Step: 2
Training loss: 2.5930954440462837
Validation loss: 2.4776594939411813

Epoch: 6| Step: 3
Training loss: 2.3976592251885664
Validation loss: 2.483118695279015

Epoch: 6| Step: 4
Training loss: 2.061440860570795
Validation loss: 2.479687889722454

Epoch: 6| Step: 5
Training loss: 2.986051078804087
Validation loss: 2.4784606494623285

Epoch: 6| Step: 6
Training loss: 2.854977587663695
Validation loss: 2.4814484831554418

Epoch: 6| Step: 7
Training loss: 2.8438779361996915
Validation loss: 2.4761859274567404

Epoch: 6| Step: 8
Training loss: 2.8536738691898162
Validation loss: 2.4757912013362584

Epoch: 6| Step: 9
Training loss: 2.2273583846880887
Validation loss: 2.4770031846803313

Epoch: 6| Step: 10
Training loss: 2.841649547834842
Validation loss: 2.4742105348766033

Epoch: 6| Step: 11
Training loss: 2.1476849711895905
Validation loss: 2.471766009783341

Epoch: 6| Step: 12
Training loss: 2.4838592185824093
Validation loss: 2.4708101070999957

Epoch: 6| Step: 13
Training loss: 2.352997807564547
Validation loss: 2.471838471873791

Epoch: 97| Step: 0
Training loss: 2.194082655505082
Validation loss: 2.4721263540684437

Epoch: 6| Step: 1
Training loss: 2.660015354542407
Validation loss: 2.474739053244368

Epoch: 6| Step: 2
Training loss: 1.9422404226026948
Validation loss: 2.480780330122076

Epoch: 6| Step: 3
Training loss: 2.1166036441261564
Validation loss: 2.4814754015366742

Epoch: 6| Step: 4
Training loss: 2.437418031536943
Validation loss: 2.4714341199273413

Epoch: 6| Step: 5
Training loss: 2.058369285897568
Validation loss: 2.4785477055246288

Epoch: 6| Step: 6
Training loss: 3.1701786409698776
Validation loss: 2.4798198822457955

Epoch: 6| Step: 7
Training loss: 2.292221233429138
Validation loss: 2.472251855003506

Epoch: 6| Step: 8
Training loss: 3.527851731400445
Validation loss: 2.4659711593968923

Epoch: 6| Step: 9
Training loss: 2.7588070381051546
Validation loss: 2.472936878480614

Epoch: 6| Step: 10
Training loss: 2.159144352520686
Validation loss: 2.4757656977670504

Epoch: 6| Step: 11
Training loss: 2.709208440005849
Validation loss: 2.476364159889957

Epoch: 6| Step: 12
Training loss: 2.413863189271711
Validation loss: 2.473653422522172

Epoch: 6| Step: 13
Training loss: 2.778292422833436
Validation loss: 2.4782221995946534

Epoch: 98| Step: 0
Training loss: 2.3771997604364863
Validation loss: 2.4766429162031147

Epoch: 6| Step: 1
Training loss: 2.7235104330586823
Validation loss: 2.4750598155284913

Epoch: 6| Step: 2
Training loss: 1.6662926572131385
Validation loss: 2.48203866693551

Epoch: 6| Step: 3
Training loss: 2.574517517812595
Validation loss: 2.4733222759476066

Epoch: 6| Step: 4
Training loss: 2.556217400452564
Validation loss: 2.47451595781409

Epoch: 6| Step: 5
Training loss: 2.7823964874124756
Validation loss: 2.4745269817875837

Epoch: 6| Step: 6
Training loss: 2.177258303484631
Validation loss: 2.47766781759199

Epoch: 6| Step: 7
Training loss: 2.1622237232987587
Validation loss: 2.4807327250192768

Epoch: 6| Step: 8
Training loss: 2.8037804967316076
Validation loss: 2.480262711746067

Epoch: 6| Step: 9
Training loss: 2.937452599974953
Validation loss: 2.468662952546325

Epoch: 6| Step: 10
Training loss: 2.7562091262104924
Validation loss: 2.4745597161958464

Epoch: 6| Step: 11
Training loss: 2.6296198019650983
Validation loss: 2.4725179126323353

Epoch: 6| Step: 12
Training loss: 2.7047967757568276
Validation loss: 2.4747608181628697

Epoch: 6| Step: 13
Training loss: 2.538965874814086
Validation loss: 2.468873000802964

Epoch: 99| Step: 0
Training loss: 2.294477080399638
Validation loss: 2.472191178797244

Epoch: 6| Step: 1
Training loss: 2.3541477731492315
Validation loss: 2.462079980856222

Epoch: 6| Step: 2
Training loss: 2.181275913554603
Validation loss: 2.46704407996444

Epoch: 6| Step: 3
Training loss: 2.9630618564561804
Validation loss: 2.474506716266057

Epoch: 6| Step: 4
Training loss: 2.710068973071747
Validation loss: 2.463873993366129

Epoch: 6| Step: 5
Training loss: 2.465871750701111
Validation loss: 2.462459743319157

Epoch: 6| Step: 6
Training loss: 2.575863858102465
Validation loss: 2.46617339675039

Epoch: 6| Step: 7
Training loss: 2.658932755990438
Validation loss: 2.4698842899411586

Epoch: 6| Step: 8
Training loss: 2.7833812991214173
Validation loss: 2.472959695670396

Epoch: 6| Step: 9
Training loss: 2.299732325361051
Validation loss: 2.4633840681210373

Epoch: 6| Step: 10
Training loss: 2.513175577462565
Validation loss: 2.467436090741298

Epoch: 6| Step: 11
Training loss: 2.971605714296605
Validation loss: 2.47211253057388

Epoch: 6| Step: 12
Training loss: 2.394052180646539
Validation loss: 2.470470987504348

Epoch: 6| Step: 13
Training loss: 2.364661956241814
Validation loss: 2.4622580401318728

Epoch: 100| Step: 0
Training loss: 2.6369736385770977
Validation loss: 2.4671362016533758

Epoch: 6| Step: 1
Training loss: 2.676779545469964
Validation loss: 2.4625415398310073

Epoch: 6| Step: 2
Training loss: 3.281296357326923
Validation loss: 2.4595513209110544

Epoch: 6| Step: 3
Training loss: 2.188096210428721
Validation loss: 2.462391725409223

Epoch: 6| Step: 4
Training loss: 2.5797363794179593
Validation loss: 2.4727921531415755

Epoch: 6| Step: 5
Training loss: 2.9086795619014554
Validation loss: 2.462551576619666

Epoch: 6| Step: 6
Training loss: 2.2882661964179225
Validation loss: 2.474311021795262

Epoch: 6| Step: 7
Training loss: 2.588836151708301
Validation loss: 2.4650406957778657

Epoch: 6| Step: 8
Training loss: 2.9614267070922913
Validation loss: 2.4677158394781635

Epoch: 6| Step: 9
Training loss: 1.9044924904536793
Validation loss: 2.4679045376298996

Epoch: 6| Step: 10
Training loss: 2.3066281181855577
Validation loss: 2.4665477362090655

Epoch: 6| Step: 11
Training loss: 2.719831580389417
Validation loss: 2.4723937350748333

Epoch: 6| Step: 12
Training loss: 2.7795590178552128
Validation loss: 2.4726379779544323

Epoch: 6| Step: 13
Training loss: 1.5045097428295109
Validation loss: 2.4770438672112176

Epoch: 101| Step: 0
Training loss: 1.93210126516272
Validation loss: 2.4749072426776313

Epoch: 6| Step: 1
Training loss: 2.6662560881998094
Validation loss: 2.4769603838832026

Epoch: 6| Step: 2
Training loss: 2.2250993170699584
Validation loss: 2.476540951479638

Epoch: 6| Step: 3
Training loss: 2.928932845513087
Validation loss: 2.477107873468354

Epoch: 6| Step: 4
Training loss: 2.244181314735283
Validation loss: 2.466845538338167

Epoch: 6| Step: 5
Training loss: 2.590250711126334
Validation loss: 2.472185183425028

Epoch: 6| Step: 6
Training loss: 2.4711637648035443
Validation loss: 2.475052157407971

Epoch: 6| Step: 7
Training loss: 3.0959897651700334
Validation loss: 2.477323060323742

Epoch: 6| Step: 8
Training loss: 2.362645995457956
Validation loss: 2.4717810328804712

Epoch: 6| Step: 9
Training loss: 2.345215097904291
Validation loss: 2.479735258492219

Epoch: 6| Step: 10
Training loss: 2.976077703610039
Validation loss: 2.473278118114451

Epoch: 6| Step: 11
Training loss: 2.750628052865596
Validation loss: 2.474083302336407

Epoch: 6| Step: 12
Training loss: 2.052229190296643
Validation loss: 2.471314993019609

Epoch: 6| Step: 13
Training loss: 2.570018809505755
Validation loss: 2.4692320051334122

Epoch: 102| Step: 0
Training loss: 2.327153969844977
Validation loss: 2.4628164071969043

Epoch: 6| Step: 1
Training loss: 2.8408587503307965
Validation loss: 2.467275476930557

Epoch: 6| Step: 2
Training loss: 2.613587137746323
Validation loss: 2.462575587292142

Epoch: 6| Step: 3
Training loss: 1.8726882670836082
Validation loss: 2.4645968241468807

Epoch: 6| Step: 4
Training loss: 2.8403711052328875
Validation loss: 2.468492969379557

Epoch: 6| Step: 5
Training loss: 2.4372777592996173
Validation loss: 2.476444807174258

Epoch: 6| Step: 6
Training loss: 2.6426499407046795
Validation loss: 2.4760413519046396

Epoch: 6| Step: 7
Training loss: 2.028624730781877
Validation loss: 2.4620850647538117

Epoch: 6| Step: 8
Training loss: 2.8089001823988293
Validation loss: 2.4596872938483423

Epoch: 6| Step: 9
Training loss: 2.78055177989614
Validation loss: 2.4650683736442547

Epoch: 6| Step: 10
Training loss: 2.104599357407532
Validation loss: 2.4609116487305815

Epoch: 6| Step: 11
Training loss: 3.009915496045522
Validation loss: 2.4677618197796747

Epoch: 6| Step: 12
Training loss: 2.7803504432060597
Validation loss: 2.467788670076075

Epoch: 6| Step: 13
Training loss: 2.4899935736822214
Validation loss: 2.46142105922386

Epoch: 103| Step: 0
Training loss: 2.8067228534840294
Validation loss: 2.462835365217987

Epoch: 6| Step: 1
Training loss: 2.565328757947515
Validation loss: 2.4577326822062346

Epoch: 6| Step: 2
Training loss: 2.406413679624796
Validation loss: 2.4729270686311384

Epoch: 6| Step: 3
Training loss: 2.213439280816083
Validation loss: 2.474211659093568

Epoch: 6| Step: 4
Training loss: 2.3718304817133062
Validation loss: 2.474175081629548

Epoch: 6| Step: 5
Training loss: 2.4850079192067995
Validation loss: 2.474797162179577

Epoch: 6| Step: 6
Training loss: 2.569203610059235
Validation loss: 2.46651199560408

Epoch: 6| Step: 7
Training loss: 2.7709474372793137
Validation loss: 2.4641749648039495

Epoch: 6| Step: 8
Training loss: 1.6431277848862547
Validation loss: 2.4717613637776212

Epoch: 6| Step: 9
Training loss: 2.3635295138516677
Validation loss: 2.472997480152336

Epoch: 6| Step: 10
Training loss: 2.924155747603516
Validation loss: 2.4684626898997695

Epoch: 6| Step: 11
Training loss: 2.627011663642609
Validation loss: 2.4725612242459545

Epoch: 6| Step: 12
Training loss: 2.6282645316624382
Validation loss: 2.4651702487281555

Epoch: 6| Step: 13
Training loss: 2.955590566110675
Validation loss: 2.4680644745439864

Epoch: 104| Step: 0
Training loss: 2.3363891981364016
Validation loss: 2.4608933379232365

Epoch: 6| Step: 1
Training loss: 2.630416730927768
Validation loss: 2.4726059653907777

Epoch: 6| Step: 2
Training loss: 2.873113593825079
Validation loss: 2.458003673971817

Epoch: 6| Step: 3
Training loss: 2.8207963438628116
Validation loss: 2.466815609129632

Epoch: 6| Step: 4
Training loss: 2.6387541875982192
Validation loss: 2.454517544294444

Epoch: 6| Step: 5
Training loss: 2.2855991032223115
Validation loss: 2.461659078420601

Epoch: 6| Step: 6
Training loss: 2.156402361365801
Validation loss: 2.4586807964485073

Epoch: 6| Step: 7
Training loss: 2.1407065271598547
Validation loss: 2.4584802055666266

Epoch: 6| Step: 8
Training loss: 2.6485905335810584
Validation loss: 2.4558045964608692

Epoch: 6| Step: 9
Training loss: 2.740531747551628
Validation loss: 2.4591199995538258

Epoch: 6| Step: 10
Training loss: 2.837847106137845
Validation loss: 2.4680159559944856

Epoch: 6| Step: 11
Training loss: 2.3624950267598117
Validation loss: 2.456126051890428

Epoch: 6| Step: 12
Training loss: 2.5715574826367633
Validation loss: 2.458163309413859

Epoch: 6| Step: 13
Training loss: 2.41141994986804
Validation loss: 2.462208495338031

Epoch: 105| Step: 0
Training loss: 2.7161274681067806
Validation loss: 2.4572912906410886

Epoch: 6| Step: 1
Training loss: 2.9302841189379905
Validation loss: 2.4579641636097636

Epoch: 6| Step: 2
Training loss: 2.7370182885091032
Validation loss: 2.455994929755234

Epoch: 6| Step: 3
Training loss: 2.2167546070791397
Validation loss: 2.457258698125173

Epoch: 6| Step: 4
Training loss: 2.563919604571972
Validation loss: 2.4627580155750204

Epoch: 6| Step: 5
Training loss: 2.4197104348582728
Validation loss: 2.4643977790003557

Epoch: 6| Step: 6
Training loss: 2.1907257274592045
Validation loss: 2.466561872816584

Epoch: 6| Step: 7
Training loss: 2.3961142554958905
Validation loss: 2.4673562924460026

Epoch: 6| Step: 8
Training loss: 2.386430538775463
Validation loss: 2.4696485598348277

Epoch: 6| Step: 9
Training loss: 2.8337301275619122
Validation loss: 2.4678378291120566

Epoch: 6| Step: 10
Training loss: 2.63017707025562
Validation loss: 2.468884476487873

Epoch: 6| Step: 11
Training loss: 2.6894086226006726
Validation loss: 2.4678194086774283

Epoch: 6| Step: 12
Training loss: 2.2228100661435124
Validation loss: 2.4685703646819026

Epoch: 6| Step: 13
Training loss: 2.3182242401511792
Validation loss: 2.4699790888839375

Epoch: 106| Step: 0
Training loss: 2.0275436626206123
Validation loss: 2.4675978857411334

Epoch: 6| Step: 1
Training loss: 2.349781464500093
Validation loss: 2.4708800562857682

Epoch: 6| Step: 2
Training loss: 2.712159862375297
Validation loss: 2.470151310390408

Epoch: 6| Step: 3
Training loss: 2.6340671345838222
Validation loss: 2.4727054408254143

Epoch: 6| Step: 4
Training loss: 2.3753387811865774
Validation loss: 2.4624967771918933

Epoch: 6| Step: 5
Training loss: 2.976296400455892
Validation loss: 2.4611734428530334

Epoch: 6| Step: 6
Training loss: 2.818653749569276
Validation loss: 2.4732357268168843

Epoch: 6| Step: 7
Training loss: 2.5483746004557584
Validation loss: 2.46884185684509

Epoch: 6| Step: 8
Training loss: 2.5935232224197864
Validation loss: 2.4745544732598987

Epoch: 6| Step: 9
Training loss: 2.64982546105589
Validation loss: 2.4730638727489604

Epoch: 6| Step: 10
Training loss: 2.53873927479915
Validation loss: 2.4722081039920916

Epoch: 6| Step: 11
Training loss: 2.3673524704659816
Validation loss: 2.4673223109555256

Epoch: 6| Step: 12
Training loss: 2.373211237234917
Validation loss: 2.4749413608578807

Epoch: 6| Step: 13
Training loss: 2.3199520152161064
Validation loss: 2.467425059243706

Epoch: 107| Step: 0
Training loss: 2.643735419339133
Validation loss: 2.472141567860029

Epoch: 6| Step: 1
Training loss: 2.695849202112801
Validation loss: 2.476121785032912

Epoch: 6| Step: 2
Training loss: 2.7246405268156404
Validation loss: 2.4689577232563735

Epoch: 6| Step: 3
Training loss: 2.1501983639784417
Validation loss: 2.4657381574082122

Epoch: 6| Step: 4
Training loss: 3.3583361061659
Validation loss: 2.468368476649264

Epoch: 6| Step: 5
Training loss: 2.7664716039014157
Validation loss: 2.4678677056697516

Epoch: 6| Step: 6
Training loss: 2.1898765732982572
Validation loss: 2.470861907802334

Epoch: 6| Step: 7
Training loss: 1.9127496693523232
Validation loss: 2.466885631310604

Epoch: 6| Step: 8
Training loss: 2.467408986988137
Validation loss: 2.4717879455643685

Epoch: 6| Step: 9
Training loss: 2.5257089507176698
Validation loss: 2.472320598140382

Epoch: 6| Step: 10
Training loss: 2.4417753627221876
Validation loss: 2.4762448850267895

Epoch: 6| Step: 11
Training loss: 1.8927988842843992
Validation loss: 2.477791514332456

Epoch: 6| Step: 12
Training loss: 2.5534482977693327
Validation loss: 2.4647753787142697

Epoch: 6| Step: 13
Training loss: 2.704762133929961
Validation loss: 2.469056878955183

Epoch: 108| Step: 0
Training loss: 2.5922315817977055
Validation loss: 2.4799204943843685

Epoch: 6| Step: 1
Training loss: 2.6211523285415796
Validation loss: 2.4733070292535038

Epoch: 6| Step: 2
Training loss: 2.433894988346978
Validation loss: 2.4665239736378015

Epoch: 6| Step: 3
Training loss: 2.824645879375337
Validation loss: 2.461451772411211

Epoch: 6| Step: 4
Training loss: 2.701241250295383
Validation loss: 2.457925865111723

Epoch: 6| Step: 5
Training loss: 2.6863930662602997
Validation loss: 2.47023101035244

Epoch: 6| Step: 6
Training loss: 1.9486598128908321
Validation loss: 2.463230086469853

Epoch: 6| Step: 7
Training loss: 2.481845935967406
Validation loss: 2.4617137027948215

Epoch: 6| Step: 8
Training loss: 2.8687483777143425
Validation loss: 2.4615254986403334

Epoch: 6| Step: 9
Training loss: 2.5804513319156976
Validation loss: 2.462530034587254

Epoch: 6| Step: 10
Training loss: 2.221686555621252
Validation loss: 2.4722424362251556

Epoch: 6| Step: 11
Training loss: 2.0203285635584685
Validation loss: 2.4653487375879157

Epoch: 6| Step: 12
Training loss: 2.7371607078114657
Validation loss: 2.4649059934661537

Epoch: 6| Step: 13
Training loss: 2.5091415163635955
Validation loss: 2.463761702235078

Epoch: 109| Step: 0
Training loss: 2.5373986059517413
Validation loss: 2.4666270370994363

Epoch: 6| Step: 1
Training loss: 2.3739298366986064
Validation loss: 2.4677332301324415

Epoch: 6| Step: 2
Training loss: 2.6304330459133918
Validation loss: 2.470300356637833

Epoch: 6| Step: 3
Training loss: 2.4339676718214487
Validation loss: 2.4711390174870673

Epoch: 6| Step: 4
Training loss: 3.099495840607369
Validation loss: 2.4776541052043584

Epoch: 6| Step: 5
Training loss: 2.222078325328075
Validation loss: 2.481024299945399

Epoch: 6| Step: 6
Training loss: 2.4218443837845567
Validation loss: 2.4820507221300616

Epoch: 6| Step: 7
Training loss: 2.660110719714068
Validation loss: 2.473844655420059

Epoch: 6| Step: 8
Training loss: 2.7273586389708355
Validation loss: 2.472137814651259

Epoch: 6| Step: 9
Training loss: 2.125818880162391
Validation loss: 2.4746403179125918

Epoch: 6| Step: 10
Training loss: 2.5695989946045104
Validation loss: 2.4660658751230824

Epoch: 6| Step: 11
Training loss: 2.691457363136066
Validation loss: 2.4614255229513686

Epoch: 6| Step: 12
Training loss: 2.7554818049511764
Validation loss: 2.463626365469111

Epoch: 6| Step: 13
Training loss: 2.424658572357123
Validation loss: 2.4646032571726244

Epoch: 110| Step: 0
Training loss: 2.5882249378695836
Validation loss: 2.469290468955498

Epoch: 6| Step: 1
Training loss: 2.1585524056306817
Validation loss: 2.455378058621055

Epoch: 6| Step: 2
Training loss: 2.6727863564445333
Validation loss: 2.4619102210670976

Epoch: 6| Step: 3
Training loss: 2.5376921256858695
Validation loss: 2.4785954006894735

Epoch: 6| Step: 4
Training loss: 2.1637914604917614
Validation loss: 2.480154391015511

Epoch: 6| Step: 5
Training loss: 2.353601325916303
Validation loss: 2.4727787833163077

Epoch: 6| Step: 6
Training loss: 2.2637428621446043
Validation loss: 2.457046112516944

Epoch: 6| Step: 7
Training loss: 2.262661067224399
Validation loss: 2.4632591155421126

Epoch: 6| Step: 8
Training loss: 2.4929963237369637
Validation loss: 2.4736626110347797

Epoch: 6| Step: 9
Training loss: 2.7771466449485214
Validation loss: 2.480033664141613

Epoch: 6| Step: 10
Training loss: 3.1342843039750767
Validation loss: 2.48322557454495

Epoch: 6| Step: 11
Training loss: 2.7254698567015594
Validation loss: 2.480973816561912

Epoch: 6| Step: 12
Training loss: 2.9599354842604066
Validation loss: 2.4812377538627057

Epoch: 6| Step: 13
Training loss: 2.619657893522637
Validation loss: 2.482624052725139

Epoch: 111| Step: 0
Training loss: 2.022540626447915
Validation loss: 2.48576834131292

Epoch: 6| Step: 1
Training loss: 2.6076389408125675
Validation loss: 2.4867736784772605

Epoch: 6| Step: 2
Training loss: 2.802530123083389
Validation loss: 2.4846583910521853

Epoch: 6| Step: 3
Training loss: 2.296880397660537
Validation loss: 2.488555717401982

Epoch: 6| Step: 4
Training loss: 2.1751633593718
Validation loss: 2.488938209446165

Epoch: 6| Step: 5
Training loss: 2.6298621425106754
Validation loss: 2.4883007805345754

Epoch: 6| Step: 6
Training loss: 2.923743644925991
Validation loss: 2.4875614835977737

Epoch: 6| Step: 7
Training loss: 3.027555751145459
Validation loss: 2.4813451945687395

Epoch: 6| Step: 8
Training loss: 2.1897375379778947
Validation loss: 2.4895530815893494

Epoch: 6| Step: 9
Training loss: 2.0673595169477545
Validation loss: 2.483952484350067

Epoch: 6| Step: 10
Training loss: 2.681510283101011
Validation loss: 2.483016116301599

Epoch: 6| Step: 11
Training loss: 2.940458228543816
Validation loss: 2.483637718346672

Epoch: 6| Step: 12
Training loss: 3.0495040115052356
Validation loss: 2.481748267942129

Epoch: 6| Step: 13
Training loss: 2.418322511101486
Validation loss: 2.4737151551776297

Epoch: 112| Step: 0
Training loss: 2.3468211080202335
Validation loss: 2.4766864444752463

Epoch: 6| Step: 1
Training loss: 2.875594036264745
Validation loss: 2.4725041556122522

Epoch: 6| Step: 2
Training loss: 2.094823647407823
Validation loss: 2.4691094728305205

Epoch: 6| Step: 3
Training loss: 2.281656307459801
Validation loss: 2.466545698275488

Epoch: 6| Step: 4
Training loss: 2.196376881893933
Validation loss: 2.463649422114982

Epoch: 6| Step: 5
Training loss: 2.7957282246039523
Validation loss: 2.458233529559597

Epoch: 6| Step: 6
Training loss: 2.3517943613307395
Validation loss: 2.472057798420804

Epoch: 6| Step: 7
Training loss: 2.422729636725831
Validation loss: 2.483127416697076

Epoch: 6| Step: 8
Training loss: 2.341361901846855
Validation loss: 2.492078756831953

Epoch: 6| Step: 9
Training loss: 2.2594921371887042
Validation loss: 2.472333006097056

Epoch: 6| Step: 10
Training loss: 2.559724560761437
Validation loss: 2.4792146170544376

Epoch: 6| Step: 11
Training loss: 2.9953695165453986
Validation loss: 2.4630414012604867

Epoch: 6| Step: 12
Training loss: 2.711167823175759
Validation loss: 2.467375094799448

Epoch: 6| Step: 13
Training loss: 3.1318435502324067
Validation loss: 2.4626049871381346

Epoch: 113| Step: 0
Training loss: 1.940697093367787
Validation loss: 2.4820199836696992

Epoch: 6| Step: 1
Training loss: 2.130471086658166
Validation loss: 2.4760915186037007

Epoch: 6| Step: 2
Training loss: 2.7849036231906132
Validation loss: 2.4769093604523653

Epoch: 6| Step: 3
Training loss: 2.306480615348738
Validation loss: 2.476698942868338

Epoch: 6| Step: 4
Training loss: 2.8946576007236584
Validation loss: 2.4771312938909946

Epoch: 6| Step: 5
Training loss: 2.8559262682803133
Validation loss: 2.472034120964105

Epoch: 6| Step: 6
Training loss: 2.213292030768727
Validation loss: 2.473827404104634

Epoch: 6| Step: 7
Training loss: 2.9164436981715407
Validation loss: 2.4740821298778792

Epoch: 6| Step: 8
Training loss: 2.705821902485223
Validation loss: 2.474409320616082

Epoch: 6| Step: 9
Training loss: 2.659238502953125
Validation loss: 2.471937045843005

Epoch: 6| Step: 10
Training loss: 2.2647691886131907
Validation loss: 2.4674906838501105

Epoch: 6| Step: 11
Training loss: 2.72723834998688
Validation loss: 2.4734716692982364

Epoch: 6| Step: 12
Training loss: 2.4005285833333945
Validation loss: 2.47578518258181

Epoch: 6| Step: 13
Training loss: 2.3787160211683096
Validation loss: 2.4720790645378834

Epoch: 114| Step: 0
Training loss: 2.667115819377897
Validation loss: 2.4664283169039267

Epoch: 6| Step: 1
Training loss: 1.9723033022743002
Validation loss: 2.47218587458128

Epoch: 6| Step: 2
Training loss: 2.8845565193234446
Validation loss: 2.458690558088172

Epoch: 6| Step: 3
Training loss: 2.107429568017701
Validation loss: 2.4669445534278838

Epoch: 6| Step: 4
Training loss: 2.7058742412094325
Validation loss: 2.4618748731468667

Epoch: 6| Step: 5
Training loss: 2.335064268677627
Validation loss: 2.459065123654529

Epoch: 6| Step: 6
Training loss: 2.254169204155792
Validation loss: 2.47121969057469

Epoch: 6| Step: 7
Training loss: 2.3581119213252144
Validation loss: 2.460067159154658

Epoch: 6| Step: 8
Training loss: 2.5644506147943256
Validation loss: 2.462863680969207

Epoch: 6| Step: 9
Training loss: 2.7500961460298887
Validation loss: 2.4621601115446143

Epoch: 6| Step: 10
Training loss: 2.892399258849859
Validation loss: 2.4682923790159066

Epoch: 6| Step: 11
Training loss: 2.904540184516592
Validation loss: 2.479041975288952

Epoch: 6| Step: 12
Training loss: 2.2017151129236865
Validation loss: 2.4776815699980994

Epoch: 6| Step: 13
Training loss: 2.385086125512209
Validation loss: 2.477921362804502

Epoch: 115| Step: 0
Training loss: 2.9668184120144874
Validation loss: 2.4752090478202593

Epoch: 6| Step: 1
Training loss: 2.6768136587513855
Validation loss: 2.480599067048165

Epoch: 6| Step: 2
Training loss: 2.5013157243305377
Validation loss: 2.4818607459471114

Epoch: 6| Step: 3
Training loss: 2.312040747326345
Validation loss: 2.470858450167422

Epoch: 6| Step: 4
Training loss: 2.7326238637982643
Validation loss: 2.476242686579722

Epoch: 6| Step: 5
Training loss: 2.5794704741067167
Validation loss: 2.474023883687334

Epoch: 6| Step: 6
Training loss: 2.9185316571859525
Validation loss: 2.482465854178168

Epoch: 6| Step: 7
Training loss: 2.3038212586847475
Validation loss: 2.469374887435371

Epoch: 6| Step: 8
Training loss: 2.923927443046374
Validation loss: 2.4685511126662014

Epoch: 6| Step: 9
Training loss: 2.2003788708522376
Validation loss: 2.4773051114228517

Epoch: 6| Step: 10
Training loss: 2.333874151587964
Validation loss: 2.4659519193169137

Epoch: 6| Step: 11
Training loss: 2.5591893092646147
Validation loss: 2.473135983501599

Epoch: 6| Step: 12
Training loss: 1.7892904344642757
Validation loss: 2.482118617557257

Epoch: 6| Step: 13
Training loss: 2.0914626651489416
Validation loss: 2.4952396051743064

Epoch: 116| Step: 0
Training loss: 3.0437698582935515
Validation loss: 2.489982705956269

Epoch: 6| Step: 1
Training loss: 2.5689206514499516
Validation loss: 2.484129727649978

Epoch: 6| Step: 2
Training loss: 2.3960531603817743
Validation loss: 2.470425097838828

Epoch: 6| Step: 3
Training loss: 2.0044104107356677
Validation loss: 2.4584201915935475

Epoch: 6| Step: 4
Training loss: 2.3202311183644944
Validation loss: 2.4596122119967454

Epoch: 6| Step: 5
Training loss: 2.423088311248958
Validation loss: 2.467579721169788

Epoch: 6| Step: 6
Training loss: 2.47754040974786
Validation loss: 2.461364014817995

Epoch: 6| Step: 7
Training loss: 2.1985535504931386
Validation loss: 2.4788459014679978

Epoch: 6| Step: 8
Training loss: 2.7898465291407066
Validation loss: 2.473506514132052

Epoch: 6| Step: 9
Training loss: 2.4134058383285883
Validation loss: 2.4657142581101947

Epoch: 6| Step: 10
Training loss: 3.1379506125712107
Validation loss: 2.473321970693325

Epoch: 6| Step: 11
Training loss: 2.77973553861007
Validation loss: 2.480751337890305

Epoch: 6| Step: 12
Training loss: 2.484041011600745
Validation loss: 2.480137247676757

Epoch: 6| Step: 13
Training loss: 2.3450959473524358
Validation loss: 2.4723663883345655

Epoch: 117| Step: 0
Training loss: 2.7830588641340936
Validation loss: 2.4787877752311545

Epoch: 6| Step: 1
Training loss: 2.826082113510626
Validation loss: 2.472189041038846

Epoch: 6| Step: 2
Training loss: 2.747672569957486
Validation loss: 2.4696454544797146

Epoch: 6| Step: 3
Training loss: 2.289956396762232
Validation loss: 2.4707502157073606

Epoch: 6| Step: 4
Training loss: 2.0953778443754394
Validation loss: 2.4728814655766995

Epoch: 6| Step: 5
Training loss: 2.467894973449151
Validation loss: 2.4716754914801653

Epoch: 6| Step: 6
Training loss: 2.2549493184283365
Validation loss: 2.468955115959791

Epoch: 6| Step: 7
Training loss: 2.6233717091656463
Validation loss: 2.4676329906508094

Epoch: 6| Step: 8
Training loss: 2.833832939828912
Validation loss: 2.4625586765740772

Epoch: 6| Step: 9
Training loss: 2.2497223576800556
Validation loss: 2.4656473130577115

Epoch: 6| Step: 10
Training loss: 2.302685712020267
Validation loss: 2.4871690980508734

Epoch: 6| Step: 11
Training loss: 2.3280301682788616
Validation loss: 2.4901632859797918

Epoch: 6| Step: 12
Training loss: 2.3765209748642504
Validation loss: 2.4810685201108793

Epoch: 6| Step: 13
Training loss: 2.757515002406129
Validation loss: 2.472123975146979

Epoch: 118| Step: 0
Training loss: 2.071693161569681
Validation loss: 2.4730172438657267

Epoch: 6| Step: 1
Training loss: 2.3339200190525964
Validation loss: 2.475576338790152

Epoch: 6| Step: 2
Training loss: 2.6272939921739775
Validation loss: 2.4654235641523123

Epoch: 6| Step: 3
Training loss: 2.828856484250109
Validation loss: 2.467968652106743

Epoch: 6| Step: 4
Training loss: 2.331038322758854
Validation loss: 2.464439137212972

Epoch: 6| Step: 5
Training loss: 2.608676931238034
Validation loss: 2.4677914476762703

Epoch: 6| Step: 6
Training loss: 2.945762539183337
Validation loss: 2.4652680335650747

Epoch: 6| Step: 7
Training loss: 2.580889520112563
Validation loss: 2.47417171695751

Epoch: 6| Step: 8
Training loss: 2.5166671205566535
Validation loss: 2.481364923821671

Epoch: 6| Step: 9
Training loss: 1.7598471162241054
Validation loss: 2.4832100206093055

Epoch: 6| Step: 10
Training loss: 2.3335469238977637
Validation loss: 2.4875529055184935

Epoch: 6| Step: 11
Training loss: 2.4427394797176967
Validation loss: 2.4860836527164643

Epoch: 6| Step: 12
Training loss: 2.4369553177485885
Validation loss: 2.484841932646183

Epoch: 6| Step: 13
Training loss: 3.1546409206720987
Validation loss: 2.4841646229341943

Epoch: 119| Step: 0
Training loss: 2.2598503446400335
Validation loss: 2.483382884647032

Epoch: 6| Step: 1
Training loss: 2.637324962864325
Validation loss: 2.482886262201687

Epoch: 6| Step: 2
Training loss: 3.1052129292232813
Validation loss: 2.485989076281951

Epoch: 6| Step: 3
Training loss: 2.7919157590809296
Validation loss: 2.486054514543236

Epoch: 6| Step: 4
Training loss: 2.017637091307666
Validation loss: 2.484804400236586

Epoch: 6| Step: 5
Training loss: 2.510249109862783
Validation loss: 2.4769809180910616

Epoch: 6| Step: 6
Training loss: 2.572243101677444
Validation loss: 2.463010135164109

Epoch: 6| Step: 7
Training loss: 2.3673484420201136
Validation loss: 2.466466757260025

Epoch: 6| Step: 8
Training loss: 2.7539803569372974
Validation loss: 2.46456402996519

Epoch: 6| Step: 9
Training loss: 2.778565300462951
Validation loss: 2.4746274879713983

Epoch: 6| Step: 10
Training loss: 2.6835389332954445
Validation loss: 2.4742460518557157

Epoch: 6| Step: 11
Training loss: 2.5770493546519933
Validation loss: 2.4603166876970906

Epoch: 6| Step: 12
Training loss: 2.1745705103771757
Validation loss: 2.4723139601794433

Epoch: 6| Step: 13
Training loss: 1.9472734609922577
Validation loss: 2.4759804074663117

Epoch: 120| Step: 0
Training loss: 2.056208986377698
Validation loss: 2.458179539110118

Epoch: 6| Step: 1
Training loss: 2.192775686019434
Validation loss: 2.474418233320486

Epoch: 6| Step: 2
Training loss: 2.1445360305260355
Validation loss: 2.4702103717756185

Epoch: 6| Step: 3
Training loss: 2.463215285463596
Validation loss: 2.4673818185184695

Epoch: 6| Step: 4
Training loss: 2.4022752705559998
Validation loss: 2.4735971822982505

Epoch: 6| Step: 5
Training loss: 2.498126472356275
Validation loss: 2.470626632853299

Epoch: 6| Step: 6
Training loss: 3.269335377430653
Validation loss: 2.4697319524446506

Epoch: 6| Step: 7
Training loss: 2.782648485031402
Validation loss: 2.46463002902047

Epoch: 6| Step: 8
Training loss: 2.829215835196471
Validation loss: 2.4602067457847525

Epoch: 6| Step: 9
Training loss: 2.46890702532907
Validation loss: 2.474414684301498

Epoch: 6| Step: 10
Training loss: 2.405635606678439
Validation loss: 2.4654467732229506

Epoch: 6| Step: 11
Training loss: 2.3806644951390203
Validation loss: 2.4670695931605486

Epoch: 6| Step: 12
Training loss: 2.5210420086034
Validation loss: 2.4714902807496464

Epoch: 6| Step: 13
Training loss: 2.458211109118708
Validation loss: 2.4699921521102053

Epoch: 121| Step: 0
Training loss: 2.1094102644621695
Validation loss: 2.4747176333590044

Epoch: 6| Step: 1
Training loss: 2.9792756458614966
Validation loss: 2.46700587410415

Epoch: 6| Step: 2
Training loss: 1.7730891351901477
Validation loss: 2.47336656151821

Epoch: 6| Step: 3
Training loss: 2.6343840937157696
Validation loss: 2.4759720861672267

Epoch: 6| Step: 4
Training loss: 2.681328540709828
Validation loss: 2.476389721480243

Epoch: 6| Step: 5
Training loss: 2.0802557784317606
Validation loss: 2.4733101460774334

Epoch: 6| Step: 6
Training loss: 2.607309494739948
Validation loss: 2.4723376188837234

Epoch: 6| Step: 7
Training loss: 2.466171076536978
Validation loss: 2.469604746613772

Epoch: 6| Step: 8
Training loss: 2.9561140484831028
Validation loss: 2.4667810241721537

Epoch: 6| Step: 9
Training loss: 2.0865681012958133
Validation loss: 2.4728007020784974

Epoch: 6| Step: 10
Training loss: 3.0606712019060063
Validation loss: 2.471857505379557

Epoch: 6| Step: 11
Training loss: 2.0678317195742246
Validation loss: 2.4728224920923183

Epoch: 6| Step: 12
Training loss: 2.758023694302451
Validation loss: 2.4730046947294313

Epoch: 6| Step: 13
Training loss: 2.4524807418082673
Validation loss: 2.4720467553989547

Epoch: 122| Step: 0
Training loss: 2.4831723355155746
Validation loss: 2.4634133615343097

Epoch: 6| Step: 1
Training loss: 2.6772885274855076
Validation loss: 2.4646447570404093

Epoch: 6| Step: 2
Training loss: 2.709824391267144
Validation loss: 2.4645035836953535

Epoch: 6| Step: 3
Training loss: 2.5415129589025853
Validation loss: 2.4709561224710455

Epoch: 6| Step: 4
Training loss: 2.911427142272453
Validation loss: 2.464761159312159

Epoch: 6| Step: 5
Training loss: 2.470310731871501
Validation loss: 2.467039457280093

Epoch: 6| Step: 6
Training loss: 2.5247200461319137
Validation loss: 2.462067230717677

Epoch: 6| Step: 7
Training loss: 2.101331393215975
Validation loss: 2.467485208489564

Epoch: 6| Step: 8
Training loss: 2.505611701791119
Validation loss: 2.4673732185967387

Epoch: 6| Step: 9
Training loss: 2.8282185744511694
Validation loss: 2.472271769333106

Epoch: 6| Step: 10
Training loss: 2.175760868326328
Validation loss: 2.4688496790854084

Epoch: 6| Step: 11
Training loss: 1.8784248861607424
Validation loss: 2.4638395767791685

Epoch: 6| Step: 12
Training loss: 2.3069067663394556
Validation loss: 2.472763099390682

Epoch: 6| Step: 13
Training loss: 2.81333029465112
Validation loss: 2.4717776729875953

Epoch: 123| Step: 0
Training loss: 1.9535006962880637
Validation loss: 2.4736061300572283

Epoch: 6| Step: 1
Training loss: 2.621652375910038
Validation loss: 2.4735797846778236

Epoch: 6| Step: 2
Training loss: 2.38857495539399
Validation loss: 2.47800495807828

Epoch: 6| Step: 3
Training loss: 1.903746477450683
Validation loss: 2.475552759192733

Epoch: 6| Step: 4
Training loss: 2.932724337505133
Validation loss: 2.482244397693953

Epoch: 6| Step: 5
Training loss: 2.3359496457603868
Validation loss: 2.4646122617681776

Epoch: 6| Step: 6
Training loss: 2.9675046215969436
Validation loss: 2.4763382450140115

Epoch: 6| Step: 7
Training loss: 2.4546362237170074
Validation loss: 2.4780260288379106

Epoch: 6| Step: 8
Training loss: 2.8880059001365685
Validation loss: 2.481267797372634

Epoch: 6| Step: 9
Training loss: 2.532579990942529
Validation loss: 2.4846085092779964

Epoch: 6| Step: 10
Training loss: 1.805108223626807
Validation loss: 2.4858315474627077

Epoch: 6| Step: 11
Training loss: 2.5672946826294165
Validation loss: 2.486865037359821

Epoch: 6| Step: 12
Training loss: 2.602703955259442
Validation loss: 2.481888860649241

Epoch: 6| Step: 13
Training loss: 3.0041381587678906
Validation loss: 2.4709734501170733

Epoch: 124| Step: 0
Training loss: 2.1262298839588576
Validation loss: 2.464129167524502

Epoch: 6| Step: 1
Training loss: 2.7054724230343425
Validation loss: 2.4735670616868073

Epoch: 6| Step: 2
Training loss: 2.460765239196735
Validation loss: 2.478734184390379

Epoch: 6| Step: 3
Training loss: 2.294245661677914
Validation loss: 2.492687545883109

Epoch: 6| Step: 4
Training loss: 2.3587532487370813
Validation loss: 2.4896957712573533

Epoch: 6| Step: 5
Training loss: 2.34728635390612
Validation loss: 2.4685185480871654

Epoch: 6| Step: 6
Training loss: 2.432742047866966
Validation loss: 2.475353696063172

Epoch: 6| Step: 7
Training loss: 2.286576206468055
Validation loss: 2.4582852558240824

Epoch: 6| Step: 8
Training loss: 1.944915485850434
Validation loss: 2.470711520335292

Epoch: 6| Step: 9
Training loss: 3.1288195346812553
Validation loss: 2.469953557477464

Epoch: 6| Step: 10
Training loss: 2.308456390993482
Validation loss: 2.4641076715360906

Epoch: 6| Step: 11
Training loss: 2.863496571936603
Validation loss: 2.464477673090528

Epoch: 6| Step: 12
Training loss: 2.602084637273294
Validation loss: 2.4821975810770627

Epoch: 6| Step: 13
Training loss: 3.0893671606212494
Validation loss: 2.4823648249615813

Epoch: 125| Step: 0
Training loss: 2.3785556478480103
Validation loss: 2.4821092682382626

Epoch: 6| Step: 1
Training loss: 2.612255402572467
Validation loss: 2.4842579972008325

Epoch: 6| Step: 2
Training loss: 2.757253184888873
Validation loss: 2.4813875514161996

Epoch: 6| Step: 3
Training loss: 2.511360297128269
Validation loss: 2.4844348988219793

Epoch: 6| Step: 4
Training loss: 2.0063014894337057
Validation loss: 2.4797524526831163

Epoch: 6| Step: 5
Training loss: 2.8340274484149126
Validation loss: 2.475380744932424

Epoch: 6| Step: 6
Training loss: 2.3631160962114377
Validation loss: 2.4709594754403383

Epoch: 6| Step: 7
Training loss: 2.034216021113943
Validation loss: 2.476676561233998

Epoch: 6| Step: 8
Training loss: 2.9985961808463193
Validation loss: 2.4730316246798516

Epoch: 6| Step: 9
Training loss: 2.5134355957145456
Validation loss: 2.4874649904813007

Epoch: 6| Step: 10
Training loss: 2.2600981550928925
Validation loss: 2.4709475912744634

Epoch: 6| Step: 11
Training loss: 3.1258807657728425
Validation loss: 2.475926988572872

Epoch: 6| Step: 12
Training loss: 1.9839960772760128
Validation loss: 2.491718148387539

Epoch: 6| Step: 13
Training loss: 2.5605170788693523
Validation loss: 2.475355847141337

Epoch: 126| Step: 0
Training loss: 2.627011482129454
Validation loss: 2.4768386991659335

Epoch: 6| Step: 1
Training loss: 2.327609216276712
Validation loss: 2.4699191049438305

Epoch: 6| Step: 2
Training loss: 2.6646832500829634
Validation loss: 2.4740115725494087

Epoch: 6| Step: 3
Training loss: 2.7024486776131487
Validation loss: 2.4723229447276367

Epoch: 6| Step: 4
Training loss: 2.6707948877321948
Validation loss: 2.4802018149614824

Epoch: 6| Step: 5
Training loss: 2.8439797109532052
Validation loss: 2.4671291631912906

Epoch: 6| Step: 6
Training loss: 2.544079234868638
Validation loss: 2.4731367948962784

Epoch: 6| Step: 7
Training loss: 2.459887277455137
Validation loss: 2.474503906057814

Epoch: 6| Step: 8
Training loss: 2.797684536353878
Validation loss: 2.4749666802574954

Epoch: 6| Step: 9
Training loss: 2.155713332465901
Validation loss: 2.4740480962162716

Epoch: 6| Step: 10
Training loss: 2.7286430225380895
Validation loss: 2.475222717565292

Epoch: 6| Step: 11
Training loss: 1.9815371187994262
Validation loss: 2.4735346916608245

Epoch: 6| Step: 12
Training loss: 2.316638233733021
Validation loss: 2.478257715199934

Epoch: 6| Step: 13
Training loss: 2.4259254302147557
Validation loss: 2.477663359069601

Epoch: 127| Step: 0
Training loss: 2.182043845976556
Validation loss: 2.476085388242654

Epoch: 6| Step: 1
Training loss: 2.4811797317048496
Validation loss: 2.465344071429675

Epoch: 6| Step: 2
Training loss: 2.5998815656243726
Validation loss: 2.4641905421352903

Epoch: 6| Step: 3
Training loss: 2.525188771358223
Validation loss: 2.4660484565971603

Epoch: 6| Step: 4
Training loss: 2.489750738115275
Validation loss: 2.4649902074540666

Epoch: 6| Step: 5
Training loss: 2.8621024376259414
Validation loss: 2.461376720167302

Epoch: 6| Step: 6
Training loss: 2.571901242016836
Validation loss: 2.480177165837873

Epoch: 6| Step: 7
Training loss: 2.6259035644372246
Validation loss: 2.4771563823720624

Epoch: 6| Step: 8
Training loss: 2.651248306784658
Validation loss: 2.4757811780957444

Epoch: 6| Step: 9
Training loss: 2.248236282814112
Validation loss: 2.4831098618115153

Epoch: 6| Step: 10
Training loss: 2.4439157024898517
Validation loss: 2.5061832257362817

Epoch: 6| Step: 11
Training loss: 2.826857393400971
Validation loss: 2.490342496631532

Epoch: 6| Step: 12
Training loss: 2.425627428666442
Validation loss: 2.489634562541217

Epoch: 6| Step: 13
Training loss: 2.277353590981632
Validation loss: 2.468167964715578

Epoch: 128| Step: 0
Training loss: 3.073034734666816
Validation loss: 2.468056818868094

Epoch: 6| Step: 1
Training loss: 2.927038353046068
Validation loss: 2.476740673246439

Epoch: 6| Step: 2
Training loss: 2.6962513933103
Validation loss: 2.47394453078318

Epoch: 6| Step: 3
Training loss: 1.9501421925469264
Validation loss: 2.4786731057705005

Epoch: 6| Step: 4
Training loss: 2.777814135843328
Validation loss: 2.4826217959037127

Epoch: 6| Step: 5
Training loss: 1.6785862350970315
Validation loss: 2.4748372788674513

Epoch: 6| Step: 6
Training loss: 2.748575188254948
Validation loss: 2.476840832911218

Epoch: 6| Step: 7
Training loss: 2.3743851518326093
Validation loss: 2.4762014452766414

Epoch: 6| Step: 8
Training loss: 2.3556280635774347
Validation loss: 2.4784065224572984

Epoch: 6| Step: 9
Training loss: 2.395485717323193
Validation loss: 2.4659289728275953

Epoch: 6| Step: 10
Training loss: 2.6456583120374284
Validation loss: 2.476104108263547

Epoch: 6| Step: 11
Training loss: 2.290846614343531
Validation loss: 2.481166150832693

Epoch: 6| Step: 12
Training loss: 2.004777209682269
Validation loss: 2.472468621646604

Epoch: 6| Step: 13
Training loss: 2.9040180783090017
Validation loss: 2.474619700052248

Epoch: 129| Step: 0
Training loss: 3.0327022259261947
Validation loss: 2.4746922311257102

Epoch: 6| Step: 1
Training loss: 1.9125221126499745
Validation loss: 2.4769165074857775

Epoch: 6| Step: 2
Training loss: 1.6478785430446483
Validation loss: 2.4851287482110127

Epoch: 6| Step: 3
Training loss: 2.8248520770209473
Validation loss: 2.473173227046421

Epoch: 6| Step: 4
Training loss: 2.096364452897577
Validation loss: 2.4662656073536406

Epoch: 6| Step: 5
Training loss: 2.609375913699784
Validation loss: 2.4729638011353647

Epoch: 6| Step: 6
Training loss: 3.1210052897840246
Validation loss: 2.479648644748443

Epoch: 6| Step: 7
Training loss: 2.666684647340554
Validation loss: 2.471473334560954

Epoch: 6| Step: 8
Training loss: 2.7180287950182014
Validation loss: 2.478373686541683

Epoch: 6| Step: 9
Training loss: 2.224419455924074
Validation loss: 2.467876360223456

Epoch: 6| Step: 10
Training loss: 2.8663754677542777
Validation loss: 2.472206440409699

Epoch: 6| Step: 11
Training loss: 1.8098355143716267
Validation loss: 2.4644519798851365

Epoch: 6| Step: 12
Training loss: 2.772646337143716
Validation loss: 2.4655893108071854

Epoch: 6| Step: 13
Training loss: 2.025326940258116
Validation loss: 2.4698515257438776

Epoch: 130| Step: 0
Training loss: 2.318453779604334
Validation loss: 2.4692945081059587

Epoch: 6| Step: 1
Training loss: 2.229028346918991
Validation loss: 2.466290274676447

Epoch: 6| Step: 2
Training loss: 2.225719198511474
Validation loss: 2.473793479379268

Epoch: 6| Step: 3
Training loss: 2.382991796533037
Validation loss: 2.468980416277025

Epoch: 6| Step: 4
Training loss: 2.818782317320975
Validation loss: 2.47891822873762

Epoch: 6| Step: 5
Training loss: 2.3609332061264
Validation loss: 2.4694864647342403

Epoch: 6| Step: 6
Training loss: 2.3730633519232502
Validation loss: 2.476852031033022

Epoch: 6| Step: 7
Training loss: 2.7843850286540777
Validation loss: 2.4723687991671994

Epoch: 6| Step: 8
Training loss: 2.3784111021283807
Validation loss: 2.4836462939490924

Epoch: 6| Step: 9
Training loss: 2.8230905983657006
Validation loss: 2.477986156202762

Epoch: 6| Step: 10
Training loss: 2.8064214505366487
Validation loss: 2.479944729458281

Epoch: 6| Step: 11
Training loss: 2.3759468600434834
Validation loss: 2.4716287077880423

Epoch: 6| Step: 12
Training loss: 1.7161076434859095
Validation loss: 2.4771801231559647

Epoch: 6| Step: 13
Training loss: 2.9151699222093392
Validation loss: 2.4823724125001956

Epoch: 131| Step: 0
Training loss: 2.1511969583412536
Validation loss: 2.488171154323349

Epoch: 6| Step: 1
Training loss: 2.4733999378390954
Validation loss: 2.4821480260588045

Epoch: 6| Step: 2
Training loss: 2.6825050244457618
Validation loss: 2.4841489069202622

Epoch: 6| Step: 3
Training loss: 2.7308637472474295
Validation loss: 2.471893088318383

Epoch: 6| Step: 4
Training loss: 2.35286435815289
Validation loss: 2.48424077021258

Epoch: 6| Step: 5
Training loss: 2.5360021370237957
Validation loss: 2.4725523369897027

Epoch: 6| Step: 6
Training loss: 2.6076822786633875
Validation loss: 2.4736585629530117

Epoch: 6| Step: 7
Training loss: 2.1101293274716615
Validation loss: 2.4832262386254245

Epoch: 6| Step: 8
Training loss: 2.10223616116002
Validation loss: 2.4767980774389406

Epoch: 6| Step: 9
Training loss: 2.2555488405717554
Validation loss: 2.48114968712856

Epoch: 6| Step: 10
Training loss: 2.796204044269649
Validation loss: 2.478852033017204

Epoch: 6| Step: 11
Training loss: 3.079804248038793
Validation loss: 2.483804505301623

Epoch: 6| Step: 12
Training loss: 2.4136306722136647
Validation loss: 2.4804329136139547

Epoch: 6| Step: 13
Training loss: 2.445680828203047
Validation loss: 2.479572717020723

Epoch: 132| Step: 0
Training loss: 2.2890579171509158
Validation loss: 2.478033004278223

Epoch: 6| Step: 1
Training loss: 2.3408586087553607
Validation loss: 2.4763950166919444

Epoch: 6| Step: 2
Training loss: 2.918672326175552
Validation loss: 2.4742142608508706

Epoch: 6| Step: 3
Training loss: 2.604136983066503
Validation loss: 2.4764072758658875

Epoch: 6| Step: 4
Training loss: 2.738255651683577
Validation loss: 2.4718788535967793

Epoch: 6| Step: 5
Training loss: 2.957527229912487
Validation loss: 2.4762454948146817

Epoch: 6| Step: 6
Training loss: 2.6040637390141095
Validation loss: 2.4798550865432265

Epoch: 6| Step: 7
Training loss: 2.6728615528905366
Validation loss: 2.4751182059115195

Epoch: 6| Step: 8
Training loss: 2.62208758868843
Validation loss: 2.480426689852659

Epoch: 6| Step: 9
Training loss: 2.12375290123358
Validation loss: 2.477903466346398

Epoch: 6| Step: 10
Training loss: 1.9196102785913562
Validation loss: 2.4760917753724185

Epoch: 6| Step: 11
Training loss: 2.243294366249659
Validation loss: 2.4720121632557603

Epoch: 6| Step: 12
Training loss: 2.381638935195501
Validation loss: 2.473386667692767

Epoch: 6| Step: 13
Training loss: 2.00664144719816
Validation loss: 2.4821656197644084

Epoch: 133| Step: 0
Training loss: 2.4949939197168054
Validation loss: 2.5106244192517635

Epoch: 6| Step: 1
Training loss: 2.518407952721919
Validation loss: 2.5134662977844897

Epoch: 6| Step: 2
Training loss: 2.480528342665056
Validation loss: 2.48840924167872

Epoch: 6| Step: 3
Training loss: 2.3069463490108206
Validation loss: 2.4850467597404924

Epoch: 6| Step: 4
Training loss: 2.423708805955888
Validation loss: 2.481261311464446

Epoch: 6| Step: 5
Training loss: 2.091378648338535
Validation loss: 2.475335427876244

Epoch: 6| Step: 6
Training loss: 2.2626032178738726
Validation loss: 2.4822723079496947

Epoch: 6| Step: 7
Training loss: 3.109684147634109
Validation loss: 2.4827390518671795

Epoch: 6| Step: 8
Training loss: 2.592441550527535
Validation loss: 2.480639466345803

Epoch: 6| Step: 9
Training loss: 2.1342580738127164
Validation loss: 2.4819642051996915

Epoch: 6| Step: 10
Training loss: 2.431726121739935
Validation loss: 2.474251183025335

Epoch: 6| Step: 11
Training loss: 2.8560329563472653
Validation loss: 2.479525681687994

Epoch: 6| Step: 12
Training loss: 2.666409976843737
Validation loss: 2.475023965045231

Epoch: 6| Step: 13
Training loss: 2.2778382590516415
Validation loss: 2.4813074811527853

Epoch: 134| Step: 0
Training loss: 3.0385198819688704
Validation loss: 2.486305750136623

Epoch: 6| Step: 1
Training loss: 2.9566209878872916
Validation loss: 2.492688087883838

Epoch: 6| Step: 2
Training loss: 2.7240989070138575
Validation loss: 2.490286665224082

Epoch: 6| Step: 3
Training loss: 2.378545423682199
Validation loss: 2.473995848254146

Epoch: 6| Step: 4
Training loss: 2.206336420111892
Validation loss: 2.487612184713656

Epoch: 6| Step: 5
Training loss: 1.9331456137099845
Validation loss: 2.4818227201456926

Epoch: 6| Step: 6
Training loss: 2.627682813532938
Validation loss: 2.4770247452215615

Epoch: 6| Step: 7
Training loss: 2.3340597611387106
Validation loss: 2.472543819336191

Epoch: 6| Step: 8
Training loss: 2.9833182016624717
Validation loss: 2.4762683617522314

Epoch: 6| Step: 9
Training loss: 2.1902032770024533
Validation loss: 2.4849840773104956

Epoch: 6| Step: 10
Training loss: 2.646576624314728
Validation loss: 2.4846962775016714

Epoch: 6| Step: 11
Training loss: 2.4314093177197025
Validation loss: 2.484178603304756

Epoch: 6| Step: 12
Training loss: 2.485480872127253
Validation loss: 2.477991343770727

Epoch: 6| Step: 13
Training loss: 1.5077928927238757
Validation loss: 2.481185497146967

Epoch: 135| Step: 0
Training loss: 2.365935343815833
Validation loss: 2.487663300104516

Epoch: 6| Step: 1
Training loss: 2.6341418976561046
Validation loss: 2.4885374183879327

Epoch: 6| Step: 2
Training loss: 2.6340763669424554
Validation loss: 2.4900310917078756

Epoch: 6| Step: 3
Training loss: 2.7125283446347206
Validation loss: 2.493905785521946

Epoch: 6| Step: 4
Training loss: 2.7428144732630404
Validation loss: 2.48593722314871

Epoch: 6| Step: 5
Training loss: 2.1107332730839676
Validation loss: 2.492936232133695

Epoch: 6| Step: 6
Training loss: 2.1424018557847457
Validation loss: 2.486510472629303

Epoch: 6| Step: 7
Training loss: 2.8669712910220992
Validation loss: 2.4704457507065074

Epoch: 6| Step: 8
Training loss: 2.1881730270454076
Validation loss: 2.4708107343115175

Epoch: 6| Step: 9
Training loss: 2.9087992326859236
Validation loss: 2.4780576346414254

Epoch: 6| Step: 10
Training loss: 2.944251883905959
Validation loss: 2.470373786618037

Epoch: 6| Step: 11
Training loss: 1.8741287114410605
Validation loss: 2.4761585503832646

Epoch: 6| Step: 12
Training loss: 2.2485463426872934
Validation loss: 2.4817859586486284

Epoch: 6| Step: 13
Training loss: 2.0985107954437
Validation loss: 2.47357824250058

Epoch: 136| Step: 0
Training loss: 2.5291464271133597
Validation loss: 2.4793157505975496

Epoch: 6| Step: 1
Training loss: 1.9936220277475527
Validation loss: 2.4766237590285263

Epoch: 6| Step: 2
Training loss: 2.653258849812601
Validation loss: 2.4844432477553884

Epoch: 6| Step: 3
Training loss: 2.7888386954476365
Validation loss: 2.477309714951387

Epoch: 6| Step: 4
Training loss: 2.8938081278225507
Validation loss: 2.476771477226724

Epoch: 6| Step: 5
Training loss: 2.190408353663385
Validation loss: 2.480369778157953

Epoch: 6| Step: 6
Training loss: 2.926011039561829
Validation loss: 2.47677396398967

Epoch: 6| Step: 7
Training loss: 2.833740896943173
Validation loss: 2.470314849781621

Epoch: 6| Step: 8
Training loss: 2.452060930338255
Validation loss: 2.4699559224014416

Epoch: 6| Step: 9
Training loss: 2.584390044716308
Validation loss: 2.4706113212728535

Epoch: 6| Step: 10
Training loss: 2.324347894751072
Validation loss: 2.4790334799330376

Epoch: 6| Step: 11
Training loss: 1.9582874887930597
Validation loss: 2.486505598480122

Epoch: 6| Step: 12
Training loss: 2.6389543112514393
Validation loss: 2.4698475196815886

Epoch: 6| Step: 13
Training loss: 1.737907180827314
Validation loss: 2.4780787129707424

Epoch: 137| Step: 0
Training loss: 2.5077227519961025
Validation loss: 2.4852991524537025

Epoch: 6| Step: 1
Training loss: 3.1717795371737427
Validation loss: 2.473964335116418

Epoch: 6| Step: 2
Training loss: 2.8002539315200776
Validation loss: 2.4703327770876804

Epoch: 6| Step: 3
Training loss: 2.209486846035236
Validation loss: 2.477340126897095

Epoch: 6| Step: 4
Training loss: 2.055969766461323
Validation loss: 2.461684647427515

Epoch: 6| Step: 5
Training loss: 1.7936548985381913
Validation loss: 2.4845524530593788

Epoch: 6| Step: 6
Training loss: 2.2554473632813323
Validation loss: 2.4741415872798536

Epoch: 6| Step: 7
Training loss: 2.6441097402551135
Validation loss: 2.4695983427065853

Epoch: 6| Step: 8
Training loss: 2.386796066605191
Validation loss: 2.483184561230736

Epoch: 6| Step: 9
Training loss: 2.7061227041704625
Validation loss: 2.4730480942245867

Epoch: 6| Step: 10
Training loss: 2.468079101568489
Validation loss: 2.48643660826848

Epoch: 6| Step: 11
Training loss: 2.2957887740983227
Validation loss: 2.486648415080052

Epoch: 6| Step: 12
Training loss: 2.882100831554488
Validation loss: 2.485633723162374

Epoch: 6| Step: 13
Training loss: 2.29155587593223
Validation loss: 2.474736564436623

Epoch: 138| Step: 0
Training loss: 2.787468035048516
Validation loss: 2.4844095479614374

Epoch: 6| Step: 1
Training loss: 1.8700994665038329
Validation loss: 2.479934851190632

Epoch: 6| Step: 2
Training loss: 2.3962110691559615
Validation loss: 2.479688931332331

Epoch: 6| Step: 3
Training loss: 2.2744963497150184
Validation loss: 2.4811779780468814

Epoch: 6| Step: 4
Training loss: 2.1707612619376975
Validation loss: 2.480839434782689

Epoch: 6| Step: 5
Training loss: 2.589862069687987
Validation loss: 2.4837409915898294

Epoch: 6| Step: 6
Training loss: 2.3897833246309346
Validation loss: 2.4834072059379544

Epoch: 6| Step: 7
Training loss: 2.367246520058897
Validation loss: 2.48552506096693

Epoch: 6| Step: 8
Training loss: 2.6894962082946225
Validation loss: 2.4772475906551814

Epoch: 6| Step: 9
Training loss: 2.7300424311208453
Validation loss: 2.4838065370736553

Epoch: 6| Step: 10
Training loss: 2.7604684117103715
Validation loss: 2.487463592697371

Epoch: 6| Step: 11
Training loss: 1.9025777245985058
Validation loss: 2.4837535664738066

Epoch: 6| Step: 12
Training loss: 2.4572405460652007
Validation loss: 2.491804613698498

Epoch: 6| Step: 13
Training loss: 3.058140980616201
Validation loss: 2.486318759545974

Epoch: 139| Step: 0
Training loss: 1.767648061138032
Validation loss: 2.4926890284142362

Epoch: 6| Step: 1
Training loss: 2.228770663539499
Validation loss: 2.480036275813684

Epoch: 6| Step: 2
Training loss: 2.407313817669384
Validation loss: 2.479603678122468

Epoch: 6| Step: 3
Training loss: 2.711913622923758
Validation loss: 2.4891844846276965

Epoch: 6| Step: 4
Training loss: 2.5813570974821904
Validation loss: 2.479028591082946

Epoch: 6| Step: 5
Training loss: 3.3017651778700015
Validation loss: 2.4774404066805245

Epoch: 6| Step: 6
Training loss: 2.616336422225069
Validation loss: 2.4733162833171947

Epoch: 6| Step: 7
Training loss: 2.379943721650808
Validation loss: 2.4815761707305493

Epoch: 6| Step: 8
Training loss: 2.3014252931883217
Validation loss: 2.484237411175884

Epoch: 6| Step: 9
Training loss: 2.465928408831138
Validation loss: 2.4827998224010375

Epoch: 6| Step: 10
Training loss: 2.524915421835087
Validation loss: 2.4911511058992173

Epoch: 6| Step: 11
Training loss: 2.4310844306171395
Validation loss: 2.486081271167124

Epoch: 6| Step: 12
Training loss: 2.5038053161940064
Validation loss: 2.490141440259317

Epoch: 6| Step: 13
Training loss: 2.17784133443192
Validation loss: 2.4932336156287556

Epoch: 140| Step: 0
Training loss: 2.0661035903780562
Validation loss: 2.4726714846366185

Epoch: 6| Step: 1
Training loss: 2.8624211329627305
Validation loss: 2.4771817753777277

Epoch: 6| Step: 2
Training loss: 2.995146003437759
Validation loss: 2.4798283428599395

Epoch: 6| Step: 3
Training loss: 2.4348822989402144
Validation loss: 2.4770203015837002

Epoch: 6| Step: 4
Training loss: 2.532607291567001
Validation loss: 2.4794948317944496

Epoch: 6| Step: 5
Training loss: 2.2234256532290466
Validation loss: 2.4790116162794145

Epoch: 6| Step: 6
Training loss: 2.276210286916319
Validation loss: 2.4828367449355087

Epoch: 6| Step: 7
Training loss: 2.220639780662642
Validation loss: 2.479198116348776

Epoch: 6| Step: 8
Training loss: 2.3100090013469017
Validation loss: 2.465473866313049

Epoch: 6| Step: 9
Training loss: 3.0602053395108477
Validation loss: 2.4718937232927614

Epoch: 6| Step: 10
Training loss: 2.2912979407323584
Validation loss: 2.4676163963968016

Epoch: 6| Step: 11
Training loss: 2.3222989913301553
Validation loss: 2.481176032205768

Epoch: 6| Step: 12
Training loss: 2.715852969733533
Validation loss: 2.4953563797002247

Epoch: 6| Step: 13
Training loss: 2.300211241599659
Validation loss: 2.5013840182201244

Epoch: 141| Step: 0
Training loss: 2.335516544035991
Validation loss: 2.5121850134178483

Epoch: 6| Step: 1
Training loss: 2.7527718879370666
Validation loss: 2.513933533212968

Epoch: 6| Step: 2
Training loss: 2.170897668725966
Validation loss: 2.4972482637012443

Epoch: 6| Step: 3
Training loss: 2.7078311063255995
Validation loss: 2.5296094939323748

Epoch: 6| Step: 4
Training loss: 2.7051657321666576
Validation loss: 2.4934418330920063

Epoch: 6| Step: 5
Training loss: 2.5611579916472764
Validation loss: 2.479686159046614

Epoch: 6| Step: 6
Training loss: 2.536516903012392
Validation loss: 2.47505772841204

Epoch: 6| Step: 7
Training loss: 2.4927291998897823
Validation loss: 2.4732409323820406

Epoch: 6| Step: 8
Training loss: 2.351870393082007
Validation loss: 2.4705263177586425

Epoch: 6| Step: 9
Training loss: 2.6763010230227318
Validation loss: 2.4703144154711123

Epoch: 6| Step: 10
Training loss: 2.141536101085718
Validation loss: 2.4717057557165054

Epoch: 6| Step: 11
Training loss: 2.609099779062597
Validation loss: 2.4696108528364404

Epoch: 6| Step: 12
Training loss: 2.3683096363117864
Validation loss: 2.4812442878766294

Epoch: 6| Step: 13
Training loss: 2.2800279244168493
Validation loss: 2.4818563590001728

Epoch: 142| Step: 0
Training loss: 2.02766748096442
Validation loss: 2.474811661101587

Epoch: 6| Step: 1
Training loss: 2.319712551659507
Validation loss: 2.4824864388870522

Epoch: 6| Step: 2
Training loss: 2.1504108036490805
Validation loss: 2.4744632540312748

Epoch: 6| Step: 3
Training loss: 2.417186703031442
Validation loss: 2.4856248346868544

Epoch: 6| Step: 4
Training loss: 2.8815586082035893
Validation loss: 2.479401278146981

Epoch: 6| Step: 5
Training loss: 2.563865483889984
Validation loss: 2.4777450465871067

Epoch: 6| Step: 6
Training loss: 2.5705076566773943
Validation loss: 2.48157658705752

Epoch: 6| Step: 7
Training loss: 2.1058243997875223
Validation loss: 2.4840934002025716

Epoch: 6| Step: 8
Training loss: 2.229126427783422
Validation loss: 2.4902086682956237

Epoch: 6| Step: 9
Training loss: 2.752408273608126
Validation loss: 2.4894778549855103

Epoch: 6| Step: 10
Training loss: 2.8707379801896447
Validation loss: 2.5018537403848553

Epoch: 6| Step: 11
Training loss: 2.2396767411972234
Validation loss: 2.494865150935647

Epoch: 6| Step: 12
Training loss: 2.7600145922841754
Validation loss: 2.5325209562583755

Epoch: 6| Step: 13
Training loss: 2.609647999262297
Validation loss: 2.525320635792204

Epoch: 143| Step: 0
Training loss: 3.322931526812547
Validation loss: 2.507844364205464

Epoch: 6| Step: 1
Training loss: 2.0906469780147314
Validation loss: 2.4988892471878987

Epoch: 6| Step: 2
Training loss: 2.018152589063002
Validation loss: 2.4890016543959006

Epoch: 6| Step: 3
Training loss: 2.054972929764631
Validation loss: 2.486386945957154

Epoch: 6| Step: 4
Training loss: 2.907451094316932
Validation loss: 2.4702640831915885

Epoch: 6| Step: 5
Training loss: 2.9749501584790576
Validation loss: 2.4864004263962194

Epoch: 6| Step: 6
Training loss: 2.897617440003646
Validation loss: 2.4723372170733806

Epoch: 6| Step: 7
Training loss: 2.1231670328088987
Validation loss: 2.486422193115685

Epoch: 6| Step: 8
Training loss: 2.3301538421530426
Validation loss: 2.4883798912055073

Epoch: 6| Step: 9
Training loss: 1.9055482166669204
Validation loss: 2.488978617073474

Epoch: 6| Step: 10
Training loss: 2.2594533059887207
Validation loss: 2.493874468202859

Epoch: 6| Step: 11
Training loss: 2.824086715123339
Validation loss: 2.48199846652094

Epoch: 6| Step: 12
Training loss: 2.5160411229919655
Validation loss: 2.4907702778143275

Epoch: 6| Step: 13
Training loss: 2.695692306516746
Validation loss: 2.4812584128185153

Epoch: 144| Step: 0
Training loss: 2.593615241169375
Validation loss: 2.481432637844471

Epoch: 6| Step: 1
Training loss: 2.6293676461746465
Validation loss: 2.4739397603726485

Epoch: 6| Step: 2
Training loss: 2.834431902767428
Validation loss: 2.4744808782883263

Epoch: 6| Step: 3
Training loss: 2.6705212649306
Validation loss: 2.4678336748652057

Epoch: 6| Step: 4
Training loss: 2.1241392748585444
Validation loss: 2.4778432492680644

Epoch: 6| Step: 5
Training loss: 1.8682553737118484
Validation loss: 2.470873695888713

Epoch: 6| Step: 6
Training loss: 2.4287988932857076
Validation loss: 2.479316127236157

Epoch: 6| Step: 7
Training loss: 2.707132532996583
Validation loss: 2.4876705759755415

Epoch: 6| Step: 8
Training loss: 2.5354237936938966
Validation loss: 2.4972320492326787

Epoch: 6| Step: 9
Training loss: 2.8344966706696972
Validation loss: 2.521334895109113

Epoch: 6| Step: 10
Training loss: 2.976506430430734
Validation loss: 2.5004894413269048

Epoch: 6| Step: 11
Training loss: 2.438409684455343
Validation loss: 2.4897987134227972

Epoch: 6| Step: 12
Training loss: 1.8650454440473605
Validation loss: 2.485011421115964

Epoch: 6| Step: 13
Training loss: 2.4669545078729755
Validation loss: 2.4663552205757133

Epoch: 145| Step: 0
Training loss: 1.805380551912904
Validation loss: 2.4791257251169174

Epoch: 6| Step: 1
Training loss: 2.3723822773707677
Validation loss: 2.4862988618345754

Epoch: 6| Step: 2
Training loss: 3.1971586905128397
Validation loss: 2.494736534789008

Epoch: 6| Step: 3
Training loss: 2.9218291416751407
Validation loss: 2.4832986223325277

Epoch: 6| Step: 4
Training loss: 2.160555314630506
Validation loss: 2.4974462181209054

Epoch: 6| Step: 5
Training loss: 2.0557339980309712
Validation loss: 2.4942305271611684

Epoch: 6| Step: 6
Training loss: 2.416829027005503
Validation loss: 2.4906709415501553

Epoch: 6| Step: 7
Training loss: 2.031232276252303
Validation loss: 2.4928398195417705

Epoch: 6| Step: 8
Training loss: 2.3735861334302784
Validation loss: 2.4931326482028657

Epoch: 6| Step: 9
Training loss: 2.888163245186665
Validation loss: 2.496177357530552

Epoch: 6| Step: 10
Training loss: 2.1620113416051376
Validation loss: 2.485071416528382

Epoch: 6| Step: 11
Training loss: 3.1378287397712255
Validation loss: 2.4944095491485685

Epoch: 6| Step: 12
Training loss: 2.532616328950267
Validation loss: 2.4849184269631857

Epoch: 6| Step: 13
Training loss: 2.6301827810324143
Validation loss: 2.484020879686908

Epoch: 146| Step: 0
Training loss: 2.074451727992541
Validation loss: 2.485510160910516

Epoch: 6| Step: 1
Training loss: 2.3907640204803853
Validation loss: 2.4920167615356394

Epoch: 6| Step: 2
Training loss: 2.3295564283294357
Validation loss: 2.488585177573844

Epoch: 6| Step: 3
Training loss: 2.3549986412870534
Validation loss: 2.4834367351851614

Epoch: 6| Step: 4
Training loss: 2.2546087323954564
Validation loss: 2.477114658997149

Epoch: 6| Step: 5
Training loss: 2.2709103725792628
Validation loss: 2.4836093674502986

Epoch: 6| Step: 6
Training loss: 1.7725514622630423
Validation loss: 2.4794192759794234

Epoch: 6| Step: 7
Training loss: 2.8568143792022607
Validation loss: 2.4865159380573485

Epoch: 6| Step: 8
Training loss: 2.9353149078758887
Validation loss: 2.495097622729373

Epoch: 6| Step: 9
Training loss: 2.4566722904832807
Validation loss: 2.4933725407606553

Epoch: 6| Step: 10
Training loss: 2.8007548608959905
Validation loss: 2.5017003634744093

Epoch: 6| Step: 11
Training loss: 2.7355203028326205
Validation loss: 2.4843457778075755

Epoch: 6| Step: 12
Training loss: 2.4278578170610614
Validation loss: 2.4916512401660373

Epoch: 6| Step: 13
Training loss: 2.647457425330804
Validation loss: 2.5013168045926655

Epoch: 147| Step: 0
Training loss: 2.6607416211897474
Validation loss: 2.4863695019847274

Epoch: 6| Step: 1
Training loss: 2.181344554349179
Validation loss: 2.494185584451459

Epoch: 6| Step: 2
Training loss: 2.4431090741286194
Validation loss: 2.4930668856883704

Epoch: 6| Step: 3
Training loss: 1.9796197339196415
Validation loss: 2.482110580987233

Epoch: 6| Step: 4
Training loss: 2.2090970524146973
Validation loss: 2.4958578922632193

Epoch: 6| Step: 5
Training loss: 2.174884714162445
Validation loss: 2.49180195057343

Epoch: 6| Step: 6
Training loss: 2.7363293448315447
Validation loss: 2.484414666137088

Epoch: 6| Step: 7
Training loss: 2.5817448028633305
Validation loss: 2.490441263617859

Epoch: 6| Step: 8
Training loss: 2.3695921314340676
Validation loss: 2.482637609616345

Epoch: 6| Step: 9
Training loss: 1.8984002003714242
Validation loss: 2.485133329252002

Epoch: 6| Step: 10
Training loss: 3.0531314096217583
Validation loss: 2.4860996202266064

Epoch: 6| Step: 11
Training loss: 2.7968656230748015
Validation loss: 2.4973739501079235

Epoch: 6| Step: 12
Training loss: 2.472743510413532
Validation loss: 2.498226585813657

Epoch: 6| Step: 13
Training loss: 2.74829933291984
Validation loss: 2.5054159309728283

Epoch: 148| Step: 0
Training loss: 2.3861697700325593
Validation loss: 2.505331109118866

Epoch: 6| Step: 1
Training loss: 2.6503377303352997
Validation loss: 2.5028668020035694

Epoch: 6| Step: 2
Training loss: 2.394107451281427
Validation loss: 2.5107381438088345

Epoch: 6| Step: 3
Training loss: 2.409644074017166
Validation loss: 2.4971026956932185

Epoch: 6| Step: 4
Training loss: 2.1992445515665633
Validation loss: 2.5114089671952327

Epoch: 6| Step: 5
Training loss: 2.5002340207241063
Validation loss: 2.5076710471945285

Epoch: 6| Step: 6
Training loss: 2.408856157181751
Validation loss: 2.505574702532516

Epoch: 6| Step: 7
Training loss: 2.6814812976157207
Validation loss: 2.4882387470026806

Epoch: 6| Step: 8
Training loss: 2.4839982040939352
Validation loss: 2.4922301030678065

Epoch: 6| Step: 9
Training loss: 2.083640444689674
Validation loss: 2.4847934458474015

Epoch: 6| Step: 10
Training loss: 3.084113323083966
Validation loss: 2.4901921207607964

Epoch: 6| Step: 11
Training loss: 2.5788820946829594
Validation loss: 2.494619986109435

Epoch: 6| Step: 12
Training loss: 2.1049638755036373
Validation loss: 2.491439324366074

Epoch: 6| Step: 13
Training loss: 2.4495781204402625
Validation loss: 2.49448238890046

Epoch: 149| Step: 0
Training loss: 2.540085055511606
Validation loss: 2.496011532666694

Epoch: 6| Step: 1
Training loss: 2.7667611584747305
Validation loss: 2.4905365485068973

Epoch: 6| Step: 2
Training loss: 1.7781195320353715
Validation loss: 2.4935196014005108

Epoch: 6| Step: 3
Training loss: 2.6794593647194236
Validation loss: 2.491873343666253

Epoch: 6| Step: 4
Training loss: 2.1701113998367494
Validation loss: 2.4908309720528994

Epoch: 6| Step: 5
Training loss: 1.7502736150191636
Validation loss: 2.4911928334482396

Epoch: 6| Step: 6
Training loss: 2.5503445261666977
Validation loss: 2.4834834964419654

Epoch: 6| Step: 7
Training loss: 3.1873294560304393
Validation loss: 2.479178938848644

Epoch: 6| Step: 8
Training loss: 2.1186548757439065
Validation loss: 2.490373196191895

Epoch: 6| Step: 9
Training loss: 2.8672437116637286
Validation loss: 2.4982515260698177

Epoch: 6| Step: 10
Training loss: 2.442441186889874
Validation loss: 2.4969141989293875

Epoch: 6| Step: 11
Training loss: 2.570145158045135
Validation loss: 2.507338577125392

Epoch: 6| Step: 12
Training loss: 2.455667332463722
Validation loss: 2.5052994587927477

Epoch: 6| Step: 13
Training loss: 2.3100998253328644
Validation loss: 2.505543951339898

Epoch: 150| Step: 0
Training loss: 2.17226137525434
Validation loss: 2.51724841570813

Epoch: 6| Step: 1
Training loss: 2.209821223799791
Validation loss: 2.51219501004372

Epoch: 6| Step: 2
Training loss: 2.6001836198377526
Validation loss: 2.5074253753987907

Epoch: 6| Step: 3
Training loss: 2.3710081785745554
Validation loss: 2.5235820213166407

Epoch: 6| Step: 4
Training loss: 3.130268843198725
Validation loss: 2.528288580620567

Epoch: 6| Step: 5
Training loss: 2.5796965462002106
Validation loss: 2.5252873634887787

Epoch: 6| Step: 6
Training loss: 2.3232255624799234
Validation loss: 2.5229004878043293

Epoch: 6| Step: 7
Training loss: 2.426808899738925
Validation loss: 2.5107017977757393

Epoch: 6| Step: 8
Training loss: 1.9099726364412517
Validation loss: 2.4945417264373293

Epoch: 6| Step: 9
Training loss: 2.7287920823393077
Validation loss: 2.491488192193534

Epoch: 6| Step: 10
Training loss: 2.4960064462309517
Validation loss: 2.4919057465573093

Epoch: 6| Step: 11
Training loss: 2.4401775228302602
Validation loss: 2.486931043761786

Epoch: 6| Step: 12
Training loss: 2.6867507954844143
Validation loss: 2.477774835759665

Epoch: 6| Step: 13
Training loss: 2.12382834053705
Validation loss: 2.486336147937681

Epoch: 151| Step: 0
Training loss: 2.906679511377261
Validation loss: 2.4888345132244782

Epoch: 6| Step: 1
Training loss: 2.5899564278372913
Validation loss: 2.4881514151578874

Epoch: 6| Step: 2
Training loss: 2.2732885777308613
Validation loss: 2.483134617844864

Epoch: 6| Step: 3
Training loss: 3.2570741397616816
Validation loss: 2.4855667071101073

Epoch: 6| Step: 4
Training loss: 2.0689540796950325
Validation loss: 2.4952845050130765

Epoch: 6| Step: 5
Training loss: 2.4477178181716575
Validation loss: 2.4873390989166047

Epoch: 6| Step: 6
Training loss: 2.670379041419685
Validation loss: 2.490424494248917

Epoch: 6| Step: 7
Training loss: 1.935001731497214
Validation loss: 2.4820903613742544

Epoch: 6| Step: 8
Training loss: 2.535355523363991
Validation loss: 2.4996334760922503

Epoch: 6| Step: 9
Training loss: 2.6161835979814505
Validation loss: 2.495452289013875

Epoch: 6| Step: 10
Training loss: 2.6340372649665422
Validation loss: 2.5092676838895924

Epoch: 6| Step: 11
Training loss: 1.757655632649009
Validation loss: 2.5176119884722117

Epoch: 6| Step: 12
Training loss: 1.9882119397147078
Validation loss: 2.53087104503816

Epoch: 6| Step: 13
Training loss: 2.13065192369239
Validation loss: 2.5142232966364637

Epoch: 152| Step: 0
Training loss: 2.775974714224478
Validation loss: 2.506130648820837

Epoch: 6| Step: 1
Training loss: 2.3737608035837594
Validation loss: 2.502213197800643

Epoch: 6| Step: 2
Training loss: 2.3544541130009415
Validation loss: 2.4923519211824625

Epoch: 6| Step: 3
Training loss: 2.0129421625067043
Validation loss: 2.4848856211281674

Epoch: 6| Step: 4
Training loss: 2.2682942418699112
Validation loss: 2.489591811310659

Epoch: 6| Step: 5
Training loss: 2.6876346643110094
Validation loss: 2.487638405443011

Epoch: 6| Step: 6
Training loss: 2.1087059938082295
Validation loss: 2.4833315851431546

Epoch: 6| Step: 7
Training loss: 2.5169209050817916
Validation loss: 2.490775239338674

Epoch: 6| Step: 8
Training loss: 2.162887309235313
Validation loss: 2.4939705380700987

Epoch: 6| Step: 9
Training loss: 2.3480913771373895
Validation loss: 2.487529199834588

Epoch: 6| Step: 10
Training loss: 2.8417133122379172
Validation loss: 2.485126285798056

Epoch: 6| Step: 11
Training loss: 2.654508580851953
Validation loss: 2.486399179838234

Epoch: 6| Step: 12
Training loss: 2.536457497807443
Validation loss: 2.4861041914869038

Epoch: 6| Step: 13
Training loss: 2.9026923605617383
Validation loss: 2.4920094186263992

Epoch: 153| Step: 0
Training loss: 2.1616396785787644
Validation loss: 2.4829896387152126

Epoch: 6| Step: 1
Training loss: 2.865062456232463
Validation loss: 2.4792845775442913

Epoch: 6| Step: 2
Training loss: 2.836842962480372
Validation loss: 2.482044414372885

Epoch: 6| Step: 3
Training loss: 2.9120769537304887
Validation loss: 2.4987840238401287

Epoch: 6| Step: 4
Training loss: 2.3216127804620617
Validation loss: 2.494099846936964

Epoch: 6| Step: 5
Training loss: 2.1990553691879042
Validation loss: 2.487722816264331

Epoch: 6| Step: 6
Training loss: 1.8870842936923204
Validation loss: 2.5062797037268587

Epoch: 6| Step: 7
Training loss: 2.292146551576449
Validation loss: 2.4927672824884755

Epoch: 6| Step: 8
Training loss: 2.051803363219975
Validation loss: 2.4906073396918953

Epoch: 6| Step: 9
Training loss: 2.141101199456363
Validation loss: 2.484305854650855

Epoch: 6| Step: 10
Training loss: 2.752933238319145
Validation loss: 2.4915270752435648

Epoch: 6| Step: 11
Training loss: 2.3875551147490515
Validation loss: 2.49097379589808

Epoch: 6| Step: 12
Training loss: 3.08107062817786
Validation loss: 2.488413106078673

Epoch: 6| Step: 13
Training loss: 2.056038068151757
Validation loss: 2.492528431691018

Epoch: 154| Step: 0
Training loss: 2.555979737262673
Validation loss: 2.499615925850193

Epoch: 6| Step: 1
Training loss: 2.1652699761627026
Validation loss: 2.499463111130077

Epoch: 6| Step: 2
Training loss: 2.880260464758115
Validation loss: 2.480311911923598

Epoch: 6| Step: 3
Training loss: 3.245370061195864
Validation loss: 2.4927367160284906

Epoch: 6| Step: 4
Training loss: 2.794629095645174
Validation loss: 2.4975991323791322

Epoch: 6| Step: 5
Training loss: 2.316985239679164
Validation loss: 2.5063109690923273

Epoch: 6| Step: 6
Training loss: 1.9730422444913245
Validation loss: 2.517298960886818

Epoch: 6| Step: 7
Training loss: 1.9774925245295651
Validation loss: 2.506098651834814

Epoch: 6| Step: 8
Training loss: 2.309808556686567
Validation loss: 2.5042871591160054

Epoch: 6| Step: 9
Training loss: 2.3072638126066893
Validation loss: 2.5123732501649774

Epoch: 6| Step: 10
Training loss: 2.7771341107918666
Validation loss: 2.4867504767014807

Epoch: 6| Step: 11
Training loss: 2.145956597599429
Validation loss: 2.490549551771517

Epoch: 6| Step: 12
Training loss: 2.8890267567463424
Validation loss: 2.4917292238332975

Epoch: 6| Step: 13
Training loss: 1.5932902252611862
Validation loss: 2.48960347080998

Epoch: 155| Step: 0
Training loss: 2.816011906501134
Validation loss: 2.4920486204222136

Epoch: 6| Step: 1
Training loss: 1.9764875917978857
Validation loss: 2.4891514476680805

Epoch: 6| Step: 2
Training loss: 2.3974504956175355
Validation loss: 2.4993181490889262

Epoch: 6| Step: 3
Training loss: 2.1862852811065854
Validation loss: 2.512194329894803

Epoch: 6| Step: 4
Training loss: 1.6684385973520737
Validation loss: 2.510110944649146

Epoch: 6| Step: 5
Training loss: 2.4459358371481867
Validation loss: 2.499452785366763

Epoch: 6| Step: 6
Training loss: 2.5865692565542133
Validation loss: 2.5052094304220502

Epoch: 6| Step: 7
Training loss: 1.9146238165703129
Validation loss: 2.514195085170394

Epoch: 6| Step: 8
Training loss: 3.0214572306069
Validation loss: 2.498954657715838

Epoch: 6| Step: 9
Training loss: 2.643799718655341
Validation loss: 2.5089538132070572

Epoch: 6| Step: 10
Training loss: 2.246215923137879
Validation loss: 2.503322602726084

Epoch: 6| Step: 11
Training loss: 2.9437518854803377
Validation loss: 2.511366380938222

Epoch: 6| Step: 12
Training loss: 2.145952597948711
Validation loss: 2.5014104043573133

Epoch: 6| Step: 13
Training loss: 2.6616563418511974
Validation loss: 2.4938621674235337

Epoch: 156| Step: 0
Training loss: 2.585984151828526
Validation loss: 2.493432765276829

Epoch: 6| Step: 1
Training loss: 2.674067974827226
Validation loss: 2.491964236536055

Epoch: 6| Step: 2
Training loss: 2.120081651302826
Validation loss: 2.4958544612960374

Epoch: 6| Step: 3
Training loss: 3.0276004805455763
Validation loss: 2.496185595554366

Epoch: 6| Step: 4
Training loss: 2.1805293600637663
Validation loss: 2.487389804565412

Epoch: 6| Step: 5
Training loss: 2.0593129590056636
Validation loss: 2.491477602119064

Epoch: 6| Step: 6
Training loss: 1.9907767293405818
Validation loss: 2.4914959592827914

Epoch: 6| Step: 7
Training loss: 2.845612136339202
Validation loss: 2.495390043126729

Epoch: 6| Step: 8
Training loss: 2.7218646919764806
Validation loss: 2.493720321669884

Epoch: 6| Step: 9
Training loss: 2.9283405106582645
Validation loss: 2.4991500204290245

Epoch: 6| Step: 10
Training loss: 1.913900750001505
Validation loss: 2.5001440801428196

Epoch: 6| Step: 11
Training loss: 1.6177956732143266
Validation loss: 2.494440079179931

Epoch: 6| Step: 12
Training loss: 2.8043131033840574
Validation loss: 2.4963421128415293

Epoch: 6| Step: 13
Training loss: 2.1724074554925106
Validation loss: 2.500401599734599

Epoch: 157| Step: 0
Training loss: 1.8507146382934887
Validation loss: 2.5128236261709818

Epoch: 6| Step: 1
Training loss: 2.7677608367760147
Validation loss: 2.5359145932231453

Epoch: 6| Step: 2
Training loss: 2.2658442950173554
Validation loss: 2.534546326640891

Epoch: 6| Step: 3
Training loss: 2.386593479796083
Validation loss: 2.5310036339193034

Epoch: 6| Step: 4
Training loss: 1.9957068379984177
Validation loss: 2.521795378243086

Epoch: 6| Step: 5
Training loss: 2.2700722028365767
Validation loss: 2.515402197596908

Epoch: 6| Step: 6
Training loss: 2.49027889436308
Validation loss: 2.5069295531089213

Epoch: 6| Step: 7
Training loss: 2.128913081446895
Validation loss: 2.5010647493181946

Epoch: 6| Step: 8
Training loss: 2.5294678619207134
Validation loss: 2.511746736156011

Epoch: 6| Step: 9
Training loss: 2.5620413579111516
Validation loss: 2.493366229771873

Epoch: 6| Step: 10
Training loss: 2.7063026053093004
Validation loss: 2.497200304212648

Epoch: 6| Step: 11
Training loss: 2.639273664519617
Validation loss: 2.4978457706201422

Epoch: 6| Step: 12
Training loss: 2.8122873861693485
Validation loss: 2.4979107232827777

Epoch: 6| Step: 13
Training loss: 2.460167755361712
Validation loss: 2.489616478948064

Epoch: 158| Step: 0
Training loss: 2.0185235052925337
Validation loss: 2.4752380487808288

Epoch: 6| Step: 1
Training loss: 2.7823784928298414
Validation loss: 2.4920804230937113

Epoch: 6| Step: 2
Training loss: 2.354759299253721
Validation loss: 2.481734017695817

Epoch: 6| Step: 3
Training loss: 3.0575966019548173
Validation loss: 2.4927143986892926

Epoch: 6| Step: 4
Training loss: 2.274427480236291
Validation loss: 2.4928226438891956

Epoch: 6| Step: 5
Training loss: 2.277034574953988
Validation loss: 2.5027506716289767

Epoch: 6| Step: 6
Training loss: 1.4883317913775058
Validation loss: 2.5005386169686883

Epoch: 6| Step: 7
Training loss: 2.895004501471042
Validation loss: 2.504255503529584

Epoch: 6| Step: 8
Training loss: 2.280739505033255
Validation loss: 2.50656246511081

Epoch: 6| Step: 9
Training loss: 2.0743700105216902
Validation loss: 2.5071544477070384

Epoch: 6| Step: 10
Training loss: 2.404421222858248
Validation loss: 2.4954030529480393

Epoch: 6| Step: 11
Training loss: 2.4212037171374843
Validation loss: 2.509317455526637

Epoch: 6| Step: 12
Training loss: 2.7126798719545806
Validation loss: 2.498604416733711

Epoch: 6| Step: 13
Training loss: 2.5334818855031043
Validation loss: 2.506602501436866

Epoch: 159| Step: 0
Training loss: 2.097115388328771
Validation loss: 2.4962012517044014

Epoch: 6| Step: 1
Training loss: 3.1718790589856263
Validation loss: 2.5037408894147597

Epoch: 6| Step: 2
Training loss: 2.51741977900985
Validation loss: 2.495961376295846

Epoch: 6| Step: 3
Training loss: 2.150873641008737
Validation loss: 2.500644314707307

Epoch: 6| Step: 4
Training loss: 2.390306638575063
Validation loss: 2.4964986760249093

Epoch: 6| Step: 5
Training loss: 1.9316844414504024
Validation loss: 2.501035428201589

Epoch: 6| Step: 6
Training loss: 2.05747164812172
Validation loss: 2.5025973338107623

Epoch: 6| Step: 7
Training loss: 2.6554973657990373
Validation loss: 2.5047258691036216

Epoch: 6| Step: 8
Training loss: 3.1400038071627527
Validation loss: 2.5058550300669498

Epoch: 6| Step: 9
Training loss: 2.1260020193626885
Validation loss: 2.509515597979839

Epoch: 6| Step: 10
Training loss: 1.8524994873581562
Validation loss: 2.5180414413231453

Epoch: 6| Step: 11
Training loss: 2.515379520546602
Validation loss: 2.5017712676129475

Epoch: 6| Step: 12
Training loss: 2.448852706398798
Validation loss: 2.510184563529436

Epoch: 6| Step: 13
Training loss: 2.440206541168598
Validation loss: 2.502196729654208

Epoch: 160| Step: 0
Training loss: 2.7629144176492604
Validation loss: 2.51957028380919

Epoch: 6| Step: 1
Training loss: 2.733243610103503
Validation loss: 2.53085357010628

Epoch: 6| Step: 2
Training loss: 1.91119001066121
Validation loss: 2.5375187959272423

Epoch: 6| Step: 3
Training loss: 2.7782148451807442
Validation loss: 2.535779503150586

Epoch: 6| Step: 4
Training loss: 2.55363587365778
Validation loss: 2.5269199430683504

Epoch: 6| Step: 5
Training loss: 2.6547192819184846
Validation loss: 2.531418892834119

Epoch: 6| Step: 6
Training loss: 2.937331499177369
Validation loss: 2.515408050470117

Epoch: 6| Step: 7
Training loss: 2.574470472980329
Validation loss: 2.510226061748856

Epoch: 6| Step: 8
Training loss: 2.582999136032214
Validation loss: 2.504604081676264

Epoch: 6| Step: 9
Training loss: 2.401508365931842
Validation loss: 2.499748948525409

Epoch: 6| Step: 10
Training loss: 1.7908084795354238
Validation loss: 2.4932283800861135

Epoch: 6| Step: 11
Training loss: 2.5766592772140577
Validation loss: 2.5016264710912908

Epoch: 6| Step: 12
Training loss: 2.039784270828902
Validation loss: 2.4922545931244406

Epoch: 6| Step: 13
Training loss: 1.355790949188108
Validation loss: 2.493642097503385

Epoch: 161| Step: 0
Training loss: 2.5963785112337128
Validation loss: 2.4910030280724853

Epoch: 6| Step: 1
Training loss: 2.1102635525450255
Validation loss: 2.4927476913037965

Epoch: 6| Step: 2
Training loss: 2.2972171035621423
Validation loss: 2.4913705824249375

Epoch: 6| Step: 3
Training loss: 2.7209873858814517
Validation loss: 2.4916643093782667

Epoch: 6| Step: 4
Training loss: 2.351285493573683
Validation loss: 2.4859701989255387

Epoch: 6| Step: 5
Training loss: 2.954846077410213
Validation loss: 2.4949961334942636

Epoch: 6| Step: 6
Training loss: 2.4241342159165495
Validation loss: 2.4968231997887673

Epoch: 6| Step: 7
Training loss: 1.9037719002939923
Validation loss: 2.4935469790925393

Epoch: 6| Step: 8
Training loss: 2.506927809538266
Validation loss: 2.513153204454082

Epoch: 6| Step: 9
Training loss: 2.428756093769999
Validation loss: 2.511869055253792

Epoch: 6| Step: 10
Training loss: 2.1056720019807305
Validation loss: 2.513879774813584

Epoch: 6| Step: 11
Training loss: 2.1110284047350345
Validation loss: 2.517284422543084

Epoch: 6| Step: 12
Training loss: 2.6954328869457247
Validation loss: 2.510689326209216

Epoch: 6| Step: 13
Training loss: 2.9685444007754036
Validation loss: 2.507330296505028

Epoch: 162| Step: 0
Training loss: 2.026993502605998
Validation loss: 2.5111849758045914

Epoch: 6| Step: 1
Training loss: 2.812750911116781
Validation loss: 2.5135401187601603

Epoch: 6| Step: 2
Training loss: 2.650118044257375
Validation loss: 2.495734358551443

Epoch: 6| Step: 3
Training loss: 2.3427768975980077
Validation loss: 2.497289905283869

Epoch: 6| Step: 4
Training loss: 2.286375375921273
Validation loss: 2.4927756672771784

Epoch: 6| Step: 5
Training loss: 2.8210767730142905
Validation loss: 2.49568329701369

Epoch: 6| Step: 6
Training loss: 2.0399685889051042
Validation loss: 2.500651926233992

Epoch: 6| Step: 7
Training loss: 2.863308894712215
Validation loss: 2.4850028182435255

Epoch: 6| Step: 8
Training loss: 1.8244337326899014
Validation loss: 2.492292603256567

Epoch: 6| Step: 9
Training loss: 2.2039196123531464
Validation loss: 2.48429165106537

Epoch: 6| Step: 10
Training loss: 1.8473768607722012
Validation loss: 2.494621419705606

Epoch: 6| Step: 11
Training loss: 2.856622089882436
Validation loss: 2.499364740405179

Epoch: 6| Step: 12
Training loss: 2.8097918717765227
Validation loss: 2.51096390791598

Epoch: 6| Step: 13
Training loss: 2.216410948647866
Validation loss: 2.508533172208645

Epoch: 163| Step: 0
Training loss: 2.714961865826451
Validation loss: 2.521457032740705

Epoch: 6| Step: 1
Training loss: 2.117936906114356
Validation loss: 2.5236630176596244

Epoch: 6| Step: 2
Training loss: 2.7593530777160833
Validation loss: 2.5121566525206567

Epoch: 6| Step: 3
Training loss: 2.7076653072371455
Validation loss: 2.5041999981820497

Epoch: 6| Step: 4
Training loss: 2.2443061415653327
Validation loss: 2.507720549453509

Epoch: 6| Step: 5
Training loss: 2.1639675298571093
Validation loss: 2.502946325458421

Epoch: 6| Step: 6
Training loss: 2.352769206227984
Validation loss: 2.505877959811084

Epoch: 6| Step: 7
Training loss: 2.3591548993854627
Validation loss: 2.519582553705905

Epoch: 6| Step: 8
Training loss: 1.6981981742292884
Validation loss: 2.5243139486918142

Epoch: 6| Step: 9
Training loss: 2.297253428314736
Validation loss: 2.5154532537810965

Epoch: 6| Step: 10
Training loss: 2.376728733727172
Validation loss: 2.5236721972910994

Epoch: 6| Step: 11
Training loss: 2.492752632951556
Validation loss: 2.523064002080156

Epoch: 6| Step: 12
Training loss: 2.9544316383260574
Validation loss: 2.508599828164067

Epoch: 6| Step: 13
Training loss: 2.3637323626783653
Validation loss: 2.5177753490598267

Epoch: 164| Step: 0
Training loss: 2.7017339754593923
Validation loss: 2.504826654767665

Epoch: 6| Step: 1
Training loss: 2.068340470729238
Validation loss: 2.4993199854121504

Epoch: 6| Step: 2
Training loss: 2.555498373617372
Validation loss: 2.5021587746898732

Epoch: 6| Step: 3
Training loss: 2.4800119535096563
Validation loss: 2.509633616180634

Epoch: 6| Step: 4
Training loss: 2.532417875654813
Validation loss: 2.5143338003504137

Epoch: 6| Step: 5
Training loss: 2.621032168351422
Validation loss: 2.497370926961854

Epoch: 6| Step: 6
Training loss: 3.182893303888075
Validation loss: 2.5096960867068816

Epoch: 6| Step: 7
Training loss: 2.2073483939725165
Validation loss: 2.503144480121073

Epoch: 6| Step: 8
Training loss: 1.8079104358254794
Validation loss: 2.507713260449836

Epoch: 6| Step: 9
Training loss: 2.136783020057181
Validation loss: 2.5086889428889867

Epoch: 6| Step: 10
Training loss: 1.9364110285942333
Validation loss: 2.508528610139333

Epoch: 6| Step: 11
Training loss: 1.8244618941990538
Validation loss: 2.5191570151906864

Epoch: 6| Step: 12
Training loss: 2.748679017195186
Validation loss: 2.5244822194719965

Epoch: 6| Step: 13
Training loss: 2.774819215264065
Validation loss: 2.5505864379081546

Epoch: 165| Step: 0
Training loss: 2.4289153120056506
Validation loss: 2.5441651545233865

Epoch: 6| Step: 1
Training loss: 1.8769824673743787
Validation loss: 2.534357682814507

Epoch: 6| Step: 2
Training loss: 2.2357397646477217
Validation loss: 2.5091412154669714

Epoch: 6| Step: 3
Training loss: 2.6746839069173403
Validation loss: 2.5179520894745235

Epoch: 6| Step: 4
Training loss: 2.6080267615320185
Validation loss: 2.53443957339431

Epoch: 6| Step: 5
Training loss: 3.0931502252129404
Validation loss: 2.51863011847124

Epoch: 6| Step: 6
Training loss: 2.732994733942837
Validation loss: 2.5037019500463984

Epoch: 6| Step: 7
Training loss: 1.9110864663876115
Validation loss: 2.4964212711153944

Epoch: 6| Step: 8
Training loss: 2.5893596582236755
Validation loss: 2.4956740144329586

Epoch: 6| Step: 9
Training loss: 2.449448570164738
Validation loss: 2.4910393265379294

Epoch: 6| Step: 10
Training loss: 2.5102301141798242
Validation loss: 2.49086867687598

Epoch: 6| Step: 11
Training loss: 2.5283380406871703
Validation loss: 2.491994373966273

Epoch: 6| Step: 12
Training loss: 1.780245447488071
Validation loss: 2.502190329757062

Epoch: 6| Step: 13
Training loss: 2.2244407851161236
Validation loss: 2.487384229231166

Epoch: 166| Step: 0
Training loss: 2.3370060852781176
Validation loss: 2.5051721952267925

Epoch: 6| Step: 1
Training loss: 1.8329915537288382
Validation loss: 2.4984313255426205

Epoch: 6| Step: 2
Training loss: 1.9235295562654877
Validation loss: 2.500654214454604

Epoch: 6| Step: 3
Training loss: 2.864594245658666
Validation loss: 2.48811013168828

Epoch: 6| Step: 4
Training loss: 2.1629036234540333
Validation loss: 2.501416027856892

Epoch: 6| Step: 5
Training loss: 3.067243677947226
Validation loss: 2.496552856441967

Epoch: 6| Step: 6
Training loss: 2.527258091791263
Validation loss: 2.506646064291489

Epoch: 6| Step: 7
Training loss: 2.929550940827755
Validation loss: 2.5054895212795154

Epoch: 6| Step: 8
Training loss: 2.0808894764459724
Validation loss: 2.515438712668339

Epoch: 6| Step: 9
Training loss: 2.534771765191361
Validation loss: 2.528797657131448

Epoch: 6| Step: 10
Training loss: 2.59808006557932
Validation loss: 2.553850283689742

Epoch: 6| Step: 11
Training loss: 2.38309784728438
Validation loss: 2.527454984989138

Epoch: 6| Step: 12
Training loss: 1.9417155765818475
Validation loss: 2.5221218777701653

Epoch: 6| Step: 13
Training loss: 2.4854633178766687
Validation loss: 2.5186412175669743

Epoch: 167| Step: 0
Training loss: 2.800213233457772
Validation loss: 2.5151531337685475

Epoch: 6| Step: 1
Training loss: 2.213323054270641
Validation loss: 2.5255715289894876

Epoch: 6| Step: 2
Training loss: 2.025304809047162
Validation loss: 2.511898724489096

Epoch: 6| Step: 3
Training loss: 2.6546421345768807
Validation loss: 2.501142908155266

Epoch: 6| Step: 4
Training loss: 2.7479475338243127
Validation loss: 2.5003549482774825

Epoch: 6| Step: 5
Training loss: 2.5952153490268794
Validation loss: 2.4933535200932084

Epoch: 6| Step: 6
Training loss: 2.0327653367760368
Validation loss: 2.502958184699059

Epoch: 6| Step: 7
Training loss: 2.448033388209319
Validation loss: 2.495036164303873

Epoch: 6| Step: 8
Training loss: 2.1272760431594318
Validation loss: 2.498078116151238

Epoch: 6| Step: 9
Training loss: 1.849037670170578
Validation loss: 2.503514807261465

Epoch: 6| Step: 10
Training loss: 2.5567256718092914
Validation loss: 2.4923610248165895

Epoch: 6| Step: 11
Training loss: 2.915322366363091
Validation loss: 2.4979816554515555

Epoch: 6| Step: 12
Training loss: 2.768379951358597
Validation loss: 2.5038233607910216

Epoch: 6| Step: 13
Training loss: 2.0452613585207646
Validation loss: 2.5023819384448287

Epoch: 168| Step: 0
Training loss: 2.1804726119846105
Validation loss: 2.516396153566053

Epoch: 6| Step: 1
Training loss: 2.396205596751217
Validation loss: 2.5278732947816462

Epoch: 6| Step: 2
Training loss: 3.1754828919370457
Validation loss: 2.5227668745039606

Epoch: 6| Step: 3
Training loss: 2.1315472661217676
Validation loss: 2.538396362562446

Epoch: 6| Step: 4
Training loss: 2.354580485564358
Validation loss: 2.528151212665607

Epoch: 6| Step: 5
Training loss: 2.762948244071931
Validation loss: 2.523391518503604

Epoch: 6| Step: 6
Training loss: 2.497598639173705
Validation loss: 2.5245188629217328

Epoch: 6| Step: 7
Training loss: 2.0380831299393694
Validation loss: 2.5226044436187873

Epoch: 6| Step: 8
Training loss: 2.281745334306588
Validation loss: 2.497978720531838

Epoch: 6| Step: 9
Training loss: 2.3513635696977735
Validation loss: 2.5014631837393435

Epoch: 6| Step: 10
Training loss: 2.3513870934243384
Validation loss: 2.5033124317760342

Epoch: 6| Step: 11
Training loss: 2.576329201152283
Validation loss: 2.4951697735305793

Epoch: 6| Step: 12
Training loss: 1.7758252038982933
Validation loss: 2.495612028836434

Epoch: 6| Step: 13
Training loss: 2.6645674688380456
Validation loss: 2.4940973694828563

Epoch: 169| Step: 0
Training loss: 2.2045008914951763
Validation loss: 2.4913230201852077

Epoch: 6| Step: 1
Training loss: 2.1071299721090657
Validation loss: 2.4831625741029235

Epoch: 6| Step: 2
Training loss: 2.0957804840684875
Validation loss: 2.494028824282241

Epoch: 6| Step: 3
Training loss: 1.9833449446180664
Validation loss: 2.4859576032853896

Epoch: 6| Step: 4
Training loss: 2.508836008525823
Validation loss: 2.4828653527202533

Epoch: 6| Step: 5
Training loss: 3.3122489402205546
Validation loss: 2.489619607275428

Epoch: 6| Step: 6
Training loss: 3.2756979336959358
Validation loss: 2.5000504170738176

Epoch: 6| Step: 7
Training loss: 1.9528561216290508
Validation loss: 2.4977325170075204

Epoch: 6| Step: 8
Training loss: 2.741111957433259
Validation loss: 2.514814653057434

Epoch: 6| Step: 9
Training loss: 2.1446359744323953
Validation loss: 2.534011464792283

Epoch: 6| Step: 10
Training loss: 2.442706684906382
Validation loss: 2.5372774706200456

Epoch: 6| Step: 11
Training loss: 2.6385252239097983
Validation loss: 2.5381144157163305

Epoch: 6| Step: 12
Training loss: 2.0759127895728446
Validation loss: 2.515177448021675

Epoch: 6| Step: 13
Training loss: 2.2640368979449845
Validation loss: 2.4992635913899184

Epoch: 170| Step: 0
Training loss: 2.5474469999391114
Validation loss: 2.503061216433083

Epoch: 6| Step: 1
Training loss: 2.425418746817157
Validation loss: 2.4915382871013887

Epoch: 6| Step: 2
Training loss: 2.4033728899546456
Validation loss: 2.4925932359618503

Epoch: 6| Step: 3
Training loss: 1.7506334656929827
Validation loss: 2.501245752534655

Epoch: 6| Step: 4
Training loss: 3.44376232885795
Validation loss: 2.4927076875075

Epoch: 6| Step: 5
Training loss: 2.745105028210353
Validation loss: 2.4978649877484274

Epoch: 6| Step: 6
Training loss: 2.0451052637219846
Validation loss: 2.4930678420146317

Epoch: 6| Step: 7
Training loss: 2.8389066595660584
Validation loss: 2.4974564010281783

Epoch: 6| Step: 8
Training loss: 2.1196252506051465
Validation loss: 2.4974446190824757

Epoch: 6| Step: 9
Training loss: 1.9597459797808832
Validation loss: 2.501598737058289

Epoch: 6| Step: 10
Training loss: 2.070876710413115
Validation loss: 2.502509653540915

Epoch: 6| Step: 11
Training loss: 2.004177617963768
Validation loss: 2.4957958793907937

Epoch: 6| Step: 12
Training loss: 2.64889117380907
Validation loss: 2.506237902338601

Epoch: 6| Step: 13
Training loss: 2.5870158088003463
Validation loss: 2.513275012402931

Epoch: 171| Step: 0
Training loss: 2.638627419707864
Validation loss: 2.52447467979587

Epoch: 6| Step: 1
Training loss: 2.5801470600769125
Validation loss: 2.5305792622363628

Epoch: 6| Step: 2
Training loss: 2.1107637708034677
Validation loss: 2.526431383306012

Epoch: 6| Step: 3
Training loss: 2.298047862684111
Validation loss: 2.5169153714816117

Epoch: 6| Step: 4
Training loss: 2.3700857014995034
Validation loss: 2.5029459841273702

Epoch: 6| Step: 5
Training loss: 2.770371496580367
Validation loss: 2.5194942580077724

Epoch: 6| Step: 6
Training loss: 2.195079859017293
Validation loss: 2.5062926094574407

Epoch: 6| Step: 7
Training loss: 2.4409489806147846
Validation loss: 2.5031056822858053

Epoch: 6| Step: 8
Training loss: 1.9666929852077029
Validation loss: 2.4922318888092367

Epoch: 6| Step: 9
Training loss: 2.178581914496815
Validation loss: 2.5039567947245436

Epoch: 6| Step: 10
Training loss: 2.6145959577724245
Validation loss: 2.4997850484628215

Epoch: 6| Step: 11
Training loss: 2.58042906483212
Validation loss: 2.4913588594220006

Epoch: 6| Step: 12
Training loss: 3.0797043829406276
Validation loss: 2.5117520675703826

Epoch: 6| Step: 13
Training loss: 1.6043687750915148
Validation loss: 2.5060633880826515

Epoch: 172| Step: 0
Training loss: 2.810338949076696
Validation loss: 2.503890380174292

Epoch: 6| Step: 1
Training loss: 2.610895045338793
Validation loss: 2.5140967850987868

Epoch: 6| Step: 2
Training loss: 2.353645795965789
Validation loss: 2.528476435719416

Epoch: 6| Step: 3
Training loss: 2.1160379927961563
Validation loss: 2.5227817277761426

Epoch: 6| Step: 4
Training loss: 1.9922977192625992
Validation loss: 2.550255963313075

Epoch: 6| Step: 5
Training loss: 1.9571500882978774
Validation loss: 2.573282985375902

Epoch: 6| Step: 6
Training loss: 2.2619692016447646
Validation loss: 2.5503471593219866

Epoch: 6| Step: 7
Training loss: 2.714762251474565
Validation loss: 2.559507755163712

Epoch: 6| Step: 8
Training loss: 1.6161729514276595
Validation loss: 2.534663359656761

Epoch: 6| Step: 9
Training loss: 3.035793399581303
Validation loss: 2.51367002544913

Epoch: 6| Step: 10
Training loss: 2.825644654169983
Validation loss: 2.507709172260241

Epoch: 6| Step: 11
Training loss: 2.536552056703104
Validation loss: 2.506703544541573

Epoch: 6| Step: 12
Training loss: 2.120950318153444
Validation loss: 2.4904652606915656

Epoch: 6| Step: 13
Training loss: 2.5144967338948896
Validation loss: 2.493754262131799

Epoch: 173| Step: 0
Training loss: 2.502047653854379
Validation loss: 2.5067883516596856

Epoch: 6| Step: 1
Training loss: 2.3604731751355845
Validation loss: 2.496812855150464

Epoch: 6| Step: 2
Training loss: 2.6195022595055977
Validation loss: 2.4949477325448517

Epoch: 6| Step: 3
Training loss: 2.170081846038499
Validation loss: 2.5078196064976095

Epoch: 6| Step: 4
Training loss: 2.5930851463405276
Validation loss: 2.501087270180853

Epoch: 6| Step: 5
Training loss: 2.9689758214894355
Validation loss: 2.497310017744568

Epoch: 6| Step: 6
Training loss: 2.1772204147573198
Validation loss: 2.4868783554229634

Epoch: 6| Step: 7
Training loss: 2.2140472433120473
Validation loss: 2.5032425356355237

Epoch: 6| Step: 8
Training loss: 2.4289889297327316
Validation loss: 2.511159420275481

Epoch: 6| Step: 9
Training loss: 2.0943351041932154
Validation loss: 2.5075364639303386

Epoch: 6| Step: 10
Training loss: 2.7341427949675023
Validation loss: 2.504567963937951

Epoch: 6| Step: 11
Training loss: 2.5509651900562864
Validation loss: 2.494540396336196

Epoch: 6| Step: 12
Training loss: 2.344587659554439
Validation loss: 2.5027229500538524

Epoch: 6| Step: 13
Training loss: 2.3049988617139143
Validation loss: 2.4949401752865277

Epoch: 174| Step: 0
Training loss: 2.596711272255258
Validation loss: 2.5173535933692897

Epoch: 6| Step: 1
Training loss: 2.9288224634379714
Validation loss: 2.5167135091131683

Epoch: 6| Step: 2
Training loss: 2.4574145092457367
Validation loss: 2.5070119909155197

Epoch: 6| Step: 3
Training loss: 2.3956649610538903
Validation loss: 2.5214957057975065

Epoch: 6| Step: 4
Training loss: 2.170168638576468
Validation loss: 2.520039336159905

Epoch: 6| Step: 5
Training loss: 2.6626633356704215
Validation loss: 2.511091044110413

Epoch: 6| Step: 6
Training loss: 2.3936573817410314
Validation loss: 2.528207418122348

Epoch: 6| Step: 7
Training loss: 2.6171225468560793
Validation loss: 2.523968155595531

Epoch: 6| Step: 8
Training loss: 2.2380528624754095
Validation loss: 2.521108554496756

Epoch: 6| Step: 9
Training loss: 1.9491994241432984
Validation loss: 2.5213136661972197

Epoch: 6| Step: 10
Training loss: 2.566760173762211
Validation loss: 2.5135116862029245

Epoch: 6| Step: 11
Training loss: 2.511110223171711
Validation loss: 2.498465591663988

Epoch: 6| Step: 12
Training loss: 1.9362356921480648
Validation loss: 2.5010486469756597

Epoch: 6| Step: 13
Training loss: 1.9682430038376262
Validation loss: 2.5069664531198415

Epoch: 175| Step: 0
Training loss: 1.7874472043436807
Validation loss: 2.511760120041259

Epoch: 6| Step: 1
Training loss: 2.428044490387737
Validation loss: 2.512726608735781

Epoch: 6| Step: 2
Training loss: 2.128359327145103
Validation loss: 2.5055152377272543

Epoch: 6| Step: 3
Training loss: 2.5292456897873445
Validation loss: 2.501609729048586

Epoch: 6| Step: 4
Training loss: 2.3827598691036904
Validation loss: 2.5099897430534575

Epoch: 6| Step: 5
Training loss: 1.988412789001346
Validation loss: 2.5042622948369773

Epoch: 6| Step: 6
Training loss: 2.7928439452556724
Validation loss: 2.5040272223756994

Epoch: 6| Step: 7
Training loss: 2.2393851495630437
Validation loss: 2.520437671937302

Epoch: 6| Step: 8
Training loss: 2.4232237966969072
Validation loss: 2.5418918593239717

Epoch: 6| Step: 9
Training loss: 2.5781847397789783
Validation loss: 2.514969560680384

Epoch: 6| Step: 10
Training loss: 2.4685289308097795
Validation loss: 2.5080141836096894

Epoch: 6| Step: 11
Training loss: 1.9239990158475075
Validation loss: 2.5089988556432665

Epoch: 6| Step: 12
Training loss: 3.1602602117575804
Validation loss: 2.5113433114326082

Epoch: 6| Step: 13
Training loss: 2.5653430704829523
Validation loss: 2.5066544660650085

Epoch: 176| Step: 0
Training loss: 2.6693347656533244
Validation loss: 2.511577912728273

Epoch: 6| Step: 1
Training loss: 2.4637893864054137
Validation loss: 2.4988042514923423

Epoch: 6| Step: 2
Training loss: 2.597378685828783
Validation loss: 2.4843334458432706

Epoch: 6| Step: 3
Training loss: 2.5115267144767777
Validation loss: 2.4984831658906272

Epoch: 6| Step: 4
Training loss: 1.7665211251726236
Validation loss: 2.490180631568756

Epoch: 6| Step: 5
Training loss: 2.3127255716366673
Validation loss: 2.5112759134016724

Epoch: 6| Step: 6
Training loss: 2.6119436082229304
Validation loss: 2.4963640157238802

Epoch: 6| Step: 7
Training loss: 2.0448114607622623
Validation loss: 2.504594395859049

Epoch: 6| Step: 8
Training loss: 2.051657295215977
Validation loss: 2.4974683022484343

Epoch: 6| Step: 9
Training loss: 2.3453830370375717
Validation loss: 2.506021559301597

Epoch: 6| Step: 10
Training loss: 2.8168552162520126
Validation loss: 2.5166765625445433

Epoch: 6| Step: 11
Training loss: 2.808730417887016
Validation loss: 2.504515480040881

Epoch: 6| Step: 12
Training loss: 2.4918493920458276
Validation loss: 2.5052222068439485

Epoch: 6| Step: 13
Training loss: 1.7745088542503433
Validation loss: 2.518902588317051

Epoch: 177| Step: 0
Training loss: 2.6071865018412668
Validation loss: 2.517690533243771

Epoch: 6| Step: 1
Training loss: 1.7702732172729567
Validation loss: 2.5352549012067835

Epoch: 6| Step: 2
Training loss: 2.6787292724604925
Validation loss: 2.526162769259335

Epoch: 6| Step: 3
Training loss: 2.1911385928621407
Validation loss: 2.512420319010137

Epoch: 6| Step: 4
Training loss: 1.9022991324015637
Validation loss: 2.5266381703189853

Epoch: 6| Step: 5
Training loss: 2.8601845184237944
Validation loss: 2.5296169554699706

Epoch: 6| Step: 6
Training loss: 1.9965208309624012
Validation loss: 2.5309441150095737

Epoch: 6| Step: 7
Training loss: 2.289291630757055
Validation loss: 2.508946702003099

Epoch: 6| Step: 8
Training loss: 2.461508645280576
Validation loss: 2.5121329417423555

Epoch: 6| Step: 9
Training loss: 2.563918116733443
Validation loss: 2.5137667456495456

Epoch: 6| Step: 10
Training loss: 2.617037003019044
Validation loss: 2.510047954111371

Epoch: 6| Step: 11
Training loss: 2.4677018463534726
Validation loss: 2.504212898762786

Epoch: 6| Step: 12
Training loss: 2.292683832250554
Validation loss: 2.4857632419100857

Epoch: 6| Step: 13
Training loss: 2.500697610797718
Validation loss: 2.4905887047497446

Epoch: 178| Step: 0
Training loss: 2.59905756962868
Validation loss: 2.499679258752403

Epoch: 6| Step: 1
Training loss: 1.8275458567824168
Validation loss: 2.493842393634272

Epoch: 6| Step: 2
Training loss: 1.9121935380720954
Validation loss: 2.506996346802618

Epoch: 6| Step: 3
Training loss: 2.3135633343662807
Validation loss: 2.4897827855955295

Epoch: 6| Step: 4
Training loss: 2.5914529947429883
Validation loss: 2.4945686946821897

Epoch: 6| Step: 5
Training loss: 2.6021205544132093
Validation loss: 2.5144185239504995

Epoch: 6| Step: 6
Training loss: 2.2625039537932694
Validation loss: 2.5116351060797677

Epoch: 6| Step: 7
Training loss: 2.643024505559361
Validation loss: 2.5314895453742308

Epoch: 6| Step: 8
Training loss: 2.6917873162628676
Validation loss: 2.5393069731563553

Epoch: 6| Step: 9
Training loss: 2.3407845619727734
Validation loss: 2.5423167496930543

Epoch: 6| Step: 10
Training loss: 1.989838235980011
Validation loss: 2.5538602183602563

Epoch: 6| Step: 11
Training loss: 2.5071775399069307
Validation loss: 2.540281791387212

Epoch: 6| Step: 12
Training loss: 2.862708144970215
Validation loss: 2.518313611944481

Epoch: 6| Step: 13
Training loss: 2.166929253536336
Validation loss: 2.535278419250832

Epoch: 179| Step: 0
Training loss: 2.7061638481399712
Validation loss: 2.5098274431148333

Epoch: 6| Step: 1
Training loss: 1.7794178022375868
Validation loss: 2.520188309506197

Epoch: 6| Step: 2
Training loss: 2.3464987340176293
Validation loss: 2.5174744877916284

Epoch: 6| Step: 3
Training loss: 2.6862255889507654
Validation loss: 2.5030266242791304

Epoch: 6| Step: 4
Training loss: 1.784738971847658
Validation loss: 2.5228808471085737

Epoch: 6| Step: 5
Training loss: 2.3686059913039603
Validation loss: 2.5135817512849794

Epoch: 6| Step: 6
Training loss: 2.1674322340776535
Validation loss: 2.51335591403049

Epoch: 6| Step: 7
Training loss: 2.5227694261857847
Validation loss: 2.506677483609716

Epoch: 6| Step: 8
Training loss: 2.4350017558567365
Validation loss: 2.5080290291894385

Epoch: 6| Step: 9
Training loss: 2.4741180582519124
Validation loss: 2.5182055867040223

Epoch: 6| Step: 10
Training loss: 2.1224399179822115
Validation loss: 2.507296357561855

Epoch: 6| Step: 11
Training loss: 2.7570244633111956
Validation loss: 2.510001078247001

Epoch: 6| Step: 12
Training loss: 2.2027806222562423
Validation loss: 2.5200491597159065

Epoch: 6| Step: 13
Training loss: 2.94383984082403
Validation loss: 2.539563690017783

Epoch: 180| Step: 0
Training loss: 2.082641855562607
Validation loss: 2.5448249257793027

Epoch: 6| Step: 1
Training loss: 2.3353256393873596
Validation loss: 2.560739905178595

Epoch: 6| Step: 2
Training loss: 1.8801266836540922
Validation loss: 2.5836408391075083

Epoch: 6| Step: 3
Training loss: 2.5748256031718473
Validation loss: 2.5756925031318065

Epoch: 6| Step: 4
Training loss: 2.120914458676193
Validation loss: 2.5541072579258337

Epoch: 6| Step: 5
Training loss: 2.761570172447605
Validation loss: 2.5410812881590434

Epoch: 6| Step: 6
Training loss: 3.3778272019361997
Validation loss: 2.5235831550314485

Epoch: 6| Step: 7
Training loss: 2.1867299495626917
Validation loss: 2.5232959939905943

Epoch: 6| Step: 8
Training loss: 2.487134636351804
Validation loss: 2.5059120527495207

Epoch: 6| Step: 9
Training loss: 2.5183829596237426
Validation loss: 2.502211911478739

Epoch: 6| Step: 10
Training loss: 2.2598559362355517
Validation loss: 2.5095618495520875

Epoch: 6| Step: 11
Training loss: 2.4444643932549637
Validation loss: 2.500467050158434

Epoch: 6| Step: 12
Training loss: 2.6944231860533696
Validation loss: 2.515572193926269

Epoch: 6| Step: 13
Training loss: 2.121551857614114
Validation loss: 2.509065934748723

Epoch: 181| Step: 0
Training loss: 2.1818489105054746
Validation loss: 2.4999278376019096

Epoch: 6| Step: 1
Training loss: 2.080665698812191
Validation loss: 2.500739210832691

Epoch: 6| Step: 2
Training loss: 2.7383408043407917
Validation loss: 2.500632698741968

Epoch: 6| Step: 3
Training loss: 2.3097423916800923
Validation loss: 2.5100181205191676

Epoch: 6| Step: 4
Training loss: 1.2962386167020903
Validation loss: 2.515940502276935

Epoch: 6| Step: 5
Training loss: 2.4925995010824806
Validation loss: 2.537912642465784

Epoch: 6| Step: 6
Training loss: 2.3219269039467476
Validation loss: 2.535649687048444

Epoch: 6| Step: 7
Training loss: 2.5860124559862174
Validation loss: 2.5650332729915517

Epoch: 6| Step: 8
Training loss: 1.8820727782776532
Validation loss: 2.5696778600939423

Epoch: 6| Step: 9
Training loss: 2.3651255071456103
Validation loss: 2.5783075749648283

Epoch: 6| Step: 10
Training loss: 2.782879212922221
Validation loss: 2.5534076731851605

Epoch: 6| Step: 11
Training loss: 2.7427355444157504
Validation loss: 2.527387049685837

Epoch: 6| Step: 12
Training loss: 2.908438402116127
Validation loss: 2.518444021869512

Epoch: 6| Step: 13
Training loss: 2.4999412529718668
Validation loss: 2.505023946869703

Epoch: 182| Step: 0
Training loss: 2.371847670728124
Validation loss: 2.5053775013824544

Epoch: 6| Step: 1
Training loss: 2.5474678706874907
Validation loss: 2.5110381743389056

Epoch: 6| Step: 2
Training loss: 1.7341338668769235
Validation loss: 2.5001855225072505

Epoch: 6| Step: 3
Training loss: 2.7689199701153013
Validation loss: 2.496798197520342

Epoch: 6| Step: 4
Training loss: 2.611712750545803
Validation loss: 2.498856887146964

Epoch: 6| Step: 5
Training loss: 2.4338623682383633
Validation loss: 2.5007470286382594

Epoch: 6| Step: 6
Training loss: 2.487747686121864
Validation loss: 2.502830206711986

Epoch: 6| Step: 7
Training loss: 2.5259424773467716
Validation loss: 2.5139554566994704

Epoch: 6| Step: 8
Training loss: 1.7159378628095592
Validation loss: 2.5107014495856363

Epoch: 6| Step: 9
Training loss: 2.141615367032572
Validation loss: 2.505771031833116

Epoch: 6| Step: 10
Training loss: 2.61284712534102
Validation loss: 2.5244638031044153

Epoch: 6| Step: 11
Training loss: 2.98213918928797
Validation loss: 2.5125371332413673

Epoch: 6| Step: 12
Training loss: 2.135203938626844
Validation loss: 2.5084369234596324

Epoch: 6| Step: 13
Training loss: 2.141560037038988
Validation loss: 2.5074228239495935

Epoch: 183| Step: 0
Training loss: 3.285097318975741
Validation loss: 2.5164918057743924

Epoch: 6| Step: 1
Training loss: 2.340958013132762
Validation loss: 2.514580756699433

Epoch: 6| Step: 2
Training loss: 2.2518363452550827
Validation loss: 2.508793085574415

Epoch: 6| Step: 3
Training loss: 2.257014678123114
Validation loss: 2.509306734834277

Epoch: 6| Step: 4
Training loss: 2.032791257215102
Validation loss: 2.5207495609792425

Epoch: 6| Step: 5
Training loss: 2.036576315607749
Validation loss: 2.523280718551757

Epoch: 6| Step: 6
Training loss: 2.376096572698704
Validation loss: 2.516481431455603

Epoch: 6| Step: 7
Training loss: 2.3463541440861424
Validation loss: 2.5284327382198573

Epoch: 6| Step: 8
Training loss: 2.0512678459176903
Validation loss: 2.530668623606277

Epoch: 6| Step: 9
Training loss: 2.1454155771451897
Validation loss: 2.529888116375539

Epoch: 6| Step: 10
Training loss: 2.498120746012433
Validation loss: 2.5231641024889737

Epoch: 6| Step: 11
Training loss: 2.7840868594223322
Validation loss: 2.5190337407001695

Epoch: 6| Step: 12
Training loss: 2.1790491625564887
Validation loss: 2.5107897617101567

Epoch: 6| Step: 13
Training loss: 2.368709062610057
Validation loss: 2.5031063014049195

Epoch: 184| Step: 0
Training loss: 2.260198474203482
Validation loss: 2.520952573956346

Epoch: 6| Step: 1
Training loss: 2.4786290352488534
Validation loss: 2.5076746125307277

Epoch: 6| Step: 2
Training loss: 2.3311096108226397
Validation loss: 2.5059133054579585

Epoch: 6| Step: 3
Training loss: 2.1197332300727854
Validation loss: 2.513661900055683

Epoch: 6| Step: 4
Training loss: 2.4652221195821187
Validation loss: 2.5068993416131224

Epoch: 6| Step: 5
Training loss: 3.499795362757194
Validation loss: 2.501988589620859

Epoch: 6| Step: 6
Training loss: 2.340472052635686
Validation loss: 2.512041418253464

Epoch: 6| Step: 7
Training loss: 2.2117838503339664
Validation loss: 2.5131211782921445

Epoch: 6| Step: 8
Training loss: 2.31112516620022
Validation loss: 2.507377864136234

Epoch: 6| Step: 9
Training loss: 2.5167680122062115
Validation loss: 2.515310011072705

Epoch: 6| Step: 10
Training loss: 1.4008443568195152
Validation loss: 2.518470907722226

Epoch: 6| Step: 11
Training loss: 2.1549467488234813
Validation loss: 2.5177843607696477

Epoch: 6| Step: 12
Training loss: 2.784515521167384
Validation loss: 2.534119035782707

Epoch: 6| Step: 13
Training loss: 1.8421302404718072
Validation loss: 2.530871759419601

Epoch: 185| Step: 0
Training loss: 2.4592149306753055
Validation loss: 2.543199754292685

Epoch: 6| Step: 1
Training loss: 2.0807115333647057
Validation loss: 2.550519103151627

Epoch: 6| Step: 2
Training loss: 2.328313730257924
Validation loss: 2.549316546533826

Epoch: 6| Step: 3
Training loss: 2.2407572900086814
Validation loss: 2.5352418451108143

Epoch: 6| Step: 4
Training loss: 1.6991082517277931
Validation loss: 2.5158655592615116

Epoch: 6| Step: 5
Training loss: 2.791697563645682
Validation loss: 2.519008911557226

Epoch: 6| Step: 6
Training loss: 2.1811194962862714
Validation loss: 2.5154866403634273

Epoch: 6| Step: 7
Training loss: 2.692654922122879
Validation loss: 2.5083151577980662

Epoch: 6| Step: 8
Training loss: 2.550782745501093
Validation loss: 2.5032112160708246

Epoch: 6| Step: 9
Training loss: 2.1148614810105895
Validation loss: 2.501704604437049

Epoch: 6| Step: 10
Training loss: 2.865722115471601
Validation loss: 2.517702843866978

Epoch: 6| Step: 11
Training loss: 2.0186990170492347
Validation loss: 2.5048335317779604

Epoch: 6| Step: 12
Training loss: 2.518950734055381
Validation loss: 2.511318999615216

Epoch: 6| Step: 13
Training loss: 2.569846809660465
Validation loss: 2.509165429611518

Epoch: 186| Step: 0
Training loss: 1.593809089313237
Validation loss: 2.5185527468700113

Epoch: 6| Step: 1
Training loss: 2.5708491452151785
Validation loss: 2.5333354820275815

Epoch: 6| Step: 2
Training loss: 2.1612940959502605
Validation loss: 2.548476887516872

Epoch: 6| Step: 3
Training loss: 2.588866634937229
Validation loss: 2.567436054229546

Epoch: 6| Step: 4
Training loss: 2.1266535888716214
Validation loss: 2.5368306998286463

Epoch: 6| Step: 5
Training loss: 2.138775548642995
Validation loss: 2.5258461053924526

Epoch: 6| Step: 6
Training loss: 2.5827395669432676
Validation loss: 2.53007154936508

Epoch: 6| Step: 7
Training loss: 2.55235272497322
Validation loss: 2.5243977706649092

Epoch: 6| Step: 8
Training loss: 1.9390309960620988
Validation loss: 2.50472117318284

Epoch: 6| Step: 9
Training loss: 2.1555790617514314
Validation loss: 2.5060020717349447

Epoch: 6| Step: 10
Training loss: 2.614005451754173
Validation loss: 2.5079907030149258

Epoch: 6| Step: 11
Training loss: 2.7936800817833505
Validation loss: 2.4972617571139604

Epoch: 6| Step: 12
Training loss: 3.0730732161305916
Validation loss: 2.498888913253498

Epoch: 6| Step: 13
Training loss: 2.408714815525183
Validation loss: 2.5135510664341365

Epoch: 187| Step: 0
Training loss: 1.8253759597852075
Validation loss: 2.5213986122917276

Epoch: 6| Step: 1
Training loss: 2.6626928841655286
Validation loss: 2.5128494019746577

Epoch: 6| Step: 2
Training loss: 2.741818568960024
Validation loss: 2.519062008397267

Epoch: 6| Step: 3
Training loss: 1.7517160448736193
Validation loss: 2.530246904774631

Epoch: 6| Step: 4
Training loss: 2.1436169730415497
Validation loss: 2.5395965796968283

Epoch: 6| Step: 5
Training loss: 2.806820539151277
Validation loss: 2.547371033962669

Epoch: 6| Step: 6
Training loss: 2.3095996298350667
Validation loss: 2.528634804342453

Epoch: 6| Step: 7
Training loss: 2.001290977577927
Validation loss: 2.5255331779540686

Epoch: 6| Step: 8
Training loss: 2.4021226238424185
Validation loss: 2.520657672489037

Epoch: 6| Step: 9
Training loss: 2.429231165383526
Validation loss: 2.5235937205991257

Epoch: 6| Step: 10
Training loss: 2.4703454765227604
Validation loss: 2.5235683694608357

Epoch: 6| Step: 11
Training loss: 2.352040796652697
Validation loss: 2.533915964270156

Epoch: 6| Step: 12
Training loss: 2.04519747650331
Validation loss: 2.5198924986045976

Epoch: 6| Step: 13
Training loss: 2.946222220456979
Validation loss: 2.5223781224055077

Epoch: 188| Step: 0
Training loss: 2.2481542009838575
Validation loss: 2.5230003112065016

Epoch: 6| Step: 1
Training loss: 2.3674361598784146
Validation loss: 2.5246284123314378

Epoch: 6| Step: 2
Training loss: 2.1755777534367233
Validation loss: 2.5222826067753727

Epoch: 6| Step: 3
Training loss: 2.399997564155614
Validation loss: 2.5277822311650917

Epoch: 6| Step: 4
Training loss: 2.7501887343405014
Validation loss: 2.52318728439616

Epoch: 6| Step: 5
Training loss: 2.7837173147556595
Validation loss: 2.5316026700963348

Epoch: 6| Step: 6
Training loss: 2.0221834162713748
Validation loss: 2.5177759645716815

Epoch: 6| Step: 7
Training loss: 1.962882365498792
Validation loss: 2.5204422439822025

Epoch: 6| Step: 8
Training loss: 1.632453623488265
Validation loss: 2.5258269910272326

Epoch: 6| Step: 9
Training loss: 2.134456685459335
Validation loss: 2.5314059425323836

Epoch: 6| Step: 10
Training loss: 2.299864607433319
Validation loss: 2.5167916003747304

Epoch: 6| Step: 11
Training loss: 3.202009946684962
Validation loss: 2.5338812287869605

Epoch: 6| Step: 12
Training loss: 2.5693042018065704
Validation loss: 2.533037888611639

Epoch: 6| Step: 13
Training loss: 2.2304151966192984
Validation loss: 2.5308512620873884

Epoch: 189| Step: 0
Training loss: 1.7948822249556633
Validation loss: 2.5323588921115467

Epoch: 6| Step: 1
Training loss: 2.300469732001272
Validation loss: 2.5407451199283844

Epoch: 6| Step: 2
Training loss: 2.279217271632385
Validation loss: 2.5356081112687914

Epoch: 6| Step: 3
Training loss: 2.1682964455323
Validation loss: 2.5217661484708382

Epoch: 6| Step: 4
Training loss: 1.8658286541017868
Validation loss: 2.525645452408869

Epoch: 6| Step: 5
Training loss: 2.1228824611474977
Validation loss: 2.521063460467649

Epoch: 6| Step: 6
Training loss: 2.111915245609698
Validation loss: 2.5105350091880427

Epoch: 6| Step: 7
Training loss: 2.6851958222257704
Validation loss: 2.517722193519742

Epoch: 6| Step: 8
Training loss: 2.445416238065123
Validation loss: 2.517902890948935

Epoch: 6| Step: 9
Training loss: 2.010669382712421
Validation loss: 2.520635224011129

Epoch: 6| Step: 10
Training loss: 2.8764807163694854
Validation loss: 2.510595613383127

Epoch: 6| Step: 11
Training loss: 2.9842922339022198
Validation loss: 2.5130955159581982

Epoch: 6| Step: 12
Training loss: 2.881440950301297
Validation loss: 2.5245074512515027

Epoch: 6| Step: 13
Training loss: 2.368123288147691
Validation loss: 2.529672295829222

Epoch: 190| Step: 0
Training loss: 2.6872460888525307
Validation loss: 2.5376934566572733

Epoch: 6| Step: 1
Training loss: 2.94009317419105
Validation loss: 2.5651380094564478

Epoch: 6| Step: 2
Training loss: 2.126593272976625
Validation loss: 2.583966521117104

Epoch: 6| Step: 3
Training loss: 2.5123750532216595
Validation loss: 2.5852613842543244

Epoch: 6| Step: 4
Training loss: 2.3006159621032425
Validation loss: 2.5488191139188574

Epoch: 6| Step: 5
Training loss: 2.578324928623434
Validation loss: 2.5397105949963015

Epoch: 6| Step: 6
Training loss: 1.97594167737566
Validation loss: 2.513671147826316

Epoch: 6| Step: 7
Training loss: 2.5036348621330915
Validation loss: 2.508730853910046

Epoch: 6| Step: 8
Training loss: 2.690971793444746
Validation loss: 2.4918146442458102

Epoch: 6| Step: 9
Training loss: 2.6244470831430413
Validation loss: 2.4973641646481872

Epoch: 6| Step: 10
Training loss: 2.007590552505059
Validation loss: 2.4915847607507335

Epoch: 6| Step: 11
Training loss: 1.8532337098938543
Validation loss: 2.4995863731261085

Epoch: 6| Step: 12
Training loss: 2.4486489249103474
Validation loss: 2.4967905901604746

Epoch: 6| Step: 13
Training loss: 2.2537767713567867
Validation loss: 2.5043518495136246

Epoch: 191| Step: 0
Training loss: 2.698548781723938
Validation loss: 2.5152053482980383

Epoch: 6| Step: 1
Training loss: 2.233475830978956
Validation loss: 2.5160398279463254

Epoch: 6| Step: 2
Training loss: 2.3821436208992144
Validation loss: 2.5209814979159755

Epoch: 6| Step: 3
Training loss: 2.1705095128938607
Validation loss: 2.5230400158196877

Epoch: 6| Step: 4
Training loss: 2.385097921028717
Validation loss: 2.5285372385002645

Epoch: 6| Step: 5
Training loss: 2.258152180499399
Validation loss: 2.5573917428898443

Epoch: 6| Step: 6
Training loss: 2.627844858377474
Validation loss: 2.5789494438910814

Epoch: 6| Step: 7
Training loss: 1.9930137566389805
Validation loss: 2.5919644211306223

Epoch: 6| Step: 8
Training loss: 2.9155017888078874
Validation loss: 2.6389530765244884

Epoch: 6| Step: 9
Training loss: 2.111876636153392
Validation loss: 2.596817133473385

Epoch: 6| Step: 10
Training loss: 2.1525971805198556
Validation loss: 2.5490790193705326

Epoch: 6| Step: 11
Training loss: 2.694278242178572
Validation loss: 2.517871966796648

Epoch: 6| Step: 12
Training loss: 2.2087866359882553
Validation loss: 2.5051757006723943

Epoch: 6| Step: 13
Training loss: 2.6227865423679013
Validation loss: 2.5149251939886494

Epoch: 192| Step: 0
Training loss: 2.5185584740907943
Validation loss: 2.4993877614891

Epoch: 6| Step: 1
Training loss: 3.2358377438525894
Validation loss: 2.5032980860232144

Epoch: 6| Step: 2
Training loss: 1.8213484930819672
Validation loss: 2.4964625126480238

Epoch: 6| Step: 3
Training loss: 2.197216579313731
Validation loss: 2.5054978317731464

Epoch: 6| Step: 4
Training loss: 2.3989201659593604
Validation loss: 2.4920772739377766

Epoch: 6| Step: 5
Training loss: 2.000254018864637
Validation loss: 2.5070163813936945

Epoch: 6| Step: 6
Training loss: 2.296986272283444
Validation loss: 2.4952662792316227

Epoch: 6| Step: 7
Training loss: 2.128398309710053
Validation loss: 2.500511816403553

Epoch: 6| Step: 8
Training loss: 2.364998589126134
Validation loss: 2.4939142700497197

Epoch: 6| Step: 9
Training loss: 2.5604580442614835
Validation loss: 2.507786450592415

Epoch: 6| Step: 10
Training loss: 2.2650939318987873
Validation loss: 2.514716227089909

Epoch: 6| Step: 11
Training loss: 2.1856051276167765
Validation loss: 2.539084676009929

Epoch: 6| Step: 12
Training loss: 2.5149426215965835
Validation loss: 2.5587709632440934

Epoch: 6| Step: 13
Training loss: 2.784145605225889
Validation loss: 2.5752665847754344

Epoch: 193| Step: 0
Training loss: 2.469883139621928
Validation loss: 2.600957668436622

Epoch: 6| Step: 1
Training loss: 2.6787339006831092
Validation loss: 2.586738500785639

Epoch: 6| Step: 2
Training loss: 2.9465704945653957
Validation loss: 2.5733094063652864

Epoch: 6| Step: 3
Training loss: 1.879395990130799
Validation loss: 2.540103139610518

Epoch: 6| Step: 4
Training loss: 2.36178082211991
Validation loss: 2.5231782919832635

Epoch: 6| Step: 5
Training loss: 2.5361127885653003
Validation loss: 2.531953290088143

Epoch: 6| Step: 6
Training loss: 2.6863757598678495
Validation loss: 2.5131903767424735

Epoch: 6| Step: 7
Training loss: 1.7578225368637066
Validation loss: 2.500275930435931

Epoch: 6| Step: 8
Training loss: 2.486565541860847
Validation loss: 2.5055151742889166

Epoch: 6| Step: 9
Training loss: 2.283957559876046
Validation loss: 2.513915735058082

Epoch: 6| Step: 10
Training loss: 2.385671632514331
Validation loss: 2.5055007896044

Epoch: 6| Step: 11
Training loss: 2.403459293046949
Validation loss: 2.509348263406103

Epoch: 6| Step: 12
Training loss: 2.2474091766303146
Validation loss: 2.503831482404277

Epoch: 6| Step: 13
Training loss: 2.3770319628590637
Validation loss: 2.50795354080112

Epoch: 194| Step: 0
Training loss: 2.0863743013958214
Validation loss: 2.5004892665208307

Epoch: 6| Step: 1
Training loss: 2.4627152092319213
Validation loss: 2.5105980349881047

Epoch: 6| Step: 2
Training loss: 2.0084298813697496
Validation loss: 2.5186471181324266

Epoch: 6| Step: 3
Training loss: 2.6970196169096288
Validation loss: 2.51657849361577

Epoch: 6| Step: 4
Training loss: 1.7528471945901039
Validation loss: 2.516274773061547

Epoch: 6| Step: 5
Training loss: 2.7086312545851325
Validation loss: 2.5309555918589397

Epoch: 6| Step: 6
Training loss: 2.4750491551613854
Validation loss: 2.533462468001461

Epoch: 6| Step: 7
Training loss: 3.3263383108039934
Validation loss: 2.53069968187096

Epoch: 6| Step: 8
Training loss: 2.5820890526931093
Validation loss: 2.521784663325478

Epoch: 6| Step: 9
Training loss: 2.2921274126598417
Validation loss: 2.5170674265995787

Epoch: 6| Step: 10
Training loss: 2.18648331040111
Validation loss: 2.5203718966355058

Epoch: 6| Step: 11
Training loss: 1.6098295884544815
Validation loss: 2.517328463521722

Epoch: 6| Step: 12
Training loss: 2.4468367338537793
Validation loss: 2.52453840430344

Epoch: 6| Step: 13
Training loss: 1.924884022278174
Validation loss: 2.5180836385329983

Epoch: 195| Step: 0
Training loss: 1.8884663514403588
Validation loss: 2.5269417538861

Epoch: 6| Step: 1
Training loss: 1.6775339204454243
Validation loss: 2.5188528798739758

Epoch: 6| Step: 2
Training loss: 2.860496259463178
Validation loss: 2.529036177820269

Epoch: 6| Step: 3
Training loss: 2.2173745633572226
Validation loss: 2.5331954779469075

Epoch: 6| Step: 4
Training loss: 2.228378893496561
Validation loss: 2.5304264879677314

Epoch: 6| Step: 5
Training loss: 2.7744412177481337
Validation loss: 2.519977492605342

Epoch: 6| Step: 6
Training loss: 2.7344668127722063
Validation loss: 2.5086878182827816

Epoch: 6| Step: 7
Training loss: 1.9389697622151796
Validation loss: 2.519199840425236

Epoch: 6| Step: 8
Training loss: 2.9879724679620656
Validation loss: 2.5091608528552127

Epoch: 6| Step: 9
Training loss: 2.125835254548193
Validation loss: 2.510071755823574

Epoch: 6| Step: 10
Training loss: 2.3020674991206955
Validation loss: 2.513522657714329

Epoch: 6| Step: 11
Training loss: 2.4902003865633944
Validation loss: 2.511796411210477

Epoch: 6| Step: 12
Training loss: 2.1658163847583647
Validation loss: 2.5062608682170073

Epoch: 6| Step: 13
Training loss: 2.572229476361886
Validation loss: 2.5125237534951665

Epoch: 196| Step: 0
Training loss: 2.4159587831834
Validation loss: 2.513136436425629

Epoch: 6| Step: 1
Training loss: 1.6930818429306873
Validation loss: 2.5122553527554325

Epoch: 6| Step: 2
Training loss: 1.9484675915190879
Validation loss: 2.5108729194544757

Epoch: 6| Step: 3
Training loss: 1.886460059460237
Validation loss: 2.5056429437743515

Epoch: 6| Step: 4
Training loss: 1.9659670582181745
Validation loss: 2.5320444155559403

Epoch: 6| Step: 5
Training loss: 2.791907646444347
Validation loss: 2.53968790812767

Epoch: 6| Step: 6
Training loss: 3.113929977697935
Validation loss: 2.547782065536781

Epoch: 6| Step: 7
Training loss: 2.6061418799059006
Validation loss: 2.5360784278770128

Epoch: 6| Step: 8
Training loss: 2.55295833197724
Validation loss: 2.5445409583879726

Epoch: 6| Step: 9
Training loss: 2.315405386576401
Validation loss: 2.5220024193296595

Epoch: 6| Step: 10
Training loss: 2.327677126822399
Validation loss: 2.528493188453709

Epoch: 6| Step: 11
Training loss: 2.1285407916321093
Validation loss: 2.5114198371366028

Epoch: 6| Step: 12
Training loss: 2.806874392230576
Validation loss: 2.4997063941208117

Epoch: 6| Step: 13
Training loss: 2.1996966803134654
Validation loss: 2.5068312613831614

Epoch: 197| Step: 0
Training loss: 2.55913024402745
Validation loss: 2.5083778354165354

Epoch: 6| Step: 1
Training loss: 2.228167788401004
Validation loss: 2.5179313607181397

Epoch: 6| Step: 2
Training loss: 2.3123010085809907
Validation loss: 2.5134604561991445

Epoch: 6| Step: 3
Training loss: 2.6215859873346243
Validation loss: 2.5007151852284664

Epoch: 6| Step: 4
Training loss: 2.3825019008632893
Validation loss: 2.5151273025793612

Epoch: 6| Step: 5
Training loss: 2.3356723188343946
Validation loss: 2.512581984920464

Epoch: 6| Step: 6
Training loss: 2.362750234924957
Validation loss: 2.520406502982624

Epoch: 6| Step: 7
Training loss: 2.4303529079669035
Validation loss: 2.4989416107300904

Epoch: 6| Step: 8
Training loss: 2.251367153612171
Validation loss: 2.5293333701467366

Epoch: 6| Step: 9
Training loss: 2.073732940622055
Validation loss: 2.5273757924677787

Epoch: 6| Step: 10
Training loss: 2.7738274958246802
Validation loss: 2.524865312414777

Epoch: 6| Step: 11
Training loss: 2.0730089585607074
Validation loss: 2.5078805615150603

Epoch: 6| Step: 12
Training loss: 2.302305173469818
Validation loss: 2.51106556674799

Epoch: 6| Step: 13
Training loss: 2.2495952878001906
Validation loss: 2.5138577084044864

Epoch: 198| Step: 0
Training loss: 2.227979991843548
Validation loss: 2.5037511181396384

Epoch: 6| Step: 1
Training loss: 2.0458392369119753
Validation loss: 2.5070831806989458

Epoch: 6| Step: 2
Training loss: 2.20229058663302
Validation loss: 2.5024122600563836

Epoch: 6| Step: 3
Training loss: 2.2575201881494533
Validation loss: 2.496533008464438

Epoch: 6| Step: 4
Training loss: 2.2022988143293443
Validation loss: 2.5199106645391414

Epoch: 6| Step: 5
Training loss: 1.5372795195004192
Validation loss: 2.5134896323715736

Epoch: 6| Step: 6
Training loss: 2.6929625951277756
Validation loss: 2.5136278648050925

Epoch: 6| Step: 7
Training loss: 2.2489100041275636
Validation loss: 2.538073663118005

Epoch: 6| Step: 8
Training loss: 2.495868702565168
Validation loss: 2.532793147652282

Epoch: 6| Step: 9
Training loss: 3.0601624890736914
Validation loss: 2.557404926741679

Epoch: 6| Step: 10
Training loss: 2.633527800063264
Validation loss: 2.569025020619082

Epoch: 6| Step: 11
Training loss: 2.439050328128411
Validation loss: 2.5724413634804244

Epoch: 6| Step: 12
Training loss: 2.6568671014561125
Validation loss: 2.5459374260316125

Epoch: 6| Step: 13
Training loss: 2.0759566618083682
Validation loss: 2.5316240638662495

Epoch: 199| Step: 0
Training loss: 1.3196598674637237
Validation loss: 2.5142716110002183

Epoch: 6| Step: 1
Training loss: 2.419061219846197
Validation loss: 2.5213524832927083

Epoch: 6| Step: 2
Training loss: 2.620702313502492
Validation loss: 2.510898857713486

Epoch: 6| Step: 3
Training loss: 1.8657790741805158
Validation loss: 2.5042505845804857

Epoch: 6| Step: 4
Training loss: 2.478442227815172
Validation loss: 2.504453998865434

Epoch: 6| Step: 5
Training loss: 2.218249197304661
Validation loss: 2.51256305431999

Epoch: 6| Step: 6
Training loss: 2.502538917688574
Validation loss: 2.5117463327399228

Epoch: 6| Step: 7
Training loss: 3.1053612648458597
Validation loss: 2.510799178321529

Epoch: 6| Step: 8
Training loss: 2.2166795338230934
Validation loss: 2.5165963045182993

Epoch: 6| Step: 9
Training loss: 1.7636638991808167
Validation loss: 2.533213932795669

Epoch: 6| Step: 10
Training loss: 2.4554389682363107
Validation loss: 2.53628203127234

Epoch: 6| Step: 11
Training loss: 2.1499815784818437
Validation loss: 2.5388649418585167

Epoch: 6| Step: 12
Training loss: 2.530151317127305
Validation loss: 2.5309240657237737

Epoch: 6| Step: 13
Training loss: 3.0047230099996387
Validation loss: 2.5277284214478453

Epoch: 200| Step: 0
Training loss: 2.5415092065116442
Validation loss: 2.540486207543827

Epoch: 6| Step: 1
Training loss: 2.5536022622669687
Validation loss: 2.522034592681901

Epoch: 6| Step: 2
Training loss: 2.6596387900426923
Validation loss: 2.5225675990836027

Epoch: 6| Step: 3
Training loss: 2.416999684331808
Validation loss: 2.5136905443218986

Epoch: 6| Step: 4
Training loss: 1.9979285599477543
Validation loss: 2.5250950773360983

Epoch: 6| Step: 5
Training loss: 2.434450050930615
Validation loss: 2.5218459583423862

Epoch: 6| Step: 6
Training loss: 1.6646430207374396
Validation loss: 2.518127578742868

Epoch: 6| Step: 7
Training loss: 2.346367455267384
Validation loss: 2.5179602483672343

Epoch: 6| Step: 8
Training loss: 2.083340632107983
Validation loss: 2.5235273347183784

Epoch: 6| Step: 9
Training loss: 2.691711408481428
Validation loss: 2.54062957137644

Epoch: 6| Step: 10
Training loss: 2.294320483036717
Validation loss: 2.534453229406282

Epoch: 6| Step: 11
Training loss: 2.568767883535537
Validation loss: 2.530757573584537

Epoch: 6| Step: 12
Training loss: 2.2106307932416756
Validation loss: 2.5345692006317635

Epoch: 6| Step: 13
Training loss: 2.20288322691276
Validation loss: 2.530468478648874

Epoch: 201| Step: 0
Training loss: 2.4564345079384413
Validation loss: 2.524814045230835

Epoch: 6| Step: 1
Training loss: 2.120548072721565
Validation loss: 2.541699742795088

Epoch: 6| Step: 2
Training loss: 2.323808290798015
Validation loss: 2.527899042884111

Epoch: 6| Step: 3
Training loss: 2.5451979469107586
Validation loss: 2.5178261046089205

Epoch: 6| Step: 4
Training loss: 2.333291791364441
Validation loss: 2.5383184506770475

Epoch: 6| Step: 5
Training loss: 1.9287081561491022
Validation loss: 2.5256667078431105

Epoch: 6| Step: 6
Training loss: 2.276156867026741
Validation loss: 2.537217597718694

Epoch: 6| Step: 7
Training loss: 2.190259555258937
Validation loss: 2.530107624996484

Epoch: 6| Step: 8
Training loss: 2.246643635983623
Validation loss: 2.5421686979511753

Epoch: 6| Step: 9
Training loss: 2.106388379540356
Validation loss: 2.5600978477971132

Epoch: 6| Step: 10
Training loss: 2.0866446564379886
Validation loss: 2.537130111519536

Epoch: 6| Step: 11
Training loss: 2.299793698553895
Validation loss: 2.543932207284902

Epoch: 6| Step: 12
Training loss: 3.214365222492512
Validation loss: 2.5375103397503236

Epoch: 6| Step: 13
Training loss: 2.5858100790571634
Validation loss: 2.5357528321568377

Epoch: 202| Step: 0
Training loss: 2.346422528207076
Validation loss: 2.523470080217511

Epoch: 6| Step: 1
Training loss: 2.2077173297561146
Validation loss: 2.5257420680079394

Epoch: 6| Step: 2
Training loss: 2.301884177958959
Validation loss: 2.5312308636479655

Epoch: 6| Step: 3
Training loss: 2.2652799146205425
Validation loss: 2.536395333909188

Epoch: 6| Step: 4
Training loss: 2.1596540036182272
Validation loss: 2.5183402151707606

Epoch: 6| Step: 5
Training loss: 2.05363210979394
Validation loss: 2.5158865972311553

Epoch: 6| Step: 6
Training loss: 2.90418013829993
Validation loss: 2.5296686515396516

Epoch: 6| Step: 7
Training loss: 2.1644635982153333
Validation loss: 2.5123760654634406

Epoch: 6| Step: 8
Training loss: 2.26465664920083
Validation loss: 2.517263269971194

Epoch: 6| Step: 9
Training loss: 2.9058502906834747
Validation loss: 2.5292693265497213

Epoch: 6| Step: 10
Training loss: 2.5357469713955876
Validation loss: 2.5200192001156294

Epoch: 6| Step: 11
Training loss: 2.0275859945289523
Validation loss: 2.5202508573961713

Epoch: 6| Step: 12
Training loss: 2.2483350103479025
Validation loss: 2.5210614114363334

Epoch: 6| Step: 13
Training loss: 2.4279049531850374
Validation loss: 2.515502200081266

Epoch: 203| Step: 0
Training loss: 2.4811127555038044
Validation loss: 2.5275073698636303

Epoch: 6| Step: 1
Training loss: 2.9144530660999695
Validation loss: 2.5291675117235695

Epoch: 6| Step: 2
Training loss: 2.2503923497907707
Validation loss: 2.5399345895650147

Epoch: 6| Step: 3
Training loss: 2.6009968093917033
Validation loss: 2.525752105371687

Epoch: 6| Step: 4
Training loss: 2.208055538722919
Validation loss: 2.5272870379240904

Epoch: 6| Step: 5
Training loss: 1.9843244771458057
Validation loss: 2.533203721077015

Epoch: 6| Step: 6
Training loss: 1.8406503776005467
Validation loss: 2.530146966794399

Epoch: 6| Step: 7
Training loss: 2.4761448456853175
Validation loss: 2.524454398112736

Epoch: 6| Step: 8
Training loss: 2.338917849953646
Validation loss: 2.5448115908737625

Epoch: 6| Step: 9
Training loss: 2.3816777763703767
Validation loss: 2.5489083346903976

Epoch: 6| Step: 10
Training loss: 1.9664877352163546
Validation loss: 2.5588817172304954

Epoch: 6| Step: 11
Training loss: 1.9357463529863554
Validation loss: 2.5689189035492923

Epoch: 6| Step: 12
Training loss: 2.3526414189413063
Validation loss: 2.5558377786188697

Epoch: 6| Step: 13
Training loss: 2.7734355228040926
Validation loss: 2.55788783461751

Epoch: 204| Step: 0
Training loss: 3.0131860861909354
Validation loss: 2.5441474897667953

Epoch: 6| Step: 1
Training loss: 3.0179774146729583
Validation loss: 2.53823986323039

Epoch: 6| Step: 2
Training loss: 2.2218446238570007
Validation loss: 2.50709868954869

Epoch: 6| Step: 3
Training loss: 2.120677591037684
Validation loss: 2.5240864111289745

Epoch: 6| Step: 4
Training loss: 1.9994126888060633
Validation loss: 2.502248102925316

Epoch: 6| Step: 5
Training loss: 1.9982488237423097
Validation loss: 2.5133938580046147

Epoch: 6| Step: 6
Training loss: 2.094067905261361
Validation loss: 2.5086972823826503

Epoch: 6| Step: 7
Training loss: 1.8226413482566997
Validation loss: 2.505255832869495

Epoch: 6| Step: 8
Training loss: 1.7632601945031503
Validation loss: 2.4991913600294025

Epoch: 6| Step: 9
Training loss: 2.0957411223110562
Validation loss: 2.5087832575407045

Epoch: 6| Step: 10
Training loss: 2.4143508689517774
Validation loss: 2.510263878906956

Epoch: 6| Step: 11
Training loss: 2.4997906597228785
Validation loss: 2.5041188642241665

Epoch: 6| Step: 12
Training loss: 2.574903660425693
Validation loss: 2.5043410440962024

Epoch: 6| Step: 13
Training loss: 2.8242730310903523
Validation loss: 2.52699083146894

Epoch: 205| Step: 0
Training loss: 2.128228819971257
Validation loss: 2.535185239182352

Epoch: 6| Step: 1
Training loss: 2.205433170735639
Validation loss: 2.5407254138605135

Epoch: 6| Step: 2
Training loss: 2.2307942114577246
Validation loss: 2.536474495483124

Epoch: 6| Step: 3
Training loss: 2.0711315909907095
Validation loss: 2.5515136524079134

Epoch: 6| Step: 4
Training loss: 2.252639599707022
Validation loss: 2.577233701825047

Epoch: 6| Step: 5
Training loss: 2.4977950863259233
Validation loss: 2.613050556121532

Epoch: 6| Step: 6
Training loss: 2.2005355443218204
Validation loss: 2.5928541957541227

Epoch: 6| Step: 7
Training loss: 2.826926720445681
Validation loss: 2.565276432868877

Epoch: 6| Step: 8
Training loss: 3.1301305235439285
Validation loss: 2.5314046239524903

Epoch: 6| Step: 9
Training loss: 1.8290060153818464
Validation loss: 2.5190095583169128

Epoch: 6| Step: 10
Training loss: 2.271665951268547
Validation loss: 2.5253765266105566

Epoch: 6| Step: 11
Training loss: 2.1898222449638634
Validation loss: 2.5037247169933394

Epoch: 6| Step: 12
Training loss: 2.9054741592951796
Validation loss: 2.4971213058936

Epoch: 6| Step: 13
Training loss: 2.128501251614619
Validation loss: 2.5126798461011077

Epoch: 206| Step: 0
Training loss: 2.715869473777448
Validation loss: 2.505629194177949

Epoch: 6| Step: 1
Training loss: 2.240443598215467
Validation loss: 2.4901252752602363

Epoch: 6| Step: 2
Training loss: 2.6742163321294394
Validation loss: 2.4843635318899273

Epoch: 6| Step: 3
Training loss: 2.5851358052630102
Validation loss: 2.4951803479346903

Epoch: 6| Step: 4
Training loss: 1.935901474636747
Validation loss: 2.515407007854024

Epoch: 6| Step: 5
Training loss: 1.8904635778196046
Validation loss: 2.5230539067744204

Epoch: 6| Step: 6
Training loss: 2.4368064089189234
Validation loss: 2.5059399768991373

Epoch: 6| Step: 7
Training loss: 2.003795003498647
Validation loss: 2.534046120085163

Epoch: 6| Step: 8
Training loss: 2.1101427729605957
Validation loss: 2.5323553772201577

Epoch: 6| Step: 9
Training loss: 1.7896599584065216
Validation loss: 2.5552557294835028

Epoch: 6| Step: 10
Training loss: 2.650797644715409
Validation loss: 2.5566489091063347

Epoch: 6| Step: 11
Training loss: 3.0453622045712807
Validation loss: 2.5561086141446103

Epoch: 6| Step: 12
Training loss: 2.563398250291907
Validation loss: 2.56898895785764

Epoch: 6| Step: 13
Training loss: 2.004827871187654
Validation loss: 2.564686904249606

Epoch: 207| Step: 0
Training loss: 1.676751413927439
Validation loss: 2.5432232535535224

Epoch: 6| Step: 1
Training loss: 2.2451830269815414
Validation loss: 2.5546771096923324

Epoch: 6| Step: 2
Training loss: 1.997428552259283
Validation loss: 2.532790786490066

Epoch: 6| Step: 3
Training loss: 2.7694115875175833
Validation loss: 2.5097332152019334

Epoch: 6| Step: 4
Training loss: 2.802047294375488
Validation loss: 2.5066771982695464

Epoch: 6| Step: 5
Training loss: 1.7697756432190899
Validation loss: 2.5054581822235003

Epoch: 6| Step: 6
Training loss: 2.6405738058149972
Validation loss: 2.507544434858273

Epoch: 6| Step: 7
Training loss: 1.735500417324094
Validation loss: 2.518186272325198

Epoch: 6| Step: 8
Training loss: 2.417541959254453
Validation loss: 2.514138748217083

Epoch: 6| Step: 9
Training loss: 2.967140644942966
Validation loss: 2.521042702127216

Epoch: 6| Step: 10
Training loss: 2.6571528078587283
Validation loss: 2.5074452639355242

Epoch: 6| Step: 11
Training loss: 3.2117645609304293
Validation loss: 2.5260401512744464

Epoch: 6| Step: 12
Training loss: 1.8055922317040305
Validation loss: 2.5176705599187024

Epoch: 6| Step: 13
Training loss: 1.9124772338509468
Validation loss: 2.525865125222168

Epoch: 208| Step: 0
Training loss: 1.9256347848160118
Validation loss: 2.527926134697788

Epoch: 6| Step: 1
Training loss: 2.624975567658572
Validation loss: 2.5242682665123386

Epoch: 6| Step: 2
Training loss: 1.9892246129332563
Validation loss: 2.543628862825493

Epoch: 6| Step: 3
Training loss: 2.7785058360180086
Validation loss: 2.550370530403627

Epoch: 6| Step: 4
Training loss: 2.2358842567486397
Validation loss: 2.5662357422707758

Epoch: 6| Step: 5
Training loss: 2.035984449218539
Validation loss: 2.57029694742833

Epoch: 6| Step: 6
Training loss: 1.9149171750556204
Validation loss: 2.564658968998293

Epoch: 6| Step: 7
Training loss: 1.6522301168124183
Validation loss: 2.563255136766306

Epoch: 6| Step: 8
Training loss: 2.1613871980168144
Validation loss: 2.5384755243495576

Epoch: 6| Step: 9
Training loss: 2.400842908023419
Validation loss: 2.5403752928794363

Epoch: 6| Step: 10
Training loss: 3.396112598255437
Validation loss: 2.5161136602767518

Epoch: 6| Step: 11
Training loss: 1.79555582467608
Validation loss: 2.517159627692631

Epoch: 6| Step: 12
Training loss: 1.9908592433635248
Validation loss: 2.501681223459946

Epoch: 6| Step: 13
Training loss: 2.9165210324213593
Validation loss: 2.4955655983392258

Epoch: 209| Step: 0
Training loss: 2.237872820433952
Validation loss: 2.503188754002842

Epoch: 6| Step: 1
Training loss: 2.0591185622833956
Validation loss: 2.4966251163904416

Epoch: 6| Step: 2
Training loss: 2.429298884968617
Validation loss: 2.5055860021925893

Epoch: 6| Step: 3
Training loss: 2.6821809517439252
Validation loss: 2.506301305726136

Epoch: 6| Step: 4
Training loss: 2.491598412419865
Validation loss: 2.49515149117197

Epoch: 6| Step: 5
Training loss: 2.921843666275841
Validation loss: 2.4924269095838123

Epoch: 6| Step: 6
Training loss: 2.2551559078005115
Validation loss: 2.50354009163882

Epoch: 6| Step: 7
Training loss: 2.3700175977608877
Validation loss: 2.526441858321321

Epoch: 6| Step: 8
Training loss: 2.6214811263379048
Validation loss: 2.5269373980276644

Epoch: 6| Step: 9
Training loss: 2.5263162260515273
Validation loss: 2.537609196961402

Epoch: 6| Step: 10
Training loss: 2.351074370862534
Validation loss: 2.5237533954246723

Epoch: 6| Step: 11
Training loss: 1.7169136641251983
Validation loss: 2.550090328187471

Epoch: 6| Step: 12
Training loss: 2.1978344532805694
Validation loss: 2.574271726859085

Epoch: 6| Step: 13
Training loss: 2.2401922300144226
Validation loss: 2.561951725929083

Epoch: 210| Step: 0
Training loss: 2.131531271175152
Validation loss: 2.550715338034052

Epoch: 6| Step: 1
Training loss: 2.1095930198744908
Validation loss: 2.533714389898947

Epoch: 6| Step: 2
Training loss: 3.1051751531811527
Validation loss: 2.5224491699511375

Epoch: 6| Step: 3
Training loss: 2.02604607301313
Validation loss: 2.521729654112506

Epoch: 6| Step: 4
Training loss: 1.9684852543192108
Validation loss: 2.5066432980410265

Epoch: 6| Step: 5
Training loss: 1.818331577895751
Validation loss: 2.5124719260752353

Epoch: 6| Step: 6
Training loss: 2.8639576361522536
Validation loss: 2.505877262090291

Epoch: 6| Step: 7
Training loss: 2.271620191218562
Validation loss: 2.505937693505058

Epoch: 6| Step: 8
Training loss: 2.9078964983795563
Validation loss: 2.506024334166541

Epoch: 6| Step: 9
Training loss: 2.4093879946742938
Validation loss: 2.5016510280024593

Epoch: 6| Step: 10
Training loss: 2.4849710769044693
Validation loss: 2.508704180461398

Epoch: 6| Step: 11
Training loss: 1.9254638534120834
Validation loss: 2.4953165849315035

Epoch: 6| Step: 12
Training loss: 2.030709532213712
Validation loss: 2.50638998691849

Epoch: 6| Step: 13
Training loss: 2.1362455914643292
Validation loss: 2.5188932335501115

Epoch: 211| Step: 0
Training loss: 2.976142272922166
Validation loss: 2.5304635792485377

Epoch: 6| Step: 1
Training loss: 1.9608305639768089
Validation loss: 2.5303503093773996

Epoch: 6| Step: 2
Training loss: 3.1284641139219045
Validation loss: 2.546392196108083

Epoch: 6| Step: 3
Training loss: 2.539106257134973
Validation loss: 2.5266858383959456

Epoch: 6| Step: 4
Training loss: 2.026022066807677
Validation loss: 2.5420970917084356

Epoch: 6| Step: 5
Training loss: 2.23741998795815
Validation loss: 2.528435292041635

Epoch: 6| Step: 6
Training loss: 2.823753645760731
Validation loss: 2.535798573836039

Epoch: 6| Step: 7
Training loss: 1.9387285582821991
Validation loss: 2.517924969251412

Epoch: 6| Step: 8
Training loss: 2.237770115408753
Validation loss: 2.5044481283258744

Epoch: 6| Step: 9
Training loss: 2.4204000596325876
Validation loss: 2.505871601030312

Epoch: 6| Step: 10
Training loss: 1.3429964747293863
Validation loss: 2.514526395829983

Epoch: 6| Step: 11
Training loss: 2.4687189027783334
Validation loss: 2.5260133774474385

Epoch: 6| Step: 12
Training loss: 2.137192919350971
Validation loss: 2.5201015566237865

Epoch: 6| Step: 13
Training loss: 1.6155608468812266
Validation loss: 2.525548109359755

Epoch: 212| Step: 0
Training loss: 2.664223853451975
Validation loss: 2.5249532078351065

Epoch: 6| Step: 1
Training loss: 2.5991820479273517
Validation loss: 2.516437936224296

Epoch: 6| Step: 2
Training loss: 2.728373977818234
Validation loss: 2.5242943426061273

Epoch: 6| Step: 3
Training loss: 2.7829550328022927
Validation loss: 2.544164092454838

Epoch: 6| Step: 4
Training loss: 2.4414955061809267
Validation loss: 2.559531516108945

Epoch: 6| Step: 5
Training loss: 2.2957263591603856
Validation loss: 2.581009901824643

Epoch: 6| Step: 6
Training loss: 2.326377878748206
Validation loss: 2.5657511610018404

Epoch: 6| Step: 7
Training loss: 1.6185480558881655
Validation loss: 2.5525815256906568

Epoch: 6| Step: 8
Training loss: 1.9989653533711562
Validation loss: 2.535440688592795

Epoch: 6| Step: 9
Training loss: 2.0357367626660667
Validation loss: 2.5182645230472374

Epoch: 6| Step: 10
Training loss: 2.1459844838458704
Validation loss: 2.5279696366110334

Epoch: 6| Step: 11
Training loss: 2.5594156823284355
Validation loss: 2.5259647449435336

Epoch: 6| Step: 12
Training loss: 2.1583753422167806
Validation loss: 2.5164185372192467

Epoch: 6| Step: 13
Training loss: 2.0925967328353527
Validation loss: 2.5233151511499328

Epoch: 213| Step: 0
Training loss: 2.787848713364554
Validation loss: 2.5231702838267616

Epoch: 6| Step: 1
Training loss: 1.9985652784309194
Validation loss: 2.51066184264628

Epoch: 6| Step: 2
Training loss: 1.8170095446792023
Validation loss: 2.526298530863696

Epoch: 6| Step: 3
Training loss: 2.3447877748022963
Validation loss: 2.520171154683814

Epoch: 6| Step: 4
Training loss: 2.8228542044135048
Validation loss: 2.5340964243005017

Epoch: 6| Step: 5
Training loss: 1.859425904675098
Validation loss: 2.545465660599906

Epoch: 6| Step: 6
Training loss: 2.6006209585630096
Validation loss: 2.560822255534443

Epoch: 6| Step: 7
Training loss: 3.142684792462163
Validation loss: 2.56167997249638

Epoch: 6| Step: 8
Training loss: 1.8541063948989946
Validation loss: 2.5378067354242413

Epoch: 6| Step: 9
Training loss: 2.1187903611381436
Validation loss: 2.5208904927186335

Epoch: 6| Step: 10
Training loss: 1.630882692455875
Validation loss: 2.5131131776172535

Epoch: 6| Step: 11
Training loss: 2.084805642269811
Validation loss: 2.5135848814032684

Epoch: 6| Step: 12
Training loss: 2.4728051211602438
Validation loss: 2.5034669360773574

Epoch: 6| Step: 13
Training loss: 2.604621074449657
Validation loss: 2.5202599785052877

Epoch: 214| Step: 0
Training loss: 2.6881962251395892
Validation loss: 2.5087578121786565

Epoch: 6| Step: 1
Training loss: 2.845125305956101
Validation loss: 2.5223339805499694

Epoch: 6| Step: 2
Training loss: 1.9063494296798715
Validation loss: 2.5117249595047215

Epoch: 6| Step: 3
Training loss: 2.502452219869929
Validation loss: 2.5011763030555185

Epoch: 6| Step: 4
Training loss: 2.066366444079917
Validation loss: 2.5076470404654754

Epoch: 6| Step: 5
Training loss: 2.718818575991733
Validation loss: 2.514099005763465

Epoch: 6| Step: 6
Training loss: 2.4805977374803985
Validation loss: 2.5120334299580342

Epoch: 6| Step: 7
Training loss: 1.8485024834993584
Validation loss: 2.529511533683868

Epoch: 6| Step: 8
Training loss: 1.8651925127214963
Validation loss: 2.52059109892726

Epoch: 6| Step: 9
Training loss: 2.03891680551393
Validation loss: 2.5295893869425505

Epoch: 6| Step: 10
Training loss: 2.1625700393536076
Validation loss: 2.5643504679795135

Epoch: 6| Step: 11
Training loss: 2.322646075398691
Validation loss: 2.556688370925442

Epoch: 6| Step: 12
Training loss: 2.019283788634715
Validation loss: 2.544856966742088

Epoch: 6| Step: 13
Training loss: 2.82070252318535
Validation loss: 2.5688690801463205

Epoch: 215| Step: 0
Training loss: 2.495672676974227
Validation loss: 2.53573441929183

Epoch: 6| Step: 1
Training loss: 1.7413601814019035
Validation loss: 2.536046409187801

Epoch: 6| Step: 2
Training loss: 2.236476843274195
Validation loss: 2.5185516897782505

Epoch: 6| Step: 3
Training loss: 2.1248682766647606
Validation loss: 2.513815345414348

Epoch: 6| Step: 4
Training loss: 3.112688455659684
Validation loss: 2.525389523566159

Epoch: 6| Step: 5
Training loss: 2.366200256953299
Validation loss: 2.527441935766852

Epoch: 6| Step: 6
Training loss: 1.9141800824853428
Validation loss: 2.52482906744981

Epoch: 6| Step: 7
Training loss: 2.241809985981111
Validation loss: 2.509409743433107

Epoch: 6| Step: 8
Training loss: 1.828377991475481
Validation loss: 2.5115173164148907

Epoch: 6| Step: 9
Training loss: 2.9549138539726356
Validation loss: 2.5239881420592485

Epoch: 6| Step: 10
Training loss: 1.7935146589443156
Validation loss: 2.5342405886428137

Epoch: 6| Step: 11
Training loss: 2.9934224501033455
Validation loss: 2.540139307422103

Epoch: 6| Step: 12
Training loss: 1.9739062890377628
Validation loss: 2.5407969101868018

Epoch: 6| Step: 13
Training loss: 1.9613811097531588
Validation loss: 2.5623838351831645

Epoch: 216| Step: 0
Training loss: 2.1928475547925284
Validation loss: 2.572700542891529

Epoch: 6| Step: 1
Training loss: 2.357991096906865
Validation loss: 2.597913854536805

Epoch: 6| Step: 2
Training loss: 2.186953122034694
Validation loss: 2.6387714072617596

Epoch: 6| Step: 3
Training loss: 2.5363382132179915
Validation loss: 2.605182424175206

Epoch: 6| Step: 4
Training loss: 2.3123161655247157
Validation loss: 2.5742501163838907

Epoch: 6| Step: 5
Training loss: 2.9096590782320333
Validation loss: 2.5830326571889195

Epoch: 6| Step: 6
Training loss: 1.9365900425462805
Validation loss: 2.5606444393826338

Epoch: 6| Step: 7
Training loss: 2.131515164254474
Validation loss: 2.5514741806377463

Epoch: 6| Step: 8
Training loss: 2.4348447960929236
Validation loss: 2.5474705536113516

Epoch: 6| Step: 9
Training loss: 2.3628708159867715
Validation loss: 2.5451532484629324

Epoch: 6| Step: 10
Training loss: 2.25591327553301
Validation loss: 2.533241587366225

Epoch: 6| Step: 11
Training loss: 2.596935200825461
Validation loss: 2.5132445609691807

Epoch: 6| Step: 12
Training loss: 2.6904980991755933
Validation loss: 2.5184606677804733

Epoch: 6| Step: 13
Training loss: 1.526394209863569
Validation loss: 2.5225974339047212

Epoch: 217| Step: 0
Training loss: 2.4528260261433887
Validation loss: 2.5167497446440183

Epoch: 6| Step: 1
Training loss: 2.642909038431857
Validation loss: 2.5051488466133

Epoch: 6| Step: 2
Training loss: 2.0338744595175084
Validation loss: 2.5110518626684923

Epoch: 6| Step: 3
Training loss: 3.0763419161832637
Validation loss: 2.512516241195086

Epoch: 6| Step: 4
Training loss: 2.2998756997064738
Validation loss: 2.499746723060865

Epoch: 6| Step: 5
Training loss: 2.2326166663704448
Validation loss: 2.5169294935840814

Epoch: 6| Step: 6
Training loss: 2.3619712035953717
Validation loss: 2.53952840589707

Epoch: 6| Step: 7
Training loss: 2.337214704432496
Validation loss: 2.538516200056185

Epoch: 6| Step: 8
Training loss: 1.655020059193177
Validation loss: 2.5508445120459236

Epoch: 6| Step: 9
Training loss: 2.1657769748487854
Validation loss: 2.559024795836447

Epoch: 6| Step: 10
Training loss: 2.4978345075325272
Validation loss: 2.552525584509567

Epoch: 6| Step: 11
Training loss: 2.270467279544118
Validation loss: 2.587052457378117

Epoch: 6| Step: 12
Training loss: 2.107862028836585
Validation loss: 2.5712559909531314

Epoch: 6| Step: 13
Training loss: 2.1575529059755962
Validation loss: 2.5323006447105

Epoch: 218| Step: 0
Training loss: 2.798487619263247
Validation loss: 2.52671157500921

Epoch: 6| Step: 1
Training loss: 2.515244544029859
Validation loss: 2.535761701625374

Epoch: 6| Step: 2
Training loss: 1.9211938162576063
Validation loss: 2.5227337024053793

Epoch: 6| Step: 3
Training loss: 2.643041644781134
Validation loss: 2.515736579394974

Epoch: 6| Step: 4
Training loss: 2.533477086037546
Validation loss: 2.499543561594108

Epoch: 6| Step: 5
Training loss: 2.6866982617031034
Validation loss: 2.537614920320519

Epoch: 6| Step: 6
Training loss: 2.194413622171563
Validation loss: 2.51904186454069

Epoch: 6| Step: 7
Training loss: 2.317333119627603
Validation loss: 2.516458282517022

Epoch: 6| Step: 8
Training loss: 2.0796273902787155
Validation loss: 2.5022884544212407

Epoch: 6| Step: 9
Training loss: 2.834792901872867
Validation loss: 2.525629215716826

Epoch: 6| Step: 10
Training loss: 1.7571506186611827
Validation loss: 2.5003141046929005

Epoch: 6| Step: 11
Training loss: 1.2695034552245805
Validation loss: 2.5010076240617565

Epoch: 6| Step: 12
Training loss: 1.9867993061326352
Validation loss: 2.5022924244270026

Epoch: 6| Step: 13
Training loss: 2.5194843140008025
Validation loss: 2.497894019967301

Epoch: 219| Step: 0
Training loss: 2.5492970002463595
Validation loss: 2.521949037759484

Epoch: 6| Step: 1
Training loss: 2.323855075112416
Validation loss: 2.528191480795933

Epoch: 6| Step: 2
Training loss: 2.2467580327134153
Validation loss: 2.5368051207006834

Epoch: 6| Step: 3
Training loss: 2.4653696989255733
Validation loss: 2.532342714155821

Epoch: 6| Step: 4
Training loss: 2.609811894737919
Validation loss: 2.5293602188014024

Epoch: 6| Step: 5
Training loss: 2.0044710727810995
Validation loss: 2.53857982253581

Epoch: 6| Step: 6
Training loss: 1.765775826012666
Validation loss: 2.5152512661707926

Epoch: 6| Step: 7
Training loss: 2.837778381942383
Validation loss: 2.5412645386647283

Epoch: 6| Step: 8
Training loss: 2.620440110230984
Validation loss: 2.5274894629113227

Epoch: 6| Step: 9
Training loss: 1.1236682532835014
Validation loss: 2.521371962535654

Epoch: 6| Step: 10
Training loss: 2.595802506151025
Validation loss: 2.5232222458370575

Epoch: 6| Step: 11
Training loss: 2.2035093580947045
Validation loss: 2.539236397290186

Epoch: 6| Step: 12
Training loss: 2.5479155679005343
Validation loss: 2.552996387767515

Epoch: 6| Step: 13
Training loss: 1.748285816420884
Validation loss: 2.552418049771143

Epoch: 220| Step: 0
Training loss: 1.7787562531973216
Validation loss: 2.573611769173182

Epoch: 6| Step: 1
Training loss: 2.666974576419106
Validation loss: 2.5763951518852926

Epoch: 6| Step: 2
Training loss: 2.0734429641801118
Validation loss: 2.5721492369284595

Epoch: 6| Step: 3
Training loss: 2.177319843885065
Validation loss: 2.5716825040064655

Epoch: 6| Step: 4
Training loss: 1.9391146668971726
Validation loss: 2.600996488566597

Epoch: 6| Step: 5
Training loss: 2.6194192509154868
Validation loss: 2.5792133538658506

Epoch: 6| Step: 6
Training loss: 2.751818402514283
Validation loss: 2.551000627525349

Epoch: 6| Step: 7
Training loss: 2.5687206405855263
Validation loss: 2.5599101633089276

Epoch: 6| Step: 8
Training loss: 2.5705166535623643
Validation loss: 2.5708843395133805

Epoch: 6| Step: 9
Training loss: 1.783742131708404
Validation loss: 2.548221739135824

Epoch: 6| Step: 10
Training loss: 2.0254219369114113
Validation loss: 2.5593774425229445

Epoch: 6| Step: 11
Training loss: 2.0641952252507507
Validation loss: 2.560927645230063

Epoch: 6| Step: 12
Training loss: 2.421094313280176
Validation loss: 2.548029398094311

Epoch: 6| Step: 13
Training loss: 2.30873192697999
Validation loss: 2.5516360195801964

Epoch: 221| Step: 0
Training loss: 1.8582125965235474
Validation loss: 2.5488187709359007

Epoch: 6| Step: 1
Training loss: 2.472176214449635
Validation loss: 2.5296541842865903

Epoch: 6| Step: 2
Training loss: 2.7278830054972865
Validation loss: 2.5223420780074495

Epoch: 6| Step: 3
Training loss: 2.3225076996806027
Validation loss: 2.5111811227120535

Epoch: 6| Step: 4
Training loss: 2.1902847003955035
Validation loss: 2.520220261628314

Epoch: 6| Step: 5
Training loss: 2.7635295278601566
Validation loss: 2.5008895562968383

Epoch: 6| Step: 6
Training loss: 2.4870196007975043
Validation loss: 2.5179317157991488

Epoch: 6| Step: 7
Training loss: 2.217494985753253
Validation loss: 2.5199516320254243

Epoch: 6| Step: 8
Training loss: 2.118163837381846
Validation loss: 2.528652271036006

Epoch: 6| Step: 9
Training loss: 2.849242554782995
Validation loss: 2.537384276734451

Epoch: 6| Step: 10
Training loss: 2.1439878682106444
Validation loss: 2.5604692957047197

Epoch: 6| Step: 11
Training loss: 2.284391669800936
Validation loss: 2.5874236370495978

Epoch: 6| Step: 12
Training loss: 1.8580656811137333
Validation loss: 2.602921200788968

Epoch: 6| Step: 13
Training loss: 1.8790290142091004
Validation loss: 2.626936682516115

Epoch: 222| Step: 0
Training loss: 2.0797748183356077
Validation loss: 2.616637731096518

Epoch: 6| Step: 1
Training loss: 2.5378540919502854
Validation loss: 2.580161459821334

Epoch: 6| Step: 2
Training loss: 2.604646430009284
Validation loss: 2.593509218614221

Epoch: 6| Step: 3
Training loss: 2.2467449803197064
Validation loss: 2.5578884016398433

Epoch: 6| Step: 4
Training loss: 2.3104585451734128
Validation loss: 2.5421349818379824

Epoch: 6| Step: 5
Training loss: 1.9288692824636373
Validation loss: 2.5171261054361445

Epoch: 6| Step: 6
Training loss: 2.782142238872214
Validation loss: 2.502871231505814

Epoch: 6| Step: 7
Training loss: 2.0842058516332838
Validation loss: 2.515343439050361

Epoch: 6| Step: 8
Training loss: 1.670591628301125
Validation loss: 2.50371339306199

Epoch: 6| Step: 9
Training loss: 2.664647907809813
Validation loss: 2.527112821536395

Epoch: 6| Step: 10
Training loss: 1.7431882712342077
Validation loss: 2.516572840838438

Epoch: 6| Step: 11
Training loss: 3.1960373781427136
Validation loss: 2.5156649394843407

Epoch: 6| Step: 12
Training loss: 2.2346131524633317
Validation loss: 2.5144739617616323

Epoch: 6| Step: 13
Training loss: 1.9510004924849804
Validation loss: 2.5131962110500257

Epoch: 223| Step: 0
Training loss: 2.4773292678222036
Validation loss: 2.518419612927188

Epoch: 6| Step: 1
Training loss: 1.818245168145813
Validation loss: 2.506955738224175

Epoch: 6| Step: 2
Training loss: 2.7422347974909647
Validation loss: 2.503618689026775

Epoch: 6| Step: 3
Training loss: 2.3647741725277793
Validation loss: 2.5167531392312927

Epoch: 6| Step: 4
Training loss: 2.33267739703834
Validation loss: 2.5212906561873627

Epoch: 6| Step: 5
Training loss: 2.866578746896412
Validation loss: 2.534562365108483

Epoch: 6| Step: 6
Training loss: 2.4305555749317955
Validation loss: 2.5308732117328967

Epoch: 6| Step: 7
Training loss: 1.1632844001312337
Validation loss: 2.535936373688641

Epoch: 6| Step: 8
Training loss: 2.2113919818811127
Validation loss: 2.556369597132972

Epoch: 6| Step: 9
Training loss: 2.353810702618413
Validation loss: 2.5613944995233386

Epoch: 6| Step: 10
Training loss: 1.3830372686956984
Validation loss: 2.5393150399624833

Epoch: 6| Step: 11
Training loss: 2.1435816039739444
Validation loss: 2.5443675485825286

Epoch: 6| Step: 12
Training loss: 2.31927374505432
Validation loss: 2.5154604413723285

Epoch: 6| Step: 13
Training loss: 2.7406540628803944
Validation loss: 2.5127935013536935

Epoch: 224| Step: 0
Training loss: 2.05511992222957
Validation loss: 2.5279920671153446

Epoch: 6| Step: 1
Training loss: 2.6062328127653362
Validation loss: 2.535415910414053

Epoch: 6| Step: 2
Training loss: 2.314101618217851
Validation loss: 2.5356270108596193

Epoch: 6| Step: 3
Training loss: 1.9306220752895205
Validation loss: 2.524485076358007

Epoch: 6| Step: 4
Training loss: 2.531294080562359
Validation loss: 2.523186441850953

Epoch: 6| Step: 5
Training loss: 2.705106328824089
Validation loss: 2.5261596547260767

Epoch: 6| Step: 6
Training loss: 2.046760847097179
Validation loss: 2.5616012951169145

Epoch: 6| Step: 7
Training loss: 1.6782910596921143
Validation loss: 2.561854211332501

Epoch: 6| Step: 8
Training loss: 1.848431543516363
Validation loss: 2.568175736934411

Epoch: 6| Step: 9
Training loss: 2.133385549840056
Validation loss: 2.559143799340419

Epoch: 6| Step: 10
Training loss: 2.4898099171039796
Validation loss: 2.5299258909315414

Epoch: 6| Step: 11
Training loss: 2.403458995452651
Validation loss: 2.513552481328593

Epoch: 6| Step: 12
Training loss: 2.6556880580914712
Validation loss: 2.5123178925318306

Epoch: 6| Step: 13
Training loss: 2.637589193707152
Validation loss: 2.5090928181507803

Epoch: 225| Step: 0
Training loss: 2.90601996054886
Validation loss: 2.5030299104749303

Epoch: 6| Step: 1
Training loss: 2.5528010598238158
Validation loss: 2.4990942744851146

Epoch: 6| Step: 2
Training loss: 1.668441169536104
Validation loss: 2.5103208330996654

Epoch: 6| Step: 3
Training loss: 2.362430438274023
Validation loss: 2.5045311872475273

Epoch: 6| Step: 4
Training loss: 2.508996226606272
Validation loss: 2.511691823511466

Epoch: 6| Step: 5
Training loss: 2.307660374053673
Validation loss: 2.514350078376129

Epoch: 6| Step: 6
Training loss: 2.805318862280611
Validation loss: 2.5014610789395593

Epoch: 6| Step: 7
Training loss: 2.178404509070609
Validation loss: 2.5223484267740246

Epoch: 6| Step: 8
Training loss: 2.0035033536711104
Validation loss: 2.551156188296701

Epoch: 6| Step: 9
Training loss: 2.196260946525516
Validation loss: 2.550819571938875

Epoch: 6| Step: 10
Training loss: 2.54445350535231
Validation loss: 2.545394716911781

Epoch: 6| Step: 11
Training loss: 1.8705574174851636
Validation loss: 2.547422338542942

Epoch: 6| Step: 12
Training loss: 2.151730874204505
Validation loss: 2.5432654704301467

Epoch: 6| Step: 13
Training loss: 1.9933782272748106
Validation loss: 2.527822693808812

Epoch: 226| Step: 0
Training loss: 2.4907492191444036
Validation loss: 2.537638745327898

Epoch: 6| Step: 1
Training loss: 2.2072710565238185
Validation loss: 2.5411257767607394

Epoch: 6| Step: 2
Training loss: 2.1180977641696153
Validation loss: 2.5494988933939133

Epoch: 6| Step: 3
Training loss: 2.5960938308169377
Validation loss: 2.560480267754163

Epoch: 6| Step: 4
Training loss: 2.3146629528105223
Validation loss: 2.530595106012847

Epoch: 6| Step: 5
Training loss: 2.1749899502226064
Validation loss: 2.5160077990444907

Epoch: 6| Step: 6
Training loss: 2.163886989265667
Validation loss: 2.515198570739544

Epoch: 6| Step: 7
Training loss: 2.3804349450570848
Validation loss: 2.518054420906714

Epoch: 6| Step: 8
Training loss: 2.204143748557848
Validation loss: 2.515680814009351

Epoch: 6| Step: 9
Training loss: 2.4563073576231305
Validation loss: 2.506078847747314

Epoch: 6| Step: 10
Training loss: 1.9533220725771054
Validation loss: 2.511623999754903

Epoch: 6| Step: 11
Training loss: 1.516100779311377
Validation loss: 2.5167207088941637

Epoch: 6| Step: 12
Training loss: 2.1823322835585364
Validation loss: 2.5242714935714514

Epoch: 6| Step: 13
Training loss: 2.9919121120008687
Validation loss: 2.5245286218263905

Epoch: 227| Step: 0
Training loss: 2.013258024769328
Validation loss: 2.51755886894223

Epoch: 6| Step: 1
Training loss: 2.272284461145497
Validation loss: 2.5130900529937596

Epoch: 6| Step: 2
Training loss: 1.4736727740087812
Validation loss: 2.5237641885807967

Epoch: 6| Step: 3
Training loss: 2.659580969538757
Validation loss: 2.5285363427345753

Epoch: 6| Step: 4
Training loss: 2.366133754351483
Validation loss: 2.5371281772667618

Epoch: 6| Step: 5
Training loss: 2.2669425553362257
Validation loss: 2.526275849383907

Epoch: 6| Step: 6
Training loss: 2.121714913757843
Validation loss: 2.539837449972521

Epoch: 6| Step: 7
Training loss: 2.5736694676091214
Validation loss: 2.5430480038373173

Epoch: 6| Step: 8
Training loss: 2.6897884650176023
Validation loss: 2.555339998216477

Epoch: 6| Step: 9
Training loss: 2.0385858555992717
Validation loss: 2.5659407179405034

Epoch: 6| Step: 10
Training loss: 2.505823410144775
Validation loss: 2.578996268350683

Epoch: 6| Step: 11
Training loss: 1.7059405091568904
Validation loss: 2.5512507163879596

Epoch: 6| Step: 12
Training loss: 2.022102062558616
Validation loss: 2.5322750512073213

Epoch: 6| Step: 13
Training loss: 2.67504373675091
Validation loss: 2.5238793205796206

Epoch: 228| Step: 0
Training loss: 2.8388663476628446
Validation loss: 2.519610042473562

Epoch: 6| Step: 1
Training loss: 1.6939515307134299
Validation loss: 2.5079643861086502

Epoch: 6| Step: 2
Training loss: 2.171927801354846
Validation loss: 2.4991402419235453

Epoch: 6| Step: 3
Training loss: 2.5597046282361324
Validation loss: 2.5367503275549166

Epoch: 6| Step: 4
Training loss: 2.6347068966710445
Validation loss: 2.50517715995147

Epoch: 6| Step: 5
Training loss: 1.7379668562245256
Validation loss: 2.524356166979964

Epoch: 6| Step: 6
Training loss: 2.133522446515423
Validation loss: 2.5075278432561

Epoch: 6| Step: 7
Training loss: 1.8644490611001894
Validation loss: 2.5127645463988943

Epoch: 6| Step: 8
Training loss: 1.6302720891248392
Validation loss: 2.551770161208201

Epoch: 6| Step: 9
Training loss: 1.9421322729555568
Validation loss: 2.547472534605645

Epoch: 6| Step: 10
Training loss: 2.627894848919016
Validation loss: 2.5488040538055565

Epoch: 6| Step: 11
Training loss: 2.7811577599477837
Validation loss: 2.541416974127637

Epoch: 6| Step: 12
Training loss: 2.641519158112809
Validation loss: 2.5404965933256554

Epoch: 6| Step: 13
Training loss: 2.101731531088586
Validation loss: 2.5490810302918847

Epoch: 229| Step: 0
Training loss: 2.1597082076958722
Validation loss: 2.536706984053772

Epoch: 6| Step: 1
Training loss: 2.034891473749036
Validation loss: 2.5347173356890207

Epoch: 6| Step: 2
Training loss: 2.623724673050346
Validation loss: 2.5225887544340218

Epoch: 6| Step: 3
Training loss: 2.0836955963520287
Validation loss: 2.528914186254852

Epoch: 6| Step: 4
Training loss: 2.2920480468600544
Validation loss: 2.5297331484060464

Epoch: 6| Step: 5
Training loss: 2.213106742466853
Validation loss: 2.500694273866535

Epoch: 6| Step: 6
Training loss: 1.6295860573493794
Validation loss: 2.5295308244240524

Epoch: 6| Step: 7
Training loss: 1.4616320585868117
Validation loss: 2.5337193849530393

Epoch: 6| Step: 8
Training loss: 2.3757048113191384
Validation loss: 2.541220795237958

Epoch: 6| Step: 9
Training loss: 2.9151540557825264
Validation loss: 2.5574814259242133

Epoch: 6| Step: 10
Training loss: 2.647766208250775
Validation loss: 2.57253243721548

Epoch: 6| Step: 11
Training loss: 2.322602859535254
Validation loss: 2.5515885528710736

Epoch: 6| Step: 12
Training loss: 1.918763161281714
Validation loss: 2.5949993571609555

Epoch: 6| Step: 13
Training loss: 2.7175555181227833
Validation loss: 2.584920992636902

Epoch: 230| Step: 0
Training loss: 1.760764665084618
Validation loss: 2.567925919192129

Epoch: 6| Step: 1
Training loss: 2.2800590855488263
Validation loss: 2.558832490377445

Epoch: 6| Step: 2
Training loss: 2.5786448561460373
Validation loss: 2.549336373236904

Epoch: 6| Step: 3
Training loss: 2.4128996878687357
Validation loss: 2.5211298008971292

Epoch: 6| Step: 4
Training loss: 2.4578807435743886
Validation loss: 2.518570961911338

Epoch: 6| Step: 5
Training loss: 2.1841867695969643
Validation loss: 2.5045409804030276

Epoch: 6| Step: 6
Training loss: 2.2428470930684825
Validation loss: 2.5177610028562807

Epoch: 6| Step: 7
Training loss: 2.6940228459013262
Validation loss: 2.5269869474399225

Epoch: 6| Step: 8
Training loss: 2.3462250928415407
Validation loss: 2.542896963142451

Epoch: 6| Step: 9
Training loss: 3.0897718341622924
Validation loss: 2.5315681069253957

Epoch: 6| Step: 10
Training loss: 2.218868950892353
Validation loss: 2.5554007993593517

Epoch: 6| Step: 11
Training loss: 1.7749425744451917
Validation loss: 2.6070024588792426

Epoch: 6| Step: 12
Training loss: 1.9970700737316482
Validation loss: 2.6378161296647025

Epoch: 6| Step: 13
Training loss: 2.1681692219741446
Validation loss: 2.629488090378394

Epoch: 231| Step: 0
Training loss: 1.9193010539173465
Validation loss: 2.5547531150611986

Epoch: 6| Step: 1
Training loss: 2.5200147534498645
Validation loss: 2.5663533894801094

Epoch: 6| Step: 2
Training loss: 1.9725077053833353
Validation loss: 2.54432666187602

Epoch: 6| Step: 3
Training loss: 2.04578492935422
Validation loss: 2.51919933567533

Epoch: 6| Step: 4
Training loss: 1.8717329171951236
Validation loss: 2.5140455354063254

Epoch: 6| Step: 5
Training loss: 2.5126837364312626
Validation loss: 2.5133061116951083

Epoch: 6| Step: 6
Training loss: 2.625583583811152
Validation loss: 2.520635082131068

Epoch: 6| Step: 7
Training loss: 2.3965772938766032
Validation loss: 2.5057597409364476

Epoch: 6| Step: 8
Training loss: 2.781466872085708
Validation loss: 2.508374896819347

Epoch: 6| Step: 9
Training loss: 2.3180056834838285
Validation loss: 2.5042848028117026

Epoch: 6| Step: 10
Training loss: 1.801678150762657
Validation loss: 2.5233538508452438

Epoch: 6| Step: 11
Training loss: 2.444747908376292
Validation loss: 2.547975111442072

Epoch: 6| Step: 12
Training loss: 2.245813713860908
Validation loss: 2.538818050256967

Epoch: 6| Step: 13
Training loss: 2.1917360978919733
Validation loss: 2.565408172923799

Epoch: 232| Step: 0
Training loss: 1.8608417015496828
Validation loss: 2.563910739521317

Epoch: 6| Step: 1
Training loss: 2.2853054421784176
Validation loss: 2.5686199486351278

Epoch: 6| Step: 2
Training loss: 2.4192891744706118
Validation loss: 2.5765287756038133

Epoch: 6| Step: 3
Training loss: 1.7891372598411788
Validation loss: 2.567324895388079

Epoch: 6| Step: 4
Training loss: 2.4252663770845655
Validation loss: 2.5635888027263474

Epoch: 6| Step: 5
Training loss: 1.7208646077169032
Validation loss: 2.5714787366050866

Epoch: 6| Step: 6
Training loss: 2.38832889568008
Validation loss: 2.557608207384881

Epoch: 6| Step: 7
Training loss: 1.9536043723241006
Validation loss: 2.554090268691893

Epoch: 6| Step: 8
Training loss: 2.3982134288781847
Validation loss: 2.563027180353306

Epoch: 6| Step: 9
Training loss: 2.3474919266404495
Validation loss: 2.558156899779043

Epoch: 6| Step: 10
Training loss: 2.8909301596735872
Validation loss: 2.5515381418853704

Epoch: 6| Step: 11
Training loss: 2.270438507006768
Validation loss: 2.555974568060393

Epoch: 6| Step: 12
Training loss: 2.280403502714568
Validation loss: 2.540922029781479

Epoch: 6| Step: 13
Training loss: 2.3952064246810747
Validation loss: 2.553162970507632

Epoch: 233| Step: 0
Training loss: 2.493290002602757
Validation loss: 2.528842424685806

Epoch: 6| Step: 1
Training loss: 1.9747469558856554
Validation loss: 2.5299131057603454

Epoch: 6| Step: 2
Training loss: 2.6679128079672183
Validation loss: 2.523940895346746

Epoch: 6| Step: 3
Training loss: 1.758335290097177
Validation loss: 2.537805929048234

Epoch: 6| Step: 4
Training loss: 2.0122228490832117
Validation loss: 2.525731181041662

Epoch: 6| Step: 5
Training loss: 2.5549775405165396
Validation loss: 2.5402923578931125

Epoch: 6| Step: 6
Training loss: 2.2807273788660023
Validation loss: 2.549804843341068

Epoch: 6| Step: 7
Training loss: 2.0520345872488663
Validation loss: 2.55379981621147

Epoch: 6| Step: 8
Training loss: 2.0935566371620737
Validation loss: 2.5575144269976953

Epoch: 6| Step: 9
Training loss: 2.6659200238983205
Validation loss: 2.543026713986627

Epoch: 6| Step: 10
Training loss: 2.5590275753394405
Validation loss: 2.5569542521736963

Epoch: 6| Step: 11
Training loss: 2.382904751352037
Validation loss: 2.530562115044391

Epoch: 6| Step: 12
Training loss: 1.7320453015188926
Validation loss: 2.545704086839706

Epoch: 6| Step: 13
Training loss: 2.147865024936213
Validation loss: 2.5431041456861077

Epoch: 234| Step: 0
Training loss: 2.435432926990624
Validation loss: 2.5296875326727206

Epoch: 6| Step: 1
Training loss: 2.715593632384109
Validation loss: 2.565908754418716

Epoch: 6| Step: 2
Training loss: 2.6055695887415675
Validation loss: 2.544275404198145

Epoch: 6| Step: 3
Training loss: 2.005194118168634
Validation loss: 2.5381731402652155

Epoch: 6| Step: 4
Training loss: 1.7628929809311134
Validation loss: 2.513363218290031

Epoch: 6| Step: 5
Training loss: 2.350835744898696
Validation loss: 2.522028495217185

Epoch: 6| Step: 6
Training loss: 2.357760047202757
Validation loss: 2.52258042936011

Epoch: 6| Step: 7
Training loss: 2.512425063804473
Validation loss: 2.4994256472450145

Epoch: 6| Step: 8
Training loss: 2.0479931288991344
Validation loss: 2.5206942927159837

Epoch: 6| Step: 9
Training loss: 2.761558689944911
Validation loss: 2.5225584311849083

Epoch: 6| Step: 10
Training loss: 1.8110762298608034
Validation loss: 2.5305420313265663

Epoch: 6| Step: 11
Training loss: 1.765952088432964
Validation loss: 2.538575189238931

Epoch: 6| Step: 12
Training loss: 1.932743941550578
Validation loss: 2.532783248013908

Epoch: 6| Step: 13
Training loss: 2.3015935270311902
Validation loss: 2.5371359220999734

Epoch: 235| Step: 0
Training loss: 2.2093949075581634
Validation loss: 2.605680763048712

Epoch: 6| Step: 1
Training loss: 2.3495171355219107
Validation loss: 2.626318449096425

Epoch: 6| Step: 2
Training loss: 3.1684004069744747
Validation loss: 2.6420900242272625

Epoch: 6| Step: 3
Training loss: 2.2245195620176768
Validation loss: 2.6281846876166632

Epoch: 6| Step: 4
Training loss: 2.503678286168637
Validation loss: 2.595023489853735

Epoch: 6| Step: 5
Training loss: 1.9651527844307695
Validation loss: 2.5745160669677545

Epoch: 6| Step: 6
Training loss: 2.487185633745295
Validation loss: 2.5636498809836645

Epoch: 6| Step: 7
Training loss: 2.273083216797361
Validation loss: 2.5353938198601362

Epoch: 6| Step: 8
Training loss: 1.7781305939866285
Validation loss: 2.528228887774052

Epoch: 6| Step: 9
Training loss: 2.015501269897273
Validation loss: 2.5020483844062147

Epoch: 6| Step: 10
Training loss: 2.4949876128292474
Validation loss: 2.4988283431757874

Epoch: 6| Step: 11
Training loss: 2.5412927779890833
Validation loss: 2.5023027940523406

Epoch: 6| Step: 12
Training loss: 2.585160153000699
Validation loss: 2.4937944323820713

Epoch: 6| Step: 13
Training loss: 2.0729911317980663
Validation loss: 2.4931085094494017

Epoch: 236| Step: 0
Training loss: 1.9511839720204955
Validation loss: 2.4730764858554113

Epoch: 6| Step: 1
Training loss: 2.719138983600101
Validation loss: 2.4908449389367173

Epoch: 6| Step: 2
Training loss: 1.8703175888056032
Validation loss: 2.5098155292541753

Epoch: 6| Step: 3
Training loss: 1.956993361542231
Validation loss: 2.566150019612403

Epoch: 6| Step: 4
Training loss: 2.722073157331512
Validation loss: 2.5744449745689524

Epoch: 6| Step: 5
Training loss: 2.2304381787665215
Validation loss: 2.6011834465090655

Epoch: 6| Step: 6
Training loss: 2.4873604740136774
Validation loss: 2.638830037604061

Epoch: 6| Step: 7
Training loss: 2.1884644698251914
Validation loss: 2.633232800057547

Epoch: 6| Step: 8
Training loss: 2.1940212592848427
Validation loss: 2.6062758538223947

Epoch: 6| Step: 9
Training loss: 2.1008306313779412
Validation loss: 2.6055669046392946

Epoch: 6| Step: 10
Training loss: 2.5624702265800816
Validation loss: 2.581437558679143

Epoch: 6| Step: 11
Training loss: 2.7283879593600697
Validation loss: 2.592710846015527

Epoch: 6| Step: 12
Training loss: 1.8494709289361595
Validation loss: 2.5613461587137314

Epoch: 6| Step: 13
Training loss: 2.3333052792452094
Validation loss: 2.574871962490525

Epoch: 237| Step: 0
Training loss: 1.4581221927202117
Validation loss: 2.572627801677034

Epoch: 6| Step: 1
Training loss: 2.4147867147275166
Validation loss: 2.5480235733681424

Epoch: 6| Step: 2
Training loss: 1.223655414296448
Validation loss: 2.54138216135668

Epoch: 6| Step: 3
Training loss: 1.9535257767518606
Validation loss: 2.5478439984027155

Epoch: 6| Step: 4
Training loss: 2.4083120254929153
Validation loss: 2.53157317684785

Epoch: 6| Step: 5
Training loss: 2.4396646131553856
Validation loss: 2.5316608236855274

Epoch: 6| Step: 6
Training loss: 1.712332796719134
Validation loss: 2.5361838117134736

Epoch: 6| Step: 7
Training loss: 2.6040471672614744
Validation loss: 2.514313618612984

Epoch: 6| Step: 8
Training loss: 2.4425772582283964
Validation loss: 2.538816485101792

Epoch: 6| Step: 9
Training loss: 2.6641846570061913
Validation loss: 2.5369493504020393

Epoch: 6| Step: 10
Training loss: 2.491313051458494
Validation loss: 2.5664905706495382

Epoch: 6| Step: 11
Training loss: 2.3838536723756407
Validation loss: 2.5664109724012

Epoch: 6| Step: 12
Training loss: 2.7229966945509054
Validation loss: 2.5740887267058814

Epoch: 6| Step: 13
Training loss: 2.349350100804195
Validation loss: 2.5735490436232578

Epoch: 238| Step: 0
Training loss: 2.2155782030164586
Validation loss: 2.577200120660871

Epoch: 6| Step: 1
Training loss: 2.179789332263679
Validation loss: 2.55029784563701

Epoch: 6| Step: 2
Training loss: 2.247070736907826
Validation loss: 2.538804182948518

Epoch: 6| Step: 3
Training loss: 1.7415146148357536
Validation loss: 2.54165987628801

Epoch: 6| Step: 4
Training loss: 2.044981568493593
Validation loss: 2.518444069204012

Epoch: 6| Step: 5
Training loss: 2.1719128722038046
Validation loss: 2.5175133956507327

Epoch: 6| Step: 6
Training loss: 1.8016759672933522
Validation loss: 2.5290118553966763

Epoch: 6| Step: 7
Training loss: 2.0538090325553178
Validation loss: 2.5276003927887443

Epoch: 6| Step: 8
Training loss: 1.9520681955353794
Validation loss: 2.5236627814765558

Epoch: 6| Step: 9
Training loss: 2.986611531832963
Validation loss: 2.528575041094599

Epoch: 6| Step: 10
Training loss: 2.5687901588883455
Validation loss: 2.5357821827707605

Epoch: 6| Step: 11
Training loss: 2.8224881305563265
Validation loss: 2.5417988278991315

Epoch: 6| Step: 12
Training loss: 2.1264180332641938
Validation loss: 2.5570039580827597

Epoch: 6| Step: 13
Training loss: 2.285457962854619
Validation loss: 2.540450998801833

Epoch: 239| Step: 0
Training loss: 1.6115665513705786
Validation loss: 2.5707826966956504

Epoch: 6| Step: 1
Training loss: 2.1884037875561577
Validation loss: 2.569421229100097

Epoch: 6| Step: 2
Training loss: 2.3971847592645106
Validation loss: 2.554525729938018

Epoch: 6| Step: 3
Training loss: 2.334261085355645
Validation loss: 2.5803189739170564

Epoch: 6| Step: 4
Training loss: 3.1515716023046543
Validation loss: 2.5767315884842192

Epoch: 6| Step: 5
Training loss: 1.870533455119962
Validation loss: 2.6088976242539084

Epoch: 6| Step: 6
Training loss: 1.698993817053777
Validation loss: 2.59368370921284

Epoch: 6| Step: 7
Training loss: 1.827286617695546
Validation loss: 2.593222123934766

Epoch: 6| Step: 8
Training loss: 2.6116459267220202
Validation loss: 2.6127219140867095

Epoch: 6| Step: 9
Training loss: 2.3947650241462153
Validation loss: 2.5981817416670325

Epoch: 6| Step: 10
Training loss: 2.0943614010097567
Validation loss: 2.580730416419185

Epoch: 6| Step: 11
Training loss: 2.206685104907739
Validation loss: 2.5620568210108723

Epoch: 6| Step: 12
Training loss: 2.33192972700261
Validation loss: 2.5763150190563784

Epoch: 6| Step: 13
Training loss: 2.162977697277736
Validation loss: 2.551686958101081

Epoch: 240| Step: 0
Training loss: 1.6354678524616577
Validation loss: 2.537143298855428

Epoch: 6| Step: 1
Training loss: 3.2360126569521617
Validation loss: 2.5325188301995603

Epoch: 6| Step: 2
Training loss: 2.4478384018960226
Validation loss: 2.5147135487247025

Epoch: 6| Step: 3
Training loss: 2.276306753776032
Validation loss: 2.5197587731117164

Epoch: 6| Step: 4
Training loss: 2.559307621964428
Validation loss: 2.5296367323652476

Epoch: 6| Step: 5
Training loss: 1.803421897840524
Validation loss: 2.520607738541391

Epoch: 6| Step: 6
Training loss: 1.8580445089398527
Validation loss: 2.5328853175469854

Epoch: 6| Step: 7
Training loss: 2.1094715237608934
Validation loss: 2.546249765362711

Epoch: 6| Step: 8
Training loss: 2.682789422426406
Validation loss: 2.52981938251412

Epoch: 6| Step: 9
Training loss: 2.429108970920951
Validation loss: 2.5370029802065557

Epoch: 6| Step: 10
Training loss: 1.9450696310999436
Validation loss: 2.5446513635529846

Epoch: 6| Step: 11
Training loss: 1.9163036693763806
Validation loss: 2.5435247091866997

Epoch: 6| Step: 12
Training loss: 1.6208897473766175
Validation loss: 2.5391528773728886

Epoch: 6| Step: 13
Training loss: 2.349053549405039
Validation loss: 2.5458837347041405

Epoch: 241| Step: 0
Training loss: 2.6600771988873797
Validation loss: 2.542650475339275

Epoch: 6| Step: 1
Training loss: 1.9052706845027523
Validation loss: 2.542110409590612

Epoch: 6| Step: 2
Training loss: 2.590986871236314
Validation loss: 2.5678041348694993

Epoch: 6| Step: 3
Training loss: 2.6563973778623127
Validation loss: 2.562853982558137

Epoch: 6| Step: 4
Training loss: 2.153921445641447
Validation loss: 2.574430087516488

Epoch: 6| Step: 5
Training loss: 2.579849775953165
Validation loss: 2.5681779649919907

Epoch: 6| Step: 6
Training loss: 2.574048327533978
Validation loss: 2.552104846059215

Epoch: 6| Step: 7
Training loss: 1.9497822346503169
Validation loss: 2.534860069556113

Epoch: 6| Step: 8
Training loss: 1.3728080965141254
Validation loss: 2.5119789981439924

Epoch: 6| Step: 9
Training loss: 2.1131354826402315
Validation loss: 2.4914262459990115

Epoch: 6| Step: 10
Training loss: 2.3023591257545624
Validation loss: 2.479916248214804

Epoch: 6| Step: 11
Training loss: 1.898829980789279
Validation loss: 2.496564411807692

Epoch: 6| Step: 12
Training loss: 2.189942113903871
Validation loss: 2.4878332272692263

Epoch: 6| Step: 13
Training loss: 2.222633830998259
Validation loss: 2.5021760212429425

Epoch: 242| Step: 0
Training loss: 2.0106990266737337
Validation loss: 2.510252956471081

Epoch: 6| Step: 1
Training loss: 2.964746767651711
Validation loss: 2.4963800289014326

Epoch: 6| Step: 2
Training loss: 2.0844300498727466
Validation loss: 2.523790616267105

Epoch: 6| Step: 3
Training loss: 2.392260621471348
Validation loss: 2.5161216435144493

Epoch: 6| Step: 4
Training loss: 2.0064669007556852
Validation loss: 2.5544827658210716

Epoch: 6| Step: 5
Training loss: 1.9627542173140855
Validation loss: 2.5693224668904846

Epoch: 6| Step: 6
Training loss: 2.5174567146709195
Validation loss: 2.632624618512616

Epoch: 6| Step: 7
Training loss: 2.1076985797114065
Validation loss: 2.6367022327800558

Epoch: 6| Step: 8
Training loss: 1.9118819914955283
Validation loss: 2.633214510478201

Epoch: 6| Step: 9
Training loss: 2.612640895420818
Validation loss: 2.5532526464470666

Epoch: 6| Step: 10
Training loss: 2.2317450991867642
Validation loss: 2.546021004318733

Epoch: 6| Step: 11
Training loss: 2.740958000665748
Validation loss: 2.5285953368708203

Epoch: 6| Step: 12
Training loss: 1.6490893769942943
Validation loss: 2.5085359442953203

Epoch: 6| Step: 13
Training loss: 2.2757330248012173
Validation loss: 2.4898098213462343

Epoch: 243| Step: 0
Training loss: 2.670822025300922
Validation loss: 2.4834590158938132

Epoch: 6| Step: 1
Training loss: 2.36439223224472
Validation loss: 2.505738031190204

Epoch: 6| Step: 2
Training loss: 2.7845698056217536
Validation loss: 2.5071276465412433

Epoch: 6| Step: 3
Training loss: 1.7885328949891108
Validation loss: 2.5100400702886296

Epoch: 6| Step: 4
Training loss: 1.8580394404139513
Validation loss: 2.5010666002468307

Epoch: 6| Step: 5
Training loss: 2.634953655436161
Validation loss: 2.50550181255327

Epoch: 6| Step: 6
Training loss: 2.606825719681734
Validation loss: 2.5092089004619424

Epoch: 6| Step: 7
Training loss: 1.3742888952659724
Validation loss: 2.524707014251852

Epoch: 6| Step: 8
Training loss: 2.506628024161876
Validation loss: 2.526367549259694

Epoch: 6| Step: 9
Training loss: 2.2849795020454926
Validation loss: 2.575919284733786

Epoch: 6| Step: 10
Training loss: 2.0491406663277045
Validation loss: 2.5867294374285676

Epoch: 6| Step: 11
Training loss: 2.3447659134492063
Validation loss: 2.5881674718024237

Epoch: 6| Step: 12
Training loss: 2.309555860155627
Validation loss: 2.579483783887604

Epoch: 6| Step: 13
Training loss: 1.7324509817127514
Validation loss: 2.5511271547443637

Epoch: 244| Step: 0
Training loss: 2.2793613088043365
Validation loss: 2.5648316111080334

Epoch: 6| Step: 1
Training loss: 2.2978124457133244
Validation loss: 2.5227889259900564

Epoch: 6| Step: 2
Training loss: 2.4717381416561848
Validation loss: 2.509606801906622

Epoch: 6| Step: 3
Training loss: 1.8009489233769032
Validation loss: 2.503683333211632

Epoch: 6| Step: 4
Training loss: 2.087568352773734
Validation loss: 2.5084192763989677

Epoch: 6| Step: 5
Training loss: 1.9824557296793666
Validation loss: 2.503005954484897

Epoch: 6| Step: 6
Training loss: 1.6870108001309003
Validation loss: 2.496747229358158

Epoch: 6| Step: 7
Training loss: 2.865038656403356
Validation loss: 2.5151524228219366

Epoch: 6| Step: 8
Training loss: 2.326441623475948
Validation loss: 2.5201787230022012

Epoch: 6| Step: 9
Training loss: 2.183024596693887
Validation loss: 2.51896836254822

Epoch: 6| Step: 10
Training loss: 1.789129264285426
Validation loss: 2.5261184733141624

Epoch: 6| Step: 11
Training loss: 2.3481440743429842
Validation loss: 2.536932214939299

Epoch: 6| Step: 12
Training loss: 2.601190213896252
Validation loss: 2.5437743770796613

Epoch: 6| Step: 13
Training loss: 1.992401889410159
Validation loss: 2.572490422595861

Epoch: 245| Step: 0
Training loss: 2.3288232153185837
Validation loss: 2.6199631732798556

Epoch: 6| Step: 1
Training loss: 2.6395537782463148
Validation loss: 2.638884841904688

Epoch: 6| Step: 2
Training loss: 1.850577176760266
Validation loss: 2.6569666774537635

Epoch: 6| Step: 3
Training loss: 2.0969283618760293
Validation loss: 2.6160130233109946

Epoch: 6| Step: 4
Training loss: 2.46521921819586
Validation loss: 2.611420840184548

Epoch: 6| Step: 5
Training loss: 2.266341734016889
Validation loss: 2.5401158578486434

Epoch: 6| Step: 6
Training loss: 1.4139042128178227
Validation loss: 2.527119551417699

Epoch: 6| Step: 7
Training loss: 2.881301938993458
Validation loss: 2.508862126228029

Epoch: 6| Step: 8
Training loss: 1.4062297395730168
Validation loss: 2.4900810563505034

Epoch: 6| Step: 9
Training loss: 3.0020805138268734
Validation loss: 2.519419696713888

Epoch: 6| Step: 10
Training loss: 2.2700731480782137
Validation loss: 2.51944180904009

Epoch: 6| Step: 11
Training loss: 2.352539771916404
Validation loss: 2.508927791487381

Epoch: 6| Step: 12
Training loss: 2.0875971331811867
Validation loss: 2.514025122169262

Epoch: 6| Step: 13
Training loss: 2.288100629654334
Validation loss: 2.5038584973904223

Epoch: 246| Step: 0
Training loss: 1.9157289062995424
Validation loss: 2.524644891551139

Epoch: 6| Step: 1
Training loss: 2.210148647021542
Validation loss: 2.5413455656076804

Epoch: 6| Step: 2
Training loss: 2.0703101967852753
Validation loss: 2.5782151485827147

Epoch: 6| Step: 3
Training loss: 2.2065392409966575
Validation loss: 2.610302347256114

Epoch: 6| Step: 4
Training loss: 2.5586999769217598
Validation loss: 2.6149961340725527

Epoch: 6| Step: 5
Training loss: 2.6654124489371656
Validation loss: 2.618239704629668

Epoch: 6| Step: 6
Training loss: 2.5286910697643856
Validation loss: 2.6271992205340258

Epoch: 6| Step: 7
Training loss: 1.5434886201439633
Validation loss: 2.6533151906637626

Epoch: 6| Step: 8
Training loss: 2.216852800781331
Validation loss: 2.638655791667768

Epoch: 6| Step: 9
Training loss: 2.161253279798765
Validation loss: 2.58857917886388

Epoch: 6| Step: 10
Training loss: 2.8190700510015025
Validation loss: 2.5482151585487456

Epoch: 6| Step: 11
Training loss: 2.3694025635480758
Validation loss: 2.50807285244804

Epoch: 6| Step: 12
Training loss: 1.9230548369533214
Validation loss: 2.5074276257431327

Epoch: 6| Step: 13
Training loss: 1.4798792166009829
Validation loss: 2.496967391627038

Epoch: 247| Step: 0
Training loss: 2.018658506605385
Validation loss: 2.48680356722267

Epoch: 6| Step: 1
Training loss: 2.7572282815317037
Validation loss: 2.4926387972178787

Epoch: 6| Step: 2
Training loss: 2.7167910830163815
Validation loss: 2.4835997517511137

Epoch: 6| Step: 3
Training loss: 2.0901354434647503
Validation loss: 2.484000003751733

Epoch: 6| Step: 4
Training loss: 2.3582324362514973
Validation loss: 2.492225383602153

Epoch: 6| Step: 5
Training loss: 2.179509090655788
Validation loss: 2.493588459388463

Epoch: 6| Step: 6
Training loss: 2.2898456158300142
Validation loss: 2.522290389315683

Epoch: 6| Step: 7
Training loss: 1.9627301658218086
Validation loss: 2.524796284430235

Epoch: 6| Step: 8
Training loss: 2.200117073411947
Validation loss: 2.5416488698951225

Epoch: 6| Step: 9
Training loss: 2.469665743801861
Validation loss: 2.5492896742467357

Epoch: 6| Step: 10
Training loss: 1.77326756137879
Validation loss: 2.5545111856853446

Epoch: 6| Step: 11
Training loss: 2.2411458323877116
Validation loss: 2.557035776505901

Epoch: 6| Step: 12
Training loss: 1.6945956775874436
Validation loss: 2.546072523386174

Epoch: 6| Step: 13
Training loss: 2.15762683199449
Validation loss: 2.53766794886027

Epoch: 248| Step: 0
Training loss: 2.321520352907207
Validation loss: 2.5497101057985887

Epoch: 6| Step: 1
Training loss: 2.2670191191618803
Validation loss: 2.5648973772118953

Epoch: 6| Step: 2
Training loss: 2.509453067539051
Validation loss: 2.5400256242485817

Epoch: 6| Step: 3
Training loss: 2.2189855316226783
Validation loss: 2.553353851035062

Epoch: 6| Step: 4
Training loss: 2.349132004187015
Validation loss: 2.5392208734661934

Epoch: 6| Step: 5
Training loss: 2.459914609465999
Validation loss: 2.5414203357667753

Epoch: 6| Step: 6
Training loss: 2.16745467405875
Validation loss: 2.5241319549161965

Epoch: 6| Step: 7
Training loss: 1.775006444677554
Validation loss: 2.534926973779565

Epoch: 6| Step: 8
Training loss: 2.1143298694057595
Validation loss: 2.5210922413007686

Epoch: 6| Step: 9
Training loss: 2.4301710230294233
Validation loss: 2.528807855215466

Epoch: 6| Step: 10
Training loss: 2.246651701250048
Validation loss: 2.544901686007914

Epoch: 6| Step: 11
Training loss: 1.7434851086316698
Validation loss: 2.53385508668941

Epoch: 6| Step: 12
Training loss: 2.3729500205286156
Validation loss: 2.5094485783983353

Epoch: 6| Step: 13
Training loss: 1.8896455355678623
Validation loss: 2.536404655457765

Epoch: 249| Step: 0
Training loss: 2.2921636100413414
Validation loss: 2.5451850979438033

Epoch: 6| Step: 1
Training loss: 2.292600429918438
Validation loss: 2.5388903124207287

Epoch: 6| Step: 2
Training loss: 2.327023956260759
Validation loss: 2.523806817553698

Epoch: 6| Step: 3
Training loss: 2.4570041770231943
Validation loss: 2.5382817716197796

Epoch: 6| Step: 4
Training loss: 2.0819347137343662
Validation loss: 2.5376026358306922

Epoch: 6| Step: 5
Training loss: 2.142484316863055
Validation loss: 2.5545134567719665

Epoch: 6| Step: 6
Training loss: 2.5234378779266358
Validation loss: 2.5316428048484934

Epoch: 6| Step: 7
Training loss: 1.5009624254681515
Validation loss: 2.532983821885002

Epoch: 6| Step: 8
Training loss: 2.0945689179826372
Validation loss: 2.535950013805766

Epoch: 6| Step: 9
Training loss: 2.611690932572749
Validation loss: 2.529382456309837

Epoch: 6| Step: 10
Training loss: 2.1093774866160113
Validation loss: 2.5316284665969073

Epoch: 6| Step: 11
Training loss: 2.1784049468562525
Validation loss: 2.541038894253564

Epoch: 6| Step: 12
Training loss: 1.95039506480443
Validation loss: 2.5596782686302015

Epoch: 6| Step: 13
Training loss: 2.1120296022262406
Validation loss: 2.5656839454561022

Epoch: 250| Step: 0
Training loss: 1.7582291172956528
Validation loss: 2.5646027102281974

Epoch: 6| Step: 1
Training loss: 1.8762426708873758
Validation loss: 2.577241657629032

Epoch: 6| Step: 2
Training loss: 2.384568264829369
Validation loss: 2.6206355976012063

Epoch: 6| Step: 3
Training loss: 2.288423312261854
Validation loss: 2.6106825577194135

Epoch: 6| Step: 4
Training loss: 1.7877173551711076
Validation loss: 2.5677845436119666

Epoch: 6| Step: 5
Training loss: 2.325632796772961
Validation loss: 2.554817064209795

Epoch: 6| Step: 6
Training loss: 2.4093210018850773
Validation loss: 2.541569681870786

Epoch: 6| Step: 7
Training loss: 2.4014417490140105
Validation loss: 2.536709067441027

Epoch: 6| Step: 8
Training loss: 1.7557418495368178
Validation loss: 2.5267805821230085

Epoch: 6| Step: 9
Training loss: 2.3947662188447376
Validation loss: 2.525541988910145

Epoch: 6| Step: 10
Training loss: 2.3857027129422046
Validation loss: 2.5213210419641534

Epoch: 6| Step: 11
Training loss: 1.7665266587302437
Validation loss: 2.543316021952411

Epoch: 6| Step: 12
Training loss: 2.3429917189695555
Validation loss: 2.542406268984914

Epoch: 6| Step: 13
Training loss: 2.704010041280307
Validation loss: 2.5389618056455547

Epoch: 251| Step: 0
Training loss: 1.7132734960405789
Validation loss: 2.535283505263656

Epoch: 6| Step: 1
Training loss: 2.1724314902930977
Validation loss: 2.554703831985018

Epoch: 6| Step: 2
Training loss: 2.2154942655530037
Validation loss: 2.556924880399171

Epoch: 6| Step: 3
Training loss: 1.6228653017794565
Validation loss: 2.556750942848862

Epoch: 6| Step: 4
Training loss: 1.981787729546348
Validation loss: 2.539212008255986

Epoch: 6| Step: 5
Training loss: 2.114016251717194
Validation loss: 2.539764964425631

Epoch: 6| Step: 6
Training loss: 1.506597632342906
Validation loss: 2.5326698465433597

Epoch: 6| Step: 7
Training loss: 2.9101972129038205
Validation loss: 2.5217462310626706

Epoch: 6| Step: 8
Training loss: 3.1012697634207527
Validation loss: 2.5330341628840958

Epoch: 6| Step: 9
Training loss: 1.5501625498784095
Validation loss: 2.5301624285032123

Epoch: 6| Step: 10
Training loss: 2.3074582788202465
Validation loss: 2.539452469051151

Epoch: 6| Step: 11
Training loss: 2.6405357932648243
Validation loss: 2.5546604431150532

Epoch: 6| Step: 12
Training loss: 1.9029929680586612
Validation loss: 2.5758473054705817

Epoch: 6| Step: 13
Training loss: 2.2549497413532418
Validation loss: 2.578332264593191

Epoch: 252| Step: 0
Training loss: 2.2130079516075343
Validation loss: 2.6090841683286685

Epoch: 6| Step: 1
Training loss: 2.2959375868963825
Validation loss: 2.5994322783584556

Epoch: 6| Step: 2
Training loss: 2.2713168501476515
Validation loss: 2.6421140275933017

Epoch: 6| Step: 3
Training loss: 2.076142362024184
Validation loss: 2.676121317468916

Epoch: 6| Step: 4
Training loss: 1.7700625668259626
Validation loss: 2.642443796123734

Epoch: 6| Step: 5
Training loss: 1.9124986137434978
Validation loss: 2.61755945399888

Epoch: 6| Step: 6
Training loss: 2.222337213825923
Validation loss: 2.577653506542817

Epoch: 6| Step: 7
Training loss: 1.9262099340233971
Validation loss: 2.5689862355355615

Epoch: 6| Step: 8
Training loss: 1.752016948783448
Validation loss: 2.5363922476074046

Epoch: 6| Step: 9
Training loss: 2.773430794721208
Validation loss: 2.5285563480927093

Epoch: 6| Step: 10
Training loss: 2.0968642346806483
Validation loss: 2.520252938620173

Epoch: 6| Step: 11
Training loss: 2.571753657318656
Validation loss: 2.5067915695181364

Epoch: 6| Step: 12
Training loss: 2.5567202632148667
Validation loss: 2.4958574703579965

Epoch: 6| Step: 13
Training loss: 2.174867612821705
Validation loss: 2.516244579018143

Epoch: 253| Step: 0
Training loss: 1.8919967214987417
Validation loss: 2.5094803664088063

Epoch: 6| Step: 1
Training loss: 1.5340735424869776
Validation loss: 2.518263544730978

Epoch: 6| Step: 2
Training loss: 2.283396507929965
Validation loss: 2.5218008617421335

Epoch: 6| Step: 3
Training loss: 1.5777723466006601
Validation loss: 2.5287056996690094

Epoch: 6| Step: 4
Training loss: 2.3588534151259832
Validation loss: 2.516859237511656

Epoch: 6| Step: 5
Training loss: 1.610326023026518
Validation loss: 2.5299697275574617

Epoch: 6| Step: 6
Training loss: 1.9379385175056085
Validation loss: 2.5468289423797517

Epoch: 6| Step: 7
Training loss: 2.3397475590620282
Validation loss: 2.5397367159364643

Epoch: 6| Step: 8
Training loss: 1.4227538693834079
Validation loss: 2.5498636726638817

Epoch: 6| Step: 9
Training loss: 2.34160240963055
Validation loss: 2.5787918461436745

Epoch: 6| Step: 10
Training loss: 2.1994446660439673
Validation loss: 2.57854131554724

Epoch: 6| Step: 11
Training loss: 3.3665884241762982
Validation loss: 2.581804643575949

Epoch: 6| Step: 12
Training loss: 2.5262114687344814
Validation loss: 2.5644914595640915

Epoch: 6| Step: 13
Training loss: 2.2395520821690122
Validation loss: 2.5855389121698007

Epoch: 254| Step: 0
Training loss: 2.4160269734664253
Validation loss: 2.5635453937311734

Epoch: 6| Step: 1
Training loss: 2.5057781203335394
Validation loss: 2.536680573447459

Epoch: 6| Step: 2
Training loss: 3.0911701890242482
Validation loss: 2.5292798447986833

Epoch: 6| Step: 3
Training loss: 1.7939737532618971
Validation loss: 2.5394011599318116

Epoch: 6| Step: 4
Training loss: 1.2890753543097258
Validation loss: 2.5123993706360315

Epoch: 6| Step: 5
Training loss: 2.0070641455176297
Validation loss: 2.5148014592397807

Epoch: 6| Step: 6
Training loss: 2.464836785598323
Validation loss: 2.5219083863372123

Epoch: 6| Step: 7
Training loss: 1.7694514174484495
Validation loss: 2.520580899128434

Epoch: 6| Step: 8
Training loss: 2.0266917802902698
Validation loss: 2.5329688244977038

Epoch: 6| Step: 9
Training loss: 2.3537315934363523
Validation loss: 2.549091201788373

Epoch: 6| Step: 10
Training loss: 2.075957465741206
Validation loss: 2.5764902808387755

Epoch: 6| Step: 11
Training loss: 1.7096662981004789
Validation loss: 2.5979289741092026

Epoch: 6| Step: 12
Training loss: 2.602525870627917
Validation loss: 2.6129115612491334

Epoch: 6| Step: 13
Training loss: 1.9920252116802455
Validation loss: 2.617267709897871

Epoch: 255| Step: 0
Training loss: 2.577069985661727
Validation loss: 2.5695781180403747

Epoch: 6| Step: 1
Training loss: 1.8857289752862825
Validation loss: 2.569981516018312

Epoch: 6| Step: 2
Training loss: 1.772641578906138
Validation loss: 2.580236676003605

Epoch: 6| Step: 3
Training loss: 1.7312216746082232
Validation loss: 2.5630210408768352

Epoch: 6| Step: 4
Training loss: 2.5621655873993427
Validation loss: 2.5550730430864697

Epoch: 6| Step: 5
Training loss: 1.8644887662238676
Validation loss: 2.5207431608944226

Epoch: 6| Step: 6
Training loss: 1.980365938606665
Validation loss: 2.5106021976108113

Epoch: 6| Step: 7
Training loss: 2.22861640294425
Validation loss: 2.5086395547780307

Epoch: 6| Step: 8
Training loss: 2.284886949109023
Validation loss: 2.5121858517440145

Epoch: 6| Step: 9
Training loss: 2.3264604801024484
Validation loss: 2.515077574818365

Epoch: 6| Step: 10
Training loss: 1.504615358899032
Validation loss: 2.525608919704984

Epoch: 6| Step: 11
Training loss: 3.0207228190935496
Validation loss: 2.551431461044349

Epoch: 6| Step: 12
Training loss: 2.4974475228082187
Validation loss: 2.5476779413143067

Epoch: 6| Step: 13
Training loss: 1.615115916695202
Validation loss: 2.5598096525807894

Epoch: 256| Step: 0
Training loss: 2.261366848095965
Validation loss: 2.590041331890533

Epoch: 6| Step: 1
Training loss: 1.6642483889489028
Validation loss: 2.5936527846781594

Epoch: 6| Step: 2
Training loss: 2.224744623508852
Validation loss: 2.605802225850925

Epoch: 6| Step: 3
Training loss: 2.0463468146796884
Validation loss: 2.6128732375113297

Epoch: 6| Step: 4
Training loss: 1.5790262198418359
Validation loss: 2.582044561970262

Epoch: 6| Step: 5
Training loss: 2.4020614830362135
Validation loss: 2.5557474781844736

Epoch: 6| Step: 6
Training loss: 2.1734776792782013
Validation loss: 2.576952596404838

Epoch: 6| Step: 7
Training loss: 1.964965088512329
Validation loss: 2.589478249743758

Epoch: 6| Step: 8
Training loss: 2.945481191807876
Validation loss: 2.5919317283705006

Epoch: 6| Step: 9
Training loss: 2.4788980632349844
Validation loss: 2.5685522357583888

Epoch: 6| Step: 10
Training loss: 2.6891655307606213
Validation loss: 2.5676848595547614

Epoch: 6| Step: 11
Training loss: 1.4363454245531064
Validation loss: 2.5554461737964704

Epoch: 6| Step: 12
Training loss: 2.080839291850358
Validation loss: 2.5703294747670387

Epoch: 6| Step: 13
Training loss: 1.714832279801296
Validation loss: 2.553742898093102

Epoch: 257| Step: 0
Training loss: 2.206615955811167
Validation loss: 2.553129913188389

Epoch: 6| Step: 1
Training loss: 2.2516602642533967
Validation loss: 2.5553862756372965

Epoch: 6| Step: 2
Training loss: 2.6832639444355473
Validation loss: 2.546185343537429

Epoch: 6| Step: 3
Training loss: 2.546799734676797
Validation loss: 2.5616656782743608

Epoch: 6| Step: 4
Training loss: 2.0300353893709313
Validation loss: 2.519307483918857

Epoch: 6| Step: 5
Training loss: 1.673123472866406
Validation loss: 2.5449349126630656

Epoch: 6| Step: 6
Training loss: 2.492166835974285
Validation loss: 2.5629183885120685

Epoch: 6| Step: 7
Training loss: 1.9143773034132034
Validation loss: 2.5997952328645844

Epoch: 6| Step: 8
Training loss: 1.5801897799316973
Validation loss: 2.5890632630928185

Epoch: 6| Step: 9
Training loss: 2.0657092471118763
Validation loss: 2.605062091743924

Epoch: 6| Step: 10
Training loss: 2.3041704018018176
Validation loss: 2.6151345926953717

Epoch: 6| Step: 11
Training loss: 1.7741969158890165
Validation loss: 2.5773013330850376

Epoch: 6| Step: 12
Training loss: 2.4324891842702603
Validation loss: 2.557174840512982

Epoch: 6| Step: 13
Training loss: 1.9785546678341739
Validation loss: 2.541586223225632

Epoch: 258| Step: 0
Training loss: 2.063031099315263
Validation loss: 2.539693751971485

Epoch: 6| Step: 1
Training loss: 2.5887826440245867
Validation loss: 2.513695073310927

Epoch: 6| Step: 2
Training loss: 1.63530617439888
Validation loss: 2.5556078078507287

Epoch: 6| Step: 3
Training loss: 1.7710137967175927
Validation loss: 2.548854970973323

Epoch: 6| Step: 4
Training loss: 2.49184001544996
Validation loss: 2.560239647834092

Epoch: 6| Step: 5
Training loss: 1.3938228399975034
Validation loss: 2.5875464406046054

Epoch: 6| Step: 6
Training loss: 2.5815097668891727
Validation loss: 2.605965860004133

Epoch: 6| Step: 7
Training loss: 2.755353658169073
Validation loss: 2.616342269526764

Epoch: 6| Step: 8
Training loss: 1.9406908893303145
Validation loss: 2.64030699912466

Epoch: 6| Step: 9
Training loss: 1.8049227078233656
Validation loss: 2.6558261757610464

Epoch: 6| Step: 10
Training loss: 2.835010555725361
Validation loss: 2.611145051156176

Epoch: 6| Step: 11
Training loss: 1.8596373300863487
Validation loss: 2.5791829568310463

Epoch: 6| Step: 12
Training loss: 2.527439781852599
Validation loss: 2.5607402931175143

Epoch: 6| Step: 13
Training loss: 1.5599178340254087
Validation loss: 2.530971904281686

Epoch: 259| Step: 0
Training loss: 2.179687062471954
Validation loss: 2.52063866065905

Epoch: 6| Step: 1
Training loss: 2.3784070924131577
Validation loss: 2.491926970860423

Epoch: 6| Step: 2
Training loss: 2.2551348691138333
Validation loss: 2.4894019078077374

Epoch: 6| Step: 3
Training loss: 1.785543253746191
Validation loss: 2.4797586380758463

Epoch: 6| Step: 4
Training loss: 2.207058148515565
Validation loss: 2.4787219527557918

Epoch: 6| Step: 5
Training loss: 1.916976641039546
Validation loss: 2.478240029614514

Epoch: 6| Step: 6
Training loss: 2.3552613428002855
Validation loss: 2.505114045354775

Epoch: 6| Step: 7
Training loss: 2.264437870897496
Validation loss: 2.5010905430371384

Epoch: 6| Step: 8
Training loss: 1.8719838997523475
Validation loss: 2.5069166506573564

Epoch: 6| Step: 9
Training loss: 2.82999792307855
Validation loss: 2.5497807034460616

Epoch: 6| Step: 10
Training loss: 1.666970519342369
Validation loss: 2.5861727635371006

Epoch: 6| Step: 11
Training loss: 1.8045810156118618
Validation loss: 2.609784198891497

Epoch: 6| Step: 12
Training loss: 2.1528040675810596
Validation loss: 2.621879054457781

Epoch: 6| Step: 13
Training loss: 3.0053973918046206
Validation loss: 2.605010503746524

Epoch: 260| Step: 0
Training loss: 2.75074125183373
Validation loss: 2.578400275436712

Epoch: 6| Step: 1
Training loss: 2.3465508573667218
Validation loss: 2.5491174214588286

Epoch: 6| Step: 2
Training loss: 1.8509830260196647
Validation loss: 2.568845861893896

Epoch: 6| Step: 3
Training loss: 1.8548255849724349
Validation loss: 2.5607268083262014

Epoch: 6| Step: 4
Training loss: 1.3568426639142506
Validation loss: 2.5152774594416334

Epoch: 6| Step: 5
Training loss: 2.194388089750749
Validation loss: 2.5418686135115447

Epoch: 6| Step: 6
Training loss: 2.554076888812724
Validation loss: 2.5250331372897294

Epoch: 6| Step: 7
Training loss: 1.6219436072390052
Validation loss: 2.5406952914328187

Epoch: 6| Step: 8
Training loss: 2.4497515571901505
Validation loss: 2.5161587482600773

Epoch: 6| Step: 9
Training loss: 2.275653401537823
Validation loss: 2.5001869449654754

Epoch: 6| Step: 10
Training loss: 1.605395387333105
Validation loss: 2.4788588378168024

Epoch: 6| Step: 11
Training loss: 2.175722076871523
Validation loss: 2.525854978184435

Epoch: 6| Step: 12
Training loss: 1.8683665874197635
Validation loss: 2.5358384384703943

Epoch: 6| Step: 13
Training loss: 2.7127730342023115
Validation loss: 2.5289214298647877

Epoch: 261| Step: 0
Training loss: 2.120233912968832
Validation loss: 2.5165566798253804

Epoch: 6| Step: 1
Training loss: 2.2672074677884795
Validation loss: 2.53755360689211

Epoch: 6| Step: 2
Training loss: 1.915799967754717
Validation loss: 2.546897700858019

Epoch: 6| Step: 3
Training loss: 1.698326350052053
Validation loss: 2.5270524404911723

Epoch: 6| Step: 4
Training loss: 1.8561330790575419
Validation loss: 2.527648011278043

Epoch: 6| Step: 5
Training loss: 1.862841156302518
Validation loss: 2.532134196005095

Epoch: 6| Step: 6
Training loss: 1.940352892879919
Validation loss: 2.5540722680707284

Epoch: 6| Step: 7
Training loss: 2.9057127753424092
Validation loss: 2.583267239268608

Epoch: 6| Step: 8
Training loss: 1.6794485942472293
Validation loss: 2.5647210675792924

Epoch: 6| Step: 9
Training loss: 2.113111337540289
Validation loss: 2.575951370855358

Epoch: 6| Step: 10
Training loss: 1.7471465962506647
Validation loss: 2.585695883535645

Epoch: 6| Step: 11
Training loss: 2.529850891001421
Validation loss: 2.573012220227404

Epoch: 6| Step: 12
Training loss: 1.8252021050569165
Validation loss: 2.5740270548072726

Epoch: 6| Step: 13
Training loss: 2.717225008810393
Validation loss: 2.5462061778089606

Epoch: 262| Step: 0
Training loss: 2.4973037485297325
Validation loss: 2.5221083834408407

Epoch: 6| Step: 1
Training loss: 2.558691404386402
Validation loss: 2.5258267393144624

Epoch: 6| Step: 2
Training loss: 2.492663299200506
Validation loss: 2.5185181939393915

Epoch: 6| Step: 3
Training loss: 2.2511160519754796
Validation loss: 2.5153415196392803

Epoch: 6| Step: 4
Training loss: 1.8607237596220974
Validation loss: 2.5397935802707114

Epoch: 6| Step: 5
Training loss: 1.5676327895237192
Validation loss: 2.5145555359305574

Epoch: 6| Step: 6
Training loss: 2.1967781577328176
Validation loss: 2.5430967862212692

Epoch: 6| Step: 7
Training loss: 2.1204556511700736
Validation loss: 2.5621294978804046

Epoch: 6| Step: 8
Training loss: 1.8968645023262856
Validation loss: 2.5806518194089647

Epoch: 6| Step: 9
Training loss: 2.425712449331293
Validation loss: 2.6031632181318125

Epoch: 6| Step: 10
Training loss: 1.3969298605845468
Validation loss: 2.5881558955286943

Epoch: 6| Step: 11
Training loss: 1.1954651778704617
Validation loss: 2.564792305566665

Epoch: 6| Step: 12
Training loss: 2.5035331555230544
Validation loss: 2.571756886597091

Epoch: 6| Step: 13
Training loss: 2.4075747719756926
Validation loss: 2.543305155530086

Epoch: 263| Step: 0
Training loss: 1.840770382798493
Validation loss: 2.5419282830679113

Epoch: 6| Step: 1
Training loss: 1.8398912427729375
Validation loss: 2.533715950364313

Epoch: 6| Step: 2
Training loss: 2.4659403977566217
Validation loss: 2.5229563849861534

Epoch: 6| Step: 3
Training loss: 2.6204797790306165
Validation loss: 2.5280165879715355

Epoch: 6| Step: 4
Training loss: 2.175338289107721
Validation loss: 2.5642435143622957

Epoch: 6| Step: 5
Training loss: 2.4473955830792216
Validation loss: 2.5607911436422945

Epoch: 6| Step: 6
Training loss: 1.738850635328527
Validation loss: 2.5813816040086603

Epoch: 6| Step: 7
Training loss: 1.8571989003832403
Validation loss: 2.6015420174007167

Epoch: 6| Step: 8
Training loss: 1.9853698759646319
Validation loss: 2.5943629141973057

Epoch: 6| Step: 9
Training loss: 1.994643548657241
Validation loss: 2.583067177833674

Epoch: 6| Step: 10
Training loss: 1.728951023244322
Validation loss: 2.55973483743892

Epoch: 6| Step: 11
Training loss: 2.2561859290834696
Validation loss: 2.55086395300959

Epoch: 6| Step: 12
Training loss: 2.2194132283731185
Validation loss: 2.5475419698221002

Epoch: 6| Step: 13
Training loss: 2.284320384989123
Validation loss: 2.547701477254506

Epoch: 264| Step: 0
Training loss: 2.006187404713735
Validation loss: 2.519269108503875

Epoch: 6| Step: 1
Training loss: 2.4704522167557577
Validation loss: 2.509850265322535

Epoch: 6| Step: 2
Training loss: 1.7821253583208971
Validation loss: 2.5185020375205975

Epoch: 6| Step: 3
Training loss: 2.3150062382986825
Validation loss: 2.5117674289413943

Epoch: 6| Step: 4
Training loss: 1.9705702828585077
Validation loss: 2.5161729930521806

Epoch: 6| Step: 5
Training loss: 1.7637393300621151
Validation loss: 2.5429757582513717

Epoch: 6| Step: 6
Training loss: 2.219299893001323
Validation loss: 2.530253963967261

Epoch: 6| Step: 7
Training loss: 1.934099289283328
Validation loss: 2.5455065055958355

Epoch: 6| Step: 8
Training loss: 2.472777449543716
Validation loss: 2.5580431629682088

Epoch: 6| Step: 9
Training loss: 2.521401165358246
Validation loss: 2.55161423296868

Epoch: 6| Step: 10
Training loss: 2.1626950567399152
Validation loss: 2.5621796694630974

Epoch: 6| Step: 11
Training loss: 2.098039929412726
Validation loss: 2.5894338706338385

Epoch: 6| Step: 12
Training loss: 1.6826793904909103
Validation loss: 2.608450567842591

Epoch: 6| Step: 13
Training loss: 2.075488260572772
Validation loss: 2.671774938542716

Epoch: 265| Step: 0
Training loss: 1.957850910854218
Validation loss: 2.702445472169539

Epoch: 6| Step: 1
Training loss: 2.1549351318225987
Validation loss: 2.653153832784045

Epoch: 6| Step: 2
Training loss: 1.7907678730206003
Validation loss: 2.60524682086843

Epoch: 6| Step: 3
Training loss: 1.6655146750150327
Validation loss: 2.5862889353576333

Epoch: 6| Step: 4
Training loss: 2.27735945367388
Validation loss: 2.5475727677863382

Epoch: 6| Step: 5
Training loss: 2.1038874702167902
Validation loss: 2.521590392397777

Epoch: 6| Step: 6
Training loss: 2.1942779166645057
Validation loss: 2.509467033703254

Epoch: 6| Step: 7
Training loss: 2.0191197815459647
Validation loss: 2.500957925377772

Epoch: 6| Step: 8
Training loss: 2.914324628479321
Validation loss: 2.4801501132028236

Epoch: 6| Step: 9
Training loss: 2.1485116286927397
Validation loss: 2.4769402986964537

Epoch: 6| Step: 10
Training loss: 2.132245781471104
Validation loss: 2.4879171283699986

Epoch: 6| Step: 11
Training loss: 2.7716571090022684
Validation loss: 2.473945687244954

Epoch: 6| Step: 12
Training loss: 2.3543188220340276
Validation loss: 2.459973343185273

Epoch: 6| Step: 13
Training loss: 2.5849415685074306
Validation loss: 2.468409575156972

Epoch: 266| Step: 0
Training loss: 2.212102899637905
Validation loss: 2.509929947477115

Epoch: 6| Step: 1
Training loss: 2.1011360047670795
Validation loss: 2.547717744844876

Epoch: 6| Step: 2
Training loss: 2.614059537622537
Validation loss: 2.5890173881067677

Epoch: 6| Step: 3
Training loss: 2.333680354153355
Validation loss: 2.6149757415006123

Epoch: 6| Step: 4
Training loss: 1.5181477581028597
Validation loss: 2.6458957594668386

Epoch: 6| Step: 5
Training loss: 1.9881780631339157
Validation loss: 2.605262256314914

Epoch: 6| Step: 6
Training loss: 1.826292374659117
Validation loss: 2.598924248012541

Epoch: 6| Step: 7
Training loss: 1.8667113523016594
Validation loss: 2.629835791060636

Epoch: 6| Step: 8
Training loss: 2.372365795717213
Validation loss: 2.583254079731024

Epoch: 6| Step: 9
Training loss: 2.4797373737206434
Validation loss: 2.608103489930689

Epoch: 6| Step: 10
Training loss: 2.1847239727194596
Validation loss: 2.577412716892042

Epoch: 6| Step: 11
Training loss: 2.409552549556599
Validation loss: 2.5573703471482867

Epoch: 6| Step: 12
Training loss: 1.9052584211030488
Validation loss: 2.530673726734581

Epoch: 6| Step: 13
Training loss: 2.3076010698231033
Validation loss: 2.5053084440049003

Epoch: 267| Step: 0
Training loss: 2.557310851440152
Validation loss: 2.4816046089045942

Epoch: 6| Step: 1
Training loss: 2.553727649174525
Validation loss: 2.477521917103128

Epoch: 6| Step: 2
Training loss: 1.8767689943054926
Validation loss: 2.488187731268514

Epoch: 6| Step: 3
Training loss: 2.6565259004806103
Validation loss: 2.505111166377598

Epoch: 6| Step: 4
Training loss: 2.2006857063481373
Validation loss: 2.496000094141714

Epoch: 6| Step: 5
Training loss: 2.2270022309407302
Validation loss: 2.5119158804399264

Epoch: 6| Step: 6
Training loss: 2.655291395558067
Validation loss: 2.5231273291218557

Epoch: 6| Step: 7
Training loss: 1.826507896475192
Validation loss: 2.533744556111888

Epoch: 6| Step: 8
Training loss: 2.5927969778827777
Validation loss: 2.5172747618382725

Epoch: 6| Step: 9
Training loss: 1.625942470433697
Validation loss: 2.5385553254480224

Epoch: 6| Step: 10
Training loss: 1.898713770728568
Validation loss: 2.5681030454955915

Epoch: 6| Step: 11
Training loss: 1.5819239450491676
Validation loss: 2.5681427645507915

Epoch: 6| Step: 12
Training loss: 1.7481720778311545
Validation loss: 2.5620896080570144

Epoch: 6| Step: 13
Training loss: 2.2610326065486044
Validation loss: 2.5605018082180093

Epoch: 268| Step: 0
Training loss: 2.3746523351684856
Validation loss: 2.537418635399645

Epoch: 6| Step: 1
Training loss: 2.5611056744491822
Validation loss: 2.5016529340915628

Epoch: 6| Step: 2
Training loss: 2.3119262808428296
Validation loss: 2.5197022688042243

Epoch: 6| Step: 3
Training loss: 2.063230558536055
Validation loss: 2.493064351422004

Epoch: 6| Step: 4
Training loss: 2.1974270774016706
Validation loss: 2.505288030952094

Epoch: 6| Step: 5
Training loss: 2.3727345955794488
Validation loss: 2.485103460392991

Epoch: 6| Step: 6
Training loss: 2.5079605201461153
Validation loss: 2.4779990409149293

Epoch: 6| Step: 7
Training loss: 1.285385065086998
Validation loss: 2.4827814169447073

Epoch: 6| Step: 8
Training loss: 1.6939169769749736
Validation loss: 2.472270338849887

Epoch: 6| Step: 9
Training loss: 1.9900371839413549
Validation loss: 2.4854197914336247

Epoch: 6| Step: 10
Training loss: 2.3807548268421566
Validation loss: 2.504109533571131

Epoch: 6| Step: 11
Training loss: 1.7189889915073873
Validation loss: 2.5341560965378944

Epoch: 6| Step: 12
Training loss: 1.9892185003172462
Validation loss: 2.5799138500310335

Epoch: 6| Step: 13
Training loss: 2.216907111968592
Validation loss: 2.5502561814519606

Epoch: 269| Step: 0
Training loss: 2.4946621175643298
Validation loss: 2.5721153421993876

Epoch: 6| Step: 1
Training loss: 2.0388300386829066
Validation loss: 2.6106757236137876

Epoch: 6| Step: 2
Training loss: 1.7690774028226506
Validation loss: 2.622676487097352

Epoch: 6| Step: 3
Training loss: 1.4509650964883398
Validation loss: 2.6257559429577118

Epoch: 6| Step: 4
Training loss: 2.217394024919628
Validation loss: 2.6493790264838464

Epoch: 6| Step: 5
Training loss: 2.2489080958536727
Validation loss: 2.6489977998802385

Epoch: 6| Step: 6
Training loss: 1.9771880716679053
Validation loss: 2.6082801273107163

Epoch: 6| Step: 7
Training loss: 2.3300337167682477
Validation loss: 2.5511542568903884

Epoch: 6| Step: 8
Training loss: 1.9968210824961505
Validation loss: 2.500435409776536

Epoch: 6| Step: 9
Training loss: 2.3413275852169018
Validation loss: 2.512715380722304

Epoch: 6| Step: 10
Training loss: 1.9673585970329501
Validation loss: 2.5021546456632144

Epoch: 6| Step: 11
Training loss: 2.577960939678169
Validation loss: 2.5017858008071596

Epoch: 6| Step: 12
Training loss: 2.5212931778425243
Validation loss: 2.5149332837001883

Epoch: 6| Step: 13
Training loss: 2.1780954104456476
Validation loss: 2.5309506777013553

Epoch: 270| Step: 0
Training loss: 2.52079554337689
Validation loss: 2.568534599486516

Epoch: 6| Step: 1
Training loss: 1.7890089268554956
Validation loss: 2.5296463929846484

Epoch: 6| Step: 2
Training loss: 2.538277372602071
Validation loss: 2.5574744341166897

Epoch: 6| Step: 3
Training loss: 2.402671531087345
Validation loss: 2.591540395066744

Epoch: 6| Step: 4
Training loss: 1.950525002842221
Validation loss: 2.6064420194808724

Epoch: 6| Step: 5
Training loss: 1.7304252808495226
Validation loss: 2.6316086066398348

Epoch: 6| Step: 6
Training loss: 1.8868679200905456
Validation loss: 2.5884424237902137

Epoch: 6| Step: 7
Training loss: 2.3315303398709024
Validation loss: 2.589521553937343

Epoch: 6| Step: 8
Training loss: 2.557599289384683
Validation loss: 2.59399012331184

Epoch: 6| Step: 9
Training loss: 1.7609760215898744
Validation loss: 2.5928354144546457

Epoch: 6| Step: 10
Training loss: 1.8927299194560618
Validation loss: 2.5849504075498206

Epoch: 6| Step: 11
Training loss: 1.7536873117935752
Validation loss: 2.58106260073552

Epoch: 6| Step: 12
Training loss: 2.302895162597145
Validation loss: 2.5889230187553514

Epoch: 6| Step: 13
Training loss: 1.9535215661855392
Validation loss: 2.5423099037405543

Epoch: 271| Step: 0
Training loss: 2.4634867709752903
Validation loss: 2.5464913248902685

Epoch: 6| Step: 1
Training loss: 2.6440384150612912
Validation loss: 2.5313263555870433

Epoch: 6| Step: 2
Training loss: 2.658381067244055
Validation loss: 2.549006297776554

Epoch: 6| Step: 3
Training loss: 1.7434611775195055
Validation loss: 2.5451877676615955

Epoch: 6| Step: 4
Training loss: 1.9076588536783017
Validation loss: 2.5882268416127308

Epoch: 6| Step: 5
Training loss: 1.9270749341077165
Validation loss: 2.608820096706902

Epoch: 6| Step: 6
Training loss: 2.4689875621211987
Validation loss: 2.590277541986977

Epoch: 6| Step: 7
Training loss: 1.8421479069642623
Validation loss: 2.576643408250478

Epoch: 6| Step: 8
Training loss: 1.6422577499041864
Validation loss: 2.5709705302778696

Epoch: 6| Step: 9
Training loss: 1.87478661912457
Validation loss: 2.54992120720797

Epoch: 6| Step: 10
Training loss: 1.7266639230895369
Validation loss: 2.5838016244510507

Epoch: 6| Step: 11
Training loss: 1.7142540128365233
Validation loss: 2.564457076244695

Epoch: 6| Step: 12
Training loss: 2.1850312607403577
Validation loss: 2.5639406976898957

Epoch: 6| Step: 13
Training loss: 2.1055943269383612
Validation loss: 2.530092155099996

Epoch: 272| Step: 0
Training loss: 1.2176772556086441
Validation loss: 2.562192526257681

Epoch: 6| Step: 1
Training loss: 2.567982368212626
Validation loss: 2.5791717870247526

Epoch: 6| Step: 2
Training loss: 2.360982082307033
Validation loss: 2.558907176614652

Epoch: 6| Step: 3
Training loss: 2.642157115795414
Validation loss: 2.6212974958068833

Epoch: 6| Step: 4
Training loss: 2.1861826608537154
Validation loss: 2.6169146191501382

Epoch: 6| Step: 5
Training loss: 2.061248862206658
Validation loss: 2.6136458009114723

Epoch: 6| Step: 6
Training loss: 2.1007791072994837
Validation loss: 2.6187081014214506

Epoch: 6| Step: 7
Training loss: 1.8278901038911164
Validation loss: 2.5659405321072253

Epoch: 6| Step: 8
Training loss: 1.6642539044117064
Validation loss: 2.510730744865869

Epoch: 6| Step: 9
Training loss: 2.3027843829056276
Validation loss: 2.4915563966172454

Epoch: 6| Step: 10
Training loss: 2.5062931960799792
Validation loss: 2.478412270301106

Epoch: 6| Step: 11
Training loss: 2.4962255595333094
Validation loss: 2.4772329776651434

Epoch: 6| Step: 12
Training loss: 1.7759381783353392
Validation loss: 2.504510180819648

Epoch: 6| Step: 13
Training loss: 1.4291641027725992
Validation loss: 2.4986813484876396

Epoch: 273| Step: 0
Training loss: 2.07174046052265
Validation loss: 2.522458952616089

Epoch: 6| Step: 1
Training loss: 1.7082392348758813
Validation loss: 2.5287788479225384

Epoch: 6| Step: 2
Training loss: 2.129037947474659
Validation loss: 2.5714207263100253

Epoch: 6| Step: 3
Training loss: 2.468975587992227
Validation loss: 2.5694559171494964

Epoch: 6| Step: 4
Training loss: 2.2837735157858865
Validation loss: 2.5799198568942474

Epoch: 6| Step: 5
Training loss: 2.3343155246904894
Validation loss: 2.5953226033013523

Epoch: 6| Step: 6
Training loss: 1.2231226997178424
Validation loss: 2.6010300069376266

Epoch: 6| Step: 7
Training loss: 1.8361546164837985
Validation loss: 2.5987952467230384

Epoch: 6| Step: 8
Training loss: 1.8179202097472729
Validation loss: 2.645581846725593

Epoch: 6| Step: 9
Training loss: 2.1172940273159773
Validation loss: 2.648689625609901

Epoch: 6| Step: 10
Training loss: 2.152019829442442
Validation loss: 2.6187120694347343

Epoch: 6| Step: 11
Training loss: 2.324601137136723
Validation loss: 2.63534909690712

Epoch: 6| Step: 12
Training loss: 2.1857047207228577
Validation loss: 2.5896404756198783

Epoch: 6| Step: 13
Training loss: 2.359861412181781
Validation loss: 2.5942145854552967

Epoch: 274| Step: 0
Training loss: 2.2411349813517862
Validation loss: 2.549045285538616

Epoch: 6| Step: 1
Training loss: 2.5568957569414588
Validation loss: 2.5092050364168457

Epoch: 6| Step: 2
Training loss: 1.4657225553990487
Validation loss: 2.486290135559104

Epoch: 6| Step: 3
Training loss: 2.3003304368532316
Validation loss: 2.514896058171303

Epoch: 6| Step: 4
Training loss: 1.4069418159118046
Validation loss: 2.5015845840054327

Epoch: 6| Step: 5
Training loss: 2.0778094747690274
Validation loss: 2.4799819668888423

Epoch: 6| Step: 6
Training loss: 2.2956977993467027
Validation loss: 2.4808386979852894

Epoch: 6| Step: 7
Training loss: 2.1301606288751023
Validation loss: 2.540729949397612

Epoch: 6| Step: 8
Training loss: 2.3265178688948662
Validation loss: 2.535315760848584

Epoch: 6| Step: 9
Training loss: 2.147569737750888
Validation loss: 2.5947284614729282

Epoch: 6| Step: 10
Training loss: 2.551262382241778
Validation loss: 2.598173574691432

Epoch: 6| Step: 11
Training loss: 1.6216676730198236
Validation loss: 2.607983840789933

Epoch: 6| Step: 12
Training loss: 1.9133845160059462
Validation loss: 2.580285402106175

Epoch: 6| Step: 13
Training loss: 1.9511284961785202
Validation loss: 2.57072450066377

Epoch: 275| Step: 0
Training loss: 2.1679709494639745
Validation loss: 2.545068673666866

Epoch: 6| Step: 1
Training loss: 1.3087381311732835
Validation loss: 2.518519716487186

Epoch: 6| Step: 2
Training loss: 2.1707589554690365
Validation loss: 2.5185083644117885

Epoch: 6| Step: 3
Training loss: 2.486540612237933
Validation loss: 2.518407321586129

Epoch: 6| Step: 4
Training loss: 1.394263703996939
Validation loss: 2.525591109426899

Epoch: 6| Step: 5
Training loss: 2.236438358705108
Validation loss: 2.5108499957609105

Epoch: 6| Step: 6
Training loss: 2.161595780625309
Validation loss: 2.533053152271898

Epoch: 6| Step: 7
Training loss: 1.827412066868565
Validation loss: 2.5775440447744393

Epoch: 6| Step: 8
Training loss: 1.735825627908561
Validation loss: 2.555967618770478

Epoch: 6| Step: 9
Training loss: 2.666264404315195
Validation loss: 2.54962504316678

Epoch: 6| Step: 10
Training loss: 1.5425757571617842
Validation loss: 2.5551588302235686

Epoch: 6| Step: 11
Training loss: 2.4859285115883325
Validation loss: 2.536459777225864

Epoch: 6| Step: 12
Training loss: 2.0017901991629503
Validation loss: 2.532899044691148

Epoch: 6| Step: 13
Training loss: 2.2099551117770098
Validation loss: 2.5542669076421256

Epoch: 276| Step: 0
Training loss: 1.8065104339703724
Validation loss: 2.5429651794564787

Epoch: 6| Step: 1
Training loss: 2.168954875844236
Validation loss: 2.538614587645659

Epoch: 6| Step: 2
Training loss: 1.4459164568983887
Validation loss: 2.5966116657316567

Epoch: 6| Step: 3
Training loss: 2.5796528306152875
Validation loss: 2.6161722823748996

Epoch: 6| Step: 4
Training loss: 1.9451165158006045
Validation loss: 2.599503428771985

Epoch: 6| Step: 5
Training loss: 1.8694741520529488
Validation loss: 2.5936361923681037

Epoch: 6| Step: 6
Training loss: 2.6091520476888626
Validation loss: 2.5608371906601115

Epoch: 6| Step: 7
Training loss: 1.8099509763664803
Validation loss: 2.5553568080889058

Epoch: 6| Step: 8
Training loss: 2.1537294998123175
Validation loss: 2.552358921248417

Epoch: 6| Step: 9
Training loss: 2.3193555714629484
Validation loss: 2.5461813327255136

Epoch: 6| Step: 10
Training loss: 2.201095620351747
Validation loss: 2.5465609272962797

Epoch: 6| Step: 11
Training loss: 2.145913934274105
Validation loss: 2.5319667162543125

Epoch: 6| Step: 12
Training loss: 1.8822023028165775
Validation loss: 2.5456186952238915

Epoch: 6| Step: 13
Training loss: 1.6218349738501647
Validation loss: 2.5810701213658596

Epoch: 277| Step: 0
Training loss: 2.2808055706051142
Validation loss: 2.5394103296156794

Epoch: 6| Step: 1
Training loss: 1.832343036335614
Validation loss: 2.54891759488863

Epoch: 6| Step: 2
Training loss: 1.58655509762167
Validation loss: 2.5719551781555134

Epoch: 6| Step: 3
Training loss: 2.3015500194576326
Validation loss: 2.599558580658475

Epoch: 6| Step: 4
Training loss: 1.773208536164269
Validation loss: 2.6820674222274996

Epoch: 6| Step: 5
Training loss: 2.7053847376716873
Validation loss: 2.64048697507786

Epoch: 6| Step: 6
Training loss: 2.314435406709605
Validation loss: 2.7076520845501983

Epoch: 6| Step: 7
Training loss: 2.4379609479084383
Validation loss: 2.630027754725417

Epoch: 6| Step: 8
Training loss: 2.3247206202179758
Validation loss: 2.6069932678217675

Epoch: 6| Step: 9
Training loss: 1.648779955541938
Validation loss: 2.5771426708778007

Epoch: 6| Step: 10
Training loss: 1.826957394976435
Validation loss: 2.5456598733682547

Epoch: 6| Step: 11
Training loss: 1.8240455692270803
Validation loss: 2.513390917367097

Epoch: 6| Step: 12
Training loss: 1.7300729406558626
Validation loss: 2.4922443570753536

Epoch: 6| Step: 13
Training loss: 2.1641230936208924
Validation loss: 2.5078728372479313

Epoch: 278| Step: 0
Training loss: 2.7848382155650153
Validation loss: 2.495897949053127

Epoch: 6| Step: 1
Training loss: 2.0667011360657424
Validation loss: 2.472861781123165

Epoch: 6| Step: 2
Training loss: 1.458932163269456
Validation loss: 2.485738927685636

Epoch: 6| Step: 3
Training loss: 1.8939683844919581
Validation loss: 2.5104457858811995

Epoch: 6| Step: 4
Training loss: 1.9189665582077702
Validation loss: 2.5224564636324693

Epoch: 6| Step: 5
Training loss: 1.7843738402247626
Validation loss: 2.5265640872155313

Epoch: 6| Step: 6
Training loss: 1.809630786690192
Validation loss: 2.5535123340604353

Epoch: 6| Step: 7
Training loss: 2.6467358909541474
Validation loss: 2.5871527544774002

Epoch: 6| Step: 8
Training loss: 2.087630253000322
Validation loss: 2.5830265037278597

Epoch: 6| Step: 9
Training loss: 1.1200613125980567
Validation loss: 2.6131488213391965

Epoch: 6| Step: 10
Training loss: 2.304038884331485
Validation loss: 2.548065640535738

Epoch: 6| Step: 11
Training loss: 2.5449838930830673
Validation loss: 2.5491158236566633

Epoch: 6| Step: 12
Training loss: 2.567741429939041
Validation loss: 2.5225348418078717

Epoch: 6| Step: 13
Training loss: 1.7661535771555557
Validation loss: 2.5093721667662097

Epoch: 279| Step: 0
Training loss: 1.820123556260822
Validation loss: 2.518377878925722

Epoch: 6| Step: 1
Training loss: 1.990667623545644
Validation loss: 2.4996918965265347

Epoch: 6| Step: 2
Training loss: 1.8393318128165892
Validation loss: 2.5064555108468234

Epoch: 6| Step: 3
Training loss: 2.7283925907300053
Validation loss: 2.517013593049717

Epoch: 6| Step: 4
Training loss: 2.850218071876427
Validation loss: 2.5074003996104968

Epoch: 6| Step: 5
Training loss: 2.2220071873999268
Validation loss: 2.5860069396193115

Epoch: 6| Step: 6
Training loss: 1.6188393233115221
Validation loss: 2.6014753600104803

Epoch: 6| Step: 7
Training loss: 1.48469604232794
Validation loss: 2.6483703199660242

Epoch: 6| Step: 8
Training loss: 1.8332221546563183
Validation loss: 2.6566893270364536

Epoch: 6| Step: 9
Training loss: 2.2732581628283497
Validation loss: 2.629168742481829

Epoch: 6| Step: 10
Training loss: 2.1858202343149635
Validation loss: 2.5807785635081952

Epoch: 6| Step: 11
Training loss: 2.106173310737286
Validation loss: 2.5700200464280734

Epoch: 6| Step: 12
Training loss: 1.8792337302726303
Validation loss: 2.5505138060338126

Epoch: 6| Step: 13
Training loss: 1.7372136984762652
Validation loss: 2.528663789716164

Epoch: 280| Step: 0
Training loss: 2.430174947335727
Validation loss: 2.5305265640857395

Epoch: 6| Step: 1
Training loss: 1.5532515138489478
Validation loss: 2.5253634666483253

Epoch: 6| Step: 2
Training loss: 2.217355209147861
Validation loss: 2.5373031311210483

Epoch: 6| Step: 3
Training loss: 1.4109421333921275
Validation loss: 2.5650614597747903

Epoch: 6| Step: 4
Training loss: 1.2413315613102651
Validation loss: 2.566035181448064

Epoch: 6| Step: 5
Training loss: 1.5421658128877378
Validation loss: 2.573095081233548

Epoch: 6| Step: 6
Training loss: 2.3671212265758914
Validation loss: 2.6004267247629

Epoch: 6| Step: 7
Training loss: 2.3650470788636957
Validation loss: 2.594666881973255

Epoch: 6| Step: 8
Training loss: 2.822217979160967
Validation loss: 2.63378812709514

Epoch: 6| Step: 9
Training loss: 1.4579034807572488
Validation loss: 2.6055961246038843

Epoch: 6| Step: 10
Training loss: 1.931501948640785
Validation loss: 2.5739780558550054

Epoch: 6| Step: 11
Training loss: 1.9217832589931958
Validation loss: 2.5778006763875365

Epoch: 6| Step: 12
Training loss: 2.3725945186780306
Validation loss: 2.551913576254174

Epoch: 6| Step: 13
Training loss: 2.192940621897226
Validation loss: 2.54651750111079

Epoch: 281| Step: 0
Training loss: 1.3047695476750993
Validation loss: 2.5658282244008777

Epoch: 6| Step: 1
Training loss: 1.2982201092425067
Validation loss: 2.5915915995537695

Epoch: 6| Step: 2
Training loss: 2.066977870747038
Validation loss: 2.570212256922364

Epoch: 6| Step: 3
Training loss: 2.362886758461562
Validation loss: 2.559843205751482

Epoch: 6| Step: 4
Training loss: 1.5766626513364819
Validation loss: 2.5951352537576176

Epoch: 6| Step: 5
Training loss: 1.8346654502805477
Validation loss: 2.5507109760381423

Epoch: 6| Step: 6
Training loss: 1.8815782228987237
Validation loss: 2.565455476873015

Epoch: 6| Step: 7
Training loss: 2.2131739651321958
Validation loss: 2.558464540126125

Epoch: 6| Step: 8
Training loss: 2.720613389133922
Validation loss: 2.5879831357531264

Epoch: 6| Step: 9
Training loss: 1.9073251912622002
Validation loss: 2.611122886031455

Epoch: 6| Step: 10
Training loss: 2.5177909104159144
Validation loss: 2.595218901273678

Epoch: 6| Step: 11
Training loss: 1.9518634841974998
Validation loss: 2.5986648934137913

Epoch: 6| Step: 12
Training loss: 2.0933164460823215
Validation loss: 2.5762141534914087

Epoch: 6| Step: 13
Training loss: 1.786989702063776
Validation loss: 2.5753817982008633

Epoch: 282| Step: 0
Training loss: 2.0400735387450006
Validation loss: 2.5458799419309224

Epoch: 6| Step: 1
Training loss: 2.1887375736809727
Validation loss: 2.5322119921681785

Epoch: 6| Step: 2
Training loss: 1.7347698964936293
Validation loss: 2.538062171487182

Epoch: 6| Step: 3
Training loss: 2.6786881521314925
Validation loss: 2.534764083679204

Epoch: 6| Step: 4
Training loss: 1.3655712492466674
Validation loss: 2.5305493487902986

Epoch: 6| Step: 5
Training loss: 1.8217411574443176
Validation loss: 2.5412510130743113

Epoch: 6| Step: 6
Training loss: 2.4731079460367766
Validation loss: 2.548460250556477

Epoch: 6| Step: 7
Training loss: 2.5457989812636286
Validation loss: 2.5733848691467465

Epoch: 6| Step: 8
Training loss: 1.9311724674994477
Validation loss: 2.5817444103849425

Epoch: 6| Step: 9
Training loss: 2.2359103816298576
Validation loss: 2.6083785265418844

Epoch: 6| Step: 10
Training loss: 2.1570801173625767
Validation loss: 2.6157035150445345

Epoch: 6| Step: 11
Training loss: 1.6579061900566257
Validation loss: 2.602659771131673

Epoch: 6| Step: 12
Training loss: 2.316122259579485
Validation loss: 2.603203195997948

Epoch: 6| Step: 13
Training loss: 1.8069736812935864
Validation loss: 2.5540936447666094

Epoch: 283| Step: 0
Training loss: 1.4673594933592329
Validation loss: 2.5130269631951765

Epoch: 6| Step: 1
Training loss: 2.3487444749963085
Validation loss: 2.510425715344426

Epoch: 6| Step: 2
Training loss: 2.1342261244318794
Validation loss: 2.4882719557751756

Epoch: 6| Step: 3
Training loss: 1.9750794889654273
Validation loss: 2.4477846529379184

Epoch: 6| Step: 4
Training loss: 2.2473526320977815
Validation loss: 2.5100207722324877

Epoch: 6| Step: 5
Training loss: 1.4343383684654312
Validation loss: 2.5151182655502278

Epoch: 6| Step: 6
Training loss: 1.8625589886227076
Validation loss: 2.5328010547841378

Epoch: 6| Step: 7
Training loss: 2.774751593666571
Validation loss: 2.518037417244136

Epoch: 6| Step: 8
Training loss: 1.902288040504708
Validation loss: 2.497751575918359

Epoch: 6| Step: 9
Training loss: 2.086864936760936
Validation loss: 2.5446075768443084

Epoch: 6| Step: 10
Training loss: 1.844885912626884
Validation loss: 2.541948323720747

Epoch: 6| Step: 11
Training loss: 2.2206107919733955
Validation loss: 2.535491874120619

Epoch: 6| Step: 12
Training loss: 1.6517758667405615
Validation loss: 2.551083837440715

Epoch: 6| Step: 13
Training loss: 2.037126930578117
Validation loss: 2.563047660672248

Epoch: 284| Step: 0
Training loss: 1.7304533189210403
Validation loss: 2.529450204490186

Epoch: 6| Step: 1
Training loss: 1.212390741361117
Validation loss: 2.536707156364061

Epoch: 6| Step: 2
Training loss: 2.8597556939517323
Validation loss: 2.5427745426553656

Epoch: 6| Step: 3
Training loss: 1.4853016420461502
Validation loss: 2.554625600829028

Epoch: 6| Step: 4
Training loss: 2.3208553822244493
Validation loss: 2.571367381644461

Epoch: 6| Step: 5
Training loss: 2.5089539399098406
Validation loss: 2.5669635262498067

Epoch: 6| Step: 6
Training loss: 2.295916195001245
Validation loss: 2.592186575336226

Epoch: 6| Step: 7
Training loss: 1.793949366000626
Validation loss: 2.5670175970950755

Epoch: 6| Step: 8
Training loss: 1.9698042090662344
Validation loss: 2.5741410887700793

Epoch: 6| Step: 9
Training loss: 1.5962188148887617
Validation loss: 2.5438716631263523

Epoch: 6| Step: 10
Training loss: 2.2822465157116096
Validation loss: 2.546424115919158

Epoch: 6| Step: 11
Training loss: 2.2049649178272377
Validation loss: 2.5288900355008876

Epoch: 6| Step: 12
Training loss: 1.8314681824782477
Validation loss: 2.541134948039967

Epoch: 6| Step: 13
Training loss: 2.0761477593701736
Validation loss: 2.560665093938968

Epoch: 285| Step: 0
Training loss: 2.19958644794702
Validation loss: 2.570246431840791

Epoch: 6| Step: 1
Training loss: 1.7963050270014047
Validation loss: 2.5714758623911265

Epoch: 6| Step: 2
Training loss: 2.071231278292869
Validation loss: 2.6525158234081436

Epoch: 6| Step: 3
Training loss: 2.3643889046163595
Validation loss: 2.6387194316954106

Epoch: 6| Step: 4
Training loss: 1.6198282840756169
Validation loss: 2.637507952095085

Epoch: 6| Step: 5
Training loss: 1.3801617836449895
Validation loss: 2.6306527898457572

Epoch: 6| Step: 6
Training loss: 2.439127647609991
Validation loss: 2.569154024178622

Epoch: 6| Step: 7
Training loss: 2.216165676244768
Validation loss: 2.611190575434352

Epoch: 6| Step: 8
Training loss: 2.020262595000657
Validation loss: 2.5533824468683264

Epoch: 6| Step: 9
Training loss: 1.7510656109711542
Validation loss: 2.5577729517466494

Epoch: 6| Step: 10
Training loss: 2.5113264996738014
Validation loss: 2.5571931145370317

Epoch: 6| Step: 11
Training loss: 1.7261064712554273
Validation loss: 2.5172666480804224

Epoch: 6| Step: 12
Training loss: 2.184400487922987
Validation loss: 2.530615377736815

Epoch: 6| Step: 13
Training loss: 1.6697125576965606
Validation loss: 2.517450669255792

Epoch: 286| Step: 0
Training loss: 1.6514588640190584
Validation loss: 2.5247450866691703

Epoch: 6| Step: 1
Training loss: 1.6165832275147276
Validation loss: 2.527102081992428

Epoch: 6| Step: 2
Training loss: 1.6265393815243632
Validation loss: 2.532568380242927

Epoch: 6| Step: 3
Training loss: 2.7383155548515394
Validation loss: 2.523997674735903

Epoch: 6| Step: 4
Training loss: 2.7880355696796753
Validation loss: 2.5581678506800944

Epoch: 6| Step: 5
Training loss: 2.187019404342239
Validation loss: 2.552947887937228

Epoch: 6| Step: 6
Training loss: 1.9174016980533835
Validation loss: 2.531408877939917

Epoch: 6| Step: 7
Training loss: 1.8566434655146717
Validation loss: 2.572415559184187

Epoch: 6| Step: 8
Training loss: 1.9471221228154199
Validation loss: 2.5348560251486116

Epoch: 6| Step: 9
Training loss: 1.5811537581394992
Validation loss: 2.52880018701437

Epoch: 6| Step: 10
Training loss: 2.1534233916300307
Validation loss: 2.550280083128266

Epoch: 6| Step: 11
Training loss: 1.5776451816644723
Validation loss: 2.5403979501467004

Epoch: 6| Step: 12
Training loss: 2.213737305616086
Validation loss: 2.505616705292297

Epoch: 6| Step: 13
Training loss: 2.063154405755843
Validation loss: 2.5597989493139917

Epoch: 287| Step: 0
Training loss: 2.3555114641001693
Validation loss: 2.491846035292348

Epoch: 6| Step: 1
Training loss: 2.2703141718501887
Validation loss: 2.5185198505975697

Epoch: 6| Step: 2
Training loss: 1.9349741314482163
Validation loss: 2.5241486105446773

Epoch: 6| Step: 3
Training loss: 2.2140679186402688
Validation loss: 2.5173973805821928

Epoch: 6| Step: 4
Training loss: 1.7250197063923696
Validation loss: 2.529664693081238

Epoch: 6| Step: 5
Training loss: 1.504156711083996
Validation loss: 2.5596843617905582

Epoch: 6| Step: 6
Training loss: 1.9081670158351036
Validation loss: 2.548249160664668

Epoch: 6| Step: 7
Training loss: 1.7280923961026429
Validation loss: 2.5727713282587663

Epoch: 6| Step: 8
Training loss: 1.3849188070219682
Validation loss: 2.5828739855110046

Epoch: 6| Step: 9
Training loss: 2.087434267391122
Validation loss: 2.603981184393844

Epoch: 6| Step: 10
Training loss: 2.361284506420959
Validation loss: 2.5856144713895217

Epoch: 6| Step: 11
Training loss: 2.2789665185428154
Validation loss: 2.5870264225030564

Epoch: 6| Step: 12
Training loss: 1.8193317439900678
Validation loss: 2.62538808648357

Epoch: 6| Step: 13
Training loss: 1.7636972216435503
Validation loss: 2.6399912177045763

Epoch: 288| Step: 0
Training loss: 1.9223198724699528
Validation loss: 2.6159478739144393

Epoch: 6| Step: 1
Training loss: 1.8062782047801953
Validation loss: 2.592516701649716

Epoch: 6| Step: 2
Training loss: 2.3491316997103904
Validation loss: 2.572473199492828

Epoch: 6| Step: 3
Training loss: 1.7327436043034163
Validation loss: 2.564522526565299

Epoch: 6| Step: 4
Training loss: 2.2887534496004287
Validation loss: 2.5800215555862778

Epoch: 6| Step: 5
Training loss: 2.0413334503215324
Validation loss: 2.6168264415175555

Epoch: 6| Step: 6
Training loss: 1.819054492224398
Validation loss: 2.6231827879399674

Epoch: 6| Step: 7
Training loss: 2.1674284940582167
Validation loss: 2.6026322358267797

Epoch: 6| Step: 8
Training loss: 1.8655059137467893
Validation loss: 2.6031073259392477

Epoch: 6| Step: 9
Training loss: 2.1587514327529895
Validation loss: 2.6353303093513696

Epoch: 6| Step: 10
Training loss: 1.4989803345289234
Validation loss: 2.5638461415134715

Epoch: 6| Step: 11
Training loss: 1.9205305157307517
Validation loss: 2.5870926074034175

Epoch: 6| Step: 12
Training loss: 2.1856830135213348
Validation loss: 2.592482230193923

Epoch: 6| Step: 13
Training loss: 1.2384511066991652
Validation loss: 2.5619291274417457

Epoch: 289| Step: 0
Training loss: 1.9975984579177362
Validation loss: 2.5402347147620343

Epoch: 6| Step: 1
Training loss: 2.0873556852424233
Validation loss: 2.5481040968827826

Epoch: 6| Step: 2
Training loss: 2.078779533392059
Validation loss: 2.548705435926561

Epoch: 6| Step: 3
Training loss: 2.18123776670157
Validation loss: 2.569698333797807

Epoch: 6| Step: 4
Training loss: 1.9783306430754437
Validation loss: 2.5527476529527875

Epoch: 6| Step: 5
Training loss: 1.4252722262643622
Validation loss: 2.571309801542756

Epoch: 6| Step: 6
Training loss: 2.1300554166220325
Validation loss: 2.560770179755176

Epoch: 6| Step: 7
Training loss: 1.9381148070430556
Validation loss: 2.6109716590094174

Epoch: 6| Step: 8
Training loss: 2.6538509530456764
Validation loss: 2.5634632006100175

Epoch: 6| Step: 9
Training loss: 1.6880945641755016
Validation loss: 2.572676216246487

Epoch: 6| Step: 10
Training loss: 2.22198615674669
Validation loss: 2.5502940360567403

Epoch: 6| Step: 11
Training loss: 1.8093268142635228
Validation loss: 2.555623138842516

Epoch: 6| Step: 12
Training loss: 1.880718158558361
Validation loss: 2.570674171240261

Epoch: 6| Step: 13
Training loss: 1.7464320731901055
Validation loss: 2.5532703415875155

Epoch: 290| Step: 0
Training loss: 2.2550719633270986
Validation loss: 2.550702018344582

Epoch: 6| Step: 1
Training loss: 2.170435915816624
Validation loss: 2.592425839483247

Epoch: 6| Step: 2
Training loss: 1.4292980560022621
Validation loss: 2.587215096457487

Epoch: 6| Step: 3
Training loss: 1.7952645424064053
Validation loss: 2.5534007947200275

Epoch: 6| Step: 4
Training loss: 2.887083616414063
Validation loss: 2.5580184328530073

Epoch: 6| Step: 5
Training loss: 1.3354016841260212
Validation loss: 2.5694355497693135

Epoch: 6| Step: 6
Training loss: 1.7371032152008787
Validation loss: 2.538150705800551

Epoch: 6| Step: 7
Training loss: 2.254032547980609
Validation loss: 2.534407792700401

Epoch: 6| Step: 8
Training loss: 1.7590659186810649
Validation loss: 2.5666214742851663

Epoch: 6| Step: 9
Training loss: 1.5602755925469949
Validation loss: 2.5139307354651743

Epoch: 6| Step: 10
Training loss: 1.3103877282194485
Validation loss: 2.5796997655357052

Epoch: 6| Step: 11
Training loss: 2.842403721986412
Validation loss: 2.5807155348298734

Epoch: 6| Step: 12
Training loss: 1.5640274211596816
Validation loss: 2.5605279963980943

Epoch: 6| Step: 13
Training loss: 1.8042154066213907
Validation loss: 2.571344031415105

Epoch: 291| Step: 0
Training loss: 1.9673701703716224
Validation loss: 2.5341860144504955

Epoch: 6| Step: 1
Training loss: 2.215845059979146
Validation loss: 2.5633645498841204

Epoch: 6| Step: 2
Training loss: 2.1649746401316876
Validation loss: 2.5626986434360934

Epoch: 6| Step: 3
Training loss: 2.022626559679432
Validation loss: 2.5565620567658054

Epoch: 6| Step: 4
Training loss: 2.133052826360938
Validation loss: 2.578798194616108

Epoch: 6| Step: 5
Training loss: 1.6002062753986042
Validation loss: 2.6091292640574313

Epoch: 6| Step: 6
Training loss: 1.911286002419427
Validation loss: 2.6523939679447657

Epoch: 6| Step: 7
Training loss: 1.9173568091213191
Validation loss: 2.6728268539630227

Epoch: 6| Step: 8
Training loss: 1.7677695829277595
Validation loss: 2.681337802993575

Epoch: 6| Step: 9
Training loss: 2.196177139246063
Validation loss: 2.6323929479749055

Epoch: 6| Step: 10
Training loss: 1.8683998928186822
Validation loss: 2.5775152545012583

Epoch: 6| Step: 11
Training loss: 2.143515980573079
Validation loss: 2.551165409184104

Epoch: 6| Step: 12
Training loss: 2.136507627109775
Validation loss: 2.505373853474898

Epoch: 6| Step: 13
Training loss: 1.8261943305771777
Validation loss: 2.510596159431512

Epoch: 292| Step: 0
Training loss: 1.824112948304462
Validation loss: 2.484343970402887

Epoch: 6| Step: 1
Training loss: 1.795207834139303
Validation loss: 2.5091526178401455

Epoch: 6| Step: 2
Training loss: 2.1679328984225936
Validation loss: 2.4938447199705585

Epoch: 6| Step: 3
Training loss: 2.2924546245381623
Validation loss: 2.524814698372649

Epoch: 6| Step: 4
Training loss: 1.878004337439845
Validation loss: 2.53941796577766

Epoch: 6| Step: 5
Training loss: 1.5135988673169614
Validation loss: 2.5421554741603565

Epoch: 6| Step: 6
Training loss: 2.4904873109902836
Validation loss: 2.5831390482128795

Epoch: 6| Step: 7
Training loss: 1.6913364739594994
Validation loss: 2.601588572695106

Epoch: 6| Step: 8
Training loss: 2.0462492940129
Validation loss: 2.6295521940651154

Epoch: 6| Step: 9
Training loss: 2.3571180449661986
Validation loss: 2.619813017761309

Epoch: 6| Step: 10
Training loss: 2.3135027386789497
Validation loss: 2.6095552134766424

Epoch: 6| Step: 11
Training loss: 1.682627389514922
Validation loss: 2.589229965549391

Epoch: 6| Step: 12
Training loss: 1.6626473440400134
Validation loss: 2.582888339283679

Epoch: 6| Step: 13
Training loss: 1.7523003173561378
Validation loss: 2.579049470628916

Epoch: 293| Step: 0
Training loss: 2.488276075899742
Validation loss: 2.556649188869307

Epoch: 6| Step: 1
Training loss: 1.8458539951565907
Validation loss: 2.5562638252089633

Epoch: 6| Step: 2
Training loss: 1.2896516782843244
Validation loss: 2.588411037492944

Epoch: 6| Step: 3
Training loss: 2.0944048867957656
Validation loss: 2.542616671845662

Epoch: 6| Step: 4
Training loss: 1.7182225892017282
Validation loss: 2.599894434668705

Epoch: 6| Step: 5
Training loss: 1.8590336333993163
Validation loss: 2.5493243868287108

Epoch: 6| Step: 6
Training loss: 1.8593540350749864
Validation loss: 2.5309851708039917

Epoch: 6| Step: 7
Training loss: 2.31762107656295
Validation loss: 2.5576571781488386

Epoch: 6| Step: 8
Training loss: 1.5596330662321796
Validation loss: 2.530519018864409

Epoch: 6| Step: 9
Training loss: 1.8168159925118923
Validation loss: 2.576993027145353

Epoch: 6| Step: 10
Training loss: 2.1875652848447205
Validation loss: 2.5750402472106804

Epoch: 6| Step: 11
Training loss: 2.2309260926634287
Validation loss: 2.5942009683169736

Epoch: 6| Step: 12
Training loss: 1.8825199010640556
Validation loss: 2.5823773543121242

Epoch: 6| Step: 13
Training loss: 1.7163731873513601
Validation loss: 2.5915854894143613

Epoch: 294| Step: 0
Training loss: 2.4435200809897086
Validation loss: 2.6151804957633695

Epoch: 6| Step: 1
Training loss: 2.108149419711534
Validation loss: 2.595241562043987

Epoch: 6| Step: 2
Training loss: 1.8212780663206922
Validation loss: 2.5901710606450132

Epoch: 6| Step: 3
Training loss: 2.4130653865221614
Validation loss: 2.59328251957654

Epoch: 6| Step: 4
Training loss: 2.0317673244476984
Validation loss: 2.6444304318840386

Epoch: 6| Step: 5
Training loss: 1.4957268566322124
Validation loss: 2.6233011833977278

Epoch: 6| Step: 6
Training loss: 1.730806959181165
Validation loss: 2.6371394973184983

Epoch: 6| Step: 7
Training loss: 1.6430368769402577
Validation loss: 2.590657945767794

Epoch: 6| Step: 8
Training loss: 2.728330896741944
Validation loss: 2.5502961239255684

Epoch: 6| Step: 9
Training loss: 1.6923360405394925
Validation loss: 2.5380015968947

Epoch: 6| Step: 10
Training loss: 1.6783838935491981
Validation loss: 2.5338713333996354

Epoch: 6| Step: 11
Training loss: 1.5706290310353694
Validation loss: 2.5109800970123524

Epoch: 6| Step: 12
Training loss: 1.7775583661633132
Validation loss: 2.530989755195533

Epoch: 6| Step: 13
Training loss: 2.2370066050814374
Validation loss: 2.4982260211557406

Epoch: 295| Step: 0
Training loss: 2.0016927707991137
Validation loss: 2.5579074861401407

Epoch: 6| Step: 1
Training loss: 1.8439864314153112
Validation loss: 2.527205371556858

Epoch: 6| Step: 2
Training loss: 2.074095296688089
Validation loss: 2.5327000330422136

Epoch: 6| Step: 3
Training loss: 2.1860913782173004
Validation loss: 2.561080702384857

Epoch: 6| Step: 4
Training loss: 1.5477627605392201
Validation loss: 2.6043106090182944

Epoch: 6| Step: 5
Training loss: 1.5139556815591062
Validation loss: 2.6648861384685443

Epoch: 6| Step: 6
Training loss: 1.9358123073785314
Validation loss: 2.6872994695561454

Epoch: 6| Step: 7
Training loss: 2.615729720230918
Validation loss: 2.6948261135412834

Epoch: 6| Step: 8
Training loss: 1.63052872829402
Validation loss: 2.7139358429462357

Epoch: 6| Step: 9
Training loss: 1.9323049238080925
Validation loss: 2.7083440095739966

Epoch: 6| Step: 10
Training loss: 1.827783405961348
Validation loss: 2.6509012860875694

Epoch: 6| Step: 11
Training loss: 1.677489790224481
Validation loss: 2.6096621905447748

Epoch: 6| Step: 12
Training loss: 2.3280856750034458
Validation loss: 2.5581080706163797

Epoch: 6| Step: 13
Training loss: 2.273375729904775
Validation loss: 2.51846319226921

Epoch: 296| Step: 0
Training loss: 1.7818159576235815
Validation loss: 2.5189939571649878

Epoch: 6| Step: 1
Training loss: 1.703274151631811
Validation loss: 2.4891422524759235

Epoch: 6| Step: 2
Training loss: 2.2490544981639884
Validation loss: 2.5111282943974125

Epoch: 6| Step: 3
Training loss: 2.3095096120458827
Validation loss: 2.4956232860319507

Epoch: 6| Step: 4
Training loss: 1.4071239722591165
Validation loss: 2.498446029257276

Epoch: 6| Step: 5
Training loss: 1.887877304058567
Validation loss: 2.509400084082368

Epoch: 6| Step: 6
Training loss: 1.9546816306632129
Validation loss: 2.540362200531395

Epoch: 6| Step: 7
Training loss: 2.4838640179355083
Validation loss: 2.5712332578814685

Epoch: 6| Step: 8
Training loss: 1.7708016187034432
Validation loss: 2.602032348850044

Epoch: 6| Step: 9
Training loss: 1.5215859923994552
Validation loss: 2.633549648365662

Epoch: 6| Step: 10
Training loss: 2.7902156038279062
Validation loss: 2.6456886962845627

Epoch: 6| Step: 11
Training loss: 1.6855765789858046
Validation loss: 2.6655519410616324

Epoch: 6| Step: 12
Training loss: 2.2690980796614526
Validation loss: 2.6512782073150336

Epoch: 6| Step: 13
Training loss: 1.4682881055109422
Validation loss: 2.6151036711079922

Epoch: 297| Step: 0
Training loss: 1.7232345337034636
Validation loss: 2.588362280132534

Epoch: 6| Step: 1
Training loss: 2.1779881350892056
Validation loss: 2.537574402418348

Epoch: 6| Step: 2
Training loss: 1.8343132463552658
Validation loss: 2.5658640141112175

Epoch: 6| Step: 3
Training loss: 2.0172840949229007
Validation loss: 2.536118280278305

Epoch: 6| Step: 4
Training loss: 1.2859521505788973
Validation loss: 2.5552867221640025

Epoch: 6| Step: 5
Training loss: 2.712671610242318
Validation loss: 2.5069561344859252

Epoch: 6| Step: 6
Training loss: 2.2060391246961015
Validation loss: 2.5374180872933234

Epoch: 6| Step: 7
Training loss: 2.1924645899280515
Validation loss: 2.5291860352412945

Epoch: 6| Step: 8
Training loss: 1.6090963177915796
Validation loss: 2.564707960069871

Epoch: 6| Step: 9
Training loss: 1.9787420988617954
Validation loss: 2.5540484796740786

Epoch: 6| Step: 10
Training loss: 2.2247385149975547
Validation loss: 2.607334427909

Epoch: 6| Step: 11
Training loss: 1.4933076019851799
Validation loss: 2.613936391077434

Epoch: 6| Step: 12
Training loss: 1.8757808331000942
Validation loss: 2.642300031248169

Epoch: 6| Step: 13
Training loss: 1.7983579404253396
Validation loss: 2.64955030260425

Epoch: 298| Step: 0
Training loss: 1.568620823864869
Validation loss: 2.6405644682618252

Epoch: 6| Step: 1
Training loss: 1.8473039416192907
Validation loss: 2.6449014769859467

Epoch: 6| Step: 2
Training loss: 1.9961065303146999
Validation loss: 2.598641742593951

Epoch: 6| Step: 3
Training loss: 2.0774096641685196
Validation loss: 2.5556740911838722

Epoch: 6| Step: 4
Training loss: 2.221520534306285
Validation loss: 2.5380816007672244

Epoch: 6| Step: 5
Training loss: 2.373107055403323
Validation loss: 2.5295563278763233

Epoch: 6| Step: 6
Training loss: 1.9190634654703773
Validation loss: 2.5578932873476186

Epoch: 6| Step: 7
Training loss: 1.543052110955237
Validation loss: 2.5097762645688877

Epoch: 6| Step: 8
Training loss: 1.6072120575917284
Validation loss: 2.516041675755145

Epoch: 6| Step: 9
Training loss: 2.4215697065328126
Validation loss: 2.5405406620405557

Epoch: 6| Step: 10
Training loss: 1.971860336031549
Validation loss: 2.555469062857248

Epoch: 6| Step: 11
Training loss: 1.8648364216756799
Validation loss: 2.5685664297752147

Epoch: 6| Step: 12
Training loss: 1.5859780893628275
Validation loss: 2.6226844111099092

Epoch: 6| Step: 13
Training loss: 1.3987385516341633
Validation loss: 2.63841631461438

Epoch: 299| Step: 0
Training loss: 1.6556837445468826
Validation loss: 2.598768786676981

Epoch: 6| Step: 1
Training loss: 1.7734252660388183
Validation loss: 2.5988374782638393

Epoch: 6| Step: 2
Training loss: 1.923347529298874
Validation loss: 2.5927714757917877

Epoch: 6| Step: 3
Training loss: 2.1845169436024032
Validation loss: 2.632967218971302

Epoch: 6| Step: 4
Training loss: 1.7596519509709607
Validation loss: 2.580039683192044

Epoch: 6| Step: 5
Training loss: 3.061048825602056
Validation loss: 2.6110833185714344

Epoch: 6| Step: 6
Training loss: 1.7333416308913554
Validation loss: 2.561335136074694

Epoch: 6| Step: 7
Training loss: 1.26314079527721
Validation loss: 2.549614386760356

Epoch: 6| Step: 8
Training loss: 1.698782538185888
Validation loss: 2.5426706743922236

Epoch: 6| Step: 9
Training loss: 1.93526471311069
Validation loss: 2.590834330839462

Epoch: 6| Step: 10
Training loss: 2.0267794196653477
Validation loss: 2.5719228104280045

Epoch: 6| Step: 11
Training loss: 1.428256543401402
Validation loss: 2.5667600653940754

Epoch: 6| Step: 12
Training loss: 1.9840872848868527
Validation loss: 2.625486798032096

Epoch: 6| Step: 13
Training loss: 1.4163166436510615
Validation loss: 2.532652540919444

Epoch: 300| Step: 0
Training loss: 2.1389059696368706
Validation loss: 2.571762572589455

Epoch: 6| Step: 1
Training loss: 2.3179446896396203
Validation loss: 2.567611914340358

Epoch: 6| Step: 2
Training loss: 1.5447850606840967
Validation loss: 2.626468913513726

Epoch: 6| Step: 3
Training loss: 1.4641674057088923
Validation loss: 2.577039362892847

Epoch: 6| Step: 4
Training loss: 2.0566760981182237
Validation loss: 2.576507785540815

Epoch: 6| Step: 5
Training loss: 2.1197379540489076
Validation loss: 2.582739336162556

Epoch: 6| Step: 6
Training loss: 1.6472876999813997
Validation loss: 2.5786135432199813

Epoch: 6| Step: 7
Training loss: 2.1587979286762087
Validation loss: 2.604998331148732

Epoch: 6| Step: 8
Training loss: 1.788919634716064
Validation loss: 2.5989971323627397

Epoch: 6| Step: 9
Training loss: 1.6322701023270272
Validation loss: 2.599370344041178

Epoch: 6| Step: 10
Training loss: 1.5568037342497214
Validation loss: 2.5836115246363107

Epoch: 6| Step: 11
Training loss: 1.8598863555686658
Validation loss: 2.5734023023250794

Epoch: 6| Step: 12
Training loss: 1.6729583082641915
Validation loss: 2.6310686171256883

Epoch: 6| Step: 13
Training loss: 2.1088391789074663
Validation loss: 2.5630718461523108

Testing loss: 2.100637630439789
