Epoch: 1| Step: 0
Training loss: 5.996950646222016
Validation loss: 5.891862949984749

Epoch: 6| Step: 1
Training loss: 6.087528123731878
Validation loss: 5.889892586558182

Epoch: 6| Step: 2
Training loss: 5.590312903420908
Validation loss: 5.888057699064179

Epoch: 6| Step: 3
Training loss: 6.029297824040256
Validation loss: 5.886063702780294

Epoch: 6| Step: 4
Training loss: 6.2140420699940755
Validation loss: 5.884108064268998

Epoch: 6| Step: 5
Training loss: 6.506770495904782
Validation loss: 5.882138210659534

Epoch: 6| Step: 6
Training loss: 6.262389148941736
Validation loss: 5.880259330895533

Epoch: 6| Step: 7
Training loss: 5.45119374351803
Validation loss: 5.878239110731041

Epoch: 6| Step: 8
Training loss: 5.665514697996369
Validation loss: 5.87625168256716

Epoch: 6| Step: 9
Training loss: 6.262994608886971
Validation loss: 5.874330874816891

Epoch: 6| Step: 10
Training loss: 5.767852270300594
Validation loss: 5.872239648020591

Epoch: 6| Step: 11
Training loss: 6.69370274460298
Validation loss: 5.870138849135849

Epoch: 6| Step: 12
Training loss: 5.456743236851968
Validation loss: 5.867958610782219

Epoch: 6| Step: 13
Training loss: 5.802523675596626
Validation loss: 5.865694400388307

Epoch: 2| Step: 0
Training loss: 7.325600911252093
Validation loss: 5.863359051348546

Epoch: 6| Step: 1
Training loss: 6.77795048616975
Validation loss: 5.860894985141388

Epoch: 6| Step: 2
Training loss: 6.069354085979503
Validation loss: 5.858326756277865

Epoch: 6| Step: 3
Training loss: 6.46769550961377
Validation loss: 5.855679172961934

Epoch: 6| Step: 4
Training loss: 6.336496801184846
Validation loss: 5.852884724673932

Epoch: 6| Step: 5
Training loss: 5.228778454883035
Validation loss: 5.849867367667349

Epoch: 6| Step: 6
Training loss: 6.263593920040316
Validation loss: 5.846968446219635

Epoch: 6| Step: 7
Training loss: 5.712497983301921
Validation loss: 5.843793627462202

Epoch: 6| Step: 8
Training loss: 4.971367104781433
Validation loss: 5.840682069279536

Epoch: 6| Step: 9
Training loss: 5.249809988307203
Validation loss: 5.837241017425608

Epoch: 6| Step: 10
Training loss: 6.263192558445726
Validation loss: 5.833800905652785

Epoch: 6| Step: 11
Training loss: 5.091908127740293
Validation loss: 5.830212339457006

Epoch: 6| Step: 12
Training loss: 5.907143822908941
Validation loss: 5.826165272914323

Epoch: 6| Step: 13
Training loss: 5.2706494003992255
Validation loss: 5.822319405030187

Epoch: 3| Step: 0
Training loss: 6.447388100926965
Validation loss: 5.818044226457235

Epoch: 6| Step: 1
Training loss: 5.52668686053579
Validation loss: 5.813411682166724

Epoch: 6| Step: 2
Training loss: 5.9916151586590285
Validation loss: 5.808899943856776

Epoch: 6| Step: 3
Training loss: 6.002323972129982
Validation loss: 5.803992413353513

Epoch: 6| Step: 4
Training loss: 5.783370995009569
Validation loss: 5.798862003627037

Epoch: 6| Step: 5
Training loss: 5.701768353196719
Validation loss: 5.793798900344387

Epoch: 6| Step: 6
Training loss: 6.898880699151352
Validation loss: 5.788012149744435

Epoch: 6| Step: 7
Training loss: 4.98756349757414
Validation loss: 5.782132797885467

Epoch: 6| Step: 8
Training loss: 5.188335856923046
Validation loss: 5.7762214579919595

Epoch: 6| Step: 9
Training loss: 6.117218368277002
Validation loss: 5.76957601720565

Epoch: 6| Step: 10
Training loss: 5.423511620896737
Validation loss: 5.763120057127652

Epoch: 6| Step: 11
Training loss: 5.176874147585723
Validation loss: 5.75624384015113

Epoch: 6| Step: 12
Training loss: 6.0263873643773795
Validation loss: 5.749383893384005

Epoch: 6| Step: 13
Training loss: 6.910315788329329
Validation loss: 5.74202706249082

Epoch: 4| Step: 0
Training loss: 6.0429460245209405
Validation loss: 5.734456656807488

Epoch: 6| Step: 1
Training loss: 6.781416508612434
Validation loss: 5.726640882038041

Epoch: 6| Step: 2
Training loss: 6.652481373356228
Validation loss: 5.718462799587216

Epoch: 6| Step: 3
Training loss: 4.859115544595788
Validation loss: 5.710099645436621

Epoch: 6| Step: 4
Training loss: 4.369710503947105
Validation loss: 5.701349576049687

Epoch: 6| Step: 5
Training loss: 5.29080509571001
Validation loss: 5.692776422771072

Epoch: 6| Step: 6
Training loss: 5.343140684491433
Validation loss: 5.684420551930524

Epoch: 6| Step: 7
Training loss: 5.901577509102737
Validation loss: 5.675520132822733

Epoch: 6| Step: 8
Training loss: 6.876895157825132
Validation loss: 5.666787183639406

Epoch: 6| Step: 9
Training loss: 6.077076485618767
Validation loss: 5.657414212904631

Epoch: 6| Step: 10
Training loss: 5.39778594792795
Validation loss: 5.64830920934192

Epoch: 6| Step: 11
Training loss: 5.1812161912723855
Validation loss: 5.6390375807794575

Epoch: 6| Step: 12
Training loss: 5.689129606425832
Validation loss: 5.629567135962201

Epoch: 6| Step: 13
Training loss: 6.0678492277320375
Validation loss: 5.620079742580877

Epoch: 5| Step: 0
Training loss: 5.35342388220597
Validation loss: 5.611091712355785

Epoch: 6| Step: 1
Training loss: 5.899484139859609
Validation loss: 5.601257883441068

Epoch: 6| Step: 2
Training loss: 6.333143867201801
Validation loss: 5.592099761487776

Epoch: 6| Step: 3
Training loss: 4.690568860332455
Validation loss: 5.582713828187772

Epoch: 6| Step: 4
Training loss: 5.606575524991315
Validation loss: 5.574014354755308

Epoch: 6| Step: 5
Training loss: 5.620687060459443
Validation loss: 5.564765468841033

Epoch: 6| Step: 6
Training loss: 6.197925454355202
Validation loss: 5.556008855552198

Epoch: 6| Step: 7
Training loss: 5.905346029222463
Validation loss: 5.54732715751733

Epoch: 6| Step: 8
Training loss: 5.34462333815106
Validation loss: 5.538863292819031

Epoch: 6| Step: 9
Training loss: 5.767578455701819
Validation loss: 5.530545148462355

Epoch: 6| Step: 10
Training loss: 5.967003052391217
Validation loss: 5.522074357186693

Epoch: 6| Step: 11
Training loss: 5.8863027080088655
Validation loss: 5.513982137323429

Epoch: 6| Step: 12
Training loss: 5.388515424513937
Validation loss: 5.506196086502694

Epoch: 6| Step: 13
Training loss: 5.24856402422665
Validation loss: 5.4982752263025505

Epoch: 6| Step: 0
Training loss: 5.998237032967446
Validation loss: 5.4911836997386745

Epoch: 6| Step: 1
Training loss: 5.641612296732258
Validation loss: 5.483769310003559

Epoch: 6| Step: 2
Training loss: 4.623561119806774
Validation loss: 5.475968427085464

Epoch: 6| Step: 3
Training loss: 5.131154528530036
Validation loss: 5.469188229395655

Epoch: 6| Step: 4
Training loss: 4.116656795803905
Validation loss: 5.461960652579692

Epoch: 6| Step: 5
Training loss: 5.904882202007088
Validation loss: 5.455408064710331

Epoch: 6| Step: 6
Training loss: 5.545424408695749
Validation loss: 5.448725137720213

Epoch: 6| Step: 7
Training loss: 5.709840932791666
Validation loss: 5.441525135078859

Epoch: 6| Step: 8
Training loss: 6.710768105763746
Validation loss: 5.434605087255842

Epoch: 6| Step: 9
Training loss: 5.0925081763672395
Validation loss: 5.427461587777863

Epoch: 6| Step: 10
Training loss: 5.811466576373863
Validation loss: 5.420824489640047

Epoch: 6| Step: 11
Training loss: 5.558061693560869
Validation loss: 5.413697421713255

Epoch: 6| Step: 12
Training loss: 5.932127117747333
Validation loss: 5.406788470255989

Epoch: 6| Step: 13
Training loss: 5.675055334686862
Validation loss: 5.399956069579217

Epoch: 7| Step: 0
Training loss: 5.98952013949906
Validation loss: 5.392834462142499

Epoch: 6| Step: 1
Training loss: 5.293867399496991
Validation loss: 5.3857174266108805

Epoch: 6| Step: 2
Training loss: 5.434476165093085
Validation loss: 5.3789495698638365

Epoch: 6| Step: 3
Training loss: 6.065396275794507
Validation loss: 5.371773335321641

Epoch: 6| Step: 4
Training loss: 5.373851564720451
Validation loss: 5.36487341037897

Epoch: 6| Step: 5
Training loss: 5.038698546994586
Validation loss: 5.357365920251755

Epoch: 6| Step: 6
Training loss: 6.099894863535879
Validation loss: 5.350361442834467

Epoch: 6| Step: 7
Training loss: 5.2919654261237445
Validation loss: 5.34281850805222

Epoch: 6| Step: 8
Training loss: 5.475907007624613
Validation loss: 5.335503504219105

Epoch: 6| Step: 9
Training loss: 5.106419072801439
Validation loss: 5.328116468197134

Epoch: 6| Step: 10
Training loss: 4.81649376757977
Validation loss: 5.320569809392473

Epoch: 6| Step: 11
Training loss: 5.964277738985158
Validation loss: 5.313329773969108

Epoch: 6| Step: 12
Training loss: 5.009460082970617
Validation loss: 5.306030822468831

Epoch: 6| Step: 13
Training loss: 5.395455758374465
Validation loss: 5.299063771406629

Epoch: 8| Step: 0
Training loss: 5.856180444261597
Validation loss: 5.291564529915077

Epoch: 6| Step: 1
Training loss: 4.376079317200465
Validation loss: 5.28439899290997

Epoch: 6| Step: 2
Training loss: 6.055279393951889
Validation loss: 5.2770504478195965

Epoch: 6| Step: 3
Training loss: 4.959445518756671
Validation loss: 5.270116322516652

Epoch: 6| Step: 4
Training loss: 5.094970369711418
Validation loss: 5.2635162085148925

Epoch: 6| Step: 5
Training loss: 5.787837054528694
Validation loss: 5.256195469655427

Epoch: 6| Step: 6
Training loss: 5.8650896611559515
Validation loss: 5.249440496391654

Epoch: 6| Step: 7
Training loss: 5.258628475815274
Validation loss: 5.242366145312026

Epoch: 6| Step: 8
Training loss: 5.48259321433588
Validation loss: 5.235316648285619

Epoch: 6| Step: 9
Training loss: 5.328363944594044
Validation loss: 5.2285361752102055

Epoch: 6| Step: 10
Training loss: 5.485157272323558
Validation loss: 5.22182457787494

Epoch: 6| Step: 11
Training loss: 4.66618751154991
Validation loss: 5.2149906285397725

Epoch: 6| Step: 12
Training loss: 5.225462109148854
Validation loss: 5.208519263445602

Epoch: 6| Step: 13
Training loss: 5.46350316802923
Validation loss: 5.201218080906288

Epoch: 9| Step: 0
Training loss: 4.178152326495926
Validation loss: 5.194810610743585

Epoch: 6| Step: 1
Training loss: 6.107384711171706
Validation loss: 5.1883395944164

Epoch: 6| Step: 2
Training loss: 4.720724943060876
Validation loss: 5.182163910433204

Epoch: 6| Step: 3
Training loss: 5.261382706070366
Validation loss: 5.17544675118005

Epoch: 6| Step: 4
Training loss: 5.8189966135180695
Validation loss: 5.169548994470768

Epoch: 6| Step: 5
Training loss: 5.583644156083693
Validation loss: 5.163309308795107

Epoch: 6| Step: 6
Training loss: 5.111348835396999
Validation loss: 5.157021482146625

Epoch: 6| Step: 7
Training loss: 4.971178720801085
Validation loss: 5.151091767913761

Epoch: 6| Step: 8
Training loss: 5.774455268567039
Validation loss: 5.144982621559325

Epoch: 6| Step: 9
Training loss: 4.430797404215976
Validation loss: 5.138964878700358

Epoch: 6| Step: 10
Training loss: 5.115842686182845
Validation loss: 5.132828819368955

Epoch: 6| Step: 11
Training loss: 5.058994916525385
Validation loss: 5.12771525213425

Epoch: 6| Step: 12
Training loss: 6.415898198601987
Validation loss: 5.12160218035719

Epoch: 6| Step: 13
Training loss: 4.869245605316349
Validation loss: 5.11572828769207

Epoch: 10| Step: 0
Training loss: 4.9109868793875435
Validation loss: 5.110026280135866

Epoch: 6| Step: 1
Training loss: 5.116257258302194
Validation loss: 5.104265681753124

Epoch: 6| Step: 2
Training loss: 4.737492608137579
Validation loss: 5.098672465908338

Epoch: 6| Step: 3
Training loss: 5.453566743725751
Validation loss: 5.0936627214751535

Epoch: 6| Step: 4
Training loss: 5.107657140852924
Validation loss: 5.087464274812901

Epoch: 6| Step: 5
Training loss: 5.831706156168582
Validation loss: 5.08239791685038

Epoch: 6| Step: 6
Training loss: 5.300107076750847
Validation loss: 5.076603869982586

Epoch: 6| Step: 7
Training loss: 5.413029471702831
Validation loss: 5.07136807575129

Epoch: 6| Step: 8
Training loss: 5.440029914998099
Validation loss: 5.064953025256102

Epoch: 6| Step: 9
Training loss: 4.714553280458006
Validation loss: 5.059633047596894

Epoch: 6| Step: 10
Training loss: 5.454585800599667
Validation loss: 5.054559579259424

Epoch: 6| Step: 11
Training loss: 5.067969111299509
Validation loss: 5.048372879016163

Epoch: 6| Step: 12
Training loss: 5.122127565367583
Validation loss: 5.0423104476794345

Epoch: 6| Step: 13
Training loss: 4.991775233001446
Validation loss: 5.036624478345021

Epoch: 11| Step: 0
Training loss: 5.16518834201818
Validation loss: 5.030996786186411

Epoch: 6| Step: 1
Training loss: 4.648001308972803
Validation loss: 5.0256461453998105

Epoch: 6| Step: 2
Training loss: 5.95692686896255
Validation loss: 5.0202476613630225

Epoch: 6| Step: 3
Training loss: 4.784391081999118
Validation loss: 5.014346521309292

Epoch: 6| Step: 4
Training loss: 4.741390657799992
Validation loss: 5.008792775302045

Epoch: 6| Step: 5
Training loss: 4.4389723363445315
Validation loss: 5.002974324893179

Epoch: 6| Step: 6
Training loss: 5.471474453891287
Validation loss: 4.997374576472373

Epoch: 6| Step: 7
Training loss: 5.852559186855314
Validation loss: 4.991628123003493

Epoch: 6| Step: 8
Training loss: 5.6423273027499405
Validation loss: 4.985963765514197

Epoch: 6| Step: 9
Training loss: 5.503979370411203
Validation loss: 4.979817665776027

Epoch: 6| Step: 10
Training loss: 3.306278648324459
Validation loss: 4.9740968801432635

Epoch: 6| Step: 11
Training loss: 5.460528837311041
Validation loss: 4.968575560508687

Epoch: 6| Step: 12
Training loss: 5.186481789543995
Validation loss: 4.962682574266305

Epoch: 6| Step: 13
Training loss: 4.917879935531442
Validation loss: 4.9567935166142725

Epoch: 12| Step: 0
Training loss: 5.3380017511530005
Validation loss: 4.951111521657139

Epoch: 6| Step: 1
Training loss: 5.345476551989644
Validation loss: 4.946074882507089

Epoch: 6| Step: 2
Training loss: 5.1641605616044
Validation loss: 4.939562113424174

Epoch: 6| Step: 3
Training loss: 3.6559888958418014
Validation loss: 4.933704994137494

Epoch: 6| Step: 4
Training loss: 5.134715663685713
Validation loss: 4.928153837769095

Epoch: 6| Step: 5
Training loss: 4.197665955635067
Validation loss: 4.92278902154985

Epoch: 6| Step: 6
Training loss: 4.654810740621563
Validation loss: 4.917377237385296

Epoch: 6| Step: 7
Training loss: 4.971799670307516
Validation loss: 4.911837399020834

Epoch: 6| Step: 8
Training loss: 5.529329817932155
Validation loss: 4.905593439380467

Epoch: 6| Step: 9
Training loss: 4.89000797949766
Validation loss: 4.899418507022019

Epoch: 6| Step: 10
Training loss: 5.376951706093165
Validation loss: 4.893510611092078

Epoch: 6| Step: 11
Training loss: 4.68325878278556
Validation loss: 4.8867095288525855

Epoch: 6| Step: 12
Training loss: 5.45535993274959
Validation loss: 4.8803875488899475

Epoch: 6| Step: 13
Training loss: 5.725296026180859
Validation loss: 4.873050821693876

Epoch: 13| Step: 0
Training loss: 5.143444459167515
Validation loss: 4.867122055764874

Epoch: 6| Step: 1
Training loss: 4.7935602620559505
Validation loss: 4.860644829805955

Epoch: 6| Step: 2
Training loss: 4.6415961177448075
Validation loss: 4.853946085926603

Epoch: 6| Step: 3
Training loss: 5.082910530559231
Validation loss: 4.8486523666576575

Epoch: 6| Step: 4
Training loss: 5.086016629448757
Validation loss: 4.840832395566085

Epoch: 6| Step: 5
Training loss: 4.948034323916347
Validation loss: 4.835271654936301

Epoch: 6| Step: 6
Training loss: 5.682242845791169
Validation loss: 4.8295063071610755

Epoch: 6| Step: 7
Training loss: 4.116131583791739
Validation loss: 4.8223469550813

Epoch: 6| Step: 8
Training loss: 4.3685767842063665
Validation loss: 4.816236391395624

Epoch: 6| Step: 9
Training loss: 5.106537103694269
Validation loss: 4.8106379023458175

Epoch: 6| Step: 10
Training loss: 5.122451148407593
Validation loss: 4.8048488682886505

Epoch: 6| Step: 11
Training loss: 4.48033188442058
Validation loss: 4.799219939637278

Epoch: 6| Step: 12
Training loss: 5.696017751473186
Validation loss: 4.793278707706766

Epoch: 6| Step: 13
Training loss: 4.804645023313255
Validation loss: 4.78733428588597

Epoch: 14| Step: 0
Training loss: 4.073210696691085
Validation loss: 4.781437523183408

Epoch: 6| Step: 1
Training loss: 4.230705444815441
Validation loss: 4.77556290163004

Epoch: 6| Step: 2
Training loss: 5.186622085739264
Validation loss: 4.770760525921087

Epoch: 6| Step: 3
Training loss: 4.00447880814749
Validation loss: 4.7637801471504675

Epoch: 6| Step: 4
Training loss: 5.131574182340852
Validation loss: 4.758113456941566

Epoch: 6| Step: 5
Training loss: 6.214490188717338
Validation loss: 4.754072050088648

Epoch: 6| Step: 6
Training loss: 5.15262027487195
Validation loss: 4.747567440690251

Epoch: 6| Step: 7
Training loss: 4.380163143376929
Validation loss: 4.741551565551017

Epoch: 6| Step: 8
Training loss: 4.8782308582889655
Validation loss: 4.735623168918107

Epoch: 6| Step: 9
Training loss: 3.893673602436965
Validation loss: 4.730320065821114

Epoch: 6| Step: 10
Training loss: 5.37201980653067
Validation loss: 4.72574423860988

Epoch: 6| Step: 11
Training loss: 4.754426600142501
Validation loss: 4.719272912969476

Epoch: 6| Step: 12
Training loss: 4.716483272765872
Validation loss: 4.713510564487194

Epoch: 6| Step: 13
Training loss: 5.594632723755931
Validation loss: 4.708324257945989

Epoch: 15| Step: 0
Training loss: 4.386307191777572
Validation loss: 4.7029154277759435

Epoch: 6| Step: 1
Training loss: 4.8557877132764204
Validation loss: 4.696873833171186

Epoch: 6| Step: 2
Training loss: 4.233354621493262
Validation loss: 4.6906959319930355

Epoch: 6| Step: 3
Training loss: 5.388923354328139
Validation loss: 4.6855216026287145

Epoch: 6| Step: 4
Training loss: 4.461499287359943
Validation loss: 4.680446964341199

Epoch: 6| Step: 5
Training loss: 5.102900237665958
Validation loss: 4.6753584889202475

Epoch: 6| Step: 6
Training loss: 5.230790006587683
Validation loss: 4.670167268511619

Epoch: 6| Step: 7
Training loss: 5.088809747834773
Validation loss: 4.6649397424947265

Epoch: 6| Step: 8
Training loss: 4.302988149645687
Validation loss: 4.658859921049001

Epoch: 6| Step: 9
Training loss: 5.2862526939747845
Validation loss: 4.652818904840445

Epoch: 6| Step: 10
Training loss: 5.212741705324155
Validation loss: 4.64699051932959

Epoch: 6| Step: 11
Training loss: 4.584687928673042
Validation loss: 4.640833514973838

Epoch: 6| Step: 12
Training loss: 4.285032731312895
Validation loss: 4.636019218229451

Epoch: 6| Step: 13
Training loss: 4.452629838150251
Validation loss: 4.631559102686663

Epoch: 16| Step: 0
Training loss: 5.667400350010128
Validation loss: 4.624850743265266

Epoch: 6| Step: 1
Training loss: 4.583494611272331
Validation loss: 4.618705624722958

Epoch: 6| Step: 2
Training loss: 4.573485226865976
Validation loss: 4.613642571555148

Epoch: 6| Step: 3
Training loss: 4.969306770655621
Validation loss: 4.607954869011788

Epoch: 6| Step: 4
Training loss: 5.2223737550398575
Validation loss: 4.601946691116711

Epoch: 6| Step: 5
Training loss: 4.760478057576773
Validation loss: 4.596189893285079

Epoch: 6| Step: 6
Training loss: 4.074023994626082
Validation loss: 4.590566314744571

Epoch: 6| Step: 7
Training loss: 5.4529193303800865
Validation loss: 4.584962913504633

Epoch: 6| Step: 8
Training loss: 4.920784771986761
Validation loss: 4.579122649453606

Epoch: 6| Step: 9
Training loss: 4.283730783589175
Validation loss: 4.573178480064217

Epoch: 6| Step: 10
Training loss: 4.368356510718456
Validation loss: 4.56890035260981

Epoch: 6| Step: 11
Training loss: 4.482645691579944
Validation loss: 4.562478923313457

Epoch: 6| Step: 12
Training loss: 4.088268074876057
Validation loss: 4.556665879653903

Epoch: 6| Step: 13
Training loss: 4.2566055126970195
Validation loss: 4.551285220551825

Epoch: 17| Step: 0
Training loss: 4.915299349387766
Validation loss: 4.545328862735709

Epoch: 6| Step: 1
Training loss: 5.236084798290855
Validation loss: 4.540535508893145

Epoch: 6| Step: 2
Training loss: 5.24630062010682
Validation loss: 4.5344018256640295

Epoch: 6| Step: 3
Training loss: 5.1284010232287525
Validation loss: 4.528595315550189

Epoch: 6| Step: 4
Training loss: 4.687154935215898
Validation loss: 4.524405736522395

Epoch: 6| Step: 5
Training loss: 4.8990376909390285
Validation loss: 4.517867150951683

Epoch: 6| Step: 6
Training loss: 3.9681078774339196
Validation loss: 4.513303324873394

Epoch: 6| Step: 7
Training loss: 4.547580520059626
Validation loss: 4.507630378133819

Epoch: 6| Step: 8
Training loss: 3.543954865523429
Validation loss: 4.501513615115149

Epoch: 6| Step: 9
Training loss: 4.406975219781541
Validation loss: 4.496290691447188

Epoch: 6| Step: 10
Training loss: 4.202984321820943
Validation loss: 4.491183439080581

Epoch: 6| Step: 11
Training loss: 4.595544373785402
Validation loss: 4.485515489329748

Epoch: 6| Step: 12
Training loss: 3.81040484282486
Validation loss: 4.480957288417481

Epoch: 6| Step: 13
Training loss: 5.324338759079436
Validation loss: 4.475496778849321

Epoch: 18| Step: 0
Training loss: 3.838863709534802
Validation loss: 4.47048592807148

Epoch: 6| Step: 1
Training loss: 4.5715568217952125
Validation loss: 4.464974931829523

Epoch: 6| Step: 2
Training loss: 4.36154416168921
Validation loss: 4.459394394053376

Epoch: 6| Step: 3
Training loss: 4.5171542102770665
Validation loss: 4.4543943503376875

Epoch: 6| Step: 4
Training loss: 4.4816822646893275
Validation loss: 4.44911907777678

Epoch: 6| Step: 5
Training loss: 4.396151827924627
Validation loss: 4.4440432738341205

Epoch: 6| Step: 6
Training loss: 4.929013455552696
Validation loss: 4.439185793886583

Epoch: 6| Step: 7
Training loss: 4.792755843503762
Validation loss: 4.433916642002683

Epoch: 6| Step: 8
Training loss: 4.759836352123781
Validation loss: 4.428929034677089

Epoch: 6| Step: 9
Training loss: 4.365943909058042
Validation loss: 4.42354093156949

Epoch: 6| Step: 10
Training loss: 3.8951522041326414
Validation loss: 4.418346691296066

Epoch: 6| Step: 11
Training loss: 4.599434378305858
Validation loss: 4.412574683864047

Epoch: 6| Step: 12
Training loss: 4.86605797362061
Validation loss: 4.408278519134005

Epoch: 6| Step: 13
Training loss: 5.305874990774341
Validation loss: 4.402456900973963

Epoch: 19| Step: 0
Training loss: 4.448141743000138
Validation loss: 4.397224561672321

Epoch: 6| Step: 1
Training loss: 4.838847774462824
Validation loss: 4.391637791653893

Epoch: 6| Step: 2
Training loss: 5.009928573129693
Validation loss: 4.386326469710741

Epoch: 6| Step: 3
Training loss: 4.768236189093455
Validation loss: 4.380874867326132

Epoch: 6| Step: 4
Training loss: 4.63128050100396
Validation loss: 4.375706642848396

Epoch: 6| Step: 5
Training loss: 4.385543108617671
Validation loss: 4.370052337449464

Epoch: 6| Step: 6
Training loss: 4.619862977014751
Validation loss: 4.364693263208887

Epoch: 6| Step: 7
Training loss: 4.466019016018676
Validation loss: 4.3593108287540945

Epoch: 6| Step: 8
Training loss: 3.5654661980721016
Validation loss: 4.354038759874728

Epoch: 6| Step: 9
Training loss: 3.450787750092927
Validation loss: 4.348840945671608

Epoch: 6| Step: 10
Training loss: 5.210531193164609
Validation loss: 4.34353703038505

Epoch: 6| Step: 11
Training loss: 4.148614969426638
Validation loss: 4.338708765201585

Epoch: 6| Step: 12
Training loss: 4.527318472211572
Validation loss: 4.333103002637916

Epoch: 6| Step: 13
Training loss: 4.4839268902442715
Validation loss: 4.32812567939248

Epoch: 20| Step: 0
Training loss: 4.425995864445633
Validation loss: 4.323039752479469

Epoch: 6| Step: 1
Training loss: 4.893712443357444
Validation loss: 4.3174866671964685

Epoch: 6| Step: 2
Training loss: 3.9600492004266568
Validation loss: 4.312539178790083

Epoch: 6| Step: 3
Training loss: 4.89327550855628
Validation loss: 4.30700183832764

Epoch: 6| Step: 4
Training loss: 3.442578534994444
Validation loss: 4.301654557234815

Epoch: 6| Step: 5
Training loss: 4.160462732621953
Validation loss: 4.296578950797979

Epoch: 6| Step: 6
Training loss: 4.340120844059534
Validation loss: 4.291525860053666

Epoch: 6| Step: 7
Training loss: 4.147573952317355
Validation loss: 4.286313406378041

Epoch: 6| Step: 8
Training loss: 4.050522504468294
Validation loss: 4.281333347075431

Epoch: 6| Step: 9
Training loss: 4.595668677489895
Validation loss: 4.27627558500101

Epoch: 6| Step: 10
Training loss: 4.605845402788684
Validation loss: 4.27119670655678

Epoch: 6| Step: 11
Training loss: 4.523423163567523
Validation loss: 4.266554362090618

Epoch: 6| Step: 12
Training loss: 4.378945233922701
Validation loss: 4.261042852793085

Epoch: 6| Step: 13
Training loss: 5.172075250442537
Validation loss: 4.256294824604121

Epoch: 21| Step: 0
Training loss: 4.54308084757981
Validation loss: 4.250708034852142

Epoch: 6| Step: 1
Training loss: 4.459511336853556
Validation loss: 4.245668766075618

Epoch: 6| Step: 2
Training loss: 4.108223293190012
Validation loss: 4.24032578149429

Epoch: 6| Step: 3
Training loss: 4.281359817321592
Validation loss: 4.234893954712193

Epoch: 6| Step: 4
Training loss: 4.891716880908865
Validation loss: 4.230143968132711

Epoch: 6| Step: 5
Training loss: 5.03891298530609
Validation loss: 4.224568045089624

Epoch: 6| Step: 6
Training loss: 5.218066690447901
Validation loss: 4.220008718834137

Epoch: 6| Step: 7
Training loss: 4.279243388814534
Validation loss: 4.21400686115804

Epoch: 6| Step: 8
Training loss: 3.440235506024851
Validation loss: 4.208160031719256

Epoch: 6| Step: 9
Training loss: 3.701015467094254
Validation loss: 4.203364917284541

Epoch: 6| Step: 10
Training loss: 3.7447098611200476
Validation loss: 4.19853553595993

Epoch: 6| Step: 11
Training loss: 3.9387312886415007
Validation loss: 4.193526453161185

Epoch: 6| Step: 12
Training loss: 4.4182914528336195
Validation loss: 4.188177670734589

Epoch: 6| Step: 13
Training loss: 4.431788247458638
Validation loss: 4.183096966898655

Epoch: 22| Step: 0
Training loss: 3.6038421896403885
Validation loss: 4.178101482910074

Epoch: 6| Step: 1
Training loss: 4.33460573931277
Validation loss: 4.173421089866573

Epoch: 6| Step: 2
Training loss: 4.490109701197086
Validation loss: 4.168410978777446

Epoch: 6| Step: 3
Training loss: 4.76654063949619
Validation loss: 4.164388847803242

Epoch: 6| Step: 4
Training loss: 4.395570840576497
Validation loss: 4.16039602815453

Epoch: 6| Step: 5
Training loss: 5.022618062296498
Validation loss: 4.155848739490417

Epoch: 6| Step: 6
Training loss: 4.232090632948245
Validation loss: 4.14994883141896

Epoch: 6| Step: 7
Training loss: 4.622846566015879
Validation loss: 4.144434048983639

Epoch: 6| Step: 8
Training loss: 4.137409617194568
Validation loss: 4.139231916517096

Epoch: 6| Step: 9
Training loss: 4.363779338387282
Validation loss: 4.134282274424617

Epoch: 6| Step: 10
Training loss: 3.8882824076688554
Validation loss: 4.129178541354373

Epoch: 6| Step: 11
Training loss: 3.369841271123303
Validation loss: 4.123430473665682

Epoch: 6| Step: 12
Training loss: 4.435744032179782
Validation loss: 4.118328807328651

Epoch: 6| Step: 13
Training loss: 3.9555003150435435
Validation loss: 4.1133142888407805

Epoch: 23| Step: 0
Training loss: 3.9371288064045116
Validation loss: 4.10825261983968

Epoch: 6| Step: 1
Training loss: 4.052256184138012
Validation loss: 4.103036941238056

Epoch: 6| Step: 2
Training loss: 4.226766020833546
Validation loss: 4.098368323136542

Epoch: 6| Step: 3
Training loss: 3.5733095774169317
Validation loss: 4.093498435796452

Epoch: 6| Step: 4
Training loss: 4.144091957677402
Validation loss: 4.088572326674783

Epoch: 6| Step: 5
Training loss: 4.649273657726935
Validation loss: 4.083518270599358

Epoch: 6| Step: 6
Training loss: 4.210417933072984
Validation loss: 4.078140512098332

Epoch: 6| Step: 7
Training loss: 4.59590399449459
Validation loss: 4.073433390406662

Epoch: 6| Step: 8
Training loss: 4.869762247850088
Validation loss: 4.068363418613719

Epoch: 6| Step: 9
Training loss: 3.7412708410108912
Validation loss: 4.063232394981342

Epoch: 6| Step: 10
Training loss: 4.0264819432091405
Validation loss: 4.058139710765147

Epoch: 6| Step: 11
Training loss: 4.888977163172924
Validation loss: 4.051737217311781

Epoch: 6| Step: 12
Training loss: 4.177580057925983
Validation loss: 4.046960738954099

Epoch: 6| Step: 13
Training loss: 3.523966476757275
Validation loss: 4.041127349159645

Epoch: 24| Step: 0
Training loss: 4.313213786886377
Validation loss: 4.035865448099222

Epoch: 6| Step: 1
Training loss: 3.9203044284632558
Validation loss: 4.030522776221454

Epoch: 6| Step: 2
Training loss: 4.60164539929571
Validation loss: 4.024816776630859

Epoch: 6| Step: 3
Training loss: 2.7014052372306723
Validation loss: 4.019469759624922

Epoch: 6| Step: 4
Training loss: 3.8672100644464806
Validation loss: 4.014841698470776

Epoch: 6| Step: 5
Training loss: 4.5883356481828725
Validation loss: 4.01014170839423

Epoch: 6| Step: 6
Training loss: 4.940705815908349
Validation loss: 4.005317292965679

Epoch: 6| Step: 7
Training loss: 4.140654941666507
Validation loss: 3.9999347522500273

Epoch: 6| Step: 8
Training loss: 4.412702664916361
Validation loss: 3.9949594766648757

Epoch: 6| Step: 9
Training loss: 4.060569186972731
Validation loss: 3.9898819110320947

Epoch: 6| Step: 10
Training loss: 4.328499127134429
Validation loss: 3.984814987323124

Epoch: 6| Step: 11
Training loss: 4.162790300939937
Validation loss: 3.979309552142132

Epoch: 6| Step: 12
Training loss: 2.8799528499558376
Validation loss: 3.9743236742116372

Epoch: 6| Step: 13
Training loss: 4.381055728017185
Validation loss: 3.969373799158026

Epoch: 25| Step: 0
Training loss: 4.072369134625733
Validation loss: 3.964597376793374

Epoch: 6| Step: 1
Training loss: 4.238004248220449
Validation loss: 3.959017557269519

Epoch: 6| Step: 2
Training loss: 4.288126970275951
Validation loss: 3.953930799057175

Epoch: 6| Step: 3
Training loss: 4.498394149778098
Validation loss: 3.9491738236032354

Epoch: 6| Step: 4
Training loss: 4.442836507697629
Validation loss: 3.944274846461993

Epoch: 6| Step: 5
Training loss: 4.205805834690447
Validation loss: 3.9386476327758615

Epoch: 6| Step: 6
Training loss: 4.017584771506413
Validation loss: 3.9333955474286766

Epoch: 6| Step: 7
Training loss: 3.63298510069644
Validation loss: 3.928097979185346

Epoch: 6| Step: 8
Training loss: 3.796933774140007
Validation loss: 3.923196962417829

Epoch: 6| Step: 9
Training loss: 3.9953675864147633
Validation loss: 3.918446190681396

Epoch: 6| Step: 10
Training loss: 3.8956416009787613
Validation loss: 3.913713796263975

Epoch: 6| Step: 11
Training loss: 2.406153689351997
Validation loss: 3.9087812030174236

Epoch: 6| Step: 12
Training loss: 4.779134643944057
Validation loss: 3.904137612434553

Epoch: 6| Step: 13
Training loss: 4.175584379859911
Validation loss: 3.8997524186964885

Epoch: 26| Step: 0
Training loss: 3.7664909158625224
Validation loss: 3.894430380496686

Epoch: 6| Step: 1
Training loss: 3.887064948071033
Validation loss: 3.8896981275332636

Epoch: 6| Step: 2
Training loss: 5.0438918990698
Validation loss: 3.8849652448267227

Epoch: 6| Step: 3
Training loss: 3.345027786390366
Validation loss: 3.8802901427927576

Epoch: 6| Step: 4
Training loss: 4.330155650241948
Validation loss: 3.875345276247245

Epoch: 6| Step: 5
Training loss: 4.475415786948119
Validation loss: 3.8705620783906673

Epoch: 6| Step: 6
Training loss: 4.003214974624351
Validation loss: 3.865707206622926

Epoch: 6| Step: 7
Training loss: 3.493361853805869
Validation loss: 3.86040617928862

Epoch: 6| Step: 8
Training loss: 3.550383189837082
Validation loss: 3.8556431734412526

Epoch: 6| Step: 9
Training loss: 4.531479191738734
Validation loss: 3.851072289232722

Epoch: 6| Step: 10
Training loss: 3.939156683310704
Validation loss: 3.8461963756361777

Epoch: 6| Step: 11
Training loss: 4.044911501073129
Validation loss: 3.8416698171695085

Epoch: 6| Step: 12
Training loss: 3.140341067408653
Validation loss: 3.8370039960005116

Epoch: 6| Step: 13
Training loss: 4.008870065221508
Validation loss: 3.8322250726790674

Epoch: 27| Step: 0
Training loss: 4.5909622972153805
Validation loss: 3.8271139872899274

Epoch: 6| Step: 1
Training loss: 3.1983893394105536
Validation loss: 3.8219471394137012

Epoch: 6| Step: 2
Training loss: 4.140046162002393
Validation loss: 3.817238140772238

Epoch: 6| Step: 3
Training loss: 3.5054494123986073
Validation loss: 3.8123073008048363

Epoch: 6| Step: 4
Training loss: 3.4973236477982317
Validation loss: 3.807438956706653

Epoch: 6| Step: 5
Training loss: 4.234374549556018
Validation loss: 3.802719787559228

Epoch: 6| Step: 6
Training loss: 4.103233011745938
Validation loss: 3.79832194403737

Epoch: 6| Step: 7
Training loss: 3.651425561389838
Validation loss: 3.793319565446894

Epoch: 6| Step: 8
Training loss: 3.5658413125168997
Validation loss: 3.7888001655924928

Epoch: 6| Step: 9
Training loss: 4.453301463060685
Validation loss: 3.784023476278483

Epoch: 6| Step: 10
Training loss: 4.145473649925489
Validation loss: 3.7792268705497

Epoch: 6| Step: 11
Training loss: 3.8169443459814585
Validation loss: 3.7742688807850566

Epoch: 6| Step: 12
Training loss: 3.9710596527791138
Validation loss: 3.769342721497168

Epoch: 6| Step: 13
Training loss: 3.91694714509131
Validation loss: 3.7645781184323783

Epoch: 28| Step: 0
Training loss: 3.6455216774113515
Validation loss: 3.759733706912678

Epoch: 6| Step: 1
Training loss: 3.878494655749539
Validation loss: 3.7551967005168114

Epoch: 6| Step: 2
Training loss: 3.267525006105897
Validation loss: 3.750564130100454

Epoch: 6| Step: 3
Training loss: 4.550225455598584
Validation loss: 3.7463078654770188

Epoch: 6| Step: 4
Training loss: 4.220625622914654
Validation loss: 3.741260814674484

Epoch: 6| Step: 5
Training loss: 4.160077619928865
Validation loss: 3.7360041215807165

Epoch: 6| Step: 6
Training loss: 4.512144866241034
Validation loss: 3.731238203599814

Epoch: 6| Step: 7
Training loss: 3.394535745106345
Validation loss: 3.726324792260842

Epoch: 6| Step: 8
Training loss: 2.87422153050754
Validation loss: 3.7214777369590326

Epoch: 6| Step: 9
Training loss: 4.032714341220531
Validation loss: 3.716968376731914

Epoch: 6| Step: 10
Training loss: 3.905707970206574
Validation loss: 3.712100583563527

Epoch: 6| Step: 11
Training loss: 4.18194416482103
Validation loss: 3.707534268187188

Epoch: 6| Step: 12
Training loss: 4.206023284107576
Validation loss: 3.7028839848415624

Epoch: 6| Step: 13
Training loss: 2.7558176752581325
Validation loss: 3.697861129272059

Epoch: 29| Step: 0
Training loss: 4.125904793199769
Validation loss: 3.693369273161203

Epoch: 6| Step: 1
Training loss: 4.207352678209647
Validation loss: 3.688580435536827

Epoch: 6| Step: 2
Training loss: 3.504687984362776
Validation loss: 3.6837325381808013

Epoch: 6| Step: 3
Training loss: 3.6576540606704544
Validation loss: 3.678931005295651

Epoch: 6| Step: 4
Training loss: 4.115963372040678
Validation loss: 3.674418484272121

Epoch: 6| Step: 5
Training loss: 3.884546395507787
Validation loss: 3.6698167158851547

Epoch: 6| Step: 6
Training loss: 4.245241081302558
Validation loss: 3.6649324405162758

Epoch: 6| Step: 7
Training loss: 3.81363611021877
Validation loss: 3.6602010652939416

Epoch: 6| Step: 8
Training loss: 3.9219192563177754
Validation loss: 3.6555481804989434

Epoch: 6| Step: 9
Training loss: 3.4952182803118843
Validation loss: 3.6506407005574584

Epoch: 6| Step: 10
Training loss: 3.372524483876751
Validation loss: 3.6459968675539614

Epoch: 6| Step: 11
Training loss: 4.346376352346887
Validation loss: 3.6411987856681067

Epoch: 6| Step: 12
Training loss: 3.027819708048721
Validation loss: 3.6364272861617777

Epoch: 6| Step: 13
Training loss: 3.2167304656927684
Validation loss: 3.6321098058209262

Epoch: 30| Step: 0
Training loss: 3.756110109082306
Validation loss: 3.6275594379472613

Epoch: 6| Step: 1
Training loss: 3.896678826014265
Validation loss: 3.623018907300241

Epoch: 6| Step: 2
Training loss: 3.110290239289515
Validation loss: 3.6188830143140986

Epoch: 6| Step: 3
Training loss: 4.547862781316686
Validation loss: 3.6140866043643767

Epoch: 6| Step: 4
Training loss: 3.787583021003132
Validation loss: 3.6093188745227605

Epoch: 6| Step: 5
Training loss: 3.6229451373434687
Validation loss: 3.6049471471318544

Epoch: 6| Step: 6
Training loss: 3.5511302545668335
Validation loss: 3.6004825939677194

Epoch: 6| Step: 7
Training loss: 4.026297906154183
Validation loss: 3.596060875109696

Epoch: 6| Step: 8
Training loss: 3.4701823808303773
Validation loss: 3.5916832329765556

Epoch: 6| Step: 9
Training loss: 3.2409056553937337
Validation loss: 3.5875459275977626

Epoch: 6| Step: 10
Training loss: 3.9790418648579813
Validation loss: 3.5827748876306207

Epoch: 6| Step: 11
Training loss: 3.623381944158915
Validation loss: 3.578801986418011

Epoch: 6| Step: 12
Training loss: 3.6930094794764514
Validation loss: 3.574031081423302

Epoch: 6| Step: 13
Training loss: 3.7938603493543135
Validation loss: 3.5698922631313956

Epoch: 31| Step: 0
Training loss: 4.4297770603821025
Validation loss: 3.5653750435368274

Epoch: 6| Step: 1
Training loss: 4.2639391575492995
Validation loss: 3.5606944544806067

Epoch: 6| Step: 2
Training loss: 3.5229838347766593
Validation loss: 3.555978773843974

Epoch: 6| Step: 3
Training loss: 3.9323112571514627
Validation loss: 3.5516110140699046

Epoch: 6| Step: 4
Training loss: 3.472833789796911
Validation loss: 3.5465695645967306

Epoch: 6| Step: 5
Training loss: 3.1930218906148
Validation loss: 3.5420279299918063

Epoch: 6| Step: 6
Training loss: 3.5403876444757767
Validation loss: 3.5378035663345586

Epoch: 6| Step: 7
Training loss: 2.669594042058783
Validation loss: 3.533010713375493

Epoch: 6| Step: 8
Training loss: 3.9161974172656997
Validation loss: 3.528825743570965

Epoch: 6| Step: 9
Training loss: 3.1874054539440118
Validation loss: 3.5247312934852224

Epoch: 6| Step: 10
Training loss: 4.155224436954033
Validation loss: 3.520299491062501

Epoch: 6| Step: 11
Training loss: 3.6395081210794573
Validation loss: 3.516052954728862

Epoch: 6| Step: 12
Training loss: 3.341750358110644
Validation loss: 3.511385654695795

Epoch: 6| Step: 13
Training loss: 3.7874086526361253
Validation loss: 3.507157092472029

Epoch: 32| Step: 0
Training loss: 3.5492048635679256
Validation loss: 3.502593215112216

Epoch: 6| Step: 1
Training loss: 3.69849450696388
Validation loss: 3.498255067640131

Epoch: 6| Step: 2
Training loss: 3.5788573469290403
Validation loss: 3.494072322273829

Epoch: 6| Step: 3
Training loss: 4.076275285433593
Validation loss: 3.4893230891569913

Epoch: 6| Step: 4
Training loss: 3.873048967985125
Validation loss: 3.4852118748713314

Epoch: 6| Step: 5
Training loss: 3.767975259736109
Validation loss: 3.4804048828475973

Epoch: 6| Step: 6
Training loss: 3.707644509337052
Validation loss: 3.4761662746763986

Epoch: 6| Step: 7
Training loss: 3.799930049854742
Validation loss: 3.4712913757429837

Epoch: 6| Step: 8
Training loss: 3.6482728189881275
Validation loss: 3.4666184414358048

Epoch: 6| Step: 9
Training loss: 3.1906124701333303
Validation loss: 3.461994202138658

Epoch: 6| Step: 10
Training loss: 3.033123420606446
Validation loss: 3.4572418551042756

Epoch: 6| Step: 11
Training loss: 3.670929222860736
Validation loss: 3.452839305906094

Epoch: 6| Step: 12
Training loss: 3.7632794811584356
Validation loss: 3.4483364959844875

Epoch: 6| Step: 13
Training loss: 3.0719818934860683
Validation loss: 3.4436182309584193

Epoch: 33| Step: 0
Training loss: 3.653960986784661
Validation loss: 3.442870055000907

Epoch: 6| Step: 1
Training loss: 3.979160741565281
Validation loss: 3.452331405747642

Epoch: 6| Step: 2
Training loss: 3.9633151109520894
Validation loss: 3.4302396684627294

Epoch: 6| Step: 3
Training loss: 4.282423318063927
Validation loss: 3.430951730518135

Epoch: 6| Step: 4
Training loss: 3.7619349971105764
Validation loss: 3.4349732562582953

Epoch: 6| Step: 5
Training loss: 3.895346109587255
Validation loss: 3.430888111368112

Epoch: 6| Step: 6
Training loss: 3.19447222342829
Validation loss: 3.42747471361133

Epoch: 6| Step: 7
Training loss: 3.0522662076529907
Validation loss: 3.4225756480938516

Epoch: 6| Step: 8
Training loss: 3.196899169353208
Validation loss: 3.4189592361348278

Epoch: 6| Step: 9
Training loss: 3.109228849570495
Validation loss: 3.4152419135746297

Epoch: 6| Step: 10
Training loss: 4.135785192921328
Validation loss: 3.4155116028385493

Epoch: 6| Step: 11
Training loss: 3.153955210791632
Validation loss: 3.4089815462276336

Epoch: 6| Step: 12
Training loss: 3.147612129862279
Validation loss: 3.4025455477784314

Epoch: 6| Step: 13
Training loss: 3.0376040531122364
Validation loss: 3.3968565789746514

Epoch: 34| Step: 0
Training loss: 3.146303575413483
Validation loss: 3.392412713468664

Epoch: 6| Step: 1
Training loss: 2.644856780849359
Validation loss: 3.387926894499998

Epoch: 6| Step: 2
Training loss: 3.4976458125228174
Validation loss: 3.383477877518676

Epoch: 6| Step: 3
Training loss: 2.5936395093065343
Validation loss: 3.379117055796093

Epoch: 6| Step: 4
Training loss: 3.4905924386577905
Validation loss: 3.3753765979274224

Epoch: 6| Step: 5
Training loss: 3.9694446346305754
Validation loss: 3.370532057178815

Epoch: 6| Step: 6
Training loss: 3.7798618259102583
Validation loss: 3.36549850788158

Epoch: 6| Step: 7
Training loss: 3.9617757719040214
Validation loss: 3.3610509196234677

Epoch: 6| Step: 8
Training loss: 3.8760160529214636
Validation loss: 3.356570896599523

Epoch: 6| Step: 9
Training loss: 3.79110920479555
Validation loss: 3.3516917407556805

Epoch: 6| Step: 10
Training loss: 3.2637522314875618
Validation loss: 3.346698874841651

Epoch: 6| Step: 11
Training loss: 3.044106032210336
Validation loss: 3.34196086802954

Epoch: 6| Step: 12
Training loss: 3.4988015711650764
Validation loss: 3.337197345055058

Epoch: 6| Step: 13
Training loss: 4.0294048019355575
Validation loss: 3.332742606907239

Epoch: 35| Step: 0
Training loss: 3.402552566514661
Validation loss: 3.3281652361567313

Epoch: 6| Step: 1
Training loss: 2.3378669654713433
Validation loss: 3.32380349135206

Epoch: 6| Step: 2
Training loss: 3.4812830048508383
Validation loss: 3.319675040293643

Epoch: 6| Step: 3
Training loss: 3.099503071241462
Validation loss: 3.3160510312890605

Epoch: 6| Step: 4
Training loss: 3.39242548096799
Validation loss: 3.312383265807605

Epoch: 6| Step: 5
Training loss: 3.6762353857762293
Validation loss: 3.30768399452218

Epoch: 6| Step: 6
Training loss: 3.4275066419630296
Validation loss: 3.3038101414433516

Epoch: 6| Step: 7
Training loss: 3.5294544077148378
Validation loss: 3.2992999663711884

Epoch: 6| Step: 8
Training loss: 3.9383878161105326
Validation loss: 3.2952906702366755

Epoch: 6| Step: 9
Training loss: 3.839033505086121
Validation loss: 3.2910336517534535

Epoch: 6| Step: 10
Training loss: 3.683710640501881
Validation loss: 3.287186752983139

Epoch: 6| Step: 11
Training loss: 3.947769578325803
Validation loss: 3.282854735320487

Epoch: 6| Step: 12
Training loss: 3.3107666662842763
Validation loss: 3.2786700687416652

Epoch: 6| Step: 13
Training loss: 2.728696933148204
Validation loss: 3.2743764181729262

Epoch: 36| Step: 0
Training loss: 3.529760671180553
Validation loss: 3.2703352303891338

Epoch: 6| Step: 1
Training loss: 3.3348335386994896
Validation loss: 3.2662936412855936

Epoch: 6| Step: 2
Training loss: 3.4895222369107395
Validation loss: 3.2620470441423177

Epoch: 6| Step: 3
Training loss: 3.209793963846315
Validation loss: 3.25803600736859

Epoch: 6| Step: 4
Training loss: 3.3470952778052276
Validation loss: 3.2537784620015477

Epoch: 6| Step: 5
Training loss: 3.398942160131938
Validation loss: 3.2494688089022934

Epoch: 6| Step: 6
Training loss: 3.6375077290141524
Validation loss: 3.245669818100802

Epoch: 6| Step: 7
Training loss: 3.5158726583775413
Validation loss: 3.241512096482293

Epoch: 6| Step: 8
Training loss: 3.0892554107616164
Validation loss: 3.2374183600305906

Epoch: 6| Step: 9
Training loss: 3.1357672781521098
Validation loss: 3.233397282299011

Epoch: 6| Step: 10
Training loss: 3.33746603044803
Validation loss: 3.2297087347707167

Epoch: 6| Step: 11
Training loss: 3.436714221268896
Validation loss: 3.226170452151632

Epoch: 6| Step: 12
Training loss: 3.373866562018733
Validation loss: 3.2225600226321554

Epoch: 6| Step: 13
Training loss: 3.5010894714620786
Validation loss: 3.218601519669122

Epoch: 37| Step: 0
Training loss: 3.594544298048408
Validation loss: 3.2155817605421073

Epoch: 6| Step: 1
Training loss: 3.511057688578941
Validation loss: 3.2121671006903685

Epoch: 6| Step: 2
Training loss: 3.4150112762935225
Validation loss: 3.2077891685106836

Epoch: 6| Step: 3
Training loss: 2.4849658959118965
Validation loss: 3.2041231414524036

Epoch: 6| Step: 4
Training loss: 3.0962209370757967
Validation loss: 3.200073513040938

Epoch: 6| Step: 5
Training loss: 3.2454526339283194
Validation loss: 3.196676521193265

Epoch: 6| Step: 6
Training loss: 3.023717586348333
Validation loss: 3.19261823136024

Epoch: 6| Step: 7
Training loss: 3.140982384536058
Validation loss: 3.1895792543537578

Epoch: 6| Step: 8
Training loss: 3.879843238534648
Validation loss: 3.1860656627690194

Epoch: 6| Step: 9
Training loss: 3.5285205926757763
Validation loss: 3.182804738507977

Epoch: 6| Step: 10
Training loss: 2.263191442054218
Validation loss: 3.1791587971147868

Epoch: 6| Step: 11
Training loss: 3.5049014512164613
Validation loss: 3.175819937895371

Epoch: 6| Step: 12
Training loss: 3.7012584505045902
Validation loss: 3.1725384874867566

Epoch: 6| Step: 13
Training loss: 3.825053200943912
Validation loss: 3.169266766827915

Epoch: 38| Step: 0
Training loss: 3.484715740153399
Validation loss: 3.1654431254744098

Epoch: 6| Step: 1
Training loss: 3.420121810706929
Validation loss: 3.1618420254411226

Epoch: 6| Step: 2
Training loss: 2.4885731859687406
Validation loss: 3.1580663685628396

Epoch: 6| Step: 3
Training loss: 3.6742068414416043
Validation loss: 3.1547879650688175

Epoch: 6| Step: 4
Training loss: 3.593634164021399
Validation loss: 3.151142053607639

Epoch: 6| Step: 5
Training loss: 3.2409269892947243
Validation loss: 3.1480006442596475

Epoch: 6| Step: 6
Training loss: 2.894504891917776
Validation loss: 3.1445162881372832

Epoch: 6| Step: 7
Training loss: 3.230116837694304
Validation loss: 3.1408393242680095

Epoch: 6| Step: 8
Training loss: 3.264325627175073
Validation loss: 3.1377074194606394

Epoch: 6| Step: 9
Training loss: 3.193624409634297
Validation loss: 3.1350268420500567

Epoch: 6| Step: 10
Training loss: 3.433640133627976
Validation loss: 3.1315595066508104

Epoch: 6| Step: 11
Training loss: 3.3994843372422343
Validation loss: 3.1283803458958506

Epoch: 6| Step: 12
Training loss: 3.4249008944018526
Validation loss: 3.124955761914255

Epoch: 6| Step: 13
Training loss: 3.0568257918654713
Validation loss: 3.1216672418990643

Epoch: 39| Step: 0
Training loss: 3.046733833368383
Validation loss: 3.118233845311513

Epoch: 6| Step: 1
Training loss: 2.654835133435573
Validation loss: 3.1148625677130526

Epoch: 6| Step: 2
Training loss: 3.104429212557247
Validation loss: 3.1116868439115373

Epoch: 6| Step: 3
Training loss: 3.5261121524018373
Validation loss: 3.108105398689431

Epoch: 6| Step: 4
Training loss: 3.2735956923105007
Validation loss: 3.104774663041124

Epoch: 6| Step: 5
Training loss: 2.8199602155381585
Validation loss: 3.1013760706861637

Epoch: 6| Step: 6
Training loss: 3.3608381057151724
Validation loss: 3.0980251200063678

Epoch: 6| Step: 7
Training loss: 3.7847080024351007
Validation loss: 3.094962925871212

Epoch: 6| Step: 8
Training loss: 3.3621162053709517
Validation loss: 3.091442107882066

Epoch: 6| Step: 9
Training loss: 3.900886698939597
Validation loss: 3.0883407055649634

Epoch: 6| Step: 10
Training loss: 3.093221137571708
Validation loss: 3.084952243021046

Epoch: 6| Step: 11
Training loss: 2.500606081928447
Validation loss: 3.0817797759283456

Epoch: 6| Step: 12
Training loss: 3.0436102175094515
Validation loss: 3.078475480369907

Epoch: 6| Step: 13
Training loss: 3.544464502174868
Validation loss: 3.0757587458199307

Epoch: 40| Step: 0
Training loss: 3.117495872904746
Validation loss: 3.0724032646658825

Epoch: 6| Step: 1
Training loss: 3.168102407399346
Validation loss: 3.068731572341234

Epoch: 6| Step: 2
Training loss: 3.377402404233477
Validation loss: 3.066043671960718

Epoch: 6| Step: 3
Training loss: 3.325648429571565
Validation loss: 3.0632579929383787

Epoch: 6| Step: 4
Training loss: 2.814344606550983
Validation loss: 3.060238762435306

Epoch: 6| Step: 5
Training loss: 3.308752855530974
Validation loss: 3.0573761303924787

Epoch: 6| Step: 6
Training loss: 2.848649718999796
Validation loss: 3.054655004980549

Epoch: 6| Step: 7
Training loss: 3.2197139740901166
Validation loss: 3.049868464630107

Epoch: 6| Step: 8
Training loss: 3.307371091514725
Validation loss: 3.048125259934415

Epoch: 6| Step: 9
Training loss: 3.198985779492466
Validation loss: 3.0445413896187725

Epoch: 6| Step: 10
Training loss: 3.3329764810917495
Validation loss: 3.0419589429154197

Epoch: 6| Step: 11
Training loss: 3.2401298887802312
Validation loss: 3.0386455416565092

Epoch: 6| Step: 12
Training loss: 2.977221318422537
Validation loss: 3.0361763423540675

Epoch: 6| Step: 13
Training loss: 3.4247251859802277
Validation loss: 3.033381404251274

Epoch: 41| Step: 0
Training loss: 2.9981443706154685
Validation loss: 3.030658100451161

Epoch: 6| Step: 1
Training loss: 2.9939734007240553
Validation loss: 3.0279951941058556

Epoch: 6| Step: 2
Training loss: 2.8542738474377316
Validation loss: 3.0254824193266

Epoch: 6| Step: 3
Training loss: 3.2667307464646456
Validation loss: 3.0224549950298343

Epoch: 6| Step: 4
Training loss: 3.163097243776104
Validation loss: 3.019663082006839

Epoch: 6| Step: 5
Training loss: 3.883424277052481
Validation loss: 3.017016048818186

Epoch: 6| Step: 6
Training loss: 2.9704922031261094
Validation loss: 3.013693854959912

Epoch: 6| Step: 7
Training loss: 3.309295543837081
Validation loss: 3.0107018138823483

Epoch: 6| Step: 8
Training loss: 2.7932031493095857
Validation loss: 3.007885265708697

Epoch: 6| Step: 9
Training loss: 2.9419201000574557
Validation loss: 3.0046100693100675

Epoch: 6| Step: 10
Training loss: 3.08135878426993
Validation loss: 3.001874523503

Epoch: 6| Step: 11
Training loss: 3.2312810722937835
Validation loss: 2.9991338327159296

Epoch: 6| Step: 12
Training loss: 3.286817495768252
Validation loss: 2.996434264911335

Epoch: 6| Step: 13
Training loss: 3.250416215507738
Validation loss: 2.9935559363171858

Epoch: 42| Step: 0
Training loss: 3.3103495401178997
Validation loss: 2.9908867673935897

Epoch: 6| Step: 1
Training loss: 2.870549613615573
Validation loss: 2.9882303071510483

Epoch: 6| Step: 2
Training loss: 2.765658965683465
Validation loss: 2.985604770126839

Epoch: 6| Step: 3
Training loss: 3.3396304413790086
Validation loss: 2.9829840489369297

Epoch: 6| Step: 4
Training loss: 3.364561114321509
Validation loss: 2.98057468637673

Epoch: 6| Step: 5
Training loss: 3.4167510386648434
Validation loss: 2.9776188268473534

Epoch: 6| Step: 6
Training loss: 2.8414594207395383
Validation loss: 2.974777313788386

Epoch: 6| Step: 7
Training loss: 2.8362461899403537
Validation loss: 2.9734997682504503

Epoch: 6| Step: 8
Training loss: 3.1180969288400258
Validation loss: 2.9762672952093117

Epoch: 6| Step: 9
Training loss: 3.0502513469251915
Validation loss: 2.9672127474701213

Epoch: 6| Step: 10
Training loss: 3.2821595883991845
Validation loss: 2.9645888361787067

Epoch: 6| Step: 11
Training loss: 3.340751087460594
Validation loss: 2.9630162868955487

Epoch: 6| Step: 12
Training loss: 3.2934846485244043
Validation loss: 2.9606746265004023

Epoch: 6| Step: 13
Training loss: 2.638119744984938
Validation loss: 2.9580561593102144

Epoch: 43| Step: 0
Training loss: 3.0639766325096915
Validation loss: 2.955651173283808

Epoch: 6| Step: 1
Training loss: 3.1274253588703242
Validation loss: 2.953308422709765

Epoch: 6| Step: 2
Training loss: 2.9367486520408366
Validation loss: 2.950484748927189

Epoch: 6| Step: 3
Training loss: 3.2766348216416383
Validation loss: 2.947336110527124

Epoch: 6| Step: 4
Training loss: 2.5183452801659816
Validation loss: 2.944732015190213

Epoch: 6| Step: 5
Training loss: 3.773548701130633
Validation loss: 2.942332330948673

Epoch: 6| Step: 6
Training loss: 3.300573218296473
Validation loss: 2.938997887795697

Epoch: 6| Step: 7
Training loss: 2.618417752477488
Validation loss: 2.935916527955229

Epoch: 6| Step: 8
Training loss: 3.1383701409686577
Validation loss: 2.9338550002610844

Epoch: 6| Step: 9
Training loss: 2.9587439310312176
Validation loss: 2.9312962163062126

Epoch: 6| Step: 10
Training loss: 2.6595861689533375
Validation loss: 2.9278243858814643

Epoch: 6| Step: 11
Training loss: 2.7848275139093555
Validation loss: 2.924512859002071

Epoch: 6| Step: 12
Training loss: 3.3305590687799436
Validation loss: 2.9221971711614816

Epoch: 6| Step: 13
Training loss: 3.38693387977342
Validation loss: 2.919399552424082

Epoch: 44| Step: 0
Training loss: 2.609454125215464
Validation loss: 2.918481239617125

Epoch: 6| Step: 1
Training loss: 3.2690827530369453
Validation loss: 2.917178399743173

Epoch: 6| Step: 2
Training loss: 4.125088777453765
Validation loss: 2.9117395109407656

Epoch: 6| Step: 3
Training loss: 3.06170472698889
Validation loss: 2.9095667436121224

Epoch: 6| Step: 4
Training loss: 3.2196846503091763
Validation loss: 2.906697392636674

Epoch: 6| Step: 5
Training loss: 3.01660361742201
Validation loss: 2.9054160203326207

Epoch: 6| Step: 6
Training loss: 2.6601646748099887
Validation loss: 2.9022925720220734

Epoch: 6| Step: 7
Training loss: 3.2825053402231883
Validation loss: 2.8998407906643715

Epoch: 6| Step: 8
Training loss: 3.083523890474968
Validation loss: 2.8975265456073367

Epoch: 6| Step: 9
Training loss: 3.0942866312721784
Validation loss: 2.8952234481289247

Epoch: 6| Step: 10
Training loss: 2.4366312679671407
Validation loss: 2.8917677811268625

Epoch: 6| Step: 11
Training loss: 3.3839859193729884
Validation loss: 2.8890999697532926

Epoch: 6| Step: 12
Training loss: 2.083911039998045
Validation loss: 2.888164345856368

Epoch: 6| Step: 13
Training loss: 2.83874994382938
Validation loss: 2.885970153238333

Epoch: 45| Step: 0
Training loss: 3.5946201763665253
Validation loss: 2.8847690548679465

Epoch: 6| Step: 1
Training loss: 2.6861590211425
Validation loss: 2.880340977811107

Epoch: 6| Step: 2
Training loss: 3.0734986524602226
Validation loss: 2.8768221982267455

Epoch: 6| Step: 3
Training loss: 2.5403762001125236
Validation loss: 2.875575408850634

Epoch: 6| Step: 4
Training loss: 2.739696447167027
Validation loss: 2.8720851164099797

Epoch: 6| Step: 5
Training loss: 2.7647195831813955
Validation loss: 2.8735096012298245

Epoch: 6| Step: 6
Training loss: 3.4012593797963047
Validation loss: 2.8690128873604546

Epoch: 6| Step: 7
Training loss: 3.092739980725652
Validation loss: 2.8667236008276196

Epoch: 6| Step: 8
Training loss: 3.131441115830547
Validation loss: 2.865383512693346

Epoch: 6| Step: 9
Training loss: 2.8266487272910896
Validation loss: 2.862589351364511

Epoch: 6| Step: 10
Training loss: 2.8127085290533
Validation loss: 2.8601766411044793

Epoch: 6| Step: 11
Training loss: 3.5340497556161967
Validation loss: 2.8584931895168406

Epoch: 6| Step: 12
Training loss: 2.7359450709980555
Validation loss: 2.8562778869425025

Epoch: 6| Step: 13
Training loss: 2.994786660010534
Validation loss: 2.854697370729605

Epoch: 46| Step: 0
Training loss: 3.0166012463580283
Validation loss: 2.8525852825177487

Epoch: 6| Step: 1
Training loss: 2.726358050794204
Validation loss: 2.8509080527767945

Epoch: 6| Step: 2
Training loss: 2.6393723987419286
Validation loss: 2.8470890856580118

Epoch: 6| Step: 3
Training loss: 2.6968987703657135
Validation loss: 2.844593537809952

Epoch: 6| Step: 4
Training loss: 2.865450548625583
Validation loss: 2.8404287149439504

Epoch: 6| Step: 5
Training loss: 3.487730591510055
Validation loss: 2.8403087376961946

Epoch: 6| Step: 6
Training loss: 3.156339134241864
Validation loss: 2.835951693861009

Epoch: 6| Step: 7
Training loss: 3.037074834007763
Validation loss: 2.835146805148433

Epoch: 6| Step: 8
Training loss: 2.385497334766838
Validation loss: 2.831040328727277

Epoch: 6| Step: 9
Training loss: 2.8096103658728233
Validation loss: 2.8341305583510756

Epoch: 6| Step: 10
Training loss: 2.868394478104266
Validation loss: 2.8338708134023025

Epoch: 6| Step: 11
Training loss: 3.4241835240530674
Validation loss: 2.867298799688045

Epoch: 6| Step: 12
Training loss: 2.9608004495512676
Validation loss: 2.822087864189016

Epoch: 6| Step: 13
Training loss: 3.4614229916606933
Validation loss: 2.8219649527608586

Epoch: 47| Step: 0
Training loss: 2.800079981479001
Validation loss: 2.82315288179457

Epoch: 6| Step: 1
Training loss: 2.813244530359502
Validation loss: 2.8269745961592783

Epoch: 6| Step: 2
Training loss: 2.710720702195503
Validation loss: 2.8380190213573875

Epoch: 6| Step: 3
Training loss: 2.6568360523643655
Validation loss: 2.8463682480882864

Epoch: 6| Step: 4
Training loss: 3.224536472099502
Validation loss: 2.8418092358157576

Epoch: 6| Step: 5
Training loss: 3.176229259989228
Validation loss: 2.8311802499697194

Epoch: 6| Step: 6
Training loss: 3.2111658910752157
Validation loss: 2.819788298495061

Epoch: 6| Step: 7
Training loss: 2.9757434589192635
Validation loss: 2.814293974471701

Epoch: 6| Step: 8
Training loss: 2.986605305154884
Validation loss: 2.808573022871152

Epoch: 6| Step: 9
Training loss: 3.2588546147325106
Validation loss: 2.8062900792398358

Epoch: 6| Step: 10
Training loss: 2.472748524177997
Validation loss: 2.8036780422419696

Epoch: 6| Step: 11
Training loss: 3.0837225968991544
Validation loss: 2.806188042062207

Epoch: 6| Step: 12
Training loss: 3.0848445453767397
Validation loss: 2.809481222812869

Epoch: 6| Step: 13
Training loss: 2.888198741573231
Validation loss: 2.804552094459308

Epoch: 48| Step: 0
Training loss: 2.5701047123457585
Validation loss: 2.800632644889197

Epoch: 6| Step: 1
Training loss: 2.7865837472993507
Validation loss: 2.8070975798617694

Epoch: 6| Step: 2
Training loss: 2.6725024997852933
Validation loss: 2.8064268593114328

Epoch: 6| Step: 3
Training loss: 3.0377404639739787
Validation loss: 2.796668018375596

Epoch: 6| Step: 4
Training loss: 3.358028692117225
Validation loss: 2.796506008478898

Epoch: 6| Step: 5
Training loss: 3.5049766853199222
Validation loss: 2.792294294111342

Epoch: 6| Step: 6
Training loss: 2.995365218373691
Validation loss: 2.7898752433475593

Epoch: 6| Step: 7
Training loss: 2.7352617842170504
Validation loss: 2.7855254611155704

Epoch: 6| Step: 8
Training loss: 2.806577592857358
Validation loss: 2.7858287254460468

Epoch: 6| Step: 9
Training loss: 3.122480521221504
Validation loss: 2.7817843206112367

Epoch: 6| Step: 10
Training loss: 2.157363604038906
Validation loss: 2.7786762029721537

Epoch: 6| Step: 11
Training loss: 2.936896241820144
Validation loss: 2.774896229129686

Epoch: 6| Step: 12
Training loss: 3.156810446354654
Validation loss: 2.77231795231265

Epoch: 6| Step: 13
Training loss: 2.9772426198672
Validation loss: 2.7700935227022216

Epoch: 49| Step: 0
Training loss: 2.3714561122667286
Validation loss: 2.7698049907691424

Epoch: 6| Step: 1
Training loss: 2.9726921811231883
Validation loss: 2.7670628030439754

Epoch: 6| Step: 2
Training loss: 2.877967961072697
Validation loss: 2.76412173003398

Epoch: 6| Step: 3
Training loss: 2.761245967642731
Validation loss: 2.7615125292267524

Epoch: 6| Step: 4
Training loss: 3.419318371936446
Validation loss: 2.764659864051029

Epoch: 6| Step: 5
Training loss: 2.667340273021063
Validation loss: 2.7601609645428575

Epoch: 6| Step: 6
Training loss: 3.0715421199403843
Validation loss: 2.759776755002511

Epoch: 6| Step: 7
Training loss: 3.049128242105307
Validation loss: 2.760299152296074

Epoch: 6| Step: 8
Training loss: 3.2467510416345418
Validation loss: 2.7526536911208743

Epoch: 6| Step: 9
Training loss: 2.8371713859738317
Validation loss: 2.75092294406243

Epoch: 6| Step: 10
Training loss: 2.505017205215424
Validation loss: 2.7514945361733423

Epoch: 6| Step: 11
Training loss: 2.6658539328256734
Validation loss: 2.7514071332401624

Epoch: 6| Step: 12
Training loss: 3.2977345869189834
Validation loss: 2.7511171614892453

Epoch: 6| Step: 13
Training loss: 2.6670191849718314
Validation loss: 2.75084940479125

Epoch: 50| Step: 0
Training loss: 2.7843971020370417
Validation loss: 2.748990494941199

Epoch: 6| Step: 1
Training loss: 3.1239307863234194
Validation loss: 2.7481867997027765

Epoch: 6| Step: 2
Training loss: 2.6555297772722746
Validation loss: 2.7472815660093475

Epoch: 6| Step: 3
Training loss: 3.522012697386504
Validation loss: 2.745055898341587

Epoch: 6| Step: 4
Training loss: 2.674470767138303
Validation loss: 2.7425362998208356

Epoch: 6| Step: 5
Training loss: 3.3800238905293725
Validation loss: 2.7395760181943363

Epoch: 6| Step: 6
Training loss: 2.776884102644373
Validation loss: 2.7368861701959815

Epoch: 6| Step: 7
Training loss: 2.6441186670402343
Validation loss: 2.73329379549351

Epoch: 6| Step: 8
Training loss: 2.5563615919159495
Validation loss: 2.732296776969766

Epoch: 6| Step: 9
Training loss: 2.8071447462562964
Validation loss: 2.7290016347671258

Epoch: 6| Step: 10
Training loss: 3.0300919985259935
Validation loss: 2.7289615486076184

Epoch: 6| Step: 11
Training loss: 2.542098826788587
Validation loss: 2.727247733184649

Epoch: 6| Step: 12
Training loss: 2.3542714278505894
Validation loss: 2.7234530202073564

Epoch: 6| Step: 13
Training loss: 3.2082928906818813
Validation loss: 2.7219851746362123

Epoch: 51| Step: 0
Training loss: 2.3821404181537575
Validation loss: 2.719348753844345

Epoch: 6| Step: 1
Training loss: 3.2875966047010237
Validation loss: 2.7179679622797033

Epoch: 6| Step: 2
Training loss: 3.1761352792174407
Validation loss: 2.7158564812406376

Epoch: 6| Step: 3
Training loss: 2.5140740962736072
Validation loss: 2.7173217734411352

Epoch: 6| Step: 4
Training loss: 2.6660494288722294
Validation loss: 2.734111598815849

Epoch: 6| Step: 5
Training loss: 2.72348705953567
Validation loss: 2.7176650502355155

Epoch: 6| Step: 6
Training loss: 3.13300305783451
Validation loss: 2.708813020823613

Epoch: 6| Step: 7
Training loss: 3.1951137191760166
Validation loss: 2.7114329036575824

Epoch: 6| Step: 8
Training loss: 2.297507270411298
Validation loss: 2.712461528710349

Epoch: 6| Step: 9
Training loss: 2.6566213011687396
Validation loss: 2.7181613328671537

Epoch: 6| Step: 10
Training loss: 3.213956059096746
Validation loss: 2.7206812755239547

Epoch: 6| Step: 11
Training loss: 3.159976383555565
Validation loss: 2.721890648827166

Epoch: 6| Step: 12
Training loss: 2.6881083310073195
Validation loss: 2.7222280069752514

Epoch: 6| Step: 13
Training loss: 2.7319795415455776
Validation loss: 2.723096128784505

Epoch: 52| Step: 0
Training loss: 1.9477718387829235
Validation loss: 2.7257529498798094

Epoch: 6| Step: 1
Training loss: 2.9712786696948164
Validation loss: 2.723750926498015

Epoch: 6| Step: 2
Training loss: 2.796647728578133
Validation loss: 2.7237977125807005

Epoch: 6| Step: 3
Training loss: 3.4065327658220377
Validation loss: 2.7201392325827785

Epoch: 6| Step: 4
Training loss: 3.1635472007571592
Validation loss: 2.7188575255663574

Epoch: 6| Step: 5
Training loss: 2.7919971403309516
Validation loss: 2.7161102926550797

Epoch: 6| Step: 6
Training loss: 3.0487200505848975
Validation loss: 2.7129266716814544

Epoch: 6| Step: 7
Training loss: 2.569285642739876
Validation loss: 2.7106252411664933

Epoch: 6| Step: 8
Training loss: 2.911459570778099
Validation loss: 2.7058947711059615

Epoch: 6| Step: 9
Training loss: 2.3493976957458433
Validation loss: 2.7062035231383925

Epoch: 6| Step: 10
Training loss: 2.8415797409529677
Validation loss: 2.703295266847281

Epoch: 6| Step: 11
Training loss: 3.1889419286158964
Validation loss: 2.7013612847659827

Epoch: 6| Step: 12
Training loss: 2.881264206195489
Validation loss: 2.696490427520943

Epoch: 6| Step: 13
Training loss: 2.689068181476875
Validation loss: 2.693211245964378

Epoch: 53| Step: 0
Training loss: 2.4494195639801966
Validation loss: 2.6902708658648087

Epoch: 6| Step: 1
Training loss: 3.0518968718317443
Validation loss: 2.6892422787588957

Epoch: 6| Step: 2
Training loss: 2.696623906086135
Validation loss: 2.6883451478402507

Epoch: 6| Step: 3
Training loss: 2.8521420242664837
Validation loss: 2.685423869697217

Epoch: 6| Step: 4
Training loss: 2.3971510428534573
Validation loss: 2.6832315717873674

Epoch: 6| Step: 5
Training loss: 3.33205328841261
Validation loss: 2.683359208979347

Epoch: 6| Step: 6
Training loss: 3.263845004244374
Validation loss: 2.678394847377901

Epoch: 6| Step: 7
Training loss: 2.7572363232653787
Validation loss: 2.67926069443682

Epoch: 6| Step: 8
Training loss: 2.664389134404675
Validation loss: 2.6795282196069903

Epoch: 6| Step: 9
Training loss: 3.3766667524251774
Validation loss: 2.6749251952362822

Epoch: 6| Step: 10
Training loss: 2.480632530272096
Validation loss: 2.673566212352803

Epoch: 6| Step: 11
Training loss: 2.4494165465385898
Validation loss: 2.6732206172281434

Epoch: 6| Step: 12
Training loss: 2.821307653971281
Validation loss: 2.6723385235897537

Epoch: 6| Step: 13
Training loss: 2.624199790693039
Validation loss: 2.6685884127509625

Epoch: 54| Step: 0
Training loss: 2.790788901578955
Validation loss: 2.6718483639108856

Epoch: 6| Step: 1
Training loss: 2.510469829159984
Validation loss: 2.6659784223594776

Epoch: 6| Step: 2
Training loss: 2.852440267835136
Validation loss: 2.6623499671321205

Epoch: 6| Step: 3
Training loss: 2.9635054994509256
Validation loss: 2.6626726330352986

Epoch: 6| Step: 4
Training loss: 3.110860651773232
Validation loss: 2.6609475279533408

Epoch: 6| Step: 5
Training loss: 3.1434668593567237
Validation loss: 2.6644792873975547

Epoch: 6| Step: 6
Training loss: 3.228703488182154
Validation loss: 2.6594877369313408

Epoch: 6| Step: 7
Training loss: 2.4398690473092155
Validation loss: 2.656895921747867

Epoch: 6| Step: 8
Training loss: 3.022246685661463
Validation loss: 2.6578533345142454

Epoch: 6| Step: 9
Training loss: 2.6877365895304783
Validation loss: 2.656735544145461

Epoch: 6| Step: 10
Training loss: 2.9700218287221287
Validation loss: 2.6572245137876074

Epoch: 6| Step: 11
Training loss: 2.719961839015519
Validation loss: 2.657138197258019

Epoch: 6| Step: 12
Training loss: 2.3882156897154467
Validation loss: 2.656799274574777

Epoch: 6| Step: 13
Training loss: 2.313962010295137
Validation loss: 2.657041992596493

Epoch: 55| Step: 0
Training loss: 2.939625721676983
Validation loss: 2.664928500616142

Epoch: 6| Step: 1
Training loss: 2.6506020132056167
Validation loss: 2.6599849248043035

Epoch: 6| Step: 2
Training loss: 2.916856668732239
Validation loss: 2.652931975886746

Epoch: 6| Step: 3
Training loss: 2.6031501210112244
Validation loss: 2.6489603957391816

Epoch: 6| Step: 4
Training loss: 3.270502417928143
Validation loss: 2.6492586916379297

Epoch: 6| Step: 5
Training loss: 2.955232060287545
Validation loss: 2.6473325451757095

Epoch: 6| Step: 6
Training loss: 2.697771714095637
Validation loss: 2.6450031259586777

Epoch: 6| Step: 7
Training loss: 2.864320241232802
Validation loss: 2.643028264170141

Epoch: 6| Step: 8
Training loss: 2.642767854971794
Validation loss: 2.643976496139453

Epoch: 6| Step: 9
Training loss: 2.3287905567382654
Validation loss: 2.6416438016493595

Epoch: 6| Step: 10
Training loss: 2.6787462722389246
Validation loss: 2.640689442768056

Epoch: 6| Step: 11
Training loss: 2.8957352290013483
Validation loss: 2.6386216519101247

Epoch: 6| Step: 12
Training loss: 2.655054429209354
Validation loss: 2.640136869258981

Epoch: 6| Step: 13
Training loss: 2.8674080163624787
Validation loss: 2.636969027473677

Epoch: 56| Step: 0
Training loss: 3.6224665503474607
Validation loss: 2.634810793946397

Epoch: 6| Step: 1
Training loss: 2.6638138730550907
Validation loss: 2.6344226927869094

Epoch: 6| Step: 2
Training loss: 2.413475483752642
Validation loss: 2.635109583236661

Epoch: 6| Step: 3
Training loss: 2.3408975154795897
Validation loss: 2.6335225341124424

Epoch: 6| Step: 4
Training loss: 2.9596214892687227
Validation loss: 2.632406035458317

Epoch: 6| Step: 5
Training loss: 3.111768864930363
Validation loss: 2.6332408884778675

Epoch: 6| Step: 6
Training loss: 2.8002836458405183
Validation loss: 2.645474001496017

Epoch: 6| Step: 7
Training loss: 2.551622144068568
Validation loss: 2.6524926781920333

Epoch: 6| Step: 8
Training loss: 2.577501903721932
Validation loss: 2.6353093955984717

Epoch: 6| Step: 9
Training loss: 2.8499540626437625
Validation loss: 2.6246158227899525

Epoch: 6| Step: 10
Training loss: 2.7256357973650718
Validation loss: 2.621410746765615

Epoch: 6| Step: 11
Training loss: 2.8147448587740804
Validation loss: 2.622272755002154

Epoch: 6| Step: 12
Training loss: 2.5794809185933527
Validation loss: 2.622915151493119

Epoch: 6| Step: 13
Training loss: 2.616787552521553
Validation loss: 2.6276094091922015

Epoch: 57| Step: 0
Training loss: 3.0384379630209586
Validation loss: 2.6311271095120627

Epoch: 6| Step: 1
Training loss: 2.114981314754689
Validation loss: 2.6370440021108688

Epoch: 6| Step: 2
Training loss: 2.4550592851181463
Validation loss: 2.6412882225928582

Epoch: 6| Step: 3
Training loss: 2.87699787547935
Validation loss: 2.642269141832499

Epoch: 6| Step: 4
Training loss: 2.7827974793480164
Validation loss: 2.642733106746394

Epoch: 6| Step: 5
Training loss: 2.732808825325172
Validation loss: 2.6481258992972463

Epoch: 6| Step: 6
Training loss: 2.6878142062304744
Validation loss: 2.652012560415275

Epoch: 6| Step: 7
Training loss: 2.514679251176501
Validation loss: 2.6390974603734763

Epoch: 6| Step: 8
Training loss: 2.936573937720489
Validation loss: 2.632576800775082

Epoch: 6| Step: 9
Training loss: 2.6870266697152423
Validation loss: 2.629831771836906

Epoch: 6| Step: 10
Training loss: 2.879116097285406
Validation loss: 2.6269674043137314

Epoch: 6| Step: 11
Training loss: 2.841060834126578
Validation loss: 2.6221046071381955

Epoch: 6| Step: 12
Training loss: 3.1483110350395895
Validation loss: 2.6216488140086036

Epoch: 6| Step: 13
Training loss: 2.9562535743611122
Validation loss: 2.6177164634480174

Epoch: 58| Step: 0
Training loss: 2.607100906333167
Validation loss: 2.6174243421286465

Epoch: 6| Step: 1
Training loss: 2.9365073616848796
Validation loss: 2.618608383197613

Epoch: 6| Step: 2
Training loss: 3.248352513524975
Validation loss: 2.6162818822180247

Epoch: 6| Step: 3
Training loss: 2.7340002184562904
Validation loss: 2.615702998533875

Epoch: 6| Step: 4
Training loss: 2.301723423321808
Validation loss: 2.6157284289670137

Epoch: 6| Step: 5
Training loss: 3.0302377170691153
Validation loss: 2.6137209428765042

Epoch: 6| Step: 6
Training loss: 2.6475504512140335
Validation loss: 2.6132826489120258

Epoch: 6| Step: 7
Training loss: 2.495177576935536
Validation loss: 2.6125619579798385

Epoch: 6| Step: 8
Training loss: 2.7031064777070433
Validation loss: 2.612748331681836

Epoch: 6| Step: 9
Training loss: 2.687249460296761
Validation loss: 2.608704775930197

Epoch: 6| Step: 10
Training loss: 2.556971098055092
Validation loss: 2.60719508257501

Epoch: 6| Step: 11
Training loss: 2.644701638078588
Validation loss: 2.6063637480700628

Epoch: 6| Step: 12
Training loss: 2.7763680462428324
Validation loss: 2.6048831005067195

Epoch: 6| Step: 13
Training loss: 3.019629473155832
Validation loss: 2.600724017375905

Epoch: 59| Step: 0
Training loss: 2.87320487328984
Validation loss: 2.602712795048449

Epoch: 6| Step: 1
Training loss: 2.957565279552169
Validation loss: 2.6033354437164595

Epoch: 6| Step: 2
Training loss: 2.286134898279698
Validation loss: 2.599416907656677

Epoch: 6| Step: 3
Training loss: 2.9488855034716845
Validation loss: 2.5994173356834165

Epoch: 6| Step: 4
Training loss: 2.8070620205193606
Validation loss: 2.5975617432193663

Epoch: 6| Step: 5
Training loss: 3.0223994087032873
Validation loss: 2.5966793737928975

Epoch: 6| Step: 6
Training loss: 2.6852833677540846
Validation loss: 2.5957689355870293

Epoch: 6| Step: 7
Training loss: 2.4038883856951694
Validation loss: 2.595946504096559

Epoch: 6| Step: 8
Training loss: 2.7214191532436898
Validation loss: 2.5919481016308663

Epoch: 6| Step: 9
Training loss: 2.8039294735341884
Validation loss: 2.591808435011349

Epoch: 6| Step: 10
Training loss: 2.380183536280729
Validation loss: 2.590344855695948

Epoch: 6| Step: 11
Training loss: 2.555723207843976
Validation loss: 2.5878805676150876

Epoch: 6| Step: 12
Training loss: 2.74781712681218
Validation loss: 2.5880410204677315

Epoch: 6| Step: 13
Training loss: 2.949551473884585
Validation loss: 2.586829747052047

Epoch: 60| Step: 0
Training loss: 2.877316412483832
Validation loss: 2.5927161182262677

Epoch: 6| Step: 1
Training loss: 3.1135115975010335
Validation loss: 2.614043986909914

Epoch: 6| Step: 2
Training loss: 2.877926042371292
Validation loss: 2.6053824269846944

Epoch: 6| Step: 3
Training loss: 2.601289110453379
Validation loss: 2.5832492342970266

Epoch: 6| Step: 4
Training loss: 2.821972725528925
Validation loss: 2.5812250784224315

Epoch: 6| Step: 5
Training loss: 2.934957824611961
Validation loss: 2.581192195759271

Epoch: 6| Step: 6
Training loss: 2.5469270478529533
Validation loss: 2.583521010646947

Epoch: 6| Step: 7
Training loss: 2.684227037182193
Validation loss: 2.5860537592174575

Epoch: 6| Step: 8
Training loss: 2.938404674417676
Validation loss: 2.586923601385655

Epoch: 6| Step: 9
Training loss: 2.6569746936228977
Validation loss: 2.589315138964402

Epoch: 6| Step: 10
Training loss: 2.0305767410757234
Validation loss: 2.587580302124207

Epoch: 6| Step: 11
Training loss: 3.081089818787428
Validation loss: 2.5863729918882044

Epoch: 6| Step: 12
Training loss: 2.278019119544169
Validation loss: 2.590659909076421

Epoch: 6| Step: 13
Training loss: 2.7173963662805267
Validation loss: 2.5891582872639654

Epoch: 61| Step: 0
Training loss: 2.8273064709177116
Validation loss: 2.592281983201698

Epoch: 6| Step: 1
Training loss: 2.555978058244733
Validation loss: 2.5894748584209117

Epoch: 6| Step: 2
Training loss: 2.91540529132663
Validation loss: 2.5897968761715036

Epoch: 6| Step: 3
Training loss: 2.4796644934468524
Validation loss: 2.5898152115344097

Epoch: 6| Step: 4
Training loss: 3.044380771206245
Validation loss: 2.5898439648044627

Epoch: 6| Step: 5
Training loss: 2.5360603307473157
Validation loss: 2.58680272681802

Epoch: 6| Step: 6
Training loss: 2.4562983306711366
Validation loss: 2.585979664930347

Epoch: 6| Step: 7
Training loss: 2.3097011021040776
Validation loss: 2.586546658070331

Epoch: 6| Step: 8
Training loss: 2.8471773056167646
Validation loss: 2.583256956222463

Epoch: 6| Step: 9
Training loss: 2.9952811639984334
Validation loss: 2.5805463729364697

Epoch: 6| Step: 10
Training loss: 2.695850263382246
Validation loss: 2.579108357014313

Epoch: 6| Step: 11
Training loss: 2.95118076164074
Validation loss: 2.5779083777463403

Epoch: 6| Step: 12
Training loss: 2.54081332363892
Validation loss: 2.57408838708996

Epoch: 6| Step: 13
Training loss: 2.7894233876176244
Validation loss: 2.572158861467007

Epoch: 62| Step: 0
Training loss: 2.465115346318362
Validation loss: 2.571164114727306

Epoch: 6| Step: 1
Training loss: 2.6675453129274103
Validation loss: 2.5768994973272155

Epoch: 6| Step: 2
Training loss: 2.933115832617053
Validation loss: 2.574218842617838

Epoch: 6| Step: 3
Training loss: 2.121737387777783
Validation loss: 2.5758203088716383

Epoch: 6| Step: 4
Training loss: 3.4656583737967
Validation loss: 2.5694715830655603

Epoch: 6| Step: 5
Training loss: 2.7202599377404604
Validation loss: 2.573339517623836

Epoch: 6| Step: 6
Training loss: 2.6202586815072126
Validation loss: 2.5761873458309075

Epoch: 6| Step: 7
Training loss: 2.3085635936852307
Validation loss: 2.5787815683651223

Epoch: 6| Step: 8
Training loss: 3.26186099170572
Validation loss: 2.5883006182574513

Epoch: 6| Step: 9
Training loss: 2.632052620370445
Validation loss: 2.5793570454906694

Epoch: 6| Step: 10
Training loss: 1.8628069835850578
Validation loss: 2.5719489054916935

Epoch: 6| Step: 11
Training loss: 2.870242287115003
Validation loss: 2.564482983863006

Epoch: 6| Step: 12
Training loss: 2.8376641179823197
Validation loss: 2.5643289908362394

Epoch: 6| Step: 13
Training loss: 2.8051711491612106
Validation loss: 2.5611602645974063

Epoch: 63| Step: 0
Training loss: 2.3811523657780267
Validation loss: 2.561662521590596

Epoch: 6| Step: 1
Training loss: 3.1488769830325953
Validation loss: 2.5623264719196013

Epoch: 6| Step: 2
Training loss: 2.5136523360861633
Validation loss: 2.5625453185129183

Epoch: 6| Step: 3
Training loss: 1.9252176137017398
Validation loss: 2.5604050143799015

Epoch: 6| Step: 4
Training loss: 2.963111904383287
Validation loss: 2.5614964295530607

Epoch: 6| Step: 5
Training loss: 2.6379347420314536
Validation loss: 2.55925778224187

Epoch: 6| Step: 6
Training loss: 2.9420854207389704
Validation loss: 2.5596659580734284

Epoch: 6| Step: 7
Training loss: 2.5660647276804043
Validation loss: 2.561602629177794

Epoch: 6| Step: 8
Training loss: 2.471782897699427
Validation loss: 2.555229090717621

Epoch: 6| Step: 9
Training loss: 2.1622112632666286
Validation loss: 2.55713119055118

Epoch: 6| Step: 10
Training loss: 2.7867681218193985
Validation loss: 2.55268148042982

Epoch: 6| Step: 11
Training loss: 2.783883380409498
Validation loss: 2.551448187649167

Epoch: 6| Step: 12
Training loss: 2.891028793587425
Validation loss: 2.55281315443367

Epoch: 6| Step: 13
Training loss: 3.3849597485626988
Validation loss: 2.5518881171682977

Epoch: 64| Step: 0
Training loss: 2.6821603292266563
Validation loss: 2.5522332024198535

Epoch: 6| Step: 1
Training loss: 2.9108056899086026
Validation loss: 2.547487399812883

Epoch: 6| Step: 2
Training loss: 2.5479884609817494
Validation loss: 2.5476452339508953

Epoch: 6| Step: 3
Training loss: 2.717076455162019
Validation loss: 2.548364995240374

Epoch: 6| Step: 4
Training loss: 2.7370567032526143
Validation loss: 2.547003385900277

Epoch: 6| Step: 5
Training loss: 2.7969409785666643
Validation loss: 2.551320383638934

Epoch: 6| Step: 6
Training loss: 2.4516735277873005
Validation loss: 2.545862960226815

Epoch: 6| Step: 7
Training loss: 2.7191018063284633
Validation loss: 2.5449401667443294

Epoch: 6| Step: 8
Training loss: 2.3594399752733115
Validation loss: 2.540578176544752

Epoch: 6| Step: 9
Training loss: 2.51106597818571
Validation loss: 2.5453866303453943

Epoch: 6| Step: 10
Training loss: 3.0210377240368436
Validation loss: 2.5453234668212077

Epoch: 6| Step: 11
Training loss: 2.9131499387978588
Validation loss: 2.539769908465645

Epoch: 6| Step: 12
Training loss: 2.74505326377458
Validation loss: 2.5398697259490457

Epoch: 6| Step: 13
Training loss: 2.3013732873815878
Validation loss: 2.539597815789686

Epoch: 65| Step: 0
Training loss: 2.956270994470741
Validation loss: 2.5406472136717793

Epoch: 6| Step: 1
Training loss: 3.1092331436999583
Validation loss: 2.5394649558346

Epoch: 6| Step: 2
Training loss: 2.7341702629824534
Validation loss: 2.5432918126561352

Epoch: 6| Step: 3
Training loss: 2.5098069480729905
Validation loss: 2.5389134289923323

Epoch: 6| Step: 4
Training loss: 3.266127844247788
Validation loss: 2.5389322883278203

Epoch: 6| Step: 5
Training loss: 2.489647985494095
Validation loss: 2.5375655392856844

Epoch: 6| Step: 6
Training loss: 2.40328241633826
Validation loss: 2.5397098596320133

Epoch: 6| Step: 7
Training loss: 2.046139184448064
Validation loss: 2.5390943711065623

Epoch: 6| Step: 8
Training loss: 2.4876365125759774
Validation loss: 2.5463357054104296

Epoch: 6| Step: 9
Training loss: 3.1937511705370287
Validation loss: 2.5577380741813145

Epoch: 6| Step: 10
Training loss: 2.366416679754789
Validation loss: 2.548163651613063

Epoch: 6| Step: 11
Training loss: 2.688889077959851
Validation loss: 2.5421513319422284

Epoch: 6| Step: 12
Training loss: 2.5776710804236718
Validation loss: 2.535039224064105

Epoch: 6| Step: 13
Training loss: 2.319270558289047
Validation loss: 2.5319632479002636

Epoch: 66| Step: 0
Training loss: 2.513962379866014
Validation loss: 2.538001737803933

Epoch: 6| Step: 1
Training loss: 2.151328510312511
Validation loss: 2.5363561203641085

Epoch: 6| Step: 2
Training loss: 2.9111021821497425
Validation loss: 2.5340015385509416

Epoch: 6| Step: 3
Training loss: 2.4657218807705275
Validation loss: 2.537365969671349

Epoch: 6| Step: 4
Training loss: 2.6794194123538375
Validation loss: 2.535365115174229

Epoch: 6| Step: 5
Training loss: 2.0484178857860886
Validation loss: 2.53556608033046

Epoch: 6| Step: 6
Training loss: 3.0230151135227414
Validation loss: 2.533566360882365

Epoch: 6| Step: 7
Training loss: 2.2209192336922627
Validation loss: 2.533031025425072

Epoch: 6| Step: 8
Training loss: 2.8849203369143135
Validation loss: 2.5342318079298196

Epoch: 6| Step: 9
Training loss: 2.814300977736058
Validation loss: 2.5325602370313125

Epoch: 6| Step: 10
Training loss: 3.0276634785798713
Validation loss: 2.5341453241212437

Epoch: 6| Step: 11
Training loss: 2.732205909336257
Validation loss: 2.5349284943095762

Epoch: 6| Step: 12
Training loss: 2.702263667300492
Validation loss: 2.5374050110073987

Epoch: 6| Step: 13
Training loss: 2.967675908184805
Validation loss: 2.5314422346045924

Epoch: 67| Step: 0
Training loss: 2.3320099847229763
Validation loss: 2.5357691293896436

Epoch: 6| Step: 1
Training loss: 2.7227515227233257
Validation loss: 2.538164874135221

Epoch: 6| Step: 2
Training loss: 2.422084380912543
Validation loss: 2.537666743144673

Epoch: 6| Step: 3
Training loss: 2.531542914126089
Validation loss: 2.536882922428101

Epoch: 6| Step: 4
Training loss: 2.323160600612668
Validation loss: 2.5363051559494703

Epoch: 6| Step: 5
Training loss: 2.5656777194109144
Validation loss: 2.5322879186048324

Epoch: 6| Step: 6
Training loss: 2.527392143717753
Validation loss: 2.5289443233068507

Epoch: 6| Step: 7
Training loss: 2.686677673859999
Validation loss: 2.5268813215766843

Epoch: 6| Step: 8
Training loss: 3.2470974799145442
Validation loss: 2.5282913939137335

Epoch: 6| Step: 9
Training loss: 2.588050923691063
Validation loss: 2.528919591466834

Epoch: 6| Step: 10
Training loss: 2.857541689964942
Validation loss: 2.52743019140919

Epoch: 6| Step: 11
Training loss: 2.873634677612305
Validation loss: 2.527264616885456

Epoch: 6| Step: 12
Training loss: 2.278417213233475
Validation loss: 2.5278999388756285

Epoch: 6| Step: 13
Training loss: 3.156296229259988
Validation loss: 2.5277410683277757

Epoch: 68| Step: 0
Training loss: 2.393933568544254
Validation loss: 2.5263925891961203

Epoch: 6| Step: 1
Training loss: 2.6925494640910776
Validation loss: 2.5232559941918975

Epoch: 6| Step: 2
Training loss: 2.663086474663037
Validation loss: 2.5231914577467736

Epoch: 6| Step: 3
Training loss: 2.2500413255075338
Validation loss: 2.520239647137329

Epoch: 6| Step: 4
Training loss: 2.647726227889969
Validation loss: 2.5219075827559814

Epoch: 6| Step: 5
Training loss: 3.092458898692123
Validation loss: 2.5150749758344793

Epoch: 6| Step: 6
Training loss: 2.8627572822721365
Validation loss: 2.5254571035101994

Epoch: 6| Step: 7
Training loss: 2.6108702983688765
Validation loss: 2.5206653812250135

Epoch: 6| Step: 8
Training loss: 2.407649636376815
Validation loss: 2.5212177950243224

Epoch: 6| Step: 9
Training loss: 2.611079407447631
Validation loss: 2.5267519840297985

Epoch: 6| Step: 10
Training loss: 2.7055471516330063
Validation loss: 2.5384646293796194

Epoch: 6| Step: 11
Training loss: 2.6017693331408753
Validation loss: 2.533040924095081

Epoch: 6| Step: 12
Training loss: 2.9872390824665223
Validation loss: 2.533644262063805

Epoch: 6| Step: 13
Training loss: 2.4635896469723675
Validation loss: 2.5277396299350494

Epoch: 69| Step: 0
Training loss: 2.8789673673231895
Validation loss: 2.5262922234823364

Epoch: 6| Step: 1
Training loss: 2.6798417739278144
Validation loss: 2.529328075790907

Epoch: 6| Step: 2
Training loss: 2.5271412032740472
Validation loss: 2.5266308965725996

Epoch: 6| Step: 3
Training loss: 2.619224734737279
Validation loss: 2.5228005974486174

Epoch: 6| Step: 4
Training loss: 3.210935123934644
Validation loss: 2.5175774620889837

Epoch: 6| Step: 5
Training loss: 2.8554517168823375
Validation loss: 2.5214130008365463

Epoch: 6| Step: 6
Training loss: 1.9396880315869334
Validation loss: 2.5174074196484075

Epoch: 6| Step: 7
Training loss: 2.695557071812556
Validation loss: 2.5273396935644126

Epoch: 6| Step: 8
Training loss: 2.9468216406804166
Validation loss: 2.5229635984516587

Epoch: 6| Step: 9
Training loss: 2.6317878336570937
Validation loss: 2.5250839987401936

Epoch: 6| Step: 10
Training loss: 2.05227054832786
Validation loss: 2.518430231713975

Epoch: 6| Step: 11
Training loss: 2.545219679159236
Validation loss: 2.519585439804035

Epoch: 6| Step: 12
Training loss: 2.7113778144252367
Validation loss: 2.5171860142172044

Epoch: 6| Step: 13
Training loss: 2.4966916127947028
Validation loss: 2.5150551160330785

Epoch: 70| Step: 0
Training loss: 2.5209689983926684
Validation loss: 2.5136528419499253

Epoch: 6| Step: 1
Training loss: 2.820510815017272
Validation loss: 2.512737757629098

Epoch: 6| Step: 2
Training loss: 2.2633440835254564
Validation loss: 2.512052554369455

Epoch: 6| Step: 3
Training loss: 2.9257887469655284
Validation loss: 2.509693363401188

Epoch: 6| Step: 4
Training loss: 2.324943160315957
Validation loss: 2.5121357256745522

Epoch: 6| Step: 5
Training loss: 2.4359682601151293
Validation loss: 2.51304283857182

Epoch: 6| Step: 6
Training loss: 2.534791329427382
Validation loss: 2.5089717574249963

Epoch: 6| Step: 7
Training loss: 2.739657982412349
Validation loss: 2.508795936568126

Epoch: 6| Step: 8
Training loss: 2.7319071941446755
Validation loss: 2.511439923461963

Epoch: 6| Step: 9
Training loss: 2.5895088174849916
Validation loss: 2.5104582744859507

Epoch: 6| Step: 10
Training loss: 2.6274527943124557
Validation loss: 2.507050553950169

Epoch: 6| Step: 11
Training loss: 2.711516392706985
Validation loss: 2.510766227940421

Epoch: 6| Step: 12
Training loss: 2.5638419568455064
Validation loss: 2.505811152163914

Epoch: 6| Step: 13
Training loss: 3.071035984207347
Validation loss: 2.5079312558839617

Epoch: 71| Step: 0
Training loss: 2.7244705875830224
Validation loss: 2.5061275093923148

Epoch: 6| Step: 1
Training loss: 3.286886260903206
Validation loss: 2.5182129400151942

Epoch: 6| Step: 2
Training loss: 2.45693906480732
Validation loss: 2.5129867050673336

Epoch: 6| Step: 3
Training loss: 2.790972400327902
Validation loss: 2.5258597292056266

Epoch: 6| Step: 4
Training loss: 2.443808095880478
Validation loss: 2.517607782197595

Epoch: 6| Step: 5
Training loss: 2.0191770497536745
Validation loss: 2.5169683625055765

Epoch: 6| Step: 6
Training loss: 2.280284102290371
Validation loss: 2.5113234933238937

Epoch: 6| Step: 7
Training loss: 2.8004981074736293
Validation loss: 2.5123085290629885

Epoch: 6| Step: 8
Training loss: 2.589949063422493
Validation loss: 2.512185440489704

Epoch: 6| Step: 9
Training loss: 2.9893986626098688
Validation loss: 2.5083266431353834

Epoch: 6| Step: 10
Training loss: 2.832150792196844
Validation loss: 2.5085829267384177

Epoch: 6| Step: 11
Training loss: 2.367562443716372
Validation loss: 2.5078545365816245

Epoch: 6| Step: 12
Training loss: 2.33252489753347
Validation loss: 2.5079102383241936

Epoch: 6| Step: 13
Training loss: 2.675600187760887
Validation loss: 2.511298049965819

Epoch: 72| Step: 0
Training loss: 2.694001606035214
Validation loss: 2.5105845182873145

Epoch: 6| Step: 1
Training loss: 3.073017666121356
Validation loss: 2.5077086810432134

Epoch: 6| Step: 2
Training loss: 3.0627105017738425
Validation loss: 2.50633893636057

Epoch: 6| Step: 3
Training loss: 2.3624436588734383
Validation loss: 2.505874851780603

Epoch: 6| Step: 4
Training loss: 2.4868081132206363
Validation loss: 2.5071908213915823

Epoch: 6| Step: 5
Training loss: 2.290776363019191
Validation loss: 2.5001737375289315

Epoch: 6| Step: 6
Training loss: 2.1829976204733783
Validation loss: 2.507804054570857

Epoch: 6| Step: 7
Training loss: 2.9361380808528037
Validation loss: 2.504127988553632

Epoch: 6| Step: 8
Training loss: 2.1682383876521687
Validation loss: 2.505632619689992

Epoch: 6| Step: 9
Training loss: 2.320089721260207
Validation loss: 2.5083933521030986

Epoch: 6| Step: 10
Training loss: 2.5358029144732495
Validation loss: 2.5096186930076887

Epoch: 6| Step: 11
Training loss: 2.676501724256861
Validation loss: 2.503179657998541

Epoch: 6| Step: 12
Training loss: 2.945146227122399
Validation loss: 2.512103805175959

Epoch: 6| Step: 13
Training loss: 2.91784079397537
Validation loss: 2.506323494154672

Epoch: 73| Step: 0
Training loss: 2.792342279773321
Validation loss: 2.5048363158909464

Epoch: 6| Step: 1
Training loss: 3.1630155361781727
Validation loss: 2.5022299040448153

Epoch: 6| Step: 2
Training loss: 2.6338008304682408
Validation loss: 2.504314657102652

Epoch: 6| Step: 3
Training loss: 2.5887732501346643
Validation loss: 2.5016968372752797

Epoch: 6| Step: 4
Training loss: 2.757169048684702
Validation loss: 2.499124373633232

Epoch: 6| Step: 5
Training loss: 2.8473442754455593
Validation loss: 2.497843161660864

Epoch: 6| Step: 6
Training loss: 2.257976803196706
Validation loss: 2.504842883529832

Epoch: 6| Step: 7
Training loss: 2.5250760359693643
Validation loss: 2.506321195255514

Epoch: 6| Step: 8
Training loss: 2.374650025933612
Validation loss: 2.5055305659684857

Epoch: 6| Step: 9
Training loss: 2.9904518770913566
Validation loss: 2.498539752470163

Epoch: 6| Step: 10
Training loss: 2.907909124819833
Validation loss: 2.498279647182461

Epoch: 6| Step: 11
Training loss: 2.2720817377404434
Validation loss: 2.49672793200726

Epoch: 6| Step: 12
Training loss: 1.9798547519043679
Validation loss: 2.502005702351476

Epoch: 6| Step: 13
Training loss: 2.363605067239321
Validation loss: 2.4995260186695156

Epoch: 74| Step: 0
Training loss: 3.1694677078087237
Validation loss: 2.493694722607449

Epoch: 6| Step: 1
Training loss: 2.65467114367731
Validation loss: 2.4973632258784892

Epoch: 6| Step: 2
Training loss: 2.395356625662497
Validation loss: 2.5016894433596164

Epoch: 6| Step: 3
Training loss: 2.7715559473668874
Validation loss: 2.497104796210167

Epoch: 6| Step: 4
Training loss: 2.2228287293029245
Validation loss: 2.507411619728908

Epoch: 6| Step: 5
Training loss: 2.3781592788932646
Validation loss: 2.504026873257483

Epoch: 6| Step: 6
Training loss: 2.240701535246529
Validation loss: 2.5121220907044597

Epoch: 6| Step: 7
Training loss: 2.7483167698786897
Validation loss: 2.518638590706517

Epoch: 6| Step: 8
Training loss: 2.804311232975763
Validation loss: 2.5162315822027708

Epoch: 6| Step: 9
Training loss: 2.6540069084853726
Validation loss: 2.50100709975215

Epoch: 6| Step: 10
Training loss: 2.4430319782464207
Validation loss: 2.502693434018652

Epoch: 6| Step: 11
Training loss: 2.5624685518149346
Validation loss: 2.497922224643644

Epoch: 6| Step: 12
Training loss: 2.8264868612802263
Validation loss: 2.4975884727562696

Epoch: 6| Step: 13
Training loss: 2.7289448033975026
Validation loss: 2.4975631917673136

Epoch: 75| Step: 0
Training loss: 2.498652381077861
Validation loss: 2.4978171355520544

Epoch: 6| Step: 1
Training loss: 2.28715711848385
Validation loss: 2.50360432518921

Epoch: 6| Step: 2
Training loss: 2.4812591014474132
Validation loss: 2.5060357348651237

Epoch: 6| Step: 3
Training loss: 2.6126529411558237
Validation loss: 2.5044597741936276

Epoch: 6| Step: 4
Training loss: 2.7288561248762564
Validation loss: 2.506855846564235

Epoch: 6| Step: 5
Training loss: 2.9099111159340794
Validation loss: 2.507961011313817

Epoch: 6| Step: 6
Training loss: 2.8178753665249836
Validation loss: 2.506532447354819

Epoch: 6| Step: 7
Training loss: 2.8492274927246246
Validation loss: 2.504345359921969

Epoch: 6| Step: 8
Training loss: 2.5606857948823603
Validation loss: 2.503309094362039

Epoch: 6| Step: 9
Training loss: 2.694993329154908
Validation loss: 2.503583739523623

Epoch: 6| Step: 10
Training loss: 3.1354990258705793
Validation loss: 2.502909032781331

Epoch: 6| Step: 11
Training loss: 2.645076272942816
Validation loss: 2.500423157165508

Epoch: 6| Step: 12
Training loss: 2.3438821373884196
Validation loss: 2.502539703671543

Epoch: 6| Step: 13
Training loss: 2.202901193059243
Validation loss: 2.498289413150922

Epoch: 76| Step: 0
Training loss: 2.4778160989855254
Validation loss: 2.498418244014711

Epoch: 6| Step: 1
Training loss: 2.724760230478754
Validation loss: 2.496928394368977

Epoch: 6| Step: 2
Training loss: 2.2375416757122797
Validation loss: 2.492114999766903

Epoch: 6| Step: 3
Training loss: 2.7808901093192917
Validation loss: 2.4963349020395214

Epoch: 6| Step: 4
Training loss: 2.432249919742752
Validation loss: 2.491451318125276

Epoch: 6| Step: 5
Training loss: 2.4593879786613053
Validation loss: 2.494426745734501

Epoch: 6| Step: 6
Training loss: 2.627031539257181
Validation loss: 2.492778727877435

Epoch: 6| Step: 7
Training loss: 2.243709247187141
Validation loss: 2.4910423015370244

Epoch: 6| Step: 8
Training loss: 3.0656787179329332
Validation loss: 2.4905384471473138

Epoch: 6| Step: 9
Training loss: 2.528955997782623
Validation loss: 2.490060263138113

Epoch: 6| Step: 10
Training loss: 2.82236961516354
Validation loss: 2.490018005944327

Epoch: 6| Step: 11
Training loss: 3.03976330362705
Validation loss: 2.4889455215031973

Epoch: 6| Step: 12
Training loss: 2.546034410925872
Validation loss: 2.489878638296091

Epoch: 6| Step: 13
Training loss: 2.3044679698808017
Validation loss: 2.494985144219928

Epoch: 77| Step: 0
Training loss: 2.8022719157880895
Validation loss: 2.4883385556347832

Epoch: 6| Step: 1
Training loss: 2.9182280766103084
Validation loss: 2.4906478957364686

Epoch: 6| Step: 2
Training loss: 2.9406134156212773
Validation loss: 2.4902133596692906

Epoch: 6| Step: 3
Training loss: 2.2967918536648635
Validation loss: 2.494332342264965

Epoch: 6| Step: 4
Training loss: 2.4806144611483663
Validation loss: 2.4930208700229435

Epoch: 6| Step: 5
Training loss: 2.453821751482637
Validation loss: 2.495777060288819

Epoch: 6| Step: 6
Training loss: 2.2063208592952606
Validation loss: 2.4938615539763442

Epoch: 6| Step: 7
Training loss: 2.0992075832852186
Validation loss: 2.492826899955201

Epoch: 6| Step: 8
Training loss: 2.4182176107546374
Validation loss: 2.4931468970503134

Epoch: 6| Step: 9
Training loss: 2.2978876697120656
Validation loss: 2.4888927720338563

Epoch: 6| Step: 10
Training loss: 2.894947675848121
Validation loss: 2.490582067613387

Epoch: 6| Step: 11
Training loss: 2.778910049036929
Validation loss: 2.4916079175098105

Epoch: 6| Step: 12
Training loss: 2.731299103528984
Validation loss: 2.492820189076285

Epoch: 6| Step: 13
Training loss: 2.9347791042091957
Validation loss: 2.490569894165876

Epoch: 78| Step: 0
Training loss: 2.135366175605125
Validation loss: 2.4921045080255984

Epoch: 6| Step: 1
Training loss: 2.8741788935509547
Validation loss: 2.4941684897590632

Epoch: 6| Step: 2
Training loss: 2.8041935647824117
Validation loss: 2.4909848427491954

Epoch: 6| Step: 3
Training loss: 2.4541513033409212
Validation loss: 2.487165974629583

Epoch: 6| Step: 4
Training loss: 2.313388138414105
Validation loss: 2.4841374697585574

Epoch: 6| Step: 5
Training loss: 2.9020951627958964
Validation loss: 2.4899093914525965

Epoch: 6| Step: 6
Training loss: 2.8793310630961915
Validation loss: 2.482956575342984

Epoch: 6| Step: 7
Training loss: 2.674436891414196
Validation loss: 2.488253191555688

Epoch: 6| Step: 8
Training loss: 2.6538495156257285
Validation loss: 2.483381396560315

Epoch: 6| Step: 9
Training loss: 2.347150649785933
Validation loss: 2.481817372470469

Epoch: 6| Step: 10
Training loss: 2.1998834232308
Validation loss: 2.4826040293655183

Epoch: 6| Step: 11
Training loss: 2.7384917740154155
Validation loss: 2.4832065801679954

Epoch: 6| Step: 12
Training loss: 2.494522292553846
Validation loss: 2.4814560094425415

Epoch: 6| Step: 13
Training loss: 2.831568692020272
Validation loss: 2.4829143892975427

Epoch: 79| Step: 0
Training loss: 2.4954374641557755
Validation loss: 2.4795175726103054

Epoch: 6| Step: 1
Training loss: 2.9889539173462563
Validation loss: 2.484138173585414

Epoch: 6| Step: 2
Training loss: 2.3209957054588233
Validation loss: 2.485773144972792

Epoch: 6| Step: 3
Training loss: 2.552804141853389
Validation loss: 2.4881635924528194

Epoch: 6| Step: 4
Training loss: 2.6303792060768028
Validation loss: 2.4850150189627054

Epoch: 6| Step: 5
Training loss: 2.3603281281159805
Validation loss: 2.4865664207852984

Epoch: 6| Step: 6
Training loss: 2.4211879617111634
Validation loss: 2.479422537371409

Epoch: 6| Step: 7
Training loss: 1.982760516027091
Validation loss: 2.4843113889087998

Epoch: 6| Step: 8
Training loss: 2.522685880891615
Validation loss: 2.482308237839834

Epoch: 6| Step: 9
Training loss: 2.7194995066240257
Validation loss: 2.486947477182075

Epoch: 6| Step: 10
Training loss: 3.041632264521891
Validation loss: 2.485845086861409

Epoch: 6| Step: 11
Training loss: 2.5246384541228166
Validation loss: 2.4851990618631272

Epoch: 6| Step: 12
Training loss: 2.7073870448452144
Validation loss: 2.485858674141342

Epoch: 6| Step: 13
Training loss: 2.8547071701566433
Validation loss: 2.486624125490901

Epoch: 80| Step: 0
Training loss: 2.633876144219925
Validation loss: 2.4877270011903185

Epoch: 6| Step: 1
Training loss: 2.5163521989135487
Validation loss: 2.487024569804316

Epoch: 6| Step: 2
Training loss: 2.6047966360421917
Validation loss: 2.4886519686393216

Epoch: 6| Step: 3
Training loss: 2.5074293372712804
Validation loss: 2.4898229082039394

Epoch: 6| Step: 4
Training loss: 2.5319435205653793
Validation loss: 2.4860960079660206

Epoch: 6| Step: 5
Training loss: 2.3191977754901325
Validation loss: 2.4849207696494346

Epoch: 6| Step: 6
Training loss: 2.655096544137596
Validation loss: 2.4889331325031003

Epoch: 6| Step: 7
Training loss: 2.7034010553246026
Validation loss: 2.486808608566134

Epoch: 6| Step: 8
Training loss: 2.798962288387463
Validation loss: 2.4912655519216016

Epoch: 6| Step: 9
Training loss: 2.7992533369426864
Validation loss: 2.4840002836983848

Epoch: 6| Step: 10
Training loss: 2.476025447918053
Validation loss: 2.4877721404406974

Epoch: 6| Step: 11
Training loss: 2.7162982804018436
Validation loss: 2.4817024427012386

Epoch: 6| Step: 12
Training loss: 2.760447337621962
Validation loss: 2.4855017995736386

Epoch: 6| Step: 13
Training loss: 2.244653495436477
Validation loss: 2.483145691569158

Epoch: 81| Step: 0
Training loss: 2.2511826691839514
Validation loss: 2.4850905885309613

Epoch: 6| Step: 1
Training loss: 2.7667316011675527
Validation loss: 2.4874519471298724

Epoch: 6| Step: 2
Training loss: 2.7301287132354255
Validation loss: 2.48558552358394

Epoch: 6| Step: 3
Training loss: 2.772565677783318
Validation loss: 2.4824088931901005

Epoch: 6| Step: 4
Training loss: 2.2080350230521484
Validation loss: 2.48401485687764

Epoch: 6| Step: 5
Training loss: 2.068232228925198
Validation loss: 2.4863434037195846

Epoch: 6| Step: 6
Training loss: 2.5261591828267633
Validation loss: 2.486373872977857

Epoch: 6| Step: 7
Training loss: 2.634607806615196
Validation loss: 2.4899935098484334

Epoch: 6| Step: 8
Training loss: 2.485160271678214
Validation loss: 2.484323976900468

Epoch: 6| Step: 9
Training loss: 2.5300928932596425
Validation loss: 2.48773490780608

Epoch: 6| Step: 10
Training loss: 2.4344083301382864
Validation loss: 2.484391954152219

Epoch: 6| Step: 11
Training loss: 3.1745896021613373
Validation loss: 2.48020287237697

Epoch: 6| Step: 12
Training loss: 2.592740701299929
Validation loss: 2.4833190961297373

Epoch: 6| Step: 13
Training loss: 2.7452897567545143
Validation loss: 2.48123554382469

Epoch: 82| Step: 0
Training loss: 2.4997297140878354
Validation loss: 2.482966665639513

Epoch: 6| Step: 1
Training loss: 2.696908848484897
Validation loss: 2.4736815983775218

Epoch: 6| Step: 2
Training loss: 2.5782217296602865
Validation loss: 2.475395417014415

Epoch: 6| Step: 3
Training loss: 2.403932322204852
Validation loss: 2.4842114344720545

Epoch: 6| Step: 4
Training loss: 3.2433543116435697
Validation loss: 2.4883566884373285

Epoch: 6| Step: 5
Training loss: 2.2314586680740915
Validation loss: 2.4864388776086455

Epoch: 6| Step: 6
Training loss: 2.6122709182980883
Validation loss: 2.481350271022997

Epoch: 6| Step: 7
Training loss: 2.6669644745791032
Validation loss: 2.482456290073779

Epoch: 6| Step: 8
Training loss: 2.84811770202358
Validation loss: 2.48353795279589

Epoch: 6| Step: 9
Training loss: 2.4728215118672074
Validation loss: 2.484836303620462

Epoch: 6| Step: 10
Training loss: 2.792523285880542
Validation loss: 2.483590823997077

Epoch: 6| Step: 11
Training loss: 2.499867435755364
Validation loss: 2.482005686954005

Epoch: 6| Step: 12
Training loss: 1.9833469280877594
Validation loss: 2.479372357936894

Epoch: 6| Step: 13
Training loss: 2.4720703202155923
Validation loss: 2.4828833094382934

Epoch: 83| Step: 0
Training loss: 2.6909310373962505
Validation loss: 2.4763129235915375

Epoch: 6| Step: 1
Training loss: 2.670818097511989
Validation loss: 2.4813495023492025

Epoch: 6| Step: 2
Training loss: 2.4503572242487874
Validation loss: 2.482405515667394

Epoch: 6| Step: 3
Training loss: 2.6011332023095677
Validation loss: 2.483755246319899

Epoch: 6| Step: 4
Training loss: 2.3951139503400514
Validation loss: 2.4740961431300827

Epoch: 6| Step: 5
Training loss: 2.5648929308877055
Validation loss: 2.478775832413036

Epoch: 6| Step: 6
Training loss: 2.140406910722641
Validation loss: 2.476879256054949

Epoch: 6| Step: 7
Training loss: 3.1637033517715047
Validation loss: 2.48054138237451

Epoch: 6| Step: 8
Training loss: 1.9873603531823008
Validation loss: 2.483371131937867

Epoch: 6| Step: 9
Training loss: 2.37213061818669
Validation loss: 2.4781465648917043

Epoch: 6| Step: 10
Training loss: 2.9358908933276817
Validation loss: 2.4875478976317185

Epoch: 6| Step: 11
Training loss: 2.0366165867135755
Validation loss: 2.4772159103535953

Epoch: 6| Step: 12
Training loss: 2.928715007864377
Validation loss: 2.4751733680654757

Epoch: 6| Step: 13
Training loss: 2.8331231057955764
Validation loss: 2.4790450047578867

Epoch: 84| Step: 0
Training loss: 2.1725478193597456
Validation loss: 2.473171363275801

Epoch: 6| Step: 1
Training loss: 2.4642923406349957
Validation loss: 2.4810696412203685

Epoch: 6| Step: 2
Training loss: 2.85813101301764
Validation loss: 2.483655509488836

Epoch: 6| Step: 3
Training loss: 2.365451087757212
Validation loss: 2.4681417464352036

Epoch: 6| Step: 4
Training loss: 3.0655346840591973
Validation loss: 2.4804892872037763

Epoch: 6| Step: 5
Training loss: 2.6334830768679534
Validation loss: 2.476326643405815

Epoch: 6| Step: 6
Training loss: 2.832999565062538
Validation loss: 2.4786999260427347

Epoch: 6| Step: 7
Training loss: 2.152011187939119
Validation loss: 2.4782681212560402

Epoch: 6| Step: 8
Training loss: 1.9375746927938104
Validation loss: 2.4746033212557084

Epoch: 6| Step: 9
Training loss: 2.4978595153362235
Validation loss: 2.4812132671721634

Epoch: 6| Step: 10
Training loss: 2.9602190016586207
Validation loss: 2.476904282917782

Epoch: 6| Step: 11
Training loss: 2.837309702403154
Validation loss: 2.4745973076409475

Epoch: 6| Step: 12
Training loss: 2.8149742263508437
Validation loss: 2.4766916267434507

Epoch: 6| Step: 13
Training loss: 2.310029643475458
Validation loss: 2.477716395720682

Epoch: 85| Step: 0
Training loss: 2.7715520763125934
Validation loss: 2.4784038289024752

Epoch: 6| Step: 1
Training loss: 1.9666805592816718
Validation loss: 2.4792574751008054

Epoch: 6| Step: 2
Training loss: 2.5486821976904492
Validation loss: 2.476360998771005

Epoch: 6| Step: 3
Training loss: 2.7716953017207815
Validation loss: 2.474095797818805

Epoch: 6| Step: 4
Training loss: 2.8706710400451336
Validation loss: 2.4740505375327384

Epoch: 6| Step: 5
Training loss: 2.7445565882467915
Validation loss: 2.4764937622928294

Epoch: 6| Step: 6
Training loss: 2.8555809656473037
Validation loss: 2.4709367845137913

Epoch: 6| Step: 7
Training loss: 2.2234421666324886
Validation loss: 2.4782444069289142

Epoch: 6| Step: 8
Training loss: 2.8740504811524956
Validation loss: 2.4714769440767284

Epoch: 6| Step: 9
Training loss: 2.649997488056648
Validation loss: 2.476018017463474

Epoch: 6| Step: 10
Training loss: 2.6887742503698417
Validation loss: 2.4729620818220974

Epoch: 6| Step: 11
Training loss: 2.573529395736566
Validation loss: 2.471237474640366

Epoch: 6| Step: 12
Training loss: 2.307942719811501
Validation loss: 2.475677139438132

Epoch: 6| Step: 13
Training loss: 2.0967392719758924
Validation loss: 2.472109910530732

Epoch: 86| Step: 0
Training loss: 2.9520130788932057
Validation loss: 2.479120307510288

Epoch: 6| Step: 1
Training loss: 2.544696273816693
Validation loss: 2.4755726951229895

Epoch: 6| Step: 2
Training loss: 2.2178914732872466
Validation loss: 2.4836136393047155

Epoch: 6| Step: 3
Training loss: 2.7445976772679628
Validation loss: 2.485166427621844

Epoch: 6| Step: 4
Training loss: 2.727420354951275
Validation loss: 2.4793621969184945

Epoch: 6| Step: 5
Training loss: 3.187716009263198
Validation loss: 2.48292579208347

Epoch: 6| Step: 6
Training loss: 2.9902088605214545
Validation loss: 2.4737916883592943

Epoch: 6| Step: 7
Training loss: 2.6416239457230994
Validation loss: 2.480674306607427

Epoch: 6| Step: 8
Training loss: 1.985670612929178
Validation loss: 2.474466256988729

Epoch: 6| Step: 9
Training loss: 2.1087094987870327
Validation loss: 2.4731887798361445

Epoch: 6| Step: 10
Training loss: 2.2592862609067326
Validation loss: 2.475785319007073

Epoch: 6| Step: 11
Training loss: 2.0143604895636935
Validation loss: 2.4750236118359163

Epoch: 6| Step: 12
Training loss: 2.621673474392921
Validation loss: 2.471919741026714

Epoch: 6| Step: 13
Training loss: 2.684251551959234
Validation loss: 2.4733296261380047

Epoch: 87| Step: 0
Training loss: 2.8360686468901006
Validation loss: 2.4683105141947714

Epoch: 6| Step: 1
Training loss: 2.7610922700412677
Validation loss: 2.471082382344847

Epoch: 6| Step: 2
Training loss: 2.843637149793387
Validation loss: 2.4706563228954037

Epoch: 6| Step: 3
Training loss: 2.2651219302741272
Validation loss: 2.465196941883163

Epoch: 6| Step: 4
Training loss: 2.4313893138520446
Validation loss: 2.4769715975068736

Epoch: 6| Step: 5
Training loss: 2.340369265837354
Validation loss: 2.471639109599582

Epoch: 6| Step: 6
Training loss: 2.239196377230457
Validation loss: 2.4796958860701426

Epoch: 6| Step: 7
Training loss: 2.314593012320547
Validation loss: 2.477122551361869

Epoch: 6| Step: 8
Training loss: 2.541969020765784
Validation loss: 2.4745418998031594

Epoch: 6| Step: 9
Training loss: 2.4197638385391573
Validation loss: 2.476490248339173

Epoch: 6| Step: 10
Training loss: 2.8757339867457166
Validation loss: 2.4805323875454084

Epoch: 6| Step: 11
Training loss: 2.9099143932636657
Validation loss: 2.4717716283841282

Epoch: 6| Step: 12
Training loss: 2.5622333294812534
Validation loss: 2.4793060861915968

Epoch: 6| Step: 13
Training loss: 2.6815734988241413
Validation loss: 2.4813876635127574

Epoch: 88| Step: 0
Training loss: 3.0565325148113707
Validation loss: 2.4763361910679724

Epoch: 6| Step: 1
Training loss: 2.676512680881675
Validation loss: 2.4786040899282336

Epoch: 6| Step: 2
Training loss: 2.091214594931774
Validation loss: 2.477614731786491

Epoch: 6| Step: 3
Training loss: 2.5218472504064007
Validation loss: 2.4816877358539005

Epoch: 6| Step: 4
Training loss: 2.5844073882835312
Validation loss: 2.478453386636066

Epoch: 6| Step: 5
Training loss: 1.901617330545837
Validation loss: 2.4728307516786407

Epoch: 6| Step: 6
Training loss: 3.1136203327538325
Validation loss: 2.470007499704031

Epoch: 6| Step: 7
Training loss: 2.060125428982927
Validation loss: 2.4726245430133287

Epoch: 6| Step: 8
Training loss: 2.8640542021369497
Validation loss: 2.4744631014745155

Epoch: 6| Step: 9
Training loss: 2.68118244432828
Validation loss: 2.4654886134677727

Epoch: 6| Step: 10
Training loss: 2.59396048921187
Validation loss: 2.476111666843104

Epoch: 6| Step: 11
Training loss: 2.7101533398759687
Validation loss: 2.4739138522248467

Epoch: 6| Step: 12
Training loss: 2.549745217853022
Validation loss: 2.4750169008493557

Epoch: 6| Step: 13
Training loss: 2.18973340053475
Validation loss: 2.4785869358667023

Epoch: 89| Step: 0
Training loss: 2.516732392705454
Validation loss: 2.4745966091293403

Epoch: 6| Step: 1
Training loss: 2.2444169394798013
Validation loss: 2.4771530778935618

Epoch: 6| Step: 2
Training loss: 2.6745549197118175
Validation loss: 2.4770523693907536

Epoch: 6| Step: 3
Training loss: 2.570377801222152
Validation loss: 2.4681256788466497

Epoch: 6| Step: 4
Training loss: 3.5379591141791784
Validation loss: 2.472307595435026

Epoch: 6| Step: 5
Training loss: 1.9434028045555545
Validation loss: 2.4724423605767454

Epoch: 6| Step: 6
Training loss: 2.4953216648112653
Validation loss: 2.475170815478378

Epoch: 6| Step: 7
Training loss: 2.1733311224655107
Validation loss: 2.47793560290463

Epoch: 6| Step: 8
Training loss: 2.1781722513817527
Validation loss: 2.477451040718937

Epoch: 6| Step: 9
Training loss: 3.0930711405996707
Validation loss: 2.475170719154285

Epoch: 6| Step: 10
Training loss: 2.4845160678183507
Validation loss: 2.4792747847973

Epoch: 6| Step: 11
Training loss: 2.326530166309067
Validation loss: 2.4760393779542387

Epoch: 6| Step: 12
Training loss: 3.0463891840253887
Validation loss: 2.4706449278158

Epoch: 6| Step: 13
Training loss: 2.0737127056757774
Validation loss: 2.4769885862906547

Epoch: 90| Step: 0
Training loss: 2.5543626117895917
Validation loss: 2.467687595506267

Epoch: 6| Step: 1
Training loss: 2.9130713692331835
Validation loss: 2.463891878834654

Epoch: 6| Step: 2
Training loss: 2.6724673501313934
Validation loss: 2.4671984597611556

Epoch: 6| Step: 3
Training loss: 2.7286211783896
Validation loss: 2.475081232452537

Epoch: 6| Step: 4
Training loss: 2.548096533535154
Validation loss: 2.468306795407302

Epoch: 6| Step: 5
Training loss: 2.629482529211678
Validation loss: 2.468491665486166

Epoch: 6| Step: 6
Training loss: 2.6266408968724764
Validation loss: 2.476853386676137

Epoch: 6| Step: 7
Training loss: 2.4974657565376397
Validation loss: 2.478437241601664

Epoch: 6| Step: 8
Training loss: 2.4753570029437584
Validation loss: 2.473576298713309

Epoch: 6| Step: 9
Training loss: 1.887253079463272
Validation loss: 2.478886104918259

Epoch: 6| Step: 10
Training loss: 2.6429333951988876
Validation loss: 2.475287252511778

Epoch: 6| Step: 11
Training loss: 2.959238657081485
Validation loss: 2.4720309543081

Epoch: 6| Step: 12
Training loss: 2.308619052083479
Validation loss: 2.4736205074477633

Epoch: 6| Step: 13
Training loss: 2.3463901145854282
Validation loss: 2.467992038502209

Epoch: 91| Step: 0
Training loss: 1.7734568590628392
Validation loss: 2.4662174803904655

Epoch: 6| Step: 1
Training loss: 2.5312155262047713
Validation loss: 2.473844221729246

Epoch: 6| Step: 2
Training loss: 2.58069237696616
Validation loss: 2.4672766365182492

Epoch: 6| Step: 3
Training loss: 2.801907407397487
Validation loss: 2.4676497619256335

Epoch: 6| Step: 4
Training loss: 2.918827691361364
Validation loss: 2.4663808214538037

Epoch: 6| Step: 5
Training loss: 2.677131879987282
Validation loss: 2.4713349631353614

Epoch: 6| Step: 6
Training loss: 2.4788552630951965
Validation loss: 2.476849632585693

Epoch: 6| Step: 7
Training loss: 2.357017096760519
Validation loss: 2.4744732665517057

Epoch: 6| Step: 8
Training loss: 2.4174210478110556
Validation loss: 2.474543136276195

Epoch: 6| Step: 9
Training loss: 2.416190286797412
Validation loss: 2.4777705859130736

Epoch: 6| Step: 10
Training loss: 2.6792070052539714
Validation loss: 2.47565540665185

Epoch: 6| Step: 11
Training loss: 2.2484544107889404
Validation loss: 2.4767371676650267

Epoch: 6| Step: 12
Training loss: 3.1739957888406414
Validation loss: 2.481998674649016

Epoch: 6| Step: 13
Training loss: 2.5120037860416624
Validation loss: 2.4705810195041003

Epoch: 92| Step: 0
Training loss: 2.613724698017675
Validation loss: 2.4722408691041156

Epoch: 6| Step: 1
Training loss: 1.4769386740771817
Validation loss: 2.47038974307423

Epoch: 6| Step: 2
Training loss: 2.609382492328783
Validation loss: 2.469029487209235

Epoch: 6| Step: 3
Training loss: 2.2451302493571212
Validation loss: 2.4689996649452333

Epoch: 6| Step: 4
Training loss: 2.264298886213116
Validation loss: 2.4638909353754013

Epoch: 6| Step: 5
Training loss: 2.7765813497355376
Validation loss: 2.4629155519995254

Epoch: 6| Step: 6
Training loss: 2.6796798483514115
Validation loss: 2.473025615277193

Epoch: 6| Step: 7
Training loss: 2.8513230314689277
Validation loss: 2.4651279033778355

Epoch: 6| Step: 8
Training loss: 2.4514943917552854
Validation loss: 2.4743616732355456

Epoch: 6| Step: 9
Training loss: 1.9773664686449528
Validation loss: 2.469729619484977

Epoch: 6| Step: 10
Training loss: 2.2861038199651342
Validation loss: 2.465378676545091

Epoch: 6| Step: 11
Training loss: 3.1067945037647804
Validation loss: 2.4515675745875667

Epoch: 6| Step: 12
Training loss: 2.9645029306846027
Validation loss: 2.466463341795804

Epoch: 6| Step: 13
Training loss: 3.007279623809334
Validation loss: 2.4691720432768403

Epoch: 93| Step: 0
Training loss: 2.6061776496486804
Validation loss: 2.4625615246182195

Epoch: 6| Step: 1
Training loss: 2.6371562679541967
Validation loss: 2.4642359351427925

Epoch: 6| Step: 2
Training loss: 2.7537493721939184
Validation loss: 2.4624826253158627

Epoch: 6| Step: 3
Training loss: 1.8157187196373652
Validation loss: 2.4713582935573477

Epoch: 6| Step: 4
Training loss: 2.421140300922375
Validation loss: 2.4595263275031956

Epoch: 6| Step: 5
Training loss: 2.410470209430973
Validation loss: 2.463960645558513

Epoch: 6| Step: 6
Training loss: 2.724571572318398
Validation loss: 2.463448106684117

Epoch: 6| Step: 7
Training loss: 2.5756604986375713
Validation loss: 2.468245305812662

Epoch: 6| Step: 8
Training loss: 2.7607846764505415
Validation loss: 2.464206167744506

Epoch: 6| Step: 9
Training loss: 2.2866232312176376
Validation loss: 2.4716447365273004

Epoch: 6| Step: 10
Training loss: 2.643631256539107
Validation loss: 2.4706899047015374

Epoch: 6| Step: 11
Training loss: 2.817562633045021
Validation loss: 2.4698916020977264

Epoch: 6| Step: 12
Training loss: 2.784641555374577
Validation loss: 2.4718960542099677

Epoch: 6| Step: 13
Training loss: 2.208467323508851
Validation loss: 2.4686435080951283

Epoch: 94| Step: 0
Training loss: 3.0205087596991724
Validation loss: 2.4678739127992535

Epoch: 6| Step: 1
Training loss: 2.5045804977168244
Validation loss: 2.4716982077783025

Epoch: 6| Step: 2
Training loss: 2.6657297952317904
Validation loss: 2.4595892548289218

Epoch: 6| Step: 3
Training loss: 2.441328221409333
Validation loss: 2.4630546464788465

Epoch: 6| Step: 4
Training loss: 2.47431685142093
Validation loss: 2.462299789319346

Epoch: 6| Step: 5
Training loss: 2.057016655290278
Validation loss: 2.468591355002847

Epoch: 6| Step: 6
Training loss: 2.286504885489998
Validation loss: 2.4623384393663432

Epoch: 6| Step: 7
Training loss: 2.3965232740259372
Validation loss: 2.4631942493300145

Epoch: 6| Step: 8
Training loss: 2.731854830536299
Validation loss: 2.4611712470886977

Epoch: 6| Step: 9
Training loss: 2.581407341768389
Validation loss: 2.46623272257684

Epoch: 6| Step: 10
Training loss: 2.485616889385969
Validation loss: 2.4626027603783305

Epoch: 6| Step: 11
Training loss: 2.3862060395753053
Validation loss: 2.4651459812400884

Epoch: 6| Step: 12
Training loss: 2.62156070466798
Validation loss: 2.469301838101175

Epoch: 6| Step: 13
Training loss: 3.014921906884863
Validation loss: 2.4681776002862454

Epoch: 95| Step: 0
Training loss: 2.388046469736272
Validation loss: 2.4727976328207104

Epoch: 6| Step: 1
Training loss: 2.8677518949145746
Validation loss: 2.472352976026094

Epoch: 6| Step: 2
Training loss: 2.5609994542167107
Validation loss: 2.471552356829867

Epoch: 6| Step: 3
Training loss: 2.57818363007434
Validation loss: 2.466607786025699

Epoch: 6| Step: 4
Training loss: 2.3500327777605725
Validation loss: 2.462272491853798

Epoch: 6| Step: 5
Training loss: 2.5978276934730653
Validation loss: 2.459712471402059

Epoch: 6| Step: 6
Training loss: 2.652644594010394
Validation loss: 2.459766298968125

Epoch: 6| Step: 7
Training loss: 2.1653189747025796
Validation loss: 2.460048502854835

Epoch: 6| Step: 8
Training loss: 2.53327841782863
Validation loss: 2.4633929723231542

Epoch: 6| Step: 9
Training loss: 2.7941637590459374
Validation loss: 2.460424452491304

Epoch: 6| Step: 10
Training loss: 2.3003750039268396
Validation loss: 2.4612993246844517

Epoch: 6| Step: 11
Training loss: 2.6164945225876086
Validation loss: 2.456907575493721

Epoch: 6| Step: 12
Training loss: 2.795889568947688
Validation loss: 2.454236015890056

Epoch: 6| Step: 13
Training loss: 2.3985305420165757
Validation loss: 2.4681505932241294

Epoch: 96| Step: 0
Training loss: 2.3298729600777204
Validation loss: 2.4767491684448864

Epoch: 6| Step: 1
Training loss: 2.224211512380655
Validation loss: 2.4753253947636775

Epoch: 6| Step: 2
Training loss: 3.0299270731896595
Validation loss: 2.4681999784923736

Epoch: 6| Step: 3
Training loss: 3.008260005011446
Validation loss: 2.4647777486066462

Epoch: 6| Step: 4
Training loss: 2.784327743591643
Validation loss: 2.4731533842439855

Epoch: 6| Step: 5
Training loss: 2.364786573461737
Validation loss: 2.468390281641919

Epoch: 6| Step: 6
Training loss: 2.768146464612799
Validation loss: 2.4715349448155117

Epoch: 6| Step: 7
Training loss: 2.446985227165324
Validation loss: 2.469950179010711

Epoch: 6| Step: 8
Training loss: 2.3375370328692977
Validation loss: 2.4636470995245414

Epoch: 6| Step: 9
Training loss: 2.632478958871768
Validation loss: 2.461829985398885

Epoch: 6| Step: 10
Training loss: 2.30147978406767
Validation loss: 2.4620849517784236

Epoch: 6| Step: 11
Training loss: 2.445313865003113
Validation loss: 2.4668699904575324

Epoch: 6| Step: 12
Training loss: 3.0852291018399014
Validation loss: 2.455822524517372

Epoch: 6| Step: 13
Training loss: 1.9522529180980968
Validation loss: 2.4619371271118533

Epoch: 97| Step: 0
Training loss: 2.4104824741868205
Validation loss: 2.463464511257241

Epoch: 6| Step: 1
Training loss: 2.895357289510802
Validation loss: 2.4553327891145234

Epoch: 6| Step: 2
Training loss: 2.677145416687761
Validation loss: 2.460029781802229

Epoch: 6| Step: 3
Training loss: 2.450106178629828
Validation loss: 2.461023254515105

Epoch: 6| Step: 4
Training loss: 2.2759232712132884
Validation loss: 2.4590211622634013

Epoch: 6| Step: 5
Training loss: 2.449339649191604
Validation loss: 2.4648106044307987

Epoch: 6| Step: 6
Training loss: 2.1680775108205945
Validation loss: 2.4625785724736344

Epoch: 6| Step: 7
Training loss: 2.549174388297255
Validation loss: 2.4707127748082307

Epoch: 6| Step: 8
Training loss: 2.1701985207735883
Validation loss: 2.4676761625637016

Epoch: 6| Step: 9
Training loss: 2.79141930770062
Validation loss: 2.4646951960127548

Epoch: 6| Step: 10
Training loss: 1.982247421030115
Validation loss: 2.465124308744752

Epoch: 6| Step: 11
Training loss: 2.8219751756361604
Validation loss: 2.470245536075138

Epoch: 6| Step: 12
Training loss: 2.884424436069106
Validation loss: 2.467857618044664

Epoch: 6| Step: 13
Training loss: 2.9291145273038572
Validation loss: 2.4701583321978995

Epoch: 98| Step: 0
Training loss: 2.73059134146739
Validation loss: 2.472016005065075

Epoch: 6| Step: 1
Training loss: 2.313192933885421
Validation loss: 2.463366437060653

Epoch: 6| Step: 2
Training loss: 2.574011185053404
Validation loss: 2.463958750628774

Epoch: 6| Step: 3
Training loss: 2.4644515848510204
Validation loss: 2.4596051843150666

Epoch: 6| Step: 4
Training loss: 2.8851930460480224
Validation loss: 2.458638597921213

Epoch: 6| Step: 5
Training loss: 3.073630212386506
Validation loss: 2.4658249052401535

Epoch: 6| Step: 6
Training loss: 2.1953533345290306
Validation loss: 2.464010316388509

Epoch: 6| Step: 7
Training loss: 2.377613336406851
Validation loss: 2.469365425500031

Epoch: 6| Step: 8
Training loss: 2.651513757746607
Validation loss: 2.4580154752251935

Epoch: 6| Step: 9
Training loss: 1.8666781444991412
Validation loss: 2.4613133461367305

Epoch: 6| Step: 10
Training loss: 2.1111338876309826
Validation loss: 2.4564160343445476

Epoch: 6| Step: 11
Training loss: 2.749561968510031
Validation loss: 2.45650403340637

Epoch: 6| Step: 12
Training loss: 2.9872686128910413
Validation loss: 2.4553290830387753

Epoch: 6| Step: 13
Training loss: 2.4304214791753234
Validation loss: 2.4604308076000483

Epoch: 99| Step: 0
Training loss: 2.588575417946515
Validation loss: 2.4629884438748904

Epoch: 6| Step: 1
Training loss: 2.5203294066437354
Validation loss: 2.4632175923292774

Epoch: 6| Step: 2
Training loss: 2.214767104879748
Validation loss: 2.4654330734507304

Epoch: 6| Step: 3
Training loss: 2.360495497040109
Validation loss: 2.463326375531637

Epoch: 6| Step: 4
Training loss: 1.9433239190782554
Validation loss: 2.465980787437511

Epoch: 6| Step: 5
Training loss: 2.732565668124965
Validation loss: 2.471828207544861

Epoch: 6| Step: 6
Training loss: 3.2050976145335985
Validation loss: 2.470922471915746

Epoch: 6| Step: 7
Training loss: 2.286590282714023
Validation loss: 2.476277267765509

Epoch: 6| Step: 8
Training loss: 2.780013163007132
Validation loss: 2.471737956778607

Epoch: 6| Step: 9
Training loss: 2.7369195923762644
Validation loss: 2.4721488894136283

Epoch: 6| Step: 10
Training loss: 2.357351180362173
Validation loss: 2.4681336160552707

Epoch: 6| Step: 11
Training loss: 2.4664567364034684
Validation loss: 2.469153093675568

Epoch: 6| Step: 12
Training loss: 2.257859490245496
Validation loss: 2.4714965993652163

Epoch: 6| Step: 13
Training loss: 3.003721789585946
Validation loss: 2.467922152370848

Epoch: 100| Step: 0
Training loss: 2.83700869167692
Validation loss: 2.46650598642739

Epoch: 6| Step: 1
Training loss: 2.3209505071002035
Validation loss: 2.4591598710711993

Epoch: 6| Step: 2
Training loss: 2.7295699270570695
Validation loss: 2.4584867919826725

Epoch: 6| Step: 3
Training loss: 2.9347410841014394
Validation loss: 2.4630476528188314

Epoch: 6| Step: 4
Training loss: 2.838420023046957
Validation loss: 2.4484855369622127

Epoch: 6| Step: 5
Training loss: 2.971728788002182
Validation loss: 2.4576637250523166

Epoch: 6| Step: 6
Training loss: 2.4421662879457076
Validation loss: 2.4434930778531823

Epoch: 6| Step: 7
Training loss: 2.2100580306223323
Validation loss: 2.46261770222076

Epoch: 6| Step: 8
Training loss: 2.3743808340797736
Validation loss: 2.456085831815665

Epoch: 6| Step: 9
Training loss: 2.1217325558835847
Validation loss: 2.4636012601734922

Epoch: 6| Step: 10
Training loss: 1.7304551100354786
Validation loss: 2.4673355895604754

Epoch: 6| Step: 11
Training loss: 3.0992884526877886
Validation loss: 2.4601022423067174

Epoch: 6| Step: 12
Training loss: 2.5054783877124036
Validation loss: 2.4660962001447815

Epoch: 6| Step: 13
Training loss: 2.338792771845909
Validation loss: 2.470350350386146

Epoch: 101| Step: 0
Training loss: 2.265504820694569
Validation loss: 2.459188689656041

Epoch: 6| Step: 1
Training loss: 2.778267708064167
Validation loss: 2.467268970345063

Epoch: 6| Step: 2
Training loss: 2.3915494241011834
Validation loss: 2.4595020447182443

Epoch: 6| Step: 3
Training loss: 2.3061996413111108
Validation loss: 2.4696428961790455

Epoch: 6| Step: 4
Training loss: 2.797370824072895
Validation loss: 2.4585550310633493

Epoch: 6| Step: 5
Training loss: 2.587460164671094
Validation loss: 2.4606816557444313

Epoch: 6| Step: 6
Training loss: 3.0948160820024344
Validation loss: 2.458475372823139

Epoch: 6| Step: 7
Training loss: 2.20328158640536
Validation loss: 2.453531008933678

Epoch: 6| Step: 8
Training loss: 2.5904386593717152
Validation loss: 2.4567131155929163

Epoch: 6| Step: 9
Training loss: 2.701831574330381
Validation loss: 2.4622084307839036

Epoch: 6| Step: 10
Training loss: 2.776401451132884
Validation loss: 2.4568491890010087

Epoch: 6| Step: 11
Training loss: 2.4915139175935783
Validation loss: 2.4558300079859947

Epoch: 6| Step: 12
Training loss: 2.7772066535860116
Validation loss: 2.461074712248286

Epoch: 6| Step: 13
Training loss: 1.9916608525700745
Validation loss: 2.464419707807718

Epoch: 102| Step: 0
Training loss: 2.630215323158771
Validation loss: 2.464975070427525

Epoch: 6| Step: 1
Training loss: 3.4161811731791096
Validation loss: 2.4601845371481206

Epoch: 6| Step: 2
Training loss: 2.44991923997081
Validation loss: 2.4639613228947472

Epoch: 6| Step: 3
Training loss: 2.4548334866242967
Validation loss: 2.462236721468183

Epoch: 6| Step: 4
Training loss: 2.646739944561415
Validation loss: 2.4669025606906856

Epoch: 6| Step: 5
Training loss: 2.4588042201554394
Validation loss: 2.4650850978887258

Epoch: 6| Step: 6
Training loss: 2.4544307853745013
Validation loss: 2.4669589535345073

Epoch: 6| Step: 7
Training loss: 2.301219749438345
Validation loss: 2.4519020887582266

Epoch: 6| Step: 8
Training loss: 2.6984909997704802
Validation loss: 2.4620221689394937

Epoch: 6| Step: 9
Training loss: 2.2158788452218365
Validation loss: 2.4614386396444914

Epoch: 6| Step: 10
Training loss: 2.276728499519093
Validation loss: 2.457498931444724

Epoch: 6| Step: 11
Training loss: 1.834037934355045
Validation loss: 2.4587526987433024

Epoch: 6| Step: 12
Training loss: 2.730597890002031
Validation loss: 2.46480718667166

Epoch: 6| Step: 13
Training loss: 2.75329972750804
Validation loss: 2.4626218652665415

Epoch: 103| Step: 0
Training loss: 2.8062615613125743
Validation loss: 2.4606642394763996

Epoch: 6| Step: 1
Training loss: 2.4188806542882477
Validation loss: 2.4640382638536407

Epoch: 6| Step: 2
Training loss: 2.95653357405867
Validation loss: 2.4687651863113933

Epoch: 6| Step: 3
Training loss: 2.5187898239887345
Validation loss: 2.4701428890210777

Epoch: 6| Step: 4
Training loss: 2.649308413105017
Validation loss: 2.470810493076336

Epoch: 6| Step: 5
Training loss: 2.3841212946354426
Validation loss: 2.4711800055977964

Epoch: 6| Step: 6
Training loss: 2.015400482211595
Validation loss: 2.468975845500988

Epoch: 6| Step: 7
Training loss: 2.7544736020742557
Validation loss: 2.473770766258622

Epoch: 6| Step: 8
Training loss: 2.3358036883248228
Validation loss: 2.469386312513058

Epoch: 6| Step: 9
Training loss: 2.750896394459991
Validation loss: 2.469584537242143

Epoch: 6| Step: 10
Training loss: 2.592476497679724
Validation loss: 2.4631541446696428

Epoch: 6| Step: 11
Training loss: 2.246486463630354
Validation loss: 2.4617179157946127

Epoch: 6| Step: 12
Training loss: 2.675722887279798
Validation loss: 2.471053839156305

Epoch: 6| Step: 13
Training loss: 2.6190952920084074
Validation loss: 2.461357702479023

Epoch: 104| Step: 0
Training loss: 3.2967428027220755
Validation loss: 2.464891307309549

Epoch: 6| Step: 1
Training loss: 2.6413682422086637
Validation loss: 2.4665247147112788

Epoch: 6| Step: 2
Training loss: 3.099832124163831
Validation loss: 2.4647875505862866

Epoch: 6| Step: 3
Training loss: 2.7419342184878186
Validation loss: 2.4754119510944963

Epoch: 6| Step: 4
Training loss: 2.3327827712334623
Validation loss: 2.4635386530808665

Epoch: 6| Step: 5
Training loss: 2.432463896464854
Validation loss: 2.461047191294516

Epoch: 6| Step: 6
Training loss: 2.7881622998791746
Validation loss: 2.4650571461721427

Epoch: 6| Step: 7
Training loss: 2.2136377889668823
Validation loss: 2.4580662280519543

Epoch: 6| Step: 8
Training loss: 1.9388012361919602
Validation loss: 2.4649202603950906

Epoch: 6| Step: 9
Training loss: 2.328658586838439
Validation loss: 2.4924963876282926

Epoch: 6| Step: 10
Training loss: 2.302077027279141
Validation loss: 2.482442139933758

Epoch: 6| Step: 11
Training loss: 2.6354762335718696
Validation loss: 2.475908347458966

Epoch: 6| Step: 12
Training loss: 2.457228611720193
Validation loss: 2.4741066068420023

Epoch: 6| Step: 13
Training loss: 2.088793224935308
Validation loss: 2.469545067347556

Epoch: 105| Step: 0
Training loss: 2.5984044424444193
Validation loss: 2.4678555087355623

Epoch: 6| Step: 1
Training loss: 2.682730590067567
Validation loss: 2.4694620787504995

Epoch: 6| Step: 2
Training loss: 2.3662866067850783
Validation loss: 2.4756485047669563

Epoch: 6| Step: 3
Training loss: 2.1307905624845196
Validation loss: 2.4618611292865133

Epoch: 6| Step: 4
Training loss: 2.49408594607742
Validation loss: 2.464301531802132

Epoch: 6| Step: 5
Training loss: 3.082833498744531
Validation loss: 2.459397850592908

Epoch: 6| Step: 6
Training loss: 2.880885526894011
Validation loss: 2.462115035327197

Epoch: 6| Step: 7
Training loss: 2.279532216923183
Validation loss: 2.4541992459512154

Epoch: 6| Step: 8
Training loss: 2.475051370723389
Validation loss: 2.4594542377896302

Epoch: 6| Step: 9
Training loss: 2.447932877723638
Validation loss: 2.4590947836161265

Epoch: 6| Step: 10
Training loss: 2.222610768152846
Validation loss: 2.4501231428586006

Epoch: 6| Step: 11
Training loss: 2.5423058086642656
Validation loss: 2.4644457480130284

Epoch: 6| Step: 12
Training loss: 2.960088200414954
Validation loss: 2.4545997916387376

Epoch: 6| Step: 13
Training loss: 2.386452418075373
Validation loss: 2.4629367841186047

Epoch: 106| Step: 0
Training loss: 2.515033154733587
Validation loss: 2.460954978921166

Epoch: 6| Step: 1
Training loss: 2.4051588482651587
Validation loss: 2.4570427324747426

Epoch: 6| Step: 2
Training loss: 2.8978537411214598
Validation loss: 2.4653059520514398

Epoch: 6| Step: 3
Training loss: 2.144031125867571
Validation loss: 2.4609973072676414

Epoch: 6| Step: 4
Training loss: 2.761644850717438
Validation loss: 2.4626609297835125

Epoch: 6| Step: 5
Training loss: 2.1358532591073986
Validation loss: 2.4633953596762215

Epoch: 6| Step: 6
Training loss: 2.764279916686114
Validation loss: 2.4642409823420595

Epoch: 6| Step: 7
Training loss: 2.7458167770727884
Validation loss: 2.4604118472016303

Epoch: 6| Step: 8
Training loss: 2.5929253427723133
Validation loss: 2.463287281239106

Epoch: 6| Step: 9
Training loss: 2.400890375916395
Validation loss: 2.4625659782103884

Epoch: 6| Step: 10
Training loss: 2.5838050001516355
Validation loss: 2.455043407064213

Epoch: 6| Step: 11
Training loss: 2.5081621443248285
Validation loss: 2.465968984018492

Epoch: 6| Step: 12
Training loss: 2.256280927366861
Validation loss: 2.466594141031401

Epoch: 6| Step: 13
Training loss: 2.696913533913447
Validation loss: 2.466003983206934

Epoch: 107| Step: 0
Training loss: 2.59721345497687
Validation loss: 2.469826169995061

Epoch: 6| Step: 1
Training loss: 2.8559010565899756
Validation loss: 2.4687029113785535

Epoch: 6| Step: 2
Training loss: 2.444933487157128
Validation loss: 2.4566935442105953

Epoch: 6| Step: 3
Training loss: 2.5576998714381514
Validation loss: 2.4535354465266384

Epoch: 6| Step: 4
Training loss: 2.93576582994979
Validation loss: 2.4662417453911942

Epoch: 6| Step: 5
Training loss: 1.859998710590859
Validation loss: 2.4573910787820807

Epoch: 6| Step: 6
Training loss: 2.1635148770530748
Validation loss: 2.457942120625635

Epoch: 6| Step: 7
Training loss: 2.4136464769712855
Validation loss: 2.460176986165996

Epoch: 6| Step: 8
Training loss: 2.804453380450914
Validation loss: 2.4578718840709888

Epoch: 6| Step: 9
Training loss: 2.456637158348196
Validation loss: 2.456872462896685

Epoch: 6| Step: 10
Training loss: 2.6727546894552225
Validation loss: 2.4563649805026486

Epoch: 6| Step: 11
Training loss: 1.8430162683225326
Validation loss: 2.464303353906633

Epoch: 6| Step: 12
Training loss: 2.8027397341793274
Validation loss: 2.4721374931770095

Epoch: 6| Step: 13
Training loss: 2.786990296159761
Validation loss: 2.4640117677938096

Epoch: 108| Step: 0
Training loss: 2.434825114210873
Validation loss: 2.451848963705321

Epoch: 6| Step: 1
Training loss: 2.55417294234417
Validation loss: 2.4591189734697703

Epoch: 6| Step: 2
Training loss: 2.578817655976688
Validation loss: 2.456088921957397

Epoch: 6| Step: 3
Training loss: 2.488876966133776
Validation loss: 2.4602019810396034

Epoch: 6| Step: 4
Training loss: 1.9084292602860902
Validation loss: 2.4504666351151614

Epoch: 6| Step: 5
Training loss: 2.0188706164156276
Validation loss: 2.4563164007191944

Epoch: 6| Step: 6
Training loss: 2.443529350290268
Validation loss: 2.4567723949029254

Epoch: 6| Step: 7
Training loss: 3.18191233037399
Validation loss: 2.458452914179834

Epoch: 6| Step: 8
Training loss: 2.4905370909757356
Validation loss: 2.454972116411693

Epoch: 6| Step: 9
Training loss: 2.6011282526916437
Validation loss: 2.4573752885610007

Epoch: 6| Step: 10
Training loss: 2.6741163880006207
Validation loss: 2.466553624458282

Epoch: 6| Step: 11
Training loss: 2.2998940484894828
Validation loss: 2.450457910965643

Epoch: 6| Step: 12
Training loss: 2.891755413998502
Validation loss: 2.4599457695263567

Epoch: 6| Step: 13
Training loss: 2.5511496775824813
Validation loss: 2.4516404634895466

Epoch: 109| Step: 0
Training loss: 1.9703768109346729
Validation loss: 2.453906281090815

Epoch: 6| Step: 1
Training loss: 2.75185825679831
Validation loss: 2.4688420499871246

Epoch: 6| Step: 2
Training loss: 2.62680990403029
Validation loss: 2.4631200487418923

Epoch: 6| Step: 3
Training loss: 2.482817827606727
Validation loss: 2.468257098346112

Epoch: 6| Step: 4
Training loss: 2.9026102223525077
Validation loss: 2.460078950509282

Epoch: 6| Step: 5
Training loss: 2.4593047038675064
Validation loss: 2.468091160547162

Epoch: 6| Step: 6
Training loss: 2.2714031332875924
Validation loss: 2.4638885807575703

Epoch: 6| Step: 7
Training loss: 2.5707947994499496
Validation loss: 2.4655503571545143

Epoch: 6| Step: 8
Training loss: 2.442878071974967
Validation loss: 2.4645836033395043

Epoch: 6| Step: 9
Training loss: 2.903499162787147
Validation loss: 2.4593101651258675

Epoch: 6| Step: 10
Training loss: 2.8744045138435372
Validation loss: 2.452779603846806

Epoch: 6| Step: 11
Training loss: 2.402538062200019
Validation loss: 2.4592757169854993

Epoch: 6| Step: 12
Training loss: 1.8999549860390401
Validation loss: 2.4539421971961297

Epoch: 6| Step: 13
Training loss: 2.454203568997701
Validation loss: 2.452184671032747

Epoch: 110| Step: 0
Training loss: 2.5812883794485217
Validation loss: 2.4544969192944546

Epoch: 6| Step: 1
Training loss: 2.6174793593094736
Validation loss: 2.457804547568016

Epoch: 6| Step: 2
Training loss: 2.527714461859923
Validation loss: 2.459938403575707

Epoch: 6| Step: 3
Training loss: 2.526918920927356
Validation loss: 2.454135484178902

Epoch: 6| Step: 4
Training loss: 2.4983842396740163
Validation loss: 2.4601740061463517

Epoch: 6| Step: 5
Training loss: 2.3257571474465957
Validation loss: 2.4623114247417894

Epoch: 6| Step: 6
Training loss: 2.358087251403029
Validation loss: 2.4592820992993305

Epoch: 6| Step: 7
Training loss: 2.3875067825620486
Validation loss: 2.458762993415409

Epoch: 6| Step: 8
Training loss: 2.1692177963337174
Validation loss: 2.4691551938296263

Epoch: 6| Step: 9
Training loss: 2.6290567930289526
Validation loss: 2.4663687057787294

Epoch: 6| Step: 10
Training loss: 2.886344090411251
Validation loss: 2.464680951964535

Epoch: 6| Step: 11
Training loss: 2.9392769491432156
Validation loss: 2.4562963246772997

Epoch: 6| Step: 12
Training loss: 2.355296266228303
Validation loss: 2.4541444867032602

Epoch: 6| Step: 13
Training loss: 2.4303760595497397
Validation loss: 2.460758553916871

Epoch: 111| Step: 0
Training loss: 2.7472812911950677
Validation loss: 2.465999487482633

Epoch: 6| Step: 1
Training loss: 2.5968713937084806
Validation loss: 2.4655983682087808

Epoch: 6| Step: 2
Training loss: 2.2472345523419994
Validation loss: 2.461078869831147

Epoch: 6| Step: 3
Training loss: 2.099384640043793
Validation loss: 2.465381867863363

Epoch: 6| Step: 4
Training loss: 2.5227811449876842
Validation loss: 2.4645935673204273

Epoch: 6| Step: 5
Training loss: 2.5273988414107604
Validation loss: 2.461759754849469

Epoch: 6| Step: 6
Training loss: 3.2159699220721656
Validation loss: 2.4636116636196794

Epoch: 6| Step: 7
Training loss: 2.175550246517435
Validation loss: 2.4539385861777503

Epoch: 6| Step: 8
Training loss: 2.2255313024639913
Validation loss: 2.463168308819772

Epoch: 6| Step: 9
Training loss: 2.3092491394351926
Validation loss: 2.4532135544524007

Epoch: 6| Step: 10
Training loss: 2.1662276141049537
Validation loss: 2.4612297409357846

Epoch: 6| Step: 11
Training loss: 2.525851485706204
Validation loss: 2.4574795846100796

Epoch: 6| Step: 12
Training loss: 3.3279794294014997
Validation loss: 2.448982077261308

Epoch: 6| Step: 13
Training loss: 2.203020458581848
Validation loss: 2.457873274433124

Epoch: 112| Step: 0
Training loss: 1.819904461752992
Validation loss: 2.460646403216933

Epoch: 6| Step: 1
Training loss: 2.6071090453431944
Validation loss: 2.455835040100181

Epoch: 6| Step: 2
Training loss: 2.219829672731658
Validation loss: 2.4578702512028263

Epoch: 6| Step: 3
Training loss: 2.209538856484083
Validation loss: 2.466205138339665

Epoch: 6| Step: 4
Training loss: 1.8144209317902242
Validation loss: 2.4537142392164912

Epoch: 6| Step: 5
Training loss: 2.6092569472967972
Validation loss: 2.4625306719759372

Epoch: 6| Step: 6
Training loss: 2.419689348947537
Validation loss: 2.4639860939205263

Epoch: 6| Step: 7
Training loss: 3.336737579242559
Validation loss: 2.4528064399456775

Epoch: 6| Step: 8
Training loss: 3.133735958230719
Validation loss: 2.466689686624833

Epoch: 6| Step: 9
Training loss: 2.3969919029484212
Validation loss: 2.468090774145555

Epoch: 6| Step: 10
Training loss: 2.10639505764113
Validation loss: 2.470611289105568

Epoch: 6| Step: 11
Training loss: 2.357764294272477
Validation loss: 2.460120074435321

Epoch: 6| Step: 12
Training loss: 2.658389587365191
Validation loss: 2.4572280942405076

Epoch: 6| Step: 13
Training loss: 2.9696573577414105
Validation loss: 2.450057588276732

Epoch: 113| Step: 0
Training loss: 2.506832703847252
Validation loss: 2.4555383947280074

Epoch: 6| Step: 1
Training loss: 2.363223341555502
Validation loss: 2.4569280508714155

Epoch: 6| Step: 2
Training loss: 2.9686529846401535
Validation loss: 2.465373132022714

Epoch: 6| Step: 3
Training loss: 2.2825064138633637
Validation loss: 2.4612036021237604

Epoch: 6| Step: 4
Training loss: 2.3265595773610652
Validation loss: 2.458534852081941

Epoch: 6| Step: 5
Training loss: 2.668723495316048
Validation loss: 2.4712221668446688

Epoch: 6| Step: 6
Training loss: 2.0256288658700767
Validation loss: 2.464311287301678

Epoch: 6| Step: 7
Training loss: 2.111075725872341
Validation loss: 2.4691344094677223

Epoch: 6| Step: 8
Training loss: 2.6881175551481022
Validation loss: 2.454317730289785

Epoch: 6| Step: 9
Training loss: 1.8985882608966782
Validation loss: 2.461530640183534

Epoch: 6| Step: 10
Training loss: 2.53271752661259
Validation loss: 2.4623636462935226

Epoch: 6| Step: 11
Training loss: 2.926568000653867
Validation loss: 2.4638449473466535

Epoch: 6| Step: 12
Training loss: 3.043850850465234
Validation loss: 2.454413089999

Epoch: 6| Step: 13
Training loss: 2.4541453772389463
Validation loss: 2.4599305126150686

Epoch: 114| Step: 0
Training loss: 2.162450417187227
Validation loss: 2.4600420579183795

Epoch: 6| Step: 1
Training loss: 2.1228100206755705
Validation loss: 2.457388135809501

Epoch: 6| Step: 2
Training loss: 2.5182588424959094
Validation loss: 2.4504509381100514

Epoch: 6| Step: 3
Training loss: 2.4877543947113754
Validation loss: 2.446808614272816

Epoch: 6| Step: 4
Training loss: 2.3713117370451418
Validation loss: 2.4517867939388704

Epoch: 6| Step: 5
Training loss: 2.7429897080470695
Validation loss: 2.4560780174608485

Epoch: 6| Step: 6
Training loss: 2.203211248346397
Validation loss: 2.45071490360823

Epoch: 6| Step: 7
Training loss: 2.2055521912419658
Validation loss: 2.4603440472391487

Epoch: 6| Step: 8
Training loss: 2.3099609044717595
Validation loss: 2.4527749623788546

Epoch: 6| Step: 9
Training loss: 3.677238540327606
Validation loss: 2.4635269911949265

Epoch: 6| Step: 10
Training loss: 1.9162581948380697
Validation loss: 2.4554742146114723

Epoch: 6| Step: 11
Training loss: 2.6115106306303377
Validation loss: 2.460256443949309

Epoch: 6| Step: 12
Training loss: 2.436956296094517
Validation loss: 2.4554484191046377

Epoch: 6| Step: 13
Training loss: 2.728145194661662
Validation loss: 2.4637467592664177

Epoch: 115| Step: 0
Training loss: 2.7221240449791524
Validation loss: 2.464472142664799

Epoch: 6| Step: 1
Training loss: 2.7821735177518385
Validation loss: 2.460322615085325

Epoch: 6| Step: 2
Training loss: 2.3452017801823595
Validation loss: 2.4614680449985267

Epoch: 6| Step: 3
Training loss: 2.8011949305502517
Validation loss: 2.4560319883031987

Epoch: 6| Step: 4
Training loss: 2.464924903174495
Validation loss: 2.45787055029262

Epoch: 6| Step: 5
Training loss: 2.823453723077657
Validation loss: 2.4597194987772073

Epoch: 6| Step: 6
Training loss: 2.416219593217915
Validation loss: 2.462893577531562

Epoch: 6| Step: 7
Training loss: 2.228633412784687
Validation loss: 2.470372724995319

Epoch: 6| Step: 8
Training loss: 2.0761809469977597
Validation loss: 2.4635927760902807

Epoch: 6| Step: 9
Training loss: 2.2971272232768114
Validation loss: 2.462302984628073

Epoch: 6| Step: 10
Training loss: 2.2989803707816336
Validation loss: 2.4614530638903247

Epoch: 6| Step: 11
Training loss: 2.451577542844175
Validation loss: 2.4534804619160893

Epoch: 6| Step: 12
Training loss: 2.605702814343425
Validation loss: 2.458689636875489

Epoch: 6| Step: 13
Training loss: 2.6047775976094028
Validation loss: 2.4663332445313313

Epoch: 116| Step: 0
Training loss: 2.3153645069049507
Validation loss: 2.4594166087694718

Epoch: 6| Step: 1
Training loss: 2.575014492105239
Validation loss: 2.461594613965783

Epoch: 6| Step: 2
Training loss: 2.022119512616211
Validation loss: 2.467599785927928

Epoch: 6| Step: 3
Training loss: 2.3371796128310414
Validation loss: 2.4597528098777524

Epoch: 6| Step: 4
Training loss: 2.4544242771176488
Validation loss: 2.4695471752135583

Epoch: 6| Step: 5
Training loss: 2.3487860932959705
Validation loss: 2.476656922988242

Epoch: 6| Step: 6
Training loss: 2.9806468105498047
Validation loss: 2.4776074825187426

Epoch: 6| Step: 7
Training loss: 2.403416439088615
Validation loss: 2.473055597873477

Epoch: 6| Step: 8
Training loss: 2.0408512615113694
Validation loss: 2.475390232032575

Epoch: 6| Step: 9
Training loss: 2.9767792390025076
Validation loss: 2.4639027729405414

Epoch: 6| Step: 10
Training loss: 2.558478759045273
Validation loss: 2.460408068024686

Epoch: 6| Step: 11
Training loss: 2.7532522737179668
Validation loss: 2.4618176213518628

Epoch: 6| Step: 12
Training loss: 2.6558379807405132
Validation loss: 2.465045870289027

Epoch: 6| Step: 13
Training loss: 2.34431115108507
Validation loss: 2.4668809922213764

Epoch: 117| Step: 0
Training loss: 2.4139128703438266
Validation loss: 2.477533384804541

Epoch: 6| Step: 1
Training loss: 2.5436367675173117
Validation loss: 2.4639680156118113

Epoch: 6| Step: 2
Training loss: 3.3030968844427098
Validation loss: 2.4678772297025224

Epoch: 6| Step: 3
Training loss: 2.5340180509025196
Validation loss: 2.4659989073885775

Epoch: 6| Step: 4
Training loss: 3.0822520207189537
Validation loss: 2.4612645653454654

Epoch: 6| Step: 5
Training loss: 2.333372615301898
Validation loss: 2.4600789989667873

Epoch: 6| Step: 6
Training loss: 2.377823406249117
Validation loss: 2.4577898513128726

Epoch: 6| Step: 7
Training loss: 2.734608144357439
Validation loss: 2.459275555407719

Epoch: 6| Step: 8
Training loss: 2.707255212455943
Validation loss: 2.4650990494487517

Epoch: 6| Step: 9
Training loss: 2.283156343083603
Validation loss: 2.4680985665662747

Epoch: 6| Step: 10
Training loss: 2.416493201333255
Validation loss: 2.4789429705272785

Epoch: 6| Step: 11
Training loss: 1.8735940748489146
Validation loss: 2.4835195128097536

Epoch: 6| Step: 12
Training loss: 2.1233068340370655
Validation loss: 2.4564976600507973

Epoch: 6| Step: 13
Training loss: 2.132642131330793
Validation loss: 2.457657952935501

Epoch: 118| Step: 0
Training loss: 2.143133322765513
Validation loss: 2.4589696696364136

Epoch: 6| Step: 1
Training loss: 2.5740355453941652
Validation loss: 2.459534874081711

Epoch: 6| Step: 2
Training loss: 2.631428793588673
Validation loss: 2.4641801895099085

Epoch: 6| Step: 3
Training loss: 2.11745054293077
Validation loss: 2.4782092599225725

Epoch: 6| Step: 4
Training loss: 2.7500456025937488
Validation loss: 2.4671455674476452

Epoch: 6| Step: 5
Training loss: 2.733454958217888
Validation loss: 2.4559853434648273

Epoch: 6| Step: 6
Training loss: 2.603750963728237
Validation loss: 2.469273716870512

Epoch: 6| Step: 7
Training loss: 2.3641291334767267
Validation loss: 2.4631376896321378

Epoch: 6| Step: 8
Training loss: 2.227096975324604
Validation loss: 2.4702224203499887

Epoch: 6| Step: 9
Training loss: 2.9584086950311543
Validation loss: 2.4565293810807383

Epoch: 6| Step: 10
Training loss: 2.6103480004009083
Validation loss: 2.466003677046758

Epoch: 6| Step: 11
Training loss: 2.5392613729207407
Validation loss: 2.463006335773959

Epoch: 6| Step: 12
Training loss: 2.145686937788819
Validation loss: 2.454730567416723

Epoch: 6| Step: 13
Training loss: 2.0421236525859965
Validation loss: 2.4566731315779626

Epoch: 119| Step: 0
Training loss: 2.302675979300912
Validation loss: 2.4672298821547

Epoch: 6| Step: 1
Training loss: 2.8436914794266226
Validation loss: 2.463492448784221

Epoch: 6| Step: 2
Training loss: 2.58398289871462
Validation loss: 2.46277163341886

Epoch: 6| Step: 3
Training loss: 2.6468067831461273
Validation loss: 2.459942886146986

Epoch: 6| Step: 4
Training loss: 2.287709327667199
Validation loss: 2.464090432682209

Epoch: 6| Step: 5
Training loss: 2.3559861255489807
Validation loss: 2.4677020878925466

Epoch: 6| Step: 6
Training loss: 2.691427864685521
Validation loss: 2.463910312504495

Epoch: 6| Step: 7
Training loss: 2.760147273515778
Validation loss: 2.467291485634693

Epoch: 6| Step: 8
Training loss: 2.0576965577433373
Validation loss: 2.471768316706812

Epoch: 6| Step: 9
Training loss: 2.3775741279991376
Validation loss: 2.4781909005445133

Epoch: 6| Step: 10
Training loss: 2.6481545446249957
Validation loss: 2.4673749901186475

Epoch: 6| Step: 11
Training loss: 2.4184707835295702
Validation loss: 2.4796519779512627

Epoch: 6| Step: 12
Training loss: 2.2039235068061096
Validation loss: 2.4846820441629007

Epoch: 6| Step: 13
Training loss: 2.914118461991973
Validation loss: 2.481427697673771

Epoch: 120| Step: 0
Training loss: 2.8625489010027976
Validation loss: 2.4804916901416245

Epoch: 6| Step: 1
Training loss: 2.110575581549002
Validation loss: 2.4799438882448075

Epoch: 6| Step: 2
Training loss: 2.7168003852870926
Validation loss: 2.4623319520104268

Epoch: 6| Step: 3
Training loss: 2.577282207178611
Validation loss: 2.468731377124965

Epoch: 6| Step: 4
Training loss: 2.599681460601325
Validation loss: 2.4587752758563513

Epoch: 6| Step: 5
Training loss: 2.937472404188031
Validation loss: 2.462015325674683

Epoch: 6| Step: 6
Training loss: 2.065411564452109
Validation loss: 2.4668679608442003

Epoch: 6| Step: 7
Training loss: 2.2187275415277865
Validation loss: 2.461639869206607

Epoch: 6| Step: 8
Training loss: 2.3836420335008506
Validation loss: 2.4665886234060164

Epoch: 6| Step: 9
Training loss: 2.4381143822691813
Validation loss: 2.462922650904692

Epoch: 6| Step: 10
Training loss: 2.5829672912995982
Validation loss: 2.4624093311741944

Epoch: 6| Step: 11
Training loss: 2.224527707497333
Validation loss: 2.461644510101872

Epoch: 6| Step: 12
Training loss: 3.2051502803140095
Validation loss: 2.4639623308352268

Epoch: 6| Step: 13
Training loss: 2.5426844659164636
Validation loss: 2.4657994436255932

Epoch: 121| Step: 0
Training loss: 2.002645173829039
Validation loss: 2.463810949682906

Epoch: 6| Step: 1
Training loss: 2.187560380374824
Validation loss: 2.457993553947768

Epoch: 6| Step: 2
Training loss: 2.1666186278470736
Validation loss: 2.464963713566495

Epoch: 6| Step: 3
Training loss: 2.612798763148242
Validation loss: 2.4539920060375517

Epoch: 6| Step: 4
Training loss: 2.4687559876188265
Validation loss: 2.457934772920329

Epoch: 6| Step: 5
Training loss: 1.978300453829794
Validation loss: 2.4613745891603056

Epoch: 6| Step: 6
Training loss: 2.761171105890955
Validation loss: 2.470927730599044

Epoch: 6| Step: 7
Training loss: 2.965726095391849
Validation loss: 2.4752716727739132

Epoch: 6| Step: 8
Training loss: 2.9586430418845717
Validation loss: 2.4688262122901

Epoch: 6| Step: 9
Training loss: 2.7800425791052525
Validation loss: 2.4653745181544773

Epoch: 6| Step: 10
Training loss: 2.46991943475089
Validation loss: 2.4667282678885205

Epoch: 6| Step: 11
Training loss: 2.6750804568161035
Validation loss: 2.4733973512907363

Epoch: 6| Step: 12
Training loss: 2.141408401037261
Validation loss: 2.483392349177698

Epoch: 6| Step: 13
Training loss: 2.461604533546694
Validation loss: 2.4862943069143864

Epoch: 122| Step: 0
Training loss: 2.4748207489761733
Validation loss: 2.484663796583476

Epoch: 6| Step: 1
Training loss: 2.446033018193444
Validation loss: 2.49903374913662

Epoch: 6| Step: 2
Training loss: 2.191902526038689
Validation loss: 2.4881702440254734

Epoch: 6| Step: 3
Training loss: 2.8405609694378593
Validation loss: 2.483856274974587

Epoch: 6| Step: 4
Training loss: 2.586042788111001
Validation loss: 2.4853033094836965

Epoch: 6| Step: 5
Training loss: 2.592801023864544
Validation loss: 2.464513128790387

Epoch: 6| Step: 6
Training loss: 2.2583271218903014
Validation loss: 2.4617614819865277

Epoch: 6| Step: 7
Training loss: 2.1252415463663445
Validation loss: 2.4691989184704473

Epoch: 6| Step: 8
Training loss: 2.6633093879715006
Validation loss: 2.4653718587149425

Epoch: 6| Step: 9
Training loss: 2.3807107630249034
Validation loss: 2.468460283301046

Epoch: 6| Step: 10
Training loss: 2.4646535760753547
Validation loss: 2.461284479778322

Epoch: 6| Step: 11
Training loss: 2.4300138493523926
Validation loss: 2.465647812654387

Epoch: 6| Step: 12
Training loss: 2.7470566864163923
Validation loss: 2.4628485954100734

Epoch: 6| Step: 13
Training loss: 2.7844136279302703
Validation loss: 2.4645094284581024

Epoch: 123| Step: 0
Training loss: 3.055206488890448
Validation loss: 2.4653040500966226

Epoch: 6| Step: 1
Training loss: 1.806286388413469
Validation loss: 2.466173912353074

Epoch: 6| Step: 2
Training loss: 2.61723997148893
Validation loss: 2.472613309675199

Epoch: 6| Step: 3
Training loss: 2.5867144290538886
Validation loss: 2.469403305206884

Epoch: 6| Step: 4
Training loss: 2.2892989209046886
Validation loss: 2.482417809187678

Epoch: 6| Step: 5
Training loss: 2.1227922751907733
Validation loss: 2.4814891888871493

Epoch: 6| Step: 6
Training loss: 2.119560235314271
Validation loss: 2.4771375018700064

Epoch: 6| Step: 7
Training loss: 2.128250329000474
Validation loss: 2.47962237959447

Epoch: 6| Step: 8
Training loss: 2.605961742972249
Validation loss: 2.4691492071788637

Epoch: 6| Step: 9
Training loss: 2.903076900744826
Validation loss: 2.4648215025367812

Epoch: 6| Step: 10
Training loss: 2.225877623046591
Validation loss: 2.4650440487333776

Epoch: 6| Step: 11
Training loss: 3.238455589396308
Validation loss: 2.461681741871923

Epoch: 6| Step: 12
Training loss: 2.46055789017865
Validation loss: 2.4582767049010763

Epoch: 6| Step: 13
Training loss: 2.283316525399747
Validation loss: 2.4710209939806616

Epoch: 124| Step: 0
Training loss: 2.5958565120570447
Validation loss: 2.468255593090713

Epoch: 6| Step: 1
Training loss: 2.3485016530424803
Validation loss: 2.4711578312590228

Epoch: 6| Step: 2
Training loss: 2.1569598591287744
Validation loss: 2.4687789078319717

Epoch: 6| Step: 3
Training loss: 3.0235144632484654
Validation loss: 2.4770705447068693

Epoch: 6| Step: 4
Training loss: 2.669976256904331
Validation loss: 2.4658108046949536

Epoch: 6| Step: 5
Training loss: 2.1304970493542412
Validation loss: 2.464657663131123

Epoch: 6| Step: 6
Training loss: 2.8722132569727954
Validation loss: 2.475116247279262

Epoch: 6| Step: 7
Training loss: 2.3592662659909274
Validation loss: 2.471362490115739

Epoch: 6| Step: 8
Training loss: 2.5982848819361117
Validation loss: 2.4748474183235927

Epoch: 6| Step: 9
Training loss: 3.005796871811987
Validation loss: 2.46851222989738

Epoch: 6| Step: 10
Training loss: 2.89051826898608
Validation loss: 2.4860660148120277

Epoch: 6| Step: 11
Training loss: 2.0675078197917176
Validation loss: 2.4764466203440554

Epoch: 6| Step: 12
Training loss: 1.8955200760929598
Validation loss: 2.4730706533059017

Epoch: 6| Step: 13
Training loss: 2.4437625348094043
Validation loss: 2.464156081592202

Epoch: 125| Step: 0
Training loss: 2.5784410687529276
Validation loss: 2.4737972702334106

Epoch: 6| Step: 1
Training loss: 2.6357893146317117
Validation loss: 2.4743148279160563

Epoch: 6| Step: 2
Training loss: 2.7196536261539705
Validation loss: 2.4747366286639507

Epoch: 6| Step: 3
Training loss: 2.232125810830558
Validation loss: 2.4760494322461772

Epoch: 6| Step: 4
Training loss: 2.387802951625409
Validation loss: 2.460599765107201

Epoch: 6| Step: 5
Training loss: 3.125075682677291
Validation loss: 2.457101057766135

Epoch: 6| Step: 6
Training loss: 2.793907935950186
Validation loss: 2.467059751927399

Epoch: 6| Step: 7
Training loss: 2.0052773467899216
Validation loss: 2.4770940296486503

Epoch: 6| Step: 8
Training loss: 2.114399781427217
Validation loss: 2.469316465842179

Epoch: 6| Step: 9
Training loss: 2.195470186591009
Validation loss: 2.467431033973342

Epoch: 6| Step: 10
Training loss: 2.7556577915620757
Validation loss: 2.4699370190342522

Epoch: 6| Step: 11
Training loss: 2.413568835104885
Validation loss: 2.4805054669403566

Epoch: 6| Step: 12
Training loss: 2.5411454797238773
Validation loss: 2.477606889104293

Epoch: 6| Step: 13
Training loss: 2.246297969656173
Validation loss: 2.4684850977163926

Epoch: 126| Step: 0
Training loss: 2.609235017413846
Validation loss: 2.4832685393856204

Epoch: 6| Step: 1
Training loss: 2.488262278246455
Validation loss: 2.4726027994671322

Epoch: 6| Step: 2
Training loss: 2.3742795152535714
Validation loss: 2.462459178528115

Epoch: 6| Step: 3
Training loss: 2.0300207086267896
Validation loss: 2.4794774915818834

Epoch: 6| Step: 4
Training loss: 2.9940654548620085
Validation loss: 2.4775460072340993

Epoch: 6| Step: 5
Training loss: 2.565270205834635
Validation loss: 2.470341696457078

Epoch: 6| Step: 6
Training loss: 2.133627711290839
Validation loss: 2.4817749589136557

Epoch: 6| Step: 7
Training loss: 3.3241341173311407
Validation loss: 2.48423013324746

Epoch: 6| Step: 8
Training loss: 1.9261856118839724
Validation loss: 2.4758020751821985

Epoch: 6| Step: 9
Training loss: 2.539221655919271
Validation loss: 2.4740409168045447

Epoch: 6| Step: 10
Training loss: 2.1702293912877795
Validation loss: 2.473629165970014

Epoch: 6| Step: 11
Training loss: 2.13826515824462
Validation loss: 2.4698441571584264

Epoch: 6| Step: 12
Training loss: 2.7010278228942455
Validation loss: 2.4804284280217996

Epoch: 6| Step: 13
Training loss: 2.0832578899710685
Validation loss: 2.4686618177543336

Epoch: 127| Step: 0
Training loss: 2.8317438229681824
Validation loss: 2.4616796918389694

Epoch: 6| Step: 1
Training loss: 2.698316762903553
Validation loss: 2.459863224388208

Epoch: 6| Step: 2
Training loss: 2.7066629883157076
Validation loss: 2.4683736924789876

Epoch: 6| Step: 3
Training loss: 2.2580060512911024
Validation loss: 2.4606838842427106

Epoch: 6| Step: 4
Training loss: 2.264328473818985
Validation loss: 2.460388235325729

Epoch: 6| Step: 5
Training loss: 2.646082278176943
Validation loss: 2.459183842146472

Epoch: 6| Step: 6
Training loss: 2.0208240259749286
Validation loss: 2.461524877134384

Epoch: 6| Step: 7
Training loss: 2.434757156638871
Validation loss: 2.4528170349802356

Epoch: 6| Step: 8
Training loss: 2.9094386502524023
Validation loss: 2.456594617383195

Epoch: 6| Step: 9
Training loss: 2.4593120717161674
Validation loss: 2.467129581956187

Epoch: 6| Step: 10
Training loss: 2.967636060029942
Validation loss: 2.4693566072011213

Epoch: 6| Step: 11
Training loss: 1.8761608345045238
Validation loss: 2.46562465382466

Epoch: 6| Step: 12
Training loss: 2.1555345979416765
Validation loss: 2.465731566188669

Epoch: 6| Step: 13
Training loss: 2.295799366814534
Validation loss: 2.475271407893442

Epoch: 128| Step: 0
Training loss: 2.6591509965629956
Validation loss: 2.4724837127961665

Epoch: 6| Step: 1
Training loss: 2.388004437428094
Validation loss: 2.4779909268414

Epoch: 6| Step: 2
Training loss: 2.0967810028429428
Validation loss: 2.482477275031121

Epoch: 6| Step: 3
Training loss: 2.756866206274232
Validation loss: 2.4724798958208214

Epoch: 6| Step: 4
Training loss: 2.420384495983735
Validation loss: 2.470292522905401

Epoch: 6| Step: 5
Training loss: 2.399115749223832
Validation loss: 2.46222155137556

Epoch: 6| Step: 6
Training loss: 1.9751440695836777
Validation loss: 2.4725472264011166

Epoch: 6| Step: 7
Training loss: 2.7443745903652497
Validation loss: 2.46457549346769

Epoch: 6| Step: 8
Training loss: 2.7265346930105148
Validation loss: 2.4702746194359615

Epoch: 6| Step: 9
Training loss: 2.160230197296126
Validation loss: 2.462859163378303

Epoch: 6| Step: 10
Training loss: 2.9575936552359905
Validation loss: 2.4624023276127387

Epoch: 6| Step: 11
Training loss: 1.7797597038217767
Validation loss: 2.461006987059966

Epoch: 6| Step: 12
Training loss: 2.801175950249136
Validation loss: 2.4653854298854445

Epoch: 6| Step: 13
Training loss: 2.5072268934220685
Validation loss: 2.470210243085589

Epoch: 129| Step: 0
Training loss: 2.526369829917443
Validation loss: 2.461662452124223

Epoch: 6| Step: 1
Training loss: 2.4694882025582676
Validation loss: 2.4620256389839574

Epoch: 6| Step: 2
Training loss: 1.8610987006512238
Validation loss: 2.469494268841815

Epoch: 6| Step: 3
Training loss: 2.763801706452384
Validation loss: 2.466299595347848

Epoch: 6| Step: 4
Training loss: 2.834102488816214
Validation loss: 2.4699912351125866

Epoch: 6| Step: 5
Training loss: 2.5326327091252403
Validation loss: 2.469793155647729

Epoch: 6| Step: 6
Training loss: 2.3032360614308063
Validation loss: 2.4807548137724322

Epoch: 6| Step: 7
Training loss: 2.4807822682647145
Validation loss: 2.472255551783838

Epoch: 6| Step: 8
Training loss: 3.011371359970631
Validation loss: 2.4836009197165616

Epoch: 6| Step: 9
Training loss: 2.2076387092670524
Validation loss: 2.4812577402040583

Epoch: 6| Step: 10
Training loss: 2.4505973476959997
Validation loss: 2.4857247962322297

Epoch: 6| Step: 11
Training loss: 1.8543593131579252
Validation loss: 2.4816604274810525

Epoch: 6| Step: 12
Training loss: 2.6079931197748527
Validation loss: 2.4836475098903223

Epoch: 6| Step: 13
Training loss: 2.4978502567510663
Validation loss: 2.4725559529658114

Epoch: 130| Step: 0
Training loss: 2.961369706870705
Validation loss: 2.4861601168196796

Epoch: 6| Step: 1
Training loss: 2.379054774265931
Validation loss: 2.4973711497201103

Epoch: 6| Step: 2
Training loss: 2.663673171068115
Validation loss: 2.4949326976395856

Epoch: 6| Step: 3
Training loss: 2.4775867931202424
Validation loss: 2.504351881247528

Epoch: 6| Step: 4
Training loss: 1.9036060821376721
Validation loss: 2.513633650672122

Epoch: 6| Step: 5
Training loss: 2.8629503254046975
Validation loss: 2.519637688648247

Epoch: 6| Step: 6
Training loss: 2.3049649346388223
Validation loss: 2.502714082577975

Epoch: 6| Step: 7
Training loss: 2.6420298794970645
Validation loss: 2.4803063046586

Epoch: 6| Step: 8
Training loss: 2.397583750513996
Validation loss: 2.4769305127237744

Epoch: 6| Step: 9
Training loss: 1.9160097143488406
Validation loss: 2.4862533442220798

Epoch: 6| Step: 10
Training loss: 2.636203110749528
Validation loss: 2.4777478932126122

Epoch: 6| Step: 11
Training loss: 2.6277184715147
Validation loss: 2.4696872557718352

Epoch: 6| Step: 12
Training loss: 1.968664803250976
Validation loss: 2.4672424606634267

Epoch: 6| Step: 13
Training loss: 3.172213230985098
Validation loss: 2.4744267284629093

Epoch: 131| Step: 0
Training loss: 1.8201937002291158
Validation loss: 2.4711457390049465

Epoch: 6| Step: 1
Training loss: 2.310347302573425
Validation loss: 2.463764516631877

Epoch: 6| Step: 2
Training loss: 3.2448788422476884
Validation loss: 2.475693109864786

Epoch: 6| Step: 3
Training loss: 2.6871422817889874
Validation loss: 2.4747515614724924

Epoch: 6| Step: 4
Training loss: 2.985661094723644
Validation loss: 2.4756766900176004

Epoch: 6| Step: 5
Training loss: 2.453518295347367
Validation loss: 2.4692637717749433

Epoch: 6| Step: 6
Training loss: 2.4434306060385427
Validation loss: 2.4791744189314824

Epoch: 6| Step: 7
Training loss: 2.2431281372966705
Validation loss: 2.477460616126235

Epoch: 6| Step: 8
Training loss: 2.249559783256454
Validation loss: 2.47173798893123

Epoch: 6| Step: 9
Training loss: 1.947283868120725
Validation loss: 2.4825753145295724

Epoch: 6| Step: 10
Training loss: 2.184040931401942
Validation loss: 2.5053721326123153

Epoch: 6| Step: 11
Training loss: 2.2300233947484696
Validation loss: 2.4990093493663887

Epoch: 6| Step: 12
Training loss: 3.4592435320759054
Validation loss: 2.4863682713929536

Epoch: 6| Step: 13
Training loss: 2.428238906054239
Validation loss: 2.501569461912101

Epoch: 132| Step: 0
Training loss: 2.4714105490445553
Validation loss: 2.489441860972984

Epoch: 6| Step: 1
Training loss: 2.5653423269765843
Validation loss: 2.4876402184408866

Epoch: 6| Step: 2
Training loss: 2.319414472354579
Validation loss: 2.4796381323102024

Epoch: 6| Step: 3
Training loss: 2.3423809885186344
Validation loss: 2.4727058586459405

Epoch: 6| Step: 4
Training loss: 2.294264159407563
Validation loss: 2.463750388166222

Epoch: 6| Step: 5
Training loss: 1.9964584943019013
Validation loss: 2.4622847164434774

Epoch: 6| Step: 6
Training loss: 1.9813116864249396
Validation loss: 2.470403206253977

Epoch: 6| Step: 7
Training loss: 1.9535307195790055
Validation loss: 2.462141503381589

Epoch: 6| Step: 8
Training loss: 2.514102735843492
Validation loss: 2.459152761303911

Epoch: 6| Step: 9
Training loss: 2.6559297256364918
Validation loss: 2.4627754251036835

Epoch: 6| Step: 10
Training loss: 2.981018255731323
Validation loss: 2.4724076936087895

Epoch: 6| Step: 11
Training loss: 2.5891456641294956
Validation loss: 2.4649797211638895

Epoch: 6| Step: 12
Training loss: 3.4373573967224784
Validation loss: 2.4728329451244577

Epoch: 6| Step: 13
Training loss: 2.34848358251215
Validation loss: 2.4704098171791795

Epoch: 133| Step: 0
Training loss: 2.148274696423892
Validation loss: 2.4672179478124865

Epoch: 6| Step: 1
Training loss: 2.052082804052088
Validation loss: 2.4711598412689253

Epoch: 6| Step: 2
Training loss: 2.2309509931830362
Validation loss: 2.495585963536775

Epoch: 6| Step: 3
Training loss: 2.223771980095533
Validation loss: 2.5049785632893276

Epoch: 6| Step: 4
Training loss: 2.337349863381624
Validation loss: 2.4972481204924635

Epoch: 6| Step: 5
Training loss: 2.606621940290865
Validation loss: 2.4873981116305046

Epoch: 6| Step: 6
Training loss: 2.760659366710708
Validation loss: 2.4676229101177687

Epoch: 6| Step: 7
Training loss: 2.072054608645365
Validation loss: 2.466455850312907

Epoch: 6| Step: 8
Training loss: 2.915280657649656
Validation loss: 2.467637563914201

Epoch: 6| Step: 9
Training loss: 2.799528429647708
Validation loss: 2.4717393313028757

Epoch: 6| Step: 10
Training loss: 2.1572670127630165
Validation loss: 2.4696286565325543

Epoch: 6| Step: 11
Training loss: 2.739030634797533
Validation loss: 2.468399924393783

Epoch: 6| Step: 12
Training loss: 2.5226293633883867
Validation loss: 2.4693567359356385

Epoch: 6| Step: 13
Training loss: 3.038442514131562
Validation loss: 2.468908860129358

Epoch: 134| Step: 0
Training loss: 1.602505438880201
Validation loss: 2.470255589819899

Epoch: 6| Step: 1
Training loss: 2.8095393386316205
Validation loss: 2.4783172006943515

Epoch: 6| Step: 2
Training loss: 2.8442821633551536
Validation loss: 2.4844270456808477

Epoch: 6| Step: 3
Training loss: 2.508719972317679
Validation loss: 2.483301630607175

Epoch: 6| Step: 4
Training loss: 2.2801734788048087
Validation loss: 2.486346440274008

Epoch: 6| Step: 5
Training loss: 2.1817760237681147
Validation loss: 2.4782791365559604

Epoch: 6| Step: 6
Training loss: 2.6144775936635134
Validation loss: 2.4764928316571866

Epoch: 6| Step: 7
Training loss: 2.3735005514121355
Validation loss: 2.482148522334284

Epoch: 6| Step: 8
Training loss: 1.9540127377050973
Validation loss: 2.470235498375548

Epoch: 6| Step: 9
Training loss: 3.0586911864369073
Validation loss: 2.485220855093796

Epoch: 6| Step: 10
Training loss: 2.6378267347975113
Validation loss: 2.475426582860634

Epoch: 6| Step: 11
Training loss: 2.4276723078852007
Validation loss: 2.4822482076584573

Epoch: 6| Step: 12
Training loss: 2.4922258619267814
Validation loss: 2.4726838506571354

Epoch: 6| Step: 13
Training loss: 2.232135637544128
Validation loss: 2.489082650523928

Epoch: 135| Step: 0
Training loss: 2.538222893032035
Validation loss: 2.486100611199832

Epoch: 6| Step: 1
Training loss: 1.97473421843535
Validation loss: 2.4852675268209268

Epoch: 6| Step: 2
Training loss: 2.4969701526830255
Validation loss: 2.4907012621453015

Epoch: 6| Step: 3
Training loss: 2.2506604814685485
Validation loss: 2.485958290612577

Epoch: 6| Step: 4
Training loss: 2.9775816606906926
Validation loss: 2.4814270731458183

Epoch: 6| Step: 5
Training loss: 1.9640745321920376
Validation loss: 2.4852675747873074

Epoch: 6| Step: 6
Training loss: 2.3361047793300163
Validation loss: 2.4890096607334957

Epoch: 6| Step: 7
Training loss: 2.5522372659983406
Validation loss: 2.477186483401658

Epoch: 6| Step: 8
Training loss: 2.62435914345748
Validation loss: 2.4724784413507708

Epoch: 6| Step: 9
Training loss: 1.8728302163047252
Validation loss: 2.4820996147092655

Epoch: 6| Step: 10
Training loss: 3.3725854218949762
Validation loss: 2.4702523565400476

Epoch: 6| Step: 11
Training loss: 2.1679547833516892
Validation loss: 2.4809006202379305

Epoch: 6| Step: 12
Training loss: 2.4747575506273756
Validation loss: 2.4751671069980925

Epoch: 6| Step: 13
Training loss: 2.31987164865808
Validation loss: 2.48340630989462

Epoch: 136| Step: 0
Training loss: 2.0154941723378976
Validation loss: 2.478794508069697

Epoch: 6| Step: 1
Training loss: 2.406909010178068
Validation loss: 2.4808474354273207

Epoch: 6| Step: 2
Training loss: 2.3152688435935977
Validation loss: 2.497440156089204

Epoch: 6| Step: 3
Training loss: 2.738427086183153
Validation loss: 2.4891474247756915

Epoch: 6| Step: 4
Training loss: 2.9580929259998068
Validation loss: 2.4851801705111103

Epoch: 6| Step: 5
Training loss: 1.8421086262908868
Validation loss: 2.4960438818370263

Epoch: 6| Step: 6
Training loss: 2.2696278956939415
Validation loss: 2.4903151954051967

Epoch: 6| Step: 7
Training loss: 1.8266060542517644
Validation loss: 2.490926712632366

Epoch: 6| Step: 8
Training loss: 2.6932035737207007
Validation loss: 2.4878699073961075

Epoch: 6| Step: 9
Training loss: 2.234615926491222
Validation loss: 2.472202237247265

Epoch: 6| Step: 10
Training loss: 2.2422253542372967
Validation loss: 2.47922668598088

Epoch: 6| Step: 11
Training loss: 2.959301176832158
Validation loss: 2.483213189011505

Epoch: 6| Step: 12
Training loss: 2.4799917648547867
Validation loss: 2.4820269638951475

Epoch: 6| Step: 13
Training loss: 2.8334906665277377
Validation loss: 2.484109300524539

Epoch: 137| Step: 0
Training loss: 2.5128746398673525
Validation loss: 2.4873775036680676

Epoch: 6| Step: 1
Training loss: 2.4217576521469737
Validation loss: 2.487322372535406

Epoch: 6| Step: 2
Training loss: 2.0185943732492118
Validation loss: 2.487143503454908

Epoch: 6| Step: 3
Training loss: 3.406775477762482
Validation loss: 2.484295569855513

Epoch: 6| Step: 4
Training loss: 2.1116605456393236
Validation loss: 2.4816065143787056

Epoch: 6| Step: 5
Training loss: 1.7729959484383238
Validation loss: 2.4845845036170973

Epoch: 6| Step: 6
Training loss: 2.8308227486160327
Validation loss: 2.481916846949862

Epoch: 6| Step: 7
Training loss: 2.0358342013498403
Validation loss: 2.4850623661404936

Epoch: 6| Step: 8
Training loss: 1.731544453062678
Validation loss: 2.481008572047128

Epoch: 6| Step: 9
Training loss: 2.312126232562036
Validation loss: 2.4869214648731264

Epoch: 6| Step: 10
Training loss: 2.206963624171347
Validation loss: 2.4832433126335154

Epoch: 6| Step: 11
Training loss: 2.2705766958636997
Validation loss: 2.5017803369713705

Epoch: 6| Step: 12
Training loss: 2.973584224510681
Validation loss: 2.4884155971762882

Epoch: 6| Step: 13
Training loss: 2.879990931072791
Validation loss: 2.4803687848951075

Epoch: 138| Step: 0
Training loss: 2.25979548296907
Validation loss: 2.4863509950986904

Epoch: 6| Step: 1
Training loss: 2.102480436181889
Validation loss: 2.4931139046285122

Epoch: 6| Step: 2
Training loss: 2.6054711291804167
Validation loss: 2.489694542309669

Epoch: 6| Step: 3
Training loss: 2.182089627062428
Validation loss: 2.482334858759628

Epoch: 6| Step: 4
Training loss: 2.5024293540106113
Validation loss: 2.486877939983559

Epoch: 6| Step: 5
Training loss: 2.6574989524114345
Validation loss: 2.487987027821347

Epoch: 6| Step: 6
Training loss: 1.930298372636615
Validation loss: 2.4748976895028756

Epoch: 6| Step: 7
Training loss: 2.013635407495927
Validation loss: 2.4826358649910487

Epoch: 6| Step: 8
Training loss: 3.3388964642526764
Validation loss: 2.4845666071740182

Epoch: 6| Step: 9
Training loss: 2.5079170751901416
Validation loss: 2.494422492398205

Epoch: 6| Step: 10
Training loss: 2.8124938964777524
Validation loss: 2.492477009538728

Epoch: 6| Step: 11
Training loss: 2.5754165756883056
Validation loss: 2.490658329796912

Epoch: 6| Step: 12
Training loss: 2.364661956241814
Validation loss: 2.511607055395425

Epoch: 6| Step: 13
Training loss: 1.8827667863923399
Validation loss: 2.4941234981354095

Epoch: 139| Step: 0
Training loss: 2.30171627610884
Validation loss: 2.5042715455835394

Epoch: 6| Step: 1
Training loss: 2.922128268602195
Validation loss: 2.5086707907328623

Epoch: 6| Step: 2
Training loss: 2.835586231850352
Validation loss: 2.5042362878380935

Epoch: 6| Step: 3
Training loss: 2.2126601554534973
Validation loss: 2.5243893177583177

Epoch: 6| Step: 4
Training loss: 2.2864487864324703
Validation loss: 2.5096488876010263

Epoch: 6| Step: 5
Training loss: 2.9412587244088426
Validation loss: 2.48088179225661

Epoch: 6| Step: 6
Training loss: 2.072488353958816
Validation loss: 2.4843918421912163

Epoch: 6| Step: 7
Training loss: 2.2164496733882966
Validation loss: 2.47364850697519

Epoch: 6| Step: 8
Training loss: 2.178674934394087
Validation loss: 2.479665767427816

Epoch: 6| Step: 9
Training loss: 2.4082926217656317
Validation loss: 2.481640340303757

Epoch: 6| Step: 10
Training loss: 2.986639471895295
Validation loss: 2.474051469087071

Epoch: 6| Step: 11
Training loss: 2.272884340927599
Validation loss: 2.472953372758962

Epoch: 6| Step: 12
Training loss: 2.6825434199336087
Validation loss: 2.4738212199445795

Epoch: 6| Step: 13
Training loss: 1.9139924951324496
Validation loss: 2.4684977744622176

Epoch: 140| Step: 0
Training loss: 1.8045621225641182
Validation loss: 2.4781259922379975

Epoch: 6| Step: 1
Training loss: 2.0530258828309327
Validation loss: 2.4882922209732876

Epoch: 6| Step: 2
Training loss: 2.076346188222756
Validation loss: 2.5086025368168223

Epoch: 6| Step: 3
Training loss: 2.831342184490216
Validation loss: 2.518718830985417

Epoch: 6| Step: 4
Training loss: 2.5090603679876455
Validation loss: 2.517144630741148

Epoch: 6| Step: 5
Training loss: 2.8920525402398574
Validation loss: 2.548370530717946

Epoch: 6| Step: 6
Training loss: 2.1607298822301697
Validation loss: 2.56517850248544

Epoch: 6| Step: 7
Training loss: 2.1196382984163313
Validation loss: 2.556974920997965

Epoch: 6| Step: 8
Training loss: 2.8040232602350517
Validation loss: 2.5371292187876695

Epoch: 6| Step: 9
Training loss: 2.65233332276577
Validation loss: 2.517690517460882

Epoch: 6| Step: 10
Training loss: 2.6167650479654574
Validation loss: 2.5009065971036635

Epoch: 6| Step: 11
Training loss: 2.6199648567929454
Validation loss: 2.4939318126156045

Epoch: 6| Step: 12
Training loss: 2.4784623328958415
Validation loss: 2.487295924813919

Epoch: 6| Step: 13
Training loss: 2.4471229943971005
Validation loss: 2.4786321614120768

Epoch: 141| Step: 0
Training loss: 2.318524940447072
Validation loss: 2.474420658212886

Epoch: 6| Step: 1
Training loss: 2.346399767591671
Validation loss: 2.4841182744037784

Epoch: 6| Step: 2
Training loss: 2.4768068211133807
Validation loss: 2.483044986071009

Epoch: 6| Step: 3
Training loss: 2.8768185378821416
Validation loss: 2.484642654172243

Epoch: 6| Step: 4
Training loss: 2.779286237791485
Validation loss: 2.475926097846989

Epoch: 6| Step: 5
Training loss: 2.931557020689135
Validation loss: 2.480884907572615

Epoch: 6| Step: 6
Training loss: 2.177118462335421
Validation loss: 2.486923078666794

Epoch: 6| Step: 7
Training loss: 2.3516347880357715
Validation loss: 2.4878733573606215

Epoch: 6| Step: 8
Training loss: 2.0812691444226714
Validation loss: 2.4838908301508713

Epoch: 6| Step: 9
Training loss: 2.5375241358318545
Validation loss: 2.498256488642109

Epoch: 6| Step: 10
Training loss: 2.404650168720898
Validation loss: 2.500274198118189

Epoch: 6| Step: 11
Training loss: 2.610582540549003
Validation loss: 2.499477236450832

Epoch: 6| Step: 12
Training loss: 2.0633104061564076
Validation loss: 2.49553231943356

Epoch: 6| Step: 13
Training loss: 2.086175454958098
Validation loss: 2.510097805260559

Epoch: 142| Step: 0
Training loss: 2.5591817631509652
Validation loss: 2.500555707840217

Epoch: 6| Step: 1
Training loss: 1.997535975851999
Validation loss: 2.5150367017334325

Epoch: 6| Step: 2
Training loss: 2.4303941097833555
Validation loss: 2.49855708761892

Epoch: 6| Step: 3
Training loss: 2.4230725680767415
Validation loss: 2.507445945372633

Epoch: 6| Step: 4
Training loss: 2.622948889702337
Validation loss: 2.5050956293610134

Epoch: 6| Step: 5
Training loss: 1.713234948377567
Validation loss: 2.507354060623492

Epoch: 6| Step: 6
Training loss: 2.165946168190086
Validation loss: 2.4921720019967766

Epoch: 6| Step: 7
Training loss: 2.516008146500248
Validation loss: 2.4827413005794883

Epoch: 6| Step: 8
Training loss: 2.226566247769598
Validation loss: 2.489017299857122

Epoch: 6| Step: 9
Training loss: 2.275877177727433
Validation loss: 2.4831549889787303

Epoch: 6| Step: 10
Training loss: 2.3411053805026394
Validation loss: 2.4846120597291406

Epoch: 6| Step: 11
Training loss: 2.7751322981081774
Validation loss: 2.4901259773946567

Epoch: 6| Step: 12
Training loss: 3.0750518794451738
Validation loss: 2.4649800677522102

Epoch: 6| Step: 13
Training loss: 2.703707064544741
Validation loss: 2.485127940731708

Epoch: 143| Step: 0
Training loss: 2.3159216233927786
Validation loss: 2.479452482679115

Epoch: 6| Step: 1
Training loss: 2.9691717550951617
Validation loss: 2.496343513613013

Epoch: 6| Step: 2
Training loss: 2.5168949499445534
Validation loss: 2.4803061764923946

Epoch: 6| Step: 3
Training loss: 1.7371213321947645
Validation loss: 2.497388524802887

Epoch: 6| Step: 4
Training loss: 2.1663299690185633
Validation loss: 2.5155117096279294

Epoch: 6| Step: 5
Training loss: 2.458177744796378
Validation loss: 2.519147606160393

Epoch: 6| Step: 6
Training loss: 2.6034632432136715
Validation loss: 2.4902102879375314

Epoch: 6| Step: 7
Training loss: 2.037136527563529
Validation loss: 2.4813339686819114

Epoch: 6| Step: 8
Training loss: 2.564930670174918
Validation loss: 2.498887863745092

Epoch: 6| Step: 9
Training loss: 2.5956792435648963
Validation loss: 2.4857198885706797

Epoch: 6| Step: 10
Training loss: 1.7667443432315895
Validation loss: 2.4759425882607133

Epoch: 6| Step: 11
Training loss: 2.9567053349434578
Validation loss: 2.4820148285364674

Epoch: 6| Step: 12
Training loss: 3.061707686092538
Validation loss: 2.474250572745938

Epoch: 6| Step: 13
Training loss: 2.178377256741074
Validation loss: 2.476105014973353

Epoch: 144| Step: 0
Training loss: 3.145434895392423
Validation loss: 2.4877252761071764

Epoch: 6| Step: 1
Training loss: 2.642757660602527
Validation loss: 2.473776581094376

Epoch: 6| Step: 2
Training loss: 2.7106525370311982
Validation loss: 2.479009564548357

Epoch: 6| Step: 3
Training loss: 2.2211037629204045
Validation loss: 2.4862250071695495

Epoch: 6| Step: 4
Training loss: 1.8440513364592626
Validation loss: 2.4913644737105622

Epoch: 6| Step: 5
Training loss: 2.2515315035844603
Validation loss: 2.5078013767459217

Epoch: 6| Step: 6
Training loss: 2.2264463160133907
Validation loss: 2.5178297660393127

Epoch: 6| Step: 7
Training loss: 2.6398599633731905
Validation loss: 2.5106611858226384

Epoch: 6| Step: 8
Training loss: 1.965762884643819
Validation loss: 2.528425658226611

Epoch: 6| Step: 9
Training loss: 2.3888620096611675
Validation loss: 2.520689847241127

Epoch: 6| Step: 10
Training loss: 2.992946916827668
Validation loss: 2.513820277261858

Epoch: 6| Step: 11
Training loss: 2.5481074808887825
Validation loss: 2.51399810183789

Epoch: 6| Step: 12
Training loss: 2.4234084658233166
Validation loss: 2.5054021801305844

Epoch: 6| Step: 13
Training loss: 2.2316649748283206
Validation loss: 2.495148481258625

Epoch: 145| Step: 0
Training loss: 2.3601477159726545
Validation loss: 2.485691097826822

Epoch: 6| Step: 1
Training loss: 1.8488283210140135
Validation loss: 2.4856030290115556

Epoch: 6| Step: 2
Training loss: 2.0167245157735283
Validation loss: 2.489694223102379

Epoch: 6| Step: 3
Training loss: 2.1893847384223983
Validation loss: 2.49460783236658

Epoch: 6| Step: 4
Training loss: 2.1230477734013737
Validation loss: 2.4932440627745955

Epoch: 6| Step: 5
Training loss: 2.4076556769214448
Validation loss: 2.4805270611174297

Epoch: 6| Step: 6
Training loss: 2.5439924532280553
Validation loss: 2.4915430397655816

Epoch: 6| Step: 7
Training loss: 3.00199966543502
Validation loss: 2.506528309679776

Epoch: 6| Step: 8
Training loss: 2.451853234172345
Validation loss: 2.491514443900912

Epoch: 6| Step: 9
Training loss: 2.691054809834328
Validation loss: 2.495034213344352

Epoch: 6| Step: 10
Training loss: 2.6813940725321768
Validation loss: 2.5091551833669685

Epoch: 6| Step: 11
Training loss: 3.09599145936404
Validation loss: 2.5056141678603017

Epoch: 6| Step: 12
Training loss: 2.2294436368865016
Validation loss: 2.517422462388097

Epoch: 6| Step: 13
Training loss: 2.008973969446122
Validation loss: 2.5168817354561632

Epoch: 146| Step: 0
Training loss: 2.77146450301742
Validation loss: 2.509345729747432

Epoch: 6| Step: 1
Training loss: 2.869186660677732
Validation loss: 2.5136096850815868

Epoch: 6| Step: 2
Training loss: 2.4967606538602762
Validation loss: 2.4972098754980228

Epoch: 6| Step: 3
Training loss: 2.1164675681524194
Validation loss: 2.5077180696100716

Epoch: 6| Step: 4
Training loss: 2.3299959588732078
Validation loss: 2.5231296048340077

Epoch: 6| Step: 5
Training loss: 2.7451209221281516
Validation loss: 2.4995546103144157

Epoch: 6| Step: 6
Training loss: 2.3038268470469556
Validation loss: 2.490913870862143

Epoch: 6| Step: 7
Training loss: 1.408851675241727
Validation loss: 2.49595508777323

Epoch: 6| Step: 8
Training loss: 2.365843841629725
Validation loss: 2.4893149360257176

Epoch: 6| Step: 9
Training loss: 2.97119345245667
Validation loss: 2.501050235765917

Epoch: 6| Step: 10
Training loss: 2.575165408108744
Validation loss: 2.5071525458005186

Epoch: 6| Step: 11
Training loss: 2.163315626913454
Validation loss: 2.5075413051231887

Epoch: 6| Step: 12
Training loss: 2.4627773612809163
Validation loss: 2.4980084593013467

Epoch: 6| Step: 13
Training loss: 2.009754711006566
Validation loss: 2.5074300821026094

Epoch: 147| Step: 0
Training loss: 3.2040119710881956
Validation loss: 2.5141010683719607

Epoch: 6| Step: 1
Training loss: 2.2882373351066807
Validation loss: 2.5122253160271577

Epoch: 6| Step: 2
Training loss: 2.7110996692534153
Validation loss: 2.5059608127739934

Epoch: 6| Step: 3
Training loss: 2.4150404446139393
Validation loss: 2.5048193970027572

Epoch: 6| Step: 4
Training loss: 1.7840547397836979
Validation loss: 2.4954475756421166

Epoch: 6| Step: 5
Training loss: 1.7543138739765225
Validation loss: 2.498723339901008

Epoch: 6| Step: 6
Training loss: 2.553805230990984
Validation loss: 2.4810365682774784

Epoch: 6| Step: 7
Training loss: 3.1335402711210376
Validation loss: 2.4845912767234575

Epoch: 6| Step: 8
Training loss: 2.5389938579964317
Validation loss: 2.4842099628772547

Epoch: 6| Step: 9
Training loss: 2.029435858863965
Validation loss: 2.4885002451073808

Epoch: 6| Step: 10
Training loss: 2.5105326983174883
Validation loss: 2.48216517151868

Epoch: 6| Step: 11
Training loss: 1.9833652600622451
Validation loss: 2.49520931583931

Epoch: 6| Step: 12
Training loss: 2.504891188460655
Validation loss: 2.5115730397628737

Epoch: 6| Step: 13
Training loss: 2.2720715591216063
Validation loss: 2.5103592186734893

Epoch: 148| Step: 0
Training loss: 2.394937054597343
Validation loss: 2.514909867705985

Epoch: 6| Step: 1
Training loss: 2.7152993238482606
Validation loss: 2.530018534372564

Epoch: 6| Step: 2
Training loss: 2.338782068029653
Validation loss: 2.5375945870696115

Epoch: 6| Step: 3
Training loss: 2.203148807911033
Validation loss: 2.5117574780742884

Epoch: 6| Step: 4
Training loss: 2.016641050233849
Validation loss: 2.5137459823801396

Epoch: 6| Step: 5
Training loss: 2.4813890086710537
Validation loss: 2.513525787906208

Epoch: 6| Step: 6
Training loss: 2.368203527377349
Validation loss: 2.501420809410148

Epoch: 6| Step: 7
Training loss: 2.671049380875326
Validation loss: 2.518146712101542

Epoch: 6| Step: 8
Training loss: 2.3364681802089464
Validation loss: 2.5104972752547012

Epoch: 6| Step: 9
Training loss: 2.815443575451352
Validation loss: 2.52104839216768

Epoch: 6| Step: 10
Training loss: 2.653230634008512
Validation loss: 2.502842542798478

Epoch: 6| Step: 11
Training loss: 1.5906356601320402
Validation loss: 2.5013103150697784

Epoch: 6| Step: 12
Training loss: 2.617493295597209
Validation loss: 2.4849635132913157

Epoch: 6| Step: 13
Training loss: 2.4831017644387017
Validation loss: 2.483931463863531

Epoch: 149| Step: 0
Training loss: 1.8513336040156414
Validation loss: 2.4848595312650805

Epoch: 6| Step: 1
Training loss: 2.374606350851165
Validation loss: 2.485904222957407

Epoch: 6| Step: 2
Training loss: 2.1578537878330697
Validation loss: 2.4828943922854623

Epoch: 6| Step: 3
Training loss: 3.016260267952406
Validation loss: 2.4770638553077093

Epoch: 6| Step: 4
Training loss: 2.5017300341783306
Validation loss: 2.4832148852251623

Epoch: 6| Step: 5
Training loss: 2.356371553154318
Validation loss: 2.4899907809524744

Epoch: 6| Step: 6
Training loss: 2.7027180095187604
Validation loss: 2.483806761048423

Epoch: 6| Step: 7
Training loss: 2.4929876209048087
Validation loss: 2.4772582255212883

Epoch: 6| Step: 8
Training loss: 2.1177806516033866
Validation loss: 2.4873896767641934

Epoch: 6| Step: 9
Training loss: 2.0605767270497553
Validation loss: 2.495132603507497

Epoch: 6| Step: 10
Training loss: 2.5167250982242257
Validation loss: 2.5166446049041142

Epoch: 6| Step: 11
Training loss: 2.9515166570396016
Validation loss: 2.511941088164335

Epoch: 6| Step: 12
Training loss: 2.188027672475835
Validation loss: 2.522635097105847

Epoch: 6| Step: 13
Training loss: 2.4158906896633083
Validation loss: 2.5424003688579924

Epoch: 150| Step: 0
Training loss: 2.6465272569173446
Validation loss: 2.574834955351944

Epoch: 6| Step: 1
Training loss: 2.9886587664927857
Validation loss: 2.576904670815295

Epoch: 6| Step: 2
Training loss: 2.147623691749163
Validation loss: 2.525057875722191

Epoch: 6| Step: 3
Training loss: 2.738604429930108
Validation loss: 2.491144230995139

Epoch: 6| Step: 4
Training loss: 2.466671998645415
Validation loss: 2.48790857547468

Epoch: 6| Step: 5
Training loss: 2.7788242519958373
Validation loss: 2.4754332044488097

Epoch: 6| Step: 6
Training loss: 2.4364443718383946
Validation loss: 2.4701704453721534

Epoch: 6| Step: 7
Training loss: 2.2368803050555717
Validation loss: 2.4703941423411546

Epoch: 6| Step: 8
Training loss: 2.4776358700169263
Validation loss: 2.469649219521162

Epoch: 6| Step: 9
Training loss: 2.9129142237461
Validation loss: 2.4703445918270557

Epoch: 6| Step: 10
Training loss: 1.8803298854547186
Validation loss: 2.468120848889763

Epoch: 6| Step: 11
Training loss: 2.5769919015078435
Validation loss: 2.4768831544867482

Epoch: 6| Step: 12
Training loss: 2.1071693474164355
Validation loss: 2.4739916561626414

Epoch: 6| Step: 13
Training loss: 2.28625868589692
Validation loss: 2.465054784608326

Epoch: 151| Step: 0
Training loss: 2.963459480813157
Validation loss: 2.4748474022674793

Epoch: 6| Step: 1
Training loss: 2.512821696928415
Validation loss: 2.469162661029589

Epoch: 6| Step: 2
Training loss: 3.3516458709946764
Validation loss: 2.4647664150190947

Epoch: 6| Step: 3
Training loss: 2.4388757393476936
Validation loss: 2.4642425061749504

Epoch: 6| Step: 4
Training loss: 2.0997349617237084
Validation loss: 2.4578334386297023

Epoch: 6| Step: 5
Training loss: 2.2621736744282845
Validation loss: 2.4654221135781427

Epoch: 6| Step: 6
Training loss: 2.2154202257660733
Validation loss: 2.464939411803772

Epoch: 6| Step: 7
Training loss: 2.5118453733999244
Validation loss: 2.471698223854873

Epoch: 6| Step: 8
Training loss: 2.126845736284065
Validation loss: 2.4663143536768475

Epoch: 6| Step: 9
Training loss: 2.2458698725042847
Validation loss: 2.475530399298944

Epoch: 6| Step: 10
Training loss: 2.513040672316175
Validation loss: 2.483271931736162

Epoch: 6| Step: 11
Training loss: 2.6309077676854944
Validation loss: 2.4815539932121182

Epoch: 6| Step: 12
Training loss: 2.766578294499313
Validation loss: 2.466504053177085

Epoch: 6| Step: 13
Training loss: 2.2255649406644475
Validation loss: 2.473322115287463

Epoch: 152| Step: 0
Training loss: 2.569267361928122
Validation loss: 2.4716784656712045

Epoch: 6| Step: 1
Training loss: 2.233142219261405
Validation loss: 2.475394807017115

Epoch: 6| Step: 2
Training loss: 2.966546294809924
Validation loss: 2.468524713337023

Epoch: 6| Step: 3
Training loss: 2.1718064990321495
Validation loss: 2.465233499430815

Epoch: 6| Step: 4
Training loss: 2.496228520392171
Validation loss: 2.470088225834076

Epoch: 6| Step: 5
Training loss: 2.315703467147728
Validation loss: 2.470698589577112

Epoch: 6| Step: 6
Training loss: 2.0486167893268177
Validation loss: 2.469845404027597

Epoch: 6| Step: 7
Training loss: 2.2429310698817124
Validation loss: 2.476975062650702

Epoch: 6| Step: 8
Training loss: 2.2991061629929486
Validation loss: 2.4761271289610427

Epoch: 6| Step: 9
Training loss: 2.3553395908048365
Validation loss: 2.4731867714752025

Epoch: 6| Step: 10
Training loss: 2.7511342917153727
Validation loss: 2.4749173657914794

Epoch: 6| Step: 11
Training loss: 2.9965543032390958
Validation loss: 2.484776846257594

Epoch: 6| Step: 12
Training loss: 2.6008832348313535
Validation loss: 2.492440636354197

Epoch: 6| Step: 13
Training loss: 2.132060047484954
Validation loss: 2.4968448597310706

Epoch: 153| Step: 0
Training loss: 2.2149707683761295
Validation loss: 2.493026958739588

Epoch: 6| Step: 1
Training loss: 2.8196636098065033
Validation loss: 2.508270926876771

Epoch: 6| Step: 2
Training loss: 2.6478825440648017
Validation loss: 2.4895875417335938

Epoch: 6| Step: 3
Training loss: 2.5761218987997414
Validation loss: 2.4992917965096315

Epoch: 6| Step: 4
Training loss: 2.6860701727374647
Validation loss: 2.5024655264335536

Epoch: 6| Step: 5
Training loss: 1.9821240732292227
Validation loss: 2.488589153472768

Epoch: 6| Step: 6
Training loss: 2.0373284577782362
Validation loss: 2.5078611121610805

Epoch: 6| Step: 7
Training loss: 2.9763492698087557
Validation loss: 2.4976959578549853

Epoch: 6| Step: 8
Training loss: 2.1013455757584865
Validation loss: 2.477550947125491

Epoch: 6| Step: 9
Training loss: 2.502002295696568
Validation loss: 2.4842239269971476

Epoch: 6| Step: 10
Training loss: 2.937535549516855
Validation loss: 2.483378596394721

Epoch: 6| Step: 11
Training loss: 2.3457370727013727
Validation loss: 2.477153174140571

Epoch: 6| Step: 12
Training loss: 2.1482943400456485
Validation loss: 2.4904816149477393

Epoch: 6| Step: 13
Training loss: 1.4253422309436001
Validation loss: 2.481232725222626

Epoch: 154| Step: 0
Training loss: 2.49201931281283
Validation loss: 2.4780003879127066

Epoch: 6| Step: 1
Training loss: 2.4417352317409535
Validation loss: 2.482464333528051

Epoch: 6| Step: 2
Training loss: 2.3939116580250457
Validation loss: 2.4853154367795445

Epoch: 6| Step: 3
Training loss: 2.388338878311922
Validation loss: 2.47834743994277

Epoch: 6| Step: 4
Training loss: 2.7343956646819594
Validation loss: 2.4819633966908383

Epoch: 6| Step: 5
Training loss: 2.241301251754646
Validation loss: 2.479246271816152

Epoch: 6| Step: 6
Training loss: 2.825693170357562
Validation loss: 2.484168110036276

Epoch: 6| Step: 7
Training loss: 2.191558560604883
Validation loss: 2.479602043539806

Epoch: 6| Step: 8
Training loss: 2.1593251069373394
Validation loss: 2.4855416075987242

Epoch: 6| Step: 9
Training loss: 2.2974259111581254
Validation loss: 2.488659361372386

Epoch: 6| Step: 10
Training loss: 3.088760977169401
Validation loss: 2.496735555473396

Epoch: 6| Step: 11
Training loss: 2.024261071349061
Validation loss: 2.517369425675849

Epoch: 6| Step: 12
Training loss: 2.4101619874957034
Validation loss: 2.5360743227385703

Epoch: 6| Step: 13
Training loss: 2.371044780596313
Validation loss: 2.512585653992777

Epoch: 155| Step: 0
Training loss: 2.945003908216283
Validation loss: 2.502040634193261

Epoch: 6| Step: 1
Training loss: 2.323243008485563
Validation loss: 2.496682556782549

Epoch: 6| Step: 2
Training loss: 2.1084432168704685
Validation loss: 2.479324773881208

Epoch: 6| Step: 3
Training loss: 2.258773968584729
Validation loss: 2.4921087174833425

Epoch: 6| Step: 4
Training loss: 2.2772622985407236
Validation loss: 2.476634877909208

Epoch: 6| Step: 5
Training loss: 2.8996714307189926
Validation loss: 2.476156079049896

Epoch: 6| Step: 6
Training loss: 2.7777726798540594
Validation loss: 2.480306272617049

Epoch: 6| Step: 7
Training loss: 2.119625700531007
Validation loss: 2.4658516879965497

Epoch: 6| Step: 8
Training loss: 3.018025287964623
Validation loss: 2.4729415142436073

Epoch: 6| Step: 9
Training loss: 2.297190534236535
Validation loss: 2.4842775593648354

Epoch: 6| Step: 10
Training loss: 2.0296809078165294
Validation loss: 2.4811432649731073

Epoch: 6| Step: 11
Training loss: 3.299994994651004
Validation loss: 2.4762188726192527

Epoch: 6| Step: 12
Training loss: 1.966769842361705
Validation loss: 2.4825032698810476

Epoch: 6| Step: 13
Training loss: 1.6151610130615504
Validation loss: 2.4923308838481972

Epoch: 156| Step: 0
Training loss: 2.1363251653118214
Validation loss: 2.493905498720503

Epoch: 6| Step: 1
Training loss: 2.5879896612830504
Validation loss: 2.5050932341615226

Epoch: 6| Step: 2
Training loss: 2.0126747008133097
Validation loss: 2.5107387373059886

Epoch: 6| Step: 3
Training loss: 2.298211779165918
Validation loss: 2.5025326298159345

Epoch: 6| Step: 4
Training loss: 2.4923745207734203
Validation loss: 2.5093506466264555

Epoch: 6| Step: 5
Training loss: 2.8564127602311826
Validation loss: 2.512503343709615

Epoch: 6| Step: 6
Training loss: 2.48247085631014
Validation loss: 2.5071819776423263

Epoch: 6| Step: 7
Training loss: 2.3180517620860424
Validation loss: 2.4993696371728285

Epoch: 6| Step: 8
Training loss: 2.8901371724662805
Validation loss: 2.5086999038132034

Epoch: 6| Step: 9
Training loss: 2.4247586710293323
Validation loss: 2.5024900909898364

Epoch: 6| Step: 10
Training loss: 2.376924036579921
Validation loss: 2.500880992155208

Epoch: 6| Step: 11
Training loss: 2.9307546884417404
Validation loss: 2.5043566413284557

Epoch: 6| Step: 12
Training loss: 2.152219017554655
Validation loss: 2.5057581709903256

Epoch: 6| Step: 13
Training loss: 2.190216557495077
Validation loss: 2.501482412790472

Epoch: 157| Step: 0
Training loss: 2.2431999871279817
Validation loss: 2.497339422379766

Epoch: 6| Step: 1
Training loss: 2.6089441549071286
Validation loss: 2.503259076271326

Epoch: 6| Step: 2
Training loss: 2.897070714106609
Validation loss: 2.5037504515676843

Epoch: 6| Step: 3
Training loss: 2.5733464200011555
Validation loss: 2.4911405941472573

Epoch: 6| Step: 4
Training loss: 2.229725728980372
Validation loss: 2.484034724894278

Epoch: 6| Step: 5
Training loss: 1.701224710583425
Validation loss: 2.482547031532034

Epoch: 6| Step: 6
Training loss: 2.668089477131023
Validation loss: 2.486002263173234

Epoch: 6| Step: 7
Training loss: 2.4326383573697474
Validation loss: 2.489027788646977

Epoch: 6| Step: 8
Training loss: 1.9946580116641783
Validation loss: 2.498084335702432

Epoch: 6| Step: 9
Training loss: 2.3122678073094662
Validation loss: 2.484608701194404

Epoch: 6| Step: 10
Training loss: 2.45021088140231
Validation loss: 2.4909504816969843

Epoch: 6| Step: 11
Training loss: 3.0100606071985974
Validation loss: 2.5133930833208713

Epoch: 6| Step: 12
Training loss: 2.420478467379407
Validation loss: 2.51735251998897

Epoch: 6| Step: 13
Training loss: 2.1960447997368298
Validation loss: 2.5259145068905635

Epoch: 158| Step: 0
Training loss: 2.0420241788951428
Validation loss: 2.531615799896586

Epoch: 6| Step: 1
Training loss: 2.468622325058423
Validation loss: 2.5337622777123525

Epoch: 6| Step: 2
Training loss: 2.0771711641475323
Validation loss: 2.5103421866315223

Epoch: 6| Step: 3
Training loss: 2.278213989026791
Validation loss: 2.4892641019785358

Epoch: 6| Step: 4
Training loss: 2.3492238528339264
Validation loss: 2.4976046053618517

Epoch: 6| Step: 5
Training loss: 2.2229324464199167
Validation loss: 2.4905859445966287

Epoch: 6| Step: 6
Training loss: 2.367804922026558
Validation loss: 2.4886551939812853

Epoch: 6| Step: 7
Training loss: 2.3702831610999446
Validation loss: 2.489265059765751

Epoch: 6| Step: 8
Training loss: 2.7700788766255466
Validation loss: 2.491578509026815

Epoch: 6| Step: 9
Training loss: 2.298204932255723
Validation loss: 2.490215019200716

Epoch: 6| Step: 10
Training loss: 1.9054443658110756
Validation loss: 2.4891763351792444

Epoch: 6| Step: 11
Training loss: 2.8345698482071726
Validation loss: 2.4861773305085744

Epoch: 6| Step: 12
Training loss: 3.395847921203609
Validation loss: 2.49373582598515

Epoch: 6| Step: 13
Training loss: 2.6026256325013173
Validation loss: 2.4966849839243537

Epoch: 159| Step: 0
Training loss: 2.6973328026120313
Validation loss: 2.4959316051753127

Epoch: 6| Step: 1
Training loss: 2.1380718068695836
Validation loss: 2.5100983118406712

Epoch: 6| Step: 2
Training loss: 3.696076199286895
Validation loss: 2.501426480542859

Epoch: 6| Step: 3
Training loss: 2.6036167225307563
Validation loss: 2.4811348969276574

Epoch: 6| Step: 4
Training loss: 1.6020841911852672
Validation loss: 2.502191536686808

Epoch: 6| Step: 5
Training loss: 2.4423243390953724
Validation loss: 2.4948432189669436

Epoch: 6| Step: 6
Training loss: 2.5110859170098063
Validation loss: 2.486181949574728

Epoch: 6| Step: 7
Training loss: 1.692821870566283
Validation loss: 2.4756986954771274

Epoch: 6| Step: 8
Training loss: 2.129197295006555
Validation loss: 2.4901565679225355

Epoch: 6| Step: 9
Training loss: 2.818696549748303
Validation loss: 2.476442400309644

Epoch: 6| Step: 10
Training loss: 2.158836030289533
Validation loss: 2.4834920725769205

Epoch: 6| Step: 11
Training loss: 2.730311748045654
Validation loss: 2.4728302856715865

Epoch: 6| Step: 12
Training loss: 2.6973531323490554
Validation loss: 2.4770446452420676

Epoch: 6| Step: 13
Training loss: 1.6807648508283088
Validation loss: 2.4933178131195057

Epoch: 160| Step: 0
Training loss: 2.580556566694226
Validation loss: 2.5006088707481657

Epoch: 6| Step: 1
Training loss: 2.4765155198126756
Validation loss: 2.5205067089324236

Epoch: 6| Step: 2
Training loss: 2.360922501703839
Validation loss: 2.5198565605757137

Epoch: 6| Step: 3
Training loss: 1.8053237652142384
Validation loss: 2.5497075810783043

Epoch: 6| Step: 4
Training loss: 2.529529316358459
Validation loss: 2.557724503650421

Epoch: 6| Step: 5
Training loss: 2.4547929863752325
Validation loss: 2.5469363464581014

Epoch: 6| Step: 6
Training loss: 2.6961958612445764
Validation loss: 2.5526256737577784

Epoch: 6| Step: 7
Training loss: 2.1731589933495377
Validation loss: 2.555847285787855

Epoch: 6| Step: 8
Training loss: 2.8406887135426393
Validation loss: 2.5531820981112814

Epoch: 6| Step: 9
Training loss: 2.8195405786052903
Validation loss: 2.52955599013595

Epoch: 6| Step: 10
Training loss: 2.6322614959167225
Validation loss: 2.531214772673949

Epoch: 6| Step: 11
Training loss: 2.1135104860650755
Validation loss: 2.523167204971234

Epoch: 6| Step: 12
Training loss: 2.4858956151822866
Validation loss: 2.5138074259851226

Epoch: 6| Step: 13
Training loss: 1.6613838952428894
Validation loss: 2.5012718144573953

Epoch: 161| Step: 0
Training loss: 2.4520078411381414
Validation loss: 2.520515632050701

Epoch: 6| Step: 1
Training loss: 2.0537515691564305
Validation loss: 2.5073667389540115

Epoch: 6| Step: 2
Training loss: 2.6835423982418503
Validation loss: 2.507666800476352

Epoch: 6| Step: 3
Training loss: 2.8802357971831904
Validation loss: 2.50252316622026

Epoch: 6| Step: 4
Training loss: 2.075583603379228
Validation loss: 2.500967839772103

Epoch: 6| Step: 5
Training loss: 1.7932667204150352
Validation loss: 2.5098665882588165

Epoch: 6| Step: 6
Training loss: 2.220196964014904
Validation loss: 2.501797967328867

Epoch: 6| Step: 7
Training loss: 2.3235231528691394
Validation loss: 2.5013290210539623

Epoch: 6| Step: 8
Training loss: 2.5274367632251553
Validation loss: 2.512901016040715

Epoch: 6| Step: 9
Training loss: 2.9964042413166436
Validation loss: 2.5108563656725953

Epoch: 6| Step: 10
Training loss: 2.0623299499692775
Validation loss: 2.5016197679339425

Epoch: 6| Step: 11
Training loss: 1.85463308689992
Validation loss: 2.4996347796379217

Epoch: 6| Step: 12
Training loss: 3.1319775312940483
Validation loss: 2.4889633226002728

Epoch: 6| Step: 13
Training loss: 1.9817865264979695
Validation loss: 2.5140118530811373

Epoch: 162| Step: 0
Training loss: 2.634287254166367
Validation loss: 2.504782076688272

Epoch: 6| Step: 1
Training loss: 2.822678859777458
Validation loss: 2.505554703991678

Epoch: 6| Step: 2
Training loss: 1.90032137110452
Validation loss: 2.5167308138152062

Epoch: 6| Step: 3
Training loss: 2.267489803674015
Validation loss: 2.5167841718622412

Epoch: 6| Step: 4
Training loss: 2.437497456867163
Validation loss: 2.535938018968004

Epoch: 6| Step: 5
Training loss: 2.590030991357796
Validation loss: 2.5225832647715283

Epoch: 6| Step: 6
Training loss: 2.4930596335356174
Validation loss: 2.5238345515847285

Epoch: 6| Step: 7
Training loss: 2.2017400189447773
Validation loss: 2.505485032967102

Epoch: 6| Step: 8
Training loss: 2.720171501979812
Validation loss: 2.493794480184443

Epoch: 6| Step: 9
Training loss: 2.2409705072561956
Validation loss: 2.48477516710216

Epoch: 6| Step: 10
Training loss: 2.8366281388292767
Validation loss: 2.4829059952132453

Epoch: 6| Step: 11
Training loss: 2.063189997996906
Validation loss: 2.483131465344958

Epoch: 6| Step: 12
Training loss: 2.5753960240089206
Validation loss: 2.483172815584059

Epoch: 6| Step: 13
Training loss: 2.1174089942300793
Validation loss: 2.481214772574106

Epoch: 163| Step: 0
Training loss: 2.234835277179392
Validation loss: 2.497624413004297

Epoch: 6| Step: 1
Training loss: 2.10054938986395
Validation loss: 2.4872346170992445

Epoch: 6| Step: 2
Training loss: 2.448249588640588
Validation loss: 2.4837004027576612

Epoch: 6| Step: 3
Training loss: 2.8757669835564528
Validation loss: 2.4868200973582217

Epoch: 6| Step: 4
Training loss: 1.8843760982276159
Validation loss: 2.5018329258955427

Epoch: 6| Step: 5
Training loss: 2.810631534025076
Validation loss: 2.4949378260814363

Epoch: 6| Step: 6
Training loss: 2.323508171643441
Validation loss: 2.508403355919044

Epoch: 6| Step: 7
Training loss: 2.385155998102519
Validation loss: 2.5112017331280114

Epoch: 6| Step: 8
Training loss: 2.6688114918541426
Validation loss: 2.5082832282840015

Epoch: 6| Step: 9
Training loss: 2.907097313531874
Validation loss: 2.5219604294939986

Epoch: 6| Step: 10
Training loss: 2.031508326609863
Validation loss: 2.5011189817537014

Epoch: 6| Step: 11
Training loss: 1.8443142948741078
Validation loss: 2.4970366398989268

Epoch: 6| Step: 12
Training loss: 2.7907021028091723
Validation loss: 2.4949322357607646

Epoch: 6| Step: 13
Training loss: 2.150576882260588
Validation loss: 2.4945483530383945

Epoch: 164| Step: 0
Training loss: 1.6545654223025081
Validation loss: 2.4903681381302865

Epoch: 6| Step: 1
Training loss: 2.1374755857980725
Validation loss: 2.5152429484073986

Epoch: 6| Step: 2
Training loss: 2.2563190734941667
Validation loss: 2.501993687718045

Epoch: 6| Step: 3
Training loss: 2.362645995457956
Validation loss: 2.5187622947171935

Epoch: 6| Step: 4
Training loss: 2.3490052370067436
Validation loss: 2.5265792327119176

Epoch: 6| Step: 5
Training loss: 3.2096648652722735
Validation loss: 2.5371629857602063

Epoch: 6| Step: 6
Training loss: 2.424651099205999
Validation loss: 2.5627579753006016

Epoch: 6| Step: 7
Training loss: 2.35974603223947
Validation loss: 2.5718770468646928

Epoch: 6| Step: 8
Training loss: 1.8899211992255727
Validation loss: 2.5587371397727976

Epoch: 6| Step: 9
Training loss: 2.6059436279546873
Validation loss: 2.5619035352284283

Epoch: 6| Step: 10
Training loss: 2.3435648527130777
Validation loss: 2.5421892212633503

Epoch: 6| Step: 11
Training loss: 2.3142505927339068
Validation loss: 2.508296789069969

Epoch: 6| Step: 12
Training loss: 2.3689747726366086
Validation loss: 2.5126127923095423

Epoch: 6| Step: 13
Training loss: 3.035108804025073
Validation loss: 2.50872793156564

Epoch: 165| Step: 0
Training loss: 2.6686993739309024
Validation loss: 2.501667626812992

Epoch: 6| Step: 1
Training loss: 3.1959314469682707
Validation loss: 2.4927666289201103

Epoch: 6| Step: 2
Training loss: 2.757420325559134
Validation loss: 2.4900316662032362

Epoch: 6| Step: 3
Training loss: 2.0390808572344765
Validation loss: 2.4934589965112965

Epoch: 6| Step: 4
Training loss: 2.3941612268906787
Validation loss: 2.4911399242010157

Epoch: 6| Step: 5
Training loss: 2.50018824822258
Validation loss: 2.4994753604983675

Epoch: 6| Step: 6
Training loss: 1.7631959663829602
Validation loss: 2.4997691763176575

Epoch: 6| Step: 7
Training loss: 2.766077554174063
Validation loss: 2.502978299239778

Epoch: 6| Step: 8
Training loss: 1.6614926692400285
Validation loss: 2.5101658127261532

Epoch: 6| Step: 9
Training loss: 1.9166187266560166
Validation loss: 2.5100307299846603

Epoch: 6| Step: 10
Training loss: 2.4547259701070243
Validation loss: 2.527461509575016

Epoch: 6| Step: 11
Training loss: 2.2242488150244557
Validation loss: 2.530418761857755

Epoch: 6| Step: 12
Training loss: 2.5400144699765845
Validation loss: 2.5471281772208125

Epoch: 6| Step: 13
Training loss: 2.322992594437407
Validation loss: 2.5559082225586156

Epoch: 166| Step: 0
Training loss: 2.4131281257377957
Validation loss: 2.557174778356215

Epoch: 6| Step: 1
Training loss: 2.16666209391576
Validation loss: 2.569273610206669

Epoch: 6| Step: 2
Training loss: 2.953643753265382
Validation loss: 2.5287825249217475

Epoch: 6| Step: 3
Training loss: 2.2801068720950446
Validation loss: 2.513471056413668

Epoch: 6| Step: 4
Training loss: 2.28023642401705
Validation loss: 2.528044535170176

Epoch: 6| Step: 5
Training loss: 2.3008235286331957
Validation loss: 2.5118557035880844

Epoch: 6| Step: 6
Training loss: 2.4691807817700884
Validation loss: 2.4999986648556005

Epoch: 6| Step: 7
Training loss: 2.636459405648385
Validation loss: 2.488909567688384

Epoch: 6| Step: 8
Training loss: 2.6585371156590827
Validation loss: 2.4902824367298297

Epoch: 6| Step: 9
Training loss: 1.932661598624385
Validation loss: 2.4923172043040416

Epoch: 6| Step: 10
Training loss: 1.984564163923805
Validation loss: 2.484887763954887

Epoch: 6| Step: 11
Training loss: 2.5260455469055785
Validation loss: 2.4856744642661863

Epoch: 6| Step: 12
Training loss: 2.8860714900414166
Validation loss: 2.4840665581806367

Epoch: 6| Step: 13
Training loss: 1.9946241250325194
Validation loss: 2.4768506192382196

Epoch: 167| Step: 0
Training loss: 2.4651642846383175
Validation loss: 2.482519564543504

Epoch: 6| Step: 1
Training loss: 2.2342642376529205
Validation loss: 2.4856713549529794

Epoch: 6| Step: 2
Training loss: 1.944664659594334
Validation loss: 2.476262151594289

Epoch: 6| Step: 3
Training loss: 2.0772966153585126
Validation loss: 2.4981593667660733

Epoch: 6| Step: 4
Training loss: 2.6568616275096364
Validation loss: 2.4898316699763257

Epoch: 6| Step: 5
Training loss: 2.2489969348878103
Validation loss: 2.4939356047253436

Epoch: 6| Step: 6
Training loss: 2.528451479282756
Validation loss: 2.509430645507426

Epoch: 6| Step: 7
Training loss: 2.491006505601643
Validation loss: 2.52255476086561

Epoch: 6| Step: 8
Training loss: 2.377310281719159
Validation loss: 2.5335548331233784

Epoch: 6| Step: 9
Training loss: 2.1620664790446082
Validation loss: 2.54122569735381

Epoch: 6| Step: 10
Training loss: 2.867823392529984
Validation loss: 2.553831620096941

Epoch: 6| Step: 11
Training loss: 2.257368948375918
Validation loss: 2.5166246943310604

Epoch: 6| Step: 12
Training loss: 2.313570651085083
Validation loss: 2.5252813918939507

Epoch: 6| Step: 13
Training loss: 2.80882328034621
Validation loss: 2.52401682656952

Epoch: 168| Step: 0
Training loss: 2.9073530175407862
Validation loss: 2.527330385749619

Epoch: 6| Step: 1
Training loss: 2.4381192716694033
Validation loss: 2.5288218244810605

Epoch: 6| Step: 2
Training loss: 1.6400564025856275
Validation loss: 2.5190542789803514

Epoch: 6| Step: 3
Training loss: 1.6972118935458906
Validation loss: 2.5322184181891543

Epoch: 6| Step: 4
Training loss: 2.0571498258601335
Validation loss: 2.514033728467118

Epoch: 6| Step: 5
Training loss: 3.2389853233200387
Validation loss: 2.518381381768312

Epoch: 6| Step: 6
Training loss: 2.8328083524342222
Validation loss: 2.5123313050074834

Epoch: 6| Step: 7
Training loss: 2.4456562617171027
Validation loss: 2.5076038594667565

Epoch: 6| Step: 8
Training loss: 1.8651046308360464
Validation loss: 2.5173972779814666

Epoch: 6| Step: 9
Training loss: 2.354188283185261
Validation loss: 2.5033386507583133

Epoch: 6| Step: 10
Training loss: 2.52355399320528
Validation loss: 2.5145674194321193

Epoch: 6| Step: 11
Training loss: 2.796970387116215
Validation loss: 2.5044901896445997

Epoch: 6| Step: 12
Training loss: 2.063727735911099
Validation loss: 2.4967712215266413

Epoch: 6| Step: 13
Training loss: 1.983481739272655
Validation loss: 2.507913589420724

Epoch: 169| Step: 0
Training loss: 2.072879107213283
Validation loss: 2.5027248870811074

Epoch: 6| Step: 1
Training loss: 2.8609878077268895
Validation loss: 2.4968668536903555

Epoch: 6| Step: 2
Training loss: 2.3981964288393076
Validation loss: 2.5011347102904664

Epoch: 6| Step: 3
Training loss: 2.0607241296686545
Validation loss: 2.502870532946841

Epoch: 6| Step: 4
Training loss: 2.3895267132872116
Validation loss: 2.4938513643574525

Epoch: 6| Step: 5
Training loss: 2.0921468717976297
Validation loss: 2.4975491272171118

Epoch: 6| Step: 6
Training loss: 2.6905762564999
Validation loss: 2.4972614706979384

Epoch: 6| Step: 7
Training loss: 1.91189938756946
Validation loss: 2.4944972751883165

Epoch: 6| Step: 8
Training loss: 2.4148974903535794
Validation loss: 2.501126544173623

Epoch: 6| Step: 9
Training loss: 2.528104546727079
Validation loss: 2.491334264861067

Epoch: 6| Step: 10
Training loss: 2.456674328519898
Validation loss: 2.4947986377042617

Epoch: 6| Step: 11
Training loss: 1.652063512823533
Validation loss: 2.504532765895677

Epoch: 6| Step: 12
Training loss: 3.2376633297286985
Validation loss: 2.5025939359002614

Epoch: 6| Step: 13
Training loss: 2.265592167057355
Validation loss: 2.501436901414265

Epoch: 170| Step: 0
Training loss: 1.751894742573422
Validation loss: 2.5112046209462946

Epoch: 6| Step: 1
Training loss: 1.7942576045714562
Validation loss: 2.523958559832613

Epoch: 6| Step: 2
Training loss: 2.4166286618982356
Validation loss: 2.5324648073091556

Epoch: 6| Step: 3
Training loss: 2.6060771088921095
Validation loss: 2.5290620869147125

Epoch: 6| Step: 4
Training loss: 2.2389219741753648
Validation loss: 2.537057078749777

Epoch: 6| Step: 5
Training loss: 2.2254481689341374
Validation loss: 2.5557170041773567

Epoch: 6| Step: 6
Training loss: 2.409446079972009
Validation loss: 2.550791297881124

Epoch: 6| Step: 7
Training loss: 2.7967021185439402
Validation loss: 2.534254527962207

Epoch: 6| Step: 8
Training loss: 3.339933124261043
Validation loss: 2.523617433917837

Epoch: 6| Step: 9
Training loss: 2.1303517884790253
Validation loss: 2.521392087776658

Epoch: 6| Step: 10
Training loss: 2.6019630467446606
Validation loss: 2.529739101638387

Epoch: 6| Step: 11
Training loss: 2.261271430863466
Validation loss: 2.514200395588192

Epoch: 6| Step: 12
Training loss: 1.9076112358287096
Validation loss: 2.5139943399904277

Epoch: 6| Step: 13
Training loss: 2.5703182510265257
Validation loss: 2.5254995544338543

Epoch: 171| Step: 0
Training loss: 2.0702452450750513
Validation loss: 2.5175176099750374

Epoch: 6| Step: 1
Training loss: 2.9782617079268436
Validation loss: 2.5073528878746796

Epoch: 6| Step: 2
Training loss: 2.2644075476939265
Validation loss: 2.511821137630931

Epoch: 6| Step: 3
Training loss: 3.157188351580171
Validation loss: 2.495325709598414

Epoch: 6| Step: 4
Training loss: 1.9001021131882894
Validation loss: 2.5000577443129774

Epoch: 6| Step: 5
Training loss: 1.7281735184051388
Validation loss: 2.506654687998267

Epoch: 6| Step: 6
Training loss: 2.669589755226851
Validation loss: 2.501597625149066

Epoch: 6| Step: 7
Training loss: 2.7498781003810997
Validation loss: 2.501488655647653

Epoch: 6| Step: 8
Training loss: 2.568541592128098
Validation loss: 2.509073512809031

Epoch: 6| Step: 9
Training loss: 2.3725665826971127
Validation loss: 2.521320679480385

Epoch: 6| Step: 10
Training loss: 2.265516607388269
Validation loss: 2.5335717091173615

Epoch: 6| Step: 11
Training loss: 2.0590012669978566
Validation loss: 2.541289470908351

Epoch: 6| Step: 12
Training loss: 2.152045532170307
Validation loss: 2.5371351390036554

Epoch: 6| Step: 13
Training loss: 2.395388476217553
Validation loss: 2.5703539936770747

Epoch: 172| Step: 0
Training loss: 1.9838714561466804
Validation loss: 2.558974577927162

Epoch: 6| Step: 1
Training loss: 2.4756731909549545
Validation loss: 2.564388060295162

Epoch: 6| Step: 2
Training loss: 2.171556737620127
Validation loss: 2.5488692980640426

Epoch: 6| Step: 3
Training loss: 2.6136445162197415
Validation loss: 2.543315654791523

Epoch: 6| Step: 4
Training loss: 2.7422640971818573
Validation loss: 2.5256972455002864

Epoch: 6| Step: 5
Training loss: 2.497831739477797
Validation loss: 2.5200307424880193

Epoch: 6| Step: 6
Training loss: 2.4496980286391534
Validation loss: 2.505284636690978

Epoch: 6| Step: 7
Training loss: 2.312348335035248
Validation loss: 2.494964280391991

Epoch: 6| Step: 8
Training loss: 2.35591053022438
Validation loss: 2.509133202101487

Epoch: 6| Step: 9
Training loss: 1.4589101831244844
Validation loss: 2.5169883808710964

Epoch: 6| Step: 10
Training loss: 1.8460600008404062
Validation loss: 2.5160262615135185

Epoch: 6| Step: 11
Training loss: 2.9596930231254888
Validation loss: 2.533599587197627

Epoch: 6| Step: 12
Training loss: 2.857613776771169
Validation loss: 2.5234109032708516

Epoch: 6| Step: 13
Training loss: 2.278773178175222
Validation loss: 2.5166786230405362

Epoch: 173| Step: 0
Training loss: 2.5752141993050297
Validation loss: 2.513999540189844

Epoch: 6| Step: 1
Training loss: 2.545741853043318
Validation loss: 2.516984449832386

Epoch: 6| Step: 2
Training loss: 2.975447638677699
Validation loss: 2.520762707900534

Epoch: 6| Step: 3
Training loss: 1.9912513478113512
Validation loss: 2.5152883205641063

Epoch: 6| Step: 4
Training loss: 1.6476295262824363
Validation loss: 2.5312395919774207

Epoch: 6| Step: 5
Training loss: 1.7823196679447477
Validation loss: 2.5280177354160323

Epoch: 6| Step: 6
Training loss: 2.690227278003108
Validation loss: 2.541348567714174

Epoch: 6| Step: 7
Training loss: 2.4190278083492838
Validation loss: 2.5199108379979545

Epoch: 6| Step: 8
Training loss: 2.0955158587260474
Validation loss: 2.5293342499199256

Epoch: 6| Step: 9
Training loss: 2.2752839550506305
Validation loss: 2.5310731362927097

Epoch: 6| Step: 10
Training loss: 2.9298294236457103
Validation loss: 2.5354019069529348

Epoch: 6| Step: 11
Training loss: 2.35758651752636
Validation loss: 2.5234572308441163

Epoch: 6| Step: 12
Training loss: 2.1237166400195546
Validation loss: 2.5142684343237565

Epoch: 6| Step: 13
Training loss: 2.4964477097062066
Validation loss: 2.5200296860162417

Epoch: 174| Step: 0
Training loss: 2.834771202852529
Validation loss: 2.519605973587105

Epoch: 6| Step: 1
Training loss: 2.711478319557285
Validation loss: 2.5112017014806693

Epoch: 6| Step: 2
Training loss: 2.495631597535517
Validation loss: 2.5172398440796764

Epoch: 6| Step: 3
Training loss: 1.7567405314300935
Validation loss: 2.503963221845598

Epoch: 6| Step: 4
Training loss: 2.9837586730140595
Validation loss: 2.5087978372287996

Epoch: 6| Step: 5
Training loss: 2.606133829359026
Validation loss: 2.521234123168643

Epoch: 6| Step: 6
Training loss: 2.3564593760912182
Validation loss: 2.5193365923774733

Epoch: 6| Step: 7
Training loss: 1.4769288269643235
Validation loss: 2.5345277795865266

Epoch: 6| Step: 8
Training loss: 2.026367540474367
Validation loss: 2.5407784478588296

Epoch: 6| Step: 9
Training loss: 2.0002751161180634
Validation loss: 2.5355586284638703

Epoch: 6| Step: 10
Training loss: 2.835658036010757
Validation loss: 2.558696684574621

Epoch: 6| Step: 11
Training loss: 1.9008931419844863
Validation loss: 2.5724718015587777

Epoch: 6| Step: 12
Training loss: 2.736305035228911
Validation loss: 2.5997296617643353

Epoch: 6| Step: 13
Training loss: 2.3904302181103363
Validation loss: 2.5610698492744692

Epoch: 175| Step: 0
Training loss: 2.7760105286379306
Validation loss: 2.540407827932448

Epoch: 6| Step: 1
Training loss: 2.7803444406107416
Validation loss: 2.5301303506525774

Epoch: 6| Step: 2
Training loss: 1.7677939267436238
Validation loss: 2.515837382005549

Epoch: 6| Step: 3
Training loss: 1.7222975446096935
Validation loss: 2.5028905053060364

Epoch: 6| Step: 4
Training loss: 2.698212851586817
Validation loss: 2.5053614981311485

Epoch: 6| Step: 5
Training loss: 2.4992071801955547
Validation loss: 2.4956533474310945

Epoch: 6| Step: 6
Training loss: 2.342341801075929
Validation loss: 2.496909376917532

Epoch: 6| Step: 7
Training loss: 2.256339361476449
Validation loss: 2.4985671705767265

Epoch: 6| Step: 8
Training loss: 2.7030225083870776
Validation loss: 2.493371727982693

Epoch: 6| Step: 9
Training loss: 2.5751507798280233
Validation loss: 2.5024618266443253

Epoch: 6| Step: 10
Training loss: 2.8485275212478887
Validation loss: 2.4926491591787636

Epoch: 6| Step: 11
Training loss: 2.3677602144378875
Validation loss: 2.494640916531733

Epoch: 6| Step: 12
Training loss: 2.1980905569511044
Validation loss: 2.501143122633926

Epoch: 6| Step: 13
Training loss: 2.051582339816245
Validation loss: 2.5084904658462257

Epoch: 176| Step: 0
Training loss: 2.1111036211293626
Validation loss: 2.5009642330979442

Epoch: 6| Step: 1
Training loss: 2.0738813625162447
Validation loss: 2.5107122434563727

Epoch: 6| Step: 2
Training loss: 2.5087060970310007
Validation loss: 2.5326596326309425

Epoch: 6| Step: 3
Training loss: 1.738884364736005
Validation loss: 2.552098906073774

Epoch: 6| Step: 4
Training loss: 2.3046326711565994
Validation loss: 2.5421708393860065

Epoch: 6| Step: 5
Training loss: 2.6832752288624633
Validation loss: 2.5457463484251566

Epoch: 6| Step: 6
Training loss: 2.5212274563811774
Validation loss: 2.5167659596777456

Epoch: 6| Step: 7
Training loss: 2.346337276373956
Validation loss: 2.509149640558815

Epoch: 6| Step: 8
Training loss: 3.063628008439778
Validation loss: 2.512315694017788

Epoch: 6| Step: 9
Training loss: 2.259514507033561
Validation loss: 2.5011141996234203

Epoch: 6| Step: 10
Training loss: 2.3537708951293057
Validation loss: 2.513526609976156

Epoch: 6| Step: 11
Training loss: 2.462060000230024
Validation loss: 2.5135801229895804

Epoch: 6| Step: 12
Training loss: 2.5183200970984996
Validation loss: 2.5119632030477845

Epoch: 6| Step: 13
Training loss: 2.2913899225693117
Validation loss: 2.5050900458460648

Epoch: 177| Step: 0
Training loss: 1.9546502833250092
Validation loss: 2.4973948892718223

Epoch: 6| Step: 1
Training loss: 2.225079815750977
Validation loss: 2.505473590113032

Epoch: 6| Step: 2
Training loss: 2.6572993281508333
Validation loss: 2.4926663758800682

Epoch: 6| Step: 3
Training loss: 2.552097325708347
Validation loss: 2.49679177582792

Epoch: 6| Step: 4
Training loss: 2.267979102615344
Validation loss: 2.4895586839889474

Epoch: 6| Step: 5
Training loss: 2.6109093820369362
Validation loss: 2.4863531046988734

Epoch: 6| Step: 6
Training loss: 2.289558435037991
Validation loss: 2.491799829639454

Epoch: 6| Step: 7
Training loss: 2.513522863232097
Validation loss: 2.4858859443873125

Epoch: 6| Step: 8
Training loss: 2.3527739689823783
Validation loss: 2.5133191394489436

Epoch: 6| Step: 9
Training loss: 1.8927193383285492
Validation loss: 2.5331165982274992

Epoch: 6| Step: 10
Training loss: 1.9929558562516259
Validation loss: 2.5456838181997505

Epoch: 6| Step: 11
Training loss: 2.7617696841020076
Validation loss: 2.569784881331309

Epoch: 6| Step: 12
Training loss: 2.732116464011885
Validation loss: 2.5806156034661156

Epoch: 6| Step: 13
Training loss: 2.753566509961267
Validation loss: 2.599749417333999

Epoch: 178| Step: 0
Training loss: 2.482964841227317
Validation loss: 2.5891275695838125

Epoch: 6| Step: 1
Training loss: 2.265021934487279
Validation loss: 2.577681254720983

Epoch: 6| Step: 2
Training loss: 2.636294453708704
Validation loss: 2.5834176039538126

Epoch: 6| Step: 3
Training loss: 2.7042205001887987
Validation loss: 2.5336628469525277

Epoch: 6| Step: 4
Training loss: 2.4204095159779513
Validation loss: 2.543420020093109

Epoch: 6| Step: 5
Training loss: 2.659447843134507
Validation loss: 2.524436634781821

Epoch: 6| Step: 6
Training loss: 2.5964741935777136
Validation loss: 2.5009913227480376

Epoch: 6| Step: 7
Training loss: 2.1403602380674034
Validation loss: 2.5102334780091553

Epoch: 6| Step: 8
Training loss: 1.7114211143615043
Validation loss: 2.502502920991893

Epoch: 6| Step: 9
Training loss: 1.6322138660864192
Validation loss: 2.4916847383573133

Epoch: 6| Step: 10
Training loss: 2.7873390493412646
Validation loss: 2.495467718874688

Epoch: 6| Step: 11
Training loss: 2.2866687952964075
Validation loss: 2.497933837305591

Epoch: 6| Step: 12
Training loss: 2.4844984107884733
Validation loss: 2.4992557848433843

Epoch: 6| Step: 13
Training loss: 2.626945138231353
Validation loss: 2.501190998576817

Epoch: 179| Step: 0
Training loss: 2.3644292391899215
Validation loss: 2.5039111378860572

Epoch: 6| Step: 1
Training loss: 2.0884734893350974
Validation loss: 2.5019535220540683

Epoch: 6| Step: 2
Training loss: 2.467316416488219
Validation loss: 2.501569390431401

Epoch: 6| Step: 3
Training loss: 2.6625569583728326
Validation loss: 2.4961851418668055

Epoch: 6| Step: 4
Training loss: 2.000612403570179
Validation loss: 2.5094035994569404

Epoch: 6| Step: 5
Training loss: 1.8042342372278146
Validation loss: 2.5110155211763634

Epoch: 6| Step: 6
Training loss: 2.6487299664807757
Validation loss: 2.5275752940724243

Epoch: 6| Step: 7
Training loss: 2.500704093965572
Validation loss: 2.529016380516451

Epoch: 6| Step: 8
Training loss: 2.347304230510764
Validation loss: 2.530722150984578

Epoch: 6| Step: 9
Training loss: 1.9626103898606355
Validation loss: 2.53968560813726

Epoch: 6| Step: 10
Training loss: 2.71409603223362
Validation loss: 2.535421129367467

Epoch: 6| Step: 11
Training loss: 2.319591885548604
Validation loss: 2.541721051577531

Epoch: 6| Step: 12
Training loss: 2.201596101568064
Validation loss: 2.5386044524365516

Epoch: 6| Step: 13
Training loss: 2.8387941207379805
Validation loss: 2.52909489319805

Epoch: 180| Step: 0
Training loss: 2.2573497258353665
Validation loss: 2.515028975745168

Epoch: 6| Step: 1
Training loss: 1.9734458627168725
Validation loss: 2.5148449906749732

Epoch: 6| Step: 2
Training loss: 2.3346699110902165
Validation loss: 2.511254615279432

Epoch: 6| Step: 3
Training loss: 2.2871194866943956
Validation loss: 2.505791615387419

Epoch: 6| Step: 4
Training loss: 2.472983291958255
Validation loss: 2.514620633758609

Epoch: 6| Step: 5
Training loss: 2.024104063789054
Validation loss: 2.5101904285683156

Epoch: 6| Step: 6
Training loss: 1.7990128777442231
Validation loss: 2.519495101787683

Epoch: 6| Step: 7
Training loss: 3.047915549983152
Validation loss: 2.520482044071006

Epoch: 6| Step: 8
Training loss: 2.237077372611646
Validation loss: 2.5248974335489387

Epoch: 6| Step: 9
Training loss: 2.223597215075189
Validation loss: 2.522563645234472

Epoch: 6| Step: 10
Training loss: 2.235203089351608
Validation loss: 2.518202383430853

Epoch: 6| Step: 11
Training loss: 2.128617965357769
Validation loss: 2.5081658277841203

Epoch: 6| Step: 12
Training loss: 2.8042799459611416
Validation loss: 2.5091807434724354

Epoch: 6| Step: 13
Training loss: 3.048296943838067
Validation loss: 2.5085247925680116

Epoch: 181| Step: 0
Training loss: 1.6744681239814572
Validation loss: 2.51877682453067

Epoch: 6| Step: 1
Training loss: 2.2391266349769903
Validation loss: 2.5143447366666862

Epoch: 6| Step: 2
Training loss: 1.6366379019131752
Validation loss: 2.520663584098488

Epoch: 6| Step: 3
Training loss: 2.382300750310338
Validation loss: 2.5216428597085567

Epoch: 6| Step: 4
Training loss: 2.436955513417806
Validation loss: 2.518051020183384

Epoch: 6| Step: 5
Training loss: 2.120441259130479
Validation loss: 2.521139194649113

Epoch: 6| Step: 6
Training loss: 2.37164018798044
Validation loss: 2.5310666445661063

Epoch: 6| Step: 7
Training loss: 2.036162554114318
Validation loss: 2.5480167193560406

Epoch: 6| Step: 8
Training loss: 2.630656369766111
Validation loss: 2.552560509946169

Epoch: 6| Step: 9
Training loss: 2.434801907011225
Validation loss: 2.5592138883241478

Epoch: 6| Step: 10
Training loss: 2.474311069974043
Validation loss: 2.552673681579114

Epoch: 6| Step: 11
Training loss: 2.6851734470486006
Validation loss: 2.5411658392919625

Epoch: 6| Step: 12
Training loss: 2.8604070749883754
Validation loss: 2.519958034120536

Epoch: 6| Step: 13
Training loss: 2.7175588519646823
Validation loss: 2.54577092459978

Epoch: 182| Step: 0
Training loss: 2.678790061747238
Validation loss: 2.5382700304523302

Epoch: 6| Step: 1
Training loss: 2.5599941934579324
Validation loss: 2.5391998566863228

Epoch: 6| Step: 2
Training loss: 1.6455324437140186
Validation loss: 2.538917920813577

Epoch: 6| Step: 3
Training loss: 1.5992907531659875
Validation loss: 2.5508962296669404

Epoch: 6| Step: 4
Training loss: 1.7216313572254325
Validation loss: 2.5610182362480276

Epoch: 6| Step: 5
Training loss: 1.6822056546578923
Validation loss: 2.5496888481990934

Epoch: 6| Step: 6
Training loss: 3.0036727358135455
Validation loss: 2.554608513936077

Epoch: 6| Step: 7
Training loss: 1.9524498344746624
Validation loss: 2.553398188057019

Epoch: 6| Step: 8
Training loss: 2.6799661474794307
Validation loss: 2.534338569928048

Epoch: 6| Step: 9
Training loss: 2.7991029187872636
Validation loss: 2.5344611000020305

Epoch: 6| Step: 10
Training loss: 2.2442175417899954
Validation loss: 2.5182490592941402

Epoch: 6| Step: 11
Training loss: 2.577512356185526
Validation loss: 2.50865962376528

Epoch: 6| Step: 12
Training loss: 2.601788485222882
Validation loss: 2.5088249690029336

Epoch: 6| Step: 13
Training loss: 2.793922101550738
Validation loss: 2.49972482597371

Epoch: 183| Step: 0
Training loss: 2.6210334418418193
Validation loss: 2.5179786255055276

Epoch: 6| Step: 1
Training loss: 2.1750548432549905
Validation loss: 2.516022613251936

Epoch: 6| Step: 2
Training loss: 1.778773811915472
Validation loss: 2.5318001828156507

Epoch: 6| Step: 3
Training loss: 1.995041123637985
Validation loss: 2.547467277948117

Epoch: 6| Step: 4
Training loss: 2.6056071963837764
Validation loss: 2.57952164860624

Epoch: 6| Step: 5
Training loss: 2.065989576706715
Validation loss: 2.568600533770754

Epoch: 6| Step: 6
Training loss: 2.459044003540082
Validation loss: 2.593047019954891

Epoch: 6| Step: 7
Training loss: 2.752029970177758
Validation loss: 2.597414713938121

Epoch: 6| Step: 8
Training loss: 2.533649955170784
Validation loss: 2.5615281689030915

Epoch: 6| Step: 9
Training loss: 1.9796096774418341
Validation loss: 2.5676167583320613

Epoch: 6| Step: 10
Training loss: 2.636974271473016
Validation loss: 2.545810110191233

Epoch: 6| Step: 11
Training loss: 2.4459531877082115
Validation loss: 2.5485261584775496

Epoch: 6| Step: 12
Training loss: 2.9077987645976306
Validation loss: 2.538536408525504

Epoch: 6| Step: 13
Training loss: 2.288657299020725
Validation loss: 2.5132508378525356

Epoch: 184| Step: 0
Training loss: 2.8022433286082586
Validation loss: 2.5146308419312593

Epoch: 6| Step: 1
Training loss: 2.8853933468827697
Validation loss: 2.5151257858774385

Epoch: 6| Step: 2
Training loss: 2.3234866231357185
Validation loss: 2.516252759239325

Epoch: 6| Step: 3
Training loss: 1.7413887964317833
Validation loss: 2.5148379751334478

Epoch: 6| Step: 4
Training loss: 2.365699224680786
Validation loss: 2.4960397984141873

Epoch: 6| Step: 5
Training loss: 1.954590026718234
Validation loss: 2.507883532380698

Epoch: 6| Step: 6
Training loss: 2.512947790372385
Validation loss: 2.5061437455862863

Epoch: 6| Step: 7
Training loss: 2.941138428834719
Validation loss: 2.516275562649871

Epoch: 6| Step: 8
Training loss: 2.1723237157310913
Validation loss: 2.513667922966574

Epoch: 6| Step: 9
Training loss: 2.2979739927010425
Validation loss: 2.5113677021277723

Epoch: 6| Step: 10
Training loss: 2.4528074605702646
Validation loss: 2.5403295866828457

Epoch: 6| Step: 11
Training loss: 1.9753773871942493
Validation loss: 2.5236096397241186

Epoch: 6| Step: 12
Training loss: 2.8555013130303863
Validation loss: 2.532114501388009

Epoch: 6| Step: 13
Training loss: 1.8808768678606325
Validation loss: 2.5450883148798438

Epoch: 185| Step: 0
Training loss: 1.6760239503191645
Validation loss: 2.5615020452438233

Epoch: 6| Step: 1
Training loss: 3.0071153501631778
Validation loss: 2.583206932503085

Epoch: 6| Step: 2
Training loss: 1.7618845927128544
Validation loss: 2.582858831655864

Epoch: 6| Step: 3
Training loss: 2.427669361621947
Validation loss: 2.5860278525803406

Epoch: 6| Step: 4
Training loss: 3.050671525415584
Validation loss: 2.572151847761898

Epoch: 6| Step: 5
Training loss: 1.5776207751003015
Validation loss: 2.5699618485880764

Epoch: 6| Step: 6
Training loss: 2.738323042655395
Validation loss: 2.5473274967935735

Epoch: 6| Step: 7
Training loss: 1.833140153532868
Validation loss: 2.5285048257239717

Epoch: 6| Step: 8
Training loss: 2.049992873016622
Validation loss: 2.52764555884557

Epoch: 6| Step: 9
Training loss: 2.157757881462192
Validation loss: 2.533860152035917

Epoch: 6| Step: 10
Training loss: 2.3937652507724443
Validation loss: 2.5261064160624973

Epoch: 6| Step: 11
Training loss: 3.056719872175585
Validation loss: 2.5165458557571365

Epoch: 6| Step: 12
Training loss: 2.0865276516239155
Validation loss: 2.5250077061803076

Epoch: 6| Step: 13
Training loss: 2.589003298536714
Validation loss: 2.5178032836770634

Epoch: 186| Step: 0
Training loss: 1.4834935833953236
Validation loss: 2.5115244915377053

Epoch: 6| Step: 1
Training loss: 2.6585725391672885
Validation loss: 2.5065204623462787

Epoch: 6| Step: 2
Training loss: 2.220043825971325
Validation loss: 2.5017122206796203

Epoch: 6| Step: 3
Training loss: 2.1309554850217514
Validation loss: 2.506206295174597

Epoch: 6| Step: 4
Training loss: 2.45901026269013
Validation loss: 2.5157109753309004

Epoch: 6| Step: 5
Training loss: 2.7267667590037497
Validation loss: 2.518802555189068

Epoch: 6| Step: 6
Training loss: 2.6741557063417707
Validation loss: 2.543022018476301

Epoch: 6| Step: 7
Training loss: 2.097495983970171
Validation loss: 2.5338446736852194

Epoch: 6| Step: 8
Training loss: 2.5469487653476
Validation loss: 2.5506388618175446

Epoch: 6| Step: 9
Training loss: 2.008944181351339
Validation loss: 2.547671374919766

Epoch: 6| Step: 10
Training loss: 2.494204096931211
Validation loss: 2.5582081744449563

Epoch: 6| Step: 11
Training loss: 2.6514835451562537
Validation loss: 2.5404818123432498

Epoch: 6| Step: 12
Training loss: 2.5341803460680743
Validation loss: 2.5386479983302865

Epoch: 6| Step: 13
Training loss: 2.1864874539943306
Validation loss: 2.542648404634257

Epoch: 187| Step: 0
Training loss: 2.545556598945995
Validation loss: 2.5416639176859346

Epoch: 6| Step: 1
Training loss: 2.319668253330953
Validation loss: 2.5196673846862203

Epoch: 6| Step: 2
Training loss: 2.5019728505699286
Validation loss: 2.516447860687981

Epoch: 6| Step: 3
Training loss: 1.815390879363477
Validation loss: 2.5183102825766848

Epoch: 6| Step: 4
Training loss: 2.602614181608197
Validation loss: 2.5224746741141004

Epoch: 6| Step: 5
Training loss: 1.780804628608837
Validation loss: 2.51266931371363

Epoch: 6| Step: 6
Training loss: 3.111476475590696
Validation loss: 2.5064034628239753

Epoch: 6| Step: 7
Training loss: 2.2169560446711403
Validation loss: 2.5159541481410783

Epoch: 6| Step: 8
Training loss: 2.6800890919125018
Validation loss: 2.520136497802198

Epoch: 6| Step: 9
Training loss: 2.487256855798679
Validation loss: 2.5136666978349504

Epoch: 6| Step: 10
Training loss: 2.043092917175548
Validation loss: 2.5287843634193474

Epoch: 6| Step: 11
Training loss: 2.3290120937349537
Validation loss: 2.5286477924081354

Epoch: 6| Step: 12
Training loss: 1.939103170824451
Validation loss: 2.531776718784678

Epoch: 6| Step: 13
Training loss: 2.252903230839997
Validation loss: 2.541169154352122

Epoch: 188| Step: 0
Training loss: 2.373725448730524
Validation loss: 2.5472247423801786

Epoch: 6| Step: 1
Training loss: 1.602519424011296
Validation loss: 2.563212923571097

Epoch: 6| Step: 2
Training loss: 2.098518748354378
Validation loss: 2.5593592617248127

Epoch: 6| Step: 3
Training loss: 2.57931657477711
Validation loss: 2.5770198572637444

Epoch: 6| Step: 4
Training loss: 2.9074366618216954
Validation loss: 2.5429049091753817

Epoch: 6| Step: 5
Training loss: 2.2016543627079184
Validation loss: 2.5508014236127585

Epoch: 6| Step: 6
Training loss: 2.106702001049989
Validation loss: 2.5427745426553656

Epoch: 6| Step: 7
Training loss: 2.38526904941777
Validation loss: 2.534185269643017

Epoch: 6| Step: 8
Training loss: 2.800319575056145
Validation loss: 2.5176623764126114

Epoch: 6| Step: 9
Training loss: 2.4722892404490096
Validation loss: 2.519086923774638

Epoch: 6| Step: 10
Training loss: 2.1385168010630533
Validation loss: 2.503512204210001

Epoch: 6| Step: 11
Training loss: 2.2997486018572517
Validation loss: 2.5149063284274353

Epoch: 6| Step: 12
Training loss: 2.3593307389914004
Validation loss: 2.5088114506687855

Epoch: 6| Step: 13
Training loss: 2.5468866078866994
Validation loss: 2.5087126545390634

Epoch: 189| Step: 0
Training loss: 2.9913622163733193
Validation loss: 2.5167018094251214

Epoch: 6| Step: 1
Training loss: 1.9398699386494271
Validation loss: 2.5182141866044447

Epoch: 6| Step: 2
Training loss: 1.7865797915380053
Validation loss: 2.5286076258330676

Epoch: 6| Step: 3
Training loss: 2.809858904652758
Validation loss: 2.5342474093542338

Epoch: 6| Step: 4
Training loss: 2.2227525740469023
Validation loss: 2.5641818536212186

Epoch: 6| Step: 5
Training loss: 2.4104229301914173
Validation loss: 2.5855874000343815

Epoch: 6| Step: 6
Training loss: 2.0159849096899043
Validation loss: 2.5989148754902605

Epoch: 6| Step: 7
Training loss: 2.2136587912295873
Validation loss: 2.5521407815085593

Epoch: 6| Step: 8
Training loss: 2.27982327512507
Validation loss: 2.5648560586340197

Epoch: 6| Step: 9
Training loss: 2.7943886728790512
Validation loss: 2.5371735887474594

Epoch: 6| Step: 10
Training loss: 2.0627696699074494
Validation loss: 2.5412567907775223

Epoch: 6| Step: 11
Training loss: 2.64139342554562
Validation loss: 2.537497201301021

Epoch: 6| Step: 12
Training loss: 2.691665083310948
Validation loss: 2.527264491100667

Epoch: 6| Step: 13
Training loss: 2.1091563923903403
Validation loss: 2.520483628494094

Epoch: 190| Step: 0
Training loss: 1.78082471087089
Validation loss: 2.5063909857233826

Epoch: 6| Step: 1
Training loss: 1.7279195846239848
Validation loss: 2.5055096789368294

Epoch: 6| Step: 2
Training loss: 2.447590994307472
Validation loss: 2.5072597159830323

Epoch: 6| Step: 3
Training loss: 2.2104800125043322
Validation loss: 2.508123709282795

Epoch: 6| Step: 4
Training loss: 2.169512884428365
Validation loss: 2.5131032874197086

Epoch: 6| Step: 5
Training loss: 2.5759317952835312
Validation loss: 2.5125554314313985

Epoch: 6| Step: 6
Training loss: 2.990996838515998
Validation loss: 2.5275234136933906

Epoch: 6| Step: 7
Training loss: 2.762051790220073
Validation loss: 2.529806863828728

Epoch: 6| Step: 8
Training loss: 1.9473011315876443
Validation loss: 2.5350984117114206

Epoch: 6| Step: 9
Training loss: 2.713607572510563
Validation loss: 2.536149044618989

Epoch: 6| Step: 10
Training loss: 2.411908716666478
Validation loss: 2.547167131329017

Epoch: 6| Step: 11
Training loss: 1.803714638599343
Validation loss: 2.537246038697595

Epoch: 6| Step: 12
Training loss: 2.7003558312934586
Validation loss: 2.5376835761352656

Epoch: 6| Step: 13
Training loss: 2.616144593107089
Validation loss: 2.545131859127072

Epoch: 191| Step: 0
Training loss: 2.0543628044451148
Validation loss: 2.544483950281401

Epoch: 6| Step: 1
Training loss: 2.298988252441339
Validation loss: 2.549961848378727

Epoch: 6| Step: 2
Training loss: 2.343988737027186
Validation loss: 2.5355811485489816

Epoch: 6| Step: 3
Training loss: 2.74424783626199
Validation loss: 2.5304521786841137

Epoch: 6| Step: 4
Training loss: 2.525174420064009
Validation loss: 2.513218741785378

Epoch: 6| Step: 5
Training loss: 2.13340063684314
Validation loss: 2.5370624979380794

Epoch: 6| Step: 6
Training loss: 2.148439275567448
Validation loss: 2.523812981572743

Epoch: 6| Step: 7
Training loss: 2.545830073461199
Validation loss: 2.5191503981143732

Epoch: 6| Step: 8
Training loss: 2.450487796724263
Validation loss: 2.5174297311718634

Epoch: 6| Step: 9
Training loss: 2.5861441077360294
Validation loss: 2.5240528313084507

Epoch: 6| Step: 10
Training loss: 2.1191910276264068
Validation loss: 2.522998594491562

Epoch: 6| Step: 11
Training loss: 2.3167812822196994
Validation loss: 2.537152445375931

Epoch: 6| Step: 12
Training loss: 2.2528219540371577
Validation loss: 2.520918258833784

Epoch: 6| Step: 13
Training loss: 2.3940539732276913
Validation loss: 2.530980288103869

Epoch: 192| Step: 0
Training loss: 2.578780767097307
Validation loss: 2.521473674520003

Epoch: 6| Step: 1
Training loss: 2.75032136946675
Validation loss: 2.526916837330972

Epoch: 6| Step: 2
Training loss: 2.043580410421832
Validation loss: 2.5095367921046345

Epoch: 6| Step: 3
Training loss: 2.23722390970228
Validation loss: 2.513011593711088

Epoch: 6| Step: 4
Training loss: 1.9091660755189301
Validation loss: 2.5062430155744764

Epoch: 6| Step: 5
Training loss: 2.518376900653498
Validation loss: 2.516525012781239

Epoch: 6| Step: 6
Training loss: 2.1912267274812134
Validation loss: 2.5157575552631473

Epoch: 6| Step: 7
Training loss: 2.639740654749007
Validation loss: 2.5043480255753443

Epoch: 6| Step: 8
Training loss: 2.6161385782849913
Validation loss: 2.498801945675477

Epoch: 6| Step: 9
Training loss: 1.9315973012788823
Validation loss: 2.5066032068821364

Epoch: 6| Step: 10
Training loss: 1.9048032429728003
Validation loss: 2.4945273103333427

Epoch: 6| Step: 11
Training loss: 2.6741414412508067
Validation loss: 2.494001607224437

Epoch: 6| Step: 12
Training loss: 1.9799300745937372
Validation loss: 2.5100006508034802

Epoch: 6| Step: 13
Training loss: 2.5403808926922857
Validation loss: 2.497551927405367

Epoch: 193| Step: 0
Training loss: 2.1972940536355368
Validation loss: 2.4930286562456354

Epoch: 6| Step: 1
Training loss: 2.381192316272757
Validation loss: 2.501276548626957

Epoch: 6| Step: 2
Training loss: 2.6239608342632166
Validation loss: 2.4910321960966813

Epoch: 6| Step: 3
Training loss: 2.0483560809286416
Validation loss: 2.5025751996753893

Epoch: 6| Step: 4
Training loss: 2.436692813345102
Validation loss: 2.4988127988983675

Epoch: 6| Step: 5
Training loss: 2.6228439013927227
Validation loss: 2.5002709957111295

Epoch: 6| Step: 6
Training loss: 2.791589954138304
Validation loss: 2.51109591801116

Epoch: 6| Step: 7
Training loss: 1.3794629753483982
Validation loss: 2.500622687675197

Epoch: 6| Step: 8
Training loss: 1.7239290063981614
Validation loss: 2.5141225557521647

Epoch: 6| Step: 9
Training loss: 2.1926246560652496
Validation loss: 2.5155851625561865

Epoch: 6| Step: 10
Training loss: 2.716250882383397
Validation loss: 2.5154293213237895

Epoch: 6| Step: 11
Training loss: 2.8113963186843063
Validation loss: 2.516179199460768

Epoch: 6| Step: 12
Training loss: 2.6284184676440403
Validation loss: 2.5243078252498514

Epoch: 6| Step: 13
Training loss: 1.8459762451900041
Validation loss: 2.5346299513188266

Epoch: 194| Step: 0
Training loss: 2.821314921513112
Validation loss: 2.527036307186412

Epoch: 6| Step: 1
Training loss: 2.0635785837223426
Validation loss: 2.5286251791448704

Epoch: 6| Step: 2
Training loss: 2.3539216130638714
Validation loss: 2.525621380531583

Epoch: 6| Step: 3
Training loss: 2.59298032808032
Validation loss: 2.516743579114491

Epoch: 6| Step: 4
Training loss: 2.2898239587808997
Validation loss: 2.508612769478614

Epoch: 6| Step: 5
Training loss: 2.067957852647962
Validation loss: 2.517047787748806

Epoch: 6| Step: 6
Training loss: 2.0232192698739446
Validation loss: 2.512768863570611

Epoch: 6| Step: 7
Training loss: 2.4351433340886017
Validation loss: 2.499137276564323

Epoch: 6| Step: 8
Training loss: 2.430854639695141
Validation loss: 2.4994988098029776

Epoch: 6| Step: 9
Training loss: 2.036551848180735
Validation loss: 2.499915201020526

Epoch: 6| Step: 10
Training loss: 2.634459028793131
Validation loss: 2.5077965519002854

Epoch: 6| Step: 11
Training loss: 2.8130996064940765
Validation loss: 2.5014209126661813

Epoch: 6| Step: 12
Training loss: 1.6665414604205133
Validation loss: 2.5139038642825984

Epoch: 6| Step: 13
Training loss: 2.298530241691994
Validation loss: 2.517072762530953

Epoch: 195| Step: 0
Training loss: 2.6371411698664686
Validation loss: 2.5210234725325464

Epoch: 6| Step: 1
Training loss: 2.7471459056598437
Validation loss: 2.553985592603561

Epoch: 6| Step: 2
Training loss: 2.1544199378381848
Validation loss: 2.554322157312365

Epoch: 6| Step: 3
Training loss: 2.6443056717514217
Validation loss: 2.5824389498924205

Epoch: 6| Step: 4
Training loss: 2.0168489983262408
Validation loss: 2.586919484769429

Epoch: 6| Step: 5
Training loss: 2.7874619622479164
Validation loss: 2.5937572310626487

Epoch: 6| Step: 6
Training loss: 2.444881510915609
Validation loss: 2.584484556521346

Epoch: 6| Step: 7
Training loss: 2.356002418199474
Validation loss: 2.5713156353342512

Epoch: 6| Step: 8
Training loss: 2.2147011147510276
Validation loss: 2.562963753891339

Epoch: 6| Step: 9
Training loss: 2.05141614986079
Validation loss: 2.5255776415007105

Epoch: 6| Step: 10
Training loss: 2.3635520086374617
Validation loss: 2.523145330027628

Epoch: 6| Step: 11
Training loss: 1.921488777368089
Validation loss: 2.5102422714334773

Epoch: 6| Step: 12
Training loss: 2.383326740744838
Validation loss: 2.510544917417129

Epoch: 6| Step: 13
Training loss: 2.0121312579574098
Validation loss: 2.5015324505207

Epoch: 196| Step: 0
Training loss: 2.942596235362595
Validation loss: 2.4995349610456463

Epoch: 6| Step: 1
Training loss: 2.448029687315002
Validation loss: 2.510303689991938

Epoch: 6| Step: 2
Training loss: 1.9605043700407123
Validation loss: 2.5011125155487854

Epoch: 6| Step: 3
Training loss: 2.337630764980601
Validation loss: 2.5051859949164186

Epoch: 6| Step: 4
Training loss: 2.7388957989674085
Validation loss: 2.5112237912284026

Epoch: 6| Step: 5
Training loss: 2.567420979503056
Validation loss: 2.5271293474512118

Epoch: 6| Step: 6
Training loss: 2.270182268328494
Validation loss: 2.538423021434829

Epoch: 6| Step: 7
Training loss: 1.4974249353206879
Validation loss: 2.551946758326747

Epoch: 6| Step: 8
Training loss: 2.2936280844404324
Validation loss: 2.5657201708272925

Epoch: 6| Step: 9
Training loss: 2.0706995188450135
Validation loss: 2.5599589425758276

Epoch: 6| Step: 10
Training loss: 2.8951723364362985
Validation loss: 2.555342237465812

Epoch: 6| Step: 11
Training loss: 2.1317230907704396
Validation loss: 2.550772401600592

Epoch: 6| Step: 12
Training loss: 1.772383994542065
Validation loss: 2.5291355312343526

Epoch: 6| Step: 13
Training loss: 2.643881060009841
Validation loss: 2.533134810507678

Epoch: 197| Step: 0
Training loss: 2.4154854441768583
Validation loss: 2.5392799010493525

Epoch: 6| Step: 1
Training loss: 2.7461086831697457
Validation loss: 2.5387746481463527

Epoch: 6| Step: 2
Training loss: 2.364932758431896
Validation loss: 2.524430212563185

Epoch: 6| Step: 3
Training loss: 2.6581448247992308
Validation loss: 2.5367598827627327

Epoch: 6| Step: 4
Training loss: 2.1782325619555922
Validation loss: 2.5384916945276443

Epoch: 6| Step: 5
Training loss: 2.160204812688758
Validation loss: 2.527945814788846

Epoch: 6| Step: 6
Training loss: 2.2536637888164375
Validation loss: 2.5329112813969417

Epoch: 6| Step: 7
Training loss: 2.622946162786415
Validation loss: 2.534462840309743

Epoch: 6| Step: 8
Training loss: 2.6049331961063333
Validation loss: 2.567616386908101

Epoch: 6| Step: 9
Training loss: 2.0984094499998402
Validation loss: 2.5470329344913756

Epoch: 6| Step: 10
Training loss: 2.7047719183077006
Validation loss: 2.540097453145196

Epoch: 6| Step: 11
Training loss: 2.0915524921437134
Validation loss: 2.53266739897363

Epoch: 6| Step: 12
Training loss: 1.6915283159078556
Validation loss: 2.5377835461401013

Epoch: 6| Step: 13
Training loss: 1.9574074145719111
Validation loss: 2.5269247707133036

Epoch: 198| Step: 0
Training loss: 2.0071260340052977
Validation loss: 2.516136401777384

Epoch: 6| Step: 1
Training loss: 2.7105286039733585
Validation loss: 2.5095005395127004

Epoch: 6| Step: 2
Training loss: 2.6951832615924496
Validation loss: 2.5099026534972126

Epoch: 6| Step: 3
Training loss: 2.626472423490759
Validation loss: 2.504957084719622

Epoch: 6| Step: 4
Training loss: 1.9092950732395393
Validation loss: 2.5228559219477438

Epoch: 6| Step: 5
Training loss: 2.578715123926769
Validation loss: 2.517973110010955

Epoch: 6| Step: 6
Training loss: 2.6979084284790416
Validation loss: 2.534961538179793

Epoch: 6| Step: 7
Training loss: 2.175917999517675
Validation loss: 2.5509785706793755

Epoch: 6| Step: 8
Training loss: 2.330855950400482
Validation loss: 2.5363279514106076

Epoch: 6| Step: 9
Training loss: 2.0690902844988943
Validation loss: 2.55515781937899

Epoch: 6| Step: 10
Training loss: 2.6915773910346164
Validation loss: 2.5631938863242825

Epoch: 6| Step: 11
Training loss: 1.7523538562825072
Validation loss: 2.5270828906439142

Epoch: 6| Step: 12
Training loss: 2.3355908599146797
Validation loss: 2.50829495139766

Epoch: 6| Step: 13
Training loss: 2.197186739035312
Validation loss: 2.5105725526226115

Epoch: 199| Step: 0
Training loss: 1.7632482955753468
Validation loss: 2.511232035275007

Epoch: 6| Step: 1
Training loss: 2.349790494792096
Validation loss: 2.4900577258117442

Epoch: 6| Step: 2
Training loss: 1.6796645052023398
Validation loss: 2.4989360452675458

Epoch: 6| Step: 3
Training loss: 2.9365684168383446
Validation loss: 2.485066907328642

Epoch: 6| Step: 4
Training loss: 2.1819494399411443
Validation loss: 2.4939940630320283

Epoch: 6| Step: 5
Training loss: 1.846490407489617
Validation loss: 2.4941059250534976

Epoch: 6| Step: 6
Training loss: 2.065467087427346
Validation loss: 2.5013369323325683

Epoch: 6| Step: 7
Training loss: 2.2380826905274684
Validation loss: 2.5149271058173577

Epoch: 6| Step: 8
Training loss: 2.382928564027836
Validation loss: 2.513888531773251

Epoch: 6| Step: 9
Training loss: 2.9021875023659587
Validation loss: 2.504892893790122

Epoch: 6| Step: 10
Training loss: 2.3782607331809174
Validation loss: 2.51986629022869

Epoch: 6| Step: 11
Training loss: 3.0360260138220165
Validation loss: 2.519388657115454

Epoch: 6| Step: 12
Training loss: 2.5181623658423278
Validation loss: 2.567215341489383

Epoch: 6| Step: 13
Training loss: 2.1697495853068975
Validation loss: 2.6058817797741116

Epoch: 200| Step: 0
Training loss: 2.8440405728629
Validation loss: 2.587509860451503

Epoch: 6| Step: 1
Training loss: 1.6647703429372807
Validation loss: 2.5656701304299308

Epoch: 6| Step: 2
Training loss: 2.4920066839652026
Validation loss: 2.5320119378203714

Epoch: 6| Step: 3
Training loss: 2.2234172892506416
Validation loss: 2.535287972169431

Epoch: 6| Step: 4
Training loss: 2.3588662514798515
Validation loss: 2.5116692316168345

Epoch: 6| Step: 5
Training loss: 2.7352682344055306
Validation loss: 2.525381530289034

Epoch: 6| Step: 6
Training loss: 2.3993816691825374
Validation loss: 2.5292032231847426

Epoch: 6| Step: 7
Training loss: 2.5630111184595292
Validation loss: 2.536510370387845

Epoch: 6| Step: 8
Training loss: 2.3442998622567988
Validation loss: 2.5163979300537394

Epoch: 6| Step: 9
Training loss: 2.2293540186599206
Validation loss: 2.5274935033848673

Epoch: 6| Step: 10
Training loss: 2.432651294421678
Validation loss: 2.5351366258830543

Epoch: 6| Step: 11
Training loss: 2.3300340237404966
Validation loss: 2.5186373916581903

Epoch: 6| Step: 12
Training loss: 1.606097467208318
Validation loss: 2.550620665468264

Epoch: 6| Step: 13
Training loss: 2.256641546285189
Validation loss: 2.5379728042772753

Epoch: 201| Step: 0
Training loss: 2.311062340140276
Validation loss: 2.5528730974007092

Epoch: 6| Step: 1
Training loss: 2.9449491807992603
Validation loss: 2.5771847792579807

Epoch: 6| Step: 2
Training loss: 1.648853629140252
Validation loss: 2.5860618108121907

Epoch: 6| Step: 3
Training loss: 1.9566384414292068
Validation loss: 2.624976521341592

Epoch: 6| Step: 4
Training loss: 2.669925804107387
Validation loss: 2.6045745123339206

Epoch: 6| Step: 5
Training loss: 2.3083580658433482
Validation loss: 2.606539680122819

Epoch: 6| Step: 6
Training loss: 2.2466038398372303
Validation loss: 2.6027652377388906

Epoch: 6| Step: 7
Training loss: 1.8644167720911897
Validation loss: 2.5828598162745333

Epoch: 6| Step: 8
Training loss: 2.5428480831646145
Validation loss: 2.5615254076262834

Epoch: 6| Step: 9
Training loss: 2.490828092519999
Validation loss: 2.557135292964504

Epoch: 6| Step: 10
Training loss: 2.0873476897998553
Validation loss: 2.5416427256806355

Epoch: 6| Step: 11
Training loss: 2.526605560181146
Validation loss: 2.5257945985340062

Epoch: 6| Step: 12
Training loss: 2.5529120105443397
Validation loss: 2.508323767845528

Epoch: 6| Step: 13
Training loss: 2.20928148991718
Validation loss: 2.4915249859728745

Epoch: 202| Step: 0
Training loss: 1.8449426446699047
Validation loss: 2.4978158628747424

Epoch: 6| Step: 1
Training loss: 2.625498588077803
Validation loss: 2.497673756420045

Epoch: 6| Step: 2
Training loss: 1.9186979255692491
Validation loss: 2.4897921140798744

Epoch: 6| Step: 3
Training loss: 2.601088747070253
Validation loss: 2.4961103141286807

Epoch: 6| Step: 4
Training loss: 3.103187730967614
Validation loss: 2.506290802024973

Epoch: 6| Step: 5
Training loss: 2.5542025324516118
Validation loss: 2.5182993792608155

Epoch: 6| Step: 6
Training loss: 2.240343884399766
Validation loss: 2.518844439910786

Epoch: 6| Step: 7
Training loss: 2.7644777666378704
Validation loss: 2.5429912044629552

Epoch: 6| Step: 8
Training loss: 2.3324705186229817
Validation loss: 2.5684380155449045

Epoch: 6| Step: 9
Training loss: 2.2905516483901582
Validation loss: 2.5870941279927413

Epoch: 6| Step: 10
Training loss: 2.185671668968432
Validation loss: 2.5604253449589094

Epoch: 6| Step: 11
Training loss: 2.4230269122988726
Validation loss: 2.5465949436976105

Epoch: 6| Step: 12
Training loss: 2.3618682420305332
Validation loss: 2.5127490329843676

Epoch: 6| Step: 13
Training loss: 1.5800662800612502
Validation loss: 2.522644737282752

Epoch: 203| Step: 0
Training loss: 2.559755297528953
Validation loss: 2.509143115866099

Epoch: 6| Step: 1
Training loss: 1.4913184546261473
Validation loss: 2.5117322210461843

Epoch: 6| Step: 2
Training loss: 2.254143396658197
Validation loss: 2.4960612263597812

Epoch: 6| Step: 3
Training loss: 2.8198854751869207
Validation loss: 2.4985374464092005

Epoch: 6| Step: 4
Training loss: 2.380668400904397
Validation loss: 2.488894959307072

Epoch: 6| Step: 5
Training loss: 2.6538528396581764
Validation loss: 2.5057617073322227

Epoch: 6| Step: 6
Training loss: 2.1950235957309046
Validation loss: 2.5179100952197353

Epoch: 6| Step: 7
Training loss: 2.1083615729610674
Validation loss: 2.4994669584397573

Epoch: 6| Step: 8
Training loss: 2.0341502685177635
Validation loss: 2.537562031606257

Epoch: 6| Step: 9
Training loss: 2.935771027494976
Validation loss: 2.531394436329926

Epoch: 6| Step: 10
Training loss: 2.6434644973301644
Validation loss: 2.5220527904540613

Epoch: 6| Step: 11
Training loss: 1.5963929645082215
Validation loss: 2.5236368326954652

Epoch: 6| Step: 12
Training loss: 2.6483973497256206
Validation loss: 2.5384462518387347

Epoch: 6| Step: 13
Training loss: 2.352893237368899
Validation loss: 2.5350535743740394

Epoch: 204| Step: 0
Training loss: 2.109810339191274
Validation loss: 2.538863611501251

Epoch: 6| Step: 1
Training loss: 1.985787137009547
Validation loss: 2.5443217579259163

Epoch: 6| Step: 2
Training loss: 2.555894479068877
Validation loss: 2.5421156148002457

Epoch: 6| Step: 3
Training loss: 1.5899773618897917
Validation loss: 2.5451373235730372

Epoch: 6| Step: 4
Training loss: 2.6043778499169314
Validation loss: 2.550833708850227

Epoch: 6| Step: 5
Training loss: 2.3582779310568682
Validation loss: 2.553304657671322

Epoch: 6| Step: 6
Training loss: 2.606775965321939
Validation loss: 2.53949190078969

Epoch: 6| Step: 7
Training loss: 3.2019552932849193
Validation loss: 2.534760070471758

Epoch: 6| Step: 8
Training loss: 2.100107362818332
Validation loss: 2.5309331091174547

Epoch: 6| Step: 9
Training loss: 1.7251728385913412
Validation loss: 2.5248598198330403

Epoch: 6| Step: 10
Training loss: 2.632976945671106
Validation loss: 2.5219930760608467

Epoch: 6| Step: 11
Training loss: 1.5991188573457644
Validation loss: 2.5299040744272556

Epoch: 6| Step: 12
Training loss: 2.2743640597699595
Validation loss: 2.53315845804043

Epoch: 6| Step: 13
Training loss: 2.6856246437603395
Validation loss: 2.5262091564744296

Epoch: 205| Step: 0
Training loss: 1.9335981889153593
Validation loss: 2.5141882535226667

Epoch: 6| Step: 1
Training loss: 1.3921973522449902
Validation loss: 2.5004492038244996

Epoch: 6| Step: 2
Training loss: 3.1619263019309565
Validation loss: 2.510943263897297

Epoch: 6| Step: 3
Training loss: 1.8069391117445674
Validation loss: 2.507827370541098

Epoch: 6| Step: 4
Training loss: 1.9241307364317393
Validation loss: 2.5107528545836053

Epoch: 6| Step: 5
Training loss: 2.0470685794525627
Validation loss: 2.5198324570515425

Epoch: 6| Step: 6
Training loss: 2.174533013383321
Validation loss: 2.5164985640595177

Epoch: 6| Step: 7
Training loss: 2.9311656427343857
Validation loss: 2.514094675070389

Epoch: 6| Step: 8
Training loss: 2.630009548619563
Validation loss: 2.519143560187693

Epoch: 6| Step: 9
Training loss: 1.1914287627547693
Validation loss: 2.523817051548969

Epoch: 6| Step: 10
Training loss: 2.1914280093059646
Validation loss: 2.531814245435011

Epoch: 6| Step: 11
Training loss: 2.8627994230829725
Validation loss: 2.5426693850957656

Epoch: 6| Step: 12
Training loss: 2.50705068074914
Validation loss: 2.5581269981437984

Epoch: 6| Step: 13
Training loss: 2.6525993841969413
Validation loss: 2.559444404502504

Epoch: 206| Step: 0
Training loss: 2.3944426328805126
Validation loss: 2.589061406008133

Epoch: 6| Step: 1
Training loss: 2.942058516241355
Validation loss: 2.611042533023546

Epoch: 6| Step: 2
Training loss: 2.1259310309633954
Validation loss: 2.5758851619390493

Epoch: 6| Step: 3
Training loss: 1.8259634296770415
Validation loss: 2.5719386621678866

Epoch: 6| Step: 4
Training loss: 2.5041102952583962
Validation loss: 2.5527214238704876

Epoch: 6| Step: 5
Training loss: 2.4673262728026875
Validation loss: 2.5340288395413495

Epoch: 6| Step: 6
Training loss: 2.29750820436559
Validation loss: 2.5114792175141916

Epoch: 6| Step: 7
Training loss: 3.031496332915396
Validation loss: 2.5096325949159244

Epoch: 6| Step: 8
Training loss: 1.5214611830308806
Validation loss: 2.5133066176285563

Epoch: 6| Step: 9
Training loss: 1.788778357450962
Validation loss: 2.5007798806333423

Epoch: 6| Step: 10
Training loss: 2.0061959612927702
Validation loss: 2.5108376357122615

Epoch: 6| Step: 11
Training loss: 2.4087925148712386
Validation loss: 2.489802511827479

Epoch: 6| Step: 12
Training loss: 2.2641379902577103
Validation loss: 2.5004932870574526

Epoch: 6| Step: 13
Training loss: 2.549578115681621
Validation loss: 2.491440887385838

Epoch: 207| Step: 0
Training loss: 2.3019686939354513
Validation loss: 2.5089879356191527

Epoch: 6| Step: 1
Training loss: 2.4362897558281174
Validation loss: 2.5311063560889218

Epoch: 6| Step: 2
Training loss: 2.4792692873790094
Validation loss: 2.534841963728127

Epoch: 6| Step: 3
Training loss: 2.1347012942045347
Validation loss: 2.5465610989398124

Epoch: 6| Step: 4
Training loss: 1.3920998628136037
Validation loss: 2.598456895625491

Epoch: 6| Step: 5
Training loss: 2.2290769065777503
Validation loss: 2.5839817761220476

Epoch: 6| Step: 6
Training loss: 2.7266091941179855
Validation loss: 2.6006586988839286

Epoch: 6| Step: 7
Training loss: 1.8404606070558174
Validation loss: 2.5636060467669997

Epoch: 6| Step: 8
Training loss: 2.260082331482764
Validation loss: 2.5430861923045534

Epoch: 6| Step: 9
Training loss: 2.8066579543436823
Validation loss: 2.52272803979321

Epoch: 6| Step: 10
Training loss: 2.336448383919537
Validation loss: 2.5322669698205784

Epoch: 6| Step: 11
Training loss: 2.88308044677023
Validation loss: 2.5248805153150986

Epoch: 6| Step: 12
Training loss: 1.945569737596501
Validation loss: 2.5179276915447795

Epoch: 6| Step: 13
Training loss: 2.472166666794912
Validation loss: 2.5150708996111826

Epoch: 208| Step: 0
Training loss: 1.847379377399547
Validation loss: 2.520619254571931

Epoch: 6| Step: 1
Training loss: 1.4573852272712027
Validation loss: 2.5193659449718773

Epoch: 6| Step: 2
Training loss: 2.4859416508475127
Validation loss: 2.5116562269466787

Epoch: 6| Step: 3
Training loss: 2.427120312148443
Validation loss: 2.5171668340906925

Epoch: 6| Step: 4
Training loss: 2.6469349607771764
Validation loss: 2.5336146043767487

Epoch: 6| Step: 5
Training loss: 2.1788302140562883
Validation loss: 2.525510465999656

Epoch: 6| Step: 6
Training loss: 3.08939062140434
Validation loss: 2.543532536089522

Epoch: 6| Step: 7
Training loss: 2.483384804757607
Validation loss: 2.545897040581963

Epoch: 6| Step: 8
Training loss: 2.4957979173222555
Validation loss: 2.569550854538641

Epoch: 6| Step: 9
Training loss: 1.8348492582807459
Validation loss: 2.592815537239617

Epoch: 6| Step: 10
Training loss: 2.523489842300122
Validation loss: 2.5903627423171587

Epoch: 6| Step: 11
Training loss: 1.8754194426274118
Validation loss: 2.606134545980684

Epoch: 6| Step: 12
Training loss: 2.3606742666697262
Validation loss: 2.6078437682925304

Epoch: 6| Step: 13
Training loss: 1.9987736160572211
Validation loss: 2.61211415959692

Epoch: 209| Step: 0
Training loss: 1.8659018715245814
Validation loss: 2.605101293057653

Epoch: 6| Step: 1
Training loss: 1.7215905039294956
Validation loss: 2.5906622098268244

Epoch: 6| Step: 2
Training loss: 2.9455342904929362
Validation loss: 2.5607134165701892

Epoch: 6| Step: 3
Training loss: 1.5898394010517145
Validation loss: 2.5427701592238057

Epoch: 6| Step: 4
Training loss: 2.6280938943843304
Validation loss: 2.5559510538880073

Epoch: 6| Step: 5
Training loss: 2.1166664974583034
Validation loss: 2.52813646952853

Epoch: 6| Step: 6
Training loss: 2.551656529036636
Validation loss: 2.5279281860243357

Epoch: 6| Step: 7
Training loss: 2.7028167196014383
Validation loss: 2.51699103313471

Epoch: 6| Step: 8
Training loss: 2.5324790702173368
Validation loss: 2.493243034796512

Epoch: 6| Step: 9
Training loss: 2.699645520711932
Validation loss: 2.5099414729201026

Epoch: 6| Step: 10
Training loss: 2.052294363669931
Validation loss: 2.5034986175072107

Epoch: 6| Step: 11
Training loss: 2.4444100661702075
Validation loss: 2.497510544758156

Epoch: 6| Step: 12
Training loss: 1.9230933320739239
Validation loss: 2.507913541887471

Epoch: 6| Step: 13
Training loss: 2.2979055155958776
Validation loss: 2.50857457894447

Epoch: 210| Step: 0
Training loss: 2.333090792266451
Validation loss: 2.5102932109524616

Epoch: 6| Step: 1
Training loss: 2.2020664783459494
Validation loss: 2.5187793960307316

Epoch: 6| Step: 2
Training loss: 2.3012156052223247
Validation loss: 2.530369813576278

Epoch: 6| Step: 3
Training loss: 2.0779308716011995
Validation loss: 2.535784525477306

Epoch: 6| Step: 4
Training loss: 2.655744796281004
Validation loss: 2.5450884866226913

Epoch: 6| Step: 5
Training loss: 2.663730097194662
Validation loss: 2.5445877289118535

Epoch: 6| Step: 6
Training loss: 2.168505353073539
Validation loss: 2.5337733418876693

Epoch: 6| Step: 7
Training loss: 2.024664311783298
Validation loss: 2.535534392115409

Epoch: 6| Step: 8
Training loss: 2.293797825618734
Validation loss: 2.534971366610261

Epoch: 6| Step: 9
Training loss: 2.4328280939032383
Validation loss: 2.543823559483988

Epoch: 6| Step: 10
Training loss: 2.750701728067886
Validation loss: 2.524797685153651

Epoch: 6| Step: 11
Training loss: 2.3764997063942985
Validation loss: 2.5458796453763997

Epoch: 6| Step: 12
Training loss: 2.063373034110184
Validation loss: 2.554225417099839

Epoch: 6| Step: 13
Training loss: 1.806291932143976
Validation loss: 2.576053704401919

Epoch: 211| Step: 0
Training loss: 2.6611710683890113
Validation loss: 2.5894551855917234

Epoch: 6| Step: 1
Training loss: 2.6302385284402816
Validation loss: 2.6084306268147115

Epoch: 6| Step: 2
Training loss: 2.377053828366977
Validation loss: 2.58536923590676

Epoch: 6| Step: 3
Training loss: 2.305719280429967
Validation loss: 2.587387416067289

Epoch: 6| Step: 4
Training loss: 2.67313520371151
Validation loss: 2.5587447337866807

Epoch: 6| Step: 5
Training loss: 2.0437348718112447
Validation loss: 2.5441161895785824

Epoch: 6| Step: 6
Training loss: 2.1158907251535974
Validation loss: 2.5318998829034713

Epoch: 6| Step: 7
Training loss: 2.4612295794862846
Validation loss: 2.512015270332525

Epoch: 6| Step: 8
Training loss: 2.24643753737879
Validation loss: 2.5160784895095625

Epoch: 6| Step: 9
Training loss: 2.8555053207623087
Validation loss: 2.500902084677541

Epoch: 6| Step: 10
Training loss: 2.170022737234508
Validation loss: 2.503481784813463

Epoch: 6| Step: 11
Training loss: 2.605379895206445
Validation loss: 2.5132004009915376

Epoch: 6| Step: 12
Training loss: 1.7484300928581091
Validation loss: 2.5177658164980463

Epoch: 6| Step: 13
Training loss: 1.572806280780565
Validation loss: 2.5282592215978252

Epoch: 212| Step: 0
Training loss: 2.3265660333958857
Validation loss: 2.544432633304067

Epoch: 6| Step: 1
Training loss: 1.7209534825583284
Validation loss: 2.537709240359052

Epoch: 6| Step: 2
Training loss: 1.682297634747984
Validation loss: 2.5548522771643603

Epoch: 6| Step: 3
Training loss: 2.434663344654994
Validation loss: 2.53402655009567

Epoch: 6| Step: 4
Training loss: 2.484703570057138
Validation loss: 2.5448670067853305

Epoch: 6| Step: 5
Training loss: 3.036207098188597
Validation loss: 2.55123772657608

Epoch: 6| Step: 6
Training loss: 2.1735740986179
Validation loss: 2.561258759751241

Epoch: 6| Step: 7
Training loss: 2.642202955456811
Validation loss: 2.5751436045333698

Epoch: 6| Step: 8
Training loss: 2.2024202775328643
Validation loss: 2.585070922955894

Epoch: 6| Step: 9
Training loss: 2.5216982490022466
Validation loss: 2.5741828603369963

Epoch: 6| Step: 10
Training loss: 2.102415911323107
Validation loss: 2.566343959940773

Epoch: 6| Step: 11
Training loss: 2.0604172796924116
Validation loss: 2.541889842715175

Epoch: 6| Step: 12
Training loss: 1.9471411631762416
Validation loss: 2.522956794484747

Epoch: 6| Step: 13
Training loss: 2.3809081425417142
Validation loss: 2.536493850762215

Epoch: 213| Step: 0
Training loss: 2.2836702650460654
Validation loss: 2.5228462589518554

Epoch: 6| Step: 1
Training loss: 2.2759454795595904
Validation loss: 2.494334349530822

Epoch: 6| Step: 2
Training loss: 1.8288407839954128
Validation loss: 2.5002243259239387

Epoch: 6| Step: 3
Training loss: 1.8298234792946033
Validation loss: 2.500367550851961

Epoch: 6| Step: 4
Training loss: 1.999182355161135
Validation loss: 2.5047436373728464

Epoch: 6| Step: 5
Training loss: 2.040611292747739
Validation loss: 2.5081342449155684

Epoch: 6| Step: 6
Training loss: 2.6293663767207844
Validation loss: 2.509763851734134

Epoch: 6| Step: 7
Training loss: 3.008477630395129
Validation loss: 2.495361770019253

Epoch: 6| Step: 8
Training loss: 2.220849883666167
Validation loss: 2.5106733172484423

Epoch: 6| Step: 9
Training loss: 1.8597695068370141
Validation loss: 2.534838569850739

Epoch: 6| Step: 10
Training loss: 2.03658673466207
Validation loss: 2.5304748698395416

Epoch: 6| Step: 11
Training loss: 2.639097595884902
Validation loss: 2.5380619757845713

Epoch: 6| Step: 12
Training loss: 2.337041995623237
Validation loss: 2.561167098950663

Epoch: 6| Step: 13
Training loss: 2.553051719407622
Validation loss: 2.5831623533538473

Epoch: 214| Step: 0
Training loss: 2.184913959511342
Validation loss: 2.6035767815388047

Epoch: 6| Step: 1
Training loss: 1.8231630721904917
Validation loss: 2.62110569624777

Epoch: 6| Step: 2
Training loss: 1.919238755791837
Validation loss: 2.631794326066376

Epoch: 6| Step: 3
Training loss: 2.317945923932311
Validation loss: 2.5822191886584016

Epoch: 6| Step: 4
Training loss: 2.058406119147233
Validation loss: 2.5641751125354872

Epoch: 6| Step: 5
Training loss: 2.456475854638137
Validation loss: 2.5380512590865885

Epoch: 6| Step: 6
Training loss: 2.526399273810545
Validation loss: 2.5085657875944354

Epoch: 6| Step: 7
Training loss: 2.5462167275323746
Validation loss: 2.501568175259184

Epoch: 6| Step: 8
Training loss: 2.9161869926202835
Validation loss: 2.497072508523428

Epoch: 6| Step: 9
Training loss: 2.700649561277051
Validation loss: 2.504955228734127

Epoch: 6| Step: 10
Training loss: 2.50173775358644
Validation loss: 2.4949348955445267

Epoch: 6| Step: 11
Training loss: 1.829854815201019
Validation loss: 2.4952827134939315

Epoch: 6| Step: 12
Training loss: 2.2139563557252324
Validation loss: 2.512455778223061

Epoch: 6| Step: 13
Training loss: 2.5433966163904915
Validation loss: 2.516780137878685

Epoch: 215| Step: 0
Training loss: 2.0089453681364713
Validation loss: 2.5303024904758944

Epoch: 6| Step: 1
Training loss: 1.8319029935990478
Validation loss: 2.516016359076916

Epoch: 6| Step: 2
Training loss: 2.448388453261942
Validation loss: 2.541273435805762

Epoch: 6| Step: 3
Training loss: 2.288413518883911
Validation loss: 2.573580533970434

Epoch: 6| Step: 4
Training loss: 2.2104720309769688
Validation loss: 2.578713875765789

Epoch: 6| Step: 5
Training loss: 2.4730193487722363
Validation loss: 2.5531238899866664

Epoch: 6| Step: 6
Training loss: 2.324337739863783
Validation loss: 2.5848360971843554

Epoch: 6| Step: 7
Training loss: 2.215084002346451
Validation loss: 2.560459223725439

Epoch: 6| Step: 8
Training loss: 2.6383126873462435
Validation loss: 2.594917700938012

Epoch: 6| Step: 9
Training loss: 1.5599710216031506
Validation loss: 2.5811318636039116

Epoch: 6| Step: 10
Training loss: 2.2080891192253
Validation loss: 2.6307003404579556

Epoch: 6| Step: 11
Training loss: 2.9567754879278105
Validation loss: 2.609188004606172

Epoch: 6| Step: 12
Training loss: 2.070352114892216
Validation loss: 2.5817552843229103

Epoch: 6| Step: 13
Training loss: 2.885743674650632
Validation loss: 2.559884139558479

Epoch: 216| Step: 0
Training loss: 2.5105995544253297
Validation loss: 2.5699626526054704

Epoch: 6| Step: 1
Training loss: 1.9523423724953874
Validation loss: 2.5284387180877217

Epoch: 6| Step: 2
Training loss: 2.437318061494179
Validation loss: 2.5139746297144407

Epoch: 6| Step: 3
Training loss: 2.267609877778868
Validation loss: 2.5254749226004476

Epoch: 6| Step: 4
Training loss: 2.1987612097597014
Validation loss: 2.5194551047319593

Epoch: 6| Step: 5
Training loss: 2.039901385448207
Validation loss: 2.5124421766216045

Epoch: 6| Step: 6
Training loss: 2.3949691098317616
Validation loss: 2.5014471792738746

Epoch: 6| Step: 7
Training loss: 2.921130243539175
Validation loss: 2.5151807973350704

Epoch: 6| Step: 8
Training loss: 1.8558150118931358
Validation loss: 2.5114815749795563

Epoch: 6| Step: 9
Training loss: 2.0186235465017877
Validation loss: 2.5143104735978086

Epoch: 6| Step: 10
Training loss: 2.202498110057007
Validation loss: 2.5171364297388363

Epoch: 6| Step: 11
Training loss: 2.6880803036161263
Validation loss: 2.5458435435072153

Epoch: 6| Step: 12
Training loss: 2.174995650363826
Validation loss: 2.547981708244369

Epoch: 6| Step: 13
Training loss: 2.303752541419049
Validation loss: 2.56055516198721

Epoch: 217| Step: 0
Training loss: 2.806472083057039
Validation loss: 2.5461784221518213

Epoch: 6| Step: 1
Training loss: 2.0225875424369866
Validation loss: 2.5396210667407173

Epoch: 6| Step: 2
Training loss: 2.409593117584288
Validation loss: 2.52675589987252

Epoch: 6| Step: 3
Training loss: 1.6957536817710621
Validation loss: 2.5295953090960017

Epoch: 6| Step: 4
Training loss: 2.683189483798943
Validation loss: 2.5203569503304606

Epoch: 6| Step: 5
Training loss: 2.775911157533072
Validation loss: 2.510672486330737

Epoch: 6| Step: 6
Training loss: 2.2261641296583985
Validation loss: 2.5270311023653385

Epoch: 6| Step: 7
Training loss: 1.7429152538206591
Validation loss: 2.5205607043508853

Epoch: 6| Step: 8
Training loss: 2.290955057343567
Validation loss: 2.553784801030057

Epoch: 6| Step: 9
Training loss: 2.232946833099311
Validation loss: 2.5524007067919054

Epoch: 6| Step: 10
Training loss: 1.723701972762624
Validation loss: 2.582316280451319

Epoch: 6| Step: 11
Training loss: 2.436607784424319
Validation loss: 2.594245219925903

Epoch: 6| Step: 12
Training loss: 2.876905887627729
Validation loss: 2.5758965465383543

Epoch: 6| Step: 13
Training loss: 1.7849526988368518
Validation loss: 2.5728164426817473

Epoch: 218| Step: 0
Training loss: 2.69731583158378
Validation loss: 2.565723097951241

Epoch: 6| Step: 1
Training loss: 2.0287836213302133
Validation loss: 2.5252678593738342

Epoch: 6| Step: 2
Training loss: 1.6279936871136762
Validation loss: 2.519554354933829

Epoch: 6| Step: 3
Training loss: 2.7110064495014172
Validation loss: 2.50240170827252

Epoch: 6| Step: 4
Training loss: 2.299156872003848
Validation loss: 2.493721453026057

Epoch: 6| Step: 5
Training loss: 2.800590561848909
Validation loss: 2.52382127109186

Epoch: 6| Step: 6
Training loss: 2.2032419809437678
Validation loss: 2.512247380957344

Epoch: 6| Step: 7
Training loss: 1.9452955865699222
Validation loss: 2.521679434112614

Epoch: 6| Step: 8
Training loss: 1.933121687167536
Validation loss: 2.534183309622291

Epoch: 6| Step: 9
Training loss: 2.449282509979236
Validation loss: 2.5211614967892193

Epoch: 6| Step: 10
Training loss: 2.9303044597771315
Validation loss: 2.556184444814947

Epoch: 6| Step: 11
Training loss: 2.1873844661175377
Validation loss: 2.5748874565640625

Epoch: 6| Step: 12
Training loss: 1.8974384457702602
Validation loss: 2.58729156662058

Epoch: 6| Step: 13
Training loss: 1.8392854074168379
Validation loss: 2.623978552311959

Epoch: 219| Step: 0
Training loss: 2.453888792445264
Validation loss: 2.625031546751318

Epoch: 6| Step: 1
Training loss: 1.7127369514873656
Validation loss: 2.644097672516207

Epoch: 6| Step: 2
Training loss: 2.3762234999670495
Validation loss: 2.632351413275695

Epoch: 6| Step: 3
Training loss: 2.778036597168057
Validation loss: 2.6073433282001086

Epoch: 6| Step: 4
Training loss: 2.12824685620318
Validation loss: 2.5708245228307804

Epoch: 6| Step: 5
Training loss: 2.0965533491643695
Validation loss: 2.5518293656600766

Epoch: 6| Step: 6
Training loss: 1.901032546208769
Validation loss: 2.5463148878041753

Epoch: 6| Step: 7
Training loss: 2.283366436497917
Validation loss: 2.5179016205332165

Epoch: 6| Step: 8
Training loss: 2.715773959623309
Validation loss: 2.490413628403426

Epoch: 6| Step: 9
Training loss: 2.219916238665201
Validation loss: 2.4895035133707335

Epoch: 6| Step: 10
Training loss: 2.757734086864388
Validation loss: 2.4855777220385837

Epoch: 6| Step: 11
Training loss: 2.227875653582562
Validation loss: 2.490830772639371

Epoch: 6| Step: 12
Training loss: 2.1706225399637162
Validation loss: 2.491970343780196

Epoch: 6| Step: 13
Training loss: 2.3652801383243096
Validation loss: 2.4886876786899337

Epoch: 220| Step: 0
Training loss: 2.4298992494018457
Validation loss: 2.4900547336782703

Epoch: 6| Step: 1
Training loss: 2.3956149015504895
Validation loss: 2.488978505318791

Epoch: 6| Step: 2
Training loss: 2.4228668150907953
Validation loss: 2.486334645636579

Epoch: 6| Step: 3
Training loss: 2.2445865782289456
Validation loss: 2.488126477468896

Epoch: 6| Step: 4
Training loss: 1.8776070589915381
Validation loss: 2.4936690595425235

Epoch: 6| Step: 5
Training loss: 2.526336044514754
Validation loss: 2.5073858672638587

Epoch: 6| Step: 6
Training loss: 1.7593337872355113
Validation loss: 2.5120814226220967

Epoch: 6| Step: 7
Training loss: 2.6523721550163457
Validation loss: 2.5097327560469265

Epoch: 6| Step: 8
Training loss: 2.3418456415311715
Validation loss: 2.5400746524032907

Epoch: 6| Step: 9
Training loss: 2.1523997997040683
Validation loss: 2.5750200320208454

Epoch: 6| Step: 10
Training loss: 2.5081504522762708
Validation loss: 2.591942367935353

Epoch: 6| Step: 11
Training loss: 2.362884538629746
Validation loss: 2.577749313570953

Epoch: 6| Step: 12
Training loss: 3.113200685614587
Validation loss: 2.567854930621055

Epoch: 6| Step: 13
Training loss: 1.7936954396951843
Validation loss: 2.5460796869667384

Epoch: 221| Step: 0
Training loss: 2.206241756780424
Validation loss: 2.5467043860456546

Epoch: 6| Step: 1
Training loss: 2.23055297906309
Validation loss: 2.534480988041937

Epoch: 6| Step: 2
Training loss: 2.6756891165137215
Validation loss: 2.5269636824528785

Epoch: 6| Step: 3
Training loss: 2.2277511903735876
Validation loss: 2.519194761374696

Epoch: 6| Step: 4
Training loss: 1.9334663734481234
Validation loss: 2.5433809539124788

Epoch: 6| Step: 5
Training loss: 1.5482660839613438
Validation loss: 2.5152705319957493

Epoch: 6| Step: 6
Training loss: 2.8828809776546866
Validation loss: 2.532114674010816

Epoch: 6| Step: 7
Training loss: 2.3178097363409607
Validation loss: 2.529659336585983

Epoch: 6| Step: 8
Training loss: 2.275274733837854
Validation loss: 2.542636472652107

Epoch: 6| Step: 9
Training loss: 2.7326975009249157
Validation loss: 2.5466022150345458

Epoch: 6| Step: 10
Training loss: 1.9329988431418914
Validation loss: 2.5754456131419343

Epoch: 6| Step: 11
Training loss: 2.547533757488688
Validation loss: 2.555986601014356

Epoch: 6| Step: 12
Training loss: 2.382073159504436
Validation loss: 2.5945265040420766

Epoch: 6| Step: 13
Training loss: 2.6148750679413273
Validation loss: 2.6082230117022185

Epoch: 222| Step: 0
Training loss: 2.5036131498328795
Validation loss: 2.614489007796015

Epoch: 6| Step: 1
Training loss: 1.7715729309625494
Validation loss: 2.6042067003351863

Epoch: 6| Step: 2
Training loss: 2.5741724406636903
Validation loss: 2.6094618761901067

Epoch: 6| Step: 3
Training loss: 2.1846563111704804
Validation loss: 2.5951035273241634

Epoch: 6| Step: 4
Training loss: 2.8224290846640883
Validation loss: 2.5562331475010924

Epoch: 6| Step: 5
Training loss: 2.1531060559860897
Validation loss: 2.532931424768494

Epoch: 6| Step: 6
Training loss: 1.9055322014823655
Validation loss: 2.4976597322661056

Epoch: 6| Step: 7
Training loss: 2.541422243299565
Validation loss: 2.4914625143749776

Epoch: 6| Step: 8
Training loss: 1.7263820778318621
Validation loss: 2.4928419156805948

Epoch: 6| Step: 9
Training loss: 3.3492731131325404
Validation loss: 2.490618444008936

Epoch: 6| Step: 10
Training loss: 1.9995294255740705
Validation loss: 2.4998038373917333

Epoch: 6| Step: 11
Training loss: 1.8895731750798441
Validation loss: 2.4936832893900953

Epoch: 6| Step: 12
Training loss: 2.3333333787463957
Validation loss: 2.5079455949397573

Epoch: 6| Step: 13
Training loss: 2.527333184386725
Validation loss: 2.5192390844208234

Epoch: 223| Step: 0
Training loss: 2.093882770029513
Validation loss: 2.532241956588259

Epoch: 6| Step: 1
Training loss: 2.115404342345976
Validation loss: 2.588662700522652

Epoch: 6| Step: 2
Training loss: 2.14984506448012
Validation loss: 2.6260750098244583

Epoch: 6| Step: 3
Training loss: 1.9400037769398841
Validation loss: 2.6102436470076458

Epoch: 6| Step: 4
Training loss: 2.3774940044596233
Validation loss: 2.6389017746147854

Epoch: 6| Step: 5
Training loss: 2.8970017488768636
Validation loss: 2.603560740868631

Epoch: 6| Step: 6
Training loss: 2.430880238478581
Validation loss: 2.6280349413621242

Epoch: 6| Step: 7
Training loss: 2.5935856410886324
Validation loss: 2.5849427521722514

Epoch: 6| Step: 8
Training loss: 2.966199240847008
Validation loss: 2.5693688636408956

Epoch: 6| Step: 9
Training loss: 2.189403250923367
Validation loss: 2.5471739876272155

Epoch: 6| Step: 10
Training loss: 1.7053859996422742
Validation loss: 2.5141719309855284

Epoch: 6| Step: 11
Training loss: 2.192620089122739
Validation loss: 2.5088104290693956

Epoch: 6| Step: 12
Training loss: 2.2745050499726474
Validation loss: 2.4983410417244016

Epoch: 6| Step: 13
Training loss: 2.4471438439247675
Validation loss: 2.500551607948631

Epoch: 224| Step: 0
Training loss: 1.8895589171503613
Validation loss: 2.504234296442971

Epoch: 6| Step: 1
Training loss: 2.4867920064487503
Validation loss: 2.50536644662017

Epoch: 6| Step: 2
Training loss: 2.3653887974724173
Validation loss: 2.523676133658004

Epoch: 6| Step: 3
Training loss: 2.1576400919990255
Validation loss: 2.5224930104869925

Epoch: 6| Step: 4
Training loss: 2.547289387510647
Validation loss: 2.5486277222561213

Epoch: 6| Step: 5
Training loss: 2.143749546240044
Validation loss: 2.5815576993414844

Epoch: 6| Step: 6
Training loss: 1.6686988679860193
Validation loss: 2.6205259675567034

Epoch: 6| Step: 7
Training loss: 2.51281258835334
Validation loss: 2.62989733276816

Epoch: 6| Step: 8
Training loss: 2.2600166095697185
Validation loss: 2.6289679041562644

Epoch: 6| Step: 9
Training loss: 2.311373255709573
Validation loss: 2.6308926186352783

Epoch: 6| Step: 10
Training loss: 2.4348999240997276
Validation loss: 2.6098735584310044

Epoch: 6| Step: 11
Training loss: 2.334235448381119
Validation loss: 2.6048490520340426

Epoch: 6| Step: 12
Training loss: 2.4033768580177504
Validation loss: 2.571645837263929

Epoch: 6| Step: 13
Training loss: 2.6298621425106754
Validation loss: 2.5313883928056398

Epoch: 225| Step: 0
Training loss: 1.9300278583551844
Validation loss: 2.5077933274087822

Epoch: 6| Step: 1
Training loss: 2.9596625731140187
Validation loss: 2.49867889943058

Epoch: 6| Step: 2
Training loss: 2.0643020617921537
Validation loss: 2.5056889179438198

Epoch: 6| Step: 3
Training loss: 1.9623649842293216
Validation loss: 2.5046420868429116

Epoch: 6| Step: 4
Training loss: 1.6516149189551228
Validation loss: 2.4914609992159247

Epoch: 6| Step: 5
Training loss: 2.822642877305802
Validation loss: 2.4970156659037275

Epoch: 6| Step: 6
Training loss: 1.4083936670836472
Validation loss: 2.512062409158199

Epoch: 6| Step: 7
Training loss: 1.5605476388941342
Validation loss: 2.514764373970813

Epoch: 6| Step: 8
Training loss: 2.335339932254431
Validation loss: 2.5096869509545985

Epoch: 6| Step: 9
Training loss: 2.8892959426141083
Validation loss: 2.528497800936581

Epoch: 6| Step: 10
Training loss: 2.9893961104585336
Validation loss: 2.5503817017049983

Epoch: 6| Step: 11
Training loss: 1.6709565108533884
Validation loss: 2.554339899491331

Epoch: 6| Step: 12
Training loss: 2.3978999526443645
Validation loss: 2.557779336852987

Epoch: 6| Step: 13
Training loss: 2.3618279646676807
Validation loss: 2.5656437391866023

Epoch: 226| Step: 0
Training loss: 1.9548554346044713
Validation loss: 2.579333228390868

Epoch: 6| Step: 1
Training loss: 1.92723489801109
Validation loss: 2.5627283134164323

Epoch: 6| Step: 2
Training loss: 2.4886274111956075
Validation loss: 2.571639100291887

Epoch: 6| Step: 3
Training loss: 2.689616589644701
Validation loss: 2.566777079135352

Epoch: 6| Step: 4
Training loss: 1.7879305261047949
Validation loss: 2.5737641800991113

Epoch: 6| Step: 5
Training loss: 2.0709298994651015
Validation loss: 2.552548429706578

Epoch: 6| Step: 6
Training loss: 2.748890999945931
Validation loss: 2.531005800500536

Epoch: 6| Step: 7
Training loss: 2.777621012608642
Validation loss: 2.539624751511868

Epoch: 6| Step: 8
Training loss: 2.4231471504495827
Validation loss: 2.5312841279668685

Epoch: 6| Step: 9
Training loss: 2.2972249912715257
Validation loss: 2.520683525825437

Epoch: 6| Step: 10
Training loss: 2.5562465938181673
Validation loss: 2.5376113657323813

Epoch: 6| Step: 11
Training loss: 1.7905585018679089
Validation loss: 2.550022933582574

Epoch: 6| Step: 12
Training loss: 1.9966272884024536
Validation loss: 2.561024124514491

Epoch: 6| Step: 13
Training loss: 2.233824868935446
Validation loss: 2.5695108479576843

Epoch: 227| Step: 0
Training loss: 2.919301250933376
Validation loss: 2.588519026556858

Epoch: 6| Step: 1
Training loss: 2.208924580244535
Validation loss: 2.5933382098079356

Epoch: 6| Step: 2
Training loss: 1.6671223335436425
Validation loss: 2.5961522999873905

Epoch: 6| Step: 3
Training loss: 2.109935431735419
Validation loss: 2.5849949558634338

Epoch: 6| Step: 4
Training loss: 2.6210033327246665
Validation loss: 2.569690060832879

Epoch: 6| Step: 5
Training loss: 1.993743169408117
Validation loss: 2.563824598149907

Epoch: 6| Step: 6
Training loss: 2.568341551744241
Validation loss: 2.5681203288529955

Epoch: 6| Step: 7
Training loss: 2.369200803994038
Validation loss: 2.538521545689396

Epoch: 6| Step: 8
Training loss: 2.3239725447328063
Validation loss: 2.529075881945858

Epoch: 6| Step: 9
Training loss: 1.578347520908825
Validation loss: 2.5210096492005145

Epoch: 6| Step: 10
Training loss: 2.7049406271463186
Validation loss: 2.51461220329376

Epoch: 6| Step: 11
Training loss: 1.767688119743138
Validation loss: 2.517098731621271

Epoch: 6| Step: 12
Training loss: 2.405054563351475
Validation loss: 2.513985204051726

Epoch: 6| Step: 13
Training loss: 2.005671327982507
Validation loss: 2.5023005073392675

Epoch: 228| Step: 0
Training loss: 2.6622738021257977
Validation loss: 2.5022641737289373

Epoch: 6| Step: 1
Training loss: 2.0629554014576565
Validation loss: 2.5021288867353677

Epoch: 6| Step: 2
Training loss: 1.6358573303690838
Validation loss: 2.5079130665548934

Epoch: 6| Step: 3
Training loss: 2.7856610925367686
Validation loss: 2.5233065489498485

Epoch: 6| Step: 4
Training loss: 2.4928620480876793
Validation loss: 2.528829107638986

Epoch: 6| Step: 5
Training loss: 2.5613737655233813
Validation loss: 2.560923067881967

Epoch: 6| Step: 6
Training loss: 2.096919379638757
Validation loss: 2.5893625969896266

Epoch: 6| Step: 7
Training loss: 1.7720612550830057
Validation loss: 2.6118805937392584

Epoch: 6| Step: 8
Training loss: 2.0733239494225852
Validation loss: 2.6195495877874113

Epoch: 6| Step: 9
Training loss: 1.652610522800088
Validation loss: 2.609077756478209

Epoch: 6| Step: 10
Training loss: 2.479569111277219
Validation loss: 2.601921201917763

Epoch: 6| Step: 11
Training loss: 2.388456270931979
Validation loss: 2.5596547496713806

Epoch: 6| Step: 12
Training loss: 2.2639256911871657
Validation loss: 2.569348882209766

Epoch: 6| Step: 13
Training loss: 2.472918214826948
Validation loss: 2.54784572956923

Epoch: 229| Step: 0
Training loss: 2.298036035346482
Validation loss: 2.5385747979127937

Epoch: 6| Step: 1
Training loss: 2.103658205546747
Validation loss: 2.538008016085159

Epoch: 6| Step: 2
Training loss: 1.4323404014850374
Validation loss: 2.5309562669661054

Epoch: 6| Step: 3
Training loss: 1.8017572831977542
Validation loss: 2.5203276565767667

Epoch: 6| Step: 4
Training loss: 3.1367835089244447
Validation loss: 2.52944084160335

Epoch: 6| Step: 5
Training loss: 2.5775748850824893
Validation loss: 2.520458309136272

Epoch: 6| Step: 6
Training loss: 2.122958380601608
Validation loss: 2.5079702008853393

Epoch: 6| Step: 7
Training loss: 2.0510528094013387
Validation loss: 2.5257762703972833

Epoch: 6| Step: 8
Training loss: 1.825446750880867
Validation loss: 2.4921934313090666

Epoch: 6| Step: 9
Training loss: 3.016086207091229
Validation loss: 2.5139387651510527

Epoch: 6| Step: 10
Training loss: 2.6503335922727898
Validation loss: 2.532796724691179

Epoch: 6| Step: 11
Training loss: 1.7030921022930094
Validation loss: 2.535145207534354

Epoch: 6| Step: 12
Training loss: 2.049461884932664
Validation loss: 2.5352368452195235

Epoch: 6| Step: 13
Training loss: 2.080152053593813
Validation loss: 2.5480509346502678

Epoch: 230| Step: 0
Training loss: 1.762180039602616
Validation loss: 2.578210833112892

Epoch: 6| Step: 1
Training loss: 2.403460384225727
Validation loss: 2.594435712262783

Epoch: 6| Step: 2
Training loss: 2.4982699129869825
Validation loss: 2.593559916934578

Epoch: 6| Step: 3
Training loss: 1.975001929076979
Validation loss: 2.586883556262417

Epoch: 6| Step: 4
Training loss: 1.791866853161252
Validation loss: 2.586569318004614

Epoch: 6| Step: 5
Training loss: 2.3582332450557
Validation loss: 2.5849697303598407

Epoch: 6| Step: 6
Training loss: 2.2989446955629087
Validation loss: 2.5551899018357043

Epoch: 6| Step: 7
Training loss: 2.475122652964252
Validation loss: 2.541130968349977

Epoch: 6| Step: 8
Training loss: 2.6739377987802193
Validation loss: 2.5100346244207095

Epoch: 6| Step: 9
Training loss: 1.4984105749167478
Validation loss: 2.4926088588796427

Epoch: 6| Step: 10
Training loss: 2.7772994540903273
Validation loss: 2.494468267155231

Epoch: 6| Step: 11
Training loss: 2.7411520543584453
Validation loss: 2.4797137054936758

Epoch: 6| Step: 12
Training loss: 2.4795460343946285
Validation loss: 2.4918943051318423

Epoch: 6| Step: 13
Training loss: 1.3901617585885875
Validation loss: 2.499174935570046

Epoch: 231| Step: 0
Training loss: 2.2001169650456296
Validation loss: 2.4962860335829675

Epoch: 6| Step: 1
Training loss: 2.237633523206981
Validation loss: 2.5157297163941092

Epoch: 6| Step: 2
Training loss: 2.725093150515335
Validation loss: 2.5193824743855404

Epoch: 6| Step: 3
Training loss: 2.1859837317877893
Validation loss: 2.535384283013099

Epoch: 6| Step: 4
Training loss: 2.9048036647507716
Validation loss: 2.5266637186957537

Epoch: 6| Step: 5
Training loss: 2.081810229166249
Validation loss: 2.536260943137711

Epoch: 6| Step: 6
Training loss: 1.835230654738338
Validation loss: 2.570304074413709

Epoch: 6| Step: 7
Training loss: 1.9552364685386374
Validation loss: 2.5717091114038086

Epoch: 6| Step: 8
Training loss: 2.1816475098859023
Validation loss: 2.5807240957960293

Epoch: 6| Step: 9
Training loss: 2.3383792631061797
Validation loss: 2.562910318475819

Epoch: 6| Step: 10
Training loss: 1.552444526922148
Validation loss: 2.5522978763838475

Epoch: 6| Step: 11
Training loss: 2.771500375713589
Validation loss: 2.5413415627935056

Epoch: 6| Step: 12
Training loss: 2.4492588557073223
Validation loss: 2.5429733127879253

Epoch: 6| Step: 13
Training loss: 1.8042072135944311
Validation loss: 2.52139646897463

Epoch: 232| Step: 0
Training loss: 2.0634840727279915
Validation loss: 2.5312700310059726

Epoch: 6| Step: 1
Training loss: 2.9626640177845665
Validation loss: 2.513384466924362

Epoch: 6| Step: 2
Training loss: 1.9958247471931971
Validation loss: 2.532564897022666

Epoch: 6| Step: 3
Training loss: 2.0411594175947867
Validation loss: 2.502152184124849

Epoch: 6| Step: 4
Training loss: 2.3224803931124156
Validation loss: 2.5120397573228423

Epoch: 6| Step: 5
Training loss: 2.504626665905557
Validation loss: 2.5217923528591975

Epoch: 6| Step: 6
Training loss: 2.5505387802899966
Validation loss: 2.52119790480604

Epoch: 6| Step: 7
Training loss: 2.638149478006211
Validation loss: 2.523090673337095

Epoch: 6| Step: 8
Training loss: 1.5709875373467415
Validation loss: 2.534663767263984

Epoch: 6| Step: 9
Training loss: 1.9803059828947323
Validation loss: 2.543228019002145

Epoch: 6| Step: 10
Training loss: 2.9327464499172025
Validation loss: 2.5429093548801225

Epoch: 6| Step: 11
Training loss: 1.984591614922637
Validation loss: 2.5643257444558594

Epoch: 6| Step: 12
Training loss: 1.7206641202526225
Validation loss: 2.54837293201997

Epoch: 6| Step: 13
Training loss: 1.8453753144945408
Validation loss: 2.570543443069445

Epoch: 233| Step: 0
Training loss: 2.2647633986021476
Validation loss: 2.578791815325809

Epoch: 6| Step: 1
Training loss: 2.3368965145078726
Validation loss: 2.5507038410430387

Epoch: 6| Step: 2
Training loss: 2.1494894885391584
Validation loss: 2.5810781500186906

Epoch: 6| Step: 3
Training loss: 2.727253211558482
Validation loss: 2.5476838526146315

Epoch: 6| Step: 4
Training loss: 2.149551158451525
Validation loss: 2.5459773660259524

Epoch: 6| Step: 5
Training loss: 2.2615311039116754
Validation loss: 2.5261233182209977

Epoch: 6| Step: 6
Training loss: 2.0051263437394438
Validation loss: 2.5448068908494177

Epoch: 6| Step: 7
Training loss: 1.7521490117243166
Validation loss: 2.551159350192589

Epoch: 6| Step: 8
Training loss: 2.5317915348937534
Validation loss: 2.5323690130885206

Epoch: 6| Step: 9
Training loss: 2.187173982576561
Validation loss: 2.5260493694594355

Epoch: 6| Step: 10
Training loss: 1.917119414994506
Validation loss: 2.535231218370823

Epoch: 6| Step: 11
Training loss: 2.3549352645885686
Validation loss: 2.538978442243415

Epoch: 6| Step: 12
Training loss: 2.117689460286262
Validation loss: 2.550697687483197

Epoch: 6| Step: 13
Training loss: 2.3000499554060303
Validation loss: 2.5790078703311674

Epoch: 234| Step: 0
Training loss: 2.791862727629924
Validation loss: 2.6067032374949197

Epoch: 6| Step: 1
Training loss: 1.3699170576173496
Validation loss: 2.6242373054819748

Epoch: 6| Step: 2
Training loss: 2.032336370021125
Validation loss: 2.640566191309979

Epoch: 6| Step: 3
Training loss: 2.2758515116318168
Validation loss: 2.6586926915936595

Epoch: 6| Step: 4
Training loss: 2.3337140680947903
Validation loss: 2.6520419428957482

Epoch: 6| Step: 5
Training loss: 2.3630084424152575
Validation loss: 2.5911444787001146

Epoch: 6| Step: 6
Training loss: 1.9016287397948297
Validation loss: 2.5316910967695545

Epoch: 6| Step: 7
Training loss: 2.1553218889688748
Validation loss: 2.495081274840418

Epoch: 6| Step: 8
Training loss: 2.628682142570901
Validation loss: 2.482550024711139

Epoch: 6| Step: 9
Training loss: 2.6218152481563393
Validation loss: 2.4813605039702007

Epoch: 6| Step: 10
Training loss: 2.0351495724383613
Validation loss: 2.4972058496750615

Epoch: 6| Step: 11
Training loss: 2.0921679540722526
Validation loss: 2.504688317355671

Epoch: 6| Step: 12
Training loss: 2.715976835402076
Validation loss: 2.471131829623556

Epoch: 6| Step: 13
Training loss: 2.6079000541749906
Validation loss: 2.4757355473622424

Epoch: 235| Step: 0
Training loss: 2.6758240188187825
Validation loss: 2.4888431507498465

Epoch: 6| Step: 1
Training loss: 1.9687458219937997
Validation loss: 2.506561823065923

Epoch: 6| Step: 2
Training loss: 2.4912399356100896
Validation loss: 2.545305107578996

Epoch: 6| Step: 3
Training loss: 2.3450341330770925
Validation loss: 2.567478708725569

Epoch: 6| Step: 4
Training loss: 2.2938666332225948
Validation loss: 2.5560048602142054

Epoch: 6| Step: 5
Training loss: 2.3336929203157357
Validation loss: 2.5545103612492905

Epoch: 6| Step: 6
Training loss: 2.4718739505963323
Validation loss: 2.5582370033725574

Epoch: 6| Step: 7
Training loss: 2.2768560446767716
Validation loss: 2.5414881617497826

Epoch: 6| Step: 8
Training loss: 2.09723498555974
Validation loss: 2.5486813713688603

Epoch: 6| Step: 9
Training loss: 1.9855836206338475
Validation loss: 2.52668037336183

Epoch: 6| Step: 10
Training loss: 1.9530121427354827
Validation loss: 2.5177033962653264

Epoch: 6| Step: 11
Training loss: 1.2673124672715261
Validation loss: 2.512948976322824

Epoch: 6| Step: 12
Training loss: 2.586719129741506
Validation loss: 2.509960011674099

Epoch: 6| Step: 13
Training loss: 3.228696251516718
Validation loss: 2.517148048475321

Epoch: 236| Step: 0
Training loss: 1.9160818230473105
Validation loss: 2.5303752392345045

Epoch: 6| Step: 1
Training loss: 2.1942118536206423
Validation loss: 2.534021837908155

Epoch: 6| Step: 2
Training loss: 1.9198938097993237
Validation loss: 2.543810336485417

Epoch: 6| Step: 3
Training loss: 2.2634325666214528
Validation loss: 2.5679580432934412

Epoch: 6| Step: 4
Training loss: 2.364748463067288
Validation loss: 2.5767292444526904

Epoch: 6| Step: 5
Training loss: 2.149873454783335
Validation loss: 2.598182093427577

Epoch: 6| Step: 6
Training loss: 2.312976891085133
Validation loss: 2.6204701651641256

Epoch: 6| Step: 7
Training loss: 3.009828362624842
Validation loss: 2.6216268816833432

Epoch: 6| Step: 8
Training loss: 2.2804166761087337
Validation loss: 2.6712306697623855

Epoch: 6| Step: 9
Training loss: 1.897351366335826
Validation loss: 2.671797485416932

Epoch: 6| Step: 10
Training loss: 2.3936299904005263
Validation loss: 2.6553150925263167

Epoch: 6| Step: 11
Training loss: 2.4744288161115926
Validation loss: 2.623685689413325

Epoch: 6| Step: 12
Training loss: 1.8584918320922514
Validation loss: 2.5825101299647293

Epoch: 6| Step: 13
Training loss: 2.1918229031687257
Validation loss: 2.5489044840593436

Epoch: 237| Step: 0
Training loss: 2.5044794006901805
Validation loss: 2.5273749591800914

Epoch: 6| Step: 1
Training loss: 1.884599146630775
Validation loss: 2.504817279159198

Epoch: 6| Step: 2
Training loss: 1.8908001526966682
Validation loss: 2.528159652994296

Epoch: 6| Step: 3
Training loss: 1.8127284070497764
Validation loss: 2.507292443024267

Epoch: 6| Step: 4
Training loss: 2.3692354213181135
Validation loss: 2.5279312197839188

Epoch: 6| Step: 5
Training loss: 2.4022522451450015
Validation loss: 2.51185663694143

Epoch: 6| Step: 6
Training loss: 2.333020075705526
Validation loss: 2.5055430314943874

Epoch: 6| Step: 7
Training loss: 2.167929929093585
Validation loss: 2.5398830868003874

Epoch: 6| Step: 8
Training loss: 2.528361426616273
Validation loss: 2.5359962846731774

Epoch: 6| Step: 9
Training loss: 2.2427563095335694
Validation loss: 2.5170206262079065

Epoch: 6| Step: 10
Training loss: 2.189866883573848
Validation loss: 2.541053578168834

Epoch: 6| Step: 11
Training loss: 2.084935894353405
Validation loss: 2.548323478775314

Epoch: 6| Step: 12
Training loss: 2.223676772388812
Validation loss: 2.58798928510589

Epoch: 6| Step: 13
Training loss: 2.6093781065779598
Validation loss: 2.56259815679359

Epoch: 238| Step: 0
Training loss: 1.912228012690673
Validation loss: 2.587024855794253

Epoch: 6| Step: 1
Training loss: 2.281680863333712
Validation loss: 2.5874484163016844

Epoch: 6| Step: 2
Training loss: 2.388257618476171
Validation loss: 2.586512567937593

Epoch: 6| Step: 3
Training loss: 2.025937219066915
Validation loss: 2.605877525370453

Epoch: 6| Step: 4
Training loss: 2.3324293247321783
Validation loss: 2.6113388377055253

Epoch: 6| Step: 5
Training loss: 2.835788859525784
Validation loss: 2.6107249927009213

Epoch: 6| Step: 6
Training loss: 2.241807752610448
Validation loss: 2.647755853035074

Epoch: 6| Step: 7
Training loss: 2.365370251180753
Validation loss: 2.6376187971217626

Epoch: 6| Step: 8
Training loss: 2.322634270670212
Validation loss: 2.618865884115094

Epoch: 6| Step: 9
Training loss: 1.4047924541433654
Validation loss: 2.5815204032295083

Epoch: 6| Step: 10
Training loss: 2.4444012878923953
Validation loss: 2.5633354995910196

Epoch: 6| Step: 11
Training loss: 2.200010980231887
Validation loss: 2.5462675871980616

Epoch: 6| Step: 12
Training loss: 2.0619799796463596
Validation loss: 2.565501703481704

Epoch: 6| Step: 13
Training loss: 2.344967233554988
Validation loss: 2.5452933519742613

Epoch: 239| Step: 0
Training loss: 2.51922936811873
Validation loss: 2.5534039616174753

Epoch: 6| Step: 1
Training loss: 2.3210542565693024
Validation loss: 2.562816894909525

Epoch: 6| Step: 2
Training loss: 2.4401227094718565
Validation loss: 2.554399884411285

Epoch: 6| Step: 3
Training loss: 2.0474538203098183
Validation loss: 2.56157340377802

Epoch: 6| Step: 4
Training loss: 2.3928312206694295
Validation loss: 2.568627931118466

Epoch: 6| Step: 5
Training loss: 1.813733437565715
Validation loss: 2.591677944939739

Epoch: 6| Step: 6
Training loss: 2.4437982422732833
Validation loss: 2.5842222765963005

Epoch: 6| Step: 7
Training loss: 1.9535537859403225
Validation loss: 2.599571313729869

Epoch: 6| Step: 8
Training loss: 2.430753320792336
Validation loss: 2.5958700745882215

Epoch: 6| Step: 9
Training loss: 3.00745197463912
Validation loss: 2.586881451841021

Epoch: 6| Step: 10
Training loss: 1.2054529828111549
Validation loss: 2.5640162889778484

Epoch: 6| Step: 11
Training loss: 1.9186718306632111
Validation loss: 2.5196874368049316

Epoch: 6| Step: 12
Training loss: 2.3806488720134364
Validation loss: 2.515255523780728

Epoch: 6| Step: 13
Training loss: 2.032227853007459
Validation loss: 2.4922486380449227

Epoch: 240| Step: 0
Training loss: 2.0404596328911415
Validation loss: 2.497286468328177

Epoch: 6| Step: 1
Training loss: 2.877846676833449
Validation loss: 2.505367429972594

Epoch: 6| Step: 2
Training loss: 2.247274867780945
Validation loss: 2.5129977263078422

Epoch: 6| Step: 3
Training loss: 2.1876900726574378
Validation loss: 2.4873748038525876

Epoch: 6| Step: 4
Training loss: 2.5643648014707217
Validation loss: 2.5199523731554936

Epoch: 6| Step: 5
Training loss: 2.0155606518313802
Validation loss: 2.563303581093238

Epoch: 6| Step: 6
Training loss: 2.073654299155186
Validation loss: 2.614813567786039

Epoch: 6| Step: 7
Training loss: 1.5268408686492152
Validation loss: 2.632139729345575

Epoch: 6| Step: 8
Training loss: 2.162275878229181
Validation loss: 2.677723838883736

Epoch: 6| Step: 9
Training loss: 2.642586605850674
Validation loss: 2.6708801082932925

Epoch: 6| Step: 10
Training loss: 1.4790736245277587
Validation loss: 2.681539179361898

Epoch: 6| Step: 11
Training loss: 3.051264803927467
Validation loss: 2.7043115000054048

Epoch: 6| Step: 12
Training loss: 2.1868693941430966
Validation loss: 2.641121180038221

Epoch: 6| Step: 13
Training loss: 2.2018197163190694
Validation loss: 2.613045081627478

Epoch: 241| Step: 0
Training loss: 2.28511764624177
Validation loss: 2.5559806234105857

Epoch: 6| Step: 1
Training loss: 2.2663969632115943
Validation loss: 2.5304436203754155

Epoch: 6| Step: 2
Training loss: 2.7869263918394926
Validation loss: 2.5058777378090342

Epoch: 6| Step: 3
Training loss: 1.8980213227154599
Validation loss: 2.4974331871211928

Epoch: 6| Step: 4
Training loss: 2.816295436419797
Validation loss: 2.489456322488009

Epoch: 6| Step: 5
Training loss: 2.156890663392975
Validation loss: 2.4770850944887086

Epoch: 6| Step: 6
Training loss: 2.2259645964282546
Validation loss: 2.470822136667581

Epoch: 6| Step: 7
Training loss: 2.271231193569592
Validation loss: 2.4794452467976527

Epoch: 6| Step: 8
Training loss: 2.9066722932230302
Validation loss: 2.4857092899069775

Epoch: 6| Step: 9
Training loss: 1.5630815568123981
Validation loss: 2.474325635982427

Epoch: 6| Step: 10
Training loss: 1.7384680486885673
Validation loss: 2.4708775716319775

Epoch: 6| Step: 11
Training loss: 2.578230699626553
Validation loss: 2.5050950028024275

Epoch: 6| Step: 12
Training loss: 1.4169484400552133
Validation loss: 2.534786697043795

Epoch: 6| Step: 13
Training loss: 2.2780323067267334
Validation loss: 2.5649344037934267

Epoch: 242| Step: 0
Training loss: 2.5301043896757007
Validation loss: 2.59431002595638

Epoch: 6| Step: 1
Training loss: 2.4778993289747855
Validation loss: 2.6458082022687406

Epoch: 6| Step: 2
Training loss: 1.82965532465138
Validation loss: 2.6985509463143598

Epoch: 6| Step: 3
Training loss: 2.312911641367371
Validation loss: 2.7023498658604272

Epoch: 6| Step: 4
Training loss: 1.7873683053967817
Validation loss: 2.7518903564052377

Epoch: 6| Step: 5
Training loss: 1.9814774391724632
Validation loss: 2.731849128660569

Epoch: 6| Step: 6
Training loss: 2.2195586759060446
Validation loss: 2.6923897048664576

Epoch: 6| Step: 7
Training loss: 1.67810942573353
Validation loss: 2.6804769111345252

Epoch: 6| Step: 8
Training loss: 2.5997772047980194
Validation loss: 2.617024491580945

Epoch: 6| Step: 9
Training loss: 2.68434525674278
Validation loss: 2.5516492565299433

Epoch: 6| Step: 10
Training loss: 1.2813676919614305
Validation loss: 2.535749572697707

Epoch: 6| Step: 11
Training loss: 2.697818199530822
Validation loss: 2.5117810658367348

Epoch: 6| Step: 12
Training loss: 1.492336165926417
Validation loss: 2.4772703681406427

Epoch: 6| Step: 13
Training loss: 3.075310209180601
Validation loss: 2.4863282848197286

Epoch: 243| Step: 0
Training loss: 2.5120253309078233
Validation loss: 2.4914100414880065

Epoch: 6| Step: 1
Training loss: 2.459305479431563
Validation loss: 2.4811387406266796

Epoch: 6| Step: 2
Training loss: 2.099777200778148
Validation loss: 2.4899044122438942

Epoch: 6| Step: 3
Training loss: 2.206528003673113
Validation loss: 2.4984290432384286

Epoch: 6| Step: 4
Training loss: 1.7549921764840617
Validation loss: 2.4885115823780857

Epoch: 6| Step: 5
Training loss: 2.94700221963261
Validation loss: 2.4797256998806665

Epoch: 6| Step: 6
Training loss: 2.3053759564941356
Validation loss: 2.5137303643682447

Epoch: 6| Step: 7
Training loss: 1.8237656351194502
Validation loss: 2.5368325794849493

Epoch: 6| Step: 8
Training loss: 2.1073202792789827
Validation loss: 2.581369951122762

Epoch: 6| Step: 9
Training loss: 2.3066623308806196
Validation loss: 2.5745822030533287

Epoch: 6| Step: 10
Training loss: 1.9226529167484312
Validation loss: 2.606954643687062

Epoch: 6| Step: 11
Training loss: 2.1053700043518737
Validation loss: 2.6508910180676675

Epoch: 6| Step: 12
Training loss: 2.3090910658293597
Validation loss: 2.650312092235324

Epoch: 6| Step: 13
Training loss: 2.657258055646477
Validation loss: 2.692008620548285

Epoch: 244| Step: 0
Training loss: 1.4927561210796874
Validation loss: 2.663282054491818

Epoch: 6| Step: 1
Training loss: 1.6783257220542984
Validation loss: 2.6575127236895133

Epoch: 6| Step: 2
Training loss: 2.561757422059618
Validation loss: 2.6426511436311872

Epoch: 6| Step: 3
Training loss: 2.3615068315984256
Validation loss: 2.633600149238361

Epoch: 6| Step: 4
Training loss: 2.727080112938161
Validation loss: 2.627375632795992

Epoch: 6| Step: 5
Training loss: 2.5364339045314948
Validation loss: 2.59588340743637

Epoch: 6| Step: 6
Training loss: 1.464435489982843
Validation loss: 2.5741930792941465

Epoch: 6| Step: 7
Training loss: 2.6908477513775746
Validation loss: 2.5398989038298003

Epoch: 6| Step: 8
Training loss: 1.4439454908253475
Validation loss: 2.536014703471322

Epoch: 6| Step: 9
Training loss: 2.3851266098804715
Validation loss: 2.5185286387565373

Epoch: 6| Step: 10
Training loss: 2.7146436000017604
Validation loss: 2.509867838993493

Epoch: 6| Step: 11
Training loss: 2.084914052824724
Validation loss: 2.5200034002250864

Epoch: 6| Step: 12
Training loss: 1.833223845362538
Validation loss: 2.514338304474871

Epoch: 6| Step: 13
Training loss: 2.3137510884765176
Validation loss: 2.5394356243142924

Epoch: 245| Step: 0
Training loss: 2.2392690985187675
Validation loss: 2.5323329304437925

Epoch: 6| Step: 1
Training loss: 1.9440757159648636
Validation loss: 2.5294122578778726

Epoch: 6| Step: 2
Training loss: 1.957635782338667
Validation loss: 2.5358156072686717

Epoch: 6| Step: 3
Training loss: 3.0708625436650467
Validation loss: 2.5574904375590486

Epoch: 6| Step: 4
Training loss: 2.2443337618832464
Validation loss: 2.5566786026665667

Epoch: 6| Step: 5
Training loss: 2.2716673156595553
Validation loss: 2.563139510021797

Epoch: 6| Step: 6
Training loss: 1.9192666442356088
Validation loss: 2.568796532078749

Epoch: 6| Step: 7
Training loss: 1.2606151466570843
Validation loss: 2.536528605297755

Epoch: 6| Step: 8
Training loss: 2.4093737452561887
Validation loss: 2.5221658500341184

Epoch: 6| Step: 9
Training loss: 2.175892578783313
Validation loss: 2.54639790752875

Epoch: 6| Step: 10
Training loss: 1.8978259196467306
Validation loss: 2.540493785727677

Epoch: 6| Step: 11
Training loss: 2.323638074127753
Validation loss: 2.537718698006337

Epoch: 6| Step: 12
Training loss: 2.4470356972494867
Validation loss: 2.534541435123247

Epoch: 6| Step: 13
Training loss: 2.5142801611393133
Validation loss: 2.5437254670980707

Epoch: 246| Step: 0
Training loss: 2.6310967081319387
Validation loss: 2.5673318681079595

Epoch: 6| Step: 1
Training loss: 1.7047207557238597
Validation loss: 2.571359083142499

Epoch: 6| Step: 2
Training loss: 2.305714317074622
Validation loss: 2.5858951960826824

Epoch: 6| Step: 3
Training loss: 2.6119174106912753
Validation loss: 2.5651729258246805

Epoch: 6| Step: 4
Training loss: 1.9710507346232522
Validation loss: 2.544475946712613

Epoch: 6| Step: 5
Training loss: 2.509587215509462
Validation loss: 2.572666184334447

Epoch: 6| Step: 6
Training loss: 1.8519772093340734
Validation loss: 2.558805718025719

Epoch: 6| Step: 7
Training loss: 2.437435247099145
Validation loss: 2.541879384462496

Epoch: 6| Step: 8
Training loss: 1.9009293893204906
Validation loss: 2.576549117757399

Epoch: 6| Step: 9
Training loss: 2.3764864636659104
Validation loss: 2.5561361298385403

Epoch: 6| Step: 10
Training loss: 1.9773445843800714
Validation loss: 2.58436687365188

Epoch: 6| Step: 11
Training loss: 2.2887502203399035
Validation loss: 2.580089429493198

Epoch: 6| Step: 12
Training loss: 2.1850866901999484
Validation loss: 2.5980066660628376

Epoch: 6| Step: 13
Training loss: 2.145327005247018
Validation loss: 2.6486027908883525

Epoch: 247| Step: 0
Training loss: 2.1267246652584926
Validation loss: 2.634751553847827

Epoch: 6| Step: 1
Training loss: 2.4436360910702426
Validation loss: 2.659866772855134

Epoch: 6| Step: 2
Training loss: 1.9134843848523062
Validation loss: 2.644392422178635

Epoch: 6| Step: 3
Training loss: 2.5507277852599386
Validation loss: 2.6714419186829126

Epoch: 6| Step: 4
Training loss: 1.9947781342395168
Validation loss: 2.647529303797092

Epoch: 6| Step: 5
Training loss: 1.8532191723830351
Validation loss: 2.635089647914311

Epoch: 6| Step: 6
Training loss: 2.4918911079018153
Validation loss: 2.5964335917597148

Epoch: 6| Step: 7
Training loss: 1.7063994122156776
Validation loss: 2.557882778015525

Epoch: 6| Step: 8
Training loss: 2.355532618426964
Validation loss: 2.556365073799832

Epoch: 6| Step: 9
Training loss: 2.881532958859427
Validation loss: 2.530890929888003

Epoch: 6| Step: 10
Training loss: 1.37392274966181
Validation loss: 2.5244222319893197

Epoch: 6| Step: 11
Training loss: 1.3788613806494505
Validation loss: 2.507332689567503

Epoch: 6| Step: 12
Training loss: 2.2985393696090086
Validation loss: 2.5138042961439395

Epoch: 6| Step: 13
Training loss: 2.4877351314271707
Validation loss: 2.5175265752557077

Epoch: 248| Step: 0
Training loss: 2.5586696001996505
Validation loss: 2.519208373838026

Epoch: 6| Step: 1
Training loss: 2.22836947818602
Validation loss: 2.5081100287372036

Epoch: 6| Step: 2
Training loss: 2.352094114924798
Validation loss: 2.5169100273226714

Epoch: 6| Step: 3
Training loss: 2.6370956942655894
Validation loss: 2.5183487357176233

Epoch: 6| Step: 4
Training loss: 1.602678161572466
Validation loss: 2.5276440182136968

Epoch: 6| Step: 5
Training loss: 2.8157965096621744
Validation loss: 2.5529028270959158

Epoch: 6| Step: 6
Training loss: 2.537119711956906
Validation loss: 2.5623165623206283

Epoch: 6| Step: 7
Training loss: 1.6255391033612192
Validation loss: 2.602765649947992

Epoch: 6| Step: 8
Training loss: 2.4644190789696365
Validation loss: 2.5657329169563936

Epoch: 6| Step: 9
Training loss: 1.8277664485040477
Validation loss: 2.5861872219199644

Epoch: 6| Step: 10
Training loss: 1.932723464086935
Validation loss: 2.5807430961122617

Epoch: 6| Step: 11
Training loss: 2.070673382093385
Validation loss: 2.586186899257679

Epoch: 6| Step: 12
Training loss: 1.914757551776773
Validation loss: 2.5849689463822934

Epoch: 6| Step: 13
Training loss: 1.9375935193533844
Validation loss: 2.5638504811619245

Epoch: 249| Step: 0
Training loss: 1.6231774600088889
Validation loss: 2.5730524889557196

Epoch: 6| Step: 1
Training loss: 2.2619601369595017
Validation loss: 2.573270099061444

Epoch: 6| Step: 2
Training loss: 2.239188817488103
Validation loss: 2.5595358087357685

Epoch: 6| Step: 3
Training loss: 2.063116617217508
Validation loss: 2.557881356572614

Epoch: 6| Step: 4
Training loss: 1.3958243137276969
Validation loss: 2.561102571378948

Epoch: 6| Step: 5
Training loss: 2.3413183186222697
Validation loss: 2.570666612467165

Epoch: 6| Step: 6
Training loss: 1.984581463503419
Validation loss: 2.561301222351535

Epoch: 6| Step: 7
Training loss: 1.7916360527202797
Validation loss: 2.579979154665223

Epoch: 6| Step: 8
Training loss: 2.899085124171062
Validation loss: 2.5727409014466973

Epoch: 6| Step: 9
Training loss: 2.5336673637656504
Validation loss: 2.593282435300968

Epoch: 6| Step: 10
Training loss: 2.503158481483514
Validation loss: 2.583098329089025

Epoch: 6| Step: 11
Training loss: 2.156426353429983
Validation loss: 2.587560184902951

Epoch: 6| Step: 12
Training loss: 2.329343540889135
Validation loss: 2.596711119229269

Epoch: 6| Step: 13
Training loss: 2.1658792409793133
Validation loss: 2.583967290020718

Epoch: 250| Step: 0
Training loss: 2.5788367936084766
Validation loss: 2.601900706870164

Epoch: 6| Step: 1
Training loss: 2.4820537159076803
Validation loss: 2.6019136575598516

Epoch: 6| Step: 2
Training loss: 2.3736399721797103
Validation loss: 2.5648088675729794

Epoch: 6| Step: 3
Training loss: 1.9959937740603417
Validation loss: 2.573037632455109

Epoch: 6| Step: 4
Training loss: 2.488638045332971
Validation loss: 2.5923290420221368

Epoch: 6| Step: 5
Training loss: 2.0563412817083426
Validation loss: 2.6018063542631737

Epoch: 6| Step: 6
Training loss: 2.244107371483119
Validation loss: 2.586214263949369

Epoch: 6| Step: 7
Training loss: 2.5705278764365884
Validation loss: 2.5524521360103583

Epoch: 6| Step: 8
Training loss: 1.520750365759376
Validation loss: 2.5359356999072604

Epoch: 6| Step: 9
Training loss: 1.572155378753203
Validation loss: 2.548790521453934

Epoch: 6| Step: 10
Training loss: 1.626198619995545
Validation loss: 2.5336916336566233

Epoch: 6| Step: 11
Training loss: 2.2823067921552673
Validation loss: 2.527406623919073

Epoch: 6| Step: 12
Training loss: 2.355055638362698
Validation loss: 2.518689881041927

Epoch: 6| Step: 13
Training loss: 1.8287000485297407
Validation loss: 2.526108972236118

Epoch: 251| Step: 0
Training loss: 2.1913337899534384
Validation loss: 2.522720360987279

Epoch: 6| Step: 1
Training loss: 2.583330759436853
Validation loss: 2.525927430286635

Epoch: 6| Step: 2
Training loss: 1.232551773407612
Validation loss: 2.5476196386254255

Epoch: 6| Step: 3
Training loss: 1.77686385498416
Validation loss: 2.561789569222903

Epoch: 6| Step: 4
Training loss: 2.186288116454328
Validation loss: 2.59827194374616

Epoch: 6| Step: 5
Training loss: 2.292965214741206
Validation loss: 2.5607249772443446

Epoch: 6| Step: 6
Training loss: 2.699779490897172
Validation loss: 2.57300086147503

Epoch: 6| Step: 7
Training loss: 1.7057179302592889
Validation loss: 2.5835471039175393

Epoch: 6| Step: 8
Training loss: 2.3951421210502932
Validation loss: 2.5795959283883456

Epoch: 6| Step: 9
Training loss: 1.901726655919359
Validation loss: 2.5948278799532822

Epoch: 6| Step: 10
Training loss: 2.3630758401175913
Validation loss: 2.5145603557085723

Epoch: 6| Step: 11
Training loss: 1.9560583441210204
Validation loss: 2.560707395688349

Epoch: 6| Step: 12
Training loss: 2.37619189420611
Validation loss: 2.507470207582507

Epoch: 6| Step: 13
Training loss: 2.4851769646432147
Validation loss: 2.506027854276506

Epoch: 252| Step: 0
Training loss: 1.865098111433014
Validation loss: 2.502248253788083

Epoch: 6| Step: 1
Training loss: 2.480731523667382
Validation loss: 2.5159818660747684

Epoch: 6| Step: 2
Training loss: 2.407728657385972
Validation loss: 2.5102951737970223

Epoch: 6| Step: 3
Training loss: 2.167374923071554
Validation loss: 2.50131778953714

Epoch: 6| Step: 4
Training loss: 1.6430954997192067
Validation loss: 2.5205801897127613

Epoch: 6| Step: 5
Training loss: 1.6792382637580399
Validation loss: 2.5119164182917233

Epoch: 6| Step: 6
Training loss: 2.60740697049228
Validation loss: 2.534400674522917

Epoch: 6| Step: 7
Training loss: 2.0253001002476725
Validation loss: 2.558213735222444

Epoch: 6| Step: 8
Training loss: 2.3515970728160887
Validation loss: 2.5591292502788865

Epoch: 6| Step: 9
Training loss: 2.627370218398307
Validation loss: 2.558729475852501

Epoch: 6| Step: 10
Training loss: 2.5407828269068253
Validation loss: 2.5766397224422297

Epoch: 6| Step: 11
Training loss: 1.9779061435922858
Validation loss: 2.6065509308327792

Epoch: 6| Step: 12
Training loss: 2.102954389388623
Validation loss: 2.625216384325189

Epoch: 6| Step: 13
Training loss: 1.7805818341888722
Validation loss: 2.6208264308852702

Epoch: 253| Step: 0
Training loss: 2.0043073999979453
Validation loss: 2.58877504602802

Epoch: 6| Step: 1
Training loss: 2.187238187108573
Validation loss: 2.5220687350607904

Epoch: 6| Step: 2
Training loss: 2.2137592762214777
Validation loss: 2.490224705097647

Epoch: 6| Step: 3
Training loss: 2.1476047080895153
Validation loss: 2.4927677766498086

Epoch: 6| Step: 4
Training loss: 2.582642544914225
Validation loss: 2.4980525219783627

Epoch: 6| Step: 5
Training loss: 2.347878850199653
Validation loss: 2.5241231075527812

Epoch: 6| Step: 6
Training loss: 2.032262227131789
Validation loss: 2.5032881332368544

Epoch: 6| Step: 7
Training loss: 1.964706628462706
Validation loss: 2.5313975758173677

Epoch: 6| Step: 8
Training loss: 2.61347338051428
Validation loss: 2.5465674809502223

Epoch: 6| Step: 9
Training loss: 2.086577813670907
Validation loss: 2.5818931092490818

Epoch: 6| Step: 10
Training loss: 2.4819995391808387
Validation loss: 2.655319379956458

Epoch: 6| Step: 11
Training loss: 1.6959964058316133
Validation loss: 2.643579143537404

Epoch: 6| Step: 12
Training loss: 2.682206640778572
Validation loss: 2.6627802144677113

Epoch: 6| Step: 13
Training loss: 2.5413961631370685
Validation loss: 2.6753806155364663

Epoch: 254| Step: 0
Training loss: 1.8077164369742722
Validation loss: 2.6317290388772596

Epoch: 6| Step: 1
Training loss: 2.058367200976934
Validation loss: 2.5234972117064514

Epoch: 6| Step: 2
Training loss: 1.8460680081206893
Validation loss: 2.46523536920263

Epoch: 6| Step: 3
Training loss: 2.8982915713032735
Validation loss: 2.466435808470453

Epoch: 6| Step: 4
Training loss: 2.5665879555395152
Validation loss: 2.4507142063966842

Epoch: 6| Step: 5
Training loss: 2.095504481134923
Validation loss: 2.460105392012745

Epoch: 6| Step: 6
Training loss: 2.1248794970284997
Validation loss: 2.4675705422131986

Epoch: 6| Step: 7
Training loss: 2.664200854694111
Validation loss: 2.462524717629659

Epoch: 6| Step: 8
Training loss: 2.6357293427229624
Validation loss: 2.47747303843784

Epoch: 6| Step: 9
Training loss: 1.663748913083198
Validation loss: 2.4336057675933875

Epoch: 6| Step: 10
Training loss: 1.7875501078805018
Validation loss: 2.457777644785524

Epoch: 6| Step: 11
Training loss: 2.3633232176025722
Validation loss: 2.4438341280740286

Epoch: 6| Step: 12
Training loss: 2.9612244640584215
Validation loss: 2.4343093628169603

Epoch: 6| Step: 13
Training loss: 2.452285331329216
Validation loss: 2.4541771124815552

Epoch: 255| Step: 0
Training loss: 2.348427542679947
Validation loss: 2.4605342151061604

Epoch: 6| Step: 1
Training loss: 2.0490211708609736
Validation loss: 2.466185175022305

Epoch: 6| Step: 2
Training loss: 2.2164124546226383
Validation loss: 2.50161225465803

Epoch: 6| Step: 3
Training loss: 2.2572563568813253
Validation loss: 2.5191079111805035

Epoch: 6| Step: 4
Training loss: 2.3935702263877494
Validation loss: 2.500727722427723

Epoch: 6| Step: 5
Training loss: 2.4345086155314135
Validation loss: 2.4981764102901614

Epoch: 6| Step: 6
Training loss: 1.8229048446998544
Validation loss: 2.4966033112959285

Epoch: 6| Step: 7
Training loss: 2.641551921610747
Validation loss: 2.5178752651805643

Epoch: 6| Step: 8
Training loss: 2.053937187556734
Validation loss: 2.500960443701209

Epoch: 6| Step: 9
Training loss: 2.033043289864516
Validation loss: 2.5399682723088755

Epoch: 6| Step: 10
Training loss: 2.182696927724025
Validation loss: 2.5486600895978975

Epoch: 6| Step: 11
Training loss: 1.817623001616969
Validation loss: 2.5422433657487558

Epoch: 6| Step: 12
Training loss: 2.27621070589089
Validation loss: 2.5732456465425835

Epoch: 6| Step: 13
Training loss: 2.0950457989914746
Validation loss: 2.5762079528950794

Epoch: 256| Step: 0
Training loss: 1.8853689226319261
Validation loss: 2.581480120360489

Epoch: 6| Step: 1
Training loss: 1.9298035127307138
Validation loss: 2.568477946011438

Epoch: 6| Step: 2
Training loss: 2.2634681695579575
Validation loss: 2.5495262856004666

Epoch: 6| Step: 3
Training loss: 2.9454651648825556
Validation loss: 2.5274402220687997

Epoch: 6| Step: 4
Training loss: 2.568248998786778
Validation loss: 2.5204307271428887

Epoch: 6| Step: 5
Training loss: 1.9940749857203308
Validation loss: 2.5329986309334456

Epoch: 6| Step: 6
Training loss: 1.8921226685660768
Validation loss: 2.518234131948526

Epoch: 6| Step: 7
Training loss: 2.010364973230493
Validation loss: 2.5276186919775903

Epoch: 6| Step: 8
Training loss: 2.1748752865168743
Validation loss: 2.5159477200638336

Epoch: 6| Step: 9
Training loss: 2.0173749793738307
Validation loss: 2.5214889924243242

Epoch: 6| Step: 10
Training loss: 1.7046229223507363
Validation loss: 2.5307919437095925

Epoch: 6| Step: 11
Training loss: 2.8685558909981643
Validation loss: 2.5513281399019703

Epoch: 6| Step: 12
Training loss: 1.979591009593103
Validation loss: 2.552217858849645

Epoch: 6| Step: 13
Training loss: 2.2417212875499684
Validation loss: 2.551286212191281

Epoch: 257| Step: 0
Training loss: 2.050393145939939
Validation loss: 2.5723563805599294

Epoch: 6| Step: 1
Training loss: 1.880648940882581
Validation loss: 2.5494406946933807

Epoch: 6| Step: 2
Training loss: 1.7619895304045161
Validation loss: 2.510151233068511

Epoch: 6| Step: 3
Training loss: 1.9670240314607847
Validation loss: 2.527172918112929

Epoch: 6| Step: 4
Training loss: 2.419368505131669
Validation loss: 2.51274846368293

Epoch: 6| Step: 5
Training loss: 2.8635921543666605
Validation loss: 2.496263700220637

Epoch: 6| Step: 6
Training loss: 1.501605128736075
Validation loss: 2.5103904015735443

Epoch: 6| Step: 7
Training loss: 2.1777672187826003
Validation loss: 2.4928484033386376

Epoch: 6| Step: 8
Training loss: 2.5889675677799833
Validation loss: 2.4757479221535967

Epoch: 6| Step: 9
Training loss: 1.840831710011135
Validation loss: 2.4772603027635616

Epoch: 6| Step: 10
Training loss: 2.395772341629112
Validation loss: 2.49465760977158

Epoch: 6| Step: 11
Training loss: 2.631594775302871
Validation loss: 2.5153643234120624

Epoch: 6| Step: 12
Training loss: 1.8474508094691462
Validation loss: 2.574715010294664

Epoch: 6| Step: 13
Training loss: 1.9249536310531514
Validation loss: 2.603903090807653

Epoch: 258| Step: 0
Training loss: 2.659480206462702
Validation loss: 2.6350810675362526

Epoch: 6| Step: 1
Training loss: 2.211941332785813
Validation loss: 2.6407485045193138

Epoch: 6| Step: 2
Training loss: 1.9386956002272704
Validation loss: 2.6398275401398683

Epoch: 6| Step: 3
Training loss: 2.7180795829524005
Validation loss: 2.644773651538466

Epoch: 6| Step: 4
Training loss: 1.4944728108061283
Validation loss: 2.6290911779030215

Epoch: 6| Step: 5
Training loss: 1.2714473408405067
Validation loss: 2.6205501229521446

Epoch: 6| Step: 6
Training loss: 2.671029118718018
Validation loss: 2.6117426320485673

Epoch: 6| Step: 7
Training loss: 2.672365913131926
Validation loss: 2.5884259746239198

Epoch: 6| Step: 8
Training loss: 1.490653802685402
Validation loss: 2.5689530570034007

Epoch: 6| Step: 9
Training loss: 1.922605174229837
Validation loss: 2.5949067596511366

Epoch: 6| Step: 10
Training loss: 2.151868708920153
Validation loss: 2.5669773188352942

Epoch: 6| Step: 11
Training loss: 1.7779487670022207
Validation loss: 2.53983248259604

Epoch: 6| Step: 12
Training loss: 2.2274105130254678
Validation loss: 2.5300214164189305

Epoch: 6| Step: 13
Training loss: 2.154569108904132
Validation loss: 2.514675442942572

Epoch: 259| Step: 0
Training loss: 2.1518506490862466
Validation loss: 2.5211366334366487

Epoch: 6| Step: 1
Training loss: 2.139903260121121
Validation loss: 2.5085441179730563

Epoch: 6| Step: 2
Training loss: 2.346043494540881
Validation loss: 2.5265769994253224

Epoch: 6| Step: 3
Training loss: 1.9880472281581565
Validation loss: 2.522800093419134

Epoch: 6| Step: 4
Training loss: 2.015839794453988
Validation loss: 2.489445212987257

Epoch: 6| Step: 5
Training loss: 1.8009990303930778
Validation loss: 2.5133471868354134

Epoch: 6| Step: 6
Training loss: 2.7377047945522284
Validation loss: 2.4882421884709567

Epoch: 6| Step: 7
Training loss: 2.1570654170374404
Validation loss: 2.5283615994953195

Epoch: 6| Step: 8
Training loss: 1.8661913908169825
Validation loss: 2.5472024968376252

Epoch: 6| Step: 9
Training loss: 1.7114454238352095
Validation loss: 2.569381900976971

Epoch: 6| Step: 10
Training loss: 2.2399328506146006
Validation loss: 2.588251144920353

Epoch: 6| Step: 11
Training loss: 2.311578515463902
Validation loss: 2.5789627409530445

Epoch: 6| Step: 12
Training loss: 2.1409312676520136
Validation loss: 2.569114661031163

Epoch: 6| Step: 13
Training loss: 2.30652671745897
Validation loss: 2.557218932589073

Epoch: 260| Step: 0
Training loss: 1.7807357447293415
Validation loss: 2.5330008899332244

Epoch: 6| Step: 1
Training loss: 2.5293753004250656
Validation loss: 2.527136918516908

Epoch: 6| Step: 2
Training loss: 2.079873059690781
Validation loss: 2.5269491289505925

Epoch: 6| Step: 3
Training loss: 2.2249615183727887
Validation loss: 2.5263298473294675

Epoch: 6| Step: 4
Training loss: 2.7668111380425287
Validation loss: 2.5299169852970085

Epoch: 6| Step: 5
Training loss: 2.133111283051151
Validation loss: 2.5211717494029817

Epoch: 6| Step: 6
Training loss: 1.8541809110058611
Validation loss: 2.5488084970159397

Epoch: 6| Step: 7
Training loss: 2.149726952358379
Validation loss: 2.545833866308711

Epoch: 6| Step: 8
Training loss: 1.1853934224849387
Validation loss: 2.5693026861544843

Epoch: 6| Step: 9
Training loss: 2.3847786218037528
Validation loss: 2.537332675221462

Epoch: 6| Step: 10
Training loss: 2.1399013660552937
Validation loss: 2.5297467984087754

Epoch: 6| Step: 11
Training loss: 2.216661356678198
Validation loss: 2.5302629155291485

Epoch: 6| Step: 12
Training loss: 1.8579383236407836
Validation loss: 2.5312168291846224

Epoch: 6| Step: 13
Training loss: 2.1733898121958783
Validation loss: 2.5197001082738746

Epoch: 261| Step: 0
Training loss: 2.346372231016293
Validation loss: 2.5433234979615165

Epoch: 6| Step: 1
Training loss: 2.278663527647073
Validation loss: 2.535397596974518

Epoch: 6| Step: 2
Training loss: 1.89036898810625
Validation loss: 2.543315186075419

Epoch: 6| Step: 3
Training loss: 2.184708476227122
Validation loss: 2.58121477954349

Epoch: 6| Step: 4
Training loss: 2.5465989226506514
Validation loss: 2.5653723303853724

Epoch: 6| Step: 5
Training loss: 1.637038024498009
Validation loss: 2.5462963796544944

Epoch: 6| Step: 6
Training loss: 2.343857317692761
Validation loss: 2.5354895233076262

Epoch: 6| Step: 7
Training loss: 1.8093589663412812
Validation loss: 2.48677280761562

Epoch: 6| Step: 8
Training loss: 2.235126715701304
Validation loss: 2.5301703831190325

Epoch: 6| Step: 9
Training loss: 1.815704406997821
Validation loss: 2.4944948299882226

Epoch: 6| Step: 10
Training loss: 2.876683944467557
Validation loss: 2.5059939690487143

Epoch: 6| Step: 11
Training loss: 1.5744883871949462
Validation loss: 2.489700335914871

Epoch: 6| Step: 12
Training loss: 1.975481303032654
Validation loss: 2.5211352227985184

Epoch: 6| Step: 13
Training loss: 2.2027832199014488
Validation loss: 2.561172901542745

Epoch: 262| Step: 0
Training loss: 2.0355191483820967
Validation loss: 2.578759055726544

Epoch: 6| Step: 1
Training loss: 1.8392567599235732
Validation loss: 2.6179794403893064

Epoch: 6| Step: 2
Training loss: 2.215289896815948
Validation loss: 2.6156821405328925

Epoch: 6| Step: 3
Training loss: 1.99816136484283
Validation loss: 2.596738916252184

Epoch: 6| Step: 4
Training loss: 2.4888675783395477
Validation loss: 2.6759299875023492

Epoch: 6| Step: 5
Training loss: 2.2042444509856267
Validation loss: 2.704219545063876

Epoch: 6| Step: 6
Training loss: 1.5872117359033209
Validation loss: 2.6992169834247113

Epoch: 6| Step: 7
Training loss: 2.338316863426379
Validation loss: 2.6907275580200696

Epoch: 6| Step: 8
Training loss: 2.0264500171324324
Validation loss: 2.619928820276503

Epoch: 6| Step: 9
Training loss: 2.268969783173219
Validation loss: 2.5797907986706603

Epoch: 6| Step: 10
Training loss: 1.7408835830241334
Validation loss: 2.5320946653797884

Epoch: 6| Step: 11
Training loss: 1.9259853912544196
Validation loss: 2.4886173358673847

Epoch: 6| Step: 12
Training loss: 2.1343447592339744
Validation loss: 2.4886828806556993

Epoch: 6| Step: 13
Training loss: 3.147147470476675
Validation loss: 2.4806399869510147

Epoch: 263| Step: 0
Training loss: 2.658151282730598
Validation loss: 2.4619333502762815

Epoch: 6| Step: 1
Training loss: 2.3208812697258043
Validation loss: 2.481758419191281

Epoch: 6| Step: 2
Training loss: 2.7263335648313607
Validation loss: 2.4626672710530864

Epoch: 6| Step: 3
Training loss: 1.945988916661534
Validation loss: 2.481261679800427

Epoch: 6| Step: 4
Training loss: 2.1603092187729356
Validation loss: 2.4853600522479016

Epoch: 6| Step: 5
Training loss: 2.075976874882374
Validation loss: 2.4891794321324356

Epoch: 6| Step: 6
Training loss: 1.8223093238162067
Validation loss: 2.4788884933802318

Epoch: 6| Step: 7
Training loss: 1.9898950888425273
Validation loss: 2.5123223053707573

Epoch: 6| Step: 8
Training loss: 2.1758307788628852
Validation loss: 2.554079160285523

Epoch: 6| Step: 9
Training loss: 2.239140903034594
Validation loss: 2.5877792238453736

Epoch: 6| Step: 10
Training loss: 1.77393021649941
Validation loss: 2.624898242491905

Epoch: 6| Step: 11
Training loss: 2.0821195372565757
Validation loss: 2.64579375430163

Epoch: 6| Step: 12
Training loss: 2.006972200171682
Validation loss: 2.6829309732460813

Epoch: 6| Step: 13
Training loss: 2.4079500608366855
Validation loss: 2.65613985020255

Epoch: 264| Step: 0
Training loss: 2.0117528819920016
Validation loss: 2.640717649621439

Epoch: 6| Step: 1
Training loss: 1.7397734334480008
Validation loss: 2.6293599689919356

Epoch: 6| Step: 2
Training loss: 2.337976490760781
Validation loss: 2.5893270016339742

Epoch: 6| Step: 3
Training loss: 2.5497123967463127
Validation loss: 2.5627777755413508

Epoch: 6| Step: 4
Training loss: 1.9575121016633765
Validation loss: 2.555993666850459

Epoch: 6| Step: 5
Training loss: 2.080770085536782
Validation loss: 2.550237172136172

Epoch: 6| Step: 6
Training loss: 1.9209191651382318
Validation loss: 2.541767873989911

Epoch: 6| Step: 7
Training loss: 2.3462391160764344
Validation loss: 2.5465050177008846

Epoch: 6| Step: 8
Training loss: 2.313417407366861
Validation loss: 2.5631239681866593

Epoch: 6| Step: 9
Training loss: 2.6400572939637836
Validation loss: 2.5602430623616126

Epoch: 6| Step: 10
Training loss: 1.6444963102638557
Validation loss: 2.5782489168846734

Epoch: 6| Step: 11
Training loss: 2.104159994083312
Validation loss: 2.5617900112920595

Epoch: 6| Step: 12
Training loss: 1.6769186930272715
Validation loss: 2.5601743674003403

Epoch: 6| Step: 13
Training loss: 2.2176980762116076
Validation loss: 2.555464848921918

Epoch: 265| Step: 0
Training loss: 1.609882756104717
Validation loss: 2.590194793430963

Epoch: 6| Step: 1
Training loss: 1.9600081958404767
Validation loss: 2.574709546889575

Epoch: 6| Step: 2
Training loss: 2.189909888203377
Validation loss: 2.57823713424808

Epoch: 6| Step: 3
Training loss: 2.4456396889483085
Validation loss: 2.542264029131138

Epoch: 6| Step: 4
Training loss: 3.0360574255878765
Validation loss: 2.551185828969847

Epoch: 6| Step: 5
Training loss: 1.5903707844478112
Validation loss: 2.534280712978073

Epoch: 6| Step: 6
Training loss: 1.8804945230401715
Validation loss: 2.5418697859685064

Epoch: 6| Step: 7
Training loss: 1.5248089217250196
Validation loss: 2.5426387309031884

Epoch: 6| Step: 8
Training loss: 1.4467668793654214
Validation loss: 2.5346816862398107

Epoch: 6| Step: 9
Training loss: 2.2036793329308315
Validation loss: 2.513472479257852

Epoch: 6| Step: 10
Training loss: 2.7101060983081298
Validation loss: 2.511261957297396

Epoch: 6| Step: 11
Training loss: 2.686059343859806
Validation loss: 2.5108676415635953

Epoch: 6| Step: 12
Training loss: 2.490096312042872
Validation loss: 2.4924883845194783

Epoch: 6| Step: 13
Training loss: 2.244903089644845
Validation loss: 2.515943392552949

Epoch: 266| Step: 0
Training loss: 1.6525191987231003
Validation loss: 2.5620063058049434

Epoch: 6| Step: 1
Training loss: 2.462798078282028
Validation loss: 2.606932938318384

Epoch: 6| Step: 2
Training loss: 2.8324629250748945
Validation loss: 2.6482787258151093

Epoch: 6| Step: 3
Training loss: 2.2769647351576103
Validation loss: 2.6334207890470256

Epoch: 6| Step: 4
Training loss: 2.4006085339582106
Validation loss: 2.6274526884475606

Epoch: 6| Step: 5
Training loss: 2.5656662894677345
Validation loss: 2.6134374065339094

Epoch: 6| Step: 6
Training loss: 2.46879529307863
Validation loss: 2.5556640391774335

Epoch: 6| Step: 7
Training loss: 1.6824137010590559
Validation loss: 2.51262243930957

Epoch: 6| Step: 8
Training loss: 1.8354777308281927
Validation loss: 2.4848886914464763

Epoch: 6| Step: 9
Training loss: 1.4102216372560015
Validation loss: 2.5047097902977873

Epoch: 6| Step: 10
Training loss: 2.411290920260375
Validation loss: 2.5241086085147217

Epoch: 6| Step: 11
Training loss: 2.3352593805965767
Validation loss: 2.510972089515364

Epoch: 6| Step: 12
Training loss: 1.9837118527567092
Validation loss: 2.518348751496387

Epoch: 6| Step: 13
Training loss: 1.5131072535649994
Validation loss: 2.544939331400782

Epoch: 267| Step: 0
Training loss: 1.6499635403390713
Validation loss: 2.5554540574838924

Epoch: 6| Step: 1
Training loss: 2.182824287573868
Validation loss: 2.5384365620936773

Epoch: 6| Step: 2
Training loss: 2.702462263946607
Validation loss: 2.550983773370683

Epoch: 6| Step: 3
Training loss: 2.776958626658374
Validation loss: 2.561659962114418

Epoch: 6| Step: 4
Training loss: 2.0821299574250722
Validation loss: 2.588755720922122

Epoch: 6| Step: 5
Training loss: 1.8363522974114008
Validation loss: 2.5916613553187986

Epoch: 6| Step: 6
Training loss: 1.7273211301291305
Validation loss: 2.606732307527941

Epoch: 6| Step: 7
Training loss: 2.876919644556544
Validation loss: 2.627959097314105

Epoch: 6| Step: 8
Training loss: 2.551089678543981
Validation loss: 2.6671735510287236

Epoch: 6| Step: 9
Training loss: 1.6659107957888253
Validation loss: 2.6658992308755294

Epoch: 6| Step: 10
Training loss: 2.2203168038119134
Validation loss: 2.6724447568673884

Epoch: 6| Step: 11
Training loss: 2.274187521423613
Validation loss: 2.6777792940051937

Epoch: 6| Step: 12
Training loss: 1.6218154220075487
Validation loss: 2.643221772783333

Epoch: 6| Step: 13
Training loss: 1.6037247366933496
Validation loss: 2.620754396213118

Epoch: 268| Step: 0
Training loss: 1.667082933258845
Validation loss: 2.613733120460439

Epoch: 6| Step: 1
Training loss: 2.6573243605096475
Validation loss: 2.591472913076105

Epoch: 6| Step: 2
Training loss: 2.277142314606551
Validation loss: 2.5880916723693947

Epoch: 6| Step: 3
Training loss: 2.7122350220528184
Validation loss: 2.635226266690216

Epoch: 6| Step: 4
Training loss: 2.1928029768596873
Validation loss: 2.630005982927641

Epoch: 6| Step: 5
Training loss: 2.0960687352186786
Validation loss: 2.6028424265715024

Epoch: 6| Step: 6
Training loss: 1.960276579707929
Validation loss: 2.6032619939432715

Epoch: 6| Step: 7
Training loss: 1.7148424987093243
Validation loss: 2.610856828978554

Epoch: 6| Step: 8
Training loss: 1.9871617971126692
Validation loss: 2.5755820323331786

Epoch: 6| Step: 9
Training loss: 1.8991125343087887
Validation loss: 2.545518494371426

Epoch: 6| Step: 10
Training loss: 2.543909417483085
Validation loss: 2.508958152773735

Epoch: 6| Step: 11
Training loss: 1.6184844929703823
Validation loss: 2.5160082254674596

Epoch: 6| Step: 12
Training loss: 2.2212525344859935
Validation loss: 2.500732298728143

Epoch: 6| Step: 13
Training loss: 2.0616943635470415
Validation loss: 2.4887197318759977

Epoch: 269| Step: 0
Training loss: 2.530110420561596
Validation loss: 2.506619511331549

Epoch: 6| Step: 1
Training loss: 2.517598580454137
Validation loss: 2.5159221892214183

Epoch: 6| Step: 2
Training loss: 2.055703263803771
Validation loss: 2.564842518017872

Epoch: 6| Step: 3
Training loss: 2.1341141861144637
Validation loss: 2.5565786410036178

Epoch: 6| Step: 4
Training loss: 1.7666444789044993
Validation loss: 2.578599990091018

Epoch: 6| Step: 5
Training loss: 2.2670998869884422
Validation loss: 2.5890949868048168

Epoch: 6| Step: 6
Training loss: 2.3179041633312156
Validation loss: 2.598513996514505

Epoch: 6| Step: 7
Training loss: 1.9865967335435932
Validation loss: 2.624770139288069

Epoch: 6| Step: 8
Training loss: 2.0928840554570103
Validation loss: 2.60794623694655

Epoch: 6| Step: 9
Training loss: 2.7018420752646537
Validation loss: 2.5918134944165407

Epoch: 6| Step: 10
Training loss: 1.602786903348023
Validation loss: 2.570254788045533

Epoch: 6| Step: 11
Training loss: 1.5529637581157507
Validation loss: 2.5613325917853347

Epoch: 6| Step: 12
Training loss: 1.7201235744530565
Validation loss: 2.547166803723863

Epoch: 6| Step: 13
Training loss: 2.050476400333043
Validation loss: 2.521711375219838

Epoch: 270| Step: 0
Training loss: 1.8589752152151737
Validation loss: 2.509493097334694

Epoch: 6| Step: 1
Training loss: 1.7639385710333426
Validation loss: 2.5320913227460156

Epoch: 6| Step: 2
Training loss: 1.35386241527108
Validation loss: 2.5037908423335447

Epoch: 6| Step: 3
Training loss: 1.4906877100647165
Validation loss: 2.5119602528260176

Epoch: 6| Step: 4
Training loss: 2.8367491682392116
Validation loss: 2.546140685833519

Epoch: 6| Step: 5
Training loss: 1.788105671313826
Validation loss: 2.5498743319244137

Epoch: 6| Step: 6
Training loss: 2.4414562494880103
Validation loss: 2.569220097229867

Epoch: 6| Step: 7
Training loss: 2.4968604401317904
Validation loss: 2.623857219141553

Epoch: 6| Step: 8
Training loss: 2.134649247385339
Validation loss: 2.6462835144169503

Epoch: 6| Step: 9
Training loss: 1.402882507032213
Validation loss: 2.6403494847291715

Epoch: 6| Step: 10
Training loss: 1.5941703092563702
Validation loss: 2.60603610776438

Epoch: 6| Step: 11
Training loss: 2.0014488217712274
Validation loss: 2.585758844602368

Epoch: 6| Step: 12
Training loss: 2.6607012981562312
Validation loss: 2.6151924994119087

Epoch: 6| Step: 13
Training loss: 2.434009106307913
Validation loss: 2.593230735552062

Epoch: 271| Step: 0
Training loss: 1.65197100391757
Validation loss: 2.587839723482307

Epoch: 6| Step: 1
Training loss: 1.9454800330642084
Validation loss: 2.5442859619273914

Epoch: 6| Step: 2
Training loss: 1.8008412249791008
Validation loss: 2.5880336352486113

Epoch: 6| Step: 3
Training loss: 1.7757345774970503
Validation loss: 2.549036961132491

Epoch: 6| Step: 4
Training loss: 2.3884736397582085
Validation loss: 2.560239275339905

Epoch: 6| Step: 5
Training loss: 2.32534921546129
Validation loss: 2.5789852209980464

Epoch: 6| Step: 6
Training loss: 2.3521103331708697
Validation loss: 2.5576473592129445

Epoch: 6| Step: 7
Training loss: 2.439497105100446
Validation loss: 2.5423568247164146

Epoch: 6| Step: 8
Training loss: 1.9523130636562747
Validation loss: 2.5497876851822463

Epoch: 6| Step: 9
Training loss: 1.6477695214526353
Validation loss: 2.5680244643238397

Epoch: 6| Step: 10
Training loss: 2.2611972029612835
Validation loss: 2.569768119449507

Epoch: 6| Step: 11
Training loss: 1.88503593127259
Validation loss: 2.585269561279432

Epoch: 6| Step: 12
Training loss: 1.6162827766794627
Validation loss: 2.590729053403188

Epoch: 6| Step: 13
Training loss: 2.4899676251126013
Validation loss: 2.57084478646751

Epoch: 272| Step: 0
Training loss: 1.8895016319952258
Validation loss: 2.612799949401416

Epoch: 6| Step: 1
Training loss: 1.9974879343482457
Validation loss: 2.6209276793883314

Epoch: 6| Step: 2
Training loss: 1.5729272433634809
Validation loss: 2.6567445182481695

Epoch: 6| Step: 3
Training loss: 1.87221969462198
Validation loss: 2.6341503151572456

Epoch: 6| Step: 4
Training loss: 2.014548908979661
Validation loss: 2.61738411084223

Epoch: 6| Step: 5
Training loss: 2.5264949640933123
Validation loss: 2.5817156438653566

Epoch: 6| Step: 6
Training loss: 2.4131705108358332
Validation loss: 2.5223267180222173

Epoch: 6| Step: 7
Training loss: 1.8663266803295615
Validation loss: 2.5284384666349555

Epoch: 6| Step: 8
Training loss: 2.9014607006450555
Validation loss: 2.504008052539776

Epoch: 6| Step: 9
Training loss: 1.868051305180677
Validation loss: 2.485576451087789

Epoch: 6| Step: 10
Training loss: 1.8813583013340807
Validation loss: 2.4683672934270984

Epoch: 6| Step: 11
Training loss: 2.207347205847849
Validation loss: 2.461021478421014

Epoch: 6| Step: 12
Training loss: 1.9515164274422976
Validation loss: 2.480959337635466

Epoch: 6| Step: 13
Training loss: 1.7801696445761732
Validation loss: 2.484306590419963

Epoch: 273| Step: 0
Training loss: 1.6699260867774006
Validation loss: 2.4923411992589943

Epoch: 6| Step: 1
Training loss: 2.237105188753832
Validation loss: 2.5105331414983074

Epoch: 6| Step: 2
Training loss: 1.9624477816881296
Validation loss: 2.5440464812386985

Epoch: 6| Step: 3
Training loss: 2.3507845279243513
Validation loss: 2.544895377890927

Epoch: 6| Step: 4
Training loss: 2.5270550664676783
Validation loss: 2.5909676853198036

Epoch: 6| Step: 5
Training loss: 1.9596870964729964
Validation loss: 2.64026838072736

Epoch: 6| Step: 6
Training loss: 1.8755658249639182
Validation loss: 2.650259555845123

Epoch: 6| Step: 7
Training loss: 2.156031943089903
Validation loss: 2.689942661889153

Epoch: 6| Step: 8
Training loss: 1.7248760980530293
Validation loss: 2.6383674873323044

Epoch: 6| Step: 9
Training loss: 1.8377122458019268
Validation loss: 2.671723463732261

Epoch: 6| Step: 10
Training loss: 2.076173138191937
Validation loss: 2.6177351952624366

Epoch: 6| Step: 11
Training loss: 1.7830208124260793
Validation loss: 2.556246687087172

Epoch: 6| Step: 12
Training loss: 2.525484465399291
Validation loss: 2.513682901140408

Epoch: 6| Step: 13
Training loss: 2.0698916601310744
Validation loss: 2.5180873784909314

Epoch: 274| Step: 0
Training loss: 1.997624178238467
Validation loss: 2.50505981216546

Epoch: 6| Step: 1
Training loss: 1.9314849759948682
Validation loss: 2.4740163749444846

Epoch: 6| Step: 2
Training loss: 2.306967018543177
Validation loss: 2.490791543699561

Epoch: 6| Step: 3
Training loss: 2.565018509468978
Validation loss: 2.4730546900456463

Epoch: 6| Step: 4
Training loss: 1.885684912832634
Validation loss: 2.4607028102481947

Epoch: 6| Step: 5
Training loss: 1.9830903828770754
Validation loss: 2.466789867786836

Epoch: 6| Step: 6
Training loss: 2.4622856201731107
Validation loss: 2.510656975816421

Epoch: 6| Step: 7
Training loss: 2.4134465391608937
Validation loss: 2.5010280561626264

Epoch: 6| Step: 8
Training loss: 1.9220974180955706
Validation loss: 2.53141661672528

Epoch: 6| Step: 9
Training loss: 2.033516426389638
Validation loss: 2.518947515954782

Epoch: 6| Step: 10
Training loss: 2.0171373002050252
Validation loss: 2.569425822239199

Epoch: 6| Step: 11
Training loss: 1.6532939226057617
Validation loss: 2.646310963409716

Epoch: 6| Step: 12
Training loss: 1.8818517742668468
Validation loss: 2.6265771608626176

Epoch: 6| Step: 13
Training loss: 2.1858957129868295
Validation loss: 2.633743589369605

Epoch: 275| Step: 0
Training loss: 2.4338541396734454
Validation loss: 2.5743606520553386

Epoch: 6| Step: 1
Training loss: 1.658245108604262
Validation loss: 2.570388406330331

Epoch: 6| Step: 2
Training loss: 2.3277448305374344
Validation loss: 2.533302762031136

Epoch: 6| Step: 3
Training loss: 2.140767113639143
Validation loss: 2.5015703514495335

Epoch: 6| Step: 4
Training loss: 1.9531181030151663
Validation loss: 2.5139241125356704

Epoch: 6| Step: 5
Training loss: 2.358545422761764
Validation loss: 2.516609646822806

Epoch: 6| Step: 6
Training loss: 2.2728155275028605
Validation loss: 2.525318369922126

Epoch: 6| Step: 7
Training loss: 1.3720391212257579
Validation loss: 2.52295962947319

Epoch: 6| Step: 8
Training loss: 1.9818363320901105
Validation loss: 2.542660414699889

Epoch: 6| Step: 9
Training loss: 2.1310141111253076
Validation loss: 2.5746478744280656

Epoch: 6| Step: 10
Training loss: 1.9466297638130037
Validation loss: 2.5827877073488446

Epoch: 6| Step: 11
Training loss: 2.0751711855215103
Validation loss: 2.586621273796062

Epoch: 6| Step: 12
Training loss: 2.1875137328670498
Validation loss: 2.61081617687184

Epoch: 6| Step: 13
Training loss: 2.1236049336266705
Validation loss: 2.614880508211596

Epoch: 276| Step: 0
Training loss: 1.6622161651623932
Validation loss: 2.6264052565430154

Epoch: 6| Step: 1
Training loss: 1.303928634241142
Validation loss: 2.5874339035364127

Epoch: 6| Step: 2
Training loss: 2.3687183227031388
Validation loss: 2.584937125916451

Epoch: 6| Step: 3
Training loss: 2.9345243275827184
Validation loss: 2.570254015039759

Epoch: 6| Step: 4
Training loss: 2.2489975709541605
Validation loss: 2.5318626321769733

Epoch: 6| Step: 5
Training loss: 1.7561504729500197
Validation loss: 2.5373011186956513

Epoch: 6| Step: 6
Training loss: 1.6149358877205477
Validation loss: 2.537297125161927

Epoch: 6| Step: 7
Training loss: 2.2128386933309523
Validation loss: 2.5378237005765647

Epoch: 6| Step: 8
Training loss: 2.6533993852084
Validation loss: 2.511268919535982

Epoch: 6| Step: 9
Training loss: 1.681220911618134
Validation loss: 2.514346332859158

Epoch: 6| Step: 10
Training loss: 1.9831272918466718
Validation loss: 2.5143058429904155

Epoch: 6| Step: 11
Training loss: 1.7196777614100784
Validation loss: 2.519339447212254

Epoch: 6| Step: 12
Training loss: 2.5190459501127203
Validation loss: 2.526672163993404

Epoch: 6| Step: 13
Training loss: 2.0957788914105726
Validation loss: 2.518482409856764

Epoch: 277| Step: 0
Training loss: 2.187909442185249
Validation loss: 2.5389302224157446

Epoch: 6| Step: 1
Training loss: 1.9188803314777039
Validation loss: 2.5623432049426103

Epoch: 6| Step: 2
Training loss: 2.0712821561058834
Validation loss: 2.567694369285223

Epoch: 6| Step: 3
Training loss: 1.5660911490464346
Validation loss: 2.5694740729012713

Epoch: 6| Step: 4
Training loss: 1.2191354679975186
Validation loss: 2.589628138708249

Epoch: 6| Step: 5
Training loss: 2.212915512982011
Validation loss: 2.544706181763632

Epoch: 6| Step: 6
Training loss: 1.4829428741091457
Validation loss: 2.521107254173411

Epoch: 6| Step: 7
Training loss: 1.8980300528877405
Validation loss: 2.5390056271174544

Epoch: 6| Step: 8
Training loss: 2.206739126131764
Validation loss: 2.5616959031305737

Epoch: 6| Step: 9
Training loss: 2.065979652142098
Validation loss: 2.551847350959313

Epoch: 6| Step: 10
Training loss: 2.7610634292009304
Validation loss: 2.5951958881402435

Epoch: 6| Step: 11
Training loss: 2.271074148119097
Validation loss: 2.5642329923151213

Epoch: 6| Step: 12
Training loss: 1.9208675318036768
Validation loss: 2.647925433352705

Epoch: 6| Step: 13
Training loss: 1.9833282353097912
Validation loss: 2.6319598770919335

Epoch: 278| Step: 0
Training loss: 2.2035638899606864
Validation loss: 2.6042793147836494

Epoch: 6| Step: 1
Training loss: 2.2032037815590666
Validation loss: 2.556546987864124

Epoch: 6| Step: 2
Training loss: 2.653047313833373
Validation loss: 2.508659275291733

Epoch: 6| Step: 3
Training loss: 1.6371425908368316
Validation loss: 2.485155378891361

Epoch: 6| Step: 4
Training loss: 1.4958636154184035
Validation loss: 2.4564020577328565

Epoch: 6| Step: 5
Training loss: 1.7548378422260402
Validation loss: 2.4617690846034734

Epoch: 6| Step: 6
Training loss: 2.0731135008121857
Validation loss: 2.471594109793902

Epoch: 6| Step: 7
Training loss: 2.1183793770593
Validation loss: 2.4645379587630867

Epoch: 6| Step: 8
Training loss: 2.23386243796572
Validation loss: 2.4698516866297777

Epoch: 6| Step: 9
Training loss: 2.2600667187455223
Validation loss: 2.4525783277959556

Epoch: 6| Step: 10
Training loss: 2.6912941874744827
Validation loss: 2.474414058003501

Epoch: 6| Step: 11
Training loss: 1.5878407750862071
Validation loss: 2.511286768095822

Epoch: 6| Step: 12
Training loss: 1.9632004526546611
Validation loss: 2.6041154525807166

Epoch: 6| Step: 13
Training loss: 2.263095574997549
Validation loss: 2.6034445308165592

Epoch: 279| Step: 0
Training loss: 1.9179754626123624
Validation loss: 2.639162640566014

Epoch: 6| Step: 1
Training loss: 1.5262959586307367
Validation loss: 2.6766201662590534

Epoch: 6| Step: 2
Training loss: 2.3065248568535313
Validation loss: 2.6858167847910535

Epoch: 6| Step: 3
Training loss: 1.7404504849459825
Validation loss: 2.620987701923734

Epoch: 6| Step: 4
Training loss: 2.2353774802929
Validation loss: 2.5926413560499775

Epoch: 6| Step: 5
Training loss: 2.125233917825248
Validation loss: 2.593773485559971

Epoch: 6| Step: 6
Training loss: 1.8108699967028268
Validation loss: 2.5093559197903534

Epoch: 6| Step: 7
Training loss: 2.655385673370409
Validation loss: 2.5064246039955846

Epoch: 6| Step: 8
Training loss: 2.055956198622801
Validation loss: 2.5273389388780036

Epoch: 6| Step: 9
Training loss: 2.3348585207633463
Validation loss: 2.513042300961104

Epoch: 6| Step: 10
Training loss: 1.8451550835660584
Validation loss: 2.527476720441749

Epoch: 6| Step: 11
Training loss: 2.4357582129076003
Validation loss: 2.5373387515694596

Epoch: 6| Step: 12
Training loss: 1.286656301403955
Validation loss: 2.5558986922958713

Epoch: 6| Step: 13
Training loss: 2.238703130405013
Validation loss: 2.5184475403982503

Epoch: 280| Step: 0
Training loss: 2.4544648805873392
Validation loss: 2.5622985419501045

Epoch: 6| Step: 1
Training loss: 1.9645787813114357
Validation loss: 2.5796130346174846

Epoch: 6| Step: 2
Training loss: 1.7668867750824624
Validation loss: 2.583549618639686

Epoch: 6| Step: 3
Training loss: 1.5113385335958698
Validation loss: 2.614015347818792

Epoch: 6| Step: 4
Training loss: 2.0306923907865846
Validation loss: 2.5970341829124584

Epoch: 6| Step: 5
Training loss: 2.3582033191154466
Validation loss: 2.6384921818633593

Epoch: 6| Step: 6
Training loss: 2.2218874387755063
Validation loss: 2.586744845116695

Epoch: 6| Step: 7
Training loss: 1.62135375362219
Validation loss: 2.6289363592954444

Epoch: 6| Step: 8
Training loss: 2.058628494577524
Validation loss: 2.6243100394894023

Epoch: 6| Step: 9
Training loss: 2.0025527874755205
Validation loss: 2.6068680955016035

Epoch: 6| Step: 10
Training loss: 2.030552083940346
Validation loss: 2.6120725686642596

Epoch: 6| Step: 11
Training loss: 1.8969188000117165
Validation loss: 2.5857264114691203

Epoch: 6| Step: 12
Training loss: 2.1660037371461422
Validation loss: 2.603038495150272

Epoch: 6| Step: 13
Training loss: 2.283175452776865
Validation loss: 2.5808642698787834

Epoch: 281| Step: 0
Training loss: 2.063159143719464
Validation loss: 2.587111353596261

Epoch: 6| Step: 1
Training loss: 1.6517507512578906
Validation loss: 2.57032125794253

Epoch: 6| Step: 2
Training loss: 2.5211938857650638
Validation loss: 2.575768852570442

Epoch: 6| Step: 3
Training loss: 2.098829569941225
Validation loss: 2.571645288726728

Epoch: 6| Step: 4
Training loss: 1.9396891378300842
Validation loss: 2.5972353333693623

Epoch: 6| Step: 5
Training loss: 2.3906483368576024
Validation loss: 2.5873652701077354

Epoch: 6| Step: 6
Training loss: 1.9043098331890846
Validation loss: 2.6200549686649683

Epoch: 6| Step: 7
Training loss: 1.6744239841542337
Validation loss: 2.6312019561223305

Epoch: 6| Step: 8
Training loss: 1.6737616758388016
Validation loss: 2.61910497160864

Epoch: 6| Step: 9
Training loss: 1.7017930448245844
Validation loss: 2.616372447470865

Epoch: 6| Step: 10
Training loss: 1.7370725394054136
Validation loss: 2.557400848067612

Epoch: 6| Step: 11
Training loss: 2.358711300902906
Validation loss: 2.5469814192492684

Epoch: 6| Step: 12
Training loss: 2.0120590959064604
Validation loss: 2.519106570389416

Epoch: 6| Step: 13
Training loss: 2.3730533050324407
Validation loss: 2.5118019798177658

Epoch: 282| Step: 0
Training loss: 1.546125827820851
Validation loss: 2.541002817436857

Epoch: 6| Step: 1
Training loss: 1.651516538213233
Validation loss: 2.5270701618485534

Epoch: 6| Step: 2
Training loss: 2.62866681441209
Validation loss: 2.5233856211585985

Epoch: 6| Step: 3
Training loss: 1.4769987239018574
Validation loss: 2.5551809598439066

Epoch: 6| Step: 4
Training loss: 1.4301065966750148
Validation loss: 2.529822979464966

Epoch: 6| Step: 5
Training loss: 2.3777168194314022
Validation loss: 2.5571230478628153

Epoch: 6| Step: 6
Training loss: 2.100266521434737
Validation loss: 2.5575199582093986

Epoch: 6| Step: 7
Training loss: 1.9669625175601213
Validation loss: 2.5697000193144985

Epoch: 6| Step: 8
Training loss: 1.5038296766727441
Validation loss: 2.600714773572017

Epoch: 6| Step: 9
Training loss: 2.269417160764577
Validation loss: 2.611561359878321

Epoch: 6| Step: 10
Training loss: 2.399379979948464
Validation loss: 2.5386628604260664

Epoch: 6| Step: 11
Training loss: 2.4126466222293894
Validation loss: 2.5762809863348637

Epoch: 6| Step: 12
Training loss: 1.7423658065898184
Validation loss: 2.535895554749362

Epoch: 6| Step: 13
Training loss: 1.9986779492568534
Validation loss: 2.5511268276477392

Epoch: 283| Step: 0
Training loss: 2.3169675407523305
Validation loss: 2.548942943339986

Epoch: 6| Step: 1
Training loss: 1.268935219159585
Validation loss: 2.5440416079873334

Epoch: 6| Step: 2
Training loss: 1.1890436479274575
Validation loss: 2.569787138919581

Epoch: 6| Step: 3
Training loss: 1.7765770904022402
Validation loss: 2.563081396253383

Epoch: 6| Step: 4
Training loss: 1.8297037985553832
Validation loss: 2.51931536239967

Epoch: 6| Step: 5
Training loss: 2.4165153017544254
Validation loss: 2.550724560515132

Epoch: 6| Step: 6
Training loss: 1.8111997083759748
Validation loss: 2.5252506289089673

Epoch: 6| Step: 7
Training loss: 2.010856013807095
Validation loss: 2.5267714295103034

Epoch: 6| Step: 8
Training loss: 1.9900901375297462
Validation loss: 2.5409926213819514

Epoch: 6| Step: 9
Training loss: 1.8306761327435352
Validation loss: 2.5882879909401115

Epoch: 6| Step: 10
Training loss: 2.3047750165454524
Validation loss: 2.643542617227285

Epoch: 6| Step: 11
Training loss: 1.5657576362025312
Validation loss: 2.632323977220897

Epoch: 6| Step: 12
Training loss: 2.161410583213776
Validation loss: 2.6266317291485817

Epoch: 6| Step: 13
Training loss: 2.8328901580080488
Validation loss: 2.6203718105542353

Epoch: 284| Step: 0
Training loss: 1.5451428512160494
Validation loss: 2.6313125155913815

Epoch: 6| Step: 1
Training loss: 2.354081942853871
Validation loss: 2.5468708810597445

Epoch: 6| Step: 2
Training loss: 2.136370698522409
Validation loss: 2.5537037175248476

Epoch: 6| Step: 3
Training loss: 2.0377295803544118
Validation loss: 2.5112006729418357

Epoch: 6| Step: 4
Training loss: 1.8719868290633472
Validation loss: 2.5620296170599635

Epoch: 6| Step: 5
Training loss: 2.0232796036668432
Validation loss: 2.6013947395557175

Epoch: 6| Step: 6
Training loss: 2.2849502861908766
Validation loss: 2.6048221424423854

Epoch: 6| Step: 7
Training loss: 1.441280866095552
Validation loss: 2.596248954903752

Epoch: 6| Step: 8
Training loss: 2.618156139983584
Validation loss: 2.5529774844612074

Epoch: 6| Step: 9
Training loss: 1.9694033552844536
Validation loss: 2.5751376636828818

Epoch: 6| Step: 10
Training loss: 1.8094164169921103
Validation loss: 2.579750026697582

Epoch: 6| Step: 11
Training loss: 2.3898667273612433
Validation loss: 2.565324498248929

Epoch: 6| Step: 12
Training loss: 1.3270216004741595
Validation loss: 2.5746900081765065

Epoch: 6| Step: 13
Training loss: 2.3048943895486094
Validation loss: 2.588856765532312

Epoch: 285| Step: 0
Training loss: 1.394682120061298
Validation loss: 2.6254334394674634

Epoch: 6| Step: 1
Training loss: 1.7230510648487514
Validation loss: 2.5973242220056245

Epoch: 6| Step: 2
Training loss: 2.1838990136298424
Validation loss: 2.606252465677658

Epoch: 6| Step: 3
Training loss: 1.8427858579668865
Validation loss: 2.623156414836096

Epoch: 6| Step: 4
Training loss: 1.721214192557503
Validation loss: 2.6383330200285093

Epoch: 6| Step: 5
Training loss: 1.9015637939248113
Validation loss: 2.5919516736860975

Epoch: 6| Step: 6
Training loss: 2.8278848114025577
Validation loss: 2.6389773041709397

Epoch: 6| Step: 7
Training loss: 1.8301707501823423
Validation loss: 2.630426912699185

Epoch: 6| Step: 8
Training loss: 2.394377512142623
Validation loss: 2.6094451331423603

Epoch: 6| Step: 9
Training loss: 1.5651076872707215
Validation loss: 2.549929396268988

Epoch: 6| Step: 10
Training loss: 1.901245426771895
Validation loss: 2.5181642278735663

Epoch: 6| Step: 11
Training loss: 2.2461863092341683
Validation loss: 2.5213450524577072

Epoch: 6| Step: 12
Training loss: 2.2623432463408193
Validation loss: 2.490298840056115

Epoch: 6| Step: 13
Training loss: 1.7089109917280436
Validation loss: 2.493374724104066

Epoch: 286| Step: 0
Training loss: 2.311692689759698
Validation loss: 2.554102699470311

Epoch: 6| Step: 1
Training loss: 1.790206277032902
Validation loss: 2.5820987325170877

Epoch: 6| Step: 2
Training loss: 1.9632169689458632
Validation loss: 2.577446233618425

Epoch: 6| Step: 3
Training loss: 2.1409546535630506
Validation loss: 2.5797250579743185

Epoch: 6| Step: 4
Training loss: 2.2873273398686718
Validation loss: 2.5621351587109307

Epoch: 6| Step: 5
Training loss: 1.9358003606244751
Validation loss: 2.5392203413979635

Epoch: 6| Step: 6
Training loss: 1.3702581310034452
Validation loss: 2.530306463640722

Epoch: 6| Step: 7
Training loss: 1.9382926181027784
Validation loss: 2.5074166117146053

Epoch: 6| Step: 8
Training loss: 1.8084511093015168
Validation loss: 2.5154127896287286

Epoch: 6| Step: 9
Training loss: 1.3949583452083194
Validation loss: 2.4936824607785777

Epoch: 6| Step: 10
Training loss: 2.1736007530390813
Validation loss: 2.489846799521628

Epoch: 6| Step: 11
Training loss: 2.9601318551671962
Validation loss: 2.4948242971135297

Epoch: 6| Step: 12
Training loss: 1.4577908006302207
Validation loss: 2.4868794579348923

Epoch: 6| Step: 13
Training loss: 2.009822803866524
Validation loss: 2.5217670151266414

Epoch: 287| Step: 0
Training loss: 1.5496306102269874
Validation loss: 2.5479398658259806

Epoch: 6| Step: 1
Training loss: 2.5073118096242344
Validation loss: 2.5841441740611018

Epoch: 6| Step: 2
Training loss: 1.5753526413942769
Validation loss: 2.588387917775964

Epoch: 6| Step: 3
Training loss: 2.385151699847752
Validation loss: 2.6467770422861996

Epoch: 6| Step: 4
Training loss: 2.5670899013325257
Validation loss: 2.60253898615834

Epoch: 6| Step: 5
Training loss: 1.9576355387605753
Validation loss: 2.549542315554679

Epoch: 6| Step: 6
Training loss: 1.4173258855814816
Validation loss: 2.55062332949669

Epoch: 6| Step: 7
Training loss: 2.094446550340659
Validation loss: 2.548997754996543

Epoch: 6| Step: 8
Training loss: 2.2588660082346537
Validation loss: 2.5031917066254046

Epoch: 6| Step: 9
Training loss: 2.5042042666472395
Validation loss: 2.477967811207612

Epoch: 6| Step: 10
Training loss: 1.4663568845070045
Validation loss: 2.4958676836285445

Epoch: 6| Step: 11
Training loss: 1.287352473871485
Validation loss: 2.476556868200788

Epoch: 6| Step: 12
Training loss: 2.2001779744378998
Validation loss: 2.4917297899634714

Epoch: 6| Step: 13
Training loss: 1.84589138786464
Validation loss: 2.4927739935098234

Epoch: 288| Step: 0
Training loss: 2.2957623959455593
Validation loss: 2.510891894448788

Epoch: 6| Step: 1
Training loss: 1.924179432351495
Validation loss: 2.5047468102648014

Epoch: 6| Step: 2
Training loss: 1.5654743114448417
Validation loss: 2.5137394538100475

Epoch: 6| Step: 3
Training loss: 2.2604897014110783
Validation loss: 2.5690917388733303

Epoch: 6| Step: 4
Training loss: 1.6000268039842387
Validation loss: 2.5742094110175735

Epoch: 6| Step: 5
Training loss: 1.6640920143912836
Validation loss: 2.6405170275642322

Epoch: 6| Step: 6
Training loss: 1.9983777381008234
Validation loss: 2.5970560475146263

Epoch: 6| Step: 7
Training loss: 1.357559526448567
Validation loss: 2.610437705971785

Epoch: 6| Step: 8
Training loss: 1.6402692136541852
Validation loss: 2.60861406633513

Epoch: 6| Step: 9
Training loss: 2.9285088775015637
Validation loss: 2.5960373042648843

Epoch: 6| Step: 10
Training loss: 2.242589721756018
Validation loss: 2.5849707602907674

Epoch: 6| Step: 11
Training loss: 1.635049628924835
Validation loss: 2.5689980528673013

Epoch: 6| Step: 12
Training loss: 2.0381763622803954
Validation loss: 2.5628903874704982

Epoch: 6| Step: 13
Training loss: 1.6774207145044102
Validation loss: 2.5886384778305027

Epoch: 289| Step: 0
Training loss: 2.1537011603398732
Validation loss: 2.607286915995138

Epoch: 6| Step: 1
Training loss: 1.4043615588914562
Validation loss: 2.562606956606843

Epoch: 6| Step: 2
Training loss: 1.9711395173688198
Validation loss: 2.553776632111897

Epoch: 6| Step: 3
Training loss: 1.8052692218893494
Validation loss: 2.5536089845805234

Epoch: 6| Step: 4
Training loss: 1.7203741549358358
Validation loss: 2.533915007678575

Epoch: 6| Step: 5
Training loss: 2.7186282777394215
Validation loss: 2.573193914840147

Epoch: 6| Step: 6
Training loss: 1.650746396333654
Validation loss: 2.558380351012487

Epoch: 6| Step: 7
Training loss: 2.357746699219546
Validation loss: 2.570557046405283

Epoch: 6| Step: 8
Training loss: 2.0564625546129913
Validation loss: 2.564766819389194

Epoch: 6| Step: 9
Training loss: 1.7361502969346123
Validation loss: 2.6289594096023294

Epoch: 6| Step: 10
Training loss: 1.6924301466620613
Validation loss: 2.6301669630567748

Epoch: 6| Step: 11
Training loss: 1.7652552394727057
Validation loss: 2.6566963867892737

Epoch: 6| Step: 12
Training loss: 1.7975325998207135
Validation loss: 2.636687267727754

Epoch: 6| Step: 13
Training loss: 2.2063494954354583
Validation loss: 2.5684037314719723

Epoch: 290| Step: 0
Training loss: 1.4042144029617303
Validation loss: 2.5633986843329075

Epoch: 6| Step: 1
Training loss: 2.0044621520072026
Validation loss: 2.4947415043533656

Epoch: 6| Step: 2
Training loss: 2.0528330974268494
Validation loss: 2.5098165266958414

Epoch: 6| Step: 3
Training loss: 1.7222139305339
Validation loss: 2.479080668862525

Epoch: 6| Step: 4
Training loss: 1.9317526943918155
Validation loss: 2.4809066185737234

Epoch: 6| Step: 5
Training loss: 2.1124954313872104
Validation loss: 2.4460147747041687

Epoch: 6| Step: 6
Training loss: 2.329317542724424
Validation loss: 2.466803769433985

Epoch: 6| Step: 7
Training loss: 2.5581560299182264
Validation loss: 2.4979337259515546

Epoch: 6| Step: 8
Training loss: 1.873333826449636
Validation loss: 2.520972182388095

Epoch: 6| Step: 9
Training loss: 1.8938513096064193
Validation loss: 2.5503170414722804

Epoch: 6| Step: 10
Training loss: 1.7931790363603577
Validation loss: 2.547578710526152

Epoch: 6| Step: 11
Training loss: 1.8818304262738772
Validation loss: 2.564195010309909

Epoch: 6| Step: 12
Training loss: 1.9545676434771595
Validation loss: 2.550477800920901

Epoch: 6| Step: 13
Training loss: 2.424401227037692
Validation loss: 2.5691211107512553

Epoch: 291| Step: 0
Training loss: 2.4312503608762186
Validation loss: 2.582977383199386

Epoch: 6| Step: 1
Training loss: 1.8156819529965196
Validation loss: 2.5570242302325528

Epoch: 6| Step: 2
Training loss: 2.104627904919077
Validation loss: 2.568906699147829

Epoch: 6| Step: 3
Training loss: 1.6982021754828538
Validation loss: 2.5807665152722956

Epoch: 6| Step: 4
Training loss: 1.9987086657173971
Validation loss: 2.5746574587588986

Epoch: 6| Step: 5
Training loss: 1.9913995119372203
Validation loss: 2.589327431328618

Epoch: 6| Step: 6
Training loss: 1.645125981524415
Validation loss: 2.660187992274404

Epoch: 6| Step: 7
Training loss: 2.158430462079181
Validation loss: 2.657638246870488

Epoch: 6| Step: 8
Training loss: 1.5945960398495773
Validation loss: 2.627918876097427

Epoch: 6| Step: 9
Training loss: 1.7374781435682698
Validation loss: 2.5876730543122703

Epoch: 6| Step: 10
Training loss: 1.3700408805539483
Validation loss: 2.5586816515395125

Epoch: 6| Step: 11
Training loss: 1.8066601561444269
Validation loss: 2.5472709644396017

Epoch: 6| Step: 12
Training loss: 1.84442927891779
Validation loss: 2.5402376165031546

Epoch: 6| Step: 13
Training loss: 2.6379581505476026
Validation loss: 2.5261269990855633

Epoch: 292| Step: 0
Training loss: 1.5390442977835828
Validation loss: 2.5420100079211125

Epoch: 6| Step: 1
Training loss: 1.7736008354625532
Validation loss: 2.4964195042880863

Epoch: 6| Step: 2
Training loss: 1.8639153575139071
Validation loss: 2.5004806851166923

Epoch: 6| Step: 3
Training loss: 2.0023040612760314
Validation loss: 2.516189622402579

Epoch: 6| Step: 4
Training loss: 1.9144838453255362
Validation loss: 2.522700514119059

Epoch: 6| Step: 5
Training loss: 2.210538902342488
Validation loss: 2.542528769718865

Epoch: 6| Step: 6
Training loss: 1.8368971893330577
Validation loss: 2.5877826020349732

Epoch: 6| Step: 7
Training loss: 1.5997672090458748
Validation loss: 2.5914794604855054

Epoch: 6| Step: 8
Training loss: 1.6562396355070752
Validation loss: 2.5908147756951374

Epoch: 6| Step: 9
Training loss: 2.201021204533013
Validation loss: 2.6293229882328237

Epoch: 6| Step: 10
Training loss: 2.060809974687142
Validation loss: 2.607015277530499

Epoch: 6| Step: 11
Training loss: 2.396324494367553
Validation loss: 2.6088993606008826

Epoch: 6| Step: 12
Training loss: 1.6923447751603973
Validation loss: 2.587534132101162

Epoch: 6| Step: 13
Training loss: 2.1656132729393094
Validation loss: 2.5661144197116945

Epoch: 293| Step: 0
Training loss: 1.5205471692782977
Validation loss: 2.5758547256290627

Epoch: 6| Step: 1
Training loss: 2.5935197291361987
Validation loss: 2.524405436497996

Epoch: 6| Step: 2
Training loss: 2.3556481035313612
Validation loss: 2.4978647809423697

Epoch: 6| Step: 3
Training loss: 1.4745805952282602
Validation loss: 2.523013903137679

Epoch: 6| Step: 4
Training loss: 1.9235181529708394
Validation loss: 2.6055116816714943

Epoch: 6| Step: 5
Training loss: 1.2996172121325913
Validation loss: 2.5840450711280907

Epoch: 6| Step: 6
Training loss: 1.4470902515571493
Validation loss: 2.6165218284838936

Epoch: 6| Step: 7
Training loss: 2.1509260711521474
Validation loss: 2.5643243730719822

Epoch: 6| Step: 8
Training loss: 1.6283269716657194
Validation loss: 2.591131535527384

Epoch: 6| Step: 9
Training loss: 2.0026563646700883
Validation loss: 2.5440088851121776

Epoch: 6| Step: 10
Training loss: 1.799638960975801
Validation loss: 2.4930835735289776

Epoch: 6| Step: 11
Training loss: 1.9405935263423435
Validation loss: 2.5077248436174946

Epoch: 6| Step: 12
Training loss: 2.366511081452803
Validation loss: 2.5027606344911923

Epoch: 6| Step: 13
Training loss: 2.045022839929305
Validation loss: 2.506592371537942

Epoch: 294| Step: 0
Training loss: 1.883142719356354
Validation loss: 2.565506481758474

Epoch: 6| Step: 1
Training loss: 2.0475307899181496
Validation loss: 2.5653385629722893

Epoch: 6| Step: 2
Training loss: 2.015356474739861
Validation loss: 2.562797777195401

Epoch: 6| Step: 3
Training loss: 2.3299354835713757
Validation loss: 2.55855878267345

Epoch: 6| Step: 4
Training loss: 1.7185358781085467
Validation loss: 2.5504721921167506

Epoch: 6| Step: 5
Training loss: 1.7092056218392948
Validation loss: 2.571615536202685

Epoch: 6| Step: 6
Training loss: 1.4849646752262904
Validation loss: 2.567722426266842

Epoch: 6| Step: 7
Training loss: 1.938932012675334
Validation loss: 2.5583118700831524

Epoch: 6| Step: 8
Training loss: 2.214743206561045
Validation loss: 2.5814863082933455

Epoch: 6| Step: 9
Training loss: 1.3412235817702773
Validation loss: 2.561323283388093

Epoch: 6| Step: 10
Training loss: 2.030662334236304
Validation loss: 2.5634275323932183

Epoch: 6| Step: 11
Training loss: 1.786495182409872
Validation loss: 2.5501860566297614

Epoch: 6| Step: 12
Training loss: 2.600588229468808
Validation loss: 2.600292227901789

Epoch: 6| Step: 13
Training loss: 2.0334025788111583
Validation loss: 2.579108495677684

Epoch: 295| Step: 0
Training loss: 2.2287048740921267
Validation loss: 2.6028638149232988

Epoch: 6| Step: 1
Training loss: 2.05990066881412
Validation loss: 2.60594140931383

Epoch: 6| Step: 2
Training loss: 2.389928978219867
Validation loss: 2.614182267957721

Epoch: 6| Step: 3
Training loss: 1.96407702068099
Validation loss: 2.6554324967731384

Epoch: 6| Step: 4
Training loss: 2.391759067394206
Validation loss: 2.682352681376481

Epoch: 6| Step: 5
Training loss: 1.4847850835418814
Validation loss: 2.6523598851652768

Epoch: 6| Step: 6
Training loss: 2.0019416920405244
Validation loss: 2.6000496682289134

Epoch: 6| Step: 7
Training loss: 1.6021132847929889
Validation loss: 2.5304471222189875

Epoch: 6| Step: 8
Training loss: 2.1562179341903547
Validation loss: 2.51602671952001

Epoch: 6| Step: 9
Training loss: 1.6889981577825353
Validation loss: 2.465687780060448

Epoch: 6| Step: 10
Training loss: 2.431450991915409
Validation loss: 2.4611699070256767

Epoch: 6| Step: 11
Training loss: 1.9776663732167874
Validation loss: 2.4740153951923998

Epoch: 6| Step: 12
Training loss: 2.0064178253997316
Validation loss: 2.483283484895221

Epoch: 6| Step: 13
Training loss: 1.1720232551890941
Validation loss: 2.4735380491670806

Epoch: 296| Step: 0
Training loss: 1.593919782383844
Validation loss: 2.4777256413345494

Epoch: 6| Step: 1
Training loss: 2.673751261507069
Validation loss: 2.475924340467955

Epoch: 6| Step: 2
Training loss: 1.4936880186621055
Validation loss: 2.4838809595778035

Epoch: 6| Step: 3
Training loss: 1.64086025912755
Validation loss: 2.5453827275531977

Epoch: 6| Step: 4
Training loss: 1.7226654536894512
Validation loss: 2.5575396902435794

Epoch: 6| Step: 5
Training loss: 1.8419116925952481
Validation loss: 2.5445262789811904

Epoch: 6| Step: 6
Training loss: 2.1608088854333407
Validation loss: 2.619341063883769

Epoch: 6| Step: 7
Training loss: 1.705642239828407
Validation loss: 2.6167526567102493

Epoch: 6| Step: 8
Training loss: 2.1034734610154437
Validation loss: 2.599124365467757

Epoch: 6| Step: 9
Training loss: 2.023823115893543
Validation loss: 2.596944029648391

Epoch: 6| Step: 10
Training loss: 1.6731143528995316
Validation loss: 2.5519255349297754

Epoch: 6| Step: 11
Training loss: 1.9057709138781822
Validation loss: 2.5409404519700103

Epoch: 6| Step: 12
Training loss: 2.0536812178365533
Validation loss: 2.506856639119252

Epoch: 6| Step: 13
Training loss: 2.510802201125423
Validation loss: 2.516755104932063

Epoch: 297| Step: 0
Training loss: 2.4321770869079575
Validation loss: 2.493492972402369

Epoch: 6| Step: 1
Training loss: 2.0011718416409447
Validation loss: 2.5082427514366064

Epoch: 6| Step: 2
Training loss: 2.4505819758301643
Validation loss: 2.5457364367220165

Epoch: 6| Step: 3
Training loss: 1.6180622480888014
Validation loss: 2.5537261709581895

Epoch: 6| Step: 4
Training loss: 1.8364823202585072
Validation loss: 2.6068828963900406

Epoch: 6| Step: 5
Training loss: 1.5505844490994556
Validation loss: 2.628086530998841

Epoch: 6| Step: 6
Training loss: 1.8114311091911106
Validation loss: 2.6019980340012423

Epoch: 6| Step: 7
Training loss: 2.0454620842842894
Validation loss: 2.5725394035438103

Epoch: 6| Step: 8
Training loss: 1.8530212965151656
Validation loss: 2.5824676468069856

Epoch: 6| Step: 9
Training loss: 2.5644013398891263
Validation loss: 2.5765416995986916

Epoch: 6| Step: 10
Training loss: 1.8194886008899067
Validation loss: 2.5874910173244863

Epoch: 6| Step: 11
Training loss: 2.106870846128938
Validation loss: 2.582174553984702

Epoch: 6| Step: 12
Training loss: 1.3637330801217515
Validation loss: 2.5785597309450545

Epoch: 6| Step: 13
Training loss: 1.4445548881383359
Validation loss: 2.5615647477835104

Epoch: 298| Step: 0
Training loss: 1.9028362913331194
Validation loss: 2.547683712240904

Epoch: 6| Step: 1
Training loss: 2.2692795316786136
Validation loss: 2.552866170798956

Epoch: 6| Step: 2
Training loss: 2.321216137566643
Validation loss: 2.5629275050642386

Epoch: 6| Step: 3
Training loss: 1.7090396196427948
Validation loss: 2.6088020015371973

Epoch: 6| Step: 4
Training loss: 1.6828984287322404
Validation loss: 2.6531755644012875

Epoch: 6| Step: 5
Training loss: 2.1026132218836264
Validation loss: 2.657392173988768

Epoch: 6| Step: 6
Training loss: 1.6483819599648317
Validation loss: 2.6227242959529873

Epoch: 6| Step: 7
Training loss: 1.9304730133170118
Validation loss: 2.617137320118098

Epoch: 6| Step: 8
Training loss: 1.4053431659972193
Validation loss: 2.6083237287285623

Epoch: 6| Step: 9
Training loss: 1.9829409967244307
Validation loss: 2.5463627025023974

Epoch: 6| Step: 10
Training loss: 2.0693547174628595
Validation loss: 2.5288730339859855

Epoch: 6| Step: 11
Training loss: 1.902310662892446
Validation loss: 2.547844154363711

Epoch: 6| Step: 12
Training loss: 2.3493939409560554
Validation loss: 2.5484881918562943

Epoch: 6| Step: 13
Training loss: 1.124101279817071
Validation loss: 2.5193860152620537

Epoch: 299| Step: 0
Training loss: 2.210521106128242
Validation loss: 2.54894132204437

Epoch: 6| Step: 1
Training loss: 1.5330693860858715
Validation loss: 2.553114987450604

Epoch: 6| Step: 2
Training loss: 2.1626835916016036
Validation loss: 2.558625393349074

Epoch: 6| Step: 3
Training loss: 1.6704352766398922
Validation loss: 2.5811208099967224

Epoch: 6| Step: 4
Training loss: 1.3312424816223747
Validation loss: 2.598313663825003

Epoch: 6| Step: 5
Training loss: 2.3921140134999344
Validation loss: 2.604107624656217

Epoch: 6| Step: 6
Training loss: 1.9028426187919139
Validation loss: 2.5683734385754455

Epoch: 6| Step: 7
Training loss: 1.2637604058928664
Validation loss: 2.572505289979963

Epoch: 6| Step: 8
Training loss: 1.5417076655254527
Validation loss: 2.5602914860798633

Epoch: 6| Step: 9
Training loss: 1.9314026411158745
Validation loss: 2.557697634252911

Epoch: 6| Step: 10
Training loss: 2.5019798068932455
Validation loss: 2.5921281240207463

Epoch: 6| Step: 11
Training loss: 1.931198331765163
Validation loss: 2.53701034168586

Epoch: 6| Step: 12
Training loss: 1.5570162866680177
Validation loss: 2.5628781543612984

Epoch: 6| Step: 13
Training loss: 1.8740294169638192
Validation loss: 2.5385396409264707

Epoch: 300| Step: 0
Training loss: 1.779716634804939
Validation loss: 2.4972715588869145

Epoch: 6| Step: 1
Training loss: 1.553076441291644
Validation loss: 2.512513773992686

Epoch: 6| Step: 2
Training loss: 2.0068140775877557
Validation loss: 2.501262036303643

Epoch: 6| Step: 3
Training loss: 2.42649656305673
Validation loss: 2.4922220831597133

Epoch: 6| Step: 4
Training loss: 1.2062396073758404
Validation loss: 2.482758401929942

Epoch: 6| Step: 5
Training loss: 2.492148754811233
Validation loss: 2.5055585578069675

Epoch: 6| Step: 6
Training loss: 1.5710099981853054
Validation loss: 2.5223505062672946

Epoch: 6| Step: 7
Training loss: 1.272028465291377
Validation loss: 2.5054589117808805

Epoch: 6| Step: 8
Training loss: 2.4939387276349163
Validation loss: 2.5109692489050595

Epoch: 6| Step: 9
Training loss: 1.8318247729586674
Validation loss: 2.556157504820084

Epoch: 6| Step: 10
Training loss: 1.3520122507431906
Validation loss: 2.584170610862985

Epoch: 6| Step: 11
Training loss: 1.6495894614916262
Validation loss: 2.633012924338404

Epoch: 6| Step: 12
Training loss: 2.0988243445201387
Validation loss: 2.644110596867114

Epoch: 6| Step: 13
Training loss: 1.9518770427125178
Validation loss: 2.6297145770336

Epoch: 301| Step: 0
Training loss: 1.2078107767228519
Validation loss: 2.6014022243185333

Epoch: 6| Step: 1
Training loss: 1.1983230178045923
Validation loss: 2.5842004110459533

Epoch: 6| Step: 2
Training loss: 1.538220790219301
Validation loss: 2.582161896709614

Epoch: 6| Step: 3
Training loss: 2.3145345037776486
Validation loss: 2.5701341499514663

Epoch: 6| Step: 4
Training loss: 2.317150903311181
Validation loss: 2.5944988517878764

Epoch: 6| Step: 5
Training loss: 2.056164576834454
Validation loss: 2.5585092778129908

Epoch: 6| Step: 6
Training loss: 1.8870000846672748
Validation loss: 2.5393813026018894

Epoch: 6| Step: 7
Training loss: 2.0362599724232093
Validation loss: 2.553382018905835

Epoch: 6| Step: 8
Training loss: 1.6523588283563273
Validation loss: 2.58611695741602

Epoch: 6| Step: 9
Training loss: 1.7342971921771242
Validation loss: 2.5701602631755827

Epoch: 6| Step: 10
Training loss: 2.2788682810877
Validation loss: 2.5899641757927565

Epoch: 6| Step: 11
Training loss: 1.5077558121377062
Validation loss: 2.6013005060770404

Epoch: 6| Step: 12
Training loss: 2.1919769251228436
Validation loss: 2.5859488403440447

Epoch: 6| Step: 13
Training loss: 1.9951942641820497
Validation loss: 2.5028201885583976

Epoch: 302| Step: 0
Training loss: 1.8102528025659836
Validation loss: 2.509513602856894

Epoch: 6| Step: 1
Training loss: 1.3314993235335313
Validation loss: 2.478085487823605

Epoch: 6| Step: 2
Training loss: 1.8251429305869535
Validation loss: 2.503011502960247

Epoch: 6| Step: 3
Training loss: 2.2524252642258413
Validation loss: 2.482086391074608

Epoch: 6| Step: 4
Training loss: 2.3294725038731987
Validation loss: 2.5167510235355754

Epoch: 6| Step: 5
Training loss: 1.2785283466548847
Validation loss: 2.511536065038804

Epoch: 6| Step: 6
Training loss: 1.7260954902773444
Validation loss: 2.536003531557827

Epoch: 6| Step: 7
Training loss: 2.062954361315077
Validation loss: 2.5784945984061918

Epoch: 6| Step: 8
Training loss: 1.6699503578300097
Validation loss: 2.5853306729639276

Epoch: 6| Step: 9
Training loss: 1.6770141618889285
Validation loss: 2.6174591834411842

Epoch: 6| Step: 10
Training loss: 1.7472135294280382
Validation loss: 2.6445144209521145

Epoch: 6| Step: 11
Training loss: 2.4427494351983015
Validation loss: 2.6773935477177724

Epoch: 6| Step: 12
Training loss: 1.7434457246839727
Validation loss: 2.6559203298599976

Epoch: 6| Step: 13
Training loss: 2.271055881432545
Validation loss: 2.7306046713569074

Epoch: 303| Step: 0
Training loss: 1.9653920798279823
Validation loss: 2.684933908502731

Epoch: 6| Step: 1
Training loss: 2.042333909078801
Validation loss: 2.6700715267468462

Epoch: 6| Step: 2
Training loss: 1.719801563748171
Validation loss: 2.5733366609298196

Epoch: 6| Step: 3
Training loss: 2.285011117353043
Validation loss: 2.5369898391297623

Epoch: 6| Step: 4
Training loss: 1.2833297411550475
Validation loss: 2.4877595858694153

Epoch: 6| Step: 5
Training loss: 2.1990392147521103
Validation loss: 2.5045028031426724

Epoch: 6| Step: 6
Training loss: 1.824036354242231
Validation loss: 2.48642460630119

Epoch: 6| Step: 7
Training loss: 2.2663408924187496
Validation loss: 2.493204465390042

Epoch: 6| Step: 8
Training loss: 1.8035705544821685
Validation loss: 2.4837789400280452

Epoch: 6| Step: 9
Training loss: 2.104448456984744
Validation loss: 2.4965928145420153

Epoch: 6| Step: 10
Training loss: 1.8063134469369388
Validation loss: 2.5122905137773053

Epoch: 6| Step: 11
Training loss: 1.5684262614162006
Validation loss: 2.5196305918268687

Epoch: 6| Step: 12
Training loss: 1.3770027314036422
Validation loss: 2.578359620178733

Epoch: 6| Step: 13
Training loss: 1.8081867592236398
Validation loss: 2.6224436649833205

Epoch: 304| Step: 0
Training loss: 1.358418138856166
Validation loss: 2.6109565464788393

Epoch: 6| Step: 1
Training loss: 1.5960365049876823
Validation loss: 2.6932373461835493

Epoch: 6| Step: 2
Training loss: 1.832337831656949
Validation loss: 2.674907680950555

Epoch: 6| Step: 3
Training loss: 1.2092077883864232
Validation loss: 2.6387261028162428

Epoch: 6| Step: 4
Training loss: 2.0057217291653875
Validation loss: 2.5826649775436357

Epoch: 6| Step: 5
Training loss: 2.1264107453114223
Validation loss: 2.5835007233891534

Epoch: 6| Step: 6
Training loss: 1.663143853586384
Validation loss: 2.539872792380158

Epoch: 6| Step: 7
Training loss: 2.7126027909592247
Validation loss: 2.5346959366734616

Epoch: 6| Step: 8
Training loss: 2.1828483169009174
Validation loss: 2.5532698124470117

Epoch: 6| Step: 9
Training loss: 1.4446120755828111
Validation loss: 2.531165824087052

Epoch: 6| Step: 10
Training loss: 1.3339976453889029
Validation loss: 2.541595150509463

Epoch: 6| Step: 11
Training loss: 1.849460229227936
Validation loss: 2.536832736122912

Epoch: 6| Step: 12
Training loss: 2.1757116666176386
Validation loss: 2.558849510241951

Epoch: 6| Step: 13
Training loss: 1.8018944996001316
Validation loss: 2.5109237274887324

Epoch: 305| Step: 0
Training loss: 1.9870665311459603
Validation loss: 2.5028330486214716

Epoch: 6| Step: 1
Training loss: 1.911591098204163
Validation loss: 2.501896869742677

Epoch: 6| Step: 2
Training loss: 2.033988280683606
Validation loss: 2.506016524895926

Epoch: 6| Step: 3
Training loss: 1.2613040018004722
Validation loss: 2.5039983723516324

Epoch: 6| Step: 4
Training loss: 1.6533922696889087
Validation loss: 2.523201095798039

Epoch: 6| Step: 5
Training loss: 1.479165663741224
Validation loss: 2.55459379905092

Epoch: 6| Step: 6
Training loss: 1.9767866045292273
Validation loss: 2.5755560975060026

Epoch: 6| Step: 7
Training loss: 2.241041362389247
Validation loss: 2.5622080504797573

Epoch: 6| Step: 8
Training loss: 1.719948922663061
Validation loss: 2.6073277526707312

Epoch: 6| Step: 9
Training loss: 1.7767459073506007
Validation loss: 2.6194219435782484

Epoch: 6| Step: 10
Training loss: 2.1598816295261307
Validation loss: 2.564806899968847

Epoch: 6| Step: 11
Training loss: 2.118783272000923
Validation loss: 2.5961784117098863

Epoch: 6| Step: 12
Training loss: 1.5963923671149003
Validation loss: 2.6103781410859286

Epoch: 6| Step: 13
Training loss: 1.9240842077540272
Validation loss: 2.5954133640557555

Epoch: 306| Step: 0
Training loss: 1.9630095336729192
Validation loss: 2.589225791212706

Epoch: 6| Step: 1
Training loss: 1.6026162751337223
Validation loss: 2.5388071411053215

Epoch: 6| Step: 2
Training loss: 1.5054243872084065
Validation loss: 2.508389542246631

Epoch: 6| Step: 3
Training loss: 1.4241971347526632
Validation loss: 2.481690962241046

Epoch: 6| Step: 4
Training loss: 2.117148648852194
Validation loss: 2.4835320088153123

Epoch: 6| Step: 5
Training loss: 1.564968524287274
Validation loss: 2.468412287666605

Epoch: 6| Step: 6
Training loss: 1.3557771886975976
Validation loss: 2.467913055194009

Epoch: 6| Step: 7
Training loss: 1.7122576075621743
Validation loss: 2.4659651166743757

Epoch: 6| Step: 8
Training loss: 2.1631885512836235
Validation loss: 2.506349273389796

Epoch: 6| Step: 9
Training loss: 1.8232559179065884
Validation loss: 2.508141215836233

Epoch: 6| Step: 10
Training loss: 2.456152147668698
Validation loss: 2.5584944300508603

Epoch: 6| Step: 11
Training loss: 1.7389860974414737
Validation loss: 2.6756456178320622

Epoch: 6| Step: 12
Training loss: 2.6720622036140758
Validation loss: 2.7660264264460475

Epoch: 6| Step: 13
Training loss: 1.9690183426374113
Validation loss: 2.7574606032452222

Epoch: 307| Step: 0
Training loss: 1.9228896277260066
Validation loss: 2.673835726518881

Epoch: 6| Step: 1
Training loss: 1.4303568956195638
Validation loss: 2.5905445775094784

Epoch: 6| Step: 2
Training loss: 1.5904460394111346
Validation loss: 2.516792018770637

Epoch: 6| Step: 3
Training loss: 2.189045823092926
Validation loss: 2.5088386535692866

Epoch: 6| Step: 4
Training loss: 1.6335878128534955
Validation loss: 2.4684890898922593

Epoch: 6| Step: 5
Training loss: 2.3208344254642386
Validation loss: 2.4725301106737354

Epoch: 6| Step: 6
Training loss: 2.0974284639765486
Validation loss: 2.507330938353135

Epoch: 6| Step: 7
Training loss: 1.3197020976266207
Validation loss: 2.4974041734117955

Epoch: 6| Step: 8
Training loss: 1.8656785046750142
Validation loss: 2.5129532773650545

Epoch: 6| Step: 9
Training loss: 2.1643787800169014
Validation loss: 2.480122747844471

Epoch: 6| Step: 10
Training loss: 1.952580673661181
Validation loss: 2.4853654962235274

Epoch: 6| Step: 11
Training loss: 1.5530566378924204
Validation loss: 2.50517765166488

Epoch: 6| Step: 12
Training loss: 2.1929184427120676
Validation loss: 2.4870822638800516

Epoch: 6| Step: 13
Training loss: 1.5231448161354881
Validation loss: 2.4995321948740474

Epoch: 308| Step: 0
Training loss: 2.043081597736259
Validation loss: 2.5646855872867445

Epoch: 6| Step: 1
Training loss: 1.810318851206283
Validation loss: 2.5511116799128883

Epoch: 6| Step: 2
Training loss: 1.1136020131377955
Validation loss: 2.5685254254831813

Epoch: 6| Step: 3
Training loss: 2.0075939965005762
Validation loss: 2.605442533118076

Epoch: 6| Step: 4
Training loss: 2.247011106822699
Validation loss: 2.5939666473726843

Epoch: 6| Step: 5
Training loss: 1.6589136836595098
Validation loss: 2.56745696368824

Epoch: 6| Step: 6
Training loss: 2.132725864090048
Validation loss: 2.6086584390298797

Epoch: 6| Step: 7
Training loss: 2.522093990985513
Validation loss: 2.6030841612007065

Epoch: 6| Step: 8
Training loss: 1.436691720364962
Validation loss: 2.5802342350542267

Epoch: 6| Step: 9
Training loss: 1.672610540001518
Validation loss: 2.538305707778267

Epoch: 6| Step: 10
Training loss: 2.068440984137183
Validation loss: 2.504404273373363

Epoch: 6| Step: 11
Training loss: 1.4329748662806225
Validation loss: 2.513819692395832

Epoch: 6| Step: 12
Training loss: 1.5927497118241747
Validation loss: 2.543309733338393

Epoch: 6| Step: 13
Training loss: 1.4891314143338337
Validation loss: 2.5508869766515234

Epoch: 309| Step: 0
Training loss: 1.461814739392755
Validation loss: 2.5754098794384106

Epoch: 6| Step: 1
Training loss: 2.662929797517454
Validation loss: 2.595781312199794

Epoch: 6| Step: 2
Training loss: 2.0648690691581666
Validation loss: 2.577877965323917

Epoch: 6| Step: 3
Training loss: 1.415798238970829
Validation loss: 2.59867498551641

Epoch: 6| Step: 4
Training loss: 1.8108115388577173
Validation loss: 2.6012996659188237

Epoch: 6| Step: 5
Training loss: 1.3726107907353118
Validation loss: 2.5882688003702734

Epoch: 6| Step: 6
Training loss: 1.8414053151804413
Validation loss: 2.581867037739077

Epoch: 6| Step: 7
Training loss: 2.225029990176276
Validation loss: 2.6014542962866236

Epoch: 6| Step: 8
Training loss: 1.39461527766256
Validation loss: 2.5775630608240445

Epoch: 6| Step: 9
Training loss: 1.680202884117351
Validation loss: 2.538631116950075

Epoch: 6| Step: 10
Training loss: 1.4294108972683013
Validation loss: 2.547322130641682

Epoch: 6| Step: 11
Training loss: 2.08584103021892
Validation loss: 2.535861018749804

Epoch: 6| Step: 12
Training loss: 1.1981148873679957
Validation loss: 2.5218590522775535

Epoch: 6| Step: 13
Training loss: 2.1701285386580436
Validation loss: 2.5208034723788404

Epoch: 310| Step: 0
Training loss: 1.5351270522430123
Validation loss: 2.553741933368298

Epoch: 6| Step: 1
Training loss: 1.5838808150486883
Validation loss: 2.577939398664157

Epoch: 6| Step: 2
Training loss: 1.6389203616351304
Validation loss: 2.5987989240441474

Epoch: 6| Step: 3
Training loss: 1.822728269015057
Validation loss: 2.5998028827185533

Epoch: 6| Step: 4
Training loss: 1.8215296527586111
Validation loss: 2.628810160951138

Epoch: 6| Step: 5
Training loss: 1.3982937701648694
Validation loss: 2.5836693611842954

Epoch: 6| Step: 6
Training loss: 2.3444193583568054
Validation loss: 2.616288033403522

Epoch: 6| Step: 7
Training loss: 1.9028213810004746
Validation loss: 2.602734153931137

Epoch: 6| Step: 8
Training loss: 1.3392863101049641
Validation loss: 2.612420412156335

Epoch: 6| Step: 9
Training loss: 2.5561361609295523
Validation loss: 2.6400539826644156

Epoch: 6| Step: 10
Training loss: 2.293956537328859
Validation loss: 2.617024582683866

Epoch: 6| Step: 11
Training loss: 1.3863613474012602
Validation loss: 2.6396700093390733

Epoch: 6| Step: 12
Training loss: 1.9557868823709168
Validation loss: 2.629814440752953

Epoch: 6| Step: 13
Training loss: 1.7913863901733527
Validation loss: 2.625397092060815

Epoch: 311| Step: 0
Training loss: 1.908318319914062
Validation loss: 2.6525322121963186

Epoch: 6| Step: 1
Training loss: 1.8395132752064185
Validation loss: 2.6661627164140835

Epoch: 6| Step: 2
Training loss: 1.7730221703138855
Validation loss: 2.5672693141624676

Epoch: 6| Step: 3
Training loss: 2.216203006734565
Validation loss: 2.55284526635657

Epoch: 6| Step: 4
Training loss: 2.0067785547224917
Validation loss: 2.528291205313172

Epoch: 6| Step: 5
Training loss: 1.538555080981222
Validation loss: 2.518807114426079

Epoch: 6| Step: 6
Training loss: 1.8855684616215647
Validation loss: 2.4865811706892886

Epoch: 6| Step: 7
Training loss: 1.8478219923720398
Validation loss: 2.4851098083550593

Epoch: 6| Step: 8
Training loss: 1.6224853425620256
Validation loss: 2.457866088192453

Epoch: 6| Step: 9
Training loss: 1.9205025835682783
Validation loss: 2.4926628767545704

Epoch: 6| Step: 10
Training loss: 1.7611047727923381
Validation loss: 2.5258663287053347

Epoch: 6| Step: 11
Training loss: 1.7255667322166255
Validation loss: 2.524440483382954

Epoch: 6| Step: 12
Training loss: 1.7430035514554618
Validation loss: 2.563568357731458

Epoch: 6| Step: 13
Training loss: 1.8805868202864908
Validation loss: 2.60400216663874

Epoch: 312| Step: 0
Training loss: 1.6220491466484812
Validation loss: 2.652977576950795

Epoch: 6| Step: 1
Training loss: 2.2492212431331704
Validation loss: 2.636375167501577

Epoch: 6| Step: 2
Training loss: 1.8010104151482333
Validation loss: 2.635492019681766

Epoch: 6| Step: 3
Training loss: 2.4531216955466397
Validation loss: 2.668977635105647

Epoch: 6| Step: 4
Training loss: 1.23501242102427
Validation loss: 2.617776180126341

Epoch: 6| Step: 5
Training loss: 1.1235582862406186
Validation loss: 2.6569782605112766

Epoch: 6| Step: 6
Training loss: 1.9670568178869496
Validation loss: 2.6108254610103883

Epoch: 6| Step: 7
Training loss: 2.270707841491263
Validation loss: 2.5510631520394713

Epoch: 6| Step: 8
Training loss: 1.819634045079921
Validation loss: 2.5452635958449923

Epoch: 6| Step: 9
Training loss: 1.4572930394844021
Validation loss: 2.5729431480455496

Epoch: 6| Step: 10
Training loss: 1.2457891109787416
Validation loss: 2.5381124117621363

Epoch: 6| Step: 11
Training loss: 1.795591078111523
Validation loss: 2.564672990890148

Epoch: 6| Step: 12
Training loss: 1.7228237079357505
Validation loss: 2.545632041511191

Epoch: 6| Step: 13
Training loss: 1.5857591199857695
Validation loss: 2.519630402578025

Epoch: 313| Step: 0
Training loss: 1.5965188601628584
Validation loss: 2.5454643727191293

Epoch: 6| Step: 1
Training loss: 1.342212817982457
Validation loss: 2.515185916088436

Epoch: 6| Step: 2
Training loss: 2.006549363662882
Validation loss: 2.5053879613314107

Epoch: 6| Step: 3
Training loss: 1.6242839262538271
Validation loss: 2.543272813782732

Epoch: 6| Step: 4
Training loss: 1.7607064394249599
Validation loss: 2.5082697307933906

Epoch: 6| Step: 5
Training loss: 1.593767951415445
Validation loss: 2.5198128712899823

Epoch: 6| Step: 6
Training loss: 1.6615818499948107
Validation loss: 2.552282774521583

Epoch: 6| Step: 7
Training loss: 1.0217724716593917
Validation loss: 2.5421697374069936

Epoch: 6| Step: 8
Training loss: 1.3879741305378268
Validation loss: 2.535696065256473

Epoch: 6| Step: 9
Training loss: 2.529197331535383
Validation loss: 2.535827187430307

Epoch: 6| Step: 10
Training loss: 1.712958548753032
Validation loss: 2.56616784260466

Epoch: 6| Step: 11
Training loss: 1.80893540914349
Validation loss: 2.57296456872825

Epoch: 6| Step: 12
Training loss: 2.1395708816101613
Validation loss: 2.5822105787891605

Epoch: 6| Step: 13
Training loss: 2.3470636975129384
Validation loss: 2.5715822061681495

Epoch: 314| Step: 0
Training loss: 1.8265000645104665
Validation loss: 2.568161068840428

Epoch: 6| Step: 1
Training loss: 2.348048528056054
Validation loss: 2.555297918624487

Epoch: 6| Step: 2
Training loss: 2.1497382647862464
Validation loss: 2.553119096317259

Epoch: 6| Step: 3
Training loss: 1.55010494984365
Validation loss: 2.528797107156565

Epoch: 6| Step: 4
Training loss: 1.1434654507240312
Validation loss: 2.5342753975985346

Epoch: 6| Step: 5
Training loss: 1.8841310687992683
Validation loss: 2.5285279665242624

Epoch: 6| Step: 6
Training loss: 1.7998207161945645
Validation loss: 2.5189896585495255

Epoch: 6| Step: 7
Training loss: 1.7143181275527757
Validation loss: 2.525384456964303

Epoch: 6| Step: 8
Training loss: 1.614296360559478
Validation loss: 2.490795962769207

Epoch: 6| Step: 9
Training loss: 1.917269763876003
Validation loss: 2.5103109239861157

Epoch: 6| Step: 10
Training loss: 1.8845658744943987
Validation loss: 2.49518555549374

Epoch: 6| Step: 11
Training loss: 1.4059787064699363
Validation loss: 2.4892715886721173

Epoch: 6| Step: 12
Training loss: 1.7222524848794918
Validation loss: 2.538583047054999

Epoch: 6| Step: 13
Training loss: 2.273245367471893
Validation loss: 2.632775507364258

Epoch: 315| Step: 0
Training loss: 1.5499664395298445
Validation loss: 2.6850548791752735

Epoch: 6| Step: 1
Training loss: 1.683750366573393
Validation loss: 2.628241218237991

Epoch: 6| Step: 2
Training loss: 1.7256624110945975
Validation loss: 2.667208412891439

Epoch: 6| Step: 3
Training loss: 1.4475958855318836
Validation loss: 2.646094426966955

Epoch: 6| Step: 4
Training loss: 2.29925953099452
Validation loss: 2.661094854708265

Epoch: 6| Step: 5
Training loss: 1.6455336028208891
Validation loss: 2.621157452585694

Epoch: 6| Step: 6
Training loss: 2.2877969726235667
Validation loss: 2.6806215487862852

Epoch: 6| Step: 7
Training loss: 1.8137161515677258
Validation loss: 2.6810809813537264

Epoch: 6| Step: 8
Training loss: 1.9497586956864763
Validation loss: 2.6628985505156098

Epoch: 6| Step: 9
Training loss: 1.5714351759189682
Validation loss: 2.5887864199903428

Epoch: 6| Step: 10
Training loss: 1.6982434510220286
Validation loss: 2.590010478932552

Epoch: 6| Step: 11
Training loss: 1.9290996690929885
Validation loss: 2.5376518673856303

Epoch: 6| Step: 12
Training loss: 1.621001018032011
Validation loss: 2.497942514951295

Epoch: 6| Step: 13
Training loss: 1.6862153709028664
Validation loss: 2.5150335418229

Epoch: 316| Step: 0
Training loss: 1.437697521405466
Validation loss: 2.5307978630490195

Epoch: 6| Step: 1
Training loss: 1.8053286515818021
Validation loss: 2.4772710418377284

Epoch: 6| Step: 2
Training loss: 1.9030218462870254
Validation loss: 2.4836615411690772

Epoch: 6| Step: 3
Training loss: 2.372421169599347
Validation loss: 2.5040228425254596

Epoch: 6| Step: 4
Training loss: 1.850296424624517
Validation loss: 2.5188055526122537

Epoch: 6| Step: 5
Training loss: 1.7142490059464603
Validation loss: 2.5477910023036574

Epoch: 6| Step: 6
Training loss: 2.11232861608037
Validation loss: 2.5198215051287565

Epoch: 6| Step: 7
Training loss: 1.7059725832821224
Validation loss: 2.559410683084664

Epoch: 6| Step: 8
Training loss: 1.2715491118702456
Validation loss: 2.5915250618898122

Epoch: 6| Step: 9
Training loss: 1.391650261277833
Validation loss: 2.6364485840081486

Epoch: 6| Step: 10
Training loss: 1.3811229146775414
Validation loss: 2.6133525327379465

Epoch: 6| Step: 11
Training loss: 2.3207267622617973
Validation loss: 2.5991591769011975

Epoch: 6| Step: 12
Training loss: 1.6257566011128517
Validation loss: 2.6146536940470537

Epoch: 6| Step: 13
Training loss: 1.7337591091541031
Validation loss: 2.5936792356343994

Epoch: 317| Step: 0
Training loss: 1.9574316532680205
Validation loss: 2.5612214628274037

Epoch: 6| Step: 1
Training loss: 1.9537162191115003
Validation loss: 2.5644778395481387

Epoch: 6| Step: 2
Training loss: 2.014230526706309
Validation loss: 2.5505603112365898

Epoch: 6| Step: 3
Training loss: 2.2078175452215887
Validation loss: 2.54257524124586

Epoch: 6| Step: 4
Training loss: 1.45170835946815
Validation loss: 2.5688226434316133

Epoch: 6| Step: 5
Training loss: 1.5302199967236092
Validation loss: 2.5777255432776123

Epoch: 6| Step: 6
Training loss: 1.7924994226345692
Validation loss: 2.5825118071196016

Epoch: 6| Step: 7
Training loss: 1.843801788637233
Validation loss: 2.56168305935534

Epoch: 6| Step: 8
Training loss: 1.5393810426668553
Validation loss: 2.569313141042525

Epoch: 6| Step: 9
Training loss: 1.7037018665167136
Validation loss: 2.5884990547914812

Epoch: 6| Step: 10
Training loss: 1.9583758153433433
Validation loss: 2.56144011683513

Epoch: 6| Step: 11
Training loss: 1.1146090970968499
Validation loss: 2.5380206273986454

Epoch: 6| Step: 12
Training loss: 1.5552177100166125
Validation loss: 2.54747226943327

Epoch: 6| Step: 13
Training loss: 1.6988663932891588
Validation loss: 2.5048332065679797

Epoch: 318| Step: 0
Training loss: 1.8392760743458643
Validation loss: 2.5020138576580186

Epoch: 6| Step: 1
Training loss: 1.8165509566224618
Validation loss: 2.4975742333383333

Epoch: 6| Step: 2
Training loss: 1.5641044008966591
Validation loss: 2.547438654711599

Epoch: 6| Step: 3
Training loss: 2.1350445927199817
Validation loss: 2.5701450884716572

Epoch: 6| Step: 4
Training loss: 1.6199409522374455
Validation loss: 2.5544940746938276

Epoch: 6| Step: 5
Training loss: 1.8805234298078162
Validation loss: 2.555646570515344

Epoch: 6| Step: 6
Training loss: 1.8593911562946979
Validation loss: 2.5784635687569644

Epoch: 6| Step: 7
Training loss: 1.4239654265503576
Validation loss: 2.546666345454823

Epoch: 6| Step: 8
Training loss: 1.470908182345143
Validation loss: 2.583631772573901

Epoch: 6| Step: 9
Training loss: 1.547828072450899
Validation loss: 2.5620129517831627

Epoch: 6| Step: 10
Training loss: 1.683231111135807
Validation loss: 2.5165914254804083

Epoch: 6| Step: 11
Training loss: 1.3843721118492156
Validation loss: 2.5580057259546

Epoch: 6| Step: 12
Training loss: 1.9825947502940264
Validation loss: 2.518502116409613

Epoch: 6| Step: 13
Training loss: 1.9052992153721304
Validation loss: 2.4913235624827967

Epoch: 319| Step: 0
Training loss: 1.4342345590755987
Validation loss: 2.5032176212949735

Epoch: 6| Step: 1
Training loss: 2.2491842486540117
Validation loss: 2.524309997578006

Epoch: 6| Step: 2
Training loss: 2.43859564781054
Validation loss: 2.5259646741531805

Epoch: 6| Step: 3
Training loss: 1.429706344063398
Validation loss: 2.5129956390751866

Epoch: 6| Step: 4
Training loss: 2.2451475588555767
Validation loss: 2.523249175265315

Epoch: 6| Step: 5
Training loss: 1.6233330025695423
Validation loss: 2.5387034626960117

Epoch: 6| Step: 6
Training loss: 1.5357594942808206
Validation loss: 2.5521942322179303

Epoch: 6| Step: 7
Training loss: 2.07880476539393
Validation loss: 2.5992744625577178

Epoch: 6| Step: 8
Training loss: 1.3431084010472893
Validation loss: 2.5834242179224316

Epoch: 6| Step: 9
Training loss: 1.713411397726444
Validation loss: 2.622675153800343

Epoch: 6| Step: 10
Training loss: 1.5070381350283368
Validation loss: 2.6255670570784932

Epoch: 6| Step: 11
Training loss: 1.2654103226555518
Validation loss: 2.6524673155970975

Epoch: 6| Step: 12
Training loss: 1.8081193141010548
Validation loss: 2.5934053368203314

Epoch: 6| Step: 13
Training loss: 1.675350676309542
Validation loss: 2.5793927861333685

Epoch: 320| Step: 0
Training loss: 1.6361505437106239
Validation loss: 2.52390768357446

Epoch: 6| Step: 1
Training loss: 1.3071315510280956
Validation loss: 2.5146721561634235

Epoch: 6| Step: 2
Training loss: 1.822945258506707
Validation loss: 2.5119071324224698

Epoch: 6| Step: 3
Training loss: 1.941328695732296
Validation loss: 2.472361807746085

Epoch: 6| Step: 4
Training loss: 1.9867706256053592
Validation loss: 2.4968272580582425

Epoch: 6| Step: 5
Training loss: 1.3676917317940376
Validation loss: 2.4944936989828084

Epoch: 6| Step: 6
Training loss: 2.1001841055685366
Validation loss: 2.486247478654522

Epoch: 6| Step: 7
Training loss: 1.6153592450032532
Validation loss: 2.5044627887827238

Epoch: 6| Step: 8
Training loss: 1.9836675629436145
Validation loss: 2.552974293687587

Epoch: 6| Step: 9
Training loss: 1.5057546378793722
Validation loss: 2.5871304529164574

Epoch: 6| Step: 10
Training loss: 1.6072868948680414
Validation loss: 2.6332856761466843

Epoch: 6| Step: 11
Training loss: 2.075472867468084
Validation loss: 2.6202255001043118

Epoch: 6| Step: 12
Training loss: 1.688757886776413
Validation loss: 2.6635670280417756

Epoch: 6| Step: 13
Training loss: 1.7913350826056604
Validation loss: 2.5860232581970792

Epoch: 321| Step: 0
Training loss: 1.371888672015421
Validation loss: 2.5697725573384482

Epoch: 6| Step: 1
Training loss: 1.708101613526358
Validation loss: 2.603268542230384

Epoch: 6| Step: 2
Training loss: 1.7804350076033213
Validation loss: 2.5740241602826126

Epoch: 6| Step: 3
Training loss: 1.6863699767552751
Validation loss: 2.5860955227515108

Epoch: 6| Step: 4
Training loss: 2.0633635591543467
Validation loss: 2.576875788586533

Epoch: 6| Step: 5
Training loss: 1.2985416870916888
Validation loss: 2.589786350540508

Epoch: 6| Step: 6
Training loss: 2.011539191963926
Validation loss: 2.575624011949095

Epoch: 6| Step: 7
Training loss: 1.5924014201411125
Validation loss: 2.6004128039766914

Epoch: 6| Step: 8
Training loss: 1.6863839732932262
Validation loss: 2.5913122893626293

Epoch: 6| Step: 9
Training loss: 1.6995425562523274
Validation loss: 2.5584208267443334

Epoch: 6| Step: 10
Training loss: 1.6367795655234434
Validation loss: 2.5818957256198476

Epoch: 6| Step: 11
Training loss: 1.142510671336214
Validation loss: 2.549922703213469

Epoch: 6| Step: 12
Training loss: 1.6700981894768632
Validation loss: 2.537038581375349

Epoch: 6| Step: 13
Training loss: 2.577787989928673
Validation loss: 2.6048429653650196

Epoch: 322| Step: 0
Training loss: 1.7855505309633937
Validation loss: 2.5866203827830048

Epoch: 6| Step: 1
Training loss: 1.9548919009789107
Validation loss: 2.5934383097814866

Epoch: 6| Step: 2
Training loss: 1.633437479682194
Validation loss: 2.5601329570754823

Epoch: 6| Step: 3
Training loss: 2.0496920935906036
Validation loss: 2.593529136476889

Epoch: 6| Step: 4
Training loss: 1.8312729036636979
Validation loss: 2.5991124863607165

Epoch: 6| Step: 5
Training loss: 2.1993553430882646
Validation loss: 2.58917809279955

Epoch: 6| Step: 6
Training loss: 1.2215397523648857
Validation loss: 2.537429566180994

Epoch: 6| Step: 7
Training loss: 1.8734752813479492
Validation loss: 2.569048306855508

Epoch: 6| Step: 8
Training loss: 1.3482273826576512
Validation loss: 2.509762315958219

Epoch: 6| Step: 9
Training loss: 1.6934939708258878
Validation loss: 2.567492088409685

Epoch: 6| Step: 10
Training loss: 1.5109564068941717
Validation loss: 2.527795655905784

Epoch: 6| Step: 11
Training loss: 1.6576220749079225
Validation loss: 2.5715932853235275

Epoch: 6| Step: 12
Training loss: 2.0029893231081157
Validation loss: 2.5625023415407475

Epoch: 6| Step: 13
Training loss: 1.9040817687003289
Validation loss: 2.5641481480153403

Epoch: 323| Step: 0
Training loss: 1.0968750043472333
Validation loss: 2.5663509895185403

Epoch: 6| Step: 1
Training loss: 2.1937961975623916
Validation loss: 2.5520820124616255

Epoch: 6| Step: 2
Training loss: 1.5838915777716946
Validation loss: 2.5520360254587033

Epoch: 6| Step: 3
Training loss: 1.9058519792110293
Validation loss: 2.5580538813483957

Epoch: 6| Step: 4
Training loss: 1.977120482802876
Validation loss: 2.536287044770377

Epoch: 6| Step: 5
Training loss: 2.0898234428773885
Validation loss: 2.5443598804229235

Epoch: 6| Step: 6
Training loss: 1.6276010091115205
Validation loss: 2.597742401453596

Epoch: 6| Step: 7
Training loss: 1.6834965299429507
Validation loss: 2.5480033855595394

Epoch: 6| Step: 8
Training loss: 1.6266287930305925
Validation loss: 2.6063144880163893

Epoch: 6| Step: 9
Training loss: 2.2431647002203055
Validation loss: 2.583504737787152

Epoch: 6| Step: 10
Training loss: 1.2914002000098141
Validation loss: 2.5410249139614516

Epoch: 6| Step: 11
Training loss: 1.5632330128759326
Validation loss: 2.52787750755384

Epoch: 6| Step: 12
Training loss: 1.88386158188076
Validation loss: 2.5131630153985762

Epoch: 6| Step: 13
Training loss: 1.5051061822180443
Validation loss: 2.5390603089934456

Epoch: 324| Step: 0
Training loss: 1.8061639600278652
Validation loss: 2.516062791217695

Epoch: 6| Step: 1
Training loss: 1.9078215702725432
Validation loss: 2.556261625628784

Epoch: 6| Step: 2
Training loss: 2.0491503233979884
Validation loss: 2.57431375871377

Epoch: 6| Step: 3
Training loss: 1.5462757838080063
Validation loss: 2.5695826799707233

Epoch: 6| Step: 4
Training loss: 1.2746009426557
Validation loss: 2.625436822179901

Epoch: 6| Step: 5
Training loss: 1.6171448190557796
Validation loss: 2.611642974992742

Epoch: 6| Step: 6
Training loss: 1.7151059447726351
Validation loss: 2.6748524336948103

Epoch: 6| Step: 7
Training loss: 1.8867254474276185
Validation loss: 2.6562542485221847

Epoch: 6| Step: 8
Training loss: 1.7016874073095931
Validation loss: 2.660770250172587

Epoch: 6| Step: 9
Training loss: 1.7408382511145541
Validation loss: 2.616341980958935

Epoch: 6| Step: 10
Training loss: 1.7749359253614745
Validation loss: 2.6339177076779174

Epoch: 6| Step: 11
Training loss: 1.7620362124754154
Validation loss: 2.607676678612427

Epoch: 6| Step: 12
Training loss: 1.1827612237133691
Validation loss: 2.616621178233651

Epoch: 6| Step: 13
Training loss: 2.1391565339824674
Validation loss: 2.602785466441882

Epoch: 325| Step: 0
Training loss: 1.717365817251963
Validation loss: 2.5347281683818683

Epoch: 6| Step: 1
Training loss: 2.069587091000011
Validation loss: 2.577655603082266

Epoch: 6| Step: 2
Training loss: 1.6473343036782033
Validation loss: 2.567284242738503

Epoch: 6| Step: 3
Training loss: 1.5438407655048558
Validation loss: 2.544093963712129

Epoch: 6| Step: 4
Training loss: 1.4867330192646895
Validation loss: 2.550963866009441

Epoch: 6| Step: 5
Training loss: 2.1655180405134153
Validation loss: 2.590605089259125

Epoch: 6| Step: 6
Training loss: 1.8946521838415609
Validation loss: 2.584342410809645

Epoch: 6| Step: 7
Training loss: 1.4750633096847487
Validation loss: 2.6008000139495575

Epoch: 6| Step: 8
Training loss: 1.339123635248539
Validation loss: 2.5924833031229797

Epoch: 6| Step: 9
Training loss: 1.543800149326982
Validation loss: 2.610062088039092

Epoch: 6| Step: 10
Training loss: 1.376854469606857
Validation loss: 2.6013210822308506

Epoch: 6| Step: 11
Training loss: 1.918898658088232
Validation loss: 2.5989508670146675

Epoch: 6| Step: 12
Training loss: 2.2093842243180073
Validation loss: 2.5644978899219124

Epoch: 6| Step: 13
Training loss: 1.1694090774928876
Validation loss: 2.5851953061795414

Epoch: 326| Step: 0
Training loss: 1.790056244163654
Validation loss: 2.5561138841224813

Epoch: 6| Step: 1
Training loss: 1.369078021175936
Validation loss: 2.539768531645342

Epoch: 6| Step: 2
Training loss: 2.2450445494447764
Validation loss: 2.515112870175571

Epoch: 6| Step: 3
Training loss: 1.4204221576119407
Validation loss: 2.5009352365197777

Epoch: 6| Step: 4
Training loss: 1.1387599171647376
Validation loss: 2.5184221847919894

Epoch: 6| Step: 5
Training loss: 1.6479139897854842
Validation loss: 2.5164288012617124

Epoch: 6| Step: 6
Training loss: 1.2904093786240542
Validation loss: 2.5342972391901415

Epoch: 6| Step: 7
Training loss: 2.1089402492518725
Validation loss: 2.5441486377454194

Epoch: 6| Step: 8
Training loss: 1.654419661359703
Validation loss: 2.5816912405553185

Epoch: 6| Step: 9
Training loss: 1.348988899660357
Validation loss: 2.6045710643853024

Epoch: 6| Step: 10
Training loss: 1.373560759098609
Validation loss: 2.6314780365268153

Epoch: 6| Step: 11
Training loss: 1.971973504993039
Validation loss: 2.575355352184002

Epoch: 6| Step: 12
Training loss: 1.3312817475737564
Validation loss: 2.597241085979026

Epoch: 6| Step: 13
Training loss: 2.329234121457054
Validation loss: 2.631857180819298

Epoch: 327| Step: 0
Training loss: 2.0204020823291056
Validation loss: 2.645919638199831

Epoch: 6| Step: 1
Training loss: 1.8591845118294443
Validation loss: 2.6219494820807387

Epoch: 6| Step: 2
Training loss: 1.9845240379294353
Validation loss: 2.5980032476351522

Epoch: 6| Step: 3
Training loss: 1.3500610567343632
Validation loss: 2.553292044035167

Epoch: 6| Step: 4
Training loss: 1.6209794705106968
Validation loss: 2.5715674956956143

Epoch: 6| Step: 5
Training loss: 2.0126613149497032
Validation loss: 2.551239517741122

Epoch: 6| Step: 6
Training loss: 1.700816628715027
Validation loss: 2.5329609178895733

Epoch: 6| Step: 7
Training loss: 1.30705038126222
Validation loss: 2.545839126338913

Epoch: 6| Step: 8
Training loss: 2.0288535433310275
Validation loss: 2.5263802737307643

Epoch: 6| Step: 9
Training loss: 2.142467402028816
Validation loss: 2.521554817379944

Epoch: 6| Step: 10
Training loss: 1.1601399635687388
Validation loss: 2.542233487279686

Epoch: 6| Step: 11
Training loss: 1.3620501536827327
Validation loss: 2.518393657457491

Epoch: 6| Step: 12
Training loss: 1.2111915075864848
Validation loss: 2.6066437092263617

Epoch: 6| Step: 13
Training loss: 1.3042094102787636
Validation loss: 2.5883678298595183

Epoch: 328| Step: 0
Training loss: 1.7264534065682948
Validation loss: 2.605378354785945

Epoch: 6| Step: 1
Training loss: 1.5012562577421324
Validation loss: 2.6577257582144678

Epoch: 6| Step: 2
Training loss: 1.5929820884756054
Validation loss: 2.650547323746075

Epoch: 6| Step: 3
Training loss: 1.5230034625589506
Validation loss: 2.713862502057548

Epoch: 6| Step: 4
Training loss: 1.420190505022703
Validation loss: 2.64957293362073

Epoch: 6| Step: 5
Training loss: 1.9777778839201785
Validation loss: 2.6622894144132037

Epoch: 6| Step: 6
Training loss: 1.9580223025882164
Validation loss: 2.671007249697348

Epoch: 6| Step: 7
Training loss: 1.8094718235180096
Validation loss: 2.554079409213926

Epoch: 6| Step: 8
Training loss: 1.6337676106724521
Validation loss: 2.534440043751859

Epoch: 6| Step: 9
Training loss: 1.4405196443043846
Validation loss: 2.558241158377093

Epoch: 6| Step: 10
Training loss: 1.472942456024595
Validation loss: 2.5349544372326336

Epoch: 6| Step: 11
Training loss: 1.559066662472207
Validation loss: 2.535141845411416

Epoch: 6| Step: 12
Training loss: 1.9663875877516295
Validation loss: 2.510217679844511

Epoch: 6| Step: 13
Training loss: 1.9662000097090662
Validation loss: 2.5271020662683186

Epoch: 329| Step: 0
Training loss: 1.586016122156389
Validation loss: 2.535555517636112

Epoch: 6| Step: 1
Training loss: 1.1243780324151802
Validation loss: 2.579474479372078

Epoch: 6| Step: 2
Training loss: 1.9373592202508587
Validation loss: 2.5681264251930314

Epoch: 6| Step: 3
Training loss: 1.7621083304609932
Validation loss: 2.553316952210444

Epoch: 6| Step: 4
Training loss: 1.2199682846793494
Validation loss: 2.5980290730949114

Epoch: 6| Step: 5
Training loss: 1.811526727801931
Validation loss: 2.6089315285042227

Epoch: 6| Step: 6
Training loss: 2.002442537357185
Validation loss: 2.5978330317792984

Epoch: 6| Step: 7
Training loss: 1.4428577919490493
Validation loss: 2.6124970419348315

Epoch: 6| Step: 8
Training loss: 1.6307359842917146
Validation loss: 2.5452247062764943

Epoch: 6| Step: 9
Training loss: 1.8796926902642261
Validation loss: 2.5693834629783976

Epoch: 6| Step: 10
Training loss: 1.241201429233103
Validation loss: 2.6198730354995168

Epoch: 6| Step: 11
Training loss: 2.0885513444963264
Validation loss: 2.604114903253449

Epoch: 6| Step: 12
Training loss: 0.9964755953256559
Validation loss: 2.5842959753621706

Epoch: 6| Step: 13
Training loss: 1.8338979227410492
Validation loss: 2.5861069238639973

Epoch: 330| Step: 0
Training loss: 1.6571503117586281
Validation loss: 2.570841478760447

Epoch: 6| Step: 1
Training loss: 1.973474132835128
Validation loss: 2.5625219886890838

Epoch: 6| Step: 2
Training loss: 1.455153495321469
Validation loss: 2.604048693209956

Epoch: 6| Step: 3
Training loss: 1.5135995761463468
Validation loss: 2.5895357941376043

Epoch: 6| Step: 4
Training loss: 1.5377604597340921
Validation loss: 2.6054537961912945

Epoch: 6| Step: 5
Training loss: 1.5788856410626169
Validation loss: 2.604632104606109

Epoch: 6| Step: 6
Training loss: 1.6356407384585332
Validation loss: 2.5788550065850955

Epoch: 6| Step: 7
Training loss: 2.211038647821572
Validation loss: 2.5690620573138023

Epoch: 6| Step: 8
Training loss: 1.7340697286197029
Validation loss: 2.598350413031616

Epoch: 6| Step: 9
Training loss: 1.8506488074742753
Validation loss: 2.559266694462897

Epoch: 6| Step: 10
Training loss: 1.495632170147094
Validation loss: 2.5540494753995064

Epoch: 6| Step: 11
Training loss: 1.4738228222276142
Validation loss: 2.5483548442347677

Epoch: 6| Step: 12
Training loss: 1.642297673181956
Validation loss: 2.5179947773922424

Epoch: 6| Step: 13
Training loss: 1.724574398666774
Validation loss: 2.5250818113412223

Epoch: 331| Step: 0
Training loss: 1.3841496269069857
Validation loss: 2.510616988318932

Epoch: 6| Step: 1
Training loss: 2.021769067739697
Validation loss: 2.5306768514142166

Epoch: 6| Step: 2
Training loss: 1.5669907694570893
Validation loss: 2.522549909104866

Epoch: 6| Step: 3
Training loss: 1.2849132922712705
Validation loss: 2.5169077223052683

Epoch: 6| Step: 4
Training loss: 1.9570876549303586
Validation loss: 2.5743236993091343

Epoch: 6| Step: 5
Training loss: 1.5854918506789417
Validation loss: 2.5524456052498348

Epoch: 6| Step: 6
Training loss: 1.6706935237441851
Validation loss: 2.5305470640479935

Epoch: 6| Step: 7
Training loss: 1.5157976347145181
Validation loss: 2.575706171837752

Epoch: 6| Step: 8
Training loss: 1.8033897060155066
Validation loss: 2.5664212687540155

Epoch: 6| Step: 9
Training loss: 1.9010563122607584
Validation loss: 2.583443582909929

Epoch: 6| Step: 10
Training loss: 1.977349407379365
Validation loss: 2.5539747326805116

Epoch: 6| Step: 11
Training loss: 1.1984610384901166
Validation loss: 2.603246455051523

Epoch: 6| Step: 12
Training loss: 1.606678453589504
Validation loss: 2.613156698211524

Epoch: 6| Step: 13
Training loss: 1.7628655940518128
Validation loss: 2.5386596673133006

Epoch: 332| Step: 0
Training loss: 1.4204480063547993
Validation loss: 2.6228444619475257

Epoch: 6| Step: 1
Training loss: 1.3736478052144172
Validation loss: 2.6139584639376356

Epoch: 6| Step: 2
Training loss: 1.6866343361818017
Validation loss: 2.5719744131991837

Epoch: 6| Step: 3
Training loss: 2.181481173706657
Validation loss: 2.5574894897851546

Epoch: 6| Step: 4
Training loss: 1.895116090464616
Validation loss: 2.5947472673556056

Epoch: 6| Step: 5
Training loss: 1.4409859724295193
Validation loss: 2.5396624360088307

Epoch: 6| Step: 6
Training loss: 1.846529078482127
Validation loss: 2.580850905630685

Epoch: 6| Step: 7
Training loss: 2.3049804501314717
Validation loss: 2.5286175261044828

Epoch: 6| Step: 8
Training loss: 1.7975360483685232
Validation loss: 2.5524325436786586

Epoch: 6| Step: 9
Training loss: 1.3221357498734556
Validation loss: 2.5557667263752

Epoch: 6| Step: 10
Training loss: 1.4737717023938877
Validation loss: 2.4943205694588872

Epoch: 6| Step: 11
Training loss: 1.0416346100007154
Validation loss: 2.536787013091047

Epoch: 6| Step: 12
Training loss: 1.7152912364162298
Validation loss: 2.501281918244675

Epoch: 6| Step: 13
Training loss: 1.1942215472483964
Validation loss: 2.4972969382988284

Epoch: 333| Step: 0
Training loss: 2.138520368670361
Validation loss: 2.4753228744394096

Epoch: 6| Step: 1
Training loss: 2.0232656987725535
Validation loss: 2.4774024092683713

Epoch: 6| Step: 2
Training loss: 1.1682738859223363
Validation loss: 2.533568838951597

Epoch: 6| Step: 3
Training loss: 1.2219097552027396
Validation loss: 2.542928653367721

Epoch: 6| Step: 4
Training loss: 1.9894658664824902
Validation loss: 2.553841515941374

Epoch: 6| Step: 5
Training loss: 1.639549993089594
Validation loss: 2.5906572095266758

Epoch: 6| Step: 6
Training loss: 1.6520803976654228
Validation loss: 2.5877808208082795

Epoch: 6| Step: 7
Training loss: 1.6762666154986656
Validation loss: 2.563661498165447

Epoch: 6| Step: 8
Training loss: 1.287648760895671
Validation loss: 2.546215931622813

Epoch: 6| Step: 9
Training loss: 1.3000723250150665
Validation loss: 2.534097239697264

Epoch: 6| Step: 10
Training loss: 1.3077714300600278
Validation loss: 2.575653895588068

Epoch: 6| Step: 11
Training loss: 1.3059739035530054
Validation loss: 2.5413333304234427

Epoch: 6| Step: 12
Training loss: 2.137943007756016
Validation loss: 2.5674146957613595

Epoch: 6| Step: 13
Training loss: 2.0518626241226494
Validation loss: 2.5774097722094202

Epoch: 334| Step: 0
Training loss: 1.3598212463347297
Validation loss: 2.6319052531987905

Epoch: 6| Step: 1
Training loss: 1.3408935704677598
Validation loss: 2.581128938559261

Epoch: 6| Step: 2
Training loss: 1.9696526653024344
Validation loss: 2.605380642538835

Epoch: 6| Step: 3
Training loss: 1.0845821347683706
Validation loss: 2.6321421599012864

Epoch: 6| Step: 4
Training loss: 1.7836957503839448
Validation loss: 2.6508439195747937

Epoch: 6| Step: 5
Training loss: 1.321203890224161
Validation loss: 2.6879125914165556

Epoch: 6| Step: 6
Training loss: 1.731715663709939
Validation loss: 2.6078687725391694

Epoch: 6| Step: 7
Training loss: 1.9149151829594089
Validation loss: 2.642896754717904

Epoch: 6| Step: 8
Training loss: 1.988549954407255
Validation loss: 2.630549347680069

Epoch: 6| Step: 9
Training loss: 1.4399461251353247
Validation loss: 2.650785082757999

Epoch: 6| Step: 10
Training loss: 1.6973584745622279
Validation loss: 2.639169250340869

Epoch: 6| Step: 11
Training loss: 1.6000810423830425
Validation loss: 2.5995791858856663

Epoch: 6| Step: 12
Training loss: 1.4851888734303635
Validation loss: 2.558906780633489

Epoch: 6| Step: 13
Training loss: 2.0164177097259475
Validation loss: 2.5776149206630246

Epoch: 335| Step: 0
Training loss: 1.6546484923695368
Validation loss: 2.5286470223976325

Epoch: 6| Step: 1
Training loss: 1.2920492077482653
Validation loss: 2.5535000326812565

Epoch: 6| Step: 2
Training loss: 1.817567318872515
Validation loss: 2.5185526364276094

Epoch: 6| Step: 3
Training loss: 1.4581019990090405
Validation loss: 2.5211376973252193

Epoch: 6| Step: 4
Training loss: 2.139534999916837
Validation loss: 2.5322199246532504

Epoch: 6| Step: 5
Training loss: 2.2818307006848983
Validation loss: 2.5661098671006926

Epoch: 6| Step: 6
Training loss: 1.2880674278427482
Validation loss: 2.5581324037639996

Epoch: 6| Step: 7
Training loss: 1.380139067249317
Validation loss: 2.605322639757048

Epoch: 6| Step: 8
Training loss: 1.7979105080343996
Validation loss: 2.601243802426343

Epoch: 6| Step: 9
Training loss: 1.8171433132634613
Validation loss: 2.61800632098848

Epoch: 6| Step: 10
Training loss: 1.59513151840362
Validation loss: 2.646243684340989

Epoch: 6| Step: 11
Training loss: 1.7533439295536783
Validation loss: 2.6496400756647005

Epoch: 6| Step: 12
Training loss: 1.6188315912252582
Validation loss: 2.6140165487211666

Epoch: 6| Step: 13
Training loss: 1.4832537783316309
Validation loss: 2.6099120936930458

Epoch: 336| Step: 0
Training loss: 1.561076469459378
Validation loss: 2.6085284415043524

Epoch: 6| Step: 1
Training loss: 2.453422771288661
Validation loss: 2.5589227751179866

Epoch: 6| Step: 2
Training loss: 1.9436190177721886
Validation loss: 2.5940277379870804

Epoch: 6| Step: 3
Training loss: 1.2522892969278598
Validation loss: 2.587425625848654

Epoch: 6| Step: 4
Training loss: 1.4240359140324887
Validation loss: 2.6019665745077023

Epoch: 6| Step: 5
Training loss: 1.3660512071425372
Validation loss: 2.557220012544041

Epoch: 6| Step: 6
Training loss: 1.3501490881506641
Validation loss: 2.579289445024344

Epoch: 6| Step: 7
Training loss: 1.7068164960961167
Validation loss: 2.5748538756652266

Epoch: 6| Step: 8
Training loss: 1.6520726046829173
Validation loss: 2.586307418502978

Epoch: 6| Step: 9
Training loss: 1.2690205177590346
Validation loss: 2.566750861826427

Epoch: 6| Step: 10
Training loss: 1.5117425645633091
Validation loss: 2.577753306095481

Epoch: 6| Step: 11
Training loss: 1.9484139961837943
Validation loss: 2.5839014402859437

Epoch: 6| Step: 12
Training loss: 1.6302742096709564
Validation loss: 2.562128520804281

Epoch: 6| Step: 13
Training loss: 1.3897084419554604
Validation loss: 2.5848291486236894

Epoch: 337| Step: 0
Training loss: 1.6946836087370185
Validation loss: 2.5254589129599774

Epoch: 6| Step: 1
Training loss: 1.0565196195406426
Validation loss: 2.5364166872546936

Epoch: 6| Step: 2
Training loss: 1.395905103783644
Validation loss: 2.5596367105611466

Epoch: 6| Step: 3
Training loss: 1.237521976699661
Validation loss: 2.5648057689831116

Epoch: 6| Step: 4
Training loss: 1.918243450685077
Validation loss: 2.555081421698791

Epoch: 6| Step: 5
Training loss: 2.1696926651697708
Validation loss: 2.5767035679150854

Epoch: 6| Step: 6
Training loss: 1.7892069529223673
Validation loss: 2.5893392018648793

Epoch: 6| Step: 7
Training loss: 1.4270194751717762
Validation loss: 2.63400097594295

Epoch: 6| Step: 8
Training loss: 1.2636958360242814
Validation loss: 2.5852756940312895

Epoch: 6| Step: 9
Training loss: 1.742192973996445
Validation loss: 2.6188138397131557

Epoch: 6| Step: 10
Training loss: 1.2773745471846407
Validation loss: 2.6625274531422134

Epoch: 6| Step: 11
Training loss: 2.291226350503045
Validation loss: 2.5964589201451

Epoch: 6| Step: 12
Training loss: 1.605090688478491
Validation loss: 2.5071671745943718

Epoch: 6| Step: 13
Training loss: 1.443121409124679
Validation loss: 2.5388705606538675

Epoch: 338| Step: 0
Training loss: 1.3211470455019847
Validation loss: 2.5138631459903285

Epoch: 6| Step: 1
Training loss: 1.7124990365798356
Validation loss: 2.532765488185335

Epoch: 6| Step: 2
Training loss: 1.5427758977580395
Validation loss: 2.5032359003017697

Epoch: 6| Step: 3
Training loss: 1.8894050382244718
Validation loss: 2.543038144119449

Epoch: 6| Step: 4
Training loss: 1.241462255886637
Validation loss: 2.521772199297861

Epoch: 6| Step: 5
Training loss: 1.3670085680901687
Validation loss: 2.588251743672367

Epoch: 6| Step: 6
Training loss: 1.8165621782870542
Validation loss: 2.5994255293245607

Epoch: 6| Step: 7
Training loss: 1.5781500786025586
Validation loss: 2.5899253744128745

Epoch: 6| Step: 8
Training loss: 1.7241118978310763
Validation loss: 2.665034082467941

Epoch: 6| Step: 9
Training loss: 1.6435497553587612
Validation loss: 2.623456698073453

Epoch: 6| Step: 10
Training loss: 1.3295442066912957
Validation loss: 2.6250109293876673

Epoch: 6| Step: 11
Training loss: 1.3972840053852051
Validation loss: 2.585267978135612

Epoch: 6| Step: 12
Training loss: 1.150186880103132
Validation loss: 2.567686832691317

Epoch: 6| Step: 13
Training loss: 2.4827243911733046
Validation loss: 2.542876937779214

Epoch: 339| Step: 0
Training loss: 2.0159283786721667
Validation loss: 2.5227978882889595

Epoch: 6| Step: 1
Training loss: 1.6391840101500106
Validation loss: 2.53255927992765

Epoch: 6| Step: 2
Training loss: 1.91302306308992
Validation loss: 2.517375471286081

Epoch: 6| Step: 3
Training loss: 1.2557811564385775
Validation loss: 2.52208498679682

Epoch: 6| Step: 4
Training loss: 1.62501239771882
Validation loss: 2.5498866430032017

Epoch: 6| Step: 5
Training loss: 1.6748216277842243
Validation loss: 2.5631969868627182

Epoch: 6| Step: 6
Training loss: 1.2564292077684305
Validation loss: 2.6113856672339635

Epoch: 6| Step: 7
Training loss: 1.3325934691864385
Validation loss: 2.58844904794665

Epoch: 6| Step: 8
Training loss: 1.628106888507408
Validation loss: 2.610869446070531

Epoch: 6| Step: 9
Training loss: 2.0895414044581226
Validation loss: 2.5755905177939953

Epoch: 6| Step: 10
Training loss: 1.4394955260037336
Validation loss: 2.599028964156352

Epoch: 6| Step: 11
Training loss: 1.3047275194437713
Validation loss: 2.5681130874962803

Epoch: 6| Step: 12
Training loss: 1.73857823953012
Validation loss: 2.5287719024649995

Epoch: 6| Step: 13
Training loss: 1.5972830562708589
Validation loss: 2.551618686858642

Epoch: 340| Step: 0
Training loss: 1.8476502497053402
Validation loss: 2.5661774431226045

Epoch: 6| Step: 1
Training loss: 1.753339306249465
Validation loss: 2.570175862956116

Epoch: 6| Step: 2
Training loss: 2.057842660507667
Validation loss: 2.583031257277817

Epoch: 6| Step: 3
Training loss: 2.0316458683133285
Validation loss: 2.5343546724268595

Epoch: 6| Step: 4
Training loss: 1.3337183138257325
Validation loss: 2.5778869519006813

Epoch: 6| Step: 5
Training loss: 1.6208834959895826
Validation loss: 2.5884201410167362

Epoch: 6| Step: 6
Training loss: 1.9396089950267985
Validation loss: 2.5975900741981977

Epoch: 6| Step: 7
Training loss: 1.0152310120723929
Validation loss: 2.5698093281234224

Epoch: 6| Step: 8
Training loss: 1.1751803259760165
Validation loss: 2.576526493077696

Epoch: 6| Step: 9
Training loss: 1.4016211728134167
Validation loss: 2.5526862282214764

Epoch: 6| Step: 10
Training loss: 1.2151354473266474
Validation loss: 2.5657071303720858

Epoch: 6| Step: 11
Training loss: 1.6282830452678034
Validation loss: 2.5328796070331023

Epoch: 6| Step: 12
Training loss: 1.8674634147032512
Validation loss: 2.5508740784528188

Epoch: 6| Step: 13
Training loss: 1.36804120249354
Validation loss: 2.534302883791964

Epoch: 341| Step: 0
Training loss: 1.3770590017749809
Validation loss: 2.521723366818684

Epoch: 6| Step: 1
Training loss: 1.7217587578889881
Validation loss: 2.524899935864134

Epoch: 6| Step: 2
Training loss: 1.7224374229901485
Validation loss: 2.5523988853052013

Epoch: 6| Step: 3
Training loss: 1.6200026183637015
Validation loss: 2.564381025336539

Epoch: 6| Step: 4
Training loss: 1.8528331147178023
Validation loss: 2.539145506455686

Epoch: 6| Step: 5
Training loss: 1.948550918324931
Validation loss: 2.5552027782489177

Epoch: 6| Step: 6
Training loss: 1.9965525956385117
Validation loss: 2.579179875510004

Epoch: 6| Step: 7
Training loss: 1.2004547211267844
Validation loss: 2.6002703905113287

Epoch: 6| Step: 8
Training loss: 0.9632208143892261
Validation loss: 2.5937591613852855

Epoch: 6| Step: 9
Training loss: 1.5717256933935506
Validation loss: 2.601538825094431

Epoch: 6| Step: 10
Training loss: 1.4211147078215978
Validation loss: 2.6166537827176595

Epoch: 6| Step: 11
Training loss: 1.6113535746096281
Validation loss: 2.6236097120630553

Epoch: 6| Step: 12
Training loss: 1.710728532405865
Validation loss: 2.668280848078861

Epoch: 6| Step: 13
Training loss: 1.5371300042790563
Validation loss: 2.6913214136344292

Epoch: 342| Step: 0
Training loss: 1.3029715852515593
Validation loss: 2.7132110296642424

Epoch: 6| Step: 1
Training loss: 1.4645415541150952
Validation loss: 2.6667825008109434

Epoch: 6| Step: 2
Training loss: 1.6983971725210336
Validation loss: 2.5651960688875897

Epoch: 6| Step: 3
Training loss: 1.4270886423425235
Validation loss: 2.5561324766419915

Epoch: 6| Step: 4
Training loss: 1.4887795402613284
Validation loss: 2.5494373436297333

Epoch: 6| Step: 5
Training loss: 2.3169292612155967
Validation loss: 2.5446869748337635

Epoch: 6| Step: 6
Training loss: 1.6374939605368557
Validation loss: 2.5270837790626914

Epoch: 6| Step: 7
Training loss: 1.9905350956758612
Validation loss: 2.5000608675222735

Epoch: 6| Step: 8
Training loss: 1.5391889026455927
Validation loss: 2.4972823471574768

Epoch: 6| Step: 9
Training loss: 1.1372429861278857
Validation loss: 2.5232242143722514

Epoch: 6| Step: 10
Training loss: 1.6647824444843773
Validation loss: 2.537733244550664

Epoch: 6| Step: 11
Training loss: 1.630676478563568
Validation loss: 2.549936338639795

Epoch: 6| Step: 12
Training loss: 1.5054649301509173
Validation loss: 2.5378337841020593

Epoch: 6| Step: 13
Training loss: 1.3611355047353961
Validation loss: 2.5813043737957764

Epoch: 343| Step: 0
Training loss: 1.6078792398760593
Validation loss: 2.5979257850109665

Epoch: 6| Step: 1
Training loss: 2.0227634087706177
Validation loss: 2.5497893215238996

Epoch: 6| Step: 2
Training loss: 1.5611108326638283
Validation loss: 2.622903940676439

Epoch: 6| Step: 3
Training loss: 1.7476389488895179
Validation loss: 2.5733982258440022

Epoch: 6| Step: 4
Training loss: 1.273765194159302
Validation loss: 2.5489459520877706

Epoch: 6| Step: 5
Training loss: 1.690724224344779
Validation loss: 2.5792364941965285

Epoch: 6| Step: 6
Training loss: 2.6507339648710038
Validation loss: 2.572469067475622

Epoch: 6| Step: 7
Training loss: 1.401987354607904
Validation loss: 2.582010597073305

Epoch: 6| Step: 8
Training loss: 1.5488216597240534
Validation loss: 2.6157642575059867

Epoch: 6| Step: 9
Training loss: 1.3225183062377104
Validation loss: 2.627476334022146

Epoch: 6| Step: 10
Training loss: 0.990942015600006
Validation loss: 2.618839771003638

Epoch: 6| Step: 11
Training loss: 1.4044933791746352
Validation loss: 2.635532577639455

Epoch: 6| Step: 12
Training loss: 1.5344649838168543
Validation loss: 2.6623221461870314

Epoch: 6| Step: 13
Training loss: 1.145546212491763
Validation loss: 2.6129526065655524

Epoch: 344| Step: 0
Training loss: 1.606386984835861
Validation loss: 2.6395114755421383

Epoch: 6| Step: 1
Training loss: 1.4090088802244618
Validation loss: 2.6214216911178108

Epoch: 6| Step: 2
Training loss: 1.6239368922604585
Validation loss: 2.6069459249792253

Epoch: 6| Step: 3
Training loss: 1.906536893674213
Validation loss: 2.5969330815974656

Epoch: 6| Step: 4
Training loss: 1.2815346750486507
Validation loss: 2.5709607699158634

Epoch: 6| Step: 5
Training loss: 1.1699197352012465
Validation loss: 2.5840208051501388

Epoch: 6| Step: 6
Training loss: 2.24011687791262
Validation loss: 2.5596628687819187

Epoch: 6| Step: 7
Training loss: 1.418513926220189
Validation loss: 2.5638805252766286

Epoch: 6| Step: 8
Training loss: 1.0371433978058697
Validation loss: 2.5446303291617913

Epoch: 6| Step: 9
Training loss: 1.547311740449011
Validation loss: 2.5596852078460723

Epoch: 6| Step: 10
Training loss: 1.7361225568605996
Validation loss: 2.6184668455396545

Epoch: 6| Step: 11
Training loss: 1.2995118141532618
Validation loss: 2.58506439005814

Epoch: 6| Step: 12
Training loss: 1.5548316467016488
Validation loss: 2.6444046989449563

Epoch: 6| Step: 13
Training loss: 1.8932084017265938
Validation loss: 2.632798493873477

Epoch: 345| Step: 0
Training loss: 2.0178581700762463
Validation loss: 2.6753126936118834

Epoch: 6| Step: 1
Training loss: 1.7997144075168308
Validation loss: 2.6263437616120493

Epoch: 6| Step: 2
Training loss: 1.3604196064534146
Validation loss: 2.617421154011528

Epoch: 6| Step: 3
Training loss: 1.3552865997084318
Validation loss: 2.597844090757023

Epoch: 6| Step: 4
Training loss: 1.581253576463115
Validation loss: 2.572694411054113

Epoch: 6| Step: 5
Training loss: 1.9849728862534564
Validation loss: 2.5251783383530895

Epoch: 6| Step: 6
Training loss: 1.92080826346476
Validation loss: 2.555516193151249

Epoch: 6| Step: 7
Training loss: 1.6690243099081
Validation loss: 2.5218789609163386

Epoch: 6| Step: 8
Training loss: 1.1462184201115808
Validation loss: 2.5253558509283307

Epoch: 6| Step: 9
Training loss: 1.5440242971524585
Validation loss: 2.5446813766891148

Epoch: 6| Step: 10
Training loss: 1.5498686827130823
Validation loss: 2.5687952790983895

Epoch: 6| Step: 11
Training loss: 1.1264820932589676
Validation loss: 2.590595487235533

Epoch: 6| Step: 12
Training loss: 1.4864698385084334
Validation loss: 2.599764381027272

Epoch: 6| Step: 13
Training loss: 1.5287342035158988
Validation loss: 2.623214674652871

Epoch: 346| Step: 0
Training loss: 1.3173430870180267
Validation loss: 2.608149851925826

Epoch: 6| Step: 1
Training loss: 1.4797957609344574
Validation loss: 2.6235432442761053

Epoch: 6| Step: 2
Training loss: 1.505343694001374
Validation loss: 2.671827988833766

Epoch: 6| Step: 3
Training loss: 1.5755404468503038
Validation loss: 2.634682433688647

Epoch: 6| Step: 4
Training loss: 2.043863541835125
Validation loss: 2.6672975618388204

Epoch: 6| Step: 5
Training loss: 2.126370605062354
Validation loss: 2.6827166371889595

Epoch: 6| Step: 6
Training loss: 0.9344795844703948
Validation loss: 2.6201768722115424

Epoch: 6| Step: 7
Training loss: 1.4389729624177148
Validation loss: 2.609463520794732

Epoch: 6| Step: 8
Training loss: 1.7356055765572744
Validation loss: 2.5923767054517075

Epoch: 6| Step: 9
Training loss: 1.3999911580487736
Validation loss: 2.593955388037737

Epoch: 6| Step: 10
Training loss: 1.5524521289269642
Validation loss: 2.5171150628055865

Epoch: 6| Step: 11
Training loss: 1.8712704760209011
Validation loss: 2.5223773189739256

Epoch: 6| Step: 12
Training loss: 0.9823864727580804
Validation loss: 2.4923393019918976

Epoch: 6| Step: 13
Training loss: 2.051703196783207
Validation loss: 2.5852814886230617

Epoch: 347| Step: 0
Training loss: 1.4376786162489115
Validation loss: 2.5632985274238265

Epoch: 6| Step: 1
Training loss: 1.433194637611359
Validation loss: 2.5895091550785128

Epoch: 6| Step: 2
Training loss: 2.062423357840022
Validation loss: 2.6389043194057553

Epoch: 6| Step: 3
Training loss: 1.7968839562234338
Validation loss: 2.6162285713378983

Epoch: 6| Step: 4
Training loss: 1.4878965666620503
Validation loss: 2.524992063402853

Epoch: 6| Step: 5
Training loss: 1.4982591699923977
Validation loss: 2.5064256107135945

Epoch: 6| Step: 6
Training loss: 1.9216245162368708
Validation loss: 2.5197373653352084

Epoch: 6| Step: 7
Training loss: 1.912040358516479
Validation loss: 2.4927956328439675

Epoch: 6| Step: 8
Training loss: 1.0293474854507747
Validation loss: 2.4685492695514717

Epoch: 6| Step: 9
Training loss: 1.9812572948429819
Validation loss: 2.5399078292218165

Epoch: 6| Step: 10
Training loss: 1.1562973218977062
Validation loss: 2.529659729291299

Epoch: 6| Step: 11
Training loss: 1.869713770130165
Validation loss: 2.5581920434619834

Epoch: 6| Step: 12
Training loss: 1.474608243221834
Validation loss: 2.5858204825702096

Epoch: 6| Step: 13
Training loss: 1.5814860593680053
Validation loss: 2.571488301842388

Epoch: 348| Step: 0
Training loss: 1.259171077982263
Validation loss: 2.586199805717686

Epoch: 6| Step: 1
Training loss: 1.9525884272715275
Validation loss: 2.574609968898888

Epoch: 6| Step: 2
Training loss: 1.5619354754124148
Validation loss: 2.5759704989299905

Epoch: 6| Step: 3
Training loss: 1.3643669898461603
Validation loss: 2.6057684791268616

Epoch: 6| Step: 4
Training loss: 2.057643374225272
Validation loss: 2.5915122049510275

Epoch: 6| Step: 5
Training loss: 1.6473230870704114
Validation loss: 2.6263109294318103

Epoch: 6| Step: 6
Training loss: 1.2991885954201285
Validation loss: 2.6255340260030002

Epoch: 6| Step: 7
Training loss: 1.118508897939528
Validation loss: 2.604703715578469

Epoch: 6| Step: 8
Training loss: 1.4210221803666951
Validation loss: 2.6267103799177502

Epoch: 6| Step: 9
Training loss: 1.5790363361992648
Validation loss: 2.560958600301594

Epoch: 6| Step: 10
Training loss: 1.3303730507445417
Validation loss: 2.5248054914182294

Epoch: 6| Step: 11
Training loss: 1.8353734225296425
Validation loss: 2.5366689501871997

Epoch: 6| Step: 12
Training loss: 1.6807185357601533
Validation loss: 2.5205330840652804

Epoch: 6| Step: 13
Training loss: 1.4408025537001172
Validation loss: 2.506188450070981

Epoch: 349| Step: 0
Training loss: 1.3299542564040303
Validation loss: 2.521844540222584

Epoch: 6| Step: 1
Training loss: 1.3685147192110825
Validation loss: 2.5145987871817668

Epoch: 6| Step: 2
Training loss: 1.2955173601925614
Validation loss: 2.528032102005781

Epoch: 6| Step: 3
Training loss: 1.88722320194398
Validation loss: 2.5028430349705517

Epoch: 6| Step: 4
Training loss: 1.4497982213604457
Validation loss: 2.5241235326047575

Epoch: 6| Step: 5
Training loss: 1.709518052832852
Validation loss: 2.5002035534960316

Epoch: 6| Step: 6
Training loss: 1.4472612594559242
Validation loss: 2.5005363365878757

Epoch: 6| Step: 7
Training loss: 1.6604889659704514
Validation loss: 2.5341032453999497

Epoch: 6| Step: 8
Training loss: 1.8187677598853003
Validation loss: 2.5433717907322433

Epoch: 6| Step: 9
Training loss: 1.192848258438179
Validation loss: 2.565477780986559

Epoch: 6| Step: 10
Training loss: 1.143443140441878
Validation loss: 2.5592351910199094

Epoch: 6| Step: 11
Training loss: 1.1245633973517861
Validation loss: 2.5749368085792455

Epoch: 6| Step: 12
Training loss: 1.5602561097333365
Validation loss: 2.5327861975140156

Epoch: 6| Step: 13
Training loss: 1.7819799968568666
Validation loss: 2.5748006484260353

Epoch: 350| Step: 0
Training loss: 1.2389233004680915
Validation loss: 2.576549796340497

Epoch: 6| Step: 1
Training loss: 1.732026374338572
Validation loss: 2.6012926238547367

Epoch: 6| Step: 2
Training loss: 1.6863154739778377
Validation loss: 2.64177537347449

Epoch: 6| Step: 3
Training loss: 1.5354047190780635
Validation loss: 2.6398478762069537

Epoch: 6| Step: 4
Training loss: 1.2314245961902397
Validation loss: 2.6116015743558

Epoch: 6| Step: 5
Training loss: 1.623355767227556
Validation loss: 2.608027797593739

Epoch: 6| Step: 6
Training loss: 1.6483959897857814
Validation loss: 2.5566815323710386

Epoch: 6| Step: 7
Training loss: 1.4666909739618623
Validation loss: 2.562970164826011

Epoch: 6| Step: 8
Training loss: 2.0133034991691754
Validation loss: 2.5068039495163217

Epoch: 6| Step: 9
Training loss: 1.3039886521711568
Validation loss: 2.5440856699623917

Epoch: 6| Step: 10
Training loss: 1.1704553779201796
Validation loss: 2.537076171156539

Epoch: 6| Step: 11
Training loss: 0.9328013612730717
Validation loss: 2.5565992662364447

Epoch: 6| Step: 12
Training loss: 1.8121450668605887
Validation loss: 2.543445673303454

Epoch: 6| Step: 13
Training loss: 1.6416454229900617
Validation loss: 2.535678317993737

Epoch: 351| Step: 0
Training loss: 1.2688254874186573
Validation loss: 2.5407057545595544

Epoch: 6| Step: 1
Training loss: 1.505721148963605
Validation loss: 2.5027806791734926

Epoch: 6| Step: 2
Training loss: 1.5985341539740427
Validation loss: 2.5038678924590183

Epoch: 6| Step: 3
Training loss: 1.7923646129304787
Validation loss: 2.524414408798735

Epoch: 6| Step: 4
Training loss: 1.4625568085421128
Validation loss: 2.544373858008132

Epoch: 6| Step: 5
Training loss: 1.402924398852798
Validation loss: 2.5819115776919106

Epoch: 6| Step: 6
Training loss: 1.5854183907150672
Validation loss: 2.6004390180845873

Epoch: 6| Step: 7
Training loss: 1.3639729665974702
Validation loss: 2.6356358393023416

Epoch: 6| Step: 8
Training loss: 1.2309613891669686
Validation loss: 2.583603096279776

Epoch: 6| Step: 9
Training loss: 1.3641610790519643
Validation loss: 2.538687466042661

Epoch: 6| Step: 10
Training loss: 1.6943768147311453
Validation loss: 2.584639501047951

Epoch: 6| Step: 11
Training loss: 1.8096927080588345
Validation loss: 2.5631487265568245

Epoch: 6| Step: 12
Training loss: 1.5594395228550881
Validation loss: 2.5651724301209153

Epoch: 6| Step: 13
Training loss: 1.2260092684284989
Validation loss: 2.5389068555810645

Epoch: 352| Step: 0
Training loss: 1.4474006208917378
Validation loss: 2.5368410535848245

Epoch: 6| Step: 1
Training loss: 1.8383553025958157
Validation loss: 2.550720751572174

Epoch: 6| Step: 2
Training loss: 1.3186103638398936
Validation loss: 2.548525456840808

Epoch: 6| Step: 3
Training loss: 1.562688587251964
Validation loss: 2.561381258638132

Epoch: 6| Step: 4
Training loss: 1.5482847937184285
Validation loss: 2.5608763939807804

Epoch: 6| Step: 5
Training loss: 1.4532604359505203
Validation loss: 2.559627706482656

Epoch: 6| Step: 6
Training loss: 1.79381287095744
Validation loss: 2.5694120582624445

Epoch: 6| Step: 7
Training loss: 0.9630466358007816
Validation loss: 2.5625967302130883

Epoch: 6| Step: 8
Training loss: 1.8030142685658308
Validation loss: 2.56989981479534

Epoch: 6| Step: 9
Training loss: 1.6087820942366464
Validation loss: 2.58850726764217

Epoch: 6| Step: 10
Training loss: 1.173544190860803
Validation loss: 2.5699660387528898

Epoch: 6| Step: 11
Training loss: 1.770105264626278
Validation loss: 2.6032351290032225

Epoch: 6| Step: 12
Training loss: 1.3400141660453935
Validation loss: 2.6467416260559413

Epoch: 6| Step: 13
Training loss: 1.5289805195916564
Validation loss: 2.5753292299182475

Epoch: 353| Step: 0
Training loss: 1.3318473263841126
Validation loss: 2.5618258031293872

Epoch: 6| Step: 1
Training loss: 1.3030907459468206
Validation loss: 2.514732107603771

Epoch: 6| Step: 2
Training loss: 1.294631304008161
Validation loss: 2.6157426100480095

Epoch: 6| Step: 3
Training loss: 1.5422496810173192
Validation loss: 2.54009779730577

Epoch: 6| Step: 4
Training loss: 1.7112076776814689
Validation loss: 2.5612376910897967

Epoch: 6| Step: 5
Training loss: 2.024401931983977
Validation loss: 2.5595756995474197

Epoch: 6| Step: 6
Training loss: 1.6652022922189456
Validation loss: 2.5477185168899674

Epoch: 6| Step: 7
Training loss: 1.462311205945594
Validation loss: 2.5939769415790117

Epoch: 6| Step: 8
Training loss: 1.0427362990209748
Validation loss: 2.6225788667527725

Epoch: 6| Step: 9
Training loss: 1.3018697588920856
Validation loss: 2.6098874896561997

Epoch: 6| Step: 10
Training loss: 1.3109008492949148
Validation loss: 2.5921479298593373

Epoch: 6| Step: 11
Training loss: 1.9613394154381514
Validation loss: 2.6232003294670485

Epoch: 6| Step: 12
Training loss: 1.0594143660441429
Validation loss: 2.660098619999142

Epoch: 6| Step: 13
Training loss: 1.2793696492003568
Validation loss: 2.60504703645226

Epoch: 354| Step: 0
Training loss: 1.1462547683200643
Validation loss: 2.597894566821024

Epoch: 6| Step: 1
Training loss: 1.9881245189715333
Validation loss: 2.6455818617455136

Epoch: 6| Step: 2
Training loss: 1.7342977420679788
Validation loss: 2.6065195110455983

Epoch: 6| Step: 3
Training loss: 1.7762665890503562
Validation loss: 2.580510555879186

Epoch: 6| Step: 4
Training loss: 1.1317734260839523
Validation loss: 2.599027848062595

Epoch: 6| Step: 5
Training loss: 1.661423502430401
Validation loss: 2.5844401070367145

Epoch: 6| Step: 6
Training loss: 1.6518117350292516
Validation loss: 2.5450234420935827

Epoch: 6| Step: 7
Training loss: 1.3977468905795558
Validation loss: 2.553323659712525

Epoch: 6| Step: 8
Training loss: 1.3890816342867134
Validation loss: 2.5522119269119328

Epoch: 6| Step: 9
Training loss: 1.2524329826562486
Validation loss: 2.6104696722552836

Epoch: 6| Step: 10
Training loss: 1.5941336674855064
Validation loss: 2.614637812519263

Epoch: 6| Step: 11
Training loss: 1.4115166270850648
Validation loss: 2.655086486902016

Epoch: 6| Step: 12
Training loss: 1.0604686392068419
Validation loss: 2.575564860760579

Epoch: 6| Step: 13
Training loss: 1.259604557593378
Validation loss: 2.576216837326983

Epoch: 355| Step: 0
Training loss: 1.4661657446078944
Validation loss: 2.5403536912510893

Epoch: 6| Step: 1
Training loss: 1.688322643812306
Validation loss: 2.5134733013452357

Epoch: 6| Step: 2
Training loss: 0.8537474782188782
Validation loss: 2.566229904673378

Epoch: 6| Step: 3
Training loss: 0.8248820957549783
Validation loss: 2.544750224424163

Epoch: 6| Step: 4
Training loss: 1.1343596318152336
Validation loss: 2.540785282298292

Epoch: 6| Step: 5
Training loss: 1.39582828501837
Validation loss: 2.5779670589888553

Epoch: 6| Step: 6
Training loss: 2.2314047110638864
Validation loss: 2.5503192539699815

Epoch: 6| Step: 7
Training loss: 1.9041419959052603
Validation loss: 2.5464466101338

Epoch: 6| Step: 8
Training loss: 1.4337751809048245
Validation loss: 2.62625506082683

Epoch: 6| Step: 9
Training loss: 1.2760137697660747
Validation loss: 2.625879223732366

Epoch: 6| Step: 10
Training loss: 1.4265789152205808
Validation loss: 2.6640214963500077

Epoch: 6| Step: 11
Training loss: 1.8196834410475242
Validation loss: 2.710985972972431

Epoch: 6| Step: 12
Training loss: 1.9950370604435737
Validation loss: 2.7757393754097657

Epoch: 6| Step: 13
Training loss: 1.6456099571876284
Validation loss: 2.734635578636603

Epoch: 356| Step: 0
Training loss: 1.6111526301211772
Validation loss: 2.722791379241537

Epoch: 6| Step: 1
Training loss: 1.203620808483055
Validation loss: 2.6503505792780757

Epoch: 6| Step: 2
Training loss: 1.1955957014898049
Validation loss: 2.6103249836434457

Epoch: 6| Step: 3
Training loss: 1.8689760077841366
Validation loss: 2.6187517340630833

Epoch: 6| Step: 4
Training loss: 1.6515624451434254
Validation loss: 2.5495256309964027

Epoch: 6| Step: 5
Training loss: 1.4676066879404954
Validation loss: 2.585988085541073

Epoch: 6| Step: 6
Training loss: 1.4089904785024052
Validation loss: 2.564091614583674

Epoch: 6| Step: 7
Training loss: 1.5086403585194716
Validation loss: 2.5618659064553486

Epoch: 6| Step: 8
Training loss: 1.4861215856466217
Validation loss: 2.6133376164385025

Epoch: 6| Step: 9
Training loss: 1.8853372448233605
Validation loss: 2.542173762363485

Epoch: 6| Step: 10
Training loss: 1.8869985684913497
Validation loss: 2.5213495834572646

Epoch: 6| Step: 11
Training loss: 1.4630707042972
Validation loss: 2.5903377838502335

Epoch: 6| Step: 12
Training loss: 1.7460994165657142
Validation loss: 2.586997868318175

Epoch: 6| Step: 13
Training loss: 1.7626667052084783
Validation loss: 2.634267312620884

Epoch: 357| Step: 0
Training loss: 1.2763309021208722
Validation loss: 2.650604156985461

Epoch: 6| Step: 1
Training loss: 1.4333688835052796
Validation loss: 2.6163246820188286

Epoch: 6| Step: 2
Training loss: 1.5255652021279207
Validation loss: 2.6017974197583684

Epoch: 6| Step: 3
Training loss: 1.5764820119918626
Validation loss: 2.5737661099775

Epoch: 6| Step: 4
Training loss: 1.4871522320603299
Validation loss: 2.554205114957868

Epoch: 6| Step: 5
Training loss: 1.5158721879561998
Validation loss: 2.5586772254741224

Epoch: 6| Step: 6
Training loss: 1.1724460482029249
Validation loss: 2.5391327285835525

Epoch: 6| Step: 7
Training loss: 1.3849179032159529
Validation loss: 2.5308602743396946

Epoch: 6| Step: 8
Training loss: 1.765807555896987
Validation loss: 2.5747756085570384

Epoch: 6| Step: 9
Training loss: 1.933965104018056
Validation loss: 2.5500044367633197

Epoch: 6| Step: 10
Training loss: 1.376031921875856
Validation loss: 2.5778795992492953

Epoch: 6| Step: 11
Training loss: 1.0882798873334187
Validation loss: 2.5716092009025293

Epoch: 6| Step: 12
Training loss: 1.8739123050563562
Validation loss: 2.599096295830103

Epoch: 6| Step: 13
Training loss: 1.3497472049537937
Validation loss: 2.5723376118003727

Epoch: 358| Step: 0
Training loss: 1.487028140070514
Validation loss: 2.5479320056751957

Epoch: 6| Step: 1
Training loss: 1.5054965243823608
Validation loss: 2.555185671888702

Epoch: 6| Step: 2
Training loss: 1.3156087027149688
Validation loss: 2.5630574434163496

Epoch: 6| Step: 3
Training loss: 1.659672062894884
Validation loss: 2.590994340055883

Epoch: 6| Step: 4
Training loss: 0.9960702033158226
Validation loss: 2.5824661696545568

Epoch: 6| Step: 5
Training loss: 1.4571560149173088
Validation loss: 2.6319157764637153

Epoch: 6| Step: 6
Training loss: 0.990950496640084
Validation loss: 2.6240454406535076

Epoch: 6| Step: 7
Training loss: 1.5784299952317848
Validation loss: 2.6256069662359693

Epoch: 6| Step: 8
Training loss: 1.3962461041538732
Validation loss: 2.6026717714561887

Epoch: 6| Step: 9
Training loss: 1.5416208294764346
Validation loss: 2.652524781825927

Epoch: 6| Step: 10
Training loss: 1.434416324460675
Validation loss: 2.636803293638811

Epoch: 6| Step: 11
Training loss: 1.2655300528621458
Validation loss: 2.6483877621821814

Epoch: 6| Step: 12
Training loss: 1.4999411889309078
Validation loss: 2.629861387025532

Epoch: 6| Step: 13
Training loss: 1.6143383045286714
Validation loss: 2.6647742430950125

Epoch: 359| Step: 0
Training loss: 1.616653280432165
Validation loss: 2.632463018840482

Epoch: 6| Step: 1
Training loss: 1.0388559695472068
Validation loss: 2.5959405802395477

Epoch: 6| Step: 2
Training loss: 1.3649170251576415
Validation loss: 2.6222903935367796

Epoch: 6| Step: 3
Training loss: 1.2387537490988159
Validation loss: 2.5786900219065108

Epoch: 6| Step: 4
Training loss: 1.2924161807833365
Validation loss: 2.5712584713339015

Epoch: 6| Step: 5
Training loss: 1.5422188397192407
Validation loss: 2.5887016896778334

Epoch: 6| Step: 6
Training loss: 1.7587282635200285
Validation loss: 2.5804781414757687

Epoch: 6| Step: 7
Training loss: 0.9516394873733554
Validation loss: 2.5812289885988906

Epoch: 6| Step: 8
Training loss: 1.6146146791758345
Validation loss: 2.620482902771443

Epoch: 6| Step: 9
Training loss: 1.8871932607841717
Validation loss: 2.609604892007198

Epoch: 6| Step: 10
Training loss: 1.4763066307271933
Validation loss: 2.6192998456053

Epoch: 6| Step: 11
Training loss: 1.607492253001576
Validation loss: 2.610167194652932

Epoch: 6| Step: 12
Training loss: 1.6276045247395439
Validation loss: 2.6387888225745635

Epoch: 6| Step: 13
Training loss: 1.437661369222576
Validation loss: 2.6346887832268666

Epoch: 360| Step: 0
Training loss: 1.304453023524525
Validation loss: 2.6200218680976106

Epoch: 6| Step: 1
Training loss: 1.1899496210477627
Validation loss: 2.618967466345779

Epoch: 6| Step: 2
Training loss: 1.1890842009680738
Validation loss: 2.6348392070037443

Epoch: 6| Step: 3
Training loss: 1.252635418772348
Validation loss: 2.6076857529746733

Epoch: 6| Step: 4
Training loss: 1.9027156897050093
Validation loss: 2.5927658052206404

Epoch: 6| Step: 5
Training loss: 1.2195456426383349
Validation loss: 2.575563981350814

Epoch: 6| Step: 6
Training loss: 1.8962890650145805
Validation loss: 2.5914022398687537

Epoch: 6| Step: 7
Training loss: 1.1296469294648344
Validation loss: 2.587871776968018

Epoch: 6| Step: 8
Training loss: 1.2584069784141907
Validation loss: 2.590091913990644

Epoch: 6| Step: 9
Training loss: 1.1636938753126027
Validation loss: 2.6367391703250544

Epoch: 6| Step: 10
Training loss: 1.7348177233103115
Validation loss: 2.579538454940765

Epoch: 6| Step: 11
Training loss: 1.021898933153709
Validation loss: 2.6242296208615206

Epoch: 6| Step: 12
Training loss: 1.510101004752882
Validation loss: 2.5754466160236977

Epoch: 6| Step: 13
Training loss: 1.2993360401090792
Validation loss: 2.615822218642168

Epoch: 361| Step: 0
Training loss: 1.0736007854978982
Validation loss: 2.6168930267619306

Epoch: 6| Step: 1
Training loss: 1.4044454228086591
Validation loss: 2.6441180809391054

Epoch: 6| Step: 2
Training loss: 1.2989413792845415
Validation loss: 2.6034633347911407

Epoch: 6| Step: 3
Training loss: 1.6930010107299889
Validation loss: 2.573116346222239

Epoch: 6| Step: 4
Training loss: 1.2140222451938685
Validation loss: 2.6106071989198227

Epoch: 6| Step: 5
Training loss: 1.2444692324447837
Validation loss: 2.5690723739760326

Epoch: 6| Step: 6
Training loss: 1.9084827292432658
Validation loss: 2.560714487292539

Epoch: 6| Step: 7
Training loss: 1.5957422706910458
Validation loss: 2.587995065944789

Epoch: 6| Step: 8
Training loss: 1.0847491891211305
Validation loss: 2.5427365370367045

Epoch: 6| Step: 9
Training loss: 1.3088532603278806
Validation loss: 2.5377151592219103

Epoch: 6| Step: 10
Training loss: 1.5577592264782842
Validation loss: 2.5570896066264748

Epoch: 6| Step: 11
Training loss: 0.9885138136246328
Validation loss: 2.543389398382682

Epoch: 6| Step: 12
Training loss: 1.7187479192547774
Validation loss: 2.5787419669463345

Epoch: 6| Step: 13
Training loss: 1.5517248554703087
Validation loss: 2.561887543842931

Epoch: 362| Step: 0
Training loss: 1.1467450704957218
Validation loss: 2.576620830664465

Epoch: 6| Step: 1
Training loss: 1.0453025623527703
Validation loss: 2.579405218214974

Epoch: 6| Step: 2
Training loss: 0.8833790539359303
Validation loss: 2.6030892902808476

Epoch: 6| Step: 3
Training loss: 1.268917040798384
Validation loss: 2.6320179571410702

Epoch: 6| Step: 4
Training loss: 1.47944311683784
Validation loss: 2.6212201985739054

Epoch: 6| Step: 5
Training loss: 1.295589591323154
Validation loss: 2.6605937820143213

Epoch: 6| Step: 6
Training loss: 1.8945936684305242
Validation loss: 2.662577747648536

Epoch: 6| Step: 7
Training loss: 1.7036232875574937
Validation loss: 2.698967943624693

Epoch: 6| Step: 8
Training loss: 1.5878076660707314
Validation loss: 2.629992921273359

Epoch: 6| Step: 9
Training loss: 1.2936598668052843
Validation loss: 2.6031118062125

Epoch: 6| Step: 10
Training loss: 1.2785436378344879
Validation loss: 2.545300829981432

Epoch: 6| Step: 11
Training loss: 1.4636029086982492
Validation loss: 2.5791931944937763

Epoch: 6| Step: 12
Training loss: 0.9971365462972811
Validation loss: 2.6168112868740554

Epoch: 6| Step: 13
Training loss: 1.618315077867614
Validation loss: 2.581926090717205

Epoch: 363| Step: 0
Training loss: 1.088483337348404
Validation loss: 2.5547163997652604

Epoch: 6| Step: 1
Training loss: 1.4010070976142885
Validation loss: 2.5369002226892725

Epoch: 6| Step: 2
Training loss: 1.7028200769002089
Validation loss: 2.519600682447795

Epoch: 6| Step: 3
Training loss: 1.654996001362652
Validation loss: 2.5504321043879634

Epoch: 6| Step: 4
Training loss: 1.4440609848849932
Validation loss: 2.556176330201251

Epoch: 6| Step: 5
Training loss: 1.2093971546125115
Validation loss: 2.5423624201647375

Epoch: 6| Step: 6
Training loss: 1.3030586353848306
Validation loss: 2.6177181484060164

Epoch: 6| Step: 7
Training loss: 1.407902065057254
Validation loss: 2.611942558501106

Epoch: 6| Step: 8
Training loss: 1.479352867692583
Validation loss: 2.6426614587035124

Epoch: 6| Step: 9
Training loss: 1.6543323283354174
Validation loss: 2.6858509534288815

Epoch: 6| Step: 10
Training loss: 1.1041570099222415
Validation loss: 2.654611059461284

Epoch: 6| Step: 11
Training loss: 1.4637077300681578
Validation loss: 2.675163253365937

Epoch: 6| Step: 12
Training loss: 1.9717152381174645
Validation loss: 2.704992880092048

Epoch: 6| Step: 13
Training loss: 1.235499485492792
Validation loss: 2.647651743348009

Epoch: 364| Step: 0
Training loss: 1.285964248026773
Validation loss: 2.647881163432376

Epoch: 6| Step: 1
Training loss: 1.0726470546786708
Validation loss: 2.660747326102922

Epoch: 6| Step: 2
Training loss: 1.4156412826847962
Validation loss: 2.6068177931929086

Epoch: 6| Step: 3
Training loss: 1.5142969821886005
Validation loss: 2.6280078760539056

Epoch: 6| Step: 4
Training loss: 0.9939345950093971
Validation loss: 2.606669517679761

Epoch: 6| Step: 5
Training loss: 1.883746916446301
Validation loss: 2.624668615101944

Epoch: 6| Step: 6
Training loss: 1.8220359927410859
Validation loss: 2.5911807161727567

Epoch: 6| Step: 7
Training loss: 1.0503920504389035
Validation loss: 2.6364902425578562

Epoch: 6| Step: 8
Training loss: 1.1637547745488908
Validation loss: 2.602855708438055

Epoch: 6| Step: 9
Training loss: 1.583578074094912
Validation loss: 2.587579595720614

Epoch: 6| Step: 10
Training loss: 1.2998651251151407
Validation loss: 2.6128138650234285

Epoch: 6| Step: 11
Training loss: 1.2070850249228027
Validation loss: 2.5633281672078008

Epoch: 6| Step: 12
Training loss: 1.2254927033604424
Validation loss: 2.6008194940164793

Epoch: 6| Step: 13
Training loss: 1.0530914097531312
Validation loss: 2.5804384583002147

Epoch: 365| Step: 0
Training loss: 1.9375012305471142
Validation loss: 2.614130768736696

Epoch: 6| Step: 1
Training loss: 1.3763433310091027
Validation loss: 2.6409946912697464

Epoch: 6| Step: 2
Training loss: 1.0829250899179685
Validation loss: 2.6590559705668357

Epoch: 6| Step: 3
Training loss: 1.3446609602961377
Validation loss: 2.628706842788654

Epoch: 6| Step: 4
Training loss: 1.546952679157554
Validation loss: 2.6231669883466875

Epoch: 6| Step: 5
Training loss: 1.3805869776686746
Validation loss: 2.639488110910974

Epoch: 6| Step: 6
Training loss: 1.430217540439977
Validation loss: 2.6121416329807507

Epoch: 6| Step: 7
Training loss: 0.9549959923625161
Validation loss: 2.641606977813303

Epoch: 6| Step: 8
Training loss: 1.682150024813005
Validation loss: 2.639913850688774

Epoch: 6| Step: 9
Training loss: 1.3585327871814672
Validation loss: 2.6147415802219447

Epoch: 6| Step: 10
Training loss: 1.126554104460227
Validation loss: 2.641534155962804

Epoch: 6| Step: 11
Training loss: 0.7873124459371044
Validation loss: 2.6487416980727922

Epoch: 6| Step: 12
Training loss: 1.5534759861735616
Validation loss: 2.604402841666805

Epoch: 6| Step: 13
Training loss: 0.9192129590599225
Validation loss: 2.612359462651006

Epoch: 366| Step: 0
Training loss: 0.7677756484879765
Validation loss: 2.6251875341123405

Epoch: 6| Step: 1
Training loss: 0.8166110133326959
Validation loss: 2.6270793823002734

Epoch: 6| Step: 2
Training loss: 1.7788473958032915
Validation loss: 2.653797034291369

Epoch: 6| Step: 3
Training loss: 1.1091529731468857
Validation loss: 2.6298677179843226

Epoch: 6| Step: 4
Training loss: 1.3835459342806093
Validation loss: 2.632506612181926

Epoch: 6| Step: 5
Training loss: 1.1425730126421416
Validation loss: 2.6331259128711735

Epoch: 6| Step: 6
Training loss: 1.2013453908749867
Validation loss: 2.6750426375178873

Epoch: 6| Step: 7
Training loss: 1.4569504948140788
Validation loss: 2.627203304285131

Epoch: 6| Step: 8
Training loss: 0.9224932585575886
Validation loss: 2.5846828709369003

Epoch: 6| Step: 9
Training loss: 1.061124528402834
Validation loss: 2.625019164242498

Epoch: 6| Step: 10
Training loss: 1.9258819615645608
Validation loss: 2.6320672041536852

Epoch: 6| Step: 11
Training loss: 1.263118192190995
Validation loss: 2.651611556657939

Epoch: 6| Step: 12
Training loss: 1.7708673212118229
Validation loss: 2.668295114717268

Epoch: 6| Step: 13
Training loss: 1.5193132964974072
Validation loss: 2.6430744345088675

Epoch: 367| Step: 0
Training loss: 1.680971160795602
Validation loss: 2.644840321964075

Epoch: 6| Step: 1
Training loss: 1.1647478684608294
Validation loss: 2.595998287521683

Epoch: 6| Step: 2
Training loss: 1.3914354512975309
Validation loss: 2.6057913378910076

Epoch: 6| Step: 3
Training loss: 1.3535367625514
Validation loss: 2.563365557492435

Epoch: 6| Step: 4
Training loss: 1.116936181884384
Validation loss: 2.548388033662982

Epoch: 6| Step: 5
Training loss: 1.6349575426847744
Validation loss: 2.539178229408825

Epoch: 6| Step: 6
Training loss: 1.118002374278023
Validation loss: 2.5806132013703005

Epoch: 6| Step: 7
Training loss: 1.6482368817217452
Validation loss: 2.543183879669128

Epoch: 6| Step: 8
Training loss: 1.6314881717254281
Validation loss: 2.601484234523274

Epoch: 6| Step: 9
Training loss: 1.4695172842072952
Validation loss: 2.5800852095655635

Epoch: 6| Step: 10
Training loss: 1.0914390673717609
Validation loss: 2.604251422774395

Epoch: 6| Step: 11
Training loss: 1.2026749797253204
Validation loss: 2.669399415927704

Epoch: 6| Step: 12
Training loss: 1.661220075052173
Validation loss: 2.6995139726537545

Epoch: 6| Step: 13
Training loss: 1.795961562473893
Validation loss: 2.746089394476861

Epoch: 368| Step: 0
Training loss: 1.3695014771937146
Validation loss: 2.718435832027969

Epoch: 6| Step: 1
Training loss: 1.4472742736805095
Validation loss: 2.732311451052901

Epoch: 6| Step: 2
Training loss: 1.450239701025209
Validation loss: 2.652865126859922

Epoch: 6| Step: 3
Training loss: 1.1034600978148157
Validation loss: 2.641478646944894

Epoch: 6| Step: 4
Training loss: 1.505430088625673
Validation loss: 2.604568165663906

Epoch: 6| Step: 5
Training loss: 1.3799779687726144
Validation loss: 2.5661968298654747

Epoch: 6| Step: 6
Training loss: 1.049042862659209
Validation loss: 2.519457612452454

Epoch: 6| Step: 7
Training loss: 2.144834069723229
Validation loss: 2.488023777550663

Epoch: 6| Step: 8
Training loss: 1.6481479191551731
Validation loss: 2.5071652726975064

Epoch: 6| Step: 9
Training loss: 1.0482792332633102
Validation loss: 2.5165195651568095

Epoch: 6| Step: 10
Training loss: 1.1717996191575955
Validation loss: 2.5496996328684935

Epoch: 6| Step: 11
Training loss: 1.2353812836098639
Validation loss: 2.546532949245826

Epoch: 6| Step: 12
Training loss: 1.9433745877231203
Validation loss: 2.660042557268376

Epoch: 6| Step: 13
Training loss: 1.5458823978558291
Validation loss: 2.643424887841474

Epoch: 369| Step: 0
Training loss: 1.0985793172739795
Validation loss: 2.680710726009306

Epoch: 6| Step: 1
Training loss: 1.3176692258235965
Validation loss: 2.6746855188466334

Epoch: 6| Step: 2
Training loss: 1.2321250787877958
Validation loss: 2.7188054513939948

Epoch: 6| Step: 3
Training loss: 2.0636757476036682
Validation loss: 2.7779885360448278

Epoch: 6| Step: 4
Training loss: 1.702718493743507
Validation loss: 2.69889188444452

Epoch: 6| Step: 5
Training loss: 1.2626346063145546
Validation loss: 2.687821657315761

Epoch: 6| Step: 6
Training loss: 0.9906636347893296
Validation loss: 2.6355148769569827

Epoch: 6| Step: 7
Training loss: 1.3770483105813636
Validation loss: 2.60159300212525

Epoch: 6| Step: 8
Training loss: 1.4073382511330075
Validation loss: 2.5484644916663486

Epoch: 6| Step: 9
Training loss: 1.238900880988394
Validation loss: 2.5502870479161754

Epoch: 6| Step: 10
Training loss: 1.9227669979658994
Validation loss: 2.5538351054301724

Epoch: 6| Step: 11
Training loss: 1.6894826897476367
Validation loss: 2.5660447050349524

Epoch: 6| Step: 12
Training loss: 1.3469486313804613
Validation loss: 2.4904953045742375

Epoch: 6| Step: 13
Training loss: 1.5010339034773423
Validation loss: 2.5310904762643616

Epoch: 370| Step: 0
Training loss: 1.4423654564269761
Validation loss: 2.571880492292977

Epoch: 6| Step: 1
Training loss: 1.094527921596697
Validation loss: 2.6279983199678854

Epoch: 6| Step: 2
Training loss: 1.5275465106282586
Validation loss: 2.601250890450277

Epoch: 6| Step: 3
Training loss: 1.2302359224477968
Validation loss: 2.67188500891404

Epoch: 6| Step: 4
Training loss: 1.3197841151301704
Validation loss: 2.6483638306820914

Epoch: 6| Step: 5
Training loss: 1.3142154019514611
Validation loss: 2.6741098348875574

Epoch: 6| Step: 6
Training loss: 1.403523960614315
Validation loss: 2.6967651138521043

Epoch: 6| Step: 7
Training loss: 1.356908116439485
Validation loss: 2.693826237991481

Epoch: 6| Step: 8
Training loss: 0.9968590881608417
Validation loss: 2.6743663676147023

Epoch: 6| Step: 9
Training loss: 1.4085079291800633
Validation loss: 2.705637959964526

Epoch: 6| Step: 10
Training loss: 1.561618327298844
Validation loss: 2.6366081610199648

Epoch: 6| Step: 11
Training loss: 1.2696950014584272
Validation loss: 2.663954895769891

Epoch: 6| Step: 12
Training loss: 1.3162442795356564
Validation loss: 2.6045168272478008

Epoch: 6| Step: 13
Training loss: 1.8446669157451043
Validation loss: 2.625121514974354

Epoch: 371| Step: 0
Training loss: 1.039572339710112
Validation loss: 2.549280680384367

Epoch: 6| Step: 1
Training loss: 1.4863285260193693
Validation loss: 2.6026501601448455

Epoch: 6| Step: 2
Training loss: 1.271209405796671
Validation loss: 2.5806483394977526

Epoch: 6| Step: 3
Training loss: 1.1418333576963176
Validation loss: 2.552891775783676

Epoch: 6| Step: 4
Training loss: 1.8769784026572465
Validation loss: 2.5621916422581887

Epoch: 6| Step: 5
Training loss: 1.6528612413177752
Validation loss: 2.565858601549677

Epoch: 6| Step: 6
Training loss: 1.1039546127146256
Validation loss: 2.566133667566227

Epoch: 6| Step: 7
Training loss: 1.478875664396236
Validation loss: 2.6121717757878864

Epoch: 6| Step: 8
Training loss: 1.435812581702567
Validation loss: 2.626139151430632

Epoch: 6| Step: 9
Training loss: 1.1677065143463277
Validation loss: 2.6576160732840823

Epoch: 6| Step: 10
Training loss: 1.083527449798367
Validation loss: 2.662038158901795

Epoch: 6| Step: 11
Training loss: 1.4008614614470198
Validation loss: 2.6161221893434945

Epoch: 6| Step: 12
Training loss: 1.2947538102810765
Validation loss: 2.52906238544124

Epoch: 6| Step: 13
Training loss: 1.297941849139224
Validation loss: 2.580673283890315

Epoch: 372| Step: 0
Training loss: 1.480510298415171
Validation loss: 2.5328668210830796

Epoch: 6| Step: 1
Training loss: 1.607676452278434
Validation loss: 2.5310280000013776

Epoch: 6| Step: 2
Training loss: 1.1397478571840474
Validation loss: 2.550355167836749

Epoch: 6| Step: 3
Training loss: 1.5153529916090398
Validation loss: 2.555959184763489

Epoch: 6| Step: 4
Training loss: 1.010189948585666
Validation loss: 2.5371554994293724

Epoch: 6| Step: 5
Training loss: 1.6390605915593037
Validation loss: 2.556074242429488

Epoch: 6| Step: 6
Training loss: 0.9883229243120095
Validation loss: 2.5622676650997973

Epoch: 6| Step: 7
Training loss: 1.358429415450381
Validation loss: 2.580105693091347

Epoch: 6| Step: 8
Training loss: 0.9120400379954146
Validation loss: 2.5946311985801973

Epoch: 6| Step: 9
Training loss: 1.7691718740771443
Validation loss: 2.5789066401368372

Epoch: 6| Step: 10
Training loss: 1.090661948378818
Validation loss: 2.6545508391627357

Epoch: 6| Step: 11
Training loss: 1.3085118965625568
Validation loss: 2.6084979595439335

Epoch: 6| Step: 12
Training loss: 1.1725937228779626
Validation loss: 2.59361671197203

Epoch: 6| Step: 13
Training loss: 1.1573970878282307
Validation loss: 2.6505318072054314

Epoch: 373| Step: 0
Training loss: 1.8352282513638138
Validation loss: 2.652328461203615

Epoch: 6| Step: 1
Training loss: 1.2159379649400373
Validation loss: 2.6198129115876956

Epoch: 6| Step: 2
Training loss: 1.2487152649990658
Validation loss: 2.625274492474608

Epoch: 6| Step: 3
Training loss: 1.6687077977705413
Validation loss: 2.5573779918346684

Epoch: 6| Step: 4
Training loss: 1.0842979733596012
Validation loss: 2.5458806911211416

Epoch: 6| Step: 5
Training loss: 1.254499396146505
Validation loss: 2.587015332641896

Epoch: 6| Step: 6
Training loss: 1.2405408585695175
Validation loss: 2.6263267555017267

Epoch: 6| Step: 7
Training loss: 1.203101219833982
Validation loss: 2.5786361187684017

Epoch: 6| Step: 8
Training loss: 1.521045626450683
Validation loss: 2.630544075766837

Epoch: 6| Step: 9
Training loss: 1.3355060795424605
Validation loss: 2.6128020633640694

Epoch: 6| Step: 10
Training loss: 1.2300361478347552
Validation loss: 2.5711517973453586

Epoch: 6| Step: 11
Training loss: 1.1336818121915626
Validation loss: 2.5442414895392287

Epoch: 6| Step: 12
Training loss: 0.8276103957949874
Validation loss: 2.58677507648533

Epoch: 6| Step: 13
Training loss: 1.1768461961913508
Validation loss: 2.5707332340168474

Epoch: 374| Step: 0
Training loss: 0.9070562853713631
Validation loss: 2.5855064224864712

Epoch: 6| Step: 1
Training loss: 1.2947750324746954
Validation loss: 2.548572918232982

Epoch: 6| Step: 2
Training loss: 1.4757628520992072
Validation loss: 2.5675169207328925

Epoch: 6| Step: 3
Training loss: 1.1696156401883977
Validation loss: 2.53827464865134

Epoch: 6| Step: 4
Training loss: 1.3971270596223755
Validation loss: 2.5413468477577625

Epoch: 6| Step: 5
Training loss: 1.5722701741976113
Validation loss: 2.5498909752421053

Epoch: 6| Step: 6
Training loss: 1.3822472058035278
Validation loss: 2.589772694774734

Epoch: 6| Step: 7
Training loss: 1.2226776023682144
Validation loss: 2.629064002554095

Epoch: 6| Step: 8
Training loss: 0.8416661915604664
Validation loss: 2.557754371151883

Epoch: 6| Step: 9
Training loss: 1.5786452238542552
Validation loss: 2.595264008260592

Epoch: 6| Step: 10
Training loss: 1.1384244097015441
Validation loss: 2.5604501449428287

Epoch: 6| Step: 11
Training loss: 0.9789295653468728
Validation loss: 2.611556688690019

Epoch: 6| Step: 12
Training loss: 1.0723871881335063
Validation loss: 2.6130155115578373

Epoch: 6| Step: 13
Training loss: 1.862784585396437
Validation loss: 2.6644351135578717

Epoch: 375| Step: 0
Training loss: 1.2131026078151892
Validation loss: 2.642557719721161

Epoch: 6| Step: 1
Training loss: 1.3248386788678892
Validation loss: 2.6826864797639116

Epoch: 6| Step: 2
Training loss: 1.33960546037228
Validation loss: 2.6710462270107205

Epoch: 6| Step: 3
Training loss: 1.06407996119934
Validation loss: 2.62964798400286

Epoch: 6| Step: 4
Training loss: 0.8698904167965624
Validation loss: 2.632711844402062

Epoch: 6| Step: 5
Training loss: 1.7932653244174255
Validation loss: 2.635430782013939

Epoch: 6| Step: 6
Training loss: 0.6775092594809002
Validation loss: 2.5371700492027274

Epoch: 6| Step: 7
Training loss: 1.3577312309079033
Validation loss: 2.534731460508004

Epoch: 6| Step: 8
Training loss: 1.2906890317536397
Validation loss: 2.5505951077910094

Epoch: 6| Step: 9
Training loss: 1.3458607087239702
Validation loss: 2.5688565506690804

Epoch: 6| Step: 10
Training loss: 1.4920703782058296
Validation loss: 2.5460025564621893

Epoch: 6| Step: 11
Training loss: 1.2404883417537291
Validation loss: 2.559719779453318

Epoch: 6| Step: 12
Training loss: 1.7018367549817137
Validation loss: 2.6057248349521966

Epoch: 6| Step: 13
Training loss: 1.1194916020019177
Validation loss: 2.578734539686448

Epoch: 376| Step: 0
Training loss: 1.643991268422498
Validation loss: 2.607945977923058

Epoch: 6| Step: 1
Training loss: 1.3743446695780974
Validation loss: 2.6027397417156948

Epoch: 6| Step: 2
Training loss: 1.310282559752165
Validation loss: 2.6113031082267466

Epoch: 6| Step: 3
Training loss: 1.628781247545525
Validation loss: 2.5989387577723737

Epoch: 6| Step: 4
Training loss: 0.5851422317109187
Validation loss: 2.557332620597093

Epoch: 6| Step: 5
Training loss: 1.1343379831711082
Validation loss: 2.524913659209037

Epoch: 6| Step: 6
Training loss: 1.0136377112009924
Validation loss: 2.5467071009799622

Epoch: 6| Step: 7
Training loss: 1.5149789593434682
Validation loss: 2.5587418452687185

Epoch: 6| Step: 8
Training loss: 1.2407545065366588
Validation loss: 2.5618344194645157

Epoch: 6| Step: 9
Training loss: 1.321039845942071
Validation loss: 2.5416428507538518

Epoch: 6| Step: 10
Training loss: 0.941213184361132
Validation loss: 2.5573211611246576

Epoch: 6| Step: 11
Training loss: 1.076574897417902
Validation loss: 2.546157860765684

Epoch: 6| Step: 12
Training loss: 1.3956712182639421
Validation loss: 2.626108571256593

Epoch: 6| Step: 13
Training loss: 1.3157676710029003
Validation loss: 2.6731947377856478

Epoch: 377| Step: 0
Training loss: 1.2755431103062314
Validation loss: 2.604560766281503

Epoch: 6| Step: 1
Training loss: 1.394854553529512
Validation loss: 2.655382373703504

Epoch: 6| Step: 2
Training loss: 1.1481616668577546
Validation loss: 2.614375016220595

Epoch: 6| Step: 3
Training loss: 1.759205990629938
Validation loss: 2.5812411655277923

Epoch: 6| Step: 4
Training loss: 1.0643829042563437
Validation loss: 2.6443253948379906

Epoch: 6| Step: 5
Training loss: 0.9011207318024312
Validation loss: 2.578101942171195

Epoch: 6| Step: 6
Training loss: 0.9828171892160403
Validation loss: 2.6051559451109574

Epoch: 6| Step: 7
Training loss: 1.7872030264908207
Validation loss: 2.576312558967631

Epoch: 6| Step: 8
Training loss: 1.30716675342691
Validation loss: 2.5928977117551084

Epoch: 6| Step: 9
Training loss: 0.978806321142322
Validation loss: 2.619733644200647

Epoch: 6| Step: 10
Training loss: 1.1793518599447128
Validation loss: 2.556158297634144

Epoch: 6| Step: 11
Training loss: 1.1730063000450481
Validation loss: 2.618516438462033

Epoch: 6| Step: 12
Training loss: 1.3208907627332303
Validation loss: 2.632050763423301

Epoch: 6| Step: 13
Training loss: 0.8988131525615437
Validation loss: 2.6680810252182026

Epoch: 378| Step: 0
Training loss: 1.2212009726984352
Validation loss: 2.653587457965027

Epoch: 6| Step: 1
Training loss: 1.7103785468378854
Validation loss: 2.7021136881923047

Epoch: 6| Step: 2
Training loss: 1.3117943637994935
Validation loss: 2.659661312805778

Epoch: 6| Step: 3
Training loss: 1.0217732300083548
Validation loss: 2.6423052345903435

Epoch: 6| Step: 4
Training loss: 1.0651155143201698
Validation loss: 2.686068293959908

Epoch: 6| Step: 5
Training loss: 1.0982465683891927
Validation loss: 2.626555103274189

Epoch: 6| Step: 6
Training loss: 1.1282411087602064
Validation loss: 2.5903364645883755

Epoch: 6| Step: 7
Training loss: 1.2299518771178142
Validation loss: 2.6311049692471373

Epoch: 6| Step: 8
Training loss: 1.534287534501076
Validation loss: 2.5752362800264517

Epoch: 6| Step: 9
Training loss: 0.9644557775165086
Validation loss: 2.6087447298024413

Epoch: 6| Step: 10
Training loss: 1.2720182033591831
Validation loss: 2.57226818937127

Epoch: 6| Step: 11
Training loss: 1.6324794009721497
Validation loss: 2.5490797987976017

Epoch: 6| Step: 12
Training loss: 1.3197053495189561
Validation loss: 2.5700110168814625

Epoch: 6| Step: 13
Training loss: 1.0647232132977371
Validation loss: 2.55623959863314

Epoch: 379| Step: 0
Training loss: 1.4240246965431274
Validation loss: 2.5780767879409363

Epoch: 6| Step: 1
Training loss: 1.2805026130783665
Validation loss: 2.6184134880907717

Epoch: 6| Step: 2
Training loss: 1.0537913718648821
Validation loss: 2.6147007149618133

Epoch: 6| Step: 3
Training loss: 1.5971998388223927
Validation loss: 2.6037970827423815

Epoch: 6| Step: 4
Training loss: 1.0720102252686046
Validation loss: 2.7106007303598756

Epoch: 6| Step: 5
Training loss: 0.9490254837268438
Validation loss: 2.624699545120074

Epoch: 6| Step: 6
Training loss: 1.6411609319268579
Validation loss: 2.591926025300468

Epoch: 6| Step: 7
Training loss: 1.1180859667562741
Validation loss: 2.661709056374175

Epoch: 6| Step: 8
Training loss: 1.157282909196509
Validation loss: 2.5458262337826527

Epoch: 6| Step: 9
Training loss: 1.3315906858829498
Validation loss: 2.5920655936037953

Epoch: 6| Step: 10
Training loss: 1.131282009283091
Validation loss: 2.6308341361394927

Epoch: 6| Step: 11
Training loss: 1.3081378199445342
Validation loss: 2.5782239952732686

Epoch: 6| Step: 12
Training loss: 0.9414935249616474
Validation loss: 2.6171774792835216

Epoch: 6| Step: 13
Training loss: 0.8699333090816536
Validation loss: 2.6045604001259512

Epoch: 380| Step: 0
Training loss: 0.9786881772487281
Validation loss: 2.569506224041336

Epoch: 6| Step: 1
Training loss: 1.1657509048003551
Validation loss: 2.6086279738211826

Epoch: 6| Step: 2
Training loss: 0.939988964908839
Validation loss: 2.647361334176241

Epoch: 6| Step: 3
Training loss: 1.08097584065587
Validation loss: 2.611760858988797

Epoch: 6| Step: 4
Training loss: 1.6290043131265979
Validation loss: 2.60073870044148

Epoch: 6| Step: 5
Training loss: 0.8333265224814244
Validation loss: 2.637714956964365

Epoch: 6| Step: 6
Training loss: 1.055763261141315
Validation loss: 2.6369859046757025

Epoch: 6| Step: 7
Training loss: 1.3300379720444369
Validation loss: 2.628076241880455

Epoch: 6| Step: 8
Training loss: 1.1939491026044557
Validation loss: 2.5962967070735754

Epoch: 6| Step: 9
Training loss: 1.2051236284713291
Validation loss: 2.58176815137223

Epoch: 6| Step: 10
Training loss: 1.7364976283133293
Validation loss: 2.591181329583082

Epoch: 6| Step: 11
Training loss: 1.200245967134368
Validation loss: 2.579691447627164

Epoch: 6| Step: 12
Training loss: 1.5263802301456115
Validation loss: 2.537977853577196

Epoch: 6| Step: 13
Training loss: 1.418175884492283
Validation loss: 2.580495634525053

Epoch: 381| Step: 0
Training loss: 1.37075392812931
Validation loss: 2.5683682633742944

Epoch: 6| Step: 1
Training loss: 0.9353627320325864
Validation loss: 2.5548476111647065

Epoch: 6| Step: 2
Training loss: 0.9101997004930729
Validation loss: 2.531699231005091

Epoch: 6| Step: 3
Training loss: 1.1286862696909155
Validation loss: 2.5656244566804944

Epoch: 6| Step: 4
Training loss: 1.6485059100234005
Validation loss: 2.5506469005743435

Epoch: 6| Step: 5
Training loss: 1.0850721245626622
Validation loss: 2.5821297261767824

Epoch: 6| Step: 6
Training loss: 1.1445694744510237
Validation loss: 2.5593669082333586

Epoch: 6| Step: 7
Training loss: 1.253204054015537
Validation loss: 2.5655284137023466

Epoch: 6| Step: 8
Training loss: 1.3523886476465048
Validation loss: 2.5986663460673407

Epoch: 6| Step: 9
Training loss: 1.0739700306879125
Validation loss: 2.590686651339127

Epoch: 6| Step: 10
Training loss: 1.02986427607314
Validation loss: 2.6655959622291094

Epoch: 6| Step: 11
Training loss: 1.1169505368194936
Validation loss: 2.678953435390864

Epoch: 6| Step: 12
Training loss: 1.6058050763993408
Validation loss: 2.6738320335060535

Epoch: 6| Step: 13
Training loss: 1.2183068276656213
Validation loss: 2.7026912657285247

Epoch: 382| Step: 0
Training loss: 1.8153384115451854
Validation loss: 2.69645041803071

Epoch: 6| Step: 1
Training loss: 1.313649627742178
Validation loss: 2.617482638442675

Epoch: 6| Step: 2
Training loss: 0.9581882878432725
Validation loss: 2.651919181600135

Epoch: 6| Step: 3
Training loss: 1.114347195195521
Validation loss: 2.6223976466082024

Epoch: 6| Step: 4
Training loss: 1.3519806848873062
Validation loss: 2.6129217960252773

Epoch: 6| Step: 5
Training loss: 0.8602080728855849
Validation loss: 2.6261510595960362

Epoch: 6| Step: 6
Training loss: 0.6706444982945343
Validation loss: 2.5913140681618496

Epoch: 6| Step: 7
Training loss: 1.0893440878635665
Validation loss: 2.6280816019038027

Epoch: 6| Step: 8
Training loss: 1.3723421418064288
Validation loss: 2.635378680250697

Epoch: 6| Step: 9
Training loss: 0.9435372194834055
Validation loss: 2.6245673292315743

Epoch: 6| Step: 10
Training loss: 1.0352561470628576
Validation loss: 2.6075860932603256

Epoch: 6| Step: 11
Training loss: 1.5992235922542104
Validation loss: 2.6490607564498228

Epoch: 6| Step: 12
Training loss: 1.3479261487404237
Validation loss: 2.6382968352759937

Epoch: 6| Step: 13
Training loss: 1.0522020795427809
Validation loss: 2.5791522050820843

Epoch: 383| Step: 0
Training loss: 1.0005808573796229
Validation loss: 2.6565366403340986

Epoch: 6| Step: 1
Training loss: 1.1440610994081903
Validation loss: 2.5839256766282315

Epoch: 6| Step: 2
Training loss: 0.9579662193422952
Validation loss: 2.6048118071936965

Epoch: 6| Step: 3
Training loss: 1.8201249971538445
Validation loss: 2.5612466119359376

Epoch: 6| Step: 4
Training loss: 1.5498990641308001
Validation loss: 2.6468046362905993

Epoch: 6| Step: 5
Training loss: 1.027839570006498
Validation loss: 2.599581524599203

Epoch: 6| Step: 6
Training loss: 1.3190352000412096
Validation loss: 2.6330424584726138

Epoch: 6| Step: 7
Training loss: 0.9991973993974597
Validation loss: 2.5831961185151293

Epoch: 6| Step: 8
Training loss: 1.3267760663157575
Validation loss: 2.578407549547179

Epoch: 6| Step: 9
Training loss: 1.3621765732769993
Validation loss: 2.5902733079759783

Epoch: 6| Step: 10
Training loss: 1.0731463263674812
Validation loss: 2.6278072665573693

Epoch: 6| Step: 11
Training loss: 1.2509223396169755
Validation loss: 2.611035585720264

Epoch: 6| Step: 12
Training loss: 1.2632134149818712
Validation loss: 2.616425861730512

Epoch: 6| Step: 13
Training loss: 1.0935775620905275
Validation loss: 2.648707058222273

Epoch: 384| Step: 0
Training loss: 1.0195957908809876
Validation loss: 2.6083332045517507

Epoch: 6| Step: 1
Training loss: 1.3048267861214722
Validation loss: 2.6366141140744626

Epoch: 6| Step: 2
Training loss: 1.0313464032976363
Validation loss: 2.68625683087332

Epoch: 6| Step: 3
Training loss: 1.6310923883874777
Validation loss: 2.6723161597163005

Epoch: 6| Step: 4
Training loss: 1.437282877571396
Validation loss: 2.6699577576561495

Epoch: 6| Step: 5
Training loss: 0.9543172852078102
Validation loss: 2.668960513553072

Epoch: 6| Step: 6
Training loss: 1.3607125552967054
Validation loss: 2.625166789311607

Epoch: 6| Step: 7
Training loss: 1.0349341964074599
Validation loss: 2.6442539477277234

Epoch: 6| Step: 8
Training loss: 1.1155125259421126
Validation loss: 2.6398231899171685

Epoch: 6| Step: 9
Training loss: 1.1302320885102826
Validation loss: 2.5981526524345684

Epoch: 6| Step: 10
Training loss: 0.9738252960298641
Validation loss: 2.577930026918151

Epoch: 6| Step: 11
Training loss: 1.2989977274134068
Validation loss: 2.5895194593323145

Epoch: 6| Step: 12
Training loss: 1.2820745466640133
Validation loss: 2.6546062993680954

Epoch: 6| Step: 13
Training loss: 1.1703945727021068
Validation loss: 2.6027264363565092

Epoch: 385| Step: 0
Training loss: 1.242361572352727
Validation loss: 2.6204653430537705

Epoch: 6| Step: 1
Training loss: 1.7356280362600955
Validation loss: 2.667761791388246

Epoch: 6| Step: 2
Training loss: 1.2116752100192507
Validation loss: 2.6075363686482773

Epoch: 6| Step: 3
Training loss: 0.9652843627583106
Validation loss: 2.629671556949924

Epoch: 6| Step: 4
Training loss: 1.0187590148152477
Validation loss: 2.6462369796151504

Epoch: 6| Step: 5
Training loss: 0.9766285988372619
Validation loss: 2.6519554576825124

Epoch: 6| Step: 6
Training loss: 1.2489406865484987
Validation loss: 2.624705986935551

Epoch: 6| Step: 7
Training loss: 1.2581668615222705
Validation loss: 2.6395859790318053

Epoch: 6| Step: 8
Training loss: 1.0814909429501607
Validation loss: 2.655628400887071

Epoch: 6| Step: 9
Training loss: 0.875109767840647
Validation loss: 2.6516866192965143

Epoch: 6| Step: 10
Training loss: 1.2137074937065937
Validation loss: 2.660494827181839

Epoch: 6| Step: 11
Training loss: 0.991379476415686
Validation loss: 2.633183363575452

Epoch: 6| Step: 12
Training loss: 1.2340325955022764
Validation loss: 2.6628173573319867

Epoch: 6| Step: 13
Training loss: 1.755569247334576
Validation loss: 2.6489339567606174

Epoch: 386| Step: 0
Training loss: 1.2325068956843794
Validation loss: 2.644445045076653

Epoch: 6| Step: 1
Training loss: 0.892375430541837
Validation loss: 2.7000437320888078

Epoch: 6| Step: 2
Training loss: 1.149422203949103
Validation loss: 2.6880518028891225

Epoch: 6| Step: 3
Training loss: 0.924585205587377
Validation loss: 2.650096872346488

Epoch: 6| Step: 4
Training loss: 1.41668643189648
Validation loss: 2.703215874998456

Epoch: 6| Step: 5
Training loss: 1.2615879333517726
Validation loss: 2.7074421272186333

Epoch: 6| Step: 6
Training loss: 1.5038243655416847
Validation loss: 2.6623072952952893

Epoch: 6| Step: 7
Training loss: 0.8924960509781865
Validation loss: 2.5875220999641604

Epoch: 6| Step: 8
Training loss: 0.9615518110522332
Validation loss: 2.573908446098797

Epoch: 6| Step: 9
Training loss: 1.5524179580068518
Validation loss: 2.5389416788160695

Epoch: 6| Step: 10
Training loss: 1.3207736592496044
Validation loss: 2.5526421123352163

Epoch: 6| Step: 11
Training loss: 1.3340313792848908
Validation loss: 2.589849641773087

Epoch: 6| Step: 12
Training loss: 1.2111055319090802
Validation loss: 2.5801549760960913

Epoch: 6| Step: 13
Training loss: 0.9537985251145129
Validation loss: 2.65617223887595

Epoch: 387| Step: 0
Training loss: 0.8155477289889121
Validation loss: 2.636711832673218

Epoch: 6| Step: 1
Training loss: 1.679332748920803
Validation loss: 2.6910024634408702

Epoch: 6| Step: 2
Training loss: 1.436209472535979
Validation loss: 2.6529277594899465

Epoch: 6| Step: 3
Training loss: 0.7466235850953191
Validation loss: 2.6584185854675875

Epoch: 6| Step: 4
Training loss: 1.3668704727997918
Validation loss: 2.737234368057855

Epoch: 6| Step: 5
Training loss: 1.0228763818415678
Validation loss: 2.73675815453358

Epoch: 6| Step: 6
Training loss: 1.0396665953864141
Validation loss: 2.6623757878135246

Epoch: 6| Step: 7
Training loss: 1.4465705963323532
Validation loss: 2.6151307484098156

Epoch: 6| Step: 8
Training loss: 1.2019641775293142
Validation loss: 2.6458866134044827

Epoch: 6| Step: 9
Training loss: 1.0657893482007406
Validation loss: 2.6082451938528926

Epoch: 6| Step: 10
Training loss: 1.2494375870997387
Validation loss: 2.5988999527749215

Epoch: 6| Step: 11
Training loss: 1.5158140713455461
Validation loss: 2.507119690137641

Epoch: 6| Step: 12
Training loss: 1.093733542182261
Validation loss: 2.5891713170366994

Epoch: 6| Step: 13
Training loss: 0.8950389104515116
Validation loss: 2.571244431265397

Epoch: 388| Step: 0
Training loss: 1.0156695429497573
Validation loss: 2.5832413277598145

Epoch: 6| Step: 1
Training loss: 1.0079246281192054
Validation loss: 2.60779647136537

Epoch: 6| Step: 2
Training loss: 1.1221978469494847
Validation loss: 2.6049800568913684

Epoch: 6| Step: 3
Training loss: 1.1814006971681061
Validation loss: 2.5938959501942955

Epoch: 6| Step: 4
Training loss: 1.183366256354372
Validation loss: 2.6184039880441503

Epoch: 6| Step: 5
Training loss: 1.0889938486098902
Validation loss: 2.657526464991406

Epoch: 6| Step: 6
Training loss: 1.0497588107708435
Validation loss: 2.6497404556210493

Epoch: 6| Step: 7
Training loss: 1.4008041473576724
Validation loss: 2.610800195900292

Epoch: 6| Step: 8
Training loss: 1.0531217467487017
Validation loss: 2.6489883945172945

Epoch: 6| Step: 9
Training loss: 0.9380377816478871
Validation loss: 2.6673823876329488

Epoch: 6| Step: 10
Training loss: 0.8310627202902031
Validation loss: 2.6301816932663615

Epoch: 6| Step: 11
Training loss: 1.4661595652757613
Validation loss: 2.6297267409970684

Epoch: 6| Step: 12
Training loss: 1.6518519325680816
Validation loss: 2.619487863650274

Epoch: 6| Step: 13
Training loss: 0.9266682492100858
Validation loss: 2.606145325776319

Epoch: 389| Step: 0
Training loss: 0.7625446634813358
Validation loss: 2.6422458166254805

Epoch: 6| Step: 1
Training loss: 1.4515149620985388
Validation loss: 2.6158687932176328

Epoch: 6| Step: 2
Training loss: 0.9663123563950557
Validation loss: 2.6570001702237414

Epoch: 6| Step: 3
Training loss: 1.1131400035466013
Validation loss: 2.6276992059815925

Epoch: 6| Step: 4
Training loss: 0.9622485513574642
Validation loss: 2.6400329859194867

Epoch: 6| Step: 5
Training loss: 1.124817568504367
Validation loss: 2.5947517926922075

Epoch: 6| Step: 6
Training loss: 1.7163572822708135
Validation loss: 2.6367575861578576

Epoch: 6| Step: 7
Training loss: 1.1405348023586284
Validation loss: 2.593650846616024

Epoch: 6| Step: 8
Training loss: 0.9408437860976507
Validation loss: 2.573875099440874

Epoch: 6| Step: 9
Training loss: 1.0514263456036719
Validation loss: 2.592933526278296

Epoch: 6| Step: 10
Training loss: 1.0414818154669059
Validation loss: 2.698865691675502

Epoch: 6| Step: 11
Training loss: 0.8683454326243083
Validation loss: 2.684800573978393

Epoch: 6| Step: 12
Training loss: 1.0535268543226275
Validation loss: 2.6058298801496425

Epoch: 6| Step: 13
Training loss: 1.367207118302325
Validation loss: 2.5894208114908897

Epoch: 390| Step: 0
Training loss: 1.234750618099746
Validation loss: 2.6252677568993303

Epoch: 6| Step: 1
Training loss: 0.8963070363686256
Validation loss: 2.667521806536619

Epoch: 6| Step: 2
Training loss: 1.1721187083826141
Validation loss: 2.66415129930274

Epoch: 6| Step: 3
Training loss: 1.4348155124381936
Validation loss: 2.6747798930134667

Epoch: 6| Step: 4
Training loss: 0.9219793163697818
Validation loss: 2.662659321228361

Epoch: 6| Step: 5
Training loss: 0.8854255825416601
Validation loss: 2.702113585252515

Epoch: 6| Step: 6
Training loss: 0.9592298515933844
Validation loss: 2.656752355606405

Epoch: 6| Step: 7
Training loss: 1.1314593421755004
Validation loss: 2.654195806521992

Epoch: 6| Step: 8
Training loss: 1.4278512638112497
Validation loss: 2.7001162121334854

Epoch: 6| Step: 9
Training loss: 0.8938613448777037
Validation loss: 2.673195860075686

Epoch: 6| Step: 10
Training loss: 1.2136542577726441
Validation loss: 2.7051450204668495

Epoch: 6| Step: 11
Training loss: 1.001108627911347
Validation loss: 2.6467364164221063

Epoch: 6| Step: 12
Training loss: 0.9065076856271571
Validation loss: 2.6703874637385687

Epoch: 6| Step: 13
Training loss: 1.238160810419675
Validation loss: 2.6363860949493443

Epoch: 391| Step: 0
Training loss: 0.723973079686727
Validation loss: 2.598451199230693

Epoch: 6| Step: 1
Training loss: 1.4250876215715629
Validation loss: 2.66154732651801

Epoch: 6| Step: 2
Training loss: 1.1599852053751152
Validation loss: 2.5984268919238294

Epoch: 6| Step: 3
Training loss: 1.1025873381433091
Validation loss: 2.596831823327464

Epoch: 6| Step: 4
Training loss: 1.400216446902067
Validation loss: 2.6266953957587313

Epoch: 6| Step: 5
Training loss: 0.9380591314624991
Validation loss: 2.612269594901557

Epoch: 6| Step: 6
Training loss: 0.8024711084364241
Validation loss: 2.570908366261924

Epoch: 6| Step: 7
Training loss: 1.1630255157381
Validation loss: 2.5606171273167977

Epoch: 6| Step: 8
Training loss: 1.0656105398500266
Validation loss: 2.6010607750164905

Epoch: 6| Step: 9
Training loss: 0.8568953720219767
Validation loss: 2.6308947482677465

Epoch: 6| Step: 10
Training loss: 1.4963408980648212
Validation loss: 2.698476671892829

Epoch: 6| Step: 11
Training loss: 1.202557219256251
Validation loss: 2.6225935789757866

Epoch: 6| Step: 12
Training loss: 0.8415269529567326
Validation loss: 2.6779939955515135

Epoch: 6| Step: 13
Training loss: 1.1512224852248873
Validation loss: 2.6225607604535903

Epoch: 392| Step: 0
Training loss: 0.9573251701084863
Validation loss: 2.672793403413654

Epoch: 6| Step: 1
Training loss: 1.0838518491271412
Validation loss: 2.7356593866636807

Epoch: 6| Step: 2
Training loss: 0.9616390551620043
Validation loss: 2.6563814467275195

Epoch: 6| Step: 3
Training loss: 1.294709431294234
Validation loss: 2.657999696592338

Epoch: 6| Step: 4
Training loss: 1.153465320021186
Validation loss: 2.66919621557132

Epoch: 6| Step: 5
Training loss: 0.9506832802668653
Validation loss: 2.6718530486694214

Epoch: 6| Step: 6
Training loss: 0.8818891304338546
Validation loss: 2.7011362304689412

Epoch: 6| Step: 7
Training loss: 1.6658778787712412
Validation loss: 2.6494087681317278

Epoch: 6| Step: 8
Training loss: 1.009293348003703
Validation loss: 2.659903209450223

Epoch: 6| Step: 9
Training loss: 0.92980077999047
Validation loss: 2.6911770114430142

Epoch: 6| Step: 10
Training loss: 0.8815085309157306
Validation loss: 2.6595618003448838

Epoch: 6| Step: 11
Training loss: 0.9039430523422073
Validation loss: 2.6239954903518297

Epoch: 6| Step: 12
Training loss: 0.780965944148429
Validation loss: 2.6124997341271468

Epoch: 6| Step: 13
Training loss: 1.5341778226436789
Validation loss: 2.617590103687483

Epoch: 393| Step: 0
Training loss: 1.0190534385505223
Validation loss: 2.6343358553945495

Epoch: 6| Step: 1
Training loss: 1.0783798911604012
Validation loss: 2.6036192560235274

Epoch: 6| Step: 2
Training loss: 1.0748434019247612
Validation loss: 2.586558932866154

Epoch: 6| Step: 3
Training loss: 0.7173572813040354
Validation loss: 2.5786833341570055

Epoch: 6| Step: 4
Training loss: 1.0230571243803952
Validation loss: 2.5608932761283434

Epoch: 6| Step: 5
Training loss: 1.1744628814898999
Validation loss: 2.6012949763034285

Epoch: 6| Step: 6
Training loss: 1.2149396656110683
Validation loss: 2.5789226800718197

Epoch: 6| Step: 7
Training loss: 1.4874903862906983
Validation loss: 2.638117154249888

Epoch: 6| Step: 8
Training loss: 1.0901633720280126
Validation loss: 2.600027034081005

Epoch: 6| Step: 9
Training loss: 0.8210652485264488
Validation loss: 2.697615188093162

Epoch: 6| Step: 10
Training loss: 1.0920528869188335
Validation loss: 2.687896521835833

Epoch: 6| Step: 11
Training loss: 0.8306009957064845
Validation loss: 2.6370178806497724

Epoch: 6| Step: 12
Training loss: 1.7043191765378123
Validation loss: 2.6338460008734637

Epoch: 6| Step: 13
Training loss: 0.9121520136601807
Validation loss: 2.5978119538186273

Epoch: 394| Step: 0
Training loss: 1.122364347625494
Validation loss: 2.5676235058579895

Epoch: 6| Step: 1
Training loss: 1.3815148078160755
Validation loss: 2.670460540376153

Epoch: 6| Step: 2
Training loss: 0.9701103687910752
Validation loss: 2.635993778733711

Epoch: 6| Step: 3
Training loss: 0.9732695947531932
Validation loss: 2.6784970055186523

Epoch: 6| Step: 4
Training loss: 0.6934620955765382
Validation loss: 2.6607034188643293

Epoch: 6| Step: 5
Training loss: 0.809907665759103
Validation loss: 2.7171328620469897

Epoch: 6| Step: 6
Training loss: 1.1685215589063154
Validation loss: 2.687193032409956

Epoch: 6| Step: 7
Training loss: 1.0010103247926525
Validation loss: 2.6903776169553733

Epoch: 6| Step: 8
Training loss: 0.8375079652777557
Validation loss: 2.7101193383464173

Epoch: 6| Step: 9
Training loss: 1.400819337734465
Validation loss: 2.67861168028848

Epoch: 6| Step: 10
Training loss: 1.228084130614208
Validation loss: 2.6852432948678318

Epoch: 6| Step: 11
Training loss: 1.7150783508687089
Validation loss: 2.710159805836548

Epoch: 6| Step: 12
Training loss: 0.7451856989129693
Validation loss: 2.6824701391799617

Epoch: 6| Step: 13
Training loss: 0.7103100617447041
Validation loss: 2.6437068614040458

Epoch: 395| Step: 0
Training loss: 1.0965202127273148
Validation loss: 2.6496531229495646

Epoch: 6| Step: 1
Training loss: 1.3788924608270565
Validation loss: 2.6447925372809027

Epoch: 6| Step: 2
Training loss: 0.8760244639216191
Validation loss: 2.6600578988258494

Epoch: 6| Step: 3
Training loss: 0.5372389758413717
Validation loss: 2.693352927720521

Epoch: 6| Step: 4
Training loss: 1.182999212930632
Validation loss: 2.672864243748271

Epoch: 6| Step: 5
Training loss: 1.2129268425833808
Validation loss: 2.705587819690572

Epoch: 6| Step: 6
Training loss: 1.2767895537479685
Validation loss: 2.7278354154619127

Epoch: 6| Step: 7
Training loss: 0.954752642317974
Validation loss: 2.6785779904481957

Epoch: 6| Step: 8
Training loss: 1.2151264217522613
Validation loss: 2.6495450385031236

Epoch: 6| Step: 9
Training loss: 0.7340551450839167
Validation loss: 2.6601793136007656

Epoch: 6| Step: 10
Training loss: 1.0333152666871095
Validation loss: 2.612563387696509

Epoch: 6| Step: 11
Training loss: 0.8674313314122197
Validation loss: 2.6263127147867262

Epoch: 6| Step: 12
Training loss: 0.9258398689350651
Validation loss: 2.6042939472882947

Epoch: 6| Step: 13
Training loss: 1.4830775965571281
Validation loss: 2.6134317199845034

Epoch: 396| Step: 0
Training loss: 1.1165974799590839
Validation loss: 2.587718999197946

Epoch: 6| Step: 1
Training loss: 0.7968512138855803
Validation loss: 2.659843064150673

Epoch: 6| Step: 2
Training loss: 1.2065163906231382
Validation loss: 2.6375806365259113

Epoch: 6| Step: 3
Training loss: 1.2615962485731151
Validation loss: 2.6152749052508595

Epoch: 6| Step: 4
Training loss: 0.8694104408044413
Validation loss: 2.6892703974714682

Epoch: 6| Step: 5
Training loss: 0.9531648033460945
Validation loss: 2.6619184560364206

Epoch: 6| Step: 6
Training loss: 0.774470554518559
Validation loss: 2.6929062869555462

Epoch: 6| Step: 7
Training loss: 0.9592629084510186
Validation loss: 2.69839011399028

Epoch: 6| Step: 8
Training loss: 0.9586083632570147
Validation loss: 2.7401814309495776

Epoch: 6| Step: 9
Training loss: 0.8787255673654314
Validation loss: 2.715279479702424

Epoch: 6| Step: 10
Training loss: 1.4292381706181971
Validation loss: 2.729494050945995

Epoch: 6| Step: 11
Training loss: 1.0972134385917605
Validation loss: 2.6916739852459344

Epoch: 6| Step: 12
Training loss: 1.3154397013962056
Validation loss: 2.6564440188888443

Epoch: 6| Step: 13
Training loss: 1.247449083990135
Validation loss: 2.600645688466734

Epoch: 397| Step: 0
Training loss: 1.0137179737229796
Validation loss: 2.634572468118396

Epoch: 6| Step: 1
Training loss: 0.633057252623957
Validation loss: 2.5601022714064423

Epoch: 6| Step: 2
Training loss: 0.893732839032791
Validation loss: 2.58098623084182

Epoch: 6| Step: 3
Training loss: 1.2301241922095822
Validation loss: 2.648911365288154

Epoch: 6| Step: 4
Training loss: 1.2948376382209617
Validation loss: 2.568198883882772

Epoch: 6| Step: 5
Training loss: 1.1633662247220764
Validation loss: 2.6068290427025715

Epoch: 6| Step: 6
Training loss: 0.6993422159482987
Validation loss: 2.609219087674967

Epoch: 6| Step: 7
Training loss: 0.9896171195971757
Validation loss: 2.640313861882843

Epoch: 6| Step: 8
Training loss: 1.4945983584502813
Validation loss: 2.618883317999817

Epoch: 6| Step: 9
Training loss: 0.9629693608465428
Validation loss: 2.643340691279224

Epoch: 6| Step: 10
Training loss: 0.8617702741946572
Validation loss: 2.6097738300025686

Epoch: 6| Step: 11
Training loss: 1.3566803807464451
Validation loss: 2.6920762688345756

Epoch: 6| Step: 12
Training loss: 1.047670773626667
Validation loss: 2.6906668021410307

Epoch: 6| Step: 13
Training loss: 1.1962076463047722
Validation loss: 2.6710435640749703

Epoch: 398| Step: 0
Training loss: 1.4991761170210094
Validation loss: 2.6640937333499477

Epoch: 6| Step: 1
Training loss: 1.0672084599638594
Validation loss: 2.6544902582296994

Epoch: 6| Step: 2
Training loss: 0.9248941412485372
Validation loss: 2.6496140708846108

Epoch: 6| Step: 3
Training loss: 1.209541549845735
Validation loss: 2.6765600254561814

Epoch: 6| Step: 4
Training loss: 0.613379938239833
Validation loss: 2.6277664986337657

Epoch: 6| Step: 5
Training loss: 0.9142097941344455
Validation loss: 2.658698774548827

Epoch: 6| Step: 6
Training loss: 0.9483764427679895
Validation loss: 2.6113958547325877

Epoch: 6| Step: 7
Training loss: 0.727554710271113
Validation loss: 2.600339332774951

Epoch: 6| Step: 8
Training loss: 0.7660106544002663
Validation loss: 2.627526490368014

Epoch: 6| Step: 9
Training loss: 1.0464025541630175
Validation loss: 2.632891018957838

Epoch: 6| Step: 10
Training loss: 1.3779314610221798
Validation loss: 2.582981313799076

Epoch: 6| Step: 11
Training loss: 1.1098541514486455
Validation loss: 2.6005391961754643

Epoch: 6| Step: 12
Training loss: 1.1963653913787045
Validation loss: 2.6351878603394474

Epoch: 6| Step: 13
Training loss: 1.3517679929246573
Validation loss: 2.656696326960939

Epoch: 399| Step: 0
Training loss: 0.8919417368481027
Validation loss: 2.631650304056927

Epoch: 6| Step: 1
Training loss: 0.903020233624646
Validation loss: 2.6424714353780514

Epoch: 6| Step: 2
Training loss: 1.1046784072782336
Validation loss: 2.6641679670203215

Epoch: 6| Step: 3
Training loss: 1.0058459234727068
Validation loss: 2.7608006528176547

Epoch: 6| Step: 4
Training loss: 1.7066166633989648
Validation loss: 2.759745755026222

Epoch: 6| Step: 5
Training loss: 1.003139930685285
Validation loss: 2.6880607020074905

Epoch: 6| Step: 6
Training loss: 1.5939944210744603
Validation loss: 2.783319010859509

Epoch: 6| Step: 7
Training loss: 0.9956936500191289
Validation loss: 2.719663320430463

Epoch: 6| Step: 8
Training loss: 0.7134945336435203
Validation loss: 2.7348435209423454

Epoch: 6| Step: 9
Training loss: 1.32797258287876
Validation loss: 2.7236251675934002

Epoch: 6| Step: 10
Training loss: 0.9970045226806632
Validation loss: 2.736116279934962

Epoch: 6| Step: 11
Training loss: 0.9934346328410785
Validation loss: 2.7068185874118127

Epoch: 6| Step: 12
Training loss: 1.0717563218681547
Validation loss: 2.703320696440989

Epoch: 6| Step: 13
Training loss: 1.2384005227393395
Validation loss: 2.681968792985302

Epoch: 400| Step: 0
Training loss: 0.9753046097905321
Validation loss: 2.7012086223567677

Epoch: 6| Step: 1
Training loss: 0.971628895107772
Validation loss: 2.657982100678839

Epoch: 6| Step: 2
Training loss: 0.9507722112873278
Validation loss: 2.636722592951482

Epoch: 6| Step: 3
Training loss: 0.9485624579827814
Validation loss: 2.6908535549017922

Epoch: 6| Step: 4
Training loss: 1.2143739730351573
Validation loss: 2.7164652201692028

Epoch: 6| Step: 5
Training loss: 0.8499635506276003
Validation loss: 2.6206253626251756

Epoch: 6| Step: 6
Training loss: 0.9098784387007052
Validation loss: 2.684268427943751

Epoch: 6| Step: 7
Training loss: 1.4706560307190488
Validation loss: 2.6594621048620652

Epoch: 6| Step: 8
Training loss: 1.3023054569246346
Validation loss: 2.6640122931886965

Epoch: 6| Step: 9
Training loss: 0.7299899403649736
Validation loss: 2.69598990510924

Epoch: 6| Step: 10
Training loss: 0.9169240972977156
Validation loss: 2.7153471774972058

Epoch: 6| Step: 11
Training loss: 1.02333609974101
Validation loss: 2.6605034077443355

Epoch: 6| Step: 12
Training loss: 1.1450772073693511
Validation loss: 2.679844813645897

Epoch: 6| Step: 13
Training loss: 1.3787720266400125
Validation loss: 2.693371384307813

Testing loss: 2.297573283844294
