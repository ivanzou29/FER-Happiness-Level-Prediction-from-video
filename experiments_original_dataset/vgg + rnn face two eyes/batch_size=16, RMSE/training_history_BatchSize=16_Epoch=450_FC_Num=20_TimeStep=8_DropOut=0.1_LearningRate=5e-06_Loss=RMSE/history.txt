Epoch: 1| Step: 0
Training loss: 6.033606192528929
Validation loss: 5.938325496643074

Epoch: 6| Step: 1
Training loss: 6.625743320438835
Validation loss: 5.936020864323213

Epoch: 6| Step: 2
Training loss: 5.241638063838932
Validation loss: 5.933766419252916

Epoch: 6| Step: 3
Training loss: 5.6218415611846
Validation loss: 5.931632693304981

Epoch: 6| Step: 4
Training loss: 5.737498750042415
Validation loss: 5.929478095054938

Epoch: 6| Step: 5
Training loss: 5.055076902504489
Validation loss: 5.9273451851747145

Epoch: 6| Step: 6
Training loss: 6.481222760723558
Validation loss: 5.9252882274372425

Epoch: 6| Step: 7
Training loss: 6.6490278867199
Validation loss: 5.923058196192864

Epoch: 6| Step: 8
Training loss: 5.750248115825498
Validation loss: 5.921054001449218

Epoch: 6| Step: 9
Training loss: 6.687715045644385
Validation loss: 5.919074235821292

Epoch: 6| Step: 10
Training loss: 6.294875516137859
Validation loss: 5.916957346621649

Epoch: 6| Step: 11
Training loss: 5.302864042210671
Validation loss: 5.914939529784862

Epoch: 6| Step: 12
Training loss: 6.371603865231241
Validation loss: 5.912923685583609

Epoch: 6| Step: 13
Training loss: 6.370469521745648
Validation loss: 5.910712814934549

Epoch: 2| Step: 0
Training loss: 5.995349989498697
Validation loss: 5.9084016086667

Epoch: 6| Step: 1
Training loss: 5.591693692016482
Validation loss: 5.906053731573801

Epoch: 6| Step: 2
Training loss: 5.594415720958814
Validation loss: 5.90356168839828

Epoch: 6| Step: 3
Training loss: 6.795411121093962
Validation loss: 5.901087016385645

Epoch: 6| Step: 4
Training loss: 5.6586271738752965
Validation loss: 5.898419553211522

Epoch: 6| Step: 5
Training loss: 7.286284576663809
Validation loss: 5.89561276871368

Epoch: 6| Step: 6
Training loss: 6.342562559644016
Validation loss: 5.892613757393163

Epoch: 6| Step: 7
Training loss: 5.912593281112893
Validation loss: 5.889569607064123

Epoch: 6| Step: 8
Training loss: 6.146785994148595
Validation loss: 5.886353958798549

Epoch: 6| Step: 9
Training loss: 5.434652174669834
Validation loss: 5.882937973325747

Epoch: 6| Step: 10
Training loss: 4.808486652188747
Validation loss: 5.879144491815777

Epoch: 6| Step: 11
Training loss: 6.022802890937569
Validation loss: 5.8755584343175205

Epoch: 6| Step: 12
Training loss: 5.562502057364437
Validation loss: 5.8718446144399215

Epoch: 6| Step: 13
Training loss: 6.513884460548932
Validation loss: 5.867947992646934

Epoch: 3| Step: 0
Training loss: 6.8111946185194014
Validation loss: 5.863690657853788

Epoch: 6| Step: 1
Training loss: 6.702295496551589
Validation loss: 5.859127653199407

Epoch: 6| Step: 2
Training loss: 5.080220796487536
Validation loss: 5.854596901647286

Epoch: 6| Step: 3
Training loss: 5.163719546750687
Validation loss: 5.849657605141669

Epoch: 6| Step: 4
Training loss: 6.027962693026196
Validation loss: 5.844708151643587

Epoch: 6| Step: 5
Training loss: 5.5948746046207924
Validation loss: 5.839576087354705

Epoch: 6| Step: 6
Training loss: 5.115971870756626
Validation loss: 5.834315035729291

Epoch: 6| Step: 7
Training loss: 5.035078972932984
Validation loss: 5.828973376014522

Epoch: 6| Step: 8
Training loss: 5.7688551540854585
Validation loss: 5.823112643725109

Epoch: 6| Step: 9
Training loss: 6.2902852072287825
Validation loss: 5.817231716848989

Epoch: 6| Step: 10
Training loss: 6.794307109657452
Validation loss: 5.811293856265961

Epoch: 6| Step: 11
Training loss: 6.272438359297874
Validation loss: 5.804832460108842

Epoch: 6| Step: 12
Training loss: 5.734206028249601
Validation loss: 5.798264137389539

Epoch: 6| Step: 13
Training loss: 6.380207403273742
Validation loss: 5.791556908461678

Epoch: 4| Step: 0
Training loss: 6.541382445298111
Validation loss: 5.784653165460276

Epoch: 6| Step: 1
Training loss: 5.549128888474157
Validation loss: 5.7775190806957575

Epoch: 6| Step: 2
Training loss: 5.425518647465341
Validation loss: 5.7700673041338275

Epoch: 6| Step: 3
Training loss: 6.500478873585968
Validation loss: 5.762760791407638

Epoch: 6| Step: 4
Training loss: 6.049725159006128
Validation loss: 5.755606557840204

Epoch: 6| Step: 5
Training loss: 6.245973434386862
Validation loss: 5.74766647976073

Epoch: 6| Step: 6
Training loss: 6.125785310187087
Validation loss: 5.740070892321536

Epoch: 6| Step: 7
Training loss: 5.789145526985584
Validation loss: 5.73227785656325

Epoch: 6| Step: 8
Training loss: 5.938295973578971
Validation loss: 5.724500950324785

Epoch: 6| Step: 9
Training loss: 5.493282029983305
Validation loss: 5.716996665898013

Epoch: 6| Step: 10
Training loss: 5.3951941544859725
Validation loss: 5.709271105659843

Epoch: 6| Step: 11
Training loss: 5.775048140948561
Validation loss: 5.7014001476296965

Epoch: 6| Step: 12
Training loss: 5.5676232222310595
Validation loss: 5.693715231294133

Epoch: 6| Step: 13
Training loss: 5.384468432925926
Validation loss: 5.68606831622961

Epoch: 5| Step: 0
Training loss: 5.888028571826608
Validation loss: 5.678252250884464

Epoch: 6| Step: 1
Training loss: 5.175781987028249
Validation loss: 5.670319763442436

Epoch: 6| Step: 2
Training loss: 6.391652218215043
Validation loss: 5.66232559407089

Epoch: 6| Step: 3
Training loss: 5.636613174686967
Validation loss: 5.65407102987002

Epoch: 6| Step: 4
Training loss: 6.033303341167504
Validation loss: 5.645657450996808

Epoch: 6| Step: 5
Training loss: 5.785492531161457
Validation loss: 5.636887767898678

Epoch: 6| Step: 6
Training loss: 5.695410959154075
Validation loss: 5.628417411012794

Epoch: 6| Step: 7
Training loss: 5.309158530938837
Validation loss: 5.619670320979678

Epoch: 6| Step: 8
Training loss: 5.912134861710013
Validation loss: 5.61110972833564

Epoch: 6| Step: 9
Training loss: 6.139936646373835
Validation loss: 5.6027397504146546

Epoch: 6| Step: 10
Training loss: 5.191244221864824
Validation loss: 5.593898920389138

Epoch: 6| Step: 11
Training loss: 5.792378041148733
Validation loss: 5.585747989027417

Epoch: 6| Step: 12
Training loss: 5.134875946775105
Validation loss: 5.577683603184924

Epoch: 6| Step: 13
Training loss: 6.122591440398822
Validation loss: 5.56923245253526

Epoch: 6| Step: 0
Training loss: 6.22858146376695
Validation loss: 5.561191161971894

Epoch: 6| Step: 1
Training loss: 4.8820684980051094
Validation loss: 5.553261875747651

Epoch: 6| Step: 2
Training loss: 5.12388077586923
Validation loss: 5.545567088778292

Epoch: 6| Step: 3
Training loss: 5.688493914270746
Validation loss: 5.537741061805491

Epoch: 6| Step: 4
Training loss: 4.248340731574813
Validation loss: 5.530463987203725

Epoch: 6| Step: 5
Training loss: 6.053214916689868
Validation loss: 5.523509124478517

Epoch: 6| Step: 6
Training loss: 6.015806992985685
Validation loss: 5.516239495848367

Epoch: 6| Step: 7
Training loss: 6.212528970140419
Validation loss: 5.509113650471022

Epoch: 6| Step: 8
Training loss: 5.858230356945608
Validation loss: 5.501970053906183

Epoch: 6| Step: 9
Training loss: 5.332197942678267
Validation loss: 5.495139372854111

Epoch: 6| Step: 10
Training loss: 6.246658652730312
Validation loss: 5.488552346553705

Epoch: 6| Step: 11
Training loss: 5.3208928848952874
Validation loss: 5.4817661844144725

Epoch: 6| Step: 12
Training loss: 6.2420322747439645
Validation loss: 5.475325085004422

Epoch: 6| Step: 13
Training loss: 4.963254372553839
Validation loss: 5.469186354894316

Epoch: 7| Step: 0
Training loss: 5.690066251184699
Validation loss: 5.462947390091725

Epoch: 6| Step: 1
Training loss: 5.952677392026627
Validation loss: 5.456895371904665

Epoch: 6| Step: 2
Training loss: 5.059049395803975
Validation loss: 5.451341047569758

Epoch: 6| Step: 3
Training loss: 5.698630372515715
Validation loss: 5.444989217158425

Epoch: 6| Step: 4
Training loss: 4.450468643028296
Validation loss: 5.439181334612772

Epoch: 6| Step: 5
Training loss: 5.258128095793915
Validation loss: 5.433059838009285

Epoch: 6| Step: 6
Training loss: 5.49041502393123
Validation loss: 5.42671944343403

Epoch: 6| Step: 7
Training loss: 5.752871915688747
Validation loss: 5.42106119547333

Epoch: 6| Step: 8
Training loss: 6.2746906097858846
Validation loss: 5.414979036008221

Epoch: 6| Step: 9
Training loss: 4.893394003205287
Validation loss: 5.409286498887136

Epoch: 6| Step: 10
Training loss: 5.813100476165546
Validation loss: 5.403759656572917

Epoch: 6| Step: 11
Training loss: 5.900228023971894
Validation loss: 5.398032409220161

Epoch: 6| Step: 12
Training loss: 5.869758377951118
Validation loss: 5.39204914243813

Epoch: 6| Step: 13
Training loss: 5.257787469177973
Validation loss: 5.386623441661226

Epoch: 8| Step: 0
Training loss: 5.876370858493593
Validation loss: 5.3811222369910245

Epoch: 6| Step: 1
Training loss: 6.061240153809155
Validation loss: 5.375911960565904

Epoch: 6| Step: 2
Training loss: 5.866177041400531
Validation loss: 5.370868455265448

Epoch: 6| Step: 3
Training loss: 6.045563942577157
Validation loss: 5.365487189829119

Epoch: 6| Step: 4
Training loss: 4.843835054696782
Validation loss: 5.360627438606679

Epoch: 6| Step: 5
Training loss: 4.524535788650942
Validation loss: 5.355515078940823

Epoch: 6| Step: 6
Training loss: 5.107353347114362
Validation loss: 5.3510171060095635

Epoch: 6| Step: 7
Training loss: 5.469861075748477
Validation loss: 5.345375007294398

Epoch: 6| Step: 8
Training loss: 5.2725183660803205
Validation loss: 5.340559276386965

Epoch: 6| Step: 9
Training loss: 5.672492379880707
Validation loss: 5.335167162253707

Epoch: 6| Step: 10
Training loss: 4.676535230889111
Validation loss: 5.330047469413797

Epoch: 6| Step: 11
Training loss: 4.7006565852829185
Validation loss: 5.325119692393004

Epoch: 6| Step: 12
Training loss: 5.954147931819811
Validation loss: 5.320041853135381

Epoch: 6| Step: 13
Training loss: 6.124786996057113
Validation loss: 5.315018060844313

Epoch: 9| Step: 0
Training loss: 4.85628732792121
Validation loss: 5.310376629304964

Epoch: 6| Step: 1
Training loss: 5.129135696148227
Validation loss: 5.30551466113314

Epoch: 6| Step: 2
Training loss: 6.585197796352805
Validation loss: 5.300256690520998

Epoch: 6| Step: 3
Training loss: 4.52087814847939
Validation loss: 5.29536877186985

Epoch: 6| Step: 4
Training loss: 5.846594786135064
Validation loss: 5.290114868589904

Epoch: 6| Step: 5
Training loss: 5.801280360472227
Validation loss: 5.2851382356511944

Epoch: 6| Step: 6
Training loss: 5.971330174895472
Validation loss: 5.27974545568467

Epoch: 6| Step: 7
Training loss: 5.39566962780542
Validation loss: 5.274131446672966

Epoch: 6| Step: 8
Training loss: 4.6586690673676365
Validation loss: 5.2691249365569135

Epoch: 6| Step: 9
Training loss: 6.011468734648484
Validation loss: 5.264034857469302

Epoch: 6| Step: 10
Training loss: 5.72525471616254
Validation loss: 5.2585722859413595

Epoch: 6| Step: 11
Training loss: 5.394453994230929
Validation loss: 5.253286876828059

Epoch: 6| Step: 12
Training loss: 4.785934646510944
Validation loss: 5.247443257788824

Epoch: 6| Step: 13
Training loss: 4.405641337892195
Validation loss: 5.242149417320067

Epoch: 10| Step: 0
Training loss: 5.505972653699004
Validation loss: 5.236759109717151

Epoch: 6| Step: 1
Training loss: 5.757071086296901
Validation loss: 5.2311088430546855

Epoch: 6| Step: 2
Training loss: 4.928082720297591
Validation loss: 5.225252984354789

Epoch: 6| Step: 3
Training loss: 4.728996822763474
Validation loss: 5.219682317057954

Epoch: 6| Step: 4
Training loss: 5.111293794066976
Validation loss: 5.21381655135749

Epoch: 6| Step: 5
Training loss: 4.906120541559344
Validation loss: 5.2080242014379765

Epoch: 6| Step: 6
Training loss: 5.058214422312467
Validation loss: 5.2022363402149585

Epoch: 6| Step: 7
Training loss: 5.988628419690196
Validation loss: 5.196880637399228

Epoch: 6| Step: 8
Training loss: 5.072226893262789
Validation loss: 5.191199519335032

Epoch: 6| Step: 9
Training loss: 6.4222833730975495
Validation loss: 5.184978592379944

Epoch: 6| Step: 10
Training loss: 5.294860096524975
Validation loss: 5.17885957739928

Epoch: 6| Step: 11
Training loss: 5.1474441704633485
Validation loss: 5.172491645738638

Epoch: 6| Step: 12
Training loss: 5.607998394801282
Validation loss: 5.165944489900915

Epoch: 6| Step: 13
Training loss: 4.676166107477544
Validation loss: 5.160360866959017

Epoch: 11| Step: 0
Training loss: 5.138552355128484
Validation loss: 5.15400372522348

Epoch: 6| Step: 1
Training loss: 4.6831425058894744
Validation loss: 5.147910384891289

Epoch: 6| Step: 2
Training loss: 5.161114242072787
Validation loss: 5.142208083637143

Epoch: 6| Step: 3
Training loss: 5.526509985702578
Validation loss: 5.135393628835427

Epoch: 6| Step: 4
Training loss: 5.604441393768128
Validation loss: 5.129142761587944

Epoch: 6| Step: 5
Training loss: 5.24242799664896
Validation loss: 5.123266593748257

Epoch: 6| Step: 6
Training loss: 4.60107046194165
Validation loss: 5.117784522563734

Epoch: 6| Step: 7
Training loss: 5.298510633687804
Validation loss: 5.111649064534447

Epoch: 6| Step: 8
Training loss: 5.044491987709218
Validation loss: 5.105766414184914

Epoch: 6| Step: 9
Training loss: 4.89374693654867
Validation loss: 5.099873768110663

Epoch: 6| Step: 10
Training loss: 5.9305002813967125
Validation loss: 5.09386567216526

Epoch: 6| Step: 11
Training loss: 5.21078413204308
Validation loss: 5.0881352283453225

Epoch: 6| Step: 12
Training loss: 5.314092958268251
Validation loss: 5.082460901823331

Epoch: 6| Step: 13
Training loss: 5.514974669245271
Validation loss: 5.076896730212337

Epoch: 12| Step: 0
Training loss: 5.892512416251967
Validation loss: 5.0715314578359685

Epoch: 6| Step: 1
Training loss: 5.066739791208584
Validation loss: 5.0649844694009305

Epoch: 6| Step: 2
Training loss: 4.860871014190931
Validation loss: 5.058818938792034

Epoch: 6| Step: 3
Training loss: 5.232504986042065
Validation loss: 5.0526590969600935

Epoch: 6| Step: 4
Training loss: 4.579875728470416
Validation loss: 5.04764243197187

Epoch: 6| Step: 5
Training loss: 5.383002954665409
Validation loss: 5.041615488512466

Epoch: 6| Step: 6
Training loss: 4.997965207910357
Validation loss: 5.036382201867584

Epoch: 6| Step: 7
Training loss: 5.553100187453359
Validation loss: 5.02985566525578

Epoch: 6| Step: 8
Training loss: 4.4832068859169985
Validation loss: 5.024189799264961

Epoch: 6| Step: 9
Training loss: 5.696016077190384
Validation loss: 5.0184260991058425

Epoch: 6| Step: 10
Training loss: 5.340970035699621
Validation loss: 5.012532010376556

Epoch: 6| Step: 11
Training loss: 4.783736237007002
Validation loss: 5.007032884206756

Epoch: 6| Step: 12
Training loss: 5.279057154715132
Validation loss: 4.999652723332145

Epoch: 6| Step: 13
Training loss: 4.843840567449665
Validation loss: 4.994699338736517

Epoch: 13| Step: 0
Training loss: 5.4197749487405025
Validation loss: 4.988488551736128

Epoch: 6| Step: 1
Training loss: 5.045718033867422
Validation loss: 4.982882125653541

Epoch: 6| Step: 2
Training loss: 4.678111121310617
Validation loss: 4.97820947403406

Epoch: 6| Step: 3
Training loss: 4.086342669323366
Validation loss: 4.973607438044769

Epoch: 6| Step: 4
Training loss: 4.521586459430741
Validation loss: 4.967572310570452

Epoch: 6| Step: 5
Training loss: 4.311307659344263
Validation loss: 4.961186792713168

Epoch: 6| Step: 6
Training loss: 4.939536531769114
Validation loss: 4.955750019499352

Epoch: 6| Step: 7
Training loss: 5.7558017154390555
Validation loss: 4.951532952399152

Epoch: 6| Step: 8
Training loss: 4.127772930878888
Validation loss: 4.946482539558808

Epoch: 6| Step: 9
Training loss: 5.568732210038837
Validation loss: 4.940542547160045

Epoch: 6| Step: 10
Training loss: 5.215002667580907
Validation loss: 4.936187054511372

Epoch: 6| Step: 11
Training loss: 6.07671836129341
Validation loss: 4.929596897588404

Epoch: 6| Step: 12
Training loss: 5.467995553428556
Validation loss: 4.923873640891866

Epoch: 6| Step: 13
Training loss: 5.367584080599454
Validation loss: 4.91898560660528

Epoch: 14| Step: 0
Training loss: 5.293607801308777
Validation loss: 4.913795904661451

Epoch: 6| Step: 1
Training loss: 5.3491658211060775
Validation loss: 4.907735806132789

Epoch: 6| Step: 2
Training loss: 4.359497724877031
Validation loss: 4.902764671867703

Epoch: 6| Step: 3
Training loss: 5.1633688133273425
Validation loss: 4.8976741603633975

Epoch: 6| Step: 4
Training loss: 4.906502103706545
Validation loss: 4.89276599434503

Epoch: 6| Step: 5
Training loss: 4.350987394671898
Validation loss: 4.887602956066324

Epoch: 6| Step: 6
Training loss: 5.3735724039273
Validation loss: 4.883197868907241

Epoch: 6| Step: 7
Training loss: 3.687500905182291
Validation loss: 4.877738933123738

Epoch: 6| Step: 8
Training loss: 5.654231095796136
Validation loss: 4.872060362213815

Epoch: 6| Step: 9
Training loss: 5.341779200439224
Validation loss: 4.866885090633735

Epoch: 6| Step: 10
Training loss: 4.8737910801344215
Validation loss: 4.861918250997891

Epoch: 6| Step: 11
Training loss: 5.707133183231541
Validation loss: 4.857171968832315

Epoch: 6| Step: 12
Training loss: 5.008248963282742
Validation loss: 4.851856462354036

Epoch: 6| Step: 13
Training loss: 4.599430231384007
Validation loss: 4.846363404470334

Epoch: 15| Step: 0
Training loss: 4.989944646677386
Validation loss: 4.842258018496335

Epoch: 6| Step: 1
Training loss: 4.995004829045463
Validation loss: 4.837034036437341

Epoch: 6| Step: 2
Training loss: 4.470086384734338
Validation loss: 4.831698793504238

Epoch: 6| Step: 3
Training loss: 3.9136070854534597
Validation loss: 4.826794059206826

Epoch: 6| Step: 4
Training loss: 4.61582097778393
Validation loss: 4.822852950639911

Epoch: 6| Step: 5
Training loss: 5.091537837736315
Validation loss: 4.817648309557107

Epoch: 6| Step: 6
Training loss: 4.678168201438172
Validation loss: 4.8134457208046895

Epoch: 6| Step: 7
Training loss: 5.235211023779364
Validation loss: 4.808619400232834

Epoch: 6| Step: 8
Training loss: 4.666055684738039
Validation loss: 4.804241806902803

Epoch: 6| Step: 9
Training loss: 5.407653979094556
Validation loss: 4.799655501930859

Epoch: 6| Step: 10
Training loss: 4.820435755806159
Validation loss: 4.795203929511891

Epoch: 6| Step: 11
Training loss: 5.190277826594288
Validation loss: 4.791178382652111

Epoch: 6| Step: 12
Training loss: 5.703060118423746
Validation loss: 4.786936484589183

Epoch: 6| Step: 13
Training loss: 5.071695524132137
Validation loss: 4.781064929580039

Epoch: 16| Step: 0
Training loss: 4.73483807908273
Validation loss: 4.776371846352427

Epoch: 6| Step: 1
Training loss: 4.973611624519222
Validation loss: 4.77165712576572

Epoch: 6| Step: 2
Training loss: 4.574107415516347
Validation loss: 4.76641092125635

Epoch: 6| Step: 3
Training loss: 4.5321645931782095
Validation loss: 4.761511890235632

Epoch: 6| Step: 4
Training loss: 4.690757331785894
Validation loss: 4.757040862183725

Epoch: 6| Step: 5
Training loss: 4.918411828792149
Validation loss: 4.752746992360173

Epoch: 6| Step: 6
Training loss: 4.662654082587735
Validation loss: 4.747689672413863

Epoch: 6| Step: 7
Training loss: 4.939101526817597
Validation loss: 4.743415987622044

Epoch: 6| Step: 8
Training loss: 4.474767941046855
Validation loss: 4.738614004872573

Epoch: 6| Step: 9
Training loss: 4.814152817713094
Validation loss: 4.733459165852655

Epoch: 6| Step: 10
Training loss: 6.054768459640179
Validation loss: 4.728713340149958

Epoch: 6| Step: 11
Training loss: 4.900886860212299
Validation loss: 4.7248681428464385

Epoch: 6| Step: 12
Training loss: 5.063837322159251
Validation loss: 4.720082177077198

Epoch: 6| Step: 13
Training loss: 4.661937951786638
Validation loss: 4.714849716979188

Epoch: 17| Step: 0
Training loss: 4.614812817977637
Validation loss: 4.7102889610412175

Epoch: 6| Step: 1
Training loss: 4.481522453676609
Validation loss: 4.705999195293893

Epoch: 6| Step: 2
Training loss: 5.086733238681178
Validation loss: 4.701971104738494

Epoch: 6| Step: 3
Training loss: 5.272630508276361
Validation loss: 4.696138720777525

Epoch: 6| Step: 4
Training loss: 4.857904438610126
Validation loss: 4.6918192482366345

Epoch: 6| Step: 5
Training loss: 5.153032258299779
Validation loss: 4.687619186581541

Epoch: 6| Step: 6
Training loss: 4.314381064784144
Validation loss: 4.682963010914633

Epoch: 6| Step: 7
Training loss: 5.162108820764726
Validation loss: 4.6779311784452515

Epoch: 6| Step: 8
Training loss: 4.9644887633713735
Validation loss: 4.673722292122572

Epoch: 6| Step: 9
Training loss: 4.774919694954222
Validation loss: 4.668218059612412

Epoch: 6| Step: 10
Training loss: 4.37393916756426
Validation loss: 4.663863850361572

Epoch: 6| Step: 11
Training loss: 4.082333085431682
Validation loss: 4.659666715172275

Epoch: 6| Step: 12
Training loss: 5.424196301534277
Validation loss: 4.654822452872867

Epoch: 6| Step: 13
Training loss: 4.519610589731432
Validation loss: 4.650022331649042

Epoch: 18| Step: 0
Training loss: 5.842912420130598
Validation loss: 4.645657089836273

Epoch: 6| Step: 1
Training loss: 4.334096156737828
Validation loss: 4.640994278828424

Epoch: 6| Step: 2
Training loss: 4.9673600081985
Validation loss: 4.636062091369897

Epoch: 6| Step: 3
Training loss: 4.017456349561235
Validation loss: 4.632527866379213

Epoch: 6| Step: 4
Training loss: 5.729067307968923
Validation loss: 4.627042680149841

Epoch: 6| Step: 5
Training loss: 3.6127026563776927
Validation loss: 4.621917522201283

Epoch: 6| Step: 6
Training loss: 3.6262546867227234
Validation loss: 4.617609890089901

Epoch: 6| Step: 7
Training loss: 4.743659757175434
Validation loss: 4.613671424380587

Epoch: 6| Step: 8
Training loss: 4.84177048134698
Validation loss: 4.609608238052021

Epoch: 6| Step: 9
Training loss: 5.005090982713427
Validation loss: 4.604431259814729

Epoch: 6| Step: 10
Training loss: 4.520676265865189
Validation loss: 4.599821200558533

Epoch: 6| Step: 11
Training loss: 4.311035792248863
Validation loss: 4.5948588618096595

Epoch: 6| Step: 12
Training loss: 5.183000750568681
Validation loss: 4.591116186930865

Epoch: 6| Step: 13
Training loss: 5.048249709976453
Validation loss: 4.587132451494431

Epoch: 19| Step: 0
Training loss: 5.120766542690773
Validation loss: 4.582711501276142

Epoch: 6| Step: 1
Training loss: 4.2236787614913895
Validation loss: 4.577586379931553

Epoch: 6| Step: 2
Training loss: 4.801902695883417
Validation loss: 4.573844549052014

Epoch: 6| Step: 3
Training loss: 4.598494175449244
Validation loss: 4.569407803363754

Epoch: 6| Step: 4
Training loss: 5.178982647884606
Validation loss: 4.565447634629385

Epoch: 6| Step: 5
Training loss: 4.015253547083083
Validation loss: 4.560567019606651

Epoch: 6| Step: 6
Training loss: 4.578722397296423
Validation loss: 4.556048914444997

Epoch: 6| Step: 7
Training loss: 4.453423098575058
Validation loss: 4.551493987015103

Epoch: 6| Step: 8
Training loss: 4.675029799422489
Validation loss: 4.547656469493083

Epoch: 6| Step: 9
Training loss: 4.478919775021006
Validation loss: 4.543266796110891

Epoch: 6| Step: 10
Training loss: 4.3701437019097895
Validation loss: 4.538658872638768

Epoch: 6| Step: 11
Training loss: 4.88348803920693
Validation loss: 4.533690889132869

Epoch: 6| Step: 12
Training loss: 5.637266051857825
Validation loss: 4.529188138647106

Epoch: 6| Step: 13
Training loss: 4.266661800938057
Validation loss: 4.524727909063927

Epoch: 20| Step: 0
Training loss: 4.571698257461377
Validation loss: 4.5204266952716115

Epoch: 6| Step: 1
Training loss: 3.982119770948411
Validation loss: 4.5162036705368305

Epoch: 6| Step: 2
Training loss: 4.3040582712759665
Validation loss: 4.5112049861644765

Epoch: 6| Step: 3
Training loss: 4.59836268932839
Validation loss: 4.507167776668061

Epoch: 6| Step: 4
Training loss: 4.430363033394218
Validation loss: 4.502409819568806

Epoch: 6| Step: 5
Training loss: 4.545781269468815
Validation loss: 4.498329240972112

Epoch: 6| Step: 6
Training loss: 4.618956457745074
Validation loss: 4.493828179214801

Epoch: 6| Step: 7
Training loss: 5.206417840310675
Validation loss: 4.4895090980617445

Epoch: 6| Step: 8
Training loss: 5.768939463768111
Validation loss: 4.485355141597654

Epoch: 6| Step: 9
Training loss: 4.727233132950153
Validation loss: 4.4806931430329735

Epoch: 6| Step: 10
Training loss: 4.7943219774934756
Validation loss: 4.4765607424428

Epoch: 6| Step: 11
Training loss: 4.143095150579795
Validation loss: 4.4713826638677965

Epoch: 6| Step: 12
Training loss: 4.203166521852876
Validation loss: 4.466858007593439

Epoch: 6| Step: 13
Training loss: 4.496260890952806
Validation loss: 4.462404685689947

Epoch: 21| Step: 0
Training loss: 4.200296464175224
Validation loss: 4.458263230292555

Epoch: 6| Step: 1
Training loss: 4.7426238762619
Validation loss: 4.4539612458942175

Epoch: 6| Step: 2
Training loss: 4.567725755345848
Validation loss: 4.449457775613629

Epoch: 6| Step: 3
Training loss: 4.616783886097305
Validation loss: 4.445373320205363

Epoch: 6| Step: 4
Training loss: 4.533504372530366
Validation loss: 4.440878464053148

Epoch: 6| Step: 5
Training loss: 4.652690166705012
Validation loss: 4.436389820041269

Epoch: 6| Step: 6
Training loss: 4.24680836830892
Validation loss: 4.432334006167427

Epoch: 6| Step: 7
Training loss: 4.405120921385842
Validation loss: 4.428090286926449

Epoch: 6| Step: 8
Training loss: 5.0026657627595625
Validation loss: 4.4237330187187505

Epoch: 6| Step: 9
Training loss: 4.976531838602562
Validation loss: 4.4189224000902305

Epoch: 6| Step: 10
Training loss: 4.687126246492783
Validation loss: 4.414898026420245

Epoch: 6| Step: 11
Training loss: 4.124738973970784
Validation loss: 4.410234710202659

Epoch: 6| Step: 12
Training loss: 4.478584618417539
Validation loss: 4.405868495721241

Epoch: 6| Step: 13
Training loss: 4.490775933115046
Validation loss: 4.401348011558238

Epoch: 22| Step: 0
Training loss: 2.853255263297376
Validation loss: 4.397337067234852

Epoch: 6| Step: 1
Training loss: 4.24750467983839
Validation loss: 4.393062272564026

Epoch: 6| Step: 2
Training loss: 4.527791564753994
Validation loss: 4.38928978868912

Epoch: 6| Step: 3
Training loss: 4.604451902826161
Validation loss: 4.384600740885337

Epoch: 6| Step: 4
Training loss: 3.8871072699581655
Validation loss: 4.380786339010279

Epoch: 6| Step: 5
Training loss: 4.356676148158884
Validation loss: 4.376651670125665

Epoch: 6| Step: 6
Training loss: 4.245926868630085
Validation loss: 4.372452275644794

Epoch: 6| Step: 7
Training loss: 5.1885792172639364
Validation loss: 4.368324946007699

Epoch: 6| Step: 8
Training loss: 4.610245754948483
Validation loss: 4.364174264509458

Epoch: 6| Step: 9
Training loss: 4.359073970341207
Validation loss: 4.359744695485557

Epoch: 6| Step: 10
Training loss: 5.118317131398596
Validation loss: 4.355340838870543

Epoch: 6| Step: 11
Training loss: 3.9149103217249355
Validation loss: 4.351190264594177

Epoch: 6| Step: 12
Training loss: 5.6220050892136815
Validation loss: 4.3467399314739925

Epoch: 6| Step: 13
Training loss: 4.779360728271854
Validation loss: 4.3427549910362675

Epoch: 23| Step: 0
Training loss: 4.947725162480962
Validation loss: 4.337774690547046

Epoch: 6| Step: 1
Training loss: 4.871096099387966
Validation loss: 4.3333319639546115

Epoch: 6| Step: 2
Training loss: 4.961129732988149
Validation loss: 4.328451022689142

Epoch: 6| Step: 3
Training loss: 4.649012528443436
Validation loss: 4.324232258211314

Epoch: 6| Step: 4
Training loss: 3.743136291639743
Validation loss: 4.319031841173953

Epoch: 6| Step: 5
Training loss: 4.620642181286111
Validation loss: 4.314860596244896

Epoch: 6| Step: 6
Training loss: 4.996498025937102
Validation loss: 4.310386545264398

Epoch: 6| Step: 7
Training loss: 3.916786814260416
Validation loss: 4.3058598209189265

Epoch: 6| Step: 8
Training loss: 3.6313771683556886
Validation loss: 4.300999847501982

Epoch: 6| Step: 9
Training loss: 3.9365785519662606
Validation loss: 4.296943710240172

Epoch: 6| Step: 10
Training loss: 4.85890318122431
Validation loss: 4.292492438316906

Epoch: 6| Step: 11
Training loss: 4.054268581969035
Validation loss: 4.287965913449687

Epoch: 6| Step: 12
Training loss: 3.836516482288597
Validation loss: 4.2838615378767635

Epoch: 6| Step: 13
Training loss: 4.73442314299728
Validation loss: 4.279149229217827

Epoch: 24| Step: 0
Training loss: 4.550706435476766
Validation loss: 4.275037801772478

Epoch: 6| Step: 1
Training loss: 4.734347201728415
Validation loss: 4.270917615601615

Epoch: 6| Step: 2
Training loss: 3.2456965197685226
Validation loss: 4.266173815325957

Epoch: 6| Step: 3
Training loss: 4.156429200862469
Validation loss: 4.262183751729419

Epoch: 6| Step: 4
Training loss: 3.2272898152151757
Validation loss: 4.257447915989685

Epoch: 6| Step: 5
Training loss: 4.679401777457568
Validation loss: 4.253674863110048

Epoch: 6| Step: 6
Training loss: 4.634649983412987
Validation loss: 4.249346439747925

Epoch: 6| Step: 7
Training loss: 4.016077157179861
Validation loss: 4.245704087875481

Epoch: 6| Step: 8
Training loss: 3.8947272677052918
Validation loss: 4.24120497873315

Epoch: 6| Step: 9
Training loss: 4.911979682681533
Validation loss: 4.2371855132397025

Epoch: 6| Step: 10
Training loss: 5.133964328049006
Validation loss: 4.232809492926634

Epoch: 6| Step: 11
Training loss: 4.369267440954038
Validation loss: 4.228424602230727

Epoch: 6| Step: 12
Training loss: 4.384289715264384
Validation loss: 4.224067802594259

Epoch: 6| Step: 13
Training loss: 4.837365058377113
Validation loss: 4.219640981519531

Epoch: 25| Step: 0
Training loss: 5.195681267751089
Validation loss: 4.215290431269522

Epoch: 6| Step: 1
Training loss: 4.205892226263687
Validation loss: 4.210817371889009

Epoch: 6| Step: 2
Training loss: 4.208900992503538
Validation loss: 4.206241156846037

Epoch: 6| Step: 3
Training loss: 4.793383194120694
Validation loss: 4.201560446579218

Epoch: 6| Step: 4
Training loss: 4.152434469184796
Validation loss: 4.196825489879807

Epoch: 6| Step: 5
Training loss: 3.5878022442077935
Validation loss: 4.192329241119116

Epoch: 6| Step: 6
Training loss: 4.331422726928817
Validation loss: 4.187897430842319

Epoch: 6| Step: 7
Training loss: 4.88841124330212
Validation loss: 4.183393429075011

Epoch: 6| Step: 8
Training loss: 4.070480723940921
Validation loss: 4.178788684449483

Epoch: 6| Step: 9
Training loss: 4.100817919767224
Validation loss: 4.174517343607921

Epoch: 6| Step: 10
Training loss: 4.096060763176587
Validation loss: 4.170241170506372

Epoch: 6| Step: 11
Training loss: 3.856597024150884
Validation loss: 4.165906162794143

Epoch: 6| Step: 12
Training loss: 4.669600631660495
Validation loss: 4.161511869249304

Epoch: 6| Step: 13
Training loss: 4.012141635376216
Validation loss: 4.157181733367399

Epoch: 26| Step: 0
Training loss: 3.5835500843821606
Validation loss: 4.152859559772442

Epoch: 6| Step: 1
Training loss: 4.000630805820805
Validation loss: 4.148715060827226

Epoch: 6| Step: 2
Training loss: 3.7849705574775188
Validation loss: 4.144621047216563

Epoch: 6| Step: 3
Training loss: 4.130769336341427
Validation loss: 4.140540643948352

Epoch: 6| Step: 4
Training loss: 4.882355447358935
Validation loss: 4.1364118914309405

Epoch: 6| Step: 5
Training loss: 5.395242941038176
Validation loss: 4.132231932967128

Epoch: 6| Step: 6
Training loss: 4.040992261064043
Validation loss: 4.127558175040333

Epoch: 6| Step: 7
Training loss: 3.9549217513454216
Validation loss: 4.1230481471679115

Epoch: 6| Step: 8
Training loss: 4.479134185436674
Validation loss: 4.118375429478364

Epoch: 6| Step: 9
Training loss: 3.9738890048971154
Validation loss: 4.114478014149359

Epoch: 6| Step: 10
Training loss: 4.092277436726477
Validation loss: 4.109834439856006

Epoch: 6| Step: 11
Training loss: 4.271219797404397
Validation loss: 4.105443778356797

Epoch: 6| Step: 12
Training loss: 4.2846076217705376
Validation loss: 4.101024018316622

Epoch: 6| Step: 13
Training loss: 4.3936055882734415
Validation loss: 4.096537080509803

Epoch: 27| Step: 0
Training loss: 4.608635484241656
Validation loss: 4.091955670148638

Epoch: 6| Step: 1
Training loss: 4.328909351875806
Validation loss: 4.087638952944015

Epoch: 6| Step: 2
Training loss: 4.299724064334704
Validation loss: 4.082913098152522

Epoch: 6| Step: 3
Training loss: 3.2184122149063805
Validation loss: 4.07835763630695

Epoch: 6| Step: 4
Training loss: 4.501823479695087
Validation loss: 4.074135223244448

Epoch: 6| Step: 5
Training loss: 3.6988334414812223
Validation loss: 4.06957854757727

Epoch: 6| Step: 6
Training loss: 3.960999979282563
Validation loss: 4.064928336518653

Epoch: 6| Step: 7
Training loss: 5.158975516645495
Validation loss: 4.060712019837478

Epoch: 6| Step: 8
Training loss: 3.3425564641184917
Validation loss: 4.055833579829495

Epoch: 6| Step: 9
Training loss: 3.513893073828764
Validation loss: 4.051529062733615

Epoch: 6| Step: 10
Training loss: 3.360585549058965
Validation loss: 4.047041488227429

Epoch: 6| Step: 11
Training loss: 3.7726013647255265
Validation loss: 4.04285892454118

Epoch: 6| Step: 12
Training loss: 5.435206313161072
Validation loss: 4.038511571935192

Epoch: 6| Step: 13
Training loss: 4.7758385446245235
Validation loss: 4.033957358366756

Epoch: 28| Step: 0
Training loss: 4.413677043457678
Validation loss: 4.029553413699465

Epoch: 6| Step: 1
Training loss: 4.139472772318194
Validation loss: 4.025075061959057

Epoch: 6| Step: 2
Training loss: 4.810682077246411
Validation loss: 4.02056389072223

Epoch: 6| Step: 3
Training loss: 4.7249448419812925
Validation loss: 4.015669687618668

Epoch: 6| Step: 4
Training loss: 4.040062549975538
Validation loss: 4.011091807950937

Epoch: 6| Step: 5
Training loss: 4.100612334138961
Validation loss: 4.006329852740125

Epoch: 6| Step: 6
Training loss: 4.001573729881011
Validation loss: 4.001783827549831

Epoch: 6| Step: 7
Training loss: 4.581691979793609
Validation loss: 3.9970297514280864

Epoch: 6| Step: 8
Training loss: 3.8498447139188694
Validation loss: 3.992164049372069

Epoch: 6| Step: 9
Training loss: 4.1679209283661205
Validation loss: 3.9875113515981293

Epoch: 6| Step: 10
Training loss: 3.670978323028417
Validation loss: 3.982897136592595

Epoch: 6| Step: 11
Training loss: 4.050669654773098
Validation loss: 3.978644365048311

Epoch: 6| Step: 12
Training loss: 3.5982046630903795
Validation loss: 3.973962439671999

Epoch: 6| Step: 13
Training loss: 3.488683252355552
Validation loss: 3.9695654003904366

Epoch: 29| Step: 0
Training loss: 3.668977933753369
Validation loss: 3.965089947552951

Epoch: 6| Step: 1
Training loss: 4.0970536508024535
Validation loss: 3.9608343488415176

Epoch: 6| Step: 2
Training loss: 3.8157327422755425
Validation loss: 3.956758922207316

Epoch: 6| Step: 3
Training loss: 3.5096445715507607
Validation loss: 3.952431257286718

Epoch: 6| Step: 4
Training loss: 4.350499240683588
Validation loss: 3.9483136838845643

Epoch: 6| Step: 5
Training loss: 4.548813029977101
Validation loss: 3.9438491172043175

Epoch: 6| Step: 6
Training loss: 4.38197555302565
Validation loss: 3.939576625700589

Epoch: 6| Step: 7
Training loss: 4.210389846547717
Validation loss: 3.9350188577112064

Epoch: 6| Step: 8
Training loss: 4.082357614420447
Validation loss: 3.930557063761056

Epoch: 6| Step: 9
Training loss: 4.017114266640918
Validation loss: 3.9260737827303536

Epoch: 6| Step: 10
Training loss: 3.5220105311828207
Validation loss: 3.921568677472133

Epoch: 6| Step: 11
Training loss: 4.406344148969219
Validation loss: 3.9170843402195916

Epoch: 6| Step: 12
Training loss: 4.431129288206205
Validation loss: 3.9124578764154045

Epoch: 6| Step: 13
Training loss: 3.747488579608599
Validation loss: 3.907642919782644

Epoch: 30| Step: 0
Training loss: 4.331450028637747
Validation loss: 3.90295065334413

Epoch: 6| Step: 1
Training loss: 5.146212153319909
Validation loss: 3.8982265621751138

Epoch: 6| Step: 2
Training loss: 4.171592902886391
Validation loss: 3.893290636817017

Epoch: 6| Step: 3
Training loss: 3.298209693085846
Validation loss: 3.8884829301721453

Epoch: 6| Step: 4
Training loss: 3.8262957503715684
Validation loss: 3.883498542502146

Epoch: 6| Step: 5
Training loss: 4.627385529473301
Validation loss: 3.878626101014081

Epoch: 6| Step: 6
Training loss: 4.135215132996951
Validation loss: 3.8731869999091257

Epoch: 6| Step: 7
Training loss: 3.2496992118735184
Validation loss: 3.868332736305499

Epoch: 6| Step: 8
Training loss: 4.159618188869365
Validation loss: 3.8631673859728983

Epoch: 6| Step: 9
Training loss: 4.376772712145251
Validation loss: 3.8579714303943797

Epoch: 6| Step: 10
Training loss: 3.776011219121139
Validation loss: 3.8531693207727944

Epoch: 6| Step: 11
Training loss: 4.135900947919446
Validation loss: 3.8480331830096177

Epoch: 6| Step: 12
Training loss: 3.315595512007332
Validation loss: 3.843326845111206

Epoch: 6| Step: 13
Training loss: 2.975686091961904
Validation loss: 3.8390111890548475

Epoch: 31| Step: 0
Training loss: 5.044321837501347
Validation loss: 3.834359335770202

Epoch: 6| Step: 1
Training loss: 4.053289683341184
Validation loss: 3.829892711829903

Epoch: 6| Step: 2
Training loss: 3.214552429274819
Validation loss: 3.8250969984600087

Epoch: 6| Step: 3
Training loss: 3.817993958298073
Validation loss: 3.8205497683621057

Epoch: 6| Step: 4
Training loss: 2.9572236213949115
Validation loss: 3.816005908345701

Epoch: 6| Step: 5
Training loss: 3.63544511465111
Validation loss: 3.811525022151434

Epoch: 6| Step: 6
Training loss: 3.4012037222061147
Validation loss: 3.8068050520595866

Epoch: 6| Step: 7
Training loss: 4.97026163774913
Validation loss: 3.802749275866682

Epoch: 6| Step: 8
Training loss: 3.926633706227055
Validation loss: 3.7979602073953886

Epoch: 6| Step: 9
Training loss: 3.5407018506698518
Validation loss: 3.793553159028292

Epoch: 6| Step: 10
Training loss: 4.172532390562471
Validation loss: 3.7887272532438994

Epoch: 6| Step: 11
Training loss: 3.8894901688786554
Validation loss: 3.7845420798419513

Epoch: 6| Step: 12
Training loss: 3.9259380555981833
Validation loss: 3.7796147911812907

Epoch: 6| Step: 13
Training loss: 4.06646112850217
Validation loss: 3.7751720119806342

Epoch: 32| Step: 0
Training loss: 3.9417268378817854
Validation loss: 3.770425904464633

Epoch: 6| Step: 1
Training loss: 3.081515695750112
Validation loss: 3.765997924910811

Epoch: 6| Step: 2
Training loss: 4.24650699461021
Validation loss: 3.761744735802315

Epoch: 6| Step: 3
Training loss: 4.143033000426977
Validation loss: 3.7571693129042325

Epoch: 6| Step: 4
Training loss: 3.502848283658263
Validation loss: 3.7524660479055636

Epoch: 6| Step: 5
Training loss: 3.2408475381924564
Validation loss: 3.7479042342811875

Epoch: 6| Step: 6
Training loss: 3.4742146654321617
Validation loss: 3.7434431821739285

Epoch: 6| Step: 7
Training loss: 3.925925059555033
Validation loss: 3.739359403545081

Epoch: 6| Step: 8
Training loss: 4.182900935062166
Validation loss: 3.7350357939448933

Epoch: 6| Step: 9
Training loss: 4.153401481432634
Validation loss: 3.730693071421429

Epoch: 6| Step: 10
Training loss: 3.8924668942650262
Validation loss: 3.7264164776720157

Epoch: 6| Step: 11
Training loss: 4.5566102773716155
Validation loss: 3.721286966167795

Epoch: 6| Step: 12
Training loss: 3.676362108313112
Validation loss: 3.716693191832814

Epoch: 6| Step: 13
Training loss: 3.9619927740517378
Validation loss: 3.7120814651574188

Epoch: 33| Step: 0
Training loss: 4.432237540369177
Validation loss: 3.707796393679791

Epoch: 6| Step: 1
Training loss: 4.121842534166588
Validation loss: 3.7027917811275293

Epoch: 6| Step: 2
Training loss: 3.980172368059928
Validation loss: 3.6974902198151467

Epoch: 6| Step: 3
Training loss: 3.782488155207774
Validation loss: 3.692964900922454

Epoch: 6| Step: 4
Training loss: 3.960607992758466
Validation loss: 3.688202634777687

Epoch: 6| Step: 5
Training loss: 3.7087964115253826
Validation loss: 3.683139895772554

Epoch: 6| Step: 6
Training loss: 2.8161406795246893
Validation loss: 3.6780425955660405

Epoch: 6| Step: 7
Training loss: 4.101483676697949
Validation loss: 3.6736893736674006

Epoch: 6| Step: 8
Training loss: 2.9427558467483803
Validation loss: 3.6688519309341694

Epoch: 6| Step: 9
Training loss: 3.590621780911987
Validation loss: 3.6646476229604903

Epoch: 6| Step: 10
Training loss: 3.8119423880611656
Validation loss: 3.6604338397841047

Epoch: 6| Step: 11
Training loss: 4.218451821421375
Validation loss: 3.6557704034981264

Epoch: 6| Step: 12
Training loss: 3.6080766464685854
Validation loss: 3.651090954471929

Epoch: 6| Step: 13
Training loss: 3.9820163103092443
Validation loss: 3.646965454165273

Epoch: 34| Step: 0
Training loss: 3.074893397522576
Validation loss: 3.642352587933665

Epoch: 6| Step: 1
Training loss: 3.3639303859171026
Validation loss: 3.6378304994455317

Epoch: 6| Step: 2
Training loss: 4.021731472344285
Validation loss: 3.6341129723489165

Epoch: 6| Step: 3
Training loss: 3.9214166016188776
Validation loss: 3.6293538244948014

Epoch: 6| Step: 4
Training loss: 3.845593514340675
Validation loss: 3.6249800933642082

Epoch: 6| Step: 5
Training loss: 2.981866871093723
Validation loss: 3.620716743362688

Epoch: 6| Step: 6
Training loss: 3.96952800183763
Validation loss: 3.6162570995406607

Epoch: 6| Step: 7
Training loss: 3.7881391835729974
Validation loss: 3.612124454113

Epoch: 6| Step: 8
Training loss: 3.147828301115813
Validation loss: 3.6078632045534924

Epoch: 6| Step: 9
Training loss: 3.399030822174217
Validation loss: 3.6034891487672054

Epoch: 6| Step: 10
Training loss: 4.210788929429154
Validation loss: 3.599371960393531

Epoch: 6| Step: 11
Training loss: 4.239165014425748
Validation loss: 3.595116706478255

Epoch: 6| Step: 12
Training loss: 3.269101860991649
Validation loss: 3.590833459020332

Epoch: 6| Step: 13
Training loss: 4.788151964062652
Validation loss: 3.5863395249476735

Epoch: 35| Step: 0
Training loss: 3.0940559313008658
Validation loss: 3.5819531303603838

Epoch: 6| Step: 1
Training loss: 3.4688231314433327
Validation loss: 3.5772925106704663

Epoch: 6| Step: 2
Training loss: 3.6451457365228515
Validation loss: 3.572759878798223

Epoch: 6| Step: 3
Training loss: 4.054225770389464
Validation loss: 3.5685896107562662

Epoch: 6| Step: 4
Training loss: 4.054400542290342
Validation loss: 3.5640236122856206

Epoch: 6| Step: 5
Training loss: 3.744930910254955
Validation loss: 3.55926002716419

Epoch: 6| Step: 6
Training loss: 3.819472518971848
Validation loss: 3.554716251243044

Epoch: 6| Step: 7
Training loss: 3.7653085409443277
Validation loss: 3.550221504321456

Epoch: 6| Step: 8
Training loss: 3.174236752540938
Validation loss: 3.5458697716483933

Epoch: 6| Step: 9
Training loss: 2.96763573867168
Validation loss: 3.5417711504315483

Epoch: 6| Step: 10
Training loss: 3.648074799833225
Validation loss: 3.5372316229464182

Epoch: 6| Step: 11
Training loss: 3.5005586723224025
Validation loss: 3.5327981351582585

Epoch: 6| Step: 12
Training loss: 4.593613810693807
Validation loss: 3.5288528250292273

Epoch: 6| Step: 13
Training loss: 3.827155290126871
Validation loss: 3.5246478678177517

Epoch: 36| Step: 0
Training loss: 3.351126404602856
Validation loss: 3.5204324249506045

Epoch: 6| Step: 1
Training loss: 3.692602990947562
Validation loss: 3.5159773134375576

Epoch: 6| Step: 2
Training loss: 3.9008183672174477
Validation loss: 3.5115532926252198

Epoch: 6| Step: 3
Training loss: 3.2718061875300264
Validation loss: 3.5071270675866093

Epoch: 6| Step: 4
Training loss: 3.1264108143489597
Validation loss: 3.502978442685573

Epoch: 6| Step: 5
Training loss: 3.927123793875033
Validation loss: 3.4987656142293093

Epoch: 6| Step: 6
Training loss: 3.9842517310128764
Validation loss: 3.494386758481486

Epoch: 6| Step: 7
Training loss: 3.1072678063235624
Validation loss: 3.4900489989869765

Epoch: 6| Step: 8
Training loss: 3.9166088235249727
Validation loss: 3.485720136754428

Epoch: 6| Step: 9
Training loss: 3.765971061032166
Validation loss: 3.4815539471056387

Epoch: 6| Step: 10
Training loss: 4.050056061533285
Validation loss: 3.4771753235372316

Epoch: 6| Step: 11
Training loss: 3.7883211964117587
Validation loss: 3.4730448896921344

Epoch: 6| Step: 12
Training loss: 3.4395083022795854
Validation loss: 3.4686901098814644

Epoch: 6| Step: 13
Training loss: 3.3278086337309682
Validation loss: 3.4645420933737

Epoch: 37| Step: 0
Training loss: 3.650455676336512
Validation loss: 3.460557306789738

Epoch: 6| Step: 1
Training loss: 4.244141523814907
Validation loss: 3.4563305505675204

Epoch: 6| Step: 2
Training loss: 3.1064479219868795
Validation loss: 3.4521758672405958

Epoch: 6| Step: 3
Training loss: 3.5520299346281052
Validation loss: 3.4479975772518725

Epoch: 6| Step: 4
Training loss: 3.861871938659472
Validation loss: 3.4441007413599487

Epoch: 6| Step: 5
Training loss: 3.63226471739518
Validation loss: 3.440031033050668

Epoch: 6| Step: 6
Training loss: 3.731918101345329
Validation loss: 3.4356306137049275

Epoch: 6| Step: 7
Training loss: 3.25720048090985
Validation loss: 3.431285338228507

Epoch: 6| Step: 8
Training loss: 3.4840254672463145
Validation loss: 3.4270847324418727

Epoch: 6| Step: 9
Training loss: 2.6472507394769265
Validation loss: 3.4230340304059883

Epoch: 6| Step: 10
Training loss: 4.047017569957888
Validation loss: 3.4192696324637115

Epoch: 6| Step: 11
Training loss: 3.2420749874585257
Validation loss: 3.415596344627804

Epoch: 6| Step: 12
Training loss: 3.0629971159131517
Validation loss: 3.4116435847567703

Epoch: 6| Step: 13
Training loss: 4.147971721585885
Validation loss: 3.407768237797086

Epoch: 38| Step: 0
Training loss: 4.26957793354224
Validation loss: 3.403834124928904

Epoch: 6| Step: 1
Training loss: 3.814583756123715
Validation loss: 3.3996325032457313

Epoch: 6| Step: 2
Training loss: 3.7571619941932703
Validation loss: 3.3956224028873887

Epoch: 6| Step: 3
Training loss: 3.3861510121017657
Validation loss: 3.391549964290416

Epoch: 6| Step: 4
Training loss: 3.390649188961816
Validation loss: 3.3874299777630896

Epoch: 6| Step: 5
Training loss: 3.6100213599167494
Validation loss: 3.3834490335033656

Epoch: 6| Step: 6
Training loss: 4.128412395814172
Validation loss: 3.3796185104752343

Epoch: 6| Step: 7
Training loss: 3.2346447818306143
Validation loss: 3.375524727331991

Epoch: 6| Step: 8
Training loss: 3.6114547484477013
Validation loss: 3.371418807240341

Epoch: 6| Step: 9
Training loss: 2.390822059637565
Validation loss: 3.3674867619455098

Epoch: 6| Step: 10
Training loss: 4.073714988630617
Validation loss: 3.363774669929574

Epoch: 6| Step: 11
Training loss: 3.063417258401517
Validation loss: 3.3599282688855237

Epoch: 6| Step: 12
Training loss: 3.1966928797480123
Validation loss: 3.3560044523807493

Epoch: 6| Step: 13
Training loss: 2.8500634838863883
Validation loss: 3.35230100567866

Epoch: 39| Step: 0
Training loss: 3.1181036575636036
Validation loss: 3.348546257394842

Epoch: 6| Step: 1
Training loss: 3.4465010273261
Validation loss: 3.344916784812829

Epoch: 6| Step: 2
Training loss: 3.513955224122623
Validation loss: 3.341483824778341

Epoch: 6| Step: 3
Training loss: 3.1944192323288685
Validation loss: 3.337766992888344

Epoch: 6| Step: 4
Training loss: 3.3216374883855173
Validation loss: 3.3342732217039206

Epoch: 6| Step: 5
Training loss: 2.9700659796581874
Validation loss: 3.3307412718711236

Epoch: 6| Step: 6
Training loss: 3.89595542893186
Validation loss: 3.327385523255378

Epoch: 6| Step: 7
Training loss: 3.118945245230994
Validation loss: 3.323810437262575

Epoch: 6| Step: 8
Training loss: 4.119083206984833
Validation loss: 3.320316353589982

Epoch: 6| Step: 9
Training loss: 3.7185403460219004
Validation loss: 3.3167661749386745

Epoch: 6| Step: 10
Training loss: 2.89164064452439
Validation loss: 3.3128818915612257

Epoch: 6| Step: 11
Training loss: 3.025030303046663
Validation loss: 3.3092388078224086

Epoch: 6| Step: 12
Training loss: 3.6731215937859742
Validation loss: 3.3057270263805987

Epoch: 6| Step: 13
Training loss: 4.168044485532037
Validation loss: 3.302203435949926

Epoch: 40| Step: 0
Training loss: 4.043946137896861
Validation loss: 3.2983864668707055

Epoch: 6| Step: 1
Training loss: 3.211802864875468
Validation loss: 3.294639902461833

Epoch: 6| Step: 2
Training loss: 3.294584228726493
Validation loss: 3.290694628416903

Epoch: 6| Step: 3
Training loss: 3.51813251504724
Validation loss: 3.2869931534975443

Epoch: 6| Step: 4
Training loss: 2.8755981818152683
Validation loss: 3.2831323704157827

Epoch: 6| Step: 5
Training loss: 3.5679429619853047
Validation loss: 3.279511224141925

Epoch: 6| Step: 6
Training loss: 3.7559512916144784
Validation loss: 3.2758883676407935

Epoch: 6| Step: 7
Training loss: 3.28658043362022
Validation loss: 3.2720428870654077

Epoch: 6| Step: 8
Training loss: 2.5433021244852396
Validation loss: 3.268244980650963

Epoch: 6| Step: 9
Training loss: 3.270139065739765
Validation loss: 3.2647907219607646

Epoch: 6| Step: 10
Training loss: 4.09038259605437
Validation loss: 3.2613416746936883

Epoch: 6| Step: 11
Training loss: 2.378937017933983
Validation loss: 3.2579565222211904

Epoch: 6| Step: 12
Training loss: 3.093598333166841
Validation loss: 3.254342747872743

Epoch: 6| Step: 13
Training loss: 4.295687646674056
Validation loss: 3.251079013409906

Epoch: 41| Step: 0
Training loss: 3.4094408121583997
Validation loss: 3.2477232465394072

Epoch: 6| Step: 1
Training loss: 3.63344406052533
Validation loss: 3.2440365953203973

Epoch: 6| Step: 2
Training loss: 3.297966220569368
Validation loss: 3.2406583680679217

Epoch: 6| Step: 3
Training loss: 3.849096038516148
Validation loss: 3.2370841555807743

Epoch: 6| Step: 4
Training loss: 3.597877984353473
Validation loss: 3.2334702680699556

Epoch: 6| Step: 5
Training loss: 3.389713287832181
Validation loss: 3.230029567154074

Epoch: 6| Step: 6
Training loss: 3.9439575285801003
Validation loss: 3.226400228119078

Epoch: 6| Step: 7
Training loss: 3.4658796101665112
Validation loss: 3.2228893835338623

Epoch: 6| Step: 8
Training loss: 2.8672866180500387
Validation loss: 3.2191161036999176

Epoch: 6| Step: 9
Training loss: 3.5062990725750036
Validation loss: 3.2158377228254094

Epoch: 6| Step: 10
Training loss: 3.0821364545574097
Validation loss: 3.2119810662414237

Epoch: 6| Step: 11
Training loss: 3.5641491736844277
Validation loss: 3.208492118242001

Epoch: 6| Step: 12
Training loss: 2.5233818496850744
Validation loss: 3.204999396988152

Epoch: 6| Step: 13
Training loss: 2.687491927023894
Validation loss: 3.2018806707761507

Epoch: 42| Step: 0
Training loss: 3.300680125115137
Validation loss: 3.198712046036445

Epoch: 6| Step: 1
Training loss: 3.0871005027630956
Validation loss: 3.1953820156503943

Epoch: 6| Step: 2
Training loss: 3.617744155795768
Validation loss: 3.192143529787373

Epoch: 6| Step: 3
Training loss: 3.630219220984764
Validation loss: 3.188916334247521

Epoch: 6| Step: 4
Training loss: 3.2141560482937357
Validation loss: 3.1858178106740223

Epoch: 6| Step: 5
Training loss: 3.7433041875513604
Validation loss: 3.1821539932830025

Epoch: 6| Step: 6
Training loss: 3.722837237574743
Validation loss: 3.1789248814930975

Epoch: 6| Step: 7
Training loss: 3.158955387130122
Validation loss: 3.175395146008232

Epoch: 6| Step: 8
Training loss: 3.4727805150801583
Validation loss: 3.171983989477941

Epoch: 6| Step: 9
Training loss: 3.01836780474347
Validation loss: 3.16862386318259

Epoch: 6| Step: 10
Training loss: 2.845783554542868
Validation loss: 3.1652801682349425

Epoch: 6| Step: 11
Training loss: 2.9683095504890344
Validation loss: 3.162244662304045

Epoch: 6| Step: 12
Training loss: 3.3471938607336456
Validation loss: 3.159225521708342

Epoch: 6| Step: 13
Training loss: 3.203033445957193
Validation loss: 3.1562631059129003

Epoch: 43| Step: 0
Training loss: 3.075199188976201
Validation loss: 3.1532666928452264

Epoch: 6| Step: 1
Training loss: 3.7060478682825932
Validation loss: 3.150383258896896

Epoch: 6| Step: 2
Training loss: 2.9232742304755637
Validation loss: 3.1476771443849842

Epoch: 6| Step: 3
Training loss: 3.3599313674456672
Validation loss: 3.1444485544897507

Epoch: 6| Step: 4
Training loss: 3.3686705684320937
Validation loss: 3.1412846139846873

Epoch: 6| Step: 5
Training loss: 2.502675246315288
Validation loss: 3.138500513582875

Epoch: 6| Step: 6
Training loss: 2.6922865536666865
Validation loss: 3.1356772296568507

Epoch: 6| Step: 7
Training loss: 2.7899334399853233
Validation loss: 3.132607267004004

Epoch: 6| Step: 8
Training loss: 2.9576413773630237
Validation loss: 3.129860632823291

Epoch: 6| Step: 9
Training loss: 3.888260823955541
Validation loss: 3.127216659201053

Epoch: 6| Step: 10
Training loss: 4.269409736376952
Validation loss: 3.1243787147910433

Epoch: 6| Step: 11
Training loss: 3.5593571770467127
Validation loss: 3.121134821781087

Epoch: 6| Step: 12
Training loss: 2.8944296053235323
Validation loss: 3.1180823244013918

Epoch: 6| Step: 13
Training loss: 3.380221530945361
Validation loss: 3.1149261736706406

Epoch: 44| Step: 0
Training loss: 3.6875488795257483
Validation loss: 3.1120905176562355

Epoch: 6| Step: 1
Training loss: 3.138592114292633
Validation loss: 3.108907840210256

Epoch: 6| Step: 2
Training loss: 3.0066968557980727
Validation loss: 3.1059950792388684

Epoch: 6| Step: 3
Training loss: 3.4505969153119653
Validation loss: 3.1031155353362108

Epoch: 6| Step: 4
Training loss: 2.5788950377009368
Validation loss: 3.1003398775600983

Epoch: 6| Step: 5
Training loss: 2.763771599901283
Validation loss: 3.0976293369453374

Epoch: 6| Step: 6
Training loss: 3.4097915576757583
Validation loss: 3.0951198537829536

Epoch: 6| Step: 7
Training loss: 2.9646267817823597
Validation loss: 3.092392993104643

Epoch: 6| Step: 8
Training loss: 3.12838653172368
Validation loss: 3.089581233662882

Epoch: 6| Step: 9
Training loss: 2.6642014811220527
Validation loss: 3.0868586328379832

Epoch: 6| Step: 10
Training loss: 3.671519680281629
Validation loss: 3.084185113186022

Epoch: 6| Step: 11
Training loss: 3.4523958152613927
Validation loss: 3.081425815644794

Epoch: 6| Step: 12
Training loss: 3.1936594970779786
Validation loss: 3.078482799099287

Epoch: 6| Step: 13
Training loss: 3.8561981346067693
Validation loss: 3.0756065793833645

Epoch: 45| Step: 0
Training loss: 2.5745307605926073
Validation loss: 3.07269612614679

Epoch: 6| Step: 1
Training loss: 3.493808173990184
Validation loss: 3.0696948387081315

Epoch: 6| Step: 2
Training loss: 3.1237992077722465
Validation loss: 3.0666053658730235

Epoch: 6| Step: 3
Training loss: 2.4575062885378594
Validation loss: 3.063924276582373

Epoch: 6| Step: 4
Training loss: 3.37932281572375
Validation loss: 3.0609338349805113

Epoch: 6| Step: 5
Training loss: 3.933894004840598
Validation loss: 3.0581926819337215

Epoch: 6| Step: 6
Training loss: 3.240857690386287
Validation loss: 3.0552950854015033

Epoch: 6| Step: 7
Training loss: 2.9617136237508395
Validation loss: 3.052347390965429

Epoch: 6| Step: 8
Training loss: 3.2599230180321888
Validation loss: 3.0492697409568126

Epoch: 6| Step: 9
Training loss: 2.8066987288479326
Validation loss: 3.0463566917965075

Epoch: 6| Step: 10
Training loss: 3.660952681910075
Validation loss: 3.0434581018702325

Epoch: 6| Step: 11
Training loss: 3.476958725884785
Validation loss: 3.040629658657895

Epoch: 6| Step: 12
Training loss: 3.3458410836997396
Validation loss: 3.0376699046900435

Epoch: 6| Step: 13
Training loss: 2.6679755416046427
Validation loss: 3.03485117671529

Epoch: 46| Step: 0
Training loss: 2.784887528262939
Validation loss: 3.032255576174598

Epoch: 6| Step: 1
Training loss: 3.1185461921836595
Validation loss: 3.0295538728705385

Epoch: 6| Step: 2
Training loss: 2.9437539912559196
Validation loss: 3.0271749338641554

Epoch: 6| Step: 3
Training loss: 2.933051128973189
Validation loss: 3.0247743396292095

Epoch: 6| Step: 4
Training loss: 3.2842907576278395
Validation loss: 3.022564113747847

Epoch: 6| Step: 5
Training loss: 3.192622239081005
Validation loss: 3.020380687782626

Epoch: 6| Step: 6
Training loss: 2.8793905153678327
Validation loss: 3.0179268545965168

Epoch: 6| Step: 7
Training loss: 3.4210817297188347
Validation loss: 3.01571178146702

Epoch: 6| Step: 8
Training loss: 3.809055961536301
Validation loss: 3.013540519312405

Epoch: 6| Step: 9
Training loss: 2.7622933875791906
Validation loss: 3.0107181798468767

Epoch: 6| Step: 10
Training loss: 3.4460355730838694
Validation loss: 3.008175188136377

Epoch: 6| Step: 11
Training loss: 3.1704546374348626
Validation loss: 3.0055314964049136

Epoch: 6| Step: 12
Training loss: 2.957637024363081
Validation loss: 3.00288070018478

Epoch: 6| Step: 13
Training loss: 3.3238434809478985
Validation loss: 3.0001920665081623

Epoch: 47| Step: 0
Training loss: 3.0892642088944022
Validation loss: 2.9977927300074243

Epoch: 6| Step: 1
Training loss: 2.659832143434995
Validation loss: 2.9948894628506757

Epoch: 6| Step: 2
Training loss: 3.1299673655213267
Validation loss: 2.992215573915365

Epoch: 6| Step: 3
Training loss: 3.3392164924038825
Validation loss: 2.9894527490963614

Epoch: 6| Step: 4
Training loss: 3.632238855498569
Validation loss: 2.987080916800479

Epoch: 6| Step: 5
Training loss: 3.1636144250150924
Validation loss: 2.9846209812483675

Epoch: 6| Step: 6
Training loss: 3.594116324952157
Validation loss: 2.981916083694701

Epoch: 6| Step: 7
Training loss: 2.7798432639417854
Validation loss: 2.9791813874492328

Epoch: 6| Step: 8
Training loss: 3.050279329360113
Validation loss: 2.9764032329625674

Epoch: 6| Step: 9
Training loss: 3.8829752160714968
Validation loss: 2.9737791329199923

Epoch: 6| Step: 10
Training loss: 2.5270210071833294
Validation loss: 2.970984477995226

Epoch: 6| Step: 11
Training loss: 3.205524866745801
Validation loss: 2.968384409027217

Epoch: 6| Step: 12
Training loss: 2.3750574205383943
Validation loss: 2.9657951507154166

Epoch: 6| Step: 13
Training loss: 2.943997927063751
Validation loss: 2.963511479675978

Epoch: 48| Step: 0
Training loss: 3.7634232918524098
Validation loss: 2.9614716838938726

Epoch: 6| Step: 1
Training loss: 3.138519796165908
Validation loss: 2.9589347944312876

Epoch: 6| Step: 2
Training loss: 3.429700429974559
Validation loss: 2.956515295317604

Epoch: 6| Step: 3
Training loss: 2.9477601745548934
Validation loss: 2.954168643242337

Epoch: 6| Step: 4
Training loss: 2.5308842335860993
Validation loss: 2.951862731494564

Epoch: 6| Step: 5
Training loss: 3.4196385430177525
Validation loss: 2.949665202523215

Epoch: 6| Step: 6
Training loss: 3.0154358799587464
Validation loss: 2.947252263838757

Epoch: 6| Step: 7
Training loss: 2.603991957843978
Validation loss: 2.945016685896247

Epoch: 6| Step: 8
Training loss: 2.970829606733798
Validation loss: 2.9428680016515267

Epoch: 6| Step: 9
Training loss: 3.0820680720035805
Validation loss: 2.940795929684311

Epoch: 6| Step: 10
Training loss: 3.6293067341581184
Validation loss: 2.9384759269283474

Epoch: 6| Step: 11
Training loss: 2.5526953346168266
Validation loss: 2.9363247975793265

Epoch: 6| Step: 12
Training loss: 2.960923328214766
Validation loss: 2.934247454984901

Epoch: 6| Step: 13
Training loss: 2.919099029648953
Validation loss: 2.9321539232730993

Epoch: 49| Step: 0
Training loss: 2.7324139347465493
Validation loss: 2.930073433781462

Epoch: 6| Step: 1
Training loss: 3.3694146174820863
Validation loss: 2.927814396873107

Epoch: 6| Step: 2
Training loss: 2.7104103829156827
Validation loss: 2.9257286620496443

Epoch: 6| Step: 3
Training loss: 3.4759996965888873
Validation loss: 2.923806325677892

Epoch: 6| Step: 4
Training loss: 3.5226018553303406
Validation loss: 2.921547271245974

Epoch: 6| Step: 5
Training loss: 3.0379398106030147
Validation loss: 2.9193969254679994

Epoch: 6| Step: 6
Training loss: 2.576723029674566
Validation loss: 2.917102744790688

Epoch: 6| Step: 7
Training loss: 3.3288553358910087
Validation loss: 2.9150012620341914

Epoch: 6| Step: 8
Training loss: 3.580427203768681
Validation loss: 2.9126685305230215

Epoch: 6| Step: 9
Training loss: 3.093774044059029
Validation loss: 2.9105240625670032

Epoch: 6| Step: 10
Training loss: 2.896073438904026
Validation loss: 2.908152951947154

Epoch: 6| Step: 11
Training loss: 2.325273444390256
Validation loss: 2.9059635280946687

Epoch: 6| Step: 12
Training loss: 2.812648175892701
Validation loss: 2.9040124681676267

Epoch: 6| Step: 13
Training loss: 3.0746688416344568
Validation loss: 2.90209876387511

Epoch: 50| Step: 0
Training loss: 3.3304067320913924
Validation loss: 2.8999496107546903

Epoch: 6| Step: 1
Training loss: 3.119892982701609
Validation loss: 2.8981375320555203

Epoch: 6| Step: 2
Training loss: 3.2179751157871306
Validation loss: 2.8960759498084157

Epoch: 6| Step: 3
Training loss: 2.8829838564841195
Validation loss: 2.8938948960963153

Epoch: 6| Step: 4
Training loss: 3.1729809566470957
Validation loss: 2.8917259800202664

Epoch: 6| Step: 5
Training loss: 2.9970397649347427
Validation loss: 2.88967219965306

Epoch: 6| Step: 6
Training loss: 2.731090382117181
Validation loss: 2.88749226765884

Epoch: 6| Step: 7
Training loss: 2.9297696928574495
Validation loss: 2.885427114603198

Epoch: 6| Step: 8
Training loss: 3.0584593605732806
Validation loss: 2.883479743246505

Epoch: 6| Step: 9
Training loss: 2.781312748919079
Validation loss: 2.88165571510377

Epoch: 6| Step: 10
Training loss: 3.4155273088478375
Validation loss: 2.8798124697789187

Epoch: 6| Step: 11
Training loss: 2.754472390277984
Validation loss: 2.8779822652065783

Epoch: 6| Step: 12
Training loss: 2.874442004911494
Validation loss: 2.8764147801883784

Epoch: 6| Step: 13
Training loss: 3.082313128249798
Validation loss: 2.8742472174478015

Epoch: 51| Step: 0
Training loss: 2.898363302674382
Validation loss: 2.872591474873252

Epoch: 6| Step: 1
Training loss: 3.483440051352919
Validation loss: 2.8706433278080175

Epoch: 6| Step: 2
Training loss: 2.632027619411176
Validation loss: 2.8688880527054192

Epoch: 6| Step: 3
Training loss: 3.269977643931084
Validation loss: 2.8670533414769857

Epoch: 6| Step: 4
Training loss: 2.7423651222020853
Validation loss: 2.864770381484914

Epoch: 6| Step: 5
Training loss: 2.5445894622937137
Validation loss: 2.8628674355996178

Epoch: 6| Step: 6
Training loss: 2.911047144988669
Validation loss: 2.861010169025275

Epoch: 6| Step: 7
Training loss: 3.60959191929677
Validation loss: 2.8590451382061124

Epoch: 6| Step: 8
Training loss: 3.2786251650222664
Validation loss: 2.8573157811627787

Epoch: 6| Step: 9
Training loss: 3.0437383694592985
Validation loss: 2.8551221812037118

Epoch: 6| Step: 10
Training loss: 3.156148474542884
Validation loss: 2.8531602537686704

Epoch: 6| Step: 11
Training loss: 2.9646779291676606
Validation loss: 2.8511552772469164

Epoch: 6| Step: 12
Training loss: 2.503849499039983
Validation loss: 2.8492354421542423

Epoch: 6| Step: 13
Training loss: 2.7973003383699138
Validation loss: 2.8474590440796117

Epoch: 52| Step: 0
Training loss: 3.5434891592973874
Validation loss: 2.845842143799607

Epoch: 6| Step: 1
Training loss: 2.3754595261780937
Validation loss: 2.8440620754163244

Epoch: 6| Step: 2
Training loss: 2.9824541710964194
Validation loss: 2.842572118492363

Epoch: 6| Step: 3
Training loss: 3.282463212747706
Validation loss: 2.840982970346365

Epoch: 6| Step: 4
Training loss: 2.8970578758349825
Validation loss: 2.8395317427458564

Epoch: 6| Step: 5
Training loss: 3.071831014634546
Validation loss: 2.8379138823936945

Epoch: 6| Step: 6
Training loss: 2.8259334608642033
Validation loss: 2.836147107941929

Epoch: 6| Step: 7
Training loss: 2.9325251556904544
Validation loss: 2.8346055671312986

Epoch: 6| Step: 8
Training loss: 3.2788466598334804
Validation loss: 2.8330446451504447

Epoch: 6| Step: 9
Training loss: 2.3970794312036285
Validation loss: 2.8314775298301025

Epoch: 6| Step: 10
Training loss: 3.011112137200375
Validation loss: 2.8299310162002946

Epoch: 6| Step: 11
Training loss: 2.6793968999566973
Validation loss: 2.8283216713653854

Epoch: 6| Step: 12
Training loss: 3.1590762939514234
Validation loss: 2.8266070034670094

Epoch: 6| Step: 13
Training loss: 3.040043454361588
Validation loss: 2.825204004669268

Epoch: 53| Step: 0
Training loss: 2.923117959742197
Validation loss: 2.823598509551541

Epoch: 6| Step: 1
Training loss: 2.5222674512332226
Validation loss: 2.821857216047798

Epoch: 6| Step: 2
Training loss: 3.245960219077777
Validation loss: 2.8202593684805515

Epoch: 6| Step: 3
Training loss: 3.301945696508413
Validation loss: 2.818652946002387

Epoch: 6| Step: 4
Training loss: 2.486776378945364
Validation loss: 2.8168342113511184

Epoch: 6| Step: 5
Training loss: 2.843558001062703
Validation loss: 2.8150714704159836

Epoch: 6| Step: 6
Training loss: 3.283836870906739
Validation loss: 2.8134437814233024

Epoch: 6| Step: 7
Training loss: 3.2367465405441633
Validation loss: 2.8117111088651656

Epoch: 6| Step: 8
Training loss: 3.119990491608045
Validation loss: 2.8101424049232224

Epoch: 6| Step: 9
Training loss: 3.582757474773708
Validation loss: 2.8083480989273646

Epoch: 6| Step: 10
Training loss: 2.7712705931631803
Validation loss: 2.8067200502799188

Epoch: 6| Step: 11
Training loss: 2.437871268925523
Validation loss: 2.8053224601057445

Epoch: 6| Step: 12
Training loss: 2.8912534288385214
Validation loss: 2.8038609809016526

Epoch: 6| Step: 13
Training loss: 2.455541890117351
Validation loss: 2.802359476391867

Epoch: 54| Step: 0
Training loss: 2.6819957878597447
Validation loss: 2.8009486873275184

Epoch: 6| Step: 1
Training loss: 2.9940141724561298
Validation loss: 2.799604423145634

Epoch: 6| Step: 2
Training loss: 3.0622060206476354
Validation loss: 2.798167209007245

Epoch: 6| Step: 3
Training loss: 3.6641728561472866
Validation loss: 2.796784809725557

Epoch: 6| Step: 4
Training loss: 2.6588843353582488
Validation loss: 2.7954913362712106

Epoch: 6| Step: 5
Training loss: 2.666747767486739
Validation loss: 2.7940451372952015

Epoch: 6| Step: 6
Training loss: 3.1872464247424754
Validation loss: 2.7928014033763238

Epoch: 6| Step: 7
Training loss: 2.0931696300925533
Validation loss: 2.791739524535846

Epoch: 6| Step: 8
Training loss: 2.6999546930255827
Validation loss: 2.7903496116892788

Epoch: 6| Step: 9
Training loss: 3.1373275223091976
Validation loss: 2.7891329231952624

Epoch: 6| Step: 10
Training loss: 3.3816313410443484
Validation loss: 2.787835429128333

Epoch: 6| Step: 11
Training loss: 2.609521918814899
Validation loss: 2.78643853486535

Epoch: 6| Step: 12
Training loss: 2.619147179102538
Validation loss: 2.785053766691558

Epoch: 6| Step: 13
Training loss: 3.2570076732738364
Validation loss: 2.7835949217103026

Epoch: 55| Step: 0
Training loss: 2.805251890897985
Validation loss: 2.78217270364847

Epoch: 6| Step: 1
Training loss: 3.0689321428928116
Validation loss: 2.7805842199212587

Epoch: 6| Step: 2
Training loss: 2.9990417221540455
Validation loss: 2.778997902462042

Epoch: 6| Step: 3
Training loss: 3.227184614378037
Validation loss: 2.7774756892502626

Epoch: 6| Step: 4
Training loss: 3.1788736937499467
Validation loss: 2.7759420771863295

Epoch: 6| Step: 5
Training loss: 2.7300496796220295
Validation loss: 2.774411097749538

Epoch: 6| Step: 6
Training loss: 2.72137552402031
Validation loss: 2.7728444929544

Epoch: 6| Step: 7
Training loss: 3.370395486417474
Validation loss: 2.771376396443243

Epoch: 6| Step: 8
Training loss: 2.706165874486332
Validation loss: 2.7700589084902774

Epoch: 6| Step: 9
Training loss: 3.2097471680701846
Validation loss: 2.7685882010161107

Epoch: 6| Step: 10
Training loss: 3.135453402450821
Validation loss: 2.767299396672866

Epoch: 6| Step: 11
Training loss: 2.4318971062025323
Validation loss: 2.7658343478349705

Epoch: 6| Step: 12
Training loss: 2.4358667623979917
Validation loss: 2.764691757532895

Epoch: 6| Step: 13
Training loss: 2.591096738928487
Validation loss: 2.763109546690932

Epoch: 56| Step: 0
Training loss: 2.8563399753547496
Validation loss: 2.7622288975089817

Epoch: 6| Step: 1
Training loss: 2.6396848370536485
Validation loss: 2.760794262281904

Epoch: 6| Step: 2
Training loss: 2.588433757863557
Validation loss: 2.7595572135326956

Epoch: 6| Step: 3
Training loss: 3.2426447166789574
Validation loss: 2.758478345449358

Epoch: 6| Step: 4
Training loss: 2.6648485920106353
Validation loss: 2.7571131438158507

Epoch: 6| Step: 5
Training loss: 3.2813569551020922
Validation loss: 2.756348924887145

Epoch: 6| Step: 6
Training loss: 2.903393890444224
Validation loss: 2.7551174088722497

Epoch: 6| Step: 7
Training loss: 3.2551062158461788
Validation loss: 2.7538352722688764

Epoch: 6| Step: 8
Training loss: 2.6670340245253854
Validation loss: 2.7523942697136534

Epoch: 6| Step: 9
Training loss: 2.8505006250080682
Validation loss: 2.751291665260436

Epoch: 6| Step: 10
Training loss: 1.8671410207669543
Validation loss: 2.7499806952521393

Epoch: 6| Step: 11
Training loss: 2.9625315539776094
Validation loss: 2.7488947583578502

Epoch: 6| Step: 12
Training loss: 3.2442291082341685
Validation loss: 2.747763793795924

Epoch: 6| Step: 13
Training loss: 3.1830287314942005
Validation loss: 2.7462984083884012

Epoch: 57| Step: 0
Training loss: 2.886012010175283
Validation loss: 2.745114393763216

Epoch: 6| Step: 1
Training loss: 2.4941727435285124
Validation loss: 2.74374933496234

Epoch: 6| Step: 2
Training loss: 2.9735406068935273
Validation loss: 2.742673593531225

Epoch: 6| Step: 3
Training loss: 2.4150335340363327
Validation loss: 2.741225302939106

Epoch: 6| Step: 4
Training loss: 2.71665268603825
Validation loss: 2.739915143552999

Epoch: 6| Step: 5
Training loss: 3.205858357623285
Validation loss: 2.7385777754136438

Epoch: 6| Step: 6
Training loss: 2.9664765336333216
Validation loss: 2.7369687376298515

Epoch: 6| Step: 7
Training loss: 3.196225061658736
Validation loss: 2.735680157845664

Epoch: 6| Step: 8
Training loss: 2.772650722606714
Validation loss: 2.734100444270389

Epoch: 6| Step: 9
Training loss: 3.0769124232621254
Validation loss: 2.7329090512121077

Epoch: 6| Step: 10
Training loss: 2.848426076392171
Validation loss: 2.7319983771548797

Epoch: 6| Step: 11
Training loss: 2.8715658824708523
Validation loss: 2.730589813473714

Epoch: 6| Step: 12
Training loss: 2.8666898622979016
Validation loss: 2.7297532977490024

Epoch: 6| Step: 13
Training loss: 2.9192622125358234
Validation loss: 2.7282520877794374

Epoch: 58| Step: 0
Training loss: 3.09020716173353
Validation loss: 2.7271432850083337

Epoch: 6| Step: 1
Training loss: 2.891060791157624
Validation loss: 2.7260010003591613

Epoch: 6| Step: 2
Training loss: 2.550203734094236
Validation loss: 2.7250775772391207

Epoch: 6| Step: 3
Training loss: 3.028308503030424
Validation loss: 2.7237392553823936

Epoch: 6| Step: 4
Training loss: 2.482632199673359
Validation loss: 2.7231749629294275

Epoch: 6| Step: 5
Training loss: 3.0599664601501195
Validation loss: 2.722160684664208

Epoch: 6| Step: 6
Training loss: 2.7045696124869556
Validation loss: 2.7209485398145943

Epoch: 6| Step: 7
Training loss: 2.566310561441486
Validation loss: 2.719778078459963

Epoch: 6| Step: 8
Training loss: 3.382306420086795
Validation loss: 2.718706781036503

Epoch: 6| Step: 9
Training loss: 2.8574505776497583
Validation loss: 2.7179875236404527

Epoch: 6| Step: 10
Training loss: 2.8806206866161905
Validation loss: 2.7166919445741864

Epoch: 6| Step: 11
Training loss: 3.0894143907002536
Validation loss: 2.715545344089858

Epoch: 6| Step: 12
Training loss: 2.805187977630688
Validation loss: 2.7144776314693098

Epoch: 6| Step: 13
Training loss: 2.525648064115092
Validation loss: 2.7129143974081056

Epoch: 59| Step: 0
Training loss: 2.853758919727423
Validation loss: 2.71143036831711

Epoch: 6| Step: 1
Training loss: 2.865459368296368
Validation loss: 2.7112225795805522

Epoch: 6| Step: 2
Training loss: 3.0458065409249504
Validation loss: 2.7091050637957466

Epoch: 6| Step: 3
Training loss: 2.9243660981674027
Validation loss: 2.707873765150006

Epoch: 6| Step: 4
Training loss: 2.9728347784863898
Validation loss: 2.7069934660681567

Epoch: 6| Step: 5
Training loss: 2.5315472463636324
Validation loss: 2.70666866984395

Epoch: 6| Step: 6
Training loss: 2.9303264277248124
Validation loss: 2.7052440532744346

Epoch: 6| Step: 7
Training loss: 2.965764200623706
Validation loss: 2.703467477848247

Epoch: 6| Step: 8
Training loss: 2.7033986741372247
Validation loss: 2.703356165179988

Epoch: 6| Step: 9
Training loss: 2.3584828490005054
Validation loss: 2.7038278272399854

Epoch: 6| Step: 10
Training loss: 3.032785557622792
Validation loss: 2.701249238048977

Epoch: 6| Step: 11
Training loss: 2.62340224550789
Validation loss: 2.6989488333315648

Epoch: 6| Step: 12
Training loss: 2.979734637843258
Validation loss: 2.6965651545222524

Epoch: 6| Step: 13
Training loss: 2.970270991950903
Validation loss: 2.6953139153075996

Epoch: 60| Step: 0
Training loss: 2.847957307366977
Validation loss: 2.695729939297405

Epoch: 6| Step: 1
Training loss: 3.071239069545425
Validation loss: 2.693605274817726

Epoch: 6| Step: 2
Training loss: 2.793492493506882
Validation loss: 2.7003652931870854

Epoch: 6| Step: 3
Training loss: 3.0274009256193533
Validation loss: 2.7357543663258013

Epoch: 6| Step: 4
Training loss: 2.746524174737851
Validation loss: 2.714467794243563

Epoch: 6| Step: 5
Training loss: 2.431035198539018
Validation loss: 2.696034018835818

Epoch: 6| Step: 6
Training loss: 2.967255868872353
Validation loss: 2.6888298470431513

Epoch: 6| Step: 7
Training loss: 2.6834781627388438
Validation loss: 2.6932571904432194

Epoch: 6| Step: 8
Training loss: 2.836545096219297
Validation loss: 2.7134709901202636

Epoch: 6| Step: 9
Training loss: 3.060353986921865
Validation loss: 2.7143676340318095

Epoch: 6| Step: 10
Training loss: 2.5304039377107714
Validation loss: 2.715146245044335

Epoch: 6| Step: 11
Training loss: 3.138357378164739
Validation loss: 2.715633184247255

Epoch: 6| Step: 12
Training loss: 2.8650223459167887
Validation loss: 2.7150333036484184

Epoch: 6| Step: 13
Training loss: 2.8527881235415684
Validation loss: 2.7132418436970394

Epoch: 61| Step: 0
Training loss: 1.9360897099817058
Validation loss: 2.711250177210182

Epoch: 6| Step: 1
Training loss: 3.413216981568714
Validation loss: 2.7102143480193743

Epoch: 6| Step: 2
Training loss: 2.3477013404311684
Validation loss: 2.7102211070682785

Epoch: 6| Step: 3
Training loss: 2.95754722215708
Validation loss: 2.707503607393247

Epoch: 6| Step: 4
Training loss: 3.0938369276376627
Validation loss: 2.7060605905689403

Epoch: 6| Step: 5
Training loss: 2.9427940873786005
Validation loss: 2.704928360705486

Epoch: 6| Step: 6
Training loss: 2.7013143307405665
Validation loss: 2.7039008965595857

Epoch: 6| Step: 7
Training loss: 2.8090280083047285
Validation loss: 2.702345057517775

Epoch: 6| Step: 8
Training loss: 2.382206874239684
Validation loss: 2.700977479343901

Epoch: 6| Step: 9
Training loss: 3.473841598966757
Validation loss: 2.699700422503705

Epoch: 6| Step: 10
Training loss: 2.8806852436780614
Validation loss: 2.69897790359671

Epoch: 6| Step: 11
Training loss: 2.5998142542880474
Validation loss: 2.6969764033261137

Epoch: 6| Step: 12
Training loss: 3.087139735651194
Validation loss: 2.6950650603745907

Epoch: 6| Step: 13
Training loss: 2.8284072313637343
Validation loss: 2.6942143068861566

Epoch: 62| Step: 0
Training loss: 2.323114931229967
Validation loss: 2.6941152816184433

Epoch: 6| Step: 1
Training loss: 2.903325239652731
Validation loss: 2.69254497767963

Epoch: 6| Step: 2
Training loss: 3.02886208144624
Validation loss: 2.6902651201654018

Epoch: 6| Step: 3
Training loss: 3.605899078378671
Validation loss: 2.688575278161606

Epoch: 6| Step: 4
Training loss: 2.9015077025991483
Validation loss: 2.686472496733962

Epoch: 6| Step: 5
Training loss: 3.0339769505006844
Validation loss: 2.687284667976986

Epoch: 6| Step: 6
Training loss: 2.144580500025039
Validation loss: 2.6878446905003752

Epoch: 6| Step: 7
Training loss: 2.613689305217857
Validation loss: 2.6883606678455374

Epoch: 6| Step: 8
Training loss: 2.8240006020953263
Validation loss: 2.687515524885891

Epoch: 6| Step: 9
Training loss: 2.563529947360792
Validation loss: 2.6882893489858657

Epoch: 6| Step: 10
Training loss: 2.9699421948288824
Validation loss: 2.6873643826118605

Epoch: 6| Step: 11
Training loss: 2.577934119354191
Validation loss: 2.685681563265481

Epoch: 6| Step: 12
Training loss: 2.8032549331473304
Validation loss: 2.6852119227670066

Epoch: 6| Step: 13
Training loss: 3.032840586733192
Validation loss: 2.683338136451482

Epoch: 63| Step: 0
Training loss: 3.0451589593596844
Validation loss: 2.680066792713829

Epoch: 6| Step: 1
Training loss: 2.8738985024769166
Validation loss: 2.67827377618288

Epoch: 6| Step: 2
Training loss: 2.576797698547937
Validation loss: 2.676673075983807

Epoch: 6| Step: 3
Training loss: 2.6106566062878875
Validation loss: 2.674871181345373

Epoch: 6| Step: 4
Training loss: 3.5393236076588765
Validation loss: 2.6734979322073635

Epoch: 6| Step: 5
Training loss: 2.760161785138538
Validation loss: 2.6725424068691743

Epoch: 6| Step: 6
Training loss: 2.6606461890221254
Validation loss: 2.6711358875492692

Epoch: 6| Step: 7
Training loss: 2.917696816311466
Validation loss: 2.6694309664198665

Epoch: 6| Step: 8
Training loss: 2.9200502297248607
Validation loss: 2.6717478552714176

Epoch: 6| Step: 9
Training loss: 2.4301462997539898
Validation loss: 2.668850977682467

Epoch: 6| Step: 10
Training loss: 3.13076220460953
Validation loss: 2.669044259232374

Epoch: 6| Step: 11
Training loss: 2.917036487203371
Validation loss: 2.664069420888493

Epoch: 6| Step: 12
Training loss: 2.5475915942136806
Validation loss: 2.6612900433768596

Epoch: 6| Step: 13
Training loss: 2.235239995236241
Validation loss: 2.6613225037514328

Epoch: 64| Step: 0
Training loss: 2.965046067804698
Validation loss: 2.662588776494874

Epoch: 6| Step: 1
Training loss: 2.7225401318607383
Validation loss: 2.6608689483575194

Epoch: 6| Step: 2
Training loss: 2.78332622055089
Validation loss: 2.662591746365851

Epoch: 6| Step: 3
Training loss: 2.805468692211213
Validation loss: 2.6607713702360765

Epoch: 6| Step: 4
Training loss: 2.738656664484932
Validation loss: 2.6610285840635854

Epoch: 6| Step: 5
Training loss: 2.502023450233834
Validation loss: 2.659475335552979

Epoch: 6| Step: 6
Training loss: 2.889353539521042
Validation loss: 2.656824700510471

Epoch: 6| Step: 7
Training loss: 2.705721451592606
Validation loss: 2.6559600372620977

Epoch: 6| Step: 8
Training loss: 2.457746683586645
Validation loss: 2.6545492973375038

Epoch: 6| Step: 9
Training loss: 2.746098611971158
Validation loss: 2.6538039669779123

Epoch: 6| Step: 10
Training loss: 3.329545841578012
Validation loss: 2.651980300743851

Epoch: 6| Step: 11
Training loss: 2.848790323625696
Validation loss: 2.6502699462583355

Epoch: 6| Step: 12
Training loss: 3.1732821044740405
Validation loss: 2.648958948165056

Epoch: 6| Step: 13
Training loss: 2.36226209623397
Validation loss: 2.6471884303578608

Epoch: 65| Step: 0
Training loss: 2.7783352440833387
Validation loss: 2.6453673535612166

Epoch: 6| Step: 1
Training loss: 2.881996928481425
Validation loss: 2.645284210252092

Epoch: 6| Step: 2
Training loss: 2.8970601801443356
Validation loss: 2.6436371336548214

Epoch: 6| Step: 3
Training loss: 2.717618509496721
Validation loss: 2.642874773192545

Epoch: 6| Step: 4
Training loss: 3.095977905786027
Validation loss: 2.645797839389728

Epoch: 6| Step: 5
Training loss: 2.2593798625466346
Validation loss: 2.639154404673042

Epoch: 6| Step: 6
Training loss: 2.8862310882913604
Validation loss: 2.6391922413877973

Epoch: 6| Step: 7
Training loss: 2.8158716972231117
Validation loss: 2.63903054699282

Epoch: 6| Step: 8
Training loss: 2.6768842887850854
Validation loss: 2.6397855127749725

Epoch: 6| Step: 9
Training loss: 2.459988753285324
Validation loss: 2.6378438174075813

Epoch: 6| Step: 10
Training loss: 2.0859290419274914
Validation loss: 2.6394841063851286

Epoch: 6| Step: 11
Training loss: 3.0144334722009036
Validation loss: 2.6363438167793656

Epoch: 6| Step: 12
Training loss: 3.0138275640277365
Validation loss: 2.6344393449665415

Epoch: 6| Step: 13
Training loss: 3.1785414221313193
Validation loss: 2.6338469513446108

Epoch: 66| Step: 0
Training loss: 2.9228843536729756
Validation loss: 2.634276167168412

Epoch: 6| Step: 1
Training loss: 2.6756896511465844
Validation loss: 2.637217789507773

Epoch: 6| Step: 2
Training loss: 3.1594429106917583
Validation loss: 2.6414082586293413

Epoch: 6| Step: 3
Training loss: 2.8687010052388686
Validation loss: 2.6475866971035735

Epoch: 6| Step: 4
Training loss: 3.142004820200175
Validation loss: 2.6417966797620984

Epoch: 6| Step: 5
Training loss: 2.6523158840238126
Validation loss: 2.6408639683084596

Epoch: 6| Step: 6
Training loss: 3.1295684989896233
Validation loss: 2.6390316612259204

Epoch: 6| Step: 7
Training loss: 2.540450998801833
Validation loss: 2.6379604251092057

Epoch: 6| Step: 8
Training loss: 3.170261216818155
Validation loss: 2.6371615115812084

Epoch: 6| Step: 9
Training loss: 2.1577788751566427
Validation loss: 2.6351567819992328

Epoch: 6| Step: 10
Training loss: 2.674227922197059
Validation loss: 2.6343418135839767

Epoch: 6| Step: 11
Training loss: 2.3306330542042883
Validation loss: 2.633396223580771

Epoch: 6| Step: 12
Training loss: 2.6921174946349264
Validation loss: 2.632661990609375

Epoch: 6| Step: 13
Training loss: 2.5906231888234394
Validation loss: 2.6320331601031874

Epoch: 67| Step: 0
Training loss: 2.59728000755648
Validation loss: 2.6302908151113487

Epoch: 6| Step: 1
Training loss: 2.797965236837787
Validation loss: 2.6276552153141064

Epoch: 6| Step: 2
Training loss: 2.7194824985867494
Validation loss: 2.6276587388288712

Epoch: 6| Step: 3
Training loss: 2.957690066036906
Validation loss: 2.628157578492061

Epoch: 6| Step: 4
Training loss: 2.729460654306895
Validation loss: 2.625218730472315

Epoch: 6| Step: 5
Training loss: 2.5083293441622456
Validation loss: 2.622673032644614

Epoch: 6| Step: 6
Training loss: 2.65769434536751
Validation loss: 2.6244453419416365

Epoch: 6| Step: 7
Training loss: 2.687220359270401
Validation loss: 2.6192623435384945

Epoch: 6| Step: 8
Training loss: 2.7335453191600565
Validation loss: 2.6191370900258506

Epoch: 6| Step: 9
Training loss: 2.9012352121511253
Validation loss: 2.617504499225703

Epoch: 6| Step: 10
Training loss: 3.04024217945966
Validation loss: 2.615857187627999

Epoch: 6| Step: 11
Training loss: 2.4451924742470688
Validation loss: 2.612592787973292

Epoch: 6| Step: 12
Training loss: 2.8176621429173583
Validation loss: 2.6120168138696007

Epoch: 6| Step: 13
Training loss: 3.0492860302355127
Validation loss: 2.6089209277617114

Epoch: 68| Step: 0
Training loss: 2.913466978201203
Validation loss: 2.608698713489708

Epoch: 6| Step: 1
Training loss: 3.2769281899084097
Validation loss: 2.6068145006443113

Epoch: 6| Step: 2
Training loss: 2.5446681659558483
Validation loss: 2.6054700615997293

Epoch: 6| Step: 3
Training loss: 3.0013065671852805
Validation loss: 2.607523781145885

Epoch: 6| Step: 4
Training loss: 2.4799779211107458
Validation loss: 2.605850942814681

Epoch: 6| Step: 5
Training loss: 2.810077726164777
Validation loss: 2.6034754153573756

Epoch: 6| Step: 6
Training loss: 3.044421651001535
Validation loss: 2.6024255705153654

Epoch: 6| Step: 7
Training loss: 2.6647780008517112
Validation loss: 2.5989419303381514

Epoch: 6| Step: 8
Training loss: 2.58646970498797
Validation loss: 2.6008792778128216

Epoch: 6| Step: 9
Training loss: 2.972328679286657
Validation loss: 2.595166933868096

Epoch: 6| Step: 10
Training loss: 2.3199341333839083
Validation loss: 2.5981107615323222

Epoch: 6| Step: 11
Training loss: 2.5135394626886534
Validation loss: 2.5986425377378146

Epoch: 6| Step: 12
Training loss: 2.915348699792503
Validation loss: 2.5943095664534717

Epoch: 6| Step: 13
Training loss: 2.182700313888236
Validation loss: 2.596722152379951

Epoch: 69| Step: 0
Training loss: 2.498934137106106
Validation loss: 2.5942906042291582

Epoch: 6| Step: 1
Training loss: 2.9691004496073217
Validation loss: 2.599011014864376

Epoch: 6| Step: 2
Training loss: 3.2417880260302168
Validation loss: 2.599432706382664

Epoch: 6| Step: 3
Training loss: 2.5864655569228905
Validation loss: 2.601689332728488

Epoch: 6| Step: 4
Training loss: 2.694439732874086
Validation loss: 2.6002964073954296

Epoch: 6| Step: 5
Training loss: 2.7375076224164356
Validation loss: 2.6031770707838056

Epoch: 6| Step: 6
Training loss: 2.8567426060568955
Validation loss: 2.602128342503143

Epoch: 6| Step: 7
Training loss: 2.6307769060130175
Validation loss: 2.6019547694636813

Epoch: 6| Step: 8
Training loss: 2.5564679115888387
Validation loss: 2.5980453008657385

Epoch: 6| Step: 9
Training loss: 2.9385224855687864
Validation loss: 2.59408841357492

Epoch: 6| Step: 10
Training loss: 2.7648167695353707
Validation loss: 2.5933865824955413

Epoch: 6| Step: 11
Training loss: 2.483334689385302
Validation loss: 2.5876171730527187

Epoch: 6| Step: 12
Training loss: 2.785317350760197
Validation loss: 2.578770381411175

Epoch: 6| Step: 13
Training loss: 2.4857081069462343
Validation loss: 2.5946636965229226

Epoch: 70| Step: 0
Training loss: 2.5347010316935523
Validation loss: 2.5924625955137675

Epoch: 6| Step: 1
Training loss: 2.0106176825981046
Validation loss: 2.5872063726640007

Epoch: 6| Step: 2
Training loss: 3.5637368180089037
Validation loss: 2.592855230215869

Epoch: 6| Step: 3
Training loss: 3.0411774402998377
Validation loss: 2.5792224128216303

Epoch: 6| Step: 4
Training loss: 2.7667533167709473
Validation loss: 2.5709574700859648

Epoch: 6| Step: 5
Training loss: 2.2767272428810092
Validation loss: 2.5702338936176807

Epoch: 6| Step: 6
Training loss: 2.0395205629981006
Validation loss: 2.5742241681379103

Epoch: 6| Step: 7
Training loss: 2.888700597283677
Validation loss: 2.5785502381706387

Epoch: 6| Step: 8
Training loss: 2.6918714589099433
Validation loss: 2.5764980384438685

Epoch: 6| Step: 9
Training loss: 2.8816037835900663
Validation loss: 2.572503652641093

Epoch: 6| Step: 10
Training loss: 3.0452710747286686
Validation loss: 2.5736429576775626

Epoch: 6| Step: 11
Training loss: 2.9457550930512375
Validation loss: 2.570563531151972

Epoch: 6| Step: 12
Training loss: 2.451657384685871
Validation loss: 2.5729031942120364

Epoch: 6| Step: 13
Training loss: 2.5514798339608977
Validation loss: 2.570811523724192

Epoch: 71| Step: 0
Training loss: 2.2697649784511973
Validation loss: 2.569931744140378

Epoch: 6| Step: 1
Training loss: 3.0450671970613623
Validation loss: 2.567502589362206

Epoch: 6| Step: 2
Training loss: 2.9820509244586106
Validation loss: 2.5687908549900085

Epoch: 6| Step: 3
Training loss: 2.5636344817429504
Validation loss: 2.5688737980200607

Epoch: 6| Step: 4
Training loss: 2.6015581010661006
Validation loss: 2.5679311958664117

Epoch: 6| Step: 5
Training loss: 2.324317429956105
Validation loss: 2.5678413361825174

Epoch: 6| Step: 6
Training loss: 2.7485506399873647
Validation loss: 2.568593355648282

Epoch: 6| Step: 7
Training loss: 2.371005765234584
Validation loss: 2.5655694658942125

Epoch: 6| Step: 8
Training loss: 3.0804007390888133
Validation loss: 2.5674508038505963

Epoch: 6| Step: 9
Training loss: 2.925635218318248
Validation loss: 2.5657643096434595

Epoch: 6| Step: 10
Training loss: 2.8782254246060424
Validation loss: 2.565147613828725

Epoch: 6| Step: 11
Training loss: 2.4005717867967316
Validation loss: 2.5654559105659605

Epoch: 6| Step: 12
Training loss: 2.8694696724607276
Validation loss: 2.5618138053579442

Epoch: 6| Step: 13
Training loss: 2.636300603417985
Validation loss: 2.563338584456338

Epoch: 72| Step: 0
Training loss: 2.598734466961361
Validation loss: 2.5663934452815473

Epoch: 6| Step: 1
Training loss: 3.181124125990065
Validation loss: 2.5596440535189506

Epoch: 6| Step: 2
Training loss: 2.7076583510258687
Validation loss: 2.5581816285556758

Epoch: 6| Step: 3
Training loss: 2.468146141659143
Validation loss: 2.5545640423698144

Epoch: 6| Step: 4
Training loss: 2.7820447150667547
Validation loss: 2.5575333511499836

Epoch: 6| Step: 5
Training loss: 2.5096315815675845
Validation loss: 2.5601921699090893

Epoch: 6| Step: 6
Training loss: 2.919045776802809
Validation loss: 2.558103837727935

Epoch: 6| Step: 7
Training loss: 3.027311302749501
Validation loss: 2.5599637079149926

Epoch: 6| Step: 8
Training loss: 2.4571408003263007
Validation loss: 2.559052777063996

Epoch: 6| Step: 9
Training loss: 2.648782803240975
Validation loss: 2.5571733798285528

Epoch: 6| Step: 10
Training loss: 2.696749097022424
Validation loss: 2.558682847352357

Epoch: 6| Step: 11
Training loss: 2.6951377037976445
Validation loss: 2.556463139733384

Epoch: 6| Step: 12
Training loss: 2.5424773273188532
Validation loss: 2.555042502714762

Epoch: 6| Step: 13
Training loss: 2.446305241026841
Validation loss: 2.5524750908393736

Epoch: 73| Step: 0
Training loss: 2.8362781330594657
Validation loss: 2.550387450933076

Epoch: 6| Step: 1
Training loss: 3.127423834174385
Validation loss: 2.5484820329465507

Epoch: 6| Step: 2
Training loss: 2.655081637864106
Validation loss: 2.5489814020403503

Epoch: 6| Step: 3
Training loss: 2.554347211006648
Validation loss: 2.5462164310170765

Epoch: 6| Step: 4
Training loss: 2.158192409298907
Validation loss: 2.547630229287932

Epoch: 6| Step: 5
Training loss: 3.2277509149457466
Validation loss: 2.5492032258611963

Epoch: 6| Step: 6
Training loss: 2.493105345653562
Validation loss: 2.546982745366386

Epoch: 6| Step: 7
Training loss: 2.81431343107842
Validation loss: 2.5502814698548923

Epoch: 6| Step: 8
Training loss: 2.482085606619491
Validation loss: 2.55232960557244

Epoch: 6| Step: 9
Training loss: 2.6608616906038987
Validation loss: 2.5538571998426836

Epoch: 6| Step: 10
Training loss: 2.473269610993624
Validation loss: 2.5580793256710748

Epoch: 6| Step: 11
Training loss: 2.934039410951163
Validation loss: 2.5510851925778644

Epoch: 6| Step: 12
Training loss: 2.500872555096464
Validation loss: 2.549600496350198

Epoch: 6| Step: 13
Training loss: 2.4523545531405286
Validation loss: 2.5484233588398

Epoch: 74| Step: 0
Training loss: 2.584304155441939
Validation loss: 2.538727535747572

Epoch: 6| Step: 1
Training loss: 3.056820020194885
Validation loss: 2.5411725475931846

Epoch: 6| Step: 2
Training loss: 2.878974820566525
Validation loss: 2.544212088139353

Epoch: 6| Step: 3
Training loss: 2.247890118950978
Validation loss: 2.5444740258523577

Epoch: 6| Step: 4
Training loss: 2.9163872902900487
Validation loss: 2.545758336071252

Epoch: 6| Step: 5
Training loss: 2.709028203784325
Validation loss: 2.548140307073189

Epoch: 6| Step: 6
Training loss: 2.803868336180742
Validation loss: 2.5487571579759534

Epoch: 6| Step: 7
Training loss: 2.649127521479673
Validation loss: 2.552788505962891

Epoch: 6| Step: 8
Training loss: 2.3084728125379357
Validation loss: 2.5524921219592396

Epoch: 6| Step: 9
Training loss: 2.6185302933548043
Validation loss: 2.5524174270450235

Epoch: 6| Step: 10
Training loss: 2.3947146471494203
Validation loss: 2.5508214568649152

Epoch: 6| Step: 11
Training loss: 2.9493636139918493
Validation loss: 2.5487938110068487

Epoch: 6| Step: 12
Training loss: 2.5526321962741845
Validation loss: 2.544232157657615

Epoch: 6| Step: 13
Training loss: 2.826618699695454
Validation loss: 2.5429579367849655

Epoch: 75| Step: 0
Training loss: 2.8096224157164755
Validation loss: 2.543361135466653

Epoch: 6| Step: 1
Training loss: 2.1643559776745835
Validation loss: 2.5396130087299746

Epoch: 6| Step: 2
Training loss: 2.7980571784447927
Validation loss: 2.540080284166465

Epoch: 6| Step: 3
Training loss: 2.612203378584613
Validation loss: 2.536875967830835

Epoch: 6| Step: 4
Training loss: 2.6957501484586883
Validation loss: 2.5558859126708042

Epoch: 6| Step: 5
Training loss: 2.264545262311211
Validation loss: 2.556380788850671

Epoch: 6| Step: 6
Training loss: 3.296017503636372
Validation loss: 2.5586159430941513

Epoch: 6| Step: 7
Training loss: 2.881867540755636
Validation loss: 2.5722727928747258

Epoch: 6| Step: 8
Training loss: 2.500818118699835
Validation loss: 2.5465491696867555

Epoch: 6| Step: 9
Training loss: 2.3174933058756224
Validation loss: 2.543210050870537

Epoch: 6| Step: 10
Training loss: 2.4521068233725014
Validation loss: 2.5396560366464374

Epoch: 6| Step: 11
Training loss: 2.715127394973403
Validation loss: 2.54423112685353

Epoch: 6| Step: 12
Training loss: 3.0232100684606737
Validation loss: 2.5436220047824523

Epoch: 6| Step: 13
Training loss: 2.823549647761272
Validation loss: 2.5381709015243334

Epoch: 76| Step: 0
Training loss: 2.7885769119476795
Validation loss: 2.536628080376166

Epoch: 6| Step: 1
Training loss: 2.543064191817346
Validation loss: 2.537086962453329

Epoch: 6| Step: 2
Training loss: 2.738135318976112
Validation loss: 2.5407663976181523

Epoch: 6| Step: 3
Training loss: 3.290956509112973
Validation loss: 2.5436480152577916

Epoch: 6| Step: 4
Training loss: 2.6368655919759134
Validation loss: 2.541863986209457

Epoch: 6| Step: 5
Training loss: 2.811694135714495
Validation loss: 2.5410038651886473

Epoch: 6| Step: 6
Training loss: 2.2246684266676824
Validation loss: 2.5394303744919036

Epoch: 6| Step: 7
Training loss: 1.844493263561163
Validation loss: 2.536914954054516

Epoch: 6| Step: 8
Training loss: 2.786529416517513
Validation loss: 2.5374015344266274

Epoch: 6| Step: 9
Training loss: 2.7779445937187957
Validation loss: 2.5339374639627166

Epoch: 6| Step: 10
Training loss: 2.2754372522381914
Validation loss: 2.532119993926105

Epoch: 6| Step: 11
Training loss: 2.8412863990610413
Validation loss: 2.5349794001874044

Epoch: 6| Step: 12
Training loss: 2.880742681693789
Validation loss: 2.534215845770061

Epoch: 6| Step: 13
Training loss: 2.8138987983394395
Validation loss: 2.5371426567183315

Epoch: 77| Step: 0
Training loss: 2.5747409690271117
Validation loss: 2.5333429482762764

Epoch: 6| Step: 1
Training loss: 2.6862770669247142
Validation loss: 2.530463720577526

Epoch: 6| Step: 2
Training loss: 2.3465524830276068
Validation loss: 2.5291555868426676

Epoch: 6| Step: 3
Training loss: 2.3138366135636237
Validation loss: 2.529085811807806

Epoch: 6| Step: 4
Training loss: 3.110415797266463
Validation loss: 2.5292279051186117

Epoch: 6| Step: 5
Training loss: 2.198388493472253
Validation loss: 2.5277791815068

Epoch: 6| Step: 6
Training loss: 3.3827035371001206
Validation loss: 2.5266148392118466

Epoch: 6| Step: 7
Training loss: 2.9017162440441533
Validation loss: 2.5272471956325604

Epoch: 6| Step: 8
Training loss: 2.4681497157915215
Validation loss: 2.523973815425463

Epoch: 6| Step: 9
Training loss: 3.052884167140325
Validation loss: 2.5242729418112733

Epoch: 6| Step: 10
Training loss: 2.2829021585078553
Validation loss: 2.525325041644869

Epoch: 6| Step: 11
Training loss: 2.632168744901387
Validation loss: 2.523860679392498

Epoch: 6| Step: 12
Training loss: 2.6841628180634856
Validation loss: 2.52504331910394

Epoch: 6| Step: 13
Training loss: 2.3564666607961176
Validation loss: 2.5244978496683137

Epoch: 78| Step: 0
Training loss: 2.8874289499764507
Validation loss: 2.5219031079067973

Epoch: 6| Step: 1
Training loss: 2.674379836593145
Validation loss: 2.5220262736566093

Epoch: 6| Step: 2
Training loss: 2.8514344069046866
Validation loss: 2.5194651671425063

Epoch: 6| Step: 3
Training loss: 3.1740749603534684
Validation loss: 2.5218487236737075

Epoch: 6| Step: 4
Training loss: 2.4492255641227976
Validation loss: 2.5236441859269063

Epoch: 6| Step: 5
Training loss: 2.1941299239908405
Validation loss: 2.5221956896074897

Epoch: 6| Step: 6
Training loss: 2.4398157905395967
Validation loss: 2.528806433143044

Epoch: 6| Step: 7
Training loss: 2.6355021969231163
Validation loss: 2.5320174305809524

Epoch: 6| Step: 8
Training loss: 2.331043641312328
Validation loss: 2.5391492623397367

Epoch: 6| Step: 9
Training loss: 2.1008483353951375
Validation loss: 2.5396427528329264

Epoch: 6| Step: 10
Training loss: 2.652955289519308
Validation loss: 2.550803417598251

Epoch: 6| Step: 11
Training loss: 2.859836061754216
Validation loss: 2.5490245368278397

Epoch: 6| Step: 12
Training loss: 2.9772765737345916
Validation loss: 2.5419234839177696

Epoch: 6| Step: 13
Training loss: 2.9728891529573525
Validation loss: 2.5341719649925487

Epoch: 79| Step: 0
Training loss: 2.340278394065748
Validation loss: 2.5206586656403935

Epoch: 6| Step: 1
Training loss: 2.0669928657323724
Validation loss: 2.5170458301700736

Epoch: 6| Step: 2
Training loss: 1.7122106822853975
Validation loss: 2.5230824050413596

Epoch: 6| Step: 3
Training loss: 3.4210346182839295
Validation loss: 2.530961134012435

Epoch: 6| Step: 4
Training loss: 2.317902311858577
Validation loss: 2.5384952322295433

Epoch: 6| Step: 5
Training loss: 2.7672084434918642
Validation loss: 2.5454228948043514

Epoch: 6| Step: 6
Training loss: 2.994303858737404
Validation loss: 2.5493367317371916

Epoch: 6| Step: 7
Training loss: 3.023102182330192
Validation loss: 2.5534347900306527

Epoch: 6| Step: 8
Training loss: 2.984223526710599
Validation loss: 2.555276116582577

Epoch: 6| Step: 9
Training loss: 2.787094062704302
Validation loss: 2.5578841839227637

Epoch: 6| Step: 10
Training loss: 3.0223285701528075
Validation loss: 2.5555476024983075

Epoch: 6| Step: 11
Training loss: 2.9229649433509453
Validation loss: 2.5561889995580906

Epoch: 6| Step: 12
Training loss: 2.6233347197274113
Validation loss: 2.558036452307318

Epoch: 6| Step: 13
Training loss: 1.8970586848052358
Validation loss: 2.5558974485395476

Epoch: 80| Step: 0
Training loss: 2.5404952012579645
Validation loss: 2.5539569646265994

Epoch: 6| Step: 1
Training loss: 2.618796784704544
Validation loss: 2.555103458678828

Epoch: 6| Step: 2
Training loss: 3.075676733464428
Validation loss: 2.5553371058498486

Epoch: 6| Step: 3
Training loss: 2.6872169877896597
Validation loss: 2.5559786801033577

Epoch: 6| Step: 4
Training loss: 2.975779352765869
Validation loss: 2.5563926644530937

Epoch: 6| Step: 5
Training loss: 2.6340454112593923
Validation loss: 2.556669797990747

Epoch: 6| Step: 6
Training loss: 2.5073717151812214
Validation loss: 2.5552484672205145

Epoch: 6| Step: 7
Training loss: 2.8240107331760886
Validation loss: 2.554516941174913

Epoch: 6| Step: 8
Training loss: 2.6075175178502628
Validation loss: 2.553951612403997

Epoch: 6| Step: 9
Training loss: 2.954770230366113
Validation loss: 2.5498341568766127

Epoch: 6| Step: 10
Training loss: 3.2531807813158573
Validation loss: 2.5526650654558707

Epoch: 6| Step: 11
Training loss: 2.049747693422157
Validation loss: 2.54876475054414

Epoch: 6| Step: 12
Training loss: 2.1605493556897937
Validation loss: 2.5523176799276057

Epoch: 6| Step: 13
Training loss: 2.448976446939577
Validation loss: 2.5479100002431383

Epoch: 81| Step: 0
Training loss: 2.9858953787379345
Validation loss: 2.5471093161670235

Epoch: 6| Step: 1
Training loss: 2.3420700155749454
Validation loss: 2.54455424786299

Epoch: 6| Step: 2
Training loss: 2.7644789740483326
Validation loss: 2.5436514051920436

Epoch: 6| Step: 3
Training loss: 2.9196571459739276
Validation loss: 2.544195720041491

Epoch: 6| Step: 4
Training loss: 2.3890895525122318
Validation loss: 2.5434281441584856

Epoch: 6| Step: 5
Training loss: 2.7466729585643415
Validation loss: 2.541914542154575

Epoch: 6| Step: 6
Training loss: 2.924339845938891
Validation loss: 2.5407853917742895

Epoch: 6| Step: 7
Training loss: 2.5392259750559187
Validation loss: 2.5413017219400023

Epoch: 6| Step: 8
Training loss: 2.690015192520747
Validation loss: 2.5413713492088217

Epoch: 6| Step: 9
Training loss: 2.369267220507305
Validation loss: 2.540154966422994

Epoch: 6| Step: 10
Training loss: 2.866254524796346
Validation loss: 2.53792350066267

Epoch: 6| Step: 11
Training loss: 2.472936629418578
Validation loss: 2.537098536812076

Epoch: 6| Step: 12
Training loss: 2.2008859064461657
Validation loss: 2.535009363246181

Epoch: 6| Step: 13
Training loss: 3.055348668656418
Validation loss: 2.536356606032977

Epoch: 82| Step: 0
Training loss: 2.5140231701398457
Validation loss: 2.5339222644360144

Epoch: 6| Step: 1
Training loss: 2.4434092369450173
Validation loss: 2.5335578444613995

Epoch: 6| Step: 2
Training loss: 2.622512547087496
Validation loss: 2.532830486669102

Epoch: 6| Step: 3
Training loss: 2.713204614911885
Validation loss: 2.531169199340716

Epoch: 6| Step: 4
Training loss: 2.700201140081867
Validation loss: 2.532011521939442

Epoch: 6| Step: 5
Training loss: 2.9964161765272364
Validation loss: 2.530537728773635

Epoch: 6| Step: 6
Training loss: 2.383876275417116
Validation loss: 2.5293662671716928

Epoch: 6| Step: 7
Training loss: 3.1321305367463137
Validation loss: 2.5293603837571474

Epoch: 6| Step: 8
Training loss: 2.503848356389994
Validation loss: 2.528494980015347

Epoch: 6| Step: 9
Training loss: 2.6185810080106204
Validation loss: 2.527613095332522

Epoch: 6| Step: 10
Training loss: 2.8768069352495997
Validation loss: 2.5269976874732025

Epoch: 6| Step: 11
Training loss: 2.164564714789211
Validation loss: 2.522943753496879

Epoch: 6| Step: 12
Training loss: 2.892468993235892
Validation loss: 2.5226194002357025

Epoch: 6| Step: 13
Training loss: 2.5293243995847905
Validation loss: 2.518364530210651

Epoch: 83| Step: 0
Training loss: 2.901240964626458
Validation loss: 2.518110338870439

Epoch: 6| Step: 1
Training loss: 2.7718910741501235
Validation loss: 2.516479157626592

Epoch: 6| Step: 2
Training loss: 2.6101816723615108
Validation loss: 2.5192084369315437

Epoch: 6| Step: 3
Training loss: 2.82049585311739
Validation loss: 2.5163537148762654

Epoch: 6| Step: 4
Training loss: 2.436101071858886
Validation loss: 2.518245572046902

Epoch: 6| Step: 5
Training loss: 3.2516017781295354
Validation loss: 2.5157933623087065

Epoch: 6| Step: 6
Training loss: 2.4954321138094193
Validation loss: 2.514527470416695

Epoch: 6| Step: 7
Training loss: 2.4782329906202
Validation loss: 2.5129707818984794

Epoch: 6| Step: 8
Training loss: 2.805237952490443
Validation loss: 2.5107849663465918

Epoch: 6| Step: 9
Training loss: 2.3565560989485177
Validation loss: 2.513590177301599

Epoch: 6| Step: 10
Training loss: 2.580990395410958
Validation loss: 2.5107463182306304

Epoch: 6| Step: 11
Training loss: 2.553833705073642
Validation loss: 2.5099608032489327

Epoch: 6| Step: 12
Training loss: 2.1559041063714175
Validation loss: 2.5078393096916844

Epoch: 6| Step: 13
Training loss: 2.622228794529683
Validation loss: 2.508902165452202

Epoch: 84| Step: 0
Training loss: 3.203333108235754
Validation loss: 2.507747169982593

Epoch: 6| Step: 1
Training loss: 2.260030112783291
Validation loss: 2.509452196630545

Epoch: 6| Step: 2
Training loss: 2.8173513321464823
Validation loss: 2.5067204427868948

Epoch: 6| Step: 3
Training loss: 2.4101351794244583
Validation loss: 2.5069378429782656

Epoch: 6| Step: 4
Training loss: 2.6372577031647118
Validation loss: 2.504155250265171

Epoch: 6| Step: 5
Training loss: 2.5231241793438643
Validation loss: 2.504515559370455

Epoch: 6| Step: 6
Training loss: 2.522616509732659
Validation loss: 2.506047436779966

Epoch: 6| Step: 7
Training loss: 2.685648169254449
Validation loss: 2.499692723146013

Epoch: 6| Step: 8
Training loss: 2.9597279838634423
Validation loss: 2.5067441889091033

Epoch: 6| Step: 9
Training loss: 2.3297142390578602
Validation loss: 2.5036958714190654

Epoch: 6| Step: 10
Training loss: 2.773163945851173
Validation loss: 2.5068108765821

Epoch: 6| Step: 11
Training loss: 2.858016061181119
Validation loss: 2.5028560854334545

Epoch: 6| Step: 12
Training loss: 2.1384435523099543
Validation loss: 2.5051652477680744

Epoch: 6| Step: 13
Training loss: 2.4685168578723737
Validation loss: 2.501724125479487

Epoch: 85| Step: 0
Training loss: 2.620542738369635
Validation loss: 2.5090786915330043

Epoch: 6| Step: 1
Training loss: 2.618275703687918
Validation loss: 2.5055308514392385

Epoch: 6| Step: 2
Training loss: 2.841025755827616
Validation loss: 2.504520144615562

Epoch: 6| Step: 3
Training loss: 2.272384766866413
Validation loss: 2.5044330393894345

Epoch: 6| Step: 4
Training loss: 2.322436660871983
Validation loss: 2.5072141668378745

Epoch: 6| Step: 5
Training loss: 2.2570384457566908
Validation loss: 2.5084002827003387

Epoch: 6| Step: 6
Training loss: 3.2789138470285173
Validation loss: 2.506842721816719

Epoch: 6| Step: 7
Training loss: 2.4317777909041602
Validation loss: 2.5090949878148505

Epoch: 6| Step: 8
Training loss: 2.467970326596125
Validation loss: 2.503112651335712

Epoch: 6| Step: 9
Training loss: 2.5241599923523443
Validation loss: 2.501437584488161

Epoch: 6| Step: 10
Training loss: 2.7324045111191047
Validation loss: 2.5036891896732985

Epoch: 6| Step: 11
Training loss: 3.077774570094647
Validation loss: 2.501807393960031

Epoch: 6| Step: 12
Training loss: 2.2930530747045226
Validation loss: 2.502436745740071

Epoch: 6| Step: 13
Training loss: 2.7517240495280366
Validation loss: 2.5020988872551775

Epoch: 86| Step: 0
Training loss: 2.528225822937417
Validation loss: 2.500053421085528

Epoch: 6| Step: 1
Training loss: 2.7952444768724325
Validation loss: 2.4998850160223225

Epoch: 6| Step: 2
Training loss: 2.8249259263851485
Validation loss: 2.5027217195644487

Epoch: 6| Step: 3
Training loss: 3.0364566408199525
Validation loss: 2.500076133840321

Epoch: 6| Step: 4
Training loss: 2.915109563898285
Validation loss: 2.4965056316847782

Epoch: 6| Step: 5
Training loss: 2.3737619084144383
Validation loss: 2.5024340383529746

Epoch: 6| Step: 6
Training loss: 2.792767454776269
Validation loss: 2.5022686519384356

Epoch: 6| Step: 7
Training loss: 2.2084132366
Validation loss: 2.4975311963917632

Epoch: 6| Step: 8
Training loss: 2.5275092092887714
Validation loss: 2.5005258166160154

Epoch: 6| Step: 9
Training loss: 3.0658644276485387
Validation loss: 2.499003990766502

Epoch: 6| Step: 10
Training loss: 2.6224920917460843
Validation loss: 2.502034138606945

Epoch: 6| Step: 11
Training loss: 1.9954499701429516
Validation loss: 2.5033332538054447

Epoch: 6| Step: 12
Training loss: 2.723453093159651
Validation loss: 2.5070277141808823

Epoch: 6| Step: 13
Training loss: 2.0014998057639537
Validation loss: 2.5116317520381184

Epoch: 87| Step: 0
Training loss: 2.8856043748818725
Validation loss: 2.5021618396937177

Epoch: 6| Step: 1
Training loss: 2.665070731707675
Validation loss: 2.511211931463214

Epoch: 6| Step: 2
Training loss: 2.6873409312879044
Validation loss: 2.5135880826565784

Epoch: 6| Step: 3
Training loss: 2.8424964908789563
Validation loss: 2.511831072426137

Epoch: 6| Step: 4
Training loss: 2.3415880531699615
Validation loss: 2.5094508665151536

Epoch: 6| Step: 5
Training loss: 2.5988085034029766
Validation loss: 2.5089942785831076

Epoch: 6| Step: 6
Training loss: 2.1797820039996973
Validation loss: 2.5043842654861654

Epoch: 6| Step: 7
Training loss: 2.8262982448963174
Validation loss: 2.5081102109337268

Epoch: 6| Step: 8
Training loss: 2.4547772522853073
Validation loss: 2.500959434783291

Epoch: 6| Step: 9
Training loss: 2.677701698064887
Validation loss: 2.4994754399879073

Epoch: 6| Step: 10
Training loss: 2.570878265169568
Validation loss: 2.498152399804407

Epoch: 6| Step: 11
Training loss: 2.4479924832770936
Validation loss: 2.4933866607433637

Epoch: 6| Step: 12
Training loss: 2.9783286314252795
Validation loss: 2.495427575560215

Epoch: 6| Step: 13
Training loss: 2.3343636304381863
Validation loss: 2.4922035240686604

Epoch: 88| Step: 0
Training loss: 2.144744251005625
Validation loss: 2.4946172702388756

Epoch: 6| Step: 1
Training loss: 2.2911754659713734
Validation loss: 2.4917915850894805

Epoch: 6| Step: 2
Training loss: 2.293083331025042
Validation loss: 2.4947194438719174

Epoch: 6| Step: 3
Training loss: 2.3388964434169726
Validation loss: 2.492536881051859

Epoch: 6| Step: 4
Training loss: 3.0120002427018715
Validation loss: 2.4912544026378183

Epoch: 6| Step: 5
Training loss: 3.0256568195613824
Validation loss: 2.5013836846187756

Epoch: 6| Step: 6
Training loss: 2.6832866909483064
Validation loss: 2.4998111176663285

Epoch: 6| Step: 7
Training loss: 2.0429359564692935
Validation loss: 2.4956536658761808

Epoch: 6| Step: 8
Training loss: 2.6344180319677784
Validation loss: 2.491935103340384

Epoch: 6| Step: 9
Training loss: 2.826198195497686
Validation loss: 2.493582244559029

Epoch: 6| Step: 10
Training loss: 3.1558284666878245
Validation loss: 2.4920430395656017

Epoch: 6| Step: 11
Training loss: 2.3702646531045506
Validation loss: 2.492067706857364

Epoch: 6| Step: 12
Training loss: 3.1055728535027294
Validation loss: 2.4909285471655647

Epoch: 6| Step: 13
Training loss: 2.4199112344651055
Validation loss: 2.4917203092595113

Epoch: 89| Step: 0
Training loss: 2.7393978525088016
Validation loss: 2.496355547481107

Epoch: 6| Step: 1
Training loss: 3.009168443097379
Validation loss: 2.491521365629438

Epoch: 6| Step: 2
Training loss: 2.4283179443367464
Validation loss: 2.4920562900933385

Epoch: 6| Step: 3
Training loss: 2.171652693314389
Validation loss: 2.49097281483962

Epoch: 6| Step: 4
Training loss: 2.9375884671788937
Validation loss: 2.49296533769059

Epoch: 6| Step: 5
Training loss: 2.3880559543590896
Validation loss: 2.488854135212005

Epoch: 6| Step: 6
Training loss: 2.6381986406861984
Validation loss: 2.490380535947568

Epoch: 6| Step: 7
Training loss: 2.2819559755483496
Validation loss: 2.4926164152353594

Epoch: 6| Step: 8
Training loss: 2.455548298318226
Validation loss: 2.4927491897399583

Epoch: 6| Step: 9
Training loss: 2.2866473166904715
Validation loss: 2.492947166681777

Epoch: 6| Step: 10
Training loss: 2.828102996909184
Validation loss: 2.49349037482479

Epoch: 6| Step: 11
Training loss: 2.825508044985941
Validation loss: 2.494946729158868

Epoch: 6| Step: 12
Training loss: 2.8619319968578343
Validation loss: 2.4962980597690834

Epoch: 6| Step: 13
Training loss: 2.5633417003215593
Validation loss: 2.4927074244798173

Epoch: 90| Step: 0
Training loss: 2.646390861182249
Validation loss: 2.4921861606701925

Epoch: 6| Step: 1
Training loss: 2.6477725114057216
Validation loss: 2.495588750005141

Epoch: 6| Step: 2
Training loss: 2.5100754839728823
Validation loss: 2.502285199011816

Epoch: 6| Step: 3
Training loss: 2.3187287445328004
Validation loss: 2.503241900676117

Epoch: 6| Step: 4
Training loss: 2.5713993082197937
Validation loss: 2.5082147578688683

Epoch: 6| Step: 5
Training loss: 2.2539139719389496
Validation loss: 2.5134369869596065

Epoch: 6| Step: 6
Training loss: 3.2459467040908634
Validation loss: 2.516774706595113

Epoch: 6| Step: 7
Training loss: 3.100570712314981
Validation loss: 2.504180337759605

Epoch: 6| Step: 8
Training loss: 2.3915154288542135
Validation loss: 2.5071560326280364

Epoch: 6| Step: 9
Training loss: 2.4081543161809154
Validation loss: 2.507883437313052

Epoch: 6| Step: 10
Training loss: 2.6633596080332227
Validation loss: 2.510416526847192

Epoch: 6| Step: 11
Training loss: 2.131943298516257
Validation loss: 2.5032195182541224

Epoch: 6| Step: 12
Training loss: 2.8220345689641997
Validation loss: 2.492686732881794

Epoch: 6| Step: 13
Training loss: 2.5521929866563178
Validation loss: 2.4977910614461774

Epoch: 91| Step: 0
Training loss: 2.3066375241432375
Validation loss: 2.4938741017297406

Epoch: 6| Step: 1
Training loss: 2.6629019527857474
Validation loss: 2.4900541033350265

Epoch: 6| Step: 2
Training loss: 2.263057964504667
Validation loss: 2.48767861854367

Epoch: 6| Step: 3
Training loss: 2.7980821444578408
Validation loss: 2.4895492429008645

Epoch: 6| Step: 4
Training loss: 2.9194351862373353
Validation loss: 2.4857593574049828

Epoch: 6| Step: 5
Training loss: 2.5621533973565467
Validation loss: 2.4891894253674884

Epoch: 6| Step: 6
Training loss: 2.7064491956316408
Validation loss: 2.4881910690023052

Epoch: 6| Step: 7
Training loss: 2.717781683703354
Validation loss: 2.4836983708988067

Epoch: 6| Step: 8
Training loss: 2.343653562469083
Validation loss: 2.49137357297808

Epoch: 6| Step: 9
Training loss: 2.195290996405471
Validation loss: 2.485287864483337

Epoch: 6| Step: 10
Training loss: 2.622075859078165
Validation loss: 2.4864208666617276

Epoch: 6| Step: 11
Training loss: 2.8498001296246365
Validation loss: 2.487303018038943

Epoch: 6| Step: 12
Training loss: 2.677683267029137
Validation loss: 2.4818684150802492

Epoch: 6| Step: 13
Training loss: 2.7465797309018143
Validation loss: 2.484345201997375

Epoch: 92| Step: 0
Training loss: 2.351195652124227
Validation loss: 2.485259580377739

Epoch: 6| Step: 1
Training loss: 3.1433826694547418
Validation loss: 2.485185854720579

Epoch: 6| Step: 2
Training loss: 2.7871650631426337
Validation loss: 2.492656890767671

Epoch: 6| Step: 3
Training loss: 2.585129718292757
Validation loss: 2.4918573174743437

Epoch: 6| Step: 4
Training loss: 2.2912795231109064
Validation loss: 2.497832105370265

Epoch: 6| Step: 5
Training loss: 2.950098333497907
Validation loss: 2.4941818883116795

Epoch: 6| Step: 6
Training loss: 1.8926888542733526
Validation loss: 2.4935665002551386

Epoch: 6| Step: 7
Training loss: 2.379158395016839
Validation loss: 2.4942460283049805

Epoch: 6| Step: 8
Training loss: 3.244479552678522
Validation loss: 2.4923601001057087

Epoch: 6| Step: 9
Training loss: 2.925380623334652
Validation loss: 2.491938117135041

Epoch: 6| Step: 10
Training loss: 2.4810169485267433
Validation loss: 2.4946303398410445

Epoch: 6| Step: 11
Training loss: 2.2898396809859682
Validation loss: 2.491831595619522

Epoch: 6| Step: 12
Training loss: 2.476875068843589
Validation loss: 2.487978363366714

Epoch: 6| Step: 13
Training loss: 2.33783575900271
Validation loss: 2.485005104883529

Epoch: 93| Step: 0
Training loss: 2.394491721195702
Validation loss: 2.4854275215297728

Epoch: 6| Step: 1
Training loss: 2.401475206624
Validation loss: 2.4854390007181615

Epoch: 6| Step: 2
Training loss: 2.5819298613201824
Validation loss: 2.485057856924332

Epoch: 6| Step: 3
Training loss: 2.6782302675512857
Validation loss: 2.4825806925843246

Epoch: 6| Step: 4
Training loss: 2.5814005994853244
Validation loss: 2.4807891718844535

Epoch: 6| Step: 5
Training loss: 2.301241402845678
Validation loss: 2.482021184397952

Epoch: 6| Step: 6
Training loss: 2.7622964084913586
Validation loss: 2.4824546813797976

Epoch: 6| Step: 7
Training loss: 2.9593865753881987
Validation loss: 2.484369753786062

Epoch: 6| Step: 8
Training loss: 2.685500621050541
Validation loss: 2.482315953613858

Epoch: 6| Step: 9
Training loss: 2.544708266409494
Validation loss: 2.4825027416632843

Epoch: 6| Step: 10
Training loss: 2.962157146718085
Validation loss: 2.483862194182423

Epoch: 6| Step: 11
Training loss: 2.110478995313776
Validation loss: 2.4831143105545097

Epoch: 6| Step: 12
Training loss: 2.719204393320555
Validation loss: 2.4808746726637025

Epoch: 6| Step: 13
Training loss: 2.5994323624346447
Validation loss: 2.482714387920919

Epoch: 94| Step: 0
Training loss: 2.117889850853703
Validation loss: 2.4820737357021

Epoch: 6| Step: 1
Training loss: 2.392796944713013
Validation loss: 2.481117383998616

Epoch: 6| Step: 2
Training loss: 2.4850871666831296
Validation loss: 2.4839593151700297

Epoch: 6| Step: 3
Training loss: 2.336089470554331
Validation loss: 2.4865840151894205

Epoch: 6| Step: 4
Training loss: 2.9967990328614587
Validation loss: 2.4896912863933895

Epoch: 6| Step: 5
Training loss: 2.611445353693458
Validation loss: 2.4912699382499

Epoch: 6| Step: 6
Training loss: 2.3292796708629075
Validation loss: 2.4924126406773177

Epoch: 6| Step: 7
Training loss: 2.3057083196726587
Validation loss: 2.488906997258107

Epoch: 6| Step: 8
Training loss: 2.1805617243955573
Validation loss: 2.4883713319163467

Epoch: 6| Step: 9
Training loss: 2.64666130347233
Validation loss: 2.493266925216394

Epoch: 6| Step: 10
Training loss: 2.759509550553273
Validation loss: 2.485366223684859

Epoch: 6| Step: 11
Training loss: 2.9729815391585825
Validation loss: 2.4867762830708067

Epoch: 6| Step: 12
Training loss: 2.8170341394946945
Validation loss: 2.490071585327098

Epoch: 6| Step: 13
Training loss: 3.1981609305040206
Validation loss: 2.4897060337448544

Epoch: 95| Step: 0
Training loss: 3.0853836528309166
Validation loss: 2.4895968230665453

Epoch: 6| Step: 1
Training loss: 2.7684403222630842
Validation loss: 2.4907810782903583

Epoch: 6| Step: 2
Training loss: 2.5946173998489876
Validation loss: 2.4870312963218373

Epoch: 6| Step: 3
Training loss: 2.4441775287014407
Validation loss: 2.4843378444108435

Epoch: 6| Step: 4
Training loss: 2.810873196912282
Validation loss: 2.4863378739846347

Epoch: 6| Step: 5
Training loss: 2.441062378126587
Validation loss: 2.482895728625425

Epoch: 6| Step: 6
Training loss: 2.1814786599877465
Validation loss: 2.4838127603650495

Epoch: 6| Step: 7
Training loss: 2.7742277497059917
Validation loss: 2.4837836755428824

Epoch: 6| Step: 8
Training loss: 3.056118447060483
Validation loss: 2.483511992776104

Epoch: 6| Step: 9
Training loss: 2.2305645229000466
Validation loss: 2.4867625410127348

Epoch: 6| Step: 10
Training loss: 2.2392465264243495
Validation loss: 2.4840278942816845

Epoch: 6| Step: 11
Training loss: 2.6443228026692953
Validation loss: 2.482328375639493

Epoch: 6| Step: 12
Training loss: 2.305194656692341
Validation loss: 2.485581590840776

Epoch: 6| Step: 13
Training loss: 2.656827258047004
Validation loss: 2.4771965490786827

Epoch: 96| Step: 0
Training loss: 2.9258136823865812
Validation loss: 2.481116687322613

Epoch: 6| Step: 1
Training loss: 2.738738844834439
Validation loss: 2.4795755855862547

Epoch: 6| Step: 2
Training loss: 2.422972104550007
Validation loss: 2.481017765352114

Epoch: 6| Step: 3
Training loss: 2.210649882773236
Validation loss: 2.4799192445691762

Epoch: 6| Step: 4
Training loss: 2.700026572061402
Validation loss: 2.483511464772886

Epoch: 6| Step: 5
Training loss: 1.9909760026467507
Validation loss: 2.485009438300422

Epoch: 6| Step: 6
Training loss: 2.3338493276175725
Validation loss: 2.488657557100467

Epoch: 6| Step: 7
Training loss: 2.6892666887143353
Validation loss: 2.493394182868549

Epoch: 6| Step: 8
Training loss: 2.53868668342494
Validation loss: 2.4889139900994803

Epoch: 6| Step: 9
Training loss: 2.3906142290658092
Validation loss: 2.489772746862469

Epoch: 6| Step: 10
Training loss: 3.0588696819379377
Validation loss: 2.489322191106538

Epoch: 6| Step: 11
Training loss: 2.6782551042787115
Validation loss: 2.4893869192195783

Epoch: 6| Step: 12
Training loss: 2.8377770376872458
Validation loss: 2.4882577907987473

Epoch: 6| Step: 13
Training loss: 2.628420644635109
Validation loss: 2.4903352046325185

Epoch: 97| Step: 0
Training loss: 2.2460314402022954
Validation loss: 2.48853566193099

Epoch: 6| Step: 1
Training loss: 2.471628370170551
Validation loss: 2.4904900712527125

Epoch: 6| Step: 2
Training loss: 2.9961472249139187
Validation loss: 2.4869202984671497

Epoch: 6| Step: 3
Training loss: 2.8813803819130577
Validation loss: 2.4818719694512454

Epoch: 6| Step: 4
Training loss: 2.1090535236800108
Validation loss: 2.48466809861033

Epoch: 6| Step: 5
Training loss: 2.682254373729424
Validation loss: 2.492485004712819

Epoch: 6| Step: 6
Training loss: 2.26378183040221
Validation loss: 2.4937839795747854

Epoch: 6| Step: 7
Training loss: 2.71899342817359
Validation loss: 2.498411723105917

Epoch: 6| Step: 8
Training loss: 3.0800753383587582
Validation loss: 2.4987439974136603

Epoch: 6| Step: 9
Training loss: 2.8150268224112494
Validation loss: 2.488996026795239

Epoch: 6| Step: 10
Training loss: 3.204895423456586
Validation loss: 2.484112819696732

Epoch: 6| Step: 11
Training loss: 2.066378559006334
Validation loss: 2.4809364498680933

Epoch: 6| Step: 12
Training loss: 2.425272766975331
Validation loss: 2.478030887594962

Epoch: 6| Step: 13
Training loss: 2.1527369532935703
Validation loss: 2.4779741533956834

Epoch: 98| Step: 0
Training loss: 2.510199815768017
Validation loss: 2.479479991656981

Epoch: 6| Step: 1
Training loss: 2.667685989431291
Validation loss: 2.478165533913661

Epoch: 6| Step: 2
Training loss: 2.011190104235792
Validation loss: 2.478127419341078

Epoch: 6| Step: 3
Training loss: 2.5463666350028933
Validation loss: 2.4813438173585376

Epoch: 6| Step: 4
Training loss: 3.001003415465199
Validation loss: 2.484620727926385

Epoch: 6| Step: 5
Training loss: 2.808912574806356
Validation loss: 2.486084947383269

Epoch: 6| Step: 6
Training loss: 2.607087554643711
Validation loss: 2.485676710322921

Epoch: 6| Step: 7
Training loss: 2.823768252667947
Validation loss: 2.4846910319660838

Epoch: 6| Step: 8
Training loss: 2.831681349613171
Validation loss: 2.4856613475740432

Epoch: 6| Step: 9
Training loss: 2.5620336340811543
Validation loss: 2.485570328133345

Epoch: 6| Step: 10
Training loss: 2.400677160259019
Validation loss: 2.4855062120608498

Epoch: 6| Step: 11
Training loss: 2.3964897472815703
Validation loss: 2.488143509865668

Epoch: 6| Step: 12
Training loss: 2.514223075371295
Validation loss: 2.485813324306711

Epoch: 6| Step: 13
Training loss: 2.7089629003970392
Validation loss: 2.4865124542478774

Epoch: 99| Step: 0
Training loss: 2.7646634429233368
Validation loss: 2.4863489094694766

Epoch: 6| Step: 1
Training loss: 2.691368069537104
Validation loss: 2.481723049753886

Epoch: 6| Step: 2
Training loss: 2.164833785233404
Validation loss: 2.4841657426464057

Epoch: 6| Step: 3
Training loss: 2.528215072404154
Validation loss: 2.4820520189004895

Epoch: 6| Step: 4
Training loss: 2.5549292027169748
Validation loss: 2.484866111725274

Epoch: 6| Step: 5
Training loss: 2.862953656492049
Validation loss: 2.4848289634797

Epoch: 6| Step: 6
Training loss: 2.7170064311928956
Validation loss: 2.4815955939106016

Epoch: 6| Step: 7
Training loss: 2.753448145214471
Validation loss: 2.4784909270418507

Epoch: 6| Step: 8
Training loss: 2.840490967932095
Validation loss: 2.4781780088126086

Epoch: 6| Step: 9
Training loss: 2.3809496993095194
Validation loss: 2.47625299679817

Epoch: 6| Step: 10
Training loss: 2.075926226979085
Validation loss: 2.478625748765316

Epoch: 6| Step: 11
Training loss: 2.342105542887305
Validation loss: 2.473795382838536

Epoch: 6| Step: 12
Training loss: 2.59673762319606
Validation loss: 2.4791887239602266

Epoch: 6| Step: 13
Training loss: 3.0765953329571047
Validation loss: 2.4758247696676956

Epoch: 100| Step: 0
Training loss: 2.919555722757511
Validation loss: 2.4781855931356445

Epoch: 6| Step: 1
Training loss: 2.452685663037545
Validation loss: 2.477514491136695

Epoch: 6| Step: 2
Training loss: 2.622271436653306
Validation loss: 2.479876237724197

Epoch: 6| Step: 3
Training loss: 2.724879228907914
Validation loss: 2.475089500555791

Epoch: 6| Step: 4
Training loss: 2.5122917316716293
Validation loss: 2.476890293574342

Epoch: 6| Step: 5
Training loss: 2.2839549501656085
Validation loss: 2.47595269109253

Epoch: 6| Step: 6
Training loss: 2.7715595603460175
Validation loss: 2.4810420457638567

Epoch: 6| Step: 7
Training loss: 2.33267381975128
Validation loss: 2.4789128587668547

Epoch: 6| Step: 8
Training loss: 2.589014625452016
Validation loss: 2.485505748430316

Epoch: 6| Step: 9
Training loss: 1.9709511214282007
Validation loss: 2.486384045295921

Epoch: 6| Step: 10
Training loss: 2.254246096054814
Validation loss: 2.485918697059887

Epoch: 6| Step: 11
Training loss: 3.2881603317523265
Validation loss: 2.4826767273148285

Epoch: 6| Step: 12
Training loss: 2.9135936533754574
Validation loss: 2.484310525181493

Epoch: 6| Step: 13
Training loss: 2.480491241593403
Validation loss: 2.4846926871896375

Epoch: 101| Step: 0
Training loss: 2.5196448958441673
Validation loss: 2.482600580081428

Epoch: 6| Step: 1
Training loss: 2.225508591034762
Validation loss: 2.4830205972190793

Epoch: 6| Step: 2
Training loss: 2.6798542293361263
Validation loss: 2.482954742921531

Epoch: 6| Step: 3
Training loss: 2.6443931284323434
Validation loss: 2.484821127575654

Epoch: 6| Step: 4
Training loss: 3.0812841943541907
Validation loss: 2.4812574038967616

Epoch: 6| Step: 5
Training loss: 2.5540991055969102
Validation loss: 2.483047850625167

Epoch: 6| Step: 6
Training loss: 2.384963368708326
Validation loss: 2.4839853265045337

Epoch: 6| Step: 7
Training loss: 2.0910102797136516
Validation loss: 2.4807171874898715

Epoch: 6| Step: 8
Training loss: 2.494684481193076
Validation loss: 2.4815392294401404

Epoch: 6| Step: 9
Training loss: 3.0019288220287397
Validation loss: 2.4829418599202975

Epoch: 6| Step: 10
Training loss: 2.8765828295087235
Validation loss: 2.482910844420791

Epoch: 6| Step: 11
Training loss: 1.9292234411048965
Validation loss: 2.4844059012548536

Epoch: 6| Step: 12
Training loss: 2.8969097378159256
Validation loss: 2.4793314090990375

Epoch: 6| Step: 13
Training loss: 2.431365779679386
Validation loss: 2.4820506901110297

Epoch: 102| Step: 0
Training loss: 2.5004177698116945
Validation loss: 2.4830527875724835

Epoch: 6| Step: 1
Training loss: 2.6713424955070817
Validation loss: 2.4856071775400297

Epoch: 6| Step: 2
Training loss: 2.621405001720343
Validation loss: 2.48222365089386

Epoch: 6| Step: 3
Training loss: 3.216822371066234
Validation loss: 2.4817239464049727

Epoch: 6| Step: 4
Training loss: 2.782754041345815
Validation loss: 2.482855918189349

Epoch: 6| Step: 5
Training loss: 3.0953639280850385
Validation loss: 2.4811876751993913

Epoch: 6| Step: 6
Training loss: 2.4780490396987416
Validation loss: 2.4808482122653146

Epoch: 6| Step: 7
Training loss: 2.550605896418099
Validation loss: 2.4807088740707712

Epoch: 6| Step: 8
Training loss: 2.283265569010835
Validation loss: 2.482325358181508

Epoch: 6| Step: 9
Training loss: 2.3161522145430378
Validation loss: 2.4814631674007956

Epoch: 6| Step: 10
Training loss: 2.494165669840486
Validation loss: 2.483855427086904

Epoch: 6| Step: 11
Training loss: 2.250257689236668
Validation loss: 2.479918924103641

Epoch: 6| Step: 12
Training loss: 2.2787061120189223
Validation loss: 2.4756156322697187

Epoch: 6| Step: 13
Training loss: 2.292874751853129
Validation loss: 2.4811351131358856

Epoch: 103| Step: 0
Training loss: 2.211351551335461
Validation loss: 2.483862978076457

Epoch: 6| Step: 1
Training loss: 2.2940387471326518
Validation loss: 2.4831670227514806

Epoch: 6| Step: 2
Training loss: 2.1556813692734185
Validation loss: 2.4853407544173964

Epoch: 6| Step: 3
Training loss: 2.323642588775454
Validation loss: 2.4920648526712608

Epoch: 6| Step: 4
Training loss: 2.8142301535982934
Validation loss: 2.486837546159288

Epoch: 6| Step: 5
Training loss: 2.3187563009253593
Validation loss: 2.4923936525421055

Epoch: 6| Step: 6
Training loss: 2.6890841406173633
Validation loss: 2.495603000751853

Epoch: 6| Step: 7
Training loss: 2.6780467000796713
Validation loss: 2.486717271579659

Epoch: 6| Step: 8
Training loss: 2.586401399335828
Validation loss: 2.489410974343351

Epoch: 6| Step: 9
Training loss: 2.4991605302922526
Validation loss: 2.486239327570361

Epoch: 6| Step: 10
Training loss: 3.1875520589728583
Validation loss: 2.486647743923539

Epoch: 6| Step: 11
Training loss: 2.6179451372475673
Validation loss: 2.4902265401480097

Epoch: 6| Step: 12
Training loss: 2.9424189512487797
Validation loss: 2.484914693052551

Epoch: 6| Step: 13
Training loss: 2.568167768518221
Validation loss: 2.4837571981396462

Epoch: 104| Step: 0
Training loss: 2.398399526686873
Validation loss: 2.479813600862079

Epoch: 6| Step: 1
Training loss: 2.790859551734215
Validation loss: 2.481920049023635

Epoch: 6| Step: 2
Training loss: 1.9062958383520858
Validation loss: 2.4793794578035855

Epoch: 6| Step: 3
Training loss: 2.4287068144943893
Validation loss: 2.479450303102425

Epoch: 6| Step: 4
Training loss: 2.640643870269345
Validation loss: 2.4820809959395067

Epoch: 6| Step: 5
Training loss: 2.92025369143067
Validation loss: 2.482702672060479

Epoch: 6| Step: 6
Training loss: 2.861447109834101
Validation loss: 2.4787462075634554

Epoch: 6| Step: 7
Training loss: 2.6811411837746935
Validation loss: 2.4819972577767664

Epoch: 6| Step: 8
Training loss: 2.1676427647653678
Validation loss: 2.4787930492895645

Epoch: 6| Step: 9
Training loss: 2.9833065337215197
Validation loss: 2.4817788736720834

Epoch: 6| Step: 10
Training loss: 2.6125709013010443
Validation loss: 2.4825373797053114

Epoch: 6| Step: 11
Training loss: 2.5061554469967975
Validation loss: 2.485326364885365

Epoch: 6| Step: 12
Training loss: 3.023618707475498
Validation loss: 2.4777955877360602

Epoch: 6| Step: 13
Training loss: 2.130214911888305
Validation loss: 2.4756827892892876

Epoch: 105| Step: 0
Training loss: 2.419709449539434
Validation loss: 2.4845870625260384

Epoch: 6| Step: 1
Training loss: 2.7042301983612194
Validation loss: 2.4801810510751148

Epoch: 6| Step: 2
Training loss: 1.5579174744831013
Validation loss: 2.4781802055428104

Epoch: 6| Step: 3
Training loss: 2.140672223760583
Validation loss: 2.484749323957306

Epoch: 6| Step: 4
Training loss: 2.1965526186907622
Validation loss: 2.4790352270935188

Epoch: 6| Step: 5
Training loss: 3.084137751490036
Validation loss: 2.4803204029007495

Epoch: 6| Step: 6
Training loss: 2.8518116463289953
Validation loss: 2.479363831659281

Epoch: 6| Step: 7
Training loss: 2.9545171776332064
Validation loss: 2.482958399761254

Epoch: 6| Step: 8
Training loss: 2.4758101322298627
Validation loss: 2.4810508385456513

Epoch: 6| Step: 9
Training loss: 2.745282374799141
Validation loss: 2.4859007462830216

Epoch: 6| Step: 10
Training loss: 2.7820681108080456
Validation loss: 2.480177646486109

Epoch: 6| Step: 11
Training loss: 2.7371035667674657
Validation loss: 2.4827919000691687

Epoch: 6| Step: 12
Training loss: 2.37213865882908
Validation loss: 2.485769636143949

Epoch: 6| Step: 13
Training loss: 2.61349016617508
Validation loss: 2.4860025029342463

Epoch: 106| Step: 0
Training loss: 2.1996734853678226
Validation loss: 2.4814553368816443

Epoch: 6| Step: 1
Training loss: 2.7557652468864733
Validation loss: 2.4861458758783344

Epoch: 6| Step: 2
Training loss: 2.3721629816063885
Validation loss: 2.477260615552788

Epoch: 6| Step: 3
Training loss: 2.9532033112653213
Validation loss: 2.483593271932829

Epoch: 6| Step: 4
Training loss: 2.0430016597044593
Validation loss: 2.4808893603054085

Epoch: 6| Step: 5
Training loss: 2.601800581202038
Validation loss: 2.482200534656182

Epoch: 6| Step: 6
Training loss: 2.7563510729191623
Validation loss: 2.4801268975288893

Epoch: 6| Step: 7
Training loss: 2.4782075923514912
Validation loss: 2.481018662258094

Epoch: 6| Step: 8
Training loss: 3.048904603711264
Validation loss: 2.4851010938941664

Epoch: 6| Step: 9
Training loss: 2.696195684389037
Validation loss: 2.4835527446858046

Epoch: 6| Step: 10
Training loss: 2.983091068198722
Validation loss: 2.4785295330245574

Epoch: 6| Step: 11
Training loss: 2.2920712431775043
Validation loss: 2.4717280778653214

Epoch: 6| Step: 12
Training loss: 2.131716827546055
Validation loss: 2.4724884860159912

Epoch: 6| Step: 13
Training loss: 2.455843057482672
Validation loss: 2.4747372468518987

Epoch: 107| Step: 0
Training loss: 2.668644429961941
Validation loss: 2.4771938221263965

Epoch: 6| Step: 1
Training loss: 2.6747850777393625
Validation loss: 2.4758509788111214

Epoch: 6| Step: 2
Training loss: 2.84113132509233
Validation loss: 2.473515494348533

Epoch: 6| Step: 3
Training loss: 1.9217679373840824
Validation loss: 2.4763475679820393

Epoch: 6| Step: 4
Training loss: 2.4683050406528277
Validation loss: 2.4698995175431424

Epoch: 6| Step: 5
Training loss: 2.469222494372487
Validation loss: 2.47147544882139

Epoch: 6| Step: 6
Training loss: 2.84921945959427
Validation loss: 2.4754719704823724

Epoch: 6| Step: 7
Training loss: 2.741055159700236
Validation loss: 2.473024008482564

Epoch: 6| Step: 8
Training loss: 2.6761964350564384
Validation loss: 2.474512802363255

Epoch: 6| Step: 9
Training loss: 3.2435818902409
Validation loss: 2.4720927837385576

Epoch: 6| Step: 10
Training loss: 2.1533285058659315
Validation loss: 2.4717105224004294

Epoch: 6| Step: 11
Training loss: 2.880136959210203
Validation loss: 2.4716659740447886

Epoch: 6| Step: 12
Training loss: 2.49162606638956
Validation loss: 2.473243454827882

Epoch: 6| Step: 13
Training loss: 1.7206098723933019
Validation loss: 2.466704942002479

Epoch: 108| Step: 0
Training loss: 2.621639825869853
Validation loss: 2.473918630716407

Epoch: 6| Step: 1
Training loss: 2.243149501170359
Validation loss: 2.470898606680255

Epoch: 6| Step: 2
Training loss: 2.2569402045837745
Validation loss: 2.4695583661819347

Epoch: 6| Step: 3
Training loss: 2.7438605006044576
Validation loss: 2.4693720874786904

Epoch: 6| Step: 4
Training loss: 2.9475259330974066
Validation loss: 2.473377012250993

Epoch: 6| Step: 5
Training loss: 2.9097688762735223
Validation loss: 2.4790449406421806

Epoch: 6| Step: 6
Training loss: 2.9076137829441175
Validation loss: 2.4822242752213937

Epoch: 6| Step: 7
Training loss: 2.1028549587789294
Validation loss: 2.478265507720634

Epoch: 6| Step: 8
Training loss: 2.2651903459006753
Validation loss: 2.4801759882493006

Epoch: 6| Step: 9
Training loss: 2.3972288186385406
Validation loss: 2.47838569543042

Epoch: 6| Step: 10
Training loss: 2.5932057740417434
Validation loss: 2.4798078963263457

Epoch: 6| Step: 11
Training loss: 3.031549969804454
Validation loss: 2.4762591508147147

Epoch: 6| Step: 12
Training loss: 2.2914158308139077
Validation loss: 2.481610629557298

Epoch: 6| Step: 13
Training loss: 2.355249296628189
Validation loss: 2.4812642261215814

Epoch: 109| Step: 0
Training loss: 2.5901852665921403
Validation loss: 2.4788156202091183

Epoch: 6| Step: 1
Training loss: 2.5383739300706476
Validation loss: 2.473420324886452

Epoch: 6| Step: 2
Training loss: 2.1598405659079565
Validation loss: 2.4828473878701556

Epoch: 6| Step: 3
Training loss: 2.421163245179546
Validation loss: 2.479707776383154

Epoch: 6| Step: 4
Training loss: 2.6545987550519734
Validation loss: 2.479017338676595

Epoch: 6| Step: 5
Training loss: 2.8056174943925103
Validation loss: 2.477461754907555

Epoch: 6| Step: 6
Training loss: 2.6602048267292893
Validation loss: 2.483976544110242

Epoch: 6| Step: 7
Training loss: 2.7323217912167768
Validation loss: 2.4848697897391756

Epoch: 6| Step: 8
Training loss: 2.632504498947951
Validation loss: 2.483731456393635

Epoch: 6| Step: 9
Training loss: 2.655219831974298
Validation loss: 2.485053891365768

Epoch: 6| Step: 10
Training loss: 2.499707395596259
Validation loss: 2.490680346478273

Epoch: 6| Step: 11
Training loss: 2.7242799840094287
Validation loss: 2.4860704822405264

Epoch: 6| Step: 12
Training loss: 2.3911486282836383
Validation loss: 2.4832594344218695

Epoch: 6| Step: 13
Training loss: 2.425892309819282
Validation loss: 2.480508895108617

Epoch: 110| Step: 0
Training loss: 2.1908021253953356
Validation loss: 2.484906921383302

Epoch: 6| Step: 1
Training loss: 2.2681447716716034
Validation loss: 2.482859487150972

Epoch: 6| Step: 2
Training loss: 2.858966735710375
Validation loss: 2.480959209502996

Epoch: 6| Step: 3
Training loss: 2.51148731832551
Validation loss: 2.4819612113141036

Epoch: 6| Step: 4
Training loss: 2.3549270639646185
Validation loss: 2.4855067396403183

Epoch: 6| Step: 5
Training loss: 2.612437752160065
Validation loss: 2.4826457725257556

Epoch: 6| Step: 6
Training loss: 3.046767638833645
Validation loss: 2.4800214709613795

Epoch: 6| Step: 7
Training loss: 2.8201114656860717
Validation loss: 2.4814389871904248

Epoch: 6| Step: 8
Training loss: 2.813293599379961
Validation loss: 2.4748559280488616

Epoch: 6| Step: 9
Training loss: 2.0514454374595332
Validation loss: 2.4735506598556154

Epoch: 6| Step: 10
Training loss: 2.585522575166254
Validation loss: 2.4789414717605225

Epoch: 6| Step: 11
Training loss: 2.1570474007128633
Validation loss: 2.4789407985174066

Epoch: 6| Step: 12
Training loss: 2.544319602683709
Validation loss: 2.476906095751229

Epoch: 6| Step: 13
Training loss: 2.9343550058806978
Validation loss: 2.477695498742107

Epoch: 111| Step: 0
Training loss: 2.3249865377713204
Validation loss: 2.479692008085105

Epoch: 6| Step: 1
Training loss: 2.7755189633746418
Validation loss: 2.479068182477069

Epoch: 6| Step: 2
Training loss: 2.3670728800504253
Validation loss: 2.4796977769862667

Epoch: 6| Step: 3
Training loss: 2.4672937081628703
Validation loss: 2.477233795738214

Epoch: 6| Step: 4
Training loss: 2.4100656353255503
Validation loss: 2.475932926737237

Epoch: 6| Step: 5
Training loss: 2.7766296069483465
Validation loss: 2.4807762536105114

Epoch: 6| Step: 6
Training loss: 3.215364027045152
Validation loss: 2.478459927990473

Epoch: 6| Step: 7
Training loss: 2.762870235575524
Validation loss: 2.4741791208359984

Epoch: 6| Step: 8
Training loss: 2.5209320196165694
Validation loss: 2.4750304271613

Epoch: 6| Step: 9
Training loss: 2.1946210213399326
Validation loss: 2.4748386677265275

Epoch: 6| Step: 10
Training loss: 2.576144203112612
Validation loss: 2.477554764307547

Epoch: 6| Step: 11
Training loss: 2.502339698771551
Validation loss: 2.478419084324613

Epoch: 6| Step: 12
Training loss: 2.377488488972713
Validation loss: 2.4779626556622376

Epoch: 6| Step: 13
Training loss: 2.572834111380883
Validation loss: 2.476569375270281

Epoch: 112| Step: 0
Training loss: 2.745274558589464
Validation loss: 2.4835338328108656

Epoch: 6| Step: 1
Training loss: 2.406225823615356
Validation loss: 2.480942039692208

Epoch: 6| Step: 2
Training loss: 2.68217366276887
Validation loss: 2.488755544735812

Epoch: 6| Step: 3
Training loss: 3.048291156018859
Validation loss: 2.4888496009340826

Epoch: 6| Step: 4
Training loss: 2.485800759842401
Validation loss: 2.4862421964353825

Epoch: 6| Step: 5
Training loss: 2.6731123708159514
Validation loss: 2.480943689408666

Epoch: 6| Step: 6
Training loss: 2.603777426558277
Validation loss: 2.488177278862678

Epoch: 6| Step: 7
Training loss: 2.6651206502031313
Validation loss: 2.4899081466513544

Epoch: 6| Step: 8
Training loss: 2.3155150476212625
Validation loss: 2.493248278277188

Epoch: 6| Step: 9
Training loss: 2.485768245399483
Validation loss: 2.49021626384856

Epoch: 6| Step: 10
Training loss: 2.1710674513534616
Validation loss: 2.4851934016677726

Epoch: 6| Step: 11
Training loss: 2.442646364728746
Validation loss: 2.488654363695635

Epoch: 6| Step: 12
Training loss: 2.196097454229411
Validation loss: 2.491244577190433

Epoch: 6| Step: 13
Training loss: 2.789116952401965
Validation loss: 2.4913763880821587

Epoch: 113| Step: 0
Training loss: 2.838062005535754
Validation loss: 2.483959299172815

Epoch: 6| Step: 1
Training loss: 2.5076449804714174
Validation loss: 2.480659970099249

Epoch: 6| Step: 2
Training loss: 2.313489135347326
Validation loss: 2.4828030553453657

Epoch: 6| Step: 3
Training loss: 2.5847629980056923
Validation loss: 2.4793836247587673

Epoch: 6| Step: 4
Training loss: 2.296377115069356
Validation loss: 2.4811889243756546

Epoch: 6| Step: 5
Training loss: 3.1776694002173413
Validation loss: 2.4752080284058318

Epoch: 6| Step: 6
Training loss: 2.8456407905406933
Validation loss: 2.476408383039604

Epoch: 6| Step: 7
Training loss: 2.238729222391347
Validation loss: 2.4749347861204365

Epoch: 6| Step: 8
Training loss: 3.100059471790452
Validation loss: 2.484186753152666

Epoch: 6| Step: 9
Training loss: 2.339052706629778
Validation loss: 2.4790305466241396

Epoch: 6| Step: 10
Training loss: 2.3241657154860476
Validation loss: 2.4794139311336494

Epoch: 6| Step: 11
Training loss: 2.5218007356848178
Validation loss: 2.481759716114443

Epoch: 6| Step: 12
Training loss: 2.1387263878968663
Validation loss: 2.47898439864645

Epoch: 6| Step: 13
Training loss: 2.495914554282713
Validation loss: 2.4792712908127426

Epoch: 114| Step: 0
Training loss: 2.7439566010916274
Validation loss: 2.4806382649487437

Epoch: 6| Step: 1
Training loss: 2.6566635707452684
Validation loss: 2.4874943437623807

Epoch: 6| Step: 2
Training loss: 1.9603870728786301
Validation loss: 2.4839988599693728

Epoch: 6| Step: 3
Training loss: 2.354822579441125
Validation loss: 2.4853756486865985

Epoch: 6| Step: 4
Training loss: 2.2012640486122166
Validation loss: 2.486464479457726

Epoch: 6| Step: 5
Training loss: 2.707673496171822
Validation loss: 2.482116472339916

Epoch: 6| Step: 6
Training loss: 2.4475453088324723
Validation loss: 2.480504601887804

Epoch: 6| Step: 7
Training loss: 2.5472652393768396
Validation loss: 2.4851766768344232

Epoch: 6| Step: 8
Training loss: 2.657973952998892
Validation loss: 2.4856430112656027

Epoch: 6| Step: 9
Training loss: 2.8691266645763154
Validation loss: 2.4844216876171537

Epoch: 6| Step: 10
Training loss: 2.48156118291309
Validation loss: 2.4860586383427496

Epoch: 6| Step: 11
Training loss: 2.543711001685375
Validation loss: 2.486144373462257

Epoch: 6| Step: 12
Training loss: 2.7223344172066124
Validation loss: 2.485413548184336

Epoch: 6| Step: 13
Training loss: 2.8792716095969575
Validation loss: 2.4862236726190674

Epoch: 115| Step: 0
Training loss: 3.067101116780971
Validation loss: 2.4792673961360796

Epoch: 6| Step: 1
Training loss: 2.418097719071645
Validation loss: 2.4778917758483265

Epoch: 6| Step: 2
Training loss: 2.7190831298185816
Validation loss: 2.4832956460572158

Epoch: 6| Step: 3
Training loss: 2.3226889825151087
Validation loss: 2.4831501722528158

Epoch: 6| Step: 4
Training loss: 2.496631259981223
Validation loss: 2.478950520450847

Epoch: 6| Step: 5
Training loss: 2.9051449223151193
Validation loss: 2.4826602096057075

Epoch: 6| Step: 6
Training loss: 2.334146380687606
Validation loss: 2.482283057356512

Epoch: 6| Step: 7
Training loss: 2.5444401060323734
Validation loss: 2.4818707846614787

Epoch: 6| Step: 8
Training loss: 2.3009036279330344
Validation loss: 2.4830331277418227

Epoch: 6| Step: 9
Training loss: 2.476648178784595
Validation loss: 2.4734423986158705

Epoch: 6| Step: 10
Training loss: 3.116001295439582
Validation loss: 2.479769742900245

Epoch: 6| Step: 11
Training loss: 2.3872634091413634
Validation loss: 2.4748655295528064

Epoch: 6| Step: 12
Training loss: 2.5689547120732015
Validation loss: 2.4810323880823693

Epoch: 6| Step: 13
Training loss: 2.2612959972319344
Validation loss: 2.4778082409037614

Epoch: 116| Step: 0
Training loss: 2.5300220289515227
Validation loss: 2.4777691986974193

Epoch: 6| Step: 1
Training loss: 2.396342303628016
Validation loss: 2.480256687821385

Epoch: 6| Step: 2
Training loss: 2.6572687327253752
Validation loss: 2.4735609893271158

Epoch: 6| Step: 3
Training loss: 2.455548880881113
Validation loss: 2.479190775543015

Epoch: 6| Step: 4
Training loss: 2.624602696460937
Validation loss: 2.477843746405727

Epoch: 6| Step: 5
Training loss: 1.9622021734615813
Validation loss: 2.4759391056228757

Epoch: 6| Step: 6
Training loss: 2.594826716111407
Validation loss: 2.4713233219602886

Epoch: 6| Step: 7
Training loss: 2.7765287982224134
Validation loss: 2.4750093389264274

Epoch: 6| Step: 8
Training loss: 2.2935754860330704
Validation loss: 2.4701239549110747

Epoch: 6| Step: 9
Training loss: 2.7805955952765653
Validation loss: 2.475691560978672

Epoch: 6| Step: 10
Training loss: 2.630166827085225
Validation loss: 2.474695217748208

Epoch: 6| Step: 11
Training loss: 2.9138304589878916
Validation loss: 2.472048523571709

Epoch: 6| Step: 12
Training loss: 3.0507420184437333
Validation loss: 2.475919012151298

Epoch: 6| Step: 13
Training loss: 2.003670304891587
Validation loss: 2.4730878456299847

Epoch: 117| Step: 0
Training loss: 2.2522933716156364
Validation loss: 2.4714512914794

Epoch: 6| Step: 1
Training loss: 2.6940257663698213
Validation loss: 2.4708585707826747

Epoch: 6| Step: 2
Training loss: 2.4183321727466844
Validation loss: 2.473879559249908

Epoch: 6| Step: 3
Training loss: 2.6092938621835056
Validation loss: 2.471134177339664

Epoch: 6| Step: 4
Training loss: 3.4911528895960937
Validation loss: 2.4823222126577407

Epoch: 6| Step: 5
Training loss: 1.8718986293212008
Validation loss: 2.475541113774328

Epoch: 6| Step: 6
Training loss: 2.3705535222971017
Validation loss: 2.4720130232428827

Epoch: 6| Step: 7
Training loss: 2.8706037661188395
Validation loss: 2.4732032239199975

Epoch: 6| Step: 8
Training loss: 2.395637592667729
Validation loss: 2.4728177034479257

Epoch: 6| Step: 9
Training loss: 2.32374437123192
Validation loss: 2.478411236171195

Epoch: 6| Step: 10
Training loss: 2.5349651435095897
Validation loss: 2.47640698703788

Epoch: 6| Step: 11
Training loss: 1.9550155644882619
Validation loss: 2.4767478608761064

Epoch: 6| Step: 12
Training loss: 2.454648850571963
Validation loss: 2.479181535393074

Epoch: 6| Step: 13
Training loss: 3.097916696766945
Validation loss: 2.4803216525138008

Epoch: 118| Step: 0
Training loss: 2.3630688784679013
Validation loss: 2.4845057678995053

Epoch: 6| Step: 1
Training loss: 2.777328040484975
Validation loss: 2.484836127713203

Epoch: 6| Step: 2
Training loss: 2.334687577938078
Validation loss: 2.4806595696369373

Epoch: 6| Step: 3
Training loss: 2.52046070549984
Validation loss: 2.4868865283802073

Epoch: 6| Step: 4
Training loss: 2.027349747665442
Validation loss: 2.4833169759514604

Epoch: 6| Step: 5
Training loss: 2.7092902815970192
Validation loss: 2.483498072653731

Epoch: 6| Step: 6
Training loss: 2.6034260624950383
Validation loss: 2.485982171118248

Epoch: 6| Step: 7
Training loss: 2.343100902955454
Validation loss: 2.488083428823972

Epoch: 6| Step: 8
Training loss: 2.781054372015222
Validation loss: 2.482624804998492

Epoch: 6| Step: 9
Training loss: 2.353055359720511
Validation loss: 2.481266340046592

Epoch: 6| Step: 10
Training loss: 2.666341930723519
Validation loss: 2.486820976192705

Epoch: 6| Step: 11
Training loss: 2.9836853189093837
Validation loss: 2.486570511775022

Epoch: 6| Step: 12
Training loss: 2.3209604713594407
Validation loss: 2.4780453034550325

Epoch: 6| Step: 13
Training loss: 2.8100934222836202
Validation loss: 2.4877758301308983

Epoch: 119| Step: 0
Training loss: 3.1091256353171906
Validation loss: 2.48479576466374

Epoch: 6| Step: 1
Training loss: 2.200575848555687
Validation loss: 2.4812721533310853

Epoch: 6| Step: 2
Training loss: 2.3321336886656137
Validation loss: 2.4850500217420373

Epoch: 6| Step: 3
Training loss: 2.5156168493292843
Validation loss: 2.4830350161165233

Epoch: 6| Step: 4
Training loss: 2.471654800657503
Validation loss: 2.4840007156160135

Epoch: 6| Step: 5
Training loss: 2.6659789589397134
Validation loss: 2.4804093000842045

Epoch: 6| Step: 6
Training loss: 2.745693562895704
Validation loss: 2.47926154609585

Epoch: 6| Step: 7
Training loss: 2.48602854084256
Validation loss: 2.4851318102341104

Epoch: 6| Step: 8
Training loss: 3.0569264043722164
Validation loss: 2.474873942880157

Epoch: 6| Step: 9
Training loss: 2.38503604389841
Validation loss: 2.475763747672123

Epoch: 6| Step: 10
Training loss: 2.6611088014971807
Validation loss: 2.4735403142763825

Epoch: 6| Step: 11
Training loss: 2.0233323942598096
Validation loss: 2.4699916212168884

Epoch: 6| Step: 12
Training loss: 2.315594947609634
Validation loss: 2.473087363603835

Epoch: 6| Step: 13
Training loss: 2.7707707868892735
Validation loss: 2.4709611318215714

Epoch: 120| Step: 0
Training loss: 2.3483544452368914
Validation loss: 2.465857714882382

Epoch: 6| Step: 1
Training loss: 2.8724584540939153
Validation loss: 2.4680137019155746

Epoch: 6| Step: 2
Training loss: 2.4440097446403466
Validation loss: 2.4672719176371527

Epoch: 6| Step: 3
Training loss: 2.378862953731618
Validation loss: 2.466659103094138

Epoch: 6| Step: 4
Training loss: 2.6233242680717344
Validation loss: 2.4668091093853834

Epoch: 6| Step: 5
Training loss: 2.6047181016100343
Validation loss: 2.465762749431248

Epoch: 6| Step: 6
Training loss: 2.184388263536605
Validation loss: 2.468263296446908

Epoch: 6| Step: 7
Training loss: 3.0601573469809114
Validation loss: 2.46484092877484

Epoch: 6| Step: 8
Training loss: 2.147480255498035
Validation loss: 2.4666229613616344

Epoch: 6| Step: 9
Training loss: 2.2681690533654617
Validation loss: 2.4663110749509065

Epoch: 6| Step: 10
Training loss: 2.620628167770731
Validation loss: 2.4692744571187424

Epoch: 6| Step: 11
Training loss: 2.534606497806783
Validation loss: 2.4696588734473646

Epoch: 6| Step: 12
Training loss: 3.26616711656979
Validation loss: 2.475192359872989

Epoch: 6| Step: 13
Training loss: 2.168583853126171
Validation loss: 2.4707702064705606

Epoch: 121| Step: 0
Training loss: 2.786836735115586
Validation loss: 2.465997714972591

Epoch: 6| Step: 1
Training loss: 2.9468675955136296
Validation loss: 2.46616485706526

Epoch: 6| Step: 2
Training loss: 2.0996413969215086
Validation loss: 2.463523208731821

Epoch: 6| Step: 3
Training loss: 2.6057589024802783
Validation loss: 2.468317750520563

Epoch: 6| Step: 4
Training loss: 2.3877941649399124
Validation loss: 2.4626307722245766

Epoch: 6| Step: 5
Training loss: 2.532289738865543
Validation loss: 2.467824287529706

Epoch: 6| Step: 6
Training loss: 2.327709391319503
Validation loss: 2.464694873567752

Epoch: 6| Step: 7
Training loss: 2.4163908855888336
Validation loss: 2.4649704035619373

Epoch: 6| Step: 8
Training loss: 2.2346671386951926
Validation loss: 2.4688519967814844

Epoch: 6| Step: 9
Training loss: 2.874429065571619
Validation loss: 2.4671620762847657

Epoch: 6| Step: 10
Training loss: 2.477569856553797
Validation loss: 2.4659340326757535

Epoch: 6| Step: 11
Training loss: 2.892606478802628
Validation loss: 2.466358233405245

Epoch: 6| Step: 12
Training loss: 2.7845840187267887
Validation loss: 2.4671719976400777

Epoch: 6| Step: 13
Training loss: 2.19469239514791
Validation loss: 2.466420277541633

Epoch: 122| Step: 0
Training loss: 2.9417463412495106
Validation loss: 2.465785060920153

Epoch: 6| Step: 1
Training loss: 2.9005193508366114
Validation loss: 2.465266252469865

Epoch: 6| Step: 2
Training loss: 2.6784146235753847
Validation loss: 2.469790798612389

Epoch: 6| Step: 3
Training loss: 2.8229540344993214
Validation loss: 2.466439175640254

Epoch: 6| Step: 4
Training loss: 2.8930497181085144
Validation loss: 2.469187106295634

Epoch: 6| Step: 5
Training loss: 2.4207479500171445
Validation loss: 2.470439236386044

Epoch: 6| Step: 6
Training loss: 1.7749341119706834
Validation loss: 2.473174705208328

Epoch: 6| Step: 7
Training loss: 1.9180092739322552
Validation loss: 2.470019822755414

Epoch: 6| Step: 8
Training loss: 2.709016234548145
Validation loss: 2.465739591681035

Epoch: 6| Step: 9
Training loss: 2.198301079807243
Validation loss: 2.4693263222194584

Epoch: 6| Step: 10
Training loss: 2.7404276969292893
Validation loss: 2.471779280592412

Epoch: 6| Step: 11
Training loss: 2.5400614020667946
Validation loss: 2.4702177392686626

Epoch: 6| Step: 12
Training loss: 2.53413020032365
Validation loss: 2.475661714636796

Epoch: 6| Step: 13
Training loss: 2.3125377342650872
Validation loss: 2.470720912783877

Epoch: 123| Step: 0
Training loss: 2.687161269021638
Validation loss: 2.4709068887793344

Epoch: 6| Step: 1
Training loss: 2.353309767968015
Validation loss: 2.4703775988049452

Epoch: 6| Step: 2
Training loss: 2.1420123206032713
Validation loss: 2.4725366355565517

Epoch: 6| Step: 3
Training loss: 2.8869954184379205
Validation loss: 2.4748408513646556

Epoch: 6| Step: 4
Training loss: 2.6306393311142586
Validation loss: 2.4719337022372234

Epoch: 6| Step: 5
Training loss: 2.184217114943568
Validation loss: 2.472714295391463

Epoch: 6| Step: 6
Training loss: 2.8048369386437373
Validation loss: 2.469187878755659

Epoch: 6| Step: 7
Training loss: 2.264314469769023
Validation loss: 2.4730450092060186

Epoch: 6| Step: 8
Training loss: 2.434627796998591
Validation loss: 2.4746205350468147

Epoch: 6| Step: 9
Training loss: 1.997143911483817
Validation loss: 2.4751748931948754

Epoch: 6| Step: 10
Training loss: 2.998048465492249
Validation loss: 2.475881103736132

Epoch: 6| Step: 11
Training loss: 1.9206575088406233
Validation loss: 2.4770637750989764

Epoch: 6| Step: 12
Training loss: 3.1055453692886936
Validation loss: 2.4721005233594764

Epoch: 6| Step: 13
Training loss: 2.7331831596182856
Validation loss: 2.4722689726572753

Epoch: 124| Step: 0
Training loss: 1.773255796828799
Validation loss: 2.48026791858407

Epoch: 6| Step: 1
Training loss: 2.730638665191062
Validation loss: 2.4771567593389903

Epoch: 6| Step: 2
Training loss: 2.509139710983308
Validation loss: 2.4773444175819566

Epoch: 6| Step: 3
Training loss: 2.594155337362756
Validation loss: 2.481535274271559

Epoch: 6| Step: 4
Training loss: 2.5897601590252357
Validation loss: 2.478279809978822

Epoch: 6| Step: 5
Training loss: 2.036555126130594
Validation loss: 2.478911127549919

Epoch: 6| Step: 6
Training loss: 2.70894424199724
Validation loss: 2.478342068735243

Epoch: 6| Step: 7
Training loss: 1.8140193227645172
Validation loss: 2.4815319596112526

Epoch: 6| Step: 8
Training loss: 3.166857429246358
Validation loss: 2.4792643188563646

Epoch: 6| Step: 9
Training loss: 2.530929450943
Validation loss: 2.483659013304871

Epoch: 6| Step: 10
Training loss: 2.5032555363939695
Validation loss: 2.483668244796509

Epoch: 6| Step: 11
Training loss: 2.232469720069097
Validation loss: 2.483319344150474

Epoch: 6| Step: 12
Training loss: 3.0288986052465106
Validation loss: 2.4850385487519633

Epoch: 6| Step: 13
Training loss: 2.8689790787996072
Validation loss: 2.4800913606243333

Epoch: 125| Step: 0
Training loss: 1.9001899448616564
Validation loss: 2.485913358195894

Epoch: 6| Step: 1
Training loss: 2.360781824923713
Validation loss: 2.485800759842401

Epoch: 6| Step: 2
Training loss: 2.8131758831433755
Validation loss: 2.484494236417961

Epoch: 6| Step: 3
Training loss: 2.60404231473936
Validation loss: 2.483333121263465

Epoch: 6| Step: 4
Training loss: 2.80056434121276
Validation loss: 2.489248585774305

Epoch: 6| Step: 5
Training loss: 2.0123682251431205
Validation loss: 2.4823226928906346

Epoch: 6| Step: 6
Training loss: 2.9286375071550643
Validation loss: 2.4832006914015756

Epoch: 6| Step: 7
Training loss: 2.377479463602896
Validation loss: 2.4831554690505686

Epoch: 6| Step: 8
Training loss: 2.6080980659957143
Validation loss: 2.481494609328582

Epoch: 6| Step: 9
Training loss: 2.8049221950082766
Validation loss: 2.4802126133954063

Epoch: 6| Step: 10
Training loss: 2.5863079255200665
Validation loss: 2.480201574639718

Epoch: 6| Step: 11
Training loss: 2.3996899841669306
Validation loss: 2.474689951013635

Epoch: 6| Step: 12
Training loss: 2.5606684768631958
Validation loss: 2.4786201937966488

Epoch: 6| Step: 13
Training loss: 2.702130437914391
Validation loss: 2.475077957312737

Epoch: 126| Step: 0
Training loss: 2.727375947559517
Validation loss: 2.478281766110857

Epoch: 6| Step: 1
Training loss: 2.3018773419722764
Validation loss: 2.471882920668459

Epoch: 6| Step: 2
Training loss: 2.310375165322943
Validation loss: 2.4742025368611675

Epoch: 6| Step: 3
Training loss: 2.4175084281387873
Validation loss: 2.472650898570557

Epoch: 6| Step: 4
Training loss: 2.5107716247423477
Validation loss: 2.4769819768815395

Epoch: 6| Step: 5
Training loss: 2.8337807769517545
Validation loss: 2.4706011965990005

Epoch: 6| Step: 6
Training loss: 2.112209083344136
Validation loss: 2.4758187108703176

Epoch: 6| Step: 7
Training loss: 2.9000506166447444
Validation loss: 2.4740217394818074

Epoch: 6| Step: 8
Training loss: 2.652826414167277
Validation loss: 2.4747450263727453

Epoch: 6| Step: 9
Training loss: 2.1416794901462692
Validation loss: 2.4765114282582714

Epoch: 6| Step: 10
Training loss: 2.5624733900223733
Validation loss: 2.474360918449975

Epoch: 6| Step: 11
Training loss: 2.992503973656281
Validation loss: 2.4711344507037234

Epoch: 6| Step: 12
Training loss: 2.26352589147214
Validation loss: 2.4727785422731214

Epoch: 6| Step: 13
Training loss: 2.6410075254842247
Validation loss: 2.4788805184730496

Epoch: 127| Step: 0
Training loss: 2.8714883338549093
Validation loss: 2.476949218336232

Epoch: 6| Step: 1
Training loss: 2.6598221041055137
Validation loss: 2.474911898833473

Epoch: 6| Step: 2
Training loss: 2.3436914055175597
Validation loss: 2.4768566674898365

Epoch: 6| Step: 3
Training loss: 2.1779676645994477
Validation loss: 2.477045118477207

Epoch: 6| Step: 4
Training loss: 2.8060356449084582
Validation loss: 2.4803264747326232

Epoch: 6| Step: 5
Training loss: 2.074134609433958
Validation loss: 2.476267158234467

Epoch: 6| Step: 6
Training loss: 2.1962224086011854
Validation loss: 2.4773856318380236

Epoch: 6| Step: 7
Training loss: 2.999683204454664
Validation loss: 2.476175127510213

Epoch: 6| Step: 8
Training loss: 2.4793545841408298
Validation loss: 2.47482188897222

Epoch: 6| Step: 9
Training loss: 2.535277659090874
Validation loss: 2.4746911713555706

Epoch: 6| Step: 10
Training loss: 2.7386629325645617
Validation loss: 2.4687491147325433

Epoch: 6| Step: 11
Training loss: 2.718982028925643
Validation loss: 2.4680831910017713

Epoch: 6| Step: 12
Training loss: 2.2046380224698177
Validation loss: 2.473721709061519

Epoch: 6| Step: 13
Training loss: 2.5772157857579296
Validation loss: 2.469309176120695

Epoch: 128| Step: 0
Training loss: 2.268439287919894
Validation loss: 2.464828370253375

Epoch: 6| Step: 1
Training loss: 3.3829261108772792
Validation loss: 2.4683970066201693

Epoch: 6| Step: 2
Training loss: 2.8294617249494824
Validation loss: 2.4673907082936957

Epoch: 6| Step: 3
Training loss: 2.4422363823057966
Validation loss: 2.467732988596416

Epoch: 6| Step: 4
Training loss: 2.4554997509253456
Validation loss: 2.470420561905512

Epoch: 6| Step: 5
Training loss: 2.6825377317478645
Validation loss: 2.465358045701031

Epoch: 6| Step: 6
Training loss: 2.1779533241952285
Validation loss: 2.4659004827881046

Epoch: 6| Step: 7
Training loss: 2.477040915504328
Validation loss: 2.4715736594506694

Epoch: 6| Step: 8
Training loss: 2.274983722502776
Validation loss: 2.467702305277693

Epoch: 6| Step: 9
Training loss: 2.605660450072687
Validation loss: 2.4686599103368323

Epoch: 6| Step: 10
Training loss: 2.1488885579420693
Validation loss: 2.467247332603803

Epoch: 6| Step: 11
Training loss: 2.6113688452205626
Validation loss: 2.469746400656164

Epoch: 6| Step: 12
Training loss: 2.704191405462851
Validation loss: 2.465353194204035

Epoch: 6| Step: 13
Training loss: 2.311648959711087
Validation loss: 2.4665205663079686

Epoch: 129| Step: 0
Training loss: 2.8360106403597793
Validation loss: 2.4662030920667872

Epoch: 6| Step: 1
Training loss: 2.691452845376318
Validation loss: 2.468771745288222

Epoch: 6| Step: 2
Training loss: 2.7926747414089794
Validation loss: 2.4690319817697692

Epoch: 6| Step: 3
Training loss: 2.8072618661028916
Validation loss: 2.4686270252615903

Epoch: 6| Step: 4
Training loss: 2.0790586740380306
Validation loss: 2.4772424416312058

Epoch: 6| Step: 5
Training loss: 2.315135793966919
Validation loss: 2.474389808907886

Epoch: 6| Step: 6
Training loss: 2.3284389616977403
Validation loss: 2.472782897116397

Epoch: 6| Step: 7
Training loss: 2.174950268056276
Validation loss: 2.4726779127251772

Epoch: 6| Step: 8
Training loss: 2.581514477053975
Validation loss: 2.4757555460214986

Epoch: 6| Step: 9
Training loss: 2.5653086830879372
Validation loss: 2.476988931198656

Epoch: 6| Step: 10
Training loss: 2.6252110714294314
Validation loss: 2.4748093008177463

Epoch: 6| Step: 11
Training loss: 2.881469082726211
Validation loss: 2.4712344677594094

Epoch: 6| Step: 12
Training loss: 2.480518538808874
Validation loss: 2.4741581939812587

Epoch: 6| Step: 13
Training loss: 2.183903817151378
Validation loss: 2.4810115670822848

Epoch: 130| Step: 0
Training loss: 2.885109913813114
Validation loss: 2.4776444663928947

Epoch: 6| Step: 1
Training loss: 2.412885557999678
Validation loss: 2.474494206800274

Epoch: 6| Step: 2
Training loss: 2.282055542740489
Validation loss: 2.471423267059031

Epoch: 6| Step: 3
Training loss: 2.207567214028956
Validation loss: 2.473882032857451

Epoch: 6| Step: 4
Training loss: 2.3478817950425936
Validation loss: 2.469944226462807

Epoch: 6| Step: 5
Training loss: 3.0028460036612104
Validation loss: 2.4702988284989598

Epoch: 6| Step: 6
Training loss: 2.453068629303559
Validation loss: 2.472928707625896

Epoch: 6| Step: 7
Training loss: 2.2507631279302887
Validation loss: 2.471315306561321

Epoch: 6| Step: 8
Training loss: 2.9551254036721053
Validation loss: 2.4706556795613284

Epoch: 6| Step: 9
Training loss: 2.4764578523397653
Validation loss: 2.4661990317407754

Epoch: 6| Step: 10
Training loss: 2.2227552556143206
Validation loss: 2.474655781195119

Epoch: 6| Step: 11
Training loss: 2.6520586043106666
Validation loss: 2.469028264068956

Epoch: 6| Step: 12
Training loss: 2.7289560736632685
Validation loss: 2.465485970268387

Epoch: 6| Step: 13
Training loss: 2.320734159130148
Validation loss: 2.468210700640104

Epoch: 131| Step: 0
Training loss: 2.2728864388651386
Validation loss: 2.4637552266909792

Epoch: 6| Step: 1
Training loss: 2.2804911148108964
Validation loss: 2.4659036895454145

Epoch: 6| Step: 2
Training loss: 2.5765572144758933
Validation loss: 2.46770812636171

Epoch: 6| Step: 3
Training loss: 2.8926813183187994
Validation loss: 2.4638225215210245

Epoch: 6| Step: 4
Training loss: 2.54817138629654
Validation loss: 2.4622348010041777

Epoch: 6| Step: 5
Training loss: 2.2731455192657184
Validation loss: 2.4631327853644014

Epoch: 6| Step: 6
Training loss: 3.1016916397076018
Validation loss: 2.4637818706637455

Epoch: 6| Step: 7
Training loss: 2.54827580222569
Validation loss: 2.4679134577246673

Epoch: 6| Step: 8
Training loss: 2.0984990932489
Validation loss: 2.4717839908685053

Epoch: 6| Step: 9
Training loss: 2.289764713210511
Validation loss: 2.476284601161405

Epoch: 6| Step: 10
Training loss: 2.2359649763145164
Validation loss: 2.4811646934469485

Epoch: 6| Step: 11
Training loss: 2.6804316518957574
Validation loss: 2.4798231190750704

Epoch: 6| Step: 12
Training loss: 2.8385075465026923
Validation loss: 2.4832194857988252

Epoch: 6| Step: 13
Training loss: 2.7202665111460305
Validation loss: 2.4784829187903137

Epoch: 132| Step: 0
Training loss: 2.268243368449608
Validation loss: 2.4770481183046336

Epoch: 6| Step: 1
Training loss: 2.2366820475944387
Validation loss: 2.473567832779035

Epoch: 6| Step: 2
Training loss: 2.749687177031817
Validation loss: 2.466481659583952

Epoch: 6| Step: 3
Training loss: 3.305708058006712
Validation loss: 2.466496585983552

Epoch: 6| Step: 4
Training loss: 2.4553964388786804
Validation loss: 2.464616590733918

Epoch: 6| Step: 5
Training loss: 2.3720061857712165
Validation loss: 2.4598580066670244

Epoch: 6| Step: 6
Training loss: 2.693800704018616
Validation loss: 2.4576647113230217

Epoch: 6| Step: 7
Training loss: 2.7570113188103416
Validation loss: 2.468005434258515

Epoch: 6| Step: 8
Training loss: 2.548782663926473
Validation loss: 2.456191444507893

Epoch: 6| Step: 9
Training loss: 2.5192130900740977
Validation loss: 2.457899012157589

Epoch: 6| Step: 10
Training loss: 2.7582073847509947
Validation loss: 2.4612808876043304

Epoch: 6| Step: 11
Training loss: 2.52405495662679
Validation loss: 2.4662856989147603

Epoch: 6| Step: 12
Training loss: 2.0997737944342885
Validation loss: 2.464434574138198

Epoch: 6| Step: 13
Training loss: 2.2381044221436466
Validation loss: 2.4673669538408767

Epoch: 133| Step: 0
Training loss: 2.4609446691983865
Validation loss: 2.4610684798973272

Epoch: 6| Step: 1
Training loss: 2.7106178820839615
Validation loss: 2.4621581748819925

Epoch: 6| Step: 2
Training loss: 2.6379480279715155
Validation loss: 2.4635920502643147

Epoch: 6| Step: 3
Training loss: 2.02876117526941
Validation loss: 2.469553144809039

Epoch: 6| Step: 4
Training loss: 2.2380527559459398
Validation loss: 2.462338027855468

Epoch: 6| Step: 5
Training loss: 2.566366674388067
Validation loss: 2.4676328779294217

Epoch: 6| Step: 6
Training loss: 2.3889737878050443
Validation loss: 2.464001349910143

Epoch: 6| Step: 7
Training loss: 2.5775317810052867
Validation loss: 2.46790131737116

Epoch: 6| Step: 8
Training loss: 2.968105045331049
Validation loss: 2.469703007499376

Epoch: 6| Step: 9
Training loss: 3.11671891670152
Validation loss: 2.4767647228450898

Epoch: 6| Step: 10
Training loss: 2.279760004763942
Validation loss: 2.4769270956455185

Epoch: 6| Step: 11
Training loss: 2.2084601983630825
Validation loss: 2.476665699249667

Epoch: 6| Step: 12
Training loss: 2.5601715115373715
Validation loss: 2.474341261825525

Epoch: 6| Step: 13
Training loss: 2.651347134621451
Validation loss: 2.4731413820829737

Epoch: 134| Step: 0
Training loss: 3.0177753272941628
Validation loss: 2.4777808015697524

Epoch: 6| Step: 1
Training loss: 2.4837687970368316
Validation loss: 2.4745898006380607

Epoch: 6| Step: 2
Training loss: 2.617061236168344
Validation loss: 2.47334785290935

Epoch: 6| Step: 3
Training loss: 2.2167867651889512
Validation loss: 2.462969987171942

Epoch: 6| Step: 4
Training loss: 2.057514986560699
Validation loss: 2.4633117364169834

Epoch: 6| Step: 5
Training loss: 2.3101028183352614
Validation loss: 2.4631920392349995

Epoch: 6| Step: 6
Training loss: 2.485581590840776
Validation loss: 2.4670480583652874

Epoch: 6| Step: 7
Training loss: 3.081654031197072
Validation loss: 2.4690803355113666

Epoch: 6| Step: 8
Training loss: 2.639561997838996
Validation loss: 2.4584946875771796

Epoch: 6| Step: 9
Training loss: 2.5904310202133156
Validation loss: 2.454872739825178

Epoch: 6| Step: 10
Training loss: 2.4865433928621035
Validation loss: 2.4576518089307178

Epoch: 6| Step: 11
Training loss: 2.751748309557993
Validation loss: 2.4614739211841754

Epoch: 6| Step: 12
Training loss: 2.607971910617955
Validation loss: 2.4639105786063307

Epoch: 6| Step: 13
Training loss: 1.921648958140574
Validation loss: 2.4659738826456667

Epoch: 135| Step: 0
Training loss: 2.440252266334784
Validation loss: 2.463119072721871

Epoch: 6| Step: 1
Training loss: 2.6808869371716257
Validation loss: 2.463273117773084

Epoch: 6| Step: 2
Training loss: 2.259710972289087
Validation loss: 2.4544598132851014

Epoch: 6| Step: 3
Training loss: 2.2755440197758205
Validation loss: 2.4544828993760515

Epoch: 6| Step: 4
Training loss: 2.3681440277825208
Validation loss: 2.452733828706615

Epoch: 6| Step: 5
Training loss: 2.678973400290057
Validation loss: 2.4479063209693837

Epoch: 6| Step: 6
Training loss: 2.119216791005935
Validation loss: 2.45404202436711

Epoch: 6| Step: 7
Training loss: 2.050736141617
Validation loss: 2.4546388624112963

Epoch: 6| Step: 8
Training loss: 2.5139173315229453
Validation loss: 2.458615987228845

Epoch: 6| Step: 9
Training loss: 2.6728531681009975
Validation loss: 2.4504188302864116

Epoch: 6| Step: 10
Training loss: 2.752498185575547
Validation loss: 2.4530634619249048

Epoch: 6| Step: 11
Training loss: 2.5713397816814614
Validation loss: 2.4580264034586143

Epoch: 6| Step: 12
Training loss: 3.409668073636419
Validation loss: 2.458391509472264

Epoch: 6| Step: 13
Training loss: 2.3864656055017166
Validation loss: 2.456232544543338

Epoch: 136| Step: 0
Training loss: 2.826341604159575
Validation loss: 2.4603485694482057

Epoch: 6| Step: 1
Training loss: 2.278858551269011
Validation loss: 2.461716172485229

Epoch: 6| Step: 2
Training loss: 2.7675779527059756
Validation loss: 2.4650750149963643

Epoch: 6| Step: 3
Training loss: 2.7093928880991993
Validation loss: 2.4668222135610165

Epoch: 6| Step: 4
Training loss: 2.453662983405181
Validation loss: 2.4670810128074194

Epoch: 6| Step: 5
Training loss: 2.4835474327354756
Validation loss: 2.4696715361233545

Epoch: 6| Step: 6
Training loss: 2.3732566458210105
Validation loss: 2.469006183063917

Epoch: 6| Step: 7
Training loss: 2.883803447993666
Validation loss: 2.472046626804523

Epoch: 6| Step: 8
Training loss: 2.7358441574931414
Validation loss: 2.4781786020903005

Epoch: 6| Step: 9
Training loss: 2.530433711545151
Validation loss: 2.4722634275148074

Epoch: 6| Step: 10
Training loss: 2.7499793658782874
Validation loss: 2.4766737534878134

Epoch: 6| Step: 11
Training loss: 2.379904952355214
Validation loss: 2.47271575775776

Epoch: 6| Step: 12
Training loss: 2.1022625859646267
Validation loss: 2.473318596827707

Epoch: 6| Step: 13
Training loss: 2.1437769051245312
Validation loss: 2.465398936510655

Epoch: 137| Step: 0
Training loss: 2.3292575615996274
Validation loss: 2.4748524438818644

Epoch: 6| Step: 1
Training loss: 2.545538241385207
Validation loss: 2.464955306715152

Epoch: 6| Step: 2
Training loss: 2.335647207740998
Validation loss: 2.4565236548261815

Epoch: 6| Step: 3
Training loss: 2.150405592697398
Validation loss: 2.458155647149504

Epoch: 6| Step: 4
Training loss: 2.9330677114501076
Validation loss: 2.4643949572646506

Epoch: 6| Step: 5
Training loss: 2.251284550513411
Validation loss: 2.4604310337027258

Epoch: 6| Step: 6
Training loss: 2.275351855557587
Validation loss: 2.468154996482139

Epoch: 6| Step: 7
Training loss: 1.9848771548754067
Validation loss: 2.461451457613074

Epoch: 6| Step: 8
Training loss: 2.9844748595142754
Validation loss: 2.47346350021015

Epoch: 6| Step: 9
Training loss: 2.4097846686058593
Validation loss: 2.471773219916794

Epoch: 6| Step: 10
Training loss: 2.632970425994215
Validation loss: 2.476873544761069

Epoch: 6| Step: 11
Training loss: 3.2145212783477097
Validation loss: 2.485051636751021

Epoch: 6| Step: 12
Training loss: 2.70210714415503
Validation loss: 2.471648128754679

Epoch: 6| Step: 13
Training loss: 2.539607062996917
Validation loss: 2.465925492161688

Epoch: 138| Step: 0
Training loss: 2.8074316344934807
Validation loss: 2.462472798024568

Epoch: 6| Step: 1
Training loss: 1.8527762382357313
Validation loss: 2.467285107934024

Epoch: 6| Step: 2
Training loss: 2.3282040576184753
Validation loss: 2.464378139652836

Epoch: 6| Step: 3
Training loss: 2.641035149678004
Validation loss: 2.469816725877414

Epoch: 6| Step: 4
Training loss: 2.544365330909417
Validation loss: 2.4699685192032512

Epoch: 6| Step: 5
Training loss: 2.2246376685536133
Validation loss: 2.470123206874012

Epoch: 6| Step: 6
Training loss: 2.666530595725133
Validation loss: 2.4768827213279625

Epoch: 6| Step: 7
Training loss: 2.180270209408723
Validation loss: 2.4738236454221836

Epoch: 6| Step: 8
Training loss: 2.849202389117065
Validation loss: 2.474342747319347

Epoch: 6| Step: 9
Training loss: 2.6773559391934194
Validation loss: 2.473832222919934

Epoch: 6| Step: 10
Training loss: 2.6087180584138787
Validation loss: 2.4760354701697382

Epoch: 6| Step: 11
Training loss: 2.555406754994531
Validation loss: 2.4706615982285025

Epoch: 6| Step: 12
Training loss: 2.9607519730794323
Validation loss: 2.47293491008642

Epoch: 6| Step: 13
Training loss: 2.778514331016631
Validation loss: 2.473236642611549

Epoch: 139| Step: 0
Training loss: 2.065904293136756
Validation loss: 2.47270846198763

Epoch: 6| Step: 1
Training loss: 2.1301328712534193
Validation loss: 2.4695577145165832

Epoch: 6| Step: 2
Training loss: 2.6291180960334635
Validation loss: 2.4704220417144596

Epoch: 6| Step: 3
Training loss: 1.7681303900282235
Validation loss: 2.4640286040328148

Epoch: 6| Step: 4
Training loss: 2.711872126605676
Validation loss: 2.4771580987742046

Epoch: 6| Step: 5
Training loss: 2.8808683130157955
Validation loss: 2.4695254045719173

Epoch: 6| Step: 6
Training loss: 2.854343009754431
Validation loss: 2.465661865783916

Epoch: 6| Step: 7
Training loss: 3.50347264901797
Validation loss: 2.46912838253331

Epoch: 6| Step: 8
Training loss: 2.8605034274404284
Validation loss: 2.471353502075835

Epoch: 6| Step: 9
Training loss: 2.317834012056577
Validation loss: 2.46572118780238

Epoch: 6| Step: 10
Training loss: 2.8491598798372166
Validation loss: 2.4735866602063368

Epoch: 6| Step: 11
Training loss: 2.5034857291181902
Validation loss: 2.464045262765271

Epoch: 6| Step: 12
Training loss: 1.6464842301953524
Validation loss: 2.470869900549169

Epoch: 6| Step: 13
Training loss: 2.1480402908737632
Validation loss: 2.467222231941974

Epoch: 140| Step: 0
Training loss: 2.4403099100883456
Validation loss: 2.463530386535326

Epoch: 6| Step: 1
Training loss: 2.656904072733712
Validation loss: 2.4706240434015085

Epoch: 6| Step: 2
Training loss: 2.3192535964002046
Validation loss: 2.466701478540648

Epoch: 6| Step: 3
Training loss: 2.2601271647570638
Validation loss: 2.4686702280797497

Epoch: 6| Step: 4
Training loss: 2.5463748745080483
Validation loss: 2.462545767550831

Epoch: 6| Step: 5
Training loss: 2.0473160596114894
Validation loss: 2.4667696434082456

Epoch: 6| Step: 6
Training loss: 2.3287865639650516
Validation loss: 2.4715463920631393

Epoch: 6| Step: 7
Training loss: 2.2387215545738544
Validation loss: 2.471460423866727

Epoch: 6| Step: 8
Training loss: 2.286605922885692
Validation loss: 2.470436244618297

Epoch: 6| Step: 9
Training loss: 2.94837399946524
Validation loss: 2.4756544917519356

Epoch: 6| Step: 10
Training loss: 2.7413165238949855
Validation loss: 2.4766697584606123

Epoch: 6| Step: 11
Training loss: 3.303638336800198
Validation loss: 2.4767088581083643

Epoch: 6| Step: 12
Training loss: 2.713525861131517
Validation loss: 2.4730283307577428

Epoch: 6| Step: 13
Training loss: 2.395995844982283
Validation loss: 2.476986548926133

Epoch: 141| Step: 0
Training loss: 2.3482949503606143
Validation loss: 2.4729743098091648

Epoch: 6| Step: 1
Training loss: 2.3142316366198368
Validation loss: 2.4766779169731588

Epoch: 6| Step: 2
Training loss: 2.354921293138053
Validation loss: 2.470748141033211

Epoch: 6| Step: 3
Training loss: 2.815914878360646
Validation loss: 2.4760481564045294

Epoch: 6| Step: 4
Training loss: 2.0655157986629797
Validation loss: 2.473213787810007

Epoch: 6| Step: 5
Training loss: 2.7881227079996465
Validation loss: 2.4687982385485703

Epoch: 6| Step: 6
Training loss: 2.9308501924607087
Validation loss: 2.473584844940152

Epoch: 6| Step: 7
Training loss: 2.2706972367220017
Validation loss: 2.4676137957345543

Epoch: 6| Step: 8
Training loss: 1.9688359801878683
Validation loss: 2.47501388250497

Epoch: 6| Step: 9
Training loss: 2.432970386593017
Validation loss: 2.4751297168583033

Epoch: 6| Step: 10
Training loss: 2.8311272802977427
Validation loss: 2.476279081057981

Epoch: 6| Step: 11
Training loss: 3.069063587831367
Validation loss: 2.4818104236776657

Epoch: 6| Step: 12
Training loss: 2.486790760087054
Validation loss: 2.4750522697914623

Epoch: 6| Step: 13
Training loss: 2.376893242588699
Validation loss: 2.4738142968795285

Epoch: 142| Step: 0
Training loss: 2.342781985968147
Validation loss: 2.473323529096367

Epoch: 6| Step: 1
Training loss: 2.3027964964585044
Validation loss: 2.465695596191139

Epoch: 6| Step: 2
Training loss: 2.3392384148894134
Validation loss: 2.4632271585394316

Epoch: 6| Step: 3
Training loss: 2.997196158821295
Validation loss: 2.460898537302136

Epoch: 6| Step: 4
Training loss: 2.5153340236535815
Validation loss: 2.458665232694515

Epoch: 6| Step: 5
Training loss: 2.5939750114184372
Validation loss: 2.4610843513714085

Epoch: 6| Step: 6
Training loss: 2.465622864928971
Validation loss: 2.464073048570849

Epoch: 6| Step: 7
Training loss: 2.1810635287526767
Validation loss: 2.459433718816092

Epoch: 6| Step: 8
Training loss: 1.7294143667865516
Validation loss: 2.4609960155493558

Epoch: 6| Step: 9
Training loss: 2.762269220162912
Validation loss: 2.4571539318061153

Epoch: 6| Step: 10
Training loss: 2.7878516210644673
Validation loss: 2.4680652393052576

Epoch: 6| Step: 11
Training loss: 3.0142831930202925
Validation loss: 2.4623480574048546

Epoch: 6| Step: 12
Training loss: 2.336243472266224
Validation loss: 2.4603086445152877

Epoch: 6| Step: 13
Training loss: 2.6255360010686797
Validation loss: 2.4609123269060147

Epoch: 143| Step: 0
Training loss: 2.3433842691535376
Validation loss: 2.463182359963398

Epoch: 6| Step: 1
Training loss: 2.791080717017817
Validation loss: 2.4596460253660233

Epoch: 6| Step: 2
Training loss: 2.1352992948204457
Validation loss: 2.458543709196297

Epoch: 6| Step: 3
Training loss: 2.649480563663879
Validation loss: 2.461667488457868

Epoch: 6| Step: 4
Training loss: 2.52918328578795
Validation loss: 2.466931216341402

Epoch: 6| Step: 5
Training loss: 1.8202426880641294
Validation loss: 2.46411460574639

Epoch: 6| Step: 6
Training loss: 2.825371344811861
Validation loss: 2.4641266518746314

Epoch: 6| Step: 7
Training loss: 2.6373443991516026
Validation loss: 2.4664515326307073

Epoch: 6| Step: 8
Training loss: 2.452890761545188
Validation loss: 2.466769200419204

Epoch: 6| Step: 9
Training loss: 2.5203971380317105
Validation loss: 2.463031148670451

Epoch: 6| Step: 10
Training loss: 2.752858237117075
Validation loss: 2.4645634656563766

Epoch: 6| Step: 11
Training loss: 2.579452912485179
Validation loss: 2.4746520719430105

Epoch: 6| Step: 12
Training loss: 2.6388186082906375
Validation loss: 2.4674718099089836

Epoch: 6| Step: 13
Training loss: 2.5093248032125253
Validation loss: 2.4657906770341653

Epoch: 144| Step: 0
Training loss: 3.291418396162018
Validation loss: 2.465718399812284

Epoch: 6| Step: 1
Training loss: 2.2943464621044893
Validation loss: 2.4595304473131816

Epoch: 6| Step: 2
Training loss: 2.6044845895617055
Validation loss: 2.464019266707575

Epoch: 6| Step: 3
Training loss: 1.781390669772712
Validation loss: 2.4642252360136765

Epoch: 6| Step: 4
Training loss: 2.712900643711252
Validation loss: 2.4620730409155827

Epoch: 6| Step: 5
Training loss: 2.6651250336822683
Validation loss: 2.463683357492252

Epoch: 6| Step: 6
Training loss: 2.2621894834098444
Validation loss: 2.4637451786772764

Epoch: 6| Step: 7
Training loss: 2.7560536770956974
Validation loss: 2.458837155799926

Epoch: 6| Step: 8
Training loss: 2.5628808831714522
Validation loss: 2.4695795492348456

Epoch: 6| Step: 9
Training loss: 2.039508639231997
Validation loss: 2.4612810974843033

Epoch: 6| Step: 10
Training loss: 2.2469134883210398
Validation loss: 2.468677793324067

Epoch: 6| Step: 11
Training loss: 2.4876245323714743
Validation loss: 2.468834839340915

Epoch: 6| Step: 12
Training loss: 2.6491941198330684
Validation loss: 2.4645288974643758

Epoch: 6| Step: 13
Training loss: 2.6236011774420187
Validation loss: 2.461041903425676

Epoch: 145| Step: 0
Training loss: 1.996094944425401
Validation loss: 2.465294685365489

Epoch: 6| Step: 1
Training loss: 3.239312719754347
Validation loss: 2.4615413025960358

Epoch: 6| Step: 2
Training loss: 2.553381536475305
Validation loss: 2.470779663026244

Epoch: 6| Step: 3
Training loss: 2.6612831451229733
Validation loss: 2.468603347092292

Epoch: 6| Step: 4
Training loss: 1.9676185262961425
Validation loss: 2.473471588973018

Epoch: 6| Step: 5
Training loss: 2.14938433503977
Validation loss: 2.475600592314653

Epoch: 6| Step: 6
Training loss: 2.2801480701953065
Validation loss: 2.4768633414055152

Epoch: 6| Step: 7
Training loss: 2.6048268409625477
Validation loss: 2.477258530290534

Epoch: 6| Step: 8
Training loss: 2.7886362471350488
Validation loss: 2.4740356326157125

Epoch: 6| Step: 9
Training loss: 1.990164893138225
Validation loss: 2.4696593883223685

Epoch: 6| Step: 10
Training loss: 3.0325201460632205
Validation loss: 2.4719517062149676

Epoch: 6| Step: 11
Training loss: 2.4163682906890576
Validation loss: 2.4709616142624986

Epoch: 6| Step: 12
Training loss: 3.017203752818651
Validation loss: 2.464449569369851

Epoch: 6| Step: 13
Training loss: 2.2836509506886773
Validation loss: 2.4650194817805513

Epoch: 146| Step: 0
Training loss: 2.518051304234697
Validation loss: 2.459173145274883

Epoch: 6| Step: 1
Training loss: 2.917522595472531
Validation loss: 2.4550068758203336

Epoch: 6| Step: 2
Training loss: 2.146418840346823
Validation loss: 2.4590193443245894

Epoch: 6| Step: 3
Training loss: 2.9246064337023574
Validation loss: 2.4622521174027936

Epoch: 6| Step: 4
Training loss: 2.111657158464655
Validation loss: 2.4613501954563586

Epoch: 6| Step: 5
Training loss: 1.7676245920385687
Validation loss: 2.464971217644481

Epoch: 6| Step: 6
Training loss: 2.6181807270252477
Validation loss: 2.467849575287696

Epoch: 6| Step: 7
Training loss: 2.6008316250589423
Validation loss: 2.4710437082551784

Epoch: 6| Step: 8
Training loss: 2.0130199779460978
Validation loss: 2.469360340499394

Epoch: 6| Step: 9
Training loss: 2.2358039608150553
Validation loss: 2.472972927937178

Epoch: 6| Step: 10
Training loss: 2.7356486814544563
Validation loss: 2.470291622105007

Epoch: 6| Step: 11
Training loss: 1.826131140922704
Validation loss: 2.47430870921268

Epoch: 6| Step: 12
Training loss: 3.2449584885397518
Validation loss: 2.4678801199131435

Epoch: 6| Step: 13
Training loss: 3.113488318474528
Validation loss: 2.4692093627032867

Epoch: 147| Step: 0
Training loss: 3.097028440182905
Validation loss: 2.463825642279212

Epoch: 6| Step: 1
Training loss: 2.8240732073710166
Validation loss: 2.464386475913881

Epoch: 6| Step: 2
Training loss: 2.228425006545238
Validation loss: 2.469484099360682

Epoch: 6| Step: 3
Training loss: 3.1958801213055317
Validation loss: 2.472880228272807

Epoch: 6| Step: 4
Training loss: 2.3574831621978527
Validation loss: 2.4704337032213437

Epoch: 6| Step: 5
Training loss: 2.3843054925029197
Validation loss: 2.4684347281364167

Epoch: 6| Step: 6
Training loss: 2.778569247552784
Validation loss: 2.468724391498617

Epoch: 6| Step: 7
Training loss: 2.091948688030969
Validation loss: 2.457065050370734

Epoch: 6| Step: 8
Training loss: 2.461395608557753
Validation loss: 2.4661444906024976

Epoch: 6| Step: 9
Training loss: 2.020966305896838
Validation loss: 2.4643927643706713

Epoch: 6| Step: 10
Training loss: 2.737559616624181
Validation loss: 2.457449355381331

Epoch: 6| Step: 11
Training loss: 2.482572849583917
Validation loss: 2.459662406831192

Epoch: 6| Step: 12
Training loss: 2.112787721440936
Validation loss: 2.4640335226441445

Epoch: 6| Step: 13
Training loss: 2.315502588740586
Validation loss: 2.454644123603099

Epoch: 148| Step: 0
Training loss: 2.6993508865540683
Validation loss: 2.4595836810999727

Epoch: 6| Step: 1
Training loss: 2.5590599974753836
Validation loss: 2.4565149117479246

Epoch: 6| Step: 2
Training loss: 2.9008412226264917
Validation loss: 2.454363775406529

Epoch: 6| Step: 3
Training loss: 2.711272820833506
Validation loss: 2.4573065396826754

Epoch: 6| Step: 4
Training loss: 2.6539862467129893
Validation loss: 2.4578335356332546

Epoch: 6| Step: 5
Training loss: 2.3361212106376277
Validation loss: 2.4554487427638674

Epoch: 6| Step: 6
Training loss: 2.654951428904821
Validation loss: 2.4574330723530196

Epoch: 6| Step: 7
Training loss: 2.417282574096331
Validation loss: 2.4566397625430376

Epoch: 6| Step: 8
Training loss: 2.048942860899006
Validation loss: 2.4556746141368886

Epoch: 6| Step: 9
Training loss: 1.791826802867227
Validation loss: 2.460812245567214

Epoch: 6| Step: 10
Training loss: 2.336538180175842
Validation loss: 2.4616217252399317

Epoch: 6| Step: 11
Training loss: 2.4989812682672095
Validation loss: 2.4606400405905995

Epoch: 6| Step: 12
Training loss: 2.897018866891362
Validation loss: 2.465816146796708

Epoch: 6| Step: 13
Training loss: 2.535227441008562
Validation loss: 2.467050039509876

Epoch: 149| Step: 0
Training loss: 2.084733594162662
Validation loss: 2.466175652511336

Epoch: 6| Step: 1
Training loss: 3.0623003836211704
Validation loss: 2.4627860579248804

Epoch: 6| Step: 2
Training loss: 1.8837224890225774
Validation loss: 2.465419937715289

Epoch: 6| Step: 3
Training loss: 2.3153257889687406
Validation loss: 2.4646111251111082

Epoch: 6| Step: 4
Training loss: 2.3146995187938946
Validation loss: 2.454810144835709

Epoch: 6| Step: 5
Training loss: 2.7807640765601285
Validation loss: 2.46016353970729

Epoch: 6| Step: 6
Training loss: 2.980821661097583
Validation loss: 2.4631171045480897

Epoch: 6| Step: 7
Training loss: 2.4682211007569155
Validation loss: 2.4560778637621086

Epoch: 6| Step: 8
Training loss: 2.3099890815179576
Validation loss: 2.4629801351489844

Epoch: 6| Step: 9
Training loss: 2.4293972222224767
Validation loss: 2.463251719170239

Epoch: 6| Step: 10
Training loss: 2.093091946714215
Validation loss: 2.462073307215991

Epoch: 6| Step: 11
Training loss: 2.6867155660181683
Validation loss: 2.467239078484285

Epoch: 6| Step: 12
Training loss: 2.267824985889779
Validation loss: 2.465986934861355

Epoch: 6| Step: 13
Training loss: 3.229320612693616
Validation loss: 2.464646127459245

Epoch: 150| Step: 0
Training loss: 2.1502675533156994
Validation loss: 2.461876793891645

Epoch: 6| Step: 1
Training loss: 2.5504424964092474
Validation loss: 2.4704246796325586

Epoch: 6| Step: 2
Training loss: 2.6101542696906774
Validation loss: 2.4601351121172246

Epoch: 6| Step: 3
Training loss: 2.440507842511044
Validation loss: 2.460634380423142

Epoch: 6| Step: 4
Training loss: 2.3326887421124414
Validation loss: 2.453294444458375

Epoch: 6| Step: 5
Training loss: 2.4883807056139493
Validation loss: 2.456076593724788

Epoch: 6| Step: 6
Training loss: 2.2645071494709135
Validation loss: 2.4610723226440845

Epoch: 6| Step: 7
Training loss: 2.7476728302707825
Validation loss: 2.45257519272622

Epoch: 6| Step: 8
Training loss: 2.0589283159180436
Validation loss: 2.4600869136798162

Epoch: 6| Step: 9
Training loss: 2.546270286992362
Validation loss: 2.4579387498988647

Epoch: 6| Step: 10
Training loss: 2.4273482957103094
Validation loss: 2.459938435882556

Epoch: 6| Step: 11
Training loss: 3.0657065595535316
Validation loss: 2.4621589656860805

Epoch: 6| Step: 12
Training loss: 2.641652736767485
Validation loss: 2.4601213666135306

Epoch: 6| Step: 13
Training loss: 2.794813365949197
Validation loss: 2.466761403799059

Epoch: 151| Step: 0
Training loss: 2.7083978107308893
Validation loss: 2.464888760195548

Epoch: 6| Step: 1
Training loss: 2.653012445621221
Validation loss: 2.4641741101442043

Epoch: 6| Step: 2
Training loss: 2.8413587304526735
Validation loss: 2.4662554809514563

Epoch: 6| Step: 3
Training loss: 2.6407746944094455
Validation loss: 2.4671415167258544

Epoch: 6| Step: 4
Training loss: 2.2787889766236997
Validation loss: 2.460642034968898

Epoch: 6| Step: 5
Training loss: 2.291038103310443
Validation loss: 2.4605445184740264

Epoch: 6| Step: 6
Training loss: 2.1382472065176232
Validation loss: 2.459240137302065

Epoch: 6| Step: 7
Training loss: 2.9086108719257493
Validation loss: 2.4574134258544826

Epoch: 6| Step: 8
Training loss: 2.4785123543984526
Validation loss: 2.4582255038088334

Epoch: 6| Step: 9
Training loss: 2.5876819454483893
Validation loss: 2.45557936814597

Epoch: 6| Step: 10
Training loss: 2.083199178826775
Validation loss: 2.4558002438714497

Epoch: 6| Step: 11
Training loss: 2.3469965510885467
Validation loss: 2.4611411035670168

Epoch: 6| Step: 12
Training loss: 2.741543338247324
Validation loss: 2.4505905860327166

Epoch: 6| Step: 13
Training loss: 2.3294673864305033
Validation loss: 2.452410859235569

Epoch: 152| Step: 0
Training loss: 2.4539635069542363
Validation loss: 2.451597527860944

Epoch: 6| Step: 1
Training loss: 2.747729317672729
Validation loss: 2.452215362166271

Epoch: 6| Step: 2
Training loss: 2.453050357144651
Validation loss: 2.4573050196339956

Epoch: 6| Step: 3
Training loss: 2.511136712822426
Validation loss: 2.4550466441885375

Epoch: 6| Step: 4
Training loss: 2.159550669876528
Validation loss: 2.46021436128199

Epoch: 6| Step: 5
Training loss: 2.999720401450349
Validation loss: 2.4570056002217573

Epoch: 6| Step: 6
Training loss: 2.8522282907464085
Validation loss: 2.457840940226443

Epoch: 6| Step: 7
Training loss: 1.3608659920371977
Validation loss: 2.454503370696516

Epoch: 6| Step: 8
Training loss: 1.7960740667843418
Validation loss: 2.45651580951225

Epoch: 6| Step: 9
Training loss: 2.4007980212027085
Validation loss: 2.4604784340551906

Epoch: 6| Step: 10
Training loss: 2.3122735814778896
Validation loss: 2.4596699755482203

Epoch: 6| Step: 11
Training loss: 3.0275472461847492
Validation loss: 2.4595092665695555

Epoch: 6| Step: 12
Training loss: 3.074908594773337
Validation loss: 2.4584788963628075

Epoch: 6| Step: 13
Training loss: 2.4592061082949006
Validation loss: 2.4640501813433473

Epoch: 153| Step: 0
Training loss: 1.888727922998508
Validation loss: 2.4544402239352454

Epoch: 6| Step: 1
Training loss: 3.101694868131402
Validation loss: 2.460580450728123

Epoch: 6| Step: 2
Training loss: 2.9642222359930215
Validation loss: 2.4609943686075586

Epoch: 6| Step: 3
Training loss: 2.1655248665607307
Validation loss: 2.4579150172649085

Epoch: 6| Step: 4
Training loss: 2.589776361891941
Validation loss: 2.467359795250759

Epoch: 6| Step: 5
Training loss: 2.6711433702821066
Validation loss: 2.464128167715246

Epoch: 6| Step: 6
Training loss: 2.0330028307022974
Validation loss: 2.4715189635974215

Epoch: 6| Step: 7
Training loss: 2.226071808937745
Validation loss: 2.4644933130028193

Epoch: 6| Step: 8
Training loss: 2.5766963815229977
Validation loss: 2.47576910842321

Epoch: 6| Step: 9
Training loss: 2.6875935028133897
Validation loss: 2.4729340905912323

Epoch: 6| Step: 10
Training loss: 2.513764066272686
Validation loss: 2.4727881357737918

Epoch: 6| Step: 11
Training loss: 2.681954184229733
Validation loss: 2.4721656541627026

Epoch: 6| Step: 12
Training loss: 2.1283265050640616
Validation loss: 2.4715498165805676

Epoch: 6| Step: 13
Training loss: 2.708413832030598
Validation loss: 2.46179988222555

Epoch: 154| Step: 0
Training loss: 2.5507233921283263
Validation loss: 2.4649310048695465

Epoch: 6| Step: 1
Training loss: 2.238198483519645
Validation loss: 2.463652083413836

Epoch: 6| Step: 2
Training loss: 2.4345700187086163
Validation loss: 2.4588338751838745

Epoch: 6| Step: 3
Training loss: 2.9729978989158417
Validation loss: 2.4592466085770637

Epoch: 6| Step: 4
Training loss: 2.873256320437592
Validation loss: 2.4598085750751384

Epoch: 6| Step: 5
Training loss: 2.4654731732751927
Validation loss: 2.459033289900821

Epoch: 6| Step: 6
Training loss: 2.4315551252538854
Validation loss: 2.4584561629779205

Epoch: 6| Step: 7
Training loss: 2.48989092683699
Validation loss: 2.4566003919984625

Epoch: 6| Step: 8
Training loss: 2.688452618343701
Validation loss: 2.4608917312806406

Epoch: 6| Step: 9
Training loss: 2.6535984942275825
Validation loss: 2.4572315225413934

Epoch: 6| Step: 10
Training loss: 2.394243780058921
Validation loss: 2.460849013579478

Epoch: 6| Step: 11
Training loss: 2.0692701486784344
Validation loss: 2.4613283684560945

Epoch: 6| Step: 12
Training loss: 1.6257353366012786
Validation loss: 2.464285261800447

Epoch: 6| Step: 13
Training loss: 2.9694190626622827
Validation loss: 2.468434309592936

Epoch: 155| Step: 0
Training loss: 2.3200207664941517
Validation loss: 2.4675647288563654

Epoch: 6| Step: 1
Training loss: 2.7014892568196367
Validation loss: 2.4682126647522082

Epoch: 6| Step: 2
Training loss: 3.188086063137518
Validation loss: 2.4736766346953925

Epoch: 6| Step: 3
Training loss: 2.6296846277557844
Validation loss: 2.4708026287965077

Epoch: 6| Step: 4
Training loss: 1.9831973208210443
Validation loss: 2.474117937795562

Epoch: 6| Step: 5
Training loss: 2.906149093352819
Validation loss: 2.4720160854375908

Epoch: 6| Step: 6
Training loss: 2.194399606539044
Validation loss: 2.46648140181479

Epoch: 6| Step: 7
Training loss: 2.7308035060016884
Validation loss: 2.4705563708963267

Epoch: 6| Step: 8
Training loss: 2.569883084587882
Validation loss: 2.4675341803268167

Epoch: 6| Step: 9
Training loss: 2.2035989454476352
Validation loss: 2.468810197442339

Epoch: 6| Step: 10
Training loss: 2.122074581866966
Validation loss: 2.462008224153353

Epoch: 6| Step: 11
Training loss: 2.09717541516795
Validation loss: 2.461944236908396

Epoch: 6| Step: 12
Training loss: 2.578502650489059
Validation loss: 2.466304920279139

Epoch: 6| Step: 13
Training loss: 2.5499752342667046
Validation loss: 2.4593693172093505

Epoch: 156| Step: 0
Training loss: 2.362741657794921
Validation loss: 2.457681041321426

Epoch: 6| Step: 1
Training loss: 2.748922830641268
Validation loss: 2.46135549073494

Epoch: 6| Step: 2
Training loss: 2.445065811925314
Validation loss: 2.458137348143064

Epoch: 6| Step: 3
Training loss: 2.4442883379054936
Validation loss: 2.464387274065055

Epoch: 6| Step: 4
Training loss: 2.0846240305227255
Validation loss: 2.4624556122731156

Epoch: 6| Step: 5
Training loss: 2.237332181124718
Validation loss: 2.458478653917579

Epoch: 6| Step: 6
Training loss: 2.601189114006079
Validation loss: 2.470721459603414

Epoch: 6| Step: 7
Training loss: 2.377377374256444
Validation loss: 2.470724772683903

Epoch: 6| Step: 8
Training loss: 2.8380893918584027
Validation loss: 2.4731261664082456

Epoch: 6| Step: 9
Training loss: 2.7863051517961526
Validation loss: 2.4716595995933384

Epoch: 6| Step: 10
Training loss: 1.9066534397137733
Validation loss: 2.478536819676009

Epoch: 6| Step: 11
Training loss: 2.899297787065181
Validation loss: 2.473264421555218

Epoch: 6| Step: 12
Training loss: 3.0525383376854665
Validation loss: 2.480460371669126

Epoch: 6| Step: 13
Training loss: 2.05273518802761
Validation loss: 2.4738145860102434

Epoch: 157| Step: 0
Training loss: 2.3900326262924594
Validation loss: 2.472351899180916

Epoch: 6| Step: 1
Training loss: 2.762484647958482
Validation loss: 2.4732289467125055

Epoch: 6| Step: 2
Training loss: 2.5638361912917893
Validation loss: 2.470009381949539

Epoch: 6| Step: 3
Training loss: 2.776044882557183
Validation loss: 2.471279152527945

Epoch: 6| Step: 4
Training loss: 1.8977785575968331
Validation loss: 2.4706253944201726

Epoch: 6| Step: 5
Training loss: 2.5904827451589614
Validation loss: 2.46880078162908

Epoch: 6| Step: 6
Training loss: 2.2115876552762304
Validation loss: 2.4711173412713676

Epoch: 6| Step: 7
Training loss: 2.730519743130775
Validation loss: 2.465180919577214

Epoch: 6| Step: 8
Training loss: 2.3267043726943566
Validation loss: 2.4651216490352845

Epoch: 6| Step: 9
Training loss: 2.4188159943480945
Validation loss: 2.46722680596675

Epoch: 6| Step: 10
Training loss: 2.31842519125195
Validation loss: 2.4584343830181177

Epoch: 6| Step: 11
Training loss: 2.5512070585204047
Validation loss: 2.470455980567678

Epoch: 6| Step: 12
Training loss: 2.6455361106713724
Validation loss: 2.469593290366081

Epoch: 6| Step: 13
Training loss: 2.6102355634415972
Validation loss: 2.4758347526074576

Epoch: 158| Step: 0
Training loss: 2.8875779046452594
Validation loss: 2.486929709590181

Epoch: 6| Step: 1
Training loss: 1.2903133912105351
Validation loss: 2.470399892742232

Epoch: 6| Step: 2
Training loss: 2.7161263269813305
Validation loss: 2.4683756967069224

Epoch: 6| Step: 3
Training loss: 2.713438260285797
Validation loss: 2.4615263703626997

Epoch: 6| Step: 4
Training loss: 2.2528223773614355
Validation loss: 2.4621405511821277

Epoch: 6| Step: 5
Training loss: 2.6461539086800774
Validation loss: 2.46142160003757

Epoch: 6| Step: 6
Training loss: 2.285826599393024
Validation loss: 2.462743260136715

Epoch: 6| Step: 7
Training loss: 2.8534280605575715
Validation loss: 2.4668507171175387

Epoch: 6| Step: 8
Training loss: 2.4890400015657708
Validation loss: 2.468307729129358

Epoch: 6| Step: 9
Training loss: 2.456520888749284
Validation loss: 2.467965415830776

Epoch: 6| Step: 10
Training loss: 2.3457537414527447
Validation loss: 2.46725618259981

Epoch: 6| Step: 11
Training loss: 2.0927524752508253
Validation loss: 2.462286572316472

Epoch: 6| Step: 12
Training loss: 3.1112438317402886
Validation loss: 2.4709867171421065

Epoch: 6| Step: 13
Training loss: 2.292597518061506
Validation loss: 2.466460490201771

Epoch: 159| Step: 0
Training loss: 2.78996745155518
Validation loss: 2.4666113623871624

Epoch: 6| Step: 1
Training loss: 2.6949655503033387
Validation loss: 2.470853336075286

Epoch: 6| Step: 2
Training loss: 2.4808551157015475
Validation loss: 2.4649710241991483

Epoch: 6| Step: 3
Training loss: 2.7630970926693954
Validation loss: 2.474720981231872

Epoch: 6| Step: 4
Training loss: 2.253915029736745
Validation loss: 2.4684157326300324

Epoch: 6| Step: 5
Training loss: 1.843633227772309
Validation loss: 2.479380114900829

Epoch: 6| Step: 6
Training loss: 2.828862215345711
Validation loss: 2.4772183726092774

Epoch: 6| Step: 7
Training loss: 2.3856894213618323
Validation loss: 2.476742678725565

Epoch: 6| Step: 8
Training loss: 2.9654297582514153
Validation loss: 2.477539503563368

Epoch: 6| Step: 9
Training loss: 2.3587431408934534
Validation loss: 2.477793919886575

Epoch: 6| Step: 10
Training loss: 2.267822147352544
Validation loss: 2.472852991361471

Epoch: 6| Step: 11
Training loss: 2.4820809959395067
Validation loss: 2.468529800058994

Epoch: 6| Step: 12
Training loss: 2.1893184188252675
Validation loss: 2.4655563203104576

Epoch: 6| Step: 13
Training loss: 2.5068344157815794
Validation loss: 2.46638811983041

Epoch: 160| Step: 0
Training loss: 2.268767814461202
Validation loss: 2.457059115123978

Epoch: 6| Step: 1
Training loss: 2.280463514227246
Validation loss: 2.4663707680254983

Epoch: 6| Step: 2
Training loss: 2.797186722246577
Validation loss: 2.4719234383037243

Epoch: 6| Step: 3
Training loss: 2.8959181702259853
Validation loss: 2.475969871429103

Epoch: 6| Step: 4
Training loss: 1.9624308337032141
Validation loss: 2.4830205972190793

Epoch: 6| Step: 5
Training loss: 2.752362970030066
Validation loss: 2.490344554981875

Epoch: 6| Step: 6
Training loss: 2.6914143112349795
Validation loss: 2.489526066992668

Epoch: 6| Step: 7
Training loss: 2.5393216514382124
Validation loss: 2.4782306416119533

Epoch: 6| Step: 8
Training loss: 2.6055562292051584
Validation loss: 2.4757107975939685

Epoch: 6| Step: 9
Training loss: 2.474541835570777
Validation loss: 2.471777447922838

Epoch: 6| Step: 10
Training loss: 2.8793524263100307
Validation loss: 2.4687123356131027

Epoch: 6| Step: 11
Training loss: 2.919765914783469
Validation loss: 2.470085933428557

Epoch: 6| Step: 12
Training loss: 2.1536499048000044
Validation loss: 2.4681613558354183

Epoch: 6| Step: 13
Training loss: 1.702218750788837
Validation loss: 2.468284546960046

Epoch: 161| Step: 0
Training loss: 2.429706536614029
Validation loss: 2.4747198893601636

Epoch: 6| Step: 1
Training loss: 2.223652862605862
Validation loss: 2.468070198172594

Epoch: 6| Step: 2
Training loss: 2.4907806156416803
Validation loss: 2.475308940371032

Epoch: 6| Step: 3
Training loss: 2.720738703049412
Validation loss: 2.472145626462672

Epoch: 6| Step: 4
Training loss: 2.3672712959590996
Validation loss: 2.4628308072390097

Epoch: 6| Step: 5
Training loss: 3.05960491123112
Validation loss: 2.4673227457927203

Epoch: 6| Step: 6
Training loss: 2.2521133035035397
Validation loss: 2.479596114162283

Epoch: 6| Step: 7
Training loss: 2.7433907241040414
Validation loss: 2.4700871640886266

Epoch: 6| Step: 8
Training loss: 2.2486072044137035
Validation loss: 2.4669281558886804

Epoch: 6| Step: 9
Training loss: 2.2077883881739133
Validation loss: 2.4560453845758623

Epoch: 6| Step: 10
Training loss: 2.7402550825014984
Validation loss: 2.46311170012839

Epoch: 6| Step: 11
Training loss: 2.583482573925714
Validation loss: 2.466282299311673

Epoch: 6| Step: 12
Training loss: 2.6620083493761695
Validation loss: 2.4586620569008346

Epoch: 6| Step: 13
Training loss: 2.31441150740536
Validation loss: 2.4620099188364404

Epoch: 162| Step: 0
Training loss: 1.7751354541942157
Validation loss: 2.463917932682054

Epoch: 6| Step: 1
Training loss: 2.218762035068592
Validation loss: 2.4667630146730097

Epoch: 6| Step: 2
Training loss: 2.6317003204564675
Validation loss: 2.463159056961003

Epoch: 6| Step: 3
Training loss: 2.769470558523782
Validation loss: 2.464869979178779

Epoch: 6| Step: 4
Training loss: 2.8016025929685715
Validation loss: 2.463871896774301

Epoch: 6| Step: 5
Training loss: 2.5161098226282506
Validation loss: 2.472040518561323

Epoch: 6| Step: 6
Training loss: 2.7333110374223644
Validation loss: 2.4725409586837124

Epoch: 6| Step: 7
Training loss: 1.5299809705261431
Validation loss: 2.4686552584854375

Epoch: 6| Step: 8
Training loss: 2.692755771910212
Validation loss: 2.4712877388572783

Epoch: 6| Step: 9
Training loss: 2.3905647619300017
Validation loss: 2.4664688838674333

Epoch: 6| Step: 10
Training loss: 2.041737289245283
Validation loss: 2.4718797216679764

Epoch: 6| Step: 11
Training loss: 2.938321749411382
Validation loss: 2.4646006936380624

Epoch: 6| Step: 12
Training loss: 2.627541810056032
Validation loss: 2.4666316283375105

Epoch: 6| Step: 13
Training loss: 2.767308127101987
Validation loss: 2.466182218375204

Epoch: 163| Step: 0
Training loss: 2.442863041927191
Validation loss: 2.4721888320849184

Epoch: 6| Step: 1
Training loss: 2.9289160768227553
Validation loss: 2.4635645493673874

Epoch: 6| Step: 2
Training loss: 2.1332313210217118
Validation loss: 2.4584968534062464

Epoch: 6| Step: 3
Training loss: 2.712993358976544
Validation loss: 2.4612202799771996

Epoch: 6| Step: 4
Training loss: 1.877819230614654
Validation loss: 2.458989319860745

Epoch: 6| Step: 5
Training loss: 2.2319640910907275
Validation loss: 2.45640283421337

Epoch: 6| Step: 6
Training loss: 2.588425468021712
Validation loss: 2.4608576685960304

Epoch: 6| Step: 7
Training loss: 2.430314550409952
Validation loss: 2.4587333698547456

Epoch: 6| Step: 8
Training loss: 2.672151517780807
Validation loss: 2.451584901498658

Epoch: 6| Step: 9
Training loss: 2.7089739897624474
Validation loss: 2.461832414620146

Epoch: 6| Step: 10
Training loss: 2.6606443968359987
Validation loss: 2.4530759024920625

Epoch: 6| Step: 11
Training loss: 1.8058427028063804
Validation loss: 2.4567021006440313

Epoch: 6| Step: 12
Training loss: 2.40450748912512
Validation loss: 2.4520535569069746

Epoch: 6| Step: 13
Training loss: 2.991401589071927
Validation loss: 2.4603160901121983

Epoch: 164| Step: 0
Training loss: 2.228086358333184
Validation loss: 2.46703636474775

Epoch: 6| Step: 1
Training loss: 2.666840209877054
Validation loss: 2.465084735195471

Epoch: 6| Step: 2
Training loss: 2.8151227801634193
Validation loss: 2.456013592577835

Epoch: 6| Step: 3
Training loss: 2.2112390966238236
Validation loss: 2.47077517599158

Epoch: 6| Step: 4
Training loss: 2.8049401299654204
Validation loss: 2.464641387419091

Epoch: 6| Step: 5
Training loss: 2.705810800201451
Validation loss: 2.4614911137896436

Epoch: 6| Step: 6
Training loss: 2.8273731728735956
Validation loss: 2.4712293866046644

Epoch: 6| Step: 7
Training loss: 2.0458655743929826
Validation loss: 2.4665454888434835

Epoch: 6| Step: 8
Training loss: 2.6183905270564503
Validation loss: 2.4754991063446585

Epoch: 6| Step: 9
Training loss: 2.5836387166648342
Validation loss: 2.4742777139736147

Epoch: 6| Step: 10
Training loss: 2.700349121127963
Validation loss: 2.4677654830307265

Epoch: 6| Step: 11
Training loss: 2.4012908364933643
Validation loss: 2.461856359672884

Epoch: 6| Step: 12
Training loss: 2.149047099240363
Validation loss: 2.4551734551752453

Epoch: 6| Step: 13
Training loss: 1.999423301521159
Validation loss: 2.453882736163028

Epoch: 165| Step: 0
Training loss: 2.0283052667051495
Validation loss: 2.4568146578322616

Epoch: 6| Step: 1
Training loss: 2.4206013930056307
Validation loss: 2.4569940205367886

Epoch: 6| Step: 2
Training loss: 2.648071984018551
Validation loss: 2.4510719471455387

Epoch: 6| Step: 3
Training loss: 2.738386252834752
Validation loss: 2.461419630506474

Epoch: 6| Step: 4
Training loss: 2.5455848843162308
Validation loss: 2.4601149380202267

Epoch: 6| Step: 5
Training loss: 2.3728188989965715
Validation loss: 2.455764759462467

Epoch: 6| Step: 6
Training loss: 2.3361821381421577
Validation loss: 2.461242729513377

Epoch: 6| Step: 7
Training loss: 2.9893726624661734
Validation loss: 2.4545146950111993

Epoch: 6| Step: 8
Training loss: 2.237573641625405
Validation loss: 2.4644036401381952

Epoch: 6| Step: 9
Training loss: 2.694857440072564
Validation loss: 2.4628761365697787

Epoch: 6| Step: 10
Training loss: 2.9298328414468973
Validation loss: 2.458712618604585

Epoch: 6| Step: 11
Training loss: 2.5198499374517107
Validation loss: 2.4595625331265607

Epoch: 6| Step: 12
Training loss: 1.9623985774565749
Validation loss: 2.4615759773138888

Epoch: 6| Step: 13
Training loss: 2.4060143689799096
Validation loss: 2.4668487438669606

Epoch: 166| Step: 0
Training loss: 2.0353200191275156
Validation loss: 2.4603799501199464

Epoch: 6| Step: 1
Training loss: 2.9578522483544885
Validation loss: 2.4614867228257684

Epoch: 6| Step: 2
Training loss: 2.536589371718756
Validation loss: 2.461109191718213

Epoch: 6| Step: 3
Training loss: 2.292176507820759
Validation loss: 2.4627727467226688

Epoch: 6| Step: 4
Training loss: 2.6254645345279775
Validation loss: 2.4639001441673645

Epoch: 6| Step: 5
Training loss: 2.603999831895486
Validation loss: 2.465649827156084

Epoch: 6| Step: 6
Training loss: 2.7971919215847882
Validation loss: 2.4651749716323037

Epoch: 6| Step: 7
Training loss: 1.994805982520092
Validation loss: 2.466086500045566

Epoch: 6| Step: 8
Training loss: 2.5223712380913015
Validation loss: 2.4613747183122974

Epoch: 6| Step: 9
Training loss: 2.677727608146993
Validation loss: 2.4635170793549697

Epoch: 6| Step: 10
Training loss: 2.1917322905642918
Validation loss: 2.466984515932846

Epoch: 6| Step: 11
Training loss: 2.016289298424863
Validation loss: 2.469981791626075

Epoch: 6| Step: 12
Training loss: 2.1908263936978205
Validation loss: 2.4665943987887813

Epoch: 6| Step: 13
Training loss: 3.1336744839699566
Validation loss: 2.4628806944648667

Epoch: 167| Step: 0
Training loss: 2.513361795383993
Validation loss: 2.457327965800729

Epoch: 6| Step: 1
Training loss: 2.128269373271983
Validation loss: 2.467302646571195

Epoch: 6| Step: 2
Training loss: 2.1386593892329597
Validation loss: 2.4653130239256535

Epoch: 6| Step: 3
Training loss: 2.461121470523078
Validation loss: 2.4628804605200147

Epoch: 6| Step: 4
Training loss: 2.372912644094575
Validation loss: 2.465969668860047

Epoch: 6| Step: 5
Training loss: 2.6712544930919657
Validation loss: 2.4648370919034397

Epoch: 6| Step: 6
Training loss: 2.511072909318705
Validation loss: 2.4586212883962526

Epoch: 6| Step: 7
Training loss: 2.8352924380438282
Validation loss: 2.4607012196296165

Epoch: 6| Step: 8
Training loss: 2.488427461792885
Validation loss: 2.463529321963543

Epoch: 6| Step: 9
Training loss: 2.7691019906561336
Validation loss: 2.4676662593382437

Epoch: 6| Step: 10
Training loss: 2.5708205813725873
Validation loss: 2.4653646540370624

Epoch: 6| Step: 11
Training loss: 2.9495197875126573
Validation loss: 2.4683128806929706

Epoch: 6| Step: 12
Training loss: 1.931446277804485
Validation loss: 2.463492932687786

Epoch: 6| Step: 13
Training loss: 2.126384508474622
Validation loss: 2.4677176590616203

Epoch: 168| Step: 0
Training loss: 2.658305102430615
Validation loss: 2.4630191294507653

Epoch: 6| Step: 1
Training loss: 2.15324014873459
Validation loss: 2.462416270167052

Epoch: 6| Step: 2
Training loss: 2.4153118172337487
Validation loss: 2.4570280074041064

Epoch: 6| Step: 3
Training loss: 1.8953797003774482
Validation loss: 2.467617354534833

Epoch: 6| Step: 4
Training loss: 2.7429760616925387
Validation loss: 2.4658647086298293

Epoch: 6| Step: 5
Training loss: 3.132663637653236
Validation loss: 2.464548616226587

Epoch: 6| Step: 6
Training loss: 3.1616922425030096
Validation loss: 2.465664444331096

Epoch: 6| Step: 7
Training loss: 2.3154315409498065
Validation loss: 2.4698149561068865

Epoch: 6| Step: 8
Training loss: 2.319248764809167
Validation loss: 2.46325142073383

Epoch: 6| Step: 9
Training loss: 2.5623429413091747
Validation loss: 2.462672031028425

Epoch: 6| Step: 10
Training loss: 2.7348450175000543
Validation loss: 2.4698338121421917

Epoch: 6| Step: 11
Training loss: 2.0301400306398443
Validation loss: 2.456407994567214

Epoch: 6| Step: 12
Training loss: 2.431196032712109
Validation loss: 2.453747040754423

Epoch: 6| Step: 13
Training loss: 1.8237492285890888
Validation loss: 2.4526719243887665

Epoch: 169| Step: 0
Training loss: 2.704511518389335
Validation loss: 2.45834304247302

Epoch: 6| Step: 1
Training loss: 2.163380539510821
Validation loss: 2.4575669311665616

Epoch: 6| Step: 2
Training loss: 2.7441951868463623
Validation loss: 2.459189893452769

Epoch: 6| Step: 3
Training loss: 2.7112756347851357
Validation loss: 2.465269669592572

Epoch: 6| Step: 4
Training loss: 2.025460546421446
Validation loss: 2.458352902436898

Epoch: 6| Step: 5
Training loss: 2.5810136737660807
Validation loss: 2.4572629106776045

Epoch: 6| Step: 6
Training loss: 1.9460235889334185
Validation loss: 2.4572624578892057

Epoch: 6| Step: 7
Training loss: 2.718454980738104
Validation loss: 2.4531449562119545

Epoch: 6| Step: 8
Training loss: 2.5853897851555234
Validation loss: 2.4611015466983086

Epoch: 6| Step: 9
Training loss: 2.7473499360552123
Validation loss: 2.4516562339185577

Epoch: 6| Step: 10
Training loss: 2.1378175466138036
Validation loss: 2.463598534302034

Epoch: 6| Step: 11
Training loss: 2.377933196705573
Validation loss: 2.4619896148423357

Epoch: 6| Step: 12
Training loss: 2.798526468146017
Validation loss: 2.461455041466405

Epoch: 6| Step: 13
Training loss: 2.5209225620419713
Validation loss: 2.465093326981343

Epoch: 170| Step: 0
Training loss: 2.7113497637715254
Validation loss: 2.464056857692634

Epoch: 6| Step: 1
Training loss: 2.006234346607973
Validation loss: 2.4611566032279186

Epoch: 6| Step: 2
Training loss: 2.403064551417887
Validation loss: 2.4598275885860477

Epoch: 6| Step: 3
Training loss: 2.04532535511054
Validation loss: 2.463708534530472

Epoch: 6| Step: 4
Training loss: 2.2301251736393852
Validation loss: 2.4594109781001476

Epoch: 6| Step: 5
Training loss: 2.675411805870949
Validation loss: 2.461877278112781

Epoch: 6| Step: 6
Training loss: 2.7175432355120757
Validation loss: 2.4562345101448058

Epoch: 6| Step: 7
Training loss: 2.0926452682914483
Validation loss: 2.4717647156545977

Epoch: 6| Step: 8
Training loss: 2.5114530479178288
Validation loss: 2.4685246811425468

Epoch: 6| Step: 9
Training loss: 2.7698849558437657
Validation loss: 2.4622449197346543

Epoch: 6| Step: 10
Training loss: 2.602850701029659
Validation loss: 2.454817178151125

Epoch: 6| Step: 11
Training loss: 2.258506272323104
Validation loss: 2.456039204178954

Epoch: 6| Step: 12
Training loss: 2.991054071241823
Validation loss: 2.4602270806442164

Epoch: 6| Step: 13
Training loss: 2.6109359549444204
Validation loss: 2.4590605586872396

Epoch: 171| Step: 0
Training loss: 1.8875220190115447
Validation loss: 2.459526036692818

Epoch: 6| Step: 1
Training loss: 2.6920446073455455
Validation loss: 2.4533079204677097

Epoch: 6| Step: 2
Training loss: 2.2908150795710864
Validation loss: 2.4551699268917697

Epoch: 6| Step: 3
Training loss: 2.458959747506241
Validation loss: 2.4583546642951317

Epoch: 6| Step: 4
Training loss: 2.534120039338961
Validation loss: 2.454934183987872

Epoch: 6| Step: 5
Training loss: 2.5095573843570222
Validation loss: 2.4571541420385956

Epoch: 6| Step: 6
Training loss: 2.3326364112208156
Validation loss: 2.456164216670151

Epoch: 6| Step: 7
Training loss: 2.877519581559914
Validation loss: 2.461580981539168

Epoch: 6| Step: 8
Training loss: 2.936074905469018
Validation loss: 2.4640426502706285

Epoch: 6| Step: 9
Training loss: 2.124908108687863
Validation loss: 2.4685263150116854

Epoch: 6| Step: 10
Training loss: 2.707203693044231
Validation loss: 2.465357658871056

Epoch: 6| Step: 11
Training loss: 2.0477281495955455
Validation loss: 2.465417036561829

Epoch: 6| Step: 12
Training loss: 2.6445168251083695
Validation loss: 2.4640051558294065

Epoch: 6| Step: 13
Training loss: 2.7147404712819263
Validation loss: 2.4653001575319773

Epoch: 172| Step: 0
Training loss: 2.6246824526587824
Validation loss: 2.4585410100425653

Epoch: 6| Step: 1
Training loss: 2.0976559090214457
Validation loss: 2.453785768838645

Epoch: 6| Step: 2
Training loss: 2.8681466060181235
Validation loss: 2.4461130897442156

Epoch: 6| Step: 3
Training loss: 2.257339269549516
Validation loss: 2.4516270269391605

Epoch: 6| Step: 4
Training loss: 2.385094522326553
Validation loss: 2.4565880663326336

Epoch: 6| Step: 5
Training loss: 2.413752168627752
Validation loss: 2.453685461598955

Epoch: 6| Step: 6
Training loss: 2.453867028623401
Validation loss: 2.4477812276396373

Epoch: 6| Step: 7
Training loss: 2.8993995899984033
Validation loss: 2.45655271462125

Epoch: 6| Step: 8
Training loss: 2.2981354245884935
Validation loss: 2.452800688799193

Epoch: 6| Step: 9
Training loss: 2.105076231312356
Validation loss: 2.452337345091837

Epoch: 6| Step: 10
Training loss: 2.8335334108805164
Validation loss: 2.4525334967277437

Epoch: 6| Step: 11
Training loss: 2.170577944952059
Validation loss: 2.453319420369061

Epoch: 6| Step: 12
Training loss: 2.706572170330584
Validation loss: 2.453505597890953

Epoch: 6| Step: 13
Training loss: 2.5718951237240026
Validation loss: 2.4539383432839466

Epoch: 173| Step: 0
Training loss: 2.8095662392436584
Validation loss: 2.4512560420891534

Epoch: 6| Step: 1
Training loss: 2.375149973099458
Validation loss: 2.45424169890939

Epoch: 6| Step: 2
Training loss: 2.4353283720650807
Validation loss: 2.450352570084046

Epoch: 6| Step: 3
Training loss: 2.8255666890210227
Validation loss: 2.4562139400070966

Epoch: 6| Step: 4
Training loss: 2.505222302012582
Validation loss: 2.4671961244058327

Epoch: 6| Step: 5
Training loss: 2.6146386331938762
Validation loss: 2.4719801586624355

Epoch: 6| Step: 6
Training loss: 2.183192234964285
Validation loss: 2.4838810875595527

Epoch: 6| Step: 7
Training loss: 1.8999411197373006
Validation loss: 2.515468363495794

Epoch: 6| Step: 8
Training loss: 3.2432440449524655
Validation loss: 2.517278455641549

Epoch: 6| Step: 9
Training loss: 2.4687654518899347
Validation loss: 2.495764163867961

Epoch: 6| Step: 10
Training loss: 1.835268848484009
Validation loss: 2.4811203228481062

Epoch: 6| Step: 11
Training loss: 2.708734502180308
Validation loss: 2.476484311511165

Epoch: 6| Step: 12
Training loss: 2.0172471017697333
Validation loss: 2.4553195831596724

Epoch: 6| Step: 13
Training loss: 2.962669168141039
Validation loss: 2.4559032234220135

Epoch: 174| Step: 0
Training loss: 3.0606285137883136
Validation loss: 2.4468839590818847

Epoch: 6| Step: 1
Training loss: 2.491549897620753
Validation loss: 2.4589075344644957

Epoch: 6| Step: 2
Training loss: 2.7267490968004107
Validation loss: 2.459848055812044

Epoch: 6| Step: 3
Training loss: 2.976439145553394
Validation loss: 2.461807678417826

Epoch: 6| Step: 4
Training loss: 2.4164134802773334
Validation loss: 2.4663988015214744

Epoch: 6| Step: 5
Training loss: 2.4032014633733
Validation loss: 2.4662882123623713

Epoch: 6| Step: 6
Training loss: 2.1494806150248658
Validation loss: 2.466047828174407

Epoch: 6| Step: 7
Training loss: 1.6977569957460386
Validation loss: 2.4590008578304796

Epoch: 6| Step: 8
Training loss: 2.5808097962769994
Validation loss: 2.4698077161233414

Epoch: 6| Step: 9
Training loss: 2.2814212891533856
Validation loss: 2.466003660933063

Epoch: 6| Step: 10
Training loss: 2.1934326377039755
Validation loss: 2.460031082104275

Epoch: 6| Step: 11
Training loss: 2.683432495069873
Validation loss: 2.4688700071372587

Epoch: 6| Step: 12
Training loss: 1.9895420835789182
Validation loss: 2.4626830838170313

Epoch: 6| Step: 13
Training loss: 2.835487855516962
Validation loss: 2.4622953191077546

Epoch: 175| Step: 0
Training loss: 2.948344402935782
Validation loss: 2.4707288416553173

Epoch: 6| Step: 1
Training loss: 2.3672808638186353
Validation loss: 2.4696325824997847

Epoch: 6| Step: 2
Training loss: 2.8697141070307524
Validation loss: 2.465720220869756

Epoch: 6| Step: 3
Training loss: 1.8550393340472398
Validation loss: 2.4687775718984217

Epoch: 6| Step: 4
Training loss: 2.5366093918913197
Validation loss: 2.462048202223552

Epoch: 6| Step: 5
Training loss: 1.9950053313908291
Validation loss: 2.4669655736895497

Epoch: 6| Step: 6
Training loss: 2.7672119759888565
Validation loss: 2.4649701698154147

Epoch: 6| Step: 7
Training loss: 2.4311387612751987
Validation loss: 2.4640728389286832

Epoch: 6| Step: 8
Training loss: 2.5613275962830206
Validation loss: 2.4661822908815783

Epoch: 6| Step: 9
Training loss: 2.351625967595035
Validation loss: 2.460452125761083

Epoch: 6| Step: 10
Training loss: 2.9131252223507644
Validation loss: 2.4582367301538017

Epoch: 6| Step: 11
Training loss: 2.0663384064063752
Validation loss: 2.460385312088668

Epoch: 6| Step: 12
Training loss: 2.449850241307412
Validation loss: 2.46572873792158

Epoch: 6| Step: 13
Training loss: 2.2891913367979853
Validation loss: 2.4576250499939216

Epoch: 176| Step: 0
Training loss: 2.493628393281914
Validation loss: 2.461101958415931

Epoch: 6| Step: 1
Training loss: 2.792117798825965
Validation loss: 2.461778010788308

Epoch: 6| Step: 2
Training loss: 2.676651817207745
Validation loss: 2.4671426038983597

Epoch: 6| Step: 3
Training loss: 2.629801038171179
Validation loss: 2.468269784312366

Epoch: 6| Step: 4
Training loss: 2.7630353106887346
Validation loss: 2.474254924998348

Epoch: 6| Step: 5
Training loss: 2.2074249726589152
Validation loss: 2.465284111719248

Epoch: 6| Step: 6
Training loss: 1.990207840402881
Validation loss: 2.4633532015842783

Epoch: 6| Step: 7
Training loss: 2.801271786688019
Validation loss: 2.4745648467150625

Epoch: 6| Step: 8
Training loss: 2.0610418077843686
Validation loss: 2.472597174719692

Epoch: 6| Step: 9
Training loss: 2.539946323037866
Validation loss: 2.4740531394594787

Epoch: 6| Step: 10
Training loss: 2.285883548123363
Validation loss: 2.4805678780840466

Epoch: 6| Step: 11
Training loss: 2.1173512300476456
Validation loss: 2.4718535025683015

Epoch: 6| Step: 12
Training loss: 2.7056565089868303
Validation loss: 2.46818927239749

Epoch: 6| Step: 13
Training loss: 2.4991247552365863
Validation loss: 2.466935951981814

Epoch: 177| Step: 0
Training loss: 2.0852781246581316
Validation loss: 2.4640153479232283

Epoch: 6| Step: 1
Training loss: 2.541721958330268
Validation loss: 2.4732959275446076

Epoch: 6| Step: 2
Training loss: 2.579675381664923
Validation loss: 2.4698263389269903

Epoch: 6| Step: 3
Training loss: 2.3453324125843653
Validation loss: 2.4690044127123967

Epoch: 6| Step: 4
Training loss: 2.4185500424554642
Validation loss: 2.4758787605212276

Epoch: 6| Step: 5
Training loss: 1.8613346576075684
Validation loss: 2.470615856855944

Epoch: 6| Step: 6
Training loss: 2.2556937549118867
Validation loss: 2.4684924542612627

Epoch: 6| Step: 7
Training loss: 2.441548433359741
Validation loss: 2.474914740689803

Epoch: 6| Step: 8
Training loss: 2.462016907374372
Validation loss: 2.466373361942814

Epoch: 6| Step: 9
Training loss: 2.6143291294087283
Validation loss: 2.470934275794733

Epoch: 6| Step: 10
Training loss: 2.6706404482918953
Validation loss: 2.472108704988473

Epoch: 6| Step: 11
Training loss: 2.2806634018127627
Validation loss: 2.469381147097158

Epoch: 6| Step: 12
Training loss: 2.7462335282371324
Validation loss: 2.4743740468683004

Epoch: 6| Step: 13
Training loss: 3.003598280498781
Validation loss: 2.4666535050668204

Epoch: 178| Step: 0
Training loss: 2.293974309862223
Validation loss: 2.465118134990497

Epoch: 6| Step: 1
Training loss: 2.571924231835568
Validation loss: 2.470709485836159

Epoch: 6| Step: 2
Training loss: 2.1892550376284383
Validation loss: 2.468437271591429

Epoch: 6| Step: 3
Training loss: 2.578699591213772
Validation loss: 2.4645818298111686

Epoch: 6| Step: 4
Training loss: 2.3683815138567144
Validation loss: 2.4688102859669083

Epoch: 6| Step: 5
Training loss: 2.846370286305472
Validation loss: 2.4700009520525006

Epoch: 6| Step: 6
Training loss: 2.7168191652459956
Validation loss: 2.474980174733403

Epoch: 6| Step: 7
Training loss: 2.597764734283122
Validation loss: 2.4687098729216372

Epoch: 6| Step: 8
Training loss: 1.9585186146953713
Validation loss: 2.466417248676899

Epoch: 6| Step: 9
Training loss: 2.603005590367625
Validation loss: 2.4712318065863124

Epoch: 6| Step: 10
Training loss: 2.5342032076822782
Validation loss: 2.4711823211082833

Epoch: 6| Step: 11
Training loss: 2.2706459971390807
Validation loss: 2.470549478892509

Epoch: 6| Step: 12
Training loss: 1.8214214041646355
Validation loss: 2.4677387854545083

Epoch: 6| Step: 13
Training loss: 2.8104360000552395
Validation loss: 2.4741590371618676

Epoch: 179| Step: 0
Training loss: 3.039138753762984
Validation loss: 2.46895654836381

Epoch: 6| Step: 1
Training loss: 1.8697272867862642
Validation loss: 2.4705319472208758

Epoch: 6| Step: 2
Training loss: 2.323759761336305
Validation loss: 2.4701094445603173

Epoch: 6| Step: 3
Training loss: 1.837348947349793
Validation loss: 2.472293893499077

Epoch: 6| Step: 4
Training loss: 2.58185414040126
Validation loss: 2.4772985509789023

Epoch: 6| Step: 5
Training loss: 2.7128519559429116
Validation loss: 2.4845255680162

Epoch: 6| Step: 6
Training loss: 2.6697472024748095
Validation loss: 2.4776523731078908

Epoch: 6| Step: 7
Training loss: 1.9579292110353261
Validation loss: 2.4837511026974823

Epoch: 6| Step: 8
Training loss: 2.5316447197484147
Validation loss: 2.4874065145181246

Epoch: 6| Step: 9
Training loss: 2.2804955057820417
Validation loss: 2.488642053081659

Epoch: 6| Step: 10
Training loss: 2.954280566632397
Validation loss: 2.474731747382263

Epoch: 6| Step: 11
Training loss: 2.5212884497370274
Validation loss: 2.4611617536144657

Epoch: 6| Step: 12
Training loss: 2.584330263869199
Validation loss: 2.463311784810894

Epoch: 6| Step: 13
Training loss: 2.230593382231066
Validation loss: 2.4691612850709483

Epoch: 180| Step: 0
Training loss: 2.3957080531882093
Validation loss: 2.4660264617054994

Epoch: 6| Step: 1
Training loss: 2.506240494631581
Validation loss: 2.4657729181449817

Epoch: 6| Step: 2
Training loss: 2.075610252633524
Validation loss: 2.462459243075669

Epoch: 6| Step: 3
Training loss: 2.967642647866655
Validation loss: 2.4587169821997685

Epoch: 6| Step: 4
Training loss: 2.6729239919853973
Validation loss: 2.4645853284976607

Epoch: 6| Step: 5
Training loss: 2.418750741253722
Validation loss: 2.467997536889346

Epoch: 6| Step: 6
Training loss: 2.741001144225234
Validation loss: 2.4674348184981065

Epoch: 6| Step: 7
Training loss: 2.2898374944606
Validation loss: 2.4695043900085136

Epoch: 6| Step: 8
Training loss: 2.289465129972471
Validation loss: 2.4729041065217396

Epoch: 6| Step: 9
Training loss: 2.4428238072108623
Validation loss: 2.4704994891738186

Epoch: 6| Step: 10
Training loss: 2.32964833237531
Validation loss: 2.474329602675478

Epoch: 6| Step: 11
Training loss: 2.6765263097914085
Validation loss: 2.4807622780927066

Epoch: 6| Step: 12
Training loss: 2.311966293194851
Validation loss: 2.4769968881326982

Epoch: 6| Step: 13
Training loss: 2.326224351318251
Validation loss: 2.481633639204458

Epoch: 181| Step: 0
Training loss: 2.856319441671161
Validation loss: 2.4776581467580745

Epoch: 6| Step: 1
Training loss: 2.8142103292978753
Validation loss: 2.4692977426400096

Epoch: 6| Step: 2
Training loss: 2.7240986444478508
Validation loss: 2.470656274645354

Epoch: 6| Step: 3
Training loss: 2.787985200949404
Validation loss: 2.4744266160510073

Epoch: 6| Step: 4
Training loss: 2.524767734684762
Validation loss: 2.472534932017379

Epoch: 6| Step: 5
Training loss: 2.5634380577465334
Validation loss: 2.4716710703787625

Epoch: 6| Step: 6
Training loss: 2.1335856954002805
Validation loss: 2.470202907742791

Epoch: 6| Step: 7
Training loss: 2.30024751906981
Validation loss: 2.4806030076906125

Epoch: 6| Step: 8
Training loss: 2.474857549710169
Validation loss: 2.4759807043684625

Epoch: 6| Step: 9
Training loss: 1.907402190654305
Validation loss: 2.4742078206935405

Epoch: 6| Step: 10
Training loss: 2.123136825551049
Validation loss: 2.470455160250184

Epoch: 6| Step: 11
Training loss: 2.164179168751235
Validation loss: 2.476537180870427

Epoch: 6| Step: 12
Training loss: 2.2033262769592836
Validation loss: 2.4783760594642303

Epoch: 6| Step: 13
Training loss: 2.57764333213598
Validation loss: 2.4733898808097905

Epoch: 182| Step: 0
Training loss: 3.0403601222308456
Validation loss: 2.4695481406477677

Epoch: 6| Step: 1
Training loss: 2.5241891786619464
Validation loss: 2.472830880232295

Epoch: 6| Step: 2
Training loss: 2.348128539451549
Validation loss: 2.4732544121742257

Epoch: 6| Step: 3
Training loss: 2.5338621436709343
Validation loss: 2.475300737213451

Epoch: 6| Step: 4
Training loss: 2.7456809719883637
Validation loss: 2.4774036924323632

Epoch: 6| Step: 5
Training loss: 2.886568264271489
Validation loss: 2.4752666079333214

Epoch: 6| Step: 6
Training loss: 1.9474396623071601
Validation loss: 2.4799046152752826

Epoch: 6| Step: 7
Training loss: 3.043723329901122
Validation loss: 2.484011281577582

Epoch: 6| Step: 8
Training loss: 1.7467577736270596
Validation loss: 2.4901307167968163

Epoch: 6| Step: 9
Training loss: 2.1430064966741464
Validation loss: 2.484343018715819

Epoch: 6| Step: 10
Training loss: 1.822447543861036
Validation loss: 2.479327803004594

Epoch: 6| Step: 11
Training loss: 2.345294596014741
Validation loss: 2.483181832853185

Epoch: 6| Step: 12
Training loss: 2.4655804145369293
Validation loss: 2.4767677149902956

Epoch: 6| Step: 13
Training loss: 2.1493009184782355
Validation loss: 2.4776027271800376

Epoch: 183| Step: 0
Training loss: 2.5757661142734705
Validation loss: 2.471256898681603

Epoch: 6| Step: 1
Training loss: 2.3206112858710966
Validation loss: 2.4720588432456445

Epoch: 6| Step: 2
Training loss: 2.8857739132139293
Validation loss: 2.470920397386229

Epoch: 6| Step: 3
Training loss: 2.5722356865486766
Validation loss: 2.4726176165977107

Epoch: 6| Step: 4
Training loss: 2.3673645557624563
Validation loss: 2.4727423855290827

Epoch: 6| Step: 5
Training loss: 2.3260933632977485
Validation loss: 2.4770978635763377

Epoch: 6| Step: 6
Training loss: 2.3985774592714324
Validation loss: 2.4746572424141204

Epoch: 6| Step: 7
Training loss: 2.1515181216204367
Validation loss: 2.4713050400594736

Epoch: 6| Step: 8
Training loss: 2.6175946730258715
Validation loss: 2.470143958785918

Epoch: 6| Step: 9
Training loss: 2.125742950711299
Validation loss: 2.4720262284281413

Epoch: 6| Step: 10
Training loss: 1.918196219883689
Validation loss: 2.470453374852344

Epoch: 6| Step: 11
Training loss: 2.8331439759052146
Validation loss: 2.4830166764167263

Epoch: 6| Step: 12
Training loss: 2.6307439176943546
Validation loss: 2.4721468641342312

Epoch: 6| Step: 13
Training loss: 2.3959751474177393
Validation loss: 2.4865166891532464

Epoch: 184| Step: 0
Training loss: 2.670311096441035
Validation loss: 2.4863154033166617

Epoch: 6| Step: 1
Training loss: 2.105704724282172
Validation loss: 2.488938728315549

Epoch: 6| Step: 2
Training loss: 2.3712578454337794
Validation loss: 2.5017858722816766

Epoch: 6| Step: 3
Training loss: 2.6566374552264302
Validation loss: 2.498931274861214

Epoch: 6| Step: 4
Training loss: 2.244450825765034
Validation loss: 2.507086786495259

Epoch: 6| Step: 5
Training loss: 2.827115210566835
Validation loss: 2.502170891755693

Epoch: 6| Step: 6
Training loss: 2.242846880464965
Validation loss: 2.4880212062052562

Epoch: 6| Step: 7
Training loss: 2.410263677394627
Validation loss: 2.4882321994164838

Epoch: 6| Step: 8
Training loss: 2.1941689333075165
Validation loss: 2.484956557305409

Epoch: 6| Step: 9
Training loss: 2.569677025060262
Validation loss: 2.471667469184867

Epoch: 6| Step: 10
Training loss: 2.0780170383948087
Validation loss: 2.471929747774548

Epoch: 6| Step: 11
Training loss: 2.288661674324426
Validation loss: 2.471322501930695

Epoch: 6| Step: 12
Training loss: 2.5811625763726127
Validation loss: 2.4748505091234185

Epoch: 6| Step: 13
Training loss: 2.944450272448388
Validation loss: 2.475064182412603

Epoch: 185| Step: 0
Training loss: 2.158072765435189
Validation loss: 2.4746219400851124

Epoch: 6| Step: 1
Training loss: 2.313737589649817
Validation loss: 2.476250822428824

Epoch: 6| Step: 2
Training loss: 2.0266767224053996
Validation loss: 2.48201154653613

Epoch: 6| Step: 3
Training loss: 2.275902529260177
Validation loss: 2.4783845250072414

Epoch: 6| Step: 4
Training loss: 2.549006968102971
Validation loss: 2.4807545895221192

Epoch: 6| Step: 5
Training loss: 2.823652239657005
Validation loss: 2.4866177014940978

Epoch: 6| Step: 6
Training loss: 2.7093817124509103
Validation loss: 2.4860171283122656

Epoch: 6| Step: 7
Training loss: 2.391537161941717
Validation loss: 2.485681346305494

Epoch: 6| Step: 8
Training loss: 2.9198800686806496
Validation loss: 2.482550817022651

Epoch: 6| Step: 9
Training loss: 2.0541256908897734
Validation loss: 2.476907539599928

Epoch: 6| Step: 10
Training loss: 2.5410424596848804
Validation loss: 2.4789283675313047

Epoch: 6| Step: 11
Training loss: 2.8756895482314526
Validation loss: 2.4728936537904027

Epoch: 6| Step: 12
Training loss: 2.4164231495554582
Validation loss: 2.470740549962559

Epoch: 6| Step: 13
Training loss: 2.318221154788681
Validation loss: 2.47285914580484

Epoch: 186| Step: 0
Training loss: 2.132234488054337
Validation loss: 2.4753610000896376

Epoch: 6| Step: 1
Training loss: 2.552312744624865
Validation loss: 2.4802667330280705

Epoch: 6| Step: 2
Training loss: 3.1903778249438663
Validation loss: 2.4790466236789217

Epoch: 6| Step: 3
Training loss: 2.8311481651198207
Validation loss: 2.4902965263639136

Epoch: 6| Step: 4
Training loss: 1.9712110607725548
Validation loss: 2.475878600026975

Epoch: 6| Step: 5
Training loss: 2.1039450374502593
Validation loss: 2.4857509329635925

Epoch: 6| Step: 6
Training loss: 2.0405541587321907
Validation loss: 2.474375837466747

Epoch: 6| Step: 7
Training loss: 2.644772494650894
Validation loss: 2.476823714767572

Epoch: 6| Step: 8
Training loss: 2.4151472598842227
Validation loss: 2.480719574188859

Epoch: 6| Step: 9
Training loss: 2.5186062793099366
Validation loss: 2.473992041642617

Epoch: 6| Step: 10
Training loss: 2.1663191834599225
Validation loss: 2.4772409819371033

Epoch: 6| Step: 11
Training loss: 2.6764449806936392
Validation loss: 2.4672172069472342

Epoch: 6| Step: 12
Training loss: 2.4782487682015066
Validation loss: 2.4643756242571175

Epoch: 6| Step: 13
Training loss: 2.213138414938559
Validation loss: 2.4598111920666708

Epoch: 187| Step: 0
Training loss: 2.4530089527064725
Validation loss: 2.470252710431581

Epoch: 6| Step: 1
Training loss: 2.6261417993755107
Validation loss: 2.471918897082273

Epoch: 6| Step: 2
Training loss: 2.4559362545998042
Validation loss: 2.4769214005046165

Epoch: 6| Step: 3
Training loss: 2.6695898445359196
Validation loss: 2.47114323049802

Epoch: 6| Step: 4
Training loss: 1.9974485454210364
Validation loss: 2.477123754464038

Epoch: 6| Step: 5
Training loss: 2.3114510296406365
Validation loss: 2.4846459486899106

Epoch: 6| Step: 6
Training loss: 2.4169779829128055
Validation loss: 2.476070559767312

Epoch: 6| Step: 7
Training loss: 2.6547770286942214
Validation loss: 2.4728930672791876

Epoch: 6| Step: 8
Training loss: 3.106283059510318
Validation loss: 2.4985648168299646

Epoch: 6| Step: 9
Training loss: 2.4181330167470376
Validation loss: 2.4948647368261865

Epoch: 6| Step: 10
Training loss: 2.522436173598438
Validation loss: 2.4988466940448237

Epoch: 6| Step: 11
Training loss: 1.9771312754706845
Validation loss: 2.492340609352573

Epoch: 6| Step: 12
Training loss: 1.164634205771045
Validation loss: 2.481336771154849

Epoch: 6| Step: 13
Training loss: 2.6990934969469342
Validation loss: 2.485393547298046

Epoch: 188| Step: 0
Training loss: 2.2454980740348867
Validation loss: 2.4847850421190225

Epoch: 6| Step: 1
Training loss: 1.6372179531025501
Validation loss: 2.4844114592813904

Epoch: 6| Step: 2
Training loss: 2.347757803803933
Validation loss: 2.4857273219956353

Epoch: 6| Step: 3
Training loss: 2.628672981966027
Validation loss: 2.4812424862200966

Epoch: 6| Step: 4
Training loss: 2.2630139267746188
Validation loss: 2.4849886346323014

Epoch: 6| Step: 5
Training loss: 2.6400032891628697
Validation loss: 2.476847266222339

Epoch: 6| Step: 6
Training loss: 2.48401557673609
Validation loss: 2.4761692380693026

Epoch: 6| Step: 7
Training loss: 2.0919775221439445
Validation loss: 2.4829377949594513

Epoch: 6| Step: 8
Training loss: 2.91079225694833
Validation loss: 2.480945579373745

Epoch: 6| Step: 9
Training loss: 2.7980399662514612
Validation loss: 2.4780853435074057

Epoch: 6| Step: 10
Training loss: 2.431584344541966
Validation loss: 2.4832906615881534

Epoch: 6| Step: 11
Training loss: 2.5981030072824662
Validation loss: 2.4900872799183005

Epoch: 6| Step: 12
Training loss: 2.8587115409208983
Validation loss: 2.486116019184328

Epoch: 6| Step: 13
Training loss: 1.9197146050615115
Validation loss: 2.4984034844699825

Epoch: 189| Step: 0
Training loss: 2.583757386217785
Validation loss: 2.495477814315064

Epoch: 6| Step: 1
Training loss: 2.392848956291331
Validation loss: 2.4850272995736815

Epoch: 6| Step: 2
Training loss: 2.824958925876949
Validation loss: 2.4909955705107913

Epoch: 6| Step: 3
Training loss: 2.1977105669292376
Validation loss: 2.4881110579786694

Epoch: 6| Step: 4
Training loss: 2.6267901175029444
Validation loss: 2.498696583476994

Epoch: 6| Step: 5
Training loss: 2.464471126870969
Validation loss: 2.489137279714624

Epoch: 6| Step: 6
Training loss: 2.5635171127745164
Validation loss: 2.486677674131942

Epoch: 6| Step: 7
Training loss: 1.4936623200416672
Validation loss: 2.4816414291306077

Epoch: 6| Step: 8
Training loss: 2.4479523568223245
Validation loss: 2.469898906188506

Epoch: 6| Step: 9
Training loss: 2.866136072276096
Validation loss: 2.478491864943491

Epoch: 6| Step: 10
Training loss: 2.514567656469478
Validation loss: 2.475987204109328

Epoch: 6| Step: 11
Training loss: 2.408168968830922
Validation loss: 2.4828094892121473

Epoch: 6| Step: 12
Training loss: 2.1191955278026127
Validation loss: 2.4773862253054717

Epoch: 6| Step: 13
Training loss: 2.5425027399789157
Validation loss: 2.4805015581819796

Epoch: 190| Step: 0
Training loss: 2.890077776274798
Validation loss: 2.4803467247451967

Epoch: 6| Step: 1
Training loss: 2.192847446066965
Validation loss: 2.48270907417686

Epoch: 6| Step: 2
Training loss: 2.2380138723507663
Validation loss: 2.4929644052341513

Epoch: 6| Step: 3
Training loss: 2.358719387290429
Validation loss: 2.4887161074517494

Epoch: 6| Step: 4
Training loss: 3.3205684069580745
Validation loss: 2.4991220681117277

Epoch: 6| Step: 5
Training loss: 2.1228284398826394
Validation loss: 2.4976393044296326

Epoch: 6| Step: 6
Training loss: 1.9712472245820318
Validation loss: 2.5039345139104956

Epoch: 6| Step: 7
Training loss: 2.4234220424333754
Validation loss: 2.5021875506403

Epoch: 6| Step: 8
Training loss: 2.4374280087525793
Validation loss: 2.5044847951731994

Epoch: 6| Step: 9
Training loss: 2.0088548144167295
Validation loss: 2.505716035806244

Epoch: 6| Step: 10
Training loss: 2.3439200784643908
Validation loss: 2.501410880925565

Epoch: 6| Step: 11
Training loss: 2.7183811332137733
Validation loss: 2.494195493902633

Epoch: 6| Step: 12
Training loss: 1.9330179609479607
Validation loss: 2.4921762113405186

Epoch: 6| Step: 13
Training loss: 2.5470436836034205
Validation loss: 2.4905698861884993

Epoch: 191| Step: 0
Training loss: 2.757592038428243
Validation loss: 2.497677534893886

Epoch: 6| Step: 1
Training loss: 2.12380790932362
Validation loss: 2.4911715390868148

Epoch: 6| Step: 2
Training loss: 2.0275663573369282
Validation loss: 2.500180285628935

Epoch: 6| Step: 3
Training loss: 2.2708895848391135
Validation loss: 2.4978235148373096

Epoch: 6| Step: 4
Training loss: 2.943920828687663
Validation loss: 2.509195297096451

Epoch: 6| Step: 5
Training loss: 2.4308958330076256
Validation loss: 2.5120145110421883

Epoch: 6| Step: 6
Training loss: 1.7852255642912942
Validation loss: 2.5360667235143763

Epoch: 6| Step: 7
Training loss: 3.1544549955530714
Validation loss: 2.5282506008564294

Epoch: 6| Step: 8
Training loss: 2.878528420073934
Validation loss: 2.519306419257398

Epoch: 6| Step: 9
Training loss: 2.1606691934503512
Validation loss: 2.4959456629197936

Epoch: 6| Step: 10
Training loss: 2.3622053739717046
Validation loss: 2.4881402199790803

Epoch: 6| Step: 11
Training loss: 2.0309926970447774
Validation loss: 2.4842947381128155

Epoch: 6| Step: 12
Training loss: 2.6071900682597864
Validation loss: 2.4821091801880018

Epoch: 6| Step: 13
Training loss: 2.252769884544349
Validation loss: 2.484550006068673

Epoch: 192| Step: 0
Training loss: 2.181326629254517
Validation loss: 2.48050484218021

Epoch: 6| Step: 1
Training loss: 2.459607543033455
Validation loss: 2.4787617574474807

Epoch: 6| Step: 2
Training loss: 2.291347573924307
Validation loss: 2.473262927380531

Epoch: 6| Step: 3
Training loss: 2.3137885962533082
Validation loss: 2.473770268302438

Epoch: 6| Step: 4
Training loss: 2.9455378519558506
Validation loss: 2.472506823451569

Epoch: 6| Step: 5
Training loss: 2.47014259946059
Validation loss: 2.480499395546625

Epoch: 6| Step: 6
Training loss: 2.5113566895564987
Validation loss: 2.474489044017719

Epoch: 6| Step: 7
Training loss: 1.781124311329349
Validation loss: 2.486336387666496

Epoch: 6| Step: 8
Training loss: 2.234920621823525
Validation loss: 2.479046174869236

Epoch: 6| Step: 9
Training loss: 2.6206556428754917
Validation loss: 2.4922307886651143

Epoch: 6| Step: 10
Training loss: 2.441071363750676
Validation loss: 2.4952933988912998

Epoch: 6| Step: 11
Training loss: 2.7839201207759325
Validation loss: 2.4977724800990764

Epoch: 6| Step: 12
Training loss: 2.6123386387980645
Validation loss: 2.5007267849207007

Epoch: 6| Step: 13
Training loss: 2.350290759340721
Validation loss: 2.498171558902236

Epoch: 193| Step: 0
Training loss: 2.612715724087682
Validation loss: 2.503925182570495

Epoch: 6| Step: 1
Training loss: 2.4402133804573496
Validation loss: 2.4914375221073746

Epoch: 6| Step: 2
Training loss: 2.948516317424934
Validation loss: 2.494830938891554

Epoch: 6| Step: 3
Training loss: 2.137024350253848
Validation loss: 2.4921623555572183

Epoch: 6| Step: 4
Training loss: 2.037596310638634
Validation loss: 2.4885117260896363

Epoch: 6| Step: 5
Training loss: 2.4383203153160595
Validation loss: 2.489127573622216

Epoch: 6| Step: 6
Training loss: 2.272769580794061
Validation loss: 2.4937402000011604

Epoch: 6| Step: 7
Training loss: 2.4797542954830822
Validation loss: 2.486821679260068

Epoch: 6| Step: 8
Training loss: 3.1904683970428693
Validation loss: 2.496629907119266

Epoch: 6| Step: 9
Training loss: 2.4401912015512583
Validation loss: 2.481430067675853

Epoch: 6| Step: 10
Training loss: 2.5720650399914637
Validation loss: 2.491685232733341

Epoch: 6| Step: 11
Training loss: 1.7886975178460194
Validation loss: 2.481975092025932

Epoch: 6| Step: 12
Training loss: 1.6522060905090312
Validation loss: 2.502197571326808

Epoch: 6| Step: 13
Training loss: 2.351607515531555
Validation loss: 2.4875158133714996

Epoch: 194| Step: 0
Training loss: 2.8782012366056753
Validation loss: 2.491403406539703

Epoch: 6| Step: 1
Training loss: 2.5632751967042684
Validation loss: 2.476667528302063

Epoch: 6| Step: 2
Training loss: 2.205202354263275
Validation loss: 2.490642694644143

Epoch: 6| Step: 3
Training loss: 2.5199668803384956
Validation loss: 2.4968309025377575

Epoch: 6| Step: 4
Training loss: 2.801241912625855
Validation loss: 2.4880876770261

Epoch: 6| Step: 5
Training loss: 2.3442067019229196
Validation loss: 2.4967641870308155

Epoch: 6| Step: 6
Training loss: 2.6007064006436083
Validation loss: 2.493531991516648

Epoch: 6| Step: 7
Training loss: 2.376775379164579
Validation loss: 2.496705220624665

Epoch: 6| Step: 8
Training loss: 2.369967600122133
Validation loss: 2.4958648019461527

Epoch: 6| Step: 9
Training loss: 2.0104383819935814
Validation loss: 2.4926741074155743

Epoch: 6| Step: 10
Training loss: 2.5648397603092543
Validation loss: 2.484665795667513

Epoch: 6| Step: 11
Training loss: 2.201791887536542
Validation loss: 2.48496970170379

Epoch: 6| Step: 12
Training loss: 2.0863359049395056
Validation loss: 2.4835015926920465

Epoch: 6| Step: 13
Training loss: 2.093953820172065
Validation loss: 2.4917973259782262

Epoch: 195| Step: 0
Training loss: 1.6237510870268415
Validation loss: 2.4875649819121173

Epoch: 6| Step: 1
Training loss: 2.5547337892404207
Validation loss: 2.4850132919969194

Epoch: 6| Step: 2
Training loss: 2.6711148078492295
Validation loss: 2.4911550378253877

Epoch: 6| Step: 3
Training loss: 2.901815332953236
Validation loss: 2.4870147596012546

Epoch: 6| Step: 4
Training loss: 2.7602136117398746
Validation loss: 2.493297987201202

Epoch: 6| Step: 5
Training loss: 2.397787894584204
Validation loss: 2.4813172178348095

Epoch: 6| Step: 6
Training loss: 1.8387636549576825
Validation loss: 2.4970292083137995

Epoch: 6| Step: 7
Training loss: 2.6876765348428417
Validation loss: 2.49312144351507

Epoch: 6| Step: 8
Training loss: 2.481679161489512
Validation loss: 2.4998501414842336

Epoch: 6| Step: 9
Training loss: 1.9533759604393277
Validation loss: 2.491541460861369

Epoch: 6| Step: 10
Training loss: 2.3812789234397265
Validation loss: 2.5002711466931924

Epoch: 6| Step: 11
Training loss: 2.177542338435961
Validation loss: 2.505229836184612

Epoch: 6| Step: 12
Training loss: 2.731860241488997
Validation loss: 2.4989887735522482

Epoch: 6| Step: 13
Training loss: 2.329565229987476
Validation loss: 2.5000547403064615

Epoch: 196| Step: 0
Training loss: 2.6734976498087137
Validation loss: 2.4994093117660454

Epoch: 6| Step: 1
Training loss: 2.7908198272600004
Validation loss: 2.4930391201893145

Epoch: 6| Step: 2
Training loss: 3.339433397214071
Validation loss: 2.496103237971828

Epoch: 6| Step: 3
Training loss: 1.981430753049947
Validation loss: 2.482283569613009

Epoch: 6| Step: 4
Training loss: 2.3639959090208746
Validation loss: 2.4901925356472954

Epoch: 6| Step: 5
Training loss: 2.558078580053497
Validation loss: 2.4813404784213295

Epoch: 6| Step: 6
Training loss: 2.2584369152380286
Validation loss: 2.480811692607863

Epoch: 6| Step: 7
Training loss: 2.285719790622349
Validation loss: 2.4865269647615746

Epoch: 6| Step: 8
Training loss: 2.1832068685737385
Validation loss: 2.4862323032322786

Epoch: 6| Step: 9
Training loss: 2.332338348053259
Validation loss: 2.486575673443858

Epoch: 6| Step: 10
Training loss: 2.675741420922778
Validation loss: 2.4934877931805883

Epoch: 6| Step: 11
Training loss: 2.1790418318032665
Validation loss: 2.493012007885233

Epoch: 6| Step: 12
Training loss: 2.0388485149482634
Validation loss: 2.4909691777414684

Epoch: 6| Step: 13
Training loss: 1.6531768213813929
Validation loss: 2.4892483622891755

Epoch: 197| Step: 0
Training loss: 2.2517930409818
Validation loss: 2.498195585109902

Epoch: 6| Step: 1
Training loss: 2.777698435180061
Validation loss: 2.4922420133011896

Epoch: 6| Step: 2
Training loss: 2.509009340088702
Validation loss: 2.506840740417706

Epoch: 6| Step: 3
Training loss: 2.5598570056556476
Validation loss: 2.509104014864197

Epoch: 6| Step: 4
Training loss: 1.975344014688109
Validation loss: 2.518352451613755

Epoch: 6| Step: 5
Training loss: 2.751213932866842
Validation loss: 2.5252202589449326

Epoch: 6| Step: 6
Training loss: 1.6444006208789332
Validation loss: 2.5193435796192998

Epoch: 6| Step: 7
Training loss: 2.197809828441075
Validation loss: 2.52763640936496

Epoch: 6| Step: 8
Training loss: 2.994576479049983
Validation loss: 2.5175159684413155

Epoch: 6| Step: 9
Training loss: 2.11957294607295
Validation loss: 2.5071379169213084

Epoch: 6| Step: 10
Training loss: 2.4522659838724588
Validation loss: 2.5093138133467776

Epoch: 6| Step: 11
Training loss: 2.2873522517949665
Validation loss: 2.5072549297164994

Epoch: 6| Step: 12
Training loss: 2.562906279572055
Validation loss: 2.49899424349155

Epoch: 6| Step: 13
Training loss: 2.178800997375238
Validation loss: 2.4918715496946695

Epoch: 198| Step: 0
Training loss: 2.6732759428007844
Validation loss: 2.4898021926340315

Epoch: 6| Step: 1
Training loss: 2.4656050725984966
Validation loss: 2.497042289161903

Epoch: 6| Step: 2
Training loss: 2.826497658259422
Validation loss: 2.4851382540615172

Epoch: 6| Step: 3
Training loss: 3.1450081220803963
Validation loss: 2.4764581170933355

Epoch: 6| Step: 4
Training loss: 2.444743617370806
Validation loss: 2.47757392230261

Epoch: 6| Step: 5
Training loss: 2.5492469648085194
Validation loss: 2.4748507740489383

Epoch: 6| Step: 6
Training loss: 2.5010804702521585
Validation loss: 2.478963929122541

Epoch: 6| Step: 7
Training loss: 2.530886023455166
Validation loss: 2.4788811436425795

Epoch: 6| Step: 8
Training loss: 2.2064333485612173
Validation loss: 2.4823437029888042

Epoch: 6| Step: 9
Training loss: 2.5308249787850183
Validation loss: 2.4895234572952756

Epoch: 6| Step: 10
Training loss: 1.7068192199733427
Validation loss: 2.4932727264579264

Epoch: 6| Step: 11
Training loss: 2.103166046422213
Validation loss: 2.494782885149086

Epoch: 6| Step: 12
Training loss: 1.8952477427565901
Validation loss: 2.5016727732160917

Epoch: 6| Step: 13
Training loss: 1.8919424085703036
Validation loss: 2.517904271834858

Epoch: 199| Step: 0
Training loss: 2.7615682730895528
Validation loss: 2.507502551548155

Epoch: 6| Step: 1
Training loss: 2.8731391523675263
Validation loss: 2.5221219565459565

Epoch: 6| Step: 2
Training loss: 2.3706978431249346
Validation loss: 2.5244086476408722

Epoch: 6| Step: 3
Training loss: 2.125907255487771
Validation loss: 2.5156735559678087

Epoch: 6| Step: 4
Training loss: 1.3063412994893975
Validation loss: 2.51048251549769

Epoch: 6| Step: 5
Training loss: 1.9785461724682458
Validation loss: 2.509929345872868

Epoch: 6| Step: 6
Training loss: 2.6738479201125362
Validation loss: 2.5023879408668566

Epoch: 6| Step: 7
Training loss: 2.485177924005612
Validation loss: 2.488958165883008

Epoch: 6| Step: 8
Training loss: 2.1853488699473425
Validation loss: 2.4910466244516285

Epoch: 6| Step: 9
Training loss: 2.2948250478243586
Validation loss: 2.4883067610314717

Epoch: 6| Step: 10
Training loss: 2.0901424016306254
Validation loss: 2.4914224022219793

Epoch: 6| Step: 11
Training loss: 2.7172034238466063
Validation loss: 2.487790676686158

Epoch: 6| Step: 12
Training loss: 2.7398926786302007
Validation loss: 2.4853033574493866

Epoch: 6| Step: 13
Training loss: 2.739351637486292
Validation loss: 2.486131227282851

Epoch: 200| Step: 0
Training loss: 2.457043573442615
Validation loss: 2.4871020594619537

Epoch: 6| Step: 1
Training loss: 2.5030091295795924
Validation loss: 2.4947953884492535

Epoch: 6| Step: 2
Training loss: 2.1879082435044275
Validation loss: 2.4920106065686665

Epoch: 6| Step: 3
Training loss: 2.677924819284148
Validation loss: 2.4849792161580235

Epoch: 6| Step: 4
Training loss: 2.456455181375282
Validation loss: 2.4957033587340356

Epoch: 6| Step: 5
Training loss: 2.079296040252627
Validation loss: 2.4989554050731053

Epoch: 6| Step: 6
Training loss: 1.88541153824532
Validation loss: 2.494020320228324

Epoch: 6| Step: 7
Training loss: 2.6520638184729677
Validation loss: 2.4952214666524553

Epoch: 6| Step: 8
Training loss: 2.6478100598892533
Validation loss: 2.4951610305029748

Epoch: 6| Step: 9
Training loss: 2.659964264651161
Validation loss: 2.4903116690414535

Epoch: 6| Step: 10
Training loss: 2.212974014798488
Validation loss: 2.488399700417598

Epoch: 6| Step: 11
Training loss: 2.050729631046794
Validation loss: 2.4917405543859705

Epoch: 6| Step: 12
Training loss: 2.109460334464586
Validation loss: 2.50991175680076

Epoch: 6| Step: 13
Training loss: 2.945453994549701
Validation loss: 2.501129213257548

Epoch: 201| Step: 0
Training loss: 2.411954385202761
Validation loss: 2.525136275438158

Epoch: 6| Step: 1
Training loss: 2.4804186718308543
Validation loss: 2.5298519669323682

Epoch: 6| Step: 2
Training loss: 2.5337662611346876
Validation loss: 2.5207325360871917

Epoch: 6| Step: 3
Training loss: 2.186848570693128
Validation loss: 2.51977408567122

Epoch: 6| Step: 4
Training loss: 2.669475526482087
Validation loss: 2.5173994641652655

Epoch: 6| Step: 5
Training loss: 2.3458771271849703
Validation loss: 2.5043658441259273

Epoch: 6| Step: 6
Training loss: 2.9400545740576822
Validation loss: 2.5127806764531075

Epoch: 6| Step: 7
Training loss: 2.8754194202491905
Validation loss: 2.505444066832376

Epoch: 6| Step: 8
Training loss: 2.07271842072466
Validation loss: 2.504832619603517

Epoch: 6| Step: 9
Training loss: 2.2165667040473225
Validation loss: 2.4945815972833523

Epoch: 6| Step: 10
Training loss: 1.828878524550566
Validation loss: 2.4991789900206762

Epoch: 6| Step: 11
Training loss: 2.865164310610202
Validation loss: 2.499305509424935

Epoch: 6| Step: 12
Training loss: 2.223894950684152
Validation loss: 2.4954542316847794

Epoch: 6| Step: 13
Training loss: 1.4377592101872523
Validation loss: 2.4953863328470223

Epoch: 202| Step: 0
Training loss: 2.639341685838901
Validation loss: 2.502791086467998

Epoch: 6| Step: 1
Training loss: 2.7290014163552114
Validation loss: 2.5074974091866045

Epoch: 6| Step: 2
Training loss: 2.234096589782825
Validation loss: 2.503332809349984

Epoch: 6| Step: 3
Training loss: 2.5228274526239187
Validation loss: 2.5029674720169526

Epoch: 6| Step: 4
Training loss: 1.5740042036211237
Validation loss: 2.507739500763907

Epoch: 6| Step: 5
Training loss: 2.531519651767281
Validation loss: 2.506322352632595

Epoch: 6| Step: 6
Training loss: 1.905251413410635
Validation loss: 2.5003965381214095

Epoch: 6| Step: 7
Training loss: 2.827357741334717
Validation loss: 2.507731609683835

Epoch: 6| Step: 8
Training loss: 2.788954703334164
Validation loss: 2.501566682105586

Epoch: 6| Step: 9
Training loss: 2.201347120699729
Validation loss: 2.506073575615978

Epoch: 6| Step: 10
Training loss: 2.039727581197859
Validation loss: 2.512670167692638

Epoch: 6| Step: 11
Training loss: 1.771157837100731
Validation loss: 2.513109944135688

Epoch: 6| Step: 12
Training loss: 2.545144645912236
Validation loss: 2.516027098559802

Epoch: 6| Step: 13
Training loss: 2.691868181824491
Validation loss: 2.508090153393542

Epoch: 203| Step: 0
Training loss: 2.481652837765577
Validation loss: 2.512398856611821

Epoch: 6| Step: 1
Training loss: 2.0964271169412805
Validation loss: 2.5117687578300427

Epoch: 6| Step: 2
Training loss: 2.354679715675898
Validation loss: 2.5236425956152844

Epoch: 6| Step: 3
Training loss: 2.5116672065631342
Validation loss: 2.5155479940629157

Epoch: 6| Step: 4
Training loss: 2.6989723015770606
Validation loss: 2.515668145988511

Epoch: 6| Step: 5
Training loss: 2.4733652360954475
Validation loss: 2.503371254455535

Epoch: 6| Step: 6
Training loss: 1.80664326435618
Validation loss: 2.51804470792373

Epoch: 6| Step: 7
Training loss: 1.892108051827712
Validation loss: 2.5137075457725646

Epoch: 6| Step: 8
Training loss: 2.2731409043266217
Validation loss: 2.5146450400715317

Epoch: 6| Step: 9
Training loss: 1.7529170383857688
Validation loss: 2.5110641267154397

Epoch: 6| Step: 10
Training loss: 3.0403690618554187
Validation loss: 2.515823372232236

Epoch: 6| Step: 11
Training loss: 3.076639349400462
Validation loss: 2.5085097915157215

Epoch: 6| Step: 12
Training loss: 2.4937310775000676
Validation loss: 2.497892333721627

Epoch: 6| Step: 13
Training loss: 1.7976973269070355
Validation loss: 2.5197993803648715

Epoch: 204| Step: 0
Training loss: 2.4046800123746324
Validation loss: 2.5120874888675258

Epoch: 6| Step: 1
Training loss: 2.7533421581240805
Validation loss: 2.5072191592167092

Epoch: 6| Step: 2
Training loss: 1.9296639012426577
Validation loss: 2.514169718287758

Epoch: 6| Step: 3
Training loss: 2.7269694289706528
Validation loss: 2.507582823316375

Epoch: 6| Step: 4
Training loss: 2.178196222572039
Validation loss: 2.5047379737507165

Epoch: 6| Step: 5
Training loss: 2.31693214249306
Validation loss: 2.518594777741096

Epoch: 6| Step: 6
Training loss: 2.163970835152504
Validation loss: 2.5198490859059333

Epoch: 6| Step: 7
Training loss: 2.5164825683693377
Validation loss: 2.5167277744486904

Epoch: 6| Step: 8
Training loss: 2.5965753816254553
Validation loss: 2.5064741070912424

Epoch: 6| Step: 9
Training loss: 2.486762572971098
Validation loss: 2.5102125826198733

Epoch: 6| Step: 10
Training loss: 2.308987501616951
Validation loss: 2.5065605865345657

Epoch: 6| Step: 11
Training loss: 2.2681692635954427
Validation loss: 2.5236401392904133

Epoch: 6| Step: 12
Training loss: 1.466656105408068
Validation loss: 2.505812230488051

Epoch: 6| Step: 13
Training loss: 2.884478989335334
Validation loss: 2.5052873806500866

Epoch: 205| Step: 0
Training loss: 1.8030090453417666
Validation loss: 2.5071425766169084

Epoch: 6| Step: 1
Training loss: 2.459226952329525
Validation loss: 2.50573980730507

Epoch: 6| Step: 2
Training loss: 3.094278309728561
Validation loss: 2.502204622308792

Epoch: 6| Step: 3
Training loss: 2.2628302865237444
Validation loss: 2.499197775556089

Epoch: 6| Step: 4
Training loss: 2.359041809403641
Validation loss: 2.4972099311911804

Epoch: 6| Step: 5
Training loss: 2.0000323054565574
Validation loss: 2.491876245910879

Epoch: 6| Step: 6
Training loss: 2.5870607823389293
Validation loss: 2.499986791575825

Epoch: 6| Step: 7
Training loss: 2.699711491040696
Validation loss: 2.5003577453234564

Epoch: 6| Step: 8
Training loss: 2.0908809761750575
Validation loss: 2.4964916566780264

Epoch: 6| Step: 9
Training loss: 1.9608038746568675
Validation loss: 2.5043105474977563

Epoch: 6| Step: 10
Training loss: 2.6954549116022988
Validation loss: 2.494854670759695

Epoch: 6| Step: 11
Training loss: 1.7591814602088742
Validation loss: 2.4933998403841917

Epoch: 6| Step: 12
Training loss: 2.4086219689432635
Validation loss: 2.4987454604488812

Epoch: 6| Step: 13
Training loss: 2.811305067745129
Validation loss: 2.495823096783449

Epoch: 206| Step: 0
Training loss: 1.9854222935706582
Validation loss: 2.503986660860869

Epoch: 6| Step: 1
Training loss: 2.6933536211357594
Validation loss: 2.531935924637295

Epoch: 6| Step: 2
Training loss: 2.227471417073493
Validation loss: 2.5434378383217706

Epoch: 6| Step: 3
Training loss: 2.0338728183830526
Validation loss: 2.5451020620774503

Epoch: 6| Step: 4
Training loss: 1.8932908864479296
Validation loss: 2.5501854878948462

Epoch: 6| Step: 5
Training loss: 2.615068813607463
Validation loss: 2.5429584836972348

Epoch: 6| Step: 6
Training loss: 3.1990327326872863
Validation loss: 2.528021523551014

Epoch: 6| Step: 7
Training loss: 2.201030520188114
Validation loss: 2.5176247808702135

Epoch: 6| Step: 8
Training loss: 2.612147155004751
Validation loss: 2.510325708495809

Epoch: 6| Step: 9
Training loss: 2.115606527092887
Validation loss: 2.4885840199313978

Epoch: 6| Step: 10
Training loss: 2.5996418412815823
Validation loss: 2.476804366470278

Epoch: 6| Step: 11
Training loss: 1.7098438826341917
Validation loss: 2.4834556557997427

Epoch: 6| Step: 12
Training loss: 2.5673884772248745
Validation loss: 2.473593808808008

Epoch: 6| Step: 13
Training loss: 3.0172731313303163
Validation loss: 2.4824990601424184

Epoch: 207| Step: 0
Training loss: 2.158657333426104
Validation loss: 2.473799213847053

Epoch: 6| Step: 1
Training loss: 1.9351154543319213
Validation loss: 2.4856546013629517

Epoch: 6| Step: 2
Training loss: 2.1705947505689562
Validation loss: 2.4874581613009323

Epoch: 6| Step: 3
Training loss: 2.6250252495414172
Validation loss: 2.4908234501635484

Epoch: 6| Step: 4
Training loss: 2.006126319186485
Validation loss: 2.4917021530924486

Epoch: 6| Step: 5
Training loss: 2.3777758789451044
Validation loss: 2.5001182766592187

Epoch: 6| Step: 6
Training loss: 2.249198770914653
Validation loss: 2.499421211636467

Epoch: 6| Step: 7
Training loss: 1.9836866731877825
Validation loss: 2.507012165266785

Epoch: 6| Step: 8
Training loss: 2.5999340195720215
Validation loss: 2.510829453674756

Epoch: 6| Step: 9
Training loss: 2.02731693669046
Validation loss: 2.4927173716892286

Epoch: 6| Step: 10
Training loss: 2.617440373744438
Validation loss: 2.4994070303548903

Epoch: 6| Step: 11
Training loss: 2.4915380319245313
Validation loss: 2.4928735807116036

Epoch: 6| Step: 12
Training loss: 3.2489871867811613
Validation loss: 2.4917411763289605

Epoch: 6| Step: 13
Training loss: 2.954765550378344
Validation loss: 2.4952850703366285

Epoch: 208| Step: 0
Training loss: 2.419204125170748
Validation loss: 2.497912998106625

Epoch: 6| Step: 1
Training loss: 2.7811145535180746
Validation loss: 2.5067983222519987

Epoch: 6| Step: 2
Training loss: 2.08339956814063
Validation loss: 2.515046086644307

Epoch: 6| Step: 3
Training loss: 1.74428155378812
Validation loss: 2.500990814323289

Epoch: 6| Step: 4
Training loss: 2.3602746928098854
Validation loss: 2.519732263713013

Epoch: 6| Step: 5
Training loss: 2.921725835409579
Validation loss: 2.5054673333952557

Epoch: 6| Step: 6
Training loss: 2.150652045800746
Validation loss: 2.511088820785664

Epoch: 6| Step: 7
Training loss: 2.2253907449918784
Validation loss: 2.5049696165515045

Epoch: 6| Step: 8
Training loss: 2.619200339550446
Validation loss: 2.50535612139642

Epoch: 6| Step: 9
Training loss: 2.7453999626457017
Validation loss: 2.5067846186216762

Epoch: 6| Step: 10
Training loss: 2.360394794287579
Validation loss: 2.5105235893515383

Epoch: 6| Step: 11
Training loss: 1.6727461639711507
Validation loss: 2.5102069709118355

Epoch: 6| Step: 12
Training loss: 2.563506417236867
Validation loss: 2.5157021773289254

Epoch: 6| Step: 13
Training loss: 2.230557254565225
Validation loss: 2.514874427294657

Epoch: 209| Step: 0
Training loss: 1.8475208837750947
Validation loss: 2.5053525369001908

Epoch: 6| Step: 1
Training loss: 2.389600546746308
Validation loss: 2.5087687886409964

Epoch: 6| Step: 2
Training loss: 2.3709895756820956
Validation loss: 2.508199192549613

Epoch: 6| Step: 3
Training loss: 2.3465870280551746
Validation loss: 2.5230265342757505

Epoch: 6| Step: 4
Training loss: 3.0651517014664917
Validation loss: 2.5150852769584837

Epoch: 6| Step: 5
Training loss: 2.7897666234679073
Validation loss: 2.532450536475195

Epoch: 6| Step: 6
Training loss: 1.8253390611238711
Validation loss: 2.5288303411383053

Epoch: 6| Step: 7
Training loss: 2.5031238113000454
Validation loss: 2.521725998344572

Epoch: 6| Step: 8
Training loss: 2.75770391407155
Validation loss: 2.512508570718144

Epoch: 6| Step: 9
Training loss: 1.7236745164705134
Validation loss: 2.509465695678417

Epoch: 6| Step: 10
Training loss: 2.478666164194309
Validation loss: 2.5193400938870862

Epoch: 6| Step: 11
Training loss: 2.3622996411815675
Validation loss: 2.504106470951246

Epoch: 6| Step: 12
Training loss: 2.0877228714983915
Validation loss: 2.5019495832749215

Epoch: 6| Step: 13
Training loss: 2.386115014967749
Validation loss: 2.5024066626145025

Epoch: 210| Step: 0
Training loss: 1.834751151671245
Validation loss: 2.5056588183587083

Epoch: 6| Step: 1
Training loss: 2.585323295372449
Validation loss: 2.5104794527383123

Epoch: 6| Step: 2
Training loss: 2.52079601628029
Validation loss: 2.5213517110542476

Epoch: 6| Step: 3
Training loss: 2.1370104044980938
Validation loss: 2.5384714230876266

Epoch: 6| Step: 4
Training loss: 2.7264319445988474
Validation loss: 2.535957840583097

Epoch: 6| Step: 5
Training loss: 2.162677638525046
Validation loss: 2.5346626541825663

Epoch: 6| Step: 6
Training loss: 2.051108139869868
Validation loss: 2.5383154762960776

Epoch: 6| Step: 7
Training loss: 2.3253513685950256
Validation loss: 2.5315382914948827

Epoch: 6| Step: 8
Training loss: 2.5774475132272165
Validation loss: 2.5093960778161524

Epoch: 6| Step: 9
Training loss: 2.1228596623198013
Validation loss: 2.5136753844004738

Epoch: 6| Step: 10
Training loss: 2.2763066490368162
Validation loss: 2.507751163037583

Epoch: 6| Step: 11
Training loss: 2.7070383839699015
Validation loss: 2.5197559976017825

Epoch: 6| Step: 12
Training loss: 2.421346299083518
Validation loss: 2.5084325354678145

Epoch: 6| Step: 13
Training loss: 2.66755031806372
Validation loss: 2.5029839509679848

Epoch: 211| Step: 0
Training loss: 2.4535525975860173
Validation loss: 2.498195561250823

Epoch: 6| Step: 1
Training loss: 1.9810993462212814
Validation loss: 2.4880488839636814

Epoch: 6| Step: 2
Training loss: 2.452039539223726
Validation loss: 2.4872316455338295

Epoch: 6| Step: 3
Training loss: 2.4090695396574833
Validation loss: 2.482270827201251

Epoch: 6| Step: 4
Training loss: 1.9609800539300803
Validation loss: 2.486623374427455

Epoch: 6| Step: 5
Training loss: 2.6749882991927034
Validation loss: 2.480829231720971

Epoch: 6| Step: 6
Training loss: 2.311320339058893
Validation loss: 2.479391317580704

Epoch: 6| Step: 7
Training loss: 2.442892223558803
Validation loss: 2.4800348498090288

Epoch: 6| Step: 8
Training loss: 2.468909342971312
Validation loss: 2.4882035495318084

Epoch: 6| Step: 9
Training loss: 2.839945501422484
Validation loss: 2.49188539912179

Epoch: 6| Step: 10
Training loss: 1.8844975572399685
Validation loss: 2.4888875034116493

Epoch: 6| Step: 11
Training loss: 2.334374558781961
Validation loss: 2.493601637962708

Epoch: 6| Step: 12
Training loss: 2.408000160939664
Validation loss: 2.502163912142376

Epoch: 6| Step: 13
Training loss: 2.627219850974643
Validation loss: 2.499182869567278

Epoch: 212| Step: 0
Training loss: 2.9966141349536
Validation loss: 2.5127269092030584

Epoch: 6| Step: 1
Training loss: 2.5334897904853797
Validation loss: 2.5067611027321406

Epoch: 6| Step: 2
Training loss: 1.862969778326663
Validation loss: 2.521253863375668

Epoch: 6| Step: 3
Training loss: 1.5144987345929808
Validation loss: 2.5361136033137726

Epoch: 6| Step: 4
Training loss: 2.3368181590747583
Validation loss: 2.521852363506892

Epoch: 6| Step: 5
Training loss: 2.177073890872416
Validation loss: 2.5264817526328422

Epoch: 6| Step: 6
Training loss: 2.7064606476661957
Validation loss: 2.5390836900658247

Epoch: 6| Step: 7
Training loss: 2.261101145908517
Validation loss: 2.5170984948222657

Epoch: 6| Step: 8
Training loss: 2.0581439864241178
Validation loss: 2.528066462030434

Epoch: 6| Step: 9
Training loss: 2.536624994357564
Validation loss: 2.5298614382463662

Epoch: 6| Step: 10
Training loss: 2.6351325343060363
Validation loss: 2.538984952867274

Epoch: 6| Step: 11
Training loss: 2.852463002612727
Validation loss: 2.5310485508508767

Epoch: 6| Step: 12
Training loss: 1.9545079332504425
Validation loss: 2.505219946587835

Epoch: 6| Step: 13
Training loss: 2.3413449981691423
Validation loss: 2.506393744325304

Epoch: 213| Step: 0
Training loss: 2.784316611828397
Validation loss: 2.505805617816555

Epoch: 6| Step: 1
Training loss: 2.1011701593429275
Validation loss: 2.488757301037571

Epoch: 6| Step: 2
Training loss: 1.6815797305185807
Validation loss: 2.495829393599197

Epoch: 6| Step: 3
Training loss: 2.3604577213857194
Validation loss: 2.480013972366104

Epoch: 6| Step: 4
Training loss: 1.9605074103093019
Validation loss: 2.4882841324801994

Epoch: 6| Step: 5
Training loss: 2.24773335196985
Validation loss: 2.494954764198793

Epoch: 6| Step: 6
Training loss: 2.0725295377865085
Validation loss: 2.4879878423583874

Epoch: 6| Step: 7
Training loss: 2.077903563669322
Validation loss: 2.5046659716567183

Epoch: 6| Step: 8
Training loss: 2.8427380448565436
Validation loss: 2.5027019205098284

Epoch: 6| Step: 9
Training loss: 2.465706409807387
Validation loss: 2.5184954581680126

Epoch: 6| Step: 10
Training loss: 2.6269648328328787
Validation loss: 2.5131897917298582

Epoch: 6| Step: 11
Training loss: 2.3982506098297627
Validation loss: 2.5152468505714283

Epoch: 6| Step: 12
Training loss: 2.7734502227921207
Validation loss: 2.5233120882188937

Epoch: 6| Step: 13
Training loss: 2.5068202447344325
Validation loss: 2.531696295934211

Epoch: 214| Step: 0
Training loss: 2.7203883353875233
Validation loss: 2.52633318185745

Epoch: 6| Step: 1
Training loss: 1.8700033367351607
Validation loss: 2.534127236707324

Epoch: 6| Step: 2
Training loss: 2.578099013688874
Validation loss: 2.5569163951570486

Epoch: 6| Step: 3
Training loss: 2.294083332507086
Validation loss: 2.5446760361881804

Epoch: 6| Step: 4
Training loss: 2.0995692901333465
Validation loss: 2.5504587620966865

Epoch: 6| Step: 5
Training loss: 1.9574836619195903
Validation loss: 2.5388438282238854

Epoch: 6| Step: 6
Training loss: 2.615735006810608
Validation loss: 2.552964620171484

Epoch: 6| Step: 7
Training loss: 2.3814556323397023
Validation loss: 2.5416606267221526

Epoch: 6| Step: 8
Training loss: 2.6562697465948
Validation loss: 2.528955479267346

Epoch: 6| Step: 9
Training loss: 2.547342737227274
Validation loss: 2.508352789903716

Epoch: 6| Step: 10
Training loss: 2.4978816594419393
Validation loss: 2.524787077408667

Epoch: 6| Step: 11
Training loss: 2.311727961979206
Validation loss: 2.5205511980881146

Epoch: 6| Step: 12
Training loss: 2.5471774430697116
Validation loss: 2.506311381310565

Epoch: 6| Step: 13
Training loss: 1.9526567431847084
Validation loss: 2.510810573165377

Epoch: 215| Step: 0
Training loss: 2.6845164926739558
Validation loss: 2.511893559488788

Epoch: 6| Step: 1
Training loss: 2.3183188559406704
Validation loss: 2.514002843654403

Epoch: 6| Step: 2
Training loss: 2.330444000245715
Validation loss: 2.5171510320824213

Epoch: 6| Step: 3
Training loss: 2.5614715000810646
Validation loss: 2.5218139559114543

Epoch: 6| Step: 4
Training loss: 2.1876713276936037
Validation loss: 2.514650073004626

Epoch: 6| Step: 5
Training loss: 2.484013081225905
Validation loss: 2.5203352717241754

Epoch: 6| Step: 6
Training loss: 2.1241733962868183
Validation loss: 2.527480029874014

Epoch: 6| Step: 7
Training loss: 2.5760685897841427
Validation loss: 2.5236493032594844

Epoch: 6| Step: 8
Training loss: 2.0881427437817086
Validation loss: 2.51837095211905

Epoch: 6| Step: 9
Training loss: 2.0690471885171076
Validation loss: 2.518787520691589

Epoch: 6| Step: 10
Training loss: 2.453836811568536
Validation loss: 2.527809630765028

Epoch: 6| Step: 11
Training loss: 2.0612072216473747
Validation loss: 2.50790470068678

Epoch: 6| Step: 12
Training loss: 2.9397441327088143
Validation loss: 2.5119625940210546

Epoch: 6| Step: 13
Training loss: 2.1683307517307795
Validation loss: 2.524192106719688

Epoch: 216| Step: 0
Training loss: 2.2589197314804004
Validation loss: 2.526582708456847

Epoch: 6| Step: 1
Training loss: 2.459844534233592
Validation loss: 2.528830042584385

Epoch: 6| Step: 2
Training loss: 3.010874272362127
Validation loss: 2.517955324628568

Epoch: 6| Step: 3
Training loss: 2.989661044042311
Validation loss: 2.5347273531880696

Epoch: 6| Step: 4
Training loss: 1.8498132224777692
Validation loss: 2.5308530284285657

Epoch: 6| Step: 5
Training loss: 1.9813704084035477
Validation loss: 2.5138720136559627

Epoch: 6| Step: 6
Training loss: 1.5461996897081216
Validation loss: 2.526794248075804

Epoch: 6| Step: 7
Training loss: 2.6351489105710497
Validation loss: 2.5376479840152317

Epoch: 6| Step: 8
Training loss: 2.213938263911976
Validation loss: 2.530581923809315

Epoch: 6| Step: 9
Training loss: 2.693637670312357
Validation loss: 2.5234572072238843

Epoch: 6| Step: 10
Training loss: 1.588758393392294
Validation loss: 2.531808281387232

Epoch: 6| Step: 11
Training loss: 2.5558857105594326
Validation loss: 2.5310557569533954

Epoch: 6| Step: 12
Training loss: 2.4399986176408697
Validation loss: 2.535835790249573

Epoch: 6| Step: 13
Training loss: 2.153983431413235
Validation loss: 2.513765781390356

Epoch: 217| Step: 0
Training loss: 2.16468091591172
Validation loss: 2.5151866270255794

Epoch: 6| Step: 1
Training loss: 2.7159465498461293
Validation loss: 2.5109785778054006

Epoch: 6| Step: 2
Training loss: 2.133745597204617
Validation loss: 2.4999259619875773

Epoch: 6| Step: 3
Training loss: 2.5565093191071377
Validation loss: 2.493075181806474

Epoch: 6| Step: 4
Training loss: 2.9336743705633044
Validation loss: 2.491159847049163

Epoch: 6| Step: 5
Training loss: 3.051266366679528
Validation loss: 2.49926264538405

Epoch: 6| Step: 6
Training loss: 2.226855128282848
Validation loss: 2.4925801636492686

Epoch: 6| Step: 7
Training loss: 2.341287463652696
Validation loss: 2.5066386294910585

Epoch: 6| Step: 8
Training loss: 2.3797211151854687
Validation loss: 2.5077333685411825

Epoch: 6| Step: 9
Training loss: 2.4173455983731156
Validation loss: 2.5091459506254554

Epoch: 6| Step: 10
Training loss: 2.0585298184451286
Validation loss: 2.5122872713285

Epoch: 6| Step: 11
Training loss: 2.1368264235681917
Validation loss: 2.5077701458072807

Epoch: 6| Step: 12
Training loss: 2.0137908633991786
Validation loss: 2.5162972130651764

Epoch: 6| Step: 13
Training loss: 1.509074972278514
Validation loss: 2.509723240436328

Epoch: 218| Step: 0
Training loss: 2.730119456378008
Validation loss: 2.50778134842615

Epoch: 6| Step: 1
Training loss: 3.0427252264358127
Validation loss: 2.5222543436638714

Epoch: 6| Step: 2
Training loss: 1.554061226766599
Validation loss: 2.5299140481584623

Epoch: 6| Step: 3
Training loss: 1.9671172986218883
Validation loss: 2.5270915782654546

Epoch: 6| Step: 4
Training loss: 2.636265965897682
Validation loss: 2.530810251223862

Epoch: 6| Step: 5
Training loss: 2.432826525893355
Validation loss: 2.5413172643252877

Epoch: 6| Step: 6
Training loss: 2.8831214635840956
Validation loss: 2.5458519720049737

Epoch: 6| Step: 7
Training loss: 2.974214523869551
Validation loss: 2.5460345357833485

Epoch: 6| Step: 8
Training loss: 1.8727437749659146
Validation loss: 2.5343801351762543

Epoch: 6| Step: 9
Training loss: 1.7030804829510235
Validation loss: 2.5180873784909314

Epoch: 6| Step: 10
Training loss: 2.511732228956349
Validation loss: 2.5318144651628187

Epoch: 6| Step: 11
Training loss: 2.2518960593173465
Validation loss: 2.5190288190597707

Epoch: 6| Step: 12
Training loss: 1.8679645788767603
Validation loss: 2.5151676370355416

Epoch: 6| Step: 13
Training loss: 2.0559987572692204
Validation loss: 2.5175260228185614

Epoch: 219| Step: 0
Training loss: 2.1767769800286088
Validation loss: 2.515424763863041

Epoch: 6| Step: 1
Training loss: 2.618384972671571
Validation loss: 2.5089772847884273

Epoch: 6| Step: 2
Training loss: 1.6991676761361654
Validation loss: 2.512911768837707

Epoch: 6| Step: 3
Training loss: 2.0635828585671967
Validation loss: 2.5373129896332967

Epoch: 6| Step: 4
Training loss: 2.5861462281225363
Validation loss: 2.527861363795432

Epoch: 6| Step: 5
Training loss: 2.5928056215634325
Validation loss: 2.51694828083067

Epoch: 6| Step: 6
Training loss: 2.0443381393594238
Validation loss: 2.5322909000656577

Epoch: 6| Step: 7
Training loss: 2.2457653037709844
Validation loss: 2.532405189366221

Epoch: 6| Step: 8
Training loss: 2.3893265532726637
Validation loss: 2.523788537960424

Epoch: 6| Step: 9
Training loss: 2.0375351136347155
Validation loss: 2.5383626119971003

Epoch: 6| Step: 10
Training loss: 2.083847313103485
Validation loss: 2.5326390634749423

Epoch: 6| Step: 11
Training loss: 2.7419652604254274
Validation loss: 2.527048509383519

Epoch: 6| Step: 12
Training loss: 2.262175255331412
Validation loss: 2.5360748241298814

Epoch: 6| Step: 13
Training loss: 3.0162760767973413
Validation loss: 2.5228130248937206

Epoch: 220| Step: 0
Training loss: 2.7738415920681128
Validation loss: 2.5391967894425473

Epoch: 6| Step: 1
Training loss: 2.3515959575718908
Validation loss: 2.531107910312567

Epoch: 6| Step: 2
Training loss: 2.4342421254240936
Validation loss: 2.5265496021854523

Epoch: 6| Step: 3
Training loss: 1.819238566947848
Validation loss: 2.526104205953374

Epoch: 6| Step: 4
Training loss: 1.5605575694838496
Validation loss: 2.513644985241883

Epoch: 6| Step: 5
Training loss: 2.1683239345166023
Validation loss: 2.5016411877943603

Epoch: 6| Step: 6
Training loss: 2.2837690267203525
Validation loss: 2.517837404523508

Epoch: 6| Step: 7
Training loss: 1.6950527994265039
Validation loss: 2.5220773532993372

Epoch: 6| Step: 8
Training loss: 2.432073078230838
Validation loss: 2.525137959227115

Epoch: 6| Step: 9
Training loss: 2.885468208229071
Validation loss: 2.541432844152422

Epoch: 6| Step: 10
Training loss: 2.1137938380193178
Validation loss: 2.53513814628732

Epoch: 6| Step: 11
Training loss: 2.8704069185379835
Validation loss: 2.5570606093639894

Epoch: 6| Step: 12
Training loss: 2.6673168542084813
Validation loss: 2.558530003964468

Epoch: 6| Step: 13
Training loss: 2.532703688659283
Validation loss: 2.5641525801341025

Epoch: 221| Step: 0
Training loss: 2.3530619457049378
Validation loss: 2.563021087388076

Epoch: 6| Step: 1
Training loss: 2.416251464780155
Validation loss: 2.551006344205015

Epoch: 6| Step: 2
Training loss: 2.374867184589424
Validation loss: 2.54504931334039

Epoch: 6| Step: 3
Training loss: 1.617536424229673
Validation loss: 2.534773426903173

Epoch: 6| Step: 4
Training loss: 2.9463458689522835
Validation loss: 2.5160263246868326

Epoch: 6| Step: 5
Training loss: 2.440829912441362
Validation loss: 2.527776674181892

Epoch: 6| Step: 6
Training loss: 2.3640908107839893
Validation loss: 2.524350075122916

Epoch: 6| Step: 7
Training loss: 1.853524436165997
Validation loss: 2.528724179427551

Epoch: 6| Step: 8
Training loss: 2.294470014524594
Validation loss: 2.511053991078355

Epoch: 6| Step: 9
Training loss: 2.1893774422760717
Validation loss: 2.5157872339224125

Epoch: 6| Step: 10
Training loss: 2.1650546997772007
Validation loss: 2.500165186828836

Epoch: 6| Step: 11
Training loss: 2.478623937189601
Validation loss: 2.502685161845207

Epoch: 6| Step: 12
Training loss: 2.7311507916273032
Validation loss: 2.5156476353481922

Epoch: 6| Step: 13
Training loss: 2.549115465125308
Validation loss: 2.507798445395821

Epoch: 222| Step: 0
Training loss: 1.756924281886244
Validation loss: 2.513821778944274

Epoch: 6| Step: 1
Training loss: 2.0886658388232164
Validation loss: 2.5248757939272832

Epoch: 6| Step: 2
Training loss: 2.6358557977321118
Validation loss: 2.5176371549478285

Epoch: 6| Step: 3
Training loss: 2.195069866415378
Validation loss: 2.516834939505703

Epoch: 6| Step: 4
Training loss: 2.92270375294487
Validation loss: 2.5112241551696104

Epoch: 6| Step: 5
Training loss: 1.9189801627918406
Validation loss: 2.5041131039781845

Epoch: 6| Step: 6
Training loss: 2.778633429878864
Validation loss: 2.521041819460508

Epoch: 6| Step: 7
Training loss: 2.851654302086064
Validation loss: 2.532392879604295

Epoch: 6| Step: 8
Training loss: 2.014594709278114
Validation loss: 2.5668383834006816

Epoch: 6| Step: 9
Training loss: 2.014980715903114
Validation loss: 2.5599043190480115

Epoch: 6| Step: 10
Training loss: 2.0669490339310275
Validation loss: 2.5407469341301243

Epoch: 6| Step: 11
Training loss: 1.8043538895770384
Validation loss: 2.5402005349742978

Epoch: 6| Step: 12
Training loss: 2.628562870811369
Validation loss: 2.5364662081513303

Epoch: 6| Step: 13
Training loss: 2.762942807710503
Validation loss: 2.534097067209509

Epoch: 223| Step: 0
Training loss: 2.3587118063029386
Validation loss: 2.51727657716962

Epoch: 6| Step: 1
Training loss: 2.2813360119634285
Validation loss: 2.525955691627803

Epoch: 6| Step: 2
Training loss: 2.886894169124595
Validation loss: 2.5066687807199344

Epoch: 6| Step: 3
Training loss: 2.289217165776585
Validation loss: 2.515075118028196

Epoch: 6| Step: 4
Training loss: 2.777451224735753
Validation loss: 2.519587631974723

Epoch: 6| Step: 5
Training loss: 2.1180530763483043
Validation loss: 2.5071745444310984

Epoch: 6| Step: 6
Training loss: 1.8729314838144386
Validation loss: 2.521447860804029

Epoch: 6| Step: 7
Training loss: 2.862827572132781
Validation loss: 2.511416862543058

Epoch: 6| Step: 8
Training loss: 2.0585518240957144
Validation loss: 2.5085052610852494

Epoch: 6| Step: 9
Training loss: 2.221062865094526
Validation loss: 2.5099691860111033

Epoch: 6| Step: 10
Training loss: 1.9325482248702035
Validation loss: 2.5233018521755954

Epoch: 6| Step: 11
Training loss: 2.239419963703599
Validation loss: 2.5240873084738866

Epoch: 6| Step: 12
Training loss: 2.6076319006295554
Validation loss: 2.519902251772367

Epoch: 6| Step: 13
Training loss: 1.9045808707503469
Validation loss: 2.5194844717173175

Epoch: 224| Step: 0
Training loss: 2.3344610645203474
Validation loss: 2.5446154160322605

Epoch: 6| Step: 1
Training loss: 2.7819190774278346
Validation loss: 2.5559123658020537

Epoch: 6| Step: 2
Training loss: 2.376495894101266
Validation loss: 2.5716122217610136

Epoch: 6| Step: 3
Training loss: 2.029151419308798
Validation loss: 2.5694258840996023

Epoch: 6| Step: 4
Training loss: 2.5664589236353974
Validation loss: 2.5708764567743634

Epoch: 6| Step: 5
Training loss: 2.2376344821516563
Validation loss: 2.5594302608127437

Epoch: 6| Step: 6
Training loss: 2.580069438680022
Validation loss: 2.5689179754599634

Epoch: 6| Step: 7
Training loss: 1.8749746956707223
Validation loss: 2.574221227526015

Epoch: 6| Step: 8
Training loss: 2.2598112030840065
Validation loss: 2.549915308886073

Epoch: 6| Step: 9
Training loss: 2.0513245653062815
Validation loss: 2.5466594643848826

Epoch: 6| Step: 10
Training loss: 2.529718854308131
Validation loss: 2.530117833505814

Epoch: 6| Step: 11
Training loss: 2.5783899344519736
Validation loss: 2.5089570441260274

Epoch: 6| Step: 12
Training loss: 2.39676889037963
Validation loss: 2.5073565012070995

Epoch: 6| Step: 13
Training loss: 1.9866638200001303
Validation loss: 2.502993166750233

Epoch: 225| Step: 0
Training loss: 2.233700950694562
Validation loss: 2.4941185671698

Epoch: 6| Step: 1
Training loss: 2.3200358730042017
Validation loss: 2.4960159106547293

Epoch: 6| Step: 2
Training loss: 2.2709533123086856
Validation loss: 2.4936293175224744

Epoch: 6| Step: 3
Training loss: 2.048238867724913
Validation loss: 2.494197310100026

Epoch: 6| Step: 4
Training loss: 2.9222570159381442
Validation loss: 2.486461634820846

Epoch: 6| Step: 5
Training loss: 1.9932317652177447
Validation loss: 2.4758578640820237

Epoch: 6| Step: 6
Training loss: 3.1912690860403172
Validation loss: 2.4679278521778336

Epoch: 6| Step: 7
Training loss: 1.6951521696579037
Validation loss: 2.4791085746648136

Epoch: 6| Step: 8
Training loss: 2.401353784052925
Validation loss: 2.47349841745096

Epoch: 6| Step: 9
Training loss: 3.3158653006810668
Validation loss: 2.478366720076888

Epoch: 6| Step: 10
Training loss: 2.655269127547992
Validation loss: 2.476354307455142

Epoch: 6| Step: 11
Training loss: 1.8448343482771041
Validation loss: 2.4856426755516328

Epoch: 6| Step: 12
Training loss: 2.3845658652131108
Validation loss: 2.480643406924074

Epoch: 6| Step: 13
Training loss: 2.138236948320243
Validation loss: 2.494769497788166

Epoch: 226| Step: 0
Training loss: 2.125524231816773
Validation loss: 2.492158528860107

Epoch: 6| Step: 1
Training loss: 2.550203734094236
Validation loss: 2.497051296129398

Epoch: 6| Step: 2
Training loss: 2.42506975683185
Validation loss: 2.501860855866856

Epoch: 6| Step: 3
Training loss: 2.4041373155764663
Validation loss: 2.4988904398103933

Epoch: 6| Step: 4
Training loss: 2.1341655756917675
Validation loss: 2.514412487034099

Epoch: 6| Step: 5
Training loss: 2.1429982638438814
Validation loss: 2.51262313515732

Epoch: 6| Step: 6
Training loss: 2.3128983438057316
Validation loss: 2.50680778555969

Epoch: 6| Step: 7
Training loss: 2.5731650990587758
Validation loss: 2.513589102314184

Epoch: 6| Step: 8
Training loss: 2.0918602457429434
Validation loss: 2.5277741511345675

Epoch: 6| Step: 9
Training loss: 2.91966253551486
Validation loss: 2.5231011543473176

Epoch: 6| Step: 10
Training loss: 1.828200249060612
Validation loss: 2.518919941081099

Epoch: 6| Step: 11
Training loss: 1.446269198119619
Validation loss: 2.5254789977654535

Epoch: 6| Step: 12
Training loss: 3.09947153324569
Validation loss: 2.538002097905271

Epoch: 6| Step: 13
Training loss: 2.2349501716469815
Validation loss: 2.577334103504085

Epoch: 227| Step: 0
Training loss: 2.271138605252885
Validation loss: 2.584628370196957

Epoch: 6| Step: 1
Training loss: 3.0511622856437777
Validation loss: 2.5878806290343506

Epoch: 6| Step: 2
Training loss: 2.597252560561311
Validation loss: 2.592658751705752

Epoch: 6| Step: 3
Training loss: 2.569464175403432
Validation loss: 2.5442419190392322

Epoch: 6| Step: 4
Training loss: 2.071627677781788
Validation loss: 2.530520926763291

Epoch: 6| Step: 5
Training loss: 2.3066362837993655
Validation loss: 2.5306102352350694

Epoch: 6| Step: 6
Training loss: 2.317196278674422
Validation loss: 2.515761693553833

Epoch: 6| Step: 7
Training loss: 2.5512887353493734
Validation loss: 2.5056420081064004

Epoch: 6| Step: 8
Training loss: 2.5536707916897003
Validation loss: 2.4971779153769047

Epoch: 6| Step: 9
Training loss: 2.365027723411995
Validation loss: 2.491453917828766

Epoch: 6| Step: 10
Training loss: 2.432889931487179
Validation loss: 2.503650368536332

Epoch: 6| Step: 11
Training loss: 1.9466888583673314
Validation loss: 2.498427341449277

Epoch: 6| Step: 12
Training loss: 1.6813424407617532
Validation loss: 2.496686583449302

Epoch: 6| Step: 13
Training loss: 1.9511613053196886
Validation loss: 2.515969152188678

Epoch: 228| Step: 0
Training loss: 1.5675358302448983
Validation loss: 2.5126361822669536

Epoch: 6| Step: 1
Training loss: 2.4484048126706877
Validation loss: 2.5244722400211113

Epoch: 6| Step: 2
Training loss: 2.146936176433457
Validation loss: 2.516944018190382

Epoch: 6| Step: 3
Training loss: 2.041331815183753
Validation loss: 2.527343639941756

Epoch: 6| Step: 4
Training loss: 2.5883309619480857
Validation loss: 2.5193377437753153

Epoch: 6| Step: 5
Training loss: 3.4167620637803098
Validation loss: 2.526606047724285

Epoch: 6| Step: 6
Training loss: 2.874601917073149
Validation loss: 2.539492917870084

Epoch: 6| Step: 7
Training loss: 2.046790201308827
Validation loss: 2.5409522433516485

Epoch: 6| Step: 8
Training loss: 2.2982879237317273
Validation loss: 2.5185204738163165

Epoch: 6| Step: 9
Training loss: 2.2860709682672464
Validation loss: 2.5281371611061787

Epoch: 6| Step: 10
Training loss: 1.8899135038978838
Validation loss: 2.503236170160184

Epoch: 6| Step: 11
Training loss: 1.6416561700837133
Validation loss: 2.511774785280444

Epoch: 6| Step: 12
Training loss: 2.7810883207154045
Validation loss: 2.514700441285694

Epoch: 6| Step: 13
Training loss: 2.4050564468643474
Validation loss: 2.514601765912461

Epoch: 229| Step: 0
Training loss: 2.528554352278542
Validation loss: 2.4909352471883777

Epoch: 6| Step: 1
Training loss: 2.015399535824464
Validation loss: 2.5060760570866956

Epoch: 6| Step: 2
Training loss: 2.3185627823178128
Validation loss: 2.5078217851857088

Epoch: 6| Step: 3
Training loss: 1.95461991129993
Validation loss: 2.5129848866370663

Epoch: 6| Step: 4
Training loss: 2.3911900070808634
Validation loss: 2.512003374757545

Epoch: 6| Step: 5
Training loss: 2.666528360435958
Validation loss: 2.519566829932885

Epoch: 6| Step: 6
Training loss: 1.953528644813579
Validation loss: 2.5249865081477014

Epoch: 6| Step: 7
Training loss: 2.7237073929821185
Validation loss: 2.538530702897289

Epoch: 6| Step: 8
Training loss: 2.1775634698563175
Validation loss: 2.589108492669701

Epoch: 6| Step: 9
Training loss: 3.0281882012762407
Validation loss: 2.6023541411642164

Epoch: 6| Step: 10
Training loss: 2.2360765074059197
Validation loss: 2.578279047515553

Epoch: 6| Step: 11
Training loss: 1.781250535396027
Validation loss: 2.5683919964980166

Epoch: 6| Step: 12
Training loss: 2.114255106089492
Validation loss: 2.5748933671273093

Epoch: 6| Step: 13
Training loss: 2.650229778764291
Validation loss: 2.579390860464811

Epoch: 230| Step: 0
Training loss: 2.1901498276482383
Validation loss: 2.5569619913470123

Epoch: 6| Step: 1
Training loss: 3.0238705504831223
Validation loss: 2.544608404488798

Epoch: 6| Step: 2
Training loss: 1.4242699543280106
Validation loss: 2.54589205381244

Epoch: 6| Step: 3
Training loss: 2.343776346694363
Validation loss: 2.5369952114733154

Epoch: 6| Step: 4
Training loss: 2.911342138566082
Validation loss: 2.5229200810966623

Epoch: 6| Step: 5
Training loss: 2.080546065873202
Validation loss: 2.5338346683788324

Epoch: 6| Step: 6
Training loss: 1.9148663759548474
Validation loss: 2.539152157496568

Epoch: 6| Step: 7
Training loss: 2.1370002519306612
Validation loss: 2.5317067648612914

Epoch: 6| Step: 8
Training loss: 2.340131280264958
Validation loss: 2.52247572956186

Epoch: 6| Step: 9
Training loss: 2.7187089588093025
Validation loss: 2.5371811063482084

Epoch: 6| Step: 10
Training loss: 2.521630552562314
Validation loss: 2.5417213955182625

Epoch: 6| Step: 11
Training loss: 2.7852748936532876
Validation loss: 2.556134637469517

Epoch: 6| Step: 12
Training loss: 1.820963207067996
Validation loss: 2.5654601545573414

Epoch: 6| Step: 13
Training loss: 1.6650154358202736
Validation loss: 2.5529320894944614

Epoch: 231| Step: 0
Training loss: 1.9868870851737768
Validation loss: 2.5642811237420107

Epoch: 6| Step: 1
Training loss: 2.226908231964238
Validation loss: 2.5682287610858965

Epoch: 6| Step: 2
Training loss: 2.330988409588775
Validation loss: 2.552898515533311

Epoch: 6| Step: 3
Training loss: 2.44208115671379
Validation loss: 2.544218530706243

Epoch: 6| Step: 4
Training loss: 1.599713407121512
Validation loss: 2.534904949505473

Epoch: 6| Step: 5
Training loss: 2.4167339271744126
Validation loss: 2.538523455400435

Epoch: 6| Step: 6
Training loss: 1.807565483289442
Validation loss: 2.540079838319002

Epoch: 6| Step: 7
Training loss: 3.073828782743131
Validation loss: 2.5446694776629277

Epoch: 6| Step: 8
Training loss: 3.126969289171994
Validation loss: 2.538388942485914

Epoch: 6| Step: 9
Training loss: 2.660441782411353
Validation loss: 2.5534030123267604

Epoch: 6| Step: 10
Training loss: 1.9919143788730556
Validation loss: 2.5784641158436585

Epoch: 6| Step: 11
Training loss: 2.3168831602888775
Validation loss: 2.5858196373823805

Epoch: 6| Step: 12
Training loss: 1.8875222716375386
Validation loss: 2.568706780013598

Epoch: 6| Step: 13
Training loss: 2.015897274109766
Validation loss: 2.5841669819214634

Epoch: 232| Step: 0
Training loss: 1.9264734351244592
Validation loss: 2.563714088698049

Epoch: 6| Step: 1
Training loss: 2.9226487711036024
Validation loss: 2.5438707727603287

Epoch: 6| Step: 2
Training loss: 2.2602063856158385
Validation loss: 2.543409521262495

Epoch: 6| Step: 3
Training loss: 1.689037258584197
Validation loss: 2.523185331580672

Epoch: 6| Step: 4
Training loss: 2.37270485253871
Validation loss: 2.526098889099306

Epoch: 6| Step: 5
Training loss: 2.236736516851972
Validation loss: 2.5328795442801306

Epoch: 6| Step: 6
Training loss: 3.1002192819625582
Validation loss: 2.556922036447531

Epoch: 6| Step: 7
Training loss: 2.2627508414299276
Validation loss: 2.5624443141190043

Epoch: 6| Step: 8
Training loss: 1.706127704527385
Validation loss: 2.5850389346566907

Epoch: 6| Step: 9
Training loss: 2.173466929189182
Validation loss: 2.5963740269938573

Epoch: 6| Step: 10
Training loss: 1.6259464295490507
Validation loss: 2.593362741017579

Epoch: 6| Step: 11
Training loss: 2.802544245102663
Validation loss: 2.601253899799426

Epoch: 6| Step: 12
Training loss: 2.490021532723955
Validation loss: 2.5455650830290604

Epoch: 6| Step: 13
Training loss: 2.6472736153067586
Validation loss: 2.512944738524015

Epoch: 233| Step: 0
Training loss: 2.6278866835597876
Validation loss: 2.491067058496244

Epoch: 6| Step: 1
Training loss: 2.3250369899637526
Validation loss: 2.4862192534138527

Epoch: 6| Step: 2
Training loss: 2.0695382451838884
Validation loss: 2.4859193684132306

Epoch: 6| Step: 3
Training loss: 1.8606880744696659
Validation loss: 2.493908597767683

Epoch: 6| Step: 4
Training loss: 1.8284929997365178
Validation loss: 2.487263613639934

Epoch: 6| Step: 5
Training loss: 2.4318206352798413
Validation loss: 2.4920329780468182

Epoch: 6| Step: 6
Training loss: 2.732022826891103
Validation loss: 2.489632727054521

Epoch: 6| Step: 7
Training loss: 2.533949366339887
Validation loss: 2.4805512502171814

Epoch: 6| Step: 8
Training loss: 2.2334032413112417
Validation loss: 2.483347010308137

Epoch: 6| Step: 9
Training loss: 2.1498233279008123
Validation loss: 2.4761138252867463

Epoch: 6| Step: 10
Training loss: 2.3833103347771285
Validation loss: 2.483274964045577

Epoch: 6| Step: 11
Training loss: 3.183703087175379
Validation loss: 2.477057165890484

Epoch: 6| Step: 12
Training loss: 2.4740998451851763
Validation loss: 2.4936947465095907

Epoch: 6| Step: 13
Training loss: 2.3083910134978236
Validation loss: 2.4941173324353665

Epoch: 234| Step: 0
Training loss: 2.2133387812964864
Validation loss: 2.4988565850119286

Epoch: 6| Step: 1
Training loss: 1.9316263690109996
Validation loss: 2.526868159312939

Epoch: 6| Step: 2
Training loss: 3.0424605252440755
Validation loss: 2.521411456396458

Epoch: 6| Step: 3
Training loss: 2.834023410310075
Validation loss: 2.5246965005604576

Epoch: 6| Step: 4
Training loss: 2.5063399986032686
Validation loss: 2.5309453867286886

Epoch: 6| Step: 5
Training loss: 1.7905280095274192
Validation loss: 2.536335596852724

Epoch: 6| Step: 6
Training loss: 2.7229496758076897
Validation loss: 2.5490830256231316

Epoch: 6| Step: 7
Training loss: 2.0062723746790083
Validation loss: 2.5451895474719013

Epoch: 6| Step: 8
Training loss: 1.7226487762911857
Validation loss: 2.575298061835701

Epoch: 6| Step: 9
Training loss: 2.2358771123402144
Validation loss: 2.5734205846456395

Epoch: 6| Step: 10
Training loss: 2.6348334912381643
Validation loss: 2.5721086219060627

Epoch: 6| Step: 11
Training loss: 2.2790230110081358
Validation loss: 2.571311316011754

Epoch: 6| Step: 12
Training loss: 2.386057161079747
Validation loss: 2.56745411592594

Epoch: 6| Step: 13
Training loss: 2.0100428442872458
Validation loss: 2.5484977810152554

Epoch: 235| Step: 0
Training loss: 2.018489960258789
Validation loss: 2.5376719887862755

Epoch: 6| Step: 1
Training loss: 2.3435644457798546
Validation loss: 2.509716400574143

Epoch: 6| Step: 2
Training loss: 2.5484577713750114
Validation loss: 2.481069489069825

Epoch: 6| Step: 3
Training loss: 2.9238786814057627
Validation loss: 2.4852159944044683

Epoch: 6| Step: 4
Training loss: 3.069600495926114
Validation loss: 2.483785611341956

Epoch: 6| Step: 5
Training loss: 2.0752348341824822
Validation loss: 2.4915554955304002

Epoch: 6| Step: 6
Training loss: 2.365628071912739
Validation loss: 2.4885585596451456

Epoch: 6| Step: 7
Training loss: 2.0271720446013175
Validation loss: 2.501915174281297

Epoch: 6| Step: 8
Training loss: 2.367363750077944
Validation loss: 2.5169277332592537

Epoch: 6| Step: 9
Training loss: 2.3410934651719693
Validation loss: 2.5445799989513462

Epoch: 6| Step: 10
Training loss: 1.6863772577970904
Validation loss: 2.5654930994633296

Epoch: 6| Step: 11
Training loss: 2.6579718899126674
Validation loss: 2.594063567545177

Epoch: 6| Step: 12
Training loss: 2.4053689904385926
Validation loss: 2.5800225874924885

Epoch: 6| Step: 13
Training loss: 1.9575845084821042
Validation loss: 2.5699837115868767

Epoch: 236| Step: 0
Training loss: 2.1463848503997114
Validation loss: 2.5788877341487777

Epoch: 6| Step: 1
Training loss: 2.3517732747563387
Validation loss: 2.5753850075006515

Epoch: 6| Step: 2
Training loss: 1.849508828609502
Validation loss: 2.567765981299173

Epoch: 6| Step: 3
Training loss: 1.6420852701904418
Validation loss: 2.5418120535454043

Epoch: 6| Step: 4
Training loss: 2.252627957315813
Validation loss: 2.521239300555258

Epoch: 6| Step: 5
Training loss: 2.8800290116862186
Validation loss: 2.5350107426512936

Epoch: 6| Step: 6
Training loss: 2.7187471060901895
Validation loss: 2.513612973250013

Epoch: 6| Step: 7
Training loss: 2.4669261907538784
Validation loss: 2.518120201512134

Epoch: 6| Step: 8
Training loss: 2.4780653957207726
Validation loss: 2.533504282888824

Epoch: 6| Step: 9
Training loss: 2.21940023001293
Validation loss: 2.5273387344837293

Epoch: 6| Step: 10
Training loss: 1.9527061928907237
Validation loss: 2.5230124463003554

Epoch: 6| Step: 11
Training loss: 1.957026011446644
Validation loss: 2.534899995976898

Epoch: 6| Step: 12
Training loss: 2.4753339831105405
Validation loss: 2.5338995218219997

Epoch: 6| Step: 13
Training loss: 2.532482647699857
Validation loss: 2.539000822442988

Epoch: 237| Step: 0
Training loss: 2.8776468449300276
Validation loss: 2.5343777833320456

Epoch: 6| Step: 1
Training loss: 1.820835218566803
Validation loss: 2.5321886261083

Epoch: 6| Step: 2
Training loss: 2.5587480571312695
Validation loss: 2.5247554112935533

Epoch: 6| Step: 3
Training loss: 1.9275550952166907
Validation loss: 2.5197420726961397

Epoch: 6| Step: 4
Training loss: 2.0933181545087916
Validation loss: 2.509730555268315

Epoch: 6| Step: 5
Training loss: 2.1591652223127515
Validation loss: 2.512562405900906

Epoch: 6| Step: 6
Training loss: 2.500467352098874
Validation loss: 2.5038901421261412

Epoch: 6| Step: 7
Training loss: 2.5105319385787594
Validation loss: 2.511436513781976

Epoch: 6| Step: 8
Training loss: 1.719475402341069
Validation loss: 2.514415789956124

Epoch: 6| Step: 9
Training loss: 3.1280559093913
Validation loss: 2.53439561025672

Epoch: 6| Step: 10
Training loss: 2.1146720779914134
Validation loss: 2.549469248694253

Epoch: 6| Step: 11
Training loss: 2.0442995365014847
Validation loss: 2.5492609311853

Epoch: 6| Step: 12
Training loss: 2.1410733609626567
Validation loss: 2.5799800171681997

Epoch: 6| Step: 13
Training loss: 2.590143292855987
Validation loss: 2.5858855919367705

Epoch: 238| Step: 0
Training loss: 2.111644061338148
Validation loss: 2.5852345781861397

Epoch: 6| Step: 1
Training loss: 2.4022296165088233
Validation loss: 2.590741016963669

Epoch: 6| Step: 2
Training loss: 1.5863320747707692
Validation loss: 2.5837787480039935

Epoch: 6| Step: 3
Training loss: 1.8270001985897464
Validation loss: 2.5869079029110242

Epoch: 6| Step: 4
Training loss: 2.195431526188335
Validation loss: 2.582281011139086

Epoch: 6| Step: 5
Training loss: 2.866817606419453
Validation loss: 2.5957935969055006

Epoch: 6| Step: 6
Training loss: 2.5513664847756057
Validation loss: 2.585998196384148

Epoch: 6| Step: 7
Training loss: 2.5385660948039126
Validation loss: 2.5842527066147993

Epoch: 6| Step: 8
Training loss: 2.303355721209856
Validation loss: 2.540518662971067

Epoch: 6| Step: 9
Training loss: 2.593790628505687
Validation loss: 2.5086436414514357

Epoch: 6| Step: 10
Training loss: 2.6988443868580303
Validation loss: 2.50091166562893

Epoch: 6| Step: 11
Training loss: 2.0990629966772736
Validation loss: 2.493035310776974

Epoch: 6| Step: 12
Training loss: 1.9829762252174967
Validation loss: 2.4868675220188843

Epoch: 6| Step: 13
Training loss: 2.427415282070548
Validation loss: 2.483457111841065

Epoch: 239| Step: 0
Training loss: 3.1182293596846926
Validation loss: 2.4859205512734417

Epoch: 6| Step: 1
Training loss: 1.6493328248385295
Validation loss: 2.4792023637482967

Epoch: 6| Step: 2
Training loss: 2.674052282708163
Validation loss: 2.477886756454315

Epoch: 6| Step: 3
Training loss: 2.3703690604475605
Validation loss: 2.4766397073064805

Epoch: 6| Step: 4
Training loss: 2.5886327982057504
Validation loss: 2.4800353545186353

Epoch: 6| Step: 5
Training loss: 1.6850946732590633
Validation loss: 2.4849304921735413

Epoch: 6| Step: 6
Training loss: 2.8125618821859706
Validation loss: 2.4745246533486207

Epoch: 6| Step: 7
Training loss: 3.0226504067733972
Validation loss: 2.4787047113387426

Epoch: 6| Step: 8
Training loss: 2.1121624648722306
Validation loss: 2.4906849891014526

Epoch: 6| Step: 9
Training loss: 2.0829020498818123
Validation loss: 2.473025470665719

Epoch: 6| Step: 10
Training loss: 2.16734797207455
Validation loss: 2.4869383057970738

Epoch: 6| Step: 11
Training loss: 2.397567839870949
Validation loss: 2.4871090254242416

Epoch: 6| Step: 12
Training loss: 2.672010987150708
Validation loss: 2.4908407113902005

Epoch: 6| Step: 13
Training loss: 1.748328023283646
Validation loss: 2.489877521153002

Epoch: 240| Step: 0
Training loss: 2.917652690065874
Validation loss: 2.484313516235886

Epoch: 6| Step: 1
Training loss: 2.3030465183835567
Validation loss: 2.4845579867680354

Epoch: 6| Step: 2
Training loss: 2.4872791901544526
Validation loss: 2.485776725731516

Epoch: 6| Step: 3
Training loss: 2.082088734475546
Validation loss: 2.487993895478237

Epoch: 6| Step: 4
Training loss: 2.2411664704875225
Validation loss: 2.48452483231194

Epoch: 6| Step: 5
Training loss: 2.008921276260936
Validation loss: 2.4769068658039735

Epoch: 6| Step: 6
Training loss: 2.5231809692373885
Validation loss: 2.480873247140958

Epoch: 6| Step: 7
Training loss: 2.411129351613808
Validation loss: 2.4851944249808815

Epoch: 6| Step: 8
Training loss: 2.0202199916208823
Validation loss: 2.505266047478446

Epoch: 6| Step: 9
Training loss: 2.9723992656453775
Validation loss: 2.512871208414375

Epoch: 6| Step: 10
Training loss: 2.0098759479104102
Validation loss: 2.5227321587738367

Epoch: 6| Step: 11
Training loss: 1.9053151073816499
Validation loss: 2.5561344820143606

Epoch: 6| Step: 12
Training loss: 2.0517318992666915
Validation loss: 2.587641958129621

Epoch: 6| Step: 13
Training loss: 2.5827218429246153
Validation loss: 2.5645736584660375

Epoch: 241| Step: 0
Training loss: 2.2528806895205524
Validation loss: 2.5579964054510906

Epoch: 6| Step: 1
Training loss: 2.0023449025948934
Validation loss: 2.5638735276718716

Epoch: 6| Step: 2
Training loss: 2.1745731417208867
Validation loss: 2.524502461580862

Epoch: 6| Step: 3
Training loss: 2.6099329369066453
Validation loss: 2.5237901596695718

Epoch: 6| Step: 4
Training loss: 2.2178606211878757
Validation loss: 2.5140003146867094

Epoch: 6| Step: 5
Training loss: 2.134656060453169
Validation loss: 2.501386702915074

Epoch: 6| Step: 6
Training loss: 2.417129494205938
Validation loss: 2.500122289845546

Epoch: 6| Step: 7
Training loss: 1.772711113542654
Validation loss: 2.4960795816527823

Epoch: 6| Step: 8
Training loss: 2.2530875743873975
Validation loss: 2.5103889374105077

Epoch: 6| Step: 9
Training loss: 2.306542842643234
Validation loss: 2.4929441620767694

Epoch: 6| Step: 10
Training loss: 2.642128240009882
Validation loss: 2.513940740955654

Epoch: 6| Step: 11
Training loss: 2.780901426267164
Validation loss: 2.5159524108245237

Epoch: 6| Step: 12
Training loss: 2.490729787577396
Validation loss: 2.524422326434128

Epoch: 6| Step: 13
Training loss: 2.671459143327439
Validation loss: 2.5415288126931617

Epoch: 242| Step: 0
Training loss: 2.1952041110503515
Validation loss: 2.5413682767679573

Epoch: 6| Step: 1
Training loss: 2.5199182494088204
Validation loss: 2.5178523973486593

Epoch: 6| Step: 2
Training loss: 2.359054038340484
Validation loss: 2.4981416630103706

Epoch: 6| Step: 3
Training loss: 1.8413137083303734
Validation loss: 2.5086686761406884

Epoch: 6| Step: 4
Training loss: 1.9014559638365722
Validation loss: 2.4971615094998945

Epoch: 6| Step: 5
Training loss: 1.7419409470518072
Validation loss: 2.4893301405437542

Epoch: 6| Step: 6
Training loss: 2.1949460412694597
Validation loss: 2.47797986215286

Epoch: 6| Step: 7
Training loss: 3.043381943274443
Validation loss: 2.4830243419796276

Epoch: 6| Step: 8
Training loss: 2.335914228954946
Validation loss: 2.4871731880492916

Epoch: 6| Step: 9
Training loss: 2.7726449613107578
Validation loss: 2.5056752320339815

Epoch: 6| Step: 10
Training loss: 2.5583561211812644
Validation loss: 2.494679129231795

Epoch: 6| Step: 11
Training loss: 2.338882070346698
Validation loss: 2.5156117472487107

Epoch: 6| Step: 12
Training loss: 2.170715461601169
Validation loss: 2.529218792784059

Epoch: 6| Step: 13
Training loss: 2.6624657104863116
Validation loss: 2.5601636734188307

Epoch: 243| Step: 0
Training loss: 2.5639704695323684
Validation loss: 2.5670949320589687

Epoch: 6| Step: 1
Training loss: 2.797515540058517
Validation loss: 2.5628934108535066

Epoch: 6| Step: 2
Training loss: 2.6859430638156363
Validation loss: 2.5522652282250577

Epoch: 6| Step: 3
Training loss: 2.773969400469517
Validation loss: 2.5478613723989074

Epoch: 6| Step: 4
Training loss: 2.0858001092247767
Validation loss: 2.5599338429068466

Epoch: 6| Step: 5
Training loss: 1.8406773195456996
Validation loss: 2.5729017965116148

Epoch: 6| Step: 6
Training loss: 2.0810100061926717
Validation loss: 2.5920724767757943

Epoch: 6| Step: 7
Training loss: 2.159170080859735
Validation loss: 2.6235168445032584

Epoch: 6| Step: 8
Training loss: 2.546777173369252
Validation loss: 2.659859079127321

Epoch: 6| Step: 9
Training loss: 1.941518431095384
Validation loss: 2.6281169067209813

Epoch: 6| Step: 10
Training loss: 2.048483762356903
Validation loss: 2.5940758220902045

Epoch: 6| Step: 11
Training loss: 2.1658265123288034
Validation loss: 2.545196752568448

Epoch: 6| Step: 12
Training loss: 2.4553809999570233
Validation loss: 2.5208478617183814

Epoch: 6| Step: 13
Training loss: 2.1956617410150026
Validation loss: 2.511601992632784

Epoch: 244| Step: 0
Training loss: 2.4381039189197624
Validation loss: 2.4919109769057406

Epoch: 6| Step: 1
Training loss: 2.4857586540371543
Validation loss: 2.4934689486905595

Epoch: 6| Step: 2
Training loss: 1.7463668848566867
Validation loss: 2.4981834885277747

Epoch: 6| Step: 3
Training loss: 2.2071534249576965
Validation loss: 2.5024578251493885

Epoch: 6| Step: 4
Training loss: 2.285951133786453
Validation loss: 2.497570542213395

Epoch: 6| Step: 5
Training loss: 2.031564306737463
Validation loss: 2.507579717398994

Epoch: 6| Step: 6
Training loss: 1.9075073098058866
Validation loss: 2.5139482806117432

Epoch: 6| Step: 7
Training loss: 2.8582517992259393
Validation loss: 2.521127200271686

Epoch: 6| Step: 8
Training loss: 1.9334914055143235
Validation loss: 2.5380584453068886

Epoch: 6| Step: 9
Training loss: 2.24863265133707
Validation loss: 2.5473940267785893

Epoch: 6| Step: 10
Training loss: 2.226595051845383
Validation loss: 2.582639375404922

Epoch: 6| Step: 11
Training loss: 2.2237580422850507
Validation loss: 2.5855114481169705

Epoch: 6| Step: 12
Training loss: 2.9354123752870365
Validation loss: 2.611351148132465

Epoch: 6| Step: 13
Training loss: 2.595629918520681
Validation loss: 2.63238980817682

Epoch: 245| Step: 0
Training loss: 2.2837722630242996
Validation loss: 2.599855750924155

Epoch: 6| Step: 1
Training loss: 2.134738373996926
Validation loss: 2.593463008583714

Epoch: 6| Step: 2
Training loss: 2.784212484872372
Validation loss: 2.5668710319687142

Epoch: 6| Step: 3
Training loss: 1.7512547218319
Validation loss: 2.5764795928873374

Epoch: 6| Step: 4
Training loss: 1.9970750878610388
Validation loss: 2.5754266200305036

Epoch: 6| Step: 5
Training loss: 1.8774683281961155
Validation loss: 2.575023781873391

Epoch: 6| Step: 6
Training loss: 2.7231086781949223
Validation loss: 2.5660736704588167

Epoch: 6| Step: 7
Training loss: 2.4149698570692304
Validation loss: 2.5573365284596803

Epoch: 6| Step: 8
Training loss: 2.300566114331673
Validation loss: 2.5586318617450163

Epoch: 6| Step: 9
Training loss: 2.562341638649448
Validation loss: 2.5309860814029723

Epoch: 6| Step: 10
Training loss: 2.656939966685786
Validation loss: 2.5186441915167976

Epoch: 6| Step: 11
Training loss: 1.9474059946781823
Validation loss: 2.5255948540010933

Epoch: 6| Step: 12
Training loss: 2.163463523407376
Validation loss: 2.508862458834976

Epoch: 6| Step: 13
Training loss: 2.0826985218544163
Validation loss: 2.508747405877805

Epoch: 246| Step: 0
Training loss: 2.17439902761352
Validation loss: 2.5011656586780635

Epoch: 6| Step: 1
Training loss: 1.957691926280194
Validation loss: 2.504756868305734

Epoch: 6| Step: 2
Training loss: 1.97014435331226
Validation loss: 2.5131271234411807

Epoch: 6| Step: 3
Training loss: 2.3582985550795166
Validation loss: 2.529564268689319

Epoch: 6| Step: 4
Training loss: 2.3568691057542708
Validation loss: 2.5307215072182005

Epoch: 6| Step: 5
Training loss: 2.6243697726876043
Validation loss: 2.5400183653730726

Epoch: 6| Step: 6
Training loss: 2.35951080941911
Validation loss: 2.539229699522926

Epoch: 6| Step: 7
Training loss: 2.3913020752153415
Validation loss: 2.5535866857270424

Epoch: 6| Step: 8
Training loss: 1.674685388881565
Validation loss: 2.5814876936494158

Epoch: 6| Step: 9
Training loss: 2.3826830219048305
Validation loss: 2.590503284523192

Epoch: 6| Step: 10
Training loss: 2.2537926392375036
Validation loss: 2.593911652334281

Epoch: 6| Step: 11
Training loss: 2.136511867626823
Validation loss: 2.58354652714606

Epoch: 6| Step: 12
Training loss: 2.5435450965778443
Validation loss: 2.599612447391474

Epoch: 6| Step: 13
Training loss: 2.625229325949347
Validation loss: 2.578373259334082

Epoch: 247| Step: 0
Training loss: 2.475648729479791
Validation loss: 2.589922973280311

Epoch: 6| Step: 1
Training loss: 2.354527831153886
Validation loss: 2.5619322140005

Epoch: 6| Step: 2
Training loss: 2.0429248695693825
Validation loss: 2.55671173066764

Epoch: 6| Step: 3
Training loss: 1.927936207139341
Validation loss: 2.5327084503671675

Epoch: 6| Step: 4
Training loss: 2.31333289740977
Validation loss: 2.550601144754029

Epoch: 6| Step: 5
Training loss: 2.673699185680815
Validation loss: 2.5389120047546685

Epoch: 6| Step: 6
Training loss: 2.0692574745846075
Validation loss: 2.5280214449590597

Epoch: 6| Step: 7
Training loss: 2.363606681170521
Validation loss: 2.5610536820111647

Epoch: 6| Step: 8
Training loss: 2.443323563542768
Validation loss: 2.5572531024539744

Epoch: 6| Step: 9
Training loss: 1.8613939623882236
Validation loss: 2.5484320438778005

Epoch: 6| Step: 10
Training loss: 1.4361883066869763
Validation loss: 2.531681400789434

Epoch: 6| Step: 11
Training loss: 2.1634630825982737
Validation loss: 2.5304839383931923

Epoch: 6| Step: 12
Training loss: 2.1634314543107718
Validation loss: 2.5211141813427718

Epoch: 6| Step: 13
Training loss: 3.3347251529478594
Validation loss: 2.516711046025468

Epoch: 248| Step: 0
Training loss: 2.3790657979645964
Validation loss: 2.5120087847201713

Epoch: 6| Step: 1
Training loss: 2.1201891577201692
Validation loss: 2.5219506921639563

Epoch: 6| Step: 2
Training loss: 2.424396014947327
Validation loss: 2.5315809779161293

Epoch: 6| Step: 3
Training loss: 1.9605173823571824
Validation loss: 2.547764862562206

Epoch: 6| Step: 4
Training loss: 1.9224246099842246
Validation loss: 2.5478080335422186

Epoch: 6| Step: 5
Training loss: 2.3802015664792577
Validation loss: 2.525699448099099

Epoch: 6| Step: 6
Training loss: 2.0411128116813546
Validation loss: 2.5158263732049004

Epoch: 6| Step: 7
Training loss: 2.463386019950705
Validation loss: 2.509731758571968

Epoch: 6| Step: 8
Training loss: 2.1141003838617585
Validation loss: 2.510085512746193

Epoch: 6| Step: 9
Training loss: 2.1011338488117692
Validation loss: 2.5089325587246294

Epoch: 6| Step: 10
Training loss: 2.7014264188860064
Validation loss: 2.533795869998917

Epoch: 6| Step: 11
Training loss: 2.568270907310719
Validation loss: 2.548586404965352

Epoch: 6| Step: 12
Training loss: 2.6378039578119963
Validation loss: 2.5780940969137065

Epoch: 6| Step: 13
Training loss: 1.9157557880006033
Validation loss: 2.5635050841667284

Epoch: 249| Step: 0
Training loss: 2.195749368335034
Validation loss: 2.5920332010589773

Epoch: 6| Step: 1
Training loss: 1.8467600546243357
Validation loss: 2.579826702734462

Epoch: 6| Step: 2
Training loss: 3.0719371894137297
Validation loss: 2.5824670774879204

Epoch: 6| Step: 3
Training loss: 2.1457353834987516
Validation loss: 2.5989450723211647

Epoch: 6| Step: 4
Training loss: 2.363052432750225
Validation loss: 2.594836930337421

Epoch: 6| Step: 5
Training loss: 2.442075884727995
Validation loss: 2.59623491988427

Epoch: 6| Step: 6
Training loss: 1.6406354631362783
Validation loss: 2.615897860132714

Epoch: 6| Step: 7
Training loss: 1.724986051420125
Validation loss: 2.6184314864871463

Epoch: 6| Step: 8
Training loss: 2.3814954776340547
Validation loss: 2.6291595231174285

Epoch: 6| Step: 9
Training loss: 2.422375633425093
Validation loss: 2.6170306562047654

Epoch: 6| Step: 10
Training loss: 1.7246930111815852
Validation loss: 2.584510386379137

Epoch: 6| Step: 11
Training loss: 2.5543876261967258
Validation loss: 2.5576216153998277

Epoch: 6| Step: 12
Training loss: 1.8920110240639305
Validation loss: 2.534741274153875

Epoch: 6| Step: 13
Training loss: 2.882636170822631
Validation loss: 2.5348997921922876

Epoch: 250| Step: 0
Training loss: 2.7408607512003784
Validation loss: 2.5343984794861796

Epoch: 6| Step: 1
Training loss: 2.603598224906416
Validation loss: 2.5327559100635524

Epoch: 6| Step: 2
Training loss: 1.7046047396898196
Validation loss: 2.545275367198998

Epoch: 6| Step: 3
Training loss: 1.9763160521768883
Validation loss: 2.5394672716724003

Epoch: 6| Step: 4
Training loss: 2.2973760979484408
Validation loss: 2.5486650163826607

Epoch: 6| Step: 5
Training loss: 1.8834133851359032
Validation loss: 2.5717924856465992

Epoch: 6| Step: 6
Training loss: 2.096742683249602
Validation loss: 2.5615219327568575

Epoch: 6| Step: 7
Training loss: 2.238157258918464
Validation loss: 2.577358494107727

Epoch: 6| Step: 8
Training loss: 2.6389885521077043
Validation loss: 2.5751676764106546

Epoch: 6| Step: 9
Training loss: 1.9838561934259393
Validation loss: 2.559229446141284

Epoch: 6| Step: 10
Training loss: 2.491175718219293
Validation loss: 2.5527155709346316

Epoch: 6| Step: 11
Training loss: 2.1777845163089706
Validation loss: 2.546765611791874

Epoch: 6| Step: 12
Training loss: 2.124874111261299
Validation loss: 2.548447332279425

Epoch: 6| Step: 13
Training loss: 2.5525584083622035
Validation loss: 2.5534757098557774

Epoch: 251| Step: 0
Training loss: 2.0912501656303637
Validation loss: 2.5594774889424596

Epoch: 6| Step: 1
Training loss: 2.121564893576496
Validation loss: 2.5793338908358154

Epoch: 6| Step: 2
Training loss: 1.884876939718044
Validation loss: 2.6020756426398

Epoch: 6| Step: 3
Training loss: 2.925645160438525
Validation loss: 2.5829260079422673

Epoch: 6| Step: 4
Training loss: 2.2373296235924856
Validation loss: 2.576812764681569

Epoch: 6| Step: 5
Training loss: 2.606887271095868
Validation loss: 2.576408492976547

Epoch: 6| Step: 6
Training loss: 2.182553174746426
Validation loss: 2.5732398557320635

Epoch: 6| Step: 7
Training loss: 2.452843911169946
Validation loss: 2.5688987175307223

Epoch: 6| Step: 8
Training loss: 2.2033596049179045
Validation loss: 2.549929326143934

Epoch: 6| Step: 9
Training loss: 1.4258656934004883
Validation loss: 2.540125361287591

Epoch: 6| Step: 10
Training loss: 2.3031501427032466
Validation loss: 2.5264636654023076

Epoch: 6| Step: 11
Training loss: 1.98663999796682
Validation loss: 2.5293106373298366

Epoch: 6| Step: 12
Training loss: 2.5588818569899288
Validation loss: 2.524160370170806

Epoch: 6| Step: 13
Training loss: 2.842393991981382
Validation loss: 2.5101629078825534

Epoch: 252| Step: 0
Training loss: 2.0433895341488473
Validation loss: 2.518643166017255

Epoch: 6| Step: 1
Training loss: 1.89516490289243
Validation loss: 2.5242806709901835

Epoch: 6| Step: 2
Training loss: 2.3862722825238434
Validation loss: 2.524869805621037

Epoch: 6| Step: 3
Training loss: 1.7333434190212165
Validation loss: 2.5289266307953504

Epoch: 6| Step: 4
Training loss: 2.2317306770145415
Validation loss: 2.538866131353835

Epoch: 6| Step: 5
Training loss: 2.446373072721636
Validation loss: 2.5460974319585894

Epoch: 6| Step: 6
Training loss: 2.4266733197061634
Validation loss: 2.5725345070356234

Epoch: 6| Step: 7
Training loss: 2.7094862513597247
Validation loss: 2.55622357181483

Epoch: 6| Step: 8
Training loss: 2.293027184958668
Validation loss: 2.5852567423977364

Epoch: 6| Step: 9
Training loss: 2.31145814675297
Validation loss: 2.606610125841501

Epoch: 6| Step: 10
Training loss: 2.711792209238013
Validation loss: 2.615607746147878

Epoch: 6| Step: 11
Training loss: 2.065114300684138
Validation loss: 2.628636656678953

Epoch: 6| Step: 12
Training loss: 2.066294560722145
Validation loss: 2.6190155780780953

Epoch: 6| Step: 13
Training loss: 2.1844956611630377
Validation loss: 2.5741116815508764

Epoch: 253| Step: 0
Training loss: 1.9819242707921585
Validation loss: 2.5755429834249717

Epoch: 6| Step: 1
Training loss: 2.0076004094420035
Validation loss: 2.5383656645945205

Epoch: 6| Step: 2
Training loss: 2.2845729507283647
Validation loss: 2.5335495319050407

Epoch: 6| Step: 3
Training loss: 1.8468630743529215
Validation loss: 2.527882270493051

Epoch: 6| Step: 4
Training loss: 2.666536943936173
Validation loss: 2.5104194472259276

Epoch: 6| Step: 5
Training loss: 1.7629176625689467
Validation loss: 2.5014506899395834

Epoch: 6| Step: 6
Training loss: 1.807274751464955
Validation loss: 2.502274162348345

Epoch: 6| Step: 7
Training loss: 2.6039892110762226
Validation loss: 2.5094763286016573

Epoch: 6| Step: 8
Training loss: 3.3975629711701307
Validation loss: 2.4958836761093024

Epoch: 6| Step: 9
Training loss: 2.2703528172903056
Validation loss: 2.507741473530045

Epoch: 6| Step: 10
Training loss: 2.038636144736829
Validation loss: 2.505780832036452

Epoch: 6| Step: 11
Training loss: 2.4397152346801803
Validation loss: 2.518139169236059

Epoch: 6| Step: 12
Training loss: 2.529688600819132
Validation loss: 2.560829920950082

Epoch: 6| Step: 13
Training loss: 2.0588558254593923
Validation loss: 2.5911043147813504

Epoch: 254| Step: 0
Training loss: 1.7548237802875453
Validation loss: 2.6000617417316163

Epoch: 6| Step: 1
Training loss: 2.561914330520494
Validation loss: 2.607449214949127

Epoch: 6| Step: 2
Training loss: 2.6444679602032437
Validation loss: 2.620569168103808

Epoch: 6| Step: 3
Training loss: 1.8475450800866187
Validation loss: 2.5831439092365347

Epoch: 6| Step: 4
Training loss: 2.868290577255256
Validation loss: 2.5944275947593627

Epoch: 6| Step: 5
Training loss: 2.0143091209118382
Validation loss: 2.5583382748318972

Epoch: 6| Step: 6
Training loss: 1.96118290190132
Validation loss: 2.5521933291858216

Epoch: 6| Step: 7
Training loss: 2.273998702479171
Validation loss: 2.53053648825519

Epoch: 6| Step: 8
Training loss: 1.4862463147861231
Validation loss: 2.5368252644813327

Epoch: 6| Step: 9
Training loss: 2.5550743999958514
Validation loss: 2.51620541465639

Epoch: 6| Step: 10
Training loss: 2.6445428800115853
Validation loss: 2.5086857749828937

Epoch: 6| Step: 11
Training loss: 2.0236587698002237
Validation loss: 2.509052623596784

Epoch: 6| Step: 12
Training loss: 2.469264399379246
Validation loss: 2.528550172064236

Epoch: 6| Step: 13
Training loss: 2.537265364599357
Validation loss: 2.5292460354245443

Epoch: 255| Step: 0
Training loss: 1.6564258985862677
Validation loss: 2.5412238991305927

Epoch: 6| Step: 1
Training loss: 1.6531580728781259
Validation loss: 2.5536302251077507

Epoch: 6| Step: 2
Training loss: 2.2985746362205357
Validation loss: 2.585929478751013

Epoch: 6| Step: 3
Training loss: 2.4646812421666784
Validation loss: 2.6021377798044147

Epoch: 6| Step: 4
Training loss: 2.5308994945343692
Validation loss: 2.6148243421949937

Epoch: 6| Step: 5
Training loss: 2.5539421837520124
Validation loss: 2.6347579786275954

Epoch: 6| Step: 6
Training loss: 2.4988367235287128
Validation loss: 2.610719071936083

Epoch: 6| Step: 7
Training loss: 1.816872682468234
Validation loss: 2.6282531622361422

Epoch: 6| Step: 8
Training loss: 2.5477385197948754
Validation loss: 2.6154605614774624

Epoch: 6| Step: 9
Training loss: 2.5503194721034537
Validation loss: 2.5622213723895446

Epoch: 6| Step: 10
Training loss: 1.9247779941111078
Validation loss: 2.5471454702975245

Epoch: 6| Step: 11
Training loss: 2.179786707216727
Validation loss: 2.525301659067515

Epoch: 6| Step: 12
Training loss: 2.3308370270448053
Validation loss: 2.509263519053058

Epoch: 6| Step: 13
Training loss: 2.618188285217583
Validation loss: 2.51350121263331

Epoch: 256| Step: 0
Training loss: 1.624604837347519
Validation loss: 2.5126141286584773

Epoch: 6| Step: 1
Training loss: 3.5453961352002916
Validation loss: 2.500795253788737

Epoch: 6| Step: 2
Training loss: 2.647049261524657
Validation loss: 2.4917473638558936

Epoch: 6| Step: 3
Training loss: 1.4132331397121942
Validation loss: 2.493522055524867

Epoch: 6| Step: 4
Training loss: 1.5255255059504642
Validation loss: 2.4859686964032894

Epoch: 6| Step: 5
Training loss: 2.1564557626928997
Validation loss: 2.483377180309775

Epoch: 6| Step: 6
Training loss: 2.4352414353383263
Validation loss: 2.4897681982975985

Epoch: 6| Step: 7
Training loss: 2.670383684114652
Validation loss: 2.4883643694877775

Epoch: 6| Step: 8
Training loss: 2.259318868908019
Validation loss: 2.499576993759246

Epoch: 6| Step: 9
Training loss: 2.941142968379677
Validation loss: 2.5253723332685993

Epoch: 6| Step: 10
Training loss: 2.0442033177462235
Validation loss: 2.52656155509357

Epoch: 6| Step: 11
Training loss: 2.622502183067788
Validation loss: 2.573594522694364

Epoch: 6| Step: 12
Training loss: 1.9231499265605652
Validation loss: 2.5901574989554086

Epoch: 6| Step: 13
Training loss: 1.8874837457828564
Validation loss: 2.597653037621369

Epoch: 257| Step: 0
Training loss: 2.0241863971040184
Validation loss: 2.622554972472171

Epoch: 6| Step: 1
Training loss: 1.7399848733441774
Validation loss: 2.610018774479053

Epoch: 6| Step: 2
Training loss: 2.5918075457815375
Validation loss: 2.5999466285362827

Epoch: 6| Step: 3
Training loss: 2.3911166215421074
Validation loss: 2.577721196157456

Epoch: 6| Step: 4
Training loss: 2.612178278921705
Validation loss: 2.5241258074187485

Epoch: 6| Step: 5
Training loss: 1.974502575681141
Validation loss: 2.5031819439084906

Epoch: 6| Step: 6
Training loss: 2.3831418669649223
Validation loss: 2.51364425806042

Epoch: 6| Step: 7
Training loss: 1.6993996710212302
Validation loss: 2.4933995614928763

Epoch: 6| Step: 8
Training loss: 2.431076683005611
Validation loss: 2.4940680381510436

Epoch: 6| Step: 9
Training loss: 1.9267530484727913
Validation loss: 2.49765410030918

Epoch: 6| Step: 10
Training loss: 2.91592274215769
Validation loss: 2.4936844207630693

Epoch: 6| Step: 11
Training loss: 2.4359224545330442
Validation loss: 2.4971742554912764

Epoch: 6| Step: 12
Training loss: 2.28893542669365
Validation loss: 2.5246760553974976

Epoch: 6| Step: 13
Training loss: 2.5004774591367793
Validation loss: 2.5295168433648136

Epoch: 258| Step: 0
Training loss: 1.7437809384243648
Validation loss: 2.5516440084769063

Epoch: 6| Step: 1
Training loss: 2.5906274222626076
Validation loss: 2.5999117970788785

Epoch: 6| Step: 2
Training loss: 2.600169682467764
Validation loss: 2.6136672300845647

Epoch: 6| Step: 3
Training loss: 2.7630489442613553
Validation loss: 2.6256217220279576

Epoch: 6| Step: 4
Training loss: 2.6352870642919273
Validation loss: 2.646835727993306

Epoch: 6| Step: 5
Training loss: 1.8496309015296297
Validation loss: 2.6020500787748473

Epoch: 6| Step: 6
Training loss: 1.9550028204348773
Validation loss: 2.586477801377313

Epoch: 6| Step: 7
Training loss: 2.0046859919601085
Validation loss: 2.5572142165213845

Epoch: 6| Step: 8
Training loss: 2.2528179324525506
Validation loss: 2.5407998894825568

Epoch: 6| Step: 9
Training loss: 1.6111128969657618
Validation loss: 2.5275432619944733

Epoch: 6| Step: 10
Training loss: 2.1052138363556914
Validation loss: 2.5037266611810267

Epoch: 6| Step: 11
Training loss: 2.296653062127748
Validation loss: 2.503983883737816

Epoch: 6| Step: 12
Training loss: 3.0095764536389256
Validation loss: 2.4873264143551133

Epoch: 6| Step: 13
Training loss: 2.026062430019597
Validation loss: 2.4941928970566947

Epoch: 259| Step: 0
Training loss: 2.624049332451546
Validation loss: 2.5038551011914105

Epoch: 6| Step: 1
Training loss: 2.1295817852020855
Validation loss: 2.4899536612870223

Epoch: 6| Step: 2
Training loss: 2.2178504087259445
Validation loss: 2.4964305907108164

Epoch: 6| Step: 3
Training loss: 3.2132545149173475
Validation loss: 2.4898466558871366

Epoch: 6| Step: 4
Training loss: 1.4665868535144337
Validation loss: 2.5019685147695836

Epoch: 6| Step: 5
Training loss: 2.0828645051500505
Validation loss: 2.5032939668126066

Epoch: 6| Step: 6
Training loss: 2.1830573608858677
Validation loss: 2.5202569749284893

Epoch: 6| Step: 7
Training loss: 3.006158230148157
Validation loss: 2.5279492493577256

Epoch: 6| Step: 8
Training loss: 2.1807517458160803
Validation loss: 2.548984909594606

Epoch: 6| Step: 9
Training loss: 1.944051801305317
Validation loss: 2.5933009911835563

Epoch: 6| Step: 10
Training loss: 1.7288738676917912
Validation loss: 2.5858665986727916

Epoch: 6| Step: 11
Training loss: 2.277261460978452
Validation loss: 2.6014109616062515

Epoch: 6| Step: 12
Training loss: 2.196930530003648
Validation loss: 2.6337930153362223

Epoch: 6| Step: 13
Training loss: 1.968419910188199
Validation loss: 2.605870358438189

Epoch: 260| Step: 0
Training loss: 2.3685962274808827
Validation loss: 2.6009096351715817

Epoch: 6| Step: 1
Training loss: 2.3980128008554096
Validation loss: 2.5563820323718347

Epoch: 6| Step: 2
Training loss: 2.378920481471696
Validation loss: 2.534200432312129

Epoch: 6| Step: 3
Training loss: 2.259761193748356
Validation loss: 2.5356615343753606

Epoch: 6| Step: 4
Training loss: 2.1198350181801833
Validation loss: 2.534943041189765

Epoch: 6| Step: 5
Training loss: 2.1164275772749357
Validation loss: 2.5423571216818583

Epoch: 6| Step: 6
Training loss: 1.730847594940589
Validation loss: 2.5403204672440505

Epoch: 6| Step: 7
Training loss: 2.1369364346880366
Validation loss: 2.5281511183600993

Epoch: 6| Step: 8
Training loss: 2.3970142826359813
Validation loss: 2.5559055795855588

Epoch: 6| Step: 9
Training loss: 1.9264593265377288
Validation loss: 2.556068163982201

Epoch: 6| Step: 10
Training loss: 1.6183811518672344
Validation loss: 2.581415454035403

Epoch: 6| Step: 11
Training loss: 3.222488454438473
Validation loss: 2.5814270759294904

Epoch: 6| Step: 12
Training loss: 1.8074203210893673
Validation loss: 2.60460542161634

Epoch: 6| Step: 13
Training loss: 2.555286675511981
Validation loss: 2.6102750219675355

Epoch: 261| Step: 0
Training loss: 2.309663218268787
Validation loss: 2.625138309407541

Epoch: 6| Step: 1
Training loss: 2.2099832692958623
Validation loss: 2.6155764503485264

Epoch: 6| Step: 2
Training loss: 2.5390979940427765
Validation loss: 2.6119009800495387

Epoch: 6| Step: 3
Training loss: 1.8539846809602034
Validation loss: 2.602711634732433

Epoch: 6| Step: 4
Training loss: 2.205136402262179
Validation loss: 2.576826065058983

Epoch: 6| Step: 5
Training loss: 2.143553686467591
Validation loss: 2.580041870201292

Epoch: 6| Step: 6
Training loss: 1.985652782520787
Validation loss: 2.5486222029284944

Epoch: 6| Step: 7
Training loss: 1.952916981109904
Validation loss: 2.5416762763503553

Epoch: 6| Step: 8
Training loss: 2.1427025285072556
Validation loss: 2.538291806361183

Epoch: 6| Step: 9
Training loss: 3.1012994380825076
Validation loss: 2.5099872733676256

Epoch: 6| Step: 10
Training loss: 2.0213058024236763
Validation loss: 2.5203497451707326

Epoch: 6| Step: 11
Training loss: 1.9398853630921304
Validation loss: 2.5100033025352566

Epoch: 6| Step: 12
Training loss: 2.1594716206421625
Validation loss: 2.5132094528224673

Epoch: 6| Step: 13
Training loss: 2.6028049011156185
Validation loss: 2.5076748343737014

Epoch: 262| Step: 0
Training loss: 1.9454633661927427
Validation loss: 2.525275491094677

Epoch: 6| Step: 1
Training loss: 1.8096417218944456
Validation loss: 2.5240280200523366

Epoch: 6| Step: 2
Training loss: 1.958310864366994
Validation loss: 2.5489551497921368

Epoch: 6| Step: 3
Training loss: 2.6618836741721488
Validation loss: 2.5612170566657544

Epoch: 6| Step: 4
Training loss: 2.412723206783673
Validation loss: 2.569509641719439

Epoch: 6| Step: 5
Training loss: 1.736999038819007
Validation loss: 2.595000842491802

Epoch: 6| Step: 6
Training loss: 2.3102065389537167
Validation loss: 2.6271391735348892

Epoch: 6| Step: 7
Training loss: 3.0203851476971755
Validation loss: 2.6225340477521475

Epoch: 6| Step: 8
Training loss: 1.884658604879356
Validation loss: 2.6398820603160935

Epoch: 6| Step: 9
Training loss: 2.5055632680176054
Validation loss: 2.6083358553385705

Epoch: 6| Step: 10
Training loss: 2.0288281601606117
Validation loss: 2.576401213222021

Epoch: 6| Step: 11
Training loss: 2.0747404142958814
Validation loss: 2.5641158522053726

Epoch: 6| Step: 12
Training loss: 2.645460047383949
Validation loss: 2.56312896018787

Epoch: 6| Step: 13
Training loss: 2.149769318203811
Validation loss: 2.567330502199286

Epoch: 263| Step: 0
Training loss: 2.1875607073398258
Validation loss: 2.540240705954343

Epoch: 6| Step: 1
Training loss: 2.4548375657490347
Validation loss: 2.5377745506450196

Epoch: 6| Step: 2
Training loss: 2.2778741601644015
Validation loss: 2.532646312121062

Epoch: 6| Step: 3
Training loss: 2.362635601531946
Validation loss: 2.549080391162015

Epoch: 6| Step: 4
Training loss: 2.815977786166183
Validation loss: 2.546099772977304

Epoch: 6| Step: 5
Training loss: 2.5790399950645546
Validation loss: 2.549051676918128

Epoch: 6| Step: 6
Training loss: 1.8940200587925462
Validation loss: 2.570136932900948

Epoch: 6| Step: 7
Training loss: 1.9367585147716286
Validation loss: 2.567892928126455

Epoch: 6| Step: 8
Training loss: 2.299811944322415
Validation loss: 2.6254761506218314

Epoch: 6| Step: 9
Training loss: 2.1433213230743804
Validation loss: 2.6161193945554575

Epoch: 6| Step: 10
Training loss: 2.2769412802327444
Validation loss: 2.6001735183084027

Epoch: 6| Step: 11
Training loss: 1.5913110658685539
Validation loss: 2.6113987458750696

Epoch: 6| Step: 12
Training loss: 1.9764421750562151
Validation loss: 2.6036875525653356

Epoch: 6| Step: 13
Training loss: 2.154163069386925
Validation loss: 2.5916816706902828

Epoch: 264| Step: 0
Training loss: 2.740263087039974
Validation loss: 2.566993263033685

Epoch: 6| Step: 1
Training loss: 1.5711159999036348
Validation loss: 2.5776101031684355

Epoch: 6| Step: 2
Training loss: 1.797530543952525
Validation loss: 2.5622836773752447

Epoch: 6| Step: 3
Training loss: 2.0861199117046803
Validation loss: 2.5579691738521095

Epoch: 6| Step: 4
Training loss: 2.889600912607668
Validation loss: 2.5528873241148067

Epoch: 6| Step: 5
Training loss: 1.7391203151802372
Validation loss: 2.5601015108566103

Epoch: 6| Step: 6
Training loss: 1.6745851600841395
Validation loss: 2.58062595093022

Epoch: 6| Step: 7
Training loss: 2.011399919743957
Validation loss: 2.5832593866244977

Epoch: 6| Step: 8
Training loss: 2.1086718482260287
Validation loss: 2.5563060054846245

Epoch: 6| Step: 9
Training loss: 2.283233616268813
Validation loss: 2.5567493731298176

Epoch: 6| Step: 10
Training loss: 3.0996401424118853
Validation loss: 2.5568611160680907

Epoch: 6| Step: 11
Training loss: 2.0882442449679695
Validation loss: 2.566391835010134

Epoch: 6| Step: 12
Training loss: 1.9959356017646466
Validation loss: 2.5834209109402386

Epoch: 6| Step: 13
Training loss: 2.527856129234301
Validation loss: 2.5618111994997057

Epoch: 265| Step: 0
Training loss: 3.2074789090254767
Validation loss: 2.574531146453474

Epoch: 6| Step: 1
Training loss: 2.6406421547958856
Validation loss: 2.5687235024130493

Epoch: 6| Step: 2
Training loss: 2.0873605967133875
Validation loss: 2.560536167055461

Epoch: 6| Step: 3
Training loss: 2.1939218263634856
Validation loss: 2.562495208363589

Epoch: 6| Step: 4
Training loss: 2.524316121014699
Validation loss: 2.5485043764646225

Epoch: 6| Step: 5
Training loss: 2.0245189943183326
Validation loss: 2.5398635383178503

Epoch: 6| Step: 6
Training loss: 2.0787382440010944
Validation loss: 2.5463873897660108

Epoch: 6| Step: 7
Training loss: 1.807899160459357
Validation loss: 2.5680671477298302

Epoch: 6| Step: 8
Training loss: 1.4633913698324343
Validation loss: 2.5657760953532964

Epoch: 6| Step: 9
Training loss: 2.3625273203405435
Validation loss: 2.557436880014556

Epoch: 6| Step: 10
Training loss: 1.683895429236808
Validation loss: 2.576257156221463

Epoch: 6| Step: 11
Training loss: 2.1031075509468384
Validation loss: 2.571170126577367

Epoch: 6| Step: 12
Training loss: 2.743403325522523
Validation loss: 2.545081929160298

Epoch: 6| Step: 13
Training loss: 1.4238545816943569
Validation loss: 2.556605343421012

Epoch: 266| Step: 0
Training loss: 2.74836005816894
Validation loss: 2.555652455609768

Epoch: 6| Step: 1
Training loss: 1.9426534472800978
Validation loss: 2.534339808585435

Epoch: 6| Step: 2
Training loss: 2.31767066039139
Validation loss: 2.5326914980187287

Epoch: 6| Step: 3
Training loss: 1.8850046273131706
Validation loss: 2.536860460889903

Epoch: 6| Step: 4
Training loss: 2.801204548321901
Validation loss: 2.5626046539273513

Epoch: 6| Step: 5
Training loss: 1.716096529061843
Validation loss: 2.5970783097440777

Epoch: 6| Step: 6
Training loss: 2.1380428138064573
Validation loss: 2.6225813970791885

Epoch: 6| Step: 7
Training loss: 1.9410188775851949
Validation loss: 2.6501898655561456

Epoch: 6| Step: 8
Training loss: 2.1290274209352584
Validation loss: 2.6600141893452958

Epoch: 6| Step: 9
Training loss: 2.0798277798293783
Validation loss: 2.627221726461211

Epoch: 6| Step: 10
Training loss: 1.9040722523772435
Validation loss: 2.615543012044267

Epoch: 6| Step: 11
Training loss: 2.264048060442869
Validation loss: 2.575461690060996

Epoch: 6| Step: 12
Training loss: 2.194036472667671
Validation loss: 2.5608336760643495

Epoch: 6| Step: 13
Training loss: 2.987679773771451
Validation loss: 2.528508495263987

Epoch: 267| Step: 0
Training loss: 2.0622862502801307
Validation loss: 2.5226700504477204

Epoch: 6| Step: 1
Training loss: 2.3362919465162504
Validation loss: 2.505602075375647

Epoch: 6| Step: 2
Training loss: 2.379602389901956
Validation loss: 2.519202758508648

Epoch: 6| Step: 3
Training loss: 2.6036167225307563
Validation loss: 2.510568564055037

Epoch: 6| Step: 4
Training loss: 2.601350059656242
Validation loss: 2.5206842982686037

Epoch: 6| Step: 5
Training loss: 2.5565931579519776
Validation loss: 2.51593972837733

Epoch: 6| Step: 6
Training loss: 2.3832825244031577
Validation loss: 2.5272679030108516

Epoch: 6| Step: 7
Training loss: 2.1684894108389496
Validation loss: 2.542172840141007

Epoch: 6| Step: 8
Training loss: 1.8825376951134203
Validation loss: 2.568702618733544

Epoch: 6| Step: 9
Training loss: 1.692935666199799
Validation loss: 2.5749997086509366

Epoch: 6| Step: 10
Training loss: 2.005450451258064
Validation loss: 2.5818386958314066

Epoch: 6| Step: 11
Training loss: 1.8343424259653407
Validation loss: 2.59514045979556

Epoch: 6| Step: 12
Training loss: 2.651421949969677
Validation loss: 2.5875164639598776

Epoch: 6| Step: 13
Training loss: 2.3300155030090886
Validation loss: 2.588023041030537

Epoch: 268| Step: 0
Training loss: 1.8099300317254867
Validation loss: 2.5857313367827888

Epoch: 6| Step: 1
Training loss: 1.7669899989494364
Validation loss: 2.6017917688591483

Epoch: 6| Step: 2
Training loss: 2.996185738992819
Validation loss: 2.5958160383486186

Epoch: 6| Step: 3
Training loss: 2.3031511778877145
Validation loss: 2.566840751945192

Epoch: 6| Step: 4
Training loss: 1.8903821048291536
Validation loss: 2.5715918482809634

Epoch: 6| Step: 5
Training loss: 2.6732823641794394
Validation loss: 2.5789878095033276

Epoch: 6| Step: 6
Training loss: 2.2756498393793554
Validation loss: 2.57790389991346

Epoch: 6| Step: 7
Training loss: 2.6919950995436075
Validation loss: 2.5645675304389752

Epoch: 6| Step: 8
Training loss: 2.34651854712299
Validation loss: 2.59301123764814

Epoch: 6| Step: 9
Training loss: 1.6054262772856673
Validation loss: 2.5865984683738867

Epoch: 6| Step: 10
Training loss: 1.715949395089368
Validation loss: 2.6005927981206054

Epoch: 6| Step: 11
Training loss: 2.433620887470332
Validation loss: 2.6240890981193794

Epoch: 6| Step: 12
Training loss: 2.2723315718106183
Validation loss: 2.6208083124790873

Epoch: 6| Step: 13
Training loss: 1.768625056837883
Validation loss: 2.6124040607315893

Epoch: 269| Step: 0
Training loss: 2.768981018072982
Validation loss: 2.639518867273494

Epoch: 6| Step: 1
Training loss: 2.044234808019221
Validation loss: 2.611112081130729

Epoch: 6| Step: 2
Training loss: 2.1916205697475837
Validation loss: 2.5995167735569287

Epoch: 6| Step: 3
Training loss: 2.3893746490837477
Validation loss: 2.6019143906158306

Epoch: 6| Step: 4
Training loss: 2.212323835870495
Validation loss: 2.6018043993655993

Epoch: 6| Step: 5
Training loss: 2.3030211550775785
Validation loss: 2.635459550249806

Epoch: 6| Step: 6
Training loss: 2.216029043441108
Validation loss: 2.616307747475889

Epoch: 6| Step: 7
Training loss: 1.9242997419230552
Validation loss: 2.579841304501647

Epoch: 6| Step: 8
Training loss: 1.872510337953844
Validation loss: 2.5629451799199416

Epoch: 6| Step: 9
Training loss: 2.4341286060771012
Validation loss: 2.550233035254004

Epoch: 6| Step: 10
Training loss: 1.8016552572862483
Validation loss: 2.5498736462423284

Epoch: 6| Step: 11
Training loss: 2.720663340127724
Validation loss: 2.524406868920078

Epoch: 6| Step: 12
Training loss: 2.415226825305603
Validation loss: 2.5177878960025195

Epoch: 6| Step: 13
Training loss: 1.6612816440619624
Validation loss: 2.5229003303013626

Epoch: 270| Step: 0
Training loss: 2.6997721611248724
Validation loss: 2.5082916245736766

Epoch: 6| Step: 1
Training loss: 2.539815092790498
Validation loss: 2.519694099781922

Epoch: 6| Step: 2
Training loss: 1.8867555223755408
Validation loss: 2.5552490115021818

Epoch: 6| Step: 3
Training loss: 2.471742675171589
Validation loss: 2.5766228355127567

Epoch: 6| Step: 4
Training loss: 1.7548997949320884
Validation loss: 2.6108727791642616

Epoch: 6| Step: 5
Training loss: 2.036271446869123
Validation loss: 2.604394968833745

Epoch: 6| Step: 6
Training loss: 2.1306862765178853
Validation loss: 2.618942659099664

Epoch: 6| Step: 7
Training loss: 2.1551859344847553
Validation loss: 2.654366262846836

Epoch: 6| Step: 8
Training loss: 2.9862749532852217
Validation loss: 2.6927885760532475

Epoch: 6| Step: 9
Training loss: 2.018634530653622
Validation loss: 2.703151210297686

Epoch: 6| Step: 10
Training loss: 2.580599712636885
Validation loss: 2.6863530247196117

Epoch: 6| Step: 11
Training loss: 2.1897612736848693
Validation loss: 2.649930190120526

Epoch: 6| Step: 12
Training loss: 1.527758451782679
Validation loss: 2.5934939430420547

Epoch: 6| Step: 13
Training loss: 1.7654662609479492
Validation loss: 2.5769794886232513

Epoch: 271| Step: 0
Training loss: 2.093580552261745
Validation loss: 2.5481166660252708

Epoch: 6| Step: 1
Training loss: 1.5448813644094124
Validation loss: 2.5523798218898635

Epoch: 6| Step: 2
Training loss: 2.679089181905763
Validation loss: 2.5261422573131034

Epoch: 6| Step: 3
Training loss: 2.3971874446219927
Validation loss: 2.5161615435305196

Epoch: 6| Step: 4
Training loss: 1.508046344550867
Validation loss: 2.508857628110705

Epoch: 6| Step: 5
Training loss: 2.5931357150386263
Validation loss: 2.5095026454867257

Epoch: 6| Step: 6
Training loss: 2.638945276650643
Validation loss: 2.5165459820776763

Epoch: 6| Step: 7
Training loss: 2.260251216429459
Validation loss: 2.5263244994923815

Epoch: 6| Step: 8
Training loss: 1.3818534068159227
Validation loss: 2.5164360650203137

Epoch: 6| Step: 9
Training loss: 2.1716040572624085
Validation loss: 2.505051991956777

Epoch: 6| Step: 10
Training loss: 2.2545812379536727
Validation loss: 2.5438183187172307

Epoch: 6| Step: 11
Training loss: 2.5055183541336095
Validation loss: 2.5504743109997685

Epoch: 6| Step: 12
Training loss: 1.8504167061679524
Validation loss: 2.592154230291744

Epoch: 6| Step: 13
Training loss: 2.6185698089880014
Validation loss: 2.6019610919648115

Epoch: 272| Step: 0
Training loss: 1.7724813833187152
Validation loss: 2.6307225294425303

Epoch: 6| Step: 1
Training loss: 2.168925196362422
Validation loss: 2.607530379686799

Epoch: 6| Step: 2
Training loss: 2.4015986085558576
Validation loss: 2.6069945634122624

Epoch: 6| Step: 3
Training loss: 1.921869045341385
Validation loss: 2.602807496465621

Epoch: 6| Step: 4
Training loss: 3.050314346123766
Validation loss: 2.5592082520856194

Epoch: 6| Step: 5
Training loss: 2.116136803976655
Validation loss: 2.54319653562702

Epoch: 6| Step: 6
Training loss: 2.0154941723378976
Validation loss: 2.535823787036502

Epoch: 6| Step: 7
Training loss: 2.200539661454831
Validation loss: 2.5257008483216308

Epoch: 6| Step: 8
Training loss: 2.158786553281587
Validation loss: 2.507855202062739

Epoch: 6| Step: 9
Training loss: 2.0660251201051545
Validation loss: 2.510016877774946

Epoch: 6| Step: 10
Training loss: 2.318375623560899
Validation loss: 2.519970199633301

Epoch: 6| Step: 11
Training loss: 2.9325197897891297
Validation loss: 2.5295745500807842

Epoch: 6| Step: 12
Training loss: 1.5525694561592827
Validation loss: 2.556176407927558

Epoch: 6| Step: 13
Training loss: 2.2519289860750926
Validation loss: 2.5721203630967344

Epoch: 273| Step: 0
Training loss: 2.284311095882033
Validation loss: 2.549127951339759

Epoch: 6| Step: 1
Training loss: 2.396629223413894
Validation loss: 2.5950092338294826

Epoch: 6| Step: 2
Training loss: 2.0120877714484044
Validation loss: 2.601861640602041

Epoch: 6| Step: 3
Training loss: 2.156737452155574
Validation loss: 2.6219194289494614

Epoch: 6| Step: 4
Training loss: 1.7887143791698616
Validation loss: 2.6317899323678926

Epoch: 6| Step: 5
Training loss: 2.6955615826936232
Validation loss: 2.6206050138577957

Epoch: 6| Step: 6
Training loss: 2.0838920479855645
Validation loss: 2.6316584048907536

Epoch: 6| Step: 7
Training loss: 3.161474455153927
Validation loss: 2.638565569584995

Epoch: 6| Step: 8
Training loss: 1.553946006730445
Validation loss: 2.5727457512266367

Epoch: 6| Step: 9
Training loss: 1.8637269324775458
Validation loss: 2.5500382046549

Epoch: 6| Step: 10
Training loss: 2.2572256203286627
Validation loss: 2.5227508476779343

Epoch: 6| Step: 11
Training loss: 2.1638044623490678
Validation loss: 2.506209799173799

Epoch: 6| Step: 12
Training loss: 2.1558138641237203
Validation loss: 2.4934508371289286

Epoch: 6| Step: 13
Training loss: 2.073491488043481
Validation loss: 2.503569740539463

Epoch: 274| Step: 0
Training loss: 1.5777488486827216
Validation loss: 2.5138004075479503

Epoch: 6| Step: 1
Training loss: 2.2769062021040596
Validation loss: 2.4999956607780947

Epoch: 6| Step: 2
Training loss: 2.800040898705558
Validation loss: 2.5040114326622307

Epoch: 6| Step: 3
Training loss: 2.0631889579725966
Validation loss: 2.5208592584290974

Epoch: 6| Step: 4
Training loss: 2.4976843599963567
Validation loss: 2.5239140677627687

Epoch: 6| Step: 5
Training loss: 2.3743233971788404
Validation loss: 2.5647979915060524

Epoch: 6| Step: 6
Training loss: 1.6068171943228886
Validation loss: 2.573667946807967

Epoch: 6| Step: 7
Training loss: 2.1844132579678446
Validation loss: 2.595093574453821

Epoch: 6| Step: 8
Training loss: 2.208864136247384
Validation loss: 2.632202485272965

Epoch: 6| Step: 9
Training loss: 1.8187943050061295
Validation loss: 2.6533072682718637

Epoch: 6| Step: 10
Training loss: 3.1638115677406318
Validation loss: 2.6536294164826737

Epoch: 6| Step: 11
Training loss: 1.749345929666464
Validation loss: 2.658686608624574

Epoch: 6| Step: 12
Training loss: 2.2130485673583435
Validation loss: 2.6071834536164427

Epoch: 6| Step: 13
Training loss: 2.0582136060151384
Validation loss: 2.5856007551692186

Epoch: 275| Step: 0
Training loss: 2.457068511243696
Validation loss: 2.5285409394235647

Epoch: 6| Step: 1
Training loss: 2.8357086509656844
Validation loss: 2.5090194919042403

Epoch: 6| Step: 2
Training loss: 2.2354914936815917
Validation loss: 2.503958453082049

Epoch: 6| Step: 3
Training loss: 2.1127112108090684
Validation loss: 2.515578433409422

Epoch: 6| Step: 4
Training loss: 1.8438958579091318
Validation loss: 2.49579983982248

Epoch: 6| Step: 5
Training loss: 2.03674605760606
Validation loss: 2.4972776531516767

Epoch: 6| Step: 6
Training loss: 2.221280012126555
Validation loss: 2.510721881932224

Epoch: 6| Step: 7
Training loss: 1.7659410176995647
Validation loss: 2.5027530611318167

Epoch: 6| Step: 8
Training loss: 1.1178206670269195
Validation loss: 2.5107006661577285

Epoch: 6| Step: 9
Training loss: 2.517520924607174
Validation loss: 2.5118615489054426

Epoch: 6| Step: 10
Training loss: 2.8992778865587843
Validation loss: 2.5269063564219736

Epoch: 6| Step: 11
Training loss: 2.1085741571489227
Validation loss: 2.5385697106675207

Epoch: 6| Step: 12
Training loss: 2.1921113591691768
Validation loss: 2.5908239551283248

Epoch: 6| Step: 13
Training loss: 2.143545233286383
Validation loss: 2.626316285492917

Epoch: 276| Step: 0
Training loss: 1.8359845094546738
Validation loss: 2.684988178745723

Epoch: 6| Step: 1
Training loss: 3.4669621989629604
Validation loss: 2.6875145933952664

Epoch: 6| Step: 2
Training loss: 1.8698096597668235
Validation loss: 2.6804698695409592

Epoch: 6| Step: 3
Training loss: 1.7204155914433856
Validation loss: 2.6121577882908116

Epoch: 6| Step: 4
Training loss: 2.4784262590702935
Validation loss: 2.5718551690598983

Epoch: 6| Step: 5
Training loss: 1.8610393864616153
Validation loss: 2.545575003204401

Epoch: 6| Step: 6
Training loss: 2.7793279285532386
Validation loss: 2.528059420306795

Epoch: 6| Step: 7
Training loss: 2.1914819714524625
Validation loss: 2.5281312512547207

Epoch: 6| Step: 8
Training loss: 2.2013243763720434
Validation loss: 2.5217515255789267

Epoch: 6| Step: 9
Training loss: 2.759007700130589
Validation loss: 2.5335525824595515

Epoch: 6| Step: 10
Training loss: 2.0065467496169727
Validation loss: 2.547260356683718

Epoch: 6| Step: 11
Training loss: 2.292335851818345
Validation loss: 2.561468133730534

Epoch: 6| Step: 12
Training loss: 1.2652576996742928
Validation loss: 2.603674198633813

Epoch: 6| Step: 13
Training loss: 1.854391005870938
Validation loss: 2.615953904365055

Epoch: 277| Step: 0
Training loss: 2.1400066512886857
Validation loss: 2.6202685387900075

Epoch: 6| Step: 1
Training loss: 1.4330820942780738
Validation loss: 2.632361142250931

Epoch: 6| Step: 2
Training loss: 2.1667797230299035
Validation loss: 2.6424542774201454

Epoch: 6| Step: 3
Training loss: 2.0180988359926073
Validation loss: 2.614450995957675

Epoch: 6| Step: 4
Training loss: 1.7142848883354378
Validation loss: 2.5903828377734204

Epoch: 6| Step: 5
Training loss: 3.0039560936412526
Validation loss: 2.55054320489878

Epoch: 6| Step: 6
Training loss: 2.3216225364892575
Validation loss: 2.5483376607199086

Epoch: 6| Step: 7
Training loss: 2.1074348852341105
Validation loss: 2.5364178622318034

Epoch: 6| Step: 8
Training loss: 2.1141937598553793
Validation loss: 2.5389059556484352

Epoch: 6| Step: 9
Training loss: 2.433998037589794
Validation loss: 2.557619455828589

Epoch: 6| Step: 10
Training loss: 2.740994272615057
Validation loss: 2.5608579134876073

Epoch: 6| Step: 11
Training loss: 2.060131446940781
Validation loss: 2.575792324669845

Epoch: 6| Step: 12
Training loss: 2.062725054859959
Validation loss: 2.6186435425939023

Epoch: 6| Step: 13
Training loss: 2.5226182109555597
Validation loss: 2.641140768931072

Epoch: 278| Step: 0
Training loss: 2.8966728658430565
Validation loss: 2.6646829816624025

Epoch: 6| Step: 1
Training loss: 2.471048564660584
Validation loss: 2.6443375141321206

Epoch: 6| Step: 2
Training loss: 1.9695257444807892
Validation loss: 2.611563976957366

Epoch: 6| Step: 3
Training loss: 2.177856989261193
Validation loss: 2.5856407048989665

Epoch: 6| Step: 4
Training loss: 2.298441864984596
Validation loss: 2.571091832334394

Epoch: 6| Step: 5
Training loss: 2.4094377680220735
Validation loss: 2.553514154752888

Epoch: 6| Step: 6
Training loss: 2.5005012009802186
Validation loss: 2.546664082973561

Epoch: 6| Step: 7
Training loss: 2.390894756181865
Validation loss: 2.549025503338027

Epoch: 6| Step: 8
Training loss: 1.779252387787703
Validation loss: 2.524280970082171

Epoch: 6| Step: 9
Training loss: 2.3180027006856014
Validation loss: 2.571236472359275

Epoch: 6| Step: 10
Training loss: 1.897220299854611
Validation loss: 2.5572828666913705

Epoch: 6| Step: 11
Training loss: 1.8894456700400144
Validation loss: 2.5616960892717704

Epoch: 6| Step: 12
Training loss: 1.4732265835203324
Validation loss: 2.5718986618294615

Epoch: 6| Step: 13
Training loss: 1.7409639723597985
Validation loss: 2.5606886191360267

Epoch: 279| Step: 0
Training loss: 1.9373568205073712
Validation loss: 2.587558096388577

Epoch: 6| Step: 1
Training loss: 2.0165582906223016
Validation loss: 2.60369391664346

Epoch: 6| Step: 2
Training loss: 2.2838341695039825
Validation loss: 2.6067107679908004

Epoch: 6| Step: 3
Training loss: 2.4519491110868055
Validation loss: 2.652360843983522

Epoch: 6| Step: 4
Training loss: 2.1988892655674555
Validation loss: 2.6283630444724686

Epoch: 6| Step: 5
Training loss: 2.404628058399711
Validation loss: 2.6404579606352994

Epoch: 6| Step: 6
Training loss: 1.36145132812628
Validation loss: 2.597398405734825

Epoch: 6| Step: 7
Training loss: 2.23076033147762
Validation loss: 2.5556121148424977

Epoch: 6| Step: 8
Training loss: 1.5725713776125259
Validation loss: 2.5506289379684906

Epoch: 6| Step: 9
Training loss: 2.2445147727842163
Validation loss: 2.531960862423228

Epoch: 6| Step: 10
Training loss: 1.993820897100428
Validation loss: 2.531736060361952

Epoch: 6| Step: 11
Training loss: 2.54943821646534
Validation loss: 2.5229038583654546

Epoch: 6| Step: 12
Training loss: 2.238611220292098
Validation loss: 2.515131505102828

Epoch: 6| Step: 13
Training loss: 3.0057334154692037
Validation loss: 2.512636229710865

Epoch: 280| Step: 0
Training loss: 1.3336143594857774
Validation loss: 2.5203612544970135

Epoch: 6| Step: 1
Training loss: 2.415734165977073
Validation loss: 2.5282679601862688

Epoch: 6| Step: 2
Training loss: 1.4096333810324224
Validation loss: 2.5349337456175483

Epoch: 6| Step: 3
Training loss: 2.3340317725312882
Validation loss: 2.5608170573144253

Epoch: 6| Step: 4
Training loss: 2.4665496291498132
Validation loss: 2.5823879101416662

Epoch: 6| Step: 5
Training loss: 1.9251975515483581
Validation loss: 2.632082723867388

Epoch: 6| Step: 6
Training loss: 2.7017608022635358
Validation loss: 2.657223227733766

Epoch: 6| Step: 7
Training loss: 1.4036685561945932
Validation loss: 2.685738156066684

Epoch: 6| Step: 8
Training loss: 2.3448099409894168
Validation loss: 2.7110055553970818

Epoch: 6| Step: 9
Training loss: 2.4362862328173454
Validation loss: 2.7005729020389153

Epoch: 6| Step: 10
Training loss: 2.556627755828478
Validation loss: 2.684970582105899

Epoch: 6| Step: 11
Training loss: 2.159808222239708
Validation loss: 2.646406432032774

Epoch: 6| Step: 12
Training loss: 2.3548765434415184
Validation loss: 2.553837968378911

Epoch: 6| Step: 13
Training loss: 2.487759569896638
Validation loss: 2.5329451595066996

Epoch: 281| Step: 0
Training loss: 2.329177413760955
Validation loss: 2.5223754758063883

Epoch: 6| Step: 1
Training loss: 2.089569473093858
Validation loss: 2.5392212646927623

Epoch: 6| Step: 2
Training loss: 2.3343410586502964
Validation loss: 2.53040494274043

Epoch: 6| Step: 3
Training loss: 1.8865381632245053
Validation loss: 2.5344196301539323

Epoch: 6| Step: 4
Training loss: 2.1654812675657626
Validation loss: 2.5398002765509475

Epoch: 6| Step: 5
Training loss: 1.4522799424000223
Validation loss: 2.5798632146987335

Epoch: 6| Step: 6
Training loss: 2.1334644480984557
Validation loss: 2.582747090383162

Epoch: 6| Step: 7
Training loss: 2.6500312263520347
Validation loss: 2.569219803369403

Epoch: 6| Step: 8
Training loss: 2.0036237789004923
Validation loss: 2.5927058956451012

Epoch: 6| Step: 9
Training loss: 1.9543936919516136
Validation loss: 2.574463465572828

Epoch: 6| Step: 10
Training loss: 2.4146316005653894
Validation loss: 2.586030234280826

Epoch: 6| Step: 11
Training loss: 1.9391291752125233
Validation loss: 2.5916133797453025

Epoch: 6| Step: 12
Training loss: 2.615782220962296
Validation loss: 2.5927889778547932

Epoch: 6| Step: 13
Training loss: 2.1873196118773257
Validation loss: 2.572045388493125

Epoch: 282| Step: 0
Training loss: 1.6430811344297176
Validation loss: 2.5609901601246596

Epoch: 6| Step: 1
Training loss: 2.6340494843963693
Validation loss: 2.548846490045986

Epoch: 6| Step: 2
Training loss: 2.071027524300122
Validation loss: 2.554922592747307

Epoch: 6| Step: 3
Training loss: 2.079603314719958
Validation loss: 2.5468012637208375

Epoch: 6| Step: 4
Training loss: 2.9899610398219774
Validation loss: 2.531532083499796

Epoch: 6| Step: 5
Training loss: 1.6080672496948054
Validation loss: 2.5340533647064047

Epoch: 6| Step: 6
Training loss: 2.1595563003680245
Validation loss: 2.5286361557958332

Epoch: 6| Step: 7
Training loss: 1.7043649202166944
Validation loss: 2.5276643293258334

Epoch: 6| Step: 8
Training loss: 1.5726105684789076
Validation loss: 2.530314551288982

Epoch: 6| Step: 9
Training loss: 3.152077513540425
Validation loss: 2.53836937466952

Epoch: 6| Step: 10
Training loss: 2.0556257883164912
Validation loss: 2.558862927281618

Epoch: 6| Step: 11
Training loss: 2.629255569172092
Validation loss: 2.545499652611509

Epoch: 6| Step: 12
Training loss: 1.5852937942324705
Validation loss: 2.5845407284448534

Epoch: 6| Step: 13
Training loss: 1.4685478071276596
Validation loss: 2.611458161948378

Epoch: 283| Step: 0
Training loss: 2.5542898072703393
Validation loss: 2.622773209926782

Epoch: 6| Step: 1
Training loss: 2.8603727340565905
Validation loss: 2.6014875643670794

Epoch: 6| Step: 2
Training loss: 2.068969751770246
Validation loss: 2.5960752030585525

Epoch: 6| Step: 3
Training loss: 1.1420077995327902
Validation loss: 2.5934325793806026

Epoch: 6| Step: 4
Training loss: 2.0545546340046807
Validation loss: 2.5765202778105185

Epoch: 6| Step: 5
Training loss: 1.7545772364986134
Validation loss: 2.563834625910719

Epoch: 6| Step: 6
Training loss: 2.053202741710052
Validation loss: 2.59072067887798

Epoch: 6| Step: 7
Training loss: 2.16524277874181
Validation loss: 2.5736851773552574

Epoch: 6| Step: 8
Training loss: 1.73054976090709
Validation loss: 2.573447513773153

Epoch: 6| Step: 9
Training loss: 2.1924862299870576
Validation loss: 2.589682626291173

Epoch: 6| Step: 10
Training loss: 2.5549135253963917
Validation loss: 2.5920053459061334

Epoch: 6| Step: 11
Training loss: 2.6742962134216888
Validation loss: 2.5844567583859863

Epoch: 6| Step: 12
Training loss: 2.1946551333124766
Validation loss: 2.5876654991259636

Epoch: 6| Step: 13
Training loss: 1.8142181671407103
Validation loss: 2.578607995614691

Epoch: 284| Step: 0
Training loss: 2.2872489541297694
Validation loss: 2.5741944454205408

Epoch: 6| Step: 1
Training loss: 1.599219566982342
Validation loss: 2.565189593808027

Epoch: 6| Step: 2
Training loss: 2.6078531544363766
Validation loss: 2.565293890170355

Epoch: 6| Step: 3
Training loss: 2.5909600017114793
Validation loss: 2.5469756467314184

Epoch: 6| Step: 4
Training loss: 1.8035310945762464
Validation loss: 2.5796615568474257

Epoch: 6| Step: 5
Training loss: 2.0684378719833783
Validation loss: 2.574752327819398

Epoch: 6| Step: 6
Training loss: 2.77719326121279
Validation loss: 2.5609843260863747

Epoch: 6| Step: 7
Training loss: 2.223479911094108
Validation loss: 2.5831161889726575

Epoch: 6| Step: 8
Training loss: 1.62343096176461
Validation loss: 2.579027299294481

Epoch: 6| Step: 9
Training loss: 2.4868432026124774
Validation loss: 2.616789541781371

Epoch: 6| Step: 10
Training loss: 2.33906198220002
Validation loss: 2.636552736683932

Epoch: 6| Step: 11
Training loss: 1.7571515684543222
Validation loss: 2.635619662059854

Epoch: 6| Step: 12
Training loss: 1.539204392451881
Validation loss: 2.636829364481472

Epoch: 6| Step: 13
Training loss: 1.9140118650628686
Validation loss: 2.635473760858411

Epoch: 285| Step: 0
Training loss: 1.7832408286847794
Validation loss: 2.6287421694409314

Epoch: 6| Step: 1
Training loss: 1.8993335383196304
Validation loss: 2.6234941856223393

Epoch: 6| Step: 2
Training loss: 2.418446532145215
Validation loss: 2.632961914169532

Epoch: 6| Step: 3
Training loss: 2.139186180668706
Validation loss: 2.5946655495978703

Epoch: 6| Step: 4
Training loss: 1.6238308148319374
Validation loss: 2.6020973808900987

Epoch: 6| Step: 5
Training loss: 1.8908434024484968
Validation loss: 2.6062830196396

Epoch: 6| Step: 6
Training loss: 1.9153394526724559
Validation loss: 2.5969217662678172

Epoch: 6| Step: 7
Training loss: 1.66541117428251
Validation loss: 2.5933186428990926

Epoch: 6| Step: 8
Training loss: 2.587589439283737
Validation loss: 2.597428604897324

Epoch: 6| Step: 9
Training loss: 1.9562224584231185
Validation loss: 2.6085195147902076

Epoch: 6| Step: 10
Training loss: 2.6158915029593883
Validation loss: 2.6319398273258647

Epoch: 6| Step: 11
Training loss: 1.5896868804096553
Validation loss: 2.6279757375284243

Epoch: 6| Step: 12
Training loss: 2.1723173500601973
Validation loss: 2.637729720345894

Epoch: 6| Step: 13
Training loss: 3.030073586505158
Validation loss: 2.608732803110136

Epoch: 286| Step: 0
Training loss: 2.6188364783964335
Validation loss: 2.6222976368181805

Epoch: 6| Step: 1
Training loss: 2.217853741218691
Validation loss: 2.590550237603778

Epoch: 6| Step: 2
Training loss: 1.677205083309579
Validation loss: 2.5671524209527896

Epoch: 6| Step: 3
Training loss: 2.080187125775219
Validation loss: 2.562185826464452

Epoch: 6| Step: 4
Training loss: 2.233038656047919
Validation loss: 2.5568597018277575

Epoch: 6| Step: 5
Training loss: 2.6910937035051234
Validation loss: 2.5576030492422164

Epoch: 6| Step: 6
Training loss: 1.3164002732500635
Validation loss: 2.5528071304845734

Epoch: 6| Step: 7
Training loss: 1.9250066410296933
Validation loss: 2.5415848942927832

Epoch: 6| Step: 8
Training loss: 2.6024577115568843
Validation loss: 2.5585508076022236

Epoch: 6| Step: 9
Training loss: 2.2600699889899554
Validation loss: 2.5781783050266855

Epoch: 6| Step: 10
Training loss: 1.7538318915630213
Validation loss: 2.600432523795101

Epoch: 6| Step: 11
Training loss: 2.711433475207997
Validation loss: 2.6490013850097953

Epoch: 6| Step: 12
Training loss: 1.7387133800563739
Validation loss: 2.6457549156122395

Epoch: 6| Step: 13
Training loss: 2.029574128377213
Validation loss: 2.6184544471622977

Epoch: 287| Step: 0
Training loss: 2.2060739247030874
Validation loss: 2.6463826177537046

Epoch: 6| Step: 1
Training loss: 1.7830581188261068
Validation loss: 2.601539420788246

Epoch: 6| Step: 2
Training loss: 2.5754432370820446
Validation loss: 2.569541065587408

Epoch: 6| Step: 3
Training loss: 1.9573003465894123
Validation loss: 2.5563970478421427

Epoch: 6| Step: 4
Training loss: 1.6351567282496016
Validation loss: 2.529695386679916

Epoch: 6| Step: 5
Training loss: 2.572544693924673
Validation loss: 2.5428720075934135

Epoch: 6| Step: 6
Training loss: 2.950886680410239
Validation loss: 2.543470451371815

Epoch: 6| Step: 7
Training loss: 2.0474194683404767
Validation loss: 2.5061808870700273

Epoch: 6| Step: 8
Training loss: 2.1434713777589214
Validation loss: 2.517819192066337

Epoch: 6| Step: 9
Training loss: 2.25118584642604
Validation loss: 2.538786183507433

Epoch: 6| Step: 10
Training loss: 1.413935323655108
Validation loss: 2.5205696115131517

Epoch: 6| Step: 11
Training loss: 2.0164093147618125
Validation loss: 2.544423958040229

Epoch: 6| Step: 12
Training loss: 1.918898285345355
Validation loss: 2.5790689455006732

Epoch: 6| Step: 13
Training loss: 1.995521478306533
Validation loss: 2.588125588168953

Epoch: 288| Step: 0
Training loss: 2.5316743848162746
Validation loss: 2.6250068043817403

Epoch: 6| Step: 1
Training loss: 1.954536172328627
Validation loss: 2.658921039473888

Epoch: 6| Step: 2
Training loss: 2.3836796417814945
Validation loss: 2.6728035724249506

Epoch: 6| Step: 3
Training loss: 2.36065265343396
Validation loss: 2.6543621011242005

Epoch: 6| Step: 4
Training loss: 2.467408310598332
Validation loss: 2.6199783931088745

Epoch: 6| Step: 5
Training loss: 1.8038025374768059
Validation loss: 2.620430587203462

Epoch: 6| Step: 6
Training loss: 2.8697215843066637
Validation loss: 2.6111665084612214

Epoch: 6| Step: 7
Training loss: 2.0744332240370547
Validation loss: 2.5845037905649946

Epoch: 6| Step: 8
Training loss: 2.2819762445629252
Validation loss: 2.576297227703318

Epoch: 6| Step: 9
Training loss: 2.0054936061577457
Validation loss: 2.5889022749944495

Epoch: 6| Step: 10
Training loss: 1.5649586978617627
Validation loss: 2.586148763364991

Epoch: 6| Step: 11
Training loss: 1.5905012790851072
Validation loss: 2.57450665189094

Epoch: 6| Step: 12
Training loss: 1.9853156556101825
Validation loss: 2.5921746491061333

Epoch: 6| Step: 13
Training loss: 1.7153551733734596
Validation loss: 2.6049454834151993

Epoch: 289| Step: 0
Training loss: 1.7915816915306928
Validation loss: 2.601756442824487

Epoch: 6| Step: 1
Training loss: 1.7622836744511539
Validation loss: 2.595649866036609

Epoch: 6| Step: 2
Training loss: 2.171155632045859
Validation loss: 2.591123929082916

Epoch: 6| Step: 3
Training loss: 1.8695565999500712
Validation loss: 2.5872426960117996

Epoch: 6| Step: 4
Training loss: 2.35682287562677
Validation loss: 2.58873699431174

Epoch: 6| Step: 5
Training loss: 2.1823787140764668
Validation loss: 2.542775980356763

Epoch: 6| Step: 6
Training loss: 2.308853986760041
Validation loss: 2.5805638501248773

Epoch: 6| Step: 7
Training loss: 1.9572139814577934
Validation loss: 2.5579729487003084

Epoch: 6| Step: 8
Training loss: 2.5226950483271353
Validation loss: 2.5823649288452395

Epoch: 6| Step: 9
Training loss: 1.9248015289048475
Validation loss: 2.580304020655241

Epoch: 6| Step: 10
Training loss: 1.9167986561759351
Validation loss: 2.6016457117651317

Epoch: 6| Step: 11
Training loss: 2.3563217718794385
Validation loss: 2.599943281435368

Epoch: 6| Step: 12
Training loss: 2.4672079944302956
Validation loss: 2.6454865886728247

Epoch: 6| Step: 13
Training loss: 2.3748602575048032
Validation loss: 2.672092614783589

Epoch: 290| Step: 0
Training loss: 1.920087277495021
Validation loss: 2.630289213743613

Epoch: 6| Step: 1
Training loss: 2.8336518800471806
Validation loss: 2.5987017141079254

Epoch: 6| Step: 2
Training loss: 2.126043287990263
Validation loss: 2.589668939290019

Epoch: 6| Step: 3
Training loss: 1.6519310979305948
Validation loss: 2.5844743782564796

Epoch: 6| Step: 4
Training loss: 2.4463103089770963
Validation loss: 2.546801513360594

Epoch: 6| Step: 5
Training loss: 1.2944389351785306
Validation loss: 2.544130855732681

Epoch: 6| Step: 6
Training loss: 1.9203611164441596
Validation loss: 2.5389809932831184

Epoch: 6| Step: 7
Training loss: 2.6614060567859013
Validation loss: 2.5509171033495015

Epoch: 6| Step: 8
Training loss: 2.8194521281153855
Validation loss: 2.5532705594688676

Epoch: 6| Step: 9
Training loss: 2.445696620813704
Validation loss: 2.531204866862491

Epoch: 6| Step: 10
Training loss: 1.578483691856572
Validation loss: 2.539565426828804

Epoch: 6| Step: 11
Training loss: 1.948656631787555
Validation loss: 2.5537606520764378

Epoch: 6| Step: 12
Training loss: 1.74739207358792
Validation loss: 2.557476469511519

Epoch: 6| Step: 13
Training loss: 1.6588329112209745
Validation loss: 2.59598467208626

Epoch: 291| Step: 0
Training loss: 2.1045666179195837
Validation loss: 2.6323923894534045

Epoch: 6| Step: 1
Training loss: 2.243819968320082
Validation loss: 2.6446906698644335

Epoch: 6| Step: 2
Training loss: 2.975918437332296
Validation loss: 2.667295036688217

Epoch: 6| Step: 3
Training loss: 2.7036929553711953
Validation loss: 2.626398531432472

Epoch: 6| Step: 4
Training loss: 1.3661247264391625
Validation loss: 2.670642992597802

Epoch: 6| Step: 5
Training loss: 2.3360069034944715
Validation loss: 2.6419820364621267

Epoch: 6| Step: 6
Training loss: 2.1285855952968222
Validation loss: 2.6259450724983338

Epoch: 6| Step: 7
Training loss: 1.4643675169873644
Validation loss: 2.59012133921649

Epoch: 6| Step: 8
Training loss: 1.9747081396078006
Validation loss: 2.5870489092778213

Epoch: 6| Step: 9
Training loss: 1.468501942566732
Validation loss: 2.575025394462622

Epoch: 6| Step: 10
Training loss: 1.9920683582059273
Validation loss: 2.5616467768935856

Epoch: 6| Step: 11
Training loss: 2.366210232182365
Validation loss: 2.562462069843215

Epoch: 6| Step: 12
Training loss: 2.049374750200718
Validation loss: 2.5615571155920427

Epoch: 6| Step: 13
Training loss: 2.134772772746497
Validation loss: 2.547777581545081

Epoch: 292| Step: 0
Training loss: 1.9468801532021989
Validation loss: 2.5557097587732187

Epoch: 6| Step: 1
Training loss: 2.1873820681798652
Validation loss: 2.569524572743993

Epoch: 6| Step: 2
Training loss: 2.316837264258674
Validation loss: 2.5884080132123564

Epoch: 6| Step: 3
Training loss: 1.439526663445491
Validation loss: 2.5938985850966176

Epoch: 6| Step: 4
Training loss: 2.4493592144417793
Validation loss: 2.605366366927959

Epoch: 6| Step: 5
Training loss: 1.9864135843833368
Validation loss: 2.6292491460599714

Epoch: 6| Step: 6
Training loss: 1.3058048420621584
Validation loss: 2.6234791225079817

Epoch: 6| Step: 7
Training loss: 2.199363581765171
Validation loss: 2.6127067964711186

Epoch: 6| Step: 8
Training loss: 2.2559760521774264
Validation loss: 2.6298545876494748

Epoch: 6| Step: 9
Training loss: 2.285103143580293
Validation loss: 2.628300166633387

Epoch: 6| Step: 10
Training loss: 1.9886650509437156
Validation loss: 2.5898258137645227

Epoch: 6| Step: 11
Training loss: 2.2753669442839626
Validation loss: 2.595005620045049

Epoch: 6| Step: 12
Training loss: 2.052276705491567
Validation loss: 2.594069009336224

Epoch: 6| Step: 13
Training loss: 2.6945135286876027
Validation loss: 2.579661040822163

Epoch: 293| Step: 0
Training loss: 2.3105554395115466
Validation loss: 2.5964503039305504

Epoch: 6| Step: 1
Training loss: 2.3679457856879917
Validation loss: 2.6091015838097156

Epoch: 6| Step: 2
Training loss: 1.6149770769317107
Validation loss: 2.5753442892130716

Epoch: 6| Step: 3
Training loss: 2.3548837317985165
Validation loss: 2.607113579705737

Epoch: 6| Step: 4
Training loss: 1.9137423500590847
Validation loss: 2.6124577386531596

Epoch: 6| Step: 5
Training loss: 2.454434865168505
Validation loss: 2.638582346216448

Epoch: 6| Step: 6
Training loss: 2.1258844890991684
Validation loss: 2.6001218027536845

Epoch: 6| Step: 7
Training loss: 1.886288927610644
Validation loss: 2.6021932881572156

Epoch: 6| Step: 8
Training loss: 1.1415736812583852
Validation loss: 2.5984474143708685

Epoch: 6| Step: 9
Training loss: 2.7023438664590986
Validation loss: 2.5959043632900634

Epoch: 6| Step: 10
Training loss: 2.1978417213522676
Validation loss: 2.618750998133406

Epoch: 6| Step: 11
Training loss: 1.9683302174456572
Validation loss: 2.613958646357191

Epoch: 6| Step: 12
Training loss: 1.3818422351060118
Validation loss: 2.622097067811878

Epoch: 6| Step: 13
Training loss: 2.67805088434743
Validation loss: 2.598735017425959

Epoch: 294| Step: 0
Training loss: 1.7229950932738964
Validation loss: 2.617417146087356

Epoch: 6| Step: 1
Training loss: 2.361304195462652
Validation loss: 2.6115783556297503

Epoch: 6| Step: 2
Training loss: 2.2514389523051768
Validation loss: 2.61815501686629

Epoch: 6| Step: 3
Training loss: 1.6239357911462722
Validation loss: 2.5865537863693646

Epoch: 6| Step: 4
Training loss: 2.0864710893271203
Validation loss: 2.6083757234567697

Epoch: 6| Step: 5
Training loss: 1.89539133585654
Validation loss: 2.5935472156351818

Epoch: 6| Step: 6
Training loss: 2.220384452453948
Validation loss: 2.5895644737860173

Epoch: 6| Step: 7
Training loss: 2.81930041976242
Validation loss: 2.593888872710854

Epoch: 6| Step: 8
Training loss: 2.1274624189381446
Validation loss: 2.619802400378667

Epoch: 6| Step: 9
Training loss: 1.5919321201651857
Validation loss: 2.6185857121928287

Epoch: 6| Step: 10
Training loss: 1.9967580984936926
Validation loss: 2.6543315916057684

Epoch: 6| Step: 11
Training loss: 2.334646627410223
Validation loss: 2.6383556719581502

Epoch: 6| Step: 12
Training loss: 1.5138310305692573
Validation loss: 2.6559358897265812

Epoch: 6| Step: 13
Training loss: 2.5259605053844294
Validation loss: 2.673634654240073

Epoch: 295| Step: 0
Training loss: 1.895723388613881
Validation loss: 2.6148604946476035

Epoch: 6| Step: 1
Training loss: 2.4202580129992968
Validation loss: 2.6078762691952866

Epoch: 6| Step: 2
Training loss: 2.0391883080501607
Validation loss: 2.564244816055852

Epoch: 6| Step: 3
Training loss: 1.7731365334986509
Validation loss: 2.5572121653788518

Epoch: 6| Step: 4
Training loss: 2.5681124376299356
Validation loss: 2.5427660570751267

Epoch: 6| Step: 5
Training loss: 1.6894241947938458
Validation loss: 2.5331138373536137

Epoch: 6| Step: 6
Training loss: 2.035941355094861
Validation loss: 2.52831616333186

Epoch: 6| Step: 7
Training loss: 2.1732444562271906
Validation loss: 2.5448052044598293

Epoch: 6| Step: 8
Training loss: 1.5433548456317205
Validation loss: 2.5703776620877887

Epoch: 6| Step: 9
Training loss: 2.3935805855902066
Validation loss: 2.5943826110772314

Epoch: 6| Step: 10
Training loss: 2.2828685296693902
Validation loss: 2.609519436735289

Epoch: 6| Step: 11
Training loss: 2.5341230500053387
Validation loss: 2.639351366464064

Epoch: 6| Step: 12
Training loss: 2.0519522094143565
Validation loss: 2.654299165501564

Epoch: 6| Step: 13
Training loss: 1.8621739710204166
Validation loss: 2.672030260360139

Epoch: 296| Step: 0
Training loss: 1.9633490942736362
Validation loss: 2.701289897261009

Epoch: 6| Step: 1
Training loss: 2.0881007260987157
Validation loss: 2.670237405583048

Epoch: 6| Step: 2
Training loss: 1.3581601995970396
Validation loss: 2.660730928178176

Epoch: 6| Step: 3
Training loss: 2.2431859574600796
Validation loss: 2.6506619484390592

Epoch: 6| Step: 4
Training loss: 2.41758180150492
Validation loss: 2.6279971859363833

Epoch: 6| Step: 5
Training loss: 2.315514223895684
Validation loss: 2.5882527722972974

Epoch: 6| Step: 6
Training loss: 2.6606000398446747
Validation loss: 2.5607645003898165

Epoch: 6| Step: 7
Training loss: 2.2120587097433835
Validation loss: 2.570495428901807

Epoch: 6| Step: 8
Training loss: 1.485070878594713
Validation loss: 2.5581668410245126

Epoch: 6| Step: 9
Training loss: 1.9087617928990641
Validation loss: 2.5569048328037747

Epoch: 6| Step: 10
Training loss: 1.8004450618685606
Validation loss: 2.5743247798063176

Epoch: 6| Step: 11
Training loss: 2.4149600832465774
Validation loss: 2.5379965711269357

Epoch: 6| Step: 12
Training loss: 1.993693422094709
Validation loss: 2.5479391016457185

Epoch: 6| Step: 13
Training loss: 2.285139347894223
Validation loss: 2.5699003327806165

Epoch: 297| Step: 0
Training loss: 2.10835953747695
Validation loss: 2.5757111471669996

Epoch: 6| Step: 1
Training loss: 2.565799356871398
Validation loss: 2.5787159637384467

Epoch: 6| Step: 2
Training loss: 1.8935029375422687
Validation loss: 2.589480628270706

Epoch: 6| Step: 3
Training loss: 2.455400711267525
Validation loss: 2.6173188057979044

Epoch: 6| Step: 4
Training loss: 1.3489241233621627
Validation loss: 2.6314176643455784

Epoch: 6| Step: 5
Training loss: 1.7577678759526814
Validation loss: 2.6249063338870977

Epoch: 6| Step: 6
Training loss: 1.7140459364140306
Validation loss: 2.6145737383135748

Epoch: 6| Step: 7
Training loss: 2.4897905739646795
Validation loss: 2.6166903047243126

Epoch: 6| Step: 8
Training loss: 2.064774270824593
Validation loss: 2.6093297410036107

Epoch: 6| Step: 9
Training loss: 2.2329603932374917
Validation loss: 2.585451539506552

Epoch: 6| Step: 10
Training loss: 1.5444511921519486
Validation loss: 2.5791438545939656

Epoch: 6| Step: 11
Training loss: 2.6238453459987383
Validation loss: 2.5847328814651664

Epoch: 6| Step: 12
Training loss: 2.3496722865382687
Validation loss: 2.603825757918743

Epoch: 6| Step: 13
Training loss: 1.575918033017438
Validation loss: 2.6063891629054448

Epoch: 298| Step: 0
Training loss: 2.3321872575931764
Validation loss: 2.6075744736649664

Epoch: 6| Step: 1
Training loss: 1.7607136838851691
Validation loss: 2.6134874217877293

Epoch: 6| Step: 2
Training loss: 2.418659659973112
Validation loss: 2.621800546721886

Epoch: 6| Step: 3
Training loss: 2.2277989217125267
Validation loss: 2.6337449170633715

Epoch: 6| Step: 4
Training loss: 1.7912988802728587
Validation loss: 2.6163281600414345

Epoch: 6| Step: 5
Training loss: 1.7705230964720542
Validation loss: 2.5795238514592556

Epoch: 6| Step: 6
Training loss: 1.5198885539257048
Validation loss: 2.5814958518423037

Epoch: 6| Step: 7
Training loss: 1.6952468226495425
Validation loss: 2.5787398558808663

Epoch: 6| Step: 8
Training loss: 1.6335719044637191
Validation loss: 2.558456471572688

Epoch: 6| Step: 9
Training loss: 1.6457864134977418
Validation loss: 2.557800690334914

Epoch: 6| Step: 10
Training loss: 2.051007125767717
Validation loss: 2.572942113300053

Epoch: 6| Step: 11
Training loss: 2.2406076853573937
Validation loss: 2.5840379820414903

Epoch: 6| Step: 12
Training loss: 3.228570271864345
Validation loss: 2.5509884464376626

Epoch: 6| Step: 13
Training loss: 2.4172756699285896
Validation loss: 2.61326663740679

Epoch: 299| Step: 0
Training loss: 2.35872383479175
Validation loss: 2.6588877577096683

Epoch: 6| Step: 1
Training loss: 1.9693494822581044
Validation loss: 2.659196214534653

Epoch: 6| Step: 2
Training loss: 2.3528909067786503
Validation loss: 2.665072789298544

Epoch: 6| Step: 3
Training loss: 1.8502843122843042
Validation loss: 2.702123570393837

Epoch: 6| Step: 4
Training loss: 1.8475623076672922
Validation loss: 2.6394768651030422

Epoch: 6| Step: 5
Training loss: 2.0919521071165175
Validation loss: 2.617954122892746

Epoch: 6| Step: 6
Training loss: 1.5102087557407875
Validation loss: 2.601254831627644

Epoch: 6| Step: 7
Training loss: 2.702532752982806
Validation loss: 2.572979580088147

Epoch: 6| Step: 8
Training loss: 1.939355822808581
Validation loss: 2.5664466301205566

Epoch: 6| Step: 9
Training loss: 2.4495794830664024
Validation loss: 2.567047379690885

Epoch: 6| Step: 10
Training loss: 2.3835282048228494
Validation loss: 2.5576962360111426

Epoch: 6| Step: 11
Training loss: 2.2896770394483164
Validation loss: 2.5542466991719723

Epoch: 6| Step: 12
Training loss: 1.5770500223260837
Validation loss: 2.586435583114175

Epoch: 6| Step: 13
Training loss: 2.126118646025842
Validation loss: 2.627194365399452

Epoch: 300| Step: 0
Training loss: 1.3576352617237564
Validation loss: 2.6250724933847267

Epoch: 6| Step: 1
Training loss: 2.14238293714103
Validation loss: 2.6261443867933565

Epoch: 6| Step: 2
Training loss: 2.663433638375981
Validation loss: 2.6084146083767075

Epoch: 6| Step: 3
Training loss: 1.6138569910585328
Validation loss: 2.63641323250475

Epoch: 6| Step: 4
Training loss: 2.213477518984727
Validation loss: 2.605511696922407

Epoch: 6| Step: 5
Training loss: 2.062920151889081
Validation loss: 2.6655388076162088

Epoch: 6| Step: 6
Training loss: 2.5720381581870844
Validation loss: 2.6461443880918143

Epoch: 6| Step: 7
Training loss: 1.9260276033318906
Validation loss: 2.62775601167874

Epoch: 6| Step: 8
Training loss: 1.5768938455502568
Validation loss: 2.6087115238059315

Epoch: 6| Step: 9
Training loss: 2.240619603021525
Validation loss: 2.627865831536559

Epoch: 6| Step: 10
Training loss: 2.152490406613122
Validation loss: 2.5920297670882326

Epoch: 6| Step: 11
Training loss: 2.1349650828166236
Validation loss: 2.5877324968886746

Epoch: 6| Step: 12
Training loss: 2.3412296222180804
Validation loss: 2.56372717028986

Epoch: 6| Step: 13
Training loss: 1.678295463556517
Validation loss: 2.534846737095331

Epoch: 301| Step: 0
Training loss: 1.3025211462841337
Validation loss: 2.516726598173391

Epoch: 6| Step: 1
Training loss: 2.387584073648556
Validation loss: 2.53047400616607

Epoch: 6| Step: 2
Training loss: 2.1058147761809516
Validation loss: 2.5127839973337687

Epoch: 6| Step: 3
Training loss: 1.2657406601038528
Validation loss: 2.5189393918099774

Epoch: 6| Step: 4
Training loss: 2.68152895456672
Validation loss: 2.5201536686279553

Epoch: 6| Step: 5
Training loss: 1.8734969154334553
Validation loss: 2.539297584018988

Epoch: 6| Step: 6
Training loss: 1.4891388592350077
Validation loss: 2.5438760056088094

Epoch: 6| Step: 7
Training loss: 1.4454072663452462
Validation loss: 2.567220588667419

Epoch: 6| Step: 8
Training loss: 2.4894452449111806
Validation loss: 2.565753213061654

Epoch: 6| Step: 9
Training loss: 2.1908439145921528
Validation loss: 2.6245022180666218

Epoch: 6| Step: 10
Training loss: 2.4054690988855705
Validation loss: 2.622172619216684

Epoch: 6| Step: 11
Training loss: 3.0592051317634796
Validation loss: 2.5919630950313777

Epoch: 6| Step: 12
Training loss: 2.2187050828282406
Validation loss: 2.6096371197343617

Epoch: 6| Step: 13
Training loss: 1.7339771948638019
Validation loss: 2.612441417882958

Epoch: 302| Step: 0
Training loss: 2.0748916367880135
Validation loss: 2.6324941893607336

Epoch: 6| Step: 1
Training loss: 2.0249958885998844
Validation loss: 2.6242979715527133

Epoch: 6| Step: 2
Training loss: 1.945566919074407
Validation loss: 2.6386360789105625

Epoch: 6| Step: 3
Training loss: 2.654008166153281
Validation loss: 2.6436968209619933

Epoch: 6| Step: 4
Training loss: 1.3677092074497719
Validation loss: 2.638184934271322

Epoch: 6| Step: 5
Training loss: 2.1664298979675336
Validation loss: 2.658766418463728

Epoch: 6| Step: 6
Training loss: 2.219026037963373
Validation loss: 2.6607184280529066

Epoch: 6| Step: 7
Training loss: 2.026557078828524
Validation loss: 2.620069459984493

Epoch: 6| Step: 8
Training loss: 2.1265681595345107
Validation loss: 2.582985875133293

Epoch: 6| Step: 9
Training loss: 1.714189617551651
Validation loss: 2.53556248369096

Epoch: 6| Step: 10
Training loss: 2.5556068749273675
Validation loss: 2.5366801974937827

Epoch: 6| Step: 11
Training loss: 2.8735689665199753
Validation loss: 2.5437479929873135

Epoch: 6| Step: 12
Training loss: 1.6162312209593903
Validation loss: 2.5411937513379392

Epoch: 6| Step: 13
Training loss: 1.9391932318157012
Validation loss: 2.5427722298296733

Epoch: 303| Step: 0
Training loss: 2.041926685306131
Validation loss: 2.563746157078658

Epoch: 6| Step: 1
Training loss: 1.5330015013476521
Validation loss: 2.5902954597540075

Epoch: 6| Step: 2
Training loss: 2.453885877658888
Validation loss: 2.6407845202535336

Epoch: 6| Step: 3
Training loss: 1.4736571616454655
Validation loss: 2.6532400842395854

Epoch: 6| Step: 4
Training loss: 2.274294766957819
Validation loss: 2.6396201966403035

Epoch: 6| Step: 5
Training loss: 1.9803283762043349
Validation loss: 2.6408989216861345

Epoch: 6| Step: 6
Training loss: 2.1601147501099516
Validation loss: 2.605165089265238

Epoch: 6| Step: 7
Training loss: 1.7071255236678846
Validation loss: 2.5802274666052276

Epoch: 6| Step: 8
Training loss: 2.682482982343322
Validation loss: 2.561786955584404

Epoch: 6| Step: 9
Training loss: 2.1267581846860613
Validation loss: 2.5479209795894806

Epoch: 6| Step: 10
Training loss: 2.138049616060414
Validation loss: 2.566135703835233

Epoch: 6| Step: 11
Training loss: 2.7195080106027754
Validation loss: 2.5467386345738774

Epoch: 6| Step: 12
Training loss: 2.491599464998725
Validation loss: 2.5529383621883657

Epoch: 6| Step: 13
Training loss: 2.0115092048026675
Validation loss: 2.5522174929693717

Epoch: 304| Step: 0
Training loss: 2.0394045955697835
Validation loss: 2.5666997036314605

Epoch: 6| Step: 1
Training loss: 1.6684255934721088
Validation loss: 2.5740733513219944

Epoch: 6| Step: 2
Training loss: 2.0136052147444263
Validation loss: 2.5873432161066585

Epoch: 6| Step: 3
Training loss: 2.2064552838401648
Validation loss: 2.5925135748669366

Epoch: 6| Step: 4
Training loss: 2.177844728145721
Validation loss: 2.5901740061609715

Epoch: 6| Step: 5
Training loss: 2.190932931630012
Validation loss: 2.608692849055226

Epoch: 6| Step: 6
Training loss: 2.2995036128563813
Validation loss: 2.581091143605257

Epoch: 6| Step: 7
Training loss: 2.5999207227798293
Validation loss: 2.610462221101808

Epoch: 6| Step: 8
Training loss: 1.8558959469155558
Validation loss: 2.609400415962993

Epoch: 6| Step: 9
Training loss: 1.845992195865092
Validation loss: 2.6213382658061515

Epoch: 6| Step: 10
Training loss: 2.1543787701172317
Validation loss: 2.596810079253507

Epoch: 6| Step: 11
Training loss: 1.955227445069687
Validation loss: 2.594706852916651

Epoch: 6| Step: 12
Training loss: 2.581467559734751
Validation loss: 2.6140794357112984

Epoch: 6| Step: 13
Training loss: 1.1857312733061982
Validation loss: 2.609907587030381

Epoch: 305| Step: 0
Training loss: 2.1050966178122814
Validation loss: 2.6074824141619204

Epoch: 6| Step: 1
Training loss: 2.500777886485847
Validation loss: 2.5899414688477993

Epoch: 6| Step: 2
Training loss: 2.041881965132581
Validation loss: 2.5867036758147997

Epoch: 6| Step: 3
Training loss: 1.435370235864084
Validation loss: 2.576249089408219

Epoch: 6| Step: 4
Training loss: 2.3028549926332635
Validation loss: 2.5732258959645966

Epoch: 6| Step: 5
Training loss: 1.2116256235369605
Validation loss: 2.5611044564945638

Epoch: 6| Step: 6
Training loss: 2.1243509535566276
Validation loss: 2.5624453686108657

Epoch: 6| Step: 7
Training loss: 1.6832321734609785
Validation loss: 2.555639760270272

Epoch: 6| Step: 8
Training loss: 1.867099265084728
Validation loss: 2.5548796664105042

Epoch: 6| Step: 9
Training loss: 2.6680926047043103
Validation loss: 2.5532751505358906

Epoch: 6| Step: 10
Training loss: 2.20277315400921
Validation loss: 2.5701586707248696

Epoch: 6| Step: 11
Training loss: 2.4217598180145576
Validation loss: 2.5912935275568354

Epoch: 6| Step: 12
Training loss: 1.900978428733801
Validation loss: 2.6139578406707242

Epoch: 6| Step: 13
Training loss: 2.237508856899697
Validation loss: 2.6213392283918906

Epoch: 306| Step: 0
Training loss: 2.3694559942483
Validation loss: 2.6481313913013267

Epoch: 6| Step: 1
Training loss: 1.9359418695014123
Validation loss: 2.633775091741234

Epoch: 6| Step: 2
Training loss: 2.2714618081491325
Validation loss: 2.6411016361362796

Epoch: 6| Step: 3
Training loss: 1.5013224017799454
Validation loss: 2.6363219916334093

Epoch: 6| Step: 4
Training loss: 1.604592931351063
Validation loss: 2.62235500653688

Epoch: 6| Step: 5
Training loss: 2.1484837752473767
Validation loss: 2.6301863238228966

Epoch: 6| Step: 6
Training loss: 1.801047017972228
Validation loss: 2.619703262283502

Epoch: 6| Step: 7
Training loss: 2.048791119556776
Validation loss: 2.6105866350723828

Epoch: 6| Step: 8
Training loss: 1.6924944541986795
Validation loss: 2.579998383792598

Epoch: 6| Step: 9
Training loss: 2.0972248678071415
Validation loss: 2.5800125918463053

Epoch: 6| Step: 10
Training loss: 2.599452907516502
Validation loss: 2.5519411683222164

Epoch: 6| Step: 11
Training loss: 2.0113789391780443
Validation loss: 2.558216779665334

Epoch: 6| Step: 12
Training loss: 2.1197111847116807
Validation loss: 2.567137514828506

Epoch: 6| Step: 13
Training loss: 2.346205785352009
Validation loss: 2.6037650192787187

Epoch: 307| Step: 0
Training loss: 1.6277378932694233
Validation loss: 2.5999685603466154

Epoch: 6| Step: 1
Training loss: 2.6367037398299606
Validation loss: 2.5962259355953283

Epoch: 6| Step: 2
Training loss: 2.440217093206073
Validation loss: 2.5950662574565997

Epoch: 6| Step: 3
Training loss: 1.7272325139178597
Validation loss: 2.587324049245521

Epoch: 6| Step: 4
Training loss: 1.7141789079500114
Validation loss: 2.612754795359027

Epoch: 6| Step: 5
Training loss: 2.4808822167086353
Validation loss: 2.596459134402291

Epoch: 6| Step: 6
Training loss: 1.336672352131067
Validation loss: 2.591893140417989

Epoch: 6| Step: 7
Training loss: 2.368989667619529
Validation loss: 2.5869713567271937

Epoch: 6| Step: 8
Training loss: 1.7889410918907103
Validation loss: 2.5983016663123

Epoch: 6| Step: 9
Training loss: 1.9999789594497182
Validation loss: 2.59031221152683

Epoch: 6| Step: 10
Training loss: 2.058086412371
Validation loss: 2.599620258280812

Epoch: 6| Step: 11
Training loss: 2.2009739757214257
Validation loss: 2.5770880106762992

Epoch: 6| Step: 12
Training loss: 1.9309815920876416
Validation loss: 2.588975671706191

Epoch: 6| Step: 13
Training loss: 2.3219429221814236
Validation loss: 2.5790386700235115

Epoch: 308| Step: 0
Training loss: 2.2202391664017123
Validation loss: 2.579206821537857

Epoch: 6| Step: 1
Training loss: 2.15749511152401
Validation loss: 2.6125058181673575

Epoch: 6| Step: 2
Training loss: 1.1660462955294146
Validation loss: 2.614989037718689

Epoch: 6| Step: 3
Training loss: 2.1668261567126947
Validation loss: 2.6060558841419255

Epoch: 6| Step: 4
Training loss: 2.778381754593017
Validation loss: 2.6277435285940816

Epoch: 6| Step: 5
Training loss: 2.1466429827945435
Validation loss: 2.6813737699904694

Epoch: 6| Step: 6
Training loss: 2.120043752866578
Validation loss: 2.653582194385377

Epoch: 6| Step: 7
Training loss: 2.4883785977327277
Validation loss: 2.652670733859132

Epoch: 6| Step: 8
Training loss: 1.9267740224783783
Validation loss: 2.6635565253957103

Epoch: 6| Step: 9
Training loss: 2.132511215448794
Validation loss: 2.6378975350178204

Epoch: 6| Step: 10
Training loss: 1.8783698000184463
Validation loss: 2.590779499375224

Epoch: 6| Step: 11
Training loss: 2.121746040211993
Validation loss: 2.5728015230388626

Epoch: 6| Step: 12
Training loss: 1.5451945415099229
Validation loss: 2.5615237399998034

Epoch: 6| Step: 13
Training loss: 1.9953805504100188
Validation loss: 2.5311908008575865

Epoch: 309| Step: 0
Training loss: 2.140336734268599
Validation loss: 2.545466089893353

Epoch: 6| Step: 1
Training loss: 1.8428785559951057
Validation loss: 2.537047258399283

Epoch: 6| Step: 2
Training loss: 1.4074072420713168
Validation loss: 2.5261236485552163

Epoch: 6| Step: 3
Training loss: 2.0179033045064103
Validation loss: 2.5213581253542863

Epoch: 6| Step: 4
Training loss: 1.7955766714239847
Validation loss: 2.5391306237105105

Epoch: 6| Step: 5
Training loss: 2.3320185726466556
Validation loss: 2.5225384727747615

Epoch: 6| Step: 6
Training loss: 2.1596498085412428
Validation loss: 2.536327591071579

Epoch: 6| Step: 7
Training loss: 1.5265181473503888
Validation loss: 2.545190203191174

Epoch: 6| Step: 8
Training loss: 2.509384850735646
Validation loss: 2.560388703241404

Epoch: 6| Step: 9
Training loss: 2.142539845544557
Validation loss: 2.586410141207983

Epoch: 6| Step: 10
Training loss: 1.9629489263729782
Validation loss: 2.596761739734474

Epoch: 6| Step: 11
Training loss: 2.255142375401451
Validation loss: 2.608831710754324

Epoch: 6| Step: 12
Training loss: 2.7034620835594594
Validation loss: 2.6265834694803862

Epoch: 6| Step: 13
Training loss: 2.5625532191262863
Validation loss: 2.6292089596917063

Epoch: 310| Step: 0
Training loss: 1.9549830029619484
Validation loss: 2.6450426817673036

Epoch: 6| Step: 1
Training loss: 1.9528434855712793
Validation loss: 2.6204382147266725

Epoch: 6| Step: 2
Training loss: 1.6918856533857984
Validation loss: 2.6298361839167614

Epoch: 6| Step: 3
Training loss: 1.9056695148076852
Validation loss: 2.599941967047529

Epoch: 6| Step: 4
Training loss: 2.4447172860358677
Validation loss: 2.5867666584364675

Epoch: 6| Step: 5
Training loss: 1.5104238400343757
Validation loss: 2.5735673789421325

Epoch: 6| Step: 6
Training loss: 2.3047534997832595
Validation loss: 2.583182781713727

Epoch: 6| Step: 7
Training loss: 2.272197476972266
Validation loss: 2.538312314055645

Epoch: 6| Step: 8
Training loss: 2.5858272286958845
Validation loss: 2.501515771388502

Epoch: 6| Step: 9
Training loss: 2.161838311189814
Validation loss: 2.5112099614234116

Epoch: 6| Step: 10
Training loss: 2.4739520156511987
Validation loss: 2.528447927528045

Epoch: 6| Step: 11
Training loss: 2.145479475553936
Validation loss: 2.5253665664286062

Epoch: 6| Step: 12
Training loss: 1.8643736126415322
Validation loss: 2.551097809337462

Epoch: 6| Step: 13
Training loss: 1.818132658857394
Validation loss: 2.5758117316072595

Epoch: 311| Step: 0
Training loss: 2.072108457827084
Validation loss: 2.6187083214452893

Epoch: 6| Step: 1
Training loss: 2.2362726862669833
Validation loss: 2.634297466230683

Epoch: 6| Step: 2
Training loss: 1.8562989636266702
Validation loss: 2.6464923628607924

Epoch: 6| Step: 3
Training loss: 2.2395625150437444
Validation loss: 2.6385811037855498

Epoch: 6| Step: 4
Training loss: 2.1209367163541333
Validation loss: 2.635419043940702

Epoch: 6| Step: 5
Training loss: 1.8357496449562258
Validation loss: 2.5846165167103896

Epoch: 6| Step: 6
Training loss: 1.8926989317012974
Validation loss: 2.576373081095944

Epoch: 6| Step: 7
Training loss: 1.8682938494269032
Validation loss: 2.5584357215282174

Epoch: 6| Step: 8
Training loss: 1.9479826101744944
Validation loss: 2.5679368129593785

Epoch: 6| Step: 9
Training loss: 1.9727114225924638
Validation loss: 2.557809895036599

Epoch: 6| Step: 10
Training loss: 2.6860423903653037
Validation loss: 2.5982918862721136

Epoch: 6| Step: 11
Training loss: 2.313186749734649
Validation loss: 2.5788875030233718

Epoch: 6| Step: 12
Training loss: 1.9513530169802829
Validation loss: 2.576646731642098

Epoch: 6| Step: 13
Training loss: 2.1013905054212114
Validation loss: 2.574153330101405

Epoch: 312| Step: 0
Training loss: 2.2339354396155593
Validation loss: 2.5468788068934036

Epoch: 6| Step: 1
Training loss: 1.3696890914667532
Validation loss: 2.58310875890687

Epoch: 6| Step: 2
Training loss: 1.9625384114387878
Validation loss: 2.5690828607356604

Epoch: 6| Step: 3
Training loss: 1.9399531431536783
Validation loss: 2.566138498863442

Epoch: 6| Step: 4
Training loss: 2.0106178011778693
Validation loss: 2.5962827794481025

Epoch: 6| Step: 5
Training loss: 1.8091812662560247
Validation loss: 2.5941785282199183

Epoch: 6| Step: 6
Training loss: 1.6674202010292838
Validation loss: 2.58541414587086

Epoch: 6| Step: 7
Training loss: 1.8561920362471245
Validation loss: 2.563726000079093

Epoch: 6| Step: 8
Training loss: 1.88883401831546
Validation loss: 2.5926361143405083

Epoch: 6| Step: 9
Training loss: 2.3156798898057525
Validation loss: 2.586727839816571

Epoch: 6| Step: 10
Training loss: 2.5516905397992287
Validation loss: 2.5959810979269604

Epoch: 6| Step: 11
Training loss: 2.0346069766213835
Validation loss: 2.5538820791671206

Epoch: 6| Step: 12
Training loss: 2.7800973796941495
Validation loss: 2.543917391593919

Epoch: 6| Step: 13
Training loss: 2.0462482453783233
Validation loss: 2.5428165716449875

Epoch: 313| Step: 0
Training loss: 2.4319511245973713
Validation loss: 2.571514045906907

Epoch: 6| Step: 1
Training loss: 2.1562176024725908
Validation loss: 2.5473050571558824

Epoch: 6| Step: 2
Training loss: 2.2545872656099903
Validation loss: 2.548581961367773

Epoch: 6| Step: 3
Training loss: 1.4051208201145062
Validation loss: 2.53907246905595

Epoch: 6| Step: 4
Training loss: 2.2410156164889097
Validation loss: 2.580619298993773

Epoch: 6| Step: 5
Training loss: 1.8395089980846584
Validation loss: 2.5577953150845176

Epoch: 6| Step: 6
Training loss: 2.1225812273242584
Validation loss: 2.5978105006873156

Epoch: 6| Step: 7
Training loss: 1.6045162596147675
Validation loss: 2.5767194750614806

Epoch: 6| Step: 8
Training loss: 2.809067135789097
Validation loss: 2.5945164417494015

Epoch: 6| Step: 9
Training loss: 2.2290152976673596
Validation loss: 2.6163016874648344

Epoch: 6| Step: 10
Training loss: 1.7565646341117813
Validation loss: 2.6148095710616963

Epoch: 6| Step: 11
Training loss: 1.8459836716348232
Validation loss: 2.5993738753229296

Epoch: 6| Step: 12
Training loss: 1.605437192583517
Validation loss: 2.6103180648760835

Epoch: 6| Step: 13
Training loss: 2.0380039317399152
Validation loss: 2.610621955777872

Epoch: 314| Step: 0
Training loss: 2.5055187347631276
Validation loss: 2.556262853663181

Epoch: 6| Step: 1
Training loss: 2.03411733281771
Validation loss: 2.5523274103861264

Epoch: 6| Step: 2
Training loss: 2.2093858429940787
Validation loss: 2.5719236138323764

Epoch: 6| Step: 3
Training loss: 2.0301275820173417
Validation loss: 2.544792400354276

Epoch: 6| Step: 4
Training loss: 1.5849694365193032
Validation loss: 2.53005849793245

Epoch: 6| Step: 5
Training loss: 1.4282044603541755
Validation loss: 2.5382086154340953

Epoch: 6| Step: 6
Training loss: 2.3290271419255566
Validation loss: 2.53963034515637

Epoch: 6| Step: 7
Training loss: 2.3865191536963355
Validation loss: 2.526306222387235

Epoch: 6| Step: 8
Training loss: 2.1404837680086244
Validation loss: 2.542259871459526

Epoch: 6| Step: 9
Training loss: 2.240985401914577
Validation loss: 2.5636576541938467

Epoch: 6| Step: 10
Training loss: 1.3658254759963797
Validation loss: 2.587325078239269

Epoch: 6| Step: 11
Training loss: 1.95040997817043
Validation loss: 2.611851002878921

Epoch: 6| Step: 12
Training loss: 2.5062796878721123
Validation loss: 2.6169920587396103

Epoch: 6| Step: 13
Training loss: 1.7507240296272937
Validation loss: 2.6112221216272165

Epoch: 315| Step: 0
Training loss: 1.8546900349883293
Validation loss: 2.6170184939650167

Epoch: 6| Step: 1
Training loss: 1.5589067723194114
Validation loss: 2.638129008348172

Epoch: 6| Step: 2
Training loss: 2.3255211522926946
Validation loss: 2.6442921322369335

Epoch: 6| Step: 3
Training loss: 2.2721047181657976
Validation loss: 2.6004186336015

Epoch: 6| Step: 4
Training loss: 2.340010240646516
Validation loss: 2.587935145732905

Epoch: 6| Step: 5
Training loss: 1.8763860030316382
Validation loss: 2.599159069883891

Epoch: 6| Step: 6
Training loss: 2.000280956561324
Validation loss: 2.5477836407806875

Epoch: 6| Step: 7
Training loss: 1.5704402586933632
Validation loss: 2.5754638501000553

Epoch: 6| Step: 8
Training loss: 1.8685926951668488
Validation loss: 2.5772078607108853

Epoch: 6| Step: 9
Training loss: 2.727132131102551
Validation loss: 2.57707771068341

Epoch: 6| Step: 10
Training loss: 1.4149482439907854
Validation loss: 2.5844696734860615

Epoch: 6| Step: 11
Training loss: 2.1886023877190532
Validation loss: 2.5821358048300573

Epoch: 6| Step: 12
Training loss: 1.891808824897248
Validation loss: 2.570039265032105

Epoch: 6| Step: 13
Training loss: 2.2864600480637316
Validation loss: 2.5647383427405677

Epoch: 316| Step: 0
Training loss: 2.4317622020309804
Validation loss: 2.599268622722997

Epoch: 6| Step: 1
Training loss: 1.9302607005454762
Validation loss: 2.5711979756325753

Epoch: 6| Step: 2
Training loss: 2.0287319127543997
Validation loss: 2.5930841196325036

Epoch: 6| Step: 3
Training loss: 1.5881713769139432
Validation loss: 2.591344690919048

Epoch: 6| Step: 4
Training loss: 2.1943477805157157
Validation loss: 2.5643676836549547

Epoch: 6| Step: 5
Training loss: 1.687359980672832
Validation loss: 2.597778776333786

Epoch: 6| Step: 6
Training loss: 1.6966077365771248
Validation loss: 2.609001589799823

Epoch: 6| Step: 7
Training loss: 2.1306423003260018
Validation loss: 2.6055908479539385

Epoch: 6| Step: 8
Training loss: 1.1055487613905846
Validation loss: 2.6186708716043454

Epoch: 6| Step: 9
Training loss: 2.0962351384145057
Validation loss: 2.6453414419701082

Epoch: 6| Step: 10
Training loss: 2.1324463694224844
Validation loss: 2.614923786830003

Epoch: 6| Step: 11
Training loss: 2.1391530788907973
Validation loss: 2.582487788311526

Epoch: 6| Step: 12
Training loss: 2.159265482840061
Validation loss: 2.616458483835524

Epoch: 6| Step: 13
Training loss: 2.6199546646971505
Validation loss: 2.603842559990839

Epoch: 317| Step: 0
Training loss: 1.5417984399239113
Validation loss: 2.603499759474059

Epoch: 6| Step: 1
Training loss: 2.3709149615331584
Validation loss: 2.5664664173863367

Epoch: 6| Step: 2
Training loss: 3.0505477288386835
Validation loss: 2.581070329202825

Epoch: 6| Step: 3
Training loss: 1.1454730536739461
Validation loss: 2.5797374653497376

Epoch: 6| Step: 4
Training loss: 1.4513545582354912
Validation loss: 2.527055506750897

Epoch: 6| Step: 5
Training loss: 2.172979389674002
Validation loss: 2.560374331971424

Epoch: 6| Step: 6
Training loss: 2.4929534787314305
Validation loss: 2.5508372138574495

Epoch: 6| Step: 7
Training loss: 1.9803859234406103
Validation loss: 2.567032542614491

Epoch: 6| Step: 8
Training loss: 1.8471827474915998
Validation loss: 2.5747418024184667

Epoch: 6| Step: 9
Training loss: 1.8550501943619464
Validation loss: 2.603800897978312

Epoch: 6| Step: 10
Training loss: 1.9742343142657894
Validation loss: 2.603587190369909

Epoch: 6| Step: 11
Training loss: 2.3834657867901767
Validation loss: 2.5566727665609164

Epoch: 6| Step: 12
Training loss: 1.6510353770171338
Validation loss: 2.5454076897088247

Epoch: 6| Step: 13
Training loss: 2.021628141589098
Validation loss: 2.542206180615635

Epoch: 318| Step: 0
Training loss: 1.8658377265736477
Validation loss: 2.5380537406050485

Epoch: 6| Step: 1
Training loss: 2.0967780464600785
Validation loss: 2.5392766774150686

Epoch: 6| Step: 2
Training loss: 2.3160179803443497
Validation loss: 2.5303334904185184

Epoch: 6| Step: 3
Training loss: 2.1540195151660786
Validation loss: 2.5562575062685866

Epoch: 6| Step: 4
Training loss: 1.9569638786978354
Validation loss: 2.5566760304298994

Epoch: 6| Step: 5
Training loss: 2.2905333288566285
Validation loss: 2.601680871296272

Epoch: 6| Step: 6
Training loss: 2.2102119684190966
Validation loss: 2.6181234024345312

Epoch: 6| Step: 7
Training loss: 1.715541410928656
Validation loss: 2.642280556220471

Epoch: 6| Step: 8
Training loss: 2.208409781902133
Validation loss: 2.6418403071025334

Epoch: 6| Step: 9
Training loss: 1.8636226061463326
Validation loss: 2.5949278152706388

Epoch: 6| Step: 10
Training loss: 1.2790014027669103
Validation loss: 2.5939410342296654

Epoch: 6| Step: 11
Training loss: 1.2297597144127652
Validation loss: 2.5938508653753147

Epoch: 6| Step: 12
Training loss: 2.718133966216673
Validation loss: 2.564705326165096

Epoch: 6| Step: 13
Training loss: 2.2105268225035886
Validation loss: 2.5781106659461845

Epoch: 319| Step: 0
Training loss: 2.158987104850025
Validation loss: 2.531591886814357

Epoch: 6| Step: 1
Training loss: 1.7462324731666734
Validation loss: 2.545887106053369

Epoch: 6| Step: 2
Training loss: 1.4901311796162777
Validation loss: 2.5892477064052244

Epoch: 6| Step: 3
Training loss: 2.2307363907397715
Validation loss: 2.571703185796462

Epoch: 6| Step: 4
Training loss: 2.077665349850461
Validation loss: 2.561001044604709

Epoch: 6| Step: 5
Training loss: 2.058958654617562
Validation loss: 2.5778659343603545

Epoch: 6| Step: 6
Training loss: 1.9185709270204363
Validation loss: 2.5788523563122308

Epoch: 6| Step: 7
Training loss: 2.054176063851404
Validation loss: 2.589234339387595

Epoch: 6| Step: 8
Training loss: 2.4243655289113146
Validation loss: 2.610977837924219

Epoch: 6| Step: 9
Training loss: 1.6579721961732927
Validation loss: 2.647320514642957

Epoch: 6| Step: 10
Training loss: 1.505233535643613
Validation loss: 2.6176716522751584

Epoch: 6| Step: 11
Training loss: 1.5226374946484318
Validation loss: 2.629916461323717

Epoch: 6| Step: 12
Training loss: 2.420045420007629
Validation loss: 2.651206640320318

Epoch: 6| Step: 13
Training loss: 2.440591074845743
Validation loss: 2.601060163936044

Epoch: 320| Step: 0
Training loss: 1.3154662537112136
Validation loss: 2.6030165663074896

Epoch: 6| Step: 1
Training loss: 1.6701240997117879
Validation loss: 2.5930552184010427

Epoch: 6| Step: 2
Training loss: 2.6136109467729334
Validation loss: 2.580822375500821

Epoch: 6| Step: 3
Training loss: 2.3716793939602367
Validation loss: 2.553127780945476

Epoch: 6| Step: 4
Training loss: 2.2970796870158807
Validation loss: 2.5704355567917796

Epoch: 6| Step: 5
Training loss: 2.3569220113301745
Validation loss: 2.534885958314065

Epoch: 6| Step: 6
Training loss: 1.7857074846410665
Validation loss: 2.5819681056963524

Epoch: 6| Step: 7
Training loss: 1.6797229851811282
Validation loss: 2.6033223474623255

Epoch: 6| Step: 8
Training loss: 2.2662004463513843
Validation loss: 2.6177701311043844

Epoch: 6| Step: 9
Training loss: 1.579983061204723
Validation loss: 2.6249242726256594

Epoch: 6| Step: 10
Training loss: 2.524619755582674
Validation loss: 2.6839093462789645

Epoch: 6| Step: 11
Training loss: 1.742410961924768
Validation loss: 2.6570161350369554

Epoch: 6| Step: 12
Training loss: 2.2175648707520716
Validation loss: 2.619668572164939

Epoch: 6| Step: 13
Training loss: 1.7314437978084887
Validation loss: 2.563898906490731

Epoch: 321| Step: 0
Training loss: 1.8772856450544337
Validation loss: 2.5776790657088915

Epoch: 6| Step: 1
Training loss: 2.6354847372760553
Validation loss: 2.541202132710381

Epoch: 6| Step: 2
Training loss: 2.1887884432707865
Validation loss: 2.550024647687086

Epoch: 6| Step: 3
Training loss: 1.974532460753207
Validation loss: 2.545777691005697

Epoch: 6| Step: 4
Training loss: 2.079588066721916
Validation loss: 2.5644201822288295

Epoch: 6| Step: 5
Training loss: 2.0753064078718486
Validation loss: 2.5694875581807177

Epoch: 6| Step: 6
Training loss: 1.963196505726267
Validation loss: 2.6058544691265797

Epoch: 6| Step: 7
Training loss: 1.3693440458976924
Validation loss: 2.6084196584227017

Epoch: 6| Step: 8
Training loss: 1.5250254644550458
Validation loss: 2.629163649164837

Epoch: 6| Step: 9
Training loss: 2.2034087302753904
Validation loss: 2.6343558718408104

Epoch: 6| Step: 10
Training loss: 1.778011925827898
Validation loss: 2.6428055647747426

Epoch: 6| Step: 11
Training loss: 2.08601236387632
Validation loss: 2.6513828490223825

Epoch: 6| Step: 12
Training loss: 2.1387349716006328
Validation loss: 2.6684566589708876

Epoch: 6| Step: 13
Training loss: 2.5087315666764582
Validation loss: 2.6656417267763897

Epoch: 322| Step: 0
Training loss: 1.6832789151047953
Validation loss: 2.6481965141972754

Epoch: 6| Step: 1
Training loss: 1.780665117577084
Validation loss: 2.6602271131729487

Epoch: 6| Step: 2
Training loss: 1.9486784100060686
Validation loss: 2.6002171486871517

Epoch: 6| Step: 3
Training loss: 1.2769629234481823
Validation loss: 2.589752280037795

Epoch: 6| Step: 4
Training loss: 2.1772956440418745
Validation loss: 2.58205064082403

Epoch: 6| Step: 5
Training loss: 2.053614114827123
Validation loss: 2.5535156797763365

Epoch: 6| Step: 6
Training loss: 1.7953164680775746
Validation loss: 2.5594533937004877

Epoch: 6| Step: 7
Training loss: 2.6388467974958867
Validation loss: 2.5387040887860697

Epoch: 6| Step: 8
Training loss: 2.607971910617955
Validation loss: 2.5628573936025463

Epoch: 6| Step: 9
Training loss: 2.4582644522979296
Validation loss: 2.5508343397518822

Epoch: 6| Step: 10
Training loss: 1.6067123608534943
Validation loss: 2.535314977190063

Epoch: 6| Step: 11
Training loss: 1.9261416084543452
Validation loss: 2.588503099815591

Epoch: 6| Step: 12
Training loss: 1.925189254176896
Validation loss: 2.6090249228397693

Epoch: 6| Step: 13
Training loss: 1.9695896598510407
Validation loss: 2.6555225647810565

Epoch: 323| Step: 0
Training loss: 2.0111976911666596
Validation loss: 2.670290114396551

Epoch: 6| Step: 1
Training loss: 1.8470623198912406
Validation loss: 2.6269964013677045

Epoch: 6| Step: 2
Training loss: 1.6512865512680721
Validation loss: 2.629041331024715

Epoch: 6| Step: 3
Training loss: 1.9022035018325545
Validation loss: 2.6226382605971956

Epoch: 6| Step: 4
Training loss: 2.3793774468559907
Validation loss: 2.6353319076558677

Epoch: 6| Step: 5
Training loss: 2.0406929600660613
Validation loss: 2.5936553662053154

Epoch: 6| Step: 6
Training loss: 2.0438509434960603
Validation loss: 2.606410141011175

Epoch: 6| Step: 7
Training loss: 2.3080004657500273
Validation loss: 2.5856714025312026

Epoch: 6| Step: 8
Training loss: 2.015232728150374
Validation loss: 2.576899073270355

Epoch: 6| Step: 9
Training loss: 1.7456676125302004
Validation loss: 2.58912657200128

Epoch: 6| Step: 10
Training loss: 1.4753753895638273
Validation loss: 2.587014395684689

Epoch: 6| Step: 11
Training loss: 2.0566374949896056
Validation loss: 2.5674782598974786

Epoch: 6| Step: 12
Training loss: 2.244422357070733
Validation loss: 2.5936033215087515

Epoch: 6| Step: 13
Training loss: 1.7251222567149853
Validation loss: 2.589455400428419

Epoch: 324| Step: 0
Training loss: 1.8703864239939925
Validation loss: 2.603706034293573

Epoch: 6| Step: 1
Training loss: 1.5601822256371893
Validation loss: 2.6009470657502116

Epoch: 6| Step: 2
Training loss: 2.1627692479445737
Validation loss: 2.601822191933903

Epoch: 6| Step: 3
Training loss: 2.0311744088999637
Validation loss: 2.658632952348502

Epoch: 6| Step: 4
Training loss: 1.8406038111453158
Validation loss: 2.635478465042999

Epoch: 6| Step: 5
Training loss: 1.5146469421182576
Validation loss: 2.618097782778212

Epoch: 6| Step: 6
Training loss: 2.660260661984718
Validation loss: 2.5916474641127376

Epoch: 6| Step: 7
Training loss: 1.5220187892781651
Validation loss: 2.5807903191448553

Epoch: 6| Step: 8
Training loss: 2.0598594639811085
Validation loss: 2.571642793267279

Epoch: 6| Step: 9
Training loss: 2.4541436285503835
Validation loss: 2.5614517207691856

Epoch: 6| Step: 10
Training loss: 1.8702264420191181
Validation loss: 2.54266019590935

Epoch: 6| Step: 11
Training loss: 2.0684206974207533
Validation loss: 2.5670742905386335

Epoch: 6| Step: 12
Training loss: 2.308649517489498
Validation loss: 2.5707676879646266

Epoch: 6| Step: 13
Training loss: 1.7228358860597865
Validation loss: 2.6001980767237396

Epoch: 325| Step: 0
Training loss: 1.2989234831947192
Validation loss: 2.6051885253039337

Epoch: 6| Step: 1
Training loss: 2.2895832185568765
Validation loss: 2.6276745719034236

Epoch: 6| Step: 2
Training loss: 1.650138880924791
Validation loss: 2.621364786050894

Epoch: 6| Step: 3
Training loss: 2.4538414753183284
Validation loss: 2.618552691690147

Epoch: 6| Step: 4
Training loss: 1.893999729120221
Validation loss: 2.618765261475879

Epoch: 6| Step: 5
Training loss: 1.4939930961428944
Validation loss: 2.5845576635751843

Epoch: 6| Step: 6
Training loss: 1.6542860659051386
Validation loss: 2.559164729969017

Epoch: 6| Step: 7
Training loss: 1.827672331756285
Validation loss: 2.568196299975753

Epoch: 6| Step: 8
Training loss: 2.0482855442929515
Validation loss: 2.5436414462709553

Epoch: 6| Step: 9
Training loss: 1.4437876312503897
Validation loss: 2.552223456032823

Epoch: 6| Step: 10
Training loss: 2.5420956379917206
Validation loss: 2.5669101044364635

Epoch: 6| Step: 11
Training loss: 1.9234217800362579
Validation loss: 2.550641323300031

Epoch: 6| Step: 12
Training loss: 2.263975713842229
Validation loss: 2.5518113023748166

Epoch: 6| Step: 13
Training loss: 2.3768524173663854
Validation loss: 2.5920469522265988

Epoch: 326| Step: 0
Training loss: 2.1704105407233913
Validation loss: 2.6099153594960933

Epoch: 6| Step: 1
Training loss: 1.7204966599848555
Validation loss: 2.629795115024212

Epoch: 6| Step: 2
Training loss: 1.6976368523379113
Validation loss: 2.6621774397479827

Epoch: 6| Step: 3
Training loss: 2.2378221077533635
Validation loss: 2.5957239598418047

Epoch: 6| Step: 4
Training loss: 1.6314184635327373
Validation loss: 2.5808476107478238

Epoch: 6| Step: 5
Training loss: 1.7207035406763829
Validation loss: 2.5581890688882956

Epoch: 6| Step: 6
Training loss: 2.3288474786068067
Validation loss: 2.563629149724606

Epoch: 6| Step: 7
Training loss: 1.466345259099738
Validation loss: 2.551699976771144

Epoch: 6| Step: 8
Training loss: 2.7455258820077466
Validation loss: 2.545996079391174

Epoch: 6| Step: 9
Training loss: 1.3927711470749204
Validation loss: 2.5807735748524863

Epoch: 6| Step: 10
Training loss: 2.393815448553501
Validation loss: 2.5622495978601334

Epoch: 6| Step: 11
Training loss: 1.985077981257866
Validation loss: 2.556703578872335

Epoch: 6| Step: 12
Training loss: 2.305415668865378
Validation loss: 2.560598008697378

Epoch: 6| Step: 13
Training loss: 2.059264679936431
Validation loss: 2.575406662455023

Epoch: 327| Step: 0
Training loss: 2.4906923598462507
Validation loss: 2.5936727090985885

Epoch: 6| Step: 1
Training loss: 2.9182668020470106
Validation loss: 2.545152514671176

Epoch: 6| Step: 2
Training loss: 2.1945757189516515
Validation loss: 2.5946669432318767

Epoch: 6| Step: 3
Training loss: 1.7014997934884422
Validation loss: 2.6238821010765196

Epoch: 6| Step: 4
Training loss: 1.5863794922936776
Validation loss: 2.5624279927006692

Epoch: 6| Step: 5
Training loss: 1.9190368785803253
Validation loss: 2.591020273716007

Epoch: 6| Step: 6
Training loss: 2.273374786036311
Validation loss: 2.574435281402009

Epoch: 6| Step: 7
Training loss: 1.7914824132287648
Validation loss: 2.543117184855485

Epoch: 6| Step: 8
Training loss: 1.9979668654366345
Validation loss: 2.5344033556009244

Epoch: 6| Step: 9
Training loss: 1.6179241769233035
Validation loss: 2.5486899463911827

Epoch: 6| Step: 10
Training loss: 1.5985825518500274
Validation loss: 2.5628752007311246

Epoch: 6| Step: 11
Training loss: 1.941479441684962
Validation loss: 2.562045405933236

Epoch: 6| Step: 12
Training loss: 1.52977479212197
Validation loss: 2.537983012463949

Epoch: 6| Step: 13
Training loss: 1.860785069856912
Validation loss: 2.5435553058345337

Epoch: 328| Step: 0
Training loss: 1.5160981059274743
Validation loss: 2.55340411723887

Epoch: 6| Step: 1
Training loss: 1.5686928666490099
Validation loss: 2.5506644580035194

Epoch: 6| Step: 2
Training loss: 1.9327205034718302
Validation loss: 2.557689244790833

Epoch: 6| Step: 3
Training loss: 2.314559431894012
Validation loss: 2.5700302510144812

Epoch: 6| Step: 4
Training loss: 2.801778746055031
Validation loss: 2.620588000832644

Epoch: 6| Step: 5
Training loss: 1.7048345262880868
Validation loss: 2.7152092484078207

Epoch: 6| Step: 6
Training loss: 2.327799831954566
Validation loss: 2.753276765633282

Epoch: 6| Step: 7
Training loss: 2.3229293708853014
Validation loss: 2.7684097207232976

Epoch: 6| Step: 8
Training loss: 1.92826982693078
Validation loss: 2.691381254112392

Epoch: 6| Step: 9
Training loss: 1.745011645062347
Validation loss: 2.6246452091778156

Epoch: 6| Step: 10
Training loss: 1.545430674725557
Validation loss: 2.589131820815834

Epoch: 6| Step: 11
Training loss: 2.411554805619265
Validation loss: 2.544717588737511

Epoch: 6| Step: 12
Training loss: 1.8253191420674768
Validation loss: 2.568414429822733

Epoch: 6| Step: 13
Training loss: 2.0809084958622894
Validation loss: 2.5516656079612976

Epoch: 329| Step: 0
Training loss: 2.3195405954112953
Validation loss: 2.577668313316169

Epoch: 6| Step: 1
Training loss: 1.5416949071960995
Validation loss: 2.5654149572372833

Epoch: 6| Step: 2
Training loss: 1.7793884588763629
Validation loss: 2.56160057379301

Epoch: 6| Step: 3
Training loss: 2.218046049818121
Validation loss: 2.569933135725087

Epoch: 6| Step: 4
Training loss: 2.224371652067387
Validation loss: 2.5536445254071536

Epoch: 6| Step: 5
Training loss: 2.1679073840554826
Validation loss: 2.5493542514289316

Epoch: 6| Step: 6
Training loss: 1.7511888961424276
Validation loss: 2.5678614995641427

Epoch: 6| Step: 7
Training loss: 2.683741403040911
Validation loss: 2.598407577431056

Epoch: 6| Step: 8
Training loss: 1.5648786368554426
Validation loss: 2.6369657348997966

Epoch: 6| Step: 9
Training loss: 2.1003559719105316
Validation loss: 2.6830438441939304

Epoch: 6| Step: 10
Training loss: 1.953514243439886
Validation loss: 2.68707442055946

Epoch: 6| Step: 11
Training loss: 1.7954788755078739
Validation loss: 2.694846675996034

Epoch: 6| Step: 12
Training loss: 2.2956757820841673
Validation loss: 2.642875119004551

Epoch: 6| Step: 13
Training loss: 2.7547155178676985
Validation loss: 2.5861128856116995

Epoch: 330| Step: 0
Training loss: 1.5335255277814255
Validation loss: 2.599373248558986

Epoch: 6| Step: 1
Training loss: 1.6376521469369083
Validation loss: 2.5631290997157143

Epoch: 6| Step: 2
Training loss: 1.9943625152015407
Validation loss: 2.54391849281588

Epoch: 6| Step: 3
Training loss: 2.0157426903246884
Validation loss: 2.5497473996779982

Epoch: 6| Step: 4
Training loss: 1.6673136011857808
Validation loss: 2.55861744954633

Epoch: 6| Step: 5
Training loss: 1.9027573529498478
Validation loss: 2.5921357045240585

Epoch: 6| Step: 6
Training loss: 1.7868301256808863
Validation loss: 2.6014618419767035

Epoch: 6| Step: 7
Training loss: 1.2034839243367919
Validation loss: 2.6044022695140416

Epoch: 6| Step: 8
Training loss: 1.6193592765984088
Validation loss: 2.583883093715765

Epoch: 6| Step: 9
Training loss: 1.4642449948168481
Validation loss: 2.6710363190910837

Epoch: 6| Step: 10
Training loss: 2.0333543880602436
Validation loss: 2.6255058981822477

Epoch: 6| Step: 11
Training loss: 2.671814321085472
Validation loss: 2.643756491891332

Epoch: 6| Step: 12
Training loss: 2.728400979606476
Validation loss: 2.639553191131572

Epoch: 6| Step: 13
Training loss: 2.753009882933104
Validation loss: 2.6386779438723615

Epoch: 331| Step: 0
Training loss: 1.3191975959401985
Validation loss: 2.6592910263245404

Epoch: 6| Step: 1
Training loss: 1.5972332755918013
Validation loss: 2.637578798536178

Epoch: 6| Step: 2
Training loss: 2.036860771773286
Validation loss: 2.6166224234985367

Epoch: 6| Step: 3
Training loss: 2.2188131833818328
Validation loss: 2.6070653626432923

Epoch: 6| Step: 4
Training loss: 2.5060359568531765
Validation loss: 2.5756750006027667

Epoch: 6| Step: 5
Training loss: 2.471434377179938
Validation loss: 2.5613872624223313

Epoch: 6| Step: 6
Training loss: 1.7667656648836643
Validation loss: 2.5413817626448862

Epoch: 6| Step: 7
Training loss: 2.232395602494683
Validation loss: 2.553604487479202

Epoch: 6| Step: 8
Training loss: 2.291714742907613
Validation loss: 2.546652817347285

Epoch: 6| Step: 9
Training loss: 1.700950844702024
Validation loss: 2.570676876317257

Epoch: 6| Step: 10
Training loss: 1.7203907850922058
Validation loss: 2.616709894280837

Epoch: 6| Step: 11
Training loss: 1.9500152244951678
Validation loss: 2.618912328697827

Epoch: 6| Step: 12
Training loss: 1.7727357257294691
Validation loss: 2.55300907290488

Epoch: 6| Step: 13
Training loss: 2.433620593564332
Validation loss: 2.5879976915008216

Epoch: 332| Step: 0
Training loss: 2.200727416203767
Validation loss: 2.563095132212982

Epoch: 6| Step: 1
Training loss: 1.7800669171045558
Validation loss: 2.5660614138117452

Epoch: 6| Step: 2
Training loss: 1.277342163458256
Validation loss: 2.5742297869355504

Epoch: 6| Step: 3
Training loss: 1.8401441065706723
Validation loss: 2.5588726949664773

Epoch: 6| Step: 4
Training loss: 1.400750320186711
Validation loss: 2.549161746429886

Epoch: 6| Step: 5
Training loss: 2.2920595930384424
Validation loss: 2.5614570573201414

Epoch: 6| Step: 6
Training loss: 2.7725433197627294
Validation loss: 2.543765605844276

Epoch: 6| Step: 7
Training loss: 2.266655312771504
Validation loss: 2.570613669517249

Epoch: 6| Step: 8
Training loss: 1.8762412095546976
Validation loss: 2.5917684346995626

Epoch: 6| Step: 9
Training loss: 1.8535166540434447
Validation loss: 2.6155559711470375

Epoch: 6| Step: 10
Training loss: 1.6703224460173651
Validation loss: 2.6262897925529805

Epoch: 6| Step: 11
Training loss: 1.7552108160920135
Validation loss: 2.6718888012862365

Epoch: 6| Step: 12
Training loss: 2.167841067291578
Validation loss: 2.62448746355071

Epoch: 6| Step: 13
Training loss: 2.2221895877773075
Validation loss: 2.6246253457718747

Epoch: 333| Step: 0
Training loss: 1.7253336265913544
Validation loss: 2.629294787598641

Epoch: 6| Step: 1
Training loss: 2.4812654432301406
Validation loss: 2.6264079269139664

Epoch: 6| Step: 2
Training loss: 2.4082855928258486
Validation loss: 2.60823256406633

Epoch: 6| Step: 3
Training loss: 1.3554061743283936
Validation loss: 2.5617643711549047

Epoch: 6| Step: 4
Training loss: 1.3560175155869985
Validation loss: 2.5693603576327066

Epoch: 6| Step: 5
Training loss: 1.6145289586253155
Validation loss: 2.5650137535207347

Epoch: 6| Step: 6
Training loss: 1.9476739116775292
Validation loss: 2.5528406745164367

Epoch: 6| Step: 7
Training loss: 1.6889487511429786
Validation loss: 2.522344346551187

Epoch: 6| Step: 8
Training loss: 2.842044528513018
Validation loss: 2.5693933685197954

Epoch: 6| Step: 9
Training loss: 1.934566430401361
Validation loss: 2.5656859123876354

Epoch: 6| Step: 10
Training loss: 1.3898205091003186
Validation loss: 2.5566035404726217

Epoch: 6| Step: 11
Training loss: 2.3644559604659916
Validation loss: 2.5578615339640223

Epoch: 6| Step: 12
Training loss: 1.811255981772413
Validation loss: 2.5634322137780847

Epoch: 6| Step: 13
Training loss: 1.9125309012914733
Validation loss: 2.6042985094392495

Epoch: 334| Step: 0
Training loss: 2.128304100622503
Validation loss: 2.5821229550018563

Epoch: 6| Step: 1
Training loss: 2.0317026660954083
Validation loss: 2.6341288489676553

Epoch: 6| Step: 2
Training loss: 1.961646935756158
Validation loss: 2.586604928266325

Epoch: 6| Step: 3
Training loss: 1.9151402144730603
Validation loss: 2.5872746724227604

Epoch: 6| Step: 4
Training loss: 1.5550514446960413
Validation loss: 2.5777472171077207

Epoch: 6| Step: 5
Training loss: 2.198185788231404
Validation loss: 2.5553571968450544

Epoch: 6| Step: 6
Training loss: 2.211190468702186
Validation loss: 2.5758557592045355

Epoch: 6| Step: 7
Training loss: 2.2746363883729424
Validation loss: 2.576544398515454

Epoch: 6| Step: 8
Training loss: 1.5559145431832324
Validation loss: 2.574097541267074

Epoch: 6| Step: 9
Training loss: 1.3750931968315945
Validation loss: 2.5795692174894262

Epoch: 6| Step: 10
Training loss: 2.633816038226241
Validation loss: 2.560246756254439

Epoch: 6| Step: 11
Training loss: 1.6229451465515432
Validation loss: 2.571811899590739

Epoch: 6| Step: 12
Training loss: 1.9596241964397083
Validation loss: 2.5836179843070135

Epoch: 6| Step: 13
Training loss: 1.3621594642157187
Validation loss: 2.5757138469540415

Epoch: 335| Step: 0
Training loss: 1.91777463346297
Validation loss: 2.5690749028666735

Epoch: 6| Step: 1
Training loss: 2.0056515950989224
Validation loss: 2.6186035880081486

Epoch: 6| Step: 2
Training loss: 1.9332855903825261
Validation loss: 2.5774931239280905

Epoch: 6| Step: 3
Training loss: 1.3363482641304376
Validation loss: 2.5936566071759124

Epoch: 6| Step: 4
Training loss: 2.2791732323067877
Validation loss: 2.5738618069720776

Epoch: 6| Step: 5
Training loss: 1.7325738025265105
Validation loss: 2.5636299247279615

Epoch: 6| Step: 6
Training loss: 2.4266481677946703
Validation loss: 2.5641081811158695

Epoch: 6| Step: 7
Training loss: 2.010077123348525
Validation loss: 2.5592891611959425

Epoch: 6| Step: 8
Training loss: 2.216332959269982
Validation loss: 2.5428141963497244

Epoch: 6| Step: 9
Training loss: 1.7025705537446945
Validation loss: 2.5382436047994483

Epoch: 6| Step: 10
Training loss: 2.6931112395045895
Validation loss: 2.5502028147756133

Epoch: 6| Step: 11
Training loss: 1.7858307146535886
Validation loss: 2.559292833176061

Epoch: 6| Step: 12
Training loss: 1.2488509619053347
Validation loss: 2.5915736370827913

Epoch: 6| Step: 13
Training loss: 1.1827573433315266
Validation loss: 2.598736408877617

Epoch: 336| Step: 0
Training loss: 1.51754693940669
Validation loss: 2.618978633322992

Epoch: 6| Step: 1
Training loss: 1.6642436613948084
Validation loss: 2.6057024483483553

Epoch: 6| Step: 2
Training loss: 1.4209844294479517
Validation loss: 2.5866169416262483

Epoch: 6| Step: 3
Training loss: 2.205650343194017
Validation loss: 2.57765958033624

Epoch: 6| Step: 4
Training loss: 1.7304805987708063
Validation loss: 2.590659387572712

Epoch: 6| Step: 5
Training loss: 2.5767086878216854
Validation loss: 2.594494494482504

Epoch: 6| Step: 6
Training loss: 2.085093581114381
Validation loss: 2.56646093642189

Epoch: 6| Step: 7
Training loss: 1.8851636713342705
Validation loss: 2.555682300681842

Epoch: 6| Step: 8
Training loss: 1.7533890741188214
Validation loss: 2.5454807170486475

Epoch: 6| Step: 9
Training loss: 1.3113502734657236
Validation loss: 2.567686337472873

Epoch: 6| Step: 10
Training loss: 2.355065863269415
Validation loss: 2.5296754295998922

Epoch: 6| Step: 11
Training loss: 2.291948497666252
Validation loss: 2.5459001699894612

Epoch: 6| Step: 12
Training loss: 1.551427672829251
Validation loss: 2.559001923051921

Epoch: 6| Step: 13
Training loss: 1.9946887302648881
Validation loss: 2.5746397408375206

Epoch: 337| Step: 0
Training loss: 2.3651077652426196
Validation loss: 2.6068294999986854

Epoch: 6| Step: 1
Training loss: 2.4864147138238772
Validation loss: 2.6429824237881347

Epoch: 6| Step: 2
Training loss: 2.1938104344056106
Validation loss: 2.6972030422455466

Epoch: 6| Step: 3
Training loss: 1.7550701535975912
Validation loss: 2.6892517723665623

Epoch: 6| Step: 4
Training loss: 1.865270931824352
Validation loss: 2.667919420984306

Epoch: 6| Step: 5
Training loss: 1.3493010724989536
Validation loss: 2.6324494259629345

Epoch: 6| Step: 6
Training loss: 1.6524583853417474
Validation loss: 2.585360075530819

Epoch: 6| Step: 7
Training loss: 2.121299663405171
Validation loss: 2.5248658475080608

Epoch: 6| Step: 8
Training loss: 1.7658671660315328
Validation loss: 2.555201028740062

Epoch: 6| Step: 9
Training loss: 1.2797548828270313
Validation loss: 2.533630429172058

Epoch: 6| Step: 10
Training loss: 2.479828903695084
Validation loss: 2.544199952641777

Epoch: 6| Step: 11
Training loss: 2.3653027172594427
Validation loss: 2.5388711867027185

Epoch: 6| Step: 12
Training loss: 1.3382577656891694
Validation loss: 2.518979097332863

Epoch: 6| Step: 13
Training loss: 1.6637410314534595
Validation loss: 2.5296165313410555

Epoch: 338| Step: 0
Training loss: 2.3796217269975144
Validation loss: 2.5413040204677593

Epoch: 6| Step: 1
Training loss: 1.5908454157731973
Validation loss: 2.541267337592946

Epoch: 6| Step: 2
Training loss: 2.000115152858661
Validation loss: 2.6046432415078327

Epoch: 6| Step: 3
Training loss: 2.2970108718647997
Validation loss: 2.6038677247443447

Epoch: 6| Step: 4
Training loss: 1.7903053597567389
Validation loss: 2.6196079733261968

Epoch: 6| Step: 5
Training loss: 1.9559509585030734
Validation loss: 2.6457501095476164

Epoch: 6| Step: 6
Training loss: 2.1050012525976083
Validation loss: 2.6398126379631197

Epoch: 6| Step: 7
Training loss: 1.6948422953290896
Validation loss: 2.6270737706574283

Epoch: 6| Step: 8
Training loss: 1.3913638691603014
Validation loss: 2.5889103484276235

Epoch: 6| Step: 9
Training loss: 1.7039794178556942
Validation loss: 2.58625840638191

Epoch: 6| Step: 10
Training loss: 1.714424029798937
Validation loss: 2.5745822647898375

Epoch: 6| Step: 11
Training loss: 2.397487688400909
Validation loss: 2.5735780017871135

Epoch: 6| Step: 12
Training loss: 2.0617443203108343
Validation loss: 2.5624891451473917

Epoch: 6| Step: 13
Training loss: 1.96724298109576
Validation loss: 2.547397006158137

Epoch: 339| Step: 0
Training loss: 2.0386421091801545
Validation loss: 2.525564905118925

Epoch: 6| Step: 1
Training loss: 2.1323482022029685
Validation loss: 2.5402020445261178

Epoch: 6| Step: 2
Training loss: 2.257404858177989
Validation loss: 2.512658876168972

Epoch: 6| Step: 3
Training loss: 2.2397467856679496
Validation loss: 2.5152004507634276

Epoch: 6| Step: 4
Training loss: 2.06080257040598
Validation loss: 2.5290959301713323

Epoch: 6| Step: 5
Training loss: 1.5276056635845283
Validation loss: 2.558213098374239

Epoch: 6| Step: 6
Training loss: 1.5218126288132767
Validation loss: 2.5527756718527828

Epoch: 6| Step: 7
Training loss: 2.036874115654893
Validation loss: 2.5830111969298875

Epoch: 6| Step: 8
Training loss: 1.896259267001055
Validation loss: 2.578974242933381

Epoch: 6| Step: 9
Training loss: 1.9017023340747987
Validation loss: 2.5607912057112836

Epoch: 6| Step: 10
Training loss: 1.516701935089078
Validation loss: 2.5458238612954536

Epoch: 6| Step: 11
Training loss: 1.8774169602805402
Validation loss: 2.528204337542432

Epoch: 6| Step: 12
Training loss: 1.9350669104074687
Validation loss: 2.5165214599840353

Epoch: 6| Step: 13
Training loss: 1.776340008360484
Validation loss: 2.5250429414175923

Epoch: 340| Step: 0
Training loss: 2.0676759449866804
Validation loss: 2.5347346899228205

Epoch: 6| Step: 1
Training loss: 1.6098605414226381
Validation loss: 2.5431318802083065

Epoch: 6| Step: 2
Training loss: 1.6572484299897867
Validation loss: 2.547094277145644

Epoch: 6| Step: 3
Training loss: 2.269043441585248
Validation loss: 2.578549575524366

Epoch: 6| Step: 4
Training loss: 2.0889039395288385
Validation loss: 2.5948050777456775

Epoch: 6| Step: 5
Training loss: 2.1009938204500593
Validation loss: 2.606406451560049

Epoch: 6| Step: 6
Training loss: 2.0104566448235914
Validation loss: 2.604414742415788

Epoch: 6| Step: 7
Training loss: 1.4667089362266728
Validation loss: 2.5888498507868563

Epoch: 6| Step: 8
Training loss: 1.5890284891905584
Validation loss: 2.5610092447847124

Epoch: 6| Step: 9
Training loss: 2.1553645873056895
Validation loss: 2.565949932157007

Epoch: 6| Step: 10
Training loss: 1.680593982323765
Validation loss: 2.553670542721466

Epoch: 6| Step: 11
Training loss: 1.707270345812697
Validation loss: 2.566434212681806

Epoch: 6| Step: 12
Training loss: 2.070617538148542
Validation loss: 2.534365412595577

Epoch: 6| Step: 13
Training loss: 2.070534517871476
Validation loss: 2.531930784817658

Epoch: 341| Step: 0
Training loss: 1.5323768673291145
Validation loss: 2.559508259727076

Epoch: 6| Step: 1
Training loss: 2.2484806016895758
Validation loss: 2.5438054159190804

Epoch: 6| Step: 2
Training loss: 1.7989185157290783
Validation loss: 2.561569153347095

Epoch: 6| Step: 3
Training loss: 1.4505082226335748
Validation loss: 2.566419395285375

Epoch: 6| Step: 4
Training loss: 2.559280047209837
Validation loss: 2.602937153804346

Epoch: 6| Step: 5
Training loss: 1.9220573524865376
Validation loss: 2.6380572503235213

Epoch: 6| Step: 6
Training loss: 2.4577096266415848
Validation loss: 2.668406624185579

Epoch: 6| Step: 7
Training loss: 1.650602537014582
Validation loss: 2.642802482454583

Epoch: 6| Step: 8
Training loss: 1.9801756512150424
Validation loss: 2.6392171142529692

Epoch: 6| Step: 9
Training loss: 1.660781634850475
Validation loss: 2.598371394867385

Epoch: 6| Step: 10
Training loss: 1.4675456039647239
Validation loss: 2.5746208806861914

Epoch: 6| Step: 11
Training loss: 1.7403480843707528
Validation loss: 2.570086692468543

Epoch: 6| Step: 12
Training loss: 2.2450511336928405
Validation loss: 2.557245737091956

Epoch: 6| Step: 13
Training loss: 1.9786516690718334
Validation loss: 2.5459959857466528

Epoch: 342| Step: 0
Training loss: 2.3136397980877255
Validation loss: 2.561154787792644

Epoch: 6| Step: 1
Training loss: 2.098716198102016
Validation loss: 2.5698978820135365

Epoch: 6| Step: 2
Training loss: 1.471367552929865
Validation loss: 2.566161772581232

Epoch: 6| Step: 3
Training loss: 2.4130151939751605
Validation loss: 2.6021038939307886

Epoch: 6| Step: 4
Training loss: 2.2436692927304596
Validation loss: 2.604667178057362

Epoch: 6| Step: 5
Training loss: 1.6386169497136278
Validation loss: 2.621776774176386

Epoch: 6| Step: 6
Training loss: 1.4679583587197496
Validation loss: 2.5570437796122856

Epoch: 6| Step: 7
Training loss: 1.6560154874786912
Validation loss: 2.552588406363476

Epoch: 6| Step: 8
Training loss: 1.7998826439005893
Validation loss: 2.53471311860794

Epoch: 6| Step: 9
Training loss: 1.9105656035040954
Validation loss: 2.5253772818834146

Epoch: 6| Step: 10
Training loss: 2.1226854622087012
Validation loss: 2.5155428602499614

Epoch: 6| Step: 11
Training loss: 1.2591643088567148
Validation loss: 2.5096822009835984

Epoch: 6| Step: 12
Training loss: 1.8575177574079051
Validation loss: 2.5246130662564803

Epoch: 6| Step: 13
Training loss: 2.656325574809535
Validation loss: 2.523465836467235

Epoch: 343| Step: 0
Training loss: 2.0186566168855347
Validation loss: 2.5112304924852347

Epoch: 6| Step: 1
Training loss: 2.5910913100648356
Validation loss: 2.526502686474523

Epoch: 6| Step: 2
Training loss: 2.0179454842000486
Validation loss: 2.5567372194309352

Epoch: 6| Step: 3
Training loss: 1.744924883714981
Validation loss: 2.616581663545

Epoch: 6| Step: 4
Training loss: 1.5576710658785113
Validation loss: 2.6101117949823354

Epoch: 6| Step: 5
Training loss: 2.3509171826611515
Validation loss: 2.5928695593842757

Epoch: 6| Step: 6
Training loss: 1.980424387658808
Validation loss: 2.5815192949587544

Epoch: 6| Step: 7
Training loss: 1.6026423093835291
Validation loss: 2.56555640144035

Epoch: 6| Step: 8
Training loss: 2.1300446712483923
Validation loss: 2.5246767872710847

Epoch: 6| Step: 9
Training loss: 2.01555083382355
Validation loss: 2.530619346484835

Epoch: 6| Step: 10
Training loss: 2.39386166145306
Validation loss: 2.50400560869253

Epoch: 6| Step: 11
Training loss: 1.5996682478768467
Validation loss: 2.533401469728136

Epoch: 6| Step: 12
Training loss: 1.3011824988484315
Validation loss: 2.529527635492624

Epoch: 6| Step: 13
Training loss: 1.877914008096433
Validation loss: 2.574150983722104

Epoch: 344| Step: 0
Training loss: 1.7588512826914173
Validation loss: 2.5515214548043055

Epoch: 6| Step: 1
Training loss: 2.125948077367162
Validation loss: 2.5696601851564624

Epoch: 6| Step: 2
Training loss: 2.182986152748299
Validation loss: 2.5716925165785374

Epoch: 6| Step: 3
Training loss: 1.0368196186821819
Validation loss: 2.5749787061236753

Epoch: 6| Step: 4
Training loss: 2.372633507914448
Validation loss: 2.583909575479482

Epoch: 6| Step: 5
Training loss: 2.0151553530948756
Validation loss: 2.614677842903016

Epoch: 6| Step: 6
Training loss: 1.773568035144653
Validation loss: 2.6116553068086388

Epoch: 6| Step: 7
Training loss: 1.674634776936051
Validation loss: 2.559407671113206

Epoch: 6| Step: 8
Training loss: 1.8615084037457865
Validation loss: 2.5312171902512093

Epoch: 6| Step: 9
Training loss: 1.8097210989566628
Validation loss: 2.5346013477251117

Epoch: 6| Step: 10
Training loss: 2.4870608224828366
Validation loss: 2.5457034156435845

Epoch: 6| Step: 11
Training loss: 2.1507716590564967
Validation loss: 2.552088528582417

Epoch: 6| Step: 12
Training loss: 1.5584551527309762
Validation loss: 2.5463260144769673

Epoch: 6| Step: 13
Training loss: 2.3140946122645287
Validation loss: 2.560199138773743

Epoch: 345| Step: 0
Training loss: 1.8270033305220792
Validation loss: 2.6101698207416804

Epoch: 6| Step: 1
Training loss: 2.644366621248968
Validation loss: 2.648420665766235

Epoch: 6| Step: 2
Training loss: 2.4561396256125487
Validation loss: 2.7307705764691423

Epoch: 6| Step: 3
Training loss: 1.7063577750685421
Validation loss: 2.796868905002197

Epoch: 6| Step: 4
Training loss: 2.008262257353736
Validation loss: 2.773107518010679

Epoch: 6| Step: 5
Training loss: 1.410708755082228
Validation loss: 2.686965563959595

Epoch: 6| Step: 6
Training loss: 2.0356100385547675
Validation loss: 2.577018978350498

Epoch: 6| Step: 7
Training loss: 1.4357205032913498
Validation loss: 2.568410662584996

Epoch: 6| Step: 8
Training loss: 1.4679785792583544
Validation loss: 2.5774122389594893

Epoch: 6| Step: 9
Training loss: 2.098714948478483
Validation loss: 2.569384792998666

Epoch: 6| Step: 10
Training loss: 2.2034856622799457
Validation loss: 2.576684368174729

Epoch: 6| Step: 11
Training loss: 1.5996312849060395
Validation loss: 2.5752911801191125

Epoch: 6| Step: 12
Training loss: 2.1108199080461842
Validation loss: 2.555199372537242

Epoch: 6| Step: 13
Training loss: 2.275689022815827
Validation loss: 2.5769819018160556

Epoch: 346| Step: 0
Training loss: 1.6807313026751158
Validation loss: 2.5307433637801884

Epoch: 6| Step: 1
Training loss: 1.232992146098051
Validation loss: 2.5679635210625196

Epoch: 6| Step: 2
Training loss: 1.7579648778355872
Validation loss: 2.6035330243112336

Epoch: 6| Step: 3
Training loss: 2.191390800761607
Validation loss: 2.6149219405131214

Epoch: 6| Step: 4
Training loss: 1.9061468753123567
Validation loss: 2.6348078078429595

Epoch: 6| Step: 5
Training loss: 1.9540177403077117
Validation loss: 2.6214598747256366

Epoch: 6| Step: 6
Training loss: 1.7809501529424188
Validation loss: 2.6241367525261436

Epoch: 6| Step: 7
Training loss: 1.4910739918238893
Validation loss: 2.5839904646682776

Epoch: 6| Step: 8
Training loss: 2.6171335698734586
Validation loss: 2.618465115537036

Epoch: 6| Step: 9
Training loss: 2.293279935396258
Validation loss: 2.593596947991648

Epoch: 6| Step: 10
Training loss: 1.5104127905784945
Validation loss: 2.5944909412438837

Epoch: 6| Step: 11
Training loss: 1.8351805729591901
Validation loss: 2.568539379856382

Epoch: 6| Step: 12
Training loss: 1.3543060328831646
Validation loss: 2.5640131351880373

Epoch: 6| Step: 13
Training loss: 2.3698384262893386
Validation loss: 2.5495205656021294

Epoch: 347| Step: 0
Training loss: 1.762122740173731
Validation loss: 2.556336379204547

Epoch: 6| Step: 1
Training loss: 1.0168565179403128
Validation loss: 2.574810957527836

Epoch: 6| Step: 2
Training loss: 2.4652351757780253
Validation loss: 2.6299108708439864

Epoch: 6| Step: 3
Training loss: 1.836573583917695
Validation loss: 2.6190820469802176

Epoch: 6| Step: 4
Training loss: 2.1164202549197477
Validation loss: 2.6253423467555326

Epoch: 6| Step: 5
Training loss: 2.185778021840392
Validation loss: 2.6212823063756443

Epoch: 6| Step: 6
Training loss: 1.5594900513062888
Validation loss: 2.6170595963382515

Epoch: 6| Step: 7
Training loss: 2.065081743372771
Validation loss: 2.605709021001989

Epoch: 6| Step: 8
Training loss: 1.556591305974516
Validation loss: 2.5568992847205356

Epoch: 6| Step: 9
Training loss: 1.597102509955804
Validation loss: 2.5749210833212413

Epoch: 6| Step: 10
Training loss: 1.5668030043724381
Validation loss: 2.5724826606287228

Epoch: 6| Step: 11
Training loss: 2.4136546756485338
Validation loss: 2.5892463328744473

Epoch: 6| Step: 12
Training loss: 1.8197745645727903
Validation loss: 2.5790792221340113

Epoch: 6| Step: 13
Training loss: 1.426246964153031
Validation loss: 2.572578722012197

Epoch: 348| Step: 0
Training loss: 1.2603346374973778
Validation loss: 2.5678100926867393

Epoch: 6| Step: 1
Training loss: 1.8529775499732737
Validation loss: 2.561665034528356

Epoch: 6| Step: 2
Training loss: 1.801872799726791
Validation loss: 2.5660992597954273

Epoch: 6| Step: 3
Training loss: 2.075794490704501
Validation loss: 2.5646576985026464

Epoch: 6| Step: 4
Training loss: 1.2461173793740703
Validation loss: 2.5611282026263513

Epoch: 6| Step: 5
Training loss: 1.5312132539038004
Validation loss: 2.5676932705223967

Epoch: 6| Step: 6
Training loss: 1.7018890095616397
Validation loss: 2.550919844954819

Epoch: 6| Step: 7
Training loss: 1.3779174890660886
Validation loss: 2.5833554472028055

Epoch: 6| Step: 8
Training loss: 1.926764370751953
Validation loss: 2.559302405141752

Epoch: 6| Step: 9
Training loss: 2.0828931216227864
Validation loss: 2.5476210112027258

Epoch: 6| Step: 10
Training loss: 2.0199588050040957
Validation loss: 2.5723125402313674

Epoch: 6| Step: 11
Training loss: 2.1503684504419818
Validation loss: 2.5945059888697943

Epoch: 6| Step: 12
Training loss: 2.652991147029066
Validation loss: 2.6141472005641235

Epoch: 6| Step: 13
Training loss: 1.5953951553617396
Validation loss: 2.6331713966684336

Epoch: 349| Step: 0
Training loss: 1.859306911215573
Validation loss: 2.6444278999242052

Epoch: 6| Step: 1
Training loss: 1.6346749812693095
Validation loss: 2.6129262518662584

Epoch: 6| Step: 2
Training loss: 2.338003616343264
Validation loss: 2.5783349462239853

Epoch: 6| Step: 3
Training loss: 2.002450276494466
Validation loss: 2.5394810727700885

Epoch: 6| Step: 4
Training loss: 2.295473774229418
Validation loss: 2.573342451522498

Epoch: 6| Step: 5
Training loss: 1.485621440981083
Validation loss: 2.5595362046196155

Epoch: 6| Step: 6
Training loss: 2.2597073849992864
Validation loss: 2.5407874718173438

Epoch: 6| Step: 7
Training loss: 2.154177125454077
Validation loss: 2.527039231945211

Epoch: 6| Step: 8
Training loss: 1.3990612663449353
Validation loss: 2.5316847439644348

Epoch: 6| Step: 9
Training loss: 1.6380582076409473
Validation loss: 2.5189712730123532

Epoch: 6| Step: 10
Training loss: 1.7840214634617726
Validation loss: 2.5296301191394748

Epoch: 6| Step: 11
Training loss: 1.4915632769736282
Validation loss: 2.549893928328794

Epoch: 6| Step: 12
Training loss: 2.2264529552616663
Validation loss: 2.5344178427803867

Epoch: 6| Step: 13
Training loss: 1.7550890360360818
Validation loss: 2.544738497486371

Epoch: 350| Step: 0
Training loss: 1.9567161808973341
Validation loss: 2.527665697018696

Epoch: 6| Step: 1
Training loss: 1.8448625214588474
Validation loss: 2.5397736712491428

Epoch: 6| Step: 2
Training loss: 1.2751682432284015
Validation loss: 2.5637220864564227

Epoch: 6| Step: 3
Training loss: 2.2672992702409096
Validation loss: 2.5422460854471094

Epoch: 6| Step: 4
Training loss: 2.1670463180485715
Validation loss: 2.5585764644126265

Epoch: 6| Step: 5
Training loss: 1.4965692068424836
Validation loss: 2.5795246524962496

Epoch: 6| Step: 6
Training loss: 1.8627355644210437
Validation loss: 2.595214751881466

Epoch: 6| Step: 7
Training loss: 1.7426821429862516
Validation loss: 2.5797070821923427

Epoch: 6| Step: 8
Training loss: 1.5355793998260612
Validation loss: 2.5933215082269987

Epoch: 6| Step: 9
Training loss: 2.022924409714667
Validation loss: 2.5921299022601163

Epoch: 6| Step: 10
Training loss: 2.2045545336492576
Validation loss: 2.6014845782000107

Epoch: 6| Step: 11
Training loss: 2.1366996694546265
Validation loss: 2.599374288069834

Epoch: 6| Step: 12
Training loss: 1.3245349157763477
Validation loss: 2.5885413391808982

Epoch: 6| Step: 13
Training loss: 1.5134600878803548
Validation loss: 2.5943886686801427

Epoch: 351| Step: 0
Training loss: 1.8102285687616602
Validation loss: 2.5603218280391524

Epoch: 6| Step: 1
Training loss: 1.4940995354082516
Validation loss: 2.556354519324713

Epoch: 6| Step: 2
Training loss: 1.3357764252939082
Validation loss: 2.5504403930800215

Epoch: 6| Step: 3
Training loss: 2.114824278184856
Validation loss: 2.5762847189281284

Epoch: 6| Step: 4
Training loss: 1.9692733311294686
Validation loss: 2.5658506336807974

Epoch: 6| Step: 5
Training loss: 1.5134403962370095
Validation loss: 2.588570720629804

Epoch: 6| Step: 6
Training loss: 2.0124183401280145
Validation loss: 2.581848907572794

Epoch: 6| Step: 7
Training loss: 2.1272167536345137
Validation loss: 2.5945222157029377

Epoch: 6| Step: 8
Training loss: 1.4541738683017615
Validation loss: 2.580762619792298

Epoch: 6| Step: 9
Training loss: 1.6280535105644127
Validation loss: 2.6195673811798823

Epoch: 6| Step: 10
Training loss: 2.220409471191537
Validation loss: 2.5954546401640246

Epoch: 6| Step: 11
Training loss: 2.0326655224056323
Validation loss: 2.6168588156723915

Epoch: 6| Step: 12
Training loss: 1.681410788182633
Validation loss: 2.616763666100443

Epoch: 6| Step: 13
Training loss: 1.8320255238783114
Validation loss: 2.6019356796931343

Epoch: 352| Step: 0
Training loss: 2.0002015727507367
Validation loss: 2.6267827353352997

Epoch: 6| Step: 1
Training loss: 1.728080806891415
Validation loss: 2.595939493432272

Epoch: 6| Step: 2
Training loss: 1.598922936195783
Validation loss: 2.565421509194235

Epoch: 6| Step: 3
Training loss: 1.6333311434491067
Validation loss: 2.568196980765878

Epoch: 6| Step: 4
Training loss: 1.7637569031015938
Validation loss: 2.5821581033622

Epoch: 6| Step: 5
Training loss: 1.717345617649221
Validation loss: 2.5718099605205347

Epoch: 6| Step: 6
Training loss: 2.151927651617928
Validation loss: 2.572850312730005

Epoch: 6| Step: 7
Training loss: 1.9943525928373058
Validation loss: 2.59035950555352

Epoch: 6| Step: 8
Training loss: 1.7491404602331495
Validation loss: 2.596238470736063

Epoch: 6| Step: 9
Training loss: 1.55840091898752
Validation loss: 2.5549022028272543

Epoch: 6| Step: 10
Training loss: 2.063513420126044
Validation loss: 2.5504624545802494

Epoch: 6| Step: 11
Training loss: 2.103171147694681
Validation loss: 2.5857995832992233

Epoch: 6| Step: 12
Training loss: 1.7227282865863982
Validation loss: 2.5653721445109205

Epoch: 6| Step: 13
Training loss: 1.4503031578165835
Validation loss: 2.583297703610076

Epoch: 353| Step: 0
Training loss: 1.9569485279501202
Validation loss: 2.533056015178404

Epoch: 6| Step: 1
Training loss: 2.4334287633429192
Validation loss: 2.5560094463699174

Epoch: 6| Step: 2
Training loss: 2.7687117597638773
Validation loss: 2.5388578674801128

Epoch: 6| Step: 3
Training loss: 1.4455162935661465
Validation loss: 2.546701390252715

Epoch: 6| Step: 4
Training loss: 1.7169928151393035
Validation loss: 2.5599558536378844

Epoch: 6| Step: 5
Training loss: 1.4900945395361231
Validation loss: 2.578697094876171

Epoch: 6| Step: 6
Training loss: 1.1408253323980573
Validation loss: 2.55966903183716

Epoch: 6| Step: 7
Training loss: 1.3266382310366205
Validation loss: 2.575231095471554

Epoch: 6| Step: 8
Training loss: 1.9282057783866615
Validation loss: 2.5660871348949734

Epoch: 6| Step: 9
Training loss: 1.2852091213122285
Validation loss: 2.5750443982491062

Epoch: 6| Step: 10
Training loss: 1.774386651893403
Validation loss: 2.5550048506579355

Epoch: 6| Step: 11
Training loss: 1.3418304572421458
Validation loss: 2.5796075584799336

Epoch: 6| Step: 12
Training loss: 2.0369815658312014
Validation loss: 2.54386535245518

Epoch: 6| Step: 13
Training loss: 1.4993722714792463
Validation loss: 2.596402906587218

Epoch: 354| Step: 0
Training loss: 1.769516294302486
Validation loss: 2.5677318043180946

Epoch: 6| Step: 1
Training loss: 0.9968714651206553
Validation loss: 2.586353264737222

Epoch: 6| Step: 2
Training loss: 1.54433903749926
Validation loss: 2.606185364626877

Epoch: 6| Step: 3
Training loss: 1.4335241482752756
Validation loss: 2.570526284213614

Epoch: 6| Step: 4
Training loss: 1.5331595833785434
Validation loss: 2.57939474261115

Epoch: 6| Step: 5
Training loss: 1.9107296946863013
Validation loss: 2.568807716061553

Epoch: 6| Step: 6
Training loss: 2.4851857907633015
Validation loss: 2.554805134622632

Epoch: 6| Step: 7
Training loss: 1.9848918692206305
Validation loss: 2.5840023056488457

Epoch: 6| Step: 8
Training loss: 2.0629079010783054
Validation loss: 2.5759956351637143

Epoch: 6| Step: 9
Training loss: 1.9770588006714054
Validation loss: 2.588345438979465

Epoch: 6| Step: 10
Training loss: 1.8400199141668656
Validation loss: 2.621681499956595

Epoch: 6| Step: 11
Training loss: 1.624612468579872
Validation loss: 2.6240632792757093

Epoch: 6| Step: 12
Training loss: 2.1077223343506857
Validation loss: 2.6507552965900314

Epoch: 6| Step: 13
Training loss: 1.751036609443413
Validation loss: 2.5810464817262595

Epoch: 355| Step: 0
Training loss: 1.7056964046059513
Validation loss: 2.573117102925207

Epoch: 6| Step: 1
Training loss: 2.3212165484177554
Validation loss: 2.535892060429596

Epoch: 6| Step: 2
Training loss: 1.5105074975775648
Validation loss: 2.5433468085949027

Epoch: 6| Step: 3
Training loss: 1.516656740736008
Validation loss: 2.547051515293645

Epoch: 6| Step: 4
Training loss: 1.265342398281072
Validation loss: 2.5610768312664143

Epoch: 6| Step: 5
Training loss: 1.2192305571128477
Validation loss: 2.5607003195823177

Epoch: 6| Step: 6
Training loss: 2.3108950019730545
Validation loss: 2.5689100248143046

Epoch: 6| Step: 7
Training loss: 1.2864859522687477
Validation loss: 2.580418193005045

Epoch: 6| Step: 8
Training loss: 1.3666359797188172
Validation loss: 2.542555361819857

Epoch: 6| Step: 9
Training loss: 2.4887489825428175
Validation loss: 2.566904872104036

Epoch: 6| Step: 10
Training loss: 1.866451166122658
Validation loss: 2.570458884356012

Epoch: 6| Step: 11
Training loss: 1.949062792209336
Validation loss: 2.5709702134337626

Epoch: 6| Step: 12
Training loss: 1.4612750311176856
Validation loss: 2.5769658112513634

Epoch: 6| Step: 13
Training loss: 2.3419734070633873
Validation loss: 2.5938934072046322

Epoch: 356| Step: 0
Training loss: 1.7657372768116002
Validation loss: 2.5835071679560895

Epoch: 6| Step: 1
Training loss: 1.7995518523872942
Validation loss: 2.596812879520958

Epoch: 6| Step: 2
Training loss: 2.043749454043254
Validation loss: 2.6325985814999817

Epoch: 6| Step: 3
Training loss: 2.455157173237651
Validation loss: 2.559174496501976

Epoch: 6| Step: 4
Training loss: 1.7507159948210032
Validation loss: 2.57950815416489

Epoch: 6| Step: 5
Training loss: 1.4953593152091045
Validation loss: 2.5595110852800755

Epoch: 6| Step: 6
Training loss: 1.9254489325658433
Validation loss: 2.561117916024583

Epoch: 6| Step: 7
Training loss: 1.728666378710206
Validation loss: 2.5403117857581767

Epoch: 6| Step: 8
Training loss: 1.2578717330348863
Validation loss: 2.542094825160507

Epoch: 6| Step: 9
Training loss: 2.4052820612094186
Validation loss: 2.5323208713978893

Epoch: 6| Step: 10
Training loss: 1.557257134130172
Validation loss: 2.561143686754429

Epoch: 6| Step: 11
Training loss: 1.3622214671321793
Validation loss: 2.5451352861166994

Epoch: 6| Step: 12
Training loss: 1.8898734498420382
Validation loss: 2.5461718284806145

Epoch: 6| Step: 13
Training loss: 1.4946066534759244
Validation loss: 2.5501458787018665

Epoch: 357| Step: 0
Training loss: 1.5686673328761933
Validation loss: 2.5567243352036875

Epoch: 6| Step: 1
Training loss: 1.9668648792317986
Validation loss: 2.5881501227256294

Epoch: 6| Step: 2
Training loss: 2.5274945881801663
Validation loss: 2.5700784594066586

Epoch: 6| Step: 3
Training loss: 1.6505538588839384
Validation loss: 2.576304908770686

Epoch: 6| Step: 4
Training loss: 1.7875511748984585
Validation loss: 2.571121204546081

Epoch: 6| Step: 5
Training loss: 2.106718184509179
Validation loss: 2.5771682196914676

Epoch: 6| Step: 6
Training loss: 2.2315494838581267
Validation loss: 2.5524574213215994

Epoch: 6| Step: 7
Training loss: 1.5100458237976992
Validation loss: 2.50492654803132

Epoch: 6| Step: 8
Training loss: 1.6471617041941553
Validation loss: 2.529788352710516

Epoch: 6| Step: 9
Training loss: 1.3272727924889658
Validation loss: 2.4919870708552674

Epoch: 6| Step: 10
Training loss: 2.072065309555712
Validation loss: 2.5116976612999387

Epoch: 6| Step: 11
Training loss: 2.062203241442243
Validation loss: 2.5083312451764748

Epoch: 6| Step: 12
Training loss: 1.24510244323378
Validation loss: 2.52355495372436

Epoch: 6| Step: 13
Training loss: 1.4788526103130715
Validation loss: 2.5736162467539776

Epoch: 358| Step: 0
Training loss: 1.9706799569105506
Validation loss: 2.56921007502243

Epoch: 6| Step: 1
Training loss: 2.098827979597054
Validation loss: 2.5744574768482176

Epoch: 6| Step: 2
Training loss: 1.6786162753042122
Validation loss: 2.5905901800315023

Epoch: 6| Step: 3
Training loss: 1.724910446274953
Validation loss: 2.63119929816779

Epoch: 6| Step: 4
Training loss: 2.0480972019016823
Validation loss: 2.6386062007762474

Epoch: 6| Step: 5
Training loss: 1.8427831409969084
Validation loss: 2.6463928432049553

Epoch: 6| Step: 6
Training loss: 2.063767939304176
Validation loss: 2.669178589258195

Epoch: 6| Step: 7
Training loss: 1.5389625787975512
Validation loss: 2.6223926916675

Epoch: 6| Step: 8
Training loss: 1.9924928917273417
Validation loss: 2.6292831808188963

Epoch: 6| Step: 9
Training loss: 1.6417822979450793
Validation loss: 2.6148765723747407

Epoch: 6| Step: 10
Training loss: 2.025773515256216
Validation loss: 2.6162400689614733

Epoch: 6| Step: 11
Training loss: 1.700951755792638
Validation loss: 2.5869965012729077

Epoch: 6| Step: 12
Training loss: 1.208655095285053
Validation loss: 2.5498824821768937

Epoch: 6| Step: 13
Training loss: 1.3131420744812143
Validation loss: 2.5446550488478694

Epoch: 359| Step: 0
Training loss: 1.8487263780262173
Validation loss: 2.5664514298625773

Epoch: 6| Step: 1
Training loss: 2.5359253267852755
Validation loss: 2.5454206468288043

Epoch: 6| Step: 2
Training loss: 1.7923037556969932
Validation loss: 2.5217212237776083

Epoch: 6| Step: 3
Training loss: 1.259943229516558
Validation loss: 2.5619825523019597

Epoch: 6| Step: 4
Training loss: 1.096979387320915
Validation loss: 2.5719460163532117

Epoch: 6| Step: 5
Training loss: 1.6086235884742435
Validation loss: 2.5990360429316257

Epoch: 6| Step: 6
Training loss: 2.2758208166965765
Validation loss: 2.60600362965606

Epoch: 6| Step: 7
Training loss: 1.7410267611073202
Validation loss: 2.6147910462405743

Epoch: 6| Step: 8
Training loss: 1.2834384650149455
Validation loss: 2.5937015345078427

Epoch: 6| Step: 9
Training loss: 1.9307735336827443
Validation loss: 2.603752619570646

Epoch: 6| Step: 10
Training loss: 1.7969262157273087
Validation loss: 2.585508712453873

Epoch: 6| Step: 11
Training loss: 1.4457189040107563
Validation loss: 2.5847555419270156

Epoch: 6| Step: 12
Training loss: 1.86116006258582
Validation loss: 2.561441761246094

Epoch: 6| Step: 13
Training loss: 1.7283049201775667
Validation loss: 2.5817443872979764

Epoch: 360| Step: 0
Training loss: 2.390952592731545
Validation loss: 2.544000341170466

Epoch: 6| Step: 1
Training loss: 1.2576739785822448
Validation loss: 2.5502550907573456

Epoch: 6| Step: 2
Training loss: 2.2194447034258236
Validation loss: 2.6168464400460447

Epoch: 6| Step: 3
Training loss: 1.5943542531756048
Validation loss: 2.5703491084652335

Epoch: 6| Step: 4
Training loss: 1.805948584727686
Validation loss: 2.6095043614771285

Epoch: 6| Step: 5
Training loss: 1.6902439978484092
Validation loss: 2.605095084951173

Epoch: 6| Step: 6
Training loss: 2.0817835447527604
Validation loss: 2.605820662082679

Epoch: 6| Step: 7
Training loss: 1.8876264769766427
Validation loss: 2.6298774183737152

Epoch: 6| Step: 8
Training loss: 1.8058572256317649
Validation loss: 2.56587347638737

Epoch: 6| Step: 9
Training loss: 1.4708143296063214
Validation loss: 2.5745849657606596

Epoch: 6| Step: 10
Training loss: 1.4810037979705764
Validation loss: 2.5234080687894043

Epoch: 6| Step: 11
Training loss: 1.5734607774363152
Validation loss: 2.538612114501841

Epoch: 6| Step: 12
Training loss: 1.1476668282703644
Validation loss: 2.5048082207968734

Epoch: 6| Step: 13
Training loss: 1.664114794558655
Validation loss: 2.5175994090859297

Epoch: 361| Step: 0
Training loss: 1.477116152995528
Validation loss: 2.5406446486648195

Epoch: 6| Step: 1
Training loss: 1.3996482594587805
Validation loss: 2.5261973591963227

Epoch: 6| Step: 2
Training loss: 1.801314070314594
Validation loss: 2.5244811648631202

Epoch: 6| Step: 3
Training loss: 1.4888077252756906
Validation loss: 2.5332879233891488

Epoch: 6| Step: 4
Training loss: 1.7596301366404923
Validation loss: 2.4974614208679693

Epoch: 6| Step: 5
Training loss: 2.112453446637105
Validation loss: 2.502655272238225

Epoch: 6| Step: 6
Training loss: 1.72461863738842
Validation loss: 2.5433289819166056

Epoch: 6| Step: 7
Training loss: 1.5551202066453573
Validation loss: 2.5587564897105515

Epoch: 6| Step: 8
Training loss: 1.9690335992878618
Validation loss: 2.6261491379516513

Epoch: 6| Step: 9
Training loss: 1.8930872497119546
Validation loss: 2.6162027812402022

Epoch: 6| Step: 10
Training loss: 2.4258433654990066
Validation loss: 2.6697409288752545

Epoch: 6| Step: 11
Training loss: 2.066955839455875
Validation loss: 2.632781046482338

Epoch: 6| Step: 12
Training loss: 1.3889028622666086
Validation loss: 2.6003970264862013

Epoch: 6| Step: 13
Training loss: 1.414334855801598
Validation loss: 2.555371876233941

Epoch: 362| Step: 0
Training loss: 1.5498422234742395
Validation loss: 2.5678589462667056

Epoch: 6| Step: 1
Training loss: 1.2284547824075756
Validation loss: 2.580084978547428

Epoch: 6| Step: 2
Training loss: 1.968701316594877
Validation loss: 2.5819672284675126

Epoch: 6| Step: 3
Training loss: 1.6273877134716535
Validation loss: 2.60518851005113

Epoch: 6| Step: 4
Training loss: 1.7254655900750264
Validation loss: 2.6049099637053548

Epoch: 6| Step: 5
Training loss: 1.676303382040598
Validation loss: 2.6363041304506583

Epoch: 6| Step: 6
Training loss: 2.8265711272336294
Validation loss: 2.606502512798102

Epoch: 6| Step: 7
Training loss: 1.5801025690514983
Validation loss: 2.6444211680548158

Epoch: 6| Step: 8
Training loss: 1.8223855979815888
Validation loss: 2.685951141447052

Epoch: 6| Step: 9
Training loss: 1.4101463169582857
Validation loss: 2.6797330683771676

Epoch: 6| Step: 10
Training loss: 1.8030140702158262
Validation loss: 2.6767736075175477

Epoch: 6| Step: 11
Training loss: 2.236781818061683
Validation loss: 2.6612471902980874

Epoch: 6| Step: 12
Training loss: 1.4582993458011668
Validation loss: 2.6868032542911457

Epoch: 6| Step: 13
Training loss: 2.0761535012122065
Validation loss: 2.646071616028503

Epoch: 363| Step: 0
Training loss: 2.0110874407635717
Validation loss: 2.5880655404723814

Epoch: 6| Step: 1
Training loss: 2.0923773977807283
Validation loss: 2.516916804219487

Epoch: 6| Step: 2
Training loss: 1.7930977968138264
Validation loss: 2.512386899588209

Epoch: 6| Step: 3
Training loss: 1.9214207802532006
Validation loss: 2.5402043518704307

Epoch: 6| Step: 4
Training loss: 2.0802236873217343
Validation loss: 2.5461328123252063

Epoch: 6| Step: 5
Training loss: 1.768619395040708
Validation loss: 2.5061447207059153

Epoch: 6| Step: 6
Training loss: 1.6831455563473792
Validation loss: 2.5779587200757406

Epoch: 6| Step: 7
Training loss: 1.4726009611481774
Validation loss: 2.663512276576963

Epoch: 6| Step: 8
Training loss: 1.7287551282915579
Validation loss: 2.7328179203980802

Epoch: 6| Step: 9
Training loss: 2.468394579834799
Validation loss: 2.7612065510679424

Epoch: 6| Step: 10
Training loss: 2.495945790282915
Validation loss: 2.7006521214520607

Epoch: 6| Step: 11
Training loss: 1.392817108920395
Validation loss: 2.6388923332682657

Epoch: 6| Step: 12
Training loss: 1.4210437398859141
Validation loss: 2.598099948400418

Epoch: 6| Step: 13
Training loss: 1.644786244102206
Validation loss: 2.5435839962041453

Epoch: 364| Step: 0
Training loss: 1.8192073758169536
Validation loss: 2.5467310437666897

Epoch: 6| Step: 1
Training loss: 1.1775793982624
Validation loss: 2.5754073644829156

Epoch: 6| Step: 2
Training loss: 2.2193659612438816
Validation loss: 2.548241246890076

Epoch: 6| Step: 3
Training loss: 2.4880438052059164
Validation loss: 2.5711537755486953

Epoch: 6| Step: 4
Training loss: 2.0428612646124202
Validation loss: 2.5739582800212277

Epoch: 6| Step: 5
Training loss: 1.3646437604885995
Validation loss: 2.533007290421657

Epoch: 6| Step: 6
Training loss: 1.5300894251102544
Validation loss: 2.557050566693071

Epoch: 6| Step: 7
Training loss: 2.0340552106507794
Validation loss: 2.5318087051489853

Epoch: 6| Step: 8
Training loss: 2.0569438656429715
Validation loss: 2.542276392693389

Epoch: 6| Step: 9
Training loss: 2.085729810111989
Validation loss: 2.581112850754432

Epoch: 6| Step: 10
Training loss: 1.459166570315239
Validation loss: 2.603803492335551

Epoch: 6| Step: 11
Training loss: 1.6028008860232192
Validation loss: 2.5828365391733543

Epoch: 6| Step: 12
Training loss: 2.0455632556579495
Validation loss: 2.5911953229666853

Epoch: 6| Step: 13
Training loss: 2.5398866225642744
Validation loss: 2.575436456041927

Epoch: 365| Step: 0
Training loss: 1.7121020669191507
Validation loss: 2.531956201320166

Epoch: 6| Step: 1
Training loss: 1.3053396274121367
Validation loss: 2.4873229316808163

Epoch: 6| Step: 2
Training loss: 1.745156670344136
Validation loss: 2.5151384566299892

Epoch: 6| Step: 3
Training loss: 1.6610453300606325
Validation loss: 2.5162255654283285

Epoch: 6| Step: 4
Training loss: 1.9086561182663078
Validation loss: 2.5250669873356686

Epoch: 6| Step: 5
Training loss: 2.189942222773677
Validation loss: 2.567673484973289

Epoch: 6| Step: 6
Training loss: 1.9917575746269887
Validation loss: 2.495747207361347

Epoch: 6| Step: 7
Training loss: 1.9686234448643747
Validation loss: 2.4843122046509807

Epoch: 6| Step: 8
Training loss: 1.7666785548667863
Validation loss: 2.486641543707187

Epoch: 6| Step: 9
Training loss: 1.5554714047664595
Validation loss: 2.4884817860040047

Epoch: 6| Step: 10
Training loss: 2.0065964159069374
Validation loss: 2.491818519311304

Epoch: 6| Step: 11
Training loss: 1.0308640075556375
Validation loss: 2.556221379972507

Epoch: 6| Step: 12
Training loss: 2.4310617761392894
Validation loss: 2.581671200578557

Epoch: 6| Step: 13
Training loss: 1.3660861129398922
Validation loss: 2.626141360573401

Epoch: 366| Step: 0
Training loss: 0.9373700369716104
Validation loss: 2.6448044215572497

Epoch: 6| Step: 1
Training loss: 1.7544007825434826
Validation loss: 2.6435397837866614

Epoch: 6| Step: 2
Training loss: 1.9839340080391774
Validation loss: 2.637488795734249

Epoch: 6| Step: 3
Training loss: 2.4181997654119134
Validation loss: 2.6320235582425933

Epoch: 6| Step: 4
Training loss: 1.9651957930263817
Validation loss: 2.6054735388609322

Epoch: 6| Step: 5
Training loss: 1.413315844600065
Validation loss: 2.600034232403294

Epoch: 6| Step: 6
Training loss: 1.6910182869146293
Validation loss: 2.5483747875699843

Epoch: 6| Step: 7
Training loss: 1.5416973815470145
Validation loss: 2.5565565701104935

Epoch: 6| Step: 8
Training loss: 1.7875879866279376
Validation loss: 2.5862866768096193

Epoch: 6| Step: 9
Training loss: 1.732155900942605
Validation loss: 2.5583198381331025

Epoch: 6| Step: 10
Training loss: 1.5419376066476196
Validation loss: 2.5547448636924246

Epoch: 6| Step: 11
Training loss: 1.9373031023943763
Validation loss: 2.5665024304378754

Epoch: 6| Step: 12
Training loss: 1.7153590651113024
Validation loss: 2.5430403316988213

Epoch: 6| Step: 13
Training loss: 1.7722511524654627
Validation loss: 2.549471703512914

Epoch: 367| Step: 0
Training loss: 1.481394294760538
Validation loss: 2.527549668442539

Epoch: 6| Step: 1
Training loss: 1.572286247923754
Validation loss: 2.5361086364776733

Epoch: 6| Step: 2
Training loss: 1.882047885743659
Validation loss: 2.5572880410183587

Epoch: 6| Step: 3
Training loss: 1.4287496523719023
Validation loss: 2.5544386031823474

Epoch: 6| Step: 4
Training loss: 1.7961874268317184
Validation loss: 2.5699601323193355

Epoch: 6| Step: 5
Training loss: 1.2941481175826106
Validation loss: 2.577210512674866

Epoch: 6| Step: 6
Training loss: 1.2912446481126658
Validation loss: 2.551618250813814

Epoch: 6| Step: 7
Training loss: 2.0433692320781174
Validation loss: 2.561463696966855

Epoch: 6| Step: 8
Training loss: 2.002601005111864
Validation loss: 2.5375668311753232

Epoch: 6| Step: 9
Training loss: 1.9592241804128439
Validation loss: 2.558351570296341

Epoch: 6| Step: 10
Training loss: 1.6900917918766638
Validation loss: 2.5354670807698616

Epoch: 6| Step: 11
Training loss: 1.716219547832297
Validation loss: 2.549371693066504

Epoch: 6| Step: 12
Training loss: 1.7669440549533426
Validation loss: 2.5742073116714055

Epoch: 6| Step: 13
Training loss: 1.5445694358631983
Validation loss: 2.5317117089422387

Epoch: 368| Step: 0
Training loss: 1.8490776417524717
Validation loss: 2.5865423027314036

Epoch: 6| Step: 1
Training loss: 1.336410037342754
Validation loss: 2.546766641570126

Epoch: 6| Step: 2
Training loss: 1.407811590569104
Validation loss: 2.541745127316334

Epoch: 6| Step: 3
Training loss: 1.2844569846019225
Validation loss: 2.567392772192371

Epoch: 6| Step: 4
Training loss: 1.9305503244428255
Validation loss: 2.5281825061823056

Epoch: 6| Step: 5
Training loss: 1.6487225471391687
Validation loss: 2.5432954218010777

Epoch: 6| Step: 6
Training loss: 1.940278675671079
Validation loss: 2.5243946854359884

Epoch: 6| Step: 7
Training loss: 1.787394649895682
Validation loss: 2.5617412126011385

Epoch: 6| Step: 8
Training loss: 1.3509973656482552
Validation loss: 2.562010555510623

Epoch: 6| Step: 9
Training loss: 1.2979706881053925
Validation loss: 2.561280161796523

Epoch: 6| Step: 10
Training loss: 1.3067400656410637
Validation loss: 2.57944901502138

Epoch: 6| Step: 11
Training loss: 2.2072793736699836
Validation loss: 2.5816342601215703

Epoch: 6| Step: 12
Training loss: 1.9110784196398596
Validation loss: 2.5507293586846687

Epoch: 6| Step: 13
Training loss: 1.6816255965320048
Validation loss: 2.5804019467758192

Epoch: 369| Step: 0
Training loss: 1.9410585518072836
Validation loss: 2.593132711591982

Epoch: 6| Step: 1
Training loss: 1.5241062359364619
Validation loss: 2.5968480432781433

Epoch: 6| Step: 2
Training loss: 1.7522922217471342
Validation loss: 2.586342233445454

Epoch: 6| Step: 3
Training loss: 1.3746863787785888
Validation loss: 2.6238294292395787

Epoch: 6| Step: 4
Training loss: 1.717834853244942
Validation loss: 2.607175954968208

Epoch: 6| Step: 5
Training loss: 1.1183709765227905
Validation loss: 2.641809728180256

Epoch: 6| Step: 6
Training loss: 2.0267108377654104
Validation loss: 2.614670738086549

Epoch: 6| Step: 7
Training loss: 1.713919214399071
Validation loss: 2.6205309866810502

Epoch: 6| Step: 8
Training loss: 2.1205683104799102
Validation loss: 2.5569164728608587

Epoch: 6| Step: 9
Training loss: 1.9183697252221548
Validation loss: 2.5943965948522245

Epoch: 6| Step: 10
Training loss: 0.8787368272035517
Validation loss: 2.572054295028075

Epoch: 6| Step: 11
Training loss: 1.7720229098903517
Validation loss: 2.588477248395123

Epoch: 6| Step: 12
Training loss: 1.2988285839108682
Validation loss: 2.602617876435216

Epoch: 6| Step: 13
Training loss: 1.8440833356152448
Validation loss: 2.586668466324852

Epoch: 370| Step: 0
Training loss: 1.9174583983602196
Validation loss: 2.60849252119571

Epoch: 6| Step: 1
Training loss: 1.6718720052817075
Validation loss: 2.5644445097159485

Epoch: 6| Step: 2
Training loss: 1.4222857542219136
Validation loss: 2.530946438644017

Epoch: 6| Step: 3
Training loss: 1.3457842665350277
Validation loss: 2.5357104745320695

Epoch: 6| Step: 4
Training loss: 1.303474913530931
Validation loss: 2.5074982253094036

Epoch: 6| Step: 5
Training loss: 1.674907251893208
Validation loss: 2.5436539515452155

Epoch: 6| Step: 6
Training loss: 1.3125727497102249
Validation loss: 2.5225402055553827

Epoch: 6| Step: 7
Training loss: 1.6439307922033832
Validation loss: 2.526723778774532

Epoch: 6| Step: 8
Training loss: 1.5209700727609656
Validation loss: 2.5308311649631845

Epoch: 6| Step: 9
Training loss: 1.5943031099232778
Validation loss: 2.5168313792518586

Epoch: 6| Step: 10
Training loss: 1.4538159932240156
Validation loss: 2.5094136705027767

Epoch: 6| Step: 11
Training loss: 2.416179037773924
Validation loss: 2.5834587179539827

Epoch: 6| Step: 12
Training loss: 1.7322019418069323
Validation loss: 2.62443384998339

Epoch: 6| Step: 13
Training loss: 1.766479285517413
Validation loss: 2.645731876460566

Epoch: 371| Step: 0
Training loss: 1.584152193974915
Validation loss: 2.6761310580775985

Epoch: 6| Step: 1
Training loss: 2.6837584599084865
Validation loss: 2.6791825481396945

Epoch: 6| Step: 2
Training loss: 1.7170151711684032
Validation loss: 2.609166287357478

Epoch: 6| Step: 3
Training loss: 1.697942214804816
Validation loss: 2.5718674830732042

Epoch: 6| Step: 4
Training loss: 1.67656954206568
Validation loss: 2.574786820583957

Epoch: 6| Step: 5
Training loss: 1.259847948799957
Validation loss: 2.5497451243461957

Epoch: 6| Step: 6
Training loss: 1.3059105993431817
Validation loss: 2.5518707472303066

Epoch: 6| Step: 7
Training loss: 1.7631579692777632
Validation loss: 2.5604036331362345

Epoch: 6| Step: 8
Training loss: 1.402188008195459
Validation loss: 2.5789492744031746

Epoch: 6| Step: 9
Training loss: 1.4809325606389936
Validation loss: 2.563814531602502

Epoch: 6| Step: 10
Training loss: 1.6503987148470365
Validation loss: 2.5714576744143236

Epoch: 6| Step: 11
Training loss: 1.41112373111535
Validation loss: 2.564502011540373

Epoch: 6| Step: 12
Training loss: 1.3344650184588644
Validation loss: 2.5777875891403768

Epoch: 6| Step: 13
Training loss: 1.9854235544582255
Validation loss: 2.5460975880265706

Epoch: 372| Step: 0
Training loss: 1.425757755451758
Validation loss: 2.565030484504815

Epoch: 6| Step: 1
Training loss: 1.417383667008751
Validation loss: 2.574181563668838

Epoch: 6| Step: 2
Training loss: 1.6578008480543411
Validation loss: 2.5623835870615133

Epoch: 6| Step: 3
Training loss: 1.6227000172295396
Validation loss: 2.5766252490395924

Epoch: 6| Step: 4
Training loss: 1.586953199637584
Validation loss: 2.579579969660774

Epoch: 6| Step: 5
Training loss: 1.944330235563431
Validation loss: 2.585938452713744

Epoch: 6| Step: 6
Training loss: 1.0450051532965088
Validation loss: 2.54841506358736

Epoch: 6| Step: 7
Training loss: 1.990745351557686
Validation loss: 2.5570974697074313

Epoch: 6| Step: 8
Training loss: 1.2707463010576152
Validation loss: 2.585222558402464

Epoch: 6| Step: 9
Training loss: 1.6513518835223735
Validation loss: 2.57416955402081

Epoch: 6| Step: 10
Training loss: 1.9072014357263807
Validation loss: 2.5332328188765394

Epoch: 6| Step: 11
Training loss: 1.2059170910881947
Validation loss: 2.5658031511735864

Epoch: 6| Step: 12
Training loss: 2.2273487509808816
Validation loss: 2.5659498856988554

Epoch: 6| Step: 13
Training loss: 1.6264027629766904
Validation loss: 2.567545737998542

Epoch: 373| Step: 0
Training loss: 1.5166896737977134
Validation loss: 2.5601593740842117

Epoch: 6| Step: 1
Training loss: 1.778288001448295
Validation loss: 2.5551339944340556

Epoch: 6| Step: 2
Training loss: 1.5470351319321656
Validation loss: 2.5596129894034108

Epoch: 6| Step: 3
Training loss: 1.3518114687540765
Validation loss: 2.5431854421364735

Epoch: 6| Step: 4
Training loss: 1.174884948779259
Validation loss: 2.535103584295022

Epoch: 6| Step: 5
Training loss: 2.176216123121155
Validation loss: 2.5356034098561584

Epoch: 6| Step: 6
Training loss: 1.472582423132886
Validation loss: 2.5435251153738663

Epoch: 6| Step: 7
Training loss: 1.8663033662640671
Validation loss: 2.57193090626058

Epoch: 6| Step: 8
Training loss: 1.5779932552527107
Validation loss: 2.5874749997907682

Epoch: 6| Step: 9
Training loss: 1.8688173084193984
Validation loss: 2.5685913909431606

Epoch: 6| Step: 10
Training loss: 1.381710497011762
Validation loss: 2.577204075490127

Epoch: 6| Step: 11
Training loss: 1.5089293775773978
Validation loss: 2.592845490933744

Epoch: 6| Step: 12
Training loss: 1.9439008255609902
Validation loss: 2.60833696744948

Epoch: 6| Step: 13
Training loss: 1.7620186222750713
Validation loss: 2.63363750749205

Epoch: 374| Step: 0
Training loss: 1.5080549608480305
Validation loss: 2.6040876198533676

Epoch: 6| Step: 1
Training loss: 1.5196635916772854
Validation loss: 2.6367210557715612

Epoch: 6| Step: 2
Training loss: 2.1252277476616834
Validation loss: 2.5823177576894882

Epoch: 6| Step: 3
Training loss: 1.1886863805391634
Validation loss: 2.5783529469837854

Epoch: 6| Step: 4
Training loss: 1.0367291286843021
Validation loss: 2.5552282820642263

Epoch: 6| Step: 5
Training loss: 2.3752336889039563
Validation loss: 2.5240810191813376

Epoch: 6| Step: 6
Training loss: 1.7105620507897545
Validation loss: 2.539553136127077

Epoch: 6| Step: 7
Training loss: 1.58091036801753
Validation loss: 2.5529834068377704

Epoch: 6| Step: 8
Training loss: 2.6101296070409528
Validation loss: 2.5262017477902137

Epoch: 6| Step: 9
Training loss: 1.6864764323528847
Validation loss: 2.512824448470642

Epoch: 6| Step: 10
Training loss: 1.5188651304209235
Validation loss: 2.5263278654852797

Epoch: 6| Step: 11
Training loss: 1.7637181070040986
Validation loss: 2.5101827034940007

Epoch: 6| Step: 12
Training loss: 1.3310338198508676
Validation loss: 2.541221827263134

Epoch: 6| Step: 13
Training loss: 1.5158743112543176
Validation loss: 2.562832306815302

Epoch: 375| Step: 0
Training loss: 1.777338250120268
Validation loss: 2.599485207603333

Epoch: 6| Step: 1
Training loss: 1.8343371619720035
Validation loss: 2.5860972436773713

Epoch: 6| Step: 2
Training loss: 1.392774142772136
Validation loss: 2.5605820091585874

Epoch: 6| Step: 3
Training loss: 2.3103054046212312
Validation loss: 2.5557334850630586

Epoch: 6| Step: 4
Training loss: 1.7472993584354375
Validation loss: 2.5553900076508445

Epoch: 6| Step: 5
Training loss: 1.5560021137919446
Validation loss: 2.533744242454126

Epoch: 6| Step: 6
Training loss: 1.4092303588808608
Validation loss: 2.5484247855581286

Epoch: 6| Step: 7
Training loss: 1.4856723938003424
Validation loss: 2.5703614142342595

Epoch: 6| Step: 8
Training loss: 1.1351818693542546
Validation loss: 2.5382744294827635

Epoch: 6| Step: 9
Training loss: 1.1535487195107592
Validation loss: 2.567711547065462

Epoch: 6| Step: 10
Training loss: 2.1642719263863297
Validation loss: 2.6161042206269944

Epoch: 6| Step: 11
Training loss: 1.3913545302257084
Validation loss: 2.614922723108502

Epoch: 6| Step: 12
Training loss: 1.6427729759809793
Validation loss: 2.6104094687624184

Epoch: 6| Step: 13
Training loss: 1.4441162107311294
Validation loss: 2.583892305463429

Epoch: 376| Step: 0
Training loss: 1.226215580759532
Validation loss: 2.596858853972025

Epoch: 6| Step: 1
Training loss: 1.547639677063942
Validation loss: 2.5707431420859197

Epoch: 6| Step: 2
Training loss: 1.6125782319246247
Validation loss: 2.5564959674318204

Epoch: 6| Step: 3
Training loss: 1.4932937116702678
Validation loss: 2.5786343158137766

Epoch: 6| Step: 4
Training loss: 1.4253800337134772
Validation loss: 2.570102965250367

Epoch: 6| Step: 5
Training loss: 1.2901541971118955
Validation loss: 2.5635775339737443

Epoch: 6| Step: 6
Training loss: 1.459798440214767
Validation loss: 2.5529731185480053

Epoch: 6| Step: 7
Training loss: 1.6854123518251594
Validation loss: 2.597615391307151

Epoch: 6| Step: 8
Training loss: 1.439400701719884
Validation loss: 2.629516999188714

Epoch: 6| Step: 9
Training loss: 1.7909324901259798
Validation loss: 2.655847810702389

Epoch: 6| Step: 10
Training loss: 1.6595140359393579
Validation loss: 2.6247379686878163

Epoch: 6| Step: 11
Training loss: 1.6570055695683603
Validation loss: 2.6146988912834024

Epoch: 6| Step: 12
Training loss: 2.3291146651885115
Validation loss: 2.607948271041901

Epoch: 6| Step: 13
Training loss: 1.5972156616665913
Validation loss: 2.603206996839859

Epoch: 377| Step: 0
Training loss: 1.642492775168126
Validation loss: 2.549137374416162

Epoch: 6| Step: 1
Training loss: 1.2049466498820143
Validation loss: 2.5406459155283367

Epoch: 6| Step: 2
Training loss: 1.474046127166945
Validation loss: 2.548707657618682

Epoch: 6| Step: 3
Training loss: 1.9127196291804753
Validation loss: 2.5565125287835317

Epoch: 6| Step: 4
Training loss: 1.5173331790839073
Validation loss: 2.525783845518843

Epoch: 6| Step: 5
Training loss: 1.3749730801114577
Validation loss: 2.5260774013443053

Epoch: 6| Step: 6
Training loss: 1.622187160667541
Validation loss: 2.548202215638323

Epoch: 6| Step: 7
Training loss: 1.7437496281011589
Validation loss: 2.581031686634887

Epoch: 6| Step: 8
Training loss: 1.9746150498728419
Validation loss: 2.616484453656275

Epoch: 6| Step: 9
Training loss: 1.7508201039882827
Validation loss: 2.6443025160439193

Epoch: 6| Step: 10
Training loss: 1.35909908607693
Validation loss: 2.6639774789975155

Epoch: 6| Step: 11
Training loss: 1.4506206466694949
Validation loss: 2.6571646966710563

Epoch: 6| Step: 12
Training loss: 1.4009863359192023
Validation loss: 2.6389925875003737

Epoch: 6| Step: 13
Training loss: 1.6261360892088463
Validation loss: 2.581137136373395

Epoch: 378| Step: 0
Training loss: 1.5798161575945713
Validation loss: 2.555708001837361

Epoch: 6| Step: 1
Training loss: 1.6887939578419437
Validation loss: 2.557819930842377

Epoch: 6| Step: 2
Training loss: 1.4990522251409226
Validation loss: 2.5770836316424366

Epoch: 6| Step: 3
Training loss: 1.550152629597753
Validation loss: 2.545023332799888

Epoch: 6| Step: 4
Training loss: 1.648044919096226
Validation loss: 2.546800233956585

Epoch: 6| Step: 5
Training loss: 1.3492099816899417
Validation loss: 2.56094471323558

Epoch: 6| Step: 6
Training loss: 1.60821580342115
Validation loss: 2.533407422182807

Epoch: 6| Step: 7
Training loss: 1.8400749174705624
Validation loss: 2.560114564343812

Epoch: 6| Step: 8
Training loss: 1.4763201156360999
Validation loss: 2.555327853364722

Epoch: 6| Step: 9
Training loss: 1.7036092927054556
Validation loss: 2.6101733298010723

Epoch: 6| Step: 10
Training loss: 1.477578514969191
Validation loss: 2.5549100493107924

Epoch: 6| Step: 11
Training loss: 1.3020878092370987
Validation loss: 2.6256864573559477

Epoch: 6| Step: 12
Training loss: 1.427261963220019
Validation loss: 2.6118149685173764

Epoch: 6| Step: 13
Training loss: 1.803654759166757
Validation loss: 2.6135262230520335

Epoch: 379| Step: 0
Training loss: 1.7485281340397598
Validation loss: 2.572189387855027

Epoch: 6| Step: 1
Training loss: 2.0322576517699447
Validation loss: 2.577567593205922

Epoch: 6| Step: 2
Training loss: 1.0882870073570114
Validation loss: 2.5911797730540984

Epoch: 6| Step: 3
Training loss: 1.6521555836269675
Validation loss: 2.5509292380461512

Epoch: 6| Step: 4
Training loss: 1.9565894566671154
Validation loss: 2.5633958475636094

Epoch: 6| Step: 5
Training loss: 1.4925013506705915
Validation loss: 2.5514646493868818

Epoch: 6| Step: 6
Training loss: 1.0706275420595757
Validation loss: 2.5320222720471843

Epoch: 6| Step: 7
Training loss: 1.4769660357920147
Validation loss: 2.537781526266697

Epoch: 6| Step: 8
Training loss: 1.5047059942358691
Validation loss: 2.552373197533764

Epoch: 6| Step: 9
Training loss: 1.2511970033959752
Validation loss: 2.547129877672893

Epoch: 6| Step: 10
Training loss: 1.341807180750998
Validation loss: 2.5680070178479713

Epoch: 6| Step: 11
Training loss: 1.5567900276043065
Validation loss: 2.5637048664456965

Epoch: 6| Step: 12
Training loss: 2.025742326473582
Validation loss: 2.5287625056391416

Epoch: 6| Step: 13
Training loss: 1.5217244224548372
Validation loss: 2.553433428359482

Epoch: 380| Step: 0
Training loss: 1.5279226157380608
Validation loss: 2.5664935820500707

Epoch: 6| Step: 1
Training loss: 1.980370393075071
Validation loss: 2.61646701897464

Epoch: 6| Step: 2
Training loss: 1.7479679707881506
Validation loss: 2.6638379193431794

Epoch: 6| Step: 3
Training loss: 1.4954488375223582
Validation loss: 2.619149879630757

Epoch: 6| Step: 4
Training loss: 1.679104300098821
Validation loss: 2.6591880257455114

Epoch: 6| Step: 5
Training loss: 1.097896454617208
Validation loss: 2.575971331923562

Epoch: 6| Step: 6
Training loss: 1.8678475334630928
Validation loss: 2.5718504412047465

Epoch: 6| Step: 7
Training loss: 1.5465996237041668
Validation loss: 2.5746771366210073

Epoch: 6| Step: 8
Training loss: 1.2725660934970806
Validation loss: 2.5522897805512708

Epoch: 6| Step: 9
Training loss: 1.5226890877499848
Validation loss: 2.5830721928265734

Epoch: 6| Step: 10
Training loss: 1.5364419537549412
Validation loss: 2.5752197465061712

Epoch: 6| Step: 11
Training loss: 1.2046127038834606
Validation loss: 2.5616765598841553

Epoch: 6| Step: 12
Training loss: 1.426804768274637
Validation loss: 2.583651712753861

Epoch: 6| Step: 13
Training loss: 1.4810153888054851
Validation loss: 2.582842262313515

Epoch: 381| Step: 0
Training loss: 1.2648421798234493
Validation loss: 2.597761629113522

Epoch: 6| Step: 1
Training loss: 1.65924937891636
Validation loss: 2.5568599660265603

Epoch: 6| Step: 2
Training loss: 1.4769859715895126
Validation loss: 2.583412743445149

Epoch: 6| Step: 3
Training loss: 1.4826682467783825
Validation loss: 2.5331840661478253

Epoch: 6| Step: 4
Training loss: 1.6166627926468724
Validation loss: 2.5758883089064906

Epoch: 6| Step: 5
Training loss: 1.4514565682741531
Validation loss: 2.5479422987248808

Epoch: 6| Step: 6
Training loss: 1.499741214045425
Validation loss: 2.5503963863607457

Epoch: 6| Step: 7
Training loss: 1.6836724141234969
Validation loss: 2.5780538529876798

Epoch: 6| Step: 8
Training loss: 1.4964885937644463
Validation loss: 2.5857821338152696

Epoch: 6| Step: 9
Training loss: 1.3029172388670645
Validation loss: 2.6147588744386914

Epoch: 6| Step: 10
Training loss: 1.8301751793985124
Validation loss: 2.614992259192209

Epoch: 6| Step: 11
Training loss: 1.2211747135941795
Validation loss: 2.6059274188717874

Epoch: 6| Step: 12
Training loss: 1.737438143171096
Validation loss: 2.6115416860547933

Epoch: 6| Step: 13
Training loss: 1.7310110237083498
Validation loss: 2.5649232803828417

Epoch: 382| Step: 0
Training loss: 1.6079563443535025
Validation loss: 2.5513133126476673

Epoch: 6| Step: 1
Training loss: 1.624738378738843
Validation loss: 2.577944030575384

Epoch: 6| Step: 2
Training loss: 1.2410918387982184
Validation loss: 2.574948783784912

Epoch: 6| Step: 3
Training loss: 1.3758831222570307
Validation loss: 2.556529385347157

Epoch: 6| Step: 4
Training loss: 1.556867135486318
Validation loss: 2.5741343351733397

Epoch: 6| Step: 5
Training loss: 1.658845774710691
Validation loss: 2.5639741115612034

Epoch: 6| Step: 6
Training loss: 1.3335762796000696
Validation loss: 2.554159920721392

Epoch: 6| Step: 7
Training loss: 1.5690744558432326
Validation loss: 2.5002112776171534

Epoch: 6| Step: 8
Training loss: 1.6869371676499623
Validation loss: 2.5743200873581156

Epoch: 6| Step: 9
Training loss: 1.1713869222853095
Validation loss: 2.539673670058335

Epoch: 6| Step: 10
Training loss: 1.7614709379563696
Validation loss: 2.558997202506107

Epoch: 6| Step: 11
Training loss: 1.5612776743602301
Validation loss: 2.573375295517621

Epoch: 6| Step: 12
Training loss: 1.5419770349358422
Validation loss: 2.5735279597751144

Epoch: 6| Step: 13
Training loss: 1.1603802294577859
Validation loss: 2.5578347980550338

Epoch: 383| Step: 0
Training loss: 2.197962237664574
Validation loss: 2.574125304622012

Epoch: 6| Step: 1
Training loss: 1.5313705085512288
Validation loss: 2.579273168576317

Epoch: 6| Step: 2
Training loss: 1.6857009057028915
Validation loss: 2.5763482801510764

Epoch: 6| Step: 3
Training loss: 1.4874942330641312
Validation loss: 2.560621565547319

Epoch: 6| Step: 4
Training loss: 1.4093741575521925
Validation loss: 2.565098367803896

Epoch: 6| Step: 5
Training loss: 1.201783658671458
Validation loss: 2.554570598824619

Epoch: 6| Step: 6
Training loss: 1.4496500447971472
Validation loss: 2.5686204591435255

Epoch: 6| Step: 7
Training loss: 1.3309267448569346
Validation loss: 2.527708016528674

Epoch: 6| Step: 8
Training loss: 1.7732263514986721
Validation loss: 2.5792390054183287

Epoch: 6| Step: 9
Training loss: 1.4092031623645678
Validation loss: 2.579594742270098

Epoch: 6| Step: 10
Training loss: 1.39058642387462
Validation loss: 2.5389185311998226

Epoch: 6| Step: 11
Training loss: 1.5196848499950388
Validation loss: 2.5581321862967408

Epoch: 6| Step: 12
Training loss: 1.4368409843782428
Validation loss: 2.5772544392859493

Epoch: 6| Step: 13
Training loss: 1.3497000855629475
Validation loss: 2.596658003363728

Epoch: 384| Step: 0
Training loss: 1.8690918982840188
Validation loss: 2.6133583715108735

Epoch: 6| Step: 1
Training loss: 1.6723288517213235
Validation loss: 2.628064289518219

Epoch: 6| Step: 2
Training loss: 1.6724327796918748
Validation loss: 2.6570557512878925

Epoch: 6| Step: 3
Training loss: 1.7346534849091675
Validation loss: 2.6858204317350163

Epoch: 6| Step: 4
Training loss: 1.32619308881689
Validation loss: 2.6502351164730795

Epoch: 6| Step: 5
Training loss: 2.099575081478658
Validation loss: 2.6272760091172933

Epoch: 6| Step: 6
Training loss: 1.0710523512482384
Validation loss: 2.6413672944439828

Epoch: 6| Step: 7
Training loss: 1.3740711542776167
Validation loss: 2.5791237794168835

Epoch: 6| Step: 8
Training loss: 1.2249042940705892
Validation loss: 2.5781251078904255

Epoch: 6| Step: 9
Training loss: 1.0052765277928446
Validation loss: 2.5954079901521183

Epoch: 6| Step: 10
Training loss: 1.0279725909679558
Validation loss: 2.5403554822692573

Epoch: 6| Step: 11
Training loss: 1.5394473296692568
Validation loss: 2.577344826455926

Epoch: 6| Step: 12
Training loss: 1.6134978880914248
Validation loss: 2.5882314013789305

Epoch: 6| Step: 13
Training loss: 1.0493675847839499
Validation loss: 2.5894302567412937

Epoch: 385| Step: 0
Training loss: 1.033443199490362
Validation loss: 2.5743811811295916

Epoch: 6| Step: 1
Training loss: 1.3222833854801033
Validation loss: 2.5960217833552846

Epoch: 6| Step: 2
Training loss: 1.7710350669693298
Validation loss: 2.5936806451188503

Epoch: 6| Step: 3
Training loss: 1.9636134396765865
Validation loss: 2.6196892770789018

Epoch: 6| Step: 4
Training loss: 1.3835563598612366
Validation loss: 2.5933841462620246

Epoch: 6| Step: 5
Training loss: 1.3682861273673081
Validation loss: 2.5783106419165422

Epoch: 6| Step: 6
Training loss: 1.341697811373361
Validation loss: 2.5862909941683903

Epoch: 6| Step: 7
Training loss: 1.4758626904288068
Validation loss: 2.5926608667643105

Epoch: 6| Step: 8
Training loss: 1.641612092029177
Validation loss: 2.543818701426346

Epoch: 6| Step: 9
Training loss: 1.3677371418870972
Validation loss: 2.5484555572612235

Epoch: 6| Step: 10
Training loss: 1.893273571251005
Validation loss: 2.546907366213473

Epoch: 6| Step: 11
Training loss: 1.3198306767640513
Validation loss: 2.5355889451219564

Epoch: 6| Step: 12
Training loss: 1.6130020602000845
Validation loss: 2.5312927462261183

Epoch: 6| Step: 13
Training loss: 1.2462252843428139
Validation loss: 2.544951931787404

Epoch: 386| Step: 0
Training loss: 1.324869271792998
Validation loss: 2.56622772137757

Epoch: 6| Step: 1
Training loss: 1.256826262892543
Validation loss: 2.576801831334405

Epoch: 6| Step: 2
Training loss: 1.6821135986694642
Validation loss: 2.55996206255459

Epoch: 6| Step: 3
Training loss: 1.011731769964032
Validation loss: 2.574418364577368

Epoch: 6| Step: 4
Training loss: 1.6693907489840654
Validation loss: 2.547385291404856

Epoch: 6| Step: 5
Training loss: 1.0978128450492493
Validation loss: 2.597533044785385

Epoch: 6| Step: 6
Training loss: 1.296661359356084
Validation loss: 2.5334041675485865

Epoch: 6| Step: 7
Training loss: 1.4327273544255168
Validation loss: 2.5862941131099224

Epoch: 6| Step: 8
Training loss: 0.9004143238051857
Validation loss: 2.5773774421480886

Epoch: 6| Step: 9
Training loss: 2.4236434878494544
Validation loss: 2.614970970041299

Epoch: 6| Step: 10
Training loss: 1.1845993956716794
Validation loss: 2.549892938772422

Epoch: 6| Step: 11
Training loss: 1.806516306955839
Validation loss: 2.55846933154572

Epoch: 6| Step: 12
Training loss: 1.5498047644189095
Validation loss: 2.57135320308905

Epoch: 6| Step: 13
Training loss: 1.5848076464784835
Validation loss: 2.61490368242044

Epoch: 387| Step: 0
Training loss: 1.6246020490036792
Validation loss: 2.6184566172619608

Epoch: 6| Step: 1
Training loss: 2.2584445161183955
Validation loss: 2.675478329183821

Epoch: 6| Step: 2
Training loss: 1.5622791897199682
Validation loss: 2.588195936318971

Epoch: 6| Step: 3
Training loss: 1.2567152841271911
Validation loss: 2.5824683238348998

Epoch: 6| Step: 4
Training loss: 1.3184317109784913
Validation loss: 2.6029026066246828

Epoch: 6| Step: 5
Training loss: 1.3516611052248584
Validation loss: 2.5754781063124113

Epoch: 6| Step: 6
Training loss: 1.4028676788973842
Validation loss: 2.5838505063181283

Epoch: 6| Step: 7
Training loss: 1.2416361418861368
Validation loss: 2.5668327948654293

Epoch: 6| Step: 8
Training loss: 1.6007807614803733
Validation loss: 2.584755057665492

Epoch: 6| Step: 9
Training loss: 1.0736761768973522
Validation loss: 2.558858579174616

Epoch: 6| Step: 10
Training loss: 1.0350240371050587
Validation loss: 2.566556356173357

Epoch: 6| Step: 11
Training loss: 1.654185610005308
Validation loss: 2.6162097679820002

Epoch: 6| Step: 12
Training loss: 1.514374600613896
Validation loss: 2.6168629459297543

Epoch: 6| Step: 13
Training loss: 1.5107901626593876
Validation loss: 2.6382399251824964

Epoch: 388| Step: 0
Training loss: 1.5960601818048312
Validation loss: 2.6364610786278

Epoch: 6| Step: 1
Training loss: 1.5170044274865897
Validation loss: 2.642806451880854

Epoch: 6| Step: 2
Training loss: 1.7848526510761236
Validation loss: 2.6530077875049156

Epoch: 6| Step: 3
Training loss: 1.37149963457337
Validation loss: 2.6272043630343815

Epoch: 6| Step: 4
Training loss: 1.2654855439390211
Validation loss: 2.6329705769128435

Epoch: 6| Step: 5
Training loss: 1.193239096715806
Validation loss: 2.5958885966664473

Epoch: 6| Step: 6
Training loss: 1.496963447394656
Validation loss: 2.592293495063737

Epoch: 6| Step: 7
Training loss: 1.2031616601684363
Validation loss: 2.5711130907089927

Epoch: 6| Step: 8
Training loss: 2.0717591036088705
Validation loss: 2.5663784573316346

Epoch: 6| Step: 9
Training loss: 1.1316420723981888
Validation loss: 2.5407850007885626

Epoch: 6| Step: 10
Training loss: 1.5229719966886306
Validation loss: 2.560985055341887

Epoch: 6| Step: 11
Training loss: 1.1511179465770494
Validation loss: 2.5862957954930788

Epoch: 6| Step: 12
Training loss: 1.6220850108455067
Validation loss: 2.5614059562855913

Epoch: 6| Step: 13
Training loss: 1.5862475312967532
Validation loss: 2.536190862215293

Epoch: 389| Step: 0
Training loss: 1.672047472462384
Validation loss: 2.6009103532326474

Epoch: 6| Step: 1
Training loss: 1.0246649217692079
Validation loss: 2.601814830559885

Epoch: 6| Step: 2
Training loss: 1.5133309060271931
Validation loss: 2.61904540660484

Epoch: 6| Step: 3
Training loss: 1.2049794952737376
Validation loss: 2.6517649015656066

Epoch: 6| Step: 4
Training loss: 1.5401367466146325
Validation loss: 2.6693252756412864

Epoch: 6| Step: 5
Training loss: 1.21677414580497
Validation loss: 2.590878164501254

Epoch: 6| Step: 6
Training loss: 2.3985084746853005
Validation loss: 2.6064522339247898

Epoch: 6| Step: 7
Training loss: 1.0790643884115876
Validation loss: 2.623826884972266

Epoch: 6| Step: 8
Training loss: 1.6089682203844653
Validation loss: 2.614395109496451

Epoch: 6| Step: 9
Training loss: 1.4376421319106436
Validation loss: 2.6154955960694086

Epoch: 6| Step: 10
Training loss: 1.494045837986043
Validation loss: 2.6023573324703553

Epoch: 6| Step: 11
Training loss: 0.8822333537666506
Validation loss: 2.610108643605463

Epoch: 6| Step: 12
Training loss: 1.6593281195101293
Validation loss: 2.614185490425427

Epoch: 6| Step: 13
Training loss: 1.299009519831402
Validation loss: 2.591539628410052

Epoch: 390| Step: 0
Training loss: 1.6407182939434077
Validation loss: 2.571587506244251

Epoch: 6| Step: 1
Training loss: 2.1277407754458992
Validation loss: 2.561597882399874

Epoch: 6| Step: 2
Training loss: 1.553638583643904
Validation loss: 2.5390444397895355

Epoch: 6| Step: 3
Training loss: 1.5959058653813034
Validation loss: 2.6072737710064025

Epoch: 6| Step: 4
Training loss: 1.0681968439805134
Validation loss: 2.570999123365801

Epoch: 6| Step: 5
Training loss: 1.2686064653056548
Validation loss: 2.567721165024663

Epoch: 6| Step: 6
Training loss: 1.51959055806897
Validation loss: 2.587506589405067

Epoch: 6| Step: 7
Training loss: 1.9589264424696595
Validation loss: 2.5486859551116545

Epoch: 6| Step: 8
Training loss: 1.1632847587988553
Validation loss: 2.5972504530668314

Epoch: 6| Step: 9
Training loss: 1.29511518459542
Validation loss: 2.5751779608973124

Epoch: 6| Step: 10
Training loss: 1.3623704901222564
Validation loss: 2.63569186335611

Epoch: 6| Step: 11
Training loss: 1.686597300084397
Validation loss: 2.6130616115231664

Epoch: 6| Step: 12
Training loss: 1.629067465582326
Validation loss: 2.6796165434671027

Epoch: 6| Step: 13
Training loss: 1.5548301899667236
Validation loss: 2.6392362957092397

Epoch: 391| Step: 0
Training loss: 1.645636470304125
Validation loss: 2.619245610040135

Epoch: 6| Step: 1
Training loss: 1.4858436145665674
Validation loss: 2.5850119725632

Epoch: 6| Step: 2
Training loss: 1.0525936110450307
Validation loss: 2.617751816979035

Epoch: 6| Step: 3
Training loss: 2.1918627149652603
Validation loss: 2.6017146786770984

Epoch: 6| Step: 4
Training loss: 1.3285436531392218
Validation loss: 2.5896762277805796

Epoch: 6| Step: 5
Training loss: 1.6556253514878103
Validation loss: 2.5720041538469975

Epoch: 6| Step: 6
Training loss: 1.0632589658802696
Validation loss: 2.59742926272725

Epoch: 6| Step: 7
Training loss: 1.9128908892322285
Validation loss: 2.572807206722544

Epoch: 6| Step: 8
Training loss: 1.5220905315828717
Validation loss: 2.592154107655736

Epoch: 6| Step: 9
Training loss: 0.8355150670599787
Validation loss: 2.571132463418558

Epoch: 6| Step: 10
Training loss: 1.308657425427241
Validation loss: 2.5411239315547807

Epoch: 6| Step: 11
Training loss: 1.464968500547307
Validation loss: 2.575205743465001

Epoch: 6| Step: 12
Training loss: 1.4816819506794838
Validation loss: 2.590363693403336

Epoch: 6| Step: 13
Training loss: 1.551322016369948
Validation loss: 2.6235982846005492

Epoch: 392| Step: 0
Training loss: 1.6195125359771105
Validation loss: 2.5965924525112474

Epoch: 6| Step: 1
Training loss: 1.8247520435100735
Validation loss: 2.5973500159698495

Epoch: 6| Step: 2
Training loss: 1.4864412081756038
Validation loss: 2.6287132218769482

Epoch: 6| Step: 3
Training loss: 1.2198442290871834
Validation loss: 2.5892640966380536

Epoch: 6| Step: 4
Training loss: 1.0878902414756113
Validation loss: 2.625237257392738

Epoch: 6| Step: 5
Training loss: 1.2825022834623654
Validation loss: 2.608614096800679

Epoch: 6| Step: 6
Training loss: 2.0782623245642906
Validation loss: 2.6130455682496363

Epoch: 6| Step: 7
Training loss: 1.086827030450447
Validation loss: 2.568070799422032

Epoch: 6| Step: 8
Training loss: 1.4779086964839276
Validation loss: 2.5767168842774875

Epoch: 6| Step: 9
Training loss: 1.1716992055644284
Validation loss: 2.5771258797573218

Epoch: 6| Step: 10
Training loss: 1.2285715645333781
Validation loss: 2.5930565056313553

Epoch: 6| Step: 11
Training loss: 1.352223317443549
Validation loss: 2.5930960570036703

Epoch: 6| Step: 12
Training loss: 1.3866766694897164
Validation loss: 2.572906530156934

Epoch: 6| Step: 13
Training loss: 1.3497205321360752
Validation loss: 2.5910292147107445

Epoch: 393| Step: 0
Training loss: 1.153481338978372
Validation loss: 2.5562711856278137

Epoch: 6| Step: 1
Training loss: 1.244043415290195
Validation loss: 2.6095637788080035

Epoch: 6| Step: 2
Training loss: 1.2451818112825146
Validation loss: 2.6077552229905447

Epoch: 6| Step: 3
Training loss: 1.2036711704036434
Validation loss: 2.6255654074263917

Epoch: 6| Step: 4
Training loss: 1.6518045903014726
Validation loss: 2.61876080798314

Epoch: 6| Step: 5
Training loss: 1.4768032301593639
Validation loss: 2.6109486629689567

Epoch: 6| Step: 6
Training loss: 1.7706545870456996
Validation loss: 2.5251004120403673

Epoch: 6| Step: 7
Training loss: 1.5600014355237175
Validation loss: 2.5832859670747137

Epoch: 6| Step: 8
Training loss: 1.2741441228871075
Validation loss: 2.5971703249346962

Epoch: 6| Step: 9
Training loss: 1.849868321243088
Validation loss: 2.5349569374580194

Epoch: 6| Step: 10
Training loss: 1.5204021243174144
Validation loss: 2.584793344792659

Epoch: 6| Step: 11
Training loss: 1.1659665504748289
Validation loss: 2.5890104814643613

Epoch: 6| Step: 12
Training loss: 1.318139675342664
Validation loss: 2.619187489506814

Epoch: 6| Step: 13
Training loss: 1.5263089237820273
Validation loss: 2.593902728934681

Epoch: 394| Step: 0
Training loss: 1.22174320924861
Validation loss: 2.600559839472721

Epoch: 6| Step: 1
Training loss: 1.5272619513342052
Validation loss: 2.625840786598771

Epoch: 6| Step: 2
Training loss: 1.4072886551891364
Validation loss: 2.6216627584461816

Epoch: 6| Step: 3
Training loss: 1.222841340214047
Validation loss: 2.604937604595014

Epoch: 6| Step: 4
Training loss: 1.5061508272691824
Validation loss: 2.608419506083599

Epoch: 6| Step: 5
Training loss: 1.0570750022342363
Validation loss: 2.624229817709222

Epoch: 6| Step: 6
Training loss: 1.2737795598546777
Validation loss: 2.629572851379454

Epoch: 6| Step: 7
Training loss: 1.5031539025967926
Validation loss: 2.616834368059659

Epoch: 6| Step: 8
Training loss: 1.9364333139013623
Validation loss: 2.614095062217224

Epoch: 6| Step: 9
Training loss: 1.2827256241814782
Validation loss: 2.6060579273366034

Epoch: 6| Step: 10
Training loss: 1.4583804350012997
Validation loss: 2.5947396868248327

Epoch: 6| Step: 11
Training loss: 1.0100523432774553
Validation loss: 2.595258159401571

Epoch: 6| Step: 12
Training loss: 1.337185237960168
Validation loss: 2.5632038080340753

Epoch: 6| Step: 13
Training loss: 1.425969610444163
Validation loss: 2.6320741789779745

Epoch: 395| Step: 0
Training loss: 1.4543687153587406
Validation loss: 2.616658384062988

Epoch: 6| Step: 1
Training loss: 1.1424678912335764
Validation loss: 2.616990145553831

Epoch: 6| Step: 2
Training loss: 1.3024046336166566
Validation loss: 2.539615355726034

Epoch: 6| Step: 3
Training loss: 1.2976595791860703
Validation loss: 2.58994759053702

Epoch: 6| Step: 4
Training loss: 1.559148780452392
Validation loss: 2.6226650404174383

Epoch: 6| Step: 5
Training loss: 1.8698766648321916
Validation loss: 2.6395006965240775

Epoch: 6| Step: 6
Training loss: 1.4439705882471776
Validation loss: 2.6056809079229724

Epoch: 6| Step: 7
Training loss: 1.4680830070040665
Validation loss: 2.6059582968590784

Epoch: 6| Step: 8
Training loss: 1.1550918139671182
Validation loss: 2.626493710190645

Epoch: 6| Step: 9
Training loss: 1.0137367301288782
Validation loss: 2.6487384426362266

Epoch: 6| Step: 10
Training loss: 1.200201569952921
Validation loss: 2.627648289249853

Epoch: 6| Step: 11
Training loss: 1.2031937616688746
Validation loss: 2.665645192626223

Epoch: 6| Step: 12
Training loss: 1.4661772901323542
Validation loss: 2.638744083134679

Epoch: 6| Step: 13
Training loss: 1.1872183817165316
Validation loss: 2.6269925441880577

Epoch: 396| Step: 0
Training loss: 1.1074311324982327
Validation loss: 2.6201972318866398

Epoch: 6| Step: 1
Training loss: 1.3149799351194853
Validation loss: 2.599713024171999

Epoch: 6| Step: 2
Training loss: 1.593995767231183
Validation loss: 2.57965081271804

Epoch: 6| Step: 3
Training loss: 1.3462412606666707
Validation loss: 2.5824190965186578

Epoch: 6| Step: 4
Training loss: 1.5851123335589217
Validation loss: 2.5965004857091794

Epoch: 6| Step: 5
Training loss: 1.1625584351814264
Validation loss: 2.6235893031404784

Epoch: 6| Step: 6
Training loss: 1.376475236358869
Validation loss: 2.6222143454509723

Epoch: 6| Step: 7
Training loss: 1.1194769601908712
Validation loss: 2.633732666045487

Epoch: 6| Step: 8
Training loss: 1.1824089641893265
Validation loss: 2.5845294203591385

Epoch: 6| Step: 9
Training loss: 1.2178427914324
Validation loss: 2.6145472859687797

Epoch: 6| Step: 10
Training loss: 1.9953841349648282
Validation loss: 2.5617548704339606

Epoch: 6| Step: 11
Training loss: 1.5056729331171517
Validation loss: 2.584406642574037

Epoch: 6| Step: 12
Training loss: 1.587639482633194
Validation loss: 2.5445461195848096

Epoch: 6| Step: 13
Training loss: 1.0566212199292542
Validation loss: 2.5596194708279567

Epoch: 397| Step: 0
Training loss: 1.2489599192367722
Validation loss: 2.543953833196603

Epoch: 6| Step: 1
Training loss: 1.8371030313819086
Validation loss: 2.5646627030123423

Epoch: 6| Step: 2
Training loss: 1.6212804479982486
Validation loss: 2.5675332639694384

Epoch: 6| Step: 3
Training loss: 1.2330685232447416
Validation loss: 2.559816436208946

Epoch: 6| Step: 4
Training loss: 1.2762437569580418
Validation loss: 2.571101167185743

Epoch: 6| Step: 5
Training loss: 1.1152785203951565
Validation loss: 2.5534051910262368

Epoch: 6| Step: 6
Training loss: 1.3363057125456743
Validation loss: 2.5191511946882463

Epoch: 6| Step: 7
Training loss: 1.4732197055469247
Validation loss: 2.558444263857324

Epoch: 6| Step: 8
Training loss: 1.354597179741418
Validation loss: 2.58177133734224

Epoch: 6| Step: 9
Training loss: 1.267705831574871
Validation loss: 2.627915163920271

Epoch: 6| Step: 10
Training loss: 1.0783364461788036
Validation loss: 2.6552413371686217

Epoch: 6| Step: 11
Training loss: 1.6418766152120197
Validation loss: 2.633356756898867

Epoch: 6| Step: 12
Training loss: 1.0666031428634317
Validation loss: 2.6461858189193204

Epoch: 6| Step: 13
Training loss: 1.4156287355352635
Validation loss: 2.6286425068527306

Epoch: 398| Step: 0
Training loss: 1.426568804055331
Validation loss: 2.644901672295138

Epoch: 6| Step: 1
Training loss: 1.1729119354387514
Validation loss: 2.673073869593329

Epoch: 6| Step: 2
Training loss: 1.6581939229721114
Validation loss: 2.6833053648618517

Epoch: 6| Step: 3
Training loss: 1.6269901266847664
Validation loss: 2.628246525008427

Epoch: 6| Step: 4
Training loss: 1.3741867955208145
Validation loss: 2.5868117975988896

Epoch: 6| Step: 5
Training loss: 1.1568112428841657
Validation loss: 2.628251952719812

Epoch: 6| Step: 6
Training loss: 0.8424601762794434
Validation loss: 2.607905524232531

Epoch: 6| Step: 7
Training loss: 1.2961921272859254
Validation loss: 2.5924641129533676

Epoch: 6| Step: 8
Training loss: 1.6200213826499081
Validation loss: 2.6290292848059003

Epoch: 6| Step: 9
Training loss: 1.67484091672276
Validation loss: 2.6076657146683093

Epoch: 6| Step: 10
Training loss: 1.3746018266700963
Validation loss: 2.5958648700135303

Epoch: 6| Step: 11
Training loss: 1.5798172140019815
Validation loss: 2.641688732652734

Epoch: 6| Step: 12
Training loss: 1.0575231790369606
Validation loss: 2.6174771428560013

Epoch: 6| Step: 13
Training loss: 1.0590822563681181
Validation loss: 2.70116376933079

Epoch: 399| Step: 0
Training loss: 1.62060980869504
Validation loss: 2.6375075227169127

Epoch: 6| Step: 1
Training loss: 1.3228244699305611
Validation loss: 2.6268949178418115

Epoch: 6| Step: 2
Training loss: 1.0424356419665495
Validation loss: 2.602425478901378

Epoch: 6| Step: 3
Training loss: 1.1091261033786017
Validation loss: 2.6185660000954094

Epoch: 6| Step: 4
Training loss: 0.9572269784505766
Validation loss: 2.620177387840276

Epoch: 6| Step: 5
Training loss: 1.9742186147420313
Validation loss: 2.610771490785743

Epoch: 6| Step: 6
Training loss: 1.0508153973671457
Validation loss: 2.6028371138059048

Epoch: 6| Step: 7
Training loss: 1.005859375
Validation loss: 2.5916128124353492

Epoch: 6| Step: 8
Training loss: 1.255359033847897
Validation loss: 2.649626848351704

Epoch: 6| Step: 9
Training loss: 1.1659309701524547
Validation loss: 2.6533199980015687

Epoch: 6| Step: 10
Training loss: 1.6630721749650754
Validation loss: 2.636737248862094

Epoch: 6| Step: 11
Training loss: 1.297227466898483
Validation loss: 2.6229766813587654

Epoch: 6| Step: 12
Training loss: 1.4419906796009996
Validation loss: 2.618841075906731

Epoch: 6| Step: 13
Training loss: 1.5398317534948567
Validation loss: 2.5736020574280642

Epoch: 400| Step: 0
Training loss: 1.1576696907547295
Validation loss: 2.605430492175526

Epoch: 6| Step: 1
Training loss: 1.223917058154056
Validation loss: 2.5885819726846715

Epoch: 6| Step: 2
Training loss: 1.0347887070451385
Validation loss: 2.5724777022255156

Epoch: 6| Step: 3
Training loss: 1.5344823857971708
Validation loss: 2.6030213596797815

Epoch: 6| Step: 4
Training loss: 0.9632808985403987
Validation loss: 2.591020457750515

Epoch: 6| Step: 5
Training loss: 1.1151515308615403
Validation loss: 2.6306254342597595

Epoch: 6| Step: 6
Training loss: 1.1487147716645416
Validation loss: 2.604914158671616

Epoch: 6| Step: 7
Training loss: 1.5551482624871014
Validation loss: 2.604567372329067

Epoch: 6| Step: 8
Training loss: 0.9413988421769941
Validation loss: 2.6279419050874173

Epoch: 6| Step: 9
Training loss: 1.419015545298166
Validation loss: 2.626573242552826

Epoch: 6| Step: 10
Training loss: 1.6969550828670843
Validation loss: 2.5935344223455283

Epoch: 6| Step: 11
Training loss: 1.2037123695425676
Validation loss: 2.5968289083161538

Epoch: 6| Step: 12
Training loss: 1.307747547355194
Validation loss: 2.6238652001652647

Epoch: 6| Step: 13
Training loss: 1.653377705460571
Validation loss: 2.643884997757656

Epoch: 401| Step: 0
Training loss: 1.3745557761034155
Validation loss: 2.6673811958596536

Epoch: 6| Step: 1
Training loss: 0.988024953546347
Validation loss: 2.6319655840004352

Epoch: 6| Step: 2
Training loss: 1.1931250509159164
Validation loss: 2.608239099874249

Epoch: 6| Step: 3
Training loss: 1.2138971891247938
Validation loss: 2.593109496057955

Epoch: 6| Step: 4
Training loss: 1.2374123975784743
Validation loss: 2.61510998461168

Epoch: 6| Step: 5
Training loss: 1.3959371708446189
Validation loss: 2.5984896515647593

Epoch: 6| Step: 6
Training loss: 1.3366851499203918
Validation loss: 2.6372510283294543

Epoch: 6| Step: 7
Training loss: 1.1991114366460784
Validation loss: 2.6205729892481395

Epoch: 6| Step: 8
Training loss: 1.3827248238392569
Validation loss: 2.6744895768945756

Epoch: 6| Step: 9
Training loss: 1.3069538830046856
Validation loss: 2.687500650568447

Epoch: 6| Step: 10
Training loss: 1.3475822096678758
Validation loss: 2.657798151377064

Epoch: 6| Step: 11
Training loss: 1.1594693497673523
Validation loss: 2.663173792058673

Epoch: 6| Step: 12
Training loss: 1.7823744453842914
Validation loss: 2.649144036227469

Epoch: 6| Step: 13
Training loss: 1.2494154994062445
Validation loss: 2.611736378870318

Epoch: 402| Step: 0
Training loss: 0.902107769383341
Validation loss: 2.632107588431958

Epoch: 6| Step: 1
Training loss: 0.9803850966554626
Validation loss: 2.57751066036098

Epoch: 6| Step: 2
Training loss: 1.1941176781962481
Validation loss: 2.606969459326512

Epoch: 6| Step: 3
Training loss: 1.524969181937581
Validation loss: 2.5569086092232953

Epoch: 6| Step: 4
Training loss: 1.3563403754293297
Validation loss: 2.5854444926995876

Epoch: 6| Step: 5
Training loss: 1.2088964180696302
Validation loss: 2.5956518944592277

Epoch: 6| Step: 6
Training loss: 1.5469052860878674
Validation loss: 2.615335976733096

Epoch: 6| Step: 7
Training loss: 1.3176550672216636
Validation loss: 2.624571644180203

Epoch: 6| Step: 8
Training loss: 1.3531290578450945
Validation loss: 2.5861455674225793

Epoch: 6| Step: 9
Training loss: 0.8507652050008095
Validation loss: 2.5767936120174864

Epoch: 6| Step: 10
Training loss: 1.5407488728645555
Validation loss: 2.6124370981093814

Epoch: 6| Step: 11
Training loss: 1.174866583534158
Validation loss: 2.572328822103752

Epoch: 6| Step: 12
Training loss: 1.092742564947335
Validation loss: 2.642695035037658

Epoch: 6| Step: 13
Training loss: 1.4662971305589632
Validation loss: 2.5762563927287485

Epoch: 403| Step: 0
Training loss: 1.539323194083525
Validation loss: 2.5608331329696514

Epoch: 6| Step: 1
Training loss: 0.7284362995231094
Validation loss: 2.563950539019124

Epoch: 6| Step: 2
Training loss: 0.9290371070365896
Validation loss: 2.574433429200351

Epoch: 6| Step: 3
Training loss: 1.2912511567427263
Validation loss: 2.595083682794091

Epoch: 6| Step: 4
Training loss: 0.9992877688815749
Validation loss: 2.5691167490718145

Epoch: 6| Step: 5
Training loss: 1.1564020623918718
Validation loss: 2.603946216153314

Epoch: 6| Step: 6
Training loss: 1.4831667349336997
Validation loss: 2.5836240594587707

Epoch: 6| Step: 7
Training loss: 1.5978753795371163
Validation loss: 2.6184746912389385

Epoch: 6| Step: 8
Training loss: 0.9558212727886366
Validation loss: 2.64391394453295

Epoch: 6| Step: 9
Training loss: 1.3513870566393689
Validation loss: 2.588076533711502

Epoch: 6| Step: 10
Training loss: 1.838974927763461
Validation loss: 2.5598994061330944

Epoch: 6| Step: 11
Training loss: 1.2911646031283235
Validation loss: 2.619597036565422

Epoch: 6| Step: 12
Training loss: 1.380893690662168
Validation loss: 2.5843207692272605

Epoch: 6| Step: 13
Training loss: 1.3426421722061186
Validation loss: 2.6005053505925906

Epoch: 404| Step: 0
Training loss: 0.8680527983727643
Validation loss: 2.6297757438228593

Epoch: 6| Step: 1
Training loss: 1.4376585499774424
Validation loss: 2.651753355675609

Epoch: 6| Step: 2
Training loss: 1.600929097785175
Validation loss: 2.6277887653173093

Epoch: 6| Step: 3
Training loss: 1.3084840643163462
Validation loss: 2.5781219944791904

Epoch: 6| Step: 4
Training loss: 1.356907237903004
Validation loss: 2.590308391763991

Epoch: 6| Step: 5
Training loss: 1.0633190588356718
Validation loss: 2.6042589145852175

Epoch: 6| Step: 6
Training loss: 0.9586202081512533
Validation loss: 2.6409777945476063

Epoch: 6| Step: 7
Training loss: 1.1633577197414522
Validation loss: 2.611048376962047

Epoch: 6| Step: 8
Training loss: 1.6651998582090803
Validation loss: 2.6471085041189832

Epoch: 6| Step: 9
Training loss: 1.1405456724408112
Validation loss: 2.6726912205428484

Epoch: 6| Step: 10
Training loss: 1.3832232624905347
Validation loss: 2.5924117990938345

Epoch: 6| Step: 11
Training loss: 1.1524936901755558
Validation loss: 2.6499156746553307

Epoch: 6| Step: 12
Training loss: 1.0858904053060858
Validation loss: 2.6413712961147673

Epoch: 6| Step: 13
Training loss: 1.3190645719546719
Validation loss: 2.616955244851895

Epoch: 405| Step: 0
Training loss: 1.2688467204993952
Validation loss: 2.639184577727742

Epoch: 6| Step: 1
Training loss: 1.0124898792279065
Validation loss: 2.608543034940524

Epoch: 6| Step: 2
Training loss: 1.1492279861462849
Validation loss: 2.6002152842866413

Epoch: 6| Step: 3
Training loss: 0.967550889187447
Validation loss: 2.667033525405197

Epoch: 6| Step: 4
Training loss: 1.4429328091972649
Validation loss: 2.643261107203235

Epoch: 6| Step: 5
Training loss: 0.949458872874149
Validation loss: 2.6712246674101214

Epoch: 6| Step: 6
Training loss: 1.8372286537831208
Validation loss: 2.6323177276476573

Epoch: 6| Step: 7
Training loss: 1.1894104798036957
Validation loss: 2.6685895146425795

Epoch: 6| Step: 8
Training loss: 1.5193946600473318
Validation loss: 2.6989735530147847

Epoch: 6| Step: 9
Training loss: 1.228740774607055
Validation loss: 2.709940980946601

Epoch: 6| Step: 10
Training loss: 0.9938814016353574
Validation loss: 2.655155719421869

Epoch: 6| Step: 11
Training loss: 1.2909479397619639
Validation loss: 2.6277023816286404

Epoch: 6| Step: 12
Training loss: 1.1911920073444104
Validation loss: 2.6287965869751

Epoch: 6| Step: 13
Training loss: 1.2681222461954433
Validation loss: 2.6066918807342803

Epoch: 406| Step: 0
Training loss: 1.7391806343856917
Validation loss: 2.5534379335430386

Epoch: 6| Step: 1
Training loss: 0.750984261303393
Validation loss: 2.5910058576389314

Epoch: 6| Step: 2
Training loss: 1.1119998450519262
Validation loss: 2.615003671078266

Epoch: 6| Step: 3
Training loss: 1.3681720785141689
Validation loss: 2.594219165331651

Epoch: 6| Step: 4
Training loss: 1.1390169906420682
Validation loss: 2.689679408013423

Epoch: 6| Step: 5
Training loss: 1.1651373899267827
Validation loss: 2.7042656404773475

Epoch: 6| Step: 6
Training loss: 2.014457186905082
Validation loss: 2.6660192468639545

Epoch: 6| Step: 7
Training loss: 1.0129197698681862
Validation loss: 2.686311325857208

Epoch: 6| Step: 8
Training loss: 1.2655250133060523
Validation loss: 2.597133283627943

Epoch: 6| Step: 9
Training loss: 1.1282341352176148
Validation loss: 2.6228945099185417

Epoch: 6| Step: 10
Training loss: 1.4793948503459042
Validation loss: 2.6283808008776623

Epoch: 6| Step: 11
Training loss: 1.1887826517556666
Validation loss: 2.682255395934165

Epoch: 6| Step: 12
Training loss: 1.2411944180401486
Validation loss: 2.6567174612364224

Epoch: 6| Step: 13
Training loss: 1.5969243320078799
Validation loss: 2.660727000427101

Epoch: 407| Step: 0
Training loss: 1.4954258795059658
Validation loss: 2.5915797549165926

Epoch: 6| Step: 1
Training loss: 1.8113855026664036
Validation loss: 2.6448298876838883

Epoch: 6| Step: 2
Training loss: 1.1386240823180651
Validation loss: 2.6271146703349033

Epoch: 6| Step: 3
Training loss: 1.1574787106626225
Validation loss: 2.602587401589463

Epoch: 6| Step: 4
Training loss: 1.5400581044221473
Validation loss: 2.6317568208578224

Epoch: 6| Step: 5
Training loss: 1.5300741546711796
Validation loss: 2.6799257430184626

Epoch: 6| Step: 6
Training loss: 1.0486292019954375
Validation loss: 2.6319336598784013

Epoch: 6| Step: 7
Training loss: 1.2377575750764438
Validation loss: 2.6124132403579883

Epoch: 6| Step: 8
Training loss: 0.7894603368400489
Validation loss: 2.5851518910888984

Epoch: 6| Step: 9
Training loss: 1.1668470220577896
Validation loss: 2.5276292799786746

Epoch: 6| Step: 10
Training loss: 1.2200518282059192
Validation loss: 2.617525084629477

Epoch: 6| Step: 11
Training loss: 1.3242446311739589
Validation loss: 2.5952394490886337

Epoch: 6| Step: 12
Training loss: 1.5940174551550141
Validation loss: 2.6407201249484196

Epoch: 6| Step: 13
Training loss: 1.1172194576360952
Validation loss: 2.5350893361528706

Epoch: 408| Step: 0
Training loss: 0.9084706558460015
Validation loss: 2.585840936031428

Epoch: 6| Step: 1
Training loss: 1.1173935280072527
Validation loss: 2.6424322621383167

Epoch: 6| Step: 2
Training loss: 1.026120752426875
Validation loss: 2.6172986362830777

Epoch: 6| Step: 3
Training loss: 1.053398870972419
Validation loss: 2.6166271919463995

Epoch: 6| Step: 4
Training loss: 1.3778221472309204
Validation loss: 2.603932260771959

Epoch: 6| Step: 5
Training loss: 1.120546001111373
Validation loss: 2.6306898349884738

Epoch: 6| Step: 6
Training loss: 1.2377026286066217
Validation loss: 2.636586443560357

Epoch: 6| Step: 7
Training loss: 1.169927632058169
Validation loss: 2.6731790108107827

Epoch: 6| Step: 8
Training loss: 1.2999166645335598
Validation loss: 2.716953897406342

Epoch: 6| Step: 9
Training loss: 1.2807511544819026
Validation loss: 2.6283577681739883

Epoch: 6| Step: 10
Training loss: 1.3994850625170798
Validation loss: 2.655563355500468

Epoch: 6| Step: 11
Training loss: 1.3036955757521922
Validation loss: 2.61805054967409

Epoch: 6| Step: 12
Training loss: 1.3155483993738013
Validation loss: 2.621619848749591

Epoch: 6| Step: 13
Training loss: 1.2865849585770062
Validation loss: 2.6417212383357596

Epoch: 409| Step: 0
Training loss: 1.327374863554605
Validation loss: 2.685833451210593

Epoch: 6| Step: 1
Training loss: 1.1897229419476185
Validation loss: 2.6540198444696803

Epoch: 6| Step: 2
Training loss: 1.1793415497047433
Validation loss: 2.6065465098278824

Epoch: 6| Step: 3
Training loss: 1.508221822729945
Validation loss: 2.588890686657581

Epoch: 6| Step: 4
Training loss: 1.2078023379590495
Validation loss: 2.6224254819879076

Epoch: 6| Step: 5
Training loss: 0.8316492269276288
Validation loss: 2.639852151126369

Epoch: 6| Step: 6
Training loss: 1.4264976896206465
Validation loss: 2.7081331227956422

Epoch: 6| Step: 7
Training loss: 1.0466438721545708
Validation loss: 2.7027346672818426

Epoch: 6| Step: 8
Training loss: 1.0442902269092575
Validation loss: 2.712960799142464

Epoch: 6| Step: 9
Training loss: 0.9990097149366065
Validation loss: 2.644482032246507

Epoch: 6| Step: 10
Training loss: 1.2228393417598304
Validation loss: 2.6618503249536114

Epoch: 6| Step: 11
Training loss: 1.2419776979246986
Validation loss: 2.633303354088632

Epoch: 6| Step: 12
Training loss: 1.4784638611211833
Validation loss: 2.626781585651586

Epoch: 6| Step: 13
Training loss: 1.486130730132059
Validation loss: 2.6020390911225055

Epoch: 410| Step: 0
Training loss: 1.4431996341007047
Validation loss: 2.640334796195084

Epoch: 6| Step: 1
Training loss: 1.3165815559273961
Validation loss: 2.627814040987843

Epoch: 6| Step: 2
Training loss: 1.3766814268181455
Validation loss: 2.6230827777873795

Epoch: 6| Step: 3
Training loss: 1.0449764059223186
Validation loss: 2.6473049566739326

Epoch: 6| Step: 4
Training loss: 0.9601933148573091
Validation loss: 2.6043720215256374

Epoch: 6| Step: 5
Training loss: 1.071398107913043
Validation loss: 2.642399449403809

Epoch: 6| Step: 6
Training loss: 1.2897677255334143
Validation loss: 2.6505016733742486

Epoch: 6| Step: 7
Training loss: 1.645657187906595
Validation loss: 2.6476841458070193

Epoch: 6| Step: 8
Training loss: 1.406677520191813
Validation loss: 2.6224463621169023

Epoch: 6| Step: 9
Training loss: 1.2551992054629804
Validation loss: 2.6057095547434357

Epoch: 6| Step: 10
Training loss: 1.168403008914274
Validation loss: 2.596487018294424

Epoch: 6| Step: 11
Training loss: 1.198085087532761
Validation loss: 2.5873170843293183

Epoch: 6| Step: 12
Training loss: 1.0660176110450077
Validation loss: 2.638780344576721

Epoch: 6| Step: 13
Training loss: 1.2850599165874195
Validation loss: 2.6287414438661987

Epoch: 411| Step: 0
Training loss: 1.6372858853894776
Validation loss: 2.6137987659343724

Epoch: 6| Step: 1
Training loss: 1.0067181818982844
Validation loss: 2.6027385814116917

Epoch: 6| Step: 2
Training loss: 1.208861213782973
Validation loss: 2.5513653166827663

Epoch: 6| Step: 3
Training loss: 1.189855347825432
Validation loss: 2.6077899192105187

Epoch: 6| Step: 4
Training loss: 1.3425414394752864
Validation loss: 2.644290569402829

Epoch: 6| Step: 5
Training loss: 1.1581453305728087
Validation loss: 2.6141101566036107

Epoch: 6| Step: 6
Training loss: 0.8946995472738141
Validation loss: 2.599831968771003

Epoch: 6| Step: 7
Training loss: 1.151563063146487
Validation loss: 2.6079995952373807

Epoch: 6| Step: 8
Training loss: 1.1155336850191546
Validation loss: 2.609879542015527

Epoch: 6| Step: 9
Training loss: 1.2743309023094953
Validation loss: 2.6082893443029143

Epoch: 6| Step: 10
Training loss: 0.9458670762774851
Validation loss: 2.5410256489451672

Epoch: 6| Step: 11
Training loss: 1.057401090825649
Validation loss: 2.5441110509380294

Epoch: 6| Step: 12
Training loss: 1.5592046701980804
Validation loss: 2.5782471598958443

Epoch: 6| Step: 13
Training loss: 1.2692188524140275
Validation loss: 2.5867656292205847

Epoch: 412| Step: 0
Training loss: 1.0040487344168032
Validation loss: 2.5912548917634353

Epoch: 6| Step: 1
Training loss: 1.0926916178736068
Validation loss: 2.5851481866696386

Epoch: 6| Step: 2
Training loss: 1.5664022164994438
Validation loss: 2.5746128241800896

Epoch: 6| Step: 3
Training loss: 1.1960407606629873
Validation loss: 2.61231309930986

Epoch: 6| Step: 4
Training loss: 1.2513048037665808
Validation loss: 2.627449089038588

Epoch: 6| Step: 5
Training loss: 1.2726125092597373
Validation loss: 2.636802223673866

Epoch: 6| Step: 6
Training loss: 1.2780170124575256
Validation loss: 2.6908651766798344

Epoch: 6| Step: 7
Training loss: 1.374132749849513
Validation loss: 2.6970660416415977

Epoch: 6| Step: 8
Training loss: 1.3424676498408223
Validation loss: 2.7579475780398623

Epoch: 6| Step: 9
Training loss: 1.0536849731979787
Validation loss: 2.724401526686971

Epoch: 6| Step: 10
Training loss: 0.6611517673857404
Validation loss: 2.635201401393906

Epoch: 6| Step: 11
Training loss: 0.9594696743751374
Validation loss: 2.583739376972115

Epoch: 6| Step: 12
Training loss: 0.8699197427409179
Validation loss: 2.650621029821539

Epoch: 6| Step: 13
Training loss: 1.5708165664520042
Validation loss: 2.5721645620194056

Epoch: 413| Step: 0
Training loss: 1.0220842806260553
Validation loss: 2.652556660364888

Epoch: 6| Step: 1
Training loss: 1.1430383521560035
Validation loss: 2.6516612714700183

Epoch: 6| Step: 2
Training loss: 1.9164352968411846
Validation loss: 2.6338224049401218

Epoch: 6| Step: 3
Training loss: 1.2706834464978338
Validation loss: 2.6537326777320036

Epoch: 6| Step: 4
Training loss: 0.965450389593023
Validation loss: 2.5999251703351316

Epoch: 6| Step: 5
Training loss: 1.1950317252508735
Validation loss: 2.615778088998492

Epoch: 6| Step: 6
Training loss: 1.4052832777409123
Validation loss: 2.7094275147167663

Epoch: 6| Step: 7
Training loss: 1.0413304867267978
Validation loss: 2.6592731401037324

Epoch: 6| Step: 8
Training loss: 1.0257762365516467
Validation loss: 2.63776293765222

Epoch: 6| Step: 9
Training loss: 1.4605862608356266
Validation loss: 2.6009292824730825

Epoch: 6| Step: 10
Training loss: 1.1744232446364553
Validation loss: 2.626509951206336

Epoch: 6| Step: 11
Training loss: 1.2118352699948098
Validation loss: 2.6009465463091326

Epoch: 6| Step: 12
Training loss: 1.0423392349806417
Validation loss: 2.5981225381594366

Epoch: 6| Step: 13
Training loss: 1.0379739092633014
Validation loss: 2.607975681655226

Epoch: 414| Step: 0
Training loss: 0.9659986495251427
Validation loss: 2.562730344638478

Epoch: 6| Step: 1
Training loss: 1.850854279481043
Validation loss: 2.6232099787717456

Epoch: 6| Step: 2
Training loss: 1.273250074577217
Validation loss: 2.582584346872181

Epoch: 6| Step: 3
Training loss: 0.9251151928185338
Validation loss: 2.6169275107231376

Epoch: 6| Step: 4
Training loss: 1.2800966514664593
Validation loss: 2.5991352125586173

Epoch: 6| Step: 5
Training loss: 0.9906689294166274
Validation loss: 2.6120891047142316

Epoch: 6| Step: 6
Training loss: 0.998692372823528
Validation loss: 2.6302247578828855

Epoch: 6| Step: 7
Training loss: 1.281881595410473
Validation loss: 2.6598389109973266

Epoch: 6| Step: 8
Training loss: 1.2493499019023546
Validation loss: 2.675550524191845

Epoch: 6| Step: 9
Training loss: 0.8728409082561012
Validation loss: 2.697258700896631

Epoch: 6| Step: 10
Training loss: 1.5673992405681125
Validation loss: 2.6349488447509075

Epoch: 6| Step: 11
Training loss: 1.1967593642665921
Validation loss: 2.6345376117999697

Epoch: 6| Step: 12
Training loss: 1.0464240284230133
Validation loss: 2.626282030721558

Epoch: 6| Step: 13
Training loss: 1.003314723436837
Validation loss: 2.6808055476712305

Epoch: 415| Step: 0
Training loss: 0.9898910980823205
Validation loss: 2.6386099807403607

Epoch: 6| Step: 1
Training loss: 1.445772994630192
Validation loss: 2.6525043631807494

Epoch: 6| Step: 2
Training loss: 1.273328156252684
Validation loss: 2.674732977472368

Epoch: 6| Step: 3
Training loss: 1.1245286801939447
Validation loss: 2.645505108837212

Epoch: 6| Step: 4
Training loss: 1.3796915730365498
Validation loss: 2.6622132327484

Epoch: 6| Step: 5
Training loss: 1.4421655985945343
Validation loss: 2.713343524593488

Epoch: 6| Step: 6
Training loss: 1.4092332772938831
Validation loss: 2.6850198346476275

Epoch: 6| Step: 7
Training loss: 1.2793613563186532
Validation loss: 2.6816421734758404

Epoch: 6| Step: 8
Training loss: 1.0011386349354787
Validation loss: 2.6998345812999087

Epoch: 6| Step: 9
Training loss: 1.0130013249078882
Validation loss: 2.6301499061263973

Epoch: 6| Step: 10
Training loss: 0.7898317873810112
Validation loss: 2.5760973113873673

Epoch: 6| Step: 11
Training loss: 1.229754625206656
Validation loss: 2.6302510374524197

Epoch: 6| Step: 12
Training loss: 1.6909020357320377
Validation loss: 2.6038350975035365

Epoch: 6| Step: 13
Training loss: 0.6431895770246149
Validation loss: 2.62871675153171

Epoch: 416| Step: 0
Training loss: 1.0696584554836344
Validation loss: 2.587445245000668

Epoch: 6| Step: 1
Training loss: 1.439967318534864
Validation loss: 2.586435798201687

Epoch: 6| Step: 2
Training loss: 1.3000676485946978
Validation loss: 2.595939493432272

Epoch: 6| Step: 3
Training loss: 1.1343171223148956
Validation loss: 2.6374702644781167

Epoch: 6| Step: 4
Training loss: 1.4406508040030752
Validation loss: 2.679674317204234

Epoch: 6| Step: 5
Training loss: 1.7358726015500838
Validation loss: 2.6976953265934434

Epoch: 6| Step: 6
Training loss: 0.9632418844899426
Validation loss: 2.632602113492444

Epoch: 6| Step: 7
Training loss: 0.8254027698379787
Validation loss: 2.6001504420502575

Epoch: 6| Step: 8
Training loss: 1.1109368518768437
Validation loss: 2.6392943210241473

Epoch: 6| Step: 9
Training loss: 1.0621676205612283
Validation loss: 2.6163002825730493

Epoch: 6| Step: 10
Training loss: 1.0043353043351286
Validation loss: 2.6080835310132287

Epoch: 6| Step: 11
Training loss: 1.3107092311935404
Validation loss: 2.609327776513918

Epoch: 6| Step: 12
Training loss: 1.079854545423385
Validation loss: 2.6424836158064062

Epoch: 6| Step: 13
Training loss: 1.2515435701955564
Validation loss: 2.63462754951266

Epoch: 417| Step: 0
Training loss: 1.2595309253271507
Validation loss: 2.6070703314729857

Epoch: 6| Step: 1
Training loss: 0.9589043174004376
Validation loss: 2.6542838355710883

Epoch: 6| Step: 2
Training loss: 1.1706991781754352
Validation loss: 2.6632504982971263

Epoch: 6| Step: 3
Training loss: 1.1761451740965216
Validation loss: 2.7425420229441415

Epoch: 6| Step: 4
Training loss: 1.2890584309831612
Validation loss: 2.7085444050238503

Epoch: 6| Step: 5
Training loss: 1.375941517737607
Validation loss: 2.668947664872347

Epoch: 6| Step: 6
Training loss: 0.6648317033368862
Validation loss: 2.698901086453115

Epoch: 6| Step: 7
Training loss: 1.0780949795731236
Validation loss: 2.6889773603427063

Epoch: 6| Step: 8
Training loss: 1.0598089134073283
Validation loss: 2.6471520138939666

Epoch: 6| Step: 9
Training loss: 1.1722726274463622
Validation loss: 2.701125888612301

Epoch: 6| Step: 10
Training loss: 0.8924207152083845
Validation loss: 2.6582940782341247

Epoch: 6| Step: 11
Training loss: 1.5480988410276608
Validation loss: 2.6727073666775523

Epoch: 6| Step: 12
Training loss: 0.7390307703929214
Validation loss: 2.6644505342184677

Epoch: 6| Step: 13
Training loss: 1.6185123342775292
Validation loss: 2.664299008190057

Epoch: 418| Step: 0
Training loss: 1.0490532035063456
Validation loss: 2.665123542703779

Epoch: 6| Step: 1
Training loss: 1.3218161693855575
Validation loss: 2.7411735522152663

Epoch: 6| Step: 2
Training loss: 1.3011911107350387
Validation loss: 2.7177933219194133

Epoch: 6| Step: 3
Training loss: 1.6132799938280142
Validation loss: 2.704770552022845

Epoch: 6| Step: 4
Training loss: 1.5210663952202128
Validation loss: 2.69747646280272

Epoch: 6| Step: 5
Training loss: 1.119806807068188
Validation loss: 2.6656204098374623

Epoch: 6| Step: 6
Training loss: 1.0298731889714596
Validation loss: 2.629592904081675

Epoch: 6| Step: 7
Training loss: 1.2174227897240606
Validation loss: 2.6584021731783807

Epoch: 6| Step: 8
Training loss: 0.7745643267899716
Validation loss: 2.657828471595338

Epoch: 6| Step: 9
Training loss: 1.0356311788242263
Validation loss: 2.6103174179057005

Epoch: 6| Step: 10
Training loss: 1.0244297720956437
Validation loss: 2.602022804266858

Epoch: 6| Step: 11
Training loss: 0.8329478484883622
Validation loss: 2.6466840342601228

Epoch: 6| Step: 12
Training loss: 1.044470402522398
Validation loss: 2.62525166712934

Epoch: 6| Step: 13
Training loss: 0.7971102797291769
Validation loss: 2.6305830786112323

Epoch: 419| Step: 0
Training loss: 1.1164555853052778
Validation loss: 2.641385091301787

Epoch: 6| Step: 1
Training loss: 0.9335865994103776
Validation loss: 2.6354185916054274

Epoch: 6| Step: 2
Training loss: 0.8547922882615824
Validation loss: 2.696500418748522

Epoch: 6| Step: 3
Training loss: 1.190809657077502
Validation loss: 2.607626109988589

Epoch: 6| Step: 4
Training loss: 1.028142176429558
Validation loss: 2.6655349018571863

Epoch: 6| Step: 5
Training loss: 1.3647510726373848
Validation loss: 2.6306004801584986

Epoch: 6| Step: 6
Training loss: 1.1692354102032947
Validation loss: 2.6624045335492252

Epoch: 6| Step: 7
Training loss: 1.3831578917111054
Validation loss: 2.6485164484280617

Epoch: 6| Step: 8
Training loss: 1.0356405600723897
Validation loss: 2.6681136933884897

Epoch: 6| Step: 9
Training loss: 1.4274441153949542
Validation loss: 2.6366448888912153

Epoch: 6| Step: 10
Training loss: 1.1666690905863695
Validation loss: 2.6300153504130357

Epoch: 6| Step: 11
Training loss: 1.2738183511021555
Validation loss: 2.602142429724251

Epoch: 6| Step: 12
Training loss: 1.061357164038316
Validation loss: 2.6383656122382178

Epoch: 6| Step: 13
Training loss: 0.8202577481844189
Validation loss: 2.6542636849613888

Epoch: 420| Step: 0
Training loss: 1.1428026810084198
Validation loss: 2.5951803468867887

Epoch: 6| Step: 1
Training loss: 1.1744920119480424
Validation loss: 2.62866587718449

Epoch: 6| Step: 2
Training loss: 1.1365401399692632
Validation loss: 2.5916452102345353

Epoch: 6| Step: 3
Training loss: 1.4407647418847151
Validation loss: 2.619579311634939

Epoch: 6| Step: 4
Training loss: 0.8087286352905655
Validation loss: 2.5608440258755842

Epoch: 6| Step: 5
Training loss: 1.0464981881284088
Validation loss: 2.578242844479602

Epoch: 6| Step: 6
Training loss: 1.2018784344525395
Validation loss: 2.594983263470157

Epoch: 6| Step: 7
Training loss: 0.7744772501658619
Validation loss: 2.6268640514904686

Epoch: 6| Step: 8
Training loss: 1.1673058507274159
Validation loss: 2.6596323954854744

Epoch: 6| Step: 9
Training loss: 1.0716676695024496
Validation loss: 2.6496724388119515

Epoch: 6| Step: 10
Training loss: 1.1801054258449555
Validation loss: 2.626031718272444

Epoch: 6| Step: 11
Training loss: 1.0412533257878966
Validation loss: 2.6433610003187193

Epoch: 6| Step: 12
Training loss: 0.6133201732553949
Validation loss: 2.685704304097806

Epoch: 6| Step: 13
Training loss: 1.5602925538572683
Validation loss: 2.668522417547679

Epoch: 421| Step: 0
Training loss: 1.1146782926709093
Validation loss: 2.6617882605574477

Epoch: 6| Step: 1
Training loss: 1.0505120028173665
Validation loss: 2.6763220989927325

Epoch: 6| Step: 2
Training loss: 1.0498407969807264
Validation loss: 2.6587677037711237

Epoch: 6| Step: 3
Training loss: 0.7422376515359312
Validation loss: 2.6562281065393893

Epoch: 6| Step: 4
Training loss: 1.0885248989048844
Validation loss: 2.6070515230309113

Epoch: 6| Step: 5
Training loss: 0.8695313679025849
Validation loss: 2.6628307280393915

Epoch: 6| Step: 6
Training loss: 1.0207772661239682
Validation loss: 2.6094438920663316

Epoch: 6| Step: 7
Training loss: 1.0987036652500133
Validation loss: 2.551682761278811

Epoch: 6| Step: 8
Training loss: 1.597231484354042
Validation loss: 2.5834512273487498

Epoch: 6| Step: 9
Training loss: 1.3601492945686606
Validation loss: 2.6105112582820458

Epoch: 6| Step: 10
Training loss: 1.1158311519834143
Validation loss: 2.5975031680937444

Epoch: 6| Step: 11
Training loss: 1.0077297561152834
Validation loss: 2.648501190049889

Epoch: 6| Step: 12
Training loss: 1.0884205265567188
Validation loss: 2.632920833664237

Epoch: 6| Step: 13
Training loss: 0.9226789040493568
Validation loss: 2.6583442809338895

Epoch: 422| Step: 0
Training loss: 1.0459463641016462
Validation loss: 2.6586627997198398

Epoch: 6| Step: 1
Training loss: 1.0292092562883777
Validation loss: 2.689113738661458

Epoch: 6| Step: 2
Training loss: 0.9737310331306815
Validation loss: 2.6464404488421964

Epoch: 6| Step: 3
Training loss: 1.0942673685683835
Validation loss: 2.6888566991448566

Epoch: 6| Step: 4
Training loss: 0.9955491615526
Validation loss: 2.6577765173609595

Epoch: 6| Step: 5
Training loss: 1.1078732494059362
Validation loss: 2.6164978257353746

Epoch: 6| Step: 6
Training loss: 1.441775721723212
Validation loss: 2.6311183953918253

Epoch: 6| Step: 7
Training loss: 1.3726171306665569
Validation loss: 2.579612464668408

Epoch: 6| Step: 8
Training loss: 1.0060206015545896
Validation loss: 2.6022525975618773

Epoch: 6| Step: 9
Training loss: 1.1266488601661875
Validation loss: 2.6598808605359534

Epoch: 6| Step: 10
Training loss: 0.8154827534660445
Validation loss: 2.5987213169390837

Epoch: 6| Step: 11
Training loss: 1.04762838783167
Validation loss: 2.642781507546325

Epoch: 6| Step: 12
Training loss: 1.059675164022952
Validation loss: 2.6393073893414796

Epoch: 6| Step: 13
Training loss: 0.8282857055198809
Validation loss: 2.624043653755977

Epoch: 423| Step: 0
Training loss: 1.1416282944368064
Validation loss: 2.727005945267985

Epoch: 6| Step: 1
Training loss: 0.9841970858178253
Validation loss: 2.706834500618388

Epoch: 6| Step: 2
Training loss: 0.9348753747144902
Validation loss: 2.697180442560685

Epoch: 6| Step: 3
Training loss: 1.0289179703516331
Validation loss: 2.682874573019288

Epoch: 6| Step: 4
Training loss: 0.8890886272754667
Validation loss: 2.686087481098805

Epoch: 6| Step: 5
Training loss: 0.9386573006160863
Validation loss: 2.6685816375965596

Epoch: 6| Step: 6
Training loss: 1.3973641991870545
Validation loss: 2.663840880363024

Epoch: 6| Step: 7
Training loss: 1.0114329755585594
Validation loss: 2.7069989634134792

Epoch: 6| Step: 8
Training loss: 1.1509982254783546
Validation loss: 2.65386978167779

Epoch: 6| Step: 9
Training loss: 1.173590104380951
Validation loss: 2.6737173618050334

Epoch: 6| Step: 10
Training loss: 0.7374758894260485
Validation loss: 2.6726553151146604

Epoch: 6| Step: 11
Training loss: 1.0854878764061942
Validation loss: 2.7186599950398294

Epoch: 6| Step: 12
Training loss: 1.1125086194679585
Validation loss: 2.6776466123378513

Epoch: 6| Step: 13
Training loss: 1.0587392334013421
Validation loss: 2.6902869508037988

Epoch: 424| Step: 0
Training loss: 1.0792464905505705
Validation loss: 2.7481283118411883

Epoch: 6| Step: 1
Training loss: 1.2292901101061082
Validation loss: 2.70443712850048

Epoch: 6| Step: 2
Training loss: 0.9193572561184221
Validation loss: 2.740743157084529

Epoch: 6| Step: 3
Training loss: 1.2231755235594508
Validation loss: 2.692975137406224

Epoch: 6| Step: 4
Training loss: 1.0865823491466493
Validation loss: 2.6679300553963294

Epoch: 6| Step: 5
Training loss: 1.3354352040226685
Validation loss: 2.611584730909952

Epoch: 6| Step: 6
Training loss: 1.1413201082219495
Validation loss: 2.635324413710358

Epoch: 6| Step: 7
Training loss: 0.878946566186876
Validation loss: 2.6574703479977466

Epoch: 6| Step: 8
Training loss: 0.8633229172261132
Validation loss: 2.685688665172636

Epoch: 6| Step: 9
Training loss: 1.0979097555523292
Validation loss: 2.646891875290174

Epoch: 6| Step: 10
Training loss: 1.3188748630512404
Validation loss: 2.6620469360044656

Epoch: 6| Step: 11
Training loss: 0.8553346851107272
Validation loss: 2.662007856777299

Epoch: 6| Step: 12
Training loss: 0.9764532104372996
Validation loss: 2.6648253004154348

Epoch: 6| Step: 13
Training loss: 1.3558108642832736
Validation loss: 2.698712019365236

Epoch: 425| Step: 0
Training loss: 1.294201865044059
Validation loss: 2.7070057965467753

Epoch: 6| Step: 1
Training loss: 0.9508495998969266
Validation loss: 2.697669225315942

Epoch: 6| Step: 2
Training loss: 0.9832826032861102
Validation loss: 2.7347102659046003

Epoch: 6| Step: 3
Training loss: 1.0177959421349423
Validation loss: 2.708408388907352

Epoch: 6| Step: 4
Training loss: 0.8883389698288711
Validation loss: 2.6988186206135865

Epoch: 6| Step: 5
Training loss: 0.9563051232799565
Validation loss: 2.6559081362469943

Epoch: 6| Step: 6
Training loss: 1.0847445734912105
Validation loss: 2.699548269676977

Epoch: 6| Step: 7
Training loss: 0.8795797861396055
Validation loss: 2.6654868545899797

Epoch: 6| Step: 8
Training loss: 1.3503385966912562
Validation loss: 2.679638015987128

Epoch: 6| Step: 9
Training loss: 1.184110925066283
Validation loss: 2.726441549188905

Epoch: 6| Step: 10
Training loss: 1.3643499519400981
Validation loss: 2.6964344140683925

Epoch: 6| Step: 11
Training loss: 1.1851499794961993
Validation loss: 2.6759523582974083

Epoch: 6| Step: 12
Training loss: 0.9505440208358974
Validation loss: 2.7051305221826296

Epoch: 6| Step: 13
Training loss: 0.9901249390573077
Validation loss: 2.7103533376517617

Epoch: 426| Step: 0
Training loss: 1.5538846343825576
Validation loss: 2.6638271790924453

Epoch: 6| Step: 1
Training loss: 0.5967393711040058
Validation loss: 2.6831063573417544

Epoch: 6| Step: 2
Training loss: 0.8057196950489333
Validation loss: 2.592137827674197

Epoch: 6| Step: 3
Training loss: 0.953588216816505
Validation loss: 2.6243428134239037

Epoch: 6| Step: 4
Training loss: 1.1601113461625117
Validation loss: 2.7059726746253916

Epoch: 6| Step: 5
Training loss: 1.0424033357552227
Validation loss: 2.622559381642422

Epoch: 6| Step: 6
Training loss: 1.064989875064772
Validation loss: 2.6951346223526502

Epoch: 6| Step: 7
Training loss: 1.1454160739753294
Validation loss: 2.6593982962974945

Epoch: 6| Step: 8
Training loss: 1.1140269141378873
Validation loss: 2.6841683177554065

Epoch: 6| Step: 9
Training loss: 0.9628751494303417
Validation loss: 2.6843762614995135

Epoch: 6| Step: 10
Training loss: 1.272719057709946
Validation loss: 2.6715883692426967

Epoch: 6| Step: 11
Training loss: 0.6790791123557403
Validation loss: 2.670941976300469

Epoch: 6| Step: 12
Training loss: 1.0025090093992657
Validation loss: 2.6907329039991796

Epoch: 6| Step: 13
Training loss: 1.02508243834044
Validation loss: 2.6157024060656395

Epoch: 427| Step: 0
Training loss: 1.2305646102137764
Validation loss: 2.6376630133080448

Epoch: 6| Step: 1
Training loss: 0.84473679376481
Validation loss: 2.646638332266521

Epoch: 6| Step: 2
Training loss: 1.4886338824927192
Validation loss: 2.70508948735721

Epoch: 6| Step: 3
Training loss: 0.7539114284831661
Validation loss: 2.737070901762842

Epoch: 6| Step: 4
Training loss: 0.8664688362927486
Validation loss: 2.626767343146487

Epoch: 6| Step: 5
Training loss: 1.1088857512173784
Validation loss: 2.6167995184280324

Epoch: 6| Step: 6
Training loss: 1.1785783416578326
Validation loss: 2.7448785660732984

Epoch: 6| Step: 7
Training loss: 1.1632828117447227
Validation loss: 2.7105084903379764

Epoch: 6| Step: 8
Training loss: 1.0046476602441927
Validation loss: 2.7104928919057385

Epoch: 6| Step: 9
Training loss: 0.8479854805755985
Validation loss: 2.69806345732999

Epoch: 6| Step: 10
Training loss: 1.1939211957315803
Validation loss: 2.654229431568005

Epoch: 6| Step: 11
Training loss: 0.9341807415458001
Validation loss: 2.687347392990908

Epoch: 6| Step: 12
Training loss: 1.1325635965439975
Validation loss: 2.6531371782470425

Epoch: 6| Step: 13
Training loss: 0.9805500255197038
Validation loss: 2.6437916850838588

Epoch: 428| Step: 0
Training loss: 0.9759868909080517
Validation loss: 2.6901531282728715

Epoch: 6| Step: 1
Training loss: 0.9703644866039681
Validation loss: 2.6572256951621

Epoch: 6| Step: 2
Training loss: 0.9143572926974192
Validation loss: 2.6590273530147845

Epoch: 6| Step: 3
Training loss: 1.1724821933622387
Validation loss: 2.665614909145132

Epoch: 6| Step: 4
Training loss: 0.9309943494696984
Validation loss: 2.660763186294649

Epoch: 6| Step: 5
Training loss: 1.1868329433323919
Validation loss: 2.6810695543013856

Epoch: 6| Step: 6
Training loss: 0.9115126166754806
Validation loss: 2.765378592625971

Epoch: 6| Step: 7
Training loss: 1.0018997624336172
Validation loss: 2.6728809834985245

Epoch: 6| Step: 8
Training loss: 1.041851516852584
Validation loss: 2.692615364776808

Epoch: 6| Step: 9
Training loss: 1.196321149123261
Validation loss: 2.6639750625714735

Epoch: 6| Step: 10
Training loss: 0.8885119954589085
Validation loss: 2.694843859634667

Epoch: 6| Step: 11
Training loss: 0.7859143445223304
Validation loss: 2.6470422511007925

Epoch: 6| Step: 12
Training loss: 0.9860556348827767
Validation loss: 2.65239372824323

Epoch: 6| Step: 13
Training loss: 1.2670014043678262
Validation loss: 2.690074803554309

Epoch: 429| Step: 0
Training loss: 0.8854275347472741
Validation loss: 2.638772397370173

Epoch: 6| Step: 1
Training loss: 0.7773776406419495
Validation loss: 2.682603115530453

Epoch: 6| Step: 2
Training loss: 0.954032559666929
Validation loss: 2.6852583592652355

Epoch: 6| Step: 3
Training loss: 0.9055184667464129
Validation loss: 2.7048136704647856

Epoch: 6| Step: 4
Training loss: 0.905618381726162
Validation loss: 2.731575642834787

Epoch: 6| Step: 5
Training loss: 1.0220127817761828
Validation loss: 2.665395647373263

Epoch: 6| Step: 6
Training loss: 0.9196358659295989
Validation loss: 2.6358295062030606

Epoch: 6| Step: 7
Training loss: 0.9298428958561339
Validation loss: 2.667071674307336

Epoch: 6| Step: 8
Training loss: 1.2246759083270589
Validation loss: 2.686959951684142

Epoch: 6| Step: 9
Training loss: 1.3019532202243627
Validation loss: 2.6489556329923167

Epoch: 6| Step: 10
Training loss: 0.8573511046658499
Validation loss: 2.717451406615861

Epoch: 6| Step: 11
Training loss: 0.9225885571511742
Validation loss: 2.685594459805699

Epoch: 6| Step: 12
Training loss: 1.3355995330738897
Validation loss: 2.782790368242197

Epoch: 6| Step: 13
Training loss: 1.2695542084011824
Validation loss: 2.7929518194507974

Epoch: 430| Step: 0
Training loss: 1.119395281992926
Validation loss: 2.774081260219789

Epoch: 6| Step: 1
Training loss: 1.0319872446085117
Validation loss: 2.702334742344047

Epoch: 6| Step: 2
Training loss: 0.6880325075747837
Validation loss: 2.7229978182042953

Epoch: 6| Step: 3
Training loss: 1.1266488072618193
Validation loss: 2.668940339756695

Epoch: 6| Step: 4
Training loss: 0.9707970986269083
Validation loss: 2.6260964813221244

Epoch: 6| Step: 5
Training loss: 1.4944708166352034
Validation loss: 2.6259314231827973

Epoch: 6| Step: 6
Training loss: 1.119538028587376
Validation loss: 2.654528220646482

Epoch: 6| Step: 7
Training loss: 1.3316597070778675
Validation loss: 2.7017875405565555

Epoch: 6| Step: 8
Training loss: 0.9183075949067245
Validation loss: 2.6640454960165734

Epoch: 6| Step: 9
Training loss: 0.7622869475341024
Validation loss: 2.6572744301406783

Epoch: 6| Step: 10
Training loss: 0.6654682091170883
Validation loss: 2.6751189291592397

Epoch: 6| Step: 11
Training loss: 1.0911039770773203
Validation loss: 2.739650121147908

Epoch: 6| Step: 12
Training loss: 0.9915272175221973
Validation loss: 2.7512121996780747

Epoch: 6| Step: 13
Training loss: 1.1502943532974095
Validation loss: 2.7892496596511642

Epoch: 431| Step: 0
Training loss: 1.2493635464668538
Validation loss: 2.788735898624996

Epoch: 6| Step: 1
Training loss: 1.038466949734079
Validation loss: 2.6944175966854442

Epoch: 6| Step: 2
Training loss: 0.874754394393746
Validation loss: 2.6875298594508985

Epoch: 6| Step: 3
Training loss: 0.9927848159345116
Validation loss: 2.6383219500320414

Epoch: 6| Step: 4
Training loss: 0.8224839308076284
Validation loss: 2.6208883205966864

Epoch: 6| Step: 5
Training loss: 1.4893874815475083
Validation loss: 2.67550645145776

Epoch: 6| Step: 6
Training loss: 1.493617545923112
Validation loss: 2.6517117720731234

Epoch: 6| Step: 7
Training loss: 1.3359672141535102
Validation loss: 2.670334310425804

Epoch: 6| Step: 8
Training loss: 0.8476791378745918
Validation loss: 2.6364334743317004

Epoch: 6| Step: 9
Training loss: 1.3090820767816338
Validation loss: 2.642860399401314

Epoch: 6| Step: 10
Training loss: 1.3686742927133182
Validation loss: 2.711666643071971

Epoch: 6| Step: 11
Training loss: 1.2012453134308374
Validation loss: 2.73388395714125

Epoch: 6| Step: 12
Training loss: 1.3872649500624432
Validation loss: 2.762195047891225

Epoch: 6| Step: 13
Training loss: 1.2605889993348904
Validation loss: 2.7274573969813583

Epoch: 432| Step: 0
Training loss: 1.013885416753621
Validation loss: 2.6711634158696653

Epoch: 6| Step: 1
Training loss: 1.166566600368272
Validation loss: 2.6280953458911505

Epoch: 6| Step: 2
Training loss: 1.1556157615048894
Validation loss: 2.702953810958261

Epoch: 6| Step: 3
Training loss: 1.4141652612598623
Validation loss: 2.676666736966992

Epoch: 6| Step: 4
Training loss: 1.2819686827888692
Validation loss: 2.665764497100955

Epoch: 6| Step: 5
Training loss: 1.4379472451434627
Validation loss: 2.636998426887044

Epoch: 6| Step: 6
Training loss: 0.936781098976814
Validation loss: 2.6375002458762102

Epoch: 6| Step: 7
Training loss: 0.9086042933291032
Validation loss: 2.670712699685131

Epoch: 6| Step: 8
Training loss: 0.8758991594255885
Validation loss: 2.6609294438011504

Epoch: 6| Step: 9
Training loss: 1.3571055970060586
Validation loss: 2.6415806382267792

Epoch: 6| Step: 10
Training loss: 0.9647463853644286
Validation loss: 2.6240938378560443

Epoch: 6| Step: 11
Training loss: 1.147591882904082
Validation loss: 2.5986279957413787

Epoch: 6| Step: 12
Training loss: 0.9392166315872552
Validation loss: 2.5627048689660623

Epoch: 6| Step: 13
Training loss: 0.9182628403993203
Validation loss: 2.5952997901294474

Epoch: 433| Step: 0
Training loss: 1.0333224770273055
Validation loss: 2.6160414506635137

Epoch: 6| Step: 1
Training loss: 1.0674153678096536
Validation loss: 2.591616078299056

Epoch: 6| Step: 2
Training loss: 0.8185816715555904
Validation loss: 2.627924334727222

Epoch: 6| Step: 3
Training loss: 1.0411363141666483
Validation loss: 2.6365359848164363

Epoch: 6| Step: 4
Training loss: 0.6959200786916068
Validation loss: 2.6315549418542408

Epoch: 6| Step: 5
Training loss: 1.135870233404234
Validation loss: 2.6681073936083446

Epoch: 6| Step: 6
Training loss: 0.8905032894559974
Validation loss: 2.6116438194310976

Epoch: 6| Step: 7
Training loss: 0.9695192174910261
Validation loss: 2.635733172040976

Epoch: 6| Step: 8
Training loss: 1.3738563289572774
Validation loss: 2.658322875581299

Epoch: 6| Step: 9
Training loss: 1.01085387271687
Validation loss: 2.6185614628017846

Epoch: 6| Step: 10
Training loss: 0.7481262324298341
Validation loss: 2.691436265428337

Epoch: 6| Step: 11
Training loss: 0.9355043150712057
Validation loss: 2.656194604034224

Epoch: 6| Step: 12
Training loss: 1.2379048735164808
Validation loss: 2.7632674174007046

Epoch: 6| Step: 13
Training loss: 1.1526566420082975
Validation loss: 2.7221167169829608

Epoch: 434| Step: 0
Training loss: 1.1446678939335828
Validation loss: 2.7621581911846134

Epoch: 6| Step: 1
Training loss: 1.1939966276558898
Validation loss: 2.7390833979910334

Epoch: 6| Step: 2
Training loss: 1.0151263259862124
Validation loss: 2.7399617406396883

Epoch: 6| Step: 3
Training loss: 1.0781727103028913
Validation loss: 2.6642005116501757

Epoch: 6| Step: 4
Training loss: 1.2987657116113078
Validation loss: 2.6598837288563097

Epoch: 6| Step: 5
Training loss: 0.7891729296469648
Validation loss: 2.6575036325606325

Epoch: 6| Step: 6
Training loss: 0.8542120076372722
Validation loss: 2.616739665570244

Epoch: 6| Step: 7
Training loss: 0.8666444745034597
Validation loss: 2.6769902748726406

Epoch: 6| Step: 8
Training loss: 0.7978685580326275
Validation loss: 2.621963955351879

Epoch: 6| Step: 9
Training loss: 0.9691814569299751
Validation loss: 2.6750144063852805

Epoch: 6| Step: 10
Training loss: 0.9882331806298504
Validation loss: 2.6530843682953953

Epoch: 6| Step: 11
Training loss: 0.8643516015494356
Validation loss: 2.5961241216850763

Epoch: 6| Step: 12
Training loss: 1.0150287932272277
Validation loss: 2.703915247130211

Epoch: 6| Step: 13
Training loss: 0.8267310304221699
Validation loss: 2.7014287135553636

Epoch: 435| Step: 0
Training loss: 1.1666047670201258
Validation loss: 2.6854043078871848

Epoch: 6| Step: 1
Training loss: 0.9140603481169582
Validation loss: 2.672874367890394

Epoch: 6| Step: 2
Training loss: 1.003314842252279
Validation loss: 2.6404331897541464

Epoch: 6| Step: 3
Training loss: 0.826535625056912
Validation loss: 2.724356063680115

Epoch: 6| Step: 4
Training loss: 1.220130236662601
Validation loss: 2.6789975033319244

Epoch: 6| Step: 5
Training loss: 0.756986462790769
Validation loss: 2.6729790709761163

Epoch: 6| Step: 6
Training loss: 0.9311606012227269
Validation loss: 2.6232375328702995

Epoch: 6| Step: 7
Training loss: 0.721327720368465
Validation loss: 2.709023282615802

Epoch: 6| Step: 8
Training loss: 0.7345578797882456
Validation loss: 2.655176940788263

Epoch: 6| Step: 9
Training loss: 0.8577987086120262
Validation loss: 2.6352749712299257

Epoch: 6| Step: 10
Training loss: 0.8057906357723608
Validation loss: 2.6312863372323343

Epoch: 6| Step: 11
Training loss: 1.0025993776413458
Validation loss: 2.636103790531193

Epoch: 6| Step: 12
Training loss: 0.8519098465887898
Validation loss: 2.6904921324233904

Epoch: 6| Step: 13
Training loss: 0.8900794650616599
Validation loss: 2.6485749905737133

Epoch: 436| Step: 0
Training loss: 0.7942706165417651
Validation loss: 2.7068156660657556

Epoch: 6| Step: 1
Training loss: 0.7500471259252338
Validation loss: 2.6634792535894194

Epoch: 6| Step: 2
Training loss: 1.0144877008150373
Validation loss: 2.6463578272519355

Epoch: 6| Step: 3
Training loss: 1.0674460794557592
Validation loss: 2.706732501801535

Epoch: 6| Step: 4
Training loss: 0.813081423261043
Validation loss: 2.6487778676541143

Epoch: 6| Step: 5
Training loss: 1.1578287738680806
Validation loss: 2.6292987169655917

Epoch: 6| Step: 6
Training loss: 0.9605733289950262
Validation loss: 2.6687414968743757

Epoch: 6| Step: 7
Training loss: 0.9776502730821076
Validation loss: 2.697414385804283

Epoch: 6| Step: 8
Training loss: 0.9119452057155293
Validation loss: 2.6198682426247673

Epoch: 6| Step: 9
Training loss: 1.018116404085538
Validation loss: 2.6797969636348498

Epoch: 6| Step: 10
Training loss: 0.8582400022769454
Validation loss: 2.688156520880728

Epoch: 6| Step: 11
Training loss: 1.0433574623653086
Validation loss: 2.6422272585767455

Epoch: 6| Step: 12
Training loss: 0.7949633388343372
Validation loss: 2.6006634736830723

Epoch: 6| Step: 13
Training loss: 0.9385295936296262
Validation loss: 2.73018968253889

Epoch: 437| Step: 0
Training loss: 0.8292060849070925
Validation loss: 2.6318639297270647

Epoch: 6| Step: 1
Training loss: 0.8371915946880248
Validation loss: 2.680714505895875

Epoch: 6| Step: 2
Training loss: 0.9751046246856037
Validation loss: 2.619256699977106

Epoch: 6| Step: 3
Training loss: 1.0133798285115538
Validation loss: 2.648859341164666

Epoch: 6| Step: 4
Training loss: 1.0178846604110037
Validation loss: 2.6933426592526897

Epoch: 6| Step: 5
Training loss: 0.9347341427760107
Validation loss: 2.7430150014291184

Epoch: 6| Step: 6
Training loss: 1.2091278336167492
Validation loss: 2.7023773776503477

Epoch: 6| Step: 7
Training loss: 0.8847231149461022
Validation loss: 2.6700123025370233

Epoch: 6| Step: 8
Training loss: 1.143012487548537
Validation loss: 2.683398465931836

Epoch: 6| Step: 9
Training loss: 0.9035943023030867
Validation loss: 2.711119500023035

Epoch: 6| Step: 10
Training loss: 0.7993653596441399
Validation loss: 2.707277889493081

Epoch: 6| Step: 11
Training loss: 0.9451570934834865
Validation loss: 2.735448099920803

Epoch: 6| Step: 12
Training loss: 0.7347546265837074
Validation loss: 2.6572104045465914

Epoch: 6| Step: 13
Training loss: 0.843878559632239
Validation loss: 2.6658252391908936

Epoch: 438| Step: 0
Training loss: 1.2404134786246868
Validation loss: 2.629012250723481

Epoch: 6| Step: 1
Training loss: 0.772058895923173
Validation loss: 2.6974381030985706

Epoch: 6| Step: 2
Training loss: 0.9581584909138608
Validation loss: 2.7036848278659282

Epoch: 6| Step: 3
Training loss: 0.8718385121356942
Validation loss: 2.727616071040746

Epoch: 6| Step: 4
Training loss: 0.9466875337653715
Validation loss: 2.6151784748905387

Epoch: 6| Step: 5
Training loss: 1.1371914644269197
Validation loss: 2.725841743932857

Epoch: 6| Step: 6
Training loss: 0.7543797562519564
Validation loss: 2.69482032594505

Epoch: 6| Step: 7
Training loss: 0.9392826298357927
Validation loss: 2.750490939505121

Epoch: 6| Step: 8
Training loss: 1.120345287827469
Validation loss: 2.670298432829656

Epoch: 6| Step: 9
Training loss: 0.8786109937006524
Validation loss: 2.6820313163747684

Epoch: 6| Step: 10
Training loss: 0.8420217262418939
Validation loss: 2.7099713189553403

Epoch: 6| Step: 11
Training loss: 0.5910094911971805
Validation loss: 2.666020252936402

Epoch: 6| Step: 12
Training loss: 1.1188662527196513
Validation loss: 2.6760333422784655

Epoch: 6| Step: 13
Training loss: 0.7113047898145081
Validation loss: 2.668928086520326

Epoch: 439| Step: 0
Training loss: 0.759314945185297
Validation loss: 2.6869250577085295

Epoch: 6| Step: 1
Training loss: 0.7272393140378222
Validation loss: 2.703281839043346

Epoch: 6| Step: 2
Training loss: 1.0123738999196519
Validation loss: 2.6846374081483275

Epoch: 6| Step: 3
Training loss: 0.9089530555827762
Validation loss: 2.637900525155515

Epoch: 6| Step: 4
Training loss: 0.9577203255091282
Validation loss: 2.698070905884101

Epoch: 6| Step: 5
Training loss: 1.0123260913833103
Validation loss: 2.626058599671413

Epoch: 6| Step: 6
Training loss: 0.8549980017990052
Validation loss: 2.6274131854203624

Epoch: 6| Step: 7
Training loss: 0.7351526242044123
Validation loss: 2.6061946347680993

Epoch: 6| Step: 8
Training loss: 1.3346906052010474
Validation loss: 2.582373645912787

Epoch: 6| Step: 9
Training loss: 1.1522615047781803
Validation loss: 2.6253781651774144

Epoch: 6| Step: 10
Training loss: 0.7859151029334275
Validation loss: 2.6649024139033974

Epoch: 6| Step: 11
Training loss: 0.9386238990743706
Validation loss: 2.7025097126511266

Epoch: 6| Step: 12
Training loss: 0.8751009474152763
Validation loss: 2.7769320397876216

Epoch: 6| Step: 13
Training loss: 1.3925276181343211
Validation loss: 2.720558149861785

Epoch: 440| Step: 0
Training loss: 0.8169418111504553
Validation loss: 2.7379194701784213

Epoch: 6| Step: 1
Training loss: 1.3010852905159682
Validation loss: 2.746453932197951

Epoch: 6| Step: 2
Training loss: 0.8846339112992271
Validation loss: 2.6409013291337753

Epoch: 6| Step: 3
Training loss: 0.9220928969119276
Validation loss: 2.6392792652788026

Epoch: 6| Step: 4
Training loss: 1.3581630960906648
Validation loss: 2.6363977910363565

Epoch: 6| Step: 5
Training loss: 0.914703014308675
Validation loss: 2.5876866136665213

Epoch: 6| Step: 6
Training loss: 0.8182545232860509
Validation loss: 2.641882241615711

Epoch: 6| Step: 7
Training loss: 0.972247853773813
Validation loss: 2.6437205542208915

Epoch: 6| Step: 8
Training loss: 0.8298873143512794
Validation loss: 2.7083829777398023

Epoch: 6| Step: 9
Training loss: 0.7633600012800384
Validation loss: 2.7432365765509843

Epoch: 6| Step: 10
Training loss: 0.6179322204209972
Validation loss: 2.6394773167428385

Epoch: 6| Step: 11
Training loss: 1.1099770752369504
Validation loss: 2.693369082773854

Epoch: 6| Step: 12
Training loss: 1.050034722253618
Validation loss: 2.7324817315526637

Epoch: 6| Step: 13
Training loss: 1.0610481889874925
Validation loss: 2.725463441642641

Epoch: 441| Step: 0
Training loss: 1.1348762917845823
Validation loss: 2.7377804576210774

Epoch: 6| Step: 1
Training loss: 1.050430693168963
Validation loss: 2.6727052703617056

Epoch: 6| Step: 2
Training loss: 0.9130617189510414
Validation loss: 2.660762267839797

Epoch: 6| Step: 3
Training loss: 0.6354256587616909
Validation loss: 2.7242412578242607

Epoch: 6| Step: 4
Training loss: 0.9566902020070405
Validation loss: 2.6721426549033436

Epoch: 6| Step: 5
Training loss: 0.8865820489448571
Validation loss: 2.667293748041118

Epoch: 6| Step: 6
Training loss: 1.0982536780705854
Validation loss: 2.668616108807661

Epoch: 6| Step: 7
Training loss: 1.2211752504960176
Validation loss: 2.6618490560628287

Epoch: 6| Step: 8
Training loss: 1.043200520683814
Validation loss: 2.7089012919847777

Epoch: 6| Step: 9
Training loss: 0.7835818775681004
Validation loss: 2.7218471293549906

Epoch: 6| Step: 10
Training loss: 0.8039613057997861
Validation loss: 2.7152547621232586

Epoch: 6| Step: 11
Training loss: 0.9281407801253151
Validation loss: 2.727715191206215

Epoch: 6| Step: 12
Training loss: 0.7782006069970197
Validation loss: 2.786220609322506

Epoch: 6| Step: 13
Training loss: 0.9958038506606
Validation loss: 2.739178810181686

Epoch: 442| Step: 0
Training loss: 0.8059113464016822
Validation loss: 2.7068547883530996

Epoch: 6| Step: 1
Training loss: 0.8859733103355271
Validation loss: 2.7077556189571874

Epoch: 6| Step: 2
Training loss: 0.9479528392275787
Validation loss: 2.671002117146146

Epoch: 6| Step: 3
Training loss: 1.0787004787000898
Validation loss: 2.6879985332149143

Epoch: 6| Step: 4
Training loss: 0.6933932014058322
Validation loss: 2.7054543721258253

Epoch: 6| Step: 5
Training loss: 0.9060336545331346
Validation loss: 2.633378433090823

Epoch: 6| Step: 6
Training loss: 0.7941523395805767
Validation loss: 2.6782094365700404

Epoch: 6| Step: 7
Training loss: 1.238447593322483
Validation loss: 2.662694645126096

Epoch: 6| Step: 8
Training loss: 0.8881892643978715
Validation loss: 2.6854103007412533

Epoch: 6| Step: 9
Training loss: 0.9002723202384173
Validation loss: 2.717981193260342

Epoch: 6| Step: 10
Training loss: 0.6795616033304853
Validation loss: 2.779059758529761

Epoch: 6| Step: 11
Training loss: 0.9565021531499067
Validation loss: 2.679130103265686

Epoch: 6| Step: 12
Training loss: 1.0633742718504084
Validation loss: 2.69692885727073

Epoch: 6| Step: 13
Training loss: 0.7282690699732648
Validation loss: 2.7280296451760773

Epoch: 443| Step: 0
Training loss: 0.9199809644637142
Validation loss: 2.7132936731653263

Epoch: 6| Step: 1
Training loss: 0.7951460388691328
Validation loss: 2.6922442382454235

Epoch: 6| Step: 2
Training loss: 0.9247231855400488
Validation loss: 2.7447522406065836

Epoch: 6| Step: 3
Training loss: 0.888204497793363
Validation loss: 2.684327196991571

Epoch: 6| Step: 4
Training loss: 0.86287848972199
Validation loss: 2.725415459439033

Epoch: 6| Step: 5
Training loss: 0.7758405326634886
Validation loss: 2.7914275071674344

Epoch: 6| Step: 6
Training loss: 0.7546562456881868
Validation loss: 2.7796824606209514

Epoch: 6| Step: 7
Training loss: 0.7123065384677846
Validation loss: 2.775476198892781

Epoch: 6| Step: 8
Training loss: 0.968881229003128
Validation loss: 2.7371996141405104

Epoch: 6| Step: 9
Training loss: 1.0069282851987043
Validation loss: 2.699823940094111

Epoch: 6| Step: 10
Training loss: 1.002028969911271
Validation loss: 2.688297079598249

Epoch: 6| Step: 11
Training loss: 1.3279099683031084
Validation loss: 2.6417073170475502

Epoch: 6| Step: 12
Training loss: 0.6449872571218707
Validation loss: 2.676985450667092

Epoch: 6| Step: 13
Training loss: 0.8863474871091265
Validation loss: 2.6769941490744946

Epoch: 444| Step: 0
Training loss: 0.7684475389021089
Validation loss: 2.7048930447975477

Epoch: 6| Step: 1
Training loss: 1.1703033589514136
Validation loss: 2.6892477015708036

Epoch: 6| Step: 2
Training loss: 0.7915375294683085
Validation loss: 2.7410011369767093

Epoch: 6| Step: 3
Training loss: 1.2235517056338723
Validation loss: 2.797973644351511

Epoch: 6| Step: 4
Training loss: 0.9532293669045558
Validation loss: 2.802356356870797

Epoch: 6| Step: 5
Training loss: 0.6971711594305139
Validation loss: 2.817632484942933

Epoch: 6| Step: 6
Training loss: 0.8913546133506494
Validation loss: 2.7712020533085706

Epoch: 6| Step: 7
Training loss: 0.7438717654271186
Validation loss: 2.758572841937052

Epoch: 6| Step: 8
Training loss: 1.1242405659333001
Validation loss: 2.7574928393808484

Epoch: 6| Step: 9
Training loss: 0.8933735981865242
Validation loss: 2.78720472565231

Epoch: 6| Step: 10
Training loss: 0.8432275779541079
Validation loss: 2.73614707563832

Epoch: 6| Step: 11
Training loss: 0.9801863609443073
Validation loss: 2.663534401078224

Epoch: 6| Step: 12
Training loss: 0.8025205378414805
Validation loss: 2.6841481768367905

Epoch: 6| Step: 13
Training loss: 0.693326449619869
Validation loss: 2.631664474837502

Epoch: 445| Step: 0
Training loss: 0.8790708938669803
Validation loss: 2.657398596366377

Epoch: 6| Step: 1
Training loss: 0.6695788870637924
Validation loss: 2.6370240814123

Epoch: 6| Step: 2
Training loss: 1.176123939837216
Validation loss: 2.659440260257125

Epoch: 6| Step: 3
Training loss: 1.2730157539939115
Validation loss: 2.6604811310830563

Epoch: 6| Step: 4
Training loss: 1.0266537978451562
Validation loss: 2.663895050782454

Epoch: 6| Step: 5
Training loss: 0.8336465405924286
Validation loss: 2.651109860685419

Epoch: 6| Step: 6
Training loss: 0.7312911193241667
Validation loss: 2.665738426022383

Epoch: 6| Step: 7
Training loss: 0.9490096878465719
Validation loss: 2.6483385035674623

Epoch: 6| Step: 8
Training loss: 0.8639593438764344
Validation loss: 2.604102802765086

Epoch: 6| Step: 9
Training loss: 1.007114020498083
Validation loss: 2.6779821101809738

Epoch: 6| Step: 10
Training loss: 0.9197273453672475
Validation loss: 2.7132581732351007

Epoch: 6| Step: 11
Training loss: 1.1517737061644497
Validation loss: 2.7082968098060625

Epoch: 6| Step: 12
Training loss: 0.8333124317091054
Validation loss: 2.74963420544733

Epoch: 6| Step: 13
Training loss: 1.0990293880591029
Validation loss: 2.8023588028592026

Epoch: 446| Step: 0
Training loss: 0.9019746562226607
Validation loss: 2.765675000099751

Epoch: 6| Step: 1
Training loss: 0.9003656015621878
Validation loss: 2.747446464084099

Epoch: 6| Step: 2
Training loss: 1.21204065096702
Validation loss: 2.7173603057751814

Epoch: 6| Step: 3
Training loss: 0.6830124481541285
Validation loss: 2.773552332546972

Epoch: 6| Step: 4
Training loss: 1.0148040387824693
Validation loss: 2.6781875668327664

Epoch: 6| Step: 5
Training loss: 1.0536342306562074
Validation loss: 2.6797117004191477

Epoch: 6| Step: 6
Training loss: 0.730176734694108
Validation loss: 2.649526441594892

Epoch: 6| Step: 7
Training loss: 0.8173524766622764
Validation loss: 2.6450965686565233

Epoch: 6| Step: 8
Training loss: 0.9509916976943369
Validation loss: 2.727336332875109

Epoch: 6| Step: 9
Training loss: 0.8400052647198588
Validation loss: 2.696247340451413

Epoch: 6| Step: 10
Training loss: 1.1985626413990054
Validation loss: 2.6421545290191624

Epoch: 6| Step: 11
Training loss: 1.123093579191899
Validation loss: 2.662614027754508

Epoch: 6| Step: 12
Training loss: 0.5975787293267383
Validation loss: 2.6767288497773754

Epoch: 6| Step: 13
Training loss: 0.6399014271135567
Validation loss: 2.7334571896574347

Epoch: 447| Step: 0
Training loss: 0.7301095089358889
Validation loss: 2.7023331322028987

Epoch: 6| Step: 1
Training loss: 0.9659159027716191
Validation loss: 2.7299206446897135

Epoch: 6| Step: 2
Training loss: 0.791458646314505
Validation loss: 2.7694737007392405

Epoch: 6| Step: 3
Training loss: 0.6405120377849938
Validation loss: 2.7309609598465396

Epoch: 6| Step: 4
Training loss: 0.5525833031265986
Validation loss: 2.763165301477931

Epoch: 6| Step: 5
Training loss: 0.809628989528611
Validation loss: 2.718790733646116

Epoch: 6| Step: 6
Training loss: 0.8359192819481853
Validation loss: 2.743549476021682

Epoch: 6| Step: 7
Training loss: 0.7855493500915718
Validation loss: 2.7666866183040297

Epoch: 6| Step: 8
Training loss: 0.8680564032656451
Validation loss: 2.761398663782092

Epoch: 6| Step: 9
Training loss: 0.9256496416375478
Validation loss: 2.7082675901405318

Epoch: 6| Step: 10
Training loss: 0.8652456037425659
Validation loss: 2.751491517843382

Epoch: 6| Step: 11
Training loss: 0.7880557596888199
Validation loss: 2.7097711903353305

Epoch: 6| Step: 12
Training loss: 1.0899787190310983
Validation loss: 2.753898544841836

Epoch: 6| Step: 13
Training loss: 0.8053500586600806
Validation loss: 2.74075412511302

Epoch: 448| Step: 0
Training loss: 0.7111796710703718
Validation loss: 2.7740735538020784

Epoch: 6| Step: 1
Training loss: 0.9267403829079193
Validation loss: 2.7588039413546044

Epoch: 6| Step: 2
Training loss: 0.7876542999842773
Validation loss: 2.7276294154703717

Epoch: 6| Step: 3
Training loss: 0.7267346742140608
Validation loss: 2.753087911020439

Epoch: 6| Step: 4
Training loss: 0.7461578980675416
Validation loss: 2.761845637477095

Epoch: 6| Step: 5
Training loss: 0.7819154194386854
Validation loss: 2.8009311382314093

Epoch: 6| Step: 6
Training loss: 1.0803664307268246
Validation loss: 2.744355101252984

Epoch: 6| Step: 7
Training loss: 0.828544150746738
Validation loss: 2.7436372958289583

Epoch: 6| Step: 8
Training loss: 1.208879506334385
Validation loss: 2.744701511897873

Epoch: 6| Step: 9
Training loss: 0.8181288219155725
Validation loss: 2.676101992055733

Epoch: 6| Step: 10
Training loss: 0.815512318336262
Validation loss: 2.6939896364118896

Epoch: 6| Step: 11
Training loss: 0.7630073797886482
Validation loss: 2.737469184969138

Epoch: 6| Step: 12
Training loss: 0.9521713488829975
Validation loss: 2.7238883501232527

Epoch: 6| Step: 13
Training loss: 0.7668959908694366
Validation loss: 2.765299323495281

Epoch: 449| Step: 0
Training loss: 0.9252006867220252
Validation loss: 2.7033645435543243

Epoch: 6| Step: 1
Training loss: 0.9908158741164852
Validation loss: 2.70362699400814

Epoch: 6| Step: 2
Training loss: 1.0695437155443668
Validation loss: 2.7302243073738524

Epoch: 6| Step: 3
Training loss: 0.6496005141983793
Validation loss: 2.7374238083453895

Epoch: 6| Step: 4
Training loss: 0.8739774723859645
Validation loss: 2.724996282709135

Epoch: 6| Step: 5
Training loss: 1.0488141447872383
Validation loss: 2.7264184777114995

Epoch: 6| Step: 6
Training loss: 1.0230510069249141
Validation loss: 2.733328279242456

Epoch: 6| Step: 7
Training loss: 0.9632696987922901
Validation loss: 2.6908051179800805

Epoch: 6| Step: 8
Training loss: 0.7728104795189655
Validation loss: 2.636560325101702

Epoch: 6| Step: 9
Training loss: 0.7367136626406732
Validation loss: 2.6648430300797075

Epoch: 6| Step: 10
Training loss: 0.5837820206463441
Validation loss: 2.6666746785122997

Epoch: 6| Step: 11
Training loss: 0.6795785093068061
Validation loss: 2.695530050592434

Epoch: 6| Step: 12
Training loss: 0.8576341857129113
Validation loss: 2.7188906359198173

Epoch: 6| Step: 13
Training loss: 0.9231659853133206
Validation loss: 2.6394371506081167

Epoch: 450| Step: 0
Training loss: 1.045795396418168
Validation loss: 2.7166601457888113

Epoch: 6| Step: 1
Training loss: 0.6777279548450864
Validation loss: 2.6656412944765244

Epoch: 6| Step: 2
Training loss: 0.4377034259335242
Validation loss: 2.696453527445149

Epoch: 6| Step: 3
Training loss: 0.9581166243513675
Validation loss: 2.7139238441083364

Epoch: 6| Step: 4
Training loss: 0.706715550201412
Validation loss: 2.6755815194759904

Epoch: 6| Step: 5
Training loss: 1.0773830348564
Validation loss: 2.765912883308375

Epoch: 6| Step: 6
Training loss: 1.0497302503588108
Validation loss: 2.7651652296984284

Epoch: 6| Step: 7
Training loss: 0.8907802513396657
Validation loss: 2.6623162730050742

Epoch: 6| Step: 8
Training loss: 0.781101403409698
Validation loss: 2.6700540475935157

Epoch: 6| Step: 9
Training loss: 0.4769172911183581
Validation loss: 2.745212751851421

Epoch: 6| Step: 10
Training loss: 0.6727631265797772
Validation loss: 2.733264414182035

Epoch: 6| Step: 11
Training loss: 0.9636109541991266
Validation loss: 2.697077798714438

Epoch: 6| Step: 12
Training loss: 0.6579504235441443
Validation loss: 2.6940260023671367

Epoch: 6| Step: 13
Training loss: 0.9110883597664446
Validation loss: 2.712927477270245

Testing loss: 2.2441724128439207
