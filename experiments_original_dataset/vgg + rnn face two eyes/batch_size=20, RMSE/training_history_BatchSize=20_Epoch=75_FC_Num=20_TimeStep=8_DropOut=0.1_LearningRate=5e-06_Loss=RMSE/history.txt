Epoch: 1| Step: 0
Training loss: 5.787905928874786
Validation loss: 5.842983950419061

Epoch: 5| Step: 1
Training loss: 6.451134621827043
Validation loss: 5.841608229583843

Epoch: 5| Step: 2
Training loss: 6.854457335024124
Validation loss: 5.840220849355304

Epoch: 5| Step: 3
Training loss: 5.802306394095955
Validation loss: 5.838823080866592

Epoch: 5| Step: 4
Training loss: 5.363403941263254
Validation loss: 5.837511156004784

Epoch: 5| Step: 5
Training loss: 6.083137857440595
Validation loss: 5.83629580840005

Epoch: 5| Step: 6
Training loss: 5.786635081707473
Validation loss: 5.834981749004029

Epoch: 5| Step: 7
Training loss: 5.212490325113736
Validation loss: 5.833702302798645

Epoch: 5| Step: 8
Training loss: 5.806161357092123
Validation loss: 5.832387904346152

Epoch: 5| Step: 9
Training loss: 5.721961281926437
Validation loss: 5.831100842747832

Epoch: 5| Step: 10
Training loss: 6.128994009290429
Validation loss: 5.829738233446578

Epoch: 5| Step: 11
Training loss: 7.348961072921693
Validation loss: 5.828389827380659

Epoch: 2| Step: 0
Training loss: 5.412846592472632
Validation loss: 5.827037160902107

Epoch: 5| Step: 1
Training loss: 6.345560952258525
Validation loss: 5.825658417738098

Epoch: 5| Step: 2
Training loss: 6.540064945656748
Validation loss: 5.824161501116347

Epoch: 5| Step: 3
Training loss: 5.449970196283725
Validation loss: 5.822648455653281

Epoch: 5| Step: 4
Training loss: 6.128146861814013
Validation loss: 5.82108545141909

Epoch: 5| Step: 5
Training loss: 5.677275133538495
Validation loss: 5.819433001605883

Epoch: 5| Step: 6
Training loss: 5.461608932759596
Validation loss: 5.817771326154903

Epoch: 5| Step: 7
Training loss: 6.018276670547139
Validation loss: 5.816055270182503

Epoch: 5| Step: 8
Training loss: 5.915458806640987
Validation loss: 5.81424560449913

Epoch: 5| Step: 9
Training loss: 6.588571259403238
Validation loss: 5.81232106196571

Epoch: 5| Step: 10
Training loss: 5.94979036106115
Validation loss: 5.810284482870978

Epoch: 5| Step: 11
Training loss: 3.8985725333577625
Validation loss: 5.808208939393776

Epoch: 3| Step: 0
Training loss: 5.843223507261257
Validation loss: 5.8061484838178865

Epoch: 5| Step: 1
Training loss: 5.325567532235909
Validation loss: 5.803842249409724

Epoch: 5| Step: 2
Training loss: 5.723944300969018
Validation loss: 5.801516762630311

Epoch: 5| Step: 3
Training loss: 5.8046224392804096
Validation loss: 5.799009302087858

Epoch: 5| Step: 4
Training loss: 5.97183132025905
Validation loss: 5.7965054184281675

Epoch: 5| Step: 5
Training loss: 6.580465665995656
Validation loss: 5.7937816650556835

Epoch: 5| Step: 6
Training loss: 6.281263968229183
Validation loss: 5.790887611007795

Epoch: 5| Step: 7
Training loss: 6.43763717949637
Validation loss: 5.787781306351738

Epoch: 5| Step: 8
Training loss: 5.579466073527951
Validation loss: 5.784596521060783

Epoch: 5| Step: 9
Training loss: 5.75947321178301
Validation loss: 5.781165718632735

Epoch: 5| Step: 10
Training loss: 5.402952390244615
Validation loss: 5.777558792785709

Epoch: 5| Step: 11
Training loss: 6.642230389586004
Validation loss: 5.773925609198817

Epoch: 4| Step: 0
Training loss: 5.577084398845485
Validation loss: 5.770025625981855

Epoch: 5| Step: 1
Training loss: 4.025449616334486
Validation loss: 5.765741700298263

Epoch: 5| Step: 2
Training loss: 5.807811527903806
Validation loss: 5.761788371037263

Epoch: 5| Step: 3
Training loss: 5.830620525438945
Validation loss: 5.757342943552492

Epoch: 5| Step: 4
Training loss: 6.308870688580831
Validation loss: 5.752795880359455

Epoch: 5| Step: 5
Training loss: 5.529685623586853
Validation loss: 5.7480570855386475

Epoch: 5| Step: 6
Training loss: 6.686110307564621
Validation loss: 5.743127399083878

Epoch: 5| Step: 7
Training loss: 5.552187157018619
Validation loss: 5.738051813055888

Epoch: 5| Step: 8
Training loss: 6.612486050740692
Validation loss: 5.732665033073531

Epoch: 5| Step: 9
Training loss: 6.146376694620008
Validation loss: 5.727122731753819

Epoch: 5| Step: 10
Training loss: 5.995998955887493
Validation loss: 5.721224161047633

Epoch: 5| Step: 11
Training loss: 5.701585033954511
Validation loss: 5.7153860318559015

Epoch: 5| Step: 0
Training loss: 5.417334510518299
Validation loss: 5.709393064139383

Epoch: 5| Step: 1
Training loss: 6.112093035484167
Validation loss: 5.703046406243559

Epoch: 5| Step: 2
Training loss: 5.750471344578152
Validation loss: 5.696498368885261

Epoch: 5| Step: 3
Training loss: 5.7567145906687065
Validation loss: 5.689975486248914

Epoch: 5| Step: 4
Training loss: 6.385648622598868
Validation loss: 5.683022332934678

Epoch: 5| Step: 5
Training loss: 5.98359758790597
Validation loss: 5.676245106634279

Epoch: 5| Step: 6
Training loss: 5.9548478324403495
Validation loss: 5.669183700328834

Epoch: 5| Step: 7
Training loss: 5.60596993893999
Validation loss: 5.661736933905027

Epoch: 5| Step: 8
Training loss: 5.936469701419282
Validation loss: 5.653928220477009

Epoch: 5| Step: 9
Training loss: 5.374649391272101
Validation loss: 5.646210586312323

Epoch: 5| Step: 10
Training loss: 5.1815042431048415
Validation loss: 5.6382236458917925

Epoch: 5| Step: 11
Training loss: 6.49471772576779
Validation loss: 5.629938853752226

Epoch: 6| Step: 0
Training loss: 5.624029626857811
Validation loss: 5.621624689783299

Epoch: 5| Step: 1
Training loss: 5.76742765370513
Validation loss: 5.612710533073222

Epoch: 5| Step: 2
Training loss: 4.882045642906652
Validation loss: 5.6039575823763

Epoch: 5| Step: 3
Training loss: 5.6662542903672675
Validation loss: 5.594855023569107

Epoch: 5| Step: 4
Training loss: 5.301931662597925
Validation loss: 5.586088485277815

Epoch: 5| Step: 5
Training loss: 5.72767851026429
Validation loss: 5.576736156196368

Epoch: 5| Step: 6
Training loss: 6.0573406485372665
Validation loss: 5.5672925027185896

Epoch: 5| Step: 7
Training loss: 5.6248192652170985
Validation loss: 5.557658892734066

Epoch: 5| Step: 8
Training loss: 5.8427984921585905
Validation loss: 5.547994703010702

Epoch: 5| Step: 9
Training loss: 6.0780314852623
Validation loss: 5.53785518084098

Epoch: 5| Step: 10
Training loss: 6.054031907551073
Validation loss: 5.527693350331959

Epoch: 5| Step: 11
Training loss: 5.046563200870555
Validation loss: 5.517313762621941

Epoch: 7| Step: 0
Training loss: 5.934141795481209
Validation loss: 5.50738081446542

Epoch: 5| Step: 1
Training loss: 5.622049532731487
Validation loss: 5.496747594140851

Epoch: 5| Step: 2
Training loss: 5.1222804227341925
Validation loss: 5.4870362377653725

Epoch: 5| Step: 3
Training loss: 5.7838485239119635
Validation loss: 5.476852830128555

Epoch: 5| Step: 4
Training loss: 6.053308184623293
Validation loss: 5.467329701866231

Epoch: 5| Step: 5
Training loss: 5.887784966377656
Validation loss: 5.458063332477841

Epoch: 5| Step: 6
Training loss: 5.99102843612114
Validation loss: 5.448493863729437

Epoch: 5| Step: 7
Training loss: 4.6623589297473575
Validation loss: 5.439587875514311

Epoch: 5| Step: 8
Training loss: 5.292936137757003
Validation loss: 5.430286284803812

Epoch: 5| Step: 9
Training loss: 5.605337235772117
Validation loss: 5.4217794155229875

Epoch: 5| Step: 10
Training loss: 5.187145175059078
Validation loss: 5.412962118658848

Epoch: 5| Step: 11
Training loss: 5.8174640418672094
Validation loss: 5.404517739666261

Epoch: 8| Step: 0
Training loss: 6.185838572613704
Validation loss: 5.396270758770285

Epoch: 5| Step: 1
Training loss: 6.152874791069625
Validation loss: 5.388130878881426

Epoch: 5| Step: 2
Training loss: 4.955061957994911
Validation loss: 5.379960513862249

Epoch: 5| Step: 3
Training loss: 5.124668017544069
Validation loss: 5.371686904984304

Epoch: 5| Step: 4
Training loss: 5.6521448233503335
Validation loss: 5.36429413198031

Epoch: 5| Step: 5
Training loss: 5.116396870577561
Validation loss: 5.357047165818327

Epoch: 5| Step: 6
Training loss: 6.1930951339089315
Validation loss: 5.349660493648952

Epoch: 5| Step: 7
Training loss: 5.342804406811404
Validation loss: 5.342078603769142

Epoch: 5| Step: 8
Training loss: 5.271412009738569
Validation loss: 5.335028254878961

Epoch: 5| Step: 9
Training loss: 4.876494740923233
Validation loss: 5.328267435834318

Epoch: 5| Step: 10
Training loss: 5.500896554179171
Validation loss: 5.321624190848644

Epoch: 5| Step: 11
Training loss: 3.62532541853263
Validation loss: 5.314853094719735

Epoch: 9| Step: 0
Training loss: 5.375300554255919
Validation loss: 5.308508050080395

Epoch: 5| Step: 1
Training loss: 5.079940142842078
Validation loss: 5.302297279323264

Epoch: 5| Step: 2
Training loss: 5.140796786049706
Validation loss: 5.2964526132759975

Epoch: 5| Step: 3
Training loss: 5.3228758967779815
Validation loss: 5.290282003209014

Epoch: 5| Step: 4
Training loss: 4.990540329723102
Validation loss: 5.283964057883868

Epoch: 5| Step: 5
Training loss: 6.173565210611124
Validation loss: 5.277658516668527

Epoch: 5| Step: 6
Training loss: 5.120175579755961
Validation loss: 5.271903795044202

Epoch: 5| Step: 7
Training loss: 4.489021047738696
Validation loss: 5.265212551305387

Epoch: 5| Step: 8
Training loss: 5.190717319905411
Validation loss: 5.260044812445492

Epoch: 5| Step: 9
Training loss: 6.13199947337766
Validation loss: 5.253690224972376

Epoch: 5| Step: 10
Training loss: 6.032751657396022
Validation loss: 5.247481082447805

Epoch: 5| Step: 11
Training loss: 5.798790299114589
Validation loss: 5.241043693727185

Epoch: 10| Step: 0
Training loss: 4.867703577299575
Validation loss: 5.235392540864602

Epoch: 5| Step: 1
Training loss: 5.570038905119157
Validation loss: 5.228539587570872

Epoch: 5| Step: 2
Training loss: 6.22801614638473
Validation loss: 5.2225910982544335

Epoch: 5| Step: 3
Training loss: 5.105796564109967
Validation loss: 5.215989599175117

Epoch: 5| Step: 4
Training loss: 4.796284095577355
Validation loss: 5.209188637759084

Epoch: 5| Step: 5
Training loss: 6.410728415106653
Validation loss: 5.202706863357694

Epoch: 5| Step: 6
Training loss: 4.681810308316808
Validation loss: 5.195051732605796

Epoch: 5| Step: 7
Training loss: 4.706182658206367
Validation loss: 5.187717257013887

Epoch: 5| Step: 8
Training loss: 5.326519229139108
Validation loss: 5.180563383235705

Epoch: 5| Step: 9
Training loss: 5.426558788330144
Validation loss: 5.172692986193545

Epoch: 5| Step: 10
Training loss: 4.823848076915881
Validation loss: 5.16490806624559

Epoch: 5| Step: 11
Training loss: 6.6010603313072815
Validation loss: 5.156902233448395

Epoch: 11| Step: 0
Training loss: 4.940697901922019
Validation loss: 5.1484087227850175

Epoch: 5| Step: 1
Training loss: 4.865523297196963
Validation loss: 5.1397390404123655

Epoch: 5| Step: 2
Training loss: 4.825194225453986
Validation loss: 5.132118917564165

Epoch: 5| Step: 3
Training loss: 5.973036260597298
Validation loss: 5.124669211652539

Epoch: 5| Step: 4
Training loss: 5.150618373448595
Validation loss: 5.117969800638134

Epoch: 5| Step: 5
Training loss: 4.764521636808076
Validation loss: 5.1111421241487385

Epoch: 5| Step: 6
Training loss: 5.491951341828843
Validation loss: 5.104752420044318

Epoch: 5| Step: 7
Training loss: 5.847209049470772
Validation loss: 5.098026150160584

Epoch: 5| Step: 8
Training loss: 5.364564568446651
Validation loss: 5.091819366104951

Epoch: 5| Step: 9
Training loss: 5.423073232205181
Validation loss: 5.086004496034012

Epoch: 5| Step: 10
Training loss: 5.019374123574296
Validation loss: 5.080088340536834

Epoch: 5| Step: 11
Training loss: 3.8685857537675097
Validation loss: 5.074604970218357

Epoch: 12| Step: 0
Training loss: 5.162482546575937
Validation loss: 5.069781557251623

Epoch: 5| Step: 1
Training loss: 5.489130897866803
Validation loss: 5.0644439293105705

Epoch: 5| Step: 2
Training loss: 6.014610938271031
Validation loss: 5.058814822831774

Epoch: 5| Step: 3
Training loss: 4.949693905392542
Validation loss: 5.0527128974370585

Epoch: 5| Step: 4
Training loss: 5.574891764184579
Validation loss: 5.047173521741986

Epoch: 5| Step: 5
Training loss: 5.436944867439539
Validation loss: 5.040866325893934

Epoch: 5| Step: 6
Training loss: 5.3304017871339
Validation loss: 5.034745607285251

Epoch: 5| Step: 7
Training loss: 4.72764466563136
Validation loss: 5.029163887710035

Epoch: 5| Step: 8
Training loss: 4.543582943622376
Validation loss: 5.023203700484875

Epoch: 5| Step: 9
Training loss: 4.120253635487985
Validation loss: 5.01713419675752

Epoch: 5| Step: 10
Training loss: 5.200235933673504
Validation loss: 5.011989262119552

Epoch: 5| Step: 11
Training loss: 5.184814493361012
Validation loss: 5.006182400822098

Epoch: 13| Step: 0
Training loss: 5.446566684946073
Validation loss: 5.000368017322312

Epoch: 5| Step: 1
Training loss: 4.6726116505484185
Validation loss: 4.994493146083008

Epoch: 5| Step: 2
Training loss: 4.849831977372024
Validation loss: 4.9889300030800925

Epoch: 5| Step: 3
Training loss: 4.5699078763862655
Validation loss: 4.982833990810491

Epoch: 5| Step: 4
Training loss: 5.826685505246596
Validation loss: 4.977452851740685

Epoch: 5| Step: 5
Training loss: 4.843526724314669
Validation loss: 4.971314741977119

Epoch: 5| Step: 6
Training loss: 4.840659847835951
Validation loss: 4.965940108803183

Epoch: 5| Step: 7
Training loss: 5.450410096024312
Validation loss: 4.96052430201803

Epoch: 5| Step: 8
Training loss: 4.812557864150912
Validation loss: 4.955407660581524

Epoch: 5| Step: 9
Training loss: 5.136215591445382
Validation loss: 4.949670575800958

Epoch: 5| Step: 10
Training loss: 5.511945410271273
Validation loss: 4.944395746688961

Epoch: 5| Step: 11
Training loss: 4.735742151251959
Validation loss: 4.938484045546907

Epoch: 14| Step: 0
Training loss: 5.695425024608567
Validation loss: 4.932975647767561

Epoch: 5| Step: 1
Training loss: 5.405641731044896
Validation loss: 4.927369319796402

Epoch: 5| Step: 2
Training loss: 4.407606632978844
Validation loss: 4.922208025933128

Epoch: 5| Step: 3
Training loss: 5.476844769439794
Validation loss: 4.916105911907004

Epoch: 5| Step: 4
Training loss: 5.452458994071505
Validation loss: 4.910960291195565

Epoch: 5| Step: 5
Training loss: 4.021258369605474
Validation loss: 4.9051601065954875

Epoch: 5| Step: 6
Training loss: 4.957681479467541
Validation loss: 4.899540494600756

Epoch: 5| Step: 7
Training loss: 4.768456590257882
Validation loss: 4.8943982584493275

Epoch: 5| Step: 8
Training loss: 4.558724709585259
Validation loss: 4.888434117411196

Epoch: 5| Step: 9
Training loss: 5.2494143204749815
Validation loss: 4.883048578277321

Epoch: 5| Step: 10
Training loss: 5.065093329907538
Validation loss: 4.878286061142057

Epoch: 5| Step: 11
Training loss: 5.055889947659244
Validation loss: 4.873057402228003

Epoch: 15| Step: 0
Training loss: 4.522951300916138
Validation loss: 4.866863388936642

Epoch: 5| Step: 1
Training loss: 5.114804057883069
Validation loss: 4.861286102354427

Epoch: 5| Step: 2
Training loss: 4.95379383854187
Validation loss: 4.856158018611655

Epoch: 5| Step: 3
Training loss: 4.1208535363936685
Validation loss: 4.8507869098466685

Epoch: 5| Step: 4
Training loss: 5.264825686678373
Validation loss: 4.846394323653743

Epoch: 5| Step: 5
Training loss: 5.67279398385416
Validation loss: 4.840626938295972

Epoch: 5| Step: 6
Training loss: 4.400003970751271
Validation loss: 4.835091660191901

Epoch: 5| Step: 7
Training loss: 5.400945983254979
Validation loss: 4.8314684799952134

Epoch: 5| Step: 8
Training loss: 5.221947335838565
Validation loss: 4.825973097030497

Epoch: 5| Step: 9
Training loss: 4.7523581022202315
Validation loss: 4.8195733112081385

Epoch: 5| Step: 10
Training loss: 4.920209524143724
Validation loss: 4.815371709322562

Epoch: 5| Step: 11
Training loss: 5.275930942630065
Validation loss: 4.810457919298967

Epoch: 16| Step: 0
Training loss: 4.546800750440796
Validation loss: 4.805199564290337

Epoch: 5| Step: 1
Training loss: 4.964063629640157
Validation loss: 4.800451819361209

Epoch: 5| Step: 2
Training loss: 5.4502566425896655
Validation loss: 4.79516497356377

Epoch: 5| Step: 3
Training loss: 4.337414848964932
Validation loss: 4.789514376141293

Epoch: 5| Step: 4
Training loss: 4.500953149517376
Validation loss: 4.784332362241843

Epoch: 5| Step: 5
Training loss: 4.336336464612285
Validation loss: 4.779421462916551

Epoch: 5| Step: 6
Training loss: 5.703335692811913
Validation loss: 4.775288074851081

Epoch: 5| Step: 7
Training loss: 4.9171406576703145
Validation loss: 4.768660232278998

Epoch: 5| Step: 8
Training loss: 4.673643460035042
Validation loss: 4.763936203195533

Epoch: 5| Step: 9
Training loss: 5.023808443365926
Validation loss: 4.7581843088377855

Epoch: 5| Step: 10
Training loss: 5.449865902992082
Validation loss: 4.752834227406505

Epoch: 5| Step: 11
Training loss: 3.9498907436278134
Validation loss: 4.748043585979746

Epoch: 17| Step: 0
Training loss: 5.416060702345769
Validation loss: 4.742843942807137

Epoch: 5| Step: 1
Training loss: 5.078594291716794
Validation loss: 4.7377959713373805

Epoch: 5| Step: 2
Training loss: 5.118862477837884
Validation loss: 4.7325192078181955

Epoch: 5| Step: 3
Training loss: 4.852383309189091
Validation loss: 4.727067753292729

Epoch: 5| Step: 4
Training loss: 4.778006656595785
Validation loss: 4.722316059726029

Epoch: 5| Step: 5
Training loss: 4.612338700614317
Validation loss: 4.717010977593656

Epoch: 5| Step: 6
Training loss: 5.980280897502818
Validation loss: 4.712370882702353

Epoch: 5| Step: 7
Training loss: 3.9180154845168826
Validation loss: 4.706852585816799

Epoch: 5| Step: 8
Training loss: 4.68177832765779
Validation loss: 4.701792734225839

Epoch: 5| Step: 9
Training loss: 4.000993843590639
Validation loss: 4.696240917796428

Epoch: 5| Step: 10
Training loss: 4.338338651024902
Validation loss: 4.692025441544672

Epoch: 5| Step: 11
Training loss: 5.527902743376947
Validation loss: 4.6870683259350985

Epoch: 18| Step: 0
Training loss: 5.805941912111798
Validation loss: 4.683705960356763

Epoch: 5| Step: 1
Training loss: 5.222322075252159
Validation loss: 4.677166441736226

Epoch: 5| Step: 2
Training loss: 5.059955098552282
Validation loss: 4.670728247166777

Epoch: 5| Step: 3
Training loss: 4.719332021225303
Validation loss: 4.666480361534744

Epoch: 5| Step: 4
Training loss: 4.2844148618706575
Validation loss: 4.662270658100729

Epoch: 5| Step: 5
Training loss: 4.647394758964887
Validation loss: 4.657461426957927

Epoch: 5| Step: 6
Training loss: 4.68179543835603
Validation loss: 4.651914810064305

Epoch: 5| Step: 7
Training loss: 4.266430006815037
Validation loss: 4.647120078045417

Epoch: 5| Step: 8
Training loss: 4.750205788421027
Validation loss: 4.642237082496607

Epoch: 5| Step: 9
Training loss: 5.040597891690319
Validation loss: 4.636781507290714

Epoch: 5| Step: 10
Training loss: 4.176588274886564
Validation loss: 4.632307663033466

Epoch: 5| Step: 11
Training loss: 3.286648913548969
Validation loss: 4.627926931322046

Epoch: 19| Step: 0
Training loss: 3.6518795922058054
Validation loss: 4.622980097707566

Epoch: 5| Step: 1
Training loss: 5.662878715195795
Validation loss: 4.6181304020500935

Epoch: 5| Step: 2
Training loss: 4.16834810026823
Validation loss: 4.6126604946508865

Epoch: 5| Step: 3
Training loss: 4.637804812056179
Validation loss: 4.608784895370696

Epoch: 5| Step: 4
Training loss: 4.74487711064955
Validation loss: 4.604555427168232

Epoch: 5| Step: 5
Training loss: 5.393905216604921
Validation loss: 4.599149977196458

Epoch: 5| Step: 6
Training loss: 4.090507329613656
Validation loss: 4.593980411451519

Epoch: 5| Step: 7
Training loss: 4.5438157109647355
Validation loss: 4.589548122543953

Epoch: 5| Step: 8
Training loss: 5.269535593493392
Validation loss: 4.584411674860745

Epoch: 5| Step: 9
Training loss: 5.280585975209299
Validation loss: 4.579344646661652

Epoch: 5| Step: 10
Training loss: 3.9085537640213057
Validation loss: 4.574753519099505

Epoch: 5| Step: 11
Training loss: 5.4719161105613185
Validation loss: 4.5689015528169

Epoch: 20| Step: 0
Training loss: 4.623870711739972
Validation loss: 4.564560829755967

Epoch: 5| Step: 1
Training loss: 4.124157443840139
Validation loss: 4.561243432903502

Epoch: 5| Step: 2
Training loss: 3.789920922010481
Validation loss: 4.556507434034777

Epoch: 5| Step: 3
Training loss: 4.431726272448046
Validation loss: 4.551684192585085

Epoch: 5| Step: 4
Training loss: 5.074582222716213
Validation loss: 4.546248087973058

Epoch: 5| Step: 5
Training loss: 4.412595251854565
Validation loss: 4.5404106322318984

Epoch: 5| Step: 6
Training loss: 5.362728926745044
Validation loss: 4.535870014266393

Epoch: 5| Step: 7
Training loss: 4.2102301575004155
Validation loss: 4.530121682534851

Epoch: 5| Step: 8
Training loss: 5.709083600638725
Validation loss: 4.524516019352348

Epoch: 5| Step: 9
Training loss: 4.593350140043017
Validation loss: 4.519685875026064

Epoch: 5| Step: 10
Training loss: 4.7990137358538645
Validation loss: 4.514422713120048

Epoch: 5| Step: 11
Training loss: 3.9424709851655306
Validation loss: 4.509046944193439

Epoch: 21| Step: 0
Training loss: 4.44593846853134
Validation loss: 4.504238146209745

Epoch: 5| Step: 1
Training loss: 4.273079977474852
Validation loss: 4.499268701965709

Epoch: 5| Step: 2
Training loss: 3.91209560169037
Validation loss: 4.493784099408805

Epoch: 5| Step: 3
Training loss: 4.4850478249065775
Validation loss: 4.488817404829875

Epoch: 5| Step: 4
Training loss: 4.772440654851263
Validation loss: 4.484778134682116

Epoch: 5| Step: 5
Training loss: 4.797072217037049
Validation loss: 4.479674974327995

Epoch: 5| Step: 6
Training loss: 5.010727246889878
Validation loss: 4.474313194166678

Epoch: 5| Step: 7
Training loss: 4.978806401497627
Validation loss: 4.469326889041596

Epoch: 5| Step: 8
Training loss: 4.900374472185913
Validation loss: 4.464268061830044

Epoch: 5| Step: 9
Training loss: 4.657780747687709
Validation loss: 4.458518588890473

Epoch: 5| Step: 10
Training loss: 4.260618072947326
Validation loss: 4.453376093695319

Epoch: 5| Step: 11
Training loss: 4.839820892550948
Validation loss: 4.448902894805042

Epoch: 22| Step: 0
Training loss: 4.442835649080025
Validation loss: 4.444038610837438

Epoch: 5| Step: 1
Training loss: 5.020184402422502
Validation loss: 4.439165854848123

Epoch: 5| Step: 2
Training loss: 4.063747742580983
Validation loss: 4.43490704818565

Epoch: 5| Step: 3
Training loss: 4.670731114208498
Validation loss: 4.429023347523346

Epoch: 5| Step: 4
Training loss: 4.788858580487239
Validation loss: 4.424032567839059

Epoch: 5| Step: 5
Training loss: 4.671393430251856
Validation loss: 4.41946026184962

Epoch: 5| Step: 6
Training loss: 4.203651820637669
Validation loss: 4.414627462145224

Epoch: 5| Step: 7
Training loss: 4.181838578336528
Validation loss: 4.409707032158321

Epoch: 5| Step: 8
Training loss: 4.926714936477207
Validation loss: 4.4047020792733935

Epoch: 5| Step: 9
Training loss: 4.720352406034766
Validation loss: 4.4001099437285776

Epoch: 5| Step: 10
Training loss: 4.449561262469233
Validation loss: 4.39406070252781

Epoch: 5| Step: 11
Training loss: 3.348307418254583
Validation loss: 4.389423305465295

Epoch: 23| Step: 0
Training loss: 4.700812395375258
Validation loss: 4.384787809659914

Epoch: 5| Step: 1
Training loss: 4.8258568828054065
Validation loss: 4.380482372128727

Epoch: 5| Step: 2
Training loss: 4.384234029579517
Validation loss: 4.375638778919832

Epoch: 5| Step: 3
Training loss: 4.1904898830082775
Validation loss: 4.3710913318653475

Epoch: 5| Step: 4
Training loss: 4.660727172566488
Validation loss: 4.366599646750434

Epoch: 5| Step: 5
Training loss: 4.9020552470511385
Validation loss: 4.362073994834631

Epoch: 5| Step: 6
Training loss: 4.2747196038629705
Validation loss: 4.356443205479974

Epoch: 5| Step: 7
Training loss: 4.627786364069729
Validation loss: 4.351765817929584

Epoch: 5| Step: 8
Training loss: 4.146928013316826
Validation loss: 4.346839163088804

Epoch: 5| Step: 9
Training loss: 4.407782754726713
Validation loss: 4.341904071875084

Epoch: 5| Step: 10
Training loss: 4.367701300625909
Validation loss: 4.337173148380966

Epoch: 5| Step: 11
Training loss: 3.6076648178041806
Validation loss: 4.333239484039701

Epoch: 24| Step: 0
Training loss: 4.537801702047961
Validation loss: 4.328115727200083

Epoch: 5| Step: 1
Training loss: 4.200950996271117
Validation loss: 4.323068320436966

Epoch: 5| Step: 2
Training loss: 4.53817199270812
Validation loss: 4.318878404886301

Epoch: 5| Step: 3
Training loss: 4.722808507290255
Validation loss: 4.3143457710491395

Epoch: 5| Step: 4
Training loss: 4.43739232752018
Validation loss: 4.309192877506373

Epoch: 5| Step: 5
Training loss: 4.7244583869011425
Validation loss: 4.3043440066150875

Epoch: 5| Step: 6
Training loss: 4.71867522123592
Validation loss: 4.299940192745565

Epoch: 5| Step: 7
Training loss: 4.342658694831419
Validation loss: 4.296009216938337

Epoch: 5| Step: 8
Training loss: 4.8317059813723855
Validation loss: 4.291406774830458

Epoch: 5| Step: 9
Training loss: 3.3453956903682225
Validation loss: 4.2863837320998

Epoch: 5| Step: 10
Training loss: 4.243048424236981
Validation loss: 4.2818724697188895

Epoch: 5| Step: 11
Training loss: 4.190823502927608
Validation loss: 4.276894360861335

Epoch: 25| Step: 0
Training loss: 3.81399031730587
Validation loss: 4.27187069025499

Epoch: 5| Step: 1
Training loss: 3.8513978377422178
Validation loss: 4.267472050073768

Epoch: 5| Step: 2
Training loss: 4.8666033692794235
Validation loss: 4.262934170236087

Epoch: 5| Step: 3
Training loss: 4.798759761163433
Validation loss: 4.257966219025793

Epoch: 5| Step: 4
Training loss: 4.98871387825135
Validation loss: 4.2536674551587295

Epoch: 5| Step: 5
Training loss: 5.015334646787061
Validation loss: 4.250036664879413

Epoch: 5| Step: 6
Training loss: 4.570864600066236
Validation loss: 4.2441241981877775

Epoch: 5| Step: 7
Training loss: 4.915799511663102
Validation loss: 4.240338123187983

Epoch: 5| Step: 8
Training loss: 3.680300133117436
Validation loss: 4.235304192086156

Epoch: 5| Step: 9
Training loss: 4.042566074829248
Validation loss: 4.230894438934909

Epoch: 5| Step: 10
Training loss: 3.7093314781303164
Validation loss: 4.225326968601048

Epoch: 5| Step: 11
Training loss: 0.47967747917021725
Validation loss: 4.220551988966371

Epoch: 26| Step: 0
Training loss: 4.7331654227835305
Validation loss: 4.217080188472768

Epoch: 5| Step: 1
Training loss: 4.617287675058071
Validation loss: 4.2124976792975275

Epoch: 5| Step: 2
Training loss: 3.817416038963866
Validation loss: 4.2073957355596185

Epoch: 5| Step: 3
Training loss: 4.556011864570528
Validation loss: 4.203793015272724

Epoch: 5| Step: 4
Training loss: 4.066658122152722
Validation loss: 4.1993150756197

Epoch: 5| Step: 5
Training loss: 4.316787357680554
Validation loss: 4.195509476776264

Epoch: 5| Step: 6
Training loss: 4.685879846964234
Validation loss: 4.191197044363398

Epoch: 5| Step: 7
Training loss: 4.124188892497056
Validation loss: 4.185898004668055

Epoch: 5| Step: 8
Training loss: 4.070185741713257
Validation loss: 4.18076470300039

Epoch: 5| Step: 9
Training loss: 3.5502676849451262
Validation loss: 4.177006312521927

Epoch: 5| Step: 10
Training loss: 4.566374087648712
Validation loss: 4.173298748780011

Epoch: 5| Step: 11
Training loss: 5.687593899465254
Validation loss: 4.168829307392753

Epoch: 27| Step: 0
Training loss: 4.126993795646735
Validation loss: 4.163150518102725

Epoch: 5| Step: 1
Training loss: 4.02840210617718
Validation loss: 4.158255100597326

Epoch: 5| Step: 2
Training loss: 5.120573225417282
Validation loss: 4.1548460929282225

Epoch: 5| Step: 3
Training loss: 4.3688596960002
Validation loss: 4.150034284067059

Epoch: 5| Step: 4
Training loss: 3.4737418058174514
Validation loss: 4.144671817352861

Epoch: 5| Step: 5
Training loss: 3.5366948104395353
Validation loss: 4.139852674899008

Epoch: 5| Step: 6
Training loss: 4.860680702167931
Validation loss: 4.13523150717344

Epoch: 5| Step: 7
Training loss: 4.321532148000426
Validation loss: 4.13032567489719

Epoch: 5| Step: 8
Training loss: 4.288677149626163
Validation loss: 4.126544417630913

Epoch: 5| Step: 9
Training loss: 3.885072108204648
Validation loss: 4.121439876152874

Epoch: 5| Step: 10
Training loss: 4.682307915523229
Validation loss: 4.1173332955823865

Epoch: 5| Step: 11
Training loss: 4.2458826203834485
Validation loss: 4.112513142905835

Epoch: 28| Step: 0
Training loss: 3.687732495236185
Validation loss: 4.108235195076208

Epoch: 5| Step: 1
Training loss: 4.276691543812002
Validation loss: 4.10411444338703

Epoch: 5| Step: 2
Training loss: 4.214797817824907
Validation loss: 4.099350173362437

Epoch: 5| Step: 3
Training loss: 4.4517066169030635
Validation loss: 4.0948549822590685

Epoch: 5| Step: 4
Training loss: 4.234551119924739
Validation loss: 4.090417597607607

Epoch: 5| Step: 5
Training loss: 4.065613712468117
Validation loss: 4.085567669150377

Epoch: 5| Step: 6
Training loss: 4.376152322785586
Validation loss: 4.080421687723957

Epoch: 5| Step: 7
Training loss: 4.161594482537308
Validation loss: 4.076092058639282

Epoch: 5| Step: 8
Training loss: 4.52561779546882
Validation loss: 4.071334281066973

Epoch: 5| Step: 9
Training loss: 3.9882435885602443
Validation loss: 4.067174071305536

Epoch: 5| Step: 10
Training loss: 4.597067329330245
Validation loss: 4.061831497551874

Epoch: 5| Step: 11
Training loss: 2.5610163976165956
Validation loss: 4.057767811537578

Epoch: 29| Step: 0
Training loss: 4.587714349795796
Validation loss: 4.054310942249106

Epoch: 5| Step: 1
Training loss: 4.29570918133496
Validation loss: 4.049037232974359

Epoch: 5| Step: 2
Training loss: 3.3160177302053335
Validation loss: 4.044241648624181

Epoch: 5| Step: 3
Training loss: 3.536298670509653
Validation loss: 4.039740032772121

Epoch: 5| Step: 4
Training loss: 4.251539512496428
Validation loss: 4.036021014078201

Epoch: 5| Step: 5
Training loss: 4.454989715461548
Validation loss: 4.031035282025397

Epoch: 5| Step: 6
Training loss: 4.394227854110195
Validation loss: 4.0271244229849925

Epoch: 5| Step: 7
Training loss: 4.321817036072459
Validation loss: 4.022317576170908

Epoch: 5| Step: 8
Training loss: 3.5333851798470257
Validation loss: 4.0179724060156685

Epoch: 5| Step: 9
Training loss: 4.660840530230807
Validation loss: 4.012684070468979

Epoch: 5| Step: 10
Training loss: 4.3053923928029905
Validation loss: 4.008566336227332

Epoch: 5| Step: 11
Training loss: 3.5236318327436833
Validation loss: 4.003940712385034

Epoch: 30| Step: 0
Training loss: 3.675073148038365
Validation loss: 3.9997491757906873

Epoch: 5| Step: 1
Training loss: 3.7618579303983526
Validation loss: 3.9950460065357776

Epoch: 5| Step: 2
Training loss: 4.184533278168966
Validation loss: 3.990622605034556

Epoch: 5| Step: 3
Training loss: 3.783943036955153
Validation loss: 3.9863770933755496

Epoch: 5| Step: 4
Training loss: 4.217455630066207
Validation loss: 3.981605544650388

Epoch: 5| Step: 5
Training loss: 4.367433380684449
Validation loss: 3.9769298731013603

Epoch: 5| Step: 6
Training loss: 4.02001665481989
Validation loss: 3.9727568837150744

Epoch: 5| Step: 7
Training loss: 4.251106791272793
Validation loss: 3.9682442500547968

Epoch: 5| Step: 8
Training loss: 4.011521435781732
Validation loss: 3.9640008390565606

Epoch: 5| Step: 9
Training loss: 4.448962812958093
Validation loss: 3.959246959989495

Epoch: 5| Step: 10
Training loss: 4.159327694045647
Validation loss: 3.954537829005105

Epoch: 5| Step: 11
Training loss: 5.180511915325935
Validation loss: 3.9498381991988563

Epoch: 31| Step: 0
Training loss: 3.797400669709937
Validation loss: 3.9450225421372678

Epoch: 5| Step: 1
Training loss: 5.012631863122449
Validation loss: 3.9405176568089306

Epoch: 5| Step: 2
Training loss: 3.742800859425389
Validation loss: 3.9357517337410384

Epoch: 5| Step: 3
Training loss: 3.728899784590037
Validation loss: 3.9305587621764877

Epoch: 5| Step: 4
Training loss: 3.6543324976968288
Validation loss: 3.9258496938024585

Epoch: 5| Step: 5
Training loss: 4.184381490963038
Validation loss: 3.9210856936510656

Epoch: 5| Step: 6
Training loss: 4.88926253673048
Validation loss: 3.9165055701761102

Epoch: 5| Step: 7
Training loss: 3.815567158628504
Validation loss: 3.9119120545061272

Epoch: 5| Step: 8
Training loss: 3.97497239013296
Validation loss: 3.9067418666156137

Epoch: 5| Step: 9
Training loss: 4.419663378294936
Validation loss: 3.9017316550119734

Epoch: 5| Step: 10
Training loss: 3.024451585979689
Validation loss: 3.897150330451786

Epoch: 5| Step: 11
Training loss: 3.8704462674324818
Validation loss: 3.8930540762051806

Epoch: 32| Step: 0
Training loss: 4.570509477592802
Validation loss: 3.888115611095423

Epoch: 5| Step: 1
Training loss: 4.047397182164769
Validation loss: 3.883936493546581

Epoch: 5| Step: 2
Training loss: 3.9723812521968704
Validation loss: 3.8792215854897

Epoch: 5| Step: 3
Training loss: 2.796269100773681
Validation loss: 3.8744019026277896

Epoch: 5| Step: 4
Training loss: 4.185839423397271
Validation loss: 3.8701333228432753

Epoch: 5| Step: 5
Training loss: 4.449505964994263
Validation loss: 3.865823565568951

Epoch: 5| Step: 6
Training loss: 4.4684467346151475
Validation loss: 3.8612079566287663

Epoch: 5| Step: 7
Training loss: 3.6134335377536275
Validation loss: 3.8566559596944785

Epoch: 5| Step: 8
Training loss: 3.263480472488157
Validation loss: 3.8520026274679062

Epoch: 5| Step: 9
Training loss: 4.667416489624862
Validation loss: 3.8475106820133176

Epoch: 5| Step: 10
Training loss: 3.2861712653303705
Validation loss: 3.8427361234075565

Epoch: 5| Step: 11
Training loss: 4.88697225155572
Validation loss: 3.8384544780185634

Epoch: 33| Step: 0
Training loss: 4.230450490135454
Validation loss: 3.8336235572304496

Epoch: 5| Step: 1
Training loss: 3.7761344670259724
Validation loss: 3.828955605632518

Epoch: 5| Step: 2
Training loss: 4.148235653781815
Validation loss: 3.824336755715843

Epoch: 5| Step: 3
Training loss: 3.489501739610839
Validation loss: 3.8195560229023395

Epoch: 5| Step: 4
Training loss: 3.6851171779764997
Validation loss: 3.8149045386397047

Epoch: 5| Step: 5
Training loss: 3.6367323861854985
Validation loss: 3.8097476300269886

Epoch: 5| Step: 6
Training loss: 3.593825098994536
Validation loss: 3.805449825211876

Epoch: 5| Step: 7
Training loss: 4.646952313291148
Validation loss: 3.8008251285666543

Epoch: 5| Step: 8
Training loss: 3.422679092480769
Validation loss: 3.7965054168625683

Epoch: 5| Step: 9
Training loss: 4.05569663012899
Validation loss: 3.79228720285701

Epoch: 5| Step: 10
Training loss: 4.212521398472982
Validation loss: 3.7874503937128083

Epoch: 5| Step: 11
Training loss: 5.265122024556666
Validation loss: 3.7826564211962683

Epoch: 34| Step: 0
Training loss: 4.143568381907903
Validation loss: 3.7776170149813932

Epoch: 5| Step: 1
Training loss: 4.089444757653943
Validation loss: 3.772948713217418

Epoch: 5| Step: 2
Training loss: 3.9140215660284676
Validation loss: 3.7679884525474443

Epoch: 5| Step: 3
Training loss: 4.409506385840989
Validation loss: 3.7632108101413935

Epoch: 5| Step: 4
Training loss: 4.243382182073593
Validation loss: 3.758579466676396

Epoch: 5| Step: 5
Training loss: 3.1406076914751595
Validation loss: 3.753326916457654

Epoch: 5| Step: 6
Training loss: 4.245527719287011
Validation loss: 3.748614691123715

Epoch: 5| Step: 7
Training loss: 3.787776642318003
Validation loss: 3.743668037031053

Epoch: 5| Step: 8
Training loss: 3.4426637185919104
Validation loss: 3.7391685992590786

Epoch: 5| Step: 9
Training loss: 3.62313584375264
Validation loss: 3.7346903137140255

Epoch: 5| Step: 10
Training loss: 3.709790375743353
Validation loss: 3.7296253043077443

Epoch: 5| Step: 11
Training loss: 3.091733333009399
Validation loss: 3.725677822408169

Epoch: 35| Step: 0
Training loss: 3.462712437692085
Validation loss: 3.7217214504098526

Epoch: 5| Step: 1
Training loss: 3.869575518411288
Validation loss: 3.717119821298747

Epoch: 5| Step: 2
Training loss: 4.232771791675671
Validation loss: 3.7122203871454675

Epoch: 5| Step: 3
Training loss: 3.6343354345186887
Validation loss: 3.707462447840767

Epoch: 5| Step: 4
Training loss: 4.202850673189321
Validation loss: 3.7040199936590796

Epoch: 5| Step: 5
Training loss: 3.812585673385811
Validation loss: 3.6991653411672654

Epoch: 5| Step: 6
Training loss: 3.4139694794786206
Validation loss: 3.694884836667477

Epoch: 5| Step: 7
Training loss: 3.634089944670075
Validation loss: 3.69034136662852

Epoch: 5| Step: 8
Training loss: 4.454673096450539
Validation loss: 3.685826061720851

Epoch: 5| Step: 9
Training loss: 3.4449471000961593
Validation loss: 3.681080872256414

Epoch: 5| Step: 10
Training loss: 3.960312050941506
Validation loss: 3.6763077080866826

Epoch: 5| Step: 11
Training loss: 3.3245044769243197
Validation loss: 3.671834396246024

Epoch: 36| Step: 0
Training loss: 4.297103376388351
Validation loss: 3.6673978416084942

Epoch: 5| Step: 1
Training loss: 3.912701337710007
Validation loss: 3.663338791030646

Epoch: 5| Step: 2
Training loss: 4.051972820013834
Validation loss: 3.6587960760136613

Epoch: 5| Step: 3
Training loss: 4.165961600095084
Validation loss: 3.6542321693323094

Epoch: 5| Step: 4
Training loss: 3.3885702772053543
Validation loss: 3.6492302283197247

Epoch: 5| Step: 5
Training loss: 3.2690799816449276
Validation loss: 3.6447925426260057

Epoch: 5| Step: 6
Training loss: 4.245824670205654
Validation loss: 3.6403901511480448

Epoch: 5| Step: 7
Training loss: 3.012159184214839
Validation loss: 3.6357673577888856

Epoch: 5| Step: 8
Training loss: 3.3813899266875023
Validation loss: 3.631049156872141

Epoch: 5| Step: 9
Training loss: 4.090641384805922
Validation loss: 3.627291579880897

Epoch: 5| Step: 10
Training loss: 3.4590530259456433
Validation loss: 3.6228638800705157

Epoch: 5| Step: 11
Training loss: 4.06081789845279
Validation loss: 3.6186672449394934

Epoch: 37| Step: 0
Training loss: 3.6851820044944863
Validation loss: 3.613586467876831

Epoch: 5| Step: 1
Training loss: 3.3138755965057305
Validation loss: 3.6091538343610274

Epoch: 5| Step: 2
Training loss: 3.1082016154208034
Validation loss: 3.6046985259519246

Epoch: 5| Step: 3
Training loss: 3.7305284425443435
Validation loss: 3.6003851134887244

Epoch: 5| Step: 4
Training loss: 3.5575763072812516
Validation loss: 3.596152605415893

Epoch: 5| Step: 5
Training loss: 3.8719275815039635
Validation loss: 3.591830279893474

Epoch: 5| Step: 6
Training loss: 3.8692734766281998
Validation loss: 3.5871731105214204

Epoch: 5| Step: 7
Training loss: 3.7590317364099115
Validation loss: 3.5829922195834163

Epoch: 5| Step: 8
Training loss: 4.346938684958201
Validation loss: 3.578579181125765

Epoch: 5| Step: 9
Training loss: 3.830258891865005
Validation loss: 3.573572185798722

Epoch: 5| Step: 10
Training loss: 3.6009813613557546
Validation loss: 3.569646304335691

Epoch: 5| Step: 11
Training loss: 4.606390966693677
Validation loss: 3.5647871249409286

Epoch: 38| Step: 0
Training loss: 3.832124450359037
Validation loss: 3.560002516752775

Epoch: 5| Step: 1
Training loss: 3.394236948053817
Validation loss: 3.555548058607887

Epoch: 5| Step: 2
Training loss: 4.292310919443605
Validation loss: 3.5508209215108555

Epoch: 5| Step: 3
Training loss: 3.4201759056674277
Validation loss: 3.5462223298323705

Epoch: 5| Step: 4
Training loss: 4.232492401422664
Validation loss: 3.541732763159828

Epoch: 5| Step: 5
Training loss: 3.616752977410729
Validation loss: 3.53723111181006

Epoch: 5| Step: 6
Training loss: 4.180082213400953
Validation loss: 3.532240939565882

Epoch: 5| Step: 7
Training loss: 3.9876927344162576
Validation loss: 3.5277949960209996

Epoch: 5| Step: 8
Training loss: 2.7961295215911712
Validation loss: 3.522945524774643

Epoch: 5| Step: 9
Training loss: 3.372476694126914
Validation loss: 3.5183364866854876

Epoch: 5| Step: 10
Training loss: 3.1081997744695715
Validation loss: 3.5140023054047695

Epoch: 5| Step: 11
Training loss: 3.0058573127328048
Validation loss: 3.5092669886212504

Epoch: 39| Step: 0
Training loss: 3.7811991790635004
Validation loss: 3.5052410632452764

Epoch: 5| Step: 1
Training loss: 3.3915943922235607
Validation loss: 3.5012658929379

Epoch: 5| Step: 2
Training loss: 4.151975570533341
Validation loss: 3.4967848906215107

Epoch: 5| Step: 3
Training loss: 2.9890234729793415
Validation loss: 3.492255418587793

Epoch: 5| Step: 4
Training loss: 2.9765815634129535
Validation loss: 3.487593032935965

Epoch: 5| Step: 5
Training loss: 3.4436566791940386
Validation loss: 3.483974245571856

Epoch: 5| Step: 6
Training loss: 3.9657086110300206
Validation loss: 3.479551120843897

Epoch: 5| Step: 7
Training loss: 3.2962265461682927
Validation loss: 3.4754810094111943

Epoch: 5| Step: 8
Training loss: 3.6447204344487227
Validation loss: 3.471555674895863

Epoch: 5| Step: 9
Training loss: 3.781451133233731
Validation loss: 3.4674325050453665

Epoch: 5| Step: 10
Training loss: 4.087106220280967
Validation loss: 3.463198320202065

Epoch: 5| Step: 11
Training loss: 4.104188844779002
Validation loss: 3.458993370005685

Epoch: 40| Step: 0
Training loss: 3.7708965457795536
Validation loss: 3.4545977057018167

Epoch: 5| Step: 1
Training loss: 3.8886527459034776
Validation loss: 3.4502890205488477

Epoch: 5| Step: 2
Training loss: 3.745248199916728
Validation loss: 3.445743386794841

Epoch: 5| Step: 3
Training loss: 4.250397607492427
Validation loss: 3.4410206942839054

Epoch: 5| Step: 4
Training loss: 4.02470706797802
Validation loss: 3.436353237876584

Epoch: 5| Step: 5
Training loss: 3.2682382449243104
Validation loss: 3.431685413928805

Epoch: 5| Step: 6
Training loss: 3.296495894922622
Validation loss: 3.427163813997774

Epoch: 5| Step: 7
Training loss: 2.7513669691304394
Validation loss: 3.422440817399966

Epoch: 5| Step: 8
Training loss: 3.4647757642886154
Validation loss: 3.4182252246361795

Epoch: 5| Step: 9
Training loss: 3.401934768849748
Validation loss: 3.41391630172501

Epoch: 5| Step: 10
Training loss: 3.4052380099694965
Validation loss: 3.4102362775934583

Epoch: 5| Step: 11
Training loss: 2.3365940970100323
Validation loss: 3.4054385394006115

Epoch: 41| Step: 0
Training loss: 2.6975159414985246
Validation loss: 3.40150423200072

Epoch: 5| Step: 1
Training loss: 3.554794544662285
Validation loss: 3.3976542889403785

Epoch: 5| Step: 2
Training loss: 3.4804965616435815
Validation loss: 3.3939156919793265

Epoch: 5| Step: 3
Training loss: 3.853616472443387
Validation loss: 3.3897589120874083

Epoch: 5| Step: 4
Training loss: 3.5787074518689024
Validation loss: 3.385824669925373

Epoch: 5| Step: 5
Training loss: 3.6559946345951433
Validation loss: 3.3813740474254015

Epoch: 5| Step: 6
Training loss: 3.545622348148962
Validation loss: 3.3772660524677356

Epoch: 5| Step: 7
Training loss: 4.112671664751017
Validation loss: 3.3729410248776746

Epoch: 5| Step: 8
Training loss: 3.1367000517519434
Validation loss: 3.3689091198391194

Epoch: 5| Step: 9
Training loss: 3.7034234679132267
Validation loss: 3.364785177516547

Epoch: 5| Step: 10
Training loss: 3.188603677596318
Validation loss: 3.360726237045364

Epoch: 5| Step: 11
Training loss: 3.606019148553075
Validation loss: 3.356876994077774

Epoch: 42| Step: 0
Training loss: 2.3514150782408074
Validation loss: 3.352150563873178

Epoch: 5| Step: 1
Training loss: 3.6917631430896662
Validation loss: 3.3484998817346994

Epoch: 5| Step: 2
Training loss: 3.895538414112693
Validation loss: 3.3444725040372556

Epoch: 5| Step: 3
Training loss: 3.745430514720649
Validation loss: 3.3403315851517665

Epoch: 5| Step: 4
Training loss: 3.6993287018786876
Validation loss: 3.336379719472108

Epoch: 5| Step: 5
Training loss: 2.890647104539639
Validation loss: 3.3318956950536096

Epoch: 5| Step: 6
Training loss: 3.8613787557536674
Validation loss: 3.3274460101410885

Epoch: 5| Step: 7
Training loss: 2.8412895877226716
Validation loss: 3.323304573226064

Epoch: 5| Step: 8
Training loss: 3.948658708203593
Validation loss: 3.319271382183606

Epoch: 5| Step: 9
Training loss: 3.777188602642076
Validation loss: 3.3151451861452563

Epoch: 5| Step: 10
Training loss: 3.2105161664241164
Validation loss: 3.310944233830943

Epoch: 5| Step: 11
Training loss: 2.6534353265696144
Validation loss: 3.306664319750571

Epoch: 43| Step: 0
Training loss: 3.4995501092865102
Validation loss: 3.3027773327386454

Epoch: 5| Step: 1
Training loss: 2.9081437698568524
Validation loss: 3.2989326853468297

Epoch: 5| Step: 2
Training loss: 3.6109511331839808
Validation loss: 3.295314262706803

Epoch: 5| Step: 3
Training loss: 3.7559935674236495
Validation loss: 3.2913593146732842

Epoch: 5| Step: 4
Training loss: 3.8552041934071104
Validation loss: 3.2874217769855743

Epoch: 5| Step: 5
Training loss: 3.3498103757112365
Validation loss: 3.2830492415136447

Epoch: 5| Step: 6
Training loss: 3.2329472878309593
Validation loss: 3.2786522467047776

Epoch: 5| Step: 7
Training loss: 3.736138729354207
Validation loss: 3.274646830019399

Epoch: 5| Step: 8
Training loss: 3.2148232812797657
Validation loss: 3.2705788705737544

Epoch: 5| Step: 9
Training loss: 2.8879023746358268
Validation loss: 3.266773210624006

Epoch: 5| Step: 10
Training loss: 3.490307875992298
Validation loss: 3.2629464646632873

Epoch: 5| Step: 11
Training loss: 3.263386520430284
Validation loss: 3.2593317308781535

Epoch: 44| Step: 0
Training loss: 4.125879829672271
Validation loss: 3.2554837326536266

Epoch: 5| Step: 1
Training loss: 3.661163159008334
Validation loss: 3.2512767680257983

Epoch: 5| Step: 2
Training loss: 3.6265984003803897
Validation loss: 3.246799580466363

Epoch: 5| Step: 3
Training loss: 3.1220205217721904
Validation loss: 3.2438470966798647

Epoch: 5| Step: 4
Training loss: 3.0868179803537896
Validation loss: 3.2394829803002434

Epoch: 5| Step: 5
Training loss: 3.5485450073243183
Validation loss: 3.2358093459833133

Epoch: 5| Step: 6
Training loss: 3.2496758812895568
Validation loss: 3.231388703695145

Epoch: 5| Step: 7
Training loss: 3.8460604538949528
Validation loss: 3.227604695401598

Epoch: 5| Step: 8
Training loss: 3.1229909924057515
Validation loss: 3.2231254220700514

Epoch: 5| Step: 9
Training loss: 2.210688816278635
Validation loss: 3.2192786409145233

Epoch: 5| Step: 10
Training loss: 3.292836830329483
Validation loss: 3.2157618253493867

Epoch: 5| Step: 11
Training loss: 2.743942264433276
Validation loss: 3.212023759366082

Epoch: 45| Step: 0
Training loss: 2.88181426176828
Validation loss: 3.208180589053708

Epoch: 5| Step: 1
Training loss: 4.05633570223467
Validation loss: 3.204908621810007

Epoch: 5| Step: 2
Training loss: 3.911410897378321
Validation loss: 3.2005247214872843

Epoch: 5| Step: 3
Training loss: 3.226767471120766
Validation loss: 3.1965566760669053

Epoch: 5| Step: 4
Training loss: 3.616216080074996
Validation loss: 3.193064031446359

Epoch: 5| Step: 5
Training loss: 3.4491969072248643
Validation loss: 3.1891651603675903

Epoch: 5| Step: 6
Training loss: 2.4324105755794845
Validation loss: 3.1847804504271555

Epoch: 5| Step: 7
Training loss: 3.034539865872716
Validation loss: 3.1811835029112423

Epoch: 5| Step: 8
Training loss: 3.7573208873949655
Validation loss: 3.1774293658981807

Epoch: 5| Step: 9
Training loss: 3.3337127628542453
Validation loss: 3.1735533829151814

Epoch: 5| Step: 10
Training loss: 2.592338269742772
Validation loss: 3.1699218561968094

Epoch: 5| Step: 11
Training loss: 3.0304303191645117
Validation loss: 3.166574380600681

Epoch: 46| Step: 0
Training loss: 3.4308985351217807
Validation loss: 3.1634921215215113

Epoch: 5| Step: 1
Training loss: 3.311139673142556
Validation loss: 3.1599507935028694

Epoch: 5| Step: 2
Training loss: 3.1211195695212535
Validation loss: 3.156573433246088

Epoch: 5| Step: 3
Training loss: 3.404954016286761
Validation loss: 3.152734911039519

Epoch: 5| Step: 4
Training loss: 3.5176255701096526
Validation loss: 3.1495637669825847

Epoch: 5| Step: 5
Training loss: 3.286175038036659
Validation loss: 3.145833644909033

Epoch: 5| Step: 6
Training loss: 3.4450201831774514
Validation loss: 3.1426810624495984

Epoch: 5| Step: 7
Training loss: 3.477617630878455
Validation loss: 3.138762400947116

Epoch: 5| Step: 8
Training loss: 3.1214099862280227
Validation loss: 3.1352878535647397

Epoch: 5| Step: 9
Training loss: 3.061592123182863
Validation loss: 3.131539254905004

Epoch: 5| Step: 10
Training loss: 3.0045904960188983
Validation loss: 3.1283582508318952

Epoch: 5| Step: 11
Training loss: 2.9559096674763716
Validation loss: 3.1247558434791864

Epoch: 47| Step: 0
Training loss: 3.595685354807393
Validation loss: 3.121173973787147

Epoch: 5| Step: 1
Training loss: 3.25914826669736
Validation loss: 3.118179603201026

Epoch: 5| Step: 2
Training loss: 2.8369922200399813
Validation loss: 3.1147349691743

Epoch: 5| Step: 3
Training loss: 3.412432597965378
Validation loss: 3.110682252624398

Epoch: 5| Step: 4
Training loss: 2.9449224643830654
Validation loss: 3.107203189964086

Epoch: 5| Step: 5
Training loss: 3.2211614667800124
Validation loss: 3.103632962133549

Epoch: 5| Step: 6
Training loss: 2.9726451818433075
Validation loss: 3.1000973422138993

Epoch: 5| Step: 7
Training loss: 2.6984523894269747
Validation loss: 3.096961836330414

Epoch: 5| Step: 8
Training loss: 2.9913289006081847
Validation loss: 3.0938366579191605

Epoch: 5| Step: 9
Training loss: 3.968535409968128
Validation loss: 3.090306063795233

Epoch: 5| Step: 10
Training loss: 3.3823774732007394
Validation loss: 3.087038801344612

Epoch: 5| Step: 11
Training loss: 4.169911125937551
Validation loss: 3.0835114805633514

Epoch: 48| Step: 0
Training loss: 2.9536649018700585
Validation loss: 3.07991178003315

Epoch: 5| Step: 1
Training loss: 3.562794991041915
Validation loss: 3.076161947890315

Epoch: 5| Step: 2
Training loss: 3.2250914094966943
Validation loss: 3.07331610632045

Epoch: 5| Step: 3
Training loss: 3.604779641536787
Validation loss: 3.069501363625446

Epoch: 5| Step: 4
Training loss: 3.0985961873426415
Validation loss: 3.065854162581094

Epoch: 5| Step: 5
Training loss: 3.53074966532006
Validation loss: 3.0627396029209026

Epoch: 5| Step: 6
Training loss: 2.9297869449268106
Validation loss: 3.058507210849861

Epoch: 5| Step: 7
Training loss: 2.6450887117850868
Validation loss: 3.0554004627420452

Epoch: 5| Step: 8
Training loss: 3.653190049635705
Validation loss: 3.0525209169611034

Epoch: 5| Step: 9
Training loss: 2.970661551782164
Validation loss: 3.0488394476977434

Epoch: 5| Step: 10
Training loss: 3.101210720762185
Validation loss: 3.0450631843550937

Epoch: 5| Step: 11
Training loss: 1.9633721667185684
Validation loss: 3.0416839525088686

Epoch: 49| Step: 0
Training loss: 2.8055080393008223
Validation loss: 3.038820817714034

Epoch: 5| Step: 1
Training loss: 2.778032477675789
Validation loss: 3.035366965842412

Epoch: 5| Step: 2
Training loss: 2.7391258602354234
Validation loss: 3.0327899206815614

Epoch: 5| Step: 3
Training loss: 3.3277829849663783
Validation loss: 3.0297901466035486

Epoch: 5| Step: 4
Training loss: 3.0635402236272706
Validation loss: 3.0266773762037333

Epoch: 5| Step: 5
Training loss: 3.1365205124935764
Validation loss: 3.024354935140862

Epoch: 5| Step: 6
Training loss: 3.584789482969262
Validation loss: 3.021101786205967

Epoch: 5| Step: 7
Training loss: 3.6106814707598582
Validation loss: 3.0174783996761274

Epoch: 5| Step: 8
Training loss: 3.288936367923675
Validation loss: 3.0140629710527826

Epoch: 5| Step: 9
Training loss: 3.1082820025612685
Validation loss: 3.0110276217154954

Epoch: 5| Step: 10
Training loss: 3.174058284923853
Validation loss: 3.008230759905245

Epoch: 5| Step: 11
Training loss: 3.4107795486540318
Validation loss: 3.00516552401529

Epoch: 50| Step: 0
Training loss: 3.360728146582513
Validation loss: 3.0016646932256195

Epoch: 5| Step: 1
Training loss: 2.9393914808735553
Validation loss: 2.998258462702299

Epoch: 5| Step: 2
Training loss: 3.7068920692227083
Validation loss: 2.994764431815771

Epoch: 5| Step: 3
Training loss: 2.6806871868310442
Validation loss: 2.991637482319252

Epoch: 5| Step: 4
Training loss: 3.128564403971471
Validation loss: 2.988306009692837

Epoch: 5| Step: 5
Training loss: 3.0764232908171505
Validation loss: 2.9852176395384524

Epoch: 5| Step: 6
Training loss: 2.9237314130527428
Validation loss: 2.982112452942397

Epoch: 5| Step: 7
Training loss: 3.0259764112219996
Validation loss: 2.9792486770830533

Epoch: 5| Step: 8
Training loss: 3.2207707848506333
Validation loss: 2.975710489078227

Epoch: 5| Step: 9
Training loss: 2.607372132016152
Validation loss: 2.9726331344821926

Epoch: 5| Step: 10
Training loss: 3.3408153169266215
Validation loss: 2.970106631386683

Epoch: 5| Step: 11
Training loss: 4.198036715902615
Validation loss: 2.9661036759959507

Epoch: 51| Step: 0
Training loss: 2.8010368709350555
Validation loss: 2.9637011745994455

Epoch: 5| Step: 1
Training loss: 3.149648580173488
Validation loss: 2.961112544808111

Epoch: 5| Step: 2
Training loss: 3.3520541597420155
Validation loss: 2.956977144970044

Epoch: 5| Step: 3
Training loss: 3.0867059837237583
Validation loss: 2.953398770891145

Epoch: 5| Step: 4
Training loss: 3.029402966489276
Validation loss: 2.9500607465427104

Epoch: 5| Step: 5
Training loss: 3.5229296942134813
Validation loss: 2.9468527020729662

Epoch: 5| Step: 6
Training loss: 3.0943439568534443
Validation loss: 2.9439749847039103

Epoch: 5| Step: 7
Training loss: 3.0885482367734625
Validation loss: 2.941160673889112

Epoch: 5| Step: 8
Training loss: 2.8439879265487362
Validation loss: 2.937490125057856

Epoch: 5| Step: 9
Training loss: 3.04925584939119
Validation loss: 2.9391884246300592

Epoch: 5| Step: 10
Training loss: 3.1855706752540547
Validation loss: 2.9458446780790717

Epoch: 5| Step: 11
Training loss: 1.4880249123077334
Validation loss: 2.9288771055271865

Epoch: 52| Step: 0
Training loss: 2.805652080633787
Validation loss: 2.9300800145315242

Epoch: 5| Step: 1
Training loss: 2.4373296042329624
Validation loss: 2.9370125203753843

Epoch: 5| Step: 2
Training loss: 3.5781519193344646
Validation loss: 2.9490967748483445

Epoch: 5| Step: 3
Training loss: 3.061836949408107
Validation loss: 2.9504248437084426

Epoch: 5| Step: 4
Training loss: 2.8839251430917954
Validation loss: 2.931684195075912

Epoch: 5| Step: 5
Training loss: 2.863831595994654
Validation loss: 2.922813016767105

Epoch: 5| Step: 6
Training loss: 3.6167111834995995
Validation loss: 2.920828228881192

Epoch: 5| Step: 7
Training loss: 3.735188415554806
Validation loss: 2.9162308753376163

Epoch: 5| Step: 8
Training loss: 2.994736026855194
Validation loss: 2.9137192081606567

Epoch: 5| Step: 9
Training loss: 2.6689315555467807
Validation loss: 2.9109535644109825

Epoch: 5| Step: 10
Training loss: 2.8414553931965707
Validation loss: 2.909533949162528

Epoch: 5| Step: 11
Training loss: 3.0663051710052276
Validation loss: 2.907304223932264

Epoch: 53| Step: 0
Training loss: 3.0459488463687014
Validation loss: 2.906970826863765

Epoch: 5| Step: 1
Training loss: 3.1351674805703102
Validation loss: 2.9048385816123927

Epoch: 5| Step: 2
Training loss: 2.7923850563319395
Validation loss: 2.902669834389168

Epoch: 5| Step: 3
Training loss: 2.554556560368803
Validation loss: 2.896483551868983

Epoch: 5| Step: 4
Training loss: 2.1152960291900462
Validation loss: 2.8923662869235516

Epoch: 5| Step: 5
Training loss: 3.4481026559935146
Validation loss: 2.888983822499658

Epoch: 5| Step: 6
Training loss: 3.0609977307315903
Validation loss: 2.885230069834806

Epoch: 5| Step: 7
Training loss: 2.963746361571371
Validation loss: 2.8820987944780883

Epoch: 5| Step: 8
Training loss: 3.2560001152938334
Validation loss: 2.8787692523521784

Epoch: 5| Step: 9
Training loss: 3.47696764010494
Validation loss: 2.8762093847535786

Epoch: 5| Step: 10
Training loss: 3.235582209321279
Validation loss: 2.8729718386742285

Epoch: 5| Step: 11
Training loss: 2.9640000742450248
Validation loss: 2.8708468030402257

Epoch: 54| Step: 0
Training loss: 2.9964817397695684
Validation loss: 2.8684167262501665

Epoch: 5| Step: 1
Training loss: 3.2799879280891635
Validation loss: 2.8645951438429145

Epoch: 5| Step: 2
Training loss: 3.091137486194545
Validation loss: 2.8618607998437557

Epoch: 5| Step: 3
Training loss: 2.7964393660057394
Validation loss: 2.859110178956941

Epoch: 5| Step: 4
Training loss: 3.110447377596018
Validation loss: 2.8560082325634166

Epoch: 5| Step: 5
Training loss: 2.5165882043628303
Validation loss: 2.853441091648084

Epoch: 5| Step: 6
Training loss: 2.8018336320725297
Validation loss: 2.8512895078930773

Epoch: 5| Step: 7
Training loss: 3.1434327285871464
Validation loss: 2.8484678921426956

Epoch: 5| Step: 8
Training loss: 3.1631251324177043
Validation loss: 2.846221115664908

Epoch: 5| Step: 9
Training loss: 3.417785988417366
Validation loss: 2.8431007636241916

Epoch: 5| Step: 10
Training loss: 2.5977441758498125
Validation loss: 2.8413508009410204

Epoch: 5| Step: 11
Training loss: 2.5074297176107097
Validation loss: 2.8376472825632857

Epoch: 55| Step: 0
Training loss: 3.400882236235358
Validation loss: 2.8364368871260295

Epoch: 5| Step: 1
Training loss: 2.822833258228294
Validation loss: 2.83370206107194

Epoch: 5| Step: 2
Training loss: 2.640265445946872
Validation loss: 2.8298047558738433

Epoch: 5| Step: 3
Training loss: 3.0351427389700887
Validation loss: 2.8277823203688857

Epoch: 5| Step: 4
Training loss: 3.150577395366496
Validation loss: 2.827724639205519

Epoch: 5| Step: 5
Training loss: 3.14802900745449
Validation loss: 2.8227550007509463

Epoch: 5| Step: 6
Training loss: 2.248927602577126
Validation loss: 2.821655270797

Epoch: 5| Step: 7
Training loss: 3.2558009388970857
Validation loss: 2.8198899985563495

Epoch: 5| Step: 8
Training loss: 2.9104410121794215
Validation loss: 2.8170582144112513

Epoch: 5| Step: 9
Training loss: 3.137599417642542
Validation loss: 2.816206951029625

Epoch: 5| Step: 10
Training loss: 2.5676075346211427
Validation loss: 2.8121738244699266

Epoch: 5| Step: 11
Training loss: 3.5054661437284858
Validation loss: 2.8093587994417795

Epoch: 56| Step: 0
Training loss: 3.3617322591252647
Validation loss: 2.808068563693835

Epoch: 5| Step: 1
Training loss: 2.365488178927554
Validation loss: 2.806794624466098

Epoch: 5| Step: 2
Training loss: 2.68180118755252
Validation loss: 2.8032140057799144

Epoch: 5| Step: 3
Training loss: 2.7417996124066955
Validation loss: 2.801047794386882

Epoch: 5| Step: 4
Training loss: 2.5591157104162594
Validation loss: 2.797447312972228

Epoch: 5| Step: 5
Training loss: 3.2238915127848293
Validation loss: 2.7963313670136882

Epoch: 5| Step: 6
Training loss: 2.8742427657986034
Validation loss: 2.7942808399335304

Epoch: 5| Step: 7
Training loss: 3.0840200913760647
Validation loss: 2.792506733274069

Epoch: 5| Step: 8
Training loss: 2.6865798794507176
Validation loss: 2.789974159818371

Epoch: 5| Step: 9
Training loss: 3.1068938050576755
Validation loss: 2.7871374580164296

Epoch: 5| Step: 10
Training loss: 3.1391394598618767
Validation loss: 2.78484091951017

Epoch: 5| Step: 11
Training loss: 4.2478387610659905
Validation loss: 2.78314145382377

Epoch: 57| Step: 0
Training loss: 3.3064743513920645
Validation loss: 2.7804026223636926

Epoch: 5| Step: 1
Training loss: 2.148398992019954
Validation loss: 2.779358163257497

Epoch: 5| Step: 2
Training loss: 2.849089252781053
Validation loss: 2.777333513072016

Epoch: 5| Step: 3
Training loss: 2.5735631174396714
Validation loss: 2.7762070559438343

Epoch: 5| Step: 4
Training loss: 3.0762923153505524
Validation loss: 2.774542216897475

Epoch: 5| Step: 5
Training loss: 2.8879302790037573
Validation loss: 2.7721607941122453

Epoch: 5| Step: 6
Training loss: 3.024274527829399
Validation loss: 2.769217397592667

Epoch: 5| Step: 7
Training loss: 2.6615371144996516
Validation loss: 2.7671529855699166

Epoch: 5| Step: 8
Training loss: 3.2002906726904468
Validation loss: 2.763478295473997

Epoch: 5| Step: 9
Training loss: 3.0209172905841517
Validation loss: 2.76143820712251

Epoch: 5| Step: 10
Training loss: 3.2615412680941884
Validation loss: 2.760294621246767

Epoch: 5| Step: 11
Training loss: 1.7941756829960849
Validation loss: 2.7574460665989973

Epoch: 58| Step: 0
Training loss: 2.194026909982208
Validation loss: 2.754345411991902

Epoch: 5| Step: 1
Training loss: 3.3089370279231276
Validation loss: 2.753629801336558

Epoch: 5| Step: 2
Training loss: 2.761939486432512
Validation loss: 2.75722788881203

Epoch: 5| Step: 3
Training loss: 2.892404864039952
Validation loss: 2.768546047118719

Epoch: 5| Step: 4
Training loss: 2.9739148637274773
Validation loss: 2.7599962790090937

Epoch: 5| Step: 5
Training loss: 3.1465480236811945
Validation loss: 2.747859761389026

Epoch: 5| Step: 6
Training loss: 2.710959486638596
Validation loss: 2.7425453843679586

Epoch: 5| Step: 7
Training loss: 2.8457812087133845
Validation loss: 2.7448592904511364

Epoch: 5| Step: 8
Training loss: 2.689646462532633
Validation loss: 2.747762401888675

Epoch: 5| Step: 9
Training loss: 3.1596465012044055
Validation loss: 2.755302417977957

Epoch: 5| Step: 10
Training loss: 2.925801459167521
Validation loss: 2.75673239776226

Epoch: 5| Step: 11
Training loss: 3.1281982840109985
Validation loss: 2.7525341538710513

Epoch: 59| Step: 0
Training loss: 2.735281483393619
Validation loss: 2.7412788863775743

Epoch: 5| Step: 1
Training loss: 2.8797813131168404
Validation loss: 2.7331723356709414

Epoch: 5| Step: 2
Training loss: 2.820870552963164
Validation loss: 2.730441299322319

Epoch: 5| Step: 3
Training loss: 2.638155894510913
Validation loss: 2.7270969460956063

Epoch: 5| Step: 4
Training loss: 2.7695174761646206
Validation loss: 2.7253447530388075

Epoch: 5| Step: 5
Training loss: 2.936270923369437
Validation loss: 2.7290570016235747

Epoch: 5| Step: 6
Training loss: 2.8800261970494154
Validation loss: 2.7308085006917286

Epoch: 5| Step: 7
Training loss: 2.9265187942003066
Validation loss: 2.7322646253272738

Epoch: 5| Step: 8
Training loss: 2.944025299741009
Validation loss: 2.735375978632578

Epoch: 5| Step: 9
Training loss: 2.89567989976606
Validation loss: 2.7317178985926613

Epoch: 5| Step: 10
Training loss: 3.1131129201376284
Validation loss: 2.7252991818318155

Epoch: 5| Step: 11
Training loss: 3.156674196045653
Validation loss: 2.7132654043332276

Epoch: 60| Step: 0
Training loss: 2.4749204565039515
Validation loss: 2.708794948167985

Epoch: 5| Step: 1
Training loss: 3.260848060481715
Validation loss: 2.70931403426261

Epoch: 5| Step: 2
Training loss: 2.620155769260291
Validation loss: 2.709067059432873

Epoch: 5| Step: 3
Training loss: 2.8193200391394484
Validation loss: 2.7074479758940426

Epoch: 5| Step: 4
Training loss: 2.950610508219582
Validation loss: 2.710266678892424

Epoch: 5| Step: 5
Training loss: 3.1616893769773937
Validation loss: 2.7099492546494135

Epoch: 5| Step: 6
Training loss: 2.711307555344463
Validation loss: 2.707398254411844

Epoch: 5| Step: 7
Training loss: 2.573325481188691
Validation loss: 2.705006894345526

Epoch: 5| Step: 8
Training loss: 2.9106000933033047
Validation loss: 2.7018105649857285

Epoch: 5| Step: 9
Training loss: 3.0522082480081507
Validation loss: 2.6979437216699518

Epoch: 5| Step: 10
Training loss: 2.728132085801893
Validation loss: 2.695228984478733

Epoch: 5| Step: 11
Training loss: 2.514688068559065
Validation loss: 2.692550545108508

Epoch: 61| Step: 0
Training loss: 3.3908251162773415
Validation loss: 2.6910737953021338

Epoch: 5| Step: 1
Training loss: 2.51369037043385
Validation loss: 2.6889918792217062

Epoch: 5| Step: 2
Training loss: 3.292895767652097
Validation loss: 2.6868039087256688

Epoch: 5| Step: 3
Training loss: 2.3985870016516366
Validation loss: 2.688190220018941

Epoch: 5| Step: 4
Training loss: 2.7706760467019276
Validation loss: 2.683038175581908

Epoch: 5| Step: 5
Training loss: 2.993376572798616
Validation loss: 2.683793965088962

Epoch: 5| Step: 6
Training loss: 2.476962373142036
Validation loss: 2.6810824152897346

Epoch: 5| Step: 7
Training loss: 3.152454322284362
Validation loss: 2.6812962632534045

Epoch: 5| Step: 8
Training loss: 2.3943625759438705
Validation loss: 2.6790468026475596

Epoch: 5| Step: 9
Training loss: 3.095377638399586
Validation loss: 2.677303428854611

Epoch: 5| Step: 10
Training loss: 2.512633351445285
Validation loss: 2.6747867341754605

Epoch: 5| Step: 11
Training loss: 1.544989390290506
Validation loss: 2.6713372334428094

Epoch: 62| Step: 0
Training loss: 3.0415996561550886
Validation loss: 2.6691684659851975

Epoch: 5| Step: 1
Training loss: 2.7071256634870418
Validation loss: 2.6704032443546457

Epoch: 5| Step: 2
Training loss: 2.5381410775500877
Validation loss: 2.671877636080923

Epoch: 5| Step: 3
Training loss: 2.5725061395421736
Validation loss: 2.669861810283442

Epoch: 5| Step: 4
Training loss: 2.821976527418552
Validation loss: 2.670991844575638

Epoch: 5| Step: 5
Training loss: 2.6123684827198588
Validation loss: 2.669242264509448

Epoch: 5| Step: 6
Training loss: 2.9600521162960907
Validation loss: 2.668299262154728

Epoch: 5| Step: 7
Training loss: 2.3725459822126993
Validation loss: 2.6663044420238

Epoch: 5| Step: 8
Training loss: 3.28903509930503
Validation loss: 2.666544271928599

Epoch: 5| Step: 9
Training loss: 2.8933585773485975
Validation loss: 2.662767030043966

Epoch: 5| Step: 10
Training loss: 2.995358691508564
Validation loss: 2.6599542108815735

Epoch: 5| Step: 11
Training loss: 2.4230037888935363
Validation loss: 2.6567712683728106

Epoch: 63| Step: 0
Training loss: 2.877567305983279
Validation loss: 2.655240267150892

Epoch: 5| Step: 1
Training loss: 2.9536309994534893
Validation loss: 2.6531335050987988

Epoch: 5| Step: 2
Training loss: 2.6930936221660517
Validation loss: 2.6499044731004586

Epoch: 5| Step: 3
Training loss: 3.224477172581475
Validation loss: 2.6490670790247783

Epoch: 5| Step: 4
Training loss: 2.702917543068768
Validation loss: 2.648547291238222

Epoch: 5| Step: 5
Training loss: 2.588489759655202
Validation loss: 2.647832274323905

Epoch: 5| Step: 6
Training loss: 2.490084056431281
Validation loss: 2.6470683074165233

Epoch: 5| Step: 7
Training loss: 2.8735049133524284
Validation loss: 2.64276691522701

Epoch: 5| Step: 8
Training loss: 2.4897571540283114
Validation loss: 2.643402241770361

Epoch: 5| Step: 9
Training loss: 2.996594562476344
Validation loss: 2.6413742259056048

Epoch: 5| Step: 10
Training loss: 2.8131585939507993
Validation loss: 2.639708655307098

Epoch: 5| Step: 11
Training loss: 1.6445000797316942
Validation loss: 2.637959875298137

Epoch: 64| Step: 0
Training loss: 2.873391074406596
Validation loss: 2.6412544666462536

Epoch: 5| Step: 1
Training loss: 2.5514894585979433
Validation loss: 2.6443663282258982

Epoch: 5| Step: 2
Training loss: 2.1072130214656686
Validation loss: 2.671504145533897

Epoch: 5| Step: 3
Training loss: 3.034587792145303
Validation loss: 2.7192015839206425

Epoch: 5| Step: 4
Training loss: 2.833045178140348
Validation loss: 2.6958007554547883

Epoch: 5| Step: 5
Training loss: 3.3033893461383226
Validation loss: 2.6496167928501952

Epoch: 5| Step: 6
Training loss: 3.1309687261588177
Validation loss: 2.63269194752398

Epoch: 5| Step: 7
Training loss: 2.9532546564935904
Validation loss: 2.631994012675099

Epoch: 5| Step: 8
Training loss: 2.1186898732163773
Validation loss: 2.6387759625103198

Epoch: 5| Step: 9
Training loss: 3.0753567248345925
Validation loss: 2.6508937387220692

Epoch: 5| Step: 10
Training loss: 2.5249164605248615
Validation loss: 2.668176463257742

Epoch: 5| Step: 11
Training loss: 3.2675238386479775
Validation loss: 2.6906378377622198

Epoch: 65| Step: 0
Training loss: 2.6618332471257755
Validation loss: 2.64840825382615

Epoch: 5| Step: 1
Training loss: 2.2710025502656284
Validation loss: 2.638483902461686

Epoch: 5| Step: 2
Training loss: 2.639547545790846
Validation loss: 2.628926016821572

Epoch: 5| Step: 3
Training loss: 2.465592791947678
Validation loss: 2.6263171516910386

Epoch: 5| Step: 4
Training loss: 2.7675030037881734
Validation loss: 2.622959475411589

Epoch: 5| Step: 5
Training loss: 2.868512006208226
Validation loss: 2.622391244580605

Epoch: 5| Step: 6
Training loss: 2.8963243539326866
Validation loss: 2.624852123333811

Epoch: 5| Step: 7
Training loss: 2.8655091240437582
Validation loss: 2.622679884728995

Epoch: 5| Step: 8
Training loss: 3.1268710829142026
Validation loss: 2.6228384776400597

Epoch: 5| Step: 9
Training loss: 2.4999158845102096
Validation loss: 2.6263681736606648

Epoch: 5| Step: 10
Training loss: 3.1902942751336725
Validation loss: 2.6403966161616648

Epoch: 5| Step: 11
Training loss: 2.976600146118152
Validation loss: 2.634025739427694

Epoch: 66| Step: 0
Training loss: 2.827456737831559
Validation loss: 2.6472766248746438

Epoch: 5| Step: 1
Training loss: 2.7241118602387653
Validation loss: 2.659626064410466

Epoch: 5| Step: 2
Training loss: 2.4475658625312255
Validation loss: 2.643678336979621

Epoch: 5| Step: 3
Training loss: 2.5560425130863598
Validation loss: 2.626474900896294

Epoch: 5| Step: 4
Training loss: 2.6340331012960227
Validation loss: 2.6227376551565604

Epoch: 5| Step: 5
Training loss: 3.0195945742975896
Validation loss: 2.6119657435631667

Epoch: 5| Step: 6
Training loss: 2.8509694776128827
Validation loss: 2.6087502399768

Epoch: 5| Step: 7
Training loss: 3.086638474826585
Validation loss: 2.609532010804458

Epoch: 5| Step: 8
Training loss: 3.2068082148768973
Validation loss: 2.6109587951010886

Epoch: 5| Step: 9
Training loss: 2.4712008129544585
Validation loss: 2.6123011508810756

Epoch: 5| Step: 10
Training loss: 2.556988814083691
Validation loss: 2.6148543856932283

Epoch: 5| Step: 11
Training loss: 2.3077376532378793
Validation loss: 2.617214510194695

Epoch: 67| Step: 0
Training loss: 2.635759645441674
Validation loss: 2.6224621660517515

Epoch: 5| Step: 1
Training loss: 2.5057571877912435
Validation loss: 2.6250043899257225

Epoch: 5| Step: 2
Training loss: 3.0292971898170373
Validation loss: 2.62321045214724

Epoch: 5| Step: 3
Training loss: 2.729468253752402
Validation loss: 2.6278614766333743

Epoch: 5| Step: 4
Training loss: 2.737777162917524
Validation loss: 2.6238070835218057

Epoch: 5| Step: 5
Training loss: 2.542204523762242
Validation loss: 2.6238853229896755

Epoch: 5| Step: 6
Training loss: 2.624515125361161
Validation loss: 2.6187350086823984

Epoch: 5| Step: 7
Training loss: 3.128225569199253
Validation loss: 2.616220422727319

Epoch: 5| Step: 8
Training loss: 2.9477506305498817
Validation loss: 2.6116516247673

Epoch: 5| Step: 9
Training loss: 2.8804526659415846
Validation loss: 2.608895217736016

Epoch: 5| Step: 10
Training loss: 2.5754145390427143
Validation loss: 2.601585040601009

Epoch: 5| Step: 11
Training loss: 1.9700397323822982
Validation loss: 2.5990623970577524

Epoch: 68| Step: 0
Training loss: 2.7397960004950392
Validation loss: 2.5950726005686113

Epoch: 5| Step: 1
Training loss: 2.879953181098155
Validation loss: 2.5935984839187767

Epoch: 5| Step: 2
Training loss: 2.7397918235050303
Validation loss: 2.5914526919034087

Epoch: 5| Step: 3
Training loss: 2.455075308738192
Validation loss: 2.587323980133986

Epoch: 5| Step: 4
Training loss: 2.844716337573883
Validation loss: 2.590687859220875

Epoch: 5| Step: 5
Training loss: 2.755900728062789
Validation loss: 2.5869392536838127

Epoch: 5| Step: 6
Training loss: 2.2809057106555017
Validation loss: 2.5857718607703073

Epoch: 5| Step: 7
Training loss: 2.6704114508333623
Validation loss: 2.582786068835888

Epoch: 5| Step: 8
Training loss: 2.9168751415042586
Validation loss: 2.5831756633408505

Epoch: 5| Step: 9
Training loss: 2.658004091815081
Validation loss: 2.581251833763426

Epoch: 5| Step: 10
Training loss: 3.0823799583902276
Validation loss: 2.582601394841596

Epoch: 5| Step: 11
Training loss: 2.1948520815632717
Validation loss: 2.577655144464407

Epoch: 69| Step: 0
Training loss: 2.722630504776502
Validation loss: 2.582302319739494

Epoch: 5| Step: 1
Training loss: 2.5126505261020284
Validation loss: 2.5811458306464137

Epoch: 5| Step: 2
Training loss: 2.80641499397509
Validation loss: 2.5778438414805924

Epoch: 5| Step: 3
Training loss: 2.936150261040418
Validation loss: 2.5767170230695533

Epoch: 5| Step: 4
Training loss: 2.863487413173886
Validation loss: 2.575485454248188

Epoch: 5| Step: 5
Training loss: 2.812642666059316
Validation loss: 2.5740363327017124

Epoch: 5| Step: 6
Training loss: 2.9531918472716927
Validation loss: 2.573161068529869

Epoch: 5| Step: 7
Training loss: 2.085010565495422
Validation loss: 2.572305229575351

Epoch: 5| Step: 8
Training loss: 2.811768161077721
Validation loss: 2.569908044563988

Epoch: 5| Step: 9
Training loss: 2.6232972753422583
Validation loss: 2.5700425235221194

Epoch: 5| Step: 10
Training loss: 2.624428550644453
Validation loss: 2.567975138072258

Epoch: 5| Step: 11
Training loss: 2.436044698709136
Validation loss: 2.572186290431867

Epoch: 70| Step: 0
Training loss: 2.5100937209546728
Validation loss: 2.570753243330756

Epoch: 5| Step: 1
Training loss: 2.8825843948224525
Validation loss: 2.572223455401547

Epoch: 5| Step: 2
Training loss: 3.0827784339658284
Validation loss: 2.575574912238577

Epoch: 5| Step: 3
Training loss: 2.9120975854892137
Validation loss: 2.5718254807665706

Epoch: 5| Step: 4
Training loss: 2.3302865458768744
Validation loss: 2.5660879168985833

Epoch: 5| Step: 5
Training loss: 2.348147729596621
Validation loss: 2.5659753485112695

Epoch: 5| Step: 6
Training loss: 3.210585080597214
Validation loss: 2.564488662740779

Epoch: 5| Step: 7
Training loss: 2.7241912411569045
Validation loss: 2.560562106585986

Epoch: 5| Step: 8
Training loss: 2.726856554674134
Validation loss: 2.563316858554508

Epoch: 5| Step: 9
Training loss: 2.3132158150995257
Validation loss: 2.558544339001364

Epoch: 5| Step: 10
Training loss: 2.62008033410883
Validation loss: 2.55919009725771

Epoch: 5| Step: 11
Training loss: 1.8606161895533107
Validation loss: 2.561060400281726

Epoch: 71| Step: 0
Training loss: 2.5396894883919825
Validation loss: 2.559507091468674

Epoch: 5| Step: 1
Training loss: 2.615280321898472
Validation loss: 2.562094163934316

Epoch: 5| Step: 2
Training loss: 2.7806226901565463
Validation loss: 2.5617234169794485

Epoch: 5| Step: 3
Training loss: 2.6145110607923647
Validation loss: 2.5632428976466746

Epoch: 5| Step: 4
Training loss: 2.4435103237932374
Validation loss: 2.5644871481163545

Epoch: 5| Step: 5
Training loss: 2.6035842142420966
Validation loss: 2.564218181569521

Epoch: 5| Step: 6
Training loss: 2.3825347238193775
Validation loss: 2.562056685302028

Epoch: 5| Step: 7
Training loss: 2.8924093152125816
Validation loss: 2.5630199866218204

Epoch: 5| Step: 8
Training loss: 3.0871914790522017
Validation loss: 2.5632847227944837

Epoch: 5| Step: 9
Training loss: 2.9182908213634566
Validation loss: 2.5607388461050467

Epoch: 5| Step: 10
Training loss: 2.6440917062538363
Validation loss: 2.5572646282706373

Epoch: 5| Step: 11
Training loss: 3.074915107857813
Validation loss: 2.554127545287915

Epoch: 72| Step: 0
Training loss: 2.6048695849028234
Validation loss: 2.5520923471616004

Epoch: 5| Step: 1
Training loss: 2.9632288941500917
Validation loss: 2.5525721036532754

Epoch: 5| Step: 2
Training loss: 2.481030209893621
Validation loss: 2.548386392523354

Epoch: 5| Step: 3
Training loss: 2.7391349125727453
Validation loss: 2.5473706166894994

Epoch: 5| Step: 4
Training loss: 2.505311283103188
Validation loss: 2.5483292482400324

Epoch: 5| Step: 5
Training loss: 2.793932427033595
Validation loss: 2.546812895347234

Epoch: 5| Step: 6
Training loss: 3.180106920328189
Validation loss: 2.5438825857052407

Epoch: 5| Step: 7
Training loss: 3.130603801269407
Validation loss: 2.5487867875723778

Epoch: 5| Step: 8
Training loss: 2.4043658918302917
Validation loss: 2.5464806865788896

Epoch: 5| Step: 9
Training loss: 2.0268752892723665
Validation loss: 2.541321630717732

Epoch: 5| Step: 10
Training loss: 2.5872556893561396
Validation loss: 2.5416486392919206

Epoch: 5| Step: 11
Training loss: 2.057021639200571
Validation loss: 2.5415233092188823

Epoch: 73| Step: 0
Training loss: 2.888379023462591
Validation loss: 2.5397321003960487

Epoch: 5| Step: 1
Training loss: 3.0306863162366895
Validation loss: 2.539169829618785

Epoch: 5| Step: 2
Training loss: 2.540738629454656
Validation loss: 2.539722501609713

Epoch: 5| Step: 3
Training loss: 2.5719654832128636
Validation loss: 2.5404949236263956

Epoch: 5| Step: 4
Training loss: 3.0017443989529666
Validation loss: 2.5404499038975468

Epoch: 5| Step: 5
Training loss: 2.49170462495433
Validation loss: 2.542188146646203

Epoch: 5| Step: 6
Training loss: 2.413474693461231
Validation loss: 2.5421660328783

Epoch: 5| Step: 7
Training loss: 2.5144315933507477
Validation loss: 2.54042963635191

Epoch: 5| Step: 8
Training loss: 3.034580249700132
Validation loss: 2.541355998694291

Epoch: 5| Step: 9
Training loss: 2.312051368703701
Validation loss: 2.539490355609081

Epoch: 5| Step: 10
Training loss: 2.332080527444714
Validation loss: 2.5397618861300324

Epoch: 5| Step: 11
Training loss: 3.261155862264697
Validation loss: 2.5388028682110546

Epoch: 74| Step: 0
Training loss: 2.533199925005207
Validation loss: 2.5365301679482406

Epoch: 5| Step: 1
Training loss: 2.258281302703158
Validation loss: 2.5337301552598706

Epoch: 5| Step: 2
Training loss: 2.6486980118809487
Validation loss: 2.5293759170416195

Epoch: 5| Step: 3
Training loss: 2.791880831877811
Validation loss: 2.5286223780090586

Epoch: 5| Step: 4
Training loss: 2.718342103723738
Validation loss: 2.5287625763511725

Epoch: 5| Step: 5
Training loss: 2.63579754596367
Validation loss: 2.5278992904607462

Epoch: 5| Step: 6
Training loss: 2.574116220009779
Validation loss: 2.528086887633464

Epoch: 5| Step: 7
Training loss: 2.985576288002766
Validation loss: 2.525601721661605

Epoch: 5| Step: 8
Training loss: 2.5503938856905943
Validation loss: 2.529373631239372

Epoch: 5| Step: 9
Training loss: 2.6333673724457283
Validation loss: 2.5299635294564857

Epoch: 5| Step: 10
Training loss: 2.8553685537311497
Validation loss: 2.521537009984295

Epoch: 5| Step: 11
Training loss: 3.0948550630074663
Validation loss: 2.5248198880898527

Epoch: 75| Step: 0
Training loss: 2.198063331760691
Validation loss: 2.5236588647707787

Epoch: 5| Step: 1
Training loss: 2.6514307622154702
Validation loss: 2.527236802571611

Epoch: 5| Step: 2
Training loss: 3.0008235436805704
Validation loss: 2.525794024306848

Epoch: 5| Step: 3
Training loss: 2.7278845787074197
Validation loss: 2.525995723398323

Epoch: 5| Step: 4
Training loss: 2.744423240145555
Validation loss: 2.5253832178481717

Epoch: 5| Step: 5
Training loss: 2.575529884705615
Validation loss: 2.5249195608539208

Epoch: 5| Step: 6
Training loss: 2.6231183165182643
Validation loss: 2.525299790497567

Epoch: 5| Step: 7
Training loss: 2.3151474309654048
Validation loss: 2.522551626125157

Epoch: 5| Step: 8
Training loss: 2.648938517034476
Validation loss: 2.523156869910821

Epoch: 5| Step: 9
Training loss: 2.9679911396480443
Validation loss: 2.52035171594951

Epoch: 5| Step: 10
Training loss: 2.6997990957325166
Validation loss: 2.5199619920579006

Epoch: 5| Step: 11
Training loss: 2.0535504926479144
Validation loss: 2.518536026624081

Testing loss: 2.082597334319211
