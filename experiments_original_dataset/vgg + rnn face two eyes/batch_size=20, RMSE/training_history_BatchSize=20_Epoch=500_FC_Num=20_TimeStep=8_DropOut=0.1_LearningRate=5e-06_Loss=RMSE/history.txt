Epoch: 1| Step: 0
Training loss: 6.278305957971807
Validation loss: 5.949271101876758

Epoch: 5| Step: 1
Training loss: 5.708901852700704
Validation loss: 5.947235083958339

Epoch: 5| Step: 2
Training loss: 5.822207640289087
Validation loss: 5.945301398435262

Epoch: 5| Step: 3
Training loss: 5.21670345906861
Validation loss: 5.943359127623417

Epoch: 5| Step: 4
Training loss: 6.5376284176410975
Validation loss: 5.941490498785024

Epoch: 5| Step: 5
Training loss: 6.0480886419349975
Validation loss: 5.939642074742281

Epoch: 5| Step: 6
Training loss: 5.8962712029825335
Validation loss: 5.937838200089139

Epoch: 5| Step: 7
Training loss: 6.363342097525991
Validation loss: 5.935948313018491

Epoch: 5| Step: 8
Training loss: 6.109847652952172
Validation loss: 5.934085138335228

Epoch: 5| Step: 9
Training loss: 6.135393005567261
Validation loss: 5.932139041088261

Epoch: 5| Step: 10
Training loss: 6.2669837600889595
Validation loss: 5.930250225748938

Epoch: 5| Step: 11
Training loss: 6.655325525406034
Validation loss: 5.928129357507445

Epoch: 2| Step: 0
Training loss: 5.700423429054005
Validation loss: 5.925900053452376

Epoch: 5| Step: 1
Training loss: 5.608209260396623
Validation loss: 5.923765378997667

Epoch: 5| Step: 2
Training loss: 6.016754599199008
Validation loss: 5.921639510734056

Epoch: 5| Step: 3
Training loss: 7.054223806829898
Validation loss: 5.919243361183746

Epoch: 5| Step: 4
Training loss: 5.132075194381046
Validation loss: 5.916781487044776

Epoch: 5| Step: 5
Training loss: 5.752128207225002
Validation loss: 5.914193908225894

Epoch: 5| Step: 6
Training loss: 6.551950749530064
Validation loss: 5.911626094728722

Epoch: 5| Step: 7
Training loss: 6.080360766298316
Validation loss: 5.908928521132472

Epoch: 5| Step: 8
Training loss: 6.199119985330926
Validation loss: 5.905964139718176

Epoch: 5| Step: 9
Training loss: 6.002215612141792
Validation loss: 5.903053697108648

Epoch: 5| Step: 10
Training loss: 5.920134517584785
Validation loss: 5.8998217442626775

Epoch: 5| Step: 11
Training loss: 6.506432504870061
Validation loss: 5.896558463140909

Epoch: 3| Step: 0
Training loss: 5.598800169610753
Validation loss: 5.8932974341249915

Epoch: 5| Step: 1
Training loss: 5.60854900941115
Validation loss: 5.889585846867906

Epoch: 5| Step: 2
Training loss: 5.862349180058754
Validation loss: 5.885895905914392

Epoch: 5| Step: 3
Training loss: 6.347813099023688
Validation loss: 5.881985319561772

Epoch: 5| Step: 4
Training loss: 6.20351794941632
Validation loss: 5.877728153442733

Epoch: 5| Step: 5
Training loss: 5.779047365981001
Validation loss: 5.87370137140072

Epoch: 5| Step: 6
Training loss: 6.352795395601759
Validation loss: 5.868840444867939

Epoch: 5| Step: 7
Training loss: 5.860296477020936
Validation loss: 5.8643238920437435

Epoch: 5| Step: 8
Training loss: 6.303590435646267
Validation loss: 5.859542403478851

Epoch: 5| Step: 9
Training loss: 6.1119544786285935
Validation loss: 5.854444302619451

Epoch: 5| Step: 10
Training loss: 5.684652097553099
Validation loss: 5.848977407920852

Epoch: 5| Step: 11
Training loss: 6.353341204280454
Validation loss: 5.843619306058238

Epoch: 4| Step: 0
Training loss: 5.050888497024558
Validation loss: 5.838008419553098

Epoch: 5| Step: 1
Training loss: 5.736693867085658
Validation loss: 5.831952131330445

Epoch: 5| Step: 2
Training loss: 5.360018054874814
Validation loss: 5.825843807766341

Epoch: 5| Step: 3
Training loss: 5.954500615138401
Validation loss: 5.8195081184846895

Epoch: 5| Step: 4
Training loss: 6.23595681833875
Validation loss: 5.813082942648501

Epoch: 5| Step: 5
Training loss: 5.963071348698418
Validation loss: 5.806628361840958

Epoch: 5| Step: 6
Training loss: 6.272160420293045
Validation loss: 5.799472579872377

Epoch: 5| Step: 7
Training loss: 6.604700333686815
Validation loss: 5.792182661530777

Epoch: 5| Step: 8
Training loss: 6.1239567082206054
Validation loss: 5.785071201287435

Epoch: 5| Step: 9
Training loss: 5.729495433275244
Validation loss: 5.777953436618436

Epoch: 5| Step: 10
Training loss: 6.009563136416504
Validation loss: 5.77062205904518

Epoch: 5| Step: 11
Training loss: 5.467284960013002
Validation loss: 5.762894491289493

Epoch: 5| Step: 0
Training loss: 6.5195224732190775
Validation loss: 5.755306138348247

Epoch: 5| Step: 1
Training loss: 6.241717840102914
Validation loss: 5.747795193660523

Epoch: 5| Step: 2
Training loss: 5.297761645982348
Validation loss: 5.739860731045847

Epoch: 5| Step: 3
Training loss: 6.510186942561604
Validation loss: 5.73219801266908

Epoch: 5| Step: 4
Training loss: 6.147023989758301
Validation loss: 5.724541321749839

Epoch: 5| Step: 5
Training loss: 5.175771484365787
Validation loss: 5.716851007735038

Epoch: 5| Step: 6
Training loss: 5.308918183035968
Validation loss: 5.709216894094859

Epoch: 5| Step: 7
Training loss: 5.36119026604406
Validation loss: 5.701582936175119

Epoch: 5| Step: 8
Training loss: 6.29375067884182
Validation loss: 5.694263733216498

Epoch: 5| Step: 9
Training loss: 5.754834671893718
Validation loss: 5.68682527557199

Epoch: 5| Step: 10
Training loss: 5.6792633443968565
Validation loss: 5.679393006831429

Epoch: 5| Step: 11
Training loss: 3.7907716023021374
Validation loss: 5.672170233771065

Epoch: 6| Step: 0
Training loss: 5.612472146693658
Validation loss: 5.665277902274216

Epoch: 5| Step: 1
Training loss: 6.145854712842404
Validation loss: 5.658587652379834

Epoch: 5| Step: 2
Training loss: 6.125051070019871
Validation loss: 5.65164900180835

Epoch: 5| Step: 3
Training loss: 5.0845621010105875
Validation loss: 5.6447737029032

Epoch: 5| Step: 4
Training loss: 6.141646516198375
Validation loss: 5.637887566968547

Epoch: 5| Step: 5
Training loss: 5.660725714322587
Validation loss: 5.6311926415077

Epoch: 5| Step: 6
Training loss: 5.923069815769562
Validation loss: 5.624640891303448

Epoch: 5| Step: 7
Training loss: 5.7028447330535315
Validation loss: 5.617697602845402

Epoch: 5| Step: 8
Training loss: 4.782571248522324
Validation loss: 5.610787103234833

Epoch: 5| Step: 9
Training loss: 5.837126379697342
Validation loss: 5.6042420643363435

Epoch: 5| Step: 10
Training loss: 5.972643156767042
Validation loss: 5.5976622626482415

Epoch: 5| Step: 11
Training loss: 6.17108133741947
Validation loss: 5.5911854738258455

Epoch: 7| Step: 0
Training loss: 5.529414847734759
Validation loss: 5.584384131357405

Epoch: 5| Step: 1
Training loss: 6.064344617084819
Validation loss: 5.577748439983116

Epoch: 5| Step: 2
Training loss: 5.568288641419825
Validation loss: 5.571396546102944

Epoch: 5| Step: 3
Training loss: 6.118758154640569
Validation loss: 5.565136366878802

Epoch: 5| Step: 4
Training loss: 4.951582129822639
Validation loss: 5.559021287043691

Epoch: 5| Step: 5
Training loss: 5.83764133323119
Validation loss: 5.552726402997084

Epoch: 5| Step: 6
Training loss: 5.21234230882435
Validation loss: 5.546863509331922

Epoch: 5| Step: 7
Training loss: 5.189097330906325
Validation loss: 5.5408820861279535

Epoch: 5| Step: 8
Training loss: 5.855122806033232
Validation loss: 5.534989072024462

Epoch: 5| Step: 9
Training loss: 5.969042066847978
Validation loss: 5.529311291150221

Epoch: 5| Step: 10
Training loss: 5.946125391002728
Validation loss: 5.52333560114008

Epoch: 5| Step: 11
Training loss: 5.7650940193125795
Validation loss: 5.517468534298357

Epoch: 8| Step: 0
Training loss: 5.213026002831865
Validation loss: 5.511565799514963

Epoch: 5| Step: 1
Training loss: 5.640863556189416
Validation loss: 5.505737620894429

Epoch: 5| Step: 2
Training loss: 5.3002956451873136
Validation loss: 5.499895535546251

Epoch: 5| Step: 3
Training loss: 6.471111364178309
Validation loss: 5.49468229887054

Epoch: 5| Step: 4
Training loss: 5.6543926751383475
Validation loss: 5.489053221652294

Epoch: 5| Step: 5
Training loss: 5.953283913561384
Validation loss: 5.483281627032477

Epoch: 5| Step: 6
Training loss: 5.116417001272297
Validation loss: 5.477572454544675

Epoch: 5| Step: 7
Training loss: 6.287876865627612
Validation loss: 5.472030091933557

Epoch: 5| Step: 8
Training loss: 5.268560751415649
Validation loss: 5.466243772703075

Epoch: 5| Step: 9
Training loss: 6.206691687042143
Validation loss: 5.460668307078767

Epoch: 5| Step: 10
Training loss: 4.546815852144284
Validation loss: 5.455089663320235

Epoch: 5| Step: 11
Training loss: 3.680467267846894
Validation loss: 5.449837510722685

Epoch: 9| Step: 0
Training loss: 5.340047524058574
Validation loss: 5.443810451447839

Epoch: 5| Step: 1
Training loss: 5.387255513956642
Validation loss: 5.438406346226815

Epoch: 5| Step: 2
Training loss: 5.7549410612666
Validation loss: 5.433087966893956

Epoch: 5| Step: 3
Training loss: 4.7826737422063035
Validation loss: 5.427529017134965

Epoch: 5| Step: 4
Training loss: 5.337038342703224
Validation loss: 5.421977486498358

Epoch: 5| Step: 5
Training loss: 5.6366256949396165
Validation loss: 5.4165907512137785

Epoch: 5| Step: 6
Training loss: 5.311590498318387
Validation loss: 5.410539002541659

Epoch: 5| Step: 7
Training loss: 5.928060315894797
Validation loss: 5.4046840421046705

Epoch: 5| Step: 8
Training loss: 6.2188567339301555
Validation loss: 5.398623612798338

Epoch: 5| Step: 9
Training loss: 6.21116597457127
Validation loss: 5.392585036860422

Epoch: 5| Step: 10
Training loss: 4.865910982659065
Validation loss: 5.386115077446106

Epoch: 5| Step: 11
Training loss: 5.121017955972768
Validation loss: 5.380276921128366

Epoch: 10| Step: 0
Training loss: 5.210166222086161
Validation loss: 5.37365638588072

Epoch: 5| Step: 1
Training loss: 5.551879688223599
Validation loss: 5.368123705344859

Epoch: 5| Step: 2
Training loss: 6.179388412780496
Validation loss: 5.362180933615302

Epoch: 5| Step: 3
Training loss: 5.566258221715941
Validation loss: 5.355975601248025

Epoch: 5| Step: 4
Training loss: 5.676536305054996
Validation loss: 5.350305681616621

Epoch: 5| Step: 5
Training loss: 4.759496331374691
Validation loss: 5.343778286686144

Epoch: 5| Step: 6
Training loss: 6.01678661674205
Validation loss: 5.337948168507107

Epoch: 5| Step: 7
Training loss: 5.442378168875868
Validation loss: 5.331351719221651

Epoch: 5| Step: 8
Training loss: 5.127748264233779
Validation loss: 5.3255336049369

Epoch: 5| Step: 9
Training loss: 5.3655493400451535
Validation loss: 5.319186075983858

Epoch: 5| Step: 10
Training loss: 4.795515333691868
Validation loss: 5.3132700118970755

Epoch: 5| Step: 11
Training loss: 6.564366828966399
Validation loss: 5.307169098291969

Epoch: 11| Step: 0
Training loss: 5.681204528962352
Validation loss: 5.301447459864444

Epoch: 5| Step: 1
Training loss: 4.669154979703213
Validation loss: 5.295161342330048

Epoch: 5| Step: 2
Training loss: 5.555850222508369
Validation loss: 5.289408095397987

Epoch: 5| Step: 3
Training loss: 4.2974491360036
Validation loss: 5.28303020050921

Epoch: 5| Step: 4
Training loss: 5.895149254175326
Validation loss: 5.276491583431475

Epoch: 5| Step: 5
Training loss: 5.340510049813883
Validation loss: 5.269725052286288

Epoch: 5| Step: 6
Training loss: 5.765031489396261
Validation loss: 5.26342302535068

Epoch: 5| Step: 7
Training loss: 5.386551265865287
Validation loss: 5.258044989227385

Epoch: 5| Step: 8
Training loss: 5.554985027687915
Validation loss: 5.2521302654505275

Epoch: 5| Step: 9
Training loss: 5.447082319488855
Validation loss: 5.247551952781556

Epoch: 5| Step: 10
Training loss: 5.281482217412248
Validation loss: 5.242215174958676

Epoch: 5| Step: 11
Training loss: 6.461810383996168
Validation loss: 5.236454276462813

Epoch: 12| Step: 0
Training loss: 5.797841282019898
Validation loss: 5.229936431622439

Epoch: 5| Step: 1
Training loss: 5.59808778130988
Validation loss: 5.224532067032938

Epoch: 5| Step: 2
Training loss: 4.5270553641838465
Validation loss: 5.2185935417676355

Epoch: 5| Step: 3
Training loss: 6.40929716259187
Validation loss: 5.213057925875906

Epoch: 5| Step: 4
Training loss: 4.2077729006213165
Validation loss: 5.206746037525834

Epoch: 5| Step: 5
Training loss: 5.458370975432536
Validation loss: 5.20128745011392

Epoch: 5| Step: 6
Training loss: 4.4691789327853
Validation loss: 5.1962426062910545

Epoch: 5| Step: 7
Training loss: 4.71149356527212
Validation loss: 5.190621352342782

Epoch: 5| Step: 8
Training loss: 5.744680846855338
Validation loss: 5.18480124228422

Epoch: 5| Step: 9
Training loss: 5.889427164456612
Validation loss: 5.178944844687004

Epoch: 5| Step: 10
Training loss: 5.120103869874679
Validation loss: 5.174178210873452

Epoch: 5| Step: 11
Training loss: 6.150928036520117
Validation loss: 5.169016306365753

Epoch: 13| Step: 0
Training loss: 5.397111169433119
Validation loss: 5.1641211263509605

Epoch: 5| Step: 1
Training loss: 5.286423175362872
Validation loss: 5.158332234733272

Epoch: 5| Step: 2
Training loss: 5.1177730312666805
Validation loss: 5.154799902874596

Epoch: 5| Step: 3
Training loss: 4.691921132822458
Validation loss: 5.1491923649526266

Epoch: 5| Step: 4
Training loss: 5.504441288756488
Validation loss: 5.143873639511538

Epoch: 5| Step: 5
Training loss: 5.296619510396706
Validation loss: 5.139110129408131

Epoch: 5| Step: 6
Training loss: 5.719731147690027
Validation loss: 5.134176288891476

Epoch: 5| Step: 7
Training loss: 5.206731239598988
Validation loss: 5.129194132929916

Epoch: 5| Step: 8
Training loss: 5.247522768768158
Validation loss: 5.124366868461593

Epoch: 5| Step: 9
Training loss: 5.016169913570177
Validation loss: 5.12019997175182

Epoch: 5| Step: 10
Training loss: 5.245008366289912
Validation loss: 5.115014427751396

Epoch: 5| Step: 11
Training loss: 5.716814224222052
Validation loss: 5.110648981166931

Epoch: 14| Step: 0
Training loss: 4.547222320819705
Validation loss: 5.10592766051369

Epoch: 5| Step: 1
Training loss: 5.695417991885663
Validation loss: 5.1000203113525435

Epoch: 5| Step: 2
Training loss: 5.369207587853161
Validation loss: 5.096232513342842

Epoch: 5| Step: 3
Training loss: 5.088021643886475
Validation loss: 5.091093833508187

Epoch: 5| Step: 4
Training loss: 5.4445821307844575
Validation loss: 5.086128328945745

Epoch: 5| Step: 5
Training loss: 5.6977168948378525
Validation loss: 5.0822693175006695

Epoch: 5| Step: 6
Training loss: 5.5314248267524775
Validation loss: 5.077422068924584

Epoch: 5| Step: 7
Training loss: 3.7681996261538995
Validation loss: 5.072368116962737

Epoch: 5| Step: 8
Training loss: 4.8109657517211035
Validation loss: 5.0679769363129425

Epoch: 5| Step: 9
Training loss: 5.825813387290667
Validation loss: 5.063487604142072

Epoch: 5| Step: 10
Training loss: 5.435676181144776
Validation loss: 5.059417791030502

Epoch: 5| Step: 11
Training loss: 3.3272328501821233
Validation loss: 5.054867434161052

Epoch: 15| Step: 0
Training loss: 5.132239833802579
Validation loss: 5.050279049984948

Epoch: 5| Step: 1
Training loss: 5.062936081177103
Validation loss: 5.046190370905537

Epoch: 5| Step: 2
Training loss: 4.267709523148759
Validation loss: 5.041737708334713

Epoch: 5| Step: 3
Training loss: 5.574663899644008
Validation loss: 5.0376134794972165

Epoch: 5| Step: 4
Training loss: 5.360759589618391
Validation loss: 5.033892077997059

Epoch: 5| Step: 5
Training loss: 5.145073447189801
Validation loss: 5.028205534908633

Epoch: 5| Step: 6
Training loss: 5.174376283367398
Validation loss: 5.024166372685886

Epoch: 5| Step: 7
Training loss: 3.87260633801619
Validation loss: 5.019736089621064

Epoch: 5| Step: 8
Training loss: 5.219813803790346
Validation loss: 5.016301506583509

Epoch: 5| Step: 9
Training loss: 6.057586881397872
Validation loss: 5.011335041583438

Epoch: 5| Step: 10
Training loss: 5.571500889514892
Validation loss: 5.00764957823537

Epoch: 5| Step: 11
Training loss: 4.587627664811344
Validation loss: 5.002540745516011

Epoch: 16| Step: 0
Training loss: 4.761178365435414
Validation loss: 4.998376471466983

Epoch: 5| Step: 1
Training loss: 4.54835763990245
Validation loss: 4.994581354014132

Epoch: 5| Step: 2
Training loss: 4.687288813602074
Validation loss: 4.989695277647287

Epoch: 5| Step: 3
Training loss: 5.748408221631405
Validation loss: 4.985413956259492

Epoch: 5| Step: 4
Training loss: 5.341230545847696
Validation loss: 4.981285453105436

Epoch: 5| Step: 5
Training loss: 5.1802829037741525
Validation loss: 4.977154515383998

Epoch: 5| Step: 6
Training loss: 5.578397514461093
Validation loss: 4.973020617652168

Epoch: 5| Step: 7
Training loss: 5.420187915767896
Validation loss: 4.9692147795306445

Epoch: 5| Step: 8
Training loss: 5.688339674452742
Validation loss: 4.964078454542432

Epoch: 5| Step: 9
Training loss: 4.8550786592847075
Validation loss: 4.959867571298545

Epoch: 5| Step: 10
Training loss: 4.1422788376093
Validation loss: 4.955032454678529

Epoch: 5| Step: 11
Training loss: 4.617902929449721
Validation loss: 4.950579272839481

Epoch: 17| Step: 0
Training loss: 5.386217344321842
Validation loss: 4.945607108791602

Epoch: 5| Step: 1
Training loss: 5.392160036762684
Validation loss: 4.941603765950428

Epoch: 5| Step: 2
Training loss: 4.445538828473312
Validation loss: 4.936962275458228

Epoch: 5| Step: 3
Training loss: 4.675580752606622
Validation loss: 4.933663024174366

Epoch: 5| Step: 4
Training loss: 5.2229376341200195
Validation loss: 4.929998840398955

Epoch: 5| Step: 5
Training loss: 5.613344111186816
Validation loss: 4.923972047394351

Epoch: 5| Step: 6
Training loss: 4.875857937953434
Validation loss: 4.919762811112399

Epoch: 5| Step: 7
Training loss: 4.59006710726481
Validation loss: 4.916308695752088

Epoch: 5| Step: 8
Training loss: 4.299319262181405
Validation loss: 4.912895229770464

Epoch: 5| Step: 9
Training loss: 5.668563001885721
Validation loss: 4.909094291770403

Epoch: 5| Step: 10
Training loss: 4.909971732934202
Validation loss: 4.902751825580345

Epoch: 5| Step: 11
Training loss: 6.1815693494113635
Validation loss: 4.896630083007605

Epoch: 18| Step: 0
Training loss: 3.8479737436425805
Validation loss: 4.891837184128363

Epoch: 5| Step: 1
Training loss: 5.480209464086539
Validation loss: 4.887868484239214

Epoch: 5| Step: 2
Training loss: 4.922072439926279
Validation loss: 4.8840433100441905

Epoch: 5| Step: 3
Training loss: 5.873855804055453
Validation loss: 4.879043792993016

Epoch: 5| Step: 4
Training loss: 4.824008804262645
Validation loss: 4.873678778256558

Epoch: 5| Step: 5
Training loss: 4.87344198517197
Validation loss: 4.869307422191046

Epoch: 5| Step: 6
Training loss: 4.787234880163242
Validation loss: 4.865295119833499

Epoch: 5| Step: 7
Training loss: 5.511768235404183
Validation loss: 4.861504328430921

Epoch: 5| Step: 8
Training loss: 4.652628674498286
Validation loss: 4.857040212352056

Epoch: 5| Step: 9
Training loss: 4.542740347869781
Validation loss: 4.851486950796464

Epoch: 5| Step: 10
Training loss: 5.243202168124941
Validation loss: 4.846756881661758

Epoch: 5| Step: 11
Training loss: 5.394512864288003
Validation loss: 4.842248577279668

Epoch: 19| Step: 0
Training loss: 5.006379063689216
Validation loss: 4.838280508208766

Epoch: 5| Step: 1
Training loss: 5.233144131457718
Validation loss: 4.83315328010531

Epoch: 5| Step: 2
Training loss: 4.764171741467991
Validation loss: 4.827834234772099

Epoch: 5| Step: 3
Training loss: 5.127236413304446
Validation loss: 4.823635676639615

Epoch: 5| Step: 4
Training loss: 4.869710938571625
Validation loss: 4.819258547351226

Epoch: 5| Step: 5
Training loss: 4.448703859995128
Validation loss: 4.814612061389943

Epoch: 5| Step: 6
Training loss: 4.116695483231685
Validation loss: 4.809751716716965

Epoch: 5| Step: 7
Training loss: 4.908043017434375
Validation loss: 4.805713178123579

Epoch: 5| Step: 8
Training loss: 5.739186277230933
Validation loss: 4.801340755990995

Epoch: 5| Step: 9
Training loss: 4.972057465298689
Validation loss: 4.7976542284150145

Epoch: 5| Step: 10
Training loss: 4.750867663994759
Validation loss: 4.792012826882753

Epoch: 5| Step: 11
Training loss: 6.037680878703876
Validation loss: 4.78813832893835

Epoch: 20| Step: 0
Training loss: 5.2681762672542884
Validation loss: 4.78317443913822

Epoch: 5| Step: 1
Training loss: 4.611335570197293
Validation loss: 4.779035608123714

Epoch: 5| Step: 2
Training loss: 4.866258266156807
Validation loss: 4.774299681072281

Epoch: 5| Step: 3
Training loss: 4.586786714653588
Validation loss: 4.769339142850672

Epoch: 5| Step: 4
Training loss: 4.892619838270284
Validation loss: 4.76500854674217

Epoch: 5| Step: 5
Training loss: 4.986183914507855
Validation loss: 4.760770157169441

Epoch: 5| Step: 6
Training loss: 5.151874697304712
Validation loss: 4.756130085994553

Epoch: 5| Step: 7
Training loss: 4.7092079543045
Validation loss: 4.751439278035668

Epoch: 5| Step: 8
Training loss: 4.923222045639314
Validation loss: 4.746741691493817

Epoch: 5| Step: 9
Training loss: 5.068722703439235
Validation loss: 4.742882180694986

Epoch: 5| Step: 10
Training loss: 5.059134223962568
Validation loss: 4.73820166378163

Epoch: 5| Step: 11
Training loss: 2.02077777694419
Validation loss: 4.733133243419454

Epoch: 21| Step: 0
Training loss: 5.750368852809302
Validation loss: 4.729399463900663

Epoch: 5| Step: 1
Training loss: 4.769314097866833
Validation loss: 4.724774529528772

Epoch: 5| Step: 2
Training loss: 4.67348041827188
Validation loss: 4.720345040185724

Epoch: 5| Step: 3
Training loss: 4.676221375876165
Validation loss: 4.716673564681186

Epoch: 5| Step: 4
Training loss: 4.617124295649253
Validation loss: 4.712495713775871

Epoch: 5| Step: 5
Training loss: 4.377964868006371
Validation loss: 4.708135789198595

Epoch: 5| Step: 6
Training loss: 4.958106968090871
Validation loss: 4.704136162054439

Epoch: 5| Step: 7
Training loss: 4.863669898501727
Validation loss: 4.699668594269227

Epoch: 5| Step: 8
Training loss: 4.4742566306427465
Validation loss: 4.6950010428056785

Epoch: 5| Step: 9
Training loss: 5.301730740657766
Validation loss: 4.690238974704448

Epoch: 5| Step: 10
Training loss: 4.450304282425726
Validation loss: 4.685991358110961

Epoch: 5| Step: 11
Training loss: 5.367191586777465
Validation loss: 4.681520836350239

Epoch: 22| Step: 0
Training loss: 4.443846771002068
Validation loss: 4.67767326299133

Epoch: 5| Step: 1
Training loss: 4.860129343831245
Validation loss: 4.6729362753826456

Epoch: 5| Step: 2
Training loss: 4.673930350754711
Validation loss: 4.669567214344822

Epoch: 5| Step: 3
Training loss: 4.7453542376539515
Validation loss: 4.664451208056461

Epoch: 5| Step: 4
Training loss: 5.336685776081616
Validation loss: 4.659326134606049

Epoch: 5| Step: 5
Training loss: 4.932420266343684
Validation loss: 4.654943099297296

Epoch: 5| Step: 6
Training loss: 4.249072703008177
Validation loss: 4.650163534153233

Epoch: 5| Step: 7
Training loss: 5.062678204449364
Validation loss: 4.645929098924157

Epoch: 5| Step: 8
Training loss: 5.311385452938574
Validation loss: 4.642144250983931

Epoch: 5| Step: 9
Training loss: 4.597659153965735
Validation loss: 4.636603465651648

Epoch: 5| Step: 10
Training loss: 4.24868350114714
Validation loss: 4.632028257090545

Epoch: 5| Step: 11
Training loss: 4.78939843049728
Validation loss: 4.627594606657642

Epoch: 23| Step: 0
Training loss: 5.178126311316408
Validation loss: 4.622995530748417

Epoch: 5| Step: 1
Training loss: 4.427014494716025
Validation loss: 4.6180261408634715

Epoch: 5| Step: 2
Training loss: 4.801609746897286
Validation loss: 4.6135025854200284

Epoch: 5| Step: 3
Training loss: 4.632757948864645
Validation loss: 4.6079612546658915

Epoch: 5| Step: 4
Training loss: 4.200820461244139
Validation loss: 4.603879672235443

Epoch: 5| Step: 5
Training loss: 4.404544797969404
Validation loss: 4.6011303286926575

Epoch: 5| Step: 6
Training loss: 5.0272136158613705
Validation loss: 4.595125420636326

Epoch: 5| Step: 7
Training loss: 5.176240766747795
Validation loss: 4.590720840952859

Epoch: 5| Step: 8
Training loss: 4.420327498787075
Validation loss: 4.5854475635883984

Epoch: 5| Step: 9
Training loss: 4.033215420683437
Validation loss: 4.581875207904726

Epoch: 5| Step: 10
Training loss: 5.217064499640406
Validation loss: 4.578909549604554

Epoch: 5| Step: 11
Training loss: 6.037371913269931
Validation loss: 4.573688158143858

Epoch: 24| Step: 0
Training loss: 5.155419300094808
Validation loss: 4.567762571017901

Epoch: 5| Step: 1
Training loss: 4.307614420092344
Validation loss: 4.562244747807899

Epoch: 5| Step: 2
Training loss: 4.412204479663349
Validation loss: 4.5569216623421145

Epoch: 5| Step: 3
Training loss: 3.8471353400955635
Validation loss: 4.551581674455317

Epoch: 5| Step: 4
Training loss: 5.161986702808397
Validation loss: 4.547931150843502

Epoch: 5| Step: 5
Training loss: 4.515075438958071
Validation loss: 4.541215150886493

Epoch: 5| Step: 6
Training loss: 4.985023575921205
Validation loss: 4.536790464077604

Epoch: 5| Step: 7
Training loss: 4.867803886657214
Validation loss: 4.5335759386660115

Epoch: 5| Step: 8
Training loss: 5.020494420601912
Validation loss: 4.527113550152315

Epoch: 5| Step: 9
Training loss: 4.543597216444609
Validation loss: 4.5220603625433125

Epoch: 5| Step: 10
Training loss: 4.65333209681745
Validation loss: 4.517467048270105

Epoch: 5| Step: 11
Training loss: 3.0706567935241025
Validation loss: 4.512753718843725

Epoch: 25| Step: 0
Training loss: 4.702283207278161
Validation loss: 4.507431331498646

Epoch: 5| Step: 1
Training loss: 5.356965260059594
Validation loss: 4.501748319368113

Epoch: 5| Step: 2
Training loss: 3.9634195410034265
Validation loss: 4.497378592429572

Epoch: 5| Step: 3
Training loss: 5.077328287862093
Validation loss: 4.492366594807976

Epoch: 5| Step: 4
Training loss: 4.173851202337349
Validation loss: 4.488189315629014

Epoch: 5| Step: 5
Training loss: 4.1986586654100675
Validation loss: 4.483163579163836

Epoch: 5| Step: 6
Training loss: 4.255509788016966
Validation loss: 4.478325945295953

Epoch: 5| Step: 7
Training loss: 5.308499793652073
Validation loss: 4.473504647050682

Epoch: 5| Step: 8
Training loss: 4.981376487437456
Validation loss: 4.467945088631102

Epoch: 5| Step: 9
Training loss: 4.396188706531217
Validation loss: 4.463147152262245

Epoch: 5| Step: 10
Training loss: 4.129904865342221
Validation loss: 4.458697164550617

Epoch: 5| Step: 11
Training loss: 4.174838153191891
Validation loss: 4.453550789091446

Epoch: 26| Step: 0
Training loss: 5.110985365071743
Validation loss: 4.448741214032888

Epoch: 5| Step: 1
Training loss: 4.433914885464971
Validation loss: 4.443794675192014

Epoch: 5| Step: 2
Training loss: 4.440638761881605
Validation loss: 4.438432156795652

Epoch: 5| Step: 3
Training loss: 4.259619429159653
Validation loss: 4.43360748064825

Epoch: 5| Step: 4
Training loss: 4.989263451289875
Validation loss: 4.427973878337171

Epoch: 5| Step: 5
Training loss: 4.108478172694582
Validation loss: 4.424473020636511

Epoch: 5| Step: 6
Training loss: 3.878063713530082
Validation loss: 4.418009579326778

Epoch: 5| Step: 7
Training loss: 4.326275041094957
Validation loss: 4.413305500126187

Epoch: 5| Step: 8
Training loss: 5.017622220271403
Validation loss: 4.408701496519019

Epoch: 5| Step: 9
Training loss: 4.267423481179787
Validation loss: 4.403929615708803

Epoch: 5| Step: 10
Training loss: 4.992353696250577
Validation loss: 4.3983332394065915

Epoch: 5| Step: 11
Training loss: 4.851932824785445
Validation loss: 4.3938783966014

Epoch: 27| Step: 0
Training loss: 4.573302140495609
Validation loss: 4.389118320702672

Epoch: 5| Step: 1
Training loss: 4.232333546321042
Validation loss: 4.383161851601187

Epoch: 5| Step: 2
Training loss: 4.790264731719028
Validation loss: 4.37769048705161

Epoch: 5| Step: 3
Training loss: 4.9960521371165765
Validation loss: 4.372592745132312

Epoch: 5| Step: 4
Training loss: 4.6082315352074135
Validation loss: 4.367383093824176

Epoch: 5| Step: 5
Training loss: 3.8799488091778764
Validation loss: 4.36093095929047

Epoch: 5| Step: 6
Training loss: 4.6990797318770925
Validation loss: 4.35686401006093

Epoch: 5| Step: 7
Training loss: 4.9681505525416325
Validation loss: 4.351738561496329

Epoch: 5| Step: 8
Training loss: 4.146146957317698
Validation loss: 4.346077247545783

Epoch: 5| Step: 9
Training loss: 4.053017685880552
Validation loss: 4.340597101629512

Epoch: 5| Step: 10
Training loss: 4.510025935468513
Validation loss: 4.334860627303625

Epoch: 5| Step: 11
Training loss: 3.371078473495224
Validation loss: 4.330320496888645

Epoch: 28| Step: 0
Training loss: 4.0315438096964735
Validation loss: 4.326524018364157

Epoch: 5| Step: 1
Training loss: 4.68378046600557
Validation loss: 4.322749617999009

Epoch: 5| Step: 2
Training loss: 4.392245499300221
Validation loss: 4.315361276202168

Epoch: 5| Step: 3
Training loss: 4.048059474266917
Validation loss: 4.310424199135371

Epoch: 5| Step: 4
Training loss: 5.043063682176761
Validation loss: 4.3057477121986985

Epoch: 5| Step: 5
Training loss: 4.127280327480959
Validation loss: 4.299152616795973

Epoch: 5| Step: 6
Training loss: 3.8017077674188133
Validation loss: 4.294525826746654

Epoch: 5| Step: 7
Training loss: 4.462072759099197
Validation loss: 4.289926586649302

Epoch: 5| Step: 8
Training loss: 4.129497041903747
Validation loss: 4.284843611925475

Epoch: 5| Step: 9
Training loss: 4.722796391505273
Validation loss: 4.278391322226023

Epoch: 5| Step: 10
Training loss: 5.234402329103096
Validation loss: 4.272498776804163

Epoch: 5| Step: 11
Training loss: 3.366837556360629
Validation loss: 4.2655449977354465

Epoch: 29| Step: 0
Training loss: 3.713594854472424
Validation loss: 4.2605761969932345

Epoch: 5| Step: 1
Training loss: 4.235408192388586
Validation loss: 4.254468200575813

Epoch: 5| Step: 2
Training loss: 4.601927660198198
Validation loss: 4.248508257017716

Epoch: 5| Step: 3
Training loss: 3.17556472922334
Validation loss: 4.242659568865402

Epoch: 5| Step: 4
Training loss: 4.99338437151492
Validation loss: 4.237149318599285

Epoch: 5| Step: 5
Training loss: 5.31772383620057
Validation loss: 4.23221660750568

Epoch: 5| Step: 6
Training loss: 4.895642129397415
Validation loss: 4.225641917760135

Epoch: 5| Step: 7
Training loss: 3.073573741598523
Validation loss: 4.218294265055719

Epoch: 5| Step: 8
Training loss: 4.838392679023754
Validation loss: 4.212695300426344

Epoch: 5| Step: 9
Training loss: 4.072404027549162
Validation loss: 4.208033601391614

Epoch: 5| Step: 10
Training loss: 4.347532532774787
Validation loss: 4.203602797946065

Epoch: 5| Step: 11
Training loss: 4.802557446733439
Validation loss: 4.196599411313143

Epoch: 30| Step: 0
Training loss: 4.598021927829804
Validation loss: 4.191525616683686

Epoch: 5| Step: 1
Training loss: 4.5304949953569205
Validation loss: 4.184929765881419

Epoch: 5| Step: 2
Training loss: 4.5543495432347845
Validation loss: 4.180458116645576

Epoch: 5| Step: 3
Training loss: 4.491616599252725
Validation loss: 4.173646029479495

Epoch: 5| Step: 4
Training loss: 3.871589143929098
Validation loss: 4.168285940554953

Epoch: 5| Step: 5
Training loss: 4.657324954893488
Validation loss: 4.161057548018343

Epoch: 5| Step: 6
Training loss: 4.044489212510315
Validation loss: 4.156592653725038

Epoch: 5| Step: 7
Training loss: 4.922598843102817
Validation loss: 4.151445891619033

Epoch: 5| Step: 8
Training loss: 3.429578496986501
Validation loss: 4.144317678976448

Epoch: 5| Step: 9
Training loss: 3.977547334380976
Validation loss: 4.137378326655322

Epoch: 5| Step: 10
Training loss: 4.11944089892089
Validation loss: 4.131473052581938

Epoch: 5| Step: 11
Training loss: 3.3190152854280117
Validation loss: 4.1253740882788925

Epoch: 31| Step: 0
Training loss: 4.226173030374646
Validation loss: 4.120501242133627

Epoch: 5| Step: 1
Training loss: 4.388984998356214
Validation loss: 4.1135663413438515

Epoch: 5| Step: 2
Training loss: 4.4540993143288015
Validation loss: 4.107992822155475

Epoch: 5| Step: 3
Training loss: 3.552384185728669
Validation loss: 4.10135315860391

Epoch: 5| Step: 4
Training loss: 3.7812806435596507
Validation loss: 4.096681724429619

Epoch: 5| Step: 5
Training loss: 4.457199427836043
Validation loss: 4.089909919463392

Epoch: 5| Step: 6
Training loss: 4.177438519503132
Validation loss: 4.084395273786301

Epoch: 5| Step: 7
Training loss: 3.7185938185263816
Validation loss: 4.078258444014434

Epoch: 5| Step: 8
Training loss: 3.877154704890154
Validation loss: 4.07422375335825

Epoch: 5| Step: 9
Training loss: 4.68160151344739
Validation loss: 4.067579082563512

Epoch: 5| Step: 10
Training loss: 4.799698486395029
Validation loss: 4.062178095266148

Epoch: 5| Step: 11
Training loss: 4.7850775264570276
Validation loss: 4.055768407319359

Epoch: 32| Step: 0
Training loss: 4.562545567115134
Validation loss: 4.0510133966761

Epoch: 5| Step: 1
Training loss: 4.363474022851024
Validation loss: 4.045128483501944

Epoch: 5| Step: 2
Training loss: 4.539600123805798
Validation loss: 4.038489728463591

Epoch: 5| Step: 3
Training loss: 3.3988290846147793
Validation loss: 4.03263746825459

Epoch: 5| Step: 4
Training loss: 3.8833771262476025
Validation loss: 4.026747108365438

Epoch: 5| Step: 5
Training loss: 3.997086059628766
Validation loss: 4.02007764754738

Epoch: 5| Step: 6
Training loss: 4.038505235372713
Validation loss: 4.015071172657431

Epoch: 5| Step: 7
Training loss: 4.198417892381875
Validation loss: 4.009128882331123

Epoch: 5| Step: 8
Training loss: 3.7354457708708204
Validation loss: 4.002999690941214

Epoch: 5| Step: 9
Training loss: 4.742031038270408
Validation loss: 4.000284294118578

Epoch: 5| Step: 10
Training loss: 4.190795967773409
Validation loss: 3.9938574605860717

Epoch: 5| Step: 11
Training loss: 3.360725025109459
Validation loss: 3.98680007037312

Epoch: 33| Step: 0
Training loss: 3.6335617769385196
Validation loss: 3.980711071361417

Epoch: 5| Step: 1
Training loss: 4.3524769450568
Validation loss: 3.9757119888666317

Epoch: 5| Step: 2
Training loss: 3.5195462885968247
Validation loss: 3.9718139365619822

Epoch: 5| Step: 3
Training loss: 4.297162632418411
Validation loss: 3.9645197092317606

Epoch: 5| Step: 4
Training loss: 4.144525037180193
Validation loss: 3.9586441453408936

Epoch: 5| Step: 5
Training loss: 4.996789664565069
Validation loss: 3.9530674725393866

Epoch: 5| Step: 6
Training loss: 3.8252148835901556
Validation loss: 3.9467015153537353

Epoch: 5| Step: 7
Training loss: 4.050902023648584
Validation loss: 3.941747856648116

Epoch: 5| Step: 8
Training loss: 4.225595303642555
Validation loss: 3.936152045810985

Epoch: 5| Step: 9
Training loss: 3.9573615370316917
Validation loss: 3.931150322132083

Epoch: 5| Step: 10
Training loss: 3.8413280517116344
Validation loss: 3.925230174189721

Epoch: 5| Step: 11
Training loss: 3.5646826766837494
Validation loss: 3.9198230071398448

Epoch: 34| Step: 0
Training loss: 4.194271022307611
Validation loss: 3.913067420260043

Epoch: 5| Step: 1
Training loss: 3.9528126951349245
Validation loss: 3.9085340104032253

Epoch: 5| Step: 2
Training loss: 3.803133104577437
Validation loss: 3.902550641883317

Epoch: 5| Step: 3
Training loss: 4.486706277257715
Validation loss: 3.898288283107484

Epoch: 5| Step: 4
Training loss: 4.0535520165412535
Validation loss: 3.891229825072206

Epoch: 5| Step: 5
Training loss: 3.4443342762081337
Validation loss: 3.8871184790474658

Epoch: 5| Step: 6
Training loss: 4.204615445690911
Validation loss: 3.8824057516304467

Epoch: 5| Step: 7
Training loss: 4.579779940986393
Validation loss: 3.8769611092716643

Epoch: 5| Step: 8
Training loss: 3.8647593880555458
Validation loss: 3.8703198831852537

Epoch: 5| Step: 9
Training loss: 3.872926834254524
Validation loss: 3.865961315848558

Epoch: 5| Step: 10
Training loss: 3.811403836116731
Validation loss: 3.8611992399798702

Epoch: 5| Step: 11
Training loss: 3.064284758261202
Validation loss: 3.854327944225065

Epoch: 35| Step: 0
Training loss: 4.06020983186635
Validation loss: 3.8481030303210626

Epoch: 5| Step: 1
Training loss: 4.2684808470291955
Validation loss: 3.8440868777971082

Epoch: 5| Step: 2
Training loss: 3.487395341731598
Validation loss: 3.8396867245880095

Epoch: 5| Step: 3
Training loss: 4.147707772595088
Validation loss: 3.833974290556948

Epoch: 5| Step: 4
Training loss: 3.6335976029160126
Validation loss: 3.827954154840888

Epoch: 5| Step: 5
Training loss: 3.558196027788234
Validation loss: 3.823595473530063

Epoch: 5| Step: 6
Training loss: 4.121011366178911
Validation loss: 3.817909030747777

Epoch: 5| Step: 7
Training loss: 4.027052712492641
Validation loss: 3.8137380877441824

Epoch: 5| Step: 8
Training loss: 4.325620070973997
Validation loss: 3.8071945463318495

Epoch: 5| Step: 9
Training loss: 3.9655239179517827
Validation loss: 3.802944533476312

Epoch: 5| Step: 10
Training loss: 3.7257455374153388
Validation loss: 3.797736443020347

Epoch: 5| Step: 11
Training loss: 4.450771633497379
Validation loss: 3.7926061098731725

Epoch: 36| Step: 0
Training loss: 3.4317481730265826
Validation loss: 3.7871395252189006

Epoch: 5| Step: 1
Training loss: 2.8612777965923653
Validation loss: 3.7827333057826733

Epoch: 5| Step: 2
Training loss: 4.08212329815476
Validation loss: 3.77819063620273

Epoch: 5| Step: 3
Training loss: 3.649510489259931
Validation loss: 3.774284999494697

Epoch: 5| Step: 4
Training loss: 3.718791672929909
Validation loss: 3.768115764494188

Epoch: 5| Step: 5
Training loss: 4.499702655717171
Validation loss: 3.764822392912037

Epoch: 5| Step: 6
Training loss: 4.173242237774664
Validation loss: 3.758120846010407

Epoch: 5| Step: 7
Training loss: 3.852923108432374
Validation loss: 3.7535454678904823

Epoch: 5| Step: 8
Training loss: 3.5885553382793964
Validation loss: 3.7479936159612866

Epoch: 5| Step: 9
Training loss: 4.288152101267341
Validation loss: 3.7438783960078537

Epoch: 5| Step: 10
Training loss: 4.406448251579457
Validation loss: 3.7388969985205747

Epoch: 5| Step: 11
Training loss: 3.9113723738664796
Validation loss: 3.7340151082679753

Epoch: 37| Step: 0
Training loss: 3.9283188850181365
Validation loss: 3.7289393833451183

Epoch: 5| Step: 1
Training loss: 4.320836509671541
Validation loss: 3.724325562979231

Epoch: 5| Step: 2
Training loss: 4.120708892352467
Validation loss: 3.7187168109171433

Epoch: 5| Step: 3
Training loss: 4.1951440532262225
Validation loss: 3.714021417232505

Epoch: 5| Step: 4
Training loss: 4.317424229507573
Validation loss: 3.708780672473455

Epoch: 5| Step: 5
Training loss: 3.7099460281188965
Validation loss: 3.703490640264747

Epoch: 5| Step: 6
Training loss: 3.615161699237435
Validation loss: 3.6975866179415156

Epoch: 5| Step: 7
Training loss: 3.677425393826589
Validation loss: 3.693263748789595

Epoch: 5| Step: 8
Training loss: 3.883479162815222
Validation loss: 3.6879513351183766

Epoch: 5| Step: 9
Training loss: 2.942213618911632
Validation loss: 3.683106925242901

Epoch: 5| Step: 10
Training loss: 3.3924327900468936
Validation loss: 3.6795197574855503

Epoch: 5| Step: 11
Training loss: 3.472806740622755
Validation loss: 3.674595381072535

Epoch: 38| Step: 0
Training loss: 3.758515290270192
Validation loss: 3.6699179878911306

Epoch: 5| Step: 1
Training loss: 3.9046835237981203
Validation loss: 3.6654607169608586

Epoch: 5| Step: 2
Training loss: 3.958209119487467
Validation loss: 3.6607379105101345

Epoch: 5| Step: 3
Training loss: 4.413268647502585
Validation loss: 3.6558693799085993

Epoch: 5| Step: 4
Training loss: 3.887423626802671
Validation loss: 3.65172070851651

Epoch: 5| Step: 5
Training loss: 3.8965673452162566
Validation loss: 3.6477321294138036

Epoch: 5| Step: 6
Training loss: 3.811820297937017
Validation loss: 3.6424226211204425

Epoch: 5| Step: 7
Training loss: 3.7849942419696183
Validation loss: 3.637772284254521

Epoch: 5| Step: 8
Training loss: 3.4953126855337735
Validation loss: 3.632466737980401

Epoch: 5| Step: 9
Training loss: 2.8436638116875503
Validation loss: 3.6282590597631836

Epoch: 5| Step: 10
Training loss: 3.663201660020581
Validation loss: 3.6235277376046295

Epoch: 5| Step: 11
Training loss: 3.875786486150968
Validation loss: 3.619496354971579

Epoch: 39| Step: 0
Training loss: 4.001548944023553
Validation loss: 3.6157832760293673

Epoch: 5| Step: 1
Training loss: 4.409925078017266
Validation loss: 3.612635390836576

Epoch: 5| Step: 2
Training loss: 4.144194363664441
Validation loss: 3.6074394386743776

Epoch: 5| Step: 3
Training loss: 2.981481457568323
Validation loss: 3.602132105382234

Epoch: 5| Step: 4
Training loss: 3.9224799552098975
Validation loss: 3.5978905804779413

Epoch: 5| Step: 5
Training loss: 3.6074982755343625
Validation loss: 3.593404371807373

Epoch: 5| Step: 6
Training loss: 3.6666907540888425
Validation loss: 3.588572828197228

Epoch: 5| Step: 7
Training loss: 3.581240168319974
Validation loss: 3.5854282945661975

Epoch: 5| Step: 8
Training loss: 3.590054145765945
Validation loss: 3.57922332542672

Epoch: 5| Step: 9
Training loss: 3.7742246829511172
Validation loss: 3.5756485321883305

Epoch: 5| Step: 10
Training loss: 3.250350199685145
Validation loss: 3.57110235824777

Epoch: 5| Step: 11
Training loss: 3.226144832890812
Validation loss: 3.5661220040334674

Epoch: 40| Step: 0
Training loss: 3.3853469763209576
Validation loss: 3.5620522691781686

Epoch: 5| Step: 1
Training loss: 3.6082665529010836
Validation loss: 3.557696874652609

Epoch: 5| Step: 2
Training loss: 3.545885796762101
Validation loss: 3.5537388077080077

Epoch: 5| Step: 3
Training loss: 3.459020079175906
Validation loss: 3.5494203998778695

Epoch: 5| Step: 4
Training loss: 3.411252469362097
Validation loss: 3.5452165605507453

Epoch: 5| Step: 5
Training loss: 3.99047958360006
Validation loss: 3.5404697284281585

Epoch: 5| Step: 6
Training loss: 2.9400537631250754
Validation loss: 3.5364572565285903

Epoch: 5| Step: 7
Training loss: 3.948207888099223
Validation loss: 3.532672016241853

Epoch: 5| Step: 8
Training loss: 3.7800081594066253
Validation loss: 3.527753956072686

Epoch: 5| Step: 9
Training loss: 4.104292246386702
Validation loss: 3.5234435927964993

Epoch: 5| Step: 10
Training loss: 3.9153822693479765
Validation loss: 3.519459787561308

Epoch: 5| Step: 11
Training loss: 4.550547581514336
Validation loss: 3.5152770258742225

Epoch: 41| Step: 0
Training loss: 3.804138770667945
Validation loss: 3.510492622089552

Epoch: 5| Step: 1
Training loss: 3.8237139765179546
Validation loss: 3.5054762493677063

Epoch: 5| Step: 2
Training loss: 3.4132027318178406
Validation loss: 3.501332370016581

Epoch: 5| Step: 3
Training loss: 3.719674131825617
Validation loss: 3.49604955890367

Epoch: 5| Step: 4
Training loss: 3.4828188034007423
Validation loss: 3.4918013578958624

Epoch: 5| Step: 5
Training loss: 3.1280199336224124
Validation loss: 3.487697101022964

Epoch: 5| Step: 6
Training loss: 3.5462766974556557
Validation loss: 3.4831747716348835

Epoch: 5| Step: 7
Training loss: 3.303791330449211
Validation loss: 3.4793972216906615

Epoch: 5| Step: 8
Training loss: 3.9914564444999074
Validation loss: 3.4749488085811455

Epoch: 5| Step: 9
Training loss: 4.128860054732117
Validation loss: 3.4711482890101064

Epoch: 5| Step: 10
Training loss: 3.3020265656574628
Validation loss: 3.4662644184251503

Epoch: 5| Step: 11
Training loss: 4.1340607054396
Validation loss: 3.4624849165348053

Epoch: 42| Step: 0
Training loss: 4.022815960032352
Validation loss: 3.4576182123949195

Epoch: 5| Step: 1
Training loss: 3.5415259539008495
Validation loss: 3.453534788094296

Epoch: 5| Step: 2
Training loss: 3.873406113177721
Validation loss: 3.4494968703952873

Epoch: 5| Step: 3
Training loss: 3.01067265848803
Validation loss: 3.4450776415852515

Epoch: 5| Step: 4
Training loss: 4.467611741438731
Validation loss: 3.4406138968223594

Epoch: 5| Step: 5
Training loss: 3.090587810913609
Validation loss: 3.43620662921795

Epoch: 5| Step: 6
Training loss: 2.395668245239219
Validation loss: 3.4323209704400934

Epoch: 5| Step: 7
Training loss: 3.2434182646067358
Validation loss: 3.42834661944505

Epoch: 5| Step: 8
Training loss: 4.337021700737272
Validation loss: 3.424547205878809

Epoch: 5| Step: 9
Training loss: 3.405425645660906
Validation loss: 3.4200675928954167

Epoch: 5| Step: 10
Training loss: 3.5673869561380944
Validation loss: 3.416088175453042

Epoch: 5| Step: 11
Training loss: 2.797141291552364
Validation loss: 3.4124977838418213

Epoch: 43| Step: 0
Training loss: 3.4746671503505335
Validation loss: 3.4083855435321677

Epoch: 5| Step: 1
Training loss: 4.011973104613075
Validation loss: 3.4048151149586943

Epoch: 5| Step: 2
Training loss: 2.9770153432084845
Validation loss: 3.400421317727245

Epoch: 5| Step: 3
Training loss: 3.540671683775557
Validation loss: 3.397158385677139

Epoch: 5| Step: 4
Training loss: 3.7576168271073556
Validation loss: 3.3932472554464175

Epoch: 5| Step: 5
Training loss: 3.0812501485642714
Validation loss: 3.3893168983401156

Epoch: 5| Step: 6
Training loss: 3.5203409396130545
Validation loss: 3.3857591113487344

Epoch: 5| Step: 7
Training loss: 4.180686075588799
Validation loss: 3.3820638790012074

Epoch: 5| Step: 8
Training loss: 4.067487267003589
Validation loss: 3.378616235300639

Epoch: 5| Step: 9
Training loss: 3.0433017220444847
Validation loss: 3.374653939766349

Epoch: 5| Step: 10
Training loss: 3.0169380768416625
Validation loss: 3.3699225803673865

Epoch: 5| Step: 11
Training loss: 2.7162741426254287
Validation loss: 3.366072326232166

Epoch: 44| Step: 0
Training loss: 3.506787122632612
Validation loss: 3.362559664621158

Epoch: 5| Step: 1
Training loss: 3.324053212223058
Validation loss: 3.358598823481417

Epoch: 5| Step: 2
Training loss: 3.3586307144704195
Validation loss: 3.3551129591772333

Epoch: 5| Step: 3
Training loss: 3.259213080183401
Validation loss: 3.3516026533755223

Epoch: 5| Step: 4
Training loss: 4.0855759411463675
Validation loss: 3.3481071580975548

Epoch: 5| Step: 5
Training loss: 3.5716207098366537
Validation loss: 3.3441941688224857

Epoch: 5| Step: 6
Training loss: 3.1987247667886325
Validation loss: 3.3402437204821993

Epoch: 5| Step: 7
Training loss: 3.8752972888732597
Validation loss: 3.3368924193907943

Epoch: 5| Step: 8
Training loss: 3.2606715548560636
Validation loss: 3.333145202851121

Epoch: 5| Step: 9
Training loss: 3.5871992031623985
Validation loss: 3.3293189592026966

Epoch: 5| Step: 10
Training loss: 3.277697574762132
Validation loss: 3.325462538950821

Epoch: 5| Step: 11
Training loss: 2.968574759681959
Validation loss: 3.322265394757633

Epoch: 45| Step: 0
Training loss: 3.4469196610657042
Validation loss: 3.318841292615721

Epoch: 5| Step: 1
Training loss: 3.351980187769495
Validation loss: 3.315214796035813

Epoch: 5| Step: 2
Training loss: 3.672669669660124
Validation loss: 3.3114196047098634

Epoch: 5| Step: 3
Training loss: 4.339084012806208
Validation loss: 3.3077734088224595

Epoch: 5| Step: 4
Training loss: 3.0027175356969775
Validation loss: 3.3038961426454114

Epoch: 5| Step: 5
Training loss: 3.4884335269989077
Validation loss: 3.3003818729317853

Epoch: 5| Step: 6
Training loss: 2.7253119543858206
Validation loss: 3.296611015996317

Epoch: 5| Step: 7
Training loss: 3.2658618311811987
Validation loss: 3.2931517327310136

Epoch: 5| Step: 8
Training loss: 3.3798273672225574
Validation loss: 3.290144955916307

Epoch: 5| Step: 9
Training loss: 3.5669874070835292
Validation loss: 3.2864717018754304

Epoch: 5| Step: 10
Training loss: 3.3410197011440412
Validation loss: 3.2833375375659446

Epoch: 5| Step: 11
Training loss: 3.653936713945862
Validation loss: 3.2793503181929915

Epoch: 46| Step: 0
Training loss: 3.5300901415503123
Validation loss: 3.2761910631394073

Epoch: 5| Step: 1
Training loss: 3.242541925751892
Validation loss: 3.2725579438933585

Epoch: 5| Step: 2
Training loss: 3.3165516096953698
Validation loss: 3.27037416665177

Epoch: 5| Step: 3
Training loss: 3.51615854241326
Validation loss: 3.2663034589119975

Epoch: 5| Step: 4
Training loss: 3.2454823125822423
Validation loss: 3.262657115826491

Epoch: 5| Step: 5
Training loss: 3.4594384384885912
Validation loss: 3.2588683688282227

Epoch: 5| Step: 6
Training loss: 3.622586992797515
Validation loss: 3.254933464143746

Epoch: 5| Step: 7
Training loss: 3.7344179031269804
Validation loss: 3.251861558757245

Epoch: 5| Step: 8
Training loss: 3.6948920690235862
Validation loss: 3.2481470388878737

Epoch: 5| Step: 9
Training loss: 3.011550601762743
Validation loss: 3.2446080896280516

Epoch: 5| Step: 10
Training loss: 3.133997514686013
Validation loss: 3.2411586615122476

Epoch: 5| Step: 11
Training loss: 2.248835156171156
Validation loss: 3.237676198133982

Epoch: 47| Step: 0
Training loss: 3.62532752300366
Validation loss: 3.234735576292144

Epoch: 5| Step: 1
Training loss: 2.9253313969084394
Validation loss: 3.2316962066239383

Epoch: 5| Step: 2
Training loss: 3.093783137596756
Validation loss: 3.2293948533845893

Epoch: 5| Step: 3
Training loss: 2.829205891295612
Validation loss: 3.2260022173399143

Epoch: 5| Step: 4
Training loss: 3.479956455396751
Validation loss: 3.223043910898878

Epoch: 5| Step: 5
Training loss: 3.6337738405855595
Validation loss: 3.219991922748497

Epoch: 5| Step: 6
Training loss: 3.5813232520901983
Validation loss: 3.217516462130301

Epoch: 5| Step: 7
Training loss: 3.319457323234683
Validation loss: 3.213886982290687

Epoch: 5| Step: 8
Training loss: 3.646072045640282
Validation loss: 3.2108258415911632

Epoch: 5| Step: 9
Training loss: 3.3775544566092255
Validation loss: 3.2076349034908276

Epoch: 5| Step: 10
Training loss: 3.480115673510463
Validation loss: 3.2049252669081487

Epoch: 5| Step: 11
Training loss: 2.4367371367959105
Validation loss: 3.2012931609902817

Epoch: 48| Step: 0
Training loss: 2.581050345986937
Validation loss: 3.1980554610626712

Epoch: 5| Step: 1
Training loss: 3.6309159773610515
Validation loss: 3.1948246976033987

Epoch: 5| Step: 2
Training loss: 3.06523788450003
Validation loss: 3.191961226968383

Epoch: 5| Step: 3
Training loss: 3.43824135848855
Validation loss: 3.189235339542176

Epoch: 5| Step: 4
Training loss: 3.697408521241495
Validation loss: 3.186043640359274

Epoch: 5| Step: 5
Training loss: 3.8310981259884413
Validation loss: 3.1834740988746826

Epoch: 5| Step: 6
Training loss: 3.325290242771213
Validation loss: 3.179987200485318

Epoch: 5| Step: 7
Training loss: 2.9780828643091675
Validation loss: 3.176574876882819

Epoch: 5| Step: 8
Training loss: 3.0151463262119202
Validation loss: 3.173260046566123

Epoch: 5| Step: 9
Training loss: 3.396989465660671
Validation loss: 3.1701340305662074

Epoch: 5| Step: 10
Training loss: 3.4038347553259607
Validation loss: 3.1676740058478186

Epoch: 5| Step: 11
Training loss: 3.273949922135549
Validation loss: 3.1638727704215217

Epoch: 49| Step: 0
Training loss: 3.747684781314028
Validation loss: 3.161045221343372

Epoch: 5| Step: 1
Training loss: 3.3367687324311928
Validation loss: 3.1578179578499594

Epoch: 5| Step: 2
Training loss: 3.3140045204108746
Validation loss: 3.1544420332916396

Epoch: 5| Step: 3
Training loss: 3.7933412284523094
Validation loss: 3.1517028976535233

Epoch: 5| Step: 4
Training loss: 3.050809227574579
Validation loss: 3.1484858853871533

Epoch: 5| Step: 5
Training loss: 2.9428605211902545
Validation loss: 3.1443733665367537

Epoch: 5| Step: 6
Training loss: 3.499049602626843
Validation loss: 3.1420364655942996

Epoch: 5| Step: 7
Training loss: 2.948581652005744
Validation loss: 3.138372312412769

Epoch: 5| Step: 8
Training loss: 3.22713703646877
Validation loss: 3.1358273871881854

Epoch: 5| Step: 9
Training loss: 3.1836819689176594
Validation loss: 3.1319308288872225

Epoch: 5| Step: 10
Training loss: 3.093039382856508
Validation loss: 3.1286813605137094

Epoch: 5| Step: 11
Training loss: 2.7356541720554652
Validation loss: 3.1260521357326163

Epoch: 50| Step: 0
Training loss: 3.3376550474120505
Validation loss: 3.1234784300277

Epoch: 5| Step: 1
Training loss: 3.2319413764376947
Validation loss: 3.1209873281580367

Epoch: 5| Step: 2
Training loss: 3.7564251850933505
Validation loss: 3.1180825283032747

Epoch: 5| Step: 3
Training loss: 2.9671726252548103
Validation loss: 3.115699916641638

Epoch: 5| Step: 4
Training loss: 2.6152010082939587
Validation loss: 3.1134532496453358

Epoch: 5| Step: 5
Training loss: 3.69016518696056
Validation loss: 3.1111428141161257

Epoch: 5| Step: 6
Training loss: 3.034240820262406
Validation loss: 3.1078322335638475

Epoch: 5| Step: 7
Training loss: 3.598090693350189
Validation loss: 3.1054297422762227

Epoch: 5| Step: 8
Training loss: 3.2536017194118227
Validation loss: 3.102315739178822

Epoch: 5| Step: 9
Training loss: 2.4523137202859338
Validation loss: 3.0993388361768828

Epoch: 5| Step: 10
Training loss: 3.5838986919253695
Validation loss: 3.0971056403517423

Epoch: 5| Step: 11
Training loss: 3.029758833802357
Validation loss: 3.094291466232844

Epoch: 51| Step: 0
Training loss: 2.716022131429401
Validation loss: 3.0914881173130215

Epoch: 5| Step: 1
Training loss: 3.565006512051449
Validation loss: 3.0886424993273787

Epoch: 5| Step: 2
Training loss: 2.967340395715977
Validation loss: 3.0862267853554024

Epoch: 5| Step: 3
Training loss: 3.1632008073847215
Validation loss: 3.0835779818999995

Epoch: 5| Step: 4
Training loss: 3.06653733671837
Validation loss: 3.080937802797465

Epoch: 5| Step: 5
Training loss: 3.3743555372015663
Validation loss: 3.0778962968526047

Epoch: 5| Step: 6
Training loss: 3.1508396724975816
Validation loss: 3.0749050991538565

Epoch: 5| Step: 7
Training loss: 3.2178223393476806
Validation loss: 3.0721568520625335

Epoch: 5| Step: 8
Training loss: 3.4004405465534213
Validation loss: 3.069729828165846

Epoch: 5| Step: 9
Training loss: 3.296654861115344
Validation loss: 3.066883644473783

Epoch: 5| Step: 10
Training loss: 3.3535538739537576
Validation loss: 3.063672301978878

Epoch: 5| Step: 11
Training loss: 3.4586171106549557
Validation loss: 3.061355250361191

Epoch: 52| Step: 0
Training loss: 3.524997408169274
Validation loss: 3.0582589217513485

Epoch: 5| Step: 1
Training loss: 3.2625864302488217
Validation loss: 3.055267802449917

Epoch: 5| Step: 2
Training loss: 3.4705550162721353
Validation loss: 3.0520674582492737

Epoch: 5| Step: 3
Training loss: 2.1757720453968226
Validation loss: 3.0490832909323546

Epoch: 5| Step: 4
Training loss: 3.3825222533988994
Validation loss: 3.0467351702042826

Epoch: 5| Step: 5
Training loss: 3.500773072015038
Validation loss: 3.043125953253707

Epoch: 5| Step: 6
Training loss: 3.2859446047979537
Validation loss: 3.0407507749853044

Epoch: 5| Step: 7
Training loss: 2.8512614888215215
Validation loss: 3.037356325108427

Epoch: 5| Step: 8
Training loss: 3.120925994298751
Validation loss: 3.0344909043443153

Epoch: 5| Step: 9
Training loss: 3.6203397852725976
Validation loss: 3.031941462826123

Epoch: 5| Step: 10
Training loss: 2.4807238350014766
Validation loss: 3.029055089133075

Epoch: 5| Step: 11
Training loss: 3.3983735177166694
Validation loss: 3.0263767921350326

Epoch: 53| Step: 0
Training loss: 3.5889156831332287
Validation loss: 3.0237759935413746

Epoch: 5| Step: 1
Training loss: 3.326913962514969
Validation loss: 3.0216988518444383

Epoch: 5| Step: 2
Training loss: 2.6465237435090727
Validation loss: 3.01857981100069

Epoch: 5| Step: 3
Training loss: 2.837254074127367
Validation loss: 3.0167059138855397

Epoch: 5| Step: 4
Training loss: 3.3704645270243816
Validation loss: 3.014407305706827

Epoch: 5| Step: 5
Training loss: 3.307598302047871
Validation loss: 3.011832568652179

Epoch: 5| Step: 6
Training loss: 2.958431582543167
Validation loss: 3.0095488288458028

Epoch: 5| Step: 7
Training loss: 3.0484286528614892
Validation loss: 3.006842598035819

Epoch: 5| Step: 8
Training loss: 3.118510871235839
Validation loss: 3.00435316632985

Epoch: 5| Step: 9
Training loss: 3.3828953827534036
Validation loss: 3.002420832828748

Epoch: 5| Step: 10
Training loss: 2.972332208644404
Validation loss: 2.9996175787157346

Epoch: 5| Step: 11
Training loss: 3.2361874132524906
Validation loss: 2.997565274899909

Epoch: 54| Step: 0
Training loss: 3.1493772708606804
Validation loss: 2.994710013340689

Epoch: 5| Step: 1
Training loss: 3.257705064644129
Validation loss: 2.992264609675438

Epoch: 5| Step: 2
Training loss: 2.90394927807063
Validation loss: 2.989743565154347

Epoch: 5| Step: 3
Training loss: 3.310485083079295
Validation loss: 2.987089992596829

Epoch: 5| Step: 4
Training loss: 3.0474676093867235
Validation loss: 2.9848904056440926

Epoch: 5| Step: 5
Training loss: 3.569730548467162
Validation loss: 2.982343554847594

Epoch: 5| Step: 6
Training loss: 2.73601792161214
Validation loss: 2.979342119790237

Epoch: 5| Step: 7
Training loss: 2.8360375420865838
Validation loss: 2.977502218977504

Epoch: 5| Step: 8
Training loss: 3.0298597156040468
Validation loss: 2.9750610429447644

Epoch: 5| Step: 9
Training loss: 2.5799363679949225
Validation loss: 2.972698293247405

Epoch: 5| Step: 10
Training loss: 3.6349676487045803
Validation loss: 2.970326804645521

Epoch: 5| Step: 11
Training loss: 3.7077398075223194
Validation loss: 2.9681405797161107

Epoch: 55| Step: 0
Training loss: 3.6889736011333016
Validation loss: 2.965054293039462

Epoch: 5| Step: 1
Training loss: 2.8880364452292095
Validation loss: 2.9621435542488377

Epoch: 5| Step: 2
Training loss: 3.5258923963376643
Validation loss: 2.959055152105346

Epoch: 5| Step: 3
Training loss: 3.2723496115613386
Validation loss: 2.9560684759958726

Epoch: 5| Step: 4
Training loss: 3.0437173767221477
Validation loss: 2.953556032698576

Epoch: 5| Step: 5
Training loss: 2.8911755836498694
Validation loss: 2.9509926721985393

Epoch: 5| Step: 6
Training loss: 3.2565697511160847
Validation loss: 2.948700394034626

Epoch: 5| Step: 7
Training loss: 3.1698061956615264
Validation loss: 2.9461080891534968

Epoch: 5| Step: 8
Training loss: 2.7724406425375534
Validation loss: 2.943600896769988

Epoch: 5| Step: 9
Training loss: 3.2456972543367444
Validation loss: 2.941699296691074

Epoch: 5| Step: 10
Training loss: 1.9611129378303376
Validation loss: 2.9390805469846457

Epoch: 5| Step: 11
Training loss: 3.0698662741795797
Validation loss: 2.936497811553545

Epoch: 56| Step: 0
Training loss: 3.233948315473412
Validation loss: 2.9340281294020545

Epoch: 5| Step: 1
Training loss: 3.3608989718688194
Validation loss: 2.931955515880112

Epoch: 5| Step: 2
Training loss: 3.4784502369187655
Validation loss: 2.929176821810907

Epoch: 5| Step: 3
Training loss: 2.891317583573204
Validation loss: 2.927249697825398

Epoch: 5| Step: 4
Training loss: 2.5590405256096758
Validation loss: 2.9242190072347176

Epoch: 5| Step: 5
Training loss: 2.6073075744493135
Validation loss: 2.9221608435196504

Epoch: 5| Step: 6
Training loss: 2.9994272639018917
Validation loss: 2.920514604335277

Epoch: 5| Step: 7
Training loss: 3.4353744871296477
Validation loss: 2.918071974801394

Epoch: 5| Step: 8
Training loss: 2.9938529934617635
Validation loss: 2.915677043508914

Epoch: 5| Step: 9
Training loss: 3.0213003564882803
Validation loss: 2.913768596674377

Epoch: 5| Step: 10
Training loss: 2.8646009040062452
Validation loss: 2.9114130672878034

Epoch: 5| Step: 11
Training loss: 3.587050587221095
Validation loss: 2.90912812439006

Epoch: 57| Step: 0
Training loss: 2.7611076401864163
Validation loss: 2.907424313507773

Epoch: 5| Step: 1
Training loss: 3.0603672308377385
Validation loss: 2.9051222305058144

Epoch: 5| Step: 2
Training loss: 2.5960356970744103
Validation loss: 2.9031425701385754

Epoch: 5| Step: 3
Training loss: 2.984764513091175
Validation loss: 2.9011175578319395

Epoch: 5| Step: 4
Training loss: 2.9365338298993025
Validation loss: 2.898615260127076

Epoch: 5| Step: 5
Training loss: 2.9658396057365555
Validation loss: 2.896784980524747

Epoch: 5| Step: 6
Training loss: 3.3488471139778615
Validation loss: 2.895190192691403

Epoch: 5| Step: 7
Training loss: 3.1954303896918503
Validation loss: 2.8926872766864173

Epoch: 5| Step: 8
Training loss: 3.241803176346072
Validation loss: 2.890781944756888

Epoch: 5| Step: 9
Training loss: 2.9842837654268624
Validation loss: 2.88852350981534

Epoch: 5| Step: 10
Training loss: 3.173250097604316
Validation loss: 2.8860645886499072

Epoch: 5| Step: 11
Training loss: 3.4997836454823243
Validation loss: 2.884202072619147

Epoch: 58| Step: 0
Training loss: 2.9069098267061166
Validation loss: 2.881967577528637

Epoch: 5| Step: 1
Training loss: 3.314374429356344
Validation loss: 2.8802266295658434

Epoch: 5| Step: 2
Training loss: 3.614252139408882
Validation loss: 2.8783258813262

Epoch: 5| Step: 3
Training loss: 3.0579423271613737
Validation loss: 2.876155064931033

Epoch: 5| Step: 4
Training loss: 3.059582313005112
Validation loss: 2.8742347680202234

Epoch: 5| Step: 5
Training loss: 2.9553617856874577
Validation loss: 2.8721666679834637

Epoch: 5| Step: 6
Training loss: 2.820086779239931
Validation loss: 2.870204360467041

Epoch: 5| Step: 7
Training loss: 3.1240643435701054
Validation loss: 2.86845574320767

Epoch: 5| Step: 8
Training loss: 2.646175172204627
Validation loss: 2.8662411499164078

Epoch: 5| Step: 9
Training loss: 2.90383909577315
Validation loss: 2.8641892017532005

Epoch: 5| Step: 10
Training loss: 2.7160229214696865
Validation loss: 2.8627807471183453

Epoch: 5| Step: 11
Training loss: 2.617992857956087
Validation loss: 2.8609323863704805

Epoch: 59| Step: 0
Training loss: 3.282193002980397
Validation loss: 2.8591335694993454

Epoch: 5| Step: 1
Training loss: 3.103656974440029
Validation loss: 2.8572666511084948

Epoch: 5| Step: 2
Training loss: 3.0223544445597055
Validation loss: 2.8553456472570273

Epoch: 5| Step: 3
Training loss: 3.1355184916609646
Validation loss: 2.853561484551253

Epoch: 5| Step: 4
Training loss: 2.884270028201426
Validation loss: 2.8516874904325595

Epoch: 5| Step: 5
Training loss: 2.89854969722619
Validation loss: 2.8498570119112543

Epoch: 5| Step: 6
Training loss: 3.0065536440845855
Validation loss: 2.847745498912202

Epoch: 5| Step: 7
Training loss: 2.636375845758274
Validation loss: 2.846170115242641

Epoch: 5| Step: 8
Training loss: 3.344036054407714
Validation loss: 2.844463915518173

Epoch: 5| Step: 9
Training loss: 2.708433022253856
Validation loss: 2.8427352631885587

Epoch: 5| Step: 10
Training loss: 2.7396971433567057
Validation loss: 2.841124573280425

Epoch: 5| Step: 11
Training loss: 3.3306585706556935
Validation loss: 2.839773919717506

Epoch: 60| Step: 0
Training loss: 2.487213432635982
Validation loss: 2.8375409675083025

Epoch: 5| Step: 1
Training loss: 2.831819429039663
Validation loss: 2.836297400330507

Epoch: 5| Step: 2
Training loss: 3.2847377587655098
Validation loss: 2.834584469469538

Epoch: 5| Step: 3
Training loss: 2.9632963180661753
Validation loss: 2.832632827882194

Epoch: 5| Step: 4
Training loss: 2.7652999773150424
Validation loss: 2.830791326481977

Epoch: 5| Step: 5
Training loss: 3.1691464870177204
Validation loss: 2.829427506993498

Epoch: 5| Step: 6
Training loss: 3.1979074550500135
Validation loss: 2.827532493669931

Epoch: 5| Step: 7
Training loss: 2.9519216517877735
Validation loss: 2.8257632958704244

Epoch: 5| Step: 8
Training loss: 2.5096582768263236
Validation loss: 2.82415057003724

Epoch: 5| Step: 9
Training loss: 3.29095013380682
Validation loss: 2.8229934932957166

Epoch: 5| Step: 10
Training loss: 3.0596186259351725
Validation loss: 2.8211611477436986

Epoch: 5| Step: 11
Training loss: 3.132473972513828
Validation loss: 2.819649203595407

Epoch: 61| Step: 0
Training loss: 3.246335825059154
Validation loss: 2.8175504761275407

Epoch: 5| Step: 1
Training loss: 3.022244476800523
Validation loss: 2.8154786760961925

Epoch: 5| Step: 2
Training loss: 3.1904507610931656
Validation loss: 2.813949776438745

Epoch: 5| Step: 3
Training loss: 2.771709838901033
Validation loss: 2.812038733486234

Epoch: 5| Step: 4
Training loss: 2.8329855948585885
Validation loss: 2.8103311441321206

Epoch: 5| Step: 5
Training loss: 2.806254339745783
Validation loss: 2.8083595740642187

Epoch: 5| Step: 6
Training loss: 2.6508266958876923
Validation loss: 2.8065477965101118

Epoch: 5| Step: 7
Training loss: 2.7696157854142727
Validation loss: 2.8048037272024966

Epoch: 5| Step: 8
Training loss: 3.097851741053128
Validation loss: 2.8033671551983863

Epoch: 5| Step: 9
Training loss: 3.1128091681563776
Validation loss: 2.801459655462593

Epoch: 5| Step: 10
Training loss: 3.100771094373093
Validation loss: 2.79984709813232

Epoch: 5| Step: 11
Training loss: 1.6432220249252574
Validation loss: 2.798332065688394

Epoch: 62| Step: 0
Training loss: 2.4596310977820464
Validation loss: 2.797030663021148

Epoch: 5| Step: 1
Training loss: 3.1882087069248044
Validation loss: 2.795763348917734

Epoch: 5| Step: 2
Training loss: 2.7456479748538136
Validation loss: 2.7943488954777904

Epoch: 5| Step: 3
Training loss: 2.915206398306398
Validation loss: 2.7933142210523534

Epoch: 5| Step: 4
Training loss: 2.985749412533369
Validation loss: 2.7918097734542524

Epoch: 5| Step: 5
Training loss: 2.971491300921582
Validation loss: 2.790447639134709

Epoch: 5| Step: 6
Training loss: 3.178017967619857
Validation loss: 2.7890576523739585

Epoch: 5| Step: 7
Training loss: 3.0117854050361506
Validation loss: 2.787550718618715

Epoch: 5| Step: 8
Training loss: 2.7106622121911603
Validation loss: 2.785910880003882

Epoch: 5| Step: 9
Training loss: 3.025616474230219
Validation loss: 2.784882234609484

Epoch: 5| Step: 10
Training loss: 2.8559701795009573
Validation loss: 2.783520500424876

Epoch: 5| Step: 11
Training loss: 3.510759436892603
Validation loss: 2.7820053967805882

Epoch: 63| Step: 0
Training loss: 3.2949851165111177
Validation loss: 2.7808267328456258

Epoch: 5| Step: 1
Training loss: 2.995189306425095
Validation loss: 2.7800198416893744

Epoch: 5| Step: 2
Training loss: 3.2361451248615287
Validation loss: 2.7780358640991336

Epoch: 5| Step: 3
Training loss: 3.0548947939574673
Validation loss: 2.776801076416361

Epoch: 5| Step: 4
Training loss: 2.802864098288196
Validation loss: 2.7759643684680686

Epoch: 5| Step: 5
Training loss: 2.5934141929821166
Validation loss: 2.7738719331295396

Epoch: 5| Step: 6
Training loss: 2.63660327799814
Validation loss: 2.7721914366650187

Epoch: 5| Step: 7
Training loss: 2.5677424513050626
Validation loss: 2.7713561903218435

Epoch: 5| Step: 8
Training loss: 3.1401157250916363
Validation loss: 2.770030871091884

Epoch: 5| Step: 9
Training loss: 2.9526780209019043
Validation loss: 2.7685898300353555

Epoch: 5| Step: 10
Training loss: 2.695684523408415
Validation loss: 2.767715421980305

Epoch: 5| Step: 11
Training loss: 2.8258738963722783
Validation loss: 2.766074214164487

Epoch: 64| Step: 0
Training loss: 2.7198989019118143
Validation loss: 2.7644927945483824

Epoch: 5| Step: 1
Training loss: 3.236610856077573
Validation loss: 2.7631522509032047

Epoch: 5| Step: 2
Training loss: 3.075553323227961
Validation loss: 2.761913463557485

Epoch: 5| Step: 3
Training loss: 2.412890004470891
Validation loss: 2.7604675660149085

Epoch: 5| Step: 4
Training loss: 2.8206233225808375
Validation loss: 2.759166723637497

Epoch: 5| Step: 5
Training loss: 2.928309734627897
Validation loss: 2.7579199398102228

Epoch: 5| Step: 6
Training loss: 2.645230312163466
Validation loss: 2.756830388188675

Epoch: 5| Step: 7
Training loss: 3.255555173579495
Validation loss: 2.7549072682835503

Epoch: 5| Step: 8
Training loss: 2.674495995359334
Validation loss: 2.7535807315718035

Epoch: 5| Step: 9
Training loss: 3.190034643959699
Validation loss: 2.752299600796266

Epoch: 5| Step: 10
Training loss: 2.8895332542944265
Validation loss: 2.7510352534130664

Epoch: 5| Step: 11
Training loss: 2.3919530433460157
Validation loss: 2.749431930736491

Epoch: 65| Step: 0
Training loss: 2.6984945338704343
Validation loss: 2.7480992662631705

Epoch: 5| Step: 1
Training loss: 2.482591576707103
Validation loss: 2.747076998947835

Epoch: 5| Step: 2
Training loss: 2.9871343668244767
Validation loss: 2.745735629856203

Epoch: 5| Step: 3
Training loss: 2.6844235043923
Validation loss: 2.7442647813107754

Epoch: 5| Step: 4
Training loss: 3.081688536722315
Validation loss: 2.742406570074108

Epoch: 5| Step: 5
Training loss: 2.9039052713355056
Validation loss: 2.741284271480587

Epoch: 5| Step: 6
Training loss: 3.3631071428875137
Validation loss: 2.7400752678682427

Epoch: 5| Step: 7
Training loss: 2.5321749657296335
Validation loss: 2.7384560457128577

Epoch: 5| Step: 8
Training loss: 2.7314384168497603
Validation loss: 2.73705103399048

Epoch: 5| Step: 9
Training loss: 2.8907632330756785
Validation loss: 2.735931534745216

Epoch: 5| Step: 10
Training loss: 3.1574422265307396
Validation loss: 2.733649148422394

Epoch: 5| Step: 11
Training loss: 3.2298181840490896
Validation loss: 2.7327600087671287

Epoch: 66| Step: 0
Training loss: 2.748213014006597
Validation loss: 2.7319090777613306

Epoch: 5| Step: 1
Training loss: 2.547728319502756
Validation loss: 2.731036464191413

Epoch: 5| Step: 2
Training loss: 3.1836866119508738
Validation loss: 2.7301801275207853

Epoch: 5| Step: 3
Training loss: 2.66837237364281
Validation loss: 2.7287660418761326

Epoch: 5| Step: 4
Training loss: 2.724337218990314
Validation loss: 2.727340171984268

Epoch: 5| Step: 5
Training loss: 2.9713722293091895
Validation loss: 2.7259335343504323

Epoch: 5| Step: 6
Training loss: 2.9405336339460844
Validation loss: 2.7245231696817

Epoch: 5| Step: 7
Training loss: 2.7744830672461838
Validation loss: 2.724144469126292

Epoch: 5| Step: 8
Training loss: 2.8354039386479473
Validation loss: 2.723181740881247

Epoch: 5| Step: 9
Training loss: 3.126203686639187
Validation loss: 2.7213798497401096

Epoch: 5| Step: 10
Training loss: 2.8262841572104147
Validation loss: 2.7200547007244853

Epoch: 5| Step: 11
Training loss: 3.4303322709521513
Validation loss: 2.7199902573871504

Epoch: 67| Step: 0
Training loss: 3.0997687468873685
Validation loss: 2.718332181811795

Epoch: 5| Step: 1
Training loss: 2.768722868155676
Validation loss: 2.7182871106597633

Epoch: 5| Step: 2
Training loss: 2.925792495441089
Validation loss: 2.7306192453919964

Epoch: 5| Step: 3
Training loss: 2.715760615466691
Validation loss: 2.7313494846781095

Epoch: 5| Step: 4
Training loss: 2.815372864741577
Validation loss: 2.715090839658913

Epoch: 5| Step: 5
Training loss: 2.8120670409207986
Validation loss: 2.7119086117495637

Epoch: 5| Step: 6
Training loss: 2.9762198183338975
Validation loss: 2.7124303029448025

Epoch: 5| Step: 7
Training loss: 2.941529776726417
Validation loss: 2.7122931338533185

Epoch: 5| Step: 8
Training loss: 3.0558414864897294
Validation loss: 2.7119987308818994

Epoch: 5| Step: 9
Training loss: 2.3622199079195787
Validation loss: 2.7117150627132407

Epoch: 5| Step: 10
Training loss: 3.08448343907655
Validation loss: 2.7116387785814116

Epoch: 5| Step: 11
Training loss: 1.502918820902683
Validation loss: 2.7101282932968846

Epoch: 68| Step: 0
Training loss: 2.543099067501395
Validation loss: 2.71124908532842

Epoch: 5| Step: 1
Training loss: 3.1957510574937102
Validation loss: 2.706116973773188

Epoch: 5| Step: 2
Training loss: 2.610837971715361
Validation loss: 2.704294763792269

Epoch: 5| Step: 3
Training loss: 3.0074670370297993
Validation loss: 2.7023244013980046

Epoch: 5| Step: 4
Training loss: 3.2261353734200053
Validation loss: 2.7008244494918134

Epoch: 5| Step: 5
Training loss: 2.7646492136445837
Validation loss: 2.699798687299899

Epoch: 5| Step: 6
Training loss: 2.957186051099983
Validation loss: 2.6979610864132004

Epoch: 5| Step: 7
Training loss: 2.778936559786911
Validation loss: 2.6971480454200822

Epoch: 5| Step: 8
Training loss: 2.8027376075220904
Validation loss: 2.696211059724173

Epoch: 5| Step: 9
Training loss: 2.6034143403849814
Validation loss: 2.6960231931317953

Epoch: 5| Step: 10
Training loss: 2.698335583147694
Validation loss: 2.6951562439963874

Epoch: 5| Step: 11
Training loss: 2.7739290043685068
Validation loss: 2.6950848948625734

Epoch: 69| Step: 0
Training loss: 2.5338618613920505
Validation loss: 2.6920239238523824

Epoch: 5| Step: 1
Training loss: 2.903595563285182
Validation loss: 2.6908643017256106

Epoch: 5| Step: 2
Training loss: 2.8577057181838583
Validation loss: 2.6893996503726987

Epoch: 5| Step: 3
Training loss: 2.417365028061348
Validation loss: 2.688614610443385

Epoch: 5| Step: 4
Training loss: 3.2013428731403093
Validation loss: 2.687499061111168

Epoch: 5| Step: 5
Training loss: 3.053676584292698
Validation loss: 2.6862904946736563

Epoch: 5| Step: 6
Training loss: 3.138418912634067
Validation loss: 2.686014896185351

Epoch: 5| Step: 7
Training loss: 3.063410720871587
Validation loss: 2.684707765748063

Epoch: 5| Step: 8
Training loss: 2.226162951575871
Validation loss: 2.68455427471915

Epoch: 5| Step: 9
Training loss: 2.5155117412210477
Validation loss: 2.6837591965199

Epoch: 5| Step: 10
Training loss: 2.9776534036343607
Validation loss: 2.682054784493549

Epoch: 5| Step: 11
Training loss: 2.9343935184889736
Validation loss: 2.6804181058482404

Epoch: 70| Step: 0
Training loss: 2.906569268522553
Validation loss: 2.680398414850518

Epoch: 5| Step: 1
Training loss: 2.2024903161034097
Validation loss: 2.691413137485234

Epoch: 5| Step: 2
Training loss: 2.2840302130175623
Validation loss: 2.6962614775336577

Epoch: 5| Step: 3
Training loss: 2.749591276833019
Validation loss: 2.6961836913456927

Epoch: 5| Step: 4
Training loss: 2.826122185956374
Validation loss: 2.6952794943737457

Epoch: 5| Step: 5
Training loss: 3.037115027124966
Validation loss: 2.6965589654191775

Epoch: 5| Step: 6
Training loss: 3.060352117187948
Validation loss: 2.6933075787139864

Epoch: 5| Step: 7
Training loss: 3.0506999729090096
Validation loss: 2.6899121829296817

Epoch: 5| Step: 8
Training loss: 2.8520276670036866
Validation loss: 2.683916397355367

Epoch: 5| Step: 9
Training loss: 3.0531020476963198
Validation loss: 2.6789442798180523

Epoch: 5| Step: 10
Training loss: 2.802972380737151
Validation loss: 2.6705895839836282

Epoch: 5| Step: 11
Training loss: 3.479611275107392
Validation loss: 2.670525237795006

Epoch: 71| Step: 0
Training loss: 3.2035851124852313
Validation loss: 2.672817967307909

Epoch: 5| Step: 1
Training loss: 2.445814964663032
Validation loss: 2.674882527175462

Epoch: 5| Step: 2
Training loss: 2.625056402417907
Validation loss: 2.6740315975014273

Epoch: 5| Step: 3
Training loss: 2.6029627242231244
Validation loss: 2.676979353601027

Epoch: 5| Step: 4
Training loss: 2.801536553981307
Validation loss: 2.672577455175548

Epoch: 5| Step: 5
Training loss: 3.0061661611433457
Validation loss: 2.6653878801548627

Epoch: 5| Step: 6
Training loss: 2.767820704347739
Validation loss: 2.66327433705983

Epoch: 5| Step: 7
Training loss: 2.5246663128020135
Validation loss: 2.661040244636065

Epoch: 5| Step: 8
Training loss: 2.905654846287562
Validation loss: 2.667457226205019

Epoch: 5| Step: 9
Training loss: 2.430768425717541
Validation loss: 2.664101206031252

Epoch: 5| Step: 10
Training loss: 3.2688206272992453
Validation loss: 2.663699527150715

Epoch: 5| Step: 11
Training loss: 3.525615957566709
Validation loss: 2.657490470554543

Epoch: 72| Step: 0
Training loss: 2.9163323528697855
Validation loss: 2.6571394833530153

Epoch: 5| Step: 1
Training loss: 2.5689465449894406
Validation loss: 2.6572056453712913

Epoch: 5| Step: 2
Training loss: 3.1829876843548863
Validation loss: 2.65470451946764

Epoch: 5| Step: 3
Training loss: 2.701336130925293
Validation loss: 2.655586844296081

Epoch: 5| Step: 4
Training loss: 2.2418198765958746
Validation loss: 2.6551325934766816

Epoch: 5| Step: 5
Training loss: 2.68905115828929
Validation loss: 2.654095333065012

Epoch: 5| Step: 6
Training loss: 3.194648356540707
Validation loss: 2.6538754227548833

Epoch: 5| Step: 7
Training loss: 2.515152407023121
Validation loss: 2.652718927125642

Epoch: 5| Step: 8
Training loss: 3.3180570234534352
Validation loss: 2.6528684483811382

Epoch: 5| Step: 9
Training loss: 3.085702776130525
Validation loss: 2.652328929382177

Epoch: 5| Step: 10
Training loss: 2.1498475042865275
Validation loss: 2.651150382060524

Epoch: 5| Step: 11
Training loss: 2.181283892611417
Validation loss: 2.650938048270677

Epoch: 73| Step: 0
Training loss: 2.591956748142361
Validation loss: 2.6504144669849334

Epoch: 5| Step: 1
Training loss: 2.728249975883479
Validation loss: 2.649471178762039

Epoch: 5| Step: 2
Training loss: 2.6310949864337316
Validation loss: 2.647539896287693

Epoch: 5| Step: 3
Training loss: 2.85704270596042
Validation loss: 2.646808960025828

Epoch: 5| Step: 4
Training loss: 2.853193595203702
Validation loss: 2.645738984225466

Epoch: 5| Step: 5
Training loss: 2.894113281384445
Validation loss: 2.6445577179689095

Epoch: 5| Step: 6
Training loss: 2.9418758508872687
Validation loss: 2.64307240865371

Epoch: 5| Step: 7
Training loss: 2.6791651803383827
Validation loss: 2.642399667454948

Epoch: 5| Step: 8
Training loss: 2.4423181890565937
Validation loss: 2.641142886538859

Epoch: 5| Step: 9
Training loss: 2.8636840703494073
Validation loss: 2.64058746220921

Epoch: 5| Step: 10
Training loss: 3.0944116058372604
Validation loss: 2.639584560188263

Epoch: 5| Step: 11
Training loss: 2.71836201321901
Validation loss: 2.637619755649163

Epoch: 74| Step: 0
Training loss: 2.7299317799243212
Validation loss: 2.6366586259179985

Epoch: 5| Step: 1
Training loss: 3.2905715054097144
Validation loss: 2.634042081088091

Epoch: 5| Step: 2
Training loss: 2.9629971630277256
Validation loss: 2.6315937145450423

Epoch: 5| Step: 3
Training loss: 2.3326306874583183
Validation loss: 2.6316582991950392

Epoch: 5| Step: 4
Training loss: 2.6705970608075353
Validation loss: 2.63078688248122

Epoch: 5| Step: 5
Training loss: 2.1163919791257624
Validation loss: 2.631126603580394

Epoch: 5| Step: 6
Training loss: 3.2715413649420446
Validation loss: 2.633411339366995

Epoch: 5| Step: 7
Training loss: 2.8610798073777266
Validation loss: 2.629240512616901

Epoch: 5| Step: 8
Training loss: 2.5789884104059677
Validation loss: 2.6291109357772147

Epoch: 5| Step: 9
Training loss: 2.3916111327136
Validation loss: 2.6282045845987834

Epoch: 5| Step: 10
Training loss: 2.9549698491502765
Validation loss: 2.626273035743972

Epoch: 5| Step: 11
Training loss: 3.1907266479201954
Validation loss: 2.6265435789426395

Epoch: 75| Step: 0
Training loss: 2.737964998231893
Validation loss: 2.624707421391722

Epoch: 5| Step: 1
Training loss: 2.9227283883898285
Validation loss: 2.6241127172173635

Epoch: 5| Step: 2
Training loss: 2.470781576848586
Validation loss: 2.623219578810073

Epoch: 5| Step: 3
Training loss: 3.191266994169584
Validation loss: 2.625709017866989

Epoch: 5| Step: 4
Training loss: 2.8308399299257996
Validation loss: 2.621614596772749

Epoch: 5| Step: 5
Training loss: 2.8442001824835663
Validation loss: 2.6221688307114706

Epoch: 5| Step: 6
Training loss: 2.6801387306859055
Validation loss: 2.622308418360032

Epoch: 5| Step: 7
Training loss: 2.9813611855556506
Validation loss: 2.6241276934097812

Epoch: 5| Step: 8
Training loss: 2.550659176766459
Validation loss: 2.623677283774653

Epoch: 5| Step: 9
Training loss: 2.770205825843163
Validation loss: 2.6239231640825174

Epoch: 5| Step: 10
Training loss: 2.554931628960374
Validation loss: 2.6247018311715595

Epoch: 5| Step: 11
Training loss: 1.0905731932132061
Validation loss: 2.624520008162781

Epoch: 76| Step: 0
Training loss: 3.266939035725487
Validation loss: 2.622218440753784

Epoch: 5| Step: 1
Training loss: 2.790765493515161
Validation loss: 2.620848525316109

Epoch: 5| Step: 2
Training loss: 2.745964036376789
Validation loss: 2.6195841657142616

Epoch: 5| Step: 3
Training loss: 2.769099149367812
Validation loss: 2.620755707743999

Epoch: 5| Step: 4
Training loss: 2.7364839976404105
Validation loss: 2.617832624341299

Epoch: 5| Step: 5
Training loss: 2.7819587575952993
Validation loss: 2.616195547664497

Epoch: 5| Step: 6
Training loss: 2.60986981297417
Validation loss: 2.6166060831463183

Epoch: 5| Step: 7
Training loss: 2.896069816611891
Validation loss: 2.6164837512595436

Epoch: 5| Step: 8
Training loss: 3.1462706878673057
Validation loss: 2.6162651068744447

Epoch: 5| Step: 9
Training loss: 2.234603336644684
Validation loss: 2.6153619387081917

Epoch: 5| Step: 10
Training loss: 2.145127177169617
Validation loss: 2.6136917795367767

Epoch: 5| Step: 11
Training loss: 2.839324190028166
Validation loss: 2.6137566659089218

Epoch: 77| Step: 0
Training loss: 2.9836479220051
Validation loss: 2.6112064322755084

Epoch: 5| Step: 1
Training loss: 2.1482041110803576
Validation loss: 2.611577290545622

Epoch: 5| Step: 2
Training loss: 2.985625798810437
Validation loss: 2.6085469651004027

Epoch: 5| Step: 3
Training loss: 2.647132034161995
Validation loss: 2.609472588943289

Epoch: 5| Step: 4
Training loss: 2.4668756443715805
Validation loss: 2.6071939775975594

Epoch: 5| Step: 5
Training loss: 3.2917089982670795
Validation loss: 2.607155272609166

Epoch: 5| Step: 6
Training loss: 2.7510852406315407
Validation loss: 2.60454200455736

Epoch: 5| Step: 7
Training loss: 3.030658467572734
Validation loss: 2.6018479031255928

Epoch: 5| Step: 8
Training loss: 2.4297113448073815
Validation loss: 2.6038404540149935

Epoch: 5| Step: 9
Training loss: 2.6038546159067346
Validation loss: 2.602939042970745

Epoch: 5| Step: 10
Training loss: 2.6775601230855743
Validation loss: 2.60262758296509

Epoch: 5| Step: 11
Training loss: 2.7106577264394716
Validation loss: 2.6017678554923265

Epoch: 78| Step: 0
Training loss: 2.397414396187764
Validation loss: 2.602432727848159

Epoch: 5| Step: 1
Training loss: 2.803616630113447
Validation loss: 2.6021739176327032

Epoch: 5| Step: 2
Training loss: 2.6312501159812918
Validation loss: 2.6025662705249917

Epoch: 5| Step: 3
Training loss: 2.8056383141711385
Validation loss: 2.6018254029831613

Epoch: 5| Step: 4
Training loss: 3.114886436045534
Validation loss: 2.600074159041421

Epoch: 5| Step: 5
Training loss: 2.5422568547987994
Validation loss: 2.6002451489184493

Epoch: 5| Step: 6
Training loss: 2.3449673352274423
Validation loss: 2.597586257488768

Epoch: 5| Step: 7
Training loss: 2.591951689016796
Validation loss: 2.596790423739336

Epoch: 5| Step: 8
Training loss: 2.8689209066440124
Validation loss: 2.5962953678820653

Epoch: 5| Step: 9
Training loss: 2.9276537537369443
Validation loss: 2.5961259890236437

Epoch: 5| Step: 10
Training loss: 3.026025103437799
Validation loss: 2.594393118060882

Epoch: 5| Step: 11
Training loss: 2.4323348069432438
Validation loss: 2.592816993170331

Epoch: 79| Step: 0
Training loss: 2.574271171163424
Validation loss: 2.5955697152838924

Epoch: 5| Step: 1
Training loss: 2.76887881149423
Validation loss: 2.5945110545013246

Epoch: 5| Step: 2
Training loss: 3.012915466277405
Validation loss: 2.5950245081381853

Epoch: 5| Step: 3
Training loss: 2.3962891739343033
Validation loss: 2.59621387486555

Epoch: 5| Step: 4
Training loss: 2.6025318253006784
Validation loss: 2.597496911231546

Epoch: 5| Step: 5
Training loss: 2.779740341739256
Validation loss: 2.596450935226104

Epoch: 5| Step: 6
Training loss: 2.9493383926476975
Validation loss: 2.597802921447141

Epoch: 5| Step: 7
Training loss: 2.559219400336047
Validation loss: 2.5975895120179024

Epoch: 5| Step: 8
Training loss: 2.582107150394926
Validation loss: 2.5965854206359826

Epoch: 5| Step: 9
Training loss: 2.8269396241969833
Validation loss: 2.5959071224393506

Epoch: 5| Step: 10
Training loss: 2.900876892633643
Validation loss: 2.5939411874190714

Epoch: 5| Step: 11
Training loss: 2.9991258301268524
Validation loss: 2.590380701679845

Epoch: 80| Step: 0
Training loss: 2.3932996759554
Validation loss: 2.589914404364164

Epoch: 5| Step: 1
Training loss: 2.710944799583787
Validation loss: 2.5865764500818393

Epoch: 5| Step: 2
Training loss: 3.0932901984802785
Validation loss: 2.58527698129252

Epoch: 5| Step: 3
Training loss: 3.004823304121102
Validation loss: 2.5854486193489628

Epoch: 5| Step: 4
Training loss: 2.213097693105968
Validation loss: 2.587475295417289

Epoch: 5| Step: 5
Training loss: 3.1787016368911556
Validation loss: 2.5840928450673464

Epoch: 5| Step: 6
Training loss: 2.368869800608017
Validation loss: 2.585216475479134

Epoch: 5| Step: 7
Training loss: 2.699162660670176
Validation loss: 2.584168115966236

Epoch: 5| Step: 8
Training loss: 2.8381208101975446
Validation loss: 2.5892288720886856

Epoch: 5| Step: 9
Training loss: 2.6580488509144553
Validation loss: 2.5876561587660576

Epoch: 5| Step: 10
Training loss: 2.8038162110700093
Validation loss: 2.5863103837833274

Epoch: 5| Step: 11
Training loss: 1.8527057836113188
Validation loss: 2.5829744679366526

Epoch: 81| Step: 0
Training loss: 2.8757552108684274
Validation loss: 2.5850955057179053

Epoch: 5| Step: 1
Training loss: 2.7194421698258
Validation loss: 2.584172748245649

Epoch: 5| Step: 2
Training loss: 2.2398290691553235
Validation loss: 2.5867722269481344

Epoch: 5| Step: 3
Training loss: 2.71230112568513
Validation loss: 2.592063171458744

Epoch: 5| Step: 4
Training loss: 2.9435294747008425
Validation loss: 2.5850257303370343

Epoch: 5| Step: 5
Training loss: 3.079973933865119
Validation loss: 2.5853011202038196

Epoch: 5| Step: 6
Training loss: 2.6259538643147877
Validation loss: 2.5817119729942912

Epoch: 5| Step: 7
Training loss: 2.4744251546958145
Validation loss: 2.579983290056335

Epoch: 5| Step: 8
Training loss: 2.4773627591734626
Validation loss: 2.5784250373802675

Epoch: 5| Step: 9
Training loss: 2.8410751002965235
Validation loss: 2.579598654917834

Epoch: 5| Step: 10
Training loss: 2.8970825647683847
Validation loss: 2.5753742030992557

Epoch: 5| Step: 11
Training loss: 2.4172262552381087
Validation loss: 2.577329027238499

Epoch: 82| Step: 0
Training loss: 2.422826370913977
Validation loss: 2.581526602610263

Epoch: 5| Step: 1
Training loss: 2.97390812944481
Validation loss: 2.587895369615344

Epoch: 5| Step: 2
Training loss: 3.087119655888866
Validation loss: 2.582286643181998

Epoch: 5| Step: 3
Training loss: 2.4418445895556573
Validation loss: 2.5744572569012365

Epoch: 5| Step: 4
Training loss: 2.675451194288092
Validation loss: 2.571698229753235

Epoch: 5| Step: 5
Training loss: 2.6302370781161852
Validation loss: 2.572189476683816

Epoch: 5| Step: 6
Training loss: 2.2506252055974483
Validation loss: 2.5710597976178398

Epoch: 5| Step: 7
Training loss: 2.8217807656878153
Validation loss: 2.5712341117275277

Epoch: 5| Step: 8
Training loss: 2.8800339786856317
Validation loss: 2.56938956405408

Epoch: 5| Step: 9
Training loss: 2.8381745733935424
Validation loss: 2.5712284786564354

Epoch: 5| Step: 10
Training loss: 2.8025585371942965
Validation loss: 2.5695483377146937

Epoch: 5| Step: 11
Training loss: 2.2141895976498533
Validation loss: 2.5695021413791825

Epoch: 83| Step: 0
Training loss: 2.305520324233578
Validation loss: 2.56772151708926

Epoch: 5| Step: 1
Training loss: 3.405335189745145
Validation loss: 2.567735735042261

Epoch: 5| Step: 2
Training loss: 2.3821033860966705
Validation loss: 2.564889352133369

Epoch: 5| Step: 3
Training loss: 2.930948296415303
Validation loss: 2.5636231860659513

Epoch: 5| Step: 4
Training loss: 2.2788187945889375
Validation loss: 2.559392708238536

Epoch: 5| Step: 5
Training loss: 2.451031806256949
Validation loss: 2.5628713129423866

Epoch: 5| Step: 6
Training loss: 2.82762495646783
Validation loss: 2.559407822488145

Epoch: 5| Step: 7
Training loss: 2.526636982930465
Validation loss: 2.5599125693088807

Epoch: 5| Step: 8
Training loss: 2.6383615758865853
Validation loss: 2.561074825885121

Epoch: 5| Step: 9
Training loss: 2.9501751088041237
Validation loss: 2.5586069626018086

Epoch: 5| Step: 10
Training loss: 2.6641161960772606
Validation loss: 2.557214461259872

Epoch: 5| Step: 11
Training loss: 3.2135883907010605
Validation loss: 2.5578249487305

Epoch: 84| Step: 0
Training loss: 2.107923559341075
Validation loss: 2.5603194107837113

Epoch: 5| Step: 1
Training loss: 2.255350955626293
Validation loss: 2.5610240469353105

Epoch: 5| Step: 2
Training loss: 3.1824943282323312
Validation loss: 2.560898086278692

Epoch: 5| Step: 3
Training loss: 2.4599684972219094
Validation loss: 2.564770719797813

Epoch: 5| Step: 4
Training loss: 3.2302011289068235
Validation loss: 2.563937408197805

Epoch: 5| Step: 5
Training loss: 2.9308132602704573
Validation loss: 2.5637689991616974

Epoch: 5| Step: 6
Training loss: 2.8708881330496583
Validation loss: 2.560247881493842

Epoch: 5| Step: 7
Training loss: 2.6912720401780987
Validation loss: 2.559120861628173

Epoch: 5| Step: 8
Training loss: 2.462408879332121
Validation loss: 2.5588738596322953

Epoch: 5| Step: 9
Training loss: 2.6963392872676444
Validation loss: 2.5546671859757937

Epoch: 5| Step: 10
Training loss: 2.5555258025865335
Validation loss: 2.5532671784150778

Epoch: 5| Step: 11
Training loss: 2.6679069098570674
Validation loss: 2.5526191745750926

Epoch: 85| Step: 0
Training loss: 2.946774066964313
Validation loss: 2.554258713041187

Epoch: 5| Step: 1
Training loss: 2.7402780519839696
Validation loss: 2.550502635311063

Epoch: 5| Step: 2
Training loss: 2.794966232832837
Validation loss: 2.55166644888922

Epoch: 5| Step: 3
Training loss: 2.6644331598701303
Validation loss: 2.5665843443136604

Epoch: 5| Step: 4
Training loss: 3.0921665339363904
Validation loss: 2.5597351013409706

Epoch: 5| Step: 5
Training loss: 2.4364224521908247
Validation loss: 2.5498839782051124

Epoch: 5| Step: 6
Training loss: 2.576440064046802
Validation loss: 2.5497319203686524

Epoch: 5| Step: 7
Training loss: 2.3869606806980985
Validation loss: 2.5443597281527177

Epoch: 5| Step: 8
Training loss: 2.825054968240066
Validation loss: 2.543770499150739

Epoch: 5| Step: 9
Training loss: 2.3047812232664473
Validation loss: 2.5444897479728246

Epoch: 5| Step: 10
Training loss: 2.5462680397649358
Validation loss: 2.54893987612842

Epoch: 5| Step: 11
Training loss: 3.1859752523702722
Validation loss: 2.5494369851435943

Epoch: 86| Step: 0
Training loss: 2.9304815004783764
Validation loss: 2.5511628352826543

Epoch: 5| Step: 1
Training loss: 2.4718916013524277
Validation loss: 2.5522163213736744

Epoch: 5| Step: 2
Training loss: 2.5001712740402673
Validation loss: 2.5533264065151364

Epoch: 5| Step: 3
Training loss: 2.7736443240994126
Validation loss: 2.5512339845946204

Epoch: 5| Step: 4
Training loss: 3.110431740773887
Validation loss: 2.5503366072084472

Epoch: 5| Step: 5
Training loss: 2.7770413906157163
Validation loss: 2.548150774716465

Epoch: 5| Step: 6
Training loss: 2.7791518966381457
Validation loss: 2.546631897009503

Epoch: 5| Step: 7
Training loss: 2.4763716855833033
Validation loss: 2.543928735719294

Epoch: 5| Step: 8
Training loss: 2.7180595836718933
Validation loss: 2.5403719103049403

Epoch: 5| Step: 9
Training loss: 2.1897870778083597
Validation loss: 2.538981388459285

Epoch: 5| Step: 10
Training loss: 2.491302045937874
Validation loss: 2.5368329084246595

Epoch: 5| Step: 11
Training loss: 3.561868176565012
Validation loss: 2.536761915197786

Epoch: 87| Step: 0
Training loss: 3.0051781153137567
Validation loss: 2.5376601077839784

Epoch: 5| Step: 1
Training loss: 2.7638736502921137
Validation loss: 2.537318872226111

Epoch: 5| Step: 2
Training loss: 2.616865178088189
Validation loss: 2.535348490130401

Epoch: 5| Step: 3
Training loss: 2.6559452555254035
Validation loss: 2.536493717602159

Epoch: 5| Step: 4
Training loss: 2.7389863285978353
Validation loss: 2.536179953513903

Epoch: 5| Step: 5
Training loss: 2.5990815117541874
Validation loss: 2.534654846921703

Epoch: 5| Step: 6
Training loss: 2.280387192692546
Validation loss: 2.536046017471459

Epoch: 5| Step: 7
Training loss: 2.7777718215454668
Validation loss: 2.5340683419542915

Epoch: 5| Step: 8
Training loss: 2.5323177016716736
Validation loss: 2.5326761929551345

Epoch: 5| Step: 9
Training loss: 2.6574771514800326
Validation loss: 2.5341111484439365

Epoch: 5| Step: 10
Training loss: 2.9034209889940272
Validation loss: 2.5291906778828714

Epoch: 5| Step: 11
Training loss: 1.232991952732182
Validation loss: 2.532673815994367

Epoch: 88| Step: 0
Training loss: 2.5660147404592974
Validation loss: 2.531100162733705

Epoch: 5| Step: 1
Training loss: 2.9761086265571475
Validation loss: 2.5308092071024673

Epoch: 5| Step: 2
Training loss: 2.4598256339328257
Validation loss: 2.5302427469873314

Epoch: 5| Step: 3
Training loss: 2.096521507518594
Validation loss: 2.5310260630477335

Epoch: 5| Step: 4
Training loss: 2.651632716474858
Validation loss: 2.529817823572045

Epoch: 5| Step: 5
Training loss: 2.3384023057042076
Validation loss: 2.529530156790958

Epoch: 5| Step: 6
Training loss: 2.5760985762411575
Validation loss: 2.528351878959653

Epoch: 5| Step: 7
Training loss: 2.4703917054538627
Validation loss: 2.5313845586921673

Epoch: 5| Step: 8
Training loss: 3.177011024194213
Validation loss: 2.5297542870297325

Epoch: 5| Step: 9
Training loss: 2.7568941397338733
Validation loss: 2.5279480625850246

Epoch: 5| Step: 10
Training loss: 3.0894645525751954
Validation loss: 2.527933247527931

Epoch: 5| Step: 11
Training loss: 2.4220410689975695
Validation loss: 2.5290431343360646

Epoch: 89| Step: 0
Training loss: 2.760692788954938
Validation loss: 2.5272678637031567

Epoch: 5| Step: 1
Training loss: 2.5881689303478286
Validation loss: 2.5280700496867765

Epoch: 5| Step: 2
Training loss: 2.092938166128261
Validation loss: 2.5294322877276145

Epoch: 5| Step: 3
Training loss: 2.4858164893907597
Validation loss: 2.531080781908252

Epoch: 5| Step: 4
Training loss: 2.44479783952278
Validation loss: 2.531394342145243

Epoch: 5| Step: 5
Training loss: 3.1203173840312144
Validation loss: 2.532196523358502

Epoch: 5| Step: 6
Training loss: 2.7534945565774787
Validation loss: 2.535995415045628

Epoch: 5| Step: 7
Training loss: 2.9126210265329164
Validation loss: 2.53681999359306

Epoch: 5| Step: 8
Training loss: 2.812400561800084
Validation loss: 2.5310735719521213

Epoch: 5| Step: 9
Training loss: 2.56481326756416
Validation loss: 2.5307976864111073

Epoch: 5| Step: 10
Training loss: 2.5965835536278163
Validation loss: 2.5270532070564524

Epoch: 5| Step: 11
Training loss: 2.85240733551978
Validation loss: 2.5276391998028487

Epoch: 90| Step: 0
Training loss: 2.4184684175515576
Validation loss: 2.5237755209514288

Epoch: 5| Step: 1
Training loss: 3.1080856333636127
Validation loss: 2.524504747858618

Epoch: 5| Step: 2
Training loss: 2.214177753084295
Validation loss: 2.5203213184862236

Epoch: 5| Step: 3
Training loss: 2.630400869039174
Validation loss: 2.523611426879755

Epoch: 5| Step: 4
Training loss: 3.2332664469718946
Validation loss: 2.5263825897663486

Epoch: 5| Step: 5
Training loss: 2.8402104409921978
Validation loss: 2.5263738131992284

Epoch: 5| Step: 6
Training loss: 2.5343092339539868
Validation loss: 2.521620794260579

Epoch: 5| Step: 7
Training loss: 2.415547923132848
Validation loss: 2.5250577773669436

Epoch: 5| Step: 8
Training loss: 2.747002354990613
Validation loss: 2.5266960371402294

Epoch: 5| Step: 9
Training loss: 2.537088888906418
Validation loss: 2.525696738115645

Epoch: 5| Step: 10
Training loss: 2.4257307308422025
Validation loss: 2.5252564825595325

Epoch: 5| Step: 11
Training loss: 2.6601068657367684
Validation loss: 2.523310651238398

Epoch: 91| Step: 0
Training loss: 2.6164875062323105
Validation loss: 2.5258119983416005

Epoch: 5| Step: 1
Training loss: 2.6333543350090465
Validation loss: 2.5238566449113673

Epoch: 5| Step: 2
Training loss: 2.2192488633376692
Validation loss: 2.524125834968386

Epoch: 5| Step: 3
Training loss: 2.920049903129667
Validation loss: 2.52130454298984

Epoch: 5| Step: 4
Training loss: 2.8103375916965883
Validation loss: 2.520130923959869

Epoch: 5| Step: 5
Training loss: 2.5124482182722714
Validation loss: 2.519757290737473

Epoch: 5| Step: 6
Training loss: 2.7236734293538327
Validation loss: 2.51711248960523

Epoch: 5| Step: 7
Training loss: 2.5545626268577903
Validation loss: 2.5192739902424246

Epoch: 5| Step: 8
Training loss: 2.4952313719897727
Validation loss: 2.517201330587766

Epoch: 5| Step: 9
Training loss: 2.8540466357606493
Validation loss: 2.5150110075958105

Epoch: 5| Step: 10
Training loss: 2.8747540244321375
Validation loss: 2.5158757465886

Epoch: 5| Step: 11
Training loss: 1.7427418600879219
Validation loss: 2.5152667799503896

Epoch: 92| Step: 0
Training loss: 2.671690281957757
Validation loss: 2.515364512981874

Epoch: 5| Step: 1
Training loss: 2.2075353536226543
Validation loss: 2.513025540098747

Epoch: 5| Step: 2
Training loss: 2.4725554869069652
Validation loss: 2.5146293960393553

Epoch: 5| Step: 3
Training loss: 2.9204749358645734
Validation loss: 2.509540715016955

Epoch: 5| Step: 4
Training loss: 2.5011630214073937
Validation loss: 2.514119868851851

Epoch: 5| Step: 5
Training loss: 2.865175960389969
Validation loss: 2.511373580226149

Epoch: 5| Step: 6
Training loss: 2.785056092332606
Validation loss: 2.515971315922897

Epoch: 5| Step: 7
Training loss: 2.4645007298337474
Validation loss: 2.517430879495718

Epoch: 5| Step: 8
Training loss: 2.376335872601523
Validation loss: 2.5172404360439056

Epoch: 5| Step: 9
Training loss: 2.948585371505156
Validation loss: 2.5211520026425607

Epoch: 5| Step: 10
Training loss: 2.5110359747044178
Validation loss: 2.527309175753054

Epoch: 5| Step: 11
Training loss: 3.8926641183896966
Validation loss: 2.539158914153789

Epoch: 93| Step: 0
Training loss: 2.700477406009432
Validation loss: 2.5413292415915523

Epoch: 5| Step: 1
Training loss: 2.733770597961997
Validation loss: 2.5280351788660016

Epoch: 5| Step: 2
Training loss: 2.4401528032328224
Validation loss: 2.5258304206112294

Epoch: 5| Step: 3
Training loss: 2.57235414067401
Validation loss: 2.526049566092708

Epoch: 5| Step: 4
Training loss: 2.248955802215193
Validation loss: 2.521644770383685

Epoch: 5| Step: 5
Training loss: 2.8055328540282214
Validation loss: 2.519977275787559

Epoch: 5| Step: 6
Training loss: 2.5980419819048324
Validation loss: 2.5175229883580736

Epoch: 5| Step: 7
Training loss: 3.1278719103214456
Validation loss: 2.518293552831354

Epoch: 5| Step: 8
Training loss: 2.177848778700432
Validation loss: 2.5155493525470525

Epoch: 5| Step: 9
Training loss: 2.8856721253127717
Validation loss: 2.515522370308286

Epoch: 5| Step: 10
Training loss: 2.7874103001415937
Validation loss: 2.5134475912254923

Epoch: 5| Step: 11
Training loss: 2.5554790612073672
Validation loss: 2.5137426726501446

Epoch: 94| Step: 0
Training loss: 2.574006646409305
Validation loss: 2.512520606239551

Epoch: 5| Step: 1
Training loss: 2.8532467401442942
Validation loss: 2.511167106741383

Epoch: 5| Step: 2
Training loss: 2.4889468945071442
Validation loss: 2.512938690160724

Epoch: 5| Step: 3
Training loss: 2.708781327584448
Validation loss: 2.5193655900930096

Epoch: 5| Step: 4
Training loss: 2.3627039180528575
Validation loss: 2.515974942542593

Epoch: 5| Step: 5
Training loss: 2.722639962233831
Validation loss: 2.5130361480773313

Epoch: 5| Step: 6
Training loss: 2.3976960169880526
Validation loss: 2.5145082621099535

Epoch: 5| Step: 7
Training loss: 2.733151407312703
Validation loss: 2.5137153074379848

Epoch: 5| Step: 8
Training loss: 3.233860288198367
Validation loss: 2.51492075214134

Epoch: 5| Step: 9
Training loss: 2.6670749669618457
Validation loss: 2.5180593207807447

Epoch: 5| Step: 10
Training loss: 2.169981426036468
Validation loss: 2.509281532317258

Epoch: 5| Step: 11
Training loss: 2.742788743403761
Validation loss: 2.5135904994025178

Epoch: 95| Step: 0
Training loss: 2.7621165289912306
Validation loss: 2.512678327921852

Epoch: 5| Step: 1
Training loss: 2.6965638724949246
Validation loss: 2.506628154945357

Epoch: 5| Step: 2
Training loss: 2.817744642060186
Validation loss: 2.506634571253801

Epoch: 5| Step: 3
Training loss: 2.161923229057832
Validation loss: 2.5046604149476996

Epoch: 5| Step: 4
Training loss: 2.779198221907324
Validation loss: 2.5017354901822095

Epoch: 5| Step: 5
Training loss: 2.727639846223615
Validation loss: 2.5061787901962247

Epoch: 5| Step: 6
Training loss: 2.9280473924772417
Validation loss: 2.5028064036087687

Epoch: 5| Step: 7
Training loss: 2.1072976515027033
Validation loss: 2.50349942699741

Epoch: 5| Step: 8
Training loss: 2.931152628438371
Validation loss: 2.5016437411692682

Epoch: 5| Step: 9
Training loss: 2.4335708249697694
Validation loss: 2.5056826974453994

Epoch: 5| Step: 10
Training loss: 2.4687437226420883
Validation loss: 2.5066312778943227

Epoch: 5| Step: 11
Training loss: 2.841465294229466
Validation loss: 2.5076970581864355

Epoch: 96| Step: 0
Training loss: 2.878210514218888
Validation loss: 2.508416349731258

Epoch: 5| Step: 1
Training loss: 2.944394401109034
Validation loss: 2.5147915006267825

Epoch: 5| Step: 2
Training loss: 2.806240066476755
Validation loss: 2.5147731495767705

Epoch: 5| Step: 3
Training loss: 2.476637204364219
Validation loss: 2.517712325373241

Epoch: 5| Step: 4
Training loss: 3.2386010613715293
Validation loss: 2.516653952240142

Epoch: 5| Step: 5
Training loss: 2.259067806818654
Validation loss: 2.5162361382021925

Epoch: 5| Step: 6
Training loss: 2.284517534769366
Validation loss: 2.5149215678302066

Epoch: 5| Step: 7
Training loss: 2.4008578039067783
Validation loss: 2.5140118570326333

Epoch: 5| Step: 8
Training loss: 2.448674045570667
Validation loss: 2.5091449727130226

Epoch: 5| Step: 9
Training loss: 2.6948696491374653
Validation loss: 2.5104946517439117

Epoch: 5| Step: 10
Training loss: 2.474015330946348
Validation loss: 2.5069169399329505

Epoch: 5| Step: 11
Training loss: 2.744212736763806
Validation loss: 2.5047529934264507

Epoch: 97| Step: 0
Training loss: 2.8187239550552383
Validation loss: 2.506243875706928

Epoch: 5| Step: 1
Training loss: 2.346802516584931
Validation loss: 2.5068292126071885

Epoch: 5| Step: 2
Training loss: 2.8881711699991666
Validation loss: 2.5075764767821163

Epoch: 5| Step: 3
Training loss: 2.2461142364894524
Validation loss: 2.5099724987380103

Epoch: 5| Step: 4
Training loss: 2.9710096894539237
Validation loss: 2.510619560263029

Epoch: 5| Step: 5
Training loss: 2.952067513828431
Validation loss: 2.5051152707035613

Epoch: 5| Step: 6
Training loss: 2.515014858770748
Validation loss: 2.505733582968432

Epoch: 5| Step: 7
Training loss: 2.3284487915174856
Validation loss: 2.501228936453171

Epoch: 5| Step: 8
Training loss: 2.284742008060428
Validation loss: 2.4994399436824333

Epoch: 5| Step: 9
Training loss: 2.7093126336017845
Validation loss: 2.4977996162964566

Epoch: 5| Step: 10
Training loss: 2.72104083482635
Validation loss: 2.4993517035094706

Epoch: 5| Step: 11
Training loss: 2.898578979658543
Validation loss: 2.4992883424330157

Epoch: 98| Step: 0
Training loss: 2.7628661797638183
Validation loss: 2.498711265752272

Epoch: 5| Step: 1
Training loss: 2.3532978131186466
Validation loss: 2.501383315274373

Epoch: 5| Step: 2
Training loss: 2.8291202711777848
Validation loss: 2.500847382779832

Epoch: 5| Step: 3
Training loss: 2.598992438592659
Validation loss: 2.5017387343943036

Epoch: 5| Step: 4
Training loss: 2.9332725460805453
Validation loss: 2.4993987512791476

Epoch: 5| Step: 5
Training loss: 2.67463532573534
Validation loss: 2.4995254185355718

Epoch: 5| Step: 6
Training loss: 2.859181215150473
Validation loss: 2.4990335662783614

Epoch: 5| Step: 7
Training loss: 3.05266002288693
Validation loss: 2.4968939997300668

Epoch: 5| Step: 8
Training loss: 2.133037625123587
Validation loss: 2.5000067432630515

Epoch: 5| Step: 9
Training loss: 2.608536271395706
Validation loss: 2.4962522628511588

Epoch: 5| Step: 10
Training loss: 1.9515519788594373
Validation loss: 2.497656745262284

Epoch: 5| Step: 11
Training loss: 1.9239879251327225
Validation loss: 2.4949197450916105

Epoch: 99| Step: 0
Training loss: 2.5439703356194943
Validation loss: 2.4967595397964573

Epoch: 5| Step: 1
Training loss: 2.918360263853432
Validation loss: 2.4940258448792973

Epoch: 5| Step: 2
Training loss: 2.4810618254751
Validation loss: 2.4952675293222395

Epoch: 5| Step: 3
Training loss: 2.5291485952855584
Validation loss: 2.4935270115738315

Epoch: 5| Step: 4
Training loss: 2.529088074302543
Validation loss: 2.4927573713449247

Epoch: 5| Step: 5
Training loss: 2.414937573686377
Validation loss: 2.4928804747564035

Epoch: 5| Step: 6
Training loss: 2.5723006608875334
Validation loss: 2.4943332065046295

Epoch: 5| Step: 7
Training loss: 2.7902725116719496
Validation loss: 2.4933554604151134

Epoch: 5| Step: 8
Training loss: 2.821464916015854
Validation loss: 2.490950122769843

Epoch: 5| Step: 9
Training loss: 2.7327983561390257
Validation loss: 2.49091863668211

Epoch: 5| Step: 10
Training loss: 2.3545185152509776
Validation loss: 2.4938486396829536

Epoch: 5| Step: 11
Training loss: 2.945000346107657
Validation loss: 2.4944040930509073

Epoch: 100| Step: 0
Training loss: 2.458799856715076
Validation loss: 2.4930470617592957

Epoch: 5| Step: 1
Training loss: 2.505489711596472
Validation loss: 2.4925472374581408

Epoch: 5| Step: 2
Training loss: 2.8066369722325306
Validation loss: 2.494496908806696

Epoch: 5| Step: 3
Training loss: 3.2513599484811584
Validation loss: 2.494983957693934

Epoch: 5| Step: 4
Training loss: 2.490354527585417
Validation loss: 2.4925632392866452

Epoch: 5| Step: 5
Training loss: 2.319009537065708
Validation loss: 2.4952549726510993

Epoch: 5| Step: 6
Training loss: 2.1789563774724767
Validation loss: 2.491752889559613

Epoch: 5| Step: 7
Training loss: 2.6295405581984648
Validation loss: 2.488146426442312

Epoch: 5| Step: 8
Training loss: 2.6308784059375707
Validation loss: 2.489950170318392

Epoch: 5| Step: 9
Training loss: 2.44079758037596
Validation loss: 2.4889671861399534

Epoch: 5| Step: 10
Training loss: 2.9698187259621895
Validation loss: 2.4918237498428257

Epoch: 5| Step: 11
Training loss: 2.0548216337218013
Validation loss: 2.490695279420951

Epoch: 101| Step: 0
Training loss: 2.120099644388497
Validation loss: 2.4829789923894214

Epoch: 5| Step: 1
Training loss: 2.760394047098633
Validation loss: 2.490628168222924

Epoch: 5| Step: 2
Training loss: 2.355012915994979
Validation loss: 2.4868503650379217

Epoch: 5| Step: 3
Training loss: 2.5182132082686297
Validation loss: 2.480537097219567

Epoch: 5| Step: 4
Training loss: 2.630686821549873
Validation loss: 2.490802248363788

Epoch: 5| Step: 5
Training loss: 2.58239817356721
Validation loss: 2.4877690816673996

Epoch: 5| Step: 6
Training loss: 2.8038980121975148
Validation loss: 2.4899065786796735

Epoch: 5| Step: 7
Training loss: 2.9695778746483605
Validation loss: 2.49257512999355

Epoch: 5| Step: 8
Training loss: 2.443617065404317
Validation loss: 2.4926739858632683

Epoch: 5| Step: 9
Training loss: 2.7860507464966324
Validation loss: 2.491068569907016

Epoch: 5| Step: 10
Training loss: 2.6436319780271615
Validation loss: 2.489895690625169

Epoch: 5| Step: 11
Training loss: 2.414862639033361
Validation loss: 2.4911879126325758

Epoch: 102| Step: 0
Training loss: 3.0890618455005314
Validation loss: 2.4898833263018036

Epoch: 5| Step: 1
Training loss: 2.6152105807531734
Validation loss: 2.488738273038623

Epoch: 5| Step: 2
Training loss: 2.6981386267676037
Validation loss: 2.489350313323947

Epoch: 5| Step: 3
Training loss: 2.202429046007556
Validation loss: 2.492289039831306

Epoch: 5| Step: 4
Training loss: 2.7284756045181497
Validation loss: 2.4870273698592475

Epoch: 5| Step: 5
Training loss: 2.7960199508882946
Validation loss: 2.488633802062137

Epoch: 5| Step: 6
Training loss: 2.4172232962425513
Validation loss: 2.4872786150233432

Epoch: 5| Step: 7
Training loss: 2.6779649720069876
Validation loss: 2.487906966313217

Epoch: 5| Step: 8
Training loss: 2.123849445100594
Validation loss: 2.4874972950458996

Epoch: 5| Step: 9
Training loss: 2.6141041371004547
Validation loss: 2.4862584346284864

Epoch: 5| Step: 10
Training loss: 2.609694227233482
Validation loss: 2.4817744385465286

Epoch: 5| Step: 11
Training loss: 2.064469755136424
Validation loss: 2.4838898702913546

Epoch: 103| Step: 0
Training loss: 2.4122356922264196
Validation loss: 2.4801357616481203

Epoch: 5| Step: 1
Training loss: 2.9234148343714823
Validation loss: 2.482216287018797

Epoch: 5| Step: 2
Training loss: 2.783742238082308
Validation loss: 2.480165738398626

Epoch: 5| Step: 3
Training loss: 2.4678549773826033
Validation loss: 2.480533090392757

Epoch: 5| Step: 4
Training loss: 2.0518190500960745
Validation loss: 2.4807178762690096

Epoch: 5| Step: 5
Training loss: 3.262012875024587
Validation loss: 2.480213174143658

Epoch: 5| Step: 6
Training loss: 2.3325096674777046
Validation loss: 2.484966807383595

Epoch: 5| Step: 7
Training loss: 2.370515001733506
Validation loss: 2.481232104649298

Epoch: 5| Step: 8
Training loss: 2.565143988956961
Validation loss: 2.481365968731058

Epoch: 5| Step: 9
Training loss: 2.673749478105135
Validation loss: 2.4853305218698427

Epoch: 5| Step: 10
Training loss: 2.6217946055002432
Validation loss: 2.484041711455761

Epoch: 5| Step: 11
Training loss: 2.4802715072906696
Validation loss: 2.485863553555218

Epoch: 104| Step: 0
Training loss: 2.6317860218190865
Validation loss: 2.487381832951862

Epoch: 5| Step: 1
Training loss: 2.3522881183614963
Validation loss: 2.486852326412401

Epoch: 5| Step: 2
Training loss: 2.5116848624451444
Validation loss: 2.4863080855223996

Epoch: 5| Step: 3
Training loss: 2.1800800366539392
Validation loss: 2.484549038467108

Epoch: 5| Step: 4
Training loss: 2.625745849007539
Validation loss: 2.48353739679831

Epoch: 5| Step: 5
Training loss: 2.957617838842545
Validation loss: 2.4839609708811734

Epoch: 5| Step: 6
Training loss: 2.8881951094048746
Validation loss: 2.4852355450304886

Epoch: 5| Step: 7
Training loss: 2.2138445717994606
Validation loss: 2.483462707991937

Epoch: 5| Step: 8
Training loss: 2.652378447225646
Validation loss: 2.483060349004367

Epoch: 5| Step: 9
Training loss: 2.5529712196458156
Validation loss: 2.4869750350731423

Epoch: 5| Step: 10
Training loss: 2.987590236178905
Validation loss: 2.4832126569442465

Epoch: 5| Step: 11
Training loss: 2.1913273707046526
Validation loss: 2.4819615715411705

Epoch: 105| Step: 0
Training loss: 2.4379109745310164
Validation loss: 2.4836986068824993

Epoch: 5| Step: 1
Training loss: 2.867795126243923
Validation loss: 2.4830011531792846

Epoch: 5| Step: 2
Training loss: 3.18299832070822
Validation loss: 2.482990802966786

Epoch: 5| Step: 3
Training loss: 2.592821529538681
Validation loss: 2.4811725088681813

Epoch: 5| Step: 4
Training loss: 2.705901555629799
Validation loss: 2.4795961702510554

Epoch: 5| Step: 5
Training loss: 2.529960869196262
Validation loss: 2.4857842628920648

Epoch: 5| Step: 6
Training loss: 2.474754949441244
Validation loss: 2.484971028932365

Epoch: 5| Step: 7
Training loss: 2.1823068282906406
Validation loss: 2.4834568118326206

Epoch: 5| Step: 8
Training loss: 2.608583981431994
Validation loss: 2.477490232289932

Epoch: 5| Step: 9
Training loss: 2.241543773794669
Validation loss: 2.4817449655749164

Epoch: 5| Step: 10
Training loss: 2.2221041833469353
Validation loss: 2.47823446175563

Epoch: 5| Step: 11
Training loss: 4.009407900811277
Validation loss: 2.4839508766250735

Epoch: 106| Step: 0
Training loss: 2.6596101040583244
Validation loss: 2.4791734291967487

Epoch: 5| Step: 1
Training loss: 2.852037698525999
Validation loss: 2.4827848579751737

Epoch: 5| Step: 2
Training loss: 2.457946800835715
Validation loss: 2.4795582299128127

Epoch: 5| Step: 3
Training loss: 2.3134207052538174
Validation loss: 2.480014497108285

Epoch: 5| Step: 4
Training loss: 2.92967610674868
Validation loss: 2.4821378323784127

Epoch: 5| Step: 5
Training loss: 2.29106318301688
Validation loss: 2.480354975296272

Epoch: 5| Step: 6
Training loss: 2.7046012595810933
Validation loss: 2.4769446983609162

Epoch: 5| Step: 7
Training loss: 2.8677276185746683
Validation loss: 2.4786183822168737

Epoch: 5| Step: 8
Training loss: 2.2485550373204957
Validation loss: 2.4859067205653145

Epoch: 5| Step: 9
Training loss: 2.2093053394002915
Validation loss: 2.4785607676782595

Epoch: 5| Step: 10
Training loss: 2.759474817978437
Validation loss: 2.4756581894703453

Epoch: 5| Step: 11
Training loss: 2.9173728814498405
Validation loss: 2.4781746736272665

Epoch: 107| Step: 0
Training loss: 3.154180924968332
Validation loss: 2.4805233446255697

Epoch: 5| Step: 1
Training loss: 2.7078215090980935
Validation loss: 2.482688003149072

Epoch: 5| Step: 2
Training loss: 3.089791433708884
Validation loss: 2.484006536498584

Epoch: 5| Step: 3
Training loss: 2.1195454997375647
Validation loss: 2.4834512516695586

Epoch: 5| Step: 4
Training loss: 2.9711528490334076
Validation loss: 2.4852489957399064

Epoch: 5| Step: 5
Training loss: 2.5116672065631342
Validation loss: 2.4863963111543437

Epoch: 5| Step: 6
Training loss: 2.2289215975185224
Validation loss: 2.4847626293723835

Epoch: 5| Step: 7
Training loss: 2.34094752291101
Validation loss: 2.483962046692895

Epoch: 5| Step: 8
Training loss: 2.6400499789969056
Validation loss: 2.4803097371073215

Epoch: 5| Step: 9
Training loss: 2.130766617445759
Validation loss: 2.4815602141461333

Epoch: 5| Step: 10
Training loss: 2.4843581097106666
Validation loss: 2.4776970704319665

Epoch: 5| Step: 11
Training loss: 1.9842317784806345
Validation loss: 2.4784729385006785

Epoch: 108| Step: 0
Training loss: 2.347010163378236
Validation loss: 2.468726339106107

Epoch: 5| Step: 1
Training loss: 2.580018798700496
Validation loss: 2.4766408464652616

Epoch: 5| Step: 2
Training loss: 2.5395021967539457
Validation loss: 2.4729034195834116

Epoch: 5| Step: 3
Training loss: 2.6334207890470256
Validation loss: 2.4789434353852324

Epoch: 5| Step: 4
Training loss: 2.430468761771486
Validation loss: 2.4784792834043246

Epoch: 5| Step: 5
Training loss: 1.9768970191349184
Validation loss: 2.4759033039823723

Epoch: 5| Step: 6
Training loss: 2.922863471774518
Validation loss: 2.476855243665354

Epoch: 5| Step: 7
Training loss: 2.537082874609002
Validation loss: 2.4728833697379744

Epoch: 5| Step: 8
Training loss: 2.9330694997508417
Validation loss: 2.4698944939732557

Epoch: 5| Step: 9
Training loss: 3.0804765887430383
Validation loss: 2.472322984908906

Epoch: 5| Step: 10
Training loss: 2.349233798659763
Validation loss: 2.4735688207406

Epoch: 5| Step: 11
Training loss: 2.4216637303893984
Validation loss: 2.4708755493310117

Epoch: 109| Step: 0
Training loss: 2.4573941349421835
Validation loss: 2.470572016558251

Epoch: 5| Step: 1
Training loss: 2.024454340002723
Validation loss: 2.469660764003494

Epoch: 5| Step: 2
Training loss: 2.820588835389947
Validation loss: 2.4795215109650837

Epoch: 5| Step: 3
Training loss: 2.8677204686545603
Validation loss: 2.4807543132136702

Epoch: 5| Step: 4
Training loss: 2.9394433918028224
Validation loss: 2.47517954483374

Epoch: 5| Step: 5
Training loss: 2.6379869816005526
Validation loss: 2.4765237149351385

Epoch: 5| Step: 6
Training loss: 1.9109151693865625
Validation loss: 2.4681934743440257

Epoch: 5| Step: 7
Training loss: 2.677691369577388
Validation loss: 2.4743955660822317

Epoch: 5| Step: 8
Training loss: 2.502987221344209
Validation loss: 2.4752884685459247

Epoch: 5| Step: 9
Training loss: 2.4766071688597804
Validation loss: 2.478732869853253

Epoch: 5| Step: 10
Training loss: 3.2889414422959935
Validation loss: 2.4786541125779227

Epoch: 5| Step: 11
Training loss: 1.8950206006623818
Validation loss: 2.477766761044909

Epoch: 110| Step: 0
Training loss: 2.77377334495509
Validation loss: 2.485713254419957

Epoch: 5| Step: 1
Training loss: 3.0902357081908387
Validation loss: 2.4816936522281146

Epoch: 5| Step: 2
Training loss: 2.4204919619238643
Validation loss: 2.4783552281730077

Epoch: 5| Step: 3
Training loss: 2.2135777967907675
Validation loss: 2.4814017035665636

Epoch: 5| Step: 4
Training loss: 2.507938179836057
Validation loss: 2.4807508533487463

Epoch: 5| Step: 5
Training loss: 2.79883655831663
Validation loss: 2.4808441238523167

Epoch: 5| Step: 6
Training loss: 2.723684721431883
Validation loss: 2.481406235440368

Epoch: 5| Step: 7
Training loss: 2.8778246396674776
Validation loss: 2.4787886208446186

Epoch: 5| Step: 8
Training loss: 1.8829486212059314
Validation loss: 2.4789711243317387

Epoch: 5| Step: 9
Training loss: 2.425553020853227
Validation loss: 2.4808235935903724

Epoch: 5| Step: 10
Training loss: 2.67713909363224
Validation loss: 2.474862904396147

Epoch: 5| Step: 11
Training loss: 1.9326427240212192
Validation loss: 2.4743944620226386

Epoch: 111| Step: 0
Training loss: 2.2104664223188775
Validation loss: 2.4685664973889603

Epoch: 5| Step: 1
Training loss: 2.0260312456845253
Validation loss: 2.4761962379115183

Epoch: 5| Step: 2
Training loss: 2.9657524636213446
Validation loss: 2.4803468729349483

Epoch: 5| Step: 3
Training loss: 2.7827578968172175
Validation loss: 2.476960933335903

Epoch: 5| Step: 4
Training loss: 2.8315244023819006
Validation loss: 2.480936337751148

Epoch: 5| Step: 5
Training loss: 2.3273103043789956
Validation loss: 2.469722330982972

Epoch: 5| Step: 6
Training loss: 2.7849058490775445
Validation loss: 2.4770973602734077

Epoch: 5| Step: 7
Training loss: 2.2691935880616483
Validation loss: 2.4761010029805455

Epoch: 5| Step: 8
Training loss: 2.4321122903185426
Validation loss: 2.4675717821795047

Epoch: 5| Step: 9
Training loss: 2.6317444397940157
Validation loss: 2.4711777061650966

Epoch: 5| Step: 10
Training loss: 3.106560281342728
Validation loss: 2.469713461667579

Epoch: 5| Step: 11
Training loss: 2.098814916010047
Validation loss: 2.475986036564541

Epoch: 112| Step: 0
Training loss: 2.0226648689283824
Validation loss: 2.479347115582553

Epoch: 5| Step: 1
Training loss: 2.4903740578165077
Validation loss: 2.4803604783184796

Epoch: 5| Step: 2
Training loss: 3.0236295890408984
Validation loss: 2.4871319402668903

Epoch: 5| Step: 3
Training loss: 2.271341412835082
Validation loss: 2.49995022167875

Epoch: 5| Step: 4
Training loss: 2.9372996809814205
Validation loss: 2.520332134223165

Epoch: 5| Step: 5
Training loss: 2.4256606509688132
Validation loss: 2.528828463390695

Epoch: 5| Step: 6
Training loss: 2.7396203873791274
Validation loss: 2.516269917087907

Epoch: 5| Step: 7
Training loss: 2.490147248782223
Validation loss: 2.515634260298782

Epoch: 5| Step: 8
Training loss: 2.9846252016969386
Validation loss: 2.528557868524886

Epoch: 5| Step: 9
Training loss: 2.8921547630761366
Validation loss: 2.5108300867153597

Epoch: 5| Step: 10
Training loss: 2.642447029239687
Validation loss: 2.5121352709131113

Epoch: 5| Step: 11
Training loss: 1.4237129154349102
Validation loss: 2.505336977589413

Epoch: 113| Step: 0
Training loss: 2.7390529181948775
Validation loss: 2.4964708909946074

Epoch: 5| Step: 1
Training loss: 2.395174571705134
Validation loss: 2.4839055839448574

Epoch: 5| Step: 2
Training loss: 2.2460220988911206
Validation loss: 2.480864641931487

Epoch: 5| Step: 3
Training loss: 2.390267837871203
Validation loss: 2.476815841504801

Epoch: 5| Step: 4
Training loss: 3.1385305832191213
Validation loss: 2.4773643832037697

Epoch: 5| Step: 5
Training loss: 2.677350418086969
Validation loss: 2.4762543728279685

Epoch: 5| Step: 6
Training loss: 2.872505100600957
Validation loss: 2.4828224889331447

Epoch: 5| Step: 7
Training loss: 2.359848884334964
Validation loss: 2.4763115114893792

Epoch: 5| Step: 8
Training loss: 2.357381622805173
Validation loss: 2.4742420087435195

Epoch: 5| Step: 9
Training loss: 2.4655507278376017
Validation loss: 2.477719130116581

Epoch: 5| Step: 10
Training loss: 2.9630969383714945
Validation loss: 2.4735930457560054

Epoch: 5| Step: 11
Training loss: 1.9598254207790144
Validation loss: 2.4729536378877204

Epoch: 114| Step: 0
Training loss: 2.9569596517504393
Validation loss: 2.47717448474039

Epoch: 5| Step: 1
Training loss: 2.6025317336904314
Validation loss: 2.473078867877529

Epoch: 5| Step: 2
Training loss: 2.6747137683069204
Validation loss: 2.4729760692845884

Epoch: 5| Step: 3
Training loss: 2.226010652384671
Validation loss: 2.4707441062694837

Epoch: 5| Step: 4
Training loss: 2.837708815902812
Validation loss: 2.4722909039756873

Epoch: 5| Step: 5
Training loss: 2.292068746724119
Validation loss: 2.473611180225576

Epoch: 5| Step: 6
Training loss: 2.1077279901777204
Validation loss: 2.4770923091917236

Epoch: 5| Step: 7
Training loss: 3.056427365014563
Validation loss: 2.4729609851567025

Epoch: 5| Step: 8
Training loss: 2.9220674012835577
Validation loss: 2.4737252108845187

Epoch: 5| Step: 9
Training loss: 2.208645984421943
Validation loss: 2.474664303622354

Epoch: 5| Step: 10
Training loss: 2.5547425617035446
Validation loss: 2.471832736876155

Epoch: 5| Step: 11
Training loss: 1.1806909196826427
Validation loss: 2.4730737543601085

Epoch: 115| Step: 0
Training loss: 2.613241380692459
Validation loss: 2.4714541051586694

Epoch: 5| Step: 1
Training loss: 2.8184441377261518
Validation loss: 2.46958898219177

Epoch: 5| Step: 2
Training loss: 3.0039821262970765
Validation loss: 2.4689212832204324

Epoch: 5| Step: 3
Training loss: 2.4542413589000565
Validation loss: 2.4695038348740543

Epoch: 5| Step: 4
Training loss: 2.4836874916262697
Validation loss: 2.469406012602085

Epoch: 5| Step: 5
Training loss: 2.5961897073208893
Validation loss: 2.4695868824066083

Epoch: 5| Step: 6
Training loss: 2.630717998010922
Validation loss: 2.46866246965618

Epoch: 5| Step: 7
Training loss: 2.365957916498174
Validation loss: 2.4698905161352487

Epoch: 5| Step: 8
Training loss: 2.271585870576132
Validation loss: 2.4650724539673763

Epoch: 5| Step: 9
Training loss: 2.550201116372541
Validation loss: 2.46968268027035

Epoch: 5| Step: 10
Training loss: 2.1541071762439317
Validation loss: 2.464760014662843

Epoch: 5| Step: 11
Training loss: 3.7090567551109643
Validation loss: 2.4687835876175903

Epoch: 116| Step: 0
Training loss: 2.861254465242154
Validation loss: 2.4606462498035473

Epoch: 5| Step: 1
Training loss: 2.3337555457908965
Validation loss: 2.4637924507570252

Epoch: 5| Step: 2
Training loss: 2.2939914586673953
Validation loss: 2.462523350064355

Epoch: 5| Step: 3
Training loss: 3.0244889513350923
Validation loss: 2.4641884881423968

Epoch: 5| Step: 4
Training loss: 2.452546555663426
Validation loss: 2.464042867978621

Epoch: 5| Step: 5
Training loss: 2.9528118956556457
Validation loss: 2.467900071532433

Epoch: 5| Step: 6
Training loss: 2.3347579376415815
Validation loss: 2.4622057598553884

Epoch: 5| Step: 7
Training loss: 2.566771598834278
Validation loss: 2.4614503558192786

Epoch: 5| Step: 8
Training loss: 2.538274836510105
Validation loss: 2.4632957381445384

Epoch: 5| Step: 9
Training loss: 2.6401372154296046
Validation loss: 2.4678334816442518

Epoch: 5| Step: 10
Training loss: 1.9451474039270522
Validation loss: 2.4710012263615715

Epoch: 5| Step: 11
Training loss: 3.6059932306599563
Validation loss: 2.468391400460636

Epoch: 117| Step: 0
Training loss: 2.4027375185416764
Validation loss: 2.466704837293239

Epoch: 5| Step: 1
Training loss: 2.4472226613285257
Validation loss: 2.4703234555481868

Epoch: 5| Step: 2
Training loss: 2.779513213261947
Validation loss: 2.4735491618376995

Epoch: 5| Step: 3
Training loss: 2.5397820494850967
Validation loss: 2.471074796321131

Epoch: 5| Step: 4
Training loss: 2.6201963522912832
Validation loss: 2.47675088512923

Epoch: 5| Step: 5
Training loss: 2.6774097248605475
Validation loss: 2.4718459189111313

Epoch: 5| Step: 6
Training loss: 3.004161808964104
Validation loss: 2.4737751193551825

Epoch: 5| Step: 7
Training loss: 2.4333446981434648
Validation loss: 2.472323185815242

Epoch: 5| Step: 8
Training loss: 2.500243747272727
Validation loss: 2.4702681448789026

Epoch: 5| Step: 9
Training loss: 2.0191612273597057
Validation loss: 2.465512281257936

Epoch: 5| Step: 10
Training loss: 2.9110843279466336
Validation loss: 2.467585172165568

Epoch: 5| Step: 11
Training loss: 1.469186920759194
Validation loss: 2.4621298005825696

Epoch: 118| Step: 0
Training loss: 2.779929972939869
Validation loss: 2.459836041231791

Epoch: 5| Step: 1
Training loss: 2.276748919790742
Validation loss: 2.4606252522654555

Epoch: 5| Step: 2
Training loss: 2.3773452823971195
Validation loss: 2.4641267486304432

Epoch: 5| Step: 3
Training loss: 2.9684812725312337
Validation loss: 2.4650814346844006

Epoch: 5| Step: 4
Training loss: 2.3130148237242376
Validation loss: 2.4642804888162435

Epoch: 5| Step: 5
Training loss: 2.6646512183717532
Validation loss: 2.468819882816202

Epoch: 5| Step: 6
Training loss: 2.302220152044327
Validation loss: 2.4702451741395635

Epoch: 5| Step: 7
Training loss: 2.5929599156104213
Validation loss: 2.472886348502091

Epoch: 5| Step: 8
Training loss: 2.1822271830667916
Validation loss: 2.46982519662515

Epoch: 5| Step: 9
Training loss: 2.833485954512382
Validation loss: 2.4686204015137934

Epoch: 5| Step: 10
Training loss: 2.9381993861256923
Validation loss: 2.466140059585553

Epoch: 5| Step: 11
Training loss: 2.587801811565635
Validation loss: 2.4633045176479778

Epoch: 119| Step: 0
Training loss: 2.1880273455806134
Validation loss: 2.468524274687248

Epoch: 5| Step: 1
Training loss: 2.1271351577866855
Validation loss: 2.460540255016694

Epoch: 5| Step: 2
Training loss: 2.371492104163508
Validation loss: 2.4572400427377965

Epoch: 5| Step: 3
Training loss: 2.210856190187178
Validation loss: 2.4598818982470205

Epoch: 5| Step: 4
Training loss: 2.6396754436685
Validation loss: 2.4595189946282505

Epoch: 5| Step: 5
Training loss: 2.318702421702741
Validation loss: 2.4590283289690924

Epoch: 5| Step: 6
Training loss: 2.8084438321101732
Validation loss: 2.461289888210173

Epoch: 5| Step: 7
Training loss: 3.14679624123684
Validation loss: 2.4672913245818484

Epoch: 5| Step: 8
Training loss: 2.576659739864591
Validation loss: 2.4690730229639417

Epoch: 5| Step: 9
Training loss: 2.611178203379127
Validation loss: 2.473114172148827

Epoch: 5| Step: 10
Training loss: 2.735690688629429
Validation loss: 2.474800983609126

Epoch: 5| Step: 11
Training loss: 3.948629363591015
Validation loss: 2.476221456220379

Epoch: 120| Step: 0
Training loss: 2.5869094543300784
Validation loss: 2.4756080761884536

Epoch: 5| Step: 1
Training loss: 2.545397183465527
Validation loss: 2.4788034370678416

Epoch: 5| Step: 2
Training loss: 2.581091174395669
Validation loss: 2.479402680476108

Epoch: 5| Step: 3
Training loss: 2.817833738421498
Validation loss: 2.481350523244034

Epoch: 5| Step: 4
Training loss: 2.745278466697084
Validation loss: 2.4765551995170805

Epoch: 5| Step: 5
Training loss: 2.229337335155552
Validation loss: 2.4776672402298305

Epoch: 5| Step: 6
Training loss: 2.2265160271328814
Validation loss: 2.4764569457591445

Epoch: 5| Step: 7
Training loss: 2.6518413084660373
Validation loss: 2.477537879647852

Epoch: 5| Step: 8
Training loss: 2.2871655620967104
Validation loss: 2.4819884723502703

Epoch: 5| Step: 9
Training loss: 2.7639996768934667
Validation loss: 2.4740060634358843

Epoch: 5| Step: 10
Training loss: 2.922632782124773
Validation loss: 2.4738285806995695

Epoch: 5| Step: 11
Training loss: 2.521866914908721
Validation loss: 2.4761719902212262

Epoch: 121| Step: 0
Training loss: 2.1923406176340454
Validation loss: 2.4730990768126717

Epoch: 5| Step: 1
Training loss: 2.2673791868752775
Validation loss: 2.4715316770346036

Epoch: 5| Step: 2
Training loss: 2.8347658201240975
Validation loss: 2.4673912940997695

Epoch: 5| Step: 3
Training loss: 2.4938356695541755
Validation loss: 2.4683289329767337

Epoch: 5| Step: 4
Training loss: 3.093556715967436
Validation loss: 2.461683529596117

Epoch: 5| Step: 5
Training loss: 2.802895401107062
Validation loss: 2.462097802695559

Epoch: 5| Step: 6
Training loss: 2.1386532578028152
Validation loss: 2.45925707487905

Epoch: 5| Step: 7
Training loss: 2.570134119029788
Validation loss: 2.468026578313646

Epoch: 5| Step: 8
Training loss: 2.2913159419933153
Validation loss: 2.4690220678884947

Epoch: 5| Step: 9
Training loss: 2.49587166384737
Validation loss: 2.4533698573278944

Epoch: 5| Step: 10
Training loss: 2.9818879794412188
Validation loss: 2.4583306285606206

Epoch: 5| Step: 11
Training loss: 2.5873168769941497
Validation loss: 2.46334036124917

Epoch: 122| Step: 0
Training loss: 2.1045397688936602
Validation loss: 2.467750717277888

Epoch: 5| Step: 1
Training loss: 3.0144685889926666
Validation loss: 2.472684577831855

Epoch: 5| Step: 2
Training loss: 2.198502039283985
Validation loss: 2.4739217708629777

Epoch: 5| Step: 3
Training loss: 2.3617361014457807
Validation loss: 2.478090787429324

Epoch: 5| Step: 4
Training loss: 2.8903181583342143
Validation loss: 2.480449666427933

Epoch: 5| Step: 5
Training loss: 2.7012889116795327
Validation loss: 2.479858006859061

Epoch: 5| Step: 6
Training loss: 2.8734121498869034
Validation loss: 2.48093987343665

Epoch: 5| Step: 7
Training loss: 3.008213402919155
Validation loss: 2.4779966836670573

Epoch: 5| Step: 8
Training loss: 2.4444580535317177
Validation loss: 2.4789743642729207

Epoch: 5| Step: 9
Training loss: 2.515439044405689
Validation loss: 2.4803664339044484

Epoch: 5| Step: 10
Training loss: 2.138820583799646
Validation loss: 2.4760926459786545

Epoch: 5| Step: 11
Training loss: 2.882988487599093
Validation loss: 2.47960503226121

Epoch: 123| Step: 0
Training loss: 2.2903267035172066
Validation loss: 2.4828837535533372

Epoch: 5| Step: 1
Training loss: 2.4927685099212833
Validation loss: 2.477769186669535

Epoch: 5| Step: 2
Training loss: 3.1947898530576615
Validation loss: 2.477241306759217

Epoch: 5| Step: 3
Training loss: 2.890850161469268
Validation loss: 2.4741887370116977

Epoch: 5| Step: 4
Training loss: 2.340182730395087
Validation loss: 2.475923702514984

Epoch: 5| Step: 5
Training loss: 2.390978020427005
Validation loss: 2.47738655812837

Epoch: 5| Step: 6
Training loss: 2.834232879406608
Validation loss: 2.4800070305373407

Epoch: 5| Step: 7
Training loss: 2.555693915210628
Validation loss: 2.47047777517781

Epoch: 5| Step: 8
Training loss: 1.765935279792142
Validation loss: 2.4729863609856184

Epoch: 5| Step: 9
Training loss: 2.4401543665349394
Validation loss: 2.4705221318430524

Epoch: 5| Step: 10
Training loss: 2.889461138689543
Validation loss: 2.473210080411922

Epoch: 5| Step: 11
Training loss: 2.034388655515625
Validation loss: 2.464372024495638

Epoch: 124| Step: 0
Training loss: 2.819461599046189
Validation loss: 2.4620377719963282

Epoch: 5| Step: 1
Training loss: 2.4290323140683174
Validation loss: 2.468070789854963

Epoch: 5| Step: 2
Training loss: 2.5553411644924173
Validation loss: 2.466575679088971

Epoch: 5| Step: 3
Training loss: 2.0925868205263143
Validation loss: 2.462881835954086

Epoch: 5| Step: 4
Training loss: 1.9382211512112872
Validation loss: 2.464476492031265

Epoch: 5| Step: 5
Training loss: 3.100576402544394
Validation loss: 2.460800054032119

Epoch: 5| Step: 6
Training loss: 2.710151668400657
Validation loss: 2.4639264358047472

Epoch: 5| Step: 7
Training loss: 2.5597938576789803
Validation loss: 2.459826530488835

Epoch: 5| Step: 8
Training loss: 2.0238829604750905
Validation loss: 2.463275916596573

Epoch: 5| Step: 9
Training loss: 3.032697508969235
Validation loss: 2.4660724050244283

Epoch: 5| Step: 10
Training loss: 2.5944023690724856
Validation loss: 2.4758371640752146

Epoch: 5| Step: 11
Training loss: 3.0182812312948113
Validation loss: 2.472851834388684

Epoch: 125| Step: 0
Training loss: 2.5125248921997447
Validation loss: 2.467055475569171

Epoch: 5| Step: 1
Training loss: 2.6066802037985957
Validation loss: 2.462127510854138

Epoch: 5| Step: 2
Training loss: 2.759139911318731
Validation loss: 2.455266710077491

Epoch: 5| Step: 3
Training loss: 2.9145183462369486
Validation loss: 2.4568159840968855

Epoch: 5| Step: 4
Training loss: 2.469714881564656
Validation loss: 2.4660138508096265

Epoch: 5| Step: 5
Training loss: 2.7200615887120496
Validation loss: 2.4699402587599018

Epoch: 5| Step: 6
Training loss: 2.772449758089912
Validation loss: 2.4716079763808425

Epoch: 5| Step: 7
Training loss: 2.308221415848952
Validation loss: 2.4737971457457077

Epoch: 5| Step: 8
Training loss: 2.186819788215941
Validation loss: 2.466099873926549

Epoch: 5| Step: 9
Training loss: 2.1343875421068974
Validation loss: 2.469593616194085

Epoch: 5| Step: 10
Training loss: 2.6985052244946193
Validation loss: 2.464310106162672

Epoch: 5| Step: 11
Training loss: 3.173588031784119
Validation loss: 2.459500130197059

Epoch: 126| Step: 0
Training loss: 3.0776613147641823
Validation loss: 2.455906414918169

Epoch: 5| Step: 1
Training loss: 2.837885752264829
Validation loss: 2.456792196138197

Epoch: 5| Step: 2
Training loss: 2.896530140716492
Validation loss: 2.4642314321615575

Epoch: 5| Step: 3
Training loss: 2.3115653133749103
Validation loss: 2.462384322397587

Epoch: 5| Step: 4
Training loss: 2.6679184379692895
Validation loss: 2.4659307776153905

Epoch: 5| Step: 5
Training loss: 2.506104835625109
Validation loss: 2.4692492724619015

Epoch: 5| Step: 6
Training loss: 2.576888279072227
Validation loss: 2.4693021478754664

Epoch: 5| Step: 7
Training loss: 2.3953926565714636
Validation loss: 2.470141203939431

Epoch: 5| Step: 8
Training loss: 2.2106496670732354
Validation loss: 2.471244312466997

Epoch: 5| Step: 9
Training loss: 2.427128170619799
Validation loss: 2.472096804245595

Epoch: 5| Step: 10
Training loss: 2.352393222213864
Validation loss: 2.472490502979848

Epoch: 5| Step: 11
Training loss: 2.228208127818509
Validation loss: 2.4729489418908073

Epoch: 127| Step: 0
Training loss: 2.8706986135939685
Validation loss: 2.470479858121258

Epoch: 5| Step: 1
Training loss: 2.258432903651966
Validation loss: 2.4722647173642742

Epoch: 5| Step: 2
Training loss: 2.3865010713246786
Validation loss: 2.468903693714536

Epoch: 5| Step: 3
Training loss: 2.818571023270518
Validation loss: 2.47034474061681

Epoch: 5| Step: 4
Training loss: 2.4801940285244655
Validation loss: 2.4698010553197354

Epoch: 5| Step: 5
Training loss: 2.437972194222035
Validation loss: 2.4680650823279633

Epoch: 5| Step: 6
Training loss: 2.449588340117837
Validation loss: 2.46566799788701

Epoch: 5| Step: 7
Training loss: 2.474480075363627
Validation loss: 2.4640983627312347

Epoch: 5| Step: 8
Training loss: 2.726916445955515
Validation loss: 2.4577520472582983

Epoch: 5| Step: 9
Training loss: 2.843194928335498
Validation loss: 2.460606612308869

Epoch: 5| Step: 10
Training loss: 2.538536322432444
Validation loss: 2.4618749599032284

Epoch: 5| Step: 11
Training loss: 2.4057615700952613
Validation loss: 2.456911198321788

Epoch: 128| Step: 0
Training loss: 2.69167216943074
Validation loss: 2.4567831022274182

Epoch: 5| Step: 1
Training loss: 2.7394003764706287
Validation loss: 2.4577555192896994

Epoch: 5| Step: 2
Training loss: 2.32184783796439
Validation loss: 2.4576958271521243

Epoch: 5| Step: 3
Training loss: 2.564065129605932
Validation loss: 2.457342317152686

Epoch: 5| Step: 4
Training loss: 2.8645101826893473
Validation loss: 2.460464214045333

Epoch: 5| Step: 5
Training loss: 2.1674497240828914
Validation loss: 2.455429193669844

Epoch: 5| Step: 6
Training loss: 2.726305318251053
Validation loss: 2.4593543354347354

Epoch: 5| Step: 7
Training loss: 2.249735180847215
Validation loss: 2.465299645776127

Epoch: 5| Step: 8
Training loss: 2.217402089052893
Validation loss: 2.4581208676050395

Epoch: 5| Step: 9
Training loss: 2.6726063402249856
Validation loss: 2.4603184764131645

Epoch: 5| Step: 10
Training loss: 2.6297627792417795
Validation loss: 2.4587130630451894

Epoch: 5| Step: 11
Training loss: 3.4773930275518765
Validation loss: 2.459658392251448

Epoch: 129| Step: 0
Training loss: 2.7463537665562825
Validation loss: 2.4590714136000003

Epoch: 5| Step: 1
Training loss: 2.4051344626542743
Validation loss: 2.460905254495879

Epoch: 5| Step: 2
Training loss: 2.7740221723620646
Validation loss: 2.4622302701556413

Epoch: 5| Step: 3
Training loss: 2.999703074702053
Validation loss: 2.464163773575513

Epoch: 5| Step: 4
Training loss: 2.527013836749183
Validation loss: 2.462181543842588

Epoch: 5| Step: 5
Training loss: 2.424068417499495
Validation loss: 2.4672237861450057

Epoch: 5| Step: 6
Training loss: 2.4113032797171954
Validation loss: 2.465925480076034

Epoch: 5| Step: 7
Training loss: 2.5993530238755014
Validation loss: 2.468059773269491

Epoch: 5| Step: 8
Training loss: 2.370364835962263
Validation loss: 2.4667440425382936

Epoch: 5| Step: 9
Training loss: 2.4128303222630434
Validation loss: 2.4630387675347043

Epoch: 5| Step: 10
Training loss: 2.515768201081142
Validation loss: 2.467247167521683

Epoch: 5| Step: 11
Training loss: 1.7803631632799142
Validation loss: 2.4660121367218517

Epoch: 130| Step: 0
Training loss: 2.9407332462247675
Validation loss: 2.467345981287274

Epoch: 5| Step: 1
Training loss: 2.149741591959584
Validation loss: 2.465491006850138

Epoch: 5| Step: 2
Training loss: 2.5628001339691635
Validation loss: 2.4625818844072445

Epoch: 5| Step: 3
Training loss: 2.6200104477361035
Validation loss: 2.4531079066950565

Epoch: 5| Step: 4
Training loss: 2.684566138393672
Validation loss: 2.457955878316217

Epoch: 5| Step: 5
Training loss: 2.7159791177781147
Validation loss: 2.4520645562757246

Epoch: 5| Step: 6
Training loss: 2.3216352706104444
Validation loss: 2.4586106052392656

Epoch: 5| Step: 7
Training loss: 2.8841263586396657
Validation loss: 2.4488541099949344

Epoch: 5| Step: 8
Training loss: 1.712206644145104
Validation loss: 2.456781472679156

Epoch: 5| Step: 9
Training loss: 2.846210128243558
Validation loss: 2.4506007528431075

Epoch: 5| Step: 10
Training loss: 2.66478211648392
Validation loss: 2.4512156306562374

Epoch: 5| Step: 11
Training loss: 1.114400414879332
Validation loss: 2.4519667148542665

Epoch: 131| Step: 0
Training loss: 1.8776194395025256
Validation loss: 2.4506388394964556

Epoch: 5| Step: 1
Training loss: 2.262002614182531
Validation loss: 2.4492173019964634

Epoch: 5| Step: 2
Training loss: 2.9087962819586597
Validation loss: 2.4550101048999013

Epoch: 5| Step: 3
Training loss: 2.614177191042993
Validation loss: 2.4458330796700323

Epoch: 5| Step: 4
Training loss: 2.8024508342803
Validation loss: 2.4495141369897775

Epoch: 5| Step: 5
Training loss: 2.9473709481988557
Validation loss: 2.457231872243986

Epoch: 5| Step: 6
Training loss: 2.118526921864471
Validation loss: 2.456780558837722

Epoch: 5| Step: 7
Training loss: 2.338795830070128
Validation loss: 2.4574732582510377

Epoch: 5| Step: 8
Training loss: 2.4426848214542316
Validation loss: 2.4537550568621636

Epoch: 5| Step: 9
Training loss: 2.7477038073769395
Validation loss: 2.4509749415748425

Epoch: 5| Step: 10
Training loss: 2.8776533073728814
Validation loss: 2.4584086024081615

Epoch: 5| Step: 11
Training loss: 1.83714812925498
Validation loss: 2.4579690256495095

Epoch: 132| Step: 0
Training loss: 2.2379936313078317
Validation loss: 2.4591679705253653

Epoch: 5| Step: 1
Training loss: 2.399913420704981
Validation loss: 2.461063906536486

Epoch: 5| Step: 2
Training loss: 2.7036821970768914
Validation loss: 2.4665769356653513

Epoch: 5| Step: 3
Training loss: 2.4012491353086536
Validation loss: 2.462886986766349

Epoch: 5| Step: 4
Training loss: 2.7684810568085814
Validation loss: 2.4646780821859435

Epoch: 5| Step: 5
Training loss: 2.958539892874438
Validation loss: 2.4680328373700324

Epoch: 5| Step: 6
Training loss: 2.666553395567689
Validation loss: 2.4710438891644912

Epoch: 5| Step: 7
Training loss: 2.4021288767916995
Validation loss: 2.4656583766829696

Epoch: 5| Step: 8
Training loss: 2.1539838741623316
Validation loss: 2.4692294906591497

Epoch: 5| Step: 9
Training loss: 2.105130594873432
Validation loss: 2.465273473553788

Epoch: 5| Step: 10
Training loss: 2.9475016666889737
Validation loss: 2.4664760249050315

Epoch: 5| Step: 11
Training loss: 3.4502056779227965
Validation loss: 2.46279785643033

Epoch: 133| Step: 0
Training loss: 2.392635920858055
Validation loss: 2.456850430334923

Epoch: 5| Step: 1
Training loss: 2.2827183426610884
Validation loss: 2.451252017794409

Epoch: 5| Step: 2
Training loss: 2.428935532563616
Validation loss: 2.4504954424254457

Epoch: 5| Step: 3
Training loss: 2.469961327933459
Validation loss: 2.4511202823229663

Epoch: 5| Step: 4
Training loss: 2.375531087021185
Validation loss: 2.4523360933717195

Epoch: 5| Step: 5
Training loss: 2.9396202065263743
Validation loss: 2.4559218262670894

Epoch: 5| Step: 6
Training loss: 3.063234046624883
Validation loss: 2.4515949061537134

Epoch: 5| Step: 7
Training loss: 3.0067009791793797
Validation loss: 2.450273273596594

Epoch: 5| Step: 8
Training loss: 2.105723859233208
Validation loss: 2.455848971397887

Epoch: 5| Step: 9
Training loss: 2.5892852595286606
Validation loss: 2.4663358465438736

Epoch: 5| Step: 10
Training loss: 2.1128146913424266
Validation loss: 2.465746158706059

Epoch: 5| Step: 11
Training loss: 3.5528049724122304
Validation loss: 2.47174792809083

Epoch: 134| Step: 0
Training loss: 2.8467378116385937
Validation loss: 2.4690922930388166

Epoch: 5| Step: 1
Training loss: 2.614300493441281
Validation loss: 2.4636094780931566

Epoch: 5| Step: 2
Training loss: 2.578058137893639
Validation loss: 2.4571099766509406

Epoch: 5| Step: 3
Training loss: 2.386113915856869
Validation loss: 2.458252607787429

Epoch: 5| Step: 4
Training loss: 2.8467939245946283
Validation loss: 2.461346569071886

Epoch: 5| Step: 5
Training loss: 2.2607600102226733
Validation loss: 2.4538040314728864

Epoch: 5| Step: 6
Training loss: 2.081080579305731
Validation loss: 2.457258099796603

Epoch: 5| Step: 7
Training loss: 2.9773571325405257
Validation loss: 2.459393524559019

Epoch: 5| Step: 8
Training loss: 2.2079802776713593
Validation loss: 2.457267345573848

Epoch: 5| Step: 9
Training loss: 1.9759695498093288
Validation loss: 2.4561915901104925

Epoch: 5| Step: 10
Training loss: 3.0155054572727598
Validation loss: 2.467354814824574

Epoch: 5| Step: 11
Training loss: 2.5316868157889805
Validation loss: 2.457625923099781

Epoch: 135| Step: 0
Training loss: 2.945497218645991
Validation loss: 2.4618091028747204

Epoch: 5| Step: 1
Training loss: 3.1418724808873493
Validation loss: 2.4610057962618797

Epoch: 5| Step: 2
Training loss: 2.406815598635712
Validation loss: 2.459367123873555

Epoch: 5| Step: 3
Training loss: 2.4184284913235006
Validation loss: 2.4696392719152276

Epoch: 5| Step: 4
Training loss: 2.6459980310157376
Validation loss: 2.463372244194204

Epoch: 5| Step: 5
Training loss: 2.3369679299318133
Validation loss: 2.4647893078449634

Epoch: 5| Step: 6
Training loss: 2.5003327148291628
Validation loss: 2.462581025160585

Epoch: 5| Step: 7
Training loss: 2.3617482154817644
Validation loss: 2.4656510197403128

Epoch: 5| Step: 8
Training loss: 2.1276277115140445
Validation loss: 2.468812189244388

Epoch: 5| Step: 9
Training loss: 2.565262770550069
Validation loss: 2.4684967241057514

Epoch: 5| Step: 10
Training loss: 2.8548237584860825
Validation loss: 2.46739192821959

Epoch: 5| Step: 11
Training loss: 1.812530122703959
Validation loss: 2.4673736010845313

Epoch: 136| Step: 0
Training loss: 2.1313727693072333
Validation loss: 2.47158658563069

Epoch: 5| Step: 1
Training loss: 2.588085008914255
Validation loss: 2.4660682437752914

Epoch: 5| Step: 2
Training loss: 2.2655654373231986
Validation loss: 2.4663066321494647

Epoch: 5| Step: 3
Training loss: 2.8043030711795143
Validation loss: 2.461627362959201

Epoch: 5| Step: 4
Training loss: 2.332737494640704
Validation loss: 2.4610387791375254

Epoch: 5| Step: 5
Training loss: 2.6559686848391477
Validation loss: 2.4669112186303646

Epoch: 5| Step: 6
Training loss: 2.7173267015158475
Validation loss: 2.4640133522436196

Epoch: 5| Step: 7
Training loss: 2.6682766782745246
Validation loss: 2.4529751409934213

Epoch: 5| Step: 8
Training loss: 2.9424759944691723
Validation loss: 2.4603693593898623

Epoch: 5| Step: 9
Training loss: 2.6070648749048977
Validation loss: 2.4597869726729487

Epoch: 5| Step: 10
Training loss: 2.3530506988588553
Validation loss: 2.458291818516084

Epoch: 5| Step: 11
Training loss: 1.9204468421719978
Validation loss: 2.4552909882208267

Epoch: 137| Step: 0
Training loss: 2.317092356461607
Validation loss: 2.4530908942635823

Epoch: 5| Step: 1
Training loss: 2.67364817892253
Validation loss: 2.4551625547051144

Epoch: 5| Step: 2
Training loss: 2.597686170821571
Validation loss: 2.457361656982857

Epoch: 5| Step: 3
Training loss: 2.194412535691623
Validation loss: 2.461911310549727

Epoch: 5| Step: 4
Training loss: 2.3410835866039794
Validation loss: 2.4665029616955145

Epoch: 5| Step: 5
Training loss: 2.440842317682074
Validation loss: 2.4618660522282836

Epoch: 5| Step: 6
Training loss: 2.631696062493585
Validation loss: 2.4626182528565796

Epoch: 5| Step: 7
Training loss: 2.359064144852015
Validation loss: 2.4534090975041103

Epoch: 5| Step: 8
Training loss: 3.1026102213373297
Validation loss: 2.4620149827039532

Epoch: 5| Step: 9
Training loss: 2.9303477446129
Validation loss: 2.452489948887244

Epoch: 5| Step: 10
Training loss: 2.2240353882876307
Validation loss: 2.4490771985356248

Epoch: 5| Step: 11
Training loss: 2.7909504460384875
Validation loss: 2.4498461984834283

Epoch: 138| Step: 0
Training loss: 2.312326785636974
Validation loss: 2.4532189361340375

Epoch: 5| Step: 1
Training loss: 2.5583196828107284
Validation loss: 2.4629602626602756

Epoch: 5| Step: 2
Training loss: 2.3334258492611766
Validation loss: 2.4663122148524343

Epoch: 5| Step: 3
Training loss: 2.3018180959039443
Validation loss: 2.472224502675532

Epoch: 5| Step: 4
Training loss: 2.630638968588552
Validation loss: 2.4725633014165216

Epoch: 5| Step: 5
Training loss: 2.834247011703823
Validation loss: 2.471154424288504

Epoch: 5| Step: 6
Training loss: 2.9020483346669406
Validation loss: 2.47568301399901

Epoch: 5| Step: 7
Training loss: 2.7639782846925467
Validation loss: 2.4750382940624376

Epoch: 5| Step: 8
Training loss: 2.291877864006756
Validation loss: 2.4730509382226695

Epoch: 5| Step: 9
Training loss: 2.517322986065617
Validation loss: 2.4735998971513427

Epoch: 5| Step: 10
Training loss: 2.7993080169642517
Validation loss: 2.4726341531819815

Epoch: 5| Step: 11
Training loss: 2.016344045679426
Validation loss: 2.4695873771837324

Epoch: 139| Step: 0
Training loss: 2.8918767744643827
Validation loss: 2.4700235872262146

Epoch: 5| Step: 1
Training loss: 2.4892602069733973
Validation loss: 2.4693284101571873

Epoch: 5| Step: 2
Training loss: 2.496197478955315
Validation loss: 2.466668257251003

Epoch: 5| Step: 3
Training loss: 2.554643263127606
Validation loss: 2.463146090587814

Epoch: 5| Step: 4
Training loss: 2.37068768563981
Validation loss: 2.462605689051134

Epoch: 5| Step: 5
Training loss: 2.504368684292801
Validation loss: 2.458371179634196

Epoch: 5| Step: 6
Training loss: 2.332868416199732
Validation loss: 2.453278692658922

Epoch: 5| Step: 7
Training loss: 2.532250948198962
Validation loss: 2.460481865902159

Epoch: 5| Step: 8
Training loss: 2.4889345374443557
Validation loss: 2.4566504300079983

Epoch: 5| Step: 9
Training loss: 2.547816190404616
Validation loss: 2.4530702046229433

Epoch: 5| Step: 10
Training loss: 2.853058054411235
Validation loss: 2.457457585788554

Epoch: 5| Step: 11
Training loss: 2.0808025119603535
Validation loss: 2.451333665510931

Epoch: 140| Step: 0
Training loss: 3.2234838544329705
Validation loss: 2.4518052497398783

Epoch: 5| Step: 1
Training loss: 2.4705496879850894
Validation loss: 2.457091621340528

Epoch: 5| Step: 2
Training loss: 2.3243445097935718
Validation loss: 2.4647592932110647

Epoch: 5| Step: 3
Training loss: 2.4511539777733073
Validation loss: 2.4670887560710466

Epoch: 5| Step: 4
Training loss: 2.3289951004232297
Validation loss: 2.4652016526469693

Epoch: 5| Step: 5
Training loss: 2.548771064674996
Validation loss: 2.456897810813341

Epoch: 5| Step: 6
Training loss: 2.6455426895022427
Validation loss: 2.458012193512476

Epoch: 5| Step: 7
Training loss: 2.8630106174859713
Validation loss: 2.451508866406836

Epoch: 5| Step: 8
Training loss: 2.308451433523144
Validation loss: 2.4498575321606806

Epoch: 5| Step: 9
Training loss: 2.2524658043030183
Validation loss: 2.452309908374631

Epoch: 5| Step: 10
Training loss: 2.588780249506863
Validation loss: 2.452598237825525

Epoch: 5| Step: 11
Training loss: 2.605706931784418
Validation loss: 2.4505065055425606

Epoch: 141| Step: 0
Training loss: 2.6668859828725506
Validation loss: 2.456793158497617

Epoch: 5| Step: 1
Training loss: 3.2229175438578683
Validation loss: 2.4529684223330586

Epoch: 5| Step: 2
Training loss: 1.9916910188641268
Validation loss: 2.4567233338952454

Epoch: 5| Step: 3
Training loss: 2.2985350131076823
Validation loss: 2.4584187934590176

Epoch: 5| Step: 4
Training loss: 2.387309449266093
Validation loss: 2.4592039471300398

Epoch: 5| Step: 5
Training loss: 2.0491526503960715
Validation loss: 2.4616208979428897

Epoch: 5| Step: 6
Training loss: 2.8718486597889252
Validation loss: 2.4601568931723308

Epoch: 5| Step: 7
Training loss: 2.4624388943753943
Validation loss: 2.464060647399761

Epoch: 5| Step: 8
Training loss: 2.7377653193689206
Validation loss: 2.459066182079363

Epoch: 5| Step: 9
Training loss: 2.594222979336224
Validation loss: 2.4532586363010616

Epoch: 5| Step: 10
Training loss: 2.520647993183894
Validation loss: 2.452979036917041

Epoch: 5| Step: 11
Training loss: 2.40179943338083
Validation loss: 2.4519732134283125

Epoch: 142| Step: 0
Training loss: 2.3603897438859525
Validation loss: 2.4522125466677807

Epoch: 5| Step: 1
Training loss: 2.296487061832658
Validation loss: 2.4539574022780077

Epoch: 5| Step: 2
Training loss: 2.6944431838024987
Validation loss: 2.456849362868663

Epoch: 5| Step: 3
Training loss: 2.8864235527029196
Validation loss: 2.457884061838199

Epoch: 5| Step: 4
Training loss: 2.597376482819897
Validation loss: 2.4581394294194343

Epoch: 5| Step: 5
Training loss: 2.647366917825184
Validation loss: 2.46084327517369

Epoch: 5| Step: 6
Training loss: 2.973524089761194
Validation loss: 2.4602687310479148

Epoch: 5| Step: 7
Training loss: 2.368066907639824
Validation loss: 2.4598524375855324

Epoch: 5| Step: 8
Training loss: 2.4890950786903456
Validation loss: 2.4554089930455616

Epoch: 5| Step: 9
Training loss: 2.1996752195778257
Validation loss: 2.4576442542090455

Epoch: 5| Step: 10
Training loss: 2.539151703661391
Validation loss: 2.4531299607212587

Epoch: 5| Step: 11
Training loss: 1.9612627709521797
Validation loss: 2.4528889593126895

Epoch: 143| Step: 0
Training loss: 2.3355592147059663
Validation loss: 2.4502847836861616

Epoch: 5| Step: 1
Training loss: 2.3848230103532733
Validation loss: 2.4525972677444203

Epoch: 5| Step: 2
Training loss: 2.5110425261280787
Validation loss: 2.455942997500552

Epoch: 5| Step: 3
Training loss: 2.626952126655247
Validation loss: 2.4499751235711043

Epoch: 5| Step: 4
Training loss: 2.995508009888254
Validation loss: 2.452127974878168

Epoch: 5| Step: 5
Training loss: 2.473229701843534
Validation loss: 2.4535182022221282

Epoch: 5| Step: 6
Training loss: 2.527028838028957
Validation loss: 2.4511038316094726

Epoch: 5| Step: 7
Training loss: 2.8229578350673457
Validation loss: 2.456521701587994

Epoch: 5| Step: 8
Training loss: 2.843820759657951
Validation loss: 2.4545439040548924

Epoch: 5| Step: 9
Training loss: 2.096371731575935
Validation loss: 2.449707651698988

Epoch: 5| Step: 10
Training loss: 2.2453721454638105
Validation loss: 2.452459240936658

Epoch: 5| Step: 11
Training loss: 2.191304522378426
Validation loss: 2.452683763447119

Epoch: 144| Step: 0
Training loss: 2.365652159279211
Validation loss: 2.4525387178800364

Epoch: 5| Step: 1
Training loss: 2.2621080132758484
Validation loss: 2.4603237254595984

Epoch: 5| Step: 2
Training loss: 2.4896973992130924
Validation loss: 2.4557363537669397

Epoch: 5| Step: 3
Training loss: 2.54233516177521
Validation loss: 2.4638634519262697

Epoch: 5| Step: 4
Training loss: 2.6267536300295724
Validation loss: 2.4721798872329193

Epoch: 5| Step: 5
Training loss: 2.414403502443932
Validation loss: 2.460325453604743

Epoch: 5| Step: 6
Training loss: 2.382876936244533
Validation loss: 2.495160349692162

Epoch: 5| Step: 7
Training loss: 2.8700090292545997
Validation loss: 2.4869363205233066

Epoch: 5| Step: 8
Training loss: 2.568178723150032
Validation loss: 2.4897740396109684

Epoch: 5| Step: 9
Training loss: 3.00756327599784
Validation loss: 2.4691201870054353

Epoch: 5| Step: 10
Training loss: 2.780897739690718
Validation loss: 2.4666145198911718

Epoch: 5| Step: 11
Training loss: 2.672935052472987
Validation loss: 2.4552711202571937

Epoch: 145| Step: 0
Training loss: 3.036207098188597
Validation loss: 2.466411577601011

Epoch: 5| Step: 1
Training loss: 2.0237662147781883
Validation loss: 2.462205424980461

Epoch: 5| Step: 2
Training loss: 2.5865341374113235
Validation loss: 2.4614987697070037

Epoch: 5| Step: 3
Training loss: 2.690356045526852
Validation loss: 2.465534780356151

Epoch: 5| Step: 4
Training loss: 2.1710583365820195
Validation loss: 2.467733254286043

Epoch: 5| Step: 5
Training loss: 2.642853107228383
Validation loss: 2.473182835083025

Epoch: 5| Step: 6
Training loss: 2.013393379141275
Validation loss: 2.472459271998414

Epoch: 5| Step: 7
Training loss: 2.602543093336466
Validation loss: 2.477156855585856

Epoch: 5| Step: 8
Training loss: 2.759716381759449
Validation loss: 2.4772341085307867

Epoch: 5| Step: 9
Training loss: 2.696491016974925
Validation loss: 2.4799883159431433

Epoch: 5| Step: 10
Training loss: 3.026973263620258
Validation loss: 2.4734838104250296

Epoch: 5| Step: 11
Training loss: 1.7892751775539564
Validation loss: 2.475206816345611

Epoch: 146| Step: 0
Training loss: 2.3809787385480723
Validation loss: 2.476257213143619

Epoch: 5| Step: 1
Training loss: 2.445251659087369
Validation loss: 2.47720316192551

Epoch: 5| Step: 2
Training loss: 2.7406844233787706
Validation loss: 2.4764063933357594

Epoch: 5| Step: 3
Training loss: 2.4744447143014776
Validation loss: 2.464619412215876

Epoch: 5| Step: 4
Training loss: 2.284018208706721
Validation loss: 2.4668747141344762

Epoch: 5| Step: 5
Training loss: 2.7068480502583627
Validation loss: 2.4646988476994656

Epoch: 5| Step: 6
Training loss: 2.744531222201466
Validation loss: 2.4671422052684964

Epoch: 5| Step: 7
Training loss: 2.3303026089606074
Validation loss: 2.4640035673426324

Epoch: 5| Step: 8
Training loss: 2.7644364556336485
Validation loss: 2.458197853967348

Epoch: 5| Step: 9
Training loss: 2.759702990901728
Validation loss: 2.459071126775605

Epoch: 5| Step: 10
Training loss: 2.4117289996137883
Validation loss: 2.459188774487373

Epoch: 5| Step: 11
Training loss: 3.330401148189408
Validation loss: 2.4616196509434083

Epoch: 147| Step: 0
Training loss: 2.636456330980746
Validation loss: 2.4604173261903743

Epoch: 5| Step: 1
Training loss: 2.2194954063263146
Validation loss: 2.456615354173751

Epoch: 5| Step: 2
Training loss: 2.41429635800928
Validation loss: 2.457187055328742

Epoch: 5| Step: 3
Training loss: 2.261144377359321
Validation loss: 2.462831864045506

Epoch: 5| Step: 4
Training loss: 2.904129074780148
Validation loss: 2.4619001372772105

Epoch: 5| Step: 5
Training loss: 2.1493760157142097
Validation loss: 2.4676736344269967

Epoch: 5| Step: 6
Training loss: 3.0063241422079656
Validation loss: 2.473036280350081

Epoch: 5| Step: 7
Training loss: 2.691637270110454
Validation loss: 2.4749352958839763

Epoch: 5| Step: 8
Training loss: 2.5060983664287395
Validation loss: 2.4773732772570427

Epoch: 5| Step: 9
Training loss: 2.6799619662020033
Validation loss: 2.4665125675222783

Epoch: 5| Step: 10
Training loss: 2.654241093939946
Validation loss: 2.462286770007209

Epoch: 5| Step: 11
Training loss: 2.4033528511358853
Validation loss: 2.462709073810247

Epoch: 148| Step: 0
Training loss: 2.1459221559184
Validation loss: 2.4551136071942157

Epoch: 5| Step: 1
Training loss: 2.8984235161703604
Validation loss: 2.453348676037065

Epoch: 5| Step: 2
Training loss: 2.428271208967511
Validation loss: 2.457256284596198

Epoch: 5| Step: 3
Training loss: 2.7738580948962293
Validation loss: 2.4627285933531833

Epoch: 5| Step: 4
Training loss: 2.8948717418978296
Validation loss: 2.463480282610853

Epoch: 5| Step: 5
Training loss: 1.987974071943803
Validation loss: 2.4660204110617028

Epoch: 5| Step: 6
Training loss: 2.4922091205101555
Validation loss: 2.468966048078421

Epoch: 5| Step: 7
Training loss: 2.531391375325922
Validation loss: 2.4696005309782456

Epoch: 5| Step: 8
Training loss: 2.7832062945431515
Validation loss: 2.4677118863077108

Epoch: 5| Step: 9
Training loss: 2.439228129948915
Validation loss: 2.472747254668084

Epoch: 5| Step: 10
Training loss: 2.5681720389734672
Validation loss: 2.4723212209505725

Epoch: 5| Step: 11
Training loss: 0.8428728347811608
Validation loss: 2.471914906426801

Epoch: 149| Step: 0
Training loss: 2.995622142692491
Validation loss: 2.4701060703285105

Epoch: 5| Step: 1
Training loss: 2.536254738868584
Validation loss: 2.4630859765413335

Epoch: 5| Step: 2
Training loss: 2.6151860569542262
Validation loss: 2.4658545644666257

Epoch: 5| Step: 3
Training loss: 1.8630100908646012
Validation loss: 2.4689298676907305

Epoch: 5| Step: 4
Training loss: 2.4413578120194903
Validation loss: 2.4658485577164786

Epoch: 5| Step: 5
Training loss: 2.3717012082888784
Validation loss: 2.462150359625893

Epoch: 5| Step: 6
Training loss: 2.553073384803288
Validation loss: 2.4603907870988886

Epoch: 5| Step: 7
Training loss: 2.5489472927721684
Validation loss: 2.4592605447856237

Epoch: 5| Step: 8
Training loss: 2.3252772381291176
Validation loss: 2.454093652771421

Epoch: 5| Step: 9
Training loss: 2.8311170062561515
Validation loss: 2.4534201353355316

Epoch: 5| Step: 10
Training loss: 2.8153975078372557
Validation loss: 2.4575054841095176

Epoch: 5| Step: 11
Training loss: 1.9921360981611678
Validation loss: 2.448962099296068

Epoch: 150| Step: 0
Training loss: 1.9620777477682563
Validation loss: 2.4563654294122514

Epoch: 5| Step: 1
Training loss: 2.7774978358880924
Validation loss: 2.4527740956465185

Epoch: 5| Step: 2
Training loss: 2.5650232499167576
Validation loss: 2.461008718761917

Epoch: 5| Step: 3
Training loss: 2.3931834175350204
Validation loss: 2.454750820163142

Epoch: 5| Step: 4
Training loss: 2.171168479992274
Validation loss: 2.4474229450000045

Epoch: 5| Step: 5
Training loss: 2.633065050277049
Validation loss: 2.451039819085792

Epoch: 5| Step: 6
Training loss: 2.800096755399643
Validation loss: 2.445623081540256

Epoch: 5| Step: 7
Training loss: 2.0277353250365
Validation loss: 2.4493383026553714

Epoch: 5| Step: 8
Training loss: 2.6242004266697116
Validation loss: 2.447044137246427

Epoch: 5| Step: 9
Training loss: 3.2075425366549206
Validation loss: 2.449834078081471

Epoch: 5| Step: 10
Training loss: 2.398930800215465
Validation loss: 2.4499824708194735

Epoch: 5| Step: 11
Training loss: 2.5958453068423903
Validation loss: 2.452548208278121

Epoch: 151| Step: 0
Training loss: 2.4669957749013975
Validation loss: 2.4541343345735935

Epoch: 5| Step: 1
Training loss: 2.666528271024352
Validation loss: 2.4570525289239775

Epoch: 5| Step: 2
Training loss: 2.4285225482637665
Validation loss: 2.4576288940826725

Epoch: 5| Step: 3
Training loss: 2.1339061573992484
Validation loss: 2.4578305770231883

Epoch: 5| Step: 4
Training loss: 2.889445296118737
Validation loss: 2.461686039671688

Epoch: 5| Step: 5
Training loss: 2.076366397504788
Validation loss: 2.4663207137482774

Epoch: 5| Step: 6
Training loss: 2.4689313604640986
Validation loss: 2.4634014409637843

Epoch: 5| Step: 7
Training loss: 2.963054936579803
Validation loss: 2.4636798413959715

Epoch: 5| Step: 8
Training loss: 2.5369271557266155
Validation loss: 2.459542431074175

Epoch: 5| Step: 9
Training loss: 2.7791072006002175
Validation loss: 2.4591130512597292

Epoch: 5| Step: 10
Training loss: 2.40258341268334
Validation loss: 2.4595885641718898

Epoch: 5| Step: 11
Training loss: 2.2182265187988337
Validation loss: 2.4497351256714857

Epoch: 152| Step: 0
Training loss: 2.778902756391447
Validation loss: 2.454725626117836

Epoch: 5| Step: 1
Training loss: 2.3759916142787723
Validation loss: 2.4526277309432527

Epoch: 5| Step: 2
Training loss: 2.446166453077572
Validation loss: 2.4479654401965916

Epoch: 5| Step: 3
Training loss: 2.4990697083506985
Validation loss: 2.4474420872033074

Epoch: 5| Step: 4
Training loss: 2.0985374943817248
Validation loss: 2.4514600161414846

Epoch: 5| Step: 5
Training loss: 2.4714036996189996
Validation loss: 2.456237490899586

Epoch: 5| Step: 6
Training loss: 2.5749716229402906
Validation loss: 2.4619192072668192

Epoch: 5| Step: 7
Training loss: 2.7767993591982654
Validation loss: 2.459607195688081

Epoch: 5| Step: 8
Training loss: 2.801797381893157
Validation loss: 2.451910564674531

Epoch: 5| Step: 9
Training loss: 2.2627795009896294
Validation loss: 2.4511130681778943

Epoch: 5| Step: 10
Training loss: 2.7114799022854745
Validation loss: 2.4527897899346027

Epoch: 5| Step: 11
Training loss: 1.6826919299953162
Validation loss: 2.4522731257592154

Epoch: 153| Step: 0
Training loss: 2.528624409127481
Validation loss: 2.4482593878136876

Epoch: 5| Step: 1
Training loss: 3.2391101618350264
Validation loss: 2.45480040418666

Epoch: 5| Step: 2
Training loss: 2.4150981965250695
Validation loss: 2.4522050967216495

Epoch: 5| Step: 3
Training loss: 2.21914024682051
Validation loss: 2.45271381852143

Epoch: 5| Step: 4
Training loss: 2.8138031377735953
Validation loss: 2.453693988035735

Epoch: 5| Step: 5
Training loss: 1.8898095508270714
Validation loss: 2.450561619715453

Epoch: 5| Step: 6
Training loss: 2.0106723471282195
Validation loss: 2.455122484743631

Epoch: 5| Step: 7
Training loss: 2.5562695378906937
Validation loss: 2.4534057205494335

Epoch: 5| Step: 8
Training loss: 3.1356147543010024
Validation loss: 2.463642659983597

Epoch: 5| Step: 9
Training loss: 2.1993958857531917
Validation loss: 2.4547525380675044

Epoch: 5| Step: 10
Training loss: 2.530089783564356
Validation loss: 2.4611702258961605

Epoch: 5| Step: 11
Training loss: 1.9341170402426673
Validation loss: 2.459038325559477

Epoch: 154| Step: 0
Training loss: 2.5279727960704244
Validation loss: 2.4601184995922103

Epoch: 5| Step: 1
Training loss: 2.1468215691415637
Validation loss: 2.4579602392132283

Epoch: 5| Step: 2
Training loss: 2.4903635268285744
Validation loss: 2.4567108309251253

Epoch: 5| Step: 3
Training loss: 2.4148758687722167
Validation loss: 2.4511076109467442

Epoch: 5| Step: 4
Training loss: 2.7308910736352687
Validation loss: 2.457498794004313

Epoch: 5| Step: 5
Training loss: 2.9468991485933107
Validation loss: 2.4562029066416455

Epoch: 5| Step: 6
Training loss: 2.343960968695109
Validation loss: 2.4524675164451617

Epoch: 5| Step: 7
Training loss: 2.6954285527551667
Validation loss: 2.4493794284581627

Epoch: 5| Step: 8
Training loss: 2.5117992429753855
Validation loss: 2.4582894908637827

Epoch: 5| Step: 9
Training loss: 2.399106407702867
Validation loss: 2.4590391799842912

Epoch: 5| Step: 10
Training loss: 2.361991896309384
Validation loss: 2.4631272196539906

Epoch: 5| Step: 11
Training loss: 2.3375409087002974
Validation loss: 2.4572577521191237

Epoch: 155| Step: 0
Training loss: 2.056117151485076
Validation loss: 2.45618168102503

Epoch: 5| Step: 1
Training loss: 1.8784618843563514
Validation loss: 2.4534901673157696

Epoch: 5| Step: 2
Training loss: 3.103107365522574
Validation loss: 2.4534509000929323

Epoch: 5| Step: 3
Training loss: 2.326047136499921
Validation loss: 2.4585433819038616

Epoch: 5| Step: 4
Training loss: 2.166259641807481
Validation loss: 2.4566917083745854

Epoch: 5| Step: 5
Training loss: 2.789099685036386
Validation loss: 2.4479429946998645

Epoch: 5| Step: 6
Training loss: 2.5887721449689027
Validation loss: 2.455926625608364

Epoch: 5| Step: 7
Training loss: 2.5497980486616467
Validation loss: 2.4518306135778345

Epoch: 5| Step: 8
Training loss: 2.864921152251518
Validation loss: 2.449859571811521

Epoch: 5| Step: 9
Training loss: 2.4085418883663072
Validation loss: 2.4594320587105507

Epoch: 5| Step: 10
Training loss: 2.7813416369482766
Validation loss: 2.4534873006435136

Epoch: 5| Step: 11
Training loss: 1.8951983663562386
Validation loss: 2.4633378367281757

Epoch: 156| Step: 0
Training loss: 2.655505984955186
Validation loss: 2.458773397131695

Epoch: 5| Step: 1
Training loss: 2.9681424774150167
Validation loss: 2.4567786523046093

Epoch: 5| Step: 2
Training loss: 2.3363117441312022
Validation loss: 2.4542434961008

Epoch: 5| Step: 3
Training loss: 2.3100466730926574
Validation loss: 2.4477605458789777

Epoch: 5| Step: 4
Training loss: 2.3424035846161644
Validation loss: 2.4470938875748143

Epoch: 5| Step: 5
Training loss: 2.629221654962794
Validation loss: 2.452596838397337

Epoch: 5| Step: 6
Training loss: 2.5794334097021947
Validation loss: 2.452744324824907

Epoch: 5| Step: 7
Training loss: 2.562233515583407
Validation loss: 2.448004472794555

Epoch: 5| Step: 8
Training loss: 1.8671265915389312
Validation loss: 2.448301850443904

Epoch: 5| Step: 9
Training loss: 3.035687531425484
Validation loss: 2.4439719509917865

Epoch: 5| Step: 10
Training loss: 2.4376421177832626
Validation loss: 2.4432084290787177

Epoch: 5| Step: 11
Training loss: 1.6492877231994678
Validation loss: 2.446752175195515

Epoch: 157| Step: 0
Training loss: 2.7984807184184533
Validation loss: 2.4472324037237847

Epoch: 5| Step: 1
Training loss: 1.8607153669458234
Validation loss: 2.447028929804264

Epoch: 5| Step: 2
Training loss: 2.145678826358924
Validation loss: 2.451341989396974

Epoch: 5| Step: 3
Training loss: 2.708086080757899
Validation loss: 2.4419533200539565

Epoch: 5| Step: 4
Training loss: 2.919093802418712
Validation loss: 2.447511579936204

Epoch: 5| Step: 5
Training loss: 2.276163989751122
Validation loss: 2.4514969649428684

Epoch: 5| Step: 6
Training loss: 2.954616593791586
Validation loss: 2.453291897451899

Epoch: 5| Step: 7
Training loss: 2.465216123380087
Validation loss: 2.4457039362348523

Epoch: 5| Step: 8
Training loss: 2.2915206053454766
Validation loss: 2.448170635900795

Epoch: 5| Step: 9
Training loss: 2.322846130759909
Validation loss: 2.4480564983822566

Epoch: 5| Step: 10
Training loss: 2.6269574814090273
Validation loss: 2.449322497022622

Epoch: 5| Step: 11
Training loss: 2.3447333752439032
Validation loss: 2.4539107827775544

Epoch: 158| Step: 0
Training loss: 2.238168124390916
Validation loss: 2.4481513512843667

Epoch: 5| Step: 1
Training loss: 2.986905128916134
Validation loss: 2.4510025168546945

Epoch: 5| Step: 2
Training loss: 2.3124620589159472
Validation loss: 2.4529737357055246

Epoch: 5| Step: 3
Training loss: 2.3399222079004844
Validation loss: 2.4547179308647507

Epoch: 5| Step: 4
Training loss: 2.5316101571515643
Validation loss: 2.45623937560834

Epoch: 5| Step: 5
Training loss: 2.387847283954579
Validation loss: 2.456950199991887

Epoch: 5| Step: 6
Training loss: 2.628842946802383
Validation loss: 2.4527289319877905

Epoch: 5| Step: 7
Training loss: 2.8381742373767302
Validation loss: 2.4543044986350435

Epoch: 5| Step: 8
Training loss: 2.294648629012172
Validation loss: 2.4548747105621183

Epoch: 5| Step: 9
Training loss: 2.620928558738251
Validation loss: 2.455496081512552

Epoch: 5| Step: 10
Training loss: 2.355157075571915
Validation loss: 2.451806335609244

Epoch: 5| Step: 11
Training loss: 1.9930794308687436
Validation loss: 2.4580517596828857

Epoch: 159| Step: 0
Training loss: 2.447977582024792
Validation loss: 2.4545864360424714

Epoch: 5| Step: 1
Training loss: 2.6294713766190694
Validation loss: 2.454891180519452

Epoch: 5| Step: 2
Training loss: 2.5172277995505934
Validation loss: 2.4543061581612697

Epoch: 5| Step: 3
Training loss: 2.5372722241628027
Validation loss: 2.4526058668215898

Epoch: 5| Step: 4
Training loss: 2.3701851877863587
Validation loss: 2.451470142875394

Epoch: 5| Step: 5
Training loss: 2.4884397255632353
Validation loss: 2.4571425307100445

Epoch: 5| Step: 6
Training loss: 2.9543738575435436
Validation loss: 2.4569498805737156

Epoch: 5| Step: 7
Training loss: 2.1791324250525776
Validation loss: 2.453038179679481

Epoch: 5| Step: 8
Training loss: 2.4515487563536347
Validation loss: 2.4599741589215003

Epoch: 5| Step: 9
Training loss: 2.5643589441185894
Validation loss: 2.45844299400488

Epoch: 5| Step: 10
Training loss: 2.352002378365229
Validation loss: 2.45744471869086

Epoch: 5| Step: 11
Training loss: 2.3976053291549237
Validation loss: 2.4598243052523725

Epoch: 160| Step: 0
Training loss: 2.4525143780612515
Validation loss: 2.4584371186563176

Epoch: 5| Step: 1
Training loss: 2.2933378426189597
Validation loss: 2.453845118866687

Epoch: 5| Step: 2
Training loss: 2.082113582851164
Validation loss: 2.4534845999760506

Epoch: 5| Step: 3
Training loss: 2.765884473449893
Validation loss: 2.4492453736435498

Epoch: 5| Step: 4
Training loss: 2.3287444858618835
Validation loss: 2.453291403437618

Epoch: 5| Step: 5
Training loss: 2.45853803612125
Validation loss: 2.455150420086228

Epoch: 5| Step: 6
Training loss: 2.470570918831926
Validation loss: 2.4520629357456745

Epoch: 5| Step: 7
Training loss: 2.116910008337255
Validation loss: 2.4589292779132528

Epoch: 5| Step: 8
Training loss: 3.1213953209085274
Validation loss: 2.4537345873957066

Epoch: 5| Step: 9
Training loss: 2.6393028425379508
Validation loss: 2.4615466014992253

Epoch: 5| Step: 10
Training loss: 2.651174205971791
Validation loss: 2.457701601201005

Epoch: 5| Step: 11
Training loss: 2.2030844177404263
Validation loss: 2.448823820941871

Epoch: 161| Step: 0
Training loss: 3.1227517241999325
Validation loss: 2.4492987498512195

Epoch: 5| Step: 1
Training loss: 2.5928924245884715
Validation loss: 2.4500073507419264

Epoch: 5| Step: 2
Training loss: 2.851101940011768
Validation loss: 2.455769174815569

Epoch: 5| Step: 3
Training loss: 2.410831795709645
Validation loss: 2.4587396768102088

Epoch: 5| Step: 4
Training loss: 2.287855018623924
Validation loss: 2.45332030310574

Epoch: 5| Step: 5
Training loss: 2.1675831494777547
Validation loss: 2.452315215072064

Epoch: 5| Step: 6
Training loss: 2.674838291164648
Validation loss: 2.4540401480909404

Epoch: 5| Step: 7
Training loss: 2.0933700900080314
Validation loss: 2.457415920079154

Epoch: 5| Step: 8
Training loss: 2.4979877957060435
Validation loss: 2.452960116115695

Epoch: 5| Step: 9
Training loss: 2.2101361335494247
Validation loss: 2.4595196994414708

Epoch: 5| Step: 10
Training loss: 2.493470247490848
Validation loss: 2.450909328711406

Epoch: 5| Step: 11
Training loss: 1.4813469770531684
Validation loss: 2.4536878138620137

Epoch: 162| Step: 0
Training loss: 2.704982670501085
Validation loss: 2.456080379566582

Epoch: 5| Step: 1
Training loss: 2.7463783344604313
Validation loss: 2.457035543804935

Epoch: 5| Step: 2
Training loss: 2.593653849462669
Validation loss: 2.4631782543275387

Epoch: 5| Step: 3
Training loss: 2.7165937094067867
Validation loss: 2.4602507627101144

Epoch: 5| Step: 4
Training loss: 2.6234724959219853
Validation loss: 2.464114771038374

Epoch: 5| Step: 5
Training loss: 2.287762998877284
Validation loss: 2.472470666751874

Epoch: 5| Step: 6
Training loss: 2.425405377985007
Validation loss: 2.461417782051676

Epoch: 5| Step: 7
Training loss: 2.5595609045456156
Validation loss: 2.454952168982816

Epoch: 5| Step: 8
Training loss: 2.1687421639160713
Validation loss: 2.4567579472192875

Epoch: 5| Step: 9
Training loss: 2.1157443487629854
Validation loss: 2.462091915894434

Epoch: 5| Step: 10
Training loss: 2.5703401419130105
Validation loss: 2.4551686725695876

Epoch: 5| Step: 11
Training loss: 1.795793025131607
Validation loss: 2.4575658155044624

Epoch: 163| Step: 0
Training loss: 2.242237263303393
Validation loss: 2.462366099194554

Epoch: 5| Step: 1
Training loss: 2.6421708316829906
Validation loss: 2.460289384379703

Epoch: 5| Step: 2
Training loss: 2.4535860248019663
Validation loss: 2.4602770085526373

Epoch: 5| Step: 3
Training loss: 2.6558929203348294
Validation loss: 2.4546582538943453

Epoch: 5| Step: 4
Training loss: 2.7296026818254453
Validation loss: 2.463751202651888

Epoch: 5| Step: 5
Training loss: 2.6996483467831625
Validation loss: 2.4526908879162037

Epoch: 5| Step: 6
Training loss: 2.2201811781831546
Validation loss: 2.4561951007483227

Epoch: 5| Step: 7
Training loss: 2.1842948320382582
Validation loss: 2.460043719631368

Epoch: 5| Step: 8
Training loss: 2.404597321741027
Validation loss: 2.4484372187461925

Epoch: 5| Step: 9
Training loss: 2.6322825999393764
Validation loss: 2.458800123369987

Epoch: 5| Step: 10
Training loss: 2.3762361421537186
Validation loss: 2.461978147369447

Epoch: 5| Step: 11
Training loss: 3.07995334292656
Validation loss: 2.4604421813464485

Epoch: 164| Step: 0
Training loss: 2.317805621787691
Validation loss: 2.460537190652173

Epoch: 5| Step: 1
Training loss: 2.5951083200004197
Validation loss: 2.463116519742053

Epoch: 5| Step: 2
Training loss: 2.3197273518406085
Validation loss: 2.47261444667133

Epoch: 5| Step: 3
Training loss: 2.6710669650899113
Validation loss: 2.474113577271738

Epoch: 5| Step: 4
Training loss: 2.8191196952001665
Validation loss: 2.4722283180360494

Epoch: 5| Step: 5
Training loss: 2.6256460575529705
Validation loss: 2.4568489463949588

Epoch: 5| Step: 6
Training loss: 2.262076499461613
Validation loss: 2.462919529002327

Epoch: 5| Step: 7
Training loss: 2.5275024175585195
Validation loss: 2.458203073191727

Epoch: 5| Step: 8
Training loss: 2.0892936766941994
Validation loss: 2.455430658238986

Epoch: 5| Step: 9
Training loss: 2.8134397843938577
Validation loss: 2.4532405396807797

Epoch: 5| Step: 10
Training loss: 2.2579330887320195
Validation loss: 2.4538687167838997

Epoch: 5| Step: 11
Training loss: 2.581913516870744
Validation loss: 2.4558449505843045

Epoch: 165| Step: 0
Training loss: 2.333413179484642
Validation loss: 2.4546385224569764

Epoch: 5| Step: 1
Training loss: 2.3430724118187998
Validation loss: 2.44759821883364

Epoch: 5| Step: 2
Training loss: 2.0531555963149613
Validation loss: 2.458451956510922

Epoch: 5| Step: 3
Training loss: 1.9245766359939322
Validation loss: 2.4597199188035916

Epoch: 5| Step: 4
Training loss: 2.152534601019841
Validation loss: 2.4594181456895265

Epoch: 5| Step: 5
Training loss: 3.0952060240177426
Validation loss: 2.4661123252668107

Epoch: 5| Step: 6
Training loss: 2.6563244977489684
Validation loss: 2.462331887459536

Epoch: 5| Step: 7
Training loss: 2.5832439120003206
Validation loss: 2.4677418972345198

Epoch: 5| Step: 8
Training loss: 2.5219903817897174
Validation loss: 2.4620199618272722

Epoch: 5| Step: 9
Training loss: 2.5065778979180555
Validation loss: 2.4641405766094664

Epoch: 5| Step: 10
Training loss: 3.2399996441970442
Validation loss: 2.46414565222428

Epoch: 5| Step: 11
Training loss: 1.6976636062230965
Validation loss: 2.46355021006828

Epoch: 166| Step: 0
Training loss: 2.835984074654139
Validation loss: 2.460807054079852

Epoch: 5| Step: 1
Training loss: 2.2791111992241526
Validation loss: 2.457533845102498

Epoch: 5| Step: 2
Training loss: 2.1834983190657127
Validation loss: 2.4600336544389054

Epoch: 5| Step: 3
Training loss: 2.9784591119126427
Validation loss: 2.4559083342633525

Epoch: 5| Step: 4
Training loss: 2.5924174551113794
Validation loss: 2.4532936669940395

Epoch: 5| Step: 5
Training loss: 2.580194186214328
Validation loss: 2.458548606455682

Epoch: 5| Step: 6
Training loss: 2.6531819295897265
Validation loss: 2.4670687314502127

Epoch: 5| Step: 7
Training loss: 2.071908012115631
Validation loss: 2.4594842121478098

Epoch: 5| Step: 8
Training loss: 1.9905598891791871
Validation loss: 2.4618535632707483

Epoch: 5| Step: 9
Training loss: 2.568345264932724
Validation loss: 2.452562806326234

Epoch: 5| Step: 10
Training loss: 2.604017227971385
Validation loss: 2.456516881167435

Epoch: 5| Step: 11
Training loss: 1.8818206073827444
Validation loss: 2.455000324579439

Epoch: 167| Step: 0
Training loss: 2.3617885951529574
Validation loss: 2.4539863669696325

Epoch: 5| Step: 1
Training loss: 2.632562551887345
Validation loss: 2.4621609063827914

Epoch: 5| Step: 2
Training loss: 2.353422221629446
Validation loss: 2.453906588760315

Epoch: 5| Step: 3
Training loss: 2.300468902888439
Validation loss: 2.4580859380366977

Epoch: 5| Step: 4
Training loss: 2.5981990849345693
Validation loss: 2.4675031402500918

Epoch: 5| Step: 5
Training loss: 2.381228661629295
Validation loss: 2.466949961531475

Epoch: 5| Step: 6
Training loss: 2.6130764229508094
Validation loss: 2.4695841430290297

Epoch: 5| Step: 7
Training loss: 2.5692013828911135
Validation loss: 2.472796307093001

Epoch: 5| Step: 8
Training loss: 2.4570609425993024
Validation loss: 2.478265535780078

Epoch: 5| Step: 9
Training loss: 2.73959549779089
Validation loss: 2.469095258271353

Epoch: 5| Step: 10
Training loss: 2.385026847160431
Validation loss: 2.4603652975117876

Epoch: 5| Step: 11
Training loss: 1.9265379125259015
Validation loss: 2.4653147888688753

Epoch: 168| Step: 0
Training loss: 2.4273436792801526
Validation loss: 2.4581417269040218

Epoch: 5| Step: 1
Training loss: 2.521875612620453
Validation loss: 2.4646899885208016

Epoch: 5| Step: 2
Training loss: 2.2560844804488958
Validation loss: 2.4616023704519048

Epoch: 5| Step: 3
Training loss: 1.8525247125869169
Validation loss: 2.469740166054102

Epoch: 5| Step: 4
Training loss: 2.671969763430532
Validation loss: 2.465284083512052

Epoch: 5| Step: 5
Training loss: 2.2041580267330025
Validation loss: 2.4661777431165133

Epoch: 5| Step: 6
Training loss: 2.966854574560296
Validation loss: 2.465811453321802

Epoch: 5| Step: 7
Training loss: 2.6687683426452216
Validation loss: 2.465147826899351

Epoch: 5| Step: 8
Training loss: 2.339435318850253
Validation loss: 2.466984000499579

Epoch: 5| Step: 9
Training loss: 2.3740820867652634
Validation loss: 2.4693682737394833

Epoch: 5| Step: 10
Training loss: 2.9584431874111843
Validation loss: 2.466946212504855

Epoch: 5| Step: 11
Training loss: 1.949052455742273
Validation loss: 2.4712689220544686

Epoch: 169| Step: 0
Training loss: 2.9318647508639275
Validation loss: 2.4698086854779246

Epoch: 5| Step: 1
Training loss: 2.3406866781056013
Validation loss: 2.470570124688951

Epoch: 5| Step: 2
Training loss: 2.68584426620425
Validation loss: 2.4770622912369546

Epoch: 5| Step: 3
Training loss: 2.7180270406684572
Validation loss: 2.466923351775632

Epoch: 5| Step: 4
Training loss: 2.5368605235444
Validation loss: 2.477542194048213

Epoch: 5| Step: 5
Training loss: 2.678284035660032
Validation loss: 2.4691019752944383

Epoch: 5| Step: 6
Training loss: 2.51919501375012
Validation loss: 2.4794345091273278

Epoch: 5| Step: 7
Training loss: 2.0422305930741724
Validation loss: 2.472713467788176

Epoch: 5| Step: 8
Training loss: 1.7372274912365344
Validation loss: 2.4591904993904965

Epoch: 5| Step: 9
Training loss: 2.630469029162862
Validation loss: 2.4579687184885133

Epoch: 5| Step: 10
Training loss: 2.223838987580235
Validation loss: 2.4583771480815293

Epoch: 5| Step: 11
Training loss: 2.122200411983526
Validation loss: 2.4581472331798033

Epoch: 170| Step: 0
Training loss: 2.157123665106217
Validation loss: 2.45718073225943

Epoch: 5| Step: 1
Training loss: 1.848373951146019
Validation loss: 2.4540036464415094

Epoch: 5| Step: 2
Training loss: 2.3559881494868478
Validation loss: 2.453810067707165

Epoch: 5| Step: 3
Training loss: 3.0927074486763444
Validation loss: 2.4579132833833155

Epoch: 5| Step: 4
Training loss: 2.801293574976887
Validation loss: 2.446646869656855

Epoch: 5| Step: 5
Training loss: 2.3522153436080377
Validation loss: 2.4563514403798594

Epoch: 5| Step: 6
Training loss: 2.202380981347122
Validation loss: 2.45264856607901

Epoch: 5| Step: 7
Training loss: 2.8071964698367076
Validation loss: 2.4539010790414464

Epoch: 5| Step: 8
Training loss: 2.438633875113147
Validation loss: 2.456486466198446

Epoch: 5| Step: 9
Training loss: 2.658209044641186
Validation loss: 2.4727933141596496

Epoch: 5| Step: 10
Training loss: 2.296977138194604
Validation loss: 2.48508057081829

Epoch: 5| Step: 11
Training loss: 2.1555503041682997
Validation loss: 2.479095767847967

Epoch: 171| Step: 0
Training loss: 2.788188637146392
Validation loss: 2.475523978617317

Epoch: 5| Step: 1
Training loss: 2.7936538816298375
Validation loss: 2.4740592226571527

Epoch: 5| Step: 2
Training loss: 2.4488977833386527
Validation loss: 2.4850160763288964

Epoch: 5| Step: 3
Training loss: 2.995672760870614
Validation loss: 2.482582505274261

Epoch: 5| Step: 4
Training loss: 2.3287759165363457
Validation loss: 2.4829812848940964

Epoch: 5| Step: 5
Training loss: 2.264715288301523
Validation loss: 2.4846607739653574

Epoch: 5| Step: 6
Training loss: 2.6138843245358894
Validation loss: 2.4812883720025254

Epoch: 5| Step: 7
Training loss: 2.7097082511697677
Validation loss: 2.484357733836444

Epoch: 5| Step: 8
Training loss: 2.0315506932634775
Validation loss: 2.4797349680487812

Epoch: 5| Step: 9
Training loss: 2.018309468958562
Validation loss: 2.476072918848875

Epoch: 5| Step: 10
Training loss: 2.2924766727371395
Validation loss: 2.469316262679703

Epoch: 5| Step: 11
Training loss: 1.794091432089281
Validation loss: 2.4672184551439984

Epoch: 172| Step: 0
Training loss: 2.6178606221025924
Validation loss: 2.4677006265807884

Epoch: 5| Step: 1
Training loss: 1.5710609891673046
Validation loss: 2.4698940796992224

Epoch: 5| Step: 2
Training loss: 2.323977674275247
Validation loss: 2.4657047579540246

Epoch: 5| Step: 3
Training loss: 2.5752810426690265
Validation loss: 2.4738146301829884

Epoch: 5| Step: 4
Training loss: 2.5438335957955553
Validation loss: 2.4684661066220204

Epoch: 5| Step: 5
Training loss: 2.5763816719148314
Validation loss: 2.47034374332315

Epoch: 5| Step: 6
Training loss: 2.923955655931951
Validation loss: 2.462754962037497

Epoch: 5| Step: 7
Training loss: 2.628287844880091
Validation loss: 2.46093153372551

Epoch: 5| Step: 8
Training loss: 2.580219042594984
Validation loss: 2.459997411328533

Epoch: 5| Step: 9
Training loss: 2.518063044994242
Validation loss: 2.464578548780383

Epoch: 5| Step: 10
Training loss: 1.9819204212999992
Validation loss: 2.4636448414484033

Epoch: 5| Step: 11
Training loss: 3.4110608206599324
Validation loss: 2.4694507022969563

Epoch: 173| Step: 0
Training loss: 2.542781043559559
Validation loss: 2.4544809930818854

Epoch: 5| Step: 1
Training loss: 3.135753440302139
Validation loss: 2.464989369197307

Epoch: 5| Step: 2
Training loss: 2.25734507860319
Validation loss: 2.4739165426371965

Epoch: 5| Step: 3
Training loss: 2.0273059995807934
Validation loss: 2.466050587593639

Epoch: 5| Step: 4
Training loss: 2.2846526805596894
Validation loss: 2.4547908617933616

Epoch: 5| Step: 5
Training loss: 2.2276764877051853
Validation loss: 2.4632020612740573

Epoch: 5| Step: 6
Training loss: 2.8051449713413565
Validation loss: 2.466827513201707

Epoch: 5| Step: 7
Training loss: 2.248166714944876
Validation loss: 2.4612710595509424

Epoch: 5| Step: 8
Training loss: 2.381167985600128
Validation loss: 2.460966705471903

Epoch: 5| Step: 9
Training loss: 2.7424298040818043
Validation loss: 2.46502675799264

Epoch: 5| Step: 10
Training loss: 2.373349369062763
Validation loss: 2.4578559191005724

Epoch: 5| Step: 11
Training loss: 2.0288683500337816
Validation loss: 2.4702696328220886

Epoch: 174| Step: 0
Training loss: 2.70491189273757
Validation loss: 2.470999007168103

Epoch: 5| Step: 1
Training loss: 2.521349441617402
Validation loss: 2.480225911105523

Epoch: 5| Step: 2
Training loss: 2.546109230670997
Validation loss: 2.483625502861871

Epoch: 5| Step: 3
Training loss: 2.468874191830246
Validation loss: 2.4748374033028337

Epoch: 5| Step: 4
Training loss: 2.048795308885786
Validation loss: 2.473354865641918

Epoch: 5| Step: 5
Training loss: 2.4967633276114145
Validation loss: 2.4663648511448915

Epoch: 5| Step: 6
Training loss: 2.7572264656531114
Validation loss: 2.468937150484877

Epoch: 5| Step: 7
Training loss: 2.4700748413732048
Validation loss: 2.4550976485652316

Epoch: 5| Step: 8
Training loss: 2.8156661120598176
Validation loss: 2.4628700217167476

Epoch: 5| Step: 9
Training loss: 2.235997817787375
Validation loss: 2.4596110084067107

Epoch: 5| Step: 10
Training loss: 2.234292408943948
Validation loss: 2.4690895772528396

Epoch: 5| Step: 11
Training loss: 1.3686778201924497
Validation loss: 2.469765969159768

Epoch: 175| Step: 0
Training loss: 2.412284813805928
Validation loss: 2.4609744437537837

Epoch: 5| Step: 1
Training loss: 1.8246946183849941
Validation loss: 2.4594218112702735

Epoch: 5| Step: 2
Training loss: 2.3502625582501206
Validation loss: 2.458780152453222

Epoch: 5| Step: 3
Training loss: 2.9911020566108277
Validation loss: 2.4633334611545097

Epoch: 5| Step: 4
Training loss: 2.592137306467826
Validation loss: 2.4634293066186372

Epoch: 5| Step: 5
Training loss: 2.5548843167984927
Validation loss: 2.466134500662127

Epoch: 5| Step: 6
Training loss: 2.3992347013687922
Validation loss: 2.471607220754341

Epoch: 5| Step: 7
Training loss: 2.5635792390151457
Validation loss: 2.4655073776843883

Epoch: 5| Step: 8
Training loss: 2.175569424685123
Validation loss: 2.4725933458664366

Epoch: 5| Step: 9
Training loss: 2.472849761477752
Validation loss: 2.470866499212378

Epoch: 5| Step: 10
Training loss: 2.5158562405851046
Validation loss: 2.476840724619678

Epoch: 5| Step: 11
Training loss: 2.833083048218931
Validation loss: 2.473001410814015

Epoch: 176| Step: 0
Training loss: 2.4414687492000207
Validation loss: 2.480183714662078

Epoch: 5| Step: 1
Training loss: 2.7404447489741837
Validation loss: 2.476100978908569

Epoch: 5| Step: 2
Training loss: 2.1226218885238666
Validation loss: 2.4749477991064377

Epoch: 5| Step: 3
Training loss: 2.119365064979605
Validation loss: 2.483414566281679

Epoch: 5| Step: 4
Training loss: 2.8341775272306733
Validation loss: 2.4905190418572074

Epoch: 5| Step: 5
Training loss: 2.3767603323493094
Validation loss: 2.48256966435831

Epoch: 5| Step: 6
Training loss: 2.361115678770347
Validation loss: 2.485530262776212

Epoch: 5| Step: 7
Training loss: 2.7485153352040013
Validation loss: 2.484369301939374

Epoch: 5| Step: 8
Training loss: 2.594006812928605
Validation loss: 2.472955493788233

Epoch: 5| Step: 9
Training loss: 2.451017409849181
Validation loss: 2.471372748339585

Epoch: 5| Step: 10
Training loss: 2.1707144730940438
Validation loss: 2.478033345031988

Epoch: 5| Step: 11
Training loss: 1.9088918171318507
Validation loss: 2.466405747415296

Epoch: 177| Step: 0
Training loss: 2.9074822551418684
Validation loss: 2.4685851275441557

Epoch: 5| Step: 1
Training loss: 2.2921602815703555
Validation loss: 2.4608265523777266

Epoch: 5| Step: 2
Training loss: 2.0199262280731713
Validation loss: 2.4601996047204597

Epoch: 5| Step: 3
Training loss: 2.1412414999557647
Validation loss: 2.4601430589538897

Epoch: 5| Step: 4
Training loss: 2.8449982638764406
Validation loss: 2.462461181518618

Epoch: 5| Step: 5
Training loss: 2.7170168734782236
Validation loss: 2.466131286148515

Epoch: 5| Step: 6
Training loss: 2.2891507180566437
Validation loss: 2.4619001433299177

Epoch: 5| Step: 7
Training loss: 2.431502274710054
Validation loss: 2.470864778439736

Epoch: 5| Step: 8
Training loss: 2.788932305724595
Validation loss: 2.4836847957991632

Epoch: 5| Step: 9
Training loss: 2.3151592738684106
Validation loss: 2.4810528165168617

Epoch: 5| Step: 10
Training loss: 2.3696582351400775
Validation loss: 2.4754727128901344

Epoch: 5| Step: 11
Training loss: 1.087499469450021
Validation loss: 2.4828594111305424

Epoch: 178| Step: 0
Training loss: 3.527279402271594
Validation loss: 2.4875859477340256

Epoch: 5| Step: 1
Training loss: 2.033230681512047
Validation loss: 2.486584738299188

Epoch: 5| Step: 2
Training loss: 2.2411837042190736
Validation loss: 2.483664617000378

Epoch: 5| Step: 3
Training loss: 2.354002842787174
Validation loss: 2.4859261119077374

Epoch: 5| Step: 4
Training loss: 2.638020240856429
Validation loss: 2.4829043668056174

Epoch: 5| Step: 5
Training loss: 2.315368213907434
Validation loss: 2.483681360015272

Epoch: 5| Step: 6
Training loss: 2.1564145232750143
Validation loss: 2.4830810568078805

Epoch: 5| Step: 7
Training loss: 2.120525923398009
Validation loss: 2.481303085220504

Epoch: 5| Step: 8
Training loss: 2.6782179826332286
Validation loss: 2.4852255878611125

Epoch: 5| Step: 9
Training loss: 1.9605514936740462
Validation loss: 2.484208135379238

Epoch: 5| Step: 10
Training loss: 2.3217596300093204
Validation loss: 2.4716377028656504

Epoch: 5| Step: 11
Training loss: 3.579230658270369
Validation loss: 2.472593313724936

Epoch: 179| Step: 0
Training loss: 2.4028719685736855
Validation loss: 2.487148971486064

Epoch: 5| Step: 1
Training loss: 2.668425804297502
Validation loss: 2.5124812533500047

Epoch: 5| Step: 2
Training loss: 2.448864876280742
Validation loss: 2.5182790912359274

Epoch: 5| Step: 3
Training loss: 2.3708113827440656
Validation loss: 2.5152684269015158

Epoch: 5| Step: 4
Training loss: 2.4165716371816117
Validation loss: 2.516748063137463

Epoch: 5| Step: 5
Training loss: 2.148650890503498
Validation loss: 2.4916445181467175

Epoch: 5| Step: 6
Training loss: 2.155717977596301
Validation loss: 2.492816227895809

Epoch: 5| Step: 7
Training loss: 3.0723337601213743
Validation loss: 2.4822881679107387

Epoch: 5| Step: 8
Training loss: 2.4913853038865494
Validation loss: 2.468068471425277

Epoch: 5| Step: 9
Training loss: 2.457657726577702
Validation loss: 2.463851426686889

Epoch: 5| Step: 10
Training loss: 2.545988150809524
Validation loss: 2.461181083613294

Epoch: 5| Step: 11
Training loss: 1.1901555735408487
Validation loss: 2.4679546604154816

Epoch: 180| Step: 0
Training loss: 2.1864622651880055
Validation loss: 2.4614823923914075

Epoch: 5| Step: 1
Training loss: 2.957613485807959
Validation loss: 2.45810367567543

Epoch: 5| Step: 2
Training loss: 2.0374011290730873
Validation loss: 2.4567925155768697

Epoch: 5| Step: 3
Training loss: 2.585243339374322
Validation loss: 2.463670758796061

Epoch: 5| Step: 4
Training loss: 2.560906077314944
Validation loss: 2.4591990350174213

Epoch: 5| Step: 5
Training loss: 2.7569210351504765
Validation loss: 2.458647499107074

Epoch: 5| Step: 6
Training loss: 2.0719876404029107
Validation loss: 2.460084979423218

Epoch: 5| Step: 7
Training loss: 2.8261975206161916
Validation loss: 2.4590375680904226

Epoch: 5| Step: 8
Training loss: 2.688792605379532
Validation loss: 2.4623850324421745

Epoch: 5| Step: 9
Training loss: 2.592976558221851
Validation loss: 2.4601888860187517

Epoch: 5| Step: 10
Training loss: 2.2478059031361735
Validation loss: 2.470865498108814

Epoch: 5| Step: 11
Training loss: 1.3591728498613305
Validation loss: 2.4717001610808147

Epoch: 181| Step: 0
Training loss: 2.721214317610012
Validation loss: 2.472807011319616

Epoch: 5| Step: 1
Training loss: 2.4091315912178213
Validation loss: 2.4925145380099303

Epoch: 5| Step: 2
Training loss: 2.305214307673579
Validation loss: 2.4875885594640343

Epoch: 5| Step: 3
Training loss: 2.465719270052306
Validation loss: 2.4880654976578134

Epoch: 5| Step: 4
Training loss: 1.8208038583751487
Validation loss: 2.480534454036191

Epoch: 5| Step: 5
Training loss: 2.6465627510880556
Validation loss: 2.492637282773834

Epoch: 5| Step: 6
Training loss: 2.5665043502940192
Validation loss: 2.498756822796518

Epoch: 5| Step: 7
Training loss: 2.464452745767426
Validation loss: 2.4976425658944827

Epoch: 5| Step: 8
Training loss: 2.542414872986519
Validation loss: 2.482570112531004

Epoch: 5| Step: 9
Training loss: 2.5578909571224986
Validation loss: 2.491085685872135

Epoch: 5| Step: 10
Training loss: 2.492652203992928
Validation loss: 2.4886478411535324

Epoch: 5| Step: 11
Training loss: 2.1315399957063668
Validation loss: 2.483374224129843

Epoch: 182| Step: 0
Training loss: 2.758500399721057
Validation loss: 2.4816625330625617

Epoch: 5| Step: 1
Training loss: 2.1674871236205284
Validation loss: 2.472001465633929

Epoch: 5| Step: 2
Training loss: 2.019701952332899
Validation loss: 2.47229192459295

Epoch: 5| Step: 3
Training loss: 2.5758955129792476
Validation loss: 2.477341546432909

Epoch: 5| Step: 4
Training loss: 2.8176084960248358
Validation loss: 2.46952948356484

Epoch: 5| Step: 5
Training loss: 2.207229686357127
Validation loss: 2.4728375810822922

Epoch: 5| Step: 6
Training loss: 2.491458606857649
Validation loss: 2.4646198072230923

Epoch: 5| Step: 7
Training loss: 2.3397442982829677
Validation loss: 2.467457763061739

Epoch: 5| Step: 8
Training loss: 2.654499778823714
Validation loss: 2.474167328422546

Epoch: 5| Step: 9
Training loss: 2.0908037779224187
Validation loss: 2.475118848085693

Epoch: 5| Step: 10
Training loss: 2.676143872269473
Validation loss: 2.4744182533941084

Epoch: 5| Step: 11
Training loss: 2.0742290949159403
Validation loss: 2.483943359897024

Epoch: 183| Step: 0
Training loss: 2.4954752984204944
Validation loss: 2.485447194396109

Epoch: 5| Step: 1
Training loss: 2.350235269822331
Validation loss: 2.4847043976648764

Epoch: 5| Step: 2
Training loss: 2.2574854419192376
Validation loss: 2.4846867819546623

Epoch: 5| Step: 3
Training loss: 2.0413109086638612
Validation loss: 2.4805698804689724

Epoch: 5| Step: 4
Training loss: 2.7700094178793653
Validation loss: 2.4893774794753685

Epoch: 5| Step: 5
Training loss: 2.4050433613760225
Validation loss: 2.483820983404829

Epoch: 5| Step: 6
Training loss: 2.2175402499806904
Validation loss: 2.480101246279654

Epoch: 5| Step: 7
Training loss: 3.1425813114204635
Validation loss: 2.4855919582417543

Epoch: 5| Step: 8
Training loss: 2.646636620678499
Validation loss: 2.479233004913954

Epoch: 5| Step: 9
Training loss: 2.6723355794203028
Validation loss: 2.4858186873634227

Epoch: 5| Step: 10
Training loss: 1.7475368331061707
Validation loss: 2.482409941661854

Epoch: 5| Step: 11
Training loss: 1.4450787329426298
Validation loss: 2.47645957724888

Epoch: 184| Step: 0
Training loss: 1.9793591522844711
Validation loss: 2.4826580848633446

Epoch: 5| Step: 1
Training loss: 2.5490408271521994
Validation loss: 2.4811866822639645

Epoch: 5| Step: 2
Training loss: 2.5155761903565006
Validation loss: 2.4848647444621967

Epoch: 5| Step: 3
Training loss: 2.085692659217407
Validation loss: 2.485911735754415

Epoch: 5| Step: 4
Training loss: 2.5093780099511056
Validation loss: 2.481973491025068

Epoch: 5| Step: 5
Training loss: 2.1187421995486364
Validation loss: 2.4937505773035338

Epoch: 5| Step: 6
Training loss: 2.7657262061615446
Validation loss: 2.4955502805439895

Epoch: 5| Step: 7
Training loss: 2.1972569444272976
Validation loss: 2.4963357974216978

Epoch: 5| Step: 8
Training loss: 2.339059943616307
Validation loss: 2.497260543823642

Epoch: 5| Step: 9
Training loss: 2.949695028284737
Validation loss: 2.4814551287079962

Epoch: 5| Step: 10
Training loss: 2.884746120131251
Validation loss: 2.487784495290914

Epoch: 5| Step: 11
Training loss: 1.3605365394639994
Validation loss: 2.478957108581926

Epoch: 185| Step: 0
Training loss: 2.462901079849935
Validation loss: 2.4791549367119607

Epoch: 5| Step: 1
Training loss: 2.1147845944493757
Validation loss: 2.4742305016968795

Epoch: 5| Step: 2
Training loss: 1.9679794620163318
Validation loss: 2.4797916038756953

Epoch: 5| Step: 3
Training loss: 2.89432037862113
Validation loss: 2.4742451846147286

Epoch: 5| Step: 4
Training loss: 2.007466921029056
Validation loss: 2.4780218856576024

Epoch: 5| Step: 5
Training loss: 2.534951788088312
Validation loss: 2.4848061033599094

Epoch: 5| Step: 6
Training loss: 2.658146170202893
Validation loss: 2.486659465166595

Epoch: 5| Step: 7
Training loss: 2.0895622848206212
Validation loss: 2.4957056713942087

Epoch: 5| Step: 8
Training loss: 3.038646679357074
Validation loss: 2.5006917751377693

Epoch: 5| Step: 9
Training loss: 2.6485164484280617
Validation loss: 2.5007194993668627

Epoch: 5| Step: 10
Training loss: 2.0355192655112195
Validation loss: 2.491518279561607

Epoch: 5| Step: 11
Training loss: 2.397591805236783
Validation loss: 2.4835240968190946

Epoch: 186| Step: 0
Training loss: 2.7300336979613262
Validation loss: 2.4910441698824948

Epoch: 5| Step: 1
Training loss: 2.2783190567399023
Validation loss: 2.4737490568822627

Epoch: 5| Step: 2
Training loss: 2.473832897553327
Validation loss: 2.4849872514460403

Epoch: 5| Step: 3
Training loss: 1.887111457092362
Validation loss: 2.4844555311926175

Epoch: 5| Step: 4
Training loss: 2.70719277256436
Validation loss: 2.497027083863023

Epoch: 5| Step: 5
Training loss: 2.3505208189074156
Validation loss: 2.498680334673726

Epoch: 5| Step: 6
Training loss: 2.7230062382935154
Validation loss: 2.5013402723779214

Epoch: 5| Step: 7
Training loss: 2.4058310404089305
Validation loss: 2.4914456222930403

Epoch: 5| Step: 8
Training loss: 2.1514440965173725
Validation loss: 2.4914648708442

Epoch: 5| Step: 9
Training loss: 2.492363998238045
Validation loss: 2.47696980477431

Epoch: 5| Step: 10
Training loss: 2.5242418831816313
Validation loss: 2.488894935358836

Epoch: 5| Step: 11
Training loss: 2.1969025307635506
Validation loss: 2.4845437886222963

Epoch: 187| Step: 0
Training loss: 2.2918446789585682
Validation loss: 2.476126422857086

Epoch: 5| Step: 1
Training loss: 2.054284465989511
Validation loss: 2.4734774286096095

Epoch: 5| Step: 2
Training loss: 2.4967920702553195
Validation loss: 2.4715856571666546

Epoch: 5| Step: 3
Training loss: 2.7024190344666943
Validation loss: 2.4742491393917616

Epoch: 5| Step: 4
Training loss: 2.450410738399837
Validation loss: 2.4711216226606427

Epoch: 5| Step: 5
Training loss: 2.147443284694668
Validation loss: 2.4717365501009323

Epoch: 5| Step: 6
Training loss: 2.9854047506608805
Validation loss: 2.4795227810130527

Epoch: 5| Step: 7
Training loss: 3.0208315794490237
Validation loss: 2.48339756945496

Epoch: 5| Step: 8
Training loss: 2.021773784763115
Validation loss: 2.500489465164096

Epoch: 5| Step: 9
Training loss: 2.2662346381431093
Validation loss: 2.5033554526679676

Epoch: 5| Step: 10
Training loss: 2.3357227443610236
Validation loss: 2.516044486948867

Epoch: 5| Step: 11
Training loss: 2.4653079990689677
Validation loss: 2.5323422159484634

Epoch: 188| Step: 0
Training loss: 2.856376201087005
Validation loss: 2.531526177649632

Epoch: 5| Step: 1
Training loss: 2.4444043115249787
Validation loss: 2.54098167856125

Epoch: 5| Step: 2
Training loss: 2.4602163075505667
Validation loss: 2.508857810252936

Epoch: 5| Step: 3
Training loss: 2.7747442900917427
Validation loss: 2.4943349987057437

Epoch: 5| Step: 4
Training loss: 2.149668614775503
Validation loss: 2.500005328649564

Epoch: 5| Step: 5
Training loss: 2.544831468289374
Validation loss: 2.4797850620280424

Epoch: 5| Step: 6
Training loss: 2.825065095539723
Validation loss: 2.4855442854249152

Epoch: 5| Step: 7
Training loss: 1.7262655149476671
Validation loss: 2.480941399025327

Epoch: 5| Step: 8
Training loss: 2.6014853342886717
Validation loss: 2.4745720727804246

Epoch: 5| Step: 9
Training loss: 2.1458020501186628
Validation loss: 2.4723129998434246

Epoch: 5| Step: 10
Training loss: 2.32241931146864
Validation loss: 2.475502224421582

Epoch: 5| Step: 11
Training loss: 2.7677256908932497
Validation loss: 2.4831176751111395

Epoch: 189| Step: 0
Training loss: 2.8227884936824292
Validation loss: 2.4651615161673877

Epoch: 5| Step: 1
Training loss: 2.0826835254706477
Validation loss: 2.4727459851575193

Epoch: 5| Step: 2
Training loss: 2.4591888512395284
Validation loss: 2.4733575727280943

Epoch: 5| Step: 3
Training loss: 2.21997917406091
Validation loss: 2.471227569606919

Epoch: 5| Step: 4
Training loss: 2.459745475658649
Validation loss: 2.47789639833238

Epoch: 5| Step: 5
Training loss: 2.203991766794823
Validation loss: 2.477957788753418

Epoch: 5| Step: 6
Training loss: 2.235613712989356
Validation loss: 2.4924354629170926

Epoch: 5| Step: 7
Training loss: 2.8167026908722708
Validation loss: 2.494251779475665

Epoch: 5| Step: 8
Training loss: 2.353366096780021
Validation loss: 2.501069436216375

Epoch: 5| Step: 9
Training loss: 2.4091341642942643
Validation loss: 2.5123788076085596

Epoch: 5| Step: 10
Training loss: 2.6418492114737644
Validation loss: 2.5097335279022777

Epoch: 5| Step: 11
Training loss: 2.00034174383593
Validation loss: 2.509155832666551

Epoch: 190| Step: 0
Training loss: 2.3074322407239234
Validation loss: 2.513731403727819

Epoch: 5| Step: 1
Training loss: 2.2202189780826638
Validation loss: 2.5099962615875633

Epoch: 5| Step: 2
Training loss: 2.4003150375545492
Validation loss: 2.522638519215347

Epoch: 5| Step: 3
Training loss: 2.4798238081025388
Validation loss: 2.513643558543271

Epoch: 5| Step: 4
Training loss: 2.6853704665071665
Validation loss: 2.4931791399469834

Epoch: 5| Step: 5
Training loss: 2.4606872431348545
Validation loss: 2.489287986687224

Epoch: 5| Step: 6
Training loss: 2.7310731843677867
Validation loss: 2.481301631918775

Epoch: 5| Step: 7
Training loss: 2.1624137023288426
Validation loss: 2.4846048788564903

Epoch: 5| Step: 8
Training loss: 2.348568350369263
Validation loss: 2.481670699179272

Epoch: 5| Step: 9
Training loss: 2.5507189989891477
Validation loss: 2.477514491136695

Epoch: 5| Step: 10
Training loss: 2.0242145474978086
Validation loss: 2.4767459697132916

Epoch: 5| Step: 11
Training loss: 3.489121287867505
Validation loss: 2.475192078930153

Epoch: 191| Step: 0
Training loss: 1.3745804059769393
Validation loss: 2.4723051845427104

Epoch: 5| Step: 1
Training loss: 2.825192612014783
Validation loss: 2.4706757474847523

Epoch: 5| Step: 2
Training loss: 2.7717644601690545
Validation loss: 2.4703938809589694

Epoch: 5| Step: 3
Training loss: 2.1637947660561103
Validation loss: 2.4671571236452285

Epoch: 5| Step: 4
Training loss: 1.9298411937465358
Validation loss: 2.4719874565820645

Epoch: 5| Step: 5
Training loss: 2.643147544665468
Validation loss: 2.4671586335973603

Epoch: 5| Step: 6
Training loss: 2.1940442966520495
Validation loss: 2.4659856215859888

Epoch: 5| Step: 7
Training loss: 2.4945269758150235
Validation loss: 2.4725793803451284

Epoch: 5| Step: 8
Training loss: 2.5500376904264015
Validation loss: 2.47162375204095

Epoch: 5| Step: 9
Training loss: 3.0809353619425015
Validation loss: 2.4801463480806833

Epoch: 5| Step: 10
Training loss: 2.8110350290271597
Validation loss: 2.4839280524169562

Epoch: 5| Step: 11
Training loss: 0.698550752337406
Validation loss: 2.489927991581648

Epoch: 192| Step: 0
Training loss: 3.0163065876337947
Validation loss: 2.4983869037351907

Epoch: 5| Step: 1
Training loss: 2.450019960906011
Validation loss: 2.50819106527583

Epoch: 5| Step: 2
Training loss: 2.8710743183334775
Validation loss: 2.5156769520072633

Epoch: 5| Step: 3
Training loss: 2.9859940695681386
Validation loss: 2.5389764076700354

Epoch: 5| Step: 4
Training loss: 1.8310006502443053
Validation loss: 2.5100102128559465

Epoch: 5| Step: 5
Training loss: 2.942967460273559
Validation loss: 2.5009276298275114

Epoch: 5| Step: 6
Training loss: 2.048638785080137
Validation loss: 2.5032885300791734

Epoch: 5| Step: 7
Training loss: 2.1454709188339076
Validation loss: 2.495937670870921

Epoch: 5| Step: 8
Training loss: 1.8300183916470565
Validation loss: 2.4785902905371393

Epoch: 5| Step: 9
Training loss: 1.7930531866266604
Validation loss: 2.4688958475031253

Epoch: 5| Step: 10
Training loss: 2.2776638741688484
Validation loss: 2.475743600613839

Epoch: 5| Step: 11
Training loss: 2.892939450339408
Validation loss: 2.4843927018916463

Epoch: 193| Step: 0
Training loss: 2.558283616700182
Validation loss: 2.4779709382050235

Epoch: 5| Step: 1
Training loss: 2.4519743924071693
Validation loss: 2.487766038863077

Epoch: 5| Step: 2
Training loss: 3.5451672177496283
Validation loss: 2.4777305167180823

Epoch: 5| Step: 3
Training loss: 2.1431466724438004
Validation loss: 2.47258779341603

Epoch: 5| Step: 4
Training loss: 2.1430051616227384
Validation loss: 2.4818626552272534

Epoch: 5| Step: 5
Training loss: 2.1469470593659765
Validation loss: 2.486764566373158

Epoch: 5| Step: 6
Training loss: 1.8697293270277535
Validation loss: 2.478037903110199

Epoch: 5| Step: 7
Training loss: 2.168891339272451
Validation loss: 2.4885991091596757

Epoch: 5| Step: 8
Training loss: 2.197889017470554
Validation loss: 2.488827707759394

Epoch: 5| Step: 9
Training loss: 2.356233033136857
Validation loss: 2.497436156492646

Epoch: 5| Step: 10
Training loss: 2.5565755324386497
Validation loss: 2.4981250328182942

Epoch: 5| Step: 11
Training loss: 3.2345134318484603
Validation loss: 2.5002957645938944

Epoch: 194| Step: 0
Training loss: 2.9769190777437284
Validation loss: 2.5093744628702983

Epoch: 5| Step: 1
Training loss: 3.1239964208838833
Validation loss: 2.506822994938326

Epoch: 5| Step: 2
Training loss: 1.822762604515644
Validation loss: 2.52553362636954

Epoch: 5| Step: 3
Training loss: 2.287429279005455
Validation loss: 2.523788006574918

Epoch: 5| Step: 4
Training loss: 2.2774126359784166
Validation loss: 2.5148513504676644

Epoch: 5| Step: 5
Training loss: 2.3817904922760693
Validation loss: 2.49621795440796

Epoch: 5| Step: 6
Training loss: 2.3443466444342267
Validation loss: 2.4903611533611296

Epoch: 5| Step: 7
Training loss: 2.3379153040807905
Validation loss: 2.476100200581204

Epoch: 5| Step: 8
Training loss: 2.2634129742340776
Validation loss: 2.473090356181328

Epoch: 5| Step: 9
Training loss: 2.339149231917645
Validation loss: 2.480016872466538

Epoch: 5| Step: 10
Training loss: 2.249216791107713
Validation loss: 2.4795999041579293

Epoch: 5| Step: 11
Training loss: 2.9954160000824266
Validation loss: 2.4832530657279097

Epoch: 195| Step: 0
Training loss: 2.5473735298007614
Validation loss: 2.480585290769274

Epoch: 5| Step: 1
Training loss: 2.376044094068287
Validation loss: 2.4809426283047595

Epoch: 5| Step: 2
Training loss: 2.4955620475489093
Validation loss: 2.485728512940148

Epoch: 5| Step: 3
Training loss: 2.381501984968045
Validation loss: 2.480369585913562

Epoch: 5| Step: 4
Training loss: 2.6926477500450656
Validation loss: 2.491110446388019

Epoch: 5| Step: 5
Training loss: 2.09970884575421
Validation loss: 2.490896909254847

Epoch: 5| Step: 6
Training loss: 2.271987714949155
Validation loss: 2.499728323162025

Epoch: 5| Step: 7
Training loss: 2.7744931213436628
Validation loss: 2.4956237418119587

Epoch: 5| Step: 8
Training loss: 2.2946687859114077
Validation loss: 2.5227314381496044

Epoch: 5| Step: 9
Training loss: 2.448608127629922
Validation loss: 2.516567136731122

Epoch: 5| Step: 10
Training loss: 2.1690398448557318
Validation loss: 2.5040440593373554

Epoch: 5| Step: 11
Training loss: 2.156796372339271
Validation loss: 2.4939819102221388

Epoch: 196| Step: 0
Training loss: 2.5085531786854687
Validation loss: 2.482129503706232

Epoch: 5| Step: 1
Training loss: 2.803720801750324
Validation loss: 2.475239172531112

Epoch: 5| Step: 2
Training loss: 2.5077389144796953
Validation loss: 2.4756366230467814

Epoch: 5| Step: 3
Training loss: 2.495449789017125
Validation loss: 2.473552868727564

Epoch: 5| Step: 4
Training loss: 1.8633911612220497
Validation loss: 2.474183380866671

Epoch: 5| Step: 5
Training loss: 2.7446178306433486
Validation loss: 2.478035193119239

Epoch: 5| Step: 6
Training loss: 2.44843743378445
Validation loss: 2.4761641911121997

Epoch: 5| Step: 7
Training loss: 2.5125377025906888
Validation loss: 2.4754563999331456

Epoch: 5| Step: 8
Training loss: 1.891748709166903
Validation loss: 2.481439091277928

Epoch: 5| Step: 9
Training loss: 2.2688403235076327
Validation loss: 2.4840932402390563

Epoch: 5| Step: 10
Training loss: 2.4893092452819596
Validation loss: 2.4913772892337835

Epoch: 5| Step: 11
Training loss: 1.72409558013992
Validation loss: 2.5109432045524223

Epoch: 197| Step: 0
Training loss: 2.798327021119309
Validation loss: 2.5265179345693274

Epoch: 5| Step: 1
Training loss: 2.058473760882845
Validation loss: 2.5622374198483904

Epoch: 5| Step: 2
Training loss: 2.500152297149446
Validation loss: 2.573499487427766

Epoch: 5| Step: 3
Training loss: 2.8267965832430653
Validation loss: 2.5702424083301136

Epoch: 5| Step: 4
Training loss: 2.294881773253352
Validation loss: 2.5717761463002917

Epoch: 5| Step: 5
Training loss: 2.8102217877922078
Validation loss: 2.549902561607467

Epoch: 5| Step: 6
Training loss: 2.181598768797507
Validation loss: 2.529896821850777

Epoch: 5| Step: 7
Training loss: 2.4854938219047753
Validation loss: 2.511032722723282

Epoch: 5| Step: 8
Training loss: 2.5012232648725594
Validation loss: 2.481197084043594

Epoch: 5| Step: 9
Training loss: 2.0260020614191774
Validation loss: 2.486316022621221

Epoch: 5| Step: 10
Training loss: 2.0228388427263746
Validation loss: 2.475092932211895

Epoch: 5| Step: 11
Training loss: 2.321752441786148
Validation loss: 2.4607188657492185

Epoch: 198| Step: 0
Training loss: 3.2526863440014644
Validation loss: 2.4626006506022384

Epoch: 5| Step: 1
Training loss: 2.0985746451047818
Validation loss: 2.467632781311085

Epoch: 5| Step: 2
Training loss: 2.5559547384370807
Validation loss: 2.46771314633116

Epoch: 5| Step: 3
Training loss: 2.1742787403927935
Validation loss: 2.4681325776186775

Epoch: 5| Step: 4
Training loss: 2.316722417293246
Validation loss: 2.470556206035316

Epoch: 5| Step: 5
Training loss: 2.1125885397510213
Validation loss: 2.4681816010092135

Epoch: 5| Step: 6
Training loss: 2.3892978150645567
Validation loss: 2.4693870808878646

Epoch: 5| Step: 7
Training loss: 2.155665774602643
Validation loss: 2.476761794871081

Epoch: 5| Step: 8
Training loss: 2.3708725249454083
Validation loss: 2.4801412972004093

Epoch: 5| Step: 9
Training loss: 2.6077318328760004
Validation loss: 2.4835589966127887

Epoch: 5| Step: 10
Training loss: 2.76076990902358
Validation loss: 2.5146130842668075

Epoch: 5| Step: 11
Training loss: 2.0431749520623796
Validation loss: 2.512696466941089

Epoch: 199| Step: 0
Training loss: 2.4814745208090123
Validation loss: 2.5481423811124424

Epoch: 5| Step: 1
Training loss: 2.2524419884192017
Validation loss: 2.560935512043102

Epoch: 5| Step: 2
Training loss: 2.768918678536072
Validation loss: 2.5499530049275756

Epoch: 5| Step: 3
Training loss: 2.7914062397506036
Validation loss: 2.5695795987356047

Epoch: 5| Step: 4
Training loss: 2.310851979043459
Validation loss: 2.5387823136109318

Epoch: 5| Step: 5
Training loss: 1.9811142691440102
Validation loss: 2.5293300768859006

Epoch: 5| Step: 6
Training loss: 2.846859918715628
Validation loss: 2.5165094909681005

Epoch: 5| Step: 7
Training loss: 2.1968074609133836
Validation loss: 2.5041204113954167

Epoch: 5| Step: 8
Training loss: 2.6361738079812245
Validation loss: 2.478019091462424

Epoch: 5| Step: 9
Training loss: 2.7869042345777726
Validation loss: 2.4764502105767945

Epoch: 5| Step: 10
Training loss: 1.7976001768887089
Validation loss: 2.4779321310859603

Epoch: 5| Step: 11
Training loss: 1.6166357306178327
Validation loss: 2.4704061618705335

Epoch: 200| Step: 0
Training loss: 1.7451075557363955
Validation loss: 2.473570539632139

Epoch: 5| Step: 1
Training loss: 2.390319704994238
Validation loss: 2.4749957041269646

Epoch: 5| Step: 2
Training loss: 2.8038901893238655
Validation loss: 2.478358058064294

Epoch: 5| Step: 3
Training loss: 2.40103754028054
Validation loss: 2.4764935055657906

Epoch: 5| Step: 4
Training loss: 2.7267053779832455
Validation loss: 2.4795059658457492

Epoch: 5| Step: 5
Training loss: 2.6216709280333066
Validation loss: 2.482498357851677

Epoch: 5| Step: 6
Training loss: 2.5065296730523836
Validation loss: 2.4781234306660798

Epoch: 5| Step: 7
Training loss: 2.4712889930377173
Validation loss: 2.4785954127133487

Epoch: 5| Step: 8
Training loss: 2.2671434247013362
Validation loss: 2.487360026704111

Epoch: 5| Step: 9
Training loss: 2.6762153217718354
Validation loss: 2.4814503286992315

Epoch: 5| Step: 10
Training loss: 2.0046896788064203
Validation loss: 2.486865608591948

Epoch: 5| Step: 11
Training loss: 2.9295432907215955
Validation loss: 2.5033241880889414

Epoch: 201| Step: 0
Training loss: 2.9529695015794357
Validation loss: 2.4999995628992333

Epoch: 5| Step: 1
Training loss: 2.4583049923400004
Validation loss: 2.4968235857225207

Epoch: 5| Step: 2
Training loss: 2.0539162932651345
Validation loss: 2.502686578913328

Epoch: 5| Step: 3
Training loss: 2.8319665940895318
Validation loss: 2.502583634963481

Epoch: 5| Step: 4
Training loss: 2.317594741152195
Validation loss: 2.4857218068760223

Epoch: 5| Step: 5
Training loss: 1.9968591704360539
Validation loss: 2.4984476515114618

Epoch: 5| Step: 6
Training loss: 2.2511045076165224
Validation loss: 2.4940481465002353

Epoch: 5| Step: 7
Training loss: 1.7707715939997613
Validation loss: 2.501149922392286

Epoch: 5| Step: 8
Training loss: 2.579206667473318
Validation loss: 2.5019139612623276

Epoch: 5| Step: 9
Training loss: 2.586740789662318
Validation loss: 2.4982282002574188

Epoch: 5| Step: 10
Training loss: 2.294916576622873
Validation loss: 2.495492925552494

Epoch: 5| Step: 11
Training loss: 2.892321114774298
Validation loss: 2.4970200580447712

Epoch: 202| Step: 0
Training loss: 2.4108042039198145
Validation loss: 2.501086606870865

Epoch: 5| Step: 1
Training loss: 2.3710755499906426
Validation loss: 2.503910425731174

Epoch: 5| Step: 2
Training loss: 2.5590956799835176
Validation loss: 2.5173907509882154

Epoch: 5| Step: 3
Training loss: 2.262926375536202
Validation loss: 2.505600584625957

Epoch: 5| Step: 4
Training loss: 2.718665373789561
Validation loss: 2.521161981444844

Epoch: 5| Step: 5
Training loss: 2.7297484576139435
Validation loss: 2.503715912581629

Epoch: 5| Step: 6
Training loss: 2.5396112875981527
Validation loss: 2.508028518230443

Epoch: 5| Step: 7
Training loss: 2.832193220045014
Validation loss: 2.5093829228080944

Epoch: 5| Step: 8
Training loss: 1.22754275276643
Validation loss: 2.5014803358059075

Epoch: 5| Step: 9
Training loss: 2.055090338955816
Validation loss: 2.4925056661007683

Epoch: 5| Step: 10
Training loss: 2.4511401656938023
Validation loss: 2.502226080833855

Epoch: 5| Step: 11
Training loss: 2.7465490015375074
Validation loss: 2.493786509126299

Epoch: 203| Step: 0
Training loss: 2.432735775599528
Validation loss: 2.5030810285207257

Epoch: 5| Step: 1
Training loss: 1.951830442557014
Validation loss: 2.4966131275910604

Epoch: 5| Step: 2
Training loss: 2.741589516324296
Validation loss: 2.501160288810754

Epoch: 5| Step: 3
Training loss: 2.709098609985522
Validation loss: 2.5215911685027605

Epoch: 5| Step: 4
Training loss: 2.1307193979359362
Validation loss: 2.5169290791579435

Epoch: 5| Step: 5
Training loss: 1.9877985460151124
Validation loss: 2.548673080853939

Epoch: 5| Step: 6
Training loss: 2.253260686971152
Validation loss: 2.524923133309588

Epoch: 5| Step: 7
Training loss: 2.2568140693242222
Validation loss: 2.545910342488258

Epoch: 5| Step: 8
Training loss: 2.7889045221803292
Validation loss: 2.548613175527884

Epoch: 5| Step: 9
Training loss: 2.8819223078805694
Validation loss: 2.5678891175691674

Epoch: 5| Step: 10
Training loss: 2.582541087914026
Validation loss: 2.5416543848230844

Epoch: 5| Step: 11
Training loss: 1.2618800671321257
Validation loss: 2.5132249139857907

Epoch: 204| Step: 0
Training loss: 2.4207905956529387
Validation loss: 2.492862781331424

Epoch: 5| Step: 1
Training loss: 2.0830677880488992
Validation loss: 2.4808203380446385

Epoch: 5| Step: 2
Training loss: 2.2830237194939462
Validation loss: 2.4764319344328145

Epoch: 5| Step: 3
Training loss: 2.6050104427311385
Validation loss: 2.4717598124277456

Epoch: 5| Step: 4
Training loss: 2.4716103316832427
Validation loss: 2.4702312033858598

Epoch: 5| Step: 5
Training loss: 2.7254067843530723
Validation loss: 2.4780998833222503

Epoch: 5| Step: 6
Training loss: 2.4490601702736603
Validation loss: 2.472002450202861

Epoch: 5| Step: 7
Training loss: 2.036323081075604
Validation loss: 2.484023959072459

Epoch: 5| Step: 8
Training loss: 2.9290826198481468
Validation loss: 2.4735337157341077

Epoch: 5| Step: 9
Training loss: 2.952154736854427
Validation loss: 2.483983084917321

Epoch: 5| Step: 10
Training loss: 2.410211843779914
Validation loss: 2.4956385794955676

Epoch: 5| Step: 11
Training loss: 1.9891344799074029
Validation loss: 2.493548640389265

Epoch: 205| Step: 0
Training loss: 2.554157353726989
Validation loss: 2.495034539831562

Epoch: 5| Step: 1
Training loss: 2.2232237294226858
Validation loss: 2.4925707539330504

Epoch: 5| Step: 2
Training loss: 3.099105669040018
Validation loss: 2.5033277219166785

Epoch: 5| Step: 3
Training loss: 2.5908632875193316
Validation loss: 2.5180875362949418

Epoch: 5| Step: 4
Training loss: 2.0048096760055842
Validation loss: 2.51588429917321

Epoch: 5| Step: 5
Training loss: 2.5811798492579103
Validation loss: 2.523221285191325

Epoch: 5| Step: 6
Training loss: 2.5150252865379006
Validation loss: 2.524003665111317

Epoch: 5| Step: 7
Training loss: 2.488006624550295
Validation loss: 2.524235051176344

Epoch: 5| Step: 8
Training loss: 2.408986108963925
Validation loss: 2.5280757632056443

Epoch: 5| Step: 9
Training loss: 1.7008342911628644
Validation loss: 2.5171267289999704

Epoch: 5| Step: 10
Training loss: 2.3844912759369725
Validation loss: 2.5197937742374013

Epoch: 5| Step: 11
Training loss: 1.9284933619366418
Validation loss: 2.497561560983595

Epoch: 206| Step: 0
Training loss: 2.8905590152941762
Validation loss: 2.495687070540069

Epoch: 5| Step: 1
Training loss: 2.4261545087604
Validation loss: 2.4904607772133116

Epoch: 5| Step: 2
Training loss: 2.32361580857783
Validation loss: 2.4830704948894904

Epoch: 5| Step: 3
Training loss: 2.316694939621491
Validation loss: 2.480873127012599

Epoch: 5| Step: 4
Training loss: 2.425776434016707
Validation loss: 2.480974809582532

Epoch: 5| Step: 5
Training loss: 2.4399040300225368
Validation loss: 2.4927188063796186

Epoch: 5| Step: 6
Training loss: 1.9616762874478626
Validation loss: 2.49806701317992

Epoch: 5| Step: 7
Training loss: 2.093101514910634
Validation loss: 2.5020646430997475

Epoch: 5| Step: 8
Training loss: 2.002396220971998
Validation loss: 2.527178476423721

Epoch: 5| Step: 9
Training loss: 2.8064285867189844
Validation loss: 2.5278262543018184

Epoch: 5| Step: 10
Training loss: 2.739110976038831
Validation loss: 2.5440580395539687

Epoch: 5| Step: 11
Training loss: 2.131067253623248
Validation loss: 2.5227154150363136

Epoch: 207| Step: 0
Training loss: 2.5180613406938335
Validation loss: 2.5096722260152355

Epoch: 5| Step: 1
Training loss: 2.4898319412875467
Validation loss: 2.507037275684914

Epoch: 5| Step: 2
Training loss: 2.575230678855082
Validation loss: 2.506536664288639

Epoch: 5| Step: 3
Training loss: 1.9448657154710192
Validation loss: 2.489828190806282

Epoch: 5| Step: 4
Training loss: 2.1377742747522435
Validation loss: 2.4913557093539858

Epoch: 5| Step: 5
Training loss: 2.292670729341907
Validation loss: 2.4836468339230677

Epoch: 5| Step: 6
Training loss: 2.3323482636613577
Validation loss: 2.485240249789134

Epoch: 5| Step: 7
Training loss: 1.651533717371113
Validation loss: 2.501815029743483

Epoch: 5| Step: 8
Training loss: 2.509657611823327
Validation loss: 2.509991397424979

Epoch: 5| Step: 9
Training loss: 3.015653145614283
Validation loss: 2.517024245395568

Epoch: 5| Step: 10
Training loss: 2.4565864973129927
Validation loss: 2.50968004766045

Epoch: 5| Step: 11
Training loss: 3.98399680343561
Validation loss: 2.5251282262819754

Epoch: 208| Step: 0
Training loss: 2.3517223823412357
Validation loss: 2.529478106394356

Epoch: 5| Step: 1
Training loss: 2.1074903192444867
Validation loss: 2.5285292276721485

Epoch: 5| Step: 2
Training loss: 1.859653804616739
Validation loss: 2.546134852884951

Epoch: 5| Step: 3
Training loss: 2.264523679151693
Validation loss: 2.541393958506747

Epoch: 5| Step: 4
Training loss: 2.5588571660382495
Validation loss: 2.5390984126754614

Epoch: 5| Step: 5
Training loss: 2.5057913458042105
Validation loss: 2.560698476843163

Epoch: 5| Step: 6
Training loss: 2.9932962858233934
Validation loss: 2.5551098426802357

Epoch: 5| Step: 7
Training loss: 1.99302015668186
Validation loss: 2.552379096013844

Epoch: 5| Step: 8
Training loss: 2.52661235432222
Validation loss: 2.560262086628739

Epoch: 5| Step: 9
Training loss: 2.610205421110198
Validation loss: 2.532937664631662

Epoch: 5| Step: 10
Training loss: 2.353555943313884
Validation loss: 2.4925955754203146

Epoch: 5| Step: 11
Training loss: 3.2663799672596476
Validation loss: 2.4952222429966313

Epoch: 209| Step: 0
Training loss: 2.4646902384161775
Validation loss: 2.490279702166752

Epoch: 5| Step: 1
Training loss: 2.526942697392353
Validation loss: 2.4919299368267778

Epoch: 5| Step: 2
Training loss: 2.8512999531318153
Validation loss: 2.4887739718719835

Epoch: 5| Step: 3
Training loss: 2.5634761904761634
Validation loss: 2.496003497048673

Epoch: 5| Step: 4
Training loss: 2.0378170960235127
Validation loss: 2.4982845142659778

Epoch: 5| Step: 5
Training loss: 1.9355969465844576
Validation loss: 2.4998880520233557

Epoch: 5| Step: 6
Training loss: 2.794199510975372
Validation loss: 2.4915533743866294

Epoch: 5| Step: 7
Training loss: 2.474600703849745
Validation loss: 2.499399661462124

Epoch: 5| Step: 8
Training loss: 2.1929103972659285
Validation loss: 2.5236366516199022

Epoch: 5| Step: 9
Training loss: 1.6560969731875093
Validation loss: 2.534260592091002

Epoch: 5| Step: 10
Training loss: 2.376330153765428
Validation loss: 2.535064323337799

Epoch: 5| Step: 11
Training loss: 3.136901470102286
Validation loss: 2.5357127781280804

Epoch: 210| Step: 0
Training loss: 2.4248212060200545
Validation loss: 2.537060230807965

Epoch: 5| Step: 1
Training loss: 2.4293033995405025
Validation loss: 2.535422238197777

Epoch: 5| Step: 2
Training loss: 2.5992611165287327
Validation loss: 2.527186255679754

Epoch: 5| Step: 3
Training loss: 2.283789697227954
Validation loss: 2.520040301960647

Epoch: 5| Step: 4
Training loss: 2.1398045436335615
Validation loss: 2.5157350788555326

Epoch: 5| Step: 5
Training loss: 2.614301131826139
Validation loss: 2.5149425346958463

Epoch: 5| Step: 6
Training loss: 2.2209373759887883
Validation loss: 2.5201221492722135

Epoch: 5| Step: 7
Training loss: 2.6729082039520455
Validation loss: 2.5067772595272815

Epoch: 5| Step: 8
Training loss: 2.372126095313369
Validation loss: 2.5027897488433246

Epoch: 5| Step: 9
Training loss: 2.2356365350516865
Validation loss: 2.5015452516792314

Epoch: 5| Step: 10
Training loss: 2.469424964285378
Validation loss: 2.5049870222101944

Epoch: 5| Step: 11
Training loss: 1.5394786910997962
Validation loss: 2.5099727203778865

Epoch: 211| Step: 0
Training loss: 2.773172543186714
Validation loss: 2.498474625309049

Epoch: 5| Step: 1
Training loss: 2.3333858983613034
Validation loss: 2.5040260361670157

Epoch: 5| Step: 2
Training loss: 2.0620012547279187
Validation loss: 2.4927135737409607

Epoch: 5| Step: 3
Training loss: 2.539863624365922
Validation loss: 2.4995003836806293

Epoch: 5| Step: 4
Training loss: 2.0346240850686654
Validation loss: 2.490806017319937

Epoch: 5| Step: 5
Training loss: 2.166331729920997
Validation loss: 2.496967216574394

Epoch: 5| Step: 6
Training loss: 2.229937969593792
Validation loss: 2.5043100357800725

Epoch: 5| Step: 7
Training loss: 2.2019522501301036
Validation loss: 2.500075053042109

Epoch: 5| Step: 8
Training loss: 2.3788144449393585
Validation loss: 2.5098163921204018

Epoch: 5| Step: 9
Training loss: 2.450928792260735
Validation loss: 2.515098970910385

Epoch: 5| Step: 10
Training loss: 2.8497372154754244
Validation loss: 2.5353241224699232

Epoch: 5| Step: 11
Training loss: 3.1902697627885317
Validation loss: 2.5481521742975395

Epoch: 212| Step: 0
Training loss: 2.333013739724053
Validation loss: 2.5275161464249627

Epoch: 5| Step: 1
Training loss: 2.969657518311162
Validation loss: 2.529628190933218

Epoch: 5| Step: 2
Training loss: 2.322231950186878
Validation loss: 2.5240494347311673

Epoch: 5| Step: 3
Training loss: 2.088778386451056
Validation loss: 2.505564084770401

Epoch: 5| Step: 4
Training loss: 2.3620751700330618
Validation loss: 2.4970296976533293

Epoch: 5| Step: 5
Training loss: 2.2350598332804217
Validation loss: 2.4990183770706285

Epoch: 5| Step: 6
Training loss: 2.5693173786625434
Validation loss: 2.4988835861986947

Epoch: 5| Step: 7
Training loss: 2.1922103304228133
Validation loss: 2.4949125062881974

Epoch: 5| Step: 8
Training loss: 2.1679151923635107
Validation loss: 2.491978555847288

Epoch: 5| Step: 9
Training loss: 2.3936646528442282
Validation loss: 2.4965235420218232

Epoch: 5| Step: 10
Training loss: 2.462013614855508
Validation loss: 2.507093895049944

Epoch: 5| Step: 11
Training loss: 3.0638617777112467
Validation loss: 2.513841826318607

Epoch: 213| Step: 0
Training loss: 2.2282126218198095
Validation loss: 2.506527287149834

Epoch: 5| Step: 1
Training loss: 2.165154907816369
Validation loss: 2.5173569516260854

Epoch: 5| Step: 2
Training loss: 2.439176911842022
Validation loss: 2.5264672946548186

Epoch: 5| Step: 3
Training loss: 2.6383798297858294
Validation loss: 2.517974238360613

Epoch: 5| Step: 4
Training loss: 1.8299205471988855
Validation loss: 2.5173657122748994

Epoch: 5| Step: 5
Training loss: 2.186290733695135
Validation loss: 2.5276515366455548

Epoch: 5| Step: 6
Training loss: 2.7568941397338733
Validation loss: 2.5284902575189943

Epoch: 5| Step: 7
Training loss: 2.541900644841302
Validation loss: 2.5212411484935684

Epoch: 5| Step: 8
Training loss: 2.2750048920295853
Validation loss: 2.507128431085649

Epoch: 5| Step: 9
Training loss: 2.487301045038067
Validation loss: 2.5143640785792405

Epoch: 5| Step: 10
Training loss: 2.5554775684546236
Validation loss: 2.5114690954187955

Epoch: 5| Step: 11
Training loss: 2.6364547032140737
Validation loss: 2.5118515430426793

Epoch: 214| Step: 0
Training loss: 2.5818775956550133
Validation loss: 2.5261001711228346

Epoch: 5| Step: 1
Training loss: 2.075651948840612
Validation loss: 2.53095311515611

Epoch: 5| Step: 2
Training loss: 2.371521962948235
Validation loss: 2.524865190444968

Epoch: 5| Step: 3
Training loss: 2.30989102804264
Validation loss: 2.5266764927872636

Epoch: 5| Step: 4
Training loss: 2.251929938932297
Validation loss: 2.541473640606143

Epoch: 5| Step: 5
Training loss: 2.021192564611236
Validation loss: 2.5370266739128815

Epoch: 5| Step: 6
Training loss: 2.3909331478407854
Validation loss: 2.5488306817715465

Epoch: 5| Step: 7
Training loss: 2.551966907155115
Validation loss: 2.561376418367756

Epoch: 5| Step: 8
Training loss: 1.9136699663266787
Validation loss: 2.5579837333953863

Epoch: 5| Step: 9
Training loss: 2.5932798763868408
Validation loss: 2.5663227898019887

Epoch: 5| Step: 10
Training loss: 3.130277830718122
Validation loss: 2.5490768720477246

Epoch: 5| Step: 11
Training loss: 1.3565903126805603
Validation loss: 2.5239888347735464

Epoch: 215| Step: 0
Training loss: 2.807602241808046
Validation loss: 2.518020283274958

Epoch: 5| Step: 1
Training loss: 2.323181228511416
Validation loss: 2.517651547233599

Epoch: 5| Step: 2
Training loss: 2.0391127773824276
Validation loss: 2.488407740629186

Epoch: 5| Step: 3
Training loss: 2.2144707259661143
Validation loss: 2.5021350128422726

Epoch: 5| Step: 4
Training loss: 2.4637025830308854
Validation loss: 2.4875340919458746

Epoch: 5| Step: 5
Training loss: 2.258099494830165
Validation loss: 2.4949090262399167

Epoch: 5| Step: 6
Training loss: 2.233354028444579
Validation loss: 2.4869468021117713

Epoch: 5| Step: 7
Training loss: 2.1609244058671546
Validation loss: 2.492008533648906

Epoch: 5| Step: 8
Training loss: 2.387701004115149
Validation loss: 2.5089940410192035

Epoch: 5| Step: 9
Training loss: 2.622322078956914
Validation loss: 2.5197828891680647

Epoch: 5| Step: 10
Training loss: 2.7893773176391736
Validation loss: 2.526306631342841

Epoch: 5| Step: 11
Training loss: 1.4319046422386938
Validation loss: 2.5493457292985444

Epoch: 216| Step: 0
Training loss: 2.076132600830908
Validation loss: 2.553658156521155

Epoch: 5| Step: 1
Training loss: 2.5739457907551855
Validation loss: 2.5955327812657036

Epoch: 5| Step: 2
Training loss: 2.168573738432935
Validation loss: 2.586155389555125

Epoch: 5| Step: 3
Training loss: 2.8456783254324334
Validation loss: 2.5765255523062076

Epoch: 5| Step: 4
Training loss: 2.5384572408101795
Validation loss: 2.554576494175306

Epoch: 5| Step: 5
Training loss: 2.105924256262322
Validation loss: 2.543579789917819

Epoch: 5| Step: 6
Training loss: 1.857959497024687
Validation loss: 2.513053863519152

Epoch: 5| Step: 7
Training loss: 2.788982742836113
Validation loss: 2.491293089960215

Epoch: 5| Step: 8
Training loss: 2.4288220596814445
Validation loss: 2.4917469133470416

Epoch: 5| Step: 9
Training loss: 2.6456640795140376
Validation loss: 2.486139522570107

Epoch: 5| Step: 10
Training loss: 2.344958489707425
Validation loss: 2.48011889055437

Epoch: 5| Step: 11
Training loss: 2.034955210649754
Validation loss: 2.4831082055328606

Epoch: 217| Step: 0
Training loss: 2.305788973082991
Validation loss: 2.475248306996628

Epoch: 5| Step: 1
Training loss: 2.1811590662148754
Validation loss: 2.482047936472777

Epoch: 5| Step: 2
Training loss: 2.5916214447328283
Validation loss: 2.480483964688154

Epoch: 5| Step: 3
Training loss: 1.932047030719582
Validation loss: 2.4746563472168677

Epoch: 5| Step: 4
Training loss: 2.9741997740500676
Validation loss: 2.4844101997297035

Epoch: 5| Step: 5
Training loss: 2.584239575160115
Validation loss: 2.4914121946525287

Epoch: 5| Step: 6
Training loss: 2.8286014387402063
Validation loss: 2.492029832817279

Epoch: 5| Step: 7
Training loss: 2.084200131974977
Validation loss: 2.5193529760883355

Epoch: 5| Step: 8
Training loss: 2.638014185534
Validation loss: 2.5313377953833207

Epoch: 5| Step: 9
Training loss: 2.0406443573061357
Validation loss: 2.5473886997640642

Epoch: 5| Step: 10
Training loss: 2.535171767365116
Validation loss: 2.5771554298975774

Epoch: 5| Step: 11
Training loss: 1.9961583673876304
Validation loss: 2.5960245691664046

Epoch: 218| Step: 0
Training loss: 2.8916287715601823
Validation loss: 2.6016181199063113

Epoch: 5| Step: 1
Training loss: 2.520085899160572
Validation loss: 2.568146238198204

Epoch: 5| Step: 2
Training loss: 2.2570472133094404
Validation loss: 2.5420622413567657

Epoch: 5| Step: 3
Training loss: 2.0012119912440376
Validation loss: 2.516047092827882

Epoch: 5| Step: 4
Training loss: 2.3506163661304273
Validation loss: 2.5102351559646894

Epoch: 5| Step: 5
Training loss: 2.0059418628821684
Validation loss: 2.502875133112857

Epoch: 5| Step: 6
Training loss: 2.2676426815073074
Validation loss: 2.4910449694621453

Epoch: 5| Step: 7
Training loss: 2.215473388305432
Validation loss: 2.496581112081626

Epoch: 5| Step: 8
Training loss: 2.5719804077054804
Validation loss: 2.5033508652895606

Epoch: 5| Step: 9
Training loss: 2.849771182595518
Validation loss: 2.4894094060585226

Epoch: 5| Step: 10
Training loss: 2.2954146744830295
Validation loss: 2.4875877208354313

Epoch: 5| Step: 11
Training loss: 0.8463810060598141
Validation loss: 2.493736172560469

Epoch: 219| Step: 0
Training loss: 2.276924945410202
Validation loss: 2.490031402892879

Epoch: 5| Step: 1
Training loss: 2.8782625345676007
Validation loss: 2.491625153366914

Epoch: 5| Step: 2
Training loss: 2.13666965351501
Validation loss: 2.4911589617698615

Epoch: 5| Step: 3
Training loss: 2.719733137194701
Validation loss: 2.4947749968883026

Epoch: 5| Step: 4
Training loss: 2.353717310957525
Validation loss: 2.4992410044083226

Epoch: 5| Step: 5
Training loss: 2.572812983062117
Validation loss: 2.5063462491789856

Epoch: 5| Step: 6
Training loss: 1.907110926594001
Validation loss: 2.5211559133920907

Epoch: 5| Step: 7
Training loss: 2.88652614007714
Validation loss: 2.535008881237968

Epoch: 5| Step: 8
Training loss: 1.4005277558544933
Validation loss: 2.5257935602053507

Epoch: 5| Step: 9
Training loss: 2.5018496346790022
Validation loss: 2.53504475337119

Epoch: 5| Step: 10
Training loss: 1.9937946493955012
Validation loss: 2.524347652936652

Epoch: 5| Step: 11
Training loss: 2.999782554375426
Validation loss: 2.5235968540451186

Epoch: 220| Step: 0
Training loss: 2.3756433920485795
Validation loss: 2.5445553410012063

Epoch: 5| Step: 1
Training loss: 1.9939577502650148
Validation loss: 2.5796836649671544

Epoch: 5| Step: 2
Training loss: 2.053736361402012
Validation loss: 2.5866613652254453

Epoch: 5| Step: 3
Training loss: 2.555018225677641
Validation loss: 2.566961006889066

Epoch: 5| Step: 4
Training loss: 2.597407049401295
Validation loss: 2.5656253085211733

Epoch: 5| Step: 5
Training loss: 1.9644954061670494
Validation loss: 2.56442766644212

Epoch: 5| Step: 6
Training loss: 2.5833187615588638
Validation loss: 2.5403294224393833

Epoch: 5| Step: 7
Training loss: 2.858762581701243
Validation loss: 2.544194607225671

Epoch: 5| Step: 8
Training loss: 2.265035934163195
Validation loss: 2.525759778893636

Epoch: 5| Step: 9
Training loss: 2.1913263914955574
Validation loss: 2.5020590806135568

Epoch: 5| Step: 10
Training loss: 2.812032957505203
Validation loss: 2.494482775196372

Epoch: 5| Step: 11
Training loss: 1.8447780006228476
Validation loss: 2.4760022015944405

Epoch: 221| Step: 0
Training loss: 2.216972928891497
Validation loss: 2.473556019378775

Epoch: 5| Step: 1
Training loss: 2.7132317676639857
Validation loss: 2.4664942821846516

Epoch: 5| Step: 2
Training loss: 2.543204254167952
Validation loss: 2.4673126680184194

Epoch: 5| Step: 3
Training loss: 2.6817300646842783
Validation loss: 2.4709925907931676

Epoch: 5| Step: 4
Training loss: 1.9801578315289676
Validation loss: 2.459176708210845

Epoch: 5| Step: 5
Training loss: 2.360016186222238
Validation loss: 2.478060053968096

Epoch: 5| Step: 6
Training loss: 3.108357478671004
Validation loss: 2.4846113180531098

Epoch: 5| Step: 7
Training loss: 2.0155258745762668
Validation loss: 2.469264274663019

Epoch: 5| Step: 8
Training loss: 1.9775845143310617
Validation loss: 2.4836063815476943

Epoch: 5| Step: 9
Training loss: 2.360226105025894
Validation loss: 2.4948615115482276

Epoch: 5| Step: 10
Training loss: 2.6129223130857127
Validation loss: 2.520395250059698

Epoch: 5| Step: 11
Training loss: 1.9365322403315748
Validation loss: 2.5129794906351575

Epoch: 222| Step: 0
Training loss: 2.5706707087375524
Validation loss: 2.5212754040599625

Epoch: 5| Step: 1
Training loss: 1.7413085636277759
Validation loss: 2.5243830882471223

Epoch: 5| Step: 2
Training loss: 2.213047490027097
Validation loss: 2.5388227965841357

Epoch: 5| Step: 3
Training loss: 2.618322507794213
Validation loss: 2.5409195393353023

Epoch: 5| Step: 4
Training loss: 1.8658808521570747
Validation loss: 2.5416036986279473

Epoch: 5| Step: 5
Training loss: 2.678739062921979
Validation loss: 2.543567752948597

Epoch: 5| Step: 6
Training loss: 2.8938007127837286
Validation loss: 2.55445026225537

Epoch: 5| Step: 7
Training loss: 2.0853733628610773
Validation loss: 2.5519890800250415

Epoch: 5| Step: 8
Training loss: 2.4789028721932747
Validation loss: 2.5560074564457373

Epoch: 5| Step: 9
Training loss: 2.6733596870696195
Validation loss: 2.5708595203959876

Epoch: 5| Step: 10
Training loss: 2.3889271809468573
Validation loss: 2.562295405431184

Epoch: 5| Step: 11
Training loss: 1.5247006388272293
Validation loss: 2.53818087408216

Epoch: 223| Step: 0
Training loss: 2.3748600567194407
Validation loss: 2.5268921603427557

Epoch: 5| Step: 1
Training loss: 2.5334505476520914
Validation loss: 2.5081050341708413

Epoch: 5| Step: 2
Training loss: 2.818798049551055
Validation loss: 2.511223725956332

Epoch: 5| Step: 3
Training loss: 2.407750343149244
Validation loss: 2.489871193325901

Epoch: 5| Step: 4
Training loss: 2.629960776787168
Validation loss: 2.4935620980471227

Epoch: 5| Step: 5
Training loss: 2.396971810784252
Validation loss: 2.497661362985726

Epoch: 5| Step: 6
Training loss: 1.630875529135002
Validation loss: 2.4979540817845933

Epoch: 5| Step: 7
Training loss: 1.6398272800209117
Validation loss: 2.4980897678553204

Epoch: 5| Step: 8
Training loss: 2.2359496216941905
Validation loss: 2.49387369143912

Epoch: 5| Step: 9
Training loss: 2.601261339139994
Validation loss: 2.4952829165328327

Epoch: 5| Step: 10
Training loss: 2.5957170863525962
Validation loss: 2.4950073655974707

Epoch: 5| Step: 11
Training loss: 2.676895600105377
Validation loss: 2.4965280504245695

Epoch: 224| Step: 0
Training loss: 2.210463186548121
Validation loss: 2.496271269390411

Epoch: 5| Step: 1
Training loss: 2.36948940040164
Validation loss: 2.5058144188503144

Epoch: 5| Step: 2
Training loss: 2.4098751949110575
Validation loss: 2.5094054996573614

Epoch: 5| Step: 3
Training loss: 2.1742461728810945
Validation loss: 2.51245012407791

Epoch: 5| Step: 4
Training loss: 2.0504686099116842
Validation loss: 2.522630832260928

Epoch: 5| Step: 5
Training loss: 2.0509477238979326
Validation loss: 2.513939464586059

Epoch: 5| Step: 6
Training loss: 2.7986445449922877
Validation loss: 2.525205313798744

Epoch: 5| Step: 7
Training loss: 2.25256222959668
Validation loss: 2.527385760453909

Epoch: 5| Step: 8
Training loss: 2.8692725808874653
Validation loss: 2.533324755138589

Epoch: 5| Step: 9
Training loss: 2.278577519437283
Validation loss: 2.548238935127638

Epoch: 5| Step: 10
Training loss: 2.254084165218584
Validation loss: 2.564444207560677

Epoch: 5| Step: 11
Training loss: 2.9129425432986285
Validation loss: 2.5543346297425793

Epoch: 225| Step: 0
Training loss: 2.1992644987887027
Validation loss: 2.5631302624474563

Epoch: 5| Step: 1
Training loss: 2.2943102991618924
Validation loss: 2.5760135751424795

Epoch: 5| Step: 2
Training loss: 2.708608368822318
Validation loss: 2.56871211696142

Epoch: 5| Step: 3
Training loss: 2.4698134437565216
Validation loss: 2.5730355591788423

Epoch: 5| Step: 4
Training loss: 2.493996755681991
Validation loss: 2.5736841930865095

Epoch: 5| Step: 5
Training loss: 2.5832884897421216
Validation loss: 2.5671675785194914

Epoch: 5| Step: 6
Training loss: 2.5002424122584896
Validation loss: 2.5540515018551346

Epoch: 5| Step: 7
Training loss: 1.9005139458879023
Validation loss: 2.555394190609551

Epoch: 5| Step: 8
Training loss: 2.2565937910986333
Validation loss: 2.5533394012636372

Epoch: 5| Step: 9
Training loss: 2.1127132421005856
Validation loss: 2.5374293038741134

Epoch: 5| Step: 10
Training loss: 2.6838619536816117
Validation loss: 2.516930480312707

Epoch: 5| Step: 11
Training loss: 1.9527519785390337
Validation loss: 2.527211664866624

Epoch: 226| Step: 0
Training loss: 1.8731686867732085
Validation loss: 2.5175913910754253

Epoch: 5| Step: 1
Training loss: 1.9613774630554384
Validation loss: 2.5149884178673543

Epoch: 5| Step: 2
Training loss: 2.352702830668598
Validation loss: 2.517068630342482

Epoch: 5| Step: 3
Training loss: 3.0176182617678604
Validation loss: 2.5235308382863333

Epoch: 5| Step: 4
Training loss: 2.088020342088316
Validation loss: 2.5195761072862566

Epoch: 5| Step: 5
Training loss: 2.8301790481379516
Validation loss: 2.511349731516923

Epoch: 5| Step: 6
Training loss: 2.241550155599276
Validation loss: 2.513509540112781

Epoch: 5| Step: 7
Training loss: 1.995155068970094
Validation loss: 2.5216855599976618

Epoch: 5| Step: 8
Training loss: 2.4056092437125067
Validation loss: 2.5164472251129197

Epoch: 5| Step: 9
Training loss: 2.2223607086369244
Validation loss: 2.5114962972215875

Epoch: 5| Step: 10
Training loss: 2.8627281331269963
Validation loss: 2.5261296810796576

Epoch: 5| Step: 11
Training loss: 1.8796057400318864
Validation loss: 2.5301550588787753

Epoch: 227| Step: 0
Training loss: 2.353550979538653
Validation loss: 2.5449491212976523

Epoch: 5| Step: 1
Training loss: 2.3428852774927824
Validation loss: 2.562763502947808

Epoch: 5| Step: 2
Training loss: 2.179653591316108
Validation loss: 2.5736184778215003

Epoch: 5| Step: 3
Training loss: 2.285144564606875
Validation loss: 2.5683944216272208

Epoch: 5| Step: 4
Training loss: 2.362398748902462
Validation loss: 2.5419397767611795

Epoch: 5| Step: 5
Training loss: 2.0079681692374147
Validation loss: 2.5165292327082884

Epoch: 5| Step: 6
Training loss: 1.8207774734948943
Validation loss: 2.4897408588536685

Epoch: 5| Step: 7
Training loss: 2.957900127517438
Validation loss: 2.4960496646846466

Epoch: 5| Step: 8
Training loss: 2.1254187900532857
Validation loss: 2.481771960796942

Epoch: 5| Step: 9
Training loss: 2.628729486970412
Validation loss: 2.4914203208381656

Epoch: 5| Step: 10
Training loss: 3.024217608448425
Validation loss: 2.498241867317118

Epoch: 5| Step: 11
Training loss: 3.3481501923738963
Validation loss: 2.5009933365856747

Epoch: 228| Step: 0
Training loss: 2.609216376868419
Validation loss: 2.498014937518029

Epoch: 5| Step: 1
Training loss: 2.0384625834890047
Validation loss: 2.498223086523105

Epoch: 5| Step: 2
Training loss: 2.128075337775783
Validation loss: 2.4978472500897415

Epoch: 5| Step: 3
Training loss: 2.5059085641910763
Validation loss: 2.516760327057375

Epoch: 5| Step: 4
Training loss: 2.415290989058795
Validation loss: 2.5345983219492654

Epoch: 5| Step: 5
Training loss: 2.4407299844627763
Validation loss: 2.556814818717209

Epoch: 5| Step: 6
Training loss: 2.0057443141901836
Validation loss: 2.5720836485242464

Epoch: 5| Step: 7
Training loss: 2.5489615102191348
Validation loss: 2.5712388677607962

Epoch: 5| Step: 8
Training loss: 2.8164534015914735
Validation loss: 2.5690476262909816

Epoch: 5| Step: 9
Training loss: 2.4776977440130294
Validation loss: 2.5659916512375056

Epoch: 5| Step: 10
Training loss: 2.0824552465715533
Validation loss: 2.56027826665087

Epoch: 5| Step: 11
Training loss: 2.366211642817425
Validation loss: 2.5683852316518183

Epoch: 229| Step: 0
Training loss: 2.261152285462113
Validation loss: 2.5463464730710204

Epoch: 5| Step: 1
Training loss: 2.594505659584258
Validation loss: 2.5346058275912675

Epoch: 5| Step: 2
Training loss: 2.1899196866084303
Validation loss: 2.5164530341051026

Epoch: 5| Step: 3
Training loss: 2.921706903691591
Validation loss: 2.504018266287881

Epoch: 5| Step: 4
Training loss: 2.129124509489851
Validation loss: 2.4885226241913827

Epoch: 5| Step: 5
Training loss: 2.0540605756227435
Validation loss: 2.480194761508005

Epoch: 5| Step: 6
Training loss: 2.6286544792608044
Validation loss: 2.482142987256179

Epoch: 5| Step: 7
Training loss: 2.080123514029435
Validation loss: 2.4858052637146133

Epoch: 5| Step: 8
Training loss: 2.3709798216747475
Validation loss: 2.482920678840678

Epoch: 5| Step: 9
Training loss: 2.7024404728462277
Validation loss: 2.485087754313875

Epoch: 5| Step: 10
Training loss: 2.4478911919316637
Validation loss: 2.4806760285846794

Epoch: 5| Step: 11
Training loss: 2.9031452289118795
Validation loss: 2.47999437857383

Epoch: 230| Step: 0
Training loss: 2.4624730723501447
Validation loss: 2.505131402423931

Epoch: 5| Step: 1
Training loss: 2.4459249198787933
Validation loss: 2.5026431217926173

Epoch: 5| Step: 2
Training loss: 2.3367312304419507
Validation loss: 2.5107978133107247

Epoch: 5| Step: 3
Training loss: 2.5336206896417455
Validation loss: 2.528582372108056

Epoch: 5| Step: 4
Training loss: 2.5507830259074504
Validation loss: 2.5266967173171615

Epoch: 5| Step: 5
Training loss: 2.1811304272775387
Validation loss: 2.5192403935950267

Epoch: 5| Step: 6
Training loss: 1.8974528329688922
Validation loss: 2.53104368789755

Epoch: 5| Step: 7
Training loss: 2.597763724720999
Validation loss: 2.5301390121049594

Epoch: 5| Step: 8
Training loss: 2.4593654879588427
Validation loss: 2.5527526496791513

Epoch: 5| Step: 9
Training loss: 2.2484678774034847
Validation loss: 2.5362384369224498

Epoch: 5| Step: 10
Training loss: 2.102182289821383
Validation loss: 2.5383032812976616

Epoch: 5| Step: 11
Training loss: 3.710880190758135
Validation loss: 2.5266461910745077

Epoch: 231| Step: 0
Training loss: 1.85120687811867
Validation loss: 2.538510776144511

Epoch: 5| Step: 1
Training loss: 1.6556505521974803
Validation loss: 2.535212997639963

Epoch: 5| Step: 2
Training loss: 2.45004662449906
Validation loss: 2.5154894798216536

Epoch: 5| Step: 3
Training loss: 2.2801681461571546
Validation loss: 2.5049639574060727

Epoch: 5| Step: 4
Training loss: 2.0941382660200527
Validation loss: 2.504497607023802

Epoch: 5| Step: 5
Training loss: 2.2365206573098604
Validation loss: 2.5002326221323043

Epoch: 5| Step: 6
Training loss: 2.808991002199803
Validation loss: 2.4965637910662646

Epoch: 5| Step: 7
Training loss: 2.5172465529994565
Validation loss: 2.5098868631452107

Epoch: 5| Step: 8
Training loss: 2.6010152338528543
Validation loss: 2.507151333334359

Epoch: 5| Step: 9
Training loss: 2.330981045260089
Validation loss: 2.516051159573074

Epoch: 5| Step: 10
Training loss: 2.9382245407981396
Validation loss: 2.544210713722972

Epoch: 5| Step: 11
Training loss: 3.5041679361154356
Validation loss: 2.531104429007269

Epoch: 232| Step: 0
Training loss: 2.7036490400972983
Validation loss: 2.5427266878317036

Epoch: 5| Step: 1
Training loss: 2.716648736750248
Validation loss: 2.521401598748911

Epoch: 5| Step: 2
Training loss: 2.3194182756766244
Validation loss: 2.531347437737491

Epoch: 5| Step: 3
Training loss: 2.1674234340216474
Validation loss: 2.5173275440360467

Epoch: 5| Step: 4
Training loss: 1.5234006437098198
Validation loss: 2.5141399178005543

Epoch: 5| Step: 5
Training loss: 2.840935792277306
Validation loss: 2.52300587870976

Epoch: 5| Step: 6
Training loss: 1.8050210487638954
Validation loss: 2.5150458496520396

Epoch: 5| Step: 7
Training loss: 2.4852576457267586
Validation loss: 2.5066592534780794

Epoch: 5| Step: 8
Training loss: 2.558243822236264
Validation loss: 2.51811182615928

Epoch: 5| Step: 9
Training loss: 2.7346540036229903
Validation loss: 2.5155857786039344

Epoch: 5| Step: 10
Training loss: 1.8598765490182112
Validation loss: 2.521703917866305

Epoch: 5| Step: 11
Training loss: 1.7416591784059205
Validation loss: 2.5333481362081844

Epoch: 233| Step: 0
Training loss: 2.5597908772050055
Validation loss: 2.5352832819181605

Epoch: 5| Step: 1
Training loss: 2.3481135121385104
Validation loss: 2.554139310795051

Epoch: 5| Step: 2
Training loss: 3.0234733007711636
Validation loss: 2.5749124413328706

Epoch: 5| Step: 3
Training loss: 2.7412175476407654
Validation loss: 2.5679611419481474

Epoch: 5| Step: 4
Training loss: 2.1237516663417373
Validation loss: 2.5458458730531364

Epoch: 5| Step: 5
Training loss: 2.2834734597565074
Validation loss: 2.5433577842045376

Epoch: 5| Step: 6
Training loss: 2.2358311529879957
Validation loss: 2.5376548777765375

Epoch: 5| Step: 7
Training loss: 2.5902993102168734
Validation loss: 2.5082826975741814

Epoch: 5| Step: 8
Training loss: 1.98954076538351
Validation loss: 2.495909129336108

Epoch: 5| Step: 9
Training loss: 1.8807783733287926
Validation loss: 2.5038283123199707

Epoch: 5| Step: 10
Training loss: 2.261858841900797
Validation loss: 2.502282193709356

Epoch: 5| Step: 11
Training loss: 2.6992535512974496
Validation loss: 2.509777214528202

Epoch: 234| Step: 0
Training loss: 2.4884857141637697
Validation loss: 2.5107164019330455

Epoch: 5| Step: 1
Training loss: 2.4527559427988965
Validation loss: 2.5078976578083703

Epoch: 5| Step: 2
Training loss: 2.3917962489983156
Validation loss: 2.5231138126092825

Epoch: 5| Step: 3
Training loss: 1.8463568281648624
Validation loss: 2.5333041698153305

Epoch: 5| Step: 4
Training loss: 1.9986911305530835
Validation loss: 2.545819139727179

Epoch: 5| Step: 5
Training loss: 2.355667637261766
Validation loss: 2.5581995497794243

Epoch: 5| Step: 6
Training loss: 2.3467018358167246
Validation loss: 2.570975796839444

Epoch: 5| Step: 7
Training loss: 2.259835046808005
Validation loss: 2.5663331677982257

Epoch: 5| Step: 8
Training loss: 2.608934742226562
Validation loss: 2.598513170747334

Epoch: 5| Step: 9
Training loss: 2.5618632386070916
Validation loss: 2.6015804412345345

Epoch: 5| Step: 10
Training loss: 2.762116097404447
Validation loss: 2.6165353066786015

Epoch: 5| Step: 11
Training loss: 1.3364539681787282
Validation loss: 2.6009477914397805

Epoch: 235| Step: 0
Training loss: 2.097365375149552
Validation loss: 2.579450790447813

Epoch: 5| Step: 1
Training loss: 2.4007459832185374
Validation loss: 2.5674199734863308

Epoch: 5| Step: 2
Training loss: 2.1599330683334093
Validation loss: 2.561069954004489

Epoch: 5| Step: 3
Training loss: 1.9667844497303333
Validation loss: 2.538376786976118

Epoch: 5| Step: 4
Training loss: 2.86228386342007
Validation loss: 2.528223154954808

Epoch: 5| Step: 5
Training loss: 2.455581698367203
Validation loss: 2.5211454045934563

Epoch: 5| Step: 6
Training loss: 2.3580532792844897
Validation loss: 2.5163248995848773

Epoch: 5| Step: 7
Training loss: 3.0338202522357807
Validation loss: 2.5075508765538865

Epoch: 5| Step: 8
Training loss: 2.2542336158423555
Validation loss: 2.5076596975072083

Epoch: 5| Step: 9
Training loss: 2.0134510470498075
Validation loss: 2.5037428891377274

Epoch: 5| Step: 10
Training loss: 2.049754556058307
Validation loss: 2.5095147429273426

Epoch: 5| Step: 11
Training loss: 3.3880963015330474
Validation loss: 2.521366399304437

Epoch: 236| Step: 0
Training loss: 2.114793726284014
Validation loss: 2.5226113272965653

Epoch: 5| Step: 1
Training loss: 2.3136402102842273
Validation loss: 2.5347024504588624

Epoch: 5| Step: 2
Training loss: 2.3273523059699226
Validation loss: 2.556930210857385

Epoch: 5| Step: 3
Training loss: 1.9795477115501579
Validation loss: 2.590138498663382

Epoch: 5| Step: 4
Training loss: 2.176807100089711
Validation loss: 2.591140890196617

Epoch: 5| Step: 5
Training loss: 2.830676703272507
Validation loss: 2.60185124014016

Epoch: 5| Step: 6
Training loss: 2.3553423238705595
Validation loss: 2.5858070171585346

Epoch: 5| Step: 7
Training loss: 1.9058988904443288
Validation loss: 2.574023951876711

Epoch: 5| Step: 8
Training loss: 2.5402659219926673
Validation loss: 2.5686273432620124

Epoch: 5| Step: 9
Training loss: 2.935766154796634
Validation loss: 2.5425851809005757

Epoch: 5| Step: 10
Training loss: 2.4192319168119822
Validation loss: 2.5400435327756763

Epoch: 5| Step: 11
Training loss: 2.8906480942911914
Validation loss: 2.543303390025022

Epoch: 237| Step: 0
Training loss: 2.602186798245869
Validation loss: 2.536760129474589

Epoch: 5| Step: 1
Training loss: 1.9981684643096225
Validation loss: 2.5385726690975505

Epoch: 5| Step: 2
Training loss: 2.294951898905996
Validation loss: 2.5302748351913436

Epoch: 5| Step: 3
Training loss: 2.0523518678688304
Validation loss: 2.5312422410822504

Epoch: 5| Step: 4
Training loss: 2.2817541114132283
Validation loss: 2.5308890654446454

Epoch: 5| Step: 5
Training loss: 2.3390491390929675
Validation loss: 2.5352831800412616

Epoch: 5| Step: 6
Training loss: 2.04329397264233
Validation loss: 2.540658001530933

Epoch: 5| Step: 7
Training loss: 2.0620135109252513
Validation loss: 2.531865570978659

Epoch: 5| Step: 8
Training loss: 2.6862728067160364
Validation loss: 2.5417893698001968

Epoch: 5| Step: 9
Training loss: 2.8187353738544885
Validation loss: 2.5419992531555984

Epoch: 5| Step: 10
Training loss: 2.662775349594563
Validation loss: 2.56197231566078

Epoch: 5| Step: 11
Training loss: 2.2327921135667794
Validation loss: 2.5604043392777527

Epoch: 238| Step: 0
Training loss: 2.6325557594878677
Validation loss: 2.567248248393243

Epoch: 5| Step: 1
Training loss: 2.2303430418275383
Validation loss: 2.5612546988500458

Epoch: 5| Step: 2
Training loss: 2.1583693772574843
Validation loss: 2.5587069576154766

Epoch: 5| Step: 3
Training loss: 2.9116852500714083
Validation loss: 2.555657726528276

Epoch: 5| Step: 4
Training loss: 2.0966637676968976
Validation loss: 2.549471044998299

Epoch: 5| Step: 5
Training loss: 1.9142375009683426
Validation loss: 2.529541816781253

Epoch: 5| Step: 6
Training loss: 1.9205040732938659
Validation loss: 2.5362227694079102

Epoch: 5| Step: 7
Training loss: 2.04511925328631
Validation loss: 2.5307582722966155

Epoch: 5| Step: 8
Training loss: 2.689930814541114
Validation loss: 2.5274712610481744

Epoch: 5| Step: 9
Training loss: 2.442365924665475
Validation loss: 2.522780574012375

Epoch: 5| Step: 10
Training loss: 2.7151251996926593
Validation loss: 2.5099515774287435

Epoch: 5| Step: 11
Training loss: 1.9479249624255865
Validation loss: 2.51951124395269

Epoch: 239| Step: 0
Training loss: 2.3235224345933996
Validation loss: 2.524758559036491

Epoch: 5| Step: 1
Training loss: 2.765939037360067
Validation loss: 2.5253970211741676

Epoch: 5| Step: 2
Training loss: 1.7351410007622565
Validation loss: 2.5137310638612376

Epoch: 5| Step: 3
Training loss: 2.7110472555231655
Validation loss: 2.538466120396586

Epoch: 5| Step: 4
Training loss: 2.0229973627319344
Validation loss: 2.5296270874173667

Epoch: 5| Step: 5
Training loss: 2.6097009877772335
Validation loss: 2.5457891204936467

Epoch: 5| Step: 6
Training loss: 1.9419791222617866
Validation loss: 2.564896350839835

Epoch: 5| Step: 7
Training loss: 1.8882220421924265
Validation loss: 2.5452488932849295

Epoch: 5| Step: 8
Training loss: 3.0240181456531072
Validation loss: 2.5510386190607806

Epoch: 5| Step: 9
Training loss: 1.8415985486075401
Validation loss: 2.5404322836943716

Epoch: 5| Step: 10
Training loss: 2.368717718785128
Validation loss: 2.5402074922017808

Epoch: 5| Step: 11
Training loss: 3.5410086226144224
Validation loss: 2.5283760584283055

Epoch: 240| Step: 0
Training loss: 2.751426500190348
Validation loss: 2.532020763503796

Epoch: 5| Step: 1
Training loss: 2.5206976504630716
Validation loss: 2.5428075236333956

Epoch: 5| Step: 2
Training loss: 2.9419356600470454
Validation loss: 2.5536213398977097

Epoch: 5| Step: 3
Training loss: 1.9850494560211167
Validation loss: 2.565590735178411

Epoch: 5| Step: 4
Training loss: 1.635373384263371
Validation loss: 2.562374627527664

Epoch: 5| Step: 5
Training loss: 1.617848284338329
Validation loss: 2.551505149170304

Epoch: 5| Step: 6
Training loss: 2.0693366287899977
Validation loss: 2.546476668429915

Epoch: 5| Step: 7
Training loss: 2.5070755966225224
Validation loss: 2.56124072030234

Epoch: 5| Step: 8
Training loss: 2.6805924647485395
Validation loss: 2.5529369341012202

Epoch: 5| Step: 9
Training loss: 2.3589390231891354
Validation loss: 2.550980221834054

Epoch: 5| Step: 10
Training loss: 2.4283327698646926
Validation loss: 2.552803007495715

Epoch: 5| Step: 11
Training loss: 1.9428335427305425
Validation loss: 2.5365992055908695

Epoch: 241| Step: 0
Training loss: 2.0942192121239254
Validation loss: 2.530268743842662

Epoch: 5| Step: 1
Training loss: 2.254152704314345
Validation loss: 2.513334040650117

Epoch: 5| Step: 2
Training loss: 2.3779225688099297
Validation loss: 2.4965987513013563

Epoch: 5| Step: 3
Training loss: 2.5648636500236988
Validation loss: 2.4873677787272723

Epoch: 5| Step: 4
Training loss: 2.247867315232024
Validation loss: 2.502656725048093

Epoch: 5| Step: 5
Training loss: 2.217098319778401
Validation loss: 2.4779172354854095

Epoch: 5| Step: 6
Training loss: 2.6480752252686557
Validation loss: 2.487250709022868

Epoch: 5| Step: 7
Training loss: 1.8091596537834376
Validation loss: 2.5013588192787046

Epoch: 5| Step: 8
Training loss: 1.9660249651878954
Validation loss: 2.489421305843901

Epoch: 5| Step: 9
Training loss: 2.889869054975887
Validation loss: 2.503995876920015

Epoch: 5| Step: 10
Training loss: 2.53403969085849
Validation loss: 2.5291938495641593

Epoch: 5| Step: 11
Training loss: 3.5158416003153925
Validation loss: 2.526032734229166

Epoch: 242| Step: 0
Training loss: 2.6618896751957655
Validation loss: 2.525833917051588

Epoch: 5| Step: 1
Training loss: 2.218237804340194
Validation loss: 2.5329655340025763

Epoch: 5| Step: 2
Training loss: 2.252799729400857
Validation loss: 2.5097914797073346

Epoch: 5| Step: 3
Training loss: 2.2452270958784215
Validation loss: 2.52459137697812

Epoch: 5| Step: 4
Training loss: 2.405320223230524
Validation loss: 2.5356602062551574

Epoch: 5| Step: 5
Training loss: 2.924770287516818
Validation loss: 2.526799205700364

Epoch: 5| Step: 6
Training loss: 2.225715770675469
Validation loss: 2.5403254453980164

Epoch: 5| Step: 7
Training loss: 2.211183999275027
Validation loss: 2.529335563687801

Epoch: 5| Step: 8
Training loss: 2.5194409731282925
Validation loss: 2.531783381335981

Epoch: 5| Step: 9
Training loss: 1.9326672733056356
Validation loss: 2.5229341223375634

Epoch: 5| Step: 10
Training loss: 2.3230898896592467
Validation loss: 2.531640846783346

Epoch: 5| Step: 11
Training loss: 1.315123071314334
Validation loss: 2.5329683342573417

Epoch: 243| Step: 0
Training loss: 2.5047794432253117
Validation loss: 2.5322934853031893

Epoch: 5| Step: 1
Training loss: 2.3907202408711656
Validation loss: 2.5238782932711614

Epoch: 5| Step: 2
Training loss: 2.635936389282933
Validation loss: 2.521728549109934

Epoch: 5| Step: 3
Training loss: 2.1439311537649104
Validation loss: 2.5452346082633586

Epoch: 5| Step: 4
Training loss: 2.0071566805729573
Validation loss: 2.5477345036296875

Epoch: 5| Step: 5
Training loss: 2.3849121848520056
Validation loss: 2.5532298036602823

Epoch: 5| Step: 6
Training loss: 2.115505549835376
Validation loss: 2.5447870600863367

Epoch: 5| Step: 7
Training loss: 2.0208032612349167
Validation loss: 2.5498426578947244

Epoch: 5| Step: 8
Training loss: 2.5278672585585045
Validation loss: 2.5620375425281594

Epoch: 5| Step: 9
Training loss: 2.7089584998426295
Validation loss: 2.5477911426714734

Epoch: 5| Step: 10
Training loss: 2.443399479305914
Validation loss: 2.5521466163003432

Epoch: 5| Step: 11
Training loss: 1.4845346465341434
Validation loss: 2.554748235013612

Epoch: 244| Step: 0
Training loss: 2.6127019448234297
Validation loss: 2.5425163644047086

Epoch: 5| Step: 1
Training loss: 2.6104665517543735
Validation loss: 2.531229611695364

Epoch: 5| Step: 2
Training loss: 2.560382805753763
Validation loss: 2.530578410375402

Epoch: 5| Step: 3
Training loss: 1.765920293640115
Validation loss: 2.5259687681920218

Epoch: 5| Step: 4
Training loss: 2.321661560188076
Validation loss: 2.538222392065046

Epoch: 5| Step: 5
Training loss: 2.595268081018513
Validation loss: 2.5200793337980434

Epoch: 5| Step: 6
Training loss: 2.4163369140149413
Validation loss: 2.5273224693632703

Epoch: 5| Step: 7
Training loss: 2.187019622372831
Validation loss: 2.538392186815294

Epoch: 5| Step: 8
Training loss: 2.4782290462091785
Validation loss: 2.5513250171523185

Epoch: 5| Step: 9
Training loss: 2.3244077974258586
Validation loss: 2.5477903784466034

Epoch: 5| Step: 10
Training loss: 1.8276560907460844
Validation loss: 2.550313866846346

Epoch: 5| Step: 11
Training loss: 1.4267403499048987
Validation loss: 2.5560073903740097

Epoch: 245| Step: 0
Training loss: 2.625774904951098
Validation loss: 2.557228290888741

Epoch: 5| Step: 1
Training loss: 1.9492022374128357
Validation loss: 2.570157835847403

Epoch: 5| Step: 2
Training loss: 2.037707232836491
Validation loss: 2.5785489822246523

Epoch: 5| Step: 3
Training loss: 2.6788011870164135
Validation loss: 2.5725243162446163

Epoch: 5| Step: 4
Training loss: 2.0097295611438737
Validation loss: 2.5599638903015762

Epoch: 5| Step: 5
Training loss: 2.530513420782433
Validation loss: 2.5587763480920342

Epoch: 5| Step: 6
Training loss: 2.2044488703369676
Validation loss: 2.5551309968607923

Epoch: 5| Step: 7
Training loss: 2.5953537911857256
Validation loss: 2.5386084145646204

Epoch: 5| Step: 8
Training loss: 2.2140772870848062
Validation loss: 2.5412392895346656

Epoch: 5| Step: 9
Training loss: 2.131596145039983
Validation loss: 2.5504030041660295

Epoch: 5| Step: 10
Training loss: 2.420905626785664
Validation loss: 2.5259978195527353

Epoch: 5| Step: 11
Training loss: 2.8095250820514175
Validation loss: 2.5336539426905746

Epoch: 246| Step: 0
Training loss: 2.0024240823706547
Validation loss: 2.5417251632295907

Epoch: 5| Step: 1
Training loss: 2.7996173392803034
Validation loss: 2.535773015637385

Epoch: 5| Step: 2
Training loss: 2.3093991496432675
Validation loss: 2.5305256140643126

Epoch: 5| Step: 3
Training loss: 2.530689883956018
Validation loss: 2.543939107446797

Epoch: 5| Step: 4
Training loss: 2.5852477660686395
Validation loss: 2.530079677028277

Epoch: 5| Step: 5
Training loss: 2.054441255963904
Validation loss: 2.547500034390924

Epoch: 5| Step: 6
Training loss: 2.517103057145847
Validation loss: 2.535280135487425

Epoch: 5| Step: 7
Training loss: 2.646767058530384
Validation loss: 2.531773960373441

Epoch: 5| Step: 8
Training loss: 2.394521691457268
Validation loss: 2.5347185114538706

Epoch: 5| Step: 9
Training loss: 1.8658476295735615
Validation loss: 2.5657264277442655

Epoch: 5| Step: 10
Training loss: 1.869760631703961
Validation loss: 2.582712046198048

Epoch: 5| Step: 11
Training loss: 2.5803024806645505
Validation loss: 2.609335154764062

Epoch: 247| Step: 0
Training loss: 2.144351916988063
Validation loss: 2.6266545330461635

Epoch: 5| Step: 1
Training loss: 2.6732985067437656
Validation loss: 2.6231075345181183

Epoch: 5| Step: 2
Training loss: 2.388396577106426
Validation loss: 2.6208341671791224

Epoch: 5| Step: 3
Training loss: 2.7652150513003044
Validation loss: 2.6215283544734858

Epoch: 5| Step: 4
Training loss: 2.231054118985472
Validation loss: 2.6427545406365214

Epoch: 5| Step: 5
Training loss: 2.7058160870089285
Validation loss: 2.645634104268977

Epoch: 5| Step: 6
Training loss: 2.7266237967959843
Validation loss: 2.6383191109846473

Epoch: 5| Step: 7
Training loss: 2.495988488403086
Validation loss: 2.6306341537892743

Epoch: 5| Step: 8
Training loss: 1.9481371858452492
Validation loss: 2.585781138783904

Epoch: 5| Step: 9
Training loss: 1.8902294911721367
Validation loss: 2.545984557187367

Epoch: 5| Step: 10
Training loss: 1.8270172936550704
Validation loss: 2.5311464790870795

Epoch: 5| Step: 11
Training loss: 1.6022411118271422
Validation loss: 2.5181229985502873

Epoch: 248| Step: 0
Training loss: 2.082240110302634
Validation loss: 2.5065443629488606

Epoch: 5| Step: 1
Training loss: 2.0800137075559397
Validation loss: 2.500022752976193

Epoch: 5| Step: 2
Training loss: 2.345299983896587
Validation loss: 2.504883883291986

Epoch: 5| Step: 3
Training loss: 2.713440105468174
Validation loss: 2.499237373380445

Epoch: 5| Step: 4
Training loss: 2.7327252452044255
Validation loss: 2.488246264728267

Epoch: 5| Step: 5
Training loss: 1.9574172806100667
Validation loss: 2.5016700729441808

Epoch: 5| Step: 6
Training loss: 2.2058280433252206
Validation loss: 2.504615746650471

Epoch: 5| Step: 7
Training loss: 1.8261864972676625
Validation loss: 2.5149316483797395

Epoch: 5| Step: 8
Training loss: 2.2698357750392852
Validation loss: 2.534999436993508

Epoch: 5| Step: 9
Training loss: 2.662903385319242
Validation loss: 2.5433892421485202

Epoch: 5| Step: 10
Training loss: 2.8323287491909643
Validation loss: 2.5739962453197274

Epoch: 5| Step: 11
Training loss: 2.922795767718381
Validation loss: 2.6082620779080994

Epoch: 249| Step: 0
Training loss: 2.2103408709398353
Validation loss: 2.630961675998409

Epoch: 5| Step: 1
Training loss: 1.8851616477968076
Validation loss: 2.633978060272053

Epoch: 5| Step: 2
Training loss: 3.2444078311276803
Validation loss: 2.582869985517269

Epoch: 5| Step: 3
Training loss: 2.347169746349051
Validation loss: 2.539840410837188

Epoch: 5| Step: 4
Training loss: 2.6620587731056027
Validation loss: 2.5265718231469525

Epoch: 5| Step: 5
Training loss: 2.8537876592182276
Validation loss: 2.515327633485858

Epoch: 5| Step: 6
Training loss: 1.8208665127499128
Validation loss: 2.5070008601471345

Epoch: 5| Step: 7
Training loss: 2.026138800194248
Validation loss: 2.5125390113028767

Epoch: 5| Step: 8
Training loss: 2.4536884414016913
Validation loss: 2.513726082439381

Epoch: 5| Step: 9
Training loss: 2.2570002061525183
Validation loss: 2.511286609864466

Epoch: 5| Step: 10
Training loss: 2.700892237423372
Validation loss: 2.5207590389075145

Epoch: 5| Step: 11
Training loss: 2.0157865710890888
Validation loss: 2.521423232728238

Epoch: 250| Step: 0
Training loss: 3.1599010840760537
Validation loss: 2.5185511651765773

Epoch: 5| Step: 1
Training loss: 1.3449847735993108
Validation loss: 2.541152156804505

Epoch: 5| Step: 2
Training loss: 2.2631520422389397
Validation loss: 2.5552860534849486

Epoch: 5| Step: 3
Training loss: 2.422451319879572
Validation loss: 2.5675711385559428

Epoch: 5| Step: 4
Training loss: 1.9568956522307168
Validation loss: 2.578747063544348

Epoch: 5| Step: 5
Training loss: 2.1963494183569905
Validation loss: 2.601695052579983

Epoch: 5| Step: 6
Training loss: 2.5612062118905343
Validation loss: 2.5928940260647213

Epoch: 5| Step: 7
Training loss: 1.8542292580773312
Validation loss: 2.601847276957623

Epoch: 5| Step: 8
Training loss: 2.6898472316430233
Validation loss: 2.5973650661553735

Epoch: 5| Step: 9
Training loss: 2.6260709848448207
Validation loss: 2.6127014087082028

Epoch: 5| Step: 10
Training loss: 2.177163470921228
Validation loss: 2.584278373495582

Epoch: 5| Step: 11
Training loss: 2.9309051831415354
Validation loss: 2.5758095525764624

Epoch: 251| Step: 0
Training loss: 2.1526270851252303
Validation loss: 2.585343864198717

Epoch: 5| Step: 1
Training loss: 2.212228674335013
Validation loss: 2.5850976922927313

Epoch: 5| Step: 2
Training loss: 2.536599804786146
Validation loss: 2.6121765941932695

Epoch: 5| Step: 3
Training loss: 2.5034474444974553
Validation loss: 2.5992194728087834

Epoch: 5| Step: 4
Training loss: 2.5593202913466557
Validation loss: 2.624682426164624

Epoch: 5| Step: 5
Training loss: 2.55838128292449
Validation loss: 2.61847035865549

Epoch: 5| Step: 6
Training loss: 2.120724584443139
Validation loss: 2.5953294740076256

Epoch: 5| Step: 7
Training loss: 2.606478516877062
Validation loss: 2.560721466373987

Epoch: 5| Step: 8
Training loss: 2.3137440814618007
Validation loss: 2.5467874983907834

Epoch: 5| Step: 9
Training loss: 2.3813501091686926
Validation loss: 2.5318278449808918

Epoch: 5| Step: 10
Training loss: 1.7320344270187513
Validation loss: 2.513823644190658

Epoch: 5| Step: 11
Training loss: 3.676618134174532
Validation loss: 2.521196210505233

Epoch: 252| Step: 0
Training loss: 2.4607615574506507
Validation loss: 2.512383060201163

Epoch: 5| Step: 1
Training loss: 2.6057072062802527
Validation loss: 2.5157209460993553

Epoch: 5| Step: 2
Training loss: 1.9785183363328227
Validation loss: 2.516440285096524

Epoch: 5| Step: 3
Training loss: 2.1093592890401602
Validation loss: 2.512642978598135

Epoch: 5| Step: 4
Training loss: 1.896362552206946
Validation loss: 2.5237719153815754

Epoch: 5| Step: 5
Training loss: 2.52940904523231
Validation loss: 2.5204039232889697

Epoch: 5| Step: 6
Training loss: 2.694168511470781
Validation loss: 2.513746136504773

Epoch: 5| Step: 7
Training loss: 3.1722234525156687
Validation loss: 2.5172460971881203

Epoch: 5| Step: 8
Training loss: 1.9090257665534827
Validation loss: 2.518536164677993

Epoch: 5| Step: 9
Training loss: 2.255144489844157
Validation loss: 2.516029021396201

Epoch: 5| Step: 10
Training loss: 1.9278877297791002
Validation loss: 2.5187491689070094

Epoch: 5| Step: 11
Training loss: 3.0237227904099657
Validation loss: 2.5221990256624562

Epoch: 253| Step: 0
Training loss: 2.2199886249560112
Validation loss: 2.535850935214761

Epoch: 5| Step: 1
Training loss: 2.4369524805431757
Validation loss: 2.5407938487808317

Epoch: 5| Step: 2
Training loss: 2.4892309942405886
Validation loss: 2.558020561019308

Epoch: 5| Step: 3
Training loss: 2.1489648899922003
Validation loss: 2.574176936564938

Epoch: 5| Step: 4
Training loss: 2.871770952766144
Validation loss: 2.5806300352414984

Epoch: 5| Step: 5
Training loss: 2.3760852342017635
Validation loss: 2.578612098532253

Epoch: 5| Step: 6
Training loss: 3.003740839378685
Validation loss: 2.590983543233803

Epoch: 5| Step: 7
Training loss: 2.1814573479066888
Validation loss: 2.5838240277937388

Epoch: 5| Step: 8
Training loss: 1.8598886629847875
Validation loss: 2.56524113065131

Epoch: 5| Step: 9
Training loss: 2.160589633395089
Validation loss: 2.5593196237214615

Epoch: 5| Step: 10
Training loss: 1.5264722283964265
Validation loss: 2.5535148627996023

Epoch: 5| Step: 11
Training loss: 1.8702516831124132
Validation loss: 2.546610313344592

Epoch: 254| Step: 0
Training loss: 2.921379169681977
Validation loss: 2.5386817724932342

Epoch: 5| Step: 1
Training loss: 2.0840206411221773
Validation loss: 2.544330773221809

Epoch: 5| Step: 2
Training loss: 2.5745284454261896
Validation loss: 2.5304376688005603

Epoch: 5| Step: 3
Training loss: 2.6761848535140884
Validation loss: 2.5446549707696433

Epoch: 5| Step: 4
Training loss: 1.9883572127365052
Validation loss: 2.564630735182903

Epoch: 5| Step: 5
Training loss: 2.2263519722975573
Validation loss: 2.577543539887546

Epoch: 5| Step: 6
Training loss: 2.160805354625588
Validation loss: 2.5824128184969735

Epoch: 5| Step: 7
Training loss: 2.308943823592374
Validation loss: 2.595692408998604

Epoch: 5| Step: 8
Training loss: 1.8584974125271188
Validation loss: 2.5652617481967557

Epoch: 5| Step: 9
Training loss: 2.9465390997958907
Validation loss: 2.5591313775214344

Epoch: 5| Step: 10
Training loss: 1.6713146090519342
Validation loss: 2.5641695801829227

Epoch: 5| Step: 11
Training loss: 1.62130802071308
Validation loss: 2.5527895994665606

Epoch: 255| Step: 0
Training loss: 2.1132426655009255
Validation loss: 2.5775919700380765

Epoch: 5| Step: 1
Training loss: 2.221605424583002
Validation loss: 2.6101109728843874

Epoch: 5| Step: 2
Training loss: 2.6611045009961876
Validation loss: 2.6400718523432127

Epoch: 5| Step: 3
Training loss: 2.230816120950071
Validation loss: 2.6321845225417304

Epoch: 5| Step: 4
Training loss: 2.3851229113370778
Validation loss: 2.6043025680684986

Epoch: 5| Step: 5
Training loss: 2.2758212357428484
Validation loss: 2.5939293267025296

Epoch: 5| Step: 6
Training loss: 2.189171071052356
Validation loss: 2.5608035962030984

Epoch: 5| Step: 7
Training loss: 2.3325732446354936
Validation loss: 2.5439810195730623

Epoch: 5| Step: 8
Training loss: 2.1426265297275524
Validation loss: 2.516931814369193

Epoch: 5| Step: 9
Training loss: 2.491843459917848
Validation loss: 2.522959007350999

Epoch: 5| Step: 10
Training loss: 2.683800568586153
Validation loss: 2.5134655152183636

Epoch: 5| Step: 11
Training loss: 3.171901909474446
Validation loss: 2.520008808781603

Epoch: 256| Step: 0
Training loss: 2.816673065118087
Validation loss: 2.515066296077801

Epoch: 5| Step: 1
Training loss: 2.6810116179519365
Validation loss: 2.509838913615612

Epoch: 5| Step: 2
Training loss: 2.535325337136146
Validation loss: 2.5083498552376016

Epoch: 5| Step: 3
Training loss: 1.84304518078271
Validation loss: 2.5025118487608253

Epoch: 5| Step: 4
Training loss: 2.279068099359862
Validation loss: 2.504925675549041

Epoch: 5| Step: 5
Training loss: 2.116275830367524
Validation loss: 2.5049055012945094

Epoch: 5| Step: 6
Training loss: 2.22923616199962
Validation loss: 2.5045097445060227

Epoch: 5| Step: 7
Training loss: 2.276891228290519
Validation loss: 2.4939402651884484

Epoch: 5| Step: 8
Training loss: 2.356703907278042
Validation loss: 2.50964844030569

Epoch: 5| Step: 9
Training loss: 2.5162916544059355
Validation loss: 2.5204408546332284

Epoch: 5| Step: 10
Training loss: 2.4298463628417704
Validation loss: 2.5556803649219124

Epoch: 5| Step: 11
Training loss: 1.8205511239617789
Validation loss: 2.5420038802114546

Epoch: 257| Step: 0
Training loss: 2.483092258793445
Validation loss: 2.5497459853880926

Epoch: 5| Step: 1
Training loss: 2.795443632100323
Validation loss: 2.5762381845172757

Epoch: 5| Step: 2
Training loss: 2.576282929751866
Validation loss: 2.57719282772395

Epoch: 5| Step: 3
Training loss: 1.8123654940452099
Validation loss: 2.586631289990687

Epoch: 5| Step: 4
Training loss: 2.9659519863448116
Validation loss: 2.5784790566593516

Epoch: 5| Step: 5
Training loss: 2.3753383796967333
Validation loss: 2.5667553204133617

Epoch: 5| Step: 6
Training loss: 1.8061634980182404
Validation loss: 2.5706036720655567

Epoch: 5| Step: 7
Training loss: 2.1914268125497514
Validation loss: 2.5653014376669736

Epoch: 5| Step: 8
Training loss: 1.9914934333043655
Validation loss: 2.566233307359417

Epoch: 5| Step: 9
Training loss: 1.8607046037635961
Validation loss: 2.5483380778347313

Epoch: 5| Step: 10
Training loss: 2.5100258065223073
Validation loss: 2.5412731348045754

Epoch: 5| Step: 11
Training loss: 2.4238790772620993
Validation loss: 2.546879388068228

Epoch: 258| Step: 0
Training loss: 3.062802202534167
Validation loss: 2.5301688715083754

Epoch: 5| Step: 1
Training loss: 2.3241557649685243
Validation loss: 2.56849806185112

Epoch: 5| Step: 2
Training loss: 1.5479599201770333
Validation loss: 2.5506621075428004

Epoch: 5| Step: 3
Training loss: 2.8202245809530346
Validation loss: 2.542151558592074

Epoch: 5| Step: 4
Training loss: 2.2032096251339124
Validation loss: 2.550604747450959

Epoch: 5| Step: 5
Training loss: 2.270273320384413
Validation loss: 2.560479829338662

Epoch: 5| Step: 6
Training loss: 2.042119799821977
Validation loss: 2.525856118744973

Epoch: 5| Step: 7
Training loss: 1.886879481701679
Validation loss: 2.5472524203374682

Epoch: 5| Step: 8
Training loss: 2.5185118986283777
Validation loss: 2.5549931902275236

Epoch: 5| Step: 9
Training loss: 2.480711533086462
Validation loss: 2.5343762036754605

Epoch: 5| Step: 10
Training loss: 2.3900533753184967
Validation loss: 2.561006824299117

Epoch: 5| Step: 11
Training loss: 1.3337275200534038
Validation loss: 2.5654854789585126

Epoch: 259| Step: 0
Training loss: 1.842102219643624
Validation loss: 2.5841697074722987

Epoch: 5| Step: 1
Training loss: 2.9124913620718376
Validation loss: 2.592575623173532

Epoch: 5| Step: 2
Training loss: 2.426994376673901
Validation loss: 2.598234275812134

Epoch: 5| Step: 3
Training loss: 2.367602824925811
Validation loss: 2.5909340329404493

Epoch: 5| Step: 4
Training loss: 1.956548086739937
Validation loss: 2.602033658364126

Epoch: 5| Step: 5
Training loss: 2.677316400696047
Validation loss: 2.5885754102711673

Epoch: 5| Step: 6
Training loss: 2.209293252816592
Validation loss: 2.586538800019644

Epoch: 5| Step: 7
Training loss: 2.0333651753835076
Validation loss: 2.591325484650194

Epoch: 5| Step: 8
Training loss: 2.1133217516841483
Validation loss: 2.6070744619959827

Epoch: 5| Step: 9
Training loss: 2.0286802028605977
Validation loss: 2.6078020940153612

Epoch: 5| Step: 10
Training loss: 2.6557827706895667
Validation loss: 2.583659450778778

Epoch: 5| Step: 11
Training loss: 2.4639922060038173
Validation loss: 2.5616480643946096

Epoch: 260| Step: 0
Training loss: 1.6503884580699533
Validation loss: 2.5555258239667094

Epoch: 5| Step: 1
Training loss: 2.9621650345472874
Validation loss: 2.531582119820988

Epoch: 5| Step: 2
Training loss: 1.927726830619419
Validation loss: 2.5288121921385787

Epoch: 5| Step: 3
Training loss: 2.6254491875838073
Validation loss: 2.5201822745854425

Epoch: 5| Step: 4
Training loss: 2.7130430108727017
Validation loss: 2.5427802192270748

Epoch: 5| Step: 5
Training loss: 2.2056639630537145
Validation loss: 2.5309671785569434

Epoch: 5| Step: 6
Training loss: 2.2796873201157077
Validation loss: 2.5356916970123784

Epoch: 5| Step: 7
Training loss: 1.8831846257242568
Validation loss: 2.5583550300568625

Epoch: 5| Step: 8
Training loss: 1.9896200952245966
Validation loss: 2.564686458806361

Epoch: 5| Step: 9
Training loss: 2.730128975221499
Validation loss: 2.578117563256221

Epoch: 5| Step: 10
Training loss: 2.3536945195884122
Validation loss: 2.57142600740262

Epoch: 5| Step: 11
Training loss: 2.1321312791081413
Validation loss: 2.57124603463428

Epoch: 261| Step: 0
Training loss: 1.9614437103401687
Validation loss: 2.575951652378454

Epoch: 5| Step: 1
Training loss: 2.201806397529294
Validation loss: 2.577581186449694

Epoch: 5| Step: 2
Training loss: 2.306265494441885
Validation loss: 2.590990183898164

Epoch: 5| Step: 3
Training loss: 2.8031918248745407
Validation loss: 2.592539566134176

Epoch: 5| Step: 4
Training loss: 2.372211927927131
Validation loss: 2.587940166646964

Epoch: 5| Step: 5
Training loss: 2.5556223614110687
Validation loss: 2.5710531325229242

Epoch: 5| Step: 6
Training loss: 2.5210970485820536
Validation loss: 2.5974591287953266

Epoch: 5| Step: 7
Training loss: 1.9987847689335518
Validation loss: 2.590344782829957

Epoch: 5| Step: 8
Training loss: 2.093906225952121
Validation loss: 2.593873220220831

Epoch: 5| Step: 9
Training loss: 2.080458972433781
Validation loss: 2.57669064858747

Epoch: 5| Step: 10
Training loss: 2.599901190127289
Validation loss: 2.5763446247677466

Epoch: 5| Step: 11
Training loss: 2.2428171157736267
Validation loss: 2.5579031830133125

Epoch: 262| Step: 0
Training loss: 2.3466019635419793
Validation loss: 2.5443810693188533

Epoch: 5| Step: 1
Training loss: 2.402484672568945
Validation loss: 2.524338367539833

Epoch: 5| Step: 2
Training loss: 1.91456753043155
Validation loss: 2.5229170531239253

Epoch: 5| Step: 3
Training loss: 2.6402927167044967
Validation loss: 2.537339190068237

Epoch: 5| Step: 4
Training loss: 2.193485572289242
Validation loss: 2.5166796335513646

Epoch: 5| Step: 5
Training loss: 2.378497108892352
Validation loss: 2.5191600240223795

Epoch: 5| Step: 6
Training loss: 2.498406283700683
Validation loss: 2.5169530289298248

Epoch: 5| Step: 7
Training loss: 2.557608238457998
Validation loss: 2.5274198285797405

Epoch: 5| Step: 8
Training loss: 2.0200121544953835
Validation loss: 2.5453126128719483

Epoch: 5| Step: 9
Training loss: 2.5831452475547323
Validation loss: 2.519619749422276

Epoch: 5| Step: 10
Training loss: 2.0087445541146596
Validation loss: 2.56096804966994

Epoch: 5| Step: 11
Training loss: 1.2587673283040537
Validation loss: 2.5707130313302358

Epoch: 263| Step: 0
Training loss: 2.0085716148412036
Validation loss: 2.5794880856742064

Epoch: 5| Step: 1
Training loss: 2.163044163147691
Validation loss: 2.6134818303746665

Epoch: 5| Step: 2
Training loss: 2.223717300491977
Validation loss: 2.6220935216689885

Epoch: 5| Step: 3
Training loss: 2.082767091729734
Validation loss: 2.5752587424528794

Epoch: 5| Step: 4
Training loss: 2.4761538002857733
Validation loss: 2.582455914192784

Epoch: 5| Step: 5
Training loss: 2.0561980869963694
Validation loss: 2.5801689715277707

Epoch: 5| Step: 6
Training loss: 2.19998941418962
Validation loss: 2.563988679624811

Epoch: 5| Step: 7
Training loss: 2.978370898123185
Validation loss: 2.539127740266355

Epoch: 5| Step: 8
Training loss: 2.4015075717022754
Validation loss: 2.521127614007731

Epoch: 5| Step: 9
Training loss: 2.1320229211115485
Validation loss: 2.51223263543677

Epoch: 5| Step: 10
Training loss: 2.3136890550497555
Validation loss: 2.5107149379601212

Epoch: 5| Step: 11
Training loss: 3.725215900488054
Validation loss: 2.514553438139044

Epoch: 264| Step: 0
Training loss: 2.091714809314563
Validation loss: 2.503766175476682

Epoch: 5| Step: 1
Training loss: 2.9965915390741498
Validation loss: 2.5090421036983117

Epoch: 5| Step: 2
Training loss: 1.9031382943927717
Validation loss: 2.5155972504911674

Epoch: 5| Step: 3
Training loss: 2.4356978185358327
Validation loss: 2.5290129434687505

Epoch: 5| Step: 4
Training loss: 2.3946369888332915
Validation loss: 2.517379496423224

Epoch: 5| Step: 5
Training loss: 1.9235298041624467
Validation loss: 2.552342947905381

Epoch: 5| Step: 6
Training loss: 2.4280924084217737
Validation loss: 2.5493207667353115

Epoch: 5| Step: 7
Training loss: 2.2169935769352422
Validation loss: 2.5829510149513135

Epoch: 5| Step: 8
Training loss: 2.4488140544526673
Validation loss: 2.5670201125303787

Epoch: 5| Step: 9
Training loss: 2.0656299539065146
Validation loss: 2.580023307516354

Epoch: 5| Step: 10
Training loss: 2.625002906434403
Validation loss: 2.556486703597493

Epoch: 5| Step: 11
Training loss: 2.279560874680049
Validation loss: 2.546244841707573

Epoch: 265| Step: 0
Training loss: 1.9083878458002632
Validation loss: 2.58646495391658

Epoch: 5| Step: 1
Training loss: 2.2538598120283817
Validation loss: 2.5904177896899

Epoch: 5| Step: 2
Training loss: 2.726110557547631
Validation loss: 2.5879300557137555

Epoch: 5| Step: 3
Training loss: 2.3149760625273132
Validation loss: 2.5975020130995343

Epoch: 5| Step: 4
Training loss: 1.6297785118196617
Validation loss: 2.58222495163795

Epoch: 5| Step: 5
Training loss: 2.4283843148700304
Validation loss: 2.580158591429456

Epoch: 5| Step: 6
Training loss: 2.182447210942855
Validation loss: 2.5540557103432606

Epoch: 5| Step: 7
Training loss: 2.501491101953852
Validation loss: 2.554202135741082

Epoch: 5| Step: 8
Training loss: 2.326949879079069
Validation loss: 2.553539535381727

Epoch: 5| Step: 9
Training loss: 2.917402301842497
Validation loss: 2.54360556258801

Epoch: 5| Step: 10
Training loss: 2.124203701043144
Validation loss: 2.5592598201000247

Epoch: 5| Step: 11
Training loss: 1.5563803805845804
Validation loss: 2.5522890254578847

Epoch: 266| Step: 0
Training loss: 2.1949629861756557
Validation loss: 2.562698465120566

Epoch: 5| Step: 1
Training loss: 2.219279910999119
Validation loss: 2.577863383264773

Epoch: 5| Step: 2
Training loss: 2.975936703716389
Validation loss: 2.591866471928362

Epoch: 5| Step: 3
Training loss: 2.2805841597718435
Validation loss: 2.5792814647247524

Epoch: 5| Step: 4
Training loss: 2.047301619238235
Validation loss: 2.5874136699950054

Epoch: 5| Step: 5
Training loss: 2.0465714324183075
Validation loss: 2.5760348700281903

Epoch: 5| Step: 6
Training loss: 2.4181180300874647
Validation loss: 2.58964792530609

Epoch: 5| Step: 7
Training loss: 2.2696609853934007
Validation loss: 2.553834636699808

Epoch: 5| Step: 8
Training loss: 2.361941728782396
Validation loss: 2.56020262707916

Epoch: 5| Step: 9
Training loss: 2.1190455542830384
Validation loss: 2.569735163632007

Epoch: 5| Step: 10
Training loss: 2.653769917280838
Validation loss: 2.557502548835506

Epoch: 5| Step: 11
Training loss: 0.9653612980436382
Validation loss: 2.563591023145279

Epoch: 267| Step: 0
Training loss: 2.8830819352938404
Validation loss: 2.561471162670554

Epoch: 5| Step: 1
Training loss: 2.014150390601326
Validation loss: 2.559430284100991

Epoch: 5| Step: 2
Training loss: 2.1846590394992913
Validation loss: 2.5712137661601484

Epoch: 5| Step: 3
Training loss: 2.0668063434448114
Validation loss: 2.563981279368801

Epoch: 5| Step: 4
Training loss: 1.7721431226560467
Validation loss: 2.571134310270764

Epoch: 5| Step: 5
Training loss: 2.198095437925691
Validation loss: 2.565960857542271

Epoch: 5| Step: 6
Training loss: 2.831161975965924
Validation loss: 2.563374715083686

Epoch: 5| Step: 7
Training loss: 2.3654043198003953
Validation loss: 2.572504641223177

Epoch: 5| Step: 8
Training loss: 1.6719370322439833
Validation loss: 2.580265047058134

Epoch: 5| Step: 9
Training loss: 2.345743882510451
Validation loss: 2.565614586924006

Epoch: 5| Step: 10
Training loss: 2.7591735247871734
Validation loss: 2.5820577969246825

Epoch: 5| Step: 11
Training loss: 1.1881796247275391
Validation loss: 2.598912043085971

Epoch: 268| Step: 0
Training loss: 2.3573278172904564
Validation loss: 2.5753203308519663

Epoch: 5| Step: 1
Training loss: 1.748425524741336
Validation loss: 2.60071250081355

Epoch: 5| Step: 2
Training loss: 2.1781648082187663
Validation loss: 2.604463542546612

Epoch: 5| Step: 3
Training loss: 2.669210254012777
Validation loss: 2.617509000398986

Epoch: 5| Step: 4
Training loss: 2.4225414712700366
Validation loss: 2.6342444256648765

Epoch: 5| Step: 5
Training loss: 2.611628307587469
Validation loss: 2.634327943803205

Epoch: 5| Step: 6
Training loss: 2.324674468682757
Validation loss: 2.617225931369389

Epoch: 5| Step: 7
Training loss: 2.4282546157313902
Validation loss: 2.6004297197850983

Epoch: 5| Step: 8
Training loss: 1.9122819364805608
Validation loss: 2.6056692073942695

Epoch: 5| Step: 9
Training loss: 2.531621740853761
Validation loss: 2.5793598570031384

Epoch: 5| Step: 10
Training loss: 1.9925397972813492
Validation loss: 2.5650696702112437

Epoch: 5| Step: 11
Training loss: 2.115797649421688
Validation loss: 2.552513262807356

Epoch: 269| Step: 0
Training loss: 2.103295841618431
Validation loss: 2.5406784549358914

Epoch: 5| Step: 1
Training loss: 2.1221817626336312
Validation loss: 2.5351626607209408

Epoch: 5| Step: 2
Training loss: 2.1433277748633053
Validation loss: 2.5245176273157917

Epoch: 5| Step: 3
Training loss: 2.0160836577693177
Validation loss: 2.5326367649280637

Epoch: 5| Step: 4
Training loss: 2.940344062706316
Validation loss: 2.5284886898997025

Epoch: 5| Step: 5
Training loss: 3.1228980052170723
Validation loss: 2.5227659333737473

Epoch: 5| Step: 6
Training loss: 2.1752769118550197
Validation loss: 2.5359976459139006

Epoch: 5| Step: 7
Training loss: 2.076620604288437
Validation loss: 2.543613432202649

Epoch: 5| Step: 8
Training loss: 2.0762415790789004
Validation loss: 2.547759750776523

Epoch: 5| Step: 9
Training loss: 2.6222677089047006
Validation loss: 2.5313728954167103

Epoch: 5| Step: 10
Training loss: 2.1195963426684035
Validation loss: 2.563228240080714

Epoch: 5| Step: 11
Training loss: 1.1929209101889375
Validation loss: 2.5775075616241545

Epoch: 270| Step: 0
Training loss: 2.3776978679353022
Validation loss: 2.5824754403107586

Epoch: 5| Step: 1
Training loss: 1.9175451863720354
Validation loss: 2.5497419801771617

Epoch: 5| Step: 2
Training loss: 1.99454535282467
Validation loss: 2.566214397039137

Epoch: 5| Step: 3
Training loss: 2.7869956000669394
Validation loss: 2.576962923882573

Epoch: 5| Step: 4
Training loss: 2.026858233048133
Validation loss: 2.5694001229790926

Epoch: 5| Step: 5
Training loss: 2.044921875
Validation loss: 2.57882677795738

Epoch: 5| Step: 6
Training loss: 2.68179514218207
Validation loss: 2.586967078904467

Epoch: 5| Step: 7
Training loss: 2.4898102043771932
Validation loss: 2.559909540465023

Epoch: 5| Step: 8
Training loss: 2.3412715777672175
Validation loss: 2.567721165024663

Epoch: 5| Step: 9
Training loss: 2.0956472654266243
Validation loss: 2.5647752825324432

Epoch: 5| Step: 10
Training loss: 2.4936944596838755
Validation loss: 2.547552763579977

Epoch: 5| Step: 11
Training loss: 1.9244517598418132
Validation loss: 2.546157747619077

Epoch: 271| Step: 0
Training loss: 2.5492085257023263
Validation loss: 2.546665393652606

Epoch: 5| Step: 1
Training loss: 2.393958167842768
Validation loss: 2.530444087549894

Epoch: 5| Step: 2
Training loss: 2.484683707388717
Validation loss: 2.515715228214001

Epoch: 5| Step: 3
Training loss: 2.5312362482144772
Validation loss: 2.5280367585552344

Epoch: 5| Step: 4
Training loss: 2.190285788923035
Validation loss: 2.517861077364521

Epoch: 5| Step: 5
Training loss: 2.6928567064580533
Validation loss: 2.520266651793683

Epoch: 5| Step: 6
Training loss: 1.9958804738869236
Validation loss: 2.536385632412377

Epoch: 5| Step: 7
Training loss: 2.5742516291230593
Validation loss: 2.548088572502728

Epoch: 5| Step: 8
Training loss: 2.2283946212561214
Validation loss: 2.555004881762714

Epoch: 5| Step: 9
Training loss: 2.154700786945187
Validation loss: 2.5640377183732084

Epoch: 5| Step: 10
Training loss: 1.792286928140981
Validation loss: 2.572497591775052

Epoch: 5| Step: 11
Training loss: 1.3649463267830255
Validation loss: 2.5856589083699224

Epoch: 272| Step: 0
Training loss: 2.355961939356934
Validation loss: 2.5753897635830065

Epoch: 5| Step: 1
Training loss: 2.272505106904489
Validation loss: 2.582571372338094

Epoch: 5| Step: 2
Training loss: 2.5255210943071784
Validation loss: 2.5824213180576012

Epoch: 5| Step: 3
Training loss: 2.0962135283562175
Validation loss: 2.5746154093643923

Epoch: 5| Step: 4
Training loss: 2.427652469643606
Validation loss: 2.5757226983788533

Epoch: 5| Step: 5
Training loss: 2.4767483903212173
Validation loss: 2.564419667010444

Epoch: 5| Step: 6
Training loss: 2.6762761681607863
Validation loss: 2.5466629361288433

Epoch: 5| Step: 7
Training loss: 2.0510376978794316
Validation loss: 2.529017170054749

Epoch: 5| Step: 8
Training loss: 1.8465017700021558
Validation loss: 2.529277450899338

Epoch: 5| Step: 9
Training loss: 2.1006591443615488
Validation loss: 2.52791332762333

Epoch: 5| Step: 10
Training loss: 2.236722979606549
Validation loss: 2.524649912419048

Epoch: 5| Step: 11
Training loss: 2.428822844979123
Validation loss: 2.5348075936512764

Epoch: 273| Step: 0
Training loss: 2.4169532233286075
Validation loss: 2.5390547962560914

Epoch: 5| Step: 1
Training loss: 2.1852132561359956
Validation loss: 2.5716887695943247

Epoch: 5| Step: 2
Training loss: 1.9328418232968516
Validation loss: 2.549521321515452

Epoch: 5| Step: 3
Training loss: 2.446717464983358
Validation loss: 2.562563294505149

Epoch: 5| Step: 4
Training loss: 2.51307160057745
Validation loss: 2.578001612783608

Epoch: 5| Step: 5
Training loss: 2.1881032929246764
Validation loss: 2.596506469504004

Epoch: 5| Step: 6
Training loss: 2.176818381314406
Validation loss: 2.629056105326884

Epoch: 5| Step: 7
Training loss: 2.214210379325405
Validation loss: 2.6214717245670647

Epoch: 5| Step: 8
Training loss: 2.1640595253603765
Validation loss: 2.6177840051264796

Epoch: 5| Step: 9
Training loss: 2.2971996674768738
Validation loss: 2.5828783816508203

Epoch: 5| Step: 10
Training loss: 2.3810782703542577
Validation loss: 2.5899659171617353

Epoch: 5| Step: 11
Training loss: 3.2088873413794894
Validation loss: 2.552596341686531

Epoch: 274| Step: 0
Training loss: 3.256688644532848
Validation loss: 2.5961899330795517

Epoch: 5| Step: 1
Training loss: 2.6678389019177478
Validation loss: 2.5930349942432884

Epoch: 5| Step: 2
Training loss: 2.188465995031102
Validation loss: 2.6264252445441034

Epoch: 5| Step: 3
Training loss: 2.4494019459621774
Validation loss: 2.611208361112142

Epoch: 5| Step: 4
Training loss: 1.9232635444175092
Validation loss: 2.6326695147739065

Epoch: 5| Step: 5
Training loss: 2.122541351634449
Validation loss: 2.650554174981972

Epoch: 5| Step: 6
Training loss: 2.2643590086652097
Validation loss: 2.659542780423605

Epoch: 5| Step: 7
Training loss: 1.624430263117896
Validation loss: 2.6443568800928485

Epoch: 5| Step: 8
Training loss: 1.7755206137094075
Validation loss: 2.6259401091190746

Epoch: 5| Step: 9
Training loss: 2.75461953307034
Validation loss: 2.6102290059918034

Epoch: 5| Step: 10
Training loss: 1.8604536373940364
Validation loss: 2.5711576739957374

Epoch: 5| Step: 11
Training loss: 1.6502054144412066
Validation loss: 2.548350033797867

Epoch: 275| Step: 0
Training loss: 1.8837828608876015
Validation loss: 2.530271423409712

Epoch: 5| Step: 1
Training loss: 2.0871334005290616
Validation loss: 2.526220761009911

Epoch: 5| Step: 2
Training loss: 1.7778495320435996
Validation loss: 2.535878792155869

Epoch: 5| Step: 3
Training loss: 2.448599072294115
Validation loss: 2.53247289983265

Epoch: 5| Step: 4
Training loss: 2.6984625500972483
Validation loss: 2.539449339521867

Epoch: 5| Step: 5
Training loss: 1.8109111398879942
Validation loss: 2.535876249747693

Epoch: 5| Step: 6
Training loss: 2.6996329799851564
Validation loss: 2.5649447022005423

Epoch: 5| Step: 7
Training loss: 2.7455391683346315
Validation loss: 2.5715451014664885

Epoch: 5| Step: 8
Training loss: 2.1620885336266853
Validation loss: 2.586857319995929

Epoch: 5| Step: 9
Training loss: 2.2846762650288834
Validation loss: 2.5881844330993693

Epoch: 5| Step: 10
Training loss: 2.5271997897199667
Validation loss: 2.60615396711495

Epoch: 5| Step: 11
Training loss: 2.408981754257635
Validation loss: 2.5990915831283745

Epoch: 276| Step: 0
Training loss: 2.915120523359274
Validation loss: 2.5596310868968715

Epoch: 5| Step: 1
Training loss: 2.388928378564874
Validation loss: 2.554955346923533

Epoch: 5| Step: 2
Training loss: 2.7953308787202813
Validation loss: 2.5432399794576357

Epoch: 5| Step: 3
Training loss: 2.1017188258685446
Validation loss: 2.5174439293111064

Epoch: 5| Step: 4
Training loss: 2.2348538399168336
Validation loss: 2.5128388011144036

Epoch: 5| Step: 5
Training loss: 2.2524407182316586
Validation loss: 2.511851697283554

Epoch: 5| Step: 6
Training loss: 2.155049307628609
Validation loss: 2.500511085402792

Epoch: 5| Step: 7
Training loss: 2.127191311308987
Validation loss: 2.5306701035145447

Epoch: 5| Step: 8
Training loss: 1.955972411719791
Validation loss: 2.5162445040063393

Epoch: 5| Step: 9
Training loss: 1.9182535181529072
Validation loss: 2.556665838596636

Epoch: 5| Step: 10
Training loss: 2.433114728732003
Validation loss: 2.56887001985465

Epoch: 5| Step: 11
Training loss: 1.926810092284428
Validation loss: 2.5701547746277043

Epoch: 277| Step: 0
Training loss: 1.7743275967212058
Validation loss: 2.593450230200514

Epoch: 5| Step: 1
Training loss: 1.7504299861719315
Validation loss: 2.6195773207013655

Epoch: 5| Step: 2
Training loss: 3.072571367594244
Validation loss: 2.620541297842901

Epoch: 5| Step: 3
Training loss: 2.530679049678985
Validation loss: 2.6112606331837176

Epoch: 5| Step: 4
Training loss: 2.0054907529699064
Validation loss: 2.6189487281724126

Epoch: 5| Step: 5
Training loss: 2.3183028126656318
Validation loss: 2.600563426439009

Epoch: 5| Step: 6
Training loss: 2.569306985655012
Validation loss: 2.591627171472041

Epoch: 5| Step: 7
Training loss: 2.3066256374870306
Validation loss: 2.55125326683786

Epoch: 5| Step: 8
Training loss: 2.6701597541707067
Validation loss: 2.5289395800446526

Epoch: 5| Step: 9
Training loss: 2.427535008218314
Validation loss: 2.5160474442265124

Epoch: 5| Step: 10
Training loss: 2.6471529295655216
Validation loss: 2.498037211479244

Epoch: 5| Step: 11
Training loss: 1.1099232138459647
Validation loss: 2.4929262559106875

Epoch: 278| Step: 0
Training loss: 2.549939424131864
Validation loss: 2.4892978477925083

Epoch: 5| Step: 1
Training loss: 2.2955698470197734
Validation loss: 2.4831117381258543

Epoch: 5| Step: 2
Training loss: 1.50668166057474
Validation loss: 2.5034464881680702

Epoch: 5| Step: 3
Training loss: 3.075495802443432
Validation loss: 2.49160253501786

Epoch: 5| Step: 4
Training loss: 2.7147615488904333
Validation loss: 2.493322630124485

Epoch: 5| Step: 5
Training loss: 1.5969500858100116
Validation loss: 2.5076778015215893

Epoch: 5| Step: 6
Training loss: 2.19126752934514
Validation loss: 2.493134098592626

Epoch: 5| Step: 7
Training loss: 2.6043416892682205
Validation loss: 2.5241761105886438

Epoch: 5| Step: 8
Training loss: 2.240519897038877
Validation loss: 2.5148885727081978

Epoch: 5| Step: 9
Training loss: 2.64051403286511
Validation loss: 2.5246127534316747

Epoch: 5| Step: 10
Training loss: 2.2725213685830337
Validation loss: 2.5053666409116073

Epoch: 5| Step: 11
Training loss: 2.1156837218571676
Validation loss: 2.493187041225944

Epoch: 279| Step: 0
Training loss: 2.958463173466062
Validation loss: 2.507219299874858

Epoch: 5| Step: 1
Training loss: 2.258107519179782
Validation loss: 2.506479449720775

Epoch: 5| Step: 2
Training loss: 2.27963408629166
Validation loss: 2.5195444151068656

Epoch: 5| Step: 3
Training loss: 1.7449729787270136
Validation loss: 2.5172594242093176

Epoch: 5| Step: 4
Training loss: 2.739901815451238
Validation loss: 2.5261666270281604

Epoch: 5| Step: 5
Training loss: 2.121470493418035
Validation loss: 2.5328097463251984

Epoch: 5| Step: 6
Training loss: 2.1849459315403856
Validation loss: 2.535598583063453

Epoch: 5| Step: 7
Training loss: 1.6988788834859283
Validation loss: 2.5317811801063064

Epoch: 5| Step: 8
Training loss: 2.4881437494203467
Validation loss: 2.5284542020293945

Epoch: 5| Step: 9
Training loss: 2.6396657792854317
Validation loss: 2.526320936882864

Epoch: 5| Step: 10
Training loss: 2.0341745304183307
Validation loss: 2.542081292264184

Epoch: 5| Step: 11
Training loss: 2.9874705293231294
Validation loss: 2.5384197967123616

Epoch: 280| Step: 0
Training loss: 3.0141488845493316
Validation loss: 2.5389746548055085

Epoch: 5| Step: 1
Training loss: 2.2073547666302717
Validation loss: 2.5531064117265467

Epoch: 5| Step: 2
Training loss: 2.5999728091358665
Validation loss: 2.5572790811129296

Epoch: 5| Step: 3
Training loss: 2.452090099739153
Validation loss: 2.537785002326907

Epoch: 5| Step: 4
Training loss: 2.5432354718333987
Validation loss: 2.5448800993794163

Epoch: 5| Step: 5
Training loss: 2.5036342907591824
Validation loss: 2.541536168880939

Epoch: 5| Step: 6
Training loss: 1.8475702439144555
Validation loss: 2.547329926377522

Epoch: 5| Step: 7
Training loss: 1.471688840719918
Validation loss: 2.531165007745955

Epoch: 5| Step: 8
Training loss: 2.5339240560795737
Validation loss: 2.5395833777181753

Epoch: 5| Step: 9
Training loss: 2.24312930646915
Validation loss: 2.5281523089668756

Epoch: 5| Step: 10
Training loss: 1.655733423826543
Validation loss: 2.5382219693740717

Epoch: 5| Step: 11
Training loss: 2.1565638880385944
Validation loss: 2.527671694421763

Epoch: 281| Step: 0
Training loss: 2.4469482021173263
Validation loss: 2.5322426313524735

Epoch: 5| Step: 1
Training loss: 2.1745951790994678
Validation loss: 2.5481439561336043

Epoch: 5| Step: 2
Training loss: 2.3079784625484803
Validation loss: 2.5573825153184653

Epoch: 5| Step: 3
Training loss: 2.5684078313513554
Validation loss: 2.5418487598248807

Epoch: 5| Step: 4
Training loss: 1.8924249325254994
Validation loss: 2.549671428212249

Epoch: 5| Step: 5
Training loss: 1.798422503636705
Validation loss: 2.550081991610337

Epoch: 5| Step: 6
Training loss: 1.8223254162300266
Validation loss: 2.5471146203650004

Epoch: 5| Step: 7
Training loss: 2.7208333419013107
Validation loss: 2.567136613183217

Epoch: 5| Step: 8
Training loss: 2.475521988202631
Validation loss: 2.565524096252935

Epoch: 5| Step: 9
Training loss: 2.9998367583048666
Validation loss: 2.5753150018125086

Epoch: 5| Step: 10
Training loss: 1.5568514385607437
Validation loss: 2.583112143204496

Epoch: 5| Step: 11
Training loss: 2.255891292726041
Validation loss: 2.5727103854639783

Epoch: 282| Step: 0
Training loss: 3.0470610732945946
Validation loss: 2.5924463021416893

Epoch: 5| Step: 1
Training loss: 1.96481499167417
Validation loss: 2.60173759214907

Epoch: 5| Step: 2
Training loss: 2.291047157012067
Validation loss: 2.577905190855751

Epoch: 5| Step: 3
Training loss: 2.032730032840951
Validation loss: 2.5875894584794166

Epoch: 5| Step: 4
Training loss: 2.2673600492009207
Validation loss: 2.5715180172072394

Epoch: 5| Step: 5
Training loss: 2.0928209435593237
Validation loss: 2.5734099418494045

Epoch: 5| Step: 6
Training loss: 2.4053318204000975
Validation loss: 2.561949659191697

Epoch: 5| Step: 7
Training loss: 2.4740090669482773
Validation loss: 2.5684139792242595

Epoch: 5| Step: 8
Training loss: 1.8941539900031488
Validation loss: 2.559059046400855

Epoch: 5| Step: 9
Training loss: 2.4275100616655134
Validation loss: 2.5583476678672414

Epoch: 5| Step: 10
Training loss: 2.1424187711364855
Validation loss: 2.548649296631852

Epoch: 5| Step: 11
Training loss: 2.1231263820496586
Validation loss: 2.542384086781079

Epoch: 283| Step: 0
Training loss: 2.5988096960421467
Validation loss: 2.560580542658517

Epoch: 5| Step: 1
Training loss: 2.6332177096547125
Validation loss: 2.5468487455422903

Epoch: 5| Step: 2
Training loss: 1.618116102964033
Validation loss: 2.5611965461938033

Epoch: 5| Step: 3
Training loss: 1.6553860696377691
Validation loss: 2.559350536137914

Epoch: 5| Step: 4
Training loss: 2.6260216859094943
Validation loss: 2.565467651225693

Epoch: 5| Step: 5
Training loss: 2.4478510638164734
Validation loss: 2.573874929618825

Epoch: 5| Step: 6
Training loss: 1.8486259770657436
Validation loss: 2.565047153413762

Epoch: 5| Step: 7
Training loss: 1.5335462052704316
Validation loss: 2.5669338858721567

Epoch: 5| Step: 8
Training loss: 1.8668812137445434
Validation loss: 2.5709603410154958

Epoch: 5| Step: 9
Training loss: 2.4598058611550533
Validation loss: 2.5677347098047463

Epoch: 5| Step: 10
Training loss: 3.1002035935519086
Validation loss: 2.5579291764300534

Epoch: 5| Step: 11
Training loss: 2.364075683234268
Validation loss: 2.5532019025783868

Epoch: 284| Step: 0
Training loss: 1.7888627919504287
Validation loss: 2.5680940053404298

Epoch: 5| Step: 1
Training loss: 2.566423343502816
Validation loss: 2.564491587396663

Epoch: 5| Step: 2
Training loss: 1.8167850878670861
Validation loss: 2.5809441382944813

Epoch: 5| Step: 3
Training loss: 2.0809524919182096
Validation loss: 2.5759590799492975

Epoch: 5| Step: 4
Training loss: 1.530801512765249
Validation loss: 2.58705348647989

Epoch: 5| Step: 5
Training loss: 2.8094138273244154
Validation loss: 2.5669178406835798

Epoch: 5| Step: 6
Training loss: 2.1850505739203383
Validation loss: 2.576769732671291

Epoch: 5| Step: 7
Training loss: 1.8256469624944027
Validation loss: 2.5864293878179794

Epoch: 5| Step: 8
Training loss: 2.4253658608591397
Validation loss: 2.5805835291433654

Epoch: 5| Step: 9
Training loss: 2.7042920895150764
Validation loss: 2.575313302612303

Epoch: 5| Step: 10
Training loss: 2.610790028907481
Validation loss: 2.588586228650384

Epoch: 5| Step: 11
Training loss: 2.851527718109792
Validation loss: 2.582477255970649

Epoch: 285| Step: 0
Training loss: 2.5489550562563275
Validation loss: 2.5892850139848735

Epoch: 5| Step: 1
Training loss: 1.9735323631700632
Validation loss: 2.5805800722374466

Epoch: 5| Step: 2
Training loss: 2.612180378175481
Validation loss: 2.6096344360089847

Epoch: 5| Step: 3
Training loss: 2.5135832847272543
Validation loss: 2.6017018835477024

Epoch: 5| Step: 4
Training loss: 2.3265527113996147
Validation loss: 2.577202653139953

Epoch: 5| Step: 5
Training loss: 1.8994512794594551
Validation loss: 2.5954244984118553

Epoch: 5| Step: 6
Training loss: 2.512819419787742
Validation loss: 2.5685692608340385

Epoch: 5| Step: 7
Training loss: 2.0238975679389095
Validation loss: 2.5758247054798966

Epoch: 5| Step: 8
Training loss: 2.2464820061851754
Validation loss: 2.5755877638793216

Epoch: 5| Step: 9
Training loss: 1.8246294821250135
Validation loss: 2.584933963063722

Epoch: 5| Step: 10
Training loss: 2.1016211519246375
Validation loss: 2.597661045614993

Epoch: 5| Step: 11
Training loss: 2.2497588134348825
Validation loss: 2.5986543922335867

Epoch: 286| Step: 0
Training loss: 2.936670226731093
Validation loss: 2.5656604854222156

Epoch: 5| Step: 1
Training loss: 2.1064820973912024
Validation loss: 2.5753284892949186

Epoch: 5| Step: 2
Training loss: 2.033570475377339
Validation loss: 2.5919070226418777

Epoch: 5| Step: 3
Training loss: 1.558631074310295
Validation loss: 2.594994640847064

Epoch: 5| Step: 4
Training loss: 2.3114671204720687
Validation loss: 2.577327778406253

Epoch: 5| Step: 5
Training loss: 2.434333015442222
Validation loss: 2.5941117314033186

Epoch: 5| Step: 6
Training loss: 2.884837692693229
Validation loss: 2.586739691308997

Epoch: 5| Step: 7
Training loss: 2.5140203250740147
Validation loss: 2.607858773154861

Epoch: 5| Step: 8
Training loss: 1.4925471965797077
Validation loss: 2.6171156232842345

Epoch: 5| Step: 9
Training loss: 2.0399983914686857
Validation loss: 2.614458933501358

Epoch: 5| Step: 10
Training loss: 2.123816328803513
Validation loss: 2.6253861453614027

Epoch: 5| Step: 11
Training loss: 2.043512975731356
Validation loss: 2.605946677629759

Epoch: 287| Step: 0
Training loss: 1.7049441639995009
Validation loss: 2.59690680532186

Epoch: 5| Step: 1
Training loss: 2.487880800323326
Validation loss: 2.6098706427608023

Epoch: 5| Step: 2
Training loss: 1.7286341739670126
Validation loss: 2.586867650173597

Epoch: 5| Step: 3
Training loss: 2.093270090245244
Validation loss: 2.583942590800002

Epoch: 5| Step: 4
Training loss: 2.8243333046712538
Validation loss: 2.5768478158471

Epoch: 5| Step: 5
Training loss: 2.431942007239216
Validation loss: 2.583627608417396

Epoch: 5| Step: 6
Training loss: 2.576572852637299
Validation loss: 2.5961253882611772

Epoch: 5| Step: 7
Training loss: 1.5342488409879924
Validation loss: 2.5937884990485305

Epoch: 5| Step: 8
Training loss: 2.406322131376257
Validation loss: 2.571920396350859

Epoch: 5| Step: 9
Training loss: 1.9587921930672834
Validation loss: 2.5781685912175036

Epoch: 5| Step: 10
Training loss: 2.7477246321259523
Validation loss: 2.580471654696499

Epoch: 5| Step: 11
Training loss: 1.8847906081367196
Validation loss: 2.5739132898193082

Epoch: 288| Step: 0
Training loss: 3.2355767565191003
Validation loss: 2.5937180383084146

Epoch: 5| Step: 1
Training loss: 2.5450390710435915
Validation loss: 2.591954674668608

Epoch: 5| Step: 2
Training loss: 1.9291094945204004
Validation loss: 2.575739020403582

Epoch: 5| Step: 3
Training loss: 1.951438725183174
Validation loss: 2.565201908837675

Epoch: 5| Step: 4
Training loss: 1.800649708476051
Validation loss: 2.592905845541863

Epoch: 5| Step: 5
Training loss: 2.223049350295417
Validation loss: 2.5880880757946443

Epoch: 5| Step: 6
Training loss: 2.170861645865978
Validation loss: 2.5673954033400808

Epoch: 5| Step: 7
Training loss: 1.7905986471051094
Validation loss: 2.5964728200437377

Epoch: 5| Step: 8
Training loss: 2.842297864452027
Validation loss: 2.596065016664139

Epoch: 5| Step: 9
Training loss: 1.7507099346461008
Validation loss: 2.570721069143468

Epoch: 5| Step: 10
Training loss: 1.914781334247699
Validation loss: 2.601239063063358

Epoch: 5| Step: 11
Training loss: 1.756997898814856
Validation loss: 2.5733206981285326

Epoch: 289| Step: 0
Training loss: 2.2128042152011576
Validation loss: 2.5910217402406297

Epoch: 5| Step: 1
Training loss: 1.7005731205595809
Validation loss: 2.5668724136023706

Epoch: 5| Step: 2
Training loss: 2.7832581203448115
Validation loss: 2.562891290609642

Epoch: 5| Step: 3
Training loss: 2.4540961220343593
Validation loss: 2.5614748625488946

Epoch: 5| Step: 4
Training loss: 1.643164785084123
Validation loss: 2.5379356094154026

Epoch: 5| Step: 5
Training loss: 2.411442887742168
Validation loss: 2.5289358580997625

Epoch: 5| Step: 6
Training loss: 1.528055322848911
Validation loss: 2.5352024883330677

Epoch: 5| Step: 7
Training loss: 2.2570571427858845
Validation loss: 2.518597140379037

Epoch: 5| Step: 8
Training loss: 2.627915897283587
Validation loss: 2.536691072714599

Epoch: 5| Step: 9
Training loss: 2.614202180312529
Validation loss: 2.5491704796131454

Epoch: 5| Step: 10
Training loss: 2.0545104207944123
Validation loss: 2.560263704635554

Epoch: 5| Step: 11
Training loss: 3.494062291691116
Validation loss: 2.610563384487217

Epoch: 290| Step: 0
Training loss: 3.070245873114157
Validation loss: 2.6416179588312

Epoch: 5| Step: 1
Training loss: 1.472883131121164
Validation loss: 2.6864128131616547

Epoch: 5| Step: 2
Training loss: 2.5280002407605022
Validation loss: 2.69779835567996

Epoch: 5| Step: 3
Training loss: 2.1092397010644928
Validation loss: 2.6660042004462747

Epoch: 5| Step: 4
Training loss: 2.3413270760643026
Validation loss: 2.700566803048305

Epoch: 5| Step: 5
Training loss: 2.705265939300173
Validation loss: 2.648645803536277

Epoch: 5| Step: 6
Training loss: 1.5029954406354409
Validation loss: 2.6185767894142264

Epoch: 5| Step: 7
Training loss: 2.6070222584103817
Validation loss: 2.581504113910428

Epoch: 5| Step: 8
Training loss: 2.3338509621258012
Validation loss: 2.5746395575613463

Epoch: 5| Step: 9
Training loss: 2.265623105804704
Validation loss: 2.5542674482437313

Epoch: 5| Step: 10
Training loss: 2.40966336791924
Validation loss: 2.574922178999838

Epoch: 5| Step: 11
Training loss: 1.3253483638214951
Validation loss: 2.5529381909736006

Epoch: 291| Step: 0
Training loss: 2.236181315971308
Validation loss: 2.5338410079525513

Epoch: 5| Step: 1
Training loss: 2.1943466940031757
Validation loss: 2.5424320418291297

Epoch: 5| Step: 2
Training loss: 1.9603889579584954
Validation loss: 2.5412373975011913

Epoch: 5| Step: 3
Training loss: 2.1201003191262386
Validation loss: 2.5400473851066714

Epoch: 5| Step: 4
Training loss: 2.0070816075298654
Validation loss: 2.542720616545513

Epoch: 5| Step: 5
Training loss: 2.701046447710444
Validation loss: 2.5465578845226444

Epoch: 5| Step: 6
Training loss: 2.2960491122864717
Validation loss: 2.5439970727537315

Epoch: 5| Step: 7
Training loss: 2.2573211029579134
Validation loss: 2.581093060307692

Epoch: 5| Step: 8
Training loss: 2.68590178762753
Validation loss: 2.565537288651772

Epoch: 5| Step: 9
Training loss: 1.9524823161361076
Validation loss: 2.582959495433858

Epoch: 5| Step: 10
Training loss: 2.7689306471471866
Validation loss: 2.6050923279065117

Epoch: 5| Step: 11
Training loss: 2.665560840760285
Validation loss: 2.592611239066003

Epoch: 292| Step: 0
Training loss: 2.7810567724419815
Validation loss: 2.598860929316403

Epoch: 5| Step: 1
Training loss: 2.409989460965614
Validation loss: 2.5902626960719872

Epoch: 5| Step: 2
Training loss: 1.7718274037798942
Validation loss: 2.60065094459144

Epoch: 5| Step: 3
Training loss: 2.042869784290327
Validation loss: 2.5929709877095686

Epoch: 5| Step: 4
Training loss: 2.6452218397887837
Validation loss: 2.602308447033497

Epoch: 5| Step: 5
Training loss: 2.421143944445547
Validation loss: 2.5866889898903427

Epoch: 5| Step: 6
Training loss: 2.5492085257023263
Validation loss: 2.6123263064051403

Epoch: 5| Step: 7
Training loss: 1.631628602038164
Validation loss: 2.608378850267553

Epoch: 5| Step: 8
Training loss: 1.6637120840565727
Validation loss: 2.599248118225583

Epoch: 5| Step: 9
Training loss: 2.521583844741152
Validation loss: 2.589538019161821

Epoch: 5| Step: 10
Training loss: 2.316228798667852
Validation loss: 2.57374373487859

Epoch: 5| Step: 11
Training loss: 1.6028278097669915
Validation loss: 2.575396548603377

Epoch: 293| Step: 0
Training loss: 2.0690693127696136
Validation loss: 2.545556001859047

Epoch: 5| Step: 1
Training loss: 2.0449056688484495
Validation loss: 2.5520958076224085

Epoch: 5| Step: 2
Training loss: 2.321236269185628
Validation loss: 2.5437380461603296

Epoch: 5| Step: 3
Training loss: 2.356028425488841
Validation loss: 2.5519579188353756

Epoch: 5| Step: 4
Training loss: 1.958050917153341
Validation loss: 2.5486084552292554

Epoch: 5| Step: 5
Training loss: 2.4846252699217226
Validation loss: 2.5666553370630307

Epoch: 5| Step: 6
Training loss: 2.257859595840452
Validation loss: 2.599554419085904

Epoch: 5| Step: 7
Training loss: 2.026923281188384
Validation loss: 2.5981783272931835

Epoch: 5| Step: 8
Training loss: 2.590946566844568
Validation loss: 2.6117296083806365

Epoch: 5| Step: 9
Training loss: 2.2871647281610255
Validation loss: 2.6378268515441197

Epoch: 5| Step: 10
Training loss: 2.5434121772207634
Validation loss: 2.604073638525968

Epoch: 5| Step: 11
Training loss: 1.6971396167893
Validation loss: 2.617779887706917

Epoch: 294| Step: 0
Training loss: 1.875534807863075
Validation loss: 2.6127043174171556

Epoch: 5| Step: 1
Training loss: 2.262385716370812
Validation loss: 2.5671779144040046

Epoch: 5| Step: 2
Training loss: 2.5185955823793083
Validation loss: 2.5410392304676956

Epoch: 5| Step: 3
Training loss: 2.6572926887042687
Validation loss: 2.5581078492636715

Epoch: 5| Step: 4
Training loss: 2.7396567640628797
Validation loss: 2.550091344936369

Epoch: 5| Step: 5
Training loss: 2.0364439070272735
Validation loss: 2.5515180169250034

Epoch: 5| Step: 6
Training loss: 1.4821073376836271
Validation loss: 2.5625741180307653

Epoch: 5| Step: 7
Training loss: 2.189043862633122
Validation loss: 2.573777457633156

Epoch: 5| Step: 8
Training loss: 1.8202401994091115
Validation loss: 2.5816679490699643

Epoch: 5| Step: 9
Training loss: 2.345748964444643
Validation loss: 2.5938923003905816

Epoch: 5| Step: 10
Training loss: 2.5579682262555967
Validation loss: 2.5859126697742676

Epoch: 5| Step: 11
Training loss: 2.436692813345102
Validation loss: 2.5741945843486076

Epoch: 295| Step: 0
Training loss: 2.2215856779560657
Validation loss: 2.560813837516137

Epoch: 5| Step: 1
Training loss: 1.935257937270301
Validation loss: 2.5477643634714546

Epoch: 5| Step: 2
Training loss: 2.2014125364085086
Validation loss: 2.5360137320025373

Epoch: 5| Step: 3
Training loss: 2.835827701849609
Validation loss: 2.532739534607643

Epoch: 5| Step: 4
Training loss: 1.9752120278419836
Validation loss: 2.5362028127711094

Epoch: 5| Step: 5
Training loss: 2.48099119436538
Validation loss: 2.5204513289261197

Epoch: 5| Step: 6
Training loss: 2.2312917710783333
Validation loss: 2.5309726539598003

Epoch: 5| Step: 7
Training loss: 2.136387550028322
Validation loss: 2.521816656279974

Epoch: 5| Step: 8
Training loss: 2.490420585102915
Validation loss: 2.5300631586052

Epoch: 5| Step: 9
Training loss: 2.0755746436392886
Validation loss: 2.5438552010673128

Epoch: 5| Step: 10
Training loss: 2.197885654706762
Validation loss: 2.5694679874910986

Epoch: 5| Step: 11
Training loss: 0.8815131288352426
Validation loss: 2.5932012689921864

Epoch: 296| Step: 0
Training loss: 2.4675150812648607
Validation loss: 2.6013179240233093

Epoch: 5| Step: 1
Training loss: 1.8832532438055045
Validation loss: 2.599627606762418

Epoch: 5| Step: 2
Training loss: 2.4119197879061933
Validation loss: 2.6199043709772294

Epoch: 5| Step: 3
Training loss: 2.7543122553663073
Validation loss: 2.6539818261208707

Epoch: 5| Step: 4
Training loss: 2.2892516386770474
Validation loss: 2.6166694507968775

Epoch: 5| Step: 5
Training loss: 2.2774603733672953
Validation loss: 2.6293088841753205

Epoch: 5| Step: 6
Training loss: 1.6192221258655206
Validation loss: 2.6009823989583065

Epoch: 5| Step: 7
Training loss: 2.086434980069091
Validation loss: 2.5722383397768946

Epoch: 5| Step: 8
Training loss: 1.7739261172541314
Validation loss: 2.5669203794369317

Epoch: 5| Step: 9
Training loss: 2.4366349861739995
Validation loss: 2.559719849310157

Epoch: 5| Step: 10
Training loss: 2.2318169949956945
Validation loss: 2.572284629865499

Epoch: 5| Step: 11
Training loss: 3.35695628543467
Validation loss: 2.569128434334654

Epoch: 297| Step: 0
Training loss: 2.6091335893075747
Validation loss: 2.573132360480431

Epoch: 5| Step: 1
Training loss: 1.388782566557403
Validation loss: 2.570951113844305

Epoch: 5| Step: 2
Training loss: 2.0812230930364675
Validation loss: 2.5779787966184498

Epoch: 5| Step: 3
Training loss: 2.3258592473983666
Validation loss: 2.597900868612271

Epoch: 5| Step: 4
Training loss: 2.499081633688828
Validation loss: 2.6083739486757787

Epoch: 5| Step: 5
Training loss: 1.8039529469733402
Validation loss: 2.627649071835539

Epoch: 5| Step: 6
Training loss: 3.063749408823032
Validation loss: 2.6146384356240855

Epoch: 5| Step: 7
Training loss: 2.394482461205144
Validation loss: 2.6208495638900207

Epoch: 5| Step: 8
Training loss: 2.2221247837109246
Validation loss: 2.6367834879145122

Epoch: 5| Step: 9
Training loss: 1.9633924459594383
Validation loss: 2.6033152879739982

Epoch: 5| Step: 10
Training loss: 1.8652311155280747
Validation loss: 2.613260083761442

Epoch: 5| Step: 11
Training loss: 1.890911490432177
Validation loss: 2.6335622246370907

Epoch: 298| Step: 0
Training loss: 2.5580706578533103
Validation loss: 2.5743815014127236

Epoch: 5| Step: 1
Training loss: 2.330939927330651
Validation loss: 2.616318337273541

Epoch: 5| Step: 2
Training loss: 1.8816854815672936
Validation loss: 2.598014325006973

Epoch: 5| Step: 3
Training loss: 1.7310738980074043
Validation loss: 2.575353431211288

Epoch: 5| Step: 4
Training loss: 2.314840215190412
Validation loss: 2.559122162045517

Epoch: 5| Step: 5
Training loss: 2.38635860541668
Validation loss: 2.549283112003666

Epoch: 5| Step: 6
Training loss: 1.8875470288209357
Validation loss: 2.561301848735556

Epoch: 5| Step: 7
Training loss: 2.895532514650111
Validation loss: 2.5646435370817375

Epoch: 5| Step: 8
Training loss: 2.4447232349918933
Validation loss: 2.5734724584790234

Epoch: 5| Step: 9
Training loss: 1.0588559885129754
Validation loss: 2.613806412810344

Epoch: 5| Step: 10
Training loss: 2.139730447566849
Validation loss: 2.6247785243956248

Epoch: 5| Step: 11
Training loss: 3.3517659443461607
Validation loss: 2.6386906086454096

Epoch: 299| Step: 0
Training loss: 2.5316339837334296
Validation loss: 2.6389220387624195

Epoch: 5| Step: 1
Training loss: 1.866195990054935
Validation loss: 2.6633899469966993

Epoch: 5| Step: 2
Training loss: 2.1064751931990533
Validation loss: 2.6500552327619986

Epoch: 5| Step: 3
Training loss: 2.0035347696461754
Validation loss: 2.654853244133113

Epoch: 5| Step: 4
Training loss: 2.7616931962661484
Validation loss: 2.62604852579914

Epoch: 5| Step: 5
Training loss: 1.7411549335058967
Validation loss: 2.5965982601066018

Epoch: 5| Step: 6
Training loss: 1.9244770949941452
Validation loss: 2.6006832603572887

Epoch: 5| Step: 7
Training loss: 2.6194665806970923
Validation loss: 2.6127098876808175

Epoch: 5| Step: 8
Training loss: 2.239622343448103
Validation loss: 2.5997371054666236

Epoch: 5| Step: 9
Training loss: 2.820941548452856
Validation loss: 2.5892414602873206

Epoch: 5| Step: 10
Training loss: 1.7259257251366162
Validation loss: 2.5897693958991703

Epoch: 5| Step: 11
Training loss: 2.37466920255511
Validation loss: 2.568446168774676

Epoch: 300| Step: 0
Training loss: 3.0650708054396394
Validation loss: 2.56828173385869

Epoch: 5| Step: 1
Training loss: 1.6566217832926255
Validation loss: 2.552398795787659

Epoch: 5| Step: 2
Training loss: 2.2240037637994328
Validation loss: 2.5434811178965937

Epoch: 5| Step: 3
Training loss: 2.098147769789652
Validation loss: 2.518431103462313

Epoch: 5| Step: 4
Training loss: 2.0162681322411733
Validation loss: 2.520983842554838

Epoch: 5| Step: 5
Training loss: 2.4112356479943413
Validation loss: 2.5242938979059106

Epoch: 5| Step: 6
Training loss: 2.7654569758005025
Validation loss: 2.546773050370115

Epoch: 5| Step: 7
Training loss: 2.370782420098324
Validation loss: 2.5319295332111436

Epoch: 5| Step: 8
Training loss: 2.1292963912870944
Validation loss: 2.548696837570031

Epoch: 5| Step: 9
Training loss: 2.699461113169381
Validation loss: 2.55738078866544

Epoch: 5| Step: 10
Training loss: 1.3473438730187832
Validation loss: 2.5584964840481947

Epoch: 5| Step: 11
Training loss: 2.5095695448696196
Validation loss: 2.5770178565792095

Epoch: 301| Step: 0
Training loss: 1.3010319648586595
Validation loss: 2.5796758322217954

Epoch: 5| Step: 1
Training loss: 2.9948778930634803
Validation loss: 2.5804104895332753

Epoch: 5| Step: 2
Training loss: 2.0290882051039074
Validation loss: 2.6054214747771054

Epoch: 5| Step: 3
Training loss: 2.2773653163510357
Validation loss: 2.641913737186108

Epoch: 5| Step: 4
Training loss: 2.5165341079192234
Validation loss: 2.6631543950718592

Epoch: 5| Step: 5
Training loss: 2.107219244378281
Validation loss: 2.6537540115503413

Epoch: 5| Step: 6
Training loss: 2.465440294046047
Validation loss: 2.598617211521649

Epoch: 5| Step: 7
Training loss: 2.5129575625873084
Validation loss: 2.5568839186428383

Epoch: 5| Step: 8
Training loss: 2.465094261920588
Validation loss: 2.5426546831629566

Epoch: 5| Step: 9
Training loss: 2.4666821475015746
Validation loss: 2.5259627234848856

Epoch: 5| Step: 10
Training loss: 2.0814276817013924
Validation loss: 2.525911954453027

Epoch: 5| Step: 11
Training loss: 2.8245583484394534
Validation loss: 2.518150761648402

Epoch: 302| Step: 0
Training loss: 2.5784210959821063
Validation loss: 2.5343125501433854

Epoch: 5| Step: 1
Training loss: 2.17856123070932
Validation loss: 2.538454716638255

Epoch: 5| Step: 2
Training loss: 2.3799443227201866
Validation loss: 2.5496336890447857

Epoch: 5| Step: 3
Training loss: 1.9367370949292209
Validation loss: 2.541111468560804

Epoch: 5| Step: 4
Training loss: 2.524500572743977
Validation loss: 2.544756813971351

Epoch: 5| Step: 5
Training loss: 1.772273013238471
Validation loss: 2.5498466006121108

Epoch: 5| Step: 6
Training loss: 2.7641903016953835
Validation loss: 2.5510292107955714

Epoch: 5| Step: 7
Training loss: 1.6159877288749032
Validation loss: 2.5584231254236256

Epoch: 5| Step: 8
Training loss: 2.805821861452859
Validation loss: 2.566603203526639

Epoch: 5| Step: 9
Training loss: 1.6764095524600622
Validation loss: 2.57868074149369

Epoch: 5| Step: 10
Training loss: 2.3712736309766296
Validation loss: 2.576448916832421

Epoch: 5| Step: 11
Training loss: 1.1927252800194235
Validation loss: 2.592536420219922

Epoch: 303| Step: 0
Training loss: 2.4221092849129504
Validation loss: 2.5913651046116244

Epoch: 5| Step: 1
Training loss: 2.3837928631293956
Validation loss: 2.551200723161283

Epoch: 5| Step: 2
Training loss: 2.1143083315269227
Validation loss: 2.5530877660419904

Epoch: 5| Step: 3
Training loss: 2.675450659607579
Validation loss: 2.531040642168997

Epoch: 5| Step: 4
Training loss: 1.806148977655521
Validation loss: 2.5305067352587685

Epoch: 5| Step: 5
Training loss: 2.2048744127835174
Validation loss: 2.524321221243691

Epoch: 5| Step: 6
Training loss: 2.510100274837639
Validation loss: 2.5281426387088235

Epoch: 5| Step: 7
Training loss: 2.4681169688175513
Validation loss: 2.519640247441719

Epoch: 5| Step: 8
Training loss: 1.7533452893467152
Validation loss: 2.5414635363428415

Epoch: 5| Step: 9
Training loss: 2.0491059935798352
Validation loss: 2.5719385115304676

Epoch: 5| Step: 10
Training loss: 2.0211986984885906
Validation loss: 2.5881512780549327

Epoch: 5| Step: 11
Training loss: 3.0852303382785498
Validation loss: 2.5746448339807175

Epoch: 304| Step: 0
Training loss: 2.0672192767894937
Validation loss: 2.608926768837087

Epoch: 5| Step: 1
Training loss: 2.2403256864155665
Validation loss: 2.6115902579153363

Epoch: 5| Step: 2
Training loss: 2.1067616415746704
Validation loss: 2.594950474754652

Epoch: 5| Step: 3
Training loss: 1.8376441328130713
Validation loss: 2.6150747815058732

Epoch: 5| Step: 4
Training loss: 2.2464703318820765
Validation loss: 2.616607077845397

Epoch: 5| Step: 5
Training loss: 2.1129066572464406
Validation loss: 2.5849169996538843

Epoch: 5| Step: 6
Training loss: 1.6956248896507737
Validation loss: 2.590049835183442

Epoch: 5| Step: 7
Training loss: 2.6126525761343666
Validation loss: 2.570469060147321

Epoch: 5| Step: 8
Training loss: 2.701711737248766
Validation loss: 2.57662142440816

Epoch: 5| Step: 9
Training loss: 2.475795687305057
Validation loss: 2.555746024458204

Epoch: 5| Step: 10
Training loss: 1.9835617922251476
Validation loss: 2.5362133296836764

Epoch: 5| Step: 11
Training loss: 3.214327245776997
Validation loss: 2.531595638208785

Epoch: 305| Step: 0
Training loss: 2.15035669783352
Validation loss: 2.5219981573538286

Epoch: 5| Step: 1
Training loss: 2.3314544628980296
Validation loss: 2.5299888420361527

Epoch: 5| Step: 2
Training loss: 2.078906607815992
Validation loss: 2.541240653830656

Epoch: 5| Step: 3
Training loss: 2.4463573819364637
Validation loss: 2.5308611967591785

Epoch: 5| Step: 4
Training loss: 2.2457511839648534
Validation loss: 2.547486442468073

Epoch: 5| Step: 5
Training loss: 2.1850545020038505
Validation loss: 2.56986762219209

Epoch: 5| Step: 6
Training loss: 2.2840974359923734
Validation loss: 2.593617010728718

Epoch: 5| Step: 7
Training loss: 2.0888928683335477
Validation loss: 2.6332255491297785

Epoch: 5| Step: 8
Training loss: 2.5487702227917857
Validation loss: 2.6360073269540587

Epoch: 5| Step: 9
Training loss: 2.4153381730081267
Validation loss: 2.617423791799183

Epoch: 5| Step: 10
Training loss: 2.446880678679404
Validation loss: 2.6194734184145534

Epoch: 5| Step: 11
Training loss: 2.515356677417763
Validation loss: 2.5818835825590076

Epoch: 306| Step: 0
Training loss: 2.0425098261135752
Validation loss: 2.5863848373247884

Epoch: 5| Step: 1
Training loss: 2.354572283704765
Validation loss: 2.5841405758365323

Epoch: 5| Step: 2
Training loss: 2.101257415522392
Validation loss: 2.583672375631819

Epoch: 5| Step: 3
Training loss: 2.2472553467113507
Validation loss: 2.6108357458187696

Epoch: 5| Step: 4
Training loss: 2.5061277630836543
Validation loss: 2.627908125134118

Epoch: 5| Step: 5
Training loss: 1.8202670505072474
Validation loss: 2.604437239260014

Epoch: 5| Step: 6
Training loss: 2.5096995066679857
Validation loss: 2.603425154338658

Epoch: 5| Step: 7
Training loss: 1.8208088996114937
Validation loss: 2.6166752252216043

Epoch: 5| Step: 8
Training loss: 2.60974438274242
Validation loss: 2.5781788984117013

Epoch: 5| Step: 9
Training loss: 1.676572670599102
Validation loss: 2.586629408116589

Epoch: 5| Step: 10
Training loss: 2.3786724207420775
Validation loss: 2.5822051889502395

Epoch: 5| Step: 11
Training loss: 1.998013284499688
Validation loss: 2.5742805639475725

Epoch: 307| Step: 0
Training loss: 2.133772302208204
Validation loss: 2.6273122019730653

Epoch: 5| Step: 1
Training loss: 2.134593401747436
Validation loss: 2.69355562604832

Epoch: 5| Step: 2
Training loss: 1.8725724718357957
Validation loss: 2.6921360187327754

Epoch: 5| Step: 3
Training loss: 1.6878122817831989
Validation loss: 2.6966955791977756

Epoch: 5| Step: 4
Training loss: 2.169457057059281
Validation loss: 2.6945907732194936

Epoch: 5| Step: 5
Training loss: 1.9213495544174177
Validation loss: 2.659751017248346

Epoch: 5| Step: 6
Training loss: 2.2977025623706195
Validation loss: 2.6249043886241137

Epoch: 5| Step: 7
Training loss: 2.7560208906591686
Validation loss: 2.5901085788656752

Epoch: 5| Step: 8
Training loss: 2.141136164091661
Validation loss: 2.5660077138318007

Epoch: 5| Step: 9
Training loss: 1.9848761939347812
Validation loss: 2.5252823124173944

Epoch: 5| Step: 10
Training loss: 3.1239358234431926
Validation loss: 2.495660719424431

Epoch: 5| Step: 11
Training loss: 3.310372010960724
Validation loss: 2.498949752184398

Epoch: 308| Step: 0
Training loss: 2.0175522454550885
Validation loss: 2.485686443878075

Epoch: 5| Step: 1
Training loss: 2.28941056140854
Validation loss: 2.48713921968945

Epoch: 5| Step: 2
Training loss: 2.2916834281539606
Validation loss: 2.493473307238546

Epoch: 5| Step: 3
Training loss: 2.4875676974952023
Validation loss: 2.506847199772719

Epoch: 5| Step: 4
Training loss: 2.471340510361099
Validation loss: 2.506508493133732

Epoch: 5| Step: 5
Training loss: 2.664251773856189
Validation loss: 2.5322435650375446

Epoch: 5| Step: 6
Training loss: 1.743068386839524
Validation loss: 2.55882763752125

Epoch: 5| Step: 7
Training loss: 2.3648966667069535
Validation loss: 2.5802983188351107

Epoch: 5| Step: 8
Training loss: 1.235327292946508
Validation loss: 2.587835216768769

Epoch: 5| Step: 9
Training loss: 2.3091278232963393
Validation loss: 2.6460667992762286

Epoch: 5| Step: 10
Training loss: 2.4068956375921267
Validation loss: 2.638926044141193

Epoch: 5| Step: 11
Training loss: 2.7632867443665337
Validation loss: 2.6569623926817982

Epoch: 309| Step: 0
Training loss: 2.829883681963339
Validation loss: 2.7127514357868443

Epoch: 5| Step: 1
Training loss: 2.170911177144356
Validation loss: 2.7742356562226873

Epoch: 5| Step: 2
Training loss: 1.8300748029127065
Validation loss: 2.8118117020047997

Epoch: 5| Step: 3
Training loss: 1.7793052497273067
Validation loss: 2.8289727017164434

Epoch: 5| Step: 4
Training loss: 2.0855802880222245
Validation loss: 2.7698539542293212

Epoch: 5| Step: 5
Training loss: 1.8997124052729146
Validation loss: 2.742111346282333

Epoch: 5| Step: 6
Training loss: 2.836089831588011
Validation loss: 2.6868970660385907

Epoch: 5| Step: 7
Training loss: 2.4567406123129367
Validation loss: 2.6189346137634217

Epoch: 5| Step: 8
Training loss: 1.7737124729824039
Validation loss: 2.566136350330948

Epoch: 5| Step: 9
Training loss: 2.3721133307132605
Validation loss: 2.5462393523280613

Epoch: 5| Step: 10
Training loss: 2.7058118575637726
Validation loss: 2.559751653378453

Epoch: 5| Step: 11
Training loss: 1.9584542162765988
Validation loss: 2.5660846224164175

Epoch: 310| Step: 0
Training loss: 2.3053153524423817
Validation loss: 2.5323648823225717

Epoch: 5| Step: 1
Training loss: 2.7360520805622155
Validation loss: 2.5243845403581813

Epoch: 5| Step: 2
Training loss: 2.161359400189406
Validation loss: 2.5364231457054807

Epoch: 5| Step: 3
Training loss: 1.882615138429836
Validation loss: 2.5451232760200453

Epoch: 5| Step: 4
Training loss: 2.203792497957545
Validation loss: 2.5343141376793277

Epoch: 5| Step: 5
Training loss: 1.651492212797464
Validation loss: 2.522343775477001

Epoch: 5| Step: 6
Training loss: 2.186546553863959
Validation loss: 2.5273800807505418

Epoch: 5| Step: 7
Training loss: 2.3649485861933943
Validation loss: 2.528380101414068

Epoch: 5| Step: 8
Training loss: 2.6780829338411096
Validation loss: 2.5446814040162105

Epoch: 5| Step: 9
Training loss: 2.786583576180441
Validation loss: 2.5426791134074396

Epoch: 5| Step: 10
Training loss: 2.2104659908830504
Validation loss: 2.5541618420761205

Epoch: 5| Step: 11
Training loss: 2.148930940316319
Validation loss: 2.5529677564803985

Epoch: 311| Step: 0
Training loss: 2.1539497822156024
Validation loss: 2.5757293822450578

Epoch: 5| Step: 1
Training loss: 2.2598370513574078
Validation loss: 2.6025225802836625

Epoch: 5| Step: 2
Training loss: 2.328827515160243
Validation loss: 2.6204069007970174

Epoch: 5| Step: 3
Training loss: 2.179989810884795
Validation loss: 2.6504061086338724

Epoch: 5| Step: 4
Training loss: 2.254500656158291
Validation loss: 2.65831949360951

Epoch: 5| Step: 5
Training loss: 1.813465058799169
Validation loss: 2.6586438107324355

Epoch: 5| Step: 6
Training loss: 1.9138331061718572
Validation loss: 2.676822435651322

Epoch: 5| Step: 7
Training loss: 2.6743523785266685
Validation loss: 2.6605813559209195

Epoch: 5| Step: 8
Training loss: 2.4136518110536245
Validation loss: 2.647490044047674

Epoch: 5| Step: 9
Training loss: 1.9745406111489057
Validation loss: 2.6300778888547613

Epoch: 5| Step: 10
Training loss: 2.331096417069931
Validation loss: 2.612992149521531

Epoch: 5| Step: 11
Training loss: 3.8129292230847804
Validation loss: 2.588992451203825

Epoch: 312| Step: 0
Training loss: 2.1903932239288335
Validation loss: 2.553991481525332

Epoch: 5| Step: 1
Training loss: 2.864015909118793
Validation loss: 2.565859205527067

Epoch: 5| Step: 2
Training loss: 1.7380676824123509
Validation loss: 2.543154067608294

Epoch: 5| Step: 3
Training loss: 2.2246065884941943
Validation loss: 2.506732078097846

Epoch: 5| Step: 4
Training loss: 1.8075280891441339
Validation loss: 2.497498325529355

Epoch: 5| Step: 5
Training loss: 2.104456160872026
Validation loss: 2.504257502841617

Epoch: 5| Step: 6
Training loss: 2.1607307649634806
Validation loss: 2.4989513105066123

Epoch: 5| Step: 7
Training loss: 2.340482850590337
Validation loss: 2.5215417061061536

Epoch: 5| Step: 8
Training loss: 2.6945372420211444
Validation loss: 2.516193617852159

Epoch: 5| Step: 9
Training loss: 2.8457413293163007
Validation loss: 2.5149907127939475

Epoch: 5| Step: 10
Training loss: 2.505711230732717
Validation loss: 2.499194078879154

Epoch: 5| Step: 11
Training loss: 1.9909854628426427
Validation loss: 2.4905497113203547

Epoch: 313| Step: 0
Training loss: 2.426919323096232
Validation loss: 2.492998846118077

Epoch: 5| Step: 1
Training loss: 1.9674131910860078
Validation loss: 2.510706027490292

Epoch: 5| Step: 2
Training loss: 1.856232752864359
Validation loss: 2.516211575582531

Epoch: 5| Step: 3
Training loss: 2.74667156972108
Validation loss: 2.5273771210107876

Epoch: 5| Step: 4
Training loss: 2.347251616023681
Validation loss: 2.546522435941891

Epoch: 5| Step: 5
Training loss: 2.7027592053177676
Validation loss: 2.5312925931698578

Epoch: 5| Step: 6
Training loss: 1.677684352426568
Validation loss: 2.535679062362661

Epoch: 5| Step: 7
Training loss: 2.3783205811609336
Validation loss: 2.5644769563364154

Epoch: 5| Step: 8
Training loss: 1.8074699189359353
Validation loss: 2.5832649165497217

Epoch: 5| Step: 9
Training loss: 2.7151315220963963
Validation loss: 2.56526493917696

Epoch: 5| Step: 10
Training loss: 1.746373233146885
Validation loss: 2.610544981749592

Epoch: 5| Step: 11
Training loss: 1.8309767561540857
Validation loss: 2.6032202921106764

Epoch: 314| Step: 0
Training loss: 2.3168463200496356
Validation loss: 2.6562813626102115

Epoch: 5| Step: 1
Training loss: 1.8633363343739555
Validation loss: 2.635971913002836

Epoch: 5| Step: 2
Training loss: 2.403555215688985
Validation loss: 2.647099110807354

Epoch: 5| Step: 3
Training loss: 1.964330526559118
Validation loss: 2.6187677537593967

Epoch: 5| Step: 4
Training loss: 1.9364634786875716
Validation loss: 2.5971276149302986

Epoch: 5| Step: 5
Training loss: 1.74870109037072
Validation loss: 2.5846992247782183

Epoch: 5| Step: 6
Training loss: 2.394354012481229
Validation loss: 2.5761656203156673

Epoch: 5| Step: 7
Training loss: 2.7667876994610845
Validation loss: 2.5793693352438267

Epoch: 5| Step: 8
Training loss: 2.036278472008179
Validation loss: 2.5463950245113125

Epoch: 5| Step: 9
Training loss: 1.935339553769573
Validation loss: 2.553720693770202

Epoch: 5| Step: 10
Training loss: 2.5676951894881537
Validation loss: 2.5405665202837664

Epoch: 5| Step: 11
Training loss: 4.3204105083254785
Validation loss: 2.5477761330191195

Epoch: 315| Step: 0
Training loss: 2.3685691502764095
Validation loss: 2.552791373976857

Epoch: 5| Step: 1
Training loss: 2.144038465126362
Validation loss: 2.5618032442479266

Epoch: 5| Step: 2
Training loss: 2.2538415116081794
Validation loss: 2.5852956753274037

Epoch: 5| Step: 3
Training loss: 2.115591876673632
Validation loss: 2.5988363391527183

Epoch: 5| Step: 4
Training loss: 2.356708560914749
Validation loss: 2.637680793730723

Epoch: 5| Step: 5
Training loss: 2.816925128010833
Validation loss: 2.628976746322931

Epoch: 5| Step: 6
Training loss: 1.8271338881744688
Validation loss: 2.619081485620155

Epoch: 5| Step: 7
Training loss: 1.7661557370441308
Validation loss: 2.614940551783506

Epoch: 5| Step: 8
Training loss: 2.2608929907181623
Validation loss: 2.615403215249049

Epoch: 5| Step: 9
Training loss: 2.054064289918088
Validation loss: 2.612646370761796

Epoch: 5| Step: 10
Training loss: 2.3241600734452588
Validation loss: 2.578688265218228

Epoch: 5| Step: 11
Training loss: 1.4720124069188572
Validation loss: 2.5669818195984155

Epoch: 316| Step: 0
Training loss: 2.6639841912805755
Validation loss: 2.5457549372359214

Epoch: 5| Step: 1
Training loss: 2.046499436263532
Validation loss: 2.5350170400963474

Epoch: 5| Step: 2
Training loss: 2.293204144380246
Validation loss: 2.5448389710755643

Epoch: 5| Step: 3
Training loss: 2.1647604357389354
Validation loss: 2.547484303551791

Epoch: 5| Step: 4
Training loss: 2.477058240690153
Validation loss: 2.5291189025556284

Epoch: 5| Step: 5
Training loss: 2.3286171207408324
Validation loss: 2.5486119126247306

Epoch: 5| Step: 6
Training loss: 2.176729334717262
Validation loss: 2.5401279972145647

Epoch: 5| Step: 7
Training loss: 1.7003103674139255
Validation loss: 2.5609841709256007

Epoch: 5| Step: 8
Training loss: 2.175250825998202
Validation loss: 2.585334895857076

Epoch: 5| Step: 9
Training loss: 2.02616339336655
Validation loss: 2.608460671593983

Epoch: 5| Step: 10
Training loss: 2.051531903168761
Validation loss: 2.665519957058463

Epoch: 5| Step: 11
Training loss: 2.7853392638524848
Validation loss: 2.6831644780083153

Epoch: 317| Step: 0
Training loss: 2.597814844782714
Validation loss: 2.7332961542713963

Epoch: 5| Step: 1
Training loss: 2.7631754398984
Validation loss: 2.735567617548821

Epoch: 5| Step: 2
Training loss: 2.2610685636103396
Validation loss: 2.729626588918804

Epoch: 5| Step: 3
Training loss: 2.6632818157702354
Validation loss: 2.6847429919592014

Epoch: 5| Step: 4
Training loss: 1.8765767143784742
Validation loss: 2.6365246190319658

Epoch: 5| Step: 5
Training loss: 1.6626566648164598
Validation loss: 2.5975348690422915

Epoch: 5| Step: 6
Training loss: 2.1397295561699763
Validation loss: 2.5732236220904334

Epoch: 5| Step: 7
Training loss: 2.4810704740442326
Validation loss: 2.5858378856945463

Epoch: 5| Step: 8
Training loss: 1.8101553385554865
Validation loss: 2.558715068086095

Epoch: 5| Step: 9
Training loss: 2.388499493121947
Validation loss: 2.5611165351653935

Epoch: 5| Step: 10
Training loss: 2.1870727121748477
Validation loss: 2.558361495253378

Epoch: 5| Step: 11
Training loss: 1.6077632054964188
Validation loss: 2.5556364678678873

Epoch: 318| Step: 0
Training loss: 2.8888947128171987
Validation loss: 2.5808595662256226

Epoch: 5| Step: 1
Training loss: 1.9818002412061924
Validation loss: 2.579448577904272

Epoch: 5| Step: 2
Training loss: 2.39200357817698
Validation loss: 2.6124282455933256

Epoch: 5| Step: 3
Training loss: 2.3164698574345475
Validation loss: 2.604972487070666

Epoch: 5| Step: 4
Training loss: 1.9580581011699763
Validation loss: 2.6314138967010576

Epoch: 5| Step: 5
Training loss: 2.278188035299573
Validation loss: 2.675732993180367

Epoch: 5| Step: 6
Training loss: 2.1958131049694476
Validation loss: 2.673289974682316

Epoch: 5| Step: 7
Training loss: 1.6571436216676763
Validation loss: 2.681170702771659

Epoch: 5| Step: 8
Training loss: 1.8408784649717185
Validation loss: 2.695997819987358

Epoch: 5| Step: 9
Training loss: 2.22272339838431
Validation loss: 2.657965581044857

Epoch: 5| Step: 10
Training loss: 2.2489329032879595
Validation loss: 2.6389704002931045

Epoch: 5| Step: 11
Training loss: 0.6332953694743956
Validation loss: 2.6357848936722057

Epoch: 319| Step: 0
Training loss: 2.1691012886776893
Validation loss: 2.6325567594811132

Epoch: 5| Step: 1
Training loss: 2.118080204332131
Validation loss: 2.6180503675396483

Epoch: 5| Step: 2
Training loss: 2.718426038360727
Validation loss: 2.622369500299175

Epoch: 5| Step: 3
Training loss: 2.384397786082811
Validation loss: 2.630181262692175

Epoch: 5| Step: 4
Training loss: 2.3722520289855122
Validation loss: 2.633530018096705

Epoch: 5| Step: 5
Training loss: 2.2712864088416436
Validation loss: 2.655359646294563

Epoch: 5| Step: 6
Training loss: 1.7591106453340182
Validation loss: 2.63624226727112

Epoch: 5| Step: 7
Training loss: 2.32772659886843
Validation loss: 2.650562667791385

Epoch: 5| Step: 8
Training loss: 1.872722832391665
Validation loss: 2.6627107474148977

Epoch: 5| Step: 9
Training loss: 1.6475594157038878
Validation loss: 2.638770473623067

Epoch: 5| Step: 10
Training loss: 2.116404483607144
Validation loss: 2.636466504499679

Epoch: 5| Step: 11
Training loss: 1.631903874679838
Validation loss: 2.6295760436529467

Epoch: 320| Step: 0
Training loss: 1.9670393035794105
Validation loss: 2.6347500042067002

Epoch: 5| Step: 1
Training loss: 2.0593912219507025
Validation loss: 2.607213975711817

Epoch: 5| Step: 2
Training loss: 3.0315642833006495
Validation loss: 2.59162303549499

Epoch: 5| Step: 3
Training loss: 2.3764988034833436
Validation loss: 2.5993237184426774

Epoch: 5| Step: 4
Training loss: 1.6655471697689446
Validation loss: 2.591927612042987

Epoch: 5| Step: 5
Training loss: 1.985397736124558
Validation loss: 2.6389734080370864

Epoch: 5| Step: 6
Training loss: 2.121586582543306
Validation loss: 2.6101698740246135

Epoch: 5| Step: 7
Training loss: 2.04362299346592
Validation loss: 2.6483789135539753

Epoch: 5| Step: 8
Training loss: 1.841695060626172
Validation loss: 2.6284801332418257

Epoch: 5| Step: 9
Training loss: 2.4492870850589608
Validation loss: 2.6549656736270566

Epoch: 5| Step: 10
Training loss: 1.6656958216055342
Validation loss: 2.6708255662572067

Epoch: 5| Step: 11
Training loss: 2.97669674227715
Validation loss: 2.6487641934801704

Epoch: 321| Step: 0
Training loss: 2.18381909894881
Validation loss: 2.6440333729314753

Epoch: 5| Step: 1
Training loss: 1.934404607740362
Validation loss: 2.6472577906273083

Epoch: 5| Step: 2
Training loss: 1.6956878106041495
Validation loss: 2.6024525850491975

Epoch: 5| Step: 3
Training loss: 2.415847464085132
Validation loss: 2.5839515043836507

Epoch: 5| Step: 4
Training loss: 2.0714083092736755
Validation loss: 2.6009340300394195

Epoch: 5| Step: 5
Training loss: 1.8924651215537918
Validation loss: 2.5589904283523683

Epoch: 5| Step: 6
Training loss: 2.7312745745707767
Validation loss: 2.5628633939287404

Epoch: 5| Step: 7
Training loss: 1.9631426445411861
Validation loss: 2.5742517641890132

Epoch: 5| Step: 8
Training loss: 2.212729546659821
Validation loss: 2.5854136098607445

Epoch: 5| Step: 9
Training loss: 2.3533578906880734
Validation loss: 2.602063070716692

Epoch: 5| Step: 10
Training loss: 2.4545500679807626
Validation loss: 2.636042363572642

Epoch: 5| Step: 11
Training loss: 1.5719378965015647
Validation loss: 2.668821069305647

Epoch: 322| Step: 0
Training loss: 2.312352665512103
Validation loss: 2.663425634186824

Epoch: 5| Step: 1
Training loss: 2.434608505077982
Validation loss: 2.6599372702685513

Epoch: 5| Step: 2
Training loss: 1.8227471699706426
Validation loss: 2.6559265014526034

Epoch: 5| Step: 3
Training loss: 2.4349732629768965
Validation loss: 2.640375545012543

Epoch: 5| Step: 4
Training loss: 2.161752397380835
Validation loss: 2.6353800598939365

Epoch: 5| Step: 5
Training loss: 2.336350420431049
Validation loss: 2.63727309439652

Epoch: 5| Step: 6
Training loss: 1.7744533637338933
Validation loss: 2.62856819582885

Epoch: 5| Step: 7
Training loss: 2.5281509454666597
Validation loss: 2.6248505564944145

Epoch: 5| Step: 8
Training loss: 2.1608574334548973
Validation loss: 2.6109655257371616

Epoch: 5| Step: 9
Training loss: 1.6246664731997777
Validation loss: 2.59468267899248

Epoch: 5| Step: 10
Training loss: 1.74114760766684
Validation loss: 2.6032014329549367

Epoch: 5| Step: 11
Training loss: 1.0901039387204072
Validation loss: 2.5698341419207895

Epoch: 323| Step: 0
Training loss: 2.1605246369454214
Validation loss: 2.5757619258305

Epoch: 5| Step: 1
Training loss: 1.9531783439980934
Validation loss: 2.5488572003300534

Epoch: 5| Step: 2
Training loss: 2.477692355359397
Validation loss: 2.552986216265212

Epoch: 5| Step: 3
Training loss: 2.5556636893389104
Validation loss: 2.551529222136297

Epoch: 5| Step: 4
Training loss: 1.6937937459891703
Validation loss: 2.5555308949506164

Epoch: 5| Step: 5
Training loss: 2.340039278499541
Validation loss: 2.572793485933475

Epoch: 5| Step: 6
Training loss: 2.1469657156933812
Validation loss: 2.6059033414120156

Epoch: 5| Step: 7
Training loss: 2.3737931447781118
Validation loss: 2.629987247856757

Epoch: 5| Step: 8
Training loss: 1.604468783708838
Validation loss: 2.6458559085353426

Epoch: 5| Step: 9
Training loss: 1.8486494495834165
Validation loss: 2.6538229868526915

Epoch: 5| Step: 10
Training loss: 2.7584281428735773
Validation loss: 2.656385190178813

Epoch: 5| Step: 11
Training loss: 1.561635655706252
Validation loss: 2.658778697981235

Epoch: 324| Step: 0
Training loss: 2.2969015729755378
Validation loss: 2.6225312484331686

Epoch: 5| Step: 1
Training loss: 1.5553543730853925
Validation loss: 2.651775641970384

Epoch: 5| Step: 2
Training loss: 2.609550150400884
Validation loss: 2.616486784852723

Epoch: 5| Step: 3
Training loss: 2.0514604297589907
Validation loss: 2.5914396314336887

Epoch: 5| Step: 4
Training loss: 2.5783915988755663
Validation loss: 2.6052083157419

Epoch: 5| Step: 5
Training loss: 2.1818632253057593
Validation loss: 2.610187917846649

Epoch: 5| Step: 6
Training loss: 2.2366290693728414
Validation loss: 2.6203752945783925

Epoch: 5| Step: 7
Training loss: 1.2401473848367999
Validation loss: 2.598444868189339

Epoch: 5| Step: 8
Training loss: 1.924499394607746
Validation loss: 2.6159574949069775

Epoch: 5| Step: 9
Training loss: 2.3298128909183786
Validation loss: 2.6532768851554454

Epoch: 5| Step: 10
Training loss: 2.2832229652554354
Validation loss: 2.6870837776438856

Epoch: 5| Step: 11
Training loss: 1.740446991781471
Validation loss: 2.678075017948593

Epoch: 325| Step: 0
Training loss: 2.173999762464017
Validation loss: 2.6703819803060584

Epoch: 5| Step: 1
Training loss: 2.1834035391355107
Validation loss: 2.6683867291412087

Epoch: 5| Step: 2
Training loss: 1.7931608874192426
Validation loss: 2.6293556883483378

Epoch: 5| Step: 3
Training loss: 1.3308213183999846
Validation loss: 2.625118218893398

Epoch: 5| Step: 4
Training loss: 2.278532421377799
Validation loss: 2.596475827278739

Epoch: 5| Step: 5
Training loss: 2.027499330758056
Validation loss: 2.5890946184620605

Epoch: 5| Step: 6
Training loss: 2.7534617396686025
Validation loss: 2.583760850407136

Epoch: 5| Step: 7
Training loss: 1.640039103204641
Validation loss: 2.5843228565138845

Epoch: 5| Step: 8
Training loss: 2.5977957551825606
Validation loss: 2.5704760127441966

Epoch: 5| Step: 9
Training loss: 2.2940854110581803
Validation loss: 2.577264337702879

Epoch: 5| Step: 10
Training loss: 2.213614524689431
Validation loss: 2.5728514131515907

Epoch: 5| Step: 11
Training loss: 3.0521634105467186
Validation loss: 2.574677576477383

Epoch: 326| Step: 0
Training loss: 2.6947998443900176
Validation loss: 2.582249925041881

Epoch: 5| Step: 1
Training loss: 2.6585954072573257
Validation loss: 2.6258599182227007

Epoch: 5| Step: 2
Training loss: 2.1289803868255324
Validation loss: 2.6002663867151568

Epoch: 5| Step: 3
Training loss: 1.6183231070706443
Validation loss: 2.6106504760806923

Epoch: 5| Step: 4
Training loss: 1.8700443263588693
Validation loss: 2.622862039824869

Epoch: 5| Step: 5
Training loss: 1.7005916267213108
Validation loss: 2.664714282300026

Epoch: 5| Step: 6
Training loss: 2.089094651630332
Validation loss: 2.633747881740786

Epoch: 5| Step: 7
Training loss: 2.1907546762784147
Validation loss: 2.631462082882204

Epoch: 5| Step: 8
Training loss: 2.0705700983978184
Validation loss: 2.621464145525315

Epoch: 5| Step: 9
Training loss: 1.812195653684915
Validation loss: 2.582388433315769

Epoch: 5| Step: 10
Training loss: 2.7668807632458647
Validation loss: 2.5775678283037444

Epoch: 5| Step: 11
Training loss: 1.4004256963661015
Validation loss: 2.6145842857409765

Epoch: 327| Step: 0
Training loss: 1.8646786486027376
Validation loss: 2.629595718550062

Epoch: 5| Step: 1
Training loss: 1.6505014235644369
Validation loss: 2.6612524424503334

Epoch: 5| Step: 2
Training loss: 2.1659567354553744
Validation loss: 2.6668058386387967

Epoch: 5| Step: 3
Training loss: 1.9695411787800423
Validation loss: 2.6959460854473773

Epoch: 5| Step: 4
Training loss: 2.4706986860755578
Validation loss: 2.653750054755789

Epoch: 5| Step: 5
Training loss: 2.6850214329721878
Validation loss: 2.6989163249103507

Epoch: 5| Step: 6
Training loss: 1.763438939187414
Validation loss: 2.6471472066131048

Epoch: 5| Step: 7
Training loss: 1.9339646108993147
Validation loss: 2.618160803191791

Epoch: 5| Step: 8
Training loss: 1.7061063237883736
Validation loss: 2.621177922132402

Epoch: 5| Step: 9
Training loss: 2.8069135497356696
Validation loss: 2.6285125566112115

Epoch: 5| Step: 10
Training loss: 1.8554700991977002
Validation loss: 2.6109235322199313

Epoch: 5| Step: 11
Training loss: 3.1808012340412777
Validation loss: 2.6350974328113534

Epoch: 328| Step: 0
Training loss: 2.2703343347705824
Validation loss: 2.613552636318263

Epoch: 5| Step: 1
Training loss: 1.6044996915004455
Validation loss: 2.6373050254541504

Epoch: 5| Step: 2
Training loss: 1.903100898978429
Validation loss: 2.6314491643608235

Epoch: 5| Step: 3
Training loss: 2.0650330218983814
Validation loss: 2.6215321552725674

Epoch: 5| Step: 4
Training loss: 2.1605482521804507
Validation loss: 2.6228860108450265

Epoch: 5| Step: 5
Training loss: 2.2914474613659994
Validation loss: 2.6164642663193813

Epoch: 5| Step: 6
Training loss: 2.165568794963345
Validation loss: 2.6215390368648595

Epoch: 5| Step: 7
Training loss: 2.5540584991434945
Validation loss: 2.6188511243974255

Epoch: 5| Step: 8
Training loss: 2.1410243643345854
Validation loss: 2.6249591695546757

Epoch: 5| Step: 9
Training loss: 2.1264544726533834
Validation loss: 2.592431085449843

Epoch: 5| Step: 10
Training loss: 2.187351112748453
Validation loss: 2.63586584542897

Epoch: 5| Step: 11
Training loss: 1.79386012041695
Validation loss: 2.6495337866393642

Epoch: 329| Step: 0
Training loss: 1.8509153369849956
Validation loss: 2.6253900805783372

Epoch: 5| Step: 1
Training loss: 1.5640397686597418
Validation loss: 2.599623674582177

Epoch: 5| Step: 2
Training loss: 2.581164146639689
Validation loss: 2.628999002756109

Epoch: 5| Step: 3
Training loss: 1.9841522932860447
Validation loss: 2.6097341431183114

Epoch: 5| Step: 4
Training loss: 2.2234299424365362
Validation loss: 2.608628049984648

Epoch: 5| Step: 5
Training loss: 2.6881407927470726
Validation loss: 2.6076538287560367

Epoch: 5| Step: 6
Training loss: 1.8821150884960793
Validation loss: 2.6377706092087445

Epoch: 5| Step: 7
Training loss: 2.616870006832573
Validation loss: 2.6660859560975996

Epoch: 5| Step: 8
Training loss: 1.9682469406462704
Validation loss: 2.685605656760806

Epoch: 5| Step: 9
Training loss: 2.0651042564619764
Validation loss: 2.6813436011669167

Epoch: 5| Step: 10
Training loss: 1.91795563547658
Validation loss: 2.670471711506324

Epoch: 5| Step: 11
Training loss: 0.3368397285171115
Validation loss: 2.6535346307686445

Epoch: 330| Step: 0
Training loss: 2.28451377770654
Validation loss: 2.642711695236776

Epoch: 5| Step: 1
Training loss: 1.618042724332928
Validation loss: 2.6438306014607913

Epoch: 5| Step: 2
Training loss: 1.4916262544808738
Validation loss: 2.6228146539009094

Epoch: 5| Step: 3
Training loss: 1.6736066175359159
Validation loss: 2.626168653168528

Epoch: 5| Step: 4
Training loss: 1.9834982068856906
Validation loss: 2.614461532481223

Epoch: 5| Step: 5
Training loss: 2.384303992577754
Validation loss: 2.610978910862368

Epoch: 5| Step: 6
Training loss: 2.0744533370243485
Validation loss: 2.5767380846788748

Epoch: 5| Step: 7
Training loss: 2.526497983846005
Validation loss: 2.5731593930016268

Epoch: 5| Step: 8
Training loss: 1.965486091593672
Validation loss: 2.5978477273607816

Epoch: 5| Step: 9
Training loss: 2.617371692154199
Validation loss: 2.6269058242188628

Epoch: 5| Step: 10
Training loss: 2.159519977919672
Validation loss: 2.65458401812659

Epoch: 5| Step: 11
Training loss: 2.840241835868605
Validation loss: 2.658866453874065

Epoch: 331| Step: 0
Training loss: 2.0398538157500714
Validation loss: 2.609844850737367

Epoch: 5| Step: 1
Training loss: 1.7302440902196754
Validation loss: 2.646691593630111

Epoch: 5| Step: 2
Training loss: 1.9331751514815056
Validation loss: 2.6093467589047425

Epoch: 5| Step: 3
Training loss: 2.4578882126929553
Validation loss: 2.57457373356196

Epoch: 5| Step: 4
Training loss: 1.9674487582057025
Validation loss: 2.603786232180839

Epoch: 5| Step: 5
Training loss: 2.2022474989844913
Validation loss: 2.596714700035045

Epoch: 5| Step: 6
Training loss: 2.5336109971251344
Validation loss: 2.5756196072842954

Epoch: 5| Step: 7
Training loss: 2.501507495320673
Validation loss: 2.5838850967738733

Epoch: 5| Step: 8
Training loss: 1.9128822892022785
Validation loss: 2.6248265315065473

Epoch: 5| Step: 9
Training loss: 1.8220172152621918
Validation loss: 2.620531638711604

Epoch: 5| Step: 10
Training loss: 2.0417002720564854
Validation loss: 2.6309559971191288

Epoch: 5| Step: 11
Training loss: 1.746937319713612
Validation loss: 2.672682244231023

Epoch: 332| Step: 0
Training loss: 2.556026376209069
Validation loss: 2.6300891786281944

Epoch: 5| Step: 1
Training loss: 2.2385340043604383
Validation loss: 2.630703048007453

Epoch: 5| Step: 2
Training loss: 1.8837117307303066
Validation loss: 2.6132032176533446

Epoch: 5| Step: 3
Training loss: 1.621935228467974
Validation loss: 2.6004676118662675

Epoch: 5| Step: 4
Training loss: 2.07007859546152
Validation loss: 2.6279743539980376

Epoch: 5| Step: 5
Training loss: 2.6620967470066867
Validation loss: 2.59094255630858

Epoch: 5| Step: 6
Training loss: 1.90412477938312
Validation loss: 2.619060013507439

Epoch: 5| Step: 7
Training loss: 1.8688736329279387
Validation loss: 2.6095024770637347

Epoch: 5| Step: 8
Training loss: 2.7172367664014554
Validation loss: 2.628716486996721

Epoch: 5| Step: 9
Training loss: 1.4615789626953877
Validation loss: 2.645694197102676

Epoch: 5| Step: 10
Training loss: 1.6990514212466923
Validation loss: 2.647788708193989

Epoch: 5| Step: 11
Training loss: 1.1617895375422098
Validation loss: 2.6611455197278793

Epoch: 333| Step: 0
Training loss: 2.58147670313748
Validation loss: 2.665665484527562

Epoch: 5| Step: 1
Training loss: 1.9137990342030822
Validation loss: 2.719767643123458

Epoch: 5| Step: 2
Training loss: 2.369278994149469
Validation loss: 2.683144177755493

Epoch: 5| Step: 3
Training loss: 1.5964642020589783
Validation loss: 2.6819887539580156

Epoch: 5| Step: 4
Training loss: 2.3535845101433512
Validation loss: 2.6678936278908214

Epoch: 5| Step: 5
Training loss: 1.2415962971624728
Validation loss: 2.6795951041408608

Epoch: 5| Step: 6
Training loss: 2.195499072852012
Validation loss: 2.676572707691759

Epoch: 5| Step: 7
Training loss: 2.073705462436791
Validation loss: 2.6517643134082465

Epoch: 5| Step: 8
Training loss: 1.685343388621497
Validation loss: 2.629816612810929

Epoch: 5| Step: 9
Training loss: 2.3538710709610404
Validation loss: 2.6159460397129117

Epoch: 5| Step: 10
Training loss: 2.0989271466105164
Validation loss: 2.6316680156333065

Epoch: 5| Step: 11
Training loss: 3.4811346613681313
Validation loss: 2.6052058066735007

Epoch: 334| Step: 0
Training loss: 2.3257313142181877
Validation loss: 2.5744306161665333

Epoch: 5| Step: 1
Training loss: 2.535890446459648
Validation loss: 2.5739147294253204

Epoch: 5| Step: 2
Training loss: 2.5438353765533157
Validation loss: 2.5519982044787652

Epoch: 5| Step: 3
Training loss: 2.037996093641436
Validation loss: 2.568969599919502

Epoch: 5| Step: 4
Training loss: 1.743205230825138
Validation loss: 2.5436562635692

Epoch: 5| Step: 5
Training loss: 1.977963459957952
Validation loss: 2.635638534243387

Epoch: 5| Step: 6
Training loss: 2.1427582740681803
Validation loss: 2.617762624833112

Epoch: 5| Step: 7
Training loss: 1.730227416972685
Validation loss: 2.6408407021629667

Epoch: 5| Step: 8
Training loss: 2.066280829908678
Validation loss: 2.691465634603012

Epoch: 5| Step: 9
Training loss: 2.185294647252974
Validation loss: 2.670789323306295

Epoch: 5| Step: 10
Training loss: 2.0008392957126935
Validation loss: 2.687932467595778

Epoch: 5| Step: 11
Training loss: 2.190530040821447
Validation loss: 2.6851556851391334

Epoch: 335| Step: 0
Training loss: 2.3528750992360346
Validation loss: 2.6398313860920286

Epoch: 5| Step: 1
Training loss: 2.141935295545301
Validation loss: 2.6543454092574152

Epoch: 5| Step: 2
Training loss: 2.171192748128071
Validation loss: 2.6261090214126526

Epoch: 5| Step: 3
Training loss: 1.9113805548896723
Validation loss: 2.6101839520985246

Epoch: 5| Step: 4
Training loss: 2.6641989754094024
Validation loss: 2.6360370197364222

Epoch: 5| Step: 5
Training loss: 2.3656097290674953
Validation loss: 2.647781061911573

Epoch: 5| Step: 6
Training loss: 1.4251358034440285
Validation loss: 2.624277859463397

Epoch: 5| Step: 7
Training loss: 1.8487407574219474
Validation loss: 2.6033828350447497

Epoch: 5| Step: 8
Training loss: 2.0510891928396586
Validation loss: 2.5872870935084853

Epoch: 5| Step: 9
Training loss: 1.8383187941491865
Validation loss: 2.580402019922578

Epoch: 5| Step: 10
Training loss: 2.068618369164519
Validation loss: 2.5507053989039346

Epoch: 5| Step: 11
Training loss: 0.9040860616262051
Validation loss: 2.5455329065845307

Epoch: 336| Step: 0
Training loss: 2.6123273217477374
Validation loss: 2.5661050009080637

Epoch: 5| Step: 1
Training loss: 1.8255875412474902
Validation loss: 2.567683002483677

Epoch: 5| Step: 2
Training loss: 2.0350524524424167
Validation loss: 2.5865078169449363

Epoch: 5| Step: 3
Training loss: 1.550753192023215
Validation loss: 2.5775358740736345

Epoch: 5| Step: 4
Training loss: 2.461652476279084
Validation loss: 2.6096440631472095

Epoch: 5| Step: 5
Training loss: 1.9964381926704668
Validation loss: 2.639773688694796

Epoch: 5| Step: 6
Training loss: 2.3433639208378665
Validation loss: 2.659087404687465

Epoch: 5| Step: 7
Training loss: 1.782995673623134
Validation loss: 2.6894265263354176

Epoch: 5| Step: 8
Training loss: 1.9605305770011145
Validation loss: 2.672389967966542

Epoch: 5| Step: 9
Training loss: 1.899361091404684
Validation loss: 2.686711191882386

Epoch: 5| Step: 10
Training loss: 2.3774210987175666
Validation loss: 2.671023532464799

Epoch: 5| Step: 11
Training loss: 1.8614745267630826
Validation loss: 2.677900632394101

Epoch: 337| Step: 0
Training loss: 2.103947643803479
Validation loss: 2.6696751631015188

Epoch: 5| Step: 1
Training loss: 2.0880034427833674
Validation loss: 2.674185688788816

Epoch: 5| Step: 2
Training loss: 2.130950002727313
Validation loss: 2.6489013183214216

Epoch: 5| Step: 3
Training loss: 1.5348709268386196
Validation loss: 2.6465823710223324

Epoch: 5| Step: 4
Training loss: 2.011264905382382
Validation loss: 2.633082610856873

Epoch: 5| Step: 5
Training loss: 3.006263076214496
Validation loss: 2.6316289080720936

Epoch: 5| Step: 6
Training loss: 1.7438052069562526
Validation loss: 2.6321588114120433

Epoch: 5| Step: 7
Training loss: 2.0393531562928335
Validation loss: 2.639845780139183

Epoch: 5| Step: 8
Training loss: 2.4375667073829783
Validation loss: 2.6312983617921573

Epoch: 5| Step: 9
Training loss: 1.7234067082356321
Validation loss: 2.650010818483354

Epoch: 5| Step: 10
Training loss: 1.7127654879193666
Validation loss: 2.6504360261615973

Epoch: 5| Step: 11
Training loss: 1.8396456018481304
Validation loss: 2.638998316843918

Epoch: 338| Step: 0
Training loss: 1.4974508878013173
Validation loss: 2.57929459060983

Epoch: 5| Step: 1
Training loss: 2.095658642242555
Validation loss: 2.579103492236327

Epoch: 5| Step: 2
Training loss: 1.864945985559028
Validation loss: 2.5699021689216135

Epoch: 5| Step: 3
Training loss: 2.5799129875059363
Validation loss: 2.589327254846898

Epoch: 5| Step: 4
Training loss: 2.483486088485877
Validation loss: 2.5963003228872035

Epoch: 5| Step: 5
Training loss: 1.9764187123465695
Validation loss: 2.613386831540847

Epoch: 5| Step: 6
Training loss: 2.413970155400296
Validation loss: 2.600937874301387

Epoch: 5| Step: 7
Training loss: 1.84747597458101
Validation loss: 2.6145698096139616

Epoch: 5| Step: 8
Training loss: 2.308470850221159
Validation loss: 2.631424372853581

Epoch: 5| Step: 9
Training loss: 1.9094603349312231
Validation loss: 2.6448997492501634

Epoch: 5| Step: 10
Training loss: 2.0427691797988423
Validation loss: 2.6172577084665773

Epoch: 5| Step: 11
Training loss: 2.207648104994784
Validation loss: 2.623913244809307

Epoch: 339| Step: 0
Training loss: 1.8022373626092354
Validation loss: 2.59678608175575

Epoch: 5| Step: 1
Training loss: 1.4296429736598608
Validation loss: 2.599836714520096

Epoch: 5| Step: 2
Training loss: 2.016141603492183
Validation loss: 2.619599865565479

Epoch: 5| Step: 3
Training loss: 1.901260224063427
Validation loss: 2.622704073314907

Epoch: 5| Step: 4
Training loss: 1.4267279003644902
Validation loss: 2.6247777920480977

Epoch: 5| Step: 5
Training loss: 2.277097816339791
Validation loss: 2.6399143135429353

Epoch: 5| Step: 6
Training loss: 2.146911078848157
Validation loss: 2.648012747973521

Epoch: 5| Step: 7
Training loss: 2.255208133641705
Validation loss: 2.715229319904019

Epoch: 5| Step: 8
Training loss: 2.628321952561352
Validation loss: 2.726319257566907

Epoch: 5| Step: 9
Training loss: 2.535921096043583
Validation loss: 2.7145162188142113

Epoch: 5| Step: 10
Training loss: 2.3194284521022386
Validation loss: 2.6960092095593664

Epoch: 5| Step: 11
Training loss: 2.135374884468017
Validation loss: 2.679032949242161

Epoch: 340| Step: 0
Training loss: 1.8358576331115535
Validation loss: 2.630454085297546

Epoch: 5| Step: 1
Training loss: 2.1632842168928845
Validation loss: 2.577301217451205

Epoch: 5| Step: 2
Training loss: 2.012307445720836
Validation loss: 2.5485245992845282

Epoch: 5| Step: 3
Training loss: 2.075284809651006
Validation loss: 2.558442407844607

Epoch: 5| Step: 4
Training loss: 2.268423102081301
Validation loss: 2.557753858474696

Epoch: 5| Step: 5
Training loss: 2.3803712439903797
Validation loss: 2.559121323567544

Epoch: 5| Step: 6
Training loss: 2.5828272621208312
Validation loss: 2.5484829548349373

Epoch: 5| Step: 7
Training loss: 1.7723751162935135
Validation loss: 2.5478111255108185

Epoch: 5| Step: 8
Training loss: 2.1154187686537296
Validation loss: 2.557581538742964

Epoch: 5| Step: 9
Training loss: 2.3677479297724346
Validation loss: 2.56923432235609

Epoch: 5| Step: 10
Training loss: 1.631472096725095
Validation loss: 2.5917565448749857

Epoch: 5| Step: 11
Training loss: 1.3680661239258847
Validation loss: 2.6244856655986424

Epoch: 341| Step: 0
Training loss: 1.5801491927678948
Validation loss: 2.6466081165696522

Epoch: 5| Step: 1
Training loss: 1.19752143753072
Validation loss: 2.6423559516013113

Epoch: 5| Step: 2
Training loss: 2.544122062297934
Validation loss: 2.6414270368027224

Epoch: 5| Step: 3
Training loss: 2.105036590330643
Validation loss: 2.629048899558679

Epoch: 5| Step: 4
Training loss: 3.000229190972626
Validation loss: 2.6285069858218004

Epoch: 5| Step: 5
Training loss: 2.603548408868515
Validation loss: 2.5913299162889345

Epoch: 5| Step: 6
Training loss: 2.4844700057379683
Validation loss: 2.6076300834363737

Epoch: 5| Step: 7
Training loss: 1.6927953922674137
Validation loss: 2.6198580236101656

Epoch: 5| Step: 8
Training loss: 1.8039184517032658
Validation loss: 2.6464048028786444

Epoch: 5| Step: 9
Training loss: 2.0922640181801246
Validation loss: 2.6474481833504973

Epoch: 5| Step: 10
Training loss: 1.4296205431992195
Validation loss: 2.6670731828203706

Epoch: 5| Step: 11
Training loss: 0.6729177987725937
Validation loss: 2.659806903114122

Epoch: 342| Step: 0
Training loss: 2.225330962522481
Validation loss: 2.6651850076004213

Epoch: 5| Step: 1
Training loss: 2.1470614378711113
Validation loss: 2.690504457296732

Epoch: 5| Step: 2
Training loss: 2.300704151668758
Validation loss: 2.6608339661014937

Epoch: 5| Step: 3
Training loss: 1.309171406797832
Validation loss: 2.66454590096824

Epoch: 5| Step: 4
Training loss: 1.983140576503112
Validation loss: 2.677680581014141

Epoch: 5| Step: 5
Training loss: 2.034620335284311
Validation loss: 2.661215595042675

Epoch: 5| Step: 6
Training loss: 1.6935481018001708
Validation loss: 2.6788653752088187

Epoch: 5| Step: 7
Training loss: 2.5646953018086545
Validation loss: 2.6218881857551435

Epoch: 5| Step: 8
Training loss: 2.378397268582292
Validation loss: 2.5848259741091155

Epoch: 5| Step: 9
Training loss: 1.72942636064115
Validation loss: 2.5989283800150953

Epoch: 5| Step: 10
Training loss: 1.93020536446862
Validation loss: 2.6084616198897868

Epoch: 5| Step: 11
Training loss: 2.662470366980186
Validation loss: 2.5992700750391404

Epoch: 343| Step: 0
Training loss: 2.0245233516387424
Validation loss: 2.6266823819359204

Epoch: 5| Step: 1
Training loss: 2.355094513019103
Validation loss: 2.6730053761826933

Epoch: 5| Step: 2
Training loss: 1.3172557591391854
Validation loss: 2.684946366188234

Epoch: 5| Step: 3
Training loss: 2.026313417020023
Validation loss: 2.6594609805117795

Epoch: 5| Step: 4
Training loss: 2.0566403931475414
Validation loss: 2.668395373675343

Epoch: 5| Step: 5
Training loss: 2.673026656526314
Validation loss: 2.665481208271102

Epoch: 5| Step: 6
Training loss: 2.284707467116224
Validation loss: 2.646333182920586

Epoch: 5| Step: 7
Training loss: 1.760709012227326
Validation loss: 2.6310350434489784

Epoch: 5| Step: 8
Training loss: 1.9893451834411782
Validation loss: 2.634132348737837

Epoch: 5| Step: 9
Training loss: 1.7999736439576721
Validation loss: 2.642390558165325

Epoch: 5| Step: 10
Training loss: 2.203810348506663
Validation loss: 2.6019800211969946

Epoch: 5| Step: 11
Training loss: 2.0770420321608896
Validation loss: 2.609311432359195

Epoch: 344| Step: 0
Training loss: 2.219087709327469
Validation loss: 2.5970049851956882

Epoch: 5| Step: 1
Training loss: 2.462984523450431
Validation loss: 2.575347911299791

Epoch: 5| Step: 2
Training loss: 2.055891489238
Validation loss: 2.5917535053333847

Epoch: 5| Step: 3
Training loss: 1.6883358474793062
Validation loss: 2.5996027563532933

Epoch: 5| Step: 4
Training loss: 2.064206197907086
Validation loss: 2.6002217370933707

Epoch: 5| Step: 5
Training loss: 2.3941664052189244
Validation loss: 2.6147755682643727

Epoch: 5| Step: 6
Training loss: 1.742767784744769
Validation loss: 2.6260596324019105

Epoch: 5| Step: 7
Training loss: 2.1426641400023025
Validation loss: 2.6222621816741993

Epoch: 5| Step: 8
Training loss: 2.248225784142499
Validation loss: 2.6544651504931167

Epoch: 5| Step: 9
Training loss: 2.0585072334538648
Validation loss: 2.671824798707258

Epoch: 5| Step: 10
Training loss: 1.4717490237482098
Validation loss: 2.6571030537236036

Epoch: 5| Step: 11
Training loss: 2.028405883335796
Validation loss: 2.6327118972287713

Epoch: 345| Step: 0
Training loss: 2.2912768176851155
Validation loss: 2.674176531751994

Epoch: 5| Step: 1
Training loss: 1.747312184665855
Validation loss: 2.617808948581377

Epoch: 5| Step: 2
Training loss: 1.5511476482650322
Validation loss: 2.622029103026911

Epoch: 5| Step: 3
Training loss: 1.6669261094658472
Validation loss: 2.6258181931706774

Epoch: 5| Step: 4
Training loss: 2.209957700989124
Validation loss: 2.645459311373842

Epoch: 5| Step: 5
Training loss: 2.3092599801416447
Validation loss: 2.642609424316424

Epoch: 5| Step: 6
Training loss: 2.5458478670178843
Validation loss: 2.6355398222200996

Epoch: 5| Step: 7
Training loss: 1.9664237796455257
Validation loss: 2.6656395913634428

Epoch: 5| Step: 8
Training loss: 2.058981929423704
Validation loss: 2.6675812070695337

Epoch: 5| Step: 9
Training loss: 1.6825971375265454
Validation loss: 2.6450296605651937

Epoch: 5| Step: 10
Training loss: 2.2354624842783033
Validation loss: 2.6329538475301413

Epoch: 5| Step: 11
Training loss: 0.9957452800293121
Validation loss: 2.624260942173489

Epoch: 346| Step: 0
Training loss: 2.264316365059048
Validation loss: 2.6132943837777116

Epoch: 5| Step: 1
Training loss: 1.7791979162373792
Validation loss: 2.5960607423462387

Epoch: 5| Step: 2
Training loss: 2.2204396436288323
Validation loss: 2.617596077222943

Epoch: 5| Step: 3
Training loss: 1.6305875814405957
Validation loss: 2.6186536677144567

Epoch: 5| Step: 4
Training loss: 1.8730195712743716
Validation loss: 2.5952555832965247

Epoch: 5| Step: 5
Training loss: 1.6472803185295881
Validation loss: 2.6174417856149876

Epoch: 5| Step: 6
Training loss: 2.8540085426208064
Validation loss: 2.595469322419631

Epoch: 5| Step: 7
Training loss: 1.5285703606850085
Validation loss: 2.607061876073858

Epoch: 5| Step: 8
Training loss: 2.554807887609229
Validation loss: 2.625175848626362

Epoch: 5| Step: 9
Training loss: 1.8614608220996525
Validation loss: 2.6567993867485575

Epoch: 5| Step: 10
Training loss: 1.7363960930788016
Validation loss: 2.600120557227492

Epoch: 5| Step: 11
Training loss: 1.9651244552647462
Validation loss: 2.6803236374044164

Epoch: 347| Step: 0
Training loss: 1.7417488401213905
Validation loss: 2.680804254401622

Epoch: 5| Step: 1
Training loss: 1.6015656261878788
Validation loss: 2.6946218444217767

Epoch: 5| Step: 2
Training loss: 2.046340290144542
Validation loss: 2.7310196043908137

Epoch: 5| Step: 3
Training loss: 1.6493540742218147
Validation loss: 2.7209973747804335

Epoch: 5| Step: 4
Training loss: 2.230781065659029
Validation loss: 2.710938720263116

Epoch: 5| Step: 5
Training loss: 2.199723668517133
Validation loss: 2.6611992242674702

Epoch: 5| Step: 6
Training loss: 2.712094810212674
Validation loss: 2.6234330314157406

Epoch: 5| Step: 7
Training loss: 2.0432597841070335
Validation loss: 2.5986877802583495

Epoch: 5| Step: 8
Training loss: 1.6712698866375004
Validation loss: 2.5675836936510743

Epoch: 5| Step: 9
Training loss: 1.5415835572944088
Validation loss: 2.5895443527978763

Epoch: 5| Step: 10
Training loss: 2.708115573834078
Validation loss: 2.5787250629648675

Epoch: 5| Step: 11
Training loss: 1.2908078486711962
Validation loss: 2.6129306506711045

Epoch: 348| Step: 0
Training loss: 2.421778129363078
Validation loss: 2.5844761156368543

Epoch: 5| Step: 1
Training loss: 1.3585713521241942
Validation loss: 2.570144647839588

Epoch: 5| Step: 2
Training loss: 2.460550526060456
Validation loss: 2.589738641354141

Epoch: 5| Step: 3
Training loss: 2.653883115113415
Validation loss: 2.611670867940481

Epoch: 5| Step: 4
Training loss: 1.884851009035841
Validation loss: 2.595043331016

Epoch: 5| Step: 5
Training loss: 2.2942023265250513
Validation loss: 2.6162135575221925

Epoch: 5| Step: 6
Training loss: 2.5948525349019285
Validation loss: 2.611691369999034

Epoch: 5| Step: 7
Training loss: 1.2142146895177148
Validation loss: 2.6025858251630103

Epoch: 5| Step: 8
Training loss: 1.8195584417582285
Validation loss: 2.6323310608074086

Epoch: 5| Step: 9
Training loss: 1.679285329533686
Validation loss: 2.6847895919741664

Epoch: 5| Step: 10
Training loss: 1.8144621915559942
Validation loss: 2.6532181060353994

Epoch: 5| Step: 11
Training loss: 1.5897203252248056
Validation loss: 2.6690561583496906

Epoch: 349| Step: 0
Training loss: 2.323300681995329
Validation loss: 2.640301667682335

Epoch: 5| Step: 1
Training loss: 2.010160861434421
Validation loss: 2.6445341236994806

Epoch: 5| Step: 2
Training loss: 2.0205330641999875
Validation loss: 2.585900128758158

Epoch: 5| Step: 3
Training loss: 1.805002754716541
Validation loss: 2.57578319194282

Epoch: 5| Step: 4
Training loss: 1.706293500967548
Validation loss: 2.555767437684802

Epoch: 5| Step: 5
Training loss: 2.0167798423010908
Validation loss: 2.5879106552020628

Epoch: 5| Step: 6
Training loss: 2.2431372780834518
Validation loss: 2.561954036950527

Epoch: 5| Step: 7
Training loss: 2.2058731146226296
Validation loss: 2.5871321846733393

Epoch: 5| Step: 8
Training loss: 2.5264203184341136
Validation loss: 2.6007179477910234

Epoch: 5| Step: 9
Training loss: 2.117830861442486
Validation loss: 2.6266318426107067

Epoch: 5| Step: 10
Training loss: 1.9212877570408928
Validation loss: 2.662625672056413

Epoch: 5| Step: 11
Training loss: 2.7289552873671674
Validation loss: 2.6829696884717915

Epoch: 350| Step: 0
Training loss: 1.825353755370414
Validation loss: 2.6900616014971472

Epoch: 5| Step: 1
Training loss: 2.405052184175212
Validation loss: 2.6774741541852474

Epoch: 5| Step: 2
Training loss: 2.527174600544926
Validation loss: 2.685398999391084

Epoch: 5| Step: 3
Training loss: 2.271320104194156
Validation loss: 2.659542985863387

Epoch: 5| Step: 4
Training loss: 2.0004533015575863
Validation loss: 2.6122205488969064

Epoch: 5| Step: 5
Training loss: 2.1671869191318165
Validation loss: 2.6000421872139805

Epoch: 5| Step: 6
Training loss: 1.7860054650644925
Validation loss: 2.61448023062132

Epoch: 5| Step: 7
Training loss: 1.7496725866026586
Validation loss: 2.5886730081457796

Epoch: 5| Step: 8
Training loss: 2.8159893007671233
Validation loss: 2.6021933721441974

Epoch: 5| Step: 9
Training loss: 1.5356495770733876
Validation loss: 2.5839884424694186

Epoch: 5| Step: 10
Training loss: 1.6168530989182182
Validation loss: 2.61068431190511

Epoch: 5| Step: 11
Training loss: 1.1728640642222443
Validation loss: 2.6087304992568394

Epoch: 351| Step: 0
Training loss: 1.4077402483724821
Validation loss: 2.636487785867147

Epoch: 5| Step: 1
Training loss: 2.3461212370002564
Validation loss: 2.5916167874355844

Epoch: 5| Step: 2
Training loss: 1.7914144057476251
Validation loss: 2.612233360956738

Epoch: 5| Step: 3
Training loss: 1.9627699478023948
Validation loss: 2.621491153340507

Epoch: 5| Step: 4
Training loss: 2.142524711617716
Validation loss: 2.635812957028426

Epoch: 5| Step: 5
Training loss: 2.535041324496849
Validation loss: 2.6177403259953507

Epoch: 5| Step: 6
Training loss: 1.6394122773272346
Validation loss: 2.6555362976766768

Epoch: 5| Step: 7
Training loss: 2.3397095503238665
Validation loss: 2.6520392721151422

Epoch: 5| Step: 8
Training loss: 2.202608629680546
Validation loss: 2.670417767498353

Epoch: 5| Step: 9
Training loss: 1.7685494299083226
Validation loss: 2.645148197335849

Epoch: 5| Step: 10
Training loss: 2.1157898741449785
Validation loss: 2.611398871411447

Epoch: 5| Step: 11
Training loss: 1.3657261040664157
Validation loss: 2.5969707148510053

Epoch: 352| Step: 0
Training loss: 2.579203986748863
Validation loss: 2.5818626167913368

Epoch: 5| Step: 1
Training loss: 2.1355497241241053
Validation loss: 2.6055864825093096

Epoch: 5| Step: 2
Training loss: 1.746063846613696
Validation loss: 2.6116599778205534

Epoch: 5| Step: 3
Training loss: 1.8463319706266412
Validation loss: 2.632854506613119

Epoch: 5| Step: 4
Training loss: 1.4239732121562536
Validation loss: 2.621863243219132

Epoch: 5| Step: 5
Training loss: 2.7286425856568335
Validation loss: 2.6287034302723873

Epoch: 5| Step: 6
Training loss: 2.2718540195928814
Validation loss: 2.630814357222313

Epoch: 5| Step: 7
Training loss: 1.4781146091475006
Validation loss: 2.6608365907200118

Epoch: 5| Step: 8
Training loss: 1.7585749350193318
Validation loss: 2.6297950432513035

Epoch: 5| Step: 9
Training loss: 1.8504087821290258
Validation loss: 2.6053586266468374

Epoch: 5| Step: 10
Training loss: 1.893754685902857
Validation loss: 2.6203797225806476

Epoch: 5| Step: 11
Training loss: 2.0330142062582595
Validation loss: 2.6370335897221437

Epoch: 353| Step: 0
Training loss: 1.9575782970686135
Validation loss: 2.6206392442756004

Epoch: 5| Step: 1
Training loss: 1.5236469613865624
Validation loss: 2.6017102876370983

Epoch: 5| Step: 2
Training loss: 1.51805690444618
Validation loss: 2.6165333286154997

Epoch: 5| Step: 3
Training loss: 2.3955280164697825
Validation loss: 2.643415107513454

Epoch: 5| Step: 4
Training loss: 1.7366808435419099
Validation loss: 2.613167148716397

Epoch: 5| Step: 5
Training loss: 2.3123851438300154
Validation loss: 2.6234559180238173

Epoch: 5| Step: 6
Training loss: 1.8948581059659837
Validation loss: 2.61228832774521

Epoch: 5| Step: 7
Training loss: 2.0354612857713663
Validation loss: 2.5907307329063585

Epoch: 5| Step: 8
Training loss: 2.5439683675178903
Validation loss: 2.615192767214199

Epoch: 5| Step: 9
Training loss: 2.0013528063337365
Validation loss: 2.6212340012769904

Epoch: 5| Step: 10
Training loss: 2.28410484709988
Validation loss: 2.5997172351666187

Epoch: 5| Step: 11
Training loss: 1.0870053646267601
Validation loss: 2.6033211339948834

Epoch: 354| Step: 0
Training loss: 1.6859322789122846
Validation loss: 2.6260560575638427

Epoch: 5| Step: 1
Training loss: 1.6043435118987932
Validation loss: 2.628412006580938

Epoch: 5| Step: 2
Training loss: 1.85943872679167
Validation loss: 2.7107763251654338

Epoch: 5| Step: 3
Training loss: 1.7422075484281219
Validation loss: 2.746944232483379

Epoch: 5| Step: 4
Training loss: 2.780400006997837
Validation loss: 2.7712823580451684

Epoch: 5| Step: 5
Training loss: 2.520462408177832
Validation loss: 2.7817314638457487

Epoch: 5| Step: 6
Training loss: 2.0618587999959175
Validation loss: 2.742993851194352

Epoch: 5| Step: 7
Training loss: 1.9626943309810712
Validation loss: 2.724956272515176

Epoch: 5| Step: 8
Training loss: 1.921041664636795
Validation loss: 2.668444585931113

Epoch: 5| Step: 9
Training loss: 2.2582261917580553
Validation loss: 2.669381098757033

Epoch: 5| Step: 10
Training loss: 1.900976986416172
Validation loss: 2.6034811122063366

Epoch: 5| Step: 11
Training loss: 1.9920398732258364
Validation loss: 2.6155344586974163

Epoch: 355| Step: 0
Training loss: 1.7639497219151974
Validation loss: 2.6392632421074786

Epoch: 5| Step: 1
Training loss: 1.926364400289794
Validation loss: 2.6320700197505635

Epoch: 5| Step: 2
Training loss: 1.9914427917408246
Validation loss: 2.640902367344893

Epoch: 5| Step: 3
Training loss: 2.637771328533715
Validation loss: 2.6638112252650648

Epoch: 5| Step: 4
Training loss: 2.033379714728663
Validation loss: 2.6498637021149603

Epoch: 5| Step: 5
Training loss: 2.8531436246867807
Validation loss: 2.6456471863292563

Epoch: 5| Step: 6
Training loss: 1.4800950839454643
Validation loss: 2.6602275911643334

Epoch: 5| Step: 7
Training loss: 2.4324391964941516
Validation loss: 2.6331078602338405

Epoch: 5| Step: 8
Training loss: 1.1320691530820564
Validation loss: 2.6302418256584943

Epoch: 5| Step: 9
Training loss: 1.8814959216411993
Validation loss: 2.631764083381561

Epoch: 5| Step: 10
Training loss: 1.9854466105468334
Validation loss: 2.621177270262614

Epoch: 5| Step: 11
Training loss: 0.5839531166105851
Validation loss: 2.657123769771781

Epoch: 356| Step: 0
Training loss: 2.12963205266744
Validation loss: 2.6591984298368705

Epoch: 5| Step: 1
Training loss: 2.25372567602182
Validation loss: 2.6746661774880733

Epoch: 5| Step: 2
Training loss: 1.9263486819329374
Validation loss: 2.696406602168502

Epoch: 5| Step: 3
Training loss: 1.9359097876732043
Validation loss: 2.67062637273121

Epoch: 5| Step: 4
Training loss: 1.476992105626915
Validation loss: 2.6894980662092434

Epoch: 5| Step: 5
Training loss: 2.000996103186676
Validation loss: 2.7079482990837

Epoch: 5| Step: 6
Training loss: 1.3918185737453697
Validation loss: 2.7059238126401026

Epoch: 5| Step: 7
Training loss: 2.5178406240429623
Validation loss: 2.6642210047190695

Epoch: 5| Step: 8
Training loss: 1.6238121679796165
Validation loss: 2.65767571951197

Epoch: 5| Step: 9
Training loss: 2.1363605429149195
Validation loss: 2.6244177096777483

Epoch: 5| Step: 10
Training loss: 2.2679545035129967
Validation loss: 2.5911548032876928

Epoch: 5| Step: 11
Training loss: 3.2369739944690843
Validation loss: 2.618442431910113

Epoch: 357| Step: 0
Training loss: 2.0057583405512536
Validation loss: 2.6310686435555395

Epoch: 5| Step: 1
Training loss: 2.6373860736847496
Validation loss: 2.647334744138045

Epoch: 5| Step: 2
Training loss: 1.9448485529758999
Validation loss: 2.6273784193915692

Epoch: 5| Step: 3
Training loss: 1.9269596850617798
Validation loss: 2.586756900070906

Epoch: 5| Step: 4
Training loss: 1.8815091002216595
Validation loss: 2.612214205592022

Epoch: 5| Step: 5
Training loss: 1.9432154003082724
Validation loss: 2.624745602617699

Epoch: 5| Step: 6
Training loss: 1.759561982052028
Validation loss: 2.590491814558503

Epoch: 5| Step: 7
Training loss: 2.0719890212132688
Validation loss: 2.591674472167434

Epoch: 5| Step: 8
Training loss: 1.988800640504447
Validation loss: 2.626091864359685

Epoch: 5| Step: 9
Training loss: 1.952386395987344
Validation loss: 2.579423696768301

Epoch: 5| Step: 10
Training loss: 1.1699472466011926
Validation loss: 2.595641951346025

Epoch: 5| Step: 11
Training loss: 3.318661986367509
Validation loss: 2.5814342376070427

Epoch: 358| Step: 0
Training loss: 2.04002749237534
Validation loss: 2.610297205709039

Epoch: 5| Step: 1
Training loss: 1.5341418460134562
Validation loss: 2.594238346348039

Epoch: 5| Step: 2
Training loss: 1.6211335326679157
Validation loss: 2.6337445474214243

Epoch: 5| Step: 3
Training loss: 2.212580094261663
Validation loss: 2.676464407556561

Epoch: 5| Step: 4
Training loss: 1.854399684308431
Validation loss: 2.7078544095437858

Epoch: 5| Step: 5
Training loss: 1.9010425166994747
Validation loss: 2.6621839513335983

Epoch: 5| Step: 6
Training loss: 1.8673419329890004
Validation loss: 2.6449421986403903

Epoch: 5| Step: 7
Training loss: 2.431338322856704
Validation loss: 2.625484391584939

Epoch: 5| Step: 8
Training loss: 2.4895504958622054
Validation loss: 2.6355840883614463

Epoch: 5| Step: 9
Training loss: 2.043566643658874
Validation loss: 2.6131382377050163

Epoch: 5| Step: 10
Training loss: 1.900499895488733
Validation loss: 2.5674855494750313

Epoch: 5| Step: 11
Training loss: 2.362954664127194
Validation loss: 2.584257023527512

Epoch: 359| Step: 0
Training loss: 2.3507596796833052
Validation loss: 2.569992161416

Epoch: 5| Step: 1
Training loss: 1.5456002888321854
Validation loss: 2.5787902205007684

Epoch: 5| Step: 2
Training loss: 1.7733755226900811
Validation loss: 2.618307137958249

Epoch: 5| Step: 3
Training loss: 2.004551595836913
Validation loss: 2.630769920197092

Epoch: 5| Step: 4
Training loss: 1.8189506839528293
Validation loss: 2.6832725706585583

Epoch: 5| Step: 5
Training loss: 1.7667313207035906
Validation loss: 2.6749238916960656

Epoch: 5| Step: 6
Training loss: 2.376155371469895
Validation loss: 2.665527213309106

Epoch: 5| Step: 7
Training loss: 1.8164568494086364
Validation loss: 2.6674347804401926

Epoch: 5| Step: 8
Training loss: 2.4483360634674507
Validation loss: 2.6489791691288547

Epoch: 5| Step: 9
Training loss: 2.1821364997805057
Validation loss: 2.6235787729830857

Epoch: 5| Step: 10
Training loss: 1.50348940930761
Validation loss: 2.5726425678697544

Epoch: 5| Step: 11
Training loss: 2.7787510650262064
Validation loss: 2.5812698295761405

Epoch: 360| Step: 0
Training loss: 1.952413322488308
Validation loss: 2.577715473208838

Epoch: 5| Step: 1
Training loss: 1.7456037614720672
Validation loss: 2.546897065080729

Epoch: 5| Step: 2
Training loss: 2.750810503729619
Validation loss: 2.580492466228486

Epoch: 5| Step: 3
Training loss: 2.0921709169694975
Validation loss: 2.5754357540219646

Epoch: 5| Step: 4
Training loss: 1.730724307235277
Validation loss: 2.571805696106017

Epoch: 5| Step: 5
Training loss: 2.5265919718441876
Validation loss: 2.612289812752749

Epoch: 5| Step: 6
Training loss: 1.8609678994617689
Validation loss: 2.6118676240075507

Epoch: 5| Step: 7
Training loss: 2.3523135585868173
Validation loss: 2.6234589132616875

Epoch: 5| Step: 8
Training loss: 2.0151870606634343
Validation loss: 2.6350863284875365

Epoch: 5| Step: 9
Training loss: 1.3559356237197628
Validation loss: 2.6716429626363594

Epoch: 5| Step: 10
Training loss: 1.5214010076245437
Validation loss: 2.6346968671773734

Epoch: 5| Step: 11
Training loss: 1.601145471381699
Validation loss: 2.675043532501565

Epoch: 361| Step: 0
Training loss: 2.1385341930924637
Validation loss: 2.6887258203265474

Epoch: 5| Step: 1
Training loss: 1.8692521686814327
Validation loss: 2.6593634889430486

Epoch: 5| Step: 2
Training loss: 1.719539946309223
Validation loss: 2.680542982617695

Epoch: 5| Step: 3
Training loss: 1.7921692638583566
Validation loss: 2.6618274736307876

Epoch: 5| Step: 4
Training loss: 1.8792388685048242
Validation loss: 2.6678267776746485

Epoch: 5| Step: 5
Training loss: 2.2124501368189424
Validation loss: 2.683701321936699

Epoch: 5| Step: 6
Training loss: 1.7700931423271002
Validation loss: 2.667060217029872

Epoch: 5| Step: 7
Training loss: 1.9549308058257218
Validation loss: 2.661079179415812

Epoch: 5| Step: 8
Training loss: 1.9140131729932273
Validation loss: 2.6770712200340987

Epoch: 5| Step: 9
Training loss: 2.232116090886534
Validation loss: 2.671407945051576

Epoch: 5| Step: 10
Training loss: 2.2162296863535063
Validation loss: 2.6302411174934193

Epoch: 5| Step: 11
Training loss: 2.49975250926456
Validation loss: 2.6014341775216607

Epoch: 362| Step: 0
Training loss: 1.646356797168452
Validation loss: 2.619037331239922

Epoch: 5| Step: 1
Training loss: 2.1567965934251094
Validation loss: 2.5457137684338376

Epoch: 5| Step: 2
Training loss: 1.9377323134413296
Validation loss: 2.5388129517604363

Epoch: 5| Step: 3
Training loss: 1.940750963235636
Validation loss: 2.504882348489997

Epoch: 5| Step: 4
Training loss: 1.8491838201294815
Validation loss: 2.5450411905466543

Epoch: 5| Step: 5
Training loss: 1.3731629497577935
Validation loss: 2.527784703114796

Epoch: 5| Step: 6
Training loss: 2.189458243017825
Validation loss: 2.538375640300747

Epoch: 5| Step: 7
Training loss: 2.463356113233872
Validation loss: 2.6118652012088868

Epoch: 5| Step: 8
Training loss: 2.0258225924815076
Validation loss: 2.6022711849182834

Epoch: 5| Step: 9
Training loss: 2.137586901944971
Validation loss: 2.6265481970021476

Epoch: 5| Step: 10
Training loss: 1.9732648156273331
Validation loss: 2.610338748815283

Epoch: 5| Step: 11
Training loss: 2.2014803327573875
Validation loss: 2.625055403351804

Epoch: 363| Step: 0
Training loss: 2.3765000073645406
Validation loss: 2.6098684807473735

Epoch: 5| Step: 1
Training loss: 1.6941242184679042
Validation loss: 2.605523745115105

Epoch: 5| Step: 2
Training loss: 2.012339435119292
Validation loss: 2.610902514281327

Epoch: 5| Step: 3
Training loss: 1.6631873610028676
Validation loss: 2.5860590680484794

Epoch: 5| Step: 4
Training loss: 1.6708891626989082
Validation loss: 2.579406296583541

Epoch: 5| Step: 5
Training loss: 1.977935796430467
Validation loss: 2.5615986463835156

Epoch: 5| Step: 6
Training loss: 1.8074345674186598
Validation loss: 2.5821999799160666

Epoch: 5| Step: 7
Training loss: 2.211817050852731
Validation loss: 2.5605697417432385

Epoch: 5| Step: 8
Training loss: 1.9279950708666589
Validation loss: 2.5514331391607215

Epoch: 5| Step: 9
Training loss: 2.2987535540753967
Validation loss: 2.552597583159559

Epoch: 5| Step: 10
Training loss: 1.5734407002512143
Validation loss: 2.548827283135637

Epoch: 5| Step: 11
Training loss: 3.5432807086853835
Validation loss: 2.566760475644851

Epoch: 364| Step: 0
Training loss: 1.4459255258737536
Validation loss: 2.5687127821454445

Epoch: 5| Step: 1
Training loss: 1.9685588320001453
Validation loss: 2.599001287183092

Epoch: 5| Step: 2
Training loss: 2.1426387698302616
Validation loss: 2.608014625866664

Epoch: 5| Step: 3
Training loss: 2.2145649298844945
Validation loss: 2.6203926899877015

Epoch: 5| Step: 4
Training loss: 1.6231355241236762
Validation loss: 2.644757965902851

Epoch: 5| Step: 5
Training loss: 2.500304012887303
Validation loss: 2.62786375615391

Epoch: 5| Step: 6
Training loss: 2.21378878541698
Validation loss: 2.644103980659324

Epoch: 5| Step: 7
Training loss: 1.7499752042921086
Validation loss: 2.599288622573686

Epoch: 5| Step: 8
Training loss: 2.035965712755105
Validation loss: 2.5740841920577826

Epoch: 5| Step: 9
Training loss: 1.603439347826098
Validation loss: 2.5682276741559353

Epoch: 5| Step: 10
Training loss: 2.011403357216942
Validation loss: 2.5589749583695736

Epoch: 5| Step: 11
Training loss: 1.8251025654438295
Validation loss: 2.5687754788337878

Epoch: 365| Step: 0
Training loss: 2.334990650787261
Validation loss: 2.603339240549381

Epoch: 5| Step: 1
Training loss: 1.9534950821255403
Validation loss: 2.5742753658909003

Epoch: 5| Step: 2
Training loss: 1.8829884427121621
Validation loss: 2.578073763097391

Epoch: 5| Step: 3
Training loss: 2.1459891500349837
Validation loss: 2.574774998954726

Epoch: 5| Step: 4
Training loss: 1.6692628508172127
Validation loss: 2.562419223287599

Epoch: 5| Step: 5
Training loss: 1.8846212855595499
Validation loss: 2.595970034839524

Epoch: 5| Step: 6
Training loss: 1.661603588423438
Validation loss: 2.5932928241599322

Epoch: 5| Step: 7
Training loss: 2.46199395648949
Validation loss: 2.641128894498581

Epoch: 5| Step: 8
Training loss: 1.6528218616978503
Validation loss: 2.6450226748347285

Epoch: 5| Step: 9
Training loss: 1.6987513809254629
Validation loss: 2.6130799737271984

Epoch: 5| Step: 10
Training loss: 1.9398715364061583
Validation loss: 2.613401838788599

Epoch: 5| Step: 11
Training loss: 1.6729531777824775
Validation loss: 2.6021409102932314

Epoch: 366| Step: 0
Training loss: 2.0872311813048947
Validation loss: 2.6242481699069797

Epoch: 5| Step: 1
Training loss: 2.084443889892132
Validation loss: 2.642155186993013

Epoch: 5| Step: 2
Training loss: 1.5011100635215882
Validation loss: 2.65152537586462

Epoch: 5| Step: 3
Training loss: 1.8644684342371811
Validation loss: 2.6387659146003517

Epoch: 5| Step: 4
Training loss: 2.4721370591867062
Validation loss: 2.6345574457200955

Epoch: 5| Step: 5
Training loss: 2.356492055910716
Validation loss: 2.6171395216762128

Epoch: 5| Step: 6
Training loss: 1.596124861792577
Validation loss: 2.6073969179023453

Epoch: 5| Step: 7
Training loss: 1.9089417760571485
Validation loss: 2.6200732780660663

Epoch: 5| Step: 8
Training loss: 1.4208976824257014
Validation loss: 2.6243072344940117

Epoch: 5| Step: 9
Training loss: 1.892220194602642
Validation loss: 2.5896140562973007

Epoch: 5| Step: 10
Training loss: 1.8097200450101794
Validation loss: 2.593319121730848

Epoch: 5| Step: 11
Training loss: 1.7662222198223845
Validation loss: 2.6094430126532053

Epoch: 367| Step: 0
Training loss: 1.5395351400648531
Validation loss: 2.622212648228321

Epoch: 5| Step: 1
Training loss: 1.4715738948268249
Validation loss: 2.6515351955886484

Epoch: 5| Step: 2
Training loss: 1.517036488616602
Validation loss: 2.622250134620126

Epoch: 5| Step: 3
Training loss: 1.9223764897271334
Validation loss: 2.6309220330872325

Epoch: 5| Step: 4
Training loss: 2.766566660425584
Validation loss: 2.6144494988787597

Epoch: 5| Step: 5
Training loss: 1.9333535401614685
Validation loss: 2.6080896672539224

Epoch: 5| Step: 6
Training loss: 2.22462512940948
Validation loss: 2.62419666759107

Epoch: 5| Step: 7
Training loss: 1.985558825030437
Validation loss: 2.6222247409157413

Epoch: 5| Step: 8
Training loss: 1.8893098276439875
Validation loss: 2.5876220909283996

Epoch: 5| Step: 9
Training loss: 2.0943105146634378
Validation loss: 2.5990260974762154

Epoch: 5| Step: 10
Training loss: 2.224224161048366
Validation loss: 2.6027832985431205

Epoch: 5| Step: 11
Training loss: 3.313701771515052
Validation loss: 2.6160330812212536

Epoch: 368| Step: 0
Training loss: 2.4066140035783135
Validation loss: 2.6396040626340174

Epoch: 5| Step: 1
Training loss: 1.4774875871424138
Validation loss: 2.672153766954346

Epoch: 5| Step: 2
Training loss: 1.4641865387669688
Validation loss: 2.6405362597721216

Epoch: 5| Step: 3
Training loss: 2.515815111641624
Validation loss: 2.669500757254811

Epoch: 5| Step: 4
Training loss: 1.9099566583559155
Validation loss: 2.684486744027374

Epoch: 5| Step: 5
Training loss: 1.6288248677586863
Validation loss: 2.754614502214935

Epoch: 5| Step: 6
Training loss: 1.7893048917658
Validation loss: 2.741191103358054

Epoch: 5| Step: 7
Training loss: 1.735123206609334
Validation loss: 2.7008914392791112

Epoch: 5| Step: 8
Training loss: 1.6553466780671693
Validation loss: 2.6450341862570714

Epoch: 5| Step: 9
Training loss: 2.151222227583364
Validation loss: 2.673282553699061

Epoch: 5| Step: 10
Training loss: 2.54407632969962
Validation loss: 2.590658425091327

Epoch: 5| Step: 11
Training loss: 1.479817994757268
Validation loss: 2.59293464116405

Epoch: 369| Step: 0
Training loss: 2.39618211501808
Validation loss: 2.588277727841062

Epoch: 5| Step: 1
Training loss: 1.36388469118317
Validation loss: 2.58471480214824

Epoch: 5| Step: 2
Training loss: 2.0186080741005004
Validation loss: 2.5829728333881663

Epoch: 5| Step: 3
Training loss: 1.8786312544422432
Validation loss: 2.5885294115069373

Epoch: 5| Step: 4
Training loss: 2.574364711576992
Validation loss: 2.579591095338174

Epoch: 5| Step: 5
Training loss: 1.935422337102505
Validation loss: 2.582544772993115

Epoch: 5| Step: 6
Training loss: 1.5674170374475984
Validation loss: 2.562219365965478

Epoch: 5| Step: 7
Training loss: 1.8705678053300174
Validation loss: 2.562255281687891

Epoch: 5| Step: 8
Training loss: 2.2650366709858463
Validation loss: 2.609265471727593

Epoch: 5| Step: 9
Training loss: 2.2210112318556177
Validation loss: 2.5895866872520754

Epoch: 5| Step: 10
Training loss: 2.0342445015253414
Validation loss: 2.5933168846281283

Epoch: 5| Step: 11
Training loss: 1.631820012031431
Validation loss: 2.6744210083063225

Epoch: 370| Step: 0
Training loss: 2.194075266316421
Validation loss: 2.653418977054513

Epoch: 5| Step: 1
Training loss: 1.779914288225235
Validation loss: 2.6400774777487563

Epoch: 5| Step: 2
Training loss: 1.4920056616749866
Validation loss: 2.6426323516011094

Epoch: 5| Step: 3
Training loss: 1.7989144071581076
Validation loss: 2.6137996020749816

Epoch: 5| Step: 4
Training loss: 2.3269446536286646
Validation loss: 2.6194838247567365

Epoch: 5| Step: 5
Training loss: 1.7765582350492657
Validation loss: 2.6199905757334156

Epoch: 5| Step: 6
Training loss: 2.060298091098016
Validation loss: 2.6490797803797497

Epoch: 5| Step: 7
Training loss: 1.7517101923177456
Validation loss: 2.659808236472371

Epoch: 5| Step: 8
Training loss: 1.8593122968599542
Validation loss: 2.6468871088212618

Epoch: 5| Step: 9
Training loss: 1.7880658034519774
Validation loss: 2.6356763083578016

Epoch: 5| Step: 10
Training loss: 2.023531053655926
Validation loss: 2.6485576996210107

Epoch: 5| Step: 11
Training loss: 2.554306141798166
Validation loss: 2.6757095067414083

Epoch: 371| Step: 0
Training loss: 1.8696322218157464
Validation loss: 2.6369106458370513

Epoch: 5| Step: 1
Training loss: 1.8846921283840299
Validation loss: 2.71808641381329

Epoch: 5| Step: 2
Training loss: 1.7366981412460178
Validation loss: 2.7223349901173823

Epoch: 5| Step: 3
Training loss: 2.3943645674424205
Validation loss: 2.776596022335375

Epoch: 5| Step: 4
Training loss: 1.7994055137153788
Validation loss: 2.7473546583998343

Epoch: 5| Step: 5
Training loss: 2.0600697620393817
Validation loss: 2.70469262489731

Epoch: 5| Step: 6
Training loss: 2.0968995958412178
Validation loss: 2.5931002366029867

Epoch: 5| Step: 7
Training loss: 1.8734056688011382
Validation loss: 2.580795407848506

Epoch: 5| Step: 8
Training loss: 2.0292996947165203
Validation loss: 2.552390490102884

Epoch: 5| Step: 9
Training loss: 1.6173686787568509
Validation loss: 2.5893228619828164

Epoch: 5| Step: 10
Training loss: 2.2462463857784076
Validation loss: 2.609165442117286

Epoch: 5| Step: 11
Training loss: 0.9118663129072437
Validation loss: 2.6063651240145562

Epoch: 372| Step: 0
Training loss: 1.8124617210818448
Validation loss: 2.635010858938051

Epoch: 5| Step: 1
Training loss: 2.5793091799835213
Validation loss: 2.616433132637605

Epoch: 5| Step: 2
Training loss: 2.2873482909210594
Validation loss: 2.59542051776064

Epoch: 5| Step: 3
Training loss: 2.30945014882963
Validation loss: 2.609681996543105

Epoch: 5| Step: 4
Training loss: 2.1157950576659594
Validation loss: 2.630558452657196

Epoch: 5| Step: 5
Training loss: 2.3129054564644904
Validation loss: 2.6299459773487532

Epoch: 5| Step: 6
Training loss: 1.5709880685189284
Validation loss: 2.6280151016868585

Epoch: 5| Step: 7
Training loss: 1.4931626254387296
Validation loss: 2.60452679369258

Epoch: 5| Step: 8
Training loss: 1.6170688161744684
Validation loss: 2.6147036936338157

Epoch: 5| Step: 9
Training loss: 1.721600336506254
Validation loss: 2.588148261147427

Epoch: 5| Step: 10
Training loss: 1.7861815331740232
Validation loss: 2.5974038061174247

Epoch: 5| Step: 11
Training loss: 1.0815285296369677
Validation loss: 2.6172582341594586

Epoch: 373| Step: 0
Training loss: 2.09226299260796
Validation loss: 2.585037186125803

Epoch: 5| Step: 1
Training loss: 1.8575336089758192
Validation loss: 2.652545121666348

Epoch: 5| Step: 2
Training loss: 1.8471386045239024
Validation loss: 2.6838919128294423

Epoch: 5| Step: 3
Training loss: 1.9900848661949577
Validation loss: 2.686237478527331

Epoch: 5| Step: 4
Training loss: 1.9280679678867376
Validation loss: 2.627682681213402

Epoch: 5| Step: 5
Training loss: 1.5349495241396358
Validation loss: 2.602451042895989

Epoch: 5| Step: 6
Training loss: 1.6410386790122908
Validation loss: 2.608774889010974

Epoch: 5| Step: 7
Training loss: 1.79954125333594
Validation loss: 2.589009031067115

Epoch: 5| Step: 8
Training loss: 1.9798667338827498
Validation loss: 2.5744657730802674

Epoch: 5| Step: 9
Training loss: 1.5489902868440404
Validation loss: 2.5769428779753363

Epoch: 5| Step: 10
Training loss: 2.562295579897727
Validation loss: 2.5565710211270165

Epoch: 5| Step: 11
Training loss: 2.9725025753847456
Validation loss: 2.563229511284889

Epoch: 374| Step: 0
Training loss: 1.675566332713837
Validation loss: 2.5336312251143056

Epoch: 5| Step: 1
Training loss: 2.2562973059769815
Validation loss: 2.5343119327680284

Epoch: 5| Step: 2
Training loss: 1.7738498426837144
Validation loss: 2.5602129716810715

Epoch: 5| Step: 3
Training loss: 2.3180024949752376
Validation loss: 2.5815876181916315

Epoch: 5| Step: 4
Training loss: 2.2536571239391083
Validation loss: 2.6097996303408117

Epoch: 5| Step: 5
Training loss: 1.6534159182616412
Validation loss: 2.543410025113615

Epoch: 5| Step: 6
Training loss: 1.6755878185684525
Validation loss: 2.6042569577141035

Epoch: 5| Step: 7
Training loss: 2.1265838554705865
Validation loss: 2.599644921277351

Epoch: 5| Step: 8
Training loss: 0.9756074431438476
Validation loss: 2.5831947763776197

Epoch: 5| Step: 9
Training loss: 1.8763143383281544
Validation loss: 2.617990364934882

Epoch: 5| Step: 10
Training loss: 2.0719265386232726
Validation loss: 2.5760236402951144

Epoch: 5| Step: 11
Training loss: 1.5671553877547997
Validation loss: 2.589043180416255

Epoch: 375| Step: 0
Training loss: 2.066397250467761
Validation loss: 2.5772363537624376

Epoch: 5| Step: 1
Training loss: 1.9650372207067268
Validation loss: 2.5841262520852095

Epoch: 5| Step: 2
Training loss: 1.7906172880369486
Validation loss: 2.5813800396464206

Epoch: 5| Step: 3
Training loss: 2.1136183267161255
Validation loss: 2.594496186863843

Epoch: 5| Step: 4
Training loss: 2.281201087740833
Validation loss: 2.576059855237385

Epoch: 5| Step: 5
Training loss: 1.1519393987345574
Validation loss: 2.592768812923773

Epoch: 5| Step: 6
Training loss: 2.344049358323453
Validation loss: 2.5678021424794806

Epoch: 5| Step: 7
Training loss: 1.7250781691158046
Validation loss: 2.591464843792934

Epoch: 5| Step: 8
Training loss: 1.9449947970990018
Validation loss: 2.58987183936811

Epoch: 5| Step: 9
Training loss: 1.7354176454514594
Validation loss: 2.6003713964555804

Epoch: 5| Step: 10
Training loss: 1.6347366020515839
Validation loss: 2.6260761068573117

Epoch: 5| Step: 11
Training loss: 1.914860150482155
Validation loss: 2.6021632550022

Epoch: 376| Step: 0
Training loss: 2.365838601309284
Validation loss: 2.617923936618747

Epoch: 5| Step: 1
Training loss: 1.7134544636375226
Validation loss: 2.6325642613051197

Epoch: 5| Step: 2
Training loss: 1.4506740614694396
Validation loss: 2.5701716654030733

Epoch: 5| Step: 3
Training loss: 2.5952910475788773
Validation loss: 2.599037082577342

Epoch: 5| Step: 4
Training loss: 1.9412476994880952
Validation loss: 2.5835613155261226

Epoch: 5| Step: 5
Training loss: 1.5653682323060643
Validation loss: 2.5909181133761625

Epoch: 5| Step: 6
Training loss: 1.4659071660852463
Validation loss: 2.570105705715839

Epoch: 5| Step: 7
Training loss: 1.8085814242838973
Validation loss: 2.6125512445860073

Epoch: 5| Step: 8
Training loss: 2.004316202508035
Validation loss: 2.5985171772448616

Epoch: 5| Step: 9
Training loss: 1.539426576568888
Validation loss: 2.610381505251909

Epoch: 5| Step: 10
Training loss: 1.7541324325205074
Validation loss: 2.6006869044503715

Epoch: 5| Step: 11
Training loss: 1.9525622968711758
Validation loss: 2.5789478337555183

Epoch: 377| Step: 0
Training loss: 1.7052354248479868
Validation loss: 2.5708761785596033

Epoch: 5| Step: 1
Training loss: 1.672293779919857
Validation loss: 2.602951458003896

Epoch: 5| Step: 2
Training loss: 1.9757318372117258
Validation loss: 2.611358688050097

Epoch: 5| Step: 3
Training loss: 2.069769561398679
Validation loss: 2.5862043037575115

Epoch: 5| Step: 4
Training loss: 1.656382141599948
Validation loss: 2.6073942071063456

Epoch: 5| Step: 5
Training loss: 1.6366628851267422
Validation loss: 2.6165420077833694

Epoch: 5| Step: 6
Training loss: 1.5256641255088703
Validation loss: 2.6161598579344223

Epoch: 5| Step: 7
Training loss: 1.6485223974268943
Validation loss: 2.6108651084764274

Epoch: 5| Step: 8
Training loss: 1.9242173474051552
Validation loss: 2.6091609950832964

Epoch: 5| Step: 9
Training loss: 2.0839915825130166
Validation loss: 2.598111086537358

Epoch: 5| Step: 10
Training loss: 2.648665246764208
Validation loss: 2.6449029530723633

Epoch: 5| Step: 11
Training loss: 2.614203639532566
Validation loss: 2.6249232886473974

Epoch: 378| Step: 0
Training loss: 1.9558607549035851
Validation loss: 2.6331950059807174

Epoch: 5| Step: 1
Training loss: 1.8873296344998864
Validation loss: 2.667347416313875

Epoch: 5| Step: 2
Training loss: 1.566112614456856
Validation loss: 2.6464733015628763

Epoch: 5| Step: 3
Training loss: 1.9981604699502677
Validation loss: 2.6256796925699337

Epoch: 5| Step: 4
Training loss: 2.027869595520271
Validation loss: 2.610998280744402

Epoch: 5| Step: 5
Training loss: 2.181700293289335
Validation loss: 2.6154433060847633

Epoch: 5| Step: 6
Training loss: 1.652157026702168
Validation loss: 2.586864950506612

Epoch: 5| Step: 7
Training loss: 1.69307297129232
Validation loss: 2.6065122715588998

Epoch: 5| Step: 8
Training loss: 1.89165928820993
Validation loss: 2.584843664483877

Epoch: 5| Step: 9
Training loss: 1.8802780251166182
Validation loss: 2.5959857933150907

Epoch: 5| Step: 10
Training loss: 1.7524697723176177
Validation loss: 2.6316274679514815

Epoch: 5| Step: 11
Training loss: 1.555053054542322
Validation loss: 2.5887470675564965

Epoch: 379| Step: 0
Training loss: 2.065924604563468
Validation loss: 2.600228740032466

Epoch: 5| Step: 1
Training loss: 1.540315689080517
Validation loss: 2.6249466315399874

Epoch: 5| Step: 2
Training loss: 1.6390725192772
Validation loss: 2.597047746943807

Epoch: 5| Step: 3
Training loss: 1.9899984262929857
Validation loss: 2.6217769484738067

Epoch: 5| Step: 4
Training loss: 1.3821594506595194
Validation loss: 2.6114791563948914

Epoch: 5| Step: 5
Training loss: 1.6095780920380647
Validation loss: 2.6019334499988

Epoch: 5| Step: 6
Training loss: 2.137187118385215
Validation loss: 2.6289418422638113

Epoch: 5| Step: 7
Training loss: 2.0590219938966405
Validation loss: 2.6794065693362183

Epoch: 5| Step: 8
Training loss: 2.139526085117095
Validation loss: 2.7057217122704356

Epoch: 5| Step: 9
Training loss: 1.6854838583825968
Validation loss: 2.7768434412815215

Epoch: 5| Step: 10
Training loss: 2.20218871221486
Validation loss: 2.7244793094048414

Epoch: 5| Step: 11
Training loss: 2.3626306568326476
Validation loss: 2.7262278062656624

Epoch: 380| Step: 0
Training loss: 1.2799374439927398
Validation loss: 2.6777912433427717

Epoch: 5| Step: 1
Training loss: 2.0940036904667756
Validation loss: 2.6077468993337627

Epoch: 5| Step: 2
Training loss: 2.296100304157135
Validation loss: 2.6459472993400652

Epoch: 5| Step: 3
Training loss: 2.1468748756197655
Validation loss: 2.6237390797354325

Epoch: 5| Step: 4
Training loss: 2.0730719835634375
Validation loss: 2.597096578400125

Epoch: 5| Step: 5
Training loss: 2.0477924183757796
Validation loss: 2.5875880648727265

Epoch: 5| Step: 6
Training loss: 1.3650435285649372
Validation loss: 2.622428069284323

Epoch: 5| Step: 7
Training loss: 2.3612937956303166
Validation loss: 2.601170851178361

Epoch: 5| Step: 8
Training loss: 2.0766194561796083
Validation loss: 2.6116037083076495

Epoch: 5| Step: 9
Training loss: 1.6805274460108215
Validation loss: 2.6191919308956115

Epoch: 5| Step: 10
Training loss: 1.746895761656518
Validation loss: 2.628438230574972

Epoch: 5| Step: 11
Training loss: 1.0691889971103088
Validation loss: 2.6427543188556655

Epoch: 381| Step: 0
Training loss: 2.2431606613219754
Validation loss: 2.6597107538972575

Epoch: 5| Step: 1
Training loss: 1.7720932760467236
Validation loss: 2.7003918024994307

Epoch: 5| Step: 2
Training loss: 2.173943282621957
Validation loss: 2.693723953132943

Epoch: 5| Step: 3
Training loss: 1.7835644191981992
Validation loss: 2.66753651295144

Epoch: 5| Step: 4
Training loss: 1.6497515462448151
Validation loss: 2.677290223188315

Epoch: 5| Step: 5
Training loss: 1.5398922150531587
Validation loss: 2.6220615872238535

Epoch: 5| Step: 6
Training loss: 1.8372787446179213
Validation loss: 2.615424854121313

Epoch: 5| Step: 7
Training loss: 1.857357822280503
Validation loss: 2.581498033769711

Epoch: 5| Step: 8
Training loss: 1.911001006948065
Validation loss: 2.599130805694535

Epoch: 5| Step: 9
Training loss: 1.759147848910771
Validation loss: 2.530922095327287

Epoch: 5| Step: 10
Training loss: 2.386765100306892
Validation loss: 2.548650076190339

Epoch: 5| Step: 11
Training loss: 0.7290324405469293
Validation loss: 2.587890870676089

Epoch: 382| Step: 0
Training loss: 1.9182200218671137
Validation loss: 2.5526756546438945

Epoch: 5| Step: 1
Training loss: 1.911743877262903
Validation loss: 2.567254184283253

Epoch: 5| Step: 2
Training loss: 1.9774257900622332
Validation loss: 2.5599409832211517

Epoch: 5| Step: 3
Training loss: 2.0750385970237235
Validation loss: 2.604807989624677

Epoch: 5| Step: 4
Training loss: 1.950579090207611
Validation loss: 2.6216998321010108

Epoch: 5| Step: 5
Training loss: 1.4516410223312248
Validation loss: 2.647755166437819

Epoch: 5| Step: 6
Training loss: 2.079355434902413
Validation loss: 2.7035292431575138

Epoch: 5| Step: 7
Training loss: 1.657883108866299
Validation loss: 2.712469695840484

Epoch: 5| Step: 8
Training loss: 1.6644609001244857
Validation loss: 2.6517016532978728

Epoch: 5| Step: 9
Training loss: 2.351700585452094
Validation loss: 2.6150224337214247

Epoch: 5| Step: 10
Training loss: 1.4389243325704382
Validation loss: 2.601663310681935

Epoch: 5| Step: 11
Training loss: 1.1988959359449092
Validation loss: 2.579638790022713

Epoch: 383| Step: 0
Training loss: 1.6469078741104144
Validation loss: 2.601195770625953

Epoch: 5| Step: 1
Training loss: 1.7348063164594028
Validation loss: 2.6267212757151928

Epoch: 5| Step: 2
Training loss: 2.2470128044982522
Validation loss: 2.6299885283426656

Epoch: 5| Step: 3
Training loss: 2.028343821331023
Validation loss: 2.6384893919450976

Epoch: 5| Step: 4
Training loss: 2.0929488741794913
Validation loss: 2.6346349511757756

Epoch: 5| Step: 5
Training loss: 2.2272195482363526
Validation loss: 2.65354139380164

Epoch: 5| Step: 6
Training loss: 1.8313696343724322
Validation loss: 2.6120442844741176

Epoch: 5| Step: 7
Training loss: 1.7313317069593293
Validation loss: 2.6627378144117166

Epoch: 5| Step: 8
Training loss: 1.186560911991804
Validation loss: 2.631616428258909

Epoch: 5| Step: 9
Training loss: 1.9101848951192841
Validation loss: 2.6454662433792864

Epoch: 5| Step: 10
Training loss: 1.8273040362703326
Validation loss: 2.6595780747453435

Epoch: 5| Step: 11
Training loss: 2.3346379470315055
Validation loss: 2.6423695010367987

Epoch: 384| Step: 0
Training loss: 1.7616950665761872
Validation loss: 2.7041717038942825

Epoch: 5| Step: 1
Training loss: 2.55988997610411
Validation loss: 2.7999424052843107

Epoch: 5| Step: 2
Training loss: 1.6341102225155542
Validation loss: 2.770080440216269

Epoch: 5| Step: 3
Training loss: 1.4540515529827989
Validation loss: 2.6796890421900934

Epoch: 5| Step: 4
Training loss: 1.8315391286241733
Validation loss: 2.6189389948901827

Epoch: 5| Step: 5
Training loss: 1.9721346628276721
Validation loss: 2.6169917170993955

Epoch: 5| Step: 6
Training loss: 2.2766169701882166
Validation loss: 2.5908640006961874

Epoch: 5| Step: 7
Training loss: 2.0056777470714624
Validation loss: 2.614165862951458

Epoch: 5| Step: 8
Training loss: 1.3659463534900604
Validation loss: 2.613012508150712

Epoch: 5| Step: 9
Training loss: 1.799324687798954
Validation loss: 2.6073453360954866

Epoch: 5| Step: 10
Training loss: 1.989271955107434
Validation loss: 2.568314890119694

Epoch: 5| Step: 11
Training loss: 1.118771637009391
Validation loss: 2.6272006195976196

Epoch: 385| Step: 0
Training loss: 2.063043233828015
Validation loss: 2.598693258238851

Epoch: 5| Step: 1
Training loss: 1.6449288003232647
Validation loss: 2.635359044758107

Epoch: 5| Step: 2
Training loss: 1.5257992947981696
Validation loss: 2.630715675649198

Epoch: 5| Step: 3
Training loss: 1.4148104043924745
Validation loss: 2.6102258128921787

Epoch: 5| Step: 4
Training loss: 2.412994741200907
Validation loss: 2.6223031867038338

Epoch: 5| Step: 5
Training loss: 1.6160833302626394
Validation loss: 2.624730300672434

Epoch: 5| Step: 6
Training loss: 1.1728310309271806
Validation loss: 2.6516348144645017

Epoch: 5| Step: 7
Training loss: 1.8686850699177342
Validation loss: 2.6216903060709034

Epoch: 5| Step: 8
Training loss: 1.8722941902030164
Validation loss: 2.6756391464331104

Epoch: 5| Step: 9
Training loss: 2.137954717086976
Validation loss: 2.654942961359693

Epoch: 5| Step: 10
Training loss: 1.927215722837559
Validation loss: 2.67705322253639

Epoch: 5| Step: 11
Training loss: 3.0749355774620697
Validation loss: 2.66062549293256

Epoch: 386| Step: 0
Training loss: 1.4557067741987464
Validation loss: 2.6657929864314314

Epoch: 5| Step: 1
Training loss: 1.634161141227525
Validation loss: 2.694605309779352

Epoch: 5| Step: 2
Training loss: 1.8021645353099982
Validation loss: 2.645159588033387

Epoch: 5| Step: 3
Training loss: 1.1217896431671808
Validation loss: 2.6224127272990145

Epoch: 5| Step: 4
Training loss: 1.8561731547366453
Validation loss: 2.600673363219177

Epoch: 5| Step: 5
Training loss: 2.1501556739337873
Validation loss: 2.574118155413076

Epoch: 5| Step: 6
Training loss: 1.7443769578912478
Validation loss: 2.5933242969388193

Epoch: 5| Step: 7
Training loss: 1.7390765139005706
Validation loss: 2.549055628653297

Epoch: 5| Step: 8
Training loss: 2.155701719596111
Validation loss: 2.5812184126355207

Epoch: 5| Step: 9
Training loss: 1.8460641336345667
Validation loss: 2.5779568704055906

Epoch: 5| Step: 10
Training loss: 2.1981498871740195
Validation loss: 2.603143778500824

Epoch: 5| Step: 11
Training loss: 3.395324684539012
Validation loss: 2.585799541039497

Epoch: 387| Step: 0
Training loss: 1.650696205876802
Validation loss: 2.6040194673262214

Epoch: 5| Step: 1
Training loss: 1.627521758981505
Validation loss: 2.6430647299344434

Epoch: 5| Step: 2
Training loss: 2.1718455799772234
Validation loss: 2.7147645678053367

Epoch: 5| Step: 3
Training loss: 2.0018166397834656
Validation loss: 2.7612460108150128

Epoch: 5| Step: 4
Training loss: 1.731450889307326
Validation loss: 2.8638578062552718

Epoch: 5| Step: 5
Training loss: 2.305208619248869
Validation loss: 2.8907051453348314

Epoch: 5| Step: 6
Training loss: 1.8167875812549528
Validation loss: 2.8300136631657153

Epoch: 5| Step: 7
Training loss: 2.1921237580106125
Validation loss: 2.8012655487661706

Epoch: 5| Step: 8
Training loss: 1.7847535328112059
Validation loss: 2.696125608153004

Epoch: 5| Step: 9
Training loss: 2.208864136247384
Validation loss: 2.572359269237512

Epoch: 5| Step: 10
Training loss: 1.7580238045739685
Validation loss: 2.544065005756458

Epoch: 5| Step: 11
Training loss: 2.227108965286997
Validation loss: 2.5542052588625075

Epoch: 388| Step: 0
Training loss: 1.7848026918839792
Validation loss: 2.57347466071976

Epoch: 5| Step: 1
Training loss: 1.433981445442518
Validation loss: 2.5726262223381196

Epoch: 5| Step: 2
Training loss: 2.3448505106699056
Validation loss: 2.595105426021247

Epoch: 5| Step: 3
Training loss: 1.480156535943204
Validation loss: 2.5671705659078348

Epoch: 5| Step: 4
Training loss: 2.308410947116878
Validation loss: 2.641998137146367

Epoch: 5| Step: 5
Training loss: 2.609750503658389
Validation loss: 2.6531632046594162

Epoch: 5| Step: 6
Training loss: 1.7193931763331989
Validation loss: 2.6893832535395066

Epoch: 5| Step: 7
Training loss: 2.0197076185529723
Validation loss: 2.6719570072966374

Epoch: 5| Step: 8
Training loss: 1.7896654204200066
Validation loss: 2.677705207663999

Epoch: 5| Step: 9
Training loss: 1.8646861923517495
Validation loss: 2.693006087072826

Epoch: 5| Step: 10
Training loss: 1.9092378807467445
Validation loss: 2.622750684765038

Epoch: 5| Step: 11
Training loss: 2.2714561401606645
Validation loss: 2.636763599155607

Epoch: 389| Step: 0
Training loss: 1.697135402306188
Validation loss: 2.5943441955133237

Epoch: 5| Step: 1
Training loss: 1.435912624139508
Validation loss: 2.5881460157368865

Epoch: 5| Step: 2
Training loss: 1.150764754229563
Validation loss: 2.5477163918157926

Epoch: 5| Step: 3
Training loss: 2.001733386378011
Validation loss: 2.553625055039644

Epoch: 5| Step: 4
Training loss: 1.7840213298206742
Validation loss: 2.5369826342196737

Epoch: 5| Step: 5
Training loss: 1.905864614083481
Validation loss: 2.534456592442715

Epoch: 5| Step: 6
Training loss: 2.1529779347991314
Validation loss: 2.56990695447872

Epoch: 5| Step: 7
Training loss: 2.1224028479961405
Validation loss: 2.5869585654785854

Epoch: 5| Step: 8
Training loss: 1.9567487745046037
Validation loss: 2.619386032331264

Epoch: 5| Step: 9
Training loss: 1.7345398145841697
Validation loss: 2.6075738412527167

Epoch: 5| Step: 10
Training loss: 2.186744232410864
Validation loss: 2.5617629828884914

Epoch: 5| Step: 11
Training loss: 3.3350179865636593
Validation loss: 2.56234068879298

Epoch: 390| Step: 0
Training loss: 1.9806246423405005
Validation loss: 2.61623713000966

Epoch: 5| Step: 1
Training loss: 1.8584587339962104
Validation loss: 2.632192321692011

Epoch: 5| Step: 2
Training loss: 2.1092261367827887
Validation loss: 2.6050168417119544

Epoch: 5| Step: 3
Training loss: 1.6418631105315586
Validation loss: 2.6118260291490367

Epoch: 5| Step: 4
Training loss: 1.772231780232027
Validation loss: 2.6110696486355525

Epoch: 5| Step: 5
Training loss: 2.1040471360906134
Validation loss: 2.5980639986192657

Epoch: 5| Step: 6
Training loss: 1.6067366964793437
Validation loss: 2.5917750733528693

Epoch: 5| Step: 7
Training loss: 1.7337677038453614
Validation loss: 2.600187742197948

Epoch: 5| Step: 8
Training loss: 1.9172239391840347
Validation loss: 2.586628490222399

Epoch: 5| Step: 9
Training loss: 1.6404132524719184
Validation loss: 2.5883243950601256

Epoch: 5| Step: 10
Training loss: 1.5763626077770019
Validation loss: 2.5600594280405753

Epoch: 5| Step: 11
Training loss: 3.5282551716931683
Validation loss: 2.5691428262365608

Epoch: 391| Step: 0
Training loss: 1.9267788483234602
Validation loss: 2.6047369535984544

Epoch: 5| Step: 1
Training loss: 1.8373855399469121
Validation loss: 2.6291744403351385

Epoch: 5| Step: 2
Training loss: 1.2808544199557728
Validation loss: 2.6028441097083417

Epoch: 5| Step: 3
Training loss: 1.7046694271203044
Validation loss: 2.617889192564411

Epoch: 5| Step: 4
Training loss: 2.237886989948119
Validation loss: 2.6497576038894413

Epoch: 5| Step: 5
Training loss: 1.9084333829459004
Validation loss: 2.6342514211223578

Epoch: 5| Step: 6
Training loss: 1.7602385331116144
Validation loss: 2.61804563962867

Epoch: 5| Step: 7
Training loss: 1.6408512504429895
Validation loss: 2.6408655670255627

Epoch: 5| Step: 8
Training loss: 2.2795584691157695
Validation loss: 2.5951261814459508

Epoch: 5| Step: 9
Training loss: 1.7822216127927841
Validation loss: 2.6270923752494255

Epoch: 5| Step: 10
Training loss: 1.6406725195406098
Validation loss: 2.6245482298211336

Epoch: 5| Step: 11
Training loss: 1.2832630439599226
Validation loss: 2.6183114366649787

Epoch: 392| Step: 0
Training loss: 1.5403571710437767
Validation loss: 2.547512243857268

Epoch: 5| Step: 1
Training loss: 1.5540879210021659
Validation loss: 2.6064381052038814

Epoch: 5| Step: 2
Training loss: 2.226506711026676
Validation loss: 2.5992245521859023

Epoch: 5| Step: 3
Training loss: 1.4845197908155756
Validation loss: 2.607604471163801

Epoch: 5| Step: 4
Training loss: 1.5191161856300246
Validation loss: 2.606283149233985

Epoch: 5| Step: 5
Training loss: 1.805352687035129
Validation loss: 2.594712676218223

Epoch: 5| Step: 6
Training loss: 1.6590224040509352
Validation loss: 2.62001388294968

Epoch: 5| Step: 7
Training loss: 1.9830798630938198
Validation loss: 2.62155572540903

Epoch: 5| Step: 8
Training loss: 2.4013241969197243
Validation loss: 2.6677624765601924

Epoch: 5| Step: 9
Training loss: 1.6209605702305994
Validation loss: 2.6604772963121204

Epoch: 5| Step: 10
Training loss: 2.10920409463897
Validation loss: 2.707124390130527

Epoch: 5| Step: 11
Training loss: 0.499077721198229
Validation loss: 2.6946095605009064

Epoch: 393| Step: 0
Training loss: 1.8768594422713414
Validation loss: 2.7186284494815607

Epoch: 5| Step: 1
Training loss: 1.7569364950463442
Validation loss: 2.6903409432084695

Epoch: 5| Step: 2
Training loss: 1.796819669452121
Validation loss: 2.6749571447712697

Epoch: 5| Step: 3
Training loss: 1.4951082574439387
Validation loss: 2.637161933481779

Epoch: 5| Step: 4
Training loss: 1.5775367471371673
Validation loss: 2.6526926903840278

Epoch: 5| Step: 5
Training loss: 1.8781001846273575
Validation loss: 2.598598104878543

Epoch: 5| Step: 6
Training loss: 1.9637849962210876
Validation loss: 2.6308132281807444

Epoch: 5| Step: 7
Training loss: 1.4329092278065128
Validation loss: 2.60832615291249

Epoch: 5| Step: 8
Training loss: 1.4738542050446037
Validation loss: 2.6009357946193887

Epoch: 5| Step: 9
Training loss: 2.9598733001089346
Validation loss: 2.6330360483712236

Epoch: 5| Step: 10
Training loss: 1.7614276924679158
Validation loss: 2.59632621120043

Epoch: 5| Step: 11
Training loss: 2.134431776238297
Validation loss: 2.5608280084775794

Epoch: 394| Step: 0
Training loss: 2.0228711370287344
Validation loss: 2.5952351695832094

Epoch: 5| Step: 1
Training loss: 1.9800807113766028
Validation loss: 2.582689487045621

Epoch: 5| Step: 2
Training loss: 1.9833532992194145
Validation loss: 2.5912761112350693

Epoch: 5| Step: 3
Training loss: 2.1429578780156793
Validation loss: 2.5767271895680337

Epoch: 5| Step: 4
Training loss: 1.647394220779728
Validation loss: 2.593255620207164

Epoch: 5| Step: 5
Training loss: 1.948402126697812
Validation loss: 2.6271745968928295

Epoch: 5| Step: 6
Training loss: 1.375570612330107
Validation loss: 2.620305317501323

Epoch: 5| Step: 7
Training loss: 1.8151492127384472
Validation loss: 2.645998962104192

Epoch: 5| Step: 8
Training loss: 1.2136315679471656
Validation loss: 2.7078003591245854

Epoch: 5| Step: 9
Training loss: 2.1295701417891943
Validation loss: 2.737830164346966

Epoch: 5| Step: 10
Training loss: 2.0229336026468525
Validation loss: 2.721224623278361

Epoch: 5| Step: 11
Training loss: 1.8286332948045312
Validation loss: 2.672907148439899

Epoch: 395| Step: 0
Training loss: 1.3381110016804654
Validation loss: 2.694289742258469

Epoch: 5| Step: 1
Training loss: 2.0545389680153914
Validation loss: 2.629069383235028

Epoch: 5| Step: 2
Training loss: 1.3992104977908044
Validation loss: 2.660769029302846

Epoch: 5| Step: 3
Training loss: 1.748548587000743
Validation loss: 2.61712544685551

Epoch: 5| Step: 4
Training loss: 1.8034455621010677
Validation loss: 2.601165349772359

Epoch: 5| Step: 5
Training loss: 1.7869835647740875
Validation loss: 2.613907465771335

Epoch: 5| Step: 6
Training loss: 1.9101244215858613
Validation loss: 2.6207235485142886

Epoch: 5| Step: 7
Training loss: 1.5466506487055296
Validation loss: 2.599042154666474

Epoch: 5| Step: 8
Training loss: 1.6915742645333787
Validation loss: 2.60597380814451

Epoch: 5| Step: 9
Training loss: 1.6676487492868288
Validation loss: 2.6054718993633554

Epoch: 5| Step: 10
Training loss: 2.1471433868784633
Validation loss: 2.6072868131215703

Epoch: 5| Step: 11
Training loss: 3.4528952129426838
Validation loss: 2.6187588202207333

Epoch: 396| Step: 0
Training loss: 1.8636911769004127
Validation loss: 2.6346917883177077

Epoch: 5| Step: 1
Training loss: 1.425853069012025
Validation loss: 2.6665462911278537

Epoch: 5| Step: 2
Training loss: 2.5698670346192154
Validation loss: 2.6671551776008355

Epoch: 5| Step: 3
Training loss: 1.8256912333310005
Validation loss: 2.6764798294308343

Epoch: 5| Step: 4
Training loss: 1.7913869225398928
Validation loss: 2.70244043976244

Epoch: 5| Step: 5
Training loss: 1.775112889957911
Validation loss: 2.7170554393858826

Epoch: 5| Step: 6
Training loss: 1.5681258582382316
Validation loss: 2.669781014913226

Epoch: 5| Step: 7
Training loss: 1.6000513902994244
Validation loss: 2.695311770231729

Epoch: 5| Step: 8
Training loss: 1.6120948400782698
Validation loss: 2.6270808305862046

Epoch: 5| Step: 9
Training loss: 1.276016105343936
Validation loss: 2.624951922264023

Epoch: 5| Step: 10
Training loss: 2.341434199332163
Validation loss: 2.606726869307033

Epoch: 5| Step: 11
Training loss: 3.1298808319514015
Validation loss: 2.5801766872711225

Epoch: 397| Step: 0
Training loss: 1.7516684072227553
Validation loss: 2.568414541988864

Epoch: 5| Step: 1
Training loss: 1.460526189175524
Validation loss: 2.5454770251438483

Epoch: 5| Step: 2
Training loss: 2.089534558392211
Validation loss: 2.591275547684952

Epoch: 5| Step: 3
Training loss: 1.586879131226122
Validation loss: 2.5738216763452906

Epoch: 5| Step: 4
Training loss: 1.5885385315243994
Validation loss: 2.6113354557517456

Epoch: 5| Step: 5
Training loss: 2.2500690873453526
Validation loss: 2.6583884438768353

Epoch: 5| Step: 6
Training loss: 2.1075614762757784
Validation loss: 2.7010837190245067

Epoch: 5| Step: 7
Training loss: 1.515594718080017
Validation loss: 2.686949784488613

Epoch: 5| Step: 8
Training loss: 1.2914656462167204
Validation loss: 2.661944807101174

Epoch: 5| Step: 9
Training loss: 1.771320373278609
Validation loss: 2.6305872930590244

Epoch: 5| Step: 10
Training loss: 2.206360301429511
Validation loss: 2.5998050607447873

Epoch: 5| Step: 11
Training loss: 2.773185181221572
Validation loss: 2.596520355757339

Epoch: 398| Step: 0
Training loss: 1.6751157065894422
Validation loss: 2.5973518594788367

Epoch: 5| Step: 1
Training loss: 1.5944394882839914
Validation loss: 2.565619579887163

Epoch: 5| Step: 2
Training loss: 2.0197190689908493
Validation loss: 2.5706534850359177

Epoch: 5| Step: 3
Training loss: 2.0430728455494873
Validation loss: 2.584839809737321

Epoch: 5| Step: 4
Training loss: 1.791363498262456
Validation loss: 2.5750877021310625

Epoch: 5| Step: 5
Training loss: 1.841654152058102
Validation loss: 2.543658591212846

Epoch: 5| Step: 6
Training loss: 1.7723689283970108
Validation loss: 2.5501086724567967

Epoch: 5| Step: 7
Training loss: 1.6285375822823764
Validation loss: 2.5543249458216932

Epoch: 5| Step: 8
Training loss: 1.7954180574385907
Validation loss: 2.592482061590745

Epoch: 5| Step: 9
Training loss: 1.563746298611024
Validation loss: 2.5896207963766016

Epoch: 5| Step: 10
Training loss: 1.8385436694716946
Validation loss: 2.600085781589668

Epoch: 5| Step: 11
Training loss: 2.1936604538598523
Validation loss: 2.623159531602423

Epoch: 399| Step: 0
Training loss: 1.8867671478571897
Validation loss: 2.6094774123327262

Epoch: 5| Step: 1
Training loss: 1.7813117033326682
Validation loss: 2.6063087897374744

Epoch: 5| Step: 2
Training loss: 1.6435261098878402
Validation loss: 2.612879267454164

Epoch: 5| Step: 3
Training loss: 1.5196938709625172
Validation loss: 2.599216556653251

Epoch: 5| Step: 4
Training loss: 2.181722586517141
Validation loss: 2.6027010048395893

Epoch: 5| Step: 5
Training loss: 1.8956026488865805
Validation loss: 2.5715643917288014

Epoch: 5| Step: 6
Training loss: 2.1649957840946725
Validation loss: 2.5607356611229815

Epoch: 5| Step: 7
Training loss: 1.1543524352771655
Validation loss: 2.5982794680914174

Epoch: 5| Step: 8
Training loss: 1.4231154511960233
Validation loss: 2.580373450180722

Epoch: 5| Step: 9
Training loss: 1.874270869584229
Validation loss: 2.6095206511272946

Epoch: 5| Step: 10
Training loss: 1.4030825653116363
Validation loss: 2.616025437056628

Epoch: 5| Step: 11
Training loss: 2.022428754534802
Validation loss: 2.5642538310404146

Epoch: 400| Step: 0
Training loss: 1.5604531423518324
Validation loss: 2.5765291765879224

Epoch: 5| Step: 1
Training loss: 1.726532258334203
Validation loss: 2.6101972765316277

Epoch: 5| Step: 2
Training loss: 1.7706799010582683
Validation loss: 2.607264245610834

Epoch: 5| Step: 3
Training loss: 1.8964709861903482
Validation loss: 2.6223666326165467

Epoch: 5| Step: 4
Training loss: 1.3266035003975947
Validation loss: 2.628459027034798

Epoch: 5| Step: 5
Training loss: 2.213118269575346
Validation loss: 2.5900588485667364

Epoch: 5| Step: 6
Training loss: 1.8993791670155733
Validation loss: 2.586791958584705

Epoch: 5| Step: 7
Training loss: 1.5383619079057549
Validation loss: 2.5803386086040123

Epoch: 5| Step: 8
Training loss: 2.407844411550629
Validation loss: 2.599008866750855

Epoch: 5| Step: 9
Training loss: 1.5707743710380824
Validation loss: 2.5779767581436057

Epoch: 5| Step: 10
Training loss: 1.1701260549342687
Validation loss: 2.600277244323673

Epoch: 5| Step: 11
Training loss: 1.1182457240240606
Validation loss: 2.6297519753753895

Epoch: 401| Step: 0
Training loss: 1.4894920890267647
Validation loss: 2.6875149001957856

Epoch: 5| Step: 1
Training loss: 2.137142383485775
Validation loss: 2.7072218240259276

Epoch: 5| Step: 2
Training loss: 1.4787453960434096
Validation loss: 2.702818461771148

Epoch: 5| Step: 3
Training loss: 1.8911582257883768
Validation loss: 2.6879328741356567

Epoch: 5| Step: 4
Training loss: 1.7715199055835942
Validation loss: 2.615006193539036

Epoch: 5| Step: 5
Training loss: 1.355667363547365
Validation loss: 2.6667126388362066

Epoch: 5| Step: 6
Training loss: 1.9232543089558163
Validation loss: 2.6428818021885614

Epoch: 5| Step: 7
Training loss: 2.6004232025512586
Validation loss: 2.661473982753145

Epoch: 5| Step: 8
Training loss: 1.8849383497401624
Validation loss: 2.6448810332921604

Epoch: 5| Step: 9
Training loss: 1.8919845610829442
Validation loss: 2.6482847239072624

Epoch: 5| Step: 10
Training loss: 1.6359057171056006
Validation loss: 2.6411495891512495

Epoch: 5| Step: 11
Training loss: 2.233141792206469
Validation loss: 2.616130983792892

Epoch: 402| Step: 0
Training loss: 2.071605811029575
Validation loss: 2.62538399234118

Epoch: 5| Step: 1
Training loss: 1.7740415645060899
Validation loss: 2.6057389770715558

Epoch: 5| Step: 2
Training loss: 1.4101854569641334
Validation loss: 2.6092047930882023

Epoch: 5| Step: 3
Training loss: 1.8590140753752342
Validation loss: 2.6056753035707167

Epoch: 5| Step: 4
Training loss: 1.8599976851336113
Validation loss: 2.586511891968273

Epoch: 5| Step: 5
Training loss: 1.9187460759523507
Validation loss: 2.5507312319935393

Epoch: 5| Step: 6
Training loss: 1.6058344737697023
Validation loss: 2.596041978504858

Epoch: 5| Step: 7
Training loss: 1.7602223471512122
Validation loss: 2.5964699122813917

Epoch: 5| Step: 8
Training loss: 1.499616812399138
Validation loss: 2.6201325391352137

Epoch: 5| Step: 9
Training loss: 2.069098580948502
Validation loss: 2.659061182215813

Epoch: 5| Step: 10
Training loss: 1.607018310020027
Validation loss: 2.6137655063243983

Epoch: 5| Step: 11
Training loss: 1.530190471062777
Validation loss: 2.6108601582834745

Epoch: 403| Step: 0
Training loss: 1.2011628437478066
Validation loss: 2.6176392502225987

Epoch: 5| Step: 1
Training loss: 1.845089571259471
Validation loss: 2.591975512812765

Epoch: 5| Step: 2
Training loss: 1.5986802380144594
Validation loss: 2.619358502190943

Epoch: 5| Step: 3
Training loss: 1.6582485592641887
Validation loss: 2.6167092147230955

Epoch: 5| Step: 4
Training loss: 2.0264168386236387
Validation loss: 2.623171729749487

Epoch: 5| Step: 5
Training loss: 1.8702407198511128
Validation loss: 2.618312616626492

Epoch: 5| Step: 6
Training loss: 1.9348633576479128
Validation loss: 2.614048725858776

Epoch: 5| Step: 7
Training loss: 2.082920020748683
Validation loss: 2.6207511514980606

Epoch: 5| Step: 8
Training loss: 1.4967554287548384
Validation loss: 2.6207738985338236

Epoch: 5| Step: 9
Training loss: 1.8555595295432676
Validation loss: 2.618075126324085

Epoch: 5| Step: 10
Training loss: 1.406029450817609
Validation loss: 2.623244303954121

Epoch: 5| Step: 11
Training loss: 2.6295375661101463
Validation loss: 2.6406063967017492

Epoch: 404| Step: 0
Training loss: 1.7444655232192006
Validation loss: 2.6256819475005417

Epoch: 5| Step: 1
Training loss: 1.9774520139020204
Validation loss: 2.677175291438842

Epoch: 5| Step: 2
Training loss: 1.9083488666396429
Validation loss: 2.7228778254553516

Epoch: 5| Step: 3
Training loss: 1.1833345740047632
Validation loss: 2.773913365046262

Epoch: 5| Step: 4
Training loss: 2.344329965678056
Validation loss: 2.6855531264723638

Epoch: 5| Step: 5
Training loss: 1.9127636297695387
Validation loss: 2.6444653343652043

Epoch: 5| Step: 6
Training loss: 1.4567656492273555
Validation loss: 2.5520411831755045

Epoch: 5| Step: 7
Training loss: 2.119402300592167
Validation loss: 2.554881163400873

Epoch: 5| Step: 8
Training loss: 1.6454539123219718
Validation loss: 2.558521811369395

Epoch: 5| Step: 9
Training loss: 1.3020510504217406
Validation loss: 2.6120353165306

Epoch: 5| Step: 10
Training loss: 2.3123402926995724
Validation loss: 2.576541341028109

Epoch: 5| Step: 11
Training loss: 1.6312623034484606
Validation loss: 2.6221210458252897

Epoch: 405| Step: 0
Training loss: 1.9190197956879094
Validation loss: 2.6465262997392713

Epoch: 5| Step: 1
Training loss: 1.8260851834369525
Validation loss: 2.642559674544676

Epoch: 5| Step: 2
Training loss: 1.9909775593909367
Validation loss: 2.6300825800277936

Epoch: 5| Step: 3
Training loss: 1.7448096279149754
Validation loss: 2.6677180535942364

Epoch: 5| Step: 4
Training loss: 2.0064551370388184
Validation loss: 2.61135271926745

Epoch: 5| Step: 5
Training loss: 1.5548469806706966
Validation loss: 2.6109304056274776

Epoch: 5| Step: 6
Training loss: 1.8924382239757078
Validation loss: 2.5560399363230495

Epoch: 5| Step: 7
Training loss: 1.530369330190899
Validation loss: 2.547385291404856

Epoch: 5| Step: 8
Training loss: 1.3756291510637628
Validation loss: 2.5355471998751367

Epoch: 5| Step: 9
Training loss: 1.830741574791162
Validation loss: 2.548815586648748

Epoch: 5| Step: 10
Training loss: 2.1358340592022795
Validation loss: 2.5199860667481815

Epoch: 5| Step: 11
Training loss: 2.1776493073001255
Validation loss: 2.521751328610515

Epoch: 406| Step: 0
Training loss: 1.4893952453236188
Validation loss: 2.526501589457449

Epoch: 5| Step: 1
Training loss: 1.6637143769380596
Validation loss: 2.5262799153923168

Epoch: 5| Step: 2
Training loss: 1.8096223546803454
Validation loss: 2.6080708433089996

Epoch: 5| Step: 3
Training loss: 2.009507350804727
Validation loss: 2.606500561422686

Epoch: 5| Step: 4
Training loss: 2.112264279187582
Validation loss: 2.614354717599413

Epoch: 5| Step: 5
Training loss: 1.3520217732589261
Validation loss: 2.6396139492877775

Epoch: 5| Step: 6
Training loss: 1.8001184795381542
Validation loss: 2.6707559290682665

Epoch: 5| Step: 7
Training loss: 2.0167246339942224
Validation loss: 2.712706304870258

Epoch: 5| Step: 8
Training loss: 1.847197655185386
Validation loss: 2.708452124313532

Epoch: 5| Step: 9
Training loss: 1.5969381420693625
Validation loss: 2.722943984470837

Epoch: 5| Step: 10
Training loss: 1.9141559811555278
Validation loss: 2.711566364736493

Epoch: 5| Step: 11
Training loss: 2.8614486096113585
Validation loss: 2.653273713909317

Epoch: 407| Step: 0
Training loss: 1.6674379312610572
Validation loss: 2.6491348788800315

Epoch: 5| Step: 1
Training loss: 1.518834363689985
Validation loss: 2.621656585768153

Epoch: 5| Step: 2
Training loss: 1.7521587408517845
Validation loss: 2.593290249933271

Epoch: 5| Step: 3
Training loss: 1.6233635511986684
Validation loss: 2.5811842482830913

Epoch: 5| Step: 4
Training loss: 2.025093019962775
Validation loss: 2.5693536649310142

Epoch: 5| Step: 5
Training loss: 1.8245029268960011
Validation loss: 2.5709402058014765

Epoch: 5| Step: 6
Training loss: 1.8643254646986869
Validation loss: 2.5350235883253607

Epoch: 5| Step: 7
Training loss: 2.001220569096349
Validation loss: 2.545937980107723

Epoch: 5| Step: 8
Training loss: 1.8930750963013079
Validation loss: 2.557133140752274

Epoch: 5| Step: 9
Training loss: 1.7199900228743281
Validation loss: 2.5665880445621676

Epoch: 5| Step: 10
Training loss: 2.0593918008075582
Validation loss: 2.52799409481055

Epoch: 5| Step: 11
Training loss: 2.6103201427916405
Validation loss: 2.5407692283741805

Epoch: 408| Step: 0
Training loss: 1.8379621015508074
Validation loss: 2.5650844489306337

Epoch: 5| Step: 1
Training loss: 1.5097127216737767
Validation loss: 2.5766031493771777

Epoch: 5| Step: 2
Training loss: 2.0751121306858176
Validation loss: 2.6527559711953637

Epoch: 5| Step: 3
Training loss: 1.9052930212065349
Validation loss: 2.657227127017188

Epoch: 5| Step: 4
Training loss: 1.6176841820827745
Validation loss: 2.7131752613681437

Epoch: 5| Step: 5
Training loss: 1.9685613753769777
Validation loss: 2.739077591478199

Epoch: 5| Step: 6
Training loss: 1.8363140612828295
Validation loss: 2.7191082875442802

Epoch: 5| Step: 7
Training loss: 1.6105130810352926
Validation loss: 2.6819951359559893

Epoch: 5| Step: 8
Training loss: 1.3858701016489277
Validation loss: 2.5977245197551078

Epoch: 5| Step: 9
Training loss: 1.816572809273777
Validation loss: 2.5713112541967105

Epoch: 5| Step: 10
Training loss: 1.493961498019714
Validation loss: 2.572645691773618

Epoch: 5| Step: 11
Training loss: 2.1965956009679832
Validation loss: 2.6175503797094386

Epoch: 409| Step: 0
Training loss: 2.2571593927257156
Validation loss: 2.602176986996221

Epoch: 5| Step: 1
Training loss: 1.3647724729114272
Validation loss: 2.5912567396087027

Epoch: 5| Step: 2
Training loss: 2.0379150201976333
Validation loss: 2.615803757958399

Epoch: 5| Step: 3
Training loss: 1.635105840541134
Validation loss: 2.6467225853199903

Epoch: 5| Step: 4
Training loss: 0.951009622948353
Validation loss: 2.6724066140381124

Epoch: 5| Step: 5
Training loss: 1.9881114475012578
Validation loss: 2.705416327495623

Epoch: 5| Step: 6
Training loss: 1.2413986868414886
Validation loss: 2.682883041274994

Epoch: 5| Step: 7
Training loss: 1.294174646171604
Validation loss: 2.6905613252590728

Epoch: 5| Step: 8
Training loss: 1.9670533635202996
Validation loss: 2.688043798092199

Epoch: 5| Step: 9
Training loss: 1.3833260740909306
Validation loss: 2.595037370644203

Epoch: 5| Step: 10
Training loss: 1.569733546176102
Validation loss: 2.638571367624983

Epoch: 5| Step: 11
Training loss: 2.7694028924162843
Validation loss: 2.6265525881224536

Epoch: 410| Step: 0
Training loss: 1.750087122792083
Validation loss: 2.6287090497735592

Epoch: 5| Step: 1
Training loss: 1.9444353814897801
Validation loss: 2.665242035618231

Epoch: 5| Step: 2
Training loss: 1.6126159330579894
Validation loss: 2.650083624821883

Epoch: 5| Step: 3
Training loss: 1.5245348768239007
Validation loss: 2.6231916382458182

Epoch: 5| Step: 4
Training loss: 1.6429958832840705
Validation loss: 2.6744200833983975

Epoch: 5| Step: 5
Training loss: 1.9003221866089157
Validation loss: 2.6519633166857677

Epoch: 5| Step: 6
Training loss: 1.6821970091212082
Validation loss: 2.6611140053927356

Epoch: 5| Step: 7
Training loss: 2.074858888171134
Validation loss: 2.6449100405292563

Epoch: 5| Step: 8
Training loss: 1.483075506684205
Validation loss: 2.5995529325354094

Epoch: 5| Step: 9
Training loss: 1.3251314871702733
Validation loss: 2.594485037037053

Epoch: 5| Step: 10
Training loss: 1.8425807801632474
Validation loss: 2.561319017028051

Epoch: 5| Step: 11
Training loss: 1.0353845884290633
Validation loss: 2.5692140730836335

Epoch: 411| Step: 0
Training loss: 1.7056136541104532
Validation loss: 2.546432499582217

Epoch: 5| Step: 1
Training loss: 1.7336611266621886
Validation loss: 2.6120824796580213

Epoch: 5| Step: 2
Training loss: 1.1619187655524459
Validation loss: 2.607426115454037

Epoch: 5| Step: 3
Training loss: 1.553714773771584
Validation loss: 2.602530080888338

Epoch: 5| Step: 4
Training loss: 1.6526592846164792
Validation loss: 2.6101688178805644

Epoch: 5| Step: 5
Training loss: 1.6625283920043534
Validation loss: 2.619506374217884

Epoch: 5| Step: 6
Training loss: 1.7067828314084654
Validation loss: 2.6227680511629137

Epoch: 5| Step: 7
Training loss: 0.9721428922046772
Validation loss: 2.638028073591192

Epoch: 5| Step: 8
Training loss: 2.1401182814023
Validation loss: 2.6435554165246695

Epoch: 5| Step: 9
Training loss: 2.2106520397720866
Validation loss: 2.629736679895638

Epoch: 5| Step: 10
Training loss: 1.851155361046336
Validation loss: 2.700943866189509

Epoch: 5| Step: 11
Training loss: 1.3728140013556518
Validation loss: 2.6506471371567675

Epoch: 412| Step: 0
Training loss: 1.6672135727335395
Validation loss: 2.6810507351294617

Epoch: 5| Step: 1
Training loss: 1.6952126469189421
Validation loss: 2.7000347105785623

Epoch: 5| Step: 2
Training loss: 1.8897844447985952
Validation loss: 2.689986464863444

Epoch: 5| Step: 3
Training loss: 1.8848855410362766
Validation loss: 2.669560796603743

Epoch: 5| Step: 4
Training loss: 1.8191591464609653
Validation loss: 2.6238504723558935

Epoch: 5| Step: 5
Training loss: 1.6328335993375473
Validation loss: 2.6386110010285506

Epoch: 5| Step: 6
Training loss: 1.6397524011765638
Validation loss: 2.6104074518072045

Epoch: 5| Step: 7
Training loss: 1.421131316826678
Validation loss: 2.594191452360954

Epoch: 5| Step: 8
Training loss: 1.6833191402076157
Validation loss: 2.580580649671942

Epoch: 5| Step: 9
Training loss: 1.7608495627704088
Validation loss: 2.5724575364093245

Epoch: 5| Step: 10
Training loss: 1.4013269505057502
Validation loss: 2.5945855522197325

Epoch: 5| Step: 11
Training loss: 1.09409326888715
Validation loss: 2.645782415145365

Epoch: 413| Step: 0
Training loss: 1.7319477038780662
Validation loss: 2.593584618408998

Epoch: 5| Step: 1
Training loss: 1.7158380289308395
Validation loss: 2.626754670050601

Epoch: 5| Step: 2
Training loss: 1.168944088736828
Validation loss: 2.630580072603126

Epoch: 5| Step: 3
Training loss: 1.6261520703420347
Validation loss: 2.645223901552674

Epoch: 5| Step: 4
Training loss: 1.9751394222639023
Validation loss: 2.635542042329537

Epoch: 5| Step: 5
Training loss: 1.9790548058737787
Validation loss: 2.6564992600716435

Epoch: 5| Step: 6
Training loss: 1.6290384874709065
Validation loss: 2.639287101804972

Epoch: 5| Step: 7
Training loss: 1.860710305695269
Validation loss: 2.6439915777385843

Epoch: 5| Step: 8
Training loss: 1.1686898241514183
Validation loss: 2.6404705905349197

Epoch: 5| Step: 9
Training loss: 1.8918281699094373
Validation loss: 2.6489218472453024

Epoch: 5| Step: 10
Training loss: 1.702678026814652
Validation loss: 2.6285762381343054

Epoch: 5| Step: 11
Training loss: 1.565821816870847
Validation loss: 2.652911433059022

Epoch: 414| Step: 0
Training loss: 2.0352586365350063
Validation loss: 2.6630136022849453

Epoch: 5| Step: 1
Training loss: 1.1496858105409884
Validation loss: 2.6218094850522964

Epoch: 5| Step: 2
Training loss: 1.5411319664574832
Validation loss: 2.6134127102465694

Epoch: 5| Step: 3
Training loss: 1.405668011079802
Validation loss: 2.6165053849923297

Epoch: 5| Step: 4
Training loss: 1.6571674325135481
Validation loss: 2.64332712051468

Epoch: 5| Step: 5
Training loss: 1.6033494610018268
Validation loss: 2.603368096298618

Epoch: 5| Step: 6
Training loss: 2.012847642904182
Validation loss: 2.607136018968661

Epoch: 5| Step: 7
Training loss: 1.4490770954501868
Validation loss: 2.6317290539762417

Epoch: 5| Step: 8
Training loss: 1.6349783226932644
Validation loss: 2.6722777585461994

Epoch: 5| Step: 9
Training loss: 1.9958131596681197
Validation loss: 2.634317087009772

Epoch: 5| Step: 10
Training loss: 1.917256209332206
Validation loss: 2.631295753014772

Epoch: 5| Step: 11
Training loss: 2.054814671979359
Validation loss: 2.6265684845973634

Epoch: 415| Step: 0
Training loss: 1.4870174779371463
Validation loss: 2.614125744924252

Epoch: 5| Step: 1
Training loss: 1.6412354559736975
Validation loss: 2.5718767726207634

Epoch: 5| Step: 2
Training loss: 1.5848362298347196
Validation loss: 2.5989766945250854

Epoch: 5| Step: 3
Training loss: 1.6514329496764988
Validation loss: 2.57769529441455

Epoch: 5| Step: 4
Training loss: 1.4968599195258256
Validation loss: 2.6022385949226856

Epoch: 5| Step: 5
Training loss: 1.7298106713966022
Validation loss: 2.6065263751047034

Epoch: 5| Step: 6
Training loss: 1.4870436120529011
Validation loss: 2.6124702168246925

Epoch: 5| Step: 7
Training loss: 1.72749827990743
Validation loss: 2.6160621197294796

Epoch: 5| Step: 8
Training loss: 1.6110913651816556
Validation loss: 2.6430792942997887

Epoch: 5| Step: 9
Training loss: 1.634224896804654
Validation loss: 2.6333515207853666

Epoch: 5| Step: 10
Training loss: 2.0224140185739454
Validation loss: 2.6130650292599427

Epoch: 5| Step: 11
Training loss: 2.5486750881978257
Validation loss: 2.5863877103343063

Epoch: 416| Step: 0
Training loss: 1.1300776650737376
Validation loss: 2.6174218751335974

Epoch: 5| Step: 1
Training loss: 2.04901000052935
Validation loss: 2.6408202232712736

Epoch: 5| Step: 2
Training loss: 1.5217958652985124
Validation loss: 2.6242902871099054

Epoch: 5| Step: 3
Training loss: 1.5053590569276314
Validation loss: 2.653119190630564

Epoch: 5| Step: 4
Training loss: 1.6568405969732534
Validation loss: 2.6378583465775

Epoch: 5| Step: 5
Training loss: 1.523598921611241
Validation loss: 2.6410698149241467

Epoch: 5| Step: 6
Training loss: 1.544970563466155
Validation loss: 2.6460969685948927

Epoch: 5| Step: 7
Training loss: 1.6710339864108792
Validation loss: 2.652316921512313

Epoch: 5| Step: 8
Training loss: 1.40085048387427
Validation loss: 2.626764990818777

Epoch: 5| Step: 9
Training loss: 1.9890026290285467
Validation loss: 2.6124960380658004

Epoch: 5| Step: 10
Training loss: 1.6480265462181716
Validation loss: 2.60277320710329

Epoch: 5| Step: 11
Training loss: 2.256213826658281
Validation loss: 2.6236179967529276

Epoch: 417| Step: 0
Training loss: 1.4254166646446504
Validation loss: 2.6412472339789557

Epoch: 5| Step: 1
Training loss: 1.0881000091294704
Validation loss: 2.6451332537779457

Epoch: 5| Step: 2
Training loss: 1.5691448824128904
Validation loss: 2.6560947522440643

Epoch: 5| Step: 3
Training loss: 2.077055347474734
Validation loss: 2.6495509699895434

Epoch: 5| Step: 4
Training loss: 1.7570850138497527
Validation loss: 2.6490656052586554

Epoch: 5| Step: 5
Training loss: 1.8102580707413864
Validation loss: 2.644038584134032

Epoch: 5| Step: 6
Training loss: 1.4385605921548892
Validation loss: 2.665345681848238

Epoch: 5| Step: 7
Training loss: 2.0852515989580325
Validation loss: 2.613817491619295

Epoch: 5| Step: 8
Training loss: 1.8593702556645748
Validation loss: 2.6355348392172364

Epoch: 5| Step: 9
Training loss: 1.0921549474315533
Validation loss: 2.6199733463841373

Epoch: 5| Step: 10
Training loss: 1.5216026015372754
Validation loss: 2.579122007617081

Epoch: 5| Step: 11
Training loss: 0.8863525306566115
Validation loss: 2.5713744090793234

Epoch: 418| Step: 0
Training loss: 1.8127984426052344
Validation loss: 2.5489317267593017

Epoch: 5| Step: 1
Training loss: 2.2057637313662677
Validation loss: 2.5737731810395523

Epoch: 5| Step: 2
Training loss: 1.3622693347787418
Validation loss: 2.558307291937964

Epoch: 5| Step: 3
Training loss: 1.7343834541733352
Validation loss: 2.5778783660981626

Epoch: 5| Step: 4
Training loss: 1.562859303170816
Validation loss: 2.596914050546544

Epoch: 5| Step: 5
Training loss: 1.4848807025603712
Validation loss: 2.592702477891583

Epoch: 5| Step: 6
Training loss: 1.199939424257411
Validation loss: 2.6413687198518465

Epoch: 5| Step: 7
Training loss: 1.5573489158424516
Validation loss: 2.6094066937743245

Epoch: 5| Step: 8
Training loss: 1.6935876606637217
Validation loss: 2.6259440737703343

Epoch: 5| Step: 9
Training loss: 1.3974494213853323
Validation loss: 2.6229254191956795

Epoch: 5| Step: 10
Training loss: 1.3922056580118234
Validation loss: 2.576399622700882

Epoch: 5| Step: 11
Training loss: 0.9427820180404081
Validation loss: 2.6201871089394664

Epoch: 419| Step: 0
Training loss: 1.44596971570351
Validation loss: 2.614303559967122

Epoch: 5| Step: 1
Training loss: 1.3002746787022186
Validation loss: 2.612752457030595

Epoch: 5| Step: 2
Training loss: 1.3507785618381878
Validation loss: 2.6478643931929895

Epoch: 5| Step: 3
Training loss: 1.584773044883804
Validation loss: 2.612757962555013

Epoch: 5| Step: 4
Training loss: 1.7170671026840008
Validation loss: 2.652056611539034

Epoch: 5| Step: 5
Training loss: 1.7570040051496578
Validation loss: 2.63804713942481

Epoch: 5| Step: 6
Training loss: 1.5237255899979176
Validation loss: 2.6495412666407563

Epoch: 5| Step: 7
Training loss: 1.4092059962406838
Validation loss: 2.6304030821560387

Epoch: 5| Step: 8
Training loss: 1.4226344668853765
Validation loss: 2.623637474001204

Epoch: 5| Step: 9
Training loss: 2.118282471333069
Validation loss: 2.703012456737732

Epoch: 5| Step: 10
Training loss: 1.605811015305419
Validation loss: 2.690029657790095

Epoch: 5| Step: 11
Training loss: 1.8792776268159856
Validation loss: 2.6633664561500887

Epoch: 420| Step: 0
Training loss: 1.4896916792442638
Validation loss: 2.680530508173621

Epoch: 5| Step: 1
Training loss: 2.0194731654183293
Validation loss: 2.7946315412874077

Epoch: 5| Step: 2
Training loss: 1.6284624039336588
Validation loss: 2.7349475987672185

Epoch: 5| Step: 3
Training loss: 1.7371028720741715
Validation loss: 2.7207624068856675

Epoch: 5| Step: 4
Training loss: 1.6763898549063505
Validation loss: 2.676475928503042

Epoch: 5| Step: 5
Training loss: 1.7340519922198994
Validation loss: 2.652681006224888

Epoch: 5| Step: 6
Training loss: 1.5567488303681687
Validation loss: 2.6591550835461066

Epoch: 5| Step: 7
Training loss: 1.2752928061017441
Validation loss: 2.688248193817161

Epoch: 5| Step: 8
Training loss: 1.5080620751847298
Validation loss: 2.6596828044983924

Epoch: 5| Step: 9
Training loss: 1.9983488061712595
Validation loss: 2.67247916338095

Epoch: 5| Step: 10
Training loss: 1.553608045162149
Validation loss: 2.6479205336843887

Epoch: 5| Step: 11
Training loss: 1.3223097552960543
Validation loss: 2.6091495462203347

Epoch: 421| Step: 0
Training loss: 1.426698488938228
Validation loss: 2.6179015556719794

Epoch: 5| Step: 1
Training loss: 1.7377762993326318
Validation loss: 2.620680111700491

Epoch: 5| Step: 2
Training loss: 1.8433011041942868
Validation loss: 2.625818128855551

Epoch: 5| Step: 3
Training loss: 1.4636269360157357
Validation loss: 2.61885824063252

Epoch: 5| Step: 4
Training loss: 1.5990884419376403
Validation loss: 2.6177662736122556

Epoch: 5| Step: 5
Training loss: 1.365321690027937
Validation loss: 2.6477039863017864

Epoch: 5| Step: 6
Training loss: 1.8726589847396724
Validation loss: 2.6299759123186224

Epoch: 5| Step: 7
Training loss: 1.7383952242743965
Validation loss: 2.602811534519744

Epoch: 5| Step: 8
Training loss: 1.460373631966572
Validation loss: 2.6458701083613745

Epoch: 5| Step: 9
Training loss: 1.337385363434442
Validation loss: 2.6746496401906006

Epoch: 5| Step: 10
Training loss: 1.526637233439298
Validation loss: 2.734045862642932

Epoch: 5| Step: 11
Training loss: 1.6376467602606528
Validation loss: 2.7058364080790103

Epoch: 422| Step: 0
Training loss: 1.7019930936626164
Validation loss: 2.6670821258640722

Epoch: 5| Step: 1
Training loss: 1.1834502683987749
Validation loss: 2.608030201102983

Epoch: 5| Step: 2
Training loss: 2.1661825984235805
Validation loss: 2.572079824864116

Epoch: 5| Step: 3
Training loss: 1.4951903800565083
Validation loss: 2.5667239243656157

Epoch: 5| Step: 4
Training loss: 1.401875877431118
Validation loss: 2.6003690775537773

Epoch: 5| Step: 5
Training loss: 1.1704195775753738
Validation loss: 2.5815754890738516

Epoch: 5| Step: 6
Training loss: 1.5226738996740357
Validation loss: 2.5639676411447043

Epoch: 5| Step: 7
Training loss: 1.2306312574825187
Validation loss: 2.59790349180485

Epoch: 5| Step: 8
Training loss: 1.4122786677647152
Validation loss: 2.6148782971533966

Epoch: 5| Step: 9
Training loss: 2.3296008456595425
Validation loss: 2.6055877730803827

Epoch: 5| Step: 10
Training loss: 1.51174753245472
Validation loss: 2.599969358905557

Epoch: 5| Step: 11
Training loss: 1.5978153960934556
Validation loss: 2.669450273142456

Epoch: 423| Step: 0
Training loss: 1.2756481991293267
Validation loss: 2.661721708600074

Epoch: 5| Step: 1
Training loss: 1.7378309030832608
Validation loss: 2.7252016651997493

Epoch: 5| Step: 2
Training loss: 1.5874685029036582
Validation loss: 2.723134666964457

Epoch: 5| Step: 3
Training loss: 1.8103100273000858
Validation loss: 2.725750249276559

Epoch: 5| Step: 4
Training loss: 1.7155580184451615
Validation loss: 2.681789307942151

Epoch: 5| Step: 5
Training loss: 1.6409396641836314
Validation loss: 2.666086716222242

Epoch: 5| Step: 6
Training loss: 1.3481161466191964
Validation loss: 2.673119153068474

Epoch: 5| Step: 7
Training loss: 1.5785737107919422
Validation loss: 2.6271871053683964

Epoch: 5| Step: 8
Training loss: 1.2925695165979825
Validation loss: 2.6124561833931064

Epoch: 5| Step: 9
Training loss: 1.531375957680212
Validation loss: 2.6118761627384544

Epoch: 5| Step: 10
Training loss: 1.5170885079300926
Validation loss: 2.6296089143999244

Epoch: 5| Step: 11
Training loss: 1.3742046656925087
Validation loss: 2.6048088515338557

Epoch: 424| Step: 0
Training loss: 1.8910779174051147
Validation loss: 2.6151841234541013

Epoch: 5| Step: 1
Training loss: 1.6804502662624656
Validation loss: 2.7073388450144997

Epoch: 5| Step: 2
Training loss: 1.3864424739229608
Validation loss: 2.731816989931793

Epoch: 5| Step: 3
Training loss: 2.202809520886642
Validation loss: 2.769896812686018

Epoch: 5| Step: 4
Training loss: 1.805587214004887
Validation loss: 2.761008409137532

Epoch: 5| Step: 5
Training loss: 1.7993751712969916
Validation loss: 2.664698031812401

Epoch: 5| Step: 6
Training loss: 1.260047159599099
Validation loss: 2.61283800236852

Epoch: 5| Step: 7
Training loss: 1.3500894446235356
Validation loss: 2.6163649144082086

Epoch: 5| Step: 8
Training loss: 1.4171532001150884
Validation loss: 2.600133062130562

Epoch: 5| Step: 9
Training loss: 1.068427828142205
Validation loss: 2.6153841590674176

Epoch: 5| Step: 10
Training loss: 2.027933553114995
Validation loss: 2.6270866010334486

Epoch: 5| Step: 11
Training loss: 1.7946201938480566
Validation loss: 2.648778358962945

Epoch: 425| Step: 0
Training loss: 1.9372147996249316
Validation loss: 2.659467028091275

Epoch: 5| Step: 1
Training loss: 1.6670094217081073
Validation loss: 2.634852723458111

Epoch: 5| Step: 2
Training loss: 1.640855536839392
Validation loss: 2.625074109287751

Epoch: 5| Step: 3
Training loss: 2.095285564252319
Validation loss: 2.6386360939700206

Epoch: 5| Step: 4
Training loss: 1.6126689349254875
Validation loss: 2.632942079549306

Epoch: 5| Step: 5
Training loss: 1.3306780343082998
Validation loss: 2.5955775459936934

Epoch: 5| Step: 6
Training loss: 1.8264776779594396
Validation loss: 2.59943412039071

Epoch: 5| Step: 7
Training loss: 1.768315518667291
Validation loss: 2.610581391341473

Epoch: 5| Step: 8
Training loss: 1.3521849681741502
Validation loss: 2.614792429148079

Epoch: 5| Step: 9
Training loss: 1.7157288789134197
Validation loss: 2.628577689374774

Epoch: 5| Step: 10
Training loss: 1.4379408616438587
Validation loss: 2.650711250074231

Epoch: 5| Step: 11
Training loss: 0.9757667045639212
Validation loss: 2.6730765156410468

Epoch: 426| Step: 0
Training loss: 1.709521260533505
Validation loss: 2.7589409296326575

Epoch: 5| Step: 1
Training loss: 2.0303538766607745
Validation loss: 2.711063374758536

Epoch: 5| Step: 2
Training loss: 1.7124851838744837
Validation loss: 2.703710841675582

Epoch: 5| Step: 3
Training loss: 1.0221115725058545
Validation loss: 2.6878262661860526

Epoch: 5| Step: 4
Training loss: 1.1896424792673965
Validation loss: 2.683953728887431

Epoch: 5| Step: 5
Training loss: 1.5987905192665048
Validation loss: 2.6435588286580782

Epoch: 5| Step: 6
Training loss: 1.7379979963653218
Validation loss: 2.634977520226095

Epoch: 5| Step: 7
Training loss: 1.7676445542809025
Validation loss: 2.6460614418960957

Epoch: 5| Step: 8
Training loss: 1.8706317243573085
Validation loss: 2.650060439620157

Epoch: 5| Step: 9
Training loss: 1.1169390635590204
Validation loss: 2.64934873705451

Epoch: 5| Step: 10
Training loss: 1.2793384807314812
Validation loss: 2.6425484154932644

Epoch: 5| Step: 11
Training loss: 1.0379210778112917
Validation loss: 2.691289233878348

Epoch: 427| Step: 0
Training loss: 1.5012060720860143
Validation loss: 2.647293864153931

Epoch: 5| Step: 1
Training loss: 1.7168324263952686
Validation loss: 2.700199024641671

Epoch: 5| Step: 2
Training loss: 1.6768018908919526
Validation loss: 2.689068281221797

Epoch: 5| Step: 3
Training loss: 1.5236100319219381
Validation loss: 2.7026993116822533

Epoch: 5| Step: 4
Training loss: 1.357650188757833
Validation loss: 2.718275580540155

Epoch: 5| Step: 5
Training loss: 1.5332550623169667
Validation loss: 2.6697007566510846

Epoch: 5| Step: 6
Training loss: 1.5425762981173106
Validation loss: 2.6803902278299705

Epoch: 5| Step: 7
Training loss: 1.392998972857467
Validation loss: 2.714819024794436

Epoch: 5| Step: 8
Training loss: 1.5191786486888499
Validation loss: 2.6664888141351444

Epoch: 5| Step: 9
Training loss: 1.456470043928499
Validation loss: 2.6659853829891507

Epoch: 5| Step: 10
Training loss: 1.7639782408196205
Validation loss: 2.682825969824416

Epoch: 5| Step: 11
Training loss: 1.2364895249727883
Validation loss: 2.6517120005974055

Epoch: 428| Step: 0
Training loss: 1.0871904129818244
Validation loss: 2.635813488442845

Epoch: 5| Step: 1
Training loss: 1.5755299297311873
Validation loss: 2.6485468411450706

Epoch: 5| Step: 2
Training loss: 1.099528389314847
Validation loss: 2.6319096957730816

Epoch: 5| Step: 3
Training loss: 1.5769368599616747
Validation loss: 2.6471274370009725

Epoch: 5| Step: 4
Training loss: 1.7989475405276711
Validation loss: 2.624540530970724

Epoch: 5| Step: 5
Training loss: 1.4640127851417808
Validation loss: 2.616777416384108

Epoch: 5| Step: 6
Training loss: 1.4417159412026344
Validation loss: 2.685920565412897

Epoch: 5| Step: 7
Training loss: 2.033098406847905
Validation loss: 2.6625648047391404

Epoch: 5| Step: 8
Training loss: 1.609653041487807
Validation loss: 2.692139662651363

Epoch: 5| Step: 9
Training loss: 1.5011541376944566
Validation loss: 2.664321655615173

Epoch: 5| Step: 10
Training loss: 1.6211876531773166
Validation loss: 2.666272101915012

Epoch: 5| Step: 11
Training loss: 1.7469249001679443
Validation loss: 2.7286885597440547

Epoch: 429| Step: 0
Training loss: 1.4961587677614998
Validation loss: 2.6498763490414894

Epoch: 5| Step: 1
Training loss: 1.2391460299147026
Validation loss: 2.638776222272191

Epoch: 5| Step: 2
Training loss: 1.039561789881236
Validation loss: 2.608166782304393

Epoch: 5| Step: 3
Training loss: 1.386494535130689
Validation loss: 2.6156746092800875

Epoch: 5| Step: 4
Training loss: 0.8687972172591569
Validation loss: 2.6324440446433237

Epoch: 5| Step: 5
Training loss: 1.9462290370353663
Validation loss: 2.590438038115699

Epoch: 5| Step: 6
Training loss: 1.2934820072675923
Validation loss: 2.652294100417036

Epoch: 5| Step: 7
Training loss: 1.661140993558999
Validation loss: 2.658904746107241

Epoch: 5| Step: 8
Training loss: 1.7377782200966934
Validation loss: 2.6443578117591584

Epoch: 5| Step: 9
Training loss: 1.9458774833925556
Validation loss: 2.690568997652815

Epoch: 5| Step: 10
Training loss: 1.5031015596524941
Validation loss: 2.7580070499026235

Epoch: 5| Step: 11
Training loss: 2.4075133735071383
Validation loss: 2.724361154057708

Epoch: 430| Step: 0
Training loss: 1.6266862483226991
Validation loss: 2.651778189391713

Epoch: 5| Step: 1
Training loss: 1.7151978285772187
Validation loss: 2.6586192261070005

Epoch: 5| Step: 2
Training loss: 1.324979490445308
Validation loss: 2.602633690082911

Epoch: 5| Step: 3
Training loss: 1.045548067791277
Validation loss: 2.636486346516619

Epoch: 5| Step: 4
Training loss: 1.7280986735596067
Validation loss: 2.6475429637119676

Epoch: 5| Step: 5
Training loss: 1.3780713458007632
Validation loss: 2.652526294866747

Epoch: 5| Step: 6
Training loss: 1.591510620589897
Validation loss: 2.647631377171516

Epoch: 5| Step: 7
Training loss: 2.0406200554920715
Validation loss: 2.693475917611961

Epoch: 5| Step: 8
Training loss: 1.2865817156272383
Validation loss: 2.64670662973086

Epoch: 5| Step: 9
Training loss: 2.1154976607841482
Validation loss: 2.6560961117765642

Epoch: 5| Step: 10
Training loss: 1.1985754716971582
Validation loss: 2.6273681029235543

Epoch: 5| Step: 11
Training loss: 2.1928525561625998
Validation loss: 2.6478341314587084

Epoch: 431| Step: 0
Training loss: 1.4426317252007401
Validation loss: 2.697544375376633

Epoch: 5| Step: 1
Training loss: 1.6047622351250572
Validation loss: 2.7625926180599674

Epoch: 5| Step: 2
Training loss: 1.6537945377641166
Validation loss: 2.726845297589353

Epoch: 5| Step: 3
Training loss: 1.4673678611258707
Validation loss: 2.8175761614324215

Epoch: 5| Step: 4
Training loss: 1.747276161822165
Validation loss: 2.7826572601238273

Epoch: 5| Step: 5
Training loss: 1.8791841868438832
Validation loss: 2.7564717636798006

Epoch: 5| Step: 6
Training loss: 1.5893484932882642
Validation loss: 2.7071246433340312

Epoch: 5| Step: 7
Training loss: 1.1466809287866142
Validation loss: 2.625418826402354

Epoch: 5| Step: 8
Training loss: 1.6347934077920299
Validation loss: 2.640766911201483

Epoch: 5| Step: 9
Training loss: 1.6256221167257596
Validation loss: 2.633389305071184

Epoch: 5| Step: 10
Training loss: 1.946810409919523
Validation loss: 2.64051439779722

Epoch: 5| Step: 11
Training loss: 1.2556631074309295
Validation loss: 2.681906145902203

Epoch: 432| Step: 0
Training loss: 1.671006592149133
Validation loss: 2.6595929483471674

Epoch: 5| Step: 1
Training loss: 1.5267880885106544
Validation loss: 2.679156481563812

Epoch: 5| Step: 2
Training loss: 2.0343264244362724
Validation loss: 2.681114458186839

Epoch: 5| Step: 3
Training loss: 1.2185227597959536
Validation loss: 2.648416550965103

Epoch: 5| Step: 4
Training loss: 1.379171805165717
Validation loss: 2.676107189068771

Epoch: 5| Step: 5
Training loss: 1.2578812100616252
Validation loss: 2.667158298820498

Epoch: 5| Step: 6
Training loss: 1.4867875420535674
Validation loss: 2.736218769975138

Epoch: 5| Step: 7
Training loss: 1.6419578587680297
Validation loss: 2.7500045552360493

Epoch: 5| Step: 8
Training loss: 1.3471500496469326
Validation loss: 2.642980634659039

Epoch: 5| Step: 9
Training loss: 1.2174611735174645
Validation loss: 2.699702240278519

Epoch: 5| Step: 10
Training loss: 1.583297486485038
Validation loss: 2.690355026399966

Epoch: 5| Step: 11
Training loss: 2.6923666072519654
Validation loss: 2.714890901810161

Epoch: 433| Step: 0
Training loss: 1.5715310602083126
Validation loss: 2.72170103621599

Epoch: 5| Step: 1
Training loss: 1.6005305989947463
Validation loss: 2.7003192599535364

Epoch: 5| Step: 2
Training loss: 1.47519826687982
Validation loss: 2.6364626913186635

Epoch: 5| Step: 3
Training loss: 1.865145792031016
Validation loss: 2.6511409543573707

Epoch: 5| Step: 4
Training loss: 1.5815238233056976
Validation loss: 2.6394818971187393

Epoch: 5| Step: 5
Training loss: 1.1676952845683455
Validation loss: 2.619945598703621

Epoch: 5| Step: 6
Training loss: 1.4788973478038245
Validation loss: 2.63119415214874

Epoch: 5| Step: 7
Training loss: 1.2539084366158406
Validation loss: 2.636826471082749

Epoch: 5| Step: 8
Training loss: 1.727489792038697
Validation loss: 2.6842913435844538

Epoch: 5| Step: 9
Training loss: 1.478168724010167
Validation loss: 2.6996998153519254

Epoch: 5| Step: 10
Training loss: 1.2990224133643629
Validation loss: 2.694776420908946

Epoch: 5| Step: 11
Training loss: 1.8647309427777072
Validation loss: 2.7728547177940897

Epoch: 434| Step: 0
Training loss: 1.340962112830286
Validation loss: 2.7116748089327154

Epoch: 5| Step: 1
Training loss: 1.7989969081162944
Validation loss: 2.6957962781392575

Epoch: 5| Step: 2
Training loss: 1.5175226660454433
Validation loss: 2.6639107430677287

Epoch: 5| Step: 3
Training loss: 1.3010516644539876
Validation loss: 2.6325007366325504

Epoch: 5| Step: 4
Training loss: 1.4919123370928415
Validation loss: 2.6014877285679825

Epoch: 5| Step: 5
Training loss: 1.1453111614724283
Validation loss: 2.5856022535833803

Epoch: 5| Step: 6
Training loss: 1.7758315811375327
Validation loss: 2.6047260535578594

Epoch: 5| Step: 7
Training loss: 1.3716591215486227
Validation loss: 2.5926593494398675

Epoch: 5| Step: 8
Training loss: 1.4356171259915318
Validation loss: 2.595288417918019

Epoch: 5| Step: 9
Training loss: 1.310055954881101
Validation loss: 2.624302638989011

Epoch: 5| Step: 10
Training loss: 1.6011067556115646
Validation loss: 2.640948394294308

Epoch: 5| Step: 11
Training loss: 0.7809575105555692
Validation loss: 2.6199957172162236

Epoch: 435| Step: 0
Training loss: 1.5291114197745967
Validation loss: 2.6482880736801446

Epoch: 5| Step: 1
Training loss: 1.4903421225536404
Validation loss: 2.669575316888109

Epoch: 5| Step: 2
Training loss: 1.2745579663874458
Validation loss: 2.652195903419716

Epoch: 5| Step: 3
Training loss: 1.5687994048709315
Validation loss: 2.6619064018580954

Epoch: 5| Step: 4
Training loss: 1.3085092090228698
Validation loss: 2.654968678217232

Epoch: 5| Step: 5
Training loss: 1.6405629464176152
Validation loss: 2.617989537721842

Epoch: 5| Step: 6
Training loss: 1.2809544664400736
Validation loss: 2.6704470925500736

Epoch: 5| Step: 7
Training loss: 1.6137125025381003
Validation loss: 2.657827182096056

Epoch: 5| Step: 8
Training loss: 1.2335174092400623
Validation loss: 2.643122825299939

Epoch: 5| Step: 9
Training loss: 1.1055328027076126
Validation loss: 2.6055084942288986

Epoch: 5| Step: 10
Training loss: 1.563184283145503
Validation loss: 2.640374090850615

Epoch: 5| Step: 11
Training loss: 1.199635883561363
Validation loss: 2.6432225432414738

Epoch: 436| Step: 0
Training loss: 1.3747827618391428
Validation loss: 2.670196727417831

Epoch: 5| Step: 1
Training loss: 1.5854047058830616
Validation loss: 2.6299273438383546

Epoch: 5| Step: 2
Training loss: 1.8619420259057107
Validation loss: 2.6663147401051326

Epoch: 5| Step: 3
Training loss: 1.197295992841063
Validation loss: 2.5975661068527325

Epoch: 5| Step: 4
Training loss: 0.9493372964812002
Validation loss: 2.6139735857155078

Epoch: 5| Step: 5
Training loss: 1.440868246267016
Validation loss: 2.649839433418011

Epoch: 5| Step: 6
Training loss: 1.0481658492661117
Validation loss: 2.656654757160294

Epoch: 5| Step: 7
Training loss: 1.7213074124248835
Validation loss: 2.648663270192577

Epoch: 5| Step: 8
Training loss: 1.5310069299960876
Validation loss: 2.6986914974053966

Epoch: 5| Step: 9
Training loss: 1.2671903184513682
Validation loss: 2.6401215549261874

Epoch: 5| Step: 10
Training loss: 1.3962881097057964
Validation loss: 2.6528504439637732

Epoch: 5| Step: 11
Training loss: 1.3512789478430158
Validation loss: 2.6477835456426297

Epoch: 437| Step: 0
Training loss: 1.4082115056691933
Validation loss: 2.653166859045317

Epoch: 5| Step: 1
Training loss: 1.4814220569975534
Validation loss: 2.698682467693628

Epoch: 5| Step: 2
Training loss: 1.5182463010821108
Validation loss: 2.64143638258931

Epoch: 5| Step: 3
Training loss: 1.6525959516822621
Validation loss: 2.6642155309671884

Epoch: 5| Step: 4
Training loss: 1.5723512993447188
Validation loss: 2.631231967414203

Epoch: 5| Step: 5
Training loss: 1.2934299349511775
Validation loss: 2.6254022494426117

Epoch: 5| Step: 6
Training loss: 1.169989429491335
Validation loss: 2.6232637195992443

Epoch: 5| Step: 7
Training loss: 1.3724971012439238
Validation loss: 2.6222704630446794

Epoch: 5| Step: 8
Training loss: 1.3739452217793315
Validation loss: 2.625989958120245

Epoch: 5| Step: 9
Training loss: 1.6583024030066122
Validation loss: 2.5998764607839155

Epoch: 5| Step: 10
Training loss: 1.146329749108875
Validation loss: 2.657597106721667

Epoch: 5| Step: 11
Training loss: 1.91441422948144
Validation loss: 2.6387106372349516

Epoch: 438| Step: 0
Training loss: 1.35105696909446
Validation loss: 2.643316003785526

Epoch: 5| Step: 1
Training loss: 1.2384314220355364
Validation loss: 2.646905791829032

Epoch: 5| Step: 2
Training loss: 1.0080982365044389
Validation loss: 2.638868003199283

Epoch: 5| Step: 3
Training loss: 1.2482717010060234
Validation loss: 2.6651291189590554

Epoch: 5| Step: 4
Training loss: 1.5293006945643952
Validation loss: 2.6622807537841977

Epoch: 5| Step: 5
Training loss: 1.5096658967355112
Validation loss: 2.660943436256667

Epoch: 5| Step: 6
Training loss: 1.5537259756303983
Validation loss: 2.6630788760341666

Epoch: 5| Step: 7
Training loss: 1.228158046675769
Validation loss: 2.6355134257671375

Epoch: 5| Step: 8
Training loss: 1.5808225182039473
Validation loss: 2.6518107699454716

Epoch: 5| Step: 9
Training loss: 1.8945485537023894
Validation loss: 2.721759132053415

Epoch: 5| Step: 10
Training loss: 1.132303583994281
Validation loss: 2.667850635123886

Epoch: 5| Step: 11
Training loss: 1.0807388243952263
Validation loss: 2.6738722031059914

Epoch: 439| Step: 0
Training loss: 1.6345427622133066
Validation loss: 2.6443254399191627

Epoch: 5| Step: 1
Training loss: 1.2934183220779119
Validation loss: 2.6663696016806586

Epoch: 5| Step: 2
Training loss: 1.3316190199191773
Validation loss: 2.6265677395113474

Epoch: 5| Step: 3
Training loss: 1.0558964335055758
Validation loss: 2.635056381828796

Epoch: 5| Step: 4
Training loss: 1.3969019978963035
Validation loss: 2.6421756630573534

Epoch: 5| Step: 5
Training loss: 1.722560058122535
Validation loss: 2.646899936983412

Epoch: 5| Step: 6
Training loss: 1.2805856052071622
Validation loss: 2.6597132582357115

Epoch: 5| Step: 7
Training loss: 1.1245662064795194
Validation loss: 2.661514842757912

Epoch: 5| Step: 8
Training loss: 1.0362007485570157
Validation loss: 2.6474742356710617

Epoch: 5| Step: 9
Training loss: 1.4565172695101234
Validation loss: 2.660078759915647

Epoch: 5| Step: 10
Training loss: 1.564437732787498
Validation loss: 2.6673741085218383

Epoch: 5| Step: 11
Training loss: 2.286790781610207
Validation loss: 2.6788691651158216

Epoch: 440| Step: 0
Training loss: 1.6068971688318923
Validation loss: 2.7074898995926993

Epoch: 5| Step: 1
Training loss: 1.3792607875565983
Validation loss: 2.739654650080223

Epoch: 5| Step: 2
Training loss: 1.437623889394294
Validation loss: 2.685292102172901

Epoch: 5| Step: 3
Training loss: 1.1788667767023229
Validation loss: 2.7312859334262294

Epoch: 5| Step: 4
Training loss: 1.5504962649677145
Validation loss: 2.6991704631926723

Epoch: 5| Step: 5
Training loss: 1.2589300178820988
Validation loss: 2.6581845774530204

Epoch: 5| Step: 6
Training loss: 1.231872242576575
Validation loss: 2.6532221422507694

Epoch: 5| Step: 7
Training loss: 1.3778590042942427
Validation loss: 2.6158533747856128

Epoch: 5| Step: 8
Training loss: 1.687626939873456
Validation loss: 2.6391636418199886

Epoch: 5| Step: 9
Training loss: 1.3170892319048868
Validation loss: 2.6520290459597664

Epoch: 5| Step: 10
Training loss: 1.5176203855622368
Validation loss: 2.6656119761832677

Epoch: 5| Step: 11
Training loss: 1.3285777498349758
Validation loss: 2.632972425665348

Epoch: 441| Step: 0
Training loss: 1.1459008572651874
Validation loss: 2.6235228007574873

Epoch: 5| Step: 1
Training loss: 1.6369084723954856
Validation loss: 2.628809565768524

Epoch: 5| Step: 2
Training loss: 1.5033374850320829
Validation loss: 2.6860933651765846

Epoch: 5| Step: 3
Training loss: 1.278795682849941
Validation loss: 2.65256943114766

Epoch: 5| Step: 4
Training loss: 1.4146681695067835
Validation loss: 2.7118093241199897

Epoch: 5| Step: 5
Training loss: 1.5901219080128823
Validation loss: 2.6949283713126855

Epoch: 5| Step: 6
Training loss: 1.454196247940354
Validation loss: 2.7536210545973328

Epoch: 5| Step: 7
Training loss: 1.2978305283930862
Validation loss: 2.682150877186583

Epoch: 5| Step: 8
Training loss: 1.2086268868616556
Validation loss: 2.671584706589172

Epoch: 5| Step: 9
Training loss: 1.2284432831101404
Validation loss: 2.672594211590209

Epoch: 5| Step: 10
Training loss: 1.300259368038334
Validation loss: 2.6238044937990703

Epoch: 5| Step: 11
Training loss: 1.1282622404442508
Validation loss: 2.6422769130960706

Epoch: 442| Step: 0
Training loss: 1.7344277863588757
Validation loss: 2.6313577891159587

Epoch: 5| Step: 1
Training loss: 1.4486209428127879
Validation loss: 2.663349843095384

Epoch: 5| Step: 2
Training loss: 1.418625608528283
Validation loss: 2.652414140249476

Epoch: 5| Step: 3
Training loss: 1.1798630135435848
Validation loss: 2.688496571226312

Epoch: 5| Step: 4
Training loss: 1.5322231392369343
Validation loss: 2.6758480648414196

Epoch: 5| Step: 5
Training loss: 1.4690890631011744
Validation loss: 2.670352624778108

Epoch: 5| Step: 6
Training loss: 1.246890874393535
Validation loss: 2.6875257897433342

Epoch: 5| Step: 7
Training loss: 1.563578043020431
Validation loss: 2.7272355160799644

Epoch: 5| Step: 8
Training loss: 0.7936199502211995
Validation loss: 2.7654681906633205

Epoch: 5| Step: 9
Training loss: 1.2540555015461843
Validation loss: 2.759382649256644

Epoch: 5| Step: 10
Training loss: 1.0612946573483664
Validation loss: 2.7107041448148204

Epoch: 5| Step: 11
Training loss: 1.1174610576628907
Validation loss: 2.6989329950950967

Epoch: 443| Step: 0
Training loss: 1.0957825439828424
Validation loss: 2.6372148852345267

Epoch: 5| Step: 1
Training loss: 1.436942780344992
Validation loss: 2.665073094955023

Epoch: 5| Step: 2
Training loss: 1.790677137431371
Validation loss: 2.6381842338866712

Epoch: 5| Step: 3
Training loss: 1.472300762304777
Validation loss: 2.65904559954178

Epoch: 5| Step: 4
Training loss: 1.4327676248127
Validation loss: 2.6612003348180546

Epoch: 5| Step: 5
Training loss: 1.7086776370930332
Validation loss: 2.6777165563256236

Epoch: 5| Step: 6
Training loss: 1.8700263496827232
Validation loss: 2.6327773109748303

Epoch: 5| Step: 7
Training loss: 1.4488421256632606
Validation loss: 2.6810499310784177

Epoch: 5| Step: 8
Training loss: 1.1350744355786537
Validation loss: 2.751184692381842

Epoch: 5| Step: 9
Training loss: 1.5928114577198866
Validation loss: 2.837119890232305

Epoch: 5| Step: 10
Training loss: 1.8783131256077088
Validation loss: 2.8204080067082393

Epoch: 5| Step: 11
Training loss: 0.7953473576249599
Validation loss: 2.7528361809475164

Epoch: 444| Step: 0
Training loss: 1.2042597089062874
Validation loss: 2.6712698186027035

Epoch: 5| Step: 1
Training loss: 1.0185955328354475
Validation loss: 2.626278981964734

Epoch: 5| Step: 2
Training loss: 1.629275785468355
Validation loss: 2.6255484681635366

Epoch: 5| Step: 3
Training loss: 1.1503815577721241
Validation loss: 2.6744730960785716

Epoch: 5| Step: 4
Training loss: 1.7043386212485818
Validation loss: 2.6568301483594507

Epoch: 5| Step: 5
Training loss: 1.193007596825508
Validation loss: 2.6275446720905102

Epoch: 5| Step: 6
Training loss: 1.7971240990509048
Validation loss: 2.6517925410682053

Epoch: 5| Step: 7
Training loss: 1.566282652737558
Validation loss: 2.6597595535233673

Epoch: 5| Step: 8
Training loss: 1.320497533709972
Validation loss: 2.6257192405938516

Epoch: 5| Step: 9
Training loss: 1.1651825604634103
Validation loss: 2.6625239944272288

Epoch: 5| Step: 10
Training loss: 1.4082851518293145
Validation loss: 2.6740515991478535

Epoch: 5| Step: 11
Training loss: 1.729219696273538
Validation loss: 2.6806395112090557

Epoch: 445| Step: 0
Training loss: 1.1884296191684205
Validation loss: 2.6926594858270567

Epoch: 5| Step: 1
Training loss: 1.021715302193905
Validation loss: 2.6315875915858027

Epoch: 5| Step: 2
Training loss: 1.2938773659194427
Validation loss: 2.6569906025063386

Epoch: 5| Step: 3
Training loss: 1.7884301813120171
Validation loss: 2.638094432490745

Epoch: 5| Step: 4
Training loss: 1.701487672840161
Validation loss: 2.6500161153975093

Epoch: 5| Step: 5
Training loss: 0.9309083631962064
Validation loss: 2.6650167883397273

Epoch: 5| Step: 6
Training loss: 1.1633712457055454
Validation loss: 2.61156785692438

Epoch: 5| Step: 7
Training loss: 1.3335626027560012
Validation loss: 2.6777346495320526

Epoch: 5| Step: 8
Training loss: 1.2725699810578015
Validation loss: 2.624978470335574

Epoch: 5| Step: 9
Training loss: 1.0044068746962727
Validation loss: 2.7014520241965796

Epoch: 5| Step: 10
Training loss: 1.450997877407296
Validation loss: 2.6758007707835123

Epoch: 5| Step: 11
Training loss: 1.2690261540284165
Validation loss: 2.704725835195363

Epoch: 446| Step: 0
Training loss: 1.100178437498874
Validation loss: 2.7221576484062586

Epoch: 5| Step: 1
Training loss: 1.7464204009029622
Validation loss: 2.706985348472407

Epoch: 5| Step: 2
Training loss: 1.4763424825487472
Validation loss: 2.63553986745155

Epoch: 5| Step: 3
Training loss: 1.2809301302703198
Validation loss: 2.642169427386918

Epoch: 5| Step: 4
Training loss: 1.4727525755445798
Validation loss: 2.6664216492762685

Epoch: 5| Step: 5
Training loss: 1.089845828256027
Validation loss: 2.633899807561263

Epoch: 5| Step: 6
Training loss: 1.4247650287382403
Validation loss: 2.6949600431562395

Epoch: 5| Step: 7
Training loss: 0.7982375519806681
Validation loss: 2.6893717546419054

Epoch: 5| Step: 8
Training loss: 1.1942451548598851
Validation loss: 2.731546779471391

Epoch: 5| Step: 9
Training loss: 1.32968882326448
Validation loss: 2.664932671931638

Epoch: 5| Step: 10
Training loss: 1.3392358407316538
Validation loss: 2.6604695856800222

Epoch: 5| Step: 11
Training loss: 0.6053120317984106
Validation loss: 2.6693092541914614

Epoch: 447| Step: 0
Training loss: 1.4861984296599187
Validation loss: 2.6781608340263374

Epoch: 5| Step: 1
Training loss: 1.4754419666797454
Validation loss: 2.7169085437853036

Epoch: 5| Step: 2
Training loss: 1.1700763886937995
Validation loss: 2.689219638031647

Epoch: 5| Step: 3
Training loss: 1.4796405982184457
Validation loss: 2.688965981624472

Epoch: 5| Step: 4
Training loss: 1.1437924444942593
Validation loss: 2.727367387980779

Epoch: 5| Step: 5
Training loss: 1.4189926948171143
Validation loss: 2.718690769237293

Epoch: 5| Step: 6
Training loss: 1.326370786151658
Validation loss: 2.7337952462434583

Epoch: 5| Step: 7
Training loss: 1.2057117051685822
Validation loss: 2.726829612276097

Epoch: 5| Step: 8
Training loss: 1.169731519494005
Validation loss: 2.708888288030105

Epoch: 5| Step: 9
Training loss: 1.3907617223157485
Validation loss: 2.6900540162859072

Epoch: 5| Step: 10
Training loss: 0.9795246213979849
Validation loss: 2.6822526885722073

Epoch: 5| Step: 11
Training loss: 0.21402019966852573
Validation loss: 2.6631667270956023

Epoch: 448| Step: 0
Training loss: 1.6407956715774543
Validation loss: 2.658263989419061

Epoch: 5| Step: 1
Training loss: 1.3966530437912794
Validation loss: 2.658908000305165

Epoch: 5| Step: 2
Training loss: 1.1213143693187466
Validation loss: 2.6696957667096

Epoch: 5| Step: 3
Training loss: 1.1386790986919773
Validation loss: 2.6705129062724255

Epoch: 5| Step: 4
Training loss: 1.1554657622034985
Validation loss: 2.6853139695407275

Epoch: 5| Step: 5
Training loss: 1.2534643802884777
Validation loss: 2.691838381568175

Epoch: 5| Step: 6
Training loss: 1.0656477917334162
Validation loss: 2.7343762170698094

Epoch: 5| Step: 7
Training loss: 1.1947385619295081
Validation loss: 2.696171222945453

Epoch: 5| Step: 8
Training loss: 1.5625581349048345
Validation loss: 2.7092493061094003

Epoch: 5| Step: 9
Training loss: 1.3357178803112135
Validation loss: 2.719449917816232

Epoch: 5| Step: 10
Training loss: 1.308128707012933
Validation loss: 2.6913182244672456

Epoch: 5| Step: 11
Training loss: 0.8713930582296643
Validation loss: 2.6681979719953715

Epoch: 449| Step: 0
Training loss: 1.355017067354827
Validation loss: 2.7172789010075595

Epoch: 5| Step: 1
Training loss: 1.141283655077762
Validation loss: 2.7405549575804065

Epoch: 5| Step: 2
Training loss: 1.5157315718159605
Validation loss: 2.6733201526398567

Epoch: 5| Step: 3
Training loss: 1.3572435001112955
Validation loss: 2.669442368865047

Epoch: 5| Step: 4
Training loss: 0.9780711917884671
Validation loss: 2.690286921263136

Epoch: 5| Step: 5
Training loss: 1.4042568917345604
Validation loss: 2.692677260956823

Epoch: 5| Step: 6
Training loss: 1.166291579622534
Validation loss: 2.691065500481713

Epoch: 5| Step: 7
Training loss: 1.6748673941659264
Validation loss: 2.7239697652446813

Epoch: 5| Step: 8
Training loss: 1.325336715811616
Validation loss: 2.749334962944574

Epoch: 5| Step: 9
Training loss: 1.5467956214343657
Validation loss: 2.7811478942530456

Epoch: 5| Step: 10
Training loss: 1.2925275066997846
Validation loss: 2.7481395034343703

Epoch: 5| Step: 11
Training loss: 1.0992408799015865
Validation loss: 2.714424346070069

Epoch: 450| Step: 0
Training loss: 1.0968287596777975
Validation loss: 2.643251117684054

Epoch: 5| Step: 1
Training loss: 1.3197198474414544
Validation loss: 2.7026402694830445

Epoch: 5| Step: 2
Training loss: 1.5345626343404786
Validation loss: 2.7009784135474915

Epoch: 5| Step: 3
Training loss: 1.5275773360034226
Validation loss: 2.721358589765005

Epoch: 5| Step: 4
Training loss: 1.7785079329182096
Validation loss: 2.715062457818709

Epoch: 5| Step: 5
Training loss: 1.3162514343688627
Validation loss: 2.683532680832757

Epoch: 5| Step: 6
Training loss: 1.282602944955043
Validation loss: 2.7207695048519094

Epoch: 5| Step: 7
Training loss: 0.9425744687012235
Validation loss: 2.7221610386507917

Epoch: 5| Step: 8
Training loss: 1.6559543705656958
Validation loss: 2.741401914859655

Epoch: 5| Step: 9
Training loss: 1.3987723008356152
Validation loss: 2.7101599781153323

Epoch: 5| Step: 10
Training loss: 1.175796559383045
Validation loss: 2.7306726513260897

Epoch: 5| Step: 11
Training loss: 0.9791305345943535
Validation loss: 2.702379292878101

Epoch: 451| Step: 0
Training loss: 1.672125182640064
Validation loss: 2.7026819847334185

Epoch: 5| Step: 1
Training loss: 1.1130302815563635
Validation loss: 2.66906252660745

Epoch: 5| Step: 2
Training loss: 1.1496523186417011
Validation loss: 2.6964250157488303

Epoch: 5| Step: 3
Training loss: 1.171895039704957
Validation loss: 2.685284542333448

Epoch: 5| Step: 4
Training loss: 1.4891654364280693
Validation loss: 2.7108626158354565

Epoch: 5| Step: 5
Training loss: 1.381948341138363
Validation loss: 2.6508232818667983

Epoch: 5| Step: 6
Training loss: 1.0918859674069965
Validation loss: 2.7035270237610023

Epoch: 5| Step: 7
Training loss: 0.9895422207507137
Validation loss: 2.7563238151336895

Epoch: 5| Step: 8
Training loss: 1.2280287027825483
Validation loss: 2.7430553964757003

Epoch: 5| Step: 9
Training loss: 1.54202821289654
Validation loss: 2.7760949025348802

Epoch: 5| Step: 10
Training loss: 1.187612126728612
Validation loss: 2.783983194889671

Epoch: 5| Step: 11
Training loss: 2.077740282285913
Validation loss: 2.7967894379440987

Epoch: 452| Step: 0
Training loss: 1.4739663850634026
Validation loss: 2.7079456944476763

Epoch: 5| Step: 1
Training loss: 1.5184020723149878
Validation loss: 2.669802756304462

Epoch: 5| Step: 2
Training loss: 1.009962051736235
Validation loss: 2.6712115581366263

Epoch: 5| Step: 3
Training loss: 1.4122250669158756
Validation loss: 2.652989690420789

Epoch: 5| Step: 4
Training loss: 1.6951444340386448
Validation loss: 2.666993142920162

Epoch: 5| Step: 5
Training loss: 1.5001686319293752
Validation loss: 2.6711208253246754

Epoch: 5| Step: 6
Training loss: 1.8446685959617821
Validation loss: 2.6536534801868377

Epoch: 5| Step: 7
Training loss: 1.4326820904904582
Validation loss: 2.6833574134524136

Epoch: 5| Step: 8
Training loss: 0.9652018326600055
Validation loss: 2.709039369889883

Epoch: 5| Step: 9
Training loss: 1.1442642681689947
Validation loss: 2.7455649628744574

Epoch: 5| Step: 10
Training loss: 0.8673165715020245
Validation loss: 2.8028571107509523

Epoch: 5| Step: 11
Training loss: 1.619377459425183
Validation loss: 2.795200830698636

Epoch: 453| Step: 0
Training loss: 1.362245794957994
Validation loss: 2.8460421145377617

Epoch: 5| Step: 1
Training loss: 0.9661861764277053
Validation loss: 2.8206699916159876

Epoch: 5| Step: 2
Training loss: 1.479303470070046
Validation loss: 2.8305033488716242

Epoch: 5| Step: 3
Training loss: 1.4386064997746422
Validation loss: 2.763995514915736

Epoch: 5| Step: 4
Training loss: 1.4128795333313036
Validation loss: 2.749762365882227

Epoch: 5| Step: 5
Training loss: 1.3120769091283615
Validation loss: 2.7504031434921252

Epoch: 5| Step: 6
Training loss: 1.2595372665785909
Validation loss: 2.695321172433068

Epoch: 5| Step: 7
Training loss: 1.604003386011141
Validation loss: 2.682730645612321

Epoch: 5| Step: 8
Training loss: 1.6043595615026074
Validation loss: 2.731446861836741

Epoch: 5| Step: 9
Training loss: 1.3507346556146917
Validation loss: 2.703377721067739

Epoch: 5| Step: 10
Training loss: 1.139557221071068
Validation loss: 2.7111298550568415

Epoch: 5| Step: 11
Training loss: 0.7215806947366116
Validation loss: 2.6913637177272194

Epoch: 454| Step: 0
Training loss: 1.31403415572252
Validation loss: 2.6772610064869315

Epoch: 5| Step: 1
Training loss: 1.1473804721620744
Validation loss: 2.719075724210777

Epoch: 5| Step: 2
Training loss: 1.2472736189932812
Validation loss: 2.731210566919095

Epoch: 5| Step: 3
Training loss: 1.7457210817264956
Validation loss: 2.686172556730461

Epoch: 5| Step: 4
Training loss: 1.1960172383300458
Validation loss: 2.6727371869641057

Epoch: 5| Step: 5
Training loss: 1.5858841309235325
Validation loss: 2.7062764622405466

Epoch: 5| Step: 6
Training loss: 0.9324088138453404
Validation loss: 2.730863623565074

Epoch: 5| Step: 7
Training loss: 1.336653668030458
Validation loss: 2.7335032572108475

Epoch: 5| Step: 8
Training loss: 1.193175456207621
Validation loss: 2.7037765695210245

Epoch: 5| Step: 9
Training loss: 1.1732956476734093
Validation loss: 2.7303584198861266

Epoch: 5| Step: 10
Training loss: 1.0672048854947682
Validation loss: 2.755885400971374

Epoch: 5| Step: 11
Training loss: 1.6595943442453556
Validation loss: 2.769734969221724

Epoch: 455| Step: 0
Training loss: 1.3842332943967015
Validation loss: 2.7042914429861273

Epoch: 5| Step: 1
Training loss: 1.1903330487525392
Validation loss: 2.749562521295641

Epoch: 5| Step: 2
Training loss: 1.1502298913137774
Validation loss: 2.720674173676191

Epoch: 5| Step: 3
Training loss: 1.2334329414525058
Validation loss: 2.739507066126812

Epoch: 5| Step: 4
Training loss: 1.566961936653932
Validation loss: 2.7399667295120587

Epoch: 5| Step: 5
Training loss: 1.336998011069006
Validation loss: 2.747408151222325

Epoch: 5| Step: 6
Training loss: 1.0023246804948431
Validation loss: 2.841004863193955

Epoch: 5| Step: 7
Training loss: 1.4143389858324995
Validation loss: 2.7882166059686644

Epoch: 5| Step: 8
Training loss: 1.7196304840335412
Validation loss: 2.7891068762232836

Epoch: 5| Step: 9
Training loss: 1.3422116189728022
Validation loss: 2.7707202190361446

Epoch: 5| Step: 10
Training loss: 1.2253512093136325
Validation loss: 2.6813022171247414

Epoch: 5| Step: 11
Training loss: 1.1754041301424305
Validation loss: 2.6747097905216597

Epoch: 456| Step: 0
Training loss: 1.2552102222138224
Validation loss: 2.714102536383657

Epoch: 5| Step: 1
Training loss: 1.0432370872914234
Validation loss: 2.719196290258043

Epoch: 5| Step: 2
Training loss: 1.7990536294718116
Validation loss: 2.7005488591347757

Epoch: 5| Step: 3
Training loss: 1.2848716351112195
Validation loss: 2.692767016560262

Epoch: 5| Step: 4
Training loss: 2.039972211985101
Validation loss: 2.6839942947860984

Epoch: 5| Step: 5
Training loss: 1.2316094817710599
Validation loss: 2.7242532185127106

Epoch: 5| Step: 6
Training loss: 1.4324282032015674
Validation loss: 2.7122664771514673

Epoch: 5| Step: 7
Training loss: 1.2731445537220984
Validation loss: 2.75720887606882

Epoch: 5| Step: 8
Training loss: 1.7289292352512846
Validation loss: 2.831384126238445

Epoch: 5| Step: 9
Training loss: 1.0581322821937167
Validation loss: 2.7736189160539353

Epoch: 5| Step: 10
Training loss: 0.8365593139450967
Validation loss: 2.7521055101304404

Epoch: 5| Step: 11
Training loss: 0.7507342082676917
Validation loss: 2.7192387488683236

Epoch: 457| Step: 0
Training loss: 1.072275741890741
Validation loss: 2.6594787907620994

Epoch: 5| Step: 1
Training loss: 1.1462058877724832
Validation loss: 2.670673181867088

Epoch: 5| Step: 2
Training loss: 1.5857001065880796
Validation loss: 2.6320720502997936

Epoch: 5| Step: 3
Training loss: 1.274271031095939
Validation loss: 2.66207465533768

Epoch: 5| Step: 4
Training loss: 1.2164275709573225
Validation loss: 2.5962851632200694

Epoch: 5| Step: 5
Training loss: 1.5337549856488837
Validation loss: 2.6624748182523743

Epoch: 5| Step: 6
Training loss: 1.0873515301785248
Validation loss: 2.668358386637127

Epoch: 5| Step: 7
Training loss: 0.9978857040911112
Validation loss: 2.677366717933618

Epoch: 5| Step: 8
Training loss: 1.0580591069280378
Validation loss: 2.741377284238588

Epoch: 5| Step: 9
Training loss: 1.5319666061496864
Validation loss: 2.771245421453286

Epoch: 5| Step: 10
Training loss: 1.3353288836894663
Validation loss: 2.7796870922983925

Epoch: 5| Step: 11
Training loss: 1.3963504326882026
Validation loss: 2.766417722005829

Epoch: 458| Step: 0
Training loss: 1.082481593532758
Validation loss: 2.7383167411474107

Epoch: 5| Step: 1
Training loss: 1.324838903818446
Validation loss: 2.6882638289384055

Epoch: 5| Step: 2
Training loss: 1.2711442765015855
Validation loss: 2.716471733274561

Epoch: 5| Step: 3
Training loss: 1.1834672413310436
Validation loss: 2.6984964776234364

Epoch: 5| Step: 4
Training loss: 1.139614702916925
Validation loss: 2.68121764275412

Epoch: 5| Step: 5
Training loss: 1.3072124421733364
Validation loss: 2.6449736615295603

Epoch: 5| Step: 6
Training loss: 1.1876534814530062
Validation loss: 2.6556691002036397

Epoch: 5| Step: 7
Training loss: 1.1879774940587366
Validation loss: 2.6517257607199345

Epoch: 5| Step: 8
Training loss: 1.3425616399015428
Validation loss: 2.688964248951789

Epoch: 5| Step: 9
Training loss: 1.3507256094315314
Validation loss: 2.6716817001408444

Epoch: 5| Step: 10
Training loss: 0.7166324603618816
Validation loss: 2.6821504142135453

Epoch: 5| Step: 11
Training loss: 0.6760052877394276
Validation loss: 2.633870128401933

Epoch: 459| Step: 0
Training loss: 1.2442885569921165
Validation loss: 2.6665556047577605

Epoch: 5| Step: 1
Training loss: 1.2639203777978496
Validation loss: 2.7248531109478296

Epoch: 5| Step: 2
Training loss: 1.1684165274856653
Validation loss: 2.8035803321208737

Epoch: 5| Step: 3
Training loss: 1.1807642689879985
Validation loss: 2.737953159124105

Epoch: 5| Step: 4
Training loss: 0.8212315451930472
Validation loss: 2.724560473514823

Epoch: 5| Step: 5
Training loss: 1.1539927435337716
Validation loss: 2.7245871521329468

Epoch: 5| Step: 6
Training loss: 1.1390378177517
Validation loss: 2.706732002661432

Epoch: 5| Step: 7
Training loss: 1.0361937883359869
Validation loss: 2.718448677026855

Epoch: 5| Step: 8
Training loss: 1.4281769991366746
Validation loss: 2.6734728580635965

Epoch: 5| Step: 9
Training loss: 1.3904644305505778
Validation loss: 2.720303676151964

Epoch: 5| Step: 10
Training loss: 1.305578829623249
Validation loss: 2.7098396232875777

Epoch: 5| Step: 11
Training loss: 0.6602228571228268
Validation loss: 2.694613202917857

Epoch: 460| Step: 0
Training loss: 1.2284309103281246
Validation loss: 2.6767425629456145

Epoch: 5| Step: 1
Training loss: 1.4318576039423505
Validation loss: 2.7109130176680947

Epoch: 5| Step: 2
Training loss: 1.003537002519905
Validation loss: 2.720076412800034

Epoch: 5| Step: 3
Training loss: 1.0084642180836008
Validation loss: 2.7034772117930825

Epoch: 5| Step: 4
Training loss: 0.7380350095849637
Validation loss: 2.6924132450428395

Epoch: 5| Step: 5
Training loss: 1.1737159002548736
Validation loss: 2.679090186778104

Epoch: 5| Step: 6
Training loss: 1.6131080368196509
Validation loss: 2.710962114029981

Epoch: 5| Step: 7
Training loss: 1.1491729561235038
Validation loss: 2.731458870985149

Epoch: 5| Step: 8
Training loss: 1.2898148162018022
Validation loss: 2.7958955132969576

Epoch: 5| Step: 9
Training loss: 1.09468953787189
Validation loss: 2.6688134832819843

Epoch: 5| Step: 10
Training loss: 1.0609835293072956
Validation loss: 2.693779982380062

Epoch: 5| Step: 11
Training loss: 0.7852665837894953
Validation loss: 2.7072811992971793

Epoch: 461| Step: 0
Training loss: 0.9530758766898142
Validation loss: 2.713341580492822

Epoch: 5| Step: 1
Training loss: 1.3172286093961143
Validation loss: 2.7211091741985776

Epoch: 5| Step: 2
Training loss: 1.19707623177022
Validation loss: 2.7028794076005025

Epoch: 5| Step: 3
Training loss: 1.2627184895972032
Validation loss: 2.7334358818794002

Epoch: 5| Step: 4
Training loss: 1.0711123408534307
Validation loss: 2.7752337446085784

Epoch: 5| Step: 5
Training loss: 1.3934603300275445
Validation loss: 2.702421067297018

Epoch: 5| Step: 6
Training loss: 1.3024129628335384
Validation loss: 2.7397510141226404

Epoch: 5| Step: 7
Training loss: 1.0862912486928606
Validation loss: 2.751897966108702

Epoch: 5| Step: 8
Training loss: 1.012022112872416
Validation loss: 2.7864908709661442

Epoch: 5| Step: 9
Training loss: 1.0133411257427491
Validation loss: 2.754723714791309

Epoch: 5| Step: 10
Training loss: 1.236023538442502
Validation loss: 2.7634262892450283

Epoch: 5| Step: 11
Training loss: 1.5739190736928177
Validation loss: 2.682643724071194

Epoch: 462| Step: 0
Training loss: 1.1657647097725274
Validation loss: 2.6887875178622243

Epoch: 5| Step: 1
Training loss: 1.2518259064165376
Validation loss: 2.696653679245496

Epoch: 5| Step: 2
Training loss: 1.2819953239284225
Validation loss: 2.7847709942164522

Epoch: 5| Step: 3
Training loss: 1.1449369681387453
Validation loss: 2.822427008039527

Epoch: 5| Step: 4
Training loss: 1.4337198061702923
Validation loss: 2.7893551834078343

Epoch: 5| Step: 5
Training loss: 1.1439626798244407
Validation loss: 2.813259657946702

Epoch: 5| Step: 6
Training loss: 1.2094403764269552
Validation loss: 2.776915565959705

Epoch: 5| Step: 7
Training loss: 1.119162940423651
Validation loss: 2.752720325416614

Epoch: 5| Step: 8
Training loss: 1.3226004645654383
Validation loss: 2.8136096037075213

Epoch: 5| Step: 9
Training loss: 1.1418889502230147
Validation loss: 2.7777721326823626

Epoch: 5| Step: 10
Training loss: 1.31989448746996
Validation loss: 2.731244724160925

Epoch: 5| Step: 11
Training loss: 2.3011304399304935
Validation loss: 2.705255400246123

Epoch: 463| Step: 0
Training loss: 1.140592287195447
Validation loss: 2.7023847959337854

Epoch: 5| Step: 1
Training loss: 1.4181619307650795
Validation loss: 2.7074700385690504

Epoch: 5| Step: 2
Training loss: 1.3858886813368148
Validation loss: 2.7315816471325034

Epoch: 5| Step: 3
Training loss: 1.425635845138058
Validation loss: 2.7155455928499377

Epoch: 5| Step: 4
Training loss: 1.0954364309248563
Validation loss: 2.723225034741666

Epoch: 5| Step: 5
Training loss: 1.4980007199335341
Validation loss: 2.739448559761459

Epoch: 5| Step: 6
Training loss: 1.4385052358925168
Validation loss: 2.7932718712703184

Epoch: 5| Step: 7
Training loss: 1.3616658781011222
Validation loss: 2.852797835506619

Epoch: 5| Step: 8
Training loss: 1.713760833483399
Validation loss: 2.819594343759686

Epoch: 5| Step: 9
Training loss: 1.2804525731608563
Validation loss: 2.792590754612879

Epoch: 5| Step: 10
Training loss: 1.1776017704292132
Validation loss: 2.7423226811344423

Epoch: 5| Step: 11
Training loss: 0.8689879551218478
Validation loss: 2.7104107934143875

Epoch: 464| Step: 0
Training loss: 1.246846656190343
Validation loss: 2.7389228602413898

Epoch: 5| Step: 1
Training loss: 1.3640150046627975
Validation loss: 2.737191959944659

Epoch: 5| Step: 2
Training loss: 1.3752487564483495
Validation loss: 2.7229608650871895

Epoch: 5| Step: 3
Training loss: 1.2747210721109363
Validation loss: 2.74922048473457

Epoch: 5| Step: 4
Training loss: 1.1018171083818202
Validation loss: 2.724807783078634

Epoch: 5| Step: 5
Training loss: 1.495528709541623
Validation loss: 2.6835239295816535

Epoch: 5| Step: 6
Training loss: 1.2980287314704473
Validation loss: 2.6823508444372064

Epoch: 5| Step: 7
Training loss: 1.0812920203891447
Validation loss: 2.780881228626559

Epoch: 5| Step: 8
Training loss: 1.5424674849584126
Validation loss: 2.748114878977303

Epoch: 5| Step: 9
Training loss: 1.1957728677453598
Validation loss: 2.866848796549812

Epoch: 5| Step: 10
Training loss: 1.2290526946079434
Validation loss: 2.8134652353465

Epoch: 5| Step: 11
Training loss: 1.0684779796982133
Validation loss: 2.7899190760968913

Epoch: 465| Step: 0
Training loss: 1.163596347945781
Validation loss: 2.7106585693508944

Epoch: 5| Step: 1
Training loss: 1.078897227277878
Validation loss: 2.742842270946465

Epoch: 5| Step: 2
Training loss: 1.1678335054104472
Validation loss: 2.7068676442683683

Epoch: 5| Step: 3
Training loss: 1.1736239289004515
Validation loss: 2.6874094807365907

Epoch: 5| Step: 4
Training loss: 1.0289636756669207
Validation loss: 2.7315954049617566

Epoch: 5| Step: 5
Training loss: 1.314889095836826
Validation loss: 2.676604641272523

Epoch: 5| Step: 6
Training loss: 1.3842758797666421
Validation loss: 2.6890439322682287

Epoch: 5| Step: 7
Training loss: 1.240035442107277
Validation loss: 2.7272715407185912

Epoch: 5| Step: 8
Training loss: 1.1093095034754898
Validation loss: 2.718463634156754

Epoch: 5| Step: 9
Training loss: 1.099588885209577
Validation loss: 2.7334540841763317

Epoch: 5| Step: 10
Training loss: 0.9430672645466187
Validation loss: 2.7423856868293686

Epoch: 5| Step: 11
Training loss: 1.4839834399520366
Validation loss: 2.7243012138935203

Epoch: 466| Step: 0
Training loss: 1.0763879133377303
Validation loss: 2.7603959148754575

Epoch: 5| Step: 1
Training loss: 1.190984032031426
Validation loss: 2.687594415795254

Epoch: 5| Step: 2
Training loss: 1.361544927028804
Validation loss: 2.7068843388842234

Epoch: 5| Step: 3
Training loss: 0.9631088040603497
Validation loss: 2.739646904839948

Epoch: 5| Step: 4
Training loss: 0.850537514430536
Validation loss: 2.6913972475208596

Epoch: 5| Step: 5
Training loss: 1.1146966870621526
Validation loss: 2.6917668706786193

Epoch: 5| Step: 6
Training loss: 1.1002840238969198
Validation loss: 2.744924051082978

Epoch: 5| Step: 7
Training loss: 1.2242193985227072
Validation loss: 2.745143753189198

Epoch: 5| Step: 8
Training loss: 1.052485732120024
Validation loss: 2.7258559917488614

Epoch: 5| Step: 9
Training loss: 1.2741043591447438
Validation loss: 2.6992105943010984

Epoch: 5| Step: 10
Training loss: 1.1662056670599275
Validation loss: 2.6626582131517447

Epoch: 5| Step: 11
Training loss: 1.3251097165872558
Validation loss: 2.6800898072926325

Epoch: 467| Step: 0
Training loss: 0.8948078644026198
Validation loss: 2.700612162581807

Epoch: 5| Step: 1
Training loss: 1.172203323147627
Validation loss: 2.6853837434177414

Epoch: 5| Step: 2
Training loss: 1.051911040950579
Validation loss: 2.701743524449679

Epoch: 5| Step: 3
Training loss: 1.15175709419558
Validation loss: 2.729694094665399

Epoch: 5| Step: 4
Training loss: 1.1164372732818602
Validation loss: 2.7473884558314965

Epoch: 5| Step: 5
Training loss: 1.2849683537278622
Validation loss: 2.7477779948249084

Epoch: 5| Step: 6
Training loss: 0.8915845487043003
Validation loss: 2.7534339048796324

Epoch: 5| Step: 7
Training loss: 1.2217537470994864
Validation loss: 2.7879058548134186

Epoch: 5| Step: 8
Training loss: 0.8650324394229197
Validation loss: 2.8268119651316383

Epoch: 5| Step: 9
Training loss: 1.2328842915758518
Validation loss: 2.787109970238846

Epoch: 5| Step: 10
Training loss: 1.445095808951417
Validation loss: 2.7984536934956843

Epoch: 5| Step: 11
Training loss: 0.7012824606224807
Validation loss: 2.7568420597467425

Epoch: 468| Step: 0
Training loss: 0.9375686620363944
Validation loss: 2.7669466312690303

Epoch: 5| Step: 1
Training loss: 1.0892854306401547
Validation loss: 2.8018397198158516

Epoch: 5| Step: 2
Training loss: 1.4476243782961127
Validation loss: 2.852744044942571

Epoch: 5| Step: 3
Training loss: 1.173553434656401
Validation loss: 2.7701419897618096

Epoch: 5| Step: 4
Training loss: 1.0661641499347172
Validation loss: 2.733150531356737

Epoch: 5| Step: 5
Training loss: 1.311282274196315
Validation loss: 2.748715205328689

Epoch: 5| Step: 6
Training loss: 1.3823725544716172
Validation loss: 2.6991797378598847

Epoch: 5| Step: 7
Training loss: 1.1554720555503872
Validation loss: 2.6570429871129884

Epoch: 5| Step: 8
Training loss: 1.466878794733055
Validation loss: 2.729852198388875

Epoch: 5| Step: 9
Training loss: 0.9093506485342967
Validation loss: 2.7953692703921846

Epoch: 5| Step: 10
Training loss: 1.1893546027610977
Validation loss: 2.747243547362165

Epoch: 5| Step: 11
Training loss: 1.0371260417166568
Validation loss: 2.7635085130627925

Epoch: 469| Step: 0
Training loss: 1.0655273057114087
Validation loss: 2.715837573915979

Epoch: 5| Step: 1
Training loss: 1.1375485567062362
Validation loss: 2.746971416987314

Epoch: 5| Step: 2
Training loss: 1.0135759076682263
Validation loss: 2.7026749440206235

Epoch: 5| Step: 3
Training loss: 1.0292587707531284
Validation loss: 2.7040018485987476

Epoch: 5| Step: 4
Training loss: 1.0750999581638654
Validation loss: 2.719844499150601

Epoch: 5| Step: 5
Training loss: 1.0155579764919052
Validation loss: 2.669260422601014

Epoch: 5| Step: 6
Training loss: 1.2739619947720322
Validation loss: 2.723956402886742

Epoch: 5| Step: 7
Training loss: 1.1549229094139348
Validation loss: 2.7701254612091

Epoch: 5| Step: 8
Training loss: 1.2542701264519789
Validation loss: 2.701379705025023

Epoch: 5| Step: 9
Training loss: 1.0532749465461764
Validation loss: 2.7231815530103662

Epoch: 5| Step: 10
Training loss: 1.3666541230781346
Validation loss: 2.770126045752785

Epoch: 5| Step: 11
Training loss: 0.7438981269340046
Validation loss: 2.8108493623597863

Epoch: 470| Step: 0
Training loss: 1.1486424892454465
Validation loss: 2.805807954201171

Epoch: 5| Step: 1
Training loss: 1.0077314713898566
Validation loss: 2.7836576284765764

Epoch: 5| Step: 2
Training loss: 1.2048774440854173
Validation loss: 2.808242892658834

Epoch: 5| Step: 3
Training loss: 0.9489251769910826
Validation loss: 2.7545697434258947

Epoch: 5| Step: 4
Training loss: 1.2684165873545776
Validation loss: 2.7035207146387834

Epoch: 5| Step: 5
Training loss: 1.3190521906432
Validation loss: 2.7400678283586695

Epoch: 5| Step: 6
Training loss: 1.0303847410997322
Validation loss: 2.7403505517753284

Epoch: 5| Step: 7
Training loss: 0.8555090907788253
Validation loss: 2.647249733776459

Epoch: 5| Step: 8
Training loss: 1.0281921480739389
Validation loss: 2.7690931403204084

Epoch: 5| Step: 9
Training loss: 1.374822995323676
Validation loss: 2.7405834270239917

Epoch: 5| Step: 10
Training loss: 1.3287542311133613
Validation loss: 2.7615690572943614

Epoch: 5| Step: 11
Training loss: 1.218473305226262
Validation loss: 2.782415103114182

Epoch: 471| Step: 0
Training loss: 1.089146435429804
Validation loss: 2.8015451316202924

Epoch: 5| Step: 1
Training loss: 1.2496488554794254
Validation loss: 2.797505085758408

Epoch: 5| Step: 2
Training loss: 1.0412519519508265
Validation loss: 2.786424930170272

Epoch: 5| Step: 3
Training loss: 0.9842408103911133
Validation loss: 2.7250730678258104

Epoch: 5| Step: 4
Training loss: 1.176325067117267
Validation loss: 2.710711837156317

Epoch: 5| Step: 5
Training loss: 0.9396076670087422
Validation loss: 2.7619174919937093

Epoch: 5| Step: 6
Training loss: 0.8416502220763123
Validation loss: 2.735977074093441

Epoch: 5| Step: 7
Training loss: 0.9977233720751753
Validation loss: 2.7304393746720064

Epoch: 5| Step: 8
Training loss: 1.6656006344270917
Validation loss: 2.7628848551452583

Epoch: 5| Step: 9
Training loss: 1.4584119048977673
Validation loss: 2.7297020719445313

Epoch: 5| Step: 10
Training loss: 1.2180620354731722
Validation loss: 2.827281436196585

Epoch: 5| Step: 11
Training loss: 1.1514489789518032
Validation loss: 2.785242586728226

Epoch: 472| Step: 0
Training loss: 1.1157977656953182
Validation loss: 2.7886282532028464

Epoch: 5| Step: 1
Training loss: 1.2817027524837759
Validation loss: 2.8365361551253034

Epoch: 5| Step: 2
Training loss: 1.4503327481172141
Validation loss: 2.799563956935721

Epoch: 5| Step: 3
Training loss: 1.2739821129505868
Validation loss: 2.7454334621018948

Epoch: 5| Step: 4
Training loss: 1.151091849267394
Validation loss: 2.703269840689206

Epoch: 5| Step: 5
Training loss: 0.9740774962342018
Validation loss: 2.6992034985285778

Epoch: 5| Step: 6
Training loss: 0.7579340099959929
Validation loss: 2.711525445626093

Epoch: 5| Step: 7
Training loss: 1.2869968857182879
Validation loss: 2.7382402258251903

Epoch: 5| Step: 8
Training loss: 0.9046799773066546
Validation loss: 2.7703134017859674

Epoch: 5| Step: 9
Training loss: 1.1951993502249987
Validation loss: 2.784265761938765

Epoch: 5| Step: 10
Training loss: 1.191865326032501
Validation loss: 2.761060299001783

Epoch: 5| Step: 11
Training loss: 1.1681340843733252
Validation loss: 2.7978807164881854

Epoch: 473| Step: 0
Training loss: 1.3439548247612885
Validation loss: 2.8229859415166634

Epoch: 5| Step: 1
Training loss: 0.9897236607422428
Validation loss: 2.79629313776003

Epoch: 5| Step: 2
Training loss: 1.045467512329263
Validation loss: 2.8350720727091656

Epoch: 5| Step: 3
Training loss: 1.1556489774239391
Validation loss: 2.783546999384306

Epoch: 5| Step: 4
Training loss: 1.070215318263565
Validation loss: 2.7397190478593343

Epoch: 5| Step: 5
Training loss: 1.1318720103350228
Validation loss: 2.7161282251993626

Epoch: 5| Step: 6
Training loss: 1.2023061467587
Validation loss: 2.738086013255168

Epoch: 5| Step: 7
Training loss: 0.9575610504408323
Validation loss: 2.6894644905760683

Epoch: 5| Step: 8
Training loss: 1.4928959467936407
Validation loss: 2.7539386431725545

Epoch: 5| Step: 9
Training loss: 1.0006909367640096
Validation loss: 2.7877111963627477

Epoch: 5| Step: 10
Training loss: 1.1815000844560706
Validation loss: 2.7107897781448127

Epoch: 5| Step: 11
Training loss: 1.0315880654815042
Validation loss: 2.7552846358369525

Epoch: 474| Step: 0
Training loss: 0.9759035252237428
Validation loss: 2.7929151658829015

Epoch: 5| Step: 1
Training loss: 1.3450177887800236
Validation loss: 2.820429946553311

Epoch: 5| Step: 2
Training loss: 0.947232967482321
Validation loss: 2.8798981143669504

Epoch: 5| Step: 3
Training loss: 1.213246611170081
Validation loss: 2.851947051294653

Epoch: 5| Step: 4
Training loss: 1.1486845204948624
Validation loss: 2.8592546260489793

Epoch: 5| Step: 5
Training loss: 0.877560309758444
Validation loss: 2.820036317189026

Epoch: 5| Step: 6
Training loss: 1.248463019538705
Validation loss: 2.770703568443508

Epoch: 5| Step: 7
Training loss: 1.0736625202323515
Validation loss: 2.7710545614070776

Epoch: 5| Step: 8
Training loss: 1.2186630902724789
Validation loss: 2.7344642733578284

Epoch: 5| Step: 9
Training loss: 1.087218756866477
Validation loss: 2.7559104426262175

Epoch: 5| Step: 10
Training loss: 1.077156737806585
Validation loss: 2.7216699785055494

Epoch: 5| Step: 11
Training loss: 1.348028513038022
Validation loss: 2.771408456376834

Epoch: 475| Step: 0
Training loss: 1.0420477869274896
Validation loss: 2.76769987676207

Epoch: 5| Step: 1
Training loss: 0.994994600511402
Validation loss: 2.777282431596686

Epoch: 5| Step: 2
Training loss: 0.9443253336077346
Validation loss: 2.7277849657674462

Epoch: 5| Step: 3
Training loss: 0.9764746664602141
Validation loss: 2.72213748202052

Epoch: 5| Step: 4
Training loss: 1.1017771302118673
Validation loss: 2.8040198910255283

Epoch: 5| Step: 5
Training loss: 1.2106471051909347
Validation loss: 2.677980107023441

Epoch: 5| Step: 6
Training loss: 0.9280935134427559
Validation loss: 2.7322701554512667

Epoch: 5| Step: 7
Training loss: 1.134917992557448
Validation loss: 2.744005421195917

Epoch: 5| Step: 8
Training loss: 1.1644437024932743
Validation loss: 2.7556606503144057

Epoch: 5| Step: 9
Training loss: 0.8538640618263799
Validation loss: 2.733124499707307

Epoch: 5| Step: 10
Training loss: 1.1735919835464983
Validation loss: 2.693714497414138

Epoch: 5| Step: 11
Training loss: 1.0991536308905716
Validation loss: 2.7441222854309135

Epoch: 476| Step: 0
Training loss: 0.9036326595229257
Validation loss: 2.7569336828240107

Epoch: 5| Step: 1
Training loss: 0.9632284875482807
Validation loss: 2.761802251219814

Epoch: 5| Step: 2
Training loss: 1.076852794203512
Validation loss: 2.71655346209403

Epoch: 5| Step: 3
Training loss: 0.6597519940356628
Validation loss: 2.7494298965328037

Epoch: 5| Step: 4
Training loss: 1.2404132864157165
Validation loss: 2.856056904265295

Epoch: 5| Step: 5
Training loss: 1.2009332683487686
Validation loss: 2.851903332412012

Epoch: 5| Step: 6
Training loss: 1.315764228177066
Validation loss: 2.773432016143392

Epoch: 5| Step: 7
Training loss: 0.9970097537429274
Validation loss: 2.716942427443263

Epoch: 5| Step: 8
Training loss: 1.0245232682981098
Validation loss: 2.712206456492878

Epoch: 5| Step: 9
Training loss: 0.983662029196178
Validation loss: 2.7036750946685655

Epoch: 5| Step: 10
Training loss: 1.106361109870396
Validation loss: 2.751835467005288

Epoch: 5| Step: 11
Training loss: 0.33776001803988087
Validation loss: 2.722830644127735

Epoch: 477| Step: 0
Training loss: 0.8631241254090802
Validation loss: 2.7307026826101857

Epoch: 5| Step: 1
Training loss: 0.7146089095125302
Validation loss: 2.7475135536947137

Epoch: 5| Step: 2
Training loss: 1.209038358848138
Validation loss: 2.7348335789835683

Epoch: 5| Step: 3
Training loss: 1.1177623310300535
Validation loss: 2.7246617502444757

Epoch: 5| Step: 4
Training loss: 0.9798519428478207
Validation loss: 2.7339543155217303

Epoch: 5| Step: 5
Training loss: 0.963402045504232
Validation loss: 2.8083291174482476

Epoch: 5| Step: 6
Training loss: 1.0568269293899437
Validation loss: 2.861961966345174

Epoch: 5| Step: 7
Training loss: 1.0206132898166984
Validation loss: 2.8197338887948926

Epoch: 5| Step: 8
Training loss: 1.2675266813821897
Validation loss: 2.823185405866136

Epoch: 5| Step: 9
Training loss: 1.055706351506837
Validation loss: 2.75825743287488

Epoch: 5| Step: 10
Training loss: 1.1114586081440427
Validation loss: 2.7498886887824225

Epoch: 5| Step: 11
Training loss: 0.4160979999779287
Validation loss: 2.7520646992489812

Epoch: 478| Step: 0
Training loss: 1.0817855941703307
Validation loss: 2.73035685719738

Epoch: 5| Step: 1
Training loss: 0.8603021302240841
Validation loss: 2.782051913777338

Epoch: 5| Step: 2
Training loss: 1.084083071502772
Validation loss: 2.78140473738994

Epoch: 5| Step: 3
Training loss: 1.3052882107919392
Validation loss: 2.8139831094029306

Epoch: 5| Step: 4
Training loss: 0.7936471376826836
Validation loss: 2.8061083078898013

Epoch: 5| Step: 5
Training loss: 1.0240722318669384
Validation loss: 2.765902061736764

Epoch: 5| Step: 6
Training loss: 0.9822019782168959
Validation loss: 2.764119070511797

Epoch: 5| Step: 7
Training loss: 0.8940624691197517
Validation loss: 2.753794804475665

Epoch: 5| Step: 8
Training loss: 0.863671469203072
Validation loss: 2.7797097216485027

Epoch: 5| Step: 9
Training loss: 1.09294158487325
Validation loss: 2.7779013623455486

Epoch: 5| Step: 10
Training loss: 1.111963717184311
Validation loss: 2.844821385764165

Epoch: 5| Step: 11
Training loss: 1.5804891723580519
Validation loss: 2.7872144629830236

Epoch: 479| Step: 0
Training loss: 1.0383350435878655
Validation loss: 2.7994171502393

Epoch: 5| Step: 1
Training loss: 1.016412400411049
Validation loss: 2.783405083361581

Epoch: 5| Step: 2
Training loss: 0.6981676822206322
Validation loss: 2.8083855379800884

Epoch: 5| Step: 3
Training loss: 0.938917899780827
Validation loss: 2.8168492385468333

Epoch: 5| Step: 4
Training loss: 1.1107522716168432
Validation loss: 2.886998604788122

Epoch: 5| Step: 5
Training loss: 0.9904345849844558
Validation loss: 2.8419633989167363

Epoch: 5| Step: 6
Training loss: 1.2250436989132802
Validation loss: 2.7987772761054064

Epoch: 5| Step: 7
Training loss: 1.027851515922796
Validation loss: 2.83172003077367

Epoch: 5| Step: 8
Training loss: 1.1976106280392291
Validation loss: 2.835204002445645

Epoch: 5| Step: 9
Training loss: 1.1560826567102018
Validation loss: 2.7424248885153646

Epoch: 5| Step: 10
Training loss: 1.051046798789302
Validation loss: 2.729726917089246

Epoch: 5| Step: 11
Training loss: 0.8230880647336446
Validation loss: 2.7131359922228415

Epoch: 480| Step: 0
Training loss: 0.8345434740260811
Validation loss: 2.780446132829812

Epoch: 5| Step: 1
Training loss: 1.2659955836154266
Validation loss: 2.7411879867065863

Epoch: 5| Step: 2
Training loss: 1.0150657874900224
Validation loss: 2.7580507047691243

Epoch: 5| Step: 3
Training loss: 1.0624507443847806
Validation loss: 2.764679554977836

Epoch: 5| Step: 4
Training loss: 1.5177638898781625
Validation loss: 2.7168478614745215

Epoch: 5| Step: 5
Training loss: 1.3382538462526037
Validation loss: 2.796675065777806

Epoch: 5| Step: 6
Training loss: 1.0858224492224093
Validation loss: 2.7717952397112646

Epoch: 5| Step: 7
Training loss: 1.1622933378388216
Validation loss: 2.829537720264613

Epoch: 5| Step: 8
Training loss: 0.8424754936661235
Validation loss: 2.7125899256026047

Epoch: 5| Step: 9
Training loss: 0.8643978371847757
Validation loss: 2.6941388509651514

Epoch: 5| Step: 10
Training loss: 1.0315095979333697
Validation loss: 2.736273929078303

Epoch: 5| Step: 11
Training loss: 0.2815076654366224
Validation loss: 2.8084224848552615

Epoch: 481| Step: 0
Training loss: 0.899136544984912
Validation loss: 2.7502322460131245

Epoch: 5| Step: 1
Training loss: 1.1357845387061547
Validation loss: 2.796472893478327

Epoch: 5| Step: 2
Training loss: 0.9984577326149888
Validation loss: 2.7706037882801713

Epoch: 5| Step: 3
Training loss: 1.0584990399211698
Validation loss: 2.7573447510716096

Epoch: 5| Step: 4
Training loss: 0.9461824181836817
Validation loss: 2.720807699917147

Epoch: 5| Step: 5
Training loss: 0.9986474009059515
Validation loss: 2.7445149737652867

Epoch: 5| Step: 6
Training loss: 1.049464538825664
Validation loss: 2.736235045892762

Epoch: 5| Step: 7
Training loss: 1.0085213112912756
Validation loss: 2.755070332542688

Epoch: 5| Step: 8
Training loss: 1.2359074122338958
Validation loss: 2.7257219346935355

Epoch: 5| Step: 9
Training loss: 0.7732982317450569
Validation loss: 2.7593436308849353

Epoch: 5| Step: 10
Training loss: 0.9586845908302073
Validation loss: 2.7529268042603534

Epoch: 5| Step: 11
Training loss: 0.7274348446748137
Validation loss: 2.81764681684901

Epoch: 482| Step: 0
Training loss: 1.0213551193354766
Validation loss: 2.8221328264119956

Epoch: 5| Step: 1
Training loss: 0.9243816951176528
Validation loss: 2.80883700997854

Epoch: 5| Step: 2
Training loss: 0.9994346391394661
Validation loss: 2.7884437594196902

Epoch: 5| Step: 3
Training loss: 1.1924173535991875
Validation loss: 2.744049421901286

Epoch: 5| Step: 4
Training loss: 1.0718873404190092
Validation loss: 2.747057648344894

Epoch: 5| Step: 5
Training loss: 1.1468252685740816
Validation loss: 2.7619973725125253

Epoch: 5| Step: 6
Training loss: 0.9619592646323342
Validation loss: 2.739725027058312

Epoch: 5| Step: 7
Training loss: 1.0578078276898695
Validation loss: 2.770574311408654

Epoch: 5| Step: 8
Training loss: 1.2798473775293195
Validation loss: 2.7783552385491466

Epoch: 5| Step: 9
Training loss: 0.7686965985862697
Validation loss: 2.842135124569806

Epoch: 5| Step: 10
Training loss: 0.8838875562887045
Validation loss: 2.796565111492758

Epoch: 5| Step: 11
Training loss: 0.6490806010279333
Validation loss: 2.79125359786252

Epoch: 483| Step: 0
Training loss: 0.847460992359899
Validation loss: 2.7237899842521687

Epoch: 5| Step: 1
Training loss: 1.076657941820285
Validation loss: 2.7829884728537824

Epoch: 5| Step: 2
Training loss: 0.9260591822120214
Validation loss: 2.709091624452015

Epoch: 5| Step: 3
Training loss: 0.7882264117248258
Validation loss: 2.7633633894104483

Epoch: 5| Step: 4
Training loss: 1.0018566300771854
Validation loss: 2.7431211557605457

Epoch: 5| Step: 5
Training loss: 0.9957967277938916
Validation loss: 2.772151946374943

Epoch: 5| Step: 6
Training loss: 0.9953545015057476
Validation loss: 2.7784296051143196

Epoch: 5| Step: 7
Training loss: 1.1114481507501959
Validation loss: 2.850740901389329

Epoch: 5| Step: 8
Training loss: 1.0371547768060636
Validation loss: 2.7809865269538627

Epoch: 5| Step: 9
Training loss: 1.0175482513084304
Validation loss: 2.801823317979834

Epoch: 5| Step: 10
Training loss: 1.1191817936806394
Validation loss: 2.8357563188613555

Epoch: 5| Step: 11
Training loss: 0.9894405697019591
Validation loss: 2.743696545635591

Epoch: 484| Step: 0
Training loss: 1.0781857017345977
Validation loss: 2.7378629962711587

Epoch: 5| Step: 1
Training loss: 0.8859959147468915
Validation loss: 2.693416879771731

Epoch: 5| Step: 2
Training loss: 0.7698734897252484
Validation loss: 2.72820193345003

Epoch: 5| Step: 3
Training loss: 1.0655035872665302
Validation loss: 2.741444344816203

Epoch: 5| Step: 4
Training loss: 0.7149100351087928
Validation loss: 2.8011698752489083

Epoch: 5| Step: 5
Training loss: 1.0964526980138878
Validation loss: 2.7735525187967736

Epoch: 5| Step: 6
Training loss: 0.8942294215435919
Validation loss: 2.777782668400804

Epoch: 5| Step: 7
Training loss: 1.26209331420767
Validation loss: 2.744144715728064

Epoch: 5| Step: 8
Training loss: 0.8369898722798148
Validation loss: 2.7538754364526317

Epoch: 5| Step: 9
Training loss: 0.9663769667436044
Validation loss: 2.8267662057879592

Epoch: 5| Step: 10
Training loss: 1.147381874769548
Validation loss: 2.848097991519522

Epoch: 5| Step: 11
Training loss: 0.4437826715450219
Validation loss: 2.8176338000261594

Epoch: 485| Step: 0
Training loss: 1.0148434492878693
Validation loss: 2.928481607424859

Epoch: 5| Step: 1
Training loss: 0.8644201783505129
Validation loss: 2.859406848028314

Epoch: 5| Step: 2
Training loss: 0.8985355157875293
Validation loss: 2.8777526000161955

Epoch: 5| Step: 3
Training loss: 1.156630479226388
Validation loss: 2.7964609361740793

Epoch: 5| Step: 4
Training loss: 1.1083435851653132
Validation loss: 2.803657353180452

Epoch: 5| Step: 5
Training loss: 1.0617299374741132
Validation loss: 2.7386346861919177

Epoch: 5| Step: 6
Training loss: 1.0733273778675154
Validation loss: 2.759003519820581

Epoch: 5| Step: 7
Training loss: 0.9026382428116867
Validation loss: 2.7529127488749054

Epoch: 5| Step: 8
Training loss: 1.1618388398008563
Validation loss: 2.7904600244891875

Epoch: 5| Step: 9
Training loss: 1.1132468234979973
Validation loss: 2.7521689271478866

Epoch: 5| Step: 10
Training loss: 0.5894621568396128
Validation loss: 2.7981594233653064

Epoch: 5| Step: 11
Training loss: 0.2496409520098561
Validation loss: 2.7890074018348487

Epoch: 486| Step: 0
Training loss: 1.0498081508845487
Validation loss: 2.810462839064488

Epoch: 5| Step: 1
Training loss: 0.8866928701783304
Validation loss: 2.851107953915079

Epoch: 5| Step: 2
Training loss: 0.6786504704826138
Validation loss: 2.838641972767299

Epoch: 5| Step: 3
Training loss: 0.8847050930309938
Validation loss: 2.8493248926280765

Epoch: 5| Step: 4
Training loss: 1.1419908367297094
Validation loss: 2.823259566244893

Epoch: 5| Step: 5
Training loss: 1.1702419346313664
Validation loss: 2.8009683465824953

Epoch: 5| Step: 6
Training loss: 0.9227628796468452
Validation loss: 2.802313030617984

Epoch: 5| Step: 7
Training loss: 0.8908412068598638
Validation loss: 2.82263371620225

Epoch: 5| Step: 8
Training loss: 1.0308259034152447
Validation loss: 2.74269138861692

Epoch: 5| Step: 9
Training loss: 1.115895678169967
Validation loss: 2.747264245424033

Epoch: 5| Step: 10
Training loss: 0.8823119238127181
Validation loss: 2.7544376302520015

Epoch: 5| Step: 11
Training loss: 1.0418508875390204
Validation loss: 2.7442861389459257

Epoch: 487| Step: 0
Training loss: 1.0583803306617452
Validation loss: 2.8017456650096655

Epoch: 5| Step: 1
Training loss: 1.0475318328463417
Validation loss: 2.779437056451203

Epoch: 5| Step: 2
Training loss: 0.7079106968011843
Validation loss: 2.832187628977705

Epoch: 5| Step: 3
Training loss: 0.9142593432672175
Validation loss: 2.871863810753013

Epoch: 5| Step: 4
Training loss: 0.9122162129403896
Validation loss: 2.862866047605225

Epoch: 5| Step: 5
Training loss: 0.8342288371446374
Validation loss: 2.853171687947137

Epoch: 5| Step: 6
Training loss: 1.0686788970317218
Validation loss: 2.9420631556639956

Epoch: 5| Step: 7
Training loss: 0.9699948219279089
Validation loss: 2.913746895970508

Epoch: 5| Step: 8
Training loss: 1.1079183874921477
Validation loss: 2.800771538554885

Epoch: 5| Step: 9
Training loss: 0.7265882179876881
Validation loss: 2.8737611485680246

Epoch: 5| Step: 10
Training loss: 0.9305880376419563
Validation loss: 2.8303948596586186

Epoch: 5| Step: 11
Training loss: 0.5121601035964507
Validation loss: 2.766154911977103

Epoch: 488| Step: 0
Training loss: 0.9366415543996661
Validation loss: 2.7820180161148964

Epoch: 5| Step: 1
Training loss: 0.9359961209542843
Validation loss: 2.7875290082268904

Epoch: 5| Step: 2
Training loss: 0.8754226140820829
Validation loss: 2.7770666922270766

Epoch: 5| Step: 3
Training loss: 0.854380642831135
Validation loss: 2.7660149157531775

Epoch: 5| Step: 4
Training loss: 1.1515753819069916
Validation loss: 2.753786741869604

Epoch: 5| Step: 5
Training loss: 0.8684000696418555
Validation loss: 2.8266461863446843

Epoch: 5| Step: 6
Training loss: 1.0706636173122523
Validation loss: 2.795476741525263

Epoch: 5| Step: 7
Training loss: 0.9343400789197229
Validation loss: 2.8384924379798693

Epoch: 5| Step: 8
Training loss: 1.0076210372386902
Validation loss: 2.8765743236723527

Epoch: 5| Step: 9
Training loss: 1.0301205200682995
Validation loss: 2.8597123862468905

Epoch: 5| Step: 10
Training loss: 0.8006709697429357
Validation loss: 2.7795433137124976

Epoch: 5| Step: 11
Training loss: 0.8721491146900854
Validation loss: 2.711001037234187

Epoch: 489| Step: 0
Training loss: 0.7574548959050941
Validation loss: 2.814801796558064

Epoch: 5| Step: 1
Training loss: 1.0586538262581462
Validation loss: 2.7618310231971144

Epoch: 5| Step: 2
Training loss: 0.7865398608932975
Validation loss: 2.7237112043808986

Epoch: 5| Step: 3
Training loss: 0.9122098422213909
Validation loss: 2.747996760211656

Epoch: 5| Step: 4
Training loss: 0.9729479616565389
Validation loss: 2.7937563801521197

Epoch: 5| Step: 5
Training loss: 1.258077605369115
Validation loss: 2.7549698779945446

Epoch: 5| Step: 6
Training loss: 1.1007876545575583
Validation loss: 2.76396203916054

Epoch: 5| Step: 7
Training loss: 1.164975672209993
Validation loss: 2.8255050107920163

Epoch: 5| Step: 8
Training loss: 0.7830921199073299
Validation loss: 2.793706601721079

Epoch: 5| Step: 9
Training loss: 0.6540619385667223
Validation loss: 2.8476808265215063

Epoch: 5| Step: 10
Training loss: 0.9289121840971623
Validation loss: 2.8549249551333316

Epoch: 5| Step: 11
Training loss: 1.487787600370812
Validation loss: 2.8727352129752317

Epoch: 490| Step: 0
Training loss: 1.06610002417733
Validation loss: 2.811613345787219

Epoch: 5| Step: 1
Training loss: 0.8547236712122546
Validation loss: 2.8148401485338552

Epoch: 5| Step: 2
Training loss: 0.7096530923771035
Validation loss: 2.806086599468064

Epoch: 5| Step: 3
Training loss: 1.0324816429224308
Validation loss: 2.7540573475466785

Epoch: 5| Step: 4
Training loss: 1.2186709158254316
Validation loss: 2.755811071299227

Epoch: 5| Step: 5
Training loss: 0.6913615497859499
Validation loss: 2.795072550147641

Epoch: 5| Step: 6
Training loss: 1.4002149144472875
Validation loss: 2.788746549660329

Epoch: 5| Step: 7
Training loss: 1.0073675311822636
Validation loss: 2.7686035941332685

Epoch: 5| Step: 8
Training loss: 1.0302071355665525
Validation loss: 2.8614784973696845

Epoch: 5| Step: 9
Training loss: 1.076597873676857
Validation loss: 2.81588472219153

Epoch: 5| Step: 10
Training loss: 0.8936566404119095
Validation loss: 2.826802079545508

Epoch: 5| Step: 11
Training loss: 0.8048509968701868
Validation loss: 2.8570564090190205

Epoch: 491| Step: 0
Training loss: 0.7841939010377112
Validation loss: 2.8348479511778137

Epoch: 5| Step: 1
Training loss: 0.8570520389786113
Validation loss: 2.782331299341827

Epoch: 5| Step: 2
Training loss: 0.7829374400196919
Validation loss: 2.7676710258116315

Epoch: 5| Step: 3
Training loss: 1.0499912397836644
Validation loss: 2.763647460829663

Epoch: 5| Step: 4
Training loss: 1.1868494159016134
Validation loss: 2.725728578751978

Epoch: 5| Step: 5
Training loss: 1.1569588009382537
Validation loss: 2.740713058211117

Epoch: 5| Step: 6
Training loss: 0.9267923491366736
Validation loss: 2.740999125510318

Epoch: 5| Step: 7
Training loss: 0.9374126075701736
Validation loss: 2.7540534410753694

Epoch: 5| Step: 8
Training loss: 1.0598229735479459
Validation loss: 2.708306790490787

Epoch: 5| Step: 9
Training loss: 1.2570991151649542
Validation loss: 2.824445215047306

Epoch: 5| Step: 10
Training loss: 1.2363886283545322
Validation loss: 2.775729866242956

Epoch: 5| Step: 11
Training loss: 0.36640308679707817
Validation loss: 2.914405158302246

Epoch: 492| Step: 0
Training loss: 1.0855915973204613
Validation loss: 2.963954519109099

Epoch: 5| Step: 1
Training loss: 1.4674806994545053
Validation loss: 3.008089599395788

Epoch: 5| Step: 2
Training loss: 0.820368011049594
Validation loss: 2.8419481409807994

Epoch: 5| Step: 3
Training loss: 0.9821998542496579
Validation loss: 2.8461775880553315

Epoch: 5| Step: 4
Training loss: 1.0955532467854099
Validation loss: 2.7965411088146466

Epoch: 5| Step: 5
Training loss: 0.8139195878709515
Validation loss: 2.781784520594389

Epoch: 5| Step: 6
Training loss: 1.1402245432582399
Validation loss: 2.7642174208149113

Epoch: 5| Step: 7
Training loss: 1.2236924822872615
Validation loss: 2.757165452878446

Epoch: 5| Step: 8
Training loss: 1.2476177403114872
Validation loss: 2.7463550651303335

Epoch: 5| Step: 9
Training loss: 1.1119878382943982
Validation loss: 2.7808279760257864

Epoch: 5| Step: 10
Training loss: 0.8836863421184256
Validation loss: 2.756894539707827

Epoch: 5| Step: 11
Training loss: 0.4762183963872699
Validation loss: 2.7809867770045136

Epoch: 493| Step: 0
Training loss: 0.8170547829800983
Validation loss: 2.833977104894531

Epoch: 5| Step: 1
Training loss: 0.8792530647118125
Validation loss: 2.82263269908212

Epoch: 5| Step: 2
Training loss: 0.8618396096712597
Validation loss: 2.865895932340185

Epoch: 5| Step: 3
Training loss: 1.0464364456985285
Validation loss: 2.8426106829078543

Epoch: 5| Step: 4
Training loss: 0.8685229560506275
Validation loss: 2.855315681386999

Epoch: 5| Step: 5
Training loss: 1.0692701624319898
Validation loss: 2.810324024929171

Epoch: 5| Step: 6
Training loss: 0.7783515186826513
Validation loss: 2.7916920124630424

Epoch: 5| Step: 7
Training loss: 0.8982916340382853
Validation loss: 2.795066799526818

Epoch: 5| Step: 8
Training loss: 0.8233102066701944
Validation loss: 2.7943225416155357

Epoch: 5| Step: 9
Training loss: 1.059810319429784
Validation loss: 2.753734361411081

Epoch: 5| Step: 10
Training loss: 0.8849885167168917
Validation loss: 2.802229548944568

Epoch: 5| Step: 11
Training loss: 1.0670173207729994
Validation loss: 2.7266989549012997

Epoch: 494| Step: 0
Training loss: 1.2609097748347193
Validation loss: 2.791559869706706

Epoch: 5| Step: 1
Training loss: 0.7108193603281167
Validation loss: 2.8165906615602148

Epoch: 5| Step: 2
Training loss: 0.9146727456693895
Validation loss: 2.7768516945202593

Epoch: 5| Step: 3
Training loss: 0.9386746359287255
Validation loss: 2.8444622810577735

Epoch: 5| Step: 4
Training loss: 0.992165392531757
Validation loss: 2.836530891318832

Epoch: 5| Step: 5
Training loss: 0.8831710087480534
Validation loss: 2.8659778541355756

Epoch: 5| Step: 6
Training loss: 1.0815484798110155
Validation loss: 2.8980206432287394

Epoch: 5| Step: 7
Training loss: 0.9299252630782723
Validation loss: 2.9602686412580757

Epoch: 5| Step: 8
Training loss: 1.0538112249722444
Validation loss: 2.8503096732944018

Epoch: 5| Step: 9
Training loss: 0.9938273657666996
Validation loss: 2.8480052934672866

Epoch: 5| Step: 10
Training loss: 0.9087035082503669
Validation loss: 2.7836272085018523

Epoch: 5| Step: 11
Training loss: 1.1682691411075394
Validation loss: 2.773079769363755

Epoch: 495| Step: 0
Training loss: 1.1907549969850426
Validation loss: 2.7708096228328416

Epoch: 5| Step: 1
Training loss: 0.9330492227271334
Validation loss: 2.7218846231517473

Epoch: 5| Step: 2
Training loss: 1.0969628692817943
Validation loss: 2.771572370613034

Epoch: 5| Step: 3
Training loss: 1.1990437830422807
Validation loss: 2.6869180182247403

Epoch: 5| Step: 4
Training loss: 0.6594010045135039
Validation loss: 2.7184066446028616

Epoch: 5| Step: 5
Training loss: 0.7406914339167896
Validation loss: 2.8263535264344313

Epoch: 5| Step: 6
Training loss: 0.9219231027240969
Validation loss: 2.8026838734470907

Epoch: 5| Step: 7
Training loss: 1.2645076481869546
Validation loss: 2.9512457208253675

Epoch: 5| Step: 8
Training loss: 0.7783485704219812
Validation loss: 2.9328728851350623

Epoch: 5| Step: 9
Training loss: 1.2021329183064833
Validation loss: 2.898166952333417

Epoch: 5| Step: 10
Training loss: 0.6199754447842813
Validation loss: 2.823308031934468

Epoch: 5| Step: 11
Training loss: 0.37700360212198863
Validation loss: 2.7684983989503573

Epoch: 496| Step: 0
Training loss: 0.9924287277497996
Validation loss: 2.797613156620691

Epoch: 5| Step: 1
Training loss: 1.021341405020741
Validation loss: 2.755917532974271

Epoch: 5| Step: 2
Training loss: 1.0338244237713172
Validation loss: 2.7711413159736478

Epoch: 5| Step: 3
Training loss: 1.0989838848789517
Validation loss: 2.8346575080642733

Epoch: 5| Step: 4
Training loss: 0.958662456857575
Validation loss: 2.7483557496121547

Epoch: 5| Step: 5
Training loss: 0.8078352830872625
Validation loss: 2.746552969319626

Epoch: 5| Step: 6
Training loss: 1.0276884363767909
Validation loss: 2.796475863258384

Epoch: 5| Step: 7
Training loss: 0.8241903291114068
Validation loss: 2.772339247912547

Epoch: 5| Step: 8
Training loss: 0.9334738746199226
Validation loss: 2.8007351682198114

Epoch: 5| Step: 9
Training loss: 0.9227680471263091
Validation loss: 2.8026477973139756

Epoch: 5| Step: 10
Training loss: 0.9462081827374702
Validation loss: 2.873179598849571

Epoch: 5| Step: 11
Training loss: 0.7375458783896037
Validation loss: 2.793588266377789

Epoch: 497| Step: 0
Training loss: 0.8167671975391098
Validation loss: 2.856101808244262

Epoch: 5| Step: 1
Training loss: 1.0518379428838884
Validation loss: 2.827571600483289

Epoch: 5| Step: 2
Training loss: 0.5522474428897368
Validation loss: 2.8078273210256413

Epoch: 5| Step: 3
Training loss: 1.0862853227322105
Validation loss: 2.773204184734168

Epoch: 5| Step: 4
Training loss: 1.140704583304979
Validation loss: 2.7798848820254296

Epoch: 5| Step: 5
Training loss: 0.795526710246454
Validation loss: 2.800031337250461

Epoch: 5| Step: 6
Training loss: 0.9569091096126912
Validation loss: 2.779664376991623

Epoch: 5| Step: 7
Training loss: 0.8342454131002877
Validation loss: 2.7597364679242014

Epoch: 5| Step: 8
Training loss: 0.8739243435227098
Validation loss: 2.7260834674791052

Epoch: 5| Step: 9
Training loss: 0.7675109523277529
Validation loss: 2.8224493545513827

Epoch: 5| Step: 10
Training loss: 0.9303402892893382
Validation loss: 2.7508617950900005

Epoch: 5| Step: 11
Training loss: 0.5558789044057136
Validation loss: 2.8137513449897416

Epoch: 498| Step: 0
Training loss: 1.0081900547367206
Validation loss: 2.7644102083074635

Epoch: 5| Step: 1
Training loss: 0.8705098543063999
Validation loss: 2.8133252098846064

Epoch: 5| Step: 2
Training loss: 0.8220022327875409
Validation loss: 2.8404497639510664

Epoch: 5| Step: 3
Training loss: 0.9765282586770401
Validation loss: 2.744375850057937

Epoch: 5| Step: 4
Training loss: 0.9214933542911289
Validation loss: 2.7929582466692713

Epoch: 5| Step: 5
Training loss: 0.7198398868365219
Validation loss: 2.849402277434423

Epoch: 5| Step: 6
Training loss: 1.0154574916325263
Validation loss: 2.869158896017359

Epoch: 5| Step: 7
Training loss: 0.9834554706843156
Validation loss: 2.773228930300527

Epoch: 5| Step: 8
Training loss: 0.5780162709034831
Validation loss: 2.714631695778889

Epoch: 5| Step: 9
Training loss: 0.8280358176523807
Validation loss: 2.773969450606156

Epoch: 5| Step: 10
Training loss: 0.9789192144048423
Validation loss: 2.7575749483180374

Epoch: 5| Step: 11
Training loss: 0.6545603662836882
Validation loss: 2.7799292082086318

Epoch: 499| Step: 0
Training loss: 0.8471191743985598
Validation loss: 2.758040630353425

Epoch: 5| Step: 1
Training loss: 0.7133208348465706
Validation loss: 2.8056634393309148

Epoch: 5| Step: 2
Training loss: 0.6690031820173099
Validation loss: 2.816170056897785

Epoch: 5| Step: 3
Training loss: 1.031068150063357
Validation loss: 2.866432658798432

Epoch: 5| Step: 4
Training loss: 0.9853207722324797
Validation loss: 2.8998532671912427

Epoch: 5| Step: 5
Training loss: 0.940489833409767
Validation loss: 2.881369028646225

Epoch: 5| Step: 6
Training loss: 1.0652796345053126
Validation loss: 2.833552819520751

Epoch: 5| Step: 7
Training loss: 0.9399705441404939
Validation loss: 2.833730358935768

Epoch: 5| Step: 8
Training loss: 0.9123587747268648
Validation loss: 2.80463768889134

Epoch: 5| Step: 9
Training loss: 0.6828388732775119
Validation loss: 2.8442097735852285

Epoch: 5| Step: 10
Training loss: 0.853159675312652
Validation loss: 2.8163511083022192

Epoch: 5| Step: 11
Training loss: 0.6891509304264255
Validation loss: 2.7759764283740993

Epoch: 500| Step: 0
Training loss: 0.8871404174587295
Validation loss: 2.809292483081505

Epoch: 5| Step: 1
Training loss: 0.7017905818211582
Validation loss: 2.787741361526489

Epoch: 5| Step: 2
Training loss: 0.8174330172963812
Validation loss: 2.8252739946450065

Epoch: 5| Step: 3
Training loss: 0.7515462988616074
Validation loss: 2.8434075124838882

Epoch: 5| Step: 4
Training loss: 0.8392829974689977
Validation loss: 2.8403615851086403

Epoch: 5| Step: 5
Training loss: 0.9532103891113869
Validation loss: 2.8841322037938597

Epoch: 5| Step: 6
Training loss: 0.7385133650880434
Validation loss: 2.9307355167601914

Epoch: 5| Step: 7
Training loss: 0.9739793105424812
Validation loss: 2.890244976185288

Epoch: 5| Step: 8
Training loss: 0.8625798202289306
Validation loss: 2.78255792646043

Epoch: 5| Step: 9
Training loss: 0.7280722488482851
Validation loss: 2.8020784893254005

Epoch: 5| Step: 10
Training loss: 0.9711066775332294
Validation loss: 2.804003466513981

Epoch: 5| Step: 11
Training loss: 0.9066610390708216
Validation loss: 2.8362440673914024

Testing loss: 2.487171667288806
