Epoch: 1| Step: 0
Training loss: 4.6443150295943765
Validation loss: 5.895362520683934

Epoch: 5| Step: 1
Training loss: 6.078995120177559
Validation loss: 5.893743241145445

Epoch: 5| Step: 2
Training loss: 6.265492882608017
Validation loss: 5.892208038431859

Epoch: 5| Step: 3
Training loss: 5.76784301108207
Validation loss: 5.890678162676374

Epoch: 5| Step: 4
Training loss: 5.738169565795378
Validation loss: 5.889272235992747

Epoch: 5| Step: 5
Training loss: 5.9284467240840355
Validation loss: 5.887835772335245

Epoch: 5| Step: 6
Training loss: 6.686563586692118
Validation loss: 5.886460536330155

Epoch: 5| Step: 7
Training loss: 5.462823763053914
Validation loss: 5.885018389793839

Epoch: 5| Step: 8
Training loss: 5.931271789960962
Validation loss: 5.883529342469704

Epoch: 5| Step: 9
Training loss: 6.322474087639046
Validation loss: 5.8820495110678115

Epoch: 5| Step: 10
Training loss: 6.660164841453403
Validation loss: 5.88047447537111

Epoch: 5| Step: 11
Training loss: 7.285577233144755
Validation loss: 5.878812574145095

Epoch: 2| Step: 0
Training loss: 6.310490656666949
Validation loss: 5.877071637621247

Epoch: 5| Step: 1
Training loss: 7.036127865304472
Validation loss: 5.875263695176073

Epoch: 5| Step: 2
Training loss: 5.4282844761605835
Validation loss: 5.873300678607661

Epoch: 5| Step: 3
Training loss: 6.305687580416302
Validation loss: 5.871307186427276

Epoch: 5| Step: 4
Training loss: 4.992010217900701
Validation loss: 5.869203237325481

Epoch: 5| Step: 5
Training loss: 6.38822910753607
Validation loss: 5.867130880340847

Epoch: 5| Step: 6
Training loss: 5.67060169398075
Validation loss: 5.864825210416642

Epoch: 5| Step: 7
Training loss: 5.525963277257782
Validation loss: 5.862369446971595

Epoch: 5| Step: 8
Training loss: 6.356783702128344
Validation loss: 5.860002163701098

Epoch: 5| Step: 9
Training loss: 5.782737416870206
Validation loss: 5.857403348015968

Epoch: 5| Step: 10
Training loss: 6.024723613303702
Validation loss: 5.854635941599358

Epoch: 5| Step: 11
Training loss: 4.3845241964435795
Validation loss: 5.851713870390609

Epoch: 3| Step: 0
Training loss: 5.765569423004494
Validation loss: 5.848731917779794

Epoch: 5| Step: 1
Training loss: 6.484186450101333
Validation loss: 5.8455790141065025

Epoch: 5| Step: 2
Training loss: 5.856383025165889
Validation loss: 5.842256535376161

Epoch: 5| Step: 3
Training loss: 6.1192104458592445
Validation loss: 5.838588590770843

Epoch: 5| Step: 4
Training loss: 5.988310553173575
Validation loss: 5.834896343730248

Epoch: 5| Step: 5
Training loss: 4.951076529222486
Validation loss: 5.831006835032429

Epoch: 5| Step: 6
Training loss: 6.591102683354245
Validation loss: 5.827022840312944

Epoch: 5| Step: 7
Training loss: 5.429920745889449
Validation loss: 5.8227534626681345

Epoch: 5| Step: 8
Training loss: 6.121052618320643
Validation loss: 5.818070186698686

Epoch: 5| Step: 9
Training loss: 5.569795774486029
Validation loss: 5.813293635286756

Epoch: 5| Step: 10
Training loss: 6.11123543044515
Validation loss: 5.808418604782632

Epoch: 5| Step: 11
Training loss: 6.994951334873324
Validation loss: 5.80313789285444

Epoch: 4| Step: 0
Training loss: 5.935045236802381
Validation loss: 5.797755542105866

Epoch: 5| Step: 1
Training loss: 5.072918003507695
Validation loss: 5.792002986043965

Epoch: 5| Step: 2
Training loss: 5.179226815981026
Validation loss: 5.786131851045982

Epoch: 5| Step: 3
Training loss: 6.260437147093251
Validation loss: 5.780068271590152

Epoch: 5| Step: 4
Training loss: 6.267505696449689
Validation loss: 5.773807904342027

Epoch: 5| Step: 5
Training loss: 6.382010700194146
Validation loss: 5.767681523511583

Epoch: 5| Step: 6
Training loss: 6.19407042936119
Validation loss: 5.7609066976081245

Epoch: 5| Step: 7
Training loss: 5.862726580505326
Validation loss: 5.754096907465121

Epoch: 5| Step: 8
Training loss: 5.752023755402514
Validation loss: 5.747047689172407

Epoch: 5| Step: 9
Training loss: 5.6807710854894005
Validation loss: 5.739872645328789

Epoch: 5| Step: 10
Training loss: 5.488117212851069
Validation loss: 5.732401994349043

Epoch: 5| Step: 11
Training loss: 7.829375328976903
Validation loss: 5.725230458880826

Epoch: 5| Step: 0
Training loss: 6.494888056142031
Validation loss: 5.718048330594879

Epoch: 5| Step: 1
Training loss: 5.159990653096095
Validation loss: 5.710352494126141

Epoch: 5| Step: 2
Training loss: 5.975885888987768
Validation loss: 5.7029318789875685

Epoch: 5| Step: 3
Training loss: 4.970560763555679
Validation loss: 5.694840790619465

Epoch: 5| Step: 4
Training loss: 5.778014891396965
Validation loss: 5.687364974881903

Epoch: 5| Step: 5
Training loss: 6.513381388762562
Validation loss: 5.679232936406246

Epoch: 5| Step: 6
Training loss: 5.979272644308877
Validation loss: 5.671392499089015

Epoch: 5| Step: 7
Training loss: 5.817918774228924
Validation loss: 5.663315654054963

Epoch: 5| Step: 8
Training loss: 5.7591393855681545
Validation loss: 5.655568870434246

Epoch: 5| Step: 9
Training loss: 5.632934907596375
Validation loss: 5.6479414866751165

Epoch: 5| Step: 10
Training loss: 5.5674952676493445
Validation loss: 5.6401544305950795

Epoch: 5| Step: 11
Training loss: 5.4035854939841474
Validation loss: 5.632645991205974

Epoch: 6| Step: 0
Training loss: 5.9162351782262705
Validation loss: 5.624817322484438

Epoch: 5| Step: 1
Training loss: 5.957630925246635
Validation loss: 5.617725556998714

Epoch: 5| Step: 2
Training loss: 6.293579147732197
Validation loss: 5.610085345869659

Epoch: 5| Step: 3
Training loss: 5.730958341709028
Validation loss: 5.602878219182464

Epoch: 5| Step: 4
Training loss: 5.543764773653423
Validation loss: 5.595642401968828

Epoch: 5| Step: 5
Training loss: 5.526712399068419
Validation loss: 5.588456033819101

Epoch: 5| Step: 6
Training loss: 6.443677290201898
Validation loss: 5.58154308977734

Epoch: 5| Step: 7
Training loss: 5.109220263269964
Validation loss: 5.574039434067421

Epoch: 5| Step: 8
Training loss: 5.479881597757332
Validation loss: 5.567576559973813

Epoch: 5| Step: 9
Training loss: 4.896981006051873
Validation loss: 5.560655173651845

Epoch: 5| Step: 10
Training loss: 5.86549712718984
Validation loss: 5.5541166145414165

Epoch: 5| Step: 11
Training loss: 4.873931963396029
Validation loss: 5.547603956867028

Epoch: 7| Step: 0
Training loss: 5.586283383631404
Validation loss: 5.541569101818041

Epoch: 5| Step: 1
Training loss: 5.74242798178406
Validation loss: 5.5353909094798315

Epoch: 5| Step: 2
Training loss: 5.810245199626704
Validation loss: 5.529364722565622

Epoch: 5| Step: 3
Training loss: 5.413591813053453
Validation loss: 5.523096191853732

Epoch: 5| Step: 4
Training loss: 5.42616985733756
Validation loss: 5.51733483602409

Epoch: 5| Step: 5
Training loss: 5.62559184033797
Validation loss: 5.511076581797222

Epoch: 5| Step: 6
Training loss: 6.643099550432982
Validation loss: 5.504973799642868

Epoch: 5| Step: 7
Training loss: 5.724402130759043
Validation loss: 5.498847443299033

Epoch: 5| Step: 8
Training loss: 5.491918521985193
Validation loss: 5.492710853700031

Epoch: 5| Step: 9
Training loss: 5.686142644197911
Validation loss: 5.486835409658105

Epoch: 5| Step: 10
Training loss: 5.042058482852696
Validation loss: 5.480598968387195

Epoch: 5| Step: 11
Training loss: 3.2578272830618578
Validation loss: 5.4747578417847

Epoch: 8| Step: 0
Training loss: 4.4047303521438925
Validation loss: 5.468807409075994

Epoch: 5| Step: 1
Training loss: 5.43204057600235
Validation loss: 5.462822337355117

Epoch: 5| Step: 2
Training loss: 6.409857501798256
Validation loss: 5.457006120817324

Epoch: 5| Step: 3
Training loss: 5.922060196127082
Validation loss: 5.45153609830951

Epoch: 5| Step: 4
Training loss: 5.930769146962352
Validation loss: 5.445353241033309

Epoch: 5| Step: 5
Training loss: 5.101701205881406
Validation loss: 5.439413691251623

Epoch: 5| Step: 6
Training loss: 5.30899183340014
Validation loss: 5.433420609531868

Epoch: 5| Step: 7
Training loss: 5.444659025587114
Validation loss: 5.427489994601541

Epoch: 5| Step: 8
Training loss: 6.253441435334327
Validation loss: 5.421151016665142

Epoch: 5| Step: 9
Training loss: 5.281456937629351
Validation loss: 5.415057547296655

Epoch: 5| Step: 10
Training loss: 4.997161059275932
Validation loss: 5.408219149735592

Epoch: 5| Step: 11
Training loss: 7.15216187558901
Validation loss: 5.401725235307341

Epoch: 9| Step: 0
Training loss: 5.5237151296032465
Validation loss: 5.395177855377994

Epoch: 5| Step: 1
Training loss: 5.4713118302022
Validation loss: 5.38967259788639

Epoch: 5| Step: 2
Training loss: 5.734101915223509
Validation loss: 5.384297749649125

Epoch: 5| Step: 3
Training loss: 5.615182404650805
Validation loss: 5.379007479348354

Epoch: 5| Step: 4
Training loss: 5.720164973407502
Validation loss: 5.37335910442284

Epoch: 5| Step: 5
Training loss: 5.610526389111367
Validation loss: 5.367188573519744

Epoch: 5| Step: 6
Training loss: 4.650065161135661
Validation loss: 5.3612594183182924

Epoch: 5| Step: 7
Training loss: 5.114790633196588
Validation loss: 5.355675476076154

Epoch: 5| Step: 8
Training loss: 5.580414630702769
Validation loss: 5.349874143813551

Epoch: 5| Step: 9
Training loss: 5.206131899663075
Validation loss: 5.344086270227515

Epoch: 5| Step: 10
Training loss: 5.837139123385013
Validation loss: 5.3377861890220135

Epoch: 5| Step: 11
Training loss: 6.43478188027222
Validation loss: 5.3324200647952935

Epoch: 10| Step: 0
Training loss: 6.2903661668023085
Validation loss: 5.32625747721918

Epoch: 5| Step: 1
Training loss: 5.206685998435446
Validation loss: 5.320562594861204

Epoch: 5| Step: 2
Training loss: 5.54853164219142
Validation loss: 5.314936606422959

Epoch: 5| Step: 3
Training loss: 5.728385437384454
Validation loss: 5.309758230549526

Epoch: 5| Step: 4
Training loss: 4.98499449703789
Validation loss: 5.304272500136253

Epoch: 5| Step: 5
Training loss: 5.167992739574895
Validation loss: 5.299380389768434

Epoch: 5| Step: 6
Training loss: 5.228665919347169
Validation loss: 5.2934447427567175

Epoch: 5| Step: 7
Training loss: 5.690535186109098
Validation loss: 5.288536950976429

Epoch: 5| Step: 8
Training loss: 5.049064610032169
Validation loss: 5.283205200871819

Epoch: 5| Step: 9
Training loss: 6.162782562772731
Validation loss: 5.277930267819183

Epoch: 5| Step: 10
Training loss: 4.575753597041143
Validation loss: 5.272391261171296

Epoch: 5| Step: 11
Training loss: 4.1057516739156705
Validation loss: 5.267150574898632

Epoch: 11| Step: 0
Training loss: 5.100724015547997
Validation loss: 5.26210327555861

Epoch: 5| Step: 1
Training loss: 5.88801205103097
Validation loss: 5.257262633366765

Epoch: 5| Step: 2
Training loss: 4.854780275694107
Validation loss: 5.252367174749885

Epoch: 5| Step: 3
Training loss: 5.600475509073705
Validation loss: 5.247655670573369

Epoch: 5| Step: 4
Training loss: 5.646737714828657
Validation loss: 5.242493242954647

Epoch: 5| Step: 5
Training loss: 4.7798938697939874
Validation loss: 5.237717983410491

Epoch: 5| Step: 6
Training loss: 5.250197633928889
Validation loss: 5.233262834965013

Epoch: 5| Step: 7
Training loss: 6.053131730563824
Validation loss: 5.228326192945607

Epoch: 5| Step: 8
Training loss: 5.643798611622733
Validation loss: 5.223120505888779

Epoch: 5| Step: 9
Training loss: 5.220924883641308
Validation loss: 5.218499229025393

Epoch: 5| Step: 10
Training loss: 4.5948516147634555
Validation loss: 5.213884381117464

Epoch: 5| Step: 11
Training loss: 6.000101088625963
Validation loss: 5.209343494365017

Epoch: 12| Step: 0
Training loss: 4.855159587024768
Validation loss: 5.204777818787689

Epoch: 5| Step: 1
Training loss: 5.4801897996208275
Validation loss: 5.199685343062103

Epoch: 5| Step: 2
Training loss: 5.0281121556679285
Validation loss: 5.195295405539017

Epoch: 5| Step: 3
Training loss: 4.913691423290672
Validation loss: 5.190593892248657

Epoch: 5| Step: 4
Training loss: 4.980635720240377
Validation loss: 5.18569838403703

Epoch: 5| Step: 5
Training loss: 6.023462199000917
Validation loss: 5.179918455687347

Epoch: 5| Step: 6
Training loss: 5.554902106108376
Validation loss: 5.174824137932186

Epoch: 5| Step: 7
Training loss: 5.648886930490536
Validation loss: 5.169374697111829

Epoch: 5| Step: 8
Training loss: 5.00904371626122
Validation loss: 5.164223949776819

Epoch: 5| Step: 9
Training loss: 5.297692159900322
Validation loss: 5.159145312989328

Epoch: 5| Step: 10
Training loss: 5.625076802047299
Validation loss: 5.154676956515954

Epoch: 5| Step: 11
Training loss: 4.1418924946816285
Validation loss: 5.148823659459016

Epoch: 13| Step: 0
Training loss: 5.834827486052367
Validation loss: 5.144230421766959

Epoch: 5| Step: 1
Training loss: 5.482670967577819
Validation loss: 5.139141382710168

Epoch: 5| Step: 2
Training loss: 4.925556271502766
Validation loss: 5.13405856060744

Epoch: 5| Step: 3
Training loss: 4.7180017547539475
Validation loss: 5.129031704455159

Epoch: 5| Step: 4
Training loss: 5.78837451630556
Validation loss: 5.123791272978288

Epoch: 5| Step: 5
Training loss: 5.255508802410742
Validation loss: 5.118440570724408

Epoch: 5| Step: 6
Training loss: 4.898097365645636
Validation loss: 5.1133403109254605

Epoch: 5| Step: 7
Training loss: 5.142716095519111
Validation loss: 5.108240396277559

Epoch: 5| Step: 8
Training loss: 5.046625562237572
Validation loss: 5.103667062195605

Epoch: 5| Step: 9
Training loss: 4.928482319438963
Validation loss: 5.098107367927752

Epoch: 5| Step: 10
Training loss: 5.325677841098078
Validation loss: 5.092528370282103

Epoch: 5| Step: 11
Training loss: 6.198674447887118
Validation loss: 5.087095965651139

Epoch: 14| Step: 0
Training loss: 4.990828303696935
Validation loss: 5.082696150362641

Epoch: 5| Step: 1
Training loss: 5.179128855503047
Validation loss: 5.076934408832492

Epoch: 5| Step: 2
Training loss: 5.162349907492015
Validation loss: 5.072773465975521

Epoch: 5| Step: 3
Training loss: 4.803960580808599
Validation loss: 5.067630005322963

Epoch: 5| Step: 4
Training loss: 6.021303503912626
Validation loss: 5.0622615915055516

Epoch: 5| Step: 5
Training loss: 5.5456044635889015
Validation loss: 5.057397877304354

Epoch: 5| Step: 6
Training loss: 5.147203311975781
Validation loss: 5.052113989773054

Epoch: 5| Step: 7
Training loss: 5.95670081050731
Validation loss: 5.046444302694659

Epoch: 5| Step: 8
Training loss: 4.193706865842119
Validation loss: 5.041820471232973

Epoch: 5| Step: 9
Training loss: 5.08477329225146
Validation loss: 5.036933374208257

Epoch: 5| Step: 10
Training loss: 4.7809773286346955
Validation loss: 5.03170900640188

Epoch: 5| Step: 11
Training loss: 4.523158353055574
Validation loss: 5.027101698124024

Epoch: 15| Step: 0
Training loss: 4.594718779051591
Validation loss: 5.021558965057035

Epoch: 5| Step: 1
Training loss: 5.75091346450888
Validation loss: 5.017090936739541

Epoch: 5| Step: 2
Training loss: 5.157455395918483
Validation loss: 5.012261416559344

Epoch: 5| Step: 3
Training loss: 5.677072208871937
Validation loss: 5.007025773435317

Epoch: 5| Step: 4
Training loss: 5.067936556604913
Validation loss: 5.002262096502188

Epoch: 5| Step: 5
Training loss: 4.413150875511103
Validation loss: 4.9969244160295165

Epoch: 5| Step: 6
Training loss: 5.972645711546458
Validation loss: 4.991924280939332

Epoch: 5| Step: 7
Training loss: 4.783514944919842
Validation loss: 4.987024820648329

Epoch: 5| Step: 8
Training loss: 4.804880823727537
Validation loss: 4.98188925438008

Epoch: 5| Step: 9
Training loss: 4.81004964695804
Validation loss: 4.976905527474346

Epoch: 5| Step: 10
Training loss: 4.810475109213973
Validation loss: 4.97188888026773

Epoch: 5| Step: 11
Training loss: 6.287335384936593
Validation loss: 4.967606642867377

Epoch: 16| Step: 0
Training loss: 4.261595670914067
Validation loss: 4.962494012747355

Epoch: 5| Step: 1
Training loss: 5.094028207869324
Validation loss: 4.957251962448102

Epoch: 5| Step: 2
Training loss: 4.820170643108657
Validation loss: 4.95274249664699

Epoch: 5| Step: 3
Training loss: 5.951819890055655
Validation loss: 4.946920718963576

Epoch: 5| Step: 4
Training loss: 4.446165837608577
Validation loss: 4.942405621739113

Epoch: 5| Step: 5
Training loss: 4.60223021139764
Validation loss: 4.93657737674795

Epoch: 5| Step: 6
Training loss: 5.498892065642401
Validation loss: 4.931615920807555

Epoch: 5| Step: 7
Training loss: 5.184157984021696
Validation loss: 4.92711096091183

Epoch: 5| Step: 8
Training loss: 5.0598412584577215
Validation loss: 4.921785400220945

Epoch: 5| Step: 9
Training loss: 4.704572993328996
Validation loss: 4.916034377654274

Epoch: 5| Step: 10
Training loss: 5.546588041377945
Validation loss: 4.91160645030665

Epoch: 5| Step: 11
Training loss: 6.230445483890729
Validation loss: 4.906293079162796

Epoch: 17| Step: 0
Training loss: 5.1095398109289425
Validation loss: 4.900595903816603

Epoch: 5| Step: 1
Training loss: 4.093264951435038
Validation loss: 4.896513492602645

Epoch: 5| Step: 2
Training loss: 5.541519201319594
Validation loss: 4.890846710542103

Epoch: 5| Step: 3
Training loss: 5.6732949405242215
Validation loss: 4.885655080783937

Epoch: 5| Step: 4
Training loss: 4.982732137353191
Validation loss: 4.880178399199449

Epoch: 5| Step: 5
Training loss: 4.827617729723009
Validation loss: 4.87518452841231

Epoch: 5| Step: 6
Training loss: 4.892806569018049
Validation loss: 4.869346980498741

Epoch: 5| Step: 7
Training loss: 4.7130650512945795
Validation loss: 4.8649739905691565

Epoch: 5| Step: 8
Training loss: 5.206431028738097
Validation loss: 4.859439649080312

Epoch: 5| Step: 9
Training loss: 4.439586310144742
Validation loss: 4.854177780575234

Epoch: 5| Step: 10
Training loss: 5.245954498919747
Validation loss: 4.850165214542988

Epoch: 5| Step: 11
Training loss: 5.396361375498374
Validation loss: 4.845859355424771

Epoch: 18| Step: 0
Training loss: 5.392517465307596
Validation loss: 4.83867098413399

Epoch: 5| Step: 1
Training loss: 4.488462067656146
Validation loss: 4.833475763042003

Epoch: 5| Step: 2
Training loss: 5.188391183803692
Validation loss: 4.828416500735947

Epoch: 5| Step: 3
Training loss: 5.0449360527167215
Validation loss: 4.822696320984059

Epoch: 5| Step: 4
Training loss: 4.409437825534663
Validation loss: 4.818058354490045

Epoch: 5| Step: 5
Training loss: 5.007446085220161
Validation loss: 4.812730560724782

Epoch: 5| Step: 6
Training loss: 4.754342353019689
Validation loss: 4.807333365025668

Epoch: 5| Step: 7
Training loss: 5.256293021988768
Validation loss: 4.80217742689823

Epoch: 5| Step: 8
Training loss: 5.657704540403635
Validation loss: 4.796775502054181

Epoch: 5| Step: 9
Training loss: 4.948544667862864
Validation loss: 4.791784544890779

Epoch: 5| Step: 10
Training loss: 4.030209192568576
Validation loss: 4.785732100734209

Epoch: 5| Step: 11
Training loss: 4.636958976506552
Validation loss: 4.781598604080632

Epoch: 19| Step: 0
Training loss: 5.105178462840566
Validation loss: 4.77683710971239

Epoch: 5| Step: 1
Training loss: 4.555616647160807
Validation loss: 4.770618507457133

Epoch: 5| Step: 2
Training loss: 4.950025292534223
Validation loss: 4.766368812089289

Epoch: 5| Step: 3
Training loss: 4.514739164166517
Validation loss: 4.761682966607412

Epoch: 5| Step: 4
Training loss: 4.4093642896363985
Validation loss: 4.755536867834868

Epoch: 5| Step: 5
Training loss: 5.502861492340311
Validation loss: 4.7507544763244836

Epoch: 5| Step: 6
Training loss: 5.64528305168506
Validation loss: 4.745296952455885

Epoch: 5| Step: 7
Training loss: 4.538774018304216
Validation loss: 4.7407717489899595

Epoch: 5| Step: 8
Training loss: 5.149213393794153
Validation loss: 4.734619658876698

Epoch: 5| Step: 9
Training loss: 4.6160470034819285
Validation loss: 4.729225556039149

Epoch: 5| Step: 10
Training loss: 4.2197415917271694
Validation loss: 4.724295992772032

Epoch: 5| Step: 11
Training loss: 5.936469380125857
Validation loss: 4.720656567681847

Epoch: 20| Step: 0
Training loss: 4.193416003416542
Validation loss: 4.716241923686835

Epoch: 5| Step: 1
Training loss: 4.579802013932087
Validation loss: 4.710746242506106

Epoch: 5| Step: 2
Training loss: 4.1503628215980495
Validation loss: 4.705173937480613

Epoch: 5| Step: 3
Training loss: 4.52383046922161
Validation loss: 4.700395216456532

Epoch: 5| Step: 4
Training loss: 4.739511253172136
Validation loss: 4.6940253297636785

Epoch: 5| Step: 5
Training loss: 4.6235274986488095
Validation loss: 4.6885920630018365

Epoch: 5| Step: 6
Training loss: 4.592673246867257
Validation loss: 4.68402092570803

Epoch: 5| Step: 7
Training loss: 5.444713149068073
Validation loss: 4.677955621147337

Epoch: 5| Step: 8
Training loss: 5.63018475109129
Validation loss: 4.67375578175388

Epoch: 5| Step: 9
Training loss: 5.070740950575349
Validation loss: 4.66827466486372

Epoch: 5| Step: 10
Training loss: 5.218513529097068
Validation loss: 4.662727467337862

Epoch: 5| Step: 11
Training loss: 4.605222117879319
Validation loss: 4.657519805287302

Epoch: 21| Step: 0
Training loss: 4.961377318102114
Validation loss: 4.653123219636807

Epoch: 5| Step: 1
Training loss: 3.9814122572671238
Validation loss: 4.647116157518195

Epoch: 5| Step: 2
Training loss: 5.252278696270401
Validation loss: 4.641881539298364

Epoch: 5| Step: 3
Training loss: 4.533559066163855
Validation loss: 4.636618189161777

Epoch: 5| Step: 4
Training loss: 5.025939413292204
Validation loss: 4.6315172088318715

Epoch: 5| Step: 5
Training loss: 4.088558953445077
Validation loss: 4.625866795840714

Epoch: 5| Step: 6
Training loss: 4.746718025751183
Validation loss: 4.620382521331706

Epoch: 5| Step: 7
Training loss: 4.767217251295028
Validation loss: 4.615653207495159

Epoch: 5| Step: 8
Training loss: 4.95345346222134
Validation loss: 4.61026749241003

Epoch: 5| Step: 9
Training loss: 5.5048127358554115
Validation loss: 4.604856623510286

Epoch: 5| Step: 10
Training loss: 4.233190617195695
Validation loss: 4.600176133363496

Epoch: 5| Step: 11
Training loss: 4.77200041020944
Validation loss: 4.594820931438799

Epoch: 22| Step: 0
Training loss: 5.113201050388049
Validation loss: 4.589887331491895

Epoch: 5| Step: 1
Training loss: 4.621945996670945
Validation loss: 4.584443103931903

Epoch: 5| Step: 2
Training loss: 4.514301462473657
Validation loss: 4.578632313608532

Epoch: 5| Step: 3
Training loss: 4.879050503897257
Validation loss: 4.573291240404357

Epoch: 5| Step: 4
Training loss: 5.218616598103184
Validation loss: 4.567898917780315

Epoch: 5| Step: 5
Training loss: 4.718676635980293
Validation loss: 4.563052618621913

Epoch: 5| Step: 6
Training loss: 4.8882216133039105
Validation loss: 4.557188556776264

Epoch: 5| Step: 7
Training loss: 4.19798060416602
Validation loss: 4.552024922407159

Epoch: 5| Step: 8
Training loss: 4.620310080885294
Validation loss: 4.546981216011542

Epoch: 5| Step: 9
Training loss: 4.687967505983612
Validation loss: 4.541208658251582

Epoch: 5| Step: 10
Training loss: 4.448523998859916
Validation loss: 4.535275120673675

Epoch: 5| Step: 11
Training loss: 1.968580026706677
Validation loss: 4.530445141398311

Epoch: 23| Step: 0
Training loss: 3.857995531909149
Validation loss: 4.525596643597951

Epoch: 5| Step: 1
Training loss: 4.699324076321188
Validation loss: 4.521945274596084

Epoch: 5| Step: 2
Training loss: 5.185688299919394
Validation loss: 4.516545022696505

Epoch: 5| Step: 3
Training loss: 5.210379277516769
Validation loss: 4.510179617674931

Epoch: 5| Step: 4
Training loss: 5.165723755637313
Validation loss: 4.505227205387639

Epoch: 5| Step: 5
Training loss: 4.305109076098362
Validation loss: 4.50037749791036

Epoch: 5| Step: 6
Training loss: 4.294971835273882
Validation loss: 4.494713379969017

Epoch: 5| Step: 7
Training loss: 4.182419613044592
Validation loss: 4.488998670043431

Epoch: 5| Step: 8
Training loss: 4.310626742647606
Validation loss: 4.483636398719678

Epoch: 5| Step: 9
Training loss: 4.992750825574456
Validation loss: 4.4795663684850995

Epoch: 5| Step: 10
Training loss: 4.355504440366662
Validation loss: 4.473743667455944

Epoch: 5| Step: 11
Training loss: 5.202982949273865
Validation loss: 4.467788161512338

Epoch: 24| Step: 0
Training loss: 4.752987775257585
Validation loss: 4.462792077287684

Epoch: 5| Step: 1
Training loss: 4.414723142624619
Validation loss: 4.457611322615684

Epoch: 5| Step: 2
Training loss: 4.68032776491781
Validation loss: 4.451337145350719

Epoch: 5| Step: 3
Training loss: 5.09065217911857
Validation loss: 4.446640245429664

Epoch: 5| Step: 4
Training loss: 4.316507219195198
Validation loss: 4.44013688270247

Epoch: 5| Step: 5
Training loss: 4.3090943973353015
Validation loss: 4.434329794397247

Epoch: 5| Step: 6
Training loss: 5.0002914343776945
Validation loss: 4.4288915539144025

Epoch: 5| Step: 7
Training loss: 4.482070383822315
Validation loss: 4.423226032167781

Epoch: 5| Step: 8
Training loss: 4.160878522614672
Validation loss: 4.417118736139368

Epoch: 5| Step: 9
Training loss: 4.460447053955756
Validation loss: 4.411396141769835

Epoch: 5| Step: 10
Training loss: 4.527057681454998
Validation loss: 4.406205896287602

Epoch: 5| Step: 11
Training loss: 4.185215113134914
Validation loss: 4.40039363205727

Epoch: 25| Step: 0
Training loss: 4.68884746258009
Validation loss: 4.394467230436459

Epoch: 5| Step: 1
Training loss: 3.8174632550202987
Validation loss: 4.388705851196004

Epoch: 5| Step: 2
Training loss: 4.879977497299092
Validation loss: 4.382057950033765

Epoch: 5| Step: 3
Training loss: 4.8642739872183895
Validation loss: 4.3765603961279

Epoch: 5| Step: 4
Training loss: 4.495423002611891
Validation loss: 4.370967650675552

Epoch: 5| Step: 5
Training loss: 4.647658031089443
Validation loss: 4.364942752845807

Epoch: 5| Step: 6
Training loss: 4.2817556263636165
Validation loss: 4.35854666256488

Epoch: 5| Step: 7
Training loss: 4.916843130964391
Validation loss: 4.353170206346856

Epoch: 5| Step: 8
Training loss: 3.7753913828083823
Validation loss: 4.347141748393759

Epoch: 5| Step: 9
Training loss: 4.354668157922599
Validation loss: 4.340865808283563

Epoch: 5| Step: 10
Training loss: 4.1457710964317345
Validation loss: 4.334907698127116

Epoch: 5| Step: 11
Training loss: 6.17906893830583
Validation loss: 4.330251155430779

Epoch: 26| Step: 0
Training loss: 3.677607699748508
Validation loss: 4.3233751107527985

Epoch: 5| Step: 1
Training loss: 3.859557236295596
Validation loss: 4.318389298962072

Epoch: 5| Step: 2
Training loss: 4.353375863475541
Validation loss: 4.312667161585819

Epoch: 5| Step: 3
Training loss: 3.6938301968461307
Validation loss: 4.306439485704145

Epoch: 5| Step: 4
Training loss: 4.185344084127261
Validation loss: 4.300758257812243

Epoch: 5| Step: 5
Training loss: 4.392429184752602
Validation loss: 4.29500642779709

Epoch: 5| Step: 6
Training loss: 4.290011608401512
Validation loss: 4.2890587154110005

Epoch: 5| Step: 7
Training loss: 4.862793336468569
Validation loss: 4.28376532774603

Epoch: 5| Step: 8
Training loss: 4.959149376316577
Validation loss: 4.279044244396193

Epoch: 5| Step: 9
Training loss: 4.7222226735033805
Validation loss: 4.272209497809563

Epoch: 5| Step: 10
Training loss: 5.124438371356042
Validation loss: 4.2672494955272455

Epoch: 5| Step: 11
Training loss: 5.5205308747362345
Validation loss: 4.261079679102703

Epoch: 27| Step: 0
Training loss: 4.494012239786685
Validation loss: 4.254171652172928

Epoch: 5| Step: 1
Training loss: 4.3717600133142795
Validation loss: 4.248086844654516

Epoch: 5| Step: 2
Training loss: 4.704536707706219
Validation loss: 4.242093328153124

Epoch: 5| Step: 3
Training loss: 4.767183442990838
Validation loss: 4.23603122128612

Epoch: 5| Step: 4
Training loss: 4.128170759942251
Validation loss: 4.229546781974548

Epoch: 5| Step: 5
Training loss: 3.87643172363709
Validation loss: 4.223922393808994

Epoch: 5| Step: 6
Training loss: 4.276221001690377
Validation loss: 4.218731501032455

Epoch: 5| Step: 7
Training loss: 4.43757070565644
Validation loss: 4.213117093203933

Epoch: 5| Step: 8
Training loss: 4.894885075499092
Validation loss: 4.207629488008148

Epoch: 5| Step: 9
Training loss: 4.272828220820335
Validation loss: 4.201278432159478

Epoch: 5| Step: 10
Training loss: 3.6706954035282466
Validation loss: 4.194138730334621

Epoch: 5| Step: 11
Training loss: 3.6683098550126343
Validation loss: 4.18888957657852

Epoch: 28| Step: 0
Training loss: 5.389127927025186
Validation loss: 4.183438233786557

Epoch: 5| Step: 1
Training loss: 4.476673277970519
Validation loss: 4.177883564629043

Epoch: 5| Step: 2
Training loss: 4.611216031965649
Validation loss: 4.1712100943338

Epoch: 5| Step: 3
Training loss: 4.012865832993113
Validation loss: 4.16516041550938

Epoch: 5| Step: 4
Training loss: 4.112554560244317
Validation loss: 4.158629814057026

Epoch: 5| Step: 5
Training loss: 4.203994377444615
Validation loss: 4.153198857508225

Epoch: 5| Step: 6
Training loss: 4.392656284042302
Validation loss: 4.14748054477604

Epoch: 5| Step: 7
Training loss: 4.419713654714845
Validation loss: 4.141942549957144

Epoch: 5| Step: 8
Training loss: 3.9282796776179185
Validation loss: 4.136129253819623

Epoch: 5| Step: 9
Training loss: 3.4694449613509866
Validation loss: 4.130650768017838

Epoch: 5| Step: 10
Training loss: 3.770967358197278
Validation loss: 4.1235808426242295

Epoch: 5| Step: 11
Training loss: 4.724945649333986
Validation loss: 4.119064014410322

Epoch: 29| Step: 0
Training loss: 4.557506807607818
Validation loss: 4.1143938318708475

Epoch: 5| Step: 1
Training loss: 4.182965228741257
Validation loss: 4.109028684385222

Epoch: 5| Step: 2
Training loss: 3.9815362129753855
Validation loss: 4.103083156073081

Epoch: 5| Step: 3
Training loss: 3.770407777381547
Validation loss: 4.0963371197280525

Epoch: 5| Step: 4
Training loss: 4.215695327839521
Validation loss: 4.091008469549759

Epoch: 5| Step: 5
Training loss: 3.9632834685845975
Validation loss: 4.08575143384353

Epoch: 5| Step: 6
Training loss: 4.19963955922031
Validation loss: 4.080756078005311

Epoch: 5| Step: 7
Training loss: 4.031694727770158
Validation loss: 4.0756368927279265

Epoch: 5| Step: 8
Training loss: 4.273443971730131
Validation loss: 4.069360603420715

Epoch: 5| Step: 9
Training loss: 4.417032454596192
Validation loss: 4.062740602459844

Epoch: 5| Step: 10
Training loss: 4.2776783990807346
Validation loss: 4.058285600837149

Epoch: 5| Step: 11
Training loss: 6.118541816076616
Validation loss: 4.052298124189003

Epoch: 30| Step: 0
Training loss: 4.049706606186602
Validation loss: 4.045963454715843

Epoch: 5| Step: 1
Training loss: 4.098390235293847
Validation loss: 4.040888803224185

Epoch: 5| Step: 2
Training loss: 4.59892759676462
Validation loss: 4.034695008398226

Epoch: 5| Step: 3
Training loss: 4.586676516928926
Validation loss: 4.029069330419784

Epoch: 5| Step: 4
Training loss: 3.9724734403995927
Validation loss: 4.023047507930787

Epoch: 5| Step: 5
Training loss: 2.690296492420969
Validation loss: 4.016926575531353

Epoch: 5| Step: 6
Training loss: 4.766964583434796
Validation loss: 4.011452863846845

Epoch: 5| Step: 7
Training loss: 3.5156415472700857
Validation loss: 4.005269543296203

Epoch: 5| Step: 8
Training loss: 4.42311623342135
Validation loss: 4.000434330367281

Epoch: 5| Step: 9
Training loss: 4.3870561424125505
Validation loss: 3.99521666864272

Epoch: 5| Step: 10
Training loss: 4.008482997793993
Validation loss: 3.989688332406875

Epoch: 5| Step: 11
Training loss: 4.782562474641867
Validation loss: 3.9800481452378125

Epoch: 31| Step: 0
Training loss: 4.013627679957412
Validation loss: 3.974036618016185

Epoch: 5| Step: 1
Training loss: 3.971221394638478
Validation loss: 3.969029594444969

Epoch: 5| Step: 2
Training loss: 4.5482333012632195
Validation loss: 3.9620454431216334

Epoch: 5| Step: 3
Training loss: 3.8860927671942234
Validation loss: 3.9545676924755555

Epoch: 5| Step: 4
Training loss: 4.200735100493898
Validation loss: 3.950152766215108

Epoch: 5| Step: 5
Training loss: 4.356323705676346
Validation loss: 3.9447971171034286

Epoch: 5| Step: 6
Training loss: 3.912102793070474
Validation loss: 3.9399547796510546

Epoch: 5| Step: 7
Training loss: 4.7720395802393645
Validation loss: 3.9333726605507504

Epoch: 5| Step: 8
Training loss: 3.1330975714380296
Validation loss: 3.9265248393104524

Epoch: 5| Step: 9
Training loss: 4.598120031568014
Validation loss: 3.9218421924530937

Epoch: 5| Step: 10
Training loss: 3.3788013949138787
Validation loss: 3.9154247418437707

Epoch: 5| Step: 11
Training loss: 2.846013436452602
Validation loss: 3.9092500940621995

Epoch: 32| Step: 0
Training loss: 3.6688668123589077
Validation loss: 3.9044332221253537

Epoch: 5| Step: 1
Training loss: 4.426052317520845
Validation loss: 3.900337113172695

Epoch: 5| Step: 2
Training loss: 4.315720171365862
Validation loss: 3.8936382100083478

Epoch: 5| Step: 3
Training loss: 4.560346330239996
Validation loss: 3.887468454206394

Epoch: 5| Step: 4
Training loss: 3.705321614132862
Validation loss: 3.8824520186803917

Epoch: 5| Step: 5
Training loss: 4.561871838111895
Validation loss: 3.8769583675627732

Epoch: 5| Step: 6
Training loss: 4.16494048919843
Validation loss: 3.871749971150146

Epoch: 5| Step: 7
Training loss: 3.580100234775563
Validation loss: 3.8658512825346008

Epoch: 5| Step: 8
Training loss: 3.4605762301744827
Validation loss: 3.8599794200239885

Epoch: 5| Step: 9
Training loss: 4.066745359149268
Validation loss: 3.8543224286058733

Epoch: 5| Step: 10
Training loss: 3.269353608805444
Validation loss: 3.8484386081154462

Epoch: 5| Step: 11
Training loss: 4.4394181095325
Validation loss: 3.8437969856181713

Epoch: 33| Step: 0
Training loss: 3.8472977059706075
Validation loss: 3.837349905502034

Epoch: 5| Step: 1
Training loss: 3.9911159562881764
Validation loss: 3.83281101248031

Epoch: 5| Step: 2
Training loss: 4.212093498923873
Validation loss: 3.8281826767501475

Epoch: 5| Step: 3
Training loss: 3.8561674681105664
Validation loss: 3.82283777507209

Epoch: 5| Step: 4
Training loss: 4.18415425568025
Validation loss: 3.8170568353517242

Epoch: 5| Step: 5
Training loss: 4.2702392661176
Validation loss: 3.811241134886807

Epoch: 5| Step: 6
Training loss: 3.434378437738199
Validation loss: 3.8050317993623164

Epoch: 5| Step: 7
Training loss: 4.094763710368402
Validation loss: 3.800426512339738

Epoch: 5| Step: 8
Training loss: 4.15746685370412
Validation loss: 3.7952444031428727

Epoch: 5| Step: 9
Training loss: 3.482154857349329
Validation loss: 3.789240263344492

Epoch: 5| Step: 10
Training loss: 4.131320388355896
Validation loss: 3.7839369671822602

Epoch: 5| Step: 11
Training loss: 1.4072959400999672
Validation loss: 3.779419037966236

Epoch: 34| Step: 0
Training loss: 4.243478146639365
Validation loss: 3.7761811890531147

Epoch: 5| Step: 1
Training loss: 4.279125939719862
Validation loss: 3.7721311678701728

Epoch: 5| Step: 2
Training loss: 3.970996611294709
Validation loss: 3.765742335727239

Epoch: 5| Step: 3
Training loss: 3.9246653323030047
Validation loss: 3.759148907964443

Epoch: 5| Step: 4
Training loss: 4.086107881396208
Validation loss: 3.7545588544993698

Epoch: 5| Step: 5
Training loss: 3.629732791324118
Validation loss: 3.750085591293115

Epoch: 5| Step: 6
Training loss: 4.0417230870874015
Validation loss: 3.745552010557306

Epoch: 5| Step: 7
Training loss: 3.718095866140626
Validation loss: 3.739156133677848

Epoch: 5| Step: 8
Training loss: 3.258911532900588
Validation loss: 3.7339022349128377

Epoch: 5| Step: 9
Training loss: 4.325263774964767
Validation loss: 3.729623482427365

Epoch: 5| Step: 10
Training loss: 3.146181723058806
Validation loss: 3.7242208997377335

Epoch: 5| Step: 11
Training loss: 3.556046245081152
Validation loss: 3.720046770970823

Epoch: 35| Step: 0
Training loss: 4.347228050566569
Validation loss: 3.715631604008304

Epoch: 5| Step: 1
Training loss: 4.116249744960894
Validation loss: 3.710602583913596

Epoch: 5| Step: 2
Training loss: 3.688216446927594
Validation loss: 3.7044504532526603

Epoch: 5| Step: 3
Training loss: 3.397377989025858
Validation loss: 3.7001066823992876

Epoch: 5| Step: 4
Training loss: 3.6800115811124265
Validation loss: 3.695966010882133

Epoch: 5| Step: 5
Training loss: 3.9063558335272432
Validation loss: 3.6912257612935155

Epoch: 5| Step: 6
Training loss: 3.4259641418005704
Validation loss: 3.686762558211374

Epoch: 5| Step: 7
Training loss: 3.4227578056435353
Validation loss: 3.6808623606886197

Epoch: 5| Step: 8
Training loss: 3.713461056013159
Validation loss: 3.6767363866390297

Epoch: 5| Step: 9
Training loss: 4.010621036755264
Validation loss: 3.671921758151112

Epoch: 5| Step: 10
Training loss: 4.081566305010525
Validation loss: 3.6677347148512367

Epoch: 5| Step: 11
Training loss: 4.6645190656061555
Validation loss: 3.6628083425840585

Epoch: 36| Step: 0
Training loss: 3.7828561193384953
Validation loss: 3.657288140396914

Epoch: 5| Step: 1
Training loss: 3.6222148587698744
Validation loss: 3.6518155727527084

Epoch: 5| Step: 2
Training loss: 3.657866161528037
Validation loss: 3.647811492864881

Epoch: 5| Step: 3
Training loss: 4.063337034412061
Validation loss: 3.641891087433828

Epoch: 5| Step: 4
Training loss: 3.5432558122147286
Validation loss: 3.637377604493294

Epoch: 5| Step: 5
Training loss: 3.69301864690383
Validation loss: 3.6330323894497885

Epoch: 5| Step: 6
Training loss: 4.135384637178519
Validation loss: 3.627786475221945

Epoch: 5| Step: 7
Training loss: 3.383660683666786
Validation loss: 3.6225530159271404

Epoch: 5| Step: 8
Training loss: 3.5195239339026347
Validation loss: 3.617744512767917

Epoch: 5| Step: 9
Training loss: 3.8509451659644087
Validation loss: 3.614071596329068

Epoch: 5| Step: 10
Training loss: 3.920375582938924
Validation loss: 3.609224632841133

Epoch: 5| Step: 11
Training loss: 4.719658568366268
Validation loss: 3.604749024297013

Epoch: 37| Step: 0
Training loss: 3.4450981090732578
Validation loss: 3.6002564617040984

Epoch: 5| Step: 1
Training loss: 4.880273949484955
Validation loss: 3.595265055308434

Epoch: 5| Step: 2
Training loss: 3.607867566031691
Validation loss: 3.5896302202247017

Epoch: 5| Step: 3
Training loss: 3.9336325407719914
Validation loss: 3.5847062855495633

Epoch: 5| Step: 4
Training loss: 3.4415647576294464
Validation loss: 3.580919132626653

Epoch: 5| Step: 5
Training loss: 3.001717393761731
Validation loss: 3.5750394396618246

Epoch: 5| Step: 6
Training loss: 3.5669735042699116
Validation loss: 3.570393512009847

Epoch: 5| Step: 7
Training loss: 3.1233087159132866
Validation loss: 3.5653697440420467

Epoch: 5| Step: 8
Training loss: 3.2309568467701513
Validation loss: 3.561755743976066

Epoch: 5| Step: 9
Training loss: 4.027987083755286
Validation loss: 3.5580367103530137

Epoch: 5| Step: 10
Training loss: 4.018707873181466
Validation loss: 3.5532763967521013

Epoch: 5| Step: 11
Training loss: 4.5599157251969515
Validation loss: 3.5485493241314487

Epoch: 38| Step: 0
Training loss: 3.399478165466775
Validation loss: 3.543627334615667

Epoch: 5| Step: 1
Training loss: 3.8647904798955417
Validation loss: 3.5394948620860176

Epoch: 5| Step: 2
Training loss: 4.062752114322462
Validation loss: 3.5344415606126156

Epoch: 5| Step: 3
Training loss: 3.8196158368737017
Validation loss: 3.5299000874591266

Epoch: 5| Step: 4
Training loss: 3.920274993242699
Validation loss: 3.52556800572155

Epoch: 5| Step: 5
Training loss: 3.6702774793205375
Validation loss: 3.5210106633841134

Epoch: 5| Step: 6
Training loss: 3.9512489903420662
Validation loss: 3.516206080133824

Epoch: 5| Step: 7
Training loss: 3.5098327392546707
Validation loss: 3.5113298415072567

Epoch: 5| Step: 8
Training loss: 3.3162467927194696
Validation loss: 3.5075471150375837

Epoch: 5| Step: 9
Training loss: 3.823019928884487
Validation loss: 3.5026400463814396

Epoch: 5| Step: 10
Training loss: 2.9218596595728648
Validation loss: 3.4981580553645064

Epoch: 5| Step: 11
Training loss: 2.6750196723571134
Validation loss: 3.4940155331015794

Epoch: 39| Step: 0
Training loss: 3.669147533603964
Validation loss: 3.4894144539274015

Epoch: 5| Step: 1
Training loss: 3.3162385967819223
Validation loss: 3.4851842262726036

Epoch: 5| Step: 2
Training loss: 3.637330623497984
Validation loss: 3.4814434920025774

Epoch: 5| Step: 3
Training loss: 3.652646367393029
Validation loss: 3.4779010067651908

Epoch: 5| Step: 4
Training loss: 3.7159998365387814
Validation loss: 3.473664476738119

Epoch: 5| Step: 5
Training loss: 3.37903297495381
Validation loss: 3.4689833301962176

Epoch: 5| Step: 6
Training loss: 3.3170276145119097
Validation loss: 3.46468828003732

Epoch: 5| Step: 7
Training loss: 3.459526101441875
Validation loss: 3.4627718689061586

Epoch: 5| Step: 8
Training loss: 3.9871943054691266
Validation loss: 3.4581935789220046

Epoch: 5| Step: 9
Training loss: 3.5977499553062
Validation loss: 3.4529190174651925

Epoch: 5| Step: 10
Training loss: 3.7814742092779863
Validation loss: 3.4482968438677584

Epoch: 5| Step: 11
Training loss: 4.057723303553746
Validation loss: 3.445582170954307

Epoch: 40| Step: 0
Training loss: 2.96484342833908
Validation loss: 3.4415558902625394

Epoch: 5| Step: 1
Training loss: 3.9044452618047036
Validation loss: 3.4365213619456085

Epoch: 5| Step: 2
Training loss: 4.257516609199817
Validation loss: 3.4310781430053465

Epoch: 5| Step: 3
Training loss: 3.3772010690136405
Validation loss: 3.4269141712972915

Epoch: 5| Step: 4
Training loss: 3.93465041938029
Validation loss: 3.423259515980191

Epoch: 5| Step: 5
Training loss: 4.136543075678453
Validation loss: 3.4187599123869767

Epoch: 5| Step: 6
Training loss: 3.043293104403768
Validation loss: 3.4149789518542666

Epoch: 5| Step: 7
Training loss: 2.8168064631996015
Validation loss: 3.4106602829733492

Epoch: 5| Step: 8
Training loss: 3.2437234572425298
Validation loss: 3.4062385325574183

Epoch: 5| Step: 9
Training loss: 3.77841042070763
Validation loss: 3.401603954076024

Epoch: 5| Step: 10
Training loss: 3.3534153793895074
Validation loss: 3.3972445853391346

Epoch: 5| Step: 11
Training loss: 3.5117029989566118
Validation loss: 3.3929499347565315

Epoch: 41| Step: 0
Training loss: 3.3738279780124723
Validation loss: 3.390753244063729

Epoch: 5| Step: 1
Training loss: 3.687737925984192
Validation loss: 3.386315104282446

Epoch: 5| Step: 2
Training loss: 3.5362984008281466
Validation loss: 3.3812355406681758

Epoch: 5| Step: 3
Training loss: 3.5779096380330357
Validation loss: 3.37769502602366

Epoch: 5| Step: 4
Training loss: 3.8499348820715666
Validation loss: 3.3736873210866722

Epoch: 5| Step: 5
Training loss: 3.5043094534856043
Validation loss: 3.369244259332288

Epoch: 5| Step: 6
Training loss: 3.5921124251768433
Validation loss: 3.365130156653963

Epoch: 5| Step: 7
Training loss: 3.607515855359125
Validation loss: 3.3605378407962125

Epoch: 5| Step: 8
Training loss: 3.107756687159874
Validation loss: 3.3564661665575573

Epoch: 5| Step: 9
Training loss: 3.492148584750665
Validation loss: 3.352568978423302

Epoch: 5| Step: 10
Training loss: 3.0630022532385976
Validation loss: 3.3488142280167157

Epoch: 5| Step: 11
Training loss: 4.0997940756094495
Validation loss: 3.3435374159691524

Epoch: 42| Step: 0
Training loss: 3.7708496318204974
Validation loss: 3.3407435582589917

Epoch: 5| Step: 1
Training loss: 3.1074757358527476
Validation loss: 3.3356347166256652

Epoch: 5| Step: 2
Training loss: 3.2898945605417844
Validation loss: 3.331379786880205

Epoch: 5| Step: 3
Training loss: 4.1195075720416385
Validation loss: 3.3274379373251564

Epoch: 5| Step: 4
Training loss: 3.747698904386783
Validation loss: 3.3230761287458788

Epoch: 5| Step: 5
Training loss: 3.2524099951216465
Validation loss: 3.319091985435242

Epoch: 5| Step: 6
Training loss: 3.460996330226219
Validation loss: 3.3146063687339087

Epoch: 5| Step: 7
Training loss: 2.9467604743329274
Validation loss: 3.312155855643537

Epoch: 5| Step: 8
Training loss: 3.0720823200540974
Validation loss: 3.307523065516866

Epoch: 5| Step: 9
Training loss: 3.566759206932026
Validation loss: 3.303656902091215

Epoch: 5| Step: 10
Training loss: 3.5128860315805897
Validation loss: 3.3002686412878064

Epoch: 5| Step: 11
Training loss: 3.6550396603208104
Validation loss: 3.2954139485245286

Epoch: 43| Step: 0
Training loss: 3.799356160080302
Validation loss: 3.2928841347342215

Epoch: 5| Step: 1
Training loss: 3.1010318946022357
Validation loss: 3.2893116359030516

Epoch: 5| Step: 2
Training loss: 3.4565477625801093
Validation loss: 3.28464467181348

Epoch: 5| Step: 3
Training loss: 4.34545491742016
Validation loss: 3.282002408183096

Epoch: 5| Step: 4
Training loss: 3.0350393618901643
Validation loss: 3.276948367712703

Epoch: 5| Step: 5
Training loss: 3.3845513436120873
Validation loss: 3.272778677667106

Epoch: 5| Step: 6
Training loss: 2.970837311030895
Validation loss: 3.268833026597401

Epoch: 5| Step: 7
Training loss: 3.5976873970133116
Validation loss: 3.265552428684884

Epoch: 5| Step: 8
Training loss: 3.3574982834710045
Validation loss: 3.2613067366729918

Epoch: 5| Step: 9
Training loss: 3.1436661756499817
Validation loss: 3.257934183825857

Epoch: 5| Step: 10
Training loss: 3.0476159393061955
Validation loss: 3.253976556293941

Epoch: 5| Step: 11
Training loss: 3.748696545725081
Validation loss: 3.250701617654696

Epoch: 44| Step: 0
Training loss: 3.6794331132625775
Validation loss: 3.24629197967143

Epoch: 5| Step: 1
Training loss: 3.2471832393427023
Validation loss: 3.2425973809304707

Epoch: 5| Step: 2
Training loss: 3.389089772953166
Validation loss: 3.238403845637976

Epoch: 5| Step: 3
Training loss: 3.3142016376673866
Validation loss: 3.23577076132222

Epoch: 5| Step: 4
Training loss: 3.054533425272337
Validation loss: 3.231846587435443

Epoch: 5| Step: 5
Training loss: 3.340874264216509
Validation loss: 3.228755473546887

Epoch: 5| Step: 6
Training loss: 3.459892855843021
Validation loss: 3.224637316978029

Epoch: 5| Step: 7
Training loss: 3.6611016842751773
Validation loss: 3.221376717605953

Epoch: 5| Step: 8
Training loss: 3.1196154171551576
Validation loss: 3.217669657537246

Epoch: 5| Step: 9
Training loss: 3.3501458719862374
Validation loss: 3.2139881087716002

Epoch: 5| Step: 10
Training loss: 3.5201403295114706
Validation loss: 3.210399752817193

Epoch: 5| Step: 11
Training loss: 2.4961317653477404
Validation loss: 3.2066133562191688

Epoch: 45| Step: 0
Training loss: 3.2263453967043656
Validation loss: 3.2027871798880665

Epoch: 5| Step: 1
Training loss: 3.605417567393008
Validation loss: 3.199492356272495

Epoch: 5| Step: 2
Training loss: 3.6186896020991264
Validation loss: 3.1958123199355613

Epoch: 5| Step: 3
Training loss: 2.9728626876311117
Validation loss: 3.191783535654444

Epoch: 5| Step: 4
Training loss: 3.5323697905627425
Validation loss: 3.189738771441309

Epoch: 5| Step: 5
Training loss: 3.0884421698683453
Validation loss: 3.1859584334332602

Epoch: 5| Step: 6
Training loss: 3.4801358150419497
Validation loss: 3.1814735513918984

Epoch: 5| Step: 7
Training loss: 3.464722365669
Validation loss: 3.1785705879193986

Epoch: 5| Step: 8
Training loss: 3.496765413177922
Validation loss: 3.1769126762874262

Epoch: 5| Step: 9
Training loss: 3.3135355644245834
Validation loss: 3.174809562548725

Epoch: 5| Step: 10
Training loss: 2.7933495321995254
Validation loss: 3.175053718442865

Epoch: 5| Step: 11
Training loss: 2.6946385522338723
Validation loss: 3.16689875446568

Epoch: 46| Step: 0
Training loss: 3.2926395925997385
Validation loss: 3.1617103656355683

Epoch: 5| Step: 1
Training loss: 2.882967316727057
Validation loss: 3.15915959394571

Epoch: 5| Step: 2
Training loss: 3.2078206697221527
Validation loss: 3.1565968508604727

Epoch: 5| Step: 3
Training loss: 3.593289287724193
Validation loss: 3.153735122025663

Epoch: 5| Step: 4
Training loss: 3.378683693673039
Validation loss: 3.150389407828329

Epoch: 5| Step: 5
Training loss: 2.6388108381362487
Validation loss: 3.1470753363210524

Epoch: 5| Step: 6
Training loss: 3.2308294793683956
Validation loss: 3.1436626869650794

Epoch: 5| Step: 7
Training loss: 3.1111077316205273
Validation loss: 3.1403823524733907

Epoch: 5| Step: 8
Training loss: 2.8754049928106933
Validation loss: 3.136653055442914

Epoch: 5| Step: 9
Training loss: 3.7560339384729273
Validation loss: 3.137277853397664

Epoch: 5| Step: 10
Training loss: 3.9770816846270947
Validation loss: 3.1360740648357943

Epoch: 5| Step: 11
Training loss: 3.160910310123883
Validation loss: 3.1306425397496707

Epoch: 47| Step: 0
Training loss: 3.5699731177164713
Validation loss: 3.127681792622249

Epoch: 5| Step: 1
Training loss: 3.473117312878814
Validation loss: 3.121528862521717

Epoch: 5| Step: 2
Training loss: 2.9203072488165067
Validation loss: 3.1203741709027497

Epoch: 5| Step: 3
Training loss: 3.8275248154347157
Validation loss: 3.1211166285510616

Epoch: 5| Step: 4
Training loss: 3.137778287301579
Validation loss: 3.1193847242247212

Epoch: 5| Step: 5
Training loss: 3.8371493101638894
Validation loss: 3.1140309623299047

Epoch: 5| Step: 6
Training loss: 3.7107281756341064
Validation loss: 3.1083695305173165

Epoch: 5| Step: 7
Training loss: 2.758448973091962
Validation loss: 3.10340615798273

Epoch: 5| Step: 8
Training loss: 2.745797153479594
Validation loss: 3.1011105487585233

Epoch: 5| Step: 9
Training loss: 2.7255453491469095
Validation loss: 3.097872556147037

Epoch: 5| Step: 10
Training loss: 2.714510978228239
Validation loss: 3.0955439224782983

Epoch: 5| Step: 11
Training loss: 3.5438818044220066
Validation loss: 3.0936730050932217

Epoch: 48| Step: 0
Training loss: 3.6246056177740793
Validation loss: 3.089684869320061

Epoch: 5| Step: 1
Training loss: 3.5667153566073355
Validation loss: 3.0855313094118704

Epoch: 5| Step: 2
Training loss: 3.2954361654982827
Validation loss: 3.083027989930986

Epoch: 5| Step: 3
Training loss: 3.142718779626937
Validation loss: 3.0785080530997777

Epoch: 5| Step: 4
Training loss: 3.0377220983114674
Validation loss: 3.0749488296489775

Epoch: 5| Step: 5
Training loss: 3.0697590957706917
Validation loss: 3.07185293094628

Epoch: 5| Step: 6
Training loss: 3.361508707607464
Validation loss: 3.0693421063880533

Epoch: 5| Step: 7
Training loss: 2.846521557035957
Validation loss: 3.0646046393764834

Epoch: 5| Step: 8
Training loss: 3.267290046793815
Validation loss: 3.061608077587355

Epoch: 5| Step: 9
Training loss: 3.4642835850210485
Validation loss: 3.058874800214259

Epoch: 5| Step: 10
Training loss: 2.7572375338469115
Validation loss: 3.0569384834999416

Epoch: 5| Step: 11
Training loss: 2.0028589795082614
Validation loss: 3.053921293669053

Epoch: 49| Step: 0
Training loss: 3.0914577122189444
Validation loss: 3.050272731104244

Epoch: 5| Step: 1
Training loss: 3.285500815665887
Validation loss: 3.048142304915291

Epoch: 5| Step: 2
Training loss: 2.826431019995184
Validation loss: 3.045166814877322

Epoch: 5| Step: 3
Training loss: 3.231548751508172
Validation loss: 3.0420833371927904

Epoch: 5| Step: 4
Training loss: 3.3924058026003614
Validation loss: 3.038452116560234

Epoch: 5| Step: 5
Training loss: 2.9241099250472384
Validation loss: 3.0362921887981034

Epoch: 5| Step: 6
Training loss: 3.3143272398475396
Validation loss: 3.0341375990773285

Epoch: 5| Step: 7
Training loss: 3.0083562186120054
Validation loss: 3.0310436978220707

Epoch: 5| Step: 8
Training loss: 3.0137253544550076
Validation loss: 3.028432979085044

Epoch: 5| Step: 9
Training loss: 3.3871767290994477
Validation loss: 3.027241048403901

Epoch: 5| Step: 10
Training loss: 3.286080573971864
Validation loss: 3.024446800316698

Epoch: 5| Step: 11
Training loss: 3.702725030730508
Validation loss: 3.022944315690345

Epoch: 50| Step: 0
Training loss: 2.4710102599057184
Validation loss: 3.0189597513056308

Epoch: 5| Step: 1
Training loss: 2.6869866524050017
Validation loss: 3.0232321006537135

Epoch: 5| Step: 2
Training loss: 3.3548044739554763
Validation loss: 3.0328326927376263

Epoch: 5| Step: 3
Training loss: 2.9408939315621736
Validation loss: 3.014351531429156

Epoch: 5| Step: 4
Training loss: 3.3585277819760084
Validation loss: 3.0078999560303643

Epoch: 5| Step: 5
Training loss: 3.0255600529039293
Validation loss: 3.006996513094042

Epoch: 5| Step: 6
Training loss: 3.3689614422460847
Validation loss: 3.0034883735139166

Epoch: 5| Step: 7
Training loss: 3.1548953028988804
Validation loss: 3.0021380514593496

Epoch: 5| Step: 8
Training loss: 3.2925025908648955
Validation loss: 3.0004001986282947

Epoch: 5| Step: 9
Training loss: 3.434426615694222
Validation loss: 2.9981301758963843

Epoch: 5| Step: 10
Training loss: 3.335276196436894
Validation loss: 2.9956898091616724

Epoch: 5| Step: 11
Training loss: 3.3607275790421736
Validation loss: 2.9927855409425868

Epoch: 51| Step: 0
Training loss: 3.1677462761933626
Validation loss: 2.9898657958852057

Epoch: 5| Step: 1
Training loss: 2.4702208760767173
Validation loss: 2.9864701644153953

Epoch: 5| Step: 2
Training loss: 2.66847253290614
Validation loss: 2.9839036546011277

Epoch: 5| Step: 3
Training loss: 2.829448748437006
Validation loss: 2.980604359486046

Epoch: 5| Step: 4
Training loss: 3.5147800362623127
Validation loss: 2.979441547828259

Epoch: 5| Step: 5
Training loss: 3.070738939950627
Validation loss: 2.976337844901251

Epoch: 5| Step: 6
Training loss: 3.040433363643631
Validation loss: 2.9726220996581016

Epoch: 5| Step: 7
Training loss: 3.4811289083079533
Validation loss: 2.970157296428395

Epoch: 5| Step: 8
Training loss: 3.624611669326518
Validation loss: 2.967524262077091

Epoch: 5| Step: 9
Training loss: 2.991211096912745
Validation loss: 2.964045595165436

Epoch: 5| Step: 10
Training loss: 3.0553034090755684
Validation loss: 2.961255072453412

Epoch: 5| Step: 11
Training loss: 3.7348397576250467
Validation loss: 2.959836142709646

Epoch: 52| Step: 0
Training loss: 3.57594946144115
Validation loss: 2.9561666604594583

Epoch: 5| Step: 1
Training loss: 2.3643299140634753
Validation loss: 2.9533982865300064

Epoch: 5| Step: 2
Training loss: 3.526561223588881
Validation loss: 2.9497938222819107

Epoch: 5| Step: 3
Training loss: 3.28976367716204
Validation loss: 2.9470657237022224

Epoch: 5| Step: 4
Training loss: 3.2221211676993056
Validation loss: 2.9449360385116834

Epoch: 5| Step: 5
Training loss: 2.844439077206687
Validation loss: 2.9417181402697374

Epoch: 5| Step: 6
Training loss: 3.2550408811096845
Validation loss: 2.9406645550231283

Epoch: 5| Step: 7
Training loss: 3.165977971996179
Validation loss: 2.936967449747765

Epoch: 5| Step: 8
Training loss: 3.017373482391394
Validation loss: 2.9351435672126223

Epoch: 5| Step: 9
Training loss: 2.754705391586112
Validation loss: 2.933777814797458

Epoch: 5| Step: 10
Training loss: 2.603694191351518
Validation loss: 2.928912807188294

Epoch: 5| Step: 11
Training loss: 3.378739722233085
Validation loss: 2.927714722075188

Epoch: 53| Step: 0
Training loss: 3.105045697648404
Validation loss: 2.9255443421059306

Epoch: 5| Step: 1
Training loss: 3.7160802923177854
Validation loss: 2.923592971862273

Epoch: 5| Step: 2
Training loss: 3.296610021564174
Validation loss: 2.9199359191760914

Epoch: 5| Step: 3
Training loss: 2.803154486561703
Validation loss: 2.917420835856517

Epoch: 5| Step: 4
Training loss: 2.6835534149647997
Validation loss: 2.915626610649512

Epoch: 5| Step: 5
Training loss: 3.1734777450826965
Validation loss: 2.9142641572150527

Epoch: 5| Step: 6
Training loss: 3.2483955237468742
Validation loss: 2.9096455034102595

Epoch: 5| Step: 7
Training loss: 2.6973421719881303
Validation loss: 2.907531322513892

Epoch: 5| Step: 8
Training loss: 2.802053761001208
Validation loss: 2.9042235696345253

Epoch: 5| Step: 9
Training loss: 2.8293228563239974
Validation loss: 2.9013866045993426

Epoch: 5| Step: 10
Training loss: 3.0193212122736695
Validation loss: 2.9003673411247117

Epoch: 5| Step: 11
Training loss: 3.3060383662255157
Validation loss: 2.8983982697031503

Epoch: 54| Step: 0
Training loss: 3.0380000829137876
Validation loss: 2.897318477490564

Epoch: 5| Step: 1
Training loss: 2.9512958008291372
Validation loss: 2.894457158467328

Epoch: 5| Step: 2
Training loss: 2.9214175269064353
Validation loss: 2.893576910418735

Epoch: 5| Step: 3
Training loss: 3.29693357587367
Validation loss: 2.8932121074916384

Epoch: 5| Step: 4
Training loss: 2.668803094340207
Validation loss: 2.892956801858627

Epoch: 5| Step: 5
Training loss: 2.860729126188436
Validation loss: 2.8874360132490127

Epoch: 5| Step: 6
Training loss: 3.313385467221484
Validation loss: 2.8849405981611507

Epoch: 5| Step: 7
Training loss: 3.522263426461136
Validation loss: 2.88281680402288

Epoch: 5| Step: 8
Training loss: 2.3678651349673188
Validation loss: 2.881656142576499

Epoch: 5| Step: 9
Training loss: 2.7498400381555133
Validation loss: 2.8843337665336963

Epoch: 5| Step: 10
Training loss: 3.1103021974104554
Validation loss: 2.8791493865698508

Epoch: 5| Step: 11
Training loss: 4.283219601398998
Validation loss: 2.8758271727435627

Epoch: 55| Step: 0
Training loss: 2.709176846730226
Validation loss: 2.8729112888329187

Epoch: 5| Step: 1
Training loss: 2.8404567219627306
Validation loss: 2.8729314999177857

Epoch: 5| Step: 2
Training loss: 3.5802629904875265
Validation loss: 2.8708996419534056

Epoch: 5| Step: 3
Training loss: 3.029895125736438
Validation loss: 2.866620848856948

Epoch: 5| Step: 4
Training loss: 3.010343363748324
Validation loss: 2.862976200217801

Epoch: 5| Step: 5
Training loss: 2.815582620553704
Validation loss: 2.861386531368263

Epoch: 5| Step: 6
Training loss: 3.189621163477554
Validation loss: 2.8585627293265423

Epoch: 5| Step: 7
Training loss: 2.769022691787313
Validation loss: 2.8567041350477695

Epoch: 5| Step: 8
Training loss: 3.0460773695539305
Validation loss: 2.8536376439646762

Epoch: 5| Step: 9
Training loss: 3.0863005991882586
Validation loss: 2.855265208729407

Epoch: 5| Step: 10
Training loss: 2.846273622946699
Validation loss: 2.8512160347656588

Epoch: 5| Step: 11
Training loss: 3.0334378241961972
Validation loss: 2.8512222226362

Epoch: 56| Step: 0
Training loss: 3.1933392165361445
Validation loss: 2.8748979999581943

Epoch: 5| Step: 1
Training loss: 3.3845123178621677
Validation loss: 2.905129083204701

Epoch: 5| Step: 2
Training loss: 2.8875009511970835
Validation loss: 2.8615581016427574

Epoch: 5| Step: 3
Training loss: 3.0442706592952438
Validation loss: 2.8441906996254716

Epoch: 5| Step: 4
Training loss: 2.770747725997552
Validation loss: 2.8443061822691162

Epoch: 5| Step: 5
Training loss: 2.755734619950416
Validation loss: 2.8538742101224694

Epoch: 5| Step: 6
Training loss: 2.277105250228385
Validation loss: 2.8614296436202378

Epoch: 5| Step: 7
Training loss: 3.1930741582299738
Validation loss: 2.8692753402906304

Epoch: 5| Step: 8
Training loss: 2.902956172768653
Validation loss: 2.868173563076343

Epoch: 5| Step: 9
Training loss: 3.4009561260189693
Validation loss: 2.875152445635274

Epoch: 5| Step: 10
Training loss: 2.8052915809839805
Validation loss: 2.8466677526416837

Epoch: 5| Step: 11
Training loss: 4.0497956212597455
Validation loss: 2.8402288491486467

Epoch: 57| Step: 0
Training loss: 3.273390448694144
Validation loss: 2.8330418925365173

Epoch: 5| Step: 1
Training loss: 3.013214412835118
Validation loss: 2.8288400459145477

Epoch: 5| Step: 2
Training loss: 2.7760919467363863
Validation loss: 2.824096715743136

Epoch: 5| Step: 3
Training loss: 3.288462532033011
Validation loss: 2.821876969025222

Epoch: 5| Step: 4
Training loss: 2.7995096935411667
Validation loss: 2.823306163554274

Epoch: 5| Step: 5
Training loss: 3.0384166197906306
Validation loss: 2.823777593027825

Epoch: 5| Step: 6
Training loss: 2.663618033911509
Validation loss: 2.8176917900027574

Epoch: 5| Step: 7
Training loss: 2.987143146478131
Validation loss: 2.8147660663185854

Epoch: 5| Step: 8
Training loss: 2.836173223781977
Validation loss: 2.8116960436091487

Epoch: 5| Step: 9
Training loss: 2.636529941156602
Validation loss: 2.811509113246569

Epoch: 5| Step: 10
Training loss: 3.3284867497518937
Validation loss: 2.8097739748594486

Epoch: 5| Step: 11
Training loss: 1.916783916646481
Validation loss: 2.8069782872471793

Epoch: 58| Step: 0
Training loss: 3.2544879736796073
Validation loss: 2.8060269287645263

Epoch: 5| Step: 1
Training loss: 3.019622524999018
Validation loss: 2.80326377839819

Epoch: 5| Step: 2
Training loss: 2.7040534216665475
Validation loss: 2.800701915232739

Epoch: 5| Step: 3
Training loss: 3.1560667381337484
Validation loss: 2.7986677416227215

Epoch: 5| Step: 4
Training loss: 3.1812055183703336
Validation loss: 2.797956506204525

Epoch: 5| Step: 5
Training loss: 2.9705392364699907
Validation loss: 2.7941821328074616

Epoch: 5| Step: 6
Training loss: 2.3700306754400575
Validation loss: 2.7922169240330845

Epoch: 5| Step: 7
Training loss: 2.326029814026412
Validation loss: 2.790470437542898

Epoch: 5| Step: 8
Training loss: 3.211175394643079
Validation loss: 2.788974717839769

Epoch: 5| Step: 9
Training loss: 2.7957370936680763
Validation loss: 2.7879215546097953

Epoch: 5| Step: 10
Training loss: 3.160118376289193
Validation loss: 2.7846507950900414

Epoch: 5| Step: 11
Training loss: 2.642667262793563
Validation loss: 2.7862165589776615

Epoch: 59| Step: 0
Training loss: 2.5559250753343017
Validation loss: 2.7798795002269183

Epoch: 5| Step: 1
Training loss: 3.096109434593914
Validation loss: 2.782124828238467

Epoch: 5| Step: 2
Training loss: 2.803000280014824
Validation loss: 2.7782357165570355

Epoch: 5| Step: 3
Training loss: 3.0814573577995543
Validation loss: 2.776266251163933

Epoch: 5| Step: 4
Training loss: 3.088903156159138
Validation loss: 2.7750686147300314

Epoch: 5| Step: 5
Training loss: 3.0240307602907364
Validation loss: 2.773451952829447

Epoch: 5| Step: 6
Training loss: 2.820230836821948
Validation loss: 2.7709384099975254

Epoch: 5| Step: 7
Training loss: 2.7115101498022223
Validation loss: 2.7681875910587026

Epoch: 5| Step: 8
Training loss: 2.82937021398761
Validation loss: 2.76872164465605

Epoch: 5| Step: 9
Training loss: 2.956986098152639
Validation loss: 2.765762253855837

Epoch: 5| Step: 10
Training loss: 2.8725288385681633
Validation loss: 2.764770771007342

Epoch: 5| Step: 11
Training loss: 3.580978122264054
Validation loss: 2.76282120228259

Epoch: 60| Step: 0
Training loss: 3.0681800328516022
Validation loss: 2.7611896272399536

Epoch: 5| Step: 1
Training loss: 2.574740506031798
Validation loss: 2.7608403882325048

Epoch: 5| Step: 2
Training loss: 2.839086712412233
Validation loss: 2.757862512064782

Epoch: 5| Step: 3
Training loss: 3.4394344088875357
Validation loss: 2.7598355359336026

Epoch: 5| Step: 4
Training loss: 2.727677781196571
Validation loss: 2.755402297972702

Epoch: 5| Step: 5
Training loss: 2.7319203721613707
Validation loss: 2.759578233221027

Epoch: 5| Step: 6
Training loss: 2.756862574038871
Validation loss: 2.7553067228829167

Epoch: 5| Step: 7
Training loss: 2.9162483096945615
Validation loss: 2.758125489136409

Epoch: 5| Step: 8
Training loss: 3.4018648250665255
Validation loss: 2.752285571083035

Epoch: 5| Step: 9
Training loss: 2.598013074646692
Validation loss: 2.7463649581464695

Epoch: 5| Step: 10
Training loss: 2.6883957722888745
Validation loss: 2.745735495989715

Epoch: 5| Step: 11
Training loss: 2.1645635031806663
Validation loss: 2.7460822027839993

Epoch: 61| Step: 0
Training loss: 2.998012043008162
Validation loss: 2.7455266490850128

Epoch: 5| Step: 1
Training loss: 2.8933844514658564
Validation loss: 2.74733968137998

Epoch: 5| Step: 2
Training loss: 2.4758892889214765
Validation loss: 2.7479240753347742

Epoch: 5| Step: 3
Training loss: 2.90769643577559
Validation loss: 2.747490113194003

Epoch: 5| Step: 4
Training loss: 2.757673308666482
Validation loss: 2.7463762003314196

Epoch: 5| Step: 5
Training loss: 2.976137626542015
Validation loss: 2.7443271632388297

Epoch: 5| Step: 6
Training loss: 2.795212150124366
Validation loss: 2.7422625720696665

Epoch: 5| Step: 7
Training loss: 2.4382455125883
Validation loss: 2.7401856943538747

Epoch: 5| Step: 8
Training loss: 3.077284335056509
Validation loss: 2.7379195681436466

Epoch: 5| Step: 9
Training loss: 3.1466962291923695
Validation loss: 2.7347629744170834

Epoch: 5| Step: 10
Training loss: 3.2333565550556873
Validation loss: 2.7312000370475094

Epoch: 5| Step: 11
Training loss: 2.196488794969877
Validation loss: 2.7303551362376095

Epoch: 62| Step: 0
Training loss: 2.689618096593582
Validation loss: 2.727914309294998

Epoch: 5| Step: 1
Training loss: 2.988366458650365
Validation loss: 2.7253764541401178

Epoch: 5| Step: 2
Training loss: 2.865633759230411
Validation loss: 2.7245031775921973

Epoch: 5| Step: 3
Training loss: 2.561922333897317
Validation loss: 2.721877586489068

Epoch: 5| Step: 4
Training loss: 2.5049395400496595
Validation loss: 2.72114882842857

Epoch: 5| Step: 5
Training loss: 3.1152890191622027
Validation loss: 2.722177019089963

Epoch: 5| Step: 6
Training loss: 3.2832311553030853
Validation loss: 2.7198758954656883

Epoch: 5| Step: 7
Training loss: 3.1570122431027388
Validation loss: 2.717897811421508

Epoch: 5| Step: 8
Training loss: 3.0161390113566777
Validation loss: 2.714948620131478

Epoch: 5| Step: 9
Training loss: 2.2444437086253117
Validation loss: 2.712441993421292

Epoch: 5| Step: 10
Training loss: 2.5611734445653953
Validation loss: 2.711301363254322

Epoch: 5| Step: 11
Training loss: 3.8331815993644307
Validation loss: 2.7103100617653366

Epoch: 63| Step: 0
Training loss: 2.6646624026722114
Validation loss: 2.709699848416594

Epoch: 5| Step: 1
Training loss: 2.5031039043018573
Validation loss: 2.709216649943696

Epoch: 5| Step: 2
Training loss: 3.1158207165188103
Validation loss: 2.7044420469944828

Epoch: 5| Step: 3
Training loss: 2.917231005613423
Validation loss: 2.7033069012835673

Epoch: 5| Step: 4
Training loss: 3.153105273908115
Validation loss: 2.7021796460561593

Epoch: 5| Step: 5
Training loss: 3.0107767138386836
Validation loss: 2.6993459845447663

Epoch: 5| Step: 6
Training loss: 2.438163373616315
Validation loss: 2.6978343904437043

Epoch: 5| Step: 7
Training loss: 2.6555706277345963
Validation loss: 2.6977605934117723

Epoch: 5| Step: 8
Training loss: 2.955521030351848
Validation loss: 2.697719092971548

Epoch: 5| Step: 9
Training loss: 2.5002354511012763
Validation loss: 2.6949626455979714

Epoch: 5| Step: 10
Training loss: 3.07165094375381
Validation loss: 2.6940969923712834

Epoch: 5| Step: 11
Training loss: 3.256282309813013
Validation loss: 2.693557573365388

Epoch: 64| Step: 0
Training loss: 3.162005474039994
Validation loss: 2.6927350975688866

Epoch: 5| Step: 1
Training loss: 2.896829410922626
Validation loss: 2.6895665495979433

Epoch: 5| Step: 2
Training loss: 2.91882850819117
Validation loss: 2.688963761291046

Epoch: 5| Step: 3
Training loss: 3.0519624931360605
Validation loss: 2.6868730708338124

Epoch: 5| Step: 4
Training loss: 3.1800605873717984
Validation loss: 2.68657823768116

Epoch: 5| Step: 5
Training loss: 2.7752167488197546
Validation loss: 2.6835280756940247

Epoch: 5| Step: 6
Training loss: 2.4603265882040497
Validation loss: 2.6840940709636607

Epoch: 5| Step: 7
Training loss: 2.4390787733807096
Validation loss: 2.68012164707501

Epoch: 5| Step: 8
Training loss: 2.835107771290027
Validation loss: 2.677926317973829

Epoch: 5| Step: 9
Training loss: 2.305691154608408
Validation loss: 2.6782985271972763

Epoch: 5| Step: 10
Training loss: 2.938429178227957
Validation loss: 2.676894167637668

Epoch: 5| Step: 11
Training loss: 2.335463868162423
Validation loss: 2.675891393171995

Epoch: 65| Step: 0
Training loss: 2.5108405635141757
Validation loss: 2.6772912918144782

Epoch: 5| Step: 1
Training loss: 2.5910370208027067
Validation loss: 2.6742393970574705

Epoch: 5| Step: 2
Training loss: 2.9797131941857242
Validation loss: 2.6803237782441522

Epoch: 5| Step: 3
Training loss: 2.947998764638241
Validation loss: 2.6800495344300446

Epoch: 5| Step: 4
Training loss: 2.809405340894368
Validation loss: 2.675464097136129

Epoch: 5| Step: 5
Training loss: 2.935168375777621
Validation loss: 2.675099819317416

Epoch: 5| Step: 6
Training loss: 2.90011293257133
Validation loss: 2.6708239668762728

Epoch: 5| Step: 7
Training loss: 2.6424249236702804
Validation loss: 2.6665390301994125

Epoch: 5| Step: 8
Training loss: 2.781075804323667
Validation loss: 2.663277168155167

Epoch: 5| Step: 9
Training loss: 2.8573242504576584
Validation loss: 2.6655293674464806

Epoch: 5| Step: 10
Training loss: 2.7714809339742557
Validation loss: 2.6634612761415006

Epoch: 5| Step: 11
Training loss: 3.3356244478587995
Validation loss: 2.662479982166527

Epoch: 66| Step: 0
Training loss: 3.1229016697892304
Validation loss: 2.662644117780004

Epoch: 5| Step: 1
Training loss: 3.0718235636350464
Validation loss: 2.660838110234813

Epoch: 5| Step: 2
Training loss: 2.5479299782514166
Validation loss: 2.6595738632822026

Epoch: 5| Step: 3
Training loss: 2.457222693039786
Validation loss: 2.6564767628534227

Epoch: 5| Step: 4
Training loss: 3.01951956407425
Validation loss: 2.657224607250799

Epoch: 5| Step: 5
Training loss: 2.8487745896433534
Validation loss: 2.6589700665496885

Epoch: 5| Step: 6
Training loss: 2.202975437146852
Validation loss: 2.6542263512859883

Epoch: 5| Step: 7
Training loss: 2.8491319304769274
Validation loss: 2.652400237630355

Epoch: 5| Step: 8
Training loss: 2.6226856383448944
Validation loss: 2.655024002479156

Epoch: 5| Step: 9
Training loss: 2.5284679807325707
Validation loss: 2.6513978472787505

Epoch: 5| Step: 10
Training loss: 3.2693186044760525
Validation loss: 2.652142730121674

Epoch: 5| Step: 11
Training loss: 2.6282559138837196
Validation loss: 2.6495332804730936

Epoch: 67| Step: 0
Training loss: 2.9807282381102396
Validation loss: 2.647386464256165

Epoch: 5| Step: 1
Training loss: 2.7310152175518456
Validation loss: 2.6468476068489646

Epoch: 5| Step: 2
Training loss: 2.707109458421112
Validation loss: 2.64639533950038

Epoch: 5| Step: 3
Training loss: 2.587465324722367
Validation loss: 2.6470913424421507

Epoch: 5| Step: 4
Training loss: 2.5372134004547235
Validation loss: 2.6443668954884783

Epoch: 5| Step: 5
Training loss: 2.779541433784142
Validation loss: 2.64246531130814

Epoch: 5| Step: 6
Training loss: 2.975284973087711
Validation loss: 2.6411860658087227

Epoch: 5| Step: 7
Training loss: 2.5511516401440195
Validation loss: 2.641271384165118

Epoch: 5| Step: 8
Training loss: 2.9704800032292695
Validation loss: 2.639530839275121

Epoch: 5| Step: 9
Training loss: 2.434434870912868
Validation loss: 2.6389815014488

Epoch: 5| Step: 10
Training loss: 3.2463801839442734
Validation loss: 2.6381537029600057

Epoch: 5| Step: 11
Training loss: 2.389639857143872
Validation loss: 2.636220004159933

Epoch: 68| Step: 0
Training loss: 2.819315218874123
Validation loss: 2.6346091263322076

Epoch: 5| Step: 1
Training loss: 2.9225445148611877
Validation loss: 2.635945019638711

Epoch: 5| Step: 2
Training loss: 2.5936817941545205
Validation loss: 2.6330310455384605

Epoch: 5| Step: 3
Training loss: 2.1823276950772477
Validation loss: 2.6354641828412415

Epoch: 5| Step: 4
Training loss: 2.610869202556667
Validation loss: 2.6324444257890436

Epoch: 5| Step: 5
Training loss: 2.6922352791574222
Validation loss: 2.633665201445111

Epoch: 5| Step: 6
Training loss: 2.99583097695659
Validation loss: 2.631717184262179

Epoch: 5| Step: 7
Training loss: 2.5978255826211556
Validation loss: 2.6264342711504267

Epoch: 5| Step: 8
Training loss: 2.7721763644845696
Validation loss: 2.626420802148834

Epoch: 5| Step: 9
Training loss: 2.9262805711272852
Validation loss: 2.628385774766167

Epoch: 5| Step: 10
Training loss: 3.1208385988674046
Validation loss: 2.6288442845289866

Epoch: 5| Step: 11
Training loss: 3.152736710230984
Validation loss: 2.6271836795342747

Epoch: 69| Step: 0
Training loss: 2.1966599642700073
Validation loss: 2.6271687585755044

Epoch: 5| Step: 1
Training loss: 2.7129424758251384
Validation loss: 2.628340525640477

Epoch: 5| Step: 2
Training loss: 2.7091383006749283
Validation loss: 2.627107640748152

Epoch: 5| Step: 3
Training loss: 2.9013729397136685
Validation loss: 2.626003694139968

Epoch: 5| Step: 4
Training loss: 2.7080015615067143
Validation loss: 2.6255577872309828

Epoch: 5| Step: 5
Training loss: 2.675592791749515
Validation loss: 2.6259800617860987

Epoch: 5| Step: 6
Training loss: 2.985560476313794
Validation loss: 2.6256403369087873

Epoch: 5| Step: 7
Training loss: 2.609701718645779
Validation loss: 2.623087367855147

Epoch: 5| Step: 8
Training loss: 3.031975728101381
Validation loss: 2.622086239937465

Epoch: 5| Step: 9
Training loss: 3.2030115619204214
Validation loss: 2.6194846514978924

Epoch: 5| Step: 10
Training loss: 2.560437651864558
Validation loss: 2.614778417677771

Epoch: 5| Step: 11
Training loss: 2.2457330297979516
Validation loss: 2.613222586254152

Epoch: 70| Step: 0
Training loss: 2.474900129981278
Validation loss: 2.613501729060773

Epoch: 5| Step: 1
Training loss: 2.989474269104795
Validation loss: 2.6167023735789026

Epoch: 5| Step: 2
Training loss: 2.8383891120069618
Validation loss: 2.6155756223720514

Epoch: 5| Step: 3
Training loss: 2.1067001903055633
Validation loss: 2.612101289905776

Epoch: 5| Step: 4
Training loss: 2.5480043680521893
Validation loss: 2.6141424674939877

Epoch: 5| Step: 5
Training loss: 3.186590925244958
Validation loss: 2.6173060300186397

Epoch: 5| Step: 6
Training loss: 2.8759782205003708
Validation loss: 2.6175316010297904

Epoch: 5| Step: 7
Training loss: 2.536410593031351
Validation loss: 2.6149823364332287

Epoch: 5| Step: 8
Training loss: 2.5322630938841937
Validation loss: 2.6154604551271627

Epoch: 5| Step: 9
Training loss: 3.1415394832322305
Validation loss: 2.613235351585187

Epoch: 5| Step: 10
Training loss: 2.6317192547186217
Validation loss: 2.6089435342500304

Epoch: 5| Step: 11
Training loss: 3.2989816308089743
Validation loss: 2.605947014999844

Epoch: 71| Step: 0
Training loss: 3.1546959403134367
Validation loss: 2.6082468582683345

Epoch: 5| Step: 1
Training loss: 3.0786947120103907
Validation loss: 2.605372177843108

Epoch: 5| Step: 2
Training loss: 2.7941089783525186
Validation loss: 2.6028556473721567

Epoch: 5| Step: 3
Training loss: 2.4642458037783506
Validation loss: 2.6021884550835988

Epoch: 5| Step: 4
Training loss: 2.759917927917704
Validation loss: 2.604656567587247

Epoch: 5| Step: 5
Training loss: 2.527218846532014
Validation loss: 2.604422588488818

Epoch: 5| Step: 6
Training loss: 2.737059229373317
Validation loss: 2.6031569367121543

Epoch: 5| Step: 7
Training loss: 2.798993464482382
Validation loss: 2.6046407433371024

Epoch: 5| Step: 8
Training loss: 2.980629692881836
Validation loss: 2.6022839887008615

Epoch: 5| Step: 9
Training loss: 2.352032079101611
Validation loss: 2.6018880577410344

Epoch: 5| Step: 10
Training loss: 2.6086914629142406
Validation loss: 2.6007846284131833

Epoch: 5| Step: 11
Training loss: 0.30892455803621205
Validation loss: 2.6006792342778615

Epoch: 72| Step: 0
Training loss: 2.4784777242349403
Validation loss: 2.6001276635959174

Epoch: 5| Step: 1
Training loss: 2.7581190419775643
Validation loss: 2.5988086104347192

Epoch: 5| Step: 2
Training loss: 3.0156362266529206
Validation loss: 2.5981648303403153

Epoch: 5| Step: 3
Training loss: 2.6593260064638153
Validation loss: 2.5962546063882623

Epoch: 5| Step: 4
Training loss: 3.151815188126128
Validation loss: 2.5948934638964904

Epoch: 5| Step: 5
Training loss: 2.338270572391988
Validation loss: 2.5963132173350147

Epoch: 5| Step: 6
Training loss: 2.8160735421872993
Validation loss: 2.5972409980070323

Epoch: 5| Step: 7
Training loss: 2.8565760186441684
Validation loss: 2.599430294923925

Epoch: 5| Step: 8
Training loss: 2.6574835213179893
Validation loss: 2.597187001765269

Epoch: 5| Step: 9
Training loss: 2.338805106659128
Validation loss: 2.5959924517971444

Epoch: 5| Step: 10
Training loss: 2.76209287793608
Validation loss: 2.59289306058155

Epoch: 5| Step: 11
Training loss: 2.879802176251143
Validation loss: 2.5919546478399162

Epoch: 73| Step: 0
Training loss: 2.5582506255491384
Validation loss: 2.5929487055407656

Epoch: 5| Step: 1
Training loss: 2.7379940823810793
Validation loss: 2.5871524972118674

Epoch: 5| Step: 2
Training loss: 3.25106632639292
Validation loss: 2.593776223996124

Epoch: 5| Step: 3
Training loss: 3.2230796951917924
Validation loss: 2.5904477442652047

Epoch: 5| Step: 4
Training loss: 2.597274958799874
Validation loss: 2.58727799367718

Epoch: 5| Step: 5
Training loss: 2.0944341424317074
Validation loss: 2.584641526580943

Epoch: 5| Step: 6
Training loss: 2.5292504030178136
Validation loss: 2.5877131371243274

Epoch: 5| Step: 7
Training loss: 2.6908253345939652
Validation loss: 2.5847860041005166

Epoch: 5| Step: 8
Training loss: 2.6491573109501068
Validation loss: 2.581845890996271

Epoch: 5| Step: 9
Training loss: 3.2817118001856196
Validation loss: 2.5844271802573875

Epoch: 5| Step: 10
Training loss: 2.0805429718266306
Validation loss: 2.582479202418181

Epoch: 5| Step: 11
Training loss: 1.9202622260394935
Validation loss: 2.5843302331173788

Epoch: 74| Step: 0
Training loss: 2.4346014541856036
Validation loss: 2.5801430135032533

Epoch: 5| Step: 1
Training loss: 2.758567641833405
Validation loss: 2.585992503277523

Epoch: 5| Step: 2
Training loss: 2.8620009741098382
Validation loss: 2.5865090805485234

Epoch: 5| Step: 3
Training loss: 3.230141785760452
Validation loss: 2.5804432551154046

Epoch: 5| Step: 4
Training loss: 2.769013306646036
Validation loss: 2.576307658062828

Epoch: 5| Step: 5
Training loss: 2.414507877288816
Validation loss: 2.5794169223411316

Epoch: 5| Step: 6
Training loss: 2.569968157025491
Validation loss: 2.5781685546124415

Epoch: 5| Step: 7
Training loss: 2.3664896222726646
Validation loss: 2.5752869368990465

Epoch: 5| Step: 8
Training loss: 2.913034539020247
Validation loss: 2.5739769018829306

Epoch: 5| Step: 9
Training loss: 2.7131728045459766
Validation loss: 2.5755719153131325

Epoch: 5| Step: 10
Training loss: 2.562834182906156
Validation loss: 2.573593692791506

Epoch: 5| Step: 11
Training loss: 3.0582654053284375
Validation loss: 2.577003697547732

Epoch: 75| Step: 0
Training loss: 3.248589136090015
Validation loss: 2.5766114502670217

Epoch: 5| Step: 1
Training loss: 2.808793571483934
Validation loss: 2.585623438761443

Epoch: 5| Step: 2
Training loss: 2.3718741073908274
Validation loss: 2.5756820857087313

Epoch: 5| Step: 3
Training loss: 2.5943654260938893
Validation loss: 2.573173272056345

Epoch: 5| Step: 4
Training loss: 2.3767065642843677
Validation loss: 2.5713660101527345

Epoch: 5| Step: 5
Training loss: 2.9639201176801744
Validation loss: 2.571190530444388

Epoch: 5| Step: 6
Training loss: 3.25737249023828
Validation loss: 2.5718843278371963

Epoch: 5| Step: 7
Training loss: 2.811373167007091
Validation loss: 2.569861730994818

Epoch: 5| Step: 8
Training loss: 2.4287666955551717
Validation loss: 2.570897446445536

Epoch: 5| Step: 9
Training loss: 2.2080064087719444
Validation loss: 2.57318040651765

Epoch: 5| Step: 10
Training loss: 2.5744116657310463
Validation loss: 2.575934541117391

Epoch: 5| Step: 11
Training loss: 2.335807056676143
Validation loss: 2.5771852302502727

Epoch: 76| Step: 0
Training loss: 2.4859291829390253
Validation loss: 2.573039188376424

Epoch: 5| Step: 1
Training loss: 2.5697300955503186
Validation loss: 2.570711222818795

Epoch: 5| Step: 2
Training loss: 2.5529624410960245
Validation loss: 2.567324605180126

Epoch: 5| Step: 3
Training loss: 2.721120042479474
Validation loss: 2.56722037583961

Epoch: 5| Step: 4
Training loss: 2.4794206462453747
Validation loss: 2.5676512579671193

Epoch: 5| Step: 5
Training loss: 2.993642746949326
Validation loss: 2.562662681594933

Epoch: 5| Step: 6
Training loss: 2.3454155662300464
Validation loss: 2.567588696326729

Epoch: 5| Step: 7
Training loss: 3.039910597741444
Validation loss: 2.565243260570705

Epoch: 5| Step: 8
Training loss: 2.7689860120635608
Validation loss: 2.566023129801471

Epoch: 5| Step: 9
Training loss: 2.4864051249553145
Validation loss: 2.5707603613225976

Epoch: 5| Step: 10
Training loss: 2.997163544289544
Validation loss: 2.569374914488671

Epoch: 5| Step: 11
Training loss: 3.33634356633713
Validation loss: 2.565693218673257

Epoch: 77| Step: 0
Training loss: 2.631205172847814
Validation loss: 2.5717841189872033

Epoch: 5| Step: 1
Training loss: 2.5676616692832592
Validation loss: 2.573191247154756

Epoch: 5| Step: 2
Training loss: 2.660105521324769
Validation loss: 2.564284273328198

Epoch: 5| Step: 3
Training loss: 2.682120417094134
Validation loss: 2.574681986612154

Epoch: 5| Step: 4
Training loss: 2.5399951337031808
Validation loss: 2.579821404182473

Epoch: 5| Step: 5
Training loss: 2.904039424113702
Validation loss: 2.5721112327807276

Epoch: 5| Step: 6
Training loss: 2.91240049527833
Validation loss: 2.5608797805050583

Epoch: 5| Step: 7
Training loss: 2.60312438451936
Validation loss: 2.5604945297962454

Epoch: 5| Step: 8
Training loss: 2.7403406080452495
Validation loss: 2.5554428772572404

Epoch: 5| Step: 9
Training loss: 2.710696162933821
Validation loss: 2.5612579064583056

Epoch: 5| Step: 10
Training loss: 2.912341225679938
Validation loss: 2.5593247861675574

Epoch: 5| Step: 11
Training loss: 1.5580781547521672
Validation loss: 2.5597016709440386

Epoch: 78| Step: 0
Training loss: 2.25334480472707
Validation loss: 2.5584316988579054

Epoch: 5| Step: 1
Training loss: 2.791343888558541
Validation loss: 2.5602846299888733

Epoch: 5| Step: 2
Training loss: 2.782585423504393
Validation loss: 2.5569897814685607

Epoch: 5| Step: 3
Training loss: 3.0319365677551886
Validation loss: 2.5558406082296883

Epoch: 5| Step: 4
Training loss: 2.5785042223759866
Validation loss: 2.554492130255721

Epoch: 5| Step: 5
Training loss: 2.230527112100398
Validation loss: 2.5583183548040465

Epoch: 5| Step: 6
Training loss: 2.9511499006461843
Validation loss: 2.5562758956629694

Epoch: 5| Step: 7
Training loss: 3.2006688074720433
Validation loss: 2.5554998002731115

Epoch: 5| Step: 8
Training loss: 2.5231330617077092
Validation loss: 2.5525918116669746

Epoch: 5| Step: 9
Training loss: 2.7848380443388483
Validation loss: 2.5538773102597307

Epoch: 5| Step: 10
Training loss: 2.1159159653243447
Validation loss: 2.5535019623132817

Epoch: 5| Step: 11
Training loss: 2.838838128989996
Validation loss: 2.5510483232450003

Epoch: 79| Step: 0
Training loss: 2.462408492038849
Validation loss: 2.555446651949803

Epoch: 5| Step: 1
Training loss: 2.6569247118154045
Validation loss: 2.5553292140264006

Epoch: 5| Step: 2
Training loss: 2.847885813309911
Validation loss: 2.5465520213216566

Epoch: 5| Step: 3
Training loss: 2.5422255313328606
Validation loss: 2.5539176550908373

Epoch: 5| Step: 4
Training loss: 2.4403447887831073
Validation loss: 2.553248098138076

Epoch: 5| Step: 5
Training loss: 2.4937580385771714
Validation loss: 2.5488716287420226

Epoch: 5| Step: 6
Training loss: 3.0536498822146285
Validation loss: 2.5479383121225028

Epoch: 5| Step: 7
Training loss: 2.4855027428233747
Validation loss: 2.5519514841288244

Epoch: 5| Step: 8
Training loss: 2.718974926293141
Validation loss: 2.5534154620130143

Epoch: 5| Step: 9
Training loss: 2.6019592899008375
Validation loss: 2.551964746691372

Epoch: 5| Step: 10
Training loss: 2.8414958361813825
Validation loss: 2.555192662183373

Epoch: 5| Step: 11
Training loss: 3.4144245016890293
Validation loss: 2.5472431930851394

Epoch: 80| Step: 0
Training loss: 2.62719317052072
Validation loss: 2.5426579064215127

Epoch: 5| Step: 1
Training loss: 2.4954525597140096
Validation loss: 2.5492434030584463

Epoch: 5| Step: 2
Training loss: 2.709588850440937
Validation loss: 2.5493861302566683

Epoch: 5| Step: 3
Training loss: 2.8831146826188383
Validation loss: 2.546026088380914

Epoch: 5| Step: 4
Training loss: 2.659192687978917
Validation loss: 2.549553685305541

Epoch: 5| Step: 5
Training loss: 2.8186151781001954
Validation loss: 2.550269285332226

Epoch: 5| Step: 6
Training loss: 2.5093305990013013
Validation loss: 2.5465620585829862

Epoch: 5| Step: 7
Training loss: 2.377369953052481
Validation loss: 2.5440814684103046

Epoch: 5| Step: 8
Training loss: 2.664985027163816
Validation loss: 2.5419901162587406

Epoch: 5| Step: 9
Training loss: 2.6129503254422497
Validation loss: 2.5422094630578482

Epoch: 5| Step: 10
Training loss: 2.7908723659601193
Validation loss: 2.5445133153548642

Epoch: 5| Step: 11
Training loss: 3.139296521150093
Validation loss: 2.541284373461062

Epoch: 81| Step: 0
Training loss: 2.8542673320606555
Validation loss: 2.5414269886720557

Epoch: 5| Step: 1
Training loss: 2.3012543533507803
Validation loss: 2.5387279779194984

Epoch: 5| Step: 2
Training loss: 2.941752662878581
Validation loss: 2.5400858220547438

Epoch: 5| Step: 3
Training loss: 2.828656731457344
Validation loss: 2.539746983528067

Epoch: 5| Step: 4
Training loss: 2.283360902475956
Validation loss: 2.5399744323071918

Epoch: 5| Step: 5
Training loss: 2.5490690738602098
Validation loss: 2.5381695238366557

Epoch: 5| Step: 6
Training loss: 2.73709912434974
Validation loss: 2.5407097505554797

Epoch: 5| Step: 7
Training loss: 2.650186506941715
Validation loss: 2.5398047785378406

Epoch: 5| Step: 8
Training loss: 2.892446572907445
Validation loss: 2.5396272940790783

Epoch: 5| Step: 9
Training loss: 2.5283736852830203
Validation loss: 2.5372004718983754

Epoch: 5| Step: 10
Training loss: 2.5530270654578753
Validation loss: 2.5402810581435915

Epoch: 5| Step: 11
Training loss: 3.1013626303279858
Validation loss: 2.5378615918778165

Epoch: 82| Step: 0
Training loss: 2.7097254085429707
Validation loss: 2.543059748336467

Epoch: 5| Step: 1
Training loss: 2.522006452838045
Validation loss: 2.551006647951941

Epoch: 5| Step: 2
Training loss: 2.4779251152712605
Validation loss: 2.550923225225501

Epoch: 5| Step: 3
Training loss: 2.5015936540406645
Validation loss: 2.5641181922705316

Epoch: 5| Step: 4
Training loss: 2.554833364259697
Validation loss: 2.5615139009814714

Epoch: 5| Step: 5
Training loss: 2.5318337226616094
Validation loss: 2.555536885268201

Epoch: 5| Step: 6
Training loss: 2.3846168565390613
Validation loss: 2.5808692622083176

Epoch: 5| Step: 7
Training loss: 2.7291950098172406
Validation loss: 2.5905612164641703

Epoch: 5| Step: 8
Training loss: 3.4748436268263925
Validation loss: 2.5851321853619735

Epoch: 5| Step: 9
Training loss: 2.8274696391640153
Validation loss: 2.5651167364183647

Epoch: 5| Step: 10
Training loss: 2.8636597595249955
Validation loss: 2.5438956052642845

Epoch: 5| Step: 11
Training loss: 2.5223666065283794
Validation loss: 2.5306911518774364

Epoch: 83| Step: 0
Training loss: 2.4505829487359234
Validation loss: 2.5314941563218287

Epoch: 5| Step: 1
Training loss: 2.885375829377832
Validation loss: 2.5341548852313203

Epoch: 5| Step: 2
Training loss: 2.4993971097692738
Validation loss: 2.543314201771319

Epoch: 5| Step: 3
Training loss: 2.8894949688884966
Validation loss: 2.549942716098453

Epoch: 5| Step: 4
Training loss: 2.4453977137333958
Validation loss: 2.555393397558426

Epoch: 5| Step: 5
Training loss: 2.791589441702155
Validation loss: 2.55240652542128

Epoch: 5| Step: 6
Training loss: 2.3667619278589984
Validation loss: 2.5445401424338074

Epoch: 5| Step: 7
Training loss: 2.7162486880106593
Validation loss: 2.5411430520455998

Epoch: 5| Step: 8
Training loss: 2.5791132102278636
Validation loss: 2.5371654211622325

Epoch: 5| Step: 9
Training loss: 2.793666085640709
Validation loss: 2.5369731855755946

Epoch: 5| Step: 10
Training loss: 2.8693274222292984
Validation loss: 2.5367251823053167

Epoch: 5| Step: 11
Training loss: 2.5789096447432027
Validation loss: 2.536890284255785

Epoch: 84| Step: 0
Training loss: 2.2465318866150388
Validation loss: 2.536053726437952

Epoch: 5| Step: 1
Training loss: 3.0156060252803303
Validation loss: 2.5360293792639617

Epoch: 5| Step: 2
Training loss: 2.7131680593213052
Validation loss: 2.533528205368015

Epoch: 5| Step: 3
Training loss: 2.4233930198773543
Validation loss: 2.5336605963846504

Epoch: 5| Step: 4
Training loss: 2.592116427467594
Validation loss: 2.53071587033

Epoch: 5| Step: 5
Training loss: 2.7453793807939415
Validation loss: 2.5305472691645474

Epoch: 5| Step: 6
Training loss: 2.4497095130450104
Validation loss: 2.5283585839329783

Epoch: 5| Step: 7
Training loss: 2.6070185088571356
Validation loss: 2.528330394635874

Epoch: 5| Step: 8
Training loss: 2.586854339981619
Validation loss: 2.527962433500419

Epoch: 5| Step: 9
Training loss: 2.81102883750864
Validation loss: 2.5264848313811434

Epoch: 5| Step: 10
Training loss: 2.6107471079325872
Validation loss: 2.5250668535730143

Epoch: 5| Step: 11
Training loss: 3.981418844382527
Validation loss: 2.524344967081579

Epoch: 85| Step: 0
Training loss: 2.4227342619478747
Validation loss: 2.5231129188553894

Epoch: 5| Step: 1
Training loss: 2.600473811919334
Validation loss: 2.5232362578371297

Epoch: 5| Step: 2
Training loss: 2.7286024796595774
Validation loss: 2.5216597957248537

Epoch: 5| Step: 3
Training loss: 2.523767030534725
Validation loss: 2.5217884844594067

Epoch: 5| Step: 4
Training loss: 2.7340885557275394
Validation loss: 2.5216880773184576

Epoch: 5| Step: 5
Training loss: 2.85199289078649
Validation loss: 2.5216176819965317

Epoch: 5| Step: 6
Training loss: 2.3985859082558303
Validation loss: 2.5224927860090065

Epoch: 5| Step: 7
Training loss: 2.4815666592415027
Validation loss: 2.5203567769023505

Epoch: 5| Step: 8
Training loss: 2.836694369451653
Validation loss: 2.521933163299504

Epoch: 5| Step: 9
Training loss: 2.8191941175741513
Validation loss: 2.5214508787215837

Epoch: 5| Step: 10
Training loss: 2.789365864131257
Validation loss: 2.5189312005947326

Epoch: 5| Step: 11
Training loss: 2.081708528796658
Validation loss: 2.519494068748688

Epoch: 86| Step: 0
Training loss: 2.5056054216297
Validation loss: 2.517659843229346

Epoch: 5| Step: 1
Training loss: 2.392808004740976
Validation loss: 2.5189262570631583

Epoch: 5| Step: 2
Training loss: 2.6533793476881584
Validation loss: 2.5180260353780026

Epoch: 5| Step: 3
Training loss: 2.7361124676627355
Validation loss: 2.5155626293214155

Epoch: 5| Step: 4
Training loss: 3.032022122234473
Validation loss: 2.517219961893573

Epoch: 5| Step: 5
Training loss: 2.233437187949522
Validation loss: 2.5166835571715938

Epoch: 5| Step: 6
Training loss: 2.9961613892401617
Validation loss: 2.51391479456593

Epoch: 5| Step: 7
Training loss: 2.668996051818283
Validation loss: 2.5147125216222443

Epoch: 5| Step: 8
Training loss: 2.3523189303920424
Validation loss: 2.5156696979034705

Epoch: 5| Step: 9
Training loss: 2.4867299752277177
Validation loss: 2.5152958759281887

Epoch: 5| Step: 10
Training loss: 2.987227110589635
Validation loss: 2.5208960648815135

Epoch: 5| Step: 11
Training loss: 2.529120408901998
Validation loss: 2.5159058108087407

Epoch: 87| Step: 0
Training loss: 2.642040347395479
Validation loss: 2.517504682868004

Epoch: 5| Step: 1
Training loss: 2.9968734979874365
Validation loss: 2.519992882678159

Epoch: 5| Step: 2
Training loss: 2.0890711416837555
Validation loss: 2.5196095693475677

Epoch: 5| Step: 3
Training loss: 2.5242549174630087
Validation loss: 2.5251462365284674

Epoch: 5| Step: 4
Training loss: 2.8260292170121835
Validation loss: 2.523922150310931

Epoch: 5| Step: 5
Training loss: 3.0765838637804146
Validation loss: 2.5252103886279786

Epoch: 5| Step: 6
Training loss: 2.852643202748549
Validation loss: 2.522922112868269

Epoch: 5| Step: 7
Training loss: 2.4159770398154206
Validation loss: 2.5194898853307155

Epoch: 5| Step: 8
Training loss: 2.5431085363545622
Validation loss: 2.5182530356968633

Epoch: 5| Step: 9
Training loss: 2.2495594653027844
Validation loss: 2.5136120761179486

Epoch: 5| Step: 10
Training loss: 2.837549009193962
Validation loss: 2.514224276524835

Epoch: 5| Step: 11
Training loss: 1.9613629369755567
Validation loss: 2.513774349057414

Epoch: 88| Step: 0
Training loss: 2.9778138581584197
Validation loss: 2.5155992802791927

Epoch: 5| Step: 1
Training loss: 2.8291364515560993
Validation loss: 2.517089022843788

Epoch: 5| Step: 2
Training loss: 2.436720796897936
Validation loss: 2.517169592722825

Epoch: 5| Step: 3
Training loss: 2.2572024884202277
Validation loss: 2.5114830642161836

Epoch: 5| Step: 4
Training loss: 2.805839110881075
Validation loss: 2.5276198435329387

Epoch: 5| Step: 5
Training loss: 2.4249372257877586
Validation loss: 2.5192916795647426

Epoch: 5| Step: 6
Training loss: 2.7189616855336345
Validation loss: 2.5124542124610625

Epoch: 5| Step: 7
Training loss: 2.937095451905422
Validation loss: 2.516810404439059

Epoch: 5| Step: 8
Training loss: 2.55911272915248
Validation loss: 2.5144708327501073

Epoch: 5| Step: 9
Training loss: 2.756765626178962
Validation loss: 2.509969894468002

Epoch: 5| Step: 10
Training loss: 2.284779157254442
Validation loss: 2.510881188391644

Epoch: 5| Step: 11
Training loss: 0.4573590659811369
Validation loss: 2.5185640711348856

Epoch: 89| Step: 0
Training loss: 2.936777391226253
Validation loss: 2.5217396286592653

Epoch: 5| Step: 1
Training loss: 2.7701647723936818
Validation loss: 2.514469023294696

Epoch: 5| Step: 2
Training loss: 2.477848910216842
Validation loss: 2.509504822713653

Epoch: 5| Step: 3
Training loss: 2.6633705292047107
Validation loss: 2.51378115416699

Epoch: 5| Step: 4
Training loss: 2.616149240914693
Validation loss: 2.5081160214115528

Epoch: 5| Step: 5
Training loss: 2.5894251236241055
Validation loss: 2.5065695632627696

Epoch: 5| Step: 6
Training loss: 2.8266530289710845
Validation loss: 2.5083653324933404

Epoch: 5| Step: 7
Training loss: 2.5667780079987814
Validation loss: 2.508459358333951

Epoch: 5| Step: 8
Training loss: 2.1850735967536608
Validation loss: 2.5085982401952296

Epoch: 5| Step: 9
Training loss: 2.3467497892541203
Validation loss: 2.5076317251614832

Epoch: 5| Step: 10
Training loss: 2.9997935224049983
Validation loss: 2.5048165295849247

Epoch: 5| Step: 11
Training loss: 1.4518709411432988
Validation loss: 2.5059476278398267

Epoch: 90| Step: 0
Training loss: 2.7443017009553996
Validation loss: 2.502764710917805

Epoch: 5| Step: 1
Training loss: 2.587619200093944
Validation loss: 2.5030032000869857

Epoch: 5| Step: 2
Training loss: 3.0513515354564
Validation loss: 2.5041938334899285

Epoch: 5| Step: 3
Training loss: 2.8919554251985713
Validation loss: 2.500366422502989

Epoch: 5| Step: 4
Training loss: 2.7044443427783893
Validation loss: 2.508282507469144

Epoch: 5| Step: 5
Training loss: 2.290369695614735
Validation loss: 2.505001033102547

Epoch: 5| Step: 6
Training loss: 2.3994231047283323
Validation loss: 2.5042652898294206

Epoch: 5| Step: 7
Training loss: 2.458924551092922
Validation loss: 2.507473598885108

Epoch: 5| Step: 8
Training loss: 2.2397986256817726
Validation loss: 2.5030312678154143

Epoch: 5| Step: 9
Training loss: 2.518935400715651
Validation loss: 2.504764530792462

Epoch: 5| Step: 10
Training loss: 2.6766459383543952
Validation loss: 2.508060229178295

Epoch: 5| Step: 11
Training loss: 3.4120193757807304
Validation loss: 2.5045875340576007

Epoch: 91| Step: 0
Training loss: 2.556249671693515
Validation loss: 2.504519938359042

Epoch: 5| Step: 1
Training loss: 2.410643294969427
Validation loss: 2.505116305706438

Epoch: 5| Step: 2
Training loss: 2.8719723557334547
Validation loss: 2.504991269505681

Epoch: 5| Step: 3
Training loss: 2.850914617645448
Validation loss: 2.504944168142479

Epoch: 5| Step: 4
Training loss: 2.4302552961141286
Validation loss: 2.505831188302052

Epoch: 5| Step: 5
Training loss: 2.121580177016595
Validation loss: 2.5040275675266153

Epoch: 5| Step: 6
Training loss: 2.5051818550175122
Validation loss: 2.50337912356568

Epoch: 5| Step: 7
Training loss: 3.032954572428596
Validation loss: 2.5008169111072576

Epoch: 5| Step: 8
Training loss: 2.3305234907104397
Validation loss: 2.499742641712703

Epoch: 5| Step: 9
Training loss: 2.78433870405351
Validation loss: 2.5049225881490833

Epoch: 5| Step: 10
Training loss: 2.754030655019185
Validation loss: 2.5021814683339896

Epoch: 5| Step: 11
Training loss: 2.5241385510619807
Validation loss: 2.5012702615525084

Epoch: 92| Step: 0
Training loss: 2.6354038605108716
Validation loss: 2.501196964139472

Epoch: 5| Step: 1
Training loss: 2.6760979012569432
Validation loss: 2.5050878171952875

Epoch: 5| Step: 2
Training loss: 2.50839901539256
Validation loss: 2.5029922380295284

Epoch: 5| Step: 3
Training loss: 2.793530217001997
Validation loss: 2.504346510278684

Epoch: 5| Step: 4
Training loss: 2.3826040708342022
Validation loss: 2.5065434692317314

Epoch: 5| Step: 5
Training loss: 2.7256352725291366
Validation loss: 2.5026621591846308

Epoch: 5| Step: 6
Training loss: 2.832411410368029
Validation loss: 2.5011330063704276

Epoch: 5| Step: 7
Training loss: 2.3466063324079043
Validation loss: 2.502809356682399

Epoch: 5| Step: 8
Training loss: 2.512546907053487
Validation loss: 2.5013370236775065

Epoch: 5| Step: 9
Training loss: 2.8859204748753364
Validation loss: 2.498633635175972

Epoch: 5| Step: 10
Training loss: 2.2846748040511398
Validation loss: 2.502881025202708

Epoch: 5| Step: 11
Training loss: 3.3773736024552456
Validation loss: 2.5007362831217748

Epoch: 93| Step: 0
Training loss: 2.424419616776446
Validation loss: 2.4987356843358586

Epoch: 5| Step: 1
Training loss: 3.118412551512494
Validation loss: 2.4991477507061624

Epoch: 5| Step: 2
Training loss: 3.088793705160568
Validation loss: 2.500639337010573

Epoch: 5| Step: 3
Training loss: 2.205538894991829
Validation loss: 2.5009374648988745

Epoch: 5| Step: 4
Training loss: 2.788839550350227
Validation loss: 2.4976847617063522

Epoch: 5| Step: 5
Training loss: 2.596790232462679
Validation loss: 2.501577400228271

Epoch: 5| Step: 6
Training loss: 2.576503544324365
Validation loss: 2.5031822375842703

Epoch: 5| Step: 7
Training loss: 2.326765341847813
Validation loss: 2.4954890362885913

Epoch: 5| Step: 8
Training loss: 2.548227617987159
Validation loss: 2.4885425320657464

Epoch: 5| Step: 9
Training loss: 2.749501443232997
Validation loss: 2.498933640188825

Epoch: 5| Step: 10
Training loss: 2.2135035851886635
Validation loss: 2.497034507497748

Epoch: 5| Step: 11
Training loss: 2.252633778518939
Validation loss: 2.500487868071794

Epoch: 94| Step: 0
Training loss: 2.580664014459008
Validation loss: 2.4999391786806244

Epoch: 5| Step: 1
Training loss: 2.5341556966891865
Validation loss: 2.499177741886575

Epoch: 5| Step: 2
Training loss: 3.1567735898668223
Validation loss: 2.500421703057879

Epoch: 5| Step: 3
Training loss: 2.64156555038415
Validation loss: 2.504951092419626

Epoch: 5| Step: 4
Training loss: 2.5350780034149714
Validation loss: 2.5096946933880586

Epoch: 5| Step: 5
Training loss: 2.605050163445023
Validation loss: 2.510234388221023

Epoch: 5| Step: 6
Training loss: 2.4767099811913016
Validation loss: 2.5053104940245174

Epoch: 5| Step: 7
Training loss: 2.745669509870786
Validation loss: 2.51237363766411

Epoch: 5| Step: 8
Training loss: 2.57161134872555
Validation loss: 2.494866723754607

Epoch: 5| Step: 9
Training loss: 2.403398483846522
Validation loss: 2.4974530279447427

Epoch: 5| Step: 10
Training loss: 2.5474084400797605
Validation loss: 2.5017099294558003

Epoch: 5| Step: 11
Training loss: 2.53615556250626
Validation loss: 2.500664551147316

Epoch: 95| Step: 0
Training loss: 2.5902647018670746
Validation loss: 2.4996545632445732

Epoch: 5| Step: 1
Training loss: 2.663452615593199
Validation loss: 2.5041876886176215

Epoch: 5| Step: 2
Training loss: 2.5141249265441745
Validation loss: 2.502523519517889

Epoch: 5| Step: 3
Training loss: 2.688014934799167
Validation loss: 2.5119764157276934

Epoch: 5| Step: 4
Training loss: 2.884240600496556
Validation loss: 2.5073759584372275

Epoch: 5| Step: 5
Training loss: 2.602229860413842
Validation loss: 2.510422506101367

Epoch: 5| Step: 6
Training loss: 2.586487679859776
Validation loss: 2.5103386092548634

Epoch: 5| Step: 7
Training loss: 2.8729300303398473
Validation loss: 2.50711167427322

Epoch: 5| Step: 8
Training loss: 2.692004310366395
Validation loss: 2.507874536588741

Epoch: 5| Step: 9
Training loss: 2.33523222313761
Validation loss: 2.5047904609178717

Epoch: 5| Step: 10
Training loss: 2.495946649983815
Validation loss: 2.505165049495568

Epoch: 5| Step: 11
Training loss: 2.451688990055872
Validation loss: 2.4999430212839227

Epoch: 96| Step: 0
Training loss: 2.9620869602108364
Validation loss: 2.502781544465074

Epoch: 5| Step: 1
Training loss: 2.3410644403947556
Validation loss: 2.498758764886106

Epoch: 5| Step: 2
Training loss: 2.664936984893521
Validation loss: 2.5033838696231796

Epoch: 5| Step: 3
Training loss: 2.642895506797625
Validation loss: 2.4982511403566545

Epoch: 5| Step: 4
Training loss: 2.3184685878209352
Validation loss: 2.4993432374401685

Epoch: 5| Step: 5
Training loss: 2.314112127108065
Validation loss: 2.498128281719135

Epoch: 5| Step: 6
Training loss: 2.769932899350946
Validation loss: 2.497427113124651

Epoch: 5| Step: 7
Training loss: 2.932609870589024
Validation loss: 2.4990478808594068

Epoch: 5| Step: 8
Training loss: 2.4804245351620335
Validation loss: 2.493615254687241

Epoch: 5| Step: 9
Training loss: 2.639454418507804
Validation loss: 2.495619882606554

Epoch: 5| Step: 10
Training loss: 2.3149823448875617
Validation loss: 2.491792318648224

Epoch: 5| Step: 11
Training loss: 3.7879216629838512
Validation loss: 2.492219484257518

Epoch: 97| Step: 0
Training loss: 2.6350599708464464
Validation loss: 2.4909217195047297

Epoch: 5| Step: 1
Training loss: 2.624516306318665
Validation loss: 2.48980279511163

Epoch: 5| Step: 2
Training loss: 3.0014711587522025
Validation loss: 2.4906392365499057

Epoch: 5| Step: 3
Training loss: 2.638038135608645
Validation loss: 2.4888726554163334

Epoch: 5| Step: 4
Training loss: 2.173630697739671
Validation loss: 2.486468754397479

Epoch: 5| Step: 5
Training loss: 2.4430271962697976
Validation loss: 2.487637003763131

Epoch: 5| Step: 6
Training loss: 2.968624554041633
Validation loss: 2.489152844504195

Epoch: 5| Step: 7
Training loss: 2.771629066265765
Validation loss: 2.483099296014959

Epoch: 5| Step: 8
Training loss: 2.423027305886841
Validation loss: 2.491018942115445

Epoch: 5| Step: 9
Training loss: 2.1068967601610895
Validation loss: 2.486058450534199

Epoch: 5| Step: 10
Training loss: 2.7521781098426605
Validation loss: 2.4863729620219703

Epoch: 5| Step: 11
Training loss: 2.0180630391976813
Validation loss: 2.4902970010699024

Epoch: 98| Step: 0
Training loss: 2.311177158889324
Validation loss: 2.487548728286682

Epoch: 5| Step: 1
Training loss: 2.3382258099255306
Validation loss: 2.488212824049816

Epoch: 5| Step: 2
Training loss: 2.9734121557088726
Validation loss: 2.4923474889282424

Epoch: 5| Step: 3
Training loss: 2.424172081161577
Validation loss: 2.4842836355207676

Epoch: 5| Step: 4
Training loss: 2.4690117033336905
Validation loss: 2.4880160335606005

Epoch: 5| Step: 5
Training loss: 2.7461231821580205
Validation loss: 2.4892082783103215

Epoch: 5| Step: 6
Training loss: 2.8070685605277648
Validation loss: 2.4887807994375635

Epoch: 5| Step: 7
Training loss: 2.26936074435485
Validation loss: 2.4875782962278783

Epoch: 5| Step: 8
Training loss: 2.5486684464170626
Validation loss: 2.4909229518350844

Epoch: 5| Step: 9
Training loss: 2.904241873060639
Validation loss: 2.486476105678559

Epoch: 5| Step: 10
Training loss: 2.746721133630314
Validation loss: 2.4846972410477823

Epoch: 5| Step: 11
Training loss: 2.1077335328734903
Validation loss: 2.4901678976523107

Epoch: 99| Step: 0
Training loss: 2.9242744589290894
Validation loss: 2.4865675474061866

Epoch: 5| Step: 1
Training loss: 2.8479732132948548
Validation loss: 2.48888818992972

Epoch: 5| Step: 2
Training loss: 2.449455675654211
Validation loss: 2.489795908504696

Epoch: 5| Step: 3
Training loss: 2.812424891846506
Validation loss: 2.4898311872018737

Epoch: 5| Step: 4
Training loss: 2.285814395909074
Validation loss: 2.4900038748382896

Epoch: 5| Step: 5
Training loss: 2.492428567641392
Validation loss: 2.4894547442555606

Epoch: 5| Step: 6
Training loss: 2.6259315291090224
Validation loss: 2.4885241131957176

Epoch: 5| Step: 7
Training loss: 2.5433479647467614
Validation loss: 2.490337857358919

Epoch: 5| Step: 8
Training loss: 2.6639718406666746
Validation loss: 2.489180908771132

Epoch: 5| Step: 9
Training loss: 2.2541197042691223
Validation loss: 2.4860909491940335

Epoch: 5| Step: 10
Training loss: 2.3106943246287117
Validation loss: 2.4852409133312676

Epoch: 5| Step: 11
Training loss: 3.3791887639299625
Validation loss: 2.4862593216527125

Epoch: 100| Step: 0
Training loss: 2.5206589651621547
Validation loss: 2.4793653301707224

Epoch: 5| Step: 1
Training loss: 2.813625280123397
Validation loss: 2.488086618968917

Epoch: 5| Step: 2
Training loss: 2.8025494345015054
Validation loss: 2.4829230354147596

Epoch: 5| Step: 3
Training loss: 2.4543727932835804
Validation loss: 2.483991975268267

Epoch: 5| Step: 4
Training loss: 2.6662695906966043
Validation loss: 2.4810686602495933

Epoch: 5| Step: 5
Training loss: 3.120777787315645
Validation loss: 2.4830358002716975

Epoch: 5| Step: 6
Training loss: 2.5550147730629793
Validation loss: 2.4841497866997506

Epoch: 5| Step: 7
Training loss: 2.387340907842868
Validation loss: 2.4842572414232125

Epoch: 5| Step: 8
Training loss: 2.6637075417051355
Validation loss: 2.4840128572697404

Epoch: 5| Step: 9
Training loss: 1.6888079342903737
Validation loss: 2.491027103481573

Epoch: 5| Step: 10
Training loss: 2.572815577777276
Validation loss: 2.488222266216235

Epoch: 5| Step: 11
Training loss: 2.9680145959006827
Validation loss: 2.4908421591262777

Epoch: 101| Step: 0
Training loss: 2.1514704710228085
Validation loss: 2.48837971355265

Epoch: 5| Step: 1
Training loss: 3.2362713990106267
Validation loss: 2.492075695372039

Epoch: 5| Step: 2
Training loss: 2.215269555767856
Validation loss: 2.4878205532133224

Epoch: 5| Step: 3
Training loss: 2.164072415435881
Validation loss: 2.488605408286634

Epoch: 5| Step: 4
Training loss: 2.834864726127491
Validation loss: 2.4860084809680085

Epoch: 5| Step: 5
Training loss: 2.737899775468685
Validation loss: 2.482831575493648

Epoch: 5| Step: 6
Training loss: 2.86022819755733
Validation loss: 2.4857699838299436

Epoch: 5| Step: 7
Training loss: 2.46929684147672
Validation loss: 2.486428278014378

Epoch: 5| Step: 8
Training loss: 2.693031208054398
Validation loss: 2.48811274686069

Epoch: 5| Step: 9
Training loss: 2.2345523363711877
Validation loss: 2.4873103468847675

Epoch: 5| Step: 10
Training loss: 2.746828678161492
Validation loss: 2.483317347982874

Epoch: 5| Step: 11
Training loss: 2.1106331922865214
Validation loss: 2.479119966905925

Epoch: 102| Step: 0
Training loss: 2.7434925766711147
Validation loss: 2.4846050987610275

Epoch: 5| Step: 1
Training loss: 1.894434975606325
Validation loss: 2.4834060698829576

Epoch: 5| Step: 2
Training loss: 2.5858131217433007
Validation loss: 2.484705205281824

Epoch: 5| Step: 3
Training loss: 2.614416676917984
Validation loss: 2.480962430831358

Epoch: 5| Step: 4
Training loss: 2.791560659720765
Validation loss: 2.4822858987779366

Epoch: 5| Step: 5
Training loss: 2.6836530076415586
Validation loss: 2.4844947602138796

Epoch: 5| Step: 6
Training loss: 2.6291015915190177
Validation loss: 2.4824394147419855

Epoch: 5| Step: 7
Training loss: 2.6774829214995703
Validation loss: 2.4814225613270313

Epoch: 5| Step: 8
Training loss: 2.681553405099028
Validation loss: 2.483926992587934

Epoch: 5| Step: 9
Training loss: 2.140102127704282
Validation loss: 2.4815591332899913

Epoch: 5| Step: 10
Training loss: 2.599347428810559
Validation loss: 2.479730687509481

Epoch: 5| Step: 11
Training loss: 3.6252233502212325
Validation loss: 2.482392539774684

Epoch: 103| Step: 0
Training loss: 2.544245948526643
Validation loss: 2.478815608186311

Epoch: 5| Step: 1
Training loss: 2.5668558455598487
Validation loss: 2.4823805122521105

Epoch: 5| Step: 2
Training loss: 2.5234937159651065
Validation loss: 2.483544152760473

Epoch: 5| Step: 3
Training loss: 2.4501076382717213
Validation loss: 2.483268115341477

Epoch: 5| Step: 4
Training loss: 2.823870752192007
Validation loss: 2.4788370567817384

Epoch: 5| Step: 5
Training loss: 2.500223054471948
Validation loss: 2.4786724364623267

Epoch: 5| Step: 6
Training loss: 2.6986100080401365
Validation loss: 2.479919553017215

Epoch: 5| Step: 7
Training loss: 2.3979175513492637
Validation loss: 2.484019697921699

Epoch: 5| Step: 8
Training loss: 2.9927389966325717
Validation loss: 2.482939275310136

Epoch: 5| Step: 9
Training loss: 2.061191721891025
Validation loss: 2.4854998471254843

Epoch: 5| Step: 10
Training loss: 2.883396658082581
Validation loss: 2.482795789217063

Epoch: 5| Step: 11
Training loss: 2.1203057667815783
Validation loss: 2.485919152621104

Epoch: 104| Step: 0
Training loss: 2.7765688130269925
Validation loss: 2.480532015096305

Epoch: 5| Step: 1
Training loss: 2.5073315881251244
Validation loss: 2.4833589311428264

Epoch: 5| Step: 2
Training loss: 2.36630514589466
Validation loss: 2.478925614432141

Epoch: 5| Step: 3
Training loss: 2.6771080124802284
Validation loss: 2.4825439803263576

Epoch: 5| Step: 4
Training loss: 2.637729569699561
Validation loss: 2.4788194073905063

Epoch: 5| Step: 5
Training loss: 2.6753152928863018
Validation loss: 2.480718603090974

Epoch: 5| Step: 6
Training loss: 2.787734369936971
Validation loss: 2.4803517591866653

Epoch: 5| Step: 7
Training loss: 2.1291049129640642
Validation loss: 2.4820217167206247

Epoch: 5| Step: 8
Training loss: 2.469679452274093
Validation loss: 2.4849404345344692

Epoch: 5| Step: 9
Training loss: 2.55937693017088
Validation loss: 2.4810881674813223

Epoch: 5| Step: 10
Training loss: 2.792716317673486
Validation loss: 2.478736959744675

Epoch: 5| Step: 11
Training loss: 2.3141685858189565
Validation loss: 2.480675756272077

Epoch: 105| Step: 0
Training loss: 2.4186517739866136
Validation loss: 2.4796443941070976

Epoch: 5| Step: 1
Training loss: 2.8676175410850164
Validation loss: 2.4748288533732836

Epoch: 5| Step: 2
Training loss: 3.2018159005531777
Validation loss: 2.4815372398470164

Epoch: 5| Step: 3
Training loss: 2.286184852134906
Validation loss: 2.4852117253043553

Epoch: 5| Step: 4
Training loss: 2.018386959347383
Validation loss: 2.4857418171103625

Epoch: 5| Step: 5
Training loss: 2.404785899825393
Validation loss: 2.483290817602987

Epoch: 5| Step: 6
Training loss: 2.658342591830626
Validation loss: 2.489167287743662

Epoch: 5| Step: 7
Training loss: 2.4823838417867345
Validation loss: 2.488308525634619

Epoch: 5| Step: 8
Training loss: 2.8581685507146766
Validation loss: 2.48462383855437

Epoch: 5| Step: 9
Training loss: 2.918084118054849
Validation loss: 2.4859851641574164

Epoch: 5| Step: 10
Training loss: 2.2223132896307143
Validation loss: 2.4837036145311613

Epoch: 5| Step: 11
Training loss: 1.703998166857884
Validation loss: 2.4809795864866535

Epoch: 106| Step: 0
Training loss: 3.1261862982689266
Validation loss: 2.477169688467822

Epoch: 5| Step: 1
Training loss: 2.522635695679996
Validation loss: 2.4784875802531894

Epoch: 5| Step: 2
Training loss: 2.0722882901461386
Validation loss: 2.4794264638572976

Epoch: 5| Step: 3
Training loss: 2.5828988930249195
Validation loss: 2.4781389884666165

Epoch: 5| Step: 4
Training loss: 2.5218383635136994
Validation loss: 2.481215917639866

Epoch: 5| Step: 5
Training loss: 3.0926527138875164
Validation loss: 2.482086639218522

Epoch: 5| Step: 6
Training loss: 2.495360265189854
Validation loss: 2.483330033020626

Epoch: 5| Step: 7
Training loss: 2.374416580820156
Validation loss: 2.4798903544347506

Epoch: 5| Step: 8
Training loss: 2.439210927040595
Validation loss: 2.481669218071864

Epoch: 5| Step: 9
Training loss: 2.5879998871392016
Validation loss: 2.4813582500030593

Epoch: 5| Step: 10
Training loss: 2.498161211894219
Validation loss: 2.4812581645917726

Epoch: 5| Step: 11
Training loss: 2.115362189914305
Validation loss: 2.4821037490817948

Epoch: 107| Step: 0
Training loss: 2.4230100863534507
Validation loss: 2.4837297285353737

Epoch: 5| Step: 1
Training loss: 2.6113757840289087
Validation loss: 2.4817907379942636

Epoch: 5| Step: 2
Training loss: 2.4169809422086885
Validation loss: 2.4781402912926858

Epoch: 5| Step: 3
Training loss: 2.517554165390983
Validation loss: 2.482873058760881

Epoch: 5| Step: 4
Training loss: 2.5668696851654427
Validation loss: 2.484324280802909

Epoch: 5| Step: 5
Training loss: 2.365341725893983
Validation loss: 2.484597871888089

Epoch: 5| Step: 6
Training loss: 2.489060978909954
Validation loss: 2.484788492368699

Epoch: 5| Step: 7
Training loss: 2.8376545397648987
Validation loss: 2.4871312572582482

Epoch: 5| Step: 8
Training loss: 2.947347489440419
Validation loss: 2.4834015856608023

Epoch: 5| Step: 9
Training loss: 2.330573823039084
Validation loss: 2.4838738525809294

Epoch: 5| Step: 10
Training loss: 2.684892409600271
Validation loss: 2.4829384631178426

Epoch: 5| Step: 11
Training loss: 2.880879237219665
Validation loss: 2.479872029534859

Epoch: 108| Step: 0
Training loss: 2.395620275781891
Validation loss: 2.473919903640753

Epoch: 5| Step: 1
Training loss: 2.4802247896146516
Validation loss: 2.4721015601292855

Epoch: 5| Step: 2
Training loss: 2.61415603205867
Validation loss: 2.470089010077581

Epoch: 5| Step: 3
Training loss: 2.476630850730196
Validation loss: 2.46653840842025

Epoch: 5| Step: 4
Training loss: 2.748474911971335
Validation loss: 2.482176433668074

Epoch: 5| Step: 5
Training loss: 2.2363232208597976
Validation loss: 2.467464381878486

Epoch: 5| Step: 6
Training loss: 2.765335585111672
Validation loss: 2.472821302966724

Epoch: 5| Step: 7
Training loss: 2.228194645760224
Validation loss: 2.4750689305875957

Epoch: 5| Step: 8
Training loss: 2.8750942048934185
Validation loss: 2.4726972451008145

Epoch: 5| Step: 9
Training loss: 2.8366903351432486
Validation loss: 2.4759699596976894

Epoch: 5| Step: 10
Training loss: 2.608096694774412
Validation loss: 2.4766107067145655

Epoch: 5| Step: 11
Training loss: 1.9435005175072384
Validation loss: 2.484886116856901

Epoch: 109| Step: 0
Training loss: 2.6836268882426766
Validation loss: 2.4865276878879334

Epoch: 5| Step: 1
Training loss: 2.5287755480469007
Validation loss: 2.487478700703179

Epoch: 5| Step: 2
Training loss: 2.803171667350568
Validation loss: 2.4847078440284367

Epoch: 5| Step: 3
Training loss: 2.4231478391943075
Validation loss: 2.4858727568789893

Epoch: 5| Step: 4
Training loss: 2.5579766148026923
Validation loss: 2.484896263282966

Epoch: 5| Step: 5
Training loss: 2.4344601382448983
Validation loss: 2.482248655889191

Epoch: 5| Step: 6
Training loss: 2.39902789773816
Validation loss: 2.4853474934862523

Epoch: 5| Step: 7
Training loss: 2.84057456665256
Validation loss: 2.483197923036449

Epoch: 5| Step: 8
Training loss: 2.6437050276734633
Validation loss: 2.485779443268177

Epoch: 5| Step: 9
Training loss: 2.026604137125275
Validation loss: 2.485646476310715

Epoch: 5| Step: 10
Training loss: 2.88192495520767
Validation loss: 2.4819591780314583

Epoch: 5| Step: 11
Training loss: 2.5515195470349363
Validation loss: 2.4814201112498604

Epoch: 110| Step: 0
Training loss: 2.2798067517952054
Validation loss: 2.477563713812167

Epoch: 5| Step: 1
Training loss: 2.3537334167252837
Validation loss: 2.476820550224311

Epoch: 5| Step: 2
Training loss: 2.576548516285867
Validation loss: 2.473032811695829

Epoch: 5| Step: 3
Training loss: 2.7273012925588302
Validation loss: 2.47393369294327

Epoch: 5| Step: 4
Training loss: 2.793725312740477
Validation loss: 2.4786522649521388

Epoch: 5| Step: 5
Training loss: 2.5601157284446705
Validation loss: 2.4774251853304277

Epoch: 5| Step: 6
Training loss: 2.593853224573176
Validation loss: 2.473807674973773

Epoch: 5| Step: 7
Training loss: 2.3390105074173126
Validation loss: 2.471155318744346

Epoch: 5| Step: 8
Training loss: 2.7258101247765274
Validation loss: 2.468939922769379

Epoch: 5| Step: 9
Training loss: 2.739360863146292
Validation loss: 2.4773677315098093

Epoch: 5| Step: 10
Training loss: 2.6381286920387446
Validation loss: 2.476942488503079

Epoch: 5| Step: 11
Training loss: 1.828404983859884
Validation loss: 2.4752418053154916

Epoch: 111| Step: 0
Training loss: 2.5892237500823914
Validation loss: 2.478993427143511

Epoch: 5| Step: 1
Training loss: 2.627974958820154
Validation loss: 2.479666011807738

Epoch: 5| Step: 2
Training loss: 2.2687114869939418
Validation loss: 2.4763049885297543

Epoch: 5| Step: 3
Training loss: 2.464676792396724
Validation loss: 2.477332944995804

Epoch: 5| Step: 4
Training loss: 2.4598264093326367
Validation loss: 2.47640218927883

Epoch: 5| Step: 5
Training loss: 2.6470409751115827
Validation loss: 2.4807170993902004

Epoch: 5| Step: 6
Training loss: 2.5262199627328306
Validation loss: 2.4727572018232404

Epoch: 5| Step: 7
Training loss: 3.255981809148188
Validation loss: 2.4745432647408903

Epoch: 5| Step: 8
Training loss: 2.6308753247474943
Validation loss: 2.475307632041459

Epoch: 5| Step: 9
Training loss: 2.374628539901483
Validation loss: 2.4730470658854915

Epoch: 5| Step: 10
Training loss: 2.121708958102658
Validation loss: 2.4751401641601056

Epoch: 5| Step: 11
Training loss: 2.8527272811063895
Validation loss: 2.476861696992865

Epoch: 112| Step: 0
Training loss: 2.617035363173767
Validation loss: 2.4775883668838548

Epoch: 5| Step: 1
Training loss: 2.3757582006368128
Validation loss: 2.474242980375852

Epoch: 5| Step: 2
Training loss: 2.642329100655684
Validation loss: 2.4735892184442525

Epoch: 5| Step: 3
Training loss: 2.957332137205927
Validation loss: 2.477634258193112

Epoch: 5| Step: 4
Training loss: 2.7616723041864417
Validation loss: 2.4717932164728493

Epoch: 5| Step: 5
Training loss: 2.5118478412588447
Validation loss: 2.4775640105245804

Epoch: 5| Step: 6
Training loss: 2.3205421411180693
Validation loss: 2.4766233779693207

Epoch: 5| Step: 7
Training loss: 2.0917720276739713
Validation loss: 2.4729626201118937

Epoch: 5| Step: 8
Training loss: 2.574180776405709
Validation loss: 2.4753266408784698

Epoch: 5| Step: 9
Training loss: 2.8018075081641807
Validation loss: 2.4707042910204966

Epoch: 5| Step: 10
Training loss: 2.592438515621034
Validation loss: 2.4759592751636754

Epoch: 5| Step: 11
Training loss: 1.4284816305002868
Validation loss: 2.4723155835080988

Epoch: 113| Step: 0
Training loss: 2.2100817638479047
Validation loss: 2.470427548767415

Epoch: 5| Step: 1
Training loss: 2.3409290885239473
Validation loss: 2.469634923596126

Epoch: 5| Step: 2
Training loss: 2.356327235729282
Validation loss: 2.4701941648222094

Epoch: 5| Step: 3
Training loss: 2.8198696644741545
Validation loss: 2.464951909307362

Epoch: 5| Step: 4
Training loss: 2.9193368587235953
Validation loss: 2.4594845191195382

Epoch: 5| Step: 5
Training loss: 2.568477636595254
Validation loss: 2.468565604007211

Epoch: 5| Step: 6
Training loss: 2.5442022797880117
Validation loss: 2.4708727068495207

Epoch: 5| Step: 7
Training loss: 2.6661341155273415
Validation loss: 2.4678357600403715

Epoch: 5| Step: 8
Training loss: 2.809370546263155
Validation loss: 2.4728635687993936

Epoch: 5| Step: 9
Training loss: 2.124177436945975
Validation loss: 2.467898914250338

Epoch: 5| Step: 10
Training loss: 2.772640059900296
Validation loss: 2.474823008897402

Epoch: 5| Step: 11
Training loss: 2.6072143014872013
Validation loss: 2.474229413623754

Epoch: 114| Step: 0
Training loss: 2.428447640093117
Validation loss: 2.4791255528115634

Epoch: 5| Step: 1
Training loss: 2.5341078084700204
Validation loss: 2.484107484949663

Epoch: 5| Step: 2
Training loss: 2.6190609731375027
Validation loss: 2.480256331351979

Epoch: 5| Step: 3
Training loss: 2.2435723789646995
Validation loss: 2.486297243640201

Epoch: 5| Step: 4
Training loss: 2.907291020815067
Validation loss: 2.4737827613502663

Epoch: 5| Step: 5
Training loss: 2.6411536776612294
Validation loss: 2.4817148637948327

Epoch: 5| Step: 6
Training loss: 2.716946672468714
Validation loss: 2.480838677963618

Epoch: 5| Step: 7
Training loss: 2.5368140961374794
Validation loss: 2.4834433954179396

Epoch: 5| Step: 8
Training loss: 2.8628742090026007
Validation loss: 2.477296594070497

Epoch: 5| Step: 9
Training loss: 2.134078994711809
Validation loss: 2.4776790841460876

Epoch: 5| Step: 10
Training loss: 2.6762112237222704
Validation loss: 2.4786491468300142

Epoch: 5| Step: 11
Training loss: 2.2182547862847044
Validation loss: 2.475406073883778

Epoch: 115| Step: 0
Training loss: 2.5719445331578643
Validation loss: 2.4733693770351155

Epoch: 5| Step: 1
Training loss: 2.622526365716729
Validation loss: 2.476586017837934

Epoch: 5| Step: 2
Training loss: 2.3389311015210246
Validation loss: 2.471910779125795

Epoch: 5| Step: 3
Training loss: 2.5287598971495178
Validation loss: 2.4707215681631607

Epoch: 5| Step: 4
Training loss: 2.6831897503681534
Validation loss: 2.4691829502956213

Epoch: 5| Step: 5
Training loss: 2.2132072525231004
Validation loss: 2.467449578089226

Epoch: 5| Step: 6
Training loss: 2.927198975655501
Validation loss: 2.4671854622727576

Epoch: 5| Step: 7
Training loss: 2.3175112065411567
Validation loss: 2.4613690033301805

Epoch: 5| Step: 8
Training loss: 2.40510244377348
Validation loss: 2.452009988388473

Epoch: 5| Step: 9
Training loss: 2.672515257032645
Validation loss: 2.459261098192855

Epoch: 5| Step: 10
Training loss: 2.7129016983102843
Validation loss: 2.4575722669348163

Epoch: 5| Step: 11
Training loss: 3.0512468322212376
Validation loss: 2.4576934787251425

Epoch: 116| Step: 0
Training loss: 2.5869380248512694
Validation loss: 2.4597726315455155

Epoch: 5| Step: 1
Training loss: 2.057083647307285
Validation loss: 2.4573812998527225

Epoch: 5| Step: 2
Training loss: 2.4705378179321125
Validation loss: 2.464091908229613

Epoch: 5| Step: 3
Training loss: 2.7552567437479407
Validation loss: 2.4581684377831463

Epoch: 5| Step: 4
Training loss: 2.2633795825163756
Validation loss: 2.467525713792087

Epoch: 5| Step: 5
Training loss: 2.591435514324511
Validation loss: 2.4667009308299597

Epoch: 5| Step: 6
Training loss: 2.7598017361513074
Validation loss: 2.4749984656114026

Epoch: 5| Step: 7
Training loss: 2.1384215883440407
Validation loss: 2.4760277789577936

Epoch: 5| Step: 8
Training loss: 3.2437757898970254
Validation loss: 2.4735443886565984

Epoch: 5| Step: 9
Training loss: 2.569977619652579
Validation loss: 2.4799055446305833

Epoch: 5| Step: 10
Training loss: 2.659235275309555
Validation loss: 2.480890645670133

Epoch: 5| Step: 11
Training loss: 2.5393975139561586
Validation loss: 2.478612502589321

Epoch: 117| Step: 0
Training loss: 2.604525508317037
Validation loss: 2.470023856691319

Epoch: 5| Step: 1
Training loss: 2.747132106374844
Validation loss: 2.4653343038988584

Epoch: 5| Step: 2
Training loss: 2.2696697041862883
Validation loss: 2.4812375056338962

Epoch: 5| Step: 3
Training loss: 2.89643745615868
Validation loss: 2.4912108019194847

Epoch: 5| Step: 4
Training loss: 2.96896843357593
Validation loss: 2.493223315863554

Epoch: 5| Step: 5
Training loss: 2.6535488980713295
Validation loss: 2.500203231657134

Epoch: 5| Step: 6
Training loss: 2.287910666369025
Validation loss: 2.49543485267863

Epoch: 5| Step: 7
Training loss: 2.3524428839241227
Validation loss: 2.4871123685999015

Epoch: 5| Step: 8
Training loss: 2.2252696784674746
Validation loss: 2.473503883516846

Epoch: 5| Step: 9
Training loss: 2.6935234877371497
Validation loss: 2.46826167045314

Epoch: 5| Step: 10
Training loss: 2.7955601334631224
Validation loss: 2.46788552194119

Epoch: 5| Step: 11
Training loss: 2.711163514139793
Validation loss: 2.466607512159968

Epoch: 118| Step: 0
Training loss: 2.320433128637837
Validation loss: 2.4672285534352447

Epoch: 5| Step: 1
Training loss: 2.4260365817086464
Validation loss: 2.4687392801945367

Epoch: 5| Step: 2
Training loss: 2.378833487765003
Validation loss: 2.4782900475871634

Epoch: 5| Step: 3
Training loss: 2.753632227473987
Validation loss: 2.479466549717142

Epoch: 5| Step: 4
Training loss: 2.521412701404358
Validation loss: 2.483179388512394

Epoch: 5| Step: 5
Training loss: 2.304140601490714
Validation loss: 2.4829909149909635

Epoch: 5| Step: 6
Training loss: 3.1109285547040684
Validation loss: 2.4814324857161845

Epoch: 5| Step: 7
Training loss: 2.959537708679631
Validation loss: 2.482403038547702

Epoch: 5| Step: 8
Training loss: 1.799199201682233
Validation loss: 2.479580188905849

Epoch: 5| Step: 9
Training loss: 3.087876109330999
Validation loss: 2.483482940432194

Epoch: 5| Step: 10
Training loss: 2.6086293142978483
Validation loss: 2.476849496219052

Epoch: 5| Step: 11
Training loss: 1.996725143039092
Validation loss: 2.4728580772145965

Epoch: 119| Step: 0
Training loss: 2.0252996293671215
Validation loss: 2.4785453528066093

Epoch: 5| Step: 1
Training loss: 2.467386762654659
Validation loss: 2.4751423997083943

Epoch: 5| Step: 2
Training loss: 2.3362055085723283
Validation loss: 2.4731458889253637

Epoch: 5| Step: 3
Training loss: 2.3197275573980143
Validation loss: 2.473498132299506

Epoch: 5| Step: 4
Training loss: 2.8968585461393057
Validation loss: 2.4754868466862447

Epoch: 5| Step: 5
Training loss: 2.632808424949322
Validation loss: 2.4710426871223636

Epoch: 5| Step: 6
Training loss: 2.4577462955587013
Validation loss: 2.4681448013581666

Epoch: 5| Step: 7
Training loss: 2.9261476009789464
Validation loss: 2.4699659049297424

Epoch: 5| Step: 8
Training loss: 3.2492438683865448
Validation loss: 2.464835040464495

Epoch: 5| Step: 9
Training loss: 2.5702169568702367
Validation loss: 2.4703740319171605

Epoch: 5| Step: 10
Training loss: 2.3227170051560866
Validation loss: 2.4676379222064857

Epoch: 5| Step: 11
Training loss: 1.0780419580295078
Validation loss: 2.4709592342196776

Epoch: 120| Step: 0
Training loss: 3.462987839248107
Validation loss: 2.465344462291283

Epoch: 5| Step: 1
Training loss: 2.5269914761857293
Validation loss: 2.468762735744413

Epoch: 5| Step: 2
Training loss: 2.8730628079945695
Validation loss: 2.468072995581184

Epoch: 5| Step: 3
Training loss: 2.234108648897391
Validation loss: 2.463126013748411

Epoch: 5| Step: 4
Training loss: 2.4957051579121865
Validation loss: 2.4636487084025274

Epoch: 5| Step: 5
Training loss: 2.740849790847497
Validation loss: 2.456521374026158

Epoch: 5| Step: 6
Training loss: 1.7804070870876563
Validation loss: 2.4662440091456874

Epoch: 5| Step: 7
Training loss: 2.2558819922432214
Validation loss: 2.4621189813448177

Epoch: 5| Step: 8
Training loss: 2.611734477049146
Validation loss: 2.4648451162778815

Epoch: 5| Step: 9
Training loss: 2.458338742869832
Validation loss: 2.461305277959066

Epoch: 5| Step: 10
Training loss: 2.3048416344777296
Validation loss: 2.45959905729115

Epoch: 5| Step: 11
Training loss: 2.2418572052971775
Validation loss: 2.467928073568376

Epoch: 121| Step: 0
Training loss: 2.411214586851198
Validation loss: 2.4611289176973674

Epoch: 5| Step: 1
Training loss: 2.6206780230459588
Validation loss: 2.4689938308120642

Epoch: 5| Step: 2
Training loss: 1.9650683416853207
Validation loss: 2.4640306400165644

Epoch: 5| Step: 3
Training loss: 2.5205880248036747
Validation loss: 2.471833492433717

Epoch: 5| Step: 4
Training loss: 2.4667003186825758
Validation loss: 2.470980658542845

Epoch: 5| Step: 5
Training loss: 2.0469599116527246
Validation loss: 2.4658158728430535

Epoch: 5| Step: 6
Training loss: 2.7421428100769902
Validation loss: 2.4691999202497037

Epoch: 5| Step: 7
Training loss: 2.928298661691288
Validation loss: 2.469414637627332

Epoch: 5| Step: 8
Training loss: 2.682392856701476
Validation loss: 2.4648240215078245

Epoch: 5| Step: 9
Training loss: 2.9138324227411196
Validation loss: 2.4663064428368044

Epoch: 5| Step: 10
Training loss: 2.4463169362808195
Validation loss: 2.4725282383827527

Epoch: 5| Step: 11
Training loss: 3.29149865474149
Validation loss: 2.4764237349951532

Epoch: 122| Step: 0
Training loss: 2.1494597621220857
Validation loss: 2.4700565341446183

Epoch: 5| Step: 1
Training loss: 2.812061699517294
Validation loss: 2.4746525054922452

Epoch: 5| Step: 2
Training loss: 2.287531943176367
Validation loss: 2.47026794380543

Epoch: 5| Step: 3
Training loss: 2.4061210895042624
Validation loss: 2.474123779921789

Epoch: 5| Step: 4
Training loss: 2.6031122031017517
Validation loss: 2.4711967447601726

Epoch: 5| Step: 5
Training loss: 2.718476380358381
Validation loss: 2.463289063765222

Epoch: 5| Step: 6
Training loss: 2.5444123701529215
Validation loss: 2.4701563615895648

Epoch: 5| Step: 7
Training loss: 2.4878547338842756
Validation loss: 2.4646022091871194

Epoch: 5| Step: 8
Training loss: 2.6913172204693874
Validation loss: 2.4700701720775737

Epoch: 5| Step: 9
Training loss: 2.26244135828052
Validation loss: 2.471613358203339

Epoch: 5| Step: 10
Training loss: 3.031857930994279
Validation loss: 2.46594270610151

Epoch: 5| Step: 11
Training loss: 2.545425283276195
Validation loss: 2.466627145839384

Epoch: 123| Step: 0
Training loss: 2.6831663810334434
Validation loss: 2.472187399544535

Epoch: 5| Step: 1
Training loss: 2.3788799917090424
Validation loss: 2.468577085145341

Epoch: 5| Step: 2
Training loss: 2.714859469800487
Validation loss: 2.474458793749507

Epoch: 5| Step: 3
Training loss: 2.672178820017231
Validation loss: 2.4739972536472177

Epoch: 5| Step: 4
Training loss: 2.184759767013982
Validation loss: 2.4734424909909616

Epoch: 5| Step: 5
Training loss: 2.5649075247173263
Validation loss: 2.473397961780655

Epoch: 5| Step: 6
Training loss: 2.337293862621952
Validation loss: 2.4703975523708213

Epoch: 5| Step: 7
Training loss: 2.5708599029437535
Validation loss: 2.474113866367478

Epoch: 5| Step: 8
Training loss: 2.8564216078076243
Validation loss: 2.4777130799609033

Epoch: 5| Step: 9
Training loss: 2.2241928608241492
Validation loss: 2.4723342878740056

Epoch: 5| Step: 10
Training loss: 2.8145488481834944
Validation loss: 2.472501897589377

Epoch: 5| Step: 11
Training loss: 2.3353728055167275
Validation loss: 2.4712436974251646

Epoch: 124| Step: 0
Training loss: 2.7536813197703274
Validation loss: 2.4711494535201415

Epoch: 5| Step: 1
Training loss: 2.544239295183534
Validation loss: 2.4677327269323612

Epoch: 5| Step: 2
Training loss: 2.586594328196528
Validation loss: 2.472160365965538

Epoch: 5| Step: 3
Training loss: 2.6740725219581556
Validation loss: 2.461890424680234

Epoch: 5| Step: 4
Training loss: 2.756250387524774
Validation loss: 2.4689643501227954

Epoch: 5| Step: 5
Training loss: 2.461118661176679
Validation loss: 2.4634073125375306

Epoch: 5| Step: 6
Training loss: 2.0019905198489183
Validation loss: 2.467704193307139

Epoch: 5| Step: 7
Training loss: 2.751718677635337
Validation loss: 2.4626221153717807

Epoch: 5| Step: 8
Training loss: 2.51282330990181
Validation loss: 2.4650142991539146

Epoch: 5| Step: 9
Training loss: 2.5125688268239714
Validation loss: 2.465245820153243

Epoch: 5| Step: 10
Training loss: 2.5415355669407624
Validation loss: 2.464755250658924

Epoch: 5| Step: 11
Training loss: 2.0176492624952815
Validation loss: 2.466975085097752

Epoch: 125| Step: 0
Training loss: 3.1257927461282597
Validation loss: 2.4601930673072676

Epoch: 5| Step: 1
Training loss: 2.328624185387423
Validation loss: 2.45853640369552

Epoch: 5| Step: 2
Training loss: 3.046594068829494
Validation loss: 2.4577393211501635

Epoch: 5| Step: 3
Training loss: 2.249899332125708
Validation loss: 2.4550559104333196

Epoch: 5| Step: 4
Training loss: 2.3090068105512107
Validation loss: 2.4621743621068966

Epoch: 5| Step: 5
Training loss: 2.231366673258742
Validation loss: 2.4542924042978287

Epoch: 5| Step: 6
Training loss: 2.1780344392840245
Validation loss: 2.4693908744835364

Epoch: 5| Step: 7
Training loss: 2.473665968367411
Validation loss: 2.4603583567722023

Epoch: 5| Step: 8
Training loss: 2.4995045170919643
Validation loss: 2.460268068846334

Epoch: 5| Step: 9
Training loss: 2.4402317487379817
Validation loss: 2.463841512120152

Epoch: 5| Step: 10
Training loss: 3.0235982058690714
Validation loss: 2.4682263772700117

Epoch: 5| Step: 11
Training loss: 2.2143600446996543
Validation loss: 2.4639222306130764

Epoch: 126| Step: 0
Training loss: 2.914066427192394
Validation loss: 2.4738198385456758

Epoch: 5| Step: 1
Training loss: 2.4027901087489227
Validation loss: 2.466896403467653

Epoch: 5| Step: 2
Training loss: 2.492185491005019
Validation loss: 2.4699514459362852

Epoch: 5| Step: 3
Training loss: 2.662755293091164
Validation loss: 2.467418192715465

Epoch: 5| Step: 4
Training loss: 2.337812914787738
Validation loss: 2.470697343138512

Epoch: 5| Step: 5
Training loss: 2.853425052570971
Validation loss: 2.468673366854142

Epoch: 5| Step: 6
Training loss: 2.191160137207504
Validation loss: 2.4622821888228987

Epoch: 5| Step: 7
Training loss: 2.6536421596413073
Validation loss: 2.4573409992573816

Epoch: 5| Step: 8
Training loss: 2.3704850296870594
Validation loss: 2.4676842783481043

Epoch: 5| Step: 9
Training loss: 2.489096994394486
Validation loss: 2.455008259712097

Epoch: 5| Step: 10
Training loss: 2.752078571262518
Validation loss: 2.4550111003295885

Epoch: 5| Step: 11
Training loss: 2.235257274660646
Validation loss: 2.4631812549108045

Epoch: 127| Step: 0
Training loss: 2.365084781215859
Validation loss: 2.47066341564248

Epoch: 5| Step: 1
Training loss: 2.686753812596069
Validation loss: 2.4796459605554158

Epoch: 5| Step: 2
Training loss: 2.473857376983417
Validation loss: 2.4786227668789214

Epoch: 5| Step: 3
Training loss: 2.618644104047847
Validation loss: 2.483740259652828

Epoch: 5| Step: 4
Training loss: 2.7916189920330616
Validation loss: 2.4828124220575796

Epoch: 5| Step: 5
Training loss: 2.718118528497412
Validation loss: 2.4817326246898213

Epoch: 5| Step: 6
Training loss: 2.6441328235972685
Validation loss: 2.477750535359275

Epoch: 5| Step: 7
Training loss: 1.8282298522615243
Validation loss: 2.4836285527388675

Epoch: 5| Step: 8
Training loss: 2.5246848221273726
Validation loss: 2.476103947783901

Epoch: 5| Step: 9
Training loss: 2.918975533832762
Validation loss: 2.4873163237722014

Epoch: 5| Step: 10
Training loss: 2.8065294258318945
Validation loss: 2.4813193797573776

Epoch: 5| Step: 11
Training loss: 2.2759889528177393
Validation loss: 2.485938362043109

Epoch: 128| Step: 0
Training loss: 1.902445201009382
Validation loss: 2.482483761764079

Epoch: 5| Step: 1
Training loss: 2.917245553107668
Validation loss: 2.479633613230066

Epoch: 5| Step: 2
Training loss: 2.2498209140290784
Validation loss: 2.4875064483955165

Epoch: 5| Step: 3
Training loss: 2.813210122211177
Validation loss: 2.4797865723030377

Epoch: 5| Step: 4
Training loss: 2.672296323517666
Validation loss: 2.4805702809457637

Epoch: 5| Step: 5
Training loss: 2.6183862474494703
Validation loss: 2.4832279068267975

Epoch: 5| Step: 6
Training loss: 2.9616963966550442
Validation loss: 2.479036950209301

Epoch: 5| Step: 7
Training loss: 2.0135958608197546
Validation loss: 2.471771825316256

Epoch: 5| Step: 8
Training loss: 2.4357291415735944
Validation loss: 2.4728096406674975

Epoch: 5| Step: 9
Training loss: 2.821297851210783
Validation loss: 2.4697066799382656

Epoch: 5| Step: 10
Training loss: 2.5278685789835484
Validation loss: 2.4671401758791043

Epoch: 5| Step: 11
Training loss: 1.9532616529342934
Validation loss: 2.4628540407428776

Epoch: 129| Step: 0
Training loss: 2.503201247064823
Validation loss: 2.456816234793167

Epoch: 5| Step: 1
Training loss: 2.5907918768169536
Validation loss: 2.4537120084368786

Epoch: 5| Step: 2
Training loss: 2.0408196022046328
Validation loss: 2.466034095485914

Epoch: 5| Step: 3
Training loss: 2.670839164675944
Validation loss: 2.453531069667213

Epoch: 5| Step: 4
Training loss: 2.918776230622732
Validation loss: 2.4586116557786974

Epoch: 5| Step: 5
Training loss: 2.047190052276031
Validation loss: 2.465324588713276

Epoch: 5| Step: 6
Training loss: 2.3143701981122016
Validation loss: 2.464149312788285

Epoch: 5| Step: 7
Training loss: 2.6343386610246675
Validation loss: 2.44886180541957

Epoch: 5| Step: 8
Training loss: 2.5627926915183186
Validation loss: 2.459650968896592

Epoch: 5| Step: 9
Training loss: 2.920463669947865
Validation loss: 2.4701911606928606

Epoch: 5| Step: 10
Training loss: 2.773358582999144
Validation loss: 2.4731595921661915

Epoch: 5| Step: 11
Training loss: 3.11388419138947
Validation loss: 2.4716674289929412

Epoch: 130| Step: 0
Training loss: 2.4389481766353684
Validation loss: 2.4671253218253666

Epoch: 5| Step: 1
Training loss: 2.9141965124492524
Validation loss: 2.466258409314675

Epoch: 5| Step: 2
Training loss: 2.392338556245791
Validation loss: 2.4659202912964147

Epoch: 5| Step: 3
Training loss: 2.2151749512961394
Validation loss: 2.469408152769742

Epoch: 5| Step: 4
Training loss: 2.423210710923863
Validation loss: 2.465499158032243

Epoch: 5| Step: 5
Training loss: 2.6675161756974264
Validation loss: 2.4666420391395545

Epoch: 5| Step: 6
Training loss: 2.561600969357757
Validation loss: 2.4688064431928955

Epoch: 5| Step: 7
Training loss: 2.2759024245023585
Validation loss: 2.471335264615341

Epoch: 5| Step: 8
Training loss: 2.5161241308682003
Validation loss: 2.4704470495473605

Epoch: 5| Step: 9
Training loss: 2.512216948701877
Validation loss: 2.4678211919554105

Epoch: 5| Step: 10
Training loss: 3.0353516818918482
Validation loss: 2.466876385339413

Epoch: 5| Step: 11
Training loss: 1.959436214287811
Validation loss: 2.465648417005069

Epoch: 131| Step: 0
Training loss: 2.1485175100513643
Validation loss: 2.4665860800584807

Epoch: 5| Step: 1
Training loss: 2.369758343025634
Validation loss: 2.454913275178103

Epoch: 5| Step: 2
Training loss: 2.084608247394455
Validation loss: 2.455998671229735

Epoch: 5| Step: 3
Training loss: 3.0449926577324504
Validation loss: 2.4586451192652587

Epoch: 5| Step: 4
Training loss: 2.4784053841100815
Validation loss: 2.470251314972627

Epoch: 5| Step: 5
Training loss: 2.5556304777837213
Validation loss: 2.4689747309706886

Epoch: 5| Step: 6
Training loss: 2.619242757901011
Validation loss: 2.461863041971616

Epoch: 5| Step: 7
Training loss: 2.3825275188189723
Validation loss: 2.4698938866394546

Epoch: 5| Step: 8
Training loss: 2.962680595462491
Validation loss: 2.4716453836231667

Epoch: 5| Step: 9
Training loss: 2.9913800696450017
Validation loss: 2.4584532697698838

Epoch: 5| Step: 10
Training loss: 2.427581757760754
Validation loss: 2.4550773926103866

Epoch: 5| Step: 11
Training loss: 1.9305224755042671
Validation loss: 2.45990079407707

Epoch: 132| Step: 0
Training loss: 2.60817960665973
Validation loss: 2.4635389232553013

Epoch: 5| Step: 1
Training loss: 1.9960273388230687
Validation loss: 2.4712059584870465

Epoch: 5| Step: 2
Training loss: 2.4273178467536347
Validation loss: 2.469921658936374

Epoch: 5| Step: 3
Training loss: 2.908640872759057
Validation loss: 2.4734124849700803

Epoch: 5| Step: 4
Training loss: 2.088513787163581
Validation loss: 2.4760449387129264

Epoch: 5| Step: 5
Training loss: 3.2052420714277097
Validation loss: 2.4818015295147093

Epoch: 5| Step: 6
Training loss: 2.836389090572751
Validation loss: 2.4828460194953994

Epoch: 5| Step: 7
Training loss: 2.931381508941536
Validation loss: 2.4814410489228487

Epoch: 5| Step: 8
Training loss: 1.9149737621731013
Validation loss: 2.4799401468442808

Epoch: 5| Step: 9
Training loss: 2.704779851560965
Validation loss: 2.480266921275176

Epoch: 5| Step: 10
Training loss: 2.1992635231135673
Validation loss: 2.4818274513876677

Epoch: 5| Step: 11
Training loss: 1.7452290760070663
Validation loss: 2.4774714906645166

Epoch: 133| Step: 0
Training loss: 2.470537142398927
Validation loss: 2.4780212662846246

Epoch: 5| Step: 1
Training loss: 2.269739978534967
Validation loss: 2.477608388678371

Epoch: 5| Step: 2
Training loss: 1.9991739474512888
Validation loss: 2.4732711493467243

Epoch: 5| Step: 3
Training loss: 2.6788198773646146
Validation loss: 2.470983585326559

Epoch: 5| Step: 4
Training loss: 2.374973798908466
Validation loss: 2.467637954412531

Epoch: 5| Step: 5
Training loss: 2.484557906801235
Validation loss: 2.4648539063838397

Epoch: 5| Step: 6
Training loss: 2.5257268860261615
Validation loss: 2.447944593608446

Epoch: 5| Step: 7
Training loss: 2.262645050794536
Validation loss: 2.455119539051668

Epoch: 5| Step: 8
Training loss: 2.566697381401413
Validation loss: 2.4551642662520683

Epoch: 5| Step: 9
Training loss: 2.8534900577974214
Validation loss: 2.4538889098463095

Epoch: 5| Step: 10
Training loss: 3.4238538898863005
Validation loss: 2.4507850331585423

Epoch: 5| Step: 11
Training loss: 1.3608643714711885
Validation loss: 2.4499679425471297

Epoch: 134| Step: 0
Training loss: 3.168749392056078
Validation loss: 2.443769288942224

Epoch: 5| Step: 1
Training loss: 1.9505252473082637
Validation loss: 2.450039390973911

Epoch: 5| Step: 2
Training loss: 2.238350805563299
Validation loss: 2.4566213551935863

Epoch: 5| Step: 3
Training loss: 2.743974934527409
Validation loss: 2.4557478422963

Epoch: 5| Step: 4
Training loss: 2.6040520197745463
Validation loss: 2.4666115395941275

Epoch: 5| Step: 5
Training loss: 2.281232232847657
Validation loss: 2.450614229477117

Epoch: 5| Step: 6
Training loss: 2.4067472464297164
Validation loss: 2.463826698658995

Epoch: 5| Step: 7
Training loss: 2.3936515050798426
Validation loss: 2.4589724248788136

Epoch: 5| Step: 8
Training loss: 2.486593443565466
Validation loss: 2.4535541483014818

Epoch: 5| Step: 9
Training loss: 2.4252848585687077
Validation loss: 2.4491150066949534

Epoch: 5| Step: 10
Training loss: 2.9935971915920505
Validation loss: 2.4546242969453202

Epoch: 5| Step: 11
Training loss: 2.382010403069905
Validation loss: 2.469509732165626

Epoch: 135| Step: 0
Training loss: 2.654033678716461
Validation loss: 2.474850342541448

Epoch: 5| Step: 1
Training loss: 2.311136410749967
Validation loss: 2.477479163360354

Epoch: 5| Step: 2
Training loss: 2.756707940152051
Validation loss: 2.480774767964651

Epoch: 5| Step: 3
Training loss: 1.80259556923041
Validation loss: 2.485427505542008

Epoch: 5| Step: 4
Training loss: 2.4339241795449755
Validation loss: 2.4841379656365903

Epoch: 5| Step: 5
Training loss: 2.744964150227678
Validation loss: 2.4882609807201472

Epoch: 5| Step: 6
Training loss: 2.5843209460508705
Validation loss: 2.486980064085687

Epoch: 5| Step: 7
Training loss: 2.687016820720783
Validation loss: 2.4851286862509765

Epoch: 5| Step: 8
Training loss: 2.658800762859457
Validation loss: 2.4840391319891557

Epoch: 5| Step: 9
Training loss: 2.814309618836611
Validation loss: 2.4786493432157135

Epoch: 5| Step: 10
Training loss: 2.4818441107313576
Validation loss: 2.475570435886141

Epoch: 5| Step: 11
Training loss: 2.0711835072629503
Validation loss: 2.472175700098805

Epoch: 136| Step: 0
Training loss: 3.131453754549526
Validation loss: 2.4657989722609464

Epoch: 5| Step: 1
Training loss: 2.3252678050372655
Validation loss: 2.4632181892102554

Epoch: 5| Step: 2
Training loss: 2.5065648668328184
Validation loss: 2.4573469782920645

Epoch: 5| Step: 3
Training loss: 2.5742036532478885
Validation loss: 2.45635703357583

Epoch: 5| Step: 4
Training loss: 2.9593298581314853
Validation loss: 2.454851223483415

Epoch: 5| Step: 5
Training loss: 2.695779511171409
Validation loss: 2.4503346668731556

Epoch: 5| Step: 6
Training loss: 1.9545559943320243
Validation loss: 2.449804427651677

Epoch: 5| Step: 7
Training loss: 2.3691850046402365
Validation loss: 2.4556496864528516

Epoch: 5| Step: 8
Training loss: 2.812439472818756
Validation loss: 2.4542306121522013

Epoch: 5| Step: 9
Training loss: 1.9336616889500688
Validation loss: 2.461448729360869

Epoch: 5| Step: 10
Training loss: 2.113422043600142
Validation loss: 2.4589251166958337

Epoch: 5| Step: 11
Training loss: 3.241355550263293
Validation loss: 2.4583338451923766

Epoch: 137| Step: 0
Training loss: 2.7489613392186953
Validation loss: 2.463294371007287

Epoch: 5| Step: 1
Training loss: 2.1608287461194493
Validation loss: 2.458169650162029

Epoch: 5| Step: 2
Training loss: 2.4026431509631974
Validation loss: 2.4612886208622826

Epoch: 5| Step: 3
Training loss: 2.6761754100655386
Validation loss: 2.4647111610181973

Epoch: 5| Step: 4
Training loss: 3.042769576129683
Validation loss: 2.4714931325695515

Epoch: 5| Step: 5
Training loss: 2.478417697471935
Validation loss: 2.466977271669475

Epoch: 5| Step: 6
Training loss: 2.7664416987709997
Validation loss: 2.4685427180320794

Epoch: 5| Step: 7
Training loss: 2.4133524915380855
Validation loss: 2.4654446618512527

Epoch: 5| Step: 8
Training loss: 2.628835600630595
Validation loss: 2.465432352195907

Epoch: 5| Step: 9
Training loss: 2.4675905426326485
Validation loss: 2.4658244056793586

Epoch: 5| Step: 10
Training loss: 2.220844408571875
Validation loss: 2.469332584015852

Epoch: 5| Step: 11
Training loss: 1.0599241448197656
Validation loss: 2.4682571224945873

Epoch: 138| Step: 0
Training loss: 2.533872117504637
Validation loss: 2.4701952506511953

Epoch: 5| Step: 1
Training loss: 2.5479267031788275
Validation loss: 2.466747373042466

Epoch: 5| Step: 2
Training loss: 2.0983713873860923
Validation loss: 2.468757383923011

Epoch: 5| Step: 3
Training loss: 2.6014325450251286
Validation loss: 2.466894365822114

Epoch: 5| Step: 4
Training loss: 2.2662556789893036
Validation loss: 2.463010175497306

Epoch: 5| Step: 5
Training loss: 2.779392951167926
Validation loss: 2.467765116705866

Epoch: 5| Step: 6
Training loss: 2.3690564926065254
Validation loss: 2.4582716010042183

Epoch: 5| Step: 7
Training loss: 2.248265551579146
Validation loss: 2.457131881553379

Epoch: 5| Step: 8
Training loss: 2.965175363845196
Validation loss: 2.460740657785433

Epoch: 5| Step: 9
Training loss: 2.5586824591014947
Validation loss: 2.4546017747362296

Epoch: 5| Step: 10
Training loss: 2.620317733659334
Validation loss: 2.4455821464482748

Epoch: 5| Step: 11
Training loss: 2.913158123005648
Validation loss: 2.4466509949128525

Epoch: 139| Step: 0
Training loss: 2.451572680285039
Validation loss: 2.4503002912063714

Epoch: 5| Step: 1
Training loss: 2.487256088950284
Validation loss: 2.443072266841097

Epoch: 5| Step: 2
Training loss: 2.998156457942325
Validation loss: 2.457994230907546

Epoch: 5| Step: 3
Training loss: 2.3777037840270214
Validation loss: 2.4527834474292383

Epoch: 5| Step: 4
Training loss: 2.4372911608314745
Validation loss: 2.4496556834825394

Epoch: 5| Step: 5
Training loss: 2.661118298412254
Validation loss: 2.458124221916732

Epoch: 5| Step: 6
Training loss: 2.2093228216632954
Validation loss: 2.45336279961739

Epoch: 5| Step: 7
Training loss: 2.7817942911823277
Validation loss: 2.4562765659548993

Epoch: 5| Step: 8
Training loss: 2.4304954436604183
Validation loss: 2.448851842334881

Epoch: 5| Step: 9
Training loss: 2.3289187313591238
Validation loss: 2.4525480746107977

Epoch: 5| Step: 10
Training loss: 2.5095692598582797
Validation loss: 2.4588287421422192

Epoch: 5| Step: 11
Training loss: 2.6214958598795226
Validation loss: 2.467439287450727

Epoch: 140| Step: 0
Training loss: 1.6907427678013467
Validation loss: 2.465087580321126

Epoch: 5| Step: 1
Training loss: 2.3384083212123343
Validation loss: 2.4685964456116904

Epoch: 5| Step: 2
Training loss: 2.3441554418196326
Validation loss: 2.4685131796390425

Epoch: 5| Step: 3
Training loss: 2.5575355263309296
Validation loss: 2.4753550083816034

Epoch: 5| Step: 4
Training loss: 2.6437980954099376
Validation loss: 2.4732664860854237

Epoch: 5| Step: 5
Training loss: 2.752704504248053
Validation loss: 2.473926366632967

Epoch: 5| Step: 6
Training loss: 3.2468149276918474
Validation loss: 2.4749649342387285

Epoch: 5| Step: 7
Training loss: 2.5027204017493196
Validation loss: 2.4682247834503115

Epoch: 5| Step: 8
Training loss: 2.010666418292252
Validation loss: 2.4713469419115834

Epoch: 5| Step: 9
Training loss: 2.6834386255997806
Validation loss: 2.45994185232947

Epoch: 5| Step: 10
Training loss: 2.849361040198722
Validation loss: 2.4513174168311034

Epoch: 5| Step: 11
Training loss: 1.8265283899573168
Validation loss: 2.45350406334059

Epoch: 141| Step: 0
Training loss: 2.761302004696139
Validation loss: 2.449225870352276

Epoch: 5| Step: 1
Training loss: 2.601300200564993
Validation loss: 2.456751052898661

Epoch: 5| Step: 2
Training loss: 2.2225417927265756
Validation loss: 2.4467181998753946

Epoch: 5| Step: 3
Training loss: 3.0158726091472254
Validation loss: 2.4539269839235396

Epoch: 5| Step: 4
Training loss: 2.3017743854144563
Validation loss: 2.446822534033584

Epoch: 5| Step: 5
Training loss: 2.536862215215248
Validation loss: 2.4437056310582017

Epoch: 5| Step: 6
Training loss: 2.3281025725442928
Validation loss: 2.448756274172612

Epoch: 5| Step: 7
Training loss: 2.6830212733462924
Validation loss: 2.4515172018546862

Epoch: 5| Step: 8
Training loss: 2.6746153581679644
Validation loss: 2.4486135579754085

Epoch: 5| Step: 9
Training loss: 2.401631269791947
Validation loss: 2.4514778462972244

Epoch: 5| Step: 10
Training loss: 2.1126676504209683
Validation loss: 2.444528844142765

Epoch: 5| Step: 11
Training loss: 2.5973679461428154
Validation loss: 2.4492736558778

Epoch: 142| Step: 0
Training loss: 2.736997382299686
Validation loss: 2.453447616323714

Epoch: 5| Step: 1
Training loss: 2.6014794688678435
Validation loss: 2.4533382817102716

Epoch: 5| Step: 2
Training loss: 1.8542819112331042
Validation loss: 2.4544332340612

Epoch: 5| Step: 3
Training loss: 2.422865634248485
Validation loss: 2.451019205351725

Epoch: 5| Step: 4
Training loss: 2.4934793311058545
Validation loss: 2.4549845108882504

Epoch: 5| Step: 5
Training loss: 2.839093766489052
Validation loss: 2.444624705573831

Epoch: 5| Step: 6
Training loss: 2.338049096876868
Validation loss: 2.444859289028628

Epoch: 5| Step: 7
Training loss: 2.6650114187314458
Validation loss: 2.4445952032722276

Epoch: 5| Step: 8
Training loss: 2.734461668548355
Validation loss: 2.4545299167828967

Epoch: 5| Step: 9
Training loss: 1.8068661440748066
Validation loss: 2.458318360062167

Epoch: 5| Step: 10
Training loss: 2.9537126874726187
Validation loss: 2.462455220952965

Epoch: 5| Step: 11
Training loss: 3.156604407024467
Validation loss: 2.4618613229762114

Epoch: 143| Step: 0
Training loss: 2.3970785360444675
Validation loss: 2.4651678429450046

Epoch: 5| Step: 1
Training loss: 2.932661576368605
Validation loss: 2.4456853653395427

Epoch: 5| Step: 2
Training loss: 2.3268690369739917
Validation loss: 2.450143099193426

Epoch: 5| Step: 3
Training loss: 2.106718750362146
Validation loss: 2.446075966209014

Epoch: 5| Step: 4
Training loss: 2.604662448737416
Validation loss: 2.4532177496544505

Epoch: 5| Step: 5
Training loss: 2.1098017508131837
Validation loss: 2.4588875199792133

Epoch: 5| Step: 6
Training loss: 2.3449083644637234
Validation loss: 2.463109909407605

Epoch: 5| Step: 7
Training loss: 2.5143811485676184
Validation loss: 2.468472263954066

Epoch: 5| Step: 8
Training loss: 3.3035316700549657
Validation loss: 2.461419941272756

Epoch: 5| Step: 9
Training loss: 2.2948235933077417
Validation loss: 2.4509188375784317

Epoch: 5| Step: 10
Training loss: 2.7434390437113887
Validation loss: 2.4571095359633763

Epoch: 5| Step: 11
Training loss: 2.8742734571529795
Validation loss: 2.456754756829332

Epoch: 144| Step: 0
Training loss: 1.9408466599518595
Validation loss: 2.4655553049633023

Epoch: 5| Step: 1
Training loss: 2.603742905788857
Validation loss: 2.47241972745722

Epoch: 5| Step: 2
Training loss: 3.0578192927655934
Validation loss: 2.4706007261504777

Epoch: 5| Step: 3
Training loss: 2.4965517104523682
Validation loss: 2.4699089191126533

Epoch: 5| Step: 4
Training loss: 2.3292854028598717
Validation loss: 2.46589788837336

Epoch: 5| Step: 5
Training loss: 2.687405163178392
Validation loss: 2.463319443135294

Epoch: 5| Step: 6
Training loss: 2.5518047154726013
Validation loss: 2.466921883962194

Epoch: 5| Step: 7
Training loss: 2.514902236130403
Validation loss: 2.466137936722796

Epoch: 5| Step: 8
Training loss: 2.4676271613380023
Validation loss: 2.466950400461179

Epoch: 5| Step: 9
Training loss: 2.515972800527781
Validation loss: 2.4636894824232143

Epoch: 5| Step: 10
Training loss: 2.375858151848009
Validation loss: 2.4573643372190515

Epoch: 5| Step: 11
Training loss: 2.8972511022665883
Validation loss: 2.464049467746973

Epoch: 145| Step: 0
Training loss: 2.7645714256262064
Validation loss: 2.459201289096634

Epoch: 5| Step: 1
Training loss: 2.308419312988621
Validation loss: 2.459219115639558

Epoch: 5| Step: 2
Training loss: 2.75458863373593
Validation loss: 2.453975578623398

Epoch: 5| Step: 3
Training loss: 2.910632858675324
Validation loss: 2.453382294316814

Epoch: 5| Step: 4
Training loss: 2.715771501494122
Validation loss: 2.445375195919266

Epoch: 5| Step: 5
Training loss: 2.2776360299683014
Validation loss: 2.4546522399811055

Epoch: 5| Step: 6
Training loss: 2.183844645763204
Validation loss: 2.4516524209849737

Epoch: 5| Step: 7
Training loss: 2.5183105350407478
Validation loss: 2.458393616799271

Epoch: 5| Step: 8
Training loss: 2.567091573082714
Validation loss: 2.458772314339198

Epoch: 5| Step: 9
Training loss: 2.4862379850362886
Validation loss: 2.4529112866524487

Epoch: 5| Step: 10
Training loss: 2.330067892763577
Validation loss: 2.456620396810674

Epoch: 5| Step: 11
Training loss: 1.0356716959986403
Validation loss: 2.460775505264452

Epoch: 146| Step: 0
Training loss: 2.4999896049283397
Validation loss: 2.464220531445967

Epoch: 5| Step: 1
Training loss: 2.7098958325512825
Validation loss: 2.465667441888804

Epoch: 5| Step: 2
Training loss: 2.7088228712503217
Validation loss: 2.4717430589927685

Epoch: 5| Step: 3
Training loss: 2.2688787838873457
Validation loss: 2.4717338975065677

Epoch: 5| Step: 4
Training loss: 2.3944728028972677
Validation loss: 2.4779754563084166

Epoch: 5| Step: 5
Training loss: 2.7691448679259354
Validation loss: 2.4720392326134633

Epoch: 5| Step: 6
Training loss: 2.255489223216853
Validation loss: 2.469072123730342

Epoch: 5| Step: 7
Training loss: 2.5720826520557902
Validation loss: 2.4716826375709835

Epoch: 5| Step: 8
Training loss: 2.497914588891301
Validation loss: 2.4666188393017805

Epoch: 5| Step: 9
Training loss: 2.544492859590316
Validation loss: 2.46089437941461

Epoch: 5| Step: 10
Training loss: 2.5460762690517282
Validation loss: 2.4592011073161286

Epoch: 5| Step: 11
Training loss: 2.3290751521694455
Validation loss: 2.4616638363098975

Epoch: 147| Step: 0
Training loss: 2.3643191241791945
Validation loss: 2.4572849476264103

Epoch: 5| Step: 1
Training loss: 2.8390519456347056
Validation loss: 2.465401418627048

Epoch: 5| Step: 2
Training loss: 2.3497958723652292
Validation loss: 2.4555778308460288

Epoch: 5| Step: 3
Training loss: 2.428204344406747
Validation loss: 2.459336513911299

Epoch: 5| Step: 4
Training loss: 2.6247000749997347
Validation loss: 2.4661837208679747

Epoch: 5| Step: 5
Training loss: 2.326488867235633
Validation loss: 2.4651548025117265

Epoch: 5| Step: 6
Training loss: 2.69632469742275
Validation loss: 2.4654945485682638

Epoch: 5| Step: 7
Training loss: 2.5818985574534534
Validation loss: 2.467849233127784

Epoch: 5| Step: 8
Training loss: 2.3712845903044477
Validation loss: 2.4523638093032174

Epoch: 5| Step: 9
Training loss: 2.824118626931584
Validation loss: 2.4648449792470957

Epoch: 5| Step: 10
Training loss: 2.340806562361837
Validation loss: 2.4636361921911916

Epoch: 5| Step: 11
Training loss: 1.7089716796403456
Validation loss: 2.4664030870738154

Epoch: 148| Step: 0
Training loss: 2.6557431803366804
Validation loss: 2.465154989897922

Epoch: 5| Step: 1
Training loss: 1.9087296914130067
Validation loss: 2.4689546250795704

Epoch: 5| Step: 2
Training loss: 2.8616704013498677
Validation loss: 2.4641061677774454

Epoch: 5| Step: 3
Training loss: 1.9126999968630412
Validation loss: 2.4678543977247

Epoch: 5| Step: 4
Training loss: 2.1472991702016926
Validation loss: 2.4735437882431786

Epoch: 5| Step: 5
Training loss: 2.4297332268732657
Validation loss: 2.474330108548831

Epoch: 5| Step: 6
Training loss: 2.988971465938465
Validation loss: 2.471292707337592

Epoch: 5| Step: 7
Training loss: 3.118323709407481
Validation loss: 2.4726484357841962

Epoch: 5| Step: 8
Training loss: 2.4418204726728296
Validation loss: 2.4727812821292874

Epoch: 5| Step: 9
Training loss: 2.2802902711169333
Validation loss: 2.4703881586928156

Epoch: 5| Step: 10
Training loss: 2.4810371288395054
Validation loss: 2.4661353385296483

Epoch: 5| Step: 11
Training loss: 2.9796184561801162
Validation loss: 2.4584715098541214

Epoch: 149| Step: 0
Training loss: 2.2845416424421434
Validation loss: 2.4611436222685557

Epoch: 5| Step: 1
Training loss: 2.95893200113509
Validation loss: 2.454344666949842

Epoch: 5| Step: 2
Training loss: 2.875523395165231
Validation loss: 2.4560619882483956

Epoch: 5| Step: 3
Training loss: 2.6713757857257767
Validation loss: 2.453660428683887

Epoch: 5| Step: 4
Training loss: 2.4395357092018446
Validation loss: 2.4524315321597485

Epoch: 5| Step: 5
Training loss: 2.5529219099534384
Validation loss: 2.4534620025205496

Epoch: 5| Step: 6
Training loss: 2.006000933531889
Validation loss: 2.4642323029266997

Epoch: 5| Step: 7
Training loss: 3.0670075234046306
Validation loss: 2.4587231498051216

Epoch: 5| Step: 8
Training loss: 2.2061167214745305
Validation loss: 2.458681358067072

Epoch: 5| Step: 9
Training loss: 2.518996449569859
Validation loss: 2.4652583886370585

Epoch: 5| Step: 10
Training loss: 1.8749224964654072
Validation loss: 2.457423944431465

Epoch: 5| Step: 11
Training loss: 2.7876533774016923
Validation loss: 2.4608569863686856

Epoch: 150| Step: 0
Training loss: 1.939255565096832
Validation loss: 2.462241865560818

Epoch: 5| Step: 1
Training loss: 2.8554567266333737
Validation loss: 2.457548522677154

Epoch: 5| Step: 2
Training loss: 2.098799353195914
Validation loss: 2.4651946126912323

Epoch: 5| Step: 3
Training loss: 2.3694080978573306
Validation loss: 2.4619632944513117

Epoch: 5| Step: 4
Training loss: 2.5903150494995897
Validation loss: 2.4584814541585085

Epoch: 5| Step: 5
Training loss: 2.1324132748283824
Validation loss: 2.4673840933054874

Epoch: 5| Step: 6
Training loss: 2.7417101322272774
Validation loss: 2.4603842421184328

Epoch: 5| Step: 7
Training loss: 2.6672793121715213
Validation loss: 2.4512249215149904

Epoch: 5| Step: 8
Training loss: 2.8247280901467597
Validation loss: 2.449056320847866

Epoch: 5| Step: 9
Training loss: 2.353866918154845
Validation loss: 2.449409655888511

Epoch: 5| Step: 10
Training loss: 2.775818568289372
Validation loss: 2.4477297420692645

Epoch: 5| Step: 11
Training loss: 3.0151305114435094
Validation loss: 2.459207546377382

Epoch: 151| Step: 0
Training loss: 2.4766908245354595
Validation loss: 2.443983689929068

Epoch: 5| Step: 1
Training loss: 2.4809904255803343
Validation loss: 2.464571825475152

Epoch: 5| Step: 2
Training loss: 3.0803532160068543
Validation loss: 2.4648883289592147

Epoch: 5| Step: 3
Training loss: 2.4740211130843366
Validation loss: 2.4713747501353547

Epoch: 5| Step: 4
Training loss: 2.502724307560815
Validation loss: 2.4741048923381306

Epoch: 5| Step: 5
Training loss: 2.0227404244280773
Validation loss: 2.4740872975248207

Epoch: 5| Step: 6
Training loss: 2.412704530258438
Validation loss: 2.480433632509443

Epoch: 5| Step: 7
Training loss: 2.264861195165814
Validation loss: 2.4774191625259316

Epoch: 5| Step: 8
Training loss: 2.6437074626269106
Validation loss: 2.4741371505092804

Epoch: 5| Step: 9
Training loss: 2.723432608078608
Validation loss: 2.4718579153056446

Epoch: 5| Step: 10
Training loss: 2.4279040693911313
Validation loss: 2.4627161329725853

Epoch: 5| Step: 11
Training loss: 3.344915169180479
Validation loss: 2.4665138281584014

Epoch: 152| Step: 0
Training loss: 2.5283740624718236
Validation loss: 2.4596596967886426

Epoch: 5| Step: 1
Training loss: 2.6859468807214206
Validation loss: 2.4635079618786895

Epoch: 5| Step: 2
Training loss: 2.9548928756789614
Validation loss: 2.454808894376485

Epoch: 5| Step: 3
Training loss: 2.162393415172739
Validation loss: 2.4613812364430756

Epoch: 5| Step: 4
Training loss: 2.04089880796083
Validation loss: 2.4579647375168676

Epoch: 5| Step: 5
Training loss: 2.6685709015474357
Validation loss: 2.4545730237129675

Epoch: 5| Step: 6
Training loss: 2.2988181685213442
Validation loss: 2.450565359350918

Epoch: 5| Step: 7
Training loss: 2.909173458998032
Validation loss: 2.460436024106522

Epoch: 5| Step: 8
Training loss: 2.4048066207005268
Validation loss: 2.4568487725272745

Epoch: 5| Step: 9
Training loss: 2.4557618954453995
Validation loss: 2.458718574102009

Epoch: 5| Step: 10
Training loss: 2.4413520501796255
Validation loss: 2.451981766076508

Epoch: 5| Step: 11
Training loss: 1.821844283249045
Validation loss: 2.459382036902682

Epoch: 153| Step: 0
Training loss: 2.967188374226438
Validation loss: 2.4634177934231882

Epoch: 5| Step: 1
Training loss: 2.3002319716526607
Validation loss: 2.459205575073093

Epoch: 5| Step: 2
Training loss: 2.42900316223592
Validation loss: 2.450866736965142

Epoch: 5| Step: 3
Training loss: 2.6985602672859312
Validation loss: 2.4568487846575784

Epoch: 5| Step: 4
Training loss: 2.1858116173644113
Validation loss: 2.450971099209465

Epoch: 5| Step: 5
Training loss: 2.0032950913793335
Validation loss: 2.4523782788232116

Epoch: 5| Step: 6
Training loss: 2.473358006504239
Validation loss: 2.453633193003264

Epoch: 5| Step: 7
Training loss: 2.6019312508463517
Validation loss: 2.4538288989623473

Epoch: 5| Step: 8
Training loss: 2.654126114787506
Validation loss: 2.454060390343102

Epoch: 5| Step: 9
Training loss: 2.4930671885250595
Validation loss: 2.4575090575479774

Epoch: 5| Step: 10
Training loss: 2.54559162780181
Validation loss: 2.4572171462853705

Epoch: 5| Step: 11
Training loss: 3.1561570862039505
Validation loss: 2.4585189439456046

Epoch: 154| Step: 0
Training loss: 2.6802722526447047
Validation loss: 2.4682208834174615

Epoch: 5| Step: 1
Training loss: 2.329701344418853
Validation loss: 2.4748498207183367

Epoch: 5| Step: 2
Training loss: 2.445839627034171
Validation loss: 2.4747950748416176

Epoch: 5| Step: 3
Training loss: 2.035185537292267
Validation loss: 2.478871485557243

Epoch: 5| Step: 4
Training loss: 2.8197759820684856
Validation loss: 2.484083710394078

Epoch: 5| Step: 5
Training loss: 2.5847693625589288
Validation loss: 2.4819676553681767

Epoch: 5| Step: 6
Training loss: 2.4447389362653222
Validation loss: 2.483082545074588

Epoch: 5| Step: 7
Training loss: 2.4117452122627028
Validation loss: 2.4832674912763792

Epoch: 5| Step: 8
Training loss: 2.150167982059592
Validation loss: 2.4831414749184026

Epoch: 5| Step: 9
Training loss: 2.877564986064335
Validation loss: 2.4838174798172785

Epoch: 5| Step: 10
Training loss: 3.0600959528420977
Validation loss: 2.4802267962818885

Epoch: 5| Step: 11
Training loss: 2.415864635982755
Validation loss: 2.4806941533239053

Epoch: 155| Step: 0
Training loss: 2.6498158336918682
Validation loss: 2.4832501734073578

Epoch: 5| Step: 1
Training loss: 2.933087057554689
Validation loss: 2.476206829151103

Epoch: 5| Step: 2
Training loss: 2.7104022022499588
Validation loss: 2.473566716301669

Epoch: 5| Step: 3
Training loss: 2.540225094410619
Validation loss: 2.4690814982748215

Epoch: 5| Step: 4
Training loss: 2.040483118706707
Validation loss: 2.4668151218507623

Epoch: 5| Step: 5
Training loss: 2.522919309338026
Validation loss: 2.4543004186243316

Epoch: 5| Step: 6
Training loss: 2.488654140157143
Validation loss: 2.456792333618137

Epoch: 5| Step: 7
Training loss: 2.289853528931482
Validation loss: 2.4608978167366944

Epoch: 5| Step: 8
Training loss: 2.7236491818652495
Validation loss: 2.4513682171529654

Epoch: 5| Step: 9
Training loss: 2.1719651237835023
Validation loss: 2.455785345498157

Epoch: 5| Step: 10
Training loss: 2.3187851936569093
Validation loss: 2.456638011586251

Epoch: 5| Step: 11
Training loss: 3.3244238676985858
Validation loss: 2.452973853150365

Epoch: 156| Step: 0
Training loss: 2.993662498007673
Validation loss: 2.452556611077527

Epoch: 5| Step: 1
Training loss: 2.751100060044119
Validation loss: 2.452403628633121

Epoch: 5| Step: 2
Training loss: 2.4399045186043664
Validation loss: 2.4516212345314092

Epoch: 5| Step: 3
Training loss: 2.7855246622571785
Validation loss: 2.4609620653167688

Epoch: 5| Step: 4
Training loss: 2.115390141353192
Validation loss: 2.456360507579063

Epoch: 5| Step: 5
Training loss: 2.350501952436067
Validation loss: 2.4541956595978838

Epoch: 5| Step: 6
Training loss: 2.6098524559089102
Validation loss: 2.4536760849134733

Epoch: 5| Step: 7
Training loss: 1.9082033124160285
Validation loss: 2.4537951916623566

Epoch: 5| Step: 8
Training loss: 2.0089297025162676
Validation loss: 2.449604310306388

Epoch: 5| Step: 9
Training loss: 2.7252157213410166
Validation loss: 2.4583863209547343

Epoch: 5| Step: 10
Training loss: 2.7940232213720346
Validation loss: 2.462313571075845

Epoch: 5| Step: 11
Training loss: 2.284272895336692
Validation loss: 2.4630599239767323

Epoch: 157| Step: 0
Training loss: 2.242520829256044
Validation loss: 2.4628144710503683

Epoch: 5| Step: 1
Training loss: 2.446936997058163
Validation loss: 2.468755919211973

Epoch: 5| Step: 2
Training loss: 2.416543420301686
Validation loss: 2.4764049491948708

Epoch: 5| Step: 3
Training loss: 2.6242555743464706
Validation loss: 2.470577915321028

Epoch: 5| Step: 4
Training loss: 2.70338376962043
Validation loss: 2.4777504030515427

Epoch: 5| Step: 5
Training loss: 2.9175369780745912
Validation loss: 2.4810856009598012

Epoch: 5| Step: 6
Training loss: 2.3546634138732134
Validation loss: 2.4697082607344853

Epoch: 5| Step: 7
Training loss: 2.5642602038831774
Validation loss: 2.4660292292054042

Epoch: 5| Step: 8
Training loss: 2.316638027901497
Validation loss: 2.475629809390235

Epoch: 5| Step: 9
Training loss: 2.6649112188498525
Validation loss: 2.4791940131936503

Epoch: 5| Step: 10
Training loss: 2.478737246297324
Validation loss: 2.4718880647811576

Epoch: 5| Step: 11
Training loss: 4.021499077953938
Validation loss: 2.4688498480841545

Epoch: 158| Step: 0
Training loss: 2.4696838930304708
Validation loss: 2.4689380256258215

Epoch: 5| Step: 1
Training loss: 2.419288484627368
Validation loss: 2.463993314724426

Epoch: 5| Step: 2
Training loss: 2.7675804509682798
Validation loss: 2.4774839449996477

Epoch: 5| Step: 3
Training loss: 2.594822213876079
Validation loss: 2.46961437657862

Epoch: 5| Step: 4
Training loss: 2.4233262174870025
Validation loss: 2.4744289285233947

Epoch: 5| Step: 5
Training loss: 2.355980762105224
Validation loss: 2.4692037342489366

Epoch: 5| Step: 6
Training loss: 2.5274727978549016
Validation loss: 2.4629652197056533

Epoch: 5| Step: 7
Training loss: 2.4640953511701214
Validation loss: 2.4679992073339636

Epoch: 5| Step: 8
Training loss: 2.1158461034008043
Validation loss: 2.46815336639211

Epoch: 5| Step: 9
Training loss: 2.9171934106293897
Validation loss: 2.467609878632839

Epoch: 5| Step: 10
Training loss: 2.6690118629932282
Validation loss: 2.470651674802942

Epoch: 5| Step: 11
Training loss: 2.072681841816302
Validation loss: 2.4644926277510093

Epoch: 159| Step: 0
Training loss: 2.948125896959166
Validation loss: 2.4677123170506237

Epoch: 5| Step: 1
Training loss: 2.431775928088094
Validation loss: 2.4631892161180446

Epoch: 5| Step: 2
Training loss: 2.438200532065443
Validation loss: 2.4632061426722425

Epoch: 5| Step: 3
Training loss: 2.6404149801489574
Validation loss: 2.4613351672161152

Epoch: 5| Step: 4
Training loss: 2.2210430062985353
Validation loss: 2.4569050686229574

Epoch: 5| Step: 5
Training loss: 2.3405098452590183
Validation loss: 2.4514430976351655

Epoch: 5| Step: 6
Training loss: 2.442772274088733
Validation loss: 2.4531287296534083

Epoch: 5| Step: 7
Training loss: 2.5244986839056787
Validation loss: 2.4419058977653414

Epoch: 5| Step: 8
Training loss: 2.284162465031
Validation loss: 2.44669674174909

Epoch: 5| Step: 9
Training loss: 2.5302720241034744
Validation loss: 2.4589522452827017

Epoch: 5| Step: 10
Training loss: 2.8294807682951046
Validation loss: 2.4490667739109826

Epoch: 5| Step: 11
Training loss: 1.8636621369823267
Validation loss: 2.452606385276527

Epoch: 160| Step: 0
Training loss: 2.6573450860476426
Validation loss: 2.4428783363012787

Epoch: 5| Step: 1
Training loss: 2.6522382173063437
Validation loss: 2.453776882404613

Epoch: 5| Step: 2
Training loss: 2.2762932423773896
Validation loss: 2.456396557655525

Epoch: 5| Step: 3
Training loss: 2.6487012523649747
Validation loss: 2.456572272971939

Epoch: 5| Step: 4
Training loss: 2.7456271343539855
Validation loss: 2.4647540173366123

Epoch: 5| Step: 5
Training loss: 2.7281507003639818
Validation loss: 2.4633383448588075

Epoch: 5| Step: 6
Training loss: 2.6062636413949054
Validation loss: 2.4642667583726383

Epoch: 5| Step: 7
Training loss: 2.470337272968616
Validation loss: 2.470944487551906

Epoch: 5| Step: 8
Training loss: 2.0298064751293534
Validation loss: 2.4625051238560176

Epoch: 5| Step: 9
Training loss: 2.1578761064462166
Validation loss: 2.462482984358193

Epoch: 5| Step: 10
Training loss: 2.2226598970889455
Validation loss: 2.456872770194736

Epoch: 5| Step: 11
Training loss: 3.3953956056650787
Validation loss: 2.463608437749592

Epoch: 161| Step: 0
Training loss: 2.1580813826664245
Validation loss: 2.4555953924177896

Epoch: 5| Step: 1
Training loss: 3.187951747821091
Validation loss: 2.4531478637796105

Epoch: 5| Step: 2
Training loss: 3.053437662660467
Validation loss: 2.4446509038068323

Epoch: 5| Step: 3
Training loss: 2.698955340857977
Validation loss: 2.4483571582848547

Epoch: 5| Step: 4
Training loss: 2.1124586383449646
Validation loss: 2.4424524125741343

Epoch: 5| Step: 5
Training loss: 2.0628239926262357
Validation loss: 2.446916316281616

Epoch: 5| Step: 6
Training loss: 2.5753832485579937
Validation loss: 2.4427191985538683

Epoch: 5| Step: 7
Training loss: 2.2958901298499206
Validation loss: 2.4548266435535857

Epoch: 5| Step: 8
Training loss: 2.2677347817468068
Validation loss: 2.4495676087274183

Epoch: 5| Step: 9
Training loss: 2.244699911438794
Validation loss: 2.449962851751997

Epoch: 5| Step: 10
Training loss: 2.6395653398638657
Validation loss: 2.4554952076493803

Epoch: 5| Step: 11
Training loss: 2.0984577373968887
Validation loss: 2.456697937676004

Epoch: 162| Step: 0
Training loss: 2.5448503930686783
Validation loss: 2.4570781256525818

Epoch: 5| Step: 1
Training loss: 2.441754857923671
Validation loss: 2.462959415645828

Epoch: 5| Step: 2
Training loss: 2.4292908372327084
Validation loss: 2.4735546197591973

Epoch: 5| Step: 3
Training loss: 3.0767710849928767
Validation loss: 2.468108568681813

Epoch: 5| Step: 4
Training loss: 2.6495216873643375
Validation loss: 2.4713117530862596

Epoch: 5| Step: 5
Training loss: 2.569692612310884
Validation loss: 2.471064898675948

Epoch: 5| Step: 6
Training loss: 2.144245955593391
Validation loss: 2.472846746514081

Epoch: 5| Step: 7
Training loss: 2.504290142178206
Validation loss: 2.471187776217294

Epoch: 5| Step: 8
Training loss: 2.1498473933862967
Validation loss: 2.464002079647237

Epoch: 5| Step: 9
Training loss: 2.55767787236497
Validation loss: 2.4528071689632833

Epoch: 5| Step: 10
Training loss: 2.262380447179643
Validation loss: 2.444603383491528

Epoch: 5| Step: 11
Training loss: 3.00813351193842
Validation loss: 2.4470608994243555

Epoch: 163| Step: 0
Training loss: 2.111685949276161
Validation loss: 2.4461722685546663

Epoch: 5| Step: 1
Training loss: 2.0395921041308505
Validation loss: 2.4499325520774544

Epoch: 5| Step: 2
Training loss: 2.3960889818102418
Validation loss: 2.45227516745189

Epoch: 5| Step: 3
Training loss: 2.249005203736333
Validation loss: 2.44650500696578

Epoch: 5| Step: 4
Training loss: 2.3077962307882767
Validation loss: 2.4485577548709774

Epoch: 5| Step: 5
Training loss: 2.714598720113652
Validation loss: 2.446106027340646

Epoch: 5| Step: 6
Training loss: 2.6487385176463305
Validation loss: 2.445522185609045

Epoch: 5| Step: 7
Training loss: 3.009432903616093
Validation loss: 2.4427063554919815

Epoch: 5| Step: 8
Training loss: 2.4103843543926513
Validation loss: 2.44106422571685

Epoch: 5| Step: 9
Training loss: 2.641441986284525
Validation loss: 2.45055013930296

Epoch: 5| Step: 10
Training loss: 2.748959257687761
Validation loss: 2.4506680156898972

Epoch: 5| Step: 11
Training loss: 1.9570604881797935
Validation loss: 2.4685056138902333

Epoch: 164| Step: 0
Training loss: 2.033516543634116
Validation loss: 2.461813352028775

Epoch: 5| Step: 1
Training loss: 1.9786596217574142
Validation loss: 2.4716430806041876

Epoch: 5| Step: 2
Training loss: 2.35399180300184
Validation loss: 2.4689421116246093

Epoch: 5| Step: 3
Training loss: 2.547498287391274
Validation loss: 2.471683517768592

Epoch: 5| Step: 4
Training loss: 2.7250648035865748
Validation loss: 2.4655526860103762

Epoch: 5| Step: 5
Training loss: 2.737387605214885
Validation loss: 2.4659268840257855

Epoch: 5| Step: 6
Training loss: 3.292471598138447
Validation loss: 2.470218672268398

Epoch: 5| Step: 7
Training loss: 2.6519913586782113
Validation loss: 2.464093911908691

Epoch: 5| Step: 8
Training loss: 2.051884701276254
Validation loss: 2.466864707016168

Epoch: 5| Step: 9
Training loss: 1.7928590429314417
Validation loss: 2.463575021519316

Epoch: 5| Step: 10
Training loss: 2.950894921547139
Validation loss: 2.4645003388383264

Epoch: 5| Step: 11
Training loss: 2.6180487738627445
Validation loss: 2.468005019667388

Epoch: 165| Step: 0
Training loss: 2.0144789638789096
Validation loss: 2.4644496177414186

Epoch: 5| Step: 1
Training loss: 2.221279904792683
Validation loss: 2.4595747146399436

Epoch: 5| Step: 2
Training loss: 2.3523294712572076
Validation loss: 2.460208841462112

Epoch: 5| Step: 3
Training loss: 2.3549498434050804
Validation loss: 2.4668021163018916

Epoch: 5| Step: 4
Training loss: 2.820521296752962
Validation loss: 2.455758564201007

Epoch: 5| Step: 5
Training loss: 2.047857383679733
Validation loss: 2.4588277704790547

Epoch: 5| Step: 6
Training loss: 2.5625541495207615
Validation loss: 2.461230701560092

Epoch: 5| Step: 7
Training loss: 3.0284243913004074
Validation loss: 2.4552476612470033

Epoch: 5| Step: 8
Training loss: 2.4486503854209105
Validation loss: 2.4558467101966923

Epoch: 5| Step: 9
Training loss: 2.5866714772772874
Validation loss: 2.4516800737360165

Epoch: 5| Step: 10
Training loss: 2.7287097771721105
Validation loss: 2.463381680757027

Epoch: 5| Step: 11
Training loss: 2.0826523875961187
Validation loss: 2.459448401209264

Epoch: 166| Step: 0
Training loss: 2.9333460229541384
Validation loss: 2.4623953603403046

Epoch: 5| Step: 1
Training loss: 2.9417479621813367
Validation loss: 2.4585757594000377

Epoch: 5| Step: 2
Training loss: 1.748580356792377
Validation loss: 2.4640407634672195

Epoch: 5| Step: 3
Training loss: 2.7358327413096055
Validation loss: 2.4651270288991936

Epoch: 5| Step: 4
Training loss: 2.0700293005376103
Validation loss: 2.459570057722355

Epoch: 5| Step: 5
Training loss: 2.128598028146622
Validation loss: 2.464768095714423

Epoch: 5| Step: 6
Training loss: 2.267704923174818
Validation loss: 2.453786153444403

Epoch: 5| Step: 7
Training loss: 2.3465968834550943
Validation loss: 2.4611787667661487

Epoch: 5| Step: 8
Training loss: 2.3489056656734664
Validation loss: 2.4657138995383834

Epoch: 5| Step: 9
Training loss: 2.9928047997585825
Validation loss: 2.4605466986482165

Epoch: 5| Step: 10
Training loss: 2.347711800475007
Validation loss: 2.4618500243849932

Epoch: 5| Step: 11
Training loss: 2.9938058485583703
Validation loss: 2.4632588050078623

Epoch: 167| Step: 0
Training loss: 2.714184665950146
Validation loss: 2.4622005713062163

Epoch: 5| Step: 1
Training loss: 2.153803335670724
Validation loss: 2.465811924684063

Epoch: 5| Step: 2
Training loss: 2.8233726574239557
Validation loss: 2.4671244480547148

Epoch: 5| Step: 3
Training loss: 2.6384476030592983
Validation loss: 2.467671355881187

Epoch: 5| Step: 4
Training loss: 2.241073916699283
Validation loss: 2.466888518656005

Epoch: 5| Step: 5
Training loss: 2.0462186503586763
Validation loss: 2.4641335860315188

Epoch: 5| Step: 6
Training loss: 2.6110756637205257
Validation loss: 2.4674863075886484

Epoch: 5| Step: 7
Training loss: 2.6394989501985724
Validation loss: 2.4649171289321683

Epoch: 5| Step: 8
Training loss: 2.5547800776421417
Validation loss: 2.4551178679363868

Epoch: 5| Step: 9
Training loss: 2.4706624988940034
Validation loss: 2.453418467111811

Epoch: 5| Step: 10
Training loss: 2.430081841460297
Validation loss: 2.4533849525808895

Epoch: 5| Step: 11
Training loss: 1.5221693189079868
Validation loss: 2.4591348433872735

Epoch: 168| Step: 0
Training loss: 2.5352956207477106
Validation loss: 2.468105859863378

Epoch: 5| Step: 1
Training loss: 1.7387469750055125
Validation loss: 2.4669564085553355

Epoch: 5| Step: 2
Training loss: 2.057001471675185
Validation loss: 2.473072203833491

Epoch: 5| Step: 3
Training loss: 2.307040600575256
Validation loss: 2.4711858305497287

Epoch: 5| Step: 4
Training loss: 2.7664850481774796
Validation loss: 2.459609861360626

Epoch: 5| Step: 5
Training loss: 2.4773266693363682
Validation loss: 2.4507744374462743

Epoch: 5| Step: 6
Training loss: 2.6598744516214805
Validation loss: 2.4593408360061337

Epoch: 5| Step: 7
Training loss: 2.433927901887337
Validation loss: 2.475871108946156

Epoch: 5| Step: 8
Training loss: 2.788445412465222
Validation loss: 2.488166399211036

Epoch: 5| Step: 9
Training loss: 3.000707383998367
Validation loss: 2.4941438571846257

Epoch: 5| Step: 10
Training loss: 2.649825371080687
Validation loss: 2.489339833874363

Epoch: 5| Step: 11
Training loss: 1.644934887858355
Validation loss: 2.4882039727348464

Epoch: 169| Step: 0
Training loss: 2.419473158496506
Validation loss: 2.4897920901402673

Epoch: 5| Step: 1
Training loss: 2.4356939031277896
Validation loss: 2.4921303785388864

Epoch: 5| Step: 2
Training loss: 2.4106880973725575
Validation loss: 2.49101159427088

Epoch: 5| Step: 3
Training loss: 2.632125085577334
Validation loss: 2.49171906137611

Epoch: 5| Step: 4
Training loss: 2.498665071754937
Validation loss: 2.486722217221429

Epoch: 5| Step: 5
Training loss: 2.673178371621757
Validation loss: 2.4867555081655572

Epoch: 5| Step: 6
Training loss: 2.1599115436596765
Validation loss: 2.4824326037503477

Epoch: 5| Step: 7
Training loss: 2.921770879348881
Validation loss: 2.4868348138001726

Epoch: 5| Step: 8
Training loss: 2.9065333402602547
Validation loss: 2.4839604109789777

Epoch: 5| Step: 9
Training loss: 2.571528648518022
Validation loss: 2.4770192809094373

Epoch: 5| Step: 10
Training loss: 2.388029497159317
Validation loss: 2.4765520586983025

Epoch: 5| Step: 11
Training loss: 1.9391160193718355
Validation loss: 2.4760702428157066

Epoch: 170| Step: 0
Training loss: 2.1251006383065505
Validation loss: 2.47944817961594

Epoch: 5| Step: 1
Training loss: 2.4753380284523847
Validation loss: 2.470648263113594

Epoch: 5| Step: 2
Training loss: 2.6923516416630506
Validation loss: 2.4705328881440267

Epoch: 5| Step: 3
Training loss: 2.395021372880918
Validation loss: 2.4739903872906326

Epoch: 5| Step: 4
Training loss: 2.9178576263144516
Validation loss: 2.4613433180348534

Epoch: 5| Step: 5
Training loss: 2.4497453284734396
Validation loss: 2.4687693691701016

Epoch: 5| Step: 6
Training loss: 2.13914371667887
Validation loss: 2.4636971214286754

Epoch: 5| Step: 7
Training loss: 2.1051153052637783
Validation loss: 2.4618485394234346

Epoch: 5| Step: 8
Training loss: 2.9966068151803227
Validation loss: 2.473893172091939

Epoch: 5| Step: 9
Training loss: 2.401913289527525
Validation loss: 2.4737488641233507

Epoch: 5| Step: 10
Training loss: 2.714840939746747
Validation loss: 2.47025438739418

Epoch: 5| Step: 11
Training loss: 2.6806265295072795
Validation loss: 2.471499292408927

Epoch: 171| Step: 0
Training loss: 2.5973353596443767
Validation loss: 2.475276617204177

Epoch: 5| Step: 1
Training loss: 2.122320280700076
Validation loss: 2.4738052816062646

Epoch: 5| Step: 2
Training loss: 2.8707127324772896
Validation loss: 2.4684495421152617

Epoch: 5| Step: 3
Training loss: 2.590821876913634
Validation loss: 2.4606213724853916

Epoch: 5| Step: 4
Training loss: 2.394631413267544
Validation loss: 2.46886838154307

Epoch: 5| Step: 5
Training loss: 2.6157868694137734
Validation loss: 2.4610679390060204

Epoch: 5| Step: 6
Training loss: 2.4229214284188036
Validation loss: 2.461269749813554

Epoch: 5| Step: 7
Training loss: 2.295416647961332
Validation loss: 2.4627711453398575

Epoch: 5| Step: 8
Training loss: 2.4448106147108772
Validation loss: 2.464342573170071

Epoch: 5| Step: 9
Training loss: 2.2989374360029378
Validation loss: 2.4589548025860273

Epoch: 5| Step: 10
Training loss: 2.2881596057216167
Validation loss: 2.4609788235217382

Epoch: 5| Step: 11
Training loss: 3.804989279933671
Validation loss: 2.461530232573358

Epoch: 172| Step: 0
Training loss: 2.535302767759019
Validation loss: 2.468000491361708

Epoch: 5| Step: 1
Training loss: 2.8094973324289336
Validation loss: 2.465924003611516

Epoch: 5| Step: 2
Training loss: 2.4485611953114543
Validation loss: 2.4724028679990258

Epoch: 5| Step: 3
Training loss: 2.1613896247943027
Validation loss: 2.4605073623565166

Epoch: 5| Step: 4
Training loss: 2.5383831347737495
Validation loss: 2.4660462752444157

Epoch: 5| Step: 5
Training loss: 2.0967371114996727
Validation loss: 2.4684448093786284

Epoch: 5| Step: 6
Training loss: 2.4509016518753923
Validation loss: 2.4686899499792743

Epoch: 5| Step: 7
Training loss: 2.3198457498902143
Validation loss: 2.4652232841653645

Epoch: 5| Step: 8
Training loss: 2.90816131418274
Validation loss: 2.466731046682755

Epoch: 5| Step: 9
Training loss: 2.8116828579107636
Validation loss: 2.4676021450561074

Epoch: 5| Step: 10
Training loss: 2.335339319704779
Validation loss: 2.468527679251345

Epoch: 5| Step: 11
Training loss: 1.5031267003547426
Validation loss: 2.464754988678746

Epoch: 173| Step: 0
Training loss: 2.6250346045256765
Validation loss: 2.4668469639130444

Epoch: 5| Step: 1
Training loss: 2.391051709358238
Validation loss: 2.4612788533821273

Epoch: 5| Step: 2
Training loss: 2.43234157034565
Validation loss: 2.4670455980392045

Epoch: 5| Step: 3
Training loss: 2.679891595213726
Validation loss: 2.4821290634584865

Epoch: 5| Step: 4
Training loss: 2.2146881963880287
Validation loss: 2.4756284972174742

Epoch: 5| Step: 5
Training loss: 1.971708345700903
Validation loss: 2.470236033237973

Epoch: 5| Step: 6
Training loss: 2.727557069232094
Validation loss: 2.463857031080692

Epoch: 5| Step: 7
Training loss: 2.6174547656795175
Validation loss: 2.4652028817156006

Epoch: 5| Step: 8
Training loss: 2.974688403056004
Validation loss: 2.4714624135329046

Epoch: 5| Step: 9
Training loss: 2.5289124421287528
Validation loss: 2.4761670676382956

Epoch: 5| Step: 10
Training loss: 2.1744518773237718
Validation loss: 2.4776427423086873

Epoch: 5| Step: 11
Training loss: 2.1864606295411977
Validation loss: 2.476588211969023

Epoch: 174| Step: 0
Training loss: 2.851591094409287
Validation loss: 2.474849565827777

Epoch: 5| Step: 1
Training loss: 2.420667778127645
Validation loss: 2.479977652727213

Epoch: 5| Step: 2
Training loss: 2.44835563673746
Validation loss: 2.4807526753846956

Epoch: 5| Step: 3
Training loss: 3.1211679996448183
Validation loss: 2.4741252615309897

Epoch: 5| Step: 4
Training loss: 2.307857492843826
Validation loss: 2.470615969441234

Epoch: 5| Step: 5
Training loss: 2.486192722034765
Validation loss: 2.473714705400648

Epoch: 5| Step: 6
Training loss: 2.4043676767220363
Validation loss: 2.4671362097065246

Epoch: 5| Step: 7
Training loss: 2.920651266288891
Validation loss: 2.4681386472341305

Epoch: 5| Step: 8
Training loss: 2.1949378946333784
Validation loss: 2.465225843022814

Epoch: 5| Step: 9
Training loss: 2.272150363526828
Validation loss: 2.463319398774347

Epoch: 5| Step: 10
Training loss: 2.178829995206201
Validation loss: 2.46107344478959

Epoch: 5| Step: 11
Training loss: 2.1717472176044916
Validation loss: 2.459057056180043

Epoch: 175| Step: 0
Training loss: 2.2074186002038396
Validation loss: 2.45960068497269

Epoch: 5| Step: 1
Training loss: 2.5504123952657722
Validation loss: 2.464805582580241

Epoch: 5| Step: 2
Training loss: 2.178423662110253
Validation loss: 2.4646369214545505

Epoch: 5| Step: 3
Training loss: 2.005299699031187
Validation loss: 2.4659570194029876

Epoch: 5| Step: 4
Training loss: 1.98767476303155
Validation loss: 2.4594216577805006

Epoch: 5| Step: 5
Training loss: 2.679766951292318
Validation loss: 2.456985829008807

Epoch: 5| Step: 6
Training loss: 2.4330742589214718
Validation loss: 2.4616162368250905

Epoch: 5| Step: 7
Training loss: 2.625959402690075
Validation loss: 2.456490227144413

Epoch: 5| Step: 8
Training loss: 3.167835990108941
Validation loss: 2.4673294897856928

Epoch: 5| Step: 9
Training loss: 2.3261584482518147
Validation loss: 2.45992611078877

Epoch: 5| Step: 10
Training loss: 2.8864468458083126
Validation loss: 2.4584211775607727

Epoch: 5| Step: 11
Training loss: 1.4266524488120917
Validation loss: 2.45656487466448

Epoch: 176| Step: 0
Training loss: 2.675712283839784
Validation loss: 2.46910541326055

Epoch: 5| Step: 1
Training loss: 2.8490020544031998
Validation loss: 2.462142350677411

Epoch: 5| Step: 2
Training loss: 2.319472138270607
Validation loss: 2.457645604278721

Epoch: 5| Step: 3
Training loss: 2.1104554976430414
Validation loss: 2.4647016529650525

Epoch: 5| Step: 4
Training loss: 2.612939376022677
Validation loss: 2.468706460560775

Epoch: 5| Step: 5
Training loss: 2.2450631339662555
Validation loss: 2.466594044372376

Epoch: 5| Step: 6
Training loss: 2.317924426573988
Validation loss: 2.470200792393179

Epoch: 5| Step: 7
Training loss: 2.2574393944193316
Validation loss: 2.468737179686661

Epoch: 5| Step: 8
Training loss: 3.0439204048848607
Validation loss: 2.4786926759409806

Epoch: 5| Step: 9
Training loss: 2.1574268170406685
Validation loss: 2.4711394174822137

Epoch: 5| Step: 10
Training loss: 2.459340767337397
Validation loss: 2.475511020828491

Epoch: 5| Step: 11
Training loss: 1.4616195800023062
Validation loss: 2.4782271180954085

Epoch: 177| Step: 0
Training loss: 2.097641246891179
Validation loss: 2.4787788461765934

Epoch: 5| Step: 1
Training loss: 2.221877244822123
Validation loss: 2.471345595307086

Epoch: 5| Step: 2
Training loss: 2.170199070074831
Validation loss: 2.480917333855775

Epoch: 5| Step: 3
Training loss: 2.771035887310633
Validation loss: 2.487600971134305

Epoch: 5| Step: 4
Training loss: 2.5392828743006466
Validation loss: 2.483556196647435

Epoch: 5| Step: 5
Training loss: 2.410220647659474
Validation loss: 2.476010306136601

Epoch: 5| Step: 6
Training loss: 3.1179397172563066
Validation loss: 2.4710315149369575

Epoch: 5| Step: 7
Training loss: 2.779009055530225
Validation loss: 2.4727757582226175

Epoch: 5| Step: 8
Training loss: 2.1917419720417084
Validation loss: 2.481416059809754

Epoch: 5| Step: 9
Training loss: 2.2994720931212576
Validation loss: 2.47384016189767

Epoch: 5| Step: 10
Training loss: 2.294054544380755
Validation loss: 2.478752744137413

Epoch: 5| Step: 11
Training loss: 2.853406336138653
Validation loss: 2.4801499209414057

Epoch: 178| Step: 0
Training loss: 2.6383990775724966
Validation loss: 2.4804704000312343

Epoch: 5| Step: 1
Training loss: 2.469750213811475
Validation loss: 2.4711617829369388

Epoch: 5| Step: 2
Training loss: 2.598281762094784
Validation loss: 2.4710967261776573

Epoch: 5| Step: 3
Training loss: 2.4109522464916804
Validation loss: 2.4740483933503126

Epoch: 5| Step: 4
Training loss: 2.473287348186955
Validation loss: 2.4852018839613623

Epoch: 5| Step: 5
Training loss: 2.447905119740192
Validation loss: 2.5001419225780928

Epoch: 5| Step: 6
Training loss: 2.6422791125061393
Validation loss: 2.4916627106162044

Epoch: 5| Step: 7
Training loss: 2.4753430369616987
Validation loss: 2.5069644401177884

Epoch: 5| Step: 8
Training loss: 2.8487111506840663
Validation loss: 2.5047979844907404

Epoch: 5| Step: 9
Training loss: 2.223526018515882
Validation loss: 2.5040038353148693

Epoch: 5| Step: 10
Training loss: 1.9220465606781734
Validation loss: 2.4906757437316296

Epoch: 5| Step: 11
Training loss: 1.9206304474743132
Validation loss: 2.4767876210868227

Epoch: 179| Step: 0
Training loss: 2.289820106303589
Validation loss: 2.480926415381459

Epoch: 5| Step: 1
Training loss: 2.3348493306072156
Validation loss: 2.476149427299453

Epoch: 5| Step: 2
Training loss: 2.263641962836236
Validation loss: 2.476016910115202

Epoch: 5| Step: 3
Training loss: 2.4183798888773183
Validation loss: 2.48197717532676

Epoch: 5| Step: 4
Training loss: 1.9365071244545822
Validation loss: 2.4770784211704924

Epoch: 5| Step: 5
Training loss: 2.4835505047081354
Validation loss: 2.4841916518462233

Epoch: 5| Step: 6
Training loss: 2.7771963517661886
Validation loss: 2.475562853583281

Epoch: 5| Step: 7
Training loss: 2.596097963497888
Validation loss: 2.4802407587957966

Epoch: 5| Step: 8
Training loss: 2.6519607020152014
Validation loss: 2.4811768249560355

Epoch: 5| Step: 9
Training loss: 2.617282512705164
Validation loss: 2.4854677664040845

Epoch: 5| Step: 10
Training loss: 2.72622862249963
Validation loss: 2.485450871550114

Epoch: 5| Step: 11
Training loss: 3.394916964654572
Validation loss: 2.476367754253811

Epoch: 180| Step: 0
Training loss: 2.4211839243666664
Validation loss: 2.4765158647865615

Epoch: 5| Step: 1
Training loss: 2.5416792780662294
Validation loss: 2.478313915801498

Epoch: 5| Step: 2
Training loss: 2.5139626643792994
Validation loss: 2.4749866128809916

Epoch: 5| Step: 3
Training loss: 2.270507077452838
Validation loss: 2.4780945195956874

Epoch: 5| Step: 4
Training loss: 2.3083890511115115
Validation loss: 2.4817737460577978

Epoch: 5| Step: 5
Training loss: 2.2928204724070667
Validation loss: 2.4721251565711007

Epoch: 5| Step: 6
Training loss: 2.317810456387032
Validation loss: 2.4751638680935577

Epoch: 5| Step: 7
Training loss: 2.9024694320554203
Validation loss: 2.4820339761202126

Epoch: 5| Step: 8
Training loss: 2.293613011897593
Validation loss: 2.4759433225028578

Epoch: 5| Step: 9
Training loss: 2.444375733170854
Validation loss: 2.4776265879823334

Epoch: 5| Step: 10
Training loss: 2.4101014463354895
Validation loss: 2.4824969512687676

Epoch: 5| Step: 11
Training loss: 3.415504692171582
Validation loss: 2.4825934814236836

Epoch: 181| Step: 0
Training loss: 2.5037175195180272
Validation loss: 2.482786310408695

Epoch: 5| Step: 1
Training loss: 2.3030443443968465
Validation loss: 2.476815316084948

Epoch: 5| Step: 2
Training loss: 2.3000319188432483
Validation loss: 2.4832839089367402

Epoch: 5| Step: 3
Training loss: 2.5898851762453203
Validation loss: 2.478616426350497

Epoch: 5| Step: 4
Training loss: 2.5743209980641923
Validation loss: 2.4758574849111348

Epoch: 5| Step: 5
Training loss: 2.745611243366571
Validation loss: 2.4781961297742345

Epoch: 5| Step: 6
Training loss: 2.2543024676790138
Validation loss: 2.479328600352595

Epoch: 5| Step: 7
Training loss: 2.155626510924852
Validation loss: 2.4703380933252563

Epoch: 5| Step: 8
Training loss: 2.879338515398091
Validation loss: 2.4665617157436124

Epoch: 5| Step: 9
Training loss: 2.4530326680100916
Validation loss: 2.481583092157363

Epoch: 5| Step: 10
Training loss: 2.1754295845673535
Validation loss: 2.47571918798574

Epoch: 5| Step: 11
Training loss: 2.9312743098505543
Validation loss: 2.47732211796958

Epoch: 182| Step: 0
Training loss: 2.828605484585427
Validation loss: 2.480343468573554

Epoch: 5| Step: 1
Training loss: 2.5754773040168417
Validation loss: 2.4849470747461297

Epoch: 5| Step: 2
Training loss: 2.3703936025465584
Validation loss: 2.499092354519231

Epoch: 5| Step: 3
Training loss: 2.497891681494221
Validation loss: 2.4886044183108296

Epoch: 5| Step: 4
Training loss: 2.423209038301162
Validation loss: 2.478929681964762

Epoch: 5| Step: 5
Training loss: 2.6496307475664804
Validation loss: 2.484710174918947

Epoch: 5| Step: 6
Training loss: 2.110181301156083
Validation loss: 2.4823438430555287

Epoch: 5| Step: 7
Training loss: 2.6046738906257665
Validation loss: 2.4786379728588734

Epoch: 5| Step: 8
Training loss: 2.165704097651945
Validation loss: 2.485208423542123

Epoch: 5| Step: 9
Training loss: 2.333407151099073
Validation loss: 2.480907407405856

Epoch: 5| Step: 10
Training loss: 2.5386295829850667
Validation loss: 2.4794401424034533

Epoch: 5| Step: 11
Training loss: 2.1669834956802365
Validation loss: 2.4858899765539224

Epoch: 183| Step: 0
Training loss: 2.657806837826034
Validation loss: 2.4850074155071304

Epoch: 5| Step: 1
Training loss: 2.314364944258974
Validation loss: 2.484741275905732

Epoch: 5| Step: 2
Training loss: 2.1777780571221586
Validation loss: 2.4857644728013826

Epoch: 5| Step: 3
Training loss: 2.971855707436886
Validation loss: 2.483809476740878

Epoch: 5| Step: 4
Training loss: 2.4808663597723375
Validation loss: 2.4847664754556553

Epoch: 5| Step: 5
Training loss: 1.983802652796008
Validation loss: 2.4863212287689325

Epoch: 5| Step: 6
Training loss: 2.7103035045304282
Validation loss: 2.483829762349645

Epoch: 5| Step: 7
Training loss: 2.2275097354629074
Validation loss: 2.4866108220462824

Epoch: 5| Step: 8
Training loss: 2.576334938748021
Validation loss: 2.4981329343604717

Epoch: 5| Step: 9
Training loss: 2.8924774008142555
Validation loss: 2.4995112100242856

Epoch: 5| Step: 10
Training loss: 2.1974941287434233
Validation loss: 2.500672083160906

Epoch: 5| Step: 11
Training loss: 1.9707406289016849
Validation loss: 2.4990209967285892

Epoch: 184| Step: 0
Training loss: 2.3254879347185367
Validation loss: 2.496487693364606

Epoch: 5| Step: 1
Training loss: 2.352999530096692
Validation loss: 2.5004586673237625

Epoch: 5| Step: 2
Training loss: 2.730968686069914
Validation loss: 2.5041949521803595

Epoch: 5| Step: 3
Training loss: 2.5412424911335547
Validation loss: 2.493373477048666

Epoch: 5| Step: 4
Training loss: 2.340451882737899
Validation loss: 2.4998451502844725

Epoch: 5| Step: 5
Training loss: 2.0456348185619753
Validation loss: 2.499667173324356

Epoch: 5| Step: 6
Training loss: 2.8432177370401526
Validation loss: 2.4938593033408827

Epoch: 5| Step: 7
Training loss: 2.0918156812661266
Validation loss: 2.4846368127897653

Epoch: 5| Step: 8
Training loss: 2.524712113691191
Validation loss: 2.483708570173531

Epoch: 5| Step: 9
Training loss: 2.4983154343397973
Validation loss: 2.4812911024620874

Epoch: 5| Step: 10
Training loss: 2.504996932555127
Validation loss: 2.4829686860944378

Epoch: 5| Step: 11
Training loss: 3.1063624217760495
Validation loss: 2.475912347727049

Epoch: 185| Step: 0
Training loss: 2.5699914424471744
Validation loss: 2.4808390423580144

Epoch: 5| Step: 1
Training loss: 2.5084829414674235
Validation loss: 2.483829298406185

Epoch: 5| Step: 2
Training loss: 2.3154745817558275
Validation loss: 2.497277975367611

Epoch: 5| Step: 3
Training loss: 2.8186523961933307
Validation loss: 2.4843804381369003

Epoch: 5| Step: 4
Training loss: 2.330463847539786
Validation loss: 2.4853285832769854

Epoch: 5| Step: 5
Training loss: 1.9969665649625608
Validation loss: 2.4812723695273533

Epoch: 5| Step: 6
Training loss: 2.7009661217562955
Validation loss: 2.4811714278431456

Epoch: 5| Step: 7
Training loss: 2.777835850638414
Validation loss: 2.4895359510969812

Epoch: 5| Step: 8
Training loss: 2.3212034011460925
Validation loss: 2.481647773939336

Epoch: 5| Step: 9
Training loss: 1.748987381742925
Validation loss: 2.4829045428497367

Epoch: 5| Step: 10
Training loss: 2.6800823310048436
Validation loss: 2.4840918645524046

Epoch: 5| Step: 11
Training loss: 2.100225427426375
Validation loss: 2.489679064699074

Epoch: 186| Step: 0
Training loss: 1.9376337558968586
Validation loss: 2.4876780035716526

Epoch: 5| Step: 1
Training loss: 2.5678233236340318
Validation loss: 2.4822107440875585

Epoch: 5| Step: 2
Training loss: 2.7603794503252326
Validation loss: 2.489071415631582

Epoch: 5| Step: 3
Training loss: 2.645925224891159
Validation loss: 2.4865181234261655

Epoch: 5| Step: 4
Training loss: 2.5442039665772405
Validation loss: 2.4893219596466407

Epoch: 5| Step: 5
Training loss: 2.1110287435536303
Validation loss: 2.4918914467605537

Epoch: 5| Step: 6
Training loss: 2.508543864526085
Validation loss: 2.48775327661438

Epoch: 5| Step: 7
Training loss: 1.9558561227145543
Validation loss: 2.4947403097474528

Epoch: 5| Step: 8
Training loss: 2.356789694582388
Validation loss: 2.492000943558761

Epoch: 5| Step: 9
Training loss: 3.0878030666843843
Validation loss: 2.5011493385352552

Epoch: 5| Step: 10
Training loss: 2.217989616658679
Validation loss: 2.5030375623730685

Epoch: 5| Step: 11
Training loss: 2.9692152762968584
Validation loss: 2.494084070052906

Epoch: 187| Step: 0
Training loss: 2.3487834541086228
Validation loss: 2.4899363540139543

Epoch: 5| Step: 1
Training loss: 2.3993055531019793
Validation loss: 2.4870814051093126

Epoch: 5| Step: 2
Training loss: 2.3830307157060084
Validation loss: 2.48127247762548

Epoch: 5| Step: 3
Training loss: 2.1374197024605515
Validation loss: 2.4854711197811237

Epoch: 5| Step: 4
Training loss: 2.127791422553119
Validation loss: 2.479591967595928

Epoch: 5| Step: 5
Training loss: 2.7222430710632106
Validation loss: 2.4809849239554

Epoch: 5| Step: 6
Training loss: 2.6507830740385248
Validation loss: 2.475446070344647

Epoch: 5| Step: 7
Training loss: 2.0039732328823985
Validation loss: 2.4765486932443865

Epoch: 5| Step: 8
Training loss: 2.6818051881578246
Validation loss: 2.4851038441493447

Epoch: 5| Step: 9
Training loss: 2.5275556189570563
Validation loss: 2.487818472809193

Epoch: 5| Step: 10
Training loss: 2.8257954313150684
Validation loss: 2.4859235204099384

Epoch: 5| Step: 11
Training loss: 2.4277672738556797
Validation loss: 2.5017211472993766

Epoch: 188| Step: 0
Training loss: 2.762004400477678
Validation loss: 2.4859553574824407

Epoch: 5| Step: 1
Training loss: 2.3013561935829125
Validation loss: 2.478383979878449

Epoch: 5| Step: 2
Training loss: 2.1120270058465853
Validation loss: 2.480882476985785

Epoch: 5| Step: 3
Training loss: 1.6387297082455061
Validation loss: 2.4780584123539846

Epoch: 5| Step: 4
Training loss: 1.9687925061678109
Validation loss: 2.4842031687366983

Epoch: 5| Step: 5
Training loss: 2.7745486330550237
Validation loss: 2.478563094329577

Epoch: 5| Step: 6
Training loss: 2.02802501837593
Validation loss: 2.485355447642469

Epoch: 5| Step: 7
Training loss: 2.767888495272077
Validation loss: 2.4859341581215446

Epoch: 5| Step: 8
Training loss: 2.9454747162929933
Validation loss: 2.4835985797852316

Epoch: 5| Step: 9
Training loss: 2.632729639396437
Validation loss: 2.4878849290816616

Epoch: 5| Step: 10
Training loss: 2.289956604992021
Validation loss: 2.4863937700889687

Epoch: 5| Step: 11
Training loss: 3.723148085295435
Validation loss: 2.488107308896045

Epoch: 189| Step: 0
Training loss: 2.3452145895956815
Validation loss: 2.493588897613031

Epoch: 5| Step: 1
Training loss: 2.1863677227938814
Validation loss: 2.488132693947896

Epoch: 5| Step: 2
Training loss: 2.31152302492603
Validation loss: 2.4858593135409213

Epoch: 5| Step: 3
Training loss: 3.2843266186839277
Validation loss: 2.4836825039438475

Epoch: 5| Step: 4
Training loss: 2.1532994967814756
Validation loss: 2.4896130713012834

Epoch: 5| Step: 5
Training loss: 1.9607895267174182
Validation loss: 2.493442219549126

Epoch: 5| Step: 6
Training loss: 2.156075180264566
Validation loss: 2.497200097351545

Epoch: 5| Step: 7
Training loss: 2.178537591854576
Validation loss: 2.5023485477245497

Epoch: 5| Step: 8
Training loss: 2.9413430256526802
Validation loss: 2.4958803168211987

Epoch: 5| Step: 9
Training loss: 1.9390728011921998
Validation loss: 2.4955774090594542

Epoch: 5| Step: 10
Training loss: 2.8322444020001405
Validation loss: 2.496386364106341

Epoch: 5| Step: 11
Training loss: 3.30346960256941
Validation loss: 2.497345142559427

Epoch: 190| Step: 0
Training loss: 2.7555165878569103
Validation loss: 2.4947359693411544

Epoch: 5| Step: 1
Training loss: 2.192637486948064
Validation loss: 2.492808385218109

Epoch: 5| Step: 2
Training loss: 2.5163625263914766
Validation loss: 2.4832919037059784

Epoch: 5| Step: 3
Training loss: 2.425125205356976
Validation loss: 2.492863323294054

Epoch: 5| Step: 4
Training loss: 2.5799787850210025
Validation loss: 2.489173986520808

Epoch: 5| Step: 5
Training loss: 2.2297732042015603
Validation loss: 2.492693782869672

Epoch: 5| Step: 6
Training loss: 2.5107953642025227
Validation loss: 2.499861451124526

Epoch: 5| Step: 7
Training loss: 2.4444440085478116
Validation loss: 2.4953446515360245

Epoch: 5| Step: 8
Training loss: 2.2923525968563845
Validation loss: 2.4926239635973655

Epoch: 5| Step: 9
Training loss: 2.5742111553259552
Validation loss: 2.4866999457764205

Epoch: 5| Step: 10
Training loss: 2.210917873767241
Validation loss: 2.498244376449137

Epoch: 5| Step: 11
Training loss: 2.2911271818534504
Validation loss: 2.4900945566855377

Epoch: 191| Step: 0
Training loss: 2.516674036263629
Validation loss: 2.4981504393487914

Epoch: 5| Step: 1
Training loss: 2.787394989499
Validation loss: 2.5039330737442187

Epoch: 5| Step: 2
Training loss: 2.182116614507924
Validation loss: 2.500163782238454

Epoch: 5| Step: 3
Training loss: 2.507634236782673
Validation loss: 2.4937851188691704

Epoch: 5| Step: 4
Training loss: 2.509250121851393
Validation loss: 2.4984892134635586

Epoch: 5| Step: 5
Training loss: 2.5857936669308037
Validation loss: 2.4941069925062482

Epoch: 5| Step: 6
Training loss: 2.3649336657586657
Validation loss: 2.488098205668717

Epoch: 5| Step: 7
Training loss: 2.0087922670656866
Validation loss: 2.4814819709545124

Epoch: 5| Step: 8
Training loss: 2.467939702581859
Validation loss: 2.481635508628842

Epoch: 5| Step: 9
Training loss: 2.6424725631978503
Validation loss: 2.483005630122928

Epoch: 5| Step: 10
Training loss: 2.4108352570229945
Validation loss: 2.480103943999252

Epoch: 5| Step: 11
Training loss: 1.330132974846472
Validation loss: 2.4813388950268744

Epoch: 192| Step: 0
Training loss: 2.525076791332102
Validation loss: 2.491050851648692

Epoch: 5| Step: 1
Training loss: 2.1639241198423633
Validation loss: 2.495364891144003

Epoch: 5| Step: 2
Training loss: 3.0674432835391583
Validation loss: 2.516998502478156

Epoch: 5| Step: 3
Training loss: 2.477347649625646
Validation loss: 2.5071340457220344

Epoch: 5| Step: 4
Training loss: 2.415290199361424
Validation loss: 2.503974366117016

Epoch: 5| Step: 5
Training loss: 3.014715027761065
Validation loss: 2.5151686797508614

Epoch: 5| Step: 6
Training loss: 2.0834290927495904
Validation loss: 2.488061321286598

Epoch: 5| Step: 7
Training loss: 1.8806888110820004
Validation loss: 2.487791595109205

Epoch: 5| Step: 8
Training loss: 2.3512605492265464
Validation loss: 2.4955043504789525

Epoch: 5| Step: 9
Training loss: 2.0425950359520595
Validation loss: 2.4915258711221213

Epoch: 5| Step: 10
Training loss: 2.670491713776167
Validation loss: 2.4954116876420547

Epoch: 5| Step: 11
Training loss: 1.80750375285623
Validation loss: 2.490313863046632

Epoch: 193| Step: 0
Training loss: 2.34362792650842
Validation loss: 2.4931910695536885

Epoch: 5| Step: 1
Training loss: 2.91230127532536
Validation loss: 2.489753495204308

Epoch: 5| Step: 2
Training loss: 2.4030499668585743
Validation loss: 2.49563543881014

Epoch: 5| Step: 3
Training loss: 2.450377267867708
Validation loss: 2.4840892291505563

Epoch: 5| Step: 4
Training loss: 2.257406442420806
Validation loss: 2.492790484054421

Epoch: 5| Step: 5
Training loss: 2.3274695990817276
Validation loss: 2.4925035856215416

Epoch: 5| Step: 6
Training loss: 2.382841616593366
Validation loss: 2.494518827890684

Epoch: 5| Step: 7
Training loss: 1.6735903772500529
Validation loss: 2.493686058066007

Epoch: 5| Step: 8
Training loss: 2.3833413459625357
Validation loss: 2.5065142478748452

Epoch: 5| Step: 9
Training loss: 3.225719720535884
Validation loss: 2.5063287974691697

Epoch: 5| Step: 10
Training loss: 2.0691292314321954
Validation loss: 2.4991089544239564

Epoch: 5| Step: 11
Training loss: 2.967565681739741
Validation loss: 2.5008307745527554

Epoch: 194| Step: 0
Training loss: 1.8137348178094026
Validation loss: 2.488077879000114

Epoch: 5| Step: 1
Training loss: 2.4427982359869027
Validation loss: 2.495305346257946

Epoch: 5| Step: 2
Training loss: 2.7301370967773226
Validation loss: 2.474969431739741

Epoch: 5| Step: 3
Training loss: 1.9589078209353372
Validation loss: 2.475120393316615

Epoch: 5| Step: 4
Training loss: 1.8285005623845525
Validation loss: 2.474442650754317

Epoch: 5| Step: 5
Training loss: 2.51385596963909
Validation loss: 2.484295533866652

Epoch: 5| Step: 6
Training loss: 2.46793999240081
Validation loss: 2.475251377229006

Epoch: 5| Step: 7
Training loss: 2.6906513988161254
Validation loss: 2.4714459012648806

Epoch: 5| Step: 8
Training loss: 2.912429965900367
Validation loss: 2.480733369744554

Epoch: 5| Step: 9
Training loss: 2.3899900303716497
Validation loss: 2.48137976869996

Epoch: 5| Step: 10
Training loss: 2.5323493359891844
Validation loss: 2.4822623829162156

Epoch: 5| Step: 11
Training loss: 3.2967684037029064
Validation loss: 2.4945607898148676

Epoch: 195| Step: 0
Training loss: 2.417570756194336
Validation loss: 2.493804446958931

Epoch: 5| Step: 1
Training loss: 2.906639975358162
Validation loss: 2.5045132905436467

Epoch: 5| Step: 2
Training loss: 2.380868988393225
Validation loss: 2.497428236835013

Epoch: 5| Step: 3
Training loss: 2.3846713460645796
Validation loss: 2.494867854590917

Epoch: 5| Step: 4
Training loss: 2.5632498969730353
Validation loss: 2.496094116147233

Epoch: 5| Step: 5
Training loss: 2.12948583710245
Validation loss: 2.509847360113727

Epoch: 5| Step: 6
Training loss: 2.769356489384386
Validation loss: 2.4950073934686317

Epoch: 5| Step: 7
Training loss: 2.0598100402430286
Validation loss: 2.5140281806090647

Epoch: 5| Step: 8
Training loss: 2.4753678867234226
Validation loss: 2.494797980686127

Epoch: 5| Step: 9
Training loss: 2.367492152586744
Validation loss: 2.4992747407178144

Epoch: 5| Step: 10
Training loss: 2.076346188222756
Validation loss: 2.503186541517927

Epoch: 5| Step: 11
Training loss: 2.843907278553362
Validation loss: 2.4908543252608104

Epoch: 196| Step: 0
Training loss: 2.4224756295914216
Validation loss: 2.4896777719012597

Epoch: 5| Step: 1
Training loss: 2.4573574607700936
Validation loss: 2.4938034749810774

Epoch: 5| Step: 2
Training loss: 2.4006913619836534
Validation loss: 2.4888729427977285

Epoch: 5| Step: 3
Training loss: 2.6160394228609953
Validation loss: 2.502951284675825

Epoch: 5| Step: 4
Training loss: 2.048910628440436
Validation loss: 2.4943995967395574

Epoch: 5| Step: 5
Training loss: 2.2583034733936658
Validation loss: 2.4950533406449193

Epoch: 5| Step: 6
Training loss: 2.6786661676273797
Validation loss: 2.499827565763238

Epoch: 5| Step: 7
Training loss: 2.548204695068422
Validation loss: 2.4999208000671396

Epoch: 5| Step: 8
Training loss: 2.097584415960435
Validation loss: 2.5034065977963924

Epoch: 5| Step: 9
Training loss: 2.4440729576621663
Validation loss: 2.498981717471874

Epoch: 5| Step: 10
Training loss: 2.705510580701694
Validation loss: 2.4998928802111227

Epoch: 5| Step: 11
Training loss: 1.877070872794344
Validation loss: 2.4962428152419984

Epoch: 197| Step: 0
Training loss: 1.9703201209094103
Validation loss: 2.5193915118912376

Epoch: 5| Step: 1
Training loss: 1.938494211880453
Validation loss: 2.5060440594036493

Epoch: 5| Step: 2
Training loss: 2.0717883337890513
Validation loss: 2.5168888084526047

Epoch: 5| Step: 3
Training loss: 2.103136572161235
Validation loss: 2.5259261304775737

Epoch: 5| Step: 4
Training loss: 2.6626909142760566
Validation loss: 2.527794209684218

Epoch: 5| Step: 5
Training loss: 2.280897452926234
Validation loss: 2.5125105911398573

Epoch: 5| Step: 6
Training loss: 3.0759322203273354
Validation loss: 2.5013304508049603

Epoch: 5| Step: 7
Training loss: 2.607864673748562
Validation loss: 2.5019906939768757

Epoch: 5| Step: 8
Training loss: 2.744831864257484
Validation loss: 2.501431170734638

Epoch: 5| Step: 9
Training loss: 2.558005042452163
Validation loss: 2.498941348358563

Epoch: 5| Step: 10
Training loss: 2.057739312123904
Validation loss: 2.4924570812763247

Epoch: 5| Step: 11
Training loss: 3.8728069129127247
Validation loss: 2.486321088926274

Epoch: 198| Step: 0
Training loss: 2.3569547858904576
Validation loss: 2.4825593483608914

Epoch: 5| Step: 1
Training loss: 2.426372855219071
Validation loss: 2.487073768028117

Epoch: 5| Step: 2
Training loss: 2.8765879682235034
Validation loss: 2.485282372371566

Epoch: 5| Step: 3
Training loss: 2.189512253710668
Validation loss: 2.493075456749397

Epoch: 5| Step: 4
Training loss: 2.5087383141884585
Validation loss: 2.4899625821857687

Epoch: 5| Step: 5
Training loss: 2.221959975451251
Validation loss: 2.499739802250874

Epoch: 5| Step: 6
Training loss: 2.463318463161462
Validation loss: 2.4949802269021495

Epoch: 5| Step: 7
Training loss: 2.6979132889145925
Validation loss: 2.507501398677569

Epoch: 5| Step: 8
Training loss: 2.3427408716213027
Validation loss: 2.5094382818468373

Epoch: 5| Step: 9
Training loss: 2.487098209001949
Validation loss: 2.5068491336131906

Epoch: 5| Step: 10
Training loss: 2.160178324084774
Validation loss: 2.506869529991424

Epoch: 5| Step: 11
Training loss: 2.1805336243106335
Validation loss: 2.511813591589843

Epoch: 199| Step: 0
Training loss: 2.2066317306396024
Validation loss: 2.50714313530432

Epoch: 5| Step: 1
Training loss: 2.3053079061008646
Validation loss: 2.5032195698450415

Epoch: 5| Step: 2
Training loss: 3.106083800630319
Validation loss: 2.4955671607649785

Epoch: 5| Step: 3
Training loss: 2.6529319234626705
Validation loss: 2.5067411215822037

Epoch: 5| Step: 4
Training loss: 2.4042308311781135
Validation loss: 2.4994534053907063

Epoch: 5| Step: 5
Training loss: 2.684483987107871
Validation loss: 2.498061720162971

Epoch: 5| Step: 6
Training loss: 1.9837444835602966
Validation loss: 2.4897966386614905

Epoch: 5| Step: 7
Training loss: 1.9044523048547777
Validation loss: 2.500207749317873

Epoch: 5| Step: 8
Training loss: 2.763338080963118
Validation loss: 2.496941424024584

Epoch: 5| Step: 9
Training loss: 2.3005201000453988
Validation loss: 2.498733678617824

Epoch: 5| Step: 10
Training loss: 2.2386644711069983
Validation loss: 2.500800640329355

Epoch: 5| Step: 11
Training loss: 1.6227258027276243
Validation loss: 2.5041644657038593

Epoch: 200| Step: 0
Training loss: 2.8072961773007497
Validation loss: 2.489688279854172

Epoch: 5| Step: 1
Training loss: 2.4681478804268924
Validation loss: 2.494782256000479

Epoch: 5| Step: 2
Training loss: 1.990677863696155
Validation loss: 2.487888958008481

Epoch: 5| Step: 3
Training loss: 2.37819105901214
Validation loss: 2.485375225001961

Epoch: 5| Step: 4
Training loss: 2.8018586495284263
Validation loss: 2.4844106795589926

Epoch: 5| Step: 5
Training loss: 2.552003062536381
Validation loss: 2.481735286611518

Epoch: 5| Step: 6
Training loss: 2.295105960037107
Validation loss: 2.491926099806461

Epoch: 5| Step: 7
Training loss: 2.546674474767462
Validation loss: 2.497824823304653

Epoch: 5| Step: 8
Training loss: 2.558660654838514
Validation loss: 2.4999867200498724

Epoch: 5| Step: 9
Training loss: 2.021820128932973
Validation loss: 2.4812523913111724

Epoch: 5| Step: 10
Training loss: 1.9966253181256177
Validation loss: 2.4902746239694387

Epoch: 5| Step: 11
Training loss: 2.494561192027865
Validation loss: 2.4836485898376264

Epoch: 201| Step: 0
Training loss: 2.19398279068908
Validation loss: 2.4901759201868336

Epoch: 5| Step: 1
Training loss: 2.425212111487481
Validation loss: 2.4874519311551193

Epoch: 5| Step: 2
Training loss: 3.062725915166603
Validation loss: 2.485861399580904

Epoch: 5| Step: 3
Training loss: 1.9980108979417672
Validation loss: 2.4905419213364293

Epoch: 5| Step: 4
Training loss: 1.9547762794977237
Validation loss: 2.4921817321072823

Epoch: 5| Step: 5
Training loss: 2.483714849706157
Validation loss: 2.4974591814319718

Epoch: 5| Step: 6
Training loss: 2.45620194405096
Validation loss: 2.493767025538098

Epoch: 5| Step: 7
Training loss: 2.3464590056971972
Validation loss: 2.4984684107054993

Epoch: 5| Step: 8
Training loss: 2.525330013955072
Validation loss: 2.5123206881215485

Epoch: 5| Step: 9
Training loss: 2.1563051741907833
Validation loss: 2.5001395981278227

Epoch: 5| Step: 10
Training loss: 2.5941010203165136
Validation loss: 2.5032175736725497

Epoch: 5| Step: 11
Training loss: 3.135471347741798
Validation loss: 2.5239829191447574

Epoch: 202| Step: 0
Training loss: 2.3913702706911386
Validation loss: 2.4914336185381547

Epoch: 5| Step: 1
Training loss: 2.2616805895285683
Validation loss: 2.4884033253027016

Epoch: 5| Step: 2
Training loss: 2.125509761926977
Validation loss: 2.482880126611488

Epoch: 5| Step: 3
Training loss: 2.320003193491349
Validation loss: 2.482438038138837

Epoch: 5| Step: 4
Training loss: 2.5071129699683157
Validation loss: 2.4871140062350845

Epoch: 5| Step: 5
Training loss: 2.612073770459827
Validation loss: 2.486425984692522

Epoch: 5| Step: 6
Training loss: 2.4368668736539774
Validation loss: 2.4944311145564604

Epoch: 5| Step: 7
Training loss: 2.3186370246283783
Validation loss: 2.4851957720760116

Epoch: 5| Step: 8
Training loss: 2.618802156133829
Validation loss: 2.4824524884320933

Epoch: 5| Step: 9
Training loss: 2.645738785223328
Validation loss: 2.4914618883751647

Epoch: 5| Step: 10
Training loss: 2.4557702447739667
Validation loss: 2.485343080717252

Epoch: 5| Step: 11
Training loss: 2.473523317873705
Validation loss: 2.4914155001551834

Epoch: 203| Step: 0
Training loss: 2.5749191234442788
Validation loss: 2.497203900410624

Epoch: 5| Step: 1
Training loss: 2.225237214376886
Validation loss: 2.4990926367503334

Epoch: 5| Step: 2
Training loss: 2.4669729669803866
Validation loss: 2.519813896313485

Epoch: 5| Step: 3
Training loss: 1.667033806735506
Validation loss: 2.5258188850768226

Epoch: 5| Step: 4
Training loss: 2.245367579624092
Validation loss: 2.5246823864904835

Epoch: 5| Step: 5
Training loss: 2.83358120301537
Validation loss: 2.5326531449708654

Epoch: 5| Step: 6
Training loss: 3.049222540651468
Validation loss: 2.5153487075497916

Epoch: 5| Step: 7
Training loss: 2.9643277610121035
Validation loss: 2.490701704866332

Epoch: 5| Step: 8
Training loss: 2.142374368053316
Validation loss: 2.4950308170785265

Epoch: 5| Step: 9
Training loss: 2.266243475322305
Validation loss: 2.4950629321107565

Epoch: 5| Step: 10
Training loss: 2.0888396801236406
Validation loss: 2.4929504821037893

Epoch: 5| Step: 11
Training loss: 2.2589657488046297
Validation loss: 2.492679782506787

Epoch: 204| Step: 0
Training loss: 2.2534988537589324
Validation loss: 2.488702509826284

Epoch: 5| Step: 1
Training loss: 2.927979645434228
Validation loss: 2.5005307230283385

Epoch: 5| Step: 2
Training loss: 2.248235116297465
Validation loss: 2.4983816670629926

Epoch: 5| Step: 3
Training loss: 2.3356915092441
Validation loss: 2.510698410833598

Epoch: 5| Step: 4
Training loss: 2.700946878480722
Validation loss: 2.5083369442500825

Epoch: 5| Step: 5
Training loss: 2.428091524696099
Validation loss: 2.514697719449076

Epoch: 5| Step: 6
Training loss: 3.016924642277327
Validation loss: 2.5307948327257908

Epoch: 5| Step: 7
Training loss: 2.484184017877938
Validation loss: 2.509888788706676

Epoch: 5| Step: 8
Training loss: 1.6454393502773914
Validation loss: 2.5148327687673446

Epoch: 5| Step: 9
Training loss: 2.1573386277619897
Validation loss: 2.508206991063879

Epoch: 5| Step: 10
Training loss: 2.1197253567558536
Validation loss: 2.5163871329370058

Epoch: 5| Step: 11
Training loss: 2.792892775135802
Validation loss: 2.5136688082226013

Epoch: 205| Step: 0
Training loss: 2.584826642832849
Validation loss: 2.5088979049796927

Epoch: 5| Step: 1
Training loss: 2.5755234973200696
Validation loss: 2.50398207860618

Epoch: 5| Step: 2
Training loss: 2.9367106574318202
Validation loss: 2.49623905847425

Epoch: 5| Step: 3
Training loss: 2.0149326761892556
Validation loss: 2.491274687438468

Epoch: 5| Step: 4
Training loss: 2.124577536382084
Validation loss: 2.492103814421083

Epoch: 5| Step: 5
Training loss: 2.4514646317328763
Validation loss: 2.489981489119096

Epoch: 5| Step: 6
Training loss: 2.06806057508873
Validation loss: 2.4918152821170874

Epoch: 5| Step: 7
Training loss: 1.8622534134221937
Validation loss: 2.488932753328478

Epoch: 5| Step: 8
Training loss: 2.864254982365206
Validation loss: 2.498508727819978

Epoch: 5| Step: 9
Training loss: 2.593738693764185
Validation loss: 2.4941342123970314

Epoch: 5| Step: 10
Training loss: 2.269456977088509
Validation loss: 2.4921024929843605

Epoch: 5| Step: 11
Training loss: 2.52374397991307
Validation loss: 2.494761517899358

Epoch: 206| Step: 0
Training loss: 2.209544143784808
Validation loss: 2.4986660975023365

Epoch: 5| Step: 1
Training loss: 2.3493227002938455
Validation loss: 2.500168862203046

Epoch: 5| Step: 2
Training loss: 2.086652197538836
Validation loss: 2.4934977811009613

Epoch: 5| Step: 3
Training loss: 2.270319737674232
Validation loss: 2.4922837863606104

Epoch: 5| Step: 4
Training loss: 2.704204365879437
Validation loss: 2.4967772274902833

Epoch: 5| Step: 5
Training loss: 2.2095900024950277
Validation loss: 2.5020132620912547

Epoch: 5| Step: 6
Training loss: 2.116201811780912
Validation loss: 2.5005669109980593

Epoch: 5| Step: 7
Training loss: 2.566203906299828
Validation loss: 2.49958911936627

Epoch: 5| Step: 8
Training loss: 2.2149598967493214
Validation loss: 2.5019907058883195

Epoch: 5| Step: 9
Training loss: 3.0069190345573493
Validation loss: 2.5037957344125186

Epoch: 5| Step: 10
Training loss: 2.4521607854814054
Validation loss: 2.5063001245574097

Epoch: 5| Step: 11
Training loss: 2.985191992331331
Validation loss: 2.503225014665296

Epoch: 207| Step: 0
Training loss: 2.2861993479344913
Validation loss: 2.502520129446446

Epoch: 5| Step: 1
Training loss: 2.4463024146654075
Validation loss: 2.515771387710038

Epoch: 5| Step: 2
Training loss: 2.415226825305603
Validation loss: 2.5112256900515164

Epoch: 5| Step: 3
Training loss: 2.2136767776243795
Validation loss: 2.5179377521686437

Epoch: 5| Step: 4
Training loss: 2.279054290493075
Validation loss: 2.525364391075584

Epoch: 5| Step: 5
Training loss: 2.1954669287181745
Validation loss: 2.5227130562553284

Epoch: 5| Step: 6
Training loss: 2.7430225633227936
Validation loss: 2.5222610707542468

Epoch: 5| Step: 7
Training loss: 2.545091718508655
Validation loss: 2.523598440449081

Epoch: 5| Step: 8
Training loss: 2.6486898206397615
Validation loss: 2.5027654214140718

Epoch: 5| Step: 9
Training loss: 2.484047346281245
Validation loss: 2.510000373756715

Epoch: 5| Step: 10
Training loss: 2.3075334983369724
Validation loss: 2.5039894042586894

Epoch: 5| Step: 11
Training loss: 1.7460033555495624
Validation loss: 2.505034027591842

Epoch: 208| Step: 0
Training loss: 2.344415798986519
Validation loss: 2.4956998081397197

Epoch: 5| Step: 1
Training loss: 2.6074814007425835
Validation loss: 2.5043569467666726

Epoch: 5| Step: 2
Training loss: 1.7362864503268178
Validation loss: 2.5056741060751517

Epoch: 5| Step: 3
Training loss: 2.315197170750933
Validation loss: 2.5089727512426716

Epoch: 5| Step: 4
Training loss: 1.8884059399245334
Validation loss: 2.4998477213894157

Epoch: 5| Step: 5
Training loss: 2.715684587639186
Validation loss: 2.5003962997406295

Epoch: 5| Step: 6
Training loss: 2.8287073031181342
Validation loss: 2.5141637479453065

Epoch: 5| Step: 7
Training loss: 2.891414060378535
Validation loss: 2.5145502183614714

Epoch: 5| Step: 8
Training loss: 2.932818151518346
Validation loss: 2.5120871645966285

Epoch: 5| Step: 9
Training loss: 2.0809955704883394
Validation loss: 2.5159373750893117

Epoch: 5| Step: 10
Training loss: 2.1118488640027366
Validation loss: 2.4988053447668364

Epoch: 5| Step: 11
Training loss: 0.8817022989087995
Validation loss: 2.5082677782454548

Epoch: 209| Step: 0
Training loss: 2.2898936146174713
Validation loss: 2.497912174875157

Epoch: 5| Step: 1
Training loss: 2.8285002907288734
Validation loss: 2.4973935964903826

Epoch: 5| Step: 2
Training loss: 2.5506065507449165
Validation loss: 2.501781389237185

Epoch: 5| Step: 3
Training loss: 2.220498698814198
Validation loss: 2.495782569110009

Epoch: 5| Step: 4
Training loss: 2.374849816643429
Validation loss: 2.5030238659351225

Epoch: 5| Step: 5
Training loss: 2.3284654816372146
Validation loss: 2.5117693550387004

Epoch: 5| Step: 6
Training loss: 2.8272685234642947
Validation loss: 2.501500871269689

Epoch: 5| Step: 7
Training loss: 2.142951981398575
Validation loss: 2.503766330215644

Epoch: 5| Step: 8
Training loss: 2.2195682360082727
Validation loss: 2.506949849767191

Epoch: 5| Step: 9
Training loss: 2.434338108316971
Validation loss: 2.5096667160157127

Epoch: 5| Step: 10
Training loss: 2.1119590472961485
Validation loss: 2.509982278578917

Epoch: 5| Step: 11
Training loss: 1.8549268071625953
Validation loss: 2.499888675913164

Epoch: 210| Step: 0
Training loss: 2.2264915053443075
Validation loss: 2.507720367228675

Epoch: 5| Step: 1
Training loss: 2.283530780395177
Validation loss: 2.507653220437495

Epoch: 5| Step: 2
Training loss: 2.4393450283170877
Validation loss: 2.506581968136695

Epoch: 5| Step: 3
Training loss: 2.215801590310394
Validation loss: 2.5057701814495874

Epoch: 5| Step: 4
Training loss: 2.4846501228055367
Validation loss: 2.522258231042055

Epoch: 5| Step: 5
Training loss: 2.3577956414552204
Validation loss: 2.518459346367391

Epoch: 5| Step: 6
Training loss: 2.3025502785692553
Validation loss: 2.514124207404168

Epoch: 5| Step: 7
Training loss: 1.9533185328919938
Validation loss: 2.510957395850221

Epoch: 5| Step: 8
Training loss: 2.4139505008530824
Validation loss: 2.5129062145494174

Epoch: 5| Step: 9
Training loss: 2.5149857555918835
Validation loss: 2.5037489160709

Epoch: 5| Step: 10
Training loss: 2.883179349223707
Validation loss: 2.511534457171797

Epoch: 5| Step: 11
Training loss: 3.084364246168009
Validation loss: 2.5081527455380592

Epoch: 211| Step: 0
Training loss: 2.253701767661874
Validation loss: 2.5063768636950132

Epoch: 5| Step: 1
Training loss: 2.5096495367728773
Validation loss: 2.5062309736891573

Epoch: 5| Step: 2
Training loss: 2.7126593055178345
Validation loss: 2.501998031415706

Epoch: 5| Step: 3
Training loss: 2.147639233801723
Validation loss: 2.5166252509134543

Epoch: 5| Step: 4
Training loss: 2.6712915330013436
Validation loss: 2.508318876676838

Epoch: 5| Step: 5
Training loss: 1.8737738096672505
Validation loss: 2.4946557939093013

Epoch: 5| Step: 6
Training loss: 2.3609136149765395
Validation loss: 2.500092538471983

Epoch: 5| Step: 7
Training loss: 2.7248758165253366
Validation loss: 2.512923474311832

Epoch: 5| Step: 8
Training loss: 2.329739516436767
Validation loss: 2.505056837951038

Epoch: 5| Step: 9
Training loss: 2.232596483185481
Validation loss: 2.5194166842492924

Epoch: 5| Step: 10
Training loss: 2.462471039112793
Validation loss: 2.5019132405977516

Epoch: 5| Step: 11
Training loss: 1.4183816440003407
Validation loss: 2.4945730035212343

Epoch: 212| Step: 0
Training loss: 2.048938788233672
Validation loss: 2.5165688380959725

Epoch: 5| Step: 1
Training loss: 1.9272044650661482
Validation loss: 2.511972789267245

Epoch: 5| Step: 2
Training loss: 2.271575269905918
Validation loss: 2.507284475257322

Epoch: 5| Step: 3
Training loss: 2.3153649187944083
Validation loss: 2.506830821510705

Epoch: 5| Step: 4
Training loss: 2.173567297849047
Validation loss: 2.509701727265235

Epoch: 5| Step: 5
Training loss: 2.5197068737240422
Validation loss: 2.506918774652721

Epoch: 5| Step: 6
Training loss: 2.246296271440371
Validation loss: 2.522534885127464

Epoch: 5| Step: 7
Training loss: 2.808185404457495
Validation loss: 2.5208028930738764

Epoch: 5| Step: 8
Training loss: 2.6208588769230943
Validation loss: 2.512346295104118

Epoch: 5| Step: 9
Training loss: 2.6603532401708976
Validation loss: 2.5199271785530666

Epoch: 5| Step: 10
Training loss: 2.704680684222664
Validation loss: 2.530666068112775

Epoch: 5| Step: 11
Training loss: 1.3560251638502574
Validation loss: 2.522696544726678

Epoch: 213| Step: 0
Training loss: 1.9425861910006859
Validation loss: 2.5174058766970453

Epoch: 5| Step: 1
Training loss: 2.548520358274685
Validation loss: 2.514203746203175

Epoch: 5| Step: 2
Training loss: 2.296787701459356
Validation loss: 2.5149431351008786

Epoch: 5| Step: 3
Training loss: 2.191863367611638
Validation loss: 2.5133671391825008

Epoch: 5| Step: 4
Training loss: 2.424767717071161
Validation loss: 2.5092218465532765

Epoch: 5| Step: 5
Training loss: 2.260140139868159
Validation loss: 2.503413762435718

Epoch: 5| Step: 6
Training loss: 2.0794269814169772
Validation loss: 2.520236596235468

Epoch: 5| Step: 7
Training loss: 2.240182864354397
Validation loss: 2.5220113371559703

Epoch: 5| Step: 8
Training loss: 2.9562053459295154
Validation loss: 2.510854363702093

Epoch: 5| Step: 9
Training loss: 2.639357493995389
Validation loss: 2.5151153861752955

Epoch: 5| Step: 10
Training loss: 2.6394404175167225
Validation loss: 2.5163620408114684

Epoch: 5| Step: 11
Training loss: 1.9877438521589381
Validation loss: 2.5290932670345465

Epoch: 214| Step: 0
Training loss: 2.524184361527304
Validation loss: 2.512611645737404

Epoch: 5| Step: 1
Training loss: 2.231957040954421
Validation loss: 2.5158321698103854

Epoch: 5| Step: 2
Training loss: 2.5411265273526102
Validation loss: 2.5160160747958638

Epoch: 5| Step: 3
Training loss: 2.008968391629314
Validation loss: 2.504477873573392

Epoch: 5| Step: 4
Training loss: 2.780355845530766
Validation loss: 2.5045458829160636

Epoch: 5| Step: 5
Training loss: 2.345153185105162
Validation loss: 2.5060341571637528

Epoch: 5| Step: 6
Training loss: 2.437607982884585
Validation loss: 2.5028091026546964

Epoch: 5| Step: 7
Training loss: 2.1865505882986582
Validation loss: 2.513783102432484

Epoch: 5| Step: 8
Training loss: 2.198372876397546
Validation loss: 2.5225659017646653

Epoch: 5| Step: 9
Training loss: 2.501460125822093
Validation loss: 2.523165763971065

Epoch: 5| Step: 10
Training loss: 2.5667230187046934
Validation loss: 2.5200529243510146

Epoch: 5| Step: 11
Training loss: 2.8747445697927207
Validation loss: 2.5282470645365067

Epoch: 215| Step: 0
Training loss: 2.4381889934497574
Validation loss: 2.53434854580658

Epoch: 5| Step: 1
Training loss: 1.9439156047766741
Validation loss: 2.5494815929012944

Epoch: 5| Step: 2
Training loss: 2.37129092457174
Validation loss: 2.563152985995583

Epoch: 5| Step: 3
Training loss: 2.056272990089528
Validation loss: 2.5813781828068616

Epoch: 5| Step: 4
Training loss: 2.8863670537514685
Validation loss: 2.607477750905769

Epoch: 5| Step: 5
Training loss: 2.266735357290894
Validation loss: 2.5924584455418405

Epoch: 5| Step: 6
Training loss: 2.3650791359821364
Validation loss: 2.5678368949559243

Epoch: 5| Step: 7
Training loss: 2.4140343525551087
Validation loss: 2.565236080798988

Epoch: 5| Step: 8
Training loss: 2.1310010210855546
Validation loss: 2.5498310478812427

Epoch: 5| Step: 9
Training loss: 2.5160202758348085
Validation loss: 2.5251066279795027

Epoch: 5| Step: 10
Training loss: 2.6266556014717035
Validation loss: 2.510714411720997

Epoch: 5| Step: 11
Training loss: 3.3436699973544783
Validation loss: 2.5031114170691753

Epoch: 216| Step: 0
Training loss: 2.012647810536914
Validation loss: 2.496323705755721

Epoch: 5| Step: 1
Training loss: 2.6638486893844595
Validation loss: 2.500840725201931

Epoch: 5| Step: 2
Training loss: 2.4320303363351057
Validation loss: 2.4920537667581986

Epoch: 5| Step: 3
Training loss: 2.551556736600292
Validation loss: 2.4980131062006516

Epoch: 5| Step: 4
Training loss: 2.2255437293743348
Validation loss: 2.5054466797717305

Epoch: 5| Step: 5
Training loss: 2.4126855571323866
Validation loss: 2.508162183931946

Epoch: 5| Step: 6
Training loss: 2.446172495975277
Validation loss: 2.5017791576389694

Epoch: 5| Step: 7
Training loss: 2.4643693518809706
Validation loss: 2.5135776133574703

Epoch: 5| Step: 8
Training loss: 2.8767452747600877
Validation loss: 2.504266154608029

Epoch: 5| Step: 9
Training loss: 2.4782900395702585
Validation loss: 2.502487042266804

Epoch: 5| Step: 10
Training loss: 3.279684946932442
Validation loss: 2.512497448484982

Epoch: 5| Step: 11
Training loss: 2.199758460050161
Validation loss: 2.502518458226867

Epoch: 217| Step: 0
Training loss: 2.8411536468668817
Validation loss: 2.5022147937917163

Epoch: 5| Step: 1
Training loss: 2.402407066937449
Validation loss: 2.4946575420749832

Epoch: 5| Step: 2
Training loss: 2.131804622851777
Validation loss: 2.4947818498411674

Epoch: 5| Step: 3
Training loss: 2.7243237417483104
Validation loss: 2.482512099504517

Epoch: 5| Step: 4
Training loss: 2.327983775111811
Validation loss: 2.4935762926501663

Epoch: 5| Step: 5
Training loss: 2.240138696225396
Validation loss: 2.497559671659663

Epoch: 5| Step: 6
Training loss: 2.167876920387655
Validation loss: 2.4983898262467936

Epoch: 5| Step: 7
Training loss: 2.803409210732501
Validation loss: 2.5038380606139734

Epoch: 5| Step: 8
Training loss: 2.4755154390849494
Validation loss: 2.4971297158445953

Epoch: 5| Step: 9
Training loss: 2.4867282494529226
Validation loss: 2.5044648712270203

Epoch: 5| Step: 10
Training loss: 2.4540371504989595
Validation loss: 2.5004352111289765

Epoch: 5| Step: 11
Training loss: 3.4334016817814184
Validation loss: 2.505869468218684

Epoch: 218| Step: 0
Training loss: 1.8316387089454682
Validation loss: 2.5032234629721004

Epoch: 5| Step: 1
Training loss: 1.7501548971016472
Validation loss: 2.5069586388587357

Epoch: 5| Step: 2
Training loss: 2.262807422638038
Validation loss: 2.5036518326723103

Epoch: 5| Step: 3
Training loss: 2.401752281260149
Validation loss: 2.5018051187064776

Epoch: 5| Step: 4
Training loss: 2.2206597504284287
Validation loss: 2.5004486118579905

Epoch: 5| Step: 5
Training loss: 2.236651134901322
Validation loss: 2.496402122460879

Epoch: 5| Step: 6
Training loss: 2.9378997855341
Validation loss: 2.4937126571166606

Epoch: 5| Step: 7
Training loss: 2.304371026503611
Validation loss: 2.4942277391754413

Epoch: 5| Step: 8
Training loss: 2.246560116325002
Validation loss: 2.5048666236557557

Epoch: 5| Step: 9
Training loss: 2.8691590725985394
Validation loss: 2.5052037718183477

Epoch: 5| Step: 10
Training loss: 2.9033871568259504
Validation loss: 2.5040469078036494

Epoch: 5| Step: 11
Training loss: 3.2051156162112546
Validation loss: 2.5075084902098896

Epoch: 219| Step: 0
Training loss: 2.092485302106677
Validation loss: 2.513117549530701

Epoch: 5| Step: 1
Training loss: 2.0960362037269262
Validation loss: 2.512675939950542

Epoch: 5| Step: 2
Training loss: 2.1164614850817562
Validation loss: 2.5106024943754743

Epoch: 5| Step: 3
Training loss: 2.5767196986706913
Validation loss: 2.5097707409441665

Epoch: 5| Step: 4
Training loss: 2.3126317579520057
Validation loss: 2.5085543983942555

Epoch: 5| Step: 5
Training loss: 2.0670871009579583
Validation loss: 2.5034297384559934

Epoch: 5| Step: 6
Training loss: 2.813038837949931
Validation loss: 2.506513110402959

Epoch: 5| Step: 7
Training loss: 2.163048020971294
Validation loss: 2.512916987090253

Epoch: 5| Step: 8
Training loss: 2.593482313935322
Validation loss: 2.502076740769704

Epoch: 5| Step: 9
Training loss: 2.8381503800813754
Validation loss: 2.511727609416076

Epoch: 5| Step: 10
Training loss: 2.4928997301608886
Validation loss: 2.5007735843654175

Epoch: 5| Step: 11
Training loss: 2.559732384700913
Validation loss: 2.5069544820740144

Epoch: 220| Step: 0
Training loss: 2.2434724853950425
Validation loss: 2.5163561269921435

Epoch: 5| Step: 1
Training loss: 2.349674011508334
Validation loss: 2.5154026004266745

Epoch: 5| Step: 2
Training loss: 2.35113653336097
Validation loss: 2.50816508317128

Epoch: 5| Step: 3
Training loss: 1.9687236602474434
Validation loss: 2.520265031758963

Epoch: 5| Step: 4
Training loss: 2.4391580468865994
Validation loss: 2.5231234076476565

Epoch: 5| Step: 5
Training loss: 2.141823871448671
Validation loss: 2.5292067424567457

Epoch: 5| Step: 6
Training loss: 2.3587270693328977
Validation loss: 2.5162089402635193

Epoch: 5| Step: 7
Training loss: 2.3868864659196056
Validation loss: 2.5199613613113265

Epoch: 5| Step: 8
Training loss: 3.3043531604937657
Validation loss: 2.520434810463602

Epoch: 5| Step: 9
Training loss: 2.7437185159671245
Validation loss: 2.5142853409922465

Epoch: 5| Step: 10
Training loss: 1.831103580076405
Validation loss: 2.5159800024284036

Epoch: 5| Step: 11
Training loss: 1.8769016794702362
Validation loss: 2.5140295636232577

Epoch: 221| Step: 0
Training loss: 2.140470847266565
Validation loss: 2.507129290914337

Epoch: 5| Step: 1
Training loss: 2.3487618329621536
Validation loss: 2.4999020994408743

Epoch: 5| Step: 2
Training loss: 2.3579014098415385
Validation loss: 2.499244235959074

Epoch: 5| Step: 3
Training loss: 2.4828194600722537
Validation loss: 2.5019229804711323

Epoch: 5| Step: 4
Training loss: 2.8126803870103436
Validation loss: 2.498593121282976

Epoch: 5| Step: 5
Training loss: 2.556926061492911
Validation loss: 2.5003754016039523

Epoch: 5| Step: 6
Training loss: 2.646311579056727
Validation loss: 2.5113195336391154

Epoch: 5| Step: 7
Training loss: 2.409578374648353
Validation loss: 2.512069910951805

Epoch: 5| Step: 8
Training loss: 1.8671101829450125
Validation loss: 2.5170760461754074

Epoch: 5| Step: 9
Training loss: 2.6912633583881904
Validation loss: 2.5207512555802607

Epoch: 5| Step: 10
Training loss: 1.9847222572518266
Validation loss: 2.5180903254791875

Epoch: 5| Step: 11
Training loss: 1.623191707681275
Validation loss: 2.531981076131153

Epoch: 222| Step: 0
Training loss: 2.5177620287151337
Validation loss: 2.519058900859031

Epoch: 5| Step: 1
Training loss: 1.937978193276528
Validation loss: 2.5277699185401765

Epoch: 5| Step: 2
Training loss: 2.689957493159035
Validation loss: 2.539009985747501

Epoch: 5| Step: 3
Training loss: 2.6843368190052885
Validation loss: 2.540435482399899

Epoch: 5| Step: 4
Training loss: 3.029967361123327
Validation loss: 2.5445630847008034

Epoch: 5| Step: 5
Training loss: 2.4856025014525254
Validation loss: 2.5479691111442992

Epoch: 5| Step: 6
Training loss: 2.6386416960825083
Validation loss: 2.541492039252434

Epoch: 5| Step: 7
Training loss: 1.6857843508025838
Validation loss: 2.5320903772349577

Epoch: 5| Step: 8
Training loss: 2.2485247119905374
Validation loss: 2.5356399983699114

Epoch: 5| Step: 9
Training loss: 1.928629720402335
Validation loss: 2.52864776097914

Epoch: 5| Step: 10
Training loss: 1.9884698624699888
Validation loss: 2.5352739484098694

Epoch: 5| Step: 11
Training loss: 2.444551099511933
Validation loss: 2.5176152674675305

Epoch: 223| Step: 0
Training loss: 2.6589948945098674
Validation loss: 2.5218311389510757

Epoch: 5| Step: 1
Training loss: 2.43154894797688
Validation loss: 2.512818526325733

Epoch: 5| Step: 2
Training loss: 2.8027161707270296
Validation loss: 2.5203162456373462

Epoch: 5| Step: 3
Training loss: 2.248098205457634
Validation loss: 2.5239579537003425

Epoch: 5| Step: 4
Training loss: 2.059902636440021
Validation loss: 2.5355590594346693

Epoch: 5| Step: 5
Training loss: 2.6593162341858747
Validation loss: 2.5281095960892017

Epoch: 5| Step: 6
Training loss: 2.1891784767942695
Validation loss: 2.5379877955802352

Epoch: 5| Step: 7
Training loss: 2.318268874602593
Validation loss: 2.535099908626851

Epoch: 5| Step: 8
Training loss: 1.7962321582776164
Validation loss: 2.528542180921038

Epoch: 5| Step: 9
Training loss: 2.799356904428076
Validation loss: 2.532032806323816

Epoch: 5| Step: 10
Training loss: 1.9901775318297796
Validation loss: 2.518637020899711

Epoch: 5| Step: 11
Training loss: 2.4851566260732385
Validation loss: 2.5201319646216076

Epoch: 224| Step: 0
Training loss: 2.571888727311387
Validation loss: 2.512416396640054

Epoch: 5| Step: 1
Training loss: 2.6473553002197887
Validation loss: 2.5058834345339713

Epoch: 5| Step: 2
Training loss: 2.0561937967985107
Validation loss: 2.5090567076177455

Epoch: 5| Step: 3
Training loss: 3.050821575137621
Validation loss: 2.497530261662422

Epoch: 5| Step: 4
Training loss: 2.1264685997562984
Validation loss: 2.498632164123637

Epoch: 5| Step: 5
Training loss: 2.5198034804783314
Validation loss: 2.493337917778404

Epoch: 5| Step: 6
Training loss: 2.0970209107891282
Validation loss: 2.4950364151414153

Epoch: 5| Step: 7
Training loss: 2.3605784195517665
Validation loss: 2.5005333132923373

Epoch: 5| Step: 8
Training loss: 1.8749031677673458
Validation loss: 2.5012237335330694

Epoch: 5| Step: 9
Training loss: 2.2841973273487852
Validation loss: 2.495779142019643

Epoch: 5| Step: 10
Training loss: 2.9648828315420745
Validation loss: 2.5084901648715068

Epoch: 5| Step: 11
Training loss: 1.1562803625295837
Validation loss: 2.5058027872072355

Epoch: 225| Step: 0
Training loss: 2.37803135210036
Validation loss: 2.528872590090928

Epoch: 5| Step: 1
Training loss: 2.21893352770339
Validation loss: 2.5245362046266666

Epoch: 5| Step: 2
Training loss: 2.1888149124184064
Validation loss: 2.556139250596989

Epoch: 5| Step: 3
Training loss: 2.0754150848699195
Validation loss: 2.547399396678736

Epoch: 5| Step: 4
Training loss: 2.3458735700265416
Validation loss: 2.556563144769709

Epoch: 5| Step: 5
Training loss: 2.8736844577425162
Validation loss: 2.566382154006132

Epoch: 5| Step: 6
Training loss: 2.507336532725969
Validation loss: 2.5523213541531025

Epoch: 5| Step: 7
Training loss: 2.1934708985588816
Validation loss: 2.514724191061635

Epoch: 5| Step: 8
Training loss: 1.8574653885133758
Validation loss: 2.505520007492659

Epoch: 5| Step: 9
Training loss: 2.639480884694512
Validation loss: 2.4949744734289636

Epoch: 5| Step: 10
Training loss: 2.994820255751222
Validation loss: 2.497702184323743

Epoch: 5| Step: 11
Training loss: 2.156375052101542
Validation loss: 2.5024127840715784

Epoch: 226| Step: 0
Training loss: 2.062154105110153
Validation loss: 2.496942486286639

Epoch: 5| Step: 1
Training loss: 2.6685415968273385
Validation loss: 2.503538552044989

Epoch: 5| Step: 2
Training loss: 2.5861027137555364
Validation loss: 2.485983401901146

Epoch: 5| Step: 3
Training loss: 2.6206662871267423
Validation loss: 2.4945245425911384

Epoch: 5| Step: 4
Training loss: 2.080281450963347
Validation loss: 2.4956271989702676

Epoch: 5| Step: 5
Training loss: 2.302600290473092
Validation loss: 2.4985520580525953

Epoch: 5| Step: 6
Training loss: 1.7953037192027843
Validation loss: 2.511079840432569

Epoch: 5| Step: 7
Training loss: 2.706973472958459
Validation loss: 2.5146289496299383

Epoch: 5| Step: 8
Training loss: 2.384836206789752
Validation loss: 2.517019351400108

Epoch: 5| Step: 9
Training loss: 2.645035891370509
Validation loss: 2.527450166217911

Epoch: 5| Step: 10
Training loss: 2.4909065805357984
Validation loss: 2.5391177909895344

Epoch: 5| Step: 11
Training loss: 1.4770960575447052
Validation loss: 2.5526353719085977

Epoch: 227| Step: 0
Training loss: 2.3603126734164444
Validation loss: 2.558435542915577

Epoch: 5| Step: 1
Training loss: 2.089186976967702
Validation loss: 2.5585262920620835

Epoch: 5| Step: 2
Training loss: 2.033338558732286
Validation loss: 2.5486688361934067

Epoch: 5| Step: 3
Training loss: 2.55811418305027
Validation loss: 2.535875689555718

Epoch: 5| Step: 4
Training loss: 2.6610956311909395
Validation loss: 2.534642395231498

Epoch: 5| Step: 5
Training loss: 2.307111390062475
Validation loss: 2.5264168621262426

Epoch: 5| Step: 6
Training loss: 1.8848604326664915
Validation loss: 2.527572059440525

Epoch: 5| Step: 7
Training loss: 2.4662836043731278
Validation loss: 2.50544740933246

Epoch: 5| Step: 8
Training loss: 2.7683919222987954
Validation loss: 2.5118941013001916

Epoch: 5| Step: 9
Training loss: 2.576526493077696
Validation loss: 2.5098891172195845

Epoch: 5| Step: 10
Training loss: 2.288280158076835
Validation loss: 2.512739599959189

Epoch: 5| Step: 11
Training loss: 2.0735407006597386
Validation loss: 2.504291558338139

Epoch: 228| Step: 0
Training loss: 2.8862030022827123
Validation loss: 2.514227358429319

Epoch: 5| Step: 1
Training loss: 2.151835913035857
Validation loss: 2.5067776439285465

Epoch: 5| Step: 2
Training loss: 1.824369305885684
Validation loss: 2.517293207122383

Epoch: 5| Step: 3
Training loss: 2.729730989385962
Validation loss: 2.509626134813247

Epoch: 5| Step: 4
Training loss: 1.986183903952611
Validation loss: 2.513655074862971

Epoch: 5| Step: 5
Training loss: 2.5527826609638025
Validation loss: 2.5234381613715753

Epoch: 5| Step: 6
Training loss: 2.778323144358179
Validation loss: 2.534352732136051

Epoch: 5| Step: 7
Training loss: 2.390987792567445
Validation loss: 2.5261708544439108

Epoch: 5| Step: 8
Training loss: 2.2392786809428817
Validation loss: 2.5420860793928335

Epoch: 5| Step: 9
Training loss: 1.9580683292159806
Validation loss: 2.532865287549156

Epoch: 5| Step: 10
Training loss: 2.5634285709793403
Validation loss: 2.525125680917862

Epoch: 5| Step: 11
Training loss: 1.7341258239458164
Validation loss: 2.520562749848013

Epoch: 229| Step: 0
Training loss: 2.5525309475060385
Validation loss: 2.505481975993532

Epoch: 5| Step: 1
Training loss: 2.190903441055996
Validation loss: 2.5193239466822988

Epoch: 5| Step: 2
Training loss: 2.0542795914979943
Validation loss: 2.5157252226584284

Epoch: 5| Step: 3
Training loss: 2.9157333697329086
Validation loss: 2.50913493226211

Epoch: 5| Step: 4
Training loss: 1.9311145648564478
Validation loss: 2.5131954086359016

Epoch: 5| Step: 5
Training loss: 2.323267637917556
Validation loss: 2.505567474688139

Epoch: 5| Step: 6
Training loss: 2.1911631838655095
Validation loss: 2.512703373808716

Epoch: 5| Step: 7
Training loss: 2.087831244770665
Validation loss: 2.5111701370143207

Epoch: 5| Step: 8
Training loss: 2.502571500048301
Validation loss: 2.5114920490606605

Epoch: 5| Step: 9
Training loss: 2.0492316504133115
Validation loss: 2.5205794054140904

Epoch: 5| Step: 10
Training loss: 3.063722327615938
Validation loss: 2.5270290542417198

Epoch: 5| Step: 11
Training loss: 2.3168245037658766
Validation loss: 2.5347409802153535

Epoch: 230| Step: 0
Training loss: 2.4238519290858713
Validation loss: 2.5290044745632807

Epoch: 5| Step: 1
Training loss: 2.700449860148133
Validation loss: 2.5413270642663415

Epoch: 5| Step: 2
Training loss: 2.9137872560820317
Validation loss: 2.534348220464206

Epoch: 5| Step: 3
Training loss: 2.6228739893811834
Validation loss: 2.5463631004342715

Epoch: 5| Step: 4
Training loss: 2.4076101248996458
Validation loss: 2.5532909468559732

Epoch: 5| Step: 5
Training loss: 2.199328675580342
Validation loss: 2.5466826742686064

Epoch: 5| Step: 6
Training loss: 2.399616262434412
Validation loss: 2.5412397586336564

Epoch: 5| Step: 7
Training loss: 2.0993293327050337
Validation loss: 2.5471001585992252

Epoch: 5| Step: 8
Training loss: 2.200180141703134
Validation loss: 2.5280617367688287

Epoch: 5| Step: 9
Training loss: 2.291130303702188
Validation loss: 2.5237787801302263

Epoch: 5| Step: 10
Training loss: 1.9422665691162457
Validation loss: 2.5172123491610496

Epoch: 5| Step: 11
Training loss: 1.6384175299854054
Validation loss: 2.5184109506147623

Epoch: 231| Step: 0
Training loss: 2.6404536265003276
Validation loss: 2.51301840483922

Epoch: 5| Step: 1
Training loss: 2.4075084219495086
Validation loss: 2.508020196317732

Epoch: 5| Step: 2
Training loss: 2.026068784504479
Validation loss: 2.5063641843208075

Epoch: 5| Step: 3
Training loss: 2.875552580430806
Validation loss: 2.4967134887377593

Epoch: 5| Step: 4
Training loss: 2.5035156326186807
Validation loss: 2.508553687557551

Epoch: 5| Step: 5
Training loss: 2.2530930769480237
Validation loss: 2.5039288325885813

Epoch: 5| Step: 6
Training loss: 2.268110188204308
Validation loss: 2.5006375969993213

Epoch: 5| Step: 7
Training loss: 1.7226532743605607
Validation loss: 2.5079348545193443

Epoch: 5| Step: 8
Training loss: 1.8667750840831985
Validation loss: 2.502833012899166

Epoch: 5| Step: 9
Training loss: 2.7017927469920737
Validation loss: 2.505478179552291

Epoch: 5| Step: 10
Training loss: 2.790138699491899
Validation loss: 2.522133540499253

Epoch: 5| Step: 11
Training loss: 1.4872212477364046
Validation loss: 2.5233722201978765

Epoch: 232| Step: 0
Training loss: 2.2351198888792463
Validation loss: 2.535935484453874

Epoch: 5| Step: 1
Training loss: 2.577020674498599
Validation loss: 2.5533523142431176

Epoch: 5| Step: 2
Training loss: 1.673392560766842
Validation loss: 2.5634463160107965

Epoch: 5| Step: 3
Training loss: 3.4780728263403495
Validation loss: 2.558070403488143

Epoch: 5| Step: 4
Training loss: 2.3295967519318292
Validation loss: 2.545402657098808

Epoch: 5| Step: 5
Training loss: 2.2063627868006566
Validation loss: 2.5331832583003058

Epoch: 5| Step: 6
Training loss: 2.478788031720577
Validation loss: 2.5254212997394863

Epoch: 5| Step: 7
Training loss: 2.2060290736602335
Validation loss: 2.5234695881318054

Epoch: 5| Step: 8
Training loss: 2.4330585803636042
Validation loss: 2.5199049403916067

Epoch: 5| Step: 9
Training loss: 1.905587190557614
Validation loss: 2.5178385487159427

Epoch: 5| Step: 10
Training loss: 2.1611687768838728
Validation loss: 2.5207894271515867

Epoch: 5| Step: 11
Training loss: 3.1377905965632666
Validation loss: 2.5140896884419317

Epoch: 233| Step: 0
Training loss: 2.473760807115909
Validation loss: 2.5239356526546897

Epoch: 5| Step: 1
Training loss: 2.2369402051973624
Validation loss: 2.525181764884039

Epoch: 5| Step: 2
Training loss: 2.3588391636591517
Validation loss: 2.53703175250532

Epoch: 5| Step: 3
Training loss: 2.6800474586839576
Validation loss: 2.5452876419780015

Epoch: 5| Step: 4
Training loss: 2.2667148468095464
Validation loss: 2.5737457728463147

Epoch: 5| Step: 5
Training loss: 2.5227023255460463
Validation loss: 2.5742870779042937

Epoch: 5| Step: 6
Training loss: 2.2564938400255476
Validation loss: 2.5800596780861116

Epoch: 5| Step: 7
Training loss: 2.226102225932199
Validation loss: 2.572978194012032

Epoch: 5| Step: 8
Training loss: 2.2240239177625285
Validation loss: 2.566683157696528

Epoch: 5| Step: 9
Training loss: 2.6358517273864
Validation loss: 2.56753039307699

Epoch: 5| Step: 10
Training loss: 2.3621834719507864
Validation loss: 2.553750405818031

Epoch: 5| Step: 11
Training loss: 2.6163136404055085
Validation loss: 2.5552400308398426

Epoch: 234| Step: 0
Training loss: 2.284881001385132
Validation loss: 2.51867333130622

Epoch: 5| Step: 1
Training loss: 2.728777753380394
Validation loss: 2.5028599314966744

Epoch: 5| Step: 2
Training loss: 2.8319347707165257
Validation loss: 2.4974473637000463

Epoch: 5| Step: 3
Training loss: 1.9406096821793184
Validation loss: 2.4930908216274363

Epoch: 5| Step: 4
Training loss: 1.9074999354051252
Validation loss: 2.501273081404658

Epoch: 5| Step: 5
Training loss: 2.149357824010126
Validation loss: 2.492322816433804

Epoch: 5| Step: 6
Training loss: 2.872398194317555
Validation loss: 2.5033517125266034

Epoch: 5| Step: 7
Training loss: 1.840168335097461
Validation loss: 2.5007531263507383

Epoch: 5| Step: 8
Training loss: 2.3896343696906612
Validation loss: 2.505082654014517

Epoch: 5| Step: 9
Training loss: 2.7966106439040477
Validation loss: 2.5049525438979754

Epoch: 5| Step: 10
Training loss: 2.708426508156618
Validation loss: 2.5035549280370337

Epoch: 5| Step: 11
Training loss: 1.9629610115450764
Validation loss: 2.5017170612304964

Epoch: 235| Step: 0
Training loss: 2.243779909577428
Validation loss: 2.5065052511318866

Epoch: 5| Step: 1
Training loss: 2.4218502904800476
Validation loss: 2.501646560600432

Epoch: 5| Step: 2
Training loss: 1.873166204794193
Validation loss: 2.5083845680386245

Epoch: 5| Step: 3
Training loss: 1.6916414938621314
Validation loss: 2.5111497755670213

Epoch: 5| Step: 4
Training loss: 1.912588930244008
Validation loss: 2.5110030116057227

Epoch: 5| Step: 5
Training loss: 2.6604721621164784
Validation loss: 2.5131122052014745

Epoch: 5| Step: 6
Training loss: 1.9783059373397904
Validation loss: 2.517601109753182

Epoch: 5| Step: 7
Training loss: 2.893538867342004
Validation loss: 2.519889049112215

Epoch: 5| Step: 8
Training loss: 2.378416815960894
Validation loss: 2.535850304502806

Epoch: 5| Step: 9
Training loss: 3.4977732795800587
Validation loss: 2.523808734462894

Epoch: 5| Step: 10
Training loss: 1.9969601178721188
Validation loss: 2.5426032628457564

Epoch: 5| Step: 11
Training loss: 1.6344310276792724
Validation loss: 2.5439767553689046

Epoch: 236| Step: 0
Training loss: 2.485466291556255
Validation loss: 2.5559234157139534

Epoch: 5| Step: 1
Training loss: 2.109196521131257
Validation loss: 2.543829108749091

Epoch: 5| Step: 2
Training loss: 2.111579929408027
Validation loss: 2.5563686606015956

Epoch: 5| Step: 3
Training loss: 2.4493176502659466
Validation loss: 2.55052627371785

Epoch: 5| Step: 4
Training loss: 2.409761813886241
Validation loss: 2.5659201174653528

Epoch: 5| Step: 5
Training loss: 2.683202367947147
Validation loss: 2.5623532617625315

Epoch: 5| Step: 6
Training loss: 2.509610586164605
Validation loss: 2.5478263435563178

Epoch: 5| Step: 7
Training loss: 2.28486576679367
Validation loss: 2.531704033841009

Epoch: 5| Step: 8
Training loss: 2.5677234166897143
Validation loss: 2.5304643212256406

Epoch: 5| Step: 9
Training loss: 2.25754944215961
Validation loss: 2.5158773418097264

Epoch: 5| Step: 10
Training loss: 2.032914638665526
Validation loss: 2.5132936095729397

Epoch: 5| Step: 11
Training loss: 2.524572347552136
Validation loss: 2.513525953901123

Epoch: 237| Step: 0
Training loss: 2.737503964495292
Validation loss: 2.508236210522711

Epoch: 5| Step: 1
Training loss: 1.533821671232897
Validation loss: 2.5083982233248725

Epoch: 5| Step: 2
Training loss: 2.2854836253879625
Validation loss: 2.507449740815468

Epoch: 5| Step: 3
Training loss: 2.6716843921868985
Validation loss: 2.5011980841702885

Epoch: 5| Step: 4
Training loss: 2.6146550466320444
Validation loss: 2.510835012557106

Epoch: 5| Step: 5
Training loss: 2.751251109503003
Validation loss: 2.5047933680259344

Epoch: 5| Step: 6
Training loss: 2.8183114939301595
Validation loss: 2.5085308753345075

Epoch: 5| Step: 7
Training loss: 2.234458121507593
Validation loss: 2.5152658715596186

Epoch: 5| Step: 8
Training loss: 1.9403376564659702
Validation loss: 2.532928687224679

Epoch: 5| Step: 9
Training loss: 2.036756592850031
Validation loss: 2.533260461476511

Epoch: 5| Step: 10
Training loss: 2.2294624583951967
Validation loss: 2.5406649829209877

Epoch: 5| Step: 11
Training loss: 1.6618979260146212
Validation loss: 2.5516292959620706

Epoch: 238| Step: 0
Training loss: 2.423092542209053
Validation loss: 2.55935796142794

Epoch: 5| Step: 1
Training loss: 2.325119946574949
Validation loss: 2.572251603945919

Epoch: 5| Step: 2
Training loss: 2.717470328301484
Validation loss: 2.560180168362189

Epoch: 5| Step: 3
Training loss: 2.1172448182177175
Validation loss: 2.562748474386836

Epoch: 5| Step: 4
Training loss: 2.087828275714866
Validation loss: 2.5482042311500805

Epoch: 5| Step: 5
Training loss: 2.0719984567260887
Validation loss: 2.54968783128969

Epoch: 5| Step: 6
Training loss: 2.5608629719733864
Validation loss: 2.5472484892044682

Epoch: 5| Step: 7
Training loss: 2.409839083732535
Validation loss: 2.549404912119887

Epoch: 5| Step: 8
Training loss: 2.198705908163541
Validation loss: 2.5407694199583837

Epoch: 5| Step: 9
Training loss: 1.8053424521971448
Validation loss: 2.5412043023242097

Epoch: 5| Step: 10
Training loss: 2.9264844143659565
Validation loss: 2.533152661866258

Epoch: 5| Step: 11
Training loss: 2.985499305051647
Validation loss: 2.5341221601342685

Epoch: 239| Step: 0
Training loss: 2.2094203744677654
Validation loss: 2.5211220265952123

Epoch: 5| Step: 1
Training loss: 2.1836947450159787
Validation loss: 2.5131866532139067

Epoch: 5| Step: 2
Training loss: 2.3616211159602045
Validation loss: 2.521031802747917

Epoch: 5| Step: 3
Training loss: 2.4902744903325273
Validation loss: 2.5183720684564928

Epoch: 5| Step: 4
Training loss: 2.272424741029678
Validation loss: 2.521225959109701

Epoch: 5| Step: 5
Training loss: 2.1112609344434157
Validation loss: 2.5212192489584506

Epoch: 5| Step: 6
Training loss: 1.9302994225040344
Validation loss: 2.5135246931299458

Epoch: 5| Step: 7
Training loss: 2.584896558097529
Validation loss: 2.527711970191133

Epoch: 5| Step: 8
Training loss: 3.1247962885262774
Validation loss: 2.5232497185753835

Epoch: 5| Step: 9
Training loss: 2.1732403970907965
Validation loss: 2.52116619755082

Epoch: 5| Step: 10
Training loss: 2.08668876006564
Validation loss: 2.527902984458457

Epoch: 5| Step: 11
Training loss: 3.1750730731394814
Validation loss: 2.516483839501447

Epoch: 240| Step: 0
Training loss: 2.589561941887624
Validation loss: 2.5128560870363894

Epoch: 5| Step: 1
Training loss: 2.489400423319007
Validation loss: 2.5138465249605866

Epoch: 5| Step: 2
Training loss: 2.1649976562064435
Validation loss: 2.510318185660617

Epoch: 5| Step: 3
Training loss: 2.571555628362327
Validation loss: 2.51125366587899

Epoch: 5| Step: 4
Training loss: 2.2890518761085588
Validation loss: 2.514816399060452

Epoch: 5| Step: 5
Training loss: 2.6262087990580643
Validation loss: 2.51495231890999

Epoch: 5| Step: 6
Training loss: 2.2109157170277416
Validation loss: 2.5153974742156167

Epoch: 5| Step: 7
Training loss: 2.0965326521496253
Validation loss: 2.508213787514639

Epoch: 5| Step: 8
Training loss: 2.0118145077331038
Validation loss: 2.5079983140313873

Epoch: 5| Step: 9
Training loss: 2.3450022086192064
Validation loss: 2.5098087094340675

Epoch: 5| Step: 10
Training loss: 2.5769086338080807
Validation loss: 2.501943988768478

Epoch: 5| Step: 11
Training loss: 2.056065782452016
Validation loss: 2.507652202327768

Epoch: 241| Step: 0
Training loss: 2.9842637925124484
Validation loss: 2.5162925268951657

Epoch: 5| Step: 1
Training loss: 2.5721775697366516
Validation loss: 2.525885592223858

Epoch: 5| Step: 2
Training loss: 2.35257503977653
Validation loss: 2.534848508490397

Epoch: 5| Step: 3
Training loss: 1.9707719622594044
Validation loss: 2.533143583258272

Epoch: 5| Step: 4
Training loss: 2.380390875318446
Validation loss: 2.5437387491175776

Epoch: 5| Step: 5
Training loss: 2.1761836941613275
Validation loss: 2.547244476166606

Epoch: 5| Step: 6
Training loss: 2.42969731270627
Validation loss: 2.5406195888797933

Epoch: 5| Step: 7
Training loss: 2.0741831171168372
Validation loss: 2.518856693623767

Epoch: 5| Step: 8
Training loss: 2.5077032618038113
Validation loss: 2.519354979191764

Epoch: 5| Step: 9
Training loss: 2.199143837013678
Validation loss: 2.537980374309211

Epoch: 5| Step: 10
Training loss: 2.2420124690094494
Validation loss: 2.521227349996128

Epoch: 5| Step: 11
Training loss: 2.390222652710163
Validation loss: 2.5214319969782686

Epoch: 242| Step: 0
Training loss: 2.4931146218597156
Validation loss: 2.530863909063033

Epoch: 5| Step: 1
Training loss: 2.119833331124314
Validation loss: 2.530397585600024

Epoch: 5| Step: 2
Training loss: 2.009891724777932
Validation loss: 2.5414827637246487

Epoch: 5| Step: 3
Training loss: 2.3416779577813394
Validation loss: 2.5391055528952093

Epoch: 5| Step: 4
Training loss: 2.8356299535696725
Validation loss: 2.548473882113367

Epoch: 5| Step: 5
Training loss: 2.0500004326424492
Validation loss: 2.5678709428739674

Epoch: 5| Step: 6
Training loss: 1.9167619004293732
Validation loss: 2.556760547643412

Epoch: 5| Step: 7
Training loss: 2.6375010594370374
Validation loss: 2.56368042537905

Epoch: 5| Step: 8
Training loss: 2.4422215435562062
Validation loss: 2.5504977977653187

Epoch: 5| Step: 9
Training loss: 1.9946058965357334
Validation loss: 2.556706108340676

Epoch: 5| Step: 10
Training loss: 2.7604840444343117
Validation loss: 2.55600655087426

Epoch: 5| Step: 11
Training loss: 2.465136237103432
Validation loss: 2.5462618559778396

Epoch: 243| Step: 0
Training loss: 3.2908692822618417
Validation loss: 2.5575371382941867

Epoch: 5| Step: 1
Training loss: 2.3510528721934607
Validation loss: 2.5593678164973226

Epoch: 5| Step: 2
Training loss: 2.604588487158569
Validation loss: 2.570807041258404

Epoch: 5| Step: 3
Training loss: 2.073917230505016
Validation loss: 2.5747814730782403

Epoch: 5| Step: 4
Training loss: 2.4939610977503808
Validation loss: 2.575302756359392

Epoch: 5| Step: 5
Training loss: 2.086026307690815
Validation loss: 2.5708418342618775

Epoch: 5| Step: 6
Training loss: 2.7421627206579413
Validation loss: 2.5713960784922953

Epoch: 5| Step: 7
Training loss: 2.058255886314572
Validation loss: 2.552260113776081

Epoch: 5| Step: 8
Training loss: 1.9080495626142246
Validation loss: 2.547822315832393

Epoch: 5| Step: 9
Training loss: 1.4482320629545375
Validation loss: 2.5539795247439394

Epoch: 5| Step: 10
Training loss: 2.45214950701266
Validation loss: 2.554416373794936

Epoch: 5| Step: 11
Training loss: 2.1189486790230423
Validation loss: 2.54297619577813

Epoch: 244| Step: 0
Training loss: 2.042233861909188
Validation loss: 2.5472645490925174

Epoch: 5| Step: 1
Training loss: 2.162203765159591
Validation loss: 2.5422893306045493

Epoch: 5| Step: 2
Training loss: 2.061024802949446
Validation loss: 2.545350638568887

Epoch: 5| Step: 3
Training loss: 2.326107507899337
Validation loss: 2.537288542958381

Epoch: 5| Step: 4
Training loss: 3.078513803470626
Validation loss: 2.5267991290361405

Epoch: 5| Step: 5
Training loss: 2.66006760862663
Validation loss: 2.5314288213539164

Epoch: 5| Step: 6
Training loss: 2.346905224804851
Validation loss: 2.530860513776274

Epoch: 5| Step: 7
Training loss: 2.6174150510336416
Validation loss: 2.5249255569109956

Epoch: 5| Step: 8
Training loss: 2.301013358411015
Validation loss: 2.5325655442430097

Epoch: 5| Step: 9
Training loss: 1.8781335713068765
Validation loss: 2.5362685691977203

Epoch: 5| Step: 10
Training loss: 2.306821707805257
Validation loss: 2.526071030488695

Epoch: 5| Step: 11
Training loss: 1.738505899721568
Validation loss: 2.5352704297231816

Epoch: 245| Step: 0
Training loss: 2.5667243191407896
Validation loss: 2.538077185746462

Epoch: 5| Step: 1
Training loss: 3.0146402124725826
Validation loss: 2.563008893662252

Epoch: 5| Step: 2
Training loss: 2.3175879515055877
Validation loss: 2.5681563767346614

Epoch: 5| Step: 3
Training loss: 2.0899842972599028
Validation loss: 2.55404406113781

Epoch: 5| Step: 4
Training loss: 2.078611388686154
Validation loss: 2.5608978341339386

Epoch: 5| Step: 5
Training loss: 1.8634163669563024
Validation loss: 2.5465755286581535

Epoch: 5| Step: 6
Training loss: 2.482138820931112
Validation loss: 2.549353877344245

Epoch: 5| Step: 7
Training loss: 2.324686365610598
Validation loss: 2.565794931469002

Epoch: 5| Step: 8
Training loss: 2.1827929398268537
Validation loss: 2.5591968437108283

Epoch: 5| Step: 9
Training loss: 2.6377207116800534
Validation loss: 2.559060044058617

Epoch: 5| Step: 10
Training loss: 2.1230438428925567
Validation loss: 2.5490305502300306

Epoch: 5| Step: 11
Training loss: 1.9540844811222449
Validation loss: 2.551254762062265

Epoch: 246| Step: 0
Training loss: 1.7475062040292526
Validation loss: 2.5438612110687147

Epoch: 5| Step: 1
Training loss: 2.2717027895381388
Validation loss: 2.5583471824900714

Epoch: 5| Step: 2
Training loss: 2.126858963996996
Validation loss: 2.5516315228948767

Epoch: 5| Step: 3
Training loss: 2.4410307328392595
Validation loss: 2.5547486471932905

Epoch: 5| Step: 4
Training loss: 2.446908253410894
Validation loss: 2.55565778872194

Epoch: 5| Step: 5
Training loss: 2.561773429768673
Validation loss: 2.5584066230349234

Epoch: 5| Step: 6
Training loss: 1.9783983713636162
Validation loss: 2.5607042727382625

Epoch: 5| Step: 7
Training loss: 2.116604883188373
Validation loss: 2.5533827620042966

Epoch: 5| Step: 8
Training loss: 2.9424768047342234
Validation loss: 2.569759417608438

Epoch: 5| Step: 9
Training loss: 2.4497751093820535
Validation loss: 2.574868521065123

Epoch: 5| Step: 10
Training loss: 2.562801715487184
Validation loss: 2.5812838766909216

Epoch: 5| Step: 11
Training loss: 1.3070259381429719
Validation loss: 2.582962891465092

Epoch: 247| Step: 0
Training loss: 1.9681164161007954
Validation loss: 2.593189860761961

Epoch: 5| Step: 1
Training loss: 3.0551393764936887
Validation loss: 2.584389102963426

Epoch: 5| Step: 2
Training loss: 2.476884887121134
Validation loss: 2.56360558951079

Epoch: 5| Step: 3
Training loss: 2.074132540360647
Validation loss: 2.5666935342356783

Epoch: 5| Step: 4
Training loss: 2.6384525730308392
Validation loss: 2.5592339294767217

Epoch: 5| Step: 5
Training loss: 2.1340080515487068
Validation loss: 2.5448328696959663

Epoch: 5| Step: 6
Training loss: 2.4836046476026055
Validation loss: 2.5404823871608393

Epoch: 5| Step: 7
Training loss: 2.142213329601869
Validation loss: 2.5350371314670657

Epoch: 5| Step: 8
Training loss: 1.9754141988888383
Validation loss: 2.5204493444303195

Epoch: 5| Step: 9
Training loss: 2.629350055116532
Validation loss: 2.5143865178560554

Epoch: 5| Step: 10
Training loss: 1.8635833943107185
Validation loss: 2.521971829055104

Epoch: 5| Step: 11
Training loss: 3.0448213356357026
Validation loss: 2.51735961928634

Epoch: 248| Step: 0
Training loss: 1.778616313400788
Validation loss: 2.5178403084039824

Epoch: 5| Step: 1
Training loss: 2.2206986158018203
Validation loss: 2.519962898755824

Epoch: 5| Step: 2
Training loss: 2.1807344718256934
Validation loss: 2.5212066796899064

Epoch: 5| Step: 3
Training loss: 1.9528986074845545
Validation loss: 2.5213649139353858

Epoch: 5| Step: 4
Training loss: 2.146294207909134
Validation loss: 2.5239763107845588

Epoch: 5| Step: 5
Training loss: 2.0976355638673914
Validation loss: 2.5351263357003186

Epoch: 5| Step: 6
Training loss: 2.4771448648016894
Validation loss: 2.544582161781046

Epoch: 5| Step: 7
Training loss: 2.345903754885323
Validation loss: 2.5608972794153932

Epoch: 5| Step: 8
Training loss: 2.619180404508923
Validation loss: 2.572379034193082

Epoch: 5| Step: 9
Training loss: 2.7607984074959684
Validation loss: 2.5455058655684675

Epoch: 5| Step: 10
Training loss: 2.7249992720576723
Validation loss: 2.563057408533414

Epoch: 5| Step: 11
Training loss: 3.2793064719372675
Validation loss: 2.5615124873708845

Epoch: 249| Step: 0
Training loss: 2.520343974721611
Validation loss: 2.553559694984096

Epoch: 5| Step: 1
Training loss: 2.7306827575903645
Validation loss: 2.542593733504762

Epoch: 5| Step: 2
Training loss: 2.145845937846179
Validation loss: 2.5249740205819444

Epoch: 5| Step: 3
Training loss: 1.9878755466566214
Validation loss: 2.52246463355447

Epoch: 5| Step: 4
Training loss: 2.669865170192693
Validation loss: 2.508180236791188

Epoch: 5| Step: 5
Training loss: 1.5639489893924
Validation loss: 2.5120398957337695

Epoch: 5| Step: 6
Training loss: 1.9289694002056983
Validation loss: 2.5127701405348164

Epoch: 5| Step: 7
Training loss: 2.116621554136752
Validation loss: 2.510257768680569

Epoch: 5| Step: 8
Training loss: 2.6204690430386086
Validation loss: 2.5143867035486807

Epoch: 5| Step: 9
Training loss: 2.8215430790047646
Validation loss: 2.5119179784567627

Epoch: 5| Step: 10
Training loss: 2.763591816419929
Validation loss: 2.513062014596479

Epoch: 5| Step: 11
Training loss: 1.683254694596847
Validation loss: 2.520941573701216

Epoch: 250| Step: 0
Training loss: 2.597745552535697
Validation loss: 2.5388273003043493

Epoch: 5| Step: 1
Training loss: 2.545523442846971
Validation loss: 2.538659702531478

Epoch: 5| Step: 2
Training loss: 1.9082083101699958
Validation loss: 2.5440514442919926

Epoch: 5| Step: 3
Training loss: 2.0123299568320236
Validation loss: 2.552633717932834

Epoch: 5| Step: 4
Training loss: 2.0738083600460233
Validation loss: 2.559124813342115

Epoch: 5| Step: 5
Training loss: 2.2407174957209315
Validation loss: 2.56383130528484

Epoch: 5| Step: 6
Training loss: 2.6123288732817307
Validation loss: 2.5847388386953827

Epoch: 5| Step: 7
Training loss: 1.9247438062138857
Validation loss: 2.5674019928055274

Epoch: 5| Step: 8
Training loss: 2.178277219162926
Validation loss: 2.565526663490546

Epoch: 5| Step: 9
Training loss: 2.941460070681244
Validation loss: 2.5609424944012957

Epoch: 5| Step: 10
Training loss: 2.6349605321371343
Validation loss: 2.5400372908137623

Epoch: 5| Step: 11
Training loss: 2.1303931966715246
Validation loss: 2.522906587099142

Epoch: 251| Step: 0
Training loss: 3.037988781946602
Validation loss: 2.5313544271458595

Epoch: 5| Step: 1
Training loss: 2.102090875506851
Validation loss: 2.5002230028191974

Epoch: 5| Step: 2
Training loss: 1.9037174849761085
Validation loss: 2.5060898359432926

Epoch: 5| Step: 3
Training loss: 2.2507506284050813
Validation loss: 2.5213732509026063

Epoch: 5| Step: 4
Training loss: 2.0625671606977836
Validation loss: 2.510902113824387

Epoch: 5| Step: 5
Training loss: 1.86396389977857
Validation loss: 2.5036910346939534

Epoch: 5| Step: 6
Training loss: 2.4489654458701366
Validation loss: 2.5162525263086843

Epoch: 5| Step: 7
Training loss: 2.3196188149862853
Validation loss: 2.515987926864313

Epoch: 5| Step: 8
Training loss: 2.791764689380461
Validation loss: 2.513152872415

Epoch: 5| Step: 9
Training loss: 2.0247994924106814
Validation loss: 2.513052831785365

Epoch: 5| Step: 10
Training loss: 2.798896442652335
Validation loss: 2.528550584585692

Epoch: 5| Step: 11
Training loss: 1.447628248657239
Validation loss: 2.528525004199339

Epoch: 252| Step: 0
Training loss: 2.349329296742211
Validation loss: 2.5323652981454696

Epoch: 5| Step: 1
Training loss: 2.098072088924956
Validation loss: 2.5250869651019587

Epoch: 5| Step: 2
Training loss: 2.4035488672559993
Validation loss: 2.5457483424678577

Epoch: 5| Step: 3
Training loss: 2.425903022400231
Validation loss: 2.547254140206248

Epoch: 5| Step: 4
Training loss: 1.921784375542931
Validation loss: 2.542349638923585

Epoch: 5| Step: 5
Training loss: 3.1616592133923
Validation loss: 2.542113707787743

Epoch: 5| Step: 6
Training loss: 1.839439720288046
Validation loss: 2.5474650200777926

Epoch: 5| Step: 7
Training loss: 2.128986546113313
Validation loss: 2.542270675920972

Epoch: 5| Step: 8
Training loss: 2.2921653782895866
Validation loss: 2.550371652210159

Epoch: 5| Step: 9
Training loss: 2.632982922027408
Validation loss: 2.5491142258534962

Epoch: 5| Step: 10
Training loss: 2.1532388200282524
Validation loss: 2.55924173744865

Epoch: 5| Step: 11
Training loss: 2.0327966523780567
Validation loss: 2.5600017410572904

Epoch: 253| Step: 0
Training loss: 2.2814513862240977
Validation loss: 2.5559068349981016

Epoch: 5| Step: 1
Training loss: 1.9600088648692922
Validation loss: 2.5442262695741147

Epoch: 5| Step: 2
Training loss: 2.7348750937774935
Validation loss: 2.537493010371937

Epoch: 5| Step: 3
Training loss: 2.3212020658721486
Validation loss: 2.541009025750862

Epoch: 5| Step: 4
Training loss: 2.5491129398160735
Validation loss: 2.5332109406565633

Epoch: 5| Step: 5
Training loss: 1.8067803736068553
Validation loss: 2.532243765112872

Epoch: 5| Step: 6
Training loss: 1.8129605333016625
Validation loss: 2.536858044774662

Epoch: 5| Step: 7
Training loss: 2.6679267489030143
Validation loss: 2.5347380761009277

Epoch: 5| Step: 8
Training loss: 2.2102970772864086
Validation loss: 2.523036667095945

Epoch: 5| Step: 9
Training loss: 3.0148902749106767
Validation loss: 2.5078427519909683

Epoch: 5| Step: 10
Training loss: 1.9571030654979118
Validation loss: 2.5163097200035724

Epoch: 5| Step: 11
Training loss: 2.6987920001438206
Validation loss: 2.504932072423421

Epoch: 254| Step: 0
Training loss: 2.4587970447160727
Validation loss: 2.5070383534816725

Epoch: 5| Step: 1
Training loss: 2.340582372789096
Validation loss: 2.528451738592086

Epoch: 5| Step: 2
Training loss: 3.1647106119108446
Validation loss: 2.5282665142348706

Epoch: 5| Step: 3
Training loss: 1.633683551817563
Validation loss: 2.5305679721111245

Epoch: 5| Step: 4
Training loss: 1.9645764754962125
Validation loss: 2.5458372455281753

Epoch: 5| Step: 5
Training loss: 1.9330534825630084
Validation loss: 2.540981107766165

Epoch: 5| Step: 6
Training loss: 2.510223655614873
Validation loss: 2.5233138952699177

Epoch: 5| Step: 7
Training loss: 2.262295189960801
Validation loss: 2.529996969965049

Epoch: 5| Step: 8
Training loss: 2.4707834102568342
Validation loss: 2.537477556138777

Epoch: 5| Step: 9
Training loss: 2.510837240063092
Validation loss: 2.539493352085051

Epoch: 5| Step: 10
Training loss: 2.203406890799364
Validation loss: 2.5391044769729705

Epoch: 5| Step: 11
Training loss: 1.8936266440323277
Validation loss: 2.5368021797893108

Epoch: 255| Step: 0
Training loss: 1.8069433999879154
Validation loss: 2.5358383914605813

Epoch: 5| Step: 1
Training loss: 2.9056190708269756
Validation loss: 2.5490399892552804

Epoch: 5| Step: 2
Training loss: 2.1796264639891794
Validation loss: 2.5430398160552814

Epoch: 5| Step: 3
Training loss: 2.206685212951507
Validation loss: 2.5700637094044865

Epoch: 5| Step: 4
Training loss: 2.063557324902897
Validation loss: 2.5739902825240026

Epoch: 5| Step: 5
Training loss: 2.3856569416245366
Validation loss: 2.5834192074582245

Epoch: 5| Step: 6
Training loss: 2.1589578405012375
Validation loss: 2.563754890954287

Epoch: 5| Step: 7
Training loss: 3.0559700617297407
Validation loss: 2.583960965781693

Epoch: 5| Step: 8
Training loss: 2.1145949590454225
Validation loss: 2.556926395618015

Epoch: 5| Step: 9
Training loss: 2.423614074452607
Validation loss: 2.5523704458132204

Epoch: 5| Step: 10
Training loss: 2.026025950183726
Validation loss: 2.5461385945571746

Epoch: 5| Step: 11
Training loss: 1.4056225542494145
Validation loss: 2.543444493761394

Epoch: 256| Step: 0
Training loss: 1.9791612993134116
Validation loss: 2.53529826953276

Epoch: 5| Step: 1
Training loss: 2.8856052011162205
Validation loss: 2.53532827192407

Epoch: 5| Step: 2
Training loss: 2.6108011699813574
Validation loss: 2.52474886004098

Epoch: 5| Step: 3
Training loss: 2.780255000405368
Validation loss: 2.5170685474618413

Epoch: 5| Step: 4
Training loss: 1.5889987809000685
Validation loss: 2.5152499193743125

Epoch: 5| Step: 5
Training loss: 1.970266938495757
Validation loss: 2.510546159899966

Epoch: 5| Step: 6
Training loss: 2.2916088328144175
Validation loss: 2.5243624752634672

Epoch: 5| Step: 7
Training loss: 2.318494707639115
Validation loss: 2.516704454096206

Epoch: 5| Step: 8
Training loss: 2.794504023785372
Validation loss: 2.517218474077777

Epoch: 5| Step: 9
Training loss: 2.2248805067571933
Validation loss: 2.521042410531998

Epoch: 5| Step: 10
Training loss: 2.1900767817166713
Validation loss: 2.528137188612104

Epoch: 5| Step: 11
Training loss: 1.2431706790193622
Validation loss: 2.544156048833051

Epoch: 257| Step: 0
Training loss: 1.94893826165628
Validation loss: 2.566998110127766

Epoch: 5| Step: 1
Training loss: 2.861608081440849
Validation loss: 2.583435673122207

Epoch: 5| Step: 2
Training loss: 2.135063688056374
Validation loss: 2.6066485073618875

Epoch: 5| Step: 3
Training loss: 3.179191381942518
Validation loss: 2.595010393761343

Epoch: 5| Step: 4
Training loss: 2.218938577724189
Validation loss: 2.560397588246477

Epoch: 5| Step: 5
Training loss: 2.5131639087381146
Validation loss: 2.5419084572042054

Epoch: 5| Step: 6
Training loss: 2.526665385739984
Validation loss: 2.539665459662836

Epoch: 5| Step: 7
Training loss: 2.1207454950495475
Validation loss: 2.5240954829564886

Epoch: 5| Step: 8
Training loss: 1.6194708732395406
Validation loss: 2.5335144110533823

Epoch: 5| Step: 9
Training loss: 2.0560219496212144
Validation loss: 2.5161669129678548

Epoch: 5| Step: 10
Training loss: 1.8066270982390569
Validation loss: 2.529456676801095

Epoch: 5| Step: 11
Training loss: 3.264694008151133
Validation loss: 2.53157857638258

Epoch: 258| Step: 0
Training loss: 2.40632787801379
Validation loss: 2.5122287266137064

Epoch: 5| Step: 1
Training loss: 2.2973572101573607
Validation loss: 2.507529511137022

Epoch: 5| Step: 2
Training loss: 1.6296936620228213
Validation loss: 2.5095522739156864

Epoch: 5| Step: 3
Training loss: 2.7070843579916306
Validation loss: 2.508513557627832

Epoch: 5| Step: 4
Training loss: 1.9488582545291326
Validation loss: 2.5133715264642027

Epoch: 5| Step: 5
Training loss: 2.584181728308893
Validation loss: 2.498433464703891

Epoch: 5| Step: 6
Training loss: 2.507079400550869
Validation loss: 2.4993019758722164

Epoch: 5| Step: 7
Training loss: 2.6675235941021316
Validation loss: 2.5037572144874036

Epoch: 5| Step: 8
Training loss: 2.0150766735776404
Validation loss: 2.5048547575868607

Epoch: 5| Step: 9
Training loss: 2.5854054621090707
Validation loss: 2.513809872158789

Epoch: 5| Step: 10
Training loss: 2.293782026602612
Validation loss: 2.5373498784524933

Epoch: 5| Step: 11
Training loss: 2.1765827777736773
Validation loss: 2.5737318775798195

Epoch: 259| Step: 0
Training loss: 2.020110587690442
Validation loss: 2.5296320002191113

Epoch: 5| Step: 1
Training loss: 2.986857714701779
Validation loss: 2.5291972313772253

Epoch: 5| Step: 2
Training loss: 2.183517645804539
Validation loss: 2.5106623135016766

Epoch: 5| Step: 3
Training loss: 2.3079048071126866
Validation loss: 2.5240710381442217

Epoch: 5| Step: 4
Training loss: 1.9698781610949232
Validation loss: 2.513841545743409

Epoch: 5| Step: 5
Training loss: 1.8892620628085912
Validation loss: 2.519787793565864

Epoch: 5| Step: 6
Training loss: 2.0967158477465198
Validation loss: 2.5278075086035265

Epoch: 5| Step: 7
Training loss: 2.851780211616283
Validation loss: 2.5154543516672403

Epoch: 5| Step: 8
Training loss: 2.2292467501031505
Validation loss: 2.5212800849086676

Epoch: 5| Step: 9
Training loss: 2.3110423262255404
Validation loss: 2.5195028535095316

Epoch: 5| Step: 10
Training loss: 2.627580917956232
Validation loss: 2.5243587170552932

Epoch: 5| Step: 11
Training loss: 1.5669889436488766
Validation loss: 2.535106499746583

Epoch: 260| Step: 0
Training loss: 1.7674905829064103
Validation loss: 2.5307160901531733

Epoch: 5| Step: 1
Training loss: 1.8288105388432814
Validation loss: 2.549793521462669

Epoch: 5| Step: 2
Training loss: 2.5687432876090828
Validation loss: 2.5669940795906943

Epoch: 5| Step: 3
Training loss: 2.323372617943119
Validation loss: 2.581762606697656

Epoch: 5| Step: 4
Training loss: 2.574509460983036
Validation loss: 2.59335467378405

Epoch: 5| Step: 5
Training loss: 2.9305679015692516
Validation loss: 2.5885222541086286

Epoch: 5| Step: 6
Training loss: 2.340612116575754
Validation loss: 2.600229786842254

Epoch: 5| Step: 7
Training loss: 2.3137696363542215
Validation loss: 2.594292147404048

Epoch: 5| Step: 8
Training loss: 2.3994710975236946
Validation loss: 2.5613942357922572

Epoch: 5| Step: 9
Training loss: 2.6172540001462865
Validation loss: 2.541073527984855

Epoch: 5| Step: 10
Training loss: 1.3636818982960415
Validation loss: 2.523343268525668

Epoch: 5| Step: 11
Training loss: 3.3663946576913717
Validation loss: 2.512528185741679

Epoch: 261| Step: 0
Training loss: 1.8657296207300986
Validation loss: 2.5160674975569255

Epoch: 5| Step: 1
Training loss: 2.482576979166812
Validation loss: 2.5285649285041774

Epoch: 5| Step: 2
Training loss: 2.225012952788294
Validation loss: 2.5304216355965385

Epoch: 5| Step: 3
Training loss: 2.4044419468760765
Validation loss: 2.527695184768447

Epoch: 5| Step: 4
Training loss: 1.9959634936210737
Validation loss: 2.5446915540600825

Epoch: 5| Step: 5
Training loss: 2.547243430981752
Validation loss: 2.5388519121529223

Epoch: 5| Step: 6
Training loss: 2.818583119394182
Validation loss: 2.5547414981995353

Epoch: 5| Step: 7
Training loss: 2.287791240891934
Validation loss: 2.545111634720173

Epoch: 5| Step: 8
Training loss: 1.7933585879640508
Validation loss: 2.5432763956124433

Epoch: 5| Step: 9
Training loss: 2.1272163053142306
Validation loss: 2.525352458070473

Epoch: 5| Step: 10
Training loss: 2.6892143813956566
Validation loss: 2.5336187252633406

Epoch: 5| Step: 11
Training loss: 2.352581829792354
Validation loss: 2.54229205806881

Epoch: 262| Step: 0
Training loss: 2.5372006206828632
Validation loss: 2.534151129785252

Epoch: 5| Step: 1
Training loss: 1.7379770076973595
Validation loss: 2.5232594548294593

Epoch: 5| Step: 2
Training loss: 2.371901347902334
Validation loss: 2.530253292598843

Epoch: 5| Step: 3
Training loss: 2.699245336818456
Validation loss: 2.520468895685754

Epoch: 5| Step: 4
Training loss: 2.2847999229733005
Validation loss: 2.5205443600203776

Epoch: 5| Step: 5
Training loss: 2.116592154605603
Validation loss: 2.5306443090213295

Epoch: 5| Step: 6
Training loss: 2.1391480634252176
Validation loss: 2.523129317417188

Epoch: 5| Step: 7
Training loss: 2.1959177723621788
Validation loss: 2.538626295914071

Epoch: 5| Step: 8
Training loss: 2.1791258604509367
Validation loss: 2.5453353784015738

Epoch: 5| Step: 9
Training loss: 2.4756583600106703
Validation loss: 2.5498672764027828

Epoch: 5| Step: 10
Training loss: 2.791218584074352
Validation loss: 2.5520552899642905

Epoch: 5| Step: 11
Training loss: 1.7410806467000886
Validation loss: 2.5488264139883405

Epoch: 263| Step: 0
Training loss: 2.7443083905290018
Validation loss: 2.555401289183657

Epoch: 5| Step: 1
Training loss: 1.650381523874684
Validation loss: 2.5512645783444747

Epoch: 5| Step: 2
Training loss: 1.7601013202113303
Validation loss: 2.5432584629771116

Epoch: 5| Step: 3
Training loss: 2.342782698339085
Validation loss: 2.5321503752930474

Epoch: 5| Step: 4
Training loss: 2.044284025178044
Validation loss: 2.527539178366649

Epoch: 5| Step: 5
Training loss: 2.0260531336076593
Validation loss: 2.541584401805727

Epoch: 5| Step: 6
Training loss: 2.7912666736451572
Validation loss: 2.5205397763369213

Epoch: 5| Step: 7
Training loss: 2.3139089467722442
Validation loss: 2.5302386245285886

Epoch: 5| Step: 8
Training loss: 2.242648937846236
Validation loss: 2.530092292523351

Epoch: 5| Step: 9
Training loss: 2.63846730216424
Validation loss: 2.5337914514311053

Epoch: 5| Step: 10
Training loss: 2.322359049516376
Validation loss: 2.5368949245457695

Epoch: 5| Step: 11
Training loss: 3.3149328834333103
Validation loss: 2.53614623220813

Epoch: 264| Step: 0
Training loss: 1.6577359137790204
Validation loss: 2.5461637541363142

Epoch: 5| Step: 1
Training loss: 2.3179181521877985
Validation loss: 2.5446184923603763

Epoch: 5| Step: 2
Training loss: 2.705893801886882
Validation loss: 2.5555163952918454

Epoch: 5| Step: 3
Training loss: 2.530012134176113
Validation loss: 2.5379580907948727

Epoch: 5| Step: 4
Training loss: 1.5361404176246103
Validation loss: 2.5458934390271764

Epoch: 5| Step: 5
Training loss: 2.235574360381394
Validation loss: 2.551323895764977

Epoch: 5| Step: 6
Training loss: 2.769619142673788
Validation loss: 2.560041702217692

Epoch: 5| Step: 7
Training loss: 2.1273599871276003
Validation loss: 2.5642785785016384

Epoch: 5| Step: 8
Training loss: 2.2355869447595516
Validation loss: 2.5855000866432745

Epoch: 5| Step: 9
Training loss: 1.9454112200219218
Validation loss: 2.578254943039019

Epoch: 5| Step: 10
Training loss: 2.9649148362072584
Validation loss: 2.554401657802937

Epoch: 5| Step: 11
Training loss: 1.1735042182251672
Validation loss: 2.548744276282603

Epoch: 265| Step: 0
Training loss: 2.6814300832316635
Validation loss: 2.5314857545803835

Epoch: 5| Step: 1
Training loss: 1.7651779824231175
Validation loss: 2.5281337267925847

Epoch: 5| Step: 2
Training loss: 2.479139942270915
Validation loss: 2.520727818753009

Epoch: 5| Step: 3
Training loss: 2.1236858792473523
Validation loss: 2.5175228976004216

Epoch: 5| Step: 4
Training loss: 2.496495747320219
Validation loss: 2.519435488435986

Epoch: 5| Step: 5
Training loss: 1.5730297056425808
Validation loss: 2.5161448903056702

Epoch: 5| Step: 6
Training loss: 2.1983313387769434
Validation loss: 2.5272536853777625

Epoch: 5| Step: 7
Training loss: 2.2003920899299447
Validation loss: 2.5344274694966997

Epoch: 5| Step: 8
Training loss: 2.52039212445783
Validation loss: 2.546172130853484

Epoch: 5| Step: 9
Training loss: 1.7831086617358727
Validation loss: 2.533226979735759

Epoch: 5| Step: 10
Training loss: 3.1716362623747614
Validation loss: 2.547641915619582

Epoch: 5| Step: 11
Training loss: 1.390996219078646
Validation loss: 2.5659861847447867

Epoch: 266| Step: 0
Training loss: 3.0886300617367826
Validation loss: 2.56965294040724

Epoch: 5| Step: 1
Training loss: 2.4882018167940902
Validation loss: 2.583662151872702

Epoch: 5| Step: 2
Training loss: 2.2670795901360576
Validation loss: 2.5883398316341295

Epoch: 5| Step: 3
Training loss: 2.376291626510954
Validation loss: 2.595654623259231

Epoch: 5| Step: 4
Training loss: 2.4243672990787277
Validation loss: 2.579996835918606

Epoch: 5| Step: 5
Training loss: 1.8396557106419422
Validation loss: 2.572063777016427

Epoch: 5| Step: 6
Training loss: 2.3690256969882624
Validation loss: 2.548730825464632

Epoch: 5| Step: 7
Training loss: 1.619364429646971
Validation loss: 2.5292944791529637

Epoch: 5| Step: 8
Training loss: 1.8878090434933916
Validation loss: 2.5337796463288216

Epoch: 5| Step: 9
Training loss: 2.1801303427340795
Validation loss: 2.5172567584160825

Epoch: 5| Step: 10
Training loss: 2.6214134601203503
Validation loss: 2.519809226539574

Epoch: 5| Step: 11
Training loss: 1.0286958448911838
Validation loss: 2.511320538394885

Epoch: 267| Step: 0
Training loss: 1.870319182241385
Validation loss: 2.5150096962200243

Epoch: 5| Step: 1
Training loss: 2.188071367030897
Validation loss: 2.519693731150223

Epoch: 5| Step: 2
Training loss: 2.303597402584614
Validation loss: 2.5231240415409872

Epoch: 5| Step: 3
Training loss: 1.8825228773046663
Validation loss: 2.5247251337407466

Epoch: 5| Step: 4
Training loss: 2.498329939921566
Validation loss: 2.5357918846174865

Epoch: 5| Step: 5
Training loss: 2.4351190529296343
Validation loss: 2.535863909825882

Epoch: 5| Step: 6
Training loss: 2.5987785037607356
Validation loss: 2.538125742724549

Epoch: 5| Step: 7
Training loss: 2.4202475709622218
Validation loss: 2.5819261484305573

Epoch: 5| Step: 8
Training loss: 2.473687943523021
Validation loss: 2.591899422305983

Epoch: 5| Step: 9
Training loss: 2.596648377814014
Validation loss: 2.599794418967708

Epoch: 5| Step: 10
Training loss: 2.350706939689099
Validation loss: 2.5732065312945123

Epoch: 5| Step: 11
Training loss: 1.3146149080880616
Validation loss: 2.5924330205918893

Epoch: 268| Step: 0
Training loss: 2.1832866964625133
Validation loss: 2.5587291031384667

Epoch: 5| Step: 1
Training loss: 2.481526403141773
Validation loss: 2.544881578830505

Epoch: 5| Step: 2
Training loss: 2.1686339861266797
Validation loss: 2.5301933123751383

Epoch: 5| Step: 3
Training loss: 2.599099858061262
Validation loss: 2.537433328519985

Epoch: 5| Step: 4
Training loss: 1.9579335338934596
Validation loss: 2.5220240717887883

Epoch: 5| Step: 5
Training loss: 2.2655958502637175
Validation loss: 2.5178818500991675

Epoch: 5| Step: 6
Training loss: 2.560106788136502
Validation loss: 2.511372191793655

Epoch: 5| Step: 7
Training loss: 2.3029085179196196
Validation loss: 2.5118395755038825

Epoch: 5| Step: 8
Training loss: 2.2101240515091187
Validation loss: 2.5207465540448637

Epoch: 5| Step: 9
Training loss: 2.422839852381264
Validation loss: 2.5219343213900376

Epoch: 5| Step: 10
Training loss: 2.4916674032390955
Validation loss: 2.5166986713416475

Epoch: 5| Step: 11
Training loss: 1.7661439251212099
Validation loss: 2.5274040769189905

Epoch: 269| Step: 0
Training loss: 2.1799510946825205
Validation loss: 2.5489221353354883

Epoch: 5| Step: 1
Training loss: 2.359026245210519
Validation loss: 2.5592313481633377

Epoch: 5| Step: 2
Training loss: 1.7312765539453379
Validation loss: 2.5684862422189747

Epoch: 5| Step: 3
Training loss: 3.102360312908286
Validation loss: 2.577342463710125

Epoch: 5| Step: 4
Training loss: 1.9093091213517719
Validation loss: 2.568930307419552

Epoch: 5| Step: 5
Training loss: 1.9820883484443417
Validation loss: 2.590268909045989

Epoch: 5| Step: 6
Training loss: 2.658699163140085
Validation loss: 2.5690767879326195

Epoch: 5| Step: 7
Training loss: 2.133452378865524
Validation loss: 2.559222400884013

Epoch: 5| Step: 8
Training loss: 2.8808640095301703
Validation loss: 2.5267977549769753

Epoch: 5| Step: 9
Training loss: 1.987806342165926
Validation loss: 2.52718358266876

Epoch: 5| Step: 10
Training loss: 2.203529050313095
Validation loss: 2.5256061506240575

Epoch: 5| Step: 11
Training loss: 2.01734968814326
Validation loss: 2.520596112105372

Epoch: 270| Step: 0
Training loss: 2.5919474577405586
Validation loss: 2.5085567902889863

Epoch: 5| Step: 1
Training loss: 2.314130878146568
Validation loss: 2.5253754920437226

Epoch: 5| Step: 2
Training loss: 2.4823667458596255
Validation loss: 2.5329901518225535

Epoch: 5| Step: 3
Training loss: 2.0944838874581437
Validation loss: 2.5378389393672784

Epoch: 5| Step: 4
Training loss: 2.439663440443521
Validation loss: 2.534721160842

Epoch: 5| Step: 5
Training loss: 1.6916591816377962
Validation loss: 2.541578382511779

Epoch: 5| Step: 6
Training loss: 1.5375816075446596
Validation loss: 2.5432065275394082

Epoch: 5| Step: 7
Training loss: 2.410219163861801
Validation loss: 2.541723279374625

Epoch: 5| Step: 8
Training loss: 2.352234500411891
Validation loss: 2.5631382465245047

Epoch: 5| Step: 9
Training loss: 3.0323918345156367
Validation loss: 2.549291751247704

Epoch: 5| Step: 10
Training loss: 1.6220558344994678
Validation loss: 2.5663821520707017

Epoch: 5| Step: 11
Training loss: 2.6095876093153376
Validation loss: 2.591147277422683

Epoch: 271| Step: 0
Training loss: 2.217763547148796
Validation loss: 2.6103678887253077

Epoch: 5| Step: 1
Training loss: 2.106212703929286
Validation loss: 2.6043072293811296

Epoch: 5| Step: 2
Training loss: 2.6487514793604294
Validation loss: 2.6045646757516288

Epoch: 5| Step: 3
Training loss: 2.598568588317599
Validation loss: 2.5841707569431516

Epoch: 5| Step: 4
Training loss: 2.5216025657936054
Validation loss: 2.5550959588175783

Epoch: 5| Step: 5
Training loss: 2.156179344014757
Validation loss: 2.5749816844498676

Epoch: 5| Step: 6
Training loss: 2.471641103141153
Validation loss: 2.5617502131289056

Epoch: 5| Step: 7
Training loss: 1.4270246544721767
Validation loss: 2.5732143489868773

Epoch: 5| Step: 8
Training loss: 2.6369615231116548
Validation loss: 2.544228909061507

Epoch: 5| Step: 9
Training loss: 2.237106361074068
Validation loss: 2.550089494530984

Epoch: 5| Step: 10
Training loss: 1.8717401140679777
Validation loss: 2.552703857239456

Epoch: 5| Step: 11
Training loss: 2.415733968588973
Validation loss: 2.537509486301273

Epoch: 272| Step: 0
Training loss: 2.309663631174973
Validation loss: 2.5309098097528384

Epoch: 5| Step: 1
Training loss: 2.4558923747310684
Validation loss: 2.5433688691316036

Epoch: 5| Step: 2
Training loss: 2.6440467108843557
Validation loss: 2.5235943031999315

Epoch: 5| Step: 3
Training loss: 1.8737792809700733
Validation loss: 2.5480910715366427

Epoch: 5| Step: 4
Training loss: 2.6696325339287688
Validation loss: 2.5428343784753262

Epoch: 5| Step: 5
Training loss: 1.991479545911546
Validation loss: 2.535516071695675

Epoch: 5| Step: 6
Training loss: 2.147499573322294
Validation loss: 2.5411539902620985

Epoch: 5| Step: 7
Training loss: 2.1790581344895568
Validation loss: 2.546381881187479

Epoch: 5| Step: 8
Training loss: 2.510026566414233
Validation loss: 2.5601445397722378

Epoch: 5| Step: 9
Training loss: 2.2848634711614926
Validation loss: 2.5749483246849483

Epoch: 5| Step: 10
Training loss: 2.075256088264449
Validation loss: 2.5822446006854856

Epoch: 5| Step: 11
Training loss: 1.3125278833243064
Validation loss: 2.587622463319854

Epoch: 273| Step: 0
Training loss: 2.709344577288512
Validation loss: 2.5878843257035657

Epoch: 5| Step: 1
Training loss: 2.3713414975593192
Validation loss: 2.5944917223441704

Epoch: 5| Step: 2
Training loss: 1.672967144056928
Validation loss: 2.5808451896221056

Epoch: 5| Step: 3
Training loss: 2.620242667134873
Validation loss: 2.580795034471953

Epoch: 5| Step: 4
Training loss: 2.098889774941389
Validation loss: 2.583456164690573

Epoch: 5| Step: 5
Training loss: 2.4441887464110206
Validation loss: 2.58530856318147

Epoch: 5| Step: 6
Training loss: 2.0148167135400072
Validation loss: 2.573998132570642

Epoch: 5| Step: 7
Training loss: 1.904987229632329
Validation loss: 2.570556153688576

Epoch: 5| Step: 8
Training loss: 2.49204447464421
Validation loss: 2.557857650206097

Epoch: 5| Step: 9
Training loss: 2.3530173632965603
Validation loss: 2.5443753572752814

Epoch: 5| Step: 10
Training loss: 2.0404172175243533
Validation loss: 2.538140815316739

Epoch: 5| Step: 11
Training loss: 2.7860508320724517
Validation loss: 2.526582735979695

Epoch: 274| Step: 0
Training loss: 1.976677450222473
Validation loss: 2.5503992103233117

Epoch: 5| Step: 1
Training loss: 3.012120716072136
Validation loss: 2.561151847690072

Epoch: 5| Step: 2
Training loss: 1.878002560094809
Validation loss: 2.5612722882848917

Epoch: 5| Step: 3
Training loss: 2.798532772519115
Validation loss: 2.587765211989157

Epoch: 5| Step: 4
Training loss: 2.3343792569327193
Validation loss: 2.6009308178896924

Epoch: 5| Step: 5
Training loss: 2.255782326707757
Validation loss: 2.604777673885453

Epoch: 5| Step: 6
Training loss: 2.1834664350322854
Validation loss: 2.5959991810560528

Epoch: 5| Step: 7
Training loss: 2.176030197831593
Validation loss: 2.591313447115709

Epoch: 5| Step: 8
Training loss: 2.294352489206173
Validation loss: 2.5751556790768655

Epoch: 5| Step: 9
Training loss: 1.7357730214151155
Validation loss: 2.549295932522193

Epoch: 5| Step: 10
Training loss: 2.212390112437912
Validation loss: 2.566461373815669

Epoch: 5| Step: 11
Training loss: 1.931978849879689
Validation loss: 2.5498714879009254

Epoch: 275| Step: 0
Training loss: 2.7930266260939627
Validation loss: 2.533169054259604

Epoch: 5| Step: 1
Training loss: 2.5137873980956917
Validation loss: 2.5289299618993364

Epoch: 5| Step: 2
Training loss: 1.749285075066236
Validation loss: 2.5281868009554116

Epoch: 5| Step: 3
Training loss: 2.367130291439487
Validation loss: 2.5250880017540878

Epoch: 5| Step: 4
Training loss: 2.7038537955851814
Validation loss: 2.5192759934086557

Epoch: 5| Step: 5
Training loss: 2.251695629792916
Validation loss: 2.5209492480737743

Epoch: 5| Step: 6
Training loss: 2.0937698135577194
Validation loss: 2.5210898967627178

Epoch: 5| Step: 7
Training loss: 2.6401853477552875
Validation loss: 2.530188808991407

Epoch: 5| Step: 8
Training loss: 1.9941544938609301
Validation loss: 2.559467005521791

Epoch: 5| Step: 9
Training loss: 1.7775805640439677
Validation loss: 2.5576998209461452

Epoch: 5| Step: 10
Training loss: 2.229649702365277
Validation loss: 2.595170731168094

Epoch: 5| Step: 11
Training loss: 1.050341829788756
Validation loss: 2.59860902297752

Epoch: 276| Step: 0
Training loss: 1.734872695034092
Validation loss: 2.560515806318552

Epoch: 5| Step: 1
Training loss: 2.8552573317552294
Validation loss: 2.612655846116434

Epoch: 5| Step: 2
Training loss: 2.683437914814422
Validation loss: 2.5610668198598208

Epoch: 5| Step: 3
Training loss: 2.2647658198812937
Validation loss: 2.5423828911168935

Epoch: 5| Step: 4
Training loss: 2.516767728010062
Validation loss: 2.5132901391656857

Epoch: 5| Step: 5
Training loss: 1.8361389049684185
Validation loss: 2.5103425981878025

Epoch: 5| Step: 6
Training loss: 1.8683351317756338
Validation loss: 2.5172831518152385

Epoch: 5| Step: 7
Training loss: 1.7767737512124149
Validation loss: 2.5089714980820723

Epoch: 5| Step: 8
Training loss: 2.504340980628121
Validation loss: 2.5074394320940874

Epoch: 5| Step: 9
Training loss: 2.6370662205944955
Validation loss: 2.5014901091350663

Epoch: 5| Step: 10
Training loss: 2.5622427276231203
Validation loss: 2.509413215248039

Epoch: 5| Step: 11
Training loss: 1.474156836992136
Validation loss: 2.4929189276351593

Epoch: 277| Step: 0
Training loss: 2.3629299438656024
Validation loss: 2.4993274996168284

Epoch: 5| Step: 1
Training loss: 1.6083509279517445
Validation loss: 2.515947799032941

Epoch: 5| Step: 2
Training loss: 2.2231343966830552
Validation loss: 2.51938523059163

Epoch: 5| Step: 3
Training loss: 2.4568922916290035
Validation loss: 2.523114166960959

Epoch: 5| Step: 4
Training loss: 2.1665925477872947
Validation loss: 2.552052637162143

Epoch: 5| Step: 5
Training loss: 2.8132163089289763
Validation loss: 2.5442832170781813

Epoch: 5| Step: 6
Training loss: 1.7930611646849959
Validation loss: 2.5733175943462396

Epoch: 5| Step: 7
Training loss: 2.4596400155703817
Validation loss: 2.574504834468459

Epoch: 5| Step: 8
Training loss: 2.412421894291529
Validation loss: 2.5882986915400648

Epoch: 5| Step: 9
Training loss: 2.42225870353843
Validation loss: 2.600761343674601

Epoch: 5| Step: 10
Training loss: 2.3857641730464665
Validation loss: 2.5938929093298584

Epoch: 5| Step: 11
Training loss: 2.101777813740672
Validation loss: 2.60950837394071

Epoch: 278| Step: 0
Training loss: 2.0693368592199457
Validation loss: 2.5807468684436548

Epoch: 5| Step: 1
Training loss: 1.9796499632639053
Validation loss: 2.5663238543130458

Epoch: 5| Step: 2
Training loss: 2.0169592884136667
Validation loss: 2.5459669206619893

Epoch: 5| Step: 3
Training loss: 2.0990753772244624
Validation loss: 2.530494274934409

Epoch: 5| Step: 4
Training loss: 2.641654541838184
Validation loss: 2.533441297579179

Epoch: 5| Step: 5
Training loss: 2.740969047569247
Validation loss: 2.5232231356151553

Epoch: 5| Step: 6
Training loss: 2.3513975370723372
Validation loss: 2.5216062650760347

Epoch: 5| Step: 7
Training loss: 2.0064111710217643
Validation loss: 2.534319746965026

Epoch: 5| Step: 8
Training loss: 1.989173314318225
Validation loss: 2.5222136774690926

Epoch: 5| Step: 9
Training loss: 2.697010776819318
Validation loss: 2.52114826132033

Epoch: 5| Step: 10
Training loss: 2.405010548209615
Validation loss: 2.5106247654741356

Epoch: 5| Step: 11
Training loss: 2.9979259951200925
Validation loss: 2.5219795574082733

Epoch: 279| Step: 0
Training loss: 2.152798640925993
Validation loss: 2.517806846502146

Epoch: 5| Step: 1
Training loss: 3.190184267037534
Validation loss: 2.523831028757775

Epoch: 5| Step: 2
Training loss: 2.20667149135066
Validation loss: 2.5341701264834993

Epoch: 5| Step: 3
Training loss: 1.9870734902754894
Validation loss: 2.530956824321885

Epoch: 5| Step: 4
Training loss: 2.0342413370548766
Validation loss: 2.550247027393398

Epoch: 5| Step: 5
Training loss: 2.7241517697877344
Validation loss: 2.552028769603986

Epoch: 5| Step: 6
Training loss: 1.9520248977019143
Validation loss: 2.556240583789523

Epoch: 5| Step: 7
Training loss: 1.9939774195197004
Validation loss: 2.5567937328633916

Epoch: 5| Step: 8
Training loss: 2.179484586944304
Validation loss: 2.5425041035969445

Epoch: 5| Step: 9
Training loss: 2.1923563864289872
Validation loss: 2.5498225624084214

Epoch: 5| Step: 10
Training loss: 1.9061638234155
Validation loss: 2.5498789135227042

Epoch: 5| Step: 11
Training loss: 3.367105646753806
Validation loss: 2.5492261320072136

Epoch: 280| Step: 0
Training loss: 2.5252087875007865
Validation loss: 2.558521520162926

Epoch: 5| Step: 1
Training loss: 2.6627517115568025
Validation loss: 2.5370982999219747

Epoch: 5| Step: 2
Training loss: 1.585751752828068
Validation loss: 2.5286966325952362

Epoch: 5| Step: 3
Training loss: 1.957004752522245
Validation loss: 2.520191683694651

Epoch: 5| Step: 4
Training loss: 2.184905557228126
Validation loss: 2.5361742739200994

Epoch: 5| Step: 5
Training loss: 2.5796747347113276
Validation loss: 2.516621386413299

Epoch: 5| Step: 6
Training loss: 2.228800187928465
Validation loss: 2.52077153159013

Epoch: 5| Step: 7
Training loss: 2.1431003932035293
Validation loss: 2.527559506042528

Epoch: 5| Step: 8
Training loss: 1.8558898447948287
Validation loss: 2.5424862358448372

Epoch: 5| Step: 9
Training loss: 1.9354250472112844
Validation loss: 2.544148489367259

Epoch: 5| Step: 10
Training loss: 3.0519174958222828
Validation loss: 2.5551164482775683

Epoch: 5| Step: 11
Training loss: 1.9326448828903946
Validation loss: 2.583920805541523

Epoch: 281| Step: 0
Training loss: 1.7841041853807789
Validation loss: 2.580642326631258

Epoch: 5| Step: 1
Training loss: 2.584316979048712
Validation loss: 2.6018637519976324

Epoch: 5| Step: 2
Training loss: 1.4867647710143066
Validation loss: 2.583607721882136

Epoch: 5| Step: 3
Training loss: 2.673183633778024
Validation loss: 2.5906436963973154

Epoch: 5| Step: 4
Training loss: 2.4891676828462996
Validation loss: 2.570543446934039

Epoch: 5| Step: 5
Training loss: 1.7430391838584882
Validation loss: 2.565473312434899

Epoch: 5| Step: 6
Training loss: 2.455474505901721
Validation loss: 2.5697192248486376

Epoch: 5| Step: 7
Training loss: 2.4916959176106146
Validation loss: 2.573391840888125

Epoch: 5| Step: 8
Training loss: 2.2189969207481
Validation loss: 2.567225609463795

Epoch: 5| Step: 9
Training loss: 2.0049479790310283
Validation loss: 2.575905806129614

Epoch: 5| Step: 10
Training loss: 2.545685191820802
Validation loss: 2.5677715600658924

Epoch: 5| Step: 11
Training loss: 1.5539019723164946
Validation loss: 2.5907035577978315

Epoch: 282| Step: 0
Training loss: 1.9556835049015457
Validation loss: 2.5837454633729844

Epoch: 5| Step: 1
Training loss: 2.4198389169976395
Validation loss: 2.5748409586311674

Epoch: 5| Step: 2
Training loss: 2.21596190738645
Validation loss: 2.558202609772144

Epoch: 5| Step: 3
Training loss: 2.16321334980282
Validation loss: 2.554197645518094

Epoch: 5| Step: 4
Training loss: 2.283760048562813
Validation loss: 2.5671663557014988

Epoch: 5| Step: 5
Training loss: 2.36391653554518
Validation loss: 2.5476040450035518

Epoch: 5| Step: 6
Training loss: 1.9432180382021316
Validation loss: 2.569652333455604

Epoch: 5| Step: 7
Training loss: 2.3571061094317765
Validation loss: 2.5589023937792508

Epoch: 5| Step: 8
Training loss: 2.6651753089886645
Validation loss: 2.5712456869158116

Epoch: 5| Step: 9
Training loss: 2.3847195357634217
Validation loss: 2.601259395289712

Epoch: 5| Step: 10
Training loss: 1.9753473338595384
Validation loss: 2.6093335747999715

Epoch: 5| Step: 11
Training loss: 1.6328299489526321
Validation loss: 2.59231571005379

Epoch: 283| Step: 0
Training loss: 2.551834800192431
Validation loss: 2.5946706187465454

Epoch: 5| Step: 1
Training loss: 1.8359018525254347
Validation loss: 2.5492063044467232

Epoch: 5| Step: 2
Training loss: 2.2347502493366904
Validation loss: 2.5481188999265503

Epoch: 5| Step: 3
Training loss: 2.0711721111195454
Validation loss: 2.52920429742733

Epoch: 5| Step: 4
Training loss: 2.1447849366828327
Validation loss: 2.533053415031945

Epoch: 5| Step: 5
Training loss: 2.241009233162076
Validation loss: 2.546299539782324

Epoch: 5| Step: 6
Training loss: 2.0863770439728047
Validation loss: 2.5457544065333244

Epoch: 5| Step: 7
Training loss: 2.247373425374571
Validation loss: 2.572842685057969

Epoch: 5| Step: 8
Training loss: 2.4583735597412
Validation loss: 2.561878974218451

Epoch: 5| Step: 9
Training loss: 2.650276738238029
Validation loss: 2.5782755470632783

Epoch: 5| Step: 10
Training loss: 2.3459675788297694
Validation loss: 2.5824253668314534

Epoch: 5| Step: 11
Training loss: 1.3013288015641065
Validation loss: 2.6066146534497148

Epoch: 284| Step: 0
Training loss: 2.3480488326731357
Validation loss: 2.60131670962084

Epoch: 5| Step: 1
Training loss: 2.120126521275804
Validation loss: 2.6073552002877025

Epoch: 5| Step: 2
Training loss: 2.196034594390148
Validation loss: 2.58935018586007

Epoch: 5| Step: 3
Training loss: 2.7243076389821335
Validation loss: 2.5632041839731055

Epoch: 5| Step: 4
Training loss: 1.7974319921581778
Validation loss: 2.5534700881844885

Epoch: 5| Step: 5
Training loss: 1.9714886826478908
Validation loss: 2.5391055059458845

Epoch: 5| Step: 6
Training loss: 2.4082424287458215
Validation loss: 2.537964917172415

Epoch: 5| Step: 7
Training loss: 2.4373285282172508
Validation loss: 2.533639392329916

Epoch: 5| Step: 8
Training loss: 2.066883169134403
Validation loss: 2.531689276078426

Epoch: 5| Step: 9
Training loss: 2.165595327727256
Validation loss: 2.5187521072328396

Epoch: 5| Step: 10
Training loss: 2.115412231745218
Validation loss: 2.5210119760808385

Epoch: 5| Step: 11
Training loss: 3.52019315839863
Validation loss: 2.52446354338545

Epoch: 285| Step: 0
Training loss: 2.2240869513193067
Validation loss: 2.5346215246976005

Epoch: 5| Step: 1
Training loss: 2.99469797181332
Validation loss: 2.5402671147426226

Epoch: 5| Step: 2
Training loss: 2.463788225176439
Validation loss: 2.565988300495652

Epoch: 5| Step: 3
Training loss: 2.4205119573514096
Validation loss: 2.5512486954953117

Epoch: 5| Step: 4
Training loss: 2.2711516224324693
Validation loss: 2.5617794287559654

Epoch: 5| Step: 5
Training loss: 2.5069456890052626
Validation loss: 2.5349187911178652

Epoch: 5| Step: 6
Training loss: 2.333075361523414
Validation loss: 2.5138185937957664

Epoch: 5| Step: 7
Training loss: 1.9170064901322657
Validation loss: 2.4991212830414193

Epoch: 5| Step: 8
Training loss: 2.041079170661492
Validation loss: 2.5004756355822533

Epoch: 5| Step: 9
Training loss: 1.6866859309160585
Validation loss: 2.4859040311410157

Epoch: 5| Step: 10
Training loss: 2.296272354474014
Validation loss: 2.4908886377872443

Epoch: 5| Step: 11
Training loss: 2.301163180245308
Validation loss: 2.488346456315104

Epoch: 286| Step: 0
Training loss: 2.451758714923557
Validation loss: 2.5260839570166067

Epoch: 5| Step: 1
Training loss: 2.424274461888534
Validation loss: 2.544562985147467

Epoch: 5| Step: 2
Training loss: 2.257623473177728
Validation loss: 2.5680179190079824

Epoch: 5| Step: 3
Training loss: 2.138878436978167
Validation loss: 2.5808902591400744

Epoch: 5| Step: 4
Training loss: 1.9428844695914282
Validation loss: 2.578869086114021

Epoch: 5| Step: 5
Training loss: 2.5614646122439075
Validation loss: 2.5862759217920184

Epoch: 5| Step: 6
Training loss: 2.429554435790589
Validation loss: 2.600148650193167

Epoch: 5| Step: 7
Training loss: 1.7288571122776029
Validation loss: 2.5605725777638377

Epoch: 5| Step: 8
Training loss: 2.209353253420756
Validation loss: 2.549976262748788

Epoch: 5| Step: 9
Training loss: 2.6549372402323854
Validation loss: 2.5394239041295577

Epoch: 5| Step: 10
Training loss: 2.029209109364431
Validation loss: 2.5096510330341864

Epoch: 5| Step: 11
Training loss: 1.6364217775544805
Validation loss: 2.5063792497407564

Epoch: 287| Step: 0
Training loss: 2.3498648665513184
Validation loss: 2.4949976425248948

Epoch: 5| Step: 1
Training loss: 2.568439763772823
Validation loss: 2.482833776108759

Epoch: 5| Step: 2
Training loss: 2.374650025933612
Validation loss: 2.498660070236392

Epoch: 5| Step: 3
Training loss: 2.6411792241230447
Validation loss: 2.4877695488693083

Epoch: 5| Step: 4
Training loss: 2.4016517200662277
Validation loss: 2.4935840851062836

Epoch: 5| Step: 5
Training loss: 2.198005083906075
Validation loss: 2.4959039193065893

Epoch: 5| Step: 6
Training loss: 2.3684181564714892
Validation loss: 2.482225992121301

Epoch: 5| Step: 7
Training loss: 2.468218879063816
Validation loss: 2.5081441428249867

Epoch: 5| Step: 8
Training loss: 2.1042367023357396
Validation loss: 2.506636814381847

Epoch: 5| Step: 9
Training loss: 2.111366631565196
Validation loss: 2.498423118780534

Epoch: 5| Step: 10
Training loss: 2.379587060382934
Validation loss: 2.496784112745832

Epoch: 5| Step: 11
Training loss: 0.5750762090766375
Validation loss: 2.5224504932123835

Epoch: 288| Step: 0
Training loss: 2.5489313915862217
Validation loss: 2.5475419581236385

Epoch: 5| Step: 1
Training loss: 2.281475944303607
Validation loss: 2.594695118215989

Epoch: 5| Step: 2
Training loss: 2.2744554685408205
Validation loss: 2.6059223906809446

Epoch: 5| Step: 3
Training loss: 2.3301303087068326
Validation loss: 2.593971193219578

Epoch: 5| Step: 4
Training loss: 2.10184678207635
Validation loss: 2.56042286960315

Epoch: 5| Step: 5
Training loss: 2.224428352044112
Validation loss: 2.5340443775311305

Epoch: 5| Step: 6
Training loss: 2.653400643164264
Validation loss: 2.533676997254238

Epoch: 5| Step: 7
Training loss: 3.0123345800545436
Validation loss: 2.501955330634553

Epoch: 5| Step: 8
Training loss: 1.785994385141259
Validation loss: 2.504312019181366

Epoch: 5| Step: 9
Training loss: 1.9942783528589083
Validation loss: 2.4934362553537093

Epoch: 5| Step: 10
Training loss: 2.0550747930648003
Validation loss: 2.508805218114097

Epoch: 5| Step: 11
Training loss: 1.9807559676007631
Validation loss: 2.502285619833273

Epoch: 289| Step: 0
Training loss: 2.302462988109687
Validation loss: 2.532227625652325

Epoch: 5| Step: 1
Training loss: 1.9970469727586326
Validation loss: 2.5148232882551027

Epoch: 5| Step: 2
Training loss: 1.7121547044571144
Validation loss: 2.525549143855878

Epoch: 5| Step: 3
Training loss: 2.1499610631211468
Validation loss: 2.52231053873662

Epoch: 5| Step: 4
Training loss: 2.5377367519934397
Validation loss: 2.516227946082928

Epoch: 5| Step: 5
Training loss: 2.366484685626228
Validation loss: 2.5245679797356093

Epoch: 5| Step: 6
Training loss: 2.1311598862197845
Validation loss: 2.512727632696486

Epoch: 5| Step: 7
Training loss: 2.573132298709135
Validation loss: 2.52831707685668

Epoch: 5| Step: 8
Training loss: 2.609378654797216
Validation loss: 2.5382346970381064

Epoch: 5| Step: 9
Training loss: 2.209268000276539
Validation loss: 2.531518596165969

Epoch: 5| Step: 10
Training loss: 2.1740542668620835
Validation loss: 2.5353736255245

Epoch: 5| Step: 11
Training loss: 1.7562580610748677
Validation loss: 2.5518158065292496

Epoch: 290| Step: 0
Training loss: 2.370148371305466
Validation loss: 2.5616214959818318

Epoch: 5| Step: 1
Training loss: 2.5791788432666314
Validation loss: 2.588853849215726

Epoch: 5| Step: 2
Training loss: 2.0102917989847717
Validation loss: 2.590362239928755

Epoch: 5| Step: 3
Training loss: 2.7519299930550605
Validation loss: 2.612824723719617

Epoch: 5| Step: 4
Training loss: 1.6404147785470782
Validation loss: 2.6007672622807183

Epoch: 5| Step: 5
Training loss: 2.527659754623641
Validation loss: 2.5801559809975667

Epoch: 5| Step: 6
Training loss: 2.3087871748033377
Validation loss: 2.5744253103673596

Epoch: 5| Step: 7
Training loss: 2.367461638739027
Validation loss: 2.542161050513158

Epoch: 5| Step: 8
Training loss: 1.5847312210782947
Validation loss: 2.536162419195914

Epoch: 5| Step: 9
Training loss: 2.6076415923051384
Validation loss: 2.5137167182880353

Epoch: 5| Step: 10
Training loss: 1.8783410505030775
Validation loss: 2.51466949750359

Epoch: 5| Step: 11
Training loss: 2.592904745968791
Validation loss: 2.4986504369176905

Epoch: 291| Step: 0
Training loss: 1.363956579266775
Validation loss: 2.5070645136858825

Epoch: 5| Step: 1
Training loss: 2.722191222224112
Validation loss: 2.5150799842083216

Epoch: 5| Step: 2
Training loss: 2.8071930725864482
Validation loss: 2.5233551893795285

Epoch: 5| Step: 3
Training loss: 1.7070332053585768
Validation loss: 2.5094120751314644

Epoch: 5| Step: 4
Training loss: 2.734241068148527
Validation loss: 2.5449277380531523

Epoch: 5| Step: 5
Training loss: 2.189754414309745
Validation loss: 2.55083742415773

Epoch: 5| Step: 6
Training loss: 2.7548578877151444
Validation loss: 2.5201654114187035

Epoch: 5| Step: 7
Training loss: 2.466346633185785
Validation loss: 2.518933835037592

Epoch: 5| Step: 8
Training loss: 1.6312380413917877
Validation loss: 2.534924120823887

Epoch: 5| Step: 9
Training loss: 2.0034738412457878
Validation loss: 2.53440778486101

Epoch: 5| Step: 10
Training loss: 2.133871744679539
Validation loss: 2.5233059347870737

Epoch: 5| Step: 11
Training loss: 1.7489839737879294
Validation loss: 2.537394455968173

Epoch: 292| Step: 0
Training loss: 2.251177691495663
Validation loss: 2.525159893622975

Epoch: 5| Step: 1
Training loss: 2.52973553598376
Validation loss: 2.5216345669677698

Epoch: 5| Step: 2
Training loss: 2.537308776866268
Validation loss: 2.514190920593826

Epoch: 5| Step: 3
Training loss: 2.315853882879519
Validation loss: 2.5240778233646006

Epoch: 5| Step: 4
Training loss: 1.7942910896859425
Validation loss: 2.5069791017099283

Epoch: 5| Step: 5
Training loss: 2.488035564180691
Validation loss: 2.506929283648081

Epoch: 5| Step: 6
Training loss: 2.2027931775130294
Validation loss: 2.5144462627629167

Epoch: 5| Step: 7
Training loss: 2.2969001197738845
Validation loss: 2.5233117535796734

Epoch: 5| Step: 8
Training loss: 1.648744527418701
Validation loss: 2.5285969319249197

Epoch: 5| Step: 9
Training loss: 2.3674167232509618
Validation loss: 2.520966304997358

Epoch: 5| Step: 10
Training loss: 2.41182073804438
Validation loss: 2.53307622406887

Epoch: 5| Step: 11
Training loss: 1.6492908312045471
Validation loss: 2.5338629532622803

Epoch: 293| Step: 0
Training loss: 2.129746801344163
Validation loss: 2.5677934533196956

Epoch: 5| Step: 1
Training loss: 2.837283989166517
Validation loss: 2.6030348638901653

Epoch: 5| Step: 2
Training loss: 2.392653857219792
Validation loss: 2.6300714224254

Epoch: 5| Step: 3
Training loss: 2.0434464722136094
Validation loss: 2.6520703399072207

Epoch: 5| Step: 4
Training loss: 2.282241919175709
Validation loss: 2.5900304121946895

Epoch: 5| Step: 5
Training loss: 2.4900726624882727
Validation loss: 2.5740871559818697

Epoch: 5| Step: 6
Training loss: 2.036261728720142
Validation loss: 2.5538113887327585

Epoch: 5| Step: 7
Training loss: 2.307914517781523
Validation loss: 2.5338351506104146

Epoch: 5| Step: 8
Training loss: 1.9623117684644438
Validation loss: 2.529667687451392

Epoch: 5| Step: 9
Training loss: 2.4920705929304905
Validation loss: 2.5061425841628178

Epoch: 5| Step: 10
Training loss: 2.138230704176003
Validation loss: 2.500745411848157

Epoch: 5| Step: 11
Training loss: 2.136655370689364
Validation loss: 2.474045046574965

Epoch: 294| Step: 0
Training loss: 2.4848093097062858
Validation loss: 2.490287678465978

Epoch: 5| Step: 1
Training loss: 2.5200868452336183
Validation loss: 2.4908832218355252

Epoch: 5| Step: 2
Training loss: 2.148455810468848
Validation loss: 2.493379457331025

Epoch: 5| Step: 3
Training loss: 2.3073864666915127
Validation loss: 2.4887435140354386

Epoch: 5| Step: 4
Training loss: 2.01886140498254
Validation loss: 2.5058183218213834

Epoch: 5| Step: 5
Training loss: 2.217275747595514
Validation loss: 2.5052155569267156

Epoch: 5| Step: 6
Training loss: 2.4711048146475627
Validation loss: 2.5095837518521824

Epoch: 5| Step: 7
Training loss: 2.381513698124419
Validation loss: 2.529673340419877

Epoch: 5| Step: 8
Training loss: 2.022246610520034
Validation loss: 2.564664116823297

Epoch: 5| Step: 9
Training loss: 2.078642357696123
Validation loss: 2.566612138623084

Epoch: 5| Step: 10
Training loss: 2.3980678807848728
Validation loss: 2.569950035688132

Epoch: 5| Step: 11
Training loss: 1.5667162657387337
Validation loss: 2.587805554413224

Epoch: 295| Step: 0
Training loss: 2.114365615034573
Validation loss: 2.572360910530147

Epoch: 5| Step: 1
Training loss: 1.8613735325529368
Validation loss: 2.5640992082366014

Epoch: 5| Step: 2
Training loss: 1.9392975497969773
Validation loss: 2.553180646815215

Epoch: 5| Step: 3
Training loss: 2.814452023740893
Validation loss: 2.5633398749830643

Epoch: 5| Step: 4
Training loss: 2.2540294805255696
Validation loss: 2.5482688943147536

Epoch: 5| Step: 5
Training loss: 2.073670510578788
Validation loss: 2.543422357717464

Epoch: 5| Step: 6
Training loss: 2.4076603311012326
Validation loss: 2.5439878141693146

Epoch: 5| Step: 7
Training loss: 2.59868565863684
Validation loss: 2.547197594524161

Epoch: 5| Step: 8
Training loss: 1.8460751113241278
Validation loss: 2.5646402175032144

Epoch: 5| Step: 9
Training loss: 1.4566710489645072
Validation loss: 2.5525947733043814

Epoch: 5| Step: 10
Training loss: 2.51111677440166
Validation loss: 2.5584185319458848

Epoch: 5| Step: 11
Training loss: 3.368988334420429
Validation loss: 2.5607193831259853

Epoch: 296| Step: 0
Training loss: 1.7589126196145535
Validation loss: 2.59062401710556

Epoch: 5| Step: 1
Training loss: 2.20686131726185
Validation loss: 2.6139815969159867

Epoch: 5| Step: 2
Training loss: 2.31435010978548
Validation loss: 2.6149011085737768

Epoch: 5| Step: 3
Training loss: 2.2663326868205105
Validation loss: 2.6267853920860347

Epoch: 5| Step: 4
Training loss: 2.5991561804149454
Validation loss: 2.6181322964035165

Epoch: 5| Step: 5
Training loss: 2.455589757031921
Validation loss: 2.612258140648391

Epoch: 5| Step: 6
Training loss: 2.3225262802821667
Validation loss: 2.6052453223135426

Epoch: 5| Step: 7
Training loss: 2.6170638781146645
Validation loss: 2.5675547568695527

Epoch: 5| Step: 8
Training loss: 1.9110845326761283
Validation loss: 2.5392930068019344

Epoch: 5| Step: 9
Training loss: 2.060439033759752
Validation loss: 2.5345996310288963

Epoch: 5| Step: 10
Training loss: 2.063552356777651
Validation loss: 2.5224787895702185

Epoch: 5| Step: 11
Training loss: 2.4260991820324143
Validation loss: 2.4959099293473175

Epoch: 297| Step: 0
Training loss: 1.6328057831986549
Validation loss: 2.502069885959958

Epoch: 5| Step: 1
Training loss: 2.4536787246402985
Validation loss: 2.4966133663330634

Epoch: 5| Step: 2
Training loss: 2.312783919767191
Validation loss: 2.5000714490535203

Epoch: 5| Step: 3
Training loss: 1.645767508369458
Validation loss: 2.511720423008197

Epoch: 5| Step: 4
Training loss: 2.599775645773249
Validation loss: 2.4961612594780083

Epoch: 5| Step: 5
Training loss: 3.27035851079412
Validation loss: 2.5035508767051406

Epoch: 5| Step: 6
Training loss: 2.343766784607868
Validation loss: 2.5048415628647

Epoch: 5| Step: 7
Training loss: 2.3755474463501756
Validation loss: 2.503596754381992

Epoch: 5| Step: 8
Training loss: 2.2229452096190454
Validation loss: 2.515333138983616

Epoch: 5| Step: 9
Training loss: 2.3299198272729846
Validation loss: 2.5260078912947987

Epoch: 5| Step: 10
Training loss: 1.5964193242659557
Validation loss: 2.5328574708260083

Epoch: 5| Step: 11
Training loss: 1.5843136747330968
Validation loss: 2.5752222732176118

Epoch: 298| Step: 0
Training loss: 1.8524776724063143
Validation loss: 2.582699151156784

Epoch: 5| Step: 1
Training loss: 1.8432756233954029
Validation loss: 2.593694728430934

Epoch: 5| Step: 2
Training loss: 2.445517144460721
Validation loss: 2.600006615801488

Epoch: 5| Step: 3
Training loss: 2.457457585788554
Validation loss: 2.6062119742652787

Epoch: 5| Step: 4
Training loss: 2.4941171093865004
Validation loss: 2.592894708032776

Epoch: 5| Step: 5
Training loss: 2.5645145777873517
Validation loss: 2.5691998942446777

Epoch: 5| Step: 6
Training loss: 1.9639745651625917
Validation loss: 2.549077610555501

Epoch: 5| Step: 7
Training loss: 1.5824460839703498
Validation loss: 2.5199777922080666

Epoch: 5| Step: 8
Training loss: 2.306080129099727
Validation loss: 2.52280592519161

Epoch: 5| Step: 9
Training loss: 1.8237632166362014
Validation loss: 2.5195761861416424

Epoch: 5| Step: 10
Training loss: 2.8463846933880714
Validation loss: 2.504439925413766

Epoch: 5| Step: 11
Training loss: 2.305605947819595
Validation loss: 2.497659294755782

Epoch: 299| Step: 0
Training loss: 2.3090109407835646
Validation loss: 2.497988432000982

Epoch: 5| Step: 1
Training loss: 1.9570621328144304
Validation loss: 2.4955620395874902

Epoch: 5| Step: 2
Training loss: 2.310438113260669
Validation loss: 2.4901710891161812

Epoch: 5| Step: 3
Training loss: 2.3889164023576908
Validation loss: 2.517345716641297

Epoch: 5| Step: 4
Training loss: 2.390728917076097
Validation loss: 2.513680830284751

Epoch: 5| Step: 5
Training loss: 2.222089805896411
Validation loss: 2.503276438265473

Epoch: 5| Step: 6
Training loss: 2.1912102977161134
Validation loss: 2.5279805178668697

Epoch: 5| Step: 7
Training loss: 2.118279995170481
Validation loss: 2.531900526370232

Epoch: 5| Step: 8
Training loss: 2.0611107511197324
Validation loss: 2.552118929141142

Epoch: 5| Step: 9
Training loss: 2.57938737885241
Validation loss: 2.570673579987339

Epoch: 5| Step: 10
Training loss: 2.1185983834271207
Validation loss: 2.56096370901615

Epoch: 5| Step: 11
Training loss: 2.8831355216319943
Validation loss: 2.5609166479435217

Epoch: 300| Step: 0
Training loss: 2.1487985758369823
Validation loss: 2.546321297741177

Epoch: 5| Step: 1
Training loss: 2.5380337083410245
Validation loss: 2.541237673097064

Epoch: 5| Step: 2
Training loss: 2.5112217816390427
Validation loss: 2.526163897883444

Epoch: 5| Step: 3
Training loss: 2.5807615727848137
Validation loss: 2.519806429401964

Epoch: 5| Step: 4
Training loss: 2.0236809190124556
Validation loss: 2.493485343006536

Epoch: 5| Step: 5
Training loss: 2.5500079584932487
Validation loss: 2.4957568717881555

Epoch: 5| Step: 6
Training loss: 1.92639107169636
Validation loss: 2.5035774086435145

Epoch: 5| Step: 7
Training loss: 2.2961301049842304
Validation loss: 2.5028255548643563

Epoch: 5| Step: 8
Training loss: 2.139308218151886
Validation loss: 2.5099877918435385

Epoch: 5| Step: 9
Training loss: 2.1061184080768895
Validation loss: 2.510352602150466

Epoch: 5| Step: 10
Training loss: 1.5586514187424028
Validation loss: 2.518706805361283

Epoch: 5| Step: 11
Training loss: 1.9275623310465424
Validation loss: 2.5152407800970367

Epoch: 301| Step: 0
Training loss: 2.594786930781795
Validation loss: 2.5152665587770144

Epoch: 5| Step: 1
Training loss: 2.594222795528903
Validation loss: 2.54547891792869

Epoch: 5| Step: 2
Training loss: 2.1055904770803915
Validation loss: 2.5600628544497135

Epoch: 5| Step: 3
Training loss: 2.0088171912909654
Validation loss: 2.5848905666425

Epoch: 5| Step: 4
Training loss: 2.4470842177003362
Validation loss: 2.579009008570465

Epoch: 5| Step: 5
Training loss: 2.6897997220724146
Validation loss: 2.6120667003950477

Epoch: 5| Step: 6
Training loss: 2.0997768601440105
Validation loss: 2.589637974484584

Epoch: 5| Step: 7
Training loss: 2.101841564156402
Validation loss: 2.5891062289074904

Epoch: 5| Step: 8
Training loss: 1.8458629720588802
Validation loss: 2.5500438650572015

Epoch: 5| Step: 9
Training loss: 1.778781049809909
Validation loss: 2.5530192598806045

Epoch: 5| Step: 10
Training loss: 2.13781074362143
Validation loss: 2.5089133471783556

Epoch: 5| Step: 11
Training loss: 1.5941738986090406
Validation loss: 2.5061474240843675

Epoch: 302| Step: 0
Training loss: 2.4264877199734363
Validation loss: 2.4972315281084145

Epoch: 5| Step: 1
Training loss: 2.329775538786239
Validation loss: 2.5023560151208377

Epoch: 5| Step: 2
Training loss: 1.7843495221832728
Validation loss: 2.5095698655073377

Epoch: 5| Step: 3
Training loss: 2.093867284422045
Validation loss: 2.5149469626795904

Epoch: 5| Step: 4
Training loss: 2.4924846220929084
Validation loss: 2.508837707214236

Epoch: 5| Step: 5
Training loss: 2.7497265419679513
Validation loss: 2.514216611258838

Epoch: 5| Step: 6
Training loss: 2.722333804155464
Validation loss: 2.5154058783527686

Epoch: 5| Step: 7
Training loss: 1.8480218440948772
Validation loss: 2.533380226252333

Epoch: 5| Step: 8
Training loss: 2.4562719290727526
Validation loss: 2.549159505648457

Epoch: 5| Step: 9
Training loss: 1.6547125392096365
Validation loss: 2.561554090631815

Epoch: 5| Step: 10
Training loss: 1.920345535180402
Validation loss: 2.5846586532252904

Epoch: 5| Step: 11
Training loss: 1.3053331890297701
Validation loss: 2.6116893730523536

Epoch: 303| Step: 0
Training loss: 1.4903338037921114
Validation loss: 2.6160738440260207

Epoch: 5| Step: 1
Training loss: 2.0878734962610066
Validation loss: 2.6408635658077655

Epoch: 5| Step: 2
Training loss: 1.9931494690334197
Validation loss: 2.6580876930991897

Epoch: 5| Step: 3
Training loss: 2.534644782104142
Validation loss: 2.6634721446794973

Epoch: 5| Step: 4
Training loss: 2.638229186154603
Validation loss: 2.6354097069709965

Epoch: 5| Step: 5
Training loss: 2.1244466846623618
Validation loss: 2.6230105778428388

Epoch: 5| Step: 6
Training loss: 1.9287469092768927
Validation loss: 2.5932084747692308

Epoch: 5| Step: 7
Training loss: 2.057927235480099
Validation loss: 2.5886424420476923

Epoch: 5| Step: 8
Training loss: 2.6521524576636626
Validation loss: 2.5495321848223664

Epoch: 5| Step: 9
Training loss: 1.7835895499849599
Validation loss: 2.5300228613673723

Epoch: 5| Step: 10
Training loss: 2.798827443518759
Validation loss: 2.5324917482905063

Epoch: 5| Step: 11
Training loss: 2.6435945505744916
Validation loss: 2.5147160651239524

Epoch: 304| Step: 0
Training loss: 2.7235957841076086
Validation loss: 2.514678895636233

Epoch: 5| Step: 1
Training loss: 2.4411365085361583
Validation loss: 2.5425707129075774

Epoch: 5| Step: 2
Training loss: 1.7231208711006694
Validation loss: 2.5388438517009675

Epoch: 5| Step: 3
Training loss: 1.7074429432396696
Validation loss: 2.535149075145786

Epoch: 5| Step: 4
Training loss: 2.666615267099296
Validation loss: 2.54239889577781

Epoch: 5| Step: 5
Training loss: 2.2890871847338503
Validation loss: 2.5470926312722497

Epoch: 5| Step: 6
Training loss: 2.100438381033133
Validation loss: 2.57123982592078

Epoch: 5| Step: 7
Training loss: 2.3579172848016854
Validation loss: 2.551233353791794

Epoch: 5| Step: 8
Training loss: 2.0755564943039646
Validation loss: 2.549863863564773

Epoch: 5| Step: 9
Training loss: 2.38485710099817
Validation loss: 2.522930966412072

Epoch: 5| Step: 10
Training loss: 2.0739378083339224
Validation loss: 2.5328795482021915

Epoch: 5| Step: 11
Training loss: 0.8359076949180559
Validation loss: 2.5243835289963665

Epoch: 305| Step: 0
Training loss: 2.7365398447602494
Validation loss: 2.5122043383466193

Epoch: 5| Step: 1
Training loss: 2.0559681429639936
Validation loss: 2.5241265512588646

Epoch: 5| Step: 2
Training loss: 1.6705948393868169
Validation loss: 2.536566057731023

Epoch: 5| Step: 3
Training loss: 2.2091351498955762
Validation loss: 2.5347863208092236

Epoch: 5| Step: 4
Training loss: 1.4181410839770918
Validation loss: 2.5429286260217894

Epoch: 5| Step: 5
Training loss: 2.4994767595138985
Validation loss: 2.553587327619301

Epoch: 5| Step: 6
Training loss: 1.7729777946049843
Validation loss: 2.53340168931828

Epoch: 5| Step: 7
Training loss: 2.1244777710923977
Validation loss: 2.555512869491072

Epoch: 5| Step: 8
Training loss: 1.9555320250957096
Validation loss: 2.536257363150938

Epoch: 5| Step: 9
Training loss: 2.70459817422609
Validation loss: 2.5427219175366313

Epoch: 5| Step: 10
Training loss: 2.650312182194003
Validation loss: 2.5617131017444477

Epoch: 5| Step: 11
Training loss: 1.9053823654031445
Validation loss: 2.5681244079095267

Epoch: 306| Step: 0
Training loss: 2.22177315651596
Validation loss: 2.5690965375403696

Epoch: 5| Step: 1
Training loss: 1.4787706283717021
Validation loss: 2.5636059653909005

Epoch: 5| Step: 2
Training loss: 2.213063326743609
Validation loss: 2.5520576800140478

Epoch: 5| Step: 3
Training loss: 2.068589555217594
Validation loss: 2.539867281406285

Epoch: 5| Step: 4
Training loss: 2.6631679431359876
Validation loss: 2.5389325935192346

Epoch: 5| Step: 5
Training loss: 1.601369185527286
Validation loss: 2.5498972398335455

Epoch: 5| Step: 6
Training loss: 3.0130146964012607
Validation loss: 2.5741150390850183

Epoch: 5| Step: 7
Training loss: 1.7464129606324335
Validation loss: 2.577694654671735

Epoch: 5| Step: 8
Training loss: 2.147689189637468
Validation loss: 2.5623668310406535

Epoch: 5| Step: 9
Training loss: 1.9028969338350803
Validation loss: 2.5737346952371447

Epoch: 5| Step: 10
Training loss: 2.5444199600689
Validation loss: 2.5901712370692405

Epoch: 5| Step: 11
Training loss: 1.7979530749238968
Validation loss: 2.569333389534213

Epoch: 307| Step: 0
Training loss: 2.3040451965137585
Validation loss: 2.5572585604221656

Epoch: 5| Step: 1
Training loss: 1.9620175369948822
Validation loss: 2.5585004289609445

Epoch: 5| Step: 2
Training loss: 1.9793941434001359
Validation loss: 2.549162751858131

Epoch: 5| Step: 3
Training loss: 2.3205527235837864
Validation loss: 2.5373020250703227

Epoch: 5| Step: 4
Training loss: 2.1975715932803586
Validation loss: 2.542094926764423

Epoch: 5| Step: 5
Training loss: 2.0607708705264995
Validation loss: 2.549818658613921

Epoch: 5| Step: 6
Training loss: 1.9230340083542432
Validation loss: 2.549069459678144

Epoch: 5| Step: 7
Training loss: 2.2084548005100753
Validation loss: 2.537127394168053

Epoch: 5| Step: 8
Training loss: 2.0012317679037546
Validation loss: 2.571769050433643

Epoch: 5| Step: 9
Training loss: 2.1499294579931973
Validation loss: 2.551499616599847

Epoch: 5| Step: 10
Training loss: 2.7162711583036274
Validation loss: 2.5702758948783484

Epoch: 5| Step: 11
Training loss: 1.6702901869051616
Validation loss: 2.6002666808874135

Epoch: 308| Step: 0
Training loss: 2.0956681987202073
Validation loss: 2.6237246238289473

Epoch: 5| Step: 1
Training loss: 1.882323648771801
Validation loss: 2.631124640262551

Epoch: 5| Step: 2
Training loss: 2.483131529355148
Validation loss: 2.6598608905166974

Epoch: 5| Step: 3
Training loss: 1.865820539952259
Validation loss: 2.65970523351274

Epoch: 5| Step: 4
Training loss: 1.9954185463633685
Validation loss: 2.6558431612995372

Epoch: 5| Step: 5
Training loss: 2.728252510158433
Validation loss: 2.6809958071433413

Epoch: 5| Step: 6
Training loss: 1.9127137706687478
Validation loss: 2.6145710482568365

Epoch: 5| Step: 7
Training loss: 2.4058949592536574
Validation loss: 2.6173267080757885

Epoch: 5| Step: 8
Training loss: 2.771838089655251
Validation loss: 2.580358918797989

Epoch: 5| Step: 9
Training loss: 1.9476395748203443
Validation loss: 2.562124759833185

Epoch: 5| Step: 10
Training loss: 1.5953628756259615
Validation loss: 2.534110215446971

Epoch: 5| Step: 11
Training loss: 1.8868896533337693
Validation loss: 2.5257087304587036

Epoch: 309| Step: 0
Training loss: 2.6770068403861282
Validation loss: 2.531478683125757

Epoch: 5| Step: 1
Training loss: 3.0964750368457024
Validation loss: 2.5304115539412027

Epoch: 5| Step: 2
Training loss: 2.185745298430958
Validation loss: 2.5508479819884022

Epoch: 5| Step: 3
Training loss: 1.527651470434752
Validation loss: 2.566567991164061

Epoch: 5| Step: 4
Training loss: 1.9786027473028842
Validation loss: 2.5774835578500093

Epoch: 5| Step: 5
Training loss: 2.1105202285747913
Validation loss: 2.5982300394735773

Epoch: 5| Step: 6
Training loss: 1.9049109461637126
Validation loss: 2.6026934665589283

Epoch: 5| Step: 7
Training loss: 1.8249856451854782
Validation loss: 2.6065547763386996

Epoch: 5| Step: 8
Training loss: 2.229966088623029
Validation loss: 2.6379717903561795

Epoch: 5| Step: 9
Training loss: 2.110100628410366
Validation loss: 2.6669982329013378

Epoch: 5| Step: 10
Training loss: 2.4616852123962603
Validation loss: 2.645031970359111

Epoch: 5| Step: 11
Training loss: 1.7884780395541706
Validation loss: 2.6540078330210655

Epoch: 310| Step: 0
Training loss: 1.999196487189508
Validation loss: 2.6368363493137443

Epoch: 5| Step: 1
Training loss: 1.723160927127826
Validation loss: 2.58095512722524

Epoch: 5| Step: 2
Training loss: 2.134954808849039
Validation loss: 2.574903220607938

Epoch: 5| Step: 3
Training loss: 2.5175592793187676
Validation loss: 2.5596792505226276

Epoch: 5| Step: 4
Training loss: 1.7945970110537712
Validation loss: 2.5551892136922296

Epoch: 5| Step: 5
Training loss: 1.714412417724894
Validation loss: 2.570841194745682

Epoch: 5| Step: 6
Training loss: 2.56423500684885
Validation loss: 2.579320795962278

Epoch: 5| Step: 7
Training loss: 2.4586545012428918
Validation loss: 2.5816581098645797

Epoch: 5| Step: 8
Training loss: 1.7995478115063286
Validation loss: 2.596601003215306

Epoch: 5| Step: 9
Training loss: 2.719466717838472
Validation loss: 2.5768739766900617

Epoch: 5| Step: 10
Training loss: 1.9617608154356534
Validation loss: 2.588465090155613

Epoch: 5| Step: 11
Training loss: 2.9720788863688186
Validation loss: 2.6118985306579825

Epoch: 311| Step: 0
Training loss: 1.833650178695211
Validation loss: 2.61817712625225

Epoch: 5| Step: 1
Training loss: 1.8373850209080766
Validation loss: 2.611468790431795

Epoch: 5| Step: 2
Training loss: 2.6572957392628584
Validation loss: 2.5982139122659462

Epoch: 5| Step: 3
Training loss: 2.352761808739276
Validation loss: 2.611650776527702

Epoch: 5| Step: 4
Training loss: 1.5638640743761556
Validation loss: 2.635104482552997

Epoch: 5| Step: 5
Training loss: 1.8679819372230952
Validation loss: 2.622169929378546

Epoch: 5| Step: 6
Training loss: 2.357950652203892
Validation loss: 2.610905759821271

Epoch: 5| Step: 7
Training loss: 2.3246678022741607
Validation loss: 2.598895037128105

Epoch: 5| Step: 8
Training loss: 2.3930279989999703
Validation loss: 2.580129252795198

Epoch: 5| Step: 9
Training loss: 2.1508564596054893
Validation loss: 2.557948334414977

Epoch: 5| Step: 10
Training loss: 2.328265499509464
Validation loss: 2.5394962840120985

Epoch: 5| Step: 11
Training loss: 1.9528868262982741
Validation loss: 2.5412387422524003

Epoch: 312| Step: 0
Training loss: 2.080080532018854
Validation loss: 2.528529942715219

Epoch: 5| Step: 1
Training loss: 1.7137122103185594
Validation loss: 2.5323030337904076

Epoch: 5| Step: 2
Training loss: 2.0720813032864323
Validation loss: 2.5277749410608696

Epoch: 5| Step: 3
Training loss: 2.241211788534697
Validation loss: 2.525654455704019

Epoch: 5| Step: 4
Training loss: 2.051663919049842
Validation loss: 2.5380522924005637

Epoch: 5| Step: 5
Training loss: 2.744184587336909
Validation loss: 2.5324191976298995

Epoch: 5| Step: 6
Training loss: 1.9920915767539278
Validation loss: 2.5483233150470705

Epoch: 5| Step: 7
Training loss: 2.850862767315608
Validation loss: 2.547035260999335

Epoch: 5| Step: 8
Training loss: 1.985507611823303
Validation loss: 2.586356909815977

Epoch: 5| Step: 9
Training loss: 1.4372005150677007
Validation loss: 2.6115126467335315

Epoch: 5| Step: 10
Training loss: 2.228541515310277
Validation loss: 2.622546279112202

Epoch: 5| Step: 11
Training loss: 2.1165626420218557
Validation loss: 2.6674721787708107

Epoch: 313| Step: 0
Training loss: 2.735839015859124
Validation loss: 2.6394060432631314

Epoch: 5| Step: 1
Training loss: 1.8805177245599238
Validation loss: 2.612277919358814

Epoch: 5| Step: 2
Training loss: 2.2584033443770744
Validation loss: 2.576822853698781

Epoch: 5| Step: 3
Training loss: 1.7003617574956689
Validation loss: 2.5408187426353224

Epoch: 5| Step: 4
Training loss: 1.8820792388815177
Validation loss: 2.526382662511065

Epoch: 5| Step: 5
Training loss: 1.927358356817876
Validation loss: 2.5296585708104415

Epoch: 5| Step: 6
Training loss: 2.688317906319078
Validation loss: 2.521348689077997

Epoch: 5| Step: 7
Training loss: 2.2393973931298325
Validation loss: 2.5150654705612716

Epoch: 5| Step: 8
Training loss: 1.981458066971641
Validation loss: 2.533471274907765

Epoch: 5| Step: 9
Training loss: 2.8977921993713256
Validation loss: 2.525248154478674

Epoch: 5| Step: 10
Training loss: 2.2046412667902175
Validation loss: 2.537606022096572

Epoch: 5| Step: 11
Training loss: 1.2739846861830668
Validation loss: 2.540749940853862

Epoch: 314| Step: 0
Training loss: 2.4563012425947592
Validation loss: 2.556808062093469

Epoch: 5| Step: 1
Training loss: 1.7948251725174638
Validation loss: 2.559705319046654

Epoch: 5| Step: 2
Training loss: 1.8267252201014357
Validation loss: 2.559351894660961

Epoch: 5| Step: 3
Training loss: 1.9812005551302567
Validation loss: 2.5856938665124964

Epoch: 5| Step: 4
Training loss: 2.157501631434455
Validation loss: 2.5691234230570332

Epoch: 5| Step: 5
Training loss: 1.7794204149791664
Validation loss: 2.5803533306712794

Epoch: 5| Step: 6
Training loss: 2.745093129424772
Validation loss: 2.5908627392165613

Epoch: 5| Step: 7
Training loss: 1.9218319523650094
Validation loss: 2.5937071455820147

Epoch: 5| Step: 8
Training loss: 1.867215463596501
Validation loss: 2.592400943031006

Epoch: 5| Step: 9
Training loss: 2.739818364687388
Validation loss: 2.575479151610591

Epoch: 5| Step: 10
Training loss: 2.4205616004573995
Validation loss: 2.606512841342867

Epoch: 5| Step: 11
Training loss: 1.3361366078981278
Validation loss: 2.5775119784792464

Epoch: 315| Step: 0
Training loss: 2.1539045099328185
Validation loss: 2.5847765841556085

Epoch: 5| Step: 1
Training loss: 2.0252425342888865
Validation loss: 2.609762589380038

Epoch: 5| Step: 2
Training loss: 2.2968808128646683
Validation loss: 2.6220147021012634

Epoch: 5| Step: 3
Training loss: 2.2165189459584975
Validation loss: 2.6095682708372125

Epoch: 5| Step: 4
Training loss: 1.4262689461816243
Validation loss: 2.629107610691165

Epoch: 5| Step: 5
Training loss: 2.4120301021260104
Validation loss: 2.6224603629230585

Epoch: 5| Step: 6
Training loss: 2.5671634573109547
Validation loss: 2.6555491289478232

Epoch: 5| Step: 7
Training loss: 1.8140329915488005
Validation loss: 2.6488469125283642

Epoch: 5| Step: 8
Training loss: 2.603254071867614
Validation loss: 2.6369420500967387

Epoch: 5| Step: 9
Training loss: 2.11377432495053
Validation loss: 2.6067659998546278

Epoch: 5| Step: 10
Training loss: 1.8830865051204104
Validation loss: 2.596069325414362

Epoch: 5| Step: 11
Training loss: 1.4181804236269588
Validation loss: 2.561200417131303

Epoch: 316| Step: 0
Training loss: 2.0431380776132375
Validation loss: 2.5760134903019454

Epoch: 5| Step: 1
Training loss: 2.3569562020648895
Validation loss: 2.5740605152760496

Epoch: 5| Step: 2
Training loss: 2.1989166973827836
Validation loss: 2.5743488130335797

Epoch: 5| Step: 3
Training loss: 2.2809453264345985
Validation loss: 2.5642737824406163

Epoch: 5| Step: 4
Training loss: 2.201634545430022
Validation loss: 2.568747123970346

Epoch: 5| Step: 5
Training loss: 2.505927973200039
Validation loss: 2.574608031936054

Epoch: 5| Step: 6
Training loss: 2.1237444815022313
Validation loss: 2.5945322913742386

Epoch: 5| Step: 7
Training loss: 1.499035604719554
Validation loss: 2.5958540743146674

Epoch: 5| Step: 8
Training loss: 1.8797665726034753
Validation loss: 2.5730407636010155

Epoch: 5| Step: 9
Training loss: 2.4679003834953397
Validation loss: 2.5914411149714263

Epoch: 5| Step: 10
Training loss: 1.7367217537068464
Validation loss: 2.5936714413247626

Epoch: 5| Step: 11
Training loss: 3.011517350999508
Validation loss: 2.590389886486224

Epoch: 317| Step: 0
Training loss: 2.1550594857982697
Validation loss: 2.5915845617758766

Epoch: 5| Step: 1
Training loss: 2.2014985269493494
Validation loss: 2.582568341219048

Epoch: 5| Step: 2
Training loss: 1.9463923264674812
Validation loss: 2.5967612500607946

Epoch: 5| Step: 3
Training loss: 2.3743650691946097
Validation loss: 2.594593225091379

Epoch: 5| Step: 4
Training loss: 1.9932287150564314
Validation loss: 2.6005501939850535

Epoch: 5| Step: 5
Training loss: 2.636536180745326
Validation loss: 2.570220733055681

Epoch: 5| Step: 6
Training loss: 1.9696375344941535
Validation loss: 2.54781392309582

Epoch: 5| Step: 7
Training loss: 2.0401872477893983
Validation loss: 2.565560343241677

Epoch: 5| Step: 8
Training loss: 2.2740496568315827
Validation loss: 2.5626401281422444

Epoch: 5| Step: 9
Training loss: 1.889089291668923
Validation loss: 2.557734361129645

Epoch: 5| Step: 10
Training loss: 2.0438125647438143
Validation loss: 2.5623542154912844

Epoch: 5| Step: 11
Training loss: 2.1351768048801354
Validation loss: 2.591395243745067

Epoch: 318| Step: 0
Training loss: 2.5961270757528476
Validation loss: 2.5941951898190703

Epoch: 5| Step: 1
Training loss: 2.3231029236252327
Validation loss: 2.6055699623805855

Epoch: 5| Step: 2
Training loss: 2.3011572745900444
Validation loss: 2.650448559788699

Epoch: 5| Step: 3
Training loss: 1.592464002983917
Validation loss: 2.6297184226654

Epoch: 5| Step: 4
Training loss: 2.1651546875840055
Validation loss: 2.618431437166246

Epoch: 5| Step: 5
Training loss: 2.3827292505949194
Validation loss: 2.603613845639891

Epoch: 5| Step: 6
Training loss: 2.2075127810565065
Validation loss: 2.5960377864218325

Epoch: 5| Step: 7
Training loss: 1.9017868323421965
Validation loss: 2.5639803456177033

Epoch: 5| Step: 8
Training loss: 2.011424100463716
Validation loss: 2.584393615686362

Epoch: 5| Step: 9
Training loss: 2.1459069347412996
Validation loss: 2.5959011850985187

Epoch: 5| Step: 10
Training loss: 2.1262237166855225
Validation loss: 2.5925184259768415

Epoch: 5| Step: 11
Training loss: 1.2678427397986343
Validation loss: 2.581354596017753

Epoch: 319| Step: 0
Training loss: 2.090476366356113
Validation loss: 2.5851522215658775

Epoch: 5| Step: 1
Training loss: 2.313213959874381
Validation loss: 2.6021722836914436

Epoch: 5| Step: 2
Training loss: 1.979198040629892
Validation loss: 2.60499681338349

Epoch: 5| Step: 3
Training loss: 1.2891320412113472
Validation loss: 2.6125279715590506

Epoch: 5| Step: 4
Training loss: 2.602942939610643
Validation loss: 2.5968894955031203

Epoch: 5| Step: 5
Training loss: 1.6483699549716893
Validation loss: 2.588721631098973

Epoch: 5| Step: 6
Training loss: 2.134191158302602
Validation loss: 2.569936471659807

Epoch: 5| Step: 7
Training loss: 2.0897431251329737
Validation loss: 2.5750893879779317

Epoch: 5| Step: 8
Training loss: 2.3490878546644196
Validation loss: 2.567482868120089

Epoch: 5| Step: 9
Training loss: 2.3452495609710415
Validation loss: 2.567404362764743

Epoch: 5| Step: 10
Training loss: 2.2900316705970787
Validation loss: 2.5437394013055172

Epoch: 5| Step: 11
Training loss: 2.4204518720715456
Validation loss: 2.5842955755831722

Epoch: 320| Step: 0
Training loss: 1.6618139988440794
Validation loss: 2.5670681723508304

Epoch: 5| Step: 1
Training loss: 1.9163280547308148
Validation loss: 2.60557152937629

Epoch: 5| Step: 2
Training loss: 1.9800985317567124
Validation loss: 2.564215527791

Epoch: 5| Step: 3
Training loss: 2.4889670105246435
Validation loss: 2.593856529744493

Epoch: 5| Step: 4
Training loss: 2.2727641258719715
Validation loss: 2.5856879806378568

Epoch: 5| Step: 5
Training loss: 2.22239149826434
Validation loss: 2.5664700481317637

Epoch: 5| Step: 6
Training loss: 1.600877717789736
Validation loss: 2.5437686441474017

Epoch: 5| Step: 7
Training loss: 2.6811004561400353
Validation loss: 2.5510849491984007

Epoch: 5| Step: 8
Training loss: 2.36434614921713
Validation loss: 2.5298760221157486

Epoch: 5| Step: 9
Training loss: 2.1905777124805463
Validation loss: 2.5313241932046475

Epoch: 5| Step: 10
Training loss: 2.2678461171108535
Validation loss: 2.5603427684374016

Epoch: 5| Step: 11
Training loss: 2.076788910175803
Validation loss: 2.5659486739151074

Epoch: 321| Step: 0
Training loss: 1.9898544712624033
Validation loss: 2.627376612074829

Epoch: 5| Step: 1
Training loss: 2.1000825002904344
Validation loss: 2.680407858245607

Epoch: 5| Step: 2
Training loss: 1.9977629787084104
Validation loss: 2.7127861733373617

Epoch: 5| Step: 3
Training loss: 1.8660330295849084
Validation loss: 2.7244796047503255

Epoch: 5| Step: 4
Training loss: 2.2070635497843885
Validation loss: 2.69277104883311

Epoch: 5| Step: 5
Training loss: 2.567389777323902
Validation loss: 2.6549622387364886

Epoch: 5| Step: 6
Training loss: 2.218914401988515
Validation loss: 2.607806234807434

Epoch: 5| Step: 7
Training loss: 2.3698183051208566
Validation loss: 2.567267332965966

Epoch: 5| Step: 8
Training loss: 1.9892720749596098
Validation loss: 2.539970855598877

Epoch: 5| Step: 9
Training loss: 1.7474428294684614
Validation loss: 2.544141080209957

Epoch: 5| Step: 10
Training loss: 2.6830980489973615
Validation loss: 2.5445737525014582

Epoch: 5| Step: 11
Training loss: 3.2784817598762555
Validation loss: 2.5308467480987784

Epoch: 322| Step: 0
Training loss: 2.341641914897532
Validation loss: 2.540706268721809

Epoch: 5| Step: 1
Training loss: 2.5021553285411704
Validation loss: 2.541709947738685

Epoch: 5| Step: 2
Training loss: 2.1928026506763514
Validation loss: 2.5627294530717477

Epoch: 5| Step: 3
Training loss: 1.8541116670602213
Validation loss: 2.5863525426346037

Epoch: 5| Step: 4
Training loss: 2.2421400749693787
Validation loss: 2.5839426773024714

Epoch: 5| Step: 5
Training loss: 1.6356336688583428
Validation loss: 2.593616574084317

Epoch: 5| Step: 6
Training loss: 1.927785453390231
Validation loss: 2.5728743288415235

Epoch: 5| Step: 7
Training loss: 2.390598670964082
Validation loss: 2.5761048426570246

Epoch: 5| Step: 8
Training loss: 2.547480318182478
Validation loss: 2.5767671380825687

Epoch: 5| Step: 9
Training loss: 1.682870802582181
Validation loss: 2.574202410617621

Epoch: 5| Step: 10
Training loss: 2.286813092932887
Validation loss: 2.5629176985676

Epoch: 5| Step: 11
Training loss: 1.5201742581816196
Validation loss: 2.5448290402237568

Epoch: 323| Step: 0
Training loss: 2.3377907842416117
Validation loss: 2.5418363394672463

Epoch: 5| Step: 1
Training loss: 1.9461658245447577
Validation loss: 2.551819458119662

Epoch: 5| Step: 2
Training loss: 1.9486049993081864
Validation loss: 2.5434670572906537

Epoch: 5| Step: 3
Training loss: 2.363308892206626
Validation loss: 2.5364517483374454

Epoch: 5| Step: 4
Training loss: 2.5070903368127158
Validation loss: 2.553311748437266

Epoch: 5| Step: 5
Training loss: 2.279650924629752
Validation loss: 2.5578251817591213

Epoch: 5| Step: 6
Training loss: 2.206385695307214
Validation loss: 2.5682154877442205

Epoch: 5| Step: 7
Training loss: 2.2396123366732694
Validation loss: 2.564875420506432

Epoch: 5| Step: 8
Training loss: 1.6417277671687593
Validation loss: 2.59141174689971

Epoch: 5| Step: 9
Training loss: 2.329573519890801
Validation loss: 2.609683111886993

Epoch: 5| Step: 10
Training loss: 1.3751367587656629
Validation loss: 2.671889842328643

Epoch: 5| Step: 11
Training loss: 1.6457797496458881
Validation loss: 2.6616307157366936

Epoch: 324| Step: 0
Training loss: 2.100409890090594
Validation loss: 2.6846026468023836

Epoch: 5| Step: 1
Training loss: 2.632152621832857
Validation loss: 2.68178987099316

Epoch: 5| Step: 2
Training loss: 2.568741802564475
Validation loss: 2.627363321830908

Epoch: 5| Step: 3
Training loss: 2.2410768955014224
Validation loss: 2.586225768249724

Epoch: 5| Step: 4
Training loss: 2.5469783457751767
Validation loss: 2.5477502348735688

Epoch: 5| Step: 5
Training loss: 1.1549215675740148
Validation loss: 2.5345763614497407

Epoch: 5| Step: 6
Training loss: 1.8122167694838245
Validation loss: 2.5214160227357176

Epoch: 5| Step: 7
Training loss: 2.4679013495737685
Validation loss: 2.5163573666056234

Epoch: 5| Step: 8
Training loss: 1.9855519206305468
Validation loss: 2.5125349863188062

Epoch: 5| Step: 9
Training loss: 2.8544637892018785
Validation loss: 2.510711752826891

Epoch: 5| Step: 10
Training loss: 1.5116299546454794
Validation loss: 2.5181547125638795

Epoch: 5| Step: 11
Training loss: 1.593986942405299
Validation loss: 2.520262509075087

Epoch: 325| Step: 0
Training loss: 2.15067377400431
Validation loss: 2.545602027876204

Epoch: 5| Step: 1
Training loss: 1.5056213903324471
Validation loss: 2.5574133326741904

Epoch: 5| Step: 2
Training loss: 2.945032404930185
Validation loss: 2.5897924572529134

Epoch: 5| Step: 3
Training loss: 2.104461372309196
Validation loss: 2.592884332903872

Epoch: 5| Step: 4
Training loss: 2.1113368200922364
Validation loss: 2.5891862421080516

Epoch: 5| Step: 5
Training loss: 2.318048779347108
Validation loss: 2.5866429921444056

Epoch: 5| Step: 6
Training loss: 2.197390621444647
Validation loss: 2.6062137352717287

Epoch: 5| Step: 7
Training loss: 2.201535023178707
Validation loss: 2.6014332247548033

Epoch: 5| Step: 8
Training loss: 1.895747850048884
Validation loss: 2.615349328095564

Epoch: 5| Step: 9
Training loss: 2.184794905964386
Validation loss: 2.5954084130986415

Epoch: 5| Step: 10
Training loss: 1.375900450551411
Validation loss: 2.6106415261806517

Epoch: 5| Step: 11
Training loss: 1.5872100084619911
Validation loss: 2.6203126079731422

Epoch: 326| Step: 0
Training loss: 1.9051576830466628
Validation loss: 2.576548207838873

Epoch: 5| Step: 1
Training loss: 2.406027350095073
Validation loss: 2.568609015222584

Epoch: 5| Step: 2
Training loss: 2.1673478620697937
Validation loss: 2.553042361362874

Epoch: 5| Step: 3
Training loss: 2.858686520597681
Validation loss: 2.582821169710003

Epoch: 5| Step: 4
Training loss: 1.8902496721973496
Validation loss: 2.586213372796087

Epoch: 5| Step: 5
Training loss: 1.3175044247518575
Validation loss: 2.5777914351639564

Epoch: 5| Step: 6
Training loss: 1.490434345712482
Validation loss: 2.577248287446926

Epoch: 5| Step: 7
Training loss: 1.9195817741231491
Validation loss: 2.6034948334337087

Epoch: 5| Step: 8
Training loss: 2.3750475828523916
Validation loss: 2.5862506665302227

Epoch: 5| Step: 9
Training loss: 1.7494582291266587
Validation loss: 2.5970342058635016

Epoch: 5| Step: 10
Training loss: 2.3645834117558895
Validation loss: 2.60457357787927

Epoch: 5| Step: 11
Training loss: 3.4497111434534053
Validation loss: 2.584501653456102

Epoch: 327| Step: 0
Training loss: 2.32962684066265
Validation loss: 2.583394251125681

Epoch: 5| Step: 1
Training loss: 2.102064335122534
Validation loss: 2.5672780283133023

Epoch: 5| Step: 2
Training loss: 2.610203228927064
Validation loss: 2.5450768549218514

Epoch: 5| Step: 3
Training loss: 2.44868290589713
Validation loss: 2.519764493648825

Epoch: 5| Step: 4
Training loss: 1.7785021014990736
Validation loss: 2.549181258681618

Epoch: 5| Step: 5
Training loss: 1.7645533862794844
Validation loss: 2.5598194438186526

Epoch: 5| Step: 6
Training loss: 2.088082571457803
Validation loss: 2.5596986282672423

Epoch: 5| Step: 7
Training loss: 1.633773593863562
Validation loss: 2.558751042702342

Epoch: 5| Step: 8
Training loss: 2.240693448562772
Validation loss: 2.5722692359738697

Epoch: 5| Step: 9
Training loss: 2.0304682474403597
Validation loss: 2.5731818928612653

Epoch: 5| Step: 10
Training loss: 2.0849792336726503
Validation loss: 2.5902514666589456

Epoch: 5| Step: 11
Training loss: 0.7413653588550055
Validation loss: 2.611968782403651

Epoch: 328| Step: 0
Training loss: 1.6334995120362767
Validation loss: 2.619332382612751

Epoch: 5| Step: 1
Training loss: 2.729198242082495
Validation loss: 2.605590855579163

Epoch: 5| Step: 2
Training loss: 1.9446420395073891
Validation loss: 2.6103191342797176

Epoch: 5| Step: 3
Training loss: 1.9809835694049047
Validation loss: 2.6124290061199376

Epoch: 5| Step: 4
Training loss: 1.6067718637752681
Validation loss: 2.6281281822387927

Epoch: 5| Step: 5
Training loss: 2.0272322607530904
Validation loss: 2.605060438640543

Epoch: 5| Step: 6
Training loss: 1.7940095693743425
Validation loss: 2.6096671049435445

Epoch: 5| Step: 7
Training loss: 1.5992493835705643
Validation loss: 2.574241730698856

Epoch: 5| Step: 8
Training loss: 2.061788147123012
Validation loss: 2.5579923238365696

Epoch: 5| Step: 9
Training loss: 3.2540167415401586
Validation loss: 2.5697800182320263

Epoch: 5| Step: 10
Training loss: 2.076363412055052
Validation loss: 2.530087188222308

Epoch: 5| Step: 11
Training loss: 1.2543419767175394
Validation loss: 2.553587922828342

Epoch: 329| Step: 0
Training loss: 2.3335643949089486
Validation loss: 2.540557745793721

Epoch: 5| Step: 1
Training loss: 2.1546684767759543
Validation loss: 2.5604496832431947

Epoch: 5| Step: 2
Training loss: 1.8478245083931426
Validation loss: 2.563521154591075

Epoch: 5| Step: 3
Training loss: 2.4424792563925113
Validation loss: 2.57123463330756

Epoch: 5| Step: 4
Training loss: 1.9563872901589447
Validation loss: 2.5776516161873118

Epoch: 5| Step: 5
Training loss: 2.1032979953576216
Validation loss: 2.612556976780008

Epoch: 5| Step: 6
Training loss: 1.5851268481690597
Validation loss: 2.6479537507068294

Epoch: 5| Step: 7
Training loss: 1.644294993630179
Validation loss: 2.6487933569650006

Epoch: 5| Step: 8
Training loss: 2.39816889050892
Validation loss: 2.585888792042151

Epoch: 5| Step: 9
Training loss: 2.2624317685792885
Validation loss: 2.6044662296931134

Epoch: 5| Step: 10
Training loss: 2.233374098030908
Validation loss: 2.57394998601293

Epoch: 5| Step: 11
Training loss: 1.3982349867141768
Validation loss: 2.5752408512213307

Epoch: 330| Step: 0
Training loss: 2.5822927368539363
Validation loss: 2.5287385302183107

Epoch: 5| Step: 1
Training loss: 1.7523701829485567
Validation loss: 2.5476414476994247

Epoch: 5| Step: 2
Training loss: 1.6627047735317209
Validation loss: 2.5172927138292094

Epoch: 5| Step: 3
Training loss: 2.3868116494936693
Validation loss: 2.5213537007498013

Epoch: 5| Step: 4
Training loss: 2.3555152091383698
Validation loss: 2.5396791227789346

Epoch: 5| Step: 5
Training loss: 2.029295230163554
Validation loss: 2.569989834430148

Epoch: 5| Step: 6
Training loss: 1.8605520545876162
Validation loss: 2.5861968172633314

Epoch: 5| Step: 7
Training loss: 2.0145921056714897
Validation loss: 2.615733009153159

Epoch: 5| Step: 8
Training loss: 2.1235547480377845
Validation loss: 2.6226954675673455

Epoch: 5| Step: 9
Training loss: 2.113304941887182
Validation loss: 2.598158108602223

Epoch: 5| Step: 10
Training loss: 2.4442899961036724
Validation loss: 2.6235423582295176

Epoch: 5| Step: 11
Training loss: 1.0664201113739702
Validation loss: 2.6122397004121996

Epoch: 331| Step: 0
Training loss: 2.0469220570986364
Validation loss: 2.5852857615497884

Epoch: 5| Step: 1
Training loss: 2.091658045331759
Validation loss: 2.5576022180345186

Epoch: 5| Step: 2
Training loss: 2.563973910087403
Validation loss: 2.5433724195790006

Epoch: 5| Step: 3
Training loss: 1.9945553339973292
Validation loss: 2.5582899384023032

Epoch: 5| Step: 4
Training loss: 1.6620016455338062
Validation loss: 2.561805214159028

Epoch: 5| Step: 5
Training loss: 2.1812924181467177
Validation loss: 2.5572897735609414

Epoch: 5| Step: 6
Training loss: 2.0020489925597773
Validation loss: 2.5944761002937615

Epoch: 5| Step: 7
Training loss: 2.705155420404022
Validation loss: 2.59303552676244

Epoch: 5| Step: 8
Training loss: 1.675913701013823
Validation loss: 2.611110342450626

Epoch: 5| Step: 9
Training loss: 2.115493603546347
Validation loss: 2.6633817095584367

Epoch: 5| Step: 10
Training loss: 1.9222870051701364
Validation loss: 2.6203505954388167

Epoch: 5| Step: 11
Training loss: 2.4689558884923986
Validation loss: 2.6313449002849234

Epoch: 332| Step: 0
Training loss: 2.5861006855256563
Validation loss: 2.6066971551554423

Epoch: 5| Step: 1
Training loss: 2.19757441406631
Validation loss: 2.586438436863103

Epoch: 5| Step: 2
Training loss: 1.9061504400550524
Validation loss: 2.5701386181300023

Epoch: 5| Step: 3
Training loss: 2.319468643407417
Validation loss: 2.543741295383316

Epoch: 5| Step: 4
Training loss: 2.2741019729725807
Validation loss: 2.540623626067356

Epoch: 5| Step: 5
Training loss: 2.4342855140780615
Validation loss: 2.5340863690255913

Epoch: 5| Step: 6
Training loss: 1.829481159827345
Validation loss: 2.5382007212343085

Epoch: 5| Step: 7
Training loss: 1.7007357435748995
Validation loss: 2.548494077889039

Epoch: 5| Step: 8
Training loss: 2.4434255321154463
Validation loss: 2.5752815074959026

Epoch: 5| Step: 9
Training loss: 1.6605451779030451
Validation loss: 2.609249226171531

Epoch: 5| Step: 10
Training loss: 1.619681384225759
Validation loss: 2.6361543668316223

Epoch: 5| Step: 11
Training loss: 2.138705876049642
Validation loss: 2.6500695187968804

Epoch: 333| Step: 0
Training loss: 1.9100198209443133
Validation loss: 2.6620893955763734

Epoch: 5| Step: 1
Training loss: 2.022377944488617
Validation loss: 2.645151438413039

Epoch: 5| Step: 2
Training loss: 1.7819556461470092
Validation loss: 2.6015227413098754

Epoch: 5| Step: 3
Training loss: 2.222292583729189
Validation loss: 2.545977814742533

Epoch: 5| Step: 4
Training loss: 2.6888748023642357
Validation loss: 2.5568681561759115

Epoch: 5| Step: 5
Training loss: 2.3204788508011402
Validation loss: 2.5257783588676452

Epoch: 5| Step: 6
Training loss: 1.599835315812139
Validation loss: 2.522312783677775

Epoch: 5| Step: 7
Training loss: 2.0998186441858397
Validation loss: 2.527687519087037

Epoch: 5| Step: 8
Training loss: 2.2462064764511465
Validation loss: 2.5209839292473255

Epoch: 5| Step: 9
Training loss: 2.582036974925102
Validation loss: 2.5436546935801694

Epoch: 5| Step: 10
Training loss: 1.747552113335812
Validation loss: 2.562235535566331

Epoch: 5| Step: 11
Training loss: 1.8042628461590027
Validation loss: 2.5820383061222647

Epoch: 334| Step: 0
Training loss: 1.8375524682060194
Validation loss: 2.584419315762327

Epoch: 5| Step: 1
Training loss: 2.189790561886122
Validation loss: 2.6070820790595137

Epoch: 5| Step: 2
Training loss: 2.433016933703652
Validation loss: 2.618305407850106

Epoch: 5| Step: 3
Training loss: 2.131752057943853
Validation loss: 2.6376050500303445

Epoch: 5| Step: 4
Training loss: 2.4813818985403695
Validation loss: 2.6307731223463704

Epoch: 5| Step: 5
Training loss: 1.7997777298281248
Validation loss: 2.5945923980763643

Epoch: 5| Step: 6
Training loss: 2.0423799034492647
Validation loss: 2.5628400670003817

Epoch: 5| Step: 7
Training loss: 1.6216643650526055
Validation loss: 2.55276813402062

Epoch: 5| Step: 8
Training loss: 1.542604813932912
Validation loss: 2.5647884013176068

Epoch: 5| Step: 9
Training loss: 1.9881896351989905
Validation loss: 2.5457535441413692

Epoch: 5| Step: 10
Training loss: 2.640511865844532
Validation loss: 2.5407353881215085

Epoch: 5| Step: 11
Training loss: 2.2952059955440167
Validation loss: 2.523699346288782

Epoch: 335| Step: 0
Training loss: 2.3423254134054807
Validation loss: 2.5289837656916676

Epoch: 5| Step: 1
Training loss: 1.5812882550704597
Validation loss: 2.5409503315564193

Epoch: 5| Step: 2
Training loss: 2.26562699942665
Validation loss: 2.549026023616545

Epoch: 5| Step: 3
Training loss: 1.963393053119109
Validation loss: 2.557071805827195

Epoch: 5| Step: 4
Training loss: 2.3399120187114
Validation loss: 2.616465902725822

Epoch: 5| Step: 5
Training loss: 2.140547256728656
Validation loss: 2.6553598670225975

Epoch: 5| Step: 6
Training loss: 1.5828399475067647
Validation loss: 2.655049333167932

Epoch: 5| Step: 7
Training loss: 1.4810769635949628
Validation loss: 2.61509420082388

Epoch: 5| Step: 8
Training loss: 2.2297385602209143
Validation loss: 2.598281402701057

Epoch: 5| Step: 9
Training loss: 2.1817060851792465
Validation loss: 2.588767881634063

Epoch: 5| Step: 10
Training loss: 2.262052046968814
Validation loss: 2.576761181698873

Epoch: 5| Step: 11
Training loss: 3.822737409804823
Validation loss: 2.5940872379127233

Epoch: 336| Step: 0
Training loss: 2.3918192753855707
Validation loss: 2.579931939888273

Epoch: 5| Step: 1
Training loss: 2.299829671606595
Validation loss: 2.580259988108854

Epoch: 5| Step: 2
Training loss: 2.051622548789771
Validation loss: 2.581115664203133

Epoch: 5| Step: 3
Training loss: 1.7696665192158094
Validation loss: 2.578212372426394

Epoch: 5| Step: 4
Training loss: 1.7195002218980082
Validation loss: 2.5508483597484095

Epoch: 5| Step: 5
Training loss: 1.9845856682395722
Validation loss: 2.5606205684979506

Epoch: 5| Step: 6
Training loss: 2.4293423619100807
Validation loss: 2.549378555125789

Epoch: 5| Step: 7
Training loss: 2.010092661415589
Validation loss: 2.567807516125915

Epoch: 5| Step: 8
Training loss: 1.810776845077567
Validation loss: 2.5805226861527752

Epoch: 5| Step: 9
Training loss: 2.3542526927072602
Validation loss: 2.626727939488509

Epoch: 5| Step: 10
Training loss: 2.226026503981802
Validation loss: 2.636713211618894

Epoch: 5| Step: 11
Training loss: 1.4898545967431336
Validation loss: 2.6610048707776253

Epoch: 337| Step: 0
Training loss: 1.8597325854700801
Validation loss: 2.6526940647673127

Epoch: 5| Step: 1
Training loss: 1.7939891695612127
Validation loss: 2.6182843087857957

Epoch: 5| Step: 2
Training loss: 1.5837916246347123
Validation loss: 2.5983848716313545

Epoch: 5| Step: 3
Training loss: 2.0670430404692457
Validation loss: 2.5734739562345412

Epoch: 5| Step: 4
Training loss: 2.392692320297747
Validation loss: 2.54521959329224

Epoch: 5| Step: 5
Training loss: 2.216138350357948
Validation loss: 2.553499733121315

Epoch: 5| Step: 6
Training loss: 2.3642732414110874
Validation loss: 2.576719527108454

Epoch: 5| Step: 7
Training loss: 2.2099933023480727
Validation loss: 2.6038777013038303

Epoch: 5| Step: 8
Training loss: 1.7131702364516261
Validation loss: 2.57188890498973

Epoch: 5| Step: 9
Training loss: 1.946902196213537
Validation loss: 2.5758089393621533

Epoch: 5| Step: 10
Training loss: 2.8110820162712025
Validation loss: 2.5793271643156976

Epoch: 5| Step: 11
Training loss: 1.2293068865091712
Validation loss: 2.584915746801349

Epoch: 338| Step: 0
Training loss: 2.323253270780625
Validation loss: 2.5689148586241792

Epoch: 5| Step: 1
Training loss: 2.0497253606166552
Validation loss: 2.5454532715500857

Epoch: 5| Step: 2
Training loss: 1.4486837299188753
Validation loss: 2.5374556009827485

Epoch: 5| Step: 3
Training loss: 2.1735105873834657
Validation loss: 2.5275894784543174

Epoch: 5| Step: 4
Training loss: 2.4007817346266394
Validation loss: 2.5319140038224295

Epoch: 5| Step: 5
Training loss: 2.0518472861708306
Validation loss: 2.5199646648447556

Epoch: 5| Step: 6
Training loss: 1.9668883952995933
Validation loss: 2.5364727878876723

Epoch: 5| Step: 7
Training loss: 2.191993457909727
Validation loss: 2.5218689908598537

Epoch: 5| Step: 8
Training loss: 2.178579725745524
Validation loss: 2.5244673132429583

Epoch: 5| Step: 9
Training loss: 1.9244819885425932
Validation loss: 2.526698148440283

Epoch: 5| Step: 10
Training loss: 1.9031550813749856
Validation loss: 2.555451787233203

Epoch: 5| Step: 11
Training loss: 2.5142003165642
Validation loss: 2.566794922930058

Epoch: 339| Step: 0
Training loss: 2.5077134347523447
Validation loss: 2.5801983251109326

Epoch: 5| Step: 1
Training loss: 2.0150015406448873
Validation loss: 2.5717743617129174

Epoch: 5| Step: 2
Training loss: 1.6036136797012477
Validation loss: 2.5516416063600085

Epoch: 5| Step: 3
Training loss: 2.2865703674072617
Validation loss: 2.5621064705785463

Epoch: 5| Step: 4
Training loss: 1.802719430251908
Validation loss: 2.5382908083680067

Epoch: 5| Step: 5
Training loss: 1.7627158039624369
Validation loss: 2.595521318217436

Epoch: 5| Step: 6
Training loss: 2.437984614003726
Validation loss: 2.5879991923657197

Epoch: 5| Step: 7
Training loss: 2.135760160282459
Validation loss: 2.611846571827916

Epoch: 5| Step: 8
Training loss: 1.8327215720123473
Validation loss: 2.6121261507148508

Epoch: 5| Step: 9
Training loss: 1.7242281223417468
Validation loss: 2.609858165482591

Epoch: 5| Step: 10
Training loss: 2.4288409067556462
Validation loss: 2.6273781093498734

Epoch: 5| Step: 11
Training loss: 1.9371405237258572
Validation loss: 2.5847268857873433

Epoch: 340| Step: 0
Training loss: 2.9292183869210517
Validation loss: 2.6122008838410333

Epoch: 5| Step: 1
Training loss: 2.0117285867098706
Validation loss: 2.5799508671031184

Epoch: 5| Step: 2
Training loss: 2.5044971072438615
Validation loss: 2.578710250702233

Epoch: 5| Step: 3
Training loss: 1.7304705410984664
Validation loss: 2.5693189871004285

Epoch: 5| Step: 4
Training loss: 2.1299662059914874
Validation loss: 2.5734087760417017

Epoch: 5| Step: 5
Training loss: 1.8168963683728283
Validation loss: 2.583295142496488

Epoch: 5| Step: 6
Training loss: 2.1569811921906865
Validation loss: 2.5780983162471993

Epoch: 5| Step: 7
Training loss: 1.51457468980984
Validation loss: 2.574274968414717

Epoch: 5| Step: 8
Training loss: 1.6333482219380766
Validation loss: 2.5665159545552156

Epoch: 5| Step: 9
Training loss: 2.2601975248321384
Validation loss: 2.5672095757725377

Epoch: 5| Step: 10
Training loss: 1.7641954964846993
Validation loss: 2.569706148632504

Epoch: 5| Step: 11
Training loss: 1.3588770688886616
Validation loss: 2.5766367306107374

Epoch: 341| Step: 0
Training loss: 2.250104265976062
Validation loss: 2.5922634660114334

Epoch: 5| Step: 1
Training loss: 1.8802170334999506
Validation loss: 2.6323396426016528

Epoch: 5| Step: 2
Training loss: 2.012090141309621
Validation loss: 2.6191829077758917

Epoch: 5| Step: 3
Training loss: 2.2013960743601992
Validation loss: 2.6696548309762385

Epoch: 5| Step: 4
Training loss: 2.2930411176293095
Validation loss: 2.7095810009272068

Epoch: 5| Step: 5
Training loss: 1.8819662384548017
Validation loss: 2.6949431235375214

Epoch: 5| Step: 6
Training loss: 2.1127969747513733
Validation loss: 2.682146358566316

Epoch: 5| Step: 7
Training loss: 1.5991011150946637
Validation loss: 2.630135832942452

Epoch: 5| Step: 8
Training loss: 2.662412966169824
Validation loss: 2.563618720094164

Epoch: 5| Step: 9
Training loss: 1.8861698592182747
Validation loss: 2.545710806595769

Epoch: 5| Step: 10
Training loss: 1.9760372986960577
Validation loss: 2.537392713756067

Epoch: 5| Step: 11
Training loss: 1.595029429579776
Validation loss: 2.5346622818488846

Epoch: 342| Step: 0
Training loss: 2.7715268713157544
Validation loss: 2.5408424359470594

Epoch: 5| Step: 1
Training loss: 1.96983495214529
Validation loss: 2.5399730888421663

Epoch: 5| Step: 2
Training loss: 2.3393243330967812
Validation loss: 2.5361503528981864

Epoch: 5| Step: 3
Training loss: 1.6205775898428707
Validation loss: 2.558117538280961

Epoch: 5| Step: 4
Training loss: 2.3093088143121134
Validation loss: 2.5619016313126446

Epoch: 5| Step: 5
Training loss: 1.631274945883177
Validation loss: 2.575625180611083

Epoch: 5| Step: 6
Training loss: 2.212985327125996
Validation loss: 2.616769838931368

Epoch: 5| Step: 7
Training loss: 1.7636741731106982
Validation loss: 2.649904465602749

Epoch: 5| Step: 8
Training loss: 1.8682715170187953
Validation loss: 2.713651425465927

Epoch: 5| Step: 9
Training loss: 2.356840275256015
Validation loss: 2.697850126503923

Epoch: 5| Step: 10
Training loss: 1.7850955477020436
Validation loss: 2.697946122400231

Epoch: 5| Step: 11
Training loss: 2.5456708624192776
Validation loss: 2.646071462102806

Epoch: 343| Step: 0
Training loss: 2.15535275132297
Validation loss: 2.648298408059147

Epoch: 5| Step: 1
Training loss: 1.9107490976928674
Validation loss: 2.597667657736298

Epoch: 5| Step: 2
Training loss: 1.3025073263947078
Validation loss: 2.5828638278224973

Epoch: 5| Step: 3
Training loss: 1.95558060963553
Validation loss: 2.580014786579332

Epoch: 5| Step: 4
Training loss: 2.1987871251271134
Validation loss: 2.571734644666518

Epoch: 5| Step: 5
Training loss: 1.9957057628065362
Validation loss: 2.582536427704705

Epoch: 5| Step: 6
Training loss: 2.071340744618365
Validation loss: 2.5580205377182264

Epoch: 5| Step: 7
Training loss: 2.1147904568662677
Validation loss: 2.5843586361115993

Epoch: 5| Step: 8
Training loss: 2.3204586098646995
Validation loss: 2.573684586794054

Epoch: 5| Step: 9
Training loss: 2.138631407472449
Validation loss: 2.5711687202075324

Epoch: 5| Step: 10
Training loss: 1.9622841880367738
Validation loss: 2.5580105997877043

Epoch: 5| Step: 11
Training loss: 3.245463947110587
Validation loss: 2.595473806308822

Epoch: 344| Step: 0
Training loss: 2.0313873244595917
Validation loss: 2.5843208038231853

Epoch: 5| Step: 1
Training loss: 2.140046424362166
Validation loss: 2.543040136379311

Epoch: 5| Step: 2
Training loss: 1.8349452807300046
Validation loss: 2.5506055575702167

Epoch: 5| Step: 3
Training loss: 2.286572869863713
Validation loss: 2.560772422014807

Epoch: 5| Step: 4
Training loss: 2.3740866059122245
Validation loss: 2.5628261048522902

Epoch: 5| Step: 5
Training loss: 1.6796849450380278
Validation loss: 2.5716365584710146

Epoch: 5| Step: 6
Training loss: 1.833366509339679
Validation loss: 2.581521823200716

Epoch: 5| Step: 7
Training loss: 2.142635654174388
Validation loss: 2.5876416356487324

Epoch: 5| Step: 8
Training loss: 2.4565554402231373
Validation loss: 2.608438898779844

Epoch: 5| Step: 9
Training loss: 1.9067482219051055
Validation loss: 2.5750448843368114

Epoch: 5| Step: 10
Training loss: 1.7524660990397765
Validation loss: 2.5498412592415387

Epoch: 5| Step: 11
Training loss: 1.8607734101767996
Validation loss: 2.5223896618602892

Epoch: 345| Step: 0
Training loss: 1.2989931847802474
Validation loss: 2.511467968102012

Epoch: 5| Step: 1
Training loss: 1.4862599501344909
Validation loss: 2.511925921639407

Epoch: 5| Step: 2
Training loss: 2.204632290825444
Validation loss: 2.5183657372782213

Epoch: 5| Step: 3
Training loss: 2.0148500830679112
Validation loss: 2.512852805784184

Epoch: 5| Step: 4
Training loss: 2.0750845558678965
Validation loss: 2.5225757036673304

Epoch: 5| Step: 5
Training loss: 2.348955198118115
Validation loss: 2.5311071410504784

Epoch: 5| Step: 6
Training loss: 2.263700312253972
Validation loss: 2.5338782648794385

Epoch: 5| Step: 7
Training loss: 2.362663453114278
Validation loss: 2.5830738773082

Epoch: 5| Step: 8
Training loss: 2.076017185595754
Validation loss: 2.6261431649574694

Epoch: 5| Step: 9
Training loss: 2.5209645534022287
Validation loss: 2.6948998397941475

Epoch: 5| Step: 10
Training loss: 1.8096027237552075
Validation loss: 2.6930167183303384

Epoch: 5| Step: 11
Training loss: 1.5239469801122871
Validation loss: 2.7150390316919033

Epoch: 346| Step: 0
Training loss: 1.9896752168166307
Validation loss: 2.6920644530170708

Epoch: 5| Step: 1
Training loss: 1.7571698857930163
Validation loss: 2.689029768323987

Epoch: 5| Step: 2
Training loss: 2.045128229873016
Validation loss: 2.6598670492313503

Epoch: 5| Step: 3
Training loss: 2.1729595303231863
Validation loss: 2.623099134601096

Epoch: 5| Step: 4
Training loss: 2.480240170016677
Validation loss: 2.6203295204248245

Epoch: 5| Step: 5
Training loss: 2.136877413199112
Validation loss: 2.5944193125822914

Epoch: 5| Step: 6
Training loss: 1.622282764133932
Validation loss: 2.5773693325888747

Epoch: 5| Step: 7
Training loss: 1.920870386567555
Validation loss: 2.542290127743404

Epoch: 5| Step: 8
Training loss: 2.8376170667790572
Validation loss: 2.5422872713280187

Epoch: 5| Step: 9
Training loss: 1.3199886398838068
Validation loss: 2.5672534142435373

Epoch: 5| Step: 10
Training loss: 1.990318049505316
Validation loss: 2.563351423811934

Epoch: 5| Step: 11
Training loss: 1.0564054837426502
Validation loss: 2.5755693696594366

Epoch: 347| Step: 0
Training loss: 1.5918152228860125
Validation loss: 2.588276461262816

Epoch: 5| Step: 1
Training loss: 2.3830006009259987
Validation loss: 2.598157948014411

Epoch: 5| Step: 2
Training loss: 2.7298102069038706
Validation loss: 2.566672289571754

Epoch: 5| Step: 3
Training loss: 2.1679470851606126
Validation loss: 2.5721357733281556

Epoch: 5| Step: 4
Training loss: 1.8723585596384684
Validation loss: 2.576551323151815

Epoch: 5| Step: 5
Training loss: 2.0743718494875236
Validation loss: 2.5634416889058946

Epoch: 5| Step: 6
Training loss: 1.6126837189571694
Validation loss: 2.564748885954463

Epoch: 5| Step: 7
Training loss: 1.5841784564119168
Validation loss: 2.5627495791460606

Epoch: 5| Step: 8
Training loss: 2.149141952157577
Validation loss: 2.559240361399646

Epoch: 5| Step: 9
Training loss: 1.282080032564232
Validation loss: 2.570024642362345

Epoch: 5| Step: 10
Training loss: 2.39651839924655
Validation loss: 2.564200368270677

Epoch: 5| Step: 11
Training loss: 2.1322694862701708
Validation loss: 2.577248684464549

Epoch: 348| Step: 0
Training loss: 1.786141555622908
Validation loss: 2.550454750215026

Epoch: 5| Step: 1
Training loss: 2.136439108114974
Validation loss: 2.5410512520484025

Epoch: 5| Step: 2
Training loss: 1.7712400829438684
Validation loss: 2.5233027576734073

Epoch: 5| Step: 3
Training loss: 2.377679818750962
Validation loss: 2.5137043565273314

Epoch: 5| Step: 4
Training loss: 2.8470145131670113
Validation loss: 2.525386431681453

Epoch: 5| Step: 5
Training loss: 1.7659946156049233
Validation loss: 2.5163479550026477

Epoch: 5| Step: 6
Training loss: 2.3218265821047366
Validation loss: 2.5519279367794123

Epoch: 5| Step: 7
Training loss: 2.190711035242965
Validation loss: 2.568494712445178

Epoch: 5| Step: 8
Training loss: 1.9993338667659084
Validation loss: 2.592991273664754

Epoch: 5| Step: 9
Training loss: 1.741283096469957
Validation loss: 2.629842854907006

Epoch: 5| Step: 10
Training loss: 1.4978462492723845
Validation loss: 2.6535750177809367

Epoch: 5| Step: 11
Training loss: 1.7261461126956397
Validation loss: 2.629961696555541

Epoch: 349| Step: 0
Training loss: 1.852383331043268
Validation loss: 2.6400247000612884

Epoch: 5| Step: 1
Training loss: 2.035253716476078
Validation loss: 2.609382248676153

Epoch: 5| Step: 2
Training loss: 2.407978675450038
Validation loss: 2.5835411554748293

Epoch: 5| Step: 3
Training loss: 2.099057203919109
Validation loss: 2.5760156922985415

Epoch: 5| Step: 4
Training loss: 1.4102477997625913
Validation loss: 2.5869053645723974

Epoch: 5| Step: 5
Training loss: 2.091245833334047
Validation loss: 2.5762029226117815

Epoch: 5| Step: 6
Training loss: 2.0236865740916232
Validation loss: 2.598358843253849

Epoch: 5| Step: 7
Training loss: 2.1646338854979263
Validation loss: 2.585239008738085

Epoch: 5| Step: 8
Training loss: 2.0158684162158456
Validation loss: 2.576141380378295

Epoch: 5| Step: 9
Training loss: 1.6934114687957342
Validation loss: 2.601950077211063

Epoch: 5| Step: 10
Training loss: 2.2883101649360618
Validation loss: 2.565304982930296

Epoch: 5| Step: 11
Training loss: 1.3619314687435247
Validation loss: 2.603344983487146

Epoch: 350| Step: 0
Training loss: 2.4599306983800417
Validation loss: 2.5656205265936998

Epoch: 5| Step: 1
Training loss: 1.6171556552571178
Validation loss: 2.579944095985451

Epoch: 5| Step: 2
Training loss: 2.093817297010534
Validation loss: 2.5863668271696856

Epoch: 5| Step: 3
Training loss: 2.099941607072157
Validation loss: 2.6027270317785116

Epoch: 5| Step: 4
Training loss: 2.0998713272274245
Validation loss: 2.5754665925756077

Epoch: 5| Step: 5
Training loss: 1.7563806424133441
Validation loss: 2.604136754182048

Epoch: 5| Step: 6
Training loss: 1.9501514229303267
Validation loss: 2.6262548187395636

Epoch: 5| Step: 7
Training loss: 1.9823882001450217
Validation loss: 2.6087093494077

Epoch: 5| Step: 8
Training loss: 1.5698541380313695
Validation loss: 2.6197591018675177

Epoch: 5| Step: 9
Training loss: 1.850602363775218
Validation loss: 2.6006452759216128

Epoch: 5| Step: 10
Training loss: 2.5787888105821577
Validation loss: 2.586801440316041

Epoch: 5| Step: 11
Training loss: 1.7445579106522617
Validation loss: 2.605141988583413

Epoch: 351| Step: 0
Training loss: 1.8316754807019213
Validation loss: 2.5827730145429517

Epoch: 5| Step: 1
Training loss: 2.1982074804290335
Validation loss: 2.5691641394047697

Epoch: 5| Step: 2
Training loss: 1.631279330519733
Validation loss: 2.5689240119016397

Epoch: 5| Step: 3
Training loss: 1.8632429906727839
Validation loss: 2.5843901485012983

Epoch: 5| Step: 4
Training loss: 2.7832002124436515
Validation loss: 2.564584121011902

Epoch: 5| Step: 5
Training loss: 2.5824816335521685
Validation loss: 2.5921552765299496

Epoch: 5| Step: 6
Training loss: 1.3998500573379904
Validation loss: 2.601030999954793

Epoch: 5| Step: 7
Training loss: 1.7554916319228002
Validation loss: 2.627645389522116

Epoch: 5| Step: 8
Training loss: 1.820792531910114
Validation loss: 2.621659863465785

Epoch: 5| Step: 9
Training loss: 1.6405231989202953
Validation loss: 2.6550047180675054

Epoch: 5| Step: 10
Training loss: 2.2729191664400235
Validation loss: 2.6451694877227623

Epoch: 5| Step: 11
Training loss: 1.7387894819701042
Validation loss: 2.626481160589944

Epoch: 352| Step: 0
Training loss: 1.652479810952088
Validation loss: 2.652598575266821

Epoch: 5| Step: 1
Training loss: 2.2809323651472484
Validation loss: 2.6523386712229313

Epoch: 5| Step: 2
Training loss: 1.9491789360796425
Validation loss: 2.6292719631500696

Epoch: 5| Step: 3
Training loss: 1.651106856189332
Validation loss: 2.6429335004436902

Epoch: 5| Step: 4
Training loss: 2.5172540353971318
Validation loss: 2.6115261089374147

Epoch: 5| Step: 5
Training loss: 2.0616638338176947
Validation loss: 2.6289852748290152

Epoch: 5| Step: 6
Training loss: 2.096142668549558
Validation loss: 2.6224266960855918

Epoch: 5| Step: 7
Training loss: 1.5895267704823974
Validation loss: 2.6014394797869547

Epoch: 5| Step: 8
Training loss: 2.54424857237548
Validation loss: 2.6209530401764103

Epoch: 5| Step: 9
Training loss: 1.8381529731269257
Validation loss: 2.5916529569743654

Epoch: 5| Step: 10
Training loss: 1.5744511359425624
Validation loss: 2.587236126361618

Epoch: 5| Step: 11
Training loss: 1.6780390967860097
Validation loss: 2.6109202182151416

Epoch: 353| Step: 0
Training loss: 1.76878607345837
Validation loss: 2.6260692049998844

Epoch: 5| Step: 1
Training loss: 2.078726315802131
Validation loss: 2.6303350883886605

Epoch: 5| Step: 2
Training loss: 1.7487383790683253
Validation loss: 2.6299582800015857

Epoch: 5| Step: 3
Training loss: 1.9430570587717124
Validation loss: 2.5848273845779364

Epoch: 5| Step: 4
Training loss: 1.6251537543696586
Validation loss: 2.607533610375107

Epoch: 5| Step: 5
Training loss: 1.8807125172863641
Validation loss: 2.6065656687320087

Epoch: 5| Step: 6
Training loss: 2.073897572164918
Validation loss: 2.576925653790486

Epoch: 5| Step: 7
Training loss: 1.8085663301107195
Validation loss: 2.5933584162786985

Epoch: 5| Step: 8
Training loss: 2.0976655700590205
Validation loss: 2.6195358577437076

Epoch: 5| Step: 9
Training loss: 2.430401957669201
Validation loss: 2.5925116781034867

Epoch: 5| Step: 10
Training loss: 2.3950145040881234
Validation loss: 2.5957897278035267

Epoch: 5| Step: 11
Training loss: 1.707238365894516
Validation loss: 2.567711578016314

Epoch: 354| Step: 0
Training loss: 1.805892476003955
Validation loss: 2.59865920703189

Epoch: 5| Step: 1
Training loss: 1.7217820905760952
Validation loss: 2.5991004810689997

Epoch: 5| Step: 2
Training loss: 2.1969965112977072
Validation loss: 2.5853742195372535

Epoch: 5| Step: 3
Training loss: 1.533858743433015
Validation loss: 2.5640984798667854

Epoch: 5| Step: 4
Training loss: 2.5634483815415283
Validation loss: 2.5833536763825884

Epoch: 5| Step: 5
Training loss: 2.547389159931205
Validation loss: 2.5878777500048242

Epoch: 5| Step: 6
Training loss: 2.0238724760207436
Validation loss: 2.6223546580188706

Epoch: 5| Step: 7
Training loss: 1.4934860890177717
Validation loss: 2.6433406236322736

Epoch: 5| Step: 8
Training loss: 1.6994848284177457
Validation loss: 2.688773411681824

Epoch: 5| Step: 9
Training loss: 2.6336249391241737
Validation loss: 2.6768023545072053

Epoch: 5| Step: 10
Training loss: 1.7693827653106105
Validation loss: 2.6639347586485247

Epoch: 5| Step: 11
Training loss: 0.9755256641850136
Validation loss: 2.634476521633603

Epoch: 355| Step: 0
Training loss: 1.3808983091830351
Validation loss: 2.5875890534505523

Epoch: 5| Step: 1
Training loss: 2.2589785195013703
Validation loss: 2.56608691035924

Epoch: 5| Step: 2
Training loss: 2.2970720063923267
Validation loss: 2.5241008433876164

Epoch: 5| Step: 3
Training loss: 1.845520850167925
Validation loss: 2.5308884648973344

Epoch: 5| Step: 4
Training loss: 1.7788094649625577
Validation loss: 2.5327952970139793

Epoch: 5| Step: 5
Training loss: 2.1975081246391843
Validation loss: 2.5251907658984143

Epoch: 5| Step: 6
Training loss: 2.037676577727364
Validation loss: 2.508735047349527

Epoch: 5| Step: 7
Training loss: 1.7748325591293272
Validation loss: 2.498521653810374

Epoch: 5| Step: 8
Training loss: 2.034290327193968
Validation loss: 2.5503083433773255

Epoch: 5| Step: 9
Training loss: 1.8524058549976672
Validation loss: 2.579687719963152

Epoch: 5| Step: 10
Training loss: 2.513535383975201
Validation loss: 2.5758466536988833

Epoch: 5| Step: 11
Training loss: 1.355921513027342
Validation loss: 2.5783992390284123

Epoch: 356| Step: 0
Training loss: 1.851015420561969
Validation loss: 2.5752800628677024

Epoch: 5| Step: 1
Training loss: 2.2365526378158846
Validation loss: 2.5932953715692166

Epoch: 5| Step: 2
Training loss: 1.8285817284911294
Validation loss: 2.565053047923017

Epoch: 5| Step: 3
Training loss: 2.309912909810546
Validation loss: 2.5796791709612945

Epoch: 5| Step: 4
Training loss: 1.597262532190849
Validation loss: 2.547905286439656

Epoch: 5| Step: 5
Training loss: 2.1597087596652256
Validation loss: 2.5830538172912636

Epoch: 5| Step: 6
Training loss: 2.204089014696228
Validation loss: 2.589649820330986

Epoch: 5| Step: 7
Training loss: 1.4417312379756955
Validation loss: 2.6111283759691655

Epoch: 5| Step: 8
Training loss: 2.645140088992087
Validation loss: 2.604858918051928

Epoch: 5| Step: 9
Training loss: 1.405611698669488
Validation loss: 2.6096252047339554

Epoch: 5| Step: 10
Training loss: 1.8973714087819389
Validation loss: 2.585270498869004

Epoch: 5| Step: 11
Training loss: 0.8927409150903975
Validation loss: 2.6075075285483766

Epoch: 357| Step: 0
Training loss: 1.9290630241330298
Validation loss: 2.6408435986869963

Epoch: 5| Step: 1
Training loss: 2.3364243016093798
Validation loss: 2.6378333140257317

Epoch: 5| Step: 2
Training loss: 2.218917303090704
Validation loss: 2.693101689416407

Epoch: 5| Step: 3
Training loss: 2.046883153535168
Validation loss: 2.6984590454066066

Epoch: 5| Step: 4
Training loss: 1.9917294443151174
Validation loss: 2.642924678659441

Epoch: 5| Step: 5
Training loss: 1.7975483835046107
Validation loss: 2.5986034492478494

Epoch: 5| Step: 6
Training loss: 2.3287787831565554
Validation loss: 2.6138527268604013

Epoch: 5| Step: 7
Training loss: 1.7716513894619537
Validation loss: 2.616865345120376

Epoch: 5| Step: 8
Training loss: 1.7749997286729202
Validation loss: 2.5937134269066195

Epoch: 5| Step: 9
Training loss: 1.682771911414963
Validation loss: 2.5596097312200223

Epoch: 5| Step: 10
Training loss: 1.7545948333592853
Validation loss: 2.5313260455541093

Epoch: 5| Step: 11
Training loss: 1.8830800479723462
Validation loss: 2.5506513717323736

Epoch: 358| Step: 0
Training loss: 1.4835750632894538
Validation loss: 2.5381319071946495

Epoch: 5| Step: 1
Training loss: 1.9598673906035635
Validation loss: 2.5757541679367857

Epoch: 5| Step: 2
Training loss: 2.0520874513949465
Validation loss: 2.5693033859837473

Epoch: 5| Step: 3
Training loss: 1.7610716720414228
Validation loss: 2.5886572627168474

Epoch: 5| Step: 4
Training loss: 2.2575012837318664
Validation loss: 2.6027470508556654

Epoch: 5| Step: 5
Training loss: 2.1267789238666577
Validation loss: 2.6221452698746766

Epoch: 5| Step: 6
Training loss: 2.375706216316554
Validation loss: 2.6368536568496936

Epoch: 5| Step: 7
Training loss: 1.96908584636584
Validation loss: 2.647445429136565

Epoch: 5| Step: 8
Training loss: 1.888207584659781
Validation loss: 2.65336066533473

Epoch: 5| Step: 9
Training loss: 1.9399336020914948
Validation loss: 2.6670654838078747

Epoch: 5| Step: 10
Training loss: 2.0586741248985607
Validation loss: 2.619310218503293

Epoch: 5| Step: 11
Training loss: 1.4411248653510074
Validation loss: 2.603409055497137

Epoch: 359| Step: 0
Training loss: 2.3437192787700116
Validation loss: 2.5596717466039514

Epoch: 5| Step: 1
Training loss: 2.1145105083183715
Validation loss: 2.538914426740769

Epoch: 5| Step: 2
Training loss: 1.7167953473844881
Validation loss: 2.5330019527605483

Epoch: 5| Step: 3
Training loss: 2.2419342004272584
Validation loss: 2.5216973508071887

Epoch: 5| Step: 4
Training loss: 1.7421511659126332
Validation loss: 2.5130724623257006

Epoch: 5| Step: 5
Training loss: 2.7136976279006895
Validation loss: 2.5045794386942637

Epoch: 5| Step: 6
Training loss: 2.0240435189857076
Validation loss: 2.518544842337291

Epoch: 5| Step: 7
Training loss: 1.9265557950313867
Validation loss: 2.5400649160721547

Epoch: 5| Step: 8
Training loss: 1.9092932001500986
Validation loss: 2.5832094898584828

Epoch: 5| Step: 9
Training loss: 1.885384540038267
Validation loss: 2.6131333716519283

Epoch: 5| Step: 10
Training loss: 1.3516148463349116
Validation loss: 2.646692276749871

Epoch: 5| Step: 11
Training loss: 1.742845966796866
Validation loss: 2.652726738928635

Epoch: 360| Step: 0
Training loss: 2.230607491101451
Validation loss: 2.6878214355575687

Epoch: 5| Step: 1
Training loss: 1.8279469721258472
Validation loss: 2.6768300509339964

Epoch: 5| Step: 2
Training loss: 2.236357549615374
Validation loss: 2.7140018868508897

Epoch: 5| Step: 3
Training loss: 1.9505973023388818
Validation loss: 2.6921717344572613

Epoch: 5| Step: 4
Training loss: 1.5885373308299775
Validation loss: 2.6623918285991732

Epoch: 5| Step: 5
Training loss: 2.237281669321791
Validation loss: 2.6576122119511507

Epoch: 5| Step: 6
Training loss: 2.0382178884873197
Validation loss: 2.603322564970581

Epoch: 5| Step: 7
Training loss: 1.3672113470995018
Validation loss: 2.5836634014881525

Epoch: 5| Step: 8
Training loss: 2.3869254214746394
Validation loss: 2.582763929577698

Epoch: 5| Step: 9
Training loss: 1.7231479211278289
Validation loss: 2.54909284637135

Epoch: 5| Step: 10
Training loss: 2.3143184831946733
Validation loss: 2.5476117774866434

Epoch: 5| Step: 11
Training loss: 1.3418877583338282
Validation loss: 2.5455294137865176

Epoch: 361| Step: 0
Training loss: 1.9706645315302396
Validation loss: 2.54981125229675

Epoch: 5| Step: 1
Training loss: 2.235220795719124
Validation loss: 2.547951706691876

Epoch: 5| Step: 2
Training loss: 1.9974536779616234
Validation loss: 2.547881424868866

Epoch: 5| Step: 3
Training loss: 2.3223559696471727
Validation loss: 2.5716458295380535

Epoch: 5| Step: 4
Training loss: 1.9156237404649585
Validation loss: 2.606227806127932

Epoch: 5| Step: 5
Training loss: 1.489958611367939
Validation loss: 2.587187926658733

Epoch: 5| Step: 6
Training loss: 1.7492239457496668
Validation loss: 2.628665540840633

Epoch: 5| Step: 7
Training loss: 1.7060816587468068
Validation loss: 2.67125978135142

Epoch: 5| Step: 8
Training loss: 2.401650330247277
Validation loss: 2.640691692405456

Epoch: 5| Step: 9
Training loss: 1.9567318990037592
Validation loss: 2.676591202046993

Epoch: 5| Step: 10
Training loss: 1.9469558943938525
Validation loss: 2.6792703494768375

Epoch: 5| Step: 11
Training loss: 2.160635758721598
Validation loss: 2.6280370770903625

Epoch: 362| Step: 0
Training loss: 1.8973908227363443
Validation loss: 2.6488594461740185

Epoch: 5| Step: 1
Training loss: 1.6143916190573517
Validation loss: 2.6593807694058382

Epoch: 5| Step: 2
Training loss: 2.2267662624349036
Validation loss: 2.626261824130797

Epoch: 5| Step: 3
Training loss: 2.1848317903416277
Validation loss: 2.6021411317179077

Epoch: 5| Step: 4
Training loss: 2.193672191837627
Validation loss: 2.611490005424861

Epoch: 5| Step: 5
Training loss: 1.6321912980113062
Validation loss: 2.6033371150868096

Epoch: 5| Step: 6
Training loss: 1.922994830139955
Validation loss: 2.5870097185735577

Epoch: 5| Step: 7
Training loss: 1.8919691241731036
Validation loss: 2.5886125510096307

Epoch: 5| Step: 8
Training loss: 2.1432269912529462
Validation loss: 2.5515546497629895

Epoch: 5| Step: 9
Training loss: 1.3788013796601062
Validation loss: 2.5586319044534584

Epoch: 5| Step: 10
Training loss: 2.112162013356576
Validation loss: 2.5774516488259827

Epoch: 5| Step: 11
Training loss: 1.2202717011063045
Validation loss: 2.5428396915905447

Epoch: 363| Step: 0
Training loss: 1.3943949400375006
Validation loss: 2.5541346084881225

Epoch: 5| Step: 1
Training loss: 1.8465465092156252
Validation loss: 2.5256654334660835

Epoch: 5| Step: 2
Training loss: 2.513304404168969
Validation loss: 2.535636613396263

Epoch: 5| Step: 3
Training loss: 1.9162698279622183
Validation loss: 2.5503317537668893

Epoch: 5| Step: 4
Training loss: 1.7391227142794945
Validation loss: 2.5772470347210144

Epoch: 5| Step: 5
Training loss: 1.7240575510230225
Validation loss: 2.5868055340783265

Epoch: 5| Step: 6
Training loss: 1.7890469079816607
Validation loss: 2.6080479207255944

Epoch: 5| Step: 7
Training loss: 2.3578929161883977
Validation loss: 2.57779187448893

Epoch: 5| Step: 8
Training loss: 2.1223480281633655
Validation loss: 2.6152732984871734

Epoch: 5| Step: 9
Training loss: 2.0395065350307426
Validation loss: 2.591227281271182

Epoch: 5| Step: 10
Training loss: 2.133799789017661
Validation loss: 2.5966455544146827

Epoch: 5| Step: 11
Training loss: 0.9070019726295427
Validation loss: 2.586504446692227

Epoch: 364| Step: 0
Training loss: 1.2451278147524416
Validation loss: 2.56968328780625

Epoch: 5| Step: 1
Training loss: 2.4452490265137126
Validation loss: 2.580998201073275

Epoch: 5| Step: 2
Training loss: 2.1284908344339395
Validation loss: 2.551126913315907

Epoch: 5| Step: 3
Training loss: 2.0654748212784404
Validation loss: 2.568982059240402

Epoch: 5| Step: 4
Training loss: 1.5864269083992995
Validation loss: 2.532026705472486

Epoch: 5| Step: 5
Training loss: 2.1576186549510714
Validation loss: 2.584220362214789

Epoch: 5| Step: 6
Training loss: 1.6401614306247148
Validation loss: 2.535698427631085

Epoch: 5| Step: 7
Training loss: 1.8146209146467178
Validation loss: 2.5821143409644547

Epoch: 5| Step: 8
Training loss: 1.9937591337275784
Validation loss: 2.6220888237799977

Epoch: 5| Step: 9
Training loss: 1.924424875721295
Validation loss: 2.6338043910226294

Epoch: 5| Step: 10
Training loss: 2.159870811766979
Validation loss: 2.605497953908001

Epoch: 5| Step: 11
Training loss: 2.6149813791053327
Validation loss: 2.5971659491614165

Epoch: 365| Step: 0
Training loss: 1.943456660763714
Validation loss: 2.6146722388381596

Epoch: 5| Step: 1
Training loss: 1.3333169767250692
Validation loss: 2.588417926545304

Epoch: 5| Step: 2
Training loss: 2.3568411856981943
Validation loss: 2.587246424309656

Epoch: 5| Step: 3
Training loss: 1.5957884374666023
Validation loss: 2.56541100359559

Epoch: 5| Step: 4
Training loss: 1.8251905446324497
Validation loss: 2.548676483593227

Epoch: 5| Step: 5
Training loss: 1.8527622118665696
Validation loss: 2.560576825969392

Epoch: 5| Step: 6
Training loss: 1.9906245664299653
Validation loss: 2.57618699492326

Epoch: 5| Step: 7
Training loss: 1.6420883918277107
Validation loss: 2.531268633864147

Epoch: 5| Step: 8
Training loss: 1.4845420341874902
Validation loss: 2.5718892564838076

Epoch: 5| Step: 9
Training loss: 2.814547069286764
Validation loss: 2.5316041612306934

Epoch: 5| Step: 10
Training loss: 2.209994704814108
Validation loss: 2.520163420784983

Epoch: 5| Step: 11
Training loss: 2.101298716273683
Validation loss: 2.5344904146204477

Epoch: 366| Step: 0
Training loss: 1.6571168610337765
Validation loss: 2.5203987954255997

Epoch: 5| Step: 1
Training loss: 1.5356585818862374
Validation loss: 2.545882294855714

Epoch: 5| Step: 2
Training loss: 2.2865268867892214
Validation loss: 2.512531756046966

Epoch: 5| Step: 3
Training loss: 1.7846316311707635
Validation loss: 2.548197295755731

Epoch: 5| Step: 4
Training loss: 2.008882704922677
Validation loss: 2.5491076261363883

Epoch: 5| Step: 5
Training loss: 1.8515554822313935
Validation loss: 2.563792011531164

Epoch: 5| Step: 6
Training loss: 1.3077860147034401
Validation loss: 2.52828002481101

Epoch: 5| Step: 7
Training loss: 1.8023269870806948
Validation loss: 2.5636168348898547

Epoch: 5| Step: 8
Training loss: 2.168967297136442
Validation loss: 2.563858094902399

Epoch: 5| Step: 9
Training loss: 2.4154529702739453
Validation loss: 2.553620484052728

Epoch: 5| Step: 10
Training loss: 2.4700242628998534
Validation loss: 2.558325049193283

Epoch: 5| Step: 11
Training loss: 0.587994639171115
Validation loss: 2.570170884641991

Epoch: 367| Step: 0
Training loss: 2.0931881962209187
Validation loss: 2.596376003197786

Epoch: 5| Step: 1
Training loss: 1.8439491293752204
Validation loss: 2.6594661540133098

Epoch: 5| Step: 2
Training loss: 1.8735436187545067
Validation loss: 2.6535102552545577

Epoch: 5| Step: 3
Training loss: 1.8130370035156325
Validation loss: 2.7036891929124813

Epoch: 5| Step: 4
Training loss: 1.9789571015352498
Validation loss: 2.682777743446731

Epoch: 5| Step: 5
Training loss: 2.2796256147826113
Validation loss: 2.652277672702531

Epoch: 5| Step: 6
Training loss: 2.183075053345074
Validation loss: 2.5906679578593197

Epoch: 5| Step: 7
Training loss: 2.2520770975944675
Validation loss: 2.5571229818199126

Epoch: 5| Step: 8
Training loss: 1.863277283350403
Validation loss: 2.5304956489492416

Epoch: 5| Step: 9
Training loss: 1.367347097618339
Validation loss: 2.5212074637934445

Epoch: 5| Step: 10
Training loss: 1.7838347570843762
Validation loss: 2.502088207099312

Epoch: 5| Step: 11
Training loss: 2.61274875752459
Validation loss: 2.5118268802004677

Epoch: 368| Step: 0
Training loss: 1.9478646201730059
Validation loss: 2.535391084975049

Epoch: 5| Step: 1
Training loss: 2.136128736416919
Validation loss: 2.5498127055106004

Epoch: 5| Step: 2
Training loss: 2.15193141857756
Validation loss: 2.5340818372785145

Epoch: 5| Step: 3
Training loss: 1.331339010209034
Validation loss: 2.5854917912374726

Epoch: 5| Step: 4
Training loss: 1.6234698794443
Validation loss: 2.616561108685275

Epoch: 5| Step: 5
Training loss: 1.691004610719717
Validation loss: 2.625531400147095

Epoch: 5| Step: 6
Training loss: 2.1302948229205874
Validation loss: 2.612128926956952

Epoch: 5| Step: 7
Training loss: 1.4450685862331403
Validation loss: 2.6375329689026334

Epoch: 5| Step: 8
Training loss: 2.869446740073112
Validation loss: 2.6439773640663997

Epoch: 5| Step: 9
Training loss: 1.8372339094918333
Validation loss: 2.5833673641568016

Epoch: 5| Step: 10
Training loss: 1.9504988447986302
Validation loss: 2.5631078371349125

Epoch: 5| Step: 11
Training loss: 1.2171720413186151
Validation loss: 2.523990062766607

Epoch: 369| Step: 0
Training loss: 1.553295182972495
Validation loss: 2.4777646762086216

Epoch: 5| Step: 1
Training loss: 1.7936211356950122
Validation loss: 2.479162457940726

Epoch: 5| Step: 2
Training loss: 2.137158113320249
Validation loss: 2.4597501483987885

Epoch: 5| Step: 3
Training loss: 2.2815248506702868
Validation loss: 2.4774640404882025

Epoch: 5| Step: 4
Training loss: 1.9535549453534116
Validation loss: 2.485786085234981

Epoch: 5| Step: 5
Training loss: 2.3578539865533483
Validation loss: 2.474198176486441

Epoch: 5| Step: 6
Training loss: 1.9737263109502061
Validation loss: 2.4865300670121204

Epoch: 5| Step: 7
Training loss: 1.9747004728499344
Validation loss: 2.510347714934763

Epoch: 5| Step: 8
Training loss: 1.9102180330547016
Validation loss: 2.5580875895846766

Epoch: 5| Step: 9
Training loss: 2.3357017168445977
Validation loss: 2.6307115709170383

Epoch: 5| Step: 10
Training loss: 1.806212800378758
Validation loss: 2.6646651018096907

Epoch: 5| Step: 11
Training loss: 2.4827614588739535
Validation loss: 2.653159464150603

Epoch: 370| Step: 0
Training loss: 2.22985553495896
Validation loss: 2.6614014768157332

Epoch: 5| Step: 1
Training loss: 1.9595637886077923
Validation loss: 2.641291381901716

Epoch: 5| Step: 2
Training loss: 2.1475397627216832
Validation loss: 2.6424911082457103

Epoch: 5| Step: 3
Training loss: 2.347041349445787
Validation loss: 2.6008275629230333

Epoch: 5| Step: 4
Training loss: 1.5595399666104888
Validation loss: 2.6036595664616353

Epoch: 5| Step: 5
Training loss: 1.851993237060821
Validation loss: 2.5717124373091207

Epoch: 5| Step: 6
Training loss: 2.0627947510000646
Validation loss: 2.581612626621031

Epoch: 5| Step: 7
Training loss: 2.0655724730861045
Validation loss: 2.5578780087995776

Epoch: 5| Step: 8
Training loss: 1.2849836146575389
Validation loss: 2.58218769978801

Epoch: 5| Step: 9
Training loss: 1.5533286438954395
Validation loss: 2.574683846351762

Epoch: 5| Step: 10
Training loss: 1.9686835141535945
Validation loss: 2.5671657055954933

Epoch: 5| Step: 11
Training loss: 1.2616038550628224
Validation loss: 2.5779604676274652

Epoch: 371| Step: 0
Training loss: 1.749140596539281
Validation loss: 2.551964626016767

Epoch: 5| Step: 1
Training loss: 1.3973728154813114
Validation loss: 2.603297093485563

Epoch: 5| Step: 2
Training loss: 2.4549356569454996
Validation loss: 2.6058541908340302

Epoch: 5| Step: 3
Training loss: 1.736323044450877
Validation loss: 2.5985019808116903

Epoch: 5| Step: 4
Training loss: 1.5923681813633148
Validation loss: 2.590365194814877

Epoch: 5| Step: 5
Training loss: 2.0121236745466575
Validation loss: 2.6310181431770028

Epoch: 5| Step: 6
Training loss: 1.7882162033123452
Validation loss: 2.623741730102523

Epoch: 5| Step: 7
Training loss: 2.2947476454806983
Validation loss: 2.6124914560071812

Epoch: 5| Step: 8
Training loss: 1.5178936368898732
Validation loss: 2.6093694759165755

Epoch: 5| Step: 9
Training loss: 2.5689806980760683
Validation loss: 2.569107828486281

Epoch: 5| Step: 10
Training loss: 1.6386899890284958
Validation loss: 2.56109406506839

Epoch: 5| Step: 11
Training loss: 1.8068763043066731
Validation loss: 2.520284428748599

Epoch: 372| Step: 0
Training loss: 2.068966755647398
Validation loss: 2.513731652699821

Epoch: 5| Step: 1
Training loss: 2.5752588234607603
Validation loss: 2.517609597288817

Epoch: 5| Step: 2
Training loss: 2.0284336225572197
Validation loss: 2.4886443423654887

Epoch: 5| Step: 3
Training loss: 2.454703630944372
Validation loss: 2.506528147184736

Epoch: 5| Step: 4
Training loss: 1.96019995447958
Validation loss: 2.498027062753826

Epoch: 5| Step: 5
Training loss: 1.9787068552312668
Validation loss: 2.519540984852045

Epoch: 5| Step: 6
Training loss: 1.9219106035113611
Validation loss: 2.5155658359559965

Epoch: 5| Step: 7
Training loss: 1.5945036359131282
Validation loss: 2.5236212286579844

Epoch: 5| Step: 8
Training loss: 1.3601413189168714
Validation loss: 2.601470143737973

Epoch: 5| Step: 9
Training loss: 1.718171039518132
Validation loss: 2.6188574061070176

Epoch: 5| Step: 10
Training loss: 1.638351245379914
Validation loss: 2.6070530319790013

Epoch: 5| Step: 11
Training loss: 2.0975869165537713
Validation loss: 2.6263855312683906

Epoch: 373| Step: 0
Training loss: 2.18028945541068
Validation loss: 2.641192467413907

Epoch: 5| Step: 1
Training loss: 1.6884363190602507
Validation loss: 2.5982653369860165

Epoch: 5| Step: 2
Training loss: 2.2474456699071883
Validation loss: 2.557671319991453

Epoch: 5| Step: 3
Training loss: 1.9496396514308787
Validation loss: 2.5289242542385275

Epoch: 5| Step: 4
Training loss: 1.935887496339412
Validation loss: 2.526816209374465

Epoch: 5| Step: 5
Training loss: 2.4265860728969098
Validation loss: 2.5569263179145065

Epoch: 5| Step: 6
Training loss: 1.8439165460399138
Validation loss: 2.5553725565531504

Epoch: 5| Step: 7
Training loss: 1.512342615057181
Validation loss: 2.598324151089169

Epoch: 5| Step: 8
Training loss: 2.0073818828565244
Validation loss: 2.5826360135667747

Epoch: 5| Step: 9
Training loss: 1.6757054167264127
Validation loss: 2.5962363777237942

Epoch: 5| Step: 10
Training loss: 1.9517001638733051
Validation loss: 2.5916173279124837

Epoch: 5| Step: 11
Training loss: 1.0282507544138428
Validation loss: 2.598263505595248

Epoch: 374| Step: 0
Training loss: 1.7050196756698695
Validation loss: 2.5845220020435384

Epoch: 5| Step: 1
Training loss: 2.230135329891468
Validation loss: 2.5523957833259208

Epoch: 5| Step: 2
Training loss: 1.3546161883635117
Validation loss: 2.562364008636723

Epoch: 5| Step: 3
Training loss: 1.8537732539194274
Validation loss: 2.5236222245795057

Epoch: 5| Step: 4
Training loss: 1.7545687437420978
Validation loss: 2.5471553843178745

Epoch: 5| Step: 5
Training loss: 2.1019366190144755
Validation loss: 2.549924175843024

Epoch: 5| Step: 6
Training loss: 1.7277671788426496
Validation loss: 2.5767327335120034

Epoch: 5| Step: 7
Training loss: 2.054010431978205
Validation loss: 2.545050708772072

Epoch: 5| Step: 8
Training loss: 1.9638385969800072
Validation loss: 2.586498940976502

Epoch: 5| Step: 9
Training loss: 2.216355979868372
Validation loss: 2.5721964130441064

Epoch: 5| Step: 10
Training loss: 2.2887301154864073
Validation loss: 2.5842603332838445

Epoch: 5| Step: 11
Training loss: 1.3499003868086084
Validation loss: 2.622119994494964

Epoch: 375| Step: 0
Training loss: 1.6532674601850168
Validation loss: 2.6345218803031454

Epoch: 5| Step: 1
Training loss: 1.8117442693060413
Validation loss: 2.6692080470198465

Epoch: 5| Step: 2
Training loss: 1.9661437449328383
Validation loss: 2.657747486088554

Epoch: 5| Step: 3
Training loss: 2.1059521065434827
Validation loss: 2.6101085712912147

Epoch: 5| Step: 4
Training loss: 1.946469311519045
Validation loss: 2.607570237261909

Epoch: 5| Step: 5
Training loss: 1.3261767739836106
Validation loss: 2.587987930099951

Epoch: 5| Step: 6
Training loss: 2.339338397698489
Validation loss: 2.554292778606507

Epoch: 5| Step: 7
Training loss: 2.246373432824767
Validation loss: 2.5104254027303012

Epoch: 5| Step: 8
Training loss: 2.340378841805092
Validation loss: 2.4998221532823144

Epoch: 5| Step: 9
Training loss: 1.5063279507675849
Validation loss: 2.5144667081380567

Epoch: 5| Step: 10
Training loss: 1.8589603378431585
Validation loss: 2.494043705311039

Epoch: 5| Step: 11
Training loss: 1.8532027693024826
Validation loss: 2.5072056203376984

Epoch: 376| Step: 0
Training loss: 1.1340156217101212
Validation loss: 2.5465830653155197

Epoch: 5| Step: 1
Training loss: 1.775677446922107
Validation loss: 2.615882453264856

Epoch: 5| Step: 2
Training loss: 1.7166389679140133
Validation loss: 2.6775109670659605

Epoch: 5| Step: 3
Training loss: 2.0690825641617385
Validation loss: 2.6622518089441845

Epoch: 5| Step: 4
Training loss: 2.1598540330945752
Validation loss: 2.638834713218012

Epoch: 5| Step: 5
Training loss: 2.061140942022073
Validation loss: 2.6455210528975877

Epoch: 5| Step: 6
Training loss: 2.6240426997339155
Validation loss: 2.640528103406852

Epoch: 5| Step: 7
Training loss: 1.5984143834386224
Validation loss: 2.610653143540713

Epoch: 5| Step: 8
Training loss: 1.4403664578283244
Validation loss: 2.5909527436713113

Epoch: 5| Step: 9
Training loss: 1.7084378311327162
Validation loss: 2.5707868043737556

Epoch: 5| Step: 10
Training loss: 2.5697613620916955
Validation loss: 2.54722271829344

Epoch: 5| Step: 11
Training loss: 1.5208677871494187
Validation loss: 2.554417344098512

Epoch: 377| Step: 0
Training loss: 2.4043803692473396
Validation loss: 2.5767325137592354

Epoch: 5| Step: 1
Training loss: 2.319579756921124
Validation loss: 2.5458720285957672

Epoch: 5| Step: 2
Training loss: 2.000628015145887
Validation loss: 2.582675886070104

Epoch: 5| Step: 3
Training loss: 1.5848879794418123
Validation loss: 2.562584208833849

Epoch: 5| Step: 4
Training loss: 1.8974943604718464
Validation loss: 2.566527330396101

Epoch: 5| Step: 5
Training loss: 1.4887243697540964
Validation loss: 2.572669242565819

Epoch: 5| Step: 6
Training loss: 1.6471056145144398
Validation loss: 2.554291642965343

Epoch: 5| Step: 7
Training loss: 1.7823661519606884
Validation loss: 2.580234716314145

Epoch: 5| Step: 8
Training loss: 1.7609369611358494
Validation loss: 2.556700707475902

Epoch: 5| Step: 9
Training loss: 1.928504364926554
Validation loss: 2.5543797119945912

Epoch: 5| Step: 10
Training loss: 2.0292247359200086
Validation loss: 2.5475792915413082

Epoch: 5| Step: 11
Training loss: 1.1913451132175057
Validation loss: 2.537842587582048

Epoch: 378| Step: 0
Training loss: 1.564229542046557
Validation loss: 2.5793219051776726

Epoch: 5| Step: 1
Training loss: 1.806509312161988
Validation loss: 2.5992289818227063

Epoch: 5| Step: 2
Training loss: 1.8209372172920895
Validation loss: 2.5959978321443056

Epoch: 5| Step: 3
Training loss: 1.6627492961546526
Validation loss: 2.5818936863899196

Epoch: 5| Step: 4
Training loss: 2.1563976071462796
Validation loss: 2.5661974647323733

Epoch: 5| Step: 5
Training loss: 2.1627746495822184
Validation loss: 2.5901789843821503

Epoch: 5| Step: 6
Training loss: 1.610305887272007
Validation loss: 2.583948309568117

Epoch: 5| Step: 7
Training loss: 1.6121269326794068
Validation loss: 2.591917715966293

Epoch: 5| Step: 8
Training loss: 2.134552298424537
Validation loss: 2.572095833989062

Epoch: 5| Step: 9
Training loss: 1.7949615905817646
Validation loss: 2.5949962065723504

Epoch: 5| Step: 10
Training loss: 1.6309689422167009
Validation loss: 2.5637623112378436

Epoch: 5| Step: 11
Training loss: 3.663367492220326
Validation loss: 2.571443337963863

Epoch: 379| Step: 0
Training loss: 1.8000466923485652
Validation loss: 2.5790209744973533

Epoch: 5| Step: 1
Training loss: 1.9049414223703451
Validation loss: 2.5688687669101347

Epoch: 5| Step: 2
Training loss: 1.943885739606688
Validation loss: 2.582072374532886

Epoch: 5| Step: 3
Training loss: 1.9642141254805456
Validation loss: 2.540555886489466

Epoch: 5| Step: 4
Training loss: 2.038665849830625
Validation loss: 2.5610513701772653

Epoch: 5| Step: 5
Training loss: 1.9459247161950106
Validation loss: 2.569924183183623

Epoch: 5| Step: 6
Training loss: 1.8248713957531932
Validation loss: 2.5708243392826167

Epoch: 5| Step: 7
Training loss: 1.8827241742322223
Validation loss: 2.5763213774880414

Epoch: 5| Step: 8
Training loss: 1.8945915291231885
Validation loss: 2.6005399525389885

Epoch: 5| Step: 9
Training loss: 1.472465442064132
Validation loss: 2.6003838161069734

Epoch: 5| Step: 10
Training loss: 2.141951658036425
Validation loss: 2.6091443338680107

Epoch: 5| Step: 11
Training loss: 1.9780234866739117
Validation loss: 2.57204604895276

Epoch: 380| Step: 0
Training loss: 1.676973074690618
Validation loss: 2.6190912107869297

Epoch: 5| Step: 1
Training loss: 1.9001224403080532
Validation loss: 2.614726333709717

Epoch: 5| Step: 2
Training loss: 1.988756224252682
Validation loss: 2.625191208520919

Epoch: 5| Step: 3
Training loss: 2.240285990884505
Validation loss: 2.6075648769830697

Epoch: 5| Step: 4
Training loss: 1.5208647302321743
Validation loss: 2.595703523022057

Epoch: 5| Step: 5
Training loss: 1.5959370137025874
Validation loss: 2.5734440357007133

Epoch: 5| Step: 6
Training loss: 1.4505968148165373
Validation loss: 2.5886106130115536

Epoch: 5| Step: 7
Training loss: 2.0906312403564375
Validation loss: 2.5806280566032886

Epoch: 5| Step: 8
Training loss: 1.5951503510599156
Validation loss: 2.572075089697329

Epoch: 5| Step: 9
Training loss: 2.3836248295150937
Validation loss: 2.58274498643771

Epoch: 5| Step: 10
Training loss: 2.0070313592883267
Validation loss: 2.6066901067123363

Epoch: 5| Step: 11
Training loss: 2.368555762547944
Validation loss: 2.6166995471409114

Epoch: 381| Step: 0
Training loss: 1.475290386258041
Validation loss: 2.6288468503925166

Epoch: 5| Step: 1
Training loss: 1.605210332190548
Validation loss: 2.6528754022176133

Epoch: 5| Step: 2
Training loss: 2.6189957023197903
Validation loss: 2.6135920979780862

Epoch: 5| Step: 3
Training loss: 2.1574082511763164
Validation loss: 2.6009662926359827

Epoch: 5| Step: 4
Training loss: 1.83374691401913
Validation loss: 2.596583316425863

Epoch: 5| Step: 5
Training loss: 1.6550295669818798
Validation loss: 2.569788476462382

Epoch: 5| Step: 6
Training loss: 1.8501386358535545
Validation loss: 2.555291239630699

Epoch: 5| Step: 7
Training loss: 2.120931995048028
Validation loss: 2.5417895183160715

Epoch: 5| Step: 8
Training loss: 1.727721088797335
Validation loss: 2.5371069238820714

Epoch: 5| Step: 9
Training loss: 2.00422829462522
Validation loss: 2.521390712740833

Epoch: 5| Step: 10
Training loss: 1.6164506348406402
Validation loss: 2.5807335035875965

Epoch: 5| Step: 11
Training loss: 1.2536323224385493
Validation loss: 2.5782851872626873

Epoch: 382| Step: 0
Training loss: 1.5238276055517732
Validation loss: 2.5783380054373186

Epoch: 5| Step: 1
Training loss: 2.074519995816674
Validation loss: 2.5914671764125274

Epoch: 5| Step: 2
Training loss: 2.223384905345202
Validation loss: 2.582486761237078

Epoch: 5| Step: 3
Training loss: 1.91816614071456
Validation loss: 2.5733309745551285

Epoch: 5| Step: 4
Training loss: 2.7807813956859793
Validation loss: 2.5794067125255817

Epoch: 5| Step: 5
Training loss: 2.142050164270202
Validation loss: 2.59577676569584

Epoch: 5| Step: 6
Training loss: 1.6167465567103099
Validation loss: 2.606086291745001

Epoch: 5| Step: 7
Training loss: 1.3222744151151467
Validation loss: 2.6373946164307136

Epoch: 5| Step: 8
Training loss: 1.5613467729078558
Validation loss: 2.6035563910980306

Epoch: 5| Step: 9
Training loss: 1.2100631018018884
Validation loss: 2.590447241893286

Epoch: 5| Step: 10
Training loss: 1.408019160980197
Validation loss: 2.530175817057417

Epoch: 5| Step: 11
Training loss: 2.784368502591106
Validation loss: 2.5287630713353315

Epoch: 383| Step: 0
Training loss: 1.7618081351397363
Validation loss: 2.4894732340538175

Epoch: 5| Step: 1
Training loss: 1.3408334707793899
Validation loss: 2.51518581734715

Epoch: 5| Step: 2
Training loss: 1.7274915172186456
Validation loss: 2.5235065415329534

Epoch: 5| Step: 3
Training loss: 2.242028420151622
Validation loss: 2.501933101481612

Epoch: 5| Step: 4
Training loss: 1.7196055970330912
Validation loss: 2.519879118490065

Epoch: 5| Step: 5
Training loss: 1.9841862385999613
Validation loss: 2.5117980011123966

Epoch: 5| Step: 6
Training loss: 2.005587402447827
Validation loss: 2.5519966396216986

Epoch: 5| Step: 7
Training loss: 1.6686194979612459
Validation loss: 2.585733173207793

Epoch: 5| Step: 8
Training loss: 2.0354430130262413
Validation loss: 2.5925393170668043

Epoch: 5| Step: 9
Training loss: 2.3118679110667664
Validation loss: 2.6209857708083715

Epoch: 5| Step: 10
Training loss: 1.7071951431754115
Validation loss: 2.587707624382862

Epoch: 5| Step: 11
Training loss: 1.2855507381431006
Validation loss: 2.577843691188245

Epoch: 384| Step: 0
Training loss: 1.6269414015183858
Validation loss: 2.5831145737427823

Epoch: 5| Step: 1
Training loss: 1.4798603669873822
Validation loss: 2.605781197103108

Epoch: 5| Step: 2
Training loss: 1.7010775516958494
Validation loss: 2.612267777131665

Epoch: 5| Step: 3
Training loss: 1.3847752666272242
Validation loss: 2.594005001509126

Epoch: 5| Step: 4
Training loss: 1.699878923929015
Validation loss: 2.6199922895621395

Epoch: 5| Step: 5
Training loss: 2.3079191664915037
Validation loss: 2.583658522217011

Epoch: 5| Step: 6
Training loss: 2.2427431275438163
Validation loss: 2.581091613158997

Epoch: 5| Step: 7
Training loss: 1.8055958629249769
Validation loss: 2.6225551391419715

Epoch: 5| Step: 8
Training loss: 2.4338239680307283
Validation loss: 2.5872740350485923

Epoch: 5| Step: 9
Training loss: 1.6792601285659943
Validation loss: 2.6168187218472703

Epoch: 5| Step: 10
Training loss: 2.077062234672539
Validation loss: 2.6138801933724545

Epoch: 5| Step: 11
Training loss: 1.410373068755022
Validation loss: 2.6228122601523567

Epoch: 385| Step: 0
Training loss: 1.9158118525569214
Validation loss: 2.6411160176185935

Epoch: 5| Step: 1
Training loss: 2.0213356442492785
Validation loss: 2.5923944266890735

Epoch: 5| Step: 2
Training loss: 2.0584461948274266
Validation loss: 2.58181434370486

Epoch: 5| Step: 3
Training loss: 1.7926104152195992
Validation loss: 2.5601439189254998

Epoch: 5| Step: 4
Training loss: 1.9553815089907967
Validation loss: 2.590162987306107

Epoch: 5| Step: 5
Training loss: 1.530965116819801
Validation loss: 2.596184560783353

Epoch: 5| Step: 6
Training loss: 1.7810929881714284
Validation loss: 2.5858762124934445

Epoch: 5| Step: 7
Training loss: 1.995299657244116
Validation loss: 2.5572027448640835

Epoch: 5| Step: 8
Training loss: 1.7042612607611047
Validation loss: 2.5543397400378383

Epoch: 5| Step: 9
Training loss: 1.9985301457837876
Validation loss: 2.549136026037638

Epoch: 5| Step: 10
Training loss: 1.6491149667298612
Validation loss: 2.5501023966980467

Epoch: 5| Step: 11
Training loss: 0.9575657189029202
Validation loss: 2.549420783076109

Epoch: 386| Step: 0
Training loss: 2.1329924678678442
Validation loss: 2.546215923819777

Epoch: 5| Step: 1
Training loss: 1.0153840586159475
Validation loss: 2.5477239640903537

Epoch: 5| Step: 2
Training loss: 1.912583507634513
Validation loss: 2.5677356499282187

Epoch: 5| Step: 3
Training loss: 2.31887207532481
Validation loss: 2.5855754933125623

Epoch: 5| Step: 4
Training loss: 1.5046000676090296
Validation loss: 2.5990092183994533

Epoch: 5| Step: 5
Training loss: 2.029173391071225
Validation loss: 2.5981803499183234

Epoch: 5| Step: 6
Training loss: 2.2724761503371864
Validation loss: 2.5974875067874574

Epoch: 5| Step: 7
Training loss: 1.72119036735341
Validation loss: 2.622680411228934

Epoch: 5| Step: 8
Training loss: 1.6865996325343748
Validation loss: 2.5835769189825246

Epoch: 5| Step: 9
Training loss: 1.8424956370577663
Validation loss: 2.581945182223799

Epoch: 5| Step: 10
Training loss: 1.4813468965795897
Validation loss: 2.544492324720328

Epoch: 5| Step: 11
Training loss: 2.911124458800074
Validation loss: 2.555506086101038

Epoch: 387| Step: 0
Training loss: 2.213197988121543
Validation loss: 2.53278975102953

Epoch: 5| Step: 1
Training loss: 2.299485986741962
Validation loss: 2.518834733918157

Epoch: 5| Step: 2
Training loss: 1.8304520492671033
Validation loss: 2.510369123639177

Epoch: 5| Step: 3
Training loss: 1.7144571272550617
Validation loss: 2.5212834852167134

Epoch: 5| Step: 4
Training loss: 1.8134112862469365
Validation loss: 2.503390925200389

Epoch: 5| Step: 5
Training loss: 1.2968404374630125
Validation loss: 2.519028661314727

Epoch: 5| Step: 6
Training loss: 1.9354744444381697
Validation loss: 2.5142904497154652

Epoch: 5| Step: 7
Training loss: 1.7472178278013493
Validation loss: 2.501694688991617

Epoch: 5| Step: 8
Training loss: 1.5779320627244935
Validation loss: 2.501343048464542

Epoch: 5| Step: 9
Training loss: 2.228254351399052
Validation loss: 2.5200743215629005

Epoch: 5| Step: 10
Training loss: 1.1481396035733278
Validation loss: 2.5124229009701664

Epoch: 5| Step: 11
Training loss: 3.1499495366005283
Validation loss: 2.564313688649314

Epoch: 388| Step: 0
Training loss: 2.1115166988376424
Validation loss: 2.569439953436378

Epoch: 5| Step: 1
Training loss: 1.648182998464185
Validation loss: 2.566836254804894

Epoch: 5| Step: 2
Training loss: 1.923920697923434
Validation loss: 2.598868761576794

Epoch: 5| Step: 3
Training loss: 1.7750380095589582
Validation loss: 2.5920743355357

Epoch: 5| Step: 4
Training loss: 1.6942902748484885
Validation loss: 2.6111949923808275

Epoch: 5| Step: 5
Training loss: 2.0704761368482507
Validation loss: 2.5571941945029035

Epoch: 5| Step: 6
Training loss: 1.3964231677746988
Validation loss: 2.513765828812948

Epoch: 5| Step: 7
Training loss: 1.8184291281264042
Validation loss: 2.5636334277402035

Epoch: 5| Step: 8
Training loss: 1.9423910364252122
Validation loss: 2.4992792620442748

Epoch: 5| Step: 9
Training loss: 1.0132996568500596
Validation loss: 2.5095792431528587

Epoch: 5| Step: 10
Training loss: 2.6720843316778278
Validation loss: 2.5035511743056498

Epoch: 5| Step: 11
Training loss: 1.3652414040664231
Validation loss: 2.4837507267314

Epoch: 389| Step: 0
Training loss: 1.9757139171079472
Validation loss: 2.526098311008729

Epoch: 5| Step: 1
Training loss: 1.868431985390464
Validation loss: 2.54254473829715

Epoch: 5| Step: 2
Training loss: 1.756171515940883
Validation loss: 2.5995922513188123

Epoch: 5| Step: 3
Training loss: 1.7767065897327436
Validation loss: 2.588181846115347

Epoch: 5| Step: 4
Training loss: 1.563029847907723
Validation loss: 2.6252702657139393

Epoch: 5| Step: 5
Training loss: 2.011609120761343
Validation loss: 2.6048900489642737

Epoch: 5| Step: 6
Training loss: 1.5163761126094601
Validation loss: 2.6102608225994834

Epoch: 5| Step: 7
Training loss: 1.6219422842780358
Validation loss: 2.55953730300291

Epoch: 5| Step: 8
Training loss: 1.6801593916076163
Validation loss: 2.541123419431703

Epoch: 5| Step: 9
Training loss: 1.3939232876739884
Validation loss: 2.537659356166806

Epoch: 5| Step: 10
Training loss: 3.0376798725637153
Validation loss: 2.557787609503552

Epoch: 5| Step: 11
Training loss: 1.276356773655035
Validation loss: 2.535473300679547

Epoch: 390| Step: 0
Training loss: 1.5284767728918145
Validation loss: 2.582851702774732

Epoch: 5| Step: 1
Training loss: 1.6331136325421585
Validation loss: 2.5916168525994716

Epoch: 5| Step: 2
Training loss: 1.8909642569332572
Validation loss: 2.6116548845913523

Epoch: 5| Step: 3
Training loss: 1.834126849830603
Validation loss: 2.616907619105686

Epoch: 5| Step: 4
Training loss: 1.491822282924872
Validation loss: 2.627463070748759

Epoch: 5| Step: 5
Training loss: 2.0469637553067592
Validation loss: 2.6563389295763264

Epoch: 5| Step: 6
Training loss: 1.902752591482324
Validation loss: 2.6468971484209773

Epoch: 5| Step: 7
Training loss: 2.0128746489578013
Validation loss: 2.6353244777934837

Epoch: 5| Step: 8
Training loss: 1.5643841636593547
Validation loss: 2.632895856041476

Epoch: 5| Step: 9
Training loss: 2.2164937757408545
Validation loss: 2.573788496461059

Epoch: 5| Step: 10
Training loss: 1.5058207426545793
Validation loss: 2.5568465773293307

Epoch: 5| Step: 11
Training loss: 2.642692884841852
Validation loss: 2.5393017621894036

Epoch: 391| Step: 0
Training loss: 1.7086583812962728
Validation loss: 2.518410082804043

Epoch: 5| Step: 1
Training loss: 2.0602786499742094
Validation loss: 2.48738388177081

Epoch: 5| Step: 2
Training loss: 1.7873524318150398
Validation loss: 2.5419827105804322

Epoch: 5| Step: 3
Training loss: 2.2630274121035585
Validation loss: 2.5658052186787437

Epoch: 5| Step: 4
Training loss: 2.3674923539969734
Validation loss: 2.5232796398188175

Epoch: 5| Step: 5
Training loss: 1.7276827944862008
Validation loss: 2.528300364211682

Epoch: 5| Step: 6
Training loss: 1.9302968904698743
Validation loss: 2.49431886685801

Epoch: 5| Step: 7
Training loss: 1.7941777427084586
Validation loss: 2.487591115282796

Epoch: 5| Step: 8
Training loss: 1.9916917969569368
Validation loss: 2.490132946865924

Epoch: 5| Step: 9
Training loss: 1.5495089829939375
Validation loss: 2.5345936049456466

Epoch: 5| Step: 10
Training loss: 1.1860337490985888
Validation loss: 2.5611766096094097

Epoch: 5| Step: 11
Training loss: 0.7538382544021289
Validation loss: 2.5801711237758664

Epoch: 392| Step: 0
Training loss: 1.9171107095699516
Validation loss: 2.6103992279416053

Epoch: 5| Step: 1
Training loss: 2.0677395937564023
Validation loss: 2.5880072954857227

Epoch: 5| Step: 2
Training loss: 2.0004556852017017
Validation loss: 2.664702539011949

Epoch: 5| Step: 3
Training loss: 1.7049708731392375
Validation loss: 2.6606397408801485

Epoch: 5| Step: 4
Training loss: 1.583374508104845
Validation loss: 2.6612293526872963

Epoch: 5| Step: 5
Training loss: 1.7749493578281648
Validation loss: 2.608990650461692

Epoch: 5| Step: 6
Training loss: 2.1755408217559293
Validation loss: 2.584337819195989

Epoch: 5| Step: 7
Training loss: 2.051114068045826
Validation loss: 2.560535825642

Epoch: 5| Step: 8
Training loss: 1.4982362550397474
Validation loss: 2.5412368502185188

Epoch: 5| Step: 9
Training loss: 1.6439859025169774
Validation loss: 2.5009272842487755

Epoch: 5| Step: 10
Training loss: 2.044648218653569
Validation loss: 2.486342676544159

Epoch: 5| Step: 11
Training loss: 1.658758602853068
Validation loss: 2.476699592654701

Epoch: 393| Step: 0
Training loss: 1.8617457814881484
Validation loss: 2.480814545725461

Epoch: 5| Step: 1
Training loss: 1.9603569113542587
Validation loss: 2.483739991675839

Epoch: 5| Step: 2
Training loss: 1.7959605004527246
Validation loss: 2.464437819081816

Epoch: 5| Step: 3
Training loss: 1.6950733350120064
Validation loss: 2.489594444877908

Epoch: 5| Step: 4
Training loss: 1.8563625391487408
Validation loss: 2.480961079435569

Epoch: 5| Step: 5
Training loss: 2.2614715388360684
Validation loss: 2.5145405511026864

Epoch: 5| Step: 6
Training loss: 1.8997324228097325
Validation loss: 2.5626595687805955

Epoch: 5| Step: 7
Training loss: 1.7526675057455738
Validation loss: 2.5719937523842114

Epoch: 5| Step: 8
Training loss: 1.541869880411086
Validation loss: 2.5789734763930854

Epoch: 5| Step: 9
Training loss: 1.9971279742210462
Validation loss: 2.5749315809832782

Epoch: 5| Step: 10
Training loss: 1.7788327864939717
Validation loss: 2.5920102707863935

Epoch: 5| Step: 11
Training loss: 1.4714315568494205
Validation loss: 2.6324623810862753

Epoch: 394| Step: 0
Training loss: 1.2607781651074201
Validation loss: 2.5610882739342755

Epoch: 5| Step: 1
Training loss: 1.0031079632509654
Validation loss: 2.544296133071123

Epoch: 5| Step: 2
Training loss: 1.786249205987539
Validation loss: 2.555535668546817

Epoch: 5| Step: 3
Training loss: 1.2808333393974694
Validation loss: 2.5461465538833443

Epoch: 5| Step: 4
Training loss: 1.9325697528247412
Validation loss: 2.5501403237048805

Epoch: 5| Step: 5
Training loss: 2.4682715229930157
Validation loss: 2.5547771613109416

Epoch: 5| Step: 6
Training loss: 2.50934570599437
Validation loss: 2.603226134528817

Epoch: 5| Step: 7
Training loss: 1.9003004187946553
Validation loss: 2.5913956845972543

Epoch: 5| Step: 8
Training loss: 2.0987336927533575
Validation loss: 2.632852446482268

Epoch: 5| Step: 9
Training loss: 1.9212120587506005
Validation loss: 2.676185039116124

Epoch: 5| Step: 10
Training loss: 1.5571093075064035
Validation loss: 2.7107749069368037

Epoch: 5| Step: 11
Training loss: 0.970130490541496
Validation loss: 2.674790893831094

Epoch: 395| Step: 0
Training loss: 2.1307578897478945
Validation loss: 2.6225657226526216

Epoch: 5| Step: 1
Training loss: 2.4966649698812766
Validation loss: 2.5879772051837175

Epoch: 5| Step: 2
Training loss: 1.5295975780455915
Validation loss: 2.546496080322015

Epoch: 5| Step: 3
Training loss: 1.5209779888318524
Validation loss: 2.4965156572714133

Epoch: 5| Step: 4
Training loss: 2.0449718917369952
Validation loss: 2.4611858182087785

Epoch: 5| Step: 5
Training loss: 1.9109710640505653
Validation loss: 2.4787321644915803

Epoch: 5| Step: 6
Training loss: 1.830844519188449
Validation loss: 2.460379938007052

Epoch: 5| Step: 7
Training loss: 1.5009293855935828
Validation loss: 2.5038589734927195

Epoch: 5| Step: 8
Training loss: 1.8333068831298602
Validation loss: 2.4819684558706196

Epoch: 5| Step: 9
Training loss: 1.4472422321194802
Validation loss: 2.539070184158044

Epoch: 5| Step: 10
Training loss: 1.8669949356443578
Validation loss: 2.5445899776232284

Epoch: 5| Step: 11
Training loss: 1.2749346024439971
Validation loss: 2.5974411342340282

Epoch: 396| Step: 0
Training loss: 1.6251109158736217
Validation loss: 2.590881339268811

Epoch: 5| Step: 1
Training loss: 1.276310774264984
Validation loss: 2.5932117118076903

Epoch: 5| Step: 2
Training loss: 2.4265126770367527
Validation loss: 2.578259533926563

Epoch: 5| Step: 3
Training loss: 1.7944087477021382
Validation loss: 2.6040962107982084

Epoch: 5| Step: 4
Training loss: 1.49776602329323
Validation loss: 2.6285480181506005

Epoch: 5| Step: 5
Training loss: 1.7221288587359858
Validation loss: 2.6393376547438465

Epoch: 5| Step: 6
Training loss: 1.438193527107595
Validation loss: 2.650916815455245

Epoch: 5| Step: 7
Training loss: 1.7121312405693296
Validation loss: 2.6475552089843486

Epoch: 5| Step: 8
Training loss: 2.147356905982595
Validation loss: 2.62513721576701

Epoch: 5| Step: 9
Training loss: 2.343947542130845
Validation loss: 2.58524062648326

Epoch: 5| Step: 10
Training loss: 1.665975411434
Validation loss: 2.5225629875717144

Epoch: 5| Step: 11
Training loss: 1.5741457484430432
Validation loss: 2.5143258272401443

Epoch: 397| Step: 0
Training loss: 2.0528196249989334
Validation loss: 2.50969413131036

Epoch: 5| Step: 1
Training loss: 2.0028049350166506
Validation loss: 2.49111224888335

Epoch: 5| Step: 2
Training loss: 1.868080213053916
Validation loss: 2.466766556578409

Epoch: 5| Step: 3
Training loss: 1.3667921966184848
Validation loss: 2.4619061819069192

Epoch: 5| Step: 4
Training loss: 1.4909581417908786
Validation loss: 2.475384416974232

Epoch: 5| Step: 5
Training loss: 2.230589854999526
Validation loss: 2.4913262659940174

Epoch: 5| Step: 6
Training loss: 1.7717215685204246
Validation loss: 2.5442998227849984

Epoch: 5| Step: 7
Training loss: 2.1358395289602723
Validation loss: 2.5169503055822777

Epoch: 5| Step: 8
Training loss: 1.7755437770206686
Validation loss: 2.533917806884069

Epoch: 5| Step: 9
Training loss: 1.916946045237148
Validation loss: 2.476322722033908

Epoch: 5| Step: 10
Training loss: 1.6776714202118235
Validation loss: 2.4791805697032565

Epoch: 5| Step: 11
Training loss: 1.6146122427372378
Validation loss: 2.533371389619767

Epoch: 398| Step: 0
Training loss: 1.8486595091426135
Validation loss: 2.592746168856478

Epoch: 5| Step: 1
Training loss: 1.5964566602884405
Validation loss: 2.5824141379599053

Epoch: 5| Step: 2
Training loss: 1.9801652363504245
Validation loss: 2.565070990849748

Epoch: 5| Step: 3
Training loss: 1.5699363751488087
Validation loss: 2.58515651776276

Epoch: 5| Step: 4
Training loss: 1.8818190870337306
Validation loss: 2.579242383238888

Epoch: 5| Step: 5
Training loss: 1.26547668906709
Validation loss: 2.5991584698224828

Epoch: 5| Step: 6
Training loss: 1.7650364257684743
Validation loss: 2.606362067206136

Epoch: 5| Step: 7
Training loss: 1.9237843155108607
Validation loss: 2.6153228892930094

Epoch: 5| Step: 8
Training loss: 1.6007356323474367
Validation loss: 2.6518728206139177

Epoch: 5| Step: 9
Training loss: 2.336339807473195
Validation loss: 2.6827904185069738

Epoch: 5| Step: 10
Training loss: 2.022544870149985
Validation loss: 2.6824844525631177

Epoch: 5| Step: 11
Training loss: 3.371499966472754
Validation loss: 2.6443198536047188

Epoch: 399| Step: 0
Training loss: 1.6772320209562455
Validation loss: 2.6081319139841295

Epoch: 5| Step: 1
Training loss: 1.4155526923771649
Validation loss: 2.6074294986684836

Epoch: 5| Step: 2
Training loss: 2.270033762676539
Validation loss: 2.550785537879693

Epoch: 5| Step: 3
Training loss: 1.2181026989464656
Validation loss: 2.5029595976436623

Epoch: 5| Step: 4
Training loss: 1.9858197337122585
Validation loss: 2.5109947410916074

Epoch: 5| Step: 5
Training loss: 1.7237904938498216
Validation loss: 2.4877735100990623

Epoch: 5| Step: 6
Training loss: 1.796735210786173
Validation loss: 2.468399296569683

Epoch: 5| Step: 7
Training loss: 1.7790488982103643
Validation loss: 2.452774533062876

Epoch: 5| Step: 8
Training loss: 1.6798873427629009
Validation loss: 2.4691821899037683

Epoch: 5| Step: 9
Training loss: 1.8963700327794033
Validation loss: 2.5457789904345325

Epoch: 5| Step: 10
Training loss: 1.9445913425844878
Validation loss: 2.5528255408424783

Epoch: 5| Step: 11
Training loss: 1.6486505307494015
Validation loss: 2.6121533539571793

Epoch: 400| Step: 0
Training loss: 1.7466291251164214
Validation loss: 2.5710172836754452

Epoch: 5| Step: 1
Training loss: 1.7951629443578803
Validation loss: 2.6026969437128726

Epoch: 5| Step: 2
Training loss: 1.3873943993187985
Validation loss: 2.5923205462054497

Epoch: 5| Step: 3
Training loss: 1.7396977857145526
Validation loss: 2.56714550192144

Epoch: 5| Step: 4
Training loss: 2.1750286451185374
Validation loss: 2.531641494239925

Epoch: 5| Step: 5
Training loss: 2.569840500925167
Validation loss: 2.5135406404554534

Epoch: 5| Step: 6
Training loss: 1.450135303630054
Validation loss: 2.550840999259841

Epoch: 5| Step: 7
Training loss: 1.5865836494964156
Validation loss: 2.5703848120383648

Epoch: 5| Step: 8
Training loss: 1.578887151105263
Validation loss: 2.5554237626882896

Epoch: 5| Step: 9
Training loss: 1.4056232327203764
Validation loss: 2.541457721975827

Epoch: 5| Step: 10
Training loss: 1.4441318122691869
Validation loss: 2.530530073665935

Epoch: 5| Step: 11
Training loss: 3.3196812646752165
Validation loss: 2.5196709527606984

Epoch: 401| Step: 0
Training loss: 1.6332145086519905
Validation loss: 2.5002460378535294

Epoch: 5| Step: 1
Training loss: 1.6811105776697224
Validation loss: 2.4859905648057574

Epoch: 5| Step: 2
Training loss: 1.5114764825251377
Validation loss: 2.4809285896571467

Epoch: 5| Step: 3
Training loss: 2.0336798586294305
Validation loss: 2.4436151587642447

Epoch: 5| Step: 4
Training loss: 2.048221290985948
Validation loss: 2.4869272529549638

Epoch: 5| Step: 5
Training loss: 1.5176868375234702
Validation loss: 2.548588617016522

Epoch: 5| Step: 6
Training loss: 1.7795086430004508
Validation loss: 2.5294346245330863

Epoch: 5| Step: 7
Training loss: 1.3949149322550638
Validation loss: 2.552661839266739

Epoch: 5| Step: 8
Training loss: 1.7856157575400815
Validation loss: 2.5658387553930115

Epoch: 5| Step: 9
Training loss: 2.135671187948807
Validation loss: 2.561181326138331

Epoch: 5| Step: 10
Training loss: 1.979721741052785
Validation loss: 2.5250681439889138

Epoch: 5| Step: 11
Training loss: 2.3950151013752357
Validation loss: 2.562269343873323

Epoch: 402| Step: 0
Training loss: 1.7842781695333252
Validation loss: 2.5633628795786967

Epoch: 5| Step: 1
Training loss: 1.7909953907662894
Validation loss: 2.5136657177292214

Epoch: 5| Step: 2
Training loss: 1.5928639211394362
Validation loss: 2.5329898106181443

Epoch: 5| Step: 3
Training loss: 1.7282020068817088
Validation loss: 2.5641481906319035

Epoch: 5| Step: 4
Training loss: 1.811051414665663
Validation loss: 2.559446151110801

Epoch: 5| Step: 5
Training loss: 2.17284761235596
Validation loss: 2.551846401089537

Epoch: 5| Step: 6
Training loss: 1.4339256629989003
Validation loss: 2.5562268382004776

Epoch: 5| Step: 7
Training loss: 1.412092744299328
Validation loss: 2.5523154380247046

Epoch: 5| Step: 8
Training loss: 2.1675357420547225
Validation loss: 2.5583896740001926

Epoch: 5| Step: 9
Training loss: 1.3704483817399142
Validation loss: 2.5794583311824737

Epoch: 5| Step: 10
Training loss: 1.7805597406749105
Validation loss: 2.5693811586393265

Epoch: 5| Step: 11
Training loss: 1.4300062314144493
Validation loss: 2.546155002836915

Epoch: 403| Step: 0
Training loss: 1.4063005226384382
Validation loss: 2.5863738445770856

Epoch: 5| Step: 1
Training loss: 1.474896818528393
Validation loss: 2.5839296980551687

Epoch: 5| Step: 2
Training loss: 1.959219373640081
Validation loss: 2.58925114022898

Epoch: 5| Step: 3
Training loss: 1.538098648260971
Validation loss: 2.624410790210503

Epoch: 5| Step: 4
Training loss: 1.5668956724491403
Validation loss: 2.599293801183743

Epoch: 5| Step: 5
Training loss: 2.118193440213805
Validation loss: 2.5931280033758926

Epoch: 5| Step: 6
Training loss: 1.3424307979031223
Validation loss: 2.54835924534777

Epoch: 5| Step: 7
Training loss: 1.916580847878288
Validation loss: 2.5699260811559426

Epoch: 5| Step: 8
Training loss: 1.7236828156477486
Validation loss: 2.544916597459912

Epoch: 5| Step: 9
Training loss: 1.8830518768222593
Validation loss: 2.5281073838018244

Epoch: 5| Step: 10
Training loss: 1.805291607303178
Validation loss: 2.535123641671854

Epoch: 5| Step: 11
Training loss: 2.3548491059898513
Validation loss: 2.543577743402736

Epoch: 404| Step: 0
Training loss: 1.6765775766965758
Validation loss: 2.5479091970646666

Epoch: 5| Step: 1
Training loss: 1.8121259895380422
Validation loss: 2.4941551249895877

Epoch: 5| Step: 2
Training loss: 1.500330570670698
Validation loss: 2.575806386229311

Epoch: 5| Step: 3
Training loss: 1.5181413192154587
Validation loss: 2.55399629689513

Epoch: 5| Step: 4
Training loss: 2.166451577979019
Validation loss: 2.53342527554169

Epoch: 5| Step: 5
Training loss: 1.6806259727262418
Validation loss: 2.547040438593244

Epoch: 5| Step: 6
Training loss: 1.837657625872338
Validation loss: 2.5823325107899455

Epoch: 5| Step: 7
Training loss: 2.1231043719215186
Validation loss: 2.626142642934533

Epoch: 5| Step: 8
Training loss: 1.3428861369608875
Validation loss: 2.5908827541096207

Epoch: 5| Step: 9
Training loss: 1.3252032286056858
Validation loss: 2.591120516910552

Epoch: 5| Step: 10
Training loss: 1.7688411352180287
Validation loss: 2.590257556934082

Epoch: 5| Step: 11
Training loss: 1.0892002844979276
Validation loss: 2.5550632375479694

Epoch: 405| Step: 0
Training loss: 1.3536855527660465
Validation loss: 2.5165227784671385

Epoch: 5| Step: 1
Training loss: 1.7287221666634434
Validation loss: 2.5111538067273598

Epoch: 5| Step: 2
Training loss: 2.1867157756516704
Validation loss: 2.506304143699727

Epoch: 5| Step: 3
Training loss: 1.9367027488253687
Validation loss: 2.47209302886711

Epoch: 5| Step: 4
Training loss: 1.3063869714791587
Validation loss: 2.5064605285171573

Epoch: 5| Step: 5
Training loss: 2.504411905205747
Validation loss: 2.4707194090295266

Epoch: 5| Step: 6
Training loss: 1.904825522575193
Validation loss: 2.490380356442932

Epoch: 5| Step: 7
Training loss: 1.8198286731482243
Validation loss: 2.5279104549628624

Epoch: 5| Step: 8
Training loss: 1.531709407477103
Validation loss: 2.6077346957001475

Epoch: 5| Step: 9
Training loss: 1.6044941935233579
Validation loss: 2.682187355506985

Epoch: 5| Step: 10
Training loss: 1.665891618127229
Validation loss: 2.6287024061387343

Epoch: 5| Step: 11
Training loss: 0.9353187617415112
Validation loss: 2.685761277396778

Epoch: 406| Step: 0
Training loss: 1.6324350021064529
Validation loss: 2.719203185900012

Epoch: 5| Step: 1
Training loss: 1.2473465890528346
Validation loss: 2.6572976084759503

Epoch: 5| Step: 2
Training loss: 1.7512025107589226
Validation loss: 2.6129763111206676

Epoch: 5| Step: 3
Training loss: 1.7502772247895313
Validation loss: 2.563774243706234

Epoch: 5| Step: 4
Training loss: 2.354625443398319
Validation loss: 2.5603678524577655

Epoch: 5| Step: 5
Training loss: 1.974197963639891
Validation loss: 2.555418339675944

Epoch: 5| Step: 6
Training loss: 1.1551333009495686
Validation loss: 2.5603969868606438

Epoch: 5| Step: 7
Training loss: 2.3321680383484886
Validation loss: 2.5628603666341414

Epoch: 5| Step: 8
Training loss: 1.866034754446837
Validation loss: 2.5886418817617978

Epoch: 5| Step: 9
Training loss: 1.1836777458979422
Validation loss: 2.556031335433646

Epoch: 5| Step: 10
Training loss: 1.6817995499181038
Validation loss: 2.5382689150385973

Epoch: 5| Step: 11
Training loss: 2.3260569764274197
Validation loss: 2.5747028217923917

Epoch: 407| Step: 0
Training loss: 1.4130359105637926
Validation loss: 2.5301739874233973

Epoch: 5| Step: 1
Training loss: 1.2159870814653622
Validation loss: 2.635246397003846

Epoch: 5| Step: 2
Training loss: 1.5462488005131576
Validation loss: 2.6490314721558437

Epoch: 5| Step: 3
Training loss: 2.0816242328326955
Validation loss: 2.643818742866883

Epoch: 5| Step: 4
Training loss: 1.9531044920798328
Validation loss: 2.635165818279322

Epoch: 5| Step: 5
Training loss: 2.1216889559685477
Validation loss: 2.5645102353889926

Epoch: 5| Step: 6
Training loss: 1.6372962242471085
Validation loss: 2.5316727917010926

Epoch: 5| Step: 7
Training loss: 1.9967946951274524
Validation loss: 2.454792472428929

Epoch: 5| Step: 8
Training loss: 1.6891269611546842
Validation loss: 2.465577515586857

Epoch: 5| Step: 9
Training loss: 2.172433136502586
Validation loss: 2.472770001294389

Epoch: 5| Step: 10
Training loss: 1.7682983280040445
Validation loss: 2.4867847599652704

Epoch: 5| Step: 11
Training loss: 1.176055470676461
Validation loss: 2.4838886504693503

Epoch: 408| Step: 0
Training loss: 1.3348752087048967
Validation loss: 2.502075708479834

Epoch: 5| Step: 1
Training loss: 1.630747314988937
Validation loss: 2.5222199280929587

Epoch: 5| Step: 2
Training loss: 1.9919995387547889
Validation loss: 2.5243143264872328

Epoch: 5| Step: 3
Training loss: 1.4225024840428766
Validation loss: 2.5162107997922774

Epoch: 5| Step: 4
Training loss: 2.0427159577855885
Validation loss: 2.5579276520960814

Epoch: 5| Step: 5
Training loss: 1.9858290984118863
Validation loss: 2.589516405656014

Epoch: 5| Step: 6
Training loss: 1.9559068323971422
Validation loss: 2.634724810156665

Epoch: 5| Step: 7
Training loss: 1.4884407178294181
Validation loss: 2.7339915451752987

Epoch: 5| Step: 8
Training loss: 1.855501258966856
Validation loss: 2.7736099368652023

Epoch: 5| Step: 9
Training loss: 1.7475881987049489
Validation loss: 2.8075295184172524

Epoch: 5| Step: 10
Training loss: 2.0443391889737805
Validation loss: 2.763781193344823

Epoch: 5| Step: 11
Training loss: 0.9355206256919035
Validation loss: 2.653345715613283

Epoch: 409| Step: 0
Training loss: 2.0308802341476615
Validation loss: 2.5319974447220397

Epoch: 5| Step: 1
Training loss: 1.6110822640317475
Validation loss: 2.4972707394219804

Epoch: 5| Step: 2
Training loss: 1.925159531955787
Validation loss: 2.4347725794530826

Epoch: 5| Step: 3
Training loss: 2.2351209555715674
Validation loss: 2.412548248684802

Epoch: 5| Step: 4
Training loss: 2.2956899063900744
Validation loss: 2.4330876591088235

Epoch: 5| Step: 5
Training loss: 1.4430873753932605
Validation loss: 2.4604654414429508

Epoch: 5| Step: 6
Training loss: 1.2011091510554
Validation loss: 2.4483225154594437

Epoch: 5| Step: 7
Training loss: 1.7677109810654414
Validation loss: 2.435405978991637

Epoch: 5| Step: 8
Training loss: 1.6143445074175309
Validation loss: 2.446451220591519

Epoch: 5| Step: 9
Training loss: 1.8225873231833536
Validation loss: 2.4921438039937103

Epoch: 5| Step: 10
Training loss: 1.8135530766875534
Validation loss: 2.482749071025204

Epoch: 5| Step: 11
Training loss: 1.3729869672096984
Validation loss: 2.49985314573661

Epoch: 410| Step: 0
Training loss: 2.1723304106406984
Validation loss: 2.5293872399800237

Epoch: 5| Step: 1
Training loss: 1.9849613554913832
Validation loss: 2.570574923861605

Epoch: 5| Step: 2
Training loss: 1.876239430539466
Validation loss: 2.571594189269245

Epoch: 5| Step: 3
Training loss: 1.4624992631437614
Validation loss: 2.6061361964968386

Epoch: 5| Step: 4
Training loss: 1.414260850346525
Validation loss: 2.545367885179821

Epoch: 5| Step: 5
Training loss: 1.7545541361047303
Validation loss: 2.525161280375524

Epoch: 5| Step: 6
Training loss: 1.6042664567038807
Validation loss: 2.5324501912753563

Epoch: 5| Step: 7
Training loss: 1.797339205281394
Validation loss: 2.5143538752499794

Epoch: 5| Step: 8
Training loss: 1.9253216363299699
Validation loss: 2.4748170881402483

Epoch: 5| Step: 9
Training loss: 1.5766964480280417
Validation loss: 2.5154924851418206

Epoch: 5| Step: 10
Training loss: 1.7439138301332242
Validation loss: 2.5760233934872443

Epoch: 5| Step: 11
Training loss: 1.5714899459842528
Validation loss: 2.5863027938879797

Epoch: 411| Step: 0
Training loss: 2.0872325520308763
Validation loss: 2.6409597504442477

Epoch: 5| Step: 1
Training loss: 2.129819901423592
Validation loss: 2.651624560524348

Epoch: 5| Step: 2
Training loss: 1.9270511796348027
Validation loss: 2.5953699055446706

Epoch: 5| Step: 3
Training loss: 1.6855401561687136
Validation loss: 2.576217608543585

Epoch: 5| Step: 4
Training loss: 1.6673549264142344
Validation loss: 2.5423030108793445

Epoch: 5| Step: 5
Training loss: 1.4887981168080124
Validation loss: 2.514126305553832

Epoch: 5| Step: 6
Training loss: 1.604510761694452
Validation loss: 2.5051422520181417

Epoch: 5| Step: 7
Training loss: 1.9067498474161044
Validation loss: 2.4799267114044268

Epoch: 5| Step: 8
Training loss: 1.875082077773029
Validation loss: 2.4820656909820453

Epoch: 5| Step: 9
Training loss: 1.029815485269357
Validation loss: 2.4836612411853265

Epoch: 5| Step: 10
Training loss: 1.2742966638035986
Validation loss: 2.5150855218466543

Epoch: 5| Step: 11
Training loss: 1.225107484111387
Validation loss: 2.4941688044107972

Epoch: 412| Step: 0
Training loss: 1.4301673625829805
Validation loss: 2.497927124239104

Epoch: 5| Step: 1
Training loss: 2.260015238145077
Validation loss: 2.5297985075324836

Epoch: 5| Step: 2
Training loss: 1.7841154774938424
Validation loss: 2.537085392314668

Epoch: 5| Step: 3
Training loss: 1.5961327038762092
Validation loss: 2.5514490208617167

Epoch: 5| Step: 4
Training loss: 1.6533940000837488
Validation loss: 2.6099772605356066

Epoch: 5| Step: 5
Training loss: 1.9516927121338634
Validation loss: 2.6101461515942046

Epoch: 5| Step: 6
Training loss: 1.8423491506535394
Validation loss: 2.661916549016797

Epoch: 5| Step: 7
Training loss: 1.6472379107243702
Validation loss: 2.666297478501255

Epoch: 5| Step: 8
Training loss: 1.6232179994494185
Validation loss: 2.6328180352670683

Epoch: 5| Step: 9
Training loss: 1.429630966319497
Validation loss: 2.5631015466948606

Epoch: 5| Step: 10
Training loss: 1.1665012492121267
Validation loss: 2.5235743175535714

Epoch: 5| Step: 11
Training loss: 1.7415495932015386
Validation loss: 2.5202183222808583

Epoch: 413| Step: 0
Training loss: 1.519674024763379
Validation loss: 2.5496243574176525

Epoch: 5| Step: 1
Training loss: 2.2367672151837024
Validation loss: 2.512809097514818

Epoch: 5| Step: 2
Training loss: 2.078157697147906
Validation loss: 2.55370166356267

Epoch: 5| Step: 3
Training loss: 1.151185879656128
Validation loss: 2.567327778118628

Epoch: 5| Step: 4
Training loss: 1.8895110324316469
Validation loss: 2.592926515130092

Epoch: 5| Step: 5
Training loss: 1.7568003813626791
Validation loss: 2.597507612139526

Epoch: 5| Step: 6
Training loss: 2.266097867880813
Validation loss: 2.6224757576625937

Epoch: 5| Step: 7
Training loss: 1.58468315242772
Validation loss: 2.5963841853930103

Epoch: 5| Step: 8
Training loss: 1.3118246702559944
Validation loss: 2.5859693965116395

Epoch: 5| Step: 9
Training loss: 1.706794704921815
Validation loss: 2.579364074266096

Epoch: 5| Step: 10
Training loss: 1.6951310021067956
Validation loss: 2.5740095139379275

Epoch: 5| Step: 11
Training loss: 1.7762535692215347
Validation loss: 2.5719575342629715

Epoch: 414| Step: 0
Training loss: 1.6893097392188121
Validation loss: 2.5234742806571844

Epoch: 5| Step: 1
Training loss: 1.7278527319548893
Validation loss: 2.52343720080804

Epoch: 5| Step: 2
Training loss: 0.9290416942824032
Validation loss: 2.512522124514109

Epoch: 5| Step: 3
Training loss: 1.4069917206239335
Validation loss: 2.5006742760213583

Epoch: 5| Step: 4
Training loss: 2.21989765842056
Validation loss: 2.5222245953728897

Epoch: 5| Step: 5
Training loss: 1.7823301687565059
Validation loss: 2.5357423877693948

Epoch: 5| Step: 6
Training loss: 2.456374233685805
Validation loss: 2.5570647313153754

Epoch: 5| Step: 7
Training loss: 1.3654902795468693
Validation loss: 2.6235008500193953

Epoch: 5| Step: 8
Training loss: 1.1062890773272263
Validation loss: 2.6388487098936686

Epoch: 5| Step: 9
Training loss: 1.727341696169912
Validation loss: 2.646454409046072

Epoch: 5| Step: 10
Training loss: 1.8119270471451177
Validation loss: 2.629096003085083

Epoch: 5| Step: 11
Training loss: 2.407432265710326
Validation loss: 2.5726720227730024

Epoch: 415| Step: 0
Training loss: 2.050775669635265
Validation loss: 2.568268087527068

Epoch: 5| Step: 1
Training loss: 2.129833670376741
Validation loss: 2.537900936776478

Epoch: 5| Step: 2
Training loss: 1.5981114865158002
Validation loss: 2.529673328638782

Epoch: 5| Step: 3
Training loss: 1.423085546269135
Validation loss: 2.531848746390963

Epoch: 5| Step: 4
Training loss: 1.9363466952604886
Validation loss: 2.5463763179792185

Epoch: 5| Step: 5
Training loss: 1.10228992009005
Validation loss: 2.5291914379084095

Epoch: 5| Step: 6
Training loss: 1.6285872844650784
Validation loss: 2.5661026742685498

Epoch: 5| Step: 7
Training loss: 1.8360400232137237
Validation loss: 2.5737845981391305

Epoch: 5| Step: 8
Training loss: 1.3815550178233762
Validation loss: 2.5752596489694963

Epoch: 5| Step: 9
Training loss: 1.6367889607740567
Validation loss: 2.544953325320755

Epoch: 5| Step: 10
Training loss: 1.3027723498435817
Validation loss: 2.598210807633167

Epoch: 5| Step: 11
Training loss: 1.3656800160794125
Validation loss: 2.5961050273058355

Epoch: 416| Step: 0
Training loss: 1.6498271996150013
Validation loss: 2.5804138042233475

Epoch: 5| Step: 1
Training loss: 1.54879395109288
Validation loss: 2.587721160522327

Epoch: 5| Step: 2
Training loss: 1.7582820011016291
Validation loss: 2.543862302552176

Epoch: 5| Step: 3
Training loss: 1.6880520518083137
Validation loss: 2.5198166599324656

Epoch: 5| Step: 4
Training loss: 1.3879900195892512
Validation loss: 2.5190403876599805

Epoch: 5| Step: 5
Training loss: 1.5167956206586446
Validation loss: 2.567115809468354

Epoch: 5| Step: 6
Training loss: 1.2061232327276221
Validation loss: 2.5279108636589425

Epoch: 5| Step: 7
Training loss: 1.5739780743730765
Validation loss: 2.5749942188444948

Epoch: 5| Step: 8
Training loss: 1.9637324259922875
Validation loss: 2.6247480475900518

Epoch: 5| Step: 9
Training loss: 1.4961458600483426
Validation loss: 2.589249336992492

Epoch: 5| Step: 10
Training loss: 2.19125893381564
Validation loss: 2.58474469598448

Epoch: 5| Step: 11
Training loss: 1.3408324928036068
Validation loss: 2.61618993925634

Epoch: 417| Step: 0
Training loss: 1.722023222648173
Validation loss: 2.6446794236414553

Epoch: 5| Step: 1
Training loss: 1.7104073317068205
Validation loss: 2.6853738588029046

Epoch: 5| Step: 2
Training loss: 1.322967433205676
Validation loss: 2.6680069190404585

Epoch: 5| Step: 3
Training loss: 1.22718833944682
Validation loss: 2.6345483432513372

Epoch: 5| Step: 4
Training loss: 2.1108016099540174
Validation loss: 2.558297813326339

Epoch: 5| Step: 5
Training loss: 1.6783995902738262
Validation loss: 2.5475293939446377

Epoch: 5| Step: 6
Training loss: 1.850085607042942
Validation loss: 2.4947737047402287

Epoch: 5| Step: 7
Training loss: 1.795613185845031
Validation loss: 2.4466811951479626

Epoch: 5| Step: 8
Training loss: 1.2854994109904283
Validation loss: 2.463113369853354

Epoch: 5| Step: 9
Training loss: 1.7606017638038503
Validation loss: 2.4488028944416196

Epoch: 5| Step: 10
Training loss: 1.9534120882755623
Validation loss: 2.4403895873089856

Epoch: 5| Step: 11
Training loss: 0.950526588457356
Validation loss: 2.4478919142966418

Epoch: 418| Step: 0
Training loss: 1.6769779796166862
Validation loss: 2.4501704405678626

Epoch: 5| Step: 1
Training loss: 1.1723864647202737
Validation loss: 2.50535461067463

Epoch: 5| Step: 2
Training loss: 1.9725745458017847
Validation loss: 2.4678685147711747

Epoch: 5| Step: 3
Training loss: 1.513030594374598
Validation loss: 2.547796344073427

Epoch: 5| Step: 4
Training loss: 1.506409224329302
Validation loss: 2.599802298090148

Epoch: 5| Step: 5
Training loss: 1.560745933164461
Validation loss: 2.579963945301974

Epoch: 5| Step: 6
Training loss: 2.03128122158998
Validation loss: 2.573225880522334

Epoch: 5| Step: 7
Training loss: 1.29237587234965
Validation loss: 2.6223272802691895

Epoch: 5| Step: 8
Training loss: 1.629676984129468
Validation loss: 2.6382172082461866

Epoch: 5| Step: 9
Training loss: 2.0286818481957023
Validation loss: 2.6058017779052918

Epoch: 5| Step: 10
Training loss: 1.5589316248064036
Validation loss: 2.5660934296301376

Epoch: 5| Step: 11
Training loss: 0.32527731242505376
Validation loss: 2.5623150095806966

Epoch: 419| Step: 0
Training loss: 1.4719439739418434
Validation loss: 2.553338556996058

Epoch: 5| Step: 1
Training loss: 1.6168642319894673
Validation loss: 2.531531557663862

Epoch: 5| Step: 2
Training loss: 1.8581639681674558
Validation loss: 2.5208218997244147

Epoch: 5| Step: 3
Training loss: 1.2420682070089495
Validation loss: 2.53085181554109

Epoch: 5| Step: 4
Training loss: 1.34620947094109
Validation loss: 2.531213556035169

Epoch: 5| Step: 5
Training loss: 1.850157514516461
Validation loss: 2.520943404124931

Epoch: 5| Step: 6
Training loss: 1.673983233997969
Validation loss: 2.499875447031589

Epoch: 5| Step: 7
Training loss: 1.09440631248692
Validation loss: 2.5320919642024866

Epoch: 5| Step: 8
Training loss: 1.315380885656889
Validation loss: 2.5168329186083516

Epoch: 5| Step: 9
Training loss: 1.7833160331219668
Validation loss: 2.528240314080966

Epoch: 5| Step: 10
Training loss: 2.1318735144707013
Validation loss: 2.570617676988901

Epoch: 5| Step: 11
Training loss: 1.3465777960966652
Validation loss: 2.5902064526385233

Epoch: 420| Step: 0
Training loss: 1.83111861867559
Validation loss: 2.6092116367575047

Epoch: 5| Step: 1
Training loss: 1.6353754981947801
Validation loss: 2.6459342600628895

Epoch: 5| Step: 2
Training loss: 1.3521824996781733
Validation loss: 2.67298923184811

Epoch: 5| Step: 3
Training loss: 1.5863576999472744
Validation loss: 2.675406206490062

Epoch: 5| Step: 4
Training loss: 1.759678710416948
Validation loss: 2.5767886619096565

Epoch: 5| Step: 5
Training loss: 1.4895832444126484
Validation loss: 2.533767931347307

Epoch: 5| Step: 6
Training loss: 1.1632768168470609
Validation loss: 2.521894355141864

Epoch: 5| Step: 7
Training loss: 1.4921082480590278
Validation loss: 2.520630809961054

Epoch: 5| Step: 8
Training loss: 1.2386767119930047
Validation loss: 2.475552293698079

Epoch: 5| Step: 9
Training loss: 2.018256783245193
Validation loss: 2.4502620107655235

Epoch: 5| Step: 10
Training loss: 1.7759846280094265
Validation loss: 2.4880631978596175

Epoch: 5| Step: 11
Training loss: 1.64461460944275
Validation loss: 2.4766092145587417

Epoch: 421| Step: 0
Training loss: 1.3323252512874628
Validation loss: 2.4810897129984615

Epoch: 5| Step: 1
Training loss: 1.9642256566564174
Validation loss: 2.468375519626608

Epoch: 5| Step: 2
Training loss: 1.2497296994737808
Validation loss: 2.4987149591678093

Epoch: 5| Step: 3
Training loss: 1.7467570229205298
Validation loss: 2.495908564153906

Epoch: 5| Step: 4
Training loss: 1.5223020577127202
Validation loss: 2.5110447297129923

Epoch: 5| Step: 5
Training loss: 1.2511233050887243
Validation loss: 2.5578320133720926

Epoch: 5| Step: 6
Training loss: 1.8476710893547195
Validation loss: 2.5893235602376925

Epoch: 5| Step: 7
Training loss: 1.7994256533786979
Validation loss: 2.618245490768009

Epoch: 5| Step: 8
Training loss: 1.8504161263613765
Validation loss: 2.6078065090822977

Epoch: 5| Step: 9
Training loss: 1.5130828301951926
Validation loss: 2.574932460609025

Epoch: 5| Step: 10
Training loss: 2.1361038466937563
Validation loss: 2.5775092651590397

Epoch: 5| Step: 11
Training loss: 2.377517369925889
Validation loss: 2.5364026540693407

Epoch: 422| Step: 0
Training loss: 1.4241896014806372
Validation loss: 2.45659296344677

Epoch: 5| Step: 1
Training loss: 1.4176584960489171
Validation loss: 2.406444248599346

Epoch: 5| Step: 2
Training loss: 1.6880541703901657
Validation loss: 2.417236759643085

Epoch: 5| Step: 3
Training loss: 1.525548948699828
Validation loss: 2.3837953677075157

Epoch: 5| Step: 4
Training loss: 1.3083669437456715
Validation loss: 2.4009788833210157

Epoch: 5| Step: 5
Training loss: 1.95628424910037
Validation loss: 2.41507564300504

Epoch: 5| Step: 6
Training loss: 1.6481058229987813
Validation loss: 2.460820012593174

Epoch: 5| Step: 7
Training loss: 2.027836675383708
Validation loss: 2.4744155474683494

Epoch: 5| Step: 8
Training loss: 1.9748154710926646
Validation loss: 2.5452958030145223

Epoch: 5| Step: 9
Training loss: 1.9721715954952417
Validation loss: 2.594213448143611

Epoch: 5| Step: 10
Training loss: 1.4131816417708818
Validation loss: 2.589664575775986

Epoch: 5| Step: 11
Training loss: 1.4632059529041064
Validation loss: 2.5838254541884202

Epoch: 423| Step: 0
Training loss: 1.207876409539884
Validation loss: 2.5225555996836886

Epoch: 5| Step: 1
Training loss: 1.9564072152726346
Validation loss: 2.5245851558354064

Epoch: 5| Step: 2
Training loss: 1.6679131456170078
Validation loss: 2.484251233182897

Epoch: 5| Step: 3
Training loss: 1.7409691078385745
Validation loss: 2.503036391570668

Epoch: 5| Step: 4
Training loss: 1.5269657067156006
Validation loss: 2.5222055835380455

Epoch: 5| Step: 5
Training loss: 1.0924628176788738
Validation loss: 2.455022315071527

Epoch: 5| Step: 6
Training loss: 2.1502200967665086
Validation loss: 2.4961659555831717

Epoch: 5| Step: 7
Training loss: 1.6495633732467443
Validation loss: 2.4992248326798245

Epoch: 5| Step: 8
Training loss: 1.7122870570419848
Validation loss: 2.521841694132519

Epoch: 5| Step: 9
Training loss: 1.9830030369276068
Validation loss: 2.5603413289602543

Epoch: 5| Step: 10
Training loss: 1.7545440805441481
Validation loss: 2.6095801518365174

Epoch: 5| Step: 11
Training loss: 1.5211597336229759
Validation loss: 2.6697164483004023

Epoch: 424| Step: 0
Training loss: 1.4310549673936876
Validation loss: 2.6152399436733758

Epoch: 5| Step: 1
Training loss: 2.134112175192802
Validation loss: 2.511626614175539

Epoch: 5| Step: 2
Training loss: 1.8435211686195956
Validation loss: 2.481046686402576

Epoch: 5| Step: 3
Training loss: 1.2281195604043718
Validation loss: 2.4628993535120327

Epoch: 5| Step: 4
Training loss: 1.0815434096359147
Validation loss: 2.451840459214206

Epoch: 5| Step: 5
Training loss: 1.981930466052903
Validation loss: 2.445305114344939

Epoch: 5| Step: 6
Training loss: 1.7829371041861013
Validation loss: 2.4256832698869566

Epoch: 5| Step: 7
Training loss: 1.4948197560434706
Validation loss: 2.419407557691593

Epoch: 5| Step: 8
Training loss: 1.7973524039928268
Validation loss: 2.4463223615602083

Epoch: 5| Step: 9
Training loss: 1.8313834340301829
Validation loss: 2.498069665649259

Epoch: 5| Step: 10
Training loss: 1.728027619693041
Validation loss: 2.5457683764618633

Epoch: 5| Step: 11
Training loss: 1.160314067548766
Validation loss: 2.5364486209806154

Epoch: 425| Step: 0
Training loss: 1.3574865970687569
Validation loss: 2.548509091109013

Epoch: 5| Step: 1
Training loss: 1.7733340464258314
Validation loss: 2.5320845433062216

Epoch: 5| Step: 2
Training loss: 1.2069089759694533
Validation loss: 2.575668690715179

Epoch: 5| Step: 3
Training loss: 1.757382963470057
Validation loss: 2.582769210554192

Epoch: 5| Step: 4
Training loss: 2.3420445658794953
Validation loss: 2.5614591709945898

Epoch: 5| Step: 5
Training loss: 1.4518103446473134
Validation loss: 2.586281257054554

Epoch: 5| Step: 6
Training loss: 1.9098606622011558
Validation loss: 2.5660990972013558

Epoch: 5| Step: 7
Training loss: 1.4737902254498745
Validation loss: 2.5721296401443543

Epoch: 5| Step: 8
Training loss: 1.649653993798509
Validation loss: 2.6124770253219225

Epoch: 5| Step: 9
Training loss: 1.6797743663948055
Validation loss: 2.642406284170602

Epoch: 5| Step: 10
Training loss: 1.3952399838389995
Validation loss: 2.698806849038903

Epoch: 5| Step: 11
Training loss: 1.5359481050546266
Validation loss: 2.7348281557515075

Epoch: 426| Step: 0
Training loss: 1.728794640042647
Validation loss: 2.6688777367413734

Epoch: 5| Step: 1
Training loss: 1.5297109693649753
Validation loss: 2.5544907847036846

Epoch: 5| Step: 2
Training loss: 1.4602271000066223
Validation loss: 2.5294022036189947

Epoch: 5| Step: 3
Training loss: 1.8415554369770455
Validation loss: 2.5348592093362594

Epoch: 5| Step: 4
Training loss: 1.6487105446259926
Validation loss: 2.5018637147601748

Epoch: 5| Step: 5
Training loss: 1.459971797226542
Validation loss: 2.4621154952927666

Epoch: 5| Step: 6
Training loss: 1.076843827339417
Validation loss: 2.449973165112108

Epoch: 5| Step: 7
Training loss: 1.4001702171116899
Validation loss: 2.4667454923351

Epoch: 5| Step: 8
Training loss: 1.1928345170661228
Validation loss: 2.47043172479026

Epoch: 5| Step: 9
Training loss: 2.2427943667789236
Validation loss: 2.4581996644312603

Epoch: 5| Step: 10
Training loss: 1.3879997247041544
Validation loss: 2.50624357842616

Epoch: 5| Step: 11
Training loss: 1.3023798744761417
Validation loss: 2.5030264218683786

Epoch: 427| Step: 0
Training loss: 1.5789070080316943
Validation loss: 2.4944157021786935

Epoch: 5| Step: 1
Training loss: 1.036839106917473
Validation loss: 2.4850500017542956

Epoch: 5| Step: 2
Training loss: 1.118527868797634
Validation loss: 2.5051296496707502

Epoch: 5| Step: 3
Training loss: 1.9442377760214573
Validation loss: 2.495264581257218

Epoch: 5| Step: 4
Training loss: 1.6964128149347748
Validation loss: 2.512498255075889

Epoch: 5| Step: 5
Training loss: 1.5383997230765598
Validation loss: 2.5247110631130956

Epoch: 5| Step: 6
Training loss: 1.68922576256414
Validation loss: 2.5631126702598195

Epoch: 5| Step: 7
Training loss: 1.6660511151700523
Validation loss: 2.5942406324369602

Epoch: 5| Step: 8
Training loss: 1.5033693618573536
Validation loss: 2.578858238527534

Epoch: 5| Step: 9
Training loss: 1.3846298172699836
Validation loss: 2.5712079591826913

Epoch: 5| Step: 10
Training loss: 2.1809668939273763
Validation loss: 2.609155969316583

Epoch: 5| Step: 11
Training loss: 1.3240290593130484
Validation loss: 2.5643021170361866

Epoch: 428| Step: 0
Training loss: 1.7608408294652973
Validation loss: 2.5384825645728615

Epoch: 5| Step: 1
Training loss: 1.4592808597105973
Validation loss: 2.559249048545685

Epoch: 5| Step: 2
Training loss: 1.1077179689522167
Validation loss: 2.533293401618841

Epoch: 5| Step: 3
Training loss: 1.3799825903582164
Validation loss: 2.5215193994494323

Epoch: 5| Step: 4
Training loss: 1.2340449121206734
Validation loss: 2.4865319866900104

Epoch: 5| Step: 5
Training loss: 1.417577095693602
Validation loss: 2.484920511794145

Epoch: 5| Step: 6
Training loss: 2.069213460310423
Validation loss: 2.4752420099983063

Epoch: 5| Step: 7
Training loss: 1.8583947811601906
Validation loss: 2.4435862988003207

Epoch: 5| Step: 8
Training loss: 1.3102449845420197
Validation loss: 2.4507730065757283

Epoch: 5| Step: 9
Training loss: 1.5987173721050139
Validation loss: 2.438753934440261

Epoch: 5| Step: 10
Training loss: 1.4966121402966355
Validation loss: 2.4677030983307495

Epoch: 5| Step: 11
Training loss: 1.899562800450468
Validation loss: 2.4490700757229664

Epoch: 429| Step: 0
Training loss: 1.5151500941038694
Validation loss: 2.4718937192739365

Epoch: 5| Step: 1
Training loss: 1.946455776579433
Validation loss: 2.488757736121224

Epoch: 5| Step: 2
Training loss: 1.2499779222446044
Validation loss: 2.4866300640776613

Epoch: 5| Step: 3
Training loss: 1.4904293867632543
Validation loss: 2.5518663872093788

Epoch: 5| Step: 4
Training loss: 0.8781240415737582
Validation loss: 2.556083531077409

Epoch: 5| Step: 5
Training loss: 1.7586349258788057
Validation loss: 2.560376477579219

Epoch: 5| Step: 6
Training loss: 1.9900265211705492
Validation loss: 2.598491842160813

Epoch: 5| Step: 7
Training loss: 1.221291899025797
Validation loss: 2.600413831611371

Epoch: 5| Step: 8
Training loss: 1.15434758160491
Validation loss: 2.561658137516581

Epoch: 5| Step: 9
Training loss: 1.9101342822100804
Validation loss: 2.6029215328264086

Epoch: 5| Step: 10
Training loss: 1.4399907468127606
Validation loss: 2.5935389995926394

Epoch: 5| Step: 11
Training loss: 1.1997343564055927
Validation loss: 2.567149596070878

Epoch: 430| Step: 0
Training loss: 1.237841506999505
Validation loss: 2.534960331176933

Epoch: 5| Step: 1
Training loss: 1.66650083034711
Validation loss: 2.5065038401860087

Epoch: 5| Step: 2
Training loss: 1.4786983966610514
Validation loss: 2.476397814725374

Epoch: 5| Step: 3
Training loss: 1.9937533937622651
Validation loss: 2.4554470921013483

Epoch: 5| Step: 4
Training loss: 1.4012979842587232
Validation loss: 2.478464445202465

Epoch: 5| Step: 5
Training loss: 1.605643529729363
Validation loss: 2.5282439231014937

Epoch: 5| Step: 6
Training loss: 1.8276944427791455
Validation loss: 2.544048867097942

Epoch: 5| Step: 7
Training loss: 1.3346353620823794
Validation loss: 2.587044719902051

Epoch: 5| Step: 8
Training loss: 1.3867657290815352
Validation loss: 2.5353027755956434

Epoch: 5| Step: 9
Training loss: 1.3544525382709613
Validation loss: 2.5136989620698644

Epoch: 5| Step: 10
Training loss: 1.6941782589409644
Validation loss: 2.519690492314319

Epoch: 5| Step: 11
Training loss: 0.8208688938035166
Validation loss: 2.5007329939119356

Epoch: 431| Step: 0
Training loss: 1.1279770349910876
Validation loss: 2.5565482079899473

Epoch: 5| Step: 1
Training loss: 1.338946606529446
Validation loss: 2.5219697334934863

Epoch: 5| Step: 2
Training loss: 1.1525389425190053
Validation loss: 2.538518630246617

Epoch: 5| Step: 3
Training loss: 1.4690789199362635
Validation loss: 2.5602529993868166

Epoch: 5| Step: 4
Training loss: 1.6562127163127403
Validation loss: 2.5763571949460573

Epoch: 5| Step: 5
Training loss: 1.6267096988791485
Validation loss: 2.565983068219292

Epoch: 5| Step: 6
Training loss: 1.1387331178923312
Validation loss: 2.557496345600688

Epoch: 5| Step: 7
Training loss: 1.556297733540004
Validation loss: 2.546719821344828

Epoch: 5| Step: 8
Training loss: 2.1637855104632084
Validation loss: 2.570128545391281

Epoch: 5| Step: 9
Training loss: 1.397463112755448
Validation loss: 2.5955750352701523

Epoch: 5| Step: 10
Training loss: 1.8445903350143413
Validation loss: 2.623035005763684

Epoch: 5| Step: 11
Training loss: 1.127085236684681
Validation loss: 2.6243060420861566

Epoch: 432| Step: 0
Training loss: 1.5148560451187636
Validation loss: 2.5534947689800314

Epoch: 5| Step: 1
Training loss: 1.3976909839968976
Validation loss: 2.5151591175612245

Epoch: 5| Step: 2
Training loss: 1.1218216822288425
Validation loss: 2.4658190454662328

Epoch: 5| Step: 3
Training loss: 1.8771849934621696
Validation loss: 2.4849894041792377

Epoch: 5| Step: 4
Training loss: 1.7553412804969994
Validation loss: 2.473019991491424

Epoch: 5| Step: 5
Training loss: 1.7775572931469528
Validation loss: 2.4202160311395864

Epoch: 5| Step: 6
Training loss: 1.5908113951225282
Validation loss: 2.4743315418561025

Epoch: 5| Step: 7
Training loss: 1.4644693531959607
Validation loss: 2.504467695415375

Epoch: 5| Step: 8
Training loss: 1.3552043118174077
Validation loss: 2.478635335666085

Epoch: 5| Step: 9
Training loss: 1.8730434381893
Validation loss: 2.5057257727916706

Epoch: 5| Step: 10
Training loss: 0.9873897768627617
Validation loss: 2.5480400552813833

Epoch: 5| Step: 11
Training loss: 0.6520160834356009
Validation loss: 2.542313100083685

Epoch: 433| Step: 0
Training loss: 1.426897589111644
Validation loss: 2.5117257683212446

Epoch: 5| Step: 1
Training loss: 1.269832352363784
Validation loss: 2.5410861377672025

Epoch: 5| Step: 2
Training loss: 1.366288199977012
Validation loss: 2.5347621280251973

Epoch: 5| Step: 3
Training loss: 1.5349617948965348
Validation loss: 2.47456771707133

Epoch: 5| Step: 4
Training loss: 1.8894893924307372
Validation loss: 2.474589322918924

Epoch: 5| Step: 5
Training loss: 1.4343651299562974
Validation loss: 2.49051798084418

Epoch: 5| Step: 6
Training loss: 1.610877141552512
Validation loss: 2.4561301834708207

Epoch: 5| Step: 7
Training loss: 1.3810802752444593
Validation loss: 2.4600495850856166

Epoch: 5| Step: 8
Training loss: 2.2057258999262506
Validation loss: 2.4948259217227378

Epoch: 5| Step: 9
Training loss: 0.8358920789125868
Validation loss: 2.530427579357381

Epoch: 5| Step: 10
Training loss: 1.4946462137341185
Validation loss: 2.569198989456553

Epoch: 5| Step: 11
Training loss: 1.8013118864039674
Validation loss: 2.603052470588568

Epoch: 434| Step: 0
Training loss: 1.71235952984598
Validation loss: 2.56707854733369

Epoch: 5| Step: 1
Training loss: 1.2393138923912301
Validation loss: 2.5242829417271477

Epoch: 5| Step: 2
Training loss: 1.4984521827336397
Validation loss: 2.5506547990955917

Epoch: 5| Step: 3
Training loss: 1.8020334255238781
Validation loss: 2.497434905498673

Epoch: 5| Step: 4
Training loss: 1.251773339275095
Validation loss: 2.5194297434938586

Epoch: 5| Step: 5
Training loss: 1.5857729521077715
Validation loss: 2.545751155977506

Epoch: 5| Step: 6
Training loss: 1.2122479147237228
Validation loss: 2.5138274477873113

Epoch: 5| Step: 7
Training loss: 1.3462134114910085
Validation loss: 2.5216717737807572

Epoch: 5| Step: 8
Training loss: 1.3673288762701763
Validation loss: 2.5217774169427085

Epoch: 5| Step: 9
Training loss: 1.3706092956728726
Validation loss: 2.5666674437975843

Epoch: 5| Step: 10
Training loss: 1.7090067660363526
Validation loss: 2.5448001648028016

Epoch: 5| Step: 11
Training loss: 2.3682211454138327
Validation loss: 2.5272652340169866

Epoch: 435| Step: 0
Training loss: 1.784807166895376
Validation loss: 2.4748645461228858

Epoch: 5| Step: 1
Training loss: 1.5833885869206434
Validation loss: 2.51596046564571

Epoch: 5| Step: 2
Training loss: 1.9091035091099942
Validation loss: 2.524046683618291

Epoch: 5| Step: 3
Training loss: 1.436507089445344
Validation loss: 2.568868233248396

Epoch: 5| Step: 4
Training loss: 1.5744112337250515
Validation loss: 2.5371289329567865

Epoch: 5| Step: 5
Training loss: 1.2499768254992882
Validation loss: 2.5463538894658373

Epoch: 5| Step: 6
Training loss: 1.1977852071971256
Validation loss: 2.506546441682148

Epoch: 5| Step: 7
Training loss: 1.314954098237578
Validation loss: 2.5398080523495357

Epoch: 5| Step: 8
Training loss: 1.4276822729036323
Validation loss: 2.518062084352834

Epoch: 5| Step: 9
Training loss: 1.1457714353084079
Validation loss: 2.52203066950862

Epoch: 5| Step: 10
Training loss: 1.4997461422048566
Validation loss: 2.552331267529617

Epoch: 5| Step: 11
Training loss: 1.6601059849927327
Validation loss: 2.495811466339898

Epoch: 436| Step: 0
Training loss: 1.6666740735207324
Validation loss: 2.4937805537214013

Epoch: 5| Step: 1
Training loss: 1.011752860771944
Validation loss: 2.506007986203656

Epoch: 5| Step: 2
Training loss: 1.5016486326793734
Validation loss: 2.5038834886711556

Epoch: 5| Step: 3
Training loss: 1.5525818180018616
Validation loss: 2.5021948676510815

Epoch: 5| Step: 4
Training loss: 1.1243249669374917
Validation loss: 2.5127968360543282

Epoch: 5| Step: 5
Training loss: 1.93064090790127
Validation loss: 2.4890245997083147

Epoch: 5| Step: 6
Training loss: 1.7476015003071301
Validation loss: 2.5384359594184898

Epoch: 5| Step: 7
Training loss: 1.6757057012854484
Validation loss: 2.559971709629045

Epoch: 5| Step: 8
Training loss: 1.4390423006013138
Validation loss: 2.588657692522662

Epoch: 5| Step: 9
Training loss: 1.7177703840045344
Validation loss: 2.6136750445814427

Epoch: 5| Step: 10
Training loss: 1.307004139602515
Validation loss: 2.6144259330718156

Epoch: 5| Step: 11
Training loss: 1.3903784801271895
Validation loss: 2.51712269161879

Epoch: 437| Step: 0
Training loss: 1.0225210964572786
Validation loss: 2.5545397646744568

Epoch: 5| Step: 1
Training loss: 1.020633496297593
Validation loss: 2.5293374744431487

Epoch: 5| Step: 2
Training loss: 1.3609928719854543
Validation loss: 2.485956412450627

Epoch: 5| Step: 3
Training loss: 1.9147246791840378
Validation loss: 2.458036707234789

Epoch: 5| Step: 4
Training loss: 1.2440662212071825
Validation loss: 2.4683226364371027

Epoch: 5| Step: 5
Training loss: 1.7836106034300112
Validation loss: 2.506346982441444

Epoch: 5| Step: 6
Training loss: 1.8686381813710775
Validation loss: 2.5182714264777832

Epoch: 5| Step: 7
Training loss: 1.3025969700218558
Validation loss: 2.546775622857115

Epoch: 5| Step: 8
Training loss: 1.6788668734839687
Validation loss: 2.569332442262525

Epoch: 5| Step: 9
Training loss: 1.435587398450149
Validation loss: 2.596622928851717

Epoch: 5| Step: 10
Training loss: 1.6252846101796798
Validation loss: 2.5969847076415253

Epoch: 5| Step: 11
Training loss: 1.4291318220037283
Validation loss: 2.5803102229584423

Epoch: 438| Step: 0
Training loss: 0.9948489021226575
Validation loss: 2.5285065701312384

Epoch: 5| Step: 1
Training loss: 1.404531064090256
Validation loss: 2.4759737833293394

Epoch: 5| Step: 2
Training loss: 1.0848335308048007
Validation loss: 2.497871005001786

Epoch: 5| Step: 3
Training loss: 1.9854278174531177
Validation loss: 2.478366471560521

Epoch: 5| Step: 4
Training loss: 1.255777311832698
Validation loss: 2.4518806597932565

Epoch: 5| Step: 5
Training loss: 1.7620867494971115
Validation loss: 2.4440785850538957

Epoch: 5| Step: 6
Training loss: 2.316881308000332
Validation loss: 2.496795062272326

Epoch: 5| Step: 7
Training loss: 1.6122628385032949
Validation loss: 2.494961437482846

Epoch: 5| Step: 8
Training loss: 1.2806046419028865
Validation loss: 2.4882266379471147

Epoch: 5| Step: 9
Training loss: 1.5937257652684076
Validation loss: 2.595770456834358

Epoch: 5| Step: 10
Training loss: 1.5230328927348533
Validation loss: 2.6653930048816354

Epoch: 5| Step: 11
Training loss: 1.7753207252767162
Validation loss: 2.7155688554749315

Epoch: 439| Step: 0
Training loss: 1.3737531991353849
Validation loss: 2.6879612079657873

Epoch: 5| Step: 1
Training loss: 1.6727908469170008
Validation loss: 2.6347791305207164

Epoch: 5| Step: 2
Training loss: 1.36132225790634
Validation loss: 2.5536808671025746

Epoch: 5| Step: 3
Training loss: 1.6404147785470782
Validation loss: 2.4895786035298597

Epoch: 5| Step: 4
Training loss: 1.4590191000772603
Validation loss: 2.4598109679263014

Epoch: 5| Step: 5
Training loss: 1.3063354135723704
Validation loss: 2.499788724395939

Epoch: 5| Step: 6
Training loss: 1.6868520128366506
Validation loss: 2.4573728751465356

Epoch: 5| Step: 7
Training loss: 1.9346787000137742
Validation loss: 2.486815233802681

Epoch: 5| Step: 8
Training loss: 1.3573479721479682
Validation loss: 2.4093396056824896

Epoch: 5| Step: 9
Training loss: 1.7296971652511266
Validation loss: 2.465959972291604

Epoch: 5| Step: 10
Training loss: 1.3664205525316575
Validation loss: 2.4722653040245564

Epoch: 5| Step: 11
Training loss: 0.6718698989319665
Validation loss: 2.4988125842196904

Epoch: 440| Step: 0
Training loss: 1.9009004165917867
Validation loss: 2.558175446383928

Epoch: 5| Step: 1
Training loss: 1.1917845578777797
Validation loss: 2.5303312172593375

Epoch: 5| Step: 2
Training loss: 1.3157151669300644
Validation loss: 2.5802348895676936

Epoch: 5| Step: 3
Training loss: 1.3276877637213826
Validation loss: 2.56241388486362

Epoch: 5| Step: 4
Training loss: 1.4783054943251757
Validation loss: 2.5202846770732457

Epoch: 5| Step: 5
Training loss: 1.44991908669801
Validation loss: 2.5493626761132746

Epoch: 5| Step: 6
Training loss: 1.2162419457477667
Validation loss: 2.4964638894763227

Epoch: 5| Step: 7
Training loss: 2.1189624061004
Validation loss: 2.4432355654720865

Epoch: 5| Step: 8
Training loss: 1.3465342840822596
Validation loss: 2.4915702497896923

Epoch: 5| Step: 9
Training loss: 1.3812078443627605
Validation loss: 2.506012235732879

Epoch: 5| Step: 10
Training loss: 1.3561720109305848
Validation loss: 2.494393045412233

Epoch: 5| Step: 11
Training loss: 1.6846787216022916
Validation loss: 2.4933889436788825

Epoch: 441| Step: 0
Training loss: 1.8036385662634886
Validation loss: 2.490110945291767

Epoch: 5| Step: 1
Training loss: 1.606090267566179
Validation loss: 2.562129166372476

Epoch: 5| Step: 2
Training loss: 1.6428906736446909
Validation loss: 2.5651029880475793

Epoch: 5| Step: 3
Training loss: 1.274427391947174
Validation loss: 2.6057535994733394

Epoch: 5| Step: 4
Training loss: 1.717280991207275
Validation loss: 2.6204359704477946

Epoch: 5| Step: 5
Training loss: 1.3641825322739582
Validation loss: 2.540337708899869

Epoch: 5| Step: 6
Training loss: 1.3876040359534045
Validation loss: 2.478106353452297

Epoch: 5| Step: 7
Training loss: 1.1899546300429562
Validation loss: 2.4937347304881357

Epoch: 5| Step: 8
Training loss: 0.9593858674766521
Validation loss: 2.482990066807779

Epoch: 5| Step: 9
Training loss: 1.8542881472221264
Validation loss: 2.493553741798312

Epoch: 5| Step: 10
Training loss: 1.5383140951808667
Validation loss: 2.4989495872089025

Epoch: 5| Step: 11
Training loss: 0.8916334165333376
Validation loss: 2.503352599446573

Epoch: 442| Step: 0
Training loss: 1.6555143918005486
Validation loss: 2.532485056221427

Epoch: 5| Step: 1
Training loss: 1.4973559918839154
Validation loss: 2.472459384499763

Epoch: 5| Step: 2
Training loss: 1.3833277114309643
Validation loss: 2.467796588241138

Epoch: 5| Step: 3
Training loss: 1.3936365928184837
Validation loss: 2.469048228539455

Epoch: 5| Step: 4
Training loss: 1.5461195054494414
Validation loss: 2.5210054407137963

Epoch: 5| Step: 5
Training loss: 1.6960893951599076
Validation loss: 2.4925101339439655

Epoch: 5| Step: 6
Training loss: 1.8588312459914749
Validation loss: 2.5306880272154575

Epoch: 5| Step: 7
Training loss: 1.1524796745179509
Validation loss: 2.5502588965004587

Epoch: 5| Step: 8
Training loss: 1.2806518833360274
Validation loss: 2.545702350314494

Epoch: 5| Step: 9
Training loss: 1.0950900996167787
Validation loss: 2.492431887738952

Epoch: 5| Step: 10
Training loss: 1.4457761278662609
Validation loss: 2.4539650655064102

Epoch: 5| Step: 11
Training loss: 0.7403902478532595
Validation loss: 2.463306872824101

Epoch: 443| Step: 0
Training loss: 1.682183402940699
Validation loss: 2.5339469062846307

Epoch: 5| Step: 1
Training loss: 1.1124068724840053
Validation loss: 2.499759161792641

Epoch: 5| Step: 2
Training loss: 1.0492739165140965
Validation loss: 2.488654156124179

Epoch: 5| Step: 3
Training loss: 2.0214969947900165
Validation loss: 2.5593351149100285

Epoch: 5| Step: 4
Training loss: 1.5728549397800726
Validation loss: 2.5740453519871713

Epoch: 5| Step: 5
Training loss: 1.1760691546912583
Validation loss: 2.5784845082247476

Epoch: 5| Step: 6
Training loss: 1.1884099084347974
Validation loss: 2.573888611836616

Epoch: 5| Step: 7
Training loss: 1.5064839256636895
Validation loss: 2.569985292549699

Epoch: 5| Step: 8
Training loss: 1.2386831118850823
Validation loss: 2.5945732962534316

Epoch: 5| Step: 9
Training loss: 1.635975889905002
Validation loss: 2.5576490798598934

Epoch: 5| Step: 10
Training loss: 1.1867310393389607
Validation loss: 2.5740226802144117

Epoch: 5| Step: 11
Training loss: 1.8102469417028324
Validation loss: 2.507736410886114

Epoch: 444| Step: 0
Training loss: 1.0602590827292004
Validation loss: 2.51551385203537

Epoch: 5| Step: 1
Training loss: 1.2740441965823932
Validation loss: 2.4883327069593673

Epoch: 5| Step: 2
Training loss: 1.7074126422032887
Validation loss: 2.4648126720115617

Epoch: 5| Step: 3
Training loss: 1.7958158605777317
Validation loss: 2.4513841007757446

Epoch: 5| Step: 4
Training loss: 1.6295128294400798
Validation loss: 2.4397227512681265

Epoch: 5| Step: 5
Training loss: 1.1848291175700387
Validation loss: 2.507442387634989

Epoch: 5| Step: 6
Training loss: 1.7175864702915153
Validation loss: 2.5316307425152798

Epoch: 5| Step: 7
Training loss: 1.304977430462699
Validation loss: 2.572871351936978

Epoch: 5| Step: 8
Training loss: 1.0702691730723535
Validation loss: 2.654229738473186

Epoch: 5| Step: 9
Training loss: 1.2817196799245472
Validation loss: 2.708984059629672

Epoch: 5| Step: 10
Training loss: 1.680343074169251
Validation loss: 2.660605872009832

Epoch: 5| Step: 11
Training loss: 1.1843137659835834
Validation loss: 2.695843501467349

Epoch: 445| Step: 0
Training loss: 1.3137291193935134
Validation loss: 2.6808878042655486

Epoch: 5| Step: 1
Training loss: 1.422612596289339
Validation loss: 2.6532862154113293

Epoch: 5| Step: 2
Training loss: 1.2555652232393364
Validation loss: 2.606656049449043

Epoch: 5| Step: 3
Training loss: 1.668540981503903
Validation loss: 2.581380949785945

Epoch: 5| Step: 4
Training loss: 1.3065058206719815
Validation loss: 2.541771434490322

Epoch: 5| Step: 5
Training loss: 1.2663447841104145
Validation loss: 2.5093618006218557

Epoch: 5| Step: 6
Training loss: 1.008524620943331
Validation loss: 2.449757364156569

Epoch: 5| Step: 7
Training loss: 1.6071289092170125
Validation loss: 2.4556685137143917

Epoch: 5| Step: 8
Training loss: 1.3243774499010916
Validation loss: 2.4824873312607347

Epoch: 5| Step: 9
Training loss: 1.3126741021350796
Validation loss: 2.4668554086151264

Epoch: 5| Step: 10
Training loss: 1.6901284692679444
Validation loss: 2.4863338465398783

Epoch: 5| Step: 11
Training loss: 2.1267429384567462
Validation loss: 2.544383431438387

Epoch: 446| Step: 0
Training loss: 1.2520360100933094
Validation loss: 2.496654226690588

Epoch: 5| Step: 1
Training loss: 1.4095298665087157
Validation loss: 2.5462035637804994

Epoch: 5| Step: 2
Training loss: 1.3539702737663932
Validation loss: 2.523563684983492

Epoch: 5| Step: 3
Training loss: 1.1153738599354783
Validation loss: 2.5274255416032414

Epoch: 5| Step: 4
Training loss: 0.9833853454627531
Validation loss: 2.5238752192153826

Epoch: 5| Step: 5
Training loss: 1.1107430417986757
Validation loss: 2.538651351896625

Epoch: 5| Step: 6
Training loss: 1.411463588503055
Validation loss: 2.5339140471661734

Epoch: 5| Step: 7
Training loss: 2.030745106083619
Validation loss: 2.50148031594945

Epoch: 5| Step: 8
Training loss: 1.4430668886825004
Validation loss: 2.556234970141857

Epoch: 5| Step: 9
Training loss: 1.2274624869680366
Validation loss: 2.581182320102373

Epoch: 5| Step: 10
Training loss: 1.406219482090731
Validation loss: 2.5735218414895193

Epoch: 5| Step: 11
Training loss: 2.052261254460864
Validation loss: 2.5584454908440715

Epoch: 447| Step: 0
Training loss: 1.301490842167821
Validation loss: 2.610479372422707

Epoch: 5| Step: 1
Training loss: 1.5733865284547766
Validation loss: 2.6232239792892713

Epoch: 5| Step: 2
Training loss: 1.7164531272490993
Validation loss: 2.6876943503197612

Epoch: 5| Step: 3
Training loss: 1.3700922598715743
Validation loss: 2.6511129783127463

Epoch: 5| Step: 4
Training loss: 1.6579646465871598
Validation loss: 2.594492825073586

Epoch: 5| Step: 5
Training loss: 1.3772637199567417
Validation loss: 2.516686896586004

Epoch: 5| Step: 6
Training loss: 1.1938432127825027
Validation loss: 2.4864729853820164

Epoch: 5| Step: 7
Training loss: 1.4938580813071876
Validation loss: 2.4793201981348956

Epoch: 5| Step: 8
Training loss: 1.0092074181298052
Validation loss: 2.4570880311228107

Epoch: 5| Step: 9
Training loss: 1.161338742974606
Validation loss: 2.4409720764654512

Epoch: 5| Step: 10
Training loss: 1.060883020903982
Validation loss: 2.4552568336738445

Epoch: 5| Step: 11
Training loss: 1.0754668042864886
Validation loss: 2.4903600164893676

Epoch: 448| Step: 0
Training loss: 1.3518643345370218
Validation loss: 2.4978381067945077

Epoch: 5| Step: 1
Training loss: 1.387231264637856
Validation loss: 2.495565626204152

Epoch: 5| Step: 2
Training loss: 1.7352917971647803
Validation loss: 2.51469234687468

Epoch: 5| Step: 3
Training loss: 1.1412669948720542
Validation loss: 2.5511994537512326

Epoch: 5| Step: 4
Training loss: 1.395980210429054
Validation loss: 2.5906861835244572

Epoch: 5| Step: 5
Training loss: 1.648643010784341
Validation loss: 2.597392324554009

Epoch: 5| Step: 6
Training loss: 1.1171794971099396
Validation loss: 2.6096335547567167

Epoch: 5| Step: 7
Training loss: 1.225927249146992
Validation loss: 2.6256514641556263

Epoch: 5| Step: 8
Training loss: 1.1706367562961837
Validation loss: 2.6000431271179583

Epoch: 5| Step: 9
Training loss: 1.0904446384416888
Validation loss: 2.5824771021012163

Epoch: 5| Step: 10
Training loss: 1.8032631145187092
Validation loss: 2.544706985953062

Epoch: 5| Step: 11
Training loss: 1.5493145596132234
Validation loss: 2.5610331508360735

Epoch: 449| Step: 0
Training loss: 1.8136786213243443
Validation loss: 2.509706204078315

Epoch: 5| Step: 1
Training loss: 1.2587190761006495
Validation loss: 2.4647203586845565

Epoch: 5| Step: 2
Training loss: 1.620270448762545
Validation loss: 2.444898702366693

Epoch: 5| Step: 3
Training loss: 1.2824574805158473
Validation loss: 2.4684745920654816

Epoch: 5| Step: 4
Training loss: 1.3712357667585924
Validation loss: 2.4777739256516216

Epoch: 5| Step: 5
Training loss: 0.9675065335587884
Validation loss: 2.492420002327266

Epoch: 5| Step: 6
Training loss: 1.4713709557399661
Validation loss: 2.494998044667468

Epoch: 5| Step: 7
Training loss: 1.6636420779975727
Validation loss: 2.521544266907173

Epoch: 5| Step: 8
Training loss: 1.2214744633344763
Validation loss: 2.549300335907298

Epoch: 5| Step: 9
Training loss: 1.3190481237637106
Validation loss: 2.5867316687071322

Epoch: 5| Step: 10
Training loss: 1.3637553267895017
Validation loss: 2.6054321850789806

Epoch: 5| Step: 11
Training loss: 0.590569006067006
Validation loss: 2.6047744588480075

Epoch: 450| Step: 0
Training loss: 1.419757901763019
Validation loss: 2.633811361246524

Epoch: 5| Step: 1
Training loss: 1.2876640826360726
Validation loss: 2.622990698270827

Epoch: 5| Step: 2
Training loss: 1.0639562164419036
Validation loss: 2.6404783859030454

Epoch: 5| Step: 3
Training loss: 1.3766728109094857
Validation loss: 2.616432954187386

Epoch: 5| Step: 4
Training loss: 1.0663129046042314
Validation loss: 2.564630067003373

Epoch: 5| Step: 5
Training loss: 1.0003050100563933
Validation loss: 2.5690957023177416

Epoch: 5| Step: 6
Training loss: 1.1267652437623292
Validation loss: 2.5684523068864635

Epoch: 5| Step: 7
Training loss: 1.4329523215923938
Validation loss: 2.539112712657041

Epoch: 5| Step: 8
Training loss: 1.7482333121161286
Validation loss: 2.531158612410799

Epoch: 5| Step: 9
Training loss: 1.3634156868567016
Validation loss: 2.5645173707087263

Epoch: 5| Step: 10
Training loss: 1.7314407684214905
Validation loss: 2.554626184130138

Epoch: 5| Step: 11
Training loss: 1.8306740489782158
Validation loss: 2.554849792520605

Testing loss: 2.1389062968221326
