Epoch: 1| Step: 0
Training loss: 6.11571062951038
Validation loss: 5.908957989182525

Epoch: 5| Step: 1
Training loss: 6.33841153724099
Validation loss: 5.907656540821936

Epoch: 5| Step: 2
Training loss: 6.40418519030018
Validation loss: 5.906491316721341

Epoch: 5| Step: 3
Training loss: 5.468730119941545
Validation loss: 5.905437911514499

Epoch: 5| Step: 4
Training loss: 6.605614568633694
Validation loss: 5.90444027794585

Epoch: 5| Step: 5
Training loss: 5.8817317623443115
Validation loss: 5.903496451914555

Epoch: 5| Step: 6
Training loss: 5.051407517788146
Validation loss: 5.902550980443232

Epoch: 5| Step: 7
Training loss: 6.084308528683994
Validation loss: 5.901635252639056

Epoch: 5| Step: 8
Training loss: 6.257961542876333
Validation loss: 5.900583175889689

Epoch: 5| Step: 9
Training loss: 6.034744436293632
Validation loss: 5.899536367292704

Epoch: 5| Step: 10
Training loss: 6.1498388998129325
Validation loss: 5.8984971605529966

Epoch: 5| Step: 11
Training loss: 4.070807311574542
Validation loss: 5.897360535379873

Epoch: 2| Step: 0
Training loss: 6.03968245271543
Validation loss: 5.896280118999985

Epoch: 5| Step: 1
Training loss: 5.7682282481540845
Validation loss: 5.895100108766926

Epoch: 5| Step: 2
Training loss: 6.32761137961904
Validation loss: 5.8938835635917135

Epoch: 5| Step: 3
Training loss: 6.269665107605305
Validation loss: 5.892662977484978

Epoch: 5| Step: 4
Training loss: 5.770064466833626
Validation loss: 5.89129088505982

Epoch: 5| Step: 5
Training loss: 5.961358251758616
Validation loss: 5.889862456407757

Epoch: 5| Step: 6
Training loss: 6.157267994631616
Validation loss: 5.888414259843144

Epoch: 5| Step: 7
Training loss: 5.701392007141045
Validation loss: 5.886880563167075

Epoch: 5| Step: 8
Training loss: 6.022444072889676
Validation loss: 5.8852586122968376

Epoch: 5| Step: 9
Training loss: 6.512609721776946
Validation loss: 5.883551751676063

Epoch: 5| Step: 10
Training loss: 5.396593234289291
Validation loss: 5.881704765679977

Epoch: 5| Step: 11
Training loss: 6.27907118324967
Validation loss: 5.879933835412066

Epoch: 3| Step: 0
Training loss: 6.470255358696307
Validation loss: 5.87788450163829

Epoch: 5| Step: 1
Training loss: 5.953039454048249
Validation loss: 5.875687099074929

Epoch: 5| Step: 2
Training loss: 6.721441537101243
Validation loss: 5.873660415082069

Epoch: 5| Step: 3
Training loss: 4.883091007682188
Validation loss: 5.871365545753541

Epoch: 5| Step: 4
Training loss: 5.936813796696055
Validation loss: 5.869002872824473

Epoch: 5| Step: 5
Training loss: 6.782279925208537
Validation loss: 5.86655802255876

Epoch: 5| Step: 6
Training loss: 5.1770410465634455
Validation loss: 5.864009180867571

Epoch: 5| Step: 7
Training loss: 6.731079144731305
Validation loss: 5.86124778827244

Epoch: 5| Step: 8
Training loss: 5.400729850613852
Validation loss: 5.858362895444222

Epoch: 5| Step: 9
Training loss: 5.362272052321698
Validation loss: 5.855376531491045

Epoch: 5| Step: 10
Training loss: 6.173786417824167
Validation loss: 5.852356018670063

Epoch: 5| Step: 11
Training loss: 5.060318841953198
Validation loss: 5.8491244565675595

Epoch: 4| Step: 0
Training loss: 6.539297885828387
Validation loss: 5.845882890110134

Epoch: 5| Step: 1
Training loss: 5.57429026375377
Validation loss: 5.842206455311169

Epoch: 5| Step: 2
Training loss: 5.655026972779724
Validation loss: 5.83848303822991

Epoch: 5| Step: 3
Training loss: 6.599365735644068
Validation loss: 5.834880319461381

Epoch: 5| Step: 4
Training loss: 5.687715295761958
Validation loss: 5.830824055708153

Epoch: 5| Step: 5
Training loss: 6.1585484585420724
Validation loss: 5.826757357493152

Epoch: 5| Step: 6
Training loss: 5.741765303887964
Validation loss: 5.822379545257314

Epoch: 5| Step: 7
Training loss: 5.733196418073681
Validation loss: 5.817791905453173

Epoch: 5| Step: 8
Training loss: 5.482394564580623
Validation loss: 5.8132997324975735

Epoch: 5| Step: 9
Training loss: 6.028053187550156
Validation loss: 5.80846784053732

Epoch: 5| Step: 10
Training loss: 6.180020830927929
Validation loss: 5.8037751868393865

Epoch: 5| Step: 11
Training loss: 5.195027600271064
Validation loss: 5.798765026900028

Epoch: 5| Step: 0
Training loss: 6.108359015785062
Validation loss: 5.793530838822151

Epoch: 5| Step: 1
Training loss: 5.976509522845267
Validation loss: 5.788143611848241

Epoch: 5| Step: 2
Training loss: 6.102939347794743
Validation loss: 5.782858870426106

Epoch: 5| Step: 3
Training loss: 7.056912262537515
Validation loss: 5.777108938016207

Epoch: 5| Step: 4
Training loss: 4.723008211334282
Validation loss: 5.771337530739078

Epoch: 5| Step: 5
Training loss: 6.5712117816872375
Validation loss: 5.765477041604879

Epoch: 5| Step: 6
Training loss: 5.35881017260963
Validation loss: 5.759364001463173

Epoch: 5| Step: 7
Training loss: 6.1864567657467004
Validation loss: 5.753447666958664

Epoch: 5| Step: 8
Training loss: 5.869786973041417
Validation loss: 5.747291189490475

Epoch: 5| Step: 9
Training loss: 4.361461946558665
Validation loss: 5.74115432821224

Epoch: 5| Step: 10
Training loss: 6.006660261641181
Validation loss: 5.735112966507432

Epoch: 5| Step: 11
Training loss: 5.193638857537125
Validation loss: 5.728972659438584

Epoch: 6| Step: 0
Training loss: 5.678597997721494
Validation loss: 5.722931075196609

Epoch: 5| Step: 1
Training loss: 6.021750761927094
Validation loss: 5.716613745745649

Epoch: 5| Step: 2
Training loss: 6.028165829185538
Validation loss: 5.7107190926636475

Epoch: 5| Step: 3
Training loss: 6.129926607523376
Validation loss: 5.704466375479608

Epoch: 5| Step: 4
Training loss: 5.678581875279938
Validation loss: 5.6985031630401926

Epoch: 5| Step: 5
Training loss: 4.847931269268649
Validation loss: 5.692469657880746

Epoch: 5| Step: 6
Training loss: 5.507792241485349
Validation loss: 5.686577082778421

Epoch: 5| Step: 7
Training loss: 6.046886039940665
Validation loss: 5.680856240772725

Epoch: 5| Step: 8
Training loss: 5.7746802039177485
Validation loss: 5.67493611130343

Epoch: 5| Step: 9
Training loss: 6.332215896540514
Validation loss: 5.669076640830945

Epoch: 5| Step: 10
Training loss: 5.906915536349276
Validation loss: 5.662999202851038

Epoch: 5| Step: 11
Training loss: 4.852295849302191
Validation loss: 5.65716917602716

Epoch: 7| Step: 0
Training loss: 5.611208135355634
Validation loss: 5.650997744153694

Epoch: 5| Step: 1
Training loss: 5.992323415077717
Validation loss: 5.644835136355544

Epoch: 5| Step: 2
Training loss: 5.650637038785255
Validation loss: 5.638729005759153

Epoch: 5| Step: 3
Training loss: 6.3794570002980935
Validation loss: 5.632462835018549

Epoch: 5| Step: 4
Training loss: 5.612622864191875
Validation loss: 5.625560817312114

Epoch: 5| Step: 5
Training loss: 5.938280877413322
Validation loss: 5.619653477942214

Epoch: 5| Step: 6
Training loss: 5.598834747606492
Validation loss: 5.612828614513187

Epoch: 5| Step: 7
Training loss: 5.660066950102151
Validation loss: 5.606266169700141

Epoch: 5| Step: 8
Training loss: 5.489573044981415
Validation loss: 5.599858903242688

Epoch: 5| Step: 9
Training loss: 5.45588749645953
Validation loss: 5.593365277747383

Epoch: 5| Step: 10
Training loss: 6.029918464375096
Validation loss: 5.586882426405652

Epoch: 5| Step: 11
Training loss: 3.5011447669233955
Validation loss: 5.580529301194837

Epoch: 8| Step: 0
Training loss: 5.022438816212464
Validation loss: 5.574134147018049

Epoch: 5| Step: 1
Training loss: 4.463102600272219
Validation loss: 5.568018936424191

Epoch: 5| Step: 2
Training loss: 6.190870811823762
Validation loss: 5.561721268624855

Epoch: 5| Step: 3
Training loss: 5.998671384575667
Validation loss: 5.555301258571979

Epoch: 5| Step: 4
Training loss: 5.951453587543761
Validation loss: 5.54836899244118

Epoch: 5| Step: 5
Training loss: 5.837507371264752
Validation loss: 5.542033572945695

Epoch: 5| Step: 6
Training loss: 5.868940434397828
Validation loss: 5.535461166120655

Epoch: 5| Step: 7
Training loss: 5.136653397873251
Validation loss: 5.529081720630566

Epoch: 5| Step: 8
Training loss: 6.312312359428836
Validation loss: 5.522896703767714

Epoch: 5| Step: 9
Training loss: 5.417983359693262
Validation loss: 5.516945930204475

Epoch: 5| Step: 10
Training loss: 5.434696746479632
Validation loss: 5.5112022339921225

Epoch: 5| Step: 11
Training loss: 7.24549094106471
Validation loss: 5.505178376269389

Epoch: 9| Step: 0
Training loss: 6.638537700449774
Validation loss: 5.498869129441823

Epoch: 5| Step: 1
Training loss: 5.687365855217488
Validation loss: 5.492647357064217

Epoch: 5| Step: 2
Training loss: 5.818485254806477
Validation loss: 5.486562156914065

Epoch: 5| Step: 3
Training loss: 5.646957435702845
Validation loss: 5.480283096442549

Epoch: 5| Step: 4
Training loss: 5.253528317610513
Validation loss: 5.474124861149304

Epoch: 5| Step: 5
Training loss: 5.747414712625691
Validation loss: 5.468495121420544

Epoch: 5| Step: 6
Training loss: 5.844416126493659
Validation loss: 5.462958046209897

Epoch: 5| Step: 7
Training loss: 4.8277443547488685
Validation loss: 5.456865020965364

Epoch: 5| Step: 8
Training loss: 5.052243805004857
Validation loss: 5.45134954688042

Epoch: 5| Step: 9
Training loss: 4.8924235488929915
Validation loss: 5.445734548609178

Epoch: 5| Step: 10
Training loss: 5.807325130987755
Validation loss: 5.440214546463115

Epoch: 5| Step: 11
Training loss: 5.766212495474716
Validation loss: 5.434522434696634

Epoch: 10| Step: 0
Training loss: 5.909448151360098
Validation loss: 5.428895060941765

Epoch: 5| Step: 1
Training loss: 6.008869926346222
Validation loss: 5.423041065307017

Epoch: 5| Step: 2
Training loss: 5.790575249381533
Validation loss: 5.417256442998314

Epoch: 5| Step: 3
Training loss: 4.467000125185604
Validation loss: 5.411616482472132

Epoch: 5| Step: 4
Training loss: 5.420615102063307
Validation loss: 5.404765629081892

Epoch: 5| Step: 5
Training loss: 4.778518594681493
Validation loss: 5.39796459667972

Epoch: 5| Step: 6
Training loss: 5.887641778684513
Validation loss: 5.390062223534135

Epoch: 5| Step: 7
Training loss: 6.079365660051489
Validation loss: 5.382983348480762

Epoch: 5| Step: 8
Training loss: 4.787766746480155
Validation loss: 5.376210231709312

Epoch: 5| Step: 9
Training loss: 5.707588351380849
Validation loss: 5.370501513572882

Epoch: 5| Step: 10
Training loss: 5.7736707338291975
Validation loss: 5.364353577468351

Epoch: 5| Step: 11
Training loss: 4.398859196939255
Validation loss: 5.358222778251639

Epoch: 11| Step: 0
Training loss: 4.722620305255063
Validation loss: 5.351848050780647

Epoch: 5| Step: 1
Training loss: 5.999718977386957
Validation loss: 5.345782103656029

Epoch: 5| Step: 2
Training loss: 4.64065315417859
Validation loss: 5.339361690406564

Epoch: 5| Step: 3
Training loss: 5.361165006341413
Validation loss: 5.333076726680894

Epoch: 5| Step: 4
Training loss: 4.56993145780686
Validation loss: 5.326773202596218

Epoch: 5| Step: 5
Training loss: 4.801130463677075
Validation loss: 5.320359224701518

Epoch: 5| Step: 6
Training loss: 5.8441292542792596
Validation loss: 5.314460669337737

Epoch: 5| Step: 7
Training loss: 5.614793800650931
Validation loss: 5.3084830487076955

Epoch: 5| Step: 8
Training loss: 5.825640519580564
Validation loss: 5.301987955051163

Epoch: 5| Step: 9
Training loss: 5.111814330739442
Validation loss: 5.296012313043335

Epoch: 5| Step: 10
Training loss: 6.947029236296688
Validation loss: 5.290520861870645

Epoch: 5| Step: 11
Training loss: 4.993281046173858
Validation loss: 5.285057824443146

Epoch: 12| Step: 0
Training loss: 4.793098081104526
Validation loss: 5.279690867860684

Epoch: 5| Step: 1
Training loss: 5.4068181615850825
Validation loss: 5.274270225051079

Epoch: 5| Step: 2
Training loss: 5.077386326984795
Validation loss: 5.269156745966864

Epoch: 5| Step: 3
Training loss: 5.603888333391825
Validation loss: 5.263589188133294

Epoch: 5| Step: 4
Training loss: 5.439168389091533
Validation loss: 5.258594252656663

Epoch: 5| Step: 5
Training loss: 5.6365485426701465
Validation loss: 5.252803235749089

Epoch: 5| Step: 6
Training loss: 5.588714549533024
Validation loss: 5.247823051939205

Epoch: 5| Step: 7
Training loss: 5.307472273349438
Validation loss: 5.242341146856276

Epoch: 5| Step: 8
Training loss: 5.151403010094639
Validation loss: 5.236630446326768

Epoch: 5| Step: 9
Training loss: 5.576699638444039
Validation loss: 5.231414481508868

Epoch: 5| Step: 10
Training loss: 5.372947123415195
Validation loss: 5.226342098224761

Epoch: 5| Step: 11
Training loss: 5.8704611919092775
Validation loss: 5.220864124719777

Epoch: 13| Step: 0
Training loss: 5.916981469317945
Validation loss: 5.215762282496707

Epoch: 5| Step: 1
Training loss: 5.32158772202232
Validation loss: 5.210641474134018

Epoch: 5| Step: 2
Training loss: 5.095806432212676
Validation loss: 5.205966673701966

Epoch: 5| Step: 3
Training loss: 4.784000577920222
Validation loss: 5.201676450600183

Epoch: 5| Step: 4
Training loss: 5.4380298224834815
Validation loss: 5.196388358864293

Epoch: 5| Step: 5
Training loss: 5.062931937169908
Validation loss: 5.191384029603989

Epoch: 5| Step: 6
Training loss: 6.074704185787504
Validation loss: 5.18661445504773

Epoch: 5| Step: 7
Training loss: 5.108114944610538
Validation loss: 5.182380877418645

Epoch: 5| Step: 8
Training loss: 5.569947133113009
Validation loss: 5.17773209567831

Epoch: 5| Step: 9
Training loss: 5.031146883648275
Validation loss: 5.17222872136235

Epoch: 5| Step: 10
Training loss: 5.205477529235242
Validation loss: 5.168054443017984

Epoch: 5| Step: 11
Training loss: 3.651010002546732
Validation loss: 5.163366427618216

Epoch: 14| Step: 0
Training loss: 4.951581166822952
Validation loss: 5.159963145506391

Epoch: 5| Step: 1
Training loss: 6.067744552657011
Validation loss: 5.155804123529329

Epoch: 5| Step: 2
Training loss: 5.159736702877152
Validation loss: 5.152143295665173

Epoch: 5| Step: 3
Training loss: 5.263336136961938
Validation loss: 5.147649995181812

Epoch: 5| Step: 4
Training loss: 4.734008976349663
Validation loss: 5.143168708027434

Epoch: 5| Step: 5
Training loss: 5.6251617408387204
Validation loss: 5.138162535234235

Epoch: 5| Step: 6
Training loss: 5.205646075955917
Validation loss: 5.134161924188586

Epoch: 5| Step: 7
Training loss: 5.163674852188699
Validation loss: 5.130021759616641

Epoch: 5| Step: 8
Training loss: 5.3340970128394565
Validation loss: 5.125267440516886

Epoch: 5| Step: 9
Training loss: 4.826235108094457
Validation loss: 5.121322390071324

Epoch: 5| Step: 10
Training loss: 5.0407971139318075
Validation loss: 5.117703135673026

Epoch: 5| Step: 11
Training loss: 6.926534423495855
Validation loss: 5.113092188282035

Epoch: 15| Step: 0
Training loss: 3.9511124987814945
Validation loss: 5.108777710264113

Epoch: 5| Step: 1
Training loss: 5.670394494059626
Validation loss: 5.104380749734675

Epoch: 5| Step: 2
Training loss: 5.891724501581779
Validation loss: 5.101077926701095

Epoch: 5| Step: 3
Training loss: 5.028136243505336
Validation loss: 5.0966278247006

Epoch: 5| Step: 4
Training loss: 5.181174408622381
Validation loss: 5.092828827237038

Epoch: 5| Step: 5
Training loss: 5.507424631732944
Validation loss: 5.087843514857073

Epoch: 5| Step: 6
Training loss: 4.707834110406653
Validation loss: 5.083659359633774

Epoch: 5| Step: 7
Training loss: 5.489086941806616
Validation loss: 5.079279059318441

Epoch: 5| Step: 8
Training loss: 5.53252021299756
Validation loss: 5.075882276567223

Epoch: 5| Step: 9
Training loss: 5.235261665515956
Validation loss: 5.071914012396151

Epoch: 5| Step: 10
Training loss: 5.211994115490933
Validation loss: 5.067458436403733

Epoch: 5| Step: 11
Training loss: 3.096297785205811
Validation loss: 5.063026424400032

Epoch: 16| Step: 0
Training loss: 5.086559626768365
Validation loss: 5.058847632597511

Epoch: 5| Step: 1
Training loss: 4.790102075751431
Validation loss: 5.054615843715532

Epoch: 5| Step: 2
Training loss: 5.332749136082502
Validation loss: 5.0511503819824615

Epoch: 5| Step: 3
Training loss: 5.094923761787583
Validation loss: 5.046950088745476

Epoch: 5| Step: 4
Training loss: 5.269369995274077
Validation loss: 5.042038638472152

Epoch: 5| Step: 5
Training loss: 5.619423539269512
Validation loss: 5.038616497795107

Epoch: 5| Step: 6
Training loss: 5.274165712162501
Validation loss: 5.034821176835356

Epoch: 5| Step: 7
Training loss: 5.155803129310033
Validation loss: 5.029909685940722

Epoch: 5| Step: 8
Training loss: 4.75630492330312
Validation loss: 5.026383939430648

Epoch: 5| Step: 9
Training loss: 5.400029479052294
Validation loss: 5.021856776142901

Epoch: 5| Step: 10
Training loss: 4.9194411299957785
Validation loss: 5.018240447758372

Epoch: 5| Step: 11
Training loss: 5.315926019307363
Validation loss: 5.014031906882573

Epoch: 17| Step: 0
Training loss: 5.207038576045109
Validation loss: 5.009184488222393

Epoch: 5| Step: 1
Training loss: 5.654069005825082
Validation loss: 5.006128973416711

Epoch: 5| Step: 2
Training loss: 4.963330462172895
Validation loss: 5.001586511362237

Epoch: 5| Step: 3
Training loss: 5.324812858051126
Validation loss: 4.997311942420302

Epoch: 5| Step: 4
Training loss: 5.063949189158681
Validation loss: 4.992706900626325

Epoch: 5| Step: 5
Training loss: 5.848818615688022
Validation loss: 4.9884655150950135

Epoch: 5| Step: 6
Training loss: 5.024685006208956
Validation loss: 4.984154842859958

Epoch: 5| Step: 7
Training loss: 4.603571558447854
Validation loss: 4.979931906894644

Epoch: 5| Step: 8
Training loss: 5.253044517213718
Validation loss: 4.975066011396644

Epoch: 5| Step: 9
Training loss: 4.343348861943725
Validation loss: 4.970290099286077

Epoch: 5| Step: 10
Training loss: 4.65561646113366
Validation loss: 4.9664704633954795

Epoch: 5| Step: 11
Training loss: 5.693192201126258
Validation loss: 4.962089809245117

Epoch: 18| Step: 0
Training loss: 5.074234725304433
Validation loss: 4.958996907343935

Epoch: 5| Step: 1
Training loss: 4.612024819313092
Validation loss: 4.9538100056748355

Epoch: 5| Step: 2
Training loss: 5.376899206277061
Validation loss: 4.948934778237604

Epoch: 5| Step: 3
Training loss: 5.473182843486267
Validation loss: 4.944583937585801

Epoch: 5| Step: 4
Training loss: 5.06183026440144
Validation loss: 4.94036859968585

Epoch: 5| Step: 5
Training loss: 5.12664173161495
Validation loss: 4.935582806791424

Epoch: 5| Step: 6
Training loss: 5.383428485765603
Validation loss: 4.932029010851355

Epoch: 5| Step: 7
Training loss: 5.128966122675098
Validation loss: 4.927920089651252

Epoch: 5| Step: 8
Training loss: 4.315789999490493
Validation loss: 4.923299544925922

Epoch: 5| Step: 9
Training loss: 4.778994358529566
Validation loss: 4.9186475637288485

Epoch: 5| Step: 10
Training loss: 5.674116212027883
Validation loss: 4.914520015958204

Epoch: 5| Step: 11
Training loss: 0.9326486951688501
Validation loss: 4.909937110933203

Epoch: 19| Step: 0
Training loss: 4.477800926945885
Validation loss: 4.905847059092116

Epoch: 5| Step: 1
Training loss: 5.6241586691774605
Validation loss: 4.902130730244873

Epoch: 5| Step: 2
Training loss: 5.522308363691427
Validation loss: 4.898255153671141

Epoch: 5| Step: 3
Training loss: 5.3834966880807285
Validation loss: 4.894220007894729

Epoch: 5| Step: 4
Training loss: 5.066731885858362
Validation loss: 4.890424819765719

Epoch: 5| Step: 5
Training loss: 5.411954483134041
Validation loss: 4.886387875559328

Epoch: 5| Step: 6
Training loss: 5.160407222677046
Validation loss: 4.881963003903173

Epoch: 5| Step: 7
Training loss: 4.461525579327672
Validation loss: 4.877215061529866

Epoch: 5| Step: 8
Training loss: 4.925519484023995
Validation loss: 4.873111228543427

Epoch: 5| Step: 9
Training loss: 4.148277495148777
Validation loss: 4.86909740483392

Epoch: 5| Step: 10
Training loss: 4.764171541291677
Validation loss: 4.865444493768597

Epoch: 5| Step: 11
Training loss: 4.795080986413031
Validation loss: 4.860188799358032

Epoch: 20| Step: 0
Training loss: 5.111247521575006
Validation loss: 4.8552208916726025

Epoch: 5| Step: 1
Training loss: 4.788722961237923
Validation loss: 4.851778501656391

Epoch: 5| Step: 2
Training loss: 4.568441624286308
Validation loss: 4.848252703674965

Epoch: 5| Step: 3
Training loss: 5.5789929310435395
Validation loss: 4.844584829928922

Epoch: 5| Step: 4
Training loss: 4.708422139548391
Validation loss: 4.8383570520544765

Epoch: 5| Step: 5
Training loss: 5.496211741359622
Validation loss: 4.833919837597913

Epoch: 5| Step: 6
Training loss: 5.473581501348481
Validation loss: 4.829785099645694

Epoch: 5| Step: 7
Training loss: 4.219778656058624
Validation loss: 4.8260178396667515

Epoch: 5| Step: 8
Training loss: 4.818056342125272
Validation loss: 4.821105669198813

Epoch: 5| Step: 9
Training loss: 4.78058654570203
Validation loss: 4.816163406788295

Epoch: 5| Step: 10
Training loss: 4.875830359533265
Validation loss: 4.811752897127885

Epoch: 5| Step: 11
Training loss: 4.795688743411278
Validation loss: 4.807781465926339

Epoch: 21| Step: 0
Training loss: 5.440186637032957
Validation loss: 4.803805965614075

Epoch: 5| Step: 1
Training loss: 4.2062219037822315
Validation loss: 4.799961054167106

Epoch: 5| Step: 2
Training loss: 5.47477312009847
Validation loss: 4.795632009757553

Epoch: 5| Step: 3
Training loss: 4.889647364782936
Validation loss: 4.790845164768068

Epoch: 5| Step: 4
Training loss: 3.7979928086279533
Validation loss: 4.786713206991169

Epoch: 5| Step: 5
Training loss: 5.315985758995574
Validation loss: 4.78177444640137

Epoch: 5| Step: 6
Training loss: 5.164624805394208
Validation loss: 4.777371639108961

Epoch: 5| Step: 7
Training loss: 5.78304382537695
Validation loss: 4.771903466333579

Epoch: 5| Step: 8
Training loss: 4.606179374246554
Validation loss: 4.767348581278944

Epoch: 5| Step: 9
Training loss: 4.098195465073169
Validation loss: 4.762775065103888

Epoch: 5| Step: 10
Training loss: 4.605771482708161
Validation loss: 4.757683203599755

Epoch: 5| Step: 11
Training loss: 5.7335540433289225
Validation loss: 4.753732143652433

Epoch: 22| Step: 0
Training loss: 4.5156788542284945
Validation loss: 4.749463092843548

Epoch: 5| Step: 1
Training loss: 5.076021198826646
Validation loss: 4.744255180750453

Epoch: 5| Step: 2
Training loss: 4.360432595656611
Validation loss: 4.739799774034664

Epoch: 5| Step: 3
Training loss: 4.440233060545134
Validation loss: 4.734623229986046

Epoch: 5| Step: 4
Training loss: 4.5272655990477615
Validation loss: 4.730391409609495

Epoch: 5| Step: 5
Training loss: 5.0580375689660775
Validation loss: 4.725697735160798

Epoch: 5| Step: 6
Training loss: 4.515707576221076
Validation loss: 4.721254572490336

Epoch: 5| Step: 7
Training loss: 5.027255350208618
Validation loss: 4.718455012787295

Epoch: 5| Step: 8
Training loss: 4.94769200935976
Validation loss: 4.712861123317427

Epoch: 5| Step: 9
Training loss: 5.28138145870043
Validation loss: 4.708254592653444

Epoch: 5| Step: 10
Training loss: 5.508955167373648
Validation loss: 4.70392365291113

Epoch: 5| Step: 11
Training loss: 4.636670620932814
Validation loss: 4.698727179036592

Epoch: 23| Step: 0
Training loss: 4.681210787396265
Validation loss: 4.693369966606924

Epoch: 5| Step: 1
Training loss: 4.44905777289173
Validation loss: 4.689417781588078

Epoch: 5| Step: 2
Training loss: 5.473950164333918
Validation loss: 4.685251027061888

Epoch: 5| Step: 3
Training loss: 5.1338341101255
Validation loss: 4.6797869655289634

Epoch: 5| Step: 4
Training loss: 5.3020922867475155
Validation loss: 4.674481033990712

Epoch: 5| Step: 5
Training loss: 4.331888373644209
Validation loss: 4.669650727402335

Epoch: 5| Step: 6
Training loss: 4.896001328636438
Validation loss: 4.665035025004141

Epoch: 5| Step: 7
Training loss: 4.723529744359572
Validation loss: 4.660125919913765

Epoch: 5| Step: 8
Training loss: 4.9158064957255965
Validation loss: 4.654728446712906

Epoch: 5| Step: 9
Training loss: 4.678906918543324
Validation loss: 4.6505383827589535

Epoch: 5| Step: 10
Training loss: 3.76994285115201
Validation loss: 4.64673951068401

Epoch: 5| Step: 11
Training loss: 5.646034415442517
Validation loss: 4.642244110053285

Epoch: 24| Step: 0
Training loss: 5.027807538885243
Validation loss: 4.63575630086729

Epoch: 5| Step: 1
Training loss: 4.552709447660737
Validation loss: 4.631780105158876

Epoch: 5| Step: 2
Training loss: 4.58059198876404
Validation loss: 4.626542770548087

Epoch: 5| Step: 3
Training loss: 4.869594217741247
Validation loss: 4.622760122925612

Epoch: 5| Step: 4
Training loss: 5.224677277596129
Validation loss: 4.617639273171467

Epoch: 5| Step: 5
Training loss: 4.760735677078881
Validation loss: 4.613264763759836

Epoch: 5| Step: 6
Training loss: 5.188059948953515
Validation loss: 4.608578038688677

Epoch: 5| Step: 7
Training loss: 4.6315267750434455
Validation loss: 4.603388322082363

Epoch: 5| Step: 8
Training loss: 4.445804615637075
Validation loss: 4.598625934320527

Epoch: 5| Step: 9
Training loss: 4.438185303115457
Validation loss: 4.594203472461694

Epoch: 5| Step: 10
Training loss: 4.31037009896072
Validation loss: 4.589403124281558

Epoch: 5| Step: 11
Training loss: 4.792623717333468
Validation loss: 4.584704777688479

Epoch: 25| Step: 0
Training loss: 4.633426516211078
Validation loss: 4.579894707863164

Epoch: 5| Step: 1
Training loss: 5.0032200934708975
Validation loss: 4.574950687649924

Epoch: 5| Step: 2
Training loss: 4.26950489255931
Validation loss: 4.570154814431643

Epoch: 5| Step: 3
Training loss: 5.235115386070182
Validation loss: 4.5651069970420455

Epoch: 5| Step: 4
Training loss: 5.060081752071451
Validation loss: 4.55988806595532

Epoch: 5| Step: 5
Training loss: 3.9036781084059493
Validation loss: 4.555501491075917

Epoch: 5| Step: 6
Training loss: 4.9661247947766
Validation loss: 4.550112341971578

Epoch: 5| Step: 7
Training loss: 4.027104575069403
Validation loss: 4.545594693862674

Epoch: 5| Step: 8
Training loss: 4.721563447864692
Validation loss: 4.541008930816639

Epoch: 5| Step: 9
Training loss: 4.607547721098205
Validation loss: 4.535829864777227

Epoch: 5| Step: 10
Training loss: 5.13032664309435
Validation loss: 4.531414116704552

Epoch: 5| Step: 11
Training loss: 3.1780920876568306
Validation loss: 4.527025318549366

Epoch: 26| Step: 0
Training loss: 5.142285110812962
Validation loss: 4.521808372627104

Epoch: 5| Step: 1
Training loss: 4.492678089719614
Validation loss: 4.5175922161035915

Epoch: 5| Step: 2
Training loss: 4.595069955121038
Validation loss: 4.5129428012248365

Epoch: 5| Step: 3
Training loss: 4.965790641043361
Validation loss: 4.50793161130168

Epoch: 5| Step: 4
Training loss: 4.51793804128581
Validation loss: 4.503487524776037

Epoch: 5| Step: 5
Training loss: 4.04160628650566
Validation loss: 4.498905242985876

Epoch: 5| Step: 6
Training loss: 4.9159349231059695
Validation loss: 4.494333461187038

Epoch: 5| Step: 7
Training loss: 4.508601127939727
Validation loss: 4.48925340447698

Epoch: 5| Step: 8
Training loss: 4.241927165268099
Validation loss: 4.48500044268064

Epoch: 5| Step: 9
Training loss: 4.819314664815006
Validation loss: 4.480761273742147

Epoch: 5| Step: 10
Training loss: 4.707992113740421
Validation loss: 4.474852727530273

Epoch: 5| Step: 11
Training loss: 3.732292967545991
Validation loss: 4.471401628328646

Epoch: 27| Step: 0
Training loss: 4.3731027031385015
Validation loss: 4.46621380486401

Epoch: 5| Step: 1
Training loss: 4.671234393135848
Validation loss: 4.462738176965519

Epoch: 5| Step: 2
Training loss: 4.970354696776436
Validation loss: 4.457225187976266

Epoch: 5| Step: 3
Training loss: 4.132239722093772
Validation loss: 4.452186940757366

Epoch: 5| Step: 4
Training loss: 4.833291656489844
Validation loss: 4.447048713041555

Epoch: 5| Step: 5
Training loss: 3.658503693688637
Validation loss: 4.44366526462551

Epoch: 5| Step: 6
Training loss: 4.834572446868343
Validation loss: 4.438978982990386

Epoch: 5| Step: 7
Training loss: 5.190000735597062
Validation loss: 4.433808927313807

Epoch: 5| Step: 8
Training loss: 5.5594134393213315
Validation loss: 4.430055373142126

Epoch: 5| Step: 9
Training loss: 3.8738634226941957
Validation loss: 4.423967996144668

Epoch: 5| Step: 10
Training loss: 3.544165025524265
Validation loss: 4.419464838388636

Epoch: 5| Step: 11
Training loss: 5.435949871929637
Validation loss: 4.414585489893925

Epoch: 28| Step: 0
Training loss: 5.334503562017166
Validation loss: 4.408797044228133

Epoch: 5| Step: 1
Training loss: 4.250109727228398
Validation loss: 4.40496003768235

Epoch: 5| Step: 2
Training loss: 4.522871598075252
Validation loss: 4.399726710357604

Epoch: 5| Step: 3
Training loss: 4.218342853255566
Validation loss: 4.3956956736386985

Epoch: 5| Step: 4
Training loss: 4.694371794088927
Validation loss: 4.39037638149271

Epoch: 5| Step: 5
Training loss: 3.9052873569706925
Validation loss: 4.384574844072758

Epoch: 5| Step: 6
Training loss: 4.187926996580352
Validation loss: 4.381058303912919

Epoch: 5| Step: 7
Training loss: 3.6573169162320123
Validation loss: 4.375976317324182

Epoch: 5| Step: 8
Training loss: 5.177478716340058
Validation loss: 4.371315658159133

Epoch: 5| Step: 9
Training loss: 4.685909153877044
Validation loss: 4.366345692381469

Epoch: 5| Step: 10
Training loss: 4.6591898195040224
Validation loss: 4.361518601732353

Epoch: 5| Step: 11
Training loss: 4.975052201653736
Validation loss: 4.357816793686538

Epoch: 29| Step: 0
Training loss: 4.025489180319473
Validation loss: 4.352262293433905

Epoch: 5| Step: 1
Training loss: 4.684806762097383
Validation loss: 4.348238494446081

Epoch: 5| Step: 2
Training loss: 4.66512441127834
Validation loss: 4.343274504435637

Epoch: 5| Step: 3
Training loss: 4.864797626924242
Validation loss: 4.339105103150455

Epoch: 5| Step: 4
Training loss: 4.9157977656459275
Validation loss: 4.333605077671531

Epoch: 5| Step: 5
Training loss: 4.376465906059853
Validation loss: 4.328220095548028

Epoch: 5| Step: 6
Training loss: 4.259049150257208
Validation loss: 4.323171753615151

Epoch: 5| Step: 7
Training loss: 3.881699953396481
Validation loss: 4.317406121120366

Epoch: 5| Step: 8
Training loss: 4.2966139835494666
Validation loss: 4.3125304621850695

Epoch: 5| Step: 9
Training loss: 4.868060136334266
Validation loss: 4.307473252269305

Epoch: 5| Step: 10
Training loss: 4.103735938279051
Validation loss: 4.302272342966494

Epoch: 5| Step: 11
Training loss: 4.193335950170367
Validation loss: 4.296646005713006

Epoch: 30| Step: 0
Training loss: 4.970325532072863
Validation loss: 4.293050555212528

Epoch: 5| Step: 1
Training loss: 4.193250437060166
Validation loss: 4.287724455879473

Epoch: 5| Step: 2
Training loss: 4.367195798152895
Validation loss: 4.282092691356657

Epoch: 5| Step: 3
Training loss: 4.92486771923896
Validation loss: 4.2767207140467

Epoch: 5| Step: 4
Training loss: 3.7314249940152777
Validation loss: 4.271353837216231

Epoch: 5| Step: 5
Training loss: 4.290100083328545
Validation loss: 4.267005445521125

Epoch: 5| Step: 6
Training loss: 3.9994694834805267
Validation loss: 4.263001376857024

Epoch: 5| Step: 7
Training loss: 4.385151883042766
Validation loss: 4.256887912979894

Epoch: 5| Step: 8
Training loss: 3.845762888771911
Validation loss: 4.251400398959686

Epoch: 5| Step: 9
Training loss: 4.481434991441863
Validation loss: 4.2465235198152

Epoch: 5| Step: 10
Training loss: 5.106435134127597
Validation loss: 4.240530722049636

Epoch: 5| Step: 11
Training loss: 3.4997619820452415
Validation loss: 4.235922001784886

Epoch: 31| Step: 0
Training loss: 4.106822798679761
Validation loss: 4.23125170374751

Epoch: 5| Step: 1
Training loss: 4.007005993337126
Validation loss: 4.2265543441082665

Epoch: 5| Step: 2
Training loss: 3.62391027974441
Validation loss: 4.222442292172376

Epoch: 5| Step: 3
Training loss: 4.583240970490108
Validation loss: 4.217451187639734

Epoch: 5| Step: 4
Training loss: 4.430438373308842
Validation loss: 4.212878900876251

Epoch: 5| Step: 5
Training loss: 4.619443700416573
Validation loss: 4.207069205535282

Epoch: 5| Step: 6
Training loss: 4.453275336689304
Validation loss: 4.202219438909723

Epoch: 5| Step: 7
Training loss: 4.471005384127541
Validation loss: 4.1974005117586355

Epoch: 5| Step: 8
Training loss: 4.159118121646064
Validation loss: 4.192994308986087

Epoch: 5| Step: 9
Training loss: 4.801352135630365
Validation loss: 4.187943416101779

Epoch: 5| Step: 10
Training loss: 3.906833208416222
Validation loss: 4.183488043676407

Epoch: 5| Step: 11
Training loss: 6.017569566997323
Validation loss: 4.17787487619485

Epoch: 32| Step: 0
Training loss: 4.461197239250369
Validation loss: 4.173044128997917

Epoch: 5| Step: 1
Training loss: 4.222762396763697
Validation loss: 4.1679009500868425

Epoch: 5| Step: 2
Training loss: 4.45785046871153
Validation loss: 4.162551777606408

Epoch: 5| Step: 3
Training loss: 4.273498646300434
Validation loss: 4.157584447004987

Epoch: 5| Step: 4
Training loss: 4.936522374968976
Validation loss: 4.152726163865886

Epoch: 5| Step: 5
Training loss: 3.886452394493035
Validation loss: 4.147773890749944

Epoch: 5| Step: 6
Training loss: 4.168032358787116
Validation loss: 4.142980080946993

Epoch: 5| Step: 7
Training loss: 4.1689124857793445
Validation loss: 4.137412234332998

Epoch: 5| Step: 8
Training loss: 4.242870409322294
Validation loss: 4.133325123137862

Epoch: 5| Step: 9
Training loss: 3.967932909859797
Validation loss: 4.128405152911374

Epoch: 5| Step: 10
Training loss: 4.287132065002598
Validation loss: 4.123235676808352

Epoch: 5| Step: 11
Training loss: 3.8377089751064117
Validation loss: 4.118194558254817

Epoch: 33| Step: 0
Training loss: 4.294197718836653
Validation loss: 4.113611056542001

Epoch: 5| Step: 1
Training loss: 3.6018749440802313
Validation loss: 4.108784980141464

Epoch: 5| Step: 2
Training loss: 3.7596020155148704
Validation loss: 4.103977328094708

Epoch: 5| Step: 3
Training loss: 4.019938604920366
Validation loss: 4.099133584308508

Epoch: 5| Step: 4
Training loss: 4.3050014152923275
Validation loss: 4.094529871147927

Epoch: 5| Step: 5
Training loss: 4.908809310208958
Validation loss: 4.090448989947695

Epoch: 5| Step: 6
Training loss: 4.669286923257565
Validation loss: 4.08536844077559

Epoch: 5| Step: 7
Training loss: 4.374239828280724
Validation loss: 4.079971543388922

Epoch: 5| Step: 8
Training loss: 4.944484165236887
Validation loss: 4.07577500530825

Epoch: 5| Step: 9
Training loss: 4.2845711182519075
Validation loss: 4.070823027260319

Epoch: 5| Step: 10
Training loss: 3.277782242622855
Validation loss: 4.066117920487993

Epoch: 5| Step: 11
Training loss: 2.0124695201010963
Validation loss: 4.06109428049303

Epoch: 34| Step: 0
Training loss: 4.325142504158032
Validation loss: 4.0563493580299586

Epoch: 5| Step: 1
Training loss: 4.322734023069671
Validation loss: 4.051903059544166

Epoch: 5| Step: 2
Training loss: 4.3940715905435885
Validation loss: 4.047583671389852

Epoch: 5| Step: 3
Training loss: 3.6701518459245737
Validation loss: 4.043150706350757

Epoch: 5| Step: 4
Training loss: 4.147079561616929
Validation loss: 4.0378161831124935

Epoch: 5| Step: 5
Training loss: 4.619899308399586
Validation loss: 4.0331632622941775

Epoch: 5| Step: 6
Training loss: 3.834686261688945
Validation loss: 4.02903095057556

Epoch: 5| Step: 7
Training loss: 4.075816235383919
Validation loss: 4.023774961868351

Epoch: 5| Step: 8
Training loss: 3.9516142721468857
Validation loss: 4.019826791054137

Epoch: 5| Step: 9
Training loss: 3.963483424851153
Validation loss: 4.014541984599876

Epoch: 5| Step: 10
Training loss: 4.209902153056015
Validation loss: 4.0104006118783335

Epoch: 5| Step: 11
Training loss: 5.205453712410742
Validation loss: 4.0057777757298885

Epoch: 35| Step: 0
Training loss: 3.9218238128118137
Validation loss: 4.001325328133327

Epoch: 5| Step: 1
Training loss: 3.851358094894561
Validation loss: 3.997434185560645

Epoch: 5| Step: 2
Training loss: 4.022244826640289
Validation loss: 3.9923826843045718

Epoch: 5| Step: 3
Training loss: 4.355959412174624
Validation loss: 3.987787871896423

Epoch: 5| Step: 4
Training loss: 4.385680322883925
Validation loss: 3.9826478094244755

Epoch: 5| Step: 5
Training loss: 3.8093352393186843
Validation loss: 3.9780938298356974

Epoch: 5| Step: 6
Training loss: 4.55506646753718
Validation loss: 3.973833132963513

Epoch: 5| Step: 7
Training loss: 4.0967687294778
Validation loss: 3.9696809773097623

Epoch: 5| Step: 8
Training loss: 4.031781302046193
Validation loss: 3.965126435924539

Epoch: 5| Step: 9
Training loss: 4.179507699111654
Validation loss: 3.960340867511985

Epoch: 5| Step: 10
Training loss: 3.53658088093466
Validation loss: 3.955164844205867

Epoch: 5| Step: 11
Training loss: 5.656531901210676
Validation loss: 3.950271164362713

Epoch: 36| Step: 0
Training loss: 3.9080841641143387
Validation loss: 3.944642033277038

Epoch: 5| Step: 1
Training loss: 3.5294146874359593
Validation loss: 3.940177456244953

Epoch: 5| Step: 2
Training loss: 4.342706129488802
Validation loss: 3.935661148923819

Epoch: 5| Step: 3
Training loss: 4.24688831184103
Validation loss: 3.930390317242101

Epoch: 5| Step: 4
Training loss: 3.797371663077817
Validation loss: 3.9254453448925806

Epoch: 5| Step: 5
Training loss: 4.312441175861263
Validation loss: 3.920941584988243

Epoch: 5| Step: 6
Training loss: 4.600752080720277
Validation loss: 3.916387668101097

Epoch: 5| Step: 7
Training loss: 3.0971671604646787
Validation loss: 3.9117484799933893

Epoch: 5| Step: 8
Training loss: 3.835915000212463
Validation loss: 3.906845459375543

Epoch: 5| Step: 9
Training loss: 4.379738557581225
Validation loss: 3.902144988646061

Epoch: 5| Step: 10
Training loss: 4.210875445246613
Validation loss: 3.8978455373749936

Epoch: 5| Step: 11
Training loss: 4.55012170817486
Validation loss: 3.8925430339654943

Epoch: 37| Step: 0
Training loss: 4.879380043548053
Validation loss: 3.887763404713023

Epoch: 5| Step: 1
Training loss: 3.3696990592451916
Validation loss: 3.882762148739802

Epoch: 5| Step: 2
Training loss: 4.535902489275085
Validation loss: 3.878037006036678

Epoch: 5| Step: 3
Training loss: 3.681632076830262
Validation loss: 3.8730594175042357

Epoch: 5| Step: 4
Training loss: 3.784311867651173
Validation loss: 3.868271364339956

Epoch: 5| Step: 5
Training loss: 3.462467311883862
Validation loss: 3.8638110850176752

Epoch: 5| Step: 6
Training loss: 3.5285774853082392
Validation loss: 3.858571456676919

Epoch: 5| Step: 7
Training loss: 4.17395516301755
Validation loss: 3.8541138447758967

Epoch: 5| Step: 8
Training loss: 4.50629027794391
Validation loss: 3.8493709300046985

Epoch: 5| Step: 9
Training loss: 4.154329931991186
Validation loss: 3.844956356019152

Epoch: 5| Step: 10
Training loss: 3.8629536581437036
Validation loss: 3.840338756881163

Epoch: 5| Step: 11
Training loss: 2.435075581217691
Validation loss: 3.835358870632182

Epoch: 38| Step: 0
Training loss: 4.305429162798862
Validation loss: 3.830892307413132

Epoch: 5| Step: 1
Training loss: 4.0618912460816965
Validation loss: 3.826427778949098

Epoch: 5| Step: 2
Training loss: 3.266997418559362
Validation loss: 3.8222878932547872

Epoch: 5| Step: 3
Training loss: 3.932715400282189
Validation loss: 3.818027606154256

Epoch: 5| Step: 4
Training loss: 4.250048020035471
Validation loss: 3.8135135220646816

Epoch: 5| Step: 5
Training loss: 3.6416387497263236
Validation loss: 3.80896144037583

Epoch: 5| Step: 6
Training loss: 4.083574067369942
Validation loss: 3.804183059662633

Epoch: 5| Step: 7
Training loss: 3.4961349399633614
Validation loss: 3.799288873262634

Epoch: 5| Step: 8
Training loss: 3.9957493608473387
Validation loss: 3.795059842939154

Epoch: 5| Step: 9
Training loss: 4.462686760250733
Validation loss: 3.7906340076646656

Epoch: 5| Step: 10
Training loss: 3.9082175220718076
Validation loss: 3.786062016094566

Epoch: 5| Step: 11
Training loss: 2.8470101585086356
Validation loss: 3.7813457865707245

Epoch: 39| Step: 0
Training loss: 3.899581466127091
Validation loss: 3.77695535939905

Epoch: 5| Step: 1
Training loss: 4.502723081866965
Validation loss: 3.7726823881824654

Epoch: 5| Step: 2
Training loss: 4.257948231064785
Validation loss: 3.767879091077073

Epoch: 5| Step: 3
Training loss: 3.8249929889290577
Validation loss: 3.7632287131927904

Epoch: 5| Step: 4
Training loss: 4.339687066464455
Validation loss: 3.7585881755107993

Epoch: 5| Step: 5
Training loss: 3.341525469783219
Validation loss: 3.7541095044818595

Epoch: 5| Step: 6
Training loss: 3.433823856632915
Validation loss: 3.749630984057851

Epoch: 5| Step: 7
Training loss: 3.8353915010476562
Validation loss: 3.74483147053086

Epoch: 5| Step: 8
Training loss: 3.5669912838199727
Validation loss: 3.7403596410533

Epoch: 5| Step: 9
Training loss: 4.391761714092551
Validation loss: 3.736208913642495

Epoch: 5| Step: 10
Training loss: 3.4918001032591492
Validation loss: 3.731450258990672

Epoch: 5| Step: 11
Training loss: 1.8057592603099308
Validation loss: 3.726972758637893

Epoch: 40| Step: 0
Training loss: 3.902497953894578
Validation loss: 3.7228988963327247

Epoch: 5| Step: 1
Training loss: 4.4947326349807435
Validation loss: 3.7187581636568963

Epoch: 5| Step: 2
Training loss: 2.762412236403279
Validation loss: 3.7145536237902483

Epoch: 5| Step: 3
Training loss: 3.886733717386382
Validation loss: 3.710382975590095

Epoch: 5| Step: 4
Training loss: 3.5234776936541294
Validation loss: 3.7057940954800754

Epoch: 5| Step: 5
Training loss: 3.9520772517989844
Validation loss: 3.701476415553953

Epoch: 5| Step: 6
Training loss: 4.2166828883968535
Validation loss: 3.6972456399357654

Epoch: 5| Step: 7
Training loss: 4.477622447594608
Validation loss: 3.693009845313191

Epoch: 5| Step: 8
Training loss: 3.5539944486644455
Validation loss: 3.6883467440239976

Epoch: 5| Step: 9
Training loss: 3.9612878046371476
Validation loss: 3.683892516732022

Epoch: 5| Step: 10
Training loss: 3.3659419258534116
Validation loss: 3.679684152351903

Epoch: 5| Step: 11
Training loss: 2.586214909267071
Validation loss: 3.674867517111775

Epoch: 41| Step: 0
Training loss: 3.114248931862534
Validation loss: 3.670882460185701

Epoch: 5| Step: 1
Training loss: 3.5419029306630154
Validation loss: 3.6668683542065983

Epoch: 5| Step: 2
Training loss: 4.0584313779628935
Validation loss: 3.66288299120392

Epoch: 5| Step: 3
Training loss: 4.233899754955208
Validation loss: 3.659101070159828

Epoch: 5| Step: 4
Training loss: 3.6181006710455574
Validation loss: 3.6543910226633205

Epoch: 5| Step: 5
Training loss: 3.1990306458932616
Validation loss: 3.6502283644327527

Epoch: 5| Step: 6
Training loss: 4.287855857561516
Validation loss: 3.6457301406788565

Epoch: 5| Step: 7
Training loss: 3.238623146626396
Validation loss: 3.6411579598779773

Epoch: 5| Step: 8
Training loss: 3.885015894833996
Validation loss: 3.637115150971214

Epoch: 5| Step: 9
Training loss: 3.3198375407076615
Validation loss: 3.632960025977641

Epoch: 5| Step: 10
Training loss: 4.722229337998558
Validation loss: 3.6286383270905866

Epoch: 5| Step: 11
Training loss: 4.047656598704989
Validation loss: 3.62418321198872

Epoch: 42| Step: 0
Training loss: 2.455904509728948
Validation loss: 3.619586667995791

Epoch: 5| Step: 1
Training loss: 2.6809276680499825
Validation loss: 3.6151528674719318

Epoch: 5| Step: 2
Training loss: 4.09209099852806
Validation loss: 3.6111928262186637

Epoch: 5| Step: 3
Training loss: 3.9657665663296626
Validation loss: 3.6074297453431816

Epoch: 5| Step: 4
Training loss: 3.8452455665935337
Validation loss: 3.6035277603344813

Epoch: 5| Step: 5
Training loss: 4.016144833890111
Validation loss: 3.5987666235881344

Epoch: 5| Step: 6
Training loss: 4.028902301708726
Validation loss: 3.5947602220455335

Epoch: 5| Step: 7
Training loss: 3.6674383102876624
Validation loss: 3.5906712958724145

Epoch: 5| Step: 8
Training loss: 4.153755988530845
Validation loss: 3.5864742046399822

Epoch: 5| Step: 9
Training loss: 4.224162155232241
Validation loss: 3.581588967410817

Epoch: 5| Step: 10
Training loss: 3.736827093169172
Validation loss: 3.577070061257827

Epoch: 5| Step: 11
Training loss: 1.9790699249181303
Validation loss: 3.5725390046528434

Epoch: 43| Step: 0
Training loss: 3.900056980401494
Validation loss: 3.568072194202975

Epoch: 5| Step: 1
Training loss: 3.4358523494895232
Validation loss: 3.564032319891736

Epoch: 5| Step: 2
Training loss: 3.990086907991503
Validation loss: 3.5599017037392326

Epoch: 5| Step: 3
Training loss: 3.806062234591224
Validation loss: 3.5555365697698202

Epoch: 5| Step: 4
Training loss: 3.6979777299737537
Validation loss: 3.5510504256513733

Epoch: 5| Step: 5
Training loss: 3.3503691854165663
Validation loss: 3.546952699098686

Epoch: 5| Step: 6
Training loss: 3.3491762999008254
Validation loss: 3.5427144445456147

Epoch: 5| Step: 7
Training loss: 3.0041497458000372
Validation loss: 3.5383599365002136

Epoch: 5| Step: 8
Training loss: 4.141934860623527
Validation loss: 3.534391648590334

Epoch: 5| Step: 9
Training loss: 3.7585202381380314
Validation loss: 3.5304643831720575

Epoch: 5| Step: 10
Training loss: 3.9022134906156496
Validation loss: 3.526180961408142

Epoch: 5| Step: 11
Training loss: 3.9241952301906284
Validation loss: 3.5217051959574186

Epoch: 44| Step: 0
Training loss: 2.6107590710837516
Validation loss: 3.5176572111235167

Epoch: 5| Step: 1
Training loss: 4.128169373844827
Validation loss: 3.5136444673146046

Epoch: 5| Step: 2
Training loss: 3.8870936534012785
Validation loss: 3.5094962550044237

Epoch: 5| Step: 3
Training loss: 3.466989568808515
Validation loss: 3.5055888943834184

Epoch: 5| Step: 4
Training loss: 3.7907095878453054
Validation loss: 3.5015727778222496

Epoch: 5| Step: 5
Training loss: 3.6153108742243947
Validation loss: 3.497700702315743

Epoch: 5| Step: 6
Training loss: 4.028900644750803
Validation loss: 3.493157817354024

Epoch: 5| Step: 7
Training loss: 3.854268638017956
Validation loss: 3.4891163024762966

Epoch: 5| Step: 8
Training loss: 3.6829354435205808
Validation loss: 3.484884415866611

Epoch: 5| Step: 9
Training loss: 3.377125671108778
Validation loss: 3.4806066472186217

Epoch: 5| Step: 10
Training loss: 3.053117197235663
Validation loss: 3.4762045915370554

Epoch: 5| Step: 11
Training loss: 4.595980148299117
Validation loss: 3.471954097356105

Epoch: 45| Step: 0
Training loss: 2.703001074623857
Validation loss: 3.4676602688077973

Epoch: 5| Step: 1
Training loss: 4.241411619381502
Validation loss: 3.4629118765063973

Epoch: 5| Step: 2
Training loss: 3.2117169030587154
Validation loss: 3.457946661891727

Epoch: 5| Step: 3
Training loss: 4.198100777778072
Validation loss: 3.453711170830115

Epoch: 5| Step: 4
Training loss: 2.835290251713641
Validation loss: 3.448369377741272

Epoch: 5| Step: 5
Training loss: 3.9308553670449355
Validation loss: 3.444103095016107

Epoch: 5| Step: 6
Training loss: 3.8478045904542504
Validation loss: 3.4398932997564047

Epoch: 5| Step: 7
Training loss: 4.222893608543453
Validation loss: 3.4350286269626156

Epoch: 5| Step: 8
Training loss: 3.7035940653856314
Validation loss: 3.4306636136694735

Epoch: 5| Step: 9
Training loss: 3.096317497444813
Validation loss: 3.4255825900012833

Epoch: 5| Step: 10
Training loss: 3.072586731520737
Validation loss: 3.422133890284251

Epoch: 5| Step: 11
Training loss: 2.8804016784192665
Validation loss: 3.4182248206718624

Epoch: 46| Step: 0
Training loss: 4.340569299020534
Validation loss: 3.4140578443784997

Epoch: 5| Step: 1
Training loss: 3.2206126628915563
Validation loss: 3.4099648863652314

Epoch: 5| Step: 2
Training loss: 2.760576197974658
Validation loss: 3.4054120109156307

Epoch: 5| Step: 3
Training loss: 3.9932954150412603
Validation loss: 3.401077934332697

Epoch: 5| Step: 4
Training loss: 2.8114109049911007
Validation loss: 3.3975133611310158

Epoch: 5| Step: 5
Training loss: 3.323527281014327
Validation loss: 3.3924965007701156

Epoch: 5| Step: 6
Training loss: 3.993177914426329
Validation loss: 3.3890004639072275

Epoch: 5| Step: 7
Training loss: 3.6193622288637517
Validation loss: 3.3846008413286914

Epoch: 5| Step: 8
Training loss: 3.67609179621035
Validation loss: 3.380528225723403

Epoch: 5| Step: 9
Training loss: 3.637375982208838
Validation loss: 3.3772098170854092

Epoch: 5| Step: 10
Training loss: 3.111164134194379
Validation loss: 3.372528825688069

Epoch: 5| Step: 11
Training loss: 3.5925896139522178
Validation loss: 3.3684515973655014

Epoch: 47| Step: 0
Training loss: 3.867173690000594
Validation loss: 3.3646490112287664

Epoch: 5| Step: 1
Training loss: 2.9945013198531156
Validation loss: 3.3611007929784558

Epoch: 5| Step: 2
Training loss: 3.669052012813322
Validation loss: 3.356544100273523

Epoch: 5| Step: 3
Training loss: 3.8862136282557755
Validation loss: 3.3526189986967525

Epoch: 5| Step: 4
Training loss: 3.040467709651365
Validation loss: 3.348440534667733

Epoch: 5| Step: 5
Training loss: 3.649572159239437
Validation loss: 3.344313149253061

Epoch: 5| Step: 6
Training loss: 3.346763037652979
Validation loss: 3.340358160606596

Epoch: 5| Step: 7
Training loss: 4.274958756454238
Validation loss: 3.336171549225689

Epoch: 5| Step: 8
Training loss: 3.168825083187287
Validation loss: 3.3318773049989576

Epoch: 5| Step: 9
Training loss: 3.184769751402101
Validation loss: 3.3273573812525132

Epoch: 5| Step: 10
Training loss: 2.912286048201703
Validation loss: 3.3238991009535175

Epoch: 5| Step: 11
Training loss: 3.7840599779452506
Validation loss: 3.3192596980459363

Epoch: 48| Step: 0
Training loss: 3.2317048628859633
Validation loss: 3.314923731270314

Epoch: 5| Step: 1
Training loss: 3.309552446746556
Validation loss: 3.31069431633016

Epoch: 5| Step: 2
Training loss: 3.4237201889093973
Validation loss: 3.3069625009849037

Epoch: 5| Step: 3
Training loss: 3.118551849614322
Validation loss: 3.3032312032659967

Epoch: 5| Step: 4
Training loss: 3.9358371674885606
Validation loss: 3.29919921161016

Epoch: 5| Step: 5
Training loss: 3.927488405634268
Validation loss: 3.2957223742519233

Epoch: 5| Step: 6
Training loss: 3.6832905681998587
Validation loss: 3.291862208356811

Epoch: 5| Step: 7
Training loss: 3.3571288650592144
Validation loss: 3.2877247824169866

Epoch: 5| Step: 8
Training loss: 2.899863003092826
Validation loss: 3.284184829718475

Epoch: 5| Step: 9
Training loss: 3.9751152597667123
Validation loss: 3.2800997519347046

Epoch: 5| Step: 10
Training loss: 2.8727658754812566
Validation loss: 3.2768375822748257

Epoch: 5| Step: 11
Training loss: 2.428681978145854
Validation loss: 3.2729177100222206

Epoch: 49| Step: 0
Training loss: 3.8233166449885734
Validation loss: 3.2695128737722836

Epoch: 5| Step: 1
Training loss: 3.199686279415863
Validation loss: 3.2655446591753767

Epoch: 5| Step: 2
Training loss: 3.5612659659384285
Validation loss: 3.2626568326609604

Epoch: 5| Step: 3
Training loss: 3.7379671959414744
Validation loss: 3.257925700927989

Epoch: 5| Step: 4
Training loss: 2.9224564080947992
Validation loss: 3.2543334619430313

Epoch: 5| Step: 5
Training loss: 3.485878111274839
Validation loss: 3.2502545293760727

Epoch: 5| Step: 6
Training loss: 2.9914121096243047
Validation loss: 3.24620247546713

Epoch: 5| Step: 7
Training loss: 2.8783006380481315
Validation loss: 3.2429349964467993

Epoch: 5| Step: 8
Training loss: 3.425632869417018
Validation loss: 3.2392158279404537

Epoch: 5| Step: 9
Training loss: 3.403478492333736
Validation loss: 3.2360500107992456

Epoch: 5| Step: 10
Training loss: 3.7055137430475886
Validation loss: 3.23276835540972

Epoch: 5| Step: 11
Training loss: 3.497443764311513
Validation loss: 3.228973586965318

Epoch: 50| Step: 0
Training loss: 3.5100202176199193
Validation loss: 3.22565626051775

Epoch: 5| Step: 1
Training loss: 3.152031827523896
Validation loss: 3.2220899789536843

Epoch: 5| Step: 2
Training loss: 3.2453549275313254
Validation loss: 3.2188666856472774

Epoch: 5| Step: 3
Training loss: 2.999923705084535
Validation loss: 3.215453085893098

Epoch: 5| Step: 4
Training loss: 3.0474106537862693
Validation loss: 3.2120933648910834

Epoch: 5| Step: 5
Training loss: 3.5315268078904105
Validation loss: 3.2087747881151945

Epoch: 5| Step: 6
Training loss: 3.2142460987132364
Validation loss: 3.205531374760981

Epoch: 5| Step: 7
Training loss: 3.4169828377176312
Validation loss: 3.2021579957512833

Epoch: 5| Step: 8
Training loss: 4.141028273035703
Validation loss: 3.1992436036575618

Epoch: 5| Step: 9
Training loss: 3.056704584494569
Validation loss: 3.195197864269994

Epoch: 5| Step: 10
Training loss: 3.657271674454749
Validation loss: 3.191848213786041

Epoch: 5| Step: 11
Training loss: 1.0373864100217502
Validation loss: 3.188368286350675

Epoch: 51| Step: 0
Training loss: 3.3747753492398442
Validation loss: 3.1854217710551813

Epoch: 5| Step: 1
Training loss: 3.2899654354146555
Validation loss: 3.1822168536010698

Epoch: 5| Step: 2
Training loss: 3.4661407279596292
Validation loss: 3.1793125003315583

Epoch: 5| Step: 3
Training loss: 3.7141077895045136
Validation loss: 3.1760164950282355

Epoch: 5| Step: 4
Training loss: 3.6763333140157717
Validation loss: 3.1729245759126936

Epoch: 5| Step: 5
Training loss: 3.3474622423180693
Validation loss: 3.169636837155966

Epoch: 5| Step: 6
Training loss: 3.634468865924969
Validation loss: 3.165983983955831

Epoch: 5| Step: 7
Training loss: 3.419690554043245
Validation loss: 3.162353248608942

Epoch: 5| Step: 8
Training loss: 2.6824700058596043
Validation loss: 3.159357630942596

Epoch: 5| Step: 9
Training loss: 3.233134746024314
Validation loss: 3.1558521322135853

Epoch: 5| Step: 10
Training loss: 2.4839982040939352
Validation loss: 3.1529076696984792

Epoch: 5| Step: 11
Training loss: 2.671389708589649
Validation loss: 3.1495964750549086

Epoch: 52| Step: 0
Training loss: 3.0834346617123765
Validation loss: 3.1469898476931353

Epoch: 5| Step: 1
Training loss: 2.895455443244796
Validation loss: 3.1438001900440105

Epoch: 5| Step: 2
Training loss: 2.9479334171389904
Validation loss: 3.140376253541593

Epoch: 5| Step: 3
Training loss: 3.3962250622060868
Validation loss: 3.137432975103793

Epoch: 5| Step: 4
Training loss: 3.225045870669117
Validation loss: 3.1345543969471086

Epoch: 5| Step: 5
Training loss: 3.891405387346823
Validation loss: 3.131514257268738

Epoch: 5| Step: 6
Training loss: 3.717541666624709
Validation loss: 3.127677552407505

Epoch: 5| Step: 7
Training loss: 3.3031872529629935
Validation loss: 3.1247346002413052

Epoch: 5| Step: 8
Training loss: 2.872601047262463
Validation loss: 3.1214645350104235

Epoch: 5| Step: 9
Training loss: 3.4785394769500884
Validation loss: 3.119463224534703

Epoch: 5| Step: 10
Training loss: 3.038098650678559
Validation loss: 3.1157214382886433

Epoch: 5| Step: 11
Training loss: 3.2176529579588484
Validation loss: 3.1129006057779027

Epoch: 53| Step: 0
Training loss: 3.707007967812491
Validation loss: 3.1095196420327564

Epoch: 5| Step: 1
Training loss: 3.2310930638229785
Validation loss: 3.106694783604014

Epoch: 5| Step: 2
Training loss: 3.0596901595881674
Validation loss: 3.104388940563662

Epoch: 5| Step: 3
Training loss: 3.277779478586334
Validation loss: 3.1017639549547975

Epoch: 5| Step: 4
Training loss: 2.8536051919550354
Validation loss: 3.098787092505182

Epoch: 5| Step: 5
Training loss: 3.337343013657437
Validation loss: 3.0956265059976493

Epoch: 5| Step: 6
Training loss: 3.4362171900609697
Validation loss: 3.0920866980819444

Epoch: 5| Step: 7
Training loss: 2.8583030150411726
Validation loss: 3.0895180126615216

Epoch: 5| Step: 8
Training loss: 3.0897347953095715
Validation loss: 3.086894109995955

Epoch: 5| Step: 9
Training loss: 3.5335318695526903
Validation loss: 3.084269314971189

Epoch: 5| Step: 10
Training loss: 3.2371179126927503
Validation loss: 3.080745736746942

Epoch: 5| Step: 11
Training loss: 2.5400759508386854
Validation loss: 3.077853457096727

Epoch: 54| Step: 0
Training loss: 2.9237560398386804
Validation loss: 3.075595985073671

Epoch: 5| Step: 1
Training loss: 3.4345020052028907
Validation loss: 3.072888210401945

Epoch: 5| Step: 2
Training loss: 2.717742645604627
Validation loss: 3.0700581698441325

Epoch: 5| Step: 3
Training loss: 2.2094976366854424
Validation loss: 3.067146228182895

Epoch: 5| Step: 4
Training loss: 3.7519888372275543
Validation loss: 3.0651306544444736

Epoch: 5| Step: 5
Training loss: 3.4409996944339776
Validation loss: 3.0614769063574188

Epoch: 5| Step: 6
Training loss: 3.4231271064198805
Validation loss: 3.0586060726328403

Epoch: 5| Step: 7
Training loss: 3.521795935026786
Validation loss: 3.056130168570442

Epoch: 5| Step: 8
Training loss: 3.285841572114537
Validation loss: 3.0529566785785653

Epoch: 5| Step: 9
Training loss: 3.4411217770034646
Validation loss: 3.0500328906101983

Epoch: 5| Step: 10
Training loss: 2.860583107466322
Validation loss: 3.0474815221429203

Epoch: 5| Step: 11
Training loss: 2.6067546548001532
Validation loss: 3.0445204513628465

Epoch: 55| Step: 0
Training loss: 2.9773380740934154
Validation loss: 3.0416789424770454

Epoch: 5| Step: 1
Training loss: 3.1092607486763275
Validation loss: 3.0390135459585452

Epoch: 5| Step: 2
Training loss: 3.1438811015100634
Validation loss: 3.0360077359511837

Epoch: 5| Step: 3
Training loss: 2.8966682566062976
Validation loss: 3.033218950343724

Epoch: 5| Step: 4
Training loss: 3.454922583633232
Validation loss: 3.030251564687012

Epoch: 5| Step: 5
Training loss: 3.1490614204219396
Validation loss: 3.0281730188762266

Epoch: 5| Step: 6
Training loss: 3.1691264754649153
Validation loss: 3.0248212448878498

Epoch: 5| Step: 7
Training loss: 3.0367006670838146
Validation loss: 3.0223293820182806

Epoch: 5| Step: 8
Training loss: 2.9564738989274137
Validation loss: 3.0196839162800075

Epoch: 5| Step: 9
Training loss: 2.926298169664739
Validation loss: 3.0170151466201838

Epoch: 5| Step: 10
Training loss: 3.6794565699331763
Validation loss: 3.0141899074048326

Epoch: 5| Step: 11
Training loss: 4.31848790302285
Validation loss: 3.0112434866520577

Epoch: 56| Step: 0
Training loss: 2.7096813270728184
Validation loss: 3.0081499711334474

Epoch: 5| Step: 1
Training loss: 3.6847505826146634
Validation loss: 3.005796746222632

Epoch: 5| Step: 2
Training loss: 3.3020248327678914
Validation loss: 3.0026360427651055

Epoch: 5| Step: 3
Training loss: 3.2283479862802924
Validation loss: 3.0000903824595655

Epoch: 5| Step: 4
Training loss: 3.6080039586893426
Validation loss: 2.997544926510048

Epoch: 5| Step: 5
Training loss: 3.2534447533908883
Validation loss: 2.994607579198703

Epoch: 5| Step: 6
Training loss: 2.6133418282870324
Validation loss: 2.991703518868086

Epoch: 5| Step: 7
Training loss: 2.0534871007060436
Validation loss: 2.9893458645354074

Epoch: 5| Step: 8
Training loss: 3.1059952199669465
Validation loss: 2.98620065633683

Epoch: 5| Step: 9
Training loss: 3.4492560759411575
Validation loss: 2.983945559349773

Epoch: 5| Step: 10
Training loss: 3.26790426192012
Validation loss: 2.9814009902113616

Epoch: 5| Step: 11
Training loss: 2.3075932175807563
Validation loss: 2.9784967240531186

Epoch: 57| Step: 0
Training loss: 3.458194929057412
Validation loss: 2.9757560979291444

Epoch: 5| Step: 1
Training loss: 2.8966035619021495
Validation loss: 2.973452942100327

Epoch: 5| Step: 2
Training loss: 3.461620943602858
Validation loss: 2.972076098741092

Epoch: 5| Step: 3
Training loss: 2.7778101876805295
Validation loss: 2.970499610659639

Epoch: 5| Step: 4
Training loss: 2.838136099210036
Validation loss: 2.96763305064235

Epoch: 5| Step: 5
Training loss: 2.6468538033493525
Validation loss: 2.964826939819554

Epoch: 5| Step: 6
Training loss: 3.386872214389915
Validation loss: 2.961572919452035

Epoch: 5| Step: 7
Training loss: 3.202090808178813
Validation loss: 2.9592978367049074

Epoch: 5| Step: 8
Training loss: 2.9220248097248356
Validation loss: 2.9570192969217937

Epoch: 5| Step: 9
Training loss: 3.5150010296967955
Validation loss: 2.9544290156194903

Epoch: 5| Step: 10
Training loss: 3.0750329612888208
Validation loss: 2.9516408208145903

Epoch: 5| Step: 11
Training loss: 2.0702212907384934
Validation loss: 2.949686022660884

Epoch: 58| Step: 0
Training loss: 3.1301795759271176
Validation loss: 2.9477120666584513

Epoch: 5| Step: 1
Training loss: 3.3718786994411762
Validation loss: 2.9449885061133654

Epoch: 5| Step: 2
Training loss: 3.233098907099939
Validation loss: 2.943109901283102

Epoch: 5| Step: 3
Training loss: 2.4160588475696185
Validation loss: 2.9404787084639654

Epoch: 5| Step: 4
Training loss: 3.0904291999284674
Validation loss: 2.938001603391178

Epoch: 5| Step: 5
Training loss: 3.6895280853621077
Validation loss: 2.9358642501314827

Epoch: 5| Step: 6
Training loss: 2.9338820883389922
Validation loss: 2.933176182787283

Epoch: 5| Step: 7
Training loss: 3.0635128292701075
Validation loss: 2.9305482642568688

Epoch: 5| Step: 8
Training loss: 2.865383984196898
Validation loss: 2.9278204466060833

Epoch: 5| Step: 9
Training loss: 3.1624806158504564
Validation loss: 2.9258308762949556

Epoch: 5| Step: 10
Training loss: 2.801861627782106
Validation loss: 2.9239870961270267

Epoch: 5| Step: 11
Training loss: 2.7321243178649546
Validation loss: 2.9211899435388053

Epoch: 59| Step: 0
Training loss: 3.1811424132255786
Validation loss: 2.9189097373702926

Epoch: 5| Step: 1
Training loss: 3.184795653586355
Validation loss: 2.916908646945242

Epoch: 5| Step: 2
Training loss: 2.96308148950584
Validation loss: 2.914978905956443

Epoch: 5| Step: 3
Training loss: 2.755120279002356
Validation loss: 2.912508689201611

Epoch: 5| Step: 4
Training loss: 2.988907014239571
Validation loss: 2.910670848979805

Epoch: 5| Step: 5
Training loss: 2.7094089035148077
Validation loss: 2.908683462208407

Epoch: 5| Step: 6
Training loss: 2.8924173932491173
Validation loss: 2.9064928725836783

Epoch: 5| Step: 7
Training loss: 3.108311456870923
Validation loss: 2.904576212676765

Epoch: 5| Step: 8
Training loss: 3.3094377578389738
Validation loss: 2.902641031298226

Epoch: 5| Step: 9
Training loss: 3.18937328867088
Validation loss: 2.9001013374983913

Epoch: 5| Step: 10
Training loss: 3.312266935390585
Validation loss: 2.898324722604828

Epoch: 5| Step: 11
Training loss: 2.4395021871942815
Validation loss: 2.8961228745063443

Epoch: 60| Step: 0
Training loss: 2.890717705966949
Validation loss: 2.89389346805906

Epoch: 5| Step: 1
Training loss: 2.3937482191432773
Validation loss: 2.892693757041185

Epoch: 5| Step: 2
Training loss: 2.8653816544138864
Validation loss: 2.890689546706412

Epoch: 5| Step: 3
Training loss: 2.5912042096844896
Validation loss: 2.889060784589204

Epoch: 5| Step: 4
Training loss: 2.9604834860218863
Validation loss: 2.8875172379214495

Epoch: 5| Step: 5
Training loss: 3.735846066123837
Validation loss: 2.8920033751272816

Epoch: 5| Step: 6
Training loss: 3.28574245452653
Validation loss: 2.8865333879602475

Epoch: 5| Step: 7
Training loss: 3.3545045544258936
Validation loss: 2.8807146801144907

Epoch: 5| Step: 8
Training loss: 3.0074535601574808
Validation loss: 2.8787284737523526

Epoch: 5| Step: 9
Training loss: 2.93653399228025
Validation loss: 2.8783377884559926

Epoch: 5| Step: 10
Training loss: 3.023543008545426
Validation loss: 2.8784860022143057

Epoch: 5| Step: 11
Training loss: 3.163292308363142
Validation loss: 2.8781030846671585

Epoch: 61| Step: 0
Training loss: 3.2411398792207047
Validation loss: 2.881176971343048

Epoch: 5| Step: 1
Training loss: 3.1940034829194173
Validation loss: 2.8820993390773344

Epoch: 5| Step: 2
Training loss: 2.4378366482392817
Validation loss: 2.8719511797531303

Epoch: 5| Step: 3
Training loss: 3.07938541225549
Validation loss: 2.866986187096283

Epoch: 5| Step: 4
Training loss: 2.907001029157112
Validation loss: 2.8627528786881706

Epoch: 5| Step: 5
Training loss: 2.8270466471582565
Validation loss: 2.860123958368888

Epoch: 5| Step: 6
Training loss: 2.604545280908031
Validation loss: 2.858398086483535

Epoch: 5| Step: 7
Training loss: 2.722574985336722
Validation loss: 2.857756846452448

Epoch: 5| Step: 8
Training loss: 3.3678510326323714
Validation loss: 2.859957005204296

Epoch: 5| Step: 9
Training loss: 3.658397858788527
Validation loss: 2.854925581468235

Epoch: 5| Step: 10
Training loss: 2.9105291550091374
Validation loss: 2.8501100228918

Epoch: 5| Step: 11
Training loss: 2.5301377478331597
Validation loss: 2.8483217784694834

Epoch: 62| Step: 0
Training loss: 2.926306642996878
Validation loss: 2.8495126053727153

Epoch: 5| Step: 1
Training loss: 2.841042036240325
Validation loss: 2.856188132508496

Epoch: 5| Step: 2
Training loss: 3.108201922245903
Validation loss: 2.85352161292828

Epoch: 5| Step: 3
Training loss: 3.0886447282463902
Validation loss: 2.8464161388262226

Epoch: 5| Step: 4
Training loss: 2.949840677129322
Validation loss: 2.8402301257881715

Epoch: 5| Step: 5
Training loss: 2.4130844554641846
Validation loss: 2.8378516183803515

Epoch: 5| Step: 6
Training loss: 2.708120327911819
Validation loss: 2.835212115580678

Epoch: 5| Step: 7
Training loss: 3.258397623844156
Validation loss: 2.8330229187134957

Epoch: 5| Step: 8
Training loss: 3.3219347771678667
Validation loss: 2.832581659959712

Epoch: 5| Step: 9
Training loss: 3.021466226159537
Validation loss: 2.8442873220076974

Epoch: 5| Step: 10
Training loss: 2.89704701263763
Validation loss: 2.8396119412730085

Epoch: 5| Step: 11
Training loss: 3.86445832714385
Validation loss: 2.82526384699714

Epoch: 63| Step: 0
Training loss: 3.1291421522728653
Validation loss: 2.8243348593299347

Epoch: 5| Step: 1
Training loss: 3.3142403403356706
Validation loss: 2.8232233554208044

Epoch: 5| Step: 2
Training loss: 2.9116133555914487
Validation loss: 2.8234452542182855

Epoch: 5| Step: 3
Training loss: 3.1783234390827584
Validation loss: 2.8239470017413484

Epoch: 5| Step: 4
Training loss: 3.0782572916329154
Validation loss: 2.8237704830994415

Epoch: 5| Step: 5
Training loss: 2.5955044431404026
Validation loss: 2.824454931265032

Epoch: 5| Step: 6
Training loss: 2.901918197793413
Validation loss: 2.8190014187828516

Epoch: 5| Step: 7
Training loss: 3.0433739525826904
Validation loss: 2.8148186839146354

Epoch: 5| Step: 8
Training loss: 3.1156012531320605
Validation loss: 2.8134509880671663

Epoch: 5| Step: 9
Training loss: 2.8485462697365613
Validation loss: 2.809876214148351

Epoch: 5| Step: 10
Training loss: 2.2204373887633517
Validation loss: 2.8066321691192337

Epoch: 5| Step: 11
Training loss: 3.336301689905224
Validation loss: 2.8047466891674664

Epoch: 64| Step: 0
Training loss: 2.8545048831183637
Validation loss: 2.802513668572575

Epoch: 5| Step: 1
Training loss: 2.8384040635846453
Validation loss: 2.8000290914568295

Epoch: 5| Step: 2
Training loss: 2.900168670484657
Validation loss: 2.798278715626086

Epoch: 5| Step: 3
Training loss: 3.1993967083632113
Validation loss: 2.7970084899075203

Epoch: 5| Step: 4
Training loss: 2.7847460087505205
Validation loss: 2.793669168638517

Epoch: 5| Step: 5
Training loss: 3.045648102840019
Validation loss: 2.792518760870851

Epoch: 5| Step: 6
Training loss: 2.422033981519561
Validation loss: 2.790614226271681

Epoch: 5| Step: 7
Training loss: 2.2989241613197056
Validation loss: 2.7877230664738093

Epoch: 5| Step: 8
Training loss: 3.328432883765415
Validation loss: 2.7858964490192744

Epoch: 5| Step: 9
Training loss: 3.0490036009119477
Validation loss: 2.7845167662682657

Epoch: 5| Step: 10
Training loss: 3.2637855423241553
Validation loss: 2.7833960822069588

Epoch: 5| Step: 11
Training loss: 3.4225314133444544
Validation loss: 2.782252998802207

Epoch: 65| Step: 0
Training loss: 2.8200414638311706
Validation loss: 2.7795907528905515

Epoch: 5| Step: 1
Training loss: 3.2652554097543693
Validation loss: 2.7796623327478627

Epoch: 5| Step: 2
Training loss: 3.265147489105255
Validation loss: 2.778070307401736

Epoch: 5| Step: 3
Training loss: 3.079905812941259
Validation loss: 2.7761196974808855

Epoch: 5| Step: 4
Training loss: 2.935047993048254
Validation loss: 2.7751052068980413

Epoch: 5| Step: 5
Training loss: 2.2244515032258754
Validation loss: 2.7729993697992383

Epoch: 5| Step: 6
Training loss: 3.087026669440501
Validation loss: 2.771515935458708

Epoch: 5| Step: 7
Training loss: 2.650735314036112
Validation loss: 2.769546135708611

Epoch: 5| Step: 8
Training loss: 2.538367355262282
Validation loss: 2.7680708384460146

Epoch: 5| Step: 9
Training loss: 2.7738598998870976
Validation loss: 2.7662965566236983

Epoch: 5| Step: 10
Training loss: 2.957894807648716
Validation loss: 2.7637065871791724

Epoch: 5| Step: 11
Training loss: 4.074264628516856
Validation loss: 2.7614209861249215

Epoch: 66| Step: 0
Training loss: 3.33194166378322
Validation loss: 2.7588378217771212

Epoch: 5| Step: 1
Training loss: 3.092084648345543
Validation loss: 2.756883156642639

Epoch: 5| Step: 2
Training loss: 3.0792093448666593
Validation loss: 2.7559969061389826

Epoch: 5| Step: 3
Training loss: 3.062985751495946
Validation loss: 2.7536223569595224

Epoch: 5| Step: 4
Training loss: 2.3698691107423593
Validation loss: 2.7521966736638714

Epoch: 5| Step: 5
Training loss: 2.547702116730298
Validation loss: 2.750221283274875

Epoch: 5| Step: 6
Training loss: 2.9402673550445417
Validation loss: 2.750768232689461

Epoch: 5| Step: 7
Training loss: 2.822651661801298
Validation loss: 2.751962218169185

Epoch: 5| Step: 8
Training loss: 2.3066913750966056
Validation loss: 2.746961352568171

Epoch: 5| Step: 9
Training loss: 3.1940311017035983
Validation loss: 2.7463868456398073

Epoch: 5| Step: 10
Training loss: 2.7925361778490796
Validation loss: 2.746226394799587

Epoch: 5| Step: 11
Training loss: 3.23483730089803
Validation loss: 2.741731969921398

Epoch: 67| Step: 0
Training loss: 2.658006334272864
Validation loss: 2.7409175203426086

Epoch: 5| Step: 1
Training loss: 2.954394839522614
Validation loss: 2.7389616544923943

Epoch: 5| Step: 2
Training loss: 3.0669814038131125
Validation loss: 2.7372729684872548

Epoch: 5| Step: 3
Training loss: 2.997327727011645
Validation loss: 2.735625121131379

Epoch: 5| Step: 4
Training loss: 2.709050117910578
Validation loss: 2.733244086229363

Epoch: 5| Step: 5
Training loss: 2.9275820885281423
Validation loss: 2.731183589270488

Epoch: 5| Step: 6
Training loss: 3.3574173302034396
Validation loss: 2.7280610528932896

Epoch: 5| Step: 7
Training loss: 2.333224044238528
Validation loss: 2.729449746445113

Epoch: 5| Step: 8
Training loss: 2.676358036887772
Validation loss: 2.7238738203097648

Epoch: 5| Step: 9
Training loss: 2.730014397579696
Validation loss: 2.7258322647844455

Epoch: 5| Step: 10
Training loss: 3.0671404500219963
Validation loss: 2.726294747570863

Epoch: 5| Step: 11
Training loss: 3.018644570351776
Validation loss: 2.722706112434691

Epoch: 68| Step: 0
Training loss: 2.72582254506978
Validation loss: 2.72062467200437

Epoch: 5| Step: 1
Training loss: 2.7233194120962554
Validation loss: 2.7231715958351415

Epoch: 5| Step: 2
Training loss: 3.0813909718916346
Validation loss: 2.7242393579661703

Epoch: 5| Step: 3
Training loss: 3.0662868209226715
Validation loss: 2.7241774933410134

Epoch: 5| Step: 4
Training loss: 2.6503478955483835
Validation loss: 2.7239616471824157

Epoch: 5| Step: 5
Training loss: 3.4824402231534304
Validation loss: 2.7250407471074714

Epoch: 5| Step: 6
Training loss: 3.0868729730735747
Validation loss: 2.7238480355352777

Epoch: 5| Step: 7
Training loss: 2.356134576778326
Validation loss: 2.721556727462045

Epoch: 5| Step: 8
Training loss: 2.708312773015157
Validation loss: 2.720052319507336

Epoch: 5| Step: 9
Training loss: 2.6698607051960868
Validation loss: 2.7174245592376822

Epoch: 5| Step: 10
Training loss: 2.9139080262341093
Validation loss: 2.7179679476597993

Epoch: 5| Step: 11
Training loss: 1.7461299337781213
Validation loss: 2.715322617851376

Epoch: 69| Step: 0
Training loss: 2.887779691287089
Validation loss: 2.713489024310024

Epoch: 5| Step: 1
Training loss: 2.6443281222475266
Validation loss: 2.712188849643864

Epoch: 5| Step: 2
Training loss: 2.3728514539841217
Validation loss: 2.7085796329793146

Epoch: 5| Step: 3
Training loss: 2.8489550230761354
Validation loss: 2.705704033850856

Epoch: 5| Step: 4
Training loss: 2.857747266055119
Validation loss: 2.7055277720384057

Epoch: 5| Step: 5
Training loss: 2.8443056339262434
Validation loss: 2.703460139702074

Epoch: 5| Step: 6
Training loss: 2.690238976339629
Validation loss: 2.702044577946866

Epoch: 5| Step: 7
Training loss: 3.0959369366553755
Validation loss: 2.700640681570782

Epoch: 5| Step: 8
Training loss: 2.721934328188135
Validation loss: 2.7001841760443663

Epoch: 5| Step: 9
Training loss: 3.0891788505133504
Validation loss: 2.70018593094974

Epoch: 5| Step: 10
Training loss: 3.1618863381135203
Validation loss: 2.701366039698141

Epoch: 5| Step: 11
Training loss: 2.9349341041666985
Validation loss: 2.6980735384625683

Epoch: 70| Step: 0
Training loss: 2.344111300276917
Validation loss: 2.6979622646784134

Epoch: 5| Step: 1
Training loss: 2.8582885012062604
Validation loss: 2.696696802221596

Epoch: 5| Step: 2
Training loss: 3.0396276110395406
Validation loss: 2.6941244114461713

Epoch: 5| Step: 3
Training loss: 2.2249438375178467
Validation loss: 2.690677143585578

Epoch: 5| Step: 4
Training loss: 3.1154544764526144
Validation loss: 2.6893294709294047

Epoch: 5| Step: 5
Training loss: 2.691951170570582
Validation loss: 2.6887803687203276

Epoch: 5| Step: 6
Training loss: 3.4027263369315865
Validation loss: 2.687495623444535

Epoch: 5| Step: 7
Training loss: 2.8427945722333567
Validation loss: 2.685357422590723

Epoch: 5| Step: 8
Training loss: 2.8401683007997387
Validation loss: 2.6851948677329323

Epoch: 5| Step: 9
Training loss: 2.9298989181528534
Validation loss: 2.682823688866625

Epoch: 5| Step: 10
Training loss: 2.671794153964648
Validation loss: 2.6809189749941535

Epoch: 5| Step: 11
Training loss: 2.7594822483670254
Validation loss: 2.6816038873336563

Epoch: 71| Step: 0
Training loss: 2.9419236658956724
Validation loss: 2.6787350317779657

Epoch: 5| Step: 1
Training loss: 2.488793720070185
Validation loss: 2.6796489486664563

Epoch: 5| Step: 2
Training loss: 2.979181214054754
Validation loss: 2.679040929049736

Epoch: 5| Step: 3
Training loss: 2.8700847902964837
Validation loss: 2.6802635834078723

Epoch: 5| Step: 4
Training loss: 3.164438484364277
Validation loss: 2.67998334699173

Epoch: 5| Step: 5
Training loss: 2.6004700529240448
Validation loss: 2.6817474381006763

Epoch: 5| Step: 6
Training loss: 2.9254335978679586
Validation loss: 2.6833284738350534

Epoch: 5| Step: 7
Training loss: 2.442610933250347
Validation loss: 2.680570392095413

Epoch: 5| Step: 8
Training loss: 2.924944728752967
Validation loss: 2.681257838791279

Epoch: 5| Step: 9
Training loss: 3.0800967025438477
Validation loss: 2.676826762856513

Epoch: 5| Step: 10
Training loss: 2.510554445741123
Validation loss: 2.6726079831433918

Epoch: 5| Step: 11
Training loss: 2.693742643200239
Validation loss: 2.667164016080931

Epoch: 72| Step: 0
Training loss: 2.9488014178545354
Validation loss: 2.666839300965217

Epoch: 5| Step: 1
Training loss: 2.939292360896532
Validation loss: 2.663801920686282

Epoch: 5| Step: 2
Training loss: 3.0829133099924673
Validation loss: 2.664905172441826

Epoch: 5| Step: 3
Training loss: 2.7196245212006596
Validation loss: 2.661079313807852

Epoch: 5| Step: 4
Training loss: 2.891504927041112
Validation loss: 2.6602949982924087

Epoch: 5| Step: 5
Training loss: 2.7448543611396192
Validation loss: 2.659690913327907

Epoch: 5| Step: 6
Training loss: 2.497515588354697
Validation loss: 2.65748832859169

Epoch: 5| Step: 7
Training loss: 2.7742813760729983
Validation loss: 2.6557696637446657

Epoch: 5| Step: 8
Training loss: 2.6996685707690657
Validation loss: 2.6552517006047376

Epoch: 5| Step: 9
Training loss: 2.3939655376238838
Validation loss: 2.6531362796179727

Epoch: 5| Step: 10
Training loss: 2.7608435726542018
Validation loss: 2.652733210050031

Epoch: 5| Step: 11
Training loss: 3.904467488807505
Validation loss: 2.651603861456021

Epoch: 73| Step: 0
Training loss: 2.9832622590647078
Validation loss: 2.652210754745652

Epoch: 5| Step: 1
Training loss: 2.879266972503626
Validation loss: 2.6503888408717664

Epoch: 5| Step: 2
Training loss: 2.5386678066124215
Validation loss: 2.650858504907258

Epoch: 5| Step: 3
Training loss: 3.419098864509198
Validation loss: 2.6511440756952354

Epoch: 5| Step: 4
Training loss: 3.2003021455218623
Validation loss: 2.646099600322283

Epoch: 5| Step: 5
Training loss: 2.399335065759258
Validation loss: 2.648257606720855

Epoch: 5| Step: 6
Training loss: 2.5866574671014746
Validation loss: 2.6510619192093023

Epoch: 5| Step: 7
Training loss: 2.2607092836428406
Validation loss: 2.6506739300762487

Epoch: 5| Step: 8
Training loss: 2.722279504791797
Validation loss: 2.650306477308393

Epoch: 5| Step: 9
Training loss: 2.9969406423052454
Validation loss: 2.6505800880849377

Epoch: 5| Step: 10
Training loss: 2.49710048378331
Validation loss: 2.650660602984394

Epoch: 5| Step: 11
Training loss: 2.6919478050148586
Validation loss: 2.6463274244100834

Epoch: 74| Step: 0
Training loss: 3.0052687155719386
Validation loss: 2.6449125194445133

Epoch: 5| Step: 1
Training loss: 3.065172858536686
Validation loss: 2.644940700040533

Epoch: 5| Step: 2
Training loss: 2.8104606864390633
Validation loss: 2.64105408096094

Epoch: 5| Step: 3
Training loss: 2.420184523743445
Validation loss: 2.6407173298601854

Epoch: 5| Step: 4
Training loss: 2.9086880865585596
Validation loss: 2.637864688471059

Epoch: 5| Step: 5
Training loss: 2.624889008128282
Validation loss: 2.6342104814049945

Epoch: 5| Step: 6
Training loss: 2.780726437097841
Validation loss: 2.6350774634675407

Epoch: 5| Step: 7
Training loss: 3.0543979205072995
Validation loss: 2.6342738894256392

Epoch: 5| Step: 8
Training loss: 2.8114633133061955
Validation loss: 2.634658215564795

Epoch: 5| Step: 9
Training loss: 2.5009166944220604
Validation loss: 2.6339327789839544

Epoch: 5| Step: 10
Training loss: 2.522291933217587
Validation loss: 2.632004445000734

Epoch: 5| Step: 11
Training loss: 2.423528881797319
Validation loss: 2.633116533815271

Epoch: 75| Step: 0
Training loss: 3.0848014188933375
Validation loss: 2.632689774064884

Epoch: 5| Step: 1
Training loss: 2.5947775586292305
Validation loss: 2.635304340537041

Epoch: 5| Step: 2
Training loss: 1.8114598018851606
Validation loss: 2.640148191272475

Epoch: 5| Step: 3
Training loss: 3.3380160500681684
Validation loss: 2.653425289244712

Epoch: 5| Step: 4
Training loss: 2.6900964658663273
Validation loss: 2.6393898891288265

Epoch: 5| Step: 5
Training loss: 2.5888895661931204
Validation loss: 2.6281203502382566

Epoch: 5| Step: 6
Training loss: 2.729992739070417
Validation loss: 2.623682247648314

Epoch: 5| Step: 7
Training loss: 2.7852244749982273
Validation loss: 2.624996855143525

Epoch: 5| Step: 8
Training loss: 3.0116669765430735
Validation loss: 2.6302244368459915

Epoch: 5| Step: 9
Training loss: 2.6416340542133
Validation loss: 2.6309434612517917

Epoch: 5| Step: 10
Training loss: 2.89754371537679
Validation loss: 2.6323796641881803

Epoch: 5| Step: 11
Training loss: 2.695730602620202
Validation loss: 2.6354191306382875

Epoch: 76| Step: 0
Training loss: 2.5477669681002375
Validation loss: 2.638652501198673

Epoch: 5| Step: 1
Training loss: 2.813156644672422
Validation loss: 2.6415473937135143

Epoch: 5| Step: 2
Training loss: 2.389124580210422
Validation loss: 2.6367821052380767

Epoch: 5| Step: 3
Training loss: 3.2745052225977322
Validation loss: 2.6312499913920133

Epoch: 5| Step: 4
Training loss: 2.7712304158222074
Validation loss: 2.6277814351005544

Epoch: 5| Step: 5
Training loss: 2.5655021758887178
Validation loss: 2.622906508563679

Epoch: 5| Step: 6
Training loss: 3.0345005814782273
Validation loss: 2.621580659502788

Epoch: 5| Step: 7
Training loss: 2.841482914626405
Validation loss: 2.6206048053655087

Epoch: 5| Step: 8
Training loss: 2.3728706451409813
Validation loss: 2.6166844088465155

Epoch: 5| Step: 9
Training loss: 2.1776620074508966
Validation loss: 2.6122977511590153

Epoch: 5| Step: 10
Training loss: 3.1783887005447413
Validation loss: 2.6145338279221875

Epoch: 5| Step: 11
Training loss: 3.6418415705552616
Validation loss: 2.6147021701043

Epoch: 77| Step: 0
Training loss: 3.204448593958218
Validation loss: 2.6188206374080503

Epoch: 5| Step: 1
Training loss: 2.9923932276187784
Validation loss: 2.609954491720357

Epoch: 5| Step: 2
Training loss: 2.7378690357638784
Validation loss: 2.6079097905647095

Epoch: 5| Step: 3
Training loss: 2.9560606559136144
Validation loss: 2.6081023548665785

Epoch: 5| Step: 4
Training loss: 2.329561443231697
Validation loss: 2.60788016226735

Epoch: 5| Step: 5
Training loss: 2.14413454037896
Validation loss: 2.605680732548867

Epoch: 5| Step: 6
Training loss: 2.6539128512035672
Validation loss: 2.611016022075778

Epoch: 5| Step: 7
Training loss: 2.9422176705959386
Validation loss: 2.614784452725095

Epoch: 5| Step: 8
Training loss: 2.802662237747618
Validation loss: 2.608608018916641

Epoch: 5| Step: 9
Training loss: 2.358399246247273
Validation loss: 2.6077645104078035

Epoch: 5| Step: 10
Training loss: 3.1120855890482853
Validation loss: 2.6054866738682287

Epoch: 5| Step: 11
Training loss: 1.666848657526465
Validation loss: 2.6072164695118216

Epoch: 78| Step: 0
Training loss: 2.651417094229888
Validation loss: 2.613147555411072

Epoch: 5| Step: 1
Training loss: 2.89077989317902
Validation loss: 2.6185646874677944

Epoch: 5| Step: 2
Training loss: 2.4192115165958574
Validation loss: 2.623659616700364

Epoch: 5| Step: 3
Training loss: 3.0025606353506866
Validation loss: 2.6262606590886257

Epoch: 5| Step: 4
Training loss: 2.7028417714527815
Validation loss: 2.6210025178331287

Epoch: 5| Step: 5
Training loss: 2.463938793301536
Validation loss: 2.6159773424831676

Epoch: 5| Step: 6
Training loss: 2.8729682045440894
Validation loss: 2.6143587492175477

Epoch: 5| Step: 7
Training loss: 2.6629817258212842
Validation loss: 2.6093000945648908

Epoch: 5| Step: 8
Training loss: 2.726580163412073
Validation loss: 2.60663184914259

Epoch: 5| Step: 9
Training loss: 2.6725385410823463
Validation loss: 2.602373132431973

Epoch: 5| Step: 10
Training loss: 3.20089197244307
Validation loss: 2.5997609496261593

Epoch: 5| Step: 11
Training loss: 2.1506042651524124
Validation loss: 2.596987308808052

Epoch: 79| Step: 0
Training loss: 2.8736258830330033
Validation loss: 2.597547068966444

Epoch: 5| Step: 1
Training loss: 2.3642408708345912
Validation loss: 2.5943056970528393

Epoch: 5| Step: 2
Training loss: 3.0374337271536618
Validation loss: 2.6004138125103586

Epoch: 5| Step: 3
Training loss: 3.026659921506964
Validation loss: 2.6019954951120505

Epoch: 5| Step: 4
Training loss: 2.687941404067287
Validation loss: 2.5994112706908052

Epoch: 5| Step: 5
Training loss: 2.5805780011713257
Validation loss: 2.5957460880670733

Epoch: 5| Step: 6
Training loss: 2.347116925688621
Validation loss: 2.589604496632829

Epoch: 5| Step: 7
Training loss: 2.8707328310031763
Validation loss: 2.589455856956337

Epoch: 5| Step: 8
Training loss: 2.4908697297632076
Validation loss: 2.587735637126309

Epoch: 5| Step: 9
Training loss: 2.889457343081533
Validation loss: 2.5870518698683393

Epoch: 5| Step: 10
Training loss: 3.0214652792605206
Validation loss: 2.5869191775590004

Epoch: 5| Step: 11
Training loss: 1.0473769962862218
Validation loss: 2.585232687610058

Epoch: 80| Step: 0
Training loss: 2.160900132745035
Validation loss: 2.5850576015913065

Epoch: 5| Step: 1
Training loss: 2.87078814274876
Validation loss: 2.587048532963868

Epoch: 5| Step: 2
Training loss: 2.5800973456891936
Validation loss: 2.5876693765363257

Epoch: 5| Step: 3
Training loss: 2.6376346607995806
Validation loss: 2.5855908886665935

Epoch: 5| Step: 4
Training loss: 2.917422732496175
Validation loss: 2.5889320092016495

Epoch: 5| Step: 5
Training loss: 2.5085757036014407
Validation loss: 2.5877004685505187

Epoch: 5| Step: 6
Training loss: 2.6611213445853816
Validation loss: 2.5870154708814552

Epoch: 5| Step: 7
Training loss: 2.816823391438428
Validation loss: 2.5870424581739067

Epoch: 5| Step: 8
Training loss: 3.026147697197529
Validation loss: 2.5878061532683363

Epoch: 5| Step: 9
Training loss: 2.83738650460484
Validation loss: 2.587397571354631

Epoch: 5| Step: 10
Training loss: 2.768114941101333
Validation loss: 2.5844016878286875

Epoch: 5| Step: 11
Training loss: 3.1083567116465862
Validation loss: 2.583093118010129

Epoch: 81| Step: 0
Training loss: 2.7625814814223677
Validation loss: 2.580109970739457

Epoch: 5| Step: 1
Training loss: 2.6036506039771026
Validation loss: 2.578828384316348

Epoch: 5| Step: 2
Training loss: 2.4769100101835275
Validation loss: 2.5753449912579667

Epoch: 5| Step: 3
Training loss: 3.0271993098102934
Validation loss: 2.5866665729562834

Epoch: 5| Step: 4
Training loss: 3.1263132006431515
Validation loss: 2.5967883426485496

Epoch: 5| Step: 5
Training loss: 2.517444686963868
Validation loss: 2.581068527948569

Epoch: 5| Step: 6
Training loss: 2.2256943465808274
Validation loss: 2.572414454714369

Epoch: 5| Step: 7
Training loss: 2.9144198528374874
Validation loss: 2.577399026401889

Epoch: 5| Step: 8
Training loss: 2.728853940639862
Validation loss: 2.573719012812043

Epoch: 5| Step: 9
Training loss: 3.0632376269090082
Validation loss: 2.5764435457862387

Epoch: 5| Step: 10
Training loss: 2.1855578929360906
Validation loss: 2.5728155661937318

Epoch: 5| Step: 11
Training loss: 2.8549056013170806
Validation loss: 2.574198671145898

Epoch: 82| Step: 0
Training loss: 2.644324425592602
Validation loss: 2.576443561209216

Epoch: 5| Step: 1
Training loss: 2.5933718118370828
Validation loss: 2.576529887949001

Epoch: 5| Step: 2
Training loss: 2.9079255227123837
Validation loss: 2.572723699327091

Epoch: 5| Step: 3
Training loss: 2.5477775425538143
Validation loss: 2.573608928221328

Epoch: 5| Step: 4
Training loss: 2.418954577407065
Validation loss: 2.5746181951869587

Epoch: 5| Step: 5
Training loss: 3.0089438948619094
Validation loss: 2.574126450809128

Epoch: 5| Step: 6
Training loss: 2.1349967977959876
Validation loss: 2.5723297373767253

Epoch: 5| Step: 7
Training loss: 2.7959264073653354
Validation loss: 2.5726272108731036

Epoch: 5| Step: 8
Training loss: 2.883235414492424
Validation loss: 2.5707596387043465

Epoch: 5| Step: 9
Training loss: 3.0462653699509827
Validation loss: 2.5716682653819776

Epoch: 5| Step: 10
Training loss: 2.4604169991471734
Validation loss: 2.566064468300652

Epoch: 5| Step: 11
Training loss: 3.51347224128021
Validation loss: 2.5695088607571965

Epoch: 83| Step: 0
Training loss: 2.763693010768341
Validation loss: 2.5670110414721035

Epoch: 5| Step: 1
Training loss: 2.6137762356448904
Validation loss: 2.5665464861299125

Epoch: 5| Step: 2
Training loss: 2.9507136112184265
Validation loss: 2.5670197990685755

Epoch: 5| Step: 3
Training loss: 2.9952644483585393
Validation loss: 2.5673922188771416

Epoch: 5| Step: 4
Training loss: 2.7996043947584592
Validation loss: 2.568381247771793

Epoch: 5| Step: 5
Training loss: 2.553898960872131
Validation loss: 2.5676888058263563

Epoch: 5| Step: 6
Training loss: 2.6945502488729307
Validation loss: 2.566246890961005

Epoch: 5| Step: 7
Training loss: 2.173008794346308
Validation loss: 2.5667512295053303

Epoch: 5| Step: 8
Training loss: 2.5500145032881636
Validation loss: 2.566417417303569

Epoch: 5| Step: 9
Training loss: 2.9267840430401977
Validation loss: 2.567070513594565

Epoch: 5| Step: 10
Training loss: 2.3642367362430567
Validation loss: 2.5635838116205765

Epoch: 5| Step: 11
Training loss: 3.475429393118602
Validation loss: 2.56695179243187

Epoch: 84| Step: 0
Training loss: 2.7052417030866467
Validation loss: 2.5631473196614847

Epoch: 5| Step: 1
Training loss: 2.391534171161578
Validation loss: 2.560682753374928

Epoch: 5| Step: 2
Training loss: 2.5791285555668093
Validation loss: 2.559408086423914

Epoch: 5| Step: 3
Training loss: 2.6298311372220717
Validation loss: 2.560131618368459

Epoch: 5| Step: 4
Training loss: 2.4588879967088553
Validation loss: 2.558459923425661

Epoch: 5| Step: 5
Training loss: 3.046215748991574
Validation loss: 2.5586804246660133

Epoch: 5| Step: 6
Training loss: 2.699152502635394
Validation loss: 2.5555011375191845

Epoch: 5| Step: 7
Training loss: 2.68944762872759
Validation loss: 2.554919171109233

Epoch: 5| Step: 8
Training loss: 2.8463173480268695
Validation loss: 2.5587638623710487

Epoch: 5| Step: 9
Training loss: 2.670323507019536
Validation loss: 2.5552644224007115

Epoch: 5| Step: 10
Training loss: 2.8688253355419127
Validation loss: 2.5568669400880317

Epoch: 5| Step: 11
Training loss: 2.2968549662644064
Validation loss: 2.555183607454304

Epoch: 85| Step: 0
Training loss: 2.555284996038646
Validation loss: 2.553652204588203

Epoch: 5| Step: 1
Training loss: 3.014910519412388
Validation loss: 2.5514866630962643

Epoch: 5| Step: 2
Training loss: 2.710663619484278
Validation loss: 2.553197793844992

Epoch: 5| Step: 3
Training loss: 2.852608768351931
Validation loss: 2.5508297793419583

Epoch: 5| Step: 4
Training loss: 2.407093544277434
Validation loss: 2.5537414471157387

Epoch: 5| Step: 5
Training loss: 2.7667484910960334
Validation loss: 2.552537131673032

Epoch: 5| Step: 6
Training loss: 2.784599002343303
Validation loss: 2.5514934143443893

Epoch: 5| Step: 7
Training loss: 2.7612882761549473
Validation loss: 2.5531811604107

Epoch: 5| Step: 8
Training loss: 2.9086618567645623
Validation loss: 2.5488945105860767

Epoch: 5| Step: 9
Training loss: 2.5579662689239826
Validation loss: 2.5457545118934077

Epoch: 5| Step: 10
Training loss: 2.109256317190703
Validation loss: 2.5488633856155265

Epoch: 5| Step: 11
Training loss: 2.613280520132559
Validation loss: 2.5482873140695217

Epoch: 86| Step: 0
Training loss: 2.26617414462209
Validation loss: 2.540907497583089

Epoch: 5| Step: 1
Training loss: 2.6801908593041213
Validation loss: 2.5479517027930156

Epoch: 5| Step: 2
Training loss: 3.5082443413279343
Validation loss: 2.553004851018

Epoch: 5| Step: 3
Training loss: 2.605914533875071
Validation loss: 2.540661974141684

Epoch: 5| Step: 4
Training loss: 3.162109073405637
Validation loss: 2.5459895905980856

Epoch: 5| Step: 5
Training loss: 2.076233311172098
Validation loss: 2.542912941128371

Epoch: 5| Step: 6
Training loss: 2.5623970941489587
Validation loss: 2.5416369097692693

Epoch: 5| Step: 7
Training loss: 2.4280936849138475
Validation loss: 2.5434982951647025

Epoch: 5| Step: 8
Training loss: 2.7242160964484676
Validation loss: 2.5409161164339444

Epoch: 5| Step: 9
Training loss: 2.944653991424362
Validation loss: 2.5425730337307937

Epoch: 5| Step: 10
Training loss: 2.2349021663204143
Validation loss: 2.541684163663913

Epoch: 5| Step: 11
Training loss: 2.2412596587160727
Validation loss: 2.540696167271687

Epoch: 87| Step: 0
Training loss: 2.3527003985514683
Validation loss: 2.541528265473241

Epoch: 5| Step: 1
Training loss: 2.6984879957818797
Validation loss: 2.5427279067754465

Epoch: 5| Step: 2
Training loss: 2.8095034424610845
Validation loss: 2.538316713012799

Epoch: 5| Step: 3
Training loss: 2.628975446450722
Validation loss: 2.5400489690583297

Epoch: 5| Step: 4
Training loss: 2.9376357026916247
Validation loss: 2.540535363668501

Epoch: 5| Step: 5
Training loss: 2.6038426210335914
Validation loss: 2.5373005157507666

Epoch: 5| Step: 6
Training loss: 2.7450985142830295
Validation loss: 2.539846954453198

Epoch: 5| Step: 7
Training loss: 2.6287391008630916
Validation loss: 2.5372696674897823

Epoch: 5| Step: 8
Training loss: 2.8816494546894345
Validation loss: 2.537127891435761

Epoch: 5| Step: 9
Training loss: 2.4191691387854637
Validation loss: 2.533031056799681

Epoch: 5| Step: 10
Training loss: 2.47072194209114
Validation loss: 2.5353683437819305

Epoch: 5| Step: 11
Training loss: 3.0054107192376542
Validation loss: 2.5368455529914136

Epoch: 88| Step: 0
Training loss: 2.8244834765279982
Validation loss: 2.53329915825689

Epoch: 5| Step: 1
Training loss: 3.0362565686220404
Validation loss: 2.5394099227703393

Epoch: 5| Step: 2
Training loss: 1.97691661693222
Validation loss: 2.5382912447454635

Epoch: 5| Step: 3
Training loss: 2.4442512720055367
Validation loss: 2.534875914009

Epoch: 5| Step: 4
Training loss: 2.4880338393114916
Validation loss: 2.532282002748487

Epoch: 5| Step: 5
Training loss: 3.186357630052571
Validation loss: 2.5329438809476916

Epoch: 5| Step: 6
Training loss: 2.4318241647599743
Validation loss: 2.5331793602363253

Epoch: 5| Step: 7
Training loss: 2.622292166475708
Validation loss: 2.532557793278211

Epoch: 5| Step: 8
Training loss: 2.424090448857456
Validation loss: 2.5328941225380106

Epoch: 5| Step: 9
Training loss: 2.4517902217446887
Validation loss: 2.5322101247744095

Epoch: 5| Step: 10
Training loss: 2.9925444467250606
Validation loss: 2.5302432259773404

Epoch: 5| Step: 11
Training loss: 3.473709821986886
Validation loss: 2.528904640685127

Epoch: 89| Step: 0
Training loss: 2.3671018880841985
Validation loss: 2.531700047173929

Epoch: 5| Step: 1
Training loss: 3.239444905519839
Validation loss: 2.5306439282453774

Epoch: 5| Step: 2
Training loss: 2.402291348513858
Validation loss: 2.5370638409865696

Epoch: 5| Step: 3
Training loss: 2.650665336433297
Validation loss: 2.534645707065679

Epoch: 5| Step: 4
Training loss: 2.906229983024984
Validation loss: 2.536077295830911

Epoch: 5| Step: 5
Training loss: 2.6843839811767687
Validation loss: 2.5376853259769505

Epoch: 5| Step: 6
Training loss: 2.9092309901799878
Validation loss: 2.5346675101926297

Epoch: 5| Step: 7
Training loss: 2.5762062099386975
Validation loss: 2.5343444221868947

Epoch: 5| Step: 8
Training loss: 2.477178743630154
Validation loss: 2.5318339423877267

Epoch: 5| Step: 9
Training loss: 2.3567227241003588
Validation loss: 2.532192498235545

Epoch: 5| Step: 10
Training loss: 2.586791943223427
Validation loss: 2.532537348817981

Epoch: 5| Step: 11
Training loss: 2.6972191300414257
Validation loss: 2.5285181994822614

Epoch: 90| Step: 0
Training loss: 2.574620031821794
Validation loss: 2.530857825019944

Epoch: 5| Step: 1
Training loss: 2.457024845666832
Validation loss: 2.5268270641456545

Epoch: 5| Step: 2
Training loss: 2.898610893882748
Validation loss: 2.526402533536693

Epoch: 5| Step: 3
Training loss: 2.8239886136028063
Validation loss: 2.5260315662195207

Epoch: 5| Step: 4
Training loss: 2.787803729150096
Validation loss: 2.5242965070750922

Epoch: 5| Step: 5
Training loss: 2.6670353654448316
Validation loss: 2.5240631036638446

Epoch: 5| Step: 6
Training loss: 2.8534720102223816
Validation loss: 2.5231814495679754

Epoch: 5| Step: 7
Training loss: 2.6029311237286876
Validation loss: 2.52787610067734

Epoch: 5| Step: 8
Training loss: 2.545278598847669
Validation loss: 2.5231802133071

Epoch: 5| Step: 9
Training loss: 2.6019285019031773
Validation loss: 2.5216042086066

Epoch: 5| Step: 10
Training loss: 2.3546832595311127
Validation loss: 2.523683667847137

Epoch: 5| Step: 11
Training loss: 2.3820431327085547
Validation loss: 2.5186760409581903

Epoch: 91| Step: 0
Training loss: 2.9699569657929574
Validation loss: 2.519230665468052

Epoch: 5| Step: 1
Training loss: 2.659667027506374
Validation loss: 2.5190311852342395

Epoch: 5| Step: 2
Training loss: 2.5082187977069323
Validation loss: 2.521209650613581

Epoch: 5| Step: 3
Training loss: 2.661389662919868
Validation loss: 2.5282659327107058

Epoch: 5| Step: 4
Training loss: 2.8016866712822344
Validation loss: 2.520634668314179

Epoch: 5| Step: 5
Training loss: 2.812383861263121
Validation loss: 2.518588301182989

Epoch: 5| Step: 6
Training loss: 2.411297841563999
Validation loss: 2.5221141065262804

Epoch: 5| Step: 7
Training loss: 2.884462458151493
Validation loss: 2.5214252932851537

Epoch: 5| Step: 8
Training loss: 2.579914281293474
Validation loss: 2.524775859748553

Epoch: 5| Step: 9
Training loss: 2.6419405397110385
Validation loss: 2.525498929003817

Epoch: 5| Step: 10
Training loss: 2.3102348162050235
Validation loss: 2.5273465839981313

Epoch: 5| Step: 11
Training loss: 1.714210758387055
Validation loss: 2.5267412036362566

Epoch: 92| Step: 0
Training loss: 2.310642527440781
Validation loss: 2.5276301682054054

Epoch: 5| Step: 1
Training loss: 2.2799130009901125
Validation loss: 2.5279576746419403

Epoch: 5| Step: 2
Training loss: 2.5481747546191027
Validation loss: 2.5274560187047705

Epoch: 5| Step: 3
Training loss: 3.247369875749345
Validation loss: 2.5286779522779326

Epoch: 5| Step: 4
Training loss: 2.86520591674901
Validation loss: 2.526378496398112

Epoch: 5| Step: 5
Training loss: 2.3801754226468312
Validation loss: 2.5295236925225906

Epoch: 5| Step: 6
Training loss: 2.4049798164393126
Validation loss: 2.5270514105415587

Epoch: 5| Step: 7
Training loss: 3.1077052861703147
Validation loss: 2.5269957179463596

Epoch: 5| Step: 8
Training loss: 2.6015143862562424
Validation loss: 2.5205201881890176

Epoch: 5| Step: 9
Training loss: 2.7658619752209077
Validation loss: 2.522772883553028

Epoch: 5| Step: 10
Training loss: 2.4103990923989023
Validation loss: 2.5187906680046264

Epoch: 5| Step: 11
Training loss: 2.94537725807456
Validation loss: 2.5190653604329443

Epoch: 93| Step: 0
Training loss: 2.5643805139841684
Validation loss: 2.51313085101083

Epoch: 5| Step: 1
Training loss: 2.303017635249779
Validation loss: 2.5124783037365472

Epoch: 5| Step: 2
Training loss: 2.424483537243196
Validation loss: 2.514978495544454

Epoch: 5| Step: 3
Training loss: 3.0560318508186026
Validation loss: 2.5171212155853437

Epoch: 5| Step: 4
Training loss: 2.1704059270382023
Validation loss: 2.5133352027029408

Epoch: 5| Step: 5
Training loss: 2.826284410283236
Validation loss: 2.5141960532161405

Epoch: 5| Step: 6
Training loss: 2.7961061582372593
Validation loss: 2.516471112360924

Epoch: 5| Step: 7
Training loss: 3.12733707775097
Validation loss: 2.514897892995139

Epoch: 5| Step: 8
Training loss: 2.451810545374364
Validation loss: 2.5168061731421236

Epoch: 5| Step: 9
Training loss: 2.512920750550515
Validation loss: 2.5142524165432407

Epoch: 5| Step: 10
Training loss: 2.718386132456281
Validation loss: 2.5091430841927918

Epoch: 5| Step: 11
Training loss: 2.2642521349018785
Validation loss: 2.509105693575056

Epoch: 94| Step: 0
Training loss: 2.435734623063789
Validation loss: 2.504346236573169

Epoch: 5| Step: 1
Training loss: 2.4823899886081544
Validation loss: 2.5049734197121345

Epoch: 5| Step: 2
Training loss: 2.4712812749941513
Validation loss: 2.506962371637617

Epoch: 5| Step: 3
Training loss: 2.582347394601712
Validation loss: 2.5102043945875114

Epoch: 5| Step: 4
Training loss: 2.589487549004431
Validation loss: 2.508846703512252

Epoch: 5| Step: 5
Training loss: 2.111709997770778
Validation loss: 2.5064402199695945

Epoch: 5| Step: 6
Training loss: 2.717656935272455
Validation loss: 2.509187826299455

Epoch: 5| Step: 7
Training loss: 3.110709972481837
Validation loss: 2.512100811619795

Epoch: 5| Step: 8
Training loss: 2.6114863459744875
Validation loss: 2.5055972740483408

Epoch: 5| Step: 9
Training loss: 2.9688409088671435
Validation loss: 2.502543633582685

Epoch: 5| Step: 10
Training loss: 2.7487621989549784
Validation loss: 2.5090365527216867

Epoch: 5| Step: 11
Training loss: 2.7135936026749685
Validation loss: 2.5126610388001573

Epoch: 95| Step: 0
Training loss: 2.6675163544544085
Validation loss: 2.513277878075716

Epoch: 5| Step: 1
Training loss: 2.6471562620068685
Validation loss: 2.5130871120007505

Epoch: 5| Step: 2
Training loss: 3.0490156430061797
Validation loss: 2.515508068518379

Epoch: 5| Step: 3
Training loss: 2.340897821027221
Validation loss: 2.5200662680647152

Epoch: 5| Step: 4
Training loss: 2.47647874371629
Validation loss: 2.5178021000131294

Epoch: 5| Step: 5
Training loss: 2.5064258960824057
Validation loss: 2.511930928382403

Epoch: 5| Step: 6
Training loss: 2.883171576076798
Validation loss: 2.5162077519015336

Epoch: 5| Step: 7
Training loss: 2.4914084624995074
Validation loss: 2.5123758321733787

Epoch: 5| Step: 8
Training loss: 3.1795882225940497
Validation loss: 2.516232048067908

Epoch: 5| Step: 9
Training loss: 2.3164245707670306
Validation loss: 2.514018653596337

Epoch: 5| Step: 10
Training loss: 2.255602959926589
Validation loss: 2.510344386873927

Epoch: 5| Step: 11
Training loss: 2.9087321848665972
Validation loss: 2.50709700553158

Epoch: 96| Step: 0
Training loss: 2.480488454184779
Validation loss: 2.5075676740095063

Epoch: 5| Step: 1
Training loss: 2.9418868727208407
Validation loss: 2.5012781392582593

Epoch: 5| Step: 2
Training loss: 2.4833368015478436
Validation loss: 2.5038476422334863

Epoch: 5| Step: 3
Training loss: 2.416462220938322
Validation loss: 2.5064395778933934

Epoch: 5| Step: 4
Training loss: 2.1950514017051925
Validation loss: 2.5016829786291965

Epoch: 5| Step: 5
Training loss: 2.723124000071092
Validation loss: 2.509329779515586

Epoch: 5| Step: 6
Training loss: 2.9675118524689093
Validation loss: 2.4936692228755013

Epoch: 5| Step: 7
Training loss: 2.2802654911531777
Validation loss: 2.5046558259931273

Epoch: 5| Step: 8
Training loss: 3.186060711403737
Validation loss: 2.499950328969245

Epoch: 5| Step: 9
Training loss: 2.550473158078345
Validation loss: 2.503956013153759

Epoch: 5| Step: 10
Training loss: 2.5947303298159046
Validation loss: 2.5035592888658975

Epoch: 5| Step: 11
Training loss: 1.3477469151170933
Validation loss: 2.5007296649729347

Epoch: 97| Step: 0
Training loss: 2.2831358756937536
Validation loss: 2.500599284663939

Epoch: 5| Step: 1
Training loss: 2.699594915873185
Validation loss: 2.5005383349007912

Epoch: 5| Step: 2
Training loss: 2.673612509282615
Validation loss: 2.5029232299419744

Epoch: 5| Step: 3
Training loss: 2.5444899548935536
Validation loss: 2.499345097593065

Epoch: 5| Step: 4
Training loss: 2.797444802320072
Validation loss: 2.495932174332417

Epoch: 5| Step: 5
Training loss: 2.616841489779118
Validation loss: 2.5000319876213877

Epoch: 5| Step: 6
Training loss: 2.7636264972533464
Validation loss: 2.5004384768928585

Epoch: 5| Step: 7
Training loss: 2.4727613477985506
Validation loss: 2.495700405213108

Epoch: 5| Step: 8
Training loss: 2.352860102238458
Validation loss: 2.495562955150502

Epoch: 5| Step: 9
Training loss: 2.6527257540285665
Validation loss: 2.5001886614503004

Epoch: 5| Step: 10
Training loss: 2.646404104669425
Validation loss: 2.4978302440906317

Epoch: 5| Step: 11
Training loss: 3.4728649578733983
Validation loss: 2.499208964926606

Epoch: 98| Step: 0
Training loss: 2.6882186638470764
Validation loss: 2.4988476759874403

Epoch: 5| Step: 1
Training loss: 2.991231501673925
Validation loss: 2.500058483393392

Epoch: 5| Step: 2
Training loss: 2.08298286033168
Validation loss: 2.497657433347369

Epoch: 5| Step: 3
Training loss: 3.1825987589122025
Validation loss: 2.497532063502074

Epoch: 5| Step: 4
Training loss: 2.3365924644206997
Validation loss: 2.4908059375537284

Epoch: 5| Step: 5
Training loss: 2.4968549018595256
Validation loss: 2.4961888827968592

Epoch: 5| Step: 6
Training loss: 2.7297578030700143
Validation loss: 2.500975730346716

Epoch: 5| Step: 7
Training loss: 2.671608448675338
Validation loss: 2.5016471125732034

Epoch: 5| Step: 8
Training loss: 2.6597849941122655
Validation loss: 2.4961049493051894

Epoch: 5| Step: 9
Training loss: 2.7194604055135208
Validation loss: 2.4976167405445673

Epoch: 5| Step: 10
Training loss: 2.1680830092005094
Validation loss: 2.503098637810743

Epoch: 5| Step: 11
Training loss: 0.648791159277842
Validation loss: 2.5024366584050486

Epoch: 99| Step: 0
Training loss: 2.3678456011710534
Validation loss: 2.4981693638449314

Epoch: 5| Step: 1
Training loss: 2.3626120888898288
Validation loss: 2.4991149011062954

Epoch: 5| Step: 2
Training loss: 2.512802151403809
Validation loss: 2.4993013756844755

Epoch: 5| Step: 3
Training loss: 2.1500325888004705
Validation loss: 2.497965915015219

Epoch: 5| Step: 4
Training loss: 2.7240175103396385
Validation loss: 2.493916707852361

Epoch: 5| Step: 5
Training loss: 2.6816605402574405
Validation loss: 2.500473486249394

Epoch: 5| Step: 6
Training loss: 3.4483370491058207
Validation loss: 2.496976844451585

Epoch: 5| Step: 7
Training loss: 2.332531745915396
Validation loss: 2.494394734023475

Epoch: 5| Step: 8
Training loss: 3.351592092672386
Validation loss: 2.495961316594756

Epoch: 5| Step: 9
Training loss: 2.056168635187626
Validation loss: 2.498173726121777

Epoch: 5| Step: 10
Training loss: 2.3404703208836066
Validation loss: 2.5034133894226005

Epoch: 5| Step: 11
Training loss: 2.5757200178852258
Validation loss: 2.4997187257528366

Epoch: 100| Step: 0
Training loss: 2.35204089801938
Validation loss: 2.5032400156394288

Epoch: 5| Step: 1
Training loss: 3.233143152628065
Validation loss: 2.505926328038648

Epoch: 5| Step: 2
Training loss: 2.7654024023788146
Validation loss: 2.5125122675746447

Epoch: 5| Step: 3
Training loss: 2.8871875015855
Validation loss: 2.5129723671042705

Epoch: 5| Step: 4
Training loss: 2.4874377295592867
Validation loss: 2.5120281663692907

Epoch: 5| Step: 5
Training loss: 2.7078907140319797
Validation loss: 2.512298374721185

Epoch: 5| Step: 6
Training loss: 2.137320090413291
Validation loss: 2.508659635645059

Epoch: 5| Step: 7
Training loss: 2.220413980976909
Validation loss: 2.5064176917161265

Epoch: 5| Step: 8
Training loss: 2.8647899946168542
Validation loss: 2.5041554922551703

Epoch: 5| Step: 9
Training loss: 2.282170044864751
Validation loss: 2.4992264584033603

Epoch: 5| Step: 10
Training loss: 2.826762340054154
Validation loss: 2.50108452558569

Epoch: 5| Step: 11
Training loss: 2.447093473500368
Validation loss: 2.50166420381371

Epoch: 101| Step: 0
Training loss: 3.1694534153040057
Validation loss: 2.4956648353118855

Epoch: 5| Step: 1
Training loss: 2.5454397077251825
Validation loss: 2.487678934016269

Epoch: 5| Step: 2
Training loss: 2.454873209241102
Validation loss: 2.4915006282965604

Epoch: 5| Step: 3
Training loss: 2.383188486921833
Validation loss: 2.505856782312754

Epoch: 5| Step: 4
Training loss: 2.8327177912455146
Validation loss: 2.5185425703712006

Epoch: 5| Step: 5
Training loss: 2.724795755553958
Validation loss: 2.509811927378192

Epoch: 5| Step: 6
Training loss: 2.7198996031689036
Validation loss: 2.5003199253417803

Epoch: 5| Step: 7
Training loss: 2.784479730522372
Validation loss: 2.4944642010654277

Epoch: 5| Step: 8
Training loss: 1.9938846315470906
Validation loss: 2.4917581521231917

Epoch: 5| Step: 9
Training loss: 2.485237499684907
Validation loss: 2.48582114509419

Epoch: 5| Step: 10
Training loss: 2.5441552366601172
Validation loss: 2.493539306038624

Epoch: 5| Step: 11
Training loss: 3.4810646651567576
Validation loss: 2.498406760841967

Epoch: 102| Step: 0
Training loss: 2.825598584114705
Validation loss: 2.496134782035005

Epoch: 5| Step: 1
Training loss: 2.833215337054027
Validation loss: 2.5009520307432807

Epoch: 5| Step: 2
Training loss: 2.450426305933428
Validation loss: 2.5044625309561668

Epoch: 5| Step: 3
Training loss: 2.4037052917290183
Validation loss: 2.5041176740917854

Epoch: 5| Step: 4
Training loss: 2.45798065328162
Validation loss: 2.5014638191502514

Epoch: 5| Step: 5
Training loss: 2.6551736782761126
Validation loss: 2.4982519793821187

Epoch: 5| Step: 6
Training loss: 2.4007264190281608
Validation loss: 2.501087202658287

Epoch: 5| Step: 7
Training loss: 2.7484119338190527
Validation loss: 2.5000646582825135

Epoch: 5| Step: 8
Training loss: 2.801356470688209
Validation loss: 2.501759140669883

Epoch: 5| Step: 9
Training loss: 2.3276228395163874
Validation loss: 2.497876024008371

Epoch: 5| Step: 10
Training loss: 2.932094226285855
Validation loss: 2.4955777076108085

Epoch: 5| Step: 11
Training loss: 2.3880400800744
Validation loss: 2.494719858005496

Epoch: 103| Step: 0
Training loss: 2.80989988725645
Validation loss: 2.494673036583326

Epoch: 5| Step: 1
Training loss: 2.8350589957313663
Validation loss: 2.487693461685788

Epoch: 5| Step: 2
Training loss: 2.475533738046809
Validation loss: 2.4879675986381886

Epoch: 5| Step: 3
Training loss: 2.7761926854455172
Validation loss: 2.4888536602308142

Epoch: 5| Step: 4
Training loss: 2.8365104663964424
Validation loss: 2.4841207418149818

Epoch: 5| Step: 5
Training loss: 2.675271090024495
Validation loss: 2.487360338223282

Epoch: 5| Step: 6
Training loss: 2.5628718594813393
Validation loss: 2.4832937578807064

Epoch: 5| Step: 7
Training loss: 2.3083589954074446
Validation loss: 2.4808482002523577

Epoch: 5| Step: 8
Training loss: 2.245256191495304
Validation loss: 2.489410838664804

Epoch: 5| Step: 9
Training loss: 2.4557894675388017
Validation loss: 2.4842092710674413

Epoch: 5| Step: 10
Training loss: 2.611252617439795
Validation loss: 2.4859389574648847

Epoch: 5| Step: 11
Training loss: 2.425418746817157
Validation loss: 2.483037754657367

Epoch: 104| Step: 0
Training loss: 2.3879818734610434
Validation loss: 2.4838785879148157

Epoch: 5| Step: 1
Training loss: 2.5012657775838827
Validation loss: 2.480601273648518

Epoch: 5| Step: 2
Training loss: 2.3768391766031516
Validation loss: 2.4891954596018158

Epoch: 5| Step: 3
Training loss: 2.723969633955457
Validation loss: 2.488385839574758

Epoch: 5| Step: 4
Training loss: 2.5194797717609285
Validation loss: 2.495140884794513

Epoch: 5| Step: 5
Training loss: 2.5280200460218625
Validation loss: 2.495565005214289

Epoch: 5| Step: 6
Training loss: 3.1414423396179867
Validation loss: 2.494764691540828

Epoch: 5| Step: 7
Training loss: 2.7364417412618733
Validation loss: 2.497092726170123

Epoch: 5| Step: 8
Training loss: 2.504666741107245
Validation loss: 2.4928461956239754

Epoch: 5| Step: 9
Training loss: 2.619944654564473
Validation loss: 2.492285564091691

Epoch: 5| Step: 10
Training loss: 2.4483183402720528
Validation loss: 2.4925406473850797

Epoch: 5| Step: 11
Training loss: 3.2503365562479583
Validation loss: 2.488142771238597

Epoch: 105| Step: 0
Training loss: 2.890759604129542
Validation loss: 2.4892082902829324

Epoch: 5| Step: 1
Training loss: 2.4018849997072813
Validation loss: 2.4911287504282114

Epoch: 5| Step: 2
Training loss: 2.649063081479141
Validation loss: 2.491687935852145

Epoch: 5| Step: 3
Training loss: 2.602956404154928
Validation loss: 2.488489043513838

Epoch: 5| Step: 4
Training loss: 2.2949108626730466
Validation loss: 2.482286739197735

Epoch: 5| Step: 5
Training loss: 2.7231744303232412
Validation loss: 2.483537800796564

Epoch: 5| Step: 6
Training loss: 2.24036985085812
Validation loss: 2.479239644384303

Epoch: 5| Step: 7
Training loss: 2.3526310821563223
Validation loss: 2.483853999275388

Epoch: 5| Step: 8
Training loss: 2.393095846409529
Validation loss: 2.473734708349696

Epoch: 5| Step: 9
Training loss: 2.9284007590934977
Validation loss: 2.479023457779974

Epoch: 5| Step: 10
Training loss: 2.9197619952571054
Validation loss: 2.4755710939944233

Epoch: 5| Step: 11
Training loss: 2.885294520320957
Validation loss: 2.4783855711731912

Epoch: 106| Step: 0
Training loss: 2.2406639744815164
Validation loss: 2.4792246504555724

Epoch: 5| Step: 1
Training loss: 2.5990918774335987
Validation loss: 2.479678889794275

Epoch: 5| Step: 2
Training loss: 3.20098805670758
Validation loss: 2.4820741859655118

Epoch: 5| Step: 3
Training loss: 2.763916004842356
Validation loss: 2.4813005389392275

Epoch: 5| Step: 4
Training loss: 2.036095342131241
Validation loss: 2.482336031322141

Epoch: 5| Step: 5
Training loss: 2.534062647827159
Validation loss: 2.4871620363971476

Epoch: 5| Step: 6
Training loss: 2.6094410596697486
Validation loss: 2.483587824072522

Epoch: 5| Step: 7
Training loss: 2.5889382829260903
Validation loss: 2.4836617251590933

Epoch: 5| Step: 8
Training loss: 2.3100066274902917
Validation loss: 2.4836960950549276

Epoch: 5| Step: 9
Training loss: 3.058720494709888
Validation loss: 2.483432819039952

Epoch: 5| Step: 10
Training loss: 2.305453002007222
Validation loss: 2.4844467424634376

Epoch: 5| Step: 11
Training loss: 2.478974332214154
Validation loss: 2.4833787884061764

Epoch: 107| Step: 0
Training loss: 2.5229858372155083
Validation loss: 2.478484614233113

Epoch: 5| Step: 1
Training loss: 2.6603211563240174
Validation loss: 2.475940200969175

Epoch: 5| Step: 2
Training loss: 2.500296956545491
Validation loss: 2.478368776348453

Epoch: 5| Step: 3
Training loss: 2.602810305547413
Validation loss: 2.4747281125071203

Epoch: 5| Step: 4
Training loss: 2.192577463867262
Validation loss: 2.472547999820272

Epoch: 5| Step: 5
Training loss: 2.6784026065485587
Validation loss: 2.4752856311319866

Epoch: 5| Step: 6
Training loss: 2.4623238669981595
Validation loss: 2.4800348638287417

Epoch: 5| Step: 7
Training loss: 2.5171879243287973
Validation loss: 2.4816897773648643

Epoch: 5| Step: 8
Training loss: 2.828809623679884
Validation loss: 2.4848472538228346

Epoch: 5| Step: 9
Training loss: 2.6339474730471535
Validation loss: 2.4825428618834686

Epoch: 5| Step: 10
Training loss: 2.612295286928179
Validation loss: 2.4840580640119696

Epoch: 5| Step: 11
Training loss: 3.5180156802055156
Validation loss: 2.4841580846045983

Epoch: 108| Step: 0
Training loss: 2.7297853152082245
Validation loss: 2.4893011920192625

Epoch: 5| Step: 1
Training loss: 1.9330939369406923
Validation loss: 2.4863852199442658

Epoch: 5| Step: 2
Training loss: 2.5555226305439303
Validation loss: 2.490648254707164

Epoch: 5| Step: 3
Training loss: 2.565857525230642
Validation loss: 2.4857442509385423

Epoch: 5| Step: 4
Training loss: 2.77113457287514
Validation loss: 2.491123083766961

Epoch: 5| Step: 5
Training loss: 2.81890588908703
Validation loss: 2.4863302106466483

Epoch: 5| Step: 6
Training loss: 2.5356013255604357
Validation loss: 2.485254655808645

Epoch: 5| Step: 7
Training loss: 2.5636833993936654
Validation loss: 2.485879030944704

Epoch: 5| Step: 8
Training loss: 2.479783235275095
Validation loss: 2.479120732263898

Epoch: 5| Step: 9
Training loss: 2.46984896765666
Validation loss: 2.4817511780245027

Epoch: 5| Step: 10
Training loss: 2.848158887502928
Validation loss: 2.470591329224036

Epoch: 5| Step: 11
Training loss: 2.9054649687391367
Validation loss: 2.47509722277874

Epoch: 109| Step: 0
Training loss: 2.4495681927126487
Validation loss: 2.478786152133413

Epoch: 5| Step: 1
Training loss: 2.383054327028158
Validation loss: 2.467102217131402

Epoch: 5| Step: 2
Training loss: 2.7071408996833775
Validation loss: 2.473935507953486

Epoch: 5| Step: 3
Training loss: 2.690713070658646
Validation loss: 2.4730229439805473

Epoch: 5| Step: 4
Training loss: 2.131966559357178
Validation loss: 2.478203102731465

Epoch: 5| Step: 5
Training loss: 2.679374476353332
Validation loss: 2.4731439608654533

Epoch: 5| Step: 6
Training loss: 2.635895596336774
Validation loss: 2.4737086615145185

Epoch: 5| Step: 7
Training loss: 2.9426723961900394
Validation loss: 2.4743215127026468

Epoch: 5| Step: 8
Training loss: 2.7167909952589593
Validation loss: 2.479296137263363

Epoch: 5| Step: 9
Training loss: 2.6971236625951294
Validation loss: 2.479221777477048

Epoch: 5| Step: 10
Training loss: 2.416695057493917
Validation loss: 2.4849866597938783

Epoch: 5| Step: 11
Training loss: 2.2788792663169364
Validation loss: 2.485529665258143

Epoch: 110| Step: 0
Training loss: 2.4289543787573433
Validation loss: 2.487884378048547

Epoch: 5| Step: 1
Training loss: 2.6114362239218725
Validation loss: 2.487337205821799

Epoch: 5| Step: 2
Training loss: 3.104059170562086
Validation loss: 2.481856943393187

Epoch: 5| Step: 3
Training loss: 2.4432453034360777
Validation loss: 2.4891364136709098

Epoch: 5| Step: 4
Training loss: 2.720629689032705
Validation loss: 2.488611587642834

Epoch: 5| Step: 5
Training loss: 1.8311029941544565
Validation loss: 2.4836423901337517

Epoch: 5| Step: 6
Training loss: 2.4276308634534813
Validation loss: 2.4845593621965985

Epoch: 5| Step: 7
Training loss: 2.8227422080847595
Validation loss: 2.483970997108412

Epoch: 5| Step: 8
Training loss: 2.496751677674799
Validation loss: 2.473729222714638

Epoch: 5| Step: 9
Training loss: 2.47356428253991
Validation loss: 2.4785826232848946

Epoch: 5| Step: 10
Training loss: 2.8372786112052055
Validation loss: 2.480039059724903

Epoch: 5| Step: 11
Training loss: 3.2844417489017386
Validation loss: 2.4753689221247472

Epoch: 111| Step: 0
Training loss: 2.5451615075087473
Validation loss: 2.4761716010687347

Epoch: 5| Step: 1
Training loss: 2.265692558596723
Validation loss: 2.472167751757533

Epoch: 5| Step: 2
Training loss: 2.9942465288776408
Validation loss: 2.469460228270112

Epoch: 5| Step: 3
Training loss: 2.56951762143885
Validation loss: 2.4686176751482822

Epoch: 5| Step: 4
Training loss: 2.527226205064545
Validation loss: 2.4701095973859633

Epoch: 5| Step: 5
Training loss: 2.614410840508574
Validation loss: 2.4730536175229565

Epoch: 5| Step: 6
Training loss: 2.5089897648650847
Validation loss: 2.474366101573911

Epoch: 5| Step: 7
Training loss: 2.3007847732491062
Validation loss: 2.4722923023015935

Epoch: 5| Step: 8
Training loss: 2.9128433418093977
Validation loss: 2.4768089167830585

Epoch: 5| Step: 9
Training loss: 2.874803619312
Validation loss: 2.4649556835329283

Epoch: 5| Step: 10
Training loss: 2.2488035623767146
Validation loss: 2.4772720644133113

Epoch: 5| Step: 11
Training loss: 2.0813650242634747
Validation loss: 2.472001662547747

Epoch: 112| Step: 0
Training loss: 2.5904665467105468
Validation loss: 2.4782496099903697

Epoch: 5| Step: 1
Training loss: 2.3814705493747055
Validation loss: 2.4741643491930936

Epoch: 5| Step: 2
Training loss: 2.8746613012746214
Validation loss: 2.4739329460581483

Epoch: 5| Step: 3
Training loss: 3.136165052216036
Validation loss: 2.474794023143748

Epoch: 5| Step: 4
Training loss: 2.61837805243786
Validation loss: 2.4784071798124954

Epoch: 5| Step: 5
Training loss: 2.5756286557381523
Validation loss: 2.477970565370924

Epoch: 5| Step: 6
Training loss: 2.656754030763945
Validation loss: 2.476050062142597

Epoch: 5| Step: 7
Training loss: 2.047504823187619
Validation loss: 2.476293358683958

Epoch: 5| Step: 8
Training loss: 2.428126578901212
Validation loss: 2.469751424527278

Epoch: 5| Step: 9
Training loss: 2.4991852386317084
Validation loss: 2.468745815096499

Epoch: 5| Step: 10
Training loss: 2.562890464993184
Validation loss: 2.4644729206336

Epoch: 5| Step: 11
Training loss: 1.4899724527667155
Validation loss: 2.4624096377812683

Epoch: 113| Step: 0
Training loss: 2.365218448349041
Validation loss: 2.466273312897533

Epoch: 5| Step: 1
Training loss: 2.405761470992097
Validation loss: 2.464506385152332

Epoch: 5| Step: 2
Training loss: 2.431014799298173
Validation loss: 2.4679181914802757

Epoch: 5| Step: 3
Training loss: 2.447073110694086
Validation loss: 2.462912280849406

Epoch: 5| Step: 4
Training loss: 2.5365074095524736
Validation loss: 2.4674673551063853

Epoch: 5| Step: 5
Training loss: 2.5169979163772394
Validation loss: 2.466448598455235

Epoch: 5| Step: 6
Training loss: 2.9049223461704226
Validation loss: 2.463772242094245

Epoch: 5| Step: 7
Training loss: 2.6570890111345613
Validation loss: 2.4708464408792734

Epoch: 5| Step: 8
Training loss: 2.783120458613335
Validation loss: 2.4755029266906177

Epoch: 5| Step: 9
Training loss: 2.3558969693606975
Validation loss: 2.4774426080745755

Epoch: 5| Step: 10
Training loss: 2.86739670824361
Validation loss: 2.474254158135241

Epoch: 5| Step: 11
Training loss: 2.597460379422265
Validation loss: 2.4787699812126878

Epoch: 114| Step: 0
Training loss: 2.761947859739469
Validation loss: 2.4823821850236696

Epoch: 5| Step: 1
Training loss: 2.189355771489146
Validation loss: 2.476810266433501

Epoch: 5| Step: 2
Training loss: 2.9215358598510317
Validation loss: 2.473342727898632

Epoch: 5| Step: 3
Training loss: 2.3483880500384156
Validation loss: 2.472426156200325

Epoch: 5| Step: 4
Training loss: 2.9538181036525137
Validation loss: 2.468329047678649

Epoch: 5| Step: 5
Training loss: 2.406679288543967
Validation loss: 2.465940067417386

Epoch: 5| Step: 6
Training loss: 2.6505077451439134
Validation loss: 2.4693855562067326

Epoch: 5| Step: 7
Training loss: 3.074980393013821
Validation loss: 2.463209897391281

Epoch: 5| Step: 8
Training loss: 2.296546133982031
Validation loss: 2.4704935500127605

Epoch: 5| Step: 9
Training loss: 2.0169343465957894
Validation loss: 2.4697802522594774

Epoch: 5| Step: 10
Training loss: 2.7436236237290426
Validation loss: 2.4715953356837086

Epoch: 5| Step: 11
Training loss: 1.3995510760980603
Validation loss: 2.4698870511073348

Epoch: 115| Step: 0
Training loss: 2.304916939387002
Validation loss: 2.476321255780208

Epoch: 5| Step: 1
Training loss: 2.684059513546509
Validation loss: 2.4784074964652416

Epoch: 5| Step: 2
Training loss: 2.4769238710743906
Validation loss: 2.4783821039931584

Epoch: 5| Step: 3
Training loss: 2.4171558301610374
Validation loss: 2.4781126451765596

Epoch: 5| Step: 4
Training loss: 2.7732941926278802
Validation loss: 2.480817807285348

Epoch: 5| Step: 5
Training loss: 2.3662750197678304
Validation loss: 2.483217121505077

Epoch: 5| Step: 6
Training loss: 2.046089545817679
Validation loss: 2.4780337379009767

Epoch: 5| Step: 7
Training loss: 2.9011693044055025
Validation loss: 2.4720044876565086

Epoch: 5| Step: 8
Training loss: 3.265846354452192
Validation loss: 2.475475674492936

Epoch: 5| Step: 9
Training loss: 2.6499513333728197
Validation loss: 2.4736834979069635

Epoch: 5| Step: 10
Training loss: 2.4474527663445413
Validation loss: 2.468036914804657

Epoch: 5| Step: 11
Training loss: 0.9906706140648335
Validation loss: 2.4659947258732258

Epoch: 116| Step: 0
Training loss: 2.7015813929447097
Validation loss: 2.463035770811132

Epoch: 5| Step: 1
Training loss: 2.209871931723728
Validation loss: 2.460248085618441

Epoch: 5| Step: 2
Training loss: 2.393909267774455
Validation loss: 2.4681157613249542

Epoch: 5| Step: 3
Training loss: 2.6072014076093333
Validation loss: 2.4666463806525307

Epoch: 5| Step: 4
Training loss: 3.1926386681942907
Validation loss: 2.4630679279250063

Epoch: 5| Step: 5
Training loss: 2.469634465031038
Validation loss: 2.4525762053460816

Epoch: 5| Step: 6
Training loss: 2.9417986968960133
Validation loss: 2.464655341490808

Epoch: 5| Step: 7
Training loss: 2.3819281265792234
Validation loss: 2.4687855713933398

Epoch: 5| Step: 8
Training loss: 2.2082943702955244
Validation loss: 2.47117204601395

Epoch: 5| Step: 9
Training loss: 2.8318517588594347
Validation loss: 2.4708674601105987

Epoch: 5| Step: 10
Training loss: 2.3113733588597563
Validation loss: 2.4742174648630484

Epoch: 5| Step: 11
Training loss: 2.5893821247360984
Validation loss: 2.4714585588044513

Epoch: 117| Step: 0
Training loss: 3.024170779234787
Validation loss: 2.472818880523288

Epoch: 5| Step: 1
Training loss: 2.582671901155339
Validation loss: 2.4730745256061466

Epoch: 5| Step: 2
Training loss: 2.346478006282195
Validation loss: 2.4701042927218193

Epoch: 5| Step: 3
Training loss: 2.5190661097108973
Validation loss: 2.4684717005387005

Epoch: 5| Step: 4
Training loss: 2.3220799967862025
Validation loss: 2.467243334392285

Epoch: 5| Step: 5
Training loss: 2.5581201479017897
Validation loss: 2.4579407100942516

Epoch: 5| Step: 6
Training loss: 2.414441224053292
Validation loss: 2.4615985204613278

Epoch: 5| Step: 7
Training loss: 2.140237703580125
Validation loss: 2.4593886451391134

Epoch: 5| Step: 8
Training loss: 2.7600662488864622
Validation loss: 2.4621116178610185

Epoch: 5| Step: 9
Training loss: 3.0779902239886545
Validation loss: 2.45337521842087

Epoch: 5| Step: 10
Training loss: 2.2898941352061803
Validation loss: 2.4500080278810037

Epoch: 5| Step: 11
Training loss: 2.7807210354931122
Validation loss: 2.4598413236158163

Epoch: 118| Step: 0
Training loss: 2.3580771407046193
Validation loss: 2.4617992365770496

Epoch: 5| Step: 1
Training loss: 2.165561528672541
Validation loss: 2.4696979795073744

Epoch: 5| Step: 2
Training loss: 2.6181643356897935
Validation loss: 2.4668951913506474

Epoch: 5| Step: 3
Training loss: 2.806753178876798
Validation loss: 2.472476737771502

Epoch: 5| Step: 4
Training loss: 2.8219322562085667
Validation loss: 2.476231493725883

Epoch: 5| Step: 5
Training loss: 2.951765605346029
Validation loss: 2.472283920370672

Epoch: 5| Step: 6
Training loss: 1.7004796753868623
Validation loss: 2.469643773081146

Epoch: 5| Step: 7
Training loss: 2.4501487025072977
Validation loss: 2.461753072270369

Epoch: 5| Step: 8
Training loss: 3.1012935954254406
Validation loss: 2.4647200443038892

Epoch: 5| Step: 9
Training loss: 2.5345435673244063
Validation loss: 2.4635640735427153

Epoch: 5| Step: 10
Training loss: 2.09443197957767
Validation loss: 2.4629282049770245

Epoch: 5| Step: 11
Training loss: 3.6723796091932757
Validation loss: 2.456705764211807

Epoch: 119| Step: 0
Training loss: 2.2211845902669385
Validation loss: 2.452684338589791

Epoch: 5| Step: 1
Training loss: 2.7222069871783225
Validation loss: 2.45249995390088

Epoch: 5| Step: 2
Training loss: 2.0535428299896865
Validation loss: 2.453969255375529

Epoch: 5| Step: 3
Training loss: 2.4100424864890098
Validation loss: 2.456022636755544

Epoch: 5| Step: 4
Training loss: 2.346772546474774
Validation loss: 2.4579661642008483

Epoch: 5| Step: 5
Training loss: 2.4985944611543176
Validation loss: 2.474027983371004

Epoch: 5| Step: 6
Training loss: 2.1138121102094356
Validation loss: 2.4751247761481627

Epoch: 5| Step: 7
Training loss: 2.730236562044194
Validation loss: 2.4810501218309975

Epoch: 5| Step: 8
Training loss: 2.8537031108197204
Validation loss: 2.480442201166926

Epoch: 5| Step: 9
Training loss: 3.2816221480274534
Validation loss: 2.4791319801938703

Epoch: 5| Step: 10
Training loss: 2.825651235545134
Validation loss: 2.4773615221027483

Epoch: 5| Step: 11
Training loss: 3.2035477522090403
Validation loss: 2.4715553673434565

Epoch: 120| Step: 0
Training loss: 2.1936051323597616
Validation loss: 2.456100643428258

Epoch: 5| Step: 1
Training loss: 2.4497633333144058
Validation loss: 2.454166353308804

Epoch: 5| Step: 2
Training loss: 2.7198297395431337
Validation loss: 2.46062731125135

Epoch: 5| Step: 3
Training loss: 2.736889712792204
Validation loss: 2.463230643018217

Epoch: 5| Step: 4
Training loss: 2.9440641717447456
Validation loss: 2.465323746540678

Epoch: 5| Step: 5
Training loss: 2.247150842449595
Validation loss: 2.468417342424378

Epoch: 5| Step: 6
Training loss: 2.736399397102226
Validation loss: 2.4616437514169833

Epoch: 5| Step: 7
Training loss: 2.5201373650184253
Validation loss: 2.4587786696778977

Epoch: 5| Step: 8
Training loss: 2.8051909523496414
Validation loss: 2.4536468655389667

Epoch: 5| Step: 9
Training loss: 2.401919145974999
Validation loss: 2.4575490966813223

Epoch: 5| Step: 10
Training loss: 2.5144944582711393
Validation loss: 2.4567944443386067

Epoch: 5| Step: 11
Training loss: 2.7350409868366716
Validation loss: 2.458480197485124

Epoch: 121| Step: 0
Training loss: 2.820635494429889
Validation loss: 2.453277996175994

Epoch: 5| Step: 1
Training loss: 2.351751478338887
Validation loss: 2.4563555655147797

Epoch: 5| Step: 2
Training loss: 2.356644724357501
Validation loss: 2.4607456273761534

Epoch: 5| Step: 3
Training loss: 2.7467831957581783
Validation loss: 2.4587718214260375

Epoch: 5| Step: 4
Training loss: 2.6464089696072532
Validation loss: 2.455042140538159

Epoch: 5| Step: 5
Training loss: 2.635781354637897
Validation loss: 2.4611924902191795

Epoch: 5| Step: 6
Training loss: 2.601708393760167
Validation loss: 2.4617293360547197

Epoch: 5| Step: 7
Training loss: 1.9856204832588193
Validation loss: 2.463769048691026

Epoch: 5| Step: 8
Training loss: 2.420482604401033
Validation loss: 2.467425457827872

Epoch: 5| Step: 9
Training loss: 2.6100822906383256
Validation loss: 2.465754107603135

Epoch: 5| Step: 10
Training loss: 2.882882135475444
Validation loss: 2.4697821950120815

Epoch: 5| Step: 11
Training loss: 2.671327501385673
Validation loss: 2.4714681976240698

Epoch: 122| Step: 0
Training loss: 1.6371721536463564
Validation loss: 2.4662065240037987

Epoch: 5| Step: 1
Training loss: 2.7528300028788113
Validation loss: 2.460447078864647

Epoch: 5| Step: 2
Training loss: 2.6391873932596606
Validation loss: 2.4505356752038736

Epoch: 5| Step: 3
Training loss: 2.246715161152019
Validation loss: 2.461019242155267

Epoch: 5| Step: 4
Training loss: 2.664990484424658
Validation loss: 2.455967068736675

Epoch: 5| Step: 5
Training loss: 2.907566551699802
Validation loss: 2.4637478943062088

Epoch: 5| Step: 6
Training loss: 3.1264349122635062
Validation loss: 2.455967897938219

Epoch: 5| Step: 7
Training loss: 2.5130285286003184
Validation loss: 2.459784020451072

Epoch: 5| Step: 8
Training loss: 2.364381745157646
Validation loss: 2.45967659108864

Epoch: 5| Step: 9
Training loss: 2.328505312175724
Validation loss: 2.451030837582391

Epoch: 5| Step: 10
Training loss: 2.7698929608317595
Validation loss: 2.4531081375222845

Epoch: 5| Step: 11
Training loss: 2.6074855153750374
Validation loss: 2.456119402518844

Epoch: 123| Step: 0
Training loss: 2.5879036150912182
Validation loss: 2.4629791510067776

Epoch: 5| Step: 1
Training loss: 2.597367487180887
Validation loss: 2.4760645938486374

Epoch: 5| Step: 2
Training loss: 2.9459420500194424
Validation loss: 2.481273166250475

Epoch: 5| Step: 3
Training loss: 2.252956038024542
Validation loss: 2.491914843848361

Epoch: 5| Step: 4
Training loss: 2.716405273999052
Validation loss: 2.488287026934103

Epoch: 5| Step: 5
Training loss: 2.574524278121392
Validation loss: 2.4902498970295963

Epoch: 5| Step: 6
Training loss: 3.105705664852479
Validation loss: 2.485466811150441

Epoch: 5| Step: 7
Training loss: 2.6339948133216255
Validation loss: 2.488788950181183

Epoch: 5| Step: 8
Training loss: 2.6906062073444503
Validation loss: 2.483852365490055

Epoch: 5| Step: 9
Training loss: 2.05853630434554
Validation loss: 2.485987334008659

Epoch: 5| Step: 10
Training loss: 2.090265021244748
Validation loss: 2.4808357347761465

Epoch: 5| Step: 11
Training loss: 2.9807074414988532
Validation loss: 2.479826436019499

Epoch: 124| Step: 0
Training loss: 2.723930684539536
Validation loss: 2.4691359081524

Epoch: 5| Step: 1
Training loss: 2.857398512165256
Validation loss: 2.4648475243911823

Epoch: 5| Step: 2
Training loss: 2.3923702476657964
Validation loss: 2.460923718610655

Epoch: 5| Step: 3
Training loss: 2.1737225036461454
Validation loss: 2.4634077561311325

Epoch: 5| Step: 4
Training loss: 2.55374361385643
Validation loss: 2.458812143012082

Epoch: 5| Step: 5
Training loss: 2.90340998537097
Validation loss: 2.4563894398901094

Epoch: 5| Step: 6
Training loss: 3.1344058582007754
Validation loss: 2.4546714654306103

Epoch: 5| Step: 7
Training loss: 1.9050921691664708
Validation loss: 2.4586392322782396

Epoch: 5| Step: 8
Training loss: 2.6389528657173904
Validation loss: 2.4674120347660873

Epoch: 5| Step: 9
Training loss: 2.6621752903614984
Validation loss: 2.470154109463828

Epoch: 5| Step: 10
Training loss: 2.2682877250905333
Validation loss: 2.466688869082132

Epoch: 5| Step: 11
Training loss: 2.0649873011755093
Validation loss: 2.4568775919387305

Epoch: 125| Step: 0
Training loss: 2.0877994984937236
Validation loss: 2.455659007057612

Epoch: 5| Step: 1
Training loss: 2.4635190955990383
Validation loss: 2.4668084167226567

Epoch: 5| Step: 2
Training loss: 2.3698892314794846
Validation loss: 2.475477789348053

Epoch: 5| Step: 3
Training loss: 2.980040273202231
Validation loss: 2.480761012683769

Epoch: 5| Step: 4
Training loss: 2.535327970217057
Validation loss: 2.4845794057828354

Epoch: 5| Step: 5
Training loss: 2.8954938145213918
Validation loss: 2.489472144661936

Epoch: 5| Step: 6
Training loss: 2.5112575742418404
Validation loss: 2.4871768546632502

Epoch: 5| Step: 7
Training loss: 2.6564155975782264
Validation loss: 2.489024907027988

Epoch: 5| Step: 8
Training loss: 2.804299330348295
Validation loss: 2.485579304731117

Epoch: 5| Step: 9
Training loss: 2.2253416763447924
Validation loss: 2.4868163782870383

Epoch: 5| Step: 10
Training loss: 2.6529605019192526
Validation loss: 2.4894043340669825

Epoch: 5| Step: 11
Training loss: 3.24137114392971
Validation loss: 2.4874225733798063

Epoch: 126| Step: 0
Training loss: 2.6782725521645436
Validation loss: 2.4806073728258533

Epoch: 5| Step: 1
Training loss: 2.062325903740664
Validation loss: 2.4725481826284006

Epoch: 5| Step: 2
Training loss: 2.742182370259848
Validation loss: 2.4725929240092097

Epoch: 5| Step: 3
Training loss: 2.9867978471943633
Validation loss: 2.4718972498088885

Epoch: 5| Step: 4
Training loss: 2.9865139790515483
Validation loss: 2.470097347173909

Epoch: 5| Step: 5
Training loss: 2.1245292815401107
Validation loss: 2.45818716088767

Epoch: 5| Step: 6
Training loss: 2.2403141928756987
Validation loss: 2.462407354364511

Epoch: 5| Step: 7
Training loss: 2.7761198585095412
Validation loss: 2.4571955291863965

Epoch: 5| Step: 8
Training loss: 2.3334004074628623
Validation loss: 2.4524411991781436

Epoch: 5| Step: 9
Training loss: 2.455150181358546
Validation loss: 2.455553403829933

Epoch: 5| Step: 10
Training loss: 2.5749097715698843
Validation loss: 2.455850913035892

Epoch: 5| Step: 11
Training loss: 2.6448123393703833
Validation loss: 2.449302773299363

Epoch: 127| Step: 0
Training loss: 2.5182924522382226
Validation loss: 2.44816968435411

Epoch: 5| Step: 1
Training loss: 2.5831011288377734
Validation loss: 2.453735263506206

Epoch: 5| Step: 2
Training loss: 2.9012894493224906
Validation loss: 2.450863903704147

Epoch: 5| Step: 3
Training loss: 3.0010065933150027
Validation loss: 2.4532909742120146

Epoch: 5| Step: 4
Training loss: 2.573051500584122
Validation loss: 2.459656485929597

Epoch: 5| Step: 5
Training loss: 2.3175433039400164
Validation loss: 2.4743512748396

Epoch: 5| Step: 6
Training loss: 3.0890462547882303
Validation loss: 2.479161590416036

Epoch: 5| Step: 7
Training loss: 2.5442525081436616
Validation loss: 2.4906036023441698

Epoch: 5| Step: 8
Training loss: 2.372124286161626
Validation loss: 2.4787790185060476

Epoch: 5| Step: 9
Training loss: 1.905128399183821
Validation loss: 2.4786878305046027

Epoch: 5| Step: 10
Training loss: 2.6565109124787907
Validation loss: 2.4702625791591464

Epoch: 5| Step: 11
Training loss: 1.6261915093472976
Validation loss: 2.4727545463063323

Epoch: 128| Step: 0
Training loss: 2.238378925422511
Validation loss: 2.4711245774179287

Epoch: 5| Step: 1
Training loss: 2.597264310481037
Validation loss: 2.4682512544082496

Epoch: 5| Step: 2
Training loss: 2.83456934354097
Validation loss: 2.4633252382812185

Epoch: 5| Step: 3
Training loss: 2.9573597089395607
Validation loss: 2.4594958810856444

Epoch: 5| Step: 4
Training loss: 2.7561295428953367
Validation loss: 2.4608544956317426

Epoch: 5| Step: 5
Training loss: 3.159029048765589
Validation loss: 2.464389658439371

Epoch: 5| Step: 6
Training loss: 2.416449295879068
Validation loss: 2.4532914965714654

Epoch: 5| Step: 7
Training loss: 2.304914456846793
Validation loss: 2.4501397400371068

Epoch: 5| Step: 8
Training loss: 2.3987417618300455
Validation loss: 2.4597709959004934

Epoch: 5| Step: 9
Training loss: 1.8027417812009294
Validation loss: 2.456058538091332

Epoch: 5| Step: 10
Training loss: 2.3932057332139327
Validation loss: 2.452736684108862

Epoch: 5| Step: 11
Training loss: 2.4075142647864305
Validation loss: 2.4520820862910866

Epoch: 129| Step: 0
Training loss: 2.626064992758444
Validation loss: 2.456242898311168

Epoch: 5| Step: 1
Training loss: 2.42677156686243
Validation loss: 2.4616867741306154

Epoch: 5| Step: 2
Training loss: 2.637076979426722
Validation loss: 2.4680698278679096

Epoch: 5| Step: 3
Training loss: 2.645603970976446
Validation loss: 2.4701866605243907

Epoch: 5| Step: 4
Training loss: 2.108591230800123
Validation loss: 2.4723489378542594

Epoch: 5| Step: 5
Training loss: 2.7096712964584975
Validation loss: 2.476587217189538

Epoch: 5| Step: 6
Training loss: 2.1917867891103042
Validation loss: 2.476982041050645

Epoch: 5| Step: 7
Training loss: 2.6429072342179625
Validation loss: 2.479840657168148

Epoch: 5| Step: 8
Training loss: 2.6080848108262598
Validation loss: 2.47929239087851

Epoch: 5| Step: 9
Training loss: 2.9267156150507407
Validation loss: 2.4848696458169948

Epoch: 5| Step: 10
Training loss: 2.583930490037174
Validation loss: 2.4747860069433907

Epoch: 5| Step: 11
Training loss: 2.416381512184439
Validation loss: 2.478293667216955

Epoch: 130| Step: 0
Training loss: 2.4858668424585937
Validation loss: 2.479423260566471

Epoch: 5| Step: 1
Training loss: 2.484296497568193
Validation loss: 2.476627585661927

Epoch: 5| Step: 2
Training loss: 2.388644925555764
Validation loss: 2.482078098250828

Epoch: 5| Step: 3
Training loss: 2.7299347493125454
Validation loss: 2.4727930088400707

Epoch: 5| Step: 4
Training loss: 2.807601647375471
Validation loss: 2.4725042962363846

Epoch: 5| Step: 5
Training loss: 2.27132629736656
Validation loss: 2.47262150567801

Epoch: 5| Step: 6
Training loss: 2.262207610906061
Validation loss: 2.4695207282033977

Epoch: 5| Step: 7
Training loss: 2.453069115263374
Validation loss: 2.465549367994482

Epoch: 5| Step: 8
Training loss: 2.6414903656124764
Validation loss: 2.458123021639459

Epoch: 5| Step: 9
Training loss: 2.908452337794227
Validation loss: 2.458428576343194

Epoch: 5| Step: 10
Training loss: 2.7280823589545036
Validation loss: 2.4605285022092245

Epoch: 5| Step: 11
Training loss: 1.762054276075322
Validation loss: 2.4501038432009903

Epoch: 131| Step: 0
Training loss: 2.579728985827741
Validation loss: 2.453648464779356

Epoch: 5| Step: 1
Training loss: 2.690744792119074
Validation loss: 2.4571486436447283

Epoch: 5| Step: 2
Training loss: 2.3381451537511024
Validation loss: 2.4564532846998475

Epoch: 5| Step: 3
Training loss: 2.551035939889453
Validation loss: 2.4619197399008876

Epoch: 5| Step: 4
Training loss: 2.3510951594829357
Validation loss: 2.4672555625374293

Epoch: 5| Step: 5
Training loss: 2.503303824334208
Validation loss: 2.470889212896898

Epoch: 5| Step: 6
Training loss: 2.7009096273466824
Validation loss: 2.4729354483821306

Epoch: 5| Step: 7
Training loss: 2.7682020174682664
Validation loss: 2.465359762258313

Epoch: 5| Step: 8
Training loss: 2.728730746877133
Validation loss: 2.4682394618468786

Epoch: 5| Step: 9
Training loss: 2.5392666309169236
Validation loss: 2.4647834315025516

Epoch: 5| Step: 10
Training loss: 2.6107137751993466
Validation loss: 2.474365218315758

Epoch: 5| Step: 11
Training loss: 1.6067799506606282
Validation loss: 2.4708711187573065

Epoch: 132| Step: 0
Training loss: 2.6246683728683515
Validation loss: 2.4617512281013245

Epoch: 5| Step: 1
Training loss: 2.4632962019224895
Validation loss: 2.4709495451703436

Epoch: 5| Step: 2
Training loss: 2.386730637341254
Validation loss: 2.468081890916925

Epoch: 5| Step: 3
Training loss: 2.9424565480410028
Validation loss: 2.458495887672999

Epoch: 5| Step: 4
Training loss: 2.742586546986695
Validation loss: 2.460680569754502

Epoch: 5| Step: 5
Training loss: 2.5354615014489155
Validation loss: 2.464596993437247

Epoch: 5| Step: 6
Training loss: 2.4849931439740724
Validation loss: 2.459950728607902

Epoch: 5| Step: 7
Training loss: 2.2106874142529462
Validation loss: 2.461584105139145

Epoch: 5| Step: 8
Training loss: 2.6399880267363023
Validation loss: 2.459297994420329

Epoch: 5| Step: 9
Training loss: 2.7492981795435547
Validation loss: 2.457548397366367

Epoch: 5| Step: 10
Training loss: 2.2489156229246183
Validation loss: 2.450573973665641

Epoch: 5| Step: 11
Training loss: 2.44161268658473
Validation loss: 2.4573257423443353

Epoch: 133| Step: 0
Training loss: 2.5203791647961182
Validation loss: 2.4524920268549724

Epoch: 5| Step: 1
Training loss: 3.0713637399009452
Validation loss: 2.454530847651275

Epoch: 5| Step: 2
Training loss: 2.341095298303712
Validation loss: 2.4589627007177373

Epoch: 5| Step: 3
Training loss: 2.7453314427182005
Validation loss: 2.4668361472423976

Epoch: 5| Step: 4
Training loss: 2.617318676749941
Validation loss: 2.4727948487916995

Epoch: 5| Step: 5
Training loss: 2.669159518766365
Validation loss: 2.468551555335473

Epoch: 5| Step: 6
Training loss: 1.6731139966498165
Validation loss: 2.4685161817861334

Epoch: 5| Step: 7
Training loss: 2.6105024449005105
Validation loss: 2.4745831045328464

Epoch: 5| Step: 8
Training loss: 2.4653753079268776
Validation loss: 2.470262289612689

Epoch: 5| Step: 9
Training loss: 2.846328739891481
Validation loss: 2.4735771621727194

Epoch: 5| Step: 10
Training loss: 2.432911490972595
Validation loss: 2.467987091553387

Epoch: 5| Step: 11
Training loss: 2.3235112499853736
Validation loss: 2.4632478515928975

Epoch: 134| Step: 0
Training loss: 2.6677422937041118
Validation loss: 2.4700105121005325

Epoch: 5| Step: 1
Training loss: 2.386098228491854
Validation loss: 2.472517522904724

Epoch: 5| Step: 2
Training loss: 2.907491603324226
Validation loss: 2.4726818298334483

Epoch: 5| Step: 3
Training loss: 2.779243774335716
Validation loss: 2.478499352111383

Epoch: 5| Step: 4
Training loss: 2.283986997203258
Validation loss: 2.474070212528166

Epoch: 5| Step: 5
Training loss: 2.7623561355621282
Validation loss: 2.478860921732849

Epoch: 5| Step: 6
Training loss: 2.435671585181758
Validation loss: 2.4706846696367912

Epoch: 5| Step: 7
Training loss: 2.345007800514245
Validation loss: 2.467943407834076

Epoch: 5| Step: 8
Training loss: 2.691287720482778
Validation loss: 2.4692598090133244

Epoch: 5| Step: 9
Training loss: 2.590270684726561
Validation loss: 2.4609676419788813

Epoch: 5| Step: 10
Training loss: 2.131541785349382
Validation loss: 2.4573140792719355

Epoch: 5| Step: 11
Training loss: 2.93662411232064
Validation loss: 2.4544367431666396

Epoch: 135| Step: 0
Training loss: 2.796931090405178
Validation loss: 2.4504600332232758

Epoch: 5| Step: 1
Training loss: 2.8113862269510115
Validation loss: 2.445503958619914

Epoch: 5| Step: 2
Training loss: 2.599970149822544
Validation loss: 2.4576715464914978

Epoch: 5| Step: 3
Training loss: 2.3962876815101675
Validation loss: 2.4487186105782692

Epoch: 5| Step: 4
Training loss: 2.223663155638109
Validation loss: 2.45384866524856

Epoch: 5| Step: 5
Training loss: 2.43920858118006
Validation loss: 2.456077544230488

Epoch: 5| Step: 6
Training loss: 2.146328643619923
Validation loss: 2.4635259346866265

Epoch: 5| Step: 7
Training loss: 2.4742908348035546
Validation loss: 2.4600153209434032

Epoch: 5| Step: 8
Training loss: 2.8574996384881595
Validation loss: 2.447275939578691

Epoch: 5| Step: 9
Training loss: 2.780212037212772
Validation loss: 2.450320554218208

Epoch: 5| Step: 10
Training loss: 2.5646831237896937
Validation loss: 2.4609129203093656

Epoch: 5| Step: 11
Training loss: 2.3604611555610995
Validation loss: 2.45679294419072

Epoch: 136| Step: 0
Training loss: 2.522063551499108
Validation loss: 2.4592201820771864

Epoch: 5| Step: 1
Training loss: 3.2698770246800968
Validation loss: 2.459822306172527

Epoch: 5| Step: 2
Training loss: 2.297147358426996
Validation loss: 2.4669475494301465

Epoch: 5| Step: 3
Training loss: 2.783964653903377
Validation loss: 2.466274513236234

Epoch: 5| Step: 4
Training loss: 2.517145964684137
Validation loss: 2.469650715882195

Epoch: 5| Step: 5
Training loss: 2.591742692508958
Validation loss: 2.471801682456733

Epoch: 5| Step: 6
Training loss: 2.457537139580892
Validation loss: 2.470233990304177

Epoch: 5| Step: 7
Training loss: 2.1801712429089104
Validation loss: 2.467951448272633

Epoch: 5| Step: 8
Training loss: 2.5487284089091116
Validation loss: 2.476151164459164

Epoch: 5| Step: 9
Training loss: 2.2717955647555996
Validation loss: 2.473678192874998

Epoch: 5| Step: 10
Training loss: 2.655635268940489
Validation loss: 2.4726120842900916

Epoch: 5| Step: 11
Training loss: 1.5674259358115652
Validation loss: 2.4692321620365214

Epoch: 137| Step: 0
Training loss: 2.4027513111790832
Validation loss: 2.460811131376448

Epoch: 5| Step: 1
Training loss: 2.8804738552957705
Validation loss: 2.456903332006953

Epoch: 5| Step: 2
Training loss: 2.603746934761664
Validation loss: 2.4461070263937983

Epoch: 5| Step: 3
Training loss: 2.043516009173536
Validation loss: 2.444968060172384

Epoch: 5| Step: 4
Training loss: 2.7370019119919444
Validation loss: 2.4463385885965083

Epoch: 5| Step: 5
Training loss: 2.358429270793528
Validation loss: 2.458546097217562

Epoch: 5| Step: 6
Training loss: 2.6238653364633717
Validation loss: 2.45992738691537

Epoch: 5| Step: 7
Training loss: 2.77450927656929
Validation loss: 2.456510180281867

Epoch: 5| Step: 8
Training loss: 2.6174034826633723
Validation loss: 2.4555343248586823

Epoch: 5| Step: 9
Training loss: 2.8013452363751625
Validation loss: 2.4561840470756

Epoch: 5| Step: 10
Training loss: 2.313363712983452
Validation loss: 2.456060370355886

Epoch: 5| Step: 11
Training loss: 2.529414795000946
Validation loss: 2.4606069070287955

Epoch: 138| Step: 0
Training loss: 3.049347642016259
Validation loss: 2.4677445742478197

Epoch: 5| Step: 1
Training loss: 2.9945072116379614
Validation loss: 2.4695058904800145

Epoch: 5| Step: 2
Training loss: 2.898750884601677
Validation loss: 2.474268110188626

Epoch: 5| Step: 3
Training loss: 2.4561375871322495
Validation loss: 2.4763935845789877

Epoch: 5| Step: 4
Training loss: 2.451314075494266
Validation loss: 2.4799131316819505

Epoch: 5| Step: 5
Training loss: 2.834431398076664
Validation loss: 2.4800130570712713

Epoch: 5| Step: 6
Training loss: 2.3579900857977454
Validation loss: 2.470008830950468

Epoch: 5| Step: 7
Training loss: 2.2674300796848765
Validation loss: 2.472467721639034

Epoch: 5| Step: 8
Training loss: 2.2252328215097665
Validation loss: 2.4747430554025427

Epoch: 5| Step: 9
Training loss: 2.1615336822490345
Validation loss: 2.463102113303971

Epoch: 5| Step: 10
Training loss: 2.336294089565141
Validation loss: 2.4700537208842612

Epoch: 5| Step: 11
Training loss: 2.1047171700360896
Validation loss: 2.461498253125032

Epoch: 139| Step: 0
Training loss: 2.2865291807513612
Validation loss: 2.4627831294665667

Epoch: 5| Step: 1
Training loss: 2.4770490006061263
Validation loss: 2.46109512066532

Epoch: 5| Step: 2
Training loss: 2.8443959938168093
Validation loss: 2.463012526921569

Epoch: 5| Step: 3
Training loss: 2.279892713632606
Validation loss: 2.454367325086504

Epoch: 5| Step: 4
Training loss: 3.125487937980863
Validation loss: 2.4518040099033733

Epoch: 5| Step: 5
Training loss: 2.633743981642833
Validation loss: 2.45416564088637

Epoch: 5| Step: 6
Training loss: 2.428627003506686
Validation loss: 2.458429368346984

Epoch: 5| Step: 7
Training loss: 2.4234366027712313
Validation loss: 2.4466335640347485

Epoch: 5| Step: 8
Training loss: 2.4582967486056932
Validation loss: 2.454617698141581

Epoch: 5| Step: 9
Training loss: 2.5779696331026125
Validation loss: 2.463218681233656

Epoch: 5| Step: 10
Training loss: 2.402560687931086
Validation loss: 2.4552416204548986

Epoch: 5| Step: 11
Training loss: 2.2092405890730222
Validation loss: 2.46017325104595

Epoch: 140| Step: 0
Training loss: 2.987638117578239
Validation loss: 2.4614822006898036

Epoch: 5| Step: 1
Training loss: 2.7372872674927327
Validation loss: 2.453596264225038

Epoch: 5| Step: 2
Training loss: 2.0586039418035185
Validation loss: 2.4569109739168566

Epoch: 5| Step: 3
Training loss: 1.9518940212606715
Validation loss: 2.464320990357339

Epoch: 5| Step: 4
Training loss: 2.177257755964365
Validation loss: 2.4591552497248

Epoch: 5| Step: 5
Training loss: 2.5261911774005963
Validation loss: 2.4491289234876614

Epoch: 5| Step: 6
Training loss: 2.324081186022212
Validation loss: 2.454475468463041

Epoch: 5| Step: 7
Training loss: 3.177013425631158
Validation loss: 2.457245324638313

Epoch: 5| Step: 8
Training loss: 2.5314099296626433
Validation loss: 2.455477167969338

Epoch: 5| Step: 9
Training loss: 2.7242840972668123
Validation loss: 2.459619304280427

Epoch: 5| Step: 10
Training loss: 2.398472888200859
Validation loss: 2.4590024131899058

Epoch: 5| Step: 11
Training loss: 3.070650426696069
Validation loss: 2.462869630462442

Epoch: 141| Step: 0
Training loss: 2.4676973054144833
Validation loss: 2.463764206161328

Epoch: 5| Step: 1
Training loss: 2.5156068031174157
Validation loss: 2.4640271526374318

Epoch: 5| Step: 2
Training loss: 2.378418620326204
Validation loss: 2.464663660691815

Epoch: 5| Step: 3
Training loss: 2.8487981905842803
Validation loss: 2.4644465340520996

Epoch: 5| Step: 4
Training loss: 2.2731953390344524
Validation loss: 2.467473404215054

Epoch: 5| Step: 5
Training loss: 2.7695356403956297
Validation loss: 2.4637827819083236

Epoch: 5| Step: 6
Training loss: 2.4314600130590223
Validation loss: 2.465082103652813

Epoch: 5| Step: 7
Training loss: 2.655712297656198
Validation loss: 2.466006670163692

Epoch: 5| Step: 8
Training loss: 2.4650194011799096
Validation loss: 2.4669818662825627

Epoch: 5| Step: 9
Training loss: 2.835736564474589
Validation loss: 2.4587122731529694

Epoch: 5| Step: 10
Training loss: 2.3535507769353603
Validation loss: 2.45724237744838

Epoch: 5| Step: 11
Training loss: 2.0693497632560787
Validation loss: 2.465424349879631

Epoch: 142| Step: 0
Training loss: 2.3945966652527315
Validation loss: 2.4710267027206263

Epoch: 5| Step: 1
Training loss: 2.2769411755227167
Validation loss: 2.4794437162818137

Epoch: 5| Step: 2
Training loss: 2.2181097906885907
Validation loss: 2.4667639852240573

Epoch: 5| Step: 3
Training loss: 2.7519969625345366
Validation loss: 2.472129834040652

Epoch: 5| Step: 4
Training loss: 2.834631753246561
Validation loss: 2.4765923595533748

Epoch: 5| Step: 5
Training loss: 2.6532377329174084
Validation loss: 2.466730619795728

Epoch: 5| Step: 6
Training loss: 2.8575476972682514
Validation loss: 2.4653481049573074

Epoch: 5| Step: 7
Training loss: 2.093168946673643
Validation loss: 2.461141688842444

Epoch: 5| Step: 8
Training loss: 2.677323613843842
Validation loss: 2.457863222582186

Epoch: 5| Step: 9
Training loss: 2.781416127247521
Validation loss: 2.4575585596462033

Epoch: 5| Step: 10
Training loss: 2.296582054089196
Validation loss: 2.4599053998884024

Epoch: 5| Step: 11
Training loss: 2.397975417366684
Validation loss: 2.4553591724899295

Epoch: 143| Step: 0
Training loss: 2.6936934321365245
Validation loss: 2.4513208473195522

Epoch: 5| Step: 1
Training loss: 3.140281544594575
Validation loss: 2.459970415416882

Epoch: 5| Step: 2
Training loss: 2.3429993508208184
Validation loss: 2.4501275501330393

Epoch: 5| Step: 3
Training loss: 2.3068334900979734
Validation loss: 2.459181761754018

Epoch: 5| Step: 4
Training loss: 2.3671926366164877
Validation loss: 2.45744918357735

Epoch: 5| Step: 5
Training loss: 2.0393123546708902
Validation loss: 2.4641866921570212

Epoch: 5| Step: 6
Training loss: 2.1564301125310585
Validation loss: 2.4628714576598525

Epoch: 5| Step: 7
Training loss: 2.668694102932529
Validation loss: 2.4603701749947904

Epoch: 5| Step: 8
Training loss: 2.5631204179687024
Validation loss: 2.456846326248092

Epoch: 5| Step: 9
Training loss: 2.685002963385909
Validation loss: 2.4549535751614773

Epoch: 5| Step: 10
Training loss: 2.673010066346331
Validation loss: 2.4558668586799364

Epoch: 5| Step: 11
Training loss: 2.853503593403793
Validation loss: 2.4533784496479876

Epoch: 144| Step: 0
Training loss: 2.4737623491793395
Validation loss: 2.454937518374204

Epoch: 5| Step: 1
Training loss: 2.774297532531655
Validation loss: 2.4575598491289856

Epoch: 5| Step: 2
Training loss: 2.5438156944246035
Validation loss: 2.4564745726744324

Epoch: 5| Step: 3
Training loss: 2.820554347777378
Validation loss: 2.4541825689589647

Epoch: 5| Step: 4
Training loss: 2.2679837280577795
Validation loss: 2.4517324872930986

Epoch: 5| Step: 5
Training loss: 2.5596382164125613
Validation loss: 2.4551729615395597

Epoch: 5| Step: 6
Training loss: 2.4217606056022896
Validation loss: 2.4510093564163995

Epoch: 5| Step: 7
Training loss: 2.640570103904233
Validation loss: 2.4437870674866824

Epoch: 5| Step: 8
Training loss: 2.0906413900191914
Validation loss: 2.4456316787364667

Epoch: 5| Step: 9
Training loss: 2.348756046987792
Validation loss: 2.4461973171834566

Epoch: 5| Step: 10
Training loss: 2.9785473230895274
Validation loss: 2.4434558210032864

Epoch: 5| Step: 11
Training loss: 2.062118032516397
Validation loss: 2.455593640716317

Epoch: 145| Step: 0
Training loss: 2.5244944340143403
Validation loss: 2.4599099774222917

Epoch: 5| Step: 1
Training loss: 3.133212779816972
Validation loss: 2.46605176387068

Epoch: 5| Step: 2
Training loss: 2.701157929114849
Validation loss: 2.472510712706138

Epoch: 5| Step: 3
Training loss: 2.291254757940219
Validation loss: 2.4685235503113026

Epoch: 5| Step: 4
Training loss: 2.2832316322602826
Validation loss: 2.4787323007546465

Epoch: 5| Step: 5
Training loss: 1.9981484186913885
Validation loss: 2.4765985608609293

Epoch: 5| Step: 6
Training loss: 2.833781450027252
Validation loss: 2.480768368865303

Epoch: 5| Step: 7
Training loss: 3.1797990709080435
Validation loss: 2.4809239007471637

Epoch: 5| Step: 8
Training loss: 2.2532822722042574
Validation loss: 2.4827009634928787

Epoch: 5| Step: 9
Training loss: 2.396798732693061
Validation loss: 2.4752337383910827

Epoch: 5| Step: 10
Training loss: 2.1915606276045736
Validation loss: 2.4721801323528347

Epoch: 5| Step: 11
Training loss: 3.1560815445164287
Validation loss: 2.4694185056034503

Epoch: 146| Step: 0
Training loss: 2.3345530818640676
Validation loss: 2.462924474029308

Epoch: 5| Step: 1
Training loss: 2.614090000333996
Validation loss: 2.4529434347487604

Epoch: 5| Step: 2
Training loss: 2.471660009552249
Validation loss: 2.4532039937383

Epoch: 5| Step: 3
Training loss: 2.873664545793912
Validation loss: 2.448737138185708

Epoch: 5| Step: 4
Training loss: 2.0157057871634074
Validation loss: 2.443246710253554

Epoch: 5| Step: 5
Training loss: 2.4931539258141955
Validation loss: 2.45065294018434

Epoch: 5| Step: 6
Training loss: 2.094341137691133
Validation loss: 2.4430306566976947

Epoch: 5| Step: 7
Training loss: 2.1894802394688697
Validation loss: 2.447336377021513

Epoch: 5| Step: 8
Training loss: 2.8738367795846305
Validation loss: 2.446117516427259

Epoch: 5| Step: 9
Training loss: 2.6224733636047026
Validation loss: 2.450816909194991

Epoch: 5| Step: 10
Training loss: 3.1122925838621724
Validation loss: 2.4500145113768266

Epoch: 5| Step: 11
Training loss: 2.003523107712923
Validation loss: 2.4473604517266163

Epoch: 147| Step: 0
Training loss: 2.8913950951069105
Validation loss: 2.450983372060049

Epoch: 5| Step: 1
Training loss: 2.3477570929425724
Validation loss: 2.448048824773961

Epoch: 5| Step: 2
Training loss: 2.5753773236896764
Validation loss: 2.4462179593674813

Epoch: 5| Step: 3
Training loss: 2.454289736897496
Validation loss: 2.4493640692277894

Epoch: 5| Step: 4
Training loss: 2.198615037030059
Validation loss: 2.448676934105527

Epoch: 5| Step: 5
Training loss: 2.131089740891765
Validation loss: 2.4555326337976746

Epoch: 5| Step: 6
Training loss: 2.929593585734322
Validation loss: 2.453832240923203

Epoch: 5| Step: 7
Training loss: 2.3087815984475086
Validation loss: 2.460477388350281

Epoch: 5| Step: 8
Training loss: 2.313199530294688
Validation loss: 2.455612852727216

Epoch: 5| Step: 9
Training loss: 2.991040839260478
Validation loss: 2.4599779629947913

Epoch: 5| Step: 10
Training loss: 2.698462108329771
Validation loss: 2.467144194390606

Epoch: 5| Step: 11
Training loss: 2.4200213814413503
Validation loss: 2.4578188880535063

Epoch: 148| Step: 0
Training loss: 2.014767486560755
Validation loss: 2.4516554518827163

Epoch: 5| Step: 1
Training loss: 2.1154974353822524
Validation loss: 2.4542588247947683

Epoch: 5| Step: 2
Training loss: 2.2382652721533773
Validation loss: 2.4557378141076325

Epoch: 5| Step: 3
Training loss: 2.480385029498801
Validation loss: 2.4534637193028295

Epoch: 5| Step: 4
Training loss: 2.8029067993292816
Validation loss: 2.4477568303675485

Epoch: 5| Step: 5
Training loss: 2.3823730063441833
Validation loss: 2.451569681702098

Epoch: 5| Step: 6
Training loss: 2.6139618538989655
Validation loss: 2.4507225708953735

Epoch: 5| Step: 7
Training loss: 2.175247318632251
Validation loss: 2.4534249456441803

Epoch: 5| Step: 8
Training loss: 2.318468073648333
Validation loss: 2.4524941898838377

Epoch: 5| Step: 9
Training loss: 2.4103129380793393
Validation loss: 2.4517502121453143

Epoch: 5| Step: 10
Training loss: 3.542442879980193
Validation loss: 2.4546797334809995

Epoch: 5| Step: 11
Training loss: 3.8088063342113263
Validation loss: 2.459053315319096

Epoch: 149| Step: 0
Training loss: 2.075854559807334
Validation loss: 2.4509073791053826

Epoch: 5| Step: 1
Training loss: 2.5192162131954663
Validation loss: 2.45940410737356

Epoch: 5| Step: 2
Training loss: 2.3850314455338535
Validation loss: 2.4561555289364794

Epoch: 5| Step: 3
Training loss: 2.567801782688497
Validation loss: 2.462314434450295

Epoch: 5| Step: 4
Training loss: 2.6540501180198506
Validation loss: 2.4613802960574716

Epoch: 5| Step: 5
Training loss: 2.2925171285507306
Validation loss: 2.4623564207106576

Epoch: 5| Step: 6
Training loss: 2.6072585608381775
Validation loss: 2.463699655661993

Epoch: 5| Step: 7
Training loss: 3.148193198444766
Validation loss: 2.4687364312293996

Epoch: 5| Step: 8
Training loss: 2.6017809710256947
Validation loss: 2.4667276960203335

Epoch: 5| Step: 9
Training loss: 2.5907687783463045
Validation loss: 2.463433677989436

Epoch: 5| Step: 10
Training loss: 2.22145957443268
Validation loss: 2.4645585561642456

Epoch: 5| Step: 11
Training loss: 3.048199018714236
Validation loss: 2.4682744046925067

Epoch: 150| Step: 0
Training loss: 2.5345952099428777
Validation loss: 2.46396660449828

Epoch: 5| Step: 1
Training loss: 2.2108527393066915
Validation loss: 2.457718430141831

Epoch: 5| Step: 2
Training loss: 2.3741271774241035
Validation loss: 2.4550743133345385

Epoch: 5| Step: 3
Training loss: 2.1087050892966253
Validation loss: 2.4564504133973624

Epoch: 5| Step: 4
Training loss: 2.636350343186399
Validation loss: 2.453645590194618

Epoch: 5| Step: 5
Training loss: 2.9056827442768394
Validation loss: 2.4558405454801764

Epoch: 5| Step: 6
Training loss: 3.1845095200805864
Validation loss: 2.4535843728862936

Epoch: 5| Step: 7
Training loss: 2.2327099978795606
Validation loss: 2.455204436685229

Epoch: 5| Step: 8
Training loss: 2.7712309320230015
Validation loss: 2.4508558416603052

Epoch: 5| Step: 9
Training loss: 2.431022645180294
Validation loss: 2.453421155704821

Epoch: 5| Step: 10
Training loss: 2.2767444168747857
Validation loss: 2.4490220854355145

Epoch: 5| Step: 11
Training loss: 1.3669847174531795
Validation loss: 2.4485611466260098

Epoch: 151| Step: 0
Training loss: 2.2350530062540757
Validation loss: 2.452570230882853

Epoch: 5| Step: 1
Training loss: 2.7774769768503202
Validation loss: 2.4613154973772344

Epoch: 5| Step: 2
Training loss: 2.752028930572986
Validation loss: 2.46469759016558

Epoch: 5| Step: 3
Training loss: 2.3228738435866454
Validation loss: 2.4598074644683225

Epoch: 5| Step: 4
Training loss: 2.6041243486144965
Validation loss: 2.463665307203919

Epoch: 5| Step: 5
Training loss: 2.5458642557100717
Validation loss: 2.4690532296904766

Epoch: 5| Step: 6
Training loss: 2.284119564861803
Validation loss: 2.4549771705169374

Epoch: 5| Step: 7
Training loss: 2.871202863838594
Validation loss: 2.4678608584873856

Epoch: 5| Step: 8
Training loss: 2.290676654477858
Validation loss: 2.456329350568911

Epoch: 5| Step: 9
Training loss: 2.294917096072152
Validation loss: 2.463139125419199

Epoch: 5| Step: 10
Training loss: 2.5861828275634786
Validation loss: 2.4545525165484636

Epoch: 5| Step: 11
Training loss: 3.144887280892828
Validation loss: 2.4585049308004345

Epoch: 152| Step: 0
Training loss: 2.5182786296942803
Validation loss: 2.4540372638448402

Epoch: 5| Step: 1
Training loss: 1.8974610631513726
Validation loss: 2.4554106113672693

Epoch: 5| Step: 2
Training loss: 2.444914471587189
Validation loss: 2.461262510928854

Epoch: 5| Step: 3
Training loss: 2.405851058586353
Validation loss: 2.4537218647427372

Epoch: 5| Step: 4
Training loss: 2.5615222275004292
Validation loss: 2.4553744395996815

Epoch: 5| Step: 5
Training loss: 2.9873726853571956
Validation loss: 2.4559606616284744

Epoch: 5| Step: 6
Training loss: 2.6506099286918077
Validation loss: 2.4516474410659743

Epoch: 5| Step: 7
Training loss: 2.8153670215016864
Validation loss: 2.4574401224162576

Epoch: 5| Step: 8
Training loss: 2.546141255471927
Validation loss: 2.456487315444813

Epoch: 5| Step: 9
Training loss: 2.443077748120558
Validation loss: 2.4647412125126142

Epoch: 5| Step: 10
Training loss: 2.5416946618044456
Validation loss: 2.4583959948641074

Epoch: 5| Step: 11
Training loss: 1.565996682520406
Validation loss: 2.4614637427822816

Epoch: 153| Step: 0
Training loss: 2.73383086103691
Validation loss: 2.467962596161502

Epoch: 5| Step: 1
Training loss: 2.917494647258957
Validation loss: 2.4679657539493594

Epoch: 5| Step: 2
Training loss: 2.7412982596529814
Validation loss: 2.465695298050526

Epoch: 5| Step: 3
Training loss: 2.937191723819394
Validation loss: 2.4744737442932476

Epoch: 5| Step: 4
Training loss: 2.4979289059077976
Validation loss: 2.4740070271300976

Epoch: 5| Step: 5
Training loss: 2.1869565016088455
Validation loss: 2.4735016746011533

Epoch: 5| Step: 6
Training loss: 2.4348198265139556
Validation loss: 2.462969366030495

Epoch: 5| Step: 7
Training loss: 2.2271030773671026
Validation loss: 2.461390583775726

Epoch: 5| Step: 8
Training loss: 2.2760281304161327
Validation loss: 2.459695763131221

Epoch: 5| Step: 9
Training loss: 2.5010924813286475
Validation loss: 2.4519853880795894

Epoch: 5| Step: 10
Training loss: 2.23409787039985
Validation loss: 2.4624570847659077

Epoch: 5| Step: 11
Training loss: 1.44455563084693
Validation loss: 2.450829247671555

Epoch: 154| Step: 0
Training loss: 1.7448925008152352
Validation loss: 2.456998383140989

Epoch: 5| Step: 1
Training loss: 2.070697791757068
Validation loss: 2.450885775259154

Epoch: 5| Step: 2
Training loss: 1.7541123165068133
Validation loss: 2.452908605600439

Epoch: 5| Step: 3
Training loss: 2.529993569588311
Validation loss: 2.4604884711847337

Epoch: 5| Step: 4
Training loss: 2.7321656811185573
Validation loss: 2.4643263115016807

Epoch: 5| Step: 5
Training loss: 2.678379373477145
Validation loss: 2.4672799663034897

Epoch: 5| Step: 6
Training loss: 3.080175655855174
Validation loss: 2.4552319219786183

Epoch: 5| Step: 7
Training loss: 3.0640239427193805
Validation loss: 2.4583113408047845

Epoch: 5| Step: 8
Training loss: 2.40591894076971
Validation loss: 2.4562431369326467

Epoch: 5| Step: 9
Training loss: 2.6251425931439187
Validation loss: 2.4540825167694993

Epoch: 5| Step: 10
Training loss: 2.785552051557033
Validation loss: 2.4618371398925105

Epoch: 5| Step: 11
Training loss: 2.6547612225476467
Validation loss: 2.4697564966558017

Epoch: 155| Step: 0
Training loss: 2.4683938071265183
Validation loss: 2.4780554257760725

Epoch: 5| Step: 1
Training loss: 2.5667760573851917
Validation loss: 2.4897088108337333

Epoch: 5| Step: 2
Training loss: 2.427524106409847
Validation loss: 2.4919428052528185

Epoch: 5| Step: 3
Training loss: 2.1761096316166375
Validation loss: 2.476643742493325

Epoch: 5| Step: 4
Training loss: 1.8880510069091225
Validation loss: 2.4836556374822027

Epoch: 5| Step: 5
Training loss: 3.009638244587088
Validation loss: 2.490431929587234

Epoch: 5| Step: 6
Training loss: 2.5486625529914697
Validation loss: 2.4782339526707164

Epoch: 5| Step: 7
Training loss: 2.571807797412605
Validation loss: 2.472733318138244

Epoch: 5| Step: 8
Training loss: 2.6253787176233656
Validation loss: 2.471077727013499

Epoch: 5| Step: 9
Training loss: 2.586497082050653
Validation loss: 2.4654632007612096

Epoch: 5| Step: 10
Training loss: 2.6107500302341147
Validation loss: 2.4553974139226225

Epoch: 5| Step: 11
Training loss: 4.225844006628661
Validation loss: 2.4543159655335938

Epoch: 156| Step: 0
Training loss: 2.684018297221186
Validation loss: 2.4581341110475767

Epoch: 5| Step: 1
Training loss: 2.533377612714116
Validation loss: 2.463968563929994

Epoch: 5| Step: 2
Training loss: 2.9022157622877702
Validation loss: 2.464227033986625

Epoch: 5| Step: 3
Training loss: 2.0803200737733802
Validation loss: 2.4627851019409377

Epoch: 5| Step: 4
Training loss: 2.086641228655867
Validation loss: 2.4685048251193416

Epoch: 5| Step: 5
Training loss: 2.1121766875659502
Validation loss: 2.4738018722582815

Epoch: 5| Step: 6
Training loss: 2.5294064059898713
Validation loss: 2.4680686928032056

Epoch: 5| Step: 7
Training loss: 3.2519787853248117
Validation loss: 2.4720218963635765

Epoch: 5| Step: 8
Training loss: 2.652268241515396
Validation loss: 2.4656018030020634

Epoch: 5| Step: 9
Training loss: 2.4903783659350998
Validation loss: 2.463372296619653

Epoch: 5| Step: 10
Training loss: 2.6862695228005693
Validation loss: 2.4546264783306952

Epoch: 5| Step: 11
Training loss: 2.1762348571986716
Validation loss: 2.4594113860615576

Epoch: 157| Step: 0
Training loss: 2.6392838723459975
Validation loss: 2.4634179144027546

Epoch: 5| Step: 1
Training loss: 2.9106208993572817
Validation loss: 2.467160139522033

Epoch: 5| Step: 2
Training loss: 2.9433238958234105
Validation loss: 2.469191403101458

Epoch: 5| Step: 3
Training loss: 1.9048997443142963
Validation loss: 2.467038265367045

Epoch: 5| Step: 4
Training loss: 2.6422977904993936
Validation loss: 2.4649882327141297

Epoch: 5| Step: 5
Training loss: 2.506244680346696
Validation loss: 2.469361116928175

Epoch: 5| Step: 6
Training loss: 2.848287964964193
Validation loss: 2.4724245369622304

Epoch: 5| Step: 7
Training loss: 1.673723286535913
Validation loss: 2.4708537381269378

Epoch: 5| Step: 8
Training loss: 2.2950234768067705
Validation loss: 2.4721502355805636

Epoch: 5| Step: 9
Training loss: 2.217395852792405
Validation loss: 2.46408124072766

Epoch: 5| Step: 10
Training loss: 3.1131113884319443
Validation loss: 2.465149346141856

Epoch: 5| Step: 11
Training loss: 1.7668415031051106
Validation loss: 2.458167593158838

Epoch: 158| Step: 0
Training loss: 2.5131508169339947
Validation loss: 2.456002420788192

Epoch: 5| Step: 1
Training loss: 2.674387860000904
Validation loss: 2.4512508060467613

Epoch: 5| Step: 2
Training loss: 2.2481023415385266
Validation loss: 2.45475811871908

Epoch: 5| Step: 3
Training loss: 2.281099706428131
Validation loss: 2.4502490106047485

Epoch: 5| Step: 4
Training loss: 2.1321235633957527
Validation loss: 2.4552323306344204

Epoch: 5| Step: 5
Training loss: 3.1935403475096216
Validation loss: 2.4575528762124605

Epoch: 5| Step: 6
Training loss: 2.5653755057385097
Validation loss: 2.4549992117974386

Epoch: 5| Step: 7
Training loss: 2.7657626705063922
Validation loss: 2.4497119664510056

Epoch: 5| Step: 8
Training loss: 2.4549198266512993
Validation loss: 2.45899254371068

Epoch: 5| Step: 9
Training loss: 2.643114891150179
Validation loss: 2.4628569570161623

Epoch: 5| Step: 10
Training loss: 2.2762788929747373
Validation loss: 2.454501743682037

Epoch: 5| Step: 11
Training loss: 2.0281542148454976
Validation loss: 2.4550730488476087

Epoch: 159| Step: 0
Training loss: 2.848149009739
Validation loss: 2.4534359915024204

Epoch: 5| Step: 1
Training loss: 2.0527297291217645
Validation loss: 2.4594773052737873

Epoch: 5| Step: 2
Training loss: 2.647602411005836
Validation loss: 2.460995619960495

Epoch: 5| Step: 3
Training loss: 2.428698961131006
Validation loss: 2.4556895900434994

Epoch: 5| Step: 4
Training loss: 2.051828229767944
Validation loss: 2.458869291061195

Epoch: 5| Step: 5
Training loss: 2.6281341734010533
Validation loss: 2.456496078841366

Epoch: 5| Step: 6
Training loss: 2.7503250970282154
Validation loss: 2.456346296084252

Epoch: 5| Step: 7
Training loss: 2.6231939369724913
Validation loss: 2.4550025986996302

Epoch: 5| Step: 8
Training loss: 2.6961889638699366
Validation loss: 2.4575504144650315

Epoch: 5| Step: 9
Training loss: 2.6306273677395646
Validation loss: 2.452411215701693

Epoch: 5| Step: 10
Training loss: 2.422820072976544
Validation loss: 2.4540502338174925

Epoch: 5| Step: 11
Training loss: 1.3156411865398447
Validation loss: 2.456962713873649

Epoch: 160| Step: 0
Training loss: 2.4027141998738917
Validation loss: 2.451659479567234

Epoch: 5| Step: 1
Training loss: 3.33613860978069
Validation loss: 2.448730525545758

Epoch: 5| Step: 2
Training loss: 2.200497622997662
Validation loss: 2.451619457704043

Epoch: 5| Step: 3
Training loss: 2.5438422184004845
Validation loss: 2.4555201814034855

Epoch: 5| Step: 4
Training loss: 2.216481190524846
Validation loss: 2.4488890211474934

Epoch: 5| Step: 5
Training loss: 2.6910240666033767
Validation loss: 2.454604664389707

Epoch: 5| Step: 6
Training loss: 2.4626662222437243
Validation loss: 2.4534938458020275

Epoch: 5| Step: 7
Training loss: 2.8453936176164385
Validation loss: 2.457288941827492

Epoch: 5| Step: 8
Training loss: 2.016518564802314
Validation loss: 2.452187946365398

Epoch: 5| Step: 9
Training loss: 2.196790096112825
Validation loss: 2.4461114733937315

Epoch: 5| Step: 10
Training loss: 2.561038740390128
Validation loss: 2.450076936954025

Epoch: 5| Step: 11
Training loss: 2.971550834938555
Validation loss: 2.45870183887514

Epoch: 161| Step: 0
Training loss: 2.186011979945408
Validation loss: 2.4572147448440793

Epoch: 5| Step: 1
Training loss: 2.153499673652491
Validation loss: 2.4550853315402903

Epoch: 5| Step: 2
Training loss: 2.542040958881918
Validation loss: 2.4549251277069932

Epoch: 5| Step: 3
Training loss: 2.757467102380231
Validation loss: 2.4629542690184474

Epoch: 5| Step: 4
Training loss: 3.0644044209701224
Validation loss: 2.460917699825015

Epoch: 5| Step: 5
Training loss: 2.110356759378724
Validation loss: 2.4610741148474533

Epoch: 5| Step: 6
Training loss: 2.2127158625413896
Validation loss: 2.472289204285374

Epoch: 5| Step: 7
Training loss: 2.1927145794004033
Validation loss: 2.471595697421568

Epoch: 5| Step: 8
Training loss: 2.690593978933398
Validation loss: 2.4647828551527127

Epoch: 5| Step: 9
Training loss: 2.6597760302681435
Validation loss: 2.4644250287389107

Epoch: 5| Step: 10
Training loss: 2.9095515704634836
Validation loss: 2.4602162086220143

Epoch: 5| Step: 11
Training loss: 2.884812568380743
Validation loss: 2.4707751357851397

Epoch: 162| Step: 0
Training loss: 2.603320012109387
Validation loss: 2.45826695374133

Epoch: 5| Step: 1
Training loss: 2.5178713039629947
Validation loss: 2.468839468723058

Epoch: 5| Step: 2
Training loss: 2.0267751848296616
Validation loss: 2.4706141459609956

Epoch: 5| Step: 3
Training loss: 2.9217286098751853
Validation loss: 2.4936012037242192

Epoch: 5| Step: 4
Training loss: 2.5820667073964825
Validation loss: 2.4883940674634175

Epoch: 5| Step: 5
Training loss: 2.67428649584732
Validation loss: 2.4740209042851444

Epoch: 5| Step: 6
Training loss: 2.209622156975966
Validation loss: 2.4664766975228485

Epoch: 5| Step: 7
Training loss: 2.9270872249554776
Validation loss: 2.45617783467129

Epoch: 5| Step: 8
Training loss: 2.9403560633011265
Validation loss: 2.4699854958258967

Epoch: 5| Step: 9
Training loss: 2.029690305077991
Validation loss: 2.4736568601864795

Epoch: 5| Step: 10
Training loss: 2.705529879640302
Validation loss: 2.468324447523973

Epoch: 5| Step: 11
Training loss: 2.217909855344515
Validation loss: 2.473863526920277

Epoch: 163| Step: 0
Training loss: 1.8079999109453837
Validation loss: 2.4879620964703837

Epoch: 5| Step: 1
Training loss: 2.7004086291191545
Validation loss: 2.482178550818384

Epoch: 5| Step: 2
Training loss: 2.7422041933252572
Validation loss: 2.484009018018061

Epoch: 5| Step: 3
Training loss: 2.518684564313141
Validation loss: 2.4784707139728126

Epoch: 5| Step: 4
Training loss: 1.978285991752503
Validation loss: 2.4819350306714214

Epoch: 5| Step: 5
Training loss: 2.6184640077277415
Validation loss: 2.4919941826186593

Epoch: 5| Step: 6
Training loss: 3.006795181042797
Validation loss: 2.4806820434818877

Epoch: 5| Step: 7
Training loss: 2.649137421340848
Validation loss: 2.4819302355933512

Epoch: 5| Step: 8
Training loss: 2.365212097819068
Validation loss: 2.489786923169674

Epoch: 5| Step: 9
Training loss: 2.6100890501769314
Validation loss: 2.479194401871722

Epoch: 5| Step: 10
Training loss: 2.9406315770009805
Validation loss: 2.4745656656701973

Epoch: 5| Step: 11
Training loss: 2.690990222064016
Validation loss: 2.47341345291192

Epoch: 164| Step: 0
Training loss: 2.786049291707301
Validation loss: 2.4682363386198225

Epoch: 5| Step: 1
Training loss: 2.346076116200276
Validation loss: 2.4708468911783754

Epoch: 5| Step: 2
Training loss: 2.5775170736552124
Validation loss: 2.464091392191277

Epoch: 5| Step: 3
Training loss: 2.1952389742121805
Validation loss: 2.46679617025245

Epoch: 5| Step: 4
Training loss: 2.5153559191360695
Validation loss: 2.46139428879672

Epoch: 5| Step: 5
Training loss: 2.612475078409139
Validation loss: 2.4549462023251194

Epoch: 5| Step: 6
Training loss: 2.617462052705077
Validation loss: 2.4600149776938367

Epoch: 5| Step: 7
Training loss: 2.250864710480231
Validation loss: 2.469093367282223

Epoch: 5| Step: 8
Training loss: 2.5717800785685334
Validation loss: 2.4654903299341493

Epoch: 5| Step: 9
Training loss: 3.0082214870073276
Validation loss: 2.4602346920406393

Epoch: 5| Step: 10
Training loss: 2.4309039735082028
Validation loss: 2.4689405061960548

Epoch: 5| Step: 11
Training loss: 1.3541925672352781
Validation loss: 2.4588207769170496

Epoch: 165| Step: 0
Training loss: 2.6154476019019532
Validation loss: 2.4616379079212822

Epoch: 5| Step: 1
Training loss: 2.730487435949563
Validation loss: 2.4677471828233997

Epoch: 5| Step: 2
Training loss: 2.356523622364875
Validation loss: 2.4600394876116307

Epoch: 5| Step: 3
Training loss: 2.4799516754672033
Validation loss: 2.4591995601615086

Epoch: 5| Step: 4
Training loss: 2.780777451736112
Validation loss: 2.4644054823223813

Epoch: 5| Step: 5
Training loss: 2.807497704658691
Validation loss: 2.466745415818068

Epoch: 5| Step: 6
Training loss: 2.0809350769239674
Validation loss: 2.470100516308789

Epoch: 5| Step: 7
Training loss: 2.3982101481783116
Validation loss: 2.476272915055814

Epoch: 5| Step: 8
Training loss: 2.0736794785459085
Validation loss: 2.478401688486287

Epoch: 5| Step: 9
Training loss: 2.897770149335331
Validation loss: 2.4660435178345375

Epoch: 5| Step: 10
Training loss: 2.611877794412586
Validation loss: 2.472878609332038

Epoch: 5| Step: 11
Training loss: 1.692225022397501
Validation loss: 2.468127413603858

Epoch: 166| Step: 0
Training loss: 2.6703580599090713
Validation loss: 2.475479193899788

Epoch: 5| Step: 1
Training loss: 2.841233198231176
Validation loss: 2.4627724502450734

Epoch: 5| Step: 2
Training loss: 2.390188339346167
Validation loss: 2.4622681063178904

Epoch: 5| Step: 3
Training loss: 2.299554624143855
Validation loss: 2.4607208156558373

Epoch: 5| Step: 4
Training loss: 2.716439767344941
Validation loss: 2.4630130673858335

Epoch: 5| Step: 5
Training loss: 2.042339979461138
Validation loss: 2.455051236851349

Epoch: 5| Step: 6
Training loss: 2.095246420777694
Validation loss: 2.4661603938595675

Epoch: 5| Step: 7
Training loss: 2.7988535100580307
Validation loss: 2.465915098477309

Epoch: 5| Step: 8
Training loss: 3.2054179102719487
Validation loss: 2.470979167007503

Epoch: 5| Step: 9
Training loss: 2.001626545389892
Validation loss: 2.4684617019067647

Epoch: 5| Step: 10
Training loss: 2.4474208140202736
Validation loss: 2.4704220256295844

Epoch: 5| Step: 11
Training loss: 2.3799022474970695
Validation loss: 2.4703520916237864

Epoch: 167| Step: 0
Training loss: 2.614159406563338
Validation loss: 2.4751570451085505

Epoch: 5| Step: 1
Training loss: 2.5794371069235664
Validation loss: 2.4781025551592895

Epoch: 5| Step: 2
Training loss: 2.6290702145190217
Validation loss: 2.4687270553745906

Epoch: 5| Step: 3
Training loss: 2.007733057728893
Validation loss: 2.4742082342452942

Epoch: 5| Step: 4
Training loss: 2.6682063565212166
Validation loss: 2.470714956061743

Epoch: 5| Step: 5
Training loss: 2.600794590061819
Validation loss: 2.4741025193343247

Epoch: 5| Step: 6
Training loss: 2.0385348634861358
Validation loss: 2.4795532940204317

Epoch: 5| Step: 7
Training loss: 2.300301208675674
Validation loss: 2.479502143654573

Epoch: 5| Step: 8
Training loss: 3.3367208592920194
Validation loss: 2.4747176273376463

Epoch: 5| Step: 9
Training loss: 2.367580972835639
Validation loss: 2.4709784071683982

Epoch: 5| Step: 10
Training loss: 2.427404576163478
Validation loss: 2.467771199301724

Epoch: 5| Step: 11
Training loss: 1.6801234899275261
Validation loss: 2.4617335732402243

Epoch: 168| Step: 0
Training loss: 3.2217480668705734
Validation loss: 2.4592720734039735

Epoch: 5| Step: 1
Training loss: 2.8435868436518934
Validation loss: 2.4622918212018696

Epoch: 5| Step: 2
Training loss: 1.9581992800127135
Validation loss: 2.463621571046778

Epoch: 5| Step: 3
Training loss: 2.1087873982639076
Validation loss: 2.458458292473839

Epoch: 5| Step: 4
Training loss: 2.6393247935898967
Validation loss: 2.460216452914963

Epoch: 5| Step: 5
Training loss: 2.304164296908364
Validation loss: 2.457831441972401

Epoch: 5| Step: 6
Training loss: 2.1615091953651153
Validation loss: 2.4595712593129497

Epoch: 5| Step: 7
Training loss: 2.9620924335303638
Validation loss: 2.4621146278137696

Epoch: 5| Step: 8
Training loss: 1.893842308388198
Validation loss: 2.4616128670937387

Epoch: 5| Step: 9
Training loss: 2.3416799940859017
Validation loss: 2.464397400081749

Epoch: 5| Step: 10
Training loss: 2.9363181800770297
Validation loss: 2.462685673550838

Epoch: 5| Step: 11
Training loss: 2.141838787697751
Validation loss: 2.4602093946560304

Epoch: 169| Step: 0
Training loss: 2.3362640867017794
Validation loss: 2.466430558334684

Epoch: 5| Step: 1
Training loss: 2.581984157392504
Validation loss: 2.4655629724356434

Epoch: 5| Step: 2
Training loss: 2.247387959336462
Validation loss: 2.473184899681336

Epoch: 5| Step: 3
Training loss: 2.78012799551527
Validation loss: 2.4748778083449188

Epoch: 5| Step: 4
Training loss: 2.8773863466886667
Validation loss: 2.4788159448248925

Epoch: 5| Step: 5
Training loss: 2.7863474220710405
Validation loss: 2.479583594315193

Epoch: 5| Step: 6
Training loss: 2.5899733659118604
Validation loss: 2.482060383853944

Epoch: 5| Step: 7
Training loss: 2.3819176166038147
Validation loss: 2.4797004491046875

Epoch: 5| Step: 8
Training loss: 2.462347395762469
Validation loss: 2.4748569716923994

Epoch: 5| Step: 9
Training loss: 2.1426415516620345
Validation loss: 2.4733108529854073

Epoch: 5| Step: 10
Training loss: 2.3771340670396914
Validation loss: 2.4653367619032442

Epoch: 5| Step: 11
Training loss: 2.6022436035089362
Validation loss: 2.4675942786028537

Epoch: 170| Step: 0
Training loss: 2.7482650659370806
Validation loss: 2.4585261100949447

Epoch: 5| Step: 1
Training loss: 2.4480458543384858
Validation loss: 2.464163890487024

Epoch: 5| Step: 2
Training loss: 2.4289048090280483
Validation loss: 2.4564544170435663

Epoch: 5| Step: 3
Training loss: 2.309760662081912
Validation loss: 2.461459513204009

Epoch: 5| Step: 4
Training loss: 2.333422273121543
Validation loss: 2.4731265801408715

Epoch: 5| Step: 5
Training loss: 2.4534528962661537
Validation loss: 2.4720291097692932

Epoch: 5| Step: 6
Training loss: 2.500326993538141
Validation loss: 2.47931326237723

Epoch: 5| Step: 7
Training loss: 2.844005195988497
Validation loss: 2.4777996891976874

Epoch: 5| Step: 8
Training loss: 2.6070375309252047
Validation loss: 2.47633873443059

Epoch: 5| Step: 9
Training loss: 2.430429425070101
Validation loss: 2.4759734723836493

Epoch: 5| Step: 10
Training loss: 2.675505909362324
Validation loss: 2.467430542789915

Epoch: 5| Step: 11
Training loss: 2.160485461570381
Validation loss: 2.4639415752416958

Epoch: 171| Step: 0
Training loss: 2.3467264222354234
Validation loss: 2.4646512866762627

Epoch: 5| Step: 1
Training loss: 2.6421708316829906
Validation loss: 2.458355840213571

Epoch: 5| Step: 2
Training loss: 2.1637176349055056
Validation loss: 2.463275839971765

Epoch: 5| Step: 3
Training loss: 2.523442224078879
Validation loss: 2.4536690240351247

Epoch: 5| Step: 4
Training loss: 2.541220349590594
Validation loss: 2.4777832752918996

Epoch: 5| Step: 5
Training loss: 3.1304106601992747
Validation loss: 2.4772837016947213

Epoch: 5| Step: 6
Training loss: 1.8502692361756141
Validation loss: 2.4796099159684593

Epoch: 5| Step: 7
Training loss: 2.7796760991995417
Validation loss: 2.465956117018858

Epoch: 5| Step: 8
Training loss: 2.1347385973672175
Validation loss: 2.457941077883315

Epoch: 5| Step: 9
Training loss: 2.265489245326695
Validation loss: 2.452549686719246

Epoch: 5| Step: 10
Training loss: 3.0530408240499223
Validation loss: 2.45644778069312

Epoch: 5| Step: 11
Training loss: 2.8892700318832563
Validation loss: 2.467592869563031

Epoch: 172| Step: 0
Training loss: 2.8701334690334384
Validation loss: 2.4598955986469218

Epoch: 5| Step: 1
Training loss: 2.6309766396355756
Validation loss: 2.4744455774578538

Epoch: 5| Step: 2
Training loss: 2.2972990929031027
Validation loss: 2.462097173264445

Epoch: 5| Step: 3
Training loss: 2.6241800753397353
Validation loss: 2.468761252928893

Epoch: 5| Step: 4
Training loss: 1.725549737435089
Validation loss: 2.475157679245597

Epoch: 5| Step: 5
Training loss: 2.4067170321547504
Validation loss: 2.4753611204854975

Epoch: 5| Step: 6
Training loss: 2.399442679545464
Validation loss: 2.4744331841092935

Epoch: 5| Step: 7
Training loss: 2.651070425380961
Validation loss: 2.4745758263116047

Epoch: 5| Step: 8
Training loss: 2.7354903208066834
Validation loss: 2.4720502274460756

Epoch: 5| Step: 9
Training loss: 3.131474311393124
Validation loss: 2.465211819645445

Epoch: 5| Step: 10
Training loss: 2.2672170372898237
Validation loss: 2.458472055357437

Epoch: 5| Step: 11
Training loss: 2.117478241611642
Validation loss: 2.4612473106143558

Epoch: 173| Step: 0
Training loss: 2.832724019524065
Validation loss: 2.4632293524710938

Epoch: 5| Step: 1
Training loss: 2.341419943666684
Validation loss: 2.4555331435434598

Epoch: 5| Step: 2
Training loss: 2.4106675259530945
Validation loss: 2.4566517523175246

Epoch: 5| Step: 3
Training loss: 2.336947015640781
Validation loss: 2.461745505922498

Epoch: 5| Step: 4
Training loss: 2.7452821142591772
Validation loss: 2.457317830865908

Epoch: 5| Step: 5
Training loss: 2.566845721237356
Validation loss: 2.4552290249711803

Epoch: 5| Step: 6
Training loss: 2.0657086700253076
Validation loss: 2.458680299476577

Epoch: 5| Step: 7
Training loss: 2.712772770540087
Validation loss: 2.453601896091952

Epoch: 5| Step: 8
Training loss: 2.588714951996772
Validation loss: 2.4530714134470286

Epoch: 5| Step: 9
Training loss: 2.1244270449865335
Validation loss: 2.4573197309167045

Epoch: 5| Step: 10
Training loss: 2.715382386707714
Validation loss: 2.452771738457028

Epoch: 5| Step: 11
Training loss: 2.8845356905761315
Validation loss: 2.44273821494581

Epoch: 174| Step: 0
Training loss: 2.6006691805115087
Validation loss: 2.4538612678175595

Epoch: 5| Step: 1
Training loss: 2.588675256936734
Validation loss: 2.4537709149133096

Epoch: 5| Step: 2
Training loss: 2.9631403878743163
Validation loss: 2.461738698207232

Epoch: 5| Step: 3
Training loss: 2.6860265019146845
Validation loss: 2.4611838323437505

Epoch: 5| Step: 4
Training loss: 2.584362460824421
Validation loss: 2.4708608142253032

Epoch: 5| Step: 5
Training loss: 2.7682008116816896
Validation loss: 2.465028706506604

Epoch: 5| Step: 6
Training loss: 2.75217473130758
Validation loss: 2.476276954852072

Epoch: 5| Step: 7
Training loss: 1.9151275785493669
Validation loss: 2.465925774160266

Epoch: 5| Step: 8
Training loss: 2.6575380680375678
Validation loss: 2.469307743921229

Epoch: 5| Step: 9
Training loss: 1.8127749661993966
Validation loss: 2.47213421815571

Epoch: 5| Step: 10
Training loss: 2.15238794741798
Validation loss: 2.4680227785957882

Epoch: 5| Step: 11
Training loss: 0.9555013456110559
Validation loss: 2.465566763856929

Epoch: 175| Step: 0
Training loss: 2.7826114708300933
Validation loss: 2.458113762915279

Epoch: 5| Step: 1
Training loss: 2.7621319797536614
Validation loss: 2.46555830668285

Epoch: 5| Step: 2
Training loss: 2.8337696711829645
Validation loss: 2.4672963373466987

Epoch: 5| Step: 3
Training loss: 2.46657930382679
Validation loss: 2.4563950410879185

Epoch: 5| Step: 4
Training loss: 1.969009927212172
Validation loss: 2.45643898072728

Epoch: 5| Step: 5
Training loss: 2.2605226084644467
Validation loss: 2.4677624477659554

Epoch: 5| Step: 6
Training loss: 2.8511840569188482
Validation loss: 2.461079035327019

Epoch: 5| Step: 7
Training loss: 2.487553512534387
Validation loss: 2.456520702726457

Epoch: 5| Step: 8
Training loss: 2.3353016475924053
Validation loss: 2.4544408269981415

Epoch: 5| Step: 9
Training loss: 2.2036527177496814
Validation loss: 2.4560366236159563

Epoch: 5| Step: 10
Training loss: 2.600056346869616
Validation loss: 2.4519366283387485

Epoch: 5| Step: 11
Training loss: 1.3959063420726416
Validation loss: 2.4585138849992947

Epoch: 176| Step: 0
Training loss: 2.1160135427953803
Validation loss: 2.4574803486229446

Epoch: 5| Step: 1
Training loss: 2.4484953717060836
Validation loss: 2.460360428094442

Epoch: 5| Step: 2
Training loss: 3.0572010830528042
Validation loss: 2.459400702297361

Epoch: 5| Step: 3
Training loss: 1.8958203521395876
Validation loss: 2.453271775400378

Epoch: 5| Step: 4
Training loss: 2.4447232349918933
Validation loss: 2.4595288680535026

Epoch: 5| Step: 5
Training loss: 2.748329869212814
Validation loss: 2.4551499669082357

Epoch: 5| Step: 6
Training loss: 2.1337611286072016
Validation loss: 2.4563449372119157

Epoch: 5| Step: 7
Training loss: 2.5151423589561346
Validation loss: 2.4515719387439234

Epoch: 5| Step: 8
Training loss: 2.740261085907547
Validation loss: 2.4474975118861475

Epoch: 5| Step: 9
Training loss: 2.9553262892533794
Validation loss: 2.4540075549007048

Epoch: 5| Step: 10
Training loss: 2.3970165703256052
Validation loss: 2.4569136667746827

Epoch: 5| Step: 11
Training loss: 2.1624974950875124
Validation loss: 2.4510521240162606

Epoch: 177| Step: 0
Training loss: 2.597931123115638
Validation loss: 2.4616243685530077

Epoch: 5| Step: 1
Training loss: 2.219764477548218
Validation loss: 2.4621322960815277

Epoch: 5| Step: 2
Training loss: 2.5736505694680356
Validation loss: 2.467075037230107

Epoch: 5| Step: 3
Training loss: 2.1476740919962993
Validation loss: 2.4642163307875165

Epoch: 5| Step: 4
Training loss: 2.406576258351678
Validation loss: 2.464265661868852

Epoch: 5| Step: 5
Training loss: 2.8182043930447205
Validation loss: 2.460270257341124

Epoch: 5| Step: 6
Training loss: 2.1305785164500044
Validation loss: 2.4613325578990404

Epoch: 5| Step: 7
Training loss: 2.733447631524092
Validation loss: 2.4598705521985362

Epoch: 5| Step: 8
Training loss: 2.5517813575262775
Validation loss: 2.4675555699734573

Epoch: 5| Step: 9
Training loss: 2.7414239325704566
Validation loss: 2.460381722639514

Epoch: 5| Step: 10
Training loss: 2.8329520997516537
Validation loss: 2.453199304479899

Epoch: 5| Step: 11
Training loss: 1.9979814237164446
Validation loss: 2.4528678872690706

Epoch: 178| Step: 0
Training loss: 2.1535724103067273
Validation loss: 2.454022302143301

Epoch: 5| Step: 1
Training loss: 2.6645910907679164
Validation loss: 2.448679753669274

Epoch: 5| Step: 2
Training loss: 2.8350515952284576
Validation loss: 2.4416818041109805

Epoch: 5| Step: 3
Training loss: 2.1635568627117836
Validation loss: 2.447344166519541

Epoch: 5| Step: 4
Training loss: 2.755833247849661
Validation loss: 2.4491756299536163

Epoch: 5| Step: 5
Training loss: 2.5211246626891213
Validation loss: 2.437880851058955

Epoch: 5| Step: 6
Training loss: 2.4051574604728
Validation loss: 2.4500633782992858

Epoch: 5| Step: 7
Training loss: 2.6141954314092652
Validation loss: 2.4483061433281654

Epoch: 5| Step: 8
Training loss: 2.516221633197888
Validation loss: 2.4509897435421286

Epoch: 5| Step: 9
Training loss: 2.248829537173052
Validation loss: 2.4490037262956883

Epoch: 5| Step: 10
Training loss: 2.509959600055087
Validation loss: 2.45249815948241

Epoch: 5| Step: 11
Training loss: 3.194825375460684
Validation loss: 2.447623638443558

Epoch: 179| Step: 0
Training loss: 2.2912725514302625
Validation loss: 2.4501164650320857

Epoch: 5| Step: 1
Training loss: 2.735065482016467
Validation loss: 2.443678717374412

Epoch: 5| Step: 2
Training loss: 2.463294556518581
Validation loss: 2.4487644567187834

Epoch: 5| Step: 3
Training loss: 2.928748221826278
Validation loss: 2.450959600449243

Epoch: 5| Step: 4
Training loss: 3.0010680840461728
Validation loss: 2.449307940500289

Epoch: 5| Step: 5
Training loss: 2.5731710290208625
Validation loss: 2.451306286453658

Epoch: 5| Step: 6
Training loss: 2.06344236173148
Validation loss: 2.4536975467819233

Epoch: 5| Step: 7
Training loss: 2.292192317902976
Validation loss: 2.4534391214231506

Epoch: 5| Step: 8
Training loss: 2.6559768536317456
Validation loss: 2.44878592918018

Epoch: 5| Step: 9
Training loss: 2.1603535843127464
Validation loss: 2.450065831350933

Epoch: 5| Step: 10
Training loss: 2.24354995643354
Validation loss: 2.4479179598757526

Epoch: 5| Step: 11
Training loss: 2.1722336068252073
Validation loss: 2.458585846723281

Epoch: 180| Step: 0
Training loss: 2.5900519792208647
Validation loss: 2.460284264469237

Epoch: 5| Step: 1
Training loss: 2.659270779173368
Validation loss: 2.466884648726461

Epoch: 5| Step: 2
Training loss: 2.8552048922637128
Validation loss: 2.4727427551340293

Epoch: 5| Step: 3
Training loss: 2.6193044726434835
Validation loss: 2.4785537175707506

Epoch: 5| Step: 4
Training loss: 2.7914119623244797
Validation loss: 2.48946754167669

Epoch: 5| Step: 5
Training loss: 2.8020242356280787
Validation loss: 2.4931430798335077

Epoch: 5| Step: 6
Training loss: 2.6410960843779434
Validation loss: 2.4929760529448917

Epoch: 5| Step: 7
Training loss: 1.8632414551649932
Validation loss: 2.493073448469959

Epoch: 5| Step: 8
Training loss: 2.3674483454546578
Validation loss: 2.4873191494590547

Epoch: 5| Step: 9
Training loss: 2.4734207586515913
Validation loss: 2.4901449788322334

Epoch: 5| Step: 10
Training loss: 2.3990289909325226
Validation loss: 2.4800917371451523

Epoch: 5| Step: 11
Training loss: 3.033462031921429
Validation loss: 2.48650809548397

Epoch: 181| Step: 0
Training loss: 2.055602823464317
Validation loss: 2.4730636960043366

Epoch: 5| Step: 1
Training loss: 2.9100974262616144
Validation loss: 2.47130308644466

Epoch: 5| Step: 2
Training loss: 2.63794414161502
Validation loss: 2.4617632373699134

Epoch: 5| Step: 3
Training loss: 2.4743551049874375
Validation loss: 2.449207036154122

Epoch: 5| Step: 4
Training loss: 2.3901600105000202
Validation loss: 2.4499470602855387

Epoch: 5| Step: 5
Training loss: 2.8366802493471366
Validation loss: 2.447989754228276

Epoch: 5| Step: 6
Training loss: 2.275307427059974
Validation loss: 2.4347353034046764

Epoch: 5| Step: 7
Training loss: 2.12003115739059
Validation loss: 2.4377787096491614

Epoch: 5| Step: 8
Training loss: 2.5404644191617516
Validation loss: 2.4447883434189093

Epoch: 5| Step: 9
Training loss: 2.7287094276756614
Validation loss: 2.4387689490782165

Epoch: 5| Step: 10
Training loss: 2.9781808533689715
Validation loss: 2.4397221852853335

Epoch: 5| Step: 11
Training loss: 1.0994116163201157
Validation loss: 2.438066775296494

Epoch: 182| Step: 0
Training loss: 2.5395167487294974
Validation loss: 2.4357091996939952

Epoch: 5| Step: 1
Training loss: 2.948246716106989
Validation loss: 2.441266947523215

Epoch: 5| Step: 2
Training loss: 2.8326992746608424
Validation loss: 2.440967355569251

Epoch: 5| Step: 3
Training loss: 2.0223421055444377
Validation loss: 2.4389484800821437

Epoch: 5| Step: 4
Training loss: 2.0301338063381347
Validation loss: 2.449020260074261

Epoch: 5| Step: 5
Training loss: 2.126161706561265
Validation loss: 2.445235101858225

Epoch: 5| Step: 6
Training loss: 2.6664851742812794
Validation loss: 2.445702250562291

Epoch: 5| Step: 7
Training loss: 2.9827329901783437
Validation loss: 2.44816044479628

Epoch: 5| Step: 8
Training loss: 2.9093239227629906
Validation loss: 2.4642455377127144

Epoch: 5| Step: 9
Training loss: 2.403828579178168
Validation loss: 2.4614706037239467

Epoch: 5| Step: 10
Training loss: 1.9916801853865007
Validation loss: 2.458742634326353

Epoch: 5| Step: 11
Training loss: 1.950815773545009
Validation loss: 2.4517690875842737

Epoch: 183| Step: 0
Training loss: 2.8740902995641644
Validation loss: 2.4531238377724263

Epoch: 5| Step: 1
Training loss: 2.704008454179809
Validation loss: 2.454128185795213

Epoch: 5| Step: 2
Training loss: 1.815238002693848
Validation loss: 2.4590384467545046

Epoch: 5| Step: 3
Training loss: 2.6454084060146625
Validation loss: 2.4482121972325586

Epoch: 5| Step: 4
Training loss: 2.7176296512730116
Validation loss: 2.4480141775851996

Epoch: 5| Step: 5
Training loss: 2.432924230578721
Validation loss: 2.449493376582303

Epoch: 5| Step: 6
Training loss: 2.0969398454397936
Validation loss: 2.4471726761418764

Epoch: 5| Step: 7
Training loss: 2.9750804665846955
Validation loss: 2.439773257578099

Epoch: 5| Step: 8
Training loss: 2.404446210647063
Validation loss: 2.443069583124117

Epoch: 5| Step: 9
Training loss: 2.5648069464477024
Validation loss: 2.4449627578436925

Epoch: 5| Step: 10
Training loss: 2.277444775076166
Validation loss: 2.452087166609532

Epoch: 5| Step: 11
Training loss: 1.6645131105483604
Validation loss: 2.449501609388504

Epoch: 184| Step: 0
Training loss: 2.4126598641196986
Validation loss: 2.4416447678084108

Epoch: 5| Step: 1
Training loss: 2.1527399435786374
Validation loss: 2.4412876395341474

Epoch: 5| Step: 2
Training loss: 2.444315454181555
Validation loss: 2.4450090522702554

Epoch: 5| Step: 3
Training loss: 2.2006683721496265
Validation loss: 2.4426040274684695

Epoch: 5| Step: 4
Training loss: 2.8137943256535434
Validation loss: 2.4463163251239664

Epoch: 5| Step: 5
Training loss: 1.9195829540550675
Validation loss: 2.4445155168325514

Epoch: 5| Step: 6
Training loss: 2.970431203140846
Validation loss: 2.456556669573741

Epoch: 5| Step: 7
Training loss: 2.911740602698383
Validation loss: 2.45401638382601

Epoch: 5| Step: 8
Training loss: 2.292939739921096
Validation loss: 2.446569367553126

Epoch: 5| Step: 9
Training loss: 2.189248830092979
Validation loss: 2.457730133736237

Epoch: 5| Step: 10
Training loss: 3.1866426997966046
Validation loss: 2.449589990672875

Epoch: 5| Step: 11
Training loss: 1.2538061369387488
Validation loss: 2.4528335997552455

Epoch: 185| Step: 0
Training loss: 1.8631860480788973
Validation loss: 2.4523555780040254

Epoch: 5| Step: 1
Training loss: 2.9084520098966857
Validation loss: 2.4544402684566724

Epoch: 5| Step: 2
Training loss: 2.3844104849198478
Validation loss: 2.4541262468421534

Epoch: 5| Step: 3
Training loss: 2.946631179382994
Validation loss: 2.452554223300147

Epoch: 5| Step: 4
Training loss: 1.8436147995856127
Validation loss: 2.4485536003703734

Epoch: 5| Step: 5
Training loss: 2.7618370192696564
Validation loss: 2.453772319744658

Epoch: 5| Step: 6
Training loss: 2.78226015412768
Validation loss: 2.4481331560435486

Epoch: 5| Step: 7
Training loss: 2.7700141518021315
Validation loss: 2.454289987851824

Epoch: 5| Step: 8
Training loss: 2.7437064373755167
Validation loss: 2.4530406216568896

Epoch: 5| Step: 9
Training loss: 1.9900246641652977
Validation loss: 2.4489780897941573

Epoch: 5| Step: 10
Training loss: 2.2971507834607516
Validation loss: 2.45478410763421

Epoch: 5| Step: 11
Training loss: 2.227950242560456
Validation loss: 2.4502717613476266

Epoch: 186| Step: 0
Training loss: 2.779252009723304
Validation loss: 2.4519730068030934

Epoch: 5| Step: 1
Training loss: 3.1186756989031736
Validation loss: 2.449057103713665

Epoch: 5| Step: 2
Training loss: 2.117456397966683
Validation loss: 2.451512379698228

Epoch: 5| Step: 3
Training loss: 3.154589225519338
Validation loss: 2.45489950448288

Epoch: 5| Step: 4
Training loss: 2.2886332347008542
Validation loss: 2.4573194034612467

Epoch: 5| Step: 5
Training loss: 2.2355527108193094
Validation loss: 2.4447773885181316

Epoch: 5| Step: 6
Training loss: 2.314685510485425
Validation loss: 2.464529683476927

Epoch: 5| Step: 7
Training loss: 2.3446570103699296
Validation loss: 2.4563284608250187

Epoch: 5| Step: 8
Training loss: 2.146476377657986
Validation loss: 2.452301498653501

Epoch: 5| Step: 9
Training loss: 2.313159126992683
Validation loss: 2.4473790829746855

Epoch: 5| Step: 10
Training loss: 2.4062648624109797
Validation loss: 2.453524293819945

Epoch: 5| Step: 11
Training loss: 2.9271276251178437
Validation loss: 2.466664721245471

Epoch: 187| Step: 0
Training loss: 2.199695596442948
Validation loss: 2.4601095148910788

Epoch: 5| Step: 1
Training loss: 2.50285729204216
Validation loss: 2.4626423637270194

Epoch: 5| Step: 2
Training loss: 2.8754156061058223
Validation loss: 2.4670853696545305

Epoch: 5| Step: 3
Training loss: 2.2781229403765124
Validation loss: 2.4569165476440897

Epoch: 5| Step: 4
Training loss: 2.067047884862126
Validation loss: 2.4653529081104755

Epoch: 5| Step: 5
Training loss: 2.2584499000598446
Validation loss: 2.459863519197201

Epoch: 5| Step: 6
Training loss: 2.8403306462332236
Validation loss: 2.4535280188174724

Epoch: 5| Step: 7
Training loss: 2.3574410906295356
Validation loss: 2.455982014545946

Epoch: 5| Step: 8
Training loss: 2.688158087776221
Validation loss: 2.4515628133124854

Epoch: 5| Step: 9
Training loss: 2.486652889452175
Validation loss: 2.4529468973870605

Epoch: 5| Step: 10
Training loss: 2.9500543686334098
Validation loss: 2.444959519557602

Epoch: 5| Step: 11
Training loss: 2.0455707151003297
Validation loss: 2.451706133772669

Epoch: 188| Step: 0
Training loss: 1.4509879364048508
Validation loss: 2.4539157257172413

Epoch: 5| Step: 1
Training loss: 2.829576320138628
Validation loss: 2.456620578782142

Epoch: 5| Step: 2
Training loss: 2.6328072477112854
Validation loss: 2.453505958246968

Epoch: 5| Step: 3
Training loss: 2.9852050905043437
Validation loss: 2.4551196887641193

Epoch: 5| Step: 4
Training loss: 2.505971547780404
Validation loss: 2.4623270824478345

Epoch: 5| Step: 5
Training loss: 2.5060042757879195
Validation loss: 2.460346821130868

Epoch: 5| Step: 6
Training loss: 2.380538305425097
Validation loss: 2.4641824732995814

Epoch: 5| Step: 7
Training loss: 2.939095895548075
Validation loss: 2.45602142331682

Epoch: 5| Step: 8
Training loss: 2.2298374652219324
Validation loss: 2.445092631114968

Epoch: 5| Step: 9
Training loss: 2.051398484122873
Validation loss: 2.4546511614412707

Epoch: 5| Step: 10
Training loss: 2.666882853884203
Validation loss: 2.4499987810644375

Epoch: 5| Step: 11
Training loss: 2.5303486290569355
Validation loss: 2.447736393939252

Epoch: 189| Step: 0
Training loss: 2.823277993438631
Validation loss: 2.4464760227295295

Epoch: 5| Step: 1
Training loss: 2.8465580752325055
Validation loss: 2.4490548484104777

Epoch: 5| Step: 2
Training loss: 2.3468604238491775
Validation loss: 2.448744736614351

Epoch: 5| Step: 3
Training loss: 2.667697518498193
Validation loss: 2.4535651733338266

Epoch: 5| Step: 4
Training loss: 2.3894600616648742
Validation loss: 2.4489965221413565

Epoch: 5| Step: 5
Training loss: 2.999492284409713
Validation loss: 2.44701020657695

Epoch: 5| Step: 6
Training loss: 2.4546854680840275
Validation loss: 2.4543396763032064

Epoch: 5| Step: 7
Training loss: 2.510463371211737
Validation loss: 2.4541046328765126

Epoch: 5| Step: 8
Training loss: 2.0160576407805673
Validation loss: 2.457584704889021

Epoch: 5| Step: 9
Training loss: 2.1614902233544195
Validation loss: 2.455665293591366

Epoch: 5| Step: 10
Training loss: 2.197575390491373
Validation loss: 2.463601014200008

Epoch: 5| Step: 11
Training loss: 1.793722953991237
Validation loss: 2.4655034451483497

Epoch: 190| Step: 0
Training loss: 2.3070383270082786
Validation loss: 2.4641621126251745

Epoch: 5| Step: 1
Training loss: 2.35834910339187
Validation loss: 2.45311739084153

Epoch: 5| Step: 2
Training loss: 3.0653839545409847
Validation loss: 2.4571165748259367

Epoch: 5| Step: 3
Training loss: 2.237895832531797
Validation loss: 2.453231707963292

Epoch: 5| Step: 4
Training loss: 2.662861752000301
Validation loss: 2.457352686457647

Epoch: 5| Step: 5
Training loss: 2.663550990603919
Validation loss: 2.4580398333179807

Epoch: 5| Step: 6
Training loss: 2.395596191169334
Validation loss: 2.4540300177940684

Epoch: 5| Step: 7
Training loss: 2.033836009733761
Validation loss: 2.451684569380551

Epoch: 5| Step: 8
Training loss: 2.8796180455923275
Validation loss: 2.4509902299141264

Epoch: 5| Step: 9
Training loss: 2.4374639068278783
Validation loss: 2.4472742306333966

Epoch: 5| Step: 10
Training loss: 2.1956811778599254
Validation loss: 2.454919909606839

Epoch: 5| Step: 11
Training loss: 2.7264719076327104
Validation loss: 2.4523465851160444

Epoch: 191| Step: 0
Training loss: 2.338484278415818
Validation loss: 2.455704371683478

Epoch: 5| Step: 1
Training loss: 2.910498026805393
Validation loss: 2.4589598767850678

Epoch: 5| Step: 2
Training loss: 2.284528805920772
Validation loss: 2.4586897459664825

Epoch: 5| Step: 3
Training loss: 2.8146250008511364
Validation loss: 2.459229052881355

Epoch: 5| Step: 4
Training loss: 2.1632335190554643
Validation loss: 2.4594898466885673

Epoch: 5| Step: 5
Training loss: 2.505379420496906
Validation loss: 2.4609480640648855

Epoch: 5| Step: 6
Training loss: 2.1770920700068292
Validation loss: 2.4583151919024218

Epoch: 5| Step: 7
Training loss: 1.940880564203257
Validation loss: 2.456416212287008

Epoch: 5| Step: 8
Training loss: 2.6577244873544723
Validation loss: 2.4590950704377628

Epoch: 5| Step: 9
Training loss: 2.524062702216258
Validation loss: 2.457197708289152

Epoch: 5| Step: 10
Training loss: 3.023092402987701
Validation loss: 2.4552190310785043

Epoch: 5| Step: 11
Training loss: 1.4730782549258876
Validation loss: 2.4520214903256887

Epoch: 192| Step: 0
Training loss: 2.810097155401683
Validation loss: 2.4607522602098695

Epoch: 5| Step: 1
Training loss: 1.8553645375750987
Validation loss: 2.4519162368774903

Epoch: 5| Step: 2
Training loss: 2.9153271096691826
Validation loss: 2.458719772068371

Epoch: 5| Step: 3
Training loss: 2.4967993274818596
Validation loss: 2.441173084568944

Epoch: 5| Step: 4
Training loss: 3.127684698833529
Validation loss: 2.4554441791647843

Epoch: 5| Step: 5
Training loss: 1.8540796480940187
Validation loss: 2.4574657272349834

Epoch: 5| Step: 6
Training loss: 2.200024093149212
Validation loss: 2.4587193054070076

Epoch: 5| Step: 7
Training loss: 2.2395764609534514
Validation loss: 2.4481483444530503

Epoch: 5| Step: 8
Training loss: 2.62197356374116
Validation loss: 2.4575422935106253

Epoch: 5| Step: 9
Training loss: 2.358136692093962
Validation loss: 2.4537693440922905

Epoch: 5| Step: 10
Training loss: 2.6382455431979057
Validation loss: 2.4548306296142437

Epoch: 5| Step: 11
Training loss: 2.5184315255304046
Validation loss: 2.4570953146502394

Epoch: 193| Step: 0
Training loss: 2.7931748107443015
Validation loss: 2.453226536878735

Epoch: 5| Step: 1
Training loss: 2.418625947200837
Validation loss: 2.453024645491957

Epoch: 5| Step: 2
Training loss: 2.648687840335892
Validation loss: 2.4597933859690024

Epoch: 5| Step: 3
Training loss: 2.4633024931625926
Validation loss: 2.4480262136634914

Epoch: 5| Step: 4
Training loss: 2.0939515429613027
Validation loss: 2.463207872828128

Epoch: 5| Step: 5
Training loss: 2.454198323052665
Validation loss: 2.4490776447247944

Epoch: 5| Step: 6
Training loss: 2.7443795422573114
Validation loss: 2.45484455851853

Epoch: 5| Step: 7
Training loss: 2.493138816338099
Validation loss: 2.457339683382684

Epoch: 5| Step: 8
Training loss: 2.561852070840046
Validation loss: 2.4600654590951003

Epoch: 5| Step: 9
Training loss: 2.58725790098272
Validation loss: 2.4712549952770244

Epoch: 5| Step: 10
Training loss: 2.4580721204527185
Validation loss: 2.471707116191733

Epoch: 5| Step: 11
Training loss: 2.1726718236755302
Validation loss: 2.4744725358879927

Epoch: 194| Step: 0
Training loss: 2.708237240382628
Validation loss: 2.462620457415606

Epoch: 5| Step: 1
Training loss: 2.367473018536802
Validation loss: 2.463109005980409

Epoch: 5| Step: 2
Training loss: 2.9642405744520026
Validation loss: 2.4513751185075137

Epoch: 5| Step: 3
Training loss: 2.622595457770723
Validation loss: 2.459497432092943

Epoch: 5| Step: 4
Training loss: 2.1183552917294803
Validation loss: 2.454963914090644

Epoch: 5| Step: 5
Training loss: 2.644355711752778
Validation loss: 2.454894867023023

Epoch: 5| Step: 6
Training loss: 2.441424023372805
Validation loss: 2.4539801125683063

Epoch: 5| Step: 7
Training loss: 2.134457243958717
Validation loss: 2.4526546456604983

Epoch: 5| Step: 8
Training loss: 2.5973750141462686
Validation loss: 2.460486634142766

Epoch: 5| Step: 9
Training loss: 2.3028947484773803
Validation loss: 2.458223103352608

Epoch: 5| Step: 10
Training loss: 2.6973282946930666
Validation loss: 2.450325735489651

Epoch: 5| Step: 11
Training loss: 2.0252312328042157
Validation loss: 2.44573381915773

Epoch: 195| Step: 0
Training loss: 2.1012751159437744
Validation loss: 2.4568198173211027

Epoch: 5| Step: 1
Training loss: 2.809701841561941
Validation loss: 2.455787610801036

Epoch: 5| Step: 2
Training loss: 2.572208528457051
Validation loss: 2.4702985469995906

Epoch: 5| Step: 3
Training loss: 2.6867759971365426
Validation loss: 2.4681810455772375

Epoch: 5| Step: 4
Training loss: 2.928591917544477
Validation loss: 2.473657143311656

Epoch: 5| Step: 5
Training loss: 2.4484028651277594
Validation loss: 2.485012720338999

Epoch: 5| Step: 6
Training loss: 2.2612600437866983
Validation loss: 2.4807921391536234

Epoch: 5| Step: 7
Training loss: 2.2624616967431153
Validation loss: 2.474151123298276

Epoch: 5| Step: 8
Training loss: 2.574834955351944
Validation loss: 2.473653173532282

Epoch: 5| Step: 9
Training loss: 2.6146240433845604
Validation loss: 2.483784635443438

Epoch: 5| Step: 10
Training loss: 2.610492581184336
Validation loss: 2.469121116396562

Epoch: 5| Step: 11
Training loss: 1.2253625917009776
Validation loss: 2.4612912645330973

Epoch: 196| Step: 0
Training loss: 1.8669927647128122
Validation loss: 2.45338064023939

Epoch: 5| Step: 1
Training loss: 2.4296598279548594
Validation loss: 2.457080850671639

Epoch: 5| Step: 2
Training loss: 3.049474145552326
Validation loss: 2.4561586452802344

Epoch: 5| Step: 3
Training loss: 2.009685192222498
Validation loss: 2.451867011847551

Epoch: 5| Step: 4
Training loss: 2.5751430027335545
Validation loss: 2.4467410057798773

Epoch: 5| Step: 5
Training loss: 2.7847982339692865
Validation loss: 2.455127158189974

Epoch: 5| Step: 6
Training loss: 2.502538060252326
Validation loss: 2.445341250217089

Epoch: 5| Step: 7
Training loss: 2.0403127527784535
Validation loss: 2.4534901470709207

Epoch: 5| Step: 8
Training loss: 2.5209750511330054
Validation loss: 2.4493401115562845

Epoch: 5| Step: 9
Training loss: 2.5857282940004134
Validation loss: 2.450021578732654

Epoch: 5| Step: 10
Training loss: 2.720840089175223
Validation loss: 2.4547305067128655

Epoch: 5| Step: 11
Training loss: 3.223761795454274
Validation loss: 2.4542220005528668

Epoch: 197| Step: 0
Training loss: 2.862493430050969
Validation loss: 2.4563417665068736

Epoch: 5| Step: 1
Training loss: 2.168315138079542
Validation loss: 2.448682137110916

Epoch: 5| Step: 2
Training loss: 2.1401058040738583
Validation loss: 2.452735157177861

Epoch: 5| Step: 3
Training loss: 2.201127898920184
Validation loss: 2.45052731412111

Epoch: 5| Step: 4
Training loss: 2.3779625735662324
Validation loss: 2.4649443487484275

Epoch: 5| Step: 5
Training loss: 2.287815001431262
Validation loss: 2.4550404450917163

Epoch: 5| Step: 6
Training loss: 3.054120023266295
Validation loss: 2.4509715835585975

Epoch: 5| Step: 7
Training loss: 2.217770319894055
Validation loss: 2.4543739508722204

Epoch: 5| Step: 8
Training loss: 2.321169608207711
Validation loss: 2.4571572227509577

Epoch: 5| Step: 9
Training loss: 2.8250980934059124
Validation loss: 2.4516653752102053

Epoch: 5| Step: 10
Training loss: 2.643971686842118
Validation loss: 2.461226051812061

Epoch: 5| Step: 11
Training loss: 2.7638508769051358
Validation loss: 2.4564582103912227

Epoch: 198| Step: 0
Training loss: 2.0423036736364946
Validation loss: 2.4556933481645618

Epoch: 5| Step: 1
Training loss: 2.348650881882154
Validation loss: 2.4546749782424993

Epoch: 5| Step: 2
Training loss: 3.167411030736977
Validation loss: 2.458262338798533

Epoch: 5| Step: 3
Training loss: 2.658756823474932
Validation loss: 2.4635797636112073

Epoch: 5| Step: 4
Training loss: 2.601821840665491
Validation loss: 2.454113767072126

Epoch: 5| Step: 5
Training loss: 2.3728558749973674
Validation loss: 2.4512688646720506

Epoch: 5| Step: 6
Training loss: 2.41986955858627
Validation loss: 2.457727116392847

Epoch: 5| Step: 7
Training loss: 1.9407873260867294
Validation loss: 2.4579819142519734

Epoch: 5| Step: 8
Training loss: 2.3505931389781147
Validation loss: 2.454368462440119

Epoch: 5| Step: 9
Training loss: 2.2348337836191026
Validation loss: 2.4578484458420786

Epoch: 5| Step: 10
Training loss: 3.0628391000281314
Validation loss: 2.4575848099868387

Epoch: 5| Step: 11
Training loss: 1.5631235023073438
Validation loss: 2.4622967916964047

Epoch: 199| Step: 0
Training loss: 2.5220600537706153
Validation loss: 2.4605270003005493

Epoch: 5| Step: 1
Training loss: 2.5222307750745476
Validation loss: 2.4608147000146574

Epoch: 5| Step: 2
Training loss: 2.166921661728367
Validation loss: 2.4577829194678595

Epoch: 5| Step: 3
Training loss: 2.375315093169662
Validation loss: 2.4563638683388653

Epoch: 5| Step: 4
Training loss: 2.1290838604953946
Validation loss: 2.4606772754475466

Epoch: 5| Step: 5
Training loss: 1.9835589074901816
Validation loss: 2.455189283834128

Epoch: 5| Step: 6
Training loss: 2.7292070652735676
Validation loss: 2.455365941250713

Epoch: 5| Step: 7
Training loss: 2.4381533016233408
Validation loss: 2.462682059217546

Epoch: 5| Step: 8
Training loss: 2.4679979555068985
Validation loss: 2.458035468520698

Epoch: 5| Step: 9
Training loss: 2.986505516876127
Validation loss: 2.456047328080969

Epoch: 5| Step: 10
Training loss: 2.7206968155436533
Validation loss: 2.4612923260367627

Epoch: 5| Step: 11
Training loss: 2.8237631866971244
Validation loss: 2.454235603020617

Epoch: 200| Step: 0
Training loss: 2.1788954304029504
Validation loss: 2.459294011561029

Epoch: 5| Step: 1
Training loss: 2.5250650831842743
Validation loss: 2.4545236840029205

Epoch: 5| Step: 2
Training loss: 2.1052239157131307
Validation loss: 2.4567478422817493

Epoch: 5| Step: 3
Training loss: 2.5815803261051276
Validation loss: 2.4614477688216514

Epoch: 5| Step: 4
Training loss: 2.773049856684858
Validation loss: 2.4578034158463207

Epoch: 5| Step: 5
Training loss: 2.393118262531782
Validation loss: 2.4591642459916505

Epoch: 5| Step: 6
Training loss: 2.889513616584924
Validation loss: 2.4512554341900685

Epoch: 5| Step: 7
Training loss: 1.8578786518969856
Validation loss: 2.459196166920813

Epoch: 5| Step: 8
Training loss: 2.867651462695392
Validation loss: 2.455170376019879

Epoch: 5| Step: 9
Training loss: 2.4219779700262514
Validation loss: 2.447391227711881

Epoch: 5| Step: 10
Training loss: 2.45516076627889
Validation loss: 2.453253586754075

Epoch: 5| Step: 11
Training loss: 2.942434022434385
Validation loss: 2.4586250581981335

Epoch: 201| Step: 0
Training loss: 2.473919441854394
Validation loss: 2.4598410510160007

Epoch: 5| Step: 1
Training loss: 2.2800476877345144
Validation loss: 2.4656400487494525

Epoch: 5| Step: 2
Training loss: 2.460233654307871
Validation loss: 2.4589027470015115

Epoch: 5| Step: 3
Training loss: 2.4446359496768912
Validation loss: 2.467280513885638

Epoch: 5| Step: 4
Training loss: 2.996639754019267
Validation loss: 2.4687121706289474

Epoch: 5| Step: 5
Training loss: 3.0588236950101853
Validation loss: 2.4669641119415155

Epoch: 5| Step: 6
Training loss: 2.1555703239109794
Validation loss: 2.467911000273979

Epoch: 5| Step: 7
Training loss: 2.3970541676944492
Validation loss: 2.462787796443251

Epoch: 5| Step: 8
Training loss: 1.9273433269350277
Validation loss: 2.4636740107940613

Epoch: 5| Step: 9
Training loss: 2.2916396283953295
Validation loss: 2.4572089615654797

Epoch: 5| Step: 10
Training loss: 2.379232049189482
Validation loss: 2.453348671987862

Epoch: 5| Step: 11
Training loss: 3.650477882350645
Validation loss: 2.454533733341004

Epoch: 202| Step: 0
Training loss: 2.3616724007841325
Validation loss: 2.4547171315930627

Epoch: 5| Step: 1
Training loss: 2.434930278242049
Validation loss: 2.4530114959569755

Epoch: 5| Step: 2
Training loss: 2.126183012232853
Validation loss: 2.4529835544797693

Epoch: 5| Step: 3
Training loss: 2.7053670240021233
Validation loss: 2.4599289538040874

Epoch: 5| Step: 4
Training loss: 2.632828166247205
Validation loss: 2.4647792519555614

Epoch: 5| Step: 5
Training loss: 2.8057218466682654
Validation loss: 2.4505013530306896

Epoch: 5| Step: 6
Training loss: 2.1064724767893814
Validation loss: 2.4548657309491544

Epoch: 5| Step: 7
Training loss: 2.919826666769288
Validation loss: 2.450752110906424

Epoch: 5| Step: 8
Training loss: 2.016505204454852
Validation loss: 2.4601689384894807

Epoch: 5| Step: 9
Training loss: 2.481567427848032
Validation loss: 2.4481809405799044

Epoch: 5| Step: 10
Training loss: 2.7378449139974688
Validation loss: 2.4568177470572894

Epoch: 5| Step: 11
Training loss: 1.6159306309040753
Validation loss: 2.459381014967223

Epoch: 203| Step: 0
Training loss: 2.735672648282687
Validation loss: 2.4649948662220162

Epoch: 5| Step: 1
Training loss: 2.5113009614079136
Validation loss: 2.4695235199461854

Epoch: 5| Step: 2
Training loss: 2.8012821701905697
Validation loss: 2.4675050203799858

Epoch: 5| Step: 3
Training loss: 2.5658991528954505
Validation loss: 2.464676316786779

Epoch: 5| Step: 4
Training loss: 1.7220069543917385
Validation loss: 2.4645383819990894

Epoch: 5| Step: 5
Training loss: 2.062075831405468
Validation loss: 2.468551233394192

Epoch: 5| Step: 6
Training loss: 2.9967180419806474
Validation loss: 2.463192664353316

Epoch: 5| Step: 7
Training loss: 2.521885444780202
Validation loss: 2.460751456842647

Epoch: 5| Step: 8
Training loss: 2.4268419093828935
Validation loss: 2.4669939346514673

Epoch: 5| Step: 9
Training loss: 2.330877328493157
Validation loss: 2.463177473933308

Epoch: 5| Step: 10
Training loss: 2.311351284615728
Validation loss: 2.4590912367204556

Epoch: 5| Step: 11
Training loss: 2.8781987515256295
Validation loss: 2.4592779184816984

Epoch: 204| Step: 0
Training loss: 2.7240809649451796
Validation loss: 2.449289583503146

Epoch: 5| Step: 1
Training loss: 2.623206297800986
Validation loss: 2.446998474039294

Epoch: 5| Step: 2
Training loss: 2.5770314989810896
Validation loss: 2.44760243583653

Epoch: 5| Step: 3
Training loss: 2.7026836939091687
Validation loss: 2.4593361624883006

Epoch: 5| Step: 4
Training loss: 2.593823811043849
Validation loss: 2.475039534301202

Epoch: 5| Step: 5
Training loss: 2.637693956665007
Validation loss: 2.47849350827457

Epoch: 5| Step: 6
Training loss: 2.261833543779658
Validation loss: 2.4610689723505033

Epoch: 5| Step: 7
Training loss: 2.2998149507135643
Validation loss: 2.457522391197541

Epoch: 5| Step: 8
Training loss: 2.5019085274860124
Validation loss: 2.4522447687407545

Epoch: 5| Step: 9
Training loss: 2.346603690769015
Validation loss: 2.4555195057844506

Epoch: 5| Step: 10
Training loss: 2.0739521782051025
Validation loss: 2.4629158827444253

Epoch: 5| Step: 11
Training loss: 2.619771746236754
Validation loss: 2.458324930747807

Epoch: 205| Step: 0
Training loss: 2.9159848824149717
Validation loss: 2.4685204536017387

Epoch: 5| Step: 1
Training loss: 2.0612426161763926
Validation loss: 2.4700544347569213

Epoch: 5| Step: 2
Training loss: 2.8436086430891416
Validation loss: 2.4745910170149408

Epoch: 5| Step: 3
Training loss: 2.35034655186834
Validation loss: 2.4779258609530808

Epoch: 5| Step: 4
Training loss: 3.0089427855488617
Validation loss: 2.477842551671498

Epoch: 5| Step: 5
Training loss: 2.1102855836227
Validation loss: 2.4770126254612506

Epoch: 5| Step: 6
Training loss: 2.493908135699196
Validation loss: 2.4744733066980573

Epoch: 5| Step: 7
Training loss: 2.7236356136817794
Validation loss: 2.470199388861733

Epoch: 5| Step: 8
Training loss: 2.2932259774400685
Validation loss: 2.463272085353242

Epoch: 5| Step: 9
Training loss: 2.352955149160298
Validation loss: 2.465352634105345

Epoch: 5| Step: 10
Training loss: 2.4861615552940677
Validation loss: 2.4557593611111272

Epoch: 5| Step: 11
Training loss: 1.2513511984160737
Validation loss: 2.457724493140192

Epoch: 206| Step: 0
Training loss: 2.5365231066402725
Validation loss: 2.463479740232816

Epoch: 5| Step: 1
Training loss: 2.546651818729809
Validation loss: 2.4550704733386155

Epoch: 5| Step: 2
Training loss: 1.8026006613888994
Validation loss: 2.450110658916766

Epoch: 5| Step: 3
Training loss: 2.03148591065456
Validation loss: 2.4534458954811234

Epoch: 5| Step: 4
Training loss: 3.2503573881397667
Validation loss: 2.4535425968648332

Epoch: 5| Step: 5
Training loss: 2.4764926070209445
Validation loss: 2.4549319543168147

Epoch: 5| Step: 6
Training loss: 2.1188695778200413
Validation loss: 2.4571926547083773

Epoch: 5| Step: 7
Training loss: 2.3235762020492756
Validation loss: 2.4568800442518572

Epoch: 5| Step: 8
Training loss: 2.423908979249233
Validation loss: 2.4607072712415134

Epoch: 5| Step: 9
Training loss: 2.632099088913843
Validation loss: 2.4573753734549335

Epoch: 5| Step: 10
Training loss: 2.787995633935999
Validation loss: 2.4531147950561523

Epoch: 5| Step: 11
Training loss: 2.8926175235226204
Validation loss: 2.449544825083859

Epoch: 207| Step: 0
Training loss: 2.7487455454569516
Validation loss: 2.4531708326330484

Epoch: 5| Step: 1
Training loss: 2.4366959443879592
Validation loss: 2.447822347136048

Epoch: 5| Step: 2
Training loss: 2.1171728605207663
Validation loss: 2.4539154747246386

Epoch: 5| Step: 3
Training loss: 2.6256239013379004
Validation loss: 2.4494261118968117

Epoch: 5| Step: 4
Training loss: 2.8006831834295918
Validation loss: 2.4445784445059706

Epoch: 5| Step: 5
Training loss: 2.8742281665528506
Validation loss: 2.4556302036855855

Epoch: 5| Step: 6
Training loss: 2.2731981708621953
Validation loss: 2.457398650452204

Epoch: 5| Step: 7
Training loss: 2.7229541413098146
Validation loss: 2.4513561934313066

Epoch: 5| Step: 8
Training loss: 2.030726203873899
Validation loss: 2.4668870327004253

Epoch: 5| Step: 9
Training loss: 2.1984670109723594
Validation loss: 2.4600238294791215

Epoch: 5| Step: 10
Training loss: 2.3061000826937557
Validation loss: 2.4679295991499375

Epoch: 5| Step: 11
Training loss: 2.056321339398757
Validation loss: 2.4560275835345395

Epoch: 208| Step: 0
Training loss: 2.26100666649505
Validation loss: 2.463065624952381

Epoch: 5| Step: 1
Training loss: 2.219746647889495
Validation loss: 2.457227018852688

Epoch: 5| Step: 2
Training loss: 2.3776894449996604
Validation loss: 2.456758456710836

Epoch: 5| Step: 3
Training loss: 2.4170519642229262
Validation loss: 2.4615647379482546

Epoch: 5| Step: 4
Training loss: 2.864467900580244
Validation loss: 2.465319499407497

Epoch: 5| Step: 5
Training loss: 2.269056470784419
Validation loss: 2.4657786793231384

Epoch: 5| Step: 6
Training loss: 2.922569804275726
Validation loss: 2.4566376395583203

Epoch: 5| Step: 7
Training loss: 2.2601602880637643
Validation loss: 2.465218879700574

Epoch: 5| Step: 8
Training loss: 2.915881859687275
Validation loss: 2.461525256495177

Epoch: 5| Step: 9
Training loss: 2.2808019119605243
Validation loss: 2.4640856069103463

Epoch: 5| Step: 10
Training loss: 2.369285635665392
Validation loss: 2.459518843164065

Epoch: 5| Step: 11
Training loss: 1.7820385977507027
Validation loss: 2.4476669847025927

Epoch: 209| Step: 0
Training loss: 2.6024220739125608
Validation loss: 2.465318109215256

Epoch: 5| Step: 1
Training loss: 2.3827535653252245
Validation loss: 2.454917673852894

Epoch: 5| Step: 2
Training loss: 2.246459188172524
Validation loss: 2.466573633123495

Epoch: 5| Step: 3
Training loss: 2.4862554379226802
Validation loss: 2.4558809354181643

Epoch: 5| Step: 4
Training loss: 2.471995381391093
Validation loss: 2.456849888514985

Epoch: 5| Step: 5
Training loss: 2.351610557090446
Validation loss: 2.462634862637445

Epoch: 5| Step: 6
Training loss: 2.9507598286346823
Validation loss: 2.4564891837857865

Epoch: 5| Step: 7
Training loss: 2.5797030156741627
Validation loss: 2.4601503879497066

Epoch: 5| Step: 8
Training loss: 2.107741224753675
Validation loss: 2.4677135166893676

Epoch: 5| Step: 9
Training loss: 2.4678956497055733
Validation loss: 2.4634233020200886

Epoch: 5| Step: 10
Training loss: 2.492582475221727
Validation loss: 2.4714582171441837

Epoch: 5| Step: 11
Training loss: 2.9663644943935386
Validation loss: 2.4676927564158055

Epoch: 210| Step: 0
Training loss: 2.2208123092181062
Validation loss: 2.459613989108472

Epoch: 5| Step: 1
Training loss: 2.168869134010876
Validation loss: 2.4626169236658746

Epoch: 5| Step: 2
Training loss: 2.4821016478768687
Validation loss: 2.4608623735374526

Epoch: 5| Step: 3
Training loss: 2.6635870635145147
Validation loss: 2.461897026183638

Epoch: 5| Step: 4
Training loss: 2.5290789300405394
Validation loss: 2.4622521496792853

Epoch: 5| Step: 5
Training loss: 2.094960332599645
Validation loss: 2.464727049340536

Epoch: 5| Step: 6
Training loss: 2.775643516363663
Validation loss: 2.4554355940733106

Epoch: 5| Step: 7
Training loss: 2.113432873488578
Validation loss: 2.462867460411659

Epoch: 5| Step: 8
Training loss: 2.951507448295903
Validation loss: 2.464696852573291

Epoch: 5| Step: 9
Training loss: 2.3160545249344806
Validation loss: 2.464421300057272

Epoch: 5| Step: 10
Training loss: 2.4372986930469596
Validation loss: 2.468606683136348

Epoch: 5| Step: 11
Training loss: 4.371021750831289
Validation loss: 2.4582734356603657

Epoch: 211| Step: 0
Training loss: 2.8346398277172464
Validation loss: 2.458125602032804

Epoch: 5| Step: 1
Training loss: 2.7559896609994103
Validation loss: 2.459331416253235

Epoch: 5| Step: 2
Training loss: 2.667711907418769
Validation loss: 2.4692993297325936

Epoch: 5| Step: 3
Training loss: 2.141533317817975
Validation loss: 2.478022701465787

Epoch: 5| Step: 4
Training loss: 1.8434367156168538
Validation loss: 2.4777238772131445

Epoch: 5| Step: 5
Training loss: 2.4359097306073814
Validation loss: 2.473815180334384

Epoch: 5| Step: 6
Training loss: 2.6073190047298658
Validation loss: 2.475190810673524

Epoch: 5| Step: 7
Training loss: 2.8573694752329746
Validation loss: 2.486004121320474

Epoch: 5| Step: 8
Training loss: 2.214591198605494
Validation loss: 2.4928971777922513

Epoch: 5| Step: 9
Training loss: 2.807173878045247
Validation loss: 2.498291977904225

Epoch: 5| Step: 10
Training loss: 2.818945809814054
Validation loss: 2.496109247532644

Epoch: 5| Step: 11
Training loss: 3.1906315996809806
Validation loss: 2.5044202549749306

Epoch: 212| Step: 0
Training loss: 2.661184955051083
Validation loss: 2.490374269233613

Epoch: 5| Step: 1
Training loss: 2.4803408131684233
Validation loss: 2.4793289689757048

Epoch: 5| Step: 2
Training loss: 2.9281166035827955
Validation loss: 2.4755183725460532

Epoch: 5| Step: 3
Training loss: 2.7235063186328494
Validation loss: 2.476899329704584

Epoch: 5| Step: 4
Training loss: 3.0343256811814943
Validation loss: 2.4758625786358452

Epoch: 5| Step: 5
Training loss: 2.517505203741732
Validation loss: 2.466403352906704

Epoch: 5| Step: 6
Training loss: 2.5109559320178043
Validation loss: 2.4632908604050585

Epoch: 5| Step: 7
Training loss: 2.1049765611372044
Validation loss: 2.4668323577721027

Epoch: 5| Step: 8
Training loss: 2.3668337516726097
Validation loss: 2.4601744139812314

Epoch: 5| Step: 9
Training loss: 2.3899797553637527
Validation loss: 2.458587525582796

Epoch: 5| Step: 10
Training loss: 2.368171210524006
Validation loss: 2.458860402798611

Epoch: 5| Step: 11
Training loss: 2.5165087172434752
Validation loss: 2.4550623118099444

Epoch: 213| Step: 0
Training loss: 2.5354152364943605
Validation loss: 2.4537745261784374

Epoch: 5| Step: 1
Training loss: 2.373107356803839
Validation loss: 2.4588160337273384

Epoch: 5| Step: 2
Training loss: 2.9125681463954556
Validation loss: 2.4506874142713473

Epoch: 5| Step: 3
Training loss: 2.833432438930974
Validation loss: 2.4485982162548128

Epoch: 5| Step: 4
Training loss: 1.9417143487055437
Validation loss: 2.455940307623349

Epoch: 5| Step: 5
Training loss: 2.791721476306247
Validation loss: 2.455923840656731

Epoch: 5| Step: 6
Training loss: 2.309207324805009
Validation loss: 2.4568377056217057

Epoch: 5| Step: 7
Training loss: 2.4545708544216485
Validation loss: 2.4631380364796502

Epoch: 5| Step: 8
Training loss: 2.021350506021798
Validation loss: 2.467352236030832

Epoch: 5| Step: 9
Training loss: 2.608411691075698
Validation loss: 2.4633368728928007

Epoch: 5| Step: 10
Training loss: 2.5121343811622285
Validation loss: 2.468349681862784

Epoch: 5| Step: 11
Training loss: 3.4597404252515287
Validation loss: 2.46551394935715

Epoch: 214| Step: 0
Training loss: 3.154976313966083
Validation loss: 2.458686844952486

Epoch: 5| Step: 1
Training loss: 2.3939254019196285
Validation loss: 2.468246094666487

Epoch: 5| Step: 2
Training loss: 2.1305604999567205
Validation loss: 2.4649454127090826

Epoch: 5| Step: 3
Training loss: 2.6059069400838544
Validation loss: 2.464936538295922

Epoch: 5| Step: 4
Training loss: 2.2196979915258708
Validation loss: 2.4655291576154448

Epoch: 5| Step: 5
Training loss: 2.4422070952133943
Validation loss: 2.470363299052391

Epoch: 5| Step: 6
Training loss: 2.453131025756433
Validation loss: 2.46418625676643

Epoch: 5| Step: 7
Training loss: 2.231019922356458
Validation loss: 2.4552766673618835

Epoch: 5| Step: 8
Training loss: 2.4704317569598837
Validation loss: 2.4589187395154726

Epoch: 5| Step: 9
Training loss: 2.605921121242299
Validation loss: 2.463653712449898

Epoch: 5| Step: 10
Training loss: 2.5537284894234293
Validation loss: 2.4548183962318975

Epoch: 5| Step: 11
Training loss: 2.0005055027137364
Validation loss: 2.4616119752239505

Epoch: 215| Step: 0
Training loss: 2.7521986408512764
Validation loss: 2.461239423850194

Epoch: 5| Step: 1
Training loss: 1.9630158493560357
Validation loss: 2.4652881816113172

Epoch: 5| Step: 2
Training loss: 2.4356389888668097
Validation loss: 2.4654013722888592

Epoch: 5| Step: 3
Training loss: 2.7822355602971824
Validation loss: 2.4633655236456926

Epoch: 5| Step: 4
Training loss: 2.6298098322066097
Validation loss: 2.4657084846947988

Epoch: 5| Step: 5
Training loss: 2.3487680249540155
Validation loss: 2.4644902938625326

Epoch: 5| Step: 6
Training loss: 3.034354281919487
Validation loss: 2.458517549907924

Epoch: 5| Step: 7
Training loss: 2.4221472802463087
Validation loss: 2.4591598347144874

Epoch: 5| Step: 8
Training loss: 2.3454549056194693
Validation loss: 2.457916367185861

Epoch: 5| Step: 9
Training loss: 2.432406262809722
Validation loss: 2.4630575826808236

Epoch: 5| Step: 10
Training loss: 2.1120058960326578
Validation loss: 2.4570631703384014

Epoch: 5| Step: 11
Training loss: 1.841000268371496
Validation loss: 2.4565415270856796

Epoch: 216| Step: 0
Training loss: 2.5923150930797516
Validation loss: 2.4627791764456894

Epoch: 5| Step: 1
Training loss: 2.6677489965145784
Validation loss: 2.46107586668462

Epoch: 5| Step: 2
Training loss: 2.5975220609724894
Validation loss: 2.4558647683987807

Epoch: 5| Step: 3
Training loss: 2.0786868605025335
Validation loss: 2.4579777716386078

Epoch: 5| Step: 4
Training loss: 2.298905286247504
Validation loss: 2.458736727371167

Epoch: 5| Step: 5
Training loss: 2.6456328989438656
Validation loss: 2.465079113443198

Epoch: 5| Step: 6
Training loss: 2.1228283275708852
Validation loss: 2.4533769757554444

Epoch: 5| Step: 7
Training loss: 2.7443503520278334
Validation loss: 2.460216576070903

Epoch: 5| Step: 8
Training loss: 2.33023958374223
Validation loss: 2.453230671317614

Epoch: 5| Step: 9
Training loss: 2.6549068869949624
Validation loss: 2.458470463295571

Epoch: 5| Step: 10
Training loss: 2.316869576805154
Validation loss: 2.4689527199000865

Epoch: 5| Step: 11
Training loss: 2.311402034432048
Validation loss: 2.462893133845351

Epoch: 217| Step: 0
Training loss: 2.2696049952385153
Validation loss: 2.4631248723723513

Epoch: 5| Step: 1
Training loss: 3.0466023641042854
Validation loss: 2.469240073561136

Epoch: 5| Step: 2
Training loss: 2.3048099808555937
Validation loss: 2.4627779703696895

Epoch: 5| Step: 3
Training loss: 2.4754611192645952
Validation loss: 2.45644387813863

Epoch: 5| Step: 4
Training loss: 2.284329152201614
Validation loss: 2.474723022468682

Epoch: 5| Step: 5
Training loss: 2.1245879727502643
Validation loss: 2.4643025920091186

Epoch: 5| Step: 6
Training loss: 2.765209533174587
Validation loss: 2.463228481351403

Epoch: 5| Step: 7
Training loss: 2.294129683749237
Validation loss: 2.4669632099257677

Epoch: 5| Step: 8
Training loss: 2.382676617859715
Validation loss: 2.4642089050378826

Epoch: 5| Step: 9
Training loss: 2.799645527472771
Validation loss: 2.4714171411967647

Epoch: 5| Step: 10
Training loss: 2.21591650332476
Validation loss: 2.462176774849651

Epoch: 5| Step: 11
Training loss: 2.370508464238911
Validation loss: 2.4711629768811085

Epoch: 218| Step: 0
Training loss: 2.8268519112628536
Validation loss: 2.468663141678273

Epoch: 5| Step: 1
Training loss: 2.8519490855248066
Validation loss: 2.461462287856606

Epoch: 5| Step: 2
Training loss: 2.5317806111607135
Validation loss: 2.4698160702580254

Epoch: 5| Step: 3
Training loss: 2.2970881979471205
Validation loss: 2.4701967064656056

Epoch: 5| Step: 4
Training loss: 2.337686043745724
Validation loss: 2.463049459717901

Epoch: 5| Step: 5
Training loss: 2.6395617268638207
Validation loss: 2.466597826153889

Epoch: 5| Step: 6
Training loss: 2.697626684995146
Validation loss: 2.469028614112453

Epoch: 5| Step: 7
Training loss: 2.3348352389642253
Validation loss: 2.46634172321535

Epoch: 5| Step: 8
Training loss: 2.159525166878269
Validation loss: 2.4617981288859467

Epoch: 5| Step: 9
Training loss: 2.5307448083164283
Validation loss: 2.467839089071202

Epoch: 5| Step: 10
Training loss: 1.7583596289357364
Validation loss: 2.4666238534332803

Epoch: 5| Step: 11
Training loss: 1.7586547190241322
Validation loss: 2.465897896430553

Epoch: 219| Step: 0
Training loss: 2.588269429823221
Validation loss: 2.4763146726715037

Epoch: 5| Step: 1
Training loss: 2.6689898881145404
Validation loss: 2.4842992727066413

Epoch: 5| Step: 2
Training loss: 2.617047570886179
Validation loss: 2.496332753120987

Epoch: 5| Step: 3
Training loss: 2.6709255740166244
Validation loss: 2.48842923030256

Epoch: 5| Step: 4
Training loss: 2.0161986015376274
Validation loss: 2.4850450887625524

Epoch: 5| Step: 5
Training loss: 2.033280634066861
Validation loss: 2.473362621395733

Epoch: 5| Step: 6
Training loss: 1.8258560315521382
Validation loss: 2.472544413965785

Epoch: 5| Step: 7
Training loss: 2.545266327928028
Validation loss: 2.467232209425234

Epoch: 5| Step: 8
Training loss: 2.5108418928933776
Validation loss: 2.46110424708028

Epoch: 5| Step: 9
Training loss: 2.890308589629511
Validation loss: 2.4749758558669064

Epoch: 5| Step: 10
Training loss: 2.7444068209411165
Validation loss: 2.462551469716787

Epoch: 5| Step: 11
Training loss: 1.4829758324020406
Validation loss: 2.4732285048804137

Epoch: 220| Step: 0
Training loss: 2.393985854200288
Validation loss: 2.4760073050518048

Epoch: 5| Step: 1
Training loss: 2.93501517530739
Validation loss: 2.4773833742544737

Epoch: 5| Step: 2
Training loss: 2.2810936443099674
Validation loss: 2.472741919505375

Epoch: 5| Step: 3
Training loss: 2.263000230655161
Validation loss: 2.473452355024335

Epoch: 5| Step: 4
Training loss: 2.568557371913043
Validation loss: 2.4726403202228755

Epoch: 5| Step: 5
Training loss: 2.4257555974073877
Validation loss: 2.4686034114791924

Epoch: 5| Step: 6
Training loss: 2.8571688787092797
Validation loss: 2.47051959053445

Epoch: 5| Step: 7
Training loss: 2.850433544177185
Validation loss: 2.470106528806047

Epoch: 5| Step: 8
Training loss: 1.6994995586712303
Validation loss: 2.470765831997184

Epoch: 5| Step: 9
Training loss: 1.993771749634931
Validation loss: 2.4738376199819263

Epoch: 5| Step: 10
Training loss: 2.218543566919318
Validation loss: 2.470203961395344

Epoch: 5| Step: 11
Training loss: 4.058163250147011
Validation loss: 2.4767314039008212

Epoch: 221| Step: 0
Training loss: 2.5806650307105765
Validation loss: 2.4642015155481993

Epoch: 5| Step: 1
Training loss: 2.4525248771440125
Validation loss: 2.490120695424046

Epoch: 5| Step: 2
Training loss: 2.484273944454881
Validation loss: 2.504214866373195

Epoch: 5| Step: 3
Training loss: 2.235216529137369
Validation loss: 2.5075821736094857

Epoch: 5| Step: 4
Training loss: 2.466753091672756
Validation loss: 2.515131868478587

Epoch: 5| Step: 5
Training loss: 2.492131917208103
Validation loss: 2.509178348213385

Epoch: 5| Step: 6
Training loss: 1.679524329488232
Validation loss: 2.496539597946809

Epoch: 5| Step: 7
Training loss: 2.5277118208481304
Validation loss: 2.4799285420574915

Epoch: 5| Step: 8
Training loss: 2.4230046744748255
Validation loss: 2.4680775398539914

Epoch: 5| Step: 9
Training loss: 2.578865176211509
Validation loss: 2.472569890495362

Epoch: 5| Step: 10
Training loss: 2.9493898051594196
Validation loss: 2.4626109473412896

Epoch: 5| Step: 11
Training loss: 2.677163673313553
Validation loss: 2.468153921830315

Epoch: 222| Step: 0
Training loss: 2.3477892845912107
Validation loss: 2.4693394814275527

Epoch: 5| Step: 1
Training loss: 2.356737898847631
Validation loss: 2.477374660684461

Epoch: 5| Step: 2
Training loss: 2.7706384422962316
Validation loss: 2.472174269559997

Epoch: 5| Step: 3
Training loss: 2.5610732782106695
Validation loss: 2.4815956139261663

Epoch: 5| Step: 4
Training loss: 2.181398219453178
Validation loss: 2.482974439380841

Epoch: 5| Step: 5
Training loss: 2.593158884367241
Validation loss: 2.471177858924678

Epoch: 5| Step: 6
Training loss: 2.2994530151769457
Validation loss: 2.4725287064556314

Epoch: 5| Step: 7
Training loss: 2.4158424309195943
Validation loss: 2.4707258341553526

Epoch: 5| Step: 8
Training loss: 2.8593398128491545
Validation loss: 2.4764616872523493

Epoch: 5| Step: 9
Training loss: 2.5281610361367197
Validation loss: 2.4690987827493567

Epoch: 5| Step: 10
Training loss: 2.2997115908041397
Validation loss: 2.473733186348216

Epoch: 5| Step: 11
Training loss: 3.0267309737690997
Validation loss: 2.4675876802637178

Epoch: 223| Step: 0
Training loss: 2.6492795252712087
Validation loss: 2.4702031389833707

Epoch: 5| Step: 1
Training loss: 2.1624267124700896
Validation loss: 2.47174962815335

Epoch: 5| Step: 2
Training loss: 1.8918553912202334
Validation loss: 2.478595324538261

Epoch: 5| Step: 3
Training loss: 1.7212072666600808
Validation loss: 2.478696763894826

Epoch: 5| Step: 4
Training loss: 3.085532323578645
Validation loss: 2.476061003056762

Epoch: 5| Step: 5
Training loss: 2.015207410034149
Validation loss: 2.479028843540195

Epoch: 5| Step: 6
Training loss: 2.742375120172959
Validation loss: 2.471509919854276

Epoch: 5| Step: 7
Training loss: 2.6397795819253362
Validation loss: 2.4598657686290433

Epoch: 5| Step: 8
Training loss: 2.219555775642172
Validation loss: 2.460264636701138

Epoch: 5| Step: 9
Training loss: 2.7641885766429994
Validation loss: 2.467361208449891

Epoch: 5| Step: 10
Training loss: 2.8910654093343866
Validation loss: 2.46956839456594

Epoch: 5| Step: 11
Training loss: 2.2163958888438646
Validation loss: 2.4642317828864435

Epoch: 224| Step: 0
Training loss: 2.6144307207247315
Validation loss: 2.4790409294000075

Epoch: 5| Step: 1
Training loss: 2.5429144646963575
Validation loss: 2.468214981034044

Epoch: 5| Step: 2
Training loss: 2.7059290459938383
Validation loss: 2.4790244195237285

Epoch: 5| Step: 3
Training loss: 1.983765215559971
Validation loss: 2.4876878191458287

Epoch: 5| Step: 4
Training loss: 2.113099152057996
Validation loss: 2.4864120728933505

Epoch: 5| Step: 5
Training loss: 2.202390940777333
Validation loss: 2.466479947835105

Epoch: 5| Step: 6
Training loss: 2.046447709307206
Validation loss: 2.4670094297546084

Epoch: 5| Step: 7
Training loss: 2.3339729340723774
Validation loss: 2.467139044413262

Epoch: 5| Step: 8
Training loss: 3.094694051334042
Validation loss: 2.472949837706133

Epoch: 5| Step: 9
Training loss: 2.5363126447902284
Validation loss: 2.4810583760489546

Epoch: 5| Step: 10
Training loss: 2.811816831904098
Validation loss: 2.4714827160754083

Epoch: 5| Step: 11
Training loss: 2.2853765919410716
Validation loss: 2.476867805378742

Epoch: 225| Step: 0
Training loss: 2.579467423938924
Validation loss: 2.469016547641895

Epoch: 5| Step: 1
Training loss: 2.0596513438303314
Validation loss: 2.4708798351597228

Epoch: 5| Step: 2
Training loss: 2.4346462074198696
Validation loss: 2.4648503294875588

Epoch: 5| Step: 3
Training loss: 2.408522783459522
Validation loss: 2.4685195984343453

Epoch: 5| Step: 4
Training loss: 2.1163402706210186
Validation loss: 2.4776562302284635

Epoch: 5| Step: 5
Training loss: 2.6961153907758506
Validation loss: 2.4876460607576507

Epoch: 5| Step: 6
Training loss: 2.6605977099620626
Validation loss: 2.4853963731724398

Epoch: 5| Step: 7
Training loss: 2.5769565593239205
Validation loss: 2.4812405764627434

Epoch: 5| Step: 8
Training loss: 2.1872289217152256
Validation loss: 2.475758116062203

Epoch: 5| Step: 9
Training loss: 2.8845451131233073
Validation loss: 2.4779726580519177

Epoch: 5| Step: 10
Training loss: 2.3334404602890273
Validation loss: 2.4749368211600835

Epoch: 5| Step: 11
Training loss: 1.8853797346962484
Validation loss: 2.4756466388470963

Epoch: 226| Step: 0
Training loss: 2.8721033514016887
Validation loss: 2.4738381600890444

Epoch: 5| Step: 1
Training loss: 2.0396687859573404
Validation loss: 2.4726508101834868

Epoch: 5| Step: 2
Training loss: 2.1837933334828774
Validation loss: 2.4733683648953133

Epoch: 5| Step: 3
Training loss: 2.2460962975529033
Validation loss: 2.480125091055155

Epoch: 5| Step: 4
Training loss: 2.92366046717873
Validation loss: 2.4748603755728786

Epoch: 5| Step: 5
Training loss: 1.9206166683752435
Validation loss: 2.47167611043373

Epoch: 5| Step: 6
Training loss: 2.716991864576575
Validation loss: 2.479408413990657

Epoch: 5| Step: 7
Training loss: 2.9428934134736187
Validation loss: 2.4745312572775604

Epoch: 5| Step: 8
Training loss: 2.050823102251512
Validation loss: 2.4700812923063085

Epoch: 5| Step: 9
Training loss: 2.459859751293296
Validation loss: 2.4766407782761943

Epoch: 5| Step: 10
Training loss: 2.263313851008137
Validation loss: 2.4732773830810872

Epoch: 5| Step: 11
Training loss: 1.8767723607755797
Validation loss: 2.469085002655485

Epoch: 227| Step: 0
Training loss: 2.503192960695224
Validation loss: 2.4739513611276993

Epoch: 5| Step: 1
Training loss: 2.3773592223517315
Validation loss: 2.4713724468641782

Epoch: 5| Step: 2
Training loss: 2.633382130021867
Validation loss: 2.4783011429583164

Epoch: 5| Step: 3
Training loss: 2.716272913787437
Validation loss: 2.479456665537837

Epoch: 5| Step: 4
Training loss: 1.945599576916931
Validation loss: 2.481676979865461

Epoch: 5| Step: 5
Training loss: 1.765264491182887
Validation loss: 2.47960475983099

Epoch: 5| Step: 6
Training loss: 2.84467895761318
Validation loss: 2.4792000957981375

Epoch: 5| Step: 7
Training loss: 2.802367374436505
Validation loss: 2.4830249180961337

Epoch: 5| Step: 8
Training loss: 1.8335093572672723
Validation loss: 2.485627396521413

Epoch: 5| Step: 9
Training loss: 2.657128222523365
Validation loss: 2.478810688849443

Epoch: 5| Step: 10
Training loss: 2.4054819838285892
Validation loss: 2.4884078364408855

Epoch: 5| Step: 11
Training loss: 2.301645942206126
Validation loss: 2.470901662215186

Epoch: 228| Step: 0
Training loss: 1.7638536868583512
Validation loss: 2.4720948251362516

Epoch: 5| Step: 1
Training loss: 2.4429096933319885
Validation loss: 2.4801718025983197

Epoch: 5| Step: 2
Training loss: 2.399852720351026
Validation loss: 2.480463056983322

Epoch: 5| Step: 3
Training loss: 2.4402382948471297
Validation loss: 2.4738985650053964

Epoch: 5| Step: 4
Training loss: 2.462880266910465
Validation loss: 2.4828298510102615

Epoch: 5| Step: 5
Training loss: 2.5140424216673662
Validation loss: 2.47009082791285

Epoch: 5| Step: 6
Training loss: 3.1302367011809062
Validation loss: 2.4758214112500534

Epoch: 5| Step: 7
Training loss: 2.8730287843052977
Validation loss: 2.4959111273735735

Epoch: 5| Step: 8
Training loss: 2.091099442046188
Validation loss: 2.484405985225131

Epoch: 5| Step: 9
Training loss: 2.2438417506253345
Validation loss: 2.4935891804670294

Epoch: 5| Step: 10
Training loss: 2.294909408210819
Validation loss: 2.492816749943093

Epoch: 5| Step: 11
Training loss: 1.7932939089136917
Validation loss: 2.4879196838512234

Epoch: 229| Step: 0
Training loss: 2.657665458975884
Validation loss: 2.4909068517299393

Epoch: 5| Step: 1
Training loss: 2.379563514850931
Validation loss: 2.5016726342315794

Epoch: 5| Step: 2
Training loss: 2.0841136488284198
Validation loss: 2.480700232250093

Epoch: 5| Step: 3
Training loss: 2.565632928610665
Validation loss: 2.4728029678632155

Epoch: 5| Step: 4
Training loss: 2.206464036279766
Validation loss: 2.473536595319237

Epoch: 5| Step: 5
Training loss: 1.9404417286207931
Validation loss: 2.469898081663921

Epoch: 5| Step: 6
Training loss: 1.9861247240798954
Validation loss: 2.473050532511279

Epoch: 5| Step: 7
Training loss: 3.1578816643661836
Validation loss: 2.474253150372367

Epoch: 5| Step: 8
Training loss: 2.62545463621331
Validation loss: 2.4843026796447054

Epoch: 5| Step: 9
Training loss: 2.599181864470723
Validation loss: 2.4835520486929594

Epoch: 5| Step: 10
Training loss: 2.513991874238617
Validation loss: 2.4899020383388044

Epoch: 5| Step: 11
Training loss: 1.9421196285059843
Validation loss: 2.4842287856287033

Epoch: 230| Step: 0
Training loss: 2.540127950284138
Validation loss: 2.5021960448024725

Epoch: 5| Step: 1
Training loss: 2.7859197268344316
Validation loss: 2.489720685247793

Epoch: 5| Step: 2
Training loss: 2.079321380648556
Validation loss: 2.500983493789865

Epoch: 5| Step: 3
Training loss: 1.9476740340894845
Validation loss: 2.5040333240021218

Epoch: 5| Step: 4
Training loss: 2.326202418001099
Validation loss: 2.530785463037619

Epoch: 5| Step: 5
Training loss: 2.2134143987234007
Validation loss: 2.5031825153856517

Epoch: 5| Step: 6
Training loss: 2.513480178411854
Validation loss: 2.4988735800508763

Epoch: 5| Step: 7
Training loss: 2.6806576588038267
Validation loss: 2.4881083150401793

Epoch: 5| Step: 8
Training loss: 2.4173161083448673
Validation loss: 2.4835167848001785

Epoch: 5| Step: 9
Training loss: 2.78789677554448
Validation loss: 2.4697144290479707

Epoch: 5| Step: 10
Training loss: 2.591031223746483
Validation loss: 2.4731740986800435

Epoch: 5| Step: 11
Training loss: 2.029142019551676
Validation loss: 2.4716631967795006

Epoch: 231| Step: 0
Training loss: 2.403081020949879
Validation loss: 2.4742914310207653

Epoch: 5| Step: 1
Training loss: 2.8220459743677657
Validation loss: 2.4685771937993897

Epoch: 5| Step: 2
Training loss: 2.222965802189192
Validation loss: 2.4768873176201045

Epoch: 5| Step: 3
Training loss: 2.303000553656117
Validation loss: 2.473757986020817

Epoch: 5| Step: 4
Training loss: 2.6070524375450095
Validation loss: 2.475869058624959

Epoch: 5| Step: 5
Training loss: 2.270119359411602
Validation loss: 2.4783274341398456

Epoch: 5| Step: 6
Training loss: 2.4208998162687685
Validation loss: 2.493019152587746

Epoch: 5| Step: 7
Training loss: 2.7501177329090547
Validation loss: 2.471633530890026

Epoch: 5| Step: 8
Training loss: 2.4166114954296085
Validation loss: 2.491926576195279

Epoch: 5| Step: 9
Training loss: 2.5064788789953147
Validation loss: 2.495268401200356

Epoch: 5| Step: 10
Training loss: 2.374421400564204
Validation loss: 2.5117592697078814

Epoch: 5| Step: 11
Training loss: 1.3904550855749425
Validation loss: 2.5259345605435035

Epoch: 232| Step: 0
Training loss: 2.3077522202808476
Validation loss: 2.517668143143514

Epoch: 5| Step: 1
Training loss: 2.9088828353812373
Validation loss: 2.5188648969129526

Epoch: 5| Step: 2
Training loss: 2.2323699704842004
Validation loss: 2.5056507898914275

Epoch: 5| Step: 3
Training loss: 2.62731078028233
Validation loss: 2.4902305333724963

Epoch: 5| Step: 4
Training loss: 2.764493894148383
Validation loss: 2.499936269901501

Epoch: 5| Step: 5
Training loss: 2.4258949633987874
Validation loss: 2.4899136564880306

Epoch: 5| Step: 6
Training loss: 1.8398990177349506
Validation loss: 2.476179207584701

Epoch: 5| Step: 7
Training loss: 2.8639105174294923
Validation loss: 2.4755109847119203

Epoch: 5| Step: 8
Training loss: 2.0317829313279017
Validation loss: 2.4816618325365924

Epoch: 5| Step: 9
Training loss: 2.3673370616234988
Validation loss: 2.471964487753952

Epoch: 5| Step: 10
Training loss: 2.2659899187528723
Validation loss: 2.475505553175044

Epoch: 5| Step: 11
Training loss: 2.180491637516759
Validation loss: 2.4667205718203227

Epoch: 233| Step: 0
Training loss: 2.318914949457216
Validation loss: 2.4838682973508672

Epoch: 5| Step: 1
Training loss: 2.146401956518805
Validation loss: 2.474559250514389

Epoch: 5| Step: 2
Training loss: 2.357845593846507
Validation loss: 2.481169477993095

Epoch: 5| Step: 3
Training loss: 2.53227938219232
Validation loss: 2.4900531298932482

Epoch: 5| Step: 4
Training loss: 2.3010003029343573
Validation loss: 2.487828499462602

Epoch: 5| Step: 5
Training loss: 2.1276877739742
Validation loss: 2.489101667908191

Epoch: 5| Step: 6
Training loss: 1.788139938297427
Validation loss: 2.4846526856450852

Epoch: 5| Step: 7
Training loss: 2.4662287911974032
Validation loss: 2.478104599623795

Epoch: 5| Step: 8
Training loss: 2.411281724783401
Validation loss: 2.486159135859585

Epoch: 5| Step: 9
Training loss: 2.9740931563317017
Validation loss: 2.489626266928626

Epoch: 5| Step: 10
Training loss: 2.8396558528902767
Validation loss: 2.4877648848326426

Epoch: 5| Step: 11
Training loss: 3.444181157034029
Validation loss: 2.5002501918849993

Epoch: 234| Step: 0
Training loss: 2.1560516266170864
Validation loss: 2.5094652918956344

Epoch: 5| Step: 1
Training loss: 2.375818914474287
Validation loss: 2.5019082971905187

Epoch: 5| Step: 2
Training loss: 2.1023002379020945
Validation loss: 2.490547545444013

Epoch: 5| Step: 3
Training loss: 3.105200644381956
Validation loss: 2.489660231281853

Epoch: 5| Step: 4
Training loss: 2.6248689346290632
Validation loss: 2.4839632544809644

Epoch: 5| Step: 5
Training loss: 2.322730759735286
Validation loss: 2.4845180270372103

Epoch: 5| Step: 6
Training loss: 3.09223515578408
Validation loss: 2.483032611639165

Epoch: 5| Step: 7
Training loss: 2.355174588739617
Validation loss: 2.4895113864116536

Epoch: 5| Step: 8
Training loss: 2.4269759082077837
Validation loss: 2.4666488131852176

Epoch: 5| Step: 9
Training loss: 2.046599274912295
Validation loss: 2.470181927094374

Epoch: 5| Step: 10
Training loss: 2.155349543428608
Validation loss: 2.4688536143389146

Epoch: 5| Step: 11
Training loss: 2.102447436896949
Validation loss: 2.4685544447565864

Epoch: 235| Step: 0
Training loss: 2.1121321002294295
Validation loss: 2.4690825001017185

Epoch: 5| Step: 1
Training loss: 2.085194430353661
Validation loss: 2.4653814085072

Epoch: 5| Step: 2
Training loss: 2.160344976144919
Validation loss: 2.4695654459919574

Epoch: 5| Step: 3
Training loss: 2.3981160995401742
Validation loss: 2.4735631660609414

Epoch: 5| Step: 4
Training loss: 3.040585173201962
Validation loss: 2.468788496755481

Epoch: 5| Step: 5
Training loss: 2.0813541420664734
Validation loss: 2.4750176694830097

Epoch: 5| Step: 6
Training loss: 2.6851834803852306
Validation loss: 2.4659249724785095

Epoch: 5| Step: 7
Training loss: 2.6986177827110507
Validation loss: 2.4848745831426

Epoch: 5| Step: 8
Training loss: 2.0755371961024416
Validation loss: 2.4776723603048416

Epoch: 5| Step: 9
Training loss: 2.7003012665694945
Validation loss: 2.4755632448379

Epoch: 5| Step: 10
Training loss: 2.5169919487964987
Validation loss: 2.4991734886860715

Epoch: 5| Step: 11
Training loss: 2.895518846153092
Validation loss: 2.5153071872097255

Epoch: 236| Step: 0
Training loss: 2.5356743845880056
Validation loss: 2.5068021067867896

Epoch: 5| Step: 1
Training loss: 2.847628955684095
Validation loss: 2.500336854810752

Epoch: 5| Step: 2
Training loss: 2.427293389089236
Validation loss: 2.48457944576589

Epoch: 5| Step: 3
Training loss: 2.433252791373826
Validation loss: 2.476291689822681

Epoch: 5| Step: 4
Training loss: 2.213469117415565
Validation loss: 2.468200256206247

Epoch: 5| Step: 5
Training loss: 2.122244113733759
Validation loss: 2.4726088219503852

Epoch: 5| Step: 6
Training loss: 2.9368829281950175
Validation loss: 2.482693206901295

Epoch: 5| Step: 7
Training loss: 2.662217561310495
Validation loss: 2.4807954908420613

Epoch: 5| Step: 8
Training loss: 2.3885591843754685
Validation loss: 2.4717771907059465

Epoch: 5| Step: 9
Training loss: 2.3708771507714803
Validation loss: 2.4689526092507577

Epoch: 5| Step: 10
Training loss: 2.126033531620723
Validation loss: 2.467837454747075

Epoch: 5| Step: 11
Training loss: 2.01887581259011
Validation loss: 2.477269706473684

Epoch: 237| Step: 0
Training loss: 2.6449230360288585
Validation loss: 2.4734614679746065

Epoch: 5| Step: 1
Training loss: 2.1665631660780633
Validation loss: 2.471300795166059

Epoch: 5| Step: 2
Training loss: 2.8757455937072325
Validation loss: 2.471789070883173

Epoch: 5| Step: 3
Training loss: 2.3138962731683064
Validation loss: 2.48730705589618

Epoch: 5| Step: 4
Training loss: 2.448034362127946
Validation loss: 2.485862202825718

Epoch: 5| Step: 5
Training loss: 2.743718429070972
Validation loss: 2.4842715611706616

Epoch: 5| Step: 6
Training loss: 2.2316316422479154
Validation loss: 2.4819085175361084

Epoch: 5| Step: 7
Training loss: 2.1312678406267924
Validation loss: 2.4878964049174876

Epoch: 5| Step: 8
Training loss: 2.2871086452883658
Validation loss: 2.4945359679704255

Epoch: 5| Step: 9
Training loss: 2.740005102918565
Validation loss: 2.5027000072809344

Epoch: 5| Step: 10
Training loss: 2.0315120821383927
Validation loss: 2.489599009721207

Epoch: 5| Step: 11
Training loss: 1.3796712682164474
Validation loss: 2.498413424905707

Epoch: 238| Step: 0
Training loss: 2.035780446691177
Validation loss: 2.483541152779543

Epoch: 5| Step: 1
Training loss: 2.2745552592429696
Validation loss: 2.4995640016882783

Epoch: 5| Step: 2
Training loss: 2.2480293757124623
Validation loss: 2.478358118189428

Epoch: 5| Step: 3
Training loss: 2.9249320128274925
Validation loss: 2.4812079341983577

Epoch: 5| Step: 4
Training loss: 2.5782867380907613
Validation loss: 2.4864681870694487

Epoch: 5| Step: 5
Training loss: 2.956691142872935
Validation loss: 2.473594913224963

Epoch: 5| Step: 6
Training loss: 1.8839006880321914
Validation loss: 2.4800898585460285

Epoch: 5| Step: 7
Training loss: 2.54774310523399
Validation loss: 2.478683842731413

Epoch: 5| Step: 8
Training loss: 2.418887751005683
Validation loss: 2.4864531648153587

Epoch: 5| Step: 9
Training loss: 2.5870692608692694
Validation loss: 2.477457937582193

Epoch: 5| Step: 10
Training loss: 2.0308595722284237
Validation loss: 2.4842073755875442

Epoch: 5| Step: 11
Training loss: 1.1052383883767345
Validation loss: 2.49607367947767

Epoch: 239| Step: 0
Training loss: 2.188946708758946
Validation loss: 2.502813885515699

Epoch: 5| Step: 1
Training loss: 2.6067975500505334
Validation loss: 2.515932522412943

Epoch: 5| Step: 2
Training loss: 3.1545219600902916
Validation loss: 2.507305299959307

Epoch: 5| Step: 3
Training loss: 1.9988403534640966
Validation loss: 2.546662464127976

Epoch: 5| Step: 4
Training loss: 2.707756881010582
Validation loss: 2.6220003806603

Epoch: 5| Step: 5
Training loss: 2.4933392485210133
Validation loss: 2.607504000662212

Epoch: 5| Step: 6
Training loss: 2.6485541664016012
Validation loss: 2.5907023000746046

Epoch: 5| Step: 7
Training loss: 2.4409355014904683
Validation loss: 2.525978352385723

Epoch: 5| Step: 8
Training loss: 2.367749540879732
Validation loss: 2.503295439093862

Epoch: 5| Step: 9
Training loss: 2.385444663159746
Validation loss: 2.485034335313042

Epoch: 5| Step: 10
Training loss: 2.1487298939881008
Validation loss: 2.4739087083089104

Epoch: 5| Step: 11
Training loss: 2.536885710527056
Validation loss: 2.4799543312890022

Epoch: 240| Step: 0
Training loss: 1.8765845914456716
Validation loss: 2.479064588021331

Epoch: 5| Step: 1
Training loss: 2.299333981819242
Validation loss: 2.4785549079541536

Epoch: 5| Step: 2
Training loss: 2.5868631878491226
Validation loss: 2.4881785724401126

Epoch: 5| Step: 3
Training loss: 1.880336035057651
Validation loss: 2.4766424709689554

Epoch: 5| Step: 4
Training loss: 2.818659163066557
Validation loss: 2.4860389942907237

Epoch: 5| Step: 5
Training loss: 2.816134922539583
Validation loss: 2.4883008124731814

Epoch: 5| Step: 6
Training loss: 3.0140202655275465
Validation loss: 2.483279976548932

Epoch: 5| Step: 7
Training loss: 2.9545523610067677
Validation loss: 2.479311699725511

Epoch: 5| Step: 8
Training loss: 2.7863665889479385
Validation loss: 2.4764029955918287

Epoch: 5| Step: 9
Training loss: 2.463413893845315
Validation loss: 2.471300730849436

Epoch: 5| Step: 10
Training loss: 2.368435269586379
Validation loss: 2.477527258011229

Epoch: 5| Step: 11
Training loss: 2.0122830386525963
Validation loss: 2.468246328102775

Epoch: 241| Step: 0
Training loss: 2.4842667466096606
Validation loss: 2.465415505396127

Epoch: 5| Step: 1
Training loss: 3.0188206950690284
Validation loss: 2.473021791104262

Epoch: 5| Step: 2
Training loss: 1.886623846158993
Validation loss: 2.4758127282949145

Epoch: 5| Step: 3
Training loss: 1.952169993569237
Validation loss: 2.465499693922164

Epoch: 5| Step: 4
Training loss: 2.4477579484712533
Validation loss: 2.471159330726565

Epoch: 5| Step: 5
Training loss: 2.5104720134622487
Validation loss: 2.467782281583762

Epoch: 5| Step: 6
Training loss: 2.513996426393917
Validation loss: 2.470128945840733

Epoch: 5| Step: 7
Training loss: 2.8242576670306647
Validation loss: 2.4929391749823475

Epoch: 5| Step: 8
Training loss: 2.4742566273532964
Validation loss: 2.4800469107382694

Epoch: 5| Step: 9
Training loss: 2.394242286359811
Validation loss: 2.499878492978834

Epoch: 5| Step: 10
Training loss: 2.4821019360422207
Validation loss: 2.48990302779868

Epoch: 5| Step: 11
Training loss: 2.222242802948487
Validation loss: 2.4920666465036905

Epoch: 242| Step: 0
Training loss: 2.224932800306865
Validation loss: 2.5125259201964902

Epoch: 5| Step: 1
Training loss: 2.453359604812328
Validation loss: 2.48854603698483

Epoch: 5| Step: 2
Training loss: 2.437443659204634
Validation loss: 2.499706360340879

Epoch: 5| Step: 3
Training loss: 2.475826310445591
Validation loss: 2.4908569475226394

Epoch: 5| Step: 4
Training loss: 2.580010851460192
Validation loss: 2.503698256052043

Epoch: 5| Step: 5
Training loss: 2.408549609477346
Validation loss: 2.487205256758861

Epoch: 5| Step: 6
Training loss: 2.3269608422408017
Validation loss: 2.484542441173667

Epoch: 5| Step: 7
Training loss: 2.2551117157594254
Validation loss: 2.4827346464658095

Epoch: 5| Step: 8
Training loss: 2.4256953471479665
Validation loss: 2.4837055903897562

Epoch: 5| Step: 9
Training loss: 3.030941662394683
Validation loss: 2.4690420303973624

Epoch: 5| Step: 10
Training loss: 2.1999997095628028
Validation loss: 2.4879596408545557

Epoch: 5| Step: 11
Training loss: 2.92515926090532
Validation loss: 2.4811303765698343

Epoch: 243| Step: 0
Training loss: 2.5536783540882584
Validation loss: 2.4813700322633805

Epoch: 5| Step: 1
Training loss: 3.1048993434347154
Validation loss: 2.469714511506573

Epoch: 5| Step: 2
Training loss: 2.115880358567672
Validation loss: 2.4796037782806843

Epoch: 5| Step: 3
Training loss: 2.922155356599061
Validation loss: 2.482386571041353

Epoch: 5| Step: 4
Training loss: 2.2636431214133172
Validation loss: 2.485933694570823

Epoch: 5| Step: 5
Training loss: 2.265404210349025
Validation loss: 2.486155989192719

Epoch: 5| Step: 6
Training loss: 2.652995910020214
Validation loss: 2.476662686925782

Epoch: 5| Step: 7
Training loss: 2.8287705164227304
Validation loss: 2.490345532298787

Epoch: 5| Step: 8
Training loss: 2.17651486313852
Validation loss: 2.504220392335289

Epoch: 5| Step: 9
Training loss: 1.922252710954449
Validation loss: 2.5218378947449964

Epoch: 5| Step: 10
Training loss: 1.5167560879402973
Validation loss: 2.510097975439827

Epoch: 5| Step: 11
Training loss: 2.254311668917245
Validation loss: 2.518601522494625

Epoch: 244| Step: 0
Training loss: 2.009755778682452
Validation loss: 2.5145050185702083

Epoch: 5| Step: 1
Training loss: 2.599653580402232
Validation loss: 2.5256247749948404

Epoch: 5| Step: 2
Training loss: 2.0944715936027136
Validation loss: 2.5156775601347747

Epoch: 5| Step: 3
Training loss: 2.4834043898006724
Validation loss: 2.500068270227961

Epoch: 5| Step: 4
Training loss: 2.5584452112775224
Validation loss: 2.5007469213819458

Epoch: 5| Step: 5
Training loss: 2.563117162305992
Validation loss: 2.5053808875875414

Epoch: 5| Step: 6
Training loss: 1.917230094803354
Validation loss: 2.4961393468569537

Epoch: 5| Step: 7
Training loss: 2.7432004791047975
Validation loss: 2.4829821210776486

Epoch: 5| Step: 8
Training loss: 2.9057876054998184
Validation loss: 2.49166509480464

Epoch: 5| Step: 9
Training loss: 2.5597376006472774
Validation loss: 2.503567228808682

Epoch: 5| Step: 10
Training loss: 1.9025916969969061
Validation loss: 2.4804939929548784

Epoch: 5| Step: 11
Training loss: 1.854743446335434
Validation loss: 2.483517204801848

Epoch: 245| Step: 0
Training loss: 2.765311185629773
Validation loss: 2.4970461024071864

Epoch: 5| Step: 1
Training loss: 2.1691248105388192
Validation loss: 2.4881883501070554

Epoch: 5| Step: 2
Training loss: 2.222139590104581
Validation loss: 2.4844197203251954

Epoch: 5| Step: 3
Training loss: 2.7428212533884797
Validation loss: 2.4817979150010325

Epoch: 5| Step: 4
Training loss: 2.454972075946437
Validation loss: 2.4869044920144154

Epoch: 5| Step: 5
Training loss: 2.5351001045581247
Validation loss: 2.4784673230670355

Epoch: 5| Step: 6
Training loss: 2.041701089477996
Validation loss: 2.4920789681044386

Epoch: 5| Step: 7
Training loss: 2.483290141538638
Validation loss: 2.5083035298305743

Epoch: 5| Step: 8
Training loss: 2.202137177770549
Validation loss: 2.506863625480889

Epoch: 5| Step: 9
Training loss: 2.6131206742519804
Validation loss: 2.498324194162545

Epoch: 5| Step: 10
Training loss: 2.313457187814608
Validation loss: 2.494331609453218

Epoch: 5| Step: 11
Training loss: 1.5081758209657787
Validation loss: 2.4929162836326912

Epoch: 246| Step: 0
Training loss: 2.3313929005206093
Validation loss: 2.4964813982092715

Epoch: 5| Step: 1
Training loss: 2.1413522863147074
Validation loss: 2.499171328295941

Epoch: 5| Step: 2
Training loss: 2.1110710954498773
Validation loss: 2.473508369617736

Epoch: 5| Step: 3
Training loss: 1.7719740690224115
Validation loss: 2.4790400297748727

Epoch: 5| Step: 4
Training loss: 2.9180061715827503
Validation loss: 2.486673203799354

Epoch: 5| Step: 5
Training loss: 3.097536486394615
Validation loss: 2.4807002562774394

Epoch: 5| Step: 6
Training loss: 2.102631024282121
Validation loss: 2.480473852277499

Epoch: 5| Step: 7
Training loss: 2.682884600142064
Validation loss: 2.481578892867169

Epoch: 5| Step: 8
Training loss: 1.9756936436632706
Validation loss: 2.478617412299724

Epoch: 5| Step: 9
Training loss: 2.8409834598864077
Validation loss: 2.4761704095395913

Epoch: 5| Step: 10
Training loss: 2.520218062124379
Validation loss: 2.480529195694827

Epoch: 5| Step: 11
Training loss: 1.4053505458181847
Validation loss: 2.479147631841936

Epoch: 247| Step: 0
Training loss: 2.148940592729716
Validation loss: 2.483805785158215

Epoch: 5| Step: 1
Training loss: 2.546908887391983
Validation loss: 2.4754982194777893

Epoch: 5| Step: 2
Training loss: 2.0938562394702753
Validation loss: 2.490905531652298

Epoch: 5| Step: 3
Training loss: 2.3855463073240073
Validation loss: 2.4949117278567665

Epoch: 5| Step: 4
Training loss: 3.1904237091503522
Validation loss: 2.502874291668109

Epoch: 5| Step: 5
Training loss: 2.3442285684909963
Validation loss: 2.495787023126344

Epoch: 5| Step: 6
Training loss: 2.379935507020752
Validation loss: 2.514897002246598

Epoch: 5| Step: 7
Training loss: 2.3801624007074507
Validation loss: 2.525697666354137

Epoch: 5| Step: 8
Training loss: 2.560033401927001
Validation loss: 2.5129778382307904

Epoch: 5| Step: 9
Training loss: 2.0829137252397163
Validation loss: 2.495362265657309

Epoch: 5| Step: 10
Training loss: 2.24504922213894
Validation loss: 2.4933259052044416

Epoch: 5| Step: 11
Training loss: 1.833045402226785
Validation loss: 2.487083264447445

Epoch: 248| Step: 0
Training loss: 2.6292550250973203
Validation loss: 2.478896688672692

Epoch: 5| Step: 1
Training loss: 2.779441931578943
Validation loss: 2.4909669484210073

Epoch: 5| Step: 2
Training loss: 2.8045725679358626
Validation loss: 2.480206154768007

Epoch: 5| Step: 3
Training loss: 2.1335579823387656
Validation loss: 2.476803556277086

Epoch: 5| Step: 4
Training loss: 2.3046396024220366
Validation loss: 2.4827482547694335

Epoch: 5| Step: 5
Training loss: 3.02324098249015
Validation loss: 2.4847841745583845

Epoch: 5| Step: 6
Training loss: 1.9898305076994216
Validation loss: 2.4775752334450347

Epoch: 5| Step: 7
Training loss: 1.7979329850689174
Validation loss: 2.4859648122192244

Epoch: 5| Step: 8
Training loss: 1.779678521539749
Validation loss: 2.4975360251581944

Epoch: 5| Step: 9
Training loss: 2.933041374531207
Validation loss: 2.491990084587075

Epoch: 5| Step: 10
Training loss: 2.1748445915737427
Validation loss: 2.5068494347849333

Epoch: 5| Step: 11
Training loss: 1.624192550763476
Validation loss: 2.5213363174555807

Epoch: 249| Step: 0
Training loss: 2.636110136645822
Validation loss: 2.5282764590632327

Epoch: 5| Step: 1
Training loss: 1.8777162586319873
Validation loss: 2.529905087508834

Epoch: 5| Step: 2
Training loss: 2.562855207433697
Validation loss: 2.4992352229826853

Epoch: 5| Step: 3
Training loss: 2.261902164276085
Validation loss: 2.503625120983679

Epoch: 5| Step: 4
Training loss: 2.622070676210403
Validation loss: 2.5036634465336

Epoch: 5| Step: 5
Training loss: 2.7116691195760776
Validation loss: 2.5102012602538935

Epoch: 5| Step: 6
Training loss: 2.6006212335956698
Validation loss: 2.498503648456019

Epoch: 5| Step: 7
Training loss: 2.4234377833353316
Validation loss: 2.50142829943284

Epoch: 5| Step: 8
Training loss: 1.6807279691011197
Validation loss: 2.4953282296248878

Epoch: 5| Step: 9
Training loss: 2.4044953922030063
Validation loss: 2.5008912166882498

Epoch: 5| Step: 10
Training loss: 2.6085810567039185
Validation loss: 2.4829211309509893

Epoch: 5| Step: 11
Training loss: 2.581878426742773
Validation loss: 2.489612025863046

Epoch: 250| Step: 0
Training loss: 2.444263367255726
Validation loss: 2.4830730353550248

Epoch: 5| Step: 1
Training loss: 2.857558210018655
Validation loss: 2.484403366150851

Epoch: 5| Step: 2
Training loss: 2.5674041712334263
Validation loss: 2.4849630455618397

Epoch: 5| Step: 3
Training loss: 2.1872939966476834
Validation loss: 2.479020123732069

Epoch: 5| Step: 4
Training loss: 2.4648884377758664
Validation loss: 2.495204275543624

Epoch: 5| Step: 5
Training loss: 2.466870908615396
Validation loss: 2.4977854476826176

Epoch: 5| Step: 6
Training loss: 2.7104584988047087
Validation loss: 2.496340700130856

Epoch: 5| Step: 7
Training loss: 2.1158268346257247
Validation loss: 2.493492319024215

Epoch: 5| Step: 8
Training loss: 1.935887496339412
Validation loss: 2.521290049413713

Epoch: 5| Step: 9
Training loss: 1.8419451527460005
Validation loss: 2.4984736054471464

Epoch: 5| Step: 10
Training loss: 2.74715788234158
Validation loss: 2.5268769636483857

Epoch: 5| Step: 11
Training loss: 1.8017730298730688
Validation loss: 2.4986346132265047

Epoch: 251| Step: 0
Training loss: 2.361354578467932
Validation loss: 2.4926362545455105

Epoch: 5| Step: 1
Training loss: 2.1691247006241734
Validation loss: 2.4859799692940756

Epoch: 5| Step: 2
Training loss: 2.3501082578031967
Validation loss: 2.487692329584848

Epoch: 5| Step: 3
Training loss: 1.9701563338392325
Validation loss: 2.4789816796718522

Epoch: 5| Step: 4
Training loss: 1.9451926933684762
Validation loss: 2.4976120014266394

Epoch: 5| Step: 5
Training loss: 2.4352086374560753
Validation loss: 2.486056992020508

Epoch: 5| Step: 6
Training loss: 2.3575728651742054
Validation loss: 2.4890360623073344

Epoch: 5| Step: 7
Training loss: 2.672113865219353
Validation loss: 2.4830230137105067

Epoch: 5| Step: 8
Training loss: 2.3622663352095494
Validation loss: 2.4920663036824813

Epoch: 5| Step: 9
Training loss: 2.958362758293134
Validation loss: 2.4961849190027103

Epoch: 5| Step: 10
Training loss: 2.4897194243919984
Validation loss: 2.487949287312711

Epoch: 5| Step: 11
Training loss: 3.4539294104240725
Validation loss: 2.5037099807951293

Epoch: 252| Step: 0
Training loss: 2.168683678220316
Validation loss: 2.5066900543971684

Epoch: 5| Step: 1
Training loss: 1.9555247708387673
Validation loss: 2.4965701417212736

Epoch: 5| Step: 2
Training loss: 2.582299661463684
Validation loss: 2.4987800522358814

Epoch: 5| Step: 3
Training loss: 2.8096404903850565
Validation loss: 2.4940839346285766

Epoch: 5| Step: 4
Training loss: 2.427604837560053
Validation loss: 2.494912177794145

Epoch: 5| Step: 5
Training loss: 2.822825572290709
Validation loss: 2.5165101857410304

Epoch: 5| Step: 6
Training loss: 2.322354943023197
Validation loss: 2.5101254612189754

Epoch: 5| Step: 7
Training loss: 2.823637463276285
Validation loss: 2.4901609063374743

Epoch: 5| Step: 8
Training loss: 1.6440714648694261
Validation loss: 2.498333450991335

Epoch: 5| Step: 9
Training loss: 2.2394985330776582
Validation loss: 2.5041001195734585

Epoch: 5| Step: 10
Training loss: 2.3837839616457615
Validation loss: 2.4881233552494346

Epoch: 5| Step: 11
Training loss: 1.1903853748513946
Validation loss: 2.4964427793520665

Epoch: 253| Step: 0
Training loss: 1.7497298168332398
Validation loss: 2.4975550656808028

Epoch: 5| Step: 1
Training loss: 1.992336970687149
Validation loss: 2.4932010746006714

Epoch: 5| Step: 2
Training loss: 2.5390701998080365
Validation loss: 2.506065635685977

Epoch: 5| Step: 3
Training loss: 2.692920983856186
Validation loss: 2.4999208954375907

Epoch: 5| Step: 4
Training loss: 2.255081690050826
Validation loss: 2.5087784702210563

Epoch: 5| Step: 5
Training loss: 2.9223020516899063
Validation loss: 2.5045203826038334

Epoch: 5| Step: 6
Training loss: 2.364219088514966
Validation loss: 2.510284560171654

Epoch: 5| Step: 7
Training loss: 2.13012996115923
Validation loss: 2.5229992008543114

Epoch: 5| Step: 8
Training loss: 2.5021324599686974
Validation loss: 2.5165076553455163

Epoch: 5| Step: 9
Training loss: 2.268938154504989
Validation loss: 2.5215926301008365

Epoch: 5| Step: 10
Training loss: 2.6621937392056796
Validation loss: 2.532735267166054

Epoch: 5| Step: 11
Training loss: 1.545776670844964
Validation loss: 2.530191027311335

Epoch: 254| Step: 0
Training loss: 2.1604938484709937
Validation loss: 2.5134665151639264

Epoch: 5| Step: 1
Training loss: 2.496034337920186
Validation loss: 2.504265964198086

Epoch: 5| Step: 2
Training loss: 2.466340059703872
Validation loss: 2.489329561895818

Epoch: 5| Step: 3
Training loss: 2.4255483027114964
Validation loss: 2.5048886027030624

Epoch: 5| Step: 4
Training loss: 2.5981588924235446
Validation loss: 2.49755219787793

Epoch: 5| Step: 5
Training loss: 2.4201282724165574
Validation loss: 2.501545990320163

Epoch: 5| Step: 6
Training loss: 2.072909586780924
Validation loss: 2.4936994233575653

Epoch: 5| Step: 7
Training loss: 2.328589169102857
Validation loss: 2.5077807779969783

Epoch: 5| Step: 8
Training loss: 2.130771428853654
Validation loss: 2.501120602274181

Epoch: 5| Step: 9
Training loss: 1.8354505826635994
Validation loss: 2.503767611771295

Epoch: 5| Step: 10
Training loss: 3.0523758749129324
Validation loss: 2.5002771422629957

Epoch: 5| Step: 11
Training loss: 2.0387274806721956
Validation loss: 2.5118414461771237

Epoch: 255| Step: 0
Training loss: 2.127307984846138
Validation loss: 2.5172803696293626

Epoch: 5| Step: 1
Training loss: 2.6671505032137226
Validation loss: 2.517940363978933

Epoch: 5| Step: 2
Training loss: 2.1773024331652984
Validation loss: 2.5106634332666764

Epoch: 5| Step: 3
Training loss: 2.2555788600617626
Validation loss: 2.5089179481432713

Epoch: 5| Step: 4
Training loss: 2.3408833583956135
Validation loss: 2.492261173988936

Epoch: 5| Step: 5
Training loss: 2.775016571545308
Validation loss: 2.499946494324635

Epoch: 5| Step: 6
Training loss: 2.5099752731929046
Validation loss: 2.5169755773449385

Epoch: 5| Step: 7
Training loss: 2.2140355056700045
Validation loss: 2.504731255123543

Epoch: 5| Step: 8
Training loss: 2.436478816600439
Validation loss: 2.497352978945621

Epoch: 5| Step: 9
Training loss: 2.141240831879932
Validation loss: 2.497901854631564

Epoch: 5| Step: 10
Training loss: 2.273464032310007
Validation loss: 2.5369888758657937

Epoch: 5| Step: 11
Training loss: 2.6508114957784388
Validation loss: 2.533738526034617

Epoch: 256| Step: 0
Training loss: 2.4071422755591194
Validation loss: 2.5678849975186315

Epoch: 5| Step: 1
Training loss: 2.820979411983447
Validation loss: 2.6167509559451507

Epoch: 5| Step: 2
Training loss: 2.4555451913138295
Validation loss: 2.588169206703707

Epoch: 5| Step: 3
Training loss: 1.8583728429702635
Validation loss: 2.5475338510766825

Epoch: 5| Step: 4
Training loss: 2.7555698861839892
Validation loss: 2.526724950395808

Epoch: 5| Step: 5
Training loss: 2.466999350700401
Validation loss: 2.500143297380141

Epoch: 5| Step: 6
Training loss: 2.2852112331459504
Validation loss: 2.5047894733728917

Epoch: 5| Step: 7
Training loss: 2.5698289039448787
Validation loss: 2.4930656145708134

Epoch: 5| Step: 8
Training loss: 2.6600632168134366
Validation loss: 2.5001548301912555

Epoch: 5| Step: 9
Training loss: 2.6962773019878887
Validation loss: 2.488395774118139

Epoch: 5| Step: 10
Training loss: 1.7582623393595194
Validation loss: 2.48853196139151

Epoch: 5| Step: 11
Training loss: 3.4621214897307926
Validation loss: 2.481564001142087

Epoch: 257| Step: 0
Training loss: 2.7650168229707095
Validation loss: 2.4935490507333697

Epoch: 5| Step: 1
Training loss: 2.104609552991821
Validation loss: 2.4857061726443472

Epoch: 5| Step: 2
Training loss: 2.519479582500756
Validation loss: 2.487807068490006

Epoch: 5| Step: 3
Training loss: 2.2301901728534914
Validation loss: 2.487200228201646

Epoch: 5| Step: 4
Training loss: 2.771023755712701
Validation loss: 2.480541049974905

Epoch: 5| Step: 5
Training loss: 2.552156927384096
Validation loss: 2.4965093880513853

Epoch: 5| Step: 6
Training loss: 2.2684906824470046
Validation loss: 2.4942300532038146

Epoch: 5| Step: 7
Training loss: 1.8961765970646984
Validation loss: 2.5117069637641025

Epoch: 5| Step: 8
Training loss: 2.401169404599042
Validation loss: 2.513351803398903

Epoch: 5| Step: 9
Training loss: 2.264915934133138
Validation loss: 2.534915679504904

Epoch: 5| Step: 10
Training loss: 2.6657234450985894
Validation loss: 2.5394020205690775

Epoch: 5| Step: 11
Training loss: 1.8156735490883626
Validation loss: 2.5229833920635647

Epoch: 258| Step: 0
Training loss: 1.8875105244930481
Validation loss: 2.5198182526587187

Epoch: 5| Step: 1
Training loss: 2.135255636951191
Validation loss: 2.540128568201353

Epoch: 5| Step: 2
Training loss: 2.1418633881502656
Validation loss: 2.5179378310753386

Epoch: 5| Step: 3
Training loss: 2.7425946316523184
Validation loss: 2.5168844509839334

Epoch: 5| Step: 4
Training loss: 2.634606901666006
Validation loss: 2.5079310538690542

Epoch: 5| Step: 5
Training loss: 2.3399242457329774
Validation loss: 2.4826081789039494

Epoch: 5| Step: 6
Training loss: 3.077341977361288
Validation loss: 2.4906643245756293

Epoch: 5| Step: 7
Training loss: 2.634130855301992
Validation loss: 2.486692391416765

Epoch: 5| Step: 8
Training loss: 2.193916175395465
Validation loss: 2.476610698692225

Epoch: 5| Step: 9
Training loss: 2.160808554420359
Validation loss: 2.4910663326997162

Epoch: 5| Step: 10
Training loss: 2.219156362366637
Validation loss: 2.4892756592529945

Epoch: 5| Step: 11
Training loss: 1.3803061924436826
Validation loss: 2.496798364627359

Epoch: 259| Step: 0
Training loss: 2.39158920091742
Validation loss: 2.513968955275945

Epoch: 5| Step: 1
Training loss: 2.1874359121471367
Validation loss: 2.5113276033197725

Epoch: 5| Step: 2
Training loss: 2.4730228194538664
Validation loss: 2.5067532085721416

Epoch: 5| Step: 3
Training loss: 2.3975903136234935
Validation loss: 2.517255164069112

Epoch: 5| Step: 4
Training loss: 1.9546730315407086
Validation loss: 2.5170108460869725

Epoch: 5| Step: 5
Training loss: 2.408171740943867
Validation loss: 2.505025596589399

Epoch: 5| Step: 6
Training loss: 3.1032038652707223
Validation loss: 2.50876006132781

Epoch: 5| Step: 7
Training loss: 2.012347610106203
Validation loss: 2.5044012706138097

Epoch: 5| Step: 8
Training loss: 2.403203645964497
Validation loss: 2.514697818209527

Epoch: 5| Step: 9
Training loss: 2.0189184443348593
Validation loss: 2.511669799185303

Epoch: 5| Step: 10
Training loss: 2.699816492696917
Validation loss: 2.5036549672694934

Epoch: 5| Step: 11
Training loss: 1.7955083542674315
Validation loss: 2.506162566120906

Epoch: 260| Step: 0
Training loss: 2.710630020161581
Validation loss: 2.5348576417366866

Epoch: 5| Step: 1
Training loss: 2.7944255310827466
Validation loss: 2.546523910537787

Epoch: 5| Step: 2
Training loss: 2.769520661370141
Validation loss: 2.5338763830315933

Epoch: 5| Step: 3
Training loss: 1.8874956825661702
Validation loss: 2.5351713049803566

Epoch: 5| Step: 4
Training loss: 1.83532776142766
Validation loss: 2.52639769702956

Epoch: 5| Step: 5
Training loss: 2.2517661474442408
Validation loss: 2.5177036330074385

Epoch: 5| Step: 6
Training loss: 2.37286120029784
Validation loss: 2.5194853588725317

Epoch: 5| Step: 7
Training loss: 2.2675004234439746
Validation loss: 2.5279836340864397

Epoch: 5| Step: 8
Training loss: 2.526279231170857
Validation loss: 2.517896890004454

Epoch: 5| Step: 9
Training loss: 2.0924968100538286
Validation loss: 2.527690798767471

Epoch: 5| Step: 10
Training loss: 2.6039165122364722
Validation loss: 2.5113580740418917

Epoch: 5| Step: 11
Training loss: 2.310978363067874
Validation loss: 2.5186217645353657

Epoch: 261| Step: 0
Training loss: 2.117087161230801
Validation loss: 2.5291313559085076

Epoch: 5| Step: 1
Training loss: 2.288260361669556
Validation loss: 2.516026222030196

Epoch: 5| Step: 2
Training loss: 2.071813075548426
Validation loss: 2.525445066702591

Epoch: 5| Step: 3
Training loss: 2.5195108102368584
Validation loss: 2.5260562044230035

Epoch: 5| Step: 4
Training loss: 2.5460669985194238
Validation loss: 2.5228593476953454

Epoch: 5| Step: 5
Training loss: 2.354180788881147
Validation loss: 2.5009638458170946

Epoch: 5| Step: 6
Training loss: 1.7538953071371812
Validation loss: 2.509374902296876

Epoch: 5| Step: 7
Training loss: 2.386792570430341
Validation loss: 2.513785074407582

Epoch: 5| Step: 8
Training loss: 2.525485315044926
Validation loss: 2.5265487764890535

Epoch: 5| Step: 9
Training loss: 2.7859442025626575
Validation loss: 2.52169846961151

Epoch: 5| Step: 10
Training loss: 2.615373489520198
Validation loss: 2.511992289834278

Epoch: 5| Step: 11
Training loss: 2.3149197265021795
Validation loss: 2.512545784174092

Epoch: 262| Step: 0
Training loss: 2.6704657334880992
Validation loss: 2.514859626074446

Epoch: 5| Step: 1
Training loss: 1.998932911398289
Validation loss: 2.522898790709348

Epoch: 5| Step: 2
Training loss: 1.3117718266102916
Validation loss: 2.5152240931286998

Epoch: 5| Step: 3
Training loss: 2.303125298136429
Validation loss: 2.522350571251432

Epoch: 5| Step: 4
Training loss: 2.480072230087054
Validation loss: 2.503527165766889

Epoch: 5| Step: 5
Training loss: 2.4632500334073475
Validation loss: 2.520583129845305

Epoch: 5| Step: 6
Training loss: 2.404566386384614
Validation loss: 2.5048771591073153

Epoch: 5| Step: 7
Training loss: 2.3000966010331987
Validation loss: 2.513964774518497

Epoch: 5| Step: 8
Training loss: 2.5503901463661673
Validation loss: 2.5102898986487854

Epoch: 5| Step: 9
Training loss: 2.2233217446493687
Validation loss: 2.5042698437978217

Epoch: 5| Step: 10
Training loss: 3.066083718606985
Validation loss: 2.5094211604210352

Epoch: 5| Step: 11
Training loss: 1.8224669056047453
Validation loss: 2.504100425042965

Epoch: 263| Step: 0
Training loss: 2.280501360397084
Validation loss: 2.526444477068362

Epoch: 5| Step: 1
Training loss: 2.5806876653008946
Validation loss: 2.530556363956961

Epoch: 5| Step: 2
Training loss: 1.9923197982840615
Validation loss: 2.535482361150606

Epoch: 5| Step: 3
Training loss: 2.94910120445595
Validation loss: 2.5236454140876714

Epoch: 5| Step: 4
Training loss: 2.0393653147844786
Validation loss: 2.539614276108116

Epoch: 5| Step: 5
Training loss: 2.0697085093313583
Validation loss: 2.5065746639324193

Epoch: 5| Step: 6
Training loss: 2.6440759264018188
Validation loss: 2.5081371719124568

Epoch: 5| Step: 7
Training loss: 2.0219044419375165
Validation loss: 2.5121902252712682

Epoch: 5| Step: 8
Training loss: 3.028075453408994
Validation loss: 2.504083953439259

Epoch: 5| Step: 9
Training loss: 2.045465814193357
Validation loss: 2.523612316520635

Epoch: 5| Step: 10
Training loss: 2.178223696077565
Validation loss: 2.508450899241621

Epoch: 5| Step: 11
Training loss: 2.7571117169946184
Validation loss: 2.510468566854004

Epoch: 264| Step: 0
Training loss: 2.6513153914139553
Validation loss: 2.50871562837916

Epoch: 5| Step: 1
Training loss: 3.0571210684719246
Validation loss: 2.5374384297886046

Epoch: 5| Step: 2
Training loss: 2.570167606988917
Validation loss: 2.577781284423979

Epoch: 5| Step: 3
Training loss: 1.781603727855645
Validation loss: 2.599585873377931

Epoch: 5| Step: 4
Training loss: 2.0734097327275394
Validation loss: 2.5919153665048897

Epoch: 5| Step: 5
Training loss: 2.3975755963226244
Validation loss: 2.5896256835944453

Epoch: 5| Step: 6
Training loss: 2.330311305488402
Validation loss: 2.5439727840294837

Epoch: 5| Step: 7
Training loss: 2.56459992127331
Validation loss: 2.516814769930121

Epoch: 5| Step: 8
Training loss: 2.531620987443848
Validation loss: 2.4981970007481635

Epoch: 5| Step: 9
Training loss: 2.678357297421796
Validation loss: 2.483509696761293

Epoch: 5| Step: 10
Training loss: 2.289157696199379
Validation loss: 2.491398561899822

Epoch: 5| Step: 11
Training loss: 2.0283246616542803
Validation loss: 2.481166823471979

Epoch: 265| Step: 0
Training loss: 2.849855847644922
Validation loss: 2.4901958308010705

Epoch: 5| Step: 1
Training loss: 2.1441630062937365
Validation loss: 2.4886869402243685

Epoch: 5| Step: 2
Training loss: 2.20049827308301
Validation loss: 2.4934492713850203

Epoch: 5| Step: 3
Training loss: 2.407721032664805
Validation loss: 2.4918325284998644

Epoch: 5| Step: 4
Training loss: 2.405013819633004
Validation loss: 2.4952816624687677

Epoch: 5| Step: 5
Training loss: 2.122740385643645
Validation loss: 2.4997424430100907

Epoch: 5| Step: 6
Training loss: 1.983794961094103
Validation loss: 2.4856640332643587

Epoch: 5| Step: 7
Training loss: 2.2743791550495867
Validation loss: 2.509855078304114

Epoch: 5| Step: 8
Training loss: 2.700741284653771
Validation loss: 2.5058229621665817

Epoch: 5| Step: 9
Training loss: 2.335743363392337
Validation loss: 2.517370802908178

Epoch: 5| Step: 10
Training loss: 2.390384836537424
Validation loss: 2.539603057442589

Epoch: 5| Step: 11
Training loss: 3.2345651764175605
Validation loss: 2.506701527365372

Epoch: 266| Step: 0
Training loss: 2.3087823213092094
Validation loss: 2.55340862636467

Epoch: 5| Step: 1
Training loss: 2.444913593941929
Validation loss: 2.5639948807129413

Epoch: 5| Step: 2
Training loss: 2.0310073707630885
Validation loss: 2.563967439670395

Epoch: 5| Step: 3
Training loss: 2.571332827556713
Validation loss: 2.5564487735968604

Epoch: 5| Step: 4
Training loss: 2.5904543978077634
Validation loss: 2.5463818889900067

Epoch: 5| Step: 5
Training loss: 1.9204820997242666
Validation loss: 2.5321754051226275

Epoch: 5| Step: 6
Training loss: 2.5949498354375753
Validation loss: 2.5250060852531404

Epoch: 5| Step: 7
Training loss: 2.6232504691092005
Validation loss: 2.5264383548581963

Epoch: 5| Step: 8
Training loss: 2.4025344896966887
Validation loss: 2.499798389093763

Epoch: 5| Step: 9
Training loss: 2.132199153809594
Validation loss: 2.4979250999755864

Epoch: 5| Step: 10
Training loss: 2.1024150041053513
Validation loss: 2.5003442090221797

Epoch: 5| Step: 11
Training loss: 2.681129890365939
Validation loss: 2.4830842433778457

Epoch: 267| Step: 0
Training loss: 1.9248617271205029
Validation loss: 2.4838934057720747

Epoch: 5| Step: 1
Training loss: 2.389648237957184
Validation loss: 2.464227549996556

Epoch: 5| Step: 2
Training loss: 2.9985278014102317
Validation loss: 2.480101350423301

Epoch: 5| Step: 3
Training loss: 2.576332810286577
Validation loss: 2.4777105941405044

Epoch: 5| Step: 4
Training loss: 2.6663435402444433
Validation loss: 2.475110000114994

Epoch: 5| Step: 5
Training loss: 1.9670265162183203
Validation loss: 2.473137371307683

Epoch: 5| Step: 6
Training loss: 2.2201432702512456
Validation loss: 2.473586182293466

Epoch: 5| Step: 7
Training loss: 2.334000412634492
Validation loss: 2.4831177911302524

Epoch: 5| Step: 8
Training loss: 1.8323187043358569
Validation loss: 2.4750230178019548

Epoch: 5| Step: 9
Training loss: 2.2202684820913796
Validation loss: 2.478499594602256

Epoch: 5| Step: 10
Training loss: 2.8294991374185545
Validation loss: 2.485342009500407

Epoch: 5| Step: 11
Training loss: 4.147206269222395
Validation loss: 2.518215642272757

Epoch: 268| Step: 0
Training loss: 2.3726362210591176
Validation loss: 2.5228750785111043

Epoch: 5| Step: 1
Training loss: 2.5562611437417075
Validation loss: 2.5345436653115487

Epoch: 5| Step: 2
Training loss: 2.0952793058970585
Validation loss: 2.5574640007505858

Epoch: 5| Step: 3
Training loss: 2.497308235634338
Validation loss: 2.5633903639091407

Epoch: 5| Step: 4
Training loss: 2.1601753440965
Validation loss: 2.615986471596131

Epoch: 5| Step: 5
Training loss: 2.5818113848038706
Validation loss: 2.6106026439883063

Epoch: 5| Step: 6
Training loss: 2.499501560113782
Validation loss: 2.5506109323933885

Epoch: 5| Step: 7
Training loss: 2.2304522886186557
Validation loss: 2.528618089868772

Epoch: 5| Step: 8
Training loss: 2.0349132663698346
Validation loss: 2.50230620823811

Epoch: 5| Step: 9
Training loss: 2.2610328174421293
Validation loss: 2.4817761397463474

Epoch: 5| Step: 10
Training loss: 2.8776320972496783
Validation loss: 2.4794347455168393

Epoch: 5| Step: 11
Training loss: 3.7433762862157787
Validation loss: 2.4735100283083056

Epoch: 269| Step: 0
Training loss: 2.4889101105118296
Validation loss: 2.47188088311461

Epoch: 5| Step: 1
Training loss: 2.629889339831298
Validation loss: 2.4770534401820505

Epoch: 5| Step: 2
Training loss: 2.417650340473726
Validation loss: 2.4805024712941193

Epoch: 5| Step: 3
Training loss: 2.240553310210399
Validation loss: 2.47501582114946

Epoch: 5| Step: 4
Training loss: 2.5696386132176374
Validation loss: 2.4973807243285253

Epoch: 5| Step: 5
Training loss: 2.8588845087656916
Validation loss: 2.5093405911630846

Epoch: 5| Step: 6
Training loss: 2.5634165729587877
Validation loss: 2.5006744746499274

Epoch: 5| Step: 7
Training loss: 2.2368895779582574
Validation loss: 2.505094935387887

Epoch: 5| Step: 8
Training loss: 2.306958647404886
Validation loss: 2.511840409990427

Epoch: 5| Step: 9
Training loss: 1.8172329897775195
Validation loss: 2.5172915536032847

Epoch: 5| Step: 10
Training loss: 2.1975418663159583
Validation loss: 2.5223064781449995

Epoch: 5| Step: 11
Training loss: 1.8153698004847958
Validation loss: 2.5224646394618513

Epoch: 270| Step: 0
Training loss: 2.5207739788875796
Validation loss: 2.5134832335624253

Epoch: 5| Step: 1
Training loss: 2.190300810547728
Validation loss: 2.5179449563397003

Epoch: 5| Step: 2
Training loss: 1.849968203709547
Validation loss: 2.5362645701213453

Epoch: 5| Step: 3
Training loss: 2.6112261390600207
Validation loss: 2.5540047140463806

Epoch: 5| Step: 4
Training loss: 2.657119249716571
Validation loss: 2.5406971955999724

Epoch: 5| Step: 5
Training loss: 2.476283205089899
Validation loss: 2.5445644179343283

Epoch: 5| Step: 6
Training loss: 2.295445626736816
Validation loss: 2.543684003787703

Epoch: 5| Step: 7
Training loss: 2.4262936553093555
Validation loss: 2.5265877883831425

Epoch: 5| Step: 8
Training loss: 2.35943472072984
Validation loss: 2.541178782857287

Epoch: 5| Step: 9
Training loss: 2.7390322886496574
Validation loss: 2.518624407190409

Epoch: 5| Step: 10
Training loss: 1.8299615877841542
Validation loss: 2.498612857475422

Epoch: 5| Step: 11
Training loss: 2.111293570123683
Validation loss: 2.4905377371516972

Epoch: 271| Step: 0
Training loss: 1.7469379338646782
Validation loss: 2.4814587417193117

Epoch: 5| Step: 1
Training loss: 2.266463972827389
Validation loss: 2.488166602830641

Epoch: 5| Step: 2
Training loss: 1.8633761271826925
Validation loss: 2.502372379002246

Epoch: 5| Step: 3
Training loss: 2.440983361812211
Validation loss: 2.4874776144314374

Epoch: 5| Step: 4
Training loss: 2.9660064869949285
Validation loss: 2.5023793024560024

Epoch: 5| Step: 5
Training loss: 2.4413091777576654
Validation loss: 2.4920834626233552

Epoch: 5| Step: 6
Training loss: 1.9355016678073944
Validation loss: 2.508580740791264

Epoch: 5| Step: 7
Training loss: 2.2478018725772557
Validation loss: 2.4989062340539467

Epoch: 5| Step: 8
Training loss: 2.441882570722183
Validation loss: 2.532619443388244

Epoch: 5| Step: 9
Training loss: 2.4830599969382083
Validation loss: 2.525628259919928

Epoch: 5| Step: 10
Training loss: 2.424327568343513
Validation loss: 2.5627208552514484

Epoch: 5| Step: 11
Training loss: 3.519957860564374
Validation loss: 2.5716166564675516

Epoch: 272| Step: 0
Training loss: 2.2093923176865053
Validation loss: 2.633563435486689

Epoch: 5| Step: 1
Training loss: 2.727390371299509
Validation loss: 2.6544359333064573

Epoch: 5| Step: 2
Training loss: 2.174684422717334
Validation loss: 2.6349905647118557

Epoch: 5| Step: 3
Training loss: 2.6925135135577163
Validation loss: 2.6227722743807838

Epoch: 5| Step: 4
Training loss: 2.4398235104002617
Validation loss: 2.570678789191415

Epoch: 5| Step: 5
Training loss: 2.518003015051287
Validation loss: 2.567337668374941

Epoch: 5| Step: 6
Training loss: 2.3213847858365866
Validation loss: 2.53184145622473

Epoch: 5| Step: 7
Training loss: 1.8526862231308312
Validation loss: 2.5113958860207344

Epoch: 5| Step: 8
Training loss: 2.256712860224401
Validation loss: 2.495888707072603

Epoch: 5| Step: 9
Training loss: 3.03566428391766
Validation loss: 2.492233248044602

Epoch: 5| Step: 10
Training loss: 2.1019349175929856
Validation loss: 2.4815887966155006

Epoch: 5| Step: 11
Training loss: 2.430747926153444
Validation loss: 2.493168373766612

Epoch: 273| Step: 0
Training loss: 2.1703697861649083
Validation loss: 2.4916607689761103

Epoch: 5| Step: 1
Training loss: 2.1163729406293506
Validation loss: 2.4908593304882185

Epoch: 5| Step: 2
Training loss: 2.261655500249019
Validation loss: 2.485142203495863

Epoch: 5| Step: 3
Training loss: 2.6209496630478175
Validation loss: 2.490765802861866

Epoch: 5| Step: 4
Training loss: 2.059922428337194
Validation loss: 2.4842752320672155

Epoch: 5| Step: 5
Training loss: 2.5290286831449103
Validation loss: 2.49272310646059

Epoch: 5| Step: 6
Training loss: 2.5113912460836847
Validation loss: 2.505866897345749

Epoch: 5| Step: 7
Training loss: 2.2095095063398023
Validation loss: 2.5057144261869304

Epoch: 5| Step: 8
Training loss: 2.603494654096665
Validation loss: 2.509357348926708

Epoch: 5| Step: 9
Training loss: 2.564294233433226
Validation loss: 2.5181173452950727

Epoch: 5| Step: 10
Training loss: 2.558441856476553
Validation loss: 2.5461881760719987

Epoch: 5| Step: 11
Training loss: 1.5835146130970714
Validation loss: 2.535607825266439

Epoch: 274| Step: 0
Training loss: 2.0058768475002764
Validation loss: 2.570988209730776

Epoch: 5| Step: 1
Training loss: 2.075929557604787
Validation loss: 2.5848500422897085

Epoch: 5| Step: 2
Training loss: 2.14762779930256
Validation loss: 2.586807342858661

Epoch: 5| Step: 3
Training loss: 2.429147936409071
Validation loss: 2.609684638346627

Epoch: 5| Step: 4
Training loss: 2.7808988542376007
Validation loss: 2.608048149266802

Epoch: 5| Step: 5
Training loss: 2.722738913289595
Validation loss: 2.5668895852729006

Epoch: 5| Step: 6
Training loss: 2.559633279700491
Validation loss: 2.543624828455032

Epoch: 5| Step: 7
Training loss: 2.590012120546237
Validation loss: 2.5141554028763755

Epoch: 5| Step: 8
Training loss: 2.0662602912106536
Validation loss: 2.49296711892051

Epoch: 5| Step: 9
Training loss: 2.78404523992503
Validation loss: 2.477324287388625

Epoch: 5| Step: 10
Training loss: 2.4407285192127146
Validation loss: 2.4862076979142698

Epoch: 5| Step: 11
Training loss: 1.5389993722429787
Validation loss: 2.4922278629171495

Epoch: 275| Step: 0
Training loss: 2.5031806739587763
Validation loss: 2.4917163184225397

Epoch: 5| Step: 1
Training loss: 2.096016525341729
Validation loss: 2.478422942256087

Epoch: 5| Step: 2
Training loss: 2.300355311605437
Validation loss: 2.491903701456195

Epoch: 5| Step: 3
Training loss: 2.159322788253213
Validation loss: 2.482941021722715

Epoch: 5| Step: 4
Training loss: 1.7976408280130118
Validation loss: 2.4874745952324884

Epoch: 5| Step: 5
Training loss: 2.100878749640473
Validation loss: 2.506074772747526

Epoch: 5| Step: 6
Training loss: 2.5785106023777966
Validation loss: 2.519470304791955

Epoch: 5| Step: 7
Training loss: 1.9670414246976193
Validation loss: 2.5313920503168665

Epoch: 5| Step: 8
Training loss: 2.5938428379587273
Validation loss: 2.516708681616898

Epoch: 5| Step: 9
Training loss: 2.959009675273438
Validation loss: 2.541429333992914

Epoch: 5| Step: 10
Training loss: 2.899678666300432
Validation loss: 2.548965750494983

Epoch: 5| Step: 11
Training loss: 2.944489786610677
Validation loss: 2.548964783962138

Epoch: 276| Step: 0
Training loss: 2.187946383026787
Validation loss: 2.5575534132398006

Epoch: 5| Step: 1
Training loss: 1.9046131673426407
Validation loss: 2.607596127977406

Epoch: 5| Step: 2
Training loss: 2.050453377808291
Validation loss: 2.5848825383015774

Epoch: 5| Step: 3
Training loss: 2.402027537306354
Validation loss: 2.5714865904556135

Epoch: 5| Step: 4
Training loss: 2.941781839452099
Validation loss: 2.5575395970217287

Epoch: 5| Step: 5
Training loss: 2.442251416210147
Validation loss: 2.5559432572402847

Epoch: 5| Step: 6
Training loss: 2.225005344855929
Validation loss: 2.541533374157485

Epoch: 5| Step: 7
Training loss: 2.0870978739023722
Validation loss: 2.553773858563742

Epoch: 5| Step: 8
Training loss: 2.242991552499416
Validation loss: 2.5373349107867536

Epoch: 5| Step: 9
Training loss: 3.2066963940972046
Validation loss: 2.534295389012364

Epoch: 5| Step: 10
Training loss: 2.0317738957802907
Validation loss: 2.540324252675449

Epoch: 5| Step: 11
Training loss: 1.5316528257561668
Validation loss: 2.539846801912431

Epoch: 277| Step: 0
Training loss: 2.1658334474855896
Validation loss: 2.517647757305874

Epoch: 5| Step: 1
Training loss: 2.5735316191591684
Validation loss: 2.5065405165941614

Epoch: 5| Step: 2
Training loss: 2.6678440852382788
Validation loss: 2.500517616728102

Epoch: 5| Step: 3
Training loss: 1.9379628151671489
Validation loss: 2.5063124514922124

Epoch: 5| Step: 4
Training loss: 1.962014924376612
Validation loss: 2.4874557011939373

Epoch: 5| Step: 5
Training loss: 2.385759875887405
Validation loss: 2.499054940728114

Epoch: 5| Step: 6
Training loss: 1.9280228944819946
Validation loss: 2.491598918774145

Epoch: 5| Step: 7
Training loss: 2.2518346512160337
Validation loss: 2.4926712021145807

Epoch: 5| Step: 8
Training loss: 2.699980124647667
Validation loss: 2.5150516678057597

Epoch: 5| Step: 9
Training loss: 2.753266215518511
Validation loss: 2.5078464953375312

Epoch: 5| Step: 10
Training loss: 2.4488277822918088
Validation loss: 2.5055165738968657

Epoch: 5| Step: 11
Training loss: 2.197855715034567
Validation loss: 2.527121457952077

Epoch: 278| Step: 0
Training loss: 2.1546883940608414
Validation loss: 2.5310427498449455

Epoch: 5| Step: 1
Training loss: 2.3144015149506805
Validation loss: 2.5702540266348475

Epoch: 5| Step: 2
Training loss: 2.615473764073936
Validation loss: 2.5568989389362375

Epoch: 5| Step: 3
Training loss: 1.7118470722328436
Validation loss: 2.586481968626654

Epoch: 5| Step: 4
Training loss: 1.9756290206699314
Validation loss: 2.5933444920261377

Epoch: 5| Step: 5
Training loss: 2.485849578664522
Validation loss: 2.556336309255248

Epoch: 5| Step: 6
Training loss: 2.467757496331328
Validation loss: 2.5660603027356643

Epoch: 5| Step: 7
Training loss: 2.6487740721965647
Validation loss: 2.534188268471794

Epoch: 5| Step: 8
Training loss: 2.2550655140632356
Validation loss: 2.5218429054446

Epoch: 5| Step: 9
Training loss: 2.4013021552613982
Validation loss: 2.4926196952286275

Epoch: 5| Step: 10
Training loss: 2.5493426391911878
Validation loss: 2.4925100901025457

Epoch: 5| Step: 11
Training loss: 3.848299636880533
Validation loss: 2.4821132885297916

Epoch: 279| Step: 0
Training loss: 2.543673697412121
Validation loss: 2.474441000718287

Epoch: 5| Step: 1
Training loss: 2.221651463591328
Validation loss: 2.483718829401736

Epoch: 5| Step: 2
Training loss: 1.5699734298012762
Validation loss: 2.4797328067479243

Epoch: 5| Step: 3
Training loss: 2.9168471870870065
Validation loss: 2.491598021689721

Epoch: 5| Step: 4
Training loss: 2.439534340965655
Validation loss: 2.492509532120772

Epoch: 5| Step: 5
Training loss: 2.05554912182371
Validation loss: 2.492261995101034

Epoch: 5| Step: 6
Training loss: 2.2872262301021378
Validation loss: 2.5039085630186984

Epoch: 5| Step: 7
Training loss: 2.3963803095401324
Validation loss: 2.5246922785455665

Epoch: 5| Step: 8
Training loss: 2.616139033953816
Validation loss: 2.5405949863351736

Epoch: 5| Step: 9
Training loss: 1.7281560663945499
Validation loss: 2.5410268843428487

Epoch: 5| Step: 10
Training loss: 2.7156643951332846
Validation loss: 2.559836230096702

Epoch: 5| Step: 11
Training loss: 2.2025988877230858
Validation loss: 2.5821852606829414

Epoch: 280| Step: 0
Training loss: 2.453434335436667
Validation loss: 2.6057389484785896

Epoch: 5| Step: 1
Training loss: 2.837257939571519
Validation loss: 2.6154652788685495

Epoch: 5| Step: 2
Training loss: 2.3002129000107745
Validation loss: 2.5864740028372717

Epoch: 5| Step: 3
Training loss: 1.9262260867249112
Validation loss: 2.562098816736816

Epoch: 5| Step: 4
Training loss: 2.9108735090297704
Validation loss: 2.5622632374747374

Epoch: 5| Step: 5
Training loss: 2.3724608651441703
Validation loss: 2.5230929549882193

Epoch: 5| Step: 6
Training loss: 1.9136027504092643
Validation loss: 2.503327114757411

Epoch: 5| Step: 7
Training loss: 1.646926331851111
Validation loss: 2.5011420264094695

Epoch: 5| Step: 8
Training loss: 2.2789958111070447
Validation loss: 2.517959770985942

Epoch: 5| Step: 9
Training loss: 2.8992152237414555
Validation loss: 2.491648989527543

Epoch: 5| Step: 10
Training loss: 2.067169221666049
Validation loss: 2.501279269181753

Epoch: 5| Step: 11
Training loss: 2.944258686020146
Validation loss: 2.5009964109618985

Epoch: 281| Step: 0
Training loss: 2.5677587931061545
Validation loss: 2.5132568577958367

Epoch: 5| Step: 1
Training loss: 2.5505249455482235
Validation loss: 2.5471090548569846

Epoch: 5| Step: 2
Training loss: 2.030027168167292
Validation loss: 2.580670595065766

Epoch: 5| Step: 3
Training loss: 1.9033079112682834
Validation loss: 2.604693395115574

Epoch: 5| Step: 4
Training loss: 2.2936625949930844
Validation loss: 2.6119997981515857

Epoch: 5| Step: 5
Training loss: 2.553553711699191
Validation loss: 2.6230112917473187

Epoch: 5| Step: 6
Training loss: 2.403217039094349
Validation loss: 2.613755343264654

Epoch: 5| Step: 7
Training loss: 2.7503420877095035
Validation loss: 2.6211138448309708

Epoch: 5| Step: 8
Training loss: 2.3026554783319386
Validation loss: 2.585023055647073

Epoch: 5| Step: 9
Training loss: 1.8898950854453478
Validation loss: 2.571096978870869

Epoch: 5| Step: 10
Training loss: 2.653230993447394
Validation loss: 2.557361684696567

Epoch: 5| Step: 11
Training loss: 1.9548170770986173
Validation loss: 2.5532226990489235

Epoch: 282| Step: 0
Training loss: 1.9093019412184336
Validation loss: 2.5124999908270134

Epoch: 5| Step: 1
Training loss: 2.8778112184536386
Validation loss: 2.5012363833619653

Epoch: 5| Step: 2
Training loss: 1.9543358673286613
Validation loss: 2.510042567626726

Epoch: 5| Step: 3
Training loss: 2.682391790107703
Validation loss: 2.492467882414324

Epoch: 5| Step: 4
Training loss: 2.0617739237478205
Validation loss: 2.503930123979576

Epoch: 5| Step: 5
Training loss: 1.9018492006876813
Validation loss: 2.509301271539164

Epoch: 5| Step: 6
Training loss: 2.4223256337939483
Validation loss: 2.5015333837545732

Epoch: 5| Step: 7
Training loss: 2.4030927281389247
Validation loss: 2.511676469588393

Epoch: 5| Step: 8
Training loss: 2.586887611492979
Validation loss: 2.5200181318127797

Epoch: 5| Step: 9
Training loss: 2.190831943809946
Validation loss: 2.5244144245395854

Epoch: 5| Step: 10
Training loss: 2.8332417604196505
Validation loss: 2.5266992787910763

Epoch: 5| Step: 11
Training loss: 3.28824241000761
Validation loss: 2.550635539591372

Epoch: 283| Step: 0
Training loss: 2.4142160706298132
Validation loss: 2.5525965674089446

Epoch: 5| Step: 1
Training loss: 2.582902769898627
Validation loss: 2.5550095513632476

Epoch: 5| Step: 2
Training loss: 2.8692571254108947
Validation loss: 2.5446969140476847

Epoch: 5| Step: 3
Training loss: 1.6682217336872764
Validation loss: 2.53391944955364

Epoch: 5| Step: 4
Training loss: 2.3942154991975766
Validation loss: 2.538085620464732

Epoch: 5| Step: 5
Training loss: 2.6134182790003564
Validation loss: 2.5475109024176437

Epoch: 5| Step: 6
Training loss: 1.5931139406020143
Validation loss: 2.536946507552198

Epoch: 5| Step: 7
Training loss: 1.8811429801232202
Validation loss: 2.5698158070255483

Epoch: 5| Step: 8
Training loss: 2.894877507018155
Validation loss: 2.563956017600997

Epoch: 5| Step: 9
Training loss: 1.8690540130223554
Validation loss: 2.5693699732862507

Epoch: 5| Step: 10
Training loss: 2.431526984198208
Validation loss: 2.5664404485041

Epoch: 5| Step: 11
Training loss: 1.417093810966511
Validation loss: 2.5664412149169675

Epoch: 284| Step: 0
Training loss: 1.9645284168365882
Validation loss: 2.5776181657223045

Epoch: 5| Step: 1
Training loss: 2.2676861036616134
Validation loss: 2.5894681064527005

Epoch: 5| Step: 2
Training loss: 2.0251371690422055
Validation loss: 2.541253710379881

Epoch: 5| Step: 3
Training loss: 2.415122876407781
Validation loss: 2.5438520808595557

Epoch: 5| Step: 4
Training loss: 1.6235707673491095
Validation loss: 2.550584698864761

Epoch: 5| Step: 5
Training loss: 2.7349424808737286
Validation loss: 2.551191443992882

Epoch: 5| Step: 6
Training loss: 2.5723897314581774
Validation loss: 2.5344637535788523

Epoch: 5| Step: 7
Training loss: 2.8432197495641316
Validation loss: 2.5526059660055194

Epoch: 5| Step: 8
Training loss: 2.6662578766139093
Validation loss: 2.5398819056038326

Epoch: 5| Step: 9
Training loss: 1.9021251639048773
Validation loss: 2.530626475298486

Epoch: 5| Step: 10
Training loss: 2.428347104395051
Validation loss: 2.535752585346978

Epoch: 5| Step: 11
Training loss: 2.433308249392185
Validation loss: 2.563596440494394

Epoch: 285| Step: 0
Training loss: 2.627392087656788
Validation loss: 2.546984529772888

Epoch: 5| Step: 1
Training loss: 2.3539221194922764
Validation loss: 2.5488097286413063

Epoch: 5| Step: 2
Training loss: 2.4933522531060164
Validation loss: 2.5253676560712783

Epoch: 5| Step: 3
Training loss: 1.707645471611985
Validation loss: 2.527450260549573

Epoch: 5| Step: 4
Training loss: 2.1840653839943758
Validation loss: 2.5268955550646064

Epoch: 5| Step: 5
Training loss: 2.545356250852934
Validation loss: 2.51555103288034

Epoch: 5| Step: 6
Training loss: 2.244736130124046
Validation loss: 2.5263947518674286

Epoch: 5| Step: 7
Training loss: 1.9378557186293217
Validation loss: 2.527132873542263

Epoch: 5| Step: 8
Training loss: 2.6600140997147275
Validation loss: 2.53691054483508

Epoch: 5| Step: 9
Training loss: 2.4828497085039825
Validation loss: 2.57195395182004

Epoch: 5| Step: 10
Training loss: 2.252343758468284
Validation loss: 2.5769518331181667

Epoch: 5| Step: 11
Training loss: 3.7525595512976415
Validation loss: 2.5908370723822127

Epoch: 286| Step: 0
Training loss: 2.0059929703867887
Validation loss: 2.5626545060881805

Epoch: 5| Step: 1
Training loss: 2.1720130931396384
Validation loss: 2.5746191289384464

Epoch: 5| Step: 2
Training loss: 2.816456872323748
Validation loss: 2.5409770027292446

Epoch: 5| Step: 3
Training loss: 1.876760355788584
Validation loss: 2.536722593752

Epoch: 5| Step: 4
Training loss: 2.6480545172135814
Validation loss: 2.5216401887004873

Epoch: 5| Step: 5
Training loss: 2.453718465951248
Validation loss: 2.5064946927985225

Epoch: 5| Step: 6
Training loss: 2.104460012805091
Validation loss: 2.505316263413082

Epoch: 5| Step: 7
Training loss: 1.911914850613409
Validation loss: 2.4974925022820953

Epoch: 5| Step: 8
Training loss: 2.2938870048664057
Validation loss: 2.5001560837976644

Epoch: 5| Step: 9
Training loss: 2.641305057152192
Validation loss: 2.5093058935667822

Epoch: 5| Step: 10
Training loss: 2.4707293723902253
Validation loss: 2.5256182692640334

Epoch: 5| Step: 11
Training loss: 3.368626404372246
Validation loss: 2.5126358857424873

Epoch: 287| Step: 0
Training loss: 2.449590189388271
Validation loss: 2.555160284283915

Epoch: 5| Step: 1
Training loss: 2.6030675068856843
Validation loss: 2.57782374076475

Epoch: 5| Step: 2
Training loss: 2.303763511481484
Validation loss: 2.6249134829054075

Epoch: 5| Step: 3
Training loss: 2.260307649248325
Validation loss: 2.6379168616414144

Epoch: 5| Step: 4
Training loss: 2.466264560074515
Validation loss: 2.662853790859623

Epoch: 5| Step: 5
Training loss: 2.286482154067497
Validation loss: 2.650049381125897

Epoch: 5| Step: 6
Training loss: 2.307057962285563
Validation loss: 2.591679286517198

Epoch: 5| Step: 7
Training loss: 2.237935463923398
Validation loss: 2.563232491636107

Epoch: 5| Step: 8
Training loss: 2.3792265377316806
Validation loss: 2.529975051983046

Epoch: 5| Step: 9
Training loss: 2.2005283934935465
Validation loss: 2.5345706390680878

Epoch: 5| Step: 10
Training loss: 2.3056417267819023
Validation loss: 2.5239599442932765

Epoch: 5| Step: 11
Training loss: 3.162389242170252
Validation loss: 2.500367892535

Epoch: 288| Step: 0
Training loss: 2.5753204812915738
Validation loss: 2.5046082086480177

Epoch: 5| Step: 1
Training loss: 2.197496407151133
Validation loss: 2.4980305822028517

Epoch: 5| Step: 2
Training loss: 2.7204483690682073
Validation loss: 2.5014004242029926

Epoch: 5| Step: 3
Training loss: 1.7338110891964642
Validation loss: 2.51497608803226

Epoch: 5| Step: 4
Training loss: 2.1509854830469703
Validation loss: 2.497394750049238

Epoch: 5| Step: 5
Training loss: 2.795488493375614
Validation loss: 2.5145747201725164

Epoch: 5| Step: 6
Training loss: 1.6308926333388356
Validation loss: 2.5160457444832436

Epoch: 5| Step: 7
Training loss: 2.610795051528638
Validation loss: 2.5176303168569705

Epoch: 5| Step: 8
Training loss: 2.3045853931631832
Validation loss: 2.517499647749744

Epoch: 5| Step: 9
Training loss: 1.9965117552478306
Validation loss: 2.5393879334651426

Epoch: 5| Step: 10
Training loss: 2.4858048840628784
Validation loss: 2.5660927386036922

Epoch: 5| Step: 11
Training loss: 3.3498396991694745
Validation loss: 2.5671768734650677

Epoch: 289| Step: 0
Training loss: 1.827783405961348
Validation loss: 2.5914734957502117

Epoch: 5| Step: 1
Training loss: 2.0673392196189306
Validation loss: 2.5685748455912023

Epoch: 5| Step: 2
Training loss: 2.78011959120579
Validation loss: 2.557436406117729

Epoch: 5| Step: 3
Training loss: 2.3767414735396564
Validation loss: 2.5534644275963947

Epoch: 5| Step: 4
Training loss: 2.0970449000742084
Validation loss: 2.541715204577976

Epoch: 5| Step: 5
Training loss: 2.454488096144985
Validation loss: 2.5332286699115394

Epoch: 5| Step: 6
Training loss: 2.5522731373071013
Validation loss: 2.534497540385009

Epoch: 5| Step: 7
Training loss: 1.938507310445686
Validation loss: 2.529970179113164

Epoch: 5| Step: 8
Training loss: 2.0228291779079135
Validation loss: 2.5148348129981124

Epoch: 5| Step: 9
Training loss: 2.688621287082657
Validation loss: 2.5285639738169783

Epoch: 5| Step: 10
Training loss: 2.693821237423132
Validation loss: 2.530801855062554

Epoch: 5| Step: 11
Training loss: 2.332660737054743
Validation loss: 2.530289043700817

Epoch: 290| Step: 0
Training loss: 2.1535168339673847
Validation loss: 2.499075448420555

Epoch: 5| Step: 1
Training loss: 2.593996151194074
Validation loss: 2.483856770908758

Epoch: 5| Step: 2
Training loss: 2.606303891875742
Validation loss: 2.476197758399077

Epoch: 5| Step: 3
Training loss: 1.7500236373394926
Validation loss: 2.4739847697133817

Epoch: 5| Step: 4
Training loss: 2.0655266488765616
Validation loss: 2.4758930484803816

Epoch: 5| Step: 5
Training loss: 2.5034108735667204
Validation loss: 2.4754797557202592

Epoch: 5| Step: 6
Training loss: 2.586600319545664
Validation loss: 2.4791185924666688

Epoch: 5| Step: 7
Training loss: 2.040649030698738
Validation loss: 2.48127274586896

Epoch: 5| Step: 8
Training loss: 2.6495965542568154
Validation loss: 2.5061727235221576

Epoch: 5| Step: 9
Training loss: 2.3964941246872784
Validation loss: 2.4872413071024746

Epoch: 5| Step: 10
Training loss: 2.6401310746570195
Validation loss: 2.480389739452758

Epoch: 5| Step: 11
Training loss: 2.771171310195463
Validation loss: 2.4954990798922

Epoch: 291| Step: 0
Training loss: 2.6582903935263915
Validation loss: 2.4862285393296455

Epoch: 5| Step: 1
Training loss: 1.6348569199604825
Validation loss: 2.493513756909568

Epoch: 5| Step: 2
Training loss: 2.104183675363619
Validation loss: 2.496889360694504

Epoch: 5| Step: 3
Training loss: 2.238423128274967
Validation loss: 2.5070690744569464

Epoch: 5| Step: 4
Training loss: 2.415716697067755
Validation loss: 2.5152932258265914

Epoch: 5| Step: 5
Training loss: 2.788928971713897
Validation loss: 2.5204887285954816

Epoch: 5| Step: 6
Training loss: 2.659484868183897
Validation loss: 2.524474526326237

Epoch: 5| Step: 7
Training loss: 2.1058336836957117
Validation loss: 2.513257719480566

Epoch: 5| Step: 8
Training loss: 2.25614270829585
Validation loss: 2.5156654409944994

Epoch: 5| Step: 9
Training loss: 2.587801719433934
Validation loss: 2.543233921115068

Epoch: 5| Step: 10
Training loss: 2.102242512216342
Validation loss: 2.5412825713702722

Epoch: 5| Step: 11
Training loss: 1.716101738957087
Validation loss: 2.5600206196595314

Epoch: 292| Step: 0
Training loss: 2.3215201475085427
Validation loss: 2.519028937368547

Epoch: 5| Step: 1
Training loss: 2.6039643984761955
Validation loss: 2.5504190500328554

Epoch: 5| Step: 2
Training loss: 2.567875875355051
Validation loss: 2.5455598770679186

Epoch: 5| Step: 3
Training loss: 2.1711940658471374
Validation loss: 2.5545580536597368

Epoch: 5| Step: 4
Training loss: 2.422720091026888
Validation loss: 2.559983091267485

Epoch: 5| Step: 5
Training loss: 1.9370349818208574
Validation loss: 2.5725023551265314

Epoch: 5| Step: 6
Training loss: 2.2128865308462786
Validation loss: 2.5731987560450666

Epoch: 5| Step: 7
Training loss: 2.4017013559300358
Validation loss: 2.549455548424793

Epoch: 5| Step: 8
Training loss: 2.25191310506233
Validation loss: 2.5434552267928305

Epoch: 5| Step: 9
Training loss: 2.5155160062883852
Validation loss: 2.5331161864496248

Epoch: 5| Step: 10
Training loss: 1.972265586316597
Validation loss: 2.521611747016534

Epoch: 5| Step: 11
Training loss: 3.2018138155730926
Validation loss: 2.5183240536654066

Epoch: 293| Step: 0
Training loss: 2.170345728532637
Validation loss: 2.51843891762738

Epoch: 5| Step: 1
Training loss: 1.9373487598087673
Validation loss: 2.5126146544997274

Epoch: 5| Step: 2
Training loss: 2.598081350320051
Validation loss: 2.493543349733012

Epoch: 5| Step: 3
Training loss: 2.441947791501378
Validation loss: 2.4960924923634433

Epoch: 5| Step: 4
Training loss: 2.9941054290474582
Validation loss: 2.490175465404364

Epoch: 5| Step: 5
Training loss: 2.8965494016111863
Validation loss: 2.4919961279853795

Epoch: 5| Step: 6
Training loss: 2.2224221801864883
Validation loss: 2.514120117785383

Epoch: 5| Step: 7
Training loss: 1.2805727587684652
Validation loss: 2.514898238629189

Epoch: 5| Step: 8
Training loss: 2.099747906040365
Validation loss: 2.514975981382774

Epoch: 5| Step: 9
Training loss: 2.175932134194081
Validation loss: 2.5314516803473097

Epoch: 5| Step: 10
Training loss: 2.6257099826338077
Validation loss: 2.5426997341795627

Epoch: 5| Step: 11
Training loss: 2.0802604774456053
Validation loss: 2.5626167487864207

Epoch: 294| Step: 0
Training loss: 1.5858573705415402
Validation loss: 2.549004524528496

Epoch: 5| Step: 1
Training loss: 2.022182001452162
Validation loss: 2.5710461660313357

Epoch: 5| Step: 2
Training loss: 2.8517999419551763
Validation loss: 2.5863144091843715

Epoch: 5| Step: 3
Training loss: 2.8410564703426404
Validation loss: 2.5702903653846922

Epoch: 5| Step: 4
Training loss: 2.554643169800061
Validation loss: 2.558518872123915

Epoch: 5| Step: 5
Training loss: 2.1977076378329214
Validation loss: 2.5261392371351743

Epoch: 5| Step: 6
Training loss: 2.344790418486995
Validation loss: 2.554128389294694

Epoch: 5| Step: 7
Training loss: 2.371287807712171
Validation loss: 2.5376398062127716

Epoch: 5| Step: 8
Training loss: 2.0427926390617412
Validation loss: 2.5672783726996506

Epoch: 5| Step: 9
Training loss: 1.696017351718526
Validation loss: 2.5747506745472104

Epoch: 5| Step: 10
Training loss: 2.6625196178591097
Validation loss: 2.567257144484028

Epoch: 5| Step: 11
Training loss: 1.9142284087853718
Validation loss: 2.5661885165786362

Epoch: 295| Step: 0
Training loss: 1.6176690015987574
Validation loss: 2.581532582631968

Epoch: 5| Step: 1
Training loss: 1.9918943900106276
Validation loss: 2.576352529334885

Epoch: 5| Step: 2
Training loss: 2.583569505622185
Validation loss: 2.56311089126783

Epoch: 5| Step: 3
Training loss: 1.7402067685319071
Validation loss: 2.5764868878431226

Epoch: 5| Step: 4
Training loss: 2.4856212057497618
Validation loss: 2.5724631513422365

Epoch: 5| Step: 5
Training loss: 2.6267851254656196
Validation loss: 2.578375239702617

Epoch: 5| Step: 6
Training loss: 2.4669729669803866
Validation loss: 2.5721290878481184

Epoch: 5| Step: 7
Training loss: 1.983793999629268
Validation loss: 2.54432131672612

Epoch: 5| Step: 8
Training loss: 2.7038667576200286
Validation loss: 2.543215699127327

Epoch: 5| Step: 9
Training loss: 2.162025346647985
Validation loss: 2.5443879096986572

Epoch: 5| Step: 10
Training loss: 2.6604562105741505
Validation loss: 2.530059872183943

Epoch: 5| Step: 11
Training loss: 2.8640179070280523
Validation loss: 2.539739532194292

Epoch: 296| Step: 0
Training loss: 1.640297266605432
Validation loss: 2.5432400302367193

Epoch: 5| Step: 1
Training loss: 2.735129203324884
Validation loss: 2.55164983272502

Epoch: 5| Step: 2
Training loss: 1.7692503716744807
Validation loss: 2.5294833552719074

Epoch: 5| Step: 3
Training loss: 2.732810657428624
Validation loss: 2.551755344308408

Epoch: 5| Step: 4
Training loss: 2.0460753298378567
Validation loss: 2.5910532118506935

Epoch: 5| Step: 5
Training loss: 1.8988346893128023
Validation loss: 2.5954631333767555

Epoch: 5| Step: 6
Training loss: 2.555582338920704
Validation loss: 2.5967000439493804

Epoch: 5| Step: 7
Training loss: 2.1774846365700906
Validation loss: 2.584133460102039

Epoch: 5| Step: 8
Training loss: 2.888122630181297
Validation loss: 2.5792607782250907

Epoch: 5| Step: 9
Training loss: 2.320979680686934
Validation loss: 2.573336247867044

Epoch: 5| Step: 10
Training loss: 2.423919602234807
Validation loss: 2.567264879685367

Epoch: 5| Step: 11
Training loss: 2.936427793223333
Validation loss: 2.522992408795704

Epoch: 297| Step: 0
Training loss: 2.3978227952159186
Validation loss: 2.50236453054555

Epoch: 5| Step: 1
Training loss: 2.4822084588754807
Validation loss: 2.478270169592446

Epoch: 5| Step: 2
Training loss: 2.826911623825276
Validation loss: 2.4840900529638774

Epoch: 5| Step: 3
Training loss: 2.997205545376859
Validation loss: 2.4814452364362465

Epoch: 5| Step: 4
Training loss: 2.094709034381793
Validation loss: 2.474244594408883

Epoch: 5| Step: 5
Training loss: 2.541109920455653
Validation loss: 2.4738368048014427

Epoch: 5| Step: 6
Training loss: 2.4418309200966575
Validation loss: 2.4742121730211535

Epoch: 5| Step: 7
Training loss: 2.170908431537668
Validation loss: 2.466229747860497

Epoch: 5| Step: 8
Training loss: 2.6755788016479958
Validation loss: 2.487015494568949

Epoch: 5| Step: 9
Training loss: 1.4297416134791934
Validation loss: 2.4837187054113166

Epoch: 5| Step: 10
Training loss: 1.9790820923520158
Validation loss: 2.477121737262403

Epoch: 5| Step: 11
Training loss: 2.3891028251762494
Validation loss: 2.5082383670656894

Epoch: 298| Step: 0
Training loss: 1.8977124748836693
Validation loss: 2.502862626515781

Epoch: 5| Step: 1
Training loss: 2.305921734860541
Validation loss: 2.546114954431428

Epoch: 5| Step: 2
Training loss: 2.3418761837266304
Validation loss: 2.5536047403441056

Epoch: 5| Step: 3
Training loss: 2.997252000439433
Validation loss: 2.5669652174322044

Epoch: 5| Step: 4
Training loss: 1.7721758820797517
Validation loss: 2.6079955614070234

Epoch: 5| Step: 5
Training loss: 1.402354503367219
Validation loss: 2.6180135647391

Epoch: 5| Step: 6
Training loss: 2.664783369066374
Validation loss: 2.6425656630623275

Epoch: 5| Step: 7
Training loss: 2.455993336087608
Validation loss: 2.676737400567657

Epoch: 5| Step: 8
Training loss: 2.3917519898652055
Validation loss: 2.6660171415629748

Epoch: 5| Step: 9
Training loss: 2.6237593852652683
Validation loss: 2.618428984398764

Epoch: 5| Step: 10
Training loss: 2.682484493299675
Validation loss: 2.5625558009701237

Epoch: 5| Step: 11
Training loss: 1.8042977312626514
Validation loss: 2.5364775856013284

Epoch: 299| Step: 0
Training loss: 2.8626844921377343
Validation loss: 2.5041637913078603

Epoch: 5| Step: 1
Training loss: 2.14070864326064
Validation loss: 2.501966636714538

Epoch: 5| Step: 2
Training loss: 2.6081162574634336
Validation loss: 2.498770149039038

Epoch: 5| Step: 3
Training loss: 2.5487321506715253
Validation loss: 2.504609333102862

Epoch: 5| Step: 4
Training loss: 2.5773322533856673
Validation loss: 2.510028090155162

Epoch: 5| Step: 5
Training loss: 2.209877649778319
Validation loss: 2.497909454630117

Epoch: 5| Step: 6
Training loss: 2.464287406415339
Validation loss: 2.5029965442743345

Epoch: 5| Step: 7
Training loss: 1.9016969431083741
Validation loss: 2.4917242881295696

Epoch: 5| Step: 8
Training loss: 1.704254196020811
Validation loss: 2.505620463858717

Epoch: 5| Step: 9
Training loss: 2.7558271053379566
Validation loss: 2.5098637186911423

Epoch: 5| Step: 10
Training loss: 2.2670396268903987
Validation loss: 2.5188181930221076

Epoch: 5| Step: 11
Training loss: 2.387688622338531
Validation loss: 2.5306625626466768

Epoch: 300| Step: 0
Training loss: 2.1577824109166635
Validation loss: 2.54230694575195

Epoch: 5| Step: 1
Training loss: 1.932531693212242
Validation loss: 2.5628718052150656

Epoch: 5| Step: 2
Training loss: 2.099166809279904
Validation loss: 2.560481016552146

Epoch: 5| Step: 3
Training loss: 2.5025350115877325
Validation loss: 2.5700541079424912

Epoch: 5| Step: 4
Training loss: 1.7074448981267771
Validation loss: 2.594658252150439

Epoch: 5| Step: 5
Training loss: 2.257961915032029
Validation loss: 2.5927886617612264

Epoch: 5| Step: 6
Training loss: 2.39283042355974
Validation loss: 2.6040376376929784

Epoch: 5| Step: 7
Training loss: 2.394507552709515
Validation loss: 2.6167920625206484

Epoch: 5| Step: 8
Training loss: 2.737140064004849
Validation loss: 2.599783486741298

Epoch: 5| Step: 9
Training loss: 2.5098106528669906
Validation loss: 2.6193809768801533

Epoch: 5| Step: 10
Training loss: 2.5799283280878305
Validation loss: 2.5658554693825977

Epoch: 5| Step: 11
Training loss: 2.999805444130789
Validation loss: 2.5485186080764697

Testing loss: 2.04584068860949
