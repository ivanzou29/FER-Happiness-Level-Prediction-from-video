Epoch: 1| Step: 0
Training loss: 6.058371485083226
Validation loss: 5.851889220463583

Epoch: 5| Step: 1
Training loss: 5.810579044028598
Validation loss: 5.850658372364726

Epoch: 5| Step: 2
Training loss: 6.175483517886474
Validation loss: 5.84939190646603

Epoch: 5| Step: 3
Training loss: 5.562257568562715
Validation loss: 5.848203386707751

Epoch: 5| Step: 4
Training loss: 5.743430987808485
Validation loss: 5.846974617051511

Epoch: 5| Step: 5
Training loss: 5.939136159229816
Validation loss: 5.845722987392647

Epoch: 5| Step: 6
Training loss: 6.570511641415794
Validation loss: 5.844449883638968

Epoch: 5| Step: 7
Training loss: 6.479301361286654
Validation loss: 5.843141547909432

Epoch: 5| Step: 8
Training loss: 5.519067311480035
Validation loss: 5.841779182736342

Epoch: 5| Step: 9
Training loss: 5.674614363015809
Validation loss: 5.840396789424789

Epoch: 5| Step: 10
Training loss: 6.061222531725886
Validation loss: 5.838993400999882

Epoch: 5| Step: 11
Training loss: 5.41249033021834
Validation loss: 5.837457053048991

Epoch: 2| Step: 0
Training loss: 5.106063469569629
Validation loss: 5.83590914758947

Epoch: 5| Step: 1
Training loss: 6.0897288039384465
Validation loss: 5.834413566931827

Epoch: 5| Step: 2
Training loss: 6.5904995829920185
Validation loss: 5.832790270004333

Epoch: 5| Step: 3
Training loss: 6.296841074660472
Validation loss: 5.831051675436579

Epoch: 5| Step: 4
Training loss: 5.479229113243489
Validation loss: 5.82921793953535

Epoch: 5| Step: 5
Training loss: 5.64246725077119
Validation loss: 5.827380544451956

Epoch: 5| Step: 6
Training loss: 5.650306065464317
Validation loss: 5.8253766245095955

Epoch: 5| Step: 7
Training loss: 5.991242056892489
Validation loss: 5.823286623681008

Epoch: 5| Step: 8
Training loss: 6.7156668752693385
Validation loss: 5.8211978861910465

Epoch: 5| Step: 9
Training loss: 6.41828079068729
Validation loss: 5.818836470472592

Epoch: 5| Step: 10
Training loss: 5.605488655506904
Validation loss: 5.816514054548922

Epoch: 5| Step: 11
Training loss: 3.191592861215267
Validation loss: 5.813880578707626

Epoch: 3| Step: 0
Training loss: 5.788957067191054
Validation loss: 5.811326595531072

Epoch: 5| Step: 1
Training loss: 6.414876944238042
Validation loss: 5.808643285270335

Epoch: 5| Step: 2
Training loss: 5.4270949506970885
Validation loss: 5.805704115934515

Epoch: 5| Step: 3
Training loss: 6.037005746643759
Validation loss: 5.802703415651013

Epoch: 5| Step: 4
Training loss: 6.156260843799935
Validation loss: 5.79945068169667

Epoch: 5| Step: 5
Training loss: 5.968398158703099
Validation loss: 5.795979823992872

Epoch: 5| Step: 6
Training loss: 6.6011946897351175
Validation loss: 5.792329601612781

Epoch: 5| Step: 7
Training loss: 5.964412051544182
Validation loss: 5.788375395008661

Epoch: 5| Step: 8
Training loss: 5.272546582728408
Validation loss: 5.784279636041413

Epoch: 5| Step: 9
Training loss: 5.4989099289308365
Validation loss: 5.779796775107299

Epoch: 5| Step: 10
Training loss: 5.830203097488027
Validation loss: 5.775499635471116

Epoch: 5| Step: 11
Training loss: 5.545566974131247
Validation loss: 5.770826541699247

Epoch: 4| Step: 0
Training loss: 5.532234406023787
Validation loss: 5.766180099602795

Epoch: 5| Step: 1
Training loss: 5.522672737842749
Validation loss: 5.761187361011635

Epoch: 5| Step: 2
Training loss: 6.439837281440097
Validation loss: 5.7560550210729655

Epoch: 5| Step: 3
Training loss: 5.61140443435974
Validation loss: 5.750730806708253

Epoch: 5| Step: 4
Training loss: 5.772938955872687
Validation loss: 5.745290887283813

Epoch: 5| Step: 5
Training loss: 6.211812659450805
Validation loss: 5.739540386096965

Epoch: 5| Step: 6
Training loss: 5.732263826079304
Validation loss: 5.733740748116692

Epoch: 5| Step: 7
Training loss: 5.660022131131852
Validation loss: 5.7277097710733536

Epoch: 5| Step: 8
Training loss: 6.262791475681678
Validation loss: 5.721550830580046

Epoch: 5| Step: 9
Training loss: 5.152680982495719
Validation loss: 5.715433447957968

Epoch: 5| Step: 10
Training loss: 6.362805839937148
Validation loss: 5.708820213196253

Epoch: 5| Step: 11
Training loss: 5.78303459048163
Validation loss: 5.702559755785149

Epoch: 5| Step: 0
Training loss: 5.427393322936928
Validation loss: 5.695982298429715

Epoch: 5| Step: 1
Training loss: 6.2741388710322665
Validation loss: 5.689567281038522

Epoch: 5| Step: 2
Training loss: 5.33561185007842
Validation loss: 5.6827998879556425

Epoch: 5| Step: 3
Training loss: 5.847295491335142
Validation loss: 5.676094629361841

Epoch: 5| Step: 4
Training loss: 5.058854097125255
Validation loss: 5.66934728563586

Epoch: 5| Step: 5
Training loss: 6.0435611604619455
Validation loss: 5.662378401920832

Epoch: 5| Step: 6
Training loss: 5.694176412751124
Validation loss: 5.655427967846152

Epoch: 5| Step: 7
Training loss: 6.399022635695132
Validation loss: 5.648465850744858

Epoch: 5| Step: 8
Training loss: 5.833798998456712
Validation loss: 5.641258647970396

Epoch: 5| Step: 9
Training loss: 5.728401419655141
Validation loss: 5.634106230430209

Epoch: 5| Step: 10
Training loss: 5.454566743115583
Validation loss: 5.6269258875630666

Epoch: 5| Step: 11
Training loss: 7.228030889667821
Validation loss: 5.619561420163285

Epoch: 6| Step: 0
Training loss: 5.707930204909753
Validation loss: 5.611926299965032

Epoch: 5| Step: 1
Training loss: 6.277960527998984
Validation loss: 5.604515265739479

Epoch: 5| Step: 2
Training loss: 5.691479642521814
Validation loss: 5.5969721998858235

Epoch: 5| Step: 3
Training loss: 5.405256058717546
Validation loss: 5.589226710653585

Epoch: 5| Step: 4
Training loss: 5.707331362959495
Validation loss: 5.581543716271765

Epoch: 5| Step: 5
Training loss: 5.341646193030167
Validation loss: 5.573936378617792

Epoch: 5| Step: 6
Training loss: 6.466853799111437
Validation loss: 5.566512485851184

Epoch: 5| Step: 7
Training loss: 5.281396987946192
Validation loss: 5.558788768843852

Epoch: 5| Step: 8
Training loss: 5.959383180689685
Validation loss: 5.5510083912015356

Epoch: 5| Step: 9
Training loss: 4.8442797955600065
Validation loss: 5.543663484972745

Epoch: 5| Step: 10
Training loss: 5.6654971916818635
Validation loss: 5.535683738899624

Epoch: 5| Step: 11
Training loss: 6.112734600159914
Validation loss: 5.528014369940862

Epoch: 7| Step: 0
Training loss: 5.5527893342777865
Validation loss: 5.520564417017722

Epoch: 5| Step: 1
Training loss: 5.444355468714966
Validation loss: 5.513056011805486

Epoch: 5| Step: 2
Training loss: 6.083378970179666
Validation loss: 5.505743466885158

Epoch: 5| Step: 3
Training loss: 5.19934384534425
Validation loss: 5.498027071965151

Epoch: 5| Step: 4
Training loss: 5.89432253761959
Validation loss: 5.490663449929512

Epoch: 5| Step: 5
Training loss: 6.057968805917277
Validation loss: 5.483555651953269

Epoch: 5| Step: 6
Training loss: 5.326572941674461
Validation loss: 5.476032334812517

Epoch: 5| Step: 7
Training loss: 5.9889430845533616
Validation loss: 5.469608021592254

Epoch: 5| Step: 8
Training loss: 5.901906187247168
Validation loss: 5.462016015977168

Epoch: 5| Step: 9
Training loss: 5.363352731338109
Validation loss: 5.455064335801192

Epoch: 5| Step: 10
Training loss: 5.079068985276942
Validation loss: 5.448133827777932

Epoch: 5| Step: 11
Training loss: 3.3165166721899744
Validation loss: 5.441133359486585

Epoch: 8| Step: 0
Training loss: 5.480324839132004
Validation loss: 5.434443056639394

Epoch: 5| Step: 1
Training loss: 5.899410748555806
Validation loss: 5.42787820873232

Epoch: 5| Step: 2
Training loss: 5.190676716105345
Validation loss: 5.421219074248136

Epoch: 5| Step: 3
Training loss: 5.478565758460456
Validation loss: 5.414665522531969

Epoch: 5| Step: 4
Training loss: 5.331654562587102
Validation loss: 5.407924319329777

Epoch: 5| Step: 5
Training loss: 5.7713221080192465
Validation loss: 5.401272667335007

Epoch: 5| Step: 6
Training loss: 5.642871187547861
Validation loss: 5.394318153100379

Epoch: 5| Step: 7
Training loss: 5.920508556688709
Validation loss: 5.387608127143246

Epoch: 5| Step: 8
Training loss: 5.225374688398457
Validation loss: 5.380488690890966

Epoch: 5| Step: 9
Training loss: 4.626377416101698
Validation loss: 5.373878443312004

Epoch: 5| Step: 10
Training loss: 5.985666638616168
Validation loss: 5.36713585974492

Epoch: 5| Step: 11
Training loss: 5.7219066141902095
Validation loss: 5.360369798514936

Epoch: 9| Step: 0
Training loss: 6.120831375000573
Validation loss: 5.353035954619811

Epoch: 5| Step: 1
Training loss: 5.523414536230111
Validation loss: 5.345972420698488

Epoch: 5| Step: 2
Training loss: 5.683766575443687
Validation loss: 5.339161417893891

Epoch: 5| Step: 3
Training loss: 5.35294625985435
Validation loss: 5.3318298301800136

Epoch: 5| Step: 4
Training loss: 5.4478643450099655
Validation loss: 5.324827678560684

Epoch: 5| Step: 5
Training loss: 5.0184926424275655
Validation loss: 5.317700701442502

Epoch: 5| Step: 6
Training loss: 5.362406682267337
Validation loss: 5.310665008177527

Epoch: 5| Step: 7
Training loss: 5.361232424578472
Validation loss: 5.303901033524882

Epoch: 5| Step: 8
Training loss: 4.503297021824395
Validation loss: 5.2973319412632565

Epoch: 5| Step: 9
Training loss: 5.180374767340925
Validation loss: 5.2907441403891085

Epoch: 5| Step: 10
Training loss: 5.965599626713982
Validation loss: 5.2843444155592465

Epoch: 5| Step: 11
Training loss: 6.111972890643969
Validation loss: 5.278100844863056

Epoch: 10| Step: 0
Training loss: 5.589453725583517
Validation loss: 5.271685726112422

Epoch: 5| Step: 1
Training loss: 5.635066878862046
Validation loss: 5.265818893228492

Epoch: 5| Step: 2
Training loss: 5.66197934483325
Validation loss: 5.259758546156097

Epoch: 5| Step: 3
Training loss: 5.05165388766218
Validation loss: 5.253679431807722

Epoch: 5| Step: 4
Training loss: 5.468036714085943
Validation loss: 5.247195728610507

Epoch: 5| Step: 5
Training loss: 4.605648279937496
Validation loss: 5.241154841414314

Epoch: 5| Step: 6
Training loss: 5.924243785388219
Validation loss: 5.234967265617288

Epoch: 5| Step: 7
Training loss: 5.0770035194924255
Validation loss: 5.229119048592023

Epoch: 5| Step: 8
Training loss: 5.885953715529661
Validation loss: 5.22343919430499

Epoch: 5| Step: 9
Training loss: 5.4236134317316855
Validation loss: 5.217753080984821

Epoch: 5| Step: 10
Training loss: 4.768674981363362
Validation loss: 5.211990364463958

Epoch: 5| Step: 11
Training loss: 3.8125096305350317
Validation loss: 5.206489086423843

Epoch: 11| Step: 0
Training loss: 4.922049576827032
Validation loss: 5.201276089823553

Epoch: 5| Step: 1
Training loss: 5.37503158205202
Validation loss: 5.196014551899262

Epoch: 5| Step: 2
Training loss: 4.303199358528289
Validation loss: 5.190333163397725

Epoch: 5| Step: 3
Training loss: 5.334147609697907
Validation loss: 5.185450505225044

Epoch: 5| Step: 4
Training loss: 5.8798671608795585
Validation loss: 5.179980369945531

Epoch: 5| Step: 5
Training loss: 5.784462855664686
Validation loss: 5.174828115548083

Epoch: 5| Step: 6
Training loss: 4.877773571857405
Validation loss: 5.169719634924033

Epoch: 5| Step: 7
Training loss: 5.372311296659277
Validation loss: 5.164703621745195

Epoch: 5| Step: 8
Training loss: 4.869090876074574
Validation loss: 5.159628013970448

Epoch: 5| Step: 9
Training loss: 5.571564735593159
Validation loss: 5.154927509906946

Epoch: 5| Step: 10
Training loss: 5.850563035263345
Validation loss: 5.149268909523156

Epoch: 5| Step: 11
Training loss: 4.679629623233502
Validation loss: 5.144030408296246

Epoch: 12| Step: 0
Training loss: 5.250410336398625
Validation loss: 5.138564843909718

Epoch: 5| Step: 1
Training loss: 5.098594187539246
Validation loss: 5.133657593930726

Epoch: 5| Step: 2
Training loss: 5.787610653175791
Validation loss: 5.128335999017138

Epoch: 5| Step: 3
Training loss: 5.122587799317719
Validation loss: 5.123504032665899

Epoch: 5| Step: 4
Training loss: 5.2330362458346995
Validation loss: 5.117842320290897

Epoch: 5| Step: 5
Training loss: 4.943587015698935
Validation loss: 5.113050462892678

Epoch: 5| Step: 6
Training loss: 5.107614756455915
Validation loss: 5.108053878475134

Epoch: 5| Step: 7
Training loss: 5.253044517213718
Validation loss: 5.102761759058248

Epoch: 5| Step: 8
Training loss: 5.810931250416779
Validation loss: 5.09779439960622

Epoch: 5| Step: 9
Training loss: 5.370517369642049
Validation loss: 5.092766883385044

Epoch: 5| Step: 10
Training loss: 4.754532107528925
Validation loss: 5.087378298298093

Epoch: 5| Step: 11
Training loss: 3.884192484390847
Validation loss: 5.08262536585567

Epoch: 13| Step: 0
Training loss: 4.987219689315099
Validation loss: 5.077620691542605

Epoch: 5| Step: 1
Training loss: 5.410300969691206
Validation loss: 5.072460172298491

Epoch: 5| Step: 2
Training loss: 4.657356489164544
Validation loss: 5.067194806459398

Epoch: 5| Step: 3
Training loss: 5.352725694754145
Validation loss: 5.062695409198059

Epoch: 5| Step: 4
Training loss: 4.79769125091552
Validation loss: 5.057532891735227

Epoch: 5| Step: 5
Training loss: 5.256685269326285
Validation loss: 5.052189857959148

Epoch: 5| Step: 6
Training loss: 5.561168554167929
Validation loss: 5.048040414894751

Epoch: 5| Step: 7
Training loss: 5.45639962846542
Validation loss: 5.04276534265439

Epoch: 5| Step: 8
Training loss: 5.017005611557205
Validation loss: 5.037677757970011

Epoch: 5| Step: 9
Training loss: 5.661214936144242
Validation loss: 5.032121736814208

Epoch: 5| Step: 10
Training loss: 4.408512048878558
Validation loss: 5.027433088803595

Epoch: 5| Step: 11
Training loss: 6.1300989841851825
Validation loss: 5.022407730733526

Epoch: 14| Step: 0
Training loss: 5.083585930890521
Validation loss: 5.017775877543565

Epoch: 5| Step: 1
Training loss: 4.8156343632037055
Validation loss: 5.0122925728919805

Epoch: 5| Step: 2
Training loss: 4.997873617063428
Validation loss: 5.007874042610905

Epoch: 5| Step: 3
Training loss: 5.0307431172994574
Validation loss: 5.002210613168815

Epoch: 5| Step: 4
Training loss: 5.287284698792376
Validation loss: 4.997576650820761

Epoch: 5| Step: 5
Training loss: 4.412694236219329
Validation loss: 4.993544766661212

Epoch: 5| Step: 6
Training loss: 3.945665037815198
Validation loss: 4.988791371716164

Epoch: 5| Step: 7
Training loss: 5.894068513356179
Validation loss: 4.984123215648861

Epoch: 5| Step: 8
Training loss: 5.3459387864227095
Validation loss: 4.979141644956321

Epoch: 5| Step: 9
Training loss: 5.6356068953339316
Validation loss: 4.97459022010058

Epoch: 5| Step: 10
Training loss: 5.346090060952895
Validation loss: 4.970099851601753

Epoch: 5| Step: 11
Training loss: 6.0131872216607505
Validation loss: 4.9653461401204355

Epoch: 15| Step: 0
Training loss: 4.629925141687169
Validation loss: 4.960453576542488

Epoch: 5| Step: 1
Training loss: 4.186850654017629
Validation loss: 4.955766833735685

Epoch: 5| Step: 2
Training loss: 4.988004218215199
Validation loss: 4.951621564498995

Epoch: 5| Step: 3
Training loss: 5.161788647575211
Validation loss: 4.946679993394721

Epoch: 5| Step: 4
Training loss: 5.299823131849009
Validation loss: 4.942317447407243

Epoch: 5| Step: 5
Training loss: 4.816455157078842
Validation loss: 4.938114892520916

Epoch: 5| Step: 6
Training loss: 5.450462762626879
Validation loss: 4.933289877704445

Epoch: 5| Step: 7
Training loss: 5.6691070612422
Validation loss: 4.928484923661241

Epoch: 5| Step: 8
Training loss: 5.248367782452256
Validation loss: 4.924362337235181

Epoch: 5| Step: 9
Training loss: 5.128609851369897
Validation loss: 4.91977715566502

Epoch: 5| Step: 10
Training loss: 4.970115234144358
Validation loss: 4.91498700508529

Epoch: 5| Step: 11
Training loss: 4.863563621320566
Validation loss: 4.910381828878302

Epoch: 16| Step: 0
Training loss: 5.046943404262631
Validation loss: 4.906423739780972

Epoch: 5| Step: 1
Training loss: 5.297784687797967
Validation loss: 4.901925653509402

Epoch: 5| Step: 2
Training loss: 5.2010066671917325
Validation loss: 4.897727018400705

Epoch: 5| Step: 3
Training loss: 5.2047171691213805
Validation loss: 4.89302208181243

Epoch: 5| Step: 4
Training loss: 5.210035529134494
Validation loss: 4.888930395821938

Epoch: 5| Step: 5
Training loss: 5.7322545093753385
Validation loss: 4.884617269002688

Epoch: 5| Step: 6
Training loss: 5.103954181011067
Validation loss: 4.880321882698572

Epoch: 5| Step: 7
Training loss: 5.6165893405983365
Validation loss: 4.876510337249929

Epoch: 5| Step: 8
Training loss: 3.9878632478673848
Validation loss: 4.871967456552862

Epoch: 5| Step: 9
Training loss: 4.027584331441739
Validation loss: 4.867513532418913

Epoch: 5| Step: 10
Training loss: 4.536226473232468
Validation loss: 4.863566382857274

Epoch: 5| Step: 11
Training loss: 4.014759727499974
Validation loss: 4.859204868883276

Epoch: 17| Step: 0
Training loss: 4.674278228039597
Validation loss: 4.855645575235708

Epoch: 5| Step: 1
Training loss: 4.292845456103137
Validation loss: 4.8516654609242735

Epoch: 5| Step: 2
Training loss: 5.378790295250709
Validation loss: 4.847644651175206

Epoch: 5| Step: 3
Training loss: 6.026127196166291
Validation loss: 4.8439583272125795

Epoch: 5| Step: 4
Training loss: 3.964872974607503
Validation loss: 4.839834045449688

Epoch: 5| Step: 5
Training loss: 5.119169128175607
Validation loss: 4.835785156216868

Epoch: 5| Step: 6
Training loss: 4.739049234444012
Validation loss: 4.832172512003322

Epoch: 5| Step: 7
Training loss: 4.8335219160099845
Validation loss: 4.828437268344761

Epoch: 5| Step: 8
Training loss: 4.4619618323731425
Validation loss: 4.824467220934734

Epoch: 5| Step: 9
Training loss: 4.702960749701449
Validation loss: 4.8207149657035595

Epoch: 5| Step: 10
Training loss: 5.779996168933906
Validation loss: 4.816803811880657

Epoch: 5| Step: 11
Training loss: 5.892857459922881
Validation loss: 4.813000186506699

Epoch: 18| Step: 0
Training loss: 5.139571710992709
Validation loss: 4.809009012429739

Epoch: 5| Step: 1
Training loss: 4.237619205924929
Validation loss: 4.804880443306895

Epoch: 5| Step: 2
Training loss: 4.9328334340281765
Validation loss: 4.801231299035093

Epoch: 5| Step: 3
Training loss: 4.667031319313083
Validation loss: 4.797837424883443

Epoch: 5| Step: 4
Training loss: 4.81089855152308
Validation loss: 4.794122318230901

Epoch: 5| Step: 5
Training loss: 5.503728296504394
Validation loss: 4.7900619086324445

Epoch: 5| Step: 6
Training loss: 4.508526882640188
Validation loss: 4.785656774384751

Epoch: 5| Step: 7
Training loss: 5.393538685501565
Validation loss: 4.78189243829177

Epoch: 5| Step: 8
Training loss: 5.1362226471459245
Validation loss: 4.778120475252952

Epoch: 5| Step: 9
Training loss: 5.085158515492466
Validation loss: 4.774031498605186

Epoch: 5| Step: 10
Training loss: 4.379017756162797
Validation loss: 4.770570908815397

Epoch: 5| Step: 11
Training loss: 5.380224483302036
Validation loss: 4.766285476359122

Epoch: 19| Step: 0
Training loss: 4.240295550284174
Validation loss: 4.762268289217485

Epoch: 5| Step: 1
Training loss: 4.484319493817522
Validation loss: 4.7584765909857785

Epoch: 5| Step: 2
Training loss: 4.689188742026664
Validation loss: 4.754470043660734

Epoch: 5| Step: 3
Training loss: 4.645907186197726
Validation loss: 4.750583604464059

Epoch: 5| Step: 4
Training loss: 5.203944602771146
Validation loss: 4.746400473145629

Epoch: 5| Step: 5
Training loss: 4.297019262493052
Validation loss: 4.742854792545905

Epoch: 5| Step: 6
Training loss: 5.807430558760408
Validation loss: 4.739360077458987

Epoch: 5| Step: 7
Training loss: 5.21642941716437
Validation loss: 4.735614383573674

Epoch: 5| Step: 8
Training loss: 4.596668380357083
Validation loss: 4.731318046083855

Epoch: 5| Step: 9
Training loss: 4.896482232560859
Validation loss: 4.727543063425715

Epoch: 5| Step: 10
Training loss: 5.19443462096638
Validation loss: 4.72333091205884

Epoch: 5| Step: 11
Training loss: 5.125559334354665
Validation loss: 4.719534322468958

Epoch: 20| Step: 0
Training loss: 4.791409140038159
Validation loss: 4.715734811106348

Epoch: 5| Step: 1
Training loss: 5.375197650912658
Validation loss: 4.711497529219839

Epoch: 5| Step: 2
Training loss: 4.693000516217193
Validation loss: 4.707581851144321

Epoch: 5| Step: 3
Training loss: 4.982828791326456
Validation loss: 4.703646617195616

Epoch: 5| Step: 4
Training loss: 4.317018215244401
Validation loss: 4.699842420601256

Epoch: 5| Step: 5
Training loss: 5.04104608336643
Validation loss: 4.696441345432307

Epoch: 5| Step: 6
Training loss: 4.700310660301586
Validation loss: 4.692431157683769

Epoch: 5| Step: 7
Training loss: 4.262245488329269
Validation loss: 4.688323605555913

Epoch: 5| Step: 8
Training loss: 4.916902288620827
Validation loss: 4.684352046612572

Epoch: 5| Step: 9
Training loss: 5.108218187504079
Validation loss: 4.680310411130368

Epoch: 5| Step: 10
Training loss: 4.712128294190756
Validation loss: 4.675598795344469

Epoch: 5| Step: 11
Training loss: 5.014344809606626
Validation loss: 4.671446696607769

Epoch: 21| Step: 0
Training loss: 5.2410265209718485
Validation loss: 4.667382988562129

Epoch: 5| Step: 1
Training loss: 4.5747028358546915
Validation loss: 4.6632990550394

Epoch: 5| Step: 2
Training loss: 4.759253873930602
Validation loss: 4.658746771074805

Epoch: 5| Step: 3
Training loss: 5.515950914647251
Validation loss: 4.654422170831062

Epoch: 5| Step: 4
Training loss: 4.409049585393655
Validation loss: 4.6509737249739596

Epoch: 5| Step: 5
Training loss: 4.280184870853889
Validation loss: 4.646605101090422

Epoch: 5| Step: 6
Training loss: 4.438217320021218
Validation loss: 4.643181350413306

Epoch: 5| Step: 7
Training loss: 4.997278998995236
Validation loss: 4.639016503097126

Epoch: 5| Step: 8
Training loss: 4.76690596577825
Validation loss: 4.635005686968045

Epoch: 5| Step: 9
Training loss: 5.417026957731613
Validation loss: 4.630981057578276

Epoch: 5| Step: 10
Training loss: 3.86677872780398
Validation loss: 4.626656948586921

Epoch: 5| Step: 11
Training loss: 4.664878888781258
Validation loss: 4.622580969599752

Epoch: 22| Step: 0
Training loss: 4.499670440474055
Validation loss: 4.61905214683309

Epoch: 5| Step: 1
Training loss: 4.714787922981415
Validation loss: 4.615047851960532

Epoch: 5| Step: 2
Training loss: 3.9919677196107264
Validation loss: 4.611610969422643

Epoch: 5| Step: 3
Training loss: 4.166994361707014
Validation loss: 4.607493500410861

Epoch: 5| Step: 4
Training loss: 4.76370730979287
Validation loss: 4.603454606702875

Epoch: 5| Step: 5
Training loss: 5.251072910213114
Validation loss: 4.59948301364463

Epoch: 5| Step: 6
Training loss: 4.486315157999872
Validation loss: 4.595839589593986

Epoch: 5| Step: 7
Training loss: 4.943914761311552
Validation loss: 4.591890689741185

Epoch: 5| Step: 8
Training loss: 5.041968638726965
Validation loss: 4.587787053744604

Epoch: 5| Step: 9
Training loss: 3.8627294873453444
Validation loss: 4.584044187502568

Epoch: 5| Step: 10
Training loss: 5.481145793833333
Validation loss: 4.579851365322065

Epoch: 5| Step: 11
Training loss: 6.754265179426528
Validation loss: 4.576016405943158

Epoch: 23| Step: 0
Training loss: 3.589528531751939
Validation loss: 4.571880564987192

Epoch: 5| Step: 1
Training loss: 4.120516102880993
Validation loss: 4.568049804845226

Epoch: 5| Step: 2
Training loss: 4.921748083991145
Validation loss: 4.563971808992002

Epoch: 5| Step: 3
Training loss: 4.839687883701335
Validation loss: 4.55981368842897

Epoch: 5| Step: 4
Training loss: 5.374821149822394
Validation loss: 4.555562645756753

Epoch: 5| Step: 5
Training loss: 4.2499719506628395
Validation loss: 4.551648124241271

Epoch: 5| Step: 6
Training loss: 5.325771852529482
Validation loss: 4.547550688676572

Epoch: 5| Step: 7
Training loss: 4.608061625982506
Validation loss: 4.5437520019722735

Epoch: 5| Step: 8
Training loss: 4.1166598074131295
Validation loss: 4.5396438725312365

Epoch: 5| Step: 9
Training loss: 4.778640733208563
Validation loss: 4.535605825329608

Epoch: 5| Step: 10
Training loss: 5.346290742845103
Validation loss: 4.531706898772452

Epoch: 5| Step: 11
Training loss: 3.714655184447577
Validation loss: 4.527562234613348

Epoch: 24| Step: 0
Training loss: 4.653369601490009
Validation loss: 4.523695750048691

Epoch: 5| Step: 1
Training loss: 4.9663149066930306
Validation loss: 4.519873832218954

Epoch: 5| Step: 2
Training loss: 5.057666496217687
Validation loss: 4.515888360427323

Epoch: 5| Step: 3
Training loss: 4.648111283852838
Validation loss: 4.511751310773221

Epoch: 5| Step: 4
Training loss: 4.614538991928904
Validation loss: 4.507902751616354

Epoch: 5| Step: 5
Training loss: 4.785733184289118
Validation loss: 4.504465810044659

Epoch: 5| Step: 6
Training loss: 4.883083000319849
Validation loss: 4.499995699633204

Epoch: 5| Step: 7
Training loss: 3.5634372214531567
Validation loss: 4.495816272753899

Epoch: 5| Step: 8
Training loss: 4.637747029513967
Validation loss: 4.491919866135861

Epoch: 5| Step: 9
Training loss: 4.857485879277758
Validation loss: 4.487929385441726

Epoch: 5| Step: 10
Training loss: 4.282374324880817
Validation loss: 4.4841361652356095

Epoch: 5| Step: 11
Training loss: 3.673837210498468
Validation loss: 4.480132290158513

Epoch: 25| Step: 0
Training loss: 4.47865893421223
Validation loss: 4.4763654983960945

Epoch: 5| Step: 1
Training loss: 5.099853790281735
Validation loss: 4.472327492082457

Epoch: 5| Step: 2
Training loss: 4.644648288185798
Validation loss: 4.468493998915304

Epoch: 5| Step: 3
Training loss: 4.757578977168852
Validation loss: 4.464431676930759

Epoch: 5| Step: 4
Training loss: 4.953386847376815
Validation loss: 4.460476011332538

Epoch: 5| Step: 5
Training loss: 4.80821909556664
Validation loss: 4.456469211474441

Epoch: 5| Step: 6
Training loss: 3.9835779926282417
Validation loss: 4.452133532348057

Epoch: 5| Step: 7
Training loss: 4.267564716798159
Validation loss: 4.448161833868208

Epoch: 5| Step: 8
Training loss: 4.603864680034094
Validation loss: 4.444132187258514

Epoch: 5| Step: 9
Training loss: 4.242353404473426
Validation loss: 4.440158101609126

Epoch: 5| Step: 10
Training loss: 4.538962909702424
Validation loss: 4.4360709598141215

Epoch: 5| Step: 11
Training loss: 4.3304509822694985
Validation loss: 4.432104466120048

Epoch: 26| Step: 0
Training loss: 4.9744538970721885
Validation loss: 4.428453752423585

Epoch: 5| Step: 1
Training loss: 3.9609175160522754
Validation loss: 4.4240989708812375

Epoch: 5| Step: 2
Training loss: 3.783209300983924
Validation loss: 4.419837347377912

Epoch: 5| Step: 3
Training loss: 4.2180188711077955
Validation loss: 4.416564785783932

Epoch: 5| Step: 4
Training loss: 4.47880351642274
Validation loss: 4.413044851018562

Epoch: 5| Step: 5
Training loss: 4.67206381731996
Validation loss: 4.4090242377471744

Epoch: 5| Step: 6
Training loss: 4.917914065298631
Validation loss: 4.404723509476341

Epoch: 5| Step: 7
Training loss: 3.932537524219512
Validation loss: 4.400512558170062

Epoch: 5| Step: 8
Training loss: 5.1016492383514445
Validation loss: 4.396680292311333

Epoch: 5| Step: 9
Training loss: 4.933926798376056
Validation loss: 4.392945799614135

Epoch: 5| Step: 10
Training loss: 4.160494594515908
Validation loss: 4.388889960934042

Epoch: 5| Step: 11
Training loss: 6.641736464889507
Validation loss: 4.3846639891854995

Epoch: 27| Step: 0
Training loss: 4.252192660914732
Validation loss: 4.379867089851819

Epoch: 5| Step: 1
Training loss: 4.194734615256565
Validation loss: 4.3754325107953225

Epoch: 5| Step: 2
Training loss: 3.5508279828814113
Validation loss: 4.371179783815037

Epoch: 5| Step: 3
Training loss: 4.421621146851478
Validation loss: 4.366960591271401

Epoch: 5| Step: 4
Training loss: 4.638976758072676
Validation loss: 4.3626255782451535

Epoch: 5| Step: 5
Training loss: 5.406175557765115
Validation loss: 4.3581986475180114

Epoch: 5| Step: 6
Training loss: 4.107259807935555
Validation loss: 4.353418635797844

Epoch: 5| Step: 7
Training loss: 4.380710471722657
Validation loss: 4.34863515174632

Epoch: 5| Step: 8
Training loss: 4.515563753234083
Validation loss: 4.343976922820167

Epoch: 5| Step: 9
Training loss: 5.056719269920001
Validation loss: 4.339342131239524

Epoch: 5| Step: 10
Training loss: 4.493915683201523
Validation loss: 4.334550130396032

Epoch: 5| Step: 11
Training loss: 4.824439756450799
Validation loss: 4.329593345107497

Epoch: 28| Step: 0
Training loss: 4.416994238647821
Validation loss: 4.325293940549854

Epoch: 5| Step: 1
Training loss: 3.7942987186591486
Validation loss: 4.3207060006390785

Epoch: 5| Step: 2
Training loss: 3.8243490475520416
Validation loss: 4.31649204819046

Epoch: 5| Step: 3
Training loss: 4.993372148295874
Validation loss: 4.312496231372311

Epoch: 5| Step: 4
Training loss: 4.599793487557221
Validation loss: 4.307481213434764

Epoch: 5| Step: 5
Training loss: 4.486334927345736
Validation loss: 4.303945358559391

Epoch: 5| Step: 6
Training loss: 4.532442975030068
Validation loss: 4.299383229002277

Epoch: 5| Step: 7
Training loss: 4.17372393266067
Validation loss: 4.294901335607721

Epoch: 5| Step: 8
Training loss: 4.849372209640823
Validation loss: 4.290275184575953

Epoch: 5| Step: 9
Training loss: 4.940534986801586
Validation loss: 4.285997603149504

Epoch: 5| Step: 10
Training loss: 4.241095695712997
Validation loss: 4.281812343188167

Epoch: 5| Step: 11
Training loss: 2.7570413262303917
Validation loss: 4.277208299974369

Epoch: 29| Step: 0
Training loss: 4.5700752392341135
Validation loss: 4.272914536003029

Epoch: 5| Step: 1
Training loss: 4.309548515162698
Validation loss: 4.268679092585347

Epoch: 5| Step: 2
Training loss: 4.147720188690635
Validation loss: 4.264764086395142

Epoch: 5| Step: 3
Training loss: 5.060613398407316
Validation loss: 4.260456983504545

Epoch: 5| Step: 4
Training loss: 4.512767058947349
Validation loss: 4.256329638109065

Epoch: 5| Step: 5
Training loss: 4.269963667489419
Validation loss: 4.2519796379686765

Epoch: 5| Step: 6
Training loss: 4.3599835589737586
Validation loss: 4.247587809696266

Epoch: 5| Step: 7
Training loss: 4.014669935595261
Validation loss: 4.243486218501354

Epoch: 5| Step: 8
Training loss: 4.08355982145844
Validation loss: 4.239216972224066

Epoch: 5| Step: 9
Training loss: 4.793249294585962
Validation loss: 4.234863628427169

Epoch: 5| Step: 10
Training loss: 3.8733491149642116
Validation loss: 4.230831563930556

Epoch: 5| Step: 11
Training loss: 4.740680989467282
Validation loss: 4.226546188200795

Epoch: 30| Step: 0
Training loss: 4.3566025972994025
Validation loss: 4.2221051379053955

Epoch: 5| Step: 1
Training loss: 4.083123545544954
Validation loss: 4.2179253090014965

Epoch: 5| Step: 2
Training loss: 4.883309935599422
Validation loss: 4.213643310540587

Epoch: 5| Step: 3
Training loss: 4.423539242775297
Validation loss: 4.209275865602858

Epoch: 5| Step: 4
Training loss: 4.058843052452075
Validation loss: 4.204938272884202

Epoch: 5| Step: 5
Training loss: 4.783776307722707
Validation loss: 4.200419461595269

Epoch: 5| Step: 6
Training loss: 4.693818576682587
Validation loss: 4.196222671860702

Epoch: 5| Step: 7
Training loss: 4.087439645677434
Validation loss: 4.191770994557794

Epoch: 5| Step: 8
Training loss: 4.234307658092854
Validation loss: 4.18746043419057

Epoch: 5| Step: 9
Training loss: 3.4238434446854926
Validation loss: 4.183058361626682

Epoch: 5| Step: 10
Training loss: 4.3619825433366906
Validation loss: 4.178870067105795

Epoch: 5| Step: 11
Training loss: 4.679220389615117
Validation loss: 4.174755430767535

Epoch: 31| Step: 0
Training loss: 4.778183096812536
Validation loss: 4.1702516566831385

Epoch: 5| Step: 1
Training loss: 3.927746879447711
Validation loss: 4.165641423293427

Epoch: 5| Step: 2
Training loss: 4.449655566655158
Validation loss: 4.161486961765987

Epoch: 5| Step: 3
Training loss: 4.820018097776255
Validation loss: 4.157337228169634

Epoch: 5| Step: 4
Training loss: 4.179138946187716
Validation loss: 4.152719762362148

Epoch: 5| Step: 5
Training loss: 3.8932730001408182
Validation loss: 4.148449099728638

Epoch: 5| Step: 6
Training loss: 4.702144482572324
Validation loss: 4.143970716456436

Epoch: 5| Step: 7
Training loss: 4.246002785867288
Validation loss: 4.139419029762346

Epoch: 5| Step: 8
Training loss: 3.530287754984798
Validation loss: 4.13497277991589

Epoch: 5| Step: 9
Training loss: 4.367785581740652
Validation loss: 4.130811739407178

Epoch: 5| Step: 10
Training loss: 3.795672190847241
Validation loss: 4.126423113432165

Epoch: 5| Step: 11
Training loss: 5.136773333241366
Validation loss: 4.122084536178066

Epoch: 32| Step: 0
Training loss: 3.1804139903036583
Validation loss: 4.117510117613161

Epoch: 5| Step: 1
Training loss: 4.630259641943057
Validation loss: 4.1135448143139515

Epoch: 5| Step: 2
Training loss: 4.640523479134697
Validation loss: 4.109152716558374

Epoch: 5| Step: 3
Training loss: 3.9936771487664227
Validation loss: 4.104842128776816

Epoch: 5| Step: 4
Training loss: 3.309277100236162
Validation loss: 4.100708718220741

Epoch: 5| Step: 5
Training loss: 4.650112536309395
Validation loss: 4.096445094330356

Epoch: 5| Step: 6
Training loss: 4.377847235484163
Validation loss: 4.092250874657236

Epoch: 5| Step: 7
Training loss: 4.089205017055123
Validation loss: 4.087866362505638

Epoch: 5| Step: 8
Training loss: 4.428651180516086
Validation loss: 4.0833832663123495

Epoch: 5| Step: 9
Training loss: 3.936697136300498
Validation loss: 4.078991229162055

Epoch: 5| Step: 10
Training loss: 4.787097820390992
Validation loss: 4.074546086397615

Epoch: 5| Step: 11
Training loss: 4.825729022516171
Validation loss: 4.070275495071747

Epoch: 33| Step: 0
Training loss: 4.161242476663065
Validation loss: 4.065761460074715

Epoch: 5| Step: 1
Training loss: 4.898504862101619
Validation loss: 4.0613816653804315

Epoch: 5| Step: 2
Training loss: 3.165196947716599
Validation loss: 4.056662777243457

Epoch: 5| Step: 3
Training loss: 3.482468155977519
Validation loss: 4.052126144666807

Epoch: 5| Step: 4
Training loss: 4.7192039018810465
Validation loss: 4.0479449130630485

Epoch: 5| Step: 5
Training loss: 4.407442188630291
Validation loss: 4.04358220506465

Epoch: 5| Step: 6
Training loss: 4.112912356217521
Validation loss: 4.039060566826068

Epoch: 5| Step: 7
Training loss: 4.359768319930176
Validation loss: 4.034472579623027

Epoch: 5| Step: 8
Training loss: 3.6683368924678423
Validation loss: 4.030149994828308

Epoch: 5| Step: 9
Training loss: 4.373394480797264
Validation loss: 4.025843239944915

Epoch: 5| Step: 10
Training loss: 4.266927555174613
Validation loss: 4.021413764500455

Epoch: 5| Step: 11
Training loss: 4.156038895602135
Validation loss: 4.016942502017444

Epoch: 34| Step: 0
Training loss: 3.9711318190403015
Validation loss: 4.012395433348819

Epoch: 5| Step: 1
Training loss: 4.787467952451688
Validation loss: 4.008025071404202

Epoch: 5| Step: 2
Training loss: 4.002252659681634
Validation loss: 4.003445681002137

Epoch: 5| Step: 3
Training loss: 3.762541335376269
Validation loss: 3.998911232591013

Epoch: 5| Step: 4
Training loss: 4.329974388769229
Validation loss: 3.9943539339418406

Epoch: 5| Step: 5
Training loss: 3.8802529693016052
Validation loss: 3.989890650308039

Epoch: 5| Step: 6
Training loss: 3.2595663861183586
Validation loss: 3.9855890007800014

Epoch: 5| Step: 7
Training loss: 3.853088695543815
Validation loss: 3.9811766060252762

Epoch: 5| Step: 8
Training loss: 4.26080094200121
Validation loss: 3.976808991252829

Epoch: 5| Step: 9
Training loss: 4.0786459871357925
Validation loss: 3.9725438004854405

Epoch: 5| Step: 10
Training loss: 4.528917435728812
Validation loss: 3.9681722966448394

Epoch: 5| Step: 11
Training loss: 5.915029953068972
Validation loss: 3.963624828868074

Epoch: 35| Step: 0
Training loss: 3.880394902533681
Validation loss: 3.9590768199503796

Epoch: 5| Step: 1
Training loss: 4.32153126528163
Validation loss: 3.9544617826488344

Epoch: 5| Step: 2
Training loss: 4.363157101523864
Validation loss: 3.9498207395655887

Epoch: 5| Step: 3
Training loss: 4.037350555583078
Validation loss: 3.94484135297871

Epoch: 5| Step: 4
Training loss: 4.3073615822274345
Validation loss: 3.940316217451843

Epoch: 5| Step: 5
Training loss: 4.457481421722361
Validation loss: 3.9355760798857577

Epoch: 5| Step: 6
Training loss: 4.030275922090039
Validation loss: 3.9308175799795664

Epoch: 5| Step: 7
Training loss: 3.639438026350228
Validation loss: 3.926192486987568

Epoch: 5| Step: 8
Training loss: 3.4963992534116883
Validation loss: 3.921259311206526

Epoch: 5| Step: 9
Training loss: 4.018444926546281
Validation loss: 3.9169021833235473

Epoch: 5| Step: 10
Training loss: 4.083241026996312
Validation loss: 3.912331574646777

Epoch: 5| Step: 11
Training loss: 4.202664147960405
Validation loss: 3.907931594020226

Epoch: 36| Step: 0
Training loss: 3.3198816356471252
Validation loss: 3.9032073874288145

Epoch: 5| Step: 1
Training loss: 4.83345108327266
Validation loss: 3.898894579433503

Epoch: 5| Step: 2
Training loss: 3.9146242024208657
Validation loss: 3.894147134023461

Epoch: 5| Step: 3
Training loss: 3.538315043558607
Validation loss: 3.8893223462286897

Epoch: 5| Step: 4
Training loss: 4.3844913524325335
Validation loss: 3.8846657294075904

Epoch: 5| Step: 5
Training loss: 3.9277894913928737
Validation loss: 3.880045968910781

Epoch: 5| Step: 6
Training loss: 4.452549733264893
Validation loss: 3.8753095164817

Epoch: 5| Step: 7
Training loss: 3.3106491388150623
Validation loss: 3.87050526415742

Epoch: 5| Step: 8
Training loss: 3.2450717827567606
Validation loss: 3.865639481431279

Epoch: 5| Step: 9
Training loss: 4.449107717145064
Validation loss: 3.8610055699015575

Epoch: 5| Step: 10
Training loss: 4.225645180823145
Validation loss: 3.8566311440251

Epoch: 5| Step: 11
Training loss: 4.83251595436774
Validation loss: 3.852023037193907

Epoch: 37| Step: 0
Training loss: 3.4114115393926125
Validation loss: 3.847549540271211

Epoch: 5| Step: 1
Training loss: 4.037091185478496
Validation loss: 3.8428996833250344

Epoch: 5| Step: 2
Training loss: 4.082227025060079
Validation loss: 3.838212694885792

Epoch: 5| Step: 3
Training loss: 4.144560703241245
Validation loss: 3.833791309793749

Epoch: 5| Step: 4
Training loss: 4.4552656416038605
Validation loss: 3.8294363409780257

Epoch: 5| Step: 5
Training loss: 4.689166573853891
Validation loss: 3.8242264806963484

Epoch: 5| Step: 6
Training loss: 3.6314005415105757
Validation loss: 3.8194622713694066

Epoch: 5| Step: 7
Training loss: 3.9028464175908533
Validation loss: 3.814794907604532

Epoch: 5| Step: 8
Training loss: 3.904552121236961
Validation loss: 3.8100084543259505

Epoch: 5| Step: 9
Training loss: 3.6510730838194836
Validation loss: 3.805114878751202

Epoch: 5| Step: 10
Training loss: 3.6761056754828054
Validation loss: 3.800609693219857

Epoch: 5| Step: 11
Training loss: 2.74656106762833
Validation loss: 3.7958924339514555

Epoch: 38| Step: 0
Training loss: 4.225618775330286
Validation loss: 3.791557497332341

Epoch: 5| Step: 1
Training loss: 4.1113814760493295
Validation loss: 3.7870462880250013

Epoch: 5| Step: 2
Training loss: 2.701438245237983
Validation loss: 3.7825350561322284

Epoch: 5| Step: 3
Training loss: 3.505863727364986
Validation loss: 3.7783892084529875

Epoch: 5| Step: 4
Training loss: 4.535997311115309
Validation loss: 3.773376822395115

Epoch: 5| Step: 5
Training loss: 4.206752417204774
Validation loss: 3.7693666306886993

Epoch: 5| Step: 6
Training loss: 4.1927775817586195
Validation loss: 3.765351719522861

Epoch: 5| Step: 7
Training loss: 4.320322654118944
Validation loss: 3.7604148720325754

Epoch: 5| Step: 8
Training loss: 3.1601656051893356
Validation loss: 3.755770466175868

Epoch: 5| Step: 9
Training loss: 4.02700913793921
Validation loss: 3.7509273283161404

Epoch: 5| Step: 10
Training loss: 3.735167606785705
Validation loss: 3.746530832853693

Epoch: 5| Step: 11
Training loss: 2.964364114798069
Validation loss: 3.7419671861201045

Epoch: 39| Step: 0
Training loss: 4.290733803899717
Validation loss: 3.7378929518489987

Epoch: 5| Step: 1
Training loss: 3.889012749531123
Validation loss: 3.733358577376122

Epoch: 5| Step: 2
Training loss: 3.4590673625173327
Validation loss: 3.7287497189681855

Epoch: 5| Step: 3
Training loss: 4.27273046024875
Validation loss: 3.7247147847758977

Epoch: 5| Step: 4
Training loss: 3.5761524076989253
Validation loss: 3.7200071202828684

Epoch: 5| Step: 5
Training loss: 3.670493397613104
Validation loss: 3.7158781283572218

Epoch: 5| Step: 6
Training loss: 3.3635792528220065
Validation loss: 3.7110886874270186

Epoch: 5| Step: 7
Training loss: 4.607441952650722
Validation loss: 3.7069261306206127

Epoch: 5| Step: 8
Training loss: 3.0409723473558277
Validation loss: 3.7022766450648734

Epoch: 5| Step: 9
Training loss: 4.293077156843256
Validation loss: 3.6982125750426316

Epoch: 5| Step: 10
Training loss: 3.5995979826359332
Validation loss: 3.693526709531656

Epoch: 5| Step: 11
Training loss: 3.880050198535047
Validation loss: 3.689145771591013

Epoch: 40| Step: 0
Training loss: 4.0880921847705
Validation loss: 3.6843647262952004

Epoch: 5| Step: 1
Training loss: 3.636893918646553
Validation loss: 3.680043936904242

Epoch: 5| Step: 2
Training loss: 3.37234604650247
Validation loss: 3.675134075513032

Epoch: 5| Step: 3
Training loss: 4.472871173875449
Validation loss: 3.6707795693786314

Epoch: 5| Step: 4
Training loss: 3.5710596684256823
Validation loss: 3.6663109686302007

Epoch: 5| Step: 5
Training loss: 3.9933110576468995
Validation loss: 3.661630187833197

Epoch: 5| Step: 6
Training loss: 3.440241466076134
Validation loss: 3.6569287846496334

Epoch: 5| Step: 7
Training loss: 3.6344599444105055
Validation loss: 3.652494512428097

Epoch: 5| Step: 8
Training loss: 3.515401061661189
Validation loss: 3.6482500930782984

Epoch: 5| Step: 9
Training loss: 3.6942488125382718
Validation loss: 3.643788612645333

Epoch: 5| Step: 10
Training loss: 4.009164325652902
Validation loss: 3.639535754627398

Epoch: 5| Step: 11
Training loss: 4.737462412501368
Validation loss: 3.6350350147731465

Epoch: 41| Step: 0
Training loss: 3.235271974477622
Validation loss: 3.630169700880379

Epoch: 5| Step: 1
Training loss: 4.3532952466372565
Validation loss: 3.6259528146560793

Epoch: 5| Step: 2
Training loss: 3.8994775275404483
Validation loss: 3.6211945356151447

Epoch: 5| Step: 3
Training loss: 4.364413723195453
Validation loss: 3.6163409995461535

Epoch: 5| Step: 4
Training loss: 4.196300084892145
Validation loss: 3.6115910716493276

Epoch: 5| Step: 5
Training loss: 4.104467209915375
Validation loss: 3.606722439144029

Epoch: 5| Step: 6
Training loss: 3.499741680966767
Validation loss: 3.6018452233416327

Epoch: 5| Step: 7
Training loss: 3.4019991046471514
Validation loss: 3.5970602187241014

Epoch: 5| Step: 8
Training loss: 3.474740431717175
Validation loss: 3.592408092794692

Epoch: 5| Step: 9
Training loss: 3.6050187942924996
Validation loss: 3.5876616278734708

Epoch: 5| Step: 10
Training loss: 2.9537278624684538
Validation loss: 3.583300943376103

Epoch: 5| Step: 11
Training loss: 2.678910657201008
Validation loss: 3.5790966052983375

Epoch: 42| Step: 0
Training loss: 3.585707447260424
Validation loss: 3.574963484757679

Epoch: 5| Step: 1
Training loss: 3.982993810274878
Validation loss: 3.5707293488990723

Epoch: 5| Step: 2
Training loss: 3.3209169084537487
Validation loss: 3.566697425278868

Epoch: 5| Step: 3
Training loss: 4.187656228866227
Validation loss: 3.5623007127445567

Epoch: 5| Step: 4
Training loss: 3.2557266839900314
Validation loss: 3.557878949384279

Epoch: 5| Step: 5
Training loss: 4.613363318557166
Validation loss: 3.5537578610764777

Epoch: 5| Step: 6
Training loss: 3.390872366183599
Validation loss: 3.549341962722935

Epoch: 5| Step: 7
Training loss: 4.170084708471769
Validation loss: 3.545049757879517

Epoch: 5| Step: 8
Training loss: 3.1885658426914616
Validation loss: 3.5406559324694977

Epoch: 5| Step: 9
Training loss: 2.8292628575762877
Validation loss: 3.5364931897939584

Epoch: 5| Step: 10
Training loss: 3.559917785681027
Validation loss: 3.5322902632567756

Epoch: 5| Step: 11
Training loss: 4.327382378613245
Validation loss: 3.527945139478591

Epoch: 43| Step: 0
Training loss: 3.4877675052991286
Validation loss: 3.523553185209648

Epoch: 5| Step: 1
Training loss: 3.3880450721634063
Validation loss: 3.5194681820315235

Epoch: 5| Step: 2
Training loss: 4.070685019991404
Validation loss: 3.515047786092993

Epoch: 5| Step: 3
Training loss: 3.9673396931347655
Validation loss: 3.510516483159341

Epoch: 5| Step: 4
Training loss: 3.285606761618345
Validation loss: 3.5062495135863996

Epoch: 5| Step: 5
Training loss: 3.822101072922235
Validation loss: 3.5019398433889446

Epoch: 5| Step: 6
Training loss: 3.6823288170623454
Validation loss: 3.4975314688022383

Epoch: 5| Step: 7
Training loss: 3.6736029272503106
Validation loss: 3.4931721788979857

Epoch: 5| Step: 8
Training loss: 2.9331034772576268
Validation loss: 3.4889584888125578

Epoch: 5| Step: 9
Training loss: 3.8693061342613255
Validation loss: 3.484483127028204

Epoch: 5| Step: 10
Training loss: 3.9465147698228846
Validation loss: 3.4802560680639667

Epoch: 5| Step: 11
Training loss: 2.1019180167313993
Validation loss: 3.475904783976162

Epoch: 44| Step: 0
Training loss: 3.324129527023091
Validation loss: 3.4719580573153968

Epoch: 5| Step: 1
Training loss: 4.246739202465789
Validation loss: 3.4682796033308354

Epoch: 5| Step: 2
Training loss: 3.67850587180632
Validation loss: 3.464169866434846

Epoch: 5| Step: 3
Training loss: 3.9327033966292673
Validation loss: 3.460015207773572

Epoch: 5| Step: 4
Training loss: 2.821731506281645
Validation loss: 3.456033411074587

Epoch: 5| Step: 5
Training loss: 3.469371018363635
Validation loss: 3.4520708088867282

Epoch: 5| Step: 6
Training loss: 3.7284452852355385
Validation loss: 3.4478877182558723

Epoch: 5| Step: 7
Training loss: 3.521846166592541
Validation loss: 3.4439971500518594

Epoch: 5| Step: 8
Training loss: 3.2075263325419785
Validation loss: 3.439817497019813

Epoch: 5| Step: 9
Training loss: 3.88913866936351
Validation loss: 3.4360533820377195

Epoch: 5| Step: 10
Training loss: 3.645375439181859
Validation loss: 3.4319431820725654

Epoch: 5| Step: 11
Training loss: 2.6480105795865034
Validation loss: 3.428110088685721

Epoch: 45| Step: 0
Training loss: 3.6103761283651656
Validation loss: 3.4239727076054747

Epoch: 5| Step: 1
Training loss: 3.655355360339644
Validation loss: 3.420029466215802

Epoch: 5| Step: 2
Training loss: 4.2759464577015995
Validation loss: 3.4161597065741556

Epoch: 5| Step: 3
Training loss: 3.5933260460274243
Validation loss: 3.4118152266711976

Epoch: 5| Step: 4
Training loss: 3.0250069736368803
Validation loss: 3.407816045690176

Epoch: 5| Step: 5
Training loss: 2.7428664537964322
Validation loss: 3.403756415923431

Epoch: 5| Step: 6
Training loss: 3.394000364169819
Validation loss: 3.3998288693556673

Epoch: 5| Step: 7
Training loss: 4.04891503954288
Validation loss: 3.395887694284514

Epoch: 5| Step: 8
Training loss: 3.4523469212300157
Validation loss: 3.3920213428757786

Epoch: 5| Step: 9
Training loss: 3.451405921517057
Validation loss: 3.38790042241977

Epoch: 5| Step: 10
Training loss: 3.325436361261158
Validation loss: 3.383842528757041

Epoch: 5| Step: 11
Training loss: 4.233606923391343
Validation loss: 3.379785194813247

Epoch: 46| Step: 0
Training loss: 3.7925390281001836
Validation loss: 3.37567327695002

Epoch: 5| Step: 1
Training loss: 3.3603619212551035
Validation loss: 3.37157226678943

Epoch: 5| Step: 2
Training loss: 3.691000360042913
Validation loss: 3.3672398137559645

Epoch: 5| Step: 3
Training loss: 2.9551899467132032
Validation loss: 3.362901483790671

Epoch: 5| Step: 4
Training loss: 3.373027507679995
Validation loss: 3.358840811197082

Epoch: 5| Step: 5
Training loss: 3.8942344498866004
Validation loss: 3.3548278433362073

Epoch: 5| Step: 6
Training loss: 3.7724716814417936
Validation loss: 3.3507397344995002

Epoch: 5| Step: 7
Training loss: 3.210865029215623
Validation loss: 3.346411088788377

Epoch: 5| Step: 8
Training loss: 3.334080628233079
Validation loss: 3.3423542484621875

Epoch: 5| Step: 9
Training loss: 3.0071816315366235
Validation loss: 3.3382204211682103

Epoch: 5| Step: 10
Training loss: 4.046600214639339
Validation loss: 3.334354778587186

Epoch: 5| Step: 11
Training loss: 2.429088555503841
Validation loss: 3.3304037313418102

Epoch: 47| Step: 0
Training loss: 3.7269215280896493
Validation loss: 3.326358439749234

Epoch: 5| Step: 1
Training loss: 3.7315566149407156
Validation loss: 3.3223375316016823

Epoch: 5| Step: 2
Training loss: 3.4291660894406566
Validation loss: 3.318240415982863

Epoch: 5| Step: 3
Training loss: 3.3523173160261996
Validation loss: 3.3143547341723876

Epoch: 5| Step: 4
Training loss: 3.7007213147177866
Validation loss: 3.310469046759079

Epoch: 5| Step: 5
Training loss: 3.443001800510048
Validation loss: 3.3064992280708543

Epoch: 5| Step: 6
Training loss: 3.7792855196050334
Validation loss: 3.302470197588863

Epoch: 5| Step: 7
Training loss: 2.6538453830390414
Validation loss: 3.2983779615133355

Epoch: 5| Step: 8
Training loss: 3.187768064708441
Validation loss: 3.294459912247895

Epoch: 5| Step: 9
Training loss: 3.397500095213046
Validation loss: 3.290715440290387

Epoch: 5| Step: 10
Training loss: 3.4262877278023463
Validation loss: 3.2870015220907427

Epoch: 5| Step: 11
Training loss: 3.1857137724040836
Validation loss: 3.2832842016336174

Epoch: 48| Step: 0
Training loss: 3.6114286054926796
Validation loss: 3.279493436967793

Epoch: 5| Step: 1
Training loss: 4.1465020846448235
Validation loss: 3.2755829025423417

Epoch: 5| Step: 2
Training loss: 2.9339614007929233
Validation loss: 3.2716219836089127

Epoch: 5| Step: 3
Training loss: 3.0162221682956423
Validation loss: 3.267710070274669

Epoch: 5| Step: 4
Training loss: 3.5817604752994012
Validation loss: 3.2640640628872433

Epoch: 5| Step: 5
Training loss: 3.776237759814965
Validation loss: 3.260341507326722

Epoch: 5| Step: 6
Training loss: 2.874395887510913
Validation loss: 3.256506184551423

Epoch: 5| Step: 7
Training loss: 3.569760870524732
Validation loss: 3.2528852682861045

Epoch: 5| Step: 8
Training loss: 3.2132975497436393
Validation loss: 3.248945373814257

Epoch: 5| Step: 9
Training loss: 3.2756081169405173
Validation loss: 3.2452539703473766

Epoch: 5| Step: 10
Training loss: 3.3987231605875836
Validation loss: 3.241544109682011

Epoch: 5| Step: 11
Training loss: 2.199977926663724
Validation loss: 3.2379170862227955

Epoch: 49| Step: 0
Training loss: 3.0411727364882086
Validation loss: 3.234287875072414

Epoch: 5| Step: 1
Training loss: 3.410523979224631
Validation loss: 3.230619978219098

Epoch: 5| Step: 2
Training loss: 2.85866567016105
Validation loss: 3.227178076151023

Epoch: 5| Step: 3
Training loss: 3.6873589181581985
Validation loss: 3.22360390649513

Epoch: 5| Step: 4
Training loss: 3.5657759210740547
Validation loss: 3.2200490064820944

Epoch: 5| Step: 5
Training loss: 3.5614669372746244
Validation loss: 3.216366944324989

Epoch: 5| Step: 6
Training loss: 3.6533757837525513
Validation loss: 3.2128326812744534

Epoch: 5| Step: 7
Training loss: 3.1560448306033804
Validation loss: 3.208907584821184

Epoch: 5| Step: 8
Training loss: 3.340504292090653
Validation loss: 3.2048932443901896

Epoch: 5| Step: 9
Training loss: 3.377560809623578
Validation loss: 3.20118507629242

Epoch: 5| Step: 10
Training loss: 3.021412252441984
Validation loss: 3.197551039546128

Epoch: 5| Step: 11
Training loss: 4.0317500787511324
Validation loss: 3.1939547886794672

Epoch: 50| Step: 0
Training loss: 3.5126541809779113
Validation loss: 3.190320686725659

Epoch: 5| Step: 1
Training loss: 3.4637983566427417
Validation loss: 3.1866312557228835

Epoch: 5| Step: 2
Training loss: 3.1599344333655
Validation loss: 3.1831104590418824

Epoch: 5| Step: 3
Training loss: 3.1590679921328784
Validation loss: 3.179501877224028

Epoch: 5| Step: 4
Training loss: 3.92804733842966
Validation loss: 3.1758633923982775

Epoch: 5| Step: 5
Training loss: 3.2757606729506654
Validation loss: 3.172041207454764

Epoch: 5| Step: 6
Training loss: 2.960971962921966
Validation loss: 3.1684066745728288

Epoch: 5| Step: 7
Training loss: 3.295889901609317
Validation loss: 3.164809922842905

Epoch: 5| Step: 8
Training loss: 2.8091530276178376
Validation loss: 3.1613871625570003

Epoch: 5| Step: 9
Training loss: 3.2264860943113747
Validation loss: 3.157988217570813

Epoch: 5| Step: 10
Training loss: 3.7699221077317047
Validation loss: 3.154546029060056

Epoch: 5| Step: 11
Training loss: 1.5104516211663428
Validation loss: 3.151174685400233

Epoch: 51| Step: 0
Training loss: 3.0744737376383187
Validation loss: 3.147731061235599

Epoch: 5| Step: 1
Training loss: 3.101122615954908
Validation loss: 3.1445335530337792

Epoch: 5| Step: 2
Training loss: 3.3645925767769618
Validation loss: 3.141290913548291

Epoch: 5| Step: 3
Training loss: 3.2547509607070007
Validation loss: 3.1378268497178055

Epoch: 5| Step: 4
Training loss: 2.600365257282707
Validation loss: 3.1346720046723107

Epoch: 5| Step: 5
Training loss: 2.937257147956688
Validation loss: 3.1313879400188482

Epoch: 5| Step: 6
Training loss: 3.488870363800477
Validation loss: 3.1283279532218793

Epoch: 5| Step: 7
Training loss: 2.991513806389802
Validation loss: 3.1251850105196746

Epoch: 5| Step: 8
Training loss: 2.844478471953125
Validation loss: 3.122270504703349

Epoch: 5| Step: 9
Training loss: 4.027318412338457
Validation loss: 3.1191662695970486

Epoch: 5| Step: 10
Training loss: 3.7519261817421445
Validation loss: 3.1158962459458386

Epoch: 5| Step: 11
Training loss: 4.50104002060522
Validation loss: 3.112500030895473

Epoch: 52| Step: 0
Training loss: 3.243398123234831
Validation loss: 3.1088468272375556

Epoch: 5| Step: 1
Training loss: 3.9538127316018836
Validation loss: 3.1051466384913233

Epoch: 5| Step: 2
Training loss: 2.597654781484547
Validation loss: 3.101538016657439

Epoch: 5| Step: 3
Training loss: 3.184452170502911
Validation loss: 3.097821706271184

Epoch: 5| Step: 4
Training loss: 3.104598934789877
Validation loss: 3.094159706036661

Epoch: 5| Step: 5
Training loss: 3.6307832033766316
Validation loss: 3.0908014169349434

Epoch: 5| Step: 6
Training loss: 3.100947167687962
Validation loss: 3.087209997701714

Epoch: 5| Step: 7
Training loss: 2.876341465337474
Validation loss: 3.083719443082339

Epoch: 5| Step: 8
Training loss: 3.4587711072470033
Validation loss: 3.0804366453611545

Epoch: 5| Step: 9
Training loss: 3.1627379859368667
Validation loss: 3.0771924105203734

Epoch: 5| Step: 10
Training loss: 3.2335484134936383
Validation loss: 3.073782502517442

Epoch: 5| Step: 11
Training loss: 2.190902352835339
Validation loss: 3.0705222591224244

Epoch: 53| Step: 0
Training loss: 3.4088133519786514
Validation loss: 3.067319535561498

Epoch: 5| Step: 1
Training loss: 3.045858829946472
Validation loss: 3.0640320416664215

Epoch: 5| Step: 2
Training loss: 3.35574130104891
Validation loss: 3.0611321969430123

Epoch: 5| Step: 3
Training loss: 2.828269996930475
Validation loss: 3.05779350078634

Epoch: 5| Step: 4
Training loss: 3.6658670825160593
Validation loss: 3.0549721028333576

Epoch: 5| Step: 5
Training loss: 2.8853037751259154
Validation loss: 3.052012307096826

Epoch: 5| Step: 6
Training loss: 3.097184557797387
Validation loss: 3.0489134156481064

Epoch: 5| Step: 7
Training loss: 3.395610185714078
Validation loss: 3.0456819529733403

Epoch: 5| Step: 8
Training loss: 3.135079417462401
Validation loss: 3.042513681515243

Epoch: 5| Step: 9
Training loss: 3.3879897604633333
Validation loss: 3.039745273725398

Epoch: 5| Step: 10
Training loss: 3.0437819210940047
Validation loss: 3.0363994328766117

Epoch: 5| Step: 11
Training loss: 1.801392358452874
Validation loss: 3.0332728318758653

Epoch: 54| Step: 0
Training loss: 2.976931571607122
Validation loss: 3.0303311413667613

Epoch: 5| Step: 1
Training loss: 3.235620231308056
Validation loss: 3.0275287136876115

Epoch: 5| Step: 2
Training loss: 2.9940248430912133
Validation loss: 3.0247266519800773

Epoch: 5| Step: 3
Training loss: 3.338545840414992
Validation loss: 3.021947176339917

Epoch: 5| Step: 4
Training loss: 3.2573312088278508
Validation loss: 3.0190755311872723

Epoch: 5| Step: 5
Training loss: 3.059723042688901
Validation loss: 3.016201787680014

Epoch: 5| Step: 6
Training loss: 3.292240302083832
Validation loss: 3.013519190943889

Epoch: 5| Step: 7
Training loss: 3.2245475629107463
Validation loss: 3.010520940952469

Epoch: 5| Step: 8
Training loss: 2.6036665372616095
Validation loss: 3.0075913517227906

Epoch: 5| Step: 9
Training loss: 3.444874707560996
Validation loss: 3.004800637730851

Epoch: 5| Step: 10
Training loss: 3.394879322182545
Validation loss: 3.0018731799263447

Epoch: 5| Step: 11
Training loss: 2.18940630002616
Validation loss: 2.9989121305760866

Epoch: 55| Step: 0
Training loss: 3.255302505148241
Validation loss: 2.996290297446131

Epoch: 5| Step: 1
Training loss: 3.0414620073696383
Validation loss: 2.993478196188679

Epoch: 5| Step: 2
Training loss: 3.311942719420309
Validation loss: 2.9906509677313635

Epoch: 5| Step: 3
Training loss: 3.069718087389681
Validation loss: 2.9880554645817248

Epoch: 5| Step: 4
Training loss: 3.423124181145916
Validation loss: 2.985313307966588

Epoch: 5| Step: 5
Training loss: 3.122936635698973
Validation loss: 2.9825744789717366

Epoch: 5| Step: 6
Training loss: 2.9865224412029927
Validation loss: 2.9799086284817244

Epoch: 5| Step: 7
Training loss: 3.424397135671891
Validation loss: 2.9771171513623873

Epoch: 5| Step: 8
Training loss: 2.7541454454798093
Validation loss: 2.9742391869006752

Epoch: 5| Step: 9
Training loss: 3.2163491785834166
Validation loss: 2.97151484989703

Epoch: 5| Step: 10
Training loss: 2.8084135249731648
Validation loss: 2.96890627801045

Epoch: 5| Step: 11
Training loss: 2.4962851580807235
Validation loss: 2.966137713833425

Epoch: 56| Step: 0
Training loss: 3.41701618980924
Validation loss: 2.9633318564769238

Epoch: 5| Step: 1
Training loss: 3.3220939614306846
Validation loss: 2.960601693656829

Epoch: 5| Step: 2
Training loss: 3.020962276118401
Validation loss: 2.957791105241036

Epoch: 5| Step: 3
Training loss: 2.6980124398885668
Validation loss: 2.955113668116663

Epoch: 5| Step: 4
Training loss: 2.666553127335381
Validation loss: 2.9526020878835912

Epoch: 5| Step: 5
Training loss: 2.812980610791161
Validation loss: 2.950022007434459

Epoch: 5| Step: 6
Training loss: 3.5404060962745625
Validation loss: 2.9475761268551857

Epoch: 5| Step: 7
Training loss: 2.647439594246087
Validation loss: 2.945053652478114

Epoch: 5| Step: 8
Training loss: 3.6061077440258824
Validation loss: 2.9424415782551057

Epoch: 5| Step: 9
Training loss: 3.066104402689334
Validation loss: 2.9397150541857737

Epoch: 5| Step: 10
Training loss: 3.0675883159033415
Validation loss: 2.9370896309792163

Epoch: 5| Step: 11
Training loss: 2.8573444431579653
Validation loss: 2.9345036673105582

Epoch: 57| Step: 0
Training loss: 3.279693670389696
Validation loss: 2.93180176463402

Epoch: 5| Step: 1
Training loss: 2.7891247312297494
Validation loss: 2.9289995292760005

Epoch: 5| Step: 2
Training loss: 3.476532599502739
Validation loss: 2.9260777695410023

Epoch: 5| Step: 3
Training loss: 3.3638463271122774
Validation loss: 2.923377206772909

Epoch: 5| Step: 4
Training loss: 2.605164746074039
Validation loss: 2.920598973727589

Epoch: 5| Step: 5
Training loss: 2.651533449696077
Validation loss: 2.9180100321881595

Epoch: 5| Step: 6
Training loss: 3.2927437158984705
Validation loss: 2.9156030532103587

Epoch: 5| Step: 7
Training loss: 2.5897733238621554
Validation loss: 2.912772253515788

Epoch: 5| Step: 8
Training loss: 3.1669903807233513
Validation loss: 2.9103280104229943

Epoch: 5| Step: 9
Training loss: 2.7882579850594094
Validation loss: 2.907941428579809

Epoch: 5| Step: 10
Training loss: 3.456570524560401
Validation loss: 2.9053765526004653

Epoch: 5| Step: 11
Training loss: 3.141944266550393
Validation loss: 2.902930544803656

Epoch: 58| Step: 0
Training loss: 2.9995523754595452
Validation loss: 2.9002946762843242

Epoch: 5| Step: 1
Training loss: 2.6342284246645256
Validation loss: 2.8977926398903913

Epoch: 5| Step: 2
Training loss: 3.265591123852402
Validation loss: 2.8952061136253735

Epoch: 5| Step: 3
Training loss: 3.0394028029365465
Validation loss: 2.8925302498526198

Epoch: 5| Step: 4
Training loss: 3.2252074714578836
Validation loss: 2.89011375442613

Epoch: 5| Step: 5
Training loss: 2.8499738056250665
Validation loss: 2.8877831898161497

Epoch: 5| Step: 6
Training loss: 2.9327389707376614
Validation loss: 2.8856407186415924

Epoch: 5| Step: 7
Training loss: 2.9116411964890667
Validation loss: 2.8832284132844164

Epoch: 5| Step: 8
Training loss: 2.9428217953213807
Validation loss: 2.8809476780693526

Epoch: 5| Step: 9
Training loss: 3.6217409150233535
Validation loss: 2.878780032686024

Epoch: 5| Step: 10
Training loss: 2.9869111953269605
Validation loss: 2.8763741305324815

Epoch: 5| Step: 11
Training loss: 1.9136284783748048
Validation loss: 2.8741139553107105

Epoch: 59| Step: 0
Training loss: 3.2383102581349266
Validation loss: 2.871559866439293

Epoch: 5| Step: 1
Training loss: 2.9359974366262613
Validation loss: 2.869318424027985

Epoch: 5| Step: 2
Training loss: 2.8221432986033084
Validation loss: 2.866916480841609

Epoch: 5| Step: 3
Training loss: 2.902063451198177
Validation loss: 2.8646303253943297

Epoch: 5| Step: 4
Training loss: 3.1529129062847105
Validation loss: 2.862322974387921

Epoch: 5| Step: 5
Training loss: 3.192768156519001
Validation loss: 2.8600363253240606

Epoch: 5| Step: 6
Training loss: 3.4650686163115254
Validation loss: 2.8576870332640523

Epoch: 5| Step: 7
Training loss: 3.016733232750786
Validation loss: 2.855331038369313

Epoch: 5| Step: 8
Training loss: 2.8903219528117905
Validation loss: 2.8523866168029293

Epoch: 5| Step: 9
Training loss: 2.653220659560122
Validation loss: 2.8500654044370703

Epoch: 5| Step: 10
Training loss: 2.6896122460814387
Validation loss: 2.847292377543196

Epoch: 5| Step: 11
Training loss: 2.89433141680091
Validation loss: 2.873924862891527

Epoch: 60| Step: 0
Training loss: 3.1769595429531416
Validation loss: 2.8437486585676783

Epoch: 5| Step: 1
Training loss: 3.3310725810773434
Validation loss: 2.8425363214398303

Epoch: 5| Step: 2
Training loss: 3.0656813621200576
Validation loss: 2.8489141699083667

Epoch: 5| Step: 3
Training loss: 3.3222825612259377
Validation loss: 2.8428336263470357

Epoch: 5| Step: 4
Training loss: 2.4806669381331257
Validation loss: 2.8365233755808847

Epoch: 5| Step: 5
Training loss: 3.104832230118893
Validation loss: 2.833930577881132

Epoch: 5| Step: 6
Training loss: 2.8833923583705308
Validation loss: 2.833233787152959

Epoch: 5| Step: 7
Training loss: 2.754982076680059
Validation loss: 2.8310044770943685

Epoch: 5| Step: 8
Training loss: 3.1476556076840683
Validation loss: 2.8332491761686627

Epoch: 5| Step: 9
Training loss: 2.450402176214205
Validation loss: 2.8334142110070903

Epoch: 5| Step: 10
Training loss: 3.2095613152524045
Validation loss: 2.8367131716344964

Epoch: 5| Step: 11
Training loss: 0.970692686335661
Validation loss: 2.8344111823338447

Epoch: 61| Step: 0
Training loss: 2.744918115780744
Validation loss: 2.848473583780374

Epoch: 5| Step: 1
Training loss: 3.2640810880592825
Validation loss: 2.845532250057768

Epoch: 5| Step: 2
Training loss: 3.2684455627697933
Validation loss: 2.820142524225511

Epoch: 5| Step: 3
Training loss: 2.5550367017524906
Validation loss: 2.815373845670756

Epoch: 5| Step: 4
Training loss: 3.223246868226999
Validation loss: 2.8167714602164504

Epoch: 5| Step: 5
Training loss: 3.2661275522584954
Validation loss: 2.813853358563989

Epoch: 5| Step: 6
Training loss: 2.920761957171694
Validation loss: 2.812549336318578

Epoch: 5| Step: 7
Training loss: 2.906438185639068
Validation loss: 2.8078594140867548

Epoch: 5| Step: 8
Training loss: 2.781074004016112
Validation loss: 2.8054857171895664

Epoch: 5| Step: 9
Training loss: 2.5812479236215733
Validation loss: 2.8056483238974663

Epoch: 5| Step: 10
Training loss: 2.9026424208075112
Validation loss: 2.8031113516150308

Epoch: 5| Step: 11
Training loss: 2.9108040517460347
Validation loss: 2.8010839585109206

Epoch: 62| Step: 0
Training loss: 3.227564030491549
Validation loss: 2.7996271931155

Epoch: 5| Step: 1
Training loss: 3.1197918025267777
Validation loss: 2.7958157769536465

Epoch: 5| Step: 2
Training loss: 2.9515198881709326
Validation loss: 2.7956987141539797

Epoch: 5| Step: 3
Training loss: 2.652850410261546
Validation loss: 2.793833199129096

Epoch: 5| Step: 4
Training loss: 3.176972901139573
Validation loss: 2.793763111319843

Epoch: 5| Step: 5
Training loss: 3.144674243400568
Validation loss: 2.791208141780086

Epoch: 5| Step: 6
Training loss: 3.263748140659628
Validation loss: 2.787450835873524

Epoch: 5| Step: 7
Training loss: 2.5916047934192123
Validation loss: 2.7854512411999433

Epoch: 5| Step: 8
Training loss: 2.6290049201394026
Validation loss: 2.7823350340047104

Epoch: 5| Step: 9
Training loss: 2.5834274787565423
Validation loss: 2.780312833874244

Epoch: 5| Step: 10
Training loss: 2.7075062784983364
Validation loss: 2.7789253778293554

Epoch: 5| Step: 11
Training loss: 3.1974377268318728
Validation loss: 2.7765810778212265

Epoch: 63| Step: 0
Training loss: 3.188374717219158
Validation loss: 2.7740839961361687

Epoch: 5| Step: 1
Training loss: 3.1150750289869844
Validation loss: 2.7717416190046524

Epoch: 5| Step: 2
Training loss: 3.108964595834809
Validation loss: 2.7687730455264696

Epoch: 5| Step: 3
Training loss: 3.0916989395911187
Validation loss: 2.7673939616924406

Epoch: 5| Step: 4
Training loss: 2.7748788446320454
Validation loss: 2.770199245426403

Epoch: 5| Step: 5
Training loss: 2.811884155665523
Validation loss: 2.783945702432769

Epoch: 5| Step: 6
Training loss: 2.7159275882826703
Validation loss: 2.783425280533205

Epoch: 5| Step: 7
Training loss: 3.153112684061366
Validation loss: 2.7668267923766505

Epoch: 5| Step: 8
Training loss: 2.1401377770823586
Validation loss: 2.7566742389610317

Epoch: 5| Step: 9
Training loss: 2.8460993860708848
Validation loss: 2.757187160956131

Epoch: 5| Step: 10
Training loss: 3.148144578204489
Validation loss: 2.7571486699852232

Epoch: 5| Step: 11
Training loss: 1.2861813338387864
Validation loss: 2.7570994160354934

Epoch: 64| Step: 0
Training loss: 2.9203719082540722
Validation loss: 2.7619105393407244

Epoch: 5| Step: 1
Training loss: 3.5975099216984447
Validation loss: 2.756805481012209

Epoch: 5| Step: 2
Training loss: 3.060109509521859
Validation loss: 2.754175657256703

Epoch: 5| Step: 3
Training loss: 2.238453909986759
Validation loss: 2.752194803932154

Epoch: 5| Step: 4
Training loss: 3.010356510885685
Validation loss: 2.7506201434986433

Epoch: 5| Step: 5
Training loss: 2.848419547639104
Validation loss: 2.74852440721763

Epoch: 5| Step: 6
Training loss: 2.60106244020998
Validation loss: 2.746699125831509

Epoch: 5| Step: 7
Training loss: 2.8410604984511285
Validation loss: 2.7437989082119407

Epoch: 5| Step: 8
Training loss: 2.4976348179198062
Validation loss: 2.740155041924532

Epoch: 5| Step: 9
Training loss: 2.8141073084625754
Validation loss: 2.740380520502241

Epoch: 5| Step: 10
Training loss: 3.199833960993865
Validation loss: 2.7379928487782315

Epoch: 5| Step: 11
Training loss: 2.455486740060967
Validation loss: 2.734009411304724

Epoch: 65| Step: 0
Training loss: 2.3113797541620977
Validation loss: 2.734065501544651

Epoch: 5| Step: 1
Training loss: 2.4881251599087313
Validation loss: 2.7324551409209046

Epoch: 5| Step: 2
Training loss: 3.135401086779104
Validation loss: 2.7304056002945987

Epoch: 5| Step: 3
Training loss: 2.7929753230090926
Validation loss: 2.730439021758664

Epoch: 5| Step: 4
Training loss: 3.064505095858701
Validation loss: 2.7346165940866283

Epoch: 5| Step: 5
Training loss: 2.4005898624978084
Validation loss: 2.7322588988557217

Epoch: 5| Step: 6
Training loss: 3.0065393701180474
Validation loss: 2.7402785268875887

Epoch: 5| Step: 7
Training loss: 3.461593118056775
Validation loss: 2.7558742011825172

Epoch: 5| Step: 8
Training loss: 3.069801812251714
Validation loss: 2.720794201540767

Epoch: 5| Step: 9
Training loss: 2.7171961410762364
Validation loss: 2.7236810084734007

Epoch: 5| Step: 10
Training loss: 3.079334621640872
Validation loss: 2.7367297142652047

Epoch: 5| Step: 11
Training loss: 2.084937266588405
Validation loss: 2.7402929117154677

Epoch: 66| Step: 0
Training loss: 2.9866506478470423
Validation loss: 2.7370229343117325

Epoch: 5| Step: 1
Training loss: 2.6964186015887623
Validation loss: 2.7382189081036397

Epoch: 5| Step: 2
Training loss: 2.5709025624587056
Validation loss: 2.7315994744729113

Epoch: 5| Step: 3
Training loss: 2.3382495677877855
Validation loss: 2.72667871644716

Epoch: 5| Step: 4
Training loss: 2.785301258223257
Validation loss: 2.7260904240478148

Epoch: 5| Step: 5
Training loss: 3.5145762595915975
Validation loss: 2.7234346361668655

Epoch: 5| Step: 6
Training loss: 3.380896891491007
Validation loss: 2.7194874592752765

Epoch: 5| Step: 7
Training loss: 3.079307522647058
Validation loss: 2.7158985311855

Epoch: 5| Step: 8
Training loss: 2.834232542922482
Validation loss: 2.7146085715029438

Epoch: 5| Step: 9
Training loss: 2.4867137720727546
Validation loss: 2.7078628363666075

Epoch: 5| Step: 10
Training loss: 2.61518751562528
Validation loss: 2.708007823505257

Epoch: 5| Step: 11
Training loss: 2.7685122316795403
Validation loss: 2.705414829346549

Epoch: 67| Step: 0
Training loss: 2.4459868162521934
Validation loss: 2.7037991250945965

Epoch: 5| Step: 1
Training loss: 3.4851738394639913
Validation loss: 2.7028559475515848

Epoch: 5| Step: 2
Training loss: 2.8521278134526193
Validation loss: 2.6996413147176312

Epoch: 5| Step: 3
Training loss: 2.978377942514521
Validation loss: 2.699363101056538

Epoch: 5| Step: 4
Training loss: 2.794214954984789
Validation loss: 2.69755508817954

Epoch: 5| Step: 5
Training loss: 2.6040769230955765
Validation loss: 2.6949403699424637

Epoch: 5| Step: 6
Training loss: 2.7519817147756402
Validation loss: 2.6921722252269085

Epoch: 5| Step: 7
Training loss: 2.86816871754389
Validation loss: 2.689613974643169

Epoch: 5| Step: 8
Training loss: 2.7154602668059438
Validation loss: 2.6884402618932026

Epoch: 5| Step: 9
Training loss: 2.5975434472394547
Validation loss: 2.688018700718873

Epoch: 5| Step: 10
Training loss: 2.9519689810138865
Validation loss: 2.687672945860067

Epoch: 5| Step: 11
Training loss: 3.0017990440085014
Validation loss: 2.685956156667521

Epoch: 68| Step: 0
Training loss: 2.9956420398771115
Validation loss: 2.682794325064739

Epoch: 5| Step: 1
Training loss: 3.085786067289204
Validation loss: 2.6819931950597797

Epoch: 5| Step: 2
Training loss: 3.1657904533688126
Validation loss: 2.6800922128959193

Epoch: 5| Step: 3
Training loss: 2.682146995618159
Validation loss: 2.679820132518196

Epoch: 5| Step: 4
Training loss: 2.1961134131768234
Validation loss: 2.6768352391112473

Epoch: 5| Step: 5
Training loss: 2.5401742232637687
Validation loss: 2.674582063700675

Epoch: 5| Step: 6
Training loss: 2.728939037197019
Validation loss: 2.6746178429793916

Epoch: 5| Step: 7
Training loss: 2.676536197388366
Validation loss: 2.671275136582726

Epoch: 5| Step: 8
Training loss: 2.9360175754738274
Validation loss: 2.6738485628567896

Epoch: 5| Step: 9
Training loss: 3.046137793927702
Validation loss: 2.669967278906288

Epoch: 5| Step: 10
Training loss: 2.756913770819444
Validation loss: 2.6692678510447645

Epoch: 5| Step: 11
Training loss: 2.8542429410298027
Validation loss: 2.6681371014838056

Epoch: 69| Step: 0
Training loss: 2.5750055109353953
Validation loss: 2.6671317534383787

Epoch: 5| Step: 1
Training loss: 2.519861291367915
Validation loss: 2.66587815448477

Epoch: 5| Step: 2
Training loss: 3.1332943514840723
Validation loss: 2.6651098256625407

Epoch: 5| Step: 3
Training loss: 3.033347593700159
Validation loss: 2.6693355174096984

Epoch: 5| Step: 4
Training loss: 2.750648682121153
Validation loss: 2.6599927190033257

Epoch: 5| Step: 5
Training loss: 2.972739179660006
Validation loss: 2.6615524175827017

Epoch: 5| Step: 6
Training loss: 2.4802576651080326
Validation loss: 2.6597692438710627

Epoch: 5| Step: 7
Training loss: 2.9022257846357995
Validation loss: 2.6621001652282836

Epoch: 5| Step: 8
Training loss: 2.8296671503810833
Validation loss: 2.6605470643813325

Epoch: 5| Step: 9
Training loss: 2.8305825362470594
Validation loss: 2.6607514927726164

Epoch: 5| Step: 10
Training loss: 2.65539483160809
Validation loss: 2.6592224095247246

Epoch: 5| Step: 11
Training loss: 3.1552076979282093
Validation loss: 2.658153020539311

Epoch: 70| Step: 0
Training loss: 2.919289817147147
Validation loss: 2.6580394252549406

Epoch: 5| Step: 1
Training loss: 2.5725552592074723
Validation loss: 2.657170992485978

Epoch: 5| Step: 2
Training loss: 2.4538852947011973
Validation loss: 2.657052244323861

Epoch: 5| Step: 3
Training loss: 2.9005806703309696
Validation loss: 2.6560883940360656

Epoch: 5| Step: 4
Training loss: 2.790812480306037
Validation loss: 2.656683628366362

Epoch: 5| Step: 5
Training loss: 3.036714328206197
Validation loss: 2.6561430068065652

Epoch: 5| Step: 6
Training loss: 2.7328430243870874
Validation loss: 2.6555279517058095

Epoch: 5| Step: 7
Training loss: 2.746534591604194
Validation loss: 2.6529158479455526

Epoch: 5| Step: 8
Training loss: 2.8936827287208025
Validation loss: 2.6526631241188574

Epoch: 5| Step: 9
Training loss: 3.033514848105939
Validation loss: 2.651205298889093

Epoch: 5| Step: 10
Training loss: 2.6507497050878714
Validation loss: 2.6511384550361674

Epoch: 5| Step: 11
Training loss: 2.6190495941022554
Validation loss: 2.6501792986510604

Epoch: 71| Step: 0
Training loss: 2.098972923158686
Validation loss: 2.647422667362421

Epoch: 5| Step: 1
Training loss: 2.5162838848957376
Validation loss: 2.647353180076352

Epoch: 5| Step: 2
Training loss: 2.4705260443272934
Validation loss: 2.646374963654757

Epoch: 5| Step: 3
Training loss: 3.08671772425081
Validation loss: 2.653823829099456

Epoch: 5| Step: 4
Training loss: 3.0652017937050755
Validation loss: 2.640602660978129

Epoch: 5| Step: 5
Training loss: 2.6346111549244964
Validation loss: 2.638968913359582

Epoch: 5| Step: 6
Training loss: 3.34647792879216
Validation loss: 2.6388724189935893

Epoch: 5| Step: 7
Training loss: 2.8485887881732674
Validation loss: 2.6381486458175445

Epoch: 5| Step: 8
Training loss: 2.912468932153907
Validation loss: 2.6348523992148296

Epoch: 5| Step: 9
Training loss: 2.9387668556239483
Validation loss: 2.6339964803234306

Epoch: 5| Step: 10
Training loss: 2.420580413352571
Validation loss: 2.6318925331272727

Epoch: 5| Step: 11
Training loss: 2.9409873228399794
Validation loss: 2.630550858254979

Epoch: 72| Step: 0
Training loss: 2.4290216152883124
Validation loss: 2.6294062319902243

Epoch: 5| Step: 1
Training loss: 2.4651580948649565
Validation loss: 2.634316434620273

Epoch: 5| Step: 2
Training loss: 2.662507260451469
Validation loss: 2.635031677040005

Epoch: 5| Step: 3
Training loss: 2.7945088015308692
Validation loss: 2.651956731307119

Epoch: 5| Step: 4
Training loss: 2.828606158892401
Validation loss: 2.6843814091870524

Epoch: 5| Step: 5
Training loss: 3.1301203168955323
Validation loss: 2.731254213622311

Epoch: 5| Step: 6
Training loss: 3.213354681294969
Validation loss: 2.6829030028511323

Epoch: 5| Step: 7
Training loss: 2.4527143389786734
Validation loss: 2.6363192936228454

Epoch: 5| Step: 8
Training loss: 3.090697044096006
Validation loss: 2.6265189642837297

Epoch: 5| Step: 9
Training loss: 2.737393702006556
Validation loss: 2.6305434941940997

Epoch: 5| Step: 10
Training loss: 2.778481723809728
Validation loss: 2.6326399085339367

Epoch: 5| Step: 11
Training loss: 3.202412000246647
Validation loss: 2.6371768129676685

Epoch: 73| Step: 0
Training loss: 2.500049399841521
Validation loss: 2.633433611133493

Epoch: 5| Step: 1
Training loss: 2.9908415553533616
Validation loss: 2.6347154594153164

Epoch: 5| Step: 2
Training loss: 2.3407729505729584
Validation loss: 2.6334176844253507

Epoch: 5| Step: 3
Training loss: 2.8159553494923304
Validation loss: 2.637388744237497

Epoch: 5| Step: 4
Training loss: 2.9269189392480124
Validation loss: 2.6298858306372606

Epoch: 5| Step: 5
Training loss: 2.7410273257719746
Validation loss: 2.6273269935608212

Epoch: 5| Step: 6
Training loss: 2.6267242218463434
Validation loss: 2.624118361692237

Epoch: 5| Step: 7
Training loss: 3.200719013498239
Validation loss: 2.622496614663091

Epoch: 5| Step: 8
Training loss: 2.532550524765882
Validation loss: 2.6191674140320633

Epoch: 5| Step: 9
Training loss: 2.6547361660201823
Validation loss: 2.6170883197875594

Epoch: 5| Step: 10
Training loss: 2.953344750680088
Validation loss: 2.614816238597475

Epoch: 5| Step: 11
Training loss: 2.720351963973016
Validation loss: 2.611643184200468

Epoch: 74| Step: 0
Training loss: 2.55652023043612
Validation loss: 2.609053772819478

Epoch: 5| Step: 1
Training loss: 2.6184150208426686
Validation loss: 2.606359315313195

Epoch: 5| Step: 2
Training loss: 2.634788971183168
Validation loss: 2.605773923160263

Epoch: 5| Step: 3
Training loss: 3.0826514409370116
Validation loss: 2.608254388116225

Epoch: 5| Step: 4
Training loss: 3.350718714352185
Validation loss: 2.6075284519392747

Epoch: 5| Step: 5
Training loss: 2.6169644844347753
Validation loss: 2.6070634516989832

Epoch: 5| Step: 6
Training loss: 2.189849245987908
Validation loss: 2.606634227261399

Epoch: 5| Step: 7
Training loss: 2.8411695908841907
Validation loss: 2.602022968433985

Epoch: 5| Step: 8
Training loss: 2.483737119920621
Validation loss: 2.602647026451635

Epoch: 5| Step: 9
Training loss: 2.929202596589672
Validation loss: 2.603626700052031

Epoch: 5| Step: 10
Training loss: 2.5051637726202505
Validation loss: 2.6008269689759724

Epoch: 5| Step: 11
Training loss: 3.293309023325949
Validation loss: 2.596467218772313

Epoch: 75| Step: 0
Training loss: 3.3022366717783855
Validation loss: 2.593783554564829

Epoch: 5| Step: 1
Training loss: 2.7253998734244953
Validation loss: 2.5909885352359674

Epoch: 5| Step: 2
Training loss: 2.409444595697338
Validation loss: 2.5907066618408043

Epoch: 5| Step: 3
Training loss: 2.4563857839389467
Validation loss: 2.5906663319995205

Epoch: 5| Step: 4
Training loss: 3.2864536259169603
Validation loss: 2.5880767793699437

Epoch: 5| Step: 5
Training loss: 2.5586028819612796
Validation loss: 2.588857229840307

Epoch: 5| Step: 6
Training loss: 2.7047462672962284
Validation loss: 2.590897872536489

Epoch: 5| Step: 7
Training loss: 2.8784016926623166
Validation loss: 2.5894036779796004

Epoch: 5| Step: 8
Training loss: 2.6015447209297706
Validation loss: 2.589899583217564

Epoch: 5| Step: 9
Training loss: 2.424472720051904
Validation loss: 2.589754642969359

Epoch: 5| Step: 10
Training loss: 2.3553297719870034
Validation loss: 2.5849807329216126

Epoch: 5| Step: 11
Training loss: 3.2428198507960317
Validation loss: 2.5881838957438505

Epoch: 76| Step: 0
Training loss: 2.7314610240431216
Validation loss: 2.5858024070157426

Epoch: 5| Step: 1
Training loss: 2.963178848198936
Validation loss: 2.5873206051851114

Epoch: 5| Step: 2
Training loss: 2.5673009047532536
Validation loss: 2.590609683185941

Epoch: 5| Step: 3
Training loss: 2.7104000911064086
Validation loss: 2.5882863866139236

Epoch: 5| Step: 4
Training loss: 2.7573316117004
Validation loss: 2.5826150039024713

Epoch: 5| Step: 5
Training loss: 2.700253499457825
Validation loss: 2.5828852931520943

Epoch: 5| Step: 6
Training loss: 2.513244450293515
Validation loss: 2.579836521969914

Epoch: 5| Step: 7
Training loss: 2.457159236127816
Validation loss: 2.580832391105811

Epoch: 5| Step: 8
Training loss: 2.7073877493430762
Validation loss: 2.5771084004547364

Epoch: 5| Step: 9
Training loss: 2.5522344635311107
Validation loss: 2.576718187380476

Epoch: 5| Step: 10
Training loss: 2.9704488611601407
Validation loss: 2.5775696821071317

Epoch: 5| Step: 11
Training loss: 3.427456001650424
Validation loss: 2.57808365836857

Epoch: 77| Step: 0
Training loss: 2.6937861889313424
Validation loss: 2.5773293548641427

Epoch: 5| Step: 1
Training loss: 2.8773369620473828
Validation loss: 2.577069958678078

Epoch: 5| Step: 2
Training loss: 2.6967831345136317
Validation loss: 2.5762998304772053

Epoch: 5| Step: 3
Training loss: 2.481682620060225
Validation loss: 2.5753716071045902

Epoch: 5| Step: 4
Training loss: 2.790670919521109
Validation loss: 2.5789016555641973

Epoch: 5| Step: 5
Training loss: 2.4322600161816412
Validation loss: 2.57617584490428

Epoch: 5| Step: 6
Training loss: 2.795742722098023
Validation loss: 2.5780411947481743

Epoch: 5| Step: 7
Training loss: 2.42788806284582
Validation loss: 2.575127730087325

Epoch: 5| Step: 8
Training loss: 2.7159723584281203
Validation loss: 2.5752300886482984

Epoch: 5| Step: 9
Training loss: 3.127658781050707
Validation loss: 2.5746422835519365

Epoch: 5| Step: 10
Training loss: 2.857521832400243
Validation loss: 2.570962269134606

Epoch: 5| Step: 11
Training loss: 2.01234583293796
Validation loss: 2.569563148666272

Epoch: 78| Step: 0
Training loss: 2.5621955504641636
Validation loss: 2.5680315047749915

Epoch: 5| Step: 1
Training loss: 2.784293920019336
Validation loss: 2.569275396531035

Epoch: 5| Step: 2
Training loss: 1.998412276907411
Validation loss: 2.570179658527643

Epoch: 5| Step: 3
Training loss: 2.9176092168898267
Validation loss: 2.572338133156654

Epoch: 5| Step: 4
Training loss: 2.7105277243714334
Validation loss: 2.5669949271069363

Epoch: 5| Step: 5
Training loss: 2.9400501950189484
Validation loss: 2.5632392352008457

Epoch: 5| Step: 6
Training loss: 2.5058814484121337
Validation loss: 2.5639922131426593

Epoch: 5| Step: 7
Training loss: 2.7866060782269138
Validation loss: 2.566345105732295

Epoch: 5| Step: 8
Training loss: 2.3586583343791405
Validation loss: 2.5632925552449053

Epoch: 5| Step: 9
Training loss: 3.0033742684112457
Validation loss: 2.5602634563084354

Epoch: 5| Step: 10
Training loss: 2.89707532270306
Validation loss: 2.562046053461079

Epoch: 5| Step: 11
Training loss: 3.0870115318466023
Validation loss: 2.5605102001039906

Epoch: 79| Step: 0
Training loss: 2.633566366419394
Validation loss: 2.5588388573108145

Epoch: 5| Step: 1
Training loss: 2.922859230120664
Validation loss: 2.5609930577437883

Epoch: 5| Step: 2
Training loss: 2.8649464510029254
Validation loss: 2.561311000130459

Epoch: 5| Step: 3
Training loss: 2.4335773889962167
Validation loss: 2.5618882689636875

Epoch: 5| Step: 4
Training loss: 3.074486300351225
Validation loss: 2.5614985354385396

Epoch: 5| Step: 5
Training loss: 2.130889920331311
Validation loss: 2.560711876436169

Epoch: 5| Step: 6
Training loss: 2.537611984262393
Validation loss: 2.5565125909564004

Epoch: 5| Step: 7
Training loss: 2.752807397957849
Validation loss: 2.560014546701954

Epoch: 5| Step: 8
Training loss: 2.9617181317593655
Validation loss: 2.557326016839586

Epoch: 5| Step: 9
Training loss: 2.684497664361237
Validation loss: 2.5533530612408364

Epoch: 5| Step: 10
Training loss: 2.5541541799848884
Validation loss: 2.553855826727195

Epoch: 5| Step: 11
Training loss: 2.434455535300847
Validation loss: 2.5557658634747615

Epoch: 80| Step: 0
Training loss: 2.514869718722709
Validation loss: 2.558862725405385

Epoch: 5| Step: 1
Training loss: 2.809872650437387
Validation loss: 2.5517123880490606

Epoch: 5| Step: 2
Training loss: 2.7699139630558807
Validation loss: 2.5537125849429785

Epoch: 5| Step: 3
Training loss: 2.4177696626755307
Validation loss: 2.550598071746897

Epoch: 5| Step: 4
Training loss: 2.4701627720933668
Validation loss: 2.5533204771528295

Epoch: 5| Step: 5
Training loss: 2.569304572986537
Validation loss: 2.551899005435345

Epoch: 5| Step: 6
Training loss: 2.6248726586835027
Validation loss: 2.5517486015393978

Epoch: 5| Step: 7
Training loss: 2.9586038779182835
Validation loss: 2.5518653789534786

Epoch: 5| Step: 8
Training loss: 2.8097326439298436
Validation loss: 2.552981585766808

Epoch: 5| Step: 9
Training loss: 2.778575253983077
Validation loss: 2.555359712095906

Epoch: 5| Step: 10
Training loss: 2.6959576263154035
Validation loss: 2.5532378186964624

Epoch: 5| Step: 11
Training loss: 3.074543064562142
Validation loss: 2.552579556444909

Epoch: 81| Step: 0
Training loss: 2.671979757118068
Validation loss: 2.5524923671504918

Epoch: 5| Step: 1
Training loss: 2.3744652798673243
Validation loss: 2.550759054947116

Epoch: 5| Step: 2
Training loss: 2.604128743213451
Validation loss: 2.550939285344366

Epoch: 5| Step: 3
Training loss: 2.6758441555675945
Validation loss: 2.550778153842607

Epoch: 5| Step: 4
Training loss: 2.7837110624771944
Validation loss: 2.552901274467261

Epoch: 5| Step: 5
Training loss: 2.412190226694052
Validation loss: 2.549374603891182

Epoch: 5| Step: 6
Training loss: 2.4533953669555832
Validation loss: 2.551214048034803

Epoch: 5| Step: 7
Training loss: 2.9859515913905788
Validation loss: 2.5474780271772377

Epoch: 5| Step: 8
Training loss: 3.0286665456801076
Validation loss: 2.5493953770294415

Epoch: 5| Step: 9
Training loss: 2.5718730606683624
Validation loss: 2.5520136583639386

Epoch: 5| Step: 10
Training loss: 2.8628239077751028
Validation loss: 2.5483289285808426

Epoch: 5| Step: 11
Training loss: 2.6796208587456465
Validation loss: 2.543284723249373

Epoch: 82| Step: 0
Training loss: 2.716992478833057
Validation loss: 2.547016089184261

Epoch: 5| Step: 1
Training loss: 2.972410495138807
Validation loss: 2.5483025799495054

Epoch: 5| Step: 2
Training loss: 2.5455344012664622
Validation loss: 2.546631963324476

Epoch: 5| Step: 3
Training loss: 2.830818032159816
Validation loss: 2.552168943305694

Epoch: 5| Step: 4
Training loss: 2.546410453883269
Validation loss: 2.5435464049584775

Epoch: 5| Step: 5
Training loss: 2.2887250111172532
Validation loss: 2.546311298544516

Epoch: 5| Step: 6
Training loss: 2.9193020676306785
Validation loss: 2.5540171063451957

Epoch: 5| Step: 7
Training loss: 2.670052336133442
Validation loss: 2.542104586933573

Epoch: 5| Step: 8
Training loss: 2.77961005391932
Validation loss: 2.5405873341601173

Epoch: 5| Step: 9
Training loss: 2.433138637940553
Validation loss: 2.5388921357733927

Epoch: 5| Step: 10
Training loss: 2.4963585081857937
Validation loss: 2.5402776070074413

Epoch: 5| Step: 11
Training loss: 3.3489306949564637
Validation loss: 2.542086774991185

Epoch: 83| Step: 0
Training loss: 2.5485757403181455
Validation loss: 2.541148728352533

Epoch: 5| Step: 1
Training loss: 2.9496479858894387
Validation loss: 2.547409945360299

Epoch: 5| Step: 2
Training loss: 2.533223642517623
Validation loss: 2.550432641907344

Epoch: 5| Step: 3
Training loss: 2.076495456689668
Validation loss: 2.5470946359615034

Epoch: 5| Step: 4
Training loss: 3.1240445011403057
Validation loss: 2.5520114084086436

Epoch: 5| Step: 5
Training loss: 2.476274924925481
Validation loss: 2.548220129076693

Epoch: 5| Step: 6
Training loss: 2.726406497372689
Validation loss: 2.543548892832631

Epoch: 5| Step: 7
Training loss: 2.783711833306805
Validation loss: 2.5437325084125506

Epoch: 5| Step: 8
Training loss: 3.1135198676396016
Validation loss: 2.5385698945911814

Epoch: 5| Step: 9
Training loss: 2.8411942619767396
Validation loss: 2.5364233121601805

Epoch: 5| Step: 10
Training loss: 2.302578442756378
Validation loss: 2.5356003774403857

Epoch: 5| Step: 11
Training loss: 1.5098625043454117
Validation loss: 2.5337545186463415

Epoch: 84| Step: 0
Training loss: 2.831402139176007
Validation loss: 2.5350085481428075

Epoch: 5| Step: 1
Training loss: 2.6520730780807518
Validation loss: 2.5317489226512135

Epoch: 5| Step: 2
Training loss: 2.3437160235167487
Validation loss: 2.530951607937988

Epoch: 5| Step: 3
Training loss: 2.7758348016917287
Validation loss: 2.530929972978948

Epoch: 5| Step: 4
Training loss: 2.886764670537161
Validation loss: 2.5339971360230815

Epoch: 5| Step: 5
Training loss: 2.5726301417226405
Validation loss: 2.5308395060741455

Epoch: 5| Step: 6
Training loss: 2.8532235102448706
Validation loss: 2.5315276707911245

Epoch: 5| Step: 7
Training loss: 2.45259175913463
Validation loss: 2.5303677563772085

Epoch: 5| Step: 8
Training loss: 2.59332961387008
Validation loss: 2.527571116169204

Epoch: 5| Step: 9
Training loss: 2.6288106597707483
Validation loss: 2.527132645545443

Epoch: 5| Step: 10
Training loss: 2.7089357928682642
Validation loss: 2.5287148688517984

Epoch: 5| Step: 11
Training loss: 2.380400791080775
Validation loss: 2.525257780746328

Epoch: 85| Step: 0
Training loss: 2.8124087000968787
Validation loss: 2.5257936152682445

Epoch: 5| Step: 1
Training loss: 2.7087437441005036
Validation loss: 2.529950243833803

Epoch: 5| Step: 2
Training loss: 2.384804415250656
Validation loss: 2.5285628384066308

Epoch: 5| Step: 3
Training loss: 2.746273116308338
Validation loss: 2.5307288437899578

Epoch: 5| Step: 4
Training loss: 2.792232731227054
Validation loss: 2.524845655527007

Epoch: 5| Step: 5
Training loss: 2.624609236923739
Validation loss: 2.520671054382469

Epoch: 5| Step: 6
Training loss: 2.4648429761785633
Validation loss: 2.522159343258723

Epoch: 5| Step: 7
Training loss: 2.836547281582286
Validation loss: 2.5219285663838744

Epoch: 5| Step: 8
Training loss: 2.7296000614584393
Validation loss: 2.522611705346975

Epoch: 5| Step: 9
Training loss: 2.477208772204399
Validation loss: 2.522772564593378

Epoch: 5| Step: 10
Training loss: 2.6381400791542498
Validation loss: 2.525294440479121

Epoch: 5| Step: 11
Training loss: 2.3675961786893134
Validation loss: 2.5264325236063314

Epoch: 86| Step: 0
Training loss: 3.0646785850080165
Validation loss: 2.5256676596921985

Epoch: 5| Step: 1
Training loss: 2.7077313463274524
Validation loss: 2.5217969854768008

Epoch: 5| Step: 2
Training loss: 2.713035013903031
Validation loss: 2.52280587793895

Epoch: 5| Step: 3
Training loss: 2.2245501074125986
Validation loss: 2.5206271486582965

Epoch: 5| Step: 4
Training loss: 2.810748932701586
Validation loss: 2.5195699723296716

Epoch: 5| Step: 5
Training loss: 2.4335303627441562
Validation loss: 2.52476618442749

Epoch: 5| Step: 6
Training loss: 2.8183535379519857
Validation loss: 2.5322816300647664

Epoch: 5| Step: 7
Training loss: 2.114600370993041
Validation loss: 2.524677979516312

Epoch: 5| Step: 8
Training loss: 2.603922463729102
Validation loss: 2.5221809234741364

Epoch: 5| Step: 9
Training loss: 2.918933387239357
Validation loss: 2.5215200219268104

Epoch: 5| Step: 10
Training loss: 2.6756469692868956
Validation loss: 2.5189637838844234

Epoch: 5| Step: 11
Training loss: 2.124974867728219
Validation loss: 2.5187554005201327

Epoch: 87| Step: 0
Training loss: 2.4320416100732
Validation loss: 2.5233954612135556

Epoch: 5| Step: 1
Training loss: 2.180487591871521
Validation loss: 2.5237653300862215

Epoch: 5| Step: 2
Training loss: 2.9257268149350315
Validation loss: 2.523998154911066

Epoch: 5| Step: 3
Training loss: 2.729270049799071
Validation loss: 2.5300036411296896

Epoch: 5| Step: 4
Training loss: 2.59357277138294
Validation loss: 2.5282446126851235

Epoch: 5| Step: 5
Training loss: 2.975107232733746
Validation loss: 2.5280483232650006

Epoch: 5| Step: 6
Training loss: 2.8383849121114206
Validation loss: 2.526034916872006

Epoch: 5| Step: 7
Training loss: 2.2289935843990203
Validation loss: 2.522789619033638

Epoch: 5| Step: 8
Training loss: 2.6373489191978825
Validation loss: 2.5235404199293603

Epoch: 5| Step: 9
Training loss: 2.5997295165584315
Validation loss: 2.5213264634542947

Epoch: 5| Step: 10
Training loss: 2.8951413725230295
Validation loss: 2.5204164926193897

Epoch: 5| Step: 11
Training loss: 2.9710512578003514
Validation loss: 2.519217009748529

Epoch: 88| Step: 0
Training loss: 2.6489728088423417
Validation loss: 2.515731911924616

Epoch: 5| Step: 1
Training loss: 2.5699981218917456
Validation loss: 2.5140191989012335

Epoch: 5| Step: 2
Training loss: 2.053243151187099
Validation loss: 2.5146419586789515

Epoch: 5| Step: 3
Training loss: 2.9084802089501127
Validation loss: 2.516733900544716

Epoch: 5| Step: 4
Training loss: 2.75233031287745
Validation loss: 2.514634950472024

Epoch: 5| Step: 5
Training loss: 2.654631985807453
Validation loss: 2.512552268400298

Epoch: 5| Step: 6
Training loss: 2.272301039174668
Validation loss: 2.5159559683737274

Epoch: 5| Step: 7
Training loss: 2.9630108421042345
Validation loss: 2.5165353987629664

Epoch: 5| Step: 8
Training loss: 2.7366756678660495
Validation loss: 2.5159378844421063

Epoch: 5| Step: 9
Training loss: 2.5354900875029434
Validation loss: 2.5150582324681348

Epoch: 5| Step: 10
Training loss: 2.6520657063567903
Validation loss: 2.5169087998222284

Epoch: 5| Step: 11
Training loss: 3.0113507749829203
Validation loss: 2.532184459739849

Epoch: 89| Step: 0
Training loss: 2.9629089717007777
Validation loss: 2.553514578802867

Epoch: 5| Step: 1
Training loss: 2.693909122166149
Validation loss: 2.5806646457668476

Epoch: 5| Step: 2
Training loss: 2.6898462566416126
Validation loss: 2.5634602825313904

Epoch: 5| Step: 3
Training loss: 2.7815111016287326
Validation loss: 2.5223381474355184

Epoch: 5| Step: 4
Training loss: 3.0518714041359627
Validation loss: 2.514423974151515

Epoch: 5| Step: 5
Training loss: 2.7987849357983556
Validation loss: 2.5116099941662453

Epoch: 5| Step: 6
Training loss: 2.1606732762035645
Validation loss: 2.519843034403345

Epoch: 5| Step: 7
Training loss: 2.747429339790622
Validation loss: 2.529720036323137

Epoch: 5| Step: 8
Training loss: 2.4492293605544186
Validation loss: 2.5429457992088382

Epoch: 5| Step: 9
Training loss: 2.4712042861901304
Validation loss: 2.566574389225295

Epoch: 5| Step: 10
Training loss: 2.637746020228298
Validation loss: 2.5576134820410945

Epoch: 5| Step: 11
Training loss: 2.698634480508097
Validation loss: 2.5686100014360957

Epoch: 90| Step: 0
Training loss: 2.144293210797173
Validation loss: 2.5368290394644197

Epoch: 5| Step: 1
Training loss: 2.628624185334802
Validation loss: 2.522405946973718

Epoch: 5| Step: 2
Training loss: 2.5176879764144786
Validation loss: 2.518131926170324

Epoch: 5| Step: 3
Training loss: 2.253878218081478
Validation loss: 2.517665489620329

Epoch: 5| Step: 4
Training loss: 2.794519380795401
Validation loss: 2.5162895264784444

Epoch: 5| Step: 5
Training loss: 2.8980141713577137
Validation loss: 2.5194811636113434

Epoch: 5| Step: 6
Training loss: 2.3599750690436476
Validation loss: 2.528109391757234

Epoch: 5| Step: 7
Training loss: 3.1913971358020867
Validation loss: 2.5419269074166797

Epoch: 5| Step: 8
Training loss: 2.8809182991855273
Validation loss: 2.545964567815407

Epoch: 5| Step: 9
Training loss: 3.035092936165967
Validation loss: 2.5490629904000115

Epoch: 5| Step: 10
Training loss: 2.4228366050273893
Validation loss: 2.5272319086986847

Epoch: 5| Step: 11
Training loss: 2.46646456620805
Validation loss: 2.52005135936726

Epoch: 91| Step: 0
Training loss: 2.9784908106036014
Validation loss: 2.512662307911924

Epoch: 5| Step: 1
Training loss: 2.295303533755994
Validation loss: 2.5135345381946452

Epoch: 5| Step: 2
Training loss: 2.951876098710146
Validation loss: 2.512279094012195

Epoch: 5| Step: 3
Training loss: 2.5153785727030575
Validation loss: 2.5157875577163917

Epoch: 5| Step: 4
Training loss: 2.5896952544803185
Validation loss: 2.5224135873534563

Epoch: 5| Step: 5
Training loss: 2.5426794962880215
Validation loss: 2.5265530425842098

Epoch: 5| Step: 6
Training loss: 2.607030489118109
Validation loss: 2.5289976318554936

Epoch: 5| Step: 7
Training loss: 2.7538404524497833
Validation loss: 2.5272359849613717

Epoch: 5| Step: 8
Training loss: 2.4161846622922143
Validation loss: 2.5245596257735823

Epoch: 5| Step: 9
Training loss: 2.658009563408748
Validation loss: 2.5243701333331736

Epoch: 5| Step: 10
Training loss: 2.8338585161146397
Validation loss: 2.5210945346115086

Epoch: 5| Step: 11
Training loss: 2.3056444153520173
Validation loss: 2.5206485843477333

Epoch: 92| Step: 0
Training loss: 2.940730813987726
Validation loss: 2.519305114060699

Epoch: 5| Step: 1
Training loss: 2.8292035317207858
Validation loss: 2.5204055570295663

Epoch: 5| Step: 2
Training loss: 2.5422578864033887
Validation loss: 2.5185600163360387

Epoch: 5| Step: 3
Training loss: 2.922487898410774
Validation loss: 2.514698655697998

Epoch: 5| Step: 4
Training loss: 2.6749228778310132
Validation loss: 2.5105914982320554

Epoch: 5| Step: 5
Training loss: 2.6912692939006457
Validation loss: 2.5159948483865677

Epoch: 5| Step: 6
Training loss: 2.5337935489775667
Validation loss: 2.5101354423014337

Epoch: 5| Step: 7
Training loss: 2.355008562724427
Validation loss: 2.510568643193344

Epoch: 5| Step: 8
Training loss: 2.318080972154151
Validation loss: 2.509533949869677

Epoch: 5| Step: 9
Training loss: 2.8371876885037697
Validation loss: 2.5061135999325237

Epoch: 5| Step: 10
Training loss: 2.464478576015999
Validation loss: 2.505350574148423

Epoch: 5| Step: 11
Training loss: 1.9593768349476182
Validation loss: 2.504665206172197

Epoch: 93| Step: 0
Training loss: 2.205394360662342
Validation loss: 2.50798941569526

Epoch: 5| Step: 1
Training loss: 2.6634398149379366
Validation loss: 2.5067512072876696

Epoch: 5| Step: 2
Training loss: 2.551244626448419
Validation loss: 2.4987713973767316

Epoch: 5| Step: 3
Training loss: 3.075461537529488
Validation loss: 2.512129683272343

Epoch: 5| Step: 4
Training loss: 2.4089386026516357
Validation loss: 2.506114943711005

Epoch: 5| Step: 5
Training loss: 2.184352026560724
Validation loss: 2.508305494232136

Epoch: 5| Step: 6
Training loss: 2.658348600847972
Validation loss: 2.507361948929797

Epoch: 5| Step: 7
Training loss: 2.599923840654447
Validation loss: 2.500456502084648

Epoch: 5| Step: 8
Training loss: 2.832904465324548
Validation loss: 2.50005188729164

Epoch: 5| Step: 9
Training loss: 2.8438970506815973
Validation loss: 2.4994083340186624

Epoch: 5| Step: 10
Training loss: 2.651440113954483
Validation loss: 2.502068780215648

Epoch: 5| Step: 11
Training loss: 3.155642611536998
Validation loss: 2.509486712086717

Epoch: 94| Step: 0
Training loss: 2.5101744560011254
Validation loss: 2.5049363753334513

Epoch: 5| Step: 1
Training loss: 2.501418664860815
Validation loss: 2.5093579467092635

Epoch: 5| Step: 2
Training loss: 2.5455708353305644
Validation loss: 2.516428165681837

Epoch: 5| Step: 3
Training loss: 2.700390353065542
Validation loss: 2.532986492697013

Epoch: 5| Step: 4
Training loss: 2.1646466620111933
Validation loss: 2.5182407159287328

Epoch: 5| Step: 5
Training loss: 2.9458507582289877
Validation loss: 2.5154002189909415

Epoch: 5| Step: 6
Training loss: 2.767785817646832
Validation loss: 2.502861209547334

Epoch: 5| Step: 7
Training loss: 2.5958131604663484
Validation loss: 2.4990130820934966

Epoch: 5| Step: 8
Training loss: 2.7571722481556638
Validation loss: 2.501611845636548

Epoch: 5| Step: 9
Training loss: 2.908777102158483
Validation loss: 2.4931276555085846

Epoch: 5| Step: 10
Training loss: 2.476073689160735
Validation loss: 2.4942920811092573

Epoch: 5| Step: 11
Training loss: 2.541397288905005
Validation loss: 2.494294980539554

Epoch: 95| Step: 0
Training loss: 2.6529796439208404
Validation loss: 2.494996256924244

Epoch: 5| Step: 1
Training loss: 2.7314405117326865
Validation loss: 2.4970687211774685

Epoch: 5| Step: 2
Training loss: 2.167865372676046
Validation loss: 2.4971638526349014

Epoch: 5| Step: 3
Training loss: 2.3326106541789735
Validation loss: 2.502426190089664

Epoch: 5| Step: 4
Training loss: 2.6519431709196013
Validation loss: 2.4993544519948174

Epoch: 5| Step: 5
Training loss: 2.6952626983906747
Validation loss: 2.5035989506326697

Epoch: 5| Step: 6
Training loss: 2.655332429264932
Validation loss: 2.503932708743268

Epoch: 5| Step: 7
Training loss: 2.5169751826606066
Validation loss: 2.5041521678659278

Epoch: 5| Step: 8
Training loss: 2.739453466163265
Validation loss: 2.499674151960768

Epoch: 5| Step: 9
Training loss: 2.6334047641804053
Validation loss: 2.5010465179951327

Epoch: 5| Step: 10
Training loss: 2.9079179796932952
Validation loss: 2.5017699215013427

Epoch: 5| Step: 11
Training loss: 3.4416902838413126
Validation loss: 2.500476777787041

Epoch: 96| Step: 0
Training loss: 2.3114135870800645
Validation loss: 2.496807002453425

Epoch: 5| Step: 1
Training loss: 2.5068566708214477
Validation loss: 2.4963812107844725

Epoch: 5| Step: 2
Training loss: 2.913281047040503
Validation loss: 2.4942804196302886

Epoch: 5| Step: 3
Training loss: 2.345918288197328
Validation loss: 2.490594029602965

Epoch: 5| Step: 4
Training loss: 2.990834380885086
Validation loss: 2.4869148339277563

Epoch: 5| Step: 5
Training loss: 2.5719144055672243
Validation loss: 2.4865829005612454

Epoch: 5| Step: 6
Training loss: 3.20781427783796
Validation loss: 2.488831132447375

Epoch: 5| Step: 7
Training loss: 2.236254774997959
Validation loss: 2.4844618228320146

Epoch: 5| Step: 8
Training loss: 2.810541615537556
Validation loss: 2.4873212702198004

Epoch: 5| Step: 9
Training loss: 1.9586897045561176
Validation loss: 2.4883445999169798

Epoch: 5| Step: 10
Training loss: 2.7654426643912546
Validation loss: 2.4888027608807404

Epoch: 5| Step: 11
Training loss: 2.483432615032218
Validation loss: 2.4912237258995615

Epoch: 97| Step: 0
Training loss: 3.265662234153386
Validation loss: 2.486680055110094

Epoch: 5| Step: 1
Training loss: 2.580209525124361
Validation loss: 2.4876847123490786

Epoch: 5| Step: 2
Training loss: 2.833200358094006
Validation loss: 2.4891373116424966

Epoch: 5| Step: 3
Training loss: 2.581973446012861
Validation loss: 2.4869730578176092

Epoch: 5| Step: 4
Training loss: 2.6129834471571356
Validation loss: 2.48983304648148

Epoch: 5| Step: 5
Training loss: 2.4219800372572857
Validation loss: 2.491623945305867

Epoch: 5| Step: 6
Training loss: 2.440859899805
Validation loss: 2.492298538301425

Epoch: 5| Step: 7
Training loss: 2.6361271399370323
Validation loss: 2.4885173188577028

Epoch: 5| Step: 8
Training loss: 2.486080519939677
Validation loss: 2.4894637168229177

Epoch: 5| Step: 9
Training loss: 2.2111382814502636
Validation loss: 2.490816482624356

Epoch: 5| Step: 10
Training loss: 2.5069057453393864
Validation loss: 2.4898674229546924

Epoch: 5| Step: 11
Training loss: 2.7021562019901095
Validation loss: 2.4843696578186307

Epoch: 98| Step: 0
Training loss: 2.8751535789270446
Validation loss: 2.4883467118192533

Epoch: 5| Step: 1
Training loss: 2.56274580358099
Validation loss: 2.4893402449122495

Epoch: 5| Step: 2
Training loss: 2.4807896684317683
Validation loss: 2.485919736059032

Epoch: 5| Step: 3
Training loss: 2.68125838342881
Validation loss: 2.4920700667406113

Epoch: 5| Step: 4
Training loss: 2.8384581573987857
Validation loss: 2.49236235209497

Epoch: 5| Step: 5
Training loss: 2.597118717880572
Validation loss: 2.491454914646869

Epoch: 5| Step: 6
Training loss: 2.5125838194572903
Validation loss: 2.500656943631658

Epoch: 5| Step: 7
Training loss: 2.691411387932777
Validation loss: 2.4961219750183106

Epoch: 5| Step: 8
Training loss: 2.3076831034941394
Validation loss: 2.4969533276993734

Epoch: 5| Step: 9
Training loss: 2.9642161231481494
Validation loss: 2.503653576540468

Epoch: 5| Step: 10
Training loss: 2.47317658504339
Validation loss: 2.503464916293247

Epoch: 5| Step: 11
Training loss: 1.943511128850331
Validation loss: 2.49702512650228

Epoch: 99| Step: 0
Training loss: 2.489238560850182
Validation loss: 2.491528682066969

Epoch: 5| Step: 1
Training loss: 2.5562226235712187
Validation loss: 2.489846356648586

Epoch: 5| Step: 2
Training loss: 2.7696196591748907
Validation loss: 2.489417814128736

Epoch: 5| Step: 3
Training loss: 3.082025061384788
Validation loss: 2.4861760159111888

Epoch: 5| Step: 4
Training loss: 2.5415387564403344
Validation loss: 2.488049155469308

Epoch: 5| Step: 5
Training loss: 2.8517073085020943
Validation loss: 2.4860965434120583

Epoch: 5| Step: 6
Training loss: 2.629425133657222
Validation loss: 2.4817643393998314

Epoch: 5| Step: 7
Training loss: 2.210052852430156
Validation loss: 2.4815101860260587

Epoch: 5| Step: 8
Training loss: 2.539215177200524
Validation loss: 2.4859682928000835

Epoch: 5| Step: 9
Training loss: 1.9900358660739002
Validation loss: 2.4845725766676843

Epoch: 5| Step: 10
Training loss: 2.860239867441925
Validation loss: 2.4895798245542267

Epoch: 5| Step: 11
Training loss: 2.417731499934169
Validation loss: 2.48955118219745

Epoch: 100| Step: 0
Training loss: 2.335141355659101
Validation loss: 2.4888453620153848

Epoch: 5| Step: 1
Training loss: 2.1856897765921657
Validation loss: 2.4894393549403167

Epoch: 5| Step: 2
Training loss: 2.6259856417191503
Validation loss: 2.4822157307251738

Epoch: 5| Step: 3
Training loss: 2.9312089148531615
Validation loss: 2.4908402248230654

Epoch: 5| Step: 4
Training loss: 2.6576245510021455
Validation loss: 2.4874305049255665

Epoch: 5| Step: 5
Training loss: 2.6375733749524497
Validation loss: 2.4864272512137386

Epoch: 5| Step: 6
Training loss: 2.6377148364466247
Validation loss: 2.4847764224708535

Epoch: 5| Step: 7
Training loss: 3.030970452386454
Validation loss: 2.4856372641559084

Epoch: 5| Step: 8
Training loss: 2.215796425540595
Validation loss: 2.483600391732249

Epoch: 5| Step: 9
Training loss: 2.8619876453018365
Validation loss: 2.4859325596704154

Epoch: 5| Step: 10
Training loss: 2.230136078245055
Validation loss: 2.4851865542531946

Epoch: 5| Step: 11
Training loss: 2.8591822157944455
Validation loss: 2.490883106178107

Epoch: 101| Step: 0
Training loss: 2.990816843223515
Validation loss: 2.487861601906358

Epoch: 5| Step: 1
Training loss: 2.635078609531766
Validation loss: 2.489289491196707

Epoch: 5| Step: 2
Training loss: 2.772759067137076
Validation loss: 2.4895717202930587

Epoch: 5| Step: 3
Training loss: 2.197009208128588
Validation loss: 2.485340302747241

Epoch: 5| Step: 4
Training loss: 2.2488614486549814
Validation loss: 2.4919029838764586

Epoch: 5| Step: 5
Training loss: 2.4310033246499745
Validation loss: 2.490153958885912

Epoch: 5| Step: 6
Training loss: 3.0444900960198873
Validation loss: 2.4888359860763494

Epoch: 5| Step: 7
Training loss: 2.6380171680079783
Validation loss: 2.493771805823268

Epoch: 5| Step: 8
Training loss: 2.83868426510128
Validation loss: 2.4878067410542997

Epoch: 5| Step: 9
Training loss: 2.2587871625721583
Validation loss: 2.4946639334220055

Epoch: 5| Step: 10
Training loss: 2.497517115751009
Validation loss: 2.488661261444939

Epoch: 5| Step: 11
Training loss: 1.7202225359296155
Validation loss: 2.4826918964610667

Epoch: 102| Step: 0
Training loss: 3.259864947324119
Validation loss: 2.4883068249085305

Epoch: 5| Step: 1
Training loss: 2.5010610236250703
Validation loss: 2.4850876423842196

Epoch: 5| Step: 2
Training loss: 2.4724780556348125
Validation loss: 2.4861043832878513

Epoch: 5| Step: 3
Training loss: 2.918244089722398
Validation loss: 2.4856090199960237

Epoch: 5| Step: 4
Training loss: 2.3497568085822755
Validation loss: 2.4855718748602063

Epoch: 5| Step: 5
Training loss: 2.3309045366911705
Validation loss: 2.48499091329007

Epoch: 5| Step: 6
Training loss: 2.36331998935191
Validation loss: 2.486656628742702

Epoch: 5| Step: 7
Training loss: 2.6314644914130745
Validation loss: 2.4810098413338593

Epoch: 5| Step: 8
Training loss: 2.5481745674901886
Validation loss: 2.485116675968306

Epoch: 5| Step: 9
Training loss: 2.4893642206746383
Validation loss: 2.4850200999129535

Epoch: 5| Step: 10
Training loss: 2.640494258736406
Validation loss: 2.486749438049431

Epoch: 5| Step: 11
Training loss: 2.1556583643294718
Validation loss: 2.4799470167563316

Epoch: 103| Step: 0
Training loss: 3.1335518361733463
Validation loss: 2.4740870084259763

Epoch: 5| Step: 1
Training loss: 2.664624644285585
Validation loss: 2.4718814537906106

Epoch: 5| Step: 2
Training loss: 2.841391790823638
Validation loss: 2.4803956989735183

Epoch: 5| Step: 3
Training loss: 2.575524885883492
Validation loss: 2.480010323201762

Epoch: 5| Step: 4
Training loss: 2.3163099092001884
Validation loss: 2.479234884162344

Epoch: 5| Step: 5
Training loss: 2.7768852188021924
Validation loss: 2.481566222897065

Epoch: 5| Step: 6
Training loss: 2.1830313680005418
Validation loss: 2.48585111922324

Epoch: 5| Step: 7
Training loss: 2.638117666372134
Validation loss: 2.485191522927764

Epoch: 5| Step: 8
Training loss: 2.6442790735274273
Validation loss: 2.478799449480634

Epoch: 5| Step: 9
Training loss: 2.4109047789216693
Validation loss: 2.484459749611641

Epoch: 5| Step: 10
Training loss: 2.325595685061089
Validation loss: 2.4859799293335465

Epoch: 5| Step: 11
Training loss: 2.0275488365679304
Validation loss: 2.4857224742860753

Epoch: 104| Step: 0
Training loss: 2.334642338285949
Validation loss: 2.4859885687850403

Epoch: 5| Step: 1
Training loss: 2.8922330765144566
Validation loss: 2.4858378016510243

Epoch: 5| Step: 2
Training loss: 2.145833160499146
Validation loss: 2.4826141090905174

Epoch: 5| Step: 3
Training loss: 2.9676662675512424
Validation loss: 2.481087574899366

Epoch: 5| Step: 4
Training loss: 2.5131127744205126
Validation loss: 2.484998952537894

Epoch: 5| Step: 5
Training loss: 2.6851161764005336
Validation loss: 2.478949366323892

Epoch: 5| Step: 6
Training loss: 2.4805908173089493
Validation loss: 2.485942362155791

Epoch: 5| Step: 7
Training loss: 2.501394264525599
Validation loss: 2.4854049546977572

Epoch: 5| Step: 8
Training loss: 2.9356167214536573
Validation loss: 2.482416496601176

Epoch: 5| Step: 9
Training loss: 2.383891177305112
Validation loss: 2.4823482651580506

Epoch: 5| Step: 10
Training loss: 2.592699964383878
Validation loss: 2.485982047240715

Epoch: 5| Step: 11
Training loss: 2.3279980106410805
Validation loss: 2.4858389765574893

Epoch: 105| Step: 0
Training loss: 2.2318153925883384
Validation loss: 2.484470735460743

Epoch: 5| Step: 1
Training loss: 2.375234190788371
Validation loss: 2.4868888971746226

Epoch: 5| Step: 2
Training loss: 2.867338005086355
Validation loss: 2.4836585333303636

Epoch: 5| Step: 3
Training loss: 2.121372605008032
Validation loss: 2.4823095985071193

Epoch: 5| Step: 4
Training loss: 2.4795358420364404
Validation loss: 2.484179970945477

Epoch: 5| Step: 5
Training loss: 2.7749801428831877
Validation loss: 2.4822008068015067

Epoch: 5| Step: 6
Training loss: 2.4606125389987015
Validation loss: 2.4750871124414258

Epoch: 5| Step: 7
Training loss: 3.185848182073526
Validation loss: 2.4822878357450437

Epoch: 5| Step: 8
Training loss: 2.5159901419114417
Validation loss: 2.4747354765859995

Epoch: 5| Step: 9
Training loss: 2.84010517328579
Validation loss: 2.4777215116847437

Epoch: 5| Step: 10
Training loss: 2.4783327532701085
Validation loss: 2.4751099579721685

Epoch: 5| Step: 11
Training loss: 2.4041403898481306
Validation loss: 2.474792812887822

Epoch: 106| Step: 0
Training loss: 2.2546614996348766
Validation loss: 2.4743940685758283

Epoch: 5| Step: 1
Training loss: 3.087060805986957
Validation loss: 2.473920220867854

Epoch: 5| Step: 2
Training loss: 2.492493039717373
Validation loss: 2.473515401976168

Epoch: 5| Step: 3
Training loss: 2.4556006313327514
Validation loss: 2.480925306219831

Epoch: 5| Step: 4
Training loss: 2.7407127827382056
Validation loss: 2.4816496193349176

Epoch: 5| Step: 5
Training loss: 2.797724078138339
Validation loss: 2.4849775371393354

Epoch: 5| Step: 6
Training loss: 2.55946225866447
Validation loss: 2.4732656626835055

Epoch: 5| Step: 7
Training loss: 2.4002847423123046
Validation loss: 2.476178509519336

Epoch: 5| Step: 8
Training loss: 2.592268003348435
Validation loss: 2.4806362986609676

Epoch: 5| Step: 9
Training loss: 2.078624923347271
Validation loss: 2.47957099828364

Epoch: 5| Step: 10
Training loss: 2.9406497382685193
Validation loss: 2.4851575334776084

Epoch: 5| Step: 11
Training loss: 2.7840114985590283
Validation loss: 2.4814297073716283

Epoch: 107| Step: 0
Training loss: 2.545377513413485
Validation loss: 2.4818943402572597

Epoch: 5| Step: 1
Training loss: 2.8324369994898566
Validation loss: 2.4860826897076933

Epoch: 5| Step: 2
Training loss: 2.7460749966020392
Validation loss: 2.496239078372399

Epoch: 5| Step: 3
Training loss: 2.4882952391801623
Validation loss: 2.4917717829085415

Epoch: 5| Step: 4
Training loss: 2.395428288815829
Validation loss: 2.4845736402196383

Epoch: 5| Step: 5
Training loss: 2.525125322914358
Validation loss: 2.485389965987268

Epoch: 5| Step: 6
Training loss: 2.7199398374916264
Validation loss: 2.4744452843861877

Epoch: 5| Step: 7
Training loss: 2.415180823781122
Validation loss: 2.48337459615268

Epoch: 5| Step: 8
Training loss: 2.677993639436309
Validation loss: 2.4753701862769404

Epoch: 5| Step: 9
Training loss: 2.6127085150777
Validation loss: 2.4792477543710336

Epoch: 5| Step: 10
Training loss: 2.4967883461440366
Validation loss: 2.476863305308664

Epoch: 5| Step: 11
Training loss: 3.3758340440791907
Validation loss: 2.473081792178105

Epoch: 108| Step: 0
Training loss: 2.5382536083816856
Validation loss: 2.47438308415799

Epoch: 5| Step: 1
Training loss: 2.6970930769392867
Validation loss: 2.4710022354506957

Epoch: 5| Step: 2
Training loss: 2.939536666950289
Validation loss: 2.4722848485724755

Epoch: 5| Step: 3
Training loss: 2.804131582946628
Validation loss: 2.4717120898577214

Epoch: 5| Step: 4
Training loss: 2.341096520390743
Validation loss: 2.4705076278520384

Epoch: 5| Step: 5
Training loss: 2.2081054234008057
Validation loss: 2.4721902626153

Epoch: 5| Step: 6
Training loss: 2.176737001849265
Validation loss: 2.4671317643644004

Epoch: 5| Step: 7
Training loss: 2.951729904120613
Validation loss: 2.4672679516763503

Epoch: 5| Step: 8
Training loss: 2.8105796191738337
Validation loss: 2.47326910891995

Epoch: 5| Step: 9
Training loss: 2.5627324999028573
Validation loss: 2.4660640361933956

Epoch: 5| Step: 10
Training loss: 2.3599236463059654
Validation loss: 2.476922713997782

Epoch: 5| Step: 11
Training loss: 2.3502776732652197
Validation loss: 2.47039980025337

Epoch: 109| Step: 0
Training loss: 2.0254923280878105
Validation loss: 2.473169656157082

Epoch: 5| Step: 1
Training loss: 2.3254602530442807
Validation loss: 2.469942167199652

Epoch: 5| Step: 2
Training loss: 2.726527522608743
Validation loss: 2.489389505116629

Epoch: 5| Step: 3
Training loss: 2.5814687603854414
Validation loss: 2.507825611749679

Epoch: 5| Step: 4
Training loss: 2.4757336694702112
Validation loss: 2.51277768765676

Epoch: 5| Step: 5
Training loss: 2.967061415851477
Validation loss: 2.5020669538505467

Epoch: 5| Step: 6
Training loss: 2.247738867637841
Validation loss: 2.5036538126271903

Epoch: 5| Step: 7
Training loss: 2.58834735798603
Validation loss: 2.5040814461914285

Epoch: 5| Step: 8
Training loss: 3.111829392833897
Validation loss: 2.4961230057905754

Epoch: 5| Step: 9
Training loss: 2.7376589863913003
Validation loss: 2.4945410534221737

Epoch: 5| Step: 10
Training loss: 2.6633015102288375
Validation loss: 2.4953654365442284

Epoch: 5| Step: 11
Training loss: 3.9360314915645542
Validation loss: 2.4684652413747834

Epoch: 110| Step: 0
Training loss: 2.6229443448408913
Validation loss: 2.487716614734153

Epoch: 5| Step: 1
Training loss: 2.46884946984885
Validation loss: 2.475463932399215

Epoch: 5| Step: 2
Training loss: 2.497069835103347
Validation loss: 2.468144539737771

Epoch: 5| Step: 3
Training loss: 2.323803673873822
Validation loss: 2.4860612117180496

Epoch: 5| Step: 4
Training loss: 2.6436780626686835
Validation loss: 2.474344060173955

Epoch: 5| Step: 5
Training loss: 3.051730937381663
Validation loss: 2.4778684387871954

Epoch: 5| Step: 6
Training loss: 2.178728008673595
Validation loss: 2.4693202997764656

Epoch: 5| Step: 7
Training loss: 2.5519180451928904
Validation loss: 2.4742039381217644

Epoch: 5| Step: 8
Training loss: 2.319358346931214
Validation loss: 2.4780087464986162

Epoch: 5| Step: 9
Training loss: 2.735797359552677
Validation loss: 2.4701435747162637

Epoch: 5| Step: 10
Training loss: 2.8793438148010404
Validation loss: 2.468432546880189

Epoch: 5| Step: 11
Training loss: 3.2167667834525298
Validation loss: 2.474372717970409

Epoch: 111| Step: 0
Training loss: 2.5360117263883843
Validation loss: 2.4679642525414875

Epoch: 5| Step: 1
Training loss: 2.478615472464286
Validation loss: 2.4669655052330497

Epoch: 5| Step: 2
Training loss: 2.3280264814384757
Validation loss: 2.4695257304088774

Epoch: 5| Step: 3
Training loss: 2.395610124445789
Validation loss: 2.474005812473788

Epoch: 5| Step: 4
Training loss: 2.756447775874865
Validation loss: 2.4719562433574227

Epoch: 5| Step: 5
Training loss: 2.865567531862246
Validation loss: 2.466296070897592

Epoch: 5| Step: 6
Training loss: 2.859947605853565
Validation loss: 2.475325707797404

Epoch: 5| Step: 7
Training loss: 2.5361659033507347
Validation loss: 2.468910159778736

Epoch: 5| Step: 8
Training loss: 2.246471605445363
Validation loss: 2.4699179787730507

Epoch: 5| Step: 9
Training loss: 2.6406745680270514
Validation loss: 2.47354859957873

Epoch: 5| Step: 10
Training loss: 2.7052147345356397
Validation loss: 2.4726080786827316

Epoch: 5| Step: 11
Training loss: 2.796773727544124
Validation loss: 2.480953481574429

Epoch: 112| Step: 0
Training loss: 2.351094652445601
Validation loss: 2.4745197836924655

Epoch: 5| Step: 1
Training loss: 2.3184900801337207
Validation loss: 2.473991009680465

Epoch: 5| Step: 2
Training loss: 2.260269570435433
Validation loss: 2.467808612371021

Epoch: 5| Step: 3
Training loss: 2.232252166251414
Validation loss: 2.4713621846193914

Epoch: 5| Step: 4
Training loss: 2.619286267855905
Validation loss: 2.473392467365962

Epoch: 5| Step: 5
Training loss: 3.2174190991833873
Validation loss: 2.46850690771541

Epoch: 5| Step: 6
Training loss: 2.574015908939783
Validation loss: 2.467440998534047

Epoch: 5| Step: 7
Training loss: 2.5393429645279904
Validation loss: 2.469053281995301

Epoch: 5| Step: 8
Training loss: 2.7998898416375555
Validation loss: 2.4737090992449735

Epoch: 5| Step: 9
Training loss: 2.7203392557737915
Validation loss: 2.466306893964821

Epoch: 5| Step: 10
Training loss: 2.447872101939481
Validation loss: 2.465140045300383

Epoch: 5| Step: 11
Training loss: 3.2129666119433753
Validation loss: 2.467822387515774

Epoch: 113| Step: 0
Training loss: 2.282003722372538
Validation loss: 2.4690354298920347

Epoch: 5| Step: 1
Training loss: 2.5640072925303237
Validation loss: 2.4752871642188463

Epoch: 5| Step: 2
Training loss: 2.539475815217908
Validation loss: 2.4755229713713756

Epoch: 5| Step: 3
Training loss: 3.3228970868880108
Validation loss: 2.4787345490941535

Epoch: 5| Step: 4
Training loss: 2.203971321473232
Validation loss: 2.4789127385434955

Epoch: 5| Step: 5
Training loss: 2.5615252059598834
Validation loss: 2.473877001312234

Epoch: 5| Step: 6
Training loss: 2.6198974244225384
Validation loss: 2.4747030214867527

Epoch: 5| Step: 7
Training loss: 2.5906426993986003
Validation loss: 2.4801992675495934

Epoch: 5| Step: 8
Training loss: 2.276451812964748
Validation loss: 2.4780345797628858

Epoch: 5| Step: 9
Training loss: 2.8413152647095816
Validation loss: 2.475581362868678

Epoch: 5| Step: 10
Training loss: 2.146469046734965
Validation loss: 2.4795542275138187

Epoch: 5| Step: 11
Training loss: 3.2872461663363852
Validation loss: 2.4762826956038375

Epoch: 114| Step: 0
Training loss: 2.6872974585571696
Validation loss: 2.4773758436145394

Epoch: 5| Step: 1
Training loss: 2.690846776738692
Validation loss: 2.4773897219486294

Epoch: 5| Step: 2
Training loss: 2.5438024791955884
Validation loss: 2.4764166306659128

Epoch: 5| Step: 3
Training loss: 2.4889509177236504
Validation loss: 2.4712062439029934

Epoch: 5| Step: 4
Training loss: 2.6689265530007567
Validation loss: 2.4749830245389526

Epoch: 5| Step: 5
Training loss: 2.65182062982029
Validation loss: 2.471075136024334

Epoch: 5| Step: 6
Training loss: 2.014845349835178
Validation loss: 2.4702797548334363

Epoch: 5| Step: 7
Training loss: 2.9165516058615046
Validation loss: 2.467785324875168

Epoch: 5| Step: 8
Training loss: 2.4737053885733418
Validation loss: 2.4701019560920736

Epoch: 5| Step: 9
Training loss: 2.807338980781469
Validation loss: 2.468909282616073

Epoch: 5| Step: 10
Training loss: 2.268194911506878
Validation loss: 2.4644573450871157

Epoch: 5| Step: 11
Training loss: 1.8313639061820715
Validation loss: 2.463775225825836

Epoch: 115| Step: 0
Training loss: 2.476618528484418
Validation loss: 2.4692602515555464

Epoch: 5| Step: 1
Training loss: 2.918173173844621
Validation loss: 2.4644546685340196

Epoch: 5| Step: 2
Training loss: 2.558806758487775
Validation loss: 2.4676860134156122

Epoch: 5| Step: 3
Training loss: 2.0775277563047267
Validation loss: 2.464655220571982

Epoch: 5| Step: 4
Training loss: 2.623941662291091
Validation loss: 2.4734906139281803

Epoch: 5| Step: 5
Training loss: 2.491653145930967
Validation loss: 2.4669166106993026

Epoch: 5| Step: 6
Training loss: 2.4623958081505326
Validation loss: 2.468317682101564

Epoch: 5| Step: 7
Training loss: 2.561934245853731
Validation loss: 2.4620001784277323

Epoch: 5| Step: 8
Training loss: 2.687302249464017
Validation loss: 2.4623718885154258

Epoch: 5| Step: 9
Training loss: 2.5952754303399423
Validation loss: 2.470753070391812

Epoch: 5| Step: 10
Training loss: 2.4148972928970913
Validation loss: 2.4679117952726264

Epoch: 5| Step: 11
Training loss: 3.8003826500825335
Validation loss: 2.4685382430284952

Epoch: 116| Step: 0
Training loss: 1.8818636834277211
Validation loss: 2.4645876864805714

Epoch: 5| Step: 1
Training loss: 2.5141344096898584
Validation loss: 2.474614364912045

Epoch: 5| Step: 2
Training loss: 2.7747846743235924
Validation loss: 2.4789507448643593

Epoch: 5| Step: 3
Training loss: 2.711064404422281
Validation loss: 2.4780675043569333

Epoch: 5| Step: 4
Training loss: 2.5069359884592055
Validation loss: 2.4848609624966667

Epoch: 5| Step: 5
Training loss: 2.644411521015681
Validation loss: 2.4817389532538723

Epoch: 5| Step: 6
Training loss: 2.5099018460721734
Validation loss: 2.484460641276546

Epoch: 5| Step: 7
Training loss: 2.7317148402281584
Validation loss: 2.476645752062055

Epoch: 5| Step: 8
Training loss: 2.927924111232266
Validation loss: 2.4754979867253457

Epoch: 5| Step: 9
Training loss: 2.842718587101808
Validation loss: 2.477389481354075

Epoch: 5| Step: 10
Training loss: 2.1378710776016874
Validation loss: 2.4797883670052845

Epoch: 5| Step: 11
Training loss: 2.2626942588069405
Validation loss: 2.4744169606524977

Epoch: 117| Step: 0
Training loss: 2.494700919288077
Validation loss: 2.474435809721848

Epoch: 5| Step: 1
Training loss: 2.4655789640550396
Validation loss: 2.4696281134935627

Epoch: 5| Step: 2
Training loss: 2.770626308958027
Validation loss: 2.4628628016530554

Epoch: 5| Step: 3
Training loss: 2.7060789164322663
Validation loss: 2.4680260872487434

Epoch: 5| Step: 4
Training loss: 2.957101395252486
Validation loss: 2.4715666255867457

Epoch: 5| Step: 5
Training loss: 2.3469535804322192
Validation loss: 2.46721709420685

Epoch: 5| Step: 6
Training loss: 2.3960497772191856
Validation loss: 2.4699489201284655

Epoch: 5| Step: 7
Training loss: 2.5324827418440656
Validation loss: 2.4611308632427105

Epoch: 5| Step: 8
Training loss: 2.926986710841772
Validation loss: 2.4628575055817055

Epoch: 5| Step: 9
Training loss: 2.634761010032328
Validation loss: 2.470527306936507

Epoch: 5| Step: 10
Training loss: 2.1895016912404577
Validation loss: 2.464456301070516

Epoch: 5| Step: 11
Training loss: 1.0927332921021748
Validation loss: 2.4676744113864824

Epoch: 118| Step: 0
Training loss: 2.2049796231943715
Validation loss: 2.4661874750818353

Epoch: 5| Step: 1
Training loss: 2.341912732030338
Validation loss: 2.4673745552906605

Epoch: 5| Step: 2
Training loss: 2.736527473109668
Validation loss: 2.4688834987229695

Epoch: 5| Step: 3
Training loss: 3.539456175072491
Validation loss: 2.472428848231535

Epoch: 5| Step: 4
Training loss: 2.6312608079846873
Validation loss: 2.4706352656799573

Epoch: 5| Step: 5
Training loss: 2.8237162416018253
Validation loss: 2.468995802348264

Epoch: 5| Step: 6
Training loss: 2.542697686956158
Validation loss: 2.4716463864204634

Epoch: 5| Step: 7
Training loss: 2.283778004842597
Validation loss: 2.4721467596554874

Epoch: 5| Step: 8
Training loss: 2.6654127172842657
Validation loss: 2.474945041579337

Epoch: 5| Step: 9
Training loss: 1.901258405758386
Validation loss: 2.4666595219388365

Epoch: 5| Step: 10
Training loss: 2.2026592871647788
Validation loss: 2.4661612236619592

Epoch: 5| Step: 11
Training loss: 2.311792007528311
Validation loss: 2.462215184750333

Epoch: 119| Step: 0
Training loss: 2.4590071600599943
Validation loss: 2.4612350606908926

Epoch: 5| Step: 1
Training loss: 2.447688888882538
Validation loss: 2.4664663987976105

Epoch: 5| Step: 2
Training loss: 2.4896547847267976
Validation loss: 2.4581859384143354

Epoch: 5| Step: 3
Training loss: 2.4584753889861766
Validation loss: 2.465302659895669

Epoch: 5| Step: 4
Training loss: 2.60526742686399
Validation loss: 2.458091692982954

Epoch: 5| Step: 5
Training loss: 2.8559905487352952
Validation loss: 2.4606684300500667

Epoch: 5| Step: 6
Training loss: 2.260796287993335
Validation loss: 2.4660165236562235

Epoch: 5| Step: 7
Training loss: 2.2005970838228404
Validation loss: 2.4713310619811084

Epoch: 5| Step: 8
Training loss: 3.010589665036666
Validation loss: 2.468690304094782

Epoch: 5| Step: 9
Training loss: 2.5157990958112335
Validation loss: 2.467304651669156

Epoch: 5| Step: 10
Training loss: 2.683223604442609
Validation loss: 2.4645264386542634

Epoch: 5| Step: 11
Training loss: 2.913278919238475
Validation loss: 2.470024403665172

Epoch: 120| Step: 0
Training loss: 2.217482943807934
Validation loss: 2.4616796878034695

Epoch: 5| Step: 1
Training loss: 2.427429032707607
Validation loss: 2.4654376910883427

Epoch: 5| Step: 2
Training loss: 3.0819484762431193
Validation loss: 2.464247077667969

Epoch: 5| Step: 3
Training loss: 2.222918288835996
Validation loss: 2.4626388158899744

Epoch: 5| Step: 4
Training loss: 2.999337123115804
Validation loss: 2.4666363564983143

Epoch: 5| Step: 5
Training loss: 2.293154135493216
Validation loss: 2.4586317654412078

Epoch: 5| Step: 6
Training loss: 2.414503631285723
Validation loss: 2.4547715259904095

Epoch: 5| Step: 7
Training loss: 3.024118588246633
Validation loss: 2.4594477832175907

Epoch: 5| Step: 8
Training loss: 2.5805137895978087
Validation loss: 2.454749114398257

Epoch: 5| Step: 9
Training loss: 2.4847328360183796
Validation loss: 2.4634602770489735

Epoch: 5| Step: 10
Training loss: 2.211685647181132
Validation loss: 2.463548645482787

Epoch: 5| Step: 11
Training loss: 2.3061561172522325
Validation loss: 2.462262088801216

Epoch: 121| Step: 0
Training loss: 2.397005032390457
Validation loss: 2.4586666710933565

Epoch: 5| Step: 1
Training loss: 2.7476098337339305
Validation loss: 2.465278234541467

Epoch: 5| Step: 2
Training loss: 2.154568887589726
Validation loss: 2.462878213841595

Epoch: 5| Step: 3
Training loss: 2.552991391518196
Validation loss: 2.4693740868733682

Epoch: 5| Step: 4
Training loss: 3.0101390213402786
Validation loss: 2.472489289587446

Epoch: 5| Step: 5
Training loss: 2.345841555357957
Validation loss: 2.4725405086931334

Epoch: 5| Step: 6
Training loss: 2.15860398656328
Validation loss: 2.4668171313720926

Epoch: 5| Step: 7
Training loss: 2.735895224723356
Validation loss: 2.469442877937633

Epoch: 5| Step: 8
Training loss: 2.7095851548296452
Validation loss: 2.472088471883164

Epoch: 5| Step: 9
Training loss: 2.848177136163129
Validation loss: 2.4689496398232813

Epoch: 5| Step: 10
Training loss: 2.361319340767625
Validation loss: 2.468737376860848

Epoch: 5| Step: 11
Training loss: 2.3220691132556412
Validation loss: 2.4731733937413543

Epoch: 122| Step: 0
Training loss: 2.3143511399603227
Validation loss: 2.4706536168703197

Epoch: 5| Step: 1
Training loss: 2.371069315701171
Validation loss: 2.4704955806686217

Epoch: 5| Step: 2
Training loss: 2.51436986472762
Validation loss: 2.4626275047301256

Epoch: 5| Step: 3
Training loss: 2.458422438305173
Validation loss: 2.475847255299999

Epoch: 5| Step: 4
Training loss: 2.4784012475763557
Validation loss: 2.4680966466384535

Epoch: 5| Step: 5
Training loss: 2.224037532304452
Validation loss: 2.475653051185157

Epoch: 5| Step: 6
Training loss: 2.4369696015601474
Validation loss: 2.476121203298298

Epoch: 5| Step: 7
Training loss: 2.5046159092695848
Validation loss: 2.475700011625327

Epoch: 5| Step: 8
Training loss: 3.607248579901267
Validation loss: 2.472860053704458

Epoch: 5| Step: 9
Training loss: 2.5226005370839126
Validation loss: 2.4676936823188713

Epoch: 5| Step: 10
Training loss: 2.6428911766600383
Validation loss: 2.4725329592854077

Epoch: 5| Step: 11
Training loss: 1.5709231883016117
Validation loss: 2.474616456416836

Epoch: 123| Step: 0
Training loss: 2.734227552525663
Validation loss: 2.4722176715782753

Epoch: 5| Step: 1
Training loss: 2.169586952381792
Validation loss: 2.472009390398047

Epoch: 5| Step: 2
Training loss: 2.3729799614408678
Validation loss: 2.4684083195135216

Epoch: 5| Step: 3
Training loss: 2.6808719074990743
Validation loss: 2.465485764775633

Epoch: 5| Step: 4
Training loss: 2.846983192975755
Validation loss: 2.4622400661382633

Epoch: 5| Step: 5
Training loss: 2.2262033273215716
Validation loss: 2.4721825192569713

Epoch: 5| Step: 6
Training loss: 2.4855821663645545
Validation loss: 2.4686835316269007

Epoch: 5| Step: 7
Training loss: 2.5916885088851633
Validation loss: 2.466822720973916

Epoch: 5| Step: 8
Training loss: 2.374280921094416
Validation loss: 2.465128793975581

Epoch: 5| Step: 9
Training loss: 2.8328058275332513
Validation loss: 2.4668598564687634

Epoch: 5| Step: 10
Training loss: 2.787881638612785
Validation loss: 2.4546580657068393

Epoch: 5| Step: 11
Training loss: 2.2429509474772975
Validation loss: 2.4658870635109573

Epoch: 124| Step: 0
Training loss: 2.8348046764655477
Validation loss: 2.465184401294405

Epoch: 5| Step: 1
Training loss: 2.5218186042464255
Validation loss: 2.4617407481910476

Epoch: 5| Step: 2
Training loss: 2.1509195313097322
Validation loss: 2.4718809032088376

Epoch: 5| Step: 3
Training loss: 2.478261659565326
Validation loss: 2.4665431528699195

Epoch: 5| Step: 4
Training loss: 2.17626827138103
Validation loss: 2.4593992198961674

Epoch: 5| Step: 5
Training loss: 2.615658350359321
Validation loss: 2.4615701699784123

Epoch: 5| Step: 6
Training loss: 2.8429740433985655
Validation loss: 2.4649522357488833

Epoch: 5| Step: 7
Training loss: 2.499267089223632
Validation loss: 2.459935887678518

Epoch: 5| Step: 8
Training loss: 2.4458340707113875
Validation loss: 2.4625121634323324

Epoch: 5| Step: 9
Training loss: 2.3543579113904407
Validation loss: 2.462586249214286

Epoch: 5| Step: 10
Training loss: 2.8069826049156976
Validation loss: 2.4660762963701237

Epoch: 5| Step: 11
Training loss: 3.6629075952986825
Validation loss: 2.4641806934354373

Epoch: 125| Step: 0
Training loss: 1.9011261664296755
Validation loss: 2.465375702812983

Epoch: 5| Step: 1
Training loss: 2.925199850705066
Validation loss: 2.465082780680902

Epoch: 5| Step: 2
Training loss: 2.61823062890364
Validation loss: 2.4643049422001653

Epoch: 5| Step: 3
Training loss: 2.4383022259778913
Validation loss: 2.4623130143201983

Epoch: 5| Step: 4
Training loss: 2.2053062516932482
Validation loss: 2.463075135287768

Epoch: 5| Step: 5
Training loss: 2.8427553218892045
Validation loss: 2.459631222986726

Epoch: 5| Step: 6
Training loss: 2.9844636754148315
Validation loss: 2.462671922113838

Epoch: 5| Step: 7
Training loss: 2.802231161952181
Validation loss: 2.461086345389653

Epoch: 5| Step: 8
Training loss: 2.808368021206516
Validation loss: 2.466556935081969

Epoch: 5| Step: 9
Training loss: 2.1338880572717014
Validation loss: 2.461097155039388

Epoch: 5| Step: 10
Training loss: 2.022693158369563
Validation loss: 2.461286142670574

Epoch: 5| Step: 11
Training loss: 3.1068810664294024
Validation loss: 2.454217189782575

Epoch: 126| Step: 0
Training loss: 2.576955356570913
Validation loss: 2.462322519493534

Epoch: 5| Step: 1
Training loss: 2.6140501433614576
Validation loss: 2.455419431201831

Epoch: 5| Step: 2
Training loss: 2.9853138670134034
Validation loss: 2.464319647975929

Epoch: 5| Step: 3
Training loss: 2.2251246042400705
Validation loss: 2.4625443354518946

Epoch: 5| Step: 4
Training loss: 2.390327085993347
Validation loss: 2.456316991188531

Epoch: 5| Step: 5
Training loss: 2.4238548799893214
Validation loss: 2.4580627645423077

Epoch: 5| Step: 6
Training loss: 2.501767677980392
Validation loss: 2.45042592485436

Epoch: 5| Step: 7
Training loss: 2.571759683241645
Validation loss: 2.460859355997764

Epoch: 5| Step: 8
Training loss: 2.991932193232555
Validation loss: 2.458570765220278

Epoch: 5| Step: 9
Training loss: 2.576336419415815
Validation loss: 2.4538931605700323

Epoch: 5| Step: 10
Training loss: 2.1513801536221275
Validation loss: 2.45805344699009

Epoch: 5| Step: 11
Training loss: 1.9792727257938176
Validation loss: 2.464661298750973

Epoch: 127| Step: 0
Training loss: 3.1568388436829258
Validation loss: 2.4599470900645204

Epoch: 5| Step: 1
Training loss: 2.528283346943946
Validation loss: 2.4629907872531978

Epoch: 5| Step: 2
Training loss: 2.2342860064089956
Validation loss: 2.472242894306503

Epoch: 5| Step: 3
Training loss: 2.8606736199495897
Validation loss: 2.45478679877834

Epoch: 5| Step: 4
Training loss: 2.6185575173226767
Validation loss: 2.463990915855572

Epoch: 5| Step: 5
Training loss: 2.031652205334654
Validation loss: 2.4675082170001144

Epoch: 5| Step: 6
Training loss: 2.384372688182345
Validation loss: 2.469884205477177

Epoch: 5| Step: 7
Training loss: 2.6191688439358836
Validation loss: 2.4716576502779795

Epoch: 5| Step: 8
Training loss: 2.6037468431941697
Validation loss: 2.4687570096974714

Epoch: 5| Step: 9
Training loss: 2.369614971126989
Validation loss: 2.4772514163249437

Epoch: 5| Step: 10
Training loss: 2.3061273764495125
Validation loss: 2.474821447424518

Epoch: 5| Step: 11
Training loss: 3.0589537037254493
Validation loss: 2.471806633828124

Epoch: 128| Step: 0
Training loss: 2.277321764674645
Validation loss: 2.4715832737054346

Epoch: 5| Step: 1
Training loss: 2.32797619644921
Validation loss: 2.4724538879993148

Epoch: 5| Step: 2
Training loss: 3.075886333473686
Validation loss: 2.466914077757259

Epoch: 5| Step: 3
Training loss: 1.7383403639439394
Validation loss: 2.4747840881895287

Epoch: 5| Step: 4
Training loss: 2.308943823592374
Validation loss: 2.479961958248614

Epoch: 5| Step: 5
Training loss: 2.724645514573268
Validation loss: 2.482824949629827

Epoch: 5| Step: 6
Training loss: 2.1858976762701054
Validation loss: 2.483465880071856

Epoch: 5| Step: 7
Training loss: 2.8450039624553636
Validation loss: 2.483202831681747

Epoch: 5| Step: 8
Training loss: 2.996335811858263
Validation loss: 2.481850082770632

Epoch: 5| Step: 9
Training loss: 2.4606603072745803
Validation loss: 2.478148877901521

Epoch: 5| Step: 10
Training loss: 2.606597335686921
Validation loss: 2.4802572485596723

Epoch: 5| Step: 11
Training loss: 3.4838031932546154
Validation loss: 2.472773271456241

Epoch: 129| Step: 0
Training loss: 2.8071828808110024
Validation loss: 2.4792518934992933

Epoch: 5| Step: 1
Training loss: 2.7742060926100827
Validation loss: 2.4743912261215026

Epoch: 5| Step: 2
Training loss: 2.3414361340229317
Validation loss: 2.4774317775177668

Epoch: 5| Step: 3
Training loss: 2.914980173714218
Validation loss: 2.502991075143716

Epoch: 5| Step: 4
Training loss: 2.4490230792427363
Validation loss: 2.534753247220685

Epoch: 5| Step: 5
Training loss: 2.802232523258982
Validation loss: 2.5500418587907894

Epoch: 5| Step: 6
Training loss: 2.1602434413206866
Validation loss: 2.572977340744749

Epoch: 5| Step: 7
Training loss: 2.945099921611966
Validation loss: 2.581235027038892

Epoch: 5| Step: 8
Training loss: 2.619604014254407
Validation loss: 2.593800421688124

Epoch: 5| Step: 9
Training loss: 2.7004569232162785
Validation loss: 2.573385247458779

Epoch: 5| Step: 10
Training loss: 2.8346956755097903
Validation loss: 2.5651115391555925

Epoch: 5| Step: 11
Training loss: 2.178787647300679
Validation loss: 2.5418667532120556

Epoch: 130| Step: 0
Training loss: 2.3140515457914046
Validation loss: 2.53368247464269

Epoch: 5| Step: 1
Training loss: 2.31976949072797
Validation loss: 2.511272270106421

Epoch: 5| Step: 2
Training loss: 2.6964676744987504
Validation loss: 2.5104983199098183

Epoch: 5| Step: 3
Training loss: 2.605989647172109
Validation loss: 2.507680816203631

Epoch: 5| Step: 4
Training loss: 3.29439838549485
Validation loss: 2.5055633512788247

Epoch: 5| Step: 5
Training loss: 2.545946665820283
Validation loss: 2.494366302277533

Epoch: 5| Step: 6
Training loss: 2.7274201801204416
Validation loss: 2.4955247042340196

Epoch: 5| Step: 7
Training loss: 2.855293404222119
Validation loss: 2.491682673140266

Epoch: 5| Step: 8
Training loss: 2.3264049346016202
Validation loss: 2.482188900415649

Epoch: 5| Step: 9
Training loss: 2.6839244033582417
Validation loss: 2.483150132246747

Epoch: 5| Step: 10
Training loss: 2.376771767937602
Validation loss: 2.4810516913957796

Epoch: 5| Step: 11
Training loss: 2.393017936298185
Validation loss: 2.4730597272808197

Epoch: 131| Step: 0
Training loss: 2.7544497122779825
Validation loss: 2.4673182927341215

Epoch: 5| Step: 1
Training loss: 2.772144972804298
Validation loss: 2.4682651719730417

Epoch: 5| Step: 2
Training loss: 2.7827805154751872
Validation loss: 2.464449722546478

Epoch: 5| Step: 3
Training loss: 2.298533146033158
Validation loss: 2.4655138889187924

Epoch: 5| Step: 4
Training loss: 2.4900946843479312
Validation loss: 2.460072313841124

Epoch: 5| Step: 5
Training loss: 3.070263112377119
Validation loss: 2.4622492710180484

Epoch: 5| Step: 6
Training loss: 2.2988257395975835
Validation loss: 2.4634156057083367

Epoch: 5| Step: 7
Training loss: 2.9982952996627086
Validation loss: 2.4637309089758372

Epoch: 5| Step: 8
Training loss: 2.5718513682358535
Validation loss: 2.463439920487054

Epoch: 5| Step: 9
Training loss: 2.082078199590838
Validation loss: 2.4575420792690554

Epoch: 5| Step: 10
Training loss: 2.129816990901774
Validation loss: 2.457886159495958

Epoch: 5| Step: 11
Training loss: 2.0700752554219743
Validation loss: 2.4513921023219596

Epoch: 132| Step: 0
Training loss: 2.621931189570351
Validation loss: 2.453906107014633

Epoch: 5| Step: 1
Training loss: 2.306342096738361
Validation loss: 2.4570687295696305

Epoch: 5| Step: 2
Training loss: 2.8571663753359022
Validation loss: 2.456670717473704

Epoch: 5| Step: 3
Training loss: 2.509380860280264
Validation loss: 2.454925868235236

Epoch: 5| Step: 4
Training loss: 2.6465205904463955
Validation loss: 2.460961554677153

Epoch: 5| Step: 5
Training loss: 2.3051384953329843
Validation loss: 2.4548825186306047

Epoch: 5| Step: 6
Training loss: 2.7163833314391237
Validation loss: 2.454506592343895

Epoch: 5| Step: 7
Training loss: 2.60190797636901
Validation loss: 2.452673504013267

Epoch: 5| Step: 8
Training loss: 2.59500643161572
Validation loss: 2.452274442327107

Epoch: 5| Step: 9
Training loss: 2.7987359531556097
Validation loss: 2.4482217368636285

Epoch: 5| Step: 10
Training loss: 2.183850213618984
Validation loss: 2.4488582234194403

Epoch: 5| Step: 11
Training loss: 2.0208063287667595
Validation loss: 2.4526982229790124

Epoch: 133| Step: 0
Training loss: 2.7162788824239037
Validation loss: 2.4492915100614514

Epoch: 5| Step: 1
Training loss: 2.9962379391029224
Validation loss: 2.4529113717008784

Epoch: 5| Step: 2
Training loss: 2.6509276080124033
Validation loss: 2.4521581015832554

Epoch: 5| Step: 3
Training loss: 2.9224688084669785
Validation loss: 2.45653744472448

Epoch: 5| Step: 4
Training loss: 2.3806706041538335
Validation loss: 2.4565723558716774

Epoch: 5| Step: 5
Training loss: 2.428370471461774
Validation loss: 2.4576129598711804

Epoch: 5| Step: 6
Training loss: 2.202494754330367
Validation loss: 2.4499418255004106

Epoch: 5| Step: 7
Training loss: 2.521334595667649
Validation loss: 2.451064428884956

Epoch: 5| Step: 8
Training loss: 2.673219398328375
Validation loss: 2.448923862841538

Epoch: 5| Step: 9
Training loss: 2.2026520349895606
Validation loss: 2.4458322267242822

Epoch: 5| Step: 10
Training loss: 2.4204002566401597
Validation loss: 2.452546685280305

Epoch: 5| Step: 11
Training loss: 1.592098652136087
Validation loss: 2.4476725652747353

Epoch: 134| Step: 0
Training loss: 3.1693143985275216
Validation loss: 2.450843637077915

Epoch: 5| Step: 1
Training loss: 2.1141179767555816
Validation loss: 2.4484692754673714

Epoch: 5| Step: 2
Training loss: 2.2164757046390946
Validation loss: 2.454063750204816

Epoch: 5| Step: 3
Training loss: 2.5165890570120024
Validation loss: 2.461209515267207

Epoch: 5| Step: 4
Training loss: 2.5412154709195978
Validation loss: 2.4587360788981356

Epoch: 5| Step: 5
Training loss: 2.4956338903592155
Validation loss: 2.4557002859079264

Epoch: 5| Step: 6
Training loss: 2.9471811695777164
Validation loss: 2.4481674282334134

Epoch: 5| Step: 7
Training loss: 2.493078473150196
Validation loss: 2.4474401977494837

Epoch: 5| Step: 8
Training loss: 2.611742692906676
Validation loss: 2.4508213030617036

Epoch: 5| Step: 9
Training loss: 2.5061811328282784
Validation loss: 2.451944719241116

Epoch: 5| Step: 10
Training loss: 2.411035806922403
Validation loss: 2.45549028002623

Epoch: 5| Step: 11
Training loss: 2.0967479138585112
Validation loss: 2.4561477592938834

Epoch: 135| Step: 0
Training loss: 2.9141333522825024
Validation loss: 2.45526549019611

Epoch: 5| Step: 1
Training loss: 2.348763558600871
Validation loss: 2.454523469497873

Epoch: 5| Step: 2
Training loss: 2.7953237994985427
Validation loss: 2.455104167175962

Epoch: 5| Step: 3
Training loss: 2.168220354206309
Validation loss: 2.4517223697465695

Epoch: 5| Step: 4
Training loss: 2.526533937499199
Validation loss: 2.4539818532770727

Epoch: 5| Step: 5
Training loss: 2.216339628813744
Validation loss: 2.4460005762042876

Epoch: 5| Step: 6
Training loss: 2.5296130126391625
Validation loss: 2.450928849005551

Epoch: 5| Step: 7
Training loss: 2.6240248912584363
Validation loss: 2.4516954893660676

Epoch: 5| Step: 8
Training loss: 2.5092754909599844
Validation loss: 2.453437825725532

Epoch: 5| Step: 9
Training loss: 2.95458544590701
Validation loss: 2.447753788554703

Epoch: 5| Step: 10
Training loss: 2.4371331745837645
Validation loss: 2.447911069065485

Epoch: 5| Step: 11
Training loss: 1.9568965050762368
Validation loss: 2.4459830838315346

Epoch: 136| Step: 0
Training loss: 2.7956310041718337
Validation loss: 2.4493784834647254

Epoch: 5| Step: 1
Training loss: 2.8215257565831746
Validation loss: 2.4509012566838697

Epoch: 5| Step: 2
Training loss: 2.2621826328647328
Validation loss: 2.4657825429308793

Epoch: 5| Step: 3
Training loss: 1.9552704281126951
Validation loss: 2.4693435647505684

Epoch: 5| Step: 4
Training loss: 2.99525266775629
Validation loss: 2.470862707882281

Epoch: 5| Step: 5
Training loss: 2.828567723138317
Validation loss: 2.489405016451969

Epoch: 5| Step: 6
Training loss: 2.7306741137899735
Validation loss: 2.4967140537377506

Epoch: 5| Step: 7
Training loss: 2.1904945585021744
Validation loss: 2.4913144630326207

Epoch: 5| Step: 8
Training loss: 2.5254618080769258
Validation loss: 2.4974168386096416

Epoch: 5| Step: 9
Training loss: 2.684396770775367
Validation loss: 2.4805607275542845

Epoch: 5| Step: 10
Training loss: 2.2840836575314074
Validation loss: 2.4667572276034435

Epoch: 5| Step: 11
Training loss: 3.3408137468877315
Validation loss: 2.459410796335141

Epoch: 137| Step: 0
Training loss: 2.0760462409806633
Validation loss: 2.459772465961748

Epoch: 5| Step: 1
Training loss: 2.4944505133079478
Validation loss: 2.4547797613290396

Epoch: 5| Step: 2
Training loss: 3.071957989306091
Validation loss: 2.4619450681318495

Epoch: 5| Step: 3
Training loss: 2.514311832750578
Validation loss: 2.4617474065912703

Epoch: 5| Step: 4
Training loss: 2.891897220563303
Validation loss: 2.4669810850781366

Epoch: 5| Step: 5
Training loss: 2.414661024641372
Validation loss: 2.468498607503235

Epoch: 5| Step: 6
Training loss: 2.747701724893358
Validation loss: 2.4745461110350897

Epoch: 5| Step: 7
Training loss: 2.0893219768837925
Validation loss: 2.4742276670847114

Epoch: 5| Step: 8
Training loss: 2.625855351917374
Validation loss: 2.4748494775192302

Epoch: 5| Step: 9
Training loss: 2.921677037025003
Validation loss: 2.484424514596976

Epoch: 5| Step: 10
Training loss: 2.472612281155281
Validation loss: 2.479977760881775

Epoch: 5| Step: 11
Training loss: 2.779600275653557
Validation loss: 2.4790517409050423

Epoch: 138| Step: 0
Training loss: 2.359552945127656
Validation loss: 2.484345851783182

Epoch: 5| Step: 1
Training loss: 2.208827869055157
Validation loss: 2.4819061880170246

Epoch: 5| Step: 2
Training loss: 2.580084963146218
Validation loss: 2.4779611442755964

Epoch: 5| Step: 3
Training loss: 2.6755055529159497
Validation loss: 2.4713063706069502

Epoch: 5| Step: 4
Training loss: 2.5964916400741784
Validation loss: 2.472077280312869

Epoch: 5| Step: 5
Training loss: 3.0021939202791246
Validation loss: 2.472589693785771

Epoch: 5| Step: 6
Training loss: 2.0531387584114973
Validation loss: 2.467971196042087

Epoch: 5| Step: 7
Training loss: 2.948860116336103
Validation loss: 2.4691614379552798

Epoch: 5| Step: 8
Training loss: 2.9008740982249543
Validation loss: 2.4661338198945564

Epoch: 5| Step: 9
Training loss: 2.553656507097988
Validation loss: 2.46842487222349

Epoch: 5| Step: 10
Training loss: 2.4705514250612293
Validation loss: 2.4743877774331278

Epoch: 5| Step: 11
Training loss: 1.9896220724385432
Validation loss: 2.4688544834738124

Epoch: 139| Step: 0
Training loss: 2.4428273207932376
Validation loss: 2.4685820610934575

Epoch: 5| Step: 1
Training loss: 2.6097249236156896
Validation loss: 2.4614119723249916

Epoch: 5| Step: 2
Training loss: 2.554650449338313
Validation loss: 2.4644494000693578

Epoch: 5| Step: 3
Training loss: 2.4810485642772093
Validation loss: 2.4690156866110646

Epoch: 5| Step: 4
Training loss: 2.50519127684647
Validation loss: 2.4660044988450394

Epoch: 5| Step: 5
Training loss: 2.4829089559516517
Validation loss: 2.466377337397753

Epoch: 5| Step: 6
Training loss: 2.483071038989414
Validation loss: 2.467434138089295

Epoch: 5| Step: 7
Training loss: 2.5866947045068405
Validation loss: 2.467924577608127

Epoch: 5| Step: 8
Training loss: 2.3682627234602887
Validation loss: 2.4584905054205044

Epoch: 5| Step: 9
Training loss: 2.509098471943008
Validation loss: 2.460366983232379

Epoch: 5| Step: 10
Training loss: 2.7318017677226005
Validation loss: 2.4622379520168107

Epoch: 5| Step: 11
Training loss: 3.0359171695391716
Validation loss: 2.4616298004515795

Epoch: 140| Step: 0
Training loss: 2.5800453201276046
Validation loss: 2.467204543754038

Epoch: 5| Step: 1
Training loss: 2.8514812301133032
Validation loss: 2.464137089385922

Epoch: 5| Step: 2
Training loss: 2.8087264282975895
Validation loss: 2.4658368503532153

Epoch: 5| Step: 3
Training loss: 2.3801725177588353
Validation loss: 2.471408607571986

Epoch: 5| Step: 4
Training loss: 2.724345445326042
Validation loss: 2.468439879434986

Epoch: 5| Step: 5
Training loss: 2.6427015457597434
Validation loss: 2.4695945413844775

Epoch: 5| Step: 6
Training loss: 2.4299454628746644
Validation loss: 2.4639585409768836

Epoch: 5| Step: 7
Training loss: 2.6353379088282542
Validation loss: 2.4671072463869748

Epoch: 5| Step: 8
Training loss: 1.7913881869097918
Validation loss: 2.463544449727353

Epoch: 5| Step: 9
Training loss: 2.5835121051910046
Validation loss: 2.4653820935119732

Epoch: 5| Step: 10
Training loss: 2.521112179637085
Validation loss: 2.4543167548169094

Epoch: 5| Step: 11
Training loss: 1.9996290458938255
Validation loss: 2.461565448229254

Epoch: 141| Step: 0
Training loss: 2.2895618714242763
Validation loss: 2.459330551831565

Epoch: 5| Step: 1
Training loss: 2.5757226096719146
Validation loss: 2.4580044984447844

Epoch: 5| Step: 2
Training loss: 2.5906279744498155
Validation loss: 2.457892545417999

Epoch: 5| Step: 3
Training loss: 3.023760953254936
Validation loss: 2.455537015180612

Epoch: 5| Step: 4
Training loss: 2.8009283434177563
Validation loss: 2.4517362069092394

Epoch: 5| Step: 5
Training loss: 2.6982615384247746
Validation loss: 2.4502371618093277

Epoch: 5| Step: 6
Training loss: 2.165105905563492
Validation loss: 2.4592988669322557

Epoch: 5| Step: 7
Training loss: 2.3971477606996188
Validation loss: 2.4537877364000975

Epoch: 5| Step: 8
Training loss: 2.313921826379926
Validation loss: 2.4599145488900693

Epoch: 5| Step: 9
Training loss: 2.6723494080668355
Validation loss: 2.453212400365637

Epoch: 5| Step: 10
Training loss: 2.357654676975977
Validation loss: 2.452324118955394

Epoch: 5| Step: 11
Training loss: 1.4171987917953883
Validation loss: 2.459683978017202

Epoch: 142| Step: 0
Training loss: 2.2695001544233775
Validation loss: 2.4549936316939123

Epoch: 5| Step: 1
Training loss: 2.2471505241550798
Validation loss: 2.4516963078565293

Epoch: 5| Step: 2
Training loss: 2.6416394694599954
Validation loss: 2.44756348003194

Epoch: 5| Step: 3
Training loss: 2.6098831504300963
Validation loss: 2.4472773176940397

Epoch: 5| Step: 4
Training loss: 2.491253046855987
Validation loss: 2.454919753812286

Epoch: 5| Step: 5
Training loss: 2.655644785429594
Validation loss: 2.454489419619427

Epoch: 5| Step: 6
Training loss: 2.376618686992471
Validation loss: 2.4547205512599772

Epoch: 5| Step: 7
Training loss: 2.2581687566982294
Validation loss: 2.45207100597471

Epoch: 5| Step: 8
Training loss: 2.3365623633504686
Validation loss: 2.4568520234465843

Epoch: 5| Step: 9
Training loss: 2.898271992937161
Validation loss: 2.4484424770347646

Epoch: 5| Step: 10
Training loss: 3.1854748744066517
Validation loss: 2.4501528340308085

Epoch: 5| Step: 11
Training loss: 1.2887219528269076
Validation loss: 2.4508225190750847

Epoch: 143| Step: 0
Training loss: 1.957913258997367
Validation loss: 2.4514248863029073

Epoch: 5| Step: 1
Training loss: 2.360470953033989
Validation loss: 2.4512158353189357

Epoch: 5| Step: 2
Training loss: 2.609141996111285
Validation loss: 2.4589311969189134

Epoch: 5| Step: 3
Training loss: 2.585113025164423
Validation loss: 2.4494121177062738

Epoch: 5| Step: 4
Training loss: 2.550060877353803
Validation loss: 2.4552898735475597

Epoch: 5| Step: 5
Training loss: 2.568926869635577
Validation loss: 2.4521450345020694

Epoch: 5| Step: 6
Training loss: 2.646128320144343
Validation loss: 2.4573287541166033

Epoch: 5| Step: 7
Training loss: 2.4780003558413393
Validation loss: 2.462081602862784

Epoch: 5| Step: 8
Training loss: 2.8621882372997947
Validation loss: 2.4502248771123454

Epoch: 5| Step: 9
Training loss: 2.855845122575057
Validation loss: 2.465755497549561

Epoch: 5| Step: 10
Training loss: 2.2630371046340985
Validation loss: 2.469261003877142

Epoch: 5| Step: 11
Training loss: 2.3839922876553308
Validation loss: 2.465133162332713

Epoch: 144| Step: 0
Training loss: 2.6795697867560655
Validation loss: 2.4688288619728604

Epoch: 5| Step: 1
Training loss: 2.744666997308953
Validation loss: 2.466806975017056

Epoch: 5| Step: 2
Training loss: 2.617848600330143
Validation loss: 2.460515544179343

Epoch: 5| Step: 3
Training loss: 2.5905538882813457
Validation loss: 2.465906988955932

Epoch: 5| Step: 4
Training loss: 2.1186160515048136
Validation loss: 2.4674474523270438

Epoch: 5| Step: 5
Training loss: 2.434847439915705
Validation loss: 2.468068910156062

Epoch: 5| Step: 6
Training loss: 2.4412207937373536
Validation loss: 2.4681224951011305

Epoch: 5| Step: 7
Training loss: 2.8890419414112696
Validation loss: 2.4627534130817446

Epoch: 5| Step: 8
Training loss: 2.5145804564536727
Validation loss: 2.4684272748322695

Epoch: 5| Step: 9
Training loss: 2.668510058156228
Validation loss: 2.471547019087812

Epoch: 5| Step: 10
Training loss: 2.328227200921097
Validation loss: 2.467857428850982

Epoch: 5| Step: 11
Training loss: 1.1940540345966848
Validation loss: 2.4622639991575834

Epoch: 145| Step: 0
Training loss: 2.433698183516129
Validation loss: 2.4620406932713865

Epoch: 5| Step: 1
Training loss: 2.763508304567595
Validation loss: 2.451174938914295

Epoch: 5| Step: 2
Training loss: 2.5391370556962585
Validation loss: 2.455826157036341

Epoch: 5| Step: 3
Training loss: 2.581277110994222
Validation loss: 2.4571778698927806

Epoch: 5| Step: 4
Training loss: 2.7911078809542635
Validation loss: 2.4586945217230154

Epoch: 5| Step: 5
Training loss: 2.446896755857444
Validation loss: 2.4560413640838297

Epoch: 5| Step: 6
Training loss: 2.7583127527151037
Validation loss: 2.459974942351088

Epoch: 5| Step: 7
Training loss: 2.518933318403057
Validation loss: 2.457755470786384

Epoch: 5| Step: 8
Training loss: 2.4639514692469
Validation loss: 2.451951748621349

Epoch: 5| Step: 9
Training loss: 2.289585092929746
Validation loss: 2.46806144769705

Epoch: 5| Step: 10
Training loss: 2.1538882382441944
Validation loss: 2.461329183743238

Epoch: 5| Step: 11
Training loss: 2.1893662257648945
Validation loss: 2.4627870300431924

Epoch: 146| Step: 0
Training loss: 2.363891321049759
Validation loss: 2.453278457798422

Epoch: 5| Step: 1
Training loss: 2.14499402220989
Validation loss: 2.457269767177443

Epoch: 5| Step: 2
Training loss: 2.6162187747759615
Validation loss: 2.453845017657083

Epoch: 5| Step: 3
Training loss: 2.5291638667066514
Validation loss: 2.460536379139981

Epoch: 5| Step: 4
Training loss: 2.1291324600288806
Validation loss: 2.4563602527920314

Epoch: 5| Step: 5
Training loss: 2.5361742700031336
Validation loss: 2.45123128831651

Epoch: 5| Step: 6
Training loss: 2.856001234177181
Validation loss: 2.4578683515776083

Epoch: 5| Step: 7
Training loss: 2.690312710138455
Validation loss: 2.4698493940047133

Epoch: 5| Step: 8
Training loss: 2.0255467088935935
Validation loss: 2.461103984711459

Epoch: 5| Step: 9
Training loss: 2.902798972491003
Validation loss: 2.4625696895310427

Epoch: 5| Step: 10
Training loss: 2.854521587793342
Validation loss: 2.4595372914332425

Epoch: 5| Step: 11
Training loss: 2.079049155890414
Validation loss: 2.4573220797008717

Epoch: 147| Step: 0
Training loss: 2.8655407409593994
Validation loss: 2.4496057114441685

Epoch: 5| Step: 1
Training loss: 2.731676786759696
Validation loss: 2.466436074299815

Epoch: 5| Step: 2
Training loss: 2.652994921475585
Validation loss: 2.4607223335944957

Epoch: 5| Step: 3
Training loss: 2.6410857932828438
Validation loss: 2.4569025132294824

Epoch: 5| Step: 4
Training loss: 2.6719803817222982
Validation loss: 2.4675452676992653

Epoch: 5| Step: 5
Training loss: 2.4531335526821447
Validation loss: 2.4582479806943005

Epoch: 5| Step: 6
Training loss: 1.765982397585764
Validation loss: 2.461413794550572

Epoch: 5| Step: 7
Training loss: 2.203540735722128
Validation loss: 2.462394254934528

Epoch: 5| Step: 8
Training loss: 2.54730726446999
Validation loss: 2.461378952072272

Epoch: 5| Step: 9
Training loss: 2.516810735995608
Validation loss: 2.4609599077122932

Epoch: 5| Step: 10
Training loss: 2.5809168639895557
Validation loss: 2.458765005477371

Epoch: 5| Step: 11
Training loss: 2.167846456291737
Validation loss: 2.456190910631623

Epoch: 148| Step: 0
Training loss: 2.3244774426017885
Validation loss: 2.464537438787327

Epoch: 5| Step: 1
Training loss: 3.0363621028528716
Validation loss: 2.471549635708287

Epoch: 5| Step: 2
Training loss: 2.7158733364115406
Validation loss: 2.468564682455428

Epoch: 5| Step: 3
Training loss: 2.7362871731968594
Validation loss: 2.474074593204831

Epoch: 5| Step: 4
Training loss: 2.5550391278938096
Validation loss: 2.4770049011886295

Epoch: 5| Step: 5
Training loss: 2.284253794824455
Validation loss: 2.4800330032118953

Epoch: 5| Step: 6
Training loss: 2.3714587262217615
Validation loss: 2.468093100604317

Epoch: 5| Step: 7
Training loss: 1.8542107423265644
Validation loss: 2.4642847699900017

Epoch: 5| Step: 8
Training loss: 2.370132075303468
Validation loss: 2.4631584822476182

Epoch: 5| Step: 9
Training loss: 2.7022623438620705
Validation loss: 2.4660552000466294

Epoch: 5| Step: 10
Training loss: 2.7053666714901095
Validation loss: 2.463238495176299

Epoch: 5| Step: 11
Training loss: 2.6692514310302213
Validation loss: 2.457779047326683

Epoch: 149| Step: 0
Training loss: 2.883468429252368
Validation loss: 2.466471074915573

Epoch: 5| Step: 1
Training loss: 2.5731456412746905
Validation loss: 2.454246624991713

Epoch: 5| Step: 2
Training loss: 2.065014549000914
Validation loss: 2.461238459193068

Epoch: 5| Step: 3
Training loss: 2.5151049153341374
Validation loss: 2.472476354064217

Epoch: 5| Step: 4
Training loss: 1.9684016812716372
Validation loss: 2.464993753921818

Epoch: 5| Step: 5
Training loss: 1.787428730430847
Validation loss: 2.457289503764168

Epoch: 5| Step: 6
Training loss: 2.775050851854286
Validation loss: 2.4599696844838164

Epoch: 5| Step: 7
Training loss: 2.710195654249701
Validation loss: 2.463207316274619

Epoch: 5| Step: 8
Training loss: 2.856791345226517
Validation loss: 2.4627399040487403

Epoch: 5| Step: 9
Training loss: 2.2067633272111937
Validation loss: 2.4655512012642897

Epoch: 5| Step: 10
Training loss: 3.015708171112621
Validation loss: 2.45992186645155

Epoch: 5| Step: 11
Training loss: 1.9889498862296309
Validation loss: 2.4680505598725255

Epoch: 150| Step: 0
Training loss: 2.7971818638398416
Validation loss: 2.4679000131651754

Epoch: 5| Step: 1
Training loss: 2.809680797325797
Validation loss: 2.4716871671690317

Epoch: 5| Step: 2
Training loss: 2.5552484205677946
Validation loss: 2.479085361258773

Epoch: 5| Step: 3
Training loss: 3.0651899707660477
Validation loss: 2.462485598507513

Epoch: 5| Step: 4
Training loss: 2.243624555646064
Validation loss: 2.472085301278267

Epoch: 5| Step: 5
Training loss: 2.512075253543925
Validation loss: 2.4656877619302193

Epoch: 5| Step: 6
Training loss: 2.0775166244851584
Validation loss: 2.4602568033165215

Epoch: 5| Step: 7
Training loss: 2.5083045357944695
Validation loss: 2.4642282252437635

Epoch: 5| Step: 8
Training loss: 2.227753972946082
Validation loss: 2.4625610808721814

Epoch: 5| Step: 9
Training loss: 2.268494360947237
Validation loss: 2.4675127180274816

Epoch: 5| Step: 10
Training loss: 2.5240298305266093
Validation loss: 2.461577070980121

Epoch: 5| Step: 11
Training loss: 3.015292134468726
Validation loss: 2.464805090873617

Epoch: 151| Step: 0
Training loss: 2.733850919363417
Validation loss: 2.4746090980053923

Epoch: 5| Step: 1
Training loss: 2.4685802159897254
Validation loss: 2.466515435166455

Epoch: 5| Step: 2
Training loss: 2.425596466643646
Validation loss: 2.4688756242812158

Epoch: 5| Step: 3
Training loss: 3.1372428636693925
Validation loss: 2.4653924209432327

Epoch: 5| Step: 4
Training loss: 2.497613530752711
Validation loss: 2.4742051065075

Epoch: 5| Step: 5
Training loss: 2.404265340788836
Validation loss: 2.4647027936109227

Epoch: 5| Step: 6
Training loss: 2.4431074151289196
Validation loss: 2.4766818839098144

Epoch: 5| Step: 7
Training loss: 2.513555492916936
Validation loss: 2.474425443755152

Epoch: 5| Step: 8
Training loss: 2.610805827301428
Validation loss: 2.4665466024576883

Epoch: 5| Step: 9
Training loss: 2.2399624407548515
Validation loss: 2.4672412084524042

Epoch: 5| Step: 10
Training loss: 2.3187544501331327
Validation loss: 2.4608071630769777

Epoch: 5| Step: 11
Training loss: 1.2544987309686255
Validation loss: 2.464473222953016

Epoch: 152| Step: 0
Training loss: 2.2722863497878363
Validation loss: 2.4705526514684166

Epoch: 5| Step: 1
Training loss: 2.8107602142525687
Validation loss: 2.470297690437027

Epoch: 5| Step: 2
Training loss: 2.3348180838057924
Validation loss: 2.465412785559969

Epoch: 5| Step: 3
Training loss: 2.3077651342491414
Validation loss: 2.473079295677211

Epoch: 5| Step: 4
Training loss: 2.5132620002310584
Validation loss: 2.4652110378801058

Epoch: 5| Step: 5
Training loss: 2.6292092317338724
Validation loss: 2.4676773541686385

Epoch: 5| Step: 6
Training loss: 2.5462098920656806
Validation loss: 2.465425997891501

Epoch: 5| Step: 7
Training loss: 2.7553257090920473
Validation loss: 2.4660867095165506

Epoch: 5| Step: 8
Training loss: 2.3708173160201866
Validation loss: 2.458195708080939

Epoch: 5| Step: 9
Training loss: 2.4736158488610993
Validation loss: 2.457131618760395

Epoch: 5| Step: 10
Training loss: 2.7669718420859004
Validation loss: 2.46749423074998

Epoch: 5| Step: 11
Training loss: 2.8561553338387644
Validation loss: 2.463446384762167

Epoch: 153| Step: 0
Training loss: 2.42965668784472
Validation loss: 2.4675429286462616

Epoch: 5| Step: 1
Training loss: 2.831720585061809
Validation loss: 2.4713175978264674

Epoch: 5| Step: 2
Training loss: 2.8149327247399736
Validation loss: 2.4620124285792504

Epoch: 5| Step: 3
Training loss: 2.4620042214686677
Validation loss: 2.4666299126653355

Epoch: 5| Step: 4
Training loss: 2.3485006378478333
Validation loss: 2.472641135797816

Epoch: 5| Step: 5
Training loss: 2.356070724669265
Validation loss: 2.467294525505157

Epoch: 5| Step: 6
Training loss: 2.677229039918669
Validation loss: 2.4627942099922873

Epoch: 5| Step: 7
Training loss: 2.6273548825856454
Validation loss: 2.464675284954718

Epoch: 5| Step: 8
Training loss: 2.5126280377155523
Validation loss: 2.463367977565471

Epoch: 5| Step: 9
Training loss: 2.4283199079880324
Validation loss: 2.464039773701178

Epoch: 5| Step: 10
Training loss: 1.9515325539385786
Validation loss: 2.4726595002243914

Epoch: 5| Step: 11
Training loss: 2.201327517269376
Validation loss: 2.4613180078281283

Epoch: 154| Step: 0
Training loss: 2.5809168639895557
Validation loss: 2.467078971287688

Epoch: 5| Step: 1
Training loss: 2.558660561657504
Validation loss: 2.4709444433278516

Epoch: 5| Step: 2
Training loss: 2.795494548739756
Validation loss: 2.4665141906415124

Epoch: 5| Step: 3
Training loss: 2.7344191193427263
Validation loss: 2.463467652631815

Epoch: 5| Step: 4
Training loss: 2.4312787012597843
Validation loss: 2.4675969920087026

Epoch: 5| Step: 5
Training loss: 2.314797162589125
Validation loss: 2.4586346948036772

Epoch: 5| Step: 6
Training loss: 2.268300022868204
Validation loss: 2.4709768352253807

Epoch: 5| Step: 7
Training loss: 3.3620722388699327
Validation loss: 2.458348631137729

Epoch: 5| Step: 8
Training loss: 2.4757678565123182
Validation loss: 2.46002232726233

Epoch: 5| Step: 9
Training loss: 2.03353014394771
Validation loss: 2.4672645373212325

Epoch: 5| Step: 10
Training loss: 2.169043911853015
Validation loss: 2.4579976116620954

Epoch: 5| Step: 11
Training loss: 1.4702985189261635
Validation loss: 2.4538741132220205

Epoch: 155| Step: 0
Training loss: 2.9580560115440075
Validation loss: 2.4655540438370864

Epoch: 5| Step: 1
Training loss: 2.3578837146963014
Validation loss: 2.4562708168668363

Epoch: 5| Step: 2
Training loss: 2.3641716911075177
Validation loss: 2.464108905181908

Epoch: 5| Step: 3
Training loss: 2.08799316611213
Validation loss: 2.4647984447638085

Epoch: 5| Step: 4
Training loss: 2.3197713407103624
Validation loss: 2.4695492911230414

Epoch: 5| Step: 5
Training loss: 2.637830621326984
Validation loss: 2.468894362755699

Epoch: 5| Step: 6
Training loss: 2.6561589842518054
Validation loss: 2.4621827058293153

Epoch: 5| Step: 7
Training loss: 2.418263751693331
Validation loss: 2.4610288532396813

Epoch: 5| Step: 8
Training loss: 2.3818874877506238
Validation loss: 2.471078054655845

Epoch: 5| Step: 9
Training loss: 2.514886309289373
Validation loss: 2.455609215847236

Epoch: 5| Step: 10
Training loss: 2.463519869836322
Validation loss: 2.471661599147186

Epoch: 5| Step: 11
Training loss: 3.5656368432613075
Validation loss: 2.4671001071764516

Epoch: 156| Step: 0
Training loss: 2.5685968209512904
Validation loss: 2.4710913070488143

Epoch: 5| Step: 1
Training loss: 2.333055536445482
Validation loss: 2.4682385924954144

Epoch: 5| Step: 2
Training loss: 2.5406983725074994
Validation loss: 2.4696702770990746

Epoch: 5| Step: 3
Training loss: 2.1807600547753774
Validation loss: 2.4692762634844168

Epoch: 5| Step: 4
Training loss: 2.447825155509143
Validation loss: 2.475884181208502

Epoch: 5| Step: 5
Training loss: 2.7923805310982495
Validation loss: 2.464898263496719

Epoch: 5| Step: 6
Training loss: 2.342693955606453
Validation loss: 2.4603033267948073

Epoch: 5| Step: 7
Training loss: 3.1022138320052766
Validation loss: 2.469715070616047

Epoch: 5| Step: 8
Training loss: 2.674627392210793
Validation loss: 2.461354957978769

Epoch: 5| Step: 9
Training loss: 2.4369372182780697
Validation loss: 2.4642456425264534

Epoch: 5| Step: 10
Training loss: 1.9252268397453085
Validation loss: 2.465518860976059

Epoch: 5| Step: 11
Training loss: 2.163669812211284
Validation loss: 2.4673789559074013

Epoch: 157| Step: 0
Training loss: 2.336466955701066
Validation loss: 2.464590137168111

Epoch: 5| Step: 1
Training loss: 2.415520977430589
Validation loss: 2.4675279964983194

Epoch: 5| Step: 2
Training loss: 2.4671702098663366
Validation loss: 2.468438812956087

Epoch: 5| Step: 3
Training loss: 2.0460681052856686
Validation loss: 2.4655397322253796

Epoch: 5| Step: 4
Training loss: 2.3892398386690585
Validation loss: 2.4662121874950427

Epoch: 5| Step: 5
Training loss: 2.7142456274012305
Validation loss: 2.464719161619493

Epoch: 5| Step: 6
Training loss: 2.309111922666142
Validation loss: 2.4708924996195107

Epoch: 5| Step: 7
Training loss: 2.965732526688953
Validation loss: 2.4615074426178296

Epoch: 5| Step: 8
Training loss: 2.46098642451988
Validation loss: 2.4693304377482055

Epoch: 5| Step: 9
Training loss: 2.8560554955697928
Validation loss: 2.4607258296943333

Epoch: 5| Step: 10
Training loss: 2.448203915455494
Validation loss: 2.4635380320827993

Epoch: 5| Step: 11
Training loss: 2.106706301561762
Validation loss: 2.455557801358053

Epoch: 158| Step: 0
Training loss: 2.7455024353916895
Validation loss: 2.461177414598253

Epoch: 5| Step: 1
Training loss: 2.3276936176212386
Validation loss: 2.467034677544225

Epoch: 5| Step: 2
Training loss: 2.5563822966200043
Validation loss: 2.4694624568919736

Epoch: 5| Step: 3
Training loss: 2.5914401144460686
Validation loss: 2.4669619575729995

Epoch: 5| Step: 4
Training loss: 2.209199039946787
Validation loss: 2.4715942384118774

Epoch: 5| Step: 5
Training loss: 2.2735205566335983
Validation loss: 2.47523538789866

Epoch: 5| Step: 6
Training loss: 2.712116172108408
Validation loss: 2.4742320755877856

Epoch: 5| Step: 7
Training loss: 2.5349164240977737
Validation loss: 2.478315913994924

Epoch: 5| Step: 8
Training loss: 2.4925798926371847
Validation loss: 2.467147401544638

Epoch: 5| Step: 9
Training loss: 2.631919822700722
Validation loss: 2.4679863348182747

Epoch: 5| Step: 10
Training loss: 2.3725273913780964
Validation loss: 2.4649322300429537

Epoch: 5| Step: 11
Training loss: 1.9903506917908351
Validation loss: 2.4746553757468366

Epoch: 159| Step: 0
Training loss: 1.836011974366311
Validation loss: 2.4712230833855253

Epoch: 5| Step: 1
Training loss: 2.610307264255391
Validation loss: 2.465604591124001

Epoch: 5| Step: 2
Training loss: 2.296068218513684
Validation loss: 2.47102850177503

Epoch: 5| Step: 3
Training loss: 2.4538604217107136
Validation loss: 2.4655683432783158

Epoch: 5| Step: 4
Training loss: 3.0161489713390437
Validation loss: 2.475036732725374

Epoch: 5| Step: 5
Training loss: 2.3273258757889277
Validation loss: 2.472628146830951

Epoch: 5| Step: 6
Training loss: 2.0945112068785274
Validation loss: 2.466788091817579

Epoch: 5| Step: 7
Training loss: 2.77228945759095
Validation loss: 2.4773820590005866

Epoch: 5| Step: 8
Training loss: 2.2913358160535813
Validation loss: 2.464417531059828

Epoch: 5| Step: 9
Training loss: 2.6598037284489338
Validation loss: 2.4587155357496306

Epoch: 5| Step: 10
Training loss: 2.6606557771973973
Validation loss: 2.4618481157249996

Epoch: 5| Step: 11
Training loss: 3.0837020309917076
Validation loss: 2.462502574273844

Epoch: 160| Step: 0
Training loss: 2.098501933593441
Validation loss: 2.4597936202074586

Epoch: 5| Step: 1
Training loss: 2.928850466364114
Validation loss: 2.4663084608284525

Epoch: 5| Step: 2
Training loss: 1.901184668888821
Validation loss: 2.4709772412772533

Epoch: 5| Step: 3
Training loss: 2.1406060656524604
Validation loss: 2.475114645855424

Epoch: 5| Step: 4
Training loss: 2.5897919202310433
Validation loss: 2.4819166388149236

Epoch: 5| Step: 5
Training loss: 2.3221763035413576
Validation loss: 2.473142378248487

Epoch: 5| Step: 6
Training loss: 2.5393654979966493
Validation loss: 2.4700824385114877

Epoch: 5| Step: 7
Training loss: 3.157737003954734
Validation loss: 2.475171168666687

Epoch: 5| Step: 8
Training loss: 2.606007670381724
Validation loss: 2.464299217888722

Epoch: 5| Step: 9
Training loss: 2.784022203351414
Validation loss: 2.4612282798174223

Epoch: 5| Step: 10
Training loss: 2.062035710644376
Validation loss: 2.4668627700199672

Epoch: 5| Step: 11
Training loss: 2.3771840142457314
Validation loss: 2.4626602762929717

Epoch: 161| Step: 0
Training loss: 2.2109644588269166
Validation loss: 2.465714181561161

Epoch: 5| Step: 1
Training loss: 2.6610360504197046
Validation loss: 2.4684399639483887

Epoch: 5| Step: 2
Training loss: 2.1693078106998733
Validation loss: 2.4664325701831986

Epoch: 5| Step: 3
Training loss: 2.577319210013136
Validation loss: 2.4770093849593664

Epoch: 5| Step: 4
Training loss: 2.720098314612177
Validation loss: 2.4821166524421896

Epoch: 5| Step: 5
Training loss: 2.1571782643345525
Validation loss: 2.470170055274174

Epoch: 5| Step: 6
Training loss: 2.674619280380464
Validation loss: 2.486340514993974

Epoch: 5| Step: 7
Training loss: 2.299728800499565
Validation loss: 2.4979361518776497

Epoch: 5| Step: 8
Training loss: 2.716986599515316
Validation loss: 2.499049371542805

Epoch: 5| Step: 9
Training loss: 2.656752774395889
Validation loss: 2.489825996373135

Epoch: 5| Step: 10
Training loss: 2.642598154199317
Validation loss: 2.4836345864844884

Epoch: 5| Step: 11
Training loss: 1.485305976042735
Validation loss: 2.4770919522669432

Epoch: 162| Step: 0
Training loss: 2.8342525636584495
Validation loss: 2.4769384818773994

Epoch: 5| Step: 1
Training loss: 2.4214249715766236
Validation loss: 2.4690340659329277

Epoch: 5| Step: 2
Training loss: 2.6480494752278316
Validation loss: 2.4698291544574387

Epoch: 5| Step: 3
Training loss: 2.16173055995063
Validation loss: 2.4721593452939623

Epoch: 5| Step: 4
Training loss: 2.7980497652853984
Validation loss: 2.470197122699678

Epoch: 5| Step: 5
Training loss: 2.552185700108704
Validation loss: 2.470950325120119

Epoch: 5| Step: 6
Training loss: 2.419494344832009
Validation loss: 2.4665384325855517

Epoch: 5| Step: 7
Training loss: 2.3387407814223424
Validation loss: 2.47201734728575

Epoch: 5| Step: 8
Training loss: 2.5039350058679317
Validation loss: 2.4721477200560837

Epoch: 5| Step: 9
Training loss: 2.4506104818087726
Validation loss: 2.4701075784779807

Epoch: 5| Step: 10
Training loss: 2.1130020041720288
Validation loss: 2.4681143324579518

Epoch: 5| Step: 11
Training loss: 2.479669589366781
Validation loss: 2.4684062831160545

Epoch: 163| Step: 0
Training loss: 3.086405349226885
Validation loss: 2.4722345564090444

Epoch: 5| Step: 1
Training loss: 2.3005014453428223
Validation loss: 2.4649323872197613

Epoch: 5| Step: 2
Training loss: 2.5080124249492766
Validation loss: 2.473016556958825

Epoch: 5| Step: 3
Training loss: 2.3734850820326105
Validation loss: 2.4684136559937757

Epoch: 5| Step: 4
Training loss: 2.6065480343131764
Validation loss: 2.471303305522941

Epoch: 5| Step: 5
Training loss: 2.4462758077235716
Validation loss: 2.465657248566134

Epoch: 5| Step: 6
Training loss: 2.1102729299036374
Validation loss: 2.47719810504423

Epoch: 5| Step: 7
Training loss: 2.100367550246949
Validation loss: 2.4704779641708208

Epoch: 5| Step: 8
Training loss: 2.8001907556133148
Validation loss: 2.4690393708846896

Epoch: 5| Step: 9
Training loss: 2.434004796370558
Validation loss: 2.472311850654226

Epoch: 5| Step: 10
Training loss: 2.417764239066839
Validation loss: 2.4757400093563984

Epoch: 5| Step: 11
Training loss: 2.0179477290329833
Validation loss: 2.47070374620754

Epoch: 164| Step: 0
Training loss: 2.9524186515745083
Validation loss: 2.4725747358677443

Epoch: 5| Step: 1
Training loss: 2.7315332959774974
Validation loss: 2.467420093040643

Epoch: 5| Step: 2
Training loss: 2.413359011764625
Validation loss: 2.4749728334586396

Epoch: 5| Step: 3
Training loss: 1.9352530709702933
Validation loss: 2.463423322183305

Epoch: 5| Step: 4
Training loss: 3.135401086779104
Validation loss: 2.4721567494108116

Epoch: 5| Step: 5
Training loss: 2.877798625652874
Validation loss: 2.4784537273320337

Epoch: 5| Step: 6
Training loss: 2.446535822135392
Validation loss: 2.470877531427203

Epoch: 5| Step: 7
Training loss: 2.3553263303298273
Validation loss: 2.477804917248414

Epoch: 5| Step: 8
Training loss: 1.8957448316883707
Validation loss: 2.4808573701258085

Epoch: 5| Step: 9
Training loss: 2.557703786507613
Validation loss: 2.482957999669643

Epoch: 5| Step: 10
Training loss: 1.5829200037818723
Validation loss: 2.4772721005042064

Epoch: 5| Step: 11
Training loss: 1.619458506708323
Validation loss: 2.4762782626695077

Epoch: 165| Step: 0
Training loss: 2.0709536153552848
Validation loss: 2.495652129378263

Epoch: 5| Step: 1
Training loss: 2.6985773188378075
Validation loss: 2.5124768170667893

Epoch: 5| Step: 2
Training loss: 3.017691107057637
Validation loss: 2.500249500540212

Epoch: 5| Step: 3
Training loss: 2.4519285941313615
Validation loss: 2.504515833057466

Epoch: 5| Step: 4
Training loss: 2.7123375171568007
Validation loss: 2.5075502862638945

Epoch: 5| Step: 5
Training loss: 2.303563558368609
Validation loss: 2.489588423581419

Epoch: 5| Step: 6
Training loss: 2.52243485032968
Validation loss: 2.482169187717476

Epoch: 5| Step: 7
Training loss: 2.2919767921298027
Validation loss: 2.468171595164749

Epoch: 5| Step: 8
Training loss: 2.671744806341201
Validation loss: 2.4735965196487446

Epoch: 5| Step: 9
Training loss: 1.7089069457905945
Validation loss: 2.4722867069841294

Epoch: 5| Step: 10
Training loss: 2.649362318220516
Validation loss: 2.467106855804643

Epoch: 5| Step: 11
Training loss: 2.7700774995173907
Validation loss: 2.471131974345846

Epoch: 166| Step: 0
Training loss: 3.1739408032882905
Validation loss: 2.4679421821428935

Epoch: 5| Step: 1
Training loss: 2.513065623673194
Validation loss: 2.467221664214716

Epoch: 5| Step: 2
Training loss: 3.346654325844959
Validation loss: 2.467083585844675

Epoch: 5| Step: 3
Training loss: 2.615943362459926
Validation loss: 2.478140070814476

Epoch: 5| Step: 4
Training loss: 2.6355203801631606
Validation loss: 2.47906242413242

Epoch: 5| Step: 5
Training loss: 1.9913577277766006
Validation loss: 2.472788183982244

Epoch: 5| Step: 6
Training loss: 2.458849696439658
Validation loss: 2.472920490546887

Epoch: 5| Step: 7
Training loss: 2.3136217644188783
Validation loss: 2.467651823101808

Epoch: 5| Step: 8
Training loss: 1.80435309676594
Validation loss: 2.4755357264455915

Epoch: 5| Step: 9
Training loss: 2.4119130660881414
Validation loss: 2.4821825329771183

Epoch: 5| Step: 10
Training loss: 1.921962829071626
Validation loss: 2.493919324902545

Epoch: 5| Step: 11
Training loss: 2.206322912464851
Validation loss: 2.498160897745342

Epoch: 167| Step: 0
Training loss: 2.512650905651128
Validation loss: 2.5033132056109864

Epoch: 5| Step: 1
Training loss: 2.097698417253957
Validation loss: 2.492955957322316

Epoch: 5| Step: 2
Training loss: 2.745346032655952
Validation loss: 2.470464766794341

Epoch: 5| Step: 3
Training loss: 2.8221650947168877
Validation loss: 2.4732879305881115

Epoch: 5| Step: 4
Training loss: 1.9407747342981774
Validation loss: 2.473903646701251

Epoch: 5| Step: 5
Training loss: 2.40663104322421
Validation loss: 2.469048276820929

Epoch: 5| Step: 6
Training loss: 2.314205056589695
Validation loss: 2.4699114912149542

Epoch: 5| Step: 7
Training loss: 2.216262712694984
Validation loss: 2.4736348887707287

Epoch: 5| Step: 8
Training loss: 2.5393551701816683
Validation loss: 2.4768370005910714

Epoch: 5| Step: 9
Training loss: 2.555477475157548
Validation loss: 2.472634659402204

Epoch: 5| Step: 10
Training loss: 3.0627270049995183
Validation loss: 2.466701083866782

Epoch: 5| Step: 11
Training loss: 2.1605835641998725
Validation loss: 2.4676545968303105

Epoch: 168| Step: 0
Training loss: 2.152574474893865
Validation loss: 2.477708473172418

Epoch: 5| Step: 1
Training loss: 2.3461965380244347
Validation loss: 2.4783220067713523

Epoch: 5| Step: 2
Training loss: 2.3783596770180453
Validation loss: 2.464744670668051

Epoch: 5| Step: 3
Training loss: 2.69856203429113
Validation loss: 2.478046670471893

Epoch: 5| Step: 4
Training loss: 2.476873624975962
Validation loss: 2.4706968887913825

Epoch: 5| Step: 5
Training loss: 2.441098613430175
Validation loss: 2.4673986398143017

Epoch: 5| Step: 6
Training loss: 2.5769071534690764
Validation loss: 2.4696859122848056

Epoch: 5| Step: 7
Training loss: 2.5324272902991423
Validation loss: 2.475566864441802

Epoch: 5| Step: 8
Training loss: 2.4557448083589097
Validation loss: 2.462347561173082

Epoch: 5| Step: 9
Training loss: 2.7156531574997533
Validation loss: 2.4651044333918755

Epoch: 5| Step: 10
Training loss: 2.4491959712233204
Validation loss: 2.477667232210911

Epoch: 5| Step: 11
Training loss: 2.4121334924148563
Validation loss: 2.4872184451902477

Epoch: 169| Step: 0
Training loss: 2.9005190220422628
Validation loss: 2.490613661660073

Epoch: 5| Step: 1
Training loss: 2.0398310239782798
Validation loss: 2.4914298824299146

Epoch: 5| Step: 2
Training loss: 2.3064165256825158
Validation loss: 2.4916612394352455

Epoch: 5| Step: 3
Training loss: 2.5415291879296102
Validation loss: 2.502508617459963

Epoch: 5| Step: 4
Training loss: 2.960658399970506
Validation loss: 2.4886316624609286

Epoch: 5| Step: 5
Training loss: 2.4160110855985044
Validation loss: 2.487069388279288

Epoch: 5| Step: 6
Training loss: 2.7543084466388428
Validation loss: 2.491509858643892

Epoch: 5| Step: 7
Training loss: 2.70881380563182
Validation loss: 2.4868573516784487

Epoch: 5| Step: 8
Training loss: 1.7252735833199428
Validation loss: 2.4752312460673296

Epoch: 5| Step: 9
Training loss: 2.0311929548029437
Validation loss: 2.4746417309683815

Epoch: 5| Step: 10
Training loss: 2.5446410884229587
Validation loss: 2.4799182270909585

Epoch: 5| Step: 11
Training loss: 2.7254178942901297
Validation loss: 2.477217779101617

Epoch: 170| Step: 0
Training loss: 2.1007220207765327
Validation loss: 2.480307642392972

Epoch: 5| Step: 1
Training loss: 1.972786111617413
Validation loss: 2.4722419781437237

Epoch: 5| Step: 2
Training loss: 2.6420709386884855
Validation loss: 2.4798279382573636

Epoch: 5| Step: 3
Training loss: 2.024761459052511
Validation loss: 2.471981183426679

Epoch: 5| Step: 4
Training loss: 2.3341031734606617
Validation loss: 2.4721708700178224

Epoch: 5| Step: 5
Training loss: 2.5531316563345565
Validation loss: 2.4769554969572902

Epoch: 5| Step: 6
Training loss: 3.0321150656332674
Validation loss: 2.481646452939487

Epoch: 5| Step: 7
Training loss: 2.7608025527038094
Validation loss: 2.4827842697993736

Epoch: 5| Step: 8
Training loss: 2.524522105400691
Validation loss: 2.4825372676606685

Epoch: 5| Step: 9
Training loss: 2.892785826650011
Validation loss: 2.487904165251762

Epoch: 5| Step: 10
Training loss: 2.137124533887987
Validation loss: 2.474797318729853

Epoch: 5| Step: 11
Training loss: 2.231105733529779
Validation loss: 2.482702958155407

Epoch: 171| Step: 0
Training loss: 2.255212573839625
Validation loss: 2.477510313018367

Epoch: 5| Step: 1
Training loss: 2.3954342606484995
Validation loss: 2.4816902056816574

Epoch: 5| Step: 2
Training loss: 2.0290769250387255
Validation loss: 2.4838749364292623

Epoch: 5| Step: 3
Training loss: 2.2008203667525086
Validation loss: 2.4715152777736544

Epoch: 5| Step: 4
Training loss: 2.221945811671032
Validation loss: 2.4750270415765074

Epoch: 5| Step: 5
Training loss: 2.357585101730552
Validation loss: 2.4697311982553423

Epoch: 5| Step: 6
Training loss: 2.9885877663979317
Validation loss: 2.467230015026606

Epoch: 5| Step: 7
Training loss: 2.58746504829131
Validation loss: 2.4737425753556077

Epoch: 5| Step: 8
Training loss: 2.3919678949159913
Validation loss: 2.4719522085562162

Epoch: 5| Step: 9
Training loss: 2.844950663536031
Validation loss: 2.4754416038076

Epoch: 5| Step: 10
Training loss: 2.34115589268397
Validation loss: 2.4751739179148675

Epoch: 5| Step: 11
Training loss: 3.455225241091354
Validation loss: 2.4717566735536467

Epoch: 172| Step: 0
Training loss: 2.921796175459571
Validation loss: 2.4647915245685716

Epoch: 5| Step: 1
Training loss: 2.7729517551631515
Validation loss: 2.471994432987294

Epoch: 5| Step: 2
Training loss: 2.011200299167535
Validation loss: 2.4834875945101476

Epoch: 5| Step: 3
Training loss: 2.7954104547625387
Validation loss: 2.4825708248052982

Epoch: 5| Step: 4
Training loss: 2.3283350292937817
Validation loss: 2.4764492799247857

Epoch: 5| Step: 5
Training loss: 1.9848888062434717
Validation loss: 2.4869795408132114

Epoch: 5| Step: 6
Training loss: 2.342078363014824
Validation loss: 2.4813332880808634

Epoch: 5| Step: 7
Training loss: 2.4265728087491807
Validation loss: 2.4802952823407387

Epoch: 5| Step: 8
Training loss: 2.386146888963043
Validation loss: 2.4878968720954866

Epoch: 5| Step: 9
Training loss: 2.505277975043642
Validation loss: 2.4802135105925482

Epoch: 5| Step: 10
Training loss: 2.6460673211227674
Validation loss: 2.490242887993517

Epoch: 5| Step: 11
Training loss: 0.9800461546091513
Validation loss: 2.491785002984789

Epoch: 173| Step: 0
Training loss: 2.612083080553594
Validation loss: 2.5001140886341426

Epoch: 5| Step: 1
Training loss: 2.290846406194641
Validation loss: 2.487814902975405

Epoch: 5| Step: 2
Training loss: 2.7597958616421274
Validation loss: 2.4826721497436575

Epoch: 5| Step: 3
Training loss: 2.6297399324118693
Validation loss: 2.4996148567757595

Epoch: 5| Step: 4
Training loss: 2.6862595822752273
Validation loss: 2.4921107743748814

Epoch: 5| Step: 5
Training loss: 1.9510017756185658
Validation loss: 2.488726090572306

Epoch: 5| Step: 6
Training loss: 2.56169553084814
Validation loss: 2.4750186548589634

Epoch: 5| Step: 7
Training loss: 2.4703566719174006
Validation loss: 2.4735753107547307

Epoch: 5| Step: 8
Training loss: 2.3953067587866412
Validation loss: 2.474146100330627

Epoch: 5| Step: 9
Training loss: 2.7780389143797732
Validation loss: 2.474168195690823

Epoch: 5| Step: 10
Training loss: 2.0718125001620287
Validation loss: 2.475034573342414

Epoch: 5| Step: 11
Training loss: 2.4867605595934466
Validation loss: 2.4777409009322806

Epoch: 174| Step: 0
Training loss: 3.007410116652069
Validation loss: 2.4795582419320192

Epoch: 5| Step: 1
Training loss: 1.8988070030269697
Validation loss: 2.4918175385854213

Epoch: 5| Step: 2
Training loss: 2.638103387161648
Validation loss: 2.498134725823906

Epoch: 5| Step: 3
Training loss: 2.449942303970778
Validation loss: 2.5093025225556165

Epoch: 5| Step: 4
Training loss: 2.618048227459011
Validation loss: 2.5208876554032407

Epoch: 5| Step: 5
Training loss: 2.2926675055989363
Validation loss: 2.5237179906357246

Epoch: 5| Step: 6
Training loss: 2.329350808040765
Validation loss: 2.5020814615052585

Epoch: 5| Step: 7
Training loss: 2.571367783433448
Validation loss: 2.4904995446734755

Epoch: 5| Step: 8
Training loss: 2.222438915601854
Validation loss: 2.47648955437285

Epoch: 5| Step: 9
Training loss: 2.8445069699402343
Validation loss: 2.4754005458015564

Epoch: 5| Step: 10
Training loss: 2.460745473968954
Validation loss: 2.4677597908998297

Epoch: 5| Step: 11
Training loss: 1.8057315993276588
Validation loss: 2.481801457464654

Epoch: 175| Step: 0
Training loss: 2.8792091738207852
Validation loss: 2.4748818704882973

Epoch: 5| Step: 1
Training loss: 2.744183544759997
Validation loss: 2.4730356416520953

Epoch: 5| Step: 2
Training loss: 1.9508105183011006
Validation loss: 2.479629198305171

Epoch: 5| Step: 3
Training loss: 2.3752934124047553
Validation loss: 2.477701941862314

Epoch: 5| Step: 4
Training loss: 2.385927659209916
Validation loss: 2.47194263592382

Epoch: 5| Step: 5
Training loss: 3.1117762202827484
Validation loss: 2.470201773658243

Epoch: 5| Step: 6
Training loss: 2.2081133055087094
Validation loss: 2.4743484604399786

Epoch: 5| Step: 7
Training loss: 2.0635277470506423
Validation loss: 2.4672983505024066

Epoch: 5| Step: 8
Training loss: 2.615153236640415
Validation loss: 2.4733393982425613

Epoch: 5| Step: 9
Training loss: 2.5038703523106824
Validation loss: 2.4666602428348336

Epoch: 5| Step: 10
Training loss: 2.383759757443538
Validation loss: 2.4766813424173186

Epoch: 5| Step: 11
Training loss: 1.211732369696235
Validation loss: 2.4786704084975346

Epoch: 176| Step: 0
Training loss: 2.7748619182702243
Validation loss: 2.492597217423922

Epoch: 5| Step: 1
Training loss: 1.7859456593618293
Validation loss: 2.489719699705502

Epoch: 5| Step: 2
Training loss: 3.011172788143947
Validation loss: 2.4983079469136196

Epoch: 5| Step: 3
Training loss: 2.6901078102601677
Validation loss: 2.4892752462090617

Epoch: 5| Step: 4
Training loss: 2.202996973957714
Validation loss: 2.4803990071421684

Epoch: 5| Step: 5
Training loss: 2.777464873386212
Validation loss: 2.495885833374871

Epoch: 5| Step: 6
Training loss: 2.203332120209253
Validation loss: 2.487215980852082

Epoch: 5| Step: 7
Training loss: 2.6099704816764056
Validation loss: 2.4913320318798284

Epoch: 5| Step: 8
Training loss: 2.1785289460982695
Validation loss: 2.487186504462389

Epoch: 5| Step: 9
Training loss: 2.2539728905199214
Validation loss: 2.4672867184660516

Epoch: 5| Step: 10
Training loss: 2.9397214241134484
Validation loss: 2.4794668902738946

Epoch: 5| Step: 11
Training loss: 2.4563716130325752
Validation loss: 2.477171352727332

Epoch: 177| Step: 0
Training loss: 2.379307204158184
Validation loss: 2.4775201127396813

Epoch: 5| Step: 1
Training loss: 2.3334668212127387
Validation loss: 2.4748429828183967

Epoch: 5| Step: 2
Training loss: 2.8822244183896273
Validation loss: 2.4855708996630206

Epoch: 5| Step: 3
Training loss: 2.082973932419032
Validation loss: 2.4741211981453706

Epoch: 5| Step: 4
Training loss: 2.6986453472728993
Validation loss: 2.471270497831531

Epoch: 5| Step: 5
Training loss: 2.1042123418200394
Validation loss: 2.473741410767234

Epoch: 5| Step: 6
Training loss: 3.006404398484436
Validation loss: 2.467727264185687

Epoch: 5| Step: 7
Training loss: 2.4449111560367762
Validation loss: 2.479170952854672

Epoch: 5| Step: 8
Training loss: 2.833870967643884
Validation loss: 2.479630580473973

Epoch: 5| Step: 9
Training loss: 2.195866742202659
Validation loss: 2.484354003081773

Epoch: 5| Step: 10
Training loss: 2.4652328546815845
Validation loss: 2.482111317407083

Epoch: 5| Step: 11
Training loss: 1.2450546667820481
Validation loss: 2.4865441319642696

Epoch: 178| Step: 0
Training loss: 2.629039925383457
Validation loss: 2.484647176136517

Epoch: 5| Step: 1
Training loss: 2.8075739636618455
Validation loss: 2.49286791004659

Epoch: 5| Step: 2
Training loss: 1.99321298571909
Validation loss: 2.5047384298552138

Epoch: 5| Step: 3
Training loss: 2.182242041655586
Validation loss: 2.5127939599494193

Epoch: 5| Step: 4
Training loss: 2.2493244852518752
Validation loss: 2.5084335255388415

Epoch: 5| Step: 5
Training loss: 2.5317957725361238
Validation loss: 2.503149730641166

Epoch: 5| Step: 6
Training loss: 2.1775149658249426
Validation loss: 2.504382893012232

Epoch: 5| Step: 7
Training loss: 2.3800532139511112
Validation loss: 2.4901295877986356

Epoch: 5| Step: 8
Training loss: 2.593313341267988
Validation loss: 2.489112623292347

Epoch: 5| Step: 9
Training loss: 2.8500977817291604
Validation loss: 2.486203722202652

Epoch: 5| Step: 10
Training loss: 2.7236919868526996
Validation loss: 2.477104665174035

Epoch: 5| Step: 11
Training loss: 2.3116783538207555
Validation loss: 2.477386670405964

Epoch: 179| Step: 0
Training loss: 2.4267553563556485
Validation loss: 2.4743975895210797

Epoch: 5| Step: 1
Training loss: 3.1330881354253766
Validation loss: 2.479196281149374

Epoch: 5| Step: 2
Training loss: 2.52267435066768
Validation loss: 2.4804582730770375

Epoch: 5| Step: 3
Training loss: 2.595298488700843
Validation loss: 2.4837174655067833

Epoch: 5| Step: 4
Training loss: 2.676725123643204
Validation loss: 2.4854052744559296

Epoch: 5| Step: 5
Training loss: 2.1068602088356965
Validation loss: 2.475253219366605

Epoch: 5| Step: 6
Training loss: 1.9729319162662262
Validation loss: 2.4850232819976688

Epoch: 5| Step: 7
Training loss: 2.1993397328789652
Validation loss: 2.4902650080772633

Epoch: 5| Step: 8
Training loss: 2.76158562626684
Validation loss: 2.511732410890124

Epoch: 5| Step: 9
Training loss: 2.2778477838918056
Validation loss: 2.484908008778816

Epoch: 5| Step: 10
Training loss: 2.998180632449847
Validation loss: 2.492854472551361

Epoch: 5| Step: 11
Training loss: 0.8903562575325978
Validation loss: 2.481451761897149

Epoch: 180| Step: 0
Training loss: 2.653469650115115
Validation loss: 2.4798108928116394

Epoch: 5| Step: 1
Training loss: 2.5056026621598564
Validation loss: 2.4773432426568407

Epoch: 5| Step: 2
Training loss: 2.305240887944823
Validation loss: 2.467897730803043

Epoch: 5| Step: 3
Training loss: 2.516365842545124
Validation loss: 2.4733595327530318

Epoch: 5| Step: 4
Training loss: 3.025023209664076
Validation loss: 2.4687112732759093

Epoch: 5| Step: 5
Training loss: 2.708386366887359
Validation loss: 2.4677268616246577

Epoch: 5| Step: 6
Training loss: 2.2698150824963754
Validation loss: 2.4666553697348848

Epoch: 5| Step: 7
Training loss: 2.27123098362303
Validation loss: 2.4669186120841022

Epoch: 5| Step: 8
Training loss: 2.4282180905754633
Validation loss: 2.4681670752144678

Epoch: 5| Step: 9
Training loss: 2.2625810893159124
Validation loss: 2.4680520853783747

Epoch: 5| Step: 10
Training loss: 2.884995210534522
Validation loss: 2.4656990207766767

Epoch: 5| Step: 11
Training loss: 2.4120571856702235
Validation loss: 2.470062192830157

Epoch: 181| Step: 0
Training loss: 2.141459170233488
Validation loss: 2.4642811781582834

Epoch: 5| Step: 1
Training loss: 2.053052360376082
Validation loss: 2.4616384285095148

Epoch: 5| Step: 2
Training loss: 2.862517251041853
Validation loss: 2.4569268621396985

Epoch: 5| Step: 3
Training loss: 2.3783234883108877
Validation loss: 2.464095367296295

Epoch: 5| Step: 4
Training loss: 1.9460893787900024
Validation loss: 2.4531498642489495

Epoch: 5| Step: 5
Training loss: 2.9560425893273243
Validation loss: 2.461034431768732

Epoch: 5| Step: 6
Training loss: 2.592899228940066
Validation loss: 2.4594889217361673

Epoch: 5| Step: 7
Training loss: 2.252745754371294
Validation loss: 2.475345673648828

Epoch: 5| Step: 8
Training loss: 2.7085567871247576
Validation loss: 2.4849198561619708

Epoch: 5| Step: 9
Training loss: 2.4811330311299438
Validation loss: 2.4951517619047383

Epoch: 5| Step: 10
Training loss: 2.9737270997982828
Validation loss: 2.4807168951591327

Epoch: 5| Step: 11
Training loss: 1.9438540341910564
Validation loss: 2.499249764961801

Epoch: 182| Step: 0
Training loss: 2.1317558605551508
Validation loss: 2.494751961112705

Epoch: 5| Step: 1
Training loss: 2.5336538133021254
Validation loss: 2.4959784746291325

Epoch: 5| Step: 2
Training loss: 2.781139414442562
Validation loss: 2.4836503077528325

Epoch: 5| Step: 3
Training loss: 2.7377669739854076
Validation loss: 2.4741841557819235

Epoch: 5| Step: 4
Training loss: 2.7105931659752787
Validation loss: 2.4750231723310736

Epoch: 5| Step: 5
Training loss: 2.1869031909434944
Validation loss: 2.4843429907250174

Epoch: 5| Step: 6
Training loss: 2.191774714699003
Validation loss: 2.4861013664170653

Epoch: 5| Step: 7
Training loss: 2.3982046803352164
Validation loss: 2.4804507798072093

Epoch: 5| Step: 8
Training loss: 2.2326010751430676
Validation loss: 2.474635207621708

Epoch: 5| Step: 9
Training loss: 2.7650232899738656
Validation loss: 2.4825411171915874

Epoch: 5| Step: 10
Training loss: 2.4007425073587974
Validation loss: 2.4835252408201067

Epoch: 5| Step: 11
Training loss: 2.387611634206011
Validation loss: 2.4783305326248004

Epoch: 183| Step: 0
Training loss: 2.1263793507677744
Validation loss: 2.4809493953369848

Epoch: 5| Step: 1
Training loss: 2.913570249978967
Validation loss: 2.4830672302874444

Epoch: 5| Step: 2
Training loss: 1.6008483038617147
Validation loss: 2.472354535039923

Epoch: 5| Step: 3
Training loss: 2.364566169934153
Validation loss: 2.489506478233972

Epoch: 5| Step: 4
Training loss: 2.0356995192448735
Validation loss: 2.4777236366510373

Epoch: 5| Step: 5
Training loss: 2.4730629247549207
Validation loss: 2.4838128123590635

Epoch: 5| Step: 6
Training loss: 2.4770091523489195
Validation loss: 2.469791144525566

Epoch: 5| Step: 7
Training loss: 3.0093988372080496
Validation loss: 2.4694373264491456

Epoch: 5| Step: 8
Training loss: 2.6299508047398077
Validation loss: 2.4750697152597625

Epoch: 5| Step: 9
Training loss: 2.8576880309549506
Validation loss: 2.4788881968263534

Epoch: 5| Step: 10
Training loss: 2.201011022260244
Validation loss: 2.470407102841593

Epoch: 5| Step: 11
Training loss: 1.6481704857241581
Validation loss: 2.4696266734340293

Epoch: 184| Step: 0
Training loss: 2.074952306544026
Validation loss: 2.473160851422532

Epoch: 5| Step: 1
Training loss: 2.082026898520898
Validation loss: 2.4781554882071015

Epoch: 5| Step: 2
Training loss: 1.8705345385313972
Validation loss: 2.47497970110343

Epoch: 5| Step: 3
Training loss: 2.1574556601201613
Validation loss: 2.4820326313114616

Epoch: 5| Step: 4
Training loss: 2.791908415010929
Validation loss: 2.4877181681130924

Epoch: 5| Step: 5
Training loss: 2.5937803335599194
Validation loss: 2.481333276070255

Epoch: 5| Step: 6
Training loss: 2.2809160589069344
Validation loss: 2.488851065794139

Epoch: 5| Step: 7
Training loss: 2.72162397346097
Validation loss: 2.489957216085479

Epoch: 5| Step: 8
Training loss: 2.6803923366665363
Validation loss: 2.4882282189547467

Epoch: 5| Step: 9
Training loss: 2.747421269351794
Validation loss: 2.484927449891099

Epoch: 5| Step: 10
Training loss: 2.744056260519229
Validation loss: 2.486924764361042

Epoch: 5| Step: 11
Training loss: 2.0439832221833765
Validation loss: 2.484765330027112

Epoch: 185| Step: 0
Training loss: 2.436032171165364
Validation loss: 2.490189922659059

Epoch: 5| Step: 1
Training loss: 2.4395854538393347
Validation loss: 2.4886204654507247

Epoch: 5| Step: 2
Training loss: 2.4691399374974323
Validation loss: 2.4848581040305278

Epoch: 5| Step: 3
Training loss: 2.2679738464193084
Validation loss: 2.4791962450864897

Epoch: 5| Step: 4
Training loss: 3.060104678987682
Validation loss: 2.4795229412714255

Epoch: 5| Step: 5
Training loss: 2.3948702548886116
Validation loss: 2.4787453619355224

Epoch: 5| Step: 6
Training loss: 1.9062053487582395
Validation loss: 2.485488282285982

Epoch: 5| Step: 7
Training loss: 2.6271368139774274
Validation loss: 2.4918848968123073

Epoch: 5| Step: 8
Training loss: 2.2239294712835225
Validation loss: 2.481610393375054

Epoch: 5| Step: 9
Training loss: 2.157594013132821
Validation loss: 2.488381903272939

Epoch: 5| Step: 10
Training loss: 2.64135488320844
Validation loss: 2.4823410617290924

Epoch: 5| Step: 11
Training loss: 2.7451803280881064
Validation loss: 2.4947803366980517

Epoch: 186| Step: 0
Training loss: 2.088165579124377
Validation loss: 2.486861176546238

Epoch: 5| Step: 1
Training loss: 2.6626393384694698
Validation loss: 2.5018370594238926

Epoch: 5| Step: 2
Training loss: 2.5502179445365507
Validation loss: 2.5018903698124695

Epoch: 5| Step: 3
Training loss: 2.7749129548038587
Validation loss: 2.5009527238799305

Epoch: 5| Step: 4
Training loss: 2.3821297089423634
Validation loss: 2.4944235935669585

Epoch: 5| Step: 5
Training loss: 2.276631422184278
Validation loss: 2.4955322796259907

Epoch: 5| Step: 6
Training loss: 2.5421223674887528
Validation loss: 2.5055742465802506

Epoch: 5| Step: 7
Training loss: 2.47978660034527
Validation loss: 2.490707675609845

Epoch: 5| Step: 8
Training loss: 2.4032099953094352
Validation loss: 2.491151400993283

Epoch: 5| Step: 9
Training loss: 2.228238943645413
Validation loss: 2.482280131889647

Epoch: 5| Step: 10
Training loss: 2.661185671780062
Validation loss: 2.47997618663158

Epoch: 5| Step: 11
Training loss: 1.3341055461759397
Validation loss: 2.477103750809394

Epoch: 187| Step: 0
Training loss: 2.571741327309153
Validation loss: 2.4793973956944906

Epoch: 5| Step: 1
Training loss: 2.454816004584361
Validation loss: 2.480388001256505

Epoch: 5| Step: 2
Training loss: 2.6018997294570054
Validation loss: 2.4805382265788776

Epoch: 5| Step: 3
Training loss: 1.7541645768878777
Validation loss: 2.476248644045812

Epoch: 5| Step: 4
Training loss: 2.025126691081128
Validation loss: 2.4861592697177066

Epoch: 5| Step: 5
Training loss: 2.5208335645270963
Validation loss: 2.4782254906219117

Epoch: 5| Step: 6
Training loss: 2.3697478796857583
Validation loss: 2.468968961155968

Epoch: 5| Step: 7
Training loss: 2.9726238474539874
Validation loss: 2.486101392390141

Epoch: 5| Step: 8
Training loss: 2.4468320567526978
Validation loss: 2.4869378504225472

Epoch: 5| Step: 9
Training loss: 2.6082732107365025
Validation loss: 2.4821925303685823

Epoch: 5| Step: 10
Training loss: 2.2943425133051463
Validation loss: 2.4925383955569065

Epoch: 5| Step: 11
Training loss: 3.1297440187147356
Validation loss: 2.495955302697682

Epoch: 188| Step: 0
Training loss: 2.4717086253738643
Validation loss: 2.4968358957843515

Epoch: 5| Step: 1
Training loss: 2.235797242697853
Validation loss: 2.4952833584409717

Epoch: 5| Step: 2
Training loss: 2.4905475255003915
Validation loss: 2.4908613904055814

Epoch: 5| Step: 3
Training loss: 2.1732906420830647
Validation loss: 2.4855223011858607

Epoch: 5| Step: 4
Training loss: 2.2266203220288094
Validation loss: 2.4934767932746422

Epoch: 5| Step: 5
Training loss: 2.591046314468953
Validation loss: 2.497341546564841

Epoch: 5| Step: 6
Training loss: 2.69876558554647
Validation loss: 2.487905644643843

Epoch: 5| Step: 7
Training loss: 2.3284000515873413
Validation loss: 2.482670425149532

Epoch: 5| Step: 8
Training loss: 2.407318868666345
Validation loss: 2.4883253970938375

Epoch: 5| Step: 9
Training loss: 2.7192029027680373
Validation loss: 2.4890382853749182

Epoch: 5| Step: 10
Training loss: 2.5698820640726274
Validation loss: 2.4897166074144037

Epoch: 5| Step: 11
Training loss: 1.5306117226152114
Validation loss: 2.4888096662017802

Epoch: 189| Step: 0
Training loss: 2.7340020497613686
Validation loss: 2.477738567494889

Epoch: 5| Step: 1
Training loss: 2.068145885021992
Validation loss: 2.493796009859854

Epoch: 5| Step: 2
Training loss: 2.6645256825628665
Validation loss: 2.483718971390757

Epoch: 5| Step: 3
Training loss: 1.9298557100071352
Validation loss: 2.498209001829063

Epoch: 5| Step: 4
Training loss: 2.3801480764918455
Validation loss: 2.4909952115901466

Epoch: 5| Step: 5
Training loss: 2.7568700979496645
Validation loss: 2.4915458108197983

Epoch: 5| Step: 6
Training loss: 2.5729541132334504
Validation loss: 2.49247648144183

Epoch: 5| Step: 7
Training loss: 2.791262573678533
Validation loss: 2.5028955102780714

Epoch: 5| Step: 8
Training loss: 2.7032707924748327
Validation loss: 2.4909598576532157

Epoch: 5| Step: 9
Training loss: 2.061650187807623
Validation loss: 2.5032501630728103

Epoch: 5| Step: 10
Training loss: 1.9717787197686931
Validation loss: 2.4892799333557516

Epoch: 5| Step: 11
Training loss: 1.6426290715103775
Validation loss: 2.4983995878083882

Epoch: 190| Step: 0
Training loss: 2.1522924621342274
Validation loss: 2.498493744163603

Epoch: 5| Step: 1
Training loss: 2.3500258789260844
Validation loss: 2.4979792415002238

Epoch: 5| Step: 2
Training loss: 2.6566968654159044
Validation loss: 2.505621704818755

Epoch: 5| Step: 3
Training loss: 2.7083793244980754
Validation loss: 2.499621497747457

Epoch: 5| Step: 4
Training loss: 2.8188017711410276
Validation loss: 2.504260263793706

Epoch: 5| Step: 5
Training loss: 1.6785904961520461
Validation loss: 2.5011894495935074

Epoch: 5| Step: 6
Training loss: 2.3389064331584684
Validation loss: 2.5155693940518993

Epoch: 5| Step: 7
Training loss: 2.3663798046429014
Validation loss: 2.5148611034352744

Epoch: 5| Step: 8
Training loss: 2.3304737711234353
Validation loss: 2.5035120772318114

Epoch: 5| Step: 9
Training loss: 2.715049066258277
Validation loss: 2.512905613657707

Epoch: 5| Step: 10
Training loss: 2.4206204025811924
Validation loss: 2.5021129460823

Epoch: 5| Step: 11
Training loss: 2.050160341272545
Validation loss: 2.5047863203652287

Epoch: 191| Step: 0
Training loss: 2.763607431475903
Validation loss: 2.499343897238149

Epoch: 5| Step: 1
Training loss: 2.282630607152304
Validation loss: 2.4863470036343553

Epoch: 5| Step: 2
Training loss: 2.7540307415899625
Validation loss: 2.493137935746083

Epoch: 5| Step: 3
Training loss: 2.550017962672976
Validation loss: 2.4916936410976933

Epoch: 5| Step: 4
Training loss: 2.6585771128010323
Validation loss: 2.4905386106856016

Epoch: 5| Step: 5
Training loss: 2.1742306017098603
Validation loss: 2.496260878689333

Epoch: 5| Step: 6
Training loss: 2.1829256458489774
Validation loss: 2.4979989348208984

Epoch: 5| Step: 7
Training loss: 2.2118515443703486
Validation loss: 2.4991823746869244

Epoch: 5| Step: 8
Training loss: 2.242580685051774
Validation loss: 2.4948356653738997

Epoch: 5| Step: 9
Training loss: 2.1261040680428116
Validation loss: 2.488169561301848

Epoch: 5| Step: 10
Training loss: 2.6874605220290397
Validation loss: 2.489314520992952

Epoch: 5| Step: 11
Training loss: 2.8475634817494013
Validation loss: 2.489063197964181

Epoch: 192| Step: 0
Training loss: 2.46545141501086
Validation loss: 2.4885447795258178

Epoch: 5| Step: 1
Training loss: 2.7337985057739935
Validation loss: 2.4862215069697537

Epoch: 5| Step: 2
Training loss: 2.0319027365437368
Validation loss: 2.492520540280969

Epoch: 5| Step: 3
Training loss: 2.112759509878498
Validation loss: 2.496506932884444

Epoch: 5| Step: 4
Training loss: 2.4202421529063645
Validation loss: 2.496533004485277

Epoch: 5| Step: 5
Training loss: 2.797573918652064
Validation loss: 2.5008323674537483

Epoch: 5| Step: 6
Training loss: 2.506656748806156
Validation loss: 2.4991985864393302

Epoch: 5| Step: 7
Training loss: 2.1654185098955
Validation loss: 2.4865241062130545

Epoch: 5| Step: 8
Training loss: 2.595887372070314
Validation loss: 2.507606664273474

Epoch: 5| Step: 9
Training loss: 2.6305345591058846
Validation loss: 2.501763770675384

Epoch: 5| Step: 10
Training loss: 2.0818275223159386
Validation loss: 2.4958247525848307

Epoch: 5| Step: 11
Training loss: 2.4128152038535355
Validation loss: 2.49230522268358

Epoch: 193| Step: 0
Training loss: 2.443200414961834
Validation loss: 2.499897946817888

Epoch: 5| Step: 1
Training loss: 2.482936610678268
Validation loss: 2.5177121359802075

Epoch: 5| Step: 2
Training loss: 2.432082881312034
Validation loss: 2.521316830057153

Epoch: 5| Step: 3
Training loss: 2.255929339756483
Validation loss: 2.5100407292536775

Epoch: 5| Step: 4
Training loss: 2.5562932278958304
Validation loss: 2.490215777159413

Epoch: 5| Step: 5
Training loss: 2.292121483723906
Validation loss: 2.491973911647621

Epoch: 5| Step: 6
Training loss: 3.2485026798433934
Validation loss: 2.4893951477900647

Epoch: 5| Step: 7
Training loss: 2.5138048493989777
Validation loss: 2.489971515021495

Epoch: 5| Step: 8
Training loss: 1.8656618916555674
Validation loss: 2.486378032206415

Epoch: 5| Step: 9
Training loss: 2.4905834237604747
Validation loss: 2.483327776840787

Epoch: 5| Step: 10
Training loss: 2.0634150931450153
Validation loss: 2.49726275559178

Epoch: 5| Step: 11
Training loss: 2.1529823643537496
Validation loss: 2.488789932100503

Epoch: 194| Step: 0
Training loss: 2.5259098188985307
Validation loss: 2.490738873209904

Epoch: 5| Step: 1
Training loss: 2.5044639787511054
Validation loss: 2.489845618526674

Epoch: 5| Step: 2
Training loss: 2.1388005187479693
Validation loss: 2.49731470771162

Epoch: 5| Step: 3
Training loss: 2.2841124669459063
Validation loss: 2.5085136704923032

Epoch: 5| Step: 4
Training loss: 2.392047932326373
Validation loss: 2.507718925275177

Epoch: 5| Step: 5
Training loss: 2.582943107501235
Validation loss: 2.5071418277378426

Epoch: 5| Step: 6
Training loss: 2.1602150769354855
Validation loss: 2.5144137947704914

Epoch: 5| Step: 7
Training loss: 2.6230660535121197
Validation loss: 2.5215806575784354

Epoch: 5| Step: 8
Training loss: 2.3696195994079803
Validation loss: 2.5252442559675203

Epoch: 5| Step: 9
Training loss: 2.3884752368853137
Validation loss: 2.5264929941745713

Epoch: 5| Step: 10
Training loss: 2.97906148942718
Validation loss: 2.5186740807007975

Epoch: 5| Step: 11
Training loss: 0.9249458567779704
Validation loss: 2.506539109631411

Epoch: 195| Step: 0
Training loss: 2.4189810906152514
Validation loss: 2.4990874055320456

Epoch: 5| Step: 1
Training loss: 2.4551349351086724
Validation loss: 2.487656675129896

Epoch: 5| Step: 2
Training loss: 2.3175321933522564
Validation loss: 2.5012045064649664

Epoch: 5| Step: 3
Training loss: 2.469582622492146
Validation loss: 2.489460241129104

Epoch: 5| Step: 4
Training loss: 1.867430986306306
Validation loss: 2.4893671178633103

Epoch: 5| Step: 5
Training loss: 2.3316217570948248
Validation loss: 2.4919963153464386

Epoch: 5| Step: 6
Training loss: 2.0932116599267196
Validation loss: 2.4870996529251492

Epoch: 5| Step: 7
Training loss: 2.9065443320588855
Validation loss: 2.487863841995507

Epoch: 5| Step: 8
Training loss: 2.1608841344018357
Validation loss: 2.490105619405517

Epoch: 5| Step: 9
Training loss: 2.9855122421593747
Validation loss: 2.48706947415679

Epoch: 5| Step: 10
Training loss: 2.879849200539271
Validation loss: 2.4875847297244444

Epoch: 5| Step: 11
Training loss: 1.1440924626844575
Validation loss: 2.500573072713478

Epoch: 196| Step: 0
Training loss: 2.6064518985257745
Validation loss: 2.505744568713933

Epoch: 5| Step: 1
Training loss: 2.3452659282088533
Validation loss: 2.5512479167308584

Epoch: 5| Step: 2
Training loss: 2.6845545041481627
Validation loss: 2.5438840618313607

Epoch: 5| Step: 3
Training loss: 2.4878108419837597
Validation loss: 2.525032539283909

Epoch: 5| Step: 4
Training loss: 2.769960442821768
Validation loss: 2.518982764974736

Epoch: 5| Step: 5
Training loss: 1.8952998853548284
Validation loss: 2.4855089298932773

Epoch: 5| Step: 6
Training loss: 2.797536590582324
Validation loss: 2.4984571186159825

Epoch: 5| Step: 7
Training loss: 2.379391475106415
Validation loss: 2.4905625749117477

Epoch: 5| Step: 8
Training loss: 2.300703737154618
Validation loss: 2.4754462629714

Epoch: 5| Step: 9
Training loss: 2.3251644486546224
Validation loss: 2.473816642049906

Epoch: 5| Step: 10
Training loss: 2.6146061707571984
Validation loss: 2.480713631464302

Epoch: 5| Step: 11
Training loss: 2.0978310510413793
Validation loss: 2.473129737360378

Epoch: 197| Step: 0
Training loss: 2.6377972692947664
Validation loss: 2.4793848387838153

Epoch: 5| Step: 1
Training loss: 2.650156729040108
Validation loss: 2.4851474200973973

Epoch: 5| Step: 2
Training loss: 2.2314970248384363
Validation loss: 2.4884517856768933

Epoch: 5| Step: 3
Training loss: 2.514065845740957
Validation loss: 2.4875435965917276

Epoch: 5| Step: 4
Training loss: 2.735676134349302
Validation loss: 2.4946216705848507

Epoch: 5| Step: 5
Training loss: 2.5626977983754426
Validation loss: 2.486482094559417

Epoch: 5| Step: 6
Training loss: 1.7914922614562603
Validation loss: 2.4840815508773355

Epoch: 5| Step: 7
Training loss: 2.249838081467701
Validation loss: 2.4991182957969547

Epoch: 5| Step: 8
Training loss: 2.296472423332248
Validation loss: 2.517316746960247

Epoch: 5| Step: 9
Training loss: 1.9880319974960758
Validation loss: 2.513395624756953

Epoch: 5| Step: 10
Training loss: 2.6817198406169034
Validation loss: 2.5197136667539235

Epoch: 5| Step: 11
Training loss: 3.7827251488843268
Validation loss: 2.5219337246189615

Epoch: 198| Step: 0
Training loss: 2.379863978433887
Validation loss: 2.5155966581402676

Epoch: 5| Step: 1
Training loss: 2.643112906669396
Validation loss: 2.50924494744023

Epoch: 5| Step: 2
Training loss: 2.8858286062039036
Validation loss: 2.5223544446968202

Epoch: 5| Step: 3
Training loss: 2.7848085932815203
Validation loss: 2.5101400370687177

Epoch: 5| Step: 4
Training loss: 2.2939336718787238
Validation loss: 2.4991642588185865

Epoch: 5| Step: 5
Training loss: 1.8873886909253574
Validation loss: 2.496765239421299

Epoch: 5| Step: 6
Training loss: 2.536418958876615
Validation loss: 2.4924898711546826

Epoch: 5| Step: 7
Training loss: 1.923100956619911
Validation loss: 2.494760677699999

Epoch: 5| Step: 8
Training loss: 2.3781415339733525
Validation loss: 2.4860453398639644

Epoch: 5| Step: 9
Training loss: 2.2571346757061046
Validation loss: 2.4900738912493408

Epoch: 5| Step: 10
Training loss: 2.5801958494740407
Validation loss: 2.4950771062310397

Epoch: 5| Step: 11
Training loss: 3.0417808789971246
Validation loss: 2.5030447776788267

Epoch: 199| Step: 0
Training loss: 2.1556654427999113
Validation loss: 2.4980303754105035

Epoch: 5| Step: 1
Training loss: 2.080606226975329
Validation loss: 2.491083317080619

Epoch: 5| Step: 2
Training loss: 2.4782107671493145
Validation loss: 2.500963635295172

Epoch: 5| Step: 3
Training loss: 2.7970575028019558
Validation loss: 2.4993441873902182

Epoch: 5| Step: 4
Training loss: 2.064481650221271
Validation loss: 2.512330498362976

Epoch: 5| Step: 5
Training loss: 2.2829796491627365
Validation loss: 2.4999156142933803

Epoch: 5| Step: 6
Training loss: 2.070579655522405
Validation loss: 2.499817038834726

Epoch: 5| Step: 7
Training loss: 2.5120872120509086
Validation loss: 2.493110860378219

Epoch: 5| Step: 8
Training loss: 2.588332251527867
Validation loss: 2.512374889127739

Epoch: 5| Step: 9
Training loss: 2.340474089989433
Validation loss: 2.5010859793079603

Epoch: 5| Step: 10
Training loss: 2.9387707498029614
Validation loss: 2.511168879016339

Epoch: 5| Step: 11
Training loss: 3.1579074850996256
Validation loss: 2.5109673775820305

Epoch: 200| Step: 0
Training loss: 2.2234325159570587
Validation loss: 2.507461154842235

Epoch: 5| Step: 1
Training loss: 2.644268884984315
Validation loss: 2.4974629085206126

Epoch: 5| Step: 2
Training loss: 2.3164871484740446
Validation loss: 2.4920059464831708

Epoch: 5| Step: 3
Training loss: 2.546410453883269
Validation loss: 2.4867963886834756

Epoch: 5| Step: 4
Training loss: 2.87023481119558
Validation loss: 2.5022718160585775

Epoch: 5| Step: 5
Training loss: 2.4630364080689398
Validation loss: 2.502835914342574

Epoch: 5| Step: 6
Training loss: 2.1787839267735225
Validation loss: 2.494960724764219

Epoch: 5| Step: 7
Training loss: 2.054225739202914
Validation loss: 2.492655886459539

Epoch: 5| Step: 8
Training loss: 2.2682848871323715
Validation loss: 2.519094783227641

Epoch: 5| Step: 9
Training loss: 2.971985990776221
Validation loss: 2.507511750723327

Epoch: 5| Step: 10
Training loss: 1.8694615262998673
Validation loss: 2.515484484110672

Epoch: 5| Step: 11
Training loss: 2.4701203032011168
Validation loss: 2.5127637438469246

Epoch: 201| Step: 0
Training loss: 2.120994495296574
Validation loss: 2.4994121456414624

Epoch: 5| Step: 1
Training loss: 2.279803091547704
Validation loss: 2.4894012453747036

Epoch: 5| Step: 2
Training loss: 2.07293328002202
Validation loss: 2.4906234656647888

Epoch: 5| Step: 3
Training loss: 2.3578539865533483
Validation loss: 2.485739299354565

Epoch: 5| Step: 4
Training loss: 2.2532989900368254
Validation loss: 2.487516015047567

Epoch: 5| Step: 5
Training loss: 2.339458656782208
Validation loss: 2.493244612623164

Epoch: 5| Step: 6
Training loss: 2.276383945267576
Validation loss: 2.5042871571325853

Epoch: 5| Step: 7
Training loss: 2.918447513957315
Validation loss: 2.500593075340703

Epoch: 5| Step: 8
Training loss: 2.7089486425748106
Validation loss: 2.519115261857786

Epoch: 5| Step: 9
Training loss: 2.812784816307775
Validation loss: 2.5230482015701243

Epoch: 5| Step: 10
Training loss: 2.4064141750062773
Validation loss: 2.538763746634148

Epoch: 5| Step: 11
Training loss: 3.2463336217874703
Validation loss: 2.5500083363776977

Epoch: 202| Step: 0
Training loss: 2.2916870694263705
Validation loss: 2.5435581276283608

Epoch: 5| Step: 1
Training loss: 1.8448996111842781
Validation loss: 2.5373968363369364

Epoch: 5| Step: 2
Training loss: 2.5971983082894896
Validation loss: 2.5028898901025975

Epoch: 5| Step: 3
Training loss: 2.596230205814903
Validation loss: 2.5044215401625847

Epoch: 5| Step: 4
Training loss: 2.3895143409708943
Validation loss: 2.4945575601616157

Epoch: 5| Step: 5
Training loss: 2.611561116428974
Validation loss: 2.4954240962302356

Epoch: 5| Step: 6
Training loss: 2.601654875893749
Validation loss: 2.487858359563412

Epoch: 5| Step: 7
Training loss: 2.379382256551168
Validation loss: 2.4798161606881033

Epoch: 5| Step: 8
Training loss: 2.2034467097019474
Validation loss: 2.479291954133811

Epoch: 5| Step: 9
Training loss: 2.6924154883592517
Validation loss: 2.483467740116835

Epoch: 5| Step: 10
Training loss: 2.3470011223886647
Validation loss: 2.4753237613691024

Epoch: 5| Step: 11
Training loss: 2.8872591785229194
Validation loss: 2.4774161872069884

Epoch: 203| Step: 0
Training loss: 1.8777962496875362
Validation loss: 2.485450959481991

Epoch: 5| Step: 1
Training loss: 2.67228927523772
Validation loss: 2.4807065314115135

Epoch: 5| Step: 2
Training loss: 2.6299312231549687
Validation loss: 2.487884813284858

Epoch: 5| Step: 3
Training loss: 3.056923908598149
Validation loss: 2.4952329326341887

Epoch: 5| Step: 4
Training loss: 2.0472671482580553
Validation loss: 2.4985872449248085

Epoch: 5| Step: 5
Training loss: 2.335152484562768
Validation loss: 2.505852615771515

Epoch: 5| Step: 6
Training loss: 1.825935421899556
Validation loss: 2.500209314802628

Epoch: 5| Step: 7
Training loss: 2.2380178140062528
Validation loss: 2.5042892655073694

Epoch: 5| Step: 8
Training loss: 2.306262599838284
Validation loss: 2.526155244430305

Epoch: 5| Step: 9
Training loss: 2.619735525046642
Validation loss: 2.505457488350795

Epoch: 5| Step: 10
Training loss: 3.039787617843832
Validation loss: 2.49808969229837

Epoch: 5| Step: 11
Training loss: 3.199882987982496
Validation loss: 2.4882410426462007

Epoch: 204| Step: 0
Training loss: 2.798553645004377
Validation loss: 2.4764246175191014

Epoch: 5| Step: 1
Training loss: 1.9453816229247867
Validation loss: 2.478518230255497

Epoch: 5| Step: 2
Training loss: 2.6611063824662273
Validation loss: 2.483195218676785

Epoch: 5| Step: 3
Training loss: 2.7189450248837037
Validation loss: 2.4732099398279197

Epoch: 5| Step: 4
Training loss: 2.32483927673693
Validation loss: 2.473629832626779

Epoch: 5| Step: 5
Training loss: 2.3692759752724406
Validation loss: 2.478028261782722

Epoch: 5| Step: 6
Training loss: 3.089636640202444
Validation loss: 2.4732885692209465

Epoch: 5| Step: 7
Training loss: 1.948275228808163
Validation loss: 2.473878928800837

Epoch: 5| Step: 8
Training loss: 2.4732697073917573
Validation loss: 2.4723490744691357

Epoch: 5| Step: 9
Training loss: 1.7334638384449117
Validation loss: 2.484883074520129

Epoch: 5| Step: 10
Training loss: 3.0418656863243805
Validation loss: 2.4851465006971556

Epoch: 5| Step: 11
Training loss: 1.162841002379728
Validation loss: 2.4895193472158534

Epoch: 205| Step: 0
Training loss: 2.5545399474482937
Validation loss: 2.4903200740653553

Epoch: 5| Step: 1
Training loss: 2.379282653796155
Validation loss: 2.4994869818422507

Epoch: 5| Step: 2
Training loss: 3.179708194899638
Validation loss: 2.4915788120444073

Epoch: 5| Step: 3
Training loss: 2.28998877626692
Validation loss: 2.4976083362109303

Epoch: 5| Step: 4
Training loss: 2.1443380188873222
Validation loss: 2.5143295411796887

Epoch: 5| Step: 5
Training loss: 2.260191301165676
Validation loss: 2.5073609623976187

Epoch: 5| Step: 6
Training loss: 2.218112692843142
Validation loss: 2.505831739353053

Epoch: 5| Step: 7
Training loss: 2.2143556302542664
Validation loss: 2.5064162173054267

Epoch: 5| Step: 8
Training loss: 2.5221372862680753
Validation loss: 2.509366580890421

Epoch: 5| Step: 9
Training loss: 2.742279485914889
Validation loss: 2.512281537719759

Epoch: 5| Step: 10
Training loss: 2.115016260287499
Validation loss: 2.5210803452103767

Epoch: 5| Step: 11
Training loss: 2.3541505075986024
Validation loss: 2.504187835396542

Epoch: 206| Step: 0
Training loss: 2.168718857775213
Validation loss: 2.4914282077584473

Epoch: 5| Step: 1
Training loss: 1.9403421413905662
Validation loss: 2.4879372187738613

Epoch: 5| Step: 2
Training loss: 2.221715208335547
Validation loss: 2.483601811689805

Epoch: 5| Step: 3
Training loss: 2.3835992233528605
Validation loss: 2.477560818859461

Epoch: 5| Step: 4
Training loss: 2.5388240760953824
Validation loss: 2.4816179632049558

Epoch: 5| Step: 5
Training loss: 2.8012322949824924
Validation loss: 2.479061690814083

Epoch: 5| Step: 6
Training loss: 2.2707186562049486
Validation loss: 2.475977582881908

Epoch: 5| Step: 7
Training loss: 2.3655256726716893
Validation loss: 2.474423372162488

Epoch: 5| Step: 8
Training loss: 2.3944919203348904
Validation loss: 2.4804685137090297

Epoch: 5| Step: 9
Training loss: 2.9268712049480423
Validation loss: 2.4816912144274577

Epoch: 5| Step: 10
Training loss: 2.5951485597573587
Validation loss: 2.4835399647860927

Epoch: 5| Step: 11
Training loss: 2.6025047085267787
Validation loss: 2.4761332030515346

Epoch: 207| Step: 0
Training loss: 2.7543995949668707
Validation loss: 2.4877281712113057

Epoch: 5| Step: 1
Training loss: 2.0964879595471966
Validation loss: 2.4857961680423655

Epoch: 5| Step: 2
Training loss: 2.1902594464049043
Validation loss: 2.477980884435938

Epoch: 5| Step: 3
Training loss: 2.5018289551606294
Validation loss: 2.4862454209078555

Epoch: 5| Step: 4
Training loss: 2.273943553066289
Validation loss: 2.4822672854074708

Epoch: 5| Step: 5
Training loss: 2.3719511037486036
Validation loss: 2.4809366120372367

Epoch: 5| Step: 6
Training loss: 2.3219124258318664
Validation loss: 2.477912767389143

Epoch: 5| Step: 7
Training loss: 2.213706072517417
Validation loss: 2.490946118734669

Epoch: 5| Step: 8
Training loss: 2.696739725585784
Validation loss: 2.4837455791900562

Epoch: 5| Step: 9
Training loss: 2.9528937678155485
Validation loss: 2.4812801725985674

Epoch: 5| Step: 10
Training loss: 2.2567786783492436
Validation loss: 2.48362256097697

Epoch: 5| Step: 11
Training loss: 2.730655254494145
Validation loss: 2.4812081704189115

Epoch: 208| Step: 0
Training loss: 3.1502194343308902
Validation loss: 2.4874013505796175

Epoch: 5| Step: 1
Training loss: 2.1002160052061716
Validation loss: 2.484373492514355

Epoch: 5| Step: 2
Training loss: 2.4156561964224057
Validation loss: 2.480231598658564

Epoch: 5| Step: 3
Training loss: 2.219237905235804
Validation loss: 2.4882474824140233

Epoch: 5| Step: 4
Training loss: 2.6805808132565088
Validation loss: 2.4777195310541424

Epoch: 5| Step: 5
Training loss: 2.258480408818957
Validation loss: 2.487312691312088

Epoch: 5| Step: 6
Training loss: 2.11942389919755
Validation loss: 2.4799521721822053

Epoch: 5| Step: 7
Training loss: 2.0942165936632047
Validation loss: 2.4880854970285453

Epoch: 5| Step: 8
Training loss: 2.5538208217575353
Validation loss: 2.48124754686979

Epoch: 5| Step: 9
Training loss: 2.6547921162918007
Validation loss: 2.4819926469326608

Epoch: 5| Step: 10
Training loss: 2.6700884997956007
Validation loss: 2.4903200261962914

Epoch: 5| Step: 11
Training loss: 2.4212285317260407
Validation loss: 2.4910038137073642

Epoch: 209| Step: 0
Training loss: 2.2856117251070396
Validation loss: 2.487693857022503

Epoch: 5| Step: 1
Training loss: 2.1622624261265044
Validation loss: 2.5016057023641047

Epoch: 5| Step: 2
Training loss: 2.101543780956073
Validation loss: 2.5036937208828847

Epoch: 5| Step: 3
Training loss: 2.1351924375335103
Validation loss: 2.4974866989094666

Epoch: 5| Step: 4
Training loss: 2.907443714072637
Validation loss: 2.5038734033168883

Epoch: 5| Step: 5
Training loss: 2.812713445405407
Validation loss: 2.505862364119275

Epoch: 5| Step: 6
Training loss: 2.658263397094065
Validation loss: 2.495551677779209

Epoch: 5| Step: 7
Training loss: 2.216235280426423
Validation loss: 2.4942909460291705

Epoch: 5| Step: 8
Training loss: 2.2990767118474382
Validation loss: 2.501062044417875

Epoch: 5| Step: 9
Training loss: 2.0220859093305443
Validation loss: 2.5035683160352695

Epoch: 5| Step: 10
Training loss: 2.8399753881113345
Validation loss: 2.4958097229627856

Epoch: 5| Step: 11
Training loss: 2.7454091679809385
Validation loss: 2.4986565437224644

Epoch: 210| Step: 0
Training loss: 2.75870194829274
Validation loss: 2.509329597407613

Epoch: 5| Step: 1
Training loss: 2.1294101503705143
Validation loss: 2.5102337392004204

Epoch: 5| Step: 2
Training loss: 2.4286155175767026
Validation loss: 2.516453892721566

Epoch: 5| Step: 3
Training loss: 2.8839889648268704
Validation loss: 2.5065063053774455

Epoch: 5| Step: 4
Training loss: 2.0599647893025996
Validation loss: 2.5175708961037766

Epoch: 5| Step: 5
Training loss: 2.4936850900257137
Validation loss: 2.51027912274888

Epoch: 5| Step: 6
Training loss: 3.070235778005322
Validation loss: 2.5118532139849843

Epoch: 5| Step: 7
Training loss: 1.9572375525735193
Validation loss: 2.516067096807745

Epoch: 5| Step: 8
Training loss: 2.2453767112942447
Validation loss: 2.5189015589788823

Epoch: 5| Step: 9
Training loss: 2.099181687908433
Validation loss: 2.5198415126551303

Epoch: 5| Step: 10
Training loss: 2.3130581156500396
Validation loss: 2.5163267945586894

Epoch: 5| Step: 11
Training loss: 2.436392801639468
Validation loss: 2.5027389225452814

Epoch: 211| Step: 0
Training loss: 3.0421157052571757
Validation loss: 2.4990797455140825

Epoch: 5| Step: 1
Training loss: 2.9280206846955306
Validation loss: 2.495384354294322

Epoch: 5| Step: 2
Training loss: 2.226233207043857
Validation loss: 2.4965727400735847

Epoch: 5| Step: 3
Training loss: 2.3155057806916095
Validation loss: 2.4918095970835688

Epoch: 5| Step: 4
Training loss: 2.0079124811712927
Validation loss: 2.491523801786228

Epoch: 5| Step: 5
Training loss: 2.444922370380352
Validation loss: 2.4821170886898645

Epoch: 5| Step: 6
Training loss: 1.8297159168307278
Validation loss: 2.4919056389204504

Epoch: 5| Step: 7
Training loss: 2.330984931992017
Validation loss: 2.4911907478849273

Epoch: 5| Step: 8
Training loss: 1.7278233407988437
Validation loss: 2.4870011506765004

Epoch: 5| Step: 9
Training loss: 3.014339983612366
Validation loss: 2.492168342731951

Epoch: 5| Step: 10
Training loss: 2.8009070630192974
Validation loss: 2.4879796011477944

Epoch: 5| Step: 11
Training loss: 2.2679608110005725
Validation loss: 2.4889388919589477

Epoch: 212| Step: 0
Training loss: 2.7914039336354266
Validation loss: 2.4941100833370093

Epoch: 5| Step: 1
Training loss: 2.72140662524511
Validation loss: 2.5094199450922665

Epoch: 5| Step: 2
Training loss: 2.210172918640473
Validation loss: 2.5043189412395725

Epoch: 5| Step: 3
Training loss: 2.851550125722295
Validation loss: 2.511368457658011

Epoch: 5| Step: 4
Training loss: 2.1049607040833003
Validation loss: 2.5260465084435904

Epoch: 5| Step: 5
Training loss: 2.399225062191509
Validation loss: 2.5338226517654547

Epoch: 5| Step: 6
Training loss: 2.6320888532232734
Validation loss: 2.5231673388345963

Epoch: 5| Step: 7
Training loss: 2.3977974401065945
Validation loss: 2.510358712146027

Epoch: 5| Step: 8
Training loss: 2.039908982471718
Validation loss: 2.519675999310449

Epoch: 5| Step: 9
Training loss: 2.225274392685473
Validation loss: 2.499167216195859

Epoch: 5| Step: 10
Training loss: 2.549074031031647
Validation loss: 2.5058304013692965

Epoch: 5| Step: 11
Training loss: 0.8213309369201915
Validation loss: 2.5044929741392608

Epoch: 213| Step: 0
Training loss: 2.027024554517458
Validation loss: 2.503934156844554

Epoch: 5| Step: 1
Training loss: 2.5976261452672844
Validation loss: 2.4929542039785364

Epoch: 5| Step: 2
Training loss: 2.0966836674318885
Validation loss: 2.4997780423180287

Epoch: 5| Step: 3
Training loss: 2.6774311853963604
Validation loss: 2.501059538112618

Epoch: 5| Step: 4
Training loss: 2.953707360061974
Validation loss: 2.495651321323279

Epoch: 5| Step: 5
Training loss: 2.68235845883858
Validation loss: 2.5035994843193095

Epoch: 5| Step: 6
Training loss: 1.6012455324204453
Validation loss: 2.495675136942412

Epoch: 5| Step: 7
Training loss: 2.7712925312940797
Validation loss: 2.4927442879374655

Epoch: 5| Step: 8
Training loss: 2.3198373224510203
Validation loss: 2.5015097907011548

Epoch: 5| Step: 9
Training loss: 2.448884737398183
Validation loss: 2.4990829852235588

Epoch: 5| Step: 10
Training loss: 2.393334741653977
Validation loss: 2.501537652798704

Epoch: 5| Step: 11
Training loss: 1.8712042216458429
Validation loss: 2.505692291834209

Epoch: 214| Step: 0
Training loss: 2.1931781642989394
Validation loss: 2.496722341715891

Epoch: 5| Step: 1
Training loss: 2.1855538566689203
Validation loss: 2.5137523330976097

Epoch: 5| Step: 2
Training loss: 1.9463474324264445
Validation loss: 2.5202966399855575

Epoch: 5| Step: 3
Training loss: 2.436173493782633
Validation loss: 2.5291622288040196

Epoch: 5| Step: 4
Training loss: 2.887619848365064
Validation loss: 2.5271152391068

Epoch: 5| Step: 5
Training loss: 2.5239469881914003
Validation loss: 2.5509209412066887

Epoch: 5| Step: 6
Training loss: 2.9264177717358546
Validation loss: 2.560753451970845

Epoch: 5| Step: 7
Training loss: 2.708492704739745
Validation loss: 2.5626549092432263

Epoch: 5| Step: 8
Training loss: 2.593979239387347
Validation loss: 2.560535592860069

Epoch: 5| Step: 9
Training loss: 2.0744231100040436
Validation loss: 2.5485108237727423

Epoch: 5| Step: 10
Training loss: 2.3658259035616154
Validation loss: 2.525893461985706

Epoch: 5| Step: 11
Training loss: 1.8281926199641898
Validation loss: 2.5145278378304288

Epoch: 215| Step: 0
Training loss: 2.3572568164046803
Validation loss: 2.5073481334819836

Epoch: 5| Step: 1
Training loss: 2.308719638032066
Validation loss: 2.4985092128937256

Epoch: 5| Step: 2
Training loss: 2.0706280161993673
Validation loss: 2.486626830116432

Epoch: 5| Step: 3
Training loss: 2.183119720705968
Validation loss: 2.4921797430382115

Epoch: 5| Step: 4
Training loss: 2.13151147306801
Validation loss: 2.4957703294799507

Epoch: 5| Step: 5
Training loss: 2.7768411731569995
Validation loss: 2.492593610594188

Epoch: 5| Step: 6
Training loss: 2.4939091873032146
Validation loss: 2.486561462848302

Epoch: 5| Step: 7
Training loss: 2.9410591477948276
Validation loss: 2.4962389351057213

Epoch: 5| Step: 8
Training loss: 2.2294577530329196
Validation loss: 2.490900773783575

Epoch: 5| Step: 9
Training loss: 2.777513544442761
Validation loss: 2.4901213018139905

Epoch: 5| Step: 10
Training loss: 2.748813199665054
Validation loss: 2.489718305182443

Epoch: 5| Step: 11
Training loss: 2.6402003381315535
Validation loss: 2.493981858440128

Epoch: 216| Step: 0
Training loss: 2.181957088730332
Validation loss: 2.496394563636312

Epoch: 5| Step: 1
Training loss: 2.334099496212926
Validation loss: 2.5043306511764283

Epoch: 5| Step: 2
Training loss: 1.934862495090658
Validation loss: 2.4907338717288576

Epoch: 5| Step: 3
Training loss: 2.4216395109806452
Validation loss: 2.505939390193913

Epoch: 5| Step: 4
Training loss: 2.3158629425158272
Validation loss: 2.505723572458289

Epoch: 5| Step: 5
Training loss: 2.620464402892856
Validation loss: 2.5279906406543704

Epoch: 5| Step: 6
Training loss: 2.795604907585549
Validation loss: 2.521826845171772

Epoch: 5| Step: 7
Training loss: 2.611626846928492
Validation loss: 2.5173154288929975

Epoch: 5| Step: 8
Training loss: 2.452723573532415
Validation loss: 2.5274167096997484

Epoch: 5| Step: 9
Training loss: 2.2158043878890084
Validation loss: 2.504679369581087

Epoch: 5| Step: 10
Training loss: 2.8496023469541503
Validation loss: 2.5102099667265025

Epoch: 5| Step: 11
Training loss: 1.9004919293680622
Validation loss: 2.500646521496265

Epoch: 217| Step: 0
Training loss: 2.2121374964757976
Validation loss: 2.517297295532483

Epoch: 5| Step: 1
Training loss: 2.869967160452397
Validation loss: 2.4990188918594733

Epoch: 5| Step: 2
Training loss: 2.5753838040136996
Validation loss: 2.4938927280561427

Epoch: 5| Step: 3
Training loss: 2.4866521224175253
Validation loss: 2.5063481279158815

Epoch: 5| Step: 4
Training loss: 2.0947325948703934
Validation loss: 2.498431092938543

Epoch: 5| Step: 5
Training loss: 2.858267647866165
Validation loss: 2.4956042944608634

Epoch: 5| Step: 6
Training loss: 2.444507990598737
Validation loss: 2.4979080666676903

Epoch: 5| Step: 7
Training loss: 2.1563184423226844
Validation loss: 2.502559777910476

Epoch: 5| Step: 8
Training loss: 2.024533243898913
Validation loss: 2.5026495403790423

Epoch: 5| Step: 9
Training loss: 2.1459895944334177
Validation loss: 2.509455141883547

Epoch: 5| Step: 10
Training loss: 2.3868172433262567
Validation loss: 2.510894889446255

Epoch: 5| Step: 11
Training loss: 1.7302360292071013
Validation loss: 2.508737965725842

Epoch: 218| Step: 0
Training loss: 1.9059444870565063
Validation loss: 2.506415071862107

Epoch: 5| Step: 1
Training loss: 2.394438052580706
Validation loss: 2.506184537766733

Epoch: 5| Step: 2
Training loss: 2.615149589913455
Validation loss: 2.517334430304722

Epoch: 5| Step: 3
Training loss: 2.086859681380842
Validation loss: 2.5088022245816908

Epoch: 5| Step: 4
Training loss: 1.697828403667332
Validation loss: 2.525201312937809

Epoch: 5| Step: 5
Training loss: 1.8228397752803163
Validation loss: 2.5114078042511214

Epoch: 5| Step: 6
Training loss: 3.0545463822103307
Validation loss: 2.507526290263841

Epoch: 5| Step: 7
Training loss: 2.911189322193478
Validation loss: 2.511368176806483

Epoch: 5| Step: 8
Training loss: 2.5788644366036673
Validation loss: 2.5165006720723095

Epoch: 5| Step: 9
Training loss: 2.7410287174751002
Validation loss: 2.5039683040203817

Epoch: 5| Step: 10
Training loss: 2.2307486817756716
Validation loss: 2.497112486155814

Epoch: 5| Step: 11
Training loss: 2.3815978909976168
Validation loss: 2.502970873389286

Epoch: 219| Step: 0
Training loss: 2.2252041069452297
Validation loss: 2.4912687060911853

Epoch: 5| Step: 1
Training loss: 2.9776200946254847
Validation loss: 2.506263995587345

Epoch: 5| Step: 2
Training loss: 2.4343400671121143
Validation loss: 2.5129844201699596

Epoch: 5| Step: 3
Training loss: 1.8011425921827726
Validation loss: 2.5213865127700306

Epoch: 5| Step: 4
Training loss: 2.7423396489463348
Validation loss: 2.509977085887883

Epoch: 5| Step: 5
Training loss: 1.8670657449393429
Validation loss: 2.5204359022383858

Epoch: 5| Step: 6
Training loss: 1.874874683006998
Validation loss: 2.507344454764448

Epoch: 5| Step: 7
Training loss: 2.5416060164255816
Validation loss: 2.507060785021533

Epoch: 5| Step: 8
Training loss: 2.556504562872238
Validation loss: 2.5116866699511515

Epoch: 5| Step: 9
Training loss: 2.3326115740782223
Validation loss: 2.506696442805977

Epoch: 5| Step: 10
Training loss: 2.8271244028285354
Validation loss: 2.5094902471330167

Epoch: 5| Step: 11
Training loss: 1.343051418314289
Validation loss: 2.51715407093787

Epoch: 220| Step: 0
Training loss: 2.4154612615247038
Validation loss: 2.5007543180843395

Epoch: 5| Step: 1
Training loss: 2.2498658458134155
Validation loss: 2.501249603059843

Epoch: 5| Step: 2
Training loss: 2.645329545084999
Validation loss: 2.4954339271163333

Epoch: 5| Step: 3
Training loss: 2.205694012922871
Validation loss: 2.4978480455031424

Epoch: 5| Step: 4
Training loss: 2.4397698617496695
Validation loss: 2.491433614550849

Epoch: 5| Step: 5
Training loss: 2.2608282414777507
Validation loss: 2.4865683064767103

Epoch: 5| Step: 6
Training loss: 2.426391819578091
Validation loss: 2.479558486322538

Epoch: 5| Step: 7
Training loss: 2.5117994328142594
Validation loss: 2.4899045159775106

Epoch: 5| Step: 8
Training loss: 2.5520007269329126
Validation loss: 2.503828982838763

Epoch: 5| Step: 9
Training loss: 2.220352346450652
Validation loss: 2.509319704174172

Epoch: 5| Step: 10
Training loss: 2.356269358750206
Validation loss: 2.482286859257683

Epoch: 5| Step: 11
Training loss: 3.35995151984344
Validation loss: 2.504716477253254

Epoch: 221| Step: 0
Training loss: 1.687008256260014
Validation loss: 2.5062012611400193

Epoch: 5| Step: 1
Training loss: 2.358129412548103
Validation loss: 2.4898069705566743

Epoch: 5| Step: 2
Training loss: 2.2535827510342896
Validation loss: 2.4915052853400064

Epoch: 5| Step: 3
Training loss: 2.852823391501932
Validation loss: 2.4859605563932963

Epoch: 5| Step: 4
Training loss: 1.9428196756673106
Validation loss: 2.4938945643908825

Epoch: 5| Step: 5
Training loss: 2.295695722255484
Validation loss: 2.4896174365997155

Epoch: 5| Step: 6
Training loss: 1.9899236644308347
Validation loss: 2.4921148203871986

Epoch: 5| Step: 7
Training loss: 2.9485103337399696
Validation loss: 2.5071801034925327

Epoch: 5| Step: 8
Training loss: 2.426778836993936
Validation loss: 2.507678126362667

Epoch: 5| Step: 9
Training loss: 2.587934109304478
Validation loss: 2.5072038254500932

Epoch: 5| Step: 10
Training loss: 2.8479479311994527
Validation loss: 2.508593005038974

Epoch: 5| Step: 11
Training loss: 1.5424288420748555
Validation loss: 2.5091043909905486

Epoch: 222| Step: 0
Training loss: 2.065389978193931
Validation loss: 2.522012965916337

Epoch: 5| Step: 1
Training loss: 2.5664374641366616
Validation loss: 2.522414536491798

Epoch: 5| Step: 2
Training loss: 2.675143022368059
Validation loss: 2.516854153737743

Epoch: 5| Step: 3
Training loss: 2.113635810822147
Validation loss: 2.5057612117689168

Epoch: 5| Step: 4
Training loss: 1.6736299804777504
Validation loss: 2.514421783405227

Epoch: 5| Step: 5
Training loss: 2.542234065608838
Validation loss: 2.5118501627841736

Epoch: 5| Step: 6
Training loss: 2.6546539897274335
Validation loss: 2.501308337231426

Epoch: 5| Step: 7
Training loss: 2.7157812462074697
Validation loss: 2.5063623888306226

Epoch: 5| Step: 8
Training loss: 2.46497819778674
Validation loss: 2.4853392834912786

Epoch: 5| Step: 9
Training loss: 2.0414225633497147
Validation loss: 2.49511118749406

Epoch: 5| Step: 10
Training loss: 2.538715139250179
Validation loss: 2.476158574454681

Epoch: 5| Step: 11
Training loss: 3.3245285732529055
Validation loss: 2.493019895747205

Epoch: 223| Step: 0
Training loss: 2.5891548725011386
Validation loss: 2.4980660428605974

Epoch: 5| Step: 1
Training loss: 2.630179970969192
Validation loss: 2.4970566907463163

Epoch: 5| Step: 2
Training loss: 1.918831066195968
Validation loss: 2.5068651511443396

Epoch: 5| Step: 3
Training loss: 2.526998646683325
Validation loss: 2.5087815706946253

Epoch: 5| Step: 4
Training loss: 2.3685485150242713
Validation loss: 2.5068858168577934

Epoch: 5| Step: 5
Training loss: 1.9890722114224026
Validation loss: 2.493562209596381

Epoch: 5| Step: 6
Training loss: 2.128448717140679
Validation loss: 2.509135235139076

Epoch: 5| Step: 7
Training loss: 2.7008774073495543
Validation loss: 2.5241484531195915

Epoch: 5| Step: 8
Training loss: 2.5389137576624488
Validation loss: 2.5104658127296635

Epoch: 5| Step: 9
Training loss: 2.6255730503012598
Validation loss: 2.536455245802695

Epoch: 5| Step: 10
Training loss: 2.2978880847341934
Validation loss: 2.5212264161716145

Epoch: 5| Step: 11
Training loss: 1.8800904790938833
Validation loss: 2.5246930517296233

Epoch: 224| Step: 0
Training loss: 2.4017267690952426
Validation loss: 2.511345071716139

Epoch: 5| Step: 1
Training loss: 1.822583267967957
Validation loss: 2.514937502348031

Epoch: 5| Step: 2
Training loss: 2.406388018724615
Validation loss: 2.52158754799067

Epoch: 5| Step: 3
Training loss: 2.1914399768321524
Validation loss: 2.512809619361881

Epoch: 5| Step: 4
Training loss: 2.133762022497435
Validation loss: 2.5260360416205523

Epoch: 5| Step: 5
Training loss: 2.476396043640782
Validation loss: 2.520701540241958

Epoch: 5| Step: 6
Training loss: 2.794879990323169
Validation loss: 2.518144151790425

Epoch: 5| Step: 7
Training loss: 2.5436766967708992
Validation loss: 2.518148672769466

Epoch: 5| Step: 8
Training loss: 2.7210314594316163
Validation loss: 2.4955758565918367

Epoch: 5| Step: 9
Training loss: 2.6398797422531106
Validation loss: 2.487806461535979

Epoch: 5| Step: 10
Training loss: 1.8412809488734538
Validation loss: 2.485507107347154

Epoch: 5| Step: 11
Training loss: 2.8900954302703115
Validation loss: 2.483707442255798

Epoch: 225| Step: 0
Training loss: 2.448952595000776
Validation loss: 2.498938561653217

Epoch: 5| Step: 1
Training loss: 1.7685348029364274
Validation loss: 2.4766268476115005

Epoch: 5| Step: 2
Training loss: 2.7111395944686802
Validation loss: 2.4875973390898425

Epoch: 5| Step: 3
Training loss: 2.8100885013476877
Validation loss: 2.4875497666049955

Epoch: 5| Step: 4
Training loss: 2.0599167569942844
Validation loss: 2.4764996268938773

Epoch: 5| Step: 5
Training loss: 2.5349197159794197
Validation loss: 2.4933851427693745

Epoch: 5| Step: 6
Training loss: 2.5329254633512344
Validation loss: 2.4979636641008556

Epoch: 5| Step: 7
Training loss: 2.3082398015799614
Validation loss: 2.489687356145641

Epoch: 5| Step: 8
Training loss: 2.419869854162406
Validation loss: 2.510044332780205

Epoch: 5| Step: 9
Training loss: 2.2021326305557967
Validation loss: 2.509821355574493

Epoch: 5| Step: 10
Training loss: 2.3858000490258786
Validation loss: 2.517769197878603

Epoch: 5| Step: 11
Training loss: 3.155217067789956
Validation loss: 2.519152145055756

Epoch: 226| Step: 0
Training loss: 2.5680786443533976
Validation loss: 2.529250532631527

Epoch: 5| Step: 1
Training loss: 2.5357335260685954
Validation loss: 2.5753420982145854

Epoch: 5| Step: 2
Training loss: 2.582154425425715
Validation loss: 2.5702939540112784

Epoch: 5| Step: 3
Training loss: 3.0925763919310385
Validation loss: 2.565486931038158

Epoch: 5| Step: 4
Training loss: 2.787396272516971
Validation loss: 2.533336611377536

Epoch: 5| Step: 5
Training loss: 2.4974279524269516
Validation loss: 2.5123044799845724

Epoch: 5| Step: 6
Training loss: 2.3922908190062127
Validation loss: 2.505385296784495

Epoch: 5| Step: 7
Training loss: 2.349113837012669
Validation loss: 2.487001406318861

Epoch: 5| Step: 8
Training loss: 2.0050534539457874
Validation loss: 2.483443247412961

Epoch: 5| Step: 9
Training loss: 1.9234947884005373
Validation loss: 2.49579281851014

Epoch: 5| Step: 10
Training loss: 2.3742431639369763
Validation loss: 2.475644973562593

Epoch: 5| Step: 11
Training loss: 1.690787539187076
Validation loss: 2.477645472776377

Epoch: 227| Step: 0
Training loss: 2.311725693022218
Validation loss: 2.476322840377192

Epoch: 5| Step: 1
Training loss: 2.455039085496587
Validation loss: 2.4746555282917426

Epoch: 5| Step: 2
Training loss: 2.6475675611367677
Validation loss: 2.4705373514925517

Epoch: 5| Step: 3
Training loss: 3.11685308895055
Validation loss: 2.4845861669082088

Epoch: 5| Step: 4
Training loss: 2.043362931394463
Validation loss: 2.47489482755721

Epoch: 5| Step: 5
Training loss: 2.3997520795563365
Validation loss: 2.478326391957748

Epoch: 5| Step: 6
Training loss: 2.64168965021799
Validation loss: 2.479661865358268

Epoch: 5| Step: 7
Training loss: 2.5176272746305446
Validation loss: 2.493018686369634

Epoch: 5| Step: 8
Training loss: 2.308811442120936
Validation loss: 2.4917595156037606

Epoch: 5| Step: 9
Training loss: 1.7233587030846713
Validation loss: 2.510856650537834

Epoch: 5| Step: 10
Training loss: 2.550320033018011
Validation loss: 2.5128051876117796

Epoch: 5| Step: 11
Training loss: 1.5193666501366967
Validation loss: 2.514962636336397

Epoch: 228| Step: 0
Training loss: 2.4940073669251372
Validation loss: 2.517465522325462

Epoch: 5| Step: 1
Training loss: 2.195253093092164
Validation loss: 2.521810532683018

Epoch: 5| Step: 2
Training loss: 2.262849251783602
Validation loss: 2.510660434036332

Epoch: 5| Step: 3
Training loss: 2.4759273256042036
Validation loss: 2.5110526815922034

Epoch: 5| Step: 4
Training loss: 3.163358332136908
Validation loss: 2.5117436156122297

Epoch: 5| Step: 5
Training loss: 2.0757687626794374
Validation loss: 2.507352075666566

Epoch: 5| Step: 6
Training loss: 1.9534174585725537
Validation loss: 2.512751614606629

Epoch: 5| Step: 7
Training loss: 2.403884815198605
Validation loss: 2.490316946617915

Epoch: 5| Step: 8
Training loss: 2.4468558319237443
Validation loss: 2.50841043302048

Epoch: 5| Step: 9
Training loss: 2.4005016676792295
Validation loss: 2.50915342550628

Epoch: 5| Step: 10
Training loss: 2.663220224887074
Validation loss: 2.497254513165313

Epoch: 5| Step: 11
Training loss: 1.1750104538472799
Validation loss: 2.500718663155536

Epoch: 229| Step: 0
Training loss: 2.558814864759754
Validation loss: 2.5062545976097192

Epoch: 5| Step: 1
Training loss: 3.1923121610509444
Validation loss: 2.5120866544630585

Epoch: 5| Step: 2
Training loss: 2.469507221996856
Validation loss: 2.4980265656561067

Epoch: 5| Step: 3
Training loss: 2.0754664344949867
Validation loss: 2.4978039633104996

Epoch: 5| Step: 4
Training loss: 2.2944478815692877
Validation loss: 2.4980453200903363

Epoch: 5| Step: 5
Training loss: 1.9105169973648097
Validation loss: 2.4998429845139603

Epoch: 5| Step: 6
Training loss: 2.1816282758645005
Validation loss: 2.5140238221336455

Epoch: 5| Step: 7
Training loss: 2.524578674970242
Validation loss: 2.526093772796475

Epoch: 5| Step: 8
Training loss: 2.602963182198484
Validation loss: 2.5368421833321375

Epoch: 5| Step: 9
Training loss: 2.047293118003123
Validation loss: 2.512066162035081

Epoch: 5| Step: 10
Training loss: 2.291479299572897
Validation loss: 2.509857251267279

Epoch: 5| Step: 11
Training loss: 1.8744375656894647
Validation loss: 2.500801132903287

Epoch: 230| Step: 0
Training loss: 2.417207909407262
Validation loss: 2.5047778092077455

Epoch: 5| Step: 1
Training loss: 2.5646499360704538
Validation loss: 2.506886296347876

Epoch: 5| Step: 2
Training loss: 2.1355428022642706
Validation loss: 2.5122351582753355

Epoch: 5| Step: 3
Training loss: 2.2681896558109473
Validation loss: 2.499920323214829

Epoch: 5| Step: 4
Training loss: 2.382407932644121
Validation loss: 2.490519751858154

Epoch: 5| Step: 5
Training loss: 2.5890597484438174
Validation loss: 2.4984180889445167

Epoch: 5| Step: 6
Training loss: 2.0462608289577733
Validation loss: 2.499883804005173

Epoch: 5| Step: 7
Training loss: 2.2348041255723716
Validation loss: 2.4983106110561484

Epoch: 5| Step: 8
Training loss: 2.1660250912073353
Validation loss: 2.5004776736725183

Epoch: 5| Step: 9
Training loss: 2.5981192498858086
Validation loss: 2.517021458976739

Epoch: 5| Step: 10
Training loss: 2.8088284581443372
Validation loss: 2.515615123626719

Epoch: 5| Step: 11
Training loss: 2.6244914152557675
Validation loss: 2.531123711532121

Epoch: 231| Step: 0
Training loss: 2.816217127784652
Validation loss: 2.5287669094235006

Epoch: 5| Step: 1
Training loss: 2.151040348917732
Validation loss: 2.5310790039514623

Epoch: 5| Step: 2
Training loss: 2.12062182717686
Validation loss: 2.5482924364919484

Epoch: 5| Step: 3
Training loss: 2.2523852526770485
Validation loss: 2.534859201498264

Epoch: 5| Step: 4
Training loss: 2.1055363518614465
Validation loss: 2.515889005846336

Epoch: 5| Step: 5
Training loss: 2.8205493605632106
Validation loss: 2.5032638384302768

Epoch: 5| Step: 6
Training loss: 2.45934978312224
Validation loss: 2.493475984514702

Epoch: 5| Step: 7
Training loss: 2.497220974324157
Validation loss: 2.475829127177703

Epoch: 5| Step: 8
Training loss: 2.7254446629288323
Validation loss: 2.4938061877543856

Epoch: 5| Step: 9
Training loss: 2.4941681551926194
Validation loss: 2.4891481910414095

Epoch: 5| Step: 10
Training loss: 1.8050442958056616
Validation loss: 2.477003834386883

Epoch: 5| Step: 11
Training loss: 1.9372165841806792
Validation loss: 2.4863697776691644

Epoch: 232| Step: 0
Training loss: 2.165239034940525
Validation loss: 2.483260680555743

Epoch: 5| Step: 1
Training loss: 2.314787377795342
Validation loss: 2.47779104925839

Epoch: 5| Step: 2
Training loss: 2.2786333937532475
Validation loss: 2.490656179969226

Epoch: 5| Step: 3
Training loss: 2.818897854126593
Validation loss: 2.48643672013741

Epoch: 5| Step: 4
Training loss: 3.0299701938485057
Validation loss: 2.4850626899402752

Epoch: 5| Step: 5
Training loss: 2.1343740259394512
Validation loss: 2.4836822879573734

Epoch: 5| Step: 6
Training loss: 2.629311608270543
Validation loss: 2.486551830599174

Epoch: 5| Step: 7
Training loss: 1.6539649315083509
Validation loss: 2.4931644928300893

Epoch: 5| Step: 8
Training loss: 2.073857795070531
Validation loss: 2.502471481018465

Epoch: 5| Step: 9
Training loss: 2.577461758467723
Validation loss: 2.5130671376654976

Epoch: 5| Step: 10
Training loss: 2.4408002177508124
Validation loss: 2.5185650808892253

Epoch: 5| Step: 11
Training loss: 3.8215499777155517
Validation loss: 2.52560157219382

Epoch: 233| Step: 0
Training loss: 2.0619539636232926
Validation loss: 2.5464770741462157

Epoch: 5| Step: 1
Training loss: 2.5639132812522614
Validation loss: 2.538614990705262

Epoch: 5| Step: 2
Training loss: 2.468546412318494
Validation loss: 2.5258022011319516

Epoch: 5| Step: 3
Training loss: 2.218758811395906
Validation loss: 2.5276350652374413

Epoch: 5| Step: 4
Training loss: 1.9749794150136815
Validation loss: 2.5261412112623027

Epoch: 5| Step: 5
Training loss: 2.2676480436101016
Validation loss: 2.5078632195118122

Epoch: 5| Step: 6
Training loss: 2.6503742529546837
Validation loss: 2.4976099669641076

Epoch: 5| Step: 7
Training loss: 1.7939145454671463
Validation loss: 2.4957987094084486

Epoch: 5| Step: 8
Training loss: 2.6650140131426294
Validation loss: 2.5014979722490516

Epoch: 5| Step: 9
Training loss: 2.6091941725155134
Validation loss: 2.4963440946145914

Epoch: 5| Step: 10
Training loss: 2.9314301457795238
Validation loss: 2.5057705739343286

Epoch: 5| Step: 11
Training loss: 2.468683555771204
Validation loss: 2.4808116805947296

Epoch: 234| Step: 0
Training loss: 1.9959758566961465
Validation loss: 2.4971788343256054

Epoch: 5| Step: 1
Training loss: 2.2528667201389694
Validation loss: 2.504121311927986

Epoch: 5| Step: 2
Training loss: 2.6478120408496166
Validation loss: 2.502810067165991

Epoch: 5| Step: 3
Training loss: 1.8105682733911124
Validation loss: 2.500469795431357

Epoch: 5| Step: 4
Training loss: 2.3045490805228197
Validation loss: 2.511528704045133

Epoch: 5| Step: 5
Training loss: 2.6581616871425777
Validation loss: 2.4929551284690463

Epoch: 5| Step: 6
Training loss: 3.011763397954559
Validation loss: 2.506222941109062

Epoch: 5| Step: 7
Training loss: 2.3031192939925713
Validation loss: 2.4999833146174253

Epoch: 5| Step: 8
Training loss: 2.169640358862316
Validation loss: 2.4973262257400592

Epoch: 5| Step: 9
Training loss: 2.1479340674370433
Validation loss: 2.497708108503019

Epoch: 5| Step: 10
Training loss: 2.7675893240885796
Validation loss: 2.506994125790327

Epoch: 5| Step: 11
Training loss: 1.2705603551299056
Validation loss: 2.486972750244385

Epoch: 235| Step: 0
Training loss: 2.165240356282894
Validation loss: 2.50180168596836

Epoch: 5| Step: 1
Training loss: 2.9873048471211954
Validation loss: 2.4940061640011932

Epoch: 5| Step: 2
Training loss: 2.320346716426218
Validation loss: 2.4933044338293944

Epoch: 5| Step: 3
Training loss: 2.544931430754796
Validation loss: 2.5007459878545784

Epoch: 5| Step: 4
Training loss: 2.043302023784147
Validation loss: 2.5058379911965747

Epoch: 5| Step: 5
Training loss: 2.2271165660332986
Validation loss: 2.5035528567398626

Epoch: 5| Step: 6
Training loss: 2.373108562405522
Validation loss: 2.4991080640104095

Epoch: 5| Step: 7
Training loss: 2.5101565045505922
Validation loss: 2.5193553321005693

Epoch: 5| Step: 8
Training loss: 2.310241627462007
Validation loss: 2.52080547827051

Epoch: 5| Step: 9
Training loss: 1.751449393466667
Validation loss: 2.5252510734407028

Epoch: 5| Step: 10
Training loss: 2.5093598627795406
Validation loss: 2.507751028351308

Epoch: 5| Step: 11
Training loss: 3.411176985381753
Validation loss: 2.5105912153151713

Epoch: 236| Step: 0
Training loss: 2.209215120090929
Validation loss: 2.5110572707249643

Epoch: 5| Step: 1
Training loss: 1.9468788673521669
Validation loss: 2.525523662873677

Epoch: 5| Step: 2
Training loss: 2.4222536836947133
Validation loss: 2.5262459361015197

Epoch: 5| Step: 3
Training loss: 2.2252033569329814
Validation loss: 2.52924668742186

Epoch: 5| Step: 4
Training loss: 2.7016058384964117
Validation loss: 2.5209135339657847

Epoch: 5| Step: 5
Training loss: 2.009048378414592
Validation loss: 2.5297481728295947

Epoch: 5| Step: 6
Training loss: 2.6850619235436937
Validation loss: 2.5225301022461557

Epoch: 5| Step: 7
Training loss: 2.417261664270595
Validation loss: 2.532886615745804

Epoch: 5| Step: 8
Training loss: 2.3503627821731494
Validation loss: 2.5363299019405505

Epoch: 5| Step: 9
Training loss: 2.4599356413385265
Validation loss: 2.5140356528281274

Epoch: 5| Step: 10
Training loss: 2.4946336370973197
Validation loss: 2.51033782571372

Epoch: 5| Step: 11
Training loss: 2.3022756596888656
Validation loss: 2.5132062748034443

Epoch: 237| Step: 0
Training loss: 2.21081542631744
Validation loss: 2.519475063909917

Epoch: 5| Step: 1
Training loss: 3.0817626526654
Validation loss: 2.493797115288766

Epoch: 5| Step: 2
Training loss: 2.8857102961964527
Validation loss: 2.4958686150003184

Epoch: 5| Step: 3
Training loss: 2.1738126605118735
Validation loss: 2.4969372704562556

Epoch: 5| Step: 4
Training loss: 1.984066255835978
Validation loss: 2.494897160592583

Epoch: 5| Step: 5
Training loss: 2.361082760011089
Validation loss: 2.5021751160400743

Epoch: 5| Step: 6
Training loss: 2.6202206472130904
Validation loss: 2.4978536929310056

Epoch: 5| Step: 7
Training loss: 1.6803553473366144
Validation loss: 2.502823086047511

Epoch: 5| Step: 8
Training loss: 1.9814660685558088
Validation loss: 2.4861365237230673

Epoch: 5| Step: 9
Training loss: 2.581733998142393
Validation loss: 2.5008493768719116

Epoch: 5| Step: 10
Training loss: 2.2225930685975515
Validation loss: 2.505681325682675

Epoch: 5| Step: 11
Training loss: 2.497279403459956
Validation loss: 2.5031187234419647

Epoch: 238| Step: 0
Training loss: 2.4339262366296155
Validation loss: 2.5220259230910202

Epoch: 5| Step: 1
Training loss: 2.0045111563018363
Validation loss: 2.540586571678458

Epoch: 5| Step: 2
Training loss: 2.5878421649354264
Validation loss: 2.5410239952315083

Epoch: 5| Step: 3
Training loss: 2.295555929697028
Validation loss: 2.5761960876576397

Epoch: 5| Step: 4
Training loss: 2.314457966602267
Validation loss: 2.555763259223924

Epoch: 5| Step: 5
Training loss: 2.5215564247669913
Validation loss: 2.536751431888151

Epoch: 5| Step: 6
Training loss: 1.9146192714014965
Validation loss: 2.5237131785061613

Epoch: 5| Step: 7
Training loss: 2.154373236761431
Validation loss: 2.498528711190011

Epoch: 5| Step: 8
Training loss: 2.016034934770559
Validation loss: 2.4909083113920154

Epoch: 5| Step: 9
Training loss: 2.9389380323711616
Validation loss: 2.4898117085711178

Epoch: 5| Step: 10
Training loss: 2.8330737911353574
Validation loss: 2.5036097413973075

Epoch: 5| Step: 11
Training loss: 1.8816121814138846
Validation loss: 2.49149099121925

Epoch: 239| Step: 0
Training loss: 2.2497223576800556
Validation loss: 2.4901611097939895

Epoch: 5| Step: 1
Training loss: 2.9341257072723828
Validation loss: 2.50497930884937

Epoch: 5| Step: 2
Training loss: 2.1093692355607
Validation loss: 2.5087573845233075

Epoch: 5| Step: 3
Training loss: 2.786419725002071
Validation loss: 2.4930840237962903

Epoch: 5| Step: 4
Training loss: 2.555506863567858
Validation loss: 2.50280683625015

Epoch: 5| Step: 5
Training loss: 1.6888021460782885
Validation loss: 2.502004239237437

Epoch: 5| Step: 6
Training loss: 2.2726111729184835
Validation loss: 2.5174588889648475

Epoch: 5| Step: 7
Training loss: 2.1204410342540854
Validation loss: 2.523485748176195

Epoch: 5| Step: 8
Training loss: 2.182682836855252
Validation loss: 2.5271231974177546

Epoch: 5| Step: 9
Training loss: 2.2416182270512497
Validation loss: 2.5336017790055583

Epoch: 5| Step: 10
Training loss: 2.6455592716882887
Validation loss: 2.536278290726334

Epoch: 5| Step: 11
Training loss: 3.3992927264416437
Validation loss: 2.5374763268429783

Epoch: 240| Step: 0
Training loss: 2.1927186024864067
Validation loss: 2.5441082082813495

Epoch: 5| Step: 1
Training loss: 2.4443573960304597
Validation loss: 2.5299800033746584

Epoch: 5| Step: 2
Training loss: 2.4142349329724464
Validation loss: 2.5311985520836857

Epoch: 5| Step: 3
Training loss: 2.5914310982001334
Validation loss: 2.5295179037287565

Epoch: 5| Step: 4
Training loss: 2.6607034487334453
Validation loss: 2.5257001816427413

Epoch: 5| Step: 5
Training loss: 2.4400768841684224
Validation loss: 2.5102696804423377

Epoch: 5| Step: 6
Training loss: 2.19754197480926
Validation loss: 2.5071983456859455

Epoch: 5| Step: 7
Training loss: 1.9550443450113077
Validation loss: 2.5112088577257388

Epoch: 5| Step: 8
Training loss: 2.5059398659008623
Validation loss: 2.5282266402275493

Epoch: 5| Step: 9
Training loss: 2.6758516399842764
Validation loss: 2.509765047105458

Epoch: 5| Step: 10
Training loss: 1.798362381706109
Validation loss: 2.5240429013251635

Epoch: 5| Step: 11
Training loss: 3.338443859808089
Validation loss: 2.512620161988313

Epoch: 241| Step: 0
Training loss: 2.1722075941802514
Validation loss: 2.5232822500367806

Epoch: 5| Step: 1
Training loss: 2.309081773118642
Validation loss: 2.515017615813389

Epoch: 5| Step: 2
Training loss: 2.1312720915692585
Validation loss: 2.5259805665377346

Epoch: 5| Step: 3
Training loss: 2.1038731914859485
Validation loss: 2.52494808134202

Epoch: 5| Step: 4
Training loss: 2.3195308306273827
Validation loss: 2.533921170631118

Epoch: 5| Step: 5
Training loss: 2.0490069752207223
Validation loss: 2.5356023833799077

Epoch: 5| Step: 6
Training loss: 1.7211670959054464
Validation loss: 2.530459806546782

Epoch: 5| Step: 7
Training loss: 2.9109817870083683
Validation loss: 2.552477700391049

Epoch: 5| Step: 8
Training loss: 2.576686665982517
Validation loss: 2.5244776075224684

Epoch: 5| Step: 9
Training loss: 3.0126399154145074
Validation loss: 2.5200140832956555

Epoch: 5| Step: 10
Training loss: 2.5969606314265143
Validation loss: 2.5177705591098674

Epoch: 5| Step: 11
Training loss: 2.0994488038164185
Validation loss: 2.5052348959632154

Epoch: 242| Step: 0
Training loss: 2.147290398668373
Validation loss: 2.528141121956338

Epoch: 5| Step: 1
Training loss: 2.492396426636374
Validation loss: 2.5194189238830003

Epoch: 5| Step: 2
Training loss: 2.615106558151281
Validation loss: 2.523778417999457

Epoch: 5| Step: 3
Training loss: 1.9756354166906953
Validation loss: 2.535343600160396

Epoch: 5| Step: 4
Training loss: 2.2941086907017763
Validation loss: 2.534808745859806

Epoch: 5| Step: 5
Training loss: 1.9759469261107492
Validation loss: 2.517733288726634

Epoch: 5| Step: 6
Training loss: 1.9407628180913337
Validation loss: 2.513572190962686

Epoch: 5| Step: 7
Training loss: 2.2943549831746526
Validation loss: 2.5139807704224495

Epoch: 5| Step: 8
Training loss: 2.8267625087408303
Validation loss: 2.515961369837263

Epoch: 5| Step: 9
Training loss: 2.5278914033645887
Validation loss: 2.5254639754788824

Epoch: 5| Step: 10
Training loss: 2.922905887974509
Validation loss: 2.497318991923188

Epoch: 5| Step: 11
Training loss: 2.4453478923344787
Validation loss: 2.5145608673156143

Epoch: 243| Step: 0
Training loss: 2.5147385071854855
Validation loss: 2.5089189578203293

Epoch: 5| Step: 1
Training loss: 2.449939579121333
Validation loss: 2.51209935636267

Epoch: 5| Step: 2
Training loss: 2.1559370615447673
Validation loss: 2.512823582683973

Epoch: 5| Step: 3
Training loss: 2.1105132246256075
Validation loss: 2.5097457825585088

Epoch: 5| Step: 4
Training loss: 2.369706830752403
Validation loss: 2.517014327151322

Epoch: 5| Step: 5
Training loss: 2.5154188557387234
Validation loss: 2.52677903703221

Epoch: 5| Step: 6
Training loss: 2.339618551023742
Validation loss: 2.524971534077546

Epoch: 5| Step: 7
Training loss: 2.1021276231781023
Validation loss: 2.5286502281541017

Epoch: 5| Step: 8
Training loss: 2.132319466751775
Validation loss: 2.53465182512904

Epoch: 5| Step: 9
Training loss: 2.6290917975823413
Validation loss: 2.5503012695800655

Epoch: 5| Step: 10
Training loss: 2.420718796909996
Validation loss: 2.5341528311049326

Epoch: 5| Step: 11
Training loss: 3.2216147109524433
Validation loss: 2.5329275184729796

Epoch: 244| Step: 0
Training loss: 2.5349240424459385
Validation loss: 2.548743676044775

Epoch: 5| Step: 1
Training loss: 2.621738405727468
Validation loss: 2.554892206107918

Epoch: 5| Step: 2
Training loss: 2.779407791208466
Validation loss: 2.553003368492011

Epoch: 5| Step: 3
Training loss: 1.8260618125673211
Validation loss: 2.5533264804375455

Epoch: 5| Step: 4
Training loss: 1.9154949200074165
Validation loss: 2.5261464454444913

Epoch: 5| Step: 5
Training loss: 2.7516592395419606
Validation loss: 2.5258560617169583

Epoch: 5| Step: 6
Training loss: 2.095588104988149
Validation loss: 2.535034678345491

Epoch: 5| Step: 7
Training loss: 2.2898895540214816
Validation loss: 2.531910872822465

Epoch: 5| Step: 8
Training loss: 2.5249336460572955
Validation loss: 2.522973138936859

Epoch: 5| Step: 9
Training loss: 2.2227356264659845
Validation loss: 2.533158030582842

Epoch: 5| Step: 10
Training loss: 2.356597174609544
Validation loss: 2.5049465158949507

Epoch: 5| Step: 11
Training loss: 1.700947690923054
Validation loss: 2.5073669865770163

Epoch: 245| Step: 0
Training loss: 2.472560404626914
Validation loss: 2.514422142932702

Epoch: 5| Step: 1
Training loss: 2.4942738759554706
Validation loss: 2.4981179146486836

Epoch: 5| Step: 2
Training loss: 1.5938511236683761
Validation loss: 2.4830705529001498

Epoch: 5| Step: 3
Training loss: 2.2693945733573395
Validation loss: 2.488198111765613

Epoch: 5| Step: 4
Training loss: 2.4120181417779323
Validation loss: 2.4901540705878418

Epoch: 5| Step: 5
Training loss: 3.2940276808835045
Validation loss: 2.4945310736613417

Epoch: 5| Step: 6
Training loss: 2.495770691694255
Validation loss: 2.507632109431765

Epoch: 5| Step: 7
Training loss: 2.372636924466488
Validation loss: 2.5006727664437167

Epoch: 5| Step: 8
Training loss: 2.4856516119223246
Validation loss: 2.5177230063281657

Epoch: 5| Step: 9
Training loss: 2.5244780954765713
Validation loss: 2.513525697004226

Epoch: 5| Step: 10
Training loss: 1.8900851905636133
Validation loss: 2.5155987669088353

Epoch: 5| Step: 11
Training loss: 1.2866489819973261
Validation loss: 2.536383983506726

Epoch: 246| Step: 0
Training loss: 2.316147994107702
Validation loss: 2.5321631570143635

Epoch: 5| Step: 1
Training loss: 2.2530469396774975
Validation loss: 2.545790907687874

Epoch: 5| Step: 2
Training loss: 2.268009798556897
Validation loss: 2.5489074811603314

Epoch: 5| Step: 3
Training loss: 1.8211308551217402
Validation loss: 2.553945900372081

Epoch: 5| Step: 4
Training loss: 2.191211603397316
Validation loss: 2.5489186666686603

Epoch: 5| Step: 5
Training loss: 2.677339732042141
Validation loss: 2.5550771954601865

Epoch: 5| Step: 6
Training loss: 1.7750423748707156
Validation loss: 2.520447218042321

Epoch: 5| Step: 7
Training loss: 1.72448287620902
Validation loss: 2.526591857821375

Epoch: 5| Step: 8
Training loss: 2.9029683279214464
Validation loss: 2.506770696956383

Epoch: 5| Step: 9
Training loss: 2.9421815293748335
Validation loss: 2.505648264388006

Epoch: 5| Step: 10
Training loss: 2.788348622148108
Validation loss: 2.5131680710637228

Epoch: 5| Step: 11
Training loss: 2.724549783034466
Validation loss: 2.5143962311423182

Epoch: 247| Step: 0
Training loss: 1.7448254102793688
Validation loss: 2.510227731794442

Epoch: 5| Step: 1
Training loss: 2.1536100508374574
Validation loss: 2.493424328912139

Epoch: 5| Step: 2
Training loss: 2.5803503431455934
Validation loss: 2.509397784042961

Epoch: 5| Step: 3
Training loss: 2.398022544328537
Validation loss: 2.5090843334792954

Epoch: 5| Step: 4
Training loss: 2.8735590101627797
Validation loss: 2.504102888633338

Epoch: 5| Step: 5
Training loss: 2.101368494544858
Validation loss: 2.5077559681637793

Epoch: 5| Step: 6
Training loss: 2.6461424659499646
Validation loss: 2.5089170453728515

Epoch: 5| Step: 7
Training loss: 2.3341188016989056
Validation loss: 2.50221501611875

Epoch: 5| Step: 8
Training loss: 2.4492273163227387
Validation loss: 2.5145895309708983

Epoch: 5| Step: 9
Training loss: 2.2467705544507486
Validation loss: 2.5191169693886555

Epoch: 5| Step: 10
Training loss: 2.5766165279463262
Validation loss: 2.521388120264372

Epoch: 5| Step: 11
Training loss: 1.6564820325011145
Validation loss: 2.527500472007428

Epoch: 248| Step: 0
Training loss: 2.38064746993305
Validation loss: 2.5231382509465847

Epoch: 5| Step: 1
Training loss: 2.359331244258741
Validation loss: 2.535522316952004

Epoch: 5| Step: 2
Training loss: 2.4357201362414944
Validation loss: 2.5331030526611635

Epoch: 5| Step: 3
Training loss: 1.9235035269070035
Validation loss: 2.555502276510201

Epoch: 5| Step: 4
Training loss: 2.1211507378610017
Validation loss: 2.5457441553666054

Epoch: 5| Step: 5
Training loss: 2.1663276578319466
Validation loss: 2.5240961953198715

Epoch: 5| Step: 6
Training loss: 2.451990338952104
Validation loss: 2.532359280475363

Epoch: 5| Step: 7
Training loss: 2.6333285315586528
Validation loss: 2.556582584989981

Epoch: 5| Step: 8
Training loss: 2.577319210013136
Validation loss: 2.5531331348951056

Epoch: 5| Step: 9
Training loss: 2.121941328627215
Validation loss: 2.5436759703640197

Epoch: 5| Step: 10
Training loss: 2.839799253595263
Validation loss: 2.5153040078916673

Epoch: 5| Step: 11
Training loss: 1.869018423137619
Validation loss: 2.5377977556691955

Epoch: 249| Step: 0
Training loss: 2.8436745434486026
Validation loss: 2.5237958631966233

Epoch: 5| Step: 1
Training loss: 2.202717736660483
Validation loss: 2.530375828125797

Epoch: 5| Step: 2
Training loss: 2.8468765007542696
Validation loss: 2.5219631828826894

Epoch: 5| Step: 3
Training loss: 2.0433288606944253
Validation loss: 2.5236258736640913

Epoch: 5| Step: 4
Training loss: 3.0042449799875297
Validation loss: 2.5203114565748406

Epoch: 5| Step: 5
Training loss: 2.232570319525998
Validation loss: 2.547914739380859

Epoch: 5| Step: 6
Training loss: 2.5247880374586376
Validation loss: 2.5430875126402386

Epoch: 5| Step: 7
Training loss: 2.2894157683887117
Validation loss: 2.542343551107133

Epoch: 5| Step: 8
Training loss: 1.7597417120626588
Validation loss: 2.551902750334476

Epoch: 5| Step: 9
Training loss: 1.7837228842734678
Validation loss: 2.521954162470763

Epoch: 5| Step: 10
Training loss: 2.0827976555377563
Validation loss: 2.544445162019485

Epoch: 5| Step: 11
Training loss: 1.9924585494608364
Validation loss: 2.5228717039739097

Epoch: 250| Step: 0
Training loss: 2.719159851751537
Validation loss: 2.5179712715100795

Epoch: 5| Step: 1
Training loss: 2.436265877544244
Validation loss: 2.527136203079687

Epoch: 5| Step: 2
Training loss: 2.420853036175474
Validation loss: 2.52369011164727

Epoch: 5| Step: 3
Training loss: 1.9369214332334925
Validation loss: 2.523470265241711

Epoch: 5| Step: 4
Training loss: 2.9210319730843004
Validation loss: 2.5149990195417167

Epoch: 5| Step: 5
Training loss: 2.306792975295265
Validation loss: 2.5384796432152004

Epoch: 5| Step: 6
Training loss: 2.3524260598703166
Validation loss: 2.513333356856878

Epoch: 5| Step: 7
Training loss: 2.1342439982703083
Validation loss: 2.512708442259316

Epoch: 5| Step: 8
Training loss: 1.814557190570626
Validation loss: 2.519102808283554

Epoch: 5| Step: 9
Training loss: 2.6352337759937323
Validation loss: 2.5181845168238635

Epoch: 5| Step: 10
Training loss: 1.90685393975405
Validation loss: 2.5200119703376895

Epoch: 5| Step: 11
Training loss: 1.9202719725265662
Validation loss: 2.517053218443125

Epoch: 251| Step: 0
Training loss: 2.7985298759170227
Validation loss: 2.5219549936105037

Epoch: 5| Step: 1
Training loss: 2.6841827146075485
Validation loss: 2.5276387517609162

Epoch: 5| Step: 2
Training loss: 2.118904571746326
Validation loss: 2.5086627521051823

Epoch: 5| Step: 3
Training loss: 2.3281956604340968
Validation loss: 2.5081678873503988

Epoch: 5| Step: 4
Training loss: 2.5875856615712722
Validation loss: 2.5148154312534987

Epoch: 5| Step: 5
Training loss: 2.412951167321143
Validation loss: 2.5130916578890306

Epoch: 5| Step: 6
Training loss: 2.5255003254040025
Validation loss: 2.528416334764639

Epoch: 5| Step: 7
Training loss: 2.110379806251885
Validation loss: 2.5021099683649903

Epoch: 5| Step: 8
Training loss: 1.9266254052800476
Validation loss: 2.5009698734891597

Epoch: 5| Step: 9
Training loss: 2.3186633482008636
Validation loss: 2.515547437242171

Epoch: 5| Step: 10
Training loss: 1.7608597177218874
Validation loss: 2.5087869955242192

Epoch: 5| Step: 11
Training loss: 2.7410962142285262
Validation loss: 2.502210867334238

Epoch: 252| Step: 0
Training loss: 2.806686326665576
Validation loss: 2.4889121500900417

Epoch: 5| Step: 1
Training loss: 1.5941716552645686
Validation loss: 2.5029071713081126

Epoch: 5| Step: 2
Training loss: 2.1246168127699487
Validation loss: 2.494521249173032

Epoch: 5| Step: 3
Training loss: 2.5075018859734484
Validation loss: 2.5075498782110004

Epoch: 5| Step: 4
Training loss: 2.6325482425453504
Validation loss: 2.5109827318847304

Epoch: 5| Step: 5
Training loss: 2.350231212036492
Validation loss: 2.5385220387706626

Epoch: 5| Step: 6
Training loss: 2.1533094617782167
Validation loss: 2.5447681348360414

Epoch: 5| Step: 7
Training loss: 2.011538954913021
Validation loss: 2.5351947336748792

Epoch: 5| Step: 8
Training loss: 2.3293977880936914
Validation loss: 2.5361285664362883

Epoch: 5| Step: 9
Training loss: 2.118642947212828
Validation loss: 2.5512293314466477

Epoch: 5| Step: 10
Training loss: 2.8439265605066484
Validation loss: 2.5374184494350134

Epoch: 5| Step: 11
Training loss: 2.9456236495337254
Validation loss: 2.5535365826207386

Epoch: 253| Step: 0
Training loss: 2.487756311447913
Validation loss: 2.5545948140074013

Epoch: 5| Step: 1
Training loss: 2.0122083938397775
Validation loss: 2.55417086931249

Epoch: 5| Step: 2
Training loss: 2.2072653317166897
Validation loss: 2.5802365027501764

Epoch: 5| Step: 3
Training loss: 2.74180265589886
Validation loss: 2.591862675536552

Epoch: 5| Step: 4
Training loss: 2.306447743774652
Validation loss: 2.556116744518901

Epoch: 5| Step: 5
Training loss: 2.8733338213372166
Validation loss: 2.5377550250655565

Epoch: 5| Step: 6
Training loss: 2.5164504503586214
Validation loss: 2.5339657222162626

Epoch: 5| Step: 7
Training loss: 2.758489336594394
Validation loss: 2.5172184346131554

Epoch: 5| Step: 8
Training loss: 1.9462815900430437
Validation loss: 2.5108095147923026

Epoch: 5| Step: 9
Training loss: 1.7668996615286088
Validation loss: 2.4971884613869073

Epoch: 5| Step: 10
Training loss: 2.040519573765567
Validation loss: 2.5068448458747215

Epoch: 5| Step: 11
Training loss: 3.035178872985186
Validation loss: 2.5024001084308263

Epoch: 254| Step: 0
Training loss: 2.6099872898654657
Validation loss: 2.517346957740605

Epoch: 5| Step: 1
Training loss: 2.206712547854809
Validation loss: 2.5167652531339058

Epoch: 5| Step: 2
Training loss: 2.6031122031017517
Validation loss: 2.5132506244071373

Epoch: 5| Step: 3
Training loss: 2.233641817603741
Validation loss: 2.5188527733886352

Epoch: 5| Step: 4
Training loss: 2.2803022950529455
Validation loss: 2.5105996493901257

Epoch: 5| Step: 5
Training loss: 1.9467879372321193
Validation loss: 2.527548190637555

Epoch: 5| Step: 6
Training loss: 1.7091706092723282
Validation loss: 2.5418485605055863

Epoch: 5| Step: 7
Training loss: 2.6101780186886883
Validation loss: 2.544213603120186

Epoch: 5| Step: 8
Training loss: 2.248020254817682
Validation loss: 2.545120902877569

Epoch: 5| Step: 9
Training loss: 2.7829294170512675
Validation loss: 2.545947957359018

Epoch: 5| Step: 10
Training loss: 2.2199982906025673
Validation loss: 2.5394099814499596

Epoch: 5| Step: 11
Training loss: 2.633997890862596
Validation loss: 2.531583238180918

Epoch: 255| Step: 0
Training loss: 2.1106143277671956
Validation loss: 2.533935072503378

Epoch: 5| Step: 1
Training loss: 2.5646420341692395
Validation loss: 2.5302117459329265

Epoch: 5| Step: 2
Training loss: 2.381979274464211
Validation loss: 2.53907732250093

Epoch: 5| Step: 3
Training loss: 2.676650481105845
Validation loss: 2.5242077859388354

Epoch: 5| Step: 4
Training loss: 2.355022837372215
Validation loss: 2.521483338836213

Epoch: 5| Step: 5
Training loss: 2.093833580056954
Validation loss: 2.5220506476929043

Epoch: 5| Step: 6
Training loss: 2.4815110307118187
Validation loss: 2.5127675273039674

Epoch: 5| Step: 7
Training loss: 2.8287518054317524
Validation loss: 2.5248235983966745

Epoch: 5| Step: 8
Training loss: 2.0757893221536334
Validation loss: 2.5090779709466693

Epoch: 5| Step: 9
Training loss: 1.7336701344066212
Validation loss: 2.5272751631315957

Epoch: 5| Step: 10
Training loss: 2.279774332255709
Validation loss: 2.526469992015713

Epoch: 5| Step: 11
Training loss: 2.557594535176748
Validation loss: 2.5376510178988636

Epoch: 256| Step: 0
Training loss: 2.149225263956641
Validation loss: 2.541092488570179

Epoch: 5| Step: 1
Training loss: 2.697087419438922
Validation loss: 2.5517826538979027

Epoch: 5| Step: 2
Training loss: 1.985844706146463
Validation loss: 2.548347227055772

Epoch: 5| Step: 3
Training loss: 2.317654509758783
Validation loss: 2.5329855710514835

Epoch: 5| Step: 4
Training loss: 2.6493615982929777
Validation loss: 2.5427629511581533

Epoch: 5| Step: 5
Training loss: 2.174452096614499
Validation loss: 2.534271893205042

Epoch: 5| Step: 6
Training loss: 1.7767589906653165
Validation loss: 2.527696969035483

Epoch: 5| Step: 7
Training loss: 2.29642715759166
Validation loss: 2.5239747049386096

Epoch: 5| Step: 8
Training loss: 2.529793873860076
Validation loss: 2.526069787776716

Epoch: 5| Step: 9
Training loss: 2.6101533562633614
Validation loss: 2.5168561469888315

Epoch: 5| Step: 10
Training loss: 2.277856471348654
Validation loss: 2.5185652623294152

Epoch: 5| Step: 11
Training loss: 2.9630501087495045
Validation loss: 2.5194115110032573

Epoch: 257| Step: 0
Training loss: 2.286572452787828
Validation loss: 2.529933194470857

Epoch: 5| Step: 1
Training loss: 2.3282552593068986
Validation loss: 2.5397874667704756

Epoch: 5| Step: 2
Training loss: 3.0265636595732164
Validation loss: 2.522800786459648

Epoch: 5| Step: 3
Training loss: 2.652509591447493
Validation loss: 2.535390309176163

Epoch: 5| Step: 4
Training loss: 2.262791196514481
Validation loss: 2.5180524542476688

Epoch: 5| Step: 5
Training loss: 2.455793350907368
Validation loss: 2.528233595041546

Epoch: 5| Step: 6
Training loss: 2.291173592899563
Validation loss: 2.542927829083087

Epoch: 5| Step: 7
Training loss: 2.492133830577824
Validation loss: 2.534355750365556

Epoch: 5| Step: 8
Training loss: 1.8794760365502277
Validation loss: 2.5193626406533727

Epoch: 5| Step: 9
Training loss: 1.7094887648528736
Validation loss: 2.524607260300466

Epoch: 5| Step: 10
Training loss: 1.9022845938569208
Validation loss: 2.5313226548116914

Epoch: 5| Step: 11
Training loss: 2.8264222472458997
Validation loss: 2.5130722844419116

Epoch: 258| Step: 0
Training loss: 2.713351974641966
Validation loss: 2.510432778830418

Epoch: 5| Step: 1
Training loss: 1.7629062346754834
Validation loss: 2.513908784101476

Epoch: 5| Step: 2
Training loss: 2.3230462715246927
Validation loss: 2.5058545900231275

Epoch: 5| Step: 3
Training loss: 2.7754533345857895
Validation loss: 2.50676469710298

Epoch: 5| Step: 4
Training loss: 2.8480467142710144
Validation loss: 2.5232549469445553

Epoch: 5| Step: 5
Training loss: 1.8576084368181482
Validation loss: 2.513837874552364

Epoch: 5| Step: 6
Training loss: 2.215622430323737
Validation loss: 2.5138733809492173

Epoch: 5| Step: 7
Training loss: 2.208912059838088
Validation loss: 2.5092971245735187

Epoch: 5| Step: 8
Training loss: 2.69262260334972
Validation loss: 2.5257626500670494

Epoch: 5| Step: 9
Training loss: 2.4584542476422544
Validation loss: 2.538399415119279

Epoch: 5| Step: 10
Training loss: 1.710210009723662
Validation loss: 2.539594709909653

Epoch: 5| Step: 11
Training loss: 0.4267688112565599
Validation loss: 2.5554367467714454

Epoch: 259| Step: 0
Training loss: 2.3291387207138112
Validation loss: 2.548168376634187

Epoch: 5| Step: 1
Training loss: 2.110814712307744
Validation loss: 2.551067295363696

Epoch: 5| Step: 2
Training loss: 2.625626534668334
Validation loss: 2.5416941497963634

Epoch: 5| Step: 3
Training loss: 2.2083576368997875
Validation loss: 2.543778165181763

Epoch: 5| Step: 4
Training loss: 2.1337387812296607
Validation loss: 2.5330011605424376

Epoch: 5| Step: 5
Training loss: 1.9472958056407705
Validation loss: 2.531287416723177

Epoch: 5| Step: 6
Training loss: 2.7673844597465806
Validation loss: 2.5265083366947017

Epoch: 5| Step: 7
Training loss: 2.7284930807832963
Validation loss: 2.5280208319417317

Epoch: 5| Step: 8
Training loss: 2.7661461635429707
Validation loss: 2.5126328572372647

Epoch: 5| Step: 9
Training loss: 2.0245512618200263
Validation loss: 2.521906676757228

Epoch: 5| Step: 10
Training loss: 1.69304938377373
Validation loss: 2.522023965437342

Epoch: 5| Step: 11
Training loss: 2.675846293974497
Validation loss: 2.535727410615103

Epoch: 260| Step: 0
Training loss: 2.5055233974700326
Validation loss: 2.521087181824335

Epoch: 5| Step: 1
Training loss: 2.4260648847238477
Validation loss: 2.5244037364795258

Epoch: 5| Step: 2
Training loss: 2.5867499144257247
Validation loss: 2.533597030739469

Epoch: 5| Step: 3
Training loss: 2.6432748173622276
Validation loss: 2.534411943654805

Epoch: 5| Step: 4
Training loss: 2.2901529572556836
Validation loss: 2.538369159422701

Epoch: 5| Step: 5
Training loss: 2.152833969312606
Validation loss: 2.539572370149285

Epoch: 5| Step: 6
Training loss: 2.062631660651798
Validation loss: 2.5294516615470597

Epoch: 5| Step: 7
Training loss: 2.2254484903326293
Validation loss: 2.522065304300413

Epoch: 5| Step: 8
Training loss: 1.9912706846035704
Validation loss: 2.512194982363244

Epoch: 5| Step: 9
Training loss: 2.3995326024149977
Validation loss: 2.523138197794344

Epoch: 5| Step: 10
Training loss: 2.494737235625607
Validation loss: 2.526758537951896

Epoch: 5| Step: 11
Training loss: 1.1312327452128752
Validation loss: 2.518103154897912

Epoch: 261| Step: 0
Training loss: 2.86917386383061
Validation loss: 2.519178636898718

Epoch: 5| Step: 1
Training loss: 1.7251619207708613
Validation loss: 2.5098083334132673

Epoch: 5| Step: 2
Training loss: 2.052716952902399
Validation loss: 2.517799369692867

Epoch: 5| Step: 3
Training loss: 2.173779647300317
Validation loss: 2.5292995791623305

Epoch: 5| Step: 4
Training loss: 2.449460931756449
Validation loss: 2.5342136819332004

Epoch: 5| Step: 5
Training loss: 2.5946165728416783
Validation loss: 2.5262231872987986

Epoch: 5| Step: 6
Training loss: 2.276287691159354
Validation loss: 2.520930348780971

Epoch: 5| Step: 7
Training loss: 2.6531782452707504
Validation loss: 2.513184783541962

Epoch: 5| Step: 8
Training loss: 1.7648285276204814
Validation loss: 2.4828615076931144

Epoch: 5| Step: 9
Training loss: 2.472977700212744
Validation loss: 2.5033149636043732

Epoch: 5| Step: 10
Training loss: 2.4704787563328576
Validation loss: 2.504437081361081

Epoch: 5| Step: 11
Training loss: 1.21408734584605
Validation loss: 2.50956198809968

Epoch: 262| Step: 0
Training loss: 2.4679938981337832
Validation loss: 2.5150105770538356

Epoch: 5| Step: 1
Training loss: 2.5981246640643576
Validation loss: 2.501745623863807

Epoch: 5| Step: 2
Training loss: 2.2708671170675987
Validation loss: 2.510012943733449

Epoch: 5| Step: 3
Training loss: 1.870743688915047
Validation loss: 2.527174631992242

Epoch: 5| Step: 4
Training loss: 2.6956722295892472
Validation loss: 2.5343889349739745

Epoch: 5| Step: 5
Training loss: 2.6595111350371283
Validation loss: 2.5496910768267114

Epoch: 5| Step: 6
Training loss: 2.412186668485796
Validation loss: 2.5382328966959005

Epoch: 5| Step: 7
Training loss: 1.8950419887832852
Validation loss: 2.52261341444916

Epoch: 5| Step: 8
Training loss: 2.0929455706376148
Validation loss: 2.5107970773915484

Epoch: 5| Step: 9
Training loss: 2.6143734507016947
Validation loss: 2.5183548420918083

Epoch: 5| Step: 10
Training loss: 2.0335302611913972
Validation loss: 2.5089806146626685

Epoch: 5| Step: 11
Training loss: 2.12475090810871
Validation loss: 2.497719392046967

Epoch: 263| Step: 0
Training loss: 1.6869647978731819
Validation loss: 2.516705701432648

Epoch: 5| Step: 1
Training loss: 2.822491509396915
Validation loss: 2.5114258812466765

Epoch: 5| Step: 2
Training loss: 2.866600371488732
Validation loss: 2.5120825259364032

Epoch: 5| Step: 3
Training loss: 2.527765395119023
Validation loss: 2.5317597680450716

Epoch: 5| Step: 4
Training loss: 2.557642915821338
Validation loss: 2.5188978596681215

Epoch: 5| Step: 5
Training loss: 1.9931916940989516
Validation loss: 2.531236252139084

Epoch: 5| Step: 6
Training loss: 2.802907054512831
Validation loss: 2.5180299884617767

Epoch: 5| Step: 7
Training loss: 1.859943847834108
Validation loss: 2.522153695111991

Epoch: 5| Step: 8
Training loss: 1.6493378119632744
Validation loss: 2.513880383375847

Epoch: 5| Step: 9
Training loss: 2.513494501621234
Validation loss: 2.5255207638941464

Epoch: 5| Step: 10
Training loss: 2.0269952669318956
Validation loss: 2.514988133470109

Epoch: 5| Step: 11
Training loss: 2.113523458819472
Validation loss: 2.523859656012529

Epoch: 264| Step: 0
Training loss: 2.5311851964119807
Validation loss: 2.5186242533642957

Epoch: 5| Step: 1
Training loss: 1.8002874065465335
Validation loss: 2.5051701292322344

Epoch: 5| Step: 2
Training loss: 2.0770717619251897
Validation loss: 2.50572111046135

Epoch: 5| Step: 3
Training loss: 1.9998235624689142
Validation loss: 2.4887316449381167

Epoch: 5| Step: 4
Training loss: 2.778400633175528
Validation loss: 2.4864858341067935

Epoch: 5| Step: 5
Training loss: 2.6682831116842007
Validation loss: 2.49497748355223

Epoch: 5| Step: 6
Training loss: 2.301220578280653
Validation loss: 2.4855394093810386

Epoch: 5| Step: 7
Training loss: 2.7684688278959353
Validation loss: 2.4903935519937

Epoch: 5| Step: 8
Training loss: 2.334643053140542
Validation loss: 2.496104817970345

Epoch: 5| Step: 9
Training loss: 2.6249674840457287
Validation loss: 2.5073805186417926

Epoch: 5| Step: 10
Training loss: 1.9903042138062395
Validation loss: 2.511469585900326

Epoch: 5| Step: 11
Training loss: 1.6680948178536188
Validation loss: 2.5138938586453468

Epoch: 265| Step: 0
Training loss: 2.7503190289023176
Validation loss: 2.543238792008005

Epoch: 5| Step: 1
Training loss: 2.433626667614451
Validation loss: 2.545554612558156

Epoch: 5| Step: 2
Training loss: 2.1903709101008255
Validation loss: 2.5615922824316066

Epoch: 5| Step: 3
Training loss: 2.6784093716962194
Validation loss: 2.5622980146740155

Epoch: 5| Step: 4
Training loss: 2.535777058582343
Validation loss: 2.57129699806257

Epoch: 5| Step: 5
Training loss: 1.746361628727984
Validation loss: 2.571389893321015

Epoch: 5| Step: 6
Training loss: 1.9750566739992637
Validation loss: 2.5462265827448616

Epoch: 5| Step: 7
Training loss: 3.1804130907278916
Validation loss: 2.5402215708500293

Epoch: 5| Step: 8
Training loss: 2.0879303631332977
Validation loss: 2.5297259974402344

Epoch: 5| Step: 9
Training loss: 1.694658707098548
Validation loss: 2.515733878423335

Epoch: 5| Step: 10
Training loss: 2.8287057859814655
Validation loss: 2.499461096059524

Epoch: 5| Step: 11
Training loss: 2.102430313352541
Validation loss: 2.515816785874417

Epoch: 266| Step: 0
Training loss: 2.3842842934730015
Validation loss: 2.503827518806375

Epoch: 5| Step: 1
Training loss: 2.3021822486673598
Validation loss: 2.511473238798064

Epoch: 5| Step: 2
Training loss: 2.1083934619556857
Validation loss: 2.4941045548895957

Epoch: 5| Step: 3
Training loss: 1.658973038834297
Validation loss: 2.5022430648976934

Epoch: 5| Step: 4
Training loss: 2.0312105615161724
Validation loss: 2.4909594708109726

Epoch: 5| Step: 5
Training loss: 2.6249002710198903
Validation loss: 2.5097830053140804

Epoch: 5| Step: 6
Training loss: 2.866839561867097
Validation loss: 2.506577905844486

Epoch: 5| Step: 7
Training loss: 2.5541030261858237
Validation loss: 2.520551194146871

Epoch: 5| Step: 8
Training loss: 2.5801904900777948
Validation loss: 2.505466782264107

Epoch: 5| Step: 9
Training loss: 2.418805644654516
Validation loss: 2.5182529015722706

Epoch: 5| Step: 10
Training loss: 2.452452160352148
Validation loss: 2.535833972534273

Epoch: 5| Step: 11
Training loss: 1.885506629553859
Validation loss: 2.5235988970813024

Epoch: 267| Step: 0
Training loss: 2.774961756537221
Validation loss: 2.5421220314178736

Epoch: 5| Step: 1
Training loss: 1.9412876760704008
Validation loss: 2.5377445341147884

Epoch: 5| Step: 2
Training loss: 2.0841182247461965
Validation loss: 2.553613625611905

Epoch: 5| Step: 3
Training loss: 2.8639787810514568
Validation loss: 2.5431762470023496

Epoch: 5| Step: 4
Training loss: 2.4841873769868315
Validation loss: 2.529415289857472

Epoch: 5| Step: 5
Training loss: 2.1526948673594144
Validation loss: 2.531413901089297

Epoch: 5| Step: 6
Training loss: 2.317450919840405
Validation loss: 2.51664762068693

Epoch: 5| Step: 7
Training loss: 2.2162911128035265
Validation loss: 2.5260242749955855

Epoch: 5| Step: 8
Training loss: 1.7127244231475174
Validation loss: 2.5107422785027596

Epoch: 5| Step: 9
Training loss: 2.1590377919722266
Validation loss: 2.528926972547966

Epoch: 5| Step: 10
Training loss: 2.8765829952738597
Validation loss: 2.5256742242945305

Epoch: 5| Step: 11
Training loss: 2.4199041407491824
Validation loss: 2.5226621391264663

Epoch: 268| Step: 0
Training loss: 2.1208444241556634
Validation loss: 2.5228342333135942

Epoch: 5| Step: 1
Training loss: 2.235063140113811
Validation loss: 2.53145091511396

Epoch: 5| Step: 2
Training loss: 2.282290077876332
Validation loss: 2.527735043579007

Epoch: 5| Step: 3
Training loss: 2.308647658594885
Validation loss: 2.5329035628663252

Epoch: 5| Step: 4
Training loss: 2.5370983801905242
Validation loss: 2.5280053807122878

Epoch: 5| Step: 5
Training loss: 2.1975783197639585
Validation loss: 2.5284013142139825

Epoch: 5| Step: 6
Training loss: 2.6106297565587653
Validation loss: 2.5340416392295153

Epoch: 5| Step: 7
Training loss: 2.644875440639234
Validation loss: 2.506849375343145

Epoch: 5| Step: 8
Training loss: 2.258594944946015
Validation loss: 2.52055521815386

Epoch: 5| Step: 9
Training loss: 2.3740431213190556
Validation loss: 2.5276844555590494

Epoch: 5| Step: 10
Training loss: 2.3907100687287337
Validation loss: 2.5128886305009814

Epoch: 5| Step: 11
Training loss: 1.7725676028941277
Validation loss: 2.5271202078946473

Epoch: 269| Step: 0
Training loss: 2.714467677133518
Validation loss: 2.534809811848183

Epoch: 5| Step: 1
Training loss: 2.3297234494705985
Validation loss: 2.552931974702463

Epoch: 5| Step: 2
Training loss: 2.182487630732596
Validation loss: 2.556729941948675

Epoch: 5| Step: 3
Training loss: 2.281107022756183
Validation loss: 2.541904619418126

Epoch: 5| Step: 4
Training loss: 2.0421655655188604
Validation loss: 2.5263437437884964

Epoch: 5| Step: 5
Training loss: 2.092583858217949
Validation loss: 2.5356796891994797

Epoch: 5| Step: 6
Training loss: 2.3606257881080417
Validation loss: 2.53346043291947

Epoch: 5| Step: 7
Training loss: 2.138470756097127
Validation loss: 2.5163886054532774

Epoch: 5| Step: 8
Training loss: 2.7092007837305383
Validation loss: 2.507360027370779

Epoch: 5| Step: 9
Training loss: 1.9257751217139116
Validation loss: 2.496233869031535

Epoch: 5| Step: 10
Training loss: 2.9786528208668934
Validation loss: 2.510147722698552

Epoch: 5| Step: 11
Training loss: 1.7405732891955557
Validation loss: 2.5021021230554843

Epoch: 270| Step: 0
Training loss: 2.101734820820543
Validation loss: 2.488756163433164

Epoch: 5| Step: 1
Training loss: 2.4910244993446873
Validation loss: 2.487303517279807

Epoch: 5| Step: 2
Training loss: 2.7916053271790364
Validation loss: 2.5048618248846632

Epoch: 5| Step: 3
Training loss: 2.105616633329813
Validation loss: 2.5158297947042354

Epoch: 5| Step: 4
Training loss: 2.5060357665777038
Validation loss: 2.513265249327673

Epoch: 5| Step: 5
Training loss: 2.7383838150036466
Validation loss: 2.513557131108817

Epoch: 5| Step: 6
Training loss: 2.296981705243564
Validation loss: 2.5320136955050536

Epoch: 5| Step: 7
Training loss: 1.6171398800827808
Validation loss: 2.5300890689621207

Epoch: 5| Step: 8
Training loss: 2.17241151618525
Validation loss: 2.5319888210145267

Epoch: 5| Step: 9
Training loss: 2.6201361144722646
Validation loss: 2.542969492234895

Epoch: 5| Step: 10
Training loss: 2.1090336276141324
Validation loss: 2.540337724542053

Epoch: 5| Step: 11
Training loss: 3.135826886653905
Validation loss: 2.565909373870596

Epoch: 271| Step: 0
Training loss: 2.415917532555465
Validation loss: 2.5311918291228697

Epoch: 5| Step: 1
Training loss: 2.6666100813902047
Validation loss: 2.517994347360451

Epoch: 5| Step: 2
Training loss: 1.8417009508673055
Validation loss: 2.51296325907532

Epoch: 5| Step: 3
Training loss: 2.5423815821374838
Validation loss: 2.499531260893003

Epoch: 5| Step: 4
Training loss: 2.0657097087810157
Validation loss: 2.504681154379101

Epoch: 5| Step: 5
Training loss: 2.647907395325363
Validation loss: 2.4872743574514113

Epoch: 5| Step: 6
Training loss: 2.8312170502553737
Validation loss: 2.4973196045210844

Epoch: 5| Step: 7
Training loss: 2.2035792538538606
Validation loss: 2.5037165077433783

Epoch: 5| Step: 8
Training loss: 2.189831717135209
Validation loss: 2.499123924454209

Epoch: 5| Step: 9
Training loss: 2.7161420393588425
Validation loss: 2.505232409693972

Epoch: 5| Step: 10
Training loss: 1.4215820346042711
Validation loss: 2.5083598711082193

Epoch: 5| Step: 11
Training loss: 1.9913200135263924
Validation loss: 2.512891204073311

Epoch: 272| Step: 0
Training loss: 2.463091195490879
Validation loss: 2.5262758002299934

Epoch: 5| Step: 1
Training loss: 2.36968851947926
Validation loss: 2.546082094331063

Epoch: 5| Step: 2
Training loss: 2.463687583252701
Validation loss: 2.560772767276064

Epoch: 5| Step: 3
Training loss: 2.50645871327897
Validation loss: 2.591225584837981

Epoch: 5| Step: 4
Training loss: 2.2973169433590632
Validation loss: 2.6228214260764364

Epoch: 5| Step: 5
Training loss: 2.553725408509429
Validation loss: 2.5938974591357784

Epoch: 5| Step: 6
Training loss: 2.3682011111792685
Validation loss: 2.5820572544467795

Epoch: 5| Step: 7
Training loss: 2.335006170979418
Validation loss: 2.5612535546599124

Epoch: 5| Step: 8
Training loss: 2.086801757075583
Validation loss: 2.5338184959250536

Epoch: 5| Step: 9
Training loss: 2.4792935208048053
Validation loss: 2.499504576708424

Epoch: 5| Step: 10
Training loss: 1.9697739496616111
Validation loss: 2.485421594059023

Epoch: 5| Step: 11
Training loss: 3.3323233186856807
Validation loss: 2.480216694838715

Epoch: 273| Step: 0
Training loss: 2.1530182434102874
Validation loss: 2.4742335972823786

Epoch: 5| Step: 1
Training loss: 2.5905219523477703
Validation loss: 2.4651405893280383

Epoch: 5| Step: 2
Training loss: 2.3712206434203282
Validation loss: 2.4682059151227165

Epoch: 5| Step: 3
Training loss: 2.2883696565386984
Validation loss: 2.4563823140156638

Epoch: 5| Step: 4
Training loss: 2.6181758096353867
Validation loss: 2.4682845228118393

Epoch: 5| Step: 5
Training loss: 2.316373210497669
Validation loss: 2.4697573896067713

Epoch: 5| Step: 6
Training loss: 1.9731139001543163
Validation loss: 2.4619419409547763

Epoch: 5| Step: 7
Training loss: 2.0818706973010506
Validation loss: 2.467220319385086

Epoch: 5| Step: 8
Training loss: 2.6187293222562404
Validation loss: 2.4628766326950515

Epoch: 5| Step: 9
Training loss: 2.9199151794969223
Validation loss: 2.470528042788076

Epoch: 5| Step: 10
Training loss: 2.803491533996307
Validation loss: 2.4679302995485446

Epoch: 5| Step: 11
Training loss: 2.7938696202008777
Validation loss: 2.496508739441877

Epoch: 274| Step: 0
Training loss: 2.1829234614530146
Validation loss: 2.5255220776790406

Epoch: 5| Step: 1
Training loss: 2.4997591856367958
Validation loss: 2.5538734904596234

Epoch: 5| Step: 2
Training loss: 2.335177090482603
Validation loss: 2.5670271170372336

Epoch: 5| Step: 3
Training loss: 2.800609801510189
Validation loss: 2.62091770708476

Epoch: 5| Step: 4
Training loss: 1.9193215503659986
Validation loss: 2.666743759193269

Epoch: 5| Step: 5
Training loss: 2.2630017056258547
Validation loss: 2.66921300065573

Epoch: 5| Step: 6
Training loss: 2.6522994339714114
Validation loss: 2.725804275411071

Epoch: 5| Step: 7
Training loss: 2.9055726277141782
Validation loss: 2.6907652122421735

Epoch: 5| Step: 8
Training loss: 2.464901302288429
Validation loss: 2.6282713464911276

Epoch: 5| Step: 9
Training loss: 2.4754606377005737
Validation loss: 2.593181042142619

Epoch: 5| Step: 10
Training loss: 2.3315000711858658
Validation loss: 2.5557187960901264

Epoch: 5| Step: 11
Training loss: 3.073050561778804
Validation loss: 2.523037803024485

Epoch: 275| Step: 0
Training loss: 2.241355608756626
Validation loss: 2.5200938225113663

Epoch: 5| Step: 1
Training loss: 2.715749466022396
Validation loss: 2.5142014782166346

Epoch: 5| Step: 2
Training loss: 2.5959761844065716
Validation loss: 2.5053624299387227

Epoch: 5| Step: 3
Training loss: 1.8740708274077442
Validation loss: 2.50946402116704

Epoch: 5| Step: 4
Training loss: 2.6934955166938197
Validation loss: 2.495873920628625

Epoch: 5| Step: 5
Training loss: 2.3300628789513262
Validation loss: 2.5114387367989197

Epoch: 5| Step: 6
Training loss: 2.2953207765018413
Validation loss: 2.496260735423907

Epoch: 5| Step: 7
Training loss: 2.2715908035444143
Validation loss: 2.496650948018741

Epoch: 5| Step: 8
Training loss: 1.9417087004645461
Validation loss: 2.4978508891039795

Epoch: 5| Step: 9
Training loss: 2.0895750639559454
Validation loss: 2.5124327938460542

Epoch: 5| Step: 10
Training loss: 2.8084801662859196
Validation loss: 2.5140806042177597

Epoch: 5| Step: 11
Training loss: 1.97773719831096
Validation loss: 2.5118490712324975

Epoch: 276| Step: 0
Training loss: 2.7403601837098717
Validation loss: 2.5232230332513192

Epoch: 5| Step: 1
Training loss: 2.4658937953159765
Validation loss: 2.517381465581109

Epoch: 5| Step: 2
Training loss: 2.33284276392035
Validation loss: 2.521445024115828

Epoch: 5| Step: 3
Training loss: 2.3111029864233616
Validation loss: 2.535299174664295

Epoch: 5| Step: 4
Training loss: 2.0102186220754246
Validation loss: 2.5255416781671274

Epoch: 5| Step: 5
Training loss: 2.4880073911673612
Validation loss: 2.520479387598219

Epoch: 5| Step: 6
Training loss: 1.7974888292159164
Validation loss: 2.521835424844595

Epoch: 5| Step: 7
Training loss: 2.5533616478082948
Validation loss: 2.5072943567109163

Epoch: 5| Step: 8
Training loss: 2.245451674531485
Validation loss: 2.4995806858955714

Epoch: 5| Step: 9
Training loss: 2.331993831161794
Validation loss: 2.5078407812851093

Epoch: 5| Step: 10
Training loss: 2.1725004105298673
Validation loss: 2.5018958612023834

Epoch: 5| Step: 11
Training loss: 3.3206054558260485
Validation loss: 2.49664587880161

Epoch: 277| Step: 0
Training loss: 1.9955429840199301
Validation loss: 2.51171597747096

Epoch: 5| Step: 1
Training loss: 2.0351103266771675
Validation loss: 2.508915099267969

Epoch: 5| Step: 2
Training loss: 2.3921597609353724
Validation loss: 2.5121968527718366

Epoch: 5| Step: 3
Training loss: 1.3581661681226083
Validation loss: 2.5123001106104064

Epoch: 5| Step: 4
Training loss: 2.257838476750976
Validation loss: 2.5120492503174643

Epoch: 5| Step: 5
Training loss: 2.6947641893029726
Validation loss: 2.5262683189932136

Epoch: 5| Step: 6
Training loss: 3.0089145771653643
Validation loss: 2.528358825571005

Epoch: 5| Step: 7
Training loss: 2.00846679951029
Validation loss: 2.5284239334083827

Epoch: 5| Step: 8
Training loss: 2.8489774509232504
Validation loss: 2.5197317078169257

Epoch: 5| Step: 9
Training loss: 2.5006728220597516
Validation loss: 2.509516005713103

Epoch: 5| Step: 10
Training loss: 2.2256345722664306
Validation loss: 2.499083205841659

Epoch: 5| Step: 11
Training loss: 2.225313070324221
Validation loss: 2.5138526580780307

Epoch: 278| Step: 0
Training loss: 2.2836188989351376
Validation loss: 2.496294044414245

Epoch: 5| Step: 1
Training loss: 2.7417225674512253
Validation loss: 2.5035716570716806

Epoch: 5| Step: 2
Training loss: 2.003805830969543
Validation loss: 2.516782304862828

Epoch: 5| Step: 3
Training loss: 2.4233921344379783
Validation loss: 2.520725666983607

Epoch: 5| Step: 4
Training loss: 2.559264582859327
Validation loss: 2.5256356584864803

Epoch: 5| Step: 5
Training loss: 2.1457152719950754
Validation loss: 2.529885650407781

Epoch: 5| Step: 6
Training loss: 2.2346540156797654
Validation loss: 2.540441871978101

Epoch: 5| Step: 7
Training loss: 1.8726167791644601
Validation loss: 2.540946752312199

Epoch: 5| Step: 8
Training loss: 2.4230640076839185
Validation loss: 2.5333587041847636

Epoch: 5| Step: 9
Training loss: 2.676838597689871
Validation loss: 2.528697445804653

Epoch: 5| Step: 10
Training loss: 1.9879184834137436
Validation loss: 2.5431487004627362

Epoch: 5| Step: 11
Training loss: 3.3514513828735657
Validation loss: 2.529132225932288

Epoch: 279| Step: 0
Training loss: 2.1658104402927902
Validation loss: 2.5153433403152587

Epoch: 5| Step: 1
Training loss: 2.4200763545325543
Validation loss: 2.514899988524277

Epoch: 5| Step: 2
Training loss: 1.5974255980595966
Validation loss: 2.524520224448599

Epoch: 5| Step: 3
Training loss: 2.2806527387960727
Validation loss: 2.52095020564468

Epoch: 5| Step: 4
Training loss: 2.239417195626602
Validation loss: 2.5118078252601466

Epoch: 5| Step: 5
Training loss: 2.697635434686563
Validation loss: 2.509321188755507

Epoch: 5| Step: 6
Training loss: 2.351074370862534
Validation loss: 2.4972065458405637

Epoch: 5| Step: 7
Training loss: 2.697287723083355
Validation loss: 2.4964256881781934

Epoch: 5| Step: 8
Training loss: 2.460283464986988
Validation loss: 2.4981394719034

Epoch: 5| Step: 9
Training loss: 2.2559003817972045
Validation loss: 2.49201983104069

Epoch: 5| Step: 10
Training loss: 2.5790756784719684
Validation loss: 2.514392151843221

Epoch: 5| Step: 11
Training loss: 2.206953901437746
Validation loss: 2.529034783372395

Epoch: 280| Step: 0
Training loss: 2.3834941952000315
Validation loss: 2.547056363285038

Epoch: 5| Step: 1
Training loss: 2.1752599232022805
Validation loss: 2.5494505452363647

Epoch: 5| Step: 2
Training loss: 2.2336866478883266
Validation loss: 2.553526751730493

Epoch: 5| Step: 3
Training loss: 2.4452963149050033
Validation loss: 2.5588172523780703

Epoch: 5| Step: 4
Training loss: 2.4318885768726095
Validation loss: 2.552514294158685

Epoch: 5| Step: 5
Training loss: 2.3039017711866223
Validation loss: 2.5540809338998653

Epoch: 5| Step: 6
Training loss: 2.0111652094178525
Validation loss: 2.5496344605097176

Epoch: 5| Step: 7
Training loss: 2.2328799921597233
Validation loss: 2.553630874769444

Epoch: 5| Step: 8
Training loss: 2.0329061945464173
Validation loss: 2.55719478110288

Epoch: 5| Step: 9
Training loss: 2.3419713710139427
Validation loss: 2.540384588092748

Epoch: 5| Step: 10
Training loss: 2.776839799402445
Validation loss: 2.549027257085416

Epoch: 5| Step: 11
Training loss: 2.842329907323038
Validation loss: 2.5397179134239676

Epoch: 281| Step: 0
Training loss: 2.2351481560537545
Validation loss: 2.5292454934025512

Epoch: 5| Step: 1
Training loss: 2.1521862270085035
Validation loss: 2.5128070417526036

Epoch: 5| Step: 2
Training loss: 1.9412115294899552
Validation loss: 2.501170416879256

Epoch: 5| Step: 3
Training loss: 2.262624713980088
Validation loss: 2.515957972207496

Epoch: 5| Step: 4
Training loss: 2.770450756842223
Validation loss: 2.5294113467123083

Epoch: 5| Step: 5
Training loss: 2.483445383483962
Validation loss: 2.510248785354406

Epoch: 5| Step: 6
Training loss: 2.1765928552486637
Validation loss: 2.5115442843281133

Epoch: 5| Step: 7
Training loss: 1.6241214284505998
Validation loss: 2.512712300916881

Epoch: 5| Step: 8
Training loss: 2.7688675315142786
Validation loss: 2.4978570217258143

Epoch: 5| Step: 9
Training loss: 2.4173531927368535
Validation loss: 2.50057992964006

Epoch: 5| Step: 10
Training loss: 2.3258348504278725
Validation loss: 2.5117956716288927

Epoch: 5| Step: 11
Training loss: 3.059010756165373
Validation loss: 2.515480611934189

Epoch: 282| Step: 0
Training loss: 1.7857369911930165
Validation loss: 2.522160595774904

Epoch: 5| Step: 1
Training loss: 2.70421406410972
Validation loss: 2.536465444430828

Epoch: 5| Step: 2
Training loss: 2.4266510170477376
Validation loss: 2.5411143927568487

Epoch: 5| Step: 3
Training loss: 2.1439746349741635
Validation loss: 2.5596852000840964

Epoch: 5| Step: 4
Training loss: 2.54141014138694
Validation loss: 2.552633939760234

Epoch: 5| Step: 5
Training loss: 2.356850087780976
Validation loss: 2.535243737700321

Epoch: 5| Step: 6
Training loss: 2.1679178317852164
Validation loss: 2.5400454960963654

Epoch: 5| Step: 7
Training loss: 2.864201708717921
Validation loss: 2.532735086740975

Epoch: 5| Step: 8
Training loss: 2.131377579346791
Validation loss: 2.5023518387807373

Epoch: 5| Step: 9
Training loss: 1.950613803116363
Validation loss: 2.500677521610201

Epoch: 5| Step: 10
Training loss: 2.420126006573896
Validation loss: 2.4970042518706324

Epoch: 5| Step: 11
Training loss: 2.5934699952989844
Validation loss: 2.4856331036878174

Epoch: 283| Step: 0
Training loss: 2.1302348339667763
Validation loss: 2.4911886862460553

Epoch: 5| Step: 1
Training loss: 3.2680752701513027
Validation loss: 2.4985139165137906

Epoch: 5| Step: 2
Training loss: 2.4011054592525993
Validation loss: 2.492623533173959

Epoch: 5| Step: 3
Training loss: 2.4976835963494546
Validation loss: 2.492137151068041

Epoch: 5| Step: 4
Training loss: 2.7015997491919457
Validation loss: 2.4902076031610854

Epoch: 5| Step: 5
Training loss: 1.9700795482898568
Validation loss: 2.501834410948781

Epoch: 5| Step: 6
Training loss: 2.4174202588095097
Validation loss: 2.5318591479857755

Epoch: 5| Step: 7
Training loss: 2.2442273155579593
Validation loss: 2.569962791762302

Epoch: 5| Step: 8
Training loss: 1.9806626204303066
Validation loss: 2.564466152463132

Epoch: 5| Step: 9
Training loss: 1.700610483171385
Validation loss: 2.54276625241569

Epoch: 5| Step: 10
Training loss: 2.349646716245255
Validation loss: 2.5424901079181095

Epoch: 5| Step: 11
Training loss: 1.2724571901326247
Validation loss: 2.525652174400289

Epoch: 284| Step: 0
Training loss: 3.175543707002473
Validation loss: 2.5239034799200737

Epoch: 5| Step: 1
Training loss: 2.696531246904706
Validation loss: 2.5211393680234013

Epoch: 5| Step: 2
Training loss: 2.0387456070357377
Validation loss: 2.5233997779128927

Epoch: 5| Step: 3
Training loss: 2.0407711192884963
Validation loss: 2.52568864748011

Epoch: 5| Step: 4
Training loss: 2.240395178507061
Validation loss: 2.5272271641879334

Epoch: 5| Step: 5
Training loss: 2.423314903203187
Validation loss: 2.540638783547712

Epoch: 5| Step: 6
Training loss: 2.108370054123738
Validation loss: 2.533047834316431

Epoch: 5| Step: 7
Training loss: 2.50940233265586
Validation loss: 2.5393229443904772

Epoch: 5| Step: 8
Training loss: 1.9461560239747788
Validation loss: 2.5137701205537977

Epoch: 5| Step: 9
Training loss: 1.6552342593077378
Validation loss: 2.5191807505556407

Epoch: 5| Step: 10
Training loss: 2.268068140725252
Validation loss: 2.5167094513327863

Epoch: 5| Step: 11
Training loss: 2.7427256346863294
Validation loss: 2.5152326834753387

Epoch: 285| Step: 0
Training loss: 2.223678702315236
Validation loss: 2.5116758921335043

Epoch: 5| Step: 1
Training loss: 1.9783637844314186
Validation loss: 2.5140974548546215

Epoch: 5| Step: 2
Training loss: 2.5227704657591214
Validation loss: 2.514136883204476

Epoch: 5| Step: 3
Training loss: 2.4173594062894384
Validation loss: 2.5046547670024166

Epoch: 5| Step: 4
Training loss: 2.6884115580533523
Validation loss: 2.5147012037154526

Epoch: 5| Step: 5
Training loss: 2.5197247571342167
Validation loss: 2.525452249458086

Epoch: 5| Step: 6
Training loss: 1.817370480798436
Validation loss: 2.534519270315617

Epoch: 5| Step: 7
Training loss: 2.702462616837475
Validation loss: 2.5558799309447813

Epoch: 5| Step: 8
Training loss: 1.8578539485173764
Validation loss: 2.561479834494391

Epoch: 5| Step: 9
Training loss: 2.3541171876101896
Validation loss: 2.565903651678163

Epoch: 5| Step: 10
Training loss: 2.6008625177100484
Validation loss: 2.533673080345715

Epoch: 5| Step: 11
Training loss: 1.596216723783042
Validation loss: 2.5333549240304873

Epoch: 286| Step: 0
Training loss: 2.428647815480747
Validation loss: 2.535111927023153

Epoch: 5| Step: 1
Training loss: 2.397672947601417
Validation loss: 2.520868038432506

Epoch: 5| Step: 2
Training loss: 1.9847193742035647
Validation loss: 2.524218093083307

Epoch: 5| Step: 3
Training loss: 1.8480629342332253
Validation loss: 2.5209515493958317

Epoch: 5| Step: 4
Training loss: 2.451692977165915
Validation loss: 2.517804352919672

Epoch: 5| Step: 5
Training loss: 3.017627742816179
Validation loss: 2.5280254334976617

Epoch: 5| Step: 6
Training loss: 2.3947412296098327
Validation loss: 2.5235231658598334

Epoch: 5| Step: 7
Training loss: 2.0814657105245224
Validation loss: 2.5304502511042672

Epoch: 5| Step: 8
Training loss: 2.438477149141399
Validation loss: 2.542660688188036

Epoch: 5| Step: 9
Training loss: 1.7483055903606717
Validation loss: 2.5490764823337724

Epoch: 5| Step: 10
Training loss: 2.4497368612862642
Validation loss: 2.5660926205291275

Epoch: 5| Step: 11
Training loss: 2.9486029986342155
Validation loss: 2.56449079328513

Epoch: 287| Step: 0
Training loss: 2.1882398171743063
Validation loss: 2.573211418802744

Epoch: 5| Step: 1
Training loss: 2.112881155445941
Validation loss: 2.5833863334961507

Epoch: 5| Step: 2
Training loss: 2.3282293513932877
Validation loss: 2.5966962488857854

Epoch: 5| Step: 3
Training loss: 2.1322787668508516
Validation loss: 2.5985897977648036

Epoch: 5| Step: 4
Training loss: 2.435417850995544
Validation loss: 2.6098810226841342

Epoch: 5| Step: 5
Training loss: 2.375431523522224
Validation loss: 2.6112147182736805

Epoch: 5| Step: 6
Training loss: 2.6520976203799327
Validation loss: 2.586278399291109

Epoch: 5| Step: 7
Training loss: 1.9990692953376192
Validation loss: 2.560843525454639

Epoch: 5| Step: 8
Training loss: 2.279315598647121
Validation loss: 2.546906554917896

Epoch: 5| Step: 9
Training loss: 2.748948329624497
Validation loss: 2.521256164419682

Epoch: 5| Step: 10
Training loss: 2.2744807310967423
Validation loss: 2.5260411265788862

Epoch: 5| Step: 11
Training loss: 1.4000700899017782
Validation loss: 2.5174736393884074

Epoch: 288| Step: 0
Training loss: 2.312337302593278
Validation loss: 2.52387576435871

Epoch: 5| Step: 1
Training loss: 2.847766596745347
Validation loss: 2.513968042464657

Epoch: 5| Step: 2
Training loss: 2.4605842457894918
Validation loss: 2.5157985232513065

Epoch: 5| Step: 3
Training loss: 1.7960019188129395
Validation loss: 2.525665677328404

Epoch: 5| Step: 4
Training loss: 2.445077220578832
Validation loss: 2.5223905401169726

Epoch: 5| Step: 5
Training loss: 2.6366213632188784
Validation loss: 2.551843711087556

Epoch: 5| Step: 6
Training loss: 2.0344634240500876
Validation loss: 2.5688842507865073

Epoch: 5| Step: 7
Training loss: 2.2430533089903717
Validation loss: 2.560903784743502

Epoch: 5| Step: 8
Training loss: 2.122864716268246
Validation loss: 2.572099649900881

Epoch: 5| Step: 9
Training loss: 2.2542985544973493
Validation loss: 2.5852318921843422

Epoch: 5| Step: 10
Training loss: 2.2116454376068084
Validation loss: 2.5824196966228725

Epoch: 5| Step: 11
Training loss: 2.4545659006596567
Validation loss: 2.5681109444840207

Epoch: 289| Step: 0
Training loss: 2.491058380827204
Validation loss: 2.5527030244364903

Epoch: 5| Step: 1
Training loss: 1.4444442202902075
Validation loss: 2.5555798452686904

Epoch: 5| Step: 2
Training loss: 2.5649738930606136
Validation loss: 2.537375420767895

Epoch: 5| Step: 3
Training loss: 1.6500945237567917
Validation loss: 2.538931607516072

Epoch: 5| Step: 4
Training loss: 2.6319587749626754
Validation loss: 2.5229622931781788

Epoch: 5| Step: 5
Training loss: 2.2397814877401516
Validation loss: 2.5257867048656752

Epoch: 5| Step: 6
Training loss: 2.2070024066491913
Validation loss: 2.5126491502360624

Epoch: 5| Step: 7
Training loss: 2.7559554031262907
Validation loss: 2.5232636162496846

Epoch: 5| Step: 8
Training loss: 2.0379576046308485
Validation loss: 2.5169351100382507

Epoch: 5| Step: 9
Training loss: 2.419770045901619
Validation loss: 2.5188925078837703

Epoch: 5| Step: 10
Training loss: 2.3959383291927447
Validation loss: 2.525085202595654

Epoch: 5| Step: 11
Training loss: 2.803330116890035
Validation loss: 2.502135187533371

Epoch: 290| Step: 0
Training loss: 2.168208368479443
Validation loss: 2.543531237465845

Epoch: 5| Step: 1
Training loss: 2.3334649820881896
Validation loss: 2.5384895539025303

Epoch: 5| Step: 2
Training loss: 2.475620608115207
Validation loss: 2.5605476276581856

Epoch: 5| Step: 3
Training loss: 2.230942229941735
Validation loss: 2.5738966474522043

Epoch: 5| Step: 4
Training loss: 2.2397060153686064
Validation loss: 2.5578224242524117

Epoch: 5| Step: 5
Training loss: 2.621539605277512
Validation loss: 2.5709364384007993

Epoch: 5| Step: 6
Training loss: 2.2892645528625923
Validation loss: 2.567599810124655

Epoch: 5| Step: 7
Training loss: 2.072356514191422
Validation loss: 2.563115263167501

Epoch: 5| Step: 8
Training loss: 1.4732736765462242
Validation loss: 2.5701375551989614

Epoch: 5| Step: 9
Training loss: 2.6226965470750807
Validation loss: 2.5578059141042813

Epoch: 5| Step: 10
Training loss: 2.394128961670073
Validation loss: 2.542974859758685

Epoch: 5| Step: 11
Training loss: 3.3749149453077365
Validation loss: 2.5357174832556075

Epoch: 291| Step: 0
Training loss: 2.211768327842535
Validation loss: 2.5149089295606495

Epoch: 5| Step: 1
Training loss: 2.442772274088733
Validation loss: 2.507746555970597

Epoch: 5| Step: 2
Training loss: 2.356819436149969
Validation loss: 2.5141415812950276

Epoch: 5| Step: 3
Training loss: 1.7378267186856855
Validation loss: 2.5080728920565685

Epoch: 5| Step: 4
Training loss: 2.3045218715312656
Validation loss: 2.503813005398345

Epoch: 5| Step: 5
Training loss: 2.950025273877516
Validation loss: 2.505730276531089

Epoch: 5| Step: 6
Training loss: 2.2558157251932287
Validation loss: 2.5094552705403532

Epoch: 5| Step: 7
Training loss: 2.220494940803741
Validation loss: 2.518687613150828

Epoch: 5| Step: 8
Training loss: 2.623998996065692
Validation loss: 2.516194794376617

Epoch: 5| Step: 9
Training loss: 2.3466279734145274
Validation loss: 2.5262337929458853

Epoch: 5| Step: 10
Training loss: 2.200758183486736
Validation loss: 2.516718376072643

Epoch: 5| Step: 11
Training loss: 1.9624893309673728
Validation loss: 2.5488154931078166

Epoch: 292| Step: 0
Training loss: 1.9583254130859375
Validation loss: 2.525488697890451

Epoch: 5| Step: 1
Training loss: 2.366319755416729
Validation loss: 2.5734904893902337

Epoch: 5| Step: 2
Training loss: 2.0811773843096986
Validation loss: 2.584048696396423

Epoch: 5| Step: 3
Training loss: 2.645468248625578
Validation loss: 2.6115271169832317

Epoch: 5| Step: 4
Training loss: 2.459186330535911
Validation loss: 2.623436091053266

Epoch: 5| Step: 5
Training loss: 2.2678108982996745
Validation loss: 2.6404834197723575

Epoch: 5| Step: 6
Training loss: 2.442188156039979
Validation loss: 2.645759455082448

Epoch: 5| Step: 7
Training loss: 2.640915894145198
Validation loss: 2.6084438535677594

Epoch: 5| Step: 8
Training loss: 2.757511803332856
Validation loss: 2.6338036442118327

Epoch: 5| Step: 9
Training loss: 2.42642159234013
Validation loss: 2.5785964688855367

Epoch: 5| Step: 10
Training loss: 1.7584316265359954
Validation loss: 2.5454728766228705

Epoch: 5| Step: 11
Training loss: 1.0612074338646116
Validation loss: 2.52074481609033

Epoch: 293| Step: 0
Training loss: 2.585765452582473
Validation loss: 2.511877107349634

Epoch: 5| Step: 1
Training loss: 2.653977981958996
Validation loss: 2.491698026672393

Epoch: 5| Step: 2
Training loss: 2.004321912223639
Validation loss: 2.5166393035912678

Epoch: 5| Step: 3
Training loss: 2.2758914249045583
Validation loss: 2.507244905469732

Epoch: 5| Step: 4
Training loss: 2.7805479213657645
Validation loss: 2.4987877926839674

Epoch: 5| Step: 5
Training loss: 1.5379359580895078
Validation loss: 2.4902989557406685

Epoch: 5| Step: 6
Training loss: 2.2514353518352803
Validation loss: 2.478897975070662

Epoch: 5| Step: 7
Training loss: 2.6721542837063463
Validation loss: 2.480595362678367

Epoch: 5| Step: 8
Training loss: 1.8965178780390661
Validation loss: 2.4803614315336038

Epoch: 5| Step: 9
Training loss: 2.3647157965260526
Validation loss: 2.483229126973375

Epoch: 5| Step: 10
Training loss: 2.395561954774411
Validation loss: 2.4995378225992515

Epoch: 5| Step: 11
Training loss: 1.0176877715038903
Validation loss: 2.5034295836962266

Epoch: 294| Step: 0
Training loss: 2.1362391182860607
Validation loss: 2.4939346766149844

Epoch: 5| Step: 1
Training loss: 2.5867971046076446
Validation loss: 2.5004506698349167

Epoch: 5| Step: 2
Training loss: 2.3525283198825915
Validation loss: 2.5055656825918478

Epoch: 5| Step: 3
Training loss: 2.4630730944809787
Validation loss: 2.5169383820215847

Epoch: 5| Step: 4
Training loss: 1.98280512670855
Validation loss: 2.544369762349358

Epoch: 5| Step: 5
Training loss: 2.1878862312489358
Validation loss: 2.533224344471039

Epoch: 5| Step: 6
Training loss: 2.1247520302097302
Validation loss: 2.519717463430667

Epoch: 5| Step: 7
Training loss: 2.601124219662668
Validation loss: 2.514731744170247

Epoch: 5| Step: 8
Training loss: 2.2404586027918425
Validation loss: 2.535544653216532

Epoch: 5| Step: 9
Training loss: 2.153152895277503
Validation loss: 2.523810344350601

Epoch: 5| Step: 10
Training loss: 2.5076441247810806
Validation loss: 2.5279691139637634

Epoch: 5| Step: 11
Training loss: 0.9550336269629808
Validation loss: 2.5158064640535587

Epoch: 295| Step: 0
Training loss: 2.7974428420922113
Validation loss: 2.5081239350468185

Epoch: 5| Step: 1
Training loss: 2.029990172338891
Validation loss: 2.509530391133625

Epoch: 5| Step: 2
Training loss: 2.257352260685248
Validation loss: 2.5052567329939293

Epoch: 5| Step: 3
Training loss: 2.3327236968587237
Validation loss: 2.509758151942506

Epoch: 5| Step: 4
Training loss: 1.9783868022828655
Validation loss: 2.4953663362552883

Epoch: 5| Step: 5
Training loss: 2.2021646773930015
Validation loss: 2.495390652217184

Epoch: 5| Step: 6
Training loss: 2.2738943787925905
Validation loss: 2.5184823033557593

Epoch: 5| Step: 7
Training loss: 2.5255101434522444
Validation loss: 2.515336191883564

Epoch: 5| Step: 8
Training loss: 1.712474185164298
Validation loss: 2.4997479987291764

Epoch: 5| Step: 9
Training loss: 2.2780142004962025
Validation loss: 2.5114450537954016

Epoch: 5| Step: 10
Training loss: 2.714818018510027
Validation loss: 2.5183393591697834

Epoch: 5| Step: 11
Training loss: 1.4154604750935733
Validation loss: 2.5193648763920238

Epoch: 296| Step: 0
Training loss: 2.525927752780761
Validation loss: 2.537166063293567

Epoch: 5| Step: 1
Training loss: 1.609831958080736
Validation loss: 2.534875075348876

Epoch: 5| Step: 2
Training loss: 2.361205142772928
Validation loss: 2.527068011548504

Epoch: 5| Step: 3
Training loss: 2.5113096957139445
Validation loss: 2.554351185662045

Epoch: 5| Step: 4
Training loss: 1.6314737042322558
Validation loss: 2.542705604310051

Epoch: 5| Step: 5
Training loss: 2.65685435880918
Validation loss: 2.5252888347491043

Epoch: 5| Step: 6
Training loss: 2.0109576220568997
Validation loss: 2.5349483669259416

Epoch: 5| Step: 7
Training loss: 2.2518699081409914
Validation loss: 2.5328398272204824

Epoch: 5| Step: 8
Training loss: 2.513340641419219
Validation loss: 2.505049822756636

Epoch: 5| Step: 9
Training loss: 2.038485273602279
Validation loss: 2.506062026438386

Epoch: 5| Step: 10
Training loss: 2.93973634692445
Validation loss: 2.5082562431315547

Epoch: 5| Step: 11
Training loss: 1.5951046889576688
Validation loss: 2.5139522005917185

Epoch: 297| Step: 0
Training loss: 2.649987321499419
Validation loss: 2.533773655541829

Epoch: 5| Step: 1
Training loss: 2.129463444858418
Validation loss: 2.5333966387401503

Epoch: 5| Step: 2
Training loss: 1.7992705589053795
Validation loss: 2.5482061725892993

Epoch: 5| Step: 3
Training loss: 2.038300236547374
Validation loss: 2.5527760376530546

Epoch: 5| Step: 4
Training loss: 2.6254194923542675
Validation loss: 2.5546490610946377

Epoch: 5| Step: 5
Training loss: 2.657481009271041
Validation loss: 2.5676660837304612

Epoch: 5| Step: 6
Training loss: 2.7924738518866135
Validation loss: 2.5548460441645777

Epoch: 5| Step: 7
Training loss: 2.5920638153203077
Validation loss: 2.569013752510598

Epoch: 5| Step: 8
Training loss: 1.5487215214682593
Validation loss: 2.541139267833933

Epoch: 5| Step: 9
Training loss: 1.9266276946410623
Validation loss: 2.526364611926767

Epoch: 5| Step: 10
Training loss: 2.334442170388294
Validation loss: 2.5160507094676188

Epoch: 5| Step: 11
Training loss: 1.8527034029059817
Validation loss: 2.5285777421001545

Epoch: 298| Step: 0
Training loss: 1.965797390072206
Validation loss: 2.509857156274393

Epoch: 5| Step: 1
Training loss: 2.1713163906174664
Validation loss: 2.513238446131342

Epoch: 5| Step: 2
Training loss: 2.1881960170262267
Validation loss: 2.5226230586469316

Epoch: 5| Step: 3
Training loss: 2.0125333747702694
Validation loss: 2.5150228691957284

Epoch: 5| Step: 4
Training loss: 2.0880185151430237
Validation loss: 2.531586818891405

Epoch: 5| Step: 5
Training loss: 2.366755178524649
Validation loss: 2.5260420074987016

Epoch: 5| Step: 6
Training loss: 2.1391013633034253
Validation loss: 2.5137770402789084

Epoch: 5| Step: 7
Training loss: 3.0368700920610165
Validation loss: 2.513663757516617

Epoch: 5| Step: 8
Training loss: 2.213660945296547
Validation loss: 2.514149732797164

Epoch: 5| Step: 9
Training loss: 2.079575340863523
Validation loss: 2.505462230471281

Epoch: 5| Step: 10
Training loss: 2.662306668421655
Validation loss: 2.540158325821448

Epoch: 5| Step: 11
Training loss: 1.5705368109527058
Validation loss: 2.5467573618488024

Epoch: 299| Step: 0
Training loss: 1.75327716241844
Validation loss: 2.5376592935320317

Epoch: 5| Step: 1
Training loss: 2.6948748689381885
Validation loss: 2.5646688191916596

Epoch: 5| Step: 2
Training loss: 2.2192842082190793
Validation loss: 2.555115390761074

Epoch: 5| Step: 3
Training loss: 1.8421077203017175
Validation loss: 2.5507605933014568

Epoch: 5| Step: 4
Training loss: 2.562789063315695
Validation loss: 2.541881471426669

Epoch: 5| Step: 5
Training loss: 2.3537073840772176
Validation loss: 2.5421885804008153

Epoch: 5| Step: 6
Training loss: 2.1441436584084252
Validation loss: 2.535919082521447

Epoch: 5| Step: 7
Training loss: 2.324727389032764
Validation loss: 2.541661044932751

Epoch: 5| Step: 8
Training loss: 1.933694177967245
Validation loss: 2.514363815841562

Epoch: 5| Step: 9
Training loss: 2.5733378036078065
Validation loss: 2.5269014343896927

Epoch: 5| Step: 10
Training loss: 2.6224349977712316
Validation loss: 2.5076219757689606

Epoch: 5| Step: 11
Training loss: 0.9280806045960228
Validation loss: 2.508316551883193

Epoch: 300| Step: 0
Training loss: 2.269471474679412
Validation loss: 2.5263932812511403

Epoch: 5| Step: 1
Training loss: 2.357995242449723
Validation loss: 2.503471467689216

Epoch: 5| Step: 2
Training loss: 2.9533571828161915
Validation loss: 2.509859069984548

Epoch: 5| Step: 3
Training loss: 2.183354728050336
Validation loss: 2.4994384293847607

Epoch: 5| Step: 4
Training loss: 2.2237538609248713
Validation loss: 2.5255031614707364

Epoch: 5| Step: 5
Training loss: 1.888018995262216
Validation loss: 2.5391813925270292

Epoch: 5| Step: 6
Training loss: 2.3244222599978337
Validation loss: 2.549082904812104

Epoch: 5| Step: 7
Training loss: 2.3470164615751083
Validation loss: 2.5505352261862733

Epoch: 5| Step: 8
Training loss: 2.505612938790755
Validation loss: 2.5456148005923622

Epoch: 5| Step: 9
Training loss: 2.2124681330395646
Validation loss: 2.5389701200454593

Epoch: 5| Step: 10
Training loss: 1.8392793798139169
Validation loss: 2.536658715173195

Epoch: 5| Step: 11
Training loss: 1.7672607136880691
Validation loss: 2.53346607938571

Epoch: 301| Step: 0
Training loss: 2.4068931611791693
Validation loss: 2.5305133383421428

Epoch: 5| Step: 1
Training loss: 2.4680118664497974
Validation loss: 2.5001182607653987

Epoch: 5| Step: 2
Training loss: 1.7173238906635304
Validation loss: 2.497330949488736

Epoch: 5| Step: 3
Training loss: 2.1233130097826387
Validation loss: 2.493529884006062

Epoch: 5| Step: 4
Training loss: 2.231574270583028
Validation loss: 2.501115697019018

Epoch: 5| Step: 5
Training loss: 2.6912392618449683
Validation loss: 2.519255060637219

Epoch: 5| Step: 6
Training loss: 2.4147440617945763
Validation loss: 2.496575803977123

Epoch: 5| Step: 7
Training loss: 2.448262443200012
Validation loss: 2.4955045097110076

Epoch: 5| Step: 8
Training loss: 2.641193215896696
Validation loss: 2.5002154654794313

Epoch: 5| Step: 9
Training loss: 2.3163446993956787
Validation loss: 2.5024303027891373

Epoch: 5| Step: 10
Training loss: 1.6450583005273063
Validation loss: 2.523049784381719

Epoch: 5| Step: 11
Training loss: 1.1842702814273631
Validation loss: 2.5261728246138575

Epoch: 302| Step: 0
Training loss: 2.559712265951087
Validation loss: 2.533682623633763

Epoch: 5| Step: 1
Training loss: 2.143645445829211
Validation loss: 2.5432226109984963

Epoch: 5| Step: 2
Training loss: 2.605504071455201
Validation loss: 2.572365482972814

Epoch: 5| Step: 3
Training loss: 2.0143544532232194
Validation loss: 2.5624323773959503

Epoch: 5| Step: 4
Training loss: 1.7299165899642799
Validation loss: 2.550828669420291

Epoch: 5| Step: 5
Training loss: 1.9585013892388208
Validation loss: 2.5404807721968043

Epoch: 5| Step: 6
Training loss: 2.0667184402789753
Validation loss: 2.5139779924849703

Epoch: 5| Step: 7
Training loss: 2.521165326748201
Validation loss: 2.496564451598804

Epoch: 5| Step: 8
Training loss: 2.5627813417391674
Validation loss: 2.5234597936379672

Epoch: 5| Step: 9
Training loss: 2.119606241150274
Validation loss: 2.5122903595633717

Epoch: 5| Step: 10
Training loss: 2.833781786564941
Validation loss: 2.5108623280535487

Epoch: 5| Step: 11
Training loss: 1.1839901099951833
Validation loss: 2.504744636834246

Epoch: 303| Step: 0
Training loss: 2.5006779705101625
Validation loss: 2.514119536940436

Epoch: 5| Step: 1
Training loss: 2.035153672698104
Validation loss: 2.5196493510479647

Epoch: 5| Step: 2
Training loss: 2.0784817726376654
Validation loss: 2.5400191788687736

Epoch: 5| Step: 3
Training loss: 2.2285250396930842
Validation loss: 2.5503345271631965

Epoch: 5| Step: 4
Training loss: 1.5470856031912663
Validation loss: 2.545819381658989

Epoch: 5| Step: 5
Training loss: 2.561369856063505
Validation loss: 2.5426333900189335

Epoch: 5| Step: 6
Training loss: 2.9507730796484717
Validation loss: 2.5465797299963

Epoch: 5| Step: 7
Training loss: 2.312076839186521
Validation loss: 2.55449601135271

Epoch: 5| Step: 8
Training loss: 2.758590285980461
Validation loss: 2.5352881563311667

Epoch: 5| Step: 9
Training loss: 1.6065148428389453
Validation loss: 2.5418262385998727

Epoch: 5| Step: 10
Training loss: 2.2319427269728083
Validation loss: 2.5414770764373937

Epoch: 5| Step: 11
Training loss: 1.7350863810646027
Validation loss: 2.5401519550841654

Epoch: 304| Step: 0
Training loss: 2.29136640720214
Validation loss: 2.5647020144133412

Epoch: 5| Step: 1
Training loss: 2.386984752559986
Validation loss: 2.5726452206783463

Epoch: 5| Step: 2
Training loss: 2.0019274007493615
Validation loss: 2.5769748703981326

Epoch: 5| Step: 3
Training loss: 2.8803228777458125
Validation loss: 2.6241057420530707

Epoch: 5| Step: 4
Training loss: 2.3954877078880155
Validation loss: 2.6258475774521726

Epoch: 5| Step: 5
Training loss: 2.610428100788215
Validation loss: 2.609546244592872

Epoch: 5| Step: 6
Training loss: 2.1285188374921273
Validation loss: 2.622353760205959

Epoch: 5| Step: 7
Training loss: 2.1398721749464062
Validation loss: 2.554400802219399

Epoch: 5| Step: 8
Training loss: 2.4173336643247523
Validation loss: 2.559764351609921

Epoch: 5| Step: 9
Training loss: 2.018985755783251
Validation loss: 2.542718702172987

Epoch: 5| Step: 10
Training loss: 1.7474789853121742
Validation loss: 2.5016099117185373

Epoch: 5| Step: 11
Training loss: 1.649624654675195
Validation loss: 2.4930301306044096

Epoch: 305| Step: 0
Training loss: 1.797670403946615
Validation loss: 2.498307807741917

Epoch: 5| Step: 1
Training loss: 2.63819312800482
Validation loss: 2.4845795057404705

Epoch: 5| Step: 2
Training loss: 1.839487741938086
Validation loss: 2.487677482442649

Epoch: 5| Step: 3
Training loss: 2.508299212894317
Validation loss: 2.48319873514388

Epoch: 5| Step: 4
Training loss: 2.2161540574049323
Validation loss: 2.5107786160366867

Epoch: 5| Step: 5
Training loss: 2.1556053856642765
Validation loss: 2.5296374353140014

Epoch: 5| Step: 6
Training loss: 2.167823250501816
Validation loss: 2.525239059254597

Epoch: 5| Step: 7
Training loss: 2.1509724037035296
Validation loss: 2.5524439044471228

Epoch: 5| Step: 8
Training loss: 2.5204243814286516
Validation loss: 2.550986464279464

Epoch: 5| Step: 9
Training loss: 3.0609500621870858
Validation loss: 2.5725094180773467

Epoch: 5| Step: 10
Training loss: 2.2061904250792645
Validation loss: 2.56324153343466

Epoch: 5| Step: 11
Training loss: 2.7469863851659087
Validation loss: 2.543031901695109

Epoch: 306| Step: 0
Training loss: 1.9872966494385969
Validation loss: 2.5513566688854783

Epoch: 5| Step: 1
Training loss: 2.1522564602025005
Validation loss: 2.5574514969694633

Epoch: 5| Step: 2
Training loss: 2.9155730967588425
Validation loss: 2.550017374422061

Epoch: 5| Step: 3
Training loss: 2.3970807242107157
Validation loss: 2.531062024989937

Epoch: 5| Step: 4
Training loss: 1.9017323602244682
Validation loss: 2.5410094909828502

Epoch: 5| Step: 5
Training loss: 2.572746538928885
Validation loss: 2.5292535216004786

Epoch: 5| Step: 6
Training loss: 2.144276643797222
Validation loss: 2.5296228657775504

Epoch: 5| Step: 7
Training loss: 2.2386410409044974
Validation loss: 2.5422564249634303

Epoch: 5| Step: 8
Training loss: 2.5524066227226623
Validation loss: 2.5442835489591107

Epoch: 5| Step: 9
Training loss: 2.231295190348186
Validation loss: 2.5628657467659908

Epoch: 5| Step: 10
Training loss: 2.3136591712439305
Validation loss: 2.5326222950176422

Epoch: 5| Step: 11
Training loss: 1.1205299368607895
Validation loss: 2.535636155014067

Epoch: 307| Step: 0
Training loss: 2.0141655421329507
Validation loss: 2.5512846079598384

Epoch: 5| Step: 1
Training loss: 2.796650200872254
Validation loss: 2.539319534985429

Epoch: 5| Step: 2
Training loss: 2.500271019550403
Validation loss: 2.5357593902385944

Epoch: 5| Step: 3
Training loss: 2.115955627841506
Validation loss: 2.547035961096453

Epoch: 5| Step: 4
Training loss: 2.510521397180168
Validation loss: 2.530531757791616

Epoch: 5| Step: 5
Training loss: 1.6865402600764212
Validation loss: 2.5267545356187666

Epoch: 5| Step: 6
Training loss: 2.636159970449636
Validation loss: 2.5388345391081084

Epoch: 5| Step: 7
Training loss: 2.3644872189339905
Validation loss: 2.555077592034851

Epoch: 5| Step: 8
Training loss: 1.9435837505913514
Validation loss: 2.5423890608943513

Epoch: 5| Step: 9
Training loss: 2.704228170564407
Validation loss: 2.5609235256171448

Epoch: 5| Step: 10
Training loss: 1.549326562712928
Validation loss: 2.552840495512332

Epoch: 5| Step: 11
Training loss: 1.4790603259191728
Validation loss: 2.5689641397635534

Epoch: 308| Step: 0
Training loss: 3.1094145652515737
Validation loss: 2.567853425719478

Epoch: 5| Step: 1
Training loss: 2.170908102064632
Validation loss: 2.568725173100075

Epoch: 5| Step: 2
Training loss: 1.5493674956613548
Validation loss: 2.5672825130712313

Epoch: 5| Step: 3
Training loss: 2.1677812374918797
Validation loss: 2.5655483009808906

Epoch: 5| Step: 4
Training loss: 2.614236198167792
Validation loss: 2.572517164517234

Epoch: 5| Step: 5
Training loss: 2.2699319876342345
Validation loss: 2.563790899471587

Epoch: 5| Step: 6
Training loss: 2.4730576224086778
Validation loss: 2.5372731677428533

Epoch: 5| Step: 7
Training loss: 2.309366422851492
Validation loss: 2.5177301302276587

Epoch: 5| Step: 8
Training loss: 1.9180759625274262
Validation loss: 2.530251435537904

Epoch: 5| Step: 9
Training loss: 1.7781987072730672
Validation loss: 2.5218490624462815

Epoch: 5| Step: 10
Training loss: 2.3389328344127462
Validation loss: 2.5430337377038583

Epoch: 5| Step: 11
Training loss: 1.6692725631379575
Validation loss: 2.5304513228545464

Epoch: 309| Step: 0
Training loss: 2.030880703734292
Validation loss: 2.5390613145091883

Epoch: 5| Step: 1
Training loss: 2.3363626660917443
Validation loss: 2.5338127130225874

Epoch: 5| Step: 2
Training loss: 2.080473068066656
Validation loss: 2.5657744188742213

Epoch: 5| Step: 3
Training loss: 2.2321016711113817
Validation loss: 2.5898780379367827

Epoch: 5| Step: 4
Training loss: 2.5393374250196583
Validation loss: 2.5944044405900173

Epoch: 5| Step: 5
Training loss: 2.3173239628536875
Validation loss: 2.5779364199015418

Epoch: 5| Step: 6
Training loss: 3.1726174072953914
Validation loss: 2.5717212716035056

Epoch: 5| Step: 7
Training loss: 2.464317301830087
Validation loss: 2.5347870223298905

Epoch: 5| Step: 8
Training loss: 1.8319057917797124
Validation loss: 2.535022252033441

Epoch: 5| Step: 9
Training loss: 1.7043154694274867
Validation loss: 2.527385823343286

Epoch: 5| Step: 10
Training loss: 2.1893282198774595
Validation loss: 2.512238950437003

Epoch: 5| Step: 11
Training loss: 1.2757278627436883
Validation loss: 2.5254289427975354

Epoch: 310| Step: 0
Training loss: 2.4287829908014116
Validation loss: 2.4903916053751294

Epoch: 5| Step: 1
Training loss: 2.057036822666801
Validation loss: 2.4884627319459387

Epoch: 5| Step: 2
Training loss: 2.305788973082991
Validation loss: 2.469536905383793

Epoch: 5| Step: 3
Training loss: 2.3962374360218313
Validation loss: 2.477749685382204

Epoch: 5| Step: 4
Training loss: 2.2066564731228
Validation loss: 2.489313603131783

Epoch: 5| Step: 5
Training loss: 2.4133987254913194
Validation loss: 2.4935454691840033

Epoch: 5| Step: 6
Training loss: 2.4072519173360454
Validation loss: 2.498465850109393

Epoch: 5| Step: 7
Training loss: 2.0060768789542696
Validation loss: 2.5118705660124445

Epoch: 5| Step: 8
Training loss: 2.1968520661156794
Validation loss: 2.5396987665576667

Epoch: 5| Step: 9
Training loss: 1.733450015737912
Validation loss: 2.537852741491251

Epoch: 5| Step: 10
Training loss: 2.9253279738479985
Validation loss: 2.5744221538940084

Epoch: 5| Step: 11
Training loss: 1.9473559818711612
Validation loss: 2.563372250326838

Epoch: 311| Step: 0
Training loss: 2.0426382231429363
Validation loss: 2.553564612315681

Epoch: 5| Step: 1
Training loss: 2.638001984468976
Validation loss: 2.539277721966917

Epoch: 5| Step: 2
Training loss: 2.627344446922298
Validation loss: 2.5125496509890506

Epoch: 5| Step: 3
Training loss: 2.3578210222559184
Validation loss: 2.5007555892662214

Epoch: 5| Step: 4
Training loss: 1.5964102141439462
Validation loss: 2.502593046726658

Epoch: 5| Step: 5
Training loss: 2.763478194820044
Validation loss: 2.503312007158805

Epoch: 5| Step: 6
Training loss: 2.009433196131276
Validation loss: 2.49453846091831

Epoch: 5| Step: 7
Training loss: 2.5258205251474912
Validation loss: 2.5078929599043516

Epoch: 5| Step: 8
Training loss: 1.9230199365241982
Validation loss: 2.5061217061959056

Epoch: 5| Step: 9
Training loss: 2.4318495572577103
Validation loss: 2.5248744621008736

Epoch: 5| Step: 10
Training loss: 1.838796394431907
Validation loss: 2.5228228770262784

Epoch: 5| Step: 11
Training loss: 2.659083571642494
Validation loss: 2.48934106499249

Epoch: 312| Step: 0
Training loss: 2.394998974570929
Validation loss: 2.5097880321645354

Epoch: 5| Step: 1
Training loss: 1.9008933928334772
Validation loss: 2.5444102345089017

Epoch: 5| Step: 2
Training loss: 2.0801368096181836
Validation loss: 2.5612664548892363

Epoch: 5| Step: 3
Training loss: 2.3638749819131184
Validation loss: 2.5955286974409573

Epoch: 5| Step: 4
Training loss: 2.2414511292180457
Validation loss: 2.5797118283808804

Epoch: 5| Step: 5
Training loss: 2.46070981864674
Validation loss: 2.5735654990954493

Epoch: 5| Step: 6
Training loss: 2.2972633915750706
Validation loss: 2.5552572884569673

Epoch: 5| Step: 7
Training loss: 2.8489684128568458
Validation loss: 2.5608396539776654

Epoch: 5| Step: 8
Training loss: 1.8506940261557248
Validation loss: 2.5529032804321745

Epoch: 5| Step: 9
Training loss: 2.2944606625976944
Validation loss: 2.5421316094205113

Epoch: 5| Step: 10
Training loss: 2.1405175175100375
Validation loss: 2.512991357870962

Epoch: 5| Step: 11
Training loss: 2.796306872073009
Validation loss: 2.5061595377209174

Epoch: 313| Step: 0
Training loss: 2.2233539150072743
Validation loss: 2.50587699648062

Epoch: 5| Step: 1
Training loss: 1.6726996268750844
Validation loss: 2.508139001778871

Epoch: 5| Step: 2
Training loss: 2.3668705189805768
Validation loss: 2.4899825902570223

Epoch: 5| Step: 3
Training loss: 1.5989721423949672
Validation loss: 2.4835238968188635

Epoch: 5| Step: 4
Training loss: 1.9697104639200214
Validation loss: 2.4991555834275663

Epoch: 5| Step: 5
Training loss: 2.6131277908861374
Validation loss: 2.50684878488797

Epoch: 5| Step: 6
Training loss: 2.1867545901431664
Validation loss: 2.4851221564539685

Epoch: 5| Step: 7
Training loss: 2.4585664498528987
Validation loss: 2.510284979652106

Epoch: 5| Step: 8
Training loss: 2.5628243217851465
Validation loss: 2.5239102183589273

Epoch: 5| Step: 9
Training loss: 2.3883039389179257
Validation loss: 2.5673017560376805

Epoch: 5| Step: 10
Training loss: 2.5976117352565096
Validation loss: 2.578636523277279

Epoch: 5| Step: 11
Training loss: 2.600264308406316
Validation loss: 2.574425916193709

Epoch: 314| Step: 0
Training loss: 2.0851864266239732
Validation loss: 2.60223774743229

Epoch: 5| Step: 1
Training loss: 2.2718610508633517
Validation loss: 2.5834303166017465

Epoch: 5| Step: 2
Training loss: 2.2452334672136307
Validation loss: 2.569047885369544

Epoch: 5| Step: 3
Training loss: 2.1792603214286874
Validation loss: 2.5847929143442716

Epoch: 5| Step: 4
Training loss: 2.6767664522673864
Validation loss: 2.5691287978065707

Epoch: 5| Step: 5
Training loss: 2.3668879454777225
Validation loss: 2.5432387138862995

Epoch: 5| Step: 6
Training loss: 1.9166775025876892
Validation loss: 2.5349535319780068

Epoch: 5| Step: 7
Training loss: 2.0220925121254947
Validation loss: 2.533772808675509

Epoch: 5| Step: 8
Training loss: 2.6092127218438956
Validation loss: 2.525355386746307

Epoch: 5| Step: 9
Training loss: 2.47434306047739
Validation loss: 2.5264303648994293

Epoch: 5| Step: 10
Training loss: 2.0374264054376203
Validation loss: 2.5190181673035132

Epoch: 5| Step: 11
Training loss: 1.6202187256269045
Validation loss: 2.5152690509258813

Epoch: 315| Step: 0
Training loss: 2.1960830150818205
Validation loss: 2.526249703299209

Epoch: 5| Step: 1
Training loss: 2.0447656376860217
Validation loss: 2.505523857396434

Epoch: 5| Step: 2
Training loss: 2.1130068560307165
Validation loss: 2.529054458764385

Epoch: 5| Step: 3
Training loss: 2.703282346170158
Validation loss: 2.5439231320010336

Epoch: 5| Step: 4
Training loss: 2.5335455010895913
Validation loss: 2.5372812684218777

Epoch: 5| Step: 5
Training loss: 2.002118895575756
Validation loss: 2.537870818010874

Epoch: 5| Step: 6
Training loss: 2.020157560114554
Validation loss: 2.5604050182597984

Epoch: 5| Step: 7
Training loss: 2.2588371934722895
Validation loss: 2.5903222863160535

Epoch: 5| Step: 8
Training loss: 2.4887535808696497
Validation loss: 2.6020932386488225

Epoch: 5| Step: 9
Training loss: 2.197128684968859
Validation loss: 2.5796030181292253

Epoch: 5| Step: 10
Training loss: 2.414951494097046
Validation loss: 2.5824325411277256

Epoch: 5| Step: 11
Training loss: 2.4504652243347236
Validation loss: 2.5785158535389403

Epoch: 316| Step: 0
Training loss: 2.5152041634115068
Validation loss: 2.557198440551352

Epoch: 5| Step: 1
Training loss: 2.6309034178175903
Validation loss: 2.5340124683911385

Epoch: 5| Step: 2
Training loss: 2.2460867442146175
Validation loss: 2.5205045944167703

Epoch: 5| Step: 3
Training loss: 1.816996685581407
Validation loss: 2.49433421810275

Epoch: 5| Step: 4
Training loss: 2.1565439880752866
Validation loss: 2.5307945265530347

Epoch: 5| Step: 5
Training loss: 1.8197644108472746
Validation loss: 2.516993515682494

Epoch: 5| Step: 6
Training loss: 2.0366362537084117
Validation loss: 2.528068866900308

Epoch: 5| Step: 7
Training loss: 1.780175001778417
Validation loss: 2.5281947146353296

Epoch: 5| Step: 8
Training loss: 2.5871353371590553
Validation loss: 2.544178280014095

Epoch: 5| Step: 9
Training loss: 2.047142186089163
Validation loss: 2.560819140482968

Epoch: 5| Step: 10
Training loss: 2.72388263157137
Validation loss: 2.579726151612539

Epoch: 5| Step: 11
Training loss: 3.150065188263192
Validation loss: 2.566648321865422

Epoch: 317| Step: 0
Training loss: 1.9296601328279828
Validation loss: 2.550500278858767

Epoch: 5| Step: 1
Training loss: 1.9845979820584887
Validation loss: 2.5402200261132686

Epoch: 5| Step: 2
Training loss: 2.669746577348113
Validation loss: 2.533638706175033

Epoch: 5| Step: 3
Training loss: 2.321967462724062
Validation loss: 2.5248290477769784

Epoch: 5| Step: 4
Training loss: 1.7619777582087588
Validation loss: 2.4989816498924164

Epoch: 5| Step: 5
Training loss: 2.255754529489956
Validation loss: 2.4799409199606983

Epoch: 5| Step: 6
Training loss: 2.0143746926463972
Validation loss: 2.4791855924883017

Epoch: 5| Step: 7
Training loss: 2.6479359379709133
Validation loss: 2.469731855908432

Epoch: 5| Step: 8
Training loss: 1.7119555645104807
Validation loss: 2.47336741701798

Epoch: 5| Step: 9
Training loss: 2.190903658700063
Validation loss: 2.463852847946236

Epoch: 5| Step: 10
Training loss: 2.904573839086647
Validation loss: 2.4775313879848246

Epoch: 5| Step: 11
Training loss: 3.1150669160516427
Validation loss: 2.5099360664173793

Epoch: 318| Step: 0
Training loss: 2.098585438005012
Validation loss: 2.525248693424747

Epoch: 5| Step: 1
Training loss: 2.104570922794831
Validation loss: 2.547008023366833

Epoch: 5| Step: 2
Training loss: 2.9317034079927873
Validation loss: 2.576335902724546

Epoch: 5| Step: 3
Training loss: 2.7563075641321384
Validation loss: 2.5868271126300497

Epoch: 5| Step: 4
Training loss: 1.6905866579795392
Validation loss: 2.5729127039602138

Epoch: 5| Step: 5
Training loss: 2.0869232020447974
Validation loss: 2.536360193713029

Epoch: 5| Step: 6
Training loss: 2.059739085590213
Validation loss: 2.5266110332406644

Epoch: 5| Step: 7
Training loss: 2.3327236968587237
Validation loss: 2.512297413852604

Epoch: 5| Step: 8
Training loss: 2.547296032887147
Validation loss: 2.4886644747996325

Epoch: 5| Step: 9
Training loss: 1.8682167695861318
Validation loss: 2.4829849817034595

Epoch: 5| Step: 10
Training loss: 2.179629854923509
Validation loss: 2.4956972407225213

Epoch: 5| Step: 11
Training loss: 2.5004557194197727
Validation loss: 2.487761067344069

Epoch: 319| Step: 0
Training loss: 2.1971909709540034
Validation loss: 2.485445515693559

Epoch: 5| Step: 1
Training loss: 2.4494098302842495
Validation loss: 2.477834723742542

Epoch: 5| Step: 2
Training loss: 1.9926096749364615
Validation loss: 2.483356955008415

Epoch: 5| Step: 3
Training loss: 2.34900838343268
Validation loss: 2.489730855861851

Epoch: 5| Step: 4
Training loss: 1.9304278108091382
Validation loss: 2.4927966450660484

Epoch: 5| Step: 5
Training loss: 2.881491092020087
Validation loss: 2.508263837500062

Epoch: 5| Step: 6
Training loss: 2.446584742297948
Validation loss: 2.5333951212119903

Epoch: 5| Step: 7
Training loss: 2.5502513200666534
Validation loss: 2.5521755175906518

Epoch: 5| Step: 8
Training loss: 2.241919524763897
Validation loss: 2.5511208853850973

Epoch: 5| Step: 9
Training loss: 1.7308957367497364
Validation loss: 2.533254542009104

Epoch: 5| Step: 10
Training loss: 1.6196959570506229
Validation loss: 2.5289959054633195

Epoch: 5| Step: 11
Training loss: 2.751669117098325
Validation loss: 2.527189541907044

Epoch: 320| Step: 0
Training loss: 2.4213865710545175
Validation loss: 2.5117990650014277

Epoch: 5| Step: 1
Training loss: 2.339085629641247
Validation loss: 2.52421962399961

Epoch: 5| Step: 2
Training loss: 1.9980083920528826
Validation loss: 2.5235164106409975

Epoch: 5| Step: 3
Training loss: 2.0466574050909148
Validation loss: 2.520330234377689

Epoch: 5| Step: 4
Training loss: 2.5367186071397594
Validation loss: 2.5331758347185653

Epoch: 5| Step: 5
Training loss: 1.6791432763198852
Validation loss: 2.5328258859985486

Epoch: 5| Step: 6
Training loss: 2.391182429330593
Validation loss: 2.5418160282607563

Epoch: 5| Step: 7
Training loss: 2.3301385965997845
Validation loss: 2.5373019330625413

Epoch: 5| Step: 8
Training loss: 2.2572644898510084
Validation loss: 2.538759399320281

Epoch: 5| Step: 9
Training loss: 1.9579754225032941
Validation loss: 2.53121523578146

Epoch: 5| Step: 10
Training loss: 2.275655077845761
Validation loss: 2.526175903738661

Epoch: 5| Step: 11
Training loss: 3.8030270315448895
Validation loss: 2.515415338897439

Epoch: 321| Step: 0
Training loss: 2.247387216727549
Validation loss: 2.511553844458981

Epoch: 5| Step: 1
Training loss: 1.8982346665772785
Validation loss: 2.526317527626005

Epoch: 5| Step: 2
Training loss: 2.3135202580033516
Validation loss: 2.5183003812317546

Epoch: 5| Step: 3
Training loss: 2.2539072020213005
Validation loss: 2.5457367625601153

Epoch: 5| Step: 4
Training loss: 2.107111189375656
Validation loss: 2.554834211921661

Epoch: 5| Step: 5
Training loss: 1.7969452553988028
Validation loss: 2.5438060641847136

Epoch: 5| Step: 6
Training loss: 2.6556220714887817
Validation loss: 2.546137556721634

Epoch: 5| Step: 7
Training loss: 2.1060816168334777
Validation loss: 2.569287324660819

Epoch: 5| Step: 8
Training loss: 2.516654994339643
Validation loss: 2.5556767888153753

Epoch: 5| Step: 9
Training loss: 2.682478627229073
Validation loss: 2.5620466195631315

Epoch: 5| Step: 10
Training loss: 1.9863570519725657
Validation loss: 2.550090125616761

Epoch: 5| Step: 11
Training loss: 1.4066487064992785
Validation loss: 2.5466144990217217

Epoch: 322| Step: 0
Training loss: 1.9228891937618782
Validation loss: 2.5695644244686004

Epoch: 5| Step: 1
Training loss: 2.403631494767944
Validation loss: 2.569476477678193

Epoch: 5| Step: 2
Training loss: 2.4558031563856697
Validation loss: 2.5571350404487223

Epoch: 5| Step: 3
Training loss: 2.878801734714534
Validation loss: 2.560085263750879

Epoch: 5| Step: 4
Training loss: 2.008564611495848
Validation loss: 2.547009017944347

Epoch: 5| Step: 5
Training loss: 2.321168581059023
Validation loss: 2.535790916980897

Epoch: 5| Step: 6
Training loss: 1.7834447089143635
Validation loss: 2.5310969326064354

Epoch: 5| Step: 7
Training loss: 2.2251295330617964
Validation loss: 2.535963841879483

Epoch: 5| Step: 8
Training loss: 2.5286309149813104
Validation loss: 2.5285007554356693

Epoch: 5| Step: 9
Training loss: 2.2351780228686025
Validation loss: 2.521023208518648

Epoch: 5| Step: 10
Training loss: 2.0213303364468973
Validation loss: 2.53167120839474

Epoch: 5| Step: 11
Training loss: 1.7706086708121107
Validation loss: 2.523402195103825

Epoch: 323| Step: 0
Training loss: 2.2466294155749216
Validation loss: 2.5193517221763235

Epoch: 5| Step: 1
Training loss: 1.4373918575575875
Validation loss: 2.519816935899958

Epoch: 5| Step: 2
Training loss: 1.9295848865484935
Validation loss: 2.525296332656058

Epoch: 5| Step: 3
Training loss: 2.4725526905520443
Validation loss: 2.5201111434213233

Epoch: 5| Step: 4
Training loss: 2.217878681005444
Validation loss: 2.512569692698425

Epoch: 5| Step: 5
Training loss: 2.5811928731217266
Validation loss: 2.5100070446385416

Epoch: 5| Step: 6
Training loss: 2.0810700393174955
Validation loss: 2.523957926148872

Epoch: 5| Step: 7
Training loss: 1.9004568654950897
Validation loss: 2.531649499143949

Epoch: 5| Step: 8
Training loss: 2.427837882133275
Validation loss: 2.535709510782097

Epoch: 5| Step: 9
Training loss: 2.6814955236599225
Validation loss: 2.521662214583681

Epoch: 5| Step: 10
Training loss: 2.2805038695132147
Validation loss: 2.563263139832248

Epoch: 5| Step: 11
Training loss: 3.5482181912995214
Validation loss: 2.574875153135303

Epoch: 324| Step: 0
Training loss: 2.217751506661712
Validation loss: 2.5827722529763886

Epoch: 5| Step: 1
Training loss: 2.4751661919176873
Validation loss: 2.565881781015879

Epoch: 5| Step: 2
Training loss: 2.074677095221923
Validation loss: 2.596973562761037

Epoch: 5| Step: 3
Training loss: 2.7444942151531815
Validation loss: 2.5737864044910155

Epoch: 5| Step: 4
Training loss: 1.9691482625524495
Validation loss: 2.5454106831216183

Epoch: 5| Step: 5
Training loss: 2.3610270192249505
Validation loss: 2.546144220710898

Epoch: 5| Step: 6
Training loss: 1.62317900228874
Validation loss: 2.5386158516090536

Epoch: 5| Step: 7
Training loss: 2.6383877819400667
Validation loss: 2.5361250019308197

Epoch: 5| Step: 8
Training loss: 2.122459351382896
Validation loss: 2.5178349228077854

Epoch: 5| Step: 9
Training loss: 2.611645378978695
Validation loss: 2.526189600489723

Epoch: 5| Step: 10
Training loss: 1.7087224966764478
Validation loss: 2.5230881180428772

Epoch: 5| Step: 11
Training loss: 1.9440605087282339
Validation loss: 2.515172819010442

Epoch: 325| Step: 0
Training loss: 2.4881141402873093
Validation loss: 2.486800778899946

Epoch: 5| Step: 1
Training loss: 1.8862246543642587
Validation loss: 2.4826686405334693

Epoch: 5| Step: 2
Training loss: 2.288694176318637
Validation loss: 2.4731192855826785

Epoch: 5| Step: 3
Training loss: 2.2695727451227583
Validation loss: 2.46258516809829

Epoch: 5| Step: 4
Training loss: 2.9140425366901646
Validation loss: 2.478311877522292

Epoch: 5| Step: 5
Training loss: 1.996185778383229
Validation loss: 2.500971049231078

Epoch: 5| Step: 6
Training loss: 1.9212025031806352
Validation loss: 2.5046075403210013

Epoch: 5| Step: 7
Training loss: 1.914309614150262
Validation loss: 2.5150173748685223

Epoch: 5| Step: 8
Training loss: 2.133712187545402
Validation loss: 2.520907079127633

Epoch: 5| Step: 9
Training loss: 2.669633962850613
Validation loss: 2.486945789505972

Epoch: 5| Step: 10
Training loss: 2.307022618666126
Validation loss: 2.4948972760639196

Epoch: 5| Step: 11
Training loss: 1.8102975815682314
Validation loss: 2.5109142322170404

Epoch: 326| Step: 0
Training loss: 2.5034318257278136
Validation loss: 2.502049087165116

Epoch: 5| Step: 1
Training loss: 2.001066638711944
Validation loss: 2.5243533630747184

Epoch: 5| Step: 2
Training loss: 1.7733835220524723
Validation loss: 2.5080024869103905

Epoch: 5| Step: 3
Training loss: 3.097317266977882
Validation loss: 2.4942819808697045

Epoch: 5| Step: 4
Training loss: 2.347047850723633
Validation loss: 2.489573244582501

Epoch: 5| Step: 5
Training loss: 2.1528773814577282
Validation loss: 2.4837221171454344

Epoch: 5| Step: 6
Training loss: 2.548254376725321
Validation loss: 2.493771283975916

Epoch: 5| Step: 7
Training loss: 2.1424034137832533
Validation loss: 2.5078364813778045

Epoch: 5| Step: 8
Training loss: 2.007745763953529
Validation loss: 2.5373755930327913

Epoch: 5| Step: 9
Training loss: 1.6932204738438001
Validation loss: 2.5536930042266874

Epoch: 5| Step: 10
Training loss: 2.0965168449512994
Validation loss: 2.5871254496300846

Epoch: 5| Step: 11
Training loss: 3.281935992512309
Validation loss: 2.5575378607641364

Epoch: 327| Step: 0
Training loss: 2.22848203133915
Validation loss: 2.5573711823158476

Epoch: 5| Step: 1
Training loss: 2.2433923547848966
Validation loss: 2.5288771193881696

Epoch: 5| Step: 2
Training loss: 1.9870122970945427
Validation loss: 2.514183595031588

Epoch: 5| Step: 3
Training loss: 2.2681965933270036
Validation loss: 2.49080221246894

Epoch: 5| Step: 4
Training loss: 2.401590170170378
Validation loss: 2.48273580283441

Epoch: 5| Step: 5
Training loss: 1.8323166874978465
Validation loss: 2.469327746362147

Epoch: 5| Step: 6
Training loss: 2.499573671229322
Validation loss: 2.490362290232373

Epoch: 5| Step: 7
Training loss: 1.7226141753648636
Validation loss: 2.500510894706906

Epoch: 5| Step: 8
Training loss: 2.458557431195491
Validation loss: 2.5357656779892266

Epoch: 5| Step: 9
Training loss: 2.449089472764413
Validation loss: 2.515002230844842

Epoch: 5| Step: 10
Training loss: 2.7084550292232485
Validation loss: 2.5145987713794726

Epoch: 5| Step: 11
Training loss: 2.274615320233622
Validation loss: 2.551731250117134

Epoch: 328| Step: 0
Training loss: 2.757465459584802
Validation loss: 2.5306879683335994

Epoch: 5| Step: 1
Training loss: 2.7073477687994103
Validation loss: 2.516130633509961

Epoch: 5| Step: 2
Training loss: 1.5924232794996842
Validation loss: 2.5093473568316536

Epoch: 5| Step: 3
Training loss: 1.842992400647877
Validation loss: 2.5102682043367213

Epoch: 5| Step: 4
Training loss: 2.310453798381514
Validation loss: 2.535733428127432

Epoch: 5| Step: 5
Training loss: 2.814781619828042
Validation loss: 2.520466550567867

Epoch: 5| Step: 6
Training loss: 1.493947374400051
Validation loss: 2.5251560559534405

Epoch: 5| Step: 7
Training loss: 2.357797764958979
Validation loss: 2.5276204134150846

Epoch: 5| Step: 8
Training loss: 2.3826067726250977
Validation loss: 2.544571843427152

Epoch: 5| Step: 9
Training loss: 2.119127799140334
Validation loss: 2.5443509159870783

Epoch: 5| Step: 10
Training loss: 2.0490321084183494
Validation loss: 2.5472115955376093

Epoch: 5| Step: 11
Training loss: 1.6413486882774209
Validation loss: 2.5301147042094474

Epoch: 329| Step: 0
Training loss: 2.3410278788474552
Validation loss: 2.517569333523044

Epoch: 5| Step: 1
Training loss: 2.125780074607471
Validation loss: 2.5237179807949777

Epoch: 5| Step: 2
Training loss: 1.9791769596300675
Validation loss: 2.4868838559939173

Epoch: 5| Step: 3
Training loss: 2.101724270972253
Validation loss: 2.478556843828971

Epoch: 5| Step: 4
Training loss: 1.9950298303271718
Validation loss: 2.489670569728309

Epoch: 5| Step: 5
Training loss: 2.2368973586400474
Validation loss: 2.4842973453053387

Epoch: 5| Step: 6
Training loss: 2.5194401214442887
Validation loss: 2.491680962756512

Epoch: 5| Step: 7
Training loss: 2.2239211091999347
Validation loss: 2.4881862221003304

Epoch: 5| Step: 8
Training loss: 2.640527305827346
Validation loss: 2.4964425565109716

Epoch: 5| Step: 9
Training loss: 2.6880367541468413
Validation loss: 2.507800437922006

Epoch: 5| Step: 10
Training loss: 1.8300194339032974
Validation loss: 2.4916201696129447

Epoch: 5| Step: 11
Training loss: 2.4370533460586463
Validation loss: 2.5233178046373124

Epoch: 330| Step: 0
Training loss: 2.448830703098719
Validation loss: 2.538595929437881

Epoch: 5| Step: 1
Training loss: 1.8733118086672238
Validation loss: 2.5723399482480684

Epoch: 5| Step: 2
Training loss: 2.272038819337365
Validation loss: 2.582123739843496

Epoch: 5| Step: 3
Training loss: 1.7465810074561927
Validation loss: 2.5926652769623857

Epoch: 5| Step: 4
Training loss: 1.8457592506554057
Validation loss: 2.6099135743431856

Epoch: 5| Step: 5
Training loss: 2.392839092113352
Validation loss: 2.57569052455747

Epoch: 5| Step: 6
Training loss: 2.13070194211762
Validation loss: 2.555896103727341

Epoch: 5| Step: 7
Training loss: 2.7041921107932434
Validation loss: 2.512824472190821

Epoch: 5| Step: 8
Training loss: 2.206701203370826
Validation loss: 2.510484177458579

Epoch: 5| Step: 9
Training loss: 2.0902345666259725
Validation loss: 2.502662937190065

Epoch: 5| Step: 10
Training loss: 2.7989591366864097
Validation loss: 2.4804856908024475

Epoch: 5| Step: 11
Training loss: 2.129358757993909
Validation loss: 2.473338056739331

Epoch: 331| Step: 0
Training loss: 1.8045557807974575
Validation loss: 2.4724375350346435

Epoch: 5| Step: 1
Training loss: 2.1574005153523483
Validation loss: 2.4712582413145734

Epoch: 5| Step: 2
Training loss: 2.087925338813384
Validation loss: 2.470511447874566

Epoch: 5| Step: 3
Training loss: 2.818618054061276
Validation loss: 2.474431164714256

Epoch: 5| Step: 4
Training loss: 2.862012803374948
Validation loss: 2.4698052786574394

Epoch: 5| Step: 5
Training loss: 2.4264567689281114
Validation loss: 2.48845876981728

Epoch: 5| Step: 6
Training loss: 1.7313129785423518
Validation loss: 2.5281071519634257

Epoch: 5| Step: 7
Training loss: 1.7260721468339757
Validation loss: 2.527773188288741

Epoch: 5| Step: 8
Training loss: 2.3909771229835335
Validation loss: 2.554495066356692

Epoch: 5| Step: 9
Training loss: 2.084569132170213
Validation loss: 2.559995819395099

Epoch: 5| Step: 10
Training loss: 2.217322199078787
Validation loss: 2.538004450305146

Epoch: 5| Step: 11
Training loss: 3.1175442063685495
Validation loss: 2.5848185239769745

Epoch: 332| Step: 0
Training loss: 2.2200179439541183
Validation loss: 2.590085370744574

Epoch: 5| Step: 1
Training loss: 2.252420606833433
Validation loss: 2.567343720140531

Epoch: 5| Step: 2
Training loss: 2.989983685809381
Validation loss: 2.590103684888179

Epoch: 5| Step: 3
Training loss: 2.0831330266661103
Validation loss: 2.5689810422341637

Epoch: 5| Step: 4
Training loss: 1.9761443166928216
Validation loss: 2.5351959131368003

Epoch: 5| Step: 5
Training loss: 2.497408190959525
Validation loss: 2.501016723993549

Epoch: 5| Step: 6
Training loss: 2.1075122661844508
Validation loss: 2.4789995102401665

Epoch: 5| Step: 7
Training loss: 1.9931035348018058
Validation loss: 2.478818409498829

Epoch: 5| Step: 8
Training loss: 2.185245878408831
Validation loss: 2.470141274318759

Epoch: 5| Step: 9
Training loss: 2.534785779971929
Validation loss: 2.467502689340782

Epoch: 5| Step: 10
Training loss: 2.0589562229062177
Validation loss: 2.4728346283718516

Epoch: 5| Step: 11
Training loss: 2.446662310909098
Validation loss: 2.465900837304193

Epoch: 333| Step: 0
Training loss: 2.299276951459245
Validation loss: 2.464825416009087

Epoch: 5| Step: 1
Training loss: 2.1805678473232115
Validation loss: 2.464659920279333

Epoch: 5| Step: 2
Training loss: 2.736473542514719
Validation loss: 2.470158850990445

Epoch: 5| Step: 3
Training loss: 2.8587804290793324
Validation loss: 2.46668693597516

Epoch: 5| Step: 4
Training loss: 2.2094896516093594
Validation loss: 2.473908929164225

Epoch: 5| Step: 5
Training loss: 2.0525553849399167
Validation loss: 2.4799546116923445

Epoch: 5| Step: 6
Training loss: 2.4908811200602208
Validation loss: 2.4870300880265326

Epoch: 5| Step: 7
Training loss: 1.9491420570223632
Validation loss: 2.491909613508046

Epoch: 5| Step: 8
Training loss: 1.5349324381122096
Validation loss: 2.499067378928007

Epoch: 5| Step: 9
Training loss: 2.276349172762265
Validation loss: 2.5233280248682717

Epoch: 5| Step: 10
Training loss: 2.187038808979768
Validation loss: 2.517667935991247

Epoch: 5| Step: 11
Training loss: 1.8401293360823152
Validation loss: 2.525100518262241

Epoch: 334| Step: 0
Training loss: 2.492115653506161
Validation loss: 2.5467092424993782

Epoch: 5| Step: 1
Training loss: 2.4831723355155746
Validation loss: 2.5411907255931494

Epoch: 5| Step: 2
Training loss: 2.0793018880637133
Validation loss: 2.5432564201095205

Epoch: 5| Step: 3
Training loss: 2.1688400030011814
Validation loss: 2.5308494368668764

Epoch: 5| Step: 4
Training loss: 2.262752948762858
Validation loss: 2.5321697753941232

Epoch: 5| Step: 5
Training loss: 2.1431440025147954
Validation loss: 2.52689796694586

Epoch: 5| Step: 6
Training loss: 2.6329789377913806
Validation loss: 2.5260845960659357

Epoch: 5| Step: 7
Training loss: 1.9292972185467083
Validation loss: 2.52267189733796

Epoch: 5| Step: 8
Training loss: 2.3701407262814436
Validation loss: 2.519832116036666

Epoch: 5| Step: 9
Training loss: 1.9832378944172737
Validation loss: 2.519269581693809

Epoch: 5| Step: 10
Training loss: 1.9635600149037733
Validation loss: 2.5262103204695503

Epoch: 5| Step: 11
Training loss: 2.9684828788645246
Validation loss: 2.520161134510651

Epoch: 335| Step: 0
Training loss: 2.1350607846829024
Validation loss: 2.5476531710231267

Epoch: 5| Step: 1
Training loss: 2.497885954612127
Validation loss: 2.5486372680141787

Epoch: 5| Step: 2
Training loss: 1.922565801260808
Validation loss: 2.5630730205376

Epoch: 5| Step: 3
Training loss: 2.149154266088929
Validation loss: 2.546707093178431

Epoch: 5| Step: 4
Training loss: 2.248430128264388
Validation loss: 2.530632767951558

Epoch: 5| Step: 5
Training loss: 1.5304029807913706
Validation loss: 2.55669646060084

Epoch: 5| Step: 6
Training loss: 2.165522444417372
Validation loss: 2.544039308028118

Epoch: 5| Step: 7
Training loss: 2.3778053580176985
Validation loss: 2.5508254097528114

Epoch: 5| Step: 8
Training loss: 2.6815785666867873
Validation loss: 2.5575398999927312

Epoch: 5| Step: 9
Training loss: 2.023278778802899
Validation loss: 2.573794884292643

Epoch: 5| Step: 10
Training loss: 2.6113592586786987
Validation loss: 2.573269875152474

Epoch: 5| Step: 11
Training loss: 1.1678288098452676
Validation loss: 2.5713857479730353

Epoch: 336| Step: 0
Training loss: 1.8952928408415324
Validation loss: 2.5762890144884776

Epoch: 5| Step: 1
Training loss: 2.402839125754742
Validation loss: 2.569296163427266

Epoch: 5| Step: 2
Training loss: 2.1470714318199575
Validation loss: 2.539842163104216

Epoch: 5| Step: 3
Training loss: 2.050425936481514
Validation loss: 2.537020322721292

Epoch: 5| Step: 4
Training loss: 2.8298806489505326
Validation loss: 2.56511108604053

Epoch: 5| Step: 5
Training loss: 2.1712309616563092
Validation loss: 2.587874625294487

Epoch: 5| Step: 6
Training loss: 2.6907347795197207
Validation loss: 2.619346001841602

Epoch: 5| Step: 7
Training loss: 2.655250810173909
Validation loss: 2.625910203803876

Epoch: 5| Step: 8
Training loss: 1.88026826151889
Validation loss: 2.6417482646790718

Epoch: 5| Step: 9
Training loss: 1.8981168499703482
Validation loss: 2.6277694965191287

Epoch: 5| Step: 10
Training loss: 1.9238061274321367
Validation loss: 2.6314538625270916

Epoch: 5| Step: 11
Training loss: 1.2659972314578334
Validation loss: 2.6421756555377116

Epoch: 337| Step: 0
Training loss: 3.04635819184682
Validation loss: 2.5960528748277487

Epoch: 5| Step: 1
Training loss: 2.0058980044737584
Validation loss: 2.555910282521014

Epoch: 5| Step: 2
Training loss: 2.4712965181069864
Validation loss: 2.5179072506004854

Epoch: 5| Step: 3
Training loss: 1.910743108361381
Validation loss: 2.502626837086218

Epoch: 5| Step: 4
Training loss: 1.7556213285435618
Validation loss: 2.505076939606189

Epoch: 5| Step: 5
Training loss: 2.610700624634093
Validation loss: 2.5112517354303177

Epoch: 5| Step: 6
Training loss: 2.102321331765111
Validation loss: 2.5056498780145047

Epoch: 5| Step: 7
Training loss: 2.308548102274487
Validation loss: 2.505282507344916

Epoch: 5| Step: 8
Training loss: 2.181181364974408
Validation loss: 2.52200011108856

Epoch: 5| Step: 9
Training loss: 1.9260283460581094
Validation loss: 2.517951055802477

Epoch: 5| Step: 10
Training loss: 2.004004998404538
Validation loss: 2.5723854680047853

Epoch: 5| Step: 11
Training loss: 2.253860340940051
Validation loss: 2.5568759655443607

Epoch: 338| Step: 0
Training loss: 2.2389459338728814
Validation loss: 2.5467684553830803

Epoch: 5| Step: 1
Training loss: 2.0083569927589493
Validation loss: 2.544427764696545

Epoch: 5| Step: 2
Training loss: 2.2797759009537177
Validation loss: 2.538148330052713

Epoch: 5| Step: 3
Training loss: 2.3268493639455685
Validation loss: 2.530408319009016

Epoch: 5| Step: 4
Training loss: 1.7303632096942476
Validation loss: 2.55128988790224

Epoch: 5| Step: 5
Training loss: 1.6873921960375102
Validation loss: 2.5630793769370888

Epoch: 5| Step: 6
Training loss: 2.826981371224135
Validation loss: 2.5713290819800623

Epoch: 5| Step: 7
Training loss: 2.324905319747145
Validation loss: 2.5613759451998086

Epoch: 5| Step: 8
Training loss: 2.2782902787146533
Validation loss: 2.55701800641217

Epoch: 5| Step: 9
Training loss: 2.1013201605743776
Validation loss: 2.5757547021002387

Epoch: 5| Step: 10
Training loss: 2.2366148918894333
Validation loss: 2.5603291690320575

Epoch: 5| Step: 11
Training loss: 1.9147043825665697
Validation loss: 2.56865373865769

Epoch: 339| Step: 0
Training loss: 2.446762386376029
Validation loss: 2.5587903439848314

Epoch: 5| Step: 1
Training loss: 1.561236137408002
Validation loss: 2.5438276208755397

Epoch: 5| Step: 2
Training loss: 2.9167353667388065
Validation loss: 2.556133176190671

Epoch: 5| Step: 3
Training loss: 2.3660675521777703
Validation loss: 2.557491206653999

Epoch: 5| Step: 4
Training loss: 2.3324207383208795
Validation loss: 2.5460183920510624

Epoch: 5| Step: 5
Training loss: 1.4939220792220829
Validation loss: 2.5364982215413407

Epoch: 5| Step: 6
Training loss: 2.1260396994457524
Validation loss: 2.545087639618082

Epoch: 5| Step: 7
Training loss: 2.508540062818439
Validation loss: 2.549354115043896

Epoch: 5| Step: 8
Training loss: 2.350280412217284
Validation loss: 2.5576834770196912

Epoch: 5| Step: 9
Training loss: 1.4884101231163864
Validation loss: 2.5614954328442288

Epoch: 5| Step: 10
Training loss: 2.358218686537607
Validation loss: 2.569791472401101

Epoch: 5| Step: 11
Training loss: 1.7831881502657108
Validation loss: 2.576623309736259

Epoch: 340| Step: 0
Training loss: 2.5134965884396294
Validation loss: 2.5751256816401358

Epoch: 5| Step: 1
Training loss: 1.856254844787646
Validation loss: 2.6050659432609957

Epoch: 5| Step: 2
Training loss: 1.8346445278774453
Validation loss: 2.575096443833057

Epoch: 5| Step: 3
Training loss: 2.0055904932521833
Validation loss: 2.573405089460887

Epoch: 5| Step: 4
Training loss: 2.071371131720708
Validation loss: 2.55308589446221

Epoch: 5| Step: 5
Training loss: 2.527509680936028
Validation loss: 2.541259855534922

Epoch: 5| Step: 6
Training loss: 2.6283136071057736
Validation loss: 2.533511489848635

Epoch: 5| Step: 7
Training loss: 2.508283814440986
Validation loss: 2.5314875126304095

Epoch: 5| Step: 8
Training loss: 2.215002844746229
Validation loss: 2.530185876094641

Epoch: 5| Step: 9
Training loss: 2.3799245875295885
Validation loss: 2.5233200663984623

Epoch: 5| Step: 10
Training loss: 1.970109742491757
Validation loss: 2.532133172045711

Epoch: 5| Step: 11
Training loss: 1.9328273911392058
Validation loss: 2.5302737123270105

Epoch: 341| Step: 0
Training loss: 3.0494500649375067
Validation loss: 2.54801163146824

Epoch: 5| Step: 1
Training loss: 2.147116848179229
Validation loss: 2.519714116205052

Epoch: 5| Step: 2
Training loss: 2.20018025006634
Validation loss: 2.531943277307705

Epoch: 5| Step: 3
Training loss: 2.1500588697313723
Validation loss: 2.524587674199895

Epoch: 5| Step: 4
Training loss: 2.1555726466315175
Validation loss: 2.5395418839414003

Epoch: 5| Step: 5
Training loss: 2.0126049275026046
Validation loss: 2.549937733345006

Epoch: 5| Step: 6
Training loss: 1.8089520818290454
Validation loss: 2.5818835941018685

Epoch: 5| Step: 7
Training loss: 1.8575719858958453
Validation loss: 2.5840977427400205

Epoch: 5| Step: 8
Training loss: 2.3635519077644607
Validation loss: 2.563763818540861

Epoch: 5| Step: 9
Training loss: 2.366904566005748
Validation loss: 2.5824977974576075

Epoch: 5| Step: 10
Training loss: 2.0899480205442096
Validation loss: 2.577541300655171

Epoch: 5| Step: 11
Training loss: 2.064462133007192
Validation loss: 2.5989369497903847

Epoch: 342| Step: 0
Training loss: 2.394836008115759
Validation loss: 2.5967268693818704

Epoch: 5| Step: 1
Training loss: 1.7948214530871627
Validation loss: 2.634628748560872

Epoch: 5| Step: 2
Training loss: 2.868389657188135
Validation loss: 2.60173869562563

Epoch: 5| Step: 3
Training loss: 2.240718559748516
Validation loss: 2.6032810129320816

Epoch: 5| Step: 4
Training loss: 2.220126195362268
Validation loss: 2.6115368664779752

Epoch: 5| Step: 5
Training loss: 1.6379708028247548
Validation loss: 2.6129262062433516

Epoch: 5| Step: 6
Training loss: 2.0525869793879337
Validation loss: 2.62116011314311

Epoch: 5| Step: 7
Training loss: 2.188502272829789
Validation loss: 2.61031216602254

Epoch: 5| Step: 8
Training loss: 1.9830966947202426
Validation loss: 2.5678495299933033

Epoch: 5| Step: 9
Training loss: 1.6637888938662444
Validation loss: 2.5574455344428038

Epoch: 5| Step: 10
Training loss: 2.9304473298524836
Validation loss: 2.5430367397706286

Epoch: 5| Step: 11
Training loss: 0.774030284865743
Validation loss: 2.503565530512193

Epoch: 343| Step: 0
Training loss: 2.4972456063814206
Validation loss: 2.5266059219067096

Epoch: 5| Step: 1
Training loss: 2.895364865253064
Validation loss: 2.5349699284013245

Epoch: 5| Step: 2
Training loss: 2.079746961424266
Validation loss: 2.529462512863359

Epoch: 5| Step: 3
Training loss: 1.8730630406546271
Validation loss: 2.530328810613627

Epoch: 5| Step: 4
Training loss: 1.938466600060987
Validation loss: 2.5469428172375412

Epoch: 5| Step: 5
Training loss: 2.727172870686357
Validation loss: 2.545117132386782

Epoch: 5| Step: 6
Training loss: 1.9419231379116215
Validation loss: 2.5945280432477884

Epoch: 5| Step: 7
Training loss: 1.8562244683253404
Validation loss: 2.5745660164612834

Epoch: 5| Step: 8
Training loss: 1.9994882882670237
Validation loss: 2.6043169143567204

Epoch: 5| Step: 9
Training loss: 1.9673077583671528
Validation loss: 2.6250624119438655

Epoch: 5| Step: 10
Training loss: 2.427286513396232
Validation loss: 2.5977097852348323

Epoch: 5| Step: 11
Training loss: 1.1206980149693428
Validation loss: 2.598852902085067

Epoch: 344| Step: 0
Training loss: 2.1495646901020664
Validation loss: 2.6160479669620877

Epoch: 5| Step: 1
Training loss: 2.654003674479444
Validation loss: 2.607911314253082

Epoch: 5| Step: 2
Training loss: 2.5757880514215348
Validation loss: 2.6113542181217366

Epoch: 5| Step: 3
Training loss: 2.1851130950779756
Validation loss: 2.618321692068331

Epoch: 5| Step: 4
Training loss: 1.89928458196608
Validation loss: 2.5777527164662826

Epoch: 5| Step: 5
Training loss: 2.07442897155191
Validation loss: 2.609610404172069

Epoch: 5| Step: 6
Training loss: 2.364939412153457
Validation loss: 2.592401793737183

Epoch: 5| Step: 7
Training loss: 2.3104527664689414
Validation loss: 2.5824795640110394

Epoch: 5| Step: 8
Training loss: 1.8562275509488295
Validation loss: 2.5660343839428426

Epoch: 5| Step: 9
Training loss: 1.6910978040423665
Validation loss: 2.546944942957157

Epoch: 5| Step: 10
Training loss: 2.233001286698896
Validation loss: 2.5424634311281724

Epoch: 5| Step: 11
Training loss: 1.390933827601264
Validation loss: 2.524393933804392

Epoch: 345| Step: 0
Training loss: 2.240354632847311
Validation loss: 2.5107957479886185

Epoch: 5| Step: 1
Training loss: 1.9634839428040383
Validation loss: 2.5055315849403286

Epoch: 5| Step: 2
Training loss: 2.5437864521235993
Validation loss: 2.515320556099445

Epoch: 5| Step: 3
Training loss: 2.3155347139824345
Validation loss: 2.522633260033643

Epoch: 5| Step: 4
Training loss: 2.2922885282234335
Validation loss: 2.5006920571883593

Epoch: 5| Step: 5
Training loss: 2.601543162964218
Validation loss: 2.526176505406288

Epoch: 5| Step: 6
Training loss: 1.7521490117243166
Validation loss: 2.5510894565823015

Epoch: 5| Step: 7
Training loss: 2.4383749736360163
Validation loss: 2.5786313224440183

Epoch: 5| Step: 8
Training loss: 1.9356613664225506
Validation loss: 2.5997972198418053

Epoch: 5| Step: 9
Training loss: 1.8640618118834844
Validation loss: 2.6167178914093836

Epoch: 5| Step: 10
Training loss: 2.7029963997475726
Validation loss: 2.62688361812185

Epoch: 5| Step: 11
Training loss: 0.8413165994840003
Validation loss: 2.607864468047005

Epoch: 346| Step: 0
Training loss: 1.8636754416705679
Validation loss: 2.5865039723600116

Epoch: 5| Step: 1
Training loss: 2.1726836750449063
Validation loss: 2.546278628246264

Epoch: 5| Step: 2
Training loss: 2.4657298096015143
Validation loss: 2.531534339884095

Epoch: 5| Step: 3
Training loss: 1.7843650216326326
Validation loss: 2.5054295231383397

Epoch: 5| Step: 4
Training loss: 2.1166732557699817
Validation loss: 2.501975133611962

Epoch: 5| Step: 5
Training loss: 1.6897814128522142
Validation loss: 2.503485149774022

Epoch: 5| Step: 6
Training loss: 2.6274393645602783
Validation loss: 2.5063064188326587

Epoch: 5| Step: 7
Training loss: 2.8391911781386803
Validation loss: 2.507085970238526

Epoch: 5| Step: 8
Training loss: 2.0193870979969137
Validation loss: 2.5231683034380237

Epoch: 5| Step: 9
Training loss: 1.9482543027113908
Validation loss: 2.5797162433873684

Epoch: 5| Step: 10
Training loss: 2.6757002546762885
Validation loss: 2.5989705520577093

Epoch: 5| Step: 11
Training loss: 1.2474275344717383
Validation loss: 2.6144364240998175

Epoch: 347| Step: 0
Training loss: 2.82386636184385
Validation loss: 2.634561880051396

Epoch: 5| Step: 1
Training loss: 1.6792754621575834
Validation loss: 2.6431033262667767

Epoch: 5| Step: 2
Training loss: 2.987220885194692
Validation loss: 2.664474738808453

Epoch: 5| Step: 3
Training loss: 2.0930924023436077
Validation loss: 2.637068469555701

Epoch: 5| Step: 4
Training loss: 1.8855448796917853
Validation loss: 2.588191134680969

Epoch: 5| Step: 5
Training loss: 2.4261801571352257
Validation loss: 2.515666827057488

Epoch: 5| Step: 6
Training loss: 2.4032462060966453
Validation loss: 2.468307982683131

Epoch: 5| Step: 7
Training loss: 2.242991871384115
Validation loss: 2.4657015146777397

Epoch: 5| Step: 8
Training loss: 1.4011204731650544
Validation loss: 2.47363324221188

Epoch: 5| Step: 9
Training loss: 2.2985564843557102
Validation loss: 2.4401514312715453

Epoch: 5| Step: 10
Training loss: 2.33728213187391
Validation loss: 2.4420688309884593

Epoch: 5| Step: 11
Training loss: 1.676121248197656
Validation loss: 2.4576638786518785

Epoch: 348| Step: 0
Training loss: 1.9535453649193437
Validation loss: 2.4565040455383764

Epoch: 5| Step: 1
Training loss: 2.3668395941871125
Validation loss: 2.443496492900482

Epoch: 5| Step: 2
Training loss: 2.5073794172204242
Validation loss: 2.44239525052696

Epoch: 5| Step: 3
Training loss: 2.6134327843128733
Validation loss: 2.4497991925617684

Epoch: 5| Step: 4
Training loss: 2.0022157078174927
Validation loss: 2.4521380461879403

Epoch: 5| Step: 5
Training loss: 1.9300363819863644
Validation loss: 2.4418083571853284

Epoch: 5| Step: 6
Training loss: 2.6423041066991235
Validation loss: 2.4673416490577873

Epoch: 5| Step: 7
Training loss: 2.456845420517661
Validation loss: 2.4693644539599746

Epoch: 5| Step: 8
Training loss: 2.1370033758027005
Validation loss: 2.4606130759528653

Epoch: 5| Step: 9
Training loss: 1.9778091660638881
Validation loss: 2.4760432857325716

Epoch: 5| Step: 10
Training loss: 2.3561439874816847
Validation loss: 2.487888997938347

Epoch: 5| Step: 11
Training loss: 2.3152228125831686
Validation loss: 2.5301303310209655

Epoch: 349| Step: 0
Training loss: 2.024540663062321
Validation loss: 2.556759098378585

Epoch: 5| Step: 1
Training loss: 1.8906498426586469
Validation loss: 2.578677805963877

Epoch: 5| Step: 2
Training loss: 2.1211806362053074
Validation loss: 2.584447195020294

Epoch: 5| Step: 3
Training loss: 2.1759201909463877
Validation loss: 2.6277214354303333

Epoch: 5| Step: 4
Training loss: 2.415136006002609
Validation loss: 2.6142771884873244

Epoch: 5| Step: 5
Training loss: 2.2594788417986225
Validation loss: 2.5685168896083237

Epoch: 5| Step: 6
Training loss: 2.5710740280206354
Validation loss: 2.5327450140234786

Epoch: 5| Step: 7
Training loss: 2.7778321599935154
Validation loss: 2.524460367728671

Epoch: 5| Step: 8
Training loss: 2.644903925861689
Validation loss: 2.523251494174864

Epoch: 5| Step: 9
Training loss: 2.4032687259548884
Validation loss: 2.5095189073469415

Epoch: 5| Step: 10
Training loss: 1.8709675342142797
Validation loss: 2.5395445224298796

Epoch: 5| Step: 11
Training loss: 2.079730797366371
Validation loss: 2.523866837375897

Epoch: 350| Step: 0
Training loss: 2.353982788826795
Validation loss: 2.5187952864230296

Epoch: 5| Step: 1
Training loss: 2.10080589089886
Validation loss: 2.5118558736482535

Epoch: 5| Step: 2
Training loss: 2.116516682675096
Validation loss: 2.5199640459253376

Epoch: 5| Step: 3
Training loss: 1.585430947572383
Validation loss: 2.5121247836960072

Epoch: 5| Step: 4
Training loss: 2.530838827010611
Validation loss: 2.518006916883259

Epoch: 5| Step: 5
Training loss: 2.144315781738773
Validation loss: 2.556241681645794

Epoch: 5| Step: 6
Training loss: 1.960237659331335
Validation loss: 2.566812615662478

Epoch: 5| Step: 7
Training loss: 2.156018341446465
Validation loss: 2.579954750332045

Epoch: 5| Step: 8
Training loss: 2.399360404619807
Validation loss: 2.589669879122849

Epoch: 5| Step: 9
Training loss: 2.256423153137373
Validation loss: 2.608472934669745

Epoch: 5| Step: 10
Training loss: 2.5257893754218976
Validation loss: 2.6190814268290605

Epoch: 5| Step: 11
Training loss: 3.096219397013616
Validation loss: 2.6147656674784794

Testing loss: 2.1952366344698118
