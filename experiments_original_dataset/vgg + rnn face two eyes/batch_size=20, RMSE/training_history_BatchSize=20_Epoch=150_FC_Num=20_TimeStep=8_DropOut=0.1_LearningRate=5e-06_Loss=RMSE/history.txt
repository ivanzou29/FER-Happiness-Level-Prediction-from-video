Epoch: 1| Step: 0
Training loss: 5.772675625263533
Validation loss: 5.88450429365451

Epoch: 5| Step: 1
Training loss: 6.010891248278646
Validation loss: 5.88293261023339

Epoch: 5| Step: 2
Training loss: 6.183595909171291
Validation loss: 5.881353203208866

Epoch: 5| Step: 3
Training loss: 6.213167224568257
Validation loss: 5.87985882819935

Epoch: 5| Step: 4
Training loss: 4.348489933335178
Validation loss: 5.87840634202878

Epoch: 5| Step: 5
Training loss: 6.3950260742228595
Validation loss: 5.877072313747557

Epoch: 5| Step: 6
Training loss: 6.23431319968586
Validation loss: 5.875713223932272

Epoch: 5| Step: 7
Training loss: 5.937988261174297
Validation loss: 5.874311623251551

Epoch: 5| Step: 8
Training loss: 5.914380164540735
Validation loss: 5.8729541408844845

Epoch: 5| Step: 9
Training loss: 6.458320798143917
Validation loss: 5.871382898455359

Epoch: 5| Step: 10
Training loss: 6.215050598576901
Validation loss: 5.86996216908557

Epoch: 5| Step: 11
Training loss: 5.856873815119331
Validation loss: 5.868370285723174

Epoch: 2| Step: 0
Training loss: 5.76479525914692
Validation loss: 5.866683958671112

Epoch: 5| Step: 1
Training loss: 5.8075688271748485
Validation loss: 5.864947233773021

Epoch: 5| Step: 2
Training loss: 5.783934593643407
Validation loss: 5.863296857792333

Epoch: 5| Step: 3
Training loss: 6.391286055643915
Validation loss: 5.861315847449879

Epoch: 5| Step: 4
Training loss: 6.208526642454582
Validation loss: 5.859365790465853

Epoch: 5| Step: 5
Training loss: 6.374324388794017
Validation loss: 5.857347318966189

Epoch: 5| Step: 6
Training loss: 5.868464954347956
Validation loss: 5.8551723820029915

Epoch: 5| Step: 7
Training loss: 5.765757985636041
Validation loss: 5.8528207157062475

Epoch: 5| Step: 8
Training loss: 5.752345063047351
Validation loss: 5.85048280201713

Epoch: 5| Step: 9
Training loss: 5.752274436590074
Validation loss: 5.847957911638695

Epoch: 5| Step: 10
Training loss: 6.184570543803288
Validation loss: 5.845263164536058

Epoch: 5| Step: 11
Training loss: 5.958029821530608
Validation loss: 5.842568024693768

Epoch: 3| Step: 0
Training loss: 6.558691172873064
Validation loss: 5.83955051532206

Epoch: 5| Step: 1
Training loss: 6.052913046431136
Validation loss: 5.836490637232376

Epoch: 5| Step: 2
Training loss: 5.164915813635154
Validation loss: 5.833304441471303

Epoch: 5| Step: 3
Training loss: 5.449751633050673
Validation loss: 5.829939422576242

Epoch: 5| Step: 4
Training loss: 6.648411106366529
Validation loss: 5.826387952769885

Epoch: 5| Step: 5
Training loss: 6.339848864465743
Validation loss: 5.822627647838415

Epoch: 5| Step: 6
Training loss: 5.860928830430471
Validation loss: 5.8186605204180575

Epoch: 5| Step: 7
Training loss: 6.012093436280932
Validation loss: 5.814542247536397

Epoch: 5| Step: 8
Training loss: 5.974209670145611
Validation loss: 5.810089794314213

Epoch: 5| Step: 9
Training loss: 5.079258061693203
Validation loss: 5.805537966296469

Epoch: 5| Step: 10
Training loss: 5.615537355956469
Validation loss: 5.800933664633642

Epoch: 5| Step: 11
Training loss: 7.408723184850162
Validation loss: 5.795707201139419

Epoch: 4| Step: 0
Training loss: 5.324349147797903
Validation loss: 5.790641380598434

Epoch: 5| Step: 1
Training loss: 5.904333378877397
Validation loss: 5.785120752514604

Epoch: 5| Step: 2
Training loss: 5.81713223201821
Validation loss: 5.779615978916695

Epoch: 5| Step: 3
Training loss: 5.140835186681827
Validation loss: 5.773635186375689

Epoch: 5| Step: 4
Training loss: 6.743704226305787
Validation loss: 5.767440737422729

Epoch: 5| Step: 5
Training loss: 5.73719290117161
Validation loss: 5.760907746043223

Epoch: 5| Step: 6
Training loss: 5.784465493556218
Validation loss: 5.754073552127064

Epoch: 5| Step: 7
Training loss: 6.1804010531465
Validation loss: 5.746985820277731

Epoch: 5| Step: 8
Training loss: 6.629642227669192
Validation loss: 5.739685572309591

Epoch: 5| Step: 9
Training loss: 5.2254710518989
Validation loss: 5.732401377410028

Epoch: 5| Step: 10
Training loss: 5.9913060461328245
Validation loss: 5.724739474958424

Epoch: 5| Step: 11
Training loss: 5.360867039599077
Validation loss: 5.716507199160568

Epoch: 5| Step: 0
Training loss: 7.011570495908303
Validation loss: 5.708557934298695

Epoch: 5| Step: 1
Training loss: 5.4001025931891125
Validation loss: 5.700105057411875

Epoch: 5| Step: 2
Training loss: 5.082089235413336
Validation loss: 5.691498905109281

Epoch: 5| Step: 3
Training loss: 6.264785367877051
Validation loss: 5.683177241459304

Epoch: 5| Step: 4
Training loss: 5.533908356045954
Validation loss: 5.674182930214007

Epoch: 5| Step: 5
Training loss: 5.731003937176251
Validation loss: 5.665231181626932

Epoch: 5| Step: 6
Training loss: 5.553518523707656
Validation loss: 5.656603751176414

Epoch: 5| Step: 7
Training loss: 5.31095055816742
Validation loss: 5.64773604459368

Epoch: 5| Step: 8
Training loss: 6.004486314081838
Validation loss: 5.639075435356876

Epoch: 5| Step: 9
Training loss: 5.753991773167876
Validation loss: 5.630229221791051

Epoch: 5| Step: 10
Training loss: 5.559670575214617
Validation loss: 5.621519742848299

Epoch: 5| Step: 11
Training loss: 6.494407889237256
Validation loss: 5.612831361386835

Epoch: 6| Step: 0
Training loss: 5.50464364737358
Validation loss: 5.604361295570228

Epoch: 5| Step: 1
Training loss: 5.8212283649169505
Validation loss: 5.595755418285685

Epoch: 5| Step: 2
Training loss: 5.556211538793169
Validation loss: 5.587508066613891

Epoch: 5| Step: 3
Training loss: 5.870683748366952
Validation loss: 5.579184103044191

Epoch: 5| Step: 4
Training loss: 6.0183520984735654
Validation loss: 5.570802293442289

Epoch: 5| Step: 5
Training loss: 5.132940328507202
Validation loss: 5.562651428561737

Epoch: 5| Step: 6
Training loss: 6.452167874124084
Validation loss: 5.554429246324149

Epoch: 5| Step: 7
Training loss: 5.173393095857648
Validation loss: 5.546227237327142

Epoch: 5| Step: 8
Training loss: 5.197995885374019
Validation loss: 5.538347041128121

Epoch: 5| Step: 9
Training loss: 5.769690261540157
Validation loss: 5.530113958445795

Epoch: 5| Step: 10
Training loss: 5.822835613453194
Validation loss: 5.522555405370632

Epoch: 5| Step: 11
Training loss: 5.803117624503088
Validation loss: 5.514601889034922

Epoch: 7| Step: 0
Training loss: 5.102027953618243
Validation loss: 5.506737858971721

Epoch: 5| Step: 1
Training loss: 5.758181514845651
Validation loss: 5.499169445905211

Epoch: 5| Step: 2
Training loss: 4.667698655235145
Validation loss: 5.491406648854471

Epoch: 5| Step: 3
Training loss: 6.288876283151478
Validation loss: 5.483989821599172

Epoch: 5| Step: 4
Training loss: 5.505000355622629
Validation loss: 5.476815167528703

Epoch: 5| Step: 5
Training loss: 6.274665075839892
Validation loss: 5.4695989912517105

Epoch: 5| Step: 6
Training loss: 6.105171025510458
Validation loss: 5.462320337316193

Epoch: 5| Step: 7
Training loss: 5.40843941340085
Validation loss: 5.455090610277252

Epoch: 5| Step: 8
Training loss: 5.616493405047789
Validation loss: 5.448471860391647

Epoch: 5| Step: 9
Training loss: 5.48234916288173
Validation loss: 5.442029856566159

Epoch: 5| Step: 10
Training loss: 4.485617223007096
Validation loss: 5.435670310969781

Epoch: 5| Step: 11
Training loss: 7.606461548821579
Validation loss: 5.429205666804768

Epoch: 8| Step: 0
Training loss: 5.730996615300854
Validation loss: 5.423400188007406

Epoch: 5| Step: 1
Training loss: 5.667582419208002
Validation loss: 5.417078232412775

Epoch: 5| Step: 2
Training loss: 6.00327370661485
Validation loss: 5.411296605865343

Epoch: 5| Step: 3
Training loss: 5.217837316688566
Validation loss: 5.405243517141858

Epoch: 5| Step: 4
Training loss: 5.747546128481566
Validation loss: 5.399515312130017

Epoch: 5| Step: 5
Training loss: 5.392426739771142
Validation loss: 5.393546244462543

Epoch: 5| Step: 6
Training loss: 5.765414267723248
Validation loss: 5.388050043006315

Epoch: 5| Step: 7
Training loss: 5.828319065657226
Validation loss: 5.382427015375245

Epoch: 5| Step: 8
Training loss: 5.223206587379381
Validation loss: 5.376687051250005

Epoch: 5| Step: 9
Training loss: 5.506235922406805
Validation loss: 5.371534435342341

Epoch: 5| Step: 10
Training loss: 4.5133050681224125
Validation loss: 5.365992487544449

Epoch: 5| Step: 11
Training loss: 5.1373332421185385
Validation loss: 5.36082097928196

Epoch: 9| Step: 0
Training loss: 6.319479228425856
Validation loss: 5.355713448938384

Epoch: 5| Step: 1
Training loss: 6.297947794586729
Validation loss: 5.351131486822664

Epoch: 5| Step: 2
Training loss: 5.3506239910412186
Validation loss: 5.345883157467689

Epoch: 5| Step: 3
Training loss: 5.6498862871187985
Validation loss: 5.340939040871717

Epoch: 5| Step: 4
Training loss: 4.119994623495501
Validation loss: 5.336215308475683

Epoch: 5| Step: 5
Training loss: 5.1391358233168
Validation loss: 5.331650098282228

Epoch: 5| Step: 6
Training loss: 5.295955972079368
Validation loss: 5.327138233262454

Epoch: 5| Step: 7
Training loss: 5.285501788813045
Validation loss: 5.322667717633179

Epoch: 5| Step: 8
Training loss: 4.949005628180642
Validation loss: 5.318058875396074

Epoch: 5| Step: 9
Training loss: 5.276537897912831
Validation loss: 5.313490786443124

Epoch: 5| Step: 10
Training loss: 5.714950216348503
Validation loss: 5.309046277128392

Epoch: 5| Step: 11
Training loss: 6.630244931951308
Validation loss: 5.304509080780606

Epoch: 10| Step: 0
Training loss: 4.443412388076611
Validation loss: 5.299840399000495

Epoch: 5| Step: 1
Training loss: 5.6855257401487975
Validation loss: 5.295471875780919

Epoch: 5| Step: 2
Training loss: 5.787831452273111
Validation loss: 5.290976909929053

Epoch: 5| Step: 3
Training loss: 5.454381759672587
Validation loss: 5.286315798286444

Epoch: 5| Step: 4
Training loss: 4.270797555665055
Validation loss: 5.281861459822056

Epoch: 5| Step: 5
Training loss: 5.428338938589055
Validation loss: 5.277341965478105

Epoch: 5| Step: 6
Training loss: 6.005018043205095
Validation loss: 5.273081675640079

Epoch: 5| Step: 7
Training loss: 5.858919253109153
Validation loss: 5.268336412058221

Epoch: 5| Step: 8
Training loss: 4.56137907289351
Validation loss: 5.263884100943977

Epoch: 5| Step: 9
Training loss: 4.827750083415661
Validation loss: 5.259098305755331

Epoch: 5| Step: 10
Training loss: 6.383766280482716
Validation loss: 5.25511509863343

Epoch: 5| Step: 11
Training loss: 6.45578753429729
Validation loss: 5.250052398844007

Epoch: 11| Step: 0
Training loss: 5.0818702384899215
Validation loss: 5.245236089742854

Epoch: 5| Step: 1
Training loss: 5.285990917669974
Validation loss: 5.240710312344736

Epoch: 5| Step: 2
Training loss: 4.97618362685293
Validation loss: 5.23606600040709

Epoch: 5| Step: 3
Training loss: 5.655037597207474
Validation loss: 5.231268200829373

Epoch: 5| Step: 4
Training loss: 5.5043945095928875
Validation loss: 5.22653598902222

Epoch: 5| Step: 5
Training loss: 5.135272454125544
Validation loss: 5.221542387984165

Epoch: 5| Step: 6
Training loss: 5.566412246433174
Validation loss: 5.217082071167324

Epoch: 5| Step: 7
Training loss: 5.490704223547595
Validation loss: 5.21200991246922

Epoch: 5| Step: 8
Training loss: 5.1194582494580745
Validation loss: 5.206921800711313

Epoch: 5| Step: 9
Training loss: 5.3897626546434
Validation loss: 5.202197277617278

Epoch: 5| Step: 10
Training loss: 5.680814733502313
Validation loss: 5.197135387510556

Epoch: 5| Step: 11
Training loss: 4.529909764416382
Validation loss: 5.191901120953274

Epoch: 12| Step: 0
Training loss: 5.111005330488441
Validation loss: 5.186861833898199

Epoch: 5| Step: 1
Training loss: 4.2146887551871
Validation loss: 5.181586184636841

Epoch: 5| Step: 2
Training loss: 6.197205609049925
Validation loss: 5.176570462689856

Epoch: 5| Step: 3
Training loss: 4.796341757693232
Validation loss: 5.171667826672169

Epoch: 5| Step: 4
Training loss: 5.379639153840814
Validation loss: 5.166488039353903

Epoch: 5| Step: 5
Training loss: 5.157489789397006
Validation loss: 5.161617360005291

Epoch: 5| Step: 6
Training loss: 5.558861732054821
Validation loss: 5.156519657366453

Epoch: 5| Step: 7
Training loss: 5.659974615896072
Validation loss: 5.151142079525654

Epoch: 5| Step: 8
Training loss: 5.246500938218401
Validation loss: 5.1460363551359345

Epoch: 5| Step: 9
Training loss: 5.522839374881564
Validation loss: 5.141077773417523

Epoch: 5| Step: 10
Training loss: 5.092687390662104
Validation loss: 5.136118164536757

Epoch: 5| Step: 11
Training loss: 5.0265217237208955
Validation loss: 5.130516711679322

Epoch: 13| Step: 0
Training loss: 5.154764782250219
Validation loss: 5.12527551918356

Epoch: 5| Step: 1
Training loss: 5.369045596705884
Validation loss: 5.120657360301041

Epoch: 5| Step: 2
Training loss: 5.976223565757071
Validation loss: 5.116437248384216

Epoch: 5| Step: 3
Training loss: 5.207277948898538
Validation loss: 5.111017458974522

Epoch: 5| Step: 4
Training loss: 5.152033891246518
Validation loss: 5.105714153374215

Epoch: 5| Step: 5
Training loss: 4.728160846420522
Validation loss: 5.100286459513413

Epoch: 5| Step: 6
Training loss: 5.385395731291916
Validation loss: 5.095119643224482

Epoch: 5| Step: 7
Training loss: 4.785566986517511
Validation loss: 5.091074859306545

Epoch: 5| Step: 8
Training loss: 5.3138546282460375
Validation loss: 5.085580066127514

Epoch: 5| Step: 9
Training loss: 5.452782562784065
Validation loss: 5.081086665457404

Epoch: 5| Step: 10
Training loss: 5.11621382673735
Validation loss: 5.076091918863569

Epoch: 5| Step: 11
Training loss: 3.645299963310258
Validation loss: 5.071451961340588

Epoch: 14| Step: 0
Training loss: 5.6691844433037515
Validation loss: 5.067138697361454

Epoch: 5| Step: 1
Training loss: 5.481292466941925
Validation loss: 5.0624250869545735

Epoch: 5| Step: 2
Training loss: 5.481258017382962
Validation loss: 5.05798376227684

Epoch: 5| Step: 3
Training loss: 5.046089229295274
Validation loss: 5.052652294198557

Epoch: 5| Step: 4
Training loss: 6.082451464690244
Validation loss: 5.047824734826659

Epoch: 5| Step: 5
Training loss: 4.897465124156984
Validation loss: 5.042361600392171

Epoch: 5| Step: 6
Training loss: 4.806849345326116
Validation loss: 5.037658030426801

Epoch: 5| Step: 7
Training loss: 4.594515782060874
Validation loss: 5.03262788847911

Epoch: 5| Step: 8
Training loss: 4.822362133248545
Validation loss: 5.027435207053758

Epoch: 5| Step: 9
Training loss: 4.840693339979176
Validation loss: 5.0226575088677405

Epoch: 5| Step: 10
Training loss: 5.022103851933906
Validation loss: 5.01832880047598

Epoch: 5| Step: 11
Training loss: 4.679956495294754
Validation loss: 5.013296218508104

Epoch: 15| Step: 0
Training loss: 4.51815904311878
Validation loss: 5.008140898364735

Epoch: 5| Step: 1
Training loss: 4.386570480436167
Validation loss: 5.003354965602019

Epoch: 5| Step: 2
Training loss: 5.088615966171143
Validation loss: 4.998657650365979

Epoch: 5| Step: 3
Training loss: 4.966289174798887
Validation loss: 4.994554494796437

Epoch: 5| Step: 4
Training loss: 5.102167768339188
Validation loss: 4.989456806954517

Epoch: 5| Step: 5
Training loss: 5.2609962471428515
Validation loss: 4.9852259277295135

Epoch: 5| Step: 6
Training loss: 5.387981441077857
Validation loss: 4.980398355622311

Epoch: 5| Step: 7
Training loss: 5.142329064005399
Validation loss: 4.975684638973896

Epoch: 5| Step: 8
Training loss: 5.680286570022513
Validation loss: 4.970496480527309

Epoch: 5| Step: 9
Training loss: 5.689628454323023
Validation loss: 4.964847239551373

Epoch: 5| Step: 10
Training loss: 4.923210035642772
Validation loss: 4.959825998979192

Epoch: 5| Step: 11
Training loss: 4.465653633896127
Validation loss: 4.954527871856585

Epoch: 16| Step: 0
Training loss: 4.939673995407815
Validation loss: 4.949149211825573

Epoch: 5| Step: 1
Training loss: 4.505823394010002
Validation loss: 4.943928199896887

Epoch: 5| Step: 2
Training loss: 5.3008291063840085
Validation loss: 4.93890406768711

Epoch: 5| Step: 3
Training loss: 5.423182964588898
Validation loss: 4.93337368669416

Epoch: 5| Step: 4
Training loss: 4.99324303871754
Validation loss: 4.928704181341756

Epoch: 5| Step: 5
Training loss: 5.631766424515734
Validation loss: 4.924292448052051

Epoch: 5| Step: 6
Training loss: 4.970456580022765
Validation loss: 4.917774248102271

Epoch: 5| Step: 7
Training loss: 4.890804397168956
Validation loss: 4.913180305930899

Epoch: 5| Step: 8
Training loss: 5.034695221693345
Validation loss: 4.908373840739137

Epoch: 5| Step: 9
Training loss: 5.241179367888666
Validation loss: 4.902827298049661

Epoch: 5| Step: 10
Training loss: 4.371589203028366
Validation loss: 4.899362528459413

Epoch: 5| Step: 11
Training loss: 5.514127446973351
Validation loss: 4.893494874061755

Epoch: 17| Step: 0
Training loss: 4.621982311682072
Validation loss: 4.888391563679125

Epoch: 5| Step: 1
Training loss: 5.436620531539338
Validation loss: 4.883659814178122

Epoch: 5| Step: 2
Training loss: 4.97790719972875
Validation loss: 4.878419948070049

Epoch: 5| Step: 3
Training loss: 5.389859794817309
Validation loss: 4.873583033440271

Epoch: 5| Step: 4
Training loss: 4.891153422805292
Validation loss: 4.869092973439468

Epoch: 5| Step: 5
Training loss: 3.978803980943823
Validation loss: 4.864662360366966

Epoch: 5| Step: 6
Training loss: 5.012457777497124
Validation loss: 4.85921323451795

Epoch: 5| Step: 7
Training loss: 5.0619532913952865
Validation loss: 4.853542200395679

Epoch: 5| Step: 8
Training loss: 3.9640527998009025
Validation loss: 4.849299068204706

Epoch: 5| Step: 9
Training loss: 5.411229304685824
Validation loss: 4.843971583722738

Epoch: 5| Step: 10
Training loss: 5.505449369766425
Validation loss: 4.839804603268505

Epoch: 5| Step: 11
Training loss: 6.407148493584931
Validation loss: 4.8347161742873945

Epoch: 18| Step: 0
Training loss: 5.02601246668844
Validation loss: 4.830028952741493

Epoch: 5| Step: 1
Training loss: 4.12055243964167
Validation loss: 4.825465855814516

Epoch: 5| Step: 2
Training loss: 4.291100523312391
Validation loss: 4.82045756760095

Epoch: 5| Step: 3
Training loss: 4.8327229651547965
Validation loss: 4.815129193546443

Epoch: 5| Step: 4
Training loss: 5.309038717611931
Validation loss: 4.810485979882963

Epoch: 5| Step: 5
Training loss: 4.645948445671655
Validation loss: 4.8054235706077435

Epoch: 5| Step: 6
Training loss: 5.188949382482906
Validation loss: 4.8009326684350535

Epoch: 5| Step: 7
Training loss: 4.327583141354642
Validation loss: 4.795463569741645

Epoch: 5| Step: 8
Training loss: 5.946581190090807
Validation loss: 4.790468350823147

Epoch: 5| Step: 9
Training loss: 5.63300719963005
Validation loss: 4.786267928140291

Epoch: 5| Step: 10
Training loss: 4.363392062645574
Validation loss: 4.78120440209946

Epoch: 5| Step: 11
Training loss: 5.79186630819732
Validation loss: 4.77660069024539

Epoch: 19| Step: 0
Training loss: 5.131724714095619
Validation loss: 4.773850543293599

Epoch: 5| Step: 1
Training loss: 4.5141206235170666
Validation loss: 4.766320274789377

Epoch: 5| Step: 2
Training loss: 5.645739152223664
Validation loss: 4.761517857149125

Epoch: 5| Step: 3
Training loss: 5.006503643796893
Validation loss: 4.7577142313813905

Epoch: 5| Step: 4
Training loss: 3.9396288732797773
Validation loss: 4.751550463220382

Epoch: 5| Step: 5
Training loss: 5.498454830557549
Validation loss: 4.7463778773111525

Epoch: 5| Step: 6
Training loss: 5.048652265131148
Validation loss: 4.742040473715924

Epoch: 5| Step: 7
Training loss: 4.806088623194947
Validation loss: 4.736368210875256

Epoch: 5| Step: 8
Training loss: 4.474098685938172
Validation loss: 4.732368001868692

Epoch: 5| Step: 9
Training loss: 4.821269974295057
Validation loss: 4.726814477682623

Epoch: 5| Step: 10
Training loss: 4.40428409955187
Validation loss: 4.72152156150845

Epoch: 5| Step: 11
Training loss: 5.154725005310283
Validation loss: 4.716089850405371

Epoch: 20| Step: 0
Training loss: 4.440209434656027
Validation loss: 4.712373640084801

Epoch: 5| Step: 1
Training loss: 5.3493004243459
Validation loss: 4.708545547811644

Epoch: 5| Step: 2
Training loss: 4.717972647192669
Validation loss: 4.7016754620260315

Epoch: 5| Step: 3
Training loss: 4.848232631553296
Validation loss: 4.695826311396731

Epoch: 5| Step: 4
Training loss: 4.575987437264331
Validation loss: 4.694828636893397

Epoch: 5| Step: 5
Training loss: 4.547271606347002
Validation loss: 4.6887634693841465

Epoch: 5| Step: 6
Training loss: 4.718697654989573
Validation loss: 4.681201174166898

Epoch: 5| Step: 7
Training loss: 5.233752951027836
Validation loss: 4.677259083640986

Epoch: 5| Step: 8
Training loss: 4.515164572925938
Validation loss: 4.671601056729119

Epoch: 5| Step: 9
Training loss: 5.123669335278711
Validation loss: 4.667489501527225

Epoch: 5| Step: 10
Training loss: 4.476732287424232
Validation loss: 4.662208491085351

Epoch: 5| Step: 11
Training loss: 6.136060420806902
Validation loss: 4.6560797265514315

Epoch: 21| Step: 0
Training loss: 3.868727745275626
Validation loss: 4.651700419229817

Epoch: 5| Step: 1
Training loss: 4.0749143626569975
Validation loss: 4.650092185723464

Epoch: 5| Step: 2
Training loss: 4.540953880628617
Validation loss: 4.641637364174598

Epoch: 5| Step: 3
Training loss: 4.212154177272047
Validation loss: 4.637648290300854

Epoch: 5| Step: 4
Training loss: 4.345031768717806
Validation loss: 4.6347013357327755

Epoch: 5| Step: 5
Training loss: 4.090301225757297
Validation loss: 4.629860471939636

Epoch: 5| Step: 6
Training loss: 5.743399106868793
Validation loss: 4.624718459899298

Epoch: 5| Step: 7
Training loss: 5.447395178183323
Validation loss: 4.617727128717831

Epoch: 5| Step: 8
Training loss: 5.691592913140926
Validation loss: 4.610929039663311

Epoch: 5| Step: 9
Training loss: 5.205841363483699
Validation loss: 4.608161279399373

Epoch: 5| Step: 10
Training loss: 4.7853238570774135
Validation loss: 4.601723806838635

Epoch: 5| Step: 11
Training loss: 3.497045087044248
Validation loss: 4.595172722316402

Epoch: 22| Step: 0
Training loss: 4.340243234454553
Validation loss: 4.590707221007912

Epoch: 5| Step: 1
Training loss: 4.507860100823741
Validation loss: 4.587191062177598

Epoch: 5| Step: 2
Training loss: 4.625001237198948
Validation loss: 4.580515882750669

Epoch: 5| Step: 3
Training loss: 4.172630441682614
Validation loss: 4.575044222480765

Epoch: 5| Step: 4
Training loss: 5.4087768999757175
Validation loss: 4.568824173603087

Epoch: 5| Step: 5
Training loss: 4.783023679769967
Validation loss: 4.563449255727382

Epoch: 5| Step: 6
Training loss: 4.60286902643733
Validation loss: 4.558210211328341

Epoch: 5| Step: 7
Training loss: 4.859250573040229
Validation loss: 4.5519330358535255

Epoch: 5| Step: 8
Training loss: 4.498251681317594
Validation loss: 4.5460511255350164

Epoch: 5| Step: 9
Training loss: 5.223810540565259
Validation loss: 4.540517585815835

Epoch: 5| Step: 10
Training loss: 4.218174421818147
Validation loss: 4.535619369811027

Epoch: 5| Step: 11
Training loss: 5.585960377466264
Validation loss: 4.530183206141925

Epoch: 23| Step: 0
Training loss: 4.521687487001124
Validation loss: 4.523896070569093

Epoch: 5| Step: 1
Training loss: 5.549407466841142
Validation loss: 4.520519863927619

Epoch: 5| Step: 2
Training loss: 4.80830696050242
Validation loss: 4.512141823576946

Epoch: 5| Step: 3
Training loss: 4.086352004548571
Validation loss: 4.507205210415563

Epoch: 5| Step: 4
Training loss: 4.201303534082969
Validation loss: 4.502746812168909

Epoch: 5| Step: 5
Training loss: 3.805433384279312
Validation loss: 4.496831038602346

Epoch: 5| Step: 6
Training loss: 4.6592154052746935
Validation loss: 4.492439952888467

Epoch: 5| Step: 7
Training loss: 4.598141601665269
Validation loss: 4.488455392476556

Epoch: 5| Step: 8
Training loss: 4.499619997722181
Validation loss: 4.483383724870127

Epoch: 5| Step: 9
Training loss: 4.259133566201137
Validation loss: 4.475831691701632

Epoch: 5| Step: 10
Training loss: 5.542878938556229
Validation loss: 4.470055280581127

Epoch: 5| Step: 11
Training loss: 4.734287978779451
Validation loss: 4.464837929495741

Epoch: 24| Step: 0
Training loss: 4.097841736820056
Validation loss: 4.458332929284383

Epoch: 5| Step: 1
Training loss: 4.275848991461031
Validation loss: 4.452207343600219

Epoch: 5| Step: 2
Training loss: 4.346674092721349
Validation loss: 4.446397529394478

Epoch: 5| Step: 3
Training loss: 4.04441022008405
Validation loss: 4.441320829484296

Epoch: 5| Step: 4
Training loss: 4.438697975603649
Validation loss: 4.435429519854488

Epoch: 5| Step: 5
Training loss: 5.448359377240497
Validation loss: 4.431437246027873

Epoch: 5| Step: 6
Training loss: 4.79956337214464
Validation loss: 4.424809509961715

Epoch: 5| Step: 7
Training loss: 3.831787599367303
Validation loss: 4.420042289456782

Epoch: 5| Step: 8
Training loss: 4.362922783506917
Validation loss: 4.413776363674708

Epoch: 5| Step: 9
Training loss: 5.043761057410238
Validation loss: 4.408459093839556

Epoch: 5| Step: 10
Training loss: 5.258161649405086
Validation loss: 4.401299728261412

Epoch: 5| Step: 11
Training loss: 3.8769425476083668
Validation loss: 4.3960165404458955

Epoch: 25| Step: 0
Training loss: 5.182911325592978
Validation loss: 4.390796010950851

Epoch: 5| Step: 1
Training loss: 4.616127989887039
Validation loss: 4.384542376549208

Epoch: 5| Step: 2
Training loss: 3.958418969014388
Validation loss: 4.380245247895872

Epoch: 5| Step: 3
Training loss: 4.0891714335920994
Validation loss: 4.375769906193044

Epoch: 5| Step: 4
Training loss: 4.743963923801187
Validation loss: 4.371564142656491

Epoch: 5| Step: 5
Training loss: 4.790920674953436
Validation loss: 4.363417830189417

Epoch: 5| Step: 6
Training loss: 5.218038361963606
Validation loss: 4.357243617327352

Epoch: 5| Step: 7
Training loss: 4.292432451288774
Validation loss: 4.352363033385484

Epoch: 5| Step: 8
Training loss: 4.0227244513785365
Validation loss: 4.347473067554294

Epoch: 5| Step: 9
Training loss: 4.288692937886614
Validation loss: 4.341452322493416

Epoch: 5| Step: 10
Training loss: 3.677080725361851
Validation loss: 4.336704706357001

Epoch: 5| Step: 11
Training loss: 5.585303893534342
Validation loss: 4.33181198477897

Epoch: 26| Step: 0
Training loss: 4.885921471169643
Validation loss: 4.326151718196023

Epoch: 5| Step: 1
Training loss: 5.234317608419044
Validation loss: 4.319546738006502

Epoch: 5| Step: 2
Training loss: 4.599953750709565
Validation loss: 4.314092738197442

Epoch: 5| Step: 3
Training loss: 3.7570527194895638
Validation loss: 4.307555317065051

Epoch: 5| Step: 4
Training loss: 4.912150534121796
Validation loss: 4.302476170717873

Epoch: 5| Step: 5
Training loss: 3.719483118961721
Validation loss: 4.299343126233101

Epoch: 5| Step: 6
Training loss: 4.36772160684631
Validation loss: 4.293340156092662

Epoch: 5| Step: 7
Training loss: 4.2936760108936305
Validation loss: 4.286956130918937

Epoch: 5| Step: 8
Training loss: 4.853278847028738
Validation loss: 4.2806867428518585

Epoch: 5| Step: 9
Training loss: 3.6887078327598495
Validation loss: 4.2751294586776165

Epoch: 5| Step: 10
Training loss: 4.003118015018179
Validation loss: 4.270234659925263

Epoch: 5| Step: 11
Training loss: 4.718106459635383
Validation loss: 4.264140903772046

Epoch: 27| Step: 0
Training loss: 4.059143087973443
Validation loss: 4.258672892114388

Epoch: 5| Step: 1
Training loss: 5.04755012082991
Validation loss: 4.254964616847296

Epoch: 5| Step: 2
Training loss: 4.497295414595596
Validation loss: 4.249545386253091

Epoch: 5| Step: 3
Training loss: 4.358718658588389
Validation loss: 4.243055326285237

Epoch: 5| Step: 4
Training loss: 3.9825899800530244
Validation loss: 4.2375625399435295

Epoch: 5| Step: 5
Training loss: 5.017751842920184
Validation loss: 4.232084515805442

Epoch: 5| Step: 6
Training loss: 3.9286548630412863
Validation loss: 4.226237220492857

Epoch: 5| Step: 7
Training loss: 3.685088063899734
Validation loss: 4.222425042197206

Epoch: 5| Step: 8
Training loss: 4.805414309229706
Validation loss: 4.215777317629345

Epoch: 5| Step: 9
Training loss: 4.293037393175617
Validation loss: 4.210621559496876

Epoch: 5| Step: 10
Training loss: 4.1064224369532285
Validation loss: 4.205979230156789

Epoch: 5| Step: 11
Training loss: 4.253047299428583
Validation loss: 4.200637416873276

Epoch: 28| Step: 0
Training loss: 4.3996328894315235
Validation loss: 4.19486332672625

Epoch: 5| Step: 1
Training loss: 3.4011707758482776
Validation loss: 4.190139199776849

Epoch: 5| Step: 2
Training loss: 3.7944782997161286
Validation loss: 4.185159000397961

Epoch: 5| Step: 3
Training loss: 4.132626736653921
Validation loss: 4.17938020711462

Epoch: 5| Step: 4
Training loss: 5.008569621490782
Validation loss: 4.173266565689643

Epoch: 5| Step: 5
Training loss: 4.171354225601016
Validation loss: 4.169225515786071

Epoch: 5| Step: 6
Training loss: 3.8874628782799823
Validation loss: 4.163345041309465

Epoch: 5| Step: 7
Training loss: 4.077362340010193
Validation loss: 4.158366493801287

Epoch: 5| Step: 8
Training loss: 4.964138554178661
Validation loss: 4.15323155010279

Epoch: 5| Step: 9
Training loss: 4.58316543733972
Validation loss: 4.148164935356344

Epoch: 5| Step: 10
Training loss: 4.269996499053449
Validation loss: 4.143094934782266

Epoch: 5| Step: 11
Training loss: 5.701782737486412
Validation loss: 4.136780173734509

Epoch: 29| Step: 0
Training loss: 3.1025942376369438
Validation loss: 4.131967973864725

Epoch: 5| Step: 1
Training loss: 5.126894344901141
Validation loss: 4.126610085269455

Epoch: 5| Step: 2
Training loss: 4.735236464077326
Validation loss: 4.1214104408688

Epoch: 5| Step: 3
Training loss: 4.871779527395488
Validation loss: 4.1146458327298925

Epoch: 5| Step: 4
Training loss: 3.707622517100289
Validation loss: 4.108390791776855

Epoch: 5| Step: 5
Training loss: 4.088516500926066
Validation loss: 4.103476532488584

Epoch: 5| Step: 6
Training loss: 5.053677064349041
Validation loss: 4.099831448943889

Epoch: 5| Step: 7
Training loss: 3.5364580486823725
Validation loss: 4.093198986680811

Epoch: 5| Step: 8
Training loss: 4.030999937359851
Validation loss: 4.086464171446358

Epoch: 5| Step: 9
Training loss: 4.485767746347321
Validation loss: 4.080796386255998

Epoch: 5| Step: 10
Training loss: 3.66826786856939
Validation loss: 4.075142735826866

Epoch: 5| Step: 11
Training loss: 1.6999207898928086
Validation loss: 4.070340659836724

Epoch: 30| Step: 0
Training loss: 4.01193554672239
Validation loss: 4.065242814659189

Epoch: 5| Step: 1
Training loss: 4.410301564257859
Validation loss: 4.05958475516103

Epoch: 5| Step: 2
Training loss: 4.2677700811377015
Validation loss: 4.054459846588478

Epoch: 5| Step: 3
Training loss: 4.219015833638479
Validation loss: 4.048982074152058

Epoch: 5| Step: 4
Training loss: 3.4691260881423274
Validation loss: 4.043090700530935

Epoch: 5| Step: 5
Training loss: 4.912603844086216
Validation loss: 4.036538241015905

Epoch: 5| Step: 6
Training loss: 4.0431048531589795
Validation loss: 4.030757193790994

Epoch: 5| Step: 7
Training loss: 4.350034709221933
Validation loss: 4.0259626445771195

Epoch: 5| Step: 8
Training loss: 4.112780650108065
Validation loss: 4.020016071625905

Epoch: 5| Step: 9
Training loss: 3.816364268576671
Validation loss: 4.015550555814417

Epoch: 5| Step: 10
Training loss: 4.255324450448975
Validation loss: 4.009007975230599

Epoch: 5| Step: 11
Training loss: 3.270421935691352
Validation loss: 4.00461759373533

Epoch: 31| Step: 0
Training loss: 4.2231772469267685
Validation loss: 3.9989017975767163

Epoch: 5| Step: 1
Training loss: 3.187250912975504
Validation loss: 3.992725990442806

Epoch: 5| Step: 2
Training loss: 4.153550727098216
Validation loss: 3.98789911933418

Epoch: 5| Step: 3
Training loss: 4.076101685428268
Validation loss: 3.982457680733789

Epoch: 5| Step: 4
Training loss: 4.38399104899864
Validation loss: 3.977645783928647

Epoch: 5| Step: 5
Training loss: 4.496139141685506
Validation loss: 3.971296784867103

Epoch: 5| Step: 6
Training loss: 4.0134221428542665
Validation loss: 3.966442954476085

Epoch: 5| Step: 7
Training loss: 3.4439709878069467
Validation loss: 3.9604467003874326

Epoch: 5| Step: 8
Training loss: 4.31523266886621
Validation loss: 3.955737762073506

Epoch: 5| Step: 9
Training loss: 4.380210171887001
Validation loss: 3.9501278136293747

Epoch: 5| Step: 10
Training loss: 4.193347548888774
Validation loss: 3.944168604838136

Epoch: 5| Step: 11
Training loss: 4.4520849251405865
Validation loss: 3.9388716543899953

Epoch: 32| Step: 0
Training loss: 4.488952639623329
Validation loss: 3.9352141865220527

Epoch: 5| Step: 1
Training loss: 4.302999674427145
Validation loss: 3.929163145115644

Epoch: 5| Step: 2
Training loss: 3.6165367513313713
Validation loss: 3.9224693688906034

Epoch: 5| Step: 3
Training loss: 4.432895474334687
Validation loss: 3.9171857472981224

Epoch: 5| Step: 4
Training loss: 4.039779746972938
Validation loss: 3.911961669977552

Epoch: 5| Step: 5
Training loss: 3.6640621095832016
Validation loss: 3.906060094667658

Epoch: 5| Step: 6
Training loss: 4.004610742137733
Validation loss: 3.900133353993775

Epoch: 5| Step: 7
Training loss: 4.083675889159202
Validation loss: 3.896520623697371

Epoch: 5| Step: 8
Training loss: 3.711527117015884
Validation loss: 3.889590155103954

Epoch: 5| Step: 9
Training loss: 4.048355126435467
Validation loss: 3.8841895585257507

Epoch: 5| Step: 10
Training loss: 3.977965461546497
Validation loss: 3.877920721526113

Epoch: 5| Step: 11
Training loss: 3.8183428907892263
Validation loss: 3.8725221104952148

Epoch: 33| Step: 0
Training loss: 3.784402337199982
Validation loss: 3.8663050148773697

Epoch: 5| Step: 1
Training loss: 3.938715066079944
Validation loss: 3.8623995750400413

Epoch: 5| Step: 2
Training loss: 4.1765398669245055
Validation loss: 3.856939723789939

Epoch: 5| Step: 3
Training loss: 3.4259332429580525
Validation loss: 3.8515584196387618

Epoch: 5| Step: 4
Training loss: 3.229808292427735
Validation loss: 3.8477381250542204

Epoch: 5| Step: 5
Training loss: 3.726370304677597
Validation loss: 3.8411566144716507

Epoch: 5| Step: 6
Training loss: 4.086630651202247
Validation loss: 3.835980857298499

Epoch: 5| Step: 7
Training loss: 4.514644107078012
Validation loss: 3.830383573909439

Epoch: 5| Step: 8
Training loss: 4.445887845154155
Validation loss: 3.825443698978813

Epoch: 5| Step: 9
Training loss: 3.799722490718201
Validation loss: 3.820801010050579

Epoch: 5| Step: 10
Training loss: 4.1904996689638265
Validation loss: 3.8156987201089385

Epoch: 5| Step: 11
Training loss: 4.853006292440067
Validation loss: 3.8101732783575506

Epoch: 34| Step: 0
Training loss: 3.886588825757169
Validation loss: 3.8037843304573613

Epoch: 5| Step: 1
Training loss: 3.615795947149244
Validation loss: 3.798680000718832

Epoch: 5| Step: 2
Training loss: 4.014673498804349
Validation loss: 3.7937645069245063

Epoch: 5| Step: 3
Training loss: 4.275662528114361
Validation loss: 3.7886616235886637

Epoch: 5| Step: 4
Training loss: 3.18367388103718
Validation loss: 3.782504412229746

Epoch: 5| Step: 5
Training loss: 3.8162896754441813
Validation loss: 3.7778231011894423

Epoch: 5| Step: 6
Training loss: 3.996587609046581
Validation loss: 3.77138016179937

Epoch: 5| Step: 7
Training loss: 3.935123513596586
Validation loss: 3.7668932075792543

Epoch: 5| Step: 8
Training loss: 4.302234317571629
Validation loss: 3.761300274635597

Epoch: 5| Step: 9
Training loss: 4.210141363239709
Validation loss: 3.756638828068382

Epoch: 5| Step: 10
Training loss: 3.9377811876439623
Validation loss: 3.7509449404034325

Epoch: 5| Step: 11
Training loss: 2.0992639159840376
Validation loss: 3.7458665319434803

Epoch: 35| Step: 0
Training loss: 3.9429445922425943
Validation loss: 3.7409298933204274

Epoch: 5| Step: 1
Training loss: 3.8298511583773993
Validation loss: 3.7379295106578634

Epoch: 5| Step: 2
Training loss: 3.0768448544609543
Validation loss: 3.731593470097625

Epoch: 5| Step: 3
Training loss: 3.8784870332218615
Validation loss: 3.727698472195322

Epoch: 5| Step: 4
Training loss: 2.9826393073163957
Validation loss: 3.7195672438168024

Epoch: 5| Step: 5
Training loss: 4.257250939530555
Validation loss: 3.7159734934154707

Epoch: 5| Step: 6
Training loss: 4.2918863085987615
Validation loss: 3.7110681022282543

Epoch: 5| Step: 7
Training loss: 3.5030647211392942
Validation loss: 3.70658454843221

Epoch: 5| Step: 8
Training loss: 4.021511646565495
Validation loss: 3.7019317195904504

Epoch: 5| Step: 9
Training loss: 4.769399480225738
Validation loss: 3.697008825627796

Epoch: 5| Step: 10
Training loss: 3.6481345334760915
Validation loss: 3.6917287049918337

Epoch: 5| Step: 11
Training loss: 2.627031539257181
Validation loss: 3.6871306994153223

Epoch: 36| Step: 0
Training loss: 4.158803284615881
Validation loss: 3.682052257404259

Epoch: 5| Step: 1
Training loss: 4.754442245872373
Validation loss: 3.6771409063541896

Epoch: 5| Step: 2
Training loss: 3.5333124400066938
Validation loss: 3.6720160815683958

Epoch: 5| Step: 3
Training loss: 3.8785151873221504
Validation loss: 3.6668025049421242

Epoch: 5| Step: 4
Training loss: 3.013393703238555
Validation loss: 3.6613321549373636

Epoch: 5| Step: 5
Training loss: 3.6803149034690343
Validation loss: 3.656908367254458

Epoch: 5| Step: 6
Training loss: 4.014329040634857
Validation loss: 3.6511874675434792

Epoch: 5| Step: 7
Training loss: 4.259021832272457
Validation loss: 3.6471489067695226

Epoch: 5| Step: 8
Training loss: 3.035196154318602
Validation loss: 3.641065715478936

Epoch: 5| Step: 9
Training loss: 3.7368094836621655
Validation loss: 3.636047153762008

Epoch: 5| Step: 10
Training loss: 3.2661836137240616
Validation loss: 3.6305297187538326

Epoch: 5| Step: 11
Training loss: 3.9836022918005107
Validation loss: 3.626966041948677

Epoch: 37| Step: 0
Training loss: 3.6003111280993774
Validation loss: 3.6221637646922047

Epoch: 5| Step: 1
Training loss: 3.298231957490279
Validation loss: 3.617403703658806

Epoch: 5| Step: 2
Training loss: 3.313399570603814
Validation loss: 3.6130613902792823

Epoch: 5| Step: 3
Training loss: 4.463523743043372
Validation loss: 3.608829809411186

Epoch: 5| Step: 4
Training loss: 3.79014260539604
Validation loss: 3.6049711187769216

Epoch: 5| Step: 5
Training loss: 4.132986486915411
Validation loss: 3.599034749759567

Epoch: 5| Step: 6
Training loss: 3.6155267779593494
Validation loss: 3.595048161326858

Epoch: 5| Step: 7
Training loss: 3.277347387373205
Validation loss: 3.5894240119072545

Epoch: 5| Step: 8
Training loss: 4.086403814660833
Validation loss: 3.584847555408598

Epoch: 5| Step: 9
Training loss: 3.525696970978157
Validation loss: 3.5802693750355195

Epoch: 5| Step: 10
Training loss: 3.898750246762839
Validation loss: 3.575490384158597

Epoch: 5| Step: 11
Training loss: 3.0497141594693384
Validation loss: 3.5706032899596862

Epoch: 38| Step: 0
Training loss: 3.73650041054369
Validation loss: 3.5667012911895526

Epoch: 5| Step: 1
Training loss: 3.6098006356684658
Validation loss: 3.5613423859224005

Epoch: 5| Step: 2
Training loss: 3.330914398522671
Validation loss: 3.557204052286926

Epoch: 5| Step: 3
Training loss: 3.5417451438436998
Validation loss: 3.5523610029828623

Epoch: 5| Step: 4
Training loss: 3.926509960352832
Validation loss: 3.548253367126024

Epoch: 5| Step: 5
Training loss: 3.539916889055575
Validation loss: 3.5446035475150954

Epoch: 5| Step: 6
Training loss: 4.0245565987634455
Validation loss: 3.5385514901629085

Epoch: 5| Step: 7
Training loss: 3.061010660306855
Validation loss: 3.53384244893923

Epoch: 5| Step: 8
Training loss: 3.0505167789094694
Validation loss: 3.528842268352439

Epoch: 5| Step: 9
Training loss: 4.2058187595268866
Validation loss: 3.5250725459125563

Epoch: 5| Step: 10
Training loss: 4.0765134469967
Validation loss: 3.5207866782232897

Epoch: 5| Step: 11
Training loss: 4.390742290192709
Validation loss: 3.515925438370609

Epoch: 39| Step: 0
Training loss: 3.231798850692959
Validation loss: 3.511273382373171

Epoch: 5| Step: 1
Training loss: 3.2017030118209466
Validation loss: 3.507003710763203

Epoch: 5| Step: 2
Training loss: 3.4801001904852438
Validation loss: 3.501915526733426

Epoch: 5| Step: 3
Training loss: 3.995328440240921
Validation loss: 3.4977123953265354

Epoch: 5| Step: 4
Training loss: 3.55315659642325
Validation loss: 3.493285516424978

Epoch: 5| Step: 5
Training loss: 3.942690138310821
Validation loss: 3.488670478341851

Epoch: 5| Step: 6
Training loss: 3.8996209620636355
Validation loss: 3.48354152296095

Epoch: 5| Step: 7
Training loss: 3.192481542666857
Validation loss: 3.478844551586151

Epoch: 5| Step: 8
Training loss: 3.566952516265937
Validation loss: 3.4745584776883227

Epoch: 5| Step: 9
Training loss: 4.032005771496593
Validation loss: 3.4701332392932955

Epoch: 5| Step: 10
Training loss: 3.560987720411554
Validation loss: 3.4637937105105983

Epoch: 5| Step: 11
Training loss: 3.9120457492173744
Validation loss: 3.4597468398297253

Epoch: 40| Step: 0
Training loss: 3.380128284480259
Validation loss: 3.454545524321864

Epoch: 5| Step: 1
Training loss: 3.334833395712692
Validation loss: 3.4498134804491403

Epoch: 5| Step: 2
Training loss: 3.655766642646026
Validation loss: 3.4456528764373555

Epoch: 5| Step: 3
Training loss: 3.6045706344332005
Validation loss: 3.4414642681264094

Epoch: 5| Step: 4
Training loss: 3.4197510698976203
Validation loss: 3.436265203470766

Epoch: 5| Step: 5
Training loss: 3.5238969253811114
Validation loss: 3.4304957672053735

Epoch: 5| Step: 6
Training loss: 3.7665706729190997
Validation loss: 3.425607895098816

Epoch: 5| Step: 7
Training loss: 3.5321066838414716
Validation loss: 3.4237496047329032

Epoch: 5| Step: 8
Training loss: 3.269824380620852
Validation loss: 3.415637167454925

Epoch: 5| Step: 9
Training loss: 3.98188710048156
Validation loss: 3.411850743135035

Epoch: 5| Step: 10
Training loss: 3.7410276522905623
Validation loss: 3.407918620508743

Epoch: 5| Step: 11
Training loss: 3.5203104627851407
Validation loss: 3.4036291171156923

Epoch: 41| Step: 0
Training loss: 3.5771700321829756
Validation loss: 3.399673736920301

Epoch: 5| Step: 1
Training loss: 2.7788258821643055
Validation loss: 3.3959512378062198

Epoch: 5| Step: 2
Training loss: 3.750542792137791
Validation loss: 3.3909127806200576

Epoch: 5| Step: 3
Training loss: 3.741561168268015
Validation loss: 3.38731380809609

Epoch: 5| Step: 4
Training loss: 3.9041211239910907
Validation loss: 3.382583874736047

Epoch: 5| Step: 5
Training loss: 3.1615753571136804
Validation loss: 3.377158428457765

Epoch: 5| Step: 6
Training loss: 3.7357856927052557
Validation loss: 3.3722019900822326

Epoch: 5| Step: 7
Training loss: 3.8329477254446362
Validation loss: 3.368313706501426

Epoch: 5| Step: 8
Training loss: 2.7666705035753725
Validation loss: 3.363612266139051

Epoch: 5| Step: 9
Training loss: 3.8554625660886326
Validation loss: 3.3588332633934934

Epoch: 5| Step: 10
Training loss: 3.3705859105640914
Validation loss: 3.353437472784156

Epoch: 5| Step: 11
Training loss: 3.1891206099632825
Validation loss: 3.3493934109449857

Epoch: 42| Step: 0
Training loss: 3.6467945393999996
Validation loss: 3.3448698539390653

Epoch: 5| Step: 1
Training loss: 3.2006096616771154
Validation loss: 3.3409417680527493

Epoch: 5| Step: 2
Training loss: 3.0273733617503384
Validation loss: 3.335820481141149

Epoch: 5| Step: 3
Training loss: 3.6700290666307467
Validation loss: 3.330859593553619

Epoch: 5| Step: 4
Training loss: 3.4668818761586477
Validation loss: 3.3278632143127616

Epoch: 5| Step: 5
Training loss: 3.7137661402816073
Validation loss: 3.324746113599414

Epoch: 5| Step: 6
Training loss: 2.680673401196165
Validation loss: 3.3189254197134157

Epoch: 5| Step: 7
Training loss: 3.788705710690557
Validation loss: 3.3139568400142316

Epoch: 5| Step: 8
Training loss: 4.016841244102419
Validation loss: 3.3095092407607023

Epoch: 5| Step: 9
Training loss: 3.5850956745229823
Validation loss: 3.3054971447137316

Epoch: 5| Step: 10
Training loss: 3.113064824219451
Validation loss: 3.301807486307038

Epoch: 5| Step: 11
Training loss: 3.1676464740032366
Validation loss: 3.298183320174236

Epoch: 43| Step: 0
Training loss: 3.655933855522694
Validation loss: 3.295452660826141

Epoch: 5| Step: 1
Training loss: 3.471665677714348
Validation loss: 3.2914310785481846

Epoch: 5| Step: 2
Training loss: 3.6981510285091233
Validation loss: 3.28624119270492

Epoch: 5| Step: 3
Training loss: 3.314707326497975
Validation loss: 3.28038558170148

Epoch: 5| Step: 4
Training loss: 2.937231984999417
Validation loss: 3.2767762703349277

Epoch: 5| Step: 5
Training loss: 2.8566539720797004
Validation loss: 3.2736776987593026

Epoch: 5| Step: 6
Training loss: 3.1281923391618704
Validation loss: 3.270707168494595

Epoch: 5| Step: 7
Training loss: 2.9617814041550288
Validation loss: 3.267112332389565

Epoch: 5| Step: 8
Training loss: 3.7259147288976706
Validation loss: 3.2641219797614798

Epoch: 5| Step: 9
Training loss: 3.7816478425374647
Validation loss: 3.2590858477510483

Epoch: 5| Step: 10
Training loss: 3.906229492133667
Validation loss: 3.2532917738498264

Epoch: 5| Step: 11
Training loss: 2.8407704600408366
Validation loss: 3.2481799776045057

Epoch: 44| Step: 0
Training loss: 3.93801028865712
Validation loss: 3.244125794880727

Epoch: 5| Step: 1
Training loss: 3.704391456079593
Validation loss: 3.2442587276536434

Epoch: 5| Step: 2
Training loss: 3.7716602381236917
Validation loss: 3.2397620324569463

Epoch: 5| Step: 3
Training loss: 3.181123376510957
Validation loss: 3.2351415404595114

Epoch: 5| Step: 4
Training loss: 3.4131425189784266
Validation loss: 3.2289429074358744

Epoch: 5| Step: 5
Training loss: 3.260055099442923
Validation loss: 3.226580212585256

Epoch: 5| Step: 6
Training loss: 3.100742798689612
Validation loss: 3.219068610215141

Epoch: 5| Step: 7
Training loss: 2.3054027417362946
Validation loss: 3.214713735566404

Epoch: 5| Step: 8
Training loss: 3.178532121026461
Validation loss: 3.21174316941349

Epoch: 5| Step: 9
Training loss: 3.6108662220660053
Validation loss: 3.208665599379239

Epoch: 5| Step: 10
Training loss: 3.248718449203443
Validation loss: 3.204415224320242

Epoch: 5| Step: 11
Training loss: 3.5025159784533875
Validation loss: 3.199971900260257

Epoch: 45| Step: 0
Training loss: 3.1724447105165097
Validation loss: 3.197831716040787

Epoch: 5| Step: 1
Training loss: 3.6240822518216596
Validation loss: 3.19378174643468

Epoch: 5| Step: 2
Training loss: 3.11680229694274
Validation loss: 3.189923879498479

Epoch: 5| Step: 3
Training loss: 2.9319883543150147
Validation loss: 3.1860418537405657

Epoch: 5| Step: 4
Training loss: 3.2050578914656884
Validation loss: 3.182963980264704

Epoch: 5| Step: 5
Training loss: 3.462845734780246
Validation loss: 3.1789879994081387

Epoch: 5| Step: 6
Training loss: 3.5502233623028863
Validation loss: 3.175024967771264

Epoch: 5| Step: 7
Training loss: 3.072983839087503
Validation loss: 3.170915104483774

Epoch: 5| Step: 8
Training loss: 2.773443517544088
Validation loss: 3.1676837872941666

Epoch: 5| Step: 9
Training loss: 3.7124161836044305
Validation loss: 3.164159724621663

Epoch: 5| Step: 10
Training loss: 3.7730252690362587
Validation loss: 3.1600988388347737

Epoch: 5| Step: 11
Training loss: 2.9582789420558755
Validation loss: 3.1563880846140275

Epoch: 46| Step: 0
Training loss: 2.9876317334359985
Validation loss: 3.152630748391981

Epoch: 5| Step: 1
Training loss: 2.0771666877063204
Validation loss: 3.148550638922143

Epoch: 5| Step: 2
Training loss: 3.3146447489907147
Validation loss: 3.1461665448606073

Epoch: 5| Step: 3
Training loss: 3.0434960041950556
Validation loss: 3.142311105394666

Epoch: 5| Step: 4
Training loss: 3.055240356679808
Validation loss: 3.138430181161329

Epoch: 5| Step: 5
Training loss: 3.9779908738220997
Validation loss: 3.1353889994282444

Epoch: 5| Step: 6
Training loss: 2.902083989837273
Validation loss: 3.132897310068212

Epoch: 5| Step: 7
Training loss: 3.251857666814045
Validation loss: 3.129376167001031

Epoch: 5| Step: 8
Training loss: 3.235606967875042
Validation loss: 3.1247041466856382

Epoch: 5| Step: 9
Training loss: 3.4978076335430415
Validation loss: 3.122309671103466

Epoch: 5| Step: 10
Training loss: 3.9518556026843608
Validation loss: 3.117431057471287

Epoch: 5| Step: 11
Training loss: 4.542707598093602
Validation loss: 3.1148302922318107

Epoch: 47| Step: 0
Training loss: 2.7550737219499055
Validation loss: 3.1155101658030744

Epoch: 5| Step: 1
Training loss: 3.0361185205417076
Validation loss: 3.1358320123745904

Epoch: 5| Step: 2
Training loss: 3.542014400390439
Validation loss: 3.1493783780227655

Epoch: 5| Step: 3
Training loss: 3.1381908492044066
Validation loss: 3.1320423565315014

Epoch: 5| Step: 4
Training loss: 3.486438225896269
Validation loss: 3.1142793504925756

Epoch: 5| Step: 5
Training loss: 3.554673414936037
Validation loss: 3.106144935038669

Epoch: 5| Step: 6
Training loss: 2.8714557860602397
Validation loss: 3.102577011521498

Epoch: 5| Step: 7
Training loss: 3.3460044034847964
Validation loss: 3.1015807086400473

Epoch: 5| Step: 8
Training loss: 3.161526490198996
Validation loss: 3.1056970156542345

Epoch: 5| Step: 9
Training loss: 3.7846547080890285
Validation loss: 3.1006367164118247

Epoch: 5| Step: 10
Training loss: 2.9129646421801616
Validation loss: 3.091768346170108

Epoch: 5| Step: 11
Training loss: 3.3655594078196684
Validation loss: 3.084882222590556

Epoch: 48| Step: 0
Training loss: 2.644385735299074
Validation loss: 3.07808584908052

Epoch: 5| Step: 1
Training loss: 3.260384328923515
Validation loss: 3.073986085055263

Epoch: 5| Step: 2
Training loss: 2.9504168975561345
Validation loss: 3.0704810862246226

Epoch: 5| Step: 3
Training loss: 3.247427288883006
Validation loss: 3.0675060494810693

Epoch: 5| Step: 4
Training loss: 3.709776751029699
Validation loss: 3.0624424675967528

Epoch: 5| Step: 5
Training loss: 3.11194201757159
Validation loss: 3.0577636995549007

Epoch: 5| Step: 6
Training loss: 3.502289023515312
Validation loss: 3.0535072817474336

Epoch: 5| Step: 7
Training loss: 3.330428351726163
Validation loss: 3.0500459814774663

Epoch: 5| Step: 8
Training loss: 3.2486705995480176
Validation loss: 3.0461887499715004

Epoch: 5| Step: 9
Training loss: 3.1175065797493153
Validation loss: 3.0420210067992213

Epoch: 5| Step: 10
Training loss: 2.9286344135967908
Validation loss: 3.038366667937281

Epoch: 5| Step: 11
Training loss: 3.1921753347709334
Validation loss: 3.0353776023792953

Epoch: 49| Step: 0
Training loss: 2.64285283659065
Validation loss: 3.032885238191843

Epoch: 5| Step: 1
Training loss: 2.4720455337515856
Validation loss: 3.029399523296383

Epoch: 5| Step: 2
Training loss: 3.498047147630503
Validation loss: 3.029036185424689

Epoch: 5| Step: 3
Training loss: 3.5171146203942123
Validation loss: 3.026355898896482

Epoch: 5| Step: 4
Training loss: 3.364983140242853
Validation loss: 3.0260147327706113

Epoch: 5| Step: 5
Training loss: 3.2546463544848048
Validation loss: 3.017943790341466

Epoch: 5| Step: 6
Training loss: 3.113355992280351
Validation loss: 3.013867454091235

Epoch: 5| Step: 7
Training loss: 3.1545180299309856
Validation loss: 3.0107623873039295

Epoch: 5| Step: 8
Training loss: 2.731679579692838
Validation loss: 3.0082386292972596

Epoch: 5| Step: 9
Training loss: 3.185981837736327
Validation loss: 3.00561193580086

Epoch: 5| Step: 10
Training loss: 3.62469586379057
Validation loss: 3.0022487656127566

Epoch: 5| Step: 11
Training loss: 2.8613364574324067
Validation loss: 2.9997117778289595

Epoch: 50| Step: 0
Training loss: 3.0562084733447006
Validation loss: 2.996936439199946

Epoch: 5| Step: 1
Training loss: 2.772386464579636
Validation loss: 2.994854687013835

Epoch: 5| Step: 2
Training loss: 3.1145095221067245
Validation loss: 2.9924155232236993

Epoch: 5| Step: 3
Training loss: 3.0324012693731834
Validation loss: 2.9898004729912744

Epoch: 5| Step: 4
Training loss: 3.23497497596083
Validation loss: 2.9873108196081293

Epoch: 5| Step: 5
Training loss: 3.4846828991799117
Validation loss: 2.984060630418242

Epoch: 5| Step: 6
Training loss: 3.2561098035625955
Validation loss: 2.9805220319619106

Epoch: 5| Step: 7
Training loss: 2.7759395005617122
Validation loss: 2.977687102604008

Epoch: 5| Step: 8
Training loss: 2.8592135691281824
Validation loss: 2.9752305823012124

Epoch: 5| Step: 9
Training loss: 3.1441971690254285
Validation loss: 2.972235022771808

Epoch: 5| Step: 10
Training loss: 3.359309847887475
Validation loss: 2.9697952739239186

Epoch: 5| Step: 11
Training loss: 3.8487014512719675
Validation loss: 2.966612682271041

Epoch: 51| Step: 0
Training loss: 2.953189586760654
Validation loss: 2.9646493398181355

Epoch: 5| Step: 1
Training loss: 2.798773776349936
Validation loss: 2.9615421432692313

Epoch: 5| Step: 2
Training loss: 2.9759836510137405
Validation loss: 2.957844298645717

Epoch: 5| Step: 3
Training loss: 2.8896010776260073
Validation loss: 2.9545023160288295

Epoch: 5| Step: 4
Training loss: 3.2029345944265417
Validation loss: 2.9517292242853963

Epoch: 5| Step: 5
Training loss: 3.555732321981093
Validation loss: 2.949039408302428

Epoch: 5| Step: 6
Training loss: 3.014988807417052
Validation loss: 2.9461086118045583

Epoch: 5| Step: 7
Training loss: 3.122049541004565
Validation loss: 2.9430700175502236

Epoch: 5| Step: 8
Training loss: 2.575237066966908
Validation loss: 2.940278578868099

Epoch: 5| Step: 9
Training loss: 3.3277776832417802
Validation loss: 2.9382430753262496

Epoch: 5| Step: 10
Training loss: 3.335481491904417
Validation loss: 2.935536803978899

Epoch: 5| Step: 11
Training loss: 3.5804614305681515
Validation loss: 2.9319624617208877

Epoch: 52| Step: 0
Training loss: 2.8841506622790374
Validation loss: 2.929675730363728

Epoch: 5| Step: 1
Training loss: 3.102092860924355
Validation loss: 2.9279991269409984

Epoch: 5| Step: 2
Training loss: 3.196071842317134
Validation loss: 2.9253984955552617

Epoch: 5| Step: 3
Training loss: 2.599344768857428
Validation loss: 2.9235263958424333

Epoch: 5| Step: 4
Training loss: 3.428601903439369
Validation loss: 2.920697258751259

Epoch: 5| Step: 5
Training loss: 2.667305502267323
Validation loss: 2.918235882332599

Epoch: 5| Step: 6
Training loss: 3.5109797327059122
Validation loss: 2.9162324934192903

Epoch: 5| Step: 7
Training loss: 3.4129643889300953
Validation loss: 2.9133049710665935

Epoch: 5| Step: 8
Training loss: 3.2894797162452405
Validation loss: 2.910276938715791

Epoch: 5| Step: 9
Training loss: 2.847554941559976
Validation loss: 2.9073580130306858

Epoch: 5| Step: 10
Training loss: 2.3932357195798026
Validation loss: 2.905739284747793

Epoch: 5| Step: 11
Training loss: 3.3704631122720397
Validation loss: 2.9025717329568663

Epoch: 53| Step: 0
Training loss: 2.9869111953269605
Validation loss: 2.8995555733084

Epoch: 5| Step: 1
Training loss: 3.230339149172538
Validation loss: 2.8984687851470965

Epoch: 5| Step: 2
Training loss: 3.944976369305946
Validation loss: 2.895240689886687

Epoch: 5| Step: 3
Training loss: 3.2574743740335625
Validation loss: 2.8928277704080974

Epoch: 5| Step: 4
Training loss: 3.135848175129947
Validation loss: 2.8905586406892025

Epoch: 5| Step: 5
Training loss: 2.9687156273709157
Validation loss: 2.8897163234453167

Epoch: 5| Step: 6
Training loss: 2.3772756816886105
Validation loss: 2.887034765831408

Epoch: 5| Step: 7
Training loss: 2.9478302169003725
Validation loss: 2.884768717391161

Epoch: 5| Step: 8
Training loss: 2.71346101744742
Validation loss: 2.8811619141767997

Epoch: 5| Step: 9
Training loss: 2.778438218335162
Validation loss: 2.8817839161594105

Epoch: 5| Step: 10
Training loss: 2.7618474647062685
Validation loss: 2.8784922695088135

Epoch: 5| Step: 11
Training loss: 2.8481880183360384
Validation loss: 2.874832214075785

Epoch: 54| Step: 0
Training loss: 3.4076750687807147
Validation loss: 2.8723230027032236

Epoch: 5| Step: 1
Training loss: 2.8890889803558446
Validation loss: 2.870640102540264

Epoch: 5| Step: 2
Training loss: 2.1943640781392633
Validation loss: 2.8698551230964107

Epoch: 5| Step: 3
Training loss: 3.0813815322874207
Validation loss: 2.867479044464353

Epoch: 5| Step: 4
Training loss: 3.2925354660082062
Validation loss: 2.866867837574679

Epoch: 5| Step: 5
Training loss: 2.716598448647696
Validation loss: 2.865075722193586

Epoch: 5| Step: 6
Training loss: 3.0526272199083833
Validation loss: 2.8630922818071864

Epoch: 5| Step: 7
Training loss: 3.4945212125474137
Validation loss: 2.8617260514094247

Epoch: 5| Step: 8
Training loss: 2.5767004527862123
Validation loss: 2.858733068648732

Epoch: 5| Step: 9
Training loss: 3.0114296305575206
Validation loss: 2.8558203449868533

Epoch: 5| Step: 10
Training loss: 3.124680617224065
Validation loss: 2.8536278025714346

Epoch: 5| Step: 11
Training loss: 2.8192202495098857
Validation loss: 2.852279200259284

Epoch: 55| Step: 0
Training loss: 2.9623393663081883
Validation loss: 2.849478628197681

Epoch: 5| Step: 1
Training loss: 3.092851758855943
Validation loss: 2.8480274392839418

Epoch: 5| Step: 2
Training loss: 2.958839015097094
Validation loss: 2.8442552837251105

Epoch: 5| Step: 3
Training loss: 2.8152318614378435
Validation loss: 2.8424443436986206

Epoch: 5| Step: 4
Training loss: 3.2767228639840686
Validation loss: 2.837851922930208

Epoch: 5| Step: 5
Training loss: 3.299174442486048
Validation loss: 2.83667961197965

Epoch: 5| Step: 6
Training loss: 2.934563975398732
Validation loss: 2.8351131638810947

Epoch: 5| Step: 7
Training loss: 3.0503896933324706
Validation loss: 2.8311130096158283

Epoch: 5| Step: 8
Training loss: 2.650579615849574
Validation loss: 2.829240122465589

Epoch: 5| Step: 9
Training loss: 2.8787530369148353
Validation loss: 2.8272957437864537

Epoch: 5| Step: 10
Training loss: 2.798952322185513
Validation loss: 2.825806621156023

Epoch: 5| Step: 11
Training loss: 2.779841034001118
Validation loss: 2.8241343364701668

Epoch: 56| Step: 0
Training loss: 2.5137657734865906
Validation loss: 2.8294367444077824

Epoch: 5| Step: 1
Training loss: 3.201703607550297
Validation loss: 2.82906632538072

Epoch: 5| Step: 2
Training loss: 2.7950360949920396
Validation loss: 2.8188908622827347

Epoch: 5| Step: 3
Training loss: 2.6234453229577377
Validation loss: 2.8191855830626245

Epoch: 5| Step: 4
Training loss: 2.902637656772907
Validation loss: 2.815747159678104

Epoch: 5| Step: 5
Training loss: 2.5806542214688335
Validation loss: 2.815445173831601

Epoch: 5| Step: 6
Training loss: 3.498914005187644
Validation loss: 2.8140121598077013

Epoch: 5| Step: 7
Training loss: 2.8411523042087077
Validation loss: 2.8149315495579

Epoch: 5| Step: 8
Training loss: 3.191467508687624
Validation loss: 2.814161011508783

Epoch: 5| Step: 9
Training loss: 3.280737555315931
Validation loss: 2.813729762616471

Epoch: 5| Step: 10
Training loss: 2.941506109277689
Validation loss: 2.81091845514597

Epoch: 5| Step: 11
Training loss: 2.9571171978613235
Validation loss: 2.808520012366392

Epoch: 57| Step: 0
Training loss: 2.854681613625824
Validation loss: 2.8061806468422423

Epoch: 5| Step: 1
Training loss: 3.0780353048975577
Validation loss: 2.804196271319697

Epoch: 5| Step: 2
Training loss: 3.0915459382236214
Validation loss: 2.802690994334583

Epoch: 5| Step: 3
Training loss: 3.0957303885333376
Validation loss: 2.7992035001125894

Epoch: 5| Step: 4
Training loss: 2.922837695475374
Validation loss: 2.796154565212853

Epoch: 5| Step: 5
Training loss: 2.7700148403720415
Validation loss: 2.795164672200852

Epoch: 5| Step: 6
Training loss: 2.960889025771991
Validation loss: 2.792933711474609

Epoch: 5| Step: 7
Training loss: 3.1610782065873697
Validation loss: 2.7934318211949365

Epoch: 5| Step: 8
Training loss: 2.9192537187567473
Validation loss: 2.7876216539713203

Epoch: 5| Step: 9
Training loss: 3.0528177846690427
Validation loss: 2.7870663927163823

Epoch: 5| Step: 10
Training loss: 2.597841000978221
Validation loss: 2.786394854146357

Epoch: 5| Step: 11
Training loss: 0.8794694240605303
Validation loss: 2.7815892659117987

Epoch: 58| Step: 0
Training loss: 2.933100713551685
Validation loss: 2.780005197880366

Epoch: 5| Step: 1
Training loss: 2.792827554615017
Validation loss: 2.781181931109177

Epoch: 5| Step: 2
Training loss: 3.1548842695142274
Validation loss: 2.7790587969544074

Epoch: 5| Step: 3
Training loss: 2.9674981941404046
Validation loss: 2.7775974506549956

Epoch: 5| Step: 4
Training loss: 2.601907334943458
Validation loss: 2.7743696625238465

Epoch: 5| Step: 5
Training loss: 2.6676968928911897
Validation loss: 2.7742373463809415

Epoch: 5| Step: 6
Training loss: 2.91869536191457
Validation loss: 2.775892619890634

Epoch: 5| Step: 7
Training loss: 3.2442755536171477
Validation loss: 2.7739097336453367

Epoch: 5| Step: 8
Training loss: 2.620472409413718
Validation loss: 2.7714774678533796

Epoch: 5| Step: 9
Training loss: 2.5694639898249836
Validation loss: 2.771428669286112

Epoch: 5| Step: 10
Training loss: 3.3318278886780677
Validation loss: 2.768243207683583

Epoch: 5| Step: 11
Training loss: 3.4562485320655507
Validation loss: 2.7649018227574937

Epoch: 59| Step: 0
Training loss: 3.135838139152105
Validation loss: 2.7635794220861722

Epoch: 5| Step: 1
Training loss: 2.759336401733157
Validation loss: 2.7603606068418824

Epoch: 5| Step: 2
Training loss: 3.0677790393463686
Validation loss: 2.7574535925203274

Epoch: 5| Step: 3
Training loss: 2.5852283070016293
Validation loss: 2.7548508595485632

Epoch: 5| Step: 4
Training loss: 3.1827066320566377
Validation loss: 2.755809950210746

Epoch: 5| Step: 5
Training loss: 2.931400052847858
Validation loss: 2.7521422307433103

Epoch: 5| Step: 6
Training loss: 2.805981860699688
Validation loss: 2.7518988072178976

Epoch: 5| Step: 7
Training loss: 2.775466391745976
Validation loss: 2.7484915743379394

Epoch: 5| Step: 8
Training loss: 3.004656991788857
Validation loss: 2.754112647147691

Epoch: 5| Step: 9
Training loss: 2.967647307547207
Validation loss: 2.7675427255316087

Epoch: 5| Step: 10
Training loss: 2.5691470022703844
Validation loss: 2.7441193060538924

Epoch: 5| Step: 11
Training loss: 2.662851634557817
Validation loss: 2.739556560216315

Epoch: 60| Step: 0
Training loss: 3.4398982611848052
Validation loss: 2.7381941182435745

Epoch: 5| Step: 1
Training loss: 2.924257174338037
Validation loss: 2.74068015712561

Epoch: 5| Step: 2
Training loss: 2.6906251701328343
Validation loss: 2.7405771089644517

Epoch: 5| Step: 3
Training loss: 2.970139991209642
Validation loss: 2.741662677126207

Epoch: 5| Step: 4
Training loss: 2.3365206293607215
Validation loss: 2.742446376394522

Epoch: 5| Step: 5
Training loss: 2.9315612497582215
Validation loss: 2.7399575675279886

Epoch: 5| Step: 6
Training loss: 3.00501245734097
Validation loss: 2.7398858441231164

Epoch: 5| Step: 7
Training loss: 2.94050947199546
Validation loss: 2.7393795392103777

Epoch: 5| Step: 8
Training loss: 2.3190311271746507
Validation loss: 2.7359108417228173

Epoch: 5| Step: 9
Training loss: 2.7350130045300935
Validation loss: 2.7356673683358346

Epoch: 5| Step: 10
Training loss: 2.953139693612172
Validation loss: 2.734279227623133

Epoch: 5| Step: 11
Training loss: 3.8381456906733584
Validation loss: 2.731842444941596

Epoch: 61| Step: 0
Training loss: 2.564050716951902
Validation loss: 2.7287939062181614

Epoch: 5| Step: 1
Training loss: 2.5135673495288873
Validation loss: 2.725330132572216

Epoch: 5| Step: 2
Training loss: 2.6906430694646772
Validation loss: 2.7236163919728247

Epoch: 5| Step: 3
Training loss: 2.821313738426183
Validation loss: 2.7230469921788587

Epoch: 5| Step: 4
Training loss: 2.606818311464068
Validation loss: 2.7229702666731854

Epoch: 5| Step: 5
Training loss: 3.456519620288161
Validation loss: 2.7312259815594495

Epoch: 5| Step: 6
Training loss: 2.5211022498924636
Validation loss: 2.7305052777104115

Epoch: 5| Step: 7
Training loss: 3.0258271780943367
Validation loss: 2.7293576484328375

Epoch: 5| Step: 8
Training loss: 3.0036716245537582
Validation loss: 2.7298484137594623

Epoch: 5| Step: 9
Training loss: 3.216470448203285
Validation loss: 2.719615984711378

Epoch: 5| Step: 10
Training loss: 2.916108831920457
Validation loss: 2.712891300605047

Epoch: 5| Step: 11
Training loss: 2.540749139321874
Validation loss: 2.7094436234228136

Epoch: 62| Step: 0
Training loss: 3.066881432131017
Validation loss: 2.7107098252025024

Epoch: 5| Step: 1
Training loss: 2.845274966985853
Validation loss: 2.709539512881403

Epoch: 5| Step: 2
Training loss: 2.89793634323435
Validation loss: 2.7143209928356735

Epoch: 5| Step: 3
Training loss: 2.833391039391579
Validation loss: 2.718131649102471

Epoch: 5| Step: 4
Training loss: 2.552399617013692
Validation loss: 2.7171104500660577

Epoch: 5| Step: 5
Training loss: 3.10739057082755
Validation loss: 2.7167717836283103

Epoch: 5| Step: 6
Training loss: 2.944088790414985
Validation loss: 2.7131238433875264

Epoch: 5| Step: 7
Training loss: 2.934542201664445
Validation loss: 2.7074699395020607

Epoch: 5| Step: 8
Training loss: 2.497175051119043
Validation loss: 2.7049749104516745

Epoch: 5| Step: 9
Training loss: 2.396445574831075
Validation loss: 2.700562565382063

Epoch: 5| Step: 10
Training loss: 3.1749171809410965
Validation loss: 2.6987653057918255

Epoch: 5| Step: 11
Training loss: 2.6983008583695467
Validation loss: 2.6954207062308915

Epoch: 63| Step: 0
Training loss: 2.553954506339704
Validation loss: 2.693912404144068

Epoch: 5| Step: 1
Training loss: 2.8339571172664
Validation loss: 2.692487893344458

Epoch: 5| Step: 2
Training loss: 2.684733541611369
Validation loss: 2.6914589465647714

Epoch: 5| Step: 3
Training loss: 2.706319696176451
Validation loss: 2.690976142196808

Epoch: 5| Step: 4
Training loss: 2.901735306186698
Validation loss: 2.6916641237307917

Epoch: 5| Step: 5
Training loss: 2.956288898365338
Validation loss: 2.690612280915636

Epoch: 5| Step: 6
Training loss: 3.417583962715754
Validation loss: 2.685153916710972

Epoch: 5| Step: 7
Training loss: 2.714013369241281
Validation loss: 2.6835710986355354

Epoch: 5| Step: 8
Training loss: 2.774499824055075
Validation loss: 2.6809477145887537

Epoch: 5| Step: 9
Training loss: 2.838197422443451
Validation loss: 2.6786377966696757

Epoch: 5| Step: 10
Training loss: 2.6160013272226683
Validation loss: 2.6775824431600657

Epoch: 5| Step: 11
Training loss: 2.9282200100689435
Validation loss: 2.6780825777377317

Epoch: 64| Step: 0
Training loss: 2.8194253218262806
Validation loss: 2.6764530572972602

Epoch: 5| Step: 1
Training loss: 3.11958759810116
Validation loss: 2.677213843141711

Epoch: 5| Step: 2
Training loss: 3.060549679421976
Validation loss: 2.6744454625329652

Epoch: 5| Step: 3
Training loss: 3.2427579446868355
Validation loss: 2.670347922506666

Epoch: 5| Step: 4
Training loss: 2.3918847648076396
Validation loss: 2.6688511414610816

Epoch: 5| Step: 5
Training loss: 2.3082291626635785
Validation loss: 2.673432671315722

Epoch: 5| Step: 6
Training loss: 2.844572514227101
Validation loss: 2.6757697149246216

Epoch: 5| Step: 7
Training loss: 2.602464399286654
Validation loss: 2.679002639105896

Epoch: 5| Step: 8
Training loss: 2.795458386933816
Validation loss: 2.6707550586849047

Epoch: 5| Step: 9
Training loss: 2.821203878192191
Validation loss: 2.6679382285238207

Epoch: 5| Step: 10
Training loss: 2.699012406186752
Validation loss: 2.6619842641701155

Epoch: 5| Step: 11
Training loss: 2.899321305669363
Validation loss: 2.668081866687375

Epoch: 65| Step: 0
Training loss: 2.0912293021209014
Validation loss: 2.662210225139904

Epoch: 5| Step: 1
Training loss: 3.1444208540404097
Validation loss: 2.6615163506879878

Epoch: 5| Step: 2
Training loss: 2.6963113454349066
Validation loss: 2.6627876908351933

Epoch: 5| Step: 3
Training loss: 2.7863658188527483
Validation loss: 2.672812986902747

Epoch: 5| Step: 4
Training loss: 2.6739287040524227
Validation loss: 2.678744206608429

Epoch: 5| Step: 5
Training loss: 2.870162376834623
Validation loss: 2.688867505673128

Epoch: 5| Step: 6
Training loss: 3.2383529599927265
Validation loss: 2.701700198898706

Epoch: 5| Step: 7
Training loss: 2.6600417954165754
Validation loss: 2.7079086129633776

Epoch: 5| Step: 8
Training loss: 2.8245277921606196
Validation loss: 2.6981013847261934

Epoch: 5| Step: 9
Training loss: 2.8357942403123455
Validation loss: 2.696319123049552

Epoch: 5| Step: 10
Training loss: 3.121079999871933
Validation loss: 2.6868281189936325

Epoch: 5| Step: 11
Training loss: 1.9713589169752839
Validation loss: 2.671805211693183

Epoch: 66| Step: 0
Training loss: 2.858858989577842
Validation loss: 2.659343346938952

Epoch: 5| Step: 1
Training loss: 2.786796611086374
Validation loss: 2.6573372205306107

Epoch: 5| Step: 2
Training loss: 2.505470489510865
Validation loss: 2.6565510523116065

Epoch: 5| Step: 3
Training loss: 3.1968435336267573
Validation loss: 2.658856418370792

Epoch: 5| Step: 4
Training loss: 2.1086462952100864
Validation loss: 2.6546204336764507

Epoch: 5| Step: 5
Training loss: 3.2982169218050608
Validation loss: 2.6564544075499166

Epoch: 5| Step: 6
Training loss: 2.584844629130421
Validation loss: 2.6535750327556142

Epoch: 5| Step: 7
Training loss: 2.8082067995024818
Validation loss: 2.6599320192541627

Epoch: 5| Step: 8
Training loss: 2.7900028299843713
Validation loss: 2.6565590622559614

Epoch: 5| Step: 9
Training loss: 2.4790167455996297
Validation loss: 2.6443554976196544

Epoch: 5| Step: 10
Training loss: 3.0356597286418885
Validation loss: 2.64079454167401

Epoch: 5| Step: 11
Training loss: 2.861506267118815
Validation loss: 2.6409388398938307

Epoch: 67| Step: 0
Training loss: 2.8863300479908838
Validation loss: 2.639623579989505

Epoch: 5| Step: 1
Training loss: 2.6696648630984017
Validation loss: 2.6405878910865623

Epoch: 5| Step: 2
Training loss: 2.8283003441844827
Validation loss: 2.6348530665527035

Epoch: 5| Step: 3
Training loss: 2.087619974491993
Validation loss: 2.6346906571672286

Epoch: 5| Step: 4
Training loss: 3.2520578178530557
Validation loss: 2.634131036324564

Epoch: 5| Step: 5
Training loss: 2.765591637361665
Validation loss: 2.6325194160793575

Epoch: 5| Step: 6
Training loss: 2.8017388360121123
Validation loss: 2.6347737728112626

Epoch: 5| Step: 7
Training loss: 3.2526014626794373
Validation loss: 2.632949523680519

Epoch: 5| Step: 8
Training loss: 2.0258813188216234
Validation loss: 2.6292589620802786

Epoch: 5| Step: 9
Training loss: 2.7830830223538006
Validation loss: 2.625655202234088

Epoch: 5| Step: 10
Training loss: 2.974483855536645
Validation loss: 2.6269700627684958

Epoch: 5| Step: 11
Training loss: 1.9804580357128203
Validation loss: 2.625320176625434

Epoch: 68| Step: 0
Training loss: 2.6793102299109504
Validation loss: 2.626696250485901

Epoch: 5| Step: 1
Training loss: 3.400448819998501
Validation loss: 2.629614656632837

Epoch: 5| Step: 2
Training loss: 3.033548014942233
Validation loss: 2.633451540824917

Epoch: 5| Step: 3
Training loss: 2.549525280315585
Validation loss: 2.621635301474691

Epoch: 5| Step: 4
Training loss: 2.7365469889273637
Validation loss: 2.6212173978518063

Epoch: 5| Step: 5
Training loss: 2.3890661006324034
Validation loss: 2.6207399807018295

Epoch: 5| Step: 6
Training loss: 2.8524375931435064
Validation loss: 2.622116461643123

Epoch: 5| Step: 7
Training loss: 2.7725969787092493
Validation loss: 2.623827979158957

Epoch: 5| Step: 8
Training loss: 2.5774518608089654
Validation loss: 2.6249839502176964

Epoch: 5| Step: 9
Training loss: 2.324259063627533
Validation loss: 2.6231980269589554

Epoch: 5| Step: 10
Training loss: 3.1550627637807773
Validation loss: 2.620597079766895

Epoch: 5| Step: 11
Training loss: 1.4743872064632546
Validation loss: 2.6217678016326684

Epoch: 69| Step: 0
Training loss: 2.718483922807345
Validation loss: 2.6182660437868535

Epoch: 5| Step: 1
Training loss: 2.8243289994581326
Validation loss: 2.6199728420902972

Epoch: 5| Step: 2
Training loss: 2.834555381073727
Validation loss: 2.618749693185429

Epoch: 5| Step: 3
Training loss: 2.633644583773622
Validation loss: 2.6166298571101296

Epoch: 5| Step: 4
Training loss: 2.5651393416779764
Validation loss: 2.6133559044788517

Epoch: 5| Step: 5
Training loss: 2.8558057176560645
Validation loss: 2.6122987018647352

Epoch: 5| Step: 6
Training loss: 2.76750214229456
Validation loss: 2.606823284575472

Epoch: 5| Step: 7
Training loss: 2.648203161444274
Validation loss: 2.613566046203615

Epoch: 5| Step: 8
Training loss: 3.0427785086753265
Validation loss: 2.6114274022497574

Epoch: 5| Step: 9
Training loss: 2.831327195620398
Validation loss: 2.6096238723822855

Epoch: 5| Step: 10
Training loss: 2.8060787225122596
Validation loss: 2.6058614378673037

Epoch: 5| Step: 11
Training loss: 0.3286135193142305
Validation loss: 2.6068575778264074

Epoch: 70| Step: 0
Training loss: 2.8779976185993577
Validation loss: 2.6064937430311006

Epoch: 5| Step: 1
Training loss: 2.469357379608123
Validation loss: 2.605299197298704

Epoch: 5| Step: 2
Training loss: 2.6791089381459674
Validation loss: 2.6073775917512294

Epoch: 5| Step: 3
Training loss: 3.032044611338442
Validation loss: 2.605991797155438

Epoch: 5| Step: 4
Training loss: 3.0752219825574207
Validation loss: 2.6092241628150465

Epoch: 5| Step: 5
Training loss: 2.645912069115343
Validation loss: 2.6089342015294785

Epoch: 5| Step: 6
Training loss: 2.650821659174755
Validation loss: 2.606837910422076

Epoch: 5| Step: 7
Training loss: 2.737012713535539
Validation loss: 2.6068743717897376

Epoch: 5| Step: 8
Training loss: 2.6043779414622406
Validation loss: 2.605774693253706

Epoch: 5| Step: 9
Training loss: 2.513443658601358
Validation loss: 2.606270208821669

Epoch: 5| Step: 10
Training loss: 2.860101993049292
Validation loss: 2.6032839550626035

Epoch: 5| Step: 11
Training loss: 2.5381653124912757
Validation loss: 2.6023093861189457

Epoch: 71| Step: 0
Training loss: 2.3719720109442957
Validation loss: 2.6015944684177055

Epoch: 5| Step: 1
Training loss: 2.5306473944820866
Validation loss: 2.598721011123821

Epoch: 5| Step: 2
Training loss: 2.8863470640915048
Validation loss: 2.598043392846104

Epoch: 5| Step: 3
Training loss: 2.528928657741223
Validation loss: 2.60203760599151

Epoch: 5| Step: 4
Training loss: 3.022859266714596
Validation loss: 2.6065584655798792

Epoch: 5| Step: 5
Training loss: 2.6136842881584808
Validation loss: 2.6119650399512864

Epoch: 5| Step: 6
Training loss: 2.8320932105290955
Validation loss: 2.6076072712683205

Epoch: 5| Step: 7
Training loss: 2.6546091733876453
Validation loss: 2.598354289790271

Epoch: 5| Step: 8
Training loss: 3.081665172036694
Validation loss: 2.5898262587196856

Epoch: 5| Step: 9
Training loss: 2.6361838469292675
Validation loss: 2.5905636630219

Epoch: 5| Step: 10
Training loss: 2.938235738615312
Validation loss: 2.5931334279756175

Epoch: 5| Step: 11
Training loss: 1.962209099269334
Validation loss: 2.5933936881635598

Epoch: 72| Step: 0
Training loss: 2.686080646528421
Validation loss: 2.592940579550884

Epoch: 5| Step: 1
Training loss: 2.789890540378766
Validation loss: 2.5939427384613

Epoch: 5| Step: 2
Training loss: 2.480341870524653
Validation loss: 2.5951551974198717

Epoch: 5| Step: 3
Training loss: 2.723738905248152
Validation loss: 2.594067443051301

Epoch: 5| Step: 4
Training loss: 2.9452768824520796
Validation loss: 2.594066520129913

Epoch: 5| Step: 5
Training loss: 2.4480357256133733
Validation loss: 2.593924474401506

Epoch: 5| Step: 6
Training loss: 2.925388284326494
Validation loss: 2.5909807520025936

Epoch: 5| Step: 7
Training loss: 2.371600780291211
Validation loss: 2.591443070019861

Epoch: 5| Step: 8
Training loss: 2.7208407901897353
Validation loss: 2.591899303490671

Epoch: 5| Step: 9
Training loss: 2.7237502845879553
Validation loss: 2.589791452254751

Epoch: 5| Step: 10
Training loss: 3.1635155475849985
Validation loss: 2.5877446508923843

Epoch: 5| Step: 11
Training loss: 2.241312633858309
Validation loss: 2.586359625377106

Epoch: 73| Step: 0
Training loss: 2.680415374393429
Validation loss: 2.5800229455792487

Epoch: 5| Step: 1
Training loss: 2.8704908088200716
Validation loss: 2.579728442860124

Epoch: 5| Step: 2
Training loss: 2.179852551189639
Validation loss: 2.5989744278913345

Epoch: 5| Step: 3
Training loss: 3.3455031602987386
Validation loss: 2.621750318724903

Epoch: 5| Step: 4
Training loss: 2.858759245730362
Validation loss: 2.5872391174551486

Epoch: 5| Step: 5
Training loss: 2.570121039126702
Validation loss: 2.5759253973250225

Epoch: 5| Step: 6
Training loss: 2.2563396784747245
Validation loss: 2.5769727039157178

Epoch: 5| Step: 7
Training loss: 2.7352358961453866
Validation loss: 2.577121994193194

Epoch: 5| Step: 8
Training loss: 2.3533926397456675
Validation loss: 2.5784899173990916

Epoch: 5| Step: 9
Training loss: 2.930510301125045
Validation loss: 2.581601032498548

Epoch: 5| Step: 10
Training loss: 3.0922246698474996
Validation loss: 2.587517677160746

Epoch: 5| Step: 11
Training loss: 2.093546615515272
Validation loss: 2.5939838886133195

Epoch: 74| Step: 0
Training loss: 2.5710698551167637
Validation loss: 2.5996136186442333

Epoch: 5| Step: 1
Training loss: 2.712550318378689
Validation loss: 2.611891528580322

Epoch: 5| Step: 2
Training loss: 2.5194479758525166
Validation loss: 2.6154703950632747

Epoch: 5| Step: 3
Training loss: 3.1882124459905494
Validation loss: 2.6123960142719778

Epoch: 5| Step: 4
Training loss: 2.4801863381923064
Validation loss: 2.613557410366967

Epoch: 5| Step: 5
Training loss: 2.221735275746876
Validation loss: 2.5995787234927077

Epoch: 5| Step: 6
Training loss: 3.1899048951898936
Validation loss: 2.5946321059858657

Epoch: 5| Step: 7
Training loss: 2.3739214003935727
Validation loss: 2.5855464620436672

Epoch: 5| Step: 8
Training loss: 3.1774789699335724
Validation loss: 2.58278528804179

Epoch: 5| Step: 9
Training loss: 2.847288508276819
Validation loss: 2.574383496428445

Epoch: 5| Step: 10
Training loss: 2.6763870778583847
Validation loss: 2.570599026927884

Epoch: 5| Step: 11
Training loss: 1.6043642426068097
Validation loss: 2.5712733709540125

Epoch: 75| Step: 0
Training loss: 2.6046232713310156
Validation loss: 2.573637723593566

Epoch: 5| Step: 1
Training loss: 2.5653950224568414
Validation loss: 2.567253727676816

Epoch: 5| Step: 2
Training loss: 2.9987602851312847
Validation loss: 2.570086990095169

Epoch: 5| Step: 3
Training loss: 2.666253852680497
Validation loss: 2.558452813923624

Epoch: 5| Step: 4
Training loss: 2.382889443077649
Validation loss: 2.561572011529981

Epoch: 5| Step: 5
Training loss: 2.7695137744346834
Validation loss: 2.567503792674214

Epoch: 5| Step: 6
Training loss: 2.4219863373790793
Validation loss: 2.562252466915284

Epoch: 5| Step: 7
Training loss: 2.5142525666857125
Validation loss: 2.56643613645976

Epoch: 5| Step: 8
Training loss: 2.4948404475933432
Validation loss: 2.5713830088717753

Epoch: 5| Step: 9
Training loss: 3.0983979730975206
Validation loss: 2.5648059316591727

Epoch: 5| Step: 10
Training loss: 2.932367589226277
Validation loss: 2.5598091015072315

Epoch: 5| Step: 11
Training loss: 3.545626517217679
Validation loss: 2.5585855809049773

Epoch: 76| Step: 0
Training loss: 3.050410171194099
Validation loss: 2.559460803166799

Epoch: 5| Step: 1
Training loss: 2.6324101262269815
Validation loss: 2.5648701181798303

Epoch: 5| Step: 2
Training loss: 2.295690737228892
Validation loss: 2.5680680799949647

Epoch: 5| Step: 3
Training loss: 3.0075452016983535
Validation loss: 2.573810058706345

Epoch: 5| Step: 4
Training loss: 2.579607450651511
Validation loss: 2.580459651224555

Epoch: 5| Step: 5
Training loss: 3.0159820187181894
Validation loss: 2.5835846514638243

Epoch: 5| Step: 6
Training loss: 2.7024359734473404
Validation loss: 2.588333959452481

Epoch: 5| Step: 7
Training loss: 2.53005915757326
Validation loss: 2.5903907992125945

Epoch: 5| Step: 8
Training loss: 2.6530931450646733
Validation loss: 2.589972940159985

Epoch: 5| Step: 9
Training loss: 2.6044351566508572
Validation loss: 2.5944553588133434

Epoch: 5| Step: 10
Training loss: 2.719820622952701
Validation loss: 2.583166449037592

Epoch: 5| Step: 11
Training loss: 2.323831375281388
Validation loss: 2.5793288339116494

Epoch: 77| Step: 0
Training loss: 2.7880317215065817
Validation loss: 2.5715868418038226

Epoch: 5| Step: 1
Training loss: 2.454732963194421
Validation loss: 2.569904097834637

Epoch: 5| Step: 2
Training loss: 2.425998549012004
Validation loss: 2.565208093438754

Epoch: 5| Step: 3
Training loss: 2.7630343615134527
Validation loss: 2.565925367292051

Epoch: 5| Step: 4
Training loss: 2.687271197138278
Validation loss: 2.5605110148487378

Epoch: 5| Step: 5
Training loss: 3.0081373163189484
Validation loss: 2.5579553210435493

Epoch: 5| Step: 6
Training loss: 2.8116904047167637
Validation loss: 2.55588109308758

Epoch: 5| Step: 7
Training loss: 2.6471843624265268
Validation loss: 2.555395108060545

Epoch: 5| Step: 8
Training loss: 2.337069642132325
Validation loss: 2.5524701363812015

Epoch: 5| Step: 9
Training loss: 2.8658449111472404
Validation loss: 2.548167784057761

Epoch: 5| Step: 10
Training loss: 2.6649334957563573
Validation loss: 2.5451785719551885

Epoch: 5| Step: 11
Training loss: 2.6326846309592167
Validation loss: 2.538660023408183

Epoch: 78| Step: 0
Training loss: 2.2961970775571365
Validation loss: 2.5428334955595155

Epoch: 5| Step: 1
Training loss: 2.839484232691324
Validation loss: 2.5413476921001465

Epoch: 5| Step: 2
Training loss: 1.9987852460605628
Validation loss: 2.5391949154486726

Epoch: 5| Step: 3
Training loss: 2.8941292631626756
Validation loss: 2.53753568862222

Epoch: 5| Step: 4
Training loss: 2.6758315923925307
Validation loss: 2.535174910011839

Epoch: 5| Step: 5
Training loss: 3.21954365547158
Validation loss: 2.5333525280999085

Epoch: 5| Step: 6
Training loss: 2.7479749506123805
Validation loss: 2.538656419412617

Epoch: 5| Step: 7
Training loss: 2.4310502036405683
Validation loss: 2.5372168498857897

Epoch: 5| Step: 8
Training loss: 2.9293085692442262
Validation loss: 2.540789125684948

Epoch: 5| Step: 9
Training loss: 2.80495228487118
Validation loss: 2.546896698436085

Epoch: 5| Step: 10
Training loss: 2.3207870665983106
Validation loss: 2.544588380882196

Epoch: 5| Step: 11
Training loss: 2.8736194115329305
Validation loss: 2.5422204357624816

Epoch: 79| Step: 0
Training loss: 2.1391041497354744
Validation loss: 2.5409279724375344

Epoch: 5| Step: 1
Training loss: 2.8988708007697865
Validation loss: 2.538430038322838

Epoch: 5| Step: 2
Training loss: 2.6943463791592706
Validation loss: 2.5392365107452033

Epoch: 5| Step: 3
Training loss: 2.7482611620764916
Validation loss: 2.5418453088631305

Epoch: 5| Step: 4
Training loss: 2.7897697855540664
Validation loss: 2.5443639351018463

Epoch: 5| Step: 5
Training loss: 2.334359749331824
Validation loss: 2.5387109640273606

Epoch: 5| Step: 6
Training loss: 2.7824448151441405
Validation loss: 2.5344962665286785

Epoch: 5| Step: 7
Training loss: 2.450040007284061
Validation loss: 2.534619776660107

Epoch: 5| Step: 8
Training loss: 3.0272637338215724
Validation loss: 2.5327030689305805

Epoch: 5| Step: 9
Training loss: 2.689336814387648
Validation loss: 2.5250120496304995

Epoch: 5| Step: 10
Training loss: 2.6394854914097925
Validation loss: 2.5263993878420496

Epoch: 5| Step: 11
Training loss: 2.586042050555956
Validation loss: 2.533112715747738

Epoch: 80| Step: 0
Training loss: 2.2561275966759746
Validation loss: 2.526668943932127

Epoch: 5| Step: 1
Training loss: 2.5335783434225045
Validation loss: 2.5316173969716487

Epoch: 5| Step: 2
Training loss: 2.4763614801599387
Validation loss: 2.531070392814151

Epoch: 5| Step: 3
Training loss: 2.569127606855844
Validation loss: 2.528394737047048

Epoch: 5| Step: 4
Training loss: 2.9980673922852503
Validation loss: 2.5279959063740773

Epoch: 5| Step: 5
Training loss: 2.428656061685288
Validation loss: 2.5301427106852925

Epoch: 5| Step: 6
Training loss: 2.873717644016924
Validation loss: 2.529955831382152

Epoch: 5| Step: 7
Training loss: 2.7757387741536643
Validation loss: 2.528877905041679

Epoch: 5| Step: 8
Training loss: 2.349870751255784
Validation loss: 2.5260633893733977

Epoch: 5| Step: 9
Training loss: 2.8582362841561744
Validation loss: 2.5319354891262646

Epoch: 5| Step: 10
Training loss: 3.0703771065085594
Validation loss: 2.52615952102128

Epoch: 5| Step: 11
Training loss: 1.9535015506157287
Validation loss: 2.530385847108658

Epoch: 81| Step: 0
Training loss: 2.1430962769727047
Validation loss: 2.5327917199730656

Epoch: 5| Step: 1
Training loss: 2.7517516886166242
Validation loss: 2.5283142694858056

Epoch: 5| Step: 2
Training loss: 2.517198153662084
Validation loss: 2.522435055121319

Epoch: 5| Step: 3
Training loss: 2.756714513133594
Validation loss: 2.5247065184724775

Epoch: 5| Step: 4
Training loss: 2.803269646866532
Validation loss: 2.5360926782964848

Epoch: 5| Step: 5
Training loss: 2.7506666242470357
Validation loss: 2.525091099905448

Epoch: 5| Step: 6
Training loss: 2.468633238530125
Validation loss: 2.526644665560222

Epoch: 5| Step: 7
Training loss: 2.7616391527934456
Validation loss: 2.5257347287504226

Epoch: 5| Step: 8
Training loss: 2.5888739103376026
Validation loss: 2.5256123574517964

Epoch: 5| Step: 9
Training loss: 2.597638903108198
Validation loss: 2.5220612984583375

Epoch: 5| Step: 10
Training loss: 2.884103046793142
Validation loss: 2.5252317736102956

Epoch: 5| Step: 11
Training loss: 3.0295644576774823
Validation loss: 2.532436179260373

Epoch: 82| Step: 0
Training loss: 2.3023360330887916
Validation loss: 2.532722939396884

Epoch: 5| Step: 1
Training loss: 2.8777944832721567
Validation loss: 2.530696054762639

Epoch: 5| Step: 2
Training loss: 2.6375459856842536
Validation loss: 2.5224877647856787

Epoch: 5| Step: 3
Training loss: 2.6082978909393035
Validation loss: 2.5273957736022874

Epoch: 5| Step: 4
Training loss: 2.8731974050789213
Validation loss: 2.526225578193835

Epoch: 5| Step: 5
Training loss: 2.8328410076173487
Validation loss: 2.523880174701661

Epoch: 5| Step: 6
Training loss: 2.8468636036214505
Validation loss: 2.5231978398101647

Epoch: 5| Step: 7
Training loss: 2.304563046990672
Validation loss: 2.5187281311827485

Epoch: 5| Step: 8
Training loss: 2.679212967476
Validation loss: 2.516605798088381

Epoch: 5| Step: 9
Training loss: 2.746256968611365
Validation loss: 2.520171288706317

Epoch: 5| Step: 10
Training loss: 2.3416895646936253
Validation loss: 2.5196978373494665

Epoch: 5| Step: 11
Training loss: 2.200036989247871
Validation loss: 2.5160627833211455

Epoch: 83| Step: 0
Training loss: 2.693678739450417
Validation loss: 2.5198526655501348

Epoch: 5| Step: 1
Training loss: 2.57968674953734
Validation loss: 2.5193035643851904

Epoch: 5| Step: 2
Training loss: 2.5618706837580763
Validation loss: 2.524656275056278

Epoch: 5| Step: 3
Training loss: 2.623827717917193
Validation loss: 2.5212989776398245

Epoch: 5| Step: 4
Training loss: 2.275269913643575
Validation loss: 2.518317268721337

Epoch: 5| Step: 5
Training loss: 2.8708592325563957
Validation loss: 2.5105732569523385

Epoch: 5| Step: 6
Training loss: 2.8686956861752297
Validation loss: 2.5146774813755584

Epoch: 5| Step: 7
Training loss: 2.1682478441552946
Validation loss: 2.5110911271883456

Epoch: 5| Step: 8
Training loss: 3.0179338066572545
Validation loss: 2.519084494555904

Epoch: 5| Step: 9
Training loss: 2.532611716123254
Validation loss: 2.516166569482133

Epoch: 5| Step: 10
Training loss: 2.69236563316291
Validation loss: 2.5294963271986624

Epoch: 5| Step: 11
Training loss: 2.322591567846989
Validation loss: 2.506718643588895

Epoch: 84| Step: 0
Training loss: 2.8128751716459455
Validation loss: 2.518049722226285

Epoch: 5| Step: 1
Training loss: 2.989227025578556
Validation loss: 2.535661930068856

Epoch: 5| Step: 2
Training loss: 3.108311917092297
Validation loss: 2.5143677904868165

Epoch: 5| Step: 3
Training loss: 2.033562620190688
Validation loss: 2.516005532684166

Epoch: 5| Step: 4
Training loss: 2.3538152606848963
Validation loss: 2.518010487310655

Epoch: 5| Step: 5
Training loss: 2.5980640062665814
Validation loss: 2.5344076711898302

Epoch: 5| Step: 6
Training loss: 2.891377119212887
Validation loss: 2.5473387594360744

Epoch: 5| Step: 7
Training loss: 2.5522275507654544
Validation loss: 2.561316166319881

Epoch: 5| Step: 8
Training loss: 2.61198568802866
Validation loss: 2.5761323722874416

Epoch: 5| Step: 9
Training loss: 2.5922114393567104
Validation loss: 2.58481026673811

Epoch: 5| Step: 10
Training loss: 2.9608236406723973
Validation loss: 2.599409631191318

Epoch: 5| Step: 11
Training loss: 2.5362945023303722
Validation loss: 2.604778043824264

Epoch: 85| Step: 0
Training loss: 2.7153148654010315
Validation loss: 2.597107376584259

Epoch: 5| Step: 1
Training loss: 2.554478254702427
Validation loss: 2.606447584070955

Epoch: 5| Step: 2
Training loss: 2.7774919129673665
Validation loss: 2.5976801706230925

Epoch: 5| Step: 3
Training loss: 2.434680090065365
Validation loss: 2.590192001349785

Epoch: 5| Step: 4
Training loss: 2.6903063294088145
Validation loss: 2.5832448503251024

Epoch: 5| Step: 5
Training loss: 3.2384480800380375
Validation loss: 2.577505041007124

Epoch: 5| Step: 6
Training loss: 2.6507351341474705
Validation loss: 2.5676692562469885

Epoch: 5| Step: 7
Training loss: 2.413630770993721
Validation loss: 2.562178591598618

Epoch: 5| Step: 8
Training loss: 2.3950790102355697
Validation loss: 2.561656628974561

Epoch: 5| Step: 9
Training loss: 2.754479487934278
Validation loss: 2.5557479174117668

Epoch: 5| Step: 10
Training loss: 2.9067343031453756
Validation loss: 2.5519007416366652

Epoch: 5| Step: 11
Training loss: 2.582124693964384
Validation loss: 2.546645893331339

Epoch: 86| Step: 0
Training loss: 2.8267419288920155
Validation loss: 2.543908964496607

Epoch: 5| Step: 1
Training loss: 2.583465870154316
Validation loss: 2.537847774144446

Epoch: 5| Step: 2
Training loss: 2.74310713342605
Validation loss: 2.535020947090798

Epoch: 5| Step: 3
Training loss: 2.5864587356458504
Validation loss: 2.533245544156865

Epoch: 5| Step: 4
Training loss: 2.5793770264196327
Validation loss: 2.531502338280509

Epoch: 5| Step: 5
Training loss: 2.7591753393843597
Validation loss: 2.5254369555926908

Epoch: 5| Step: 6
Training loss: 2.294114510575764
Validation loss: 2.525608561769978

Epoch: 5| Step: 7
Training loss: 3.0353785449383044
Validation loss: 2.525452926036412

Epoch: 5| Step: 8
Training loss: 2.6609121360622763
Validation loss: 2.523414564471343

Epoch: 5| Step: 9
Training loss: 2.608356391227945
Validation loss: 2.5181536020475743

Epoch: 5| Step: 10
Training loss: 2.5066132812530437
Validation loss: 2.5181229275394843

Epoch: 5| Step: 11
Training loss: 2.274947251766848
Validation loss: 2.519038638669289

Epoch: 87| Step: 0
Training loss: 2.5982039483697617
Validation loss: 2.5170627102898706

Epoch: 5| Step: 1
Training loss: 2.574471399067999
Validation loss: 2.516496436306988

Epoch: 5| Step: 2
Training loss: 2.7531602214244604
Validation loss: 2.515225096324717

Epoch: 5| Step: 3
Training loss: 2.793646968844783
Validation loss: 2.5105119359998227

Epoch: 5| Step: 4
Training loss: 2.779185868577712
Validation loss: 2.509369017537271

Epoch: 5| Step: 5
Training loss: 2.5707930373666605
Validation loss: 2.508344271045634

Epoch: 5| Step: 6
Training loss: 2.500647365676944
Validation loss: 2.5070089001410736

Epoch: 5| Step: 7
Training loss: 2.476605436031103
Validation loss: 2.50750813563375

Epoch: 5| Step: 8
Training loss: 2.2719156211779077
Validation loss: 2.507027040555104

Epoch: 5| Step: 9
Training loss: 2.717757120470691
Validation loss: 2.5067212789775963

Epoch: 5| Step: 10
Training loss: 2.7582896741041414
Validation loss: 2.504444871757117

Epoch: 5| Step: 11
Training loss: 3.295121291479499
Validation loss: 2.5008627118252877

Epoch: 88| Step: 0
Training loss: 2.386127105154016
Validation loss: 2.495036988484274

Epoch: 5| Step: 1
Training loss: 2.812665637754891
Validation loss: 2.502779567789371

Epoch: 5| Step: 2
Training loss: 2.989085369750461
Validation loss: 2.507439543025981

Epoch: 5| Step: 3
Training loss: 2.3539771169686237
Validation loss: 2.488777606190866

Epoch: 5| Step: 4
Training loss: 2.624433365472846
Validation loss: 2.492546007923606

Epoch: 5| Step: 5
Training loss: 2.98102817309918
Validation loss: 2.4933301524428444

Epoch: 5| Step: 6
Training loss: 2.4841932314229025
Validation loss: 2.4987978270041946

Epoch: 5| Step: 7
Training loss: 2.5645724034224964
Validation loss: 2.501183595222285

Epoch: 5| Step: 8
Training loss: 2.4460099173319056
Validation loss: 2.495231455595748

Epoch: 5| Step: 9
Training loss: 2.457265190789344
Validation loss: 2.497841658326384

Epoch: 5| Step: 10
Training loss: 2.7845670657377437
Validation loss: 2.4977761311537896

Epoch: 5| Step: 11
Training loss: 2.538034647723879
Validation loss: 2.4968296094643025

Epoch: 89| Step: 0
Training loss: 2.7086780817741323
Validation loss: 2.498027627456716

Epoch: 5| Step: 1
Training loss: 2.5200094552846664
Validation loss: 2.5054329806435898

Epoch: 5| Step: 2
Training loss: 2.4129660872642518
Validation loss: 2.4952706764425

Epoch: 5| Step: 3
Training loss: 2.9075285037505774
Validation loss: 2.495153963598073

Epoch: 5| Step: 4
Training loss: 2.6351548820014794
Validation loss: 2.5019855998440796

Epoch: 5| Step: 5
Training loss: 2.4846761269081816
Validation loss: 2.5076431066676608

Epoch: 5| Step: 6
Training loss: 2.9051541138836403
Validation loss: 2.5042001528942053

Epoch: 5| Step: 7
Training loss: 2.7620300376523863
Validation loss: 2.513122601334418

Epoch: 5| Step: 8
Training loss: 2.928713705348392
Validation loss: 2.5115139345279562

Epoch: 5| Step: 9
Training loss: 2.3771158129796435
Validation loss: 2.509083533709435

Epoch: 5| Step: 10
Training loss: 2.268205738202112
Validation loss: 2.503850292546613

Epoch: 5| Step: 11
Training loss: 0.43106472209387
Validation loss: 2.4944913095330636

Epoch: 90| Step: 0
Training loss: 2.4223752397312412
Validation loss: 2.4974476978271967

Epoch: 5| Step: 1
Training loss: 2.5807951076075706
Validation loss: 2.4924706883111485

Epoch: 5| Step: 2
Training loss: 2.3997472113358542
Validation loss: 2.4950750915997513

Epoch: 5| Step: 3
Training loss: 2.988563035631729
Validation loss: 2.491296116494112

Epoch: 5| Step: 4
Training loss: 2.7887930432686456
Validation loss: 2.4954993187407832

Epoch: 5| Step: 5
Training loss: 2.28550208971541
Validation loss: 2.491193463503352

Epoch: 5| Step: 6
Training loss: 2.4261336753981384
Validation loss: 2.491400966277829

Epoch: 5| Step: 7
Training loss: 2.284311408998618
Validation loss: 2.499421100348696

Epoch: 5| Step: 8
Training loss: 2.8230613774631386
Validation loss: 2.493566966370827

Epoch: 5| Step: 9
Training loss: 2.784279362912376
Validation loss: 2.494392177210725

Epoch: 5| Step: 10
Training loss: 2.798144771530785
Validation loss: 2.4934363868291127

Epoch: 5| Step: 11
Training loss: 2.611379162126299
Validation loss: 2.4984301585458772

Epoch: 91| Step: 0
Training loss: 2.4019199400684728
Validation loss: 2.4977599320435506

Epoch: 5| Step: 1
Training loss: 2.903872265846509
Validation loss: 2.49008235691788

Epoch: 5| Step: 2
Training loss: 2.272780805304097
Validation loss: 2.483871596895059

Epoch: 5| Step: 3
Training loss: 2.6587763721071016
Validation loss: 2.4927542150738087

Epoch: 5| Step: 4
Training loss: 2.18327785110837
Validation loss: 2.4857116358443534

Epoch: 5| Step: 5
Training loss: 2.5957826669645843
Validation loss: 2.488009056162988

Epoch: 5| Step: 6
Training loss: 2.554404800125472
Validation loss: 2.483651857675311

Epoch: 5| Step: 7
Training loss: 2.5889843281448024
Validation loss: 2.4847258733895874

Epoch: 5| Step: 8
Training loss: 3.235308821027667
Validation loss: 2.483132161455688

Epoch: 5| Step: 9
Training loss: 2.5196554936965656
Validation loss: 2.4848980822793196

Epoch: 5| Step: 10
Training loss: 2.544479179376598
Validation loss: 2.493136748340971

Epoch: 5| Step: 11
Training loss: 3.1068049405259677
Validation loss: 2.489048534608765

Epoch: 92| Step: 0
Training loss: 2.4966151210860863
Validation loss: 2.4869948434918134

Epoch: 5| Step: 1
Training loss: 2.6101906238383124
Validation loss: 2.482306140809969

Epoch: 5| Step: 2
Training loss: 2.406498388375861
Validation loss: 2.4830974917036692

Epoch: 5| Step: 3
Training loss: 3.1167458434086
Validation loss: 2.484533412849162

Epoch: 5| Step: 4
Training loss: 1.7867483973076266
Validation loss: 2.4985671825044915

Epoch: 5| Step: 5
Training loss: 2.9781553957369695
Validation loss: 2.500665862100679

Epoch: 5| Step: 6
Training loss: 2.3403329990511508
Validation loss: 2.4954135865541582

Epoch: 5| Step: 7
Training loss: 3.281222970033757
Validation loss: 2.492230326285555

Epoch: 5| Step: 8
Training loss: 1.9918320881075708
Validation loss: 2.477245156499542

Epoch: 5| Step: 9
Training loss: 2.9053532026865234
Validation loss: 2.49199874705252

Epoch: 5| Step: 10
Training loss: 2.381608102059286
Validation loss: 2.4905687534007077

Epoch: 5| Step: 11
Training loss: 2.231751081690115
Validation loss: 2.4927704706243854

Epoch: 93| Step: 0
Training loss: 2.5981956897008316
Validation loss: 2.4989186849201044

Epoch: 5| Step: 1
Training loss: 2.802321517256341
Validation loss: 2.495852542818133

Epoch: 5| Step: 2
Training loss: 2.65970736622016
Validation loss: 2.4952920472945705

Epoch: 5| Step: 3
Training loss: 2.847890501499788
Validation loss: 2.4950741519687916

Epoch: 5| Step: 4
Training loss: 2.381982877796301
Validation loss: 2.498953075543865

Epoch: 5| Step: 5
Training loss: 2.2421137036663543
Validation loss: 2.4995549759546845

Epoch: 5| Step: 6
Training loss: 2.6484341691707947
Validation loss: 2.5090180427786386

Epoch: 5| Step: 7
Training loss: 2.1220491902423246
Validation loss: 2.502585012393707

Epoch: 5| Step: 8
Training loss: 2.6468553346446084
Validation loss: 2.503972890267616

Epoch: 5| Step: 9
Training loss: 2.7389452424441014
Validation loss: 2.496701721191266

Epoch: 5| Step: 10
Training loss: 2.9100015688757583
Validation loss: 2.498002231607593

Epoch: 5| Step: 11
Training loss: 3.030533381434491
Validation loss: 2.4991613729873903

Epoch: 94| Step: 0
Training loss: 2.430802558579447
Validation loss: 2.5008240652903044

Epoch: 5| Step: 1
Training loss: 2.587113864853891
Validation loss: 2.4949879233960535

Epoch: 5| Step: 2
Training loss: 2.6368506730596977
Validation loss: 2.4950524726731733

Epoch: 5| Step: 3
Training loss: 2.7599352050860166
Validation loss: 2.4993682539959257

Epoch: 5| Step: 4
Training loss: 2.7922575785462076
Validation loss: 2.4911461132213435

Epoch: 5| Step: 5
Training loss: 2.2162661551517657
Validation loss: 2.4962026724533706

Epoch: 5| Step: 6
Training loss: 2.794108722365449
Validation loss: 2.496793673690411

Epoch: 5| Step: 7
Training loss: 2.837167184275675
Validation loss: 2.511771585671107

Epoch: 5| Step: 8
Training loss: 2.5366088279449595
Validation loss: 2.510466212394446

Epoch: 5| Step: 9
Training loss: 2.701669201748706
Validation loss: 2.5082029314035617

Epoch: 5| Step: 10
Training loss: 2.656031431293646
Validation loss: 2.506648874133031

Epoch: 5| Step: 11
Training loss: 2.1706222104472856
Validation loss: 2.4958575420022844

Epoch: 95| Step: 0
Training loss: 2.461636108057243
Validation loss: 2.491438225865628

Epoch: 5| Step: 1
Training loss: 2.423551508314224
Validation loss: 2.4825549266343656

Epoch: 5| Step: 2
Training loss: 2.887895935128014
Validation loss: 2.477002017614431

Epoch: 5| Step: 3
Training loss: 3.021271632175867
Validation loss: 2.491071879853525

Epoch: 5| Step: 4
Training loss: 2.3822042720784236
Validation loss: 2.490070316670005

Epoch: 5| Step: 5
Training loss: 2.2446752696531913
Validation loss: 2.491681692360914

Epoch: 5| Step: 6
Training loss: 2.770322269738748
Validation loss: 2.4897572657480436

Epoch: 5| Step: 7
Training loss: 2.6740582564234345
Validation loss: 2.483972052919376

Epoch: 5| Step: 8
Training loss: 2.170443275636649
Validation loss: 2.4837915587152093

Epoch: 5| Step: 9
Training loss: 2.7169382482256808
Validation loss: 2.487903783923836

Epoch: 5| Step: 10
Training loss: 2.707141163894118
Validation loss: 2.4823640125813364

Epoch: 5| Step: 11
Training loss: 2.731151140811339
Validation loss: 2.4879011086372667

Epoch: 96| Step: 0
Training loss: 2.643549636931821
Validation loss: 2.4878713868085596

Epoch: 5| Step: 1
Training loss: 2.870692799915947
Validation loss: 2.488882787586177

Epoch: 5| Step: 2
Training loss: 2.7858692342681652
Validation loss: 2.4829083598032566

Epoch: 5| Step: 3
Training loss: 2.5083315303284848
Validation loss: 2.4899722092199816

Epoch: 5| Step: 4
Training loss: 3.1978249966449823
Validation loss: 2.485744938324723

Epoch: 5| Step: 5
Training loss: 2.393305852337313
Validation loss: 2.4874872271211443

Epoch: 5| Step: 6
Training loss: 2.399265804841705
Validation loss: 2.494282546420477

Epoch: 5| Step: 7
Training loss: 2.0691572312892585
Validation loss: 2.4872111819758596

Epoch: 5| Step: 8
Training loss: 2.576833875625435
Validation loss: 2.4933214109330373

Epoch: 5| Step: 9
Training loss: 2.7050448088539523
Validation loss: 2.4908944046860713

Epoch: 5| Step: 10
Training loss: 2.3673122864115888
Validation loss: 2.491596650146688

Epoch: 5| Step: 11
Training loss: 2.576671953808623
Validation loss: 2.486716772221098

Epoch: 97| Step: 0
Training loss: 2.9615585762811834
Validation loss: 2.4833921571672906

Epoch: 5| Step: 1
Training loss: 2.3817790807840775
Validation loss: 2.478571176470025

Epoch: 5| Step: 2
Training loss: 2.294219993232962
Validation loss: 2.4719712974480204

Epoch: 5| Step: 3
Training loss: 2.5138465802851666
Validation loss: 2.4761124652267523

Epoch: 5| Step: 4
Training loss: 2.6490632614813254
Validation loss: 2.4690597114568162

Epoch: 5| Step: 5
Training loss: 2.1118484124200334
Validation loss: 2.4746293988179193

Epoch: 5| Step: 6
Training loss: 2.7404238689046276
Validation loss: 2.466368834669203

Epoch: 5| Step: 7
Training loss: 3.121704041894924
Validation loss: 2.471016623971509

Epoch: 5| Step: 8
Training loss: 2.5072772919628825
Validation loss: 2.4704457446747368

Epoch: 5| Step: 9
Training loss: 2.5992456148695253
Validation loss: 2.481750769732546

Epoch: 5| Step: 10
Training loss: 2.2014456767376642
Validation loss: 2.483851023665557

Epoch: 5| Step: 11
Training loss: 3.372302778965735
Validation loss: 2.4870167368236338

Epoch: 98| Step: 0
Training loss: 2.8729781629487325
Validation loss: 2.4781871725319187

Epoch: 5| Step: 1
Training loss: 2.1632415646611536
Validation loss: 2.4696531012085257

Epoch: 5| Step: 2
Training loss: 2.780167186704615
Validation loss: 2.473334146695076

Epoch: 5| Step: 3
Training loss: 2.983402433252234
Validation loss: 2.4744633624268615

Epoch: 5| Step: 4
Training loss: 2.208625366286903
Validation loss: 2.4832954140356036

Epoch: 5| Step: 5
Training loss: 2.0721595442187306
Validation loss: 2.4731854821066177

Epoch: 5| Step: 6
Training loss: 2.6907038554156846
Validation loss: 2.481796293871926

Epoch: 5| Step: 7
Training loss: 2.7860769325747006
Validation loss: 2.4818345162118987

Epoch: 5| Step: 8
Training loss: 2.6690575094190883
Validation loss: 2.4943826707827

Epoch: 5| Step: 9
Training loss: 2.3566806389566666
Validation loss: 2.490246901137818

Epoch: 5| Step: 10
Training loss: 2.6975927465296072
Validation loss: 2.494826550860333

Epoch: 5| Step: 11
Training loss: 3.231253919469939
Validation loss: 2.498448267808732

Epoch: 99| Step: 0
Training loss: 2.7968741475535537
Validation loss: 2.4932833925790097

Epoch: 5| Step: 1
Training loss: 2.876757540661692
Validation loss: 2.490808797170712

Epoch: 5| Step: 2
Training loss: 2.633468319857506
Validation loss: 2.4915171272691494

Epoch: 5| Step: 3
Training loss: 2.8531242378960853
Validation loss: 2.4871837445277993

Epoch: 5| Step: 4
Training loss: 2.5453165352861373
Validation loss: 2.4898034175386643

Epoch: 5| Step: 5
Training loss: 2.7492869059468745
Validation loss: 2.484333753743254

Epoch: 5| Step: 6
Training loss: 2.1150658594072493
Validation loss: 2.483959779089205

Epoch: 5| Step: 7
Training loss: 2.3381143588772533
Validation loss: 2.4882648413579735

Epoch: 5| Step: 8
Training loss: 2.640392406083889
Validation loss: 2.48426731444043

Epoch: 5| Step: 9
Training loss: 2.046861954276175
Validation loss: 2.4774339548604614

Epoch: 5| Step: 10
Training loss: 2.7272512008800027
Validation loss: 2.473028559725641

Epoch: 5| Step: 11
Training loss: 3.140294147733545
Validation loss: 2.479038484983512

Epoch: 100| Step: 0
Training loss: 2.7129984560272065
Validation loss: 2.4832663631583047

Epoch: 5| Step: 1
Training loss: 2.235784766140921
Validation loss: 2.484151110367394

Epoch: 5| Step: 2
Training loss: 2.045519547441095
Validation loss: 2.474315040705337

Epoch: 5| Step: 3
Training loss: 2.2667117965169807
Validation loss: 2.4962706087802933

Epoch: 5| Step: 4
Training loss: 2.725911409742332
Validation loss: 2.496736152299094

Epoch: 5| Step: 5
Training loss: 2.8068816122020914
Validation loss: 2.500783467711387

Epoch: 5| Step: 6
Training loss: 2.7917845876660046
Validation loss: 2.489426964407335

Epoch: 5| Step: 7
Training loss: 2.5044118100063177
Validation loss: 2.4760946840786917

Epoch: 5| Step: 8
Training loss: 2.854427038043736
Validation loss: 2.4843849605784483

Epoch: 5| Step: 9
Training loss: 2.8322337952893646
Validation loss: 2.4903169107160723

Epoch: 5| Step: 10
Training loss: 2.7772706957087263
Validation loss: 2.477985226127605

Epoch: 5| Step: 11
Training loss: 2.7759711069917548
Validation loss: 2.491441704780987

Epoch: 101| Step: 0
Training loss: 2.754761302043753
Validation loss: 2.491360745473475

Epoch: 5| Step: 1
Training loss: 2.480693656757472
Validation loss: 2.492622006764426

Epoch: 5| Step: 2
Training loss: 2.841530069627397
Validation loss: 2.492557119545933

Epoch: 5| Step: 3
Training loss: 2.640671769128634
Validation loss: 2.4948182466294893

Epoch: 5| Step: 4
Training loss: 2.5845647666108884
Validation loss: 2.489027381548652

Epoch: 5| Step: 5
Training loss: 2.3767731723043006
Validation loss: 2.4888953544529406

Epoch: 5| Step: 6
Training loss: 2.579969913543811
Validation loss: 2.489843404159626

Epoch: 5| Step: 7
Training loss: 2.620041569241687
Validation loss: 2.494127050973732

Epoch: 5| Step: 8
Training loss: 2.3034568475084876
Validation loss: 2.4919988586717587

Epoch: 5| Step: 9
Training loss: 2.888653221869711
Validation loss: 2.4852149870893725

Epoch: 5| Step: 10
Training loss: 2.620165778586422
Validation loss: 2.490795484169985

Epoch: 5| Step: 11
Training loss: 2.052796048037322
Validation loss: 2.47906300517685

Epoch: 102| Step: 0
Training loss: 2.7899541204365037
Validation loss: 2.4822208414180165

Epoch: 5| Step: 1
Training loss: 2.881455347517773
Validation loss: 2.4795820158083846

Epoch: 5| Step: 2
Training loss: 2.051278074120065
Validation loss: 2.472822134551237

Epoch: 5| Step: 3
Training loss: 2.749273724452131
Validation loss: 2.471050333547599

Epoch: 5| Step: 4
Training loss: 2.7560969303730625
Validation loss: 2.460282411123626

Epoch: 5| Step: 5
Training loss: 2.625578771092048
Validation loss: 2.473055710347698

Epoch: 5| Step: 6
Training loss: 2.505894578194367
Validation loss: 2.466585687379886

Epoch: 5| Step: 7
Training loss: 2.248551008104411
Validation loss: 2.47287392524434

Epoch: 5| Step: 8
Training loss: 2.9169119232240592
Validation loss: 2.480566051907585

Epoch: 5| Step: 9
Training loss: 2.398203487349612
Validation loss: 2.4737311302391896

Epoch: 5| Step: 10
Training loss: 2.544860136464529
Validation loss: 2.4814777955130136

Epoch: 5| Step: 11
Training loss: 2.105556054508057
Validation loss: 2.478627271770424

Epoch: 103| Step: 0
Training loss: 2.731315514239242
Validation loss: 2.479293220292543

Epoch: 5| Step: 1
Training loss: 2.7391856573328752
Validation loss: 2.4834001015854956

Epoch: 5| Step: 2
Training loss: 2.8308411090314696
Validation loss: 2.478187569385139

Epoch: 5| Step: 3
Training loss: 3.0906955012813255
Validation loss: 2.4807372180702076

Epoch: 5| Step: 4
Training loss: 2.359664191907776
Validation loss: 2.483786675230887

Epoch: 5| Step: 5
Training loss: 2.5212033423218685
Validation loss: 2.4914939935894926

Epoch: 5| Step: 6
Training loss: 2.407189619233507
Validation loss: 2.480156634060413

Epoch: 5| Step: 7
Training loss: 2.883681747759846
Validation loss: 2.485217881120534

Epoch: 5| Step: 8
Training loss: 2.095637367546524
Validation loss: 2.4802734017731978

Epoch: 5| Step: 9
Training loss: 2.4105910738989977
Validation loss: 2.478021362497913

Epoch: 5| Step: 10
Training loss: 2.387089227620396
Validation loss: 2.4772135643911004

Epoch: 5| Step: 11
Training loss: 1.7117861380603139
Validation loss: 2.4780878249431066

Epoch: 104| Step: 0
Training loss: 2.5453228111362662
Validation loss: 2.455305968490315

Epoch: 5| Step: 1
Training loss: 2.5669098103115506
Validation loss: 2.468716375709467

Epoch: 5| Step: 2
Training loss: 2.188760666660567
Validation loss: 2.4714120162019038

Epoch: 5| Step: 3
Training loss: 2.809586944902107
Validation loss: 2.47235397652735

Epoch: 5| Step: 4
Training loss: 2.2170771350235072
Validation loss: 2.4612391130611195

Epoch: 5| Step: 5
Training loss: 3.0287630556512393
Validation loss: 2.4704978445463563

Epoch: 5| Step: 6
Training loss: 2.459402810779264
Validation loss: 2.466121034319594

Epoch: 5| Step: 7
Training loss: 2.654664946713442
Validation loss: 2.469336854419127

Epoch: 5| Step: 8
Training loss: 2.59461409181817
Validation loss: 2.477296325396477

Epoch: 5| Step: 9
Training loss: 2.5132379994748595
Validation loss: 2.4791475036158297

Epoch: 5| Step: 10
Training loss: 2.524023029433922
Validation loss: 2.474070810806188

Epoch: 5| Step: 11
Training loss: 3.102379371824734
Validation loss: 2.4764932087251186

Epoch: 105| Step: 0
Training loss: 2.6102478942950285
Validation loss: 2.467529079474612

Epoch: 5| Step: 1
Training loss: 2.572828643981702
Validation loss: 2.474128309065825

Epoch: 5| Step: 2
Training loss: 2.6633913867274637
Validation loss: 2.4699665082238744

Epoch: 5| Step: 3
Training loss: 2.0853262587953325
Validation loss: 2.4656483364249864

Epoch: 5| Step: 4
Training loss: 2.753037855520596
Validation loss: 2.477517698900304

Epoch: 5| Step: 5
Training loss: 2.029884818619414
Validation loss: 2.471572107982976

Epoch: 5| Step: 6
Training loss: 2.4005906570309965
Validation loss: 2.4749162740064112

Epoch: 5| Step: 7
Training loss: 3.0246633168903267
Validation loss: 2.4782711677048757

Epoch: 5| Step: 8
Training loss: 2.7673738629025926
Validation loss: 2.469482896559313

Epoch: 5| Step: 9
Training loss: 2.3285550737935004
Validation loss: 2.4762279292526683

Epoch: 5| Step: 10
Training loss: 2.6397658536131297
Validation loss: 2.4821225397781985

Epoch: 5| Step: 11
Training loss: 3.6296998173623334
Validation loss: 2.4773266172062236

Epoch: 106| Step: 0
Training loss: 2.585981201540189
Validation loss: 2.4760747603752673

Epoch: 5| Step: 1
Training loss: 2.524781804996582
Validation loss: 2.472088295068803

Epoch: 5| Step: 2
Training loss: 2.155381179695405
Validation loss: 2.4666257120826485

Epoch: 5| Step: 3
Training loss: 2.2100009619594223
Validation loss: 2.4800673112399685

Epoch: 5| Step: 4
Training loss: 2.6765528547889277
Validation loss: 2.4739592113827937

Epoch: 5| Step: 5
Training loss: 2.6009606934026297
Validation loss: 2.476054840523597

Epoch: 5| Step: 6
Training loss: 2.3061324423004557
Validation loss: 2.4698160421025874

Epoch: 5| Step: 7
Training loss: 2.3658080661343033
Validation loss: 2.4660999383788123

Epoch: 5| Step: 8
Training loss: 3.149070657150002
Validation loss: 2.4634002351924433

Epoch: 5| Step: 9
Training loss: 2.850711894217479
Validation loss: 2.4625681364247103

Epoch: 5| Step: 10
Training loss: 2.482029989720722
Validation loss: 2.4524097290755833

Epoch: 5| Step: 11
Training loss: 2.934637744909524
Validation loss: 2.4723510835105627

Epoch: 107| Step: 0
Training loss: 2.9127087759738792
Validation loss: 2.5057414446598463

Epoch: 5| Step: 1
Training loss: 2.650322077630064
Validation loss: 2.5831647280820675

Epoch: 5| Step: 2
Training loss: 2.6365069721085606
Validation loss: 2.515075629530527

Epoch: 5| Step: 3
Training loss: 2.5974690075843694
Validation loss: 2.486694456783371

Epoch: 5| Step: 4
Training loss: 2.5529501137198296
Validation loss: 2.4741405152283265

Epoch: 5| Step: 5
Training loss: 2.34092450536651
Validation loss: 2.4750972548877246

Epoch: 5| Step: 6
Training loss: 2.4624239837222084
Validation loss: 2.466465416046455

Epoch: 5| Step: 7
Training loss: 1.9317034488409228
Validation loss: 2.465644617651321

Epoch: 5| Step: 8
Training loss: 2.7998111593053907
Validation loss: 2.472021333757232

Epoch: 5| Step: 9
Training loss: 2.709700508319618
Validation loss: 2.4690994828163064

Epoch: 5| Step: 10
Training loss: 2.7796704382370114
Validation loss: 2.4764266834262054

Epoch: 5| Step: 11
Training loss: 3.1635270030553015
Validation loss: 2.482358281891464

Epoch: 108| Step: 0
Training loss: 2.2340180438686725
Validation loss: 2.4888008649077387

Epoch: 5| Step: 1
Training loss: 2.6223862668986433
Validation loss: 2.491541233594771

Epoch: 5| Step: 2
Training loss: 2.642390456658412
Validation loss: 2.4950484115169576

Epoch: 5| Step: 3
Training loss: 2.4176335757256164
Validation loss: 2.503370278255577

Epoch: 5| Step: 4
Training loss: 2.8284206341240723
Validation loss: 2.506371869638431

Epoch: 5| Step: 5
Training loss: 2.8563476545806052
Validation loss: 2.5042242799395056

Epoch: 5| Step: 6
Training loss: 2.497403035768393
Validation loss: 2.5098710687358516

Epoch: 5| Step: 7
Training loss: 2.6124587425369072
Validation loss: 2.5121949863175983

Epoch: 5| Step: 8
Training loss: 2.6374813531153176
Validation loss: 2.511930449855265

Epoch: 5| Step: 9
Training loss: 2.6072360654768194
Validation loss: 2.50602125010217

Epoch: 5| Step: 10
Training loss: 2.7415920382684353
Validation loss: 2.5064913992552533

Epoch: 5| Step: 11
Training loss: 2.6313114584951105
Validation loss: 2.504263695145148

Epoch: 109| Step: 0
Training loss: 3.065105342081515
Validation loss: 2.498448514327597

Epoch: 5| Step: 1
Training loss: 2.4080538243206266
Validation loss: 2.495422639209604

Epoch: 5| Step: 2
Training loss: 2.2205974785226372
Validation loss: 2.4926798701836566

Epoch: 5| Step: 3
Training loss: 2.3349139672711936
Validation loss: 2.482834054186348

Epoch: 5| Step: 4
Training loss: 2.3730259772742395
Validation loss: 2.4837379198527705

Epoch: 5| Step: 5
Training loss: 2.469314993416726
Validation loss: 2.4733483007448136

Epoch: 5| Step: 6
Training loss: 2.7941982310812588
Validation loss: 2.4665265955869855

Epoch: 5| Step: 7
Training loss: 2.6078853352445246
Validation loss: 2.4615742318861464

Epoch: 5| Step: 8
Training loss: 2.7489733079909806
Validation loss: 2.4674713589939485

Epoch: 5| Step: 9
Training loss: 2.436165370890275
Validation loss: 2.4696262832501565

Epoch: 5| Step: 10
Training loss: 2.8728460453049713
Validation loss: 2.467305134825047

Epoch: 5| Step: 11
Training loss: 2.8340001910955976
Validation loss: 2.462133458091497

Epoch: 110| Step: 0
Training loss: 2.7671175447621956
Validation loss: 2.4655267703139185

Epoch: 5| Step: 1
Training loss: 2.3933485884786823
Validation loss: 2.4582106039694325

Epoch: 5| Step: 2
Training loss: 2.4421167911341395
Validation loss: 2.4626818292876815

Epoch: 5| Step: 3
Training loss: 2.57830865379248
Validation loss: 2.463848086220202

Epoch: 5| Step: 4
Training loss: 3.042144702988485
Validation loss: 2.4655381346543352

Epoch: 5| Step: 5
Training loss: 2.0552611039881055
Validation loss: 2.4738155778889657

Epoch: 5| Step: 6
Training loss: 3.0619676088280565
Validation loss: 2.4636429422434776

Epoch: 5| Step: 7
Training loss: 2.3642083989698888
Validation loss: 2.4686562001238843

Epoch: 5| Step: 8
Training loss: 2.347324239957892
Validation loss: 2.474879542383224

Epoch: 5| Step: 9
Training loss: 2.560682256801943
Validation loss: 2.464603756980939

Epoch: 5| Step: 10
Training loss: 2.5070247185260333
Validation loss: 2.465562122286181

Epoch: 5| Step: 11
Training loss: 2.157665064786311
Validation loss: 2.475645097957378

Epoch: 111| Step: 0
Training loss: 3.1230728310561466
Validation loss: 2.465805929916285

Epoch: 5| Step: 1
Training loss: 2.6489525578283746
Validation loss: 2.453499787649028

Epoch: 5| Step: 2
Training loss: 2.490024883957888
Validation loss: 2.468091591223882

Epoch: 5| Step: 3
Training loss: 2.493322610203061
Validation loss: 2.4648288659856985

Epoch: 5| Step: 4
Training loss: 2.2531783649193478
Validation loss: 2.496983846520771

Epoch: 5| Step: 5
Training loss: 2.31969374295977
Validation loss: 2.5270224970900648

Epoch: 5| Step: 6
Training loss: 2.996547142448539
Validation loss: 2.5216556237788508

Epoch: 5| Step: 7
Training loss: 2.161343074314602
Validation loss: 2.4830009171293064

Epoch: 5| Step: 8
Training loss: 2.668607263969182
Validation loss: 2.4676953449178516

Epoch: 5| Step: 9
Training loss: 2.609587243865111
Validation loss: 2.472244401152441

Epoch: 5| Step: 10
Training loss: 2.665709224322889
Validation loss: 2.4662811956480515

Epoch: 5| Step: 11
Training loss: 3.36603740690846
Validation loss: 2.472131015461974

Epoch: 112| Step: 0
Training loss: 2.678835363554337
Validation loss: 2.4710500682146277

Epoch: 5| Step: 1
Training loss: 2.218691435564842
Validation loss: 2.4780813427383133

Epoch: 5| Step: 2
Training loss: 2.573013880407949
Validation loss: 2.480533012298617

Epoch: 5| Step: 3
Training loss: 2.901846061330557
Validation loss: 2.4806987145222226

Epoch: 5| Step: 4
Training loss: 2.7402311557525194
Validation loss: 2.4788012769585825

Epoch: 5| Step: 5
Training loss: 1.5721999634483963
Validation loss: 2.484531149765335

Epoch: 5| Step: 6
Training loss: 2.7176730774454056
Validation loss: 2.484472634738192

Epoch: 5| Step: 7
Training loss: 3.1114341780026407
Validation loss: 2.480826941231961

Epoch: 5| Step: 8
Training loss: 2.4033987814483133
Validation loss: 2.481135709710343

Epoch: 5| Step: 9
Training loss: 2.7397589294861726
Validation loss: 2.477265331447104

Epoch: 5| Step: 10
Training loss: 2.620275878650341
Validation loss: 2.4808036678216157

Epoch: 5| Step: 11
Training loss: 2.4441199761643744
Validation loss: 2.4711180287062016

Epoch: 113| Step: 0
Training loss: 2.575753710908761
Validation loss: 2.475186696861947

Epoch: 5| Step: 1
Training loss: 2.4933449858462877
Validation loss: 2.4760256244512595

Epoch: 5| Step: 2
Training loss: 2.716997392879916
Validation loss: 2.4739960811479103

Epoch: 5| Step: 3
Training loss: 2.536146161701968
Validation loss: 2.4914541770015113

Epoch: 5| Step: 4
Training loss: 2.6095550840447532
Validation loss: 2.492304732416446

Epoch: 5| Step: 5
Training loss: 2.5537687276862124
Validation loss: 2.486703605098389

Epoch: 5| Step: 6
Training loss: 2.855689169416766
Validation loss: 2.49133134204772

Epoch: 5| Step: 7
Training loss: 2.5566891169484522
Validation loss: 2.4800822199630796

Epoch: 5| Step: 8
Training loss: 2.5201120106462755
Validation loss: 2.4821695699263904

Epoch: 5| Step: 9
Training loss: 2.379249886183572
Validation loss: 2.476453315421917

Epoch: 5| Step: 10
Training loss: 2.8914600712596683
Validation loss: 2.4782685301217593

Epoch: 5| Step: 11
Training loss: 2.4692282877337566
Validation loss: 2.475692134788926

Epoch: 114| Step: 0
Training loss: 2.5950213154705652
Validation loss: 2.4817218889104797

Epoch: 5| Step: 1
Training loss: 2.7874836874172355
Validation loss: 2.480610824881494

Epoch: 5| Step: 2
Training loss: 2.927529967274383
Validation loss: 2.472891478475848

Epoch: 5| Step: 3
Training loss: 2.0636253754610068
Validation loss: 2.478239063557822

Epoch: 5| Step: 4
Training loss: 2.7012211263473587
Validation loss: 2.4627934355268755

Epoch: 5| Step: 5
Training loss: 2.3946176734251092
Validation loss: 2.4646909881021535

Epoch: 5| Step: 6
Training loss: 2.5605719221040877
Validation loss: 2.466175720989761

Epoch: 5| Step: 7
Training loss: 2.979755441244134
Validation loss: 2.466749555788831

Epoch: 5| Step: 8
Training loss: 2.0878525990091372
Validation loss: 2.462517657918601

Epoch: 5| Step: 9
Training loss: 2.404884347177036
Validation loss: 2.469453811919767

Epoch: 5| Step: 10
Training loss: 2.4679497496189597
Validation loss: 2.46442668548105

Epoch: 5| Step: 11
Training loss: 3.1933326463426503
Validation loss: 2.461786719033281

Epoch: 115| Step: 0
Training loss: 2.646890283966074
Validation loss: 2.4617228773593554

Epoch: 5| Step: 1
Training loss: 2.565943474465884
Validation loss: 2.460054741827989

Epoch: 5| Step: 2
Training loss: 2.839621764772163
Validation loss: 2.467980836406181

Epoch: 5| Step: 3
Training loss: 2.291657210821815
Validation loss: 2.4674462968456954

Epoch: 5| Step: 4
Training loss: 2.646886500814374
Validation loss: 2.468886822317317

Epoch: 5| Step: 5
Training loss: 2.506953107044567
Validation loss: 2.476492057464338

Epoch: 5| Step: 6
Training loss: 2.8558703347591816
Validation loss: 2.476471428946576

Epoch: 5| Step: 7
Training loss: 2.6873015397005786
Validation loss: 2.4654737373757882

Epoch: 5| Step: 8
Training loss: 2.315813628839611
Validation loss: 2.4628007889047945

Epoch: 5| Step: 9
Training loss: 2.671768097105262
Validation loss: 2.4749443230965165

Epoch: 5| Step: 10
Training loss: 2.434212252424993
Validation loss: 2.4699771985714585

Epoch: 5| Step: 11
Training loss: 1.4102126768029044
Validation loss: 2.471208004637262

Epoch: 116| Step: 0
Training loss: 2.2966489096713136
Validation loss: 2.480558795245728

Epoch: 5| Step: 1
Training loss: 2.693861241710011
Validation loss: 2.4776155417144246

Epoch: 5| Step: 2
Training loss: 2.8737196351812013
Validation loss: 2.4709259736854565

Epoch: 5| Step: 3
Training loss: 2.6896890108802998
Validation loss: 2.468316708136787

Epoch: 5| Step: 4
Training loss: 2.3029221837508147
Validation loss: 2.465617171880675

Epoch: 5| Step: 5
Training loss: 2.648496013883933
Validation loss: 2.473812405481937

Epoch: 5| Step: 6
Training loss: 2.008728768237081
Validation loss: 2.4682871106932973

Epoch: 5| Step: 7
Training loss: 2.1917387086271325
Validation loss: 2.470841897678382

Epoch: 5| Step: 8
Training loss: 3.0766639921342738
Validation loss: 2.4651533920775406

Epoch: 5| Step: 9
Training loss: 2.609136696172971
Validation loss: 2.4591939148566953

Epoch: 5| Step: 10
Training loss: 2.729796407325198
Validation loss: 2.45869163687627

Epoch: 5| Step: 11
Training loss: 1.9730004340827259
Validation loss: 2.4661418662329684

Epoch: 117| Step: 0
Training loss: 2.703753447933882
Validation loss: 2.4482062324081957

Epoch: 5| Step: 1
Training loss: 2.469876382491156
Validation loss: 2.4639091553643606

Epoch: 5| Step: 2
Training loss: 2.4486925451169803
Validation loss: 2.4532685207490794

Epoch: 5| Step: 3
Training loss: 2.8392457607916475
Validation loss: 2.448067345276696

Epoch: 5| Step: 4
Training loss: 2.0580231601461034
Validation loss: 2.4617433066330214

Epoch: 5| Step: 5
Training loss: 2.8000987989161037
Validation loss: 2.4483625222390617

Epoch: 5| Step: 6
Training loss: 2.568595243001393
Validation loss: 2.455919419514247

Epoch: 5| Step: 7
Training loss: 2.45108102576909
Validation loss: 2.4488065414301046

Epoch: 5| Step: 8
Training loss: 2.671804059073986
Validation loss: 2.4629814338934257

Epoch: 5| Step: 9
Training loss: 2.2883493399656425
Validation loss: 2.44843581085374

Epoch: 5| Step: 10
Training loss: 2.8021039619300985
Validation loss: 2.464302908458644

Epoch: 5| Step: 11
Training loss: 1.8309727195195
Validation loss: 2.4707479882470613

Epoch: 118| Step: 0
Training loss: 2.6932023343562097
Validation loss: 2.473825669328828

Epoch: 5| Step: 1
Training loss: 2.205545380977519
Validation loss: 2.4606610864485403

Epoch: 5| Step: 2
Training loss: 2.6726934060750773
Validation loss: 2.4594185314340935

Epoch: 5| Step: 3
Training loss: 2.5212729414887627
Validation loss: 2.4656435660794185

Epoch: 5| Step: 4
Training loss: 2.285968029890007
Validation loss: 2.4592748808203715

Epoch: 5| Step: 5
Training loss: 2.9610616612634395
Validation loss: 2.445998655176664

Epoch: 5| Step: 6
Training loss: 2.2921220038066195
Validation loss: 2.462408022042245

Epoch: 5| Step: 7
Training loss: 2.526897786103988
Validation loss: 2.462317008434007

Epoch: 5| Step: 8
Training loss: 2.707026582083593
Validation loss: 2.46069623985643

Epoch: 5| Step: 9
Training loss: 2.413921858261565
Validation loss: 2.458878773185903

Epoch: 5| Step: 10
Training loss: 2.746662542222763
Validation loss: 2.4602506294612767

Epoch: 5| Step: 11
Training loss: 1.9474595565416075
Validation loss: 2.4575462266591415

Epoch: 119| Step: 0
Training loss: 2.593320236450832
Validation loss: 2.4633990334531957

Epoch: 5| Step: 1
Training loss: 2.4852373078170564
Validation loss: 2.4618083321346904

Epoch: 5| Step: 2
Training loss: 2.417549848861139
Validation loss: 2.460960343673687

Epoch: 5| Step: 3
Training loss: 2.563519809903052
Validation loss: 2.4568111561667347

Epoch: 5| Step: 4
Training loss: 2.1940372333340434
Validation loss: 2.4764127314997

Epoch: 5| Step: 5
Training loss: 1.8425206110511865
Validation loss: 2.4648623115658816

Epoch: 5| Step: 6
Training loss: 2.5531406210674774
Validation loss: 2.4662263179698334

Epoch: 5| Step: 7
Training loss: 2.9147486965413085
Validation loss: 2.4635539844250696

Epoch: 5| Step: 8
Training loss: 2.6375030481402244
Validation loss: 2.4670652282321957

Epoch: 5| Step: 9
Training loss: 2.51228651212037
Validation loss: 2.4521050327176

Epoch: 5| Step: 10
Training loss: 2.96731838040115
Validation loss: 2.4656662734863675

Epoch: 5| Step: 11
Training loss: 3.131374419095148
Validation loss: 2.4731728615225523

Epoch: 120| Step: 0
Training loss: 2.4899039494323234
Validation loss: 2.4599913216259472

Epoch: 5| Step: 1
Training loss: 2.4531697068726763
Validation loss: 2.4556345929853047

Epoch: 5| Step: 2
Training loss: 2.304443139521688
Validation loss: 2.463187086679115

Epoch: 5| Step: 3
Training loss: 2.7538499758767236
Validation loss: 2.4576822013939172

Epoch: 5| Step: 4
Training loss: 2.7380878635962715
Validation loss: 2.457905596089354

Epoch: 5| Step: 5
Training loss: 2.3740522601795693
Validation loss: 2.4642521248444145

Epoch: 5| Step: 6
Training loss: 2.384259494368601
Validation loss: 2.471017110421852

Epoch: 5| Step: 7
Training loss: 2.9236523123702534
Validation loss: 2.4750304271613

Epoch: 5| Step: 8
Training loss: 2.22861030504531
Validation loss: 2.4667435310819945

Epoch: 5| Step: 9
Training loss: 2.6810549258247782
Validation loss: 2.4675113653045564

Epoch: 5| Step: 10
Training loss: 2.4517603680692988
Validation loss: 2.4668941282309236

Epoch: 5| Step: 11
Training loss: 3.1927905588104584
Validation loss: 2.4645947281699536

Epoch: 121| Step: 0
Training loss: 2.7156464851328415
Validation loss: 2.4720206144246473

Epoch: 5| Step: 1
Training loss: 2.5643955755930747
Validation loss: 2.4676421653493588

Epoch: 5| Step: 2
Training loss: 2.6640364570127812
Validation loss: 2.465525435640117

Epoch: 5| Step: 3
Training loss: 2.3346857397751677
Validation loss: 2.4632614344654713

Epoch: 5| Step: 4
Training loss: 2.3568662732998886
Validation loss: 2.4571293061809225

Epoch: 5| Step: 5
Training loss: 2.515446626961753
Validation loss: 2.4631253845800476

Epoch: 5| Step: 6
Training loss: 2.6283673078348504
Validation loss: 2.457701865954059

Epoch: 5| Step: 7
Training loss: 2.4631966046115705
Validation loss: 2.455052276774687

Epoch: 5| Step: 8
Training loss: 2.895324021886225
Validation loss: 2.4615151872713295

Epoch: 5| Step: 9
Training loss: 2.1921539934878096
Validation loss: 2.456045408844406

Epoch: 5| Step: 10
Training loss: 2.576655576006802
Validation loss: 2.4725899027058227

Epoch: 5| Step: 11
Training loss: 2.2856993461869974
Validation loss: 2.470239075517159

Epoch: 122| Step: 0
Training loss: 2.595920803337364
Validation loss: 2.468245394357491

Epoch: 5| Step: 1
Training loss: 1.973241919266691
Validation loss: 2.469934975853135

Epoch: 5| Step: 2
Training loss: 2.872884220625187
Validation loss: 2.464438897369588

Epoch: 5| Step: 3
Training loss: 2.647406183152897
Validation loss: 2.4700938361859768

Epoch: 5| Step: 4
Training loss: 2.506831372341967
Validation loss: 2.475910861168802

Epoch: 5| Step: 5
Training loss: 2.7184505955492173
Validation loss: 2.4878193233393064

Epoch: 5| Step: 6
Training loss: 3.2672445123515335
Validation loss: 2.480657705484025

Epoch: 5| Step: 7
Training loss: 2.7295931611466235
Validation loss: 2.4870104376672684

Epoch: 5| Step: 8
Training loss: 2.462058741348307
Validation loss: 2.485759828981029

Epoch: 5| Step: 9
Training loss: 2.3776407117148515
Validation loss: 2.4793194889335295

Epoch: 5| Step: 10
Training loss: 2.0794095536466295
Validation loss: 2.483717089535609

Epoch: 5| Step: 11
Training loss: 2.216503564192791
Validation loss: 2.4802290392613098

Epoch: 123| Step: 0
Training loss: 2.6501040096384623
Validation loss: 2.4812642501434663

Epoch: 5| Step: 1
Training loss: 2.6666339534501384
Validation loss: 2.4766336906140847

Epoch: 5| Step: 2
Training loss: 2.355636666608843
Validation loss: 2.4768595271686484

Epoch: 5| Step: 3
Training loss: 2.521927892799132
Validation loss: 2.4656981525439696

Epoch: 5| Step: 4
Training loss: 2.1797429559687673
Validation loss: 2.469106946161393

Epoch: 5| Step: 5
Training loss: 2.6714373670743568
Validation loss: 2.4654663758528668

Epoch: 5| Step: 6
Training loss: 2.6609740491631677
Validation loss: 2.4591288464812684

Epoch: 5| Step: 7
Training loss: 2.809263274248779
Validation loss: 2.4660460234722756

Epoch: 5| Step: 8
Training loss: 2.5160004708755124
Validation loss: 2.4595998569958626

Epoch: 5| Step: 9
Training loss: 2.742176371060038
Validation loss: 2.4594010819858068

Epoch: 5| Step: 10
Training loss: 2.3770943492352203
Validation loss: 2.4739045602408845

Epoch: 5| Step: 11
Training loss: 1.973255391299979
Validation loss: 2.4658002735494535

Epoch: 124| Step: 0
Training loss: 2.382921560324362
Validation loss: 2.462880734800184

Epoch: 5| Step: 1
Training loss: 2.5224972322446915
Validation loss: 2.476125094899668

Epoch: 5| Step: 2
Training loss: 2.9670755583190687
Validation loss: 2.4780973978898606

Epoch: 5| Step: 3
Training loss: 2.457188927180538
Validation loss: 2.473214360186789

Epoch: 5| Step: 4
Training loss: 2.0306908644881125
Validation loss: 2.4715203703989364

Epoch: 5| Step: 5
Training loss: 2.3006210400900406
Validation loss: 2.467042594102559

Epoch: 5| Step: 6
Training loss: 2.4729879196001505
Validation loss: 2.466406973870016

Epoch: 5| Step: 7
Training loss: 2.7751602195332055
Validation loss: 2.4682875413358274

Epoch: 5| Step: 8
Training loss: 2.348548757591519
Validation loss: 2.4718974286463244

Epoch: 5| Step: 9
Training loss: 2.711343256681861
Validation loss: 2.4810603440042147

Epoch: 5| Step: 10
Training loss: 2.6932616461602343
Validation loss: 2.479891059466996

Epoch: 5| Step: 11
Training loss: 3.0229655841328333
Validation loss: 2.488645358271936

Epoch: 125| Step: 0
Training loss: 2.0900741877918194
Validation loss: 2.4839495708476647

Epoch: 5| Step: 1
Training loss: 2.431627290375084
Validation loss: 2.485497333121405

Epoch: 5| Step: 2
Training loss: 2.477632020883691
Validation loss: 2.478564106352078

Epoch: 5| Step: 3
Training loss: 2.6620776705627667
Validation loss: 2.4832011054559207

Epoch: 5| Step: 4
Training loss: 3.3367884531066894
Validation loss: 2.4783736544751465

Epoch: 5| Step: 5
Training loss: 2.1808424866828853
Validation loss: 2.475730573754063

Epoch: 5| Step: 6
Training loss: 2.7103302465135157
Validation loss: 2.4692776876559765

Epoch: 5| Step: 7
Training loss: 2.3166540827054902
Validation loss: 2.4753555742434643

Epoch: 5| Step: 8
Training loss: 2.630292371156422
Validation loss: 2.468113124964065

Epoch: 5| Step: 9
Training loss: 2.2570296781698835
Validation loss: 2.465519376715623

Epoch: 5| Step: 10
Training loss: 2.486121757195645
Validation loss: 2.4669597951488775

Epoch: 5| Step: 11
Training loss: 2.9258751236609215
Validation loss: 2.454912919075291

Epoch: 126| Step: 0
Training loss: 2.597446978177487
Validation loss: 2.451974359995387

Epoch: 5| Step: 1
Training loss: 2.483368003739738
Validation loss: 2.4685617890220484

Epoch: 5| Step: 2
Training loss: 2.919987522777916
Validation loss: 2.463756391967605

Epoch: 5| Step: 3
Training loss: 2.9310592491697527
Validation loss: 2.458634787735119

Epoch: 5| Step: 4
Training loss: 2.515058560305819
Validation loss: 2.4668699703224877

Epoch: 5| Step: 5
Training loss: 2.6681381774991557
Validation loss: 2.4601512036272295

Epoch: 5| Step: 6
Training loss: 2.3022667537017067
Validation loss: 2.465487831790201

Epoch: 5| Step: 7
Training loss: 2.208617593955678
Validation loss: 2.473987767228491

Epoch: 5| Step: 8
Training loss: 2.6675557700765142
Validation loss: 2.4756203954381446

Epoch: 5| Step: 9
Training loss: 2.6341287735415224
Validation loss: 2.4838953254880045

Epoch: 5| Step: 10
Training loss: 2.2828775113331177
Validation loss: 2.477154641906994

Epoch: 5| Step: 11
Training loss: 0.9304336630918347
Validation loss: 2.485685436753627

Epoch: 127| Step: 0
Training loss: 2.8147828903627987
Validation loss: 2.4739633272354853

Epoch: 5| Step: 1
Training loss: 2.8849991772946355
Validation loss: 2.4721961133152113

Epoch: 5| Step: 2
Training loss: 2.7983037613136776
Validation loss: 2.471350077286376

Epoch: 5| Step: 3
Training loss: 1.904079327016705
Validation loss: 2.4784825139681024

Epoch: 5| Step: 4
Training loss: 2.2460036284569416
Validation loss: 2.468266053389338

Epoch: 5| Step: 5
Training loss: 2.4595898041232647
Validation loss: 2.467536362377184

Epoch: 5| Step: 6
Training loss: 2.9434411860830814
Validation loss: 2.475536366505001

Epoch: 5| Step: 7
Training loss: 2.717685359469291
Validation loss: 2.462381264362306

Epoch: 5| Step: 8
Training loss: 2.465648682919322
Validation loss: 2.4750594904200827

Epoch: 5| Step: 9
Training loss: 2.4425591028065474
Validation loss: 2.477334751500573

Epoch: 5| Step: 10
Training loss: 2.2360546494563196
Validation loss: 2.464708811214495

Epoch: 5| Step: 11
Training loss: 3.0004491469808587
Validation loss: 2.4703212598741455

Epoch: 128| Step: 0
Training loss: 2.7908705719720346
Validation loss: 2.464274554822992

Epoch: 5| Step: 1
Training loss: 2.4956364697833586
Validation loss: 2.4763512947524684

Epoch: 5| Step: 2
Training loss: 2.7321854026181653
Validation loss: 2.471770712046674

Epoch: 5| Step: 3
Training loss: 2.6330969229540653
Validation loss: 2.4754730901134523

Epoch: 5| Step: 4
Training loss: 2.7495056054723594
Validation loss: 2.4768284555586555

Epoch: 5| Step: 5
Training loss: 2.4230042808831813
Validation loss: 2.4787317236404336

Epoch: 5| Step: 6
Training loss: 2.932583692158031
Validation loss: 2.4698853035087076

Epoch: 5| Step: 7
Training loss: 2.2136492056061994
Validation loss: 2.4729139927884702

Epoch: 5| Step: 8
Training loss: 1.7300629495182116
Validation loss: 2.463257171677719

Epoch: 5| Step: 9
Training loss: 2.806314660497708
Validation loss: 2.4552953012530927

Epoch: 5| Step: 10
Training loss: 2.2014845564224945
Validation loss: 2.4612831801384494

Epoch: 5| Step: 11
Training loss: 2.3430433098001244
Validation loss: 2.4649844283127305

Epoch: 129| Step: 0
Training loss: 2.042232811212789
Validation loss: 2.456328594286623

Epoch: 5| Step: 1
Training loss: 2.3357490795272096
Validation loss: 2.4876290888493857

Epoch: 5| Step: 2
Training loss: 2.6199546646971505
Validation loss: 2.4925282762543945

Epoch: 5| Step: 3
Training loss: 2.584479159893456
Validation loss: 2.485472910378691

Epoch: 5| Step: 4
Training loss: 2.4376976715533716
Validation loss: 2.467404083157853

Epoch: 5| Step: 5
Training loss: 2.6488246578480203
Validation loss: 2.465081950515482

Epoch: 5| Step: 6
Training loss: 2.616375333114121
Validation loss: 2.452881900218491

Epoch: 5| Step: 7
Training loss: 2.2568043500669703
Validation loss: 2.4557298166079318

Epoch: 5| Step: 8
Training loss: 2.728727164563938
Validation loss: 2.4787285555214744

Epoch: 5| Step: 9
Training loss: 2.7010626891514975
Validation loss: 2.4837354200639483

Epoch: 5| Step: 10
Training loss: 3.0982205236567664
Validation loss: 2.475674727814501

Epoch: 5| Step: 11
Training loss: 1.585785506157534
Validation loss: 2.4736848070955393

Epoch: 130| Step: 0
Training loss: 2.270941448846032
Validation loss: 2.481061449101499

Epoch: 5| Step: 1
Training loss: 2.524823071163588
Validation loss: 2.4740688272529963

Epoch: 5| Step: 2
Training loss: 2.7393448487732406
Validation loss: 2.4779707718328248

Epoch: 5| Step: 3
Training loss: 2.3232610700945546
Validation loss: 2.4757512646206776

Epoch: 5| Step: 4
Training loss: 2.638231897273764
Validation loss: 2.4602312113943747

Epoch: 5| Step: 5
Training loss: 2.332971124691911
Validation loss: 2.4592953082126856

Epoch: 5| Step: 6
Training loss: 2.5991902117342054
Validation loss: 2.4670834046449563

Epoch: 5| Step: 7
Training loss: 1.9747553468625318
Validation loss: 2.4647543256672484

Epoch: 5| Step: 8
Training loss: 2.5993112899042567
Validation loss: 2.461143250921696

Epoch: 5| Step: 9
Training loss: 3.0886939763322543
Validation loss: 2.4668712388299827

Epoch: 5| Step: 10
Training loss: 2.926117616679245
Validation loss: 2.4711315803795912

Epoch: 5| Step: 11
Training loss: 0.994057342698199
Validation loss: 2.4614276902374836

Epoch: 131| Step: 0
Training loss: 2.6560434597722558
Validation loss: 2.4708321840456198

Epoch: 5| Step: 1
Training loss: 2.088473375175839
Validation loss: 2.456424316743579

Epoch: 5| Step: 2
Training loss: 2.184000103695486
Validation loss: 2.4687151483900553

Epoch: 5| Step: 3
Training loss: 2.90283741096274
Validation loss: 2.4648550308380486

Epoch: 5| Step: 4
Training loss: 2.7632598246271445
Validation loss: 2.466295752689835

Epoch: 5| Step: 5
Training loss: 2.3912398601023863
Validation loss: 2.471505753692133

Epoch: 5| Step: 6
Training loss: 2.6008930433223765
Validation loss: 2.4656962166458127

Epoch: 5| Step: 7
Training loss: 3.1097773766029055
Validation loss: 2.4684988006721267

Epoch: 5| Step: 8
Training loss: 2.5296596664584525
Validation loss: 2.470664304244845

Epoch: 5| Step: 9
Training loss: 2.039842244574679
Validation loss: 2.469274569765193

Epoch: 5| Step: 10
Training loss: 2.233760829359209
Validation loss: 2.4774202251389736

Epoch: 5| Step: 11
Training loss: 2.704702986172087
Validation loss: 2.471206171544024

Epoch: 132| Step: 0
Training loss: 3.0098090345060657
Validation loss: 2.480914000350903

Epoch: 5| Step: 1
Training loss: 2.28148012437592
Validation loss: 2.467002237912707

Epoch: 5| Step: 2
Training loss: 2.942058678317378
Validation loss: 2.4845482347977534

Epoch: 5| Step: 3
Training loss: 2.463160210420444
Validation loss: 2.4745140709673827

Epoch: 5| Step: 4
Training loss: 2.1508866101060957
Validation loss: 2.479788891795205

Epoch: 5| Step: 5
Training loss: 1.8448505026770552
Validation loss: 2.4821046616045233

Epoch: 5| Step: 6
Training loss: 2.1432878402026856
Validation loss: 2.4799753334115917

Epoch: 5| Step: 7
Training loss: 2.471043161506952
Validation loss: 2.480250095131727

Epoch: 5| Step: 8
Training loss: 2.883790881359484
Validation loss: 2.4624287482021034

Epoch: 5| Step: 9
Training loss: 2.4889354953583935
Validation loss: 2.470917711752407

Epoch: 5| Step: 10
Training loss: 2.8504797146939733
Validation loss: 2.459158780369598

Epoch: 5| Step: 11
Training loss: 2.5428218301032532
Validation loss: 2.464816299342044

Epoch: 133| Step: 0
Training loss: 2.5071387410857864
Validation loss: 2.4615308419707245

Epoch: 5| Step: 1
Training loss: 2.439154234779441
Validation loss: 2.4631325030460602

Epoch: 5| Step: 2
Training loss: 2.1524617185300996
Validation loss: 2.461219230551225

Epoch: 5| Step: 3
Training loss: 2.68090383433601
Validation loss: 2.4722990447929956

Epoch: 5| Step: 4
Training loss: 2.797250477398634
Validation loss: 2.4639280445003338

Epoch: 5| Step: 5
Training loss: 1.9912869680724292
Validation loss: 2.454897483182737

Epoch: 5| Step: 6
Training loss: 2.4870808578924546
Validation loss: 2.456858217972466

Epoch: 5| Step: 7
Training loss: 2.4135844427035376
Validation loss: 2.4788256872859393

Epoch: 5| Step: 8
Training loss: 2.9844197374755437
Validation loss: 2.4719790655801073

Epoch: 5| Step: 9
Training loss: 3.1166430310935773
Validation loss: 2.484372204952947

Epoch: 5| Step: 10
Training loss: 2.3321835773245394
Validation loss: 2.4823108070992004

Epoch: 5| Step: 11
Training loss: 2.021261687613569
Validation loss: 2.471834878961622

Epoch: 134| Step: 0
Training loss: 2.973673542414
Validation loss: 2.4751000965312326

Epoch: 5| Step: 1
Training loss: 2.786867105798348
Validation loss: 2.474026381242739

Epoch: 5| Step: 2
Training loss: 2.202394946187654
Validation loss: 2.4768192707690435

Epoch: 5| Step: 3
Training loss: 2.4080874870857545
Validation loss: 2.4727657026721075

Epoch: 5| Step: 4
Training loss: 2.939302905733819
Validation loss: 2.475031217866269

Epoch: 5| Step: 5
Training loss: 2.1621560192504172
Validation loss: 2.4676607038529026

Epoch: 5| Step: 6
Training loss: 2.1852810095426456
Validation loss: 2.4763022806540143

Epoch: 5| Step: 7
Training loss: 2.5460083780083425
Validation loss: 2.474433107829988

Epoch: 5| Step: 8
Training loss: 2.707355342251687
Validation loss: 2.4744998272356

Epoch: 5| Step: 9
Training loss: 2.188092614691231
Validation loss: 2.466420221153228

Epoch: 5| Step: 10
Training loss: 2.2863196908080594
Validation loss: 2.459378058218761

Epoch: 5| Step: 11
Training loss: 2.809680457901342
Validation loss: 2.460702802173991

Epoch: 135| Step: 0
Training loss: 2.549700988741332
Validation loss: 2.4799395019127846

Epoch: 5| Step: 1
Training loss: 3.0853289426653103
Validation loss: 2.4858605403884027

Epoch: 5| Step: 2
Training loss: 2.7218512024917634
Validation loss: 2.464132320146194

Epoch: 5| Step: 3
Training loss: 2.1067186371915647
Validation loss: 2.468638779754479

Epoch: 5| Step: 4
Training loss: 2.1429815755773918
Validation loss: 2.47022243241462

Epoch: 5| Step: 5
Training loss: 2.4720645335147156
Validation loss: 2.4720584534456598

Epoch: 5| Step: 6
Training loss: 2.248672623631066
Validation loss: 2.475924051583611

Epoch: 5| Step: 7
Training loss: 2.7227429413094955
Validation loss: 2.4811143290328537

Epoch: 5| Step: 8
Training loss: 2.7916881693301336
Validation loss: 2.476339267974782

Epoch: 5| Step: 9
Training loss: 2.332266586416473
Validation loss: 2.4707658199352065

Epoch: 5| Step: 10
Training loss: 2.5710594691932775
Validation loss: 2.4757381756061765

Epoch: 5| Step: 11
Training loss: 2.118641034140274
Validation loss: 2.4620865092243864

Epoch: 136| Step: 0
Training loss: 2.8189195061782115
Validation loss: 2.466208771678267

Epoch: 5| Step: 1
Training loss: 1.896160125513701
Validation loss: 2.4732381729518758

Epoch: 5| Step: 2
Training loss: 2.398823163465802
Validation loss: 2.4668199221474967

Epoch: 5| Step: 3
Training loss: 2.742472924487429
Validation loss: 2.458999928654249

Epoch: 5| Step: 4
Training loss: 2.8277331338925307
Validation loss: 2.4701310532084877

Epoch: 5| Step: 5
Training loss: 2.8427036582169345
Validation loss: 2.471455833560061

Epoch: 5| Step: 6
Training loss: 2.044772633641945
Validation loss: 2.4770788382534077

Epoch: 5| Step: 7
Training loss: 2.1704696389662574
Validation loss: 2.475334392460909

Epoch: 5| Step: 8
Training loss: 2.5870574646455804
Validation loss: 2.4788608175370883

Epoch: 5| Step: 9
Training loss: 2.775899648463071
Validation loss: 2.468898863267846

Epoch: 5| Step: 10
Training loss: 2.3138105442033394
Validation loss: 2.461682448083667

Epoch: 5| Step: 11
Training loss: 3.119511782277096
Validation loss: 2.4759400926382438

Epoch: 137| Step: 0
Training loss: 2.4952281232982654
Validation loss: 2.4791270514670325

Epoch: 5| Step: 1
Training loss: 2.587724511915179
Validation loss: 2.490054741657298

Epoch: 5| Step: 2
Training loss: 2.571746704313047
Validation loss: 2.510202103200062

Epoch: 5| Step: 3
Training loss: 2.477668972315905
Validation loss: 2.470424558996122

Epoch: 5| Step: 4
Training loss: 1.9910359962922555
Validation loss: 2.470502830699593

Epoch: 5| Step: 5
Training loss: 2.974803494927868
Validation loss: 2.4506294693955133

Epoch: 5| Step: 6
Training loss: 2.5814227658291777
Validation loss: 2.462677557428929

Epoch: 5| Step: 7
Training loss: 2.1312001600059243
Validation loss: 2.4736896864272264

Epoch: 5| Step: 8
Training loss: 2.796371670404878
Validation loss: 2.4627379194368726

Epoch: 5| Step: 9
Training loss: 2.757365160746706
Validation loss: 2.4755882529022806

Epoch: 5| Step: 10
Training loss: 2.4191756433348206
Validation loss: 2.466889138810643

Epoch: 5| Step: 11
Training loss: 2.779249178811573
Validation loss: 2.4736195114748

Epoch: 138| Step: 0
Training loss: 2.7077615476680257
Validation loss: 2.4768981465469295

Epoch: 5| Step: 1
Training loss: 2.6109093820369362
Validation loss: 2.4707717443695167

Epoch: 5| Step: 2
Training loss: 2.0561891587367023
Validation loss: 2.4733946603136405

Epoch: 5| Step: 3
Training loss: 2.0826901651042626
Validation loss: 2.471042355455119

Epoch: 5| Step: 4
Training loss: 2.462624785848722
Validation loss: 2.4753166940155347

Epoch: 5| Step: 5
Training loss: 2.6058074868236583
Validation loss: 2.4665395018999092

Epoch: 5| Step: 6
Training loss: 2.308526827234318
Validation loss: 2.461873230828189

Epoch: 5| Step: 7
Training loss: 2.785970218485577
Validation loss: 2.4590117412859263

Epoch: 5| Step: 8
Training loss: 2.9796661456202553
Validation loss: 2.4489647197653635

Epoch: 5| Step: 9
Training loss: 2.5829549225149835
Validation loss: 2.448098023101797

Epoch: 5| Step: 10
Training loss: 2.696516481263934
Validation loss: 2.443318704886142

Epoch: 5| Step: 11
Training loss: 2.3041857157006604
Validation loss: 2.439424488641719

Epoch: 139| Step: 0
Training loss: 2.001747679054322
Validation loss: 2.4516128447343206

Epoch: 5| Step: 1
Training loss: 2.4114643423666076
Validation loss: 2.461732241554137

Epoch: 5| Step: 2
Training loss: 2.957786634909443
Validation loss: 2.460938283122912

Epoch: 5| Step: 3
Training loss: 2.3294365791879246
Validation loss: 2.4579131742578597

Epoch: 5| Step: 4
Training loss: 2.334251280012185
Validation loss: 2.4612433026559923

Epoch: 5| Step: 5
Training loss: 2.4924945701914942
Validation loss: 2.450277092730581

Epoch: 5| Step: 6
Training loss: 2.887659809925062
Validation loss: 2.4614055047249708

Epoch: 5| Step: 7
Training loss: 2.641215060969291
Validation loss: 2.4568100907051598

Epoch: 5| Step: 8
Training loss: 2.7031577224073873
Validation loss: 2.4608741832842957

Epoch: 5| Step: 9
Training loss: 2.2842093307182965
Validation loss: 2.4585053146679323

Epoch: 5| Step: 10
Training loss: 2.815304608168303
Validation loss: 2.462784190327212

Epoch: 5| Step: 11
Training loss: 1.5167345527854508
Validation loss: 2.4617787532904707

Epoch: 140| Step: 0
Training loss: 2.802255069806695
Validation loss: 2.457826369485526

Epoch: 5| Step: 1
Training loss: 2.1759304906317745
Validation loss: 2.4565597510353787

Epoch: 5| Step: 2
Training loss: 1.9379524810090911
Validation loss: 2.462056740047842

Epoch: 5| Step: 3
Training loss: 2.6572651437960784
Validation loss: 2.462750589461981

Epoch: 5| Step: 4
Training loss: 2.6281910528530132
Validation loss: 2.4580824179751484

Epoch: 5| Step: 5
Training loss: 2.528511449750579
Validation loss: 2.4605211097412765

Epoch: 5| Step: 6
Training loss: 2.163592015431912
Validation loss: 2.464778232257872

Epoch: 5| Step: 7
Training loss: 2.3652877990586028
Validation loss: 2.4595061726470377

Epoch: 5| Step: 8
Training loss: 2.829901879971911
Validation loss: 2.460532087406873

Epoch: 5| Step: 9
Training loss: 2.3407542092447304
Validation loss: 2.4515196737127227

Epoch: 5| Step: 10
Training loss: 2.8627246352096343
Validation loss: 2.4642873620718166

Epoch: 5| Step: 11
Training loss: 3.527393767381398
Validation loss: 2.4642821456555577

Epoch: 141| Step: 0
Training loss: 2.0179972328719042
Validation loss: 2.4577914761506827

Epoch: 5| Step: 1
Training loss: 3.0060643255745854
Validation loss: 2.4746629507943667

Epoch: 5| Step: 2
Training loss: 2.292807994191834
Validation loss: 2.464813562723208

Epoch: 5| Step: 3
Training loss: 2.4629556766785723
Validation loss: 2.4730359650180773

Epoch: 5| Step: 4
Training loss: 2.2988803958054778
Validation loss: 2.4803616317888357

Epoch: 5| Step: 5
Training loss: 3.14000638876101
Validation loss: 2.4764928436912705

Epoch: 5| Step: 6
Training loss: 2.372394337044728
Validation loss: 2.477087095678588

Epoch: 5| Step: 7
Training loss: 2.7602108476790357
Validation loss: 2.4782672233546164

Epoch: 5| Step: 8
Training loss: 2.6494357498018104
Validation loss: 2.468864635429614

Epoch: 5| Step: 9
Training loss: 2.3353051187609686
Validation loss: 2.474225229958056

Epoch: 5| Step: 10
Training loss: 2.2006419372340167
Validation loss: 2.470612083235311

Epoch: 5| Step: 11
Training loss: 2.4500264808625007
Validation loss: 2.4652518344164784

Epoch: 142| Step: 0
Training loss: 2.1814417189149156
Validation loss: 2.4652884354756495

Epoch: 5| Step: 1
Training loss: 3.012664923367802
Validation loss: 2.458659998289381

Epoch: 5| Step: 2
Training loss: 2.522183605725644
Validation loss: 2.462222015355842

Epoch: 5| Step: 3
Training loss: 2.7844387162749986
Validation loss: 2.4656712694101492

Epoch: 5| Step: 4
Training loss: 2.4227460709853803
Validation loss: 2.469713526025538

Epoch: 5| Step: 5
Training loss: 2.656029097403427
Validation loss: 2.462034120397631

Epoch: 5| Step: 6
Training loss: 2.1311218491673665
Validation loss: 2.462623047215272

Epoch: 5| Step: 7
Training loss: 2.5665385358790824
Validation loss: 2.459235734240053

Epoch: 5| Step: 8
Training loss: 2.6389337123164895
Validation loss: 2.4478085040822783

Epoch: 5| Step: 9
Training loss: 2.3768124942349713
Validation loss: 2.4566298148273775

Epoch: 5| Step: 10
Training loss: 2.48774960286357
Validation loss: 2.4668530326646736

Epoch: 5| Step: 11
Training loss: 2.1904749667912573
Validation loss: 2.4549702307300496

Epoch: 143| Step: 0
Training loss: 2.923174237743372
Validation loss: 2.4628234902533466

Epoch: 5| Step: 1
Training loss: 2.343345301974224
Validation loss: 2.468698283752347

Epoch: 5| Step: 2
Training loss: 2.576329293694251
Validation loss: 2.46609512056752

Epoch: 5| Step: 3
Training loss: 2.525297914058564
Validation loss: 2.4663743447306494

Epoch: 5| Step: 4
Training loss: 2.840786238354862
Validation loss: 2.460141165121669

Epoch: 5| Step: 5
Training loss: 2.4236696546516296
Validation loss: 2.4549481042114802

Epoch: 5| Step: 6
Training loss: 2.0513812831266174
Validation loss: 2.4564325667617273

Epoch: 5| Step: 7
Training loss: 2.3269875839420187
Validation loss: 2.4483011160272223

Epoch: 5| Step: 8
Training loss: 2.4335257580414615
Validation loss: 2.4495909964159397

Epoch: 5| Step: 9
Training loss: 2.2408458138039475
Validation loss: 2.448562732959586

Epoch: 5| Step: 10
Training loss: 2.6911832719849955
Validation loss: 2.45255849658966

Epoch: 5| Step: 11
Training loss: 3.5838432097113895
Validation loss: 2.4513936989808793

Epoch: 144| Step: 0
Training loss: 2.5755704303487823
Validation loss: 2.447467841267333

Epoch: 5| Step: 1
Training loss: 2.1259456101329715
Validation loss: 2.4589806158488017

Epoch: 5| Step: 2
Training loss: 2.0488459292675527
Validation loss: 2.45818581515666

Epoch: 5| Step: 3
Training loss: 2.781631957840029
Validation loss: 2.4566436162610836

Epoch: 5| Step: 4
Training loss: 2.3593917745031794
Validation loss: 2.468954544607394

Epoch: 5| Step: 5
Training loss: 2.511420865585679
Validation loss: 2.4859125249963996

Epoch: 5| Step: 6
Training loss: 2.6499780546035416
Validation loss: 2.4801906119371324

Epoch: 5| Step: 7
Training loss: 2.5350316374119366
Validation loss: 2.465996808574918

Epoch: 5| Step: 8
Training loss: 2.53419436411935
Validation loss: 2.4649681023667585

Epoch: 5| Step: 9
Training loss: 2.519992425392514
Validation loss: 2.4605928734763776

Epoch: 5| Step: 10
Training loss: 3.2389722208855787
Validation loss: 2.455581750958976

Epoch: 5| Step: 11
Training loss: 1.7266218770721855
Validation loss: 2.4527084742089467

Epoch: 145| Step: 0
Training loss: 2.6492053693896365
Validation loss: 2.454925617345911

Epoch: 5| Step: 1
Training loss: 3.0319548111922474
Validation loss: 2.458023659280308

Epoch: 5| Step: 2
Training loss: 2.242030121600089
Validation loss: 2.4611673964237166

Epoch: 5| Step: 3
Training loss: 2.7252741614498013
Validation loss: 2.4578387212759125

Epoch: 5| Step: 4
Training loss: 2.2611421630855832
Validation loss: 2.4632554919679364

Epoch: 5| Step: 5
Training loss: 2.469191596216151
Validation loss: 2.4631542414636556

Epoch: 5| Step: 6
Training loss: 2.618837479835008
Validation loss: 2.463809344942876

Epoch: 5| Step: 7
Training loss: 2.549186359822862
Validation loss: 2.460764694201774

Epoch: 5| Step: 8
Training loss: 2.429606445530546
Validation loss: 2.464731478867243

Epoch: 5| Step: 9
Training loss: 2.3187184622128743
Validation loss: 2.4576662190229652

Epoch: 5| Step: 10
Training loss: 2.303462022737004
Validation loss: 2.46044534272988

Epoch: 5| Step: 11
Training loss: 2.5365972670169463
Validation loss: 2.462416064418126

Epoch: 146| Step: 0
Training loss: 2.323074700378272
Validation loss: 2.4592310443644134

Epoch: 5| Step: 1
Training loss: 3.118138524353218
Validation loss: 2.459594687183025

Epoch: 5| Step: 2
Training loss: 2.5318682822065615
Validation loss: 2.4644148141532827

Epoch: 5| Step: 3
Training loss: 2.294862241578938
Validation loss: 2.4687701397488793

Epoch: 5| Step: 4
Training loss: 2.5675763347090785
Validation loss: 2.4645442589257858

Epoch: 5| Step: 5
Training loss: 2.2570257697165963
Validation loss: 2.460055468697619

Epoch: 5| Step: 6
Training loss: 2.3398871569038233
Validation loss: 2.4596594423433618

Epoch: 5| Step: 7
Training loss: 2.734567253983496
Validation loss: 2.4491747457231057

Epoch: 5| Step: 8
Training loss: 2.117331524556698
Validation loss: 2.4503588499610434

Epoch: 5| Step: 9
Training loss: 2.91035958418212
Validation loss: 2.4590065136782235

Epoch: 5| Step: 10
Training loss: 2.3715850974572263
Validation loss: 2.4647605466830136

Epoch: 5| Step: 11
Training loss: 0.7798696148541694
Validation loss: 2.4524282531016945

Epoch: 147| Step: 0
Training loss: 2.5303816071050793
Validation loss: 2.4532037507717637

Epoch: 5| Step: 1
Training loss: 2.696598708055234
Validation loss: 2.4555788139089967

Epoch: 5| Step: 2
Training loss: 2.062173297322734
Validation loss: 2.453526366862745

Epoch: 5| Step: 3
Training loss: 2.044124823213396
Validation loss: 2.454735373133986

Epoch: 5| Step: 4
Training loss: 2.8674708753867764
Validation loss: 2.460303843627674

Epoch: 5| Step: 5
Training loss: 2.351916416441183
Validation loss: 2.461406150476751

Epoch: 5| Step: 6
Training loss: 2.5390434381796494
Validation loss: 2.4636410873922427

Epoch: 5| Step: 7
Training loss: 2.4686915716669198
Validation loss: 2.4696613331812793

Epoch: 5| Step: 8
Training loss: 2.61378727277453
Validation loss: 2.4700610506373897

Epoch: 5| Step: 9
Training loss: 2.9681325169924158
Validation loss: 2.4555868442645927

Epoch: 5| Step: 10
Training loss: 2.605895686593525
Validation loss: 2.461203916953599

Epoch: 5| Step: 11
Training loss: 2.030243022446843
Validation loss: 2.446924342587261

Epoch: 148| Step: 0
Training loss: 2.326745463005242
Validation loss: 2.4556353171178684

Epoch: 5| Step: 1
Training loss: 2.5527859298064866
Validation loss: 2.4554629392248684

Epoch: 5| Step: 2
Training loss: 2.8861423686144834
Validation loss: 2.4605740071849884

Epoch: 5| Step: 3
Training loss: 2.626167582653509
Validation loss: 2.463461603768347

Epoch: 5| Step: 4
Training loss: 2.5467561097274474
Validation loss: 2.4759117699555286

Epoch: 5| Step: 5
Training loss: 2.6934195685351305
Validation loss: 2.4590703511376364

Epoch: 5| Step: 6
Training loss: 2.256340418137195
Validation loss: 2.4542483128911052

Epoch: 5| Step: 7
Training loss: 2.2616981940249485
Validation loss: 2.454577653686535

Epoch: 5| Step: 8
Training loss: 2.2462667647358656
Validation loss: 2.46369731699013

Epoch: 5| Step: 9
Training loss: 2.1003599448762995
Validation loss: 2.4538655550243185

Epoch: 5| Step: 10
Training loss: 2.8735571848268853
Validation loss: 2.4547125302112476

Epoch: 5| Step: 11
Training loss: 2.5319374940457915
Validation loss: 2.4637301952869888

Epoch: 149| Step: 0
Training loss: 2.7731131350538782
Validation loss: 2.4592764562037086

Epoch: 5| Step: 1
Training loss: 1.7373805766607266
Validation loss: 2.4601981207816825

Epoch: 5| Step: 2
Training loss: 2.7489471153925638
Validation loss: 2.4740214222677235

Epoch: 5| Step: 3
Training loss: 1.979886844175941
Validation loss: 2.4614309633605687

Epoch: 5| Step: 4
Training loss: 2.1255342148616108
Validation loss: 2.459468504030187

Epoch: 5| Step: 5
Training loss: 2.6453855140555325
Validation loss: 2.457672888462023

Epoch: 5| Step: 6
Training loss: 2.027658779827338
Validation loss: 2.459841081304871

Epoch: 5| Step: 7
Training loss: 2.7078912423071158
Validation loss: 2.458884356592892

Epoch: 5| Step: 8
Training loss: 2.961489824701669
Validation loss: 2.4529115255980294

Epoch: 5| Step: 9
Training loss: 2.8320049837144006
Validation loss: 2.4528778299914316

Epoch: 5| Step: 10
Training loss: 2.777318168339904
Validation loss: 2.4561564672779093

Epoch: 5| Step: 11
Training loss: 1.8939694544978605
Validation loss: 2.457186056737675

Epoch: 150| Step: 0
Training loss: 2.8032070492374936
Validation loss: 2.4599933811424344

Epoch: 5| Step: 1
Training loss: 2.254076549634854
Validation loss: 2.4559379453828947

Epoch: 5| Step: 2
Training loss: 2.615324535909665
Validation loss: 2.4558490219613964

Epoch: 5| Step: 3
Training loss: 2.918892873661203
Validation loss: 2.461948312321674

Epoch: 5| Step: 4
Training loss: 2.3451088590101548
Validation loss: 2.465552387852482

Epoch: 5| Step: 5
Training loss: 2.2066317306396024
Validation loss: 2.461046392060107

Epoch: 5| Step: 6
Training loss: 2.735515945000424
Validation loss: 2.461020675141674

Epoch: 5| Step: 7
Training loss: 2.059409513748687
Validation loss: 2.4637396788643007

Epoch: 5| Step: 8
Training loss: 2.8749469254611904
Validation loss: 2.4648055906410047

Epoch: 5| Step: 9
Training loss: 1.9729691361160848
Validation loss: 2.4624156045087013

Epoch: 5| Step: 10
Training loss: 2.5323488652433084
Validation loss: 2.4665845556596904

Epoch: 5| Step: 11
Training loss: 1.7936237277468343
Validation loss: 2.4608050356136904

Testing loss: 1.9800040893645519
