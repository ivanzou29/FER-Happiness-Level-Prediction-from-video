Epoch: 1| Step: 0
Training loss: 6.118428967853428
Validation loss: 5.914168873833502

Epoch: 5| Step: 1
Training loss: 6.215933463841477
Validation loss: 5.9124210419601315

Epoch: 5| Step: 2
Training loss: 5.9293806275584
Validation loss: 5.910601941784723

Epoch: 5| Step: 3
Training loss: 5.792108349687658
Validation loss: 5.908932179428739

Epoch: 5| Step: 4
Training loss: 5.097087492217523
Validation loss: 5.907368387571533

Epoch: 5| Step: 5
Training loss: 6.412584401666468
Validation loss: 5.905824575290759

Epoch: 5| Step: 6
Training loss: 5.689419600613555
Validation loss: 5.90427338695071

Epoch: 5| Step: 7
Training loss: 5.992997852026524
Validation loss: 5.90282179223898

Epoch: 5| Step: 8
Training loss: 6.924590325201557
Validation loss: 5.901265713870709

Epoch: 5| Step: 9
Training loss: 6.3810653256287395
Validation loss: 5.899645717404261

Epoch: 5| Step: 10
Training loss: 5.57078911880983
Validation loss: 5.898044443402639

Epoch: 5| Step: 11
Training loss: 5.649657058435467
Validation loss: 5.8963011116862445

Epoch: 2| Step: 0
Training loss: 4.960884826861117
Validation loss: 5.894509489248062

Epoch: 5| Step: 1
Training loss: 5.416916396424225
Validation loss: 5.892574672341824

Epoch: 5| Step: 2
Training loss: 6.168978008783267
Validation loss: 5.890720747785927

Epoch: 5| Step: 3
Training loss: 4.67934267432612
Validation loss: 5.8886593103142975

Epoch: 5| Step: 4
Training loss: 6.457252789416392
Validation loss: 5.886494578898699

Epoch: 5| Step: 5
Training loss: 6.2699404193779085
Validation loss: 5.884241134139205

Epoch: 5| Step: 6
Training loss: 6.33426291352947
Validation loss: 5.88195937118628

Epoch: 5| Step: 7
Training loss: 6.032552153594683
Validation loss: 5.879312177227618

Epoch: 5| Step: 8
Training loss: 6.659691722253307
Validation loss: 5.876752970633904

Epoch: 5| Step: 9
Training loss: 6.170504569964211
Validation loss: 5.873868643945287

Epoch: 5| Step: 10
Training loss: 6.387559076024818
Validation loss: 5.870989370697818

Epoch: 5| Step: 11
Training loss: 6.5055834924431215
Validation loss: 5.867971659956601

Epoch: 3| Step: 0
Training loss: 5.951086941980904
Validation loss: 5.864877068959481

Epoch: 5| Step: 1
Training loss: 6.322390220717742
Validation loss: 5.861447265390383

Epoch: 5| Step: 2
Training loss: 5.878629172249617
Validation loss: 5.857976361663435

Epoch: 5| Step: 3
Training loss: 4.935457217478097
Validation loss: 5.854464542598322

Epoch: 5| Step: 4
Training loss: 6.462395684527406
Validation loss: 5.850610707404149

Epoch: 5| Step: 5
Training loss: 5.974724301158465
Validation loss: 5.846605714910158

Epoch: 5| Step: 6
Training loss: 5.547875714362805
Validation loss: 5.842416621385729

Epoch: 5| Step: 7
Training loss: 5.558839086183732
Validation loss: 5.838128274058334

Epoch: 5| Step: 8
Training loss: 5.371533007606548
Validation loss: 5.833775022224321

Epoch: 5| Step: 9
Training loss: 6.622800641895025
Validation loss: 5.828910740580199

Epoch: 5| Step: 10
Training loss: 6.608999255166031
Validation loss: 5.824309919954101

Epoch: 5| Step: 11
Training loss: 6.3804582155041905
Validation loss: 5.818999030892435

Epoch: 4| Step: 0
Training loss: 6.306568342629286
Validation loss: 5.8138089500691414

Epoch: 5| Step: 1
Training loss: 5.954664296665793
Validation loss: 5.808310985202933

Epoch: 5| Step: 2
Training loss: 5.723018533221065
Validation loss: 5.802491612568713

Epoch: 5| Step: 3
Training loss: 5.647164651168948
Validation loss: 5.79681179838181

Epoch: 5| Step: 4
Training loss: 5.483079371421733
Validation loss: 5.790870586635368

Epoch: 5| Step: 5
Training loss: 6.717177663948079
Validation loss: 5.784685973071271

Epoch: 5| Step: 6
Training loss: 5.938870884093178
Validation loss: 5.778028047421168

Epoch: 5| Step: 7
Training loss: 6.481728916995678
Validation loss: 5.771643291422015

Epoch: 5| Step: 8
Training loss: 5.5009709281492984
Validation loss: 5.764578134111386

Epoch: 5| Step: 9
Training loss: 6.318948907485339
Validation loss: 5.757559175064385

Epoch: 5| Step: 10
Training loss: 4.876741538386729
Validation loss: 5.750562398469103

Epoch: 5| Step: 11
Training loss: 4.151354437723011
Validation loss: 5.7430484947992495

Epoch: 5| Step: 0
Training loss: 6.413276800803975
Validation loss: 5.7356210406391135

Epoch: 5| Step: 1
Training loss: 6.04060294773361
Validation loss: 5.727628788159886

Epoch: 5| Step: 2
Training loss: 5.352672422822084
Validation loss: 5.719925132597181

Epoch: 5| Step: 3
Training loss: 5.933623001800016
Validation loss: 5.711349994254113

Epoch: 5| Step: 4
Training loss: 5.8981781555154145
Validation loss: 5.703053443494623

Epoch: 5| Step: 5
Training loss: 4.907008215758009
Validation loss: 5.69444689039886

Epoch: 5| Step: 6
Training loss: 5.968156235805198
Validation loss: 5.685965921502688

Epoch: 5| Step: 7
Training loss: 5.416295239356238
Validation loss: 5.677265824584148

Epoch: 5| Step: 8
Training loss: 6.248590539315834
Validation loss: 5.668393119841431

Epoch: 5| Step: 9
Training loss: 5.185422918127677
Validation loss: 5.659664956747699

Epoch: 5| Step: 10
Training loss: 6.300179724173332
Validation loss: 5.651165048216251

Epoch: 5| Step: 11
Training loss: 5.973786949974166
Validation loss: 5.64245801115378

Epoch: 6| Step: 0
Training loss: 6.0932407264155275
Validation loss: 5.633546122739918

Epoch: 5| Step: 1
Training loss: 5.308070232073333
Validation loss: 5.62525559303839

Epoch: 5| Step: 2
Training loss: 4.831360556853759
Validation loss: 5.6166998130242884

Epoch: 5| Step: 3
Training loss: 5.883255373228422
Validation loss: 5.608334840695924

Epoch: 5| Step: 4
Training loss: 5.960900702806641
Validation loss: 5.600418122894497

Epoch: 5| Step: 5
Training loss: 6.356055740793824
Validation loss: 5.592457939970887

Epoch: 5| Step: 6
Training loss: 5.7455271033697715
Validation loss: 5.5845977955075226

Epoch: 5| Step: 7
Training loss: 5.6912809108110025
Validation loss: 5.577101128195569

Epoch: 5| Step: 8
Training loss: 6.332970391297498
Validation loss: 5.56945199905141

Epoch: 5| Step: 9
Training loss: 5.270116684434388
Validation loss: 5.561980769751376

Epoch: 5| Step: 10
Training loss: 5.16598331895617
Validation loss: 5.554830836339309

Epoch: 5| Step: 11
Training loss: 5.578146712744419
Validation loss: 5.547729168525364

Epoch: 7| Step: 0
Training loss: 6.223941648665747
Validation loss: 5.540597262728149

Epoch: 5| Step: 1
Training loss: 5.608292754179042
Validation loss: 5.533130577501408

Epoch: 5| Step: 2
Training loss: 5.6782614322578
Validation loss: 5.526254571330209

Epoch: 5| Step: 3
Training loss: 5.5607787480193664
Validation loss: 5.519259673589651

Epoch: 5| Step: 4
Training loss: 5.178649890474384
Validation loss: 5.512571604545495

Epoch: 5| Step: 5
Training loss: 5.70074061885959
Validation loss: 5.505653120374627

Epoch: 5| Step: 6
Training loss: 5.803396006856877
Validation loss: 5.499458040643083

Epoch: 5| Step: 7
Training loss: 5.611841196250877
Validation loss: 5.493065240719896

Epoch: 5| Step: 8
Training loss: 4.690014380979959
Validation loss: 5.486638086765211

Epoch: 5| Step: 9
Training loss: 5.434304537105181
Validation loss: 5.480281254739356

Epoch: 5| Step: 10
Training loss: 6.335666561330953
Validation loss: 5.474011758192147

Epoch: 5| Step: 11
Training loss: 5.049166416072299
Validation loss: 5.467285316146808

Epoch: 8| Step: 0
Training loss: 5.770445589151957
Validation loss: 5.4611756978183195

Epoch: 5| Step: 1
Training loss: 4.836431869356655
Validation loss: 5.455487946220654

Epoch: 5| Step: 2
Training loss: 5.605941359105401
Validation loss: 5.449386481070175

Epoch: 5| Step: 3
Training loss: 5.39463979513805
Validation loss: 5.443141926068848

Epoch: 5| Step: 4
Training loss: 5.941462750388814
Validation loss: 5.437504450478322

Epoch: 5| Step: 5
Training loss: 5.231843524109508
Validation loss: 5.432094415562319

Epoch: 5| Step: 6
Training loss: 5.958795205023424
Validation loss: 5.426604546961515

Epoch: 5| Step: 7
Training loss: 6.105525606541087
Validation loss: 5.4205998616981015

Epoch: 5| Step: 8
Training loss: 5.498693657838107
Validation loss: 5.415383658926233

Epoch: 5| Step: 9
Training loss: 5.101651294630674
Validation loss: 5.410327836126235

Epoch: 5| Step: 10
Training loss: 5.810795687950112
Validation loss: 5.4041488915795455

Epoch: 5| Step: 11
Training loss: 3.721446109790022
Validation loss: 5.398701751027033

Epoch: 9| Step: 0
Training loss: 5.592352154362975
Validation loss: 5.393608093457773

Epoch: 5| Step: 1
Training loss: 5.658684812405824
Validation loss: 5.388341359160928

Epoch: 5| Step: 2
Training loss: 6.416674659360721
Validation loss: 5.383413915158994

Epoch: 5| Step: 3
Training loss: 5.243477720846041
Validation loss: 5.378109143603377

Epoch: 5| Step: 4
Training loss: 6.1569706064216225
Validation loss: 5.372468115473954

Epoch: 5| Step: 5
Training loss: 5.048529102907626
Validation loss: 5.367318763960153

Epoch: 5| Step: 6
Training loss: 5.120938808678206
Validation loss: 5.361514051093633

Epoch: 5| Step: 7
Training loss: 5.69898146513833
Validation loss: 5.356374844342853

Epoch: 5| Step: 8
Training loss: 5.118702997497209
Validation loss: 5.350899009691656

Epoch: 5| Step: 9
Training loss: 4.458483019065882
Validation loss: 5.345303374751662

Epoch: 5| Step: 10
Training loss: 5.237864683287426
Validation loss: 5.340508606343436

Epoch: 5| Step: 11
Training loss: 7.070250183168053
Validation loss: 5.335142054920396

Epoch: 10| Step: 0
Training loss: 5.5739364499074995
Validation loss: 5.329818053870668

Epoch: 5| Step: 1
Training loss: 5.2631241380713245
Validation loss: 5.325029818431962

Epoch: 5| Step: 2
Training loss: 5.704726738900589
Validation loss: 5.320321477508066

Epoch: 5| Step: 3
Training loss: 6.020144342865505
Validation loss: 5.315351909998436

Epoch: 5| Step: 4
Training loss: 5.687965457859663
Validation loss: 5.310365337763784

Epoch: 5| Step: 5
Training loss: 5.382100937184927
Validation loss: 5.305842233183746

Epoch: 5| Step: 6
Training loss: 5.034687644868993
Validation loss: 5.300856452695175

Epoch: 5| Step: 7
Training loss: 5.182770928948445
Validation loss: 5.295797998093865

Epoch: 5| Step: 8
Training loss: 5.631459744322844
Validation loss: 5.291078071699808

Epoch: 5| Step: 9
Training loss: 4.995186205076711
Validation loss: 5.286046583053873

Epoch: 5| Step: 10
Training loss: 5.367931775235141
Validation loss: 5.281734369100235

Epoch: 5| Step: 11
Training loss: 4.182402055486219
Validation loss: 5.27729071857077

Epoch: 11| Step: 0
Training loss: 5.321387900675267
Validation loss: 5.272956310029244

Epoch: 5| Step: 1
Training loss: 5.307812765917071
Validation loss: 5.268789493206127

Epoch: 5| Step: 2
Training loss: 5.702961122431473
Validation loss: 5.264355605523457

Epoch: 5| Step: 3
Training loss: 5.883760130245256
Validation loss: 5.260119539940408

Epoch: 5| Step: 4
Training loss: 5.232852543574857
Validation loss: 5.256173160277091

Epoch: 5| Step: 5
Training loss: 5.067822707618096
Validation loss: 5.251736868305695

Epoch: 5| Step: 6
Training loss: 5.74633672370385
Validation loss: 5.2474896923471

Epoch: 5| Step: 7
Training loss: 5.141438243043599
Validation loss: 5.243434350293014

Epoch: 5| Step: 8
Training loss: 4.850800139503606
Validation loss: 5.239282931847985

Epoch: 5| Step: 9
Training loss: 5.609876519950488
Validation loss: 5.234938823642475

Epoch: 5| Step: 10
Training loss: 4.913325947445856
Validation loss: 5.231175491489073

Epoch: 5| Step: 11
Training loss: 6.445189984631042
Validation loss: 5.227369625339369

Epoch: 12| Step: 0
Training loss: 5.585536958432347
Validation loss: 5.222969656351998

Epoch: 5| Step: 1
Training loss: 5.799630962338587
Validation loss: 5.218567035993143

Epoch: 5| Step: 2
Training loss: 5.436079519356895
Validation loss: 5.214676544518716

Epoch: 5| Step: 3
Training loss: 5.18458125719908
Validation loss: 5.210219296094766

Epoch: 5| Step: 4
Training loss: 5.328105490192928
Validation loss: 5.20648056136449

Epoch: 5| Step: 5
Training loss: 5.770416171239874
Validation loss: 5.20199020428672

Epoch: 5| Step: 6
Training loss: 5.214759808839866
Validation loss: 5.197902276803422

Epoch: 5| Step: 7
Training loss: 5.272252109247698
Validation loss: 5.193599975108454

Epoch: 5| Step: 8
Training loss: 4.76075310495543
Validation loss: 5.189667237516108

Epoch: 5| Step: 9
Training loss: 4.733719481356476
Validation loss: 5.18465941762072

Epoch: 5| Step: 10
Training loss: 5.67858254704925
Validation loss: 5.180675690422468

Epoch: 5| Step: 11
Training loss: 3.500409238595751
Validation loss: 5.176406488620944

Epoch: 13| Step: 0
Training loss: 4.9794901765354345
Validation loss: 5.1720651781779745

Epoch: 5| Step: 1
Training loss: 5.35816964254912
Validation loss: 5.168301726110001

Epoch: 5| Step: 2
Training loss: 5.572531409331257
Validation loss: 5.1638971822634545

Epoch: 5| Step: 3
Training loss: 5.244192999040142
Validation loss: 5.159775956006566

Epoch: 5| Step: 4
Training loss: 5.557341337354416
Validation loss: 5.155161740836377

Epoch: 5| Step: 5
Training loss: 4.65688672928593
Validation loss: 5.1509135673596615

Epoch: 5| Step: 6
Training loss: 5.232185292920457
Validation loss: 5.146016888555792

Epoch: 5| Step: 7
Training loss: 4.9906570882607655
Validation loss: 5.141519509264844

Epoch: 5| Step: 8
Training loss: 5.819104124247811
Validation loss: 5.1372663276169455

Epoch: 5| Step: 9
Training loss: 5.75296872665947
Validation loss: 5.131903503534556

Epoch: 5| Step: 10
Training loss: 4.67729948885282
Validation loss: 5.127530388198792

Epoch: 5| Step: 11
Training loss: 5.336547459246478
Validation loss: 5.122438837545444

Epoch: 14| Step: 0
Training loss: 5.564990225592269
Validation loss: 5.118093954856965

Epoch: 5| Step: 1
Training loss: 5.35521142565372
Validation loss: 5.113194592399457

Epoch: 5| Step: 2
Training loss: 5.303773062406589
Validation loss: 5.1084399753078475

Epoch: 5| Step: 3
Training loss: 4.796740999120808
Validation loss: 5.104882344525639

Epoch: 5| Step: 4
Training loss: 5.480960663452304
Validation loss: 5.100275591030017

Epoch: 5| Step: 5
Training loss: 4.922051901892823
Validation loss: 5.095644779828995

Epoch: 5| Step: 6
Training loss: 4.733313916842615
Validation loss: 5.090412356980137

Epoch: 5| Step: 7
Training loss: 5.601812593843876
Validation loss: 5.086414672218357

Epoch: 5| Step: 8
Training loss: 5.563354769406963
Validation loss: 5.081272139897897

Epoch: 5| Step: 9
Training loss: 5.086903095141998
Validation loss: 5.076912532725422

Epoch: 5| Step: 10
Training loss: 5.136986462249056
Validation loss: 5.071614220308643

Epoch: 5| Step: 11
Training loss: 3.8798042786775633
Validation loss: 5.066842591008858

Epoch: 15| Step: 0
Training loss: 6.197721419478051
Validation loss: 5.0633039581789445

Epoch: 5| Step: 1
Training loss: 4.764124099268147
Validation loss: 5.0594421382264105

Epoch: 5| Step: 2
Training loss: 5.384744372237711
Validation loss: 5.054879375041092

Epoch: 5| Step: 3
Training loss: 4.760977858750111
Validation loss: 5.050007205429225

Epoch: 5| Step: 4
Training loss: 4.325854866348042
Validation loss: 5.045690816834876

Epoch: 5| Step: 5
Training loss: 5.760660654963163
Validation loss: 5.041819214155022

Epoch: 5| Step: 6
Training loss: 6.380465091028398
Validation loss: 5.037506438914586

Epoch: 5| Step: 7
Training loss: 4.894407911641815
Validation loss: 5.0320766709687295

Epoch: 5| Step: 8
Training loss: 5.21396495258008
Validation loss: 5.027460562755075

Epoch: 5| Step: 9
Training loss: 4.395714684402289
Validation loss: 5.023028161757426

Epoch: 5| Step: 10
Training loss: 4.320138772572268
Validation loss: 5.019822421206956

Epoch: 5| Step: 11
Training loss: 4.709077129296989
Validation loss: 5.014805315802154

Epoch: 16| Step: 0
Training loss: 5.2432119900549745
Validation loss: 5.010388977651031

Epoch: 5| Step: 1
Training loss: 4.897925245157721
Validation loss: 5.005118547547914

Epoch: 5| Step: 2
Training loss: 5.0398397156795784
Validation loss: 5.000335984067712

Epoch: 5| Step: 3
Training loss: 4.491576469992581
Validation loss: 4.995724057658728

Epoch: 5| Step: 4
Training loss: 5.724770633817084
Validation loss: 4.990786081611536

Epoch: 5| Step: 5
Training loss: 5.061236565313694
Validation loss: 4.986142720990353

Epoch: 5| Step: 6
Training loss: 5.4268972568743115
Validation loss: 4.9816154087493025

Epoch: 5| Step: 7
Training loss: 4.740248055707493
Validation loss: 4.976714015632396

Epoch: 5| Step: 8
Training loss: 5.115364134236201
Validation loss: 4.97264712428484

Epoch: 5| Step: 9
Training loss: 4.99770207052379
Validation loss: 4.968101243185335

Epoch: 5| Step: 10
Training loss: 5.437261115778983
Validation loss: 4.9631761040686815

Epoch: 5| Step: 11
Training loss: 4.728521675569239
Validation loss: 4.958962571530753

Epoch: 17| Step: 0
Training loss: 4.972283216749951
Validation loss: 4.954157973277317

Epoch: 5| Step: 1
Training loss: 5.201828070404466
Validation loss: 4.949740957616952

Epoch: 5| Step: 2
Training loss: 5.099343066820937
Validation loss: 4.9447360312937025

Epoch: 5| Step: 3
Training loss: 5.020554446419528
Validation loss: 4.9408045305628665

Epoch: 5| Step: 4
Training loss: 5.764505417213009
Validation loss: 4.93621599829188

Epoch: 5| Step: 5
Training loss: 5.397043315867006
Validation loss: 4.931413528702758

Epoch: 5| Step: 6
Training loss: 4.644417288932526
Validation loss: 4.926917884527431

Epoch: 5| Step: 7
Training loss: 5.42551407729532
Validation loss: 4.922607875938037

Epoch: 5| Step: 8
Training loss: 4.430844756240761
Validation loss: 4.917769763608369

Epoch: 5| Step: 9
Training loss: 4.611135372930428
Validation loss: 4.91384536271519

Epoch: 5| Step: 10
Training loss: 4.401133278640007
Validation loss: 4.909013362768681

Epoch: 5| Step: 11
Training loss: 7.011103407017095
Validation loss: 4.904195991348494

Epoch: 18| Step: 0
Training loss: 5.676282615072286
Validation loss: 4.899835714518543

Epoch: 5| Step: 1
Training loss: 5.59000565502993
Validation loss: 4.8958389715067545

Epoch: 5| Step: 2
Training loss: 5.548972149772002
Validation loss: 4.891195416320198

Epoch: 5| Step: 3
Training loss: 5.1656465856489975
Validation loss: 4.886724726660327

Epoch: 5| Step: 4
Training loss: 4.704468392673716
Validation loss: 4.881896276343391

Epoch: 5| Step: 5
Training loss: 4.742561338165765
Validation loss: 4.8772913120817085

Epoch: 5| Step: 6
Training loss: 3.867787570828341
Validation loss: 4.873201348169541

Epoch: 5| Step: 7
Training loss: 4.920046705939187
Validation loss: 4.868822152905289

Epoch: 5| Step: 8
Training loss: 5.227399773241207
Validation loss: 4.863919854781155

Epoch: 5| Step: 9
Training loss: 5.118561026004155
Validation loss: 4.860137985858245

Epoch: 5| Step: 10
Training loss: 3.987161297897804
Validation loss: 4.85560997665241

Epoch: 5| Step: 11
Training loss: 5.601960363583549
Validation loss: 4.851006771412935

Epoch: 19| Step: 0
Training loss: 4.389739357894615
Validation loss: 4.846902170275236

Epoch: 5| Step: 1
Training loss: 4.898874753087238
Validation loss: 4.842714867683521

Epoch: 5| Step: 2
Training loss: 5.26929633406598
Validation loss: 4.838760102771542

Epoch: 5| Step: 3
Training loss: 4.864828600476251
Validation loss: 4.834152689357191

Epoch: 5| Step: 4
Training loss: 4.547713055015864
Validation loss: 4.830467610505844

Epoch: 5| Step: 5
Training loss: 5.6332746890173775
Validation loss: 4.825180027951741

Epoch: 5| Step: 6
Training loss: 5.021404608467969
Validation loss: 4.821234377393202

Epoch: 5| Step: 7
Training loss: 6.025779654681819
Validation loss: 4.816809396817986

Epoch: 5| Step: 8
Training loss: 4.191492483313181
Validation loss: 4.812895762696718

Epoch: 5| Step: 9
Training loss: 5.0100030021125495
Validation loss: 4.808346652911077

Epoch: 5| Step: 10
Training loss: 4.514498560235257
Validation loss: 4.80404922670452

Epoch: 5| Step: 11
Training loss: 3.804896793444554
Validation loss: 4.799571850013369

Epoch: 20| Step: 0
Training loss: 4.526053981376491
Validation loss: 4.7951314948955925

Epoch: 5| Step: 1
Training loss: 4.864168507480496
Validation loss: 4.791332352074238

Epoch: 5| Step: 2
Training loss: 4.0633811581941925
Validation loss: 4.7873888021093345

Epoch: 5| Step: 3
Training loss: 4.908988042839005
Validation loss: 4.783451105566428

Epoch: 5| Step: 4
Training loss: 5.007694046595363
Validation loss: 4.77871473160499

Epoch: 5| Step: 5
Training loss: 5.074873696244756
Validation loss: 4.774799932912139

Epoch: 5| Step: 6
Training loss: 5.3813090003276
Validation loss: 4.770513843127798

Epoch: 5| Step: 7
Training loss: 4.547708651226508
Validation loss: 4.766641318758456

Epoch: 5| Step: 8
Training loss: 5.474064974437219
Validation loss: 4.762880571099712

Epoch: 5| Step: 9
Training loss: 4.817368855930776
Validation loss: 4.7584298771530165

Epoch: 5| Step: 10
Training loss: 5.3072796472994215
Validation loss: 4.754420139577699

Epoch: 5| Step: 11
Training loss: 3.4639656132495587
Validation loss: 4.750522233463506

Epoch: 21| Step: 0
Training loss: 4.884080889945043
Validation loss: 4.746371539742114

Epoch: 5| Step: 1
Training loss: 5.129748679803362
Validation loss: 4.741692422395736

Epoch: 5| Step: 2
Training loss: 5.079141086746572
Validation loss: 4.736952936967732

Epoch: 5| Step: 3
Training loss: 4.485565771780495
Validation loss: 4.733122043975575

Epoch: 5| Step: 4
Training loss: 5.00236359996989
Validation loss: 4.728380829755524

Epoch: 5| Step: 5
Training loss: 5.061124261494002
Validation loss: 4.724436358989397

Epoch: 5| Step: 6
Training loss: 4.878850345581434
Validation loss: 4.720804571393511

Epoch: 5| Step: 7
Training loss: 4.834095642658826
Validation loss: 4.715953600409865

Epoch: 5| Step: 8
Training loss: 5.305219620770602
Validation loss: 4.712292857385897

Epoch: 5| Step: 9
Training loss: 4.389077779404474
Validation loss: 4.707419731602439

Epoch: 5| Step: 10
Training loss: 4.529308666166195
Validation loss: 4.703747417710449

Epoch: 5| Step: 11
Training loss: 3.0514438901040153
Validation loss: 4.699779490783405

Epoch: 22| Step: 0
Training loss: 4.935839023555679
Validation loss: 4.695501788106269

Epoch: 5| Step: 1
Training loss: 4.372713635974385
Validation loss: 4.691008149386015

Epoch: 5| Step: 2
Training loss: 6.059998615629837
Validation loss: 4.687027182574891

Epoch: 5| Step: 3
Training loss: 4.296947353794237
Validation loss: 4.682757161063465

Epoch: 5| Step: 4
Training loss: 5.048979990462608
Validation loss: 4.678838373671604

Epoch: 5| Step: 5
Training loss: 4.916849725623637
Validation loss: 4.674262284230168

Epoch: 5| Step: 6
Training loss: 4.080094252974946
Validation loss: 4.670339844582039

Epoch: 5| Step: 7
Training loss: 4.2609502307462455
Validation loss: 4.666051622573639

Epoch: 5| Step: 8
Training loss: 4.074331338703805
Validation loss: 4.662047747068966

Epoch: 5| Step: 9
Training loss: 5.2998436454886075
Validation loss: 4.657634768144443

Epoch: 5| Step: 10
Training loss: 4.931911927871607
Validation loss: 4.653984922732717

Epoch: 5| Step: 11
Training loss: 5.517530420147755
Validation loss: 4.649272901334736

Epoch: 23| Step: 0
Training loss: 4.516614970419288
Validation loss: 4.6450059721394705

Epoch: 5| Step: 1
Training loss: 4.595434801120841
Validation loss: 4.6410863456499625

Epoch: 5| Step: 2
Training loss: 5.480440385762755
Validation loss: 4.636454522462626

Epoch: 5| Step: 3
Training loss: 4.251975778318731
Validation loss: 4.632512340717927

Epoch: 5| Step: 4
Training loss: 4.37783786831412
Validation loss: 4.627813437185683

Epoch: 5| Step: 5
Training loss: 4.355148618419972
Validation loss: 4.623421193332929

Epoch: 5| Step: 6
Training loss: 4.75370102300699
Validation loss: 4.619527276640242

Epoch: 5| Step: 7
Training loss: 5.347953526194385
Validation loss: 4.615513187639071

Epoch: 5| Step: 8
Training loss: 5.0408801681723245
Validation loss: 4.611064657235196

Epoch: 5| Step: 9
Training loss: 4.233084506634331
Validation loss: 4.606790764310715

Epoch: 5| Step: 10
Training loss: 4.865338263518481
Validation loss: 4.602320316695157

Epoch: 5| Step: 11
Training loss: 5.84748239711087
Validation loss: 4.598640425146443

Epoch: 24| Step: 0
Training loss: 4.799029037499022
Validation loss: 4.594350641475172

Epoch: 5| Step: 1
Training loss: 4.9272060042978785
Validation loss: 4.590098566868307

Epoch: 5| Step: 2
Training loss: 4.477891654771808
Validation loss: 4.5858498109473755

Epoch: 5| Step: 3
Training loss: 4.018725433986444
Validation loss: 4.581528931227996

Epoch: 5| Step: 4
Training loss: 4.650990222790221
Validation loss: 4.577277112611293

Epoch: 5| Step: 5
Training loss: 4.23415855614653
Validation loss: 4.573180704452268

Epoch: 5| Step: 6
Training loss: 4.789124430867406
Validation loss: 4.5690553071744855

Epoch: 5| Step: 7
Training loss: 5.151951888469884
Validation loss: 4.564725354920533

Epoch: 5| Step: 8
Training loss: 5.206935461011746
Validation loss: 4.5609775162906345

Epoch: 5| Step: 9
Training loss: 4.740213451488638
Validation loss: 4.556444478081567

Epoch: 5| Step: 10
Training loss: 4.630758257871672
Validation loss: 4.552726445572324

Epoch: 5| Step: 11
Training loss: 4.421187600128751
Validation loss: 4.548274511965931

Epoch: 25| Step: 0
Training loss: 4.652213170855884
Validation loss: 4.54368468022959

Epoch: 5| Step: 1
Training loss: 5.385819302626748
Validation loss: 4.5392733167670745

Epoch: 5| Step: 2
Training loss: 4.231950917642587
Validation loss: 4.534877859459464

Epoch: 5| Step: 3
Training loss: 4.878777825258832
Validation loss: 4.530653780593494

Epoch: 5| Step: 4
Training loss: 4.3261945805696485
Validation loss: 4.526592070456935

Epoch: 5| Step: 5
Training loss: 4.091796408860355
Validation loss: 4.522192511915253

Epoch: 5| Step: 6
Training loss: 5.042626071577577
Validation loss: 4.517851732596503

Epoch: 5| Step: 7
Training loss: 4.918540575932532
Validation loss: 4.513791637188117

Epoch: 5| Step: 8
Training loss: 4.140081405945004
Validation loss: 4.509403487917628

Epoch: 5| Step: 9
Training loss: 4.783698358907434
Validation loss: 4.505532819348495

Epoch: 5| Step: 10
Training loss: 4.564517685478917
Validation loss: 4.501310413791701

Epoch: 5| Step: 11
Training loss: 4.453802545769089
Validation loss: 4.497121380278887

Epoch: 26| Step: 0
Training loss: 5.188967577609671
Validation loss: 4.493154670425279

Epoch: 5| Step: 1
Training loss: 4.668042298060759
Validation loss: 4.488895455020932

Epoch: 5| Step: 2
Training loss: 5.098668444468243
Validation loss: 4.485051306789375

Epoch: 5| Step: 3
Training loss: 4.068698790150323
Validation loss: 4.480370438153165

Epoch: 5| Step: 4
Training loss: 4.196155086985953
Validation loss: 4.476264007185676

Epoch: 5| Step: 5
Training loss: 4.332624939945674
Validation loss: 4.472178355621172

Epoch: 5| Step: 6
Training loss: 4.289752619797848
Validation loss: 4.468269304506615

Epoch: 5| Step: 7
Training loss: 4.900318423454247
Validation loss: 4.463809432281515

Epoch: 5| Step: 8
Training loss: 4.515512643228047
Validation loss: 4.459804936734945

Epoch: 5| Step: 9
Training loss: 4.1413661077626776
Validation loss: 4.455787514134184

Epoch: 5| Step: 10
Training loss: 5.207820938336998
Validation loss: 4.451537820933523

Epoch: 5| Step: 11
Training loss: 3.469352463649205
Validation loss: 4.447422592750306

Epoch: 27| Step: 0
Training loss: 4.932648991897812
Validation loss: 4.443648685636323

Epoch: 5| Step: 1
Training loss: 4.863780094897737
Validation loss: 4.439634839383742

Epoch: 5| Step: 2
Training loss: 4.232866870281692
Validation loss: 4.435541777535761

Epoch: 5| Step: 3
Training loss: 4.08876607809518
Validation loss: 4.431229329206698

Epoch: 5| Step: 4
Training loss: 4.24040170530039
Validation loss: 4.427322473985907

Epoch: 5| Step: 5
Training loss: 5.344588364540056
Validation loss: 4.423398010587882

Epoch: 5| Step: 6
Training loss: 5.279082987944356
Validation loss: 4.419013806228496

Epoch: 5| Step: 7
Training loss: 5.016591772151971
Validation loss: 4.41485777135848

Epoch: 5| Step: 8
Training loss: 3.9681412838271126
Validation loss: 4.410327206393424

Epoch: 5| Step: 9
Training loss: 4.741693159855116
Validation loss: 4.406463906437008

Epoch: 5| Step: 10
Training loss: 3.335505080058959
Validation loss: 4.4017661482130075

Epoch: 5| Step: 11
Training loss: 1.7495116506113928
Validation loss: 4.397430087732534

Epoch: 28| Step: 0
Training loss: 4.2756821562179965
Validation loss: 4.39274851716028

Epoch: 5| Step: 1
Training loss: 5.417901685721831
Validation loss: 4.388014192510121

Epoch: 5| Step: 2
Training loss: 3.724914698296126
Validation loss: 4.383014137131252

Epoch: 5| Step: 3
Training loss: 4.090788490752635
Validation loss: 4.37760010158782

Epoch: 5| Step: 4
Training loss: 4.067658655674897
Validation loss: 4.373603093704677

Epoch: 5| Step: 5
Training loss: 5.001024141329274
Validation loss: 4.369784607121884

Epoch: 5| Step: 6
Training loss: 4.65332922759508
Validation loss: 4.364768034214162

Epoch: 5| Step: 7
Training loss: 4.472688659817074
Validation loss: 4.3607295585505605

Epoch: 5| Step: 8
Training loss: 4.269000272549343
Validation loss: 4.35733528227852

Epoch: 5| Step: 9
Training loss: 4.690960230021
Validation loss: 4.353075605643028

Epoch: 5| Step: 10
Training loss: 4.7437498230865005
Validation loss: 4.348123777191135

Epoch: 5| Step: 11
Training loss: 3.5394515945739435
Validation loss: 4.343989496009379

Epoch: 29| Step: 0
Training loss: 5.36886832447689
Validation loss: 4.339507100495898

Epoch: 5| Step: 1
Training loss: 4.249466806512134
Validation loss: 4.335431016088322

Epoch: 5| Step: 2
Training loss: 4.504407419739352
Validation loss: 4.331188407705887

Epoch: 5| Step: 3
Training loss: 4.21326796778745
Validation loss: 4.326759393780381

Epoch: 5| Step: 4
Training loss: 4.937862720928197
Validation loss: 4.322700033926176

Epoch: 5| Step: 5
Training loss: 4.398379174721527
Validation loss: 4.318257331073815

Epoch: 5| Step: 6
Training loss: 4.030738029202418
Validation loss: 4.314101470067539

Epoch: 5| Step: 7
Training loss: 4.035836383115561
Validation loss: 4.309835896454596

Epoch: 5| Step: 8
Training loss: 4.083575235065402
Validation loss: 4.306273346548367

Epoch: 5| Step: 9
Training loss: 4.525961269049432
Validation loss: 4.3016870961202365

Epoch: 5| Step: 10
Training loss: 4.403468992659256
Validation loss: 4.2973335899931335

Epoch: 5| Step: 11
Training loss: 4.454209580436264
Validation loss: 4.293434383928835

Epoch: 30| Step: 0
Training loss: 5.35300451745481
Validation loss: 4.288820904966803

Epoch: 5| Step: 1
Training loss: 3.942420670141182
Validation loss: 4.283863995974626

Epoch: 5| Step: 2
Training loss: 4.347154778609735
Validation loss: 4.279501936326048

Epoch: 5| Step: 3
Training loss: 4.412055769650011
Validation loss: 4.2753766836441836

Epoch: 5| Step: 4
Training loss: 4.876028490391676
Validation loss: 4.270710927868376

Epoch: 5| Step: 5
Training loss: 3.975905328494674
Validation loss: 4.266431655347115

Epoch: 5| Step: 6
Training loss: 3.877716096996562
Validation loss: 4.261966314680623

Epoch: 5| Step: 7
Training loss: 3.6908705226746883
Validation loss: 4.257357637799466

Epoch: 5| Step: 8
Training loss: 4.608357359195229
Validation loss: 4.252860368936738

Epoch: 5| Step: 9
Training loss: 5.159703803025997
Validation loss: 4.248503477616136

Epoch: 5| Step: 10
Training loss: 3.8192551598703495
Validation loss: 4.243022319034335

Epoch: 5| Step: 11
Training loss: 4.105875476032197
Validation loss: 4.238492931699227

Epoch: 31| Step: 0
Training loss: 4.607044730086689
Validation loss: 4.233947417945545

Epoch: 5| Step: 1
Training loss: 4.772358724062735
Validation loss: 4.229811176116708

Epoch: 5| Step: 2
Training loss: 4.839416534312595
Validation loss: 4.22569269712954

Epoch: 5| Step: 3
Training loss: 4.982403308410624
Validation loss: 4.221150885395389

Epoch: 5| Step: 4
Training loss: 3.93033614218323
Validation loss: 4.216386698235216

Epoch: 5| Step: 5
Training loss: 3.815529292075547
Validation loss: 4.212320547686754

Epoch: 5| Step: 6
Training loss: 4.302929417106852
Validation loss: 4.208939582604066

Epoch: 5| Step: 7
Training loss: 4.784179189152097
Validation loss: 4.2042880664886635

Epoch: 5| Step: 8
Training loss: 3.7418983682259896
Validation loss: 4.199401950832022

Epoch: 5| Step: 9
Training loss: 4.001574921504906
Validation loss: 4.194448811940719

Epoch: 5| Step: 10
Training loss: 3.630854647152651
Validation loss: 4.190269868402319

Epoch: 5| Step: 11
Training loss: 4.824722424364739
Validation loss: 4.186657199216169

Epoch: 32| Step: 0
Training loss: 4.5044012798475865
Validation loss: 4.182109955497721

Epoch: 5| Step: 1
Training loss: 3.914261316058322
Validation loss: 4.177842252794062

Epoch: 5| Step: 2
Training loss: 4.268652431998309
Validation loss: 4.173579202481692

Epoch: 5| Step: 3
Training loss: 4.236221867904386
Validation loss: 4.1696415422059605

Epoch: 5| Step: 4
Training loss: 4.40613810079267
Validation loss: 4.16537623768025

Epoch: 5| Step: 5
Training loss: 3.9150723127407567
Validation loss: 4.161096500649216

Epoch: 5| Step: 6
Training loss: 4.432253462749693
Validation loss: 4.156694412373375

Epoch: 5| Step: 7
Training loss: 4.346714243326189
Validation loss: 4.152279719053114

Epoch: 5| Step: 8
Training loss: 4.239275472024667
Validation loss: 4.147813844707632

Epoch: 5| Step: 9
Training loss: 4.001231719156707
Validation loss: 4.1436273737925955

Epoch: 5| Step: 10
Training loss: 4.887374431431238
Validation loss: 4.13956174814439

Epoch: 5| Step: 11
Training loss: 4.1564333308808905
Validation loss: 4.135395845926113

Epoch: 33| Step: 0
Training loss: 4.539413359799155
Validation loss: 4.131097294634589

Epoch: 5| Step: 1
Training loss: 3.7994172803908004
Validation loss: 4.126984311642078

Epoch: 5| Step: 2
Training loss: 4.177016615235697
Validation loss: 4.122146274373131

Epoch: 5| Step: 3
Training loss: 4.372159417194249
Validation loss: 4.1181359064341105

Epoch: 5| Step: 4
Training loss: 4.181434907801817
Validation loss: 4.11375340489699

Epoch: 5| Step: 5
Training loss: 4.200046248408406
Validation loss: 4.109505345509818

Epoch: 5| Step: 6
Training loss: 4.199588010653963
Validation loss: 4.105290344601288

Epoch: 5| Step: 7
Training loss: 4.394636066458315
Validation loss: 4.101269210744083

Epoch: 5| Step: 8
Training loss: 4.342387253215075
Validation loss: 4.097127283293083

Epoch: 5| Step: 9
Training loss: 4.341706158732349
Validation loss: 4.092871515883959

Epoch: 5| Step: 10
Training loss: 4.300728696247368
Validation loss: 4.0884662629319735

Epoch: 5| Step: 11
Training loss: 2.8609656407020747
Validation loss: 4.084085938455522

Epoch: 34| Step: 0
Training loss: 4.309283840219413
Validation loss: 4.079666304390201

Epoch: 5| Step: 1
Training loss: 3.989723355829911
Validation loss: 4.075315469883535

Epoch: 5| Step: 2
Training loss: 4.024464655749987
Validation loss: 4.071124327198336

Epoch: 5| Step: 3
Training loss: 4.29122964553606
Validation loss: 4.066983941995625

Epoch: 5| Step: 4
Training loss: 4.225830014653233
Validation loss: 4.062933331389109

Epoch: 5| Step: 5
Training loss: 4.027475645345672
Validation loss: 4.059056025329637

Epoch: 5| Step: 6
Training loss: 4.304879795217229
Validation loss: 4.054886756072987

Epoch: 5| Step: 7
Training loss: 4.241397903611239
Validation loss: 4.050840102098987

Epoch: 5| Step: 8
Training loss: 4.2061339318414355
Validation loss: 4.046643990657899

Epoch: 5| Step: 9
Training loss: 4.6340591786062895
Validation loss: 4.042188206021218

Epoch: 5| Step: 10
Training loss: 3.846869714579914
Validation loss: 4.037911768289572

Epoch: 5| Step: 11
Training loss: 3.903280853995892
Validation loss: 4.0333309864531275

Epoch: 35| Step: 0
Training loss: 3.48549630635982
Validation loss: 4.029380428885883

Epoch: 5| Step: 1
Training loss: 4.778853869435633
Validation loss: 4.024917453803993

Epoch: 5| Step: 2
Training loss: 4.313823552130525
Validation loss: 4.020616770958817

Epoch: 5| Step: 3
Training loss: 4.198531693430134
Validation loss: 4.016345997167781

Epoch: 5| Step: 4
Training loss: 4.927315166844716
Validation loss: 4.01193244659598

Epoch: 5| Step: 5
Training loss: 3.9657357851971384
Validation loss: 4.007373480890855

Epoch: 5| Step: 6
Training loss: 4.39143423856385
Validation loss: 4.0031107737248455

Epoch: 5| Step: 7
Training loss: 4.091334438367544
Validation loss: 3.9988258545893234

Epoch: 5| Step: 8
Training loss: 3.7899124922501275
Validation loss: 3.9945147773576615

Epoch: 5| Step: 9
Training loss: 4.118721547701423
Validation loss: 3.990178960987068

Epoch: 5| Step: 10
Training loss: 3.4971316709571045
Validation loss: 3.9857097908114474

Epoch: 5| Step: 11
Training loss: 2.6231872112031067
Validation loss: 3.981506506872427

Epoch: 36| Step: 0
Training loss: 4.1223318545239955
Validation loss: 3.9773988874663955

Epoch: 5| Step: 1
Training loss: 4.024294508241476
Validation loss: 3.9732236803902006

Epoch: 5| Step: 2
Training loss: 3.9128247891006054
Validation loss: 3.9692283552348133

Epoch: 5| Step: 3
Training loss: 4.38999201328533
Validation loss: 3.9653563470325484

Epoch: 5| Step: 4
Training loss: 3.496803049773992
Validation loss: 3.9608996839053634

Epoch: 5| Step: 5
Training loss: 4.168659471160846
Validation loss: 3.956922046978402

Epoch: 5| Step: 6
Training loss: 3.98935008881955
Validation loss: 3.952735957124546

Epoch: 5| Step: 7
Training loss: 3.845150824119841
Validation loss: 3.9484413707509383

Epoch: 5| Step: 8
Training loss: 4.358785391145057
Validation loss: 3.9444704825403036

Epoch: 5| Step: 9
Training loss: 4.534718626266593
Validation loss: 3.940189578317052

Epoch: 5| Step: 10
Training loss: 4.218022488631327
Validation loss: 3.9360857800473465

Epoch: 5| Step: 11
Training loss: 3.125189966149886
Validation loss: 3.9318634187374895

Epoch: 37| Step: 0
Training loss: 3.737039804354325
Validation loss: 3.9275434293638414

Epoch: 5| Step: 1
Training loss: 4.429446582196937
Validation loss: 3.92370443748877

Epoch: 5| Step: 2
Training loss: 4.016570339920891
Validation loss: 3.9195047538966294

Epoch: 5| Step: 3
Training loss: 4.304188998897751
Validation loss: 3.9154552233139466

Epoch: 5| Step: 4
Training loss: 3.8759036087317353
Validation loss: 3.911100052003024

Epoch: 5| Step: 5
Training loss: 4.582936957588067
Validation loss: 3.9069479865497967

Epoch: 5| Step: 6
Training loss: 3.5834433664387153
Validation loss: 3.9025150346761657

Epoch: 5| Step: 7
Training loss: 3.5407578742202266
Validation loss: 3.8983581983391136

Epoch: 5| Step: 8
Training loss: 4.208540480145398
Validation loss: 3.8941746442927916

Epoch: 5| Step: 9
Training loss: 4.434934922421442
Validation loss: 3.8900526052103475

Epoch: 5| Step: 10
Training loss: 3.7765139089353723
Validation loss: 3.8858280458413663

Epoch: 5| Step: 11
Training loss: 2.9150498586483495
Validation loss: 3.881630797653808

Epoch: 38| Step: 0
Training loss: 3.4864848638611092
Validation loss: 3.877688782509334

Epoch: 5| Step: 1
Training loss: 4.220329384626997
Validation loss: 3.873745079287694

Epoch: 5| Step: 2
Training loss: 3.6868881752514655
Validation loss: 3.869655271293924

Epoch: 5| Step: 3
Training loss: 4.148783696271386
Validation loss: 3.865713302191748

Epoch: 5| Step: 4
Training loss: 4.482455277993732
Validation loss: 3.8617949884508627

Epoch: 5| Step: 5
Training loss: 3.8039863457339425
Validation loss: 3.857697347470257

Epoch: 5| Step: 6
Training loss: 3.936000356743959
Validation loss: 3.853499017915872

Epoch: 5| Step: 7
Training loss: 3.963827609935763
Validation loss: 3.8492635297070676

Epoch: 5| Step: 8
Training loss: 3.467366260460479
Validation loss: 3.8449084027611202

Epoch: 5| Step: 9
Training loss: 4.024477926005346
Validation loss: 3.8409557472221594

Epoch: 5| Step: 10
Training loss: 4.774202825500668
Validation loss: 3.8369411442630144

Epoch: 5| Step: 11
Training loss: 2.1098199445727226
Validation loss: 3.8326505108148483

Epoch: 39| Step: 0
Training loss: 4.30064598376634
Validation loss: 3.8285658083025846

Epoch: 5| Step: 1
Training loss: 3.6445773041034455
Validation loss: 3.8244137167141035

Epoch: 5| Step: 2
Training loss: 4.521764468916256
Validation loss: 3.820137285142328

Epoch: 5| Step: 3
Training loss: 3.5962896246876768
Validation loss: 3.8160355699298916

Epoch: 5| Step: 4
Training loss: 3.8110144800948573
Validation loss: 3.8117766606103696

Epoch: 5| Step: 5
Training loss: 4.75198162303929
Validation loss: 3.807494175957216

Epoch: 5| Step: 6
Training loss: 3.8878786742820948
Validation loss: 3.803182122651254

Epoch: 5| Step: 7
Training loss: 3.9578999867730174
Validation loss: 3.7988262055562982

Epoch: 5| Step: 8
Training loss: 3.7586491341436266
Validation loss: 3.794301310643533

Epoch: 5| Step: 9
Training loss: 2.8869354620955225
Validation loss: 3.7903150238323087

Epoch: 5| Step: 10
Training loss: 3.753865602017181
Validation loss: 3.7862226875506417

Epoch: 5| Step: 11
Training loss: 4.8154109721612075
Validation loss: 3.7823589422276176

Epoch: 40| Step: 0
Training loss: 4.433445327223786
Validation loss: 3.7777073924124243

Epoch: 5| Step: 1
Training loss: 4.38727569441434
Validation loss: 3.7733892275800787

Epoch: 5| Step: 2
Training loss: 3.8092183231870043
Validation loss: 3.768613861138716

Epoch: 5| Step: 3
Training loss: 3.5047530189815173
Validation loss: 3.763890010501996

Epoch: 5| Step: 4
Training loss: 3.2400351124497444
Validation loss: 3.7596733630201022

Epoch: 5| Step: 5
Training loss: 4.099723592605556
Validation loss: 3.7549111578921037

Epoch: 5| Step: 6
Training loss: 4.224840529101411
Validation loss: 3.7506361845578944

Epoch: 5| Step: 7
Training loss: 3.7892742923653286
Validation loss: 3.7450451223509744

Epoch: 5| Step: 8
Training loss: 4.385602256973615
Validation loss: 3.740240770671479

Epoch: 5| Step: 9
Training loss: 3.2445552407105005
Validation loss: 3.7355826379115262

Epoch: 5| Step: 10
Training loss: 3.4185024694902784
Validation loss: 3.7314731597194073

Epoch: 5| Step: 11
Training loss: 3.883770891568631
Validation loss: 3.727255345627898

Epoch: 41| Step: 0
Training loss: 2.649089631669233
Validation loss: 3.723099502374561

Epoch: 5| Step: 1
Training loss: 4.12480348061118
Validation loss: 3.7191012240689574

Epoch: 5| Step: 2
Training loss: 3.710301908974161
Validation loss: 3.7153249082022004

Epoch: 5| Step: 3
Training loss: 3.8440394098760455
Validation loss: 3.7116861545226434

Epoch: 5| Step: 4
Training loss: 3.2823124210077204
Validation loss: 3.7067621774569273

Epoch: 5| Step: 5
Training loss: 4.242067001626573
Validation loss: 3.7026482501884397

Epoch: 5| Step: 6
Training loss: 4.043928214955706
Validation loss: 3.6987595828749646

Epoch: 5| Step: 7
Training loss: 4.036428983848271
Validation loss: 3.6936039325042245

Epoch: 5| Step: 8
Training loss: 3.5688941191585735
Validation loss: 3.6892149811183215

Epoch: 5| Step: 9
Training loss: 4.403936549839219
Validation loss: 3.6845222562353346

Epoch: 5| Step: 10
Training loss: 4.143917056207277
Validation loss: 3.6819346343407457

Epoch: 5| Step: 11
Training loss: 2.90187399593667
Validation loss: 3.6774324336048294

Epoch: 42| Step: 0
Training loss: 4.606315606114584
Validation loss: 3.6725424680684546

Epoch: 5| Step: 1
Training loss: 3.6070118223397913
Validation loss: 3.6710440107949704

Epoch: 5| Step: 2
Training loss: 3.8966147035299903
Validation loss: 3.668186407432652

Epoch: 5| Step: 3
Training loss: 3.917966072484753
Validation loss: 3.6623872290425683

Epoch: 5| Step: 4
Training loss: 3.113946515730807
Validation loss: 3.6565048313725343

Epoch: 5| Step: 5
Training loss: 3.7888739784770187
Validation loss: 3.651770912983831

Epoch: 5| Step: 6
Training loss: 3.7581714609364703
Validation loss: 3.6472822125967976

Epoch: 5| Step: 7
Training loss: 3.8081233433454234
Validation loss: 3.64235510258421

Epoch: 5| Step: 8
Training loss: 3.490125213606645
Validation loss: 3.6380076625460864

Epoch: 5| Step: 9
Training loss: 3.0650098208694807
Validation loss: 3.634074117156629

Epoch: 5| Step: 10
Training loss: 4.016536386574598
Validation loss: 3.630304385446505

Epoch: 5| Step: 11
Training loss: 5.386637133117641
Validation loss: 3.6264381734718985

Epoch: 43| Step: 0
Training loss: 4.0438140722561124
Validation loss: 3.622989266786708

Epoch: 5| Step: 1
Training loss: 4.130582326702376
Validation loss: 3.6179835718518936

Epoch: 5| Step: 2
Training loss: 3.9733103585912435
Validation loss: 3.6129998119824744

Epoch: 5| Step: 3
Training loss: 2.8729542627195985
Validation loss: 3.608312431139823

Epoch: 5| Step: 4
Training loss: 3.566080669737943
Validation loss: 3.6044946348584554

Epoch: 5| Step: 5
Training loss: 3.9914551303907153
Validation loss: 3.5997224742710308

Epoch: 5| Step: 6
Training loss: 3.656283386599704
Validation loss: 3.5953154485282317

Epoch: 5| Step: 7
Training loss: 3.1466794086726337
Validation loss: 3.590951194587683

Epoch: 5| Step: 8
Training loss: 4.017611120048638
Validation loss: 3.587580850733531

Epoch: 5| Step: 9
Training loss: 3.867094034934296
Validation loss: 3.582431572551009

Epoch: 5| Step: 10
Training loss: 3.644957489896064
Validation loss: 3.5777272721063302

Epoch: 5| Step: 11
Training loss: 3.7062986271001734
Validation loss: 3.5736109176787574

Epoch: 44| Step: 0
Training loss: 3.935917006284417
Validation loss: 3.5705612006959844

Epoch: 5| Step: 1
Training loss: 3.767653176295311
Validation loss: 3.565461812588158

Epoch: 5| Step: 2
Training loss: 3.2818062447047667
Validation loss: 3.561893550942525

Epoch: 5| Step: 3
Training loss: 3.527810641425207
Validation loss: 3.557586854087568

Epoch: 5| Step: 4
Training loss: 3.9014000653730414
Validation loss: 3.5533687674566963

Epoch: 5| Step: 5
Training loss: 3.514637855117439
Validation loss: 3.549876731200959

Epoch: 5| Step: 6
Training loss: 3.591791299190207
Validation loss: 3.5450962608747747

Epoch: 5| Step: 7
Training loss: 3.9496201972409466
Validation loss: 3.541346909543187

Epoch: 5| Step: 8
Training loss: 3.833471682719453
Validation loss: 3.5373378590694924

Epoch: 5| Step: 9
Training loss: 3.502541028367192
Validation loss: 3.5330733371540455

Epoch: 5| Step: 10
Training loss: 3.725337628930286
Validation loss: 3.5287878629621736

Epoch: 5| Step: 11
Training loss: 3.4950489720745983
Validation loss: 3.524849996914794

Epoch: 45| Step: 0
Training loss: 3.603200941120926
Validation loss: 3.5208878296616684

Epoch: 5| Step: 1
Training loss: 3.9596586852898947
Validation loss: 3.5167957645301375

Epoch: 5| Step: 2
Training loss: 4.3640656205933395
Validation loss: 3.5126466186530765

Epoch: 5| Step: 3
Training loss: 3.7636067533773216
Validation loss: 3.508154169221102

Epoch: 5| Step: 4
Training loss: 2.9029298911832164
Validation loss: 3.5039116566310464

Epoch: 5| Step: 5
Training loss: 4.025119822359402
Validation loss: 3.499466821385984

Epoch: 5| Step: 6
Training loss: 3.237878643266376
Validation loss: 3.4953097922516863

Epoch: 5| Step: 7
Training loss: 3.1858896413728512
Validation loss: 3.49102830529191

Epoch: 5| Step: 8
Training loss: 3.9680924959784676
Validation loss: 3.48710080941944

Epoch: 5| Step: 9
Training loss: 3.2938140110115115
Validation loss: 3.482797148533642

Epoch: 5| Step: 10
Training loss: 3.345205827889343
Validation loss: 3.478892102324471

Epoch: 5| Step: 11
Training loss: 4.196348037642653
Validation loss: 3.475340976498374

Epoch: 46| Step: 0
Training loss: 3.991495987037764
Validation loss: 3.47146084681874

Epoch: 5| Step: 1
Training loss: 3.6051589981549412
Validation loss: 3.4670699865372114

Epoch: 5| Step: 2
Training loss: 3.7420638985818155
Validation loss: 3.4626680615674093

Epoch: 5| Step: 3
Training loss: 3.256495220886594
Validation loss: 3.4584429026485353

Epoch: 5| Step: 4
Training loss: 3.46996031944607
Validation loss: 3.453452737712649

Epoch: 5| Step: 5
Training loss: 3.6520172136366953
Validation loss: 3.4475406382136313

Epoch: 5| Step: 6
Training loss: 3.3957687246967243
Validation loss: 3.443684216959707

Epoch: 5| Step: 7
Training loss: 3.9658892075322654
Validation loss: 3.4393531197012464

Epoch: 5| Step: 8
Training loss: 3.112732574475391
Validation loss: 3.434915160307209

Epoch: 5| Step: 9
Training loss: 3.8190294229073736
Validation loss: 3.4331235885594067

Epoch: 5| Step: 10
Training loss: 3.336237373542547
Validation loss: 3.4265959237517247

Epoch: 5| Step: 11
Training loss: 3.6759009833298837
Validation loss: 3.427158979066083

Epoch: 47| Step: 0
Training loss: 3.3316375392488493
Validation loss: 3.429482340197939

Epoch: 5| Step: 1
Training loss: 3.8465701046684946
Validation loss: 3.431619810918028

Epoch: 5| Step: 2
Training loss: 3.527961482540596
Validation loss: 3.4136953905771565

Epoch: 5| Step: 3
Training loss: 3.8162606874348155
Validation loss: 3.4072204572295455

Epoch: 5| Step: 4
Training loss: 3.0853034418329157
Validation loss: 3.404544099843044

Epoch: 5| Step: 5
Training loss: 3.4320524573240747
Validation loss: 3.407337341811031

Epoch: 5| Step: 6
Training loss: 3.363670548117698
Validation loss: 3.4064221703183413

Epoch: 5| Step: 7
Training loss: 4.1823434537513435
Validation loss: 3.3997787196715428

Epoch: 5| Step: 8
Training loss: 3.2623916023340884
Validation loss: 3.393398310948532

Epoch: 5| Step: 9
Training loss: 3.3386743829605505
Validation loss: 3.386316007832351

Epoch: 5| Step: 10
Training loss: 3.5028998759447227
Validation loss: 3.382637418778259

Epoch: 5| Step: 11
Training loss: 4.2732714632964095
Validation loss: 3.3794134975710066

Epoch: 48| Step: 0
Training loss: 3.2889504311648827
Validation loss: 3.3760297022749444

Epoch: 5| Step: 1
Training loss: 4.148750824958372
Validation loss: 3.373027419325178

Epoch: 5| Step: 2
Training loss: 4.11141441417761
Validation loss: 3.3691981302412413

Epoch: 5| Step: 3
Training loss: 2.827755814371041
Validation loss: 3.3647005023376164

Epoch: 5| Step: 4
Training loss: 3.812510380965311
Validation loss: 3.360134316912143

Epoch: 5| Step: 5
Training loss: 2.8982608052400027
Validation loss: 3.354727263822757

Epoch: 5| Step: 6
Training loss: 3.1200077616766215
Validation loss: 3.350319531844945

Epoch: 5| Step: 7
Training loss: 3.361752258885546
Validation loss: 3.3463047345539083

Epoch: 5| Step: 8
Training loss: 2.7141253721589793
Validation loss: 3.3424632843975983

Epoch: 5| Step: 9
Training loss: 3.567794078529756
Validation loss: 3.3390046908001105

Epoch: 5| Step: 10
Training loss: 4.22596812696303
Validation loss: 3.335706424378103

Epoch: 5| Step: 11
Training loss: 3.1901123711097727
Validation loss: 3.33168473105871

Epoch: 49| Step: 0
Training loss: 3.3158158314803763
Validation loss: 3.327565016222402

Epoch: 5| Step: 1
Training loss: 3.8038057092654367
Validation loss: 3.3237301579103473

Epoch: 5| Step: 2
Training loss: 3.459697561551765
Validation loss: 3.320270062343687

Epoch: 5| Step: 3
Training loss: 2.875635988960254
Validation loss: 3.3163127489093047

Epoch: 5| Step: 4
Training loss: 4.316028423084926
Validation loss: 3.3126386157608967

Epoch: 5| Step: 5
Training loss: 3.5237670203018103
Validation loss: 3.308911509081782

Epoch: 5| Step: 6
Training loss: 3.590775560852832
Validation loss: 3.3051475403095263

Epoch: 5| Step: 7
Training loss: 3.2800311049870574
Validation loss: 3.3013113013847954

Epoch: 5| Step: 8
Training loss: 3.353217296627721
Validation loss: 3.2979637806929465

Epoch: 5| Step: 9
Training loss: 3.0689960015980318
Validation loss: 3.2941623996585068

Epoch: 5| Step: 10
Training loss: 3.2941003486435556
Validation loss: 3.2905332670258955

Epoch: 5| Step: 11
Training loss: 2.639918215814222
Validation loss: 3.286994513508723

Epoch: 50| Step: 0
Training loss: 3.3508480706626456
Validation loss: 3.2838331318160665

Epoch: 5| Step: 1
Training loss: 3.873802984613264
Validation loss: 3.280626031797081

Epoch: 5| Step: 2
Training loss: 3.738186347737383
Validation loss: 3.2770594525462404

Epoch: 5| Step: 3
Training loss: 3.2310101241127582
Validation loss: 3.273550227370562

Epoch: 5| Step: 4
Training loss: 2.547224523981687
Validation loss: 3.2700117298230817

Epoch: 5| Step: 5
Training loss: 3.6198104016301738
Validation loss: 3.266519344950668

Epoch: 5| Step: 6
Training loss: 3.2118561630156877
Validation loss: 3.263304334514255

Epoch: 5| Step: 7
Training loss: 3.250063088611674
Validation loss: 3.260093622179721

Epoch: 5| Step: 8
Training loss: 3.268446292225273
Validation loss: 3.2569752172974282

Epoch: 5| Step: 9
Training loss: 3.489056918545063
Validation loss: 3.2536357631357546

Epoch: 5| Step: 10
Training loss: 3.7417593374578657
Validation loss: 3.250355089792059

Epoch: 5| Step: 11
Training loss: 3.2561308914043994
Validation loss: 3.246998170897377

Epoch: 51| Step: 0
Training loss: 3.9981139027875487
Validation loss: 3.2440310158644228

Epoch: 5| Step: 1
Training loss: 2.943179220598118
Validation loss: 3.240747436839457

Epoch: 5| Step: 2
Training loss: 3.4568202067467237
Validation loss: 3.2377346545376553

Epoch: 5| Step: 3
Training loss: 3.058968512521125
Validation loss: 3.23463851051847

Epoch: 5| Step: 4
Training loss: 3.399525014572923
Validation loss: 3.2314675757758597

Epoch: 5| Step: 5
Training loss: 3.260763391618313
Validation loss: 3.2282937479981197

Epoch: 5| Step: 6
Training loss: 3.3329312717826567
Validation loss: 3.2252106532463536

Epoch: 5| Step: 7
Training loss: 3.1984768520780027
Validation loss: 3.221936534314939

Epoch: 5| Step: 8
Training loss: 3.354645989014174
Validation loss: 3.2188503718852473

Epoch: 5| Step: 9
Training loss: 3.5946959204327666
Validation loss: 3.215829956769262

Epoch: 5| Step: 10
Training loss: 3.515122169986995
Validation loss: 3.212645065060315

Epoch: 5| Step: 11
Training loss: 2.4467395847309747
Validation loss: 3.209466245989093

Epoch: 52| Step: 0
Training loss: 3.4431833621438517
Validation loss: 3.206623272921086

Epoch: 5| Step: 1
Training loss: 3.72117766310323
Validation loss: 3.2036273531359294

Epoch: 5| Step: 2
Training loss: 3.2597659175591542
Validation loss: 3.200509357147293

Epoch: 5| Step: 3
Training loss: 3.264074952433688
Validation loss: 3.1975864504992257

Epoch: 5| Step: 4
Training loss: 3.4412099065637825
Validation loss: 3.194432781838583

Epoch: 5| Step: 5
Training loss: 3.1402086579795
Validation loss: 3.1915492598118522

Epoch: 5| Step: 6
Training loss: 2.4714369818609696
Validation loss: 3.188570634389846

Epoch: 5| Step: 7
Training loss: 3.427514293593549
Validation loss: 3.1859375826923086

Epoch: 5| Step: 8
Training loss: 3.1497622748392438
Validation loss: 3.183039882667119

Epoch: 5| Step: 9
Training loss: 3.6158943254001406
Validation loss: 3.180369273583552

Epoch: 5| Step: 10
Training loss: 3.4863770895546122
Validation loss: 3.17726379048799

Epoch: 5| Step: 11
Training loss: 3.6690951599273816
Validation loss: 3.17408645282829

Epoch: 53| Step: 0
Training loss: 3.2621381478587526
Validation loss: 3.1709693780922428

Epoch: 5| Step: 1
Training loss: 3.3682273445146094
Validation loss: 3.1676675925394133

Epoch: 5| Step: 2
Training loss: 4.081323531278521
Validation loss: 3.1645404627350757

Epoch: 5| Step: 3
Training loss: 2.552560556648015
Validation loss: 3.1611398675804696

Epoch: 5| Step: 4
Training loss: 3.150070940460173
Validation loss: 3.1580703603644458

Epoch: 5| Step: 5
Training loss: 3.018222935000622
Validation loss: 3.155128966061928

Epoch: 5| Step: 6
Training loss: 3.4249894413472055
Validation loss: 3.1520187859608755

Epoch: 5| Step: 7
Training loss: 3.5882891753923336
Validation loss: 3.148889122716691

Epoch: 5| Step: 8
Training loss: 3.595562950273896
Validation loss: 3.1459428608166187

Epoch: 5| Step: 9
Training loss: 2.8312514079850426
Validation loss: 3.142719746890198

Epoch: 5| Step: 10
Training loss: 3.162465537867289
Validation loss: 3.1396450456014597

Epoch: 5| Step: 11
Training loss: 3.1367474812371117
Validation loss: 3.1365141906798346

Epoch: 54| Step: 0
Training loss: 3.5428052231504528
Validation loss: 3.133394195256386

Epoch: 5| Step: 1
Training loss: 2.8375061572844125
Validation loss: 3.1301676683540247

Epoch: 5| Step: 2
Training loss: 3.4819108263896834
Validation loss: 3.1272480698681027

Epoch: 5| Step: 3
Training loss: 3.21320435635796
Validation loss: 3.1244158357761185

Epoch: 5| Step: 4
Training loss: 3.216723646802358
Validation loss: 3.121414963764377

Epoch: 5| Step: 5
Training loss: 3.734224835173815
Validation loss: 3.118573431216432

Epoch: 5| Step: 6
Training loss: 2.869390903928201
Validation loss: 3.1154394833637924

Epoch: 5| Step: 7
Training loss: 2.8222086019596166
Validation loss: 3.1122991591564944

Epoch: 5| Step: 8
Training loss: 3.0364657489736224
Validation loss: 3.109560470544714

Epoch: 5| Step: 9
Training loss: 3.392156580252983
Validation loss: 3.1066598523321716

Epoch: 5| Step: 10
Training loss: 3.3886153070746787
Validation loss: 3.1042648796998233

Epoch: 5| Step: 11
Training loss: 4.048342405591473
Validation loss: 3.1008405029243375

Epoch: 55| Step: 0
Training loss: 3.184657156800377
Validation loss: 3.0976462923253067

Epoch: 5| Step: 1
Training loss: 3.109541845398008
Validation loss: 3.095045412554177

Epoch: 5| Step: 2
Training loss: 2.47554789557186
Validation loss: 3.092456232427827

Epoch: 5| Step: 3
Training loss: 3.516930909797915
Validation loss: 3.0890623536123556

Epoch: 5| Step: 4
Training loss: 2.8765513339595206
Validation loss: 3.086390060526283

Epoch: 5| Step: 5
Training loss: 3.271809539577303
Validation loss: 3.0829805492363316

Epoch: 5| Step: 6
Training loss: 2.9338872892213312
Validation loss: 3.080358727509359

Epoch: 5| Step: 7
Training loss: 3.39737069058602
Validation loss: 3.0769619850417587

Epoch: 5| Step: 8
Training loss: 3.44031340169466
Validation loss: 3.073947304775129

Epoch: 5| Step: 9
Training loss: 3.549986831210789
Validation loss: 3.071358923832624

Epoch: 5| Step: 10
Training loss: 3.3653745085176725
Validation loss: 3.067915944499091

Epoch: 5| Step: 11
Training loss: 3.962022019688567
Validation loss: 3.065167235463192

Epoch: 56| Step: 0
Training loss: 3.2272680956603357
Validation loss: 3.0617964903175108

Epoch: 5| Step: 1
Training loss: 3.792401476632048
Validation loss: 3.0596326555202875

Epoch: 5| Step: 2
Training loss: 3.204599478418112
Validation loss: 3.056865400310827

Epoch: 5| Step: 3
Training loss: 3.4585236339988645
Validation loss: 3.0531505903813407

Epoch: 5| Step: 4
Training loss: 2.822261316632741
Validation loss: 3.0503244029473566

Epoch: 5| Step: 5
Training loss: 3.0227273900624563
Validation loss: 3.0475259656063343

Epoch: 5| Step: 6
Training loss: 3.1097385826511528
Validation loss: 3.044757084101433

Epoch: 5| Step: 7
Training loss: 2.986885333174053
Validation loss: 3.041257952747538

Epoch: 5| Step: 8
Training loss: 2.818534903767144
Validation loss: 3.0384217430950415

Epoch: 5| Step: 9
Training loss: 3.3415991023995124
Validation loss: 3.036200554420108

Epoch: 5| Step: 10
Training loss: 3.4071158612265138
Validation loss: 3.0328202260787167

Epoch: 5| Step: 11
Training loss: 1.7829539531253897
Validation loss: 3.0298749059457855

Epoch: 57| Step: 0
Training loss: 3.468890625448673
Validation loss: 3.02774870102207

Epoch: 5| Step: 1
Training loss: 3.0534524982081312
Validation loss: 3.0247555306854874

Epoch: 5| Step: 2
Training loss: 2.614394972704626
Validation loss: 3.0224752808920226

Epoch: 5| Step: 3
Training loss: 3.6529327733589194
Validation loss: 3.0199824132259865

Epoch: 5| Step: 4
Training loss: 3.1487788543045427
Validation loss: 3.0175700528099623

Epoch: 5| Step: 5
Training loss: 3.795413893895706
Validation loss: 3.0152003429047523

Epoch: 5| Step: 6
Training loss: 3.0050764049394694
Validation loss: 3.0122208199463962

Epoch: 5| Step: 7
Training loss: 3.057923615024932
Validation loss: 3.0099670124939455

Epoch: 5| Step: 8
Training loss: 2.4732544764400433
Validation loss: 3.006105660339382

Epoch: 5| Step: 9
Training loss: 3.247032130884538
Validation loss: 3.0043377080700195

Epoch: 5| Step: 10
Training loss: 2.909133465141359
Validation loss: 3.0059833496913915

Epoch: 5| Step: 11
Training loss: 3.4977471049055975
Validation loss: 3.0018633248062874

Epoch: 58| Step: 0
Training loss: 3.104658680951502
Validation loss: 2.997211478248158

Epoch: 5| Step: 1
Training loss: 2.5787498872787444
Validation loss: 2.9954499237210213

Epoch: 5| Step: 2
Training loss: 3.0648822471812704
Validation loss: 2.993095373098795

Epoch: 5| Step: 3
Training loss: 3.1462391639980574
Validation loss: 2.9913397369070385

Epoch: 5| Step: 4
Training loss: 3.358475817615021
Validation loss: 2.989316391186582

Epoch: 5| Step: 5
Training loss: 3.3323602368636527
Validation loss: 2.986747607451697

Epoch: 5| Step: 6
Training loss: 3.050000744178556
Validation loss: 2.9843763680979203

Epoch: 5| Step: 7
Training loss: 2.9475825539401743
Validation loss: 2.9822219884906773

Epoch: 5| Step: 8
Training loss: 3.179662605956759
Validation loss: 2.980677066187448

Epoch: 5| Step: 9
Training loss: 3.2824980769039196
Validation loss: 2.9781292040362577

Epoch: 5| Step: 10
Training loss: 3.330643395022152
Validation loss: 2.97520023120911

Epoch: 5| Step: 11
Training loss: 2.9037249681212445
Validation loss: 2.9730944316800962

Epoch: 59| Step: 0
Training loss: 3.1950992429121987
Validation loss: 2.9707316560898778

Epoch: 5| Step: 1
Training loss: 2.6715411596709795
Validation loss: 2.9676801092149807

Epoch: 5| Step: 2
Training loss: 2.7836583029654443
Validation loss: 2.9660246034162503

Epoch: 5| Step: 3
Training loss: 2.9037415538571403
Validation loss: 2.963335896048566

Epoch: 5| Step: 4
Training loss: 3.7283104849603963
Validation loss: 2.960593784885239

Epoch: 5| Step: 5
Training loss: 3.3217958256068423
Validation loss: 2.958159959888616

Epoch: 5| Step: 6
Training loss: 3.0546434794422446
Validation loss: 2.955933559033453

Epoch: 5| Step: 7
Training loss: 3.025033455655807
Validation loss: 2.953306047921329

Epoch: 5| Step: 8
Training loss: 3.498754688517382
Validation loss: 2.9512566470769177

Epoch: 5| Step: 9
Training loss: 2.9566922717901294
Validation loss: 2.9502276953685977

Epoch: 5| Step: 10
Training loss: 2.6862231037822335
Validation loss: 2.9467974426376324

Epoch: 5| Step: 11
Training loss: 3.557507681070964
Validation loss: 2.944013118391162

Epoch: 60| Step: 0
Training loss: 3.610040776664398
Validation loss: 2.9416252551167235

Epoch: 5| Step: 1
Training loss: 3.1355808422073217
Validation loss: 2.938764671906722

Epoch: 5| Step: 2
Training loss: 2.9364180499982404
Validation loss: 2.935847737589819

Epoch: 5| Step: 3
Training loss: 2.8632862460520876
Validation loss: 2.933045787742831

Epoch: 5| Step: 4
Training loss: 2.8926943408562167
Validation loss: 2.9310567207843694

Epoch: 5| Step: 5
Training loss: 3.0587259510062967
Validation loss: 2.929819675430938

Epoch: 5| Step: 6
Training loss: 3.28836146334104
Validation loss: 2.927406888209122

Epoch: 5| Step: 7
Training loss: 2.733451033205797
Validation loss: 2.9242436740773448

Epoch: 5| Step: 8
Training loss: 3.3857830299310443
Validation loss: 2.9219189196870956

Epoch: 5| Step: 9
Training loss: 2.8923384253528255
Validation loss: 2.9187476715634064

Epoch: 5| Step: 10
Training loss: 2.8536369407604836
Validation loss: 2.916215409838004

Epoch: 5| Step: 11
Training loss: 3.142389665243243
Validation loss: 2.914395334635184

Epoch: 61| Step: 0
Training loss: 3.0023112930342117
Validation loss: 2.912040404320231

Epoch: 5| Step: 1
Training loss: 2.5171768425041594
Validation loss: 2.910332809656458

Epoch: 5| Step: 2
Training loss: 2.705458587442336
Validation loss: 2.908002113310909

Epoch: 5| Step: 3
Training loss: 3.139400718017076
Validation loss: 2.907280137765774

Epoch: 5| Step: 4
Training loss: 3.6489239190769536
Validation loss: 2.904906512685937

Epoch: 5| Step: 5
Training loss: 2.8606559510710037
Validation loss: 2.9038277653147393

Epoch: 5| Step: 6
Training loss: 3.2151274805023435
Validation loss: 2.901758147727062

Epoch: 5| Step: 7
Training loss: 3.415940665049121
Validation loss: 2.8986671027782287

Epoch: 5| Step: 8
Training loss: 3.3316983663766147
Validation loss: 2.89709873247674

Epoch: 5| Step: 9
Training loss: 3.017652393402399
Validation loss: 2.8947270095941873

Epoch: 5| Step: 10
Training loss: 2.4898213122493655
Validation loss: 2.892284600791625

Epoch: 5| Step: 11
Training loss: 2.646015781710178
Validation loss: 2.890777735068736

Epoch: 62| Step: 0
Training loss: 3.041223537268791
Validation loss: 2.8881439627612573

Epoch: 5| Step: 1
Training loss: 3.118261472552623
Validation loss: 2.8861218955146795

Epoch: 5| Step: 2
Training loss: 3.2102234132211063
Validation loss: 2.8827419703125314

Epoch: 5| Step: 3
Training loss: 3.028448954005433
Validation loss: 2.8804316868099114

Epoch: 5| Step: 4
Training loss: 2.7608889961407774
Validation loss: 2.878486778724553

Epoch: 5| Step: 5
Training loss: 2.914558920622849
Validation loss: 2.8745912765829633

Epoch: 5| Step: 6
Training loss: 3.0415170362761423
Validation loss: 2.872331974199288

Epoch: 5| Step: 7
Training loss: 3.0883189609424413
Validation loss: 2.8705556905961473

Epoch: 5| Step: 8
Training loss: 3.058764456592813
Validation loss: 2.8684109841393677

Epoch: 5| Step: 9
Training loss: 3.0807449886445637
Validation loss: 2.867741315610205

Epoch: 5| Step: 10
Training loss: 2.993342323657881
Validation loss: 2.8654969278639824

Epoch: 5| Step: 11
Training loss: 2.1983020559095405
Validation loss: 2.864204528500259

Epoch: 63| Step: 0
Training loss: 3.08912714040115
Validation loss: 2.8626135602300233

Epoch: 5| Step: 1
Training loss: 3.0233504408492897
Validation loss: 2.862440307555618

Epoch: 5| Step: 2
Training loss: 2.871646085795642
Validation loss: 2.861421356591793

Epoch: 5| Step: 3
Training loss: 3.0972232010806087
Validation loss: 2.859649839551017

Epoch: 5| Step: 4
Training loss: 2.8152108585396496
Validation loss: 2.857647660696339

Epoch: 5| Step: 5
Training loss: 3.1098058967488793
Validation loss: 2.855135089742482

Epoch: 5| Step: 6
Training loss: 2.8240861241605266
Validation loss: 2.8549439921733857

Epoch: 5| Step: 7
Training loss: 3.418400363373419
Validation loss: 2.8525026626641354

Epoch: 5| Step: 8
Training loss: 2.5092619037914012
Validation loss: 2.8500740625841487

Epoch: 5| Step: 9
Training loss: 2.8448133890800227
Validation loss: 2.848953049472928

Epoch: 5| Step: 10
Training loss: 3.142840159357925
Validation loss: 2.84681527723806

Epoch: 5| Step: 11
Training loss: 3.478484096309248
Validation loss: 2.8439691515028356

Epoch: 64| Step: 0
Training loss: 3.554674353942038
Validation loss: 2.8423412033275715

Epoch: 5| Step: 1
Training loss: 2.7762334780006053
Validation loss: 2.8388452361747256

Epoch: 5| Step: 2
Training loss: 3.002410079537032
Validation loss: 2.8379826523136593

Epoch: 5| Step: 3
Training loss: 2.600803757189428
Validation loss: 2.8352730448157732

Epoch: 5| Step: 4
Training loss: 2.331074427316137
Validation loss: 2.8336224420155545

Epoch: 5| Step: 5
Training loss: 2.3235795881260355
Validation loss: 2.8315569741383526

Epoch: 5| Step: 6
Training loss: 3.06904960459486
Validation loss: 2.8309150548201587

Epoch: 5| Step: 7
Training loss: 3.1129223701657294
Validation loss: 2.826808668768687

Epoch: 5| Step: 8
Training loss: 3.1882206719197534
Validation loss: 2.8267437528293398

Epoch: 5| Step: 9
Training loss: 2.9306357514877126
Validation loss: 2.82473502885708

Epoch: 5| Step: 10
Training loss: 3.229100593793328
Validation loss: 2.8214151546390354

Epoch: 5| Step: 11
Training loss: 4.3094108685168795
Validation loss: 2.8197620238564034

Epoch: 65| Step: 0
Training loss: 3.3075278050183097
Validation loss: 2.8174927864670614

Epoch: 5| Step: 1
Training loss: 2.3860271844202616
Validation loss: 2.8158272383045237

Epoch: 5| Step: 2
Training loss: 3.065109698026728
Validation loss: 2.8137695590706033

Epoch: 5| Step: 3
Training loss: 2.5669945168936303
Validation loss: 2.8107988263611476

Epoch: 5| Step: 4
Training loss: 2.9704340926420953
Validation loss: 2.809169524574316

Epoch: 5| Step: 5
Training loss: 2.880945112601295
Validation loss: 2.8095612961694374

Epoch: 5| Step: 6
Training loss: 3.1492134444339457
Validation loss: 2.8088588669054593

Epoch: 5| Step: 7
Training loss: 3.426081192996368
Validation loss: 2.8073461252473075

Epoch: 5| Step: 8
Training loss: 2.755322940127805
Validation loss: 2.8008139487343597

Epoch: 5| Step: 9
Training loss: 2.7894267210373807
Validation loss: 2.7985378096178195

Epoch: 5| Step: 10
Training loss: 2.9521224323304667
Validation loss: 2.796290412915473

Epoch: 5| Step: 11
Training loss: 2.987247861812413
Validation loss: 2.795367006637953

Epoch: 66| Step: 0
Training loss: 2.90213377489524
Validation loss: 2.7939157938850654

Epoch: 5| Step: 1
Training loss: 2.5945259680000716
Validation loss: 2.791829575344946

Epoch: 5| Step: 2
Training loss: 2.676513927974339
Validation loss: 2.79073233887471

Epoch: 5| Step: 3
Training loss: 3.2986341366326757
Validation loss: 2.787063733702689

Epoch: 5| Step: 4
Training loss: 2.7037080345477174
Validation loss: 2.786680474146337

Epoch: 5| Step: 5
Training loss: 3.0775731555415478
Validation loss: 2.7829461158633175

Epoch: 5| Step: 6
Training loss: 3.395202359670238
Validation loss: 2.781782138651264

Epoch: 5| Step: 7
Training loss: 2.8448631706922107
Validation loss: 2.7796991396269495

Epoch: 5| Step: 8
Training loss: 2.909906855400099
Validation loss: 2.7772173202216854

Epoch: 5| Step: 9
Training loss: 2.8671979774054988
Validation loss: 2.776822999474061

Epoch: 5| Step: 10
Training loss: 2.8582314461064415
Validation loss: 2.7760545373633767

Epoch: 5| Step: 11
Training loss: 2.6282670716339323
Validation loss: 2.7712413241282583

Epoch: 67| Step: 0
Training loss: 3.309357502056255
Validation loss: 2.7725873584416743

Epoch: 5| Step: 1
Training loss: 3.1440640120165675
Validation loss: 2.769603030660467

Epoch: 5| Step: 2
Training loss: 3.2306163528099354
Validation loss: 2.7748290211181232

Epoch: 5| Step: 3
Training loss: 2.7094573011734884
Validation loss: 2.7744250800292085

Epoch: 5| Step: 4
Training loss: 2.836159101082884
Validation loss: 2.7690791813426476

Epoch: 5| Step: 5
Training loss: 3.100163603126439
Validation loss: 2.7637034096508173

Epoch: 5| Step: 6
Training loss: 3.0040913340046758
Validation loss: 2.763965705196017

Epoch: 5| Step: 7
Training loss: 2.47699644697271
Validation loss: 2.7646651784591434

Epoch: 5| Step: 8
Training loss: 2.918855953539785
Validation loss: 2.7624579361694965

Epoch: 5| Step: 9
Training loss: 2.648758680285299
Validation loss: 2.7616805488070226

Epoch: 5| Step: 10
Training loss: 2.515340469096793
Validation loss: 2.7652029803859963

Epoch: 5| Step: 11
Training loss: 2.582220165826734
Validation loss: 2.768477027158181

Epoch: 68| Step: 0
Training loss: 2.787769947751373
Validation loss: 2.757562336008159

Epoch: 5| Step: 1
Training loss: 2.9594693935208256
Validation loss: 2.7551190602791333

Epoch: 5| Step: 2
Training loss: 3.089013375107301
Validation loss: 2.7536611064624172

Epoch: 5| Step: 3
Training loss: 2.8938455322842787
Validation loss: 2.750979733061845

Epoch: 5| Step: 4
Training loss: 3.042576031201135
Validation loss: 2.748548771389701

Epoch: 5| Step: 5
Training loss: 3.1305183515243855
Validation loss: 2.74662437033339

Epoch: 5| Step: 6
Training loss: 3.0020741603975023
Validation loss: 2.7449858426074654

Epoch: 5| Step: 7
Training loss: 2.457431196644715
Validation loss: 2.743909355002374

Epoch: 5| Step: 8
Training loss: 2.9109898135060415
Validation loss: 2.7426519009736356

Epoch: 5| Step: 9
Training loss: 2.7398777115813338
Validation loss: 2.7405443403668968

Epoch: 5| Step: 10
Training loss: 2.7820945057671524
Validation loss: 2.7383401948731034

Epoch: 5| Step: 11
Training loss: 2.397230012109191
Validation loss: 2.7382565368901233

Epoch: 69| Step: 0
Training loss: 2.83855727071877
Validation loss: 2.7375044181068104

Epoch: 5| Step: 1
Training loss: 2.7211193415369035
Validation loss: 2.7405370761247365

Epoch: 5| Step: 2
Training loss: 3.3145615981992003
Validation loss: 2.73932926948353

Epoch: 5| Step: 3
Training loss: 2.9146361412806865
Validation loss: 2.742429075984457

Epoch: 5| Step: 4
Training loss: 2.6953750381954458
Validation loss: 2.7369474499307813

Epoch: 5| Step: 5
Training loss: 2.8760776987735093
Validation loss: 2.733381475968619

Epoch: 5| Step: 6
Training loss: 2.8894750008677437
Validation loss: 2.7308425429170162

Epoch: 5| Step: 7
Training loss: 2.815684063257025
Validation loss: 2.725729223840718

Epoch: 5| Step: 8
Training loss: 2.8319846103379374
Validation loss: 2.7256341244501763

Epoch: 5| Step: 9
Training loss: 2.9852145147640083
Validation loss: 2.725396013357077

Epoch: 5| Step: 10
Training loss: 2.806915588289305
Validation loss: 2.722877840048893

Epoch: 5| Step: 11
Training loss: 2.256494157002122
Validation loss: 2.7212323479407705

Epoch: 70| Step: 0
Training loss: 3.0152374176630747
Validation loss: 2.7192217793862707

Epoch: 5| Step: 1
Training loss: 2.9666758469285974
Validation loss: 2.7177344723886225

Epoch: 5| Step: 2
Training loss: 2.8543592142095005
Validation loss: 2.714561930786998

Epoch: 5| Step: 3
Training loss: 3.0779180311922345
Validation loss: 2.716197240433816

Epoch: 5| Step: 4
Training loss: 2.4745849993558244
Validation loss: 2.714272217086586

Epoch: 5| Step: 5
Training loss: 2.88884387429534
Validation loss: 2.714062640113805

Epoch: 5| Step: 6
Training loss: 3.0378302500590495
Validation loss: 2.7149957042587514

Epoch: 5| Step: 7
Training loss: 3.11488628296221
Validation loss: 2.719227357955349

Epoch: 5| Step: 8
Training loss: 2.759845794571583
Validation loss: 2.712285413032853

Epoch: 5| Step: 9
Training loss: 2.7206891039660253
Validation loss: 2.706729929026931

Epoch: 5| Step: 10
Training loss: 2.4320620987329877
Validation loss: 2.70518181300295

Epoch: 5| Step: 11
Training loss: 2.675780537180562
Validation loss: 2.7046640053883224

Epoch: 71| Step: 0
Training loss: 2.6227456357994345
Validation loss: 2.7044003478730505

Epoch: 5| Step: 1
Training loss: 2.705971866966102
Validation loss: 2.7039685265394775

Epoch: 5| Step: 2
Training loss: 3.2327135029417704
Validation loss: 2.701087838182975

Epoch: 5| Step: 3
Training loss: 2.5567346239404394
Validation loss: 2.701297991519159

Epoch: 5| Step: 4
Training loss: 2.9238569911839085
Validation loss: 2.700534457568114

Epoch: 5| Step: 5
Training loss: 2.7049544653876443
Validation loss: 2.698909743674158

Epoch: 5| Step: 6
Training loss: 3.3056653607364512
Validation loss: 2.6970871210938467

Epoch: 5| Step: 7
Training loss: 3.178387050271412
Validation loss: 2.6964546658436146

Epoch: 5| Step: 8
Training loss: 2.754350861715623
Validation loss: 2.694712692821893

Epoch: 5| Step: 9
Training loss: 2.6067819102862075
Validation loss: 2.694217216085524

Epoch: 5| Step: 10
Training loss: 2.4672660713658026
Validation loss: 2.691821028994497

Epoch: 5| Step: 11
Training loss: 2.860491758631073
Validation loss: 2.691225127911246

Epoch: 72| Step: 0
Training loss: 2.7619299045758794
Validation loss: 2.689738025594782

Epoch: 5| Step: 1
Training loss: 2.970813716557935
Validation loss: 2.687641432093887

Epoch: 5| Step: 2
Training loss: 3.1639802144971596
Validation loss: 2.686681582160593

Epoch: 5| Step: 3
Training loss: 2.636554356854406
Validation loss: 2.68510964273347

Epoch: 5| Step: 4
Training loss: 2.5372745733241033
Validation loss: 2.68416074179732

Epoch: 5| Step: 5
Training loss: 3.1035348304648833
Validation loss: 2.6829683221922536

Epoch: 5| Step: 6
Training loss: 3.182877273911718
Validation loss: 2.680477081614982

Epoch: 5| Step: 7
Training loss: 2.442599513077537
Validation loss: 2.6785584416907207

Epoch: 5| Step: 8
Training loss: 2.4967782241724845
Validation loss: 2.6767019836400663

Epoch: 5| Step: 9
Training loss: 2.946717268766778
Validation loss: 2.6781474508311147

Epoch: 5| Step: 10
Training loss: 2.6925009396125477
Validation loss: 2.6736672396912686

Epoch: 5| Step: 11
Training loss: 2.516278105122591
Validation loss: 2.6750840441255432

Epoch: 73| Step: 0
Training loss: 3.1614895378638312
Validation loss: 2.6741730732443307

Epoch: 5| Step: 1
Training loss: 2.917061660904772
Validation loss: 2.6729987292924755

Epoch: 5| Step: 2
Training loss: 2.625282635686361
Validation loss: 2.670954305842077

Epoch: 5| Step: 3
Training loss: 2.498444740995849
Validation loss: 2.6739249740162276

Epoch: 5| Step: 4
Training loss: 2.7147170222501598
Validation loss: 2.6706735017614114

Epoch: 5| Step: 5
Training loss: 2.409233126687417
Validation loss: 2.672204107052192

Epoch: 5| Step: 6
Training loss: 2.9105425891836987
Validation loss: 2.669574792194432

Epoch: 5| Step: 7
Training loss: 3.014306921810065
Validation loss: 2.673070811026481

Epoch: 5| Step: 8
Training loss: 2.7061325717319495
Validation loss: 2.6698196194351675

Epoch: 5| Step: 9
Training loss: 2.961788970992263
Validation loss: 2.6696122684600576

Epoch: 5| Step: 10
Training loss: 2.791812854943685
Validation loss: 2.662849399911023

Epoch: 5| Step: 11
Training loss: 3.048439602286564
Validation loss: 2.6619232254454666

Epoch: 74| Step: 0
Training loss: 2.5519906371013645
Validation loss: 2.6621922204646387

Epoch: 5| Step: 1
Training loss: 2.934790152695154
Validation loss: 2.6633080750160083

Epoch: 5| Step: 2
Training loss: 2.8192354718850745
Validation loss: 2.6660272134568617

Epoch: 5| Step: 3
Training loss: 2.792990346971788
Validation loss: 2.667634189940292

Epoch: 5| Step: 4
Training loss: 2.861793704122653
Validation loss: 2.66319860507508

Epoch: 5| Step: 5
Training loss: 2.888706044581122
Validation loss: 2.663181050971641

Epoch: 5| Step: 6
Training loss: 1.9643602629547823
Validation loss: 2.662634066667338

Epoch: 5| Step: 7
Training loss: 3.1368885493133143
Validation loss: 2.658905769816317

Epoch: 5| Step: 8
Training loss: 3.026333311715455
Validation loss: 2.6565289444407085

Epoch: 5| Step: 9
Training loss: 2.789548516335178
Validation loss: 2.6541232851596286

Epoch: 5| Step: 10
Training loss: 2.9526361938900023
Validation loss: 2.6536703448650045

Epoch: 5| Step: 11
Training loss: 2.221352568637382
Validation loss: 2.6521919330637633

Epoch: 75| Step: 0
Training loss: 2.3956351046171194
Validation loss: 2.6493548639613222

Epoch: 5| Step: 1
Training loss: 2.760899790585672
Validation loss: 2.6484420948870175

Epoch: 5| Step: 2
Training loss: 2.6269836197114786
Validation loss: 2.6453225000608924

Epoch: 5| Step: 3
Training loss: 2.973184425861939
Validation loss: 2.6465600409957832

Epoch: 5| Step: 4
Training loss: 2.968261196652878
Validation loss: 2.643014383593951

Epoch: 5| Step: 5
Training loss: 2.529500662941364
Validation loss: 2.64256248272131

Epoch: 5| Step: 6
Training loss: 2.8972181855569112
Validation loss: 2.642258588367337

Epoch: 5| Step: 7
Training loss: 2.780582647946388
Validation loss: 2.641424550855531

Epoch: 5| Step: 8
Training loss: 2.777090755909651
Validation loss: 2.643422403773117

Epoch: 5| Step: 9
Training loss: 2.9114006095900793
Validation loss: 2.649187347576979

Epoch: 5| Step: 10
Training loss: 2.7988403916339704
Validation loss: 2.648251297218103

Epoch: 5| Step: 11
Training loss: 3.370209296091697
Validation loss: 2.640215290796583

Epoch: 76| Step: 0
Training loss: 2.0522182697785203
Validation loss: 2.636793660171178

Epoch: 5| Step: 1
Training loss: 2.791260523692962
Validation loss: 2.6343659893649556

Epoch: 5| Step: 2
Training loss: 2.6582997211336328
Validation loss: 2.6322580597038834

Epoch: 5| Step: 3
Training loss: 3.0637562569064465
Validation loss: 2.632638791595603

Epoch: 5| Step: 4
Training loss: 2.752636945680291
Validation loss: 2.6338120967398524

Epoch: 5| Step: 5
Training loss: 2.666329948703878
Validation loss: 2.630813911647438

Epoch: 5| Step: 6
Training loss: 2.7067874506918077
Validation loss: 2.630739775244611

Epoch: 5| Step: 7
Training loss: 2.8736232280603775
Validation loss: 2.6305109070331403

Epoch: 5| Step: 8
Training loss: 2.971543132491406
Validation loss: 2.6297449075073116

Epoch: 5| Step: 9
Training loss: 3.002712612834988
Validation loss: 2.6295822997421854

Epoch: 5| Step: 10
Training loss: 2.635846209796622
Validation loss: 2.627830372132367

Epoch: 5| Step: 11
Training loss: 3.3357143640153515
Validation loss: 2.625269455930904

Epoch: 77| Step: 0
Training loss: 2.357954696705407
Validation loss: 2.62406843170747

Epoch: 5| Step: 1
Training loss: 2.8718919954845146
Validation loss: 2.621590557287018

Epoch: 5| Step: 2
Training loss: 2.9403111419042127
Validation loss: 2.621205376315113

Epoch: 5| Step: 3
Training loss: 3.2561371884417913
Validation loss: 2.6222390232472885

Epoch: 5| Step: 4
Training loss: 3.069615408699308
Validation loss: 2.6250128064524385

Epoch: 5| Step: 5
Training loss: 2.6994893756790925
Validation loss: 2.62417062645431

Epoch: 5| Step: 6
Training loss: 2.4281116539233647
Validation loss: 2.619695530234113

Epoch: 5| Step: 7
Training loss: 2.722397035275307
Validation loss: 2.618256676001154

Epoch: 5| Step: 8
Training loss: 2.6477717910459155
Validation loss: 2.612934783335808

Epoch: 5| Step: 9
Training loss: 2.7527592427946734
Validation loss: 2.614005223733809

Epoch: 5| Step: 10
Training loss: 2.4193340138595323
Validation loss: 2.611521852317015

Epoch: 5| Step: 11
Training loss: 2.699092701951307
Validation loss: 2.6134853273849172

Epoch: 78| Step: 0
Training loss: 2.6522357002913415
Validation loss: 2.61087521810344

Epoch: 5| Step: 1
Training loss: 2.5721531917993805
Validation loss: 2.610960119162015

Epoch: 5| Step: 2
Training loss: 2.9015132901934026
Validation loss: 2.6123095208714533

Epoch: 5| Step: 3
Training loss: 2.4333386233894987
Validation loss: 2.6110468170578676

Epoch: 5| Step: 4
Training loss: 2.07753728142257
Validation loss: 2.6090090070485914

Epoch: 5| Step: 5
Training loss: 2.0401713546143534
Validation loss: 2.6085781548220397

Epoch: 5| Step: 6
Training loss: 2.7226361967686454
Validation loss: 2.6080297440174016

Epoch: 5| Step: 7
Training loss: 2.809235182561902
Validation loss: 2.6062207526037953

Epoch: 5| Step: 8
Training loss: 3.2065029289913913
Validation loss: 2.606429262803841

Epoch: 5| Step: 9
Training loss: 3.394072998862347
Validation loss: 2.6029189185074815

Epoch: 5| Step: 10
Training loss: 3.0202057986842967
Validation loss: 2.603321206497671

Epoch: 5| Step: 11
Training loss: 2.6629035643858745
Validation loss: 2.6028278126233553

Epoch: 79| Step: 0
Training loss: 2.3423343706557094
Validation loss: 2.6028717610863086

Epoch: 5| Step: 1
Training loss: 2.6136052910084757
Validation loss: 2.6001902140827156

Epoch: 5| Step: 2
Training loss: 2.5362594390738615
Validation loss: 2.59364674833757

Epoch: 5| Step: 3
Training loss: 2.6487942345648916
Validation loss: 2.598445074636583

Epoch: 5| Step: 4
Training loss: 2.9720885126890653
Validation loss: 2.6015086240029786

Epoch: 5| Step: 5
Training loss: 2.7698849558437657
Validation loss: 2.6011249873135514

Epoch: 5| Step: 6
Training loss: 2.8201324320870604
Validation loss: 2.597444897612737

Epoch: 5| Step: 7
Training loss: 3.147094137068092
Validation loss: 2.602930333711411

Epoch: 5| Step: 8
Training loss: 3.038423368034074
Validation loss: 2.5985676689063206

Epoch: 5| Step: 9
Training loss: 2.872647525461833
Validation loss: 2.5943931984713076

Epoch: 5| Step: 10
Training loss: 2.2668476883279203
Validation loss: 2.591082568650308

Epoch: 5| Step: 11
Training loss: 2.13234361797407
Validation loss: 2.5909211960739933

Epoch: 80| Step: 0
Training loss: 2.570976380294978
Validation loss: 2.593215653710607

Epoch: 5| Step: 1
Training loss: 3.0859031965063335
Validation loss: 2.5931388372403146

Epoch: 5| Step: 2
Training loss: 2.9875315006143595
Validation loss: 2.59249072164888

Epoch: 5| Step: 3
Training loss: 2.5594585325887786
Validation loss: 2.592587915405591

Epoch: 5| Step: 4
Training loss: 2.7911775834307093
Validation loss: 2.5930069621274994

Epoch: 5| Step: 5
Training loss: 3.107477423784613
Validation loss: 2.591975141046717

Epoch: 5| Step: 6
Training loss: 2.8462040970107574
Validation loss: 2.5885530749145707

Epoch: 5| Step: 7
Training loss: 2.661839516970402
Validation loss: 2.5905153986835123

Epoch: 5| Step: 8
Training loss: 2.638441458354268
Validation loss: 2.5891119612099947

Epoch: 5| Step: 9
Training loss: 2.5668041089237112
Validation loss: 2.5866939248925647

Epoch: 5| Step: 10
Training loss: 2.2221156637816755
Validation loss: 2.586186445993925

Epoch: 5| Step: 11
Training loss: 1.2170998577252923
Validation loss: 2.5835111323565227

Epoch: 81| Step: 0
Training loss: 2.047283801540542
Validation loss: 2.581933651155381

Epoch: 5| Step: 1
Training loss: 3.1444009884219235
Validation loss: 2.586813529569097

Epoch: 5| Step: 2
Training loss: 3.170306339323733
Validation loss: 2.579758991349874

Epoch: 5| Step: 3
Training loss: 2.77606360526419
Validation loss: 2.5821697950104348

Epoch: 5| Step: 4
Training loss: 2.6218428926923103
Validation loss: 2.583302472043024

Epoch: 5| Step: 5
Training loss: 2.428294282213899
Validation loss: 2.578806700311959

Epoch: 5| Step: 6
Training loss: 2.6360943994594215
Validation loss: 2.5812700604882344

Epoch: 5| Step: 7
Training loss: 2.723969021272327
Validation loss: 2.584291404808205

Epoch: 5| Step: 8
Training loss: 2.3012584974970207
Validation loss: 2.5806395742581185

Epoch: 5| Step: 9
Training loss: 2.9829580728088927
Validation loss: 2.583588223547072

Epoch: 5| Step: 10
Training loss: 2.7229303252138566
Validation loss: 2.5882344987912878

Epoch: 5| Step: 11
Training loss: 3.0458181259951527
Validation loss: 2.5787674459834036

Epoch: 82| Step: 0
Training loss: 2.4687856357754874
Validation loss: 2.578951369889239

Epoch: 5| Step: 1
Training loss: 2.8121848035728023
Validation loss: 2.5856495184992614

Epoch: 5| Step: 2
Training loss: 2.7607680954744724
Validation loss: 2.590263861964541

Epoch: 5| Step: 3
Training loss: 2.646473384144613
Validation loss: 2.5856030104743057

Epoch: 5| Step: 4
Training loss: 2.8924244821197362
Validation loss: 2.5755626082367216

Epoch: 5| Step: 5
Training loss: 2.4644121133678434
Validation loss: 2.5767686146467534

Epoch: 5| Step: 6
Training loss: 2.7652314331711554
Validation loss: 2.5755573240548726

Epoch: 5| Step: 7
Training loss: 3.0578325476595944
Validation loss: 2.568915798315763

Epoch: 5| Step: 8
Training loss: 2.7131945094493237
Validation loss: 2.575274789678584

Epoch: 5| Step: 9
Training loss: 2.764639727418061
Validation loss: 2.570539420023661

Epoch: 5| Step: 10
Training loss: 2.4195206550462247
Validation loss: 2.5704532843686008

Epoch: 5| Step: 11
Training loss: 2.170137437608022
Validation loss: 2.5731378561895086

Epoch: 83| Step: 0
Training loss: 2.7118614007591706
Validation loss: 2.5714159474334206

Epoch: 5| Step: 1
Training loss: 2.7898376413501187
Validation loss: 2.568788020308168

Epoch: 5| Step: 2
Training loss: 2.5120589291409074
Validation loss: 2.5689760268020745

Epoch: 5| Step: 3
Training loss: 2.8253269580242866
Validation loss: 2.569964523491126

Epoch: 5| Step: 4
Training loss: 2.4901576849404377
Validation loss: 2.567690279873308

Epoch: 5| Step: 5
Training loss: 2.8220516348101983
Validation loss: 2.5667786272408804

Epoch: 5| Step: 6
Training loss: 2.8588556537194583
Validation loss: 2.563348203321598

Epoch: 5| Step: 7
Training loss: 2.6821047720872815
Validation loss: 2.5632990157389437

Epoch: 5| Step: 8
Training loss: 2.6182361836159473
Validation loss: 2.563104255888125

Epoch: 5| Step: 9
Training loss: 2.8953788638550897
Validation loss: 2.565568602418728

Epoch: 5| Step: 10
Training loss: 2.546878744485361
Validation loss: 2.5643265851060657

Epoch: 5| Step: 11
Training loss: 2.029400262043933
Validation loss: 2.562052164254704

Epoch: 84| Step: 0
Training loss: 2.4575291843175457
Validation loss: 2.5625986529953173

Epoch: 5| Step: 1
Training loss: 2.5181201383913496
Validation loss: 2.558775653148344

Epoch: 5| Step: 2
Training loss: 2.5208272277085526
Validation loss: 2.5575380549764533

Epoch: 5| Step: 3
Training loss: 2.907657077577432
Validation loss: 2.55986971500664

Epoch: 5| Step: 4
Training loss: 2.8258688341762697
Validation loss: 2.5584461703459724

Epoch: 5| Step: 5
Training loss: 2.7674726790515702
Validation loss: 2.5634917728033373

Epoch: 5| Step: 6
Training loss: 2.411769827600566
Validation loss: 2.5603008098685396

Epoch: 5| Step: 7
Training loss: 2.534986493227036
Validation loss: 2.5598102812701957

Epoch: 5| Step: 8
Training loss: 2.8727957526957155
Validation loss: 2.564130001043588

Epoch: 5| Step: 9
Training loss: 2.693722197705596
Validation loss: 2.5634742799779024

Epoch: 5| Step: 10
Training loss: 3.008756415150693
Validation loss: 2.5578414704071237

Epoch: 5| Step: 11
Training loss: 2.8583930992647453
Validation loss: 2.5567681863822505

Epoch: 85| Step: 0
Training loss: 2.5662870568128358
Validation loss: 2.552940424547139

Epoch: 5| Step: 1
Training loss: 2.2571900245539367
Validation loss: 2.558156290099841

Epoch: 5| Step: 2
Training loss: 2.626074434827745
Validation loss: 2.564996398882355

Epoch: 5| Step: 3
Training loss: 2.8872522421228726
Validation loss: 2.5652998809250045

Epoch: 5| Step: 4
Training loss: 2.924341965692797
Validation loss: 2.5607895143307937

Epoch: 5| Step: 5
Training loss: 2.713861564968087
Validation loss: 2.5603493256141676

Epoch: 5| Step: 6
Training loss: 3.031132017376131
Validation loss: 2.561727981263785

Epoch: 5| Step: 7
Training loss: 2.345321433643097
Validation loss: 2.559472070637842

Epoch: 5| Step: 8
Training loss: 2.62274945377282
Validation loss: 2.5600070495868517

Epoch: 5| Step: 9
Training loss: 3.037449425798268
Validation loss: 2.558036665899226

Epoch: 5| Step: 10
Training loss: 2.3638740741799937
Validation loss: 2.559279173849158

Epoch: 5| Step: 11
Training loss: 2.8379606906461605
Validation loss: 2.5604272771314918

Epoch: 86| Step: 0
Training loss: 2.5729951627754795
Validation loss: 2.5558686787321627

Epoch: 5| Step: 1
Training loss: 3.0314513464057113
Validation loss: 2.5606846387996036

Epoch: 5| Step: 2
Training loss: 3.185402423102446
Validation loss: 2.5547732728641632

Epoch: 5| Step: 3
Training loss: 2.3605624614872025
Validation loss: 2.5556915518837466

Epoch: 5| Step: 4
Training loss: 2.7524138173982107
Validation loss: 2.5548393484360794

Epoch: 5| Step: 5
Training loss: 2.771679130093401
Validation loss: 2.5524708486094805

Epoch: 5| Step: 6
Training loss: 2.4310830576244915
Validation loss: 2.550613401692411

Epoch: 5| Step: 7
Training loss: 2.910980640364037
Validation loss: 2.5490651630660346

Epoch: 5| Step: 8
Training loss: 2.5540172385916255
Validation loss: 2.548936411383088

Epoch: 5| Step: 9
Training loss: 2.695453496368733
Validation loss: 2.5458714706032577

Epoch: 5| Step: 10
Training loss: 2.3759201676542934
Validation loss: 2.5439512676186395

Epoch: 5| Step: 11
Training loss: 0.47439220153520495
Validation loss: 2.5448797051192185

Epoch: 87| Step: 0
Training loss: 2.876054984870939
Validation loss: 2.5413385528607253

Epoch: 5| Step: 1
Training loss: 2.268302230154575
Validation loss: 2.5432766299740805

Epoch: 5| Step: 2
Training loss: 2.4595873807649453
Validation loss: 2.5436061952824938

Epoch: 5| Step: 3
Training loss: 2.4846445573164773
Validation loss: 2.5411416876972086

Epoch: 5| Step: 4
Training loss: 2.8213959617868696
Validation loss: 2.5419936998958534

Epoch: 5| Step: 5
Training loss: 2.8997176394626494
Validation loss: 2.539279799332799

Epoch: 5| Step: 6
Training loss: 2.6817387773370185
Validation loss: 2.5429236685902166

Epoch: 5| Step: 7
Training loss: 2.4118317108342153
Validation loss: 2.542438066916646

Epoch: 5| Step: 8
Training loss: 2.71331366363944
Validation loss: 2.544391474341346

Epoch: 5| Step: 9
Training loss: 2.837386672659895
Validation loss: 2.537550482850665

Epoch: 5| Step: 10
Training loss: 2.7416826527911144
Validation loss: 2.5381971518111732

Epoch: 5| Step: 11
Training loss: 2.964296715169378
Validation loss: 2.5377230979924805

Epoch: 88| Step: 0
Training loss: 2.6898961585326977
Validation loss: 2.54043674545733

Epoch: 5| Step: 1
Training loss: 2.9136885743149117
Validation loss: 2.5391768835663657

Epoch: 5| Step: 2
Training loss: 2.670571349373067
Validation loss: 2.539808435662935

Epoch: 5| Step: 3
Training loss: 2.806191553811345
Validation loss: 2.540119972099005

Epoch: 5| Step: 4
Training loss: 2.702287577309672
Validation loss: 2.541672789977989

Epoch: 5| Step: 5
Training loss: 2.6343339548047076
Validation loss: 2.537272553045516

Epoch: 5| Step: 6
Training loss: 2.5153670089830573
Validation loss: 2.537161591863461

Epoch: 5| Step: 7
Training loss: 2.6855640979561364
Validation loss: 2.5375560497489054

Epoch: 5| Step: 8
Training loss: 2.398711844295369
Validation loss: 2.536988871950086

Epoch: 5| Step: 9
Training loss: 2.6073901456695388
Validation loss: 2.5357521269857464

Epoch: 5| Step: 10
Training loss: 2.765797582726495
Validation loss: 2.5371011719682413

Epoch: 5| Step: 11
Training loss: 1.8956895571116434
Validation loss: 2.535518536105436

Epoch: 89| Step: 0
Training loss: 2.854527267360566
Validation loss: 2.5340754826264464

Epoch: 5| Step: 1
Training loss: 2.6927423136846413
Validation loss: 2.5320504143576295

Epoch: 5| Step: 2
Training loss: 2.7913178373055016
Validation loss: 2.5296063640071575

Epoch: 5| Step: 3
Training loss: 2.7756613828168137
Validation loss: 2.5334166959067814

Epoch: 5| Step: 4
Training loss: 2.794878625435156
Validation loss: 2.5310507841168683

Epoch: 5| Step: 5
Training loss: 2.2110787606015974
Validation loss: 2.530380158435561

Epoch: 5| Step: 6
Training loss: 2.6804653629113693
Validation loss: 2.530243414432401

Epoch: 5| Step: 7
Training loss: 2.6429416042809035
Validation loss: 2.5341872531824485

Epoch: 5| Step: 8
Training loss: 2.6783478616329544
Validation loss: 2.5335232020948673

Epoch: 5| Step: 9
Training loss: 2.4487200994452687
Validation loss: 2.53053584444158

Epoch: 5| Step: 10
Training loss: 2.5311256660725423
Validation loss: 2.528482042240178

Epoch: 5| Step: 11
Training loss: 2.8929307144470826
Validation loss: 2.531149579634659

Epoch: 90| Step: 0
Training loss: 3.1678374953543083
Validation loss: 2.530245083044304

Epoch: 5| Step: 1
Training loss: 2.517063464110677
Validation loss: 2.530523608026161

Epoch: 5| Step: 2
Training loss: 2.704193256954738
Validation loss: 2.531907651576606

Epoch: 5| Step: 3
Training loss: 2.1510273807473044
Validation loss: 2.524160197004018

Epoch: 5| Step: 4
Training loss: 2.583149124058703
Validation loss: 2.527874013940083

Epoch: 5| Step: 5
Training loss: 3.005665515698768
Validation loss: 2.532334434878314

Epoch: 5| Step: 6
Training loss: 2.513351455575922
Validation loss: 2.5242363695659007

Epoch: 5| Step: 7
Training loss: 2.3684044658905483
Validation loss: 2.5288520647697474

Epoch: 5| Step: 8
Training loss: 2.3661313360398335
Validation loss: 2.527695719262669

Epoch: 5| Step: 9
Training loss: 2.757477045594835
Validation loss: 2.5278650401642815

Epoch: 5| Step: 10
Training loss: 2.8225628019902764
Validation loss: 2.5234671591953592

Epoch: 5| Step: 11
Training loss: 2.8789890644890033
Validation loss: 2.52765874850246

Epoch: 91| Step: 0
Training loss: 2.562748594553652
Validation loss: 2.530510213460601

Epoch: 5| Step: 1
Training loss: 2.2792665402731833
Validation loss: 2.526933348802348

Epoch: 5| Step: 2
Training loss: 2.962166644305768
Validation loss: 2.5231644450221014

Epoch: 5| Step: 3
Training loss: 2.2375479623779353
Validation loss: 2.5258679176168726

Epoch: 5| Step: 4
Training loss: 2.950426594552684
Validation loss: 2.5282765572932666

Epoch: 5| Step: 5
Training loss: 2.6121910569620495
Validation loss: 2.5239936719607017

Epoch: 5| Step: 6
Training loss: 2.975343629882328
Validation loss: 2.5240605611613836

Epoch: 5| Step: 7
Training loss: 2.7010558924733745
Validation loss: 2.522550984211745

Epoch: 5| Step: 8
Training loss: 2.630654375887022
Validation loss: 2.5188367058823036

Epoch: 5| Step: 9
Training loss: 2.3472319106805553
Validation loss: 2.5223554844411886

Epoch: 5| Step: 10
Training loss: 2.6507439486765434
Validation loss: 2.5222722129505337

Epoch: 5| Step: 11
Training loss: 3.1434186210941433
Validation loss: 2.5260362500529205

Epoch: 92| Step: 0
Training loss: 2.1727697052699053
Validation loss: 2.5196148486400896

Epoch: 5| Step: 1
Training loss: 2.1578732337663795
Validation loss: 2.519983342736308

Epoch: 5| Step: 2
Training loss: 2.8072589785077025
Validation loss: 2.5227783885539616

Epoch: 5| Step: 3
Training loss: 2.383980186642489
Validation loss: 2.5277573012796526

Epoch: 5| Step: 4
Training loss: 2.724971449116217
Validation loss: 2.5287446115033774

Epoch: 5| Step: 5
Training loss: 3.000758075301849
Validation loss: 2.5310815472535055

Epoch: 5| Step: 6
Training loss: 2.605972538730911
Validation loss: 2.5292417306669637

Epoch: 5| Step: 7
Training loss: 2.8678573117055066
Validation loss: 2.5333387955702906

Epoch: 5| Step: 8
Training loss: 2.5244353125616725
Validation loss: 2.52641125495461

Epoch: 5| Step: 9
Training loss: 3.153603832533243
Validation loss: 2.527255933789536

Epoch: 5| Step: 10
Training loss: 2.550079015367787
Validation loss: 2.5233431976617715

Epoch: 5| Step: 11
Training loss: 2.6726394362869983
Validation loss: 2.52264948253604

Epoch: 93| Step: 0
Training loss: 2.725807413296531
Validation loss: 2.5226080213220823

Epoch: 5| Step: 1
Training loss: 2.6022936277621618
Validation loss: 2.5190614089739465

Epoch: 5| Step: 2
Training loss: 2.931745696297479
Validation loss: 2.5217138176657516

Epoch: 5| Step: 3
Training loss: 2.7509540290166945
Validation loss: 2.51852823248236

Epoch: 5| Step: 4
Training loss: 2.8539228311971265
Validation loss: 2.5193267344976964

Epoch: 5| Step: 5
Training loss: 2.382697030693513
Validation loss: 2.5167754328720835

Epoch: 5| Step: 6
Training loss: 2.6075340675476575
Validation loss: 2.5166649574206614

Epoch: 5| Step: 7
Training loss: 2.1348904837542633
Validation loss: 2.5168173394877753

Epoch: 5| Step: 8
Training loss: 2.719843677348282
Validation loss: 2.515252447085588

Epoch: 5| Step: 9
Training loss: 2.46858948777294
Validation loss: 2.5084657105549435

Epoch: 5| Step: 10
Training loss: 2.7881238196583626
Validation loss: 2.5147640816476025

Epoch: 5| Step: 11
Training loss: 2.48594577483425
Validation loss: 2.5169577592591037

Epoch: 94| Step: 0
Training loss: 3.0278445906271734
Validation loss: 2.516242304975098

Epoch: 5| Step: 1
Training loss: 2.9536214744188105
Validation loss: 2.5155854310898387

Epoch: 5| Step: 2
Training loss: 3.086266145227473
Validation loss: 2.5190568580843467

Epoch: 5| Step: 3
Training loss: 2.230544000481931
Validation loss: 2.5197586114698862

Epoch: 5| Step: 4
Training loss: 2.536635991218886
Validation loss: 2.523488598317016

Epoch: 5| Step: 5
Training loss: 2.356423255763432
Validation loss: 2.5244906602622383

Epoch: 5| Step: 6
Training loss: 2.2663701377708354
Validation loss: 2.5237420550821676

Epoch: 5| Step: 7
Training loss: 2.497312245380568
Validation loss: 2.5232063518276404

Epoch: 5| Step: 8
Training loss: 2.5429978141940284
Validation loss: 2.5231704137528075

Epoch: 5| Step: 9
Training loss: 2.3495320523826315
Validation loss: 2.520232347040417

Epoch: 5| Step: 10
Training loss: 2.732192209120384
Validation loss: 2.5200364663498003

Epoch: 5| Step: 11
Training loss: 3.8867010835025635
Validation loss: 2.516259869535457

Epoch: 95| Step: 0
Training loss: 2.1106676450153974
Validation loss: 2.518770261671987

Epoch: 5| Step: 1
Training loss: 2.383851272040064
Validation loss: 2.5177195341350083

Epoch: 5| Step: 2
Training loss: 2.8122929814760886
Validation loss: 2.513646736009433

Epoch: 5| Step: 3
Training loss: 2.3412541642689164
Validation loss: 2.513732368000196

Epoch: 5| Step: 4
Training loss: 2.626162771004644
Validation loss: 2.5116233669144004

Epoch: 5| Step: 5
Training loss: 2.531113420734165
Validation loss: 2.5114114394385787

Epoch: 5| Step: 6
Training loss: 2.919080407598494
Validation loss: 2.5104203336274735

Epoch: 5| Step: 7
Training loss: 3.041211934696147
Validation loss: 2.5108910596470078

Epoch: 5| Step: 8
Training loss: 2.877083728154013
Validation loss: 2.509138669721718

Epoch: 5| Step: 9
Training loss: 2.66278564640146
Validation loss: 2.505786624128898

Epoch: 5| Step: 10
Training loss: 2.307539490995212
Validation loss: 2.5112018518055406

Epoch: 5| Step: 11
Training loss: 3.6466025857914888
Validation loss: 2.505159513720852

Epoch: 96| Step: 0
Training loss: 1.7122023971252094
Validation loss: 2.5086411387607606

Epoch: 5| Step: 1
Training loss: 2.4974260431132516
Validation loss: 2.507507571085044

Epoch: 5| Step: 2
Training loss: 2.849124566527982
Validation loss: 2.5059456338404362

Epoch: 5| Step: 3
Training loss: 2.640694340805558
Validation loss: 2.5067441096500573

Epoch: 5| Step: 4
Training loss: 2.7839034206694806
Validation loss: 2.5036095112583006

Epoch: 5| Step: 5
Training loss: 2.660943585588773
Validation loss: 2.5056043828641097

Epoch: 5| Step: 6
Training loss: 3.0912912790370606
Validation loss: 2.5053733261139097

Epoch: 5| Step: 7
Training loss: 3.101337722589345
Validation loss: 2.508165356460061

Epoch: 5| Step: 8
Training loss: 2.5595721754571628
Validation loss: 2.502725228442312

Epoch: 5| Step: 9
Training loss: 2.048085793709823
Validation loss: 2.508906809992523

Epoch: 5| Step: 10
Training loss: 2.6892281232474025
Validation loss: 2.5037062034896462

Epoch: 5| Step: 11
Training loss: 2.331680143625041
Validation loss: 2.502533995365376

Epoch: 97| Step: 0
Training loss: 3.1067311150356045
Validation loss: 2.500240123660997

Epoch: 5| Step: 1
Training loss: 2.3989819831251102
Validation loss: 2.504568269350397

Epoch: 5| Step: 2
Training loss: 2.6135668862196537
Validation loss: 2.50259266565216

Epoch: 5| Step: 3
Training loss: 2.8480684795719107
Validation loss: 2.501925227823406

Epoch: 5| Step: 4
Training loss: 2.248216239853034
Validation loss: 2.5018037607007524

Epoch: 5| Step: 5
Training loss: 2.4875822657491407
Validation loss: 2.503905043896778

Epoch: 5| Step: 6
Training loss: 2.606894404746767
Validation loss: 2.502709180445999

Epoch: 5| Step: 7
Training loss: 2.485507251232423
Validation loss: 2.5008207205831767

Epoch: 5| Step: 8
Training loss: 2.58619988254166
Validation loss: 2.4992781828888564

Epoch: 5| Step: 9
Training loss: 2.6947716211714483
Validation loss: 2.5033302219826994

Epoch: 5| Step: 10
Training loss: 2.595792311032487
Validation loss: 2.503384214862797

Epoch: 5| Step: 11
Training loss: 2.991818557184538
Validation loss: 2.505156718070663

Epoch: 98| Step: 0
Training loss: 2.89312982030975
Validation loss: 2.4994211877890877

Epoch: 5| Step: 1
Training loss: 3.0409317348034737
Validation loss: 2.5021961460414364

Epoch: 5| Step: 2
Training loss: 1.901778808929167
Validation loss: 2.500569795207167

Epoch: 5| Step: 3
Training loss: 2.5845399520245067
Validation loss: 2.5026016526436194

Epoch: 5| Step: 4
Training loss: 2.414645818955599
Validation loss: 2.5039285072610986

Epoch: 5| Step: 5
Training loss: 3.1204350508079854
Validation loss: 2.5018481774297534

Epoch: 5| Step: 6
Training loss: 2.696531954238761
Validation loss: 2.5063899195387807

Epoch: 5| Step: 7
Training loss: 2.260504678398612
Validation loss: 2.50853663335639

Epoch: 5| Step: 8
Training loss: 2.338691236531471
Validation loss: 2.500347260358011

Epoch: 5| Step: 9
Training loss: 2.737739454970692
Validation loss: 2.502130689233707

Epoch: 5| Step: 10
Training loss: 2.6521102060862876
Validation loss: 2.505443265900495

Epoch: 5| Step: 11
Training loss: 2.7756716044378114
Validation loss: 2.5046248493382697

Epoch: 99| Step: 0
Training loss: 2.625917819193502
Validation loss: 2.5039862442926073

Epoch: 5| Step: 1
Training loss: 2.6496320073115665
Validation loss: 2.5088588951868234

Epoch: 5| Step: 2
Training loss: 2.7096865183410874
Validation loss: 2.5056238378412816

Epoch: 5| Step: 3
Training loss: 2.532997375932698
Validation loss: 2.5087282008332887

Epoch: 5| Step: 4
Training loss: 2.7479262769491037
Validation loss: 2.509742026211909

Epoch: 5| Step: 5
Training loss: 2.4509319051172613
Validation loss: 2.507895942638699

Epoch: 5| Step: 6
Training loss: 2.409213730378652
Validation loss: 2.510636736825205

Epoch: 5| Step: 7
Training loss: 2.8612766300293733
Validation loss: 2.510307663151058

Epoch: 5| Step: 8
Training loss: 2.8131653740389835
Validation loss: 2.511082613663979

Epoch: 5| Step: 9
Training loss: 2.634398574090103
Validation loss: 2.5094276170926704

Epoch: 5| Step: 10
Training loss: 2.4487112392533854
Validation loss: 2.5070225232952073

Epoch: 5| Step: 11
Training loss: 2.7308889783308645
Validation loss: 2.505887561380899

Epoch: 100| Step: 0
Training loss: 2.209529684605876
Validation loss: 2.5044691233745673

Epoch: 5| Step: 1
Training loss: 3.039410490299071
Validation loss: 2.504892409952577

Epoch: 5| Step: 2
Training loss: 2.6507065316981997
Validation loss: 2.502964046826373

Epoch: 5| Step: 3
Training loss: 2.45618466588845
Validation loss: 2.502504806583805

Epoch: 5| Step: 4
Training loss: 2.623017970626766
Validation loss: 2.500356342827784

Epoch: 5| Step: 5
Training loss: 2.548134334454481
Validation loss: 2.493892548804306

Epoch: 5| Step: 6
Training loss: 2.6120299578083483
Validation loss: 2.500219538109169

Epoch: 5| Step: 7
Training loss: 2.600476012304299
Validation loss: 2.496612447176226

Epoch: 5| Step: 8
Training loss: 2.747292486238742
Validation loss: 2.496202011825099

Epoch: 5| Step: 9
Training loss: 2.622527820305044
Validation loss: 2.4932774519098038

Epoch: 5| Step: 10
Training loss: 2.9145070572952685
Validation loss: 2.495203658445112

Epoch: 5| Step: 11
Training loss: 1.8452020520031607
Validation loss: 2.496177652030423

Epoch: 101| Step: 0
Training loss: 2.8147763682782987
Validation loss: 2.4995249515438274

Epoch: 5| Step: 1
Training loss: 2.331798343753202
Validation loss: 2.505323353200216

Epoch: 5| Step: 2
Training loss: 2.837784095019614
Validation loss: 2.500347252411829

Epoch: 5| Step: 3
Training loss: 2.6543651400805803
Validation loss: 2.5027931226727307

Epoch: 5| Step: 4
Training loss: 2.7000583607053015
Validation loss: 2.50452450376381

Epoch: 5| Step: 5
Training loss: 2.352982912675166
Validation loss: 2.5055555861669974

Epoch: 5| Step: 6
Training loss: 2.4856301262111815
Validation loss: 2.503374556072082

Epoch: 5| Step: 7
Training loss: 2.702233492743401
Validation loss: 2.504061776903788

Epoch: 5| Step: 8
Training loss: 2.748191065147072
Validation loss: 2.5044923236308136

Epoch: 5| Step: 9
Training loss: 2.7290671138709137
Validation loss: 2.5013289058795407

Epoch: 5| Step: 10
Training loss: 2.480134716220433
Validation loss: 2.5030573389288318

Epoch: 5| Step: 11
Training loss: 2.236328125
Validation loss: 2.4988612999044943

Epoch: 102| Step: 0
Training loss: 2.214589691392223
Validation loss: 2.4980023906804236

Epoch: 5| Step: 1
Training loss: 2.4662350749566206
Validation loss: 2.499505935963318

Epoch: 5| Step: 2
Training loss: 2.4386792387049945
Validation loss: 2.4974862255700487

Epoch: 5| Step: 3
Training loss: 2.6202419392065317
Validation loss: 2.496208172375929

Epoch: 5| Step: 4
Training loss: 2.5055854391931884
Validation loss: 2.493154001520728

Epoch: 5| Step: 5
Training loss: 2.6627698877938735
Validation loss: 2.4905838146497925

Epoch: 5| Step: 6
Training loss: 2.7736451836852654
Validation loss: 2.491178617288945

Epoch: 5| Step: 7
Training loss: 2.8638264343904427
Validation loss: 2.4900621900682034

Epoch: 5| Step: 8
Training loss: 2.7067418239600736
Validation loss: 2.4917590930045996

Epoch: 5| Step: 9
Training loss: 2.781851799824668
Validation loss: 2.5007287234941553

Epoch: 5| Step: 10
Training loss: 2.6984701484865363
Validation loss: 2.497040482990482

Epoch: 5| Step: 11
Training loss: 2.6730906080308383
Validation loss: 2.500273963698953

Epoch: 103| Step: 0
Training loss: 2.480840411839773
Validation loss: 2.5006432222368056

Epoch: 5| Step: 1
Training loss: 3.2065530436708825
Validation loss: 2.4978979850263467

Epoch: 5| Step: 2
Training loss: 2.8562660200141377
Validation loss: 2.5012762388409677

Epoch: 5| Step: 3
Training loss: 2.374606652061381
Validation loss: 2.502635561970734

Epoch: 5| Step: 4
Training loss: 2.528587919463169
Validation loss: 2.504244761166966

Epoch: 5| Step: 5
Training loss: 2.2386342247995423
Validation loss: 2.5042769682822965

Epoch: 5| Step: 6
Training loss: 2.629150288606908
Validation loss: 2.5009804392581887

Epoch: 5| Step: 7
Training loss: 2.182684912260241
Validation loss: 2.503693843884081

Epoch: 5| Step: 8
Training loss: 2.8420160058340613
Validation loss: 2.5025647756048035

Epoch: 5| Step: 9
Training loss: 2.8955916342736567
Validation loss: 2.499955288169303

Epoch: 5| Step: 10
Training loss: 2.521660619082598
Validation loss: 2.502054165287131

Epoch: 5| Step: 11
Training loss: 2.1692757180942404
Validation loss: 2.4996237034522863

Epoch: 104| Step: 0
Training loss: 2.5783466590614252
Validation loss: 2.499010247765542

Epoch: 5| Step: 1
Training loss: 3.052981629612191
Validation loss: 2.4957499896692763

Epoch: 5| Step: 2
Training loss: 2.487131856388646
Validation loss: 2.495875184345632

Epoch: 5| Step: 3
Training loss: 2.6558995632806552
Validation loss: 2.4954223923918173

Epoch: 5| Step: 4
Training loss: 1.733281933804897
Validation loss: 2.4953522911713053

Epoch: 5| Step: 5
Training loss: 2.2486555533218846
Validation loss: 2.4929322033941586

Epoch: 5| Step: 6
Training loss: 3.1743767554662647
Validation loss: 2.4897109854198454

Epoch: 5| Step: 7
Training loss: 2.2479516348064963
Validation loss: 2.4883373978776007

Epoch: 5| Step: 8
Training loss: 2.75096711579293
Validation loss: 2.4862404863045424

Epoch: 5| Step: 9
Training loss: 2.735884941637604
Validation loss: 2.495258710994484

Epoch: 5| Step: 10
Training loss: 2.7388528833952224
Validation loss: 2.495488570531914

Epoch: 5| Step: 11
Training loss: 2.6029148195554397
Validation loss: 2.4926404631052654

Epoch: 105| Step: 0
Training loss: 2.764202377031929
Validation loss: 2.4882114506408066

Epoch: 5| Step: 1
Training loss: 2.832768290406716
Validation loss: 2.494722438374705

Epoch: 5| Step: 2
Training loss: 2.394051085179618
Validation loss: 2.4919142378948624

Epoch: 5| Step: 3
Training loss: 2.7841043291493905
Validation loss: 2.4943800263404783

Epoch: 5| Step: 4
Training loss: 2.0444063631717397
Validation loss: 2.4977959374360266

Epoch: 5| Step: 5
Training loss: 2.418776665276899
Validation loss: 2.501299492541588

Epoch: 5| Step: 6
Training loss: 2.722018940357289
Validation loss: 2.5032412577795533

Epoch: 5| Step: 7
Training loss: 2.7711960022190496
Validation loss: 2.5038346009063237

Epoch: 5| Step: 8
Training loss: 2.4731378312316696
Validation loss: 2.503313038938863

Epoch: 5| Step: 9
Training loss: 2.411325625454318
Validation loss: 2.503055572816921

Epoch: 5| Step: 10
Training loss: 2.9016279978387645
Validation loss: 2.5068936273831772

Epoch: 5| Step: 11
Training loss: 3.2160105482469343
Validation loss: 2.5070765436427234

Epoch: 106| Step: 0
Training loss: 2.516570867100345
Validation loss: 2.506878612607326

Epoch: 5| Step: 1
Training loss: 2.469172284672097
Validation loss: 2.5107490997436916

Epoch: 5| Step: 2
Training loss: 2.6618538479883784
Validation loss: 2.505724408981658

Epoch: 5| Step: 3
Training loss: 3.017112088557439
Validation loss: 2.506401148144187

Epoch: 5| Step: 4
Training loss: 2.576689904500081
Validation loss: 2.50120155149655

Epoch: 5| Step: 5
Training loss: 2.4834934805962474
Validation loss: 2.501106239977661

Epoch: 5| Step: 6
Training loss: 2.386890761050448
Validation loss: 2.497084308137984

Epoch: 5| Step: 7
Training loss: 2.6689791685958664
Validation loss: 2.5007199522317873

Epoch: 5| Step: 8
Training loss: 2.353814045201364
Validation loss: 2.4960031746682128

Epoch: 5| Step: 9
Training loss: 2.8872984844750893
Validation loss: 2.498241314591976

Epoch: 5| Step: 10
Training loss: 2.924458549791438
Validation loss: 2.4939287733470192

Epoch: 5| Step: 11
Training loss: 1.5408788506713593
Validation loss: 2.4953563239656984

Epoch: 107| Step: 0
Training loss: 2.286342215286861
Validation loss: 2.492037913139158

Epoch: 5| Step: 1
Training loss: 2.4087057091957007
Validation loss: 2.490044969324356

Epoch: 5| Step: 2
Training loss: 2.511949875610934
Validation loss: 2.483280200571192

Epoch: 5| Step: 3
Training loss: 2.1403140099712696
Validation loss: 2.49045307470647

Epoch: 5| Step: 4
Training loss: 3.138140402556461
Validation loss: 2.48734035099434

Epoch: 5| Step: 5
Training loss: 3.0070091066365294
Validation loss: 2.4809001237128223

Epoch: 5| Step: 6
Training loss: 3.0508187617732228
Validation loss: 2.4828901912120327

Epoch: 5| Step: 7
Training loss: 2.5699924629189965
Validation loss: 2.484831098359478

Epoch: 5| Step: 8
Training loss: 2.138943645332367
Validation loss: 2.482495242559581

Epoch: 5| Step: 9
Training loss: 2.5813828662731955
Validation loss: 2.4874680536221936

Epoch: 5| Step: 10
Training loss: 2.714797116983709
Validation loss: 2.4862242479942136

Epoch: 5| Step: 11
Training loss: 0.8728695887857172
Validation loss: 2.483705906366997

Epoch: 108| Step: 0
Training loss: 2.7633175464389312
Validation loss: 2.477914824037416

Epoch: 5| Step: 1
Training loss: 2.5981775205367814
Validation loss: 2.483620709047638

Epoch: 5| Step: 2
Training loss: 2.7817894915995587
Validation loss: 2.484915780444664

Epoch: 5| Step: 3
Training loss: 2.788934357421505
Validation loss: 2.4884800175316797

Epoch: 5| Step: 4
Training loss: 3.0280752959369703
Validation loss: 2.479122491384207

Epoch: 5| Step: 5
Training loss: 2.3976377464716525
Validation loss: 2.4848633212284867

Epoch: 5| Step: 6
Training loss: 2.556429767583239
Validation loss: 2.486990847069172

Epoch: 5| Step: 7
Training loss: 2.444862592459605
Validation loss: 2.482324329683717

Epoch: 5| Step: 8
Training loss: 2.3142415267856804
Validation loss: 2.4895540312847553

Epoch: 5| Step: 9
Training loss: 2.5242200647773965
Validation loss: 2.4833655035785536

Epoch: 5| Step: 10
Training loss: 2.1101789284722887
Validation loss: 2.4834234526676027

Epoch: 5| Step: 11
Training loss: 2.660630955401569
Validation loss: 2.4825332660629487

Epoch: 109| Step: 0
Training loss: 2.500561460389946
Validation loss: 2.48980943432531

Epoch: 5| Step: 1
Training loss: 2.6162145827475536
Validation loss: 2.4876655842990285

Epoch: 5| Step: 2
Training loss: 2.7663940394944624
Validation loss: 2.48586769365645

Epoch: 5| Step: 3
Training loss: 2.2674760294428475
Validation loss: 2.490199664503547

Epoch: 5| Step: 4
Training loss: 2.2727693709896073
Validation loss: 2.491419343942864

Epoch: 5| Step: 5
Training loss: 2.7675675288975436
Validation loss: 2.4866326388591045

Epoch: 5| Step: 6
Training loss: 2.8523733997919734
Validation loss: 2.4812375056338962

Epoch: 5| Step: 7
Training loss: 2.0569158154416445
Validation loss: 2.4889265588043603

Epoch: 5| Step: 8
Training loss: 2.755223515161657
Validation loss: 2.4845363716482294

Epoch: 5| Step: 9
Training loss: 3.037994118519678
Validation loss: 2.4781447449483207

Epoch: 5| Step: 10
Training loss: 2.598442979578605
Validation loss: 2.4857729291679718

Epoch: 5| Step: 11
Training loss: 2.568510496385784
Validation loss: 2.4835947438930344

Epoch: 110| Step: 0
Training loss: 2.3367569420644974
Validation loss: 2.4835736923791805

Epoch: 5| Step: 1
Training loss: 2.788419590642083
Validation loss: 2.4816989561375276

Epoch: 5| Step: 2
Training loss: 2.761722203189142
Validation loss: 2.483083073169012

Epoch: 5| Step: 3
Training loss: 2.443585453201084
Validation loss: 2.4836447300238063

Epoch: 5| Step: 4
Training loss: 2.6385366996741477
Validation loss: 2.489808520636497

Epoch: 5| Step: 5
Training loss: 2.228371511040527
Validation loss: 2.4906859742617873

Epoch: 5| Step: 6
Training loss: 2.645860346458487
Validation loss: 2.4833605992550627

Epoch: 5| Step: 7
Training loss: 2.5502325288555374
Validation loss: 2.4880317750567347

Epoch: 5| Step: 8
Training loss: 2.4292742509611913
Validation loss: 2.485977216012104

Epoch: 5| Step: 9
Training loss: 2.4803410054150437
Validation loss: 2.4844932767915644

Epoch: 5| Step: 10
Training loss: 3.083247690471977
Validation loss: 2.4842860447854584

Epoch: 5| Step: 11
Training loss: 3.0732215514579653
Validation loss: 2.4890123827227635

Epoch: 111| Step: 0
Training loss: 2.4631448201618866
Validation loss: 2.4845602018473816

Epoch: 5| Step: 1
Training loss: 2.6465476165760173
Validation loss: 2.4875172111260855

Epoch: 5| Step: 2
Training loss: 2.4386994760696776
Validation loss: 2.487513744693272

Epoch: 5| Step: 3
Training loss: 2.912720890427826
Validation loss: 2.4883511392229276

Epoch: 5| Step: 4
Training loss: 3.10000563590245
Validation loss: 2.484405933243531

Epoch: 5| Step: 5
Training loss: 2.3229789440434008
Validation loss: 2.4835814962197786

Epoch: 5| Step: 6
Training loss: 2.730135350208217
Validation loss: 2.487715384808752

Epoch: 5| Step: 7
Training loss: 2.013041888904544
Validation loss: 2.4861385276165935

Epoch: 5| Step: 8
Training loss: 2.6825146233692454
Validation loss: 2.482759634310965

Epoch: 5| Step: 9
Training loss: 2.142557204917239
Validation loss: 2.4801169058300743

Epoch: 5| Step: 10
Training loss: 2.9503779476322203
Validation loss: 2.4764915841235133

Epoch: 5| Step: 11
Training loss: 1.8378492425684496
Validation loss: 2.4788010565391647

Epoch: 112| Step: 0
Training loss: 2.6500051354412486
Validation loss: 2.4776586319044562

Epoch: 5| Step: 1
Training loss: 2.6057978798219597
Validation loss: 2.474664606703894

Epoch: 5| Step: 2
Training loss: 2.505002928711175
Validation loss: 2.477297339941506

Epoch: 5| Step: 3
Training loss: 2.7231460634213236
Validation loss: 2.4736324430280434

Epoch: 5| Step: 4
Training loss: 3.0168238021081555
Validation loss: 2.4833868328727893

Epoch: 5| Step: 5
Training loss: 2.256146301253514
Validation loss: 2.4771276003767198

Epoch: 5| Step: 6
Training loss: 2.538112333482643
Validation loss: 2.479331998093965

Epoch: 5| Step: 7
Training loss: 2.9415544166076986
Validation loss: 2.4770362673609405

Epoch: 5| Step: 8
Training loss: 2.8088939012946836
Validation loss: 2.478089656954622

Epoch: 5| Step: 9
Training loss: 2.2212000469543685
Validation loss: 2.476747596153509

Epoch: 5| Step: 10
Training loss: 1.8873310872469604
Validation loss: 2.4818337877153724

Epoch: 5| Step: 11
Training loss: 2.9000387781115586
Validation loss: 2.480802554600715

Epoch: 113| Step: 0
Training loss: 2.2891439481963483
Validation loss: 2.4836179791492907

Epoch: 5| Step: 1
Training loss: 2.7135591610120646
Validation loss: 2.48062476721279

Epoch: 5| Step: 2
Training loss: 2.340774885810261
Validation loss: 2.4798870696227833

Epoch: 5| Step: 3
Training loss: 3.0066959042477372
Validation loss: 2.485066627502148

Epoch: 5| Step: 4
Training loss: 2.2356025151632934
Validation loss: 2.484666647276824

Epoch: 5| Step: 5
Training loss: 2.491888811634327
Validation loss: 2.4793751626270684

Epoch: 5| Step: 6
Training loss: 2.4637997406729086
Validation loss: 2.484472856653673

Epoch: 5| Step: 7
Training loss: 2.7659555873380737
Validation loss: 2.4824000131768407

Epoch: 5| Step: 8
Training loss: 2.5369570409605764
Validation loss: 2.4816066144560867

Epoch: 5| Step: 9
Training loss: 2.524108891884342
Validation loss: 2.480174622406073

Epoch: 5| Step: 10
Training loss: 2.879801017192092
Validation loss: 2.480679228255516

Epoch: 5| Step: 11
Training loss: 2.9211651760937705
Validation loss: 2.4779834361328392

Epoch: 114| Step: 0
Training loss: 2.4733353536482765
Validation loss: 2.4769412331746095

Epoch: 5| Step: 1
Training loss: 2.675619256900718
Validation loss: 2.474420738507295

Epoch: 5| Step: 2
Training loss: 2.7009278116137394
Validation loss: 2.4698836102071327

Epoch: 5| Step: 3
Training loss: 2.1958385122432356
Validation loss: 2.4763277867202405

Epoch: 5| Step: 4
Training loss: 2.3414353194164867
Validation loss: 2.4718269697137467

Epoch: 5| Step: 5
Training loss: 2.8617922045262487
Validation loss: 2.479120800384753

Epoch: 5| Step: 6
Training loss: 2.228206094814943
Validation loss: 2.474518478960211

Epoch: 5| Step: 7
Training loss: 2.498374887603942
Validation loss: 2.4856573390159875

Epoch: 5| Step: 8
Training loss: 2.4890599252576138
Validation loss: 2.4793921950416897

Epoch: 5| Step: 9
Training loss: 3.113410669410466
Validation loss: 2.4825968666936626

Epoch: 5| Step: 10
Training loss: 2.8567875062125037
Validation loss: 2.484516707563454

Epoch: 5| Step: 11
Training loss: 2.435125710690862
Validation loss: 2.4855791028979084

Epoch: 115| Step: 0
Training loss: 2.142821027814706
Validation loss: 2.4812369531245215

Epoch: 5| Step: 1
Training loss: 2.600115582758038
Validation loss: 2.4830785883635524

Epoch: 5| Step: 2
Training loss: 2.539125318483727
Validation loss: 2.4766290537398383

Epoch: 5| Step: 3
Training loss: 2.680909525988455
Validation loss: 2.475841991016098

Epoch: 5| Step: 4
Training loss: 3.073703436698547
Validation loss: 2.4770582647528268

Epoch: 5| Step: 5
Training loss: 3.06701918386474
Validation loss: 2.4755230415976994

Epoch: 5| Step: 6
Training loss: 2.073433650228093
Validation loss: 2.481665839542467

Epoch: 5| Step: 7
Training loss: 1.9924241467711128
Validation loss: 2.4761785937686147

Epoch: 5| Step: 8
Training loss: 2.7912085048052866
Validation loss: 2.4812941572102067

Epoch: 5| Step: 9
Training loss: 2.51282330990181
Validation loss: 2.477814407094516

Epoch: 5| Step: 10
Training loss: 2.942211998236347
Validation loss: 2.478411917574673

Epoch: 5| Step: 11
Training loss: 1.248882270810914
Validation loss: 2.4751271722533374

Epoch: 116| Step: 0
Training loss: 2.12365231132695
Validation loss: 2.473640599510244

Epoch: 5| Step: 1
Training loss: 3.1039877377002405
Validation loss: 2.4767331205974776

Epoch: 5| Step: 2
Training loss: 2.7703243352182154
Validation loss: 2.482749587186803

Epoch: 5| Step: 3
Training loss: 2.8304689925907294
Validation loss: 2.485914988628629

Epoch: 5| Step: 4
Training loss: 2.356983918450335
Validation loss: 2.483451723683885

Epoch: 5| Step: 5
Training loss: 2.2545757390250807
Validation loss: 2.481910690951427

Epoch: 5| Step: 6
Training loss: 2.55378347844508
Validation loss: 2.4832463689805886

Epoch: 5| Step: 7
Training loss: 2.532539698448723
Validation loss: 2.483471700207956

Epoch: 5| Step: 8
Training loss: 3.0681744379539224
Validation loss: 2.4888448511094423

Epoch: 5| Step: 9
Training loss: 2.4197858105601076
Validation loss: 2.4892465624349893

Epoch: 5| Step: 10
Training loss: 2.4939442723830942
Validation loss: 2.4909701986818367

Epoch: 5| Step: 11
Training loss: 2.492226722910882
Validation loss: 2.4887811327324516

Epoch: 117| Step: 0
Training loss: 2.6707532881606086
Validation loss: 2.489958700242255

Epoch: 5| Step: 1
Training loss: 2.7246665155578578
Validation loss: 2.4856183641444414

Epoch: 5| Step: 2
Training loss: 2.626683558137029
Validation loss: 2.4866802109122763

Epoch: 5| Step: 3
Training loss: 2.8256023811256856
Validation loss: 2.4864080176012258

Epoch: 5| Step: 4
Training loss: 2.699907802844361
Validation loss: 2.4808633265210807

Epoch: 5| Step: 5
Training loss: 2.6909797673820353
Validation loss: 2.483584788145184

Epoch: 5| Step: 6
Training loss: 2.3012485515335057
Validation loss: 2.489016832889422

Epoch: 5| Step: 7
Training loss: 1.9086233904204257
Validation loss: 2.481281762035924

Epoch: 5| Step: 8
Training loss: 2.6363852508998207
Validation loss: 2.4812381342132523

Epoch: 5| Step: 9
Training loss: 2.456010421445028
Validation loss: 2.4809572474737287

Epoch: 5| Step: 10
Training loss: 2.6982855722568475
Validation loss: 2.481000307653291

Epoch: 5| Step: 11
Training loss: 3.5034908869262655
Validation loss: 2.481759389882292

Epoch: 118| Step: 0
Training loss: 2.5549993762110716
Validation loss: 2.4760288461800752

Epoch: 5| Step: 1
Training loss: 2.829642041755928
Validation loss: 2.4727103301246527

Epoch: 5| Step: 2
Training loss: 3.0591049059524846
Validation loss: 2.4661795960598907

Epoch: 5| Step: 3
Training loss: 2.242937022549136
Validation loss: 2.471334227524057

Epoch: 5| Step: 4
Training loss: 2.610237572917981
Validation loss: 2.468264709128742

Epoch: 5| Step: 5
Training loss: 3.2004247681509774
Validation loss: 2.4733611433461307

Epoch: 5| Step: 6
Training loss: 2.3277645984216884
Validation loss: 2.4659209721229343

Epoch: 5| Step: 7
Training loss: 2.366453453542753
Validation loss: 2.469064048718645

Epoch: 5| Step: 8
Training loss: 2.419531198759636
Validation loss: 2.4654082806988136

Epoch: 5| Step: 9
Training loss: 2.6092109857054537
Validation loss: 2.4776495664675253

Epoch: 5| Step: 10
Training loss: 1.9865631894657558
Validation loss: 2.471673397486759

Epoch: 5| Step: 11
Training loss: 1.880405517833593
Validation loss: 2.4722371682835624

Epoch: 119| Step: 0
Training loss: 2.4343626910817866
Validation loss: 2.466790193985132

Epoch: 5| Step: 1
Training loss: 2.476821260141212
Validation loss: 2.469535314421229

Epoch: 5| Step: 2
Training loss: 2.4107076796183824
Validation loss: 2.472140105154077

Epoch: 5| Step: 3
Training loss: 2.9950808885760947
Validation loss: 2.468820337508765

Epoch: 5| Step: 4
Training loss: 2.7109023210073375
Validation loss: 2.4678518134148897

Epoch: 5| Step: 5
Training loss: 2.554507094613253
Validation loss: 2.4670465845859644

Epoch: 5| Step: 6
Training loss: 2.8450530703242474
Validation loss: 2.474712290401437

Epoch: 5| Step: 7
Training loss: 2.157210868477883
Validation loss: 2.477803413784036

Epoch: 5| Step: 8
Training loss: 2.2994832909713745
Validation loss: 2.4799996480633886

Epoch: 5| Step: 9
Training loss: 2.7818166605570687
Validation loss: 2.481181693558185

Epoch: 5| Step: 10
Training loss: 2.5938114940293633
Validation loss: 2.481499309169989

Epoch: 5| Step: 11
Training loss: 2.7654676662024595
Validation loss: 2.483069742751164

Epoch: 120| Step: 0
Training loss: 3.011722233197564
Validation loss: 2.4813979003091915

Epoch: 5| Step: 1
Training loss: 2.495928691725725
Validation loss: 2.472986019536427

Epoch: 5| Step: 2
Training loss: 2.691807156450307
Validation loss: 2.475113223035631

Epoch: 5| Step: 3
Training loss: 2.6782939167679016
Validation loss: 2.4687808473486696

Epoch: 5| Step: 4
Training loss: 2.9942804491772637
Validation loss: 2.46731675469574

Epoch: 5| Step: 5
Training loss: 2.3154397784865517
Validation loss: 2.46865557236496

Epoch: 5| Step: 6
Training loss: 2.3365730773351685
Validation loss: 2.464681484001772

Epoch: 5| Step: 7
Training loss: 2.0161095561655764
Validation loss: 2.4694287055259805

Epoch: 5| Step: 8
Training loss: 2.331910198910166
Validation loss: 2.4745010637296585

Epoch: 5| Step: 9
Training loss: 2.0136673757981987
Validation loss: 2.472821640421343

Epoch: 5| Step: 10
Training loss: 3.204851829448323
Validation loss: 2.4738328252711868

Epoch: 5| Step: 11
Training loss: 2.215688285408054
Validation loss: 2.460604977218221

Epoch: 121| Step: 0
Training loss: 2.400470182933254
Validation loss: 2.4627616015607523

Epoch: 5| Step: 1
Training loss: 2.7739908015697536
Validation loss: 2.4698239376792

Epoch: 5| Step: 2
Training loss: 2.5781503387130758
Validation loss: 2.4684203849328243

Epoch: 5| Step: 3
Training loss: 2.0331487144496734
Validation loss: 2.4715814328518566

Epoch: 5| Step: 4
Training loss: 2.5538663798592784
Validation loss: 2.4727794984109552

Epoch: 5| Step: 5
Training loss: 2.9671507694005865
Validation loss: 2.4712099342076224

Epoch: 5| Step: 6
Training loss: 2.0728503524933455
Validation loss: 2.4737836769424186

Epoch: 5| Step: 7
Training loss: 2.660760169579963
Validation loss: 2.4796600305020866

Epoch: 5| Step: 8
Training loss: 2.4889131758655365
Validation loss: 2.4772716313225276

Epoch: 5| Step: 9
Training loss: 2.59401269524614
Validation loss: 2.4843789986312323

Epoch: 5| Step: 10
Training loss: 2.8571269886393615
Validation loss: 2.4823738891861855

Epoch: 5| Step: 11
Training loss: 3.6475933658606876
Validation loss: 2.4808244865621947

Epoch: 122| Step: 0
Training loss: 1.7430961531546263
Validation loss: 2.478676524449552

Epoch: 5| Step: 1
Training loss: 2.821330301598048
Validation loss: 2.4762258451266725

Epoch: 5| Step: 2
Training loss: 2.7185184774803983
Validation loss: 2.478856028534898

Epoch: 5| Step: 3
Training loss: 2.640303372089556
Validation loss: 2.475968114081139

Epoch: 5| Step: 4
Training loss: 3.037297459509678
Validation loss: 2.4760220336028698

Epoch: 5| Step: 5
Training loss: 2.4600374059236785
Validation loss: 2.475956454567394

Epoch: 5| Step: 6
Training loss: 2.501318679164074
Validation loss: 2.474072693975662

Epoch: 5| Step: 7
Training loss: 2.421660383005866
Validation loss: 2.472585254230503

Epoch: 5| Step: 8
Training loss: 2.192241869773584
Validation loss: 2.468665560151478

Epoch: 5| Step: 9
Training loss: 2.7054551505645605
Validation loss: 2.461289409927686

Epoch: 5| Step: 10
Training loss: 2.6159495600116034
Validation loss: 2.465689730066507

Epoch: 5| Step: 11
Training loss: 3.3593290104046796
Validation loss: 2.462312832769417

Epoch: 123| Step: 0
Training loss: 2.795923337515737
Validation loss: 2.465471775111017

Epoch: 5| Step: 1
Training loss: 2.2587426193614935
Validation loss: 2.466988166244266

Epoch: 5| Step: 2
Training loss: 2.73427708041748
Validation loss: 2.4703417447132723

Epoch: 5| Step: 3
Training loss: 2.6004205436985295
Validation loss: 2.4637261187890944

Epoch: 5| Step: 4
Training loss: 2.3698568370088267
Validation loss: 2.465161778104363

Epoch: 5| Step: 5
Training loss: 1.9451534711799687
Validation loss: 2.4664549440835946

Epoch: 5| Step: 6
Training loss: 2.7162946816924203
Validation loss: 2.4670412169614795

Epoch: 5| Step: 7
Training loss: 2.6346123313564833
Validation loss: 2.4628444488819077

Epoch: 5| Step: 8
Training loss: 2.1350468261014783
Validation loss: 2.4663084568005265

Epoch: 5| Step: 9
Training loss: 2.5611318331818174
Validation loss: 2.4711057774631664

Epoch: 5| Step: 10
Training loss: 3.0724540405312424
Validation loss: 2.47481953070517

Epoch: 5| Step: 11
Training loss: 3.4070923489885234
Validation loss: 2.4708715971953215

Epoch: 124| Step: 0
Training loss: 2.790779333343027
Validation loss: 2.4734799066355513

Epoch: 5| Step: 1
Training loss: 2.5241613147167126
Validation loss: 2.4711650471869717

Epoch: 5| Step: 2
Training loss: 2.638159328690117
Validation loss: 2.473841764146536

Epoch: 5| Step: 3
Training loss: 2.4987379703356196
Validation loss: 2.4742271330851717

Epoch: 5| Step: 4
Training loss: 2.3953029764263545
Validation loss: 2.4753573480790987

Epoch: 5| Step: 5
Training loss: 2.4125373244486625
Validation loss: 2.4726542693296416

Epoch: 5| Step: 6
Training loss: 2.5708662091775065
Validation loss: 2.474624276461316

Epoch: 5| Step: 7
Training loss: 2.824334064414064
Validation loss: 2.4674842543262256

Epoch: 5| Step: 8
Training loss: 2.62050625489072
Validation loss: 2.4688051434889173

Epoch: 5| Step: 9
Training loss: 2.7033019256021618
Validation loss: 2.46757210022271

Epoch: 5| Step: 10
Training loss: 1.9297521171098608
Validation loss: 2.4652769793179314

Epoch: 5| Step: 11
Training loss: 3.257503796777979
Validation loss: 2.468895783123852

Epoch: 125| Step: 0
Training loss: 2.8136673094344204
Validation loss: 2.467294181255114

Epoch: 5| Step: 1
Training loss: 1.7682040797510663
Validation loss: 2.4642275782158456

Epoch: 5| Step: 2
Training loss: 2.5760821022431637
Validation loss: 2.460009324164669

Epoch: 5| Step: 3
Training loss: 2.6861080734654785
Validation loss: 2.4667027753257638

Epoch: 5| Step: 4
Training loss: 2.5253521059997444
Validation loss: 2.4686776967466257

Epoch: 5| Step: 5
Training loss: 2.4372783462295624
Validation loss: 2.4676301041765067

Epoch: 5| Step: 6
Training loss: 2.971924379662547
Validation loss: 2.4747900812798163

Epoch: 5| Step: 7
Training loss: 2.7845734017154253
Validation loss: 2.473650394482131

Epoch: 5| Step: 8
Training loss: 2.4737469285017766
Validation loss: 2.470688300408681

Epoch: 5| Step: 9
Training loss: 2.368609916953441
Validation loss: 2.4699652573938766

Epoch: 5| Step: 10
Training loss: 2.519390344745728
Validation loss: 2.470404344267301

Epoch: 5| Step: 11
Training loss: 3.1169474803329313
Validation loss: 2.4591006856715016

Epoch: 126| Step: 0
Training loss: 2.6354400472898045
Validation loss: 2.4616536102667537

Epoch: 5| Step: 1
Training loss: 2.3781303054810543
Validation loss: 2.4656048107086153

Epoch: 5| Step: 2
Training loss: 2.6985178588140526
Validation loss: 2.4634756209786195

Epoch: 5| Step: 3
Training loss: 2.4935524769048123
Validation loss: 2.4680171957370094

Epoch: 5| Step: 4
Training loss: 2.500495670771765
Validation loss: 2.4640849900816826

Epoch: 5| Step: 5
Training loss: 2.950909141493946
Validation loss: 2.4800409944412185

Epoch: 5| Step: 6
Training loss: 2.319177728979073
Validation loss: 2.488259838896436

Epoch: 5| Step: 7
Training loss: 2.375327740191137
Validation loss: 2.4810788022674966

Epoch: 5| Step: 8
Training loss: 2.9318148200974874
Validation loss: 2.475293340703147

Epoch: 5| Step: 9
Training loss: 2.5036287674713393
Validation loss: 2.4688865124909145

Epoch: 5| Step: 10
Training loss: 2.7393672166487915
Validation loss: 2.472686879880801

Epoch: 5| Step: 11
Training loss: 1.4061436083072125
Validation loss: 2.475302402729543

Epoch: 127| Step: 0
Training loss: 2.3609522921933817
Validation loss: 2.483678842170625

Epoch: 5| Step: 1
Training loss: 2.5973572064124406
Validation loss: 2.480402863996659

Epoch: 5| Step: 2
Training loss: 2.784283473162052
Validation loss: 2.480210222203223

Epoch: 5| Step: 3
Training loss: 2.1496569692509593
Validation loss: 2.484498078918277

Epoch: 5| Step: 4
Training loss: 2.9983640024660416
Validation loss: 2.4778247308190666

Epoch: 5| Step: 5
Training loss: 2.749555205006515
Validation loss: 2.4787703419035196

Epoch: 5| Step: 6
Training loss: 2.7102242446687654
Validation loss: 2.4842488278832833

Epoch: 5| Step: 7
Training loss: 2.3315189891600636
Validation loss: 2.4798167896277397

Epoch: 5| Step: 8
Training loss: 2.54473375048154
Validation loss: 2.481347384491526

Epoch: 5| Step: 9
Training loss: 2.6316712393387762
Validation loss: 2.4813077814210995

Epoch: 5| Step: 10
Training loss: 2.3547249753687254
Validation loss: 2.4748717953971253

Epoch: 5| Step: 11
Training loss: 3.1276782956365725
Validation loss: 2.4761608291430157

Epoch: 128| Step: 0
Training loss: 2.2413166760868224
Validation loss: 2.476943767894699

Epoch: 5| Step: 1
Training loss: 2.9594178338661936
Validation loss: 2.481854273596582

Epoch: 5| Step: 2
Training loss: 2.7036341369607144
Validation loss: 2.479382298545907

Epoch: 5| Step: 3
Training loss: 2.7224371451135907
Validation loss: 2.474006505129112

Epoch: 5| Step: 4
Training loss: 2.812199131449538
Validation loss: 2.476747235168103

Epoch: 5| Step: 5
Training loss: 2.19681549208722
Validation loss: 2.4765201849787144

Epoch: 5| Step: 6
Training loss: 2.47252569110047
Validation loss: 2.4707098517244668

Epoch: 5| Step: 7
Training loss: 2.121567590662161
Validation loss: 2.4698747173382336

Epoch: 5| Step: 8
Training loss: 2.574381474400895
Validation loss: 2.473922184462549

Epoch: 5| Step: 9
Training loss: 2.6010668399821424
Validation loss: 2.4664536511958657

Epoch: 5| Step: 10
Training loss: 2.800291138226843
Validation loss: 2.4652959425948

Epoch: 5| Step: 11
Training loss: 1.3127846182169047
Validation loss: 2.463144920989365

Epoch: 129| Step: 0
Training loss: 2.3336728961550675
Validation loss: 2.464061627078421

Epoch: 5| Step: 1
Training loss: 2.9427028599690987
Validation loss: 2.4600538534314835

Epoch: 5| Step: 2
Training loss: 2.1359575160441415
Validation loss: 2.4620424767000357

Epoch: 5| Step: 3
Training loss: 2.8620691166708525
Validation loss: 2.4575405876621375

Epoch: 5| Step: 4
Training loss: 2.9444603129825
Validation loss: 2.460434784581605

Epoch: 5| Step: 5
Training loss: 2.655883763814699
Validation loss: 2.460652503409854

Epoch: 5| Step: 6
Training loss: 2.8277965375989553
Validation loss: 2.463886322902742

Epoch: 5| Step: 7
Training loss: 2.2678290859928456
Validation loss: 2.45948732225434

Epoch: 5| Step: 8
Training loss: 2.362312357883372
Validation loss: 2.4584707905977137

Epoch: 5| Step: 9
Training loss: 2.2982091856417286
Validation loss: 2.4619583232834725

Epoch: 5| Step: 10
Training loss: 2.2248922943449525
Validation loss: 2.46833260544769

Epoch: 5| Step: 11
Training loss: 2.8781876514752285
Validation loss: 2.462570879572895

Epoch: 130| Step: 0
Training loss: 2.848547441513006
Validation loss: 2.4634594100435256

Epoch: 5| Step: 1
Training loss: 2.5577029475646613
Validation loss: 2.4707130562604047

Epoch: 5| Step: 2
Training loss: 2.871325259054803
Validation loss: 2.467132903886741

Epoch: 5| Step: 3
Training loss: 2.8826550283041206
Validation loss: 2.4683969100317427

Epoch: 5| Step: 4
Training loss: 2.2360791729949123
Validation loss: 2.4659313013258872

Epoch: 5| Step: 5
Training loss: 2.131371538830254
Validation loss: 2.4604137569758056

Epoch: 5| Step: 6
Training loss: 2.4490616305389747
Validation loss: 2.457848886397158

Epoch: 5| Step: 7
Training loss: 2.280688595605128
Validation loss: 2.457631937820604

Epoch: 5| Step: 8
Training loss: 2.601002859229159
Validation loss: 2.4637615933686616

Epoch: 5| Step: 9
Training loss: 2.6864965472856803
Validation loss: 2.472905829892494

Epoch: 5| Step: 10
Training loss: 2.216176326794439
Validation loss: 2.467913807926286

Epoch: 5| Step: 11
Training loss: 3.6838195019635362
Validation loss: 2.474135773301955

Epoch: 131| Step: 0
Training loss: 2.723403455966847
Validation loss: 2.4763075379419113

Epoch: 5| Step: 1
Training loss: 2.3174285948451163
Validation loss: 2.470178637415494

Epoch: 5| Step: 2
Training loss: 2.161138218227819
Validation loss: 2.4732669359439168

Epoch: 5| Step: 3
Training loss: 2.8704489470451784
Validation loss: 2.4769083277003214

Epoch: 5| Step: 4
Training loss: 2.482365305186232
Validation loss: 2.4750868796503225

Epoch: 5| Step: 5
Training loss: 2.777245714305703
Validation loss: 2.476126093876765

Epoch: 5| Step: 6
Training loss: 2.516097314696211
Validation loss: 2.474591063181048

Epoch: 5| Step: 7
Training loss: 2.8019977731416774
Validation loss: 2.474165216462415

Epoch: 5| Step: 8
Training loss: 2.1254855330537312
Validation loss: 2.4693025179953474

Epoch: 5| Step: 9
Training loss: 2.569324338242299
Validation loss: 2.4689350783108286

Epoch: 5| Step: 10
Training loss: 2.7916219812109633
Validation loss: 2.47058773047723

Epoch: 5| Step: 11
Training loss: 1.9821839739488336
Validation loss: 2.4663353309750433

Epoch: 132| Step: 0
Training loss: 2.5702022076628808
Validation loss: 2.4675039051853394

Epoch: 5| Step: 1
Training loss: 2.1267887889194217
Validation loss: 2.4609157561295256

Epoch: 5| Step: 2
Training loss: 2.3772167100411825
Validation loss: 2.4573672519220624

Epoch: 5| Step: 3
Training loss: 2.689094248024018
Validation loss: 2.4561457086865586

Epoch: 5| Step: 4
Training loss: 2.770240337811115
Validation loss: 2.464464919232911

Epoch: 5| Step: 5
Training loss: 2.6717170534798367
Validation loss: 2.457731598955234

Epoch: 5| Step: 6
Training loss: 3.0777008229109404
Validation loss: 2.460062119544757

Epoch: 5| Step: 7
Training loss: 2.4569686614829913
Validation loss: 2.4600713144021715

Epoch: 5| Step: 8
Training loss: 2.451298999909392
Validation loss: 2.4650749464873623

Epoch: 5| Step: 9
Training loss: 2.627498890507225
Validation loss: 2.4562083747967005

Epoch: 5| Step: 10
Training loss: 2.1003349718237723
Validation loss: 2.462300491319346

Epoch: 5| Step: 11
Training loss: 2.499191248731396
Validation loss: 2.461842139551687

Epoch: 133| Step: 0
Training loss: 2.407786683693629
Validation loss: 2.463537640934586

Epoch: 5| Step: 1
Training loss: 2.854442072665622
Validation loss: 2.4637580048063166

Epoch: 5| Step: 2
Training loss: 2.5515188929422528
Validation loss: 2.4602466118035315

Epoch: 5| Step: 3
Training loss: 2.2735876708886327
Validation loss: 2.4643012697737188

Epoch: 5| Step: 4
Training loss: 2.72265397322134
Validation loss: 2.467588851782205

Epoch: 5| Step: 5
Training loss: 2.933376095922477
Validation loss: 2.472789774860636

Epoch: 5| Step: 6
Training loss: 2.6769768264502787
Validation loss: 2.4682793148431066

Epoch: 5| Step: 7
Training loss: 2.760088362454124
Validation loss: 2.4699993473121613

Epoch: 5| Step: 8
Training loss: 1.8787450265215782
Validation loss: 2.464213178273304

Epoch: 5| Step: 9
Training loss: 2.758037957763606
Validation loss: 2.4696861656970857

Epoch: 5| Step: 10
Training loss: 2.186374265651788
Validation loss: 2.463946078752658

Epoch: 5| Step: 11
Training loss: 2.0459845549819904
Validation loss: 2.4670689408377986

Epoch: 134| Step: 0
Training loss: 2.6355283409451875
Validation loss: 2.458078368483641

Epoch: 5| Step: 1
Training loss: 2.308396900646751
Validation loss: 2.4606359751221385

Epoch: 5| Step: 2
Training loss: 2.5654141672838966
Validation loss: 2.4580708271972447

Epoch: 5| Step: 3
Training loss: 2.2229284780153367
Validation loss: 2.4606151995448764

Epoch: 5| Step: 4
Training loss: 2.6668833008827635
Validation loss: 2.463336441384791

Epoch: 5| Step: 5
Training loss: 2.9278553841632498
Validation loss: 2.461750005380168

Epoch: 5| Step: 6
Training loss: 2.093669491259103
Validation loss: 2.4605940725488566

Epoch: 5| Step: 7
Training loss: 2.578367464628308
Validation loss: 2.462430591863738

Epoch: 5| Step: 8
Training loss: 2.643865278900586
Validation loss: 2.465025002918247

Epoch: 5| Step: 9
Training loss: 2.744983084927054
Validation loss: 2.4677971638871243

Epoch: 5| Step: 10
Training loss: 2.6891542710510237
Validation loss: 2.4708834817267036

Epoch: 5| Step: 11
Training loss: 1.894841308390857
Validation loss: 2.4669340553105976

Epoch: 135| Step: 0
Training loss: 2.784314727987137
Validation loss: 2.4678739329261075

Epoch: 5| Step: 1
Training loss: 3.1417884000336396
Validation loss: 2.46821470130942

Epoch: 5| Step: 2
Training loss: 2.5863071880406325
Validation loss: 2.4632254062157726

Epoch: 5| Step: 3
Training loss: 2.764767185087749
Validation loss: 2.464126599465232

Epoch: 5| Step: 4
Training loss: 2.6460033472260562
Validation loss: 2.466364746421213

Epoch: 5| Step: 5
Training loss: 2.3473330765629874
Validation loss: 2.4641814674648495

Epoch: 5| Step: 6
Training loss: 2.1918164853524225
Validation loss: 2.4643338538009827

Epoch: 5| Step: 7
Training loss: 2.0473625243149387
Validation loss: 2.459567319305294

Epoch: 5| Step: 8
Training loss: 2.7143622760443735
Validation loss: 2.4635832435588885

Epoch: 5| Step: 9
Training loss: 2.241798393699662
Validation loss: 2.460277493088636

Epoch: 5| Step: 10
Training loss: 2.3223632586643483
Validation loss: 2.452110951596805

Epoch: 5| Step: 11
Training loss: 2.3021455874303642
Validation loss: 2.4522737050491745

Epoch: 136| Step: 0
Training loss: 2.8030067444419764
Validation loss: 2.4629059845790553

Epoch: 5| Step: 1
Training loss: 2.414076919265695
Validation loss: 2.4575785202787768

Epoch: 5| Step: 2
Training loss: 2.507152054474433
Validation loss: 2.464198717776

Epoch: 5| Step: 3
Training loss: 2.4553792521484543
Validation loss: 2.4617979533501524

Epoch: 5| Step: 4
Training loss: 2.7360017133897023
Validation loss: 2.4620866141300377

Epoch: 5| Step: 5
Training loss: 2.5320895651152195
Validation loss: 2.467493212174262

Epoch: 5| Step: 6
Training loss: 2.887463134266065
Validation loss: 2.4691515004540565

Epoch: 5| Step: 7
Training loss: 2.3349890170768224
Validation loss: 2.4684730326133932

Epoch: 5| Step: 8
Training loss: 2.4348071947470586
Validation loss: 2.4662673313352323

Epoch: 5| Step: 9
Training loss: 1.8014436442728956
Validation loss: 2.4722025104932235

Epoch: 5| Step: 10
Training loss: 2.9012705486051473
Validation loss: 2.472815096203917

Epoch: 5| Step: 11
Training loss: 2.345145763592604
Validation loss: 2.473737631874977

Epoch: 137| Step: 0
Training loss: 2.450778884083971
Validation loss: 2.470636459878569

Epoch: 5| Step: 1
Training loss: 2.4053670080510394
Validation loss: 2.4742822950301617

Epoch: 5| Step: 2
Training loss: 2.604065753253098
Validation loss: 2.4728565225354857

Epoch: 5| Step: 3
Training loss: 2.6543582238299748
Validation loss: 2.4760449347008393

Epoch: 5| Step: 4
Training loss: 2.370756474094387
Validation loss: 2.4755215748703483

Epoch: 5| Step: 5
Training loss: 2.4857070518726645
Validation loss: 2.4700199031928847

Epoch: 5| Step: 6
Training loss: 2.4540922359800894
Validation loss: 2.4687400809623945

Epoch: 5| Step: 7
Training loss: 2.7869334923918845
Validation loss: 2.470573604842729

Epoch: 5| Step: 8
Training loss: 2.900423176900664
Validation loss: 2.4613566894359034

Epoch: 5| Step: 9
Training loss: 2.612704043656451
Validation loss: 2.4641333401111725

Epoch: 5| Step: 10
Training loss: 2.262957140015605
Validation loss: 2.4643857543527483

Epoch: 5| Step: 11
Training loss: 2.3222794849184276
Validation loss: 2.460207258599994

Epoch: 138| Step: 0
Training loss: 2.4090239154013364
Validation loss: 2.4618925754164778

Epoch: 5| Step: 1
Training loss: 2.4047793563540463
Validation loss: 2.4517213040994705

Epoch: 5| Step: 2
Training loss: 2.4909682206094934
Validation loss: 2.472728023120153

Epoch: 5| Step: 3
Training loss: 2.529640722284074
Validation loss: 2.4621976784634

Epoch: 5| Step: 4
Training loss: 2.710503799089599
Validation loss: 2.4638464794883843

Epoch: 5| Step: 5
Training loss: 2.478878923488534
Validation loss: 2.468097713265205

Epoch: 5| Step: 6
Training loss: 2.4340080288242896
Validation loss: 2.468797196367668

Epoch: 5| Step: 7
Training loss: 3.050429867328256
Validation loss: 2.4752187201961053

Epoch: 5| Step: 8
Training loss: 2.6049890262423876
Validation loss: 2.4793817776766134

Epoch: 5| Step: 9
Training loss: 2.214772810296082
Validation loss: 2.4758699854826967

Epoch: 5| Step: 10
Training loss: 2.4666420351121734
Validation loss: 2.4752727202555

Epoch: 5| Step: 11
Training loss: 3.4388976983563704
Validation loss: 2.481107930809278

Epoch: 139| Step: 0
Training loss: 2.995295014029392
Validation loss: 2.479515272896687

Epoch: 5| Step: 1
Training loss: 2.5834274787565423
Validation loss: 2.4779127152713283

Epoch: 5| Step: 2
Training loss: 2.322676767411954
Validation loss: 2.4779093917561137

Epoch: 5| Step: 3
Training loss: 2.257388170752782
Validation loss: 2.482014144119682

Epoch: 5| Step: 4
Training loss: 2.540031084035672
Validation loss: 2.4854289804128533

Epoch: 5| Step: 5
Training loss: 2.6574000842025147
Validation loss: 2.484484168319228

Epoch: 5| Step: 6
Training loss: 2.609906901895173
Validation loss: 2.4853213844890374

Epoch: 5| Step: 7
Training loss: 2.2175674510790984
Validation loss: 2.4857464889393635

Epoch: 5| Step: 8
Training loss: 2.7762724665351493
Validation loss: 2.4824327017935444

Epoch: 5| Step: 9
Training loss: 2.8263110671601686
Validation loss: 2.4742999968595827

Epoch: 5| Step: 10
Training loss: 2.6373506368134376
Validation loss: 2.4802930954942353

Epoch: 5| Step: 11
Training loss: 1.5808136952490366
Validation loss: 2.4768730193534565

Epoch: 140| Step: 0
Training loss: 2.663424060200851
Validation loss: 2.4766906279944623

Epoch: 5| Step: 1
Training loss: 2.181217763930347
Validation loss: 2.472229308542056

Epoch: 5| Step: 2
Training loss: 2.526070464189641
Validation loss: 2.467140216144783

Epoch: 5| Step: 3
Training loss: 2.637114228153863
Validation loss: 2.462356069718655

Epoch: 5| Step: 4
Training loss: 2.454028892427839
Validation loss: 2.454070044873115

Epoch: 5| Step: 5
Training loss: 2.135044927727355
Validation loss: 2.4574535736705982

Epoch: 5| Step: 6
Training loss: 2.541297844146966
Validation loss: 2.464289825151699

Epoch: 5| Step: 7
Training loss: 3.133576792193426
Validation loss: 2.4662865890944157

Epoch: 5| Step: 8
Training loss: 2.3694051797686075
Validation loss: 2.4626833621530384

Epoch: 5| Step: 9
Training loss: 2.751729681339768
Validation loss: 2.467778248009209

Epoch: 5| Step: 10
Training loss: 2.3214809160304664
Validation loss: 2.4719339393440323

Epoch: 5| Step: 11
Training loss: 3.276357145336697
Validation loss: 2.4728179926951657

Epoch: 141| Step: 0
Training loss: 2.758794939153033
Validation loss: 2.4587071438978234

Epoch: 5| Step: 1
Training loss: 2.462493501451312
Validation loss: 2.4578698247977186

Epoch: 5| Step: 2
Training loss: 2.2296053255760118
Validation loss: 2.460421555541433

Epoch: 5| Step: 3
Training loss: 3.139767354134051
Validation loss: 2.4589620381644406

Epoch: 5| Step: 4
Training loss: 2.8557512845431625
Validation loss: 2.4635310841521925

Epoch: 5| Step: 5
Training loss: 1.8950721204616723
Validation loss: 2.4635274448481606

Epoch: 5| Step: 6
Training loss: 2.6134155421399097
Validation loss: 2.46563169658156

Epoch: 5| Step: 7
Training loss: 2.4803162054779415
Validation loss: 2.466520002446786

Epoch: 5| Step: 8
Training loss: 2.7173238938304602
Validation loss: 2.4580570822743697

Epoch: 5| Step: 9
Training loss: 2.351546683527582
Validation loss: 2.4675001247925166

Epoch: 5| Step: 10
Training loss: 2.2389430587227173
Validation loss: 2.4635591096374787

Epoch: 5| Step: 11
Training loss: 2.571049268691873
Validation loss: 2.4620401889078463

Epoch: 142| Step: 0
Training loss: 2.37313830038648
Validation loss: 2.463895447042664

Epoch: 5| Step: 1
Training loss: 2.5826526073111866
Validation loss: 2.4653774918880145

Epoch: 5| Step: 2
Training loss: 2.083527962812131
Validation loss: 2.4728880819282435

Epoch: 5| Step: 3
Training loss: 2.943683203974043
Validation loss: 2.4661147683968863

Epoch: 5| Step: 4
Training loss: 3.081826864410879
Validation loss: 2.465381827568966

Epoch: 5| Step: 5
Training loss: 2.2254630603488557
Validation loss: 2.4774988732782877

Epoch: 5| Step: 6
Training loss: 2.7888195455609237
Validation loss: 2.471154173036805

Epoch: 5| Step: 7
Training loss: 2.45889517188281
Validation loss: 2.472090690098621

Epoch: 5| Step: 8
Training loss: 2.613721322951767
Validation loss: 2.4784168637566575

Epoch: 5| Step: 9
Training loss: 2.5821319883608123
Validation loss: 2.471375863583304

Epoch: 5| Step: 10
Training loss: 2.188962066328681
Validation loss: 2.4720993338866015

Epoch: 5| Step: 11
Training loss: 2.356583718868406
Validation loss: 2.4660391269198207

Epoch: 143| Step: 0
Training loss: 2.960110913853475
Validation loss: 2.462582872742234

Epoch: 5| Step: 1
Training loss: 2.415876873352553
Validation loss: 2.453805897808478

Epoch: 5| Step: 2
Training loss: 2.3308130913370224
Validation loss: 2.4550308469814244

Epoch: 5| Step: 3
Training loss: 2.361109014273317
Validation loss: 2.4519811016368833

Epoch: 5| Step: 4
Training loss: 2.373224498239256
Validation loss: 2.4607069079029937

Epoch: 5| Step: 5
Training loss: 2.3790144872236323
Validation loss: 2.4510678779658543

Epoch: 5| Step: 6
Training loss: 2.6795373101588273
Validation loss: 2.4560707612519708

Epoch: 5| Step: 7
Training loss: 2.7254581346279414
Validation loss: 2.4575339744563345

Epoch: 5| Step: 8
Training loss: 2.272529237095393
Validation loss: 2.454331878650496

Epoch: 5| Step: 9
Training loss: 2.547018503464104
Validation loss: 2.455199124094141

Epoch: 5| Step: 10
Training loss: 2.950234264835121
Validation loss: 2.457603505200152

Epoch: 5| Step: 11
Training loss: 1.7294953581545611
Validation loss: 2.468727634827594

Epoch: 144| Step: 0
Training loss: 2.463886927685488
Validation loss: 2.468153539463448

Epoch: 5| Step: 1
Training loss: 2.7273260320887265
Validation loss: 2.471283019595691

Epoch: 5| Step: 2
Training loss: 2.7458223341710437
Validation loss: 2.4703814632626737

Epoch: 5| Step: 3
Training loss: 2.126396169330944
Validation loss: 2.474354928335047

Epoch: 5| Step: 4
Training loss: 2.725410283550732
Validation loss: 2.4736244471594655

Epoch: 5| Step: 5
Training loss: 2.5999475914001313
Validation loss: 2.474350676629392

Epoch: 5| Step: 6
Training loss: 2.2753463020428275
Validation loss: 2.4665453438520855

Epoch: 5| Step: 7
Training loss: 2.3455182335347544
Validation loss: 2.4649935282376583

Epoch: 5| Step: 8
Training loss: 2.765662758779583
Validation loss: 2.4603939889244413

Epoch: 5| Step: 9
Training loss: 2.3237913620311286
Validation loss: 2.459016791128255

Epoch: 5| Step: 10
Training loss: 2.8384395102687305
Validation loss: 2.4545397698044105

Epoch: 5| Step: 11
Training loss: 1.643871474038265
Validation loss: 2.4577754581131295

Epoch: 145| Step: 0
Training loss: 2.4757107494424275
Validation loss: 2.454719652839072

Epoch: 5| Step: 1
Training loss: 2.573346327351918
Validation loss: 2.4479390867031734

Epoch: 5| Step: 2
Training loss: 2.241368479791069
Validation loss: 2.4521894432537557

Epoch: 5| Step: 3
Training loss: 2.7100710844732374
Validation loss: 2.45609948260876

Epoch: 5| Step: 4
Training loss: 2.989990383885463
Validation loss: 2.449288683090113

Epoch: 5| Step: 5
Training loss: 2.5220775423645696
Validation loss: 2.446987650824916

Epoch: 5| Step: 6
Training loss: 2.507231362767567
Validation loss: 2.451344088600383

Epoch: 5| Step: 7
Training loss: 2.516818124958793
Validation loss: 2.459415643397383

Epoch: 5| Step: 8
Training loss: 2.4849060258807567
Validation loss: 2.457282279431787

Epoch: 5| Step: 9
Training loss: 1.9421217154596444
Validation loss: 2.467538375337066

Epoch: 5| Step: 10
Training loss: 2.5536768602829105
Validation loss: 2.4654750468945306

Epoch: 5| Step: 11
Training loss: 3.2177786240948336
Validation loss: 2.4728700164748307

Epoch: 146| Step: 0
Training loss: 2.8721893503786813
Validation loss: 2.4734316067716784

Epoch: 5| Step: 1
Training loss: 2.836198274587127
Validation loss: 2.467753458690696

Epoch: 5| Step: 2
Training loss: 2.364283224770491
Validation loss: 2.4584830744984845

Epoch: 5| Step: 3
Training loss: 2.4441201712600096
Validation loss: 2.4620599195324973

Epoch: 5| Step: 4
Training loss: 2.8312288397194045
Validation loss: 2.4616450468309337

Epoch: 5| Step: 5
Training loss: 2.2542208182646077
Validation loss: 2.456099328911364

Epoch: 5| Step: 6
Training loss: 2.5801099129854794
Validation loss: 2.451720246555694

Epoch: 5| Step: 7
Training loss: 2.4560674041358164
Validation loss: 2.4524606789247216

Epoch: 5| Step: 8
Training loss: 2.0165456399252686
Validation loss: 2.4600706965669796

Epoch: 5| Step: 9
Training loss: 2.348550990973402
Validation loss: 2.454412268367075

Epoch: 5| Step: 10
Training loss: 2.7524588602787246
Validation loss: 2.457618905906882

Epoch: 5| Step: 11
Training loss: 2.653607568786288
Validation loss: 2.4538269233370724

Epoch: 147| Step: 0
Training loss: 1.867939179241056
Validation loss: 2.4563729435806296

Epoch: 5| Step: 1
Training loss: 3.05964371745051
Validation loss: 2.4560611267207673

Epoch: 5| Step: 2
Training loss: 2.6204669504248748
Validation loss: 2.4556319250201892

Epoch: 5| Step: 3
Training loss: 2.4295446225072523
Validation loss: 2.451335031213744

Epoch: 5| Step: 4
Training loss: 2.1842481147903805
Validation loss: 2.4546889323119694

Epoch: 5| Step: 5
Training loss: 2.560756648568875
Validation loss: 2.4500352916965342

Epoch: 5| Step: 6
Training loss: 2.7542848150984467
Validation loss: 2.451337709934262

Epoch: 5| Step: 7
Training loss: 2.0636467491120785
Validation loss: 2.4530111112297597

Epoch: 5| Step: 8
Training loss: 2.9166619618695777
Validation loss: 2.4542495980415433

Epoch: 5| Step: 9
Training loss: 2.4244638695867673
Validation loss: 2.45848231483798

Epoch: 5| Step: 10
Training loss: 2.713623650911567
Validation loss: 2.4603106189734967

Epoch: 5| Step: 11
Training loss: 2.559289921987182
Validation loss: 2.4560458032082053

Epoch: 148| Step: 0
Training loss: 2.368075566162204
Validation loss: 2.4616011516924363

Epoch: 5| Step: 1
Training loss: 2.817372911458989
Validation loss: 2.460091779600442

Epoch: 5| Step: 2
Training loss: 3.0199250708373016
Validation loss: 2.463900886030017

Epoch: 5| Step: 3
Training loss: 2.6266363583993
Validation loss: 2.4673545007795785

Epoch: 5| Step: 4
Training loss: 2.4995805388461125
Validation loss: 2.4666461792838232

Epoch: 5| Step: 5
Training loss: 2.409387796766286
Validation loss: 2.4656349681528655

Epoch: 5| Step: 6
Training loss: 2.3710527243670723
Validation loss: 2.4558522640914315

Epoch: 5| Step: 7
Training loss: 2.5246969097768095
Validation loss: 2.4636022198730805

Epoch: 5| Step: 8
Training loss: 2.5803557946073865
Validation loss: 2.4481784653508414

Epoch: 5| Step: 9
Training loss: 2.6551741272459126
Validation loss: 2.4589308232179286

Epoch: 5| Step: 10
Training loss: 1.9489788144732993
Validation loss: 2.456821374061298

Epoch: 5| Step: 11
Training loss: 1.7569699451001515
Validation loss: 2.4642171854326183

Epoch: 149| Step: 0
Training loss: 3.056168687358939
Validation loss: 2.4574509743806074

Epoch: 5| Step: 1
Training loss: 2.9295620090310943
Validation loss: 2.4594750514475403

Epoch: 5| Step: 2
Training loss: 2.71015756254585
Validation loss: 2.4578342469925203

Epoch: 5| Step: 3
Training loss: 2.231813256043407
Validation loss: 2.4514876001480004

Epoch: 5| Step: 4
Training loss: 2.1924278339614527
Validation loss: 2.4556819362420232

Epoch: 5| Step: 5
Training loss: 1.7401969725831186
Validation loss: 2.456287423059883

Epoch: 5| Step: 6
Training loss: 2.4248352663383494
Validation loss: 2.457299095073585

Epoch: 5| Step: 7
Training loss: 2.5051348405131475
Validation loss: 2.455131677869448

Epoch: 5| Step: 8
Training loss: 2.608323119349687
Validation loss: 2.4617582879926276

Epoch: 5| Step: 9
Training loss: 2.562304233423334
Validation loss: 2.469369814523015

Epoch: 5| Step: 10
Training loss: 2.3835192023228586
Validation loss: 2.4650111597503646

Epoch: 5| Step: 11
Training loss: 3.3983872683967284
Validation loss: 2.462349013558476

Epoch: 150| Step: 0
Training loss: 2.6089995336799015
Validation loss: 2.460347959758005

Epoch: 5| Step: 1
Training loss: 2.1619136346087187
Validation loss: 2.4614730454073963

Epoch: 5| Step: 2
Training loss: 2.4557070415925426
Validation loss: 2.455310647656366

Epoch: 5| Step: 3
Training loss: 2.43283358192987
Validation loss: 2.4558778753524795

Epoch: 5| Step: 4
Training loss: 2.6563376019561984
Validation loss: 2.463338615055212

Epoch: 5| Step: 5
Training loss: 2.6723121151660107
Validation loss: 2.459206035582843

Epoch: 5| Step: 6
Training loss: 2.2953604550996887
Validation loss: 2.4661034550528513

Epoch: 5| Step: 7
Training loss: 2.578384941174748
Validation loss: 2.4595368410830534

Epoch: 5| Step: 8
Training loss: 2.636504078356032
Validation loss: 2.455665241001382

Epoch: 5| Step: 9
Training loss: 2.7276446536802568
Validation loss: 2.4555241744295526

Epoch: 5| Step: 10
Training loss: 2.513285811031473
Validation loss: 2.4546867509820944

Epoch: 5| Step: 11
Training loss: 1.9931833807360912
Validation loss: 2.454127515864841

Epoch: 151| Step: 0
Training loss: 2.780425560303084
Validation loss: 2.449847311578561

Epoch: 5| Step: 1
Training loss: 2.3761843689629716
Validation loss: 2.45211866110798

Epoch: 5| Step: 2
Training loss: 2.4973907205465022
Validation loss: 2.45785715992604

Epoch: 5| Step: 3
Training loss: 2.1442485129604854
Validation loss: 2.4569277880566296

Epoch: 5| Step: 4
Training loss: 2.628504548125299
Validation loss: 2.451816418369546

Epoch: 5| Step: 5
Training loss: 2.316977522140482
Validation loss: 2.452164846770756

Epoch: 5| Step: 6
Training loss: 2.911570283560622
Validation loss: 2.4489292214979663

Epoch: 5| Step: 7
Training loss: 2.7159837703079472
Validation loss: 2.4596562557169004

Epoch: 5| Step: 8
Training loss: 2.4729358581295333
Validation loss: 2.4495190320240807

Epoch: 5| Step: 9
Training loss: 2.7039664838508215
Validation loss: 2.458292505496376

Epoch: 5| Step: 10
Training loss: 2.294172084962225
Validation loss: 2.4522256235168616

Epoch: 5| Step: 11
Training loss: 1.8299806745999203
Validation loss: 2.449285892618792

Epoch: 152| Step: 0
Training loss: 2.638366365288212
Validation loss: 2.456163848615018

Epoch: 5| Step: 1
Training loss: 1.8812392377070295
Validation loss: 2.451134682179388

Epoch: 5| Step: 2
Training loss: 2.8167193658025744
Validation loss: 2.4538922456529764

Epoch: 5| Step: 3
Training loss: 2.318665507543156
Validation loss: 2.4542541820765997

Epoch: 5| Step: 4
Training loss: 2.8086878902696735
Validation loss: 2.459304675591729

Epoch: 5| Step: 5
Training loss: 2.5638329365379975
Validation loss: 2.4587499190128317

Epoch: 5| Step: 6
Training loss: 2.2788603298411214
Validation loss: 2.4567197431393177

Epoch: 5| Step: 7
Training loss: 2.1635249051978525
Validation loss: 2.4555471048729918

Epoch: 5| Step: 8
Training loss: 2.7998700861083665
Validation loss: 2.4480929182734363

Epoch: 5| Step: 9
Training loss: 2.618825462546844
Validation loss: 2.4482198378672977

Epoch: 5| Step: 10
Training loss: 2.3655090424552903
Validation loss: 2.4488378834008966

Epoch: 5| Step: 11
Training loss: 3.5949376009856513
Validation loss: 2.442585738033093

Epoch: 153| Step: 0
Training loss: 2.47378384158834
Validation loss: 2.4365247218065567

Epoch: 5| Step: 1
Training loss: 2.047077896894642
Validation loss: 2.4502433527867433

Epoch: 5| Step: 2
Training loss: 2.6494136125540995
Validation loss: 2.462524277911104

Epoch: 5| Step: 3
Training loss: 2.1844917320746355
Validation loss: 2.45149975289739

Epoch: 5| Step: 4
Training loss: 2.9023097409788234
Validation loss: 2.456023012921427

Epoch: 5| Step: 5
Training loss: 2.494680658364761
Validation loss: 2.4575986080785635

Epoch: 5| Step: 6
Training loss: 2.2535280541738296
Validation loss: 2.4557202090561496

Epoch: 5| Step: 7
Training loss: 2.285110760097437
Validation loss: 2.4509391400614926

Epoch: 5| Step: 8
Training loss: 2.5913808642556524
Validation loss: 2.4589610847337737

Epoch: 5| Step: 9
Training loss: 2.349600648427789
Validation loss: 2.4634046187128513

Epoch: 5| Step: 10
Training loss: 3.140759821033434
Validation loss: 2.4611282032539816

Epoch: 5| Step: 11
Training loss: 2.9434837917466763
Validation loss: 2.4697530857410186

Epoch: 154| Step: 0
Training loss: 2.3936056865486894
Validation loss: 2.473778476535121

Epoch: 5| Step: 1
Training loss: 2.7794046173336238
Validation loss: 2.475113979598585

Epoch: 5| Step: 2
Training loss: 1.7212402336824222
Validation loss: 2.469651546523076

Epoch: 5| Step: 3
Training loss: 2.2169743269421955
Validation loss: 2.47083740271565

Epoch: 5| Step: 4
Training loss: 2.813252411969706
Validation loss: 2.4687739041132875

Epoch: 5| Step: 5
Training loss: 2.573456392294136
Validation loss: 2.4667272127513393

Epoch: 5| Step: 6
Training loss: 2.406421803868209
Validation loss: 2.4661043171004757

Epoch: 5| Step: 7
Training loss: 2.7533765351028863
Validation loss: 2.4637941442128595

Epoch: 5| Step: 8
Training loss: 2.852702041143953
Validation loss: 2.4579819304182555

Epoch: 5| Step: 9
Training loss: 3.0280951373475102
Validation loss: 2.4484838248039207

Epoch: 5| Step: 10
Training loss: 2.122217376008861
Validation loss: 2.454681595103776

Epoch: 5| Step: 11
Training loss: 1.8906748741444335
Validation loss: 2.445333535588373

Epoch: 155| Step: 0
Training loss: 2.5666027255164874
Validation loss: 2.450432976834544

Epoch: 5| Step: 1
Training loss: 1.9816046773370977
Validation loss: 2.444969323790782

Epoch: 5| Step: 2
Training loss: 2.5272597898896865
Validation loss: 2.451397532579014

Epoch: 5| Step: 3
Training loss: 2.7176392138634804
Validation loss: 2.465129434722176

Epoch: 5| Step: 4
Training loss: 2.647412667279429
Validation loss: 2.472760644750901

Epoch: 5| Step: 5
Training loss: 3.0048928097920307
Validation loss: 2.4777744909610626

Epoch: 5| Step: 6
Training loss: 2.7901272491094637
Validation loss: 2.477453641079227

Epoch: 5| Step: 7
Training loss: 2.7242807716549406
Validation loss: 2.465628638544851

Epoch: 5| Step: 8
Training loss: 2.2590258021137073
Validation loss: 2.469651616916358

Epoch: 5| Step: 9
Training loss: 2.6613714772563437
Validation loss: 2.4649085445925603

Epoch: 5| Step: 10
Training loss: 1.826790477403947
Validation loss: 2.4666290306643868

Epoch: 5| Step: 11
Training loss: 2.1913984165969618
Validation loss: 2.4737247691410653

Epoch: 156| Step: 0
Training loss: 2.4503292991277354
Validation loss: 2.46416656735596

Epoch: 5| Step: 1
Training loss: 2.6499995573511295
Validation loss: 2.4691497100902726

Epoch: 5| Step: 2
Training loss: 2.051672402174262
Validation loss: 2.4683690642355707

Epoch: 5| Step: 3
Training loss: 2.416811763310019
Validation loss: 2.457174207028899

Epoch: 5| Step: 4
Training loss: 2.6978508095576936
Validation loss: 2.4583391995009785

Epoch: 5| Step: 5
Training loss: 2.7163459409086537
Validation loss: 2.45916006901329

Epoch: 5| Step: 6
Training loss: 2.3946125956373017
Validation loss: 2.455507393157762

Epoch: 5| Step: 7
Training loss: 2.5596398930295887
Validation loss: 2.455758501499946

Epoch: 5| Step: 8
Training loss: 2.5225509172637106
Validation loss: 2.4485651144865797

Epoch: 5| Step: 9
Training loss: 2.977945161815406
Validation loss: 2.4531014232757897

Epoch: 5| Step: 10
Training loss: 2.461113042474261
Validation loss: 2.4462267026992284

Epoch: 5| Step: 11
Training loss: 1.8106379974709859
Validation loss: 2.4490187064879447

Epoch: 157| Step: 0
Training loss: 2.8053305906069634
Validation loss: 2.447841039801518

Epoch: 5| Step: 1
Training loss: 2.48132645803883
Validation loss: 2.4503209555846968

Epoch: 5| Step: 2
Training loss: 2.1023462812223475
Validation loss: 2.448321574115581

Epoch: 5| Step: 3
Training loss: 2.8340279531776127
Validation loss: 2.4479307837113025

Epoch: 5| Step: 4
Training loss: 2.4126238934422615
Validation loss: 2.456413207484189

Epoch: 5| Step: 5
Training loss: 2.2491832946336068
Validation loss: 2.455778699249259

Epoch: 5| Step: 6
Training loss: 2.4370586289094867
Validation loss: 2.4497140346095225

Epoch: 5| Step: 7
Training loss: 2.4977156693183273
Validation loss: 2.454663051659113

Epoch: 5| Step: 8
Training loss: 2.7736479343582037
Validation loss: 2.4613936511137657

Epoch: 5| Step: 9
Training loss: 2.102816636490605
Validation loss: 2.454056030612069

Epoch: 5| Step: 10
Training loss: 2.8920411636040004
Validation loss: 2.4625278521348806

Epoch: 5| Step: 11
Training loss: 3.0678909497830498
Validation loss: 2.452587194269936

Epoch: 158| Step: 0
Training loss: 2.381448524189481
Validation loss: 2.4584467479169327

Epoch: 5| Step: 1
Training loss: 2.823523302574187
Validation loss: 2.452546940463516

Epoch: 5| Step: 2
Training loss: 2.6174128648888475
Validation loss: 2.455870673160363

Epoch: 5| Step: 3
Training loss: 2.212184486952927
Validation loss: 2.4530310197715055

Epoch: 5| Step: 4
Training loss: 2.2748272505347282
Validation loss: 2.4554603863762927

Epoch: 5| Step: 5
Training loss: 2.250068345621315
Validation loss: 2.456118039476339

Epoch: 5| Step: 6
Training loss: 2.466888981758509
Validation loss: 2.455588583834385

Epoch: 5| Step: 7
Training loss: 2.185623453961666
Validation loss: 2.448454592153569

Epoch: 5| Step: 8
Training loss: 2.6032589258590275
Validation loss: 2.4545287268897598

Epoch: 5| Step: 9
Training loss: 2.5068834907351807
Validation loss: 2.448719584224366

Epoch: 5| Step: 10
Training loss: 2.8382740326213973
Validation loss: 2.460084458506254

Epoch: 5| Step: 11
Training loss: 4.2449458868489
Validation loss: 2.4568562852173725

Epoch: 159| Step: 0
Training loss: 2.6261909144861946
Validation loss: 2.4586237652335092

Epoch: 5| Step: 1
Training loss: 2.739074243932726
Validation loss: 2.460486149647952

Epoch: 5| Step: 2
Training loss: 2.5261064239276507
Validation loss: 2.4695979967664026

Epoch: 5| Step: 3
Training loss: 2.704624267403132
Validation loss: 2.4640531365170926

Epoch: 5| Step: 4
Training loss: 2.399036345136193
Validation loss: 2.4626013807543985

Epoch: 5| Step: 5
Training loss: 2.307179697274917
Validation loss: 2.461039679288136

Epoch: 5| Step: 6
Training loss: 2.24797210436445
Validation loss: 2.4657933521370596

Epoch: 5| Step: 7
Training loss: 2.43393436699475
Validation loss: 2.468808233805614

Epoch: 5| Step: 8
Training loss: 2.7636689418601925
Validation loss: 2.4681571659089285

Epoch: 5| Step: 9
Training loss: 2.2128593799509746
Validation loss: 2.462889515782993

Epoch: 5| Step: 10
Training loss: 2.651733687836789
Validation loss: 2.461494586600654

Epoch: 5| Step: 11
Training loss: 2.693737155680116
Validation loss: 2.467106714872859

Epoch: 160| Step: 0
Training loss: 2.041080338761751
Validation loss: 2.457282279431787

Epoch: 5| Step: 1
Training loss: 2.531960470074816
Validation loss: 2.4597334625966893

Epoch: 5| Step: 2
Training loss: 2.0258482486871974
Validation loss: 2.458625336993541

Epoch: 5| Step: 3
Training loss: 2.86916189789595
Validation loss: 2.458896561666336

Epoch: 5| Step: 4
Training loss: 2.8125022040464454
Validation loss: 2.4568481457948237

Epoch: 5| Step: 5
Training loss: 2.450233553439375
Validation loss: 2.4615739675495827

Epoch: 5| Step: 6
Training loss: 2.8047277931145542
Validation loss: 2.4582562124687914

Epoch: 5| Step: 7
Training loss: 2.729650459409446
Validation loss: 2.4559123246358405

Epoch: 5| Step: 8
Training loss: 2.6407892300249505
Validation loss: 2.4528065492983324

Epoch: 5| Step: 9
Training loss: 2.0564378600411666
Validation loss: 2.45312831659761

Epoch: 5| Step: 10
Training loss: 2.450475245722985
Validation loss: 2.451458504624592

Epoch: 5| Step: 11
Training loss: 2.6444964498148784
Validation loss: 2.4595935179152555

Epoch: 161| Step: 0
Training loss: 2.7787556124556296
Validation loss: 2.458479203460062

Epoch: 5| Step: 1
Training loss: 2.443558816675334
Validation loss: 2.453453795150928

Epoch: 5| Step: 2
Training loss: 2.4041251176211187
Validation loss: 2.45488448328969

Epoch: 5| Step: 3
Training loss: 2.3776750056119975
Validation loss: 2.462432338701606

Epoch: 5| Step: 4
Training loss: 2.651639819661662
Validation loss: 2.4599378705126327

Epoch: 5| Step: 5
Training loss: 2.9390999515303062
Validation loss: 2.4601982378816456

Epoch: 5| Step: 6
Training loss: 1.8995975670515182
Validation loss: 2.4656965369454045

Epoch: 5| Step: 7
Training loss: 2.5359506170717445
Validation loss: 2.453450527581725

Epoch: 5| Step: 8
Training loss: 2.5814241512193488
Validation loss: 2.4530559214202206

Epoch: 5| Step: 9
Training loss: 2.651009180335831
Validation loss: 2.4528519241541478

Epoch: 5| Step: 10
Training loss: 2.2379749880800115
Validation loss: 2.456716936846685

Epoch: 5| Step: 11
Training loss: 2.079554933468572
Validation loss: 2.4576136470412355

Epoch: 162| Step: 0
Training loss: 2.5509515445523085
Validation loss: 2.459722963992734

Epoch: 5| Step: 1
Training loss: 2.9245236065897107
Validation loss: 2.4601394449231213

Epoch: 5| Step: 2
Training loss: 2.305006309053802
Validation loss: 2.458896359662965

Epoch: 5| Step: 3
Training loss: 2.92952359567552
Validation loss: 2.459849226978072

Epoch: 5| Step: 4
Training loss: 1.6384303354837515
Validation loss: 2.461790883484308

Epoch: 5| Step: 5
Training loss: 2.4274284433961877
Validation loss: 2.462377342971138

Epoch: 5| Step: 6
Training loss: 2.5905565572608498
Validation loss: 2.457892484792235

Epoch: 5| Step: 7
Training loss: 2.4126117383943146
Validation loss: 2.460186939728482

Epoch: 5| Step: 8
Training loss: 2.367184075582816
Validation loss: 2.4590007245139116

Epoch: 5| Step: 9
Training loss: 2.5486829460569402
Validation loss: 2.458597170416569

Epoch: 5| Step: 10
Training loss: 2.706937009373747
Validation loss: 2.458927900268266

Epoch: 5| Step: 11
Training loss: 1.9269890702021293
Validation loss: 2.4586696933443606

Epoch: 163| Step: 0
Training loss: 2.3153139469174646
Validation loss: 2.4597317077841057

Epoch: 5| Step: 1
Training loss: 2.2134698714038437
Validation loss: 2.460621873102518

Epoch: 5| Step: 2
Training loss: 2.4772276361225734
Validation loss: 2.4671841375558756

Epoch: 5| Step: 3
Training loss: 2.9161632830059183
Validation loss: 2.468901412280251

Epoch: 5| Step: 4
Training loss: 2.6780591638367075
Validation loss: 2.4660604711231744

Epoch: 5| Step: 5
Training loss: 2.460096136711241
Validation loss: 2.470496811124628

Epoch: 5| Step: 6
Training loss: 2.6931835667670705
Validation loss: 2.4734886700720464

Epoch: 5| Step: 7
Training loss: 2.4083331120192835
Validation loss: 2.4818465123574582

Epoch: 5| Step: 8
Training loss: 2.234375960343161
Validation loss: 2.4663114193381728

Epoch: 5| Step: 9
Training loss: 2.9112474687040337
Validation loss: 2.467798649294679

Epoch: 5| Step: 10
Training loss: 2.505995903547612
Validation loss: 2.462337838237689

Epoch: 5| Step: 11
Training loss: 1.3132830055311315
Validation loss: 2.46835268823332

Epoch: 164| Step: 0
Training loss: 2.21704067956531
Validation loss: 2.472582160599042

Epoch: 5| Step: 1
Training loss: 3.1628720151399223
Validation loss: 2.478817591948722

Epoch: 5| Step: 2
Training loss: 2.4887581791879856
Validation loss: 2.4775938459791793

Epoch: 5| Step: 3
Training loss: 2.2886426104399815
Validation loss: 2.4700975160872924

Epoch: 5| Step: 4
Training loss: 2.7287285625403785
Validation loss: 2.4762849060504792

Epoch: 5| Step: 5
Training loss: 2.9816941608194076
Validation loss: 2.4775115399905068

Epoch: 5| Step: 6
Training loss: 2.748747800624049
Validation loss: 2.4800859411215295

Epoch: 5| Step: 7
Training loss: 2.1272048731150908
Validation loss: 2.4769049246288883

Epoch: 5| Step: 8
Training loss: 2.183186993050471
Validation loss: 2.4738756440381087

Epoch: 5| Step: 9
Training loss: 2.8093135160819314
Validation loss: 2.4777850674358994

Epoch: 5| Step: 10
Training loss: 2.0879673600258224
Validation loss: 2.473359086927824

Epoch: 5| Step: 11
Training loss: 2.9732904346718523
Validation loss: 2.478553925988088

Epoch: 165| Step: 0
Training loss: 2.161638465330723
Validation loss: 2.4874067381687377

Epoch: 5| Step: 1
Training loss: 2.2848964445659536
Validation loss: 2.4820981498670074

Epoch: 5| Step: 2
Training loss: 3.0891192680394925
Validation loss: 2.4889411071307244

Epoch: 5| Step: 3
Training loss: 2.671528933237574
Validation loss: 2.4837630775874024

Epoch: 5| Step: 4
Training loss: 2.8592023953731434
Validation loss: 2.4736563019679507

Epoch: 5| Step: 5
Training loss: 2.4743020123467594
Validation loss: 2.4834542797599064

Epoch: 5| Step: 6
Training loss: 2.845891795714489
Validation loss: 2.47817084938278

Epoch: 5| Step: 7
Training loss: 2.18681172033239
Validation loss: 2.4704506444779266

Epoch: 5| Step: 8
Training loss: 2.554428600759746
Validation loss: 2.4728273490216637

Epoch: 5| Step: 9
Training loss: 2.1715404884100034
Validation loss: 2.469343874519625

Epoch: 5| Step: 10
Training loss: 2.5541984253278494
Validation loss: 2.46960126710596

Epoch: 5| Step: 11
Training loss: 3.3035061214870103
Validation loss: 2.4614771619591322

Epoch: 166| Step: 0
Training loss: 2.5478543697881237
Validation loss: 2.4617902459040844

Epoch: 5| Step: 1
Training loss: 2.311663914655694
Validation loss: 2.461426431032375

Epoch: 5| Step: 2
Training loss: 3.0198423316673146
Validation loss: 2.4630893563569067

Epoch: 5| Step: 3
Training loss: 2.7388729919924852
Validation loss: 2.4570910472294885

Epoch: 5| Step: 4
Training loss: 2.460108347887041
Validation loss: 2.4595375317546098

Epoch: 5| Step: 5
Training loss: 2.3604303488092144
Validation loss: 2.4619504428320687

Epoch: 5| Step: 6
Training loss: 2.8899185554617537
Validation loss: 2.4662731074703816

Epoch: 5| Step: 7
Training loss: 2.7635566175171182
Validation loss: 2.4620896563919774

Epoch: 5| Step: 8
Training loss: 2.116268169507588
Validation loss: 2.457003493725864

Epoch: 5| Step: 9
Training loss: 2.0359015390611868
Validation loss: 2.453605147264451

Epoch: 5| Step: 10
Training loss: 2.26483961501703
Validation loss: 2.4581833419193693

Epoch: 5| Step: 11
Training loss: 2.535091076029307
Validation loss: 2.4561172730173872

Epoch: 167| Step: 0
Training loss: 2.2132565901944825
Validation loss: 2.4613388097616204

Epoch: 5| Step: 1
Training loss: 2.343868303492112
Validation loss: 2.4656865995808244

Epoch: 5| Step: 2
Training loss: 2.522781050481435
Validation loss: 2.467101931240665

Epoch: 5| Step: 3
Training loss: 2.5737996201551305
Validation loss: 2.4648650682820166

Epoch: 5| Step: 4
Training loss: 2.3922422835083763
Validation loss: 2.459557322845453

Epoch: 5| Step: 5
Training loss: 2.451696283544935
Validation loss: 2.4625324308451186

Epoch: 5| Step: 6
Training loss: 2.5924583803991075
Validation loss: 2.4623494008611027

Epoch: 5| Step: 7
Training loss: 2.275511015625428
Validation loss: 2.4474459959935895

Epoch: 5| Step: 8
Training loss: 2.488728768963691
Validation loss: 2.4563415966475595

Epoch: 5| Step: 9
Training loss: 2.555245901319663
Validation loss: 2.4601510501829638

Epoch: 5| Step: 10
Training loss: 2.8817816651319585
Validation loss: 2.457795986888824

Epoch: 5| Step: 11
Training loss: 3.3042820169935783
Validation loss: 2.453396448072041

Epoch: 168| Step: 0
Training loss: 2.7012980025517526
Validation loss: 2.4586757459160835

Epoch: 5| Step: 1
Training loss: 2.6190070815891864
Validation loss: 2.465853863478429

Epoch: 5| Step: 2
Training loss: 2.226745169658653
Validation loss: 2.4663331498760246

Epoch: 5| Step: 3
Training loss: 3.049356086173473
Validation loss: 2.4681429458652233

Epoch: 5| Step: 4
Training loss: 2.253051489954888
Validation loss: 2.4690207944507785

Epoch: 5| Step: 5
Training loss: 2.0545938564761603
Validation loss: 2.4613009472054688

Epoch: 5| Step: 6
Training loss: 2.2894180594562354
Validation loss: 2.4593277404393588

Epoch: 5| Step: 7
Training loss: 2.540357429706793
Validation loss: 2.4583203320779057

Epoch: 5| Step: 8
Training loss: 2.935748937864387
Validation loss: 2.456262501595013

Epoch: 5| Step: 9
Training loss: 2.4150454794508867
Validation loss: 2.4560982166272884

Epoch: 5| Step: 10
Training loss: 2.374835159202893
Validation loss: 2.4495882914528067

Epoch: 5| Step: 11
Training loss: 2.2900598846334828
Validation loss: 2.4559284721286567

Epoch: 169| Step: 0
Training loss: 2.701400912622292
Validation loss: 2.4600070465963904

Epoch: 5| Step: 1
Training loss: 2.6999599029954506
Validation loss: 2.458504245899856

Epoch: 5| Step: 2
Training loss: 1.8758895035678267
Validation loss: 2.4685394221444352

Epoch: 5| Step: 3
Training loss: 1.9642981194438844
Validation loss: 2.4808718976987283

Epoch: 5| Step: 4
Training loss: 2.594285564971761
Validation loss: 2.481914425378827

Epoch: 5| Step: 5
Training loss: 2.634864799606809
Validation loss: 2.4703839484154386

Epoch: 5| Step: 6
Training loss: 2.7617586340715317
Validation loss: 2.4725739242886213

Epoch: 5| Step: 7
Training loss: 2.646689769474285
Validation loss: 2.4656960232573595

Epoch: 5| Step: 8
Training loss: 2.6938826596902263
Validation loss: 2.4531859493580663

Epoch: 5| Step: 9
Training loss: 2.5150570435624413
Validation loss: 2.4721311038676284

Epoch: 5| Step: 10
Training loss: 2.6485815318504686
Validation loss: 2.466981789772862

Epoch: 5| Step: 11
Training loss: 2.203062232455825
Validation loss: 2.469708795711094

Epoch: 170| Step: 0
Training loss: 2.4684789967577365
Validation loss: 2.47826416487545

Epoch: 5| Step: 1
Training loss: 2.69265872951445
Validation loss: 2.4808816521073407

Epoch: 5| Step: 2
Training loss: 3.094473551901119
Validation loss: 2.4722089719476785

Epoch: 5| Step: 3
Training loss: 2.187853975266595
Validation loss: 2.4692761266995342

Epoch: 5| Step: 4
Training loss: 2.6129613660605284
Validation loss: 2.4598827018982297

Epoch: 5| Step: 5
Training loss: 2.3032645277722223
Validation loss: 2.457818637459495

Epoch: 5| Step: 6
Training loss: 2.655508858001019
Validation loss: 2.4508343042401783

Epoch: 5| Step: 7
Training loss: 2.2923685097294926
Validation loss: 2.4616273932260913

Epoch: 5| Step: 8
Training loss: 2.586293452447744
Validation loss: 2.45572880933374

Epoch: 5| Step: 9
Training loss: 2.4672457784156037
Validation loss: 2.457702633939854

Epoch: 5| Step: 10
Training loss: 2.501221358456021
Validation loss: 2.460394546114339

Epoch: 5| Step: 11
Training loss: 1.1478290113616336
Validation loss: 2.453242066297223

Epoch: 171| Step: 0
Training loss: 2.439712498408396
Validation loss: 2.4512818573978095

Epoch: 5| Step: 1
Training loss: 2.551048463433587
Validation loss: 2.4637327274702177

Epoch: 5| Step: 2
Training loss: 2.500090883510391
Validation loss: 2.4570150571935425

Epoch: 5| Step: 3
Training loss: 2.56017514344951
Validation loss: 2.455155906770285

Epoch: 5| Step: 4
Training loss: 2.4538023189771576
Validation loss: 2.458515804329192

Epoch: 5| Step: 5
Training loss: 2.539964533280389
Validation loss: 2.455855989603005

Epoch: 5| Step: 6
Training loss: 1.9464908079943992
Validation loss: 2.4558459699461173

Epoch: 5| Step: 7
Training loss: 2.156634531425348
Validation loss: 2.4537281137294555

Epoch: 5| Step: 8
Training loss: 2.8648201214575595
Validation loss: 2.453484923894344

Epoch: 5| Step: 9
Training loss: 2.567013928425015
Validation loss: 2.4516195590055236

Epoch: 5| Step: 10
Training loss: 2.668492189055332
Validation loss: 2.456802818462677

Epoch: 5| Step: 11
Training loss: 3.345261846993621
Validation loss: 2.4565783165577533

Epoch: 172| Step: 0
Training loss: 2.5132389481257005
Validation loss: 2.4534365563461074

Epoch: 5| Step: 1
Training loss: 2.024966100715123
Validation loss: 2.4545835342260367

Epoch: 5| Step: 2
Training loss: 2.5721363217607554
Validation loss: 2.458510846393951

Epoch: 5| Step: 3
Training loss: 2.726075311982026
Validation loss: 2.45320518022454

Epoch: 5| Step: 4
Training loss: 2.8257772912337056
Validation loss: 2.4608464764105076

Epoch: 5| Step: 5
Training loss: 2.420610356088356
Validation loss: 2.4537388545810064

Epoch: 5| Step: 6
Training loss: 2.51436882168103
Validation loss: 2.453591235616912

Epoch: 5| Step: 7
Training loss: 2.3668682021533742
Validation loss: 2.4560526570386942

Epoch: 5| Step: 8
Training loss: 2.590755618567753
Validation loss: 2.450371490749218

Epoch: 5| Step: 9
Training loss: 2.1971102375611684
Validation loss: 2.457945337765818

Epoch: 5| Step: 10
Training loss: 2.668518903316898
Validation loss: 2.4548253607286266

Epoch: 5| Step: 11
Training loss: 2.393364029088016
Validation loss: 2.453472157432233

Epoch: 173| Step: 0
Training loss: 2.6018032386444694
Validation loss: 2.4499701483523295

Epoch: 5| Step: 1
Training loss: 2.357189758048859
Validation loss: 2.455641093988999

Epoch: 5| Step: 2
Training loss: 2.2161170488423942
Validation loss: 2.45994213501399

Epoch: 5| Step: 3
Training loss: 2.7147736684412234
Validation loss: 2.4504473239738958

Epoch: 5| Step: 4
Training loss: 2.6443944808325344
Validation loss: 2.453472934840008

Epoch: 5| Step: 5
Training loss: 2.575251139273288
Validation loss: 2.450409037721881

Epoch: 5| Step: 6
Training loss: 2.0556606990397066
Validation loss: 2.458503799401146

Epoch: 5| Step: 7
Training loss: 2.666934526421486
Validation loss: 2.4516886679262715

Epoch: 5| Step: 8
Training loss: 3.0392605047763763
Validation loss: 2.4524021379516467

Epoch: 5| Step: 9
Training loss: 2.5099018460721734
Validation loss: 2.4578821258480428

Epoch: 5| Step: 10
Training loss: 2.068112799019675
Validation loss: 2.458505852082328

Epoch: 5| Step: 11
Training loss: 2.158796051188023
Validation loss: 2.459633832089244

Epoch: 174| Step: 0
Training loss: 1.780957114250046
Validation loss: 2.4568538834233595

Epoch: 5| Step: 1
Training loss: 2.9491432432904645
Validation loss: 2.4594914340514826

Epoch: 5| Step: 2
Training loss: 3.067901674318878
Validation loss: 2.4589544652483792

Epoch: 5| Step: 3
Training loss: 2.8967522094117637
Validation loss: 2.4563004175500835

Epoch: 5| Step: 4
Training loss: 1.5152554405579215
Validation loss: 2.4528813008222934

Epoch: 5| Step: 5
Training loss: 2.039479297118567
Validation loss: 2.4521615511514336

Epoch: 5| Step: 6
Training loss: 2.8858110913410853
Validation loss: 2.4502854445315085

Epoch: 5| Step: 7
Training loss: 2.3846387524796877
Validation loss: 2.447509558622965

Epoch: 5| Step: 8
Training loss: 2.644582908497711
Validation loss: 2.443438298215962

Epoch: 5| Step: 9
Training loss: 2.5815916855892445
Validation loss: 2.4425554180203166

Epoch: 5| Step: 10
Training loss: 2.462246404457159
Validation loss: 2.4412767747243165

Epoch: 5| Step: 11
Training loss: 1.9075107470168395
Validation loss: 2.4431185076349093

Epoch: 175| Step: 0
Training loss: 2.4242928525888794
Validation loss: 2.4469820199738987

Epoch: 5| Step: 1
Training loss: 2.43027040413472
Validation loss: 2.451573575807071

Epoch: 5| Step: 2
Training loss: 2.4930477750250053
Validation loss: 2.4489999132887155

Epoch: 5| Step: 3
Training loss: 2.5608612030561826
Validation loss: 2.4423696870182954

Epoch: 5| Step: 4
Training loss: 2.5435349732040464
Validation loss: 2.446484184478309

Epoch: 5| Step: 5
Training loss: 2.49201108493452
Validation loss: 2.4467197508622833

Epoch: 5| Step: 6
Training loss: 2.8225215808999575
Validation loss: 2.44389042723197

Epoch: 5| Step: 7
Training loss: 2.3050367187752876
Validation loss: 2.451980844369053

Epoch: 5| Step: 8
Training loss: 2.651308287357967
Validation loss: 2.4532519184171004

Epoch: 5| Step: 9
Training loss: 2.431401669201502
Validation loss: 2.4597231336185437

Epoch: 5| Step: 10
Training loss: 2.180496011178843
Validation loss: 2.461929331329502

Epoch: 5| Step: 11
Training loss: 3.15494805101286
Validation loss: 2.4574394271127544

Testing loss: 1.9903628135313118
