Epoch: 1| Step: 0
Training loss: 5.809905098486374
Validation loss: 5.834895655906607

Epoch: 5| Step: 1
Training loss: 5.629612027990326
Validation loss: 5.83391560191607

Epoch: 5| Step: 2
Training loss: 6.046571551454218
Validation loss: 5.8329271129673845

Epoch: 5| Step: 3
Training loss: 6.061895595979259
Validation loss: 5.83197163174292

Epoch: 5| Step: 4
Training loss: 6.712116604161562
Validation loss: 5.8310794108938975

Epoch: 5| Step: 5
Training loss: 5.937381140874461
Validation loss: 5.830203956255674

Epoch: 5| Step: 6
Training loss: 6.201476062913306
Validation loss: 5.829258962704473

Epoch: 5| Step: 7
Training loss: 5.5033056555517375
Validation loss: 5.828274947377516

Epoch: 5| Step: 8
Training loss: 5.925176419878944
Validation loss: 5.8272508608272044

Epoch: 5| Step: 9
Training loss: 6.118855722700496
Validation loss: 5.826197301144373

Epoch: 5| Step: 10
Training loss: 5.055781297685779
Validation loss: 5.82504892178622

Epoch: 5| Step: 11
Training loss: 7.166725986442212
Validation loss: 5.823879860617854

Epoch: 2| Step: 0
Training loss: 6.306633064121358
Validation loss: 5.822652939321591

Epoch: 5| Step: 1
Training loss: 6.536676370294823
Validation loss: 5.821342448818644

Epoch: 5| Step: 2
Training loss: 5.376115550116378
Validation loss: 5.820021592621223

Epoch: 5| Step: 3
Training loss: 6.22302773726343
Validation loss: 5.818623444915166

Epoch: 5| Step: 4
Training loss: 5.781297838167786
Validation loss: 5.817173914210839

Epoch: 5| Step: 5
Training loss: 5.589371144744386
Validation loss: 5.815609964757496

Epoch: 5| Step: 6
Training loss: 5.880619689050304
Validation loss: 5.814000253977211

Epoch: 5| Step: 7
Training loss: 6.093636692656516
Validation loss: 5.812352154673366

Epoch: 5| Step: 8
Training loss: 5.689421276837569
Validation loss: 5.810634505094644

Epoch: 5| Step: 9
Training loss: 6.313511833452329
Validation loss: 5.80874650006551

Epoch: 5| Step: 10
Training loss: 5.03871387783873
Validation loss: 5.806776127077341

Epoch: 5| Step: 11
Training loss: 7.090332014437065
Validation loss: 5.804827723086565

Epoch: 3| Step: 0
Training loss: 4.648841237718882
Validation loss: 5.802514663452046

Epoch: 5| Step: 1
Training loss: 5.807120510253379
Validation loss: 5.800335148741654

Epoch: 5| Step: 2
Training loss: 5.761851494763214
Validation loss: 5.797842460849209

Epoch: 5| Step: 3
Training loss: 5.87524575876023
Validation loss: 5.795410382515635

Epoch: 5| Step: 4
Training loss: 5.197032213614391
Validation loss: 5.79279069033091

Epoch: 5| Step: 5
Training loss: 5.936586008496744
Validation loss: 5.789975278402993

Epoch: 5| Step: 6
Training loss: 6.795060821103811
Validation loss: 5.786984893253082

Epoch: 5| Step: 7
Training loss: 7.226621621379782
Validation loss: 5.783754297797219

Epoch: 5| Step: 8
Training loss: 5.513803327117041
Validation loss: 5.7804732617108305

Epoch: 5| Step: 9
Training loss: 5.601580546628008
Validation loss: 5.776712234781065

Epoch: 5| Step: 10
Training loss: 6.181947008106358
Validation loss: 5.772899184469539

Epoch: 5| Step: 11
Training loss: 5.849960209637815
Validation loss: 5.768924282605754

Epoch: 4| Step: 0
Training loss: 5.27924846213466
Validation loss: 5.76460786443614

Epoch: 5| Step: 1
Training loss: 5.8957649289893155
Validation loss: 5.759968630409474

Epoch: 5| Step: 2
Training loss: 6.097087239726679
Validation loss: 5.755197014660874

Epoch: 5| Step: 3
Training loss: 5.645503335953293
Validation loss: 5.750226306608242

Epoch: 5| Step: 4
Training loss: 6.364482206632753
Validation loss: 5.7448922013322035

Epoch: 5| Step: 5
Training loss: 5.7707176150989135
Validation loss: 5.739357774829048

Epoch: 5| Step: 6
Training loss: 5.781439370842738
Validation loss: 5.733561140162523

Epoch: 5| Step: 7
Training loss: 6.056616691141037
Validation loss: 5.727421445037276

Epoch: 5| Step: 8
Training loss: 6.3595150643935145
Validation loss: 5.721115429121894

Epoch: 5| Step: 9
Training loss: 5.812304749849835
Validation loss: 5.714032629913959

Epoch: 5| Step: 10
Training loss: 5.285933364834974
Validation loss: 5.707443866439774

Epoch: 5| Step: 11
Training loss: 5.502031991303322
Validation loss: 5.700011029427995

Epoch: 5| Step: 0
Training loss: 6.634741764289594
Validation loss: 5.692699752293919

Epoch: 5| Step: 1
Training loss: 5.519918267571003
Validation loss: 5.684810100147191

Epoch: 5| Step: 2
Training loss: 5.905781722301024
Validation loss: 5.6768650771250355

Epoch: 5| Step: 3
Training loss: 6.205621865439144
Validation loss: 5.668776198960635

Epoch: 5| Step: 4
Training loss: 4.885534202392715
Validation loss: 5.6603866400382685

Epoch: 5| Step: 5
Training loss: 5.125481931775683
Validation loss: 5.652187286369638

Epoch: 5| Step: 6
Training loss: 5.298474095768542
Validation loss: 5.643749474194158

Epoch: 5| Step: 7
Training loss: 6.288733735583842
Validation loss: 5.6351464066304215

Epoch: 5| Step: 8
Training loss: 5.924784325645949
Validation loss: 5.626501003198736

Epoch: 5| Step: 9
Training loss: 5.98305279739091
Validation loss: 5.618143933133771

Epoch: 5| Step: 10
Training loss: 5.46456976115783
Validation loss: 5.609403491501277

Epoch: 5| Step: 11
Training loss: 5.610106014127193
Validation loss: 5.600582695061815

Epoch: 6| Step: 0
Training loss: 5.576585573259303
Validation loss: 5.591888927963817

Epoch: 5| Step: 1
Training loss: 6.06005715774422
Validation loss: 5.58307780444965

Epoch: 5| Step: 2
Training loss: 5.112377532760622
Validation loss: 5.574509753637813

Epoch: 5| Step: 3
Training loss: 5.329192560812541
Validation loss: 5.565553534261504

Epoch: 5| Step: 4
Training loss: 6.051937064298059
Validation loss: 5.557054668927589

Epoch: 5| Step: 5
Training loss: 6.024989540439249
Validation loss: 5.548414698999468

Epoch: 5| Step: 6
Training loss: 5.042544748224035
Validation loss: 5.53978007573231

Epoch: 5| Step: 7
Training loss: 6.049826047303899
Validation loss: 5.531170415215954

Epoch: 5| Step: 8
Training loss: 5.758371644322779
Validation loss: 5.52248481904973

Epoch: 5| Step: 9
Training loss: 5.611840346552574
Validation loss: 5.513972740058913

Epoch: 5| Step: 10
Training loss: 5.46760625595571
Validation loss: 5.505695818271189

Epoch: 5| Step: 11
Training loss: 6.258840793128586
Validation loss: 5.49710727249346

Epoch: 7| Step: 0
Training loss: 5.523982559353355
Validation loss: 5.488644067756602

Epoch: 5| Step: 1
Training loss: 5.1437937701044385
Validation loss: 5.479876985909509

Epoch: 5| Step: 2
Training loss: 5.362041555161824
Validation loss: 5.471562902822488

Epoch: 5| Step: 3
Training loss: 5.754908581230488
Validation loss: 5.4630984649927345

Epoch: 5| Step: 4
Training loss: 6.360606381281399
Validation loss: 5.454819103683301

Epoch: 5| Step: 5
Training loss: 5.354196075873248
Validation loss: 5.4456110196996015

Epoch: 5| Step: 6
Training loss: 6.0122793430752965
Validation loss: 5.437090759662054

Epoch: 5| Step: 7
Training loss: 5.355163521001942
Validation loss: 5.428130272786053

Epoch: 5| Step: 8
Training loss: 5.424659563624761
Validation loss: 5.419581614401399

Epoch: 5| Step: 9
Training loss: 5.272888607139891
Validation loss: 5.410694838247162

Epoch: 5| Step: 10
Training loss: 5.54720733076854
Validation loss: 5.40186811382045

Epoch: 5| Step: 11
Training loss: 5.521495774550489
Validation loss: 5.3932828312636385

Epoch: 8| Step: 0
Training loss: 4.9973860583690985
Validation loss: 5.384721363076196

Epoch: 5| Step: 1
Training loss: 5.481732636693923
Validation loss: 5.376204577468962

Epoch: 5| Step: 2
Training loss: 6.034704296386379
Validation loss: 5.367428814434169

Epoch: 5| Step: 3
Training loss: 4.983234908919176
Validation loss: 5.359212192624183

Epoch: 5| Step: 4
Training loss: 5.979565792076175
Validation loss: 5.35070389219992

Epoch: 5| Step: 5
Training loss: 5.606996504840881
Validation loss: 5.342048723698675

Epoch: 5| Step: 6
Training loss: 4.796199390660349
Validation loss: 5.333763845273925

Epoch: 5| Step: 7
Training loss: 5.252594806118746
Validation loss: 5.325331320029369

Epoch: 5| Step: 8
Training loss: 5.067714125292436
Validation loss: 5.317777435820188

Epoch: 5| Step: 9
Training loss: 6.179785649307484
Validation loss: 5.309790110849086

Epoch: 5| Step: 10
Training loss: 5.548458249507984
Validation loss: 5.30231390890756

Epoch: 5| Step: 11
Training loss: 5.296467183035469
Validation loss: 5.295162452964951

Epoch: 9| Step: 0
Training loss: 5.812207614558889
Validation loss: 5.287799731417391

Epoch: 5| Step: 1
Training loss: 4.773955521515793
Validation loss: 5.280527347578764

Epoch: 5| Step: 2
Training loss: 5.101561004498249
Validation loss: 5.273015519201122

Epoch: 5| Step: 3
Training loss: 4.681467064993114
Validation loss: 5.265980498164183

Epoch: 5| Step: 4
Training loss: 5.778043940518664
Validation loss: 5.259134867900488

Epoch: 5| Step: 5
Training loss: 6.210258475558964
Validation loss: 5.252066818487745

Epoch: 5| Step: 6
Training loss: 5.675714711628216
Validation loss: 5.245220453437442

Epoch: 5| Step: 7
Training loss: 5.826684195858029
Validation loss: 5.2381365417321755

Epoch: 5| Step: 8
Training loss: 5.3461391172222
Validation loss: 5.231476150905078

Epoch: 5| Step: 9
Training loss: 5.438465778040798
Validation loss: 5.224962248962405

Epoch: 5| Step: 10
Training loss: 4.40430293791157
Validation loss: 5.218285004997012

Epoch: 5| Step: 11
Training loss: 4.133262220406734
Validation loss: 5.211962643376031

Epoch: 10| Step: 0
Training loss: 4.478726860751043
Validation loss: 5.2058601102124555

Epoch: 5| Step: 1
Training loss: 5.604166912471194
Validation loss: 5.199891369553058

Epoch: 5| Step: 2
Training loss: 5.032535933599842
Validation loss: 5.1941136403862815

Epoch: 5| Step: 3
Training loss: 5.076538589341389
Validation loss: 5.188045113046561

Epoch: 5| Step: 4
Training loss: 5.33923255977791
Validation loss: 5.182686544993751

Epoch: 5| Step: 5
Training loss: 5.511063459063877
Validation loss: 5.176865727273049

Epoch: 5| Step: 6
Training loss: 5.968444816416696
Validation loss: 5.17064073476999

Epoch: 5| Step: 7
Training loss: 4.889522928006471
Validation loss: 5.164482411266272

Epoch: 5| Step: 8
Training loss: 4.612531609155539
Validation loss: 5.158689126217157

Epoch: 5| Step: 9
Training loss: 5.371610237951178
Validation loss: 5.152250407166087

Epoch: 5| Step: 10
Training loss: 6.071504493046351
Validation loss: 5.146563291577996

Epoch: 5| Step: 11
Training loss: 5.692868224955587
Validation loss: 5.1402054975919755

Epoch: 11| Step: 0
Training loss: 5.033985413170627
Validation loss: 5.133721993438613

Epoch: 5| Step: 1
Training loss: 5.4381366225516174
Validation loss: 5.127539889228367

Epoch: 5| Step: 2
Training loss: 5.749867976787665
Validation loss: 5.121176402077026

Epoch: 5| Step: 3
Training loss: 5.605087299194527
Validation loss: 5.114860964799964

Epoch: 5| Step: 4
Training loss: 5.185112829056743
Validation loss: 5.108680615695582

Epoch: 5| Step: 5
Training loss: 5.206684349964574
Validation loss: 5.102543563719108

Epoch: 5| Step: 6
Training loss: 4.968692995140277
Validation loss: 5.096297401368087

Epoch: 5| Step: 7
Training loss: 5.321880182430591
Validation loss: 5.090493563521669

Epoch: 5| Step: 8
Training loss: 5.1596038083704245
Validation loss: 5.084132579861562

Epoch: 5| Step: 9
Training loss: 5.6641079604856674
Validation loss: 5.078197232246193

Epoch: 5| Step: 10
Training loss: 3.7431948904613654
Validation loss: 5.072212611643468

Epoch: 5| Step: 11
Training loss: 5.876655832252894
Validation loss: 5.066510703589262

Epoch: 12| Step: 0
Training loss: 5.562322549454053
Validation loss: 5.061164310841976

Epoch: 5| Step: 1
Training loss: 4.652505892627393
Validation loss: 5.05585995597279

Epoch: 5| Step: 2
Training loss: 5.042317792392941
Validation loss: 5.0506192815920015

Epoch: 5| Step: 3
Training loss: 5.251077632204505
Validation loss: 5.045399319195231

Epoch: 5| Step: 4
Training loss: 5.97625292805271
Validation loss: 5.040327464382308

Epoch: 5| Step: 5
Training loss: 4.593068390187378
Validation loss: 5.034929758230349

Epoch: 5| Step: 6
Training loss: 4.744849373905844
Validation loss: 5.029611103401611

Epoch: 5| Step: 7
Training loss: 6.0939183921044515
Validation loss: 5.024171481935606

Epoch: 5| Step: 8
Training loss: 4.82059145325846
Validation loss: 5.019425557529138

Epoch: 5| Step: 9
Training loss: 4.994740581019167
Validation loss: 5.014851907665129

Epoch: 5| Step: 10
Training loss: 4.987390831538928
Validation loss: 5.0097215240302235

Epoch: 5| Step: 11
Training loss: 3.924692912146233
Validation loss: 5.004914102099854

Epoch: 13| Step: 0
Training loss: 4.854977301280333
Validation loss: 4.999935952412158

Epoch: 5| Step: 1
Training loss: 5.3251076485941775
Validation loss: 4.994996579461491

Epoch: 5| Step: 2
Training loss: 5.162087390288505
Validation loss: 4.990275168454329

Epoch: 5| Step: 3
Training loss: 5.424544235281196
Validation loss: 4.985280559555999

Epoch: 5| Step: 4
Training loss: 4.650576213288047
Validation loss: 4.980205773285962

Epoch: 5| Step: 5
Training loss: 4.587045772838891
Validation loss: 4.975788744985045

Epoch: 5| Step: 6
Training loss: 5.438620090217533
Validation loss: 4.9708840647643004

Epoch: 5| Step: 7
Training loss: 5.570043014278094
Validation loss: 4.96593729217089

Epoch: 5| Step: 8
Training loss: 4.179851778313661
Validation loss: 4.960990068452513

Epoch: 5| Step: 9
Training loss: 5.086972460939746
Validation loss: 4.9561210580274695

Epoch: 5| Step: 10
Training loss: 5.684214554798268
Validation loss: 4.951074554871325

Epoch: 5| Step: 11
Training loss: 4.714078498183514
Validation loss: 4.946476088838782

Epoch: 14| Step: 0
Training loss: 5.431396742266156
Validation loss: 4.942335931424583

Epoch: 5| Step: 1
Training loss: 5.761099344354129
Validation loss: 4.937440895982286

Epoch: 5| Step: 2
Training loss: 4.6677344099782205
Validation loss: 4.93264489149431

Epoch: 5| Step: 3
Training loss: 5.42624103748396
Validation loss: 4.928610077897954

Epoch: 5| Step: 4
Training loss: 4.732394871337526
Validation loss: 4.923988276127571

Epoch: 5| Step: 5
Training loss: 4.590251394796547
Validation loss: 4.919298003973037

Epoch: 5| Step: 6
Training loss: 3.6876161201426774
Validation loss: 4.914462511432521

Epoch: 5| Step: 7
Training loss: 5.044791816219391
Validation loss: 4.910473748793649

Epoch: 5| Step: 8
Training loss: 5.630451697054705
Validation loss: 4.90593645588233

Epoch: 5| Step: 9
Training loss: 5.030508045908601
Validation loss: 4.9016640079175025

Epoch: 5| Step: 10
Training loss: 5.209962676458239
Validation loss: 4.897432612561929

Epoch: 5| Step: 11
Training loss: 4.717688839058563
Validation loss: 4.892985122818129

Epoch: 15| Step: 0
Training loss: 5.04068132760443
Validation loss: 4.88871449944587

Epoch: 5| Step: 1
Training loss: 5.194757371657566
Validation loss: 4.884679672296439

Epoch: 5| Step: 2
Training loss: 5.405703831244624
Validation loss: 4.880106232456152

Epoch: 5| Step: 3
Training loss: 5.409258231539563
Validation loss: 4.875635268724556

Epoch: 5| Step: 4
Training loss: 4.8668200995588204
Validation loss: 4.871251927356568

Epoch: 5| Step: 5
Training loss: 4.732751549082393
Validation loss: 4.866511584232174

Epoch: 5| Step: 6
Training loss: 4.511524067431176
Validation loss: 4.862758370393954

Epoch: 5| Step: 7
Training loss: 5.431622013744634
Validation loss: 4.858039762461693

Epoch: 5| Step: 8
Training loss: 4.872072172059426
Validation loss: 4.853642016478677

Epoch: 5| Step: 9
Training loss: 4.7457131566792485
Validation loss: 4.849412766362109

Epoch: 5| Step: 10
Training loss: 4.4781463643833535
Validation loss: 4.845430382101675

Epoch: 5| Step: 11
Training loss: 5.541028017037606
Validation loss: 4.841195686115111

Epoch: 16| Step: 0
Training loss: 5.10084012161615
Validation loss: 4.838049933087674

Epoch: 5| Step: 1
Training loss: 4.877215151150832
Validation loss: 4.833140931191377

Epoch: 5| Step: 2
Training loss: 4.664693460645309
Validation loss: 4.828381355664837

Epoch: 5| Step: 3
Training loss: 5.596867891154841
Validation loss: 4.823632381494949

Epoch: 5| Step: 4
Training loss: 4.416907225961286
Validation loss: 4.819451113441878

Epoch: 5| Step: 5
Training loss: 4.599988373451467
Validation loss: 4.8149543052557044

Epoch: 5| Step: 6
Training loss: 4.534172010446063
Validation loss: 4.811196080380831

Epoch: 5| Step: 7
Training loss: 5.128304695361023
Validation loss: 4.8067362152064375

Epoch: 5| Step: 8
Training loss: 5.0099668347142305
Validation loss: 4.802852778599592

Epoch: 5| Step: 9
Training loss: 5.395511789449892
Validation loss: 4.798471812526459

Epoch: 5| Step: 10
Training loss: 5.0937541189352595
Validation loss: 4.793736867542672

Epoch: 5| Step: 11
Training loss: 3.812738254794414
Validation loss: 4.789802473358383

Epoch: 17| Step: 0
Training loss: 5.39781668995072
Validation loss: 4.78509391899774

Epoch: 5| Step: 1
Training loss: 5.3096117134157
Validation loss: 4.78138425218844

Epoch: 5| Step: 2
Training loss: 4.295025569675347
Validation loss: 4.777602722351839

Epoch: 5| Step: 3
Training loss: 5.205528093824459
Validation loss: 4.773114349032338

Epoch: 5| Step: 4
Training loss: 4.916923042121814
Validation loss: 4.768657765761002

Epoch: 5| Step: 5
Training loss: 4.411320359535581
Validation loss: 4.7649630936350515

Epoch: 5| Step: 6
Training loss: 5.188105352539388
Validation loss: 4.760069772558918

Epoch: 5| Step: 7
Training loss: 4.262435223487135
Validation loss: 4.756449595543816

Epoch: 5| Step: 8
Training loss: 5.8762975031026725
Validation loss: 4.751638439424224

Epoch: 5| Step: 9
Training loss: 4.802735764983024
Validation loss: 4.747432466561968

Epoch: 5| Step: 10
Training loss: 4.074005969920066
Validation loss: 4.742984711003298

Epoch: 5| Step: 11
Training loss: 3.2700076832812277
Validation loss: 4.738608721900645

Epoch: 18| Step: 0
Training loss: 5.089560441558903
Validation loss: 4.734565193879864

Epoch: 5| Step: 1
Training loss: 4.842084832224745
Validation loss: 4.730047827257728

Epoch: 5| Step: 2
Training loss: 4.932514812681188
Validation loss: 4.726127053791908

Epoch: 5| Step: 3
Training loss: 5.263528559331417
Validation loss: 4.721578310404493

Epoch: 5| Step: 4
Training loss: 4.780664944226897
Validation loss: 4.718388718338708

Epoch: 5| Step: 5
Training loss: 5.10746967592354
Validation loss: 4.7134463291818545

Epoch: 5| Step: 6
Training loss: 4.96014061482366
Validation loss: 4.709312829390078

Epoch: 5| Step: 7
Training loss: 4.924601256983473
Validation loss: 4.7049844979798685

Epoch: 5| Step: 8
Training loss: 4.55947315719606
Validation loss: 4.700376127627474

Epoch: 5| Step: 9
Training loss: 4.051472883487531
Validation loss: 4.696141462306317

Epoch: 5| Step: 10
Training loss: 4.775488479953435
Validation loss: 4.691688861534692

Epoch: 5| Step: 11
Training loss: 4.041131734677983
Validation loss: 4.687492340929344

Epoch: 19| Step: 0
Training loss: 4.170460207493312
Validation loss: 4.6832802831738105

Epoch: 5| Step: 1
Training loss: 5.137581617166473
Validation loss: 4.678628189182174

Epoch: 5| Step: 2
Training loss: 5.299623029725996
Validation loss: 4.674224063071797

Epoch: 5| Step: 3
Training loss: 4.566127014759553
Validation loss: 4.670379586459568

Epoch: 5| Step: 4
Training loss: 5.251104874379619
Validation loss: 4.665094130528219

Epoch: 5| Step: 5
Training loss: 4.509402941579558
Validation loss: 4.660824237793922

Epoch: 5| Step: 6
Training loss: 4.877800161725018
Validation loss: 4.657191128101705

Epoch: 5| Step: 7
Training loss: 4.753165144189654
Validation loss: 4.652195379078377

Epoch: 5| Step: 8
Training loss: 4.696732038300632
Validation loss: 4.647316437930544

Epoch: 5| Step: 9
Training loss: 4.76406004177792
Validation loss: 4.64389281808423

Epoch: 5| Step: 10
Training loss: 4.455731616157945
Validation loss: 4.63965811969633

Epoch: 5| Step: 11
Training loss: 5.098413871502288
Validation loss: 4.63462635403855

Epoch: 20| Step: 0
Training loss: 5.531904106473005
Validation loss: 4.63036232324998

Epoch: 5| Step: 1
Training loss: 4.193887422359568
Validation loss: 4.625573054029155

Epoch: 5| Step: 2
Training loss: 5.861972731444528
Validation loss: 4.6207452483018345

Epoch: 5| Step: 3
Training loss: 4.578006261125502
Validation loss: 4.616143992453522

Epoch: 5| Step: 4
Training loss: 4.04214495683304
Validation loss: 4.6111079692191534

Epoch: 5| Step: 5
Training loss: 4.836015001209048
Validation loss: 4.607441081586075

Epoch: 5| Step: 6
Training loss: 5.475363955310663
Validation loss: 4.60208237911207

Epoch: 5| Step: 7
Training loss: 4.717435944349227
Validation loss: 4.597557021425819

Epoch: 5| Step: 8
Training loss: 4.428751528721093
Validation loss: 4.593748330529011

Epoch: 5| Step: 9
Training loss: 3.707666115618064
Validation loss: 4.5886210746114795

Epoch: 5| Step: 10
Training loss: 4.274561425628333
Validation loss: 4.584157777098165

Epoch: 5| Step: 11
Training loss: 4.525194844640174
Validation loss: 4.579425470827144

Epoch: 21| Step: 0
Training loss: 5.38047423048808
Validation loss: 4.575261380245474

Epoch: 5| Step: 1
Training loss: 4.637762657603526
Validation loss: 4.57095226363784

Epoch: 5| Step: 2
Training loss: 5.3175631461902455
Validation loss: 4.566815273391529

Epoch: 5| Step: 3
Training loss: 3.7755049260455533
Validation loss: 4.5614452884845

Epoch: 5| Step: 4
Training loss: 5.062487566897349
Validation loss: 4.557264607667064

Epoch: 5| Step: 5
Training loss: 4.366263904391039
Validation loss: 4.5527303164614175

Epoch: 5| Step: 6
Training loss: 4.023913901558805
Validation loss: 4.548984103970229

Epoch: 5| Step: 7
Training loss: 5.0253807568888735
Validation loss: 4.544186259214127

Epoch: 5| Step: 8
Training loss: 4.9402784425047885
Validation loss: 4.539328041560334

Epoch: 5| Step: 9
Training loss: 4.035059585225879
Validation loss: 4.536188153332081

Epoch: 5| Step: 10
Training loss: 4.481292409443458
Validation loss: 4.531535260220983

Epoch: 5| Step: 11
Training loss: 5.288632261281584
Validation loss: 4.527209354805268

Epoch: 22| Step: 0
Training loss: 3.8846614127471923
Validation loss: 4.522054079662324

Epoch: 5| Step: 1
Training loss: 5.2535063524041705
Validation loss: 4.518174864985929

Epoch: 5| Step: 2
Training loss: 4.117232436454252
Validation loss: 4.514607615186274

Epoch: 5| Step: 3
Training loss: 4.626071702664515
Validation loss: 4.50944132607391

Epoch: 5| Step: 4
Training loss: 5.208352152472511
Validation loss: 4.504617039974826

Epoch: 5| Step: 5
Training loss: 4.608107984297491
Validation loss: 4.500235657349478

Epoch: 5| Step: 6
Training loss: 4.100115769775473
Validation loss: 4.495700442259514

Epoch: 5| Step: 7
Training loss: 4.827629187350313
Validation loss: 4.491383807394478

Epoch: 5| Step: 8
Training loss: 3.873813816762297
Validation loss: 4.486834508416751

Epoch: 5| Step: 9
Training loss: 5.227043642897099
Validation loss: 4.483160742849401

Epoch: 5| Step: 10
Training loss: 4.527298249879212
Validation loss: 4.478861654971084

Epoch: 5| Step: 11
Training loss: 6.1615048361340365
Validation loss: 4.474393451153701

Epoch: 23| Step: 0
Training loss: 4.872230134148277
Validation loss: 4.468846682411864

Epoch: 5| Step: 1
Training loss: 4.295151021342856
Validation loss: 4.465131170233518

Epoch: 5| Step: 2
Training loss: 4.529333090627097
Validation loss: 4.4602778760450414

Epoch: 5| Step: 3
Training loss: 4.913357003274439
Validation loss: 4.455927452195392

Epoch: 5| Step: 4
Training loss: 5.135948396072922
Validation loss: 4.451571210194586

Epoch: 5| Step: 5
Training loss: 3.7144970335949186
Validation loss: 4.446494170569676

Epoch: 5| Step: 6
Training loss: 4.752637632766019
Validation loss: 4.442135793711712

Epoch: 5| Step: 7
Training loss: 4.532887130170272
Validation loss: 4.437760461855342

Epoch: 5| Step: 8
Training loss: 4.377162290015618
Validation loss: 4.4334413252969265

Epoch: 5| Step: 9
Training loss: 4.538330439299185
Validation loss: 4.429130779359014

Epoch: 5| Step: 10
Training loss: 4.395068109568285
Validation loss: 4.425008227633426

Epoch: 5| Step: 11
Training loss: 5.140679541765179
Validation loss: 4.4199070140067915

Epoch: 24| Step: 0
Training loss: 4.744918313483989
Validation loss: 4.416677352004651

Epoch: 5| Step: 1
Training loss: 4.700648267151003
Validation loss: 4.413536481544391

Epoch: 5| Step: 2
Training loss: 3.85374354883793
Validation loss: 4.409731965876083

Epoch: 5| Step: 3
Training loss: 5.337123577057423
Validation loss: 4.406526038358951

Epoch: 5| Step: 4
Training loss: 4.165351253137209
Validation loss: 4.40201543685515

Epoch: 5| Step: 5
Training loss: 4.432198810015623
Validation loss: 4.396534595629161

Epoch: 5| Step: 6
Training loss: 5.463900961272963
Validation loss: 4.391851052618454

Epoch: 5| Step: 7
Training loss: 4.609837809458876
Validation loss: 4.387417949007105

Epoch: 5| Step: 8
Training loss: 4.498637098976869
Validation loss: 4.383561621669289

Epoch: 5| Step: 9
Training loss: 4.088950802039445
Validation loss: 4.378386962118322

Epoch: 5| Step: 10
Training loss: 3.7806549865169123
Validation loss: 4.373825578642557

Epoch: 5| Step: 11
Training loss: 3.317059527824729
Validation loss: 4.369138665071655

Epoch: 25| Step: 0
Training loss: 3.9065910495648297
Validation loss: 4.364441455850616

Epoch: 5| Step: 1
Training loss: 4.146744492179721
Validation loss: 4.360490334962768

Epoch: 5| Step: 2
Training loss: 3.8432461788312593
Validation loss: 4.356414108432552

Epoch: 5| Step: 3
Training loss: 5.2804675002194665
Validation loss: 4.352377901323886

Epoch: 5| Step: 4
Training loss: 3.752785474680071
Validation loss: 4.34780089305406

Epoch: 5| Step: 5
Training loss: 5.0558546743995185
Validation loss: 4.344269517892949

Epoch: 5| Step: 6
Training loss: 3.90061238689489
Validation loss: 4.339820181905374

Epoch: 5| Step: 7
Training loss: 4.312944693373726
Validation loss: 4.335450877699756

Epoch: 5| Step: 8
Training loss: 4.978861758208259
Validation loss: 4.331367655115263

Epoch: 5| Step: 9
Training loss: 4.768345790945876
Validation loss: 4.3271255808227815

Epoch: 5| Step: 10
Training loss: 4.759261488484477
Validation loss: 4.323019484557305

Epoch: 5| Step: 11
Training loss: 5.1192941304245085
Validation loss: 4.318411254111098

Epoch: 26| Step: 0
Training loss: 3.977177600466116
Validation loss: 4.3142644294953865

Epoch: 5| Step: 1
Training loss: 4.550798014990578
Validation loss: 4.309555587322712

Epoch: 5| Step: 2
Training loss: 3.94677767599629
Validation loss: 4.305530841647082

Epoch: 5| Step: 3
Training loss: 3.8547701526404268
Validation loss: 4.301044683562378

Epoch: 5| Step: 4
Training loss: 4.84136155830994
Validation loss: 4.2969082640314005

Epoch: 5| Step: 5
Training loss: 4.953633279322928
Validation loss: 4.292831071584506

Epoch: 5| Step: 6
Training loss: 4.751574205248037
Validation loss: 4.288511730747784

Epoch: 5| Step: 7
Training loss: 4.542589612968103
Validation loss: 4.283770308983048

Epoch: 5| Step: 8
Training loss: 4.247594264681305
Validation loss: 4.279366183187595

Epoch: 5| Step: 9
Training loss: 4.599278451471483
Validation loss: 4.274640385335358

Epoch: 5| Step: 10
Training loss: 3.86140468832162
Validation loss: 4.270541407524751

Epoch: 5| Step: 11
Training loss: 5.815206574356702
Validation loss: 4.26609982187189

Epoch: 27| Step: 0
Training loss: 5.364466081344035
Validation loss: 4.261432273273454

Epoch: 5| Step: 1
Training loss: 4.129934653811241
Validation loss: 4.257479224737659

Epoch: 5| Step: 2
Training loss: 4.156161429243062
Validation loss: 4.252273311542045

Epoch: 5| Step: 3
Training loss: 3.640597756738196
Validation loss: 4.247563336794325

Epoch: 5| Step: 4
Training loss: 4.415713489291038
Validation loss: 4.243546977030075

Epoch: 5| Step: 5
Training loss: 5.1988034558970275
Validation loss: 4.239113505931068

Epoch: 5| Step: 6
Training loss: 3.977025572788816
Validation loss: 4.23461498129435

Epoch: 5| Step: 7
Training loss: 4.113971648641988
Validation loss: 4.230380084657574

Epoch: 5| Step: 8
Training loss: 4.197695263245212
Validation loss: 4.2258963162716014

Epoch: 5| Step: 9
Training loss: 3.9386860105788073
Validation loss: 4.221859875964171

Epoch: 5| Step: 10
Training loss: 4.246929181267698
Validation loss: 4.217402151043399

Epoch: 5| Step: 11
Training loss: 5.970593552212598
Validation loss: 4.213165807129778

Epoch: 28| Step: 0
Training loss: 4.729698969030322
Validation loss: 4.208389195301203

Epoch: 5| Step: 1
Training loss: 4.857990423350909
Validation loss: 4.203713485758829

Epoch: 5| Step: 2
Training loss: 4.513443469380551
Validation loss: 4.199361896292897

Epoch: 5| Step: 3
Training loss: 4.560326881738912
Validation loss: 4.194849657684561

Epoch: 5| Step: 4
Training loss: 3.6664591354825005
Validation loss: 4.19041596132376

Epoch: 5| Step: 5
Training loss: 3.8827846226756417
Validation loss: 4.185522333649641

Epoch: 5| Step: 6
Training loss: 4.543554397843401
Validation loss: 4.181189422282641

Epoch: 5| Step: 7
Training loss: 4.378254579073684
Validation loss: 4.176556426354381

Epoch: 5| Step: 8
Training loss: 4.714116531077599
Validation loss: 4.172478611934906

Epoch: 5| Step: 9
Training loss: 3.4190087703426104
Validation loss: 4.168033555256049

Epoch: 5| Step: 10
Training loss: 4.039094375100894
Validation loss: 4.163243936762931

Epoch: 5| Step: 11
Training loss: 3.986681700543111
Validation loss: 4.15894516105052

Epoch: 29| Step: 0
Training loss: 4.798199896238453
Validation loss: 4.154896173859311

Epoch: 5| Step: 1
Training loss: 4.145553017090106
Validation loss: 4.150508193800491

Epoch: 5| Step: 2
Training loss: 4.8796243498005065
Validation loss: 4.145963046985587

Epoch: 5| Step: 3
Training loss: 4.653831519499782
Validation loss: 4.14195429738936

Epoch: 5| Step: 4
Training loss: 3.599719057776853
Validation loss: 4.1374423673213485

Epoch: 5| Step: 5
Training loss: 2.9708074567683496
Validation loss: 4.133142608362024

Epoch: 5| Step: 6
Training loss: 4.053957129170382
Validation loss: 4.128593733745825

Epoch: 5| Step: 7
Training loss: 4.403625572454253
Validation loss: 4.124589422773616

Epoch: 5| Step: 8
Training loss: 4.273501101060652
Validation loss: 4.120597667274604

Epoch: 5| Step: 9
Training loss: 3.807638476953819
Validation loss: 4.116407780222555

Epoch: 5| Step: 10
Training loss: 4.904968483111028
Validation loss: 4.112110281608044

Epoch: 5| Step: 11
Training loss: 4.282812125906359
Validation loss: 4.10759119110203

Epoch: 30| Step: 0
Training loss: 4.0704542490463025
Validation loss: 4.103626059090618

Epoch: 5| Step: 1
Training loss: 3.7105156267189456
Validation loss: 4.099429619276899

Epoch: 5| Step: 2
Training loss: 4.279680395938677
Validation loss: 4.094617780772981

Epoch: 5| Step: 3
Training loss: 5.0566647655372
Validation loss: 4.0898410295527805

Epoch: 5| Step: 4
Training loss: 4.147296180982614
Validation loss: 4.085269905046664

Epoch: 5| Step: 5
Training loss: 3.160608586967809
Validation loss: 4.081230973398471

Epoch: 5| Step: 6
Training loss: 4.51352608551334
Validation loss: 4.076774271168471

Epoch: 5| Step: 7
Training loss: 4.448238221218045
Validation loss: 4.072522145096542

Epoch: 5| Step: 8
Training loss: 4.890691494718184
Validation loss: 4.067910904506947

Epoch: 5| Step: 9
Training loss: 3.8469509039795913
Validation loss: 4.064084497196945

Epoch: 5| Step: 10
Training loss: 3.9451304780876058
Validation loss: 4.059457612952891

Epoch: 5| Step: 11
Training loss: 3.908083554049182
Validation loss: 4.054964731057565

Epoch: 31| Step: 0
Training loss: 3.7784296031298643
Validation loss: 4.050817731633551

Epoch: 5| Step: 1
Training loss: 4.481885903754407
Validation loss: 4.046631180967967

Epoch: 5| Step: 2
Training loss: 3.773812285266546
Validation loss: 4.042658628403751

Epoch: 5| Step: 3
Training loss: 3.851778654954448
Validation loss: 4.038572413252289

Epoch: 5| Step: 4
Training loss: 4.44479801572971
Validation loss: 4.034403004094801

Epoch: 5| Step: 5
Training loss: 4.537274794861659
Validation loss: 4.030019873088115

Epoch: 5| Step: 6
Training loss: 4.820523991574436
Validation loss: 4.025428027738577

Epoch: 5| Step: 7
Training loss: 3.538747474510507
Validation loss: 4.020875128428337

Epoch: 5| Step: 8
Training loss: 4.122100967333005
Validation loss: 4.01665130443458

Epoch: 5| Step: 9
Training loss: 4.1740337601426445
Validation loss: 4.012461528217322

Epoch: 5| Step: 10
Training loss: 4.149151009732292
Validation loss: 4.0080987680578986

Epoch: 5| Step: 11
Training loss: 3.8072464814572813
Validation loss: 4.003952552093493

Epoch: 32| Step: 0
Training loss: 4.525644136390218
Validation loss: 3.9996906399306593

Epoch: 5| Step: 1
Training loss: 4.017627973530079
Validation loss: 3.9949876703208136

Epoch: 5| Step: 2
Training loss: 4.673530821026326
Validation loss: 3.990749371332361

Epoch: 5| Step: 3
Training loss: 3.979808629098033
Validation loss: 3.986450781547996

Epoch: 5| Step: 4
Training loss: 4.013292637193063
Validation loss: 3.982147072613261

Epoch: 5| Step: 5
Training loss: 3.6023046428118795
Validation loss: 3.97777978418579

Epoch: 5| Step: 6
Training loss: 2.891535270263402
Validation loss: 3.9738855551092045

Epoch: 5| Step: 7
Training loss: 4.283188207124614
Validation loss: 3.9699042786830034

Epoch: 5| Step: 8
Training loss: 4.415637250209697
Validation loss: 3.966048074353652

Epoch: 5| Step: 9
Training loss: 4.146152937692875
Validation loss: 3.9610805147073367

Epoch: 5| Step: 10
Training loss: 4.475523183916645
Validation loss: 3.9573407869569763

Epoch: 5| Step: 11
Training loss: 3.5593385555555073
Validation loss: 3.9526876577072048

Epoch: 33| Step: 0
Training loss: 3.4286800634112664
Validation loss: 3.948148910146511

Epoch: 5| Step: 1
Training loss: 4.119151043505672
Validation loss: 3.9445480260695622

Epoch: 5| Step: 2
Training loss: 4.1050965987071235
Validation loss: 3.939546129134057

Epoch: 5| Step: 3
Training loss: 4.124322084150145
Validation loss: 3.9354336680497237

Epoch: 5| Step: 4
Training loss: 4.730326416495145
Validation loss: 3.9311097884734507

Epoch: 5| Step: 5
Training loss: 3.6013048456339436
Validation loss: 3.9261509811366135

Epoch: 5| Step: 6
Training loss: 3.585164437666002
Validation loss: 3.921704109997756

Epoch: 5| Step: 7
Training loss: 4.350205488941931
Validation loss: 3.9172443951295546

Epoch: 5| Step: 8
Training loss: 4.486756652640052
Validation loss: 3.9127820497275523

Epoch: 5| Step: 9
Training loss: 3.6743288322568124
Validation loss: 3.908561648157518

Epoch: 5| Step: 10
Training loss: 4.419834056863443
Validation loss: 3.904020716009651

Epoch: 5| Step: 11
Training loss: 2.939504548190148
Validation loss: 3.900053567192433

Epoch: 34| Step: 0
Training loss: 3.6704763792436994
Validation loss: 3.895671365128349

Epoch: 5| Step: 1
Training loss: 3.73972527846448
Validation loss: 3.891046335266181

Epoch: 5| Step: 2
Training loss: 4.037231502522001
Validation loss: 3.887072277764187

Epoch: 5| Step: 3
Training loss: 4.3244739102253495
Validation loss: 3.8826419631687172

Epoch: 5| Step: 4
Training loss: 4.043718321969477
Validation loss: 3.8787110104426303

Epoch: 5| Step: 5
Training loss: 4.180850770876062
Validation loss: 3.874507001053891

Epoch: 5| Step: 6
Training loss: 4.726137555148553
Validation loss: 3.8698158811048655

Epoch: 5| Step: 7
Training loss: 4.2062341471539115
Validation loss: 3.8650197025239383

Epoch: 5| Step: 8
Training loss: 3.6915967781104917
Validation loss: 3.8604169306555116

Epoch: 5| Step: 9
Training loss: 2.8131966469842222
Validation loss: 3.8559118632694713

Epoch: 5| Step: 10
Training loss: 4.296952014579705
Validation loss: 3.8517480667527675

Epoch: 5| Step: 11
Training loss: 4.284121698839653
Validation loss: 3.847360156134707

Epoch: 35| Step: 0
Training loss: 4.125375903948264
Validation loss: 3.8427906441535566

Epoch: 5| Step: 1
Training loss: 4.55046479921733
Validation loss: 3.8386809877175088

Epoch: 5| Step: 2
Training loss: 4.27260836799201
Validation loss: 3.834025184076027

Epoch: 5| Step: 3
Training loss: 3.6468807060242825
Validation loss: 3.8297545409667153

Epoch: 5| Step: 4
Training loss: 4.000993128512507
Validation loss: 3.8255420404637976

Epoch: 5| Step: 5
Training loss: 3.967112165699591
Validation loss: 3.820752665223857

Epoch: 5| Step: 6
Training loss: 4.082357614420447
Validation loss: 3.816386753476287

Epoch: 5| Step: 7
Training loss: 4.04054572432564
Validation loss: 3.8116652351318883

Epoch: 5| Step: 8
Training loss: 3.0487799533750484
Validation loss: 3.807343268229604

Epoch: 5| Step: 9
Training loss: 4.132981410477849
Validation loss: 3.803076855520095

Epoch: 5| Step: 10
Training loss: 3.358781913035
Validation loss: 3.7986703926557763

Epoch: 5| Step: 11
Training loss: 4.357151790850948
Validation loss: 3.7944750166887493

Epoch: 36| Step: 0
Training loss: 3.9617630137816375
Validation loss: 3.7904868840578274

Epoch: 5| Step: 1
Training loss: 4.362532152642191
Validation loss: 3.7860263287677824

Epoch: 5| Step: 2
Training loss: 4.069387144018774
Validation loss: 3.7819025406648703

Epoch: 5| Step: 3
Training loss: 3.415170590118001
Validation loss: 3.7777631514319094

Epoch: 5| Step: 4
Training loss: 3.744796576074487
Validation loss: 3.773362447915011

Epoch: 5| Step: 5
Training loss: 4.115826665967252
Validation loss: 3.76912890248705

Epoch: 5| Step: 6
Training loss: 4.305657749945758
Validation loss: 3.764591280927574

Epoch: 5| Step: 7
Training loss: 3.757700833190132
Validation loss: 3.7604441478848707

Epoch: 5| Step: 8
Training loss: 4.095894521189594
Validation loss: 3.7559728263109666

Epoch: 5| Step: 9
Training loss: 3.3261307306707306
Validation loss: 3.7520221238524454

Epoch: 5| Step: 10
Training loss: 3.621233858198296
Validation loss: 3.747962636632136

Epoch: 5| Step: 11
Training loss: 4.065815203804076
Validation loss: 3.743514601471824

Epoch: 37| Step: 0
Training loss: 3.512387017981776
Validation loss: 3.7391458253653016

Epoch: 5| Step: 1
Training loss: 4.262746209783481
Validation loss: 3.7349106472311897

Epoch: 5| Step: 2
Training loss: 4.139041468277776
Validation loss: 3.7306718434810735

Epoch: 5| Step: 3
Training loss: 3.633424243897899
Validation loss: 3.72631313148073

Epoch: 5| Step: 4
Training loss: 3.727436850797686
Validation loss: 3.72198795218741

Epoch: 5| Step: 5
Training loss: 3.982545320357162
Validation loss: 3.7175227953244643

Epoch: 5| Step: 6
Training loss: 3.94946952348119
Validation loss: 3.7129864039033027

Epoch: 5| Step: 7
Training loss: 3.875484313232267
Validation loss: 3.7088160343546424

Epoch: 5| Step: 8
Training loss: 4.15190321701823
Validation loss: 3.704074096846052

Epoch: 5| Step: 9
Training loss: 3.8875522965719114
Validation loss: 3.6995575752024665

Epoch: 5| Step: 10
Training loss: 2.9807995853818974
Validation loss: 3.6953088439106074

Epoch: 5| Step: 11
Training loss: 4.431196436807137
Validation loss: 3.6907477220356286

Epoch: 38| Step: 0
Training loss: 4.264231695310885
Validation loss: 3.6862719856383563

Epoch: 5| Step: 1
Training loss: 4.071876620733681
Validation loss: 3.682026130062423

Epoch: 5| Step: 2
Training loss: 4.232890076347069
Validation loss: 3.6777945290898217

Epoch: 5| Step: 3
Training loss: 3.195741209636238
Validation loss: 3.6731719952637887

Epoch: 5| Step: 4
Training loss: 3.0946256380967667
Validation loss: 3.6691084212815572

Epoch: 5| Step: 5
Training loss: 4.011168861032139
Validation loss: 3.6649054592632018

Epoch: 5| Step: 6
Training loss: 3.907646234842618
Validation loss: 3.660239317449074

Epoch: 5| Step: 7
Training loss: 4.286450645220487
Validation loss: 3.656640246613743

Epoch: 5| Step: 8
Training loss: 3.957058001745085
Validation loss: 3.651946793198218

Epoch: 5| Step: 9
Training loss: 3.447714731501435
Validation loss: 3.6477628869729357

Epoch: 5| Step: 10
Training loss: 3.2190474585702127
Validation loss: 3.6431563313065625

Epoch: 5| Step: 11
Training loss: 2.9983207453289777
Validation loss: 3.639024205195374

Epoch: 39| Step: 0
Training loss: 3.7623223348347348
Validation loss: 3.6349856531943607

Epoch: 5| Step: 1
Training loss: 2.6123065128498295
Validation loss: 3.631378612768498

Epoch: 5| Step: 2
Training loss: 4.303554822056449
Validation loss: 3.626953097610323

Epoch: 5| Step: 3
Training loss: 3.234814157940696
Validation loss: 3.6227520352308447

Epoch: 5| Step: 4
Training loss: 3.927875685082324
Validation loss: 3.6188008807200953

Epoch: 5| Step: 5
Training loss: 3.8998603746900526
Validation loss: 3.61462430170388

Epoch: 5| Step: 6
Training loss: 3.8177196854669355
Validation loss: 3.610507842356461

Epoch: 5| Step: 7
Training loss: 3.983500545508854
Validation loss: 3.6063917307381486

Epoch: 5| Step: 8
Training loss: 3.3916423343719777
Validation loss: 3.602140213425531

Epoch: 5| Step: 9
Training loss: 3.3746346169945234
Validation loss: 3.598572268207479

Epoch: 5| Step: 10
Training loss: 4.062899291149661
Validation loss: 3.594646364184652

Epoch: 5| Step: 11
Training loss: 5.960880224270213
Validation loss: 3.589925334060095

Epoch: 40| Step: 0
Training loss: 3.0418763458581304
Validation loss: 3.5853104330517023

Epoch: 5| Step: 1
Training loss: 3.9481435155321143
Validation loss: 3.5805942560847996

Epoch: 5| Step: 2
Training loss: 4.2179921917759415
Validation loss: 3.5760744152056714

Epoch: 5| Step: 3
Training loss: 3.5997489947657995
Validation loss: 3.5717582418783187

Epoch: 5| Step: 4
Training loss: 3.924866527061656
Validation loss: 3.566840683993861

Epoch: 5| Step: 5
Training loss: 3.2422886844150596
Validation loss: 3.562310905345844

Epoch: 5| Step: 6
Training loss: 3.8565972714347665
Validation loss: 3.5578171084595707

Epoch: 5| Step: 7
Training loss: 3.5376714873787116
Validation loss: 3.553588937774228

Epoch: 5| Step: 8
Training loss: 4.11382189437186
Validation loss: 3.5492829818785623

Epoch: 5| Step: 9
Training loss: 3.785144534255282
Validation loss: 3.5447378680039985

Epoch: 5| Step: 10
Training loss: 3.0933786805161403
Validation loss: 3.540372778586185

Epoch: 5| Step: 11
Training loss: 4.329511399750703
Validation loss: 3.53633511103407

Epoch: 41| Step: 0
Training loss: 3.4882757821205748
Validation loss: 3.5321631474664974

Epoch: 5| Step: 1
Training loss: 3.3234225439139555
Validation loss: 3.527893806453438

Epoch: 5| Step: 2
Training loss: 3.8221676930399404
Validation loss: 3.5239703444410484

Epoch: 5| Step: 3
Training loss: 3.3818899398752893
Validation loss: 3.5199189193104132

Epoch: 5| Step: 4
Training loss: 3.913691398403619
Validation loss: 3.516139319203861

Epoch: 5| Step: 5
Training loss: 3.46993613368468
Validation loss: 3.512186117616887

Epoch: 5| Step: 6
Training loss: 3.7918556222189443
Validation loss: 3.508338407360283

Epoch: 5| Step: 7
Training loss: 3.5104396981560084
Validation loss: 3.504377267536418

Epoch: 5| Step: 8
Training loss: 3.9478910876462883
Validation loss: 3.5004581878116348

Epoch: 5| Step: 9
Training loss: 3.6663363625843712
Validation loss: 3.4962900628749667

Epoch: 5| Step: 10
Training loss: 3.7449595591012996
Validation loss: 3.4921472022272515

Epoch: 5| Step: 11
Training loss: 3.738928408994081
Validation loss: 3.48798392161767

Epoch: 42| Step: 0
Training loss: 4.143597611837236
Validation loss: 3.4839750667669653

Epoch: 5| Step: 1
Training loss: 3.964572419903091
Validation loss: 3.4797567202222726

Epoch: 5| Step: 2
Training loss: 3.68039523241356
Validation loss: 3.4750506882206804

Epoch: 5| Step: 3
Training loss: 3.8425328258137306
Validation loss: 3.4710179094753544

Epoch: 5| Step: 4
Training loss: 3.1271676747034927
Validation loss: 3.4669015329529755

Epoch: 5| Step: 5
Training loss: 4.067882317580318
Validation loss: 3.4623988548773728

Epoch: 5| Step: 6
Training loss: 3.0593790773202847
Validation loss: 3.4578360100389496

Epoch: 5| Step: 7
Training loss: 3.566643162825198
Validation loss: 3.453903214117449

Epoch: 5| Step: 8
Training loss: 3.246701694302183
Validation loss: 3.4496386032355097

Epoch: 5| Step: 9
Training loss: 3.4857968564047295
Validation loss: 3.4456525765965824

Epoch: 5| Step: 10
Training loss: 3.5100149194557915
Validation loss: 3.4416245136188826

Epoch: 5| Step: 11
Training loss: 2.027806929229266
Validation loss: 3.437505051580243

Epoch: 43| Step: 0
Training loss: 3.2253773431549533
Validation loss: 3.4342539691049123

Epoch: 5| Step: 1
Training loss: 3.6688412084728173
Validation loss: 3.4310210813443383

Epoch: 5| Step: 2
Training loss: 3.780287060408804
Validation loss: 3.427810329019591

Epoch: 5| Step: 3
Training loss: 3.211115254403521
Validation loss: 3.4242565338907203

Epoch: 5| Step: 4
Training loss: 3.7014578756583787
Validation loss: 3.4207067484014417

Epoch: 5| Step: 5
Training loss: 4.2622962791109265
Validation loss: 3.4173149544439583

Epoch: 5| Step: 6
Training loss: 3.7052972916777347
Validation loss: 3.4134252726073857

Epoch: 5| Step: 7
Training loss: 2.734011555087068
Validation loss: 3.4094695120397165

Epoch: 5| Step: 8
Training loss: 3.620185944012555
Validation loss: 3.406027836218649

Epoch: 5| Step: 9
Training loss: 3.1656274763513728
Validation loss: 3.402210669500671

Epoch: 5| Step: 10
Training loss: 3.748024738160917
Validation loss: 3.3986806965185803

Epoch: 5| Step: 11
Training loss: 3.8632608843229
Validation loss: 3.3954676224461497

Epoch: 44| Step: 0
Training loss: 3.0729213046453787
Validation loss: 3.3915057935373265

Epoch: 5| Step: 1
Training loss: 3.9533511613526393
Validation loss: 3.388191299000912

Epoch: 5| Step: 2
Training loss: 3.3085460456732854
Validation loss: 3.384120864343728

Epoch: 5| Step: 3
Training loss: 3.7387289418935077
Validation loss: 3.380144983686449

Epoch: 5| Step: 4
Training loss: 3.7779839652646587
Validation loss: 3.376562669228275

Epoch: 5| Step: 5
Training loss: 3.2441922160162533
Validation loss: 3.3722442219749946

Epoch: 5| Step: 6
Training loss: 3.65518081551767
Validation loss: 3.3686709105125625

Epoch: 5| Step: 7
Training loss: 3.8242287250891356
Validation loss: 3.364665418200308

Epoch: 5| Step: 8
Training loss: 2.993218226977292
Validation loss: 3.3605881858674174

Epoch: 5| Step: 9
Training loss: 3.021136529549067
Validation loss: 3.356257288644881

Epoch: 5| Step: 10
Training loss: 3.630128324147822
Validation loss: 3.351442780983352

Epoch: 5| Step: 11
Training loss: 4.520106642486241
Validation loss: 3.347363412068024

Epoch: 45| Step: 0
Training loss: 3.1502105037046917
Validation loss: 3.343264820871297

Epoch: 5| Step: 1
Training loss: 2.9208081587623944
Validation loss: 3.3402513519285137

Epoch: 5| Step: 2
Training loss: 4.374943760101693
Validation loss: 3.3362304118174415

Epoch: 5| Step: 3
Training loss: 3.8091218083444986
Validation loss: 3.332535473386013

Epoch: 5| Step: 4
Training loss: 2.9433307000822024
Validation loss: 3.328729326902841

Epoch: 5| Step: 5
Training loss: 3.32081984290267
Validation loss: 3.325268834702133

Epoch: 5| Step: 6
Training loss: 3.5521127619414568
Validation loss: 3.3216920926112565

Epoch: 5| Step: 7
Training loss: 3.6403714202191564
Validation loss: 3.3177608783259873

Epoch: 5| Step: 8
Training loss: 3.642035738983851
Validation loss: 3.3138470939572184

Epoch: 5| Step: 9
Training loss: 3.402485858739298
Validation loss: 3.3097034441451303

Epoch: 5| Step: 10
Training loss: 3.1821468505540738
Validation loss: 3.3057737556713107

Epoch: 5| Step: 11
Training loss: 2.99425863193944
Validation loss: 3.3020936241751686

Epoch: 46| Step: 0
Training loss: 3.4657651413701878
Validation loss: 3.2982719017201254

Epoch: 5| Step: 1
Training loss: 3.3991493619562667
Validation loss: 3.2946494969197575

Epoch: 5| Step: 2
Training loss: 3.0300096943514503
Validation loss: 3.2911368961799465

Epoch: 5| Step: 3
Training loss: 4.241477499430338
Validation loss: 3.287439098205006

Epoch: 5| Step: 4
Training loss: 3.19992307332081
Validation loss: 3.2841869712988534

Epoch: 5| Step: 5
Training loss: 3.4461065575347187
Validation loss: 3.2805913718286566

Epoch: 5| Step: 6
Training loss: 3.3349610804813294
Validation loss: 3.2768364666405967

Epoch: 5| Step: 7
Training loss: 3.222923757836683
Validation loss: 3.2738102812167527

Epoch: 5| Step: 8
Training loss: 3.3464713742798566
Validation loss: 3.270164325150106

Epoch: 5| Step: 9
Training loss: 3.091266598654985
Validation loss: 3.2665110242429773

Epoch: 5| Step: 10
Training loss: 3.4985705590170535
Validation loss: 3.262902836392584

Epoch: 5| Step: 11
Training loss: 4.302039908989692
Validation loss: 3.259020672048528

Epoch: 47| Step: 0
Training loss: 3.4938940192549692
Validation loss: 3.2554408160797026

Epoch: 5| Step: 1
Training loss: 4.009707354286171
Validation loss: 3.252095066825688

Epoch: 5| Step: 2
Training loss: 3.122697974129787
Validation loss: 3.2482156745997353

Epoch: 5| Step: 3
Training loss: 3.6481032943406633
Validation loss: 3.244496977616124

Epoch: 5| Step: 4
Training loss: 3.8094726800325724
Validation loss: 3.2405837907074626

Epoch: 5| Step: 5
Training loss: 2.950966505356315
Validation loss: 3.2366982745039268

Epoch: 5| Step: 6
Training loss: 2.8959841974786222
Validation loss: 3.2325340781661422

Epoch: 5| Step: 7
Training loss: 3.279385863704728
Validation loss: 3.2286255208731482

Epoch: 5| Step: 8
Training loss: 3.567834440726692
Validation loss: 3.2253246195746277

Epoch: 5| Step: 9
Training loss: 2.9985879117880936
Validation loss: 3.2214227338610524

Epoch: 5| Step: 10
Training loss: 3.045419824782732
Validation loss: 3.2175444657049974

Epoch: 5| Step: 11
Training loss: 3.9963290535866807
Validation loss: 3.2144246096599214

Epoch: 48| Step: 0
Training loss: 3.7154694520620866
Validation loss: 3.2111031457849144

Epoch: 5| Step: 1
Training loss: 3.086700113443486
Validation loss: 3.2075093478678354

Epoch: 5| Step: 2
Training loss: 2.9149541641217387
Validation loss: 3.2039371298302033

Epoch: 5| Step: 3
Training loss: 3.7804119347853455
Validation loss: 3.200414382161644

Epoch: 5| Step: 4
Training loss: 3.3737363922308297
Validation loss: 3.1965545441478804

Epoch: 5| Step: 5
Training loss: 3.4422959596756093
Validation loss: 3.192610838222398

Epoch: 5| Step: 6
Training loss: 3.3930226651307986
Validation loss: 3.189141474158233

Epoch: 5| Step: 7
Training loss: 2.5964137726997487
Validation loss: 3.1852156020320312

Epoch: 5| Step: 8
Training loss: 3.877348403574303
Validation loss: 3.182004773099809

Epoch: 5| Step: 9
Training loss: 3.095069372727705
Validation loss: 3.1787692531973177

Epoch: 5| Step: 10
Training loss: 3.463647749956512
Validation loss: 3.1754273033205878

Epoch: 5| Step: 11
Training loss: 1.4375066342408052
Validation loss: 3.1720971403961826

Epoch: 49| Step: 0
Training loss: 3.393454781577951
Validation loss: 3.169049224168672

Epoch: 5| Step: 1
Training loss: 3.474929803372537
Validation loss: 3.1662959249875384

Epoch: 5| Step: 2
Training loss: 3.3439852908052794
Validation loss: 3.162944709284327

Epoch: 5| Step: 3
Training loss: 3.2555970633778846
Validation loss: 3.1597997450954267

Epoch: 5| Step: 4
Training loss: 3.0499821396601807
Validation loss: 3.156703145322595

Epoch: 5| Step: 5
Training loss: 3.396483532651563
Validation loss: 3.1537190194409406

Epoch: 5| Step: 6
Training loss: 3.57527626944157
Validation loss: 3.1507430867794746

Epoch: 5| Step: 7
Training loss: 3.2685062529089914
Validation loss: 3.1473809765790137

Epoch: 5| Step: 8
Training loss: 2.963798006812054
Validation loss: 3.144340885315718

Epoch: 5| Step: 9
Training loss: 3.6049625789483137
Validation loss: 3.141202212505403

Epoch: 5| Step: 10
Training loss: 2.6615165111854453
Validation loss: 3.138106001757371

Epoch: 5| Step: 11
Training loss: 3.9838184641187793
Validation loss: 3.135143003000866

Epoch: 50| Step: 0
Training loss: 2.7876784365895606
Validation loss: 3.131542496969607

Epoch: 5| Step: 1
Training loss: 3.436361228277804
Validation loss: 3.1286316749976764

Epoch: 5| Step: 2
Training loss: 3.864274100847021
Validation loss: 3.125534857436818

Epoch: 5| Step: 3
Training loss: 3.3152940590354842
Validation loss: 3.1224684633912876

Epoch: 5| Step: 4
Training loss: 3.444628589247161
Validation loss: 3.1188107297969054

Epoch: 5| Step: 5
Training loss: 3.1354990258705793
Validation loss: 3.115937143936063

Epoch: 5| Step: 6
Training loss: 3.5060873228471774
Validation loss: 3.112887783227154

Epoch: 5| Step: 7
Training loss: 3.215336591504454
Validation loss: 3.109463829420239

Epoch: 5| Step: 8
Training loss: 2.8071194361767335
Validation loss: 3.106278000161088

Epoch: 5| Step: 9
Training loss: 2.5864667552534857
Validation loss: 3.103007232336725

Epoch: 5| Step: 10
Training loss: 3.055554357200927
Validation loss: 3.100212578509225

Epoch: 5| Step: 11
Training loss: 5.072074971749035
Validation loss: 3.0973516493261357

Epoch: 51| Step: 0
Training loss: 2.9562374445384476
Validation loss: 3.0937279112826856

Epoch: 5| Step: 1
Training loss: 4.102006346892492
Validation loss: 3.090203188354376

Epoch: 5| Step: 2
Training loss: 3.3934204953234213
Validation loss: 3.0872491101402604

Epoch: 5| Step: 3
Training loss: 3.9310750464488704
Validation loss: 3.0838604274626715

Epoch: 5| Step: 4
Training loss: 3.281892985968631
Validation loss: 3.080225761776225

Epoch: 5| Step: 5
Training loss: 3.1077192489112835
Validation loss: 3.0765201561168993

Epoch: 5| Step: 6
Training loss: 2.272335244093145
Validation loss: 3.073331544100502

Epoch: 5| Step: 7
Training loss: 2.7384535535293724
Validation loss: 3.069973804794949

Epoch: 5| Step: 8
Training loss: 2.9387636104708283
Validation loss: 3.067130752792526

Epoch: 5| Step: 9
Training loss: 3.293383733953179
Validation loss: 3.064042345259858

Epoch: 5| Step: 10
Training loss: 3.1595597240503794
Validation loss: 3.061400777417003

Epoch: 5| Step: 11
Training loss: 2.331493015253484
Validation loss: 3.0586385776422587

Epoch: 52| Step: 0
Training loss: 3.412758724479542
Validation loss: 3.055560953804989

Epoch: 5| Step: 1
Training loss: 3.4116224564925894
Validation loss: 3.0524603520775337

Epoch: 5| Step: 2
Training loss: 3.031529993713274
Validation loss: 3.0496812987451016

Epoch: 5| Step: 3
Training loss: 3.820787021990002
Validation loss: 3.047006838953915

Epoch: 5| Step: 4
Training loss: 2.997964963508466
Validation loss: 3.0441001678915125

Epoch: 5| Step: 5
Training loss: 3.223323646565044
Validation loss: 3.0411761271531565

Epoch: 5| Step: 6
Training loss: 3.1718458352838677
Validation loss: 3.0381050203272366

Epoch: 5| Step: 7
Training loss: 2.798224437958469
Validation loss: 3.0356756393526485

Epoch: 5| Step: 8
Training loss: 2.8886319274409895
Validation loss: 3.0328657294634556

Epoch: 5| Step: 9
Training loss: 3.231177477142651
Validation loss: 3.0301268584434795

Epoch: 5| Step: 10
Training loss: 2.876809753036091
Validation loss: 3.027271005720433

Epoch: 5| Step: 11
Training loss: 3.2949557390264825
Validation loss: 3.0244292243542166

Epoch: 53| Step: 0
Training loss: 2.784399242702316
Validation loss: 3.0216425875023285

Epoch: 5| Step: 1
Training loss: 3.320132979981486
Validation loss: 3.0191641942652083

Epoch: 5| Step: 2
Training loss: 3.2300440590986157
Validation loss: 3.016318022530988

Epoch: 5| Step: 3
Training loss: 2.9809477135015103
Validation loss: 3.0140074408976614

Epoch: 5| Step: 4
Training loss: 2.9967998284388226
Validation loss: 3.0116893471660915

Epoch: 5| Step: 5
Training loss: 3.209563692334802
Validation loss: 3.0092793838664895

Epoch: 5| Step: 6
Training loss: 3.6724715377296757
Validation loss: 3.0072395604720614

Epoch: 5| Step: 7
Training loss: 3.088946688482517
Validation loss: 3.004528029255595

Epoch: 5| Step: 8
Training loss: 2.846446006435694
Validation loss: 3.001777188753187

Epoch: 5| Step: 9
Training loss: 3.295080482993442
Validation loss: 2.9994281051501432

Epoch: 5| Step: 10
Training loss: 3.2720543754834828
Validation loss: 2.9966227509138186

Epoch: 5| Step: 11
Training loss: 2.2884608184280695
Validation loss: 2.9937758185136762

Epoch: 54| Step: 0
Training loss: 2.495035774112091
Validation loss: 2.9908282028569473

Epoch: 5| Step: 1
Training loss: 2.598716760287934
Validation loss: 2.988809779016201

Epoch: 5| Step: 2
Training loss: 2.272859165526082
Validation loss: 2.986132285809417

Epoch: 5| Step: 3
Training loss: 3.008813627019572
Validation loss: 2.983693978862848

Epoch: 5| Step: 4
Training loss: 2.9881470494273645
Validation loss: 2.981297365714687

Epoch: 5| Step: 5
Training loss: 3.668794159241663
Validation loss: 2.9789458017352217

Epoch: 5| Step: 6
Training loss: 3.7088771521330086
Validation loss: 2.976431809540782

Epoch: 5| Step: 7
Training loss: 3.6386212904931288
Validation loss: 2.973675737243426

Epoch: 5| Step: 8
Training loss: 3.3918879393834582
Validation loss: 2.970788068725249

Epoch: 5| Step: 9
Training loss: 2.8767492528960683
Validation loss: 2.9682694598330905

Epoch: 5| Step: 10
Training loss: 3.3098995149693495
Validation loss: 2.9658375122924787

Epoch: 5| Step: 11
Training loss: 2.924108294338054
Validation loss: 2.963139345227813

Epoch: 55| Step: 0
Training loss: 3.28340819091147
Validation loss: 2.9606401366295905

Epoch: 5| Step: 1
Training loss: 2.60781996756205
Validation loss: 2.957989747731211

Epoch: 5| Step: 2
Training loss: 3.138115482828721
Validation loss: 2.9555099249148085

Epoch: 5| Step: 3
Training loss: 3.309800541564244
Validation loss: 2.953326418565731

Epoch: 5| Step: 4
Training loss: 3.2081655152923054
Validation loss: 2.950145543813115

Epoch: 5| Step: 5
Training loss: 3.3136705453643596
Validation loss: 2.947881311984184

Epoch: 5| Step: 6
Training loss: 3.3290273669863457
Validation loss: 2.9450273384181087

Epoch: 5| Step: 7
Training loss: 2.745461359911275
Validation loss: 2.9425612230016776

Epoch: 5| Step: 8
Training loss: 2.77923210749486
Validation loss: 2.9398632891327767

Epoch: 5| Step: 9
Training loss: 3.2300905608245616
Validation loss: 2.9376808374622865

Epoch: 5| Step: 10
Training loss: 2.8979457222098746
Validation loss: 2.935089431014311

Epoch: 5| Step: 11
Training loss: 3.321929466109661
Validation loss: 2.9332598188428785

Epoch: 56| Step: 0
Training loss: 2.8823423751783936
Validation loss: 2.930727781615544

Epoch: 5| Step: 1
Training loss: 3.2583519651330675
Validation loss: 2.9285301703056694

Epoch: 5| Step: 2
Training loss: 3.3659498591006214
Validation loss: 2.9259696156227246

Epoch: 5| Step: 3
Training loss: 3.4491298573359215
Validation loss: 2.923592540327599

Epoch: 5| Step: 4
Training loss: 3.12279570084192
Validation loss: 2.921091637683318

Epoch: 5| Step: 5
Training loss: 3.2728512769383564
Validation loss: 2.918473645591067

Epoch: 5| Step: 6
Training loss: 3.3717932831741044
Validation loss: 2.91622208828683

Epoch: 5| Step: 7
Training loss: 2.4453951788139285
Validation loss: 2.9136001758794734

Epoch: 5| Step: 8
Training loss: 2.71241715476098
Validation loss: 2.9115049134397024

Epoch: 5| Step: 9
Training loss: 3.183624903988671
Validation loss: 2.909243504973644

Epoch: 5| Step: 10
Training loss: 2.5822210891350545
Validation loss: 2.90701178168558

Epoch: 5| Step: 11
Training loss: 2.2033889287762745
Validation loss: 2.9048666857902705

Epoch: 57| Step: 0
Training loss: 2.7995158253716568
Validation loss: 2.9030713982864054

Epoch: 5| Step: 1
Training loss: 2.8400892232929316
Validation loss: 2.900717319366568

Epoch: 5| Step: 2
Training loss: 3.028637418901995
Validation loss: 2.898459370162999

Epoch: 5| Step: 3
Training loss: 2.3513792860066998
Validation loss: 2.896452162964989

Epoch: 5| Step: 4
Training loss: 3.178927093985024
Validation loss: 2.894605765196535

Epoch: 5| Step: 5
Training loss: 2.516258965451167
Validation loss: 2.892432724970703

Epoch: 5| Step: 6
Training loss: 3.282513184589947
Validation loss: 2.8906498263555926

Epoch: 5| Step: 7
Training loss: 3.1831109739871284
Validation loss: 2.8885363206746297

Epoch: 5| Step: 8
Training loss: 3.493910805920289
Validation loss: 2.8865488782704936

Epoch: 5| Step: 9
Training loss: 3.2923631212983406
Validation loss: 2.8846449089577137

Epoch: 5| Step: 10
Training loss: 3.3515324802432525
Validation loss: 2.882419349168535

Epoch: 5| Step: 11
Training loss: 2.163282894355697
Validation loss: 2.8802927992416945

Epoch: 58| Step: 0
Training loss: 3.348760825463967
Validation loss: 2.878207580453062

Epoch: 5| Step: 1
Training loss: 2.984148905712864
Validation loss: 2.876211693677334

Epoch: 5| Step: 2
Training loss: 3.518951063357334
Validation loss: 2.8740574839791098

Epoch: 5| Step: 3
Training loss: 2.416312838554778
Validation loss: 2.8721206489414146

Epoch: 5| Step: 4
Training loss: 2.9026483347706247
Validation loss: 2.8703543162808445

Epoch: 5| Step: 5
Training loss: 3.1694624421565893
Validation loss: 2.8680603645896054

Epoch: 5| Step: 6
Training loss: 2.581958856303588
Validation loss: 2.866076927366529

Epoch: 5| Step: 7
Training loss: 2.9527353503996108
Validation loss: 2.864265730619622

Epoch: 5| Step: 8
Training loss: 2.879290157895604
Validation loss: 2.8623749225337187

Epoch: 5| Step: 9
Training loss: 3.095080157152512
Validation loss: 2.8609558175717793

Epoch: 5| Step: 10
Training loss: 3.1421697812408333
Validation loss: 2.859029867191914

Epoch: 5| Step: 11
Training loss: 2.910258983872475
Validation loss: 2.857203011291071

Epoch: 59| Step: 0
Training loss: 3.2586894147279755
Validation loss: 2.855221596322516

Epoch: 5| Step: 1
Training loss: 3.3109838506776565
Validation loss: 2.853242941623016

Epoch: 5| Step: 2
Training loss: 3.3355799892134077
Validation loss: 2.851213355441421

Epoch: 5| Step: 3
Training loss: 2.5938367714213135
Validation loss: 2.84898654475125

Epoch: 5| Step: 4
Training loss: 2.897172759883392
Validation loss: 2.846924358516498

Epoch: 5| Step: 5
Training loss: 3.1210028452519554
Validation loss: 2.8448237358771085

Epoch: 5| Step: 6
Training loss: 2.921321714514234
Validation loss: 2.8424326706513967

Epoch: 5| Step: 7
Training loss: 2.670294757246131
Validation loss: 2.8405009562620527

Epoch: 5| Step: 8
Training loss: 2.779126846356101
Validation loss: 2.838560941904867

Epoch: 5| Step: 9
Training loss: 2.9362489998963115
Validation loss: 2.8365892024021577

Epoch: 5| Step: 10
Training loss: 2.776238029553792
Validation loss: 2.8349256856060143

Epoch: 5| Step: 11
Training loss: 3.715595221500402
Validation loss: 2.833324622860777

Epoch: 60| Step: 0
Training loss: 3.2978839505553506
Validation loss: 2.8311227292668426

Epoch: 5| Step: 1
Training loss: 2.8370085235994753
Validation loss: 2.829262678505087

Epoch: 5| Step: 2
Training loss: 2.7642603379130697
Validation loss: 2.8276677543576287

Epoch: 5| Step: 3
Training loss: 2.956356803142231
Validation loss: 2.825815979386724

Epoch: 5| Step: 4
Training loss: 3.0043603680331525
Validation loss: 2.8241245013102483

Epoch: 5| Step: 5
Training loss: 3.1258743588806195
Validation loss: 2.8222564450722962

Epoch: 5| Step: 6
Training loss: 2.7314364965389997
Validation loss: 2.8199824900060975

Epoch: 5| Step: 7
Training loss: 3.1199781121195356
Validation loss: 2.8182086899891847

Epoch: 5| Step: 8
Training loss: 2.8794577496054177
Validation loss: 2.8167269308557885

Epoch: 5| Step: 9
Training loss: 2.8783256535371495
Validation loss: 2.814726866293678

Epoch: 5| Step: 10
Training loss: 2.851138901274856
Validation loss: 2.812937342231026

Epoch: 5| Step: 11
Training loss: 3.4996264122080825
Validation loss: 2.811245398262524

Epoch: 61| Step: 0
Training loss: 2.6838680832305437
Validation loss: 2.809370592231956

Epoch: 5| Step: 1
Training loss: 3.0364313576984823
Validation loss: 2.8076540418776794

Epoch: 5| Step: 2
Training loss: 3.0204367717155
Validation loss: 2.8058543173395525

Epoch: 5| Step: 3
Training loss: 2.510383975078622
Validation loss: 2.8041761883257053

Epoch: 5| Step: 4
Training loss: 2.979992589749333
Validation loss: 2.8025279466413586

Epoch: 5| Step: 5
Training loss: 2.830083685132996
Validation loss: 2.8011892882507037

Epoch: 5| Step: 6
Training loss: 2.9228848430906815
Validation loss: 2.7992969412231976

Epoch: 5| Step: 7
Training loss: 3.0082516040073335
Validation loss: 2.7976315716440916

Epoch: 5| Step: 8
Training loss: 3.0346556733082575
Validation loss: 2.7961221281908295

Epoch: 5| Step: 9
Training loss: 2.855969344693172
Validation loss: 2.7942865708409537

Epoch: 5| Step: 10
Training loss: 3.3189315257742695
Validation loss: 2.792503542270309

Epoch: 5| Step: 11
Training loss: 3.4013240087519163
Validation loss: 2.79084208513765

Epoch: 62| Step: 0
Training loss: 2.831657269218827
Validation loss: 2.7895613828787345

Epoch: 5| Step: 1
Training loss: 2.7986003306528033
Validation loss: 2.7876224664833655

Epoch: 5| Step: 2
Training loss: 2.9270696311620923
Validation loss: 2.7857881268849973

Epoch: 5| Step: 3
Training loss: 2.709712122586545
Validation loss: 2.784301055828283

Epoch: 5| Step: 4
Training loss: 2.314675313207559
Validation loss: 2.782436692744968

Epoch: 5| Step: 5
Training loss: 2.951542990656887
Validation loss: 2.781159317309866

Epoch: 5| Step: 6
Training loss: 2.988301993902674
Validation loss: 2.7794627687220963

Epoch: 5| Step: 7
Training loss: 3.125629971902055
Validation loss: 2.7778297818137294

Epoch: 5| Step: 8
Training loss: 3.1027371658798666
Validation loss: 2.776547542711342

Epoch: 5| Step: 9
Training loss: 3.0750807216562865
Validation loss: 2.7747617112340572

Epoch: 5| Step: 10
Training loss: 3.128150420033219
Validation loss: 2.7735037710662653

Epoch: 5| Step: 11
Training loss: 3.440547909682881
Validation loss: 2.7717483427060494

Epoch: 63| Step: 0
Training loss: 3.0181633736672513
Validation loss: 2.7700852027073424

Epoch: 5| Step: 1
Training loss: 3.150655036515209
Validation loss: 2.768865978001989

Epoch: 5| Step: 2
Training loss: 2.952015340305157
Validation loss: 2.7675707163472643

Epoch: 5| Step: 3
Training loss: 2.5037628466028505
Validation loss: 2.765679012281221

Epoch: 5| Step: 4
Training loss: 2.9625101467554344
Validation loss: 2.7642067040146863

Epoch: 5| Step: 5
Training loss: 2.6730242482807696
Validation loss: 2.7628130437658194

Epoch: 5| Step: 6
Training loss: 2.715814694011628
Validation loss: 2.761531120232229

Epoch: 5| Step: 7
Training loss: 3.16237929042189
Validation loss: 2.7597900015187955

Epoch: 5| Step: 8
Training loss: 2.8075610558247592
Validation loss: 2.7584528229197347

Epoch: 5| Step: 9
Training loss: 2.987310433857664
Validation loss: 2.7573159611036036

Epoch: 5| Step: 10
Training loss: 2.611272795611011
Validation loss: 2.755275074102981

Epoch: 5| Step: 11
Training loss: 4.22705526529052
Validation loss: 2.7537309451027636

Epoch: 64| Step: 0
Training loss: 2.5324706913569184
Validation loss: 2.752628060450408

Epoch: 5| Step: 1
Training loss: 2.7674208160898908
Validation loss: 2.7493835646974394

Epoch: 5| Step: 2
Training loss: 2.7791505240257988
Validation loss: 2.749351710430228

Epoch: 5| Step: 3
Training loss: 2.672303817870888
Validation loss: 2.748061808401172

Epoch: 5| Step: 4
Training loss: 3.00781995103582
Validation loss: 2.746377893166094

Epoch: 5| Step: 5
Training loss: 3.041982468884957
Validation loss: 2.7453192626661402

Epoch: 5| Step: 6
Training loss: 2.988614411575073
Validation loss: 2.74342391495702

Epoch: 5| Step: 7
Training loss: 3.040532323007104
Validation loss: 2.7421113209227674

Epoch: 5| Step: 8
Training loss: 2.625307882509461
Validation loss: 2.7404882522330745

Epoch: 5| Step: 9
Training loss: 2.5758721883709126
Validation loss: 2.740322826695351

Epoch: 5| Step: 10
Training loss: 3.454026186624558
Validation loss: 2.738082352478596

Epoch: 5| Step: 11
Training loss: 3.5454559848577962
Validation loss: 2.736702758353211

Epoch: 65| Step: 0
Training loss: 2.921182642214417
Validation loss: 2.736816551442161

Epoch: 5| Step: 1
Training loss: 3.2639301775401726
Validation loss: 2.7343700445221093

Epoch: 5| Step: 2
Training loss: 2.1012314319414256
Validation loss: 2.73353576860319

Epoch: 5| Step: 3
Training loss: 3.1617883115166427
Validation loss: 2.7325432009479735

Epoch: 5| Step: 4
Training loss: 2.7820400873144004
Validation loss: 2.7298964818021942

Epoch: 5| Step: 5
Training loss: 3.2090824458157767
Validation loss: 2.728762499654965

Epoch: 5| Step: 6
Training loss: 2.822929035079906
Validation loss: 2.726959826239834

Epoch: 5| Step: 7
Training loss: 2.535045838853872
Validation loss: 2.726051377388598

Epoch: 5| Step: 8
Training loss: 2.465899016380106
Validation loss: 2.7240914457533094

Epoch: 5| Step: 9
Training loss: 3.1729600675891176
Validation loss: 2.7234271165478763

Epoch: 5| Step: 10
Training loss: 2.9027735108299066
Validation loss: 2.720173470415251

Epoch: 5| Step: 11
Training loss: 2.8766819553550973
Validation loss: 2.720078541998448

Epoch: 66| Step: 0
Training loss: 2.63967047599938
Validation loss: 2.7118142768653413

Epoch: 5| Step: 1
Training loss: 2.800277685973445
Validation loss: 2.717554172887175

Epoch: 5| Step: 2
Training loss: 3.3904596103815936
Validation loss: 2.7413484642828676

Epoch: 5| Step: 3
Training loss: 2.487783337275885
Validation loss: 2.7176122623324823

Epoch: 5| Step: 4
Training loss: 2.4936393885353456
Validation loss: 2.7128061089603177

Epoch: 5| Step: 5
Training loss: 3.020290896066601
Validation loss: 2.714909398591053

Epoch: 5| Step: 6
Training loss: 2.6500739609095847
Validation loss: 2.7193170263116

Epoch: 5| Step: 7
Training loss: 2.8184344941912123
Validation loss: 2.7209121320762897

Epoch: 5| Step: 8
Training loss: 3.126481277348755
Validation loss: 2.7264635929797216

Epoch: 5| Step: 9
Training loss: 3.104036435119884
Validation loss: 2.7105847183212117

Epoch: 5| Step: 10
Training loss: 2.9423110198572213
Validation loss: 2.7053991024031356

Epoch: 5| Step: 11
Training loss: 2.1518535298061097
Validation loss: 2.704747666648918

Epoch: 67| Step: 0
Training loss: 2.8821676716788875
Validation loss: 2.705929482871034

Epoch: 5| Step: 1
Training loss: 2.7144626706743673
Validation loss: 2.716407833952831

Epoch: 5| Step: 2
Training loss: 2.8588181250444245
Validation loss: 2.7151200517523537

Epoch: 5| Step: 3
Training loss: 2.301881070694802
Validation loss: 2.6999853051339087

Epoch: 5| Step: 4
Training loss: 2.7368501632201148
Validation loss: 2.6956811883101355

Epoch: 5| Step: 5
Training loss: 3.013975334588006
Validation loss: 2.693865106399473

Epoch: 5| Step: 6
Training loss: 2.5675785632867987
Validation loss: 2.6904311386076794

Epoch: 5| Step: 7
Training loss: 2.843948022005268
Validation loss: 2.686214335408824

Epoch: 5| Step: 8
Training loss: 2.8595941178210516
Validation loss: 2.691790549160526

Epoch: 5| Step: 9
Training loss: 3.3149938732338007
Validation loss: 2.6974298352145336

Epoch: 5| Step: 10
Training loss: 3.130540437689128
Validation loss: 2.689685365488334

Epoch: 5| Step: 11
Training loss: 2.5710238599942374
Validation loss: 2.6819386382632495

Epoch: 68| Step: 0
Training loss: 2.8461216688815587
Validation loss: 2.6899423775238667

Epoch: 5| Step: 1
Training loss: 2.2990591861627863
Validation loss: 2.7075859224499763

Epoch: 5| Step: 2
Training loss: 2.772910914330328
Validation loss: 2.7353818583737257

Epoch: 5| Step: 3
Training loss: 3.1672338345887674
Validation loss: 2.766174926250477

Epoch: 5| Step: 4
Training loss: 2.798596922967588
Validation loss: 2.740297914485692

Epoch: 5| Step: 5
Training loss: 2.7418218732999424
Validation loss: 2.7120585217095257

Epoch: 5| Step: 6
Training loss: 2.6696982635420383
Validation loss: 2.69774925542232

Epoch: 5| Step: 7
Training loss: 2.8673444907633505
Validation loss: 2.688565190973619

Epoch: 5| Step: 8
Training loss: 2.769648583082914
Validation loss: 2.6816511716586633

Epoch: 5| Step: 9
Training loss: 3.3059163435397756
Validation loss: 2.6758908140300552

Epoch: 5| Step: 10
Training loss: 3.06858346024915
Validation loss: 2.6741517723047523

Epoch: 5| Step: 11
Training loss: 2.1369383313818173
Validation loss: 2.6789405196830947

Epoch: 69| Step: 0
Training loss: 3.0591371718519023
Validation loss: 2.6894577975614613

Epoch: 5| Step: 1
Training loss: 2.987500855513574
Validation loss: 2.6710680064526264

Epoch: 5| Step: 2
Training loss: 2.7953137350319555
Validation loss: 2.6728713834281077

Epoch: 5| Step: 3
Training loss: 2.3035066327247327
Validation loss: 2.669588088123685

Epoch: 5| Step: 4
Training loss: 3.1066273573269902
Validation loss: 2.6778974569211473

Epoch: 5| Step: 5
Training loss: 2.6938942536497996
Validation loss: 2.661463957082004

Epoch: 5| Step: 6
Training loss: 2.2570668609545743
Validation loss: 2.664011979952501

Epoch: 5| Step: 7
Training loss: 2.6256197243255883
Validation loss: 2.6668215473218893

Epoch: 5| Step: 8
Training loss: 2.6037121388818396
Validation loss: 2.667434020699701

Epoch: 5| Step: 9
Training loss: 3.2880651996208967
Validation loss: 2.668319950846563

Epoch: 5| Step: 10
Training loss: 3.1153222337728175
Validation loss: 2.6696855430680695

Epoch: 5| Step: 11
Training loss: 2.507489240020455
Validation loss: 2.669757498439281

Epoch: 70| Step: 0
Training loss: 2.9020941769483364
Validation loss: 2.6672348681226934

Epoch: 5| Step: 1
Training loss: 2.7145940652099885
Validation loss: 2.6651631055354112

Epoch: 5| Step: 2
Training loss: 2.6255986575535255
Validation loss: 2.662173316357452

Epoch: 5| Step: 3
Training loss: 2.653231263026523
Validation loss: 2.6610698316861505

Epoch: 5| Step: 4
Training loss: 2.997881618256885
Validation loss: 2.6598772153743706

Epoch: 5| Step: 5
Training loss: 2.6433454415940782
Validation loss: 2.658775550110937

Epoch: 5| Step: 6
Training loss: 2.8718240860005015
Validation loss: 2.654303095279055

Epoch: 5| Step: 7
Training loss: 1.8874577245967372
Validation loss: 2.6539524501447156

Epoch: 5| Step: 8
Training loss: 3.3157981431858876
Validation loss: 2.650588558323997

Epoch: 5| Step: 9
Training loss: 3.081072175812095
Validation loss: 2.651200045568097

Epoch: 5| Step: 10
Training loss: 2.8506573638383585
Validation loss: 2.649091562922678

Epoch: 5| Step: 11
Training loss: 2.7114587991669867
Validation loss: 2.648092909519377

Epoch: 71| Step: 0
Training loss: 2.596362441396329
Validation loss: 2.6497641572429806

Epoch: 5| Step: 1
Training loss: 2.9870510386450886
Validation loss: 2.6527467626541656

Epoch: 5| Step: 2
Training loss: 3.0469854872795805
Validation loss: 2.655048150825059

Epoch: 5| Step: 3
Training loss: 2.848968078113095
Validation loss: 2.6577871362910073

Epoch: 5| Step: 4
Training loss: 2.6099767847599877
Validation loss: 2.659615852485449

Epoch: 5| Step: 5
Training loss: 2.606054328873261
Validation loss: 2.66250513371792

Epoch: 5| Step: 6
Training loss: 2.883081604510882
Validation loss: 2.6576585550518956

Epoch: 5| Step: 7
Training loss: 2.7637215653660085
Validation loss: 2.656408428628563

Epoch: 5| Step: 8
Training loss: 2.4593311698526965
Validation loss: 2.6530928043288653

Epoch: 5| Step: 9
Training loss: 2.874551821066559
Validation loss: 2.649972465210142

Epoch: 5| Step: 10
Training loss: 2.922055488764535
Validation loss: 2.647321437761256

Epoch: 5| Step: 11
Training loss: 3.2726971282919344
Validation loss: 2.6470683712153398

Epoch: 72| Step: 0
Training loss: 3.1231222996481534
Validation loss: 2.644870689316342

Epoch: 5| Step: 1
Training loss: 2.5420037238921376
Validation loss: 2.64372917795361

Epoch: 5| Step: 2
Training loss: 2.4649094272091383
Validation loss: 2.642496284896082

Epoch: 5| Step: 3
Training loss: 2.2046990148945174
Validation loss: 2.6417501712160165

Epoch: 5| Step: 4
Training loss: 3.1400197522945303
Validation loss: 2.6406251843394077

Epoch: 5| Step: 5
Training loss: 2.9327623837578387
Validation loss: 2.6394036193965347

Epoch: 5| Step: 6
Training loss: 2.8955395958942787
Validation loss: 2.6386505020672755

Epoch: 5| Step: 7
Training loss: 2.550411086512345
Validation loss: 2.638008002161803

Epoch: 5| Step: 8
Training loss: 2.738652485757209
Validation loss: 2.6369873023141523

Epoch: 5| Step: 9
Training loss: 2.6763433381168915
Validation loss: 2.6357138972479652

Epoch: 5| Step: 10
Training loss: 3.013773137070625
Validation loss: 2.6350675560231287

Epoch: 5| Step: 11
Training loss: 3.390771678089961
Validation loss: 2.632164238604256

Epoch: 73| Step: 0
Training loss: 2.699150647685784
Validation loss: 2.631058773875523

Epoch: 5| Step: 1
Training loss: 3.2345928911170025
Validation loss: 2.631108793968562

Epoch: 5| Step: 2
Training loss: 3.066777259104092
Validation loss: 2.63046597392917

Epoch: 5| Step: 3
Training loss: 2.595236938038006
Validation loss: 2.628724143384357

Epoch: 5| Step: 4
Training loss: 2.9438753137825224
Validation loss: 2.6277941939741973

Epoch: 5| Step: 5
Training loss: 3.12354504093373
Validation loss: 2.625265017255903

Epoch: 5| Step: 6
Training loss: 2.3754572177279085
Validation loss: 2.6251868302600587

Epoch: 5| Step: 7
Training loss: 2.2669126863294506
Validation loss: 2.622924911682001

Epoch: 5| Step: 8
Training loss: 2.7391350866558626
Validation loss: 2.6225353697569593

Epoch: 5| Step: 9
Training loss: 2.7378893257493973
Validation loss: 2.624541450746076

Epoch: 5| Step: 10
Training loss: 2.5882492565477104
Validation loss: 2.6228701072016634

Epoch: 5| Step: 11
Training loss: 2.3475781521366663
Validation loss: 2.6211299637909358

Epoch: 74| Step: 0
Training loss: 2.6218334353838593
Validation loss: 2.6187787584715005

Epoch: 5| Step: 1
Training loss: 2.66755693197944
Validation loss: 2.6189758833075474

Epoch: 5| Step: 2
Training loss: 2.488653756948253
Validation loss: 2.62019333436704

Epoch: 5| Step: 3
Training loss: 2.937212828539035
Validation loss: 2.618830276296735

Epoch: 5| Step: 4
Training loss: 2.410375748937936
Validation loss: 2.617817756338202

Epoch: 5| Step: 5
Training loss: 2.7641150884116357
Validation loss: 2.618882661765614

Epoch: 5| Step: 6
Training loss: 3.1376539762488806
Validation loss: 2.617572076734804

Epoch: 5| Step: 7
Training loss: 2.743300861276159
Validation loss: 2.6164614035548404

Epoch: 5| Step: 8
Training loss: 2.923226436659978
Validation loss: 2.6148345504886126

Epoch: 5| Step: 9
Training loss: 2.65548183329076
Validation loss: 2.615671175963494

Epoch: 5| Step: 10
Training loss: 2.9399188208239133
Validation loss: 2.6124192599546405

Epoch: 5| Step: 11
Training loss: 2.6111894341032986
Validation loss: 2.613515006170499

Epoch: 75| Step: 0
Training loss: 2.3637638324431665
Validation loss: 2.6137413908471396

Epoch: 5| Step: 1
Training loss: 2.1776932100930004
Validation loss: 2.6106809709604035

Epoch: 5| Step: 2
Training loss: 2.5171090244631706
Validation loss: 2.6116524273614643

Epoch: 5| Step: 3
Training loss: 2.6680890303345395
Validation loss: 2.6118532317137517

Epoch: 5| Step: 4
Training loss: 2.934419680774214
Validation loss: 2.609194892103987

Epoch: 5| Step: 5
Training loss: 2.916185357480654
Validation loss: 2.6101773907131567

Epoch: 5| Step: 6
Training loss: 2.980819741476622
Validation loss: 2.6089892264024668

Epoch: 5| Step: 7
Training loss: 2.4355043898534867
Validation loss: 2.6062999888260285

Epoch: 5| Step: 8
Training loss: 2.6954895845925604
Validation loss: 2.607873541755819

Epoch: 5| Step: 9
Training loss: 2.9212102286782233
Validation loss: 2.6074370880254643

Epoch: 5| Step: 10
Training loss: 3.1771908267654645
Validation loss: 2.608608136970914

Epoch: 5| Step: 11
Training loss: 3.8349628025921745
Validation loss: 2.6067051048769994

Epoch: 76| Step: 0
Training loss: 2.9820555616251734
Validation loss: 2.6072392165155827

Epoch: 5| Step: 1
Training loss: 3.2239678320593277
Validation loss: 2.6080222554205577

Epoch: 5| Step: 2
Training loss: 3.1243721903547765
Validation loss: 2.6067464651416317

Epoch: 5| Step: 3
Training loss: 2.75755356391629
Validation loss: 2.6078402675264964

Epoch: 5| Step: 4
Training loss: 2.43306808550137
Validation loss: 2.6058312296902084

Epoch: 5| Step: 5
Training loss: 2.6358876366639143
Validation loss: 2.6063182042785344

Epoch: 5| Step: 6
Training loss: 2.5006891254496897
Validation loss: 2.6057620705547593

Epoch: 5| Step: 7
Training loss: 2.428458832286408
Validation loss: 2.605832400053919

Epoch: 5| Step: 8
Training loss: 2.7348037819501863
Validation loss: 2.605829113884773

Epoch: 5| Step: 9
Training loss: 2.5140140659178525
Validation loss: 2.605778619964255

Epoch: 5| Step: 10
Training loss: 2.766578466855593
Validation loss: 2.6035808107686846

Epoch: 5| Step: 11
Training loss: 2.5392660675607104
Validation loss: 2.6023696815666884

Epoch: 77| Step: 0
Training loss: 2.6439864754035143
Validation loss: 2.6021766357757032

Epoch: 5| Step: 1
Training loss: 2.9138932984347736
Validation loss: 2.6007009536419505

Epoch: 5| Step: 2
Training loss: 2.7557645547560843
Validation loss: 2.5993469816634556

Epoch: 5| Step: 3
Training loss: 2.79804959486771
Validation loss: 2.59852521315926

Epoch: 5| Step: 4
Training loss: 3.002058912112151
Validation loss: 2.598358866193192

Epoch: 5| Step: 5
Training loss: 2.9704029500916347
Validation loss: 2.5959411695644294

Epoch: 5| Step: 6
Training loss: 2.6104443580354144
Validation loss: 2.5925647103201728

Epoch: 5| Step: 7
Training loss: 2.5227889889940265
Validation loss: 2.590924662187572

Epoch: 5| Step: 8
Training loss: 2.818432463969126
Validation loss: 2.5899002467955587

Epoch: 5| Step: 9
Training loss: 2.6738529134511113
Validation loss: 2.588816719613705

Epoch: 5| Step: 10
Training loss: 2.228581206069709
Validation loss: 2.586165384506616

Epoch: 5| Step: 11
Training loss: 2.7391846128532915
Validation loss: 2.5931309685186736

Epoch: 78| Step: 0
Training loss: 2.867865957705692
Validation loss: 2.5899587560619883

Epoch: 5| Step: 1
Training loss: 2.4998147895871745
Validation loss: 2.58730893681259

Epoch: 5| Step: 2
Training loss: 2.725180114253157
Validation loss: 2.5807734478264046

Epoch: 5| Step: 3
Training loss: 2.785169946495074
Validation loss: 2.580472594029344

Epoch: 5| Step: 4
Training loss: 3.0001115778200846
Validation loss: 2.5813641054181136

Epoch: 5| Step: 5
Training loss: 2.617295356919345
Validation loss: 2.5847056894173903

Epoch: 5| Step: 6
Training loss: 2.7074591668625905
Validation loss: 2.58488058213431

Epoch: 5| Step: 7
Training loss: 2.4899312392089805
Validation loss: 2.586149850445464

Epoch: 5| Step: 8
Training loss: 2.587767722612261
Validation loss: 2.5867676722905184

Epoch: 5| Step: 9
Training loss: 2.951378522867187
Validation loss: 2.5875031148735133

Epoch: 5| Step: 10
Training loss: 2.519791937064926
Validation loss: 2.5874247427913466

Epoch: 5| Step: 11
Training loss: 3.873368196532972
Validation loss: 2.5869681426007247

Epoch: 79| Step: 0
Training loss: 2.2566530623183207
Validation loss: 2.5849821509920075

Epoch: 5| Step: 1
Training loss: 2.7292122194016892
Validation loss: 2.585810340298033

Epoch: 5| Step: 2
Training loss: 2.4163092864173974
Validation loss: 2.5855465273605462

Epoch: 5| Step: 3
Training loss: 2.8418936906296004
Validation loss: 2.583262155434156

Epoch: 5| Step: 4
Training loss: 2.751296431389254
Validation loss: 2.5867963403854826

Epoch: 5| Step: 5
Training loss: 2.5200844800503366
Validation loss: 2.58676197703704

Epoch: 5| Step: 6
Training loss: 2.978130098000293
Validation loss: 2.585976626281696

Epoch: 5| Step: 7
Training loss: 2.8140807901536804
Validation loss: 2.5858998329515606

Epoch: 5| Step: 8
Training loss: 2.5803038666562133
Validation loss: 2.586625302553854

Epoch: 5| Step: 9
Training loss: 2.7239782990306822
Validation loss: 2.58934039119249

Epoch: 5| Step: 10
Training loss: 3.2243924359661498
Validation loss: 2.5880645885416573

Epoch: 5| Step: 11
Training loss: 2.9351981051651252
Validation loss: 2.586103435927913

Epoch: 80| Step: 0
Training loss: 3.1312851833415083
Validation loss: 2.5832095975365497

Epoch: 5| Step: 1
Training loss: 2.389036161727875
Validation loss: 2.580135309209884

Epoch: 5| Step: 2
Training loss: 2.408893470787173
Validation loss: 2.5782946405567206

Epoch: 5| Step: 3
Training loss: 2.28877147087389
Validation loss: 2.5747715072424975

Epoch: 5| Step: 4
Training loss: 2.8443237396630403
Validation loss: 2.5746738068286374

Epoch: 5| Step: 5
Training loss: 2.6815407797610926
Validation loss: 2.574540600026655

Epoch: 5| Step: 6
Training loss: 2.739042646963936
Validation loss: 2.5684880406939974

Epoch: 5| Step: 7
Training loss: 2.57481412124092
Validation loss: 2.567550496994915

Epoch: 5| Step: 8
Training loss: 2.8651749618392737
Validation loss: 2.5648486802464987

Epoch: 5| Step: 9
Training loss: 2.7536917095620987
Validation loss: 2.5676410980913467

Epoch: 5| Step: 10
Training loss: 2.9922137944034777
Validation loss: 2.563602504966767

Epoch: 5| Step: 11
Training loss: 2.9527571514657662
Validation loss: 2.5654190967439465

Epoch: 81| Step: 0
Training loss: 3.0950644426924208
Validation loss: 2.564279124740653

Epoch: 5| Step: 1
Training loss: 2.6167994880577807
Validation loss: 2.5668970158452287

Epoch: 5| Step: 2
Training loss: 2.5387366452563143
Validation loss: 2.568890732021736

Epoch: 5| Step: 3
Training loss: 2.892611424204853
Validation loss: 2.569839843764349

Epoch: 5| Step: 4
Training loss: 2.9078609144801657
Validation loss: 2.570034394683456

Epoch: 5| Step: 5
Training loss: 2.119441897867233
Validation loss: 2.5695270354654975

Epoch: 5| Step: 6
Training loss: 2.8384082634518486
Validation loss: 2.5706005186285843

Epoch: 5| Step: 7
Training loss: 2.64111296529798
Validation loss: 2.5728949740237987

Epoch: 5| Step: 8
Training loss: 2.606482267207114
Validation loss: 2.5720013111194215

Epoch: 5| Step: 9
Training loss: 2.973592563099935
Validation loss: 2.573232289053345

Epoch: 5| Step: 10
Training loss: 2.577419392521339
Validation loss: 2.572879174508871

Epoch: 5| Step: 11
Training loss: 1.9590449832504933
Validation loss: 2.5717333274499388

Epoch: 82| Step: 0
Training loss: 3.0207131899038644
Validation loss: 2.5689591010965986

Epoch: 5| Step: 1
Training loss: 2.7200039131472993
Validation loss: 2.5683037774821456

Epoch: 5| Step: 2
Training loss: 3.057522991901827
Validation loss: 2.5685506848542494

Epoch: 5| Step: 3
Training loss: 2.8574939648288327
Validation loss: 2.563947346403073

Epoch: 5| Step: 4
Training loss: 2.7015487396966473
Validation loss: 2.5649208132410193

Epoch: 5| Step: 5
Training loss: 2.474348456425141
Validation loss: 2.5641421816895247

Epoch: 5| Step: 6
Training loss: 2.5102919446003176
Validation loss: 2.563550807301577

Epoch: 5| Step: 7
Training loss: 2.1958589247117692
Validation loss: 2.5608907624332766

Epoch: 5| Step: 8
Training loss: 2.9933461468372076
Validation loss: 2.5591670706796363

Epoch: 5| Step: 9
Training loss: 2.7107175358516393
Validation loss: 2.559649556842438

Epoch: 5| Step: 10
Training loss: 2.4278982756231122
Validation loss: 2.5567268996208

Epoch: 5| Step: 11
Training loss: 2.3604107534856933
Validation loss: 2.5596331361010196

Epoch: 83| Step: 0
Training loss: 2.5189336023548754
Validation loss: 2.5568902321499083

Epoch: 5| Step: 1
Training loss: 2.48772784775846
Validation loss: 2.557792235185233

Epoch: 5| Step: 2
Training loss: 2.609414197433184
Validation loss: 2.5577179863521207

Epoch: 5| Step: 3
Training loss: 2.5060681132005347
Validation loss: 2.55527480643255

Epoch: 5| Step: 4
Training loss: 2.6081310665042694
Validation loss: 2.5538419088180544

Epoch: 5| Step: 5
Training loss: 2.441686897931784
Validation loss: 2.5504401087409376

Epoch: 5| Step: 6
Training loss: 3.062806717441262
Validation loss: 2.549899148816684

Epoch: 5| Step: 7
Training loss: 2.9350382452427426
Validation loss: 2.5525885036579243

Epoch: 5| Step: 8
Training loss: 2.8762191177958294
Validation loss: 2.5490321558800626

Epoch: 5| Step: 9
Training loss: 2.9230406368953212
Validation loss: 2.5474825721396654

Epoch: 5| Step: 10
Training loss: 2.438177259208312
Validation loss: 2.548384240718726

Epoch: 5| Step: 11
Training loss: 3.131586686419609
Validation loss: 2.5468479069241905

Epoch: 84| Step: 0
Training loss: 2.5582163292122777
Validation loss: 2.550129899287974

Epoch: 5| Step: 1
Training loss: 2.746438754943529
Validation loss: 2.5603499580510385

Epoch: 5| Step: 2
Training loss: 2.6477585543995965
Validation loss: 2.581836102488994

Epoch: 5| Step: 3
Training loss: 2.7712191454142348
Validation loss: 2.575707560302695

Epoch: 5| Step: 4
Training loss: 2.96360059164471
Validation loss: 2.5538247972321804

Epoch: 5| Step: 5
Training loss: 2.396617385170119
Validation loss: 2.5615830486621807

Epoch: 5| Step: 6
Training loss: 2.628950778986503
Validation loss: 2.5557500163730107

Epoch: 5| Step: 7
Training loss: 2.985066119153439
Validation loss: 2.543416473617972

Epoch: 5| Step: 8
Training loss: 2.419943352974198
Validation loss: 2.544296215064823

Epoch: 5| Step: 9
Training loss: 2.936916536864273
Validation loss: 2.545362319755345

Epoch: 5| Step: 10
Training loss: 2.553420939855736
Validation loss: 2.551104238409171

Epoch: 5| Step: 11
Training loss: 1.6678704047412434
Validation loss: 2.55780811624029

Epoch: 85| Step: 0
Training loss: 2.8025177024534025
Validation loss: 2.5593359377918903

Epoch: 5| Step: 1
Training loss: 2.4579854061664994
Validation loss: 2.56289900410267

Epoch: 5| Step: 2
Training loss: 2.5242467002065028
Validation loss: 2.565001782279731

Epoch: 5| Step: 3
Training loss: 2.835066228022363
Validation loss: 2.5747345333847864

Epoch: 5| Step: 4
Training loss: 2.7166102967137973
Validation loss: 2.57641006999693

Epoch: 5| Step: 5
Training loss: 2.9245563790151294
Validation loss: 2.5723462508534176

Epoch: 5| Step: 6
Training loss: 2.076704070099851
Validation loss: 2.573103671414443

Epoch: 5| Step: 7
Training loss: 2.9630761789396685
Validation loss: 2.5723264895078657

Epoch: 5| Step: 8
Training loss: 2.809948760139041
Validation loss: 2.5659321850819308

Epoch: 5| Step: 9
Training loss: 3.0634818546734652
Validation loss: 2.562466140461342

Epoch: 5| Step: 10
Training loss: 2.45898951377665
Validation loss: 2.5601300623631835

Epoch: 5| Step: 11
Training loss: 2.418842607642522
Validation loss: 2.55946011617161

Epoch: 86| Step: 0
Training loss: 2.8256859140763972
Validation loss: 2.5578004728394523

Epoch: 5| Step: 1
Training loss: 2.7644969988989656
Validation loss: 2.555407349779789

Epoch: 5| Step: 2
Training loss: 2.8470769850328272
Validation loss: 2.5532335738430563

Epoch: 5| Step: 3
Training loss: 3.060489695391596
Validation loss: 2.5500872818339397

Epoch: 5| Step: 4
Training loss: 2.715686431295288
Validation loss: 2.547753629097487

Epoch: 5| Step: 5
Training loss: 2.5853870186244414
Validation loss: 2.5412479913068453

Epoch: 5| Step: 6
Training loss: 2.1779069088044074
Validation loss: 2.540008341363792

Epoch: 5| Step: 7
Training loss: 2.565760515283831
Validation loss: 2.5402784243307606

Epoch: 5| Step: 8
Training loss: 2.8420579508511246
Validation loss: 2.5348686991714753

Epoch: 5| Step: 9
Training loss: 2.4794912259376827
Validation loss: 2.5279596198411625

Epoch: 5| Step: 10
Training loss: 2.3156340728870313
Validation loss: 2.5244485858890635

Epoch: 5| Step: 11
Training loss: 3.122430737034941
Validation loss: 2.5313732996293767

Epoch: 87| Step: 0
Training loss: 2.5548881428638683
Validation loss: 2.564023340434892

Epoch: 5| Step: 1
Training loss: 2.751566094174656
Validation loss: 2.60908344109464

Epoch: 5| Step: 2
Training loss: 2.567673090344048
Validation loss: 2.6479390555835125

Epoch: 5| Step: 3
Training loss: 2.9818443233756615
Validation loss: 2.6454787517353506

Epoch: 5| Step: 4
Training loss: 2.7315875859554812
Validation loss: 2.610782909705937

Epoch: 5| Step: 5
Training loss: 3.0374753283844846
Validation loss: 2.571400556067968

Epoch: 5| Step: 6
Training loss: 2.467321827802998
Validation loss: 2.5451552624860274

Epoch: 5| Step: 7
Training loss: 2.634219554871811
Validation loss: 2.5434562032308516

Epoch: 5| Step: 8
Training loss: 2.8349646378721975
Validation loss: 2.538717254250308

Epoch: 5| Step: 9
Training loss: 2.857186068480566
Validation loss: 2.538314302197367

Epoch: 5| Step: 10
Training loss: 2.365099902311232
Validation loss: 2.5324530587862233

Epoch: 5| Step: 11
Training loss: 2.5804546581025587
Validation loss: 2.5350396551232053

Epoch: 88| Step: 0
Training loss: 2.306940664856956
Validation loss: 2.5428652002490515

Epoch: 5| Step: 1
Training loss: 2.8513245365713815
Validation loss: 2.5487898744560606

Epoch: 5| Step: 2
Training loss: 2.8645150101345487
Validation loss: 2.558559512620305

Epoch: 5| Step: 3
Training loss: 2.420352974362998
Validation loss: 2.5602257529881984

Epoch: 5| Step: 4
Training loss: 2.8634359570350973
Validation loss: 2.56463297794075

Epoch: 5| Step: 5
Training loss: 2.7637586600221025
Validation loss: 2.5630249788255557

Epoch: 5| Step: 6
Training loss: 2.4938519220390005
Validation loss: 2.5618905994306096

Epoch: 5| Step: 7
Training loss: 2.488032593571882
Validation loss: 2.55487014008761

Epoch: 5| Step: 8
Training loss: 2.6728097273340454
Validation loss: 2.548899491481473

Epoch: 5| Step: 9
Training loss: 2.7905806996074722
Validation loss: 2.5482060946198817

Epoch: 5| Step: 10
Training loss: 2.8480308087536312
Validation loss: 2.54063300834917

Epoch: 5| Step: 11
Training loss: 3.120672510244984
Validation loss: 2.54319637938101

Epoch: 89| Step: 0
Training loss: 2.9573372968481464
Validation loss: 2.5432034729401782

Epoch: 5| Step: 1
Training loss: 2.1439257046509304
Validation loss: 2.5360256089663387

Epoch: 5| Step: 2
Training loss: 2.3782837903699847
Validation loss: 2.5365235961935944

Epoch: 5| Step: 3
Training loss: 2.5764682879784764
Validation loss: 2.5323491633823734

Epoch: 5| Step: 4
Training loss: 2.9780273037203844
Validation loss: 2.531708350107345

Epoch: 5| Step: 5
Training loss: 2.7387313581674038
Validation loss: 2.5311568717936157

Epoch: 5| Step: 6
Training loss: 3.039453162651812
Validation loss: 2.5235204417294717

Epoch: 5| Step: 7
Training loss: 2.6482641112697864
Validation loss: 2.523355838962087

Epoch: 5| Step: 8
Training loss: 2.636276547120569
Validation loss: 2.515219926306315

Epoch: 5| Step: 9
Training loss: 2.3510468890383254
Validation loss: 2.5115555413091886

Epoch: 5| Step: 10
Training loss: 2.8312761655023686
Validation loss: 2.5105545248798755

Epoch: 5| Step: 11
Training loss: 2.1605312580653946
Validation loss: 2.5141399257031436

Epoch: 90| Step: 0
Training loss: 2.892354581799311
Validation loss: 2.514666222568074

Epoch: 5| Step: 1
Training loss: 2.515319995278911
Validation loss: 2.5205665097748193

Epoch: 5| Step: 2
Training loss: 2.6053389898698844
Validation loss: 2.5436248831319253

Epoch: 5| Step: 3
Training loss: 2.8076181216031055
Validation loss: 2.552932151754526

Epoch: 5| Step: 4
Training loss: 2.392882035864082
Validation loss: 2.5479923636815087

Epoch: 5| Step: 5
Training loss: 2.6951521231441515
Validation loss: 2.526924145636016

Epoch: 5| Step: 6
Training loss: 2.871331901793798
Validation loss: 2.519211644840487

Epoch: 5| Step: 7
Training loss: 2.4758946814993874
Validation loss: 2.5152995410417436

Epoch: 5| Step: 8
Training loss: 2.9085692309120477
Validation loss: 2.509165556303615

Epoch: 5| Step: 9
Training loss: 2.447224414962535
Validation loss: 2.5127725442303834

Epoch: 5| Step: 10
Training loss: 2.8187571117370616
Validation loss: 2.5166328891062135

Epoch: 5| Step: 11
Training loss: 2.347689966350026
Validation loss: 2.516119752334317

Epoch: 91| Step: 0
Training loss: 2.2675968402678364
Validation loss: 2.521550070066628

Epoch: 5| Step: 1
Training loss: 2.629713368189436
Validation loss: 2.525209908683325

Epoch: 5| Step: 2
Training loss: 2.9280190561643753
Validation loss: 2.533850072300038

Epoch: 5| Step: 3
Training loss: 2.3585536108047838
Validation loss: 2.5338184861235353

Epoch: 5| Step: 4
Training loss: 2.2992589088326247
Validation loss: 2.540532196370704

Epoch: 5| Step: 5
Training loss: 2.7501023880364595
Validation loss: 2.542634843428196

Epoch: 5| Step: 6
Training loss: 2.6548683612323254
Validation loss: 2.545282380808113

Epoch: 5| Step: 7
Training loss: 3.0859815377099107
Validation loss: 2.544657914317111

Epoch: 5| Step: 8
Training loss: 3.0811904127692613
Validation loss: 2.544672155729448

Epoch: 5| Step: 9
Training loss: 2.8331761223055727
Validation loss: 2.54610411165963

Epoch: 5| Step: 10
Training loss: 2.4521213106138435
Validation loss: 2.5435132812404215

Epoch: 5| Step: 11
Training loss: 2.158634360197528
Validation loss: 2.54022777325197

Epoch: 92| Step: 0
Training loss: 2.8580659465082054
Validation loss: 2.5393445293586634

Epoch: 5| Step: 1
Training loss: 2.5629157682725374
Validation loss: 2.5363483143992913

Epoch: 5| Step: 2
Training loss: 3.1872842753095845
Validation loss: 2.5322747373675405

Epoch: 5| Step: 3
Training loss: 2.699611872574042
Validation loss: 2.530206834256851

Epoch: 5| Step: 4
Training loss: 2.629843920148502
Validation loss: 2.523345831435263

Epoch: 5| Step: 5
Training loss: 2.466896713544
Validation loss: 2.522955873112817

Epoch: 5| Step: 6
Training loss: 2.6611271681419497
Validation loss: 2.52028256434214

Epoch: 5| Step: 7
Training loss: 2.354444898069533
Validation loss: 2.5199121980723262

Epoch: 5| Step: 8
Training loss: 2.8052620896888945
Validation loss: 2.515982059546452

Epoch: 5| Step: 9
Training loss: 2.621183800322992
Validation loss: 2.520623294234792

Epoch: 5| Step: 10
Training loss: 2.4057749489849574
Validation loss: 2.5183349095378955

Epoch: 5| Step: 11
Training loss: 2.237123519509043
Validation loss: 2.5150706665710856

Epoch: 93| Step: 0
Training loss: 2.3485316010871413
Validation loss: 2.5111645274461325

Epoch: 5| Step: 1
Training loss: 2.8818365993518387
Validation loss: 2.5128526120715704

Epoch: 5| Step: 2
Training loss: 2.840598571452965
Validation loss: 2.5153046477050656

Epoch: 5| Step: 3
Training loss: 2.018718268083076
Validation loss: 2.515634319532993

Epoch: 5| Step: 4
Training loss: 3.027426284157198
Validation loss: 2.5130041619309513

Epoch: 5| Step: 5
Training loss: 2.5653291297026923
Validation loss: 2.5146788363795167

Epoch: 5| Step: 6
Training loss: 2.4212884007974815
Validation loss: 2.512688196070616

Epoch: 5| Step: 7
Training loss: 2.1019973021470895
Validation loss: 2.516704280416399

Epoch: 5| Step: 8
Training loss: 2.7597549989013848
Validation loss: 2.51060289797536

Epoch: 5| Step: 9
Training loss: 2.733361105273822
Validation loss: 2.508876392650663

Epoch: 5| Step: 10
Training loss: 3.17582404188767
Validation loss: 2.5109450422647286

Epoch: 5| Step: 11
Training loss: 2.4620083855517927
Validation loss: 2.510050799722032

Epoch: 94| Step: 0
Training loss: 1.974116866725007
Validation loss: 2.503188484139316

Epoch: 5| Step: 1
Training loss: 2.89821704118623
Validation loss: 2.506449989812488

Epoch: 5| Step: 2
Training loss: 2.60853325521466
Validation loss: 2.512030297906557

Epoch: 5| Step: 3
Training loss: 2.129678624583143
Validation loss: 2.5277329213548856

Epoch: 5| Step: 4
Training loss: 2.5447567983563304
Validation loss: 2.532395782485348

Epoch: 5| Step: 5
Training loss: 3.1998181649043977
Validation loss: 2.526182801279199

Epoch: 5| Step: 6
Training loss: 2.691900863930629
Validation loss: 2.516940833046121

Epoch: 5| Step: 7
Training loss: 2.474336315526154
Validation loss: 2.5178796169890965

Epoch: 5| Step: 8
Training loss: 2.7096057445997954
Validation loss: 2.5090923034491746

Epoch: 5| Step: 9
Training loss: 2.6459519867811885
Validation loss: 2.5084391451745844

Epoch: 5| Step: 10
Training loss: 3.0899482256060975
Validation loss: 2.5051051982394403

Epoch: 5| Step: 11
Training loss: 2.710974349505273
Validation loss: 2.503960766052525

Epoch: 95| Step: 0
Training loss: 2.785120895610768
Validation loss: 2.5012234714009307

Epoch: 5| Step: 1
Training loss: 2.6722899889884335
Validation loss: 2.5096599551664363

Epoch: 5| Step: 2
Training loss: 3.0119897940616016
Validation loss: 2.501424546481538

Epoch: 5| Step: 3
Training loss: 2.641389995571198
Validation loss: 2.5088173624741397

Epoch: 5| Step: 4
Training loss: 2.904201318724757
Validation loss: 2.505479886464704

Epoch: 5| Step: 5
Training loss: 2.912017841294936
Validation loss: 2.501872386716592

Epoch: 5| Step: 6
Training loss: 2.321871968776937
Validation loss: 2.508762167923428

Epoch: 5| Step: 7
Training loss: 2.68155758389497
Validation loss: 2.510127060094489

Epoch: 5| Step: 8
Training loss: 2.4266481677946703
Validation loss: 2.510557844748282

Epoch: 5| Step: 9
Training loss: 2.264566739982822
Validation loss: 2.5048108819916552

Epoch: 5| Step: 10
Training loss: 2.3977903804009864
Validation loss: 2.506107852199325

Epoch: 5| Step: 11
Training loss: 2.263727274653736
Validation loss: 2.5039468842302397

Epoch: 96| Step: 0
Training loss: 2.5341638818148717
Validation loss: 2.5025926577131075

Epoch: 5| Step: 1
Training loss: 2.4477327210053437
Validation loss: 2.5040232551203743

Epoch: 5| Step: 2
Training loss: 3.0619120130698154
Validation loss: 2.502439774675535

Epoch: 5| Step: 3
Training loss: 2.322947024387942
Validation loss: 2.503517834892613

Epoch: 5| Step: 4
Training loss: 3.088928472904119
Validation loss: 2.500786133189083

Epoch: 5| Step: 5
Training loss: 2.447272931671804
Validation loss: 2.50585980711428

Epoch: 5| Step: 6
Training loss: 2.8109983886095313
Validation loss: 2.4998112488064517

Epoch: 5| Step: 7
Training loss: 2.7264185651590345
Validation loss: 2.498438144609799

Epoch: 5| Step: 8
Training loss: 2.31943225540136
Validation loss: 2.4981818064540238

Epoch: 5| Step: 9
Training loss: 2.5682039743267198
Validation loss: 2.5007673595852675

Epoch: 5| Step: 10
Training loss: 2.6949815629884024
Validation loss: 2.498746963239602

Epoch: 5| Step: 11
Training loss: 1.706815727822267
Validation loss: 2.497997328182621

Epoch: 97| Step: 0
Training loss: 3.0013556596300384
Validation loss: 2.498435391140307

Epoch: 5| Step: 1
Training loss: 2.6389672306768386
Validation loss: 2.492905416693327

Epoch: 5| Step: 2
Training loss: 2.7633479167735944
Validation loss: 2.4929127310612826

Epoch: 5| Step: 3
Training loss: 2.714606536820715
Validation loss: 2.491854371354715

Epoch: 5| Step: 4
Training loss: 2.361144255112535
Validation loss: 2.490263049390671

Epoch: 5| Step: 5
Training loss: 2.8610553077597185
Validation loss: 2.4920601966735076

Epoch: 5| Step: 6
Training loss: 2.4157451209913487
Validation loss: 2.4924852837064666

Epoch: 5| Step: 7
Training loss: 2.5956643634826913
Validation loss: 2.4975186073480686

Epoch: 5| Step: 8
Training loss: 2.268086116117938
Validation loss: 2.4828444610676756

Epoch: 5| Step: 9
Training loss: 3.1399268138155967
Validation loss: 2.488913515129712

Epoch: 5| Step: 10
Training loss: 2.1684557668419813
Validation loss: 2.489901415936423

Epoch: 5| Step: 11
Training loss: 1.940522697074195
Validation loss: 2.4947671285124664

Epoch: 98| Step: 0
Training loss: 1.8715073799275195
Validation loss: 2.4895223639350044

Epoch: 5| Step: 1
Training loss: 2.671233696965908
Validation loss: 2.4914615315153283

Epoch: 5| Step: 2
Training loss: 2.6967972798381568
Validation loss: 2.4924800147068735

Epoch: 5| Step: 3
Training loss: 3.017126944678526
Validation loss: 2.4972208868067245

Epoch: 5| Step: 4
Training loss: 2.8152691242587085
Validation loss: 2.493555086369439

Epoch: 5| Step: 5
Training loss: 2.563384112916276
Validation loss: 2.48970371551168

Epoch: 5| Step: 6
Training loss: 2.676142446823584
Validation loss: 2.4959593305376955

Epoch: 5| Step: 7
Training loss: 2.449078374852351
Validation loss: 2.495815530234787

Epoch: 5| Step: 8
Training loss: 2.524570081010449
Validation loss: 2.4956505053068967

Epoch: 5| Step: 9
Training loss: 2.56476846166723
Validation loss: 2.4899050466147874

Epoch: 5| Step: 10
Training loss: 2.4812375777003273
Validation loss: 2.4986736315643223

Epoch: 5| Step: 11
Training loss: 3.7108846881521673
Validation loss: 2.495966275760397

Epoch: 99| Step: 0
Training loss: 2.7372614856785247
Validation loss: 2.4987016008252843

Epoch: 5| Step: 1
Training loss: 2.5885454839196003
Validation loss: 2.491151496699459

Epoch: 5| Step: 2
Training loss: 3.1410080405699845
Validation loss: 2.4941332047007805

Epoch: 5| Step: 3
Training loss: 2.9643308173210094
Validation loss: 2.496316230263353

Epoch: 5| Step: 4
Training loss: 2.665665219932597
Validation loss: 2.4981397741251654

Epoch: 5| Step: 5
Training loss: 2.2868249783149808
Validation loss: 2.4865204006823043

Epoch: 5| Step: 6
Training loss: 2.8958435790248904
Validation loss: 2.4908509292780807

Epoch: 5| Step: 7
Training loss: 2.422163226296737
Validation loss: 2.4887530459952636

Epoch: 5| Step: 8
Training loss: 2.4104723854405967
Validation loss: 2.4847986911667888

Epoch: 5| Step: 9
Training loss: 2.203794120740712
Validation loss: 2.4905592762544906

Epoch: 5| Step: 10
Training loss: 2.183957746872524
Validation loss: 2.4890612143852264

Epoch: 5| Step: 11
Training loss: 2.3518684669746537
Validation loss: 2.483786611237581

Epoch: 100| Step: 0
Training loss: 2.354735302961966
Validation loss: 2.4921985693738566

Epoch: 5| Step: 1
Training loss: 2.538373366516312
Validation loss: 2.501777934627003

Epoch: 5| Step: 2
Training loss: 2.8247233635142575
Validation loss: 2.55010859844111

Epoch: 5| Step: 3
Training loss: 3.3498275997153857
Validation loss: 2.5688611854226444

Epoch: 5| Step: 4
Training loss: 2.7361380860300115
Validation loss: 2.6124496695432637

Epoch: 5| Step: 5
Training loss: 2.563398715335833
Validation loss: 2.5961381496505584

Epoch: 5| Step: 6
Training loss: 2.721147992417348
Validation loss: 2.5386433768973036

Epoch: 5| Step: 7
Training loss: 2.7222781910840963
Validation loss: 2.5047926144784656

Epoch: 5| Step: 8
Training loss: 2.2768284000274126
Validation loss: 2.4870339685496985

Epoch: 5| Step: 9
Training loss: 2.733539388224559
Validation loss: 2.4947481423698012

Epoch: 5| Step: 10
Training loss: 2.5451585098997542
Validation loss: 2.493486199571722

Epoch: 5| Step: 11
Training loss: 2.8792224229050247
Validation loss: 2.495173595609526

Testing loss: 2.062876280945489
