Epoch: 1| Step: 0
Training loss: 5.363823413848877
Validation loss: 5.300411383310954

Epoch: 6| Step: 1
Training loss: 5.912297248840332
Validation loss: 5.298979918162028

Epoch: 6| Step: 2
Training loss: 4.904858112335205
Validation loss: 5.297555605570476

Epoch: 6| Step: 3
Training loss: 6.421828269958496
Validation loss: 5.296151876449585

Epoch: 6| Step: 4
Training loss: 5.064277648925781
Validation loss: 5.294762214024861

Epoch: 6| Step: 5
Training loss: 3.594466209411621
Validation loss: 5.2933932940165205

Epoch: 6| Step: 6
Training loss: 4.850874423980713
Validation loss: 5.291955550511678

Epoch: 6| Step: 7
Training loss: 4.435810565948486
Validation loss: 5.290647268295288

Epoch: 6| Step: 8
Training loss: 6.494996547698975
Validation loss: 5.2891989549001055

Epoch: 6| Step: 9
Training loss: 6.676028251647949
Validation loss: 5.287767251332601

Epoch: 6| Step: 10
Training loss: 4.620267868041992
Validation loss: 5.286245981852214

Epoch: 6| Step: 11
Training loss: 5.008981704711914
Validation loss: 5.28470245997111

Epoch: 6| Step: 12
Training loss: 6.220698833465576
Validation loss: 5.283109823862712

Epoch: 6| Step: 13
Training loss: 5.477333068847656
Validation loss: 5.281499624252319

Epoch: 2| Step: 0
Training loss: 5.856302738189697
Validation loss: 5.279735167821248

Epoch: 6| Step: 1
Training loss: 5.001679420471191
Validation loss: 5.277983029683431

Epoch: 6| Step: 2
Training loss: 5.026695251464844
Validation loss: 5.275995413462321

Epoch: 6| Step: 3
Training loss: 5.254053592681885
Validation loss: 5.274057626724243

Epoch: 6| Step: 4
Training loss: 4.965644359588623
Validation loss: 5.271939277648926

Epoch: 6| Step: 5
Training loss: 4.810359001159668
Validation loss: 5.269766251246135

Epoch: 6| Step: 6
Training loss: 5.848064422607422
Validation loss: 5.267450412114461

Epoch: 6| Step: 7
Training loss: 4.694989204406738
Validation loss: 5.265011390050252

Epoch: 6| Step: 8
Training loss: 5.81374454498291
Validation loss: 5.262475967407227

Epoch: 6| Step: 9
Training loss: 4.203608512878418
Validation loss: 5.259925762812297

Epoch: 6| Step: 10
Training loss: 6.21498441696167
Validation loss: 5.2570531368255615

Epoch: 6| Step: 11
Training loss: 5.4542951583862305
Validation loss: 5.254015525182088

Epoch: 6| Step: 12
Training loss: 5.542111396789551
Validation loss: 5.250921328862508

Epoch: 6| Step: 13
Training loss: 5.99385929107666
Validation loss: 5.2475394407908125

Epoch: 3| Step: 0
Training loss: 4.969264507293701
Validation loss: 5.244024912516276

Epoch: 6| Step: 1
Training loss: 5.421224594116211
Validation loss: 5.240313291549683

Epoch: 6| Step: 2
Training loss: 4.800568580627441
Validation loss: 5.236298322677612

Epoch: 6| Step: 3
Training loss: 5.438104152679443
Validation loss: 5.231999397277832

Epoch: 6| Step: 4
Training loss: 5.154449939727783
Validation loss: 5.227584044138591

Epoch: 6| Step: 5
Training loss: 4.247309684753418
Validation loss: 5.22288711865743

Epoch: 6| Step: 6
Training loss: 5.370763778686523
Validation loss: 5.21783185005188

Epoch: 6| Step: 7
Training loss: 5.388829231262207
Validation loss: 5.212519804636638

Epoch: 6| Step: 8
Training loss: 5.518505096435547
Validation loss: 5.206879059473674

Epoch: 6| Step: 9
Training loss: 5.752252101898193
Validation loss: 5.201065301895142

Epoch: 6| Step: 10
Training loss: 5.995996475219727
Validation loss: 5.195166667302449

Epoch: 6| Step: 11
Training loss: 5.301559925079346
Validation loss: 5.188817183176677

Epoch: 6| Step: 12
Training loss: 3.9838428497314453
Validation loss: 5.182161728541057

Epoch: 6| Step: 13
Training loss: 6.620387077331543
Validation loss: 5.174877484639485

Epoch: 4| Step: 0
Training loss: 5.1429643630981445
Validation loss: 5.167829354604085

Epoch: 6| Step: 1
Training loss: 4.859500885009766
Validation loss: 5.159844477971395

Epoch: 6| Step: 2
Training loss: 4.997367858886719
Validation loss: 5.151815414428711

Epoch: 6| Step: 3
Training loss: 5.006572723388672
Validation loss: 5.143827597300212

Epoch: 6| Step: 4
Training loss: 5.000520706176758
Validation loss: 5.135226209958394

Epoch: 6| Step: 5
Training loss: 3.9365971088409424
Validation loss: 5.126431306203206

Epoch: 6| Step: 6
Training loss: 6.40883731842041
Validation loss: 5.117381413777669

Epoch: 6| Step: 7
Training loss: 5.197144985198975
Validation loss: 5.108426014582316

Epoch: 6| Step: 8
Training loss: 5.444279193878174
Validation loss: 5.098753174146016

Epoch: 6| Step: 9
Training loss: 4.909236431121826
Validation loss: 5.089130640029907

Epoch: 6| Step: 10
Training loss: 5.97774076461792
Validation loss: 5.079797744750977

Epoch: 6| Step: 11
Training loss: 5.950118064880371
Validation loss: 5.069968303044637

Epoch: 6| Step: 12
Training loss: 5.296669960021973
Validation loss: 5.060057322184245

Epoch: 6| Step: 13
Training loss: 4.459230422973633
Validation loss: 5.049937566121419

Epoch: 5| Step: 0
Training loss: 4.9286417961120605
Validation loss: 5.040087461471558

Epoch: 6| Step: 1
Training loss: 4.9422101974487305
Validation loss: 5.030035018920898

Epoch: 6| Step: 2
Training loss: 5.557646751403809
Validation loss: 5.01996390024821

Epoch: 6| Step: 3
Training loss: 5.775967121124268
Validation loss: 5.010200182596843

Epoch: 6| Step: 4
Training loss: 4.785003185272217
Validation loss: 5.000353177388509

Epoch: 6| Step: 5
Training loss: 4.0322771072387695
Validation loss: 4.9903349081675215

Epoch: 6| Step: 6
Training loss: 4.9398345947265625
Validation loss: 4.9802470207214355

Epoch: 6| Step: 7
Training loss: 6.099993705749512
Validation loss: 4.970862785975139

Epoch: 6| Step: 8
Training loss: 5.252659797668457
Validation loss: 4.961055755615234

Epoch: 6| Step: 9
Training loss: 4.44744873046875
Validation loss: 4.951516270637512

Epoch: 6| Step: 10
Training loss: 5.646957874298096
Validation loss: 4.94214940071106

Epoch: 6| Step: 11
Training loss: 4.340673446655273
Validation loss: 4.932865381240845

Epoch: 6| Step: 12
Training loss: 4.910771369934082
Validation loss: 4.923855900764465

Epoch: 6| Step: 13
Training loss: 5.1437578201293945
Validation loss: 4.915257374445598

Epoch: 6| Step: 0
Training loss: 5.004624366760254
Validation loss: 4.906401713689168

Epoch: 6| Step: 1
Training loss: 5.026524543762207
Validation loss: 4.898414770762126

Epoch: 6| Step: 2
Training loss: 4.629331588745117
Validation loss: 4.890246351559957

Epoch: 6| Step: 3
Training loss: 4.838163375854492
Validation loss: 4.882668495178223

Epoch: 6| Step: 4
Training loss: 5.683597564697266
Validation loss: 4.875370184580485

Epoch: 6| Step: 5
Training loss: 4.583252906799316
Validation loss: 4.868245959281921

Epoch: 6| Step: 6
Training loss: 4.5860795974731445
Validation loss: 4.861002763112386

Epoch: 6| Step: 7
Training loss: 4.694919586181641
Validation loss: 4.853813409805298

Epoch: 6| Step: 8
Training loss: 5.296801567077637
Validation loss: 4.847179174423218

Epoch: 6| Step: 9
Training loss: 4.243785858154297
Validation loss: 4.840421199798584

Epoch: 6| Step: 10
Training loss: 6.032393932342529
Validation loss: 4.833754142125447

Epoch: 6| Step: 11
Training loss: 4.046727180480957
Validation loss: 4.827108065287272

Epoch: 6| Step: 12
Training loss: 5.644916534423828
Validation loss: 4.821234424908956

Epoch: 6| Step: 13
Training loss: 4.900285720825195
Validation loss: 4.814454992612203

Epoch: 7| Step: 0
Training loss: 4.848981857299805
Validation loss: 4.808510820070903

Epoch: 6| Step: 1
Training loss: 3.577266216278076
Validation loss: 4.802167296409607

Epoch: 6| Step: 2
Training loss: 5.485995292663574
Validation loss: 4.796163320541382

Epoch: 6| Step: 3
Training loss: 5.645220756530762
Validation loss: 4.790024717648824

Epoch: 6| Step: 4
Training loss: 6.236018180847168
Validation loss: 4.784081776936849

Epoch: 6| Step: 5
Training loss: 4.630128383636475
Validation loss: 4.777765830357869

Epoch: 6| Step: 6
Training loss: 5.133904457092285
Validation loss: 4.771508773167928

Epoch: 6| Step: 7
Training loss: 4.9127116203308105
Validation loss: 4.765280246734619

Epoch: 6| Step: 8
Training loss: 4.97048282623291
Validation loss: 4.7589900096257525

Epoch: 6| Step: 9
Training loss: 3.841453790664673
Validation loss: 4.752653042475383

Epoch: 6| Step: 10
Training loss: 5.066459655761719
Validation loss: 4.746942679087321

Epoch: 6| Step: 11
Training loss: 4.412123680114746
Validation loss: 4.741393605868022

Epoch: 6| Step: 12
Training loss: 4.655384540557861
Validation loss: 4.735716740290324

Epoch: 6| Step: 13
Training loss: 4.634357929229736
Validation loss: 4.730477889378865

Epoch: 8| Step: 0
Training loss: 5.025191307067871
Validation loss: 4.72470235824585

Epoch: 6| Step: 1
Training loss: 5.261833190917969
Validation loss: 4.719399372736613

Epoch: 6| Step: 2
Training loss: 3.5199387073516846
Validation loss: 4.714293638865153

Epoch: 6| Step: 3
Training loss: 5.139538764953613
Validation loss: 4.708995421727498

Epoch: 6| Step: 4
Training loss: 4.406811714172363
Validation loss: 4.704022566477458

Epoch: 6| Step: 5
Training loss: 6.089668273925781
Validation loss: 4.698774814605713

Epoch: 6| Step: 6
Training loss: 5.786153316497803
Validation loss: 4.693620840708415

Epoch: 6| Step: 7
Training loss: 3.850344657897949
Validation loss: 4.687860329945882

Epoch: 6| Step: 8
Training loss: 5.465902328491211
Validation loss: 4.682901859283447

Epoch: 6| Step: 9
Training loss: 6.008150100708008
Validation loss: 4.677578369776408

Epoch: 6| Step: 10
Training loss: 4.398385047912598
Validation loss: 4.672226786613464

Epoch: 6| Step: 11
Training loss: 4.797623157501221
Validation loss: 4.6667875448862715

Epoch: 6| Step: 12
Training loss: 4.162193298339844
Validation loss: 4.661574284235637

Epoch: 6| Step: 13
Training loss: 3.0762226581573486
Validation loss: 4.655428806940715

Epoch: 9| Step: 0
Training loss: 3.843606948852539
Validation loss: 4.650386095046997

Epoch: 6| Step: 1
Training loss: 4.932665824890137
Validation loss: 4.644727071126302

Epoch: 6| Step: 2
Training loss: 4.252110958099365
Validation loss: 4.639154990514119

Epoch: 6| Step: 3
Training loss: 4.2596588134765625
Validation loss: 4.633918642997742

Epoch: 6| Step: 4
Training loss: 4.930159091949463
Validation loss: 4.628190358479817

Epoch: 6| Step: 5
Training loss: 4.092900276184082
Validation loss: 4.6226151784261065

Epoch: 6| Step: 6
Training loss: 5.368163108825684
Validation loss: 4.617040753364563

Epoch: 6| Step: 7
Training loss: 5.701674461364746
Validation loss: 4.611575762430827

Epoch: 6| Step: 8
Training loss: 4.691583633422852
Validation loss: 4.606279929478963

Epoch: 6| Step: 9
Training loss: 4.8315958976745605
Validation loss: 4.6009795268376665

Epoch: 6| Step: 10
Training loss: 5.575546741485596
Validation loss: 4.595046162605286

Epoch: 6| Step: 11
Training loss: 5.172679901123047
Validation loss: 4.589523394902547

Epoch: 6| Step: 12
Training loss: 4.443478584289551
Validation loss: 4.583500385284424

Epoch: 6| Step: 13
Training loss: 3.8718981742858887
Validation loss: 4.577592293421428

Epoch: 10| Step: 0
Training loss: 5.733428001403809
Validation loss: 4.570690910021464

Epoch: 6| Step: 1
Training loss: 5.060185432434082
Validation loss: 4.5646053949991865

Epoch: 6| Step: 2
Training loss: 4.4417524337768555
Validation loss: 4.558436354001363

Epoch: 6| Step: 3
Training loss: 5.090310096740723
Validation loss: 4.551550308863322

Epoch: 6| Step: 4
Training loss: 5.311282157897949
Validation loss: 4.544964631398519

Epoch: 6| Step: 5
Training loss: 4.581142902374268
Validation loss: 4.538026332855225

Epoch: 6| Step: 6
Training loss: 3.8736393451690674
Validation loss: 4.531285881996155

Epoch: 6| Step: 7
Training loss: 4.2209601402282715
Validation loss: 4.524643182754517

Epoch: 6| Step: 8
Training loss: 5.035141944885254
Validation loss: 4.51820707321167

Epoch: 6| Step: 9
Training loss: 5.469783306121826
Validation loss: 4.511870503425598

Epoch: 6| Step: 10
Training loss: 4.57140588760376
Validation loss: 4.504812995592753

Epoch: 6| Step: 11
Training loss: 3.6667370796203613
Validation loss: 4.497579018274943

Epoch: 6| Step: 12
Training loss: 3.155759811401367
Validation loss: 4.49125878016154

Epoch: 6| Step: 13
Training loss: 4.6369829177856445
Validation loss: 4.484417915344238

Epoch: 11| Step: 0
Training loss: 4.29911470413208
Validation loss: 4.476923545201619

Epoch: 6| Step: 1
Training loss: 5.10185432434082
Validation loss: 4.471008857091268

Epoch: 6| Step: 2
Training loss: 4.446045398712158
Validation loss: 4.464542110761006

Epoch: 6| Step: 3
Training loss: 4.4865312576293945
Validation loss: 4.457655668258667

Epoch: 6| Step: 4
Training loss: 4.2671098709106445
Validation loss: 4.451296369234721

Epoch: 6| Step: 5
Training loss: 3.451569080352783
Validation loss: 4.444740414619446

Epoch: 6| Step: 6
Training loss: 4.801955223083496
Validation loss: 4.43807319800059

Epoch: 6| Step: 7
Training loss: 5.543627738952637
Validation loss: 4.431619127591451

Epoch: 6| Step: 8
Training loss: 3.860694408416748
Validation loss: 4.425125201543172

Epoch: 6| Step: 9
Training loss: 5.013904571533203
Validation loss: 4.418381651242574

Epoch: 6| Step: 10
Training loss: 4.650087356567383
Validation loss: 4.411724328994751

Epoch: 6| Step: 11
Training loss: 4.496688365936279
Validation loss: 4.4052650928497314

Epoch: 6| Step: 12
Training loss: 4.468402862548828
Validation loss: 4.39873480796814

Epoch: 6| Step: 13
Training loss: 4.777661323547363
Validation loss: 4.392933646837871

Epoch: 12| Step: 0
Training loss: 3.5440337657928467
Validation loss: 4.387108325958252

Epoch: 6| Step: 1
Training loss: 4.978797435760498
Validation loss: 4.381255467732747

Epoch: 6| Step: 2
Training loss: 4.923183441162109
Validation loss: 4.375357309977214

Epoch: 6| Step: 3
Training loss: 4.592518329620361
Validation loss: 4.369246045748393

Epoch: 6| Step: 4
Training loss: 4.420988082885742
Validation loss: 4.364082415898641

Epoch: 6| Step: 5
Training loss: 4.48082160949707
Validation loss: 4.358207265535991

Epoch: 6| Step: 6
Training loss: 3.5925331115722656
Validation loss: 4.352030952771504

Epoch: 6| Step: 7
Training loss: 5.082426071166992
Validation loss: 4.345621109008789

Epoch: 6| Step: 8
Training loss: 4.166971206665039
Validation loss: 4.34021790822347

Epoch: 6| Step: 9
Training loss: 3.9745569229125977
Validation loss: 4.334833264350891

Epoch: 6| Step: 10
Training loss: 4.839605808258057
Validation loss: 4.3289854526519775

Epoch: 6| Step: 11
Training loss: 5.499759197235107
Validation loss: 4.323349714279175

Epoch: 6| Step: 12
Training loss: 4.424002647399902
Validation loss: 4.317559639612834

Epoch: 6| Step: 13
Training loss: 4.052520751953125
Validation loss: 4.312003413836162

Epoch: 13| Step: 0
Training loss: 4.478344440460205
Validation loss: 4.306111176808675

Epoch: 6| Step: 1
Training loss: 4.523531436920166
Validation loss: 4.3009620904922485

Epoch: 6| Step: 2
Training loss: 4.598564147949219
Validation loss: 4.294847011566162

Epoch: 6| Step: 3
Training loss: 3.6411612033843994
Validation loss: 4.2888375123341875

Epoch: 6| Step: 4
Training loss: 4.367917060852051
Validation loss: 4.283063451449077

Epoch: 6| Step: 5
Training loss: 4.558686256408691
Validation loss: 4.2769425710042315

Epoch: 6| Step: 6
Training loss: 4.280457496643066
Validation loss: 4.271624843279521

Epoch: 6| Step: 7
Training loss: 4.174507141113281
Validation loss: 4.2667763233184814

Epoch: 6| Step: 8
Training loss: 4.28892183303833
Validation loss: 4.261321067810059

Epoch: 6| Step: 9
Training loss: 5.04902982711792
Validation loss: 4.255844434102376

Epoch: 6| Step: 10
Training loss: 3.955439567565918
Validation loss: 4.249066392580668

Epoch: 6| Step: 11
Training loss: 4.922165870666504
Validation loss: 4.243265151977539

Epoch: 6| Step: 12
Training loss: 3.8539934158325195
Validation loss: 4.23845100402832

Epoch: 6| Step: 13
Training loss: 4.871615409851074
Validation loss: 4.232727726300557

Epoch: 14| Step: 0
Training loss: 4.8208112716674805
Validation loss: 4.227056384086609

Epoch: 6| Step: 1
Training loss: 4.161228179931641
Validation loss: 4.221825321515401

Epoch: 6| Step: 2
Training loss: 5.11513090133667
Validation loss: 4.2159585158030195

Epoch: 6| Step: 3
Training loss: 4.036838531494141
Validation loss: 4.210308829943339

Epoch: 6| Step: 4
Training loss: 4.443967819213867
Validation loss: 4.205614964167277

Epoch: 6| Step: 5
Training loss: 5.164648056030273
Validation loss: 4.199432571729024

Epoch: 6| Step: 6
Training loss: 3.7221975326538086
Validation loss: 4.193269332249959

Epoch: 6| Step: 7
Training loss: 4.427709579467773
Validation loss: 4.187872767448425

Epoch: 6| Step: 8
Training loss: 3.25727915763855
Validation loss: 4.181889335314433

Epoch: 6| Step: 9
Training loss: 3.9480502605438232
Validation loss: 4.177115360895793

Epoch: 6| Step: 10
Training loss: 4.41942834854126
Validation loss: 4.172281583150228

Epoch: 6| Step: 11
Training loss: 5.031336784362793
Validation loss: 4.165284156799316

Epoch: 6| Step: 12
Training loss: 3.4177114963531494
Validation loss: 4.160133322079976

Epoch: 6| Step: 13
Training loss: 4.59696626663208
Validation loss: 4.155720472335815

Epoch: 15| Step: 0
Training loss: 3.836308002471924
Validation loss: 4.150990843772888

Epoch: 6| Step: 1
Training loss: 4.877447605133057
Validation loss: 4.144578735033671

Epoch: 6| Step: 2
Training loss: 3.5792250633239746
Validation loss: 4.138728221257527

Epoch: 6| Step: 3
Training loss: 4.0079216957092285
Validation loss: 4.133310556411743

Epoch: 6| Step: 4
Training loss: 5.045845031738281
Validation loss: 4.128148158391316

Epoch: 6| Step: 5
Training loss: 4.061944007873535
Validation loss: 4.1235671043396

Epoch: 6| Step: 6
Training loss: 3.8828229904174805
Validation loss: 4.1179585456848145

Epoch: 6| Step: 7
Training loss: 4.856655597686768
Validation loss: 4.113056659698486

Epoch: 6| Step: 8
Training loss: 3.4886770248413086
Validation loss: 4.106753985087077

Epoch: 6| Step: 9
Training loss: 4.210367202758789
Validation loss: 4.10107700030009

Epoch: 6| Step: 10
Training loss: 4.0121588706970215
Validation loss: 4.095677137374878

Epoch: 6| Step: 11
Training loss: 4.783174514770508
Validation loss: 4.090621789296468

Epoch: 6| Step: 12
Training loss: 4.296329975128174
Validation loss: 4.084074139595032

Epoch: 6| Step: 13
Training loss: 4.619534969329834
Validation loss: 4.078865925470988

Epoch: 16| Step: 0
Training loss: 4.469817161560059
Validation loss: 4.073484381039937

Epoch: 6| Step: 1
Training loss: 4.26075553894043
Validation loss: 4.0671550035476685

Epoch: 6| Step: 2
Training loss: 4.202564239501953
Validation loss: 4.062323331832886

Epoch: 6| Step: 3
Training loss: 4.97824239730835
Validation loss: 4.0571407079696655

Epoch: 6| Step: 4
Training loss: 4.368740558624268
Validation loss: 4.0519092082977295

Epoch: 6| Step: 5
Training loss: 3.4082326889038086
Validation loss: 4.046560287475586

Epoch: 6| Step: 6
Training loss: 4.077282905578613
Validation loss: 4.040154774983724

Epoch: 6| Step: 7
Training loss: 4.415682792663574
Validation loss: 4.034745415051778

Epoch: 6| Step: 8
Training loss: 4.067987442016602
Validation loss: 4.02918295065562

Epoch: 6| Step: 9
Training loss: 4.759990692138672
Validation loss: 4.02418573697408

Epoch: 6| Step: 10
Training loss: 4.400418281555176
Validation loss: 4.017947276433309

Epoch: 6| Step: 11
Training loss: 4.537689208984375
Validation loss: 4.013563275337219

Epoch: 6| Step: 12
Training loss: 2.7998008728027344
Validation loss: 4.007047812143962

Epoch: 6| Step: 13
Training loss: 3.7952239513397217
Validation loss: 4.001988569895427

Epoch: 17| Step: 0
Training loss: 3.8316242694854736
Validation loss: 3.9969037771224976

Epoch: 6| Step: 1
Training loss: 3.549283027648926
Validation loss: 3.9909090995788574

Epoch: 6| Step: 2
Training loss: 3.243025779724121
Validation loss: 3.9855149189631143

Epoch: 6| Step: 3
Training loss: 3.9911792278289795
Validation loss: 3.9806864261627197

Epoch: 6| Step: 4
Training loss: 4.837919235229492
Validation loss: 3.9752422173817954

Epoch: 6| Step: 5
Training loss: 4.5681867599487305
Validation loss: 3.9710034132003784

Epoch: 6| Step: 6
Training loss: 4.169063568115234
Validation loss: 3.965873678525289

Epoch: 6| Step: 7
Training loss: 4.812963008880615
Validation loss: 3.959754149119059

Epoch: 6| Step: 8
Training loss: 3.3216428756713867
Validation loss: 3.9548281033833823

Epoch: 6| Step: 9
Training loss: 3.9886515140533447
Validation loss: 3.9507455031077066

Epoch: 6| Step: 10
Training loss: 3.963425397872925
Validation loss: 3.9433993895848594

Epoch: 6| Step: 11
Training loss: 4.871982574462891
Validation loss: 3.9376277128855386

Epoch: 6| Step: 12
Training loss: 4.081831455230713
Validation loss: 3.9321926832199097

Epoch: 6| Step: 13
Training loss: 4.3085103034973145
Validation loss: 3.9290130933125815

Epoch: 18| Step: 0
Training loss: 3.8087430000305176
Validation loss: 3.9233138958613076

Epoch: 6| Step: 1
Training loss: 3.996190071105957
Validation loss: 3.917043844858805

Epoch: 6| Step: 2
Training loss: 4.088136672973633
Validation loss: 3.911888599395752

Epoch: 6| Step: 3
Training loss: 3.973865509033203
Validation loss: 3.9058556954065957

Epoch: 6| Step: 4
Training loss: 4.038368225097656
Validation loss: 3.902339140574137

Epoch: 6| Step: 5
Training loss: 4.34638786315918
Validation loss: 3.894866704940796

Epoch: 6| Step: 6
Training loss: 3.799783706665039
Validation loss: 3.890154401461283

Epoch: 6| Step: 7
Training loss: 4.319637298583984
Validation loss: 3.8871572017669678

Epoch: 6| Step: 8
Training loss: 4.567663192749023
Validation loss: 3.881158788998922

Epoch: 6| Step: 9
Training loss: 3.2592155933380127
Validation loss: 3.87412957350413

Epoch: 6| Step: 10
Training loss: 3.85272216796875
Validation loss: 3.868899385134379

Epoch: 6| Step: 11
Training loss: 4.476302623748779
Validation loss: 3.86523699760437

Epoch: 6| Step: 12
Training loss: 3.536285400390625
Validation loss: 3.858921766281128

Epoch: 6| Step: 13
Training loss: 4.489060401916504
Validation loss: 3.853515625

Epoch: 19| Step: 0
Training loss: 4.054257869720459
Validation loss: 3.847532033920288

Epoch: 6| Step: 1
Training loss: 4.468025207519531
Validation loss: 3.843729615211487

Epoch: 6| Step: 2
Training loss: 4.1611199378967285
Validation loss: 3.8389810721079507

Epoch: 6| Step: 3
Training loss: 3.1432695388793945
Validation loss: 3.8323368231455484

Epoch: 6| Step: 4
Training loss: 3.4256081581115723
Validation loss: 3.8264511823654175

Epoch: 6| Step: 5
Training loss: 4.298547267913818
Validation loss: 3.8221576611200967

Epoch: 6| Step: 6
Training loss: 4.329687118530273
Validation loss: 3.81555438041687

Epoch: 6| Step: 7
Training loss: 4.321981906890869
Validation loss: 3.81142258644104

Epoch: 6| Step: 8
Training loss: 3.5757405757904053
Validation loss: 3.807203769683838

Epoch: 6| Step: 9
Training loss: 3.4092960357666016
Validation loss: 3.8006279865900674

Epoch: 6| Step: 10
Training loss: 3.9179863929748535
Validation loss: 3.7949033975601196

Epoch: 6| Step: 11
Training loss: 4.601091384887695
Validation loss: 3.7899688482284546

Epoch: 6| Step: 12
Training loss: 3.8595809936523438
Validation loss: 3.7850895722707114

Epoch: 6| Step: 13
Training loss: 4.021466255187988
Validation loss: 3.7810835043589273

Epoch: 20| Step: 0
Training loss: 3.2217392921447754
Validation loss: 3.7759732802708945

Epoch: 6| Step: 1
Training loss: 3.71645188331604
Validation loss: 3.7711660464604697

Epoch: 6| Step: 2
Training loss: 4.878203868865967
Validation loss: 3.765749454498291

Epoch: 6| Step: 3
Training loss: 4.221912384033203
Validation loss: 3.761499563852946

Epoch: 6| Step: 4
Training loss: 2.77286958694458
Validation loss: 3.7556320826212564

Epoch: 6| Step: 5
Training loss: 2.729915142059326
Validation loss: 3.7509108781814575

Epoch: 6| Step: 6
Training loss: 4.687216281890869
Validation loss: 3.7459256649017334

Epoch: 6| Step: 7
Training loss: 4.62244987487793
Validation loss: 3.741142988204956

Epoch: 6| Step: 8
Training loss: 3.9107818603515625
Validation loss: 3.7364577054977417

Epoch: 6| Step: 9
Training loss: 4.171051979064941
Validation loss: 3.7313973108927407

Epoch: 6| Step: 10
Training loss: 3.5316643714904785
Validation loss: 3.727076013882955

Epoch: 6| Step: 11
Training loss: 3.2332663536071777
Validation loss: 3.7228833039601645

Epoch: 6| Step: 12
Training loss: 4.667239189147949
Validation loss: 3.7162022988001504

Epoch: 6| Step: 13
Training loss: 4.288421630859375
Validation loss: 3.7127989133199057

Epoch: 21| Step: 0
Training loss: 4.1161909103393555
Validation loss: 3.7086907625198364

Epoch: 6| Step: 1
Training loss: 3.5066418647766113
Validation loss: 3.704535404841105

Epoch: 6| Step: 2
Training loss: 4.076143264770508
Validation loss: 3.699474334716797

Epoch: 6| Step: 3
Training loss: 4.15346097946167
Validation loss: 3.6942987044652305

Epoch: 6| Step: 4
Training loss: 3.176025867462158
Validation loss: 3.6893479426701865

Epoch: 6| Step: 5
Training loss: 4.856204986572266
Validation loss: 3.684683402379354

Epoch: 6| Step: 6
Training loss: 3.567638635635376
Validation loss: 3.6803680260976157

Epoch: 6| Step: 7
Training loss: 3.0985357761383057
Validation loss: 3.6760061184565225

Epoch: 6| Step: 8
Training loss: 3.169217824935913
Validation loss: 3.671818256378174

Epoch: 6| Step: 9
Training loss: 4.02451229095459
Validation loss: 3.666163166364034

Epoch: 6| Step: 10
Training loss: 3.855983257293701
Validation loss: 3.6611785888671875

Epoch: 6| Step: 11
Training loss: 3.094667434692383
Validation loss: 3.656361977259318

Epoch: 6| Step: 12
Training loss: 4.710990905761719
Validation loss: 3.6528337001800537

Epoch: 6| Step: 13
Training loss: 4.347197532653809
Validation loss: 3.649405360221863

Epoch: 22| Step: 0
Training loss: 4.645051002502441
Validation loss: 3.643260876337687

Epoch: 6| Step: 1
Training loss: 3.574479579925537
Validation loss: 3.6372066338857016

Epoch: 6| Step: 2
Training loss: 3.075183868408203
Validation loss: 3.6332798401514688

Epoch: 6| Step: 3
Training loss: 2.6495823860168457
Validation loss: 3.6312333742777505

Epoch: 6| Step: 4
Training loss: 3.7914061546325684
Validation loss: 3.62577486038208

Epoch: 6| Step: 5
Training loss: 4.352433204650879
Validation loss: 3.618042985598246

Epoch: 6| Step: 6
Training loss: 3.6680920124053955
Validation loss: 3.615025043487549

Epoch: 6| Step: 7
Training loss: 3.5524418354034424
Validation loss: 3.6118558247884116

Epoch: 6| Step: 8
Training loss: 4.3845672607421875
Validation loss: 3.607999245325724

Epoch: 6| Step: 9
Training loss: 3.829310178756714
Validation loss: 3.602394421895345

Epoch: 6| Step: 10
Training loss: 3.756892204284668
Validation loss: 3.5960614681243896

Epoch: 6| Step: 11
Training loss: 4.208215236663818
Validation loss: 3.591063976287842

Epoch: 6| Step: 12
Training loss: 3.833961009979248
Validation loss: 3.585304339726766

Epoch: 6| Step: 13
Training loss: 3.5426700115203857
Validation loss: 3.5812179247538247

Epoch: 23| Step: 0
Training loss: 2.858443260192871
Validation loss: 3.576482057571411

Epoch: 6| Step: 1
Training loss: 3.938756227493286
Validation loss: 3.572235663731893

Epoch: 6| Step: 2
Training loss: 4.149022102355957
Validation loss: 3.5671382347742715

Epoch: 6| Step: 3
Training loss: 2.9064278602600098
Validation loss: 3.5622658729553223

Epoch: 6| Step: 4
Training loss: 4.104012489318848
Validation loss: 3.5584741830825806

Epoch: 6| Step: 5
Training loss: 3.707017421722412
Validation loss: 3.5535523891448975

Epoch: 6| Step: 6
Training loss: 3.2265048027038574
Validation loss: 3.5493045250574746

Epoch: 6| Step: 7
Training loss: 3.524600028991699
Validation loss: 3.544498324394226

Epoch: 6| Step: 8
Training loss: 3.2763519287109375
Validation loss: 3.5388192335764566

Epoch: 6| Step: 9
Training loss: 3.4277350902557373
Validation loss: 3.5336193243662515

Epoch: 6| Step: 10
Training loss: 4.852531909942627
Validation loss: 3.529104153315226

Epoch: 6| Step: 11
Training loss: 4.047285079956055
Validation loss: 3.5253771940867105

Epoch: 6| Step: 12
Training loss: 3.7455215454101562
Validation loss: 3.5211400985717773

Epoch: 6| Step: 13
Training loss: 4.168801307678223
Validation loss: 3.5165031353632608

Epoch: 24| Step: 0
Training loss: 4.675450325012207
Validation loss: 3.5110853910446167

Epoch: 6| Step: 1
Training loss: 1.9646679162979126
Validation loss: 3.505699872970581

Epoch: 6| Step: 2
Training loss: 4.058771133422852
Validation loss: 3.5004172325134277

Epoch: 6| Step: 3
Training loss: 4.093895435333252
Validation loss: 3.495069702466329

Epoch: 6| Step: 4
Training loss: 4.461568832397461
Validation loss: 3.4895215034484863

Epoch: 6| Step: 5
Training loss: 2.6296610832214355
Validation loss: 3.4849201440811157

Epoch: 6| Step: 6
Training loss: 3.9220118522644043
Validation loss: 3.480077107747396

Epoch: 6| Step: 7
Training loss: 3.3756256103515625
Validation loss: 3.4750752449035645

Epoch: 6| Step: 8
Training loss: 4.0898118019104
Validation loss: 3.470615784327189

Epoch: 6| Step: 9
Training loss: 3.401266574859619
Validation loss: 3.4652849038441977

Epoch: 6| Step: 10
Training loss: 3.4799206256866455
Validation loss: 3.4606182177861533

Epoch: 6| Step: 11
Training loss: 3.810673236846924
Validation loss: 3.4568798939387

Epoch: 6| Step: 12
Training loss: 3.4486947059631348
Validation loss: 3.4509796301523843

Epoch: 6| Step: 13
Training loss: 3.6224613189697266
Validation loss: 3.445956826210022

Epoch: 25| Step: 0
Training loss: 3.5445213317871094
Validation loss: 3.442253669102987

Epoch: 6| Step: 1
Training loss: 2.607109785079956
Validation loss: 3.436939795811971

Epoch: 6| Step: 2
Training loss: 3.503901243209839
Validation loss: 3.43346377213796

Epoch: 6| Step: 3
Training loss: 3.7511208057403564
Validation loss: 3.428968826929728

Epoch: 6| Step: 4
Training loss: 2.5498342514038086
Validation loss: 3.423856774965922

Epoch: 6| Step: 5
Training loss: 4.559586524963379
Validation loss: 3.419151782989502

Epoch: 6| Step: 6
Training loss: 3.311800241470337
Validation loss: 3.415373762448629

Epoch: 6| Step: 7
Training loss: 3.041779041290283
Validation loss: 3.4107932647069297

Epoch: 6| Step: 8
Training loss: 4.0979204177856445
Validation loss: 3.406013290087382

Epoch: 6| Step: 9
Training loss: 3.4256229400634766
Validation loss: 3.401474038759867

Epoch: 6| Step: 10
Training loss: 3.6919360160827637
Validation loss: 3.396546165148417

Epoch: 6| Step: 11
Training loss: 3.9815633296966553
Validation loss: 3.3919396003087363

Epoch: 6| Step: 12
Training loss: 4.317535877227783
Validation loss: 3.3872197469075522

Epoch: 6| Step: 13
Training loss: 3.751206874847412
Validation loss: 3.382742444674174

Epoch: 26| Step: 0
Training loss: 3.840449333190918
Validation loss: 3.3779062032699585

Epoch: 6| Step: 1
Training loss: 3.449429512023926
Validation loss: 3.3742884397506714

Epoch: 6| Step: 2
Training loss: 3.4513485431671143
Validation loss: 3.3698524236679077

Epoch: 6| Step: 3
Training loss: 3.648056745529175
Validation loss: 3.365357836087545

Epoch: 6| Step: 4
Training loss: 3.1986355781555176
Validation loss: 3.3605712254842124

Epoch: 6| Step: 5
Training loss: 3.4383397102355957
Validation loss: 3.356682459513346

Epoch: 6| Step: 6
Training loss: 3.5393424034118652
Validation loss: 3.3517722686131797

Epoch: 6| Step: 7
Training loss: 2.9408278465270996
Validation loss: 3.34794811407725

Epoch: 6| Step: 8
Training loss: 3.4744200706481934
Validation loss: 3.343890150388082

Epoch: 6| Step: 9
Training loss: 3.3030598163604736
Validation loss: 3.3393128712972007

Epoch: 6| Step: 10
Training loss: 3.1123666763305664
Validation loss: 3.3351553678512573

Epoch: 6| Step: 11
Training loss: 4.238544464111328
Validation loss: 3.3309626976648965

Epoch: 6| Step: 12
Training loss: 4.206048011779785
Validation loss: 3.3261186281840005

Epoch: 6| Step: 13
Training loss: 3.4531095027923584
Validation loss: 3.3217363754908242

Epoch: 27| Step: 0
Training loss: 5.037598609924316
Validation loss: 3.3162476619084678

Epoch: 6| Step: 1
Training loss: 2.7045392990112305
Validation loss: 3.3129491408665976

Epoch: 6| Step: 2
Training loss: 3.895277976989746
Validation loss: 3.3083642721176147

Epoch: 6| Step: 3
Training loss: 3.1148173809051514
Validation loss: 3.3032819827397666

Epoch: 6| Step: 4
Training loss: 3.93939471244812
Validation loss: 3.299129366874695

Epoch: 6| Step: 5
Training loss: 2.3146023750305176
Validation loss: 3.295205513636271

Epoch: 6| Step: 6
Training loss: 3.277987003326416
Validation loss: 3.290965994199117

Epoch: 6| Step: 7
Training loss: 2.906846523284912
Validation loss: 3.2867374420166016

Epoch: 6| Step: 8
Training loss: 3.21109676361084
Validation loss: 3.2833996613820395

Epoch: 6| Step: 9
Training loss: 4.375834941864014
Validation loss: 3.2790982325871787

Epoch: 6| Step: 10
Training loss: 3.716829299926758
Validation loss: 3.2742445866266885

Epoch: 6| Step: 11
Training loss: 3.388339042663574
Validation loss: 3.2707220315933228

Epoch: 6| Step: 12
Training loss: 3.660829544067383
Validation loss: 3.2658379077911377

Epoch: 6| Step: 13
Training loss: 2.987016439437866
Validation loss: 3.2620641390482583

Epoch: 28| Step: 0
Training loss: 2.6058268547058105
Validation loss: 3.258093317349752

Epoch: 6| Step: 1
Training loss: 3.5790252685546875
Validation loss: 3.2537833054860434

Epoch: 6| Step: 2
Training loss: 3.1443963050842285
Validation loss: 3.24973992506663

Epoch: 6| Step: 3
Training loss: 2.456725597381592
Validation loss: 3.2458448807398477

Epoch: 6| Step: 4
Training loss: 4.155336856842041
Validation loss: 3.2426976362864175

Epoch: 6| Step: 5
Training loss: 3.7034056186676025
Validation loss: 3.2398784160614014

Epoch: 6| Step: 6
Training loss: 3.3478050231933594
Validation loss: 3.2352367639541626

Epoch: 6| Step: 7
Training loss: 3.0540597438812256
Validation loss: 3.229629715283712

Epoch: 6| Step: 8
Training loss: 3.8852906227111816
Validation loss: 3.2260733445485434

Epoch: 6| Step: 9
Training loss: 3.558732509613037
Validation loss: 3.2221409678459167

Epoch: 6| Step: 10
Training loss: 3.515568256378174
Validation loss: 3.2187626361846924

Epoch: 6| Step: 11
Training loss: 4.089105606079102
Validation loss: 3.215082049369812

Epoch: 6| Step: 12
Training loss: 3.4761433601379395
Validation loss: 3.2107871174812317

Epoch: 6| Step: 13
Training loss: 3.1682724952697754
Validation loss: 3.207093516985575

Epoch: 29| Step: 0
Training loss: 3.825949192047119
Validation loss: 3.2031184832255044

Epoch: 6| Step: 1
Training loss: 3.735226631164551
Validation loss: 3.1982213656107583

Epoch: 6| Step: 2
Training loss: 3.2841906547546387
Validation loss: 3.194044748942057

Epoch: 6| Step: 3
Training loss: 3.4257373809814453
Validation loss: 3.1895196437835693

Epoch: 6| Step: 4
Training loss: 2.3762640953063965
Validation loss: 3.1846166054407754

Epoch: 6| Step: 5
Training loss: 3.423489570617676
Validation loss: 3.1803746223449707

Epoch: 6| Step: 6
Training loss: 3.3997411727905273
Validation loss: 3.1762353579203286

Epoch: 6| Step: 7
Training loss: 3.129244804382324
Validation loss: 3.1716920534769693

Epoch: 6| Step: 8
Training loss: 3.468813419342041
Validation loss: 3.1672714948654175

Epoch: 6| Step: 9
Training loss: 3.0440118312835693
Validation loss: 3.162745952606201

Epoch: 6| Step: 10
Training loss: 3.1193580627441406
Validation loss: 3.158322731653849

Epoch: 6| Step: 11
Training loss: 3.84851336479187
Validation loss: 3.153985341389974

Epoch: 6| Step: 12
Training loss: 3.7146241664886475
Validation loss: 3.149073839187622

Epoch: 6| Step: 13
Training loss: 3.229261636734009
Validation loss: 3.1449279387791953

Epoch: 30| Step: 0
Training loss: 2.8553781509399414
Validation loss: 3.14067542552948

Epoch: 6| Step: 1
Training loss: 2.233999252319336
Validation loss: 3.1375067631403604

Epoch: 6| Step: 2
Training loss: 3.3623392581939697
Validation loss: 3.132959167162577

Epoch: 6| Step: 3
Training loss: 3.723939895629883
Validation loss: 3.1295477946599326

Epoch: 6| Step: 4
Training loss: 3.7542405128479004
Validation loss: 3.1252766052881875

Epoch: 6| Step: 5
Training loss: 3.8191871643066406
Validation loss: 3.1214277744293213

Epoch: 6| Step: 6
Training loss: 2.996328353881836
Validation loss: 3.117839813232422

Epoch: 6| Step: 7
Training loss: 3.7831196784973145
Validation loss: 3.113926887512207

Epoch: 6| Step: 8
Training loss: 3.067066192626953
Validation loss: 3.109464248021444

Epoch: 6| Step: 9
Training loss: 3.6661853790283203
Validation loss: 3.105438152949015

Epoch: 6| Step: 10
Training loss: 2.7786316871643066
Validation loss: 3.10166064898173

Epoch: 6| Step: 11
Training loss: 3.7772722244262695
Validation loss: 3.0982635021209717

Epoch: 6| Step: 12
Training loss: 3.3425228595733643
Validation loss: 3.094342311223348

Epoch: 6| Step: 13
Training loss: 3.0867221355438232
Validation loss: 3.0906595389048257

Epoch: 31| Step: 0
Training loss: 3.729813575744629
Validation loss: 3.0876475969950357

Epoch: 6| Step: 1
Training loss: 3.899308919906616
Validation loss: 3.0837103525797525

Epoch: 6| Step: 2
Training loss: 3.0121567249298096
Validation loss: 3.079895337422689

Epoch: 6| Step: 3
Training loss: 3.9771339893341064
Validation loss: 3.0760974089304605

Epoch: 6| Step: 4
Training loss: 3.288771629333496
Validation loss: 3.0730468034744263

Epoch: 6| Step: 5
Training loss: 3.1307599544525146
Validation loss: 3.068445324897766

Epoch: 6| Step: 6
Training loss: 2.4025518894195557
Validation loss: 3.0646314223607383

Epoch: 6| Step: 7
Training loss: 3.0823066234588623
Validation loss: 3.061131000518799

Epoch: 6| Step: 8
Training loss: 3.455172538757324
Validation loss: 3.058115522066752

Epoch: 6| Step: 9
Training loss: 3.3155226707458496
Validation loss: 3.054830312728882

Epoch: 6| Step: 10
Training loss: 2.285332441329956
Validation loss: 3.0514665047327676

Epoch: 6| Step: 11
Training loss: 2.8139123916625977
Validation loss: 3.048254370689392

Epoch: 6| Step: 12
Training loss: 2.982171058654785
Validation loss: 3.044746160507202

Epoch: 6| Step: 13
Training loss: 4.183259010314941
Validation loss: 3.0415884256362915

Epoch: 32| Step: 0
Training loss: 3.734437942504883
Validation loss: 3.037822206815084

Epoch: 6| Step: 1
Training loss: 3.373016834259033
Validation loss: 3.03414785861969

Epoch: 6| Step: 2
Training loss: 3.0655269622802734
Validation loss: 3.0302716493606567

Epoch: 6| Step: 3
Training loss: 3.0696470737457275
Validation loss: 3.0266879002253213

Epoch: 6| Step: 4
Training loss: 2.962667465209961
Validation loss: 3.0227883060773215

Epoch: 6| Step: 5
Training loss: 4.1376190185546875
Validation loss: 3.0195854107538858

Epoch: 6| Step: 6
Training loss: 3.425736665725708
Validation loss: 3.015735149383545

Epoch: 6| Step: 7
Training loss: 2.5136032104492188
Validation loss: 3.011604150136312

Epoch: 6| Step: 8
Training loss: 3.97292423248291
Validation loss: 3.008425315221151

Epoch: 6| Step: 9
Training loss: 2.715747117996216
Validation loss: 3.0048283338546753

Epoch: 6| Step: 10
Training loss: 3.2163209915161133
Validation loss: 3.0012452205022178

Epoch: 6| Step: 11
Training loss: 3.1028780937194824
Validation loss: 2.997327129046122

Epoch: 6| Step: 12
Training loss: 2.3450825214385986
Validation loss: 2.9937448104222617

Epoch: 6| Step: 13
Training loss: 3.300565719604492
Validation loss: 2.9909722805023193

Epoch: 33| Step: 0
Training loss: 3.219914674758911
Validation loss: 2.988101045290629

Epoch: 6| Step: 1
Training loss: 3.205747604370117
Validation loss: 2.984549562136332

Epoch: 6| Step: 2
Training loss: 2.4825987815856934
Validation loss: 2.9816609621047974

Epoch: 6| Step: 3
Training loss: 2.8722479343414307
Validation loss: 2.9788359006245932

Epoch: 6| Step: 4
Training loss: 3.6006643772125244
Validation loss: 2.975482781728109

Epoch: 6| Step: 5
Training loss: 3.3154916763305664
Validation loss: 2.972511370976766

Epoch: 6| Step: 6
Training loss: 3.72261905670166
Validation loss: 2.96897292137146

Epoch: 6| Step: 7
Training loss: 2.4662461280822754
Validation loss: 2.9651821851730347

Epoch: 6| Step: 8
Training loss: 3.5156126022338867
Validation loss: 2.961826801300049

Epoch: 6| Step: 9
Training loss: 3.038112163543701
Validation loss: 2.9586859544118247

Epoch: 6| Step: 10
Training loss: 3.2972750663757324
Validation loss: 2.9548484484354653

Epoch: 6| Step: 11
Training loss: 2.465221405029297
Validation loss: 2.9517229795455933

Epoch: 6| Step: 12
Training loss: 3.1493754386901855
Validation loss: 2.948339899381002

Epoch: 6| Step: 13
Training loss: 3.9481866359710693
Validation loss: 2.9454003175099692

Epoch: 34| Step: 0
Training loss: 3.067011594772339
Validation loss: 2.9415603081385293

Epoch: 6| Step: 1
Training loss: 3.2345404624938965
Validation loss: 2.9385700623194375

Epoch: 6| Step: 2
Training loss: 3.162233352661133
Validation loss: 2.935301105181376

Epoch: 6| Step: 3
Training loss: 3.4018959999084473
Validation loss: 2.931657393773397

Epoch: 6| Step: 4
Training loss: 3.313359260559082
Validation loss: 2.928188145160675

Epoch: 6| Step: 5
Training loss: 3.1188645362854004
Validation loss: 2.9250678618748984

Epoch: 6| Step: 6
Training loss: 2.751115322113037
Validation loss: 2.9215432008107505

Epoch: 6| Step: 7
Training loss: 2.6908559799194336
Validation loss: 2.91800586382548

Epoch: 6| Step: 8
Training loss: 3.479665756225586
Validation loss: 2.9146682024002075

Epoch: 6| Step: 9
Training loss: 3.204653739929199
Validation loss: 2.911798675855001

Epoch: 6| Step: 10
Training loss: 3.9804506301879883
Validation loss: 2.9081857204437256

Epoch: 6| Step: 11
Training loss: 3.1432995796203613
Validation loss: 2.9047983487447104

Epoch: 6| Step: 12
Training loss: 2.42946457862854
Validation loss: 2.901825229326884

Epoch: 6| Step: 13
Training loss: 2.7686851024627686
Validation loss: 2.8982573747634888

Epoch: 35| Step: 0
Training loss: 3.7344179153442383
Validation loss: 2.894604444503784

Epoch: 6| Step: 1
Training loss: 2.3103833198547363
Validation loss: 2.8915042877197266

Epoch: 6| Step: 2
Training loss: 2.8943419456481934
Validation loss: 2.8888795375823975

Epoch: 6| Step: 3
Training loss: 3.0134034156799316
Validation loss: 2.8859386841456094

Epoch: 6| Step: 4
Training loss: 3.144298553466797
Validation loss: 2.8829155365626016

Epoch: 6| Step: 5
Training loss: 3.265597105026245
Validation loss: 2.880137006441752

Epoch: 6| Step: 6
Training loss: 3.356645107269287
Validation loss: 2.8768796920776367

Epoch: 6| Step: 7
Training loss: 2.312274932861328
Validation loss: 2.873594085375468

Epoch: 6| Step: 8
Training loss: 2.8976430892944336
Validation loss: 2.8705141146977744

Epoch: 6| Step: 9
Training loss: 3.1522574424743652
Validation loss: 2.867235700289408

Epoch: 6| Step: 10
Training loss: 3.870647668838501
Validation loss: 2.8642833630243936

Epoch: 6| Step: 11
Training loss: 3.1876895427703857
Validation loss: 2.8609125216801963

Epoch: 6| Step: 12
Training loss: 3.379733085632324
Validation loss: 2.857926328976949

Epoch: 6| Step: 13
Training loss: 2.636639356613159
Validation loss: 2.855227748552958

Epoch: 36| Step: 0
Training loss: 3.3371386528015137
Validation loss: 2.851680318514506

Epoch: 6| Step: 1
Training loss: 2.5953187942504883
Validation loss: 2.848581631978353

Epoch: 6| Step: 2
Training loss: 3.08549165725708
Validation loss: 2.8451830546061196

Epoch: 6| Step: 3
Training loss: 2.706275224685669
Validation loss: 2.841708461443583

Epoch: 6| Step: 4
Training loss: 4.284765243530273
Validation loss: 2.838923692703247

Epoch: 6| Step: 5
Training loss: 3.4028937816619873
Validation loss: 2.8358177741368613

Epoch: 6| Step: 6
Training loss: 3.0162224769592285
Validation loss: 2.832327047983805

Epoch: 6| Step: 7
Training loss: 3.3657097816467285
Validation loss: 2.829062898953756

Epoch: 6| Step: 8
Training loss: 2.7746880054473877
Validation loss: 2.8257717291514077

Epoch: 6| Step: 9
Training loss: 2.5691165924072266
Validation loss: 2.8224156697591147

Epoch: 6| Step: 10
Training loss: 2.307138442993164
Validation loss: 2.8195394476254783

Epoch: 6| Step: 11
Training loss: 2.471000909805298
Validation loss: 2.8166606028874717

Epoch: 6| Step: 12
Training loss: 3.1919968128204346
Validation loss: 2.8141499360402427

Epoch: 6| Step: 13
Training loss: 3.5215225219726562
Validation loss: 2.8110364278157554

Epoch: 37| Step: 0
Training loss: 2.468052387237549
Validation loss: 2.8097735246022544

Epoch: 6| Step: 1
Training loss: 3.0340657234191895
Validation loss: 2.815141518910726

Epoch: 6| Step: 2
Training loss: 2.9057390689849854
Validation loss: 2.8077739477157593

Epoch: 6| Step: 3
Training loss: 2.783618211746216
Validation loss: 2.8100642760594687

Epoch: 6| Step: 4
Training loss: 2.9875705242156982
Validation loss: 2.798115889231364

Epoch: 6| Step: 5
Training loss: 2.8368711471557617
Validation loss: 2.795765479405721

Epoch: 6| Step: 6
Training loss: 2.551149606704712
Validation loss: 2.7932014067967734

Epoch: 6| Step: 7
Training loss: 4.0876569747924805
Validation loss: 2.7903854052225747

Epoch: 6| Step: 8
Training loss: 3.2583203315734863
Validation loss: 2.78845222791036

Epoch: 6| Step: 9
Training loss: 3.8243253231048584
Validation loss: 2.786322553952535

Epoch: 6| Step: 10
Training loss: 3.1350183486938477
Validation loss: 2.783320983250936

Epoch: 6| Step: 11
Training loss: 2.625617027282715
Validation loss: 2.7798256874084473

Epoch: 6| Step: 12
Training loss: 2.7256946563720703
Validation loss: 2.7764764626820884

Epoch: 6| Step: 13
Training loss: 2.8325300216674805
Validation loss: 2.772891362508138

Epoch: 38| Step: 0
Training loss: 2.5142269134521484
Validation loss: 2.770320932070414

Epoch: 6| Step: 1
Training loss: 3.0140209197998047
Validation loss: 2.7676322857538858

Epoch: 6| Step: 2
Training loss: 3.6472537517547607
Validation loss: 2.7651399970054626

Epoch: 6| Step: 3
Training loss: 3.304002523422241
Validation loss: 2.76232639948527

Epoch: 6| Step: 4
Training loss: 2.7960269451141357
Validation loss: 2.759528557459513

Epoch: 6| Step: 5
Training loss: 2.8105814456939697
Validation loss: 2.756718118985494

Epoch: 6| Step: 6
Training loss: 2.9825592041015625
Validation loss: 2.75385590394338

Epoch: 6| Step: 7
Training loss: 2.990567684173584
Validation loss: 2.7503451108932495

Epoch: 6| Step: 8
Training loss: 3.5890660285949707
Validation loss: 2.7481927474339805

Epoch: 6| Step: 9
Training loss: 2.4942407608032227
Validation loss: 2.744820515314738

Epoch: 6| Step: 10
Training loss: 3.724997043609619
Validation loss: 2.742451469103495

Epoch: 6| Step: 11
Training loss: 2.0990495681762695
Validation loss: 2.7391474644343057

Epoch: 6| Step: 12
Training loss: 2.237592935562134
Validation loss: 2.735493461290995

Epoch: 6| Step: 13
Training loss: 3.2796506881713867
Validation loss: 2.7343380053838096

Epoch: 39| Step: 0
Training loss: 2.7761003971099854
Validation loss: 2.7304404576619468

Epoch: 6| Step: 1
Training loss: 3.1351239681243896
Validation loss: 2.7270484368006387

Epoch: 6| Step: 2
Training loss: 2.5591747760772705
Validation loss: 2.725679039955139

Epoch: 6| Step: 3
Training loss: 2.5414958000183105
Validation loss: 2.721930662790934

Epoch: 6| Step: 4
Training loss: 3.1042137145996094
Validation loss: 2.718921502431234

Epoch: 6| Step: 5
Training loss: 3.0271918773651123
Validation loss: 2.7167872190475464

Epoch: 6| Step: 6
Training loss: 2.923076868057251
Validation loss: 2.715251088142395

Epoch: 6| Step: 7
Training loss: 2.6816413402557373
Validation loss: 2.7123337586720786

Epoch: 6| Step: 8
Training loss: 2.9006757736206055
Validation loss: 2.7098531325658164

Epoch: 6| Step: 9
Training loss: 3.257333993911743
Validation loss: 2.707622766494751

Epoch: 6| Step: 10
Training loss: 3.33827543258667
Validation loss: 2.702609380086263

Epoch: 6| Step: 11
Training loss: 2.181182622909546
Validation loss: 2.702212691307068

Epoch: 6| Step: 12
Training loss: 3.391155958175659
Validation loss: 2.6992559830347695

Epoch: 6| Step: 13
Training loss: 3.063875198364258
Validation loss: 2.6963147719701133

Epoch: 40| Step: 0
Training loss: 2.4339089393615723
Validation loss: 2.693267047405243

Epoch: 6| Step: 1
Training loss: 2.9596567153930664
Validation loss: 2.6883715987205505

Epoch: 6| Step: 2
Training loss: 3.0388717651367188
Validation loss: 2.6859873135884604

Epoch: 6| Step: 3
Training loss: 2.879533290863037
Validation loss: 2.6805452903111777

Epoch: 6| Step: 4
Training loss: 2.671638011932373
Validation loss: 2.6790748039881387

Epoch: 6| Step: 5
Training loss: 2.8522276878356934
Validation loss: 2.6751061280568442

Epoch: 6| Step: 6
Training loss: 2.4736557006835938
Validation loss: 2.673073728879293

Epoch: 6| Step: 7
Training loss: 3.654055595397949
Validation loss: 2.673343221346537

Epoch: 6| Step: 8
Training loss: 3.2480781078338623
Validation loss: 2.667515238126119

Epoch: 6| Step: 9
Training loss: 2.8062448501586914
Validation loss: 2.6670230627059937

Epoch: 6| Step: 10
Training loss: 3.5829529762268066
Validation loss: 2.661531686782837

Epoch: 6| Step: 11
Training loss: 3.190479278564453
Validation loss: 2.659481724103292

Epoch: 6| Step: 12
Training loss: 2.2459118366241455
Validation loss: 2.6571805477142334

Epoch: 6| Step: 13
Training loss: 2.2735090255737305
Validation loss: 2.6559813817342124

Epoch: 41| Step: 0
Training loss: 2.2298667430877686
Validation loss: 2.6530287663141885

Epoch: 6| Step: 1
Training loss: 3.0122506618499756
Validation loss: 2.6502326329549155

Epoch: 6| Step: 2
Training loss: 2.9036734104156494
Validation loss: 2.6472115516662598

Epoch: 6| Step: 3
Training loss: 2.7296125888824463
Validation loss: 2.6459712187449136

Epoch: 6| Step: 4
Training loss: 2.6168603897094727
Validation loss: 2.642854690551758

Epoch: 6| Step: 5
Training loss: 2.9829416275024414
Validation loss: 2.645897308985392

Epoch: 6| Step: 6
Training loss: 3.4630908966064453
Validation loss: 2.635402798652649

Epoch: 6| Step: 7
Training loss: 2.411931276321411
Validation loss: 2.6346585353215537

Epoch: 6| Step: 8
Training loss: 2.3412015438079834
Validation loss: 2.63360325495402

Epoch: 6| Step: 9
Training loss: 2.6854312419891357
Validation loss: 2.631601313749949

Epoch: 6| Step: 10
Training loss: 3.399881601333618
Validation loss: 2.630617618560791

Epoch: 6| Step: 11
Training loss: 2.854677677154541
Validation loss: 2.625389297803243

Epoch: 6| Step: 12
Training loss: 2.907327175140381
Validation loss: 2.622035185496012

Epoch: 6| Step: 13
Training loss: 3.2194418907165527
Validation loss: 2.618495066960653

Epoch: 42| Step: 0
Training loss: 2.445657253265381
Validation loss: 2.6144771178563437

Epoch: 6| Step: 1
Training loss: 2.7904305458068848
Validation loss: 2.611303687095642

Epoch: 6| Step: 2
Training loss: 2.905550718307495
Validation loss: 2.6086544195810952

Epoch: 6| Step: 3
Training loss: 2.9354641437530518
Validation loss: 2.605177084604899

Epoch: 6| Step: 4
Training loss: 2.944645881652832
Validation loss: 2.602703809738159

Epoch: 6| Step: 5
Training loss: 2.8476743698120117
Validation loss: 2.6007188161214194

Epoch: 6| Step: 6
Training loss: 2.623209238052368
Validation loss: 2.5990432500839233

Epoch: 6| Step: 7
Training loss: 2.6871068477630615
Validation loss: 2.5937753121058145

Epoch: 6| Step: 8
Training loss: 2.829610824584961
Validation loss: 2.591179927190145

Epoch: 6| Step: 9
Training loss: 2.9309463500976562
Validation loss: 2.589357773462931

Epoch: 6| Step: 10
Training loss: 2.9359447956085205
Validation loss: 2.583461284637451

Epoch: 6| Step: 11
Training loss: 2.7248616218566895
Validation loss: 2.5816920598347983

Epoch: 6| Step: 12
Training loss: 2.7433204650878906
Validation loss: 2.577052275339762

Epoch: 6| Step: 13
Training loss: 2.8159704208374023
Validation loss: 2.5762857596079507

Epoch: 43| Step: 0
Training loss: 2.8271450996398926
Validation loss: 2.5743319193522134

Epoch: 6| Step: 1
Training loss: 3.6748573780059814
Validation loss: 2.5732434391975403

Epoch: 6| Step: 2
Training loss: 2.6060333251953125
Validation loss: 2.572839140892029

Epoch: 6| Step: 3
Training loss: 2.2746315002441406
Validation loss: 2.569937547047933

Epoch: 6| Step: 4
Training loss: 3.393280506134033
Validation loss: 2.5679158369700112

Epoch: 6| Step: 5
Training loss: 3.080798625946045
Validation loss: 2.5645645459493003

Epoch: 6| Step: 6
Training loss: 2.392033100128174
Validation loss: 2.5611422856648765

Epoch: 6| Step: 7
Training loss: 2.801556348800659
Validation loss: 2.5594727595647178

Epoch: 6| Step: 8
Training loss: 2.91713285446167
Validation loss: 2.5562243858973184

Epoch: 6| Step: 9
Training loss: 2.9433517456054688
Validation loss: 2.552328586578369

Epoch: 6| Step: 10
Training loss: 2.2113327980041504
Validation loss: 2.547830502192179

Epoch: 6| Step: 11
Training loss: 2.2136385440826416
Validation loss: 2.5442909399668374

Epoch: 6| Step: 12
Training loss: 2.878140926361084
Validation loss: 2.5405882596969604

Epoch: 6| Step: 13
Training loss: 2.3837640285491943
Validation loss: 2.5382297039031982

Epoch: 44| Step: 0
Training loss: 3.0120015144348145
Validation loss: 2.5328770875930786

Epoch: 6| Step: 1
Training loss: 2.708817481994629
Validation loss: 2.529015680154165

Epoch: 6| Step: 2
Training loss: 2.780616283416748
Validation loss: 2.527841567993164

Epoch: 6| Step: 3
Training loss: 1.881422519683838
Validation loss: 2.524291674296061

Epoch: 6| Step: 4
Training loss: 2.592543601989746
Validation loss: 2.5197739799817405

Epoch: 6| Step: 5
Training loss: 2.9628257751464844
Validation loss: 2.5187888542811074

Epoch: 6| Step: 6
Training loss: 2.855064630508423
Validation loss: 2.5173038244247437

Epoch: 6| Step: 7
Training loss: 3.1230340003967285
Validation loss: 2.5126047134399414

Epoch: 6| Step: 8
Training loss: 2.8931832313537598
Validation loss: 2.513106107711792

Epoch: 6| Step: 9
Training loss: 2.5474376678466797
Validation loss: 2.5071785052617392

Epoch: 6| Step: 10
Training loss: 3.1904189586639404
Validation loss: 2.504074732462565

Epoch: 6| Step: 11
Training loss: 2.4615867137908936
Validation loss: 2.5021316607793174

Epoch: 6| Step: 12
Training loss: 2.3579463958740234
Validation loss: 2.497421383857727

Epoch: 6| Step: 13
Training loss: 2.7124433517456055
Validation loss: 2.4963141083717346

Epoch: 45| Step: 0
Training loss: 2.8442249298095703
Validation loss: 2.492445786794027

Epoch: 6| Step: 1
Training loss: 2.3363351821899414
Validation loss: 2.4902405937512717

Epoch: 6| Step: 2
Training loss: 2.1708321571350098
Validation loss: 2.4905006090799966

Epoch: 6| Step: 3
Training loss: 2.5798404216766357
Validation loss: 2.4944734970728555

Epoch: 6| Step: 4
Training loss: 3.382094144821167
Validation loss: 2.4898969531059265

Epoch: 6| Step: 5
Training loss: 2.465400218963623
Validation loss: 2.485631306966146

Epoch: 6| Step: 6
Training loss: 2.345792531967163
Validation loss: 2.4778052965799966

Epoch: 6| Step: 7
Training loss: 3.14357328414917
Validation loss: 2.475887894630432

Epoch: 6| Step: 8
Training loss: 3.5128650665283203
Validation loss: 2.4729669094085693

Epoch: 6| Step: 9
Training loss: 2.3670878410339355
Validation loss: 2.470786730448405

Epoch: 6| Step: 10
Training loss: 2.145442247390747
Validation loss: 2.4692211945851645

Epoch: 6| Step: 11
Training loss: 3.6323978900909424
Validation loss: 2.468268712361654

Epoch: 6| Step: 12
Training loss: 2.9912633895874023
Validation loss: 2.4665342768033347

Epoch: 6| Step: 13
Training loss: 1.560978889465332
Validation loss: 2.467184563477834

Epoch: 46| Step: 0
Training loss: 2.629178047180176
Validation loss: 2.466015855471293

Epoch: 6| Step: 1
Training loss: 3.0441017150878906
Validation loss: 2.463655630747477

Epoch: 6| Step: 2
Training loss: 2.460740327835083
Validation loss: 2.4613085190455117

Epoch: 6| Step: 3
Training loss: 2.811927318572998
Validation loss: 2.4587263266245523

Epoch: 6| Step: 4
Training loss: 2.588439464569092
Validation loss: 2.455227772394816

Epoch: 6| Step: 5
Training loss: 2.2889602184295654
Validation loss: 2.4539664586385093

Epoch: 6| Step: 6
Training loss: 3.157370090484619
Validation loss: 2.448928157488505

Epoch: 6| Step: 7
Training loss: 2.8572299480438232
Validation loss: 2.446823994318644

Epoch: 6| Step: 8
Training loss: 2.868478536605835
Validation loss: 2.4449841181437173

Epoch: 6| Step: 9
Training loss: 2.25459885597229
Validation loss: 2.439364512761434

Epoch: 6| Step: 10
Training loss: 1.4482977390289307
Validation loss: 2.436266521612803

Epoch: 6| Step: 11
Training loss: 2.910836696624756
Validation loss: 2.430735945701599

Epoch: 6| Step: 12
Training loss: 2.7082200050354004
Validation loss: 2.425189197063446

Epoch: 6| Step: 13
Training loss: 2.9432873725891113
Validation loss: 2.4250998497009277

Epoch: 47| Step: 0
Training loss: 2.126845598220825
Validation loss: 2.4223844011624656

Epoch: 6| Step: 1
Training loss: 2.7155117988586426
Validation loss: 2.421596566836039

Epoch: 6| Step: 2
Training loss: 2.3836121559143066
Validation loss: 2.419994910558065

Epoch: 6| Step: 3
Training loss: 2.630464553833008
Validation loss: 2.4136746724446616

Epoch: 6| Step: 4
Training loss: 2.5883560180664062
Validation loss: 2.417158007621765

Epoch: 6| Step: 5
Training loss: 2.7883644104003906
Validation loss: 2.409529765446981

Epoch: 6| Step: 6
Training loss: 2.6683542728424072
Validation loss: 2.4058252573013306

Epoch: 6| Step: 7
Training loss: 2.670700788497925
Validation loss: 2.4091583887736

Epoch: 6| Step: 8
Training loss: 2.557711362838745
Validation loss: 2.404587904612223

Epoch: 6| Step: 9
Training loss: 3.0941247940063477
Validation loss: 2.4004175662994385

Epoch: 6| Step: 10
Training loss: 2.5388174057006836
Validation loss: 2.399066686630249

Epoch: 6| Step: 11
Training loss: 2.803229808807373
Validation loss: 2.3935983578364053

Epoch: 6| Step: 12
Training loss: 2.3700990676879883
Validation loss: 2.392854372660319

Epoch: 6| Step: 13
Training loss: 2.442237377166748
Validation loss: 2.3928425312042236

Epoch: 48| Step: 0
Training loss: 2.130417585372925
Validation loss: 2.3869410355885825

Epoch: 6| Step: 1
Training loss: 2.5925750732421875
Validation loss: 2.3819870154062905

Epoch: 6| Step: 2
Training loss: 2.722165107727051
Validation loss: 2.385628422101339

Epoch: 6| Step: 3
Training loss: 2.6403982639312744
Validation loss: 2.3868237336476645

Epoch: 6| Step: 4
Training loss: 3.06717586517334
Validation loss: 2.3914693792661033

Epoch: 6| Step: 5
Training loss: 2.847595691680908
Validation loss: 2.3935048977533975

Epoch: 6| Step: 6
Training loss: 3.2984139919281006
Validation loss: 2.3946011463801065

Epoch: 6| Step: 7
Training loss: 2.46555757522583
Validation loss: 2.371992369492849

Epoch: 6| Step: 8
Training loss: 1.8016527891159058
Validation loss: 2.369812766710917

Epoch: 6| Step: 9
Training loss: 2.346562623977661
Validation loss: 2.3665510018666587

Epoch: 6| Step: 10
Training loss: 2.6971120834350586
Validation loss: 2.367447336514791

Epoch: 6| Step: 11
Training loss: 2.8046512603759766
Validation loss: 2.3693073987960815

Epoch: 6| Step: 12
Training loss: 1.92995023727417
Validation loss: 2.365427553653717

Epoch: 6| Step: 13
Training loss: 2.4930243492126465
Validation loss: 2.3648985822995505

Epoch: 49| Step: 0
Training loss: 2.1280455589294434
Validation loss: 2.3692269722620645

Epoch: 6| Step: 1
Training loss: 2.3628392219543457
Validation loss: 2.3691618839899697

Epoch: 6| Step: 2
Training loss: 3.057298183441162
Validation loss: 2.365612824757894

Epoch: 6| Step: 3
Training loss: 2.5104384422302246
Validation loss: 2.35823126633962

Epoch: 6| Step: 4
Training loss: 2.7283153533935547
Validation loss: 2.35404109954834

Epoch: 6| Step: 5
Training loss: 2.1701035499572754
Validation loss: 2.3468509912490845

Epoch: 6| Step: 6
Training loss: 2.402420997619629
Validation loss: 2.344000597794851

Epoch: 6| Step: 7
Training loss: 2.5664515495300293
Validation loss: 2.341171085834503

Epoch: 6| Step: 8
Training loss: 2.9122440814971924
Validation loss: 2.338922301928202

Epoch: 6| Step: 9
Training loss: 2.633423328399658
Validation loss: 2.3381217320760093

Epoch: 6| Step: 10
Training loss: 2.35498046875
Validation loss: 2.3336139718691506

Epoch: 6| Step: 11
Training loss: 2.476046085357666
Validation loss: 2.330886483192444

Epoch: 6| Step: 12
Training loss: 2.6852242946624756
Validation loss: 2.328994711240133

Epoch: 6| Step: 13
Training loss: 2.3889265060424805
Validation loss: 2.326194783051809

Epoch: 50| Step: 0
Training loss: 2.560640335083008
Validation loss: 2.3248451550801597

Epoch: 6| Step: 1
Training loss: 2.1411728858947754
Validation loss: 2.319804092248281

Epoch: 6| Step: 2
Training loss: 2.3629894256591797
Validation loss: 2.3181480964024863

Epoch: 6| Step: 3
Training loss: 2.837791681289673
Validation loss: 2.3170275688171387

Epoch: 6| Step: 4
Training loss: 2.5574193000793457
Validation loss: 2.312621553738912

Epoch: 6| Step: 5
Training loss: 2.7199625968933105
Validation loss: 2.3161486784617105

Epoch: 6| Step: 6
Training loss: 1.8183403015136719
Validation loss: 2.317535678545634

Epoch: 6| Step: 7
Training loss: 2.318735361099243
Validation loss: 2.3117018938064575

Epoch: 6| Step: 8
Training loss: 1.9133163690567017
Validation loss: 2.306847870349884

Epoch: 6| Step: 9
Training loss: 2.3697304725646973
Validation loss: 2.3040727376937866

Epoch: 6| Step: 10
Training loss: 3.4577715396881104
Validation loss: 2.3064679304758706

Epoch: 6| Step: 11
Training loss: 2.453521490097046
Validation loss: 2.300035754839579

Epoch: 6| Step: 12
Training loss: 2.5893712043762207
Validation loss: 2.290501435597738

Epoch: 6| Step: 13
Training loss: 2.668152093887329
Validation loss: 2.289706826210022

Epoch: 51| Step: 0
Training loss: 2.308866024017334
Validation loss: 2.288796087106069

Epoch: 6| Step: 1
Training loss: 2.3099558353424072
Validation loss: 2.2890746196111045

Epoch: 6| Step: 2
Training loss: 2.313178539276123
Validation loss: 2.28564182917277

Epoch: 6| Step: 3
Training loss: 2.5043816566467285
Validation loss: 2.2845853567123413

Epoch: 6| Step: 4
Training loss: 2.207324981689453
Validation loss: 2.280941049257914

Epoch: 6| Step: 5
Training loss: 2.077580213546753
Validation loss: 2.28054940700531

Epoch: 6| Step: 6
Training loss: 2.540925979614258
Validation loss: 2.2773694594701133

Epoch: 6| Step: 7
Training loss: 2.269850730895996
Validation loss: 2.275559425354004

Epoch: 6| Step: 8
Training loss: 2.1355364322662354
Validation loss: 2.2744378050168357

Epoch: 6| Step: 9
Training loss: 3.071420669555664
Validation loss: 2.2698826789855957

Epoch: 6| Step: 10
Training loss: 2.8352317810058594
Validation loss: 2.2684985597928367

Epoch: 6| Step: 11
Training loss: 2.8130688667297363
Validation loss: 2.264799435933431

Epoch: 6| Step: 12
Training loss: 2.5952532291412354
Validation loss: 2.263728360335032

Epoch: 6| Step: 13
Training loss: 2.2881393432617188
Validation loss: 2.260764002799988

Epoch: 52| Step: 0
Training loss: 2.9900007247924805
Validation loss: 2.262122650941213

Epoch: 6| Step: 1
Training loss: 2.0132198333740234
Validation loss: 2.2593321402867637

Epoch: 6| Step: 2
Training loss: 2.6960396766662598
Validation loss: 2.2515138387680054

Epoch: 6| Step: 3
Training loss: 2.609233856201172
Validation loss: 2.251760184764862

Epoch: 6| Step: 4
Training loss: 2.528709888458252
Validation loss: 2.25736403465271

Epoch: 6| Step: 5
Training loss: 2.7054224014282227
Validation loss: 2.2688913345336914

Epoch: 6| Step: 6
Training loss: 2.326829195022583
Validation loss: 2.270952065785726

Epoch: 6| Step: 7
Training loss: 1.607714295387268
Validation loss: 2.2542229096094766

Epoch: 6| Step: 8
Training loss: 2.3287343978881836
Validation loss: 2.246606787045797

Epoch: 6| Step: 9
Training loss: 2.491886854171753
Validation loss: 2.240639328956604

Epoch: 6| Step: 10
Training loss: 2.559049606323242
Validation loss: 2.2384116649627686

Epoch: 6| Step: 11
Training loss: 2.1006522178649902
Validation loss: 2.2385168274243674

Epoch: 6| Step: 12
Training loss: 1.7784799337387085
Validation loss: 2.2371020714441934

Epoch: 6| Step: 13
Training loss: 3.1752493381500244
Validation loss: 2.2348852157592773

Epoch: 53| Step: 0
Training loss: 2.4325313568115234
Validation loss: 2.2394970258076987

Epoch: 6| Step: 1
Training loss: 2.004403591156006
Validation loss: 2.235519508520762

Epoch: 6| Step: 2
Training loss: 2.822158098220825
Validation loss: 2.2347578207651773

Epoch: 6| Step: 3
Training loss: 1.5068279504776
Validation loss: 2.2339309652646384

Epoch: 6| Step: 4
Training loss: 2.4651544094085693
Validation loss: 2.2322123050689697

Epoch: 6| Step: 5
Training loss: 2.6035828590393066
Validation loss: 2.2265087366104126

Epoch: 6| Step: 6
Training loss: 2.4058151245117188
Validation loss: 2.227730413277944

Epoch: 6| Step: 7
Training loss: 2.160465717315674
Validation loss: 2.2201912999153137

Epoch: 6| Step: 8
Training loss: 2.660524368286133
Validation loss: 2.2175338665644326

Epoch: 6| Step: 9
Training loss: 2.383279800415039
Validation loss: 2.21370792388916

Epoch: 6| Step: 10
Training loss: 2.3362653255462646
Validation loss: 2.2145469188690186

Epoch: 6| Step: 11
Training loss: 2.9256458282470703
Validation loss: 2.2106631795565286

Epoch: 6| Step: 12
Training loss: 2.2517080307006836
Validation loss: 2.2100837230682373

Epoch: 6| Step: 13
Training loss: 2.469226360321045
Validation loss: 2.2080607811609902

Epoch: 54| Step: 0
Training loss: 1.984902262687683
Validation loss: 2.205658197402954

Epoch: 6| Step: 1
Training loss: 2.3266074657440186
Validation loss: 2.200679898262024

Epoch: 6| Step: 2
Training loss: 1.9157871007919312
Validation loss: 2.2013290325800576

Epoch: 6| Step: 3
Training loss: 1.9052760601043701
Validation loss: 2.200864851474762

Epoch: 6| Step: 4
Training loss: 2.715254306793213
Validation loss: 2.1965337991714478

Epoch: 6| Step: 5
Training loss: 1.864363193511963
Validation loss: 2.2030289570490518

Epoch: 6| Step: 6
Training loss: 2.5593786239624023
Validation loss: 2.196572562058767

Epoch: 6| Step: 7
Training loss: 2.7512683868408203
Validation loss: 2.1921134988466897

Epoch: 6| Step: 8
Training loss: 2.894127607345581
Validation loss: 2.1895796855290732

Epoch: 6| Step: 9
Training loss: 2.6273140907287598
Validation loss: 2.1912413835525513

Epoch: 6| Step: 10
Training loss: 2.3904552459716797
Validation loss: 2.1929141879081726

Epoch: 6| Step: 11
Training loss: 2.620138645172119
Validation loss: 2.189193626244863

Epoch: 6| Step: 12
Training loss: 2.4778459072113037
Validation loss: 2.1880336006482444

Epoch: 6| Step: 13
Training loss: 2.010356903076172
Validation loss: 2.1854663689931235

Epoch: 55| Step: 0
Training loss: 2.6759743690490723
Validation loss: 2.1828958789507547

Epoch: 6| Step: 1
Training loss: 1.777395486831665
Validation loss: 2.188583195209503

Epoch: 6| Step: 2
Training loss: 2.435547351837158
Validation loss: 2.186517596244812

Epoch: 6| Step: 3
Training loss: 1.3961684703826904
Validation loss: 2.1893728574117026

Epoch: 6| Step: 4
Training loss: 2.947918653488159
Validation loss: 2.1838491360346475

Epoch: 6| Step: 5
Training loss: 2.431870937347412
Validation loss: 2.1837660868962607

Epoch: 6| Step: 6
Training loss: 2.8915886878967285
Validation loss: 2.182605723539988

Epoch: 6| Step: 7
Training loss: 2.483778238296509
Validation loss: 2.181187311808268

Epoch: 6| Step: 8
Training loss: 2.3366777896881104
Validation loss: 2.1782772541046143

Epoch: 6| Step: 9
Training loss: 2.1827850341796875
Validation loss: 2.176841755708059

Epoch: 6| Step: 10
Training loss: 2.01324200630188
Validation loss: 2.1756438612937927

Epoch: 6| Step: 11
Training loss: 2.547278642654419
Validation loss: 2.1733052333196006

Epoch: 6| Step: 12
Training loss: 2.4401354789733887
Validation loss: 2.170746664206187

Epoch: 6| Step: 13
Training loss: 2.23630428314209
Validation loss: 2.169560730457306

Epoch: 56| Step: 0
Training loss: 2.625972270965576
Validation loss: 2.1688931981722512

Epoch: 6| Step: 1
Training loss: 1.9068498611450195
Validation loss: 2.1664700905481973

Epoch: 6| Step: 2
Training loss: 2.2017369270324707
Validation loss: 2.1678253809611

Epoch: 6| Step: 3
Training loss: 2.8545992374420166
Validation loss: 2.1647767623265586

Epoch: 6| Step: 4
Training loss: 2.5745956897735596
Validation loss: 2.1614942948023477

Epoch: 6| Step: 5
Training loss: 2.582089900970459
Validation loss: 2.157014270623525

Epoch: 6| Step: 6
Training loss: 1.3878512382507324
Validation loss: 2.1629103620847068

Epoch: 6| Step: 7
Training loss: 3.1603760719299316
Validation loss: 2.167886435985565

Epoch: 6| Step: 8
Training loss: 2.1597490310668945
Validation loss: 2.157972534497579

Epoch: 6| Step: 9
Training loss: 2.0163497924804688
Validation loss: 2.149824380874634

Epoch: 6| Step: 10
Training loss: 2.06954288482666
Validation loss: 2.155766169230143

Epoch: 6| Step: 11
Training loss: 3.2184700965881348
Validation loss: 2.146247843901316

Epoch: 6| Step: 12
Training loss: 1.5944740772247314
Validation loss: 2.152643144130707

Epoch: 6| Step: 13
Training loss: 2.2207136154174805
Validation loss: 2.1523919105529785

Epoch: 57| Step: 0
Training loss: 2.4429521560668945
Validation loss: 2.1490395267804465

Epoch: 6| Step: 1
Training loss: 2.440830707550049
Validation loss: 2.1468740502993264

Epoch: 6| Step: 2
Training loss: 1.930983304977417
Validation loss: 2.147352854410807

Epoch: 6| Step: 3
Training loss: 2.4427688121795654
Validation loss: 2.1502845088640847

Epoch: 6| Step: 4
Training loss: 2.447971820831299
Validation loss: 2.146250545978546

Epoch: 6| Step: 5
Training loss: 2.36368989944458
Validation loss: 2.1473334431648254

Epoch: 6| Step: 6
Training loss: 1.7300697565078735
Validation loss: 2.146845897038778

Epoch: 6| Step: 7
Training loss: 2.8214497566223145
Validation loss: 2.1491417288780212

Epoch: 6| Step: 8
Training loss: 2.3228156566619873
Validation loss: 2.1424148281415305

Epoch: 6| Step: 9
Training loss: 2.030132532119751
Validation loss: 2.140847384929657

Epoch: 6| Step: 10
Training loss: 2.4774155616760254
Validation loss: 2.139379362265269

Epoch: 6| Step: 11
Training loss: 2.6661770343780518
Validation loss: 2.130535344282786

Epoch: 6| Step: 12
Training loss: 2.0409750938415527
Validation loss: 2.1308142940203347

Epoch: 6| Step: 13
Training loss: 2.170380115509033
Validation loss: 2.13450421889623

Epoch: 58| Step: 0
Training loss: 2.1080408096313477
Validation loss: 2.134786546230316

Epoch: 6| Step: 1
Training loss: 2.1921286582946777
Validation loss: 2.139479398727417

Epoch: 6| Step: 2
Training loss: 2.5616767406463623
Validation loss: 2.143474042415619

Epoch: 6| Step: 3
Training loss: 2.158390998840332
Validation loss: 2.1434435844421387

Epoch: 6| Step: 4
Training loss: 1.222956895828247
Validation loss: 2.145582298437754

Epoch: 6| Step: 5
Training loss: 2.2916550636291504
Validation loss: 2.139084299405416

Epoch: 6| Step: 6
Training loss: 2.5627403259277344
Validation loss: 2.1261542042096457

Epoch: 6| Step: 7
Training loss: 2.303659439086914
Validation loss: 2.1270459294319153

Epoch: 6| Step: 8
Training loss: 1.7213678359985352
Validation loss: 2.119643986225128

Epoch: 6| Step: 9
Training loss: 2.9701075553894043
Validation loss: 2.126154979070028

Epoch: 6| Step: 10
Training loss: 2.0687406063079834
Validation loss: 2.1199515660603843

Epoch: 6| Step: 11
Training loss: 2.381533622741699
Validation loss: 2.123177627722422

Epoch: 6| Step: 12
Training loss: 2.445375442504883
Validation loss: 2.1229578852653503

Epoch: 6| Step: 13
Training loss: 3.0296952724456787
Validation loss: 2.12420654296875

Epoch: 59| Step: 0
Training loss: 2.313720703125
Validation loss: 2.1217083732287088

Epoch: 6| Step: 1
Training loss: 2.530247688293457
Validation loss: 2.1220229864120483

Epoch: 6| Step: 2
Training loss: 2.495340347290039
Validation loss: 2.123105307420095

Epoch: 6| Step: 3
Training loss: 2.2430381774902344
Validation loss: 2.1206754644711814

Epoch: 6| Step: 4
Training loss: 2.3187079429626465
Validation loss: 2.11984912554423

Epoch: 6| Step: 5
Training loss: 1.4936407804489136
Validation loss: 2.117547949155172

Epoch: 6| Step: 6
Training loss: 2.0906755924224854
Validation loss: 2.1146703163782754

Epoch: 6| Step: 7
Training loss: 1.947137713432312
Validation loss: 2.111713687578837

Epoch: 6| Step: 8
Training loss: 2.7944862842559814
Validation loss: 2.1067958871523538

Epoch: 6| Step: 9
Training loss: 2.9406423568725586
Validation loss: 2.1014615297317505

Epoch: 6| Step: 10
Training loss: 2.204251527786255
Validation loss: 2.1044286489486694

Epoch: 6| Step: 11
Training loss: 2.26986026763916
Validation loss: 2.1032070318857827

Epoch: 6| Step: 12
Training loss: 1.860531210899353
Validation loss: 2.0987825791041055

Epoch: 6| Step: 13
Training loss: 2.4971208572387695
Validation loss: 2.098300556341807

Epoch: 60| Step: 0
Training loss: 2.6981518268585205
Validation loss: 2.0970321893692017

Epoch: 6| Step: 1
Training loss: 2.4222044944763184
Validation loss: 2.1035956541697183

Epoch: 6| Step: 2
Training loss: 2.1052887439727783
Validation loss: 2.097033123175303

Epoch: 6| Step: 3
Training loss: 2.3216469287872314
Validation loss: 2.0930877327919006

Epoch: 6| Step: 4
Training loss: 1.8087830543518066
Validation loss: 2.0891835689544678

Epoch: 6| Step: 5
Training loss: 2.3848989009857178
Validation loss: 2.0869792103767395

Epoch: 6| Step: 6
Training loss: 1.7931537628173828
Validation loss: 2.087992171446482

Epoch: 6| Step: 7
Training loss: 2.070981979370117
Validation loss: 2.087107499440511

Epoch: 6| Step: 8
Training loss: 2.2238240242004395
Validation loss: 2.084630012512207

Epoch: 6| Step: 9
Training loss: 1.9964478015899658
Validation loss: 2.0772850712140403

Epoch: 6| Step: 10
Training loss: 2.5972065925598145
Validation loss: 2.0763463377952576

Epoch: 6| Step: 11
Training loss: 2.5541329383850098
Validation loss: 2.0805552999178567

Epoch: 6| Step: 12
Training loss: 2.8083832263946533
Validation loss: 2.100157618522644

Epoch: 6| Step: 13
Training loss: 2.014474391937256
Validation loss: 2.0998290181159973

Epoch: 61| Step: 0
Training loss: 2.071375846862793
Validation loss: 2.0957823197046914

Epoch: 6| Step: 1
Training loss: 2.7399330139160156
Validation loss: 2.0843145648638406

Epoch: 6| Step: 2
Training loss: 2.3884639739990234
Validation loss: 2.074915905793508

Epoch: 6| Step: 3
Training loss: 2.5398242473602295
Validation loss: 2.0783696373303733

Epoch: 6| Step: 4
Training loss: 1.7318685054779053
Validation loss: 2.077005445957184

Epoch: 6| Step: 5
Training loss: 2.275942325592041
Validation loss: 2.077571670214335

Epoch: 6| Step: 6
Training loss: 1.9822393655776978
Validation loss: 2.0814191699028015

Epoch: 6| Step: 7
Training loss: 2.1075599193573
Validation loss: 2.07637882232666

Epoch: 6| Step: 8
Training loss: 1.8642029762268066
Validation loss: 2.0679312149683633

Epoch: 6| Step: 9
Training loss: 2.1136980056762695
Validation loss: 2.074356218179067

Epoch: 6| Step: 10
Training loss: 2.8288400173187256
Validation loss: 2.072462558746338

Epoch: 6| Step: 11
Training loss: 2.6473922729492188
Validation loss: 2.0708372592926025

Epoch: 6| Step: 12
Training loss: 1.3893318176269531
Validation loss: 2.0718462665875754

Epoch: 6| Step: 13
Training loss: 2.9199862480163574
Validation loss: 2.070257623990377

Epoch: 62| Step: 0
Training loss: 2.7489500045776367
Validation loss: 2.072778662045797

Epoch: 6| Step: 1
Training loss: 2.3121209144592285
Validation loss: 2.0773494044939675

Epoch: 6| Step: 2
Training loss: 2.846419334411621
Validation loss: 2.079368233680725

Epoch: 6| Step: 3
Training loss: 2.253528118133545
Validation loss: 2.0826213161150613

Epoch: 6| Step: 4
Training loss: 2.7980666160583496
Validation loss: 2.0825945933659873

Epoch: 6| Step: 5
Training loss: 2.2839086055755615
Validation loss: 2.0820335944493613

Epoch: 6| Step: 6
Training loss: 1.8718616962432861
Validation loss: 2.0849563678105674

Epoch: 6| Step: 7
Training loss: 2.064093589782715
Validation loss: 2.085087299346924

Epoch: 6| Step: 8
Training loss: 2.722797155380249
Validation loss: 2.084426780541738

Epoch: 6| Step: 9
Training loss: 1.457840919494629
Validation loss: 2.0804194609324136

Epoch: 6| Step: 10
Training loss: 2.258455753326416
Validation loss: 2.0787755449612937

Epoch: 6| Step: 11
Training loss: 2.5131683349609375
Validation loss: 2.075113753477732

Epoch: 6| Step: 12
Training loss: 2.0391035079956055
Validation loss: 2.074217200279236

Epoch: 6| Step: 13
Training loss: 1.5360751152038574
Validation loss: 2.070774515469869

Epoch: 63| Step: 0
Training loss: 2.266361713409424
Validation loss: 2.0692869822184243

Epoch: 6| Step: 1
Training loss: 3.1165194511413574
Validation loss: 2.0639333923657737

Epoch: 6| Step: 2
Training loss: 2.2474818229675293
Validation loss: 2.065015951792399

Epoch: 6| Step: 3
Training loss: 2.8207805156707764
Validation loss: 2.065524915854136

Epoch: 6| Step: 4
Training loss: 2.0378928184509277
Validation loss: 2.0672250191370645

Epoch: 6| Step: 5
Training loss: 1.997593641281128
Validation loss: 2.064796805381775

Epoch: 6| Step: 6
Training loss: 1.9346379041671753
Validation loss: 2.0585501194000244

Epoch: 6| Step: 7
Training loss: 1.8583565950393677
Validation loss: 2.0616496404012046

Epoch: 6| Step: 8
Training loss: 2.01289701461792
Validation loss: 2.0579031705856323

Epoch: 6| Step: 9
Training loss: 2.353064775466919
Validation loss: 2.0559369723002114

Epoch: 6| Step: 10
Training loss: 2.3227169513702393
Validation loss: 2.0561756094296775

Epoch: 6| Step: 11
Training loss: 2.553148031234741
Validation loss: 2.0467349688212075

Epoch: 6| Step: 12
Training loss: 2.2401552200317383
Validation loss: 2.05962864557902

Epoch: 6| Step: 13
Training loss: 1.6837496757507324
Validation loss: 2.0696470538775125

Epoch: 64| Step: 0
Training loss: 2.092998504638672
Validation loss: 2.079367995262146

Epoch: 6| Step: 1
Training loss: 2.4341046810150146
Validation loss: 2.089702924092611

Epoch: 6| Step: 2
Training loss: 2.7355117797851562
Validation loss: 2.101956288019816

Epoch: 6| Step: 3
Training loss: 1.7556111812591553
Validation loss: 2.0893672903378806

Epoch: 6| Step: 4
Training loss: 1.9114443063735962
Validation loss: 2.0756097038586936

Epoch: 6| Step: 5
Training loss: 1.9640170335769653
Validation loss: 2.0618176261583963

Epoch: 6| Step: 6
Training loss: 2.947910785675049
Validation loss: 2.0604570706685386

Epoch: 6| Step: 7
Training loss: 2.1644668579101562
Validation loss: 2.0635465582211814

Epoch: 6| Step: 8
Training loss: 1.9733829498291016
Validation loss: 2.0574127237002053

Epoch: 6| Step: 9
Training loss: 2.024129867553711
Validation loss: 2.05095511674881

Epoch: 6| Step: 10
Training loss: 2.4107213020324707
Validation loss: 2.0444198648134866

Epoch: 6| Step: 11
Training loss: 2.4313817024230957
Validation loss: 2.0431439677874246

Epoch: 6| Step: 12
Training loss: 1.9346940517425537
Validation loss: 2.0404533743858337

Epoch: 6| Step: 13
Training loss: 2.593334436416626
Validation loss: 2.034490168094635

Epoch: 65| Step: 0
Training loss: 2.994626998901367
Validation loss: 2.0366328954696655

Epoch: 6| Step: 1
Training loss: 2.774073600769043
Validation loss: 2.036505937576294

Epoch: 6| Step: 2
Training loss: 2.6741509437561035
Validation loss: 2.0463163455327353

Epoch: 6| Step: 3
Training loss: 1.79059636592865
Validation loss: 2.0534499684969583

Epoch: 6| Step: 4
Training loss: 1.794952392578125
Validation loss: 2.0807186166445413

Epoch: 6| Step: 5
Training loss: 2.3472766876220703
Validation loss: 2.0810095071792603

Epoch: 6| Step: 6
Training loss: 2.5502560138702393
Validation loss: 2.070680816968282

Epoch: 6| Step: 7
Training loss: 2.004305839538574
Validation loss: 2.044711112976074

Epoch: 6| Step: 8
Training loss: 1.821275234222412
Validation loss: 2.042586167653402

Epoch: 6| Step: 9
Training loss: 1.6256375312805176
Validation loss: 2.036543389161428

Epoch: 6| Step: 10
Training loss: 2.1767568588256836
Validation loss: 2.032557209332784

Epoch: 6| Step: 11
Training loss: 2.00783634185791
Validation loss: 2.038196881612142

Epoch: 6| Step: 12
Training loss: 2.2116405963897705
Validation loss: 2.0453909238179526

Epoch: 6| Step: 13
Training loss: 2.4371025562286377
Validation loss: 2.043610076109568

Epoch: 66| Step: 0
Training loss: 2.4689197540283203
Validation loss: 2.0554959575335183

Epoch: 6| Step: 1
Training loss: 1.6186295747756958
Validation loss: 2.0532289147377014

Epoch: 6| Step: 2
Training loss: 2.4947926998138428
Validation loss: 2.0520067612330117

Epoch: 6| Step: 3
Training loss: 2.2681546211242676
Validation loss: 2.0488836963971457

Epoch: 6| Step: 4
Training loss: 2.7772300243377686
Validation loss: 2.05023725827535

Epoch: 6| Step: 5
Training loss: 1.4725958108901978
Validation loss: 2.055350343386332

Epoch: 6| Step: 6
Training loss: 2.6941895484924316
Validation loss: 2.061125854651133

Epoch: 6| Step: 7
Training loss: 1.6244933605194092
Validation loss: 2.0634718338648477

Epoch: 6| Step: 8
Training loss: 2.526648998260498
Validation loss: 2.065119663874308

Epoch: 6| Step: 9
Training loss: 2.448244333267212
Validation loss: 2.0561697483062744

Epoch: 6| Step: 10
Training loss: 1.877906084060669
Validation loss: 2.0543084939320884

Epoch: 6| Step: 11
Training loss: 2.1354432106018066
Validation loss: 2.0461848179499307

Epoch: 6| Step: 12
Training loss: 2.3710179328918457
Validation loss: 2.042156934738159

Epoch: 6| Step: 13
Training loss: 2.5521013736724854
Validation loss: 2.0397922595342

Epoch: 67| Step: 0
Training loss: 2.1429219245910645
Validation loss: 2.0362210472424827

Epoch: 6| Step: 1
Training loss: 2.0084590911865234
Validation loss: 2.0377655227979026

Epoch: 6| Step: 2
Training loss: 1.7925864458084106
Validation loss: 2.0383568008740744

Epoch: 6| Step: 3
Training loss: 2.471816301345825
Validation loss: 2.0490025877952576

Epoch: 6| Step: 4
Training loss: 2.6464343070983887
Validation loss: 2.0640456676483154

Epoch: 6| Step: 5
Training loss: 2.104581356048584
Validation loss: 2.0724758307139077

Epoch: 6| Step: 6
Training loss: 2.669788360595703
Validation loss: 2.0717270771662393

Epoch: 6| Step: 7
Training loss: 2.2064239978790283
Validation loss: 2.078090031941732

Epoch: 6| Step: 8
Training loss: 2.732395648956299
Validation loss: 2.081318954626719

Epoch: 6| Step: 9
Training loss: 2.7190134525299072
Validation loss: 2.07054195801417

Epoch: 6| Step: 10
Training loss: 1.597508430480957
Validation loss: 2.0558824141820273

Epoch: 6| Step: 11
Training loss: 2.466212034225464
Validation loss: 2.0453602274258933

Epoch: 6| Step: 12
Training loss: 2.1385788917541504
Validation loss: 2.0439275900522866

Epoch: 6| Step: 13
Training loss: 1.4865314960479736
Validation loss: 2.0462249517440796

Epoch: 68| Step: 0
Training loss: 2.430351734161377
Validation loss: 2.0360039472579956

Epoch: 6| Step: 1
Training loss: 1.4970872402191162
Validation loss: 2.0284843842188516

Epoch: 6| Step: 2
Training loss: 3.0050711631774902
Validation loss: 2.032222807407379

Epoch: 6| Step: 3
Training loss: 2.779956817626953
Validation loss: 2.042872111002604

Epoch: 6| Step: 4
Training loss: 1.7958829402923584
Validation loss: 2.0378275314966836

Epoch: 6| Step: 5
Training loss: 1.7639000415802002
Validation loss: 2.0431323448816934

Epoch: 6| Step: 6
Training loss: 2.0504117012023926
Validation loss: 2.047553757826487

Epoch: 6| Step: 7
Training loss: 2.0238492488861084
Validation loss: 2.052362402280172

Epoch: 6| Step: 8
Training loss: 2.4229989051818848
Validation loss: 2.047383427619934

Epoch: 6| Step: 9
Training loss: 2.466888904571533
Validation loss: 2.040358821551005

Epoch: 6| Step: 10
Training loss: 2.081496238708496
Validation loss: 2.0415639082590737

Epoch: 6| Step: 11
Training loss: 2.1700706481933594
Validation loss: 2.038246214389801

Epoch: 6| Step: 12
Training loss: 2.065643787384033
Validation loss: 2.0370932618776956

Epoch: 6| Step: 13
Training loss: 2.550870418548584
Validation loss: 2.033074140548706

Epoch: 69| Step: 0
Training loss: 2.111964702606201
Validation loss: 2.023779511451721

Epoch: 6| Step: 1
Training loss: 2.381165027618408
Validation loss: 2.0356325507164

Epoch: 6| Step: 2
Training loss: 2.435331106185913
Validation loss: 2.037691374619802

Epoch: 6| Step: 3
Training loss: 2.5449604988098145
Validation loss: 2.051665206750234

Epoch: 6| Step: 4
Training loss: 2.1167044639587402
Validation loss: 2.074977219104767

Epoch: 6| Step: 5
Training loss: 1.9244194030761719
Validation loss: 2.1022018790245056

Epoch: 6| Step: 6
Training loss: 2.621613025665283
Validation loss: 2.0989080667495728

Epoch: 6| Step: 7
Training loss: 1.8577899932861328
Validation loss: 2.0910145044326782

Epoch: 6| Step: 8
Training loss: 2.3000235557556152
Validation loss: 2.0757000843683877

Epoch: 6| Step: 9
Training loss: 2.028968572616577
Validation loss: 2.0565614302953086

Epoch: 6| Step: 10
Training loss: 1.9092319011688232
Validation loss: 2.0428249835968018

Epoch: 6| Step: 11
Training loss: 2.08817720413208
Validation loss: 2.030769864718119

Epoch: 6| Step: 12
Training loss: 2.4385876655578613
Validation loss: 2.024226208527883

Epoch: 6| Step: 13
Training loss: 2.363311290740967
Validation loss: 2.026040335496267

Epoch: 70| Step: 0
Training loss: 2.1941113471984863
Validation loss: 2.0168734590212503

Epoch: 6| Step: 1
Training loss: 1.837801218032837
Validation loss: 2.0281014641126

Epoch: 6| Step: 2
Training loss: 2.4258852005004883
Validation loss: 2.0174155036608377

Epoch: 6| Step: 3
Training loss: 1.8886206150054932
Validation loss: 2.0229151248931885

Epoch: 6| Step: 4
Training loss: 2.6749958992004395
Validation loss: 2.020835061868032

Epoch: 6| Step: 5
Training loss: 1.9372766017913818
Validation loss: 2.022804041703542

Epoch: 6| Step: 6
Training loss: 2.1309218406677246
Validation loss: 2.024277687072754

Epoch: 6| Step: 7
Training loss: 1.8742051124572754
Validation loss: 2.02606733640035

Epoch: 6| Step: 8
Training loss: 2.7256460189819336
Validation loss: 2.038616398970286

Epoch: 6| Step: 9
Training loss: 2.271988868713379
Validation loss: 2.04276434580485

Epoch: 6| Step: 10
Training loss: 2.106335401535034
Validation loss: 2.04251492023468

Epoch: 6| Step: 11
Training loss: 1.8512344360351562
Validation loss: 2.048835873603821

Epoch: 6| Step: 12
Training loss: 2.0096311569213867
Validation loss: 2.04466180006663

Epoch: 6| Step: 13
Training loss: 2.9548349380493164
Validation loss: 2.0435505708058677

Epoch: 71| Step: 0
Training loss: 2.1930837631225586
Validation loss: 2.0319760839144387

Epoch: 6| Step: 1
Training loss: 2.7413716316223145
Validation loss: 2.028265416622162

Epoch: 6| Step: 2
Training loss: 2.879390239715576
Validation loss: 2.022548238436381

Epoch: 6| Step: 3
Training loss: 2.0270638465881348
Validation loss: 2.0226563612620034

Epoch: 6| Step: 4
Training loss: 2.2487311363220215
Validation loss: 2.0263293782869973

Epoch: 6| Step: 5
Training loss: 2.398430824279785
Validation loss: 2.029926300048828

Epoch: 6| Step: 6
Training loss: 1.8886666297912598
Validation loss: 2.036423603693644

Epoch: 6| Step: 7
Training loss: 1.6211254596710205
Validation loss: 2.035034934679667

Epoch: 6| Step: 8
Training loss: 1.4881585836410522
Validation loss: 2.0430140296618142

Epoch: 6| Step: 9
Training loss: 1.8159586191177368
Validation loss: 2.0479894280433655

Epoch: 6| Step: 10
Training loss: 3.1646406650543213
Validation loss: 2.0485374530156455

Epoch: 6| Step: 11
Training loss: 2.0766825675964355
Validation loss: 2.046056886514028

Epoch: 6| Step: 12
Training loss: 2.2670257091522217
Validation loss: 2.0501346786816916

Epoch: 6| Step: 13
Training loss: 2.250962734222412
Validation loss: 2.043680806954702

Epoch: 72| Step: 0
Training loss: 2.5133419036865234
Validation loss: 2.038966794808706

Epoch: 6| Step: 1
Training loss: 2.3404531478881836
Validation loss: 2.0355146527290344

Epoch: 6| Step: 2
Training loss: 1.6450872421264648
Validation loss: 2.0335127313931785

Epoch: 6| Step: 3
Training loss: 2.116936445236206
Validation loss: 2.0328669945398965

Epoch: 6| Step: 4
Training loss: 1.7147119045257568
Validation loss: 2.0244838992754617

Epoch: 6| Step: 5
Training loss: 2.277092218399048
Validation loss: 2.021535317103068

Epoch: 6| Step: 6
Training loss: 1.7236562967300415
Validation loss: 2.021272659301758

Epoch: 6| Step: 7
Training loss: 2.051525592803955
Validation loss: 2.025415559609731

Epoch: 6| Step: 8
Training loss: 2.771742820739746
Validation loss: 2.0243174036343894

Epoch: 6| Step: 9
Training loss: 2.131345748901367
Validation loss: 2.028299351533254

Epoch: 6| Step: 10
Training loss: 2.43302583694458
Validation loss: 2.032306452592214

Epoch: 6| Step: 11
Training loss: 2.708043336868286
Validation loss: 2.032341738541921

Epoch: 6| Step: 12
Training loss: 1.5933451652526855
Validation loss: 2.0412613352139792

Epoch: 6| Step: 13
Training loss: 2.3285319805145264
Validation loss: 2.059361000855764

Epoch: 73| Step: 0
Training loss: 1.833277940750122
Validation loss: 2.0725882252057395

Epoch: 6| Step: 1
Training loss: 2.475808620452881
Validation loss: 2.083925028642019

Epoch: 6| Step: 2
Training loss: 2.602206230163574
Validation loss: 2.094501773516337

Epoch: 6| Step: 3
Training loss: 1.4562478065490723
Validation loss: 2.0908897320429483

Epoch: 6| Step: 4
Training loss: 3.235267400741577
Validation loss: 2.1011576453844705

Epoch: 6| Step: 5
Training loss: 2.462127447128296
Validation loss: 2.0910158157348633

Epoch: 6| Step: 6
Training loss: 2.4888014793395996
Validation loss: 2.0755415161450705

Epoch: 6| Step: 7
Training loss: 2.2979516983032227
Validation loss: 2.0520013769467673

Epoch: 6| Step: 8
Training loss: 1.882430911064148
Validation loss: 2.040265520413717

Epoch: 6| Step: 9
Training loss: 1.9823312759399414
Validation loss: 2.029580771923065

Epoch: 6| Step: 10
Training loss: 2.5217456817626953
Validation loss: 2.0231886506080627

Epoch: 6| Step: 11
Training loss: 2.2745933532714844
Validation loss: 2.021866579850515

Epoch: 6| Step: 12
Training loss: 2.1063525676727295
Validation loss: 2.0265987316767373

Epoch: 6| Step: 13
Training loss: 1.3988773822784424
Validation loss: 2.0263938307762146

Epoch: 74| Step: 0
Training loss: 2.261151075363159
Validation loss: 2.0233317216237388

Epoch: 6| Step: 1
Training loss: 1.2766685485839844
Validation loss: 2.0275099873542786

Epoch: 6| Step: 2
Training loss: 2.183459758758545
Validation loss: 2.034841517607371

Epoch: 6| Step: 3
Training loss: 2.874222993850708
Validation loss: 2.030764579772949

Epoch: 6| Step: 4
Training loss: 2.485421657562256
Validation loss: 2.0284322102864585

Epoch: 6| Step: 5
Training loss: 1.9189600944519043
Validation loss: 2.028753916422526

Epoch: 6| Step: 6
Training loss: 2.8877716064453125
Validation loss: 2.031919757525126

Epoch: 6| Step: 7
Training loss: 2.3244314193725586
Validation loss: 2.03120489915212

Epoch: 6| Step: 8
Training loss: 2.723353862762451
Validation loss: 2.031856377919515

Epoch: 6| Step: 9
Training loss: 1.1709622144699097
Validation loss: 2.0284249583880105

Epoch: 6| Step: 10
Training loss: 2.649064540863037
Validation loss: 2.0248101154963174

Epoch: 6| Step: 11
Training loss: 1.651597499847412
Validation loss: 2.0245060324668884

Epoch: 6| Step: 12
Training loss: 1.4766066074371338
Validation loss: 2.0230908393859863

Epoch: 6| Step: 13
Training loss: 2.7339086532592773
Validation loss: 2.0213985045750937

Epoch: 75| Step: 0
Training loss: 1.8273258209228516
Validation loss: 2.0263271729151406

Epoch: 6| Step: 1
Training loss: 1.7806181907653809
Validation loss: 2.025965710481008

Epoch: 6| Step: 2
Training loss: 1.8029601573944092
Validation loss: 2.0390779972076416

Epoch: 6| Step: 3
Training loss: 2.6490237712860107
Validation loss: 2.0491823554039

Epoch: 6| Step: 4
Training loss: 2.431901216506958
Validation loss: 2.0419668356577554

Epoch: 6| Step: 5
Training loss: 1.9061589241027832
Validation loss: 2.0391677419344583

Epoch: 6| Step: 6
Training loss: 2.2737929821014404
Validation loss: 2.028240442276001

Epoch: 6| Step: 7
Training loss: 1.5848371982574463
Validation loss: 2.01744536558787

Epoch: 6| Step: 8
Training loss: 1.9171411991119385
Validation loss: 2.014597177505493

Epoch: 6| Step: 9
Training loss: 2.845214605331421
Validation loss: 2.021640658378601

Epoch: 6| Step: 10
Training loss: 2.4257709980010986
Validation loss: 2.0151875019073486

Epoch: 6| Step: 11
Training loss: 2.320643901824951
Validation loss: 2.0221301913261414

Epoch: 6| Step: 12
Training loss: 2.1517322063446045
Validation loss: 2.028741637865702

Epoch: 6| Step: 13
Training loss: 2.5667765140533447
Validation loss: 2.0211336811383567

Epoch: 76| Step: 0
Training loss: 2.185854911804199
Validation loss: 2.0275190472602844

Epoch: 6| Step: 1
Training loss: 2.188319683074951
Validation loss: 2.0271876653035483

Epoch: 6| Step: 2
Training loss: 1.8412890434265137
Validation loss: 2.029866317907969

Epoch: 6| Step: 3
Training loss: 2.040778875350952
Validation loss: 2.030986805756887

Epoch: 6| Step: 4
Training loss: 2.4204087257385254
Validation loss: 2.028679688771566

Epoch: 6| Step: 5
Training loss: 2.168272018432617
Validation loss: 2.019134442011515

Epoch: 6| Step: 6
Training loss: 2.3140878677368164
Validation loss: 2.0301575462023416

Epoch: 6| Step: 7
Training loss: 1.8539562225341797
Validation loss: 2.025903125603994

Epoch: 6| Step: 8
Training loss: 1.768237829208374
Validation loss: 2.023461083571116

Epoch: 6| Step: 9
Training loss: 2.3942062854766846
Validation loss: 2.027705192565918

Epoch: 6| Step: 10
Training loss: 2.9193265438079834
Validation loss: 2.0277505119641623

Epoch: 6| Step: 11
Training loss: 1.8828297853469849
Validation loss: 2.025676349798838

Epoch: 6| Step: 12
Training loss: 2.061985731124878
Validation loss: 2.0276015798250833

Epoch: 6| Step: 13
Training loss: 2.1938862800598145
Validation loss: 2.0298316876093545

Epoch: 77| Step: 0
Training loss: 2.3315773010253906
Validation loss: 2.021137058734894

Epoch: 6| Step: 1
Training loss: 2.1943814754486084
Validation loss: 2.0243390599886575

Epoch: 6| Step: 2
Training loss: 2.3991026878356934
Validation loss: 2.0258571108182273

Epoch: 6| Step: 3
Training loss: 2.0152058601379395
Validation loss: 2.030236542224884

Epoch: 6| Step: 4
Training loss: 1.6573736667633057
Validation loss: 2.0374197165171304

Epoch: 6| Step: 5
Training loss: 2.167346715927124
Validation loss: 2.042863051096598

Epoch: 6| Step: 6
Training loss: 2.3117127418518066
Validation loss: 2.04841148853302

Epoch: 6| Step: 7
Training loss: 2.251922607421875
Validation loss: 2.045157233874003

Epoch: 6| Step: 8
Training loss: 2.344628095626831
Validation loss: 2.050378064314524

Epoch: 6| Step: 9
Training loss: 1.615730881690979
Validation loss: 2.0347081820170083

Epoch: 6| Step: 10
Training loss: 2.3983817100524902
Validation loss: 2.0346690813700357

Epoch: 6| Step: 11
Training loss: 1.957817554473877
Validation loss: 2.034902652104696

Epoch: 6| Step: 12
Training loss: 1.830911636352539
Validation loss: 2.026047666867574

Epoch: 6| Step: 13
Training loss: 2.8365511894226074
Validation loss: 2.0254267851511636

Epoch: 78| Step: 0
Training loss: 2.6753439903259277
Validation loss: 2.028343756993612

Epoch: 6| Step: 1
Training loss: 1.895294189453125
Validation loss: 2.03200101852417

Epoch: 6| Step: 2
Training loss: 2.4500560760498047
Validation loss: 2.034695823987325

Epoch: 6| Step: 3
Training loss: 2.3068060874938965
Validation loss: 2.0368857383728027

Epoch: 6| Step: 4
Training loss: 2.7639260292053223
Validation loss: 2.0357481241226196

Epoch: 6| Step: 5
Training loss: 2.288207769393921
Validation loss: 2.037673532962799

Epoch: 6| Step: 6
Training loss: 1.5661993026733398
Validation loss: 2.037669022878011

Epoch: 6| Step: 7
Training loss: 1.9279811382293701
Validation loss: 2.0383798281351724

Epoch: 6| Step: 8
Training loss: 1.773564100265503
Validation loss: 2.0354803601900735

Epoch: 6| Step: 9
Training loss: 2.3750011920928955
Validation loss: 2.0328652461369834

Epoch: 6| Step: 10
Training loss: 1.925970196723938
Validation loss: 2.0252046386400857

Epoch: 6| Step: 11
Training loss: 1.9015848636627197
Validation loss: 2.0242266257603965

Epoch: 6| Step: 12
Training loss: 2.141822099685669
Validation loss: 2.030362586180369

Epoch: 6| Step: 13
Training loss: 2.323444366455078
Validation loss: 2.030983050664266

Epoch: 79| Step: 0
Training loss: 2.1346852779388428
Validation loss: 2.040303866068522

Epoch: 6| Step: 1
Training loss: 2.19826340675354
Validation loss: 2.038713892300924

Epoch: 6| Step: 2
Training loss: 2.254568576812744
Validation loss: 2.05102676153183

Epoch: 6| Step: 3
Training loss: 1.682456612586975
Validation loss: 2.046753168106079

Epoch: 6| Step: 4
Training loss: 2.592337131500244
Validation loss: 2.047165274620056

Epoch: 6| Step: 5
Training loss: 2.484522819519043
Validation loss: 2.052307109038035

Epoch: 6| Step: 6
Training loss: 1.9494993686676025
Validation loss: 2.0367414156595864

Epoch: 6| Step: 7
Training loss: 2.266577959060669
Validation loss: 2.0383860071500144

Epoch: 6| Step: 8
Training loss: 2.0654654502868652
Validation loss: 2.0190524061520896

Epoch: 6| Step: 9
Training loss: 2.642642021179199
Validation loss: 2.028691132863363

Epoch: 6| Step: 10
Training loss: 2.007603168487549
Validation loss: 2.030299961566925

Epoch: 6| Step: 11
Training loss: 2.466085433959961
Validation loss: 2.038483122984568

Epoch: 6| Step: 12
Training loss: 1.6050066947937012
Validation loss: 2.0307083129882812

Epoch: 6| Step: 13
Training loss: 2.1098408699035645
Validation loss: 2.0345986684163413

Epoch: 80| Step: 0
Training loss: 1.6003273725509644
Validation loss: 2.03427126010259

Epoch: 6| Step: 1
Training loss: 1.782896876335144
Validation loss: 2.0329341491063437

Epoch: 6| Step: 2
Training loss: 1.946462869644165
Validation loss: 2.0335474610328674

Epoch: 6| Step: 3
Training loss: 2.3274402618408203
Validation loss: 2.030824601650238

Epoch: 6| Step: 4
Training loss: 2.3739871978759766
Validation loss: 2.028394321600596

Epoch: 6| Step: 5
Training loss: 2.123429536819458
Validation loss: 2.0286688208580017

Epoch: 6| Step: 6
Training loss: 2.089132785797119
Validation loss: 2.0351261695226035

Epoch: 6| Step: 7
Training loss: 2.434446334838867
Validation loss: 2.03477277358373

Epoch: 6| Step: 8
Training loss: 3.0420613288879395
Validation loss: 2.0302785634994507

Epoch: 6| Step: 9
Training loss: 2.4799299240112305
Validation loss: 2.0370728969573975

Epoch: 6| Step: 10
Training loss: 1.9503536224365234
Validation loss: 2.033458868662516

Epoch: 6| Step: 11
Training loss: 2.152956962585449
Validation loss: 2.0292646884918213

Epoch: 6| Step: 12
Training loss: 2.2511069774627686
Validation loss: 2.0303927461306253

Epoch: 6| Step: 13
Training loss: 1.9834074974060059
Validation loss: 2.033642848332723

Epoch: 81| Step: 0
Training loss: 2.2361950874328613
Validation loss: 2.0277110735575357

Epoch: 6| Step: 1
Training loss: 1.8400356769561768
Validation loss: 2.0255295634269714

Epoch: 6| Step: 2
Training loss: 2.3915796279907227
Validation loss: 2.027302622795105

Epoch: 6| Step: 3
Training loss: 2.512396812438965
Validation loss: 2.0229753057161965

Epoch: 6| Step: 4
Training loss: 1.9026422500610352
Validation loss: 2.0281330943107605

Epoch: 6| Step: 5
Training loss: 1.7826006412506104
Validation loss: 2.0285092989603677

Epoch: 6| Step: 6
Training loss: 2.9321682453155518
Validation loss: 2.026446600755056

Epoch: 6| Step: 7
Training loss: 1.3491487503051758
Validation loss: 2.0365878343582153

Epoch: 6| Step: 8
Training loss: 2.347656011581421
Validation loss: 2.0399439136187234

Epoch: 6| Step: 9
Training loss: 2.645021438598633
Validation loss: 2.041173259417216

Epoch: 6| Step: 10
Training loss: 2.2717292308807373
Validation loss: 2.0444432298342385

Epoch: 6| Step: 11
Training loss: 1.2986712455749512
Validation loss: 2.052307744820913

Epoch: 6| Step: 12
Training loss: 2.0157299041748047
Validation loss: 2.046361764272054

Epoch: 6| Step: 13
Training loss: 2.434861183166504
Validation loss: 2.047153910001119

Epoch: 82| Step: 0
Training loss: 1.8893697261810303
Validation loss: 2.0471081535021463

Epoch: 6| Step: 1
Training loss: 1.8921170234680176
Validation loss: 2.051410754521688

Epoch: 6| Step: 2
Training loss: 1.9038068056106567
Validation loss: 2.055856208006541

Epoch: 6| Step: 3
Training loss: 1.7605295181274414
Validation loss: 2.044167776902517

Epoch: 6| Step: 4
Training loss: 2.4775891304016113
Validation loss: 2.0503253738085427

Epoch: 6| Step: 5
Training loss: 1.9615150690078735
Validation loss: 2.0313746134440103

Epoch: 6| Step: 6
Training loss: 2.441542387008667
Validation loss: 2.0219958225886026

Epoch: 6| Step: 7
Training loss: 2.5132689476013184
Validation loss: 2.025436758995056

Epoch: 6| Step: 8
Training loss: 2.228853225708008
Validation loss: 2.024876852830251

Epoch: 6| Step: 9
Training loss: 2.1648740768432617
Validation loss: 2.0343440572420755

Epoch: 6| Step: 10
Training loss: 2.6707377433776855
Validation loss: 2.0291945934295654

Epoch: 6| Step: 11
Training loss: 2.4834303855895996
Validation loss: 2.034408708413442

Epoch: 6| Step: 12
Training loss: 2.074432849884033
Validation loss: 2.0282769997914634

Epoch: 6| Step: 13
Training loss: 1.832610011100769
Validation loss: 2.0320181449254355

Epoch: 83| Step: 0
Training loss: 2.7262892723083496
Validation loss: 2.025722622871399

Epoch: 6| Step: 1
Training loss: 1.6178953647613525
Validation loss: 2.0271993478139243

Epoch: 6| Step: 2
Training loss: 1.930176854133606
Validation loss: 2.0254152417182922

Epoch: 6| Step: 3
Training loss: 2.212146759033203
Validation loss: 2.0236737529436746

Epoch: 6| Step: 4
Training loss: 1.9802584648132324
Validation loss: 2.0238656202952066

Epoch: 6| Step: 5
Training loss: 2.418764591217041
Validation loss: 2.022293428579966

Epoch: 6| Step: 6
Training loss: 2.303314685821533
Validation loss: 2.0222665468851724

Epoch: 6| Step: 7
Training loss: 2.0704007148742676
Validation loss: 2.0229959885279336

Epoch: 6| Step: 8
Training loss: 1.9579544067382812
Validation loss: 2.01937202612559

Epoch: 6| Step: 9
Training loss: 2.100538730621338
Validation loss: 2.0131304462750754

Epoch: 6| Step: 10
Training loss: 1.893090844154358
Validation loss: 2.014655272165934

Epoch: 6| Step: 11
Training loss: 2.1155049800872803
Validation loss: 2.0187629659970603

Epoch: 6| Step: 12
Training loss: 2.6181044578552246
Validation loss: 2.023981511592865

Epoch: 6| Step: 13
Training loss: 2.430077075958252
Validation loss: 2.0164499282836914

Epoch: 84| Step: 0
Training loss: 1.9180982112884521
Validation loss: 2.013735552628835

Epoch: 6| Step: 1
Training loss: 2.1142454147338867
Validation loss: 2.0158631602923074

Epoch: 6| Step: 2
Training loss: 1.9616847038269043
Validation loss: 2.0264931321144104

Epoch: 6| Step: 3
Training loss: 2.5512237548828125
Validation loss: 2.0340176224708557

Epoch: 6| Step: 4
Training loss: 2.10374116897583
Validation loss: 2.0301424066225686

Epoch: 6| Step: 5
Training loss: 2.4223127365112305
Validation loss: 2.0279995997746787

Epoch: 6| Step: 6
Training loss: 2.0818819999694824
Validation loss: 2.0317670702934265

Epoch: 6| Step: 7
Training loss: 1.5603702068328857
Validation loss: 2.02838671207428

Epoch: 6| Step: 8
Training loss: 2.9588136672973633
Validation loss: 2.0207587281862893

Epoch: 6| Step: 9
Training loss: 1.8308361768722534
Validation loss: 2.0213693579037986

Epoch: 6| Step: 10
Training loss: 2.0441150665283203
Validation loss: 2.018287936846415

Epoch: 6| Step: 11
Training loss: 2.0165865421295166
Validation loss: 2.011306047439575

Epoch: 6| Step: 12
Training loss: 2.032639265060425
Validation loss: 2.019529620806376

Epoch: 6| Step: 13
Training loss: 2.794590711593628
Validation loss: 2.0182137489318848

Epoch: 85| Step: 0
Training loss: 1.4983018636703491
Validation loss: 2.025700887044271

Epoch: 6| Step: 1
Training loss: 2.3481361865997314
Validation loss: 2.0211923519770303

Epoch: 6| Step: 2
Training loss: 2.1270837783813477
Validation loss: 2.0246907075246177

Epoch: 6| Step: 3
Training loss: 2.1606242656707764
Validation loss: 2.024141252040863

Epoch: 6| Step: 4
Training loss: 2.525569200515747
Validation loss: 2.0231932004292807

Epoch: 6| Step: 5
Training loss: 1.7873189449310303
Validation loss: 2.025442282358805

Epoch: 6| Step: 6
Training loss: 2.5267081260681152
Validation loss: 2.0253146290779114

Epoch: 6| Step: 7
Training loss: 2.2751026153564453
Validation loss: 2.024825096130371

Epoch: 6| Step: 8
Training loss: 2.5095863342285156
Validation loss: 2.0246349374453225

Epoch: 6| Step: 9
Training loss: 2.139869451522827
Validation loss: 2.0224061806996665

Epoch: 6| Step: 10
Training loss: 2.2902767658233643
Validation loss: 2.023133377234141

Epoch: 6| Step: 11
Training loss: 1.958485722541809
Validation loss: 2.023197372754415

Epoch: 6| Step: 12
Training loss: 2.2959365844726562
Validation loss: 2.0215253035227456

Epoch: 6| Step: 13
Training loss: 1.8113024234771729
Validation loss: 2.0223058263460794

Epoch: 86| Step: 0
Training loss: 1.7082968950271606
Validation loss: 2.023167391618093

Epoch: 6| Step: 1
Training loss: 1.9104893207550049
Validation loss: 2.02174703280131

Epoch: 6| Step: 2
Training loss: 1.958068609237671
Validation loss: 2.0409910082817078

Epoch: 6| Step: 3
Training loss: 2.1160330772399902
Validation loss: 2.0463335712750754

Epoch: 6| Step: 4
Training loss: 2.0572619438171387
Validation loss: 2.0498910943667092

Epoch: 6| Step: 5
Training loss: 2.367828369140625
Validation loss: 2.0509446461995444

Epoch: 6| Step: 6
Training loss: 2.0420093536376953
Validation loss: 2.0461636781692505

Epoch: 6| Step: 7
Training loss: 2.223703145980835
Validation loss: 2.0353415807088218

Epoch: 6| Step: 8
Training loss: 1.6877301931381226
Validation loss: 2.0356814861297607

Epoch: 6| Step: 9
Training loss: 2.554692268371582
Validation loss: 2.032643993695577

Epoch: 6| Step: 10
Training loss: 2.4496612548828125
Validation loss: 2.0191677014033

Epoch: 6| Step: 11
Training loss: 2.342278480529785
Validation loss: 2.018599033355713

Epoch: 6| Step: 12
Training loss: 2.372030019760132
Validation loss: 2.011235217253367

Epoch: 6| Step: 13
Training loss: 2.484804630279541
Validation loss: 2.016156812508901

Epoch: 87| Step: 0
Training loss: 2.5719587802886963
Validation loss: 2.0239176551500955

Epoch: 6| Step: 1
Training loss: 2.4261574745178223
Validation loss: 2.0256283481915793

Epoch: 6| Step: 2
Training loss: 1.8059614896774292
Validation loss: 2.0324307481447854

Epoch: 6| Step: 3
Training loss: 2.8491241931915283
Validation loss: 2.030150532722473

Epoch: 6| Step: 4
Training loss: 2.5254743099212646
Validation loss: 2.0314725836118064

Epoch: 6| Step: 5
Training loss: 1.6588445901870728
Validation loss: 2.0366735259691873

Epoch: 6| Step: 6
Training loss: 2.0606682300567627
Validation loss: 2.03430438041687

Epoch: 6| Step: 7
Training loss: 1.7935242652893066
Validation loss: 2.029200275739034

Epoch: 6| Step: 8
Training loss: 1.7793481349945068
Validation loss: 2.029476006825765

Epoch: 6| Step: 9
Training loss: 2.1282410621643066
Validation loss: 2.0298999349276223

Epoch: 6| Step: 10
Training loss: 3.0624585151672363
Validation loss: 2.0274941325187683

Epoch: 6| Step: 11
Training loss: 1.6831036806106567
Validation loss: 2.022940476735433

Epoch: 6| Step: 12
Training loss: 2.7047300338745117
Validation loss: 2.0241406162579856

Epoch: 6| Step: 13
Training loss: 1.3811795711517334
Validation loss: 2.020337760448456

Epoch: 88| Step: 0
Training loss: 1.980077862739563
Validation loss: 2.0205418268839517

Epoch: 6| Step: 1
Training loss: 1.8907713890075684
Validation loss: 2.0193686485290527

Epoch: 6| Step: 2
Training loss: 2.2339651584625244
Validation loss: 2.020932674407959

Epoch: 6| Step: 3
Training loss: 2.4271695613861084
Validation loss: 2.023859441280365

Epoch: 6| Step: 4
Training loss: 2.016568899154663
Validation loss: 2.0169670780499778

Epoch: 6| Step: 5
Training loss: 1.8173800706863403
Validation loss: 2.018755793571472

Epoch: 6| Step: 6
Training loss: 2.053023099899292
Validation loss: 2.0155365665753684

Epoch: 6| Step: 7
Training loss: 1.8121016025543213
Validation loss: 2.016668736934662

Epoch: 6| Step: 8
Training loss: 2.241427421569824
Validation loss: 2.0124303499857583

Epoch: 6| Step: 9
Training loss: 2.609675884246826
Validation loss: 2.0173951586087546

Epoch: 6| Step: 10
Training loss: 2.045154333114624
Validation loss: 2.0252078572909036

Epoch: 6| Step: 11
Training loss: 2.5749874114990234
Validation loss: 2.0122166077295938

Epoch: 6| Step: 12
Training loss: 2.513704538345337
Validation loss: 2.0213610529899597

Epoch: 6| Step: 13
Training loss: 1.8646886348724365
Validation loss: 2.0277427633603415

Epoch: 89| Step: 0
Training loss: 1.977163553237915
Validation loss: 2.025855541229248

Epoch: 6| Step: 1
Training loss: 2.345033645629883
Validation loss: 2.0203603506088257

Epoch: 6| Step: 2
Training loss: 2.0283050537109375
Validation loss: 2.030430575211843

Epoch: 6| Step: 3
Training loss: 2.378264904022217
Validation loss: 2.018668254216512

Epoch: 6| Step: 4
Training loss: 1.98630690574646
Validation loss: 2.0272845029830933

Epoch: 6| Step: 5
Training loss: 2.1326122283935547
Validation loss: 2.0274832248687744

Epoch: 6| Step: 6
Training loss: 1.5199642181396484
Validation loss: 2.0270718137423196

Epoch: 6| Step: 7
Training loss: 2.923595428466797
Validation loss: 2.020702381928762

Epoch: 6| Step: 8
Training loss: 2.3466057777404785
Validation loss: 2.028741101423899

Epoch: 6| Step: 9
Training loss: 1.7636067867279053
Validation loss: 2.0307744344075522

Epoch: 6| Step: 10
Training loss: 2.6274495124816895
Validation loss: 2.0294118920962014

Epoch: 6| Step: 11
Training loss: 1.629638433456421
Validation loss: 2.029127856095632

Epoch: 6| Step: 12
Training loss: 2.212521553039551
Validation loss: 2.027308146158854

Epoch: 6| Step: 13
Training loss: 2.0293071269989014
Validation loss: 2.024758537610372

Epoch: 90| Step: 0
Training loss: 1.8071470260620117
Validation loss: 2.0212939778963723

Epoch: 6| Step: 1
Training loss: 2.288726329803467
Validation loss: 2.019984722137451

Epoch: 6| Step: 2
Training loss: 2.184170961380005
Validation loss: 2.025226593017578

Epoch: 6| Step: 3
Training loss: 2.4660534858703613
Validation loss: 2.023240009943644

Epoch: 6| Step: 4
Training loss: 2.5597105026245117
Validation loss: 2.027638057867686

Epoch: 6| Step: 5
Training loss: 1.461126446723938
Validation loss: 2.023228883743286

Epoch: 6| Step: 6
Training loss: 2.3984580039978027
Validation loss: 2.026232441266378

Epoch: 6| Step: 7
Training loss: 2.320014476776123
Validation loss: 2.020399272441864

Epoch: 6| Step: 8
Training loss: 1.9721460342407227
Validation loss: 2.0215176939964294

Epoch: 6| Step: 9
Training loss: 2.018031597137451
Validation loss: 2.015280306339264

Epoch: 6| Step: 10
Training loss: 2.405869722366333
Validation loss: 2.0234568317731223

Epoch: 6| Step: 11
Training loss: 1.9556673765182495
Validation loss: 2.0229100783665976

Epoch: 6| Step: 12
Training loss: 2.056216239929199
Validation loss: 2.0252829591433206

Epoch: 6| Step: 13
Training loss: 2.030792474746704
Validation loss: 2.0187014738718667

Epoch: 91| Step: 0
Training loss: 2.0299344062805176
Validation loss: 2.030654470125834

Epoch: 6| Step: 1
Training loss: 2.3059239387512207
Validation loss: 2.033504764238993

Epoch: 6| Step: 2
Training loss: 2.7154834270477295
Validation loss: 2.0324627161026

Epoch: 6| Step: 3
Training loss: 2.008305072784424
Validation loss: 2.0341909527778625

Epoch: 6| Step: 4
Training loss: 1.7585021257400513
Validation loss: 2.0283928910891214

Epoch: 6| Step: 5
Training loss: 2.293067455291748
Validation loss: 2.034539222717285

Epoch: 6| Step: 6
Training loss: 1.9342350959777832
Validation loss: 2.024411221345266

Epoch: 6| Step: 7
Training loss: 2.521850347518921
Validation loss: 2.0229875644048056

Epoch: 6| Step: 8
Training loss: 2.5803773403167725
Validation loss: 2.020461102326711

Epoch: 6| Step: 9
Training loss: 2.4309821128845215
Validation loss: 2.0246381163597107

Epoch: 6| Step: 10
Training loss: 2.071969985961914
Validation loss: 2.0260454217592874

Epoch: 6| Step: 11
Training loss: 1.7571004629135132
Validation loss: 2.023365537325541

Epoch: 6| Step: 12
Training loss: 1.4991778135299683
Validation loss: 2.0230119228363037

Epoch: 6| Step: 13
Training loss: 1.8490232229232788
Validation loss: 2.022244175275167

Epoch: 92| Step: 0
Training loss: 1.8694828748703003
Validation loss: 2.023408571879069

Epoch: 6| Step: 1
Training loss: 2.0398693084716797
Validation loss: 2.0197264750798545

Epoch: 6| Step: 2
Training loss: 2.3284730911254883
Validation loss: 2.0196133057276406

Epoch: 6| Step: 3
Training loss: 1.957231044769287
Validation loss: 2.019642472267151

Epoch: 6| Step: 4
Training loss: 2.1189565658569336
Validation loss: 2.02085679769516

Epoch: 6| Step: 5
Training loss: 2.0815792083740234
Validation loss: 2.0236334800720215

Epoch: 6| Step: 6
Training loss: 2.3277130126953125
Validation loss: 2.027236898740133

Epoch: 6| Step: 7
Training loss: 2.4620442390441895
Validation loss: 2.0232499043146768

Epoch: 6| Step: 8
Training loss: 1.457554578781128
Validation loss: 2.028129776318868

Epoch: 6| Step: 9
Training loss: 2.7847421169281006
Validation loss: 2.035807251930237

Epoch: 6| Step: 10
Training loss: 2.167788028717041
Validation loss: 2.0302959084510803

Epoch: 6| Step: 11
Training loss: 1.9083783626556396
Validation loss: 2.0438102881113687

Epoch: 6| Step: 12
Training loss: 2.1175036430358887
Validation loss: 2.049033006032308

Epoch: 6| Step: 13
Training loss: 2.2086122035980225
Validation loss: 2.0481417576471963

Epoch: 93| Step: 0
Training loss: 2.008396625518799
Validation loss: 2.034012575944265

Epoch: 6| Step: 1
Training loss: 1.813231110572815
Validation loss: 2.039279321829478

Epoch: 6| Step: 2
Training loss: 2.3994431495666504
Validation loss: 2.0244548320770264

Epoch: 6| Step: 3
Training loss: 2.214867115020752
Validation loss: 2.032522221406301

Epoch: 6| Step: 4
Training loss: 2.2825217247009277
Validation loss: 2.02640171845754

Epoch: 6| Step: 5
Training loss: 1.8316816091537476
Validation loss: 2.015556514263153

Epoch: 6| Step: 6
Training loss: 2.716008424758911
Validation loss: 2.015016476313273

Epoch: 6| Step: 7
Training loss: 2.1358046531677246
Validation loss: 2.0173378388086953

Epoch: 6| Step: 8
Training loss: 2.0984411239624023
Validation loss: 2.01746674378713

Epoch: 6| Step: 9
Training loss: 2.3987679481506348
Validation loss: 2.0142409801483154

Epoch: 6| Step: 10
Training loss: 2.099658966064453
Validation loss: 2.021118481953939

Epoch: 6| Step: 11
Training loss: 1.9657747745513916
Validation loss: 2.0225622256596885

Epoch: 6| Step: 12
Training loss: 1.8042335510253906
Validation loss: 2.026430527369181

Epoch: 6| Step: 13
Training loss: 2.2394723892211914
Validation loss: 2.0257823864618936

Epoch: 94| Step: 0
Training loss: 2.1831412315368652
Validation loss: 2.0230132341384888

Epoch: 6| Step: 1
Training loss: 2.123824119567871
Validation loss: 2.0191372831662497

Epoch: 6| Step: 2
Training loss: 2.3636131286621094
Validation loss: 2.011641502380371

Epoch: 6| Step: 3
Training loss: 2.172900915145874
Validation loss: 2.0193457206090293

Epoch: 6| Step: 4
Training loss: 2.530454635620117
Validation loss: 2.017840484778086

Epoch: 6| Step: 5
Training loss: 2.388406753540039
Validation loss: 2.0230252742767334

Epoch: 6| Step: 6
Training loss: 1.7312196493148804
Validation loss: 2.0205285946528115

Epoch: 6| Step: 7
Training loss: 1.8653796911239624
Validation loss: 2.0278386871019998

Epoch: 6| Step: 8
Training loss: 1.9583619832992554
Validation loss: 2.0231817762056985

Epoch: 6| Step: 9
Training loss: 1.6829149723052979
Validation loss: 2.0253851811091104

Epoch: 6| Step: 10
Training loss: 2.4631285667419434
Validation loss: 2.027127464612325

Epoch: 6| Step: 11
Training loss: 2.3832125663757324
Validation loss: 2.0323290824890137

Epoch: 6| Step: 12
Training loss: 2.106938362121582
Validation loss: 2.031367540359497

Epoch: 6| Step: 13
Training loss: 1.864808201789856
Validation loss: 2.026457130908966

Epoch: 95| Step: 0
Training loss: 2.06496000289917
Validation loss: 2.0205119252204895

Epoch: 6| Step: 1
Training loss: 2.482513904571533
Validation loss: 2.0269983609517417

Epoch: 6| Step: 2
Training loss: 2.0932464599609375
Validation loss: 2.0306542913118997

Epoch: 6| Step: 3
Training loss: 2.863955020904541
Validation loss: 2.031460960706075

Epoch: 6| Step: 4
Training loss: 2.1563119888305664
Validation loss: 2.037020126978556

Epoch: 6| Step: 5
Training loss: 2.564147472381592
Validation loss: 2.0322230458259583

Epoch: 6| Step: 6
Training loss: 2.0117011070251465
Validation loss: 2.0288557410240173

Epoch: 6| Step: 7
Training loss: 2.1631579399108887
Validation loss: 2.025179306666056

Epoch: 6| Step: 8
Training loss: 1.8501781225204468
Validation loss: 2.02553121248881

Epoch: 6| Step: 9
Training loss: 1.966598629951477
Validation loss: 2.032297670841217

Epoch: 6| Step: 10
Training loss: 1.498072862625122
Validation loss: 2.031312028566996

Epoch: 6| Step: 11
Training loss: 1.9660699367523193
Validation loss: 2.028504272301992

Epoch: 6| Step: 12
Training loss: 1.8578373193740845
Validation loss: 2.03608500957489

Epoch: 6| Step: 13
Training loss: 2.216911792755127
Validation loss: 2.026305139064789

Epoch: 96| Step: 0
Training loss: 1.9969736337661743
Validation loss: 2.036193291346232

Epoch: 6| Step: 1
Training loss: 2.315523862838745
Validation loss: 2.0332824985186257

Epoch: 6| Step: 2
Training loss: 1.985781192779541
Validation loss: 2.039480209350586

Epoch: 6| Step: 3
Training loss: 1.734321117401123
Validation loss: 2.045277714729309

Epoch: 6| Step: 4
Training loss: 2.1831912994384766
Validation loss: 2.043360114097595

Epoch: 6| Step: 5
Training loss: 2.2487800121307373
Validation loss: 2.0557548801104226

Epoch: 6| Step: 6
Training loss: 2.613983631134033
Validation loss: 2.0576932231585183

Epoch: 6| Step: 7
Training loss: 2.2954742908477783
Validation loss: 2.0518160661061606

Epoch: 6| Step: 8
Training loss: 2.2446186542510986
Validation loss: 2.0510794123013816

Epoch: 6| Step: 9
Training loss: 2.0719518661499023
Validation loss: 2.0443200866381326

Epoch: 6| Step: 10
Training loss: 2.0927681922912598
Validation loss: 2.037622630596161

Epoch: 6| Step: 11
Training loss: 2.212371826171875
Validation loss: 2.0329949855804443

Epoch: 6| Step: 12
Training loss: 1.9769917726516724
Validation loss: 2.0308250188827515

Epoch: 6| Step: 13
Training loss: 2.0035347938537598
Validation loss: 2.031496604283651

Epoch: 97| Step: 0
Training loss: 1.8873579502105713
Validation loss: 2.0266732374827066

Epoch: 6| Step: 1
Training loss: 2.963496446609497
Validation loss: 2.023743828137716

Epoch: 6| Step: 2
Training loss: 2.4889869689941406
Validation loss: 2.0268234610557556

Epoch: 6| Step: 3
Training loss: 2.0549826622009277
Validation loss: 2.024657050768534

Epoch: 6| Step: 4
Training loss: 2.6441125869750977
Validation loss: 2.027069648106893

Epoch: 6| Step: 5
Training loss: 1.8538321256637573
Validation loss: 2.034483333428701

Epoch: 6| Step: 6
Training loss: 2.1736042499542236
Validation loss: 2.038218140602112

Epoch: 6| Step: 7
Training loss: 1.7415087223052979
Validation loss: 2.040240486462911

Epoch: 6| Step: 8
Training loss: 1.7660748958587646
Validation loss: 2.0449547370274863

Epoch: 6| Step: 9
Training loss: 2.51739501953125
Validation loss: 2.047385652860006

Epoch: 6| Step: 10
Training loss: 1.9104282855987549
Validation loss: 2.032297054926554

Epoch: 6| Step: 11
Training loss: 1.5924367904663086
Validation loss: 2.034123957157135

Epoch: 6| Step: 12
Training loss: 2.325556755065918
Validation loss: 2.028623382250468

Epoch: 6| Step: 13
Training loss: 2.002470016479492
Validation loss: 2.023586889108022

Epoch: 98| Step: 0
Training loss: 1.9676802158355713
Validation loss: 2.024487853050232

Epoch: 6| Step: 1
Training loss: 1.7932779788970947
Validation loss: 2.0265976190567017

Epoch: 6| Step: 2
Training loss: 1.7219877243041992
Validation loss: 2.014784097671509

Epoch: 6| Step: 3
Training loss: 2.3613462448120117
Validation loss: 2.0301817059516907

Epoch: 6| Step: 4
Training loss: 2.3627846240997314
Validation loss: 2.024203916390737

Epoch: 6| Step: 5
Training loss: 2.3187062740325928
Validation loss: 2.0427818298339844

Epoch: 6| Step: 6
Training loss: 2.4131808280944824
Validation loss: 2.0407270987828574

Epoch: 6| Step: 7
Training loss: 2.1484007835388184
Validation loss: 2.0361934105555215

Epoch: 6| Step: 8
Training loss: 2.0518798828125
Validation loss: 2.031909982363383

Epoch: 6| Step: 9
Training loss: 1.87399423122406
Validation loss: 2.0330660740534463

Epoch: 6| Step: 10
Training loss: 2.3834972381591797
Validation loss: 2.0424991846084595

Epoch: 6| Step: 11
Training loss: 2.366792678833008
Validation loss: 2.0312072237332663

Epoch: 6| Step: 12
Training loss: 1.9657931327819824
Validation loss: 2.0283252596855164

Epoch: 6| Step: 13
Training loss: 1.9264792203903198
Validation loss: 2.0238715012868247

Epoch: 99| Step: 0
Training loss: 2.3262991905212402
Validation loss: 2.019576072692871

Epoch: 6| Step: 1
Training loss: 1.9072072505950928
Validation loss: 2.0217132369677224

Epoch: 6| Step: 2
Training loss: 2.5233373641967773
Validation loss: 2.022867182890574

Epoch: 6| Step: 3
Training loss: 1.6296744346618652
Validation loss: 2.026171088218689

Epoch: 6| Step: 4
Training loss: 2.180927276611328
Validation loss: 2.018192251523336

Epoch: 6| Step: 5
Training loss: 2.3149971961975098
Validation loss: 2.018049200375875

Epoch: 6| Step: 6
Training loss: 1.594460129737854
Validation loss: 2.0257679224014282

Epoch: 6| Step: 7
Training loss: 2.333420753479004
Validation loss: 2.024925410747528

Epoch: 6| Step: 8
Training loss: 1.981979489326477
Validation loss: 2.0144608418146768

Epoch: 6| Step: 9
Training loss: 2.3271892070770264
Validation loss: 2.013715386390686

Epoch: 6| Step: 10
Training loss: 3.004891872406006
Validation loss: 2.0197947025299072

Epoch: 6| Step: 11
Training loss: 1.67657470703125
Validation loss: 2.0140377084414163

Epoch: 6| Step: 12
Training loss: 1.8322921991348267
Validation loss: 2.0125115116437278

Epoch: 6| Step: 13
Training loss: 2.090787410736084
Validation loss: 2.014928181966146

Epoch: 100| Step: 0
Training loss: 2.3970189094543457
Validation loss: 2.0132724046707153

Epoch: 6| Step: 1
Training loss: 2.767947196960449
Validation loss: 2.017663558324178

Epoch: 6| Step: 2
Training loss: 1.574401617050171
Validation loss: 2.0192203720410666

Epoch: 6| Step: 3
Training loss: 1.8147170543670654
Validation loss: 2.020507832368215

Epoch: 6| Step: 4
Training loss: 1.9739264249801636
Validation loss: 2.018623431523641

Epoch: 6| Step: 5
Training loss: 2.1632494926452637
Validation loss: 2.02107701698939

Epoch: 6| Step: 6
Training loss: 2.613377094268799
Validation loss: 2.0179941058158875

Epoch: 6| Step: 7
Training loss: 2.3093748092651367
Validation loss: 2.0209380388259888

Epoch: 6| Step: 8
Training loss: 1.8240907192230225
Validation loss: 2.0257694522539773

Epoch: 6| Step: 9
Training loss: 1.9743918180465698
Validation loss: 2.0303132136662803

Epoch: 6| Step: 10
Training loss: 2.497462749481201
Validation loss: 2.0337839921315513

Epoch: 6| Step: 11
Training loss: 1.8885115385055542
Validation loss: 2.031632661819458

Epoch: 6| Step: 12
Training loss: 1.7184052467346191
Validation loss: 2.0264015793800354

Epoch: 6| Step: 13
Training loss: 2.092088222503662
Validation loss: 2.0200124780337014

Epoch: 101| Step: 0
Training loss: 2.1360831260681152
Validation loss: 2.0266644954681396

Epoch: 6| Step: 1
Training loss: 1.8202714920043945
Validation loss: 2.027009050051371

Epoch: 6| Step: 2
Training loss: 1.9139386415481567
Validation loss: 2.0291383465131125

Epoch: 6| Step: 3
Training loss: 2.301640033721924
Validation loss: 2.0223865111668906

Epoch: 6| Step: 4
Training loss: 2.0057551860809326
Validation loss: 2.0183247725168862

Epoch: 6| Step: 5
Training loss: 2.5951576232910156
Validation loss: 2.025492310523987

Epoch: 6| Step: 6
Training loss: 2.170400857925415
Validation loss: 2.0314178466796875

Epoch: 6| Step: 7
Training loss: 2.657805919647217
Validation loss: 2.020508289337158

Epoch: 6| Step: 8
Training loss: 2.0397963523864746
Validation loss: 2.0169349114100137

Epoch: 6| Step: 9
Training loss: 1.9148086309432983
Validation loss: 2.026785890261332

Epoch: 6| Step: 10
Training loss: 2.029411554336548
Validation loss: 2.02502832810084

Epoch: 6| Step: 11
Training loss: 1.868089199066162
Validation loss: 2.034040868282318

Epoch: 6| Step: 12
Training loss: 2.306016445159912
Validation loss: 2.0209885636965432

Epoch: 6| Step: 13
Training loss: 1.7691359519958496
Validation loss: 2.0293243726094565

Epoch: 102| Step: 0
Training loss: 1.8958545923233032
Validation loss: 2.025701959927877

Epoch: 6| Step: 1
Training loss: 1.9748530387878418
Validation loss: 2.020894487698873

Epoch: 6| Step: 2
Training loss: 1.8936655521392822
Validation loss: 2.029454310735067

Epoch: 6| Step: 3
Training loss: 1.5050355195999146
Validation loss: 2.0247371395428977

Epoch: 6| Step: 4
Training loss: 2.490987539291382
Validation loss: 2.025266965230306

Epoch: 6| Step: 5
Training loss: 2.2847893238067627
Validation loss: 2.023619552453359

Epoch: 6| Step: 6
Training loss: 2.6593422889709473
Validation loss: 2.023179531097412

Epoch: 6| Step: 7
Training loss: 2.7605621814727783
Validation loss: 2.0290236274401345

Epoch: 6| Step: 8
Training loss: 1.9780964851379395
Validation loss: 2.0265718698501587

Epoch: 6| Step: 9
Training loss: 1.880938172340393
Validation loss: 2.0260032018025718

Epoch: 6| Step: 10
Training loss: 2.427997589111328
Validation loss: 2.026102602481842

Epoch: 6| Step: 11
Training loss: 1.7429065704345703
Validation loss: 2.0336034297943115

Epoch: 6| Step: 12
Training loss: 1.8651551008224487
Validation loss: 2.019684076309204

Epoch: 6| Step: 13
Training loss: 2.1764798164367676
Validation loss: 2.0194472670555115

Epoch: 103| Step: 0
Training loss: 1.9802446365356445
Validation loss: 2.0241432388623557

Epoch: 6| Step: 1
Training loss: 1.5556490421295166
Validation loss: 2.026094615459442

Epoch: 6| Step: 2
Training loss: 2.0813651084899902
Validation loss: 2.0247624715169272

Epoch: 6| Step: 3
Training loss: 2.4233016967773438
Validation loss: 2.019672234853109

Epoch: 6| Step: 4
Training loss: 2.253572940826416
Validation loss: 2.0278746684392295

Epoch: 6| Step: 5
Training loss: 2.2090585231781006
Validation loss: 2.02316951751709

Epoch: 6| Step: 6
Training loss: 1.991471290588379
Validation loss: 2.0228398044904075

Epoch: 6| Step: 7
Training loss: 1.57930326461792
Validation loss: 2.024813691775004

Epoch: 6| Step: 8
Training loss: 2.0822832584381104
Validation loss: 2.0291190346082053

Epoch: 6| Step: 9
Training loss: 2.5311965942382812
Validation loss: 2.0204121470451355

Epoch: 6| Step: 10
Training loss: 1.706930160522461
Validation loss: 2.0194621682167053

Epoch: 6| Step: 11
Training loss: 2.529536247253418
Validation loss: 2.0224993427594504

Epoch: 6| Step: 12
Training loss: 2.5011940002441406
Validation loss: 2.021469831466675

Epoch: 6| Step: 13
Training loss: 2.1710667610168457
Validation loss: 2.022453546524048

Epoch: 104| Step: 0
Training loss: 2.6007027626037598
Validation loss: 2.0243186155954995

Epoch: 6| Step: 1
Training loss: 1.5369254350662231
Validation loss: 2.022532602151235

Epoch: 6| Step: 2
Training loss: 2.5160903930664062
Validation loss: 2.039656400680542

Epoch: 6| Step: 3
Training loss: 2.737107992172241
Validation loss: 2.0353461702664695

Epoch: 6| Step: 4
Training loss: 1.7002596855163574
Validation loss: 2.025529205799103

Epoch: 6| Step: 5
Training loss: 2.2189948558807373
Validation loss: 2.024174670378367

Epoch: 6| Step: 6
Training loss: 2.3186233043670654
Validation loss: 2.0323996941248574

Epoch: 6| Step: 7
Training loss: 1.6501610279083252
Validation loss: 2.0289145509401956

Epoch: 6| Step: 8
Training loss: 2.149510383605957
Validation loss: 2.0192590157190957

Epoch: 6| Step: 9
Training loss: 2.3178601264953613
Validation loss: 2.0227033495903015

Epoch: 6| Step: 10
Training loss: 1.8672951459884644
Validation loss: 2.027082880338033

Epoch: 6| Step: 11
Training loss: 2.2964165210723877
Validation loss: 2.0162806709607444

Epoch: 6| Step: 12
Training loss: 1.7779216766357422
Validation loss: 2.018035411834717

Epoch: 6| Step: 13
Training loss: 1.9735147953033447
Validation loss: 2.021545092264811

Epoch: 105| Step: 0
Training loss: 2.082296133041382
Validation loss: 2.0110211769739785

Epoch: 6| Step: 1
Training loss: 1.6498502492904663
Validation loss: 2.002766708532969

Epoch: 6| Step: 2
Training loss: 2.2160682678222656
Validation loss: 2.0177942514419556

Epoch: 6| Step: 3
Training loss: 2.4112610816955566
Validation loss: 2.0149873892466226

Epoch: 6| Step: 4
Training loss: 2.0014870166778564
Validation loss: 2.0203393499056497

Epoch: 6| Step: 5
Training loss: 2.227487802505493
Validation loss: 2.0237638354301453

Epoch: 6| Step: 6
Training loss: 1.2610230445861816
Validation loss: 2.0261708895365396

Epoch: 6| Step: 7
Training loss: 2.4715335369110107
Validation loss: 2.0203192234039307

Epoch: 6| Step: 8
Training loss: 2.616730213165283
Validation loss: 2.0279283126195273

Epoch: 6| Step: 9
Training loss: 1.7870373725891113
Validation loss: 2.028584619363149

Epoch: 6| Step: 10
Training loss: 2.6011345386505127
Validation loss: 2.0360241731007895

Epoch: 6| Step: 11
Training loss: 2.087682008743286
Validation loss: 2.0360418359438577

Epoch: 6| Step: 12
Training loss: 1.6845111846923828
Validation loss: 2.037260055541992

Epoch: 6| Step: 13
Training loss: 2.3648557662963867
Validation loss: 2.0387951930363974

Epoch: 106| Step: 0
Training loss: 2.3145084381103516
Validation loss: 2.036111613114675

Epoch: 6| Step: 1
Training loss: 2.291457176208496
Validation loss: 2.029251058896383

Epoch: 6| Step: 2
Training loss: 1.9611936807632446
Validation loss: 2.027900755405426

Epoch: 6| Step: 3
Training loss: 2.04221773147583
Validation loss: 2.018904427687327

Epoch: 6| Step: 4
Training loss: 1.9928691387176514
Validation loss: 2.0219186345736184

Epoch: 6| Step: 5
Training loss: 1.4088690280914307
Validation loss: 2.0264687140782676

Epoch: 6| Step: 6
Training loss: 2.4921040534973145
Validation loss: 2.017165720462799

Epoch: 6| Step: 7
Training loss: 2.376826763153076
Validation loss: 2.0216687520345054

Epoch: 6| Step: 8
Training loss: 2.092402935028076
Validation loss: 2.0191457668940225

Epoch: 6| Step: 9
Training loss: 2.6536645889282227
Validation loss: 2.0267823537190757

Epoch: 6| Step: 10
Training loss: 1.6232075691223145
Validation loss: 2.026023030281067

Epoch: 6| Step: 11
Training loss: 2.506685256958008
Validation loss: 2.0235676964124045

Epoch: 6| Step: 12
Training loss: 1.7802772521972656
Validation loss: 2.0237058202425637

Epoch: 6| Step: 13
Training loss: 1.9216432571411133
Validation loss: 2.0239164233207703

Epoch: 107| Step: 0
Training loss: 2.0215721130371094
Validation loss: 2.0247750679651895

Epoch: 6| Step: 1
Training loss: 1.9184962511062622
Validation loss: 2.0237617095311484

Epoch: 6| Step: 2
Training loss: 2.726473808288574
Validation loss: 2.0251476168632507

Epoch: 6| Step: 3
Training loss: 2.194373607635498
Validation loss: 2.0238187114397683

Epoch: 6| Step: 4
Training loss: 2.0212907791137695
Validation loss: 2.0243600606918335

Epoch: 6| Step: 5
Training loss: 2.2660038471221924
Validation loss: 2.0232089360555015

Epoch: 6| Step: 6
Training loss: 1.9184513092041016
Validation loss: 2.016096552213033

Epoch: 6| Step: 7
Training loss: 2.0632505416870117
Validation loss: 2.012543022632599

Epoch: 6| Step: 8
Training loss: 1.9528499841690063
Validation loss: 2.0063351591428122

Epoch: 6| Step: 9
Training loss: 2.174055576324463
Validation loss: 2.013748129208883

Epoch: 6| Step: 10
Training loss: 1.7140223979949951
Validation loss: 2.0250794291496277

Epoch: 6| Step: 11
Training loss: 1.8864402770996094
Validation loss: 2.0251068472862244

Epoch: 6| Step: 12
Training loss: 2.805222511291504
Validation loss: 2.0293581088383994

Epoch: 6| Step: 13
Training loss: 1.7192394733428955
Validation loss: 2.0375033815701804

Epoch: 108| Step: 0
Training loss: 2.224398136138916
Validation loss: 2.0314272046089172

Epoch: 6| Step: 1
Training loss: 1.4989211559295654
Validation loss: 2.03303454319636

Epoch: 6| Step: 2
Training loss: 2.084611415863037
Validation loss: 2.040386358896891

Epoch: 6| Step: 3
Training loss: 2.061370611190796
Validation loss: 2.033274531364441

Epoch: 6| Step: 4
Training loss: 2.3840856552124023
Validation loss: 2.0219437082608542

Epoch: 6| Step: 5
Training loss: 1.8722805976867676
Validation loss: 2.01783017317454

Epoch: 6| Step: 6
Training loss: 2.3324480056762695
Validation loss: 2.018252193927765

Epoch: 6| Step: 7
Training loss: 2.3473165035247803
Validation loss: 2.0138378739356995

Epoch: 6| Step: 8
Training loss: 2.451998710632324
Validation loss: 2.0122208992640176

Epoch: 6| Step: 9
Training loss: 2.2021703720092773
Validation loss: 2.0177581310272217

Epoch: 6| Step: 10
Training loss: 2.191103935241699
Validation loss: 2.0191720922787986

Epoch: 6| Step: 11
Training loss: 1.6876466274261475
Validation loss: 2.0166905323664346

Epoch: 6| Step: 12
Training loss: 2.1924946308135986
Validation loss: 2.021081785360972

Epoch: 6| Step: 13
Training loss: 2.0878515243530273
Validation loss: 2.0102052092552185

Epoch: 109| Step: 0
Training loss: 1.7557487487792969
Validation loss: 2.0160073240598044

Epoch: 6| Step: 1
Training loss: 1.6892750263214111
Validation loss: 2.0038432478904724

Epoch: 6| Step: 2
Training loss: 1.9446117877960205
Validation loss: 2.0100371638933816

Epoch: 6| Step: 3
Training loss: 2.0270447731018066
Validation loss: 2.006476024786631

Epoch: 6| Step: 4
Training loss: 1.4286506175994873
Validation loss: 2.0182748436927795

Epoch: 6| Step: 5
Training loss: 2.4826488494873047
Validation loss: 2.0143107970555625

Epoch: 6| Step: 6
Training loss: 2.194835662841797
Validation loss: 2.027438839276632

Epoch: 6| Step: 7
Training loss: 2.632154941558838
Validation loss: 2.023149092992147

Epoch: 6| Step: 8
Training loss: 2.1143240928649902
Validation loss: 2.0264308055241904

Epoch: 6| Step: 9
Training loss: 2.6718568801879883
Validation loss: 2.023622691631317

Epoch: 6| Step: 10
Training loss: 2.4120492935180664
Validation loss: 2.027268429597219

Epoch: 6| Step: 11
Training loss: 1.5794023275375366
Validation loss: 2.030861417452494

Epoch: 6| Step: 12
Training loss: 2.1436963081359863
Validation loss: 2.022387464841207

Epoch: 6| Step: 13
Training loss: 2.6232974529266357
Validation loss: 2.0251198609670005

Epoch: 110| Step: 0
Training loss: 1.8380870819091797
Validation loss: 2.0194315910339355

Epoch: 6| Step: 1
Training loss: 2.3130862712860107
Validation loss: 2.0212522745132446

Epoch: 6| Step: 2
Training loss: 2.4620161056518555
Validation loss: 2.0271610816319785

Epoch: 6| Step: 3
Training loss: 2.500521183013916
Validation loss: 2.0158242185910544

Epoch: 6| Step: 4
Training loss: 1.736997127532959
Validation loss: 2.0278478066126504

Epoch: 6| Step: 5
Training loss: 1.4193840026855469
Validation loss: 2.0167463620503745

Epoch: 6| Step: 6
Training loss: 2.318235397338867
Validation loss: 2.0224804282188416

Epoch: 6| Step: 7
Training loss: 2.218839406967163
Validation loss: 2.031985859076182

Epoch: 6| Step: 8
Training loss: 1.6549922227859497
Validation loss: 2.017567833264669

Epoch: 6| Step: 9
Training loss: 2.3741111755371094
Validation loss: 2.0231561263402305

Epoch: 6| Step: 10
Training loss: 1.994685411453247
Validation loss: 2.031975348790487

Epoch: 6| Step: 11
Training loss: 2.3011162281036377
Validation loss: 2.020101249217987

Epoch: 6| Step: 12
Training loss: 2.304910659790039
Validation loss: 2.0178191463152566

Epoch: 6| Step: 13
Training loss: 1.7429003715515137
Validation loss: 2.0238255063692727

Epoch: 111| Step: 0
Training loss: 1.9278022050857544
Validation loss: 2.027229368686676

Epoch: 6| Step: 1
Training loss: 2.242154598236084
Validation loss: 2.022313396135966

Epoch: 6| Step: 2
Training loss: 2.2999303340911865
Validation loss: 2.020768642425537

Epoch: 6| Step: 3
Training loss: 2.1519908905029297
Validation loss: 2.023680051167806

Epoch: 6| Step: 4
Training loss: 1.5963406562805176
Validation loss: 2.0259288946787515

Epoch: 6| Step: 5
Training loss: 2.021073818206787
Validation loss: 2.0257256031036377

Epoch: 6| Step: 6
Training loss: 1.8375530242919922
Validation loss: 2.017424166202545

Epoch: 6| Step: 7
Training loss: 2.1778831481933594
Validation loss: 2.02444980541865

Epoch: 6| Step: 8
Training loss: 2.5314505100250244
Validation loss: 2.017739693323771

Epoch: 6| Step: 9
Training loss: 2.1387691497802734
Validation loss: 2.011250456174215

Epoch: 6| Step: 10
Training loss: 1.8417026996612549
Validation loss: 2.012508670488993

Epoch: 6| Step: 11
Training loss: 2.2038402557373047
Validation loss: 2.01277756690979

Epoch: 6| Step: 12
Training loss: 1.892711877822876
Validation loss: 2.018018662929535

Epoch: 6| Step: 13
Training loss: 2.492082118988037
Validation loss: 2.022454837958018

Epoch: 112| Step: 0
Training loss: 2.5737526416778564
Validation loss: 2.0229774117469788

Epoch: 6| Step: 1
Training loss: 2.5513598918914795
Validation loss: 2.0180426041285195

Epoch: 6| Step: 2
Training loss: 2.2201356887817383
Validation loss: 2.0144686897595725

Epoch: 6| Step: 3
Training loss: 2.069706916809082
Validation loss: 2.0157176852226257

Epoch: 6| Step: 4
Training loss: 1.346111536026001
Validation loss: 2.0126574635505676

Epoch: 6| Step: 5
Training loss: 2.0786337852478027
Validation loss: 2.0124005873998008

Epoch: 6| Step: 6
Training loss: 1.874733567237854
Validation loss: 2.015830119450887

Epoch: 6| Step: 7
Training loss: 2.1230151653289795
Validation loss: 2.016800502936045

Epoch: 6| Step: 8
Training loss: 2.3167147636413574
Validation loss: 2.01485542456309

Epoch: 6| Step: 9
Training loss: 2.689497947692871
Validation loss: 2.025813639163971

Epoch: 6| Step: 10
Training loss: 1.5283070802688599
Validation loss: 2.020366827646891

Epoch: 6| Step: 11
Training loss: 1.7812453508377075
Validation loss: 2.0258255302906036

Epoch: 6| Step: 12
Training loss: 1.9329018592834473
Validation loss: 2.022191107273102

Epoch: 6| Step: 13
Training loss: 2.2806873321533203
Validation loss: 2.0316710074742637

Epoch: 113| Step: 0
Training loss: 2.047147512435913
Validation loss: 2.030126909414927

Epoch: 6| Step: 1
Training loss: 2.269089698791504
Validation loss: 2.0315183202425637

Epoch: 6| Step: 2
Training loss: 1.6300435066223145
Validation loss: 2.0382964611053467

Epoch: 6| Step: 3
Training loss: 2.4956514835357666
Validation loss: 2.0496155420939126

Epoch: 6| Step: 4
Training loss: 2.0232269763946533
Validation loss: 2.063532372315725

Epoch: 6| Step: 5
Training loss: 2.3072710037231445
Validation loss: 2.052573879559835

Epoch: 6| Step: 6
Training loss: 2.4861888885498047
Validation loss: 2.02089524269104

Epoch: 6| Step: 7
Training loss: 1.9408385753631592
Validation loss: 2.016086757183075

Epoch: 6| Step: 8
Training loss: 1.6292383670806885
Validation loss: 2.02676131327947

Epoch: 6| Step: 9
Training loss: 2.076782703399658
Validation loss: 2.031907379627228

Epoch: 6| Step: 10
Training loss: 1.510751724243164
Validation loss: 2.0187578201293945

Epoch: 6| Step: 11
Training loss: 2.9527969360351562
Validation loss: 2.0227014819780984

Epoch: 6| Step: 12
Training loss: 1.9538160562515259
Validation loss: 2.0298397739728293

Epoch: 6| Step: 13
Training loss: 2.4066684246063232
Validation loss: 2.02226593097051

Epoch: 114| Step: 0
Training loss: 2.056612014770508
Validation loss: 2.030463000138601

Epoch: 6| Step: 1
Training loss: 2.449855327606201
Validation loss: 2.0324889620145163

Epoch: 6| Step: 2
Training loss: 2.091538429260254
Validation loss: 2.027693768342336

Epoch: 6| Step: 3
Training loss: 1.9777655601501465
Validation loss: 2.025578022003174

Epoch: 6| Step: 4
Training loss: 2.3174479007720947
Validation loss: 2.0117831230163574

Epoch: 6| Step: 5
Training loss: 2.601062774658203
Validation loss: 2.0040979385375977

Epoch: 6| Step: 6
Training loss: 2.0769708156585693
Validation loss: 2.0077330072720847

Epoch: 6| Step: 7
Training loss: 2.2443490028381348
Validation loss: 2.0055203437805176

Epoch: 6| Step: 8
Training loss: 2.0047976970672607
Validation loss: 1.9992611805597942

Epoch: 6| Step: 9
Training loss: 1.5403457880020142
Validation loss: 2.0063400665918985

Epoch: 6| Step: 10
Training loss: 2.1645474433898926
Validation loss: 2.011047343413035

Epoch: 6| Step: 11
Training loss: 1.6381109952926636
Validation loss: 2.013735910256704

Epoch: 6| Step: 12
Training loss: 2.050981283187866
Validation loss: 2.0111078023910522

Epoch: 6| Step: 13
Training loss: 2.1860342025756836
Validation loss: 2.017774681250254

Epoch: 115| Step: 0
Training loss: 1.4550143480300903
Validation loss: 2.026310841242472

Epoch: 6| Step: 1
Training loss: 1.787285566329956
Validation loss: 2.0296830336252847

Epoch: 6| Step: 2
Training loss: 2.060553550720215
Validation loss: 2.0397485494613647

Epoch: 6| Step: 3
Training loss: 2.1557159423828125
Validation loss: 2.036235988140106

Epoch: 6| Step: 4
Training loss: 2.397002935409546
Validation loss: 2.042266527811686

Epoch: 6| Step: 5
Training loss: 2.005258083343506
Validation loss: 2.047950327396393

Epoch: 6| Step: 6
Training loss: 2.1183691024780273
Validation loss: 2.05050265789032

Epoch: 6| Step: 7
Training loss: 2.2290902137756348
Validation loss: 2.0542862017949424

Epoch: 6| Step: 8
Training loss: 2.515576124191284
Validation loss: 2.050188144048055

Epoch: 6| Step: 9
Training loss: 1.5834563970565796
Validation loss: 2.0448184410730996

Epoch: 6| Step: 10
Training loss: 2.5485854148864746
Validation loss: 2.0355880657831826

Epoch: 6| Step: 11
Training loss: 2.1517693996429443
Validation loss: 2.0242667198181152

Epoch: 6| Step: 12
Training loss: 2.4358468055725098
Validation loss: 2.0271031061808267

Epoch: 6| Step: 13
Training loss: 1.696044683456421
Validation loss: 2.031425178050995

Epoch: 116| Step: 0
Training loss: 1.551477074623108
Validation loss: 2.023419717947642

Epoch: 6| Step: 1
Training loss: 2.7310259342193604
Validation loss: 2.0346369544665017

Epoch: 6| Step: 2
Training loss: 2.0017857551574707
Validation loss: 2.0421325961748757

Epoch: 6| Step: 3
Training loss: 1.850154995918274
Validation loss: 2.0431928038597107

Epoch: 6| Step: 4
Training loss: 1.7655882835388184
Validation loss: 2.038461903731028

Epoch: 6| Step: 5
Training loss: 2.1840057373046875
Validation loss: 2.038977801799774

Epoch: 6| Step: 6
Training loss: 1.990546703338623
Validation loss: 2.0294761856396994

Epoch: 6| Step: 7
Training loss: 1.7034739255905151
Validation loss: 2.026246647040049

Epoch: 6| Step: 8
Training loss: 2.113431692123413
Validation loss: 2.0291597048441568

Epoch: 6| Step: 9
Training loss: 2.711682081222534
Validation loss: 2.030421237150828

Epoch: 6| Step: 10
Training loss: 2.9918923377990723
Validation loss: 2.0293089151382446

Epoch: 6| Step: 11
Training loss: 1.702893853187561
Validation loss: 2.0297648509343467

Epoch: 6| Step: 12
Training loss: 2.4348926544189453
Validation loss: 2.036541481812795

Epoch: 6| Step: 13
Training loss: 1.9679325819015503
Validation loss: 2.040435512860616

Epoch: 117| Step: 0
Training loss: 2.3084893226623535
Validation loss: 2.0354374249776206

Epoch: 6| Step: 1
Training loss: 1.755364179611206
Validation loss: 2.042777717113495

Epoch: 6| Step: 2
Training loss: 2.407334089279175
Validation loss: 2.055026034514109

Epoch: 6| Step: 3
Training loss: 1.909555435180664
Validation loss: 2.0552565852801004

Epoch: 6| Step: 4
Training loss: 1.8002363443374634
Validation loss: 2.0549519260724387

Epoch: 6| Step: 5
Training loss: 1.7533392906188965
Validation loss: 2.0528788566589355

Epoch: 6| Step: 6
Training loss: 1.760688066482544
Validation loss: 2.0370070536931357

Epoch: 6| Step: 7
Training loss: 2.8751392364501953
Validation loss: 2.041224956512451

Epoch: 6| Step: 8
Training loss: 2.1946089267730713
Validation loss: 2.04740039507548

Epoch: 6| Step: 9
Training loss: 2.0431056022644043
Validation loss: 2.0368347764015198

Epoch: 6| Step: 10
Training loss: 2.6437435150146484
Validation loss: 2.028222640355428

Epoch: 6| Step: 11
Training loss: 1.7941303253173828
Validation loss: 2.0292211174964905

Epoch: 6| Step: 12
Training loss: 2.0678484439849854
Validation loss: 2.0186920762062073

Epoch: 6| Step: 13
Training loss: 2.101557493209839
Validation loss: 2.0140379468599954

Epoch: 118| Step: 0
Training loss: 2.751664161682129
Validation loss: 2.02041228612264

Epoch: 6| Step: 1
Training loss: 2.0751543045043945
Validation loss: 2.017348269621531

Epoch: 6| Step: 2
Training loss: 2.1154420375823975
Validation loss: 2.0155219038327536

Epoch: 6| Step: 3
Training loss: 2.448302745819092
Validation loss: 2.014552632967631

Epoch: 6| Step: 4
Training loss: 2.271784782409668
Validation loss: 2.0163493156433105

Epoch: 6| Step: 5
Training loss: 2.1171958446502686
Validation loss: 2.0122260451316833

Epoch: 6| Step: 6
Training loss: 1.8779144287109375
Validation loss: 2.0120641787846885

Epoch: 6| Step: 7
Training loss: 1.632173776626587
Validation loss: 2.011137823263804

Epoch: 6| Step: 8
Training loss: 1.6021268367767334
Validation loss: 2.0100287199020386

Epoch: 6| Step: 9
Training loss: 2.7806003093719482
Validation loss: 2.0149890383084617

Epoch: 6| Step: 10
Training loss: 1.9286201000213623
Validation loss: 2.0119820634524026

Epoch: 6| Step: 11
Training loss: 2.0970044136047363
Validation loss: 2.0201651453971863

Epoch: 6| Step: 12
Training loss: 1.760974645614624
Validation loss: 2.021816531817118

Epoch: 6| Step: 13
Training loss: 1.8599514961242676
Validation loss: 2.0146833856900535

Epoch: 119| Step: 0
Training loss: 1.8926893472671509
Validation loss: 2.0255348682403564

Epoch: 6| Step: 1
Training loss: 1.2628028392791748
Validation loss: 2.019043266773224

Epoch: 6| Step: 2
Training loss: 1.9589216709136963
Validation loss: 2.0225318471590676

Epoch: 6| Step: 3
Training loss: 2.1493921279907227
Validation loss: 2.035941263039907

Epoch: 6| Step: 4
Training loss: 1.7006430625915527
Validation loss: 2.028543492158254

Epoch: 6| Step: 5
Training loss: 1.922525405883789
Validation loss: 2.032253603140513

Epoch: 6| Step: 6
Training loss: 2.2181875705718994
Validation loss: 2.044054687023163

Epoch: 6| Step: 7
Training loss: 2.24702525138855
Validation loss: 2.0372066299120584

Epoch: 6| Step: 8
Training loss: 1.9827871322631836
Validation loss: 2.0321662227312722

Epoch: 6| Step: 9
Training loss: 2.5037598609924316
Validation loss: 2.0287970701853433

Epoch: 6| Step: 10
Training loss: 2.574167490005493
Validation loss: 2.0250000754992166

Epoch: 6| Step: 11
Training loss: 2.002225399017334
Validation loss: 2.0197470585505166

Epoch: 6| Step: 12
Training loss: 2.4892873764038086
Validation loss: 2.02510529756546

Epoch: 6| Step: 13
Training loss: 2.4040896892547607
Validation loss: 2.024758239587148

Epoch: 120| Step: 0
Training loss: 2.2391982078552246
Validation loss: 2.0246771574020386

Epoch: 6| Step: 1
Training loss: 1.6745132207870483
Validation loss: 2.0312114556630454

Epoch: 6| Step: 2
Training loss: 2.0776448249816895
Validation loss: 2.023769517739614

Epoch: 6| Step: 3
Training loss: 1.4785561561584473
Validation loss: 2.028217097123464

Epoch: 6| Step: 4
Training loss: 2.127807140350342
Validation loss: 2.0326969822247825

Epoch: 6| Step: 5
Training loss: 1.6482000350952148
Validation loss: 2.026720662911733

Epoch: 6| Step: 6
Training loss: 2.2678964138031006
Validation loss: 2.0277387301127114

Epoch: 6| Step: 7
Training loss: 2.6333203315734863
Validation loss: 2.0269211729367576

Epoch: 6| Step: 8
Training loss: 1.8570843935012817
Validation loss: 2.0279800494511924

Epoch: 6| Step: 9
Training loss: 2.0587987899780273
Validation loss: 2.03012486298879

Epoch: 6| Step: 10
Training loss: 1.9816570281982422
Validation loss: 2.0303232073783875

Epoch: 6| Step: 11
Training loss: 2.3817944526672363
Validation loss: 2.033068140347799

Epoch: 6| Step: 12
Training loss: 1.6437270641326904
Validation loss: 2.040302793184916

Epoch: 6| Step: 13
Training loss: 2.9307498931884766
Validation loss: 2.0351354082425437

Epoch: 121| Step: 0
Training loss: 2.5433530807495117
Validation loss: 2.0353281497955322

Epoch: 6| Step: 1
Training loss: 1.4689733982086182
Validation loss: 2.0398753682772317

Epoch: 6| Step: 2
Training loss: 2.480299949645996
Validation loss: 2.0307492216428122

Epoch: 6| Step: 3
Training loss: 1.8458508253097534
Validation loss: 2.0344152053197226

Epoch: 6| Step: 4
Training loss: 1.7726701498031616
Validation loss: 2.0356763005256653

Epoch: 6| Step: 5
Training loss: 1.9628386497497559
Validation loss: 2.0400492548942566

Epoch: 6| Step: 6
Training loss: 2.5668694972991943
Validation loss: 2.0295491814613342

Epoch: 6| Step: 7
Training loss: 2.031158447265625
Validation loss: 2.0302261114120483

Epoch: 6| Step: 8
Training loss: 2.2471137046813965
Validation loss: 2.038951277732849

Epoch: 6| Step: 9
Training loss: 2.049807548522949
Validation loss: 2.032724301020304

Epoch: 6| Step: 10
Training loss: 2.658383846282959
Validation loss: 2.019319156805674

Epoch: 6| Step: 11
Training loss: 1.9723312854766846
Validation loss: 2.0291125774383545

Epoch: 6| Step: 12
Training loss: 1.877846598625183
Validation loss: 2.0216273864110312

Epoch: 6| Step: 13
Training loss: 1.6123014688491821
Validation loss: 2.0192736387252808

Epoch: 122| Step: 0
Training loss: 2.146517276763916
Validation loss: 2.0113826394081116

Epoch: 6| Step: 1
Training loss: 1.4605084657669067
Validation loss: 2.019204298655192

Epoch: 6| Step: 2
Training loss: 1.9111909866333008
Validation loss: 2.023361563682556

Epoch: 6| Step: 3
Training loss: 1.6904159784317017
Validation loss: 2.01463919878006

Epoch: 6| Step: 4
Training loss: 1.3754136562347412
Validation loss: 2.017512241999308

Epoch: 6| Step: 5
Training loss: 2.4627668857574463
Validation loss: 2.0132282972335815

Epoch: 6| Step: 6
Training loss: 2.823864221572876
Validation loss: 2.016136427720388

Epoch: 6| Step: 7
Training loss: 2.355618953704834
Validation loss: 2.0166876316070557

Epoch: 6| Step: 8
Training loss: 2.055811643600464
Validation loss: 2.0093347628911338

Epoch: 6| Step: 9
Training loss: 2.3159000873565674
Validation loss: 2.018255293369293

Epoch: 6| Step: 10
Training loss: 2.86604380607605
Validation loss: 2.022400895754496

Epoch: 6| Step: 11
Training loss: 1.6789973974227905
Validation loss: 2.0248760978380838

Epoch: 6| Step: 12
Training loss: 1.9742246866226196
Validation loss: 2.0283201932907104

Epoch: 6| Step: 13
Training loss: 2.094102382659912
Validation loss: 2.011967122554779

Epoch: 123| Step: 0
Training loss: 2.0137171745300293
Validation loss: 2.021513819694519

Epoch: 6| Step: 1
Training loss: 1.537889838218689
Validation loss: 2.020256539185842

Epoch: 6| Step: 2
Training loss: 2.002774477005005
Validation loss: 2.012462019920349

Epoch: 6| Step: 3
Training loss: 1.9738237857818604
Validation loss: 2.027041435241699

Epoch: 6| Step: 4
Training loss: 2.1055185794830322
Validation loss: 2.0275805592536926

Epoch: 6| Step: 5
Training loss: 2.7892866134643555
Validation loss: 2.0287283658981323

Epoch: 6| Step: 6
Training loss: 2.517024040222168
Validation loss: 2.019526739915212

Epoch: 6| Step: 7
Training loss: 2.6368367671966553
Validation loss: 2.0249551932017007

Epoch: 6| Step: 8
Training loss: 1.4829703569412231
Validation loss: 2.0252826809883118

Epoch: 6| Step: 9
Training loss: 1.841953992843628
Validation loss: 2.0184773802757263

Epoch: 6| Step: 10
Training loss: 2.2254204750061035
Validation loss: 2.0292386213938394

Epoch: 6| Step: 11
Training loss: 2.090871810913086
Validation loss: 2.0207022428512573

Epoch: 6| Step: 12
Training loss: 1.4438343048095703
Validation loss: 2.018363813559214

Epoch: 6| Step: 13
Training loss: 2.2339019775390625
Validation loss: 2.0283262928326926

Epoch: 124| Step: 0
Training loss: 1.8000290393829346
Validation loss: 2.0235435962677

Epoch: 6| Step: 1
Training loss: 1.9884655475616455
Validation loss: 2.0223945577939353

Epoch: 6| Step: 2
Training loss: 1.430423617362976
Validation loss: 2.025598724683126

Epoch: 6| Step: 3
Training loss: 2.7754721641540527
Validation loss: 2.022240777810415

Epoch: 6| Step: 4
Training loss: 2.061119794845581
Validation loss: 2.0286491314570108

Epoch: 6| Step: 5
Training loss: 2.1470508575439453
Validation loss: 2.03431499004364

Epoch: 6| Step: 6
Training loss: 2.1415181159973145
Validation loss: 2.038341204325358

Epoch: 6| Step: 7
Training loss: 1.9821892976760864
Validation loss: 2.03997133175532

Epoch: 6| Step: 8
Training loss: 1.7104833126068115
Validation loss: 2.0470871130625405

Epoch: 6| Step: 9
Training loss: 1.6969234943389893
Validation loss: 2.042899211247762

Epoch: 6| Step: 10
Training loss: 2.462890148162842
Validation loss: 2.045581897099813

Epoch: 6| Step: 11
Training loss: 2.289092540740967
Validation loss: 2.040863037109375

Epoch: 6| Step: 12
Training loss: 2.0871520042419434
Validation loss: 2.03489222129186

Epoch: 6| Step: 13
Training loss: 2.3497023582458496
Validation loss: 2.0313333670298257

Epoch: 125| Step: 0
Training loss: 2.1326100826263428
Validation loss: 2.03006104628245

Epoch: 6| Step: 1
Training loss: 1.8232648372650146
Validation loss: 2.0306507547696433

Epoch: 6| Step: 2
Training loss: 2.603766918182373
Validation loss: 2.0216421683629355

Epoch: 6| Step: 3
Training loss: 2.382863998413086
Validation loss: 2.019540230433146

Epoch: 6| Step: 4
Training loss: 2.2780237197875977
Validation loss: 2.0188806851704917

Epoch: 6| Step: 5
Training loss: 1.856292724609375
Validation loss: 2.0246615409851074

Epoch: 6| Step: 6
Training loss: 2.0185909271240234
Validation loss: 2.0281723141670227

Epoch: 6| Step: 7
Training loss: 1.6339199542999268
Validation loss: 2.0206679900487265

Epoch: 6| Step: 8
Training loss: 1.608519196510315
Validation loss: 2.0377764900525412

Epoch: 6| Step: 9
Training loss: 1.893916368484497
Validation loss: 2.0365148782730103

Epoch: 6| Step: 10
Training loss: 2.321882963180542
Validation loss: 2.0277684529622397

Epoch: 6| Step: 11
Training loss: 2.3222122192382812
Validation loss: 2.036548435688019

Epoch: 6| Step: 12
Training loss: 1.7555582523345947
Validation loss: 2.0288619796435037

Epoch: 6| Step: 13
Training loss: 2.424675941467285
Validation loss: 2.0252647598584494

Epoch: 126| Step: 0
Training loss: 2.0018703937530518
Validation loss: 2.0269811352094016

Epoch: 6| Step: 1
Training loss: 2.097379684448242
Validation loss: 2.018005073070526

Epoch: 6| Step: 2
Training loss: 1.4966317415237427
Validation loss: 2.0166108210881553

Epoch: 6| Step: 3
Training loss: 2.8684515953063965
Validation loss: 2.006643235683441

Epoch: 6| Step: 4
Training loss: 2.139608144760132
Validation loss: 2.008142411708832

Epoch: 6| Step: 5
Training loss: 2.0106780529022217
Validation loss: 2.0237059791882834

Epoch: 6| Step: 6
Training loss: 2.028000593185425
Validation loss: 2.0194882353146872

Epoch: 6| Step: 7
Training loss: 1.894443154335022
Validation loss: 2.0127985874811807

Epoch: 6| Step: 8
Training loss: 2.058283805847168
Validation loss: 2.0284190575281777

Epoch: 6| Step: 9
Training loss: 2.311448097229004
Validation loss: 2.026528815428416

Epoch: 6| Step: 10
Training loss: 1.6257246732711792
Validation loss: 2.0348970691363015

Epoch: 6| Step: 11
Training loss: 2.2966365814208984
Validation loss: 2.040634016195933

Epoch: 6| Step: 12
Training loss: 1.788949728012085
Validation loss: 2.039810578028361

Epoch: 6| Step: 13
Training loss: 2.3038864135742188
Validation loss: 2.045130431652069

Epoch: 127| Step: 0
Training loss: 1.847675085067749
Validation loss: 2.0511449178059897

Epoch: 6| Step: 1
Training loss: 1.620417833328247
Validation loss: 2.050507128238678

Epoch: 6| Step: 2
Training loss: 2.435558795928955
Validation loss: 2.0479135314623513

Epoch: 6| Step: 3
Training loss: 1.9985363483428955
Validation loss: 2.0562606851259866

Epoch: 6| Step: 4
Training loss: 2.042210340499878
Validation loss: 2.0577770272890725

Epoch: 6| Step: 5
Training loss: 2.682873487472534
Validation loss: 2.0492584109306335

Epoch: 6| Step: 6
Training loss: 2.1507492065429688
Validation loss: 2.055271943410238

Epoch: 6| Step: 7
Training loss: 1.8516062498092651
Validation loss: 2.0500635703404746

Epoch: 6| Step: 8
Training loss: 1.699941635131836
Validation loss: 2.050484359264374

Epoch: 6| Step: 9
Training loss: 1.5163726806640625
Validation loss: 2.0416778723398843

Epoch: 6| Step: 10
Training loss: 2.130913257598877
Validation loss: 2.0358885129292807

Epoch: 6| Step: 11
Training loss: 2.0538828372955322
Validation loss: 2.032838503519694

Epoch: 6| Step: 12
Training loss: 1.7431817054748535
Validation loss: 2.0432239174842834

Epoch: 6| Step: 13
Training loss: 2.936741590499878
Validation loss: 2.031138241291046

Epoch: 128| Step: 0
Training loss: 2.416116237640381
Validation loss: 2.026273806889852

Epoch: 6| Step: 1
Training loss: 1.89967679977417
Validation loss: 2.02343088388443

Epoch: 6| Step: 2
Training loss: 1.858813762664795
Validation loss: 2.014279385407766

Epoch: 6| Step: 3
Training loss: 1.7367701530456543
Validation loss: 2.0323532621065774

Epoch: 6| Step: 4
Training loss: 2.023016929626465
Validation loss: 2.02571568886439

Epoch: 6| Step: 5
Training loss: 1.8994133472442627
Validation loss: 2.0202696522076926

Epoch: 6| Step: 6
Training loss: 1.996748685836792
Validation loss: 2.022363841533661

Epoch: 6| Step: 7
Training loss: 2.7366275787353516
Validation loss: 2.0262149572372437

Epoch: 6| Step: 8
Training loss: 2.3258895874023438
Validation loss: 2.0252594351768494

Epoch: 6| Step: 9
Training loss: 1.8122942447662354
Validation loss: 2.029227832953135

Epoch: 6| Step: 10
Training loss: 1.9507603645324707
Validation loss: 2.050055424372355

Epoch: 6| Step: 11
Training loss: 1.8465908765792847
Validation loss: 2.0479432145754495

Epoch: 6| Step: 12
Training loss: 2.460914134979248
Validation loss: 2.046898126602173

Epoch: 6| Step: 13
Training loss: 1.9935201406478882
Validation loss: 2.0487606724103293

Epoch: 129| Step: 0
Training loss: 2.4935462474823
Validation loss: 2.024036467075348

Epoch: 6| Step: 1
Training loss: 1.5888690948486328
Validation loss: 2.031164050102234

Epoch: 6| Step: 2
Training loss: 1.6391472816467285
Validation loss: 2.0285745660463967

Epoch: 6| Step: 3
Training loss: 1.41524076461792
Validation loss: 2.0287293990453086

Epoch: 6| Step: 4
Training loss: 2.181732416152954
Validation loss: 2.0293718377749124

Epoch: 6| Step: 5
Training loss: 1.8382474184036255
Validation loss: 2.024844308694204

Epoch: 6| Step: 6
Training loss: 2.2124924659729004
Validation loss: 2.027540862560272

Epoch: 6| Step: 7
Training loss: 2.2545166015625
Validation loss: 2.0239625175793967

Epoch: 6| Step: 8
Training loss: 2.2616238594055176
Validation loss: 2.022113482157389

Epoch: 6| Step: 9
Training loss: 2.484313488006592
Validation loss: 2.0295079151789346

Epoch: 6| Step: 10
Training loss: 1.9964598417282104
Validation loss: 2.0262170831362405

Epoch: 6| Step: 11
Training loss: 1.960913896560669
Validation loss: 2.0442885160446167

Epoch: 6| Step: 12
Training loss: 2.3141732215881348
Validation loss: 2.035101572672526

Epoch: 6| Step: 13
Training loss: 1.9533467292785645
Validation loss: 2.041649063428243

Epoch: 130| Step: 0
Training loss: 2.202974319458008
Validation loss: 2.0316073298454285

Epoch: 6| Step: 1
Training loss: 2.0673279762268066
Validation loss: 2.050467054049174

Epoch: 6| Step: 2
Training loss: 2.0450313091278076
Validation loss: 2.0670512119928994

Epoch: 6| Step: 3
Training loss: 1.9227416515350342
Validation loss: 2.059601088364919

Epoch: 6| Step: 4
Training loss: 2.0434794425964355
Validation loss: 2.042403757572174

Epoch: 6| Step: 5
Training loss: 2.332610607147217
Validation loss: 2.043394903341929

Epoch: 6| Step: 6
Training loss: 2.7986974716186523
Validation loss: 2.037724951903025

Epoch: 6| Step: 7
Training loss: 1.8094372749328613
Validation loss: 2.0351311564445496

Epoch: 6| Step: 8
Training loss: 2.0598015785217285
Validation loss: 2.036944349606832

Epoch: 6| Step: 9
Training loss: 1.5773499011993408
Validation loss: 2.030390123526255

Epoch: 6| Step: 10
Training loss: 2.4086573123931885
Validation loss: 2.032767732938131

Epoch: 6| Step: 11
Training loss: 1.8905551433563232
Validation loss: 2.0323369105656943

Epoch: 6| Step: 12
Training loss: 2.5138750076293945
Validation loss: 2.031800468762716

Epoch: 6| Step: 13
Training loss: 1.3128130435943604
Validation loss: 2.031785488128662

Epoch: 131| Step: 0
Training loss: 1.6758813858032227
Validation loss: 2.035139580567678

Epoch: 6| Step: 1
Training loss: 1.8775452375411987
Validation loss: 2.03419961531957

Epoch: 6| Step: 2
Training loss: 1.8222529888153076
Validation loss: 2.0420841574668884

Epoch: 6| Step: 3
Training loss: 2.1370444297790527
Validation loss: 2.0403648217519126

Epoch: 6| Step: 4
Training loss: 2.7879228591918945
Validation loss: 2.0529128909111023

Epoch: 6| Step: 5
Training loss: 1.9886245727539062
Validation loss: 2.052462915579478

Epoch: 6| Step: 6
Training loss: 1.929837703704834
Validation loss: 2.0549877285957336

Epoch: 6| Step: 7
Training loss: 2.4754066467285156
Validation loss: 2.0364328821500144

Epoch: 6| Step: 8
Training loss: 2.0065131187438965
Validation loss: 2.0454271833101907

Epoch: 6| Step: 9
Training loss: 1.958595871925354
Validation loss: 2.0429667234420776

Epoch: 6| Step: 10
Training loss: 2.412632942199707
Validation loss: 2.043027639389038

Epoch: 6| Step: 11
Training loss: 1.5454021692276
Validation loss: 2.037764926751455

Epoch: 6| Step: 12
Training loss: 2.2276761531829834
Validation loss: 2.042172392209371

Epoch: 6| Step: 13
Training loss: 1.9907805919647217
Validation loss: 2.0364805857340493

Epoch: 132| Step: 0
Training loss: 2.2422189712524414
Validation loss: 2.038896938165029

Epoch: 6| Step: 1
Training loss: 2.3950626850128174
Validation loss: 2.0431420604387918

Epoch: 6| Step: 2
Training loss: 1.6657519340515137
Validation loss: 2.0431740482648215

Epoch: 6| Step: 3
Training loss: 1.855311632156372
Validation loss: 2.0462816953659058

Epoch: 6| Step: 4
Training loss: 2.4774162769317627
Validation loss: 2.0500096678733826

Epoch: 6| Step: 5
Training loss: 1.6848533153533936
Validation loss: 2.0482288201649985

Epoch: 6| Step: 6
Training loss: 2.068680763244629
Validation loss: 2.0547877152760825

Epoch: 6| Step: 7
Training loss: 1.9640413522720337
Validation loss: 2.0507179299990335

Epoch: 6| Step: 8
Training loss: 2.0080883502960205
Validation loss: 2.050996164480845

Epoch: 6| Step: 9
Training loss: 2.34257435798645
Validation loss: 2.0495113531748452

Epoch: 6| Step: 10
Training loss: 2.3374953269958496
Validation loss: 2.0504427949587503

Epoch: 6| Step: 11
Training loss: 2.189795970916748
Validation loss: 2.0509770115216575

Epoch: 6| Step: 12
Training loss: 1.3924989700317383
Validation loss: 2.0475399096806846

Epoch: 6| Step: 13
Training loss: 1.9830918312072754
Validation loss: 2.0417741934458413

Epoch: 133| Step: 0
Training loss: 2.188469886779785
Validation loss: 2.046416441599528

Epoch: 6| Step: 1
Training loss: 2.0125296115875244
Validation loss: 2.0430937806765237

Epoch: 6| Step: 2
Training loss: 2.252208948135376
Validation loss: 2.047610282897949

Epoch: 6| Step: 3
Training loss: 2.1495471000671387
Validation loss: 2.0335572759310403

Epoch: 6| Step: 4
Training loss: 2.0288267135620117
Validation loss: 2.027262032032013

Epoch: 6| Step: 5
Training loss: 1.2042694091796875
Validation loss: 2.040202577908834

Epoch: 6| Step: 6
Training loss: 2.252300262451172
Validation loss: 2.031920234362284

Epoch: 6| Step: 7
Training loss: 1.6045103073120117
Validation loss: 2.0434977412223816

Epoch: 6| Step: 8
Training loss: 2.1647024154663086
Validation loss: 2.0406696597735086

Epoch: 6| Step: 9
Training loss: 2.044022560119629
Validation loss: 2.049085577329

Epoch: 6| Step: 10
Training loss: 1.8914036750793457
Validation loss: 2.0492493311564126

Epoch: 6| Step: 11
Training loss: 2.648820638656616
Validation loss: 2.0524762074152627

Epoch: 6| Step: 12
Training loss: 1.5218602418899536
Validation loss: 2.0567877292633057

Epoch: 6| Step: 13
Training loss: 2.4039039611816406
Validation loss: 2.0529320438702903

Epoch: 134| Step: 0
Training loss: 1.9960545301437378
Validation loss: 2.0618832111358643

Epoch: 6| Step: 1
Training loss: 1.5457297563552856
Validation loss: 2.0484675963719687

Epoch: 6| Step: 2
Training loss: 2.150444746017456
Validation loss: 2.051232635974884

Epoch: 6| Step: 3
Training loss: 2.343188524246216
Validation loss: 2.049385925134023

Epoch: 6| Step: 4
Training loss: 1.2920105457305908
Validation loss: 2.049702763557434

Epoch: 6| Step: 5
Training loss: 1.857001543045044
Validation loss: 2.048189560572306

Epoch: 6| Step: 6
Training loss: 2.337787628173828
Validation loss: 2.0367676417032876

Epoch: 6| Step: 7
Training loss: 2.3716766834259033
Validation loss: 2.043889125188192

Epoch: 6| Step: 8
Training loss: 2.5251383781433105
Validation loss: 2.0401625434557595

Epoch: 6| Step: 9
Training loss: 2.0191869735717773
Validation loss: 2.0394212007522583

Epoch: 6| Step: 10
Training loss: 1.6188114881515503
Validation loss: 2.0406054655710855

Epoch: 6| Step: 11
Training loss: 1.7807542085647583
Validation loss: 2.0316350062688193

Epoch: 6| Step: 12
Training loss: 2.261890411376953
Validation loss: 2.0344711740811667

Epoch: 6| Step: 13
Training loss: 2.2398083209991455
Validation loss: 2.038248578707377

Epoch: 135| Step: 0
Training loss: 2.0716211795806885
Validation loss: 2.0461297233899436

Epoch: 6| Step: 1
Training loss: 2.0726301670074463
Validation loss: 2.0539623498916626

Epoch: 6| Step: 2
Training loss: 2.37235426902771
Validation loss: 2.049269517262777

Epoch: 6| Step: 3
Training loss: 1.6687487363815308
Validation loss: 2.052150249481201

Epoch: 6| Step: 4
Training loss: 1.865744948387146
Validation loss: 2.0645481944084167

Epoch: 6| Step: 5
Training loss: 2.3309037685394287
Validation loss: 2.0510801672935486

Epoch: 6| Step: 6
Training loss: 1.7892980575561523
Validation loss: 2.0509042143821716

Epoch: 6| Step: 7
Training loss: 2.5680854320526123
Validation loss: 2.0447085897127786

Epoch: 6| Step: 8
Training loss: 1.9087152481079102
Validation loss: 2.0523125727971396

Epoch: 6| Step: 9
Training loss: 1.674311876296997
Validation loss: 2.0360290805498757

Epoch: 6| Step: 10
Training loss: 2.1534535884857178
Validation loss: 2.040187398592631

Epoch: 6| Step: 11
Training loss: 2.724513530731201
Validation loss: 2.0511744221051535

Epoch: 6| Step: 12
Training loss: 1.6006309986114502
Validation loss: 2.0551743110020957

Epoch: 6| Step: 13
Training loss: 1.625235676765442
Validation loss: 2.0523159901301065

Epoch: 136| Step: 0
Training loss: 2.087003231048584
Validation loss: 2.061384677886963

Epoch: 6| Step: 1
Training loss: 2.519590377807617
Validation loss: 2.06423157453537

Epoch: 6| Step: 2
Training loss: 1.573507308959961
Validation loss: 2.061262329419454

Epoch: 6| Step: 3
Training loss: 1.9578325748443604
Validation loss: 2.0790215333302817

Epoch: 6| Step: 4
Training loss: 2.413914680480957
Validation loss: 2.0687039494514465

Epoch: 6| Step: 5
Training loss: 2.085134744644165
Validation loss: 2.076222777366638

Epoch: 6| Step: 6
Training loss: 2.480982780456543
Validation loss: 2.066062072912852

Epoch: 6| Step: 7
Training loss: 2.5977158546447754
Validation loss: 2.0565116008122764

Epoch: 6| Step: 8
Training loss: 1.7150061130523682
Validation loss: 2.0724487702051797

Epoch: 6| Step: 9
Training loss: 1.9111599922180176
Validation loss: 2.0531423489252725

Epoch: 6| Step: 10
Training loss: 1.1783102750778198
Validation loss: 2.052366475264231

Epoch: 6| Step: 11
Training loss: 1.9773229360580444
Validation loss: 2.0494787891705832

Epoch: 6| Step: 12
Training loss: 2.1078245639801025
Validation loss: 2.0366197625796

Epoch: 6| Step: 13
Training loss: 1.735212802886963
Validation loss: 2.038867791493734

Epoch: 137| Step: 0
Training loss: 2.175211191177368
Validation loss: 2.041054606437683

Epoch: 6| Step: 1
Training loss: 1.6417555809020996
Validation loss: 2.0410419702529907

Epoch: 6| Step: 2
Training loss: 1.6821517944335938
Validation loss: 2.0395731329917908

Epoch: 6| Step: 3
Training loss: 2.670236349105835
Validation loss: 2.0379103620847068

Epoch: 6| Step: 4
Training loss: 2.482015371322632
Validation loss: 2.0388429959615073

Epoch: 6| Step: 5
Training loss: 1.8834775686264038
Validation loss: 2.0474496483802795

Epoch: 6| Step: 6
Training loss: 2.641252040863037
Validation loss: 2.0446406404177346

Epoch: 6| Step: 7
Training loss: 1.7796812057495117
Validation loss: 2.0461609164873757

Epoch: 6| Step: 8
Training loss: 1.7636948823928833
Validation loss: 2.052723705768585

Epoch: 6| Step: 9
Training loss: 1.9674937725067139
Validation loss: 2.0583751797676086

Epoch: 6| Step: 10
Training loss: 2.02044677734375
Validation loss: 2.07152525583903

Epoch: 6| Step: 11
Training loss: 2.148390054702759
Validation loss: 2.077117641766866

Epoch: 6| Step: 12
Training loss: 2.3594303131103516
Validation loss: 2.0540080666542053

Epoch: 6| Step: 13
Training loss: 2.1487555503845215
Validation loss: 2.0537403225898743

Epoch: 138| Step: 0
Training loss: 2.233821392059326
Validation loss: 2.066514511903127

Epoch: 6| Step: 1
Training loss: 2.0904500484466553
Validation loss: 2.065394421418508

Epoch: 6| Step: 2
Training loss: 2.2425708770751953
Validation loss: 2.069183588027954

Epoch: 6| Step: 3
Training loss: 2.0423712730407715
Validation loss: 2.0729916095733643

Epoch: 6| Step: 4
Training loss: 1.7247240543365479
Validation loss: 2.070370316505432

Epoch: 6| Step: 5
Training loss: 2.0439202785491943
Validation loss: 2.0625612139701843

Epoch: 6| Step: 6
Training loss: 1.7695200443267822
Validation loss: 2.0571347077687583

Epoch: 6| Step: 7
Training loss: 1.8638646602630615
Validation loss: 2.0628809928894043

Epoch: 6| Step: 8
Training loss: 2.3102643489837646
Validation loss: 2.051003336906433

Epoch: 6| Step: 9
Training loss: 2.766916036605835
Validation loss: 2.0481106440226235

Epoch: 6| Step: 10
Training loss: 1.9250727891921997
Validation loss: 2.0368018547693887

Epoch: 6| Step: 11
Training loss: 2.0891547203063965
Validation loss: 2.0346128344535828

Epoch: 6| Step: 12
Training loss: 1.7780845165252686
Validation loss: 2.0337754289309182

Epoch: 6| Step: 13
Training loss: 1.5707429647445679
Validation loss: 2.037748157978058

Epoch: 139| Step: 0
Training loss: 1.6099255084991455
Validation loss: 2.0391331116358438

Epoch: 6| Step: 1
Training loss: 1.9579448699951172
Validation loss: 2.045603930950165

Epoch: 6| Step: 2
Training loss: 2.5240445137023926
Validation loss: 2.051361918449402

Epoch: 6| Step: 3
Training loss: 1.6259597539901733
Validation loss: 2.0567562182744346

Epoch: 6| Step: 4
Training loss: 2.683023691177368
Validation loss: 2.0686766107877097

Epoch: 6| Step: 5
Training loss: 2.562775135040283
Validation loss: 2.074033558368683

Epoch: 6| Step: 6
Training loss: 1.9874851703643799
Validation loss: 2.075688123703003

Epoch: 6| Step: 7
Training loss: 1.7168549299240112
Validation loss: 2.0898975928624473

Epoch: 6| Step: 8
Training loss: 1.8579834699630737
Validation loss: 2.087173561255137

Epoch: 6| Step: 9
Training loss: 2.703333616256714
Validation loss: 2.077059825261434

Epoch: 6| Step: 10
Training loss: 2.5012340545654297
Validation loss: 2.083668371041616

Epoch: 6| Step: 11
Training loss: 1.4971249103546143
Validation loss: 2.0759132504463196

Epoch: 6| Step: 12
Training loss: 1.6078224182128906
Validation loss: 2.0826465487480164

Epoch: 6| Step: 13
Training loss: 1.7988814115524292
Validation loss: 2.068095624446869

Epoch: 140| Step: 0
Training loss: 1.5503971576690674
Validation loss: 2.0646327137947083

Epoch: 6| Step: 1
Training loss: 1.966869592666626
Validation loss: 2.045401930809021

Epoch: 6| Step: 2
Training loss: 2.6974129676818848
Validation loss: 2.045033315817515

Epoch: 6| Step: 3
Training loss: 1.8358595371246338
Validation loss: 2.0309279759724936

Epoch: 6| Step: 4
Training loss: 2.1759047508239746
Validation loss: 2.03469846645991

Epoch: 6| Step: 5
Training loss: 1.126443862915039
Validation loss: 2.026642302672068

Epoch: 6| Step: 6
Training loss: 2.1000895500183105
Validation loss: 2.0292285482088723

Epoch: 6| Step: 7
Training loss: 2.2877235412597656
Validation loss: 2.038506289323171

Epoch: 6| Step: 8
Training loss: 1.919040322303772
Validation loss: 2.033228596051534

Epoch: 6| Step: 9
Training loss: 1.7424960136413574
Validation loss: 2.0368525981903076

Epoch: 6| Step: 10
Training loss: 2.4712271690368652
Validation loss: 2.0328220327695212

Epoch: 6| Step: 11
Training loss: 2.815629720687866
Validation loss: 2.0389686028162637

Epoch: 6| Step: 12
Training loss: 1.5209293365478516
Validation loss: 2.0365769068400064

Epoch: 6| Step: 13
Training loss: 2.514706611633301
Validation loss: 2.035502851009369

Epoch: 141| Step: 0
Training loss: 1.8677608966827393
Validation loss: 2.040004094441732

Epoch: 6| Step: 1
Training loss: 2.386988639831543
Validation loss: 2.0490440726280212

Epoch: 6| Step: 2
Training loss: 2.4626007080078125
Validation loss: 2.0430548588434854

Epoch: 6| Step: 3
Training loss: 1.8920581340789795
Validation loss: 2.0494139393170676

Epoch: 6| Step: 4
Training loss: 2.7068676948547363
Validation loss: 2.0532092849413552

Epoch: 6| Step: 5
Training loss: 2.1406502723693848
Validation loss: 2.0614469846089682

Epoch: 6| Step: 6
Training loss: 1.566623568534851
Validation loss: 2.065967619419098

Epoch: 6| Step: 7
Training loss: 1.5001976490020752
Validation loss: 2.0695528984069824

Epoch: 6| Step: 8
Training loss: 1.804922342300415
Validation loss: 2.0555668075879416

Epoch: 6| Step: 9
Training loss: 2.0883216857910156
Validation loss: 2.050216873486837

Epoch: 6| Step: 10
Training loss: 2.037768840789795
Validation loss: 2.052510460217794

Epoch: 6| Step: 11
Training loss: 1.7661998271942139
Validation loss: 2.0340038935343423

Epoch: 6| Step: 12
Training loss: 1.84901762008667
Validation loss: 2.04356316725413

Epoch: 6| Step: 13
Training loss: 2.5012032985687256
Validation loss: 2.031230409940084

Epoch: 142| Step: 0
Training loss: 1.776238203048706
Validation loss: 2.0323520501454673

Epoch: 6| Step: 1
Training loss: 1.5446255207061768
Validation loss: 2.0367801189422607

Epoch: 6| Step: 2
Training loss: 1.676268458366394
Validation loss: 2.0339964230855307

Epoch: 6| Step: 3
Training loss: 2.4255025386810303
Validation loss: 2.03429106871287

Epoch: 6| Step: 4
Training loss: 1.7846871614456177
Validation loss: 2.0472384889920554

Epoch: 6| Step: 5
Training loss: 2.098806858062744
Validation loss: 2.0481741229693093

Epoch: 6| Step: 6
Training loss: 2.135795831680298
Validation loss: 2.047648807366689

Epoch: 6| Step: 7
Training loss: 1.929084300994873
Validation loss: 2.0528595248858132

Epoch: 6| Step: 8
Training loss: 1.5020136833190918
Validation loss: 2.058678905169169

Epoch: 6| Step: 9
Training loss: 2.705470085144043
Validation loss: 2.0470744371414185

Epoch: 6| Step: 10
Training loss: 2.643800735473633
Validation loss: 2.0480021039644876

Epoch: 6| Step: 11
Training loss: 1.7320266962051392
Validation loss: 2.0561288793881736

Epoch: 6| Step: 12
Training loss: 3.0923118591308594
Validation loss: 2.042606512705485

Epoch: 6| Step: 13
Training loss: 1.6910947561264038
Validation loss: 2.044214129447937

Epoch: 143| Step: 0
Training loss: 2.482487678527832
Validation loss: 2.045902411142985

Epoch: 6| Step: 1
Training loss: 1.8491120338439941
Validation loss: 2.0412227312723794

Epoch: 6| Step: 2
Training loss: 1.7376049757003784
Validation loss: 2.0536343852678933

Epoch: 6| Step: 3
Training loss: 2.1371352672576904
Validation loss: 2.0524986386299133

Epoch: 6| Step: 4
Training loss: 1.827406644821167
Validation loss: 2.051928758621216

Epoch: 6| Step: 5
Training loss: 1.849042296409607
Validation loss: 2.0569801330566406

Epoch: 6| Step: 6
Training loss: 2.300727605819702
Validation loss: 2.049130360285441

Epoch: 6| Step: 7
Training loss: 2.13828706741333
Validation loss: 2.061050514380137

Epoch: 6| Step: 8
Training loss: 1.8061240911483765
Validation loss: 2.056133588155111

Epoch: 6| Step: 9
Training loss: 1.887495756149292
Validation loss: 2.0560530622800193

Epoch: 6| Step: 10
Training loss: 2.3182148933410645
Validation loss: 2.066271444161733

Epoch: 6| Step: 11
Training loss: 2.1361894607543945
Validation loss: 2.061813791592916

Epoch: 6| Step: 12
Training loss: 1.9335538148880005
Validation loss: 2.06736954053243

Epoch: 6| Step: 13
Training loss: 1.970116138458252
Validation loss: 2.061208208401998

Epoch: 144| Step: 0
Training loss: 1.6202826499938965
Validation loss: 2.061175843079885

Epoch: 6| Step: 1
Training loss: 2.363863945007324
Validation loss: 2.0636897881825766

Epoch: 6| Step: 2
Training loss: 1.7818968296051025
Validation loss: 2.0611533721288047

Epoch: 6| Step: 3
Training loss: 1.810636043548584
Validation loss: 2.06825715303421

Epoch: 6| Step: 4
Training loss: 2.1722073554992676
Validation loss: 2.05533758799235

Epoch: 6| Step: 5
Training loss: 1.6193621158599854
Validation loss: 2.057172497113546

Epoch: 6| Step: 6
Training loss: 2.4305944442749023
Validation loss: 2.0500306288401284

Epoch: 6| Step: 7
Training loss: 2.311206340789795
Validation loss: 2.054780900478363

Epoch: 6| Step: 8
Training loss: 2.3885817527770996
Validation loss: 2.0527329246203103

Epoch: 6| Step: 9
Training loss: 2.43485951423645
Validation loss: 2.054511229197184

Epoch: 6| Step: 10
Training loss: 1.8429173231124878
Validation loss: 2.05276087919871

Epoch: 6| Step: 11
Training loss: 2.0236048698425293
Validation loss: 2.061875025431315

Epoch: 6| Step: 12
Training loss: 1.8815019130706787
Validation loss: 2.0580087900161743

Epoch: 6| Step: 13
Training loss: 1.6419950723648071
Validation loss: 2.0743080377578735

Epoch: 145| Step: 0
Training loss: 2.214590549468994
Validation loss: 2.075743536154429

Epoch: 6| Step: 1
Training loss: 2.160040855407715
Validation loss: 2.0659059882164

Epoch: 6| Step: 2
Training loss: 2.004181385040283
Validation loss: 2.0956859389940896

Epoch: 6| Step: 3
Training loss: 2.281968593597412
Validation loss: 2.092827320098877

Epoch: 6| Step: 4
Training loss: 2.203139305114746
Validation loss: 2.107710599899292

Epoch: 6| Step: 5
Training loss: 1.0261247158050537
Validation loss: 2.099668045838674

Epoch: 6| Step: 6
Training loss: 1.9295259714126587
Validation loss: 2.1052157084147134

Epoch: 6| Step: 7
Training loss: 1.8648431301116943
Validation loss: 2.0934036572774253

Epoch: 6| Step: 8
Training loss: 2.262657642364502
Validation loss: 2.091734210650126

Epoch: 6| Step: 9
Training loss: 2.7569680213928223
Validation loss: 2.061086813608805

Epoch: 6| Step: 10
Training loss: 2.396285057067871
Validation loss: 2.052842994530996

Epoch: 6| Step: 11
Training loss: 2.1199088096618652
Validation loss: 2.04555481672287

Epoch: 6| Step: 12
Training loss: 1.8691171407699585
Validation loss: 2.038290858268738

Epoch: 6| Step: 13
Training loss: 1.7370944023132324
Validation loss: 2.051994283994039

Epoch: 146| Step: 0
Training loss: 2.2833900451660156
Validation loss: 2.0491952896118164

Epoch: 6| Step: 1
Training loss: 2.1472744941711426
Validation loss: 2.0426858266194663

Epoch: 6| Step: 2
Training loss: 2.0822393894195557
Validation loss: 2.050467371940613

Epoch: 6| Step: 3
Training loss: 1.8753235340118408
Validation loss: 2.048569699128469

Epoch: 6| Step: 4
Training loss: 2.0284571647644043
Validation loss: 2.0465522011121116

Epoch: 6| Step: 5
Training loss: 1.9775304794311523
Validation loss: 2.0464800198872886

Epoch: 6| Step: 6
Training loss: 1.7189080715179443
Validation loss: 2.0508979161580405

Epoch: 6| Step: 7
Training loss: 1.9298676252365112
Validation loss: 2.0409588615099588

Epoch: 6| Step: 8
Training loss: 2.3174924850463867
Validation loss: 2.044206122557322

Epoch: 6| Step: 9
Training loss: 1.8419523239135742
Validation loss: 2.0502222180366516

Epoch: 6| Step: 10
Training loss: 2.5796313285827637
Validation loss: 2.0479292074839273

Epoch: 6| Step: 11
Training loss: 1.69388747215271
Validation loss: 2.044386883576711

Epoch: 6| Step: 12
Training loss: 1.7757716178894043
Validation loss: 2.0654773314793906

Epoch: 6| Step: 13
Training loss: 2.568373203277588
Validation loss: 2.071676731109619

Epoch: 147| Step: 0
Training loss: 2.3364782333374023
Validation loss: 2.0660184820493064

Epoch: 6| Step: 1
Training loss: 1.4002885818481445
Validation loss: 2.0740615924199424

Epoch: 6| Step: 2
Training loss: 1.704790711402893
Validation loss: 2.0852456291516623

Epoch: 6| Step: 3
Training loss: 1.7473602294921875
Validation loss: 2.0844430327415466

Epoch: 6| Step: 4
Training loss: 1.8215124607086182
Validation loss: 2.1000589529673257

Epoch: 6| Step: 5
Training loss: 2.09706449508667
Validation loss: 2.107006867726644

Epoch: 6| Step: 6
Training loss: 1.319354772567749
Validation loss: 2.0916258692741394

Epoch: 6| Step: 7
Training loss: 2.03776216506958
Validation loss: 2.09321137269338

Epoch: 6| Step: 8
Training loss: 2.5520176887512207
Validation loss: 2.077692667643229

Epoch: 6| Step: 9
Training loss: 2.2018136978149414
Validation loss: 2.0877352555592856

Epoch: 6| Step: 10
Training loss: 2.4202404022216797
Validation loss: 2.059911628564199

Epoch: 6| Step: 11
Training loss: 2.216508388519287
Validation loss: 2.0536476373672485

Epoch: 6| Step: 12
Training loss: 2.0666675567626953
Validation loss: 2.0466055075327554

Epoch: 6| Step: 13
Training loss: 2.4773035049438477
Validation loss: 2.042487462361654

Epoch: 148| Step: 0
Training loss: 1.6533687114715576
Validation loss: 2.0313687523206077

Epoch: 6| Step: 1
Training loss: 2.184931755065918
Validation loss: 2.043418745199839

Epoch: 6| Step: 2
Training loss: 2.7088770866394043
Validation loss: 2.0522514184316

Epoch: 6| Step: 3
Training loss: 1.7979683876037598
Validation loss: 2.042252858479818

Epoch: 6| Step: 4
Training loss: 2.1467909812927246
Validation loss: 2.0469812154769897

Epoch: 6| Step: 5
Training loss: 2.351304054260254
Validation loss: 2.0497395594914756

Epoch: 6| Step: 6
Training loss: 1.4571995735168457
Validation loss: 2.051810562610626

Epoch: 6| Step: 7
Training loss: 2.3577704429626465
Validation loss: 2.062732776006063

Epoch: 6| Step: 8
Training loss: 2.01425838470459
Validation loss: 2.0584066907564798

Epoch: 6| Step: 9
Training loss: 2.2637529373168945
Validation loss: 2.0653663277626038

Epoch: 6| Step: 10
Training loss: 2.063450813293457
Validation loss: 2.0822426875432334

Epoch: 6| Step: 11
Training loss: 2.3389978408813477
Validation loss: 2.0896681348482766

Epoch: 6| Step: 12
Training loss: 1.0880765914916992
Validation loss: 2.1041778127352395

Epoch: 6| Step: 13
Training loss: 1.6872539520263672
Validation loss: 2.100128730138143

Epoch: 149| Step: 0
Training loss: 2.383714437484741
Validation loss: 2.1146353085835776

Epoch: 6| Step: 1
Training loss: 2.334611654281616
Validation loss: 2.119711399078369

Epoch: 6| Step: 2
Training loss: 1.8932936191558838
Validation loss: 2.1043301224708557

Epoch: 6| Step: 3
Training loss: 2.151820659637451
Validation loss: 2.0870202779769897

Epoch: 6| Step: 4
Training loss: 1.5362443923950195
Validation loss: 2.073773463567098

Epoch: 6| Step: 5
Training loss: 2.232663154602051
Validation loss: 2.0650702714920044

Epoch: 6| Step: 6
Training loss: 2.0435757637023926
Validation loss: 2.0619927048683167

Epoch: 6| Step: 7
Training loss: 2.024977445602417
Validation loss: 2.03777668873469

Epoch: 6| Step: 8
Training loss: 1.8634504079818726
Validation loss: 2.03439861536026

Epoch: 6| Step: 9
Training loss: 1.9338340759277344
Validation loss: 2.0220555861790976

Epoch: 6| Step: 10
Training loss: 2.3340511322021484
Validation loss: 2.02940442164739

Epoch: 6| Step: 11
Training loss: 1.6118485927581787
Validation loss: 2.029912531375885

Epoch: 6| Step: 12
Training loss: 2.3718080520629883
Validation loss: 2.0269246896107993

Epoch: 6| Step: 13
Training loss: 2.2792725563049316
Validation loss: 2.0172604521115622

Epoch: 150| Step: 0
Training loss: 2.11183500289917
Validation loss: 2.020626346270243

Epoch: 6| Step: 1
Training loss: 2.0005202293395996
Validation loss: 2.0353137254714966

Epoch: 6| Step: 2
Training loss: 2.2665865421295166
Validation loss: 2.0424620707829795

Epoch: 6| Step: 3
Training loss: 2.191939353942871
Validation loss: 2.027270495891571

Epoch: 6| Step: 4
Training loss: 1.9927195310592651
Validation loss: 2.0391064882278442

Epoch: 6| Step: 5
Training loss: 1.9685144424438477
Validation loss: 2.041462858517965

Epoch: 6| Step: 6
Training loss: 1.68813157081604
Validation loss: 2.055226445198059

Epoch: 6| Step: 7
Training loss: 2.01584529876709
Validation loss: 2.068713068962097

Epoch: 6| Step: 8
Training loss: 2.209892988204956
Validation loss: 2.078234295050303

Epoch: 6| Step: 9
Training loss: 1.9436850547790527
Validation loss: 2.0906388560930886

Epoch: 6| Step: 10
Training loss: 2.602405548095703
Validation loss: 2.084644913673401

Epoch: 6| Step: 11
Training loss: 1.404669165611267
Validation loss: 2.0883444945017495

Epoch: 6| Step: 12
Training loss: 2.4614462852478027
Validation loss: 2.0847370823224387

Epoch: 6| Step: 13
Training loss: 1.9031676054000854
Validation loss: 2.0929293036460876

Epoch: 151| Step: 0
Training loss: 1.660471796989441
Validation loss: 2.0793528159459433

Epoch: 6| Step: 1
Training loss: 1.803575038909912
Validation loss: 2.0804007848103843

Epoch: 6| Step: 2
Training loss: 2.0772242546081543
Validation loss: 2.069220165411631

Epoch: 6| Step: 3
Training loss: 2.48819637298584
Validation loss: 2.0690298477808633

Epoch: 6| Step: 4
Training loss: 1.8850898742675781
Validation loss: 2.064487636089325

Epoch: 6| Step: 5
Training loss: 2.2888832092285156
Validation loss: 2.0615739822387695

Epoch: 6| Step: 6
Training loss: 2.533019542694092
Validation loss: 2.050576647122701

Epoch: 6| Step: 7
Training loss: 1.8095500469207764
Validation loss: 2.0464322566986084

Epoch: 6| Step: 8
Training loss: 2.6204490661621094
Validation loss: 2.047278106212616

Epoch: 6| Step: 9
Training loss: 1.4579243659973145
Validation loss: 2.0539498925209045

Epoch: 6| Step: 10
Training loss: 1.9961663484573364
Validation loss: 2.060491939385732

Epoch: 6| Step: 11
Training loss: 1.7915620803833008
Validation loss: 2.0612202088038125

Epoch: 6| Step: 12
Training loss: 2.192363977432251
Validation loss: 2.057734807332357

Epoch: 6| Step: 13
Training loss: 1.6163934469223022
Validation loss: 2.0804471174875894

Epoch: 152| Step: 0
Training loss: 2.227313995361328
Validation loss: 2.0865039626757302

Epoch: 6| Step: 1
Training loss: 1.815002202987671
Validation loss: 2.109197954336802

Epoch: 6| Step: 2
Training loss: 1.7570748329162598
Validation loss: 2.0932490626970925

Epoch: 6| Step: 3
Training loss: 1.3608980178833008
Validation loss: 2.096736272176107

Epoch: 6| Step: 4
Training loss: 2.048396110534668
Validation loss: 2.1000910003980002

Epoch: 6| Step: 5
Training loss: 2.2343571186065674
Validation loss: 2.1035067041714988

Epoch: 6| Step: 6
Training loss: 2.180971622467041
Validation loss: 2.0859805742899575

Epoch: 6| Step: 7
Training loss: 2.1542110443115234
Validation loss: 2.0801867643992105

Epoch: 6| Step: 8
Training loss: 1.4737045764923096
Validation loss: 2.084153950214386

Epoch: 6| Step: 9
Training loss: 1.7443358898162842
Validation loss: 2.0755147139231362

Epoch: 6| Step: 10
Training loss: 2.858022928237915
Validation loss: 2.070190648237864

Epoch: 6| Step: 11
Training loss: 2.2190723419189453
Validation loss: 2.070012847582499

Epoch: 6| Step: 12
Training loss: 2.4432382583618164
Validation loss: 2.0778207778930664

Epoch: 6| Step: 13
Training loss: 1.8256564140319824
Validation loss: 2.0695234139760337

Epoch: 153| Step: 0
Training loss: 2.0503921508789062
Validation loss: 2.0702630281448364

Epoch: 6| Step: 1
Training loss: 1.8415039777755737
Validation loss: 2.066855569680532

Epoch: 6| Step: 2
Training loss: 2.404263973236084
Validation loss: 2.085442582766215

Epoch: 6| Step: 3
Training loss: 2.2052032947540283
Validation loss: 2.0837923487027488

Epoch: 6| Step: 4
Training loss: 1.6033501625061035
Validation loss: 2.0872166752815247

Epoch: 6| Step: 5
Training loss: 2.15846586227417
Validation loss: 2.089369257291158

Epoch: 6| Step: 6
Training loss: 2.6096906661987305
Validation loss: 2.079097886880239

Epoch: 6| Step: 7
Training loss: 1.8053776025772095
Validation loss: 2.0832204023996987

Epoch: 6| Step: 8
Training loss: 1.4217371940612793
Validation loss: 2.073778510093689

Epoch: 6| Step: 9
Training loss: 1.7185187339782715
Validation loss: 2.0884934862454734

Epoch: 6| Step: 10
Training loss: 2.0469441413879395
Validation loss: 2.0828128854433694

Epoch: 6| Step: 11
Training loss: 2.2322301864624023
Validation loss: 2.0715855956077576

Epoch: 6| Step: 12
Training loss: 1.7414344549179077
Validation loss: 2.0691691835721335

Epoch: 6| Step: 13
Training loss: 2.1342248916625977
Validation loss: 2.060810844103495

Epoch: 154| Step: 0
Training loss: 2.2901482582092285
Validation loss: 2.0553588271141052

Epoch: 6| Step: 1
Training loss: 1.642646312713623
Validation loss: 2.0469099283218384

Epoch: 6| Step: 2
Training loss: 2.4088945388793945
Validation loss: 2.0415205359458923

Epoch: 6| Step: 3
Training loss: 1.7633552551269531
Validation loss: 2.037969787915548

Epoch: 6| Step: 4
Training loss: 1.7411487102508545
Validation loss: 2.023854076862335

Epoch: 6| Step: 5
Training loss: 1.926046371459961
Validation loss: 2.038639406363169

Epoch: 6| Step: 6
Training loss: 2.1936421394348145
Validation loss: 2.0336593190828958

Epoch: 6| Step: 7
Training loss: 1.9032188653945923
Validation loss: 2.053472876548767

Epoch: 6| Step: 8
Training loss: 2.1594371795654297
Validation loss: 2.036276320616404

Epoch: 6| Step: 9
Training loss: 1.8676027059555054
Validation loss: 2.049315929412842

Epoch: 6| Step: 10
Training loss: 2.3273234367370605
Validation loss: 2.041731894016266

Epoch: 6| Step: 11
Training loss: 2.163597583770752
Validation loss: 2.049828131993612

Epoch: 6| Step: 12
Training loss: 1.7828121185302734
Validation loss: 2.0570685466130576

Epoch: 6| Step: 13
Training loss: 2.367549419403076
Validation loss: 2.054620544115702

Epoch: 155| Step: 0
Training loss: 2.075913429260254
Validation loss: 2.047101676464081

Epoch: 6| Step: 1
Training loss: 2.468477725982666
Validation loss: 2.056172509988149

Epoch: 6| Step: 2
Training loss: 1.4955999851226807
Validation loss: 2.0578501423199973

Epoch: 6| Step: 3
Training loss: 1.9815757274627686
Validation loss: 2.0611897309621177

Epoch: 6| Step: 4
Training loss: 1.7599835395812988
Validation loss: 2.062468389670054

Epoch: 6| Step: 5
Training loss: 1.9788601398468018
Validation loss: 2.0536693334579468

Epoch: 6| Step: 6
Training loss: 2.002035617828369
Validation loss: 2.0595921675364175

Epoch: 6| Step: 7
Training loss: 1.827052354812622
Validation loss: 2.070221185684204

Epoch: 6| Step: 8
Training loss: 2.169466733932495
Validation loss: 2.0803993145624795

Epoch: 6| Step: 9
Training loss: 2.32143497467041
Validation loss: 2.0795088410377502

Epoch: 6| Step: 10
Training loss: 2.255450487136841
Validation loss: 2.109802265961965

Epoch: 6| Step: 11
Training loss: 1.8563246726989746
Validation loss: 2.0990767081578574

Epoch: 6| Step: 12
Training loss: 1.7489676475524902
Validation loss: 2.095782697200775

Epoch: 6| Step: 13
Training loss: 2.0961802005767822
Validation loss: 2.10055673122406

Epoch: 156| Step: 0
Training loss: 1.5338011980056763
Validation loss: 2.110036094983419

Epoch: 6| Step: 1
Training loss: 1.5152113437652588
Validation loss: 2.1104878385861716

Epoch: 6| Step: 2
Training loss: 1.8822531700134277
Validation loss: 2.095188021659851

Epoch: 6| Step: 3
Training loss: 2.1304354667663574
Validation loss: 2.130013187726339

Epoch: 6| Step: 4
Training loss: 1.8891404867172241
Validation loss: 2.1070838570594788

Epoch: 6| Step: 5
Training loss: 2.3320531845092773
Validation loss: 2.11296816666921

Epoch: 6| Step: 6
Training loss: 1.7634034156799316
Validation loss: 2.1031633218129477

Epoch: 6| Step: 7
Training loss: 2.175075054168701
Validation loss: 2.0910091002782187

Epoch: 6| Step: 8
Training loss: 1.994083285331726
Validation loss: 2.0956557790438333

Epoch: 6| Step: 9
Training loss: 2.413506507873535
Validation loss: 2.0838942527770996

Epoch: 6| Step: 10
Training loss: 2.2022666931152344
Validation loss: 2.0849156181017556

Epoch: 6| Step: 11
Training loss: 1.9476135969161987
Validation loss: 2.0858123302459717

Epoch: 6| Step: 12
Training loss: 2.040663719177246
Validation loss: 2.090145726998647

Epoch: 6| Step: 13
Training loss: 2.233649730682373
Validation loss: 2.082895278930664

Epoch: 157| Step: 0
Training loss: 1.9484121799468994
Validation loss: 2.077489137649536

Epoch: 6| Step: 1
Training loss: 2.226612091064453
Validation loss: 2.0759472648302713

Epoch: 6| Step: 2
Training loss: 1.7436178922653198
Validation loss: 2.069520354270935

Epoch: 6| Step: 3
Training loss: 2.103092670440674
Validation loss: 2.072707196076711

Epoch: 6| Step: 4
Training loss: 2.5394837856292725
Validation loss: 2.0663628776868186

Epoch: 6| Step: 5
Training loss: 2.006500244140625
Validation loss: 2.0748984018961587

Epoch: 6| Step: 6
Training loss: 2.14378023147583
Validation loss: 2.0790017445882163

Epoch: 6| Step: 7
Training loss: 1.7725281715393066
Validation loss: 2.081522067387899

Epoch: 6| Step: 8
Training loss: 2.6535916328430176
Validation loss: 2.081155280272166

Epoch: 6| Step: 9
Training loss: 2.251364231109619
Validation loss: 2.0797584851582847

Epoch: 6| Step: 10
Training loss: 1.83212149143219
Validation loss: 2.08595476547877

Epoch: 6| Step: 11
Training loss: 1.5115705728530884
Validation loss: 2.0909330646197

Epoch: 6| Step: 12
Training loss: 1.3245577812194824
Validation loss: 2.076759934425354

Epoch: 6| Step: 13
Training loss: 1.9627296924591064
Validation loss: 2.09219761689504

Epoch: 158| Step: 0
Training loss: 1.8707962036132812
Validation loss: 2.0918239752451577

Epoch: 6| Step: 1
Training loss: 1.318427324295044
Validation loss: 2.0863752961158752

Epoch: 6| Step: 2
Training loss: 2.317866325378418
Validation loss: 2.0940444469451904

Epoch: 6| Step: 3
Training loss: 1.4344744682312012
Validation loss: 2.085991680622101

Epoch: 6| Step: 4
Training loss: 1.7143001556396484
Validation loss: 2.0922829707463584

Epoch: 6| Step: 5
Training loss: 2.231828212738037
Validation loss: 2.1017497976620994

Epoch: 6| Step: 6
Training loss: 2.214354991912842
Validation loss: 2.101637899875641

Epoch: 6| Step: 7
Training loss: 2.3969080448150635
Validation loss: 2.102319141228994

Epoch: 6| Step: 8
Training loss: 2.1288414001464844
Validation loss: 2.1186147928237915

Epoch: 6| Step: 9
Training loss: 2.2448348999023438
Validation loss: 2.110639770825704

Epoch: 6| Step: 10
Training loss: 1.733359932899475
Validation loss: 2.094446082909902

Epoch: 6| Step: 11
Training loss: 1.881731629371643
Validation loss: 2.0901408592859902

Epoch: 6| Step: 12
Training loss: 1.9267230033874512
Validation loss: 2.0808415611584983

Epoch: 6| Step: 13
Training loss: 2.194418430328369
Validation loss: 2.061293443044027

Epoch: 159| Step: 0
Training loss: 1.9807183742523193
Validation loss: 2.075066248575846

Epoch: 6| Step: 1
Training loss: 2.0289206504821777
Validation loss: 2.069544772307078

Epoch: 6| Step: 2
Training loss: 2.2637624740600586
Validation loss: 2.057076374689738

Epoch: 6| Step: 3
Training loss: 1.6001853942871094
Validation loss: 2.0668160716692605

Epoch: 6| Step: 4
Training loss: 2.495303153991699
Validation loss: 2.0807225505510965

Epoch: 6| Step: 5
Training loss: 2.411921262741089
Validation loss: 2.077717940012614

Epoch: 6| Step: 6
Training loss: 1.7099889516830444
Validation loss: 2.0827633341153464

Epoch: 6| Step: 7
Training loss: 1.4718966484069824
Validation loss: 2.0881906946500144

Epoch: 6| Step: 8
Training loss: 2.2090182304382324
Validation loss: 2.098210553328196

Epoch: 6| Step: 9
Training loss: 1.8483717441558838
Validation loss: 2.0869088570276895

Epoch: 6| Step: 10
Training loss: 1.8703582286834717
Validation loss: 2.0939528544743857

Epoch: 6| Step: 11
Training loss: 1.6463292837142944
Validation loss: 2.089896082878113

Epoch: 6| Step: 12
Training loss: 2.7275147438049316
Validation loss: 2.1038405299186707

Epoch: 6| Step: 13
Training loss: 1.8496439456939697
Validation loss: 2.0860591729482016

Epoch: 160| Step: 0
Training loss: 2.712984561920166
Validation loss: 2.092957556247711

Epoch: 6| Step: 1
Training loss: 1.8926501274108887
Validation loss: 2.0795555313428244

Epoch: 6| Step: 2
Training loss: 2.0243396759033203
Validation loss: 2.075974722703298

Epoch: 6| Step: 3
Training loss: 1.801208734512329
Validation loss: 2.074820021788279

Epoch: 6| Step: 4
Training loss: 1.8397849798202515
Validation loss: 2.072064737478892

Epoch: 6| Step: 5
Training loss: 1.570655345916748
Validation loss: 2.063559134801229

Epoch: 6| Step: 6
Training loss: 1.799349069595337
Validation loss: 2.0637484788894653

Epoch: 6| Step: 7
Training loss: 2.4239678382873535
Validation loss: 2.063470800717672

Epoch: 6| Step: 8
Training loss: 1.8756465911865234
Validation loss: 2.0741350253423056

Epoch: 6| Step: 9
Training loss: 2.017537832260132
Validation loss: 2.0688651402791343

Epoch: 6| Step: 10
Training loss: 2.179832935333252
Validation loss: 2.0641638239224753

Epoch: 6| Step: 11
Training loss: 1.6843132972717285
Validation loss: 2.07404488325119

Epoch: 6| Step: 12
Training loss: 1.7008540630340576
Validation loss: 2.065722167491913

Epoch: 6| Step: 13
Training loss: 2.7092459201812744
Validation loss: 2.0879591703414917

Epoch: 161| Step: 0
Training loss: 2.1808102130889893
Validation loss: 2.079619546731313

Epoch: 6| Step: 1
Training loss: 1.8438905477523804
Validation loss: 2.0686251322428384

Epoch: 6| Step: 2
Training loss: 2.1444499492645264
Validation loss: 2.0767592787742615

Epoch: 6| Step: 3
Training loss: 2.2265326976776123
Validation loss: 2.078066647052765

Epoch: 6| Step: 4
Training loss: 1.7236535549163818
Validation loss: 2.077088395754496

Epoch: 6| Step: 5
Training loss: 2.3634841442108154
Validation loss: 2.0664165218671164

Epoch: 6| Step: 6
Training loss: 1.5303480625152588
Validation loss: 2.071281830469767

Epoch: 6| Step: 7
Training loss: 2.233260154724121
Validation loss: 2.0742191076278687

Epoch: 6| Step: 8
Training loss: 2.1310691833496094
Validation loss: 2.0702205101648965

Epoch: 6| Step: 9
Training loss: 1.6694116592407227
Validation loss: 2.068336029847463

Epoch: 6| Step: 10
Training loss: 2.186159372329712
Validation loss: 2.062871436278025

Epoch: 6| Step: 11
Training loss: 2.2370011806488037
Validation loss: 2.0720119873682656

Epoch: 6| Step: 12
Training loss: 1.5750901699066162
Validation loss: 2.0633808175722756

Epoch: 6| Step: 13
Training loss: 2.250174045562744
Validation loss: 2.0726677576700845

Epoch: 162| Step: 0
Training loss: 1.6678627729415894
Validation loss: 2.080687423547109

Epoch: 6| Step: 1
Training loss: 1.5701411962509155
Validation loss: 2.080387274424235

Epoch: 6| Step: 2
Training loss: 1.9620295763015747
Validation loss: 2.075048347314199

Epoch: 6| Step: 3
Training loss: 1.74629545211792
Validation loss: 2.073705514272054

Epoch: 6| Step: 4
Training loss: 2.3059844970703125
Validation loss: 2.0949948827425637

Epoch: 6| Step: 5
Training loss: 1.7036950588226318
Validation loss: 2.087292273839315

Epoch: 6| Step: 6
Training loss: 2.2598705291748047
Validation loss: 2.095939119656881

Epoch: 6| Step: 7
Training loss: 2.275306224822998
Validation loss: 2.0969430406888327

Epoch: 6| Step: 8
Training loss: 1.3989412784576416
Validation loss: 2.081309119860331

Epoch: 6| Step: 9
Training loss: 2.4344048500061035
Validation loss: 2.078411420186361

Epoch: 6| Step: 10
Training loss: 2.891984462738037
Validation loss: 2.0818379720052085

Epoch: 6| Step: 11
Training loss: 1.659470796585083
Validation loss: 2.079938213030497

Epoch: 6| Step: 12
Training loss: 2.0113754272460938
Validation loss: 2.0865177313486734

Epoch: 6| Step: 13
Training loss: 2.023864269256592
Validation loss: 2.0790249705314636

Epoch: 163| Step: 0
Training loss: 2.1800317764282227
Validation loss: 2.076026995976766

Epoch: 6| Step: 1
Training loss: 1.5752289295196533
Validation loss: 2.0779508352279663

Epoch: 6| Step: 2
Training loss: 2.103020429611206
Validation loss: 2.0810802976290383

Epoch: 6| Step: 3
Training loss: 1.4932920932769775
Validation loss: 2.0779990951220193

Epoch: 6| Step: 4
Training loss: 2.4820165634155273
Validation loss: 2.066775679588318

Epoch: 6| Step: 5
Training loss: 1.5310630798339844
Validation loss: 2.092331866423289

Epoch: 6| Step: 6
Training loss: 1.9157503843307495
Validation loss: 2.0969719886779785

Epoch: 6| Step: 7
Training loss: 2.4357669353485107
Validation loss: 2.087013820807139

Epoch: 6| Step: 8
Training loss: 1.7403433322906494
Validation loss: 2.089024464289347

Epoch: 6| Step: 9
Training loss: 2.3299343585968018
Validation loss: 2.0947911938031516

Epoch: 6| Step: 10
Training loss: 1.7335779666900635
Validation loss: 2.084938645362854

Epoch: 6| Step: 11
Training loss: 1.7702609300613403
Validation loss: 2.0896882017453513

Epoch: 6| Step: 12
Training loss: 2.344897747039795
Validation loss: 2.1012497544288635

Epoch: 6| Step: 13
Training loss: 2.104186534881592
Validation loss: 2.0879536469777427

Epoch: 164| Step: 0
Training loss: 2.2315008640289307
Validation loss: 2.085838476816813

Epoch: 6| Step: 1
Training loss: 1.9325584173202515
Validation loss: 2.0851186712582908

Epoch: 6| Step: 2
Training loss: 2.066270112991333
Validation loss: 2.0973833799362183

Epoch: 6| Step: 3
Training loss: 1.2729305028915405
Validation loss: 2.075290401776632

Epoch: 6| Step: 4
Training loss: 1.7775967121124268
Validation loss: 2.0772603352864585

Epoch: 6| Step: 5
Training loss: 1.7824640274047852
Validation loss: 2.076668997605642

Epoch: 6| Step: 6
Training loss: 2.418415069580078
Validation loss: 2.0739131371180215

Epoch: 6| Step: 7
Training loss: 2.0443577766418457
Validation loss: 2.065919498602549

Epoch: 6| Step: 8
Training loss: 1.7473974227905273
Validation loss: 2.060616453488668

Epoch: 6| Step: 9
Training loss: 2.2488622665405273
Validation loss: 2.0587557554244995

Epoch: 6| Step: 10
Training loss: 2.086472272872925
Validation loss: 2.0665640036265054

Epoch: 6| Step: 11
Training loss: 2.132929563522339
Validation loss: 2.065367897351583

Epoch: 6| Step: 12
Training loss: 1.7445855140686035
Validation loss: 2.070763329664866

Epoch: 6| Step: 13
Training loss: 2.0838027000427246
Validation loss: 2.0759721398353577

Epoch: 165| Step: 0
Training loss: 2.2151379585266113
Validation loss: 2.072590629259745

Epoch: 6| Step: 1
Training loss: 2.2207841873168945
Validation loss: 2.078345457712809

Epoch: 6| Step: 2
Training loss: 1.9702059030532837
Validation loss: 2.0697306791941323

Epoch: 6| Step: 3
Training loss: 2.0982468128204346
Validation loss: 2.088372528553009

Epoch: 6| Step: 4
Training loss: 2.07464861869812
Validation loss: 2.0762476325035095

Epoch: 6| Step: 5
Training loss: 2.3414618968963623
Validation loss: 2.078985571861267

Epoch: 6| Step: 6
Training loss: 1.6168440580368042
Validation loss: 2.088187495867411

Epoch: 6| Step: 7
Training loss: 1.9764938354492188
Validation loss: 2.0818795959154763

Epoch: 6| Step: 8
Training loss: 1.3932013511657715
Validation loss: 2.0860373775164285

Epoch: 6| Step: 9
Training loss: 1.5123456716537476
Validation loss: 2.09260227282842

Epoch: 6| Step: 10
Training loss: 1.9674863815307617
Validation loss: 2.0790030360221863

Epoch: 6| Step: 11
Training loss: 1.6762198209762573
Validation loss: 2.0881510376930237

Epoch: 6| Step: 12
Training loss: 2.3560566902160645
Validation loss: 2.084920128186544

Epoch: 6| Step: 13
Training loss: 1.840576410293579
Validation loss: 2.0874823133150735

Epoch: 166| Step: 0
Training loss: 2.5461816787719727
Validation loss: 2.085804601510366

Epoch: 6| Step: 1
Training loss: 2.0156123638153076
Validation loss: 2.086930294831594

Epoch: 6| Step: 2
Training loss: 1.8412644863128662
Validation loss: 2.0848270654678345

Epoch: 6| Step: 3
Training loss: 1.7664484977722168
Validation loss: 2.091211259365082

Epoch: 6| Step: 4
Training loss: 1.8540818691253662
Validation loss: 2.0846583048502603

Epoch: 6| Step: 5
Training loss: 1.5925414562225342
Validation loss: 2.094685117403666

Epoch: 6| Step: 6
Training loss: 2.2168731689453125
Validation loss: 2.0827991366386414

Epoch: 6| Step: 7
Training loss: 2.4878089427948
Validation loss: 2.0843792955080667

Epoch: 6| Step: 8
Training loss: 1.9975565671920776
Validation loss: 2.0741049448649087

Epoch: 6| Step: 9
Training loss: 1.1252164840698242
Validation loss: 2.060380776723226

Epoch: 6| Step: 10
Training loss: 1.946425437927246
Validation loss: 2.060935119787852

Epoch: 6| Step: 11
Training loss: 1.6340439319610596
Validation loss: 2.061104873816172

Epoch: 6| Step: 12
Training loss: 2.2775473594665527
Validation loss: 2.06380029519399

Epoch: 6| Step: 13
Training loss: 2.552123546600342
Validation loss: 2.0654874245325723

Epoch: 167| Step: 0
Training loss: 1.5950696468353271
Validation loss: 2.0674367348353067

Epoch: 6| Step: 1
Training loss: 2.1691489219665527
Validation loss: 2.0769978562990823

Epoch: 6| Step: 2
Training loss: 2.1303324699401855
Validation loss: 2.0849535862604776

Epoch: 6| Step: 3
Training loss: 2.552964687347412
Validation loss: 2.1002370516459146

Epoch: 6| Step: 4
Training loss: 1.7741796970367432
Validation loss: 2.1117520332336426

Epoch: 6| Step: 5
Training loss: 1.385162353515625
Validation loss: 2.104048808415731

Epoch: 6| Step: 6
Training loss: 1.8101346492767334
Validation loss: 2.1075801253318787

Epoch: 6| Step: 7
Training loss: 2.3000121116638184
Validation loss: 2.1054221789042153

Epoch: 6| Step: 8
Training loss: 2.197068691253662
Validation loss: 2.112558126449585

Epoch: 6| Step: 9
Training loss: 1.5964769124984741
Validation loss: 2.1101600925127664

Epoch: 6| Step: 10
Training loss: 2.098641872406006
Validation loss: 2.1061351895332336

Epoch: 6| Step: 11
Training loss: 1.7721344232559204
Validation loss: 2.1036831736564636

Epoch: 6| Step: 12
Training loss: 1.7691086530685425
Validation loss: 2.0990195075670877

Epoch: 6| Step: 13
Training loss: 2.5150108337402344
Validation loss: 2.0833290020624795

Epoch: 168| Step: 0
Training loss: 1.4079160690307617
Validation loss: 2.0753012895584106

Epoch: 6| Step: 1
Training loss: 1.7933971881866455
Validation loss: 2.064737319946289

Epoch: 6| Step: 2
Training loss: 2.247246026992798
Validation loss: 2.07219535112381

Epoch: 6| Step: 3
Training loss: 1.9067342281341553
Validation loss: 2.062009851137797

Epoch: 6| Step: 4
Training loss: 2.0022060871124268
Validation loss: 2.070834676424662

Epoch: 6| Step: 5
Training loss: 2.3273987770080566
Validation loss: 2.0547345876693726

Epoch: 6| Step: 6
Training loss: 1.703688144683838
Validation loss: 2.0680088003476462

Epoch: 6| Step: 7
Training loss: 1.826861023902893
Validation loss: 2.065546711285909

Epoch: 6| Step: 8
Training loss: 2.8347442150115967
Validation loss: 2.0643935402234397

Epoch: 6| Step: 9
Training loss: 2.1071622371673584
Validation loss: 2.0589404900868735

Epoch: 6| Step: 10
Training loss: 2.232353687286377
Validation loss: 2.0710244178771973

Epoch: 6| Step: 11
Training loss: 2.099086284637451
Validation loss: 2.0610806941986084

Epoch: 6| Step: 12
Training loss: 2.2831039428710938
Validation loss: 2.075666149457296

Epoch: 6| Step: 13
Training loss: 1.7320432662963867
Validation loss: 2.08722315231959

Epoch: 169| Step: 0
Training loss: 1.9132049083709717
Validation loss: 2.084704339504242

Epoch: 6| Step: 1
Training loss: 2.2914416790008545
Validation loss: 2.0856438080469766

Epoch: 6| Step: 2
Training loss: 2.642451047897339
Validation loss: 2.082200547059377

Epoch: 6| Step: 3
Training loss: 1.8420143127441406
Validation loss: 2.0900976260503135

Epoch: 6| Step: 4
Training loss: 1.2845497131347656
Validation loss: 2.082100828488668

Epoch: 6| Step: 5
Training loss: 2.3783118724823
Validation loss: 2.0802295406659446

Epoch: 6| Step: 6
Training loss: 1.6516919136047363
Validation loss: 2.0844507217407227

Epoch: 6| Step: 7
Training loss: 1.6346681118011475
Validation loss: 2.0845956603686013

Epoch: 6| Step: 8
Training loss: 1.447009801864624
Validation loss: 2.0744820833206177

Epoch: 6| Step: 9
Training loss: 2.0880236625671387
Validation loss: 2.0775959889094033

Epoch: 6| Step: 10
Training loss: 1.861183524131775
Validation loss: 2.0759645104408264

Epoch: 6| Step: 11
Training loss: 2.2821946144104004
Validation loss: 2.0677404006322226

Epoch: 6| Step: 12
Training loss: 1.6740128993988037
Validation loss: 2.068025827407837

Epoch: 6| Step: 13
Training loss: 2.4908065795898438
Validation loss: 2.0737386345863342

Epoch: 170| Step: 0
Training loss: 2.159358501434326
Validation loss: 2.0785672267278037

Epoch: 6| Step: 1
Training loss: 1.7382543087005615
Validation loss: 2.063020964463552

Epoch: 6| Step: 2
Training loss: 1.763155460357666
Validation loss: 2.0719067056973777

Epoch: 6| Step: 3
Training loss: 1.8111796379089355
Validation loss: 2.0865959922472634

Epoch: 6| Step: 4
Training loss: 1.7481281757354736
Validation loss: 2.099154551823934

Epoch: 6| Step: 5
Training loss: 1.619787573814392
Validation loss: 2.0951465566953025

Epoch: 6| Step: 6
Training loss: 2.5704822540283203
Validation loss: 2.105710426966349

Epoch: 6| Step: 7
Training loss: 2.140216827392578
Validation loss: 2.098278204600016

Epoch: 6| Step: 8
Training loss: 1.530582308769226
Validation loss: 2.1099566221237183

Epoch: 6| Step: 9
Training loss: 1.8566126823425293
Validation loss: 2.1021552681922913

Epoch: 6| Step: 10
Training loss: 2.249408006668091
Validation loss: 2.123436133066813

Epoch: 6| Step: 11
Training loss: 2.234231472015381
Validation loss: 2.111277957757314

Epoch: 6| Step: 12
Training loss: 1.8354915380477905
Validation loss: 2.113181988398234

Epoch: 6| Step: 13
Training loss: 2.15381121635437
Validation loss: 2.1219427386919656

Epoch: 171| Step: 0
Training loss: 1.878556489944458
Validation loss: 2.1234399875005088

Epoch: 6| Step: 1
Training loss: 2.2484471797943115
Validation loss: 2.114779512087504

Epoch: 6| Step: 2
Training loss: 1.4689104557037354
Validation loss: 2.096542179584503

Epoch: 6| Step: 3
Training loss: 1.5662152767181396
Validation loss: 2.0983602007230124

Epoch: 6| Step: 4
Training loss: 1.1377933025360107
Validation loss: 2.0890337427457175

Epoch: 6| Step: 5
Training loss: 2.582911491394043
Validation loss: 2.081423282623291

Epoch: 6| Step: 6
Training loss: 2.414469003677368
Validation loss: 2.0804144144058228

Epoch: 6| Step: 7
Training loss: 1.7684979438781738
Validation loss: 2.0838995774586997

Epoch: 6| Step: 8
Training loss: 2.2542643547058105
Validation loss: 2.0779621799786887

Epoch: 6| Step: 9
Training loss: 2.1323981285095215
Validation loss: 2.0787153840065002

Epoch: 6| Step: 10
Training loss: 1.974260687828064
Validation loss: 2.0888395508130393

Epoch: 6| Step: 11
Training loss: 2.464848518371582
Validation loss: 2.0817065636316934

Epoch: 6| Step: 12
Training loss: 2.022578716278076
Validation loss: 2.1010117530822754

Epoch: 6| Step: 13
Training loss: 1.9059340953826904
Validation loss: 2.1105109453201294

Epoch: 172| Step: 0
Training loss: 1.6519501209259033
Validation loss: 2.119568387667338

Epoch: 6| Step: 1
Training loss: 2.035287380218506
Validation loss: 2.135183413823446

Epoch: 6| Step: 2
Training loss: 2.1722307205200195
Validation loss: 2.1447470982869468

Epoch: 6| Step: 3
Training loss: 2.4353227615356445
Validation loss: 2.1395294864972434

Epoch: 6| Step: 4
Training loss: 2.0251598358154297
Validation loss: 2.1360968550046286

Epoch: 6| Step: 5
Training loss: 2.3208060264587402
Validation loss: 2.1299131313959756

Epoch: 6| Step: 6
Training loss: 1.4605307579040527
Validation loss: 2.125799616177877

Epoch: 6| Step: 7
Training loss: 2.0510916709899902
Validation loss: 2.1086772878964744

Epoch: 6| Step: 8
Training loss: 1.8708653450012207
Validation loss: 2.08169162273407

Epoch: 6| Step: 9
Training loss: 2.317445993423462
Validation loss: 2.0772751371065774

Epoch: 6| Step: 10
Training loss: 1.7810115814208984
Validation loss: 2.072219888369242

Epoch: 6| Step: 11
Training loss: 2.5612664222717285
Validation loss: 2.0647881428400674

Epoch: 6| Step: 12
Training loss: 1.165488839149475
Validation loss: 2.068526327610016

Epoch: 6| Step: 13
Training loss: 2.2663402557373047
Validation loss: 2.067948798338572

Epoch: 173| Step: 0
Training loss: 1.758040189743042
Validation loss: 2.0658981601397195

Epoch: 6| Step: 1
Training loss: 2.1591796875
Validation loss: 2.0698458353678384

Epoch: 6| Step: 2
Training loss: 1.53466796875
Validation loss: 2.074242730935415

Epoch: 6| Step: 3
Training loss: 2.4049973487854004
Validation loss: 2.0791390538215637

Epoch: 6| Step: 4
Training loss: 2.0845916271209717
Validation loss: 2.0732359687487283

Epoch: 6| Step: 5
Training loss: 1.735766053199768
Validation loss: 2.08076274394989

Epoch: 6| Step: 6
Training loss: 1.815695881843567
Validation loss: 2.0731834173202515

Epoch: 6| Step: 7
Training loss: 2.1347503662109375
Validation loss: 2.086805740992228

Epoch: 6| Step: 8
Training loss: 1.7218225002288818
Validation loss: 2.081333339214325

Epoch: 6| Step: 9
Training loss: 2.6575005054473877
Validation loss: 2.078548312187195

Epoch: 6| Step: 10
Training loss: 1.8118849992752075
Validation loss: 2.0798257191975913

Epoch: 6| Step: 11
Training loss: 2.777864933013916
Validation loss: 2.1045095125834146

Epoch: 6| Step: 12
Training loss: 1.6061177253723145
Validation loss: 2.1206692457199097

Epoch: 6| Step: 13
Training loss: 1.9637486934661865
Validation loss: 2.116695006688436

Epoch: 174| Step: 0
Training loss: 2.266831874847412
Validation loss: 2.1084258953730264

Epoch: 6| Step: 1
Training loss: 1.877974510192871
Validation loss: 2.108532210191091

Epoch: 6| Step: 2
Training loss: 1.703210711479187
Validation loss: 2.1121811072031655

Epoch: 6| Step: 3
Training loss: 2.3949551582336426
Validation loss: 2.108424425125122

Epoch: 6| Step: 4
Training loss: 2.087376356124878
Validation loss: 2.105098764101664

Epoch: 6| Step: 5
Training loss: 1.454850673675537
Validation loss: 2.09236345688502

Epoch: 6| Step: 6
Training loss: 1.7086424827575684
Validation loss: 2.10135147968928

Epoch: 6| Step: 7
Training loss: 2.0347986221313477
Validation loss: 2.1060717900594077

Epoch: 6| Step: 8
Training loss: 1.8526272773742676
Validation loss: 2.1002099911371865

Epoch: 6| Step: 9
Training loss: 1.629345417022705
Validation loss: 2.109238008658091

Epoch: 6| Step: 10
Training loss: 1.6071780920028687
Validation loss: 2.1067851384480796

Epoch: 6| Step: 11
Training loss: 2.579566240310669
Validation loss: 2.104917327562968

Epoch: 6| Step: 12
Training loss: 1.9959452152252197
Validation loss: 2.112086554368337

Epoch: 6| Step: 13
Training loss: 1.897515892982483
Validation loss: 2.09367040793101

Epoch: 175| Step: 0
Training loss: 2.367631196975708
Validation loss: 2.1028261383374534

Epoch: 6| Step: 1
Training loss: 1.843224287033081
Validation loss: 2.0926301081975303

Epoch: 6| Step: 2
Training loss: 2.5433807373046875
Validation loss: 2.097430149714152

Epoch: 6| Step: 3
Training loss: 2.1697330474853516
Validation loss: 2.092277228832245

Epoch: 6| Step: 4
Training loss: 2.253446578979492
Validation loss: 2.110580881436666

Epoch: 6| Step: 5
Training loss: 2.3971362113952637
Validation loss: 2.1141242384910583

Epoch: 6| Step: 6
Training loss: 1.5449782609939575
Validation loss: 2.1040287812550864

Epoch: 6| Step: 7
Training loss: 1.8023210763931274
Validation loss: 2.12610125541687

Epoch: 6| Step: 8
Training loss: 1.6841778755187988
Validation loss: 2.1130648056666055

Epoch: 6| Step: 9
Training loss: 1.906113624572754
Validation loss: 2.1034631927808127

Epoch: 6| Step: 10
Training loss: 1.5843157768249512
Validation loss: 2.1114859580993652

Epoch: 6| Step: 11
Training loss: 1.7886097431182861
Validation loss: 2.112161954243978

Epoch: 6| Step: 12
Training loss: 1.7770283222198486
Validation loss: 2.1123854915301004

Epoch: 6| Step: 13
Training loss: 1.6095942258834839
Validation loss: 2.105560382207235

Epoch: 176| Step: 0
Training loss: 1.86029851436615
Validation loss: 2.0928964217503867

Epoch: 6| Step: 1
Training loss: 1.8763082027435303
Validation loss: 2.0877527395884194

Epoch: 6| Step: 2
Training loss: 2.065311908721924
Validation loss: 2.085856775442759

Epoch: 6| Step: 3
Training loss: 1.6316417455673218
Validation loss: 2.101356784502665

Epoch: 6| Step: 4
Training loss: 2.1551756858825684
Validation loss: 2.094894846280416

Epoch: 6| Step: 5
Training loss: 1.7875502109527588
Validation loss: 2.1156646013259888

Epoch: 6| Step: 6
Training loss: 1.7968401908874512
Validation loss: 2.0968259970347085

Epoch: 6| Step: 7
Training loss: 2.1454830169677734
Validation loss: 2.114896853764852

Epoch: 6| Step: 8
Training loss: 2.271700382232666
Validation loss: 2.1052982608477273

Epoch: 6| Step: 9
Training loss: 2.052788257598877
Validation loss: 2.107624093691508

Epoch: 6| Step: 10
Training loss: 0.9837074279785156
Validation loss: 2.115261177221934

Epoch: 6| Step: 11
Training loss: 2.1119961738586426
Validation loss: 2.1257314880688987

Epoch: 6| Step: 12
Training loss: 1.8274562358856201
Validation loss: 2.1198195616404214

Epoch: 6| Step: 13
Training loss: 2.558095932006836
Validation loss: 2.1229370633761087

Epoch: 177| Step: 0
Training loss: 1.4280061721801758
Validation loss: 2.114840487639109

Epoch: 6| Step: 1
Training loss: 1.4248793125152588
Validation loss: 2.1181387106577554

Epoch: 6| Step: 2
Training loss: 3.0643882751464844
Validation loss: 2.118650575478872

Epoch: 6| Step: 3
Training loss: 2.2506160736083984
Validation loss: 2.119405289491018

Epoch: 6| Step: 4
Training loss: 1.7131123542785645
Validation loss: 2.123166084289551

Epoch: 6| Step: 5
Training loss: 2.0069501399993896
Validation loss: 2.1224273840586343

Epoch: 6| Step: 6
Training loss: 1.538205862045288
Validation loss: 2.110910495122274

Epoch: 6| Step: 7
Training loss: 2.2896385192871094
Validation loss: 2.116975168387095

Epoch: 6| Step: 8
Training loss: 1.224445104598999
Validation loss: 2.121038774649302

Epoch: 6| Step: 9
Training loss: 1.8585398197174072
Validation loss: 2.099327107270559

Epoch: 6| Step: 10
Training loss: 1.602234125137329
Validation loss: 2.108196755250295

Epoch: 6| Step: 11
Training loss: 1.9233057498931885
Validation loss: 2.1012712319691977

Epoch: 6| Step: 12
Training loss: 2.604175090789795
Validation loss: 2.090964674949646

Epoch: 6| Step: 13
Training loss: 2.1152420043945312
Validation loss: 2.101092000802358

Epoch: 178| Step: 0
Training loss: 2.3466806411743164
Validation loss: 2.09837673107783

Epoch: 6| Step: 1
Training loss: 2.312837600708008
Validation loss: 2.1012892723083496

Epoch: 6| Step: 2
Training loss: 2.086942434310913
Validation loss: 2.108567257722219

Epoch: 6| Step: 3
Training loss: 1.9633277654647827
Validation loss: 2.113699754079183

Epoch: 6| Step: 4
Training loss: 1.457319974899292
Validation loss: 2.122054636478424

Epoch: 6| Step: 5
Training loss: 1.403092384338379
Validation loss: 2.1182063023249307

Epoch: 6| Step: 6
Training loss: 1.3709255456924438
Validation loss: 2.109434346357981

Epoch: 6| Step: 7
Training loss: 1.9748114347457886
Validation loss: 2.117237309614817

Epoch: 6| Step: 8
Training loss: 2.165125846862793
Validation loss: 2.12900439898173

Epoch: 6| Step: 9
Training loss: 1.3293225765228271
Validation loss: 2.119863986968994

Epoch: 6| Step: 10
Training loss: 1.8265347480773926
Validation loss: 2.1396583914756775

Epoch: 6| Step: 11
Training loss: 2.4798970222473145
Validation loss: 2.1379544734954834

Epoch: 6| Step: 12
Training loss: 2.498042583465576
Validation loss: 2.127992351849874

Epoch: 6| Step: 13
Training loss: 1.659842848777771
Validation loss: 2.1441389520963035

Epoch: 179| Step: 0
Training loss: 2.2528934478759766
Validation loss: 2.1222418944040933

Epoch: 6| Step: 1
Training loss: 1.9243097305297852
Validation loss: 2.1189224322636924

Epoch: 6| Step: 2
Training loss: 1.645186185836792
Validation loss: 2.117372691631317

Epoch: 6| Step: 3
Training loss: 2.3447227478027344
Validation loss: 2.135522464911143

Epoch: 6| Step: 4
Training loss: 1.596653938293457
Validation loss: 2.142696658770243

Epoch: 6| Step: 5
Training loss: 2.1931231021881104
Validation loss: 2.1170308788617453

Epoch: 6| Step: 6
Training loss: 1.7467353343963623
Validation loss: 2.12093452612559

Epoch: 6| Step: 7
Training loss: 1.8677895069122314
Validation loss: 2.119867205619812

Epoch: 6| Step: 8
Training loss: 2.055605888366699
Validation loss: 2.1206780274709067

Epoch: 6| Step: 9
Training loss: 1.9455009698867798
Validation loss: 2.1082588036855063

Epoch: 6| Step: 10
Training loss: 1.7959449291229248
Validation loss: 2.114694515864054

Epoch: 6| Step: 11
Training loss: 1.808995008468628
Validation loss: 2.1050290067990622

Epoch: 6| Step: 12
Training loss: 2.148087978363037
Validation loss: 2.091223180294037

Epoch: 6| Step: 13
Training loss: 1.9141634702682495
Validation loss: 2.0838160316149392

Epoch: 180| Step: 0
Training loss: 2.0539467334747314
Validation loss: 2.0910902420679727

Epoch: 6| Step: 1
Training loss: 1.6974672079086304
Validation loss: 2.0844629605611167

Epoch: 6| Step: 2
Training loss: 2.212430477142334
Validation loss: 2.074719707171122

Epoch: 6| Step: 3
Training loss: 1.8981554508209229
Validation loss: 2.0863985617955527

Epoch: 6| Step: 4
Training loss: 1.7301610708236694
Validation loss: 2.071320096651713

Epoch: 6| Step: 5
Training loss: 2.828841209411621
Validation loss: 2.0794458985328674

Epoch: 6| Step: 6
Training loss: 1.802205204963684
Validation loss: 2.0764100352923074

Epoch: 6| Step: 7
Training loss: 1.7626469135284424
Validation loss: 2.089504619439443

Epoch: 6| Step: 8
Training loss: 1.9843018054962158
Validation loss: 2.101313511530558

Epoch: 6| Step: 9
Training loss: 2.0327839851379395
Validation loss: 2.101034184296926

Epoch: 6| Step: 10
Training loss: 2.183748722076416
Validation loss: 2.1098540226618447

Epoch: 6| Step: 11
Training loss: 1.759867548942566
Validation loss: 2.1234883666038513

Epoch: 6| Step: 12
Training loss: 2.063234567642212
Validation loss: 2.122256596883138

Epoch: 6| Step: 13
Training loss: 2.0729596614837646
Validation loss: 2.141476035118103

Epoch: 181| Step: 0
Training loss: 1.4062156677246094
Validation loss: 2.152357260386149

Epoch: 6| Step: 1
Training loss: 1.5823105573654175
Validation loss: 2.1551308035850525

Epoch: 6| Step: 2
Training loss: 1.6747078895568848
Validation loss: 2.1468344926834106

Epoch: 6| Step: 3
Training loss: 1.5782582759857178
Validation loss: 2.1492158571879068

Epoch: 6| Step: 4
Training loss: 2.0324628353118896
Validation loss: 2.1569984356562295

Epoch: 6| Step: 5
Training loss: 2.124417781829834
Validation loss: 2.1543434858322144

Epoch: 6| Step: 6
Training loss: 2.496575355529785
Validation loss: 2.138398289680481

Epoch: 6| Step: 7
Training loss: 1.9699087142944336
Validation loss: 2.1266940037409463

Epoch: 6| Step: 8
Training loss: 1.9757903814315796
Validation loss: 2.112805644671122

Epoch: 6| Step: 9
Training loss: 2.8028712272644043
Validation loss: 2.127919356028239

Epoch: 6| Step: 10
Training loss: 1.8048112392425537
Validation loss: 2.1090548237164817

Epoch: 6| Step: 11
Training loss: 1.6859080791473389
Validation loss: 2.1071790059407554

Epoch: 6| Step: 12
Training loss: 1.9113080501556396
Validation loss: 2.095509688059489

Epoch: 6| Step: 13
Training loss: 1.9004639387130737
Validation loss: 2.075033982594808

Epoch: 182| Step: 0
Training loss: 1.7346961498260498
Validation loss: 2.0851494471232095

Epoch: 6| Step: 1
Training loss: 2.648502826690674
Validation loss: 2.082201679547628

Epoch: 6| Step: 2
Training loss: 1.6759592294692993
Validation loss: 2.0830188194910684

Epoch: 6| Step: 3
Training loss: 1.8549919128417969
Validation loss: 2.0848705172538757

Epoch: 6| Step: 4
Training loss: 0.9691724181175232
Validation loss: 2.0931413571039834

Epoch: 6| Step: 5
Training loss: 2.2059717178344727
Validation loss: 2.100744068622589

Epoch: 6| Step: 6
Training loss: 1.8970463275909424
Validation loss: 2.1046695510546365

Epoch: 6| Step: 7
Training loss: 2.3572592735290527
Validation loss: 2.1048643787701926

Epoch: 6| Step: 8
Training loss: 1.8548717498779297
Validation loss: 2.1007293065389

Epoch: 6| Step: 9
Training loss: 2.750662326812744
Validation loss: 2.1004198789596558

Epoch: 6| Step: 10
Training loss: 1.87386953830719
Validation loss: 2.0951416889826455

Epoch: 6| Step: 11
Training loss: 2.1255171298980713
Validation loss: 2.114969571431478

Epoch: 6| Step: 12
Training loss: 1.5624101161956787
Validation loss: 2.1133850812911987

Epoch: 6| Step: 13
Training loss: 1.8762322664260864
Validation loss: 2.1032827297846475

Epoch: 183| Step: 0
Training loss: 1.7755606174468994
Validation loss: 2.1245718598365784

Epoch: 6| Step: 1
Training loss: 2.338268518447876
Validation loss: 2.142805894215902

Epoch: 6| Step: 2
Training loss: 1.9584944248199463
Validation loss: 2.125723918279012

Epoch: 6| Step: 3
Training loss: 1.763589859008789
Validation loss: 2.1410064101219177

Epoch: 6| Step: 4
Training loss: 1.9540655612945557
Validation loss: 2.136451562245687

Epoch: 6| Step: 5
Training loss: 2.007223606109619
Validation loss: 2.1325338880221048

Epoch: 6| Step: 6
Training loss: 2.570943593978882
Validation loss: 2.132488568623861

Epoch: 6| Step: 7
Training loss: 1.4147279262542725
Validation loss: 2.119071920712789

Epoch: 6| Step: 8
Training loss: 2.4678449630737305
Validation loss: 2.1372563242912292

Epoch: 6| Step: 9
Training loss: 1.464125156402588
Validation loss: 2.132648150126139

Epoch: 6| Step: 10
Training loss: 2.1599771976470947
Validation loss: 2.119969964027405

Epoch: 6| Step: 11
Training loss: 2.1941819190979004
Validation loss: 2.1146008372306824

Epoch: 6| Step: 12
Training loss: 1.710904836654663
Validation loss: 2.1170301834742227

Epoch: 6| Step: 13
Training loss: 1.1787289381027222
Validation loss: 2.0880959232648215

Epoch: 184| Step: 0
Training loss: 1.8447734117507935
Validation loss: 2.1083633303642273

Epoch: 6| Step: 1
Training loss: 1.2338323593139648
Validation loss: 2.0981379548708596

Epoch: 6| Step: 2
Training loss: 2.3038718700408936
Validation loss: 2.110957086086273

Epoch: 6| Step: 3
Training loss: 1.2787580490112305
Validation loss: 2.108888785044352

Epoch: 6| Step: 4
Training loss: 1.8661348819732666
Validation loss: 2.0978914300600686

Epoch: 6| Step: 5
Training loss: 1.6424912214279175
Validation loss: 2.1037082274754844

Epoch: 6| Step: 6
Training loss: 1.7037851810455322
Validation loss: 2.099648932615916

Epoch: 6| Step: 7
Training loss: 2.1717700958251953
Validation loss: 2.119345466295878

Epoch: 6| Step: 8
Training loss: 2.2584893703460693
Validation loss: 2.1159138480822244

Epoch: 6| Step: 9
Training loss: 2.318289279937744
Validation loss: 2.1188013156255088

Epoch: 6| Step: 10
Training loss: 2.222445011138916
Validation loss: 2.116360306739807

Epoch: 6| Step: 11
Training loss: 1.507784128189087
Validation loss: 2.114211678504944

Epoch: 6| Step: 12
Training loss: 2.09979248046875
Validation loss: 2.133010228474935

Epoch: 6| Step: 13
Training loss: 2.667421340942383
Validation loss: 2.132355014483134

Epoch: 185| Step: 0
Training loss: 1.7138540744781494
Validation loss: 2.13667094707489

Epoch: 6| Step: 1
Training loss: 2.3033759593963623
Validation loss: 2.139257629712423

Epoch: 6| Step: 2
Training loss: 1.4372268915176392
Validation loss: 2.1425084273020425

Epoch: 6| Step: 3
Training loss: 2.2773077487945557
Validation loss: 2.1379931569099426

Epoch: 6| Step: 4
Training loss: 1.8572994470596313
Validation loss: 2.1450894276301065

Epoch: 6| Step: 5
Training loss: 1.9590996503829956
Validation loss: 2.143324891726176

Epoch: 6| Step: 6
Training loss: 2.047191858291626
Validation loss: 2.1367708444595337

Epoch: 6| Step: 7
Training loss: 1.6352903842926025
Validation loss: 2.1359090407689414

Epoch: 6| Step: 8
Training loss: 2.235291004180908
Validation loss: 2.1234786113103232

Epoch: 6| Step: 9
Training loss: 1.5703566074371338
Validation loss: 2.104883352915446

Epoch: 6| Step: 10
Training loss: 1.6632517576217651
Validation loss: 2.1028260588645935

Epoch: 6| Step: 11
Training loss: 2.454824924468994
Validation loss: 2.1214561263720193

Epoch: 6| Step: 12
Training loss: 2.127960205078125
Validation loss: 2.121896266937256

Epoch: 6| Step: 13
Training loss: 1.6047964096069336
Validation loss: 2.1169294714927673

Epoch: 186| Step: 0
Training loss: 2.0653295516967773
Validation loss: 2.09380704164505

Epoch: 6| Step: 1
Training loss: 1.4009878635406494
Validation loss: 2.1046350399653115

Epoch: 6| Step: 2
Training loss: 1.6873232126235962
Validation loss: 2.097314774990082

Epoch: 6| Step: 3
Training loss: 1.9248089790344238
Validation loss: 2.0947142442067466

Epoch: 6| Step: 4
Training loss: 1.9315975904464722
Validation loss: 2.110085427761078

Epoch: 6| Step: 5
Training loss: 1.9564425945281982
Validation loss: 2.1165202458699546

Epoch: 6| Step: 6
Training loss: 2.133227586746216
Validation loss: 2.1167734066645303

Epoch: 6| Step: 7
Training loss: 2.4361510276794434
Validation loss: 2.1211169759432473

Epoch: 6| Step: 8
Training loss: 1.8272130489349365
Validation loss: 2.1236660480499268

Epoch: 6| Step: 9
Training loss: 1.6907615661621094
Validation loss: 2.1345380942026773

Epoch: 6| Step: 10
Training loss: 1.8309909105300903
Validation loss: 2.136620899041494

Epoch: 6| Step: 11
Training loss: 1.929206132888794
Validation loss: 2.128083606561025

Epoch: 6| Step: 12
Training loss: 2.109311580657959
Validation loss: 2.141682187716166

Epoch: 6| Step: 13
Training loss: 2.143808364868164
Validation loss: 2.131447672843933

Epoch: 187| Step: 0
Training loss: 2.2963438034057617
Validation loss: 2.136831005414327

Epoch: 6| Step: 1
Training loss: 1.7824409008026123
Validation loss: 2.1303703784942627

Epoch: 6| Step: 2
Training loss: 1.899007797241211
Validation loss: 2.126226564248403

Epoch: 6| Step: 3
Training loss: 1.3825221061706543
Validation loss: 2.108085870742798

Epoch: 6| Step: 4
Training loss: 1.4176524877548218
Validation loss: 2.112931470076243

Epoch: 6| Step: 5
Training loss: 1.6874901056289673
Validation loss: 2.114912132422129

Epoch: 6| Step: 6
Training loss: 2.3677122592926025
Validation loss: 2.114721417427063

Epoch: 6| Step: 7
Training loss: 1.6918137073516846
Validation loss: 2.1122430165608725

Epoch: 6| Step: 8
Training loss: 1.9365553855895996
Validation loss: 2.107032318909963

Epoch: 6| Step: 9
Training loss: 2.2526731491088867
Validation loss: 2.1246590614318848

Epoch: 6| Step: 10
Training loss: 2.216081142425537
Validation loss: 2.119060536225637

Epoch: 6| Step: 11
Training loss: 2.266294240951538
Validation loss: 2.1094502806663513

Epoch: 6| Step: 12
Training loss: 1.4069218635559082
Validation loss: 2.117511431376139

Epoch: 6| Step: 13
Training loss: 2.143998384475708
Validation loss: 2.121151248613993

Epoch: 188| Step: 0
Training loss: 1.9360939264297485
Validation loss: 2.1214330395062766

Epoch: 6| Step: 1
Training loss: 2.2323861122131348
Validation loss: 2.130869468053182

Epoch: 6| Step: 2
Training loss: 1.9630894660949707
Validation loss: 2.1113696893056235

Epoch: 6| Step: 3
Training loss: 2.281858444213867
Validation loss: 2.128084043661753

Epoch: 6| Step: 4
Training loss: 1.9598089456558228
Validation loss: 2.1225421826044717

Epoch: 6| Step: 5
Training loss: 1.8384089469909668
Validation loss: 2.1151825984319053

Epoch: 6| Step: 6
Training loss: 1.7098886966705322
Validation loss: 2.1196380456288657

Epoch: 6| Step: 7
Training loss: 1.9978573322296143
Validation loss: 2.1053074995676675

Epoch: 6| Step: 8
Training loss: 1.657644510269165
Validation loss: 2.12130469083786

Epoch: 6| Step: 9
Training loss: 1.862816572189331
Validation loss: 2.1246228416760764

Epoch: 6| Step: 10
Training loss: 1.755171537399292
Validation loss: 2.1049854159355164

Epoch: 6| Step: 11
Training loss: 1.8040921688079834
Validation loss: 2.105416019757589

Epoch: 6| Step: 12
Training loss: 1.8040063381195068
Validation loss: 2.1081495881080627

Epoch: 6| Step: 13
Training loss: 1.9281456470489502
Validation loss: 2.116409500439962

Epoch: 189| Step: 0
Training loss: 1.7064129114151
Validation loss: 2.109676420688629

Epoch: 6| Step: 1
Training loss: 2.2746593952178955
Validation loss: 2.099279801050822

Epoch: 6| Step: 2
Training loss: 2.3182926177978516
Validation loss: 2.1037785013516745

Epoch: 6| Step: 3
Training loss: 1.9778608083724976
Validation loss: 2.093683401743571

Epoch: 6| Step: 4
Training loss: 1.9683823585510254
Validation loss: 2.0924245913823447

Epoch: 6| Step: 5
Training loss: 1.9038881063461304
Validation loss: 2.095591187477112

Epoch: 6| Step: 6
Training loss: 1.7259087562561035
Validation loss: 2.1103582978248596

Epoch: 6| Step: 7
Training loss: 1.9810314178466797
Validation loss: 2.0961241126060486

Epoch: 6| Step: 8
Training loss: 1.7515774965286255
Validation loss: 2.0985994140307107

Epoch: 6| Step: 9
Training loss: 2.0780792236328125
Validation loss: 2.106222152709961

Epoch: 6| Step: 10
Training loss: 2.386746406555176
Validation loss: 2.110324045022329

Epoch: 6| Step: 11
Training loss: 1.5524587631225586
Validation loss: 2.1028266151746116

Epoch: 6| Step: 12
Training loss: 2.0139851570129395
Validation loss: 2.106163223584493

Epoch: 6| Step: 13
Training loss: 2.151527166366577
Validation loss: 2.119413177172343

Epoch: 190| Step: 0
Training loss: 1.1600614786148071
Validation loss: 2.1406708558400473

Epoch: 6| Step: 1
Training loss: 1.8703125715255737
Validation loss: 2.1277429660161338

Epoch: 6| Step: 2
Training loss: 1.1196105480194092
Validation loss: 2.1283124685287476

Epoch: 6| Step: 3
Training loss: 2.3292832374572754
Validation loss: 2.1234494050343833

Epoch: 6| Step: 4
Training loss: 1.2877111434936523
Validation loss: 2.1103928685188293

Epoch: 6| Step: 5
Training loss: 2.5660910606384277
Validation loss: 2.105260153611501

Epoch: 6| Step: 6
Training loss: 1.590815782546997
Validation loss: 2.1043699781099954

Epoch: 6| Step: 7
Training loss: 2.580322742462158
Validation loss: 2.106325368086497

Epoch: 6| Step: 8
Training loss: 1.8048490285873413
Validation loss: 2.1118337512016296

Epoch: 6| Step: 9
Training loss: 2.433812379837036
Validation loss: 2.118230680624644

Epoch: 6| Step: 10
Training loss: 2.1808481216430664
Validation loss: 2.1230374773343406

Epoch: 6| Step: 11
Training loss: 2.4127306938171387
Validation loss: 2.105999767780304

Epoch: 6| Step: 12
Training loss: 1.6497795581817627
Validation loss: 2.1219640175501504

Epoch: 6| Step: 13
Training loss: 2.05251145362854
Validation loss: 2.1146204074223838

Epoch: 191| Step: 0
Training loss: 1.5246937274932861
Validation loss: 2.1284029881159463

Epoch: 6| Step: 1
Training loss: 1.7878272533416748
Validation loss: 2.14005970954895

Epoch: 6| Step: 2
Training loss: 2.061819076538086
Validation loss: 2.109964966773987

Epoch: 6| Step: 3
Training loss: 1.6902024745941162
Validation loss: 2.1165724396705627

Epoch: 6| Step: 4
Training loss: 1.925665259361267
Validation loss: 2.1225191752115884

Epoch: 6| Step: 5
Training loss: 2.2431578636169434
Validation loss: 2.117085556189219

Epoch: 6| Step: 6
Training loss: 2.176793098449707
Validation loss: 2.123352030913035

Epoch: 6| Step: 7
Training loss: 1.8407213687896729
Validation loss: 2.125470221042633

Epoch: 6| Step: 8
Training loss: 1.90882408618927
Validation loss: 2.1279693444569907

Epoch: 6| Step: 9
Training loss: 2.129652500152588
Validation loss: 2.1279961466789246

Epoch: 6| Step: 10
Training loss: 1.7044676542282104
Validation loss: 2.107872486114502

Epoch: 6| Step: 11
Training loss: 1.9034565687179565
Validation loss: 2.120516578356425

Epoch: 6| Step: 12
Training loss: 2.1347618103027344
Validation loss: 2.110460559527079

Epoch: 6| Step: 13
Training loss: 1.6612327098846436
Validation loss: 2.124933878580729

Epoch: 192| Step: 0
Training loss: 2.2475733757019043
Validation loss: 2.126973787943522

Epoch: 6| Step: 1
Training loss: 1.9069602489471436
Validation loss: 2.123133420944214

Epoch: 6| Step: 2
Training loss: 2.215348243713379
Validation loss: 2.125363012154897

Epoch: 6| Step: 3
Training loss: 1.5460797548294067
Validation loss: 2.121056834856669

Epoch: 6| Step: 4
Training loss: 2.534656047821045
Validation loss: 2.126359740893046

Epoch: 6| Step: 5
Training loss: 1.9811878204345703
Validation loss: 2.1250184973080954

Epoch: 6| Step: 6
Training loss: 1.7567510604858398
Validation loss: 2.116782248020172

Epoch: 6| Step: 7
Training loss: 1.4748058319091797
Validation loss: 2.1202558080355325

Epoch: 6| Step: 8
Training loss: 2.464653968811035
Validation loss: 2.114056567351023

Epoch: 6| Step: 9
Training loss: 1.7931246757507324
Validation loss: 2.1361239353815713

Epoch: 6| Step: 10
Training loss: 1.2626677751541138
Validation loss: 2.1215340296427407

Epoch: 6| Step: 11
Training loss: 2.256002187728882
Validation loss: 2.1276471416155496

Epoch: 6| Step: 12
Training loss: 1.9791518449783325
Validation loss: 2.13405579328537

Epoch: 6| Step: 13
Training loss: 1.020308494567871
Validation loss: 2.129109561443329

Epoch: 193| Step: 0
Training loss: 2.0637574195861816
Validation loss: 2.1262013713518777

Epoch: 6| Step: 1
Training loss: 1.7430145740509033
Validation loss: 2.126807967821757

Epoch: 6| Step: 2
Training loss: 1.7635176181793213
Validation loss: 2.1438990235328674

Epoch: 6| Step: 3
Training loss: 2.0876412391662598
Validation loss: 2.1328396995862327

Epoch: 6| Step: 4
Training loss: 1.4210084676742554
Validation loss: 2.1523528695106506

Epoch: 6| Step: 5
Training loss: 2.001436233520508
Validation loss: 2.1430629094441733

Epoch: 6| Step: 6
Training loss: 1.7427470684051514
Validation loss: 2.145626942316691

Epoch: 6| Step: 7
Training loss: 2.784013032913208
Validation loss: 2.141311446825663

Epoch: 6| Step: 8
Training loss: 1.5249449014663696
Validation loss: 2.126857499281565

Epoch: 6| Step: 9
Training loss: 2.305748462677002
Validation loss: 2.12490447362264

Epoch: 6| Step: 10
Training loss: 1.406718373298645
Validation loss: 2.1288136641184487

Epoch: 6| Step: 11
Training loss: 2.0695087909698486
Validation loss: 2.1305904189745584

Epoch: 6| Step: 12
Training loss: 1.541236162185669
Validation loss: 2.139569262663523

Epoch: 6| Step: 13
Training loss: 2.1006019115448
Validation loss: 2.1377553145090737

Epoch: 194| Step: 0
Training loss: 1.4537543058395386
Validation loss: 2.1351553201675415

Epoch: 6| Step: 1
Training loss: 1.90805184841156
Validation loss: 2.1312130093574524

Epoch: 6| Step: 2
Training loss: 1.9429811239242554
Validation loss: 2.128170927365621

Epoch: 6| Step: 3
Training loss: 1.5698466300964355
Validation loss: 2.140925089518229

Epoch: 6| Step: 4
Training loss: 1.2254523038864136
Validation loss: 2.140734155972799

Epoch: 6| Step: 5
Training loss: 2.2629761695861816
Validation loss: 2.141579747200012

Epoch: 6| Step: 6
Training loss: 1.7646698951721191
Validation loss: 2.161310056845347

Epoch: 6| Step: 7
Training loss: 1.955603837966919
Validation loss: 2.1486085057258606

Epoch: 6| Step: 8
Training loss: 2.0593721866607666
Validation loss: 2.1371349096298218

Epoch: 6| Step: 9
Training loss: 2.1718595027923584
Validation loss: 2.1451473434766135

Epoch: 6| Step: 10
Training loss: 2.359511375427246
Validation loss: 2.1405141949653625

Epoch: 6| Step: 11
Training loss: 1.4902018308639526
Validation loss: 2.1347049474716187

Epoch: 6| Step: 12
Training loss: 1.8994388580322266
Validation loss: 2.129285216331482

Epoch: 6| Step: 13
Training loss: 2.295422077178955
Validation loss: 2.114818036556244

Epoch: 195| Step: 0
Training loss: 1.6612486839294434
Validation loss: 2.1278531153996787

Epoch: 6| Step: 1
Training loss: 1.742169737815857
Validation loss: 2.126938263575236

Epoch: 6| Step: 2
Training loss: 1.4844212532043457
Validation loss: 2.1292981704076133

Epoch: 6| Step: 3
Training loss: 1.5895917415618896
Validation loss: 2.127397278944651

Epoch: 6| Step: 4
Training loss: 2.6256723403930664
Validation loss: 2.137468079725901

Epoch: 6| Step: 5
Training loss: 2.2010655403137207
Validation loss: 2.1399725874265036

Epoch: 6| Step: 6
Training loss: 2.4322926998138428
Validation loss: 2.148283223311106

Epoch: 6| Step: 7
Training loss: 1.7084616422653198
Validation loss: 2.1494572957356772

Epoch: 6| Step: 8
Training loss: 1.3478801250457764
Validation loss: 2.1462091406186423

Epoch: 6| Step: 9
Training loss: 2.3917574882507324
Validation loss: 2.13720033566157

Epoch: 6| Step: 10
Training loss: 2.1454873085021973
Validation loss: 2.121953070163727

Epoch: 6| Step: 11
Training loss: 1.5271247625350952
Validation loss: 2.1377331018447876

Epoch: 6| Step: 12
Training loss: 1.877112627029419
Validation loss: 2.14565501610438

Epoch: 6| Step: 13
Training loss: 1.8867617845535278
Validation loss: 2.1260998845100403

Epoch: 196| Step: 0
Training loss: 2.4844412803649902
Validation loss: 2.1218095223108926

Epoch: 6| Step: 1
Training loss: 1.629120111465454
Validation loss: 2.1305655241012573

Epoch: 6| Step: 2
Training loss: 1.4845472574234009
Validation loss: 2.1108767787615457

Epoch: 6| Step: 3
Training loss: 1.4312744140625
Validation loss: 2.1176608006159463

Epoch: 6| Step: 4
Training loss: 2.1082396507263184
Validation loss: 2.1244729359944663

Epoch: 6| Step: 5
Training loss: 2.191089153289795
Validation loss: 2.1248377362887063

Epoch: 6| Step: 6
Training loss: 2.4390978813171387
Validation loss: 2.1106804410616555

Epoch: 6| Step: 7
Training loss: 2.2316110134124756
Validation loss: 2.1220854918162027

Epoch: 6| Step: 8
Training loss: 2.203218936920166
Validation loss: 2.1186718543370566

Epoch: 6| Step: 9
Training loss: 1.9792600870132446
Validation loss: 2.1159133911132812

Epoch: 6| Step: 10
Training loss: 1.7516865730285645
Validation loss: 2.1175705989201865

Epoch: 6| Step: 11
Training loss: 2.1983697414398193
Validation loss: 2.124251365661621

Epoch: 6| Step: 12
Training loss: 1.5827901363372803
Validation loss: 2.1263126532236734

Epoch: 6| Step: 13
Training loss: 1.3776769638061523
Validation loss: 2.1282017628351846

Epoch: 197| Step: 0
Training loss: 1.9658071994781494
Validation loss: 2.117399533589681

Epoch: 6| Step: 1
Training loss: 2.1787467002868652
Validation loss: 2.124470134576162

Epoch: 6| Step: 2
Training loss: 1.6624730825424194
Validation loss: 2.144632577896118

Epoch: 6| Step: 3
Training loss: 2.606339931488037
Validation loss: 2.136695901552836

Epoch: 6| Step: 4
Training loss: 1.4654881954193115
Validation loss: 2.127041300137838

Epoch: 6| Step: 5
Training loss: 1.3482801914215088
Validation loss: 2.126434604326884

Epoch: 6| Step: 6
Training loss: 2.3025989532470703
Validation loss: 2.118502994378408

Epoch: 6| Step: 7
Training loss: 1.9830436706542969
Validation loss: 2.129714787006378

Epoch: 6| Step: 8
Training loss: 2.945990800857544
Validation loss: 2.1346457600593567

Epoch: 6| Step: 9
Training loss: 1.6476240158081055
Validation loss: 2.1063426534334817

Epoch: 6| Step: 10
Training loss: 1.5383312702178955
Validation loss: 2.1135445634524026

Epoch: 6| Step: 11
Training loss: 2.161402702331543
Validation loss: 2.116253674030304

Epoch: 6| Step: 12
Training loss: 1.4486362934112549
Validation loss: 2.1091352502504983

Epoch: 6| Step: 13
Training loss: 1.4287731647491455
Validation loss: 2.1181832551956177

Epoch: 198| Step: 0
Training loss: 1.7798173427581787
Validation loss: 2.126349369684855

Epoch: 6| Step: 1
Training loss: 1.588456392288208
Validation loss: 2.1136672695477805

Epoch: 6| Step: 2
Training loss: 2.066117763519287
Validation loss: 2.1257278521855674

Epoch: 6| Step: 3
Training loss: 2.1796023845672607
Validation loss: 2.1224055687586465

Epoch: 6| Step: 4
Training loss: 1.9998079538345337
Validation loss: 2.122875769933065

Epoch: 6| Step: 5
Training loss: 2.2156553268432617
Validation loss: 2.123332977294922

Epoch: 6| Step: 6
Training loss: 1.8131545782089233
Validation loss: 2.118052343527476

Epoch: 6| Step: 7
Training loss: 1.7508883476257324
Validation loss: 2.12094646692276

Epoch: 6| Step: 8
Training loss: 1.7382439374923706
Validation loss: 2.127775947252909

Epoch: 6| Step: 9
Training loss: 1.9836881160736084
Validation loss: 2.1177284717559814

Epoch: 6| Step: 10
Training loss: 1.892086148262024
Validation loss: 2.105434795220693

Epoch: 6| Step: 11
Training loss: 1.6628413200378418
Validation loss: 2.112082322438558

Epoch: 6| Step: 12
Training loss: 1.555532455444336
Validation loss: 2.1131023367245994

Epoch: 6| Step: 13
Training loss: 2.165391206741333
Validation loss: 2.122752626736959

Epoch: 199| Step: 0
Training loss: 1.0642080307006836
Validation loss: 2.131147623062134

Epoch: 6| Step: 1
Training loss: 1.990224003791809
Validation loss: 2.1498296658198037

Epoch: 6| Step: 2
Training loss: 2.294052839279175
Validation loss: 2.1411539117495217

Epoch: 6| Step: 3
Training loss: 1.9241517782211304
Validation loss: 2.1879809498786926

Epoch: 6| Step: 4
Training loss: 2.354492425918579
Validation loss: 2.154592831929525

Epoch: 6| Step: 5
Training loss: 1.8977205753326416
Validation loss: 2.1567031741142273

Epoch: 6| Step: 6
Training loss: 1.7737274169921875
Validation loss: 2.1462546984354653

Epoch: 6| Step: 7
Training loss: 1.6365725994110107
Validation loss: 2.144268810749054

Epoch: 6| Step: 8
Training loss: 2.360518455505371
Validation loss: 2.126849095026652

Epoch: 6| Step: 9
Training loss: 1.9628872871398926
Validation loss: 2.1162500580151877

Epoch: 6| Step: 10
Training loss: 2.408013343811035
Validation loss: 2.118975897630056

Epoch: 6| Step: 11
Training loss: 1.4520008563995361
Validation loss: 2.1173535784085593

Epoch: 6| Step: 12
Training loss: 1.9287495613098145
Validation loss: 2.117652436097463

Epoch: 6| Step: 13
Training loss: 2.0909838676452637
Validation loss: 2.1140110095342

Epoch: 200| Step: 0
Training loss: 1.6120795011520386
Validation loss: 2.11528209845225

Epoch: 6| Step: 1
Training loss: 1.660786747932434
Validation loss: 2.1008844574292502

Epoch: 6| Step: 2
Training loss: 1.9989197254180908
Validation loss: 2.117445786794027

Epoch: 6| Step: 3
Training loss: 2.7223825454711914
Validation loss: 2.126516421635946

Epoch: 6| Step: 4
Training loss: 2.1009464263916016
Validation loss: 2.1070878307024636

Epoch: 6| Step: 5
Training loss: 1.9642395973205566
Validation loss: 2.1046871344248452

Epoch: 6| Step: 6
Training loss: 1.7258672714233398
Validation loss: 2.1127618153889975

Epoch: 6| Step: 7
Training loss: 2.1591153144836426
Validation loss: 2.125050644079844

Epoch: 6| Step: 8
Training loss: 2.119591236114502
Validation loss: 2.1257935961087546

Epoch: 6| Step: 9
Training loss: 1.704086184501648
Validation loss: 2.1363865733146667

Epoch: 6| Step: 10
Training loss: 1.5768179893493652
Validation loss: 2.154642701148987

Epoch: 6| Step: 11
Training loss: 1.9242786169052124
Validation loss: 2.1386508345603943

Epoch: 6| Step: 12
Training loss: 1.8003361225128174
Validation loss: 2.1505300005277

Epoch: 6| Step: 13
Training loss: 1.8338271379470825
Validation loss: 2.163038154443105

Epoch: 201| Step: 0
Training loss: 1.8993103504180908
Validation loss: 2.1421305934588113

Epoch: 6| Step: 1
Training loss: 1.7196173667907715
Validation loss: 2.145599583784739

Epoch: 6| Step: 2
Training loss: 1.4661612510681152
Validation loss: 2.137274364630381

Epoch: 6| Step: 3
Training loss: 2.4021410942077637
Validation loss: 2.1387388904889426

Epoch: 6| Step: 4
Training loss: 1.7873337268829346
Validation loss: 2.1334721644719443

Epoch: 6| Step: 5
Training loss: 1.7563645839691162
Validation loss: 2.128970523675283

Epoch: 6| Step: 6
Training loss: 2.7026169300079346
Validation loss: 2.1273827950159707

Epoch: 6| Step: 7
Training loss: 1.9758272171020508
Validation loss: 2.1409345666567483

Epoch: 6| Step: 8
Training loss: 1.5836926698684692
Validation loss: 2.123737116654714

Epoch: 6| Step: 9
Training loss: 1.8006682395935059
Validation loss: 2.1275935967763266

Epoch: 6| Step: 10
Training loss: 2.0478601455688477
Validation loss: 2.133361260096232

Epoch: 6| Step: 11
Training loss: 2.094487190246582
Validation loss: 2.123357673486074

Epoch: 6| Step: 12
Training loss: 1.7349122762680054
Validation loss: 2.138433257738749

Epoch: 6| Step: 13
Training loss: 1.6233909130096436
Validation loss: 2.133882164955139

Epoch: 202| Step: 0
Training loss: 1.6120169162750244
Validation loss: 2.157819449901581

Epoch: 6| Step: 1
Training loss: 2.1724300384521484
Validation loss: 2.1438931028048196

Epoch: 6| Step: 2
Training loss: 1.418196678161621
Validation loss: 2.1483484705289206

Epoch: 6| Step: 3
Training loss: 1.4295859336853027
Validation loss: 2.1526561180750527

Epoch: 6| Step: 4
Training loss: 1.3806096315383911
Validation loss: 2.1576204895973206

Epoch: 6| Step: 5
Training loss: 1.190659761428833
Validation loss: 2.16717799504598

Epoch: 6| Step: 6
Training loss: 1.9622386693954468
Validation loss: 2.162380854288737

Epoch: 6| Step: 7
Training loss: 2.8725385665893555
Validation loss: 2.174676855405172

Epoch: 6| Step: 8
Training loss: 1.9187088012695312
Validation loss: 2.1450281540552774

Epoch: 6| Step: 9
Training loss: 2.2907750606536865
Validation loss: 2.14037694533666

Epoch: 6| Step: 10
Training loss: 2.6363282203674316
Validation loss: 2.1354376872380576

Epoch: 6| Step: 11
Training loss: 1.3665928840637207
Validation loss: 2.136272410551707

Epoch: 6| Step: 12
Training loss: 2.405402183532715
Validation loss: 2.133168717225393

Epoch: 6| Step: 13
Training loss: 1.8519757986068726
Validation loss: 2.133293926715851

Epoch: 203| Step: 0
Training loss: 2.3881144523620605
Validation loss: 2.128224531809489

Epoch: 6| Step: 1
Training loss: 2.071633815765381
Validation loss: 2.137735426425934

Epoch: 6| Step: 2
Training loss: 1.276174545288086
Validation loss: 2.130854388078054

Epoch: 6| Step: 3
Training loss: 1.9525043964385986
Validation loss: 2.1474729975064597

Epoch: 6| Step: 4
Training loss: 1.5003163814544678
Validation loss: 2.135851502418518

Epoch: 6| Step: 5
Training loss: 1.897578239440918
Validation loss: 2.1509474714597068

Epoch: 6| Step: 6
Training loss: 1.9042532444000244
Validation loss: 2.165716369946798

Epoch: 6| Step: 7
Training loss: 1.8852903842926025
Validation loss: 2.164936105410258

Epoch: 6| Step: 8
Training loss: 1.6831704378128052
Validation loss: 2.173140068848928

Epoch: 6| Step: 9
Training loss: 1.9676487445831299
Validation loss: 2.166690389315287

Epoch: 6| Step: 10
Training loss: 2.3503177165985107
Validation loss: 2.167533020178477

Epoch: 6| Step: 11
Training loss: 1.4611499309539795
Validation loss: 2.164466361204783

Epoch: 6| Step: 12
Training loss: 1.918501853942871
Validation loss: 2.1470992962519326

Epoch: 6| Step: 13
Training loss: 2.1279406547546387
Validation loss: 2.155154804388682

Epoch: 204| Step: 0
Training loss: 1.785151720046997
Validation loss: 2.1406357089678445

Epoch: 6| Step: 1
Training loss: 1.6680285930633545
Validation loss: 2.1313721338907876

Epoch: 6| Step: 2
Training loss: 2.099066734313965
Validation loss: 2.1204216281572976

Epoch: 6| Step: 3
Training loss: 1.954403042793274
Validation loss: 2.132938345273336

Epoch: 6| Step: 4
Training loss: 2.362269401550293
Validation loss: 2.137592871983846

Epoch: 6| Step: 5
Training loss: 1.5772788524627686
Validation loss: 2.1340434551239014

Epoch: 6| Step: 6
Training loss: 1.685192346572876
Validation loss: 2.1456201672554016

Epoch: 6| Step: 7
Training loss: 2.0110154151916504
Validation loss: 2.1346295873324075

Epoch: 6| Step: 8
Training loss: 2.396493673324585
Validation loss: 2.13804562886556

Epoch: 6| Step: 9
Training loss: 1.4571765661239624
Validation loss: 2.1286846001942954

Epoch: 6| Step: 10
Training loss: 1.1862995624542236
Validation loss: 2.1335227886835733

Epoch: 6| Step: 11
Training loss: 1.4708974361419678
Validation loss: 2.1540553172429404

Epoch: 6| Step: 12
Training loss: 2.1792047023773193
Validation loss: 2.1513617038726807

Epoch: 6| Step: 13
Training loss: 2.16513991355896
Validation loss: 2.1355322996775308

Epoch: 205| Step: 0
Training loss: 1.7441742420196533
Validation loss: 2.1479435563087463

Epoch: 6| Step: 1
Training loss: 1.961754560470581
Validation loss: 2.140634377797445

Epoch: 6| Step: 2
Training loss: 1.8568899631500244
Validation loss: 2.1579936742782593

Epoch: 6| Step: 3
Training loss: 2.350677490234375
Validation loss: 2.13441135485967

Epoch: 6| Step: 4
Training loss: 1.8366281986236572
Validation loss: 2.148360093434652

Epoch: 6| Step: 5
Training loss: 1.5492534637451172
Validation loss: 2.151518781979879

Epoch: 6| Step: 6
Training loss: 1.9076720476150513
Validation loss: 2.149767835934957

Epoch: 6| Step: 7
Training loss: 1.904163122177124
Validation loss: 2.1267404158910117

Epoch: 6| Step: 8
Training loss: 1.7060880661010742
Validation loss: 2.11646831035614

Epoch: 6| Step: 9
Training loss: 1.614562749862671
Validation loss: 2.1217764814694724

Epoch: 6| Step: 10
Training loss: 1.8374487161636353
Validation loss: 2.129948874314626

Epoch: 6| Step: 11
Training loss: 1.7880632877349854
Validation loss: 2.1213287115097046

Epoch: 6| Step: 12
Training loss: 1.427793025970459
Validation loss: 2.1187432010968528

Epoch: 6| Step: 13
Training loss: 3.072455883026123
Validation loss: 2.1148565212885537

Epoch: 206| Step: 0
Training loss: 1.6035757064819336
Validation loss: 2.1220836440722146

Epoch: 6| Step: 1
Training loss: 2.309134006500244
Validation loss: 2.1197992165883384

Epoch: 6| Step: 2
Training loss: 2.3300771713256836
Validation loss: 2.126045266787211

Epoch: 6| Step: 3
Training loss: 1.9973230361938477
Validation loss: 2.138198733329773

Epoch: 6| Step: 4
Training loss: 1.2456305027008057
Validation loss: 2.1353056033452353

Epoch: 6| Step: 5
Training loss: 2.152733087539673
Validation loss: 2.131409148375193

Epoch: 6| Step: 6
Training loss: 1.8052356243133545
Validation loss: 2.149256924788157

Epoch: 6| Step: 7
Training loss: 1.3537522554397583
Validation loss: 2.1319197018941245

Epoch: 6| Step: 8
Training loss: 1.6067719459533691
Validation loss: 2.1520922581354776

Epoch: 6| Step: 9
Training loss: 1.1283830404281616
Validation loss: 2.146530826886495

Epoch: 6| Step: 10
Training loss: 1.9003164768218994
Validation loss: 2.142198920249939

Epoch: 6| Step: 11
Training loss: 2.3096823692321777
Validation loss: 2.166684408982595

Epoch: 6| Step: 12
Training loss: 1.4738086462020874
Validation loss: 2.159633676211039

Epoch: 6| Step: 13
Training loss: 2.8713555335998535
Validation loss: 2.154858946800232

Epoch: 207| Step: 0
Training loss: 2.321943759918213
Validation loss: 2.1664830843607583

Epoch: 6| Step: 1
Training loss: 1.0371475219726562
Validation loss: 2.166565994421641

Epoch: 6| Step: 2
Training loss: 1.2608447074890137
Validation loss: 2.167267918586731

Epoch: 6| Step: 3
Training loss: 1.310084581375122
Validation loss: 2.1598594784736633

Epoch: 6| Step: 4
Training loss: 2.018305778503418
Validation loss: 2.1501712600390115

Epoch: 6| Step: 5
Training loss: 2.3995072841644287
Validation loss: 2.14670991897583

Epoch: 6| Step: 6
Training loss: 1.4377599954605103
Validation loss: 2.1445513367652893

Epoch: 6| Step: 7
Training loss: 1.9490299224853516
Validation loss: 2.1503373980522156

Epoch: 6| Step: 8
Training loss: 1.683410882949829
Validation loss: 2.1391011079152427

Epoch: 6| Step: 9
Training loss: 2.6233673095703125
Validation loss: 2.121854623158773

Epoch: 6| Step: 10
Training loss: 1.6932860612869263
Validation loss: 2.123361865679423

Epoch: 6| Step: 11
Training loss: 2.459498882293701
Validation loss: 2.129327932993571

Epoch: 6| Step: 12
Training loss: 2.3871331214904785
Validation loss: 2.123547613620758

Epoch: 6| Step: 13
Training loss: 1.8813815116882324
Validation loss: 2.13607265551885

Epoch: 208| Step: 0
Training loss: 1.5169830322265625
Validation loss: 2.135093092918396

Epoch: 6| Step: 1
Training loss: 1.8681237697601318
Validation loss: 2.1386108001073203

Epoch: 6| Step: 2
Training loss: 1.9136556386947632
Validation loss: 2.137982408205668

Epoch: 6| Step: 3
Training loss: 2.2486627101898193
Validation loss: 2.1459463636080423

Epoch: 6| Step: 4
Training loss: 1.8292980194091797
Validation loss: 2.1596200863520303

Epoch: 6| Step: 5
Training loss: 1.769330382347107
Validation loss: 2.162562131881714

Epoch: 6| Step: 6
Training loss: 2.2873196601867676
Validation loss: 2.184283276398977

Epoch: 6| Step: 7
Training loss: 2.5949618816375732
Validation loss: 2.1641822854677835

Epoch: 6| Step: 8
Training loss: 1.6105648279190063
Validation loss: 2.1657824913660684

Epoch: 6| Step: 9
Training loss: 1.965238332748413
Validation loss: 2.167868216832479

Epoch: 6| Step: 10
Training loss: 1.6160224676132202
Validation loss: 2.1766429344813027

Epoch: 6| Step: 11
Training loss: 1.4624308347702026
Validation loss: 2.166541635990143

Epoch: 6| Step: 12
Training loss: 1.358108639717102
Validation loss: 2.1479265093803406

Epoch: 6| Step: 13
Training loss: 2.003941774368286
Validation loss: 2.154248138268789

Epoch: 209| Step: 0
Training loss: 1.8845301866531372
Validation loss: 2.1503830552101135

Epoch: 6| Step: 1
Training loss: 1.7244006395339966
Validation loss: 2.1561342676480613

Epoch: 6| Step: 2
Training loss: 2.0289385318756104
Validation loss: 2.164535701274872

Epoch: 6| Step: 3
Training loss: 1.6112711429595947
Validation loss: 2.1665134032567344

Epoch: 6| Step: 4
Training loss: 1.7890082597732544
Validation loss: 2.160968462626139

Epoch: 6| Step: 5
Training loss: 2.3428032398223877
Validation loss: 2.1542841593424478

Epoch: 6| Step: 6
Training loss: 1.4898663759231567
Validation loss: 2.1576813459396362

Epoch: 6| Step: 7
Training loss: 1.804243803024292
Validation loss: 2.1702223420143127

Epoch: 6| Step: 8
Training loss: 1.9522595405578613
Validation loss: 2.1654603481292725

Epoch: 6| Step: 9
Training loss: 2.0128605365753174
Validation loss: 2.15971044699351

Epoch: 6| Step: 10
Training loss: 2.0160765647888184
Validation loss: 2.1543615659077964

Epoch: 6| Step: 11
Training loss: 1.492769718170166
Validation loss: 2.151589651902517

Epoch: 6| Step: 12
Training loss: 1.6621067523956299
Validation loss: 2.15076474348704

Epoch: 6| Step: 13
Training loss: 2.1787288188934326
Validation loss: 2.169930020968119

Epoch: 210| Step: 0
Training loss: 2.3361563682556152
Validation loss: 2.170843183994293

Epoch: 6| Step: 1
Training loss: 1.8287333250045776
Validation loss: 2.169734080632528

Epoch: 6| Step: 2
Training loss: 1.574923038482666
Validation loss: 2.1478060682614646

Epoch: 6| Step: 3
Training loss: 1.7018780708312988
Validation loss: 2.155621369679769

Epoch: 6| Step: 4
Training loss: 1.723945140838623
Validation loss: 2.158700704574585

Epoch: 6| Step: 5
Training loss: 2.4157772064208984
Validation loss: 2.158334970474243

Epoch: 6| Step: 6
Training loss: 1.5839335918426514
Validation loss: 2.150232116381327

Epoch: 6| Step: 7
Training loss: 1.5618257522583008
Validation loss: 2.147403577963511

Epoch: 6| Step: 8
Training loss: 1.8864082098007202
Validation loss: 2.14704163869222

Epoch: 6| Step: 9
Training loss: 1.7322746515274048
Validation loss: 2.1516765356063843

Epoch: 6| Step: 10
Training loss: 1.352413296699524
Validation loss: 2.1595041950543723

Epoch: 6| Step: 11
Training loss: 2.013817548751831
Validation loss: 2.1344693501790366

Epoch: 6| Step: 12
Training loss: 2.1233339309692383
Validation loss: 2.144876797993978

Epoch: 6| Step: 13
Training loss: 2.1928117275238037
Validation loss: 2.1381966272989907

Epoch: 211| Step: 0
Training loss: 1.4683177471160889
Validation loss: 2.134612222512563

Epoch: 6| Step: 1
Training loss: 1.7807375192642212
Validation loss: 2.1543869574864707

Epoch: 6| Step: 2
Training loss: 1.6738789081573486
Validation loss: 2.152457594871521

Epoch: 6| Step: 3
Training loss: 2.2111101150512695
Validation loss: 2.1486789782842

Epoch: 6| Step: 4
Training loss: 1.6053133010864258
Validation loss: 2.1554654836654663

Epoch: 6| Step: 5
Training loss: 1.9997398853302002
Validation loss: 2.1588980754216514

Epoch: 6| Step: 6
Training loss: 1.7762700319290161
Validation loss: 2.1648622949918113

Epoch: 6| Step: 7
Training loss: 1.8654835224151611
Validation loss: 2.171276072661082

Epoch: 6| Step: 8
Training loss: 2.453781843185425
Validation loss: 2.1583805481592813

Epoch: 6| Step: 9
Training loss: 1.528188705444336
Validation loss: 2.163508137067159

Epoch: 6| Step: 10
Training loss: 2.096055507659912
Validation loss: 2.1646852493286133

Epoch: 6| Step: 11
Training loss: 2.165125608444214
Validation loss: 2.159927487373352

Epoch: 6| Step: 12
Training loss: 1.636382818222046
Validation loss: 2.1297972997029624

Epoch: 6| Step: 13
Training loss: 1.5458991527557373
Validation loss: 2.1526213685671487

Epoch: 212| Step: 0
Training loss: 1.6278104782104492
Validation loss: 2.139421363671621

Epoch: 6| Step: 1
Training loss: 2.304882526397705
Validation loss: 2.1721344788869223

Epoch: 6| Step: 2
Training loss: 2.398837089538574
Validation loss: 2.156489292780558

Epoch: 6| Step: 3
Training loss: 2.0020623207092285
Validation loss: 2.1495542923609414

Epoch: 6| Step: 4
Training loss: 1.4221454858779907
Validation loss: 2.1662367781003318

Epoch: 6| Step: 5
Training loss: 2.2069778442382812
Validation loss: 2.1699471275011697

Epoch: 6| Step: 6
Training loss: 1.3765183687210083
Validation loss: 2.167494853337606

Epoch: 6| Step: 7
Training loss: 2.263497829437256
Validation loss: 2.171952565511068

Epoch: 6| Step: 8
Training loss: 1.9517332315444946
Validation loss: 2.1780580282211304

Epoch: 6| Step: 9
Training loss: 1.9156078100204468
Validation loss: 2.1874165534973145

Epoch: 6| Step: 10
Training loss: 1.664499044418335
Validation loss: 2.1637250582377114

Epoch: 6| Step: 11
Training loss: 1.8325090408325195
Validation loss: 2.156938095887502

Epoch: 6| Step: 12
Training loss: 0.8413729667663574
Validation loss: 2.1792988777160645

Epoch: 6| Step: 13
Training loss: 2.1356163024902344
Validation loss: 2.174215833346049

Epoch: 213| Step: 0
Training loss: 1.5189528465270996
Validation loss: 2.154342452685038

Epoch: 6| Step: 1
Training loss: 1.673079013824463
Validation loss: 2.147608915964762

Epoch: 6| Step: 2
Training loss: 2.0933713912963867
Validation loss: 2.1457130908966064

Epoch: 6| Step: 3
Training loss: 1.9894192218780518
Validation loss: 2.145236293474833

Epoch: 6| Step: 4
Training loss: 2.2539193630218506
Validation loss: 2.1499271790186563

Epoch: 6| Step: 5
Training loss: 1.7846423387527466
Validation loss: 2.156409800052643

Epoch: 6| Step: 6
Training loss: 1.466637134552002
Validation loss: 2.1655900279680886

Epoch: 6| Step: 7
Training loss: 1.4750185012817383
Validation loss: 2.158795336882273

Epoch: 6| Step: 8
Training loss: 2.150311231613159
Validation loss: 2.1653504570325217

Epoch: 6| Step: 9
Training loss: 1.7197829484939575
Validation loss: 2.1751588781674704

Epoch: 6| Step: 10
Training loss: 1.6799744367599487
Validation loss: 2.1693022648493447

Epoch: 6| Step: 11
Training loss: 1.7720508575439453
Validation loss: 2.1667577624320984

Epoch: 6| Step: 12
Training loss: 2.073279619216919
Validation loss: 2.176800707976023

Epoch: 6| Step: 13
Training loss: 2.0133137702941895
Validation loss: 2.1725193659464517

Epoch: 214| Step: 0
Training loss: 1.6671037673950195
Validation loss: 2.1609028776486716

Epoch: 6| Step: 1
Training loss: 1.8483912944793701
Validation loss: 2.1871012449264526

Epoch: 6| Step: 2
Training loss: 2.2869505882263184
Validation loss: 2.158731162548065

Epoch: 6| Step: 3
Training loss: 2.3940043449401855
Validation loss: 2.1787344217300415

Epoch: 6| Step: 4
Training loss: 1.370863676071167
Validation loss: 2.1691419084866843

Epoch: 6| Step: 5
Training loss: 1.2609732151031494
Validation loss: 2.1644433736801147

Epoch: 6| Step: 6
Training loss: 1.8912396430969238
Validation loss: 2.1445554296175637

Epoch: 6| Step: 7
Training loss: 1.6985769271850586
Validation loss: 2.1371308167775473

Epoch: 6| Step: 8
Training loss: 1.8199927806854248
Validation loss: 2.1423080364863076

Epoch: 6| Step: 9
Training loss: 1.8130111694335938
Validation loss: 2.1280319889386496

Epoch: 6| Step: 10
Training loss: 1.6938321590423584
Validation loss: 2.1264978448549905

Epoch: 6| Step: 11
Training loss: 2.314357280731201
Validation loss: 2.1269641518592834

Epoch: 6| Step: 12
Training loss: 2.713575601577759
Validation loss: 2.122140725453695

Epoch: 6| Step: 13
Training loss: 2.162696361541748
Validation loss: 2.1264331936836243

Epoch: 215| Step: 0
Training loss: 1.7441030740737915
Validation loss: 2.1252580285072327

Epoch: 6| Step: 1
Training loss: 1.9794620275497437
Validation loss: 2.1347629626592

Epoch: 6| Step: 2
Training loss: 1.5007191896438599
Validation loss: 2.124031682809194

Epoch: 6| Step: 3
Training loss: 1.9981486797332764
Validation loss: 2.1326566338539124

Epoch: 6| Step: 4
Training loss: 1.940598964691162
Validation loss: 2.132621645927429

Epoch: 6| Step: 5
Training loss: 2.117918014526367
Validation loss: 2.140934964021047

Epoch: 6| Step: 6
Training loss: 1.63291597366333
Validation loss: 2.1530450781186423

Epoch: 6| Step: 7
Training loss: 1.9913721084594727
Validation loss: 2.149222493171692

Epoch: 6| Step: 8
Training loss: 2.2165327072143555
Validation loss: 2.1587252418200173

Epoch: 6| Step: 9
Training loss: 1.6512080430984497
Validation loss: 2.148593763510386

Epoch: 6| Step: 10
Training loss: 1.9069225788116455
Validation loss: 2.1520758668581643

Epoch: 6| Step: 11
Training loss: 1.710169792175293
Validation loss: 2.1568214297294617

Epoch: 6| Step: 12
Training loss: 1.909216046333313
Validation loss: 2.159290293852488

Epoch: 6| Step: 13
Training loss: 2.061025857925415
Validation loss: 2.1484679778416953

Epoch: 216| Step: 0
Training loss: 1.695878028869629
Validation loss: 2.1688205003738403

Epoch: 6| Step: 1
Training loss: 2.060699939727783
Validation loss: 2.1638806462287903

Epoch: 6| Step: 2
Training loss: 1.9600945711135864
Validation loss: 2.15049014488856

Epoch: 6| Step: 3
Training loss: 1.972071886062622
Validation loss: 2.1442139943440757

Epoch: 6| Step: 4
Training loss: 1.382558822631836
Validation loss: 2.1503230333328247

Epoch: 6| Step: 5
Training loss: 2.5989809036254883
Validation loss: 2.143503506978353

Epoch: 6| Step: 6
Training loss: 1.1572072505950928
Validation loss: 2.1463966369628906

Epoch: 6| Step: 7
Training loss: 1.2589974403381348
Validation loss: 2.150976916154226

Epoch: 6| Step: 8
Training loss: 2.579529047012329
Validation loss: 2.148059686024984

Epoch: 6| Step: 9
Training loss: 1.3701016902923584
Validation loss: 2.1597690979639688

Epoch: 6| Step: 10
Training loss: 2.216295003890991
Validation loss: 2.1527854005495706

Epoch: 6| Step: 11
Training loss: 1.9200125932693481
Validation loss: 2.165705442428589

Epoch: 6| Step: 12
Training loss: 1.601038932800293
Validation loss: 2.1686238050460815

Epoch: 6| Step: 13
Training loss: 1.9185924530029297
Validation loss: 2.1659464836120605

Epoch: 217| Step: 0
Training loss: 1.6971795558929443
Validation loss: 2.1455336809158325

Epoch: 6| Step: 1
Training loss: 1.8365263938903809
Validation loss: 2.150132139523824

Epoch: 6| Step: 2
Training loss: 1.4169796705245972
Validation loss: 2.155980348587036

Epoch: 6| Step: 3
Training loss: 1.9392554759979248
Validation loss: 2.1457881132761636

Epoch: 6| Step: 4
Training loss: 2.0653066635131836
Validation loss: 2.156049907207489

Epoch: 6| Step: 5
Training loss: 1.969147801399231
Validation loss: 2.149917801221212

Epoch: 6| Step: 6
Training loss: 1.877463936805725
Validation loss: 2.15444278717041

Epoch: 6| Step: 7
Training loss: 1.629112958908081
Validation loss: 2.1411059697469077

Epoch: 6| Step: 8
Training loss: 1.8595964908599854
Validation loss: 2.1527370611826577

Epoch: 6| Step: 9
Training loss: 1.8737932443618774
Validation loss: 2.1603254079818726

Epoch: 6| Step: 10
Training loss: 1.925444483757019
Validation loss: 2.1599016586939492

Epoch: 6| Step: 11
Training loss: 2.0173940658569336
Validation loss: 2.1514858404795327

Epoch: 6| Step: 12
Training loss: 1.6261467933654785
Validation loss: 2.146175523598989

Epoch: 6| Step: 13
Training loss: 1.856536865234375
Validation loss: 2.142484188079834

Epoch: 218| Step: 0
Training loss: 1.4512073993682861
Validation loss: 2.1455671191215515

Epoch: 6| Step: 1
Training loss: 1.5083879232406616
Validation loss: 2.156534512837728

Epoch: 6| Step: 2
Training loss: 2.2881336212158203
Validation loss: 2.1541677713394165

Epoch: 6| Step: 3
Training loss: 2.3687806129455566
Validation loss: 2.1394253969192505

Epoch: 6| Step: 4
Training loss: 1.2365543842315674
Validation loss: 2.145081102848053

Epoch: 6| Step: 5
Training loss: 1.5534007549285889
Validation loss: 2.153660158316294

Epoch: 6| Step: 6
Training loss: 1.8878002166748047
Validation loss: 2.1384977300961814

Epoch: 6| Step: 7
Training loss: 1.166616439819336
Validation loss: 2.132640322049459

Epoch: 6| Step: 8
Training loss: 2.277963876724243
Validation loss: 2.1436621149381003

Epoch: 6| Step: 9
Training loss: 1.8327890634536743
Validation loss: 2.140434483687083

Epoch: 6| Step: 10
Training loss: 1.9314541816711426
Validation loss: 2.1522134939829507

Epoch: 6| Step: 11
Training loss: 2.0970377922058105
Validation loss: 2.1544649600982666

Epoch: 6| Step: 12
Training loss: 2.2606115341186523
Validation loss: 2.170913020769755

Epoch: 6| Step: 13
Training loss: 1.4970285892486572
Validation loss: 2.1422987381617227

Epoch: 219| Step: 0
Training loss: 1.465641975402832
Validation loss: 2.1716808080673218

Epoch: 6| Step: 1
Training loss: 1.2509746551513672
Validation loss: 2.13748566309611

Epoch: 6| Step: 2
Training loss: 2.502772569656372
Validation loss: 2.1487560669581094

Epoch: 6| Step: 3
Training loss: 2.1702494621276855
Validation loss: 2.1478740771611533

Epoch: 6| Step: 4
Training loss: 1.6262476444244385
Validation loss: 2.128405769666036

Epoch: 6| Step: 5
Training loss: 1.034027099609375
Validation loss: 2.1347336769104004

Epoch: 6| Step: 6
Training loss: 2.4222962856292725
Validation loss: 2.126178820927938

Epoch: 6| Step: 7
Training loss: 1.6501948833465576
Validation loss: 2.139413336912791

Epoch: 6| Step: 8
Training loss: 2.3147571086883545
Validation loss: 2.1216111381848655

Epoch: 6| Step: 9
Training loss: 1.8977327346801758
Validation loss: 2.1349019606908164

Epoch: 6| Step: 10
Training loss: 1.6667051315307617
Validation loss: 2.134134908517202

Epoch: 6| Step: 11
Training loss: 1.749877691268921
Validation loss: 2.1332483490308127

Epoch: 6| Step: 12
Training loss: 2.298781394958496
Validation loss: 2.15531591574351

Epoch: 6| Step: 13
Training loss: 1.2872240543365479
Validation loss: 2.1507954200108848

Epoch: 220| Step: 0
Training loss: 1.9015486240386963
Validation loss: 2.1643014351526895

Epoch: 6| Step: 1
Training loss: 1.5601392984390259
Validation loss: 2.1744229197502136

Epoch: 6| Step: 2
Training loss: 1.7288603782653809
Validation loss: 2.163459082444509

Epoch: 6| Step: 3
Training loss: 2.2322239875793457
Validation loss: 2.145264526208242

Epoch: 6| Step: 4
Training loss: 1.5908645391464233
Validation loss: 2.1583121617635093

Epoch: 6| Step: 5
Training loss: 1.3908488750457764
Validation loss: 2.1735482215881348

Epoch: 6| Step: 6
Training loss: 2.03556227684021
Validation loss: 2.1531516710917153

Epoch: 6| Step: 7
Training loss: 1.8363683223724365
Validation loss: 2.1721492211023965

Epoch: 6| Step: 8
Training loss: 1.505371332168579
Validation loss: 2.1709927320480347

Epoch: 6| Step: 9
Training loss: 2.3198206424713135
Validation loss: 2.1748450994491577

Epoch: 6| Step: 10
Training loss: 1.7753868103027344
Validation loss: 2.154217223326365

Epoch: 6| Step: 11
Training loss: 2.1768898963928223
Validation loss: 2.160677214463552

Epoch: 6| Step: 12
Training loss: 1.9463094472885132
Validation loss: 2.155222316582998

Epoch: 6| Step: 13
Training loss: 1.1651722192764282
Validation loss: 2.1670214335123696

Epoch: 221| Step: 0
Training loss: 1.899773359298706
Validation loss: 2.1527210076649985

Epoch: 6| Step: 1
Training loss: 1.9144511222839355
Validation loss: 2.16827662785848

Epoch: 6| Step: 2
Training loss: 1.1977896690368652
Validation loss: 2.152769168217977

Epoch: 6| Step: 3
Training loss: 1.9979394674301147
Validation loss: 2.1527101198832193

Epoch: 6| Step: 4
Training loss: 1.9137359857559204
Validation loss: 2.1523046692212424

Epoch: 6| Step: 5
Training loss: 2.39509916305542
Validation loss: 2.151638150215149

Epoch: 6| Step: 6
Training loss: 1.4585797786712646
Validation loss: 2.136437396208445

Epoch: 6| Step: 7
Training loss: 2.6843924522399902
Validation loss: 2.1615889072418213

Epoch: 6| Step: 8
Training loss: 1.9549765586853027
Validation loss: 2.1567670702934265

Epoch: 6| Step: 9
Training loss: 1.4051002264022827
Validation loss: 2.1425806283950806

Epoch: 6| Step: 10
Training loss: 1.7081061601638794
Validation loss: 2.1649487813313804

Epoch: 6| Step: 11
Training loss: 1.5484153032302856
Validation loss: 2.16939910252889

Epoch: 6| Step: 12
Training loss: 1.8747265338897705
Validation loss: 2.165949821472168

Epoch: 6| Step: 13
Training loss: 1.2371163368225098
Validation loss: 2.1860270301500955

Epoch: 222| Step: 0
Training loss: 1.1965972185134888
Validation loss: 2.16174324353536

Epoch: 6| Step: 1
Training loss: 1.805796504020691
Validation loss: 2.182336171468099

Epoch: 6| Step: 2
Training loss: 2.452077627182007
Validation loss: 2.1703738967577615

Epoch: 6| Step: 3
Training loss: 1.9478249549865723
Validation loss: 2.1732386549313865

Epoch: 6| Step: 4
Training loss: 1.8369979858398438
Validation loss: 2.1749085783958435

Epoch: 6| Step: 5
Training loss: 1.7956416606903076
Validation loss: 2.1714232762654624

Epoch: 6| Step: 6
Training loss: 1.5213758945465088
Validation loss: 2.167846957842509

Epoch: 6| Step: 7
Training loss: 2.21378231048584
Validation loss: 2.165397842725118

Epoch: 6| Step: 8
Training loss: 2.1558358669281006
Validation loss: 2.158392051855723

Epoch: 6| Step: 9
Training loss: 1.4973804950714111
Validation loss: 2.154595375061035

Epoch: 6| Step: 10
Training loss: 1.4586225748062134
Validation loss: 2.143163561820984

Epoch: 6| Step: 11
Training loss: 1.480456829071045
Validation loss: 2.1622817715009055

Epoch: 6| Step: 12
Training loss: 1.3172967433929443
Validation loss: 2.1443135937054953

Epoch: 6| Step: 13
Training loss: 2.5074448585510254
Validation loss: 2.1544412771860757

Epoch: 223| Step: 0
Training loss: 1.7076350450515747
Validation loss: 2.1739879846572876

Epoch: 6| Step: 1
Training loss: 2.1070425510406494
Validation loss: 2.1712326804796853

Epoch: 6| Step: 2
Training loss: 2.3192548751831055
Validation loss: 2.1636820236841836

Epoch: 6| Step: 3
Training loss: 1.4506653547286987
Validation loss: 2.171206772327423

Epoch: 6| Step: 4
Training loss: 1.9977246522903442
Validation loss: 2.182119846343994

Epoch: 6| Step: 5
Training loss: 1.9846513271331787
Validation loss: 2.188193440437317

Epoch: 6| Step: 6
Training loss: 1.4918619394302368
Validation loss: 2.180534541606903

Epoch: 6| Step: 7
Training loss: 1.4883968830108643
Validation loss: 2.1807052294413247

Epoch: 6| Step: 8
Training loss: 1.6539294719696045
Validation loss: 2.1651633580525718

Epoch: 6| Step: 9
Training loss: 1.91340970993042
Validation loss: 2.179970681667328

Epoch: 6| Step: 10
Training loss: 1.6792477369308472
Validation loss: 2.2021790941556296

Epoch: 6| Step: 11
Training loss: 1.9267910718917847
Validation loss: 2.1820197701454163

Epoch: 6| Step: 12
Training loss: 1.5674808025360107
Validation loss: 2.2121450503667197

Epoch: 6| Step: 13
Training loss: 1.6466658115386963
Validation loss: 2.1691636641820273

Epoch: 224| Step: 0
Training loss: 1.8804466724395752
Validation loss: 2.1686856547991433

Epoch: 6| Step: 1
Training loss: 1.790852665901184
Validation loss: 2.1506068110466003

Epoch: 6| Step: 2
Training loss: 2.3978404998779297
Validation loss: 2.157701015472412

Epoch: 6| Step: 3
Training loss: 1.4824070930480957
Validation loss: 2.157618443171183

Epoch: 6| Step: 4
Training loss: 1.3537046909332275
Validation loss: 2.1534130573272705

Epoch: 6| Step: 5
Training loss: 1.667242407798767
Validation loss: 2.150839328765869

Epoch: 6| Step: 6
Training loss: 2.366513967514038
Validation loss: 2.1669028401374817

Epoch: 6| Step: 7
Training loss: 2.613755702972412
Validation loss: 2.158599396546682

Epoch: 6| Step: 8
Training loss: 1.5840098857879639
Validation loss: 2.1464373071988425

Epoch: 6| Step: 9
Training loss: 1.7321085929870605
Validation loss: 2.1637787421544394

Epoch: 6| Step: 10
Training loss: 1.7701575756072998
Validation loss: 2.185667395591736

Epoch: 6| Step: 11
Training loss: 2.1811513900756836
Validation loss: 2.201176186402639

Epoch: 6| Step: 12
Training loss: 1.1974902153015137
Validation loss: 2.2060219248135886

Epoch: 6| Step: 13
Training loss: 1.8098845481872559
Validation loss: 2.217183848222097

Epoch: 225| Step: 0
Training loss: 1.8522040843963623
Validation loss: 2.2249156832695007

Epoch: 6| Step: 1
Training loss: 1.4451100826263428
Validation loss: 2.2005656162897744

Epoch: 6| Step: 2
Training loss: 1.9746167659759521
Validation loss: 2.2207693258921304

Epoch: 6| Step: 3
Training loss: 2.2962701320648193
Validation loss: 2.205545961856842

Epoch: 6| Step: 4
Training loss: 1.4342695474624634
Validation loss: 2.1818899313608804

Epoch: 6| Step: 5
Training loss: 1.3918533325195312
Validation loss: 2.1807677149772644

Epoch: 6| Step: 6
Training loss: 1.4439175128936768
Validation loss: 2.189020792643229

Epoch: 6| Step: 7
Training loss: 1.151413917541504
Validation loss: 2.1891967058181763

Epoch: 6| Step: 8
Training loss: 2.050894260406494
Validation loss: 2.163004994392395

Epoch: 6| Step: 9
Training loss: 2.431399345397949
Validation loss: 2.1718993186950684

Epoch: 6| Step: 10
Training loss: 1.6828548908233643
Validation loss: 2.175689379374186

Epoch: 6| Step: 11
Training loss: 1.668178677558899
Validation loss: 2.156507909297943

Epoch: 6| Step: 12
Training loss: 1.783072829246521
Validation loss: 2.1526045401891074

Epoch: 6| Step: 13
Training loss: 2.397942543029785
Validation loss: 2.1688544948895774

Epoch: 226| Step: 0
Training loss: 1.9192829132080078
Validation loss: 2.1494583090146384

Epoch: 6| Step: 1
Training loss: 1.9199331998825073
Validation loss: 2.174294392267863

Epoch: 6| Step: 2
Training loss: 1.7311756610870361
Validation loss: 2.1495011846224465

Epoch: 6| Step: 3
Training loss: 1.3660211563110352
Validation loss: 2.179591794808706

Epoch: 6| Step: 4
Training loss: 1.6126468181610107
Validation loss: 2.190956195195516

Epoch: 6| Step: 5
Training loss: 1.9213467836380005
Validation loss: 2.1664385398228965

Epoch: 6| Step: 6
Training loss: 1.0336146354675293
Validation loss: 2.1936477025349936

Epoch: 6| Step: 7
Training loss: 1.1765837669372559
Validation loss: 2.173108537991842

Epoch: 6| Step: 8
Training loss: 2.0614676475524902
Validation loss: 2.180068850517273

Epoch: 6| Step: 9
Training loss: 2.3474204540252686
Validation loss: 2.1692411303520203

Epoch: 6| Step: 10
Training loss: 2.39892578125
Validation loss: 2.1711666584014893

Epoch: 6| Step: 11
Training loss: 1.4327318668365479
Validation loss: 2.1701484521230063

Epoch: 6| Step: 12
Training loss: 2.0375428199768066
Validation loss: 2.1535762548446655

Epoch: 6| Step: 13
Training loss: 2.070948600769043
Validation loss: 2.131691118081411

Epoch: 227| Step: 0
Training loss: 2.1565310955047607
Validation loss: 2.1592568159103394

Epoch: 6| Step: 1
Training loss: 2.1364874839782715
Validation loss: 2.138796865940094

Epoch: 6| Step: 2
Training loss: 1.4832544326782227
Validation loss: 2.125861883163452

Epoch: 6| Step: 3
Training loss: 2.004904270172119
Validation loss: 2.1457934776941934

Epoch: 6| Step: 4
Training loss: 1.6687939167022705
Validation loss: 2.14319642384847

Epoch: 6| Step: 5
Training loss: 1.640413522720337
Validation loss: 2.1558287143707275

Epoch: 6| Step: 6
Training loss: 1.8887667655944824
Validation loss: 2.1332996686299643

Epoch: 6| Step: 7
Training loss: 1.3873977661132812
Validation loss: 2.1542679270108542

Epoch: 6| Step: 8
Training loss: 1.7577800750732422
Validation loss: 2.1565452416737876

Epoch: 6| Step: 9
Training loss: 1.6981797218322754
Validation loss: 2.1624357104301453

Epoch: 6| Step: 10
Training loss: 1.597374439239502
Validation loss: 2.1858968138694763

Epoch: 6| Step: 11
Training loss: 1.8497649431228638
Validation loss: 2.173734744389852

Epoch: 6| Step: 12
Training loss: 1.7982592582702637
Validation loss: 2.178008258342743

Epoch: 6| Step: 13
Training loss: 1.9857468605041504
Validation loss: 2.1773049235343933

Epoch: 228| Step: 0
Training loss: 1.9514188766479492
Validation loss: 2.1740578611691794

Epoch: 6| Step: 1
Training loss: 1.5780744552612305
Validation loss: 2.1865381598472595

Epoch: 6| Step: 2
Training loss: 1.714561104774475
Validation loss: 2.1936243573824563

Epoch: 6| Step: 3
Training loss: 1.647245168685913
Validation loss: 2.187766710917155

Epoch: 6| Step: 4
Training loss: 2.5948586463928223
Validation loss: 2.1955519119898477

Epoch: 6| Step: 5
Training loss: 1.3760979175567627
Validation loss: 2.185150424639384

Epoch: 6| Step: 6
Training loss: 1.9922497272491455
Validation loss: 2.17691836754481

Epoch: 6| Step: 7
Training loss: 1.3112574815750122
Validation loss: 2.1577252546946206

Epoch: 6| Step: 8
Training loss: 1.5275394916534424
Validation loss: 2.150903801123301

Epoch: 6| Step: 9
Training loss: 2.0456509590148926
Validation loss: 2.1586225231488547

Epoch: 6| Step: 10
Training loss: 1.8883309364318848
Validation loss: 2.1399588783582053

Epoch: 6| Step: 11
Training loss: 2.0832486152648926
Validation loss: 2.1632861495018005

Epoch: 6| Step: 12
Training loss: 1.6157792806625366
Validation loss: 2.137610991795858

Epoch: 6| Step: 13
Training loss: 1.8562413454055786
Validation loss: 2.149876296520233

Epoch: 229| Step: 0
Training loss: 1.202460765838623
Validation loss: 2.147578775882721

Epoch: 6| Step: 1
Training loss: 1.7608903646469116
Validation loss: 2.17511522769928

Epoch: 6| Step: 2
Training loss: 1.7699646949768066
Validation loss: 2.187737007935842

Epoch: 6| Step: 3
Training loss: 1.3607816696166992
Validation loss: 2.1802404721577964

Epoch: 6| Step: 4
Training loss: 2.4630279541015625
Validation loss: 2.174444039662679

Epoch: 6| Step: 5
Training loss: 1.8632144927978516
Validation loss: 2.1878594160079956

Epoch: 6| Step: 6
Training loss: 2.176945209503174
Validation loss: 2.1812744537989297

Epoch: 6| Step: 7
Training loss: 1.6409778594970703
Validation loss: 2.1870665152867637

Epoch: 6| Step: 8
Training loss: 2.070551872253418
Validation loss: 2.183952550093333

Epoch: 6| Step: 9
Training loss: 1.4482868909835815
Validation loss: 2.188189387321472

Epoch: 6| Step: 10
Training loss: 2.1366820335388184
Validation loss: 2.158494293689728

Epoch: 6| Step: 11
Training loss: 1.4354572296142578
Validation loss: 2.157983879248301

Epoch: 6| Step: 12
Training loss: 1.4179890155792236
Validation loss: 2.1747451027234397

Epoch: 6| Step: 13
Training loss: 1.9694041013717651
Validation loss: 2.1713218688964844

Epoch: 230| Step: 0
Training loss: 1.3189516067504883
Validation loss: 2.143885016441345

Epoch: 6| Step: 1
Training loss: 1.639336347579956
Validation loss: 2.1516735752423606

Epoch: 6| Step: 2
Training loss: 2.2427313327789307
Validation loss: 2.1581914027531943

Epoch: 6| Step: 3
Training loss: 1.6969997882843018
Validation loss: 2.1652305920918784

Epoch: 6| Step: 4
Training loss: 1.767956018447876
Validation loss: 2.1662419637044272

Epoch: 6| Step: 5
Training loss: 1.4930884838104248
Validation loss: 2.1749494274457297

Epoch: 6| Step: 6
Training loss: 2.182070732116699
Validation loss: 2.1824136773745217

Epoch: 6| Step: 7
Training loss: 1.6611111164093018
Validation loss: 2.191118041674296

Epoch: 6| Step: 8
Training loss: 1.5387918949127197
Validation loss: 2.1960171858469644

Epoch: 6| Step: 9
Training loss: 2.6696066856384277
Validation loss: 2.201256891091665

Epoch: 6| Step: 10
Training loss: 1.5679993629455566
Validation loss: 2.2179250518480935

Epoch: 6| Step: 11
Training loss: 2.3736274242401123
Validation loss: 2.196463088194529

Epoch: 6| Step: 12
Training loss: 1.4365395307540894
Validation loss: 2.189790507157644

Epoch: 6| Step: 13
Training loss: 1.5254653692245483
Validation loss: 2.181522766749064

Epoch: 231| Step: 0
Training loss: 1.4894795417785645
Validation loss: 2.174972871939341

Epoch: 6| Step: 1
Training loss: 1.6214308738708496
Validation loss: 2.144211252530416

Epoch: 6| Step: 2
Training loss: 1.2454016208648682
Validation loss: 2.1400570273399353

Epoch: 6| Step: 3
Training loss: 1.8403668403625488
Validation loss: 2.175835371017456

Epoch: 6| Step: 4
Training loss: 2.1751246452331543
Validation loss: 2.151286005973816

Epoch: 6| Step: 5
Training loss: 1.860715627670288
Validation loss: 2.162433902422587

Epoch: 6| Step: 6
Training loss: 1.4057148694992065
Validation loss: 2.163000484307607

Epoch: 6| Step: 7
Training loss: 2.2605433464050293
Validation loss: 2.1873276233673096

Epoch: 6| Step: 8
Training loss: 2.0624446868896484
Validation loss: 2.1795328855514526

Epoch: 6| Step: 9
Training loss: 1.8207277059555054
Validation loss: 2.1753971576690674

Epoch: 6| Step: 10
Training loss: 1.4879025220870972
Validation loss: 2.195293923219045

Epoch: 6| Step: 11
Training loss: 2.265972852706909
Validation loss: 2.1918702721595764

Epoch: 6| Step: 12
Training loss: 1.313603401184082
Validation loss: 2.1834671099980674

Epoch: 6| Step: 13
Training loss: 2.0696213245391846
Validation loss: 2.17428187529246

Epoch: 232| Step: 0
Training loss: 2.1261088848114014
Validation loss: 2.162571609020233

Epoch: 6| Step: 1
Training loss: 2.0982918739318848
Validation loss: 2.1820152203241983

Epoch: 6| Step: 2
Training loss: 1.877982497215271
Validation loss: 2.167533278465271

Epoch: 6| Step: 3
Training loss: 1.7572379112243652
Validation loss: 2.167170524597168

Epoch: 6| Step: 4
Training loss: 1.3286001682281494
Validation loss: 2.1679387291272483

Epoch: 6| Step: 5
Training loss: 1.2089707851409912
Validation loss: 2.1560312310854592

Epoch: 6| Step: 6
Training loss: 1.404524326324463
Validation loss: 2.157965898513794

Epoch: 6| Step: 7
Training loss: 1.8547111749649048
Validation loss: 2.1759007771809897

Epoch: 6| Step: 8
Training loss: 1.717416763305664
Validation loss: 2.1557170152664185

Epoch: 6| Step: 9
Training loss: 2.104316234588623
Validation loss: 2.1658236980438232

Epoch: 6| Step: 10
Training loss: 2.2198963165283203
Validation loss: 2.1653242111206055

Epoch: 6| Step: 11
Training loss: 1.3535422086715698
Validation loss: 2.156427323818207

Epoch: 6| Step: 12
Training loss: 1.734322428703308
Validation loss: 2.1652196248372397

Epoch: 6| Step: 13
Training loss: 1.832452416419983
Validation loss: 2.1501532793045044

Epoch: 233| Step: 0
Training loss: 1.7519643306732178
Validation loss: 2.1627142429351807

Epoch: 6| Step: 1
Training loss: 1.493679165840149
Validation loss: 2.1460518836975098

Epoch: 6| Step: 2
Training loss: 1.4684276580810547
Validation loss: 2.178595185279846

Epoch: 6| Step: 3
Training loss: 1.356604814529419
Validation loss: 2.1706767479578652

Epoch: 6| Step: 4
Training loss: 2.038346290588379
Validation loss: 2.188430905342102

Epoch: 6| Step: 5
Training loss: 1.66697359085083
Validation loss: 2.1764352321624756

Epoch: 6| Step: 6
Training loss: 1.3142273426055908
Validation loss: 2.190364201863607

Epoch: 6| Step: 7
Training loss: 1.845381259918213
Validation loss: 2.1522162159283957

Epoch: 6| Step: 8
Training loss: 1.3885948657989502
Validation loss: 2.1813392639160156

Epoch: 6| Step: 9
Training loss: 2.0593836307525635
Validation loss: 2.1785348653793335

Epoch: 6| Step: 10
Training loss: 1.2417882680892944
Validation loss: 2.1798449754714966

Epoch: 6| Step: 11
Training loss: 2.088977336883545
Validation loss: 2.168840169906616

Epoch: 6| Step: 12
Training loss: 2.5942184925079346
Validation loss: 2.1781488259633384

Epoch: 6| Step: 13
Training loss: 2.332754135131836
Validation loss: 2.182611028353373

Epoch: 234| Step: 0
Training loss: 1.7397326231002808
Validation loss: 2.161186178525289

Epoch: 6| Step: 1
Training loss: 1.9432240724563599
Validation loss: 2.1657534639040628

Epoch: 6| Step: 2
Training loss: 1.4609874486923218
Validation loss: 2.1938271522521973

Epoch: 6| Step: 3
Training loss: 1.6185810565948486
Validation loss: 2.1658058563868203

Epoch: 6| Step: 4
Training loss: 2.1548538208007812
Validation loss: 2.15932289759318

Epoch: 6| Step: 5
Training loss: 1.7739179134368896
Validation loss: 2.1594056685765586

Epoch: 6| Step: 6
Training loss: 1.1640552282333374
Validation loss: 2.1443467140197754

Epoch: 6| Step: 7
Training loss: 1.6114299297332764
Validation loss: 2.132824500401815

Epoch: 6| Step: 8
Training loss: 0.9447386860847473
Validation loss: 2.1566377679506936

Epoch: 6| Step: 9
Training loss: 2.0655641555786133
Validation loss: 2.1543373266855874

Epoch: 6| Step: 10
Training loss: 1.8258357048034668
Validation loss: 2.1533202131589255

Epoch: 6| Step: 11
Training loss: 1.9165171384811401
Validation loss: 2.1523747046788535

Epoch: 6| Step: 12
Training loss: 2.6576294898986816
Validation loss: 2.1659544308980307

Epoch: 6| Step: 13
Training loss: 1.3987667560577393
Validation loss: 2.155365844567617

Epoch: 235| Step: 0
Training loss: 1.511265516281128
Validation loss: 2.155947426954905

Epoch: 6| Step: 1
Training loss: 2.4071555137634277
Validation loss: 2.1739891171455383

Epoch: 6| Step: 2
Training loss: 1.4360154867172241
Validation loss: 2.174001455307007

Epoch: 6| Step: 3
Training loss: 1.6079224348068237
Validation loss: 2.179068088531494

Epoch: 6| Step: 4
Training loss: 1.9380602836608887
Validation loss: 2.195248822371165

Epoch: 6| Step: 5
Training loss: 1.8746072053909302
Validation loss: 2.196349084377289

Epoch: 6| Step: 6
Training loss: 1.6026803255081177
Validation loss: 2.201428929964701

Epoch: 6| Step: 7
Training loss: 1.3533672094345093
Validation loss: 2.1960110465685525

Epoch: 6| Step: 8
Training loss: 1.3516454696655273
Validation loss: 2.2060375412305198

Epoch: 6| Step: 9
Training loss: 1.9198482036590576
Validation loss: 2.1915404001871743

Epoch: 6| Step: 10
Training loss: 2.2467551231384277
Validation loss: 2.2169679005940757

Epoch: 6| Step: 11
Training loss: 2.3995940685272217
Validation loss: 2.1940712928771973

Epoch: 6| Step: 12
Training loss: 1.5680205821990967
Validation loss: 2.221884528795878

Epoch: 6| Step: 13
Training loss: 1.3379182815551758
Validation loss: 2.194671114285787

Epoch: 236| Step: 0
Training loss: 1.0768346786499023
Validation loss: 2.164269049962362

Epoch: 6| Step: 1
Training loss: 1.538240671157837
Validation loss: 2.1876479188601174

Epoch: 6| Step: 2
Training loss: 1.349806308746338
Validation loss: 2.1674248576164246

Epoch: 6| Step: 3
Training loss: 1.70943021774292
Validation loss: 2.1770940025647483

Epoch: 6| Step: 4
Training loss: 1.6632256507873535
Validation loss: 2.1572310527165732

Epoch: 6| Step: 5
Training loss: 1.9455113410949707
Validation loss: 2.1545082330703735

Epoch: 6| Step: 6
Training loss: 2.066498279571533
Validation loss: 2.156437655289968

Epoch: 6| Step: 7
Training loss: 1.9354569911956787
Validation loss: 2.1556382179260254

Epoch: 6| Step: 8
Training loss: 1.6980265378952026
Validation loss: 2.1493762930234275

Epoch: 6| Step: 9
Training loss: 1.4896817207336426
Validation loss: 2.1561426520347595

Epoch: 6| Step: 10
Training loss: 2.574676036834717
Validation loss: 2.1734001437822976

Epoch: 6| Step: 11
Training loss: 1.353723406791687
Validation loss: 2.1641154090563455

Epoch: 6| Step: 12
Training loss: 1.999903917312622
Validation loss: 2.156629264354706

Epoch: 6| Step: 13
Training loss: 2.735240936279297
Validation loss: 2.1759073535601297

Epoch: 237| Step: 0
Training loss: 1.18202805519104
Validation loss: 2.1730032165845237

Epoch: 6| Step: 1
Training loss: 1.8394277095794678
Validation loss: 2.201686362425486

Epoch: 6| Step: 2
Training loss: 2.2837069034576416
Validation loss: 2.1820722619692483

Epoch: 6| Step: 3
Training loss: 2.7955918312072754
Validation loss: 2.1808112064997354

Epoch: 6| Step: 4
Training loss: 1.6873856782913208
Validation loss: 2.176276961962382

Epoch: 6| Step: 5
Training loss: 1.936967134475708
Validation loss: 2.171089231967926

Epoch: 6| Step: 6
Training loss: 1.0506856441497803
Validation loss: 2.160806934038798

Epoch: 6| Step: 7
Training loss: 1.2586103677749634
Validation loss: 2.1741116642951965

Epoch: 6| Step: 8
Training loss: 1.3497734069824219
Validation loss: 2.1796112656593323

Epoch: 6| Step: 9
Training loss: 2.0545899868011475
Validation loss: 2.167414128780365

Epoch: 6| Step: 10
Training loss: 1.4797182083129883
Validation loss: 2.167614003022512

Epoch: 6| Step: 11
Training loss: 2.0137150287628174
Validation loss: 2.1732803781827292

Epoch: 6| Step: 12
Training loss: 1.8263529539108276
Validation loss: 2.178341527779897

Epoch: 6| Step: 13
Training loss: 1.8424835205078125
Validation loss: 2.175685465335846

Epoch: 238| Step: 0
Training loss: 1.1572294235229492
Validation loss: 2.1585246324539185

Epoch: 6| Step: 1
Training loss: 1.6113991737365723
Validation loss: 2.154807905356089

Epoch: 6| Step: 2
Training loss: 2.376894474029541
Validation loss: 2.1672220627466836

Epoch: 6| Step: 3
Training loss: 1.8746575117111206
Validation loss: 2.15492045879364

Epoch: 6| Step: 4
Training loss: 1.7527339458465576
Validation loss: 2.1757861574490867

Epoch: 6| Step: 5
Training loss: 1.4499926567077637
Validation loss: 2.2101181546847024

Epoch: 6| Step: 6
Training loss: 2.1958236694335938
Validation loss: 2.1794114907582602

Epoch: 6| Step: 7
Training loss: 2.132554054260254
Validation loss: 2.1853631337483725

Epoch: 6| Step: 8
Training loss: 1.7931318283081055
Validation loss: 2.201336443424225

Epoch: 6| Step: 9
Training loss: 1.783928394317627
Validation loss: 2.1880630254745483

Epoch: 6| Step: 10
Training loss: 0.9389991164207458
Validation loss: 2.1785037318865457

Epoch: 6| Step: 11
Training loss: 1.899991512298584
Validation loss: 2.1702929536501565

Epoch: 6| Step: 12
Training loss: 1.8944900035858154
Validation loss: 2.178950091203054

Epoch: 6| Step: 13
Training loss: 1.783514142036438
Validation loss: 2.1467689275741577

Epoch: 239| Step: 0
Training loss: 1.1924042701721191
Validation loss: 2.1473129789034524

Epoch: 6| Step: 1
Training loss: 1.601056456565857
Validation loss: 2.1625400384267173

Epoch: 6| Step: 2
Training loss: 2.14066743850708
Validation loss: 2.1288936535517373

Epoch: 6| Step: 3
Training loss: 2.0151114463806152
Validation loss: 2.134435554345449

Epoch: 6| Step: 4
Training loss: 1.8936197757720947
Validation loss: 2.128422955671946

Epoch: 6| Step: 5
Training loss: 1.9772968292236328
Validation loss: 2.1293301582336426

Epoch: 6| Step: 6
Training loss: 2.0487828254699707
Validation loss: 2.1539367039998374

Epoch: 6| Step: 7
Training loss: 1.9613978862762451
Validation loss: 2.1477464040120444

Epoch: 6| Step: 8
Training loss: 1.3458259105682373
Validation loss: 2.1568665305773416

Epoch: 6| Step: 9
Training loss: 2.633279800415039
Validation loss: 2.151030679543813

Epoch: 6| Step: 10
Training loss: 1.4955472946166992
Validation loss: 2.1582586765289307

Epoch: 6| Step: 11
Training loss: 1.586821436882019
Validation loss: 2.1893076499303183

Epoch: 6| Step: 12
Training loss: 1.5045238733291626
Validation loss: 2.1718454559644065

Epoch: 6| Step: 13
Training loss: 1.681164264678955
Validation loss: 2.1827443838119507

Epoch: 240| Step: 0
Training loss: 1.5932626724243164
Validation loss: 2.182531734307607

Epoch: 6| Step: 1
Training loss: 1.8949755430221558
Validation loss: 2.1873046358426413

Epoch: 6| Step: 2
Training loss: 1.05837082862854
Validation loss: 2.1840991179148355

Epoch: 6| Step: 3
Training loss: 1.6596739292144775
Validation loss: 2.1544059117635093

Epoch: 6| Step: 4
Training loss: 1.682051181793213
Validation loss: 2.1447258989016214

Epoch: 6| Step: 5
Training loss: 1.455242395401001
Validation loss: 2.1579651633898416

Epoch: 6| Step: 6
Training loss: 1.8937554359436035
Validation loss: 2.1549286047617593

Epoch: 6| Step: 7
Training loss: 1.1721117496490479
Validation loss: 2.16921603679657

Epoch: 6| Step: 8
Training loss: 2.0122056007385254
Validation loss: 2.1777172883351645

Epoch: 6| Step: 9
Training loss: 1.7891966104507446
Validation loss: 2.17899219195048

Epoch: 6| Step: 10
Training loss: 1.8687541484832764
Validation loss: 2.1627249717712402

Epoch: 6| Step: 11
Training loss: 1.7006800174713135
Validation loss: 2.1534849603970847

Epoch: 6| Step: 12
Training loss: 1.861876130104065
Validation loss: 2.157083431879679

Epoch: 6| Step: 13
Training loss: 2.8053503036499023
Validation loss: 2.194192965825399

Epoch: 241| Step: 0
Training loss: 2.220348834991455
Validation loss: 2.179570436477661

Epoch: 6| Step: 1
Training loss: 1.5006499290466309
Validation loss: 2.2063742677370706

Epoch: 6| Step: 2
Training loss: 2.259855270385742
Validation loss: 2.1671746969223022

Epoch: 6| Step: 3
Training loss: 1.838463306427002
Validation loss: 2.158685823281606

Epoch: 6| Step: 4
Training loss: 1.675752878189087
Validation loss: 2.1911206444104514

Epoch: 6| Step: 5
Training loss: 1.566856861114502
Validation loss: 2.1660677989323935

Epoch: 6| Step: 6
Training loss: 1.3397648334503174
Validation loss: 2.1720679998397827

Epoch: 6| Step: 7
Training loss: 1.2821087837219238
Validation loss: 2.183129092057546

Epoch: 6| Step: 8
Training loss: 1.6523728370666504
Validation loss: 2.1667767564455667

Epoch: 6| Step: 9
Training loss: 2.6893322467803955
Validation loss: 2.165995260079702

Epoch: 6| Step: 10
Training loss: 1.8403921127319336
Validation loss: 2.1701931158701577

Epoch: 6| Step: 11
Training loss: 1.55454683303833
Validation loss: 2.180428067843119

Epoch: 6| Step: 12
Training loss: 1.7442058324813843
Validation loss: 2.1912901401519775

Epoch: 6| Step: 13
Training loss: 1.858797550201416
Validation loss: 2.2128583788871765

Epoch: 242| Step: 0
Training loss: 1.5276025533676147
Validation loss: 2.193770448366801

Epoch: 6| Step: 1
Training loss: 1.1744211912155151
Validation loss: 2.210976163546244

Epoch: 6| Step: 2
Training loss: 1.8271763324737549
Validation loss: 2.2221707105636597

Epoch: 6| Step: 3
Training loss: 1.8773455619812012
Validation loss: 2.2177937030792236

Epoch: 6| Step: 4
Training loss: 1.3985333442687988
Validation loss: 2.2100031971931458

Epoch: 6| Step: 5
Training loss: 1.5719916820526123
Validation loss: 2.2135329246520996

Epoch: 6| Step: 6
Training loss: 1.827313780784607
Validation loss: 2.21661514043808

Epoch: 6| Step: 7
Training loss: 1.0595743656158447
Validation loss: 2.1882612705230713

Epoch: 6| Step: 8
Training loss: 1.8603355884552002
Validation loss: 2.194709857304891

Epoch: 6| Step: 9
Training loss: 1.647094488143921
Validation loss: 2.180156489213308

Epoch: 6| Step: 10
Training loss: 2.8903183937072754
Validation loss: 2.179730216662089

Epoch: 6| Step: 11
Training loss: 1.7717362642288208
Validation loss: 2.16331022977829

Epoch: 6| Step: 12
Training loss: 1.8168809413909912
Validation loss: 2.188729166984558

Epoch: 6| Step: 13
Training loss: 2.4065942764282227
Validation loss: 2.1904079914093018

Epoch: 243| Step: 0
Training loss: 1.652195692062378
Validation loss: 2.187693198521932

Epoch: 6| Step: 1
Training loss: 2.1075594425201416
Validation loss: 2.2096997102101645

Epoch: 6| Step: 2
Training loss: 1.6109027862548828
Validation loss: 2.1991540789604187

Epoch: 6| Step: 3
Training loss: 1.5699448585510254
Validation loss: 2.1998876333236694

Epoch: 6| Step: 4
Training loss: 1.2937371730804443
Validation loss: 2.1864782174428306

Epoch: 6| Step: 5
Training loss: 1.9586589336395264
Validation loss: 2.193036139011383

Epoch: 6| Step: 6
Training loss: 1.447950839996338
Validation loss: 2.1939191023508706

Epoch: 6| Step: 7
Training loss: 2.201906681060791
Validation loss: 2.2060095071792603

Epoch: 6| Step: 8
Training loss: 1.0211923122406006
Validation loss: 2.218531847000122

Epoch: 6| Step: 9
Training loss: 1.7382361888885498
Validation loss: 2.2085346579551697

Epoch: 6| Step: 10
Training loss: 1.8703218698501587
Validation loss: 2.198312064011892

Epoch: 6| Step: 11
Training loss: 1.425062894821167
Validation loss: 2.1762388745943704

Epoch: 6| Step: 12
Training loss: 2.2681047916412354
Validation loss: 2.1816708048184714

Epoch: 6| Step: 13
Training loss: 2.1656267642974854
Validation loss: 2.170642634232839

Epoch: 244| Step: 0
Training loss: 1.6910426616668701
Validation loss: 2.1736185948053994

Epoch: 6| Step: 1
Training loss: 1.6302812099456787
Validation loss: 2.1620572408040366

Epoch: 6| Step: 2
Training loss: 1.2663650512695312
Validation loss: 2.1706607341766357

Epoch: 6| Step: 3
Training loss: 1.9343113899230957
Validation loss: 2.175330658753713

Epoch: 6| Step: 4
Training loss: 2.4943439960479736
Validation loss: 2.179117759068807

Epoch: 6| Step: 5
Training loss: 1.449225902557373
Validation loss: 2.1776820023854575

Epoch: 6| Step: 6
Training loss: 1.3409944772720337
Validation loss: 2.1873938838640847

Epoch: 6| Step: 7
Training loss: 1.9210362434387207
Validation loss: 2.2005104621251426

Epoch: 6| Step: 8
Training loss: 2.1708552837371826
Validation loss: 2.1953053077061973

Epoch: 6| Step: 9
Training loss: 2.041592597961426
Validation loss: 2.203310171763102

Epoch: 6| Step: 10
Training loss: 1.913264274597168
Validation loss: 2.248373329639435

Epoch: 6| Step: 11
Training loss: 1.526773452758789
Validation loss: 2.2112491726875305

Epoch: 6| Step: 12
Training loss: 1.7605953216552734
Validation loss: 2.208573798338572

Epoch: 6| Step: 13
Training loss: 1.8198661804199219
Validation loss: 2.212090174357096

Epoch: 245| Step: 0
Training loss: 1.4042812585830688
Validation loss: 2.17543617884318

Epoch: 6| Step: 1
Training loss: 2.138451099395752
Validation loss: 2.161974390347799

Epoch: 6| Step: 2
Training loss: 1.2472175359725952
Validation loss: 2.160801867643992

Epoch: 6| Step: 3
Training loss: 2.075395345687866
Validation loss: 2.167467554410299

Epoch: 6| Step: 4
Training loss: 2.2815258502960205
Validation loss: 2.1893503268559775

Epoch: 6| Step: 5
Training loss: 1.8897380828857422
Validation loss: 2.175600985685984

Epoch: 6| Step: 6
Training loss: 2.0734286308288574
Validation loss: 2.1638916730880737

Epoch: 6| Step: 7
Training loss: 2.1388025283813477
Validation loss: 2.1854125261306763

Epoch: 6| Step: 8
Training loss: 1.304328203201294
Validation loss: 2.1708098649978638

Epoch: 6| Step: 9
Training loss: 1.372143268585205
Validation loss: 2.1814515590667725

Epoch: 6| Step: 10
Training loss: 1.5183513164520264
Validation loss: 2.16980242729187

Epoch: 6| Step: 11
Training loss: 1.8899497985839844
Validation loss: 2.170907497406006

Epoch: 6| Step: 12
Training loss: 1.3052949905395508
Validation loss: 2.189291556676229

Epoch: 6| Step: 13
Training loss: 1.8178550004959106
Validation loss: 2.1799294551213584

Epoch: 246| Step: 0
Training loss: 1.3452835083007812
Validation loss: 2.1770548025767007

Epoch: 6| Step: 1
Training loss: 2.5449228286743164
Validation loss: 2.206454813480377

Epoch: 6| Step: 2
Training loss: 1.4721835851669312
Validation loss: 2.182225306828817

Epoch: 6| Step: 3
Training loss: 1.6311942338943481
Validation loss: 2.2059258818626404

Epoch: 6| Step: 4
Training loss: 1.1518404483795166
Validation loss: 2.2096241315205893

Epoch: 6| Step: 5
Training loss: 1.4040064811706543
Validation loss: 2.224891940752665

Epoch: 6| Step: 6
Training loss: 2.1255786418914795
Validation loss: 2.206464648246765

Epoch: 6| Step: 7
Training loss: 2.262261390686035
Validation loss: 2.205662469069163

Epoch: 6| Step: 8
Training loss: 2.1515164375305176
Validation loss: 2.199435909589132

Epoch: 6| Step: 9
Training loss: 1.5958088636398315
Validation loss: 2.173634926478068

Epoch: 6| Step: 10
Training loss: 1.480250597000122
Validation loss: 2.171976844469706

Epoch: 6| Step: 11
Training loss: 0.98637855052948
Validation loss: 2.190863569577535

Epoch: 6| Step: 12
Training loss: 2.5238733291625977
Validation loss: 2.1868275006612143

Epoch: 6| Step: 13
Training loss: 1.5142954587936401
Validation loss: 2.1903262933095298

Epoch: 247| Step: 0
Training loss: 2.1996400356292725
Validation loss: 2.1838980515797934

Epoch: 6| Step: 1
Training loss: 1.4482636451721191
Validation loss: 2.18339471022288

Epoch: 6| Step: 2
Training loss: 1.8119683265686035
Validation loss: 2.1813591917355857

Epoch: 6| Step: 3
Training loss: 1.7353425025939941
Validation loss: 2.198775331179301

Epoch: 6| Step: 4
Training loss: 1.9589978456497192
Validation loss: 2.1884413162867227

Epoch: 6| Step: 5
Training loss: 1.5422710180282593
Validation loss: 2.2049326300621033

Epoch: 6| Step: 6
Training loss: 1.482177495956421
Validation loss: 2.190661668777466

Epoch: 6| Step: 7
Training loss: 1.401595115661621
Validation loss: 2.232760190963745

Epoch: 6| Step: 8
Training loss: 1.209120750427246
Validation loss: 2.193372925122579

Epoch: 6| Step: 9
Training loss: 2.4464211463928223
Validation loss: 2.187204202016195

Epoch: 6| Step: 10
Training loss: 1.3744627237319946
Validation loss: 2.201789617538452

Epoch: 6| Step: 11
Training loss: 1.9509369134902954
Validation loss: 2.2031163970629373

Epoch: 6| Step: 12
Training loss: 1.3738512992858887
Validation loss: 2.1914122899373374

Epoch: 6| Step: 13
Training loss: 1.8470685482025146
Validation loss: 2.1863298416137695

Epoch: 248| Step: 0
Training loss: 1.3594369888305664
Validation loss: 2.1987059513727822

Epoch: 6| Step: 1
Training loss: 1.5543913841247559
Validation loss: 2.19650661945343

Epoch: 6| Step: 2
Training loss: 1.52388596534729
Validation loss: 2.167486786842346

Epoch: 6| Step: 3
Training loss: 1.7690002918243408
Validation loss: 2.1833877563476562

Epoch: 6| Step: 4
Training loss: 1.4822834730148315
Validation loss: 2.199555277824402

Epoch: 6| Step: 5
Training loss: 1.9713472127914429
Validation loss: 2.1820791761080423

Epoch: 6| Step: 6
Training loss: 1.2814891338348389
Validation loss: 2.192815979321798

Epoch: 6| Step: 7
Training loss: 1.5268354415893555
Validation loss: 2.2057835261027017

Epoch: 6| Step: 8
Training loss: 1.514840841293335
Validation loss: 2.1928304036458335

Epoch: 6| Step: 9
Training loss: 1.6919426918029785
Validation loss: 2.1865800420443215

Epoch: 6| Step: 10
Training loss: 1.7638431787490845
Validation loss: 2.1704090436299643

Epoch: 6| Step: 11
Training loss: 2.0750861167907715
Validation loss: 2.191440999507904

Epoch: 6| Step: 12
Training loss: 2.314640998840332
Validation loss: 2.1778714060783386

Epoch: 6| Step: 13
Training loss: 1.4782631397247314
Validation loss: 2.1763163010279336

Epoch: 249| Step: 0
Training loss: 1.7272289991378784
Validation loss: 2.1729083259900412

Epoch: 6| Step: 1
Training loss: 1.6123343706130981
Validation loss: 2.179258624712626

Epoch: 6| Step: 2
Training loss: 1.6528406143188477
Validation loss: 2.1866466403007507

Epoch: 6| Step: 3
Training loss: 2.1389317512512207
Validation loss: 2.1724685629208884

Epoch: 6| Step: 4
Training loss: 1.7111797332763672
Validation loss: 2.20711350440979

Epoch: 6| Step: 5
Training loss: 2.4847848415374756
Validation loss: 2.169980823993683

Epoch: 6| Step: 6
Training loss: 1.4426567554473877
Validation loss: 2.1860681970914206

Epoch: 6| Step: 7
Training loss: 1.4669532775878906
Validation loss: 2.1968783140182495

Epoch: 6| Step: 8
Training loss: 1.1799159049987793
Validation loss: 2.2029558420181274

Epoch: 6| Step: 9
Training loss: 1.9337364435195923
Validation loss: 2.198707938194275

Epoch: 6| Step: 10
Training loss: 1.6465100049972534
Validation loss: 2.172929803530375

Epoch: 6| Step: 11
Training loss: 1.412916660308838
Validation loss: 2.1888083616892495

Epoch: 6| Step: 12
Training loss: 1.4680211544036865
Validation loss: 2.1840280890464783

Epoch: 6| Step: 13
Training loss: 1.7807400226593018
Validation loss: 2.182309607664744

Epoch: 250| Step: 0
Training loss: 1.9129407405853271
Validation loss: 2.1927265723546348

Epoch: 6| Step: 1
Training loss: 1.7995823621749878
Validation loss: 2.1917269428571067

Epoch: 6| Step: 2
Training loss: 1.342828392982483
Validation loss: 2.1843742728233337

Epoch: 6| Step: 3
Training loss: 1.704242467880249
Validation loss: 2.1987260778745017

Epoch: 6| Step: 4
Training loss: 2.306720495223999
Validation loss: 2.1876387000083923

Epoch: 6| Step: 5
Training loss: 1.748152732849121
Validation loss: 2.183064619700114

Epoch: 6| Step: 6
Training loss: 1.2779840230941772
Validation loss: 2.1884599725405374

Epoch: 6| Step: 7
Training loss: 1.9862279891967773
Validation loss: 2.1931248903274536

Epoch: 6| Step: 8
Training loss: 1.5941991806030273
Validation loss: 2.1867304046948752

Epoch: 6| Step: 9
Training loss: 1.4946653842926025
Validation loss: 2.211317261060079

Epoch: 6| Step: 10
Training loss: 1.902378797531128
Validation loss: 2.1957327326138816

Epoch: 6| Step: 11
Training loss: 1.3179926872253418
Validation loss: 2.182361980279287

Epoch: 6| Step: 12
Training loss: 1.4710392951965332
Validation loss: 2.1745609442392984

Epoch: 6| Step: 13
Training loss: 1.554537057876587
Validation loss: 2.165506958961487

Epoch: 251| Step: 0
Training loss: 1.6999180316925049
Validation loss: 2.1735228300094604

Epoch: 6| Step: 1
Training loss: 1.4003605842590332
Validation loss: 2.176952878634135

Epoch: 6| Step: 2
Training loss: 1.8961763381958008
Validation loss: 2.1777788003285727

Epoch: 6| Step: 3
Training loss: 1.421816110610962
Validation loss: 2.1723759373029075

Epoch: 6| Step: 4
Training loss: 1.1801379919052124
Validation loss: 2.1860283613204956

Epoch: 6| Step: 5
Training loss: 2.0716183185577393
Validation loss: 2.184580087661743

Epoch: 6| Step: 6
Training loss: 1.8609850406646729
Validation loss: 2.1881590684254966

Epoch: 6| Step: 7
Training loss: 2.1023812294006348
Validation loss: 2.208362897237142

Epoch: 6| Step: 8
Training loss: 1.17359459400177
Validation loss: 2.1709136764208474

Epoch: 6| Step: 9
Training loss: 1.6909496784210205
Validation loss: 2.1637470523516336

Epoch: 6| Step: 10
Training loss: 1.8900151252746582
Validation loss: 2.172260304292043

Epoch: 6| Step: 11
Training loss: 1.5755805969238281
Validation loss: 2.1573217113812766

Epoch: 6| Step: 12
Training loss: 2.0801143646240234
Validation loss: 2.1468668977419534

Epoch: 6| Step: 13
Training loss: 1.4207935333251953
Validation loss: 2.1612065037091575

Epoch: 252| Step: 0
Training loss: 1.2973036766052246
Validation loss: 2.1576215823491416

Epoch: 6| Step: 1
Training loss: 2.7113685607910156
Validation loss: 2.155531366666158

Epoch: 6| Step: 2
Training loss: 1.7271833419799805
Validation loss: 2.1263669530550637

Epoch: 6| Step: 3
Training loss: 1.5972418785095215
Validation loss: 2.1513798236846924

Epoch: 6| Step: 4
Training loss: 2.080159902572632
Validation loss: 2.168138802051544

Epoch: 6| Step: 5
Training loss: 1.3854273557662964
Validation loss: 2.143897612889608

Epoch: 6| Step: 6
Training loss: 1.4918898344039917
Validation loss: 2.1520909667015076

Epoch: 6| Step: 7
Training loss: 1.945125937461853
Validation loss: 2.1414329608281455

Epoch: 6| Step: 8
Training loss: 1.1978464126586914
Validation loss: 2.157622675100962

Epoch: 6| Step: 9
Training loss: 2.2960734367370605
Validation loss: 2.156426707903544

Epoch: 6| Step: 10
Training loss: 1.8333919048309326
Validation loss: 2.1678447326024375

Epoch: 6| Step: 11
Training loss: 1.7141931056976318
Validation loss: 2.158636212348938

Epoch: 6| Step: 12
Training loss: 1.4212052822113037
Validation loss: 2.154147187868754

Epoch: 6| Step: 13
Training loss: 1.0401690006256104
Validation loss: 2.1684293945630393

Epoch: 253| Step: 0
Training loss: 1.5958733558654785
Validation loss: 2.1490273475646973

Epoch: 6| Step: 1
Training loss: 1.5473439693450928
Validation loss: 2.1597649653752646

Epoch: 6| Step: 2
Training loss: 1.6064517498016357
Validation loss: 2.162694970766703

Epoch: 6| Step: 3
Training loss: 1.2061272859573364
Validation loss: 2.1759139696756997

Epoch: 6| Step: 4
Training loss: 1.9599316120147705
Validation loss: 2.184203644593557

Epoch: 6| Step: 5
Training loss: 1.7614340782165527
Validation loss: 2.152305543422699

Epoch: 6| Step: 6
Training loss: 1.5968331098556519
Validation loss: 2.1812239487965903

Epoch: 6| Step: 7
Training loss: 1.6735721826553345
Validation loss: 2.1794031063715615

Epoch: 6| Step: 8
Training loss: 1.8368380069732666
Validation loss: 2.208142856756846

Epoch: 6| Step: 9
Training loss: 1.5973708629608154
Validation loss: 2.2168690959612527

Epoch: 6| Step: 10
Training loss: 1.806117057800293
Validation loss: 2.198195219039917

Epoch: 6| Step: 11
Training loss: 2.119462728500366
Validation loss: 2.2184988458951316

Epoch: 6| Step: 12
Training loss: 1.7522051334381104
Validation loss: 2.200409452120463

Epoch: 6| Step: 13
Training loss: 1.287288784980774
Validation loss: 2.1973150173823037

Epoch: 254| Step: 0
Training loss: 1.0423749685287476
Validation loss: 2.221941113471985

Epoch: 6| Step: 1
Training loss: 1.514587640762329
Validation loss: 2.1925711830457053

Epoch: 6| Step: 2
Training loss: 1.5000395774841309
Validation loss: 2.1978562076886496

Epoch: 6| Step: 3
Training loss: 1.7110552787780762
Validation loss: 2.188607633113861

Epoch: 6| Step: 4
Training loss: 2.098876953125
Validation loss: 2.2047723531723022

Epoch: 6| Step: 5
Training loss: 1.8171463012695312
Validation loss: 2.1933869123458862

Epoch: 6| Step: 6
Training loss: 1.3478658199310303
Validation loss: 2.21251771847407

Epoch: 6| Step: 7
Training loss: 1.941017508506775
Validation loss: 2.1965437730153403

Epoch: 6| Step: 8
Training loss: 3.0018749237060547
Validation loss: 2.1937709053357444

Epoch: 6| Step: 9
Training loss: 1.8731403350830078
Validation loss: 2.1940671801567078

Epoch: 6| Step: 10
Training loss: 1.0102574825286865
Validation loss: 2.1968393325805664

Epoch: 6| Step: 11
Training loss: 1.5630488395690918
Validation loss: 2.191094974676768

Epoch: 6| Step: 12
Training loss: 1.2841970920562744
Validation loss: 2.1905582348505654

Epoch: 6| Step: 13
Training loss: 1.6644322872161865
Validation loss: 2.1925120751063027

Epoch: 255| Step: 0
Training loss: 2.148844003677368
Validation loss: 2.171425978342692

Epoch: 6| Step: 1
Training loss: 0.9107649326324463
Validation loss: 2.1809774041175842

Epoch: 6| Step: 2
Training loss: 1.6511304378509521
Validation loss: 2.1653404037157693

Epoch: 6| Step: 3
Training loss: 1.852778434753418
Validation loss: 2.182861804962158

Epoch: 6| Step: 4
Training loss: 1.6136246919631958
Validation loss: 2.184329708417257

Epoch: 6| Step: 5
Training loss: 1.7948362827301025
Validation loss: 2.1718046267827353

Epoch: 6| Step: 6
Training loss: 2.3047454357147217
Validation loss: 2.1765759785970054

Epoch: 6| Step: 7
Training loss: 1.9912869930267334
Validation loss: 2.1871604720751443

Epoch: 6| Step: 8
Training loss: 1.5320395231246948
Validation loss: 2.200328767299652

Epoch: 6| Step: 9
Training loss: 1.412583351135254
Validation loss: 2.2003167470296225

Epoch: 6| Step: 10
Training loss: 1.3295978307724
Validation loss: 2.1886931657791138

Epoch: 6| Step: 11
Training loss: 1.3547523021697998
Validation loss: 2.2110463778177896

Epoch: 6| Step: 12
Training loss: 1.9896610975265503
Validation loss: 2.207382400830587

Epoch: 6| Step: 13
Training loss: 1.8900747299194336
Validation loss: 2.183287481466929

Epoch: 256| Step: 0
Training loss: 1.6744625568389893
Validation loss: 2.2126198013623557

Epoch: 6| Step: 1
Training loss: 1.838901400566101
Validation loss: 2.1927228371302285

Epoch: 6| Step: 2
Training loss: 1.5076119899749756
Validation loss: 2.163150429725647

Epoch: 6| Step: 3
Training loss: 1.1947944164276123
Validation loss: 2.122422754764557

Epoch: 6| Step: 4
Training loss: 1.9870694875717163
Validation loss: 2.1436415910720825

Epoch: 6| Step: 5
Training loss: 1.9296374320983887
Validation loss: 2.1311960419019065

Epoch: 6| Step: 6
Training loss: 1.399545669555664
Validation loss: 2.1471847891807556

Epoch: 6| Step: 7
Training loss: 1.8378987312316895
Validation loss: 2.14149934053421

Epoch: 6| Step: 8
Training loss: 2.2509865760803223
Validation loss: 2.1711623469988504

Epoch: 6| Step: 9
Training loss: 1.9324761629104614
Validation loss: 2.1610100666681924

Epoch: 6| Step: 10
Training loss: 1.4936130046844482
Validation loss: 2.174083888530731

Epoch: 6| Step: 11
Training loss: 2.1977436542510986
Validation loss: 2.164334237575531

Epoch: 6| Step: 12
Training loss: 1.3270970582962036
Validation loss: 2.15714031457901

Epoch: 6| Step: 13
Training loss: 1.547428846359253
Validation loss: 2.156208078066508

Epoch: 257| Step: 0
Training loss: 1.8497356176376343
Validation loss: 2.142357369263967

Epoch: 6| Step: 1
Training loss: 1.0933094024658203
Validation loss: 2.1413978338241577

Epoch: 6| Step: 2
Training loss: 1.6337827444076538
Validation loss: 2.1837448279062905

Epoch: 6| Step: 3
Training loss: 1.3990044593811035
Validation loss: 2.15030304590861

Epoch: 6| Step: 4
Training loss: 1.4628159999847412
Validation loss: 2.1712511579195657

Epoch: 6| Step: 5
Training loss: 2.458298444747925
Validation loss: 2.185773491859436

Epoch: 6| Step: 6
Training loss: 1.4974589347839355
Validation loss: 2.173167407512665

Epoch: 6| Step: 7
Training loss: 2.321524143218994
Validation loss: 2.186187823613485

Epoch: 6| Step: 8
Training loss: 0.918682336807251
Validation loss: 2.185140371322632

Epoch: 6| Step: 9
Training loss: 1.7965625524520874
Validation loss: 2.1800572872161865

Epoch: 6| Step: 10
Training loss: 1.8020031452178955
Validation loss: 2.1891384522120156

Epoch: 6| Step: 11
Training loss: 2.234494209289551
Validation loss: 2.1775901317596436

Epoch: 6| Step: 12
Training loss: 1.6836333274841309
Validation loss: 2.1670402685801187

Epoch: 6| Step: 13
Training loss: 1.0163376331329346
Validation loss: 2.1831935048103333

Epoch: 258| Step: 0
Training loss: 1.4415870904922485
Validation loss: 2.169128139813741

Epoch: 6| Step: 1
Training loss: 1.3641330003738403
Validation loss: 2.1789804299672446

Epoch: 6| Step: 2
Training loss: 2.2471611499786377
Validation loss: 2.172720114390055

Epoch: 6| Step: 3
Training loss: 2.059175968170166
Validation loss: 2.183266202608744

Epoch: 6| Step: 4
Training loss: 1.483517050743103
Validation loss: 2.1787240505218506

Epoch: 6| Step: 5
Training loss: 2.3876452445983887
Validation loss: 2.1886552572250366

Epoch: 6| Step: 6
Training loss: 1.6692636013031006
Validation loss: 2.2042452891667685

Epoch: 6| Step: 7
Training loss: 1.938804268836975
Validation loss: 2.20747443040212

Epoch: 6| Step: 8
Training loss: 1.2957825660705566
Validation loss: 2.2002253929773965

Epoch: 6| Step: 9
Training loss: 1.1780166625976562
Validation loss: 2.2423011461893716

Epoch: 6| Step: 10
Training loss: 1.7609872817993164
Validation loss: 2.2135459184646606

Epoch: 6| Step: 11
Training loss: 1.4376261234283447
Validation loss: 2.200982371966044

Epoch: 6| Step: 12
Training loss: 1.4872286319732666
Validation loss: 2.189996858437856

Epoch: 6| Step: 13
Training loss: 1.5886807441711426
Validation loss: 2.172717014948527

Epoch: 259| Step: 0
Training loss: 1.5171719789505005
Validation loss: 2.1879297693570456

Epoch: 6| Step: 1
Training loss: 1.7260901927947998
Validation loss: 2.1912084221839905

Epoch: 6| Step: 2
Training loss: 1.7771077156066895
Validation loss: 2.1842773954073587

Epoch: 6| Step: 3
Training loss: 1.7538572549819946
Validation loss: 2.1835052172342935

Epoch: 6| Step: 4
Training loss: 1.4858243465423584
Validation loss: 2.164606829484304

Epoch: 6| Step: 5
Training loss: 1.4804987907409668
Validation loss: 2.1682533423105874

Epoch: 6| Step: 6
Training loss: 2.2305514812469482
Validation loss: 2.16152552763621

Epoch: 6| Step: 7
Training loss: 1.1868529319763184
Validation loss: 2.160856048266093

Epoch: 6| Step: 8
Training loss: 0.9380213022232056
Validation loss: 2.1850772301355996

Epoch: 6| Step: 9
Training loss: 1.849813461303711
Validation loss: 2.1739659309387207

Epoch: 6| Step: 10
Training loss: 1.3240206241607666
Validation loss: 2.1706488331158957

Epoch: 6| Step: 11
Training loss: 1.7050838470458984
Validation loss: 2.186867356300354

Epoch: 6| Step: 12
Training loss: 1.5369813442230225
Validation loss: 2.2185795108477273

Epoch: 6| Step: 13
Training loss: 2.869901180267334
Validation loss: 2.1847225228945413

Epoch: 260| Step: 0
Training loss: 1.9862794876098633
Validation loss: 2.2245696584383645

Epoch: 6| Step: 1
Training loss: 1.7342345714569092
Validation loss: 2.2166184186935425

Epoch: 6| Step: 2
Training loss: 1.394552230834961
Validation loss: 2.2291267116864524

Epoch: 6| Step: 3
Training loss: 1.8659396171569824
Validation loss: 2.2146300872166953

Epoch: 6| Step: 4
Training loss: 1.5759541988372803
Validation loss: 2.1536139845848083

Epoch: 6| Step: 5
Training loss: 1.5408730506896973
Validation loss: 2.1721357504526773

Epoch: 6| Step: 6
Training loss: 1.9542737007141113
Validation loss: 2.1607828537623086

Epoch: 6| Step: 7
Training loss: 2.5830864906311035
Validation loss: 2.17066099246343

Epoch: 6| Step: 8
Training loss: 1.7308903932571411
Validation loss: 2.1726324558258057

Epoch: 6| Step: 9
Training loss: 1.1238667964935303
Validation loss: 2.164307634035746

Epoch: 6| Step: 10
Training loss: 1.7064354419708252
Validation loss: 2.1636557976404824

Epoch: 6| Step: 11
Training loss: 1.4759716987609863
Validation loss: 2.175959805647532

Epoch: 6| Step: 12
Training loss: 0.9286386370658875
Validation loss: 2.163348654905955

Epoch: 6| Step: 13
Training loss: 1.7161176204681396
Validation loss: 2.191733638445536

Epoch: 261| Step: 0
Training loss: 2.28271746635437
Validation loss: 2.191109617551168

Epoch: 6| Step: 1
Training loss: 1.278174638748169
Validation loss: 2.173392176628113

Epoch: 6| Step: 2
Training loss: 1.9938535690307617
Validation loss: 2.160946508248647

Epoch: 6| Step: 3
Training loss: 1.4844777584075928
Validation loss: 2.171901981035868

Epoch: 6| Step: 4
Training loss: 1.8903512954711914
Validation loss: 2.1505726973215737

Epoch: 6| Step: 5
Training loss: 2.2799370288848877
Validation loss: 2.1453351974487305

Epoch: 6| Step: 6
Training loss: 1.472383737564087
Validation loss: 2.1338831583658853

Epoch: 6| Step: 7
Training loss: 2.035491704940796
Validation loss: 2.166540245215098

Epoch: 6| Step: 8
Training loss: 1.6155258417129517
Validation loss: 2.1727654933929443

Epoch: 6| Step: 9
Training loss: 1.5477759838104248
Validation loss: 2.1662755409876504

Epoch: 6| Step: 10
Training loss: 1.7715070247650146
Validation loss: 2.153796156247457

Epoch: 6| Step: 11
Training loss: 1.0920623540878296
Validation loss: 2.166296740372976

Epoch: 6| Step: 12
Training loss: 1.300175666809082
Validation loss: 2.1643291314442954

Epoch: 6| Step: 13
Training loss: 1.3144140243530273
Validation loss: 2.15902179479599

Epoch: 262| Step: 0
Training loss: 1.8305702209472656
Validation loss: 2.1800289154052734

Epoch: 6| Step: 1
Training loss: 1.5140509605407715
Validation loss: 2.180116613705953

Epoch: 6| Step: 2
Training loss: 1.568044662475586
Validation loss: 2.1924748023351035

Epoch: 6| Step: 3
Training loss: 1.9518053531646729
Validation loss: 2.211129148801168

Epoch: 6| Step: 4
Training loss: 1.327862024307251
Validation loss: 2.1665417750676474

Epoch: 6| Step: 5
Training loss: 2.164341926574707
Validation loss: 2.2098727027575173

Epoch: 6| Step: 6
Training loss: 1.5608031749725342
Validation loss: 2.2066772977511087

Epoch: 6| Step: 7
Training loss: 1.4481945037841797
Validation loss: 2.2228830059369407

Epoch: 6| Step: 8
Training loss: 1.5989662408828735
Validation loss: 2.2248342831929526

Epoch: 6| Step: 9
Training loss: 2.0671496391296387
Validation loss: 2.2361448605855307

Epoch: 6| Step: 10
Training loss: 1.4861688613891602
Validation loss: 2.202593227227529

Epoch: 6| Step: 11
Training loss: 1.6929214000701904
Validation loss: 2.224249541759491

Epoch: 6| Step: 12
Training loss: 1.4791463613510132
Validation loss: 2.231964588165283

Epoch: 6| Step: 13
Training loss: 1.4834420680999756
Validation loss: 2.228493332862854

Epoch: 263| Step: 0
Training loss: 1.0597851276397705
Validation loss: 2.2118472258249917

Epoch: 6| Step: 1
Training loss: 1.1076501607894897
Validation loss: 2.228460152943929

Epoch: 6| Step: 2
Training loss: 1.3052098751068115
Validation loss: 2.193720599015554

Epoch: 6| Step: 3
Training loss: 2.0702762603759766
Validation loss: 2.1796550154685974

Epoch: 6| Step: 4
Training loss: 1.5817742347717285
Validation loss: 2.176594316959381

Epoch: 6| Step: 5
Training loss: 1.7859346866607666
Validation loss: 2.1591259837150574

Epoch: 6| Step: 6
Training loss: 2.0744848251342773
Validation loss: 2.137732287247976

Epoch: 6| Step: 7
Training loss: 2.639805793762207
Validation loss: 2.15873517592748

Epoch: 6| Step: 8
Training loss: 1.8517506122589111
Validation loss: 2.170758863290151

Epoch: 6| Step: 9
Training loss: 1.892626404762268
Validation loss: 2.1577174266179404

Epoch: 6| Step: 10
Training loss: 1.6871907711029053
Validation loss: 2.1547457774480185

Epoch: 6| Step: 11
Training loss: 2.034811496734619
Validation loss: 2.1394814451535544

Epoch: 6| Step: 12
Training loss: 1.3159031867980957
Validation loss: 2.1466881036758423

Epoch: 6| Step: 13
Training loss: 1.713058590888977
Validation loss: 2.1710875233014426

Epoch: 264| Step: 0
Training loss: 1.8228461742401123
Validation loss: 2.194532632827759

Epoch: 6| Step: 1
Training loss: 1.3603909015655518
Validation loss: 2.2065264781316123

Epoch: 6| Step: 2
Training loss: 1.1037254333496094
Validation loss: 2.1782753070195517

Epoch: 6| Step: 3
Training loss: 1.8605691194534302
Validation loss: 2.174916406472524

Epoch: 6| Step: 4
Training loss: 1.6821479797363281
Validation loss: 2.193119764328003

Epoch: 6| Step: 5
Training loss: 2.0167388916015625
Validation loss: 2.1925206979115806

Epoch: 6| Step: 6
Training loss: 1.9157109260559082
Validation loss: 2.1977204084396362

Epoch: 6| Step: 7
Training loss: 1.4639290571212769
Validation loss: 2.1698312560717263

Epoch: 6| Step: 8
Training loss: 2.3689541816711426
Validation loss: 2.1677122910817466

Epoch: 6| Step: 9
Training loss: 1.1659700870513916
Validation loss: 2.2046732107798257

Epoch: 6| Step: 10
Training loss: 1.8247419595718384
Validation loss: 2.189927558104197

Epoch: 6| Step: 11
Training loss: 2.39780855178833
Validation loss: 2.1621662775675454

Epoch: 6| Step: 12
Training loss: 1.9854555130004883
Validation loss: 2.176803986231486

Epoch: 6| Step: 13
Training loss: 1.2195205688476562
Validation loss: 2.2170846660931907

Epoch: 265| Step: 0
Training loss: 1.2429547309875488
Validation loss: 2.193499128023783

Epoch: 6| Step: 1
Training loss: 1.8295567035675049
Validation loss: 2.1879586378733316

Epoch: 6| Step: 2
Training loss: 1.5301264524459839
Validation loss: 2.1982120275497437

Epoch: 6| Step: 3
Training loss: 1.6765782833099365
Validation loss: 2.1694549918174744

Epoch: 6| Step: 4
Training loss: 1.3665475845336914
Validation loss: 2.2129344741503396

Epoch: 6| Step: 5
Training loss: 1.5248615741729736
Validation loss: 2.1764865716298423

Epoch: 6| Step: 6
Training loss: 1.725430965423584
Validation loss: 2.1638500491778054

Epoch: 6| Step: 7
Training loss: 2.3566715717315674
Validation loss: 2.170084059238434

Epoch: 6| Step: 8
Training loss: 1.9564238786697388
Validation loss: 2.200866480668386

Epoch: 6| Step: 9
Training loss: 1.223219871520996
Validation loss: 2.1813658674558005

Epoch: 6| Step: 10
Training loss: 2.2311220169067383
Validation loss: 2.197073062260946

Epoch: 6| Step: 11
Training loss: 1.567828893661499
Validation loss: 2.187774658203125

Epoch: 6| Step: 12
Training loss: 1.0740474462509155
Validation loss: 2.176400125026703

Epoch: 6| Step: 13
Training loss: 2.0406339168548584
Validation loss: 2.1804601748784385

Epoch: 266| Step: 0
Training loss: 2.286388397216797
Validation loss: 2.1574445168177285

Epoch: 6| Step: 1
Training loss: 1.2948452234268188
Validation loss: 2.1627954641977944

Epoch: 6| Step: 2
Training loss: 1.4447901248931885
Validation loss: 2.1559057235717773

Epoch: 6| Step: 3
Training loss: 2.0363540649414062
Validation loss: 2.1450116833051047

Epoch: 6| Step: 4
Training loss: 2.460453510284424
Validation loss: 2.1590073903401694

Epoch: 6| Step: 5
Training loss: 1.1097320318222046
Validation loss: 2.175619661808014

Epoch: 6| Step: 6
Training loss: 1.097703456878662
Validation loss: 2.1895825068155923

Epoch: 6| Step: 7
Training loss: 1.3539233207702637
Validation loss: 2.175287405649821

Epoch: 6| Step: 8
Training loss: 1.3264155387878418
Validation loss: 2.2133925358454385

Epoch: 6| Step: 9
Training loss: 2.4344475269317627
Validation loss: 2.1825889348983765

Epoch: 6| Step: 10
Training loss: 1.136949062347412
Validation loss: 2.199017564455668

Epoch: 6| Step: 11
Training loss: 1.1060068607330322
Validation loss: 2.1827349861462912

Epoch: 6| Step: 12
Training loss: 2.4403059482574463
Validation loss: 2.2243916392326355

Epoch: 6| Step: 13
Training loss: 1.4074686765670776
Validation loss: 2.18804140885671

Epoch: 267| Step: 0
Training loss: 3.098008632659912
Validation loss: 2.2001445293426514

Epoch: 6| Step: 1
Training loss: 1.6138278245925903
Validation loss: 2.192469298839569

Epoch: 6| Step: 2
Training loss: 1.7021684646606445
Validation loss: 2.227003892262777

Epoch: 6| Step: 3
Training loss: 1.639797568321228
Validation loss: 2.1896063486735025

Epoch: 6| Step: 4
Training loss: 1.7978591918945312
Validation loss: 2.178639014561971

Epoch: 6| Step: 5
Training loss: 0.9512606263160706
Validation loss: 2.1975467602411904

Epoch: 6| Step: 6
Training loss: 1.2515246868133545
Validation loss: 2.187798043092092

Epoch: 6| Step: 7
Training loss: 1.273776888847351
Validation loss: 2.199482500553131

Epoch: 6| Step: 8
Training loss: 2.184652805328369
Validation loss: 2.168770889441172

Epoch: 6| Step: 9
Training loss: 1.4186211824417114
Validation loss: 2.20274152358373

Epoch: 6| Step: 10
Training loss: 1.2871744632720947
Validation loss: 2.196363389492035

Epoch: 6| Step: 11
Training loss: 1.4022102355957031
Validation loss: 2.194481094678243

Epoch: 6| Step: 12
Training loss: 1.2507644891738892
Validation loss: 2.2048505942026773

Epoch: 6| Step: 13
Training loss: 1.5836600065231323
Validation loss: 2.2006000677744546

Epoch: 268| Step: 0
Training loss: 1.4783661365509033
Validation loss: 2.1994930505752563

Epoch: 6| Step: 1
Training loss: 1.5535016059875488
Validation loss: 2.217200458049774

Epoch: 6| Step: 2
Training loss: 1.8899205923080444
Validation loss: 2.1818963289260864

Epoch: 6| Step: 3
Training loss: 1.6885051727294922
Validation loss: 2.175877253214518

Epoch: 6| Step: 4
Training loss: 1.5558561086654663
Validation loss: 2.1884262363115945

Epoch: 6| Step: 5
Training loss: 1.4788260459899902
Validation loss: 2.190443197886149

Epoch: 6| Step: 6
Training loss: 1.089423656463623
Validation loss: 2.172631025314331

Epoch: 6| Step: 7
Training loss: 1.7818551063537598
Validation loss: 2.1819965839385986

Epoch: 6| Step: 8
Training loss: 1.7017602920532227
Validation loss: 2.185457626978556

Epoch: 6| Step: 9
Training loss: 1.4489747285842896
Validation loss: 2.181189775466919

Epoch: 6| Step: 10
Training loss: 1.5989603996276855
Validation loss: 2.190301795800527

Epoch: 6| Step: 11
Training loss: 1.640911340713501
Validation loss: 2.2037082513173423

Epoch: 6| Step: 12
Training loss: 1.6837961673736572
Validation loss: 2.1949663758277893

Epoch: 6| Step: 13
Training loss: 2.1686441898345947
Validation loss: 2.232030987739563

Epoch: 269| Step: 0
Training loss: 2.0972399711608887
Validation loss: 2.2103777726491294

Epoch: 6| Step: 1
Training loss: 1.5503778457641602
Validation loss: 2.195651868979136

Epoch: 6| Step: 2
Training loss: 1.480737566947937
Validation loss: 2.2079039017359414

Epoch: 6| Step: 3
Training loss: 1.0679080486297607
Validation loss: 2.195712705453237

Epoch: 6| Step: 4
Training loss: 1.0843307971954346
Validation loss: 2.1911762158075967

Epoch: 6| Step: 5
Training loss: 1.3954737186431885
Validation loss: 2.176866034666697

Epoch: 6| Step: 6
Training loss: 1.4978294372558594
Validation loss: 2.182332913080851

Epoch: 6| Step: 7
Training loss: 1.3109855651855469
Validation loss: 2.1828991572062173

Epoch: 6| Step: 8
Training loss: 1.4539825916290283
Validation loss: 2.1734860142072043

Epoch: 6| Step: 9
Training loss: 1.8298109769821167
Validation loss: 2.1860153476397195

Epoch: 6| Step: 10
Training loss: 2.348917007446289
Validation loss: 2.1779338717460632

Epoch: 6| Step: 11
Training loss: 1.749894142150879
Validation loss: 2.174577454725901

Epoch: 6| Step: 12
Training loss: 1.6675159931182861
Validation loss: 2.174988349278768

Epoch: 6| Step: 13
Training loss: 1.8365209102630615
Validation loss: 2.1618956327438354

Epoch: 270| Step: 0
Training loss: 1.5491833686828613
Validation loss: 2.2026659647623696

Epoch: 6| Step: 1
Training loss: 1.75460684299469
Validation loss: 2.160426139831543

Epoch: 6| Step: 2
Training loss: 1.6851229667663574
Validation loss: 2.1909093260765076

Epoch: 6| Step: 3
Training loss: 2.245595693588257
Validation loss: 2.208104689915975

Epoch: 6| Step: 4
Training loss: 1.535017490386963
Validation loss: 2.1819529136021933

Epoch: 6| Step: 5
Training loss: 1.747507095336914
Validation loss: 2.1919756531715393

Epoch: 6| Step: 6
Training loss: 1.7322279214859009
Validation loss: 2.1910229325294495

Epoch: 6| Step: 7
Training loss: 1.323874831199646
Validation loss: 2.2044867873191833

Epoch: 6| Step: 8
Training loss: 1.2773469686508179
Validation loss: 2.200947880744934

Epoch: 6| Step: 9
Training loss: 1.452565312385559
Validation loss: 2.2119847734769187

Epoch: 6| Step: 10
Training loss: 1.6225509643554688
Validation loss: 2.2023686369260154

Epoch: 6| Step: 11
Training loss: 0.9761509299278259
Validation loss: 2.2048031091690063

Epoch: 6| Step: 12
Training loss: 1.3978662490844727
Validation loss: 2.190772513548533

Epoch: 6| Step: 13
Training loss: 2.0244438648223877
Validation loss: 2.20402999718984

Epoch: 271| Step: 0
Training loss: 1.226590633392334
Validation loss: 2.204688807328542

Epoch: 6| Step: 1
Training loss: 2.3984103202819824
Validation loss: 2.21182781457901

Epoch: 6| Step: 2
Training loss: 1.5530211925506592
Validation loss: 2.1802619298299155

Epoch: 6| Step: 3
Training loss: 1.346989631652832
Validation loss: 2.1877649426460266

Epoch: 6| Step: 4
Training loss: 1.1444947719573975
Validation loss: 2.2021137873331704

Epoch: 6| Step: 5
Training loss: 1.4971725940704346
Validation loss: 2.1812517642974854

Epoch: 6| Step: 6
Training loss: 1.2196719646453857
Validation loss: 2.1961618065834045

Epoch: 6| Step: 7
Training loss: 1.6067917346954346
Validation loss: 2.191746493180593

Epoch: 6| Step: 8
Training loss: 1.9263951778411865
Validation loss: 2.207615832487742

Epoch: 6| Step: 9
Training loss: 2.07769775390625
Validation loss: 2.2038144866625466

Epoch: 6| Step: 10
Training loss: 2.0779547691345215
Validation loss: 2.198717157046

Epoch: 6| Step: 11
Training loss: 1.4744350910186768
Validation loss: 2.218456824620565

Epoch: 6| Step: 12
Training loss: 1.672813892364502
Validation loss: 2.2438960472742715

Epoch: 6| Step: 13
Training loss: 1.295719027519226
Validation loss: 2.207702616850535

Epoch: 272| Step: 0
Training loss: 1.5082097053527832
Validation loss: 2.2360432744026184

Epoch: 6| Step: 1
Training loss: 2.217587947845459
Validation loss: 2.1940574248631797

Epoch: 6| Step: 2
Training loss: 1.4594173431396484
Validation loss: 2.2057897647221885

Epoch: 6| Step: 3
Training loss: 1.6073228120803833
Validation loss: 2.217231551806132

Epoch: 6| Step: 4
Training loss: 1.4187597036361694
Validation loss: 2.2120318611462912

Epoch: 6| Step: 5
Training loss: 1.346955418586731
Validation loss: 2.182681421438853

Epoch: 6| Step: 6
Training loss: 1.2766222953796387
Validation loss: 2.206192751725515

Epoch: 6| Step: 7
Training loss: 1.71117103099823
Validation loss: 2.2059550682703652

Epoch: 6| Step: 8
Training loss: 1.6860183477401733
Validation loss: 2.2087408900260925

Epoch: 6| Step: 9
Training loss: 1.7073018550872803
Validation loss: 2.213677227497101

Epoch: 6| Step: 10
Training loss: 2.172525405883789
Validation loss: 2.2109660307566323

Epoch: 6| Step: 11
Training loss: 1.088891625404358
Validation loss: 2.1987996101379395

Epoch: 6| Step: 12
Training loss: 1.4894510507583618
Validation loss: 2.2130932211875916

Epoch: 6| Step: 13
Training loss: 1.3893057107925415
Validation loss: 2.2149244944254556

Epoch: 273| Step: 0
Training loss: 1.5493180751800537
Validation loss: 2.19071364402771

Epoch: 6| Step: 1
Training loss: 1.5802305936813354
Validation loss: 2.171823422114054

Epoch: 6| Step: 2
Training loss: 1.7531399726867676
Validation loss: 2.2038098573684692

Epoch: 6| Step: 3
Training loss: 1.8897271156311035
Validation loss: 2.1985947688420615

Epoch: 6| Step: 4
Training loss: 1.9344592094421387
Validation loss: 2.214727799097697

Epoch: 6| Step: 5
Training loss: 1.7246017456054688
Validation loss: 2.2150052388509116

Epoch: 6| Step: 6
Training loss: 1.3754922151565552
Validation loss: 2.185148298740387

Epoch: 6| Step: 7
Training loss: 1.8558168411254883
Validation loss: 2.19338850180308

Epoch: 6| Step: 8
Training loss: 1.0001416206359863
Validation loss: 2.192709724108378

Epoch: 6| Step: 9
Training loss: 1.1256814002990723
Validation loss: 2.2084638277689614

Epoch: 6| Step: 10
Training loss: 1.6091642379760742
Validation loss: 2.1913025975227356

Epoch: 6| Step: 11
Training loss: 1.627023458480835
Validation loss: 2.1767906745274863

Epoch: 6| Step: 12
Training loss: 1.7791447639465332
Validation loss: 2.173217256863912

Epoch: 6| Step: 13
Training loss: 1.686754584312439
Validation loss: 2.19049205382665

Epoch: 274| Step: 0
Training loss: 1.0863821506500244
Validation loss: 2.1852972507476807

Epoch: 6| Step: 1
Training loss: 1.360283613204956
Validation loss: 2.182710369427999

Epoch: 6| Step: 2
Training loss: 2.1655831336975098
Validation loss: 2.1802941163380942

Epoch: 6| Step: 3
Training loss: 2.354102611541748
Validation loss: 2.192232668399811

Epoch: 6| Step: 4
Training loss: 1.4082189798355103
Validation loss: 2.1958123048146567

Epoch: 6| Step: 5
Training loss: 1.754725694656372
Validation loss: 2.1777696212132773

Epoch: 6| Step: 6
Training loss: 1.6823420524597168
Validation loss: 2.2066908876101174

Epoch: 6| Step: 7
Training loss: 1.387647271156311
Validation loss: 2.2040191292762756

Epoch: 6| Step: 8
Training loss: 1.5416369438171387
Validation loss: 2.187263309955597

Epoch: 6| Step: 9
Training loss: 1.871117353439331
Validation loss: 2.180955151716868

Epoch: 6| Step: 10
Training loss: 1.422240138053894
Validation loss: 2.1761674284934998

Epoch: 6| Step: 11
Training loss: 1.25368332862854
Validation loss: 2.197757144769033

Epoch: 6| Step: 12
Training loss: 1.906137466430664
Validation loss: 2.1889010667800903

Epoch: 6| Step: 13
Training loss: 1.286912202835083
Validation loss: 2.2057835857073465

Epoch: 275| Step: 0
Training loss: 1.413001298904419
Validation loss: 2.2176781495412192

Epoch: 6| Step: 1
Training loss: 1.9033576250076294
Validation loss: 2.19258451461792

Epoch: 6| Step: 2
Training loss: 1.8249883651733398
Validation loss: 2.213956435521444

Epoch: 6| Step: 3
Training loss: 1.3479794263839722
Validation loss: 2.189235587914785

Epoch: 6| Step: 4
Training loss: 2.4113364219665527
Validation loss: 2.2234278321266174

Epoch: 6| Step: 5
Training loss: 1.7322204113006592
Validation loss: 2.225039303302765

Epoch: 6| Step: 6
Training loss: 1.7824934720993042
Validation loss: 2.200980464617411

Epoch: 6| Step: 7
Training loss: 1.2607667446136475
Validation loss: 2.201192537943522

Epoch: 6| Step: 8
Training loss: 1.2753896713256836
Validation loss: 2.203362743059794

Epoch: 6| Step: 9
Training loss: 1.928971529006958
Validation loss: 2.184729735056559

Epoch: 6| Step: 10
Training loss: 1.5207878351211548
Validation loss: 2.1779846946398416

Epoch: 6| Step: 11
Training loss: 1.7041659355163574
Validation loss: 2.150057077407837

Epoch: 6| Step: 12
Training loss: 1.2541792392730713
Validation loss: 2.159813622633616

Epoch: 6| Step: 13
Training loss: 1.091081976890564
Validation loss: 2.1230955918629966

Epoch: 276| Step: 0
Training loss: 2.5249857902526855
Validation loss: 2.1469624837239585

Epoch: 6| Step: 1
Training loss: 1.2114582061767578
Validation loss: 2.136078119277954

Epoch: 6| Step: 2
Training loss: 1.5631673336029053
Validation loss: 2.162262260913849

Epoch: 6| Step: 3
Training loss: 1.6941415071487427
Validation loss: 2.1617957949638367

Epoch: 6| Step: 4
Training loss: 1.9512622356414795
Validation loss: 2.1406530340512595

Epoch: 6| Step: 5
Training loss: 0.9930386543273926
Validation loss: 2.143738865852356

Epoch: 6| Step: 6
Training loss: 1.5278760194778442
Validation loss: 2.1554198265075684

Epoch: 6| Step: 7
Training loss: 1.9481723308563232
Validation loss: 2.1213224728902182

Epoch: 6| Step: 8
Training loss: 1.2773261070251465
Validation loss: 2.1603227059046426

Epoch: 6| Step: 9
Training loss: 2.0614285469055176
Validation loss: 2.156170209248861

Epoch: 6| Step: 10
Training loss: 1.5460700988769531
Validation loss: 2.181236684322357

Epoch: 6| Step: 11
Training loss: 1.519174337387085
Validation loss: 2.1773337523142495

Epoch: 6| Step: 12
Training loss: 1.739148497581482
Validation loss: 2.1725995540618896

Epoch: 6| Step: 13
Training loss: 1.132270336151123
Validation loss: 2.1887958645820618

Epoch: 277| Step: 0
Training loss: 1.6545058488845825
Validation loss: 2.1784262458483377

Epoch: 6| Step: 1
Training loss: 0.6110084056854248
Validation loss: 2.182249148686727

Epoch: 6| Step: 2
Training loss: 1.5803725719451904
Validation loss: 2.2021653254826865

Epoch: 6| Step: 3
Training loss: 1.4321186542510986
Validation loss: 2.1979843775431314

Epoch: 6| Step: 4
Training loss: 2.2776265144348145
Validation loss: 2.1931950449943542

Epoch: 6| Step: 5
Training loss: 1.783357858657837
Validation loss: 2.169258972009023

Epoch: 6| Step: 6
Training loss: 2.08174467086792
Validation loss: 2.1763482292493186

Epoch: 6| Step: 7
Training loss: 1.7870572805404663
Validation loss: 2.2044237852096558

Epoch: 6| Step: 8
Training loss: 1.063150405883789
Validation loss: 2.194445768992106

Epoch: 6| Step: 9
Training loss: 1.50551438331604
Validation loss: 2.202630877494812

Epoch: 6| Step: 10
Training loss: 1.5903091430664062
Validation loss: 2.198569099108378

Epoch: 6| Step: 11
Training loss: 1.5768781900405884
Validation loss: 2.225672801335653

Epoch: 6| Step: 12
Training loss: 1.6408065557479858
Validation loss: 2.1925800442695618

Epoch: 6| Step: 13
Training loss: 1.6997075080871582
Validation loss: 2.199277957280477

Epoch: 278| Step: 0
Training loss: 1.8702201843261719
Validation loss: 2.2087059219678244

Epoch: 6| Step: 1
Training loss: 1.1345932483673096
Validation loss: 2.186877429485321

Epoch: 6| Step: 2
Training loss: 2.1100621223449707
Validation loss: 2.2119109829266868

Epoch: 6| Step: 3
Training loss: 1.254050374031067
Validation loss: 2.2043092846870422

Epoch: 6| Step: 4
Training loss: 1.2993595600128174
Validation loss: 2.1919778982798257

Epoch: 6| Step: 5
Training loss: 1.1588551998138428
Validation loss: 2.1879637241363525

Epoch: 6| Step: 6
Training loss: 1.7513928413391113
Validation loss: 2.1851635376612344

Epoch: 6| Step: 7
Training loss: 1.4475302696228027
Validation loss: 2.212693671385447

Epoch: 6| Step: 8
Training loss: 2.195713758468628
Validation loss: 2.207056403160095

Epoch: 6| Step: 9
Training loss: 1.2627403736114502
Validation loss: 2.1887968381245932

Epoch: 6| Step: 10
Training loss: 1.999735951423645
Validation loss: 2.1960832277933755

Epoch: 6| Step: 11
Training loss: 1.4590229988098145
Validation loss: 2.226378162701925

Epoch: 6| Step: 12
Training loss: 1.142624855041504
Validation loss: 2.232198158899943

Epoch: 6| Step: 13
Training loss: 1.7729499340057373
Validation loss: 2.2204334338506064

Epoch: 279| Step: 0
Training loss: 1.7205328941345215
Validation loss: 2.2124025424321494

Epoch: 6| Step: 1
Training loss: 1.3220690488815308
Validation loss: 2.2233420610427856

Epoch: 6| Step: 2
Training loss: 1.9331930875778198
Validation loss: 2.2076855897903442

Epoch: 6| Step: 3
Training loss: 1.2055549621582031
Validation loss: 2.2126514315605164

Epoch: 6| Step: 4
Training loss: 1.3911728858947754
Validation loss: 2.2239946722984314

Epoch: 6| Step: 5
Training loss: 2.6126179695129395
Validation loss: 2.183294196923574

Epoch: 6| Step: 6
Training loss: 1.2300721406936646
Validation loss: 2.168603499730428

Epoch: 6| Step: 7
Training loss: 1.7630269527435303
Validation loss: 2.1895384391148887

Epoch: 6| Step: 8
Training loss: 1.0846667289733887
Validation loss: 2.1910874247550964

Epoch: 6| Step: 9
Training loss: 1.2561484575271606
Validation loss: 2.163511117299398

Epoch: 6| Step: 10
Training loss: 0.6924614906311035
Validation loss: 2.169670800367991

Epoch: 6| Step: 11
Training loss: 2.090787887573242
Validation loss: 2.1889973481496177

Epoch: 6| Step: 12
Training loss: 2.388697624206543
Validation loss: 2.1750936110814414

Epoch: 6| Step: 13
Training loss: 1.9342230558395386
Validation loss: 2.18533988793691

Epoch: 280| Step: 0
Training loss: 1.3712475299835205
Validation loss: 2.184394359588623

Epoch: 6| Step: 1
Training loss: 1.0607802867889404
Validation loss: 2.191461126009623

Epoch: 6| Step: 2
Training loss: 1.6719337701797485
Validation loss: 2.2098729411760965

Epoch: 6| Step: 3
Training loss: 1.0908679962158203
Validation loss: 2.1861033837000527

Epoch: 6| Step: 4
Training loss: 1.9800231456756592
Validation loss: 2.188629666964213

Epoch: 6| Step: 5
Training loss: 1.5147695541381836
Validation loss: 2.1671807368596396

Epoch: 6| Step: 6
Training loss: 1.7798001766204834
Validation loss: 2.198056479295095

Epoch: 6| Step: 7
Training loss: 2.189319372177124
Validation loss: 2.2056328654289246

Epoch: 6| Step: 8
Training loss: 1.239092230796814
Validation loss: 2.213700850804647

Epoch: 6| Step: 9
Training loss: 1.426093339920044
Validation loss: 2.216568191846212

Epoch: 6| Step: 10
Training loss: 1.3260663747787476
Validation loss: 2.233871579170227

Epoch: 6| Step: 11
Training loss: 1.7308028936386108
Validation loss: 2.2177522778511047

Epoch: 6| Step: 12
Training loss: 2.018071174621582
Validation loss: 2.228958865006765

Epoch: 6| Step: 13
Training loss: 1.3096253871917725
Validation loss: 2.2091508706410727

Epoch: 281| Step: 0
Training loss: 1.8172130584716797
Validation loss: 2.2120458086331687

Epoch: 6| Step: 1
Training loss: 1.6401453018188477
Validation loss: 2.2485788265864053

Epoch: 6| Step: 2
Training loss: 1.006103754043579
Validation loss: 2.223672568798065

Epoch: 6| Step: 3
Training loss: 1.9556117057800293
Validation loss: 2.212514559427897

Epoch: 6| Step: 4
Training loss: 1.3699918985366821
Validation loss: 2.2138723333676658

Epoch: 6| Step: 5
Training loss: 1.4415857791900635
Validation loss: 2.176743229230245

Epoch: 6| Step: 6
Training loss: 2.2185802459716797
Validation loss: 2.183118999004364

Epoch: 6| Step: 7
Training loss: 1.859483003616333
Validation loss: 2.1612464586893716

Epoch: 6| Step: 8
Training loss: 1.5339301824569702
Validation loss: 2.1805519660313926

Epoch: 6| Step: 9
Training loss: 1.543064832687378
Validation loss: 2.1843296686808267

Epoch: 6| Step: 10
Training loss: 1.770753264427185
Validation loss: 2.181493083635966

Epoch: 6| Step: 11
Training loss: 1.096522569656372
Validation loss: 2.1926725109418235

Epoch: 6| Step: 12
Training loss: 1.675743818283081
Validation loss: 2.206738452116648

Epoch: 6| Step: 13
Training loss: 1.332809329032898
Validation loss: 2.189132332801819

Epoch: 282| Step: 0
Training loss: 2.183950901031494
Validation loss: 2.2008387247721353

Epoch: 6| Step: 1
Training loss: 1.2243444919586182
Validation loss: 2.2030500173568726

Epoch: 6| Step: 2
Training loss: 1.5166957378387451
Validation loss: 2.2103705604871116

Epoch: 6| Step: 3
Training loss: 1.1871106624603271
Validation loss: 2.201432685057322

Epoch: 6| Step: 4
Training loss: 2.0225720405578613
Validation loss: 2.2093816995620728

Epoch: 6| Step: 5
Training loss: 1.579439640045166
Validation loss: 2.1862314144770303

Epoch: 6| Step: 6
Training loss: 0.9939229488372803
Validation loss: 2.1983200510342917

Epoch: 6| Step: 7
Training loss: 2.538379430770874
Validation loss: 2.2017831206321716

Epoch: 6| Step: 8
Training loss: 1.5409584045410156
Validation loss: 2.1712290048599243

Epoch: 6| Step: 9
Training loss: 0.9722337126731873
Validation loss: 2.203544537226359

Epoch: 6| Step: 10
Training loss: 2.7351908683776855
Validation loss: 2.185336490472158

Epoch: 6| Step: 11
Training loss: 1.1120930910110474
Validation loss: 2.196539878845215

Epoch: 6| Step: 12
Training loss: 1.4685299396514893
Validation loss: 2.2098692854245505

Epoch: 6| Step: 13
Training loss: 1.3700412511825562
Validation loss: 2.1924551129341125

Epoch: 283| Step: 0
Training loss: 1.299079418182373
Validation loss: 2.1802064180374146

Epoch: 6| Step: 1
Training loss: 1.4587467908859253
Validation loss: 2.204109231630961

Epoch: 6| Step: 2
Training loss: 1.127652883529663
Validation loss: 2.209752360979716

Epoch: 6| Step: 3
Training loss: 1.6911282539367676
Validation loss: 2.2347397406895957

Epoch: 6| Step: 4
Training loss: 1.3206795454025269
Validation loss: 2.232916514078776

Epoch: 6| Step: 5
Training loss: 1.8236238956451416
Validation loss: 2.235891858736674

Epoch: 6| Step: 6
Training loss: 1.655779242515564
Validation loss: 2.228251854578654

Epoch: 6| Step: 7
Training loss: 1.6698063611984253
Validation loss: 2.2090503374735513

Epoch: 6| Step: 8
Training loss: 1.8425745964050293
Validation loss: 2.203939358393351

Epoch: 6| Step: 9
Training loss: 1.3042101860046387
Validation loss: 2.2202236652374268

Epoch: 6| Step: 10
Training loss: 1.7368245124816895
Validation loss: 2.2129618922869363

Epoch: 6| Step: 11
Training loss: 1.2801263332366943
Validation loss: 2.204723596572876

Epoch: 6| Step: 12
Training loss: 1.2351341247558594
Validation loss: 2.2059832016626992

Epoch: 6| Step: 13
Training loss: 1.9368517398834229
Validation loss: 2.19390332698822

Epoch: 284| Step: 0
Training loss: 0.7149279117584229
Validation loss: 2.204055428504944

Epoch: 6| Step: 1
Training loss: 0.5401314496994019
Validation loss: 2.2141361236572266

Epoch: 6| Step: 2
Training loss: 1.7892260551452637
Validation loss: 2.2134729623794556

Epoch: 6| Step: 3
Training loss: 1.5723047256469727
Validation loss: 2.183113714059194

Epoch: 6| Step: 4
Training loss: 1.7882319688796997
Validation loss: 2.2151479721069336

Epoch: 6| Step: 5
Training loss: 1.4777346849441528
Validation loss: 2.2361462712287903

Epoch: 6| Step: 6
Training loss: 2.5125370025634766
Validation loss: 2.2064948081970215

Epoch: 6| Step: 7
Training loss: 1.9811550378799438
Validation loss: 2.2093899647394815

Epoch: 6| Step: 8
Training loss: 1.9197683334350586
Validation loss: 2.2077258030573526

Epoch: 6| Step: 9
Training loss: 1.3186919689178467
Validation loss: 2.1756535371144614

Epoch: 6| Step: 10
Training loss: 1.4548227787017822
Validation loss: 2.189147333304087

Epoch: 6| Step: 11
Training loss: 1.7763738632202148
Validation loss: 2.1785114208857217

Epoch: 6| Step: 12
Training loss: 1.2740728855133057
Validation loss: 2.192295253276825

Epoch: 6| Step: 13
Training loss: 1.6398639678955078
Validation loss: 2.159050722916921

Epoch: 285| Step: 0
Training loss: 1.6056115627288818
Validation loss: 2.1995595693588257

Epoch: 6| Step: 1
Training loss: 1.2107847929000854
Validation loss: 2.1948938568433127

Epoch: 6| Step: 2
Training loss: 2.1067466735839844
Validation loss: 2.1983575026194253

Epoch: 6| Step: 3
Training loss: 1.6852960586547852
Validation loss: 2.188547591368357

Epoch: 6| Step: 4
Training loss: 1.471671462059021
Validation loss: 2.210972249507904

Epoch: 6| Step: 5
Training loss: 1.9969199895858765
Validation loss: 2.2363316218058267

Epoch: 6| Step: 6
Training loss: 1.3419721126556396
Validation loss: 2.2308404246966043

Epoch: 6| Step: 7
Training loss: 1.4131877422332764
Validation loss: 2.2051007946332297

Epoch: 6| Step: 8
Training loss: 1.5311663150787354
Validation loss: 2.204728424549103

Epoch: 6| Step: 9
Training loss: 1.196354627609253
Validation loss: 2.230486214160919

Epoch: 6| Step: 10
Training loss: 1.2256531715393066
Validation loss: 2.1976643800735474

Epoch: 6| Step: 11
Training loss: 1.7305291891098022
Validation loss: 2.230923374493917

Epoch: 6| Step: 12
Training loss: 1.5696861743927002
Validation loss: 2.210072080294291

Epoch: 6| Step: 13
Training loss: 1.362762212753296
Validation loss: 2.1953993240992227

Epoch: 286| Step: 0
Training loss: 1.820383071899414
Validation loss: 2.190711756547292

Epoch: 6| Step: 1
Training loss: 1.1033376455307007
Validation loss: 2.1959537069002786

Epoch: 6| Step: 2
Training loss: 1.0486271381378174
Validation loss: 2.1772790352503457

Epoch: 6| Step: 3
Training loss: 1.1205841302871704
Validation loss: 2.1714362303415933

Epoch: 6| Step: 4
Training loss: 2.3702287673950195
Validation loss: 2.2020289301872253

Epoch: 6| Step: 5
Training loss: 0.8781062364578247
Validation loss: 2.2060292760531106

Epoch: 6| Step: 6
Training loss: 1.6136891841888428
Validation loss: 2.197171926498413

Epoch: 6| Step: 7
Training loss: 1.2681306600570679
Validation loss: 2.187819163004557

Epoch: 6| Step: 8
Training loss: 1.7969847917556763
Validation loss: 2.1883358359336853

Epoch: 6| Step: 9
Training loss: 2.2222509384155273
Validation loss: 2.186486462752024

Epoch: 6| Step: 10
Training loss: 1.7219187021255493
Validation loss: 2.2005481123924255

Epoch: 6| Step: 11
Training loss: 1.8753187656402588
Validation loss: 2.1994587580362954

Epoch: 6| Step: 12
Training loss: 1.3994461297988892
Validation loss: 2.187274694442749

Epoch: 6| Step: 13
Training loss: 1.5403029918670654
Validation loss: 2.1869792540868125

Epoch: 287| Step: 0
Training loss: 1.1126954555511475
Validation loss: 2.191401402155558

Epoch: 6| Step: 1
Training loss: 0.7752343416213989
Validation loss: 2.1778586506843567

Epoch: 6| Step: 2
Training loss: 2.1512506008148193
Validation loss: 2.1849331061045327

Epoch: 6| Step: 3
Training loss: 1.3155572414398193
Validation loss: 2.1938014030456543

Epoch: 6| Step: 4
Training loss: 1.646371603012085
Validation loss: 2.221436699231466

Epoch: 6| Step: 5
Training loss: 1.1560862064361572
Validation loss: 2.206543425718943

Epoch: 6| Step: 6
Training loss: 1.2775689363479614
Validation loss: 2.198075850804647

Epoch: 6| Step: 7
Training loss: 1.3479893207550049
Validation loss: 2.192120393117269

Epoch: 6| Step: 8
Training loss: 2.3160977363586426
Validation loss: 2.2233638564745584

Epoch: 6| Step: 9
Training loss: 1.205014705657959
Validation loss: 2.20615816116333

Epoch: 6| Step: 10
Training loss: 2.6608753204345703
Validation loss: 2.203491687774658

Epoch: 6| Step: 11
Training loss: 1.2038097381591797
Validation loss: 2.1990902423858643

Epoch: 6| Step: 12
Training loss: 1.1676414012908936
Validation loss: 2.2074799140294394

Epoch: 6| Step: 13
Training loss: 1.821376919746399
Validation loss: 2.2020678917566934

Epoch: 288| Step: 0
Training loss: 1.3334513902664185
Validation loss: 2.19983446598053

Epoch: 6| Step: 1
Training loss: 1.57778799533844
Validation loss: 2.194062074025472

Epoch: 6| Step: 2
Training loss: 1.6223094463348389
Validation loss: 2.1838664412498474

Epoch: 6| Step: 3
Training loss: 1.8623265027999878
Validation loss: 2.151926596959432

Epoch: 6| Step: 4
Training loss: 1.1920959949493408
Validation loss: 2.158381183942159

Epoch: 6| Step: 5
Training loss: 1.8154592514038086
Validation loss: 2.134539564450582

Epoch: 6| Step: 6
Training loss: 1.8054277896881104
Validation loss: 2.1769498785336814

Epoch: 6| Step: 7
Training loss: 0.9153167605400085
Validation loss: 2.1851652463277182

Epoch: 6| Step: 8
Training loss: 1.5775724649429321
Validation loss: 2.1911651690800986

Epoch: 6| Step: 9
Training loss: 1.4932892322540283
Validation loss: 2.1828456123669944

Epoch: 6| Step: 10
Training loss: 1.3416343927383423
Validation loss: 2.189103364944458

Epoch: 6| Step: 11
Training loss: 2.042135000228882
Validation loss: 2.1705023646354675

Epoch: 6| Step: 12
Training loss: 1.3171741962432861
Validation loss: 2.1885356505711875

Epoch: 6| Step: 13
Training loss: 1.5033117532730103
Validation loss: 2.1857789754867554

Epoch: 289| Step: 0
Training loss: 1.3585864305496216
Validation loss: 2.1740376949310303

Epoch: 6| Step: 1
Training loss: 1.9323570728302002
Validation loss: 2.185599982738495

Epoch: 6| Step: 2
Training loss: 1.2372065782546997
Validation loss: 2.2224950591723123

Epoch: 6| Step: 3
Training loss: 1.7737078666687012
Validation loss: 2.234872897466024

Epoch: 6| Step: 4
Training loss: 1.39964759349823
Validation loss: 2.203704535961151

Epoch: 6| Step: 5
Training loss: 1.133860468864441
Validation loss: 2.2217222650845847

Epoch: 6| Step: 6
Training loss: 1.6320536136627197
Validation loss: 2.2041351000467935

Epoch: 6| Step: 7
Training loss: 1.6798551082611084
Validation loss: 2.2162572940190635

Epoch: 6| Step: 8
Training loss: 1.3531560897827148
Validation loss: 2.222347597281138

Epoch: 6| Step: 9
Training loss: 1.5860154628753662
Validation loss: 2.2276097933451333

Epoch: 6| Step: 10
Training loss: 1.1320898532867432
Validation loss: 2.2082489331563315

Epoch: 6| Step: 11
Training loss: 1.6754662990570068
Validation loss: 2.1941898266474404

Epoch: 6| Step: 12
Training loss: 1.1364178657531738
Validation loss: 2.2045411268870034

Epoch: 6| Step: 13
Training loss: 1.8513309955596924
Validation loss: 2.216935078303019

Epoch: 290| Step: 0
Training loss: 1.1306910514831543
Validation loss: 2.1760745644569397

Epoch: 6| Step: 1
Training loss: 2.4860010147094727
Validation loss: 2.205410599708557

Epoch: 6| Step: 2
Training loss: 1.253763198852539
Validation loss: 2.188203990459442

Epoch: 6| Step: 3
Training loss: 1.2109601497650146
Validation loss: 2.229137599468231

Epoch: 6| Step: 4
Training loss: 1.1843693256378174
Validation loss: 2.2025815645853677

Epoch: 6| Step: 5
Training loss: 1.4591457843780518
Validation loss: 2.2283719579378762

Epoch: 6| Step: 6
Training loss: 1.7445491552352905
Validation loss: 2.216877281665802

Epoch: 6| Step: 7
Training loss: 1.504899501800537
Validation loss: 2.223288814226786

Epoch: 6| Step: 8
Training loss: 1.1186223030090332
Validation loss: 2.2022390564282737

Epoch: 6| Step: 9
Training loss: 2.149519443511963
Validation loss: 2.242327650388082

Epoch: 6| Step: 10
Training loss: 1.5859019756317139
Validation loss: 2.231574018796285

Epoch: 6| Step: 11
Training loss: 1.5477631092071533
Validation loss: 2.2049469550450644

Epoch: 6| Step: 12
Training loss: 0.994175910949707
Validation loss: 2.1992239952087402

Epoch: 6| Step: 13
Training loss: 1.7960907220840454
Validation loss: 2.1943689982096353

Epoch: 291| Step: 0
Training loss: 1.1428431272506714
Validation loss: 2.2327392299969993

Epoch: 6| Step: 1
Training loss: 1.5232487916946411
Validation loss: 2.2028620640436807

Epoch: 6| Step: 2
Training loss: 2.283094882965088
Validation loss: 2.191843112309774

Epoch: 6| Step: 3
Training loss: 1.1166452169418335
Validation loss: 2.194957137107849

Epoch: 6| Step: 4
Training loss: 1.1338037252426147
Validation loss: 2.156185428301493

Epoch: 6| Step: 5
Training loss: 1.8957704305648804
Validation loss: 2.1753390630086265

Epoch: 6| Step: 6
Training loss: 0.8605085015296936
Validation loss: 2.210483491420746

Epoch: 6| Step: 7
Training loss: 1.7292799949645996
Validation loss: 2.1523279349009194

Epoch: 6| Step: 8
Training loss: 1.706755518913269
Validation loss: 2.208724796772003

Epoch: 6| Step: 9
Training loss: 0.8383128643035889
Validation loss: 2.1799100438753762

Epoch: 6| Step: 10
Training loss: 2.1211512088775635
Validation loss: 2.1730085015296936

Epoch: 6| Step: 11
Training loss: 1.691180944442749
Validation loss: 2.170152425765991

Epoch: 6| Step: 12
Training loss: 1.5618410110473633
Validation loss: 2.19805254538854

Epoch: 6| Step: 13
Training loss: 1.6331781148910522
Validation loss: 2.1756374835968018

Epoch: 292| Step: 0
Training loss: 1.4161412715911865
Validation loss: 2.187141398588816

Epoch: 6| Step: 1
Training loss: 2.1993021965026855
Validation loss: 2.196566343307495

Epoch: 6| Step: 2
Training loss: 1.6802928447723389
Validation loss: 2.2182350556055703

Epoch: 6| Step: 3
Training loss: 1.851847767829895
Validation loss: 2.2225860555966697

Epoch: 6| Step: 4
Training loss: 0.920187771320343
Validation loss: 2.2002238631248474

Epoch: 6| Step: 5
Training loss: 1.80158531665802
Validation loss: 2.2056817015012107

Epoch: 6| Step: 6
Training loss: 1.6610182523727417
Validation loss: 2.2026723623275757

Epoch: 6| Step: 7
Training loss: 1.6127523183822632
Validation loss: 2.210912764072418

Epoch: 6| Step: 8
Training loss: 1.2543776035308838
Validation loss: 2.2194429437319436

Epoch: 6| Step: 9
Training loss: 1.661481261253357
Validation loss: 2.218304475148519

Epoch: 6| Step: 10
Training loss: 1.6245603561401367
Validation loss: 2.204274276892344

Epoch: 6| Step: 11
Training loss: 1.4861268997192383
Validation loss: 2.2061468760172525

Epoch: 6| Step: 12
Training loss: 0.916792631149292
Validation loss: 2.2299421230951944

Epoch: 6| Step: 13
Training loss: 1.3348150253295898
Validation loss: 2.223004857699076

Epoch: 293| Step: 0
Training loss: 1.116729736328125
Validation loss: 2.17939160267512

Epoch: 6| Step: 1
Training loss: 1.4728024005889893
Validation loss: 2.22476989030838

Epoch: 6| Step: 2
Training loss: 1.0179989337921143
Validation loss: 2.1917958855628967

Epoch: 6| Step: 3
Training loss: 1.4740691184997559
Validation loss: 2.1938237150510154

Epoch: 6| Step: 4
Training loss: 0.8803179860115051
Validation loss: 2.1825427214304605

Epoch: 6| Step: 5
Training loss: 1.1237409114837646
Validation loss: 2.1573148568471274

Epoch: 6| Step: 6
Training loss: 1.6947956085205078
Validation loss: 2.19170214732488

Epoch: 6| Step: 7
Training loss: 1.7463858127593994
Validation loss: 2.2084999879201255

Epoch: 6| Step: 8
Training loss: 1.4052989482879639
Validation loss: 2.2150112986564636

Epoch: 6| Step: 9
Training loss: 2.1579389572143555
Validation loss: 2.2085012197494507

Epoch: 6| Step: 10
Training loss: 1.6730568408966064
Validation loss: 2.240210751692454

Epoch: 6| Step: 11
Training loss: 2.369905948638916
Validation loss: 2.241108556588491

Epoch: 6| Step: 12
Training loss: 2.2008116245269775
Validation loss: 2.24163681268692

Epoch: 6| Step: 13
Training loss: 0.7918632626533508
Validation loss: 2.233274777730306

Epoch: 294| Step: 0
Training loss: 1.0833724737167358
Validation loss: 2.2068081299463906

Epoch: 6| Step: 1
Training loss: 1.2904596328735352
Validation loss: 2.24359397093455

Epoch: 6| Step: 2
Training loss: 1.2302610874176025
Validation loss: 2.2129119237264

Epoch: 6| Step: 3
Training loss: 0.940402626991272
Validation loss: 2.1912622650464377

Epoch: 6| Step: 4
Training loss: 2.0484683513641357
Validation loss: 2.1969030499458313

Epoch: 6| Step: 5
Training loss: 1.6214306354522705
Validation loss: 2.2020483215649924

Epoch: 6| Step: 6
Training loss: 1.0204213857650757
Validation loss: 2.202972133954366

Epoch: 6| Step: 7
Training loss: 1.015637993812561
Validation loss: 2.192749241987864

Epoch: 6| Step: 8
Training loss: 1.5306636095046997
Validation loss: 2.211126168568929

Epoch: 6| Step: 9
Training loss: 2.0063323974609375
Validation loss: 2.1679960091908774

Epoch: 6| Step: 10
Training loss: 1.9738609790802002
Validation loss: 2.1870357592900596

Epoch: 6| Step: 11
Training loss: 1.0984628200531006
Validation loss: 2.2196706533432007

Epoch: 6| Step: 12
Training loss: 0.8822973966598511
Validation loss: 2.1906943718592324

Epoch: 6| Step: 13
Training loss: 3.135982036590576
Validation loss: 2.2049116293589273

Epoch: 295| Step: 0
Training loss: 0.8260641098022461
Validation loss: 2.1923597852389016

Epoch: 6| Step: 1
Training loss: 0.9719147086143494
Validation loss: 2.1995307008425393

Epoch: 6| Step: 2
Training loss: 1.3003294467926025
Validation loss: 2.1951792240142822

Epoch: 6| Step: 3
Training loss: 1.9506198167800903
Validation loss: 2.206845243771871

Epoch: 6| Step: 4
Training loss: 1.6124069690704346
Validation loss: 2.224501887957255

Epoch: 6| Step: 5
Training loss: 1.3738112449645996
Validation loss: 2.1930055618286133

Epoch: 6| Step: 6
Training loss: 1.5743534564971924
Validation loss: 2.2203026612599692

Epoch: 6| Step: 7
Training loss: 0.8650740385055542
Validation loss: 2.226634442806244

Epoch: 6| Step: 8
Training loss: 1.895634651184082
Validation loss: 2.209888676802317

Epoch: 6| Step: 9
Training loss: 1.4960178136825562
Validation loss: 2.194136639436086

Epoch: 6| Step: 10
Training loss: 2.268911361694336
Validation loss: 2.2008320887883506

Epoch: 6| Step: 11
Training loss: 1.4293866157531738
Validation loss: 2.213494519392649

Epoch: 6| Step: 12
Training loss: 1.8552547693252563
Validation loss: 2.245967427889506

Epoch: 6| Step: 13
Training loss: 1.5736589431762695
Validation loss: 2.219560464223226

Epoch: 296| Step: 0
Training loss: 1.9364533424377441
Validation loss: 2.214913268884023

Epoch: 6| Step: 1
Training loss: 1.913641333580017
Validation loss: 2.252522428830465

Epoch: 6| Step: 2
Training loss: 1.7943364381790161
Validation loss: 2.243833899497986

Epoch: 6| Step: 3
Training loss: 1.2253773212432861
Validation loss: 2.218836267789205

Epoch: 6| Step: 4
Training loss: 1.3449335098266602
Validation loss: 2.229415694872538

Epoch: 6| Step: 5
Training loss: 1.8930262327194214
Validation loss: 2.2093295454978943

Epoch: 6| Step: 6
Training loss: 1.521702766418457
Validation loss: 2.2074763576189675

Epoch: 6| Step: 7
Training loss: 1.6027603149414062
Validation loss: 2.208539068698883

Epoch: 6| Step: 8
Training loss: 0.8688639998435974
Validation loss: 2.1538902521133423

Epoch: 6| Step: 9
Training loss: 1.9188506603240967
Validation loss: 2.1790358622868857

Epoch: 6| Step: 10
Training loss: 1.3246194124221802
Validation loss: 2.1777287125587463

Epoch: 6| Step: 11
Training loss: 1.2282490730285645
Validation loss: 2.1729834278424582

Epoch: 6| Step: 12
Training loss: 1.4741244316101074
Validation loss: 2.19974817832311

Epoch: 6| Step: 13
Training loss: 1.3229871988296509
Validation loss: 2.2261726458867392

Epoch: 297| Step: 0
Training loss: 2.17995023727417
Validation loss: 2.20783797899882

Epoch: 6| Step: 1
Training loss: 1.6732800006866455
Validation loss: 2.227929631868998

Epoch: 6| Step: 2
Training loss: 1.0484018325805664
Validation loss: 2.218590199947357

Epoch: 6| Step: 3
Training loss: 0.7724227905273438
Validation loss: 2.2351100842158

Epoch: 6| Step: 4
Training loss: 1.0704638957977295
Validation loss: 2.2656746904055276

Epoch: 6| Step: 5
Training loss: 2.4709408283233643
Validation loss: 2.248897592226664

Epoch: 6| Step: 6
Training loss: 1.2114040851593018
Validation loss: 2.2217808961868286

Epoch: 6| Step: 7
Training loss: 1.5015583038330078
Validation loss: 2.232167402903239

Epoch: 6| Step: 8
Training loss: 1.960991382598877
Validation loss: 2.223381817340851

Epoch: 6| Step: 9
Training loss: 1.3978939056396484
Validation loss: 2.237034559249878

Epoch: 6| Step: 10
Training loss: 1.2577321529388428
Validation loss: 2.198825200398763

Epoch: 6| Step: 11
Training loss: 1.0850653648376465
Validation loss: 2.1937324603398642

Epoch: 6| Step: 12
Training loss: 1.4648640155792236
Validation loss: 2.173758327960968

Epoch: 6| Step: 13
Training loss: 1.1184720993041992
Validation loss: 2.2059674064318338

Epoch: 298| Step: 0
Training loss: 1.3835827112197876
Validation loss: 2.1801796555519104

Epoch: 6| Step: 1
Training loss: 1.4968345165252686
Validation loss: 2.179880460103353

Epoch: 6| Step: 2
Training loss: 1.177214503288269
Validation loss: 2.1447038650512695

Epoch: 6| Step: 3
Training loss: 1.6657925844192505
Validation loss: 2.189699113368988

Epoch: 6| Step: 4
Training loss: 1.6514784097671509
Validation loss: 2.191142757733663

Epoch: 6| Step: 5
Training loss: 1.3496623039245605
Validation loss: 2.1469982465108237

Epoch: 6| Step: 6
Training loss: 1.3104734420776367
Validation loss: 2.165637791156769

Epoch: 6| Step: 7
Training loss: 1.7736948728561401
Validation loss: 2.20921782652537

Epoch: 6| Step: 8
Training loss: 1.4223167896270752
Validation loss: 2.1850145856539407

Epoch: 6| Step: 9
Training loss: 1.323359489440918
Validation loss: 2.1884981592496238

Epoch: 6| Step: 10
Training loss: 1.7980817556381226
Validation loss: 2.184065798918406

Epoch: 6| Step: 11
Training loss: 1.5344927310943604
Validation loss: 2.2016324400901794

Epoch: 6| Step: 12
Training loss: 2.024134397506714
Validation loss: 2.222917298475901

Epoch: 6| Step: 13
Training loss: 1.637056827545166
Validation loss: 2.2393019596735635

Epoch: 299| Step: 0
Training loss: 1.9766956567764282
Validation loss: 2.21891196568807

Epoch: 6| Step: 1
Training loss: 1.6793649196624756
Validation loss: 2.2031018137931824

Epoch: 6| Step: 2
Training loss: 1.5217461585998535
Validation loss: 2.2050843437512717

Epoch: 6| Step: 3
Training loss: 1.7561826705932617
Validation loss: 2.2127938667933145

Epoch: 6| Step: 4
Training loss: 1.745793104171753
Validation loss: 2.2037041584650674

Epoch: 6| Step: 5
Training loss: 1.0647810697555542
Validation loss: 2.2149649063746133

Epoch: 6| Step: 6
Training loss: 1.4173593521118164
Validation loss: 2.2188482085863748

Epoch: 6| Step: 7
Training loss: 1.3808958530426025
Validation loss: 2.2143337527910867

Epoch: 6| Step: 8
Training loss: 1.2265501022338867
Validation loss: 2.2240889271100364

Epoch: 6| Step: 9
Training loss: 1.6428847312927246
Validation loss: 2.2136780818303428

Epoch: 6| Step: 10
Training loss: 1.3332628011703491
Validation loss: 2.1979124943415322

Epoch: 6| Step: 11
Training loss: 1.464104413986206
Validation loss: 2.2008484999338784

Epoch: 6| Step: 12
Training loss: 1.1459920406341553
Validation loss: 2.1785301764806113

Epoch: 6| Step: 13
Training loss: 1.9934381246566772
Validation loss: 2.1603601574897766

Epoch: 300| Step: 0
Training loss: 1.5536985397338867
Validation loss: 2.207078993320465

Epoch: 6| Step: 1
Training loss: 1.2176134586334229
Validation loss: 2.1743770837783813

Epoch: 6| Step: 2
Training loss: 1.7546974420547485
Validation loss: 2.1863138675689697

Epoch: 6| Step: 3
Training loss: 0.957047700881958
Validation loss: 2.190611402193705

Epoch: 6| Step: 4
Training loss: 2.2004408836364746
Validation loss: 2.1917572617530823

Epoch: 6| Step: 5
Training loss: 0.7396664023399353
Validation loss: 2.1996870239575705

Epoch: 6| Step: 6
Training loss: 1.7511751651763916
Validation loss: 2.226332108179728

Epoch: 6| Step: 7
Training loss: 0.963068962097168
Validation loss: 2.2077564795811973

Epoch: 6| Step: 8
Training loss: 1.3395026922225952
Validation loss: 2.237303455670675

Epoch: 6| Step: 9
Training loss: 1.1816507577896118
Validation loss: 2.2405922015508017

Epoch: 6| Step: 10
Training loss: 2.4795050621032715
Validation loss: 2.1992368698120117

Epoch: 6| Step: 11
Training loss: 1.1617571115493774
Validation loss: 2.223063508669535

Epoch: 6| Step: 12
Training loss: 0.8255210518836975
Validation loss: 2.2385008931159973

Epoch: 6| Step: 13
Training loss: 2.319352865219116
Validation loss: 2.206591626008352

Epoch: 301| Step: 0
Training loss: 1.9067673683166504
Validation loss: 2.1893516381581626

Epoch: 6| Step: 1
Training loss: 1.3437049388885498
Validation loss: 2.2317340970039368

Epoch: 6| Step: 2
Training loss: 1.0236608982086182
Validation loss: 2.1851513584454856

Epoch: 6| Step: 3
Training loss: 1.571204423904419
Validation loss: 2.2041120529174805

Epoch: 6| Step: 4
Training loss: 1.0935027599334717
Validation loss: 2.184429407119751

Epoch: 6| Step: 5
Training loss: 1.5435138940811157
Validation loss: 2.2044664422671

Epoch: 6| Step: 6
Training loss: 1.509358525276184
Validation loss: 2.214825987815857

Epoch: 6| Step: 7
Training loss: 1.4355965852737427
Validation loss: 2.2087406317392984

Epoch: 6| Step: 8
Training loss: 1.376197338104248
Validation loss: 2.1969476540883384

Epoch: 6| Step: 9
Training loss: 0.8424116373062134
Validation loss: 2.2098745505015054

Epoch: 6| Step: 10
Training loss: 1.2052801847457886
Validation loss: 2.1792805989583335

Epoch: 6| Step: 11
Training loss: 2.6015894412994385
Validation loss: 2.1760116616884866

Epoch: 6| Step: 12
Training loss: 0.9812861084938049
Validation loss: 2.217026114463806

Epoch: 6| Step: 13
Training loss: 1.8703309297561646
Validation loss: 2.1989808281262717

Epoch: 302| Step: 0
Training loss: 0.9510142803192139
Validation loss: 2.211689750353495

Epoch: 6| Step: 1
Training loss: 1.519394040107727
Validation loss: 2.2276609539985657

Epoch: 6| Step: 2
Training loss: 1.4639124870300293
Validation loss: 2.2371698220570884

Epoch: 6| Step: 3
Training loss: 1.8673319816589355
Validation loss: 2.228707810242971

Epoch: 6| Step: 4
Training loss: 1.0543100833892822
Validation loss: 2.240596572558085

Epoch: 6| Step: 5
Training loss: 1.4321995973587036
Validation loss: 2.196568191051483

Epoch: 6| Step: 6
Training loss: 1.6382789611816406
Validation loss: 2.2169566551844277

Epoch: 6| Step: 7
Training loss: 1.185235619544983
Validation loss: 2.1644010146458945

Epoch: 6| Step: 8
Training loss: 1.3422354459762573
Validation loss: 2.186689098676046

Epoch: 6| Step: 9
Training loss: 1.6462420225143433
Validation loss: 2.1838146448135376

Epoch: 6| Step: 10
Training loss: 1.7171964645385742
Validation loss: 2.21960578362147

Epoch: 6| Step: 11
Training loss: 1.5789058208465576
Validation loss: 2.204671402772268

Epoch: 6| Step: 12
Training loss: 1.0313630104064941
Validation loss: 2.229657789071401

Epoch: 6| Step: 13
Training loss: 1.3463146686553955
Validation loss: 2.200340727965037

Epoch: 303| Step: 0
Training loss: 1.2654962539672852
Validation loss: 2.2293986280759177

Epoch: 6| Step: 1
Training loss: 1.5515278577804565
Validation loss: 2.2104244033495584

Epoch: 6| Step: 2
Training loss: 1.2876007556915283
Validation loss: 2.235793113708496

Epoch: 6| Step: 3
Training loss: 1.588563323020935
Validation loss: 2.2016207774480185

Epoch: 6| Step: 4
Training loss: 1.5735065937042236
Validation loss: 2.2323325673739114

Epoch: 6| Step: 5
Training loss: 1.358133316040039
Validation loss: 2.1969332695007324

Epoch: 6| Step: 6
Training loss: 1.2188334465026855
Validation loss: 2.192002236843109

Epoch: 6| Step: 7
Training loss: 0.7186449766159058
Validation loss: 2.202970643838247

Epoch: 6| Step: 8
Training loss: 1.7430469989776611
Validation loss: 2.152128497759501

Epoch: 6| Step: 9
Training loss: 1.7329050302505493
Validation loss: 2.1637741923332214

Epoch: 6| Step: 10
Training loss: 1.3525277376174927
Validation loss: 2.205529808998108

Epoch: 6| Step: 11
Training loss: 1.0869805812835693
Validation loss: 2.1902185678482056

Epoch: 6| Step: 12
Training loss: 1.7058025598526
Validation loss: 2.207857052485148

Epoch: 6| Step: 13
Training loss: 1.760194182395935
Validation loss: 2.2215316692988076

Epoch: 304| Step: 0
Training loss: 1.03749418258667
Validation loss: 2.2302364110946655

Epoch: 6| Step: 1
Training loss: 1.3918732404708862
Validation loss: 2.2205581665039062

Epoch: 6| Step: 2
Training loss: 1.0735650062561035
Validation loss: 2.2449350357055664

Epoch: 6| Step: 3
Training loss: 1.631532907485962
Validation loss: 2.2409221728642783

Epoch: 6| Step: 4
Training loss: 0.9512541890144348
Validation loss: 2.265296975771586

Epoch: 6| Step: 5
Training loss: 1.1386783123016357
Validation loss: 2.20613694190979

Epoch: 6| Step: 6
Training loss: 1.5464696884155273
Validation loss: 2.210186719894409

Epoch: 6| Step: 7
Training loss: 1.6112786531448364
Validation loss: 2.212148745854696

Epoch: 6| Step: 8
Training loss: 1.8331632614135742
Validation loss: 2.225930114587148

Epoch: 6| Step: 9
Training loss: 1.468320369720459
Validation loss: 2.220211386680603

Epoch: 6| Step: 10
Training loss: 1.8615548610687256
Validation loss: 2.2086042165756226

Epoch: 6| Step: 11
Training loss: 1.5839989185333252
Validation loss: 2.2402828534444175

Epoch: 6| Step: 12
Training loss: 1.6181693077087402
Validation loss: 2.215941150983175

Epoch: 6| Step: 13
Training loss: 1.924333095550537
Validation loss: 2.279470980167389

Epoch: 305| Step: 0
Training loss: 1.6556470394134521
Validation loss: 2.230115056037903

Epoch: 6| Step: 1
Training loss: 1.482779860496521
Validation loss: 2.244671583175659

Epoch: 6| Step: 2
Training loss: 1.4786574840545654
Validation loss: 2.247368494669596

Epoch: 6| Step: 3
Training loss: 1.2050178050994873
Validation loss: 2.2342758576075235

Epoch: 6| Step: 4
Training loss: 2.200023889541626
Validation loss: 2.273062845071157

Epoch: 6| Step: 5
Training loss: 1.10648512840271
Validation loss: 2.2666225830713906

Epoch: 6| Step: 6
Training loss: 1.2619988918304443
Validation loss: 2.2274218797683716

Epoch: 6| Step: 7
Training loss: 1.6888389587402344
Validation loss: 2.2436219255129495

Epoch: 6| Step: 8
Training loss: 2.3507280349731445
Validation loss: 2.2261467774709067

Epoch: 6| Step: 9
Training loss: 1.186983585357666
Validation loss: 2.2249825596809387

Epoch: 6| Step: 10
Training loss: 1.5040799379348755
Validation loss: 2.2428799072901406

Epoch: 6| Step: 11
Training loss: 0.47929897904396057
Validation loss: 2.2462612787882485

Epoch: 6| Step: 12
Training loss: 1.4651926755905151
Validation loss: 2.2637045780817666

Epoch: 6| Step: 13
Training loss: 1.090247392654419
Validation loss: 2.1905232071876526

Epoch: 306| Step: 0
Training loss: 1.555937647819519
Validation loss: 2.219965875148773

Epoch: 6| Step: 1
Training loss: 2.172511577606201
Validation loss: 2.209981381893158

Epoch: 6| Step: 2
Training loss: 0.9052362442016602
Validation loss: 2.22216260433197

Epoch: 6| Step: 3
Training loss: 1.9552862644195557
Validation loss: 2.1778939962387085

Epoch: 6| Step: 4
Training loss: 0.8903197050094604
Validation loss: 2.1908467610677085

Epoch: 6| Step: 5
Training loss: 1.2094709873199463
Validation loss: 2.2015145421028137

Epoch: 6| Step: 6
Training loss: 2.129094123840332
Validation loss: 2.154883941014608

Epoch: 6| Step: 7
Training loss: 1.6461392641067505
Validation loss: 2.148681163787842

Epoch: 6| Step: 8
Training loss: 1.5798918008804321
Validation loss: 2.166152318318685

Epoch: 6| Step: 9
Training loss: 1.673088550567627
Validation loss: 2.1595645745595298

Epoch: 6| Step: 10
Training loss: 1.1407628059387207
Validation loss: 2.1652943889300027

Epoch: 6| Step: 11
Training loss: 1.2378227710723877
Validation loss: 2.1585060954093933

Epoch: 6| Step: 12
Training loss: 1.0094090700149536
Validation loss: 2.1690527399381003

Epoch: 6| Step: 13
Training loss: 0.6643392443656921
Validation loss: 2.1605986754099527

Epoch: 307| Step: 0
Training loss: 2.184288501739502
Validation loss: 2.1925703485806785

Epoch: 6| Step: 1
Training loss: 1.9250930547714233
Validation loss: 2.2075786193211875

Epoch: 6| Step: 2
Training loss: 2.751605272293091
Validation loss: 2.232213318347931

Epoch: 6| Step: 3
Training loss: 1.750616192817688
Validation loss: 2.197273075580597

Epoch: 6| Step: 4
Training loss: 1.225027322769165
Validation loss: 2.187898596127828

Epoch: 6| Step: 5
Training loss: 1.338811993598938
Validation loss: 2.165588676929474

Epoch: 6| Step: 6
Training loss: 1.0658948421478271
Validation loss: 2.2116374373435974

Epoch: 6| Step: 7
Training loss: 1.5180981159210205
Validation loss: 2.2033987442652383

Epoch: 6| Step: 8
Training loss: 1.2961702346801758
Validation loss: 2.1959522366523743

Epoch: 6| Step: 9
Training loss: 1.173750400543213
Validation loss: 2.174735407034556

Epoch: 6| Step: 10
Training loss: 0.9242184162139893
Validation loss: 2.1935799519220986

Epoch: 6| Step: 11
Training loss: 1.1948829889297485
Validation loss: 2.206359048684438

Epoch: 6| Step: 12
Training loss: 1.0834460258483887
Validation loss: 2.202716807524363

Epoch: 6| Step: 13
Training loss: 1.6722931861877441
Validation loss: 2.1828968127568564

Epoch: 308| Step: 0
Training loss: 1.6114070415496826
Validation loss: 2.200856606165568

Epoch: 6| Step: 1
Training loss: 1.4145114421844482
Validation loss: 2.1787548661231995

Epoch: 6| Step: 2
Training loss: 1.0014288425445557
Validation loss: 2.15086030960083

Epoch: 6| Step: 3
Training loss: 2.2123851776123047
Validation loss: 2.1782100598017373

Epoch: 6| Step: 4
Training loss: 1.1206718683242798
Validation loss: 2.1987671852111816

Epoch: 6| Step: 5
Training loss: 1.4515776634216309
Validation loss: 2.1895546317100525

Epoch: 6| Step: 6
Training loss: 1.243282675743103
Validation loss: 2.211108922958374

Epoch: 6| Step: 7
Training loss: 1.1901638507843018
Validation loss: 2.201512853304545

Epoch: 6| Step: 8
Training loss: 1.4846563339233398
Validation loss: 2.2032424012819924

Epoch: 6| Step: 9
Training loss: 1.7082173824310303
Validation loss: 2.196146031220754

Epoch: 6| Step: 10
Training loss: 2.7432684898376465
Validation loss: 2.192397634188334

Epoch: 6| Step: 11
Training loss: 0.8148316740989685
Validation loss: 2.2087629238764444

Epoch: 6| Step: 12
Training loss: 0.8391697406768799
Validation loss: 2.204591393470764

Epoch: 6| Step: 13
Training loss: 1.0572786331176758
Validation loss: 2.1972586711247764

Epoch: 309| Step: 0
Training loss: 0.970409095287323
Validation loss: 2.1667420466740928

Epoch: 6| Step: 1
Training loss: 1.6774563789367676
Validation loss: 2.1744359930356345

Epoch: 6| Step: 2
Training loss: 1.3807945251464844
Validation loss: 2.1926167607307434

Epoch: 6| Step: 3
Training loss: 1.6281081438064575
Validation loss: 2.1263121565183005

Epoch: 6| Step: 4
Training loss: 1.164292812347412
Validation loss: 2.1817890405654907

Epoch: 6| Step: 5
Training loss: 1.5362597703933716
Validation loss: 2.1879734992980957

Epoch: 6| Step: 6
Training loss: 1.1951521635055542
Validation loss: 2.175049821535746

Epoch: 6| Step: 7
Training loss: 1.8131186962127686
Validation loss: 2.207893411318461

Epoch: 6| Step: 8
Training loss: 1.0477319955825806
Validation loss: 2.154750645160675

Epoch: 6| Step: 9
Training loss: 1.706944227218628
Validation loss: 2.161329984664917

Epoch: 6| Step: 10
Training loss: 1.281027913093567
Validation loss: 2.154920816421509

Epoch: 6| Step: 11
Training loss: 1.3219945430755615
Validation loss: 2.188357492287954

Epoch: 6| Step: 12
Training loss: 1.2180087566375732
Validation loss: 2.197375992933909

Epoch: 6| Step: 13
Training loss: 1.5490410327911377
Validation loss: 2.193562090396881

Epoch: 310| Step: 0
Training loss: 1.1400572061538696
Validation loss: 2.1592368682225547

Epoch: 6| Step: 1
Training loss: 0.8352291584014893
Validation loss: 2.2330094973246255

Epoch: 6| Step: 2
Training loss: 1.590801477432251
Validation loss: 2.252208888530731

Epoch: 6| Step: 3
Training loss: 1.0871076583862305
Validation loss: 2.233096718788147

Epoch: 6| Step: 4
Training loss: 0.9553025960922241
Validation loss: 2.24314284324646

Epoch: 6| Step: 5
Training loss: 1.6232686042785645
Validation loss: 2.233875870704651

Epoch: 6| Step: 6
Training loss: 1.0443615913391113
Validation loss: 2.19486266374588

Epoch: 6| Step: 7
Training loss: 0.9088961482048035
Validation loss: 2.1994971434275308

Epoch: 6| Step: 8
Training loss: 1.3384758234024048
Validation loss: 2.16438364982605

Epoch: 6| Step: 9
Training loss: 1.8690261840820312
Validation loss: 2.186310569445292

Epoch: 6| Step: 10
Training loss: 1.2555586099624634
Validation loss: 2.174388368924459

Epoch: 6| Step: 11
Training loss: 1.970911979675293
Validation loss: 2.169107894102732

Epoch: 6| Step: 12
Training loss: 2.2816450595855713
Validation loss: 2.149668057759603

Epoch: 6| Step: 13
Training loss: 1.6509532928466797
Validation loss: 2.1556442777315774

Epoch: 311| Step: 0
Training loss: 1.068261981010437
Validation loss: 2.2119791309038797

Epoch: 6| Step: 1
Training loss: 1.5612125396728516
Validation loss: 2.2293795545895896

Epoch: 6| Step: 2
Training loss: 1.6106443405151367
Validation loss: 2.200932244459788

Epoch: 6| Step: 3
Training loss: 1.392349362373352
Validation loss: 2.17426335811615

Epoch: 6| Step: 4
Training loss: 0.848121166229248
Validation loss: 2.2110542257626853

Epoch: 6| Step: 5
Training loss: 1.4807554483413696
Validation loss: 2.1819785833358765

Epoch: 6| Step: 6
Training loss: 1.56692636013031
Validation loss: 2.213768720626831

Epoch: 6| Step: 7
Training loss: 1.8213509321212769
Validation loss: 2.1878541111946106

Epoch: 6| Step: 8
Training loss: 0.8607678413391113
Validation loss: 2.1617987553278604

Epoch: 6| Step: 9
Training loss: 1.3607765436172485
Validation loss: 2.2002507050832114

Epoch: 6| Step: 10
Training loss: 1.3728413581848145
Validation loss: 2.18873397509257

Epoch: 6| Step: 11
Training loss: 0.9289731979370117
Validation loss: 2.1826343536376953

Epoch: 6| Step: 12
Training loss: 1.0978761911392212
Validation loss: 2.1736426949501038

Epoch: 6| Step: 13
Training loss: 2.1984610557556152
Validation loss: 2.1445793906847634

Epoch: 312| Step: 0
Training loss: 0.707892894744873
Validation loss: 2.1737828056017556

Epoch: 6| Step: 1
Training loss: 0.7431179285049438
Validation loss: 2.1719310681025186

Epoch: 6| Step: 2
Training loss: 1.9231133460998535
Validation loss: 2.1725338300069175

Epoch: 6| Step: 3
Training loss: 1.7915751934051514
Validation loss: 2.2200902303059897

Epoch: 6| Step: 4
Training loss: 1.2653512954711914
Validation loss: 2.201139767964681

Epoch: 6| Step: 5
Training loss: 0.9959142804145813
Validation loss: 2.22499942779541

Epoch: 6| Step: 6
Training loss: 1.0727640390396118
Validation loss: 2.258452316125234

Epoch: 6| Step: 7
Training loss: 1.2829391956329346
Validation loss: 2.219587484995524

Epoch: 6| Step: 8
Training loss: 2.1308841705322266
Validation loss: 2.2320180336634317

Epoch: 6| Step: 9
Training loss: 2.0121138095855713
Validation loss: 2.216423829396566

Epoch: 6| Step: 10
Training loss: 0.992504894733429
Validation loss: 2.2143585085868835

Epoch: 6| Step: 11
Training loss: 1.671651840209961
Validation loss: 2.1934146682421365

Epoch: 6| Step: 12
Training loss: 1.732269048690796
Validation loss: 2.2090074022610984

Epoch: 6| Step: 13
Training loss: 1.2676172256469727
Validation loss: 2.164294501145681

Epoch: 313| Step: 0
Training loss: 1.1884053945541382
Validation loss: 2.173788587252299

Epoch: 6| Step: 1
Training loss: 0.7158051133155823
Validation loss: 2.1704712311426797

Epoch: 6| Step: 2
Training loss: 1.8926355838775635
Validation loss: 2.2080628275871277

Epoch: 6| Step: 3
Training loss: 1.651427984237671
Validation loss: 2.172367791334788

Epoch: 6| Step: 4
Training loss: 1.750171184539795
Validation loss: 2.1961658199628196

Epoch: 6| Step: 5
Training loss: 1.3070167303085327
Validation loss: 2.2016984621683755

Epoch: 6| Step: 6
Training loss: 1.3555294275283813
Validation loss: 2.2141672174135842

Epoch: 6| Step: 7
Training loss: 1.903097152709961
Validation loss: 2.148071308930715

Epoch: 6| Step: 8
Training loss: 0.5960431694984436
Validation loss: 2.1841190457344055

Epoch: 6| Step: 9
Training loss: 1.147666096687317
Validation loss: 2.1952681144078574

Epoch: 6| Step: 10
Training loss: 1.751866340637207
Validation loss: 2.1567241152127585

Epoch: 6| Step: 11
Training loss: 0.938292920589447
Validation loss: 2.1240894397099814

Epoch: 6| Step: 12
Training loss: 1.9890820980072021
Validation loss: 2.146324396133423

Epoch: 6| Step: 13
Training loss: 1.4098470211029053
Validation loss: 2.1242241064707437

Epoch: 314| Step: 0
Training loss: 1.2941017150878906
Validation loss: 2.101535419623057

Epoch: 6| Step: 1
Training loss: 0.9948322772979736
Validation loss: 2.1429209113121033

Epoch: 6| Step: 2
Training loss: 0.7460180521011353
Validation loss: 2.202628751595815

Epoch: 6| Step: 3
Training loss: 0.9844807386398315
Validation loss: 2.2029296358426413

Epoch: 6| Step: 4
Training loss: 1.7664132118225098
Validation loss: 2.2121147910753884

Epoch: 6| Step: 5
Training loss: 1.529514193534851
Validation loss: 2.220126827557882

Epoch: 6| Step: 6
Training loss: 1.883241057395935
Validation loss: 2.2282678882280984

Epoch: 6| Step: 7
Training loss: 0.898378849029541
Validation loss: 2.2059681018193564

Epoch: 6| Step: 8
Training loss: 1.1534618139266968
Validation loss: 2.20329886674881

Epoch: 6| Step: 9
Training loss: 1.2248713970184326
Validation loss: 2.217317541440328

Epoch: 6| Step: 10
Training loss: 0.8806518912315369
Validation loss: 2.2200103600819907

Epoch: 6| Step: 11
Training loss: 2.589892864227295
Validation loss: 2.22826353708903

Epoch: 6| Step: 12
Training loss: 1.5518712997436523
Validation loss: 2.2157774766286216

Epoch: 6| Step: 13
Training loss: 1.2676218748092651
Validation loss: 2.2109193205833435

Epoch: 315| Step: 0
Training loss: 1.056916356086731
Validation loss: 2.1727432012557983

Epoch: 6| Step: 1
Training loss: 1.529371738433838
Validation loss: 2.1960710287094116

Epoch: 6| Step: 2
Training loss: 0.8519130349159241
Validation loss: 2.186412791411082

Epoch: 6| Step: 3
Training loss: 1.4615192413330078
Validation loss: 2.187340517838796

Epoch: 6| Step: 4
Training loss: 1.3680965900421143
Validation loss: 2.224469780921936

Epoch: 6| Step: 5
Training loss: 1.352142095565796
Validation loss: 2.22594145933787

Epoch: 6| Step: 6
Training loss: 0.5971466302871704
Validation loss: 2.2402307987213135

Epoch: 6| Step: 7
Training loss: 1.2410588264465332
Validation loss: 2.2351136008898416

Epoch: 6| Step: 8
Training loss: 1.7476677894592285
Validation loss: 2.2374815742174783

Epoch: 6| Step: 9
Training loss: 1.9650851488113403
Validation loss: 2.2245301802953086

Epoch: 6| Step: 10
Training loss: 1.3942984342575073
Validation loss: 2.2194321155548096

Epoch: 6| Step: 11
Training loss: 1.5427181720733643
Validation loss: 2.225166440010071

Epoch: 6| Step: 12
Training loss: 1.51220703125
Validation loss: 2.228946248690287

Epoch: 6| Step: 13
Training loss: 1.6106462478637695
Validation loss: 2.1816328962643943

Epoch: 316| Step: 0
Training loss: 2.061633348464966
Validation loss: 2.1862502098083496

Epoch: 6| Step: 1
Training loss: 0.806650698184967
Validation loss: 2.191439390182495

Epoch: 6| Step: 2
Training loss: 1.4745934009552002
Validation loss: 2.23239399989446

Epoch: 6| Step: 3
Training loss: 1.659928798675537
Validation loss: 2.2056700785954795

Epoch: 6| Step: 4
Training loss: 1.388648271560669
Validation loss: 2.234397768974304

Epoch: 6| Step: 5
Training loss: 0.8282147645950317
Validation loss: 2.259809931119283

Epoch: 6| Step: 6
Training loss: 1.7111353874206543
Validation loss: 2.2219399015108743

Epoch: 6| Step: 7
Training loss: 0.9132072329521179
Validation loss: 2.227000633875529

Epoch: 6| Step: 8
Training loss: 1.275328516960144
Validation loss: 2.2572526931762695

Epoch: 6| Step: 9
Training loss: 1.361047625541687
Validation loss: 2.2303300301233926

Epoch: 6| Step: 10
Training loss: 1.463905930519104
Validation loss: 2.1918450593948364

Epoch: 6| Step: 11
Training loss: 1.1010050773620605
Validation loss: 2.204021414120992

Epoch: 6| Step: 12
Training loss: 1.4495265483856201
Validation loss: 2.1646321614583335

Epoch: 6| Step: 13
Training loss: 1.891516923904419
Validation loss: 2.1798541943232217

Epoch: 317| Step: 0
Training loss: 1.034775972366333
Validation loss: 2.1643378933270774

Epoch: 6| Step: 1
Training loss: 1.4503566026687622
Validation loss: 2.153498589992523

Epoch: 6| Step: 2
Training loss: 1.814159870147705
Validation loss: 2.1577953497568765

Epoch: 6| Step: 3
Training loss: 1.0969475507736206
Validation loss: 2.1330778201421103

Epoch: 6| Step: 4
Training loss: 1.320098638534546
Validation loss: 2.1816645661989846

Epoch: 6| Step: 5
Training loss: 1.6602580547332764
Validation loss: 2.182907780011495

Epoch: 6| Step: 6
Training loss: 1.9738962650299072
Validation loss: 2.1865940491358438

Epoch: 6| Step: 7
Training loss: 2.140291213989258
Validation loss: 2.166086951891581

Epoch: 6| Step: 8
Training loss: 1.1990065574645996
Validation loss: 2.188079218069712

Epoch: 6| Step: 9
Training loss: 1.4121596813201904
Validation loss: 2.1765149434407554

Epoch: 6| Step: 10
Training loss: 1.096996545791626
Validation loss: 2.172779142856598

Epoch: 6| Step: 11
Training loss: 1.533552646636963
Validation loss: 2.1893678307533264

Epoch: 6| Step: 12
Training loss: 1.4348313808441162
Validation loss: 2.2000871698061624

Epoch: 6| Step: 13
Training loss: 1.3921265602111816
Validation loss: 2.203586220741272

Epoch: 318| Step: 0
Training loss: 1.5352237224578857
Validation loss: 2.221799393494924

Epoch: 6| Step: 1
Training loss: 0.6997798681259155
Validation loss: 2.253276308377584

Epoch: 6| Step: 2
Training loss: 1.7306379079818726
Validation loss: 2.232025980949402

Epoch: 6| Step: 3
Training loss: 1.172802448272705
Validation loss: 2.2332926591237388

Epoch: 6| Step: 4
Training loss: 1.244127631187439
Validation loss: 2.2109499971071878

Epoch: 6| Step: 5
Training loss: 1.8511109352111816
Validation loss: 2.191943128903707

Epoch: 6| Step: 6
Training loss: 1.298454761505127
Validation loss: 2.2110684712727866

Epoch: 6| Step: 7
Training loss: 1.053567886352539
Validation loss: 2.200148026148478

Epoch: 6| Step: 8
Training loss: 1.6462113857269287
Validation loss: 2.1961926023165383

Epoch: 6| Step: 9
Training loss: 1.5223214626312256
Validation loss: 2.218504091103872

Epoch: 6| Step: 10
Training loss: 1.0400035381317139
Validation loss: 2.2207977771759033

Epoch: 6| Step: 11
Training loss: 0.8509002923965454
Validation loss: 2.2162868777910867

Epoch: 6| Step: 12
Training loss: 2.258403778076172
Validation loss: 2.223427732785543

Epoch: 6| Step: 13
Training loss: 1.3728848695755005
Validation loss: 2.224557956059774

Epoch: 319| Step: 0
Training loss: 1.6159430742263794
Validation loss: 2.2546955347061157

Epoch: 6| Step: 1
Training loss: 2.174853801727295
Validation loss: 2.1838735342025757

Epoch: 6| Step: 2
Training loss: 1.5979914665222168
Validation loss: 2.2289241552352905

Epoch: 6| Step: 3
Training loss: 1.67409348487854
Validation loss: 2.196930170059204

Epoch: 6| Step: 4
Training loss: 0.9699561595916748
Validation loss: 2.2076144019762673

Epoch: 6| Step: 5
Training loss: 1.306706428527832
Validation loss: 2.183173676331838

Epoch: 6| Step: 6
Training loss: 1.8658298254013062
Validation loss: 2.179269313812256

Epoch: 6| Step: 7
Training loss: 1.1312925815582275
Validation loss: 2.1325690944989524

Epoch: 6| Step: 8
Training loss: 1.1786152124404907
Validation loss: 2.1609538396199546

Epoch: 6| Step: 9
Training loss: 0.7096483707427979
Validation loss: 2.127515971660614

Epoch: 6| Step: 10
Training loss: 0.6778599619865417
Validation loss: 2.1394890546798706

Epoch: 6| Step: 11
Training loss: 1.16446053981781
Validation loss: 2.1600540479024253

Epoch: 6| Step: 12
Training loss: 1.6710593700408936
Validation loss: 2.187385062376658

Epoch: 6| Step: 13
Training loss: 1.145970106124878
Validation loss: 2.18570085366567

Epoch: 320| Step: 0
Training loss: 1.1136348247528076
Validation loss: 2.23703400293986

Epoch: 6| Step: 1
Training loss: 1.5701903104782104
Validation loss: 2.213584383328756

Epoch: 6| Step: 2
Training loss: 2.0554375648498535
Validation loss: 2.205552637577057

Epoch: 6| Step: 3
Training loss: 1.2160474061965942
Validation loss: 2.229809522628784

Epoch: 6| Step: 4
Training loss: 1.5930428504943848
Validation loss: 2.2651530504226685

Epoch: 6| Step: 5
Training loss: 1.654484748840332
Validation loss: 2.249603589375814

Epoch: 6| Step: 6
Training loss: 1.5795698165893555
Validation loss: 2.2805097699165344

Epoch: 6| Step: 7
Training loss: 1.457901954650879
Validation loss: 2.2180370887120566

Epoch: 6| Step: 8
Training loss: 0.9622706174850464
Validation loss: 2.2249766190846763

Epoch: 6| Step: 9
Training loss: 1.2372949123382568
Validation loss: 2.2383564710617065

Epoch: 6| Step: 10
Training loss: 1.4027304649353027
Validation loss: 2.202802538871765

Epoch: 6| Step: 11
Training loss: 1.320834755897522
Validation loss: 2.179144541422526

Epoch: 6| Step: 12
Training loss: 0.7015362977981567
Validation loss: 2.1916492184003196

Epoch: 6| Step: 13
Training loss: 1.1787539720535278
Validation loss: 2.1466245452562966

Epoch: 321| Step: 0
Training loss: 0.6314601898193359
Validation loss: 2.2255077362060547

Epoch: 6| Step: 1
Training loss: 1.2888675928115845
Validation loss: 2.1978289087613425

Epoch: 6| Step: 2
Training loss: 1.3390729427337646
Validation loss: 2.2107126911481223

Epoch: 6| Step: 3
Training loss: 1.5459315776824951
Validation loss: 2.1924413243929544

Epoch: 6| Step: 4
Training loss: 2.3137288093566895
Validation loss: 2.2070208191871643

Epoch: 6| Step: 5
Training loss: 1.2210538387298584
Validation loss: 2.199922482172648

Epoch: 6| Step: 6
Training loss: 1.5833998918533325
Validation loss: 2.1768147548039756

Epoch: 6| Step: 7
Training loss: 1.389416217803955
Validation loss: 2.1863842209180198

Epoch: 6| Step: 8
Training loss: 1.2023690938949585
Validation loss: 2.2032156387964883

Epoch: 6| Step: 9
Training loss: 1.8647875785827637
Validation loss: 2.1835535764694214

Epoch: 6| Step: 10
Training loss: 1.2180637121200562
Validation loss: 2.1852306922276816

Epoch: 6| Step: 11
Training loss: 0.740178108215332
Validation loss: 2.2015312115351358

Epoch: 6| Step: 12
Training loss: 1.3311283588409424
Validation loss: 2.2148719429969788

Epoch: 6| Step: 13
Training loss: 1.1823068857192993
Validation loss: 2.2213796774546304

Epoch: 322| Step: 0
Training loss: 2.0366899967193604
Validation loss: 2.2495376666386924

Epoch: 6| Step: 1
Training loss: 0.90803062915802
Validation loss: 2.2223527431488037

Epoch: 6| Step: 2
Training loss: 1.9354948997497559
Validation loss: 2.285953144232432

Epoch: 6| Step: 3
Training loss: 1.415839672088623
Validation loss: 2.215671201546987

Epoch: 6| Step: 4
Training loss: 0.8081127405166626
Validation loss: 2.1970658898353577

Epoch: 6| Step: 5
Training loss: 1.5442514419555664
Validation loss: 2.2143545945485434

Epoch: 6| Step: 6
Training loss: 1.084767460823059
Validation loss: 2.2055656909942627

Epoch: 6| Step: 7
Training loss: 1.473179578781128
Validation loss: 2.1441627144813538

Epoch: 6| Step: 8
Training loss: 1.2492380142211914
Validation loss: 2.166978041330973

Epoch: 6| Step: 9
Training loss: 0.795828640460968
Validation loss: 2.1585983832677207

Epoch: 6| Step: 10
Training loss: 1.9194395542144775
Validation loss: 2.2342677315076194

Epoch: 6| Step: 11
Training loss: 0.7646196484565735
Validation loss: 2.177883764108022

Epoch: 6| Step: 12
Training loss: 1.3359673023223877
Validation loss: 2.221227844556173

Epoch: 6| Step: 13
Training loss: 1.312016248703003
Validation loss: 2.2263636589050293

Epoch: 323| Step: 0
Training loss: 1.5523035526275635
Validation loss: 2.2657861709594727

Epoch: 6| Step: 1
Training loss: 1.6130664348602295
Validation loss: 2.256342609723409

Epoch: 6| Step: 2
Training loss: 1.7775949239730835
Validation loss: 2.258699099222819

Epoch: 6| Step: 3
Training loss: 1.5141047239303589
Validation loss: 2.232303003470103

Epoch: 6| Step: 4
Training loss: 2.2548716068267822
Validation loss: 2.2418991724650064

Epoch: 6| Step: 5
Training loss: 1.2083909511566162
Validation loss: 2.219962775707245

Epoch: 6| Step: 6
Training loss: 0.8750428557395935
Validation loss: 2.203342159589132

Epoch: 6| Step: 7
Training loss: 1.2345447540283203
Validation loss: 2.1859172582626343

Epoch: 6| Step: 8
Training loss: 1.0230321884155273
Validation loss: 2.213292181491852

Epoch: 6| Step: 9
Training loss: 1.5454139709472656
Validation loss: 2.1870686411857605

Epoch: 6| Step: 10
Training loss: 1.3788599967956543
Validation loss: 2.2035815914471946

Epoch: 6| Step: 11
Training loss: 1.9859825372695923
Validation loss: 2.2195388873418174

Epoch: 6| Step: 12
Training loss: 0.528479814529419
Validation loss: 2.2082918286323547

Epoch: 6| Step: 13
Training loss: 1.2225358486175537
Validation loss: 2.197400132815043

Epoch: 324| Step: 0
Training loss: 1.1469265222549438
Validation loss: 2.1909444332122803

Epoch: 6| Step: 1
Training loss: 0.796583354473114
Validation loss: 2.2199117143948874

Epoch: 6| Step: 2
Training loss: 1.4636468887329102
Validation loss: 2.203340152899424

Epoch: 6| Step: 3
Training loss: 0.9141272306442261
Validation loss: 2.179074684778849

Epoch: 6| Step: 4
Training loss: 1.0375268459320068
Validation loss: 2.185272514820099

Epoch: 6| Step: 5
Training loss: 1.5553624629974365
Validation loss: 2.198815027872721

Epoch: 6| Step: 6
Training loss: 1.045081377029419
Validation loss: 2.1865827242533364

Epoch: 6| Step: 7
Training loss: 1.3196570873260498
Validation loss: 2.118347426255544

Epoch: 6| Step: 8
Training loss: 2.361945867538452
Validation loss: 2.1922397216161094

Epoch: 6| Step: 9
Training loss: 1.3908836841583252
Validation loss: 2.1738306681315103

Epoch: 6| Step: 10
Training loss: 0.837039053440094
Validation loss: 2.2178695599238076

Epoch: 6| Step: 11
Training loss: 1.602790117263794
Validation loss: 2.1890999476114907

Epoch: 6| Step: 12
Training loss: 1.5008327960968018
Validation loss: 2.1922775506973267

Epoch: 6| Step: 13
Training loss: 1.5347731113433838
Validation loss: 2.2092517018318176

Epoch: 325| Step: 0
Training loss: 2.217214822769165
Validation loss: 2.224350392818451

Epoch: 6| Step: 1
Training loss: 0.7247188091278076
Validation loss: 2.204631586869558

Epoch: 6| Step: 2
Training loss: 1.0575129985809326
Validation loss: 2.190239648024241

Epoch: 6| Step: 3
Training loss: 1.0386247634887695
Validation loss: 2.187215288480123

Epoch: 6| Step: 4
Training loss: 1.1638141870498657
Validation loss: 2.155462682247162

Epoch: 6| Step: 5
Training loss: 1.4705312252044678
Validation loss: 2.2042927940686545

Epoch: 6| Step: 6
Training loss: 2.0292489528656006
Validation loss: 2.1381395061810813

Epoch: 6| Step: 7
Training loss: 1.160022497177124
Validation loss: 2.1767360170682273

Epoch: 6| Step: 8
Training loss: 1.3625128269195557
Validation loss: 2.182790299256643

Epoch: 6| Step: 9
Training loss: 1.3373684883117676
Validation loss: 2.190687894821167

Epoch: 6| Step: 10
Training loss: 1.2739529609680176
Validation loss: 2.2356884479522705

Epoch: 6| Step: 11
Training loss: 1.269895076751709
Validation loss: 2.1878469785054526

Epoch: 6| Step: 12
Training loss: 1.5259723663330078
Validation loss: 2.1849044362703958

Epoch: 6| Step: 13
Training loss: 1.3811209201812744
Validation loss: 2.21940408150355

Epoch: 326| Step: 0
Training loss: 1.0764250755310059
Validation loss: 2.2804800868034363

Epoch: 6| Step: 1
Training loss: 0.8165310025215149
Validation loss: 2.273502210776011

Epoch: 6| Step: 2
Training loss: 1.4982836246490479
Validation loss: 2.2625579237937927

Epoch: 6| Step: 3
Training loss: 1.2102196216583252
Validation loss: 2.2655888001124063

Epoch: 6| Step: 4
Training loss: 1.0358418226242065
Validation loss: 2.255455414454142

Epoch: 6| Step: 5
Training loss: 0.9724753499031067
Validation loss: 2.26075271765391

Epoch: 6| Step: 6
Training loss: 1.4808852672576904
Validation loss: 2.189543863137563

Epoch: 6| Step: 7
Training loss: 2.333620548248291
Validation loss: 2.205424726009369

Epoch: 6| Step: 8
Training loss: 1.3159934282302856
Validation loss: 2.1593148509661355

Epoch: 6| Step: 9
Training loss: 1.1593319177627563
Validation loss: 2.1951952377955117

Epoch: 6| Step: 10
Training loss: 1.8814598321914673
Validation loss: 2.1473365227381387

Epoch: 6| Step: 11
Training loss: 1.3614705801010132
Validation loss: 2.18459814786911

Epoch: 6| Step: 12
Training loss: 1.4223668575286865
Validation loss: 2.1746227939923606

Epoch: 6| Step: 13
Training loss: 1.4355685710906982
Validation loss: 2.1858200828234353

Epoch: 327| Step: 0
Training loss: 0.9011930227279663
Validation loss: 2.1743331948916116

Epoch: 6| Step: 1
Training loss: 0.9705613851547241
Validation loss: 2.1824313004811606

Epoch: 6| Step: 2
Training loss: 1.156135082244873
Validation loss: 2.17550919453303

Epoch: 6| Step: 3
Training loss: 2.4597253799438477
Validation loss: 2.1725536982218423

Epoch: 6| Step: 4
Training loss: 1.0957422256469727
Validation loss: 2.177040775616964

Epoch: 6| Step: 5
Training loss: 1.660534143447876
Validation loss: 2.169813255469004

Epoch: 6| Step: 6
Training loss: 1.1240766048431396
Validation loss: 2.2167822321256003

Epoch: 6| Step: 7
Training loss: 1.3941773176193237
Validation loss: 2.261650045712789

Epoch: 6| Step: 8
Training loss: 1.5294737815856934
Validation loss: 2.254404067993164

Epoch: 6| Step: 9
Training loss: 1.1625522375106812
Validation loss: 2.2621492544809976

Epoch: 6| Step: 10
Training loss: 0.9684498310089111
Validation loss: 2.2476351658503213

Epoch: 6| Step: 11
Training loss: 1.9845590591430664
Validation loss: 2.2036585013071694

Epoch: 6| Step: 12
Training loss: 0.9832190275192261
Validation loss: 2.2160942951838174

Epoch: 6| Step: 13
Training loss: 0.9869420528411865
Validation loss: 2.173506021499634

Epoch: 328| Step: 0
Training loss: 0.7122795581817627
Validation loss: 2.1797169049580893

Epoch: 6| Step: 1
Training loss: 1.649651050567627
Validation loss: 2.167720357577006

Epoch: 6| Step: 2
Training loss: 2.220466136932373
Validation loss: 2.210262358188629

Epoch: 6| Step: 3
Training loss: 1.479730248451233
Validation loss: 2.168729245662689

Epoch: 6| Step: 4
Training loss: 1.2211092710494995
Validation loss: 2.1596720814704895

Epoch: 6| Step: 5
Training loss: 1.0298376083374023
Validation loss: 2.179179072380066

Epoch: 6| Step: 6
Training loss: 1.6818962097167969
Validation loss: 2.173129975795746

Epoch: 6| Step: 7
Training loss: 1.21596360206604
Validation loss: 2.2161019245783486

Epoch: 6| Step: 8
Training loss: 1.916735053062439
Validation loss: 2.2616266012191772

Epoch: 6| Step: 9
Training loss: 0.7318134903907776
Validation loss: 2.259741723537445

Epoch: 6| Step: 10
Training loss: 1.1594046354293823
Validation loss: 2.2308611472447715

Epoch: 6| Step: 11
Training loss: 1.698115348815918
Validation loss: 2.2348894079526267

Epoch: 6| Step: 12
Training loss: 1.1166622638702393
Validation loss: 2.2339649200439453

Epoch: 6| Step: 13
Training loss: 0.9002325534820557
Validation loss: 2.184248983860016

Epoch: 329| Step: 0
Training loss: 1.2654584646224976
Validation loss: 2.1981759071350098

Epoch: 6| Step: 1
Training loss: 2.0498600006103516
Validation loss: 2.1434653401374817

Epoch: 6| Step: 2
Training loss: 0.9686096906661987
Validation loss: 2.191992203394572

Epoch: 6| Step: 3
Training loss: 1.3086035251617432
Validation loss: 2.1865954796473184

Epoch: 6| Step: 4
Training loss: 1.4527504444122314
Validation loss: 2.185279885927836

Epoch: 6| Step: 5
Training loss: 1.0297422409057617
Validation loss: 2.173413892587026

Epoch: 6| Step: 6
Training loss: 1.3900411128997803
Validation loss: 2.2088043292363486

Epoch: 6| Step: 7
Training loss: 1.4342972040176392
Validation loss: 2.2118106484413147

Epoch: 6| Step: 8
Training loss: 0.908484160900116
Validation loss: 2.184039135773977

Epoch: 6| Step: 9
Training loss: 1.4391000270843506
Validation loss: 2.2425472736358643

Epoch: 6| Step: 10
Training loss: 1.3842251300811768
Validation loss: 2.218141953150431

Epoch: 6| Step: 11
Training loss: 0.9391706585884094
Validation loss: 2.224255839983622

Epoch: 6| Step: 12
Training loss: 1.0982069969177246
Validation loss: 2.2154675722122192

Epoch: 6| Step: 13
Training loss: 1.6504687070846558
Validation loss: 2.2058773040771484

Epoch: 330| Step: 0
Training loss: 1.0935120582580566
Validation loss: 2.18796706199646

Epoch: 6| Step: 1
Training loss: 0.6927289962768555
Validation loss: 2.2503104209899902

Epoch: 6| Step: 2
Training loss: 1.232004165649414
Validation loss: 2.218992273012797

Epoch: 6| Step: 3
Training loss: 1.2373958826065063
Validation loss: 2.259746710459391

Epoch: 6| Step: 4
Training loss: 1.3757331371307373
Validation loss: 2.263619144757589

Epoch: 6| Step: 5
Training loss: 1.599116325378418
Validation loss: 2.2640262444814048

Epoch: 6| Step: 6
Training loss: 1.8140597343444824
Validation loss: 2.22557924191157

Epoch: 6| Step: 7
Training loss: 1.0185455083847046
Validation loss: 2.255453089872996

Epoch: 6| Step: 8
Training loss: 1.129625678062439
Validation loss: 2.22223969300588

Epoch: 6| Step: 9
Training loss: 1.3429253101348877
Validation loss: 2.216636876265208

Epoch: 6| Step: 10
Training loss: 1.6840510368347168
Validation loss: 2.201804796854655

Epoch: 6| Step: 11
Training loss: 1.2159684896469116
Validation loss: 2.2270290851593018

Epoch: 6| Step: 12
Training loss: 1.0476475954055786
Validation loss: 2.2262547413508096

Epoch: 6| Step: 13
Training loss: 1.6370785236358643
Validation loss: 2.238205889860789

Epoch: 331| Step: 0
Training loss: 1.0851792097091675
Validation loss: 2.2510507106781006

Epoch: 6| Step: 1
Training loss: 1.268547534942627
Validation loss: 2.22957452138265

Epoch: 6| Step: 2
Training loss: 0.9581834077835083
Validation loss: 2.2216389179229736

Epoch: 6| Step: 3
Training loss: 0.9321567416191101
Validation loss: 2.2501120567321777

Epoch: 6| Step: 4
Training loss: 0.609211802482605
Validation loss: 2.21611217657725

Epoch: 6| Step: 5
Training loss: 1.148923635482788
Validation loss: 2.2228267987569175

Epoch: 6| Step: 6
Training loss: 2.10971736907959
Validation loss: 2.199373265107473

Epoch: 6| Step: 7
Training loss: 1.7160663604736328
Validation loss: 2.2073477307955423

Epoch: 6| Step: 8
Training loss: 0.9969024062156677
Validation loss: 2.1969640056292215

Epoch: 6| Step: 9
Training loss: 1.4214451313018799
Validation loss: 2.211060643196106

Epoch: 6| Step: 10
Training loss: 1.343165397644043
Validation loss: 2.1805092692375183

Epoch: 6| Step: 11
Training loss: 1.6946598291397095
Validation loss: 2.1955296397209167

Epoch: 6| Step: 12
Training loss: 1.1096489429473877
Validation loss: 2.1843022108078003

Epoch: 6| Step: 13
Training loss: 1.5866925716400146
Validation loss: 2.203783949216207

Epoch: 332| Step: 0
Training loss: 1.3036973476409912
Validation loss: 2.205437978108724

Epoch: 6| Step: 1
Training loss: 1.260169267654419
Validation loss: 2.1870521306991577

Epoch: 6| Step: 2
Training loss: 1.1363451480865479
Validation loss: 2.1712706287701926

Epoch: 6| Step: 3
Training loss: 1.5655126571655273
Validation loss: 2.2237337827682495

Epoch: 6| Step: 4
Training loss: 2.0624585151672363
Validation loss: 2.2058618466059365

Epoch: 6| Step: 5
Training loss: 1.0737282037734985
Validation loss: 2.190144340197245

Epoch: 6| Step: 6
Training loss: 1.5107394456863403
Validation loss: 2.155988256136576

Epoch: 6| Step: 7
Training loss: 1.7349941730499268
Validation loss: 2.1796714663505554

Epoch: 6| Step: 8
Training loss: 0.6813693642616272
Validation loss: 2.198251783847809

Epoch: 6| Step: 9
Training loss: 1.5780328512191772
Validation loss: 2.155661861101786

Epoch: 6| Step: 10
Training loss: 1.1072230339050293
Validation loss: 2.1984320680300393

Epoch: 6| Step: 11
Training loss: 0.9294463396072388
Validation loss: 2.178777833779653

Epoch: 6| Step: 12
Training loss: 0.9606320858001709
Validation loss: 2.180229345957438

Epoch: 6| Step: 13
Training loss: 1.1629544496536255
Validation loss: 2.160372773806254

Epoch: 333| Step: 0
Training loss: 1.2473678588867188
Validation loss: 2.253341476122538

Epoch: 6| Step: 1
Training loss: 1.06631600856781
Validation loss: 2.2293867270151773

Epoch: 6| Step: 2
Training loss: 1.1004843711853027
Validation loss: 2.257220149040222

Epoch: 6| Step: 3
Training loss: 0.6666598916053772
Validation loss: 2.2494746843973794

Epoch: 6| Step: 4
Training loss: 0.8443854451179504
Validation loss: 2.2482574780782065

Epoch: 6| Step: 5
Training loss: 0.9600253701210022
Validation loss: 2.229405144850413

Epoch: 6| Step: 6
Training loss: 1.3068245649337769
Validation loss: 2.2011561195055642

Epoch: 6| Step: 7
Training loss: 1.3171162605285645
Validation loss: 2.188657224178314

Epoch: 6| Step: 8
Training loss: 1.6945390701293945
Validation loss: 2.182925502459208

Epoch: 6| Step: 9
Training loss: 2.1007204055786133
Validation loss: 2.2431644797325134

Epoch: 6| Step: 10
Training loss: 1.0899662971496582
Validation loss: 2.2104782263437905

Epoch: 6| Step: 11
Training loss: 1.3461437225341797
Validation loss: 2.2070481379826865

Epoch: 6| Step: 12
Training loss: 2.0718729496002197
Validation loss: 2.1603214343388877

Epoch: 6| Step: 13
Training loss: 1.4163154363632202
Validation loss: 2.18078484137853

Epoch: 334| Step: 0
Training loss: 1.4591665267944336
Validation loss: 2.209701975186666

Epoch: 6| Step: 1
Training loss: 1.2482465505599976
Validation loss: 2.234726349512736

Epoch: 6| Step: 2
Training loss: 1.3944525718688965
Validation loss: 2.219551225503286

Epoch: 6| Step: 3
Training loss: 1.3398494720458984
Validation loss: 2.241446018218994

Epoch: 6| Step: 4
Training loss: 1.1843277215957642
Validation loss: 2.2518589893976846

Epoch: 6| Step: 5
Training loss: 1.2942702770233154
Validation loss: 2.2212408979733786

Epoch: 6| Step: 6
Training loss: 0.7256148457527161
Validation loss: 2.18488609790802

Epoch: 6| Step: 7
Training loss: 1.6312941312789917
Validation loss: 2.176271120707194

Epoch: 6| Step: 8
Training loss: 0.923078715801239
Validation loss: 2.183649003505707

Epoch: 6| Step: 9
Training loss: 1.7732505798339844
Validation loss: 2.1813108126322427

Epoch: 6| Step: 10
Training loss: 1.1803828477859497
Validation loss: 2.1729068756103516

Epoch: 6| Step: 11
Training loss: 1.3783009052276611
Validation loss: 2.1747666597366333

Epoch: 6| Step: 12
Training loss: 1.0393589735031128
Validation loss: 2.1858245730400085

Epoch: 6| Step: 13
Training loss: 1.235032081604004
Validation loss: 2.2512683669726052

Epoch: 335| Step: 0
Training loss: 2.1142308712005615
Validation loss: 2.228151182333628

Epoch: 6| Step: 1
Training loss: 1.047029972076416
Validation loss: 2.250025987625122

Epoch: 6| Step: 2
Training loss: 0.6313351392745972
Validation loss: 2.2669044733047485

Epoch: 6| Step: 3
Training loss: 1.9989955425262451
Validation loss: 2.263349791367849

Epoch: 6| Step: 4
Training loss: 1.3491239547729492
Validation loss: 2.2506678899129233

Epoch: 6| Step: 5
Training loss: 0.8968629240989685
Validation loss: 2.2494887510935464

Epoch: 6| Step: 6
Training loss: 0.8615015149116516
Validation loss: 2.2799094915390015

Epoch: 6| Step: 7
Training loss: 1.2646903991699219
Validation loss: 2.223502496878306

Epoch: 6| Step: 8
Training loss: 1.774223804473877
Validation loss: 2.1789439916610718

Epoch: 6| Step: 9
Training loss: 1.2593215703964233
Validation loss: 2.20443203051885

Epoch: 6| Step: 10
Training loss: 1.381611943244934
Validation loss: 2.1840726931889853

Epoch: 6| Step: 11
Training loss: 1.0043901205062866
Validation loss: 2.1953184008598328

Epoch: 6| Step: 12
Training loss: 0.983678936958313
Validation loss: 2.244948705037435

Epoch: 6| Step: 13
Training loss: 0.8031677603721619
Validation loss: 2.211449146270752

Epoch: 336| Step: 0
Training loss: 1.2555897235870361
Validation loss: 2.1611831188201904

Epoch: 6| Step: 1
Training loss: 1.7283272743225098
Validation loss: 2.2366672356923423

Epoch: 6| Step: 2
Training loss: 1.7802443504333496
Validation loss: 2.240215023358663

Epoch: 6| Step: 3
Training loss: 0.8160287737846375
Validation loss: 2.220582067966461

Epoch: 6| Step: 4
Training loss: 0.5555561780929565
Validation loss: 2.2534842689832053

Epoch: 6| Step: 5
Training loss: 1.586333990097046
Validation loss: 2.245647390683492

Epoch: 6| Step: 6
Training loss: 1.2855656147003174
Validation loss: 2.2462296883265176

Epoch: 6| Step: 7
Training loss: 1.374730110168457
Validation loss: 2.2684315840403237

Epoch: 6| Step: 8
Training loss: 1.0242795944213867
Validation loss: 2.252545098463694

Epoch: 6| Step: 9
Training loss: 1.489811897277832
Validation loss: 2.2126755913098655

Epoch: 6| Step: 10
Training loss: 0.9930084943771362
Validation loss: 2.2066896160443625

Epoch: 6| Step: 11
Training loss: 1.5521560907363892
Validation loss: 2.229967474937439

Epoch: 6| Step: 12
Training loss: 1.2220964431762695
Validation loss: 2.1699733336766562

Epoch: 6| Step: 13
Training loss: 1.004366397857666
Validation loss: 2.145180066426595

Epoch: 337| Step: 0
Training loss: 1.2589701414108276
Validation loss: 2.1684064070383706

Epoch: 6| Step: 1
Training loss: 1.155336856842041
Validation loss: 2.1563445329666138

Epoch: 6| Step: 2
Training loss: 0.637302577495575
Validation loss: 2.22854346036911

Epoch: 6| Step: 3
Training loss: 2.1607275009155273
Validation loss: 2.210609177748362

Epoch: 6| Step: 4
Training loss: 0.8044243454933167
Validation loss: 2.2107386787732444

Epoch: 6| Step: 5
Training loss: 1.69398832321167
Validation loss: 2.1971956690152488

Epoch: 6| Step: 6
Training loss: 2.3584978580474854
Validation loss: 2.221449911594391

Epoch: 6| Step: 7
Training loss: 1.223198413848877
Validation loss: 2.21027272939682

Epoch: 6| Step: 8
Training loss: 1.0183242559432983
Validation loss: 2.17393159866333

Epoch: 6| Step: 9
Training loss: 1.3487215042114258
Validation loss: 2.1991016467412314

Epoch: 6| Step: 10
Training loss: 0.6137911677360535
Validation loss: 2.2201050321261087

Epoch: 6| Step: 11
Training loss: 1.3041455745697021
Validation loss: 2.2119458516438804

Epoch: 6| Step: 12
Training loss: 1.1311826705932617
Validation loss: 2.199188709259033

Epoch: 6| Step: 13
Training loss: 1.265514612197876
Validation loss: 2.2266114552815757

Epoch: 338| Step: 0
Training loss: 1.1457737684249878
Validation loss: 2.2290226221084595

Epoch: 6| Step: 1
Training loss: 1.7573319673538208
Validation loss: 2.221231758594513

Epoch: 6| Step: 2
Training loss: 1.3025274276733398
Validation loss: 2.231243848800659

Epoch: 6| Step: 3
Training loss: 0.8355606198310852
Validation loss: 2.251718580722809

Epoch: 6| Step: 4
Training loss: 1.218316912651062
Validation loss: 2.2231514056523642

Epoch: 6| Step: 5
Training loss: 1.6714684963226318
Validation loss: 2.2403480609258017

Epoch: 6| Step: 6
Training loss: 1.3820991516113281
Validation loss: 2.262536406517029

Epoch: 6| Step: 7
Training loss: 0.9050865173339844
Validation loss: 2.246663967768351

Epoch: 6| Step: 8
Training loss: 0.943771481513977
Validation loss: 2.236094653606415

Epoch: 6| Step: 9
Training loss: 1.2327079772949219
Validation loss: 2.2651150226593018

Epoch: 6| Step: 10
Training loss: 1.5019950866699219
Validation loss: 2.242055296897888

Epoch: 6| Step: 11
Training loss: 1.160913109779358
Validation loss: 2.1856111685434976

Epoch: 6| Step: 12
Training loss: 1.3796119689941406
Validation loss: 2.1937036911646524

Epoch: 6| Step: 13
Training loss: 1.430445909500122
Validation loss: 2.212894002596537

Epoch: 339| Step: 0
Training loss: 1.2550926208496094
Validation loss: 2.188384751478831

Epoch: 6| Step: 1
Training loss: 1.972820520401001
Validation loss: 2.1755395929018655

Epoch: 6| Step: 2
Training loss: 1.657941460609436
Validation loss: 2.187216301759084

Epoch: 6| Step: 3
Training loss: 0.8181605935096741
Validation loss: 2.2047037879625955

Epoch: 6| Step: 4
Training loss: 0.8662847876548767
Validation loss: 2.2022929588953652

Epoch: 6| Step: 5
Training loss: 1.1024210453033447
Validation loss: 2.2201951146125793

Epoch: 6| Step: 6
Training loss: 1.750447154045105
Validation loss: 2.2295228441556296

Epoch: 6| Step: 7
Training loss: 0.8447930812835693
Validation loss: 2.211566964785258

Epoch: 6| Step: 8
Training loss: 1.032301902770996
Validation loss: 2.2201470335324607

Epoch: 6| Step: 9
Training loss: 1.266204833984375
Validation loss: 2.1902722318967185

Epoch: 6| Step: 10
Training loss: 1.6231234073638916
Validation loss: 2.201740006605784

Epoch: 6| Step: 11
Training loss: 0.8200103044509888
Validation loss: 2.2323903838793435

Epoch: 6| Step: 12
Training loss: 1.0252560377120972
Validation loss: 2.2267253597577414

Epoch: 6| Step: 13
Training loss: 0.8818429112434387
Validation loss: 2.2285253206888833

Epoch: 340| Step: 0
Training loss: 1.5593047142028809
Validation loss: 2.222261965274811

Epoch: 6| Step: 1
Training loss: 1.652408480644226
Validation loss: 2.25275452931722

Epoch: 6| Step: 2
Training loss: 1.5046206712722778
Validation loss: 2.236909826596578

Epoch: 6| Step: 3
Training loss: 1.0943546295166016
Validation loss: 2.2267465591430664

Epoch: 6| Step: 4
Training loss: 1.8221750259399414
Validation loss: 2.215953012307485

Epoch: 6| Step: 5
Training loss: 1.7749103307724
Validation loss: 2.2003069718678794

Epoch: 6| Step: 6
Training loss: 0.9888832569122314
Validation loss: 2.192193627357483

Epoch: 6| Step: 7
Training loss: 0.5253874659538269
Validation loss: 2.170801818370819

Epoch: 6| Step: 8
Training loss: 1.0066636800765991
Validation loss: 2.2018646200497947

Epoch: 6| Step: 9
Training loss: 1.1712925434112549
Validation loss: 2.1935742497444153

Epoch: 6| Step: 10
Training loss: 0.9486910700798035
Validation loss: 2.191552738348643

Epoch: 6| Step: 11
Training loss: 0.8654866218566895
Validation loss: 2.2059749364852905

Epoch: 6| Step: 12
Training loss: 0.9802778959274292
Validation loss: 2.1848870515823364

Epoch: 6| Step: 13
Training loss: 1.024433970451355
Validation loss: 2.1852397123972573

Epoch: 341| Step: 0
Training loss: 1.3282028436660767
Validation loss: 2.1615550915400186

Epoch: 6| Step: 1
Training loss: 0.504622220993042
Validation loss: 2.184533953666687

Epoch: 6| Step: 2
Training loss: 1.0577914714813232
Validation loss: 2.1918214559555054

Epoch: 6| Step: 3
Training loss: 1.7610044479370117
Validation loss: 2.1941996415456138

Epoch: 6| Step: 4
Training loss: 1.143978476524353
Validation loss: 2.220149576663971

Epoch: 6| Step: 5
Training loss: 1.4584895372390747
Validation loss: 2.2216174403826394

Epoch: 6| Step: 6
Training loss: 1.233458399772644
Validation loss: 2.2125319639841714

Epoch: 6| Step: 7
Training loss: 1.237739086151123
Validation loss: 2.2094805439313254

Epoch: 6| Step: 8
Training loss: 1.260754108428955
Validation loss: 2.220575988292694

Epoch: 6| Step: 9
Training loss: 1.1968655586242676
Validation loss: 2.2802526553471885

Epoch: 6| Step: 10
Training loss: 1.3372833728790283
Validation loss: 2.2529884576797485

Epoch: 6| Step: 11
Training loss: 1.349381446838379
Validation loss: 2.204214851061503

Epoch: 6| Step: 12
Training loss: 1.0076590776443481
Validation loss: 2.2169255216916404

Epoch: 6| Step: 13
Training loss: 1.5419045686721802
Validation loss: 2.2658193508783975

Epoch: 342| Step: 0
Training loss: 0.9103103876113892
Validation loss: 2.2061848243077598

Epoch: 6| Step: 1
Training loss: 1.0535900592803955
Validation loss: 2.20378307501475

Epoch: 6| Step: 2
Training loss: 0.8812757134437561
Validation loss: 2.2379003763198853

Epoch: 6| Step: 3
Training loss: 0.7473569512367249
Validation loss: 2.2281741897265115

Epoch: 6| Step: 4
Training loss: 1.4338898658752441
Validation loss: 2.215700348218282

Epoch: 6| Step: 5
Training loss: 0.8614883422851562
Validation loss: 2.1959572633107505

Epoch: 6| Step: 6
Training loss: 1.558863639831543
Validation loss: 2.180627703666687

Epoch: 6| Step: 7
Training loss: 1.3253929615020752
Validation loss: 2.223597844441732

Epoch: 6| Step: 8
Training loss: 1.7765285968780518
Validation loss: 2.1866928339004517

Epoch: 6| Step: 9
Training loss: 1.7239670753479004
Validation loss: 2.19631826877594

Epoch: 6| Step: 10
Training loss: 0.9104331731796265
Validation loss: 2.1853551864624023

Epoch: 6| Step: 11
Training loss: 1.9655557870864868
Validation loss: 2.221926669279734

Epoch: 6| Step: 12
Training loss: 0.6362051963806152
Validation loss: 2.206392069657644

Epoch: 6| Step: 13
Training loss: 0.7598385214805603
Validation loss: 2.1842232942581177

Epoch: 343| Step: 0
Training loss: 0.6521718502044678
Validation loss: 2.183300813039144

Epoch: 6| Step: 1
Training loss: 1.2975811958312988
Validation loss: 2.19570529460907

Epoch: 6| Step: 2
Training loss: 1.3801186084747314
Validation loss: 2.189087132612864

Epoch: 6| Step: 3
Training loss: 1.261680245399475
Validation loss: 2.218448201815287

Epoch: 6| Step: 4
Training loss: 1.7000017166137695
Validation loss: 2.1660624742507935

Epoch: 6| Step: 5
Training loss: 0.4915747046470642
Validation loss: 2.1418755650520325

Epoch: 6| Step: 6
Training loss: 1.6338555812835693
Validation loss: 2.199350039164225

Epoch: 6| Step: 7
Training loss: 1.2620495557785034
Validation loss: 2.1842724680900574

Epoch: 6| Step: 8
Training loss: 1.1475086212158203
Validation loss: 2.2053155501683555

Epoch: 6| Step: 9
Training loss: 0.6350076198577881
Validation loss: 2.17229034503301

Epoch: 6| Step: 10
Training loss: 0.607621967792511
Validation loss: 2.150281290213267

Epoch: 6| Step: 11
Training loss: 1.042842984199524
Validation loss: 2.16156005859375

Epoch: 6| Step: 12
Training loss: 1.3677012920379639
Validation loss: 2.155327240626017

Epoch: 6| Step: 13
Training loss: 2.010991096496582
Validation loss: 2.1807550191879272

Epoch: 344| Step: 0
Training loss: 1.2386915683746338
Validation loss: 2.195706864198049

Epoch: 6| Step: 1
Training loss: 1.4394813776016235
Validation loss: 2.168761452039083

Epoch: 6| Step: 2
Training loss: 1.029138207435608
Validation loss: 2.176946997642517

Epoch: 6| Step: 3
Training loss: 1.4203341007232666
Validation loss: 2.161757210890452

Epoch: 6| Step: 4
Training loss: 0.6635482311248779
Validation loss: 2.2083683808644614

Epoch: 6| Step: 5
Training loss: 1.9394768476486206
Validation loss: 2.2170982162157693

Epoch: 6| Step: 6
Training loss: 1.7976751327514648
Validation loss: 2.2373382250467935

Epoch: 6| Step: 7
Training loss: 0.6140930652618408
Validation loss: 2.265874902407328

Epoch: 6| Step: 8
Training loss: 1.08256196975708
Validation loss: 2.289589524269104

Epoch: 6| Step: 9
Training loss: 1.6541142463684082
Validation loss: 2.2936716874440513

Epoch: 6| Step: 10
Training loss: 1.2838996648788452
Validation loss: 2.2541345357894897

Epoch: 6| Step: 11
Training loss: 0.8963260650634766
Validation loss: 2.2351880073547363

Epoch: 6| Step: 12
Training loss: 1.1308822631835938
Validation loss: 2.257226506868998

Epoch: 6| Step: 13
Training loss: 0.5122568011283875
Validation loss: 2.215462565422058

Epoch: 345| Step: 0
Training loss: 1.372086763381958
Validation loss: 2.225073993206024

Epoch: 6| Step: 1
Training loss: 1.928046703338623
Validation loss: 2.1803988814353943

Epoch: 6| Step: 2
Training loss: 1.1196298599243164
Validation loss: 2.211652855078379

Epoch: 6| Step: 3
Training loss: 1.403195858001709
Validation loss: 2.211327612400055

Epoch: 6| Step: 4
Training loss: 1.2720677852630615
Validation loss: 2.2745914459228516

Epoch: 6| Step: 5
Training loss: 1.0732784271240234
Validation loss: 2.222873071829478

Epoch: 6| Step: 6
Training loss: 1.0224988460540771
Validation loss: 2.2521548867225647

Epoch: 6| Step: 7
Training loss: 1.9203791618347168
Validation loss: 2.2207552989323935

Epoch: 6| Step: 8
Training loss: 1.2753037214279175
Validation loss: 2.18893434604009

Epoch: 6| Step: 9
Training loss: 1.0015125274658203
Validation loss: 2.1763052543004355

Epoch: 6| Step: 10
Training loss: 1.0026824474334717
Validation loss: 2.1545583605766296

Epoch: 6| Step: 11
Training loss: 1.867226004600525
Validation loss: 2.2006739576657615

Epoch: 6| Step: 12
Training loss: 0.6462194919586182
Validation loss: 2.1550091902414956

Epoch: 6| Step: 13
Training loss: 0.7104471921920776
Validation loss: 2.17503430445989

Epoch: 346| Step: 0
Training loss: 1.4631257057189941
Validation loss: 2.1972126563390098

Epoch: 6| Step: 1
Training loss: 1.378593921661377
Validation loss: 2.2153822580973306

Epoch: 6| Step: 2
Training loss: 1.3406436443328857
Validation loss: 2.18394402662913

Epoch: 6| Step: 3
Training loss: 1.7191354036331177
Validation loss: 2.1915457248687744

Epoch: 6| Step: 4
Training loss: 1.5337018966674805
Validation loss: 2.165213108062744

Epoch: 6| Step: 5
Training loss: 1.0548096895217896
Validation loss: 2.143438756465912

Epoch: 6| Step: 6
Training loss: 1.0678210258483887
Validation loss: 2.1868815422058105

Epoch: 6| Step: 7
Training loss: 0.6575680375099182
Validation loss: 2.179180165131887

Epoch: 6| Step: 8
Training loss: 1.2680153846740723
Validation loss: 2.1716449658075967

Epoch: 6| Step: 9
Training loss: 1.2440824508666992
Validation loss: 2.2098214626312256

Epoch: 6| Step: 10
Training loss: 0.9307221174240112
Validation loss: 2.174294571081797

Epoch: 6| Step: 11
Training loss: 1.2802174091339111
Validation loss: 2.1891671419143677

Epoch: 6| Step: 12
Training loss: 0.8273317813873291
Validation loss: 2.1947683691978455

Epoch: 6| Step: 13
Training loss: 1.0381033420562744
Validation loss: 2.170986215273539

Epoch: 347| Step: 0
Training loss: 0.7788233757019043
Validation loss: 2.1809810400009155

Epoch: 6| Step: 1
Training loss: 1.180095911026001
Validation loss: 2.1984379490216575

Epoch: 6| Step: 2
Training loss: 0.8867605924606323
Validation loss: 2.2442878683408103

Epoch: 6| Step: 3
Training loss: 1.5122734308242798
Validation loss: 2.2447871367136636

Epoch: 6| Step: 4
Training loss: 1.4678020477294922
Validation loss: 2.267863631248474

Epoch: 6| Step: 5
Training loss: 1.5800375938415527
Validation loss: 2.2608858148256936

Epoch: 6| Step: 6
Training loss: 1.6876802444458008
Validation loss: 2.235678474108378

Epoch: 6| Step: 7
Training loss: 0.7105681896209717
Validation loss: 2.2107887665430703

Epoch: 6| Step: 8
Training loss: 0.8056733012199402
Validation loss: 2.1938976049423218

Epoch: 6| Step: 9
Training loss: 1.6240992546081543
Validation loss: 2.1279116670290628

Epoch: 6| Step: 10
Training loss: 1.0326015949249268
Validation loss: 2.125900665918986

Epoch: 6| Step: 11
Training loss: 1.7241381406784058
Validation loss: 2.1745632886886597

Epoch: 6| Step: 12
Training loss: 0.9473143815994263
Validation loss: 2.177772879600525

Epoch: 6| Step: 13
Training loss: 1.687251091003418
Validation loss: 2.206497530142466

Epoch: 348| Step: 0
Training loss: 1.186781883239746
Validation loss: 2.224423805872599

Epoch: 6| Step: 1
Training loss: 0.9814109802246094
Validation loss: 2.2196561892827353

Epoch: 6| Step: 2
Training loss: 0.8258923292160034
Validation loss: 2.2428470849990845

Epoch: 6| Step: 3
Training loss: 1.3119333982467651
Validation loss: 2.2040927012761435

Epoch: 6| Step: 4
Training loss: 1.2201683521270752
Validation loss: 2.213747719923655

Epoch: 6| Step: 5
Training loss: 1.475728988647461
Validation loss: 2.229974925518036

Epoch: 6| Step: 6
Training loss: 0.5853925943374634
Validation loss: 2.1929760376612344

Epoch: 6| Step: 7
Training loss: 1.5374339818954468
Validation loss: 2.206777115662893

Epoch: 6| Step: 8
Training loss: 0.9755584001541138
Validation loss: 2.1865934332211814

Epoch: 6| Step: 9
Training loss: 1.2840819358825684
Validation loss: 2.19536954164505

Epoch: 6| Step: 10
Training loss: 1.1533409357070923
Validation loss: 2.185819466908773

Epoch: 6| Step: 11
Training loss: 1.092045545578003
Validation loss: 2.23735241095225

Epoch: 6| Step: 12
Training loss: 1.9627771377563477
Validation loss: 2.2490965127944946

Epoch: 6| Step: 13
Training loss: 1.023370623588562
Validation loss: 2.269692361354828

Epoch: 349| Step: 0
Training loss: 1.378800392150879
Validation loss: 2.2773187160491943

Epoch: 6| Step: 1
Training loss: 1.3806928396224976
Validation loss: 2.1967670718828836

Epoch: 6| Step: 2
Training loss: 0.8639397025108337
Validation loss: 2.159577786922455

Epoch: 6| Step: 3
Training loss: 1.0916156768798828
Validation loss: 2.18877245982488

Epoch: 6| Step: 4
Training loss: 1.219756007194519
Validation loss: 2.174240986506144

Epoch: 6| Step: 5
Training loss: 1.4848523139953613
Validation loss: 2.175398826599121

Epoch: 6| Step: 6
Training loss: 1.1273161172866821
Validation loss: 2.1630478700002036

Epoch: 6| Step: 7
Training loss: 1.1313759088516235
Validation loss: 2.190480093161265

Epoch: 6| Step: 8
Training loss: 1.3806902170181274
Validation loss: 2.1784438292185464

Epoch: 6| Step: 9
Training loss: 0.6030178070068359
Validation loss: 2.2354263265927634

Epoch: 6| Step: 10
Training loss: 1.1071363687515259
Validation loss: 2.231008688608805

Epoch: 6| Step: 11
Training loss: 1.242412805557251
Validation loss: 2.236791253089905

Epoch: 6| Step: 12
Training loss: 1.7807021141052246
Validation loss: 2.271963874499003

Epoch: 6| Step: 13
Training loss: 1.1815507411956787
Validation loss: 2.284281293551127

Epoch: 350| Step: 0
Training loss: 0.77506023645401
Validation loss: 2.2881977558135986

Epoch: 6| Step: 1
Training loss: 1.129919409751892
Validation loss: 2.2243167559305825

Epoch: 6| Step: 2
Training loss: 0.8531216382980347
Validation loss: 2.2233973344167075

Epoch: 6| Step: 3
Training loss: 1.5294239521026611
Validation loss: 2.235917806625366

Epoch: 6| Step: 4
Training loss: 1.3614847660064697
Validation loss: 2.2074220180511475

Epoch: 6| Step: 5
Training loss: 0.7264143824577332
Validation loss: 2.1970474322636924

Epoch: 6| Step: 6
Training loss: 0.7256896495819092
Validation loss: 2.2365287939707437

Epoch: 6| Step: 7
Training loss: 1.684290885925293
Validation loss: 2.2033249735832214

Epoch: 6| Step: 8
Training loss: 1.3164950609207153
Validation loss: 2.2116810083389282

Epoch: 6| Step: 9
Training loss: 2.175483226776123
Validation loss: 2.230491816997528

Epoch: 6| Step: 10
Training loss: 0.8676999807357788
Validation loss: 2.277260700861613

Epoch: 6| Step: 11
Training loss: 1.0821017026901245
Validation loss: 2.2455622355143228

Epoch: 6| Step: 12
Training loss: 0.8373095393180847
Validation loss: 2.2275420824686685

Epoch: 6| Step: 13
Training loss: 1.5471000671386719
Validation loss: 2.2156050403912864

Testing loss: 1.9475423466387412
