Epoch: 1| Step: 0
Training loss: 5.800702095031738
Validation loss: 5.2978135744730634

Epoch: 6| Step: 1
Training loss: 4.8852362632751465
Validation loss: 5.296463092168172

Epoch: 6| Step: 2
Training loss: 5.627369403839111
Validation loss: 5.295095682144165

Epoch: 6| Step: 3
Training loss: 5.5134477615356445
Validation loss: 5.293771266937256

Epoch: 6| Step: 4
Training loss: 4.575047492980957
Validation loss: 5.292377392450969

Epoch: 6| Step: 5
Training loss: 4.7051615715026855
Validation loss: 5.290919303894043

Epoch: 6| Step: 6
Training loss: 5.146592140197754
Validation loss: 5.289507865905762

Epoch: 6| Step: 7
Training loss: 5.51419734954834
Validation loss: 5.288045485814412

Epoch: 6| Step: 8
Training loss: 5.112283706665039
Validation loss: 5.2865651448567705

Epoch: 6| Step: 9
Training loss: 5.285604476928711
Validation loss: 5.2850009600321455

Epoch: 6| Step: 10
Training loss: 6.040857791900635
Validation loss: 5.28337820370992

Epoch: 6| Step: 11
Training loss: 5.401500225067139
Validation loss: 5.2817362149556475

Epoch: 6| Step: 12
Training loss: 6.6864776611328125
Validation loss: 5.279961744944255

Epoch: 6| Step: 13
Training loss: 4.709997177124023
Validation loss: 5.278141736984253

Epoch: 2| Step: 0
Training loss: 5.452181816101074
Validation loss: 5.276158809661865

Epoch: 6| Step: 1
Training loss: 5.033080577850342
Validation loss: 5.27422563234965

Epoch: 6| Step: 2
Training loss: 6.637932777404785
Validation loss: 5.272125403086345

Epoch: 6| Step: 3
Training loss: 4.743988037109375
Validation loss: 5.269873221715291

Epoch: 6| Step: 4
Training loss: 3.6717381477355957
Validation loss: 5.267607768376668

Epoch: 6| Step: 5
Training loss: 5.919333457946777
Validation loss: 5.265214602152507

Epoch: 6| Step: 6
Training loss: 4.88116979598999
Validation loss: 5.262600501378377

Epoch: 6| Step: 7
Training loss: 5.510293960571289
Validation loss: 5.259901523590088

Epoch: 6| Step: 8
Training loss: 5.6269073486328125
Validation loss: 5.257113059361775

Epoch: 6| Step: 9
Training loss: 5.224991798400879
Validation loss: 5.254157304763794

Epoch: 6| Step: 10
Training loss: 5.8223443031311035
Validation loss: 5.251037955284119

Epoch: 6| Step: 11
Training loss: 5.448696136474609
Validation loss: 5.247678995132446

Epoch: 6| Step: 12
Training loss: 5.61751127243042
Validation loss: 5.244202057520549

Epoch: 6| Step: 13
Training loss: 5.028251647949219
Validation loss: 5.240619818369548

Epoch: 3| Step: 0
Training loss: 5.052008628845215
Validation loss: 5.236589272816976

Epoch: 6| Step: 1
Training loss: 4.701229095458984
Validation loss: 5.232524236043294

Epoch: 6| Step: 2
Training loss: 4.6017351150512695
Validation loss: 5.228099187215169

Epoch: 6| Step: 3
Training loss: 6.71442985534668
Validation loss: 5.223661422729492

Epoch: 6| Step: 4
Training loss: 5.512059211730957
Validation loss: 5.218614975611369

Epoch: 6| Step: 5
Training loss: 5.505022048950195
Validation loss: 5.2134872277577715

Epoch: 6| Step: 6
Training loss: 4.4681806564331055
Validation loss: 5.2078038056691485

Epoch: 6| Step: 7
Training loss: 6.515338897705078
Validation loss: 5.202053705851237

Epoch: 6| Step: 8
Training loss: 5.664443016052246
Validation loss: 5.19600526491801

Epoch: 6| Step: 9
Training loss: 5.202269554138184
Validation loss: 5.189642111460368

Epoch: 6| Step: 10
Training loss: 5.478909492492676
Validation loss: 5.182770490646362

Epoch: 6| Step: 11
Training loss: 4.791244983673096
Validation loss: 5.175567865371704

Epoch: 6| Step: 12
Training loss: 5.387810707092285
Validation loss: 5.168269793192546

Epoch: 6| Step: 13
Training loss: 4.226377010345459
Validation loss: 5.16062347094218

Epoch: 4| Step: 0
Training loss: 5.546369552612305
Validation loss: 5.152864535649617

Epoch: 6| Step: 1
Training loss: 5.763551712036133
Validation loss: 5.144643624623616

Epoch: 6| Step: 2
Training loss: 5.426257133483887
Validation loss: 5.135989189147949

Epoch: 6| Step: 3
Training loss: 4.7472920417785645
Validation loss: 5.127212921778361

Epoch: 6| Step: 4
Training loss: 4.623815536499023
Validation loss: 5.11808967590332

Epoch: 6| Step: 5
Training loss: 4.946514129638672
Validation loss: 5.108827352523804

Epoch: 6| Step: 6
Training loss: 5.870416164398193
Validation loss: 5.099491834640503

Epoch: 6| Step: 7
Training loss: 5.810415267944336
Validation loss: 5.089868704477946

Epoch: 6| Step: 8
Training loss: 4.759379863739014
Validation loss: 5.079833189646403

Epoch: 6| Step: 9
Training loss: 5.060726165771484
Validation loss: 5.069447835286458

Epoch: 6| Step: 10
Training loss: 5.010077476501465
Validation loss: 5.059115568796794

Epoch: 6| Step: 11
Training loss: 4.962298393249512
Validation loss: 5.0484393040339155

Epoch: 6| Step: 12
Training loss: 4.447397232055664
Validation loss: 5.037246743837993

Epoch: 6| Step: 13
Training loss: 5.369253635406494
Validation loss: 5.026248296101888

Epoch: 5| Step: 0
Training loss: 4.372408866882324
Validation loss: 5.015244166056315

Epoch: 6| Step: 1
Training loss: 5.003175735473633
Validation loss: 5.003870487213135

Epoch: 6| Step: 2
Training loss: 4.571217060089111
Validation loss: 4.992503643035889

Epoch: 6| Step: 3
Training loss: 5.5877556800842285
Validation loss: 4.98133659362793

Epoch: 6| Step: 4
Training loss: 3.9208483695983887
Validation loss: 4.970161120096843

Epoch: 6| Step: 5
Training loss: 4.5265607833862305
Validation loss: 4.958808660507202

Epoch: 6| Step: 6
Training loss: 4.394279956817627
Validation loss: 4.947914918263753

Epoch: 6| Step: 7
Training loss: 4.596249580383301
Validation loss: 4.936945796012878

Epoch: 6| Step: 8
Training loss: 5.596165657043457
Validation loss: 4.925993204116821

Epoch: 6| Step: 9
Training loss: 4.607051849365234
Validation loss: 4.9150863488515215

Epoch: 6| Step: 10
Training loss: 6.257946968078613
Validation loss: 4.9045916001002

Epoch: 6| Step: 11
Training loss: 5.506758689880371
Validation loss: 4.8944798310597735

Epoch: 6| Step: 12
Training loss: 5.117886543273926
Validation loss: 4.8843616644541425

Epoch: 6| Step: 13
Training loss: 6.279952049255371
Validation loss: 4.874939600626628

Epoch: 6| Step: 0
Training loss: 4.3192548751831055
Validation loss: 4.865438063939412

Epoch: 6| Step: 1
Training loss: 4.499831199645996
Validation loss: 4.856305122375488

Epoch: 6| Step: 2
Training loss: 4.234010219573975
Validation loss: 4.847337086995442

Epoch: 6| Step: 3
Training loss: 5.785889625549316
Validation loss: 4.838536262512207

Epoch: 6| Step: 4
Training loss: 5.520606994628906
Validation loss: 4.830074787139893

Epoch: 6| Step: 5
Training loss: 5.538381576538086
Validation loss: 4.821616013844808

Epoch: 6| Step: 6
Training loss: 4.862490653991699
Validation loss: 4.81335445245107

Epoch: 6| Step: 7
Training loss: 4.796268463134766
Validation loss: 4.805349985758464

Epoch: 6| Step: 8
Training loss: 5.371023178100586
Validation loss: 4.797302484512329

Epoch: 6| Step: 9
Training loss: 4.615285396575928
Validation loss: 4.789312362670898

Epoch: 6| Step: 10
Training loss: 5.515639305114746
Validation loss: 4.781496445337932

Epoch: 6| Step: 11
Training loss: 3.6221842765808105
Validation loss: 4.773511330286662

Epoch: 6| Step: 12
Training loss: 3.850118398666382
Validation loss: 4.765608946482341

Epoch: 6| Step: 13
Training loss: 6.053304195404053
Validation loss: 4.7581361929575605

Epoch: 7| Step: 0
Training loss: 4.324046611785889
Validation loss: 4.7502055168151855

Epoch: 6| Step: 1
Training loss: 5.0332136154174805
Validation loss: 4.742611567179362

Epoch: 6| Step: 2
Training loss: 4.678197860717773
Validation loss: 4.734917521476746

Epoch: 6| Step: 3
Training loss: 4.441610336303711
Validation loss: 4.727202733357747

Epoch: 6| Step: 4
Training loss: 5.736769199371338
Validation loss: 4.71963373819987

Epoch: 6| Step: 5
Training loss: 4.340721130371094
Validation loss: 4.711704651514689

Epoch: 6| Step: 6
Training loss: 5.336258411407471
Validation loss: 4.704064687093099

Epoch: 6| Step: 7
Training loss: 3.9114370346069336
Validation loss: 4.696505069732666

Epoch: 6| Step: 8
Training loss: 4.575984001159668
Validation loss: 4.688488523165385

Epoch: 6| Step: 9
Training loss: 4.6345062255859375
Validation loss: 4.680623769760132

Epoch: 6| Step: 10
Training loss: 5.497018814086914
Validation loss: 4.6726118723551435

Epoch: 6| Step: 11
Training loss: 5.560898780822754
Validation loss: 4.664902766545613

Epoch: 6| Step: 12
Training loss: 4.253155708312988
Validation loss: 4.657051682472229

Epoch: 6| Step: 13
Training loss: 4.793978691101074
Validation loss: 4.648836851119995

Epoch: 8| Step: 0
Training loss: 4.937408447265625
Validation loss: 4.641168236732483

Epoch: 6| Step: 1
Training loss: 4.648094177246094
Validation loss: 4.6331526438395185

Epoch: 6| Step: 2
Training loss: 5.040775299072266
Validation loss: 4.62537944316864

Epoch: 6| Step: 3
Training loss: 4.8878560066223145
Validation loss: 4.617414275805156

Epoch: 6| Step: 4
Training loss: 4.764832496643066
Validation loss: 4.6098552942276

Epoch: 6| Step: 5
Training loss: 4.771782398223877
Validation loss: 4.602369586626689

Epoch: 6| Step: 6
Training loss: 5.079655647277832
Validation loss: 4.5946981112162275

Epoch: 6| Step: 7
Training loss: 5.333592891693115
Validation loss: 4.587001760800679

Epoch: 6| Step: 8
Training loss: 5.002938270568848
Validation loss: 4.579535802205403

Epoch: 6| Step: 9
Training loss: 4.355688095092773
Validation loss: 4.571872433026631

Epoch: 6| Step: 10
Training loss: 4.142836570739746
Validation loss: 4.564251621564229

Epoch: 6| Step: 11
Training loss: 4.201239585876465
Validation loss: 4.557210087776184

Epoch: 6| Step: 12
Training loss: 3.9683139324188232
Validation loss: 4.550034602483113

Epoch: 6| Step: 13
Training loss: 4.576408386230469
Validation loss: 4.543238480885823

Epoch: 9| Step: 0
Training loss: 4.856966018676758
Validation loss: 4.536158482233684

Epoch: 6| Step: 1
Training loss: 3.3340096473693848
Validation loss: 4.52943229675293

Epoch: 6| Step: 2
Training loss: 4.78886604309082
Validation loss: 4.5227891604105634

Epoch: 6| Step: 3
Training loss: 4.102531909942627
Validation loss: 4.515341281890869

Epoch: 6| Step: 4
Training loss: 4.666886329650879
Validation loss: 4.508790731430054

Epoch: 6| Step: 5
Training loss: 4.914882183074951
Validation loss: 4.501728057861328

Epoch: 6| Step: 6
Training loss: 4.8096771240234375
Validation loss: 4.494915882746379

Epoch: 6| Step: 7
Training loss: 5.41166877746582
Validation loss: 4.487951834996541

Epoch: 6| Step: 8
Training loss: 3.6429977416992188
Validation loss: 4.48096485932668

Epoch: 6| Step: 9
Training loss: 5.178720951080322
Validation loss: 4.473716815312703

Epoch: 6| Step: 10
Training loss: 4.213440895080566
Validation loss: 4.466577609380086

Epoch: 6| Step: 11
Training loss: 5.3158278465271
Validation loss: 4.458888252576192

Epoch: 6| Step: 12
Training loss: 5.522662162780762
Validation loss: 4.45232359568278

Epoch: 6| Step: 13
Training loss: 3.63437557220459
Validation loss: 4.444405476252238

Epoch: 10| Step: 0
Training loss: 4.273828029632568
Validation loss: 4.4369397560755415

Epoch: 6| Step: 1
Training loss: 4.820015907287598
Validation loss: 4.4295676946640015

Epoch: 6| Step: 2
Training loss: 4.523630619049072
Validation loss: 4.422280470530192

Epoch: 6| Step: 3
Training loss: 4.403044700622559
Validation loss: 4.415520747502645

Epoch: 6| Step: 4
Training loss: 4.261788845062256
Validation loss: 4.408101479212443

Epoch: 6| Step: 5
Training loss: 4.254426002502441
Validation loss: 4.401886940002441

Epoch: 6| Step: 6
Training loss: 5.200640678405762
Validation loss: 4.395884712537129

Epoch: 6| Step: 7
Training loss: 5.015061378479004
Validation loss: 4.388102809588115

Epoch: 6| Step: 8
Training loss: 3.9866561889648438
Validation loss: 4.3819038073221845

Epoch: 6| Step: 9
Training loss: 3.984719753265381
Validation loss: 4.375410000483195

Epoch: 6| Step: 10
Training loss: 3.699110984802246
Validation loss: 4.369442264238994

Epoch: 6| Step: 11
Training loss: 4.933879852294922
Validation loss: 4.36328125

Epoch: 6| Step: 12
Training loss: 5.2451910972595215
Validation loss: 4.357180277506511

Epoch: 6| Step: 13
Training loss: 4.547703742980957
Validation loss: 4.351646423339844

Epoch: 11| Step: 0
Training loss: 4.589097499847412
Validation loss: 4.34576936562856

Epoch: 6| Step: 1
Training loss: 4.2025861740112305
Validation loss: 4.339813272158305

Epoch: 6| Step: 2
Training loss: 4.414189338684082
Validation loss: 4.335343956947327

Epoch: 6| Step: 3
Training loss: 4.931210517883301
Validation loss: 4.329387068748474

Epoch: 6| Step: 4
Training loss: 4.998634338378906
Validation loss: 4.323850035667419

Epoch: 6| Step: 5
Training loss: 4.497419834136963
Validation loss: 4.318622907002767

Epoch: 6| Step: 6
Training loss: 5.22459077835083
Validation loss: 4.313670913378398

Epoch: 6| Step: 7
Training loss: 5.6103739738464355
Validation loss: 4.308231075604756

Epoch: 6| Step: 8
Training loss: 4.19450569152832
Validation loss: 4.302923758824666

Epoch: 6| Step: 9
Training loss: 4.190701484680176
Validation loss: 4.297128200531006

Epoch: 6| Step: 10
Training loss: 4.498401165008545
Validation loss: 4.2919230461120605

Epoch: 6| Step: 11
Training loss: 3.452037811279297
Validation loss: 4.286278327306111

Epoch: 6| Step: 12
Training loss: 3.9780399799346924
Validation loss: 4.280657211939494

Epoch: 6| Step: 13
Training loss: 3.2951998710632324
Validation loss: 4.275467753410339

Epoch: 12| Step: 0
Training loss: 4.792561054229736
Validation loss: 4.269356211026509

Epoch: 6| Step: 1
Training loss: 5.03133487701416
Validation loss: 4.263186931610107

Epoch: 6| Step: 2
Training loss: 3.2893667221069336
Validation loss: 4.257823189099629

Epoch: 6| Step: 3
Training loss: 4.113775730133057
Validation loss: 4.252587795257568

Epoch: 6| Step: 4
Training loss: 3.9149675369262695
Validation loss: 4.2467695871988935

Epoch: 6| Step: 5
Training loss: 4.874514102935791
Validation loss: 4.241520007451375

Epoch: 6| Step: 6
Training loss: 3.419609308242798
Validation loss: 4.235765258471171

Epoch: 6| Step: 7
Training loss: 4.4578986167907715
Validation loss: 4.22957444190979

Epoch: 6| Step: 8
Training loss: 4.629569053649902
Validation loss: 4.224313338597615

Epoch: 6| Step: 9
Training loss: 3.969966411590576
Validation loss: 4.218551715215047

Epoch: 6| Step: 10
Training loss: 4.569787502288818
Validation loss: 4.213593006134033

Epoch: 6| Step: 11
Training loss: 5.3201446533203125
Validation loss: 4.208806912104289

Epoch: 6| Step: 12
Training loss: 4.648158550262451
Validation loss: 4.203245162963867

Epoch: 6| Step: 13
Training loss: 4.0559468269348145
Validation loss: 4.1956493854522705

Epoch: 13| Step: 0
Training loss: 3.928788423538208
Validation loss: 4.189873814582825

Epoch: 6| Step: 1
Training loss: 4.194923400878906
Validation loss: 4.185254216194153

Epoch: 6| Step: 2
Training loss: 4.4167375564575195
Validation loss: 4.180353919665019

Epoch: 6| Step: 3
Training loss: 3.776560068130493
Validation loss: 4.17437760035197

Epoch: 6| Step: 4
Training loss: 4.000322341918945
Validation loss: 4.167400558789571

Epoch: 6| Step: 5
Training loss: 3.8972370624542236
Validation loss: 4.161189953486125

Epoch: 6| Step: 6
Training loss: 3.923083782196045
Validation loss: 4.1565210819244385

Epoch: 6| Step: 7
Training loss: 4.648618698120117
Validation loss: 4.150484720865886

Epoch: 6| Step: 8
Training loss: 4.164630889892578
Validation loss: 4.144088268280029

Epoch: 6| Step: 9
Training loss: 5.262372016906738
Validation loss: 4.139337182044983

Epoch: 6| Step: 10
Training loss: 5.1828765869140625
Validation loss: 4.134309569994609

Epoch: 6| Step: 11
Training loss: 4.798611640930176
Validation loss: 4.1287951072057085

Epoch: 6| Step: 12
Training loss: 3.1722168922424316
Validation loss: 4.122952938079834

Epoch: 6| Step: 13
Training loss: 4.711764335632324
Validation loss: 4.117670178413391

Epoch: 14| Step: 0
Training loss: 4.689411163330078
Validation loss: 4.113962531089783

Epoch: 6| Step: 1
Training loss: 5.175321578979492
Validation loss: 4.109165112177531

Epoch: 6| Step: 2
Training loss: 4.874537467956543
Validation loss: 4.103852232297261

Epoch: 6| Step: 3
Training loss: 4.666672706604004
Validation loss: 4.09756616751353

Epoch: 6| Step: 4
Training loss: 3.616609811782837
Validation loss: 4.09162966410319

Epoch: 6| Step: 5
Training loss: 5.115245342254639
Validation loss: 4.087198734283447

Epoch: 6| Step: 6
Training loss: 3.7967472076416016
Validation loss: 4.08208950360616

Epoch: 6| Step: 7
Training loss: 3.6266252994537354
Validation loss: 4.076593677202861

Epoch: 6| Step: 8
Training loss: 3.1556239128112793
Validation loss: 4.071622927983602

Epoch: 6| Step: 9
Training loss: 4.076820373535156
Validation loss: 4.0666080713272095

Epoch: 6| Step: 10
Training loss: 4.457314491271973
Validation loss: 4.062724828720093

Epoch: 6| Step: 11
Training loss: 3.451418876647949
Validation loss: 4.058390220006307

Epoch: 6| Step: 12
Training loss: 3.5487968921661377
Validation loss: 4.053010582923889

Epoch: 6| Step: 13
Training loss: 4.8723039627075195
Validation loss: 4.047814687093099

Epoch: 15| Step: 0
Training loss: 4.702939987182617
Validation loss: 4.043477495511373

Epoch: 6| Step: 1
Training loss: 4.020260810852051
Validation loss: 4.0388344923655195

Epoch: 6| Step: 2
Training loss: 3.2094945907592773
Validation loss: 4.033529082934062

Epoch: 6| Step: 3
Training loss: 4.017606735229492
Validation loss: 4.030386765797933

Epoch: 6| Step: 4
Training loss: 3.9661030769348145
Validation loss: 4.0260173082351685

Epoch: 6| Step: 5
Training loss: 4.560734748840332
Validation loss: 4.020517627398173

Epoch: 6| Step: 6
Training loss: 3.689657688140869
Validation loss: 4.016262610753377

Epoch: 6| Step: 7
Training loss: 4.3348212242126465
Validation loss: 4.011621713638306

Epoch: 6| Step: 8
Training loss: 4.4546308517456055
Validation loss: 4.0076455275217695

Epoch: 6| Step: 9
Training loss: 5.359399795532227
Validation loss: 4.003174940745036

Epoch: 6| Step: 10
Training loss: 3.739769697189331
Validation loss: 3.9986332654953003

Epoch: 6| Step: 11
Training loss: 4.888795852661133
Validation loss: 3.9940157731374106

Epoch: 6| Step: 12
Training loss: 3.0576419830322266
Validation loss: 3.9885714054107666

Epoch: 6| Step: 13
Training loss: 4.219448089599609
Validation loss: 3.9840875466664634

Epoch: 16| Step: 0
Training loss: 5.248505592346191
Validation loss: 3.979207436243693

Epoch: 6| Step: 1
Training loss: 3.907606601715088
Validation loss: 3.973646958669027

Epoch: 6| Step: 2
Training loss: 4.246745586395264
Validation loss: 3.969486633936564

Epoch: 6| Step: 3
Training loss: 4.294689655303955
Validation loss: 3.9653839667638144

Epoch: 6| Step: 4
Training loss: 3.357189893722534
Validation loss: 3.9616461594899497

Epoch: 6| Step: 5
Training loss: 3.7485883235931396
Validation loss: 3.9563867648442588

Epoch: 6| Step: 6
Training loss: 3.5877561569213867
Validation loss: 3.951865275700887

Epoch: 6| Step: 7
Training loss: 4.005433559417725
Validation loss: 3.947764237721761

Epoch: 6| Step: 8
Training loss: 5.115575313568115
Validation loss: 3.945828676223755

Epoch: 6| Step: 9
Training loss: 3.6670053005218506
Validation loss: 3.937995711962382

Epoch: 6| Step: 10
Training loss: 3.8950862884521484
Validation loss: 3.9340007305145264

Epoch: 6| Step: 11
Training loss: 3.7762932777404785
Validation loss: 3.9279050827026367

Epoch: 6| Step: 12
Training loss: 3.9353976249694824
Validation loss: 3.9241507053375244

Epoch: 6| Step: 13
Training loss: 4.585984706878662
Validation loss: 3.92000412940979

Epoch: 17| Step: 0
Training loss: 4.017956733703613
Validation loss: 3.91404390335083

Epoch: 6| Step: 1
Training loss: 4.529712200164795
Validation loss: 3.909581184387207

Epoch: 6| Step: 2
Training loss: 3.621920108795166
Validation loss: 3.9049298763275146

Epoch: 6| Step: 3
Training loss: 3.9323692321777344
Validation loss: 3.900041103363037

Epoch: 6| Step: 4
Training loss: 4.786436080932617
Validation loss: 3.895932912826538

Epoch: 6| Step: 5
Training loss: 3.838285446166992
Validation loss: 3.8911463022232056

Epoch: 6| Step: 6
Training loss: 4.270593166351318
Validation loss: 3.8859064976374307

Epoch: 6| Step: 7
Training loss: 3.6989059448242188
Validation loss: 3.880676746368408

Epoch: 6| Step: 8
Training loss: 3.984391212463379
Validation loss: 3.877239465713501

Epoch: 6| Step: 9
Training loss: 4.611016273498535
Validation loss: 3.8733173608779907

Epoch: 6| Step: 10
Training loss: 3.8117408752441406
Validation loss: 3.8696595827738443

Epoch: 6| Step: 11
Training loss: 3.500115394592285
Validation loss: 3.863966703414917

Epoch: 6| Step: 12
Training loss: 3.5020089149475098
Validation loss: 3.8605385621388755

Epoch: 6| Step: 13
Training loss: 4.381265640258789
Validation loss: 3.85480006535848

Epoch: 18| Step: 0
Training loss: 4.398441314697266
Validation loss: 3.849284569422404

Epoch: 6| Step: 1
Training loss: 4.498152732849121
Validation loss: 3.843910058339437

Epoch: 6| Step: 2
Training loss: 3.7918639183044434
Validation loss: 3.8388739824295044

Epoch: 6| Step: 3
Training loss: 4.802041053771973
Validation loss: 3.8350478410720825

Epoch: 6| Step: 4
Training loss: 4.337125301361084
Validation loss: 3.8307481606801352

Epoch: 6| Step: 5
Training loss: 3.344663381576538
Validation loss: 3.826181928316752

Epoch: 6| Step: 6
Training loss: 4.049261093139648
Validation loss: 3.821572422981262

Epoch: 6| Step: 7
Training loss: 2.583679676055908
Validation loss: 3.8169556856155396

Epoch: 6| Step: 8
Training loss: 3.6430907249450684
Validation loss: 3.8129473527272544

Epoch: 6| Step: 9
Training loss: 3.8475756645202637
Validation loss: 3.8091028928756714

Epoch: 6| Step: 10
Training loss: 5.39024543762207
Validation loss: 3.8058060805002847

Epoch: 6| Step: 11
Training loss: 4.476287841796875
Validation loss: 3.800564765930176

Epoch: 6| Step: 12
Training loss: 3.7558975219726562
Validation loss: 3.7960148255030313

Epoch: 6| Step: 13
Training loss: 2.7130603790283203
Validation loss: 3.791269222895304

Epoch: 19| Step: 0
Training loss: 3.141162157058716
Validation loss: 3.78669544061025

Epoch: 6| Step: 1
Training loss: 4.324226379394531
Validation loss: 3.78257417678833

Epoch: 6| Step: 2
Training loss: 3.2383852005004883
Validation loss: 3.7782958348592124

Epoch: 6| Step: 3
Training loss: 3.954902172088623
Validation loss: 3.7737486362457275

Epoch: 6| Step: 4
Training loss: 4.6209611892700195
Validation loss: 3.7696785926818848

Epoch: 6| Step: 5
Training loss: 3.5315587520599365
Validation loss: 3.7645828326543174

Epoch: 6| Step: 6
Training loss: 3.745610237121582
Validation loss: 3.759842316309611

Epoch: 6| Step: 7
Training loss: 4.494311332702637
Validation loss: 3.7558956146240234

Epoch: 6| Step: 8
Training loss: 4.219952583312988
Validation loss: 3.7513628005981445

Epoch: 6| Step: 9
Training loss: 3.6757259368896484
Validation loss: 3.747521003087362

Epoch: 6| Step: 10
Training loss: 3.9730141162872314
Validation loss: 3.7431366046269736

Epoch: 6| Step: 11
Training loss: 3.4204413890838623
Validation loss: 3.739032586415609

Epoch: 6| Step: 12
Training loss: 3.9198808670043945
Validation loss: 3.7342870235443115

Epoch: 6| Step: 13
Training loss: 4.5669660568237305
Validation loss: 3.730498472849528

Epoch: 20| Step: 0
Training loss: 3.4188003540039062
Validation loss: 3.7257558504740396

Epoch: 6| Step: 1
Training loss: 4.145984172821045
Validation loss: 3.7218250036239624

Epoch: 6| Step: 2
Training loss: 3.582180976867676
Validation loss: 3.7170494000116983

Epoch: 6| Step: 3
Training loss: 4.026511192321777
Validation loss: 3.7135295073191323

Epoch: 6| Step: 4
Training loss: 3.7811152935028076
Validation loss: 3.709128657976786

Epoch: 6| Step: 5
Training loss: 3.5673632621765137
Validation loss: 3.7052767276763916

Epoch: 6| Step: 6
Training loss: 4.473173141479492
Validation loss: 3.700870394706726

Epoch: 6| Step: 7
Training loss: 3.3486294746398926
Validation loss: 3.6968483924865723

Epoch: 6| Step: 8
Training loss: 4.39892578125
Validation loss: 3.6930463314056396

Epoch: 6| Step: 9
Training loss: 2.645224094390869
Validation loss: 3.6890061299006143

Epoch: 6| Step: 10
Training loss: 3.8353939056396484
Validation loss: 3.6850406726201377

Epoch: 6| Step: 11
Training loss: 4.908909797668457
Validation loss: 3.680619478225708

Epoch: 6| Step: 12
Training loss: 3.8461108207702637
Validation loss: 3.676545778910319

Epoch: 6| Step: 13
Training loss: 4.061371326446533
Validation loss: 3.672799269358317

Epoch: 21| Step: 0
Training loss: 5.021117210388184
Validation loss: 3.668083906173706

Epoch: 6| Step: 1
Training loss: 3.881333827972412
Validation loss: 3.6641162236531577

Epoch: 6| Step: 2
Training loss: 3.590080976486206
Validation loss: 3.6602429151535034

Epoch: 6| Step: 3
Training loss: 3.6050891876220703
Validation loss: 3.655824303627014

Epoch: 6| Step: 4
Training loss: 4.29750919342041
Validation loss: 3.65157683690389

Epoch: 6| Step: 5
Training loss: 3.6651406288146973
Validation loss: 3.647229552268982

Epoch: 6| Step: 6
Training loss: 2.8510355949401855
Validation loss: 3.6427692572275796

Epoch: 6| Step: 7
Training loss: 4.064263343811035
Validation loss: 3.6390681664148965

Epoch: 6| Step: 8
Training loss: 3.473595142364502
Validation loss: 3.634721517562866

Epoch: 6| Step: 9
Training loss: 4.726543426513672
Validation loss: 3.629832943280538

Epoch: 6| Step: 10
Training loss: 3.3663992881774902
Validation loss: 3.626227299372355

Epoch: 6| Step: 11
Training loss: 3.4587514400482178
Validation loss: 3.62193763256073

Epoch: 6| Step: 12
Training loss: 3.643339157104492
Validation loss: 3.617926836013794

Epoch: 6| Step: 13
Training loss: 3.6209559440612793
Validation loss: 3.6140025854110718

Epoch: 22| Step: 0
Training loss: 3.9169492721557617
Validation loss: 3.609043757120768

Epoch: 6| Step: 1
Training loss: 3.2537879943847656
Validation loss: 3.605141599973043

Epoch: 6| Step: 2
Training loss: 4.057134628295898
Validation loss: 3.6011370023091636

Epoch: 6| Step: 3
Training loss: 3.6136107444763184
Validation loss: 3.5965675910313926

Epoch: 6| Step: 4
Training loss: 3.5154225826263428
Validation loss: 3.5924033323923745

Epoch: 6| Step: 5
Training loss: 2.832381248474121
Validation loss: 3.588675061861674

Epoch: 6| Step: 6
Training loss: 3.771714448928833
Validation loss: 3.5846176942189536

Epoch: 6| Step: 7
Training loss: 4.404081344604492
Validation loss: 3.580591082572937

Epoch: 6| Step: 8
Training loss: 3.520409107208252
Validation loss: 3.576474587122599

Epoch: 6| Step: 9
Training loss: 4.274136066436768
Validation loss: 3.571927865346273

Epoch: 6| Step: 10
Training loss: 4.273850440979004
Validation loss: 3.567943294843038

Epoch: 6| Step: 11
Training loss: 3.7692923545837402
Validation loss: 3.5650619665781655

Epoch: 6| Step: 12
Training loss: 3.502413511276245
Validation loss: 3.560189445813497

Epoch: 6| Step: 13
Training loss: 3.738661050796509
Validation loss: 3.5554869174957275

Epoch: 23| Step: 0
Training loss: 4.406613349914551
Validation loss: 3.5503997008005777

Epoch: 6| Step: 1
Training loss: 2.1155500411987305
Validation loss: 3.54677947362264

Epoch: 6| Step: 2
Training loss: 2.7894110679626465
Validation loss: 3.543646454811096

Epoch: 6| Step: 3
Training loss: 3.765228271484375
Validation loss: 3.5400849183400473

Epoch: 6| Step: 4
Training loss: 4.211230278015137
Validation loss: 3.5358017683029175

Epoch: 6| Step: 5
Training loss: 4.373246192932129
Validation loss: 3.530459403991699

Epoch: 6| Step: 6
Training loss: 4.576109886169434
Validation loss: 3.5252850453058877

Epoch: 6| Step: 7
Training loss: 2.335552453994751
Validation loss: 3.520414153734843

Epoch: 6| Step: 8
Training loss: 3.3505642414093018
Validation loss: 3.5162654717763266

Epoch: 6| Step: 9
Training loss: 3.5739502906799316
Validation loss: 3.512640436490377

Epoch: 6| Step: 10
Training loss: 3.3696024417877197
Validation loss: 3.5084808270136514

Epoch: 6| Step: 11
Training loss: 4.173299789428711
Validation loss: 3.5033886432647705

Epoch: 6| Step: 12
Training loss: 3.5599400997161865
Validation loss: 3.4996711810429892

Epoch: 6| Step: 13
Training loss: 5.044564723968506
Validation loss: 3.495579957962036

Epoch: 24| Step: 0
Training loss: 3.9503231048583984
Validation loss: 3.490979870160421

Epoch: 6| Step: 1
Training loss: 3.9894204139709473
Validation loss: 3.48654838403066

Epoch: 6| Step: 2
Training loss: 3.1283068656921387
Validation loss: 3.4817176262537637

Epoch: 6| Step: 3
Training loss: 3.388794183731079
Validation loss: 3.4778665701548257

Epoch: 6| Step: 4
Training loss: 4.134214878082275
Validation loss: 3.473876118659973

Epoch: 6| Step: 5
Training loss: 3.6057610511779785
Validation loss: 3.4692116578420005

Epoch: 6| Step: 6
Training loss: 3.409853458404541
Validation loss: 3.466682036717733

Epoch: 6| Step: 7
Training loss: 3.4118459224700928
Validation loss: 3.4611576000849404

Epoch: 6| Step: 8
Training loss: 3.803426742553711
Validation loss: 3.4575010935465493

Epoch: 6| Step: 9
Training loss: 3.689723253250122
Validation loss: 3.45345946153005

Epoch: 6| Step: 10
Training loss: 2.7515041828155518
Validation loss: 3.4492267370224

Epoch: 6| Step: 11
Training loss: 3.394465208053589
Validation loss: 3.4447398583094277

Epoch: 6| Step: 12
Training loss: 4.463399887084961
Validation loss: 3.440019726753235

Epoch: 6| Step: 13
Training loss: 3.6948699951171875
Validation loss: 3.435995856920878

Epoch: 25| Step: 0
Training loss: 3.315983772277832
Validation loss: 3.4313814640045166

Epoch: 6| Step: 1
Training loss: 3.944873809814453
Validation loss: 3.426864584287008

Epoch: 6| Step: 2
Training loss: 2.885143280029297
Validation loss: 3.4230966170628867

Epoch: 6| Step: 3
Training loss: 3.951704978942871
Validation loss: 3.4191863934199014

Epoch: 6| Step: 4
Training loss: 4.302134037017822
Validation loss: 3.4157665967941284

Epoch: 6| Step: 5
Training loss: 3.0443263053894043
Validation loss: 3.4113686084747314

Epoch: 6| Step: 6
Training loss: 3.74353289604187
Validation loss: 3.4075798193613687

Epoch: 6| Step: 7
Training loss: 3.1085915565490723
Validation loss: 3.403684059778849

Epoch: 6| Step: 8
Training loss: 4.1078715324401855
Validation loss: 3.401019732157389

Epoch: 6| Step: 9
Training loss: 4.58649206161499
Validation loss: 3.3958115577697754

Epoch: 6| Step: 10
Training loss: 3.1666557788848877
Validation loss: 3.3918656508127847

Epoch: 6| Step: 11
Training loss: 3.0729098320007324
Validation loss: 3.3873204787572226

Epoch: 6| Step: 12
Training loss: 2.6399905681610107
Validation loss: 3.3830569982528687

Epoch: 6| Step: 13
Training loss: 4.1236066818237305
Validation loss: 3.3790340423583984

Epoch: 26| Step: 0
Training loss: 4.412477493286133
Validation loss: 3.375259757041931

Epoch: 6| Step: 1
Training loss: 2.273343086242676
Validation loss: 3.370862444241842

Epoch: 6| Step: 2
Training loss: 3.440141439437866
Validation loss: 3.3667381207148233

Epoch: 6| Step: 3
Training loss: 4.203038215637207
Validation loss: 3.362315018971761

Epoch: 6| Step: 4
Training loss: 2.7712361812591553
Validation loss: 3.3579411109288535

Epoch: 6| Step: 5
Training loss: 3.34570574760437
Validation loss: 3.3534429470698037

Epoch: 6| Step: 6
Training loss: 3.956169843673706
Validation loss: 3.3490182558695474

Epoch: 6| Step: 7
Training loss: 4.011882781982422
Validation loss: 3.3450992504755654

Epoch: 6| Step: 8
Training loss: 2.8991763591766357
Validation loss: 3.3418113390604653

Epoch: 6| Step: 9
Training loss: 3.813969135284424
Validation loss: 3.337133208910624

Epoch: 6| Step: 10
Training loss: 3.1028356552124023
Validation loss: 3.332821170488993

Epoch: 6| Step: 11
Training loss: 3.562826156616211
Validation loss: 3.3288619915644326

Epoch: 6| Step: 12
Training loss: 4.090054035186768
Validation loss: 3.325567881266276

Epoch: 6| Step: 13
Training loss: 3.3810629844665527
Validation loss: 3.3221764167149863

Epoch: 27| Step: 0
Training loss: 3.108705520629883
Validation loss: 3.3179367780685425

Epoch: 6| Step: 1
Training loss: 3.6007754802703857
Validation loss: 3.3135449488957724

Epoch: 6| Step: 2
Training loss: 3.38092303276062
Validation loss: 3.308889945348104

Epoch: 6| Step: 3
Training loss: 3.394890308380127
Validation loss: 3.3042157888412476

Epoch: 6| Step: 4
Training loss: 3.720322608947754
Validation loss: 3.30070968468984

Epoch: 6| Step: 5
Training loss: 3.8791913986206055
Validation loss: 3.296493172645569

Epoch: 6| Step: 6
Training loss: 2.7195627689361572
Validation loss: 3.2927101055781045

Epoch: 6| Step: 7
Training loss: 2.815004587173462
Validation loss: 3.2885986963907876

Epoch: 6| Step: 8
Training loss: 3.527667999267578
Validation loss: 3.284397999445597

Epoch: 6| Step: 9
Training loss: 4.1904497146606445
Validation loss: 3.280477523803711

Epoch: 6| Step: 10
Training loss: 3.3217251300811768
Validation loss: 3.2761555910110474

Epoch: 6| Step: 11
Training loss: 3.6034858226776123
Validation loss: 3.272475242614746

Epoch: 6| Step: 12
Training loss: 4.081959247589111
Validation loss: 3.268537680308024

Epoch: 6| Step: 13
Training loss: 3.207674264907837
Validation loss: 3.265017867088318

Epoch: 28| Step: 0
Training loss: 3.645841598510742
Validation loss: 3.2613263924916587

Epoch: 6| Step: 1
Training loss: 2.6468167304992676
Validation loss: 3.2573999166488647

Epoch: 6| Step: 2
Training loss: 2.5914485454559326
Validation loss: 3.25419819355011

Epoch: 6| Step: 3
Training loss: 3.947317123413086
Validation loss: 3.2505549987157187

Epoch: 6| Step: 4
Training loss: 3.0698537826538086
Validation loss: 3.24812775850296

Epoch: 6| Step: 5
Training loss: 4.533332824707031
Validation loss: 3.243829607963562

Epoch: 6| Step: 6
Training loss: 3.2392046451568604
Validation loss: 3.239821672439575

Epoch: 6| Step: 7
Training loss: 3.6282761096954346
Validation loss: 3.2360401153564453

Epoch: 6| Step: 8
Training loss: 3.1615068912506104
Validation loss: 3.232680400212606

Epoch: 6| Step: 9
Training loss: 3.9623031616210938
Validation loss: 3.2280835707982383

Epoch: 6| Step: 10
Training loss: 2.9026520252227783
Validation loss: 3.2237592140833535

Epoch: 6| Step: 11
Training loss: 4.5734100341796875
Validation loss: 3.220783750216166

Epoch: 6| Step: 12
Training loss: 3.217510223388672
Validation loss: 3.217038710912069

Epoch: 6| Step: 13
Training loss: 2.692483901977539
Validation loss: 3.212602217992147

Epoch: 29| Step: 0
Training loss: 3.431459903717041
Validation loss: 3.2084171374638877

Epoch: 6| Step: 1
Training loss: 3.500302314758301
Validation loss: 3.204535126686096

Epoch: 6| Step: 2
Training loss: 3.2584052085876465
Validation loss: 3.2007107734680176

Epoch: 6| Step: 3
Training loss: 2.1762290000915527
Validation loss: 3.196900486946106

Epoch: 6| Step: 4
Training loss: 3.9952101707458496
Validation loss: 3.193342924118042

Epoch: 6| Step: 5
Training loss: 3.6905922889709473
Validation loss: 3.18965216477712

Epoch: 6| Step: 6
Training loss: 2.652833938598633
Validation loss: 3.185641288757324

Epoch: 6| Step: 7
Training loss: 3.8205010890960693
Validation loss: 3.1817748149236045

Epoch: 6| Step: 8
Training loss: 4.890867233276367
Validation loss: 3.1784323851267495

Epoch: 6| Step: 9
Training loss: 3.7192111015319824
Validation loss: 3.1737971703211465

Epoch: 6| Step: 10
Training loss: 2.3408493995666504
Validation loss: 3.169714411099752

Epoch: 6| Step: 11
Training loss: 3.0530457496643066
Validation loss: 3.1655742724736533

Epoch: 6| Step: 12
Training loss: 3.2743654251098633
Validation loss: 3.1617586612701416

Epoch: 6| Step: 13
Training loss: 3.330918073654175
Validation loss: 3.1584476232528687

Epoch: 30| Step: 0
Training loss: 3.3713769912719727
Validation loss: 3.1545341412226358

Epoch: 6| Step: 1
Training loss: 2.7686009407043457
Validation loss: 3.150255560874939

Epoch: 6| Step: 2
Training loss: 2.639042615890503
Validation loss: 3.146975874900818

Epoch: 6| Step: 3
Training loss: 3.665311813354492
Validation loss: 3.1435607274373374

Epoch: 6| Step: 4
Training loss: 3.793911933898926
Validation loss: 3.139410058657328

Epoch: 6| Step: 5
Training loss: 3.624138832092285
Validation loss: 3.13577930132548

Epoch: 6| Step: 6
Training loss: 3.1639585494995117
Validation loss: 3.13169797261556

Epoch: 6| Step: 7
Training loss: 3.5774288177490234
Validation loss: 3.128517826398214

Epoch: 6| Step: 8
Training loss: 4.008172035217285
Validation loss: 3.1249391237894693

Epoch: 6| Step: 9
Training loss: 2.9131975173950195
Validation loss: 3.1205140352249146

Epoch: 6| Step: 10
Training loss: 3.462156295776367
Validation loss: 3.116096258163452

Epoch: 6| Step: 11
Training loss: 3.6347806453704834
Validation loss: 3.1127806107203164

Epoch: 6| Step: 12
Training loss: 2.8398096561431885
Validation loss: 3.1086172262827554

Epoch: 6| Step: 13
Training loss: 2.9970922470092773
Validation loss: 3.104910929997762

Epoch: 31| Step: 0
Training loss: 3.3040218353271484
Validation loss: 3.1012807289759317

Epoch: 6| Step: 1
Training loss: 3.3312010765075684
Validation loss: 3.097961187362671

Epoch: 6| Step: 2
Training loss: 3.8519058227539062
Validation loss: 3.0948398113250732

Epoch: 6| Step: 3
Training loss: 3.0248522758483887
Validation loss: 3.091798027356466

Epoch: 6| Step: 4
Training loss: 3.053567886352539
Validation loss: 3.088977018992106

Epoch: 6| Step: 5
Training loss: 3.9667181968688965
Validation loss: 3.0859156052271524

Epoch: 6| Step: 6
Training loss: 3.126816749572754
Validation loss: 3.0826202630996704

Epoch: 6| Step: 7
Training loss: 2.5063564777374268
Validation loss: 3.0798170963923135

Epoch: 6| Step: 8
Training loss: 3.8226122856140137
Validation loss: 3.075848937034607

Epoch: 6| Step: 9
Training loss: 3.289900779724121
Validation loss: 3.072325428326925

Epoch: 6| Step: 10
Training loss: 2.9281253814697266
Validation loss: 3.0690757830937705

Epoch: 6| Step: 11
Training loss: 3.218620538711548
Validation loss: 3.065479318300883

Epoch: 6| Step: 12
Training loss: 3.0469510555267334
Validation loss: 3.0623088677724204

Epoch: 6| Step: 13
Training loss: 3.3032684326171875
Validation loss: 3.0586690107981362

Epoch: 32| Step: 0
Training loss: 3.4979965686798096
Validation loss: 3.056393345197042

Epoch: 6| Step: 1
Training loss: 3.33034086227417
Validation loss: 3.053070306777954

Epoch: 6| Step: 2
Training loss: 2.616847038269043
Validation loss: 3.051709294319153

Epoch: 6| Step: 3
Training loss: 3.906466484069824
Validation loss: 3.049794316291809

Epoch: 6| Step: 4
Training loss: 3.514763355255127
Validation loss: 3.0440731048583984

Epoch: 6| Step: 5
Training loss: 3.9605553150177
Validation loss: 3.039946675300598

Epoch: 6| Step: 6
Training loss: 3.3613059520721436
Validation loss: 3.0348172982533774

Epoch: 6| Step: 7
Training loss: 2.2298834323883057
Validation loss: 3.032404661178589

Epoch: 6| Step: 8
Training loss: 3.5310792922973633
Validation loss: 3.0293956995010376

Epoch: 6| Step: 9
Training loss: 2.7112083435058594
Validation loss: 3.026787042617798

Epoch: 6| Step: 10
Training loss: 3.235135078430176
Validation loss: 3.0236171086629233

Epoch: 6| Step: 11
Training loss: 3.891503095626831
Validation loss: 3.021078666051229

Epoch: 6| Step: 12
Training loss: 2.092221736907959
Validation loss: 3.016955534617106

Epoch: 6| Step: 13
Training loss: 3.31117582321167
Validation loss: 3.013706862926483

Epoch: 33| Step: 0
Training loss: 3.5252137184143066
Validation loss: 3.0099905331929526

Epoch: 6| Step: 1
Training loss: 3.208922863006592
Validation loss: 3.0066906611124673

Epoch: 6| Step: 2
Training loss: 3.2070744037628174
Validation loss: 3.002771337827047

Epoch: 6| Step: 3
Training loss: 3.384788990020752
Validation loss: 2.9990145762761435

Epoch: 6| Step: 4
Training loss: 2.53497314453125
Validation loss: 2.9961010217666626

Epoch: 6| Step: 5
Training loss: 3.409776210784912
Validation loss: 2.993035316467285

Epoch: 6| Step: 6
Training loss: 3.513216972351074
Validation loss: 2.989701509475708

Epoch: 6| Step: 7
Training loss: 2.9130961894989014
Validation loss: 2.9865059852600098

Epoch: 6| Step: 8
Training loss: 3.440034866333008
Validation loss: 2.9826528231302896

Epoch: 6| Step: 9
Training loss: 2.6819334030151367
Validation loss: 2.9803291956583657

Epoch: 6| Step: 10
Training loss: 3.3056206703186035
Validation loss: 2.9784732659657798

Epoch: 6| Step: 11
Training loss: 2.6259942054748535
Validation loss: 2.9759761889775596

Epoch: 6| Step: 12
Training loss: 3.348578929901123
Validation loss: 2.971507747968038

Epoch: 6| Step: 13
Training loss: 3.4697344303131104
Validation loss: 2.9677321513493857

Epoch: 34| Step: 0
Training loss: 3.6251113414764404
Validation loss: 2.963472843170166

Epoch: 6| Step: 1
Training loss: 3.6128032207489014
Validation loss: 2.9601394732793174

Epoch: 6| Step: 2
Training loss: 4.098940849304199
Validation loss: 2.9566315015157065

Epoch: 6| Step: 3
Training loss: 2.836347818374634
Validation loss: 2.9530757665634155

Epoch: 6| Step: 4
Training loss: 2.6900298595428467
Validation loss: 2.9493261575698853

Epoch: 6| Step: 5
Training loss: 3.382658004760742
Validation loss: 2.9461648066838584

Epoch: 6| Step: 6
Training loss: 2.9065465927124023
Validation loss: 2.943096081415812

Epoch: 6| Step: 7
Training loss: 2.7908029556274414
Validation loss: 2.9395889043807983

Epoch: 6| Step: 8
Training loss: 3.4798057079315186
Validation loss: 2.936174154281616

Epoch: 6| Step: 9
Training loss: 2.8618879318237305
Validation loss: 2.9321832259496055

Epoch: 6| Step: 10
Training loss: 3.7021219730377197
Validation loss: 2.9287352561950684

Epoch: 6| Step: 11
Training loss: 3.1832010746002197
Validation loss: 2.925097703933716

Epoch: 6| Step: 12
Training loss: 2.425482749938965
Validation loss: 2.9219791094462075

Epoch: 6| Step: 13
Training loss: 2.446631908416748
Validation loss: 2.919652978579203

Epoch: 35| Step: 0
Training loss: 2.279982089996338
Validation loss: 2.9173452059427896

Epoch: 6| Step: 1
Training loss: 2.851142168045044
Validation loss: 2.9141703049341836

Epoch: 6| Step: 2
Training loss: 3.1313061714172363
Validation loss: 2.910593787829081

Epoch: 6| Step: 3
Training loss: 3.6718454360961914
Validation loss: 2.90709396203359

Epoch: 6| Step: 4
Training loss: 3.365115165710449
Validation loss: 2.9042760531107583

Epoch: 6| Step: 5
Training loss: 3.4979119300842285
Validation loss: 2.9016425212224326

Epoch: 6| Step: 6
Training loss: 3.006715774536133
Validation loss: 2.897596756617228

Epoch: 6| Step: 7
Training loss: 2.9445109367370605
Validation loss: 2.894761880238851

Epoch: 6| Step: 8
Training loss: 2.984065055847168
Validation loss: 2.8914211988449097

Epoch: 6| Step: 9
Training loss: 3.710118055343628
Validation loss: 2.888296882311503

Epoch: 6| Step: 10
Training loss: 2.3203415870666504
Validation loss: 2.885691205660502

Epoch: 6| Step: 11
Training loss: 2.775848388671875
Validation loss: 2.88214639822642

Epoch: 6| Step: 12
Training loss: 3.209177017211914
Validation loss: 2.8794572353363037

Epoch: 6| Step: 13
Training loss: 3.707033157348633
Validation loss: 2.8765520254770913

Epoch: 36| Step: 0
Training loss: 3.6526718139648438
Validation loss: 2.8736796379089355

Epoch: 6| Step: 1
Training loss: 3.2779464721679688
Validation loss: 2.870227297147115

Epoch: 6| Step: 2
Training loss: 3.095327854156494
Validation loss: 2.870203177134196

Epoch: 6| Step: 3
Training loss: 2.850273370742798
Validation loss: 2.8789889415105185

Epoch: 6| Step: 4
Training loss: 2.613595485687256
Validation loss: 2.861532211303711

Epoch: 6| Step: 5
Training loss: 2.7625718116760254
Validation loss: 2.858764330546061

Epoch: 6| Step: 6
Training loss: 3.525200843811035
Validation loss: 2.8561155200004578

Epoch: 6| Step: 7
Training loss: 2.4620137214660645
Validation loss: 2.8542454640070596

Epoch: 6| Step: 8
Training loss: 2.6675548553466797
Validation loss: 2.854931871096293

Epoch: 6| Step: 9
Training loss: 3.2914085388183594
Validation loss: 2.862118045488993

Epoch: 6| Step: 10
Training loss: 3.2193336486816406
Validation loss: 2.8458545207977295

Epoch: 6| Step: 11
Training loss: 3.284722328186035
Validation loss: 2.8424218893051147

Epoch: 6| Step: 12
Training loss: 2.584373950958252
Validation loss: 2.841479460398356

Epoch: 6| Step: 13
Training loss: 3.658961534500122
Validation loss: 2.8436190287272134

Epoch: 37| Step: 0
Training loss: 3.532907485961914
Validation loss: 2.8347428242365518

Epoch: 6| Step: 1
Training loss: 3.0872912406921387
Validation loss: 2.830824295679728

Epoch: 6| Step: 2
Training loss: 3.3077526092529297
Validation loss: 2.82795786857605

Epoch: 6| Step: 3
Training loss: 3.919384479522705
Validation loss: 2.825206478436788

Epoch: 6| Step: 4
Training loss: 2.214747428894043
Validation loss: 2.823870619138082

Epoch: 6| Step: 5
Training loss: 2.6496634483337402
Validation loss: 2.820947011311849

Epoch: 6| Step: 6
Training loss: 3.0847973823547363
Validation loss: 2.8201945622762046

Epoch: 6| Step: 7
Training loss: 2.4865214824676514
Validation loss: 2.814867377281189

Epoch: 6| Step: 8
Training loss: 3.430363655090332
Validation loss: 2.811920921007792

Epoch: 6| Step: 9
Training loss: 3.41978120803833
Validation loss: 2.808456460634867

Epoch: 6| Step: 10
Training loss: 2.666607618331909
Validation loss: 2.8057183821996055

Epoch: 6| Step: 11
Training loss: 3.4330484867095947
Validation loss: 2.8022140661875405

Epoch: 6| Step: 12
Training loss: 2.8316478729248047
Validation loss: 2.800093332926432

Epoch: 6| Step: 13
Training loss: 2.3463456630706787
Validation loss: 2.797058860460917

Epoch: 38| Step: 0
Training loss: 3.1105592250823975
Validation loss: 2.7943780024846396

Epoch: 6| Step: 1
Training loss: 3.263110637664795
Validation loss: 2.7917032639185586

Epoch: 6| Step: 2
Training loss: 2.3358054161071777
Validation loss: 2.789673169453939

Epoch: 6| Step: 3
Training loss: 2.2728958129882812
Validation loss: 2.7885780731836953

Epoch: 6| Step: 4
Training loss: 2.8550732135772705
Validation loss: 2.784332593282064

Epoch: 6| Step: 5
Training loss: 4.263647079467773
Validation loss: 2.783146699269613

Epoch: 6| Step: 6
Training loss: 2.901374340057373
Validation loss: 2.780678908030192

Epoch: 6| Step: 7
Training loss: 3.287987470626831
Validation loss: 2.777298887570699

Epoch: 6| Step: 8
Training loss: 2.247938632965088
Validation loss: 2.775020639101664

Epoch: 6| Step: 9
Training loss: 3.5027263164520264
Validation loss: 2.77153472105662

Epoch: 6| Step: 10
Training loss: 3.0179977416992188
Validation loss: 2.7687425216039023

Epoch: 6| Step: 11
Training loss: 2.776710033416748
Validation loss: 2.766174634297689

Epoch: 6| Step: 12
Training loss: 3.0839333534240723
Validation loss: 2.7632711927096048

Epoch: 6| Step: 13
Training loss: 2.904998302459717
Validation loss: 2.7594338258107505

Epoch: 39| Step: 0
Training loss: 2.3544745445251465
Validation loss: 2.757122278213501

Epoch: 6| Step: 1
Training loss: 3.515575647354126
Validation loss: 2.754462798436483

Epoch: 6| Step: 2
Training loss: 2.2964212894439697
Validation loss: 2.751212199529012

Epoch: 6| Step: 3
Training loss: 2.955815315246582
Validation loss: 2.7484440406163535

Epoch: 6| Step: 4
Training loss: 3.5653276443481445
Validation loss: 2.7453837792078652

Epoch: 6| Step: 5
Training loss: 3.3681726455688477
Validation loss: 2.7420231898625693

Epoch: 6| Step: 6
Training loss: 2.1200101375579834
Validation loss: 2.7397350072860718

Epoch: 6| Step: 7
Training loss: 3.556931734085083
Validation loss: 2.7368046045303345

Epoch: 6| Step: 8
Training loss: 2.934018850326538
Validation loss: 2.7353517611821494

Epoch: 6| Step: 9
Training loss: 3.0551095008850098
Validation loss: 2.7312613328297934

Epoch: 6| Step: 10
Training loss: 2.725205659866333
Validation loss: 2.729257901509603

Epoch: 6| Step: 11
Training loss: 2.4893856048583984
Validation loss: 2.7269890705744424

Epoch: 6| Step: 12
Training loss: 3.290127754211426
Validation loss: 2.7234076658884683

Epoch: 6| Step: 13
Training loss: 3.08944034576416
Validation loss: 2.720317324002584

Epoch: 40| Step: 0
Training loss: 3.166067600250244
Validation loss: 2.717553496360779

Epoch: 6| Step: 1
Training loss: 2.4714109897613525
Validation loss: 2.7150062719980874

Epoch: 6| Step: 2
Training loss: 2.905651569366455
Validation loss: 2.710270722707113

Epoch: 6| Step: 3
Training loss: 2.5321524143218994
Validation loss: 2.707981069882711

Epoch: 6| Step: 4
Training loss: 2.712559700012207
Validation loss: 2.706542690594991

Epoch: 6| Step: 5
Training loss: 3.02903413772583
Validation loss: 2.704930861790975

Epoch: 6| Step: 6
Training loss: 3.801755428314209
Validation loss: 2.700281500816345

Epoch: 6| Step: 7
Training loss: 3.073352336883545
Validation loss: 2.6967345078786216

Epoch: 6| Step: 8
Training loss: 3.3393359184265137
Validation loss: 2.696270227432251

Epoch: 6| Step: 9
Training loss: 3.6802263259887695
Validation loss: 2.6928266684214273

Epoch: 6| Step: 10
Training loss: 2.5477614402770996
Validation loss: 2.6911829710006714

Epoch: 6| Step: 11
Training loss: 2.6062395572662354
Validation loss: 2.6931505600611367

Epoch: 6| Step: 12
Training loss: 1.7451571226119995
Validation loss: 2.6921120087305703

Epoch: 6| Step: 13
Training loss: 3.1635258197784424
Validation loss: 2.6936421394348145

Epoch: 41| Step: 0
Training loss: 2.6768429279327393
Validation loss: 2.6816378831863403

Epoch: 6| Step: 1
Training loss: 2.926032066345215
Validation loss: 2.6790342330932617

Epoch: 6| Step: 2
Training loss: 2.6810460090637207
Validation loss: 2.677123506863912

Epoch: 6| Step: 3
Training loss: 2.8629565238952637
Validation loss: 2.6757556597391763

Epoch: 6| Step: 4
Training loss: 2.7703840732574463
Validation loss: 2.6731449365615845

Epoch: 6| Step: 5
Training loss: 3.14298677444458
Validation loss: 2.671550432840983

Epoch: 6| Step: 6
Training loss: 2.9924187660217285
Validation loss: 2.667936682701111

Epoch: 6| Step: 7
Training loss: 3.0495777130126953
Validation loss: 2.665939728418986

Epoch: 6| Step: 8
Training loss: 2.568985939025879
Validation loss: 2.6614259481430054

Epoch: 6| Step: 9
Training loss: 2.6541128158569336
Validation loss: 2.658966302871704

Epoch: 6| Step: 10
Training loss: 2.774228572845459
Validation loss: 2.6562994718551636

Epoch: 6| Step: 11
Training loss: 3.187558174133301
Validation loss: 2.6549045642217

Epoch: 6| Step: 12
Training loss: 2.8918018341064453
Validation loss: 2.650535265604655

Epoch: 6| Step: 13
Training loss: 3.0215160846710205
Validation loss: 2.6483140786488852

Epoch: 42| Step: 0
Training loss: 2.952131748199463
Validation loss: 2.6470806201299033

Epoch: 6| Step: 1
Training loss: 3.050645351409912
Validation loss: 2.643734614054362

Epoch: 6| Step: 2
Training loss: 2.4030795097351074
Validation loss: 2.6408365964889526

Epoch: 6| Step: 3
Training loss: 2.5333027839660645
Validation loss: 2.638595143953959

Epoch: 6| Step: 4
Training loss: 3.0965776443481445
Validation loss: 2.634484569231669

Epoch: 6| Step: 5
Training loss: 2.9575486183166504
Validation loss: 2.631437838077545

Epoch: 6| Step: 6
Training loss: 2.572866201400757
Validation loss: 2.6326507727305093

Epoch: 6| Step: 7
Training loss: 3.1962273120880127
Validation loss: 2.6276187896728516

Epoch: 6| Step: 8
Training loss: 3.241513967514038
Validation loss: 2.6242018938064575

Epoch: 6| Step: 9
Training loss: 2.5191311836242676
Validation loss: 2.6205706199010215

Epoch: 6| Step: 10
Training loss: 3.1186091899871826
Validation loss: 2.6180289586385093

Epoch: 6| Step: 11
Training loss: 3.083373546600342
Validation loss: 2.61583403746287

Epoch: 6| Step: 12
Training loss: 2.5826163291931152
Validation loss: 2.614907383918762

Epoch: 6| Step: 13
Training loss: 2.3582746982574463
Validation loss: 2.6142351428667703

Epoch: 43| Step: 0
Training loss: 3.406862497329712
Validation loss: 2.6112889448801675

Epoch: 6| Step: 1
Training loss: 3.069714307785034
Validation loss: 2.609528422355652

Epoch: 6| Step: 2
Training loss: 2.768075466156006
Validation loss: 2.6076565980911255

Epoch: 6| Step: 3
Training loss: 2.3716824054718018
Validation loss: 2.606999397277832

Epoch: 6| Step: 4
Training loss: 3.2687792778015137
Validation loss: 2.604002078374227

Epoch: 6| Step: 5
Training loss: 2.730330467224121
Validation loss: 2.6011943022410073

Epoch: 6| Step: 6
Training loss: 2.562556266784668
Validation loss: 2.599360783894857

Epoch: 6| Step: 7
Training loss: 2.9415998458862305
Validation loss: 2.5958255926767984

Epoch: 6| Step: 8
Training loss: 2.911142587661743
Validation loss: 2.5929267009099326

Epoch: 6| Step: 9
Training loss: 2.2884621620178223
Validation loss: 2.5906163851420083

Epoch: 6| Step: 10
Training loss: 2.781531572341919
Validation loss: 2.5857338905334473

Epoch: 6| Step: 11
Training loss: 3.285703182220459
Validation loss: 2.5827906727790833

Epoch: 6| Step: 12
Training loss: 2.361764907836914
Validation loss: 2.5798257986704507

Epoch: 6| Step: 13
Training loss: 2.434696674346924
Validation loss: 2.5773037672042847

Epoch: 44| Step: 0
Training loss: 3.1687512397766113
Validation loss: 2.575095812479655

Epoch: 6| Step: 1
Training loss: 3.3632307052612305
Validation loss: 2.572750449180603

Epoch: 6| Step: 2
Training loss: 2.701054811477661
Validation loss: 2.5702439149220786

Epoch: 6| Step: 3
Training loss: 2.0592429637908936
Validation loss: 2.5680126349131265

Epoch: 6| Step: 4
Training loss: 2.924827814102173
Validation loss: 2.5641127030054727

Epoch: 6| Step: 5
Training loss: 2.8780832290649414
Validation loss: 2.5620954434076944

Epoch: 6| Step: 6
Training loss: 2.3885464668273926
Validation loss: 2.561676303545634

Epoch: 6| Step: 7
Training loss: 2.9576196670532227
Validation loss: 2.558502276738485

Epoch: 6| Step: 8
Training loss: 1.7037887573242188
Validation loss: 2.5582353870073953

Epoch: 6| Step: 9
Training loss: 2.6943793296813965
Validation loss: 2.554819345474243

Epoch: 6| Step: 10
Training loss: 3.305365562438965
Validation loss: 2.549988547960917

Epoch: 6| Step: 11
Training loss: 3.5029754638671875
Validation loss: 2.549377918243408

Epoch: 6| Step: 12
Training loss: 2.398996353149414
Validation loss: 2.5462663571039834

Epoch: 6| Step: 13
Training loss: 2.576411485671997
Validation loss: 2.544769207636515

Epoch: 45| Step: 0
Training loss: 2.403172731399536
Validation loss: 2.5431149005889893

Epoch: 6| Step: 1
Training loss: 2.9117631912231445
Validation loss: 2.5417093634605408

Epoch: 6| Step: 2
Training loss: 2.772850513458252
Validation loss: 2.539353311061859

Epoch: 6| Step: 3
Training loss: 2.816005229949951
Validation loss: 2.537577450275421

Epoch: 6| Step: 4
Training loss: 2.21928071975708
Validation loss: 2.535159150759379

Epoch: 6| Step: 5
Training loss: 3.045936107635498
Validation loss: 2.5339335997899375

Epoch: 6| Step: 6
Training loss: 2.3437271118164062
Validation loss: 2.5314114491144815

Epoch: 6| Step: 7
Training loss: 2.690484046936035
Validation loss: 2.530082106590271

Epoch: 6| Step: 8
Training loss: 2.9710302352905273
Validation loss: 2.5301297903060913

Epoch: 6| Step: 9
Training loss: 3.031649589538574
Validation loss: 2.528212865193685

Epoch: 6| Step: 10
Training loss: 2.7910208702087402
Validation loss: 2.5265843073527017

Epoch: 6| Step: 11
Training loss: 2.8582468032836914
Validation loss: 2.52511457602183

Epoch: 6| Step: 12
Training loss: 2.333292007446289
Validation loss: 2.522374669710795

Epoch: 6| Step: 13
Training loss: 2.984860420227051
Validation loss: 2.518482247988383

Epoch: 46| Step: 0
Training loss: 2.698235511779785
Validation loss: 2.5160717566808066

Epoch: 6| Step: 1
Training loss: 2.5495336055755615
Validation loss: 2.5133838454882302

Epoch: 6| Step: 2
Training loss: 2.467121124267578
Validation loss: 2.5092879136403403

Epoch: 6| Step: 3
Training loss: 2.857435703277588
Validation loss: 2.504661281903585

Epoch: 6| Step: 4
Training loss: 1.7795207500457764
Validation loss: 2.5033332109451294

Epoch: 6| Step: 5
Training loss: 2.6166977882385254
Validation loss: 2.5004954735438027

Epoch: 6| Step: 6
Training loss: 2.988823652267456
Validation loss: 2.4977688789367676

Epoch: 6| Step: 7
Training loss: 2.7138991355895996
Validation loss: 2.494809707005819

Epoch: 6| Step: 8
Training loss: 3.2450501918792725
Validation loss: 2.491734584172567

Epoch: 6| Step: 9
Training loss: 2.1181623935699463
Validation loss: 2.48916494846344

Epoch: 6| Step: 10
Training loss: 2.8573687076568604
Validation loss: 2.4843953053156533

Epoch: 6| Step: 11
Training loss: 3.2574868202209473
Validation loss: 2.4850608309110007

Epoch: 6| Step: 12
Training loss: 2.4641261100769043
Validation loss: 2.482632100582123

Epoch: 6| Step: 13
Training loss: 3.087573289871216
Validation loss: 2.480815867582957

Epoch: 47| Step: 0
Training loss: 2.6472086906433105
Validation loss: 2.4776467084884644

Epoch: 6| Step: 1
Training loss: 2.606243133544922
Validation loss: 2.4771854480107627

Epoch: 6| Step: 2
Training loss: 3.240936756134033
Validation loss: 2.4731006423632302

Epoch: 6| Step: 3
Training loss: 2.9021167755126953
Validation loss: 2.4716542959213257

Epoch: 6| Step: 4
Training loss: 2.9581592082977295
Validation loss: 2.467984437942505

Epoch: 6| Step: 5
Training loss: 1.983993411064148
Validation loss: 2.4673784573872886

Epoch: 6| Step: 6
Training loss: 2.0591466426849365
Validation loss: 2.4655539989471436

Epoch: 6| Step: 7
Training loss: 2.482043504714966
Validation loss: 2.4628199338912964

Epoch: 6| Step: 8
Training loss: 2.7719130516052246
Validation loss: 2.463373382886251

Epoch: 6| Step: 9
Training loss: 2.7090470790863037
Validation loss: 2.465845227241516

Epoch: 6| Step: 10
Training loss: 2.8342156410217285
Validation loss: 2.462760806083679

Epoch: 6| Step: 11
Training loss: 2.963639497756958
Validation loss: 2.455507755279541

Epoch: 6| Step: 12
Training loss: 2.528489828109741
Validation loss: 2.4502710898717246

Epoch: 6| Step: 13
Training loss: 2.5255799293518066
Validation loss: 2.44766096274058

Epoch: 48| Step: 0
Training loss: 2.5769853591918945
Validation loss: 2.448843558629354

Epoch: 6| Step: 1
Training loss: 3.482572555541992
Validation loss: 2.450006067752838

Epoch: 6| Step: 2
Training loss: 2.6337928771972656
Validation loss: 2.449881990750631

Epoch: 6| Step: 3
Training loss: 3.2588772773742676
Validation loss: 2.448262174924215

Epoch: 6| Step: 4
Training loss: 2.6505396366119385
Validation loss: 2.448455055554708

Epoch: 6| Step: 5
Training loss: 1.9074437618255615
Validation loss: 2.443582057952881

Epoch: 6| Step: 6
Training loss: 3.352064847946167
Validation loss: 2.4417436917622886

Epoch: 6| Step: 7
Training loss: 2.273740768432617
Validation loss: 2.4336325327555337

Epoch: 6| Step: 8
Training loss: 2.5918619632720947
Validation loss: 2.4325957695643106

Epoch: 6| Step: 9
Training loss: 2.0528669357299805
Validation loss: 2.427791396776835

Epoch: 6| Step: 10
Training loss: 2.4528963565826416
Validation loss: 2.4233285188674927

Epoch: 6| Step: 11
Training loss: 2.3828606605529785
Validation loss: 2.4229872624079385

Epoch: 6| Step: 12
Training loss: 2.29288649559021
Validation loss: 2.4229782223701477

Epoch: 6| Step: 13
Training loss: 2.888517141342163
Validation loss: 2.4213252663612366

Epoch: 49| Step: 0
Training loss: 2.4093260765075684
Validation loss: 2.417687197526296

Epoch: 6| Step: 1
Training loss: 2.604475736618042
Validation loss: 2.414323170979818

Epoch: 6| Step: 2
Training loss: 2.5658388137817383
Validation loss: 2.4112481673558555

Epoch: 6| Step: 3
Training loss: 3.153536319732666
Validation loss: 2.4078469276428223

Epoch: 6| Step: 4
Training loss: 3.0785961151123047
Validation loss: 2.403200626373291

Epoch: 6| Step: 5
Training loss: 1.6496392488479614
Validation loss: 2.4025962948799133

Epoch: 6| Step: 6
Training loss: 2.844543933868408
Validation loss: 2.401614546775818

Epoch: 6| Step: 7
Training loss: 2.289123296737671
Validation loss: 2.39821728070577

Epoch: 6| Step: 8
Training loss: 2.0583853721618652
Validation loss: 2.3983492056528726

Epoch: 6| Step: 9
Training loss: 2.5768706798553467
Validation loss: 2.3974700768788657

Epoch: 6| Step: 10
Training loss: 3.327202796936035
Validation loss: 2.4029493729273477

Epoch: 6| Step: 11
Training loss: 2.473794937133789
Validation loss: 2.3898704449335733

Epoch: 6| Step: 12
Training loss: 2.2503342628479004
Validation loss: 2.3857808113098145

Epoch: 6| Step: 13
Training loss: 2.9941835403442383
Validation loss: 2.3861347834269204

Epoch: 50| Step: 0
Training loss: 2.1410105228424072
Validation loss: 2.3894104758898416

Epoch: 6| Step: 1
Training loss: 2.2585573196411133
Validation loss: 2.38883646329244

Epoch: 6| Step: 2
Training loss: 2.273409128189087
Validation loss: 2.388356606165568

Epoch: 6| Step: 3
Training loss: 2.9328134059906006
Validation loss: 2.3883211612701416

Epoch: 6| Step: 4
Training loss: 2.5134778022766113
Validation loss: 2.387784242630005

Epoch: 6| Step: 5
Training loss: 2.594407558441162
Validation loss: 2.3854342301686606

Epoch: 6| Step: 6
Training loss: 2.5125865936279297
Validation loss: 2.3829087813695273

Epoch: 6| Step: 7
Training loss: 2.9899988174438477
Validation loss: 2.383092761039734

Epoch: 6| Step: 8
Training loss: 2.628448009490967
Validation loss: 2.3820475737253823

Epoch: 6| Step: 9
Training loss: 2.1257457733154297
Validation loss: 2.379404306411743

Epoch: 6| Step: 10
Training loss: 2.6669974327087402
Validation loss: 2.374133070309957

Epoch: 6| Step: 11
Training loss: 2.9366884231567383
Validation loss: 2.3710519671440125

Epoch: 6| Step: 12
Training loss: 2.5109503269195557
Validation loss: 2.3674704233805337

Epoch: 6| Step: 13
Training loss: 2.7909035682678223
Validation loss: 2.3662866751352944

Epoch: 51| Step: 0
Training loss: 2.538085460662842
Validation loss: 2.3638652165730796

Epoch: 6| Step: 1
Training loss: 2.1992695331573486
Validation loss: 2.358877658843994

Epoch: 6| Step: 2
Training loss: 2.1780412197113037
Validation loss: 2.3538767099380493

Epoch: 6| Step: 3
Training loss: 2.4443814754486084
Validation loss: 2.3515027364095054

Epoch: 6| Step: 4
Training loss: 2.8541531562805176
Validation loss: 2.353069265683492

Epoch: 6| Step: 5
Training loss: 2.7058510780334473
Validation loss: 2.3494584560394287

Epoch: 6| Step: 6
Training loss: 2.0306501388549805
Validation loss: 2.3434922297795615

Epoch: 6| Step: 7
Training loss: 3.015385627746582
Validation loss: 2.3411277532577515

Epoch: 6| Step: 8
Training loss: 2.1836490631103516
Validation loss: 2.3407263358434043

Epoch: 6| Step: 9
Training loss: 3.2058019638061523
Validation loss: 2.3378527959187827

Epoch: 6| Step: 10
Training loss: 1.816650390625
Validation loss: 2.336487372716268

Epoch: 6| Step: 11
Training loss: 3.1892051696777344
Validation loss: 2.3335994680722556

Epoch: 6| Step: 12
Training loss: 2.542360305786133
Validation loss: 2.3334668477376304

Epoch: 6| Step: 13
Training loss: 2.451530933380127
Validation loss: 2.330882251262665

Epoch: 52| Step: 0
Training loss: 2.972525119781494
Validation loss: 2.3290725151697793

Epoch: 6| Step: 1
Training loss: 2.5579090118408203
Validation loss: 2.3243835965792337

Epoch: 6| Step: 2
Training loss: 2.162154197692871
Validation loss: 2.3233171105384827

Epoch: 6| Step: 3
Training loss: 2.6369810104370117
Validation loss: 2.323554297288259

Epoch: 6| Step: 4
Training loss: 2.378047227859497
Validation loss: 2.3226125637690225

Epoch: 6| Step: 5
Training loss: 2.6542062759399414
Validation loss: 2.3169174989064536

Epoch: 6| Step: 6
Training loss: 2.2560839653015137
Validation loss: 2.318708380063375

Epoch: 6| Step: 7
Training loss: 2.657655715942383
Validation loss: 2.3114002545674643

Epoch: 6| Step: 8
Training loss: 2.1424062252044678
Validation loss: 2.3086110750834146

Epoch: 6| Step: 9
Training loss: 2.7389395236968994
Validation loss: 2.3094415863355002

Epoch: 6| Step: 10
Training loss: 2.424328327178955
Validation loss: 2.3052024841308594

Epoch: 6| Step: 11
Training loss: 2.402919292449951
Validation loss: 2.3029538790384927

Epoch: 6| Step: 12
Training loss: 2.5284829139709473
Validation loss: 2.3057796160380044

Epoch: 6| Step: 13
Training loss: 2.3414087295532227
Validation loss: 2.301174441973368

Epoch: 53| Step: 0
Training loss: 2.3236186504364014
Validation loss: 2.298796772956848

Epoch: 6| Step: 1
Training loss: 2.9649548530578613
Validation loss: 2.2971155246098838

Epoch: 6| Step: 2
Training loss: 2.4842658042907715
Validation loss: 2.2923916578292847

Epoch: 6| Step: 3
Training loss: 2.349039077758789
Validation loss: 2.2920355796813965

Epoch: 6| Step: 4
Training loss: 2.145756721496582
Validation loss: 2.2926655809084573

Epoch: 6| Step: 5
Training loss: 2.616511344909668
Validation loss: 2.289755622545878

Epoch: 6| Step: 6
Training loss: 2.65970516204834
Validation loss: 2.2893784046173096

Epoch: 6| Step: 7
Training loss: 2.179112434387207
Validation loss: 2.2833867271741233

Epoch: 6| Step: 8
Training loss: 3.0432469844818115
Validation loss: 2.2814257542292276

Epoch: 6| Step: 9
Training loss: 2.2270801067352295
Validation loss: 2.2850318948427835

Epoch: 6| Step: 10
Training loss: 2.5085694789886475
Validation loss: 2.2783490419387817

Epoch: 6| Step: 11
Training loss: 1.899214506149292
Validation loss: 2.279135266939799

Epoch: 6| Step: 12
Training loss: 2.188833713531494
Validation loss: 2.2760393420855203

Epoch: 6| Step: 13
Training loss: 2.8487117290496826
Validation loss: 2.275898297627767

Epoch: 54| Step: 0
Training loss: 2.6823065280914307
Validation loss: 2.2704685727755227

Epoch: 6| Step: 1
Training loss: 2.0864267349243164
Validation loss: 2.2681479454040527

Epoch: 6| Step: 2
Training loss: 3.149616241455078
Validation loss: 2.2683780789375305

Epoch: 6| Step: 3
Training loss: 2.293551206588745
Validation loss: 2.2697629928588867

Epoch: 6| Step: 4
Training loss: 2.7135205268859863
Validation loss: 2.262234687805176

Epoch: 6| Step: 5
Training loss: 2.161229372024536
Validation loss: 2.261118531227112

Epoch: 6| Step: 6
Training loss: 2.7080483436584473
Validation loss: 2.2579983870188394

Epoch: 6| Step: 7
Training loss: 2.294686794281006
Validation loss: 2.2569374243418374

Epoch: 6| Step: 8
Training loss: 2.3007712364196777
Validation loss: 2.256256858507792

Epoch: 6| Step: 9
Training loss: 2.2365763187408447
Validation loss: 2.2521836360295615

Epoch: 6| Step: 10
Training loss: 2.3362534046173096
Validation loss: 2.250951131184896

Epoch: 6| Step: 11
Training loss: 1.8485407829284668
Validation loss: 2.2467625737190247

Epoch: 6| Step: 12
Training loss: 2.6992571353912354
Validation loss: 2.246913174788157

Epoch: 6| Step: 13
Training loss: 2.4468677043914795
Validation loss: 2.24688587586085

Epoch: 55| Step: 0
Training loss: 1.7853832244873047
Validation loss: 2.2423961559931436

Epoch: 6| Step: 1
Training loss: 2.0633151531219482
Validation loss: 2.2419856588045755

Epoch: 6| Step: 2
Training loss: 2.7675976753234863
Validation loss: 2.2433656255404153

Epoch: 6| Step: 3
Training loss: 2.315060615539551
Validation loss: 2.2423205375671387

Epoch: 6| Step: 4
Training loss: 2.669656276702881
Validation loss: 2.2398392955462136

Epoch: 6| Step: 5
Training loss: 2.858053207397461
Validation loss: 2.239899476369222

Epoch: 6| Step: 6
Training loss: 2.5713887214660645
Validation loss: 2.2360275785128274

Epoch: 6| Step: 7
Training loss: 2.7351279258728027
Validation loss: 2.232767919699351

Epoch: 6| Step: 8
Training loss: 2.2525365352630615
Validation loss: 2.2311968406041465

Epoch: 6| Step: 9
Training loss: 2.5481386184692383
Validation loss: 2.230951110521952

Epoch: 6| Step: 10
Training loss: 2.1215577125549316
Validation loss: 2.2279566725095115

Epoch: 6| Step: 11
Training loss: 2.341926097869873
Validation loss: 2.226417342821757

Epoch: 6| Step: 12
Training loss: 2.1887807846069336
Validation loss: 2.2377544244130454

Epoch: 6| Step: 13
Training loss: 2.5024490356445312
Validation loss: 2.2321611444155374

Epoch: 56| Step: 0
Training loss: 2.3775792121887207
Validation loss: 2.2242093880971274

Epoch: 6| Step: 1
Training loss: 2.1291024684906006
Validation loss: 2.2222349643707275

Epoch: 6| Step: 2
Training loss: 2.637453317642212
Validation loss: 2.2214795351028442

Epoch: 6| Step: 3
Training loss: 2.340728282928467
Validation loss: 2.223746657371521

Epoch: 6| Step: 4
Training loss: 1.2636209726333618
Validation loss: 2.231309195359548

Epoch: 6| Step: 5
Training loss: 2.437915802001953
Validation loss: 2.2320700883865356

Epoch: 6| Step: 6
Training loss: 2.6873464584350586
Validation loss: 2.2315234740575156

Epoch: 6| Step: 7
Training loss: 2.5613901615142822
Validation loss: 2.228135605653127

Epoch: 6| Step: 8
Training loss: 3.0534157752990723
Validation loss: 2.2260694901148477

Epoch: 6| Step: 9
Training loss: 2.265687942504883
Validation loss: 2.2211320400238037

Epoch: 6| Step: 10
Training loss: 2.491339921951294
Validation loss: 2.2116259336471558

Epoch: 6| Step: 11
Training loss: 2.5812339782714844
Validation loss: 2.2079151471455893

Epoch: 6| Step: 12
Training loss: 2.353883743286133
Validation loss: 2.2043621142705283

Epoch: 6| Step: 13
Training loss: 2.2219645977020264
Validation loss: 2.20371675491333

Epoch: 57| Step: 0
Training loss: 2.2091002464294434
Validation loss: 2.2000975608825684

Epoch: 6| Step: 1
Training loss: 2.7637906074523926
Validation loss: 2.1927978793780007

Epoch: 6| Step: 2
Training loss: 2.487353563308716
Validation loss: 2.1933022141456604

Epoch: 6| Step: 3
Training loss: 1.7088626623153687
Validation loss: 2.1895671685536704

Epoch: 6| Step: 4
Training loss: 2.642988681793213
Validation loss: 2.2010405460993447

Epoch: 6| Step: 5
Training loss: 2.9685091972351074
Validation loss: 2.194806456565857

Epoch: 6| Step: 6
Training loss: 1.7927848100662231
Validation loss: 2.1946516235669455

Epoch: 6| Step: 7
Training loss: 2.709836006164551
Validation loss: 2.1871031324068704

Epoch: 6| Step: 8
Training loss: 1.1849154233932495
Validation loss: 2.1880223155021667

Epoch: 6| Step: 9
Training loss: 2.5321269035339355
Validation loss: 2.1861798763275146

Epoch: 6| Step: 10
Training loss: 2.123873233795166
Validation loss: 2.1908525228500366

Epoch: 6| Step: 11
Training loss: 2.777965545654297
Validation loss: 2.188916345437368

Epoch: 6| Step: 12
Training loss: 2.5824570655822754
Validation loss: 2.190981686115265

Epoch: 6| Step: 13
Training loss: 2.547553777694702
Validation loss: 2.1924432118733725

Epoch: 58| Step: 0
Training loss: 2.1515231132507324
Validation loss: 2.190654476483663

Epoch: 6| Step: 1
Training loss: 2.0126304626464844
Validation loss: 2.189587195714315

Epoch: 6| Step: 2
Training loss: 2.8754777908325195
Validation loss: 2.1883838971455893

Epoch: 6| Step: 3
Training loss: 2.00860333442688
Validation loss: 2.189443747202555

Epoch: 6| Step: 4
Training loss: 2.662660598754883
Validation loss: 2.1855600674947104

Epoch: 6| Step: 5
Training loss: 2.3068478107452393
Validation loss: 2.183935284614563

Epoch: 6| Step: 6
Training loss: 2.584989309310913
Validation loss: 2.1828523675600686

Epoch: 6| Step: 7
Training loss: 2.0928797721862793
Validation loss: 2.1817959547042847

Epoch: 6| Step: 8
Training loss: 2.4054641723632812
Validation loss: 2.1764042576154075

Epoch: 6| Step: 9
Training loss: 2.437143564224243
Validation loss: 2.1768610874811807

Epoch: 6| Step: 10
Training loss: 1.8588510751724243
Validation loss: 2.171101450920105

Epoch: 6| Step: 11
Training loss: 2.9955921173095703
Validation loss: 2.1706993778546653

Epoch: 6| Step: 12
Training loss: 2.0985565185546875
Validation loss: 2.167122960090637

Epoch: 6| Step: 13
Training loss: 2.3538312911987305
Validation loss: 2.16620804866155

Epoch: 59| Step: 0
Training loss: 2.0224194526672363
Validation loss: 2.1691287557284036

Epoch: 6| Step: 1
Training loss: 2.612344980239868
Validation loss: 2.1654647986094155

Epoch: 6| Step: 2
Training loss: 2.917336940765381
Validation loss: 2.1660803953806558

Epoch: 6| Step: 3
Training loss: 2.090904712677002
Validation loss: 2.1625176668167114

Epoch: 6| Step: 4
Training loss: 1.691317081451416
Validation loss: 2.1572083234786987

Epoch: 6| Step: 5
Training loss: 2.519045829772949
Validation loss: 2.1562836170196533

Epoch: 6| Step: 6
Training loss: 2.0004024505615234
Validation loss: 2.1548362374305725

Epoch: 6| Step: 7
Training loss: 1.6955920457839966
Validation loss: 2.15927783648173

Epoch: 6| Step: 8
Training loss: 2.9568042755126953
Validation loss: 2.159818967183431

Epoch: 6| Step: 9
Training loss: 1.884134292602539
Validation loss: 2.1596270402272544

Epoch: 6| Step: 10
Training loss: 2.555727243423462
Validation loss: 2.16293865442276

Epoch: 6| Step: 11
Training loss: 2.4327499866485596
Validation loss: 2.1626270413398743

Epoch: 6| Step: 12
Training loss: 2.5169615745544434
Validation loss: 2.1646650234858194

Epoch: 6| Step: 13
Training loss: 2.833512783050537
Validation loss: 2.1619003216425576

Epoch: 60| Step: 0
Training loss: 2.6623973846435547
Validation loss: 2.1604201992352805

Epoch: 6| Step: 1
Training loss: 2.194077968597412
Validation loss: 2.160295784473419

Epoch: 6| Step: 2
Training loss: 2.424976110458374
Validation loss: 2.157950282096863

Epoch: 6| Step: 3
Training loss: 2.031369209289551
Validation loss: 2.1591000159581504

Epoch: 6| Step: 4
Training loss: 1.6271514892578125
Validation loss: 2.1549165646235147

Epoch: 6| Step: 5
Training loss: 2.8158960342407227
Validation loss: 2.1537904739379883

Epoch: 6| Step: 6
Training loss: 2.3166818618774414
Validation loss: 2.150161643822988

Epoch: 6| Step: 7
Training loss: 2.864199161529541
Validation loss: 2.1502545873324075

Epoch: 6| Step: 8
Training loss: 1.6488213539123535
Validation loss: 2.149342934290568

Epoch: 6| Step: 9
Training loss: 2.888892889022827
Validation loss: 2.1455805897712708

Epoch: 6| Step: 10
Training loss: 2.127653121948242
Validation loss: 2.143117348353068

Epoch: 6| Step: 11
Training loss: 2.5467183589935303
Validation loss: 2.139713168144226

Epoch: 6| Step: 12
Training loss: 2.010960102081299
Validation loss: 2.140334983666738

Epoch: 6| Step: 13
Training loss: 2.2154572010040283
Validation loss: 2.139125863711039

Epoch: 61| Step: 0
Training loss: 1.9247570037841797
Validation loss: 2.134284337361654

Epoch: 6| Step: 1
Training loss: 2.5752296447753906
Validation loss: 2.135425329208374

Epoch: 6| Step: 2
Training loss: 2.531954765319824
Validation loss: 2.1366520325342813

Epoch: 6| Step: 3
Training loss: 3.074786424636841
Validation loss: 2.1388548413912454

Epoch: 6| Step: 4
Training loss: 2.148776054382324
Validation loss: 2.136741896470388

Epoch: 6| Step: 5
Training loss: 1.3566927909851074
Validation loss: 2.131902277469635

Epoch: 6| Step: 6
Training loss: 2.6122689247131348
Validation loss: 2.140706260999044

Epoch: 6| Step: 7
Training loss: 2.13909649848938
Validation loss: 2.154802997907003

Epoch: 6| Step: 8
Training loss: 2.8378186225891113
Validation loss: 2.1487876971562705

Epoch: 6| Step: 9
Training loss: 2.5434303283691406
Validation loss: 2.1358388861020408

Epoch: 6| Step: 10
Training loss: 1.679955244064331
Validation loss: 2.140480319658915

Epoch: 6| Step: 11
Training loss: 2.3341903686523438
Validation loss: 2.1438849171002707

Epoch: 6| Step: 12
Training loss: 2.204599618911743
Validation loss: 2.139887571334839

Epoch: 6| Step: 13
Training loss: 2.3465576171875
Validation loss: 2.1480805476506553

Epoch: 62| Step: 0
Training loss: 1.6434181928634644
Validation loss: 2.12938924630483

Epoch: 6| Step: 1
Training loss: 2.370755195617676
Validation loss: 2.1276409029960632

Epoch: 6| Step: 2
Training loss: 2.3748908042907715
Validation loss: 2.123710870742798

Epoch: 6| Step: 3
Training loss: 1.7053154706954956
Validation loss: 2.1257095336914062

Epoch: 6| Step: 4
Training loss: 2.1452040672302246
Validation loss: 2.130906343460083

Epoch: 6| Step: 5
Training loss: 2.189545154571533
Validation loss: 2.1348156929016113

Epoch: 6| Step: 6
Training loss: 2.2329530715942383
Validation loss: 2.13259094953537

Epoch: 6| Step: 7
Training loss: 2.3498499393463135
Validation loss: 2.133182922999064

Epoch: 6| Step: 8
Training loss: 2.4946179389953613
Validation loss: 2.141324758529663

Epoch: 6| Step: 9
Training loss: 2.3540897369384766
Validation loss: 2.1413148840268454

Epoch: 6| Step: 10
Training loss: 3.0582144260406494
Validation loss: 2.144297401110331

Epoch: 6| Step: 11
Training loss: 2.2644176483154297
Validation loss: 2.1412211457888284

Epoch: 6| Step: 12
Training loss: 2.930079936981201
Validation loss: 2.143639028072357

Epoch: 6| Step: 13
Training loss: 2.3004040718078613
Validation loss: 2.139699876308441

Epoch: 63| Step: 0
Training loss: 2.55294132232666
Validation loss: 2.138768176237742

Epoch: 6| Step: 1
Training loss: 2.0249061584472656
Validation loss: 2.1291822592417398

Epoch: 6| Step: 2
Training loss: 2.6425514221191406
Validation loss: 2.1245550513267517

Epoch: 6| Step: 3
Training loss: 2.735049247741699
Validation loss: 2.1202041506767273

Epoch: 6| Step: 4
Training loss: 2.5715291500091553
Validation loss: 2.119034210840861

Epoch: 6| Step: 5
Training loss: 2.295851469039917
Validation loss: 2.1164111693700156

Epoch: 6| Step: 6
Training loss: 2.342569351196289
Validation loss: 2.11390213171641

Epoch: 6| Step: 7
Training loss: 2.1989331245422363
Validation loss: 2.112840791543325

Epoch: 6| Step: 8
Training loss: 2.394975185394287
Validation loss: 2.112672289212545

Epoch: 6| Step: 9
Training loss: 1.8273385763168335
Validation loss: 2.116769274075826

Epoch: 6| Step: 10
Training loss: 2.100034475326538
Validation loss: 2.1121256152788797

Epoch: 6| Step: 11
Training loss: 2.0024752616882324
Validation loss: 2.1076209346453347

Epoch: 6| Step: 12
Training loss: 2.4048242568969727
Validation loss: 2.1060746908187866

Epoch: 6| Step: 13
Training loss: 2.1133873462677
Validation loss: 2.1082237164179483

Epoch: 64| Step: 0
Training loss: 2.3586738109588623
Validation loss: 2.10365496079127

Epoch: 6| Step: 1
Training loss: 2.296886920928955
Validation loss: 2.1022921204566956

Epoch: 6| Step: 2
Training loss: 2.0666375160217285
Validation loss: 2.097333470980326

Epoch: 6| Step: 3
Training loss: 1.9960379600524902
Validation loss: 2.09634659687678

Epoch: 6| Step: 4
Training loss: 2.233853340148926
Validation loss: 2.1043702761332193

Epoch: 6| Step: 5
Training loss: 2.5252766609191895
Validation loss: 2.1105330983797708

Epoch: 6| Step: 6
Training loss: 2.086350440979004
Validation loss: 2.1187145511309304

Epoch: 6| Step: 7
Training loss: 2.795347213745117
Validation loss: 2.121370236078898

Epoch: 6| Step: 8
Training loss: 2.0519585609436035
Validation loss: 2.1097539265950522

Epoch: 6| Step: 9
Training loss: 2.22165846824646
Validation loss: 2.1027661164601645

Epoch: 6| Step: 10
Training loss: 1.8544930219650269
Validation loss: 2.0976409117380777

Epoch: 6| Step: 11
Training loss: 2.2603001594543457
Validation loss: 2.093531628449758

Epoch: 6| Step: 12
Training loss: 2.9578089714050293
Validation loss: 2.097626348336538

Epoch: 6| Step: 13
Training loss: 2.253666639328003
Validation loss: 2.0961737831433616

Epoch: 65| Step: 0
Training loss: 2.2529592514038086
Validation loss: 2.0964918732643127

Epoch: 6| Step: 1
Training loss: 2.468184471130371
Validation loss: 2.102018137772878

Epoch: 6| Step: 2
Training loss: 2.514876365661621
Validation loss: 2.1028275887171426

Epoch: 6| Step: 3
Training loss: 2.467825412750244
Validation loss: 2.103248198827108

Epoch: 6| Step: 4
Training loss: 2.3708596229553223
Validation loss: 2.103482802708944

Epoch: 6| Step: 5
Training loss: 2.371640682220459
Validation loss: 2.1041582822799683

Epoch: 6| Step: 6
Training loss: 2.6490728855133057
Validation loss: 2.106527407964071

Epoch: 6| Step: 7
Training loss: 1.7477600574493408
Validation loss: 2.1022204955418906

Epoch: 6| Step: 8
Training loss: 1.8028564453125
Validation loss: 2.102908651034037

Epoch: 6| Step: 9
Training loss: 2.032623052597046
Validation loss: 2.102158308029175

Epoch: 6| Step: 10
Training loss: 1.517411708831787
Validation loss: 2.1004405419031777

Epoch: 6| Step: 11
Training loss: 2.493502140045166
Validation loss: 2.0992224415143332

Epoch: 6| Step: 12
Training loss: 2.554520606994629
Validation loss: 2.0960447589556375

Epoch: 6| Step: 13
Training loss: 2.685535430908203
Validation loss: 2.0904715061187744

Epoch: 66| Step: 0
Training loss: 2.3480184078216553
Validation loss: 2.093925694624583

Epoch: 6| Step: 1
Training loss: 2.083531379699707
Validation loss: 2.0894556244214377

Epoch: 6| Step: 2
Training loss: 2.285372018814087
Validation loss: 2.0863373279571533

Epoch: 6| Step: 3
Training loss: 1.886083960533142
Validation loss: 2.0833857655525208

Epoch: 6| Step: 4
Training loss: 2.027531623840332
Validation loss: 2.081227501233419

Epoch: 6| Step: 5
Training loss: 2.0639190673828125
Validation loss: 2.0736458897590637

Epoch: 6| Step: 6
Training loss: 2.5937461853027344
Validation loss: 2.0771235624949136

Epoch: 6| Step: 7
Training loss: 2.2018890380859375
Validation loss: 2.07043186823527

Epoch: 6| Step: 8
Training loss: 2.1276626586914062
Validation loss: 2.075985372066498

Epoch: 6| Step: 9
Training loss: 2.2388055324554443
Validation loss: 2.0737845500310264

Epoch: 6| Step: 10
Training loss: 1.9652626514434814
Validation loss: 2.099666198094686

Epoch: 6| Step: 11
Training loss: 2.9402050971984863
Validation loss: 2.127901534239451

Epoch: 6| Step: 12
Training loss: 2.624516487121582
Validation loss: 2.1490337252616882

Epoch: 6| Step: 13
Training loss: 2.5222597122192383
Validation loss: 2.1769224405288696

Epoch: 67| Step: 0
Training loss: 2.6926376819610596
Validation loss: 2.1261222759882608

Epoch: 6| Step: 1
Training loss: 2.3926355838775635
Validation loss: 2.0903107722600303

Epoch: 6| Step: 2
Training loss: 2.950411081314087
Validation loss: 2.065471808115641

Epoch: 6| Step: 3
Training loss: 2.9000115394592285
Validation loss: 2.0691502491633096

Epoch: 6| Step: 4
Training loss: 2.2487387657165527
Validation loss: 2.068809429804484

Epoch: 6| Step: 5
Training loss: 2.224168300628662
Validation loss: 2.0761872132619223

Epoch: 6| Step: 6
Training loss: 1.6390129327774048
Validation loss: 2.0778799454371133

Epoch: 6| Step: 7
Training loss: 2.1364245414733887
Validation loss: 2.0784117778142295

Epoch: 6| Step: 8
Training loss: 1.8093277215957642
Validation loss: 2.0827989975611367

Epoch: 6| Step: 9
Training loss: 1.780179738998413
Validation loss: 2.084289809068044

Epoch: 6| Step: 10
Training loss: 2.022608518600464
Validation loss: 2.086973468462626

Epoch: 6| Step: 11
Training loss: 2.6786632537841797
Validation loss: 2.092684328556061

Epoch: 6| Step: 12
Training loss: 1.8448055982589722
Validation loss: 2.092291017373403

Epoch: 6| Step: 13
Training loss: 2.569235324859619
Validation loss: 2.0898953676223755

Epoch: 68| Step: 0
Training loss: 2.3381495475769043
Validation loss: 2.0907976627349854

Epoch: 6| Step: 1
Training loss: 2.4748568534851074
Validation loss: 2.0875890254974365

Epoch: 6| Step: 2
Training loss: 2.5617241859436035
Validation loss: 2.0883644223213196

Epoch: 6| Step: 3
Training loss: 2.3499395847320557
Validation loss: 2.083725849787394

Epoch: 6| Step: 4
Training loss: 1.9710667133331299
Validation loss: 2.0815731485684714

Epoch: 6| Step: 5
Training loss: 2.2024354934692383
Validation loss: 2.0814605355262756

Epoch: 6| Step: 6
Training loss: 2.789358139038086
Validation loss: 2.0770036578178406

Epoch: 6| Step: 7
Training loss: 2.0840892791748047
Validation loss: 2.076346536477407

Epoch: 6| Step: 8
Training loss: 1.9610875844955444
Validation loss: 2.0761676828066506

Epoch: 6| Step: 9
Training loss: 2.921187400817871
Validation loss: 2.073371410369873

Epoch: 6| Step: 10
Training loss: 2.142958402633667
Validation loss: 2.07291841506958

Epoch: 6| Step: 11
Training loss: 1.7160652875900269
Validation loss: 2.0706995129585266

Epoch: 6| Step: 12
Training loss: 1.9251832962036133
Validation loss: 2.0693158507347107

Epoch: 6| Step: 13
Training loss: 2.2203361988067627
Validation loss: 2.0645480950673423

Epoch: 69| Step: 0
Training loss: 2.4364495277404785
Validation loss: 2.0621455113093057

Epoch: 6| Step: 1
Training loss: 1.9838156700134277
Validation loss: 2.0619176228841147

Epoch: 6| Step: 2
Training loss: 2.231198310852051
Validation loss: 2.0616528391838074

Epoch: 6| Step: 3
Training loss: 1.780672550201416
Validation loss: 2.058443228403727

Epoch: 6| Step: 4
Training loss: 1.8755351305007935
Validation loss: 2.054339289665222

Epoch: 6| Step: 5
Training loss: 2.745026111602783
Validation loss: 2.0542808771133423

Epoch: 6| Step: 6
Training loss: 2.6032309532165527
Validation loss: 2.0564915935198465

Epoch: 6| Step: 7
Training loss: 2.2501134872436523
Validation loss: 2.0513518253962197

Epoch: 6| Step: 8
Training loss: 2.277947187423706
Validation loss: 2.0546550154685974

Epoch: 6| Step: 9
Training loss: 1.693410873413086
Validation loss: 2.058919092019399

Epoch: 6| Step: 10
Training loss: 2.801516056060791
Validation loss: 2.0584433476130166

Epoch: 6| Step: 11
Training loss: 2.4516499042510986
Validation loss: 2.063153008619944

Epoch: 6| Step: 12
Training loss: 2.333287239074707
Validation loss: 2.0581078131993613

Epoch: 6| Step: 13
Training loss: 1.9066276550292969
Validation loss: 2.059379597504934

Epoch: 70| Step: 0
Training loss: 2.1866188049316406
Validation loss: 2.0609536170959473

Epoch: 6| Step: 1
Training loss: 2.287705659866333
Validation loss: 2.055700977643331

Epoch: 6| Step: 2
Training loss: 2.5533905029296875
Validation loss: 2.0596747994422913

Epoch: 6| Step: 3
Training loss: 1.648632287979126
Validation loss: 2.0572468042373657

Epoch: 6| Step: 4
Training loss: 2.2825818061828613
Validation loss: 2.0533719658851624

Epoch: 6| Step: 5
Training loss: 2.2617077827453613
Validation loss: 2.0427464644114175

Epoch: 6| Step: 6
Training loss: 1.8331396579742432
Validation loss: 2.043390452861786

Epoch: 6| Step: 7
Training loss: 2.887845039367676
Validation loss: 2.0372734467188516

Epoch: 6| Step: 8
Training loss: 2.3247787952423096
Validation loss: 2.0341922839482627

Epoch: 6| Step: 9
Training loss: 2.2394111156463623
Validation loss: 2.0345200896263123

Epoch: 6| Step: 10
Training loss: 2.008373737335205
Validation loss: 2.047405461470286

Epoch: 6| Step: 11
Training loss: 2.216071844100952
Validation loss: 2.0482247273127236

Epoch: 6| Step: 12
Training loss: 2.070098876953125
Validation loss: 2.043614466985067

Epoch: 6| Step: 13
Training loss: 2.4573569297790527
Validation loss: 2.044481555620829

Epoch: 71| Step: 0
Training loss: 1.3777908086776733
Validation loss: 2.0375553369522095

Epoch: 6| Step: 1
Training loss: 3.1837174892425537
Validation loss: 2.0403555432955423

Epoch: 6| Step: 2
Training loss: 2.4273507595062256
Validation loss: 2.0371952851613364

Epoch: 6| Step: 3
Training loss: 2.169623851776123
Validation loss: 2.036661465962728

Epoch: 6| Step: 4
Training loss: 2.244372844696045
Validation loss: 2.0440142154693604

Epoch: 6| Step: 5
Training loss: 2.4303507804870605
Validation loss: 2.045518696308136

Epoch: 6| Step: 6
Training loss: 2.4234821796417236
Validation loss: 2.0369690656661987

Epoch: 6| Step: 7
Training loss: 1.965094804763794
Validation loss: 2.044214983781179

Epoch: 6| Step: 8
Training loss: 1.8006572723388672
Validation loss: 2.045639971892039

Epoch: 6| Step: 9
Training loss: 1.8430832624435425
Validation loss: 2.0507339239120483

Epoch: 6| Step: 10
Training loss: 1.5141701698303223
Validation loss: 2.0467122395833335

Epoch: 6| Step: 11
Training loss: 2.8982839584350586
Validation loss: 2.0502671003341675

Epoch: 6| Step: 12
Training loss: 2.4303131103515625
Validation loss: 2.0435394644737244

Epoch: 6| Step: 13
Training loss: 2.3640055656433105
Validation loss: 2.0385575691858926

Epoch: 72| Step: 0
Training loss: 3.0416808128356934
Validation loss: 2.0399154225985208

Epoch: 6| Step: 1
Training loss: 2.0470266342163086
Validation loss: 2.036612093448639

Epoch: 6| Step: 2
Training loss: 2.368189811706543
Validation loss: 2.032237470149994

Epoch: 6| Step: 3
Training loss: 1.64393949508667
Validation loss: 2.0316460927327475

Epoch: 6| Step: 4
Training loss: 2.2799086570739746
Validation loss: 2.0294357538223267

Epoch: 6| Step: 5
Training loss: 2.0114688873291016
Validation loss: 2.034739832083384

Epoch: 6| Step: 6
Training loss: 2.777042865753174
Validation loss: 2.039997657140096

Epoch: 6| Step: 7
Training loss: 1.8125954866409302
Validation loss: 2.036387284596761

Epoch: 6| Step: 8
Training loss: 2.2714033126831055
Validation loss: 2.04757551352183

Epoch: 6| Step: 9
Training loss: 1.643782138824463
Validation loss: 2.0448084672292075

Epoch: 6| Step: 10
Training loss: 2.4623546600341797
Validation loss: 2.034753123919169

Epoch: 6| Step: 11
Training loss: 2.2844150066375732
Validation loss: 2.038650691509247

Epoch: 6| Step: 12
Training loss: 2.2113115787506104
Validation loss: 2.0296127597490945

Epoch: 6| Step: 13
Training loss: 2.111520290374756
Validation loss: 2.0379337072372437

Epoch: 73| Step: 0
Training loss: 2.6333580017089844
Validation loss: 2.0293535192807517

Epoch: 6| Step: 1
Training loss: 1.7267534732818604
Validation loss: 2.03729118903478

Epoch: 6| Step: 2
Training loss: 2.579582452774048
Validation loss: 2.028577506542206

Epoch: 6| Step: 3
Training loss: 2.3784313201904297
Validation loss: 2.033240000406901

Epoch: 6| Step: 4
Training loss: 2.700558662414551
Validation loss: 2.028670291105906

Epoch: 6| Step: 5
Training loss: 1.788557529449463
Validation loss: 2.0269153118133545

Epoch: 6| Step: 6
Training loss: 1.8650445938110352
Validation loss: 2.0236062010129294

Epoch: 6| Step: 7
Training loss: 2.8386070728302
Validation loss: 2.028408090273539

Epoch: 6| Step: 8
Training loss: 2.114657402038574
Validation loss: 2.0234323740005493

Epoch: 6| Step: 9
Training loss: 2.414185047149658
Validation loss: 2.0334719816843667

Epoch: 6| Step: 10
Training loss: 2.1950368881225586
Validation loss: 2.035259425640106

Epoch: 6| Step: 11
Training loss: 1.898023009300232
Validation loss: 2.0360803802808127

Epoch: 6| Step: 12
Training loss: 1.8475459814071655
Validation loss: 2.0394150018692017

Epoch: 6| Step: 13
Training loss: 1.9498653411865234
Validation loss: 2.0344563126564026

Epoch: 74| Step: 0
Training loss: 1.266971230506897
Validation loss: 2.0301443139712014

Epoch: 6| Step: 1
Training loss: 2.197450876235962
Validation loss: 2.0241119861602783

Epoch: 6| Step: 2
Training loss: 2.0288469791412354
Validation loss: 2.0250362952550254

Epoch: 6| Step: 3
Training loss: 2.2097315788269043
Validation loss: 2.020397901535034

Epoch: 6| Step: 4
Training loss: 2.022552251815796
Validation loss: 2.021171510219574

Epoch: 6| Step: 5
Training loss: 1.9969878196716309
Validation loss: 2.0219624439875283

Epoch: 6| Step: 6
Training loss: 1.9175209999084473
Validation loss: 2.02029820283254

Epoch: 6| Step: 7
Training loss: 2.307682991027832
Validation loss: 2.017954428990682

Epoch: 6| Step: 8
Training loss: 2.45426607131958
Validation loss: 2.019848048686981

Epoch: 6| Step: 9
Training loss: 2.0411882400512695
Validation loss: 2.0204659899075827

Epoch: 6| Step: 10
Training loss: 2.351841926574707
Validation loss: 2.023707469304403

Epoch: 6| Step: 11
Training loss: 2.193842887878418
Validation loss: 2.0251511534055076

Epoch: 6| Step: 12
Training loss: 2.9928059577941895
Validation loss: 2.0235335429509482

Epoch: 6| Step: 13
Training loss: 2.689824104309082
Validation loss: 2.0231016278266907

Epoch: 75| Step: 0
Training loss: 2.271951675415039
Validation loss: 2.032086114088694

Epoch: 6| Step: 1
Training loss: 1.37166166305542
Validation loss: 2.0286083022753396

Epoch: 6| Step: 2
Training loss: 1.9761712551116943
Validation loss: 2.033158004283905

Epoch: 6| Step: 3
Training loss: 2.4447450637817383
Validation loss: 2.017073929309845

Epoch: 6| Step: 4
Training loss: 2.3882617950439453
Validation loss: 2.0209621588389077

Epoch: 6| Step: 5
Training loss: 2.2333569526672363
Validation loss: 2.024556040763855

Epoch: 6| Step: 6
Training loss: 2.08512544631958
Validation loss: 2.0270389517148337

Epoch: 6| Step: 7
Training loss: 2.539867401123047
Validation loss: 2.023900111516317

Epoch: 6| Step: 8
Training loss: 1.6567890644073486
Validation loss: 2.0196643670399985

Epoch: 6| Step: 9
Training loss: 2.6034064292907715
Validation loss: 2.02446585893631

Epoch: 6| Step: 10
Training loss: 2.240260362625122
Validation loss: 2.026129722595215

Epoch: 6| Step: 11
Training loss: 2.475919246673584
Validation loss: 2.0254592895507812

Epoch: 6| Step: 12
Training loss: 2.008793592453003
Validation loss: 2.030746638774872

Epoch: 6| Step: 13
Training loss: 2.3747479915618896
Validation loss: 2.027998387813568

Epoch: 76| Step: 0
Training loss: 1.9943358898162842
Validation loss: 2.025253494580587

Epoch: 6| Step: 1
Training loss: 2.0952858924865723
Validation loss: 2.0234138568242392

Epoch: 6| Step: 2
Training loss: 1.6912600994110107
Validation loss: 2.0254835883776345

Epoch: 6| Step: 3
Training loss: 2.7967097759246826
Validation loss: 2.022440274556478

Epoch: 6| Step: 4
Training loss: 2.527409076690674
Validation loss: 2.020505726337433

Epoch: 6| Step: 5
Training loss: 1.7004951238632202
Validation loss: 2.0336997310320535

Epoch: 6| Step: 6
Training loss: 2.388061046600342
Validation loss: 2.0359888871510825

Epoch: 6| Step: 7
Training loss: 2.171330690383911
Validation loss: 2.0269782741864524

Epoch: 6| Step: 8
Training loss: 2.6159276962280273
Validation loss: 2.0280354817708335

Epoch: 6| Step: 9
Training loss: 2.218005657196045
Validation loss: 2.0314440727233887

Epoch: 6| Step: 10
Training loss: 1.896535038948059
Validation loss: 2.0322379072507224

Epoch: 6| Step: 11
Training loss: 2.260650634765625
Validation loss: 2.025042712688446

Epoch: 6| Step: 12
Training loss: 2.068189859390259
Validation loss: 2.0257741610209146

Epoch: 6| Step: 13
Training loss: 2.273874044418335
Validation loss: 2.02239598830541

Epoch: 77| Step: 0
Training loss: 2.3582558631896973
Validation loss: 2.019126276175181

Epoch: 6| Step: 1
Training loss: 1.9110790491104126
Validation loss: 2.022020856539408

Epoch: 6| Step: 2
Training loss: 1.9456835985183716
Validation loss: 2.0173380374908447

Epoch: 6| Step: 3
Training loss: 2.6033804416656494
Validation loss: 2.0169041752815247

Epoch: 6| Step: 4
Training loss: 2.5088419914245605
Validation loss: 2.011105934778849

Epoch: 6| Step: 5
Training loss: 2.4373815059661865
Validation loss: 2.0152891476949057

Epoch: 6| Step: 6
Training loss: 1.8816373348236084
Validation loss: 2.016328513622284

Epoch: 6| Step: 7
Training loss: 2.4953527450561523
Validation loss: 2.0185174147288003

Epoch: 6| Step: 8
Training loss: 2.0104832649230957
Validation loss: 2.0098827481269836

Epoch: 6| Step: 9
Training loss: 1.6564176082611084
Validation loss: 2.016511559486389

Epoch: 6| Step: 10
Training loss: 2.1004061698913574
Validation loss: 2.0176905194918313

Epoch: 6| Step: 11
Training loss: 2.176723003387451
Validation loss: 2.014711618423462

Epoch: 6| Step: 12
Training loss: 2.382248640060425
Validation loss: 2.022465765476227

Epoch: 6| Step: 13
Training loss: 2.1304914951324463
Validation loss: 2.025286634763082

Epoch: 78| Step: 0
Training loss: 2.5505592823028564
Validation loss: 2.0208027164141336

Epoch: 6| Step: 1
Training loss: 2.099947690963745
Validation loss: 2.0159876346588135

Epoch: 6| Step: 2
Training loss: 2.3878445625305176
Validation loss: 2.022014101346334

Epoch: 6| Step: 3
Training loss: 2.152951955795288
Validation loss: 2.025788426399231

Epoch: 6| Step: 4
Training loss: 2.157888174057007
Validation loss: 2.0243404110272727

Epoch: 6| Step: 5
Training loss: 1.7218945026397705
Validation loss: 2.027951419353485

Epoch: 6| Step: 6
Training loss: 2.517756700515747
Validation loss: 2.0187273224194846

Epoch: 6| Step: 7
Training loss: 2.1334352493286133
Validation loss: 2.0163644552230835

Epoch: 6| Step: 8
Training loss: 2.3629260063171387
Validation loss: 2.020969053109487

Epoch: 6| Step: 9
Training loss: 1.8096333742141724
Validation loss: 2.025001068909963

Epoch: 6| Step: 10
Training loss: 2.3036487102508545
Validation loss: 2.0294010241826377

Epoch: 6| Step: 11
Training loss: 2.2561826705932617
Validation loss: 2.023172934850057

Epoch: 6| Step: 12
Training loss: 1.962766170501709
Validation loss: 2.029686987400055

Epoch: 6| Step: 13
Training loss: 2.0754666328430176
Validation loss: 2.028913378715515

Epoch: 79| Step: 0
Training loss: 2.211561679840088
Validation loss: 2.0309928258260093

Epoch: 6| Step: 1
Training loss: 2.1939520835876465
Validation loss: 2.0315364003181458

Epoch: 6| Step: 2
Training loss: 2.303286552429199
Validation loss: 2.032371679941813

Epoch: 6| Step: 3
Training loss: 1.8188375234603882
Validation loss: 2.024030844370524

Epoch: 6| Step: 4
Training loss: 1.9643795490264893
Validation loss: 2.0201205809911094

Epoch: 6| Step: 5
Training loss: 2.5047240257263184
Validation loss: 2.0219162702560425

Epoch: 6| Step: 6
Training loss: 2.502253293991089
Validation loss: 2.026375671227773

Epoch: 6| Step: 7
Training loss: 2.4230904579162598
Validation loss: 2.011842211087545

Epoch: 6| Step: 8
Training loss: 1.7777830362319946
Validation loss: 2.019637187321981

Epoch: 6| Step: 9
Training loss: 2.414621591567993
Validation loss: 2.0247952938079834

Epoch: 6| Step: 10
Training loss: 1.8749357461929321
Validation loss: 2.022287428379059

Epoch: 6| Step: 11
Training loss: 1.834567666053772
Validation loss: 2.0250960985819497

Epoch: 6| Step: 12
Training loss: 2.4562816619873047
Validation loss: 2.0243598222732544

Epoch: 6| Step: 13
Training loss: 2.4245080947875977
Validation loss: 2.020129462083181

Epoch: 80| Step: 0
Training loss: 1.9278727769851685
Validation loss: 2.013412654399872

Epoch: 6| Step: 1
Training loss: 2.794285297393799
Validation loss: 2.021799067656199

Epoch: 6| Step: 2
Training loss: 2.227226495742798
Validation loss: 2.0184388558069863

Epoch: 6| Step: 3
Training loss: 2.7188191413879395
Validation loss: 2.023443639278412

Epoch: 6| Step: 4
Training loss: 2.291609525680542
Validation loss: 2.0232207576433816

Epoch: 6| Step: 5
Training loss: 2.296503782272339
Validation loss: 2.0284149050712585

Epoch: 6| Step: 6
Training loss: 2.1574981212615967
Validation loss: 2.028891404469808

Epoch: 6| Step: 7
Training loss: 2.2137622833251953
Validation loss: 2.0349647204081216

Epoch: 6| Step: 8
Training loss: 2.2647576332092285
Validation loss: 2.0354214310646057

Epoch: 6| Step: 9
Training loss: 2.5315279960632324
Validation loss: 2.0259955128033957

Epoch: 6| Step: 10
Training loss: 1.8690485954284668
Validation loss: 2.0201845367749534

Epoch: 6| Step: 11
Training loss: 1.4970765113830566
Validation loss: 2.025773207346598

Epoch: 6| Step: 12
Training loss: 2.1919751167297363
Validation loss: 2.015965243180593

Epoch: 6| Step: 13
Training loss: 1.7061506509780884
Validation loss: 2.0251757899920144

Epoch: 81| Step: 0
Training loss: 2.307481288909912
Validation loss: 2.0185881853103638

Epoch: 6| Step: 1
Training loss: 1.838832139968872
Validation loss: 2.0229156215985618

Epoch: 6| Step: 2
Training loss: 2.1746737957000732
Validation loss: 2.0170949896176658

Epoch: 6| Step: 3
Training loss: 2.2511234283447266
Validation loss: 2.022683600584666

Epoch: 6| Step: 4
Training loss: 2.3258485794067383
Validation loss: 2.0209715167681375

Epoch: 6| Step: 5
Training loss: 2.2529966831207275
Validation loss: 2.0214110215504966

Epoch: 6| Step: 6
Training loss: 2.415544033050537
Validation loss: 2.020434776941935

Epoch: 6| Step: 7
Training loss: 3.0765113830566406
Validation loss: 2.014885902404785

Epoch: 6| Step: 8
Training loss: 1.6781328916549683
Validation loss: 2.012804090976715

Epoch: 6| Step: 9
Training loss: 1.8768666982650757
Validation loss: 2.0207517941792807

Epoch: 6| Step: 10
Training loss: 1.6220192909240723
Validation loss: 2.0172279477119446

Epoch: 6| Step: 11
Training loss: 2.3353378772735596
Validation loss: 2.027691900730133

Epoch: 6| Step: 12
Training loss: 1.8005353212356567
Validation loss: 2.0177589853604636

Epoch: 6| Step: 13
Training loss: 2.3683269023895264
Validation loss: 2.016136586666107

Epoch: 82| Step: 0
Training loss: 2.584157705307007
Validation loss: 2.025411864121755

Epoch: 6| Step: 1
Training loss: 1.5736663341522217
Validation loss: 2.0192337036132812

Epoch: 6| Step: 2
Training loss: 2.1635594367980957
Validation loss: 2.027890145778656

Epoch: 6| Step: 3
Training loss: 2.608264923095703
Validation loss: 2.0345816810925803

Epoch: 6| Step: 4
Training loss: 2.1259963512420654
Validation loss: 2.0257134636243186

Epoch: 6| Step: 5
Training loss: 1.6939418315887451
Validation loss: 2.0277312199274697

Epoch: 6| Step: 6
Training loss: 2.1082603931427
Validation loss: 2.011678695678711

Epoch: 6| Step: 7
Training loss: 1.9042131900787354
Validation loss: 2.016223649183909

Epoch: 6| Step: 8
Training loss: 1.800339698791504
Validation loss: 2.0094388723373413

Epoch: 6| Step: 9
Training loss: 2.5099215507507324
Validation loss: 2.0171703696250916

Epoch: 6| Step: 10
Training loss: 2.1145381927490234
Validation loss: 2.008321781953176

Epoch: 6| Step: 11
Training loss: 2.2742409706115723
Validation loss: 2.0224244197209678

Epoch: 6| Step: 12
Training loss: 2.7608251571655273
Validation loss: 2.036608338356018

Epoch: 6| Step: 13
Training loss: 2.1967430114746094
Validation loss: 2.0353763699531555

Epoch: 83| Step: 0
Training loss: 2.308025360107422
Validation loss: 2.0354091127713523

Epoch: 6| Step: 1
Training loss: 1.594130516052246
Validation loss: 2.037157734235128

Epoch: 6| Step: 2
Training loss: 2.1793556213378906
Validation loss: 2.030324419339498

Epoch: 6| Step: 3
Training loss: 2.6358304023742676
Validation loss: 2.021302421887716

Epoch: 6| Step: 4
Training loss: 2.420653820037842
Validation loss: 2.0236458778381348

Epoch: 6| Step: 5
Training loss: 1.9235725402832031
Validation loss: 2.015165150165558

Epoch: 6| Step: 6
Training loss: 2.5405616760253906
Validation loss: 2.0068295200665793

Epoch: 6| Step: 7
Training loss: 2.3903701305389404
Validation loss: 2.020764410495758

Epoch: 6| Step: 8
Training loss: 2.0884809494018555
Validation loss: 2.0211925705273948

Epoch: 6| Step: 9
Training loss: 2.137850761413574
Validation loss: 2.0187670985857644

Epoch: 6| Step: 10
Training loss: 2.235316276550293
Validation loss: 2.026255428791046

Epoch: 6| Step: 11
Training loss: 1.9877028465270996
Validation loss: 2.0283860762914023

Epoch: 6| Step: 12
Training loss: 1.8425549268722534
Validation loss: 2.0257383584976196

Epoch: 6| Step: 13
Training loss: 2.286487579345703
Validation loss: 2.015806575616201

Epoch: 84| Step: 0
Training loss: 2.6798605918884277
Validation loss: 2.0140059192975364

Epoch: 6| Step: 1
Training loss: 2.39652156829834
Validation loss: 2.0116661190986633

Epoch: 6| Step: 2
Training loss: 1.817431926727295
Validation loss: 2.0162241061528525

Epoch: 6| Step: 3
Training loss: 2.228107452392578
Validation loss: 2.016656776269277

Epoch: 6| Step: 4
Training loss: 2.397428512573242
Validation loss: 2.019433577855428

Epoch: 6| Step: 5
Training loss: 2.358391523361206
Validation loss: 2.029333929220835

Epoch: 6| Step: 6
Training loss: 2.4525723457336426
Validation loss: 2.0300650596618652

Epoch: 6| Step: 7
Training loss: 1.4486219882965088
Validation loss: 2.0301125248273215

Epoch: 6| Step: 8
Training loss: 2.1925716400146484
Validation loss: 2.0278369188308716

Epoch: 6| Step: 9
Training loss: 1.9282552003860474
Validation loss: 2.022979180018107

Epoch: 6| Step: 10
Training loss: 2.0218753814697266
Validation loss: 2.018877387046814

Epoch: 6| Step: 11
Training loss: 1.8654142618179321
Validation loss: 2.0241926511128745

Epoch: 6| Step: 12
Training loss: 2.0632762908935547
Validation loss: 2.0186344385147095

Epoch: 6| Step: 13
Training loss: 2.396930694580078
Validation loss: 2.0120677947998047

Epoch: 85| Step: 0
Training loss: 1.816596269607544
Validation loss: 2.0186723272005715

Epoch: 6| Step: 1
Training loss: 1.8746508359909058
Validation loss: 2.0130919019381204

Epoch: 6| Step: 2
Training loss: 1.8623652458190918
Validation loss: 2.025688429673513

Epoch: 6| Step: 3
Training loss: 2.2777459621429443
Validation loss: 2.026217520236969

Epoch: 6| Step: 4
Training loss: 2.134566307067871
Validation loss: 2.0187916358311973

Epoch: 6| Step: 5
Training loss: 2.1311135292053223
Validation loss: 2.022079288959503

Epoch: 6| Step: 6
Training loss: 2.0555810928344727
Validation loss: 2.0331902503967285

Epoch: 6| Step: 7
Training loss: 2.021696090698242
Validation loss: 2.03211510181427

Epoch: 6| Step: 8
Training loss: 1.7118349075317383
Validation loss: 2.026460607846578

Epoch: 6| Step: 9
Training loss: 2.4077582359313965
Validation loss: 2.023249785105387

Epoch: 6| Step: 10
Training loss: 2.5064518451690674
Validation loss: 2.0257777174313865

Epoch: 6| Step: 11
Training loss: 2.290632963180542
Validation loss: 2.018010675907135

Epoch: 6| Step: 12
Training loss: 2.4864420890808105
Validation loss: 2.0194490551948547

Epoch: 6| Step: 13
Training loss: 2.50803279876709
Validation loss: 2.0175442496935525

Epoch: 86| Step: 0
Training loss: 2.695051908493042
Validation loss: 2.0150620142618814

Epoch: 6| Step: 1
Training loss: 2.368271589279175
Validation loss: 2.031934936841329

Epoch: 6| Step: 2
Training loss: 2.4378786087036133
Validation loss: 2.0292075475056968

Epoch: 6| Step: 3
Training loss: 2.0108723640441895
Validation loss: 2.034049948056539

Epoch: 6| Step: 4
Training loss: 2.2135190963745117
Validation loss: 2.0420967737833657

Epoch: 6| Step: 5
Training loss: 1.9742921590805054
Validation loss: 2.0377674102783203

Epoch: 6| Step: 6
Training loss: 2.054138660430908
Validation loss: 2.0434186458587646

Epoch: 6| Step: 7
Training loss: 1.7211618423461914
Validation loss: 2.043864687283834

Epoch: 6| Step: 8
Training loss: 2.6979496479034424
Validation loss: 2.0392128825187683

Epoch: 6| Step: 9
Training loss: 2.2278990745544434
Validation loss: 2.045385499795278

Epoch: 6| Step: 10
Training loss: 2.158167839050293
Validation loss: 2.038257380326589

Epoch: 6| Step: 11
Training loss: 2.0320143699645996
Validation loss: 2.040460765361786

Epoch: 6| Step: 12
Training loss: 1.5206243991851807
Validation loss: 2.0398189226786294

Epoch: 6| Step: 13
Training loss: 2.712588310241699
Validation loss: 2.0404338240623474

Epoch: 87| Step: 0
Training loss: 2.564668893814087
Validation loss: 2.034289995829264

Epoch: 6| Step: 1
Training loss: 2.3443944454193115
Validation loss: 2.0224905212720237

Epoch: 6| Step: 2
Training loss: 2.3751978874206543
Validation loss: 2.024687111377716

Epoch: 6| Step: 3
Training loss: 2.0739340782165527
Validation loss: 2.0225727756818137

Epoch: 6| Step: 4
Training loss: 1.5435172319412231
Validation loss: 2.0212020675341287

Epoch: 6| Step: 5
Training loss: 3.050105571746826
Validation loss: 2.030660112698873

Epoch: 6| Step: 6
Training loss: 2.083219528198242
Validation loss: 2.0388309160868325

Epoch: 6| Step: 7
Training loss: 1.825738787651062
Validation loss: 2.044735848903656

Epoch: 6| Step: 8
Training loss: 1.7897282838821411
Validation loss: 2.0405659476915994

Epoch: 6| Step: 9
Training loss: 2.322509288787842
Validation loss: 2.0364734133084617

Epoch: 6| Step: 10
Training loss: 2.547976016998291
Validation loss: 2.031879266103109

Epoch: 6| Step: 11
Training loss: 1.8191001415252686
Validation loss: 2.0268754959106445

Epoch: 6| Step: 12
Training loss: 2.709456443786621
Validation loss: 2.01411642630895

Epoch: 6| Step: 13
Training loss: 1.4300141334533691
Validation loss: 2.009838322798411

Epoch: 88| Step: 0
Training loss: 2.3629043102264404
Validation loss: 2.01233301560084

Epoch: 6| Step: 1
Training loss: 2.4057979583740234
Validation loss: 2.01151305437088

Epoch: 6| Step: 2
Training loss: 1.710341453552246
Validation loss: 2.0144245425860086

Epoch: 6| Step: 3
Training loss: 1.9514809846878052
Validation loss: 2.0215363105138144

Epoch: 6| Step: 4
Training loss: 2.3070874214172363
Validation loss: 2.0234702825546265

Epoch: 6| Step: 5
Training loss: 2.274533271789551
Validation loss: 2.025516231854757

Epoch: 6| Step: 6
Training loss: 2.3093886375427246
Validation loss: 2.0290731390317283

Epoch: 6| Step: 7
Training loss: 2.695420026779175
Validation loss: 2.028602103392283

Epoch: 6| Step: 8
Training loss: 2.0074989795684814
Validation loss: 2.024912416934967

Epoch: 6| Step: 9
Training loss: 2.038867473602295
Validation loss: 2.017669061819712

Epoch: 6| Step: 10
Training loss: 2.6626553535461426
Validation loss: 2.0188241799672446

Epoch: 6| Step: 11
Training loss: 2.0122673511505127
Validation loss: 2.0090335806210837

Epoch: 6| Step: 12
Training loss: 2.3352715969085693
Validation loss: 1.9988527297973633

Epoch: 6| Step: 13
Training loss: 1.4882733821868896
Validation loss: 1.9945728580156963

Epoch: 89| Step: 0
Training loss: 2.8640432357788086
Validation loss: 2.0012810826301575

Epoch: 6| Step: 1
Training loss: 1.9981379508972168
Validation loss: 2.0037906964619956

Epoch: 6| Step: 2
Training loss: 2.1912953853607178
Validation loss: 2.000960191090902

Epoch: 6| Step: 3
Training loss: 2.3562569618225098
Validation loss: 2.0016834338506064

Epoch: 6| Step: 4
Training loss: 1.5565133094787598
Validation loss: 1.9971985816955566

Epoch: 6| Step: 5
Training loss: 1.9709526300430298
Validation loss: 2.00300125281016

Epoch: 6| Step: 6
Training loss: 1.6704952716827393
Validation loss: 1.999999721844991

Epoch: 6| Step: 7
Training loss: 2.2014827728271484
Validation loss: 2.005340794722239

Epoch: 6| Step: 8
Training loss: 2.379840135574341
Validation loss: 2.0013339519500732

Epoch: 6| Step: 9
Training loss: 2.0520153045654297
Validation loss: 1.999911646048228

Epoch: 6| Step: 10
Training loss: 2.2227025032043457
Validation loss: 2.0025784174601235

Epoch: 6| Step: 11
Training loss: 1.8433070182800293
Validation loss: 1.9986712336540222

Epoch: 6| Step: 12
Training loss: 1.8726434707641602
Validation loss: 2.0031688610712686

Epoch: 6| Step: 13
Training loss: 3.0423641204833984
Validation loss: 2.010559697945913

Epoch: 90| Step: 0
Training loss: 2.2401328086853027
Validation loss: 2.0097455978393555

Epoch: 6| Step: 1
Training loss: 1.9820674657821655
Validation loss: 2.021078129609426

Epoch: 6| Step: 2
Training loss: 2.5830602645874023
Validation loss: 2.016904056072235

Epoch: 6| Step: 3
Training loss: 2.577852725982666
Validation loss: 2.0379398663838706

Epoch: 6| Step: 4
Training loss: 1.7582149505615234
Validation loss: 2.031127134958903

Epoch: 6| Step: 5
Training loss: 1.8569400310516357
Validation loss: 2.0337610642115274

Epoch: 6| Step: 6
Training loss: 1.8642864227294922
Validation loss: 2.0351540446281433

Epoch: 6| Step: 7
Training loss: 2.6627023220062256
Validation loss: 2.029988487561544

Epoch: 6| Step: 8
Training loss: 1.2483248710632324
Validation loss: 2.0171925822893777

Epoch: 6| Step: 9
Training loss: 2.5765256881713867
Validation loss: 2.0051007866859436

Epoch: 6| Step: 10
Training loss: 3.068843126296997
Validation loss: 2.007520397504171

Epoch: 6| Step: 11
Training loss: 1.7508453130722046
Validation loss: 2.013101577758789

Epoch: 6| Step: 12
Training loss: 2.2108190059661865
Validation loss: 2.013209064801534

Epoch: 6| Step: 13
Training loss: 1.7379239797592163
Validation loss: 2.0138367215792337

Epoch: 91| Step: 0
Training loss: 1.997981071472168
Validation loss: 2.013063967227936

Epoch: 6| Step: 1
Training loss: 2.9580793380737305
Validation loss: 2.0172468423843384

Epoch: 6| Step: 2
Training loss: 2.4595775604248047
Validation loss: 2.0093478163083396

Epoch: 6| Step: 3
Training loss: 2.4071428775787354
Validation loss: 2.0100598335266113

Epoch: 6| Step: 4
Training loss: 1.678565263748169
Validation loss: 2.0047707557678223

Epoch: 6| Step: 5
Training loss: 2.4114441871643066
Validation loss: 2.00370321671168

Epoch: 6| Step: 6
Training loss: 1.8807227611541748
Validation loss: 2.004923105239868

Epoch: 6| Step: 7
Training loss: 2.6559486389160156
Validation loss: 1.9974409739176433

Epoch: 6| Step: 8
Training loss: 1.4811652898788452
Validation loss: 2.0080902576446533

Epoch: 6| Step: 9
Training loss: 2.0728888511657715
Validation loss: 2.0092954436937966

Epoch: 6| Step: 10
Training loss: 2.272374391555786
Validation loss: 2.0125481883684793

Epoch: 6| Step: 11
Training loss: 1.9330679178237915
Validation loss: 2.027657469113668

Epoch: 6| Step: 12
Training loss: 1.9798680543899536
Validation loss: 2.0300055146217346

Epoch: 6| Step: 13
Training loss: 2.119184970855713
Validation loss: 2.0405750473340354

Epoch: 92| Step: 0
Training loss: 2.069051742553711
Validation loss: 2.0327104330062866

Epoch: 6| Step: 1
Training loss: 2.1151885986328125
Validation loss: 2.0292022029558816

Epoch: 6| Step: 2
Training loss: 2.1433653831481934
Validation loss: 2.021272857983907

Epoch: 6| Step: 3
Training loss: 1.7774659395217896
Validation loss: 2.013255755106608

Epoch: 6| Step: 4
Training loss: 2.1889114379882812
Validation loss: 2.0032187501589456

Epoch: 6| Step: 5
Training loss: 2.434363603591919
Validation loss: 2.016901751359304

Epoch: 6| Step: 6
Training loss: 2.9726123809814453
Validation loss: 2.010442773501078

Epoch: 6| Step: 7
Training loss: 2.6386959552764893
Validation loss: 2.0130558013916016

Epoch: 6| Step: 8
Training loss: 2.1429457664489746
Validation loss: 2.009135286013285

Epoch: 6| Step: 9
Training loss: 1.8374065160751343
Validation loss: 2.012451966603597

Epoch: 6| Step: 10
Training loss: 1.7241371870040894
Validation loss: 2.014765282471975

Epoch: 6| Step: 11
Training loss: 1.8335297107696533
Validation loss: 2.016213913758596

Epoch: 6| Step: 12
Training loss: 1.7885289192199707
Validation loss: 2.026462813218435

Epoch: 6| Step: 13
Training loss: 2.5359034538269043
Validation loss: 2.019329766432444

Epoch: 93| Step: 0
Training loss: 1.9946722984313965
Validation loss: 2.0258672634760537

Epoch: 6| Step: 1
Training loss: 1.8898651599884033
Validation loss: 2.022746821244558

Epoch: 6| Step: 2
Training loss: 1.8759764432907104
Validation loss: 2.028630097707113

Epoch: 6| Step: 3
Training loss: 2.2227694988250732
Validation loss: 2.036660373210907

Epoch: 6| Step: 4
Training loss: 2.1066925525665283
Validation loss: 2.030329644680023

Epoch: 6| Step: 5
Training loss: 1.9757953882217407
Validation loss: 2.0195754170417786

Epoch: 6| Step: 6
Training loss: 1.995178461074829
Validation loss: 2.0203464031219482

Epoch: 6| Step: 7
Training loss: 2.3943164348602295
Validation loss: 2.0165442625681558

Epoch: 6| Step: 8
Training loss: 2.11932110786438
Validation loss: 2.0172996123631797

Epoch: 6| Step: 9
Training loss: 1.9805313348770142
Validation loss: 2.0091883142789206

Epoch: 6| Step: 10
Training loss: 2.6007909774780273
Validation loss: 2.0084803899129233

Epoch: 6| Step: 11
Training loss: 2.668826103210449
Validation loss: 2.0133622686068215

Epoch: 6| Step: 12
Training loss: 2.273225784301758
Validation loss: 2.01005228360494

Epoch: 6| Step: 13
Training loss: 1.7415225505828857
Validation loss: 2.0073825120925903

Epoch: 94| Step: 0
Training loss: 2.966542959213257
Validation loss: 2.008852561314901

Epoch: 6| Step: 1
Training loss: 2.5185165405273438
Validation loss: 2.0162920157114663

Epoch: 6| Step: 2
Training loss: 1.9701255559921265
Validation loss: 2.0132965644200644

Epoch: 6| Step: 3
Training loss: 2.0493946075439453
Validation loss: 2.021539866924286

Epoch: 6| Step: 4
Training loss: 2.5102474689483643
Validation loss: 2.024936238924662

Epoch: 6| Step: 5
Training loss: 2.273056745529175
Validation loss: 2.031276524066925

Epoch: 6| Step: 6
Training loss: 1.6816056966781616
Validation loss: 2.0174866318702698

Epoch: 6| Step: 7
Training loss: 2.1158437728881836
Validation loss: 2.0226719776789346

Epoch: 6| Step: 8
Training loss: 1.8037364482879639
Validation loss: 2.019597053527832

Epoch: 6| Step: 9
Training loss: 2.447202205657959
Validation loss: 2.014166533946991

Epoch: 6| Step: 10
Training loss: 1.5529013872146606
Validation loss: 2.01034152507782

Epoch: 6| Step: 11
Training loss: 1.8114584684371948
Validation loss: 2.013000786304474

Epoch: 6| Step: 12
Training loss: 1.7416175603866577
Validation loss: 2.016105572382609

Epoch: 6| Step: 13
Training loss: 2.483041763305664
Validation loss: 2.0180894136428833

Epoch: 95| Step: 0
Training loss: 2.570363998413086
Validation loss: 2.021995743115743

Epoch: 6| Step: 1
Training loss: 1.6244313716888428
Validation loss: 2.0246822436650596

Epoch: 6| Step: 2
Training loss: 2.001180648803711
Validation loss: 2.0173064867655435

Epoch: 6| Step: 3
Training loss: 2.2818822860717773
Validation loss: 2.0190072059631348

Epoch: 6| Step: 4
Training loss: 2.7658791542053223
Validation loss: 2.0137595335642495

Epoch: 6| Step: 5
Training loss: 2.069866180419922
Validation loss: 2.0177581906318665

Epoch: 6| Step: 6
Training loss: 2.235563039779663
Validation loss: 2.021290361881256

Epoch: 6| Step: 7
Training loss: 2.0817322731018066
Validation loss: 2.028586288293203

Epoch: 6| Step: 8
Training loss: 1.6135646104812622
Validation loss: 2.027219990889231

Epoch: 6| Step: 9
Training loss: 2.3075668811798096
Validation loss: 2.00586473941803

Epoch: 6| Step: 10
Training loss: 1.4828755855560303
Validation loss: 2.01161136229833

Epoch: 6| Step: 11
Training loss: 2.8971564769744873
Validation loss: 2.010404904683431

Epoch: 6| Step: 12
Training loss: 2.0987889766693115
Validation loss: 2.01375683148702

Epoch: 6| Step: 13
Training loss: 1.775595784187317
Validation loss: 2.0087474981943765

Epoch: 96| Step: 0
Training loss: 1.8483707904815674
Validation loss: 2.0165865818659463

Epoch: 6| Step: 1
Training loss: 2.4712321758270264
Validation loss: 2.0102299451828003

Epoch: 6| Step: 2
Training loss: 2.227078437805176
Validation loss: 2.010120769341787

Epoch: 6| Step: 3
Training loss: 2.2706098556518555
Validation loss: 2.0071959495544434

Epoch: 6| Step: 4
Training loss: 2.7408933639526367
Validation loss: 2.013082583745321

Epoch: 6| Step: 5
Training loss: 1.9196559190750122
Validation loss: 2.0070446928342185

Epoch: 6| Step: 6
Training loss: 2.329239845275879
Validation loss: 2.026781439781189

Epoch: 6| Step: 7
Training loss: 2.3484325408935547
Validation loss: 2.021388212839762

Epoch: 6| Step: 8
Training loss: 2.214846611022949
Validation loss: 2.008259872595469

Epoch: 6| Step: 9
Training loss: 1.7210938930511475
Validation loss: 2.0007574558258057

Epoch: 6| Step: 10
Training loss: 1.634290099143982
Validation loss: 2.0201637546221414

Epoch: 6| Step: 11
Training loss: 1.7990895509719849
Validation loss: 2.0036620696385703

Epoch: 6| Step: 12
Training loss: 2.1181862354278564
Validation loss: 2.014186362425486

Epoch: 6| Step: 13
Training loss: 2.2687206268310547
Validation loss: 2.008923570315043

Epoch: 97| Step: 0
Training loss: 1.8288218975067139
Validation loss: 2.0057088136672974

Epoch: 6| Step: 1
Training loss: 1.916766881942749
Validation loss: 2.0141201615333557

Epoch: 6| Step: 2
Training loss: 2.7035863399505615
Validation loss: 2.0285053054491677

Epoch: 6| Step: 3
Training loss: 2.523043632507324
Validation loss: 2.022263785203298

Epoch: 6| Step: 4
Training loss: 2.535412311553955
Validation loss: 2.0403937896092734

Epoch: 6| Step: 5
Training loss: 1.7527704238891602
Validation loss: 2.0433329145113626

Epoch: 6| Step: 6
Training loss: 2.402064323425293
Validation loss: 2.04203599691391

Epoch: 6| Step: 7
Training loss: 2.1201906204223633
Validation loss: 2.0229667822519937

Epoch: 6| Step: 8
Training loss: 1.9189677238464355
Validation loss: 2.02483997742335

Epoch: 6| Step: 9
Training loss: 2.672558069229126
Validation loss: 1.9943352540334065

Epoch: 6| Step: 10
Training loss: 1.7208871841430664
Validation loss: 1.9934009909629822

Epoch: 6| Step: 11
Training loss: 2.393101930618286
Validation loss: 1.9969047109285991

Epoch: 6| Step: 12
Training loss: 1.907222867012024
Validation loss: 2.0067317883173623

Epoch: 6| Step: 13
Training loss: 1.632603406906128
Validation loss: 2.014051914215088

Epoch: 98| Step: 0
Training loss: 2.555219888687134
Validation loss: 2.0204827388127646

Epoch: 6| Step: 1
Training loss: 2.141120433807373
Validation loss: 2.023181994756063

Epoch: 6| Step: 2
Training loss: 2.452179431915283
Validation loss: 2.0280023217201233

Epoch: 6| Step: 3
Training loss: 2.356273889541626
Validation loss: 2.0261594454447427

Epoch: 6| Step: 4
Training loss: 1.8651642799377441
Validation loss: 2.024811307589213

Epoch: 6| Step: 5
Training loss: 2.295379161834717
Validation loss: 2.014690180619558

Epoch: 6| Step: 6
Training loss: 2.4867122173309326
Validation loss: 2.005432963371277

Epoch: 6| Step: 7
Training loss: 2.1800122261047363
Validation loss: 2.00466654698054

Epoch: 6| Step: 8
Training loss: 1.5853455066680908
Validation loss: 1.9967528780301411

Epoch: 6| Step: 9
Training loss: 2.5221340656280518
Validation loss: 1.9979538520177205

Epoch: 6| Step: 10
Training loss: 1.967803955078125
Validation loss: 2.0010855396588645

Epoch: 6| Step: 11
Training loss: 2.2794203758239746
Validation loss: 2.0089123845100403

Epoch: 6| Step: 12
Training loss: 1.551729679107666
Validation loss: 2.02056485414505

Epoch: 6| Step: 13
Training loss: 1.8110153675079346
Validation loss: 2.029411335786184

Epoch: 99| Step: 0
Training loss: 2.251084327697754
Validation loss: 2.0306145350138345

Epoch: 6| Step: 1
Training loss: 2.0013372898101807
Validation loss: 2.0268896420796714

Epoch: 6| Step: 2
Training loss: 2.0651915073394775
Validation loss: 2.035148024559021

Epoch: 6| Step: 3
Training loss: 1.6655083894729614
Validation loss: 2.0330926974614463

Epoch: 6| Step: 4
Training loss: 2.2029056549072266
Validation loss: 2.026570498943329

Epoch: 6| Step: 5
Training loss: 1.7031984329223633
Validation loss: 2.0203415751457214

Epoch: 6| Step: 6
Training loss: 2.4191036224365234
Validation loss: 2.003602663675944

Epoch: 6| Step: 7
Training loss: 1.8680120706558228
Validation loss: 2.0117342670758567

Epoch: 6| Step: 8
Training loss: 1.9702534675598145
Validation loss: 2.0075060526529946

Epoch: 6| Step: 9
Training loss: 2.027374267578125
Validation loss: 2.0063008666038513

Epoch: 6| Step: 10
Training loss: 2.5054216384887695
Validation loss: 1.9984664519627888

Epoch: 6| Step: 11
Training loss: 2.480961799621582
Validation loss: 1.9987034400304158

Epoch: 6| Step: 12
Training loss: 2.3971545696258545
Validation loss: 2.0024218956629434

Epoch: 6| Step: 13
Training loss: 2.6315956115722656
Validation loss: 1.9931615193684895

Epoch: 100| Step: 0
Training loss: 2.2102396488189697
Validation loss: 2.0066049297650657

Epoch: 6| Step: 1
Training loss: 2.203763484954834
Validation loss: 2.0041942795117698

Epoch: 6| Step: 2
Training loss: 1.8568785190582275
Validation loss: 2.0073742866516113

Epoch: 6| Step: 3
Training loss: 2.706685781478882
Validation loss: 2.005824645360311

Epoch: 6| Step: 4
Training loss: 2.285216808319092
Validation loss: 2.0051336685816445

Epoch: 6| Step: 5
Training loss: 2.0765321254730225
Validation loss: 2.0058423479398093

Epoch: 6| Step: 6
Training loss: 1.7449138164520264
Validation loss: 2.0007625420888266

Epoch: 6| Step: 7
Training loss: 2.7411892414093018
Validation loss: 2.0000091393788657

Epoch: 6| Step: 8
Training loss: 2.221839666366577
Validation loss: 2.0129663546880088

Epoch: 6| Step: 9
Training loss: 1.6284444332122803
Validation loss: 2.008169631163279

Epoch: 6| Step: 10
Training loss: 1.4263713359832764
Validation loss: 2.007293442885081

Epoch: 6| Step: 11
Training loss: 2.08862566947937
Validation loss: 2.0200600226720176

Epoch: 6| Step: 12
Training loss: 2.910592555999756
Validation loss: 2.024547020594279

Epoch: 6| Step: 13
Training loss: 1.832627773284912
Validation loss: 2.020785868167877

Epoch: 101| Step: 0
Training loss: 2.2398900985717773
Validation loss: 2.0283275047938027

Epoch: 6| Step: 1
Training loss: 1.7996718883514404
Validation loss: 2.0175546407699585

Epoch: 6| Step: 2
Training loss: 2.9478297233581543
Validation loss: 2.008569836616516

Epoch: 6| Step: 3
Training loss: 1.7425225973129272
Validation loss: 2.0148192842801413

Epoch: 6| Step: 4
Training loss: 1.8268191814422607
Validation loss: 2.0040724078814187

Epoch: 6| Step: 5
Training loss: 1.8801231384277344
Validation loss: 2.0110172231992087

Epoch: 6| Step: 6
Training loss: 1.2884576320648193
Validation loss: 2.0017594695091248

Epoch: 6| Step: 7
Training loss: 2.050790309906006
Validation loss: 2.003858983516693

Epoch: 6| Step: 8
Training loss: 1.9308936595916748
Validation loss: 1.9956583778063457

Epoch: 6| Step: 9
Training loss: 2.8280956745147705
Validation loss: 2.0010990301767984

Epoch: 6| Step: 10
Training loss: 2.5512495040893555
Validation loss: 2.0089529156684875

Epoch: 6| Step: 11
Training loss: 2.29002046585083
Validation loss: 2.00525172551473

Epoch: 6| Step: 12
Training loss: 2.5784735679626465
Validation loss: 2.0214284658432007

Epoch: 6| Step: 13
Training loss: 1.7594993114471436
Validation loss: 2.0269319216410318

Epoch: 102| Step: 0
Training loss: 2.12652587890625
Validation loss: 2.030621866385142

Epoch: 6| Step: 1
Training loss: 2.048609972000122
Validation loss: 2.019370416800181

Epoch: 6| Step: 2
Training loss: 2.5540518760681152
Validation loss: 2.02077051003774

Epoch: 6| Step: 3
Training loss: 2.062161922454834
Validation loss: 2.020197868347168

Epoch: 6| Step: 4
Training loss: 2.148001194000244
Validation loss: 2.0256093740463257

Epoch: 6| Step: 5
Training loss: 1.9769450426101685
Validation loss: 2.021752953529358

Epoch: 6| Step: 6
Training loss: 2.414414167404175
Validation loss: 2.024881958961487

Epoch: 6| Step: 7
Training loss: 1.727484941482544
Validation loss: 2.018901268641154

Epoch: 6| Step: 8
Training loss: 1.9670917987823486
Validation loss: 2.016705811023712

Epoch: 6| Step: 9
Training loss: 2.634139060974121
Validation loss: 2.0121986865997314

Epoch: 6| Step: 10
Training loss: 1.8289936780929565
Validation loss: 2.0096548000971475

Epoch: 6| Step: 11
Training loss: 1.676080584526062
Validation loss: 2.0104306737581887

Epoch: 6| Step: 12
Training loss: 2.1423027515411377
Validation loss: 2.0068960984547934

Epoch: 6| Step: 13
Training loss: 2.530014991760254
Validation loss: 2.0141884485880532

Epoch: 103| Step: 0
Training loss: 2.004094123840332
Validation loss: 2.0117845137914023

Epoch: 6| Step: 1
Training loss: 2.4418606758117676
Validation loss: 2.014669974644979

Epoch: 6| Step: 2
Training loss: 2.1409249305725098
Validation loss: 2.016404926776886

Epoch: 6| Step: 3
Training loss: 2.262117862701416
Validation loss: 2.0049041310946145

Epoch: 6| Step: 4
Training loss: 2.308349132537842
Validation loss: 2.013450562953949

Epoch: 6| Step: 5
Training loss: 1.9461617469787598
Validation loss: 2.0121122002601624

Epoch: 6| Step: 6
Training loss: 1.3611329793930054
Validation loss: 2.009140988190969

Epoch: 6| Step: 7
Training loss: 2.003512382507324
Validation loss: 2.009562611579895

Epoch: 6| Step: 8
Training loss: 2.183835744857788
Validation loss: 2.0167775551478067

Epoch: 6| Step: 9
Training loss: 1.9306682348251343
Validation loss: 2.0270220836003623

Epoch: 6| Step: 10
Training loss: 2.286048173904419
Validation loss: 2.0325589378674827

Epoch: 6| Step: 11
Training loss: 2.2037534713745117
Validation loss: 2.030957738558451

Epoch: 6| Step: 12
Training loss: 2.203756093978882
Validation loss: 2.0398916006088257

Epoch: 6| Step: 13
Training loss: 2.7252326011657715
Validation loss: 2.0324425101280212

Epoch: 104| Step: 0
Training loss: 2.6916160583496094
Validation loss: 2.0116902192433677

Epoch: 6| Step: 1
Training loss: 2.049240827560425
Validation loss: 2.0232534607251487

Epoch: 6| Step: 2
Training loss: 2.688354253768921
Validation loss: 2.012256662050883

Epoch: 6| Step: 3
Training loss: 1.3352758884429932
Validation loss: 2.005854864915212

Epoch: 6| Step: 4
Training loss: 2.503958225250244
Validation loss: 2.0048298041025796

Epoch: 6| Step: 5
Training loss: 1.8328421115875244
Validation loss: 2.004401663939158

Epoch: 6| Step: 6
Training loss: 2.171203374862671
Validation loss: 2.0036357045173645

Epoch: 6| Step: 7
Training loss: 1.7651399374008179
Validation loss: 2.003561556339264

Epoch: 6| Step: 8
Training loss: 2.175548553466797
Validation loss: 2.009710947672526

Epoch: 6| Step: 9
Training loss: 1.918733835220337
Validation loss: 2.0046642422676086

Epoch: 6| Step: 10
Training loss: 2.0130081176757812
Validation loss: 2.0022635062535605

Epoch: 6| Step: 11
Training loss: 2.1388378143310547
Validation loss: 2.0030593872070312

Epoch: 6| Step: 12
Training loss: 2.3268628120422363
Validation loss: 2.0016741156578064

Epoch: 6| Step: 13
Training loss: 2.0489721298217773
Validation loss: 2.009390910466512

Epoch: 105| Step: 0
Training loss: 1.838701605796814
Validation loss: 2.0128161311149597

Epoch: 6| Step: 1
Training loss: 1.8171334266662598
Validation loss: 2.0169507265090942

Epoch: 6| Step: 2
Training loss: 2.347763776779175
Validation loss: 2.0188080072402954

Epoch: 6| Step: 3
Training loss: 1.8431243896484375
Validation loss: 2.013744036356608

Epoch: 6| Step: 4
Training loss: 2.5565145015716553
Validation loss: 2.0133870442708335

Epoch: 6| Step: 5
Training loss: 1.7907545566558838
Validation loss: 2.0089967052141824

Epoch: 6| Step: 6
Training loss: 1.8498518466949463
Validation loss: 2.0093449552853904

Epoch: 6| Step: 7
Training loss: 2.6946845054626465
Validation loss: 2.0043386022249856

Epoch: 6| Step: 8
Training loss: 1.5193111896514893
Validation loss: 2.0066065589586892

Epoch: 6| Step: 9
Training loss: 2.2552425861358643
Validation loss: 2.001198391119639

Epoch: 6| Step: 10
Training loss: 2.1615121364593506
Validation loss: 2.0040979782740274

Epoch: 6| Step: 11
Training loss: 2.369313955307007
Validation loss: 2.0072021087010703

Epoch: 6| Step: 12
Training loss: 2.4794836044311523
Validation loss: 2.016317387421926

Epoch: 6| Step: 13
Training loss: 2.004794120788574
Validation loss: 2.014807164669037

Epoch: 106| Step: 0
Training loss: 1.6740047931671143
Validation loss: 2.0219878554344177

Epoch: 6| Step: 1
Training loss: 2.739009380340576
Validation loss: 2.015985290209452

Epoch: 6| Step: 2
Training loss: 2.3053793907165527
Validation loss: 2.016300996144613

Epoch: 6| Step: 3
Training loss: 2.1123251914978027
Validation loss: 2.0268243749936423

Epoch: 6| Step: 4
Training loss: 2.2794041633605957
Validation loss: 2.02151491244634

Epoch: 6| Step: 5
Training loss: 2.037558078765869
Validation loss: 2.015054921309153

Epoch: 6| Step: 6
Training loss: 1.944751262664795
Validation loss: 2.0212507843971252

Epoch: 6| Step: 7
Training loss: 2.1005687713623047
Validation loss: 2.023821791013082

Epoch: 6| Step: 8
Training loss: 1.840973138809204
Validation loss: 2.0136984388033548

Epoch: 6| Step: 9
Training loss: 1.8441460132598877
Validation loss: 2.02556719382604

Epoch: 6| Step: 10
Training loss: 2.195021629333496
Validation loss: 2.0293271938959756

Epoch: 6| Step: 11
Training loss: 1.830499291419983
Validation loss: 2.0282694896062217

Epoch: 6| Step: 12
Training loss: 2.0983495712280273
Validation loss: 2.030653635660807

Epoch: 6| Step: 13
Training loss: 2.5137391090393066
Validation loss: 2.038670321305593

Epoch: 107| Step: 0
Training loss: 1.679973840713501
Validation loss: 2.0463284651438394

Epoch: 6| Step: 1
Training loss: 1.7450357675552368
Validation loss: 2.0498389999071756

Epoch: 6| Step: 2
Training loss: 2.131965160369873
Validation loss: 2.049008826414744

Epoch: 6| Step: 3
Training loss: 1.9272308349609375
Validation loss: 2.0363274812698364

Epoch: 6| Step: 4
Training loss: 2.417301654815674
Validation loss: 2.0294910271962485

Epoch: 6| Step: 5
Training loss: 2.172370672225952
Validation loss: 2.0236411889394126

Epoch: 6| Step: 6
Training loss: 1.922965168952942
Validation loss: 2.017712334791819

Epoch: 6| Step: 7
Training loss: 2.189157247543335
Validation loss: 2.0260667403539023

Epoch: 6| Step: 8
Training loss: 2.2740867137908936
Validation loss: 2.018397887547811

Epoch: 6| Step: 9
Training loss: 2.619563102722168
Validation loss: 2.009690582752228

Epoch: 6| Step: 10
Training loss: 2.3461203575134277
Validation loss: 2.0131359696388245

Epoch: 6| Step: 11
Training loss: 2.7162537574768066
Validation loss: 2.018449624379476

Epoch: 6| Step: 12
Training loss: 2.010854721069336
Validation loss: 2.026527722676595

Epoch: 6| Step: 13
Training loss: 1.5747764110565186
Validation loss: 2.032568375269572

Epoch: 108| Step: 0
Training loss: 2.190138339996338
Validation loss: 2.0344941218694053

Epoch: 6| Step: 1
Training loss: 2.4246933460235596
Validation loss: 2.0336495439211526

Epoch: 6| Step: 2
Training loss: 2.333803176879883
Validation loss: 2.046384950478872

Epoch: 6| Step: 3
Training loss: 2.0552849769592285
Validation loss: 2.0410549441973367

Epoch: 6| Step: 4
Training loss: 1.9679439067840576
Validation loss: 2.0426252086957297

Epoch: 6| Step: 5
Training loss: 1.8198473453521729
Validation loss: 2.035186151663462

Epoch: 6| Step: 6
Training loss: 2.307469606399536
Validation loss: 2.0346895853678384

Epoch: 6| Step: 7
Training loss: 2.4720282554626465
Validation loss: 2.038730005423228

Epoch: 6| Step: 8
Training loss: 2.107423782348633
Validation loss: 2.0348866979281106

Epoch: 6| Step: 9
Training loss: 1.965382695198059
Validation loss: 2.03105765581131

Epoch: 6| Step: 10
Training loss: 3.0920157432556152
Validation loss: 2.0320372382799783

Epoch: 6| Step: 11
Training loss: 1.7337744235992432
Validation loss: 2.0235240856806436

Epoch: 6| Step: 12
Training loss: 1.8080201148986816
Validation loss: 2.0128007729848227

Epoch: 6| Step: 13
Training loss: 1.9446520805358887
Validation loss: 2.0169674356778464

Epoch: 109| Step: 0
Training loss: 1.9325603246688843
Validation loss: 2.001688857873281

Epoch: 6| Step: 1
Training loss: 1.9551936388015747
Validation loss: 1.9977701505025227

Epoch: 6| Step: 2
Training loss: 1.7209062576293945
Validation loss: 2.0066185792287192

Epoch: 6| Step: 3
Training loss: 2.653618335723877
Validation loss: 2.0134145617485046

Epoch: 6| Step: 4
Training loss: 1.9390239715576172
Validation loss: 2.020163873831431

Epoch: 6| Step: 5
Training loss: 2.0982086658477783
Validation loss: 2.025907834370931

Epoch: 6| Step: 6
Training loss: 2.4071478843688965
Validation loss: 2.0277707974116006

Epoch: 6| Step: 7
Training loss: 1.7205746173858643
Validation loss: 2.0404189427693686

Epoch: 6| Step: 8
Training loss: 2.0204594135284424
Validation loss: 2.0323211749394736

Epoch: 6| Step: 9
Training loss: 2.008340835571289
Validation loss: 2.024999976158142

Epoch: 6| Step: 10
Training loss: 2.3453946113586426
Validation loss: 2.024360795815786

Epoch: 6| Step: 11
Training loss: 2.4793663024902344
Validation loss: 2.020016292730967

Epoch: 6| Step: 12
Training loss: 2.038499116897583
Validation loss: 2.009461303551992

Epoch: 6| Step: 13
Training loss: 2.3204245567321777
Validation loss: 2.0157333413759866

Epoch: 110| Step: 0
Training loss: 2.014733076095581
Validation loss: 2.0055424173672995

Epoch: 6| Step: 1
Training loss: 1.9827511310577393
Validation loss: 2.0095945596694946

Epoch: 6| Step: 2
Training loss: 2.082613468170166
Validation loss: 2.003049830595652

Epoch: 6| Step: 3
Training loss: 1.5137629508972168
Validation loss: 2.0073898235956826

Epoch: 6| Step: 4
Training loss: 1.9246753454208374
Validation loss: 2.0002936720848083

Epoch: 6| Step: 5
Training loss: 2.2289161682128906
Validation loss: 2.0122806628545127

Epoch: 6| Step: 6
Training loss: 2.331073045730591
Validation loss: 2.0162891944249473

Epoch: 6| Step: 7
Training loss: 1.7396916151046753
Validation loss: 2.024831255276998

Epoch: 6| Step: 8
Training loss: 1.9807202816009521
Validation loss: 2.0267675121625266

Epoch: 6| Step: 9
Training loss: 2.621030330657959
Validation loss: 2.023677627245585

Epoch: 6| Step: 10
Training loss: 1.6454439163208008
Validation loss: 2.0188787380854287

Epoch: 6| Step: 11
Training loss: 2.998243808746338
Validation loss: 2.017931560675303

Epoch: 6| Step: 12
Training loss: 1.9838347434997559
Validation loss: 2.015754302342733

Epoch: 6| Step: 13
Training loss: 2.4855871200561523
Validation loss: 2.0187209645907083

Epoch: 111| Step: 0
Training loss: 2.0030765533447266
Validation loss: 2.0248188177744546

Epoch: 6| Step: 1
Training loss: 1.901625633239746
Validation loss: 2.021278202533722

Epoch: 6| Step: 2
Training loss: 2.2738218307495117
Validation loss: 2.0236334800720215

Epoch: 6| Step: 3
Training loss: 1.8757848739624023
Validation loss: 2.0205094814300537

Epoch: 6| Step: 4
Training loss: 2.0839998722076416
Validation loss: 2.0226073066393533

Epoch: 6| Step: 5
Training loss: 1.7368978261947632
Validation loss: 2.021666089693705

Epoch: 6| Step: 6
Training loss: 1.7407431602478027
Validation loss: 2.027814527352651

Epoch: 6| Step: 7
Training loss: 2.2950429916381836
Validation loss: 2.02350507179896

Epoch: 6| Step: 8
Training loss: 1.996476173400879
Validation loss: 2.014069755872091

Epoch: 6| Step: 9
Training loss: 2.163632392883301
Validation loss: 2.0185017188390098

Epoch: 6| Step: 10
Training loss: 2.0155086517333984
Validation loss: 2.01972496509552

Epoch: 6| Step: 11
Training loss: 2.46781063079834
Validation loss: 2.0108049511909485

Epoch: 6| Step: 12
Training loss: 2.3160464763641357
Validation loss: 2.0176820953687034

Epoch: 6| Step: 13
Training loss: 2.430124044418335
Validation loss: 2.011524816354116

Epoch: 112| Step: 0
Training loss: 2.14890718460083
Validation loss: 2.0156289537747702

Epoch: 6| Step: 1
Training loss: 2.266201972961426
Validation loss: 2.0126684506734214

Epoch: 6| Step: 2
Training loss: 1.4250142574310303
Validation loss: 2.0155738592147827

Epoch: 6| Step: 3
Training loss: 2.192293167114258
Validation loss: 2.0147902766863504

Epoch: 6| Step: 4
Training loss: 1.8781243562698364
Validation loss: 2.0198296705881753

Epoch: 6| Step: 5
Training loss: 1.2923015356063843
Validation loss: 2.008401354153951

Epoch: 6| Step: 6
Training loss: 2.423586368560791
Validation loss: 2.0193657676378884

Epoch: 6| Step: 7
Training loss: 2.4757943153381348
Validation loss: 2.0198971033096313

Epoch: 6| Step: 8
Training loss: 1.9292843341827393
Validation loss: 2.0202646056811013

Epoch: 6| Step: 9
Training loss: 2.5909175872802734
Validation loss: 2.0337629119555154

Epoch: 6| Step: 10
Training loss: 2.3431551456451416
Validation loss: 2.023183763027191

Epoch: 6| Step: 11
Training loss: 2.2030155658721924
Validation loss: 2.022151509920756

Epoch: 6| Step: 12
Training loss: 2.522770881652832
Validation loss: 2.0238119761149087

Epoch: 6| Step: 13
Training loss: 1.7098331451416016
Validation loss: 2.0343540708223977

Epoch: 113| Step: 0
Training loss: 2.2604079246520996
Validation loss: 2.0263633330663047

Epoch: 6| Step: 1
Training loss: 1.8992522954940796
Validation loss: 2.0171375473340354

Epoch: 6| Step: 2
Training loss: 2.095762252807617
Validation loss: 2.013947387536367

Epoch: 6| Step: 3
Training loss: 2.2923619747161865
Validation loss: 2.0178141991297402

Epoch: 6| Step: 4
Training loss: 2.5356969833374023
Validation loss: 2.0065111915270486

Epoch: 6| Step: 5
Training loss: 2.7304787635803223
Validation loss: 2.007744391759237

Epoch: 6| Step: 6
Training loss: 1.7176350355148315
Validation loss: 2.0149572292963662

Epoch: 6| Step: 7
Training loss: 2.073444366455078
Validation loss: 2.0102023482322693

Epoch: 6| Step: 8
Training loss: 1.669758677482605
Validation loss: 2.0145230094591775

Epoch: 6| Step: 9
Training loss: 1.8559163808822632
Validation loss: 2.008909583091736

Epoch: 6| Step: 10
Training loss: 1.90540611743927
Validation loss: 2.0147112806638083

Epoch: 6| Step: 11
Training loss: 1.5747959613800049
Validation loss: 2.0139835476875305

Epoch: 6| Step: 12
Training loss: 2.630438804626465
Validation loss: 2.0264265735944114

Epoch: 6| Step: 13
Training loss: 2.162039279937744
Validation loss: 2.0399457613627114

Epoch: 114| Step: 0
Training loss: 2.2744665145874023
Validation loss: 2.0543117920557656

Epoch: 6| Step: 1
Training loss: 2.1827268600463867
Validation loss: 2.0699899593989053

Epoch: 6| Step: 2
Training loss: 2.5488522052764893
Validation loss: 2.0623042384783425

Epoch: 6| Step: 3
Training loss: 2.194652795791626
Validation loss: 2.0657829443613687

Epoch: 6| Step: 4
Training loss: 1.7983007431030273
Validation loss: 2.054501752058665

Epoch: 6| Step: 5
Training loss: 2.481095790863037
Validation loss: 2.060729960600535

Epoch: 6| Step: 6
Training loss: 2.1412172317504883
Validation loss: 2.034323831399282

Epoch: 6| Step: 7
Training loss: 1.6471219062805176
Validation loss: 2.0376272400220237

Epoch: 6| Step: 8
Training loss: 1.9747812747955322
Validation loss: 2.0285668770472207

Epoch: 6| Step: 9
Training loss: 2.128870964050293
Validation loss: 2.016768972078959

Epoch: 6| Step: 10
Training loss: 2.066310405731201
Validation loss: 2.0085489749908447

Epoch: 6| Step: 11
Training loss: 1.9165849685668945
Validation loss: 2.0195627411206565

Epoch: 6| Step: 12
Training loss: 1.998321294784546
Validation loss: 2.019032816092173

Epoch: 6| Step: 13
Training loss: 2.201199531555176
Validation loss: 2.0219576557477317

Epoch: 115| Step: 0
Training loss: 1.779157280921936
Validation loss: 2.0209388931592307

Epoch: 6| Step: 1
Training loss: 2.402350902557373
Validation loss: 2.0266026655832925

Epoch: 6| Step: 2
Training loss: 1.9029831886291504
Validation loss: 2.0270914236704507

Epoch: 6| Step: 3
Training loss: 2.1082725524902344
Validation loss: 2.028743783632914

Epoch: 6| Step: 4
Training loss: 2.1350011825561523
Validation loss: 2.0206332206726074

Epoch: 6| Step: 5
Training loss: 1.8557604551315308
Validation loss: 2.0193863113721213

Epoch: 6| Step: 6
Training loss: 1.449701189994812
Validation loss: 2.0171743631362915

Epoch: 6| Step: 7
Training loss: 2.6196670532226562
Validation loss: 2.004150708516439

Epoch: 6| Step: 8
Training loss: 2.4626212120056152
Validation loss: 2.012937923272451

Epoch: 6| Step: 9
Training loss: 2.024489402770996
Validation loss: 2.01028581460317

Epoch: 6| Step: 10
Training loss: 1.872194528579712
Validation loss: 2.023871143658956

Epoch: 6| Step: 11
Training loss: 1.6285682916641235
Validation loss: 2.0331627130508423

Epoch: 6| Step: 12
Training loss: 3.049501419067383
Validation loss: 2.040446142355601

Epoch: 6| Step: 13
Training loss: 2.4665660858154297
Validation loss: 2.0386993487675986

Epoch: 116| Step: 0
Training loss: 1.9610810279846191
Validation loss: 2.034195303916931

Epoch: 6| Step: 1
Training loss: 2.1965882778167725
Validation loss: 2.039372682571411

Epoch: 6| Step: 2
Training loss: 2.6173245906829834
Validation loss: 2.0369730393091836

Epoch: 6| Step: 3
Training loss: 1.9625370502471924
Validation loss: 2.0280025601387024

Epoch: 6| Step: 4
Training loss: 2.0625150203704834
Validation loss: 2.02743798494339

Epoch: 6| Step: 5
Training loss: 2.5773427486419678
Validation loss: 2.015031556288401

Epoch: 6| Step: 6
Training loss: 1.4135706424713135
Validation loss: 2.014464716116587

Epoch: 6| Step: 7
Training loss: 2.3013668060302734
Validation loss: 2.011935293674469

Epoch: 6| Step: 8
Training loss: 2.282961368560791
Validation loss: 2.008102516333262

Epoch: 6| Step: 9
Training loss: 2.256079912185669
Validation loss: 2.0131948391596475

Epoch: 6| Step: 10
Training loss: 2.21549916267395
Validation loss: 2.015438119570414

Epoch: 6| Step: 11
Training loss: 1.4593220949172974
Validation loss: 2.0189989606539407

Epoch: 6| Step: 12
Training loss: 2.045835256576538
Validation loss: 2.0078373352686563

Epoch: 6| Step: 13
Training loss: 2.186307907104492
Validation loss: 2.0175596276919046

Epoch: 117| Step: 0
Training loss: 2.357907295227051
Validation loss: 2.0115875403086343

Epoch: 6| Step: 1
Training loss: 1.8845558166503906
Validation loss: 2.0131516456604004

Epoch: 6| Step: 2
Training loss: 2.1149797439575195
Validation loss: 2.017900069554647

Epoch: 6| Step: 3
Training loss: 2.2010109424591064
Validation loss: 2.0084222157796225

Epoch: 6| Step: 4
Training loss: 2.4897913932800293
Validation loss: 2.014561673005422

Epoch: 6| Step: 5
Training loss: 2.0264041423797607
Validation loss: 2.008880853652954

Epoch: 6| Step: 6
Training loss: 1.8818899393081665
Validation loss: 2.004413147767385

Epoch: 6| Step: 7
Training loss: 2.1130876541137695
Validation loss: 2.0030550161997476

Epoch: 6| Step: 8
Training loss: 2.1208438873291016
Validation loss: 2.0065370996793113

Epoch: 6| Step: 9
Training loss: 2.365945339202881
Validation loss: 2.0057387351989746

Epoch: 6| Step: 10
Training loss: 1.7512117624282837
Validation loss: 2.0062553882598877

Epoch: 6| Step: 11
Training loss: 1.4657158851623535
Validation loss: 2.0153915087381997

Epoch: 6| Step: 12
Training loss: 2.5877909660339355
Validation loss: 2.0063699881235757

Epoch: 6| Step: 13
Training loss: 1.9009840488433838
Validation loss: 2.0070179303487143

Epoch: 118| Step: 0
Training loss: 2.280097484588623
Validation loss: 2.008885304133097

Epoch: 6| Step: 1
Training loss: 2.145777463912964
Validation loss: 2.0117446184158325

Epoch: 6| Step: 2
Training loss: 2.206218719482422
Validation loss: 2.0099201798439026

Epoch: 6| Step: 3
Training loss: 1.7408562898635864
Validation loss: 2.0045494635899863

Epoch: 6| Step: 4
Training loss: 1.9180961847305298
Validation loss: 2.0151939392089844

Epoch: 6| Step: 5
Training loss: 2.2308506965637207
Validation loss: 2.022475520769755

Epoch: 6| Step: 6
Training loss: 1.5532550811767578
Validation loss: 2.0214629570643106

Epoch: 6| Step: 7
Training loss: 1.7960606813430786
Validation loss: 2.0378095706303916

Epoch: 6| Step: 8
Training loss: 2.403909921646118
Validation loss: 2.0507193009058633

Epoch: 6| Step: 9
Training loss: 2.0966076850891113
Validation loss: 2.030524651209513

Epoch: 6| Step: 10
Training loss: 2.7074460983276367
Validation loss: 2.0186225970586142

Epoch: 6| Step: 11
Training loss: 1.8917109966278076
Validation loss: 2.0199712912241616

Epoch: 6| Step: 12
Training loss: 2.603217601776123
Validation loss: 2.0104257464408875

Epoch: 6| Step: 13
Training loss: 2.167994976043701
Validation loss: 2.0151090025901794

Epoch: 119| Step: 0
Training loss: 1.7086364030838013
Validation loss: 2.008291999499003

Epoch: 6| Step: 1
Training loss: 1.9404466152191162
Validation loss: 2.0128066738446555

Epoch: 6| Step: 2
Training loss: 2.2630233764648438
Validation loss: 2.014216403166453

Epoch: 6| Step: 3
Training loss: 1.8425683975219727
Validation loss: 2.008879005908966

Epoch: 6| Step: 4
Training loss: 2.2995951175689697
Validation loss: 2.0125649770100913

Epoch: 6| Step: 5
Training loss: 2.10528564453125
Validation loss: 2.0180314580599465

Epoch: 6| Step: 6
Training loss: 2.6546132564544678
Validation loss: 2.0271711548169455

Epoch: 6| Step: 7
Training loss: 2.5797181129455566
Validation loss: 2.014930009841919

Epoch: 6| Step: 8
Training loss: 2.1384434700012207
Validation loss: 2.0102156599362693

Epoch: 6| Step: 9
Training loss: 1.967588186264038
Validation loss: 2.0200979510943093

Epoch: 6| Step: 10
Training loss: 2.8530943393707275
Validation loss: 2.002577841281891

Epoch: 6| Step: 11
Training loss: 1.930184245109558
Validation loss: 2.0076241493225098

Epoch: 6| Step: 12
Training loss: 1.4588727951049805
Validation loss: 2.0091976126035056

Epoch: 6| Step: 13
Training loss: 1.8499575853347778
Validation loss: 2.019905666510264

Epoch: 120| Step: 0
Training loss: 2.4513261318206787
Validation loss: 2.013529618581136

Epoch: 6| Step: 1
Training loss: 1.785825490951538
Validation loss: 2.019094487031301

Epoch: 6| Step: 2
Training loss: 2.013171672821045
Validation loss: 2.029220461845398

Epoch: 6| Step: 3
Training loss: 2.0387120246887207
Validation loss: 2.0385412176450095

Epoch: 6| Step: 4
Training loss: 1.8847720623016357
Validation loss: 2.0345806082089744

Epoch: 6| Step: 5
Training loss: 2.1899356842041016
Validation loss: 2.040471076965332

Epoch: 6| Step: 6
Training loss: 2.3920645713806152
Validation loss: 2.051156461238861

Epoch: 6| Step: 7
Training loss: 1.9216614961624146
Validation loss: 2.0368391275405884

Epoch: 6| Step: 8
Training loss: 2.122882843017578
Validation loss: 2.0331772565841675

Epoch: 6| Step: 9
Training loss: 2.2788472175598145
Validation loss: 2.0171751379966736

Epoch: 6| Step: 10
Training loss: 2.485374927520752
Validation loss: 2.0209548473358154

Epoch: 6| Step: 11
Training loss: 2.1050727367401123
Validation loss: 2.018731117248535

Epoch: 6| Step: 12
Training loss: 1.3267178535461426
Validation loss: 2.015591263771057

Epoch: 6| Step: 13
Training loss: 2.4014458656311035
Validation loss: 2.0072895089785256

Epoch: 121| Step: 0
Training loss: 2.1295671463012695
Validation loss: 2.002673109372457

Epoch: 6| Step: 1
Training loss: 1.746966004371643
Validation loss: 2.0068087577819824

Epoch: 6| Step: 2
Training loss: 2.5897340774536133
Validation loss: 2.007211764653524

Epoch: 6| Step: 3
Training loss: 1.3651841878890991
Validation loss: 2.01149449745814

Epoch: 6| Step: 4
Training loss: 2.0798492431640625
Validation loss: 2.008861462275187

Epoch: 6| Step: 5
Training loss: 1.9603649377822876
Validation loss: 2.007643143335978

Epoch: 6| Step: 6
Training loss: 2.238738775253296
Validation loss: 2.010516365369161

Epoch: 6| Step: 7
Training loss: 2.3069841861724854
Validation loss: 2.014082054297129

Epoch: 6| Step: 8
Training loss: 2.29179310798645
Validation loss: 2.0097872018814087

Epoch: 6| Step: 9
Training loss: 2.3147099018096924
Validation loss: 2.0105294585227966

Epoch: 6| Step: 10
Training loss: 2.23775053024292
Validation loss: 2.0139235456784568

Epoch: 6| Step: 11
Training loss: 1.721551775932312
Validation loss: 2.019343455632528

Epoch: 6| Step: 12
Training loss: 1.725293755531311
Validation loss: 2.0258793433507285

Epoch: 6| Step: 13
Training loss: 2.5336525440216064
Validation loss: 2.0291094382603965

Epoch: 122| Step: 0
Training loss: 2.330389976501465
Validation loss: 2.032919704914093

Epoch: 6| Step: 1
Training loss: 2.785280704498291
Validation loss: 2.023691197236379

Epoch: 6| Step: 2
Training loss: 1.7003898620605469
Validation loss: 2.0269150535265603

Epoch: 6| Step: 3
Training loss: 2.0684030055999756
Validation loss: 2.023775637149811

Epoch: 6| Step: 4
Training loss: 1.922858715057373
Validation loss: 2.026109794775645

Epoch: 6| Step: 5
Training loss: 2.1540350914001465
Validation loss: 2.0353210965792337

Epoch: 6| Step: 6
Training loss: 2.1671509742736816
Validation loss: 2.0331554412841797

Epoch: 6| Step: 7
Training loss: 2.4035046100616455
Validation loss: 2.024406691392263

Epoch: 6| Step: 8
Training loss: 1.9797717332839966
Validation loss: 2.018685261408488

Epoch: 6| Step: 9
Training loss: 1.7856409549713135
Validation loss: 2.0165186325709024

Epoch: 6| Step: 10
Training loss: 1.7921960353851318
Validation loss: 2.013644794623057

Epoch: 6| Step: 11
Training loss: 1.7713954448699951
Validation loss: 2.0091405312220254

Epoch: 6| Step: 12
Training loss: 2.300807476043701
Validation loss: 2.0096974968910217

Epoch: 6| Step: 13
Training loss: 2.1497230529785156
Validation loss: 2.011171738306681

Epoch: 123| Step: 0
Training loss: 2.251018524169922
Validation loss: 2.0153717597325644

Epoch: 6| Step: 1
Training loss: 2.6595959663391113
Validation loss: 2.0203829209009805

Epoch: 6| Step: 2
Training loss: 2.2345757484436035
Validation loss: 2.0279566645622253

Epoch: 6| Step: 3
Training loss: 1.9494026899337769
Validation loss: 2.028194765249888

Epoch: 6| Step: 4
Training loss: 1.7843846082687378
Validation loss: 2.027385493119558

Epoch: 6| Step: 5
Training loss: 2.1167173385620117
Validation loss: 2.02454282840093

Epoch: 6| Step: 6
Training loss: 2.0549020767211914
Validation loss: 2.041439096132914

Epoch: 6| Step: 7
Training loss: 2.277414321899414
Validation loss: 2.0474544763565063

Epoch: 6| Step: 8
Training loss: 2.2154808044433594
Validation loss: 2.0610315004984536

Epoch: 6| Step: 9
Training loss: 2.393367290496826
Validation loss: 2.0619752605756125

Epoch: 6| Step: 10
Training loss: 1.9153789281845093
Validation loss: 2.0357727805773416

Epoch: 6| Step: 11
Training loss: 1.6673924922943115
Validation loss: 2.0236778060595193

Epoch: 6| Step: 12
Training loss: 1.955014944076538
Validation loss: 2.022637049357096

Epoch: 6| Step: 13
Training loss: 1.8658788204193115
Validation loss: 2.0158283511797586

Epoch: 124| Step: 0
Training loss: 1.8551727533340454
Validation loss: 2.0182551542917886

Epoch: 6| Step: 1
Training loss: 2.011618137359619
Validation loss: 2.0082727670669556

Epoch: 6| Step: 2
Training loss: 1.564597725868225
Validation loss: 2.0091052651405334

Epoch: 6| Step: 3
Training loss: 2.4026944637298584
Validation loss: 2.0090699195861816

Epoch: 6| Step: 4
Training loss: 2.2304630279541016
Validation loss: 2.006303350130717

Epoch: 6| Step: 5
Training loss: 2.2437145709991455
Validation loss: 2.0135934750239053

Epoch: 6| Step: 6
Training loss: 1.8871655464172363
Validation loss: 2.012857993443807

Epoch: 6| Step: 7
Training loss: 2.177236318588257
Validation loss: 2.015998621781667

Epoch: 6| Step: 8
Training loss: 1.9959800243377686
Validation loss: 2.010822057723999

Epoch: 6| Step: 9
Training loss: 1.4604434967041016
Validation loss: 2.013018767038981

Epoch: 6| Step: 10
Training loss: 2.688335657119751
Validation loss: 2.011099318663279

Epoch: 6| Step: 11
Training loss: 1.681757926940918
Validation loss: 2.0200032790501914

Epoch: 6| Step: 12
Training loss: 2.6112635135650635
Validation loss: 2.016687790552775

Epoch: 6| Step: 13
Training loss: 2.509178638458252
Validation loss: 2.015036165714264

Epoch: 125| Step: 0
Training loss: 2.13688325881958
Validation loss: 2.0412497917811074

Epoch: 6| Step: 1
Training loss: 1.5409595966339111
Validation loss: 2.0499207973480225

Epoch: 6| Step: 2
Training loss: 2.3354015350341797
Validation loss: 2.0546829104423523

Epoch: 6| Step: 3
Training loss: 2.03757905960083
Validation loss: 2.0579153498013816

Epoch: 6| Step: 4
Training loss: 2.5678210258483887
Validation loss: 2.0664464235305786

Epoch: 6| Step: 5
Training loss: 2.2545230388641357
Validation loss: 2.06823992729187

Epoch: 6| Step: 6
Training loss: 2.4191863536834717
Validation loss: 2.056606729825338

Epoch: 6| Step: 7
Training loss: 1.6240638494491577
Validation loss: 2.060779054959615

Epoch: 6| Step: 8
Training loss: 1.7932145595550537
Validation loss: 2.0481036901474

Epoch: 6| Step: 9
Training loss: 2.1730270385742188
Validation loss: 2.042961756388346

Epoch: 6| Step: 10
Training loss: 1.9339070320129395
Validation loss: 2.0301683147748313

Epoch: 6| Step: 11
Training loss: 1.9949538707733154
Validation loss: 2.020809551080068

Epoch: 6| Step: 12
Training loss: 2.6536245346069336
Validation loss: 2.020828286806742

Epoch: 6| Step: 13
Training loss: 1.8838051557540894
Validation loss: 2.0186217228571572

Epoch: 126| Step: 0
Training loss: 2.227450370788574
Validation loss: 2.020637114842733

Epoch: 6| Step: 1
Training loss: 1.9122357368469238
Validation loss: 2.0280115803082785

Epoch: 6| Step: 2
Training loss: 2.5291476249694824
Validation loss: 2.0244204998016357

Epoch: 6| Step: 3
Training loss: 1.915071964263916
Validation loss: 2.0285915533701577

Epoch: 6| Step: 4
Training loss: 2.174894332885742
Validation loss: 2.0333555936813354

Epoch: 6| Step: 5
Training loss: 2.285706043243408
Validation loss: 2.028347074985504

Epoch: 6| Step: 6
Training loss: 2.113929510116577
Validation loss: 2.023560404777527

Epoch: 6| Step: 7
Training loss: 2.341787338256836
Validation loss: 2.0227432250976562

Epoch: 6| Step: 8
Training loss: 1.918257713317871
Validation loss: 2.0249991416931152

Epoch: 6| Step: 9
Training loss: 2.392158031463623
Validation loss: 2.0222925941149392

Epoch: 6| Step: 10
Training loss: 1.4143366813659668
Validation loss: 2.0293585658073425

Epoch: 6| Step: 11
Training loss: 1.7808622121810913
Validation loss: 2.0387786428133645

Epoch: 6| Step: 12
Training loss: 1.952828049659729
Validation loss: 2.0446165402730307

Epoch: 6| Step: 13
Training loss: 2.5951972007751465
Validation loss: 2.0370792746543884

Epoch: 127| Step: 0
Training loss: 2.391921043395996
Validation loss: 2.05463045835495

Epoch: 6| Step: 1
Training loss: 1.8233749866485596
Validation loss: 2.0494812528292337

Epoch: 6| Step: 2
Training loss: 1.9578534364700317
Validation loss: 2.0544338623682656

Epoch: 6| Step: 3
Training loss: 2.601883888244629
Validation loss: 2.0636784633000693

Epoch: 6| Step: 4
Training loss: 1.7249953746795654
Validation loss: 2.0636490980784097

Epoch: 6| Step: 5
Training loss: 2.368654251098633
Validation loss: 2.0633721152941384

Epoch: 6| Step: 6
Training loss: 2.539710760116577
Validation loss: 2.052033563454946

Epoch: 6| Step: 7
Training loss: 1.8246545791625977
Validation loss: 2.042491535345713

Epoch: 6| Step: 8
Training loss: 1.5697767734527588
Validation loss: 2.036837557951609

Epoch: 6| Step: 9
Training loss: 1.8915696144104004
Validation loss: 2.0321536858876548

Epoch: 6| Step: 10
Training loss: 1.9664812088012695
Validation loss: 2.0266923308372498

Epoch: 6| Step: 11
Training loss: 2.397970676422119
Validation loss: 2.02560027440389

Epoch: 6| Step: 12
Training loss: 2.740095615386963
Validation loss: 2.02321728070577

Epoch: 6| Step: 13
Training loss: 1.3322525024414062
Validation loss: 2.027230660120646

Epoch: 128| Step: 0
Training loss: 2.121744394302368
Validation loss: 2.023464103539785

Epoch: 6| Step: 1
Training loss: 2.1701302528381348
Validation loss: 2.0283360878626504

Epoch: 6| Step: 2
Training loss: 1.9666085243225098
Validation loss: 2.022916038831075

Epoch: 6| Step: 3
Training loss: 1.8027241230010986
Validation loss: 2.027935485045115

Epoch: 6| Step: 4
Training loss: 2.0425162315368652
Validation loss: 2.0191916028658548

Epoch: 6| Step: 5
Training loss: 2.1549527645111084
Validation loss: 2.0215077797571817

Epoch: 6| Step: 6
Training loss: 1.9334347248077393
Validation loss: 2.0288041830062866

Epoch: 6| Step: 7
Training loss: 2.2186150550842285
Validation loss: 2.0262468457221985

Epoch: 6| Step: 8
Training loss: 1.8348844051361084
Validation loss: 2.0363490184148154

Epoch: 6| Step: 9
Training loss: 1.6195415258407593
Validation loss: 2.0294793248176575

Epoch: 6| Step: 10
Training loss: 2.1713430881500244
Validation loss: 2.0417003631591797

Epoch: 6| Step: 11
Training loss: 2.377213478088379
Validation loss: 2.041681706905365

Epoch: 6| Step: 12
Training loss: 2.1310172080993652
Validation loss: 2.039344052473704

Epoch: 6| Step: 13
Training loss: 2.2319295406341553
Validation loss: 2.053759535153707

Epoch: 129| Step: 0
Training loss: 2.050283432006836
Validation loss: 2.052709937095642

Epoch: 6| Step: 1
Training loss: 2.1240899562835693
Validation loss: 2.0545207063357034

Epoch: 6| Step: 2
Training loss: 1.8440625667572021
Validation loss: 2.0455091993014016

Epoch: 6| Step: 3
Training loss: 2.253594398498535
Validation loss: 2.035333057244619

Epoch: 6| Step: 4
Training loss: 2.3096323013305664
Validation loss: 2.034457047780355

Epoch: 6| Step: 5
Training loss: 1.3382360935211182
Validation loss: 2.0275107622146606

Epoch: 6| Step: 6
Training loss: 2.058206558227539
Validation loss: 2.026529908180237

Epoch: 6| Step: 7
Training loss: 1.924830436706543
Validation loss: 2.023804704348246

Epoch: 6| Step: 8
Training loss: 1.9798762798309326
Validation loss: 2.0308881203333535

Epoch: 6| Step: 9
Training loss: 2.343204975128174
Validation loss: 2.0259101192156472

Epoch: 6| Step: 10
Training loss: 1.909878134727478
Validation loss: 2.020998259385427

Epoch: 6| Step: 11
Training loss: 2.417454242706299
Validation loss: 2.027246435483297

Epoch: 6| Step: 12
Training loss: 2.0032572746276855
Validation loss: 2.025216003259023

Epoch: 6| Step: 13
Training loss: 2.3199868202209473
Validation loss: 2.022625287373861

Epoch: 130| Step: 0
Training loss: 1.491684079170227
Validation loss: 2.0184877514839172

Epoch: 6| Step: 1
Training loss: 2.21075177192688
Validation loss: 2.0410776138305664

Epoch: 6| Step: 2
Training loss: 1.739592432975769
Validation loss: 2.044135570526123

Epoch: 6| Step: 3
Training loss: 2.249192237854004
Validation loss: 2.038414478302002

Epoch: 6| Step: 4
Training loss: 1.683520793914795
Validation loss: 2.048194090525309

Epoch: 6| Step: 5
Training loss: 2.061278820037842
Validation loss: 2.047217766443888

Epoch: 6| Step: 6
Training loss: 2.4834277629852295
Validation loss: 2.0383534828821817

Epoch: 6| Step: 7
Training loss: 2.139146089553833
Validation loss: 2.040373464425405

Epoch: 6| Step: 8
Training loss: 2.4522485733032227
Validation loss: 2.0295336643854776

Epoch: 6| Step: 9
Training loss: 1.9821313619613647
Validation loss: 2.032571494579315

Epoch: 6| Step: 10
Training loss: 1.8730568885803223
Validation loss: 2.022519071896871

Epoch: 6| Step: 11
Training loss: 1.9208582639694214
Validation loss: 2.0202989180882773

Epoch: 6| Step: 12
Training loss: 2.4368631839752197
Validation loss: 2.0256588459014893

Epoch: 6| Step: 13
Training loss: 2.350785493850708
Validation loss: 2.0262224276860556

Epoch: 131| Step: 0
Training loss: 2.109951972961426
Validation loss: 2.0368763208389282

Epoch: 6| Step: 1
Training loss: 1.875687599182129
Validation loss: 2.03825972477595

Epoch: 6| Step: 2
Training loss: 2.0831212997436523
Validation loss: 2.0401389400164285

Epoch: 6| Step: 3
Training loss: 2.2157974243164062
Validation loss: 2.0475143790245056

Epoch: 6| Step: 4
Training loss: 1.6529498100280762
Validation loss: 2.0409981409708657

Epoch: 6| Step: 5
Training loss: 2.4387097358703613
Validation loss: 2.0318347613016763

Epoch: 6| Step: 6
Training loss: 1.867967963218689
Validation loss: 2.0286173820495605

Epoch: 6| Step: 7
Training loss: 2.1116294860839844
Validation loss: 2.0420073668162027

Epoch: 6| Step: 8
Training loss: 2.1714844703674316
Validation loss: 2.0320002237955728

Epoch: 6| Step: 9
Training loss: 2.126741886138916
Validation loss: 2.0405494769414267

Epoch: 6| Step: 10
Training loss: 1.3177038431167603
Validation loss: 2.039652427037557

Epoch: 6| Step: 11
Training loss: 2.6399214267730713
Validation loss: 2.0345239440600076

Epoch: 6| Step: 12
Training loss: 2.156524181365967
Validation loss: 2.0311493078867593

Epoch: 6| Step: 13
Training loss: 1.945792555809021
Validation loss: 2.033914844195048

Epoch: 132| Step: 0
Training loss: 1.4366579055786133
Validation loss: 2.0396352410316467

Epoch: 6| Step: 1
Training loss: 2.3512814044952393
Validation loss: 2.043283144632975

Epoch: 6| Step: 2
Training loss: 2.1912074089050293
Validation loss: 2.049803157647451

Epoch: 6| Step: 3
Training loss: 2.1716880798339844
Validation loss: 2.0492594043413797

Epoch: 6| Step: 4
Training loss: 1.177437424659729
Validation loss: 2.053503235181173

Epoch: 6| Step: 5
Training loss: 2.144594192504883
Validation loss: 2.033803939819336

Epoch: 6| Step: 6
Training loss: 2.439206123352051
Validation loss: 2.028469741344452

Epoch: 6| Step: 7
Training loss: 1.757716178894043
Validation loss: 2.01824418703715

Epoch: 6| Step: 8
Training loss: 2.217682361602783
Validation loss: 2.0276861786842346

Epoch: 6| Step: 9
Training loss: 1.6611396074295044
Validation loss: 2.0194946924845376

Epoch: 6| Step: 10
Training loss: 2.962484359741211
Validation loss: 2.0109540621439614

Epoch: 6| Step: 11
Training loss: 1.9423398971557617
Validation loss: 2.018516739209493

Epoch: 6| Step: 12
Training loss: 2.3436810970306396
Validation loss: 2.018048048019409

Epoch: 6| Step: 13
Training loss: 2.062563419342041
Validation loss: 2.0168156226476035

Epoch: 133| Step: 0
Training loss: 2.4902701377868652
Validation loss: 2.014618178208669

Epoch: 6| Step: 1
Training loss: 1.6531201601028442
Validation loss: 2.024293065071106

Epoch: 6| Step: 2
Training loss: 2.52451229095459
Validation loss: 2.015520393848419

Epoch: 6| Step: 3
Training loss: 2.496427536010742
Validation loss: 2.0283875664075217

Epoch: 6| Step: 4
Training loss: 1.9104572534561157
Validation loss: 2.027936339378357

Epoch: 6| Step: 5
Training loss: 2.171322822570801
Validation loss: 2.023911456267039

Epoch: 6| Step: 6
Training loss: 1.8010563850402832
Validation loss: 2.0413858890533447

Epoch: 6| Step: 7
Training loss: 2.442060947418213
Validation loss: 2.0352429946263633

Epoch: 6| Step: 8
Training loss: 1.8894143104553223
Validation loss: 2.052036782105764

Epoch: 6| Step: 9
Training loss: 1.840609073638916
Validation loss: 2.0481069485346475

Epoch: 6| Step: 10
Training loss: 1.9093166589736938
Validation loss: 2.0589922269185386

Epoch: 6| Step: 11
Training loss: 1.7948849201202393
Validation loss: 2.061927159627279

Epoch: 6| Step: 12
Training loss: 2.1052703857421875
Validation loss: 2.0500238140424094

Epoch: 6| Step: 13
Training loss: 1.9438469409942627
Validation loss: 2.0486778616905212

Epoch: 134| Step: 0
Training loss: 2.021082639694214
Validation loss: 2.0447253584861755

Epoch: 6| Step: 1
Training loss: 2.5801236629486084
Validation loss: 2.045189102490743

Epoch: 6| Step: 2
Training loss: 1.9513245820999146
Validation loss: 2.0296714901924133

Epoch: 6| Step: 3
Training loss: 2.3836846351623535
Validation loss: 2.0390110413233438

Epoch: 6| Step: 4
Training loss: 2.1328887939453125
Validation loss: 2.035823961098989

Epoch: 6| Step: 5
Training loss: 1.7540593147277832
Validation loss: 2.0290470123291016

Epoch: 6| Step: 6
Training loss: 2.0879342555999756
Validation loss: 2.03048582871755

Epoch: 6| Step: 7
Training loss: 2.017223358154297
Validation loss: 2.0331615209579468

Epoch: 6| Step: 8
Training loss: 2.54378080368042
Validation loss: 2.036861856778463

Epoch: 6| Step: 9
Training loss: 1.629544734954834
Validation loss: 2.01775199174881

Epoch: 6| Step: 10
Training loss: 2.1560354232788086
Validation loss: 2.0230817993481955

Epoch: 6| Step: 11
Training loss: 1.8158080577850342
Validation loss: 2.0322144428888955

Epoch: 6| Step: 12
Training loss: 2.105713367462158
Validation loss: 2.0442779858907065

Epoch: 6| Step: 13
Training loss: 1.7590758800506592
Validation loss: 2.049841662247976

Epoch: 135| Step: 0
Training loss: 1.9884748458862305
Validation loss: 2.0545808474222818

Epoch: 6| Step: 1
Training loss: 2.359398365020752
Validation loss: 2.057924966017405

Epoch: 6| Step: 2
Training loss: 2.0074551105499268
Validation loss: 2.0591293573379517

Epoch: 6| Step: 3
Training loss: 2.0674009323120117
Validation loss: 2.061095913251241

Epoch: 6| Step: 4
Training loss: 2.7251811027526855
Validation loss: 2.058724820613861

Epoch: 6| Step: 5
Training loss: 1.8123239278793335
Validation loss: 2.0524981021881104

Epoch: 6| Step: 6
Training loss: 1.6868000030517578
Validation loss: 2.0488239924112954

Epoch: 6| Step: 7
Training loss: 1.9181063175201416
Validation loss: 2.0380468169848123

Epoch: 6| Step: 8
Training loss: 2.5801644325256348
Validation loss: 2.040535489718119

Epoch: 6| Step: 9
Training loss: 2.129317283630371
Validation loss: 2.044053037961324

Epoch: 6| Step: 10
Training loss: 2.060443878173828
Validation loss: 2.0329015056292215

Epoch: 6| Step: 11
Training loss: 2.1653480529785156
Validation loss: 2.025882601737976

Epoch: 6| Step: 12
Training loss: 1.6091766357421875
Validation loss: 2.021624445915222

Epoch: 6| Step: 13
Training loss: 2.0550498962402344
Validation loss: 2.0237244764963784

Epoch: 136| Step: 0
Training loss: 2.2504172325134277
Validation loss: 2.021863579750061

Epoch: 6| Step: 1
Training loss: 2.1283929347991943
Validation loss: 2.0284883181254068

Epoch: 6| Step: 2
Training loss: 1.6299419403076172
Validation loss: 2.0302339990933738

Epoch: 6| Step: 3
Training loss: 2.6730408668518066
Validation loss: 2.0335360964139304

Epoch: 6| Step: 4
Training loss: 1.8671138286590576
Validation loss: 2.0418707927068076

Epoch: 6| Step: 5
Training loss: 1.6297937631607056
Validation loss: 2.0456270972887673

Epoch: 6| Step: 6
Training loss: 1.810943365097046
Validation loss: 2.0506437619527182

Epoch: 6| Step: 7
Training loss: 1.9477030038833618
Validation loss: 2.050505300362905

Epoch: 6| Step: 8
Training loss: 2.603843927383423
Validation loss: 2.0805252393086753

Epoch: 6| Step: 9
Training loss: 2.4427475929260254
Validation loss: 2.069117546081543

Epoch: 6| Step: 10
Training loss: 1.8625973463058472
Validation loss: 2.0718241333961487

Epoch: 6| Step: 11
Training loss: 1.8750381469726562
Validation loss: 2.0825172662734985

Epoch: 6| Step: 12
Training loss: 1.7065379619598389
Validation loss: 2.0768734415372214

Epoch: 6| Step: 13
Training loss: 2.4996728897094727
Validation loss: 2.0769297083218894

Epoch: 137| Step: 0
Training loss: 2.455052375793457
Validation loss: 2.084233899911245

Epoch: 6| Step: 1
Training loss: 2.1243295669555664
Validation loss: 2.0642390847206116

Epoch: 6| Step: 2
Training loss: 1.8493670225143433
Validation loss: 2.0607162714004517

Epoch: 6| Step: 3
Training loss: 2.3245794773101807
Validation loss: 2.050014396508535

Epoch: 6| Step: 4
Training loss: 1.9917722940444946
Validation loss: 2.0534947514533997

Epoch: 6| Step: 5
Training loss: 2.284066915512085
Validation loss: 2.0404887199401855

Epoch: 6| Step: 6
Training loss: 1.9201183319091797
Validation loss: 2.0390848318735757

Epoch: 6| Step: 7
Training loss: 1.845340371131897
Validation loss: 2.0384981830914817

Epoch: 6| Step: 8
Training loss: 1.5161187648773193
Validation loss: 2.046332319577535

Epoch: 6| Step: 9
Training loss: 2.126333236694336
Validation loss: 2.0397659142812095

Epoch: 6| Step: 10
Training loss: 2.436765670776367
Validation loss: 2.047268191973368

Epoch: 6| Step: 11
Training loss: 2.312340259552002
Validation loss: 2.0517895817756653

Epoch: 6| Step: 12
Training loss: 2.197479724884033
Validation loss: 2.0483436981836953

Epoch: 6| Step: 13
Training loss: 1.5295605659484863
Validation loss: 2.054488162199656

Epoch: 138| Step: 0
Training loss: 1.89028000831604
Validation loss: 2.052107354005178

Epoch: 6| Step: 1
Training loss: 2.2204551696777344
Validation loss: 2.0645918051401773

Epoch: 6| Step: 2
Training loss: 2.370121955871582
Validation loss: 2.0577341318130493

Epoch: 6| Step: 3
Training loss: 1.91011381149292
Validation loss: 2.0706323782602944

Epoch: 6| Step: 4
Training loss: 1.9676226377487183
Validation loss: 2.0646937092145285

Epoch: 6| Step: 5
Training loss: 1.4869688749313354
Validation loss: 2.0657320419947305

Epoch: 6| Step: 6
Training loss: 2.290228843688965
Validation loss: 2.0625726183255515

Epoch: 6| Step: 7
Training loss: 1.616100549697876
Validation loss: 2.0609439412752786

Epoch: 6| Step: 8
Training loss: 1.8402758836746216
Validation loss: 2.058923661708832

Epoch: 6| Step: 9
Training loss: 2.200031280517578
Validation loss: 2.0602256655693054

Epoch: 6| Step: 10
Training loss: 2.3072762489318848
Validation loss: 2.0618594884872437

Epoch: 6| Step: 11
Training loss: 1.9063310623168945
Validation loss: 2.0689600507418313

Epoch: 6| Step: 12
Training loss: 2.209298849105835
Validation loss: 2.0617336432139077

Epoch: 6| Step: 13
Training loss: 2.3042473793029785
Validation loss: 2.050329089164734

Epoch: 139| Step: 0
Training loss: 2.330941677093506
Validation loss: 2.0665730635325112

Epoch: 6| Step: 1
Training loss: 1.7310433387756348
Validation loss: 2.0610125064849854

Epoch: 6| Step: 2
Training loss: 1.8635005950927734
Validation loss: 2.0476046999295554

Epoch: 6| Step: 3
Training loss: 2.53262996673584
Validation loss: 2.0658492843310037

Epoch: 6| Step: 4
Training loss: 1.6771939992904663
Validation loss: 2.0740760564804077

Epoch: 6| Step: 5
Training loss: 1.8972666263580322
Validation loss: 2.0758923292160034

Epoch: 6| Step: 6
Training loss: 1.9893829822540283
Validation loss: 2.0682387153307595

Epoch: 6| Step: 7
Training loss: 1.70074462890625
Validation loss: 2.068499505519867

Epoch: 6| Step: 8
Training loss: 2.3489022254943848
Validation loss: 2.064929445584615

Epoch: 6| Step: 9
Training loss: 2.013338088989258
Validation loss: 2.0604951977729797

Epoch: 6| Step: 10
Training loss: 2.404853343963623
Validation loss: 2.0555270115534463

Epoch: 6| Step: 11
Training loss: 1.940562129020691
Validation loss: 2.047394792238871

Epoch: 6| Step: 12
Training loss: 2.562833309173584
Validation loss: 2.0372342069943747

Epoch: 6| Step: 13
Training loss: 1.8108806610107422
Validation loss: 2.0321462949117026

Epoch: 140| Step: 0
Training loss: 2.0617904663085938
Validation loss: 2.0200666983922324

Epoch: 6| Step: 1
Training loss: 2.391423463821411
Validation loss: 2.026318987210592

Epoch: 6| Step: 2
Training loss: 1.8681621551513672
Validation loss: 2.0225804845492044

Epoch: 6| Step: 3
Training loss: 1.6193606853485107
Validation loss: 2.029096166292826

Epoch: 6| Step: 4
Training loss: 2.0387935638427734
Validation loss: 2.025785287221273

Epoch: 6| Step: 5
Training loss: 1.6816356182098389
Validation loss: 2.024356027444204

Epoch: 6| Step: 6
Training loss: 2.470034122467041
Validation loss: 2.036858002344767

Epoch: 6| Step: 7
Training loss: 2.1057753562927246
Validation loss: 2.02814257144928

Epoch: 6| Step: 8
Training loss: 1.8501811027526855
Validation loss: 2.0397680004437766

Epoch: 6| Step: 9
Training loss: 2.380581855773926
Validation loss: 2.061858057975769

Epoch: 6| Step: 10
Training loss: 2.541646957397461
Validation loss: 2.0782699386278787

Epoch: 6| Step: 11
Training loss: 1.9469801187515259
Validation loss: 2.0789663195610046

Epoch: 6| Step: 12
Training loss: 2.32905912399292
Validation loss: 2.0787472327550254

Epoch: 6| Step: 13
Training loss: 1.7889302968978882
Validation loss: 2.063569207986196

Epoch: 141| Step: 0
Training loss: 1.8848227262496948
Validation loss: 2.0685006777445474

Epoch: 6| Step: 1
Training loss: 1.9011478424072266
Validation loss: 2.050239165623983

Epoch: 6| Step: 2
Training loss: 2.191342353820801
Validation loss: 2.046526571114858

Epoch: 6| Step: 3
Training loss: 1.7695791721343994
Validation loss: 2.0532286961873374

Epoch: 6| Step: 4
Training loss: 2.1008548736572266
Validation loss: 2.0400431553522744

Epoch: 6| Step: 5
Training loss: 1.593717098236084
Validation loss: 2.0465362071990967

Epoch: 6| Step: 6
Training loss: 1.9363402128219604
Validation loss: 2.046514093875885

Epoch: 6| Step: 7
Training loss: 1.9534435272216797
Validation loss: 2.056772251923879

Epoch: 6| Step: 8
Training loss: 2.423309803009033
Validation loss: 2.0524545510609946

Epoch: 6| Step: 9
Training loss: 2.28106689453125
Validation loss: 2.0555370847384133

Epoch: 6| Step: 10
Training loss: 2.4282820224761963
Validation loss: 2.0590803623199463

Epoch: 6| Step: 11
Training loss: 2.006279706954956
Validation loss: 2.0495803356170654

Epoch: 6| Step: 12
Training loss: 1.8783533573150635
Validation loss: 2.0552525321642556

Epoch: 6| Step: 13
Training loss: 2.0015652179718018
Validation loss: 2.053246100743612

Epoch: 142| Step: 0
Training loss: 1.8292213678359985
Validation loss: 2.049327790737152

Epoch: 6| Step: 1
Training loss: 2.131342887878418
Validation loss: 2.0531075596809387

Epoch: 6| Step: 2
Training loss: 1.7935208082199097
Validation loss: 2.0423039396603904

Epoch: 6| Step: 3
Training loss: 1.6071765422821045
Validation loss: 2.05528457959493

Epoch: 6| Step: 4
Training loss: 1.7865718603134155
Validation loss: 2.0607020457585654

Epoch: 6| Step: 5
Training loss: 2.0939087867736816
Validation loss: 2.0596523682276406

Epoch: 6| Step: 6
Training loss: 1.8548238277435303
Validation loss: 2.060593585173289

Epoch: 6| Step: 7
Training loss: 2.368532657623291
Validation loss: 2.0625803470611572

Epoch: 6| Step: 8
Training loss: 2.0069544315338135
Validation loss: 2.0832729736963906

Epoch: 6| Step: 9
Training loss: 2.217313766479492
Validation loss: 2.0781153043111167

Epoch: 6| Step: 10
Training loss: 2.5536131858825684
Validation loss: 2.077348609765371

Epoch: 6| Step: 11
Training loss: 1.712538480758667
Validation loss: 2.060583015282949

Epoch: 6| Step: 12
Training loss: 2.0974087715148926
Validation loss: 2.057027538617452

Epoch: 6| Step: 13
Training loss: 2.315523624420166
Validation loss: 2.0477883418401084

Epoch: 143| Step: 0
Training loss: 2.190702438354492
Validation loss: 2.0470618406931558

Epoch: 6| Step: 1
Training loss: 2.1944632530212402
Validation loss: 2.0485132733980813

Epoch: 6| Step: 2
Training loss: 2.5038352012634277
Validation loss: 2.036103308200836

Epoch: 6| Step: 3
Training loss: 2.4479331970214844
Validation loss: 2.035293161869049

Epoch: 6| Step: 4
Training loss: 1.7431786060333252
Validation loss: 2.041663706302643

Epoch: 6| Step: 5
Training loss: 1.9531381130218506
Validation loss: 2.0329282681147256

Epoch: 6| Step: 6
Training loss: 1.517770528793335
Validation loss: 2.037373940149943

Epoch: 6| Step: 7
Training loss: 1.4878538846969604
Validation loss: 2.039744555950165

Epoch: 6| Step: 8
Training loss: 1.7354559898376465
Validation loss: 2.0385833779970803

Epoch: 6| Step: 9
Training loss: 2.1812005043029785
Validation loss: 2.0518803000450134

Epoch: 6| Step: 10
Training loss: 1.9887361526489258
Validation loss: 2.0555723905563354

Epoch: 6| Step: 11
Training loss: 1.769335150718689
Validation loss: 2.0562544465065002

Epoch: 6| Step: 12
Training loss: 2.4165871143341064
Validation loss: 2.0454211036364236

Epoch: 6| Step: 13
Training loss: 2.1232500076293945
Validation loss: 2.0552411874135337

Epoch: 144| Step: 0
Training loss: 2.024423122406006
Validation loss: 2.054272989432017

Epoch: 6| Step: 1
Training loss: 2.208733558654785
Validation loss: 2.058854103088379

Epoch: 6| Step: 2
Training loss: 2.1453211307525635
Validation loss: 2.0585037668546042

Epoch: 6| Step: 3
Training loss: 1.880164384841919
Validation loss: 2.047598421573639

Epoch: 6| Step: 4
Training loss: 2.282444477081299
Validation loss: 2.051569402217865

Epoch: 6| Step: 5
Training loss: 2.3300857543945312
Validation loss: 2.0517035722732544

Epoch: 6| Step: 6
Training loss: 2.0519206523895264
Validation loss: 2.0582491755485535

Epoch: 6| Step: 7
Training loss: 2.0054712295532227
Validation loss: 2.0609784921010337

Epoch: 6| Step: 8
Training loss: 2.27063250541687
Validation loss: 2.059172511100769

Epoch: 6| Step: 9
Training loss: 1.2647879123687744
Validation loss: 2.061331808567047

Epoch: 6| Step: 10
Training loss: 2.0733916759490967
Validation loss: 2.0697951714197793

Epoch: 6| Step: 11
Training loss: 1.9207454919815063
Validation loss: 2.0649375319480896

Epoch: 6| Step: 12
Training loss: 1.6140069961547852
Validation loss: 2.059474249680837

Epoch: 6| Step: 13
Training loss: 2.3073625564575195
Validation loss: 2.0755664308865867

Epoch: 145| Step: 0
Training loss: 1.5311005115509033
Validation loss: 2.0756215254465737

Epoch: 6| Step: 1
Training loss: 2.596562623977661
Validation loss: 2.068147381146749

Epoch: 6| Step: 2
Training loss: 2.1172125339508057
Validation loss: 2.062966307004293

Epoch: 6| Step: 3
Training loss: 2.431030035018921
Validation loss: 2.0632233023643494

Epoch: 6| Step: 4
Training loss: 1.955838680267334
Validation loss: 2.0686802864074707

Epoch: 6| Step: 5
Training loss: 1.550229549407959
Validation loss: 2.0628820856412253

Epoch: 6| Step: 6
Training loss: 1.8512372970581055
Validation loss: 2.0719037453333535

Epoch: 6| Step: 7
Training loss: 2.0400354862213135
Validation loss: 2.0627504189809165

Epoch: 6| Step: 8
Training loss: 1.9597339630126953
Validation loss: 2.054798146088918

Epoch: 6| Step: 9
Training loss: 1.687415361404419
Validation loss: 2.0623139142990112

Epoch: 6| Step: 10
Training loss: 2.0202279090881348
Validation loss: 2.0640262365341187

Epoch: 6| Step: 11
Training loss: 2.249206781387329
Validation loss: 2.061998963356018

Epoch: 6| Step: 12
Training loss: 2.0796351432800293
Validation loss: 2.054262936115265

Epoch: 6| Step: 13
Training loss: 2.143322467803955
Validation loss: 2.070616046587626

Epoch: 146| Step: 0
Training loss: 2.86069655418396
Validation loss: 2.0802082419395447

Epoch: 6| Step: 1
Training loss: 2.077726364135742
Validation loss: 2.0685656468073526

Epoch: 6| Step: 2
Training loss: 1.6959638595581055
Validation loss: 2.086713512738546

Epoch: 6| Step: 3
Training loss: 2.3972649574279785
Validation loss: 2.083280007044474

Epoch: 6| Step: 4
Training loss: 1.6132380962371826
Validation loss: 2.084060331185659

Epoch: 6| Step: 5
Training loss: 2.4786643981933594
Validation loss: 2.0853628714879355

Epoch: 6| Step: 6
Training loss: 2.3147788047790527
Validation loss: 2.0786602099736533

Epoch: 6| Step: 7
Training loss: 1.5699901580810547
Validation loss: 2.08322540918986

Epoch: 6| Step: 8
Training loss: 2.23337721824646
Validation loss: 2.074432988961538

Epoch: 6| Step: 9
Training loss: 1.7477772235870361
Validation loss: 2.0612855752309165

Epoch: 6| Step: 10
Training loss: 1.8534153699874878
Validation loss: 2.058217167854309

Epoch: 6| Step: 11
Training loss: 1.7295117378234863
Validation loss: 2.0543763637542725

Epoch: 6| Step: 12
Training loss: 1.4074100255966187
Validation loss: 2.0603115359942117

Epoch: 6| Step: 13
Training loss: 2.3725790977478027
Validation loss: 2.06029345591863

Epoch: 147| Step: 0
Training loss: 2.183246612548828
Validation loss: 2.0640872716903687

Epoch: 6| Step: 1
Training loss: 1.6287126541137695
Validation loss: 2.0627992153167725

Epoch: 6| Step: 2
Training loss: 1.8478885889053345
Validation loss: 2.061397393544515

Epoch: 6| Step: 3
Training loss: 2.101935863494873
Validation loss: 2.0732086896896362

Epoch: 6| Step: 4
Training loss: 1.8912603855133057
Validation loss: 2.0727494955062866

Epoch: 6| Step: 5
Training loss: 2.564218759536743
Validation loss: 2.062161068121592

Epoch: 6| Step: 6
Training loss: 2.5140583515167236
Validation loss: 2.076030671596527

Epoch: 6| Step: 7
Training loss: 2.727815628051758
Validation loss: 2.0718470017115274

Epoch: 6| Step: 8
Training loss: 1.9308041334152222
Validation loss: 2.077016830444336

Epoch: 6| Step: 9
Training loss: 1.8360590934753418
Validation loss: 2.0827441612879434

Epoch: 6| Step: 10
Training loss: 2.1904594898223877
Validation loss: 2.0658120115598044

Epoch: 6| Step: 11
Training loss: 1.5956231355667114
Validation loss: 2.07914932568868

Epoch: 6| Step: 12
Training loss: 1.6729423999786377
Validation loss: 2.0884685118993125

Epoch: 6| Step: 13
Training loss: 1.4692978858947754
Validation loss: 2.0835084319114685

Epoch: 148| Step: 0
Training loss: 1.726024866104126
Validation loss: 2.0758726398150125

Epoch: 6| Step: 1
Training loss: 1.652228832244873
Validation loss: 2.072514017422994

Epoch: 6| Step: 2
Training loss: 2.149613380432129
Validation loss: 2.0861271222432456

Epoch: 6| Step: 3
Training loss: 1.6901021003723145
Validation loss: 2.0802374879519143

Epoch: 6| Step: 4
Training loss: 2.0001416206359863
Validation loss: 2.076895515124003

Epoch: 6| Step: 5
Training loss: 1.639050841331482
Validation loss: 2.0725706020991006

Epoch: 6| Step: 6
Training loss: 2.5096912384033203
Validation loss: 2.0589683055877686

Epoch: 6| Step: 7
Training loss: 1.8945426940917969
Validation loss: 2.0648880998293557

Epoch: 6| Step: 8
Training loss: 1.7810802459716797
Validation loss: 2.052879194418589

Epoch: 6| Step: 9
Training loss: 2.976928472518921
Validation loss: 2.0561201572418213

Epoch: 6| Step: 10
Training loss: 2.4495627880096436
Validation loss: 2.0485576589902244

Epoch: 6| Step: 11
Training loss: 1.683562159538269
Validation loss: 2.050360937913259

Epoch: 6| Step: 12
Training loss: 1.8005309104919434
Validation loss: 2.0612208247184753

Epoch: 6| Step: 13
Training loss: 2.3084747791290283
Validation loss: 2.0648726423581443

Epoch: 149| Step: 0
Training loss: 2.332907199859619
Validation loss: 2.067315916220347

Epoch: 6| Step: 1
Training loss: 1.4386935234069824
Validation loss: 2.075461685657501

Epoch: 6| Step: 2
Training loss: 2.977937698364258
Validation loss: 2.0707125663757324

Epoch: 6| Step: 3
Training loss: 2.0669147968292236
Validation loss: 2.0672060449918113

Epoch: 6| Step: 4
Training loss: 1.8076735734939575
Validation loss: 2.0768935680389404

Epoch: 6| Step: 5
Training loss: 2.831707715988159
Validation loss: 2.066013753414154

Epoch: 6| Step: 6
Training loss: 2.3248205184936523
Validation loss: 2.0650105079015098

Epoch: 6| Step: 7
Training loss: 1.8825657367706299
Validation loss: 2.053724149862925

Epoch: 6| Step: 8
Training loss: 1.6354939937591553
Validation loss: 2.0536253849665322

Epoch: 6| Step: 9
Training loss: 2.152705192565918
Validation loss: 2.039793054262797

Epoch: 6| Step: 10
Training loss: 1.7199920415878296
Validation loss: 2.049078404903412

Epoch: 6| Step: 11
Training loss: 1.7958801984786987
Validation loss: 2.0474553306897483

Epoch: 6| Step: 12
Training loss: 1.9826712608337402
Validation loss: 2.036965072154999

Epoch: 6| Step: 13
Training loss: 1.6284652948379517
Validation loss: 2.056463082631429

Epoch: 150| Step: 0
Training loss: 1.9571824073791504
Validation loss: 2.0500900546709695

Epoch: 6| Step: 1
Training loss: 1.921539068222046
Validation loss: 2.047618548075358

Epoch: 6| Step: 2
Training loss: 2.6264593601226807
Validation loss: 2.058903614679972

Epoch: 6| Step: 3
Training loss: 1.7629263401031494
Validation loss: 2.064240554968516

Epoch: 6| Step: 4
Training loss: 1.948346495628357
Validation loss: 2.0577024022738137

Epoch: 6| Step: 5
Training loss: 1.7469711303710938
Validation loss: 2.053463558355967

Epoch: 6| Step: 6
Training loss: 1.6231918334960938
Validation loss: 2.050499379634857

Epoch: 6| Step: 7
Training loss: 2.3513331413269043
Validation loss: 2.058870037396749

Epoch: 6| Step: 8
Training loss: 1.458382248878479
Validation loss: 2.047716955343882

Epoch: 6| Step: 9
Training loss: 2.0453689098358154
Validation loss: 2.053835848967234

Epoch: 6| Step: 10
Training loss: 2.4045493602752686
Validation loss: 2.0483486453692117

Epoch: 6| Step: 11
Training loss: 2.1363039016723633
Validation loss: 2.0580730040868125

Epoch: 6| Step: 12
Training loss: 2.314772844314575
Validation loss: 2.0443950096766152

Epoch: 6| Step: 13
Training loss: 1.869704008102417
Validation loss: 2.0479219953219094

Epoch: 151| Step: 0
Training loss: 1.8422448635101318
Validation loss: 2.046719968318939

Epoch: 6| Step: 1
Training loss: 1.954230785369873
Validation loss: 2.0474881529808044

Epoch: 6| Step: 2
Training loss: 1.6410542726516724
Validation loss: 2.062623381614685

Epoch: 6| Step: 3
Training loss: 2.7865962982177734
Validation loss: 2.0585737029711404

Epoch: 6| Step: 4
Training loss: 1.6782324314117432
Validation loss: 2.055736541748047

Epoch: 6| Step: 5
Training loss: 1.4597886800765991
Validation loss: 2.0682976841926575

Epoch: 6| Step: 6
Training loss: 2.2666406631469727
Validation loss: 2.0674371321996055

Epoch: 6| Step: 7
Training loss: 2.076958179473877
Validation loss: 2.0737706820170083

Epoch: 6| Step: 8
Training loss: 1.7961039543151855
Validation loss: 2.0747154156366983

Epoch: 6| Step: 9
Training loss: 2.792964458465576
Validation loss: 2.066137512524923

Epoch: 6| Step: 10
Training loss: 1.9076077938079834
Validation loss: 2.0551437735557556

Epoch: 6| Step: 11
Training loss: 2.452622413635254
Validation loss: 2.043319900830587

Epoch: 6| Step: 12
Training loss: 1.6732683181762695
Validation loss: 2.0656485160191855

Epoch: 6| Step: 13
Training loss: 1.8778223991394043
Validation loss: 2.0594059030214944

Epoch: 152| Step: 0
Training loss: 1.7798017263412476
Validation loss: 2.067177633444468

Epoch: 6| Step: 1
Training loss: 2.462495803833008
Validation loss: 2.05928502480189

Epoch: 6| Step: 2
Training loss: 2.0534257888793945
Validation loss: 2.0645936330159507

Epoch: 6| Step: 3
Training loss: 2.3609466552734375
Validation loss: 2.0588599840799966

Epoch: 6| Step: 4
Training loss: 1.4812142848968506
Validation loss: 2.078196167945862

Epoch: 6| Step: 5
Training loss: 1.9986652135849
Validation loss: 2.068172593911489

Epoch: 6| Step: 6
Training loss: 1.7612433433532715
Validation loss: 2.0873543421427407

Epoch: 6| Step: 7
Training loss: 2.2206473350524902
Validation loss: 2.0756136576334634

Epoch: 6| Step: 8
Training loss: 2.202439069747925
Validation loss: 2.082304755846659

Epoch: 6| Step: 9
Training loss: 1.6728012561798096
Validation loss: 2.087415178616842

Epoch: 6| Step: 10
Training loss: 2.0665783882141113
Validation loss: 2.078227937221527

Epoch: 6| Step: 11
Training loss: 1.7460697889328003
Validation loss: 2.083021899064382

Epoch: 6| Step: 12
Training loss: 2.089366912841797
Validation loss: 2.0673691829045615

Epoch: 6| Step: 13
Training loss: 2.0444893836975098
Validation loss: 2.076109846433004

Epoch: 153| Step: 0
Training loss: 2.542670249938965
Validation loss: 2.076206942399343

Epoch: 6| Step: 1
Training loss: 2.209930896759033
Validation loss: 2.061470707257589

Epoch: 6| Step: 2
Training loss: 1.6026850938796997
Validation loss: 2.0605349938074746

Epoch: 6| Step: 3
Training loss: 2.72649884223938
Validation loss: 2.070271889368693

Epoch: 6| Step: 4
Training loss: 1.8326215744018555
Validation loss: 2.075678984324137

Epoch: 6| Step: 5
Training loss: 2.333955764770508
Validation loss: 2.0729256868362427

Epoch: 6| Step: 6
Training loss: 1.9067615270614624
Validation loss: 2.073137660821279

Epoch: 6| Step: 7
Training loss: 1.4703381061553955
Validation loss: 2.0626367727915444

Epoch: 6| Step: 8
Training loss: 1.8068815469741821
Validation loss: 2.0625760753949485

Epoch: 6| Step: 9
Training loss: 1.8461735248565674
Validation loss: 2.051448384920756

Epoch: 6| Step: 10
Training loss: 2.5252559185028076
Validation loss: 2.0585668087005615

Epoch: 6| Step: 11
Training loss: 1.337397575378418
Validation loss: 2.057486136754354

Epoch: 6| Step: 12
Training loss: 1.9396758079528809
Validation loss: 2.0631324648857117

Epoch: 6| Step: 13
Training loss: 2.0296790599823
Validation loss: 2.080158074696859

Epoch: 154| Step: 0
Training loss: 2.1438534259796143
Validation loss: 2.082722544670105

Epoch: 6| Step: 1
Training loss: 2.4069089889526367
Validation loss: 2.100274920463562

Epoch: 6| Step: 2
Training loss: 2.470867156982422
Validation loss: 2.0830002427101135

Epoch: 6| Step: 3
Training loss: 2.4055237770080566
Validation loss: 2.1011984944343567

Epoch: 6| Step: 4
Training loss: 2.023188352584839
Validation loss: 2.093754529953003

Epoch: 6| Step: 5
Training loss: 2.4481916427612305
Validation loss: 2.074073771635691

Epoch: 6| Step: 6
Training loss: 1.8609803915023804
Validation loss: 2.0766159693400064

Epoch: 6| Step: 7
Training loss: 1.2687584161758423
Validation loss: 2.0759806632995605

Epoch: 6| Step: 8
Training loss: 1.8738017082214355
Validation loss: 2.0702770551045737

Epoch: 6| Step: 9
Training loss: 2.1021175384521484
Validation loss: 2.05775515238444

Epoch: 6| Step: 10
Training loss: 1.675656795501709
Validation loss: 2.054397980372111

Epoch: 6| Step: 11
Training loss: 1.7692230939865112
Validation loss: 2.056421677271525

Epoch: 6| Step: 12
Training loss: 2.2106566429138184
Validation loss: 2.050658404827118

Epoch: 6| Step: 13
Training loss: 1.6974538564682007
Validation loss: 2.058542708555857

Epoch: 155| Step: 0
Training loss: 2.4765729904174805
Validation loss: 2.056861956914266

Epoch: 6| Step: 1
Training loss: 1.604561448097229
Validation loss: 2.0509673754374185

Epoch: 6| Step: 2
Training loss: 2.3973336219787598
Validation loss: 2.069686790307363

Epoch: 6| Step: 3
Training loss: 2.260463237762451
Validation loss: 2.0657259623209634

Epoch: 6| Step: 4
Training loss: 2.0408434867858887
Validation loss: 2.0685450434684753

Epoch: 6| Step: 5
Training loss: 1.671992301940918
Validation loss: 2.066770076751709

Epoch: 6| Step: 6
Training loss: 1.847548484802246
Validation loss: 2.0717453956604004

Epoch: 6| Step: 7
Training loss: 1.9508395195007324
Validation loss: 2.0576416850090027

Epoch: 6| Step: 8
Training loss: 2.463381290435791
Validation loss: 2.0532955129941306

Epoch: 6| Step: 9
Training loss: 1.7172064781188965
Validation loss: 2.0603156288464866

Epoch: 6| Step: 10
Training loss: 1.7960619926452637
Validation loss: 2.0458982388178506

Epoch: 6| Step: 11
Training loss: 2.466823101043701
Validation loss: 2.0558390617370605

Epoch: 6| Step: 12
Training loss: 1.6800470352172852
Validation loss: 2.059584637482961

Epoch: 6| Step: 13
Training loss: 1.5339438915252686
Validation loss: 2.044078608353933

Epoch: 156| Step: 0
Training loss: 1.5491089820861816
Validation loss: 2.0500388542811074

Epoch: 6| Step: 1
Training loss: 1.6974883079528809
Validation loss: 2.059753954410553

Epoch: 6| Step: 2
Training loss: 1.8835813999176025
Validation loss: 2.062459429105123

Epoch: 6| Step: 3
Training loss: 1.9444859027862549
Validation loss: 2.0635687510172525

Epoch: 6| Step: 4
Training loss: 2.331101417541504
Validation loss: 2.065337578455607

Epoch: 6| Step: 5
Training loss: 1.7658551931381226
Validation loss: 2.06709893544515

Epoch: 6| Step: 6
Training loss: 1.8097350597381592
Validation loss: 2.0817753076553345

Epoch: 6| Step: 7
Training loss: 1.9575656652450562
Validation loss: 2.0738898317019143

Epoch: 6| Step: 8
Training loss: 2.081042766571045
Validation loss: 2.0766897996266684

Epoch: 6| Step: 9
Training loss: 1.513466715812683
Validation loss: 2.07212370634079

Epoch: 6| Step: 10
Training loss: 2.065725326538086
Validation loss: 2.0625811020533242

Epoch: 6| Step: 11
Training loss: 2.6301822662353516
Validation loss: 2.081864515940348

Epoch: 6| Step: 12
Training loss: 2.2670657634735107
Validation loss: 2.0910873413085938

Epoch: 6| Step: 13
Training loss: 2.5033252239227295
Validation loss: 2.069164216518402

Epoch: 157| Step: 0
Training loss: 1.7646136283874512
Validation loss: 2.0783888498942056

Epoch: 6| Step: 1
Training loss: 2.5606837272644043
Validation loss: 2.074465493361155

Epoch: 6| Step: 2
Training loss: 2.2428083419799805
Validation loss: 2.076328456401825

Epoch: 6| Step: 3
Training loss: 1.7006624937057495
Validation loss: 2.0636786222457886

Epoch: 6| Step: 4
Training loss: 2.2395284175872803
Validation loss: 2.0859603881835938

Epoch: 6| Step: 5
Training loss: 2.270965576171875
Validation loss: 2.054578344027201

Epoch: 6| Step: 6
Training loss: 1.3304486274719238
Validation loss: 2.0597073634465537

Epoch: 6| Step: 7
Training loss: 2.445253610610962
Validation loss: 2.056734085083008

Epoch: 6| Step: 8
Training loss: 1.717661738395691
Validation loss: 2.060405890146891

Epoch: 6| Step: 9
Training loss: 2.1126482486724854
Validation loss: 2.052194118499756

Epoch: 6| Step: 10
Training loss: 2.211581230163574
Validation loss: 2.054615000883738

Epoch: 6| Step: 11
Training loss: 1.7850183248519897
Validation loss: 2.0562471747398376

Epoch: 6| Step: 12
Training loss: 1.735705852508545
Validation loss: 2.0549566547075906

Epoch: 6| Step: 13
Training loss: 2.129180669784546
Validation loss: 2.0701714356740317

Epoch: 158| Step: 0
Training loss: 2.1596851348876953
Validation loss: 2.0861271619796753

Epoch: 6| Step: 1
Training loss: 2.1081931591033936
Validation loss: 2.0671480894088745

Epoch: 6| Step: 2
Training loss: 1.7784405946731567
Validation loss: 2.076836625734965

Epoch: 6| Step: 3
Training loss: 2.042285919189453
Validation loss: 2.0970056851704917

Epoch: 6| Step: 4
Training loss: 2.3319520950317383
Validation loss: 2.0886407693227134

Epoch: 6| Step: 5
Training loss: 1.5766017436981201
Validation loss: 2.0937370459238687

Epoch: 6| Step: 6
Training loss: 2.3865044116973877
Validation loss: 2.0827292799949646

Epoch: 6| Step: 7
Training loss: 2.207432746887207
Validation loss: 2.08209361632665

Epoch: 6| Step: 8
Training loss: 1.7588247060775757
Validation loss: 2.075893441836039

Epoch: 6| Step: 9
Training loss: 2.110003709793091
Validation loss: 2.080964128176371

Epoch: 6| Step: 10
Training loss: 1.8009065389633179
Validation loss: 2.0769206086794534

Epoch: 6| Step: 11
Training loss: 2.598254680633545
Validation loss: 2.0815453131993613

Epoch: 6| Step: 12
Training loss: 1.7470273971557617
Validation loss: 2.0642667611440024

Epoch: 6| Step: 13
Training loss: 1.3175451755523682
Validation loss: 2.071338713169098

Epoch: 159| Step: 0
Training loss: 2.0385305881500244
Validation loss: 2.070549726486206

Epoch: 6| Step: 1
Training loss: 1.5757791996002197
Validation loss: 2.0818763375282288

Epoch: 6| Step: 2
Training loss: 2.669896364212036
Validation loss: 2.067128340403239

Epoch: 6| Step: 3
Training loss: 1.6682791709899902
Validation loss: 2.085362990697225

Epoch: 6| Step: 4
Training loss: 2.046234130859375
Validation loss: 2.0932243863741555

Epoch: 6| Step: 5
Training loss: 2.3620095252990723
Validation loss: 2.0994377732276917

Epoch: 6| Step: 6
Training loss: 2.083920478820801
Validation loss: 2.0872207283973694

Epoch: 6| Step: 7
Training loss: 1.8344581127166748
Validation loss: 2.082599103450775

Epoch: 6| Step: 8
Training loss: 2.4398205280303955
Validation loss: 2.073065201441447

Epoch: 6| Step: 9
Training loss: 1.4049243927001953
Validation loss: 2.0701725284258523

Epoch: 6| Step: 10
Training loss: 1.740792989730835
Validation loss: 2.062136391798655

Epoch: 6| Step: 11
Training loss: 2.146425247192383
Validation loss: 2.0560196240743003

Epoch: 6| Step: 12
Training loss: 1.8387742042541504
Validation loss: 2.054879367351532

Epoch: 6| Step: 13
Training loss: 1.9205436706542969
Validation loss: 2.048389256000519

Epoch: 160| Step: 0
Training loss: 1.817718744277954
Validation loss: 2.0648831923802695

Epoch: 6| Step: 1
Training loss: 2.154812812805176
Validation loss: 2.0455044905344644

Epoch: 6| Step: 2
Training loss: 1.9035263061523438
Validation loss: 2.0436319708824158

Epoch: 6| Step: 3
Training loss: 1.6018617153167725
Validation loss: 2.05739027261734

Epoch: 6| Step: 4
Training loss: 2.5295357704162598
Validation loss: 2.0526639024416604

Epoch: 6| Step: 5
Training loss: 2.0206398963928223
Validation loss: 2.048068642616272

Epoch: 6| Step: 6
Training loss: 2.1083500385284424
Validation loss: 2.0491636395454407

Epoch: 6| Step: 7
Training loss: 2.166940927505493
Validation loss: 2.054429372151693

Epoch: 6| Step: 8
Training loss: 2.52081561088562
Validation loss: 2.0681716402371726

Epoch: 6| Step: 9
Training loss: 2.6128807067871094
Validation loss: 2.0542523860931396

Epoch: 6| Step: 10
Training loss: 1.2328753471374512
Validation loss: 2.0739925305048623

Epoch: 6| Step: 11
Training loss: 1.6589734554290771
Validation loss: 2.06591268380483

Epoch: 6| Step: 12
Training loss: 1.7757325172424316
Validation loss: 2.0744640827178955

Epoch: 6| Step: 13
Training loss: 1.7625705003738403
Validation loss: 2.07676633199056

Epoch: 161| Step: 0
Training loss: 1.8874374628067017
Validation loss: 2.0879427393277488

Epoch: 6| Step: 1
Training loss: 2.1334168910980225
Validation loss: 2.0746411283810935

Epoch: 6| Step: 2
Training loss: 1.9026310443878174
Validation loss: 2.089257021745046

Epoch: 6| Step: 3
Training loss: 2.27200984954834
Validation loss: 2.07644913593928

Epoch: 6| Step: 4
Training loss: 1.6451361179351807
Validation loss: 2.0818660855293274

Epoch: 6| Step: 5
Training loss: 1.7967052459716797
Validation loss: 2.078305502732595

Epoch: 6| Step: 6
Training loss: 1.6373612880706787
Validation loss: 2.0669321020444236

Epoch: 6| Step: 7
Training loss: 2.0186824798583984
Validation loss: 2.076940357685089

Epoch: 6| Step: 8
Training loss: 2.765885353088379
Validation loss: 2.080096344153086

Epoch: 6| Step: 9
Training loss: 1.878535509109497
Validation loss: 2.0623198747634888

Epoch: 6| Step: 10
Training loss: 1.945368766784668
Validation loss: 2.0667863488197327

Epoch: 6| Step: 11
Training loss: 2.631814956665039
Validation loss: 2.06129523118337

Epoch: 6| Step: 12
Training loss: 1.691114068031311
Validation loss: 2.0601588686307273

Epoch: 6| Step: 13
Training loss: 1.60071861743927
Validation loss: 2.0634897351264954

Epoch: 162| Step: 0
Training loss: 1.942291259765625
Validation loss: 2.071780264377594

Epoch: 6| Step: 1
Training loss: 2.2049458026885986
Validation loss: 2.073814352353414

Epoch: 6| Step: 2
Training loss: 1.9219756126403809
Validation loss: 2.0815258026123047

Epoch: 6| Step: 3
Training loss: 1.9309337139129639
Validation loss: 2.0863961577415466

Epoch: 6| Step: 4
Training loss: 2.3048176765441895
Validation loss: 2.080875833829244

Epoch: 6| Step: 5
Training loss: 2.113783836364746
Validation loss: 2.0872511068979898

Epoch: 6| Step: 6
Training loss: 1.9322744607925415
Validation loss: 2.0988423029581704

Epoch: 6| Step: 7
Training loss: 1.0687980651855469
Validation loss: 2.0893863240877786

Epoch: 6| Step: 8
Training loss: 2.3482718467712402
Validation loss: 2.101364572842916

Epoch: 6| Step: 9
Training loss: 1.5430667400360107
Validation loss: 2.0848384300867715

Epoch: 6| Step: 10
Training loss: 2.1623167991638184
Validation loss: 2.094726244608561

Epoch: 6| Step: 11
Training loss: 2.110104560852051
Validation loss: 2.08419132232666

Epoch: 6| Step: 12
Training loss: 2.1321725845336914
Validation loss: 2.083466629187266

Epoch: 6| Step: 13
Training loss: 1.9382950067520142
Validation loss: 2.0778276721636453

Epoch: 163| Step: 0
Training loss: 1.7343478202819824
Validation loss: 2.0603679021199546

Epoch: 6| Step: 1
Training loss: 1.491682529449463
Validation loss: 2.062514384587606

Epoch: 6| Step: 2
Training loss: 1.7411131858825684
Validation loss: 2.058789908885956

Epoch: 6| Step: 3
Training loss: 2.5488386154174805
Validation loss: 2.0784875551859536

Epoch: 6| Step: 4
Training loss: 1.6053801774978638
Validation loss: 2.067007839679718

Epoch: 6| Step: 5
Training loss: 2.2115917205810547
Validation loss: 2.093195597330729

Epoch: 6| Step: 6
Training loss: 1.8338563442230225
Validation loss: 2.107618272304535

Epoch: 6| Step: 7
Training loss: 2.6117615699768066
Validation loss: 2.1071629524230957

Epoch: 6| Step: 8
Training loss: 1.6407148838043213
Validation loss: 2.1378478606541953

Epoch: 6| Step: 9
Training loss: 2.0331528186798096
Validation loss: 2.1235630909601846

Epoch: 6| Step: 10
Training loss: 2.484651565551758
Validation loss: 2.126035451889038

Epoch: 6| Step: 11
Training loss: 2.4989686012268066
Validation loss: 2.117015540599823

Epoch: 6| Step: 12
Training loss: 1.6942882537841797
Validation loss: 2.108400205771128

Epoch: 6| Step: 13
Training loss: 2.572275161743164
Validation loss: 2.0901082158088684

Epoch: 164| Step: 0
Training loss: 1.9913172721862793
Validation loss: 2.072077214717865

Epoch: 6| Step: 1
Training loss: 1.49740469455719
Validation loss: 2.0648593306541443

Epoch: 6| Step: 2
Training loss: 2.715331554412842
Validation loss: 2.0577856302261353

Epoch: 6| Step: 3
Training loss: 1.7514212131500244
Validation loss: 2.060909708340963

Epoch: 6| Step: 4
Training loss: 1.6635894775390625
Validation loss: 2.0656190117200217

Epoch: 6| Step: 5
Training loss: 1.9175187349319458
Validation loss: 2.067882796128591

Epoch: 6| Step: 6
Training loss: 2.0145199298858643
Validation loss: 2.060808261235555

Epoch: 6| Step: 7
Training loss: 2.111109733581543
Validation loss: 2.0857929587364197

Epoch: 6| Step: 8
Training loss: 2.251267671585083
Validation loss: 2.0870513717333474

Epoch: 6| Step: 9
Training loss: 1.9869321584701538
Validation loss: 2.0838087995847068

Epoch: 6| Step: 10
Training loss: 2.388974189758301
Validation loss: 2.0893497268358865

Epoch: 6| Step: 11
Training loss: 2.555081605911255
Validation loss: 2.102453589439392

Epoch: 6| Step: 12
Training loss: 1.8325170278549194
Validation loss: 2.1010249654452005

Epoch: 6| Step: 13
Training loss: 1.4227709770202637
Validation loss: 2.1029260754585266

Epoch: 165| Step: 0
Training loss: 1.6855406761169434
Validation loss: 2.0888599952061973

Epoch: 6| Step: 1
Training loss: 1.4868428707122803
Validation loss: 2.083893636862437

Epoch: 6| Step: 2
Training loss: 2.0631043910980225
Validation loss: 2.07038684686025

Epoch: 6| Step: 3
Training loss: 2.1873257160186768
Validation loss: 2.079231063524882

Epoch: 6| Step: 4
Training loss: 3.026426315307617
Validation loss: 2.0697876612345376

Epoch: 6| Step: 5
Training loss: 2.144092082977295
Validation loss: 2.0678845643997192

Epoch: 6| Step: 6
Training loss: 1.7800393104553223
Validation loss: 2.0685869057973227

Epoch: 6| Step: 7
Training loss: 1.713600516319275
Validation loss: 2.072558124860128

Epoch: 6| Step: 8
Training loss: 2.4285664558410645
Validation loss: 2.066765030225118

Epoch: 6| Step: 9
Training loss: 1.3706905841827393
Validation loss: 2.069488008817037

Epoch: 6| Step: 10
Training loss: 1.9433059692382812
Validation loss: 2.072253425916036

Epoch: 6| Step: 11
Training loss: 1.6391242742538452
Validation loss: 2.0844994386037192

Epoch: 6| Step: 12
Training loss: 2.0747251510620117
Validation loss: 2.1002203027407327

Epoch: 6| Step: 13
Training loss: 2.33866548538208
Validation loss: 2.0846760471661887

Epoch: 166| Step: 0
Training loss: 1.3903898000717163
Validation loss: 2.101557950178782

Epoch: 6| Step: 1
Training loss: 1.9953076839447021
Validation loss: 2.1006632645924888

Epoch: 6| Step: 2
Training loss: 1.8484694957733154
Validation loss: 2.081298589706421

Epoch: 6| Step: 3
Training loss: 1.9864717721939087
Validation loss: 2.076588730017344

Epoch: 6| Step: 4
Training loss: 2.1069464683532715
Validation loss: 2.0952988664309182

Epoch: 6| Step: 5
Training loss: 2.5119426250457764
Validation loss: 2.0824117064476013

Epoch: 6| Step: 6
Training loss: 1.3978660106658936
Validation loss: 2.0911670525868735

Epoch: 6| Step: 7
Training loss: 2.330979347229004
Validation loss: 2.084547539552053

Epoch: 6| Step: 8
Training loss: 2.1466124057769775
Validation loss: 2.0751266876856485

Epoch: 6| Step: 9
Training loss: 1.904414176940918
Validation loss: 2.070639948050181

Epoch: 6| Step: 10
Training loss: 2.0627753734588623
Validation loss: 2.070117970307668

Epoch: 6| Step: 11
Training loss: 1.6573734283447266
Validation loss: 2.082458972930908

Epoch: 6| Step: 12
Training loss: 2.5293374061584473
Validation loss: 2.0733476678530374

Epoch: 6| Step: 13
Training loss: 1.7754263877868652
Validation loss: 2.065393586953481

Epoch: 167| Step: 0
Training loss: 1.6035056114196777
Validation loss: 2.0680229663848877

Epoch: 6| Step: 1
Training loss: 1.9769039154052734
Validation loss: 2.0648120641708374

Epoch: 6| Step: 2
Training loss: 2.2170984745025635
Validation loss: 2.07230414946874

Epoch: 6| Step: 3
Training loss: 2.055366277694702
Validation loss: 2.0766078432401023

Epoch: 6| Step: 4
Training loss: 1.3862056732177734
Validation loss: 2.081514577070872

Epoch: 6| Step: 5
Training loss: 2.2083628177642822
Validation loss: 2.0921936631202698

Epoch: 6| Step: 6
Training loss: 2.5470023155212402
Validation loss: 2.0826141834259033

Epoch: 6| Step: 7
Training loss: 2.025505542755127
Validation loss: 2.0844993591308594

Epoch: 6| Step: 8
Training loss: 1.4944043159484863
Validation loss: 2.082029143969218

Epoch: 6| Step: 9
Training loss: 2.0647687911987305
Validation loss: 2.063455502192179

Epoch: 6| Step: 10
Training loss: 2.054576873779297
Validation loss: 2.086561640103658

Epoch: 6| Step: 11
Training loss: 2.0170369148254395
Validation loss: 2.0807119011878967

Epoch: 6| Step: 12
Training loss: 2.241720676422119
Validation loss: 2.0816085934638977

Epoch: 6| Step: 13
Training loss: 1.7449233531951904
Validation loss: 2.0811787843704224

Epoch: 168| Step: 0
Training loss: 2.2791829109191895
Validation loss: 2.087645431359609

Epoch: 6| Step: 1
Training loss: 1.910169243812561
Validation loss: 2.0940130750338235

Epoch: 6| Step: 2
Training loss: 2.007565498352051
Validation loss: 2.088616689046224

Epoch: 6| Step: 3
Training loss: 1.537824034690857
Validation loss: 2.081931988398234

Epoch: 6| Step: 4
Training loss: 2.0798277854919434
Validation loss: 2.0850128332773843

Epoch: 6| Step: 5
Training loss: 1.7291326522827148
Validation loss: 2.093385616938273

Epoch: 6| Step: 6
Training loss: 1.706158995628357
Validation loss: 2.081386168797811

Epoch: 6| Step: 7
Training loss: 2.257671356201172
Validation loss: 2.0893335143725076

Epoch: 6| Step: 8
Training loss: 2.1319260597229004
Validation loss: 2.0979302326838174

Epoch: 6| Step: 9
Training loss: 2.0879859924316406
Validation loss: 2.083453635374705

Epoch: 6| Step: 10
Training loss: 2.0061914920806885
Validation loss: 2.09568460782369

Epoch: 6| Step: 11
Training loss: 1.5810391902923584
Validation loss: 2.0980889598528543

Epoch: 6| Step: 12
Training loss: 1.5055227279663086
Validation loss: 2.086959481239319

Epoch: 6| Step: 13
Training loss: 2.3898143768310547
Validation loss: 2.094942092895508

Epoch: 169| Step: 0
Training loss: 1.3528008460998535
Validation loss: 2.0886081059773765

Epoch: 6| Step: 1
Training loss: 2.6038999557495117
Validation loss: 2.0991799434026084

Epoch: 6| Step: 2
Training loss: 1.9097681045532227
Validation loss: 2.0930089751879373

Epoch: 6| Step: 3
Training loss: 1.2642041444778442
Validation loss: 2.101187745730082

Epoch: 6| Step: 4
Training loss: 1.8969457149505615
Validation loss: 2.1024550398190818

Epoch: 6| Step: 5
Training loss: 1.8045016527175903
Validation loss: 2.104262888431549

Epoch: 6| Step: 6
Training loss: 1.5129826068878174
Validation loss: 2.1005553801854453

Epoch: 6| Step: 7
Training loss: 2.508700370788574
Validation loss: 2.0943930546442666

Epoch: 6| Step: 8
Training loss: 1.9388879537582397
Validation loss: 2.0927348136901855

Epoch: 6| Step: 9
Training loss: 1.6138168573379517
Validation loss: 2.083901663621267

Epoch: 6| Step: 10
Training loss: 2.207573413848877
Validation loss: 2.0955790281295776

Epoch: 6| Step: 11
Training loss: 2.0689327716827393
Validation loss: 2.089466671148936

Epoch: 6| Step: 12
Training loss: 2.4367330074310303
Validation loss: 2.0760692954063416

Epoch: 6| Step: 13
Training loss: 2.281010627746582
Validation loss: 2.0688257416089377

Epoch: 170| Step: 0
Training loss: 1.8430776596069336
Validation loss: 2.0747147599856057

Epoch: 6| Step: 1
Training loss: 2.2506957054138184
Validation loss: 2.083726723988851

Epoch: 6| Step: 2
Training loss: 2.57905912399292
Validation loss: 2.0708306431770325

Epoch: 6| Step: 3
Training loss: 2.033156156539917
Validation loss: 2.0908655722935996

Epoch: 6| Step: 4
Training loss: 1.980387806892395
Validation loss: 2.096076269944509

Epoch: 6| Step: 5
Training loss: 1.4271488189697266
Validation loss: 2.09734437863032

Epoch: 6| Step: 6
Training loss: 2.6016011238098145
Validation loss: 2.0964742302894592

Epoch: 6| Step: 7
Training loss: 1.4215688705444336
Validation loss: 2.1011576652526855

Epoch: 6| Step: 8
Training loss: 1.2768056392669678
Validation loss: 2.0961406429608664

Epoch: 6| Step: 9
Training loss: 1.8122972249984741
Validation loss: 2.104028662045797

Epoch: 6| Step: 10
Training loss: 2.075486660003662
Validation loss: 2.1160602370897927

Epoch: 6| Step: 11
Training loss: 1.885482907295227
Validation loss: 2.1124563415845237

Epoch: 6| Step: 12
Training loss: 2.36592435836792
Validation loss: 2.1121946573257446

Epoch: 6| Step: 13
Training loss: 1.8250154256820679
Validation loss: 2.1250508030255637

Epoch: 171| Step: 0
Training loss: 2.0127902030944824
Validation loss: 2.112383782863617

Epoch: 6| Step: 1
Training loss: 2.1838784217834473
Validation loss: 2.124632477760315

Epoch: 6| Step: 2
Training loss: 2.3199572563171387
Validation loss: 2.1223132411638894

Epoch: 6| Step: 3
Training loss: 1.566488265991211
Validation loss: 2.1142953634262085

Epoch: 6| Step: 4
Training loss: 1.8836485147476196
Validation loss: 2.1091295878092446

Epoch: 6| Step: 5
Training loss: 1.7122721672058105
Validation loss: 2.1077051162719727

Epoch: 6| Step: 6
Training loss: 1.6122865676879883
Validation loss: 2.090220272541046

Epoch: 6| Step: 7
Training loss: 1.6772230863571167
Validation loss: 2.0950335462888083

Epoch: 6| Step: 8
Training loss: 2.1559770107269287
Validation loss: 2.077838102976481

Epoch: 6| Step: 9
Training loss: 2.120925188064575
Validation loss: 2.0935295820236206

Epoch: 6| Step: 10
Training loss: 1.5953810214996338
Validation loss: 2.09112940231959

Epoch: 6| Step: 11
Training loss: 2.3160438537597656
Validation loss: 2.087708373864492

Epoch: 6| Step: 12
Training loss: 1.7262948751449585
Validation loss: 2.0953981081644693

Epoch: 6| Step: 13
Training loss: 2.2469282150268555
Validation loss: 2.096589426199595

Epoch: 172| Step: 0
Training loss: 2.165205478668213
Validation loss: 2.0880784591039023

Epoch: 6| Step: 1
Training loss: 2.3968591690063477
Validation loss: 2.0795006354649863

Epoch: 6| Step: 2
Training loss: 2.366061210632324
Validation loss: 2.0670201579729715

Epoch: 6| Step: 3
Training loss: 1.9949641227722168
Validation loss: 2.0678770542144775

Epoch: 6| Step: 4
Training loss: 1.9616732597351074
Validation loss: 2.075077474117279

Epoch: 6| Step: 5
Training loss: 1.7369263172149658
Validation loss: 2.0876899361610413

Epoch: 6| Step: 6
Training loss: 1.8111276626586914
Validation loss: 2.096410552660624

Epoch: 6| Step: 7
Training loss: 1.8567324876785278
Validation loss: 2.0985675056775412

Epoch: 6| Step: 8
Training loss: 1.9550561904907227
Validation loss: 2.1043824553489685

Epoch: 6| Step: 9
Training loss: 1.9921013116836548
Validation loss: 2.1050455371538797

Epoch: 6| Step: 10
Training loss: 1.7758114337921143
Validation loss: 2.0961820681889853

Epoch: 6| Step: 11
Training loss: 1.302626609802246
Validation loss: 2.098653038342794

Epoch: 6| Step: 12
Training loss: 2.2181389331817627
Validation loss: 2.0931716362635293

Epoch: 6| Step: 13
Training loss: 2.0238146781921387
Validation loss: 2.086945136388143

Epoch: 173| Step: 0
Training loss: 1.3969241380691528
Validation loss: 2.0778762896855674

Epoch: 6| Step: 1
Training loss: 1.7921643257141113
Validation loss: 2.0741565426190696

Epoch: 6| Step: 2
Training loss: 1.595348596572876
Validation loss: 2.0727963050206504

Epoch: 6| Step: 3
Training loss: 1.7403559684753418
Validation loss: 2.078600804011027

Epoch: 6| Step: 4
Training loss: 1.9288452863693237
Validation loss: 2.0737588008244834

Epoch: 6| Step: 5
Training loss: 2.060619831085205
Validation loss: 2.0853248039881387

Epoch: 6| Step: 6
Training loss: 2.2331199645996094
Validation loss: 2.07801353931427

Epoch: 6| Step: 7
Training loss: 2.0466222763061523
Validation loss: 2.088758647441864

Epoch: 6| Step: 8
Training loss: 2.882392406463623
Validation loss: 2.08876899878184

Epoch: 6| Step: 9
Training loss: 1.9349219799041748
Validation loss: 2.094916582107544

Epoch: 6| Step: 10
Training loss: 2.227184295654297
Validation loss: 2.0935657819112143

Epoch: 6| Step: 11
Training loss: 2.321835994720459
Validation loss: 2.0910774072011313

Epoch: 6| Step: 12
Training loss: 1.495577335357666
Validation loss: 2.0909687280654907

Epoch: 6| Step: 13
Training loss: 2.1997721195220947
Validation loss: 2.0954355200131736

Epoch: 174| Step: 0
Training loss: 1.5195345878601074
Validation loss: 2.0958268443743386

Epoch: 6| Step: 1
Training loss: 1.5119576454162598
Validation loss: 2.0961398482322693

Epoch: 6| Step: 2
Training loss: 2.028785467147827
Validation loss: 2.0788551966349282

Epoch: 6| Step: 3
Training loss: 2.2416462898254395
Validation loss: 2.0781147678693137

Epoch: 6| Step: 4
Training loss: 1.806599497795105
Validation loss: 2.066756467024485

Epoch: 6| Step: 5
Training loss: 2.0326180458068848
Validation loss: 2.068158507347107

Epoch: 6| Step: 6
Training loss: 2.124112606048584
Validation loss: 2.078409274419149

Epoch: 6| Step: 7
Training loss: 1.9359279870986938
Validation loss: 2.062948207060496

Epoch: 6| Step: 8
Training loss: 2.5400896072387695
Validation loss: 2.061265210310618

Epoch: 6| Step: 9
Training loss: 0.8404699563980103
Validation loss: 2.06070609887441

Epoch: 6| Step: 10
Training loss: 1.9296551942825317
Validation loss: 2.0767616828282676

Epoch: 6| Step: 11
Training loss: 1.9824936389923096
Validation loss: 2.0863540967305503

Epoch: 6| Step: 12
Training loss: 2.4414873123168945
Validation loss: 2.1017345984776816

Epoch: 6| Step: 13
Training loss: 2.5542678833007812
Validation loss: 2.11344975233078

Epoch: 175| Step: 0
Training loss: 1.9250800609588623
Validation loss: 2.1013556718826294

Epoch: 6| Step: 1
Training loss: 2.006895065307617
Validation loss: 2.119201103846232

Epoch: 6| Step: 2
Training loss: 2.3904922008514404
Validation loss: 2.104203979174296

Epoch: 6| Step: 3
Training loss: 2.2879724502563477
Validation loss: 2.094697952270508

Epoch: 6| Step: 4
Training loss: 2.0499343872070312
Validation loss: 2.0815828839937844

Epoch: 6| Step: 5
Training loss: 1.7132346630096436
Validation loss: 2.0724467237790427

Epoch: 6| Step: 6
Training loss: 2.6752102375030518
Validation loss: 2.077208479245504

Epoch: 6| Step: 7
Training loss: 1.999171257019043
Validation loss: 2.064483424027761

Epoch: 6| Step: 8
Training loss: 1.4929255247116089
Validation loss: 2.068223516146342

Epoch: 6| Step: 9
Training loss: 1.9570388793945312
Validation loss: 2.0688548485438027

Epoch: 6| Step: 10
Training loss: 1.4047921895980835
Validation loss: 2.0764809052149453

Epoch: 6| Step: 11
Training loss: 1.7950236797332764
Validation loss: 2.0783721804618835

Epoch: 6| Step: 12
Training loss: 2.0587069988250732
Validation loss: 2.0754305720329285

Epoch: 6| Step: 13
Training loss: 2.2835464477539062
Validation loss: 2.0903210639953613

Epoch: 176| Step: 0
Training loss: 1.7784570455551147
Validation loss: 2.1114313999811807

Epoch: 6| Step: 1
Training loss: 1.7912099361419678
Validation loss: 2.1037434935569763

Epoch: 6| Step: 2
Training loss: 2.115226984024048
Validation loss: 2.1054192781448364

Epoch: 6| Step: 3
Training loss: 2.0087175369262695
Validation loss: 2.13109815120697

Epoch: 6| Step: 4
Training loss: 2.28983211517334
Validation loss: 2.12188986937205

Epoch: 6| Step: 5
Training loss: 1.828292727470398
Validation loss: 2.0995429952939353

Epoch: 6| Step: 6
Training loss: 1.9883298873901367
Validation loss: 2.1030234495798745

Epoch: 6| Step: 7
Training loss: 2.3383498191833496
Validation loss: 2.0933773120244346

Epoch: 6| Step: 8
Training loss: 2.1786932945251465
Validation loss: 2.0840736031532288

Epoch: 6| Step: 9
Training loss: 1.6306307315826416
Validation loss: 2.089030305544535

Epoch: 6| Step: 10
Training loss: 2.2119364738464355
Validation loss: 2.081667721271515

Epoch: 6| Step: 11
Training loss: 1.4645872116088867
Validation loss: 2.0731878876686096

Epoch: 6| Step: 12
Training loss: 1.872104287147522
Validation loss: 2.0837151408195496

Epoch: 6| Step: 13
Training loss: 1.9452269077301025
Validation loss: 2.083507498105367

Epoch: 177| Step: 0
Training loss: 1.2546281814575195
Validation loss: 2.086302876472473

Epoch: 6| Step: 1
Training loss: 2.2072956562042236
Validation loss: 2.0949924985567727

Epoch: 6| Step: 2
Training loss: 2.0584208965301514
Validation loss: 2.0821241537729898

Epoch: 6| Step: 3
Training loss: 1.3627545833587646
Validation loss: 2.072670300801595

Epoch: 6| Step: 4
Training loss: 2.1519718170166016
Validation loss: 2.077812929948171

Epoch: 6| Step: 5
Training loss: 1.8341294527053833
Validation loss: 2.0924295783042908

Epoch: 6| Step: 6
Training loss: 2.371680498123169
Validation loss: 2.09048859278361

Epoch: 6| Step: 7
Training loss: 1.7253222465515137
Validation loss: 2.0907346407572427

Epoch: 6| Step: 8
Training loss: 2.019028663635254
Validation loss: 2.098362386226654

Epoch: 6| Step: 9
Training loss: 1.7571091651916504
Validation loss: 2.0947117606798806

Epoch: 6| Step: 10
Training loss: 1.5847748517990112
Validation loss: 2.0879249970118203

Epoch: 6| Step: 11
Training loss: 1.8419617414474487
Validation loss: 2.1063592433929443

Epoch: 6| Step: 12
Training loss: 2.4805264472961426
Validation loss: 2.091821551322937

Epoch: 6| Step: 13
Training loss: 2.3224339485168457
Validation loss: 2.114831248919169

Epoch: 178| Step: 0
Training loss: 1.9106011390686035
Validation loss: 2.131438056627909

Epoch: 6| Step: 1
Training loss: 2.1980092525482178
Validation loss: 2.123855988184611

Epoch: 6| Step: 2
Training loss: 1.4874281883239746
Validation loss: 2.147312343120575

Epoch: 6| Step: 3
Training loss: 2.1949658393859863
Validation loss: 2.127201497554779

Epoch: 6| Step: 4
Training loss: 2.498778820037842
Validation loss: 2.0851529439290366

Epoch: 6| Step: 5
Training loss: 1.5648319721221924
Validation loss: 2.078050911426544

Epoch: 6| Step: 6
Training loss: 2.2558484077453613
Validation loss: 2.0870772997538247

Epoch: 6| Step: 7
Training loss: 1.9628942012786865
Validation loss: 2.082987070083618

Epoch: 6| Step: 8
Training loss: 1.866789698600769
Validation loss: 2.0689657330513

Epoch: 6| Step: 9
Training loss: 2.1239616870880127
Validation loss: 2.063512841860453

Epoch: 6| Step: 10
Training loss: 1.6110925674438477
Validation loss: 2.0558539827664695

Epoch: 6| Step: 11
Training loss: 1.6378551721572876
Validation loss: 2.06544961531957

Epoch: 6| Step: 12
Training loss: 1.9777863025665283
Validation loss: 2.070319712162018

Epoch: 6| Step: 13
Training loss: 2.815868616104126
Validation loss: 2.0654021898905435

Epoch: 179| Step: 0
Training loss: 2.5478515625
Validation loss: 2.077922066052755

Epoch: 6| Step: 1
Training loss: 1.9032915830612183
Validation loss: 2.069011608759562

Epoch: 6| Step: 2
Training loss: 1.8499455451965332
Validation loss: 2.085319221019745

Epoch: 6| Step: 3
Training loss: 1.1024212837219238
Validation loss: 2.0699294805526733

Epoch: 6| Step: 4
Training loss: 1.4585471153259277
Validation loss: 2.0863688389460244

Epoch: 6| Step: 5
Training loss: 1.67539381980896
Validation loss: 2.095879932244619

Epoch: 6| Step: 6
Training loss: 2.256955862045288
Validation loss: 2.08488800128301

Epoch: 6| Step: 7
Training loss: 1.9977916479110718
Validation loss: 2.109445333480835

Epoch: 6| Step: 8
Training loss: 2.422724485397339
Validation loss: 2.120989422003428

Epoch: 6| Step: 9
Training loss: 1.9867713451385498
Validation loss: 2.1134976943333945

Epoch: 6| Step: 10
Training loss: 2.1855974197387695
Validation loss: 2.1008900801340737

Epoch: 6| Step: 11
Training loss: 1.8918533325195312
Validation loss: 2.113215208053589

Epoch: 6| Step: 12
Training loss: 2.387531280517578
Validation loss: 2.1290460228919983

Epoch: 6| Step: 13
Training loss: 1.7050124406814575
Validation loss: 2.1145530939102173

Epoch: 180| Step: 0
Training loss: 1.074175238609314
Validation loss: 2.09913569688797

Epoch: 6| Step: 1
Training loss: 1.6683084964752197
Validation loss: 2.0870185097058616

Epoch: 6| Step: 2
Training loss: 1.9627350568771362
Validation loss: 2.0791693528493247

Epoch: 6| Step: 3
Training loss: 2.626375436782837
Validation loss: 2.0743791858355203

Epoch: 6| Step: 4
Training loss: 2.372465133666992
Validation loss: 2.0706541339556375

Epoch: 6| Step: 5
Training loss: 2.7489445209503174
Validation loss: 2.0786437392234802

Epoch: 6| Step: 6
Training loss: 2.009873151779175
Validation loss: 2.0936896006266275

Epoch: 6| Step: 7
Training loss: 2.7727270126342773
Validation loss: 2.0842844247817993

Epoch: 6| Step: 8
Training loss: 2.565429210662842
Validation loss: 2.099522292613983

Epoch: 6| Step: 9
Training loss: 1.5097657442092896
Validation loss: 2.088381270567576

Epoch: 6| Step: 10
Training loss: 2.193821430206299
Validation loss: 2.093896448612213

Epoch: 6| Step: 11
Training loss: 1.953453540802002
Validation loss: 2.0754816929499307

Epoch: 6| Step: 12
Training loss: 1.664402961730957
Validation loss: 2.0752474665641785

Epoch: 6| Step: 13
Training loss: 1.8505585193634033
Validation loss: 2.060706615447998

Epoch: 181| Step: 0
Training loss: 1.8918201923370361
Validation loss: 2.071046551068624

Epoch: 6| Step: 1
Training loss: 2.2311062812805176
Validation loss: 2.0601513783137

Epoch: 6| Step: 2
Training loss: 1.9554842710494995
Validation loss: 2.076459228992462

Epoch: 6| Step: 3
Training loss: 2.0980701446533203
Validation loss: 2.0729918479919434

Epoch: 6| Step: 4
Training loss: 2.290156602859497
Validation loss: 2.0864562590916953

Epoch: 6| Step: 5
Training loss: 1.8391618728637695
Validation loss: 2.0741005142529807

Epoch: 6| Step: 6
Training loss: 1.9049153327941895
Validation loss: 2.082996924718221

Epoch: 6| Step: 7
Training loss: 1.9332863092422485
Validation loss: 2.1069496472676597

Epoch: 6| Step: 8
Training loss: 1.3317619562149048
Validation loss: 2.094210684299469

Epoch: 6| Step: 9
Training loss: 2.2088119983673096
Validation loss: 2.088490307331085

Epoch: 6| Step: 10
Training loss: 2.3533999919891357
Validation loss: 2.0848099191983542

Epoch: 6| Step: 11
Training loss: 1.3160040378570557
Validation loss: 2.0933003425598145

Epoch: 6| Step: 12
Training loss: 2.3789687156677246
Validation loss: 2.0908905466397605

Epoch: 6| Step: 13
Training loss: 2.010366678237915
Validation loss: 2.0906052390734353

Epoch: 182| Step: 0
Training loss: 2.226073980331421
Validation loss: 2.0895845095316568

Epoch: 6| Step: 1
Training loss: 1.7375764846801758
Validation loss: 2.1144076784451804

Epoch: 6| Step: 2
Training loss: 1.3491239547729492
Validation loss: 2.1209385991096497

Epoch: 6| Step: 3
Training loss: 2.289602041244507
Validation loss: 2.1223009824752808

Epoch: 6| Step: 4
Training loss: 1.8487428426742554
Validation loss: 2.103260338306427

Epoch: 6| Step: 5
Training loss: 2.091479539871216
Validation loss: 2.100905179977417

Epoch: 6| Step: 6
Training loss: 1.8962801694869995
Validation loss: 2.095198412736257

Epoch: 6| Step: 7
Training loss: 1.5057659149169922
Validation loss: 2.0898585120836892

Epoch: 6| Step: 8
Training loss: 1.4392344951629639
Validation loss: 2.0925308068593345

Epoch: 6| Step: 9
Training loss: 2.2075743675231934
Validation loss: 2.0989561875661216

Epoch: 6| Step: 10
Training loss: 1.7761484384536743
Validation loss: 2.0879374742507935

Epoch: 6| Step: 11
Training loss: 2.316709041595459
Validation loss: 2.077099025249481

Epoch: 6| Step: 12
Training loss: 2.1819159984588623
Validation loss: 2.0863983631134033

Epoch: 6| Step: 13
Training loss: 2.1231489181518555
Validation loss: 2.070527990659078

Epoch: 183| Step: 0
Training loss: 2.382355213165283
Validation loss: 2.0844101905822754

Epoch: 6| Step: 1
Training loss: 2.1666667461395264
Validation loss: 2.088341693083445

Epoch: 6| Step: 2
Training loss: 1.5895600318908691
Validation loss: 2.0833569765090942

Epoch: 6| Step: 3
Training loss: 1.3783512115478516
Validation loss: 2.100322345892588

Epoch: 6| Step: 4
Training loss: 1.951644778251648
Validation loss: 2.10495134194692

Epoch: 6| Step: 5
Training loss: 1.7280253171920776
Validation loss: 2.0927610397338867

Epoch: 6| Step: 6
Training loss: 2.1554787158966064
Validation loss: 2.105241596698761

Epoch: 6| Step: 7
Training loss: 2.354804515838623
Validation loss: 2.1027511755625405

Epoch: 6| Step: 8
Training loss: 2.089846611022949
Validation loss: 2.1079219977060952

Epoch: 6| Step: 9
Training loss: 2.066655158996582
Validation loss: 2.0935343503952026

Epoch: 6| Step: 10
Training loss: 1.685274362564087
Validation loss: 2.105215569337209

Epoch: 6| Step: 11
Training loss: 2.0182647705078125
Validation loss: 2.094550828138987

Epoch: 6| Step: 12
Training loss: 1.6787207126617432
Validation loss: 2.0833011070887246

Epoch: 6| Step: 13
Training loss: 2.204493522644043
Validation loss: 2.079541285832723

Epoch: 184| Step: 0
Training loss: 1.9634462594985962
Validation loss: 2.083528200785319

Epoch: 6| Step: 1
Training loss: 1.9461555480957031
Validation loss: 2.0806526144345603

Epoch: 6| Step: 2
Training loss: 1.9997323751449585
Validation loss: 2.0855557521184287

Epoch: 6| Step: 3
Training loss: 1.5112411975860596
Validation loss: 2.080882430076599

Epoch: 6| Step: 4
Training loss: 2.190579891204834
Validation loss: 2.101361632347107

Epoch: 6| Step: 5
Training loss: 2.737562656402588
Validation loss: 2.095572769641876

Epoch: 6| Step: 6
Training loss: 1.7547353506088257
Validation loss: 2.105052371819814

Epoch: 6| Step: 7
Training loss: 1.9815868139266968
Validation loss: 2.096866945425669

Epoch: 6| Step: 8
Training loss: 1.63084077835083
Validation loss: 2.1174901326497397

Epoch: 6| Step: 9
Training loss: 2.573981523513794
Validation loss: 2.1025135119756064

Epoch: 6| Step: 10
Training loss: 1.1949330568313599
Validation loss: 2.095532794793447

Epoch: 6| Step: 11
Training loss: 2.339962959289551
Validation loss: 2.0862080454826355

Epoch: 6| Step: 12
Training loss: 1.1431297063827515
Validation loss: 2.098960022131602

Epoch: 6| Step: 13
Training loss: 2.124319076538086
Validation loss: 2.085718055566152

Epoch: 185| Step: 0
Training loss: 2.095153570175171
Validation loss: 2.08154966433843

Epoch: 6| Step: 1
Training loss: 2.709679126739502
Validation loss: 2.086290796597799

Epoch: 6| Step: 2
Training loss: 2.3004491329193115
Validation loss: 2.091993828614553

Epoch: 6| Step: 3
Training loss: 1.6257308721542358
Validation loss: 2.087121526400248

Epoch: 6| Step: 4
Training loss: 1.415205955505371
Validation loss: 2.0867297053337097

Epoch: 6| Step: 5
Training loss: 2.0450186729431152
Validation loss: 2.0891464749972024

Epoch: 6| Step: 6
Training loss: 1.6923046112060547
Validation loss: 2.0821488300959268

Epoch: 6| Step: 7
Training loss: 2.605764389038086
Validation loss: 2.0960038701693215

Epoch: 6| Step: 8
Training loss: 1.7261101007461548
Validation loss: 2.08822363615036

Epoch: 6| Step: 9
Training loss: 1.8059250116348267
Validation loss: 2.1033454140027366

Epoch: 6| Step: 10
Training loss: 1.6764025688171387
Validation loss: 2.1059720118840537

Epoch: 6| Step: 11
Training loss: 1.813363790512085
Validation loss: 2.102638085683187

Epoch: 6| Step: 12
Training loss: 1.8218363523483276
Validation loss: 2.1216328740119934

Epoch: 6| Step: 13
Training loss: 1.7491194009780884
Validation loss: 2.116595904032389

Epoch: 186| Step: 0
Training loss: 2.679206371307373
Validation loss: 2.142600735028585

Epoch: 6| Step: 1
Training loss: 1.693145513534546
Validation loss: 2.125587443510691

Epoch: 6| Step: 2
Training loss: 1.5653597116470337
Validation loss: 2.1156949202219644

Epoch: 6| Step: 3
Training loss: 2.676605701446533
Validation loss: 2.1194613178571067

Epoch: 6| Step: 4
Training loss: 2.063699722290039
Validation loss: 2.1230969031651816

Epoch: 6| Step: 5
Training loss: 1.8597841262817383
Validation loss: 2.1058014233907065

Epoch: 6| Step: 6
Training loss: 1.317138671875
Validation loss: 2.1121585766474404

Epoch: 6| Step: 7
Training loss: 2.6353864669799805
Validation loss: 2.1076742808024087

Epoch: 6| Step: 8
Training loss: 1.8810235261917114
Validation loss: 2.1099732518196106

Epoch: 6| Step: 9
Training loss: 1.6347060203552246
Validation loss: 2.0897560119628906

Epoch: 6| Step: 10
Training loss: 2.0430068969726562
Validation loss: 2.1074352661768594

Epoch: 6| Step: 11
Training loss: 1.61824631690979
Validation loss: 2.105814496676127

Epoch: 6| Step: 12
Training loss: 1.988840103149414
Validation loss: 2.1113656560579934

Epoch: 6| Step: 13
Training loss: 1.2290501594543457
Validation loss: 2.105970044930776

Epoch: 187| Step: 0
Training loss: 2.524043560028076
Validation loss: 2.1116302808125815

Epoch: 6| Step: 1
Training loss: 2.021052837371826
Validation loss: 2.1229081749916077

Epoch: 6| Step: 2
Training loss: 1.1627157926559448
Validation loss: 2.106368601322174

Epoch: 6| Step: 3
Training loss: 1.897499442100525
Validation loss: 2.11163067817688

Epoch: 6| Step: 4
Training loss: 2.0682315826416016
Validation loss: 2.1260790824890137

Epoch: 6| Step: 5
Training loss: 2.1022956371307373
Validation loss: 2.1325607697168985

Epoch: 6| Step: 6
Training loss: 1.6990149021148682
Validation loss: 2.122239132722219

Epoch: 6| Step: 7
Training loss: 1.7813761234283447
Validation loss: 2.121016204357147

Epoch: 6| Step: 8
Training loss: 2.303119659423828
Validation loss: 2.100874364376068

Epoch: 6| Step: 9
Training loss: 2.319171905517578
Validation loss: 2.095021605491638

Epoch: 6| Step: 10
Training loss: 1.5643917322158813
Validation loss: 2.1033759911855063

Epoch: 6| Step: 11
Training loss: 1.8792362213134766
Validation loss: 2.1020482381184897

Epoch: 6| Step: 12
Training loss: 2.0536906719207764
Validation loss: 2.0889440178871155

Epoch: 6| Step: 13
Training loss: 1.7293444871902466
Validation loss: 2.0954415996869407

Epoch: 188| Step: 0
Training loss: 1.7801477909088135
Validation loss: 2.1058570742607117

Epoch: 6| Step: 1
Training loss: 2.1980247497558594
Validation loss: 2.08389949798584

Epoch: 6| Step: 2
Training loss: 1.688673973083496
Validation loss: 2.0928755402565002

Epoch: 6| Step: 3
Training loss: 1.7300746440887451
Validation loss: 2.0843289494514465

Epoch: 6| Step: 4
Training loss: 1.6870355606079102
Validation loss: 2.091823101043701

Epoch: 6| Step: 5
Training loss: 2.0602779388427734
Validation loss: 2.097972790400187

Epoch: 6| Step: 6
Training loss: 1.9620864391326904
Validation loss: 2.097093125184377

Epoch: 6| Step: 7
Training loss: 1.69215726852417
Validation loss: 2.130507250626882

Epoch: 6| Step: 8
Training loss: 2.557837724685669
Validation loss: 2.114366292953491

Epoch: 6| Step: 9
Training loss: 1.8060932159423828
Validation loss: 2.1129232247670493

Epoch: 6| Step: 10
Training loss: 2.0490641593933105
Validation loss: 2.1224268078804016

Epoch: 6| Step: 11
Training loss: 2.2036609649658203
Validation loss: 2.108855048815409

Epoch: 6| Step: 12
Training loss: 1.8699274063110352
Validation loss: 2.1193738182385764

Epoch: 6| Step: 13
Training loss: 1.8195068836212158
Validation loss: 2.119865914185842

Epoch: 189| Step: 0
Training loss: 2.002488136291504
Validation loss: 2.1169286370277405

Epoch: 6| Step: 1
Training loss: 1.6559250354766846
Validation loss: 2.106683631738027

Epoch: 6| Step: 2
Training loss: 1.8371894359588623
Validation loss: 2.112808585166931

Epoch: 6| Step: 3
Training loss: 1.6127521991729736
Validation loss: 2.114782472451528

Epoch: 6| Step: 4
Training loss: 1.2689235210418701
Validation loss: 2.1082667311032615

Epoch: 6| Step: 5
Training loss: 2.460732936859131
Validation loss: 2.1019270618756614

Epoch: 6| Step: 6
Training loss: 2.188331127166748
Validation loss: 2.1121893326441445

Epoch: 6| Step: 7
Training loss: 1.5370475053787231
Validation loss: 2.096104164918264

Epoch: 6| Step: 8
Training loss: 2.0446794033050537
Validation loss: 2.0910122195879617

Epoch: 6| Step: 9
Training loss: 2.264554977416992
Validation loss: 2.1057416200637817

Epoch: 6| Step: 10
Training loss: 1.5221797227859497
Validation loss: 2.112911264101664

Epoch: 6| Step: 11
Training loss: 1.9242390394210815
Validation loss: 2.116499960422516

Epoch: 6| Step: 12
Training loss: 1.9271377325057983
Validation loss: 2.1125623186429343

Epoch: 6| Step: 13
Training loss: 2.4034109115600586
Validation loss: 2.1192593574523926

Epoch: 190| Step: 0
Training loss: 2.4326331615448
Validation loss: 2.129185219605764

Epoch: 6| Step: 1
Training loss: 1.5626804828643799
Validation loss: 2.126187721888224

Epoch: 6| Step: 2
Training loss: 1.490365743637085
Validation loss: 2.1409468253453574

Epoch: 6| Step: 3
Training loss: 1.99551260471344
Validation loss: 2.1230772336324057

Epoch: 6| Step: 4
Training loss: 2.1746766567230225
Validation loss: 2.1051113605499268

Epoch: 6| Step: 5
Training loss: 1.6032612323760986
Validation loss: 2.109913686911265

Epoch: 6| Step: 6
Training loss: 2.010842800140381
Validation loss: 2.1097508470217385

Epoch: 6| Step: 7
Training loss: 1.9695637226104736
Validation loss: 2.1027113596598306

Epoch: 6| Step: 8
Training loss: 1.4856798648834229
Validation loss: 2.095751424630483

Epoch: 6| Step: 9
Training loss: 1.798466682434082
Validation loss: 2.095444142818451

Epoch: 6| Step: 10
Training loss: 1.864001750946045
Validation loss: 2.095050017038981

Epoch: 6| Step: 11
Training loss: 1.939530849456787
Validation loss: 2.0994465351104736

Epoch: 6| Step: 12
Training loss: 2.3064205646514893
Validation loss: 2.103098154067993

Epoch: 6| Step: 13
Training loss: 2.1432700157165527
Validation loss: 2.097550868988037

Epoch: 191| Step: 0
Training loss: 1.5693120956420898
Validation loss: 2.1079736749331155

Epoch: 6| Step: 1
Training loss: 1.539867877960205
Validation loss: 2.089626451333364

Epoch: 6| Step: 2
Training loss: 2.188142776489258
Validation loss: 2.0981735785802207

Epoch: 6| Step: 3
Training loss: 1.2225648164749146
Validation loss: 2.0910414656003318

Epoch: 6| Step: 4
Training loss: 1.5605134963989258
Validation loss: 2.0913957158724465

Epoch: 6| Step: 5
Training loss: 2.2985239028930664
Validation loss: 2.1093032161394754

Epoch: 6| Step: 6
Training loss: 1.4010424613952637
Validation loss: 2.109170913696289

Epoch: 6| Step: 7
Training loss: 2.00972843170166
Validation loss: 2.1044487357139587

Epoch: 6| Step: 8
Training loss: 2.148834705352783
Validation loss: 2.1309991081555686

Epoch: 6| Step: 9
Training loss: 1.9275332689285278
Validation loss: 2.1080374320348105

Epoch: 6| Step: 10
Training loss: 2.568514347076416
Validation loss: 2.111133853594462

Epoch: 6| Step: 11
Training loss: 1.6299506425857544
Validation loss: 2.108590543270111

Epoch: 6| Step: 12
Training loss: 1.9300131797790527
Validation loss: 2.1171756784121194

Epoch: 6| Step: 13
Training loss: 2.7259140014648438
Validation loss: 2.1021070877710977

Epoch: 192| Step: 0
Training loss: 1.939577579498291
Validation loss: 2.105851173400879

Epoch: 6| Step: 1
Training loss: 1.4552286863327026
Validation loss: 2.109477917353312

Epoch: 6| Step: 2
Training loss: 1.4662890434265137
Validation loss: 2.111335039138794

Epoch: 6| Step: 3
Training loss: 2.271566867828369
Validation loss: 2.1111862858136496

Epoch: 6| Step: 4
Training loss: 2.4167728424072266
Validation loss: 2.1040863196055093

Epoch: 6| Step: 5
Training loss: 2.131187677383423
Validation loss: 2.110078493754069

Epoch: 6| Step: 6
Training loss: 1.6233713626861572
Validation loss: 2.113577405611674

Epoch: 6| Step: 7
Training loss: 2.3236353397369385
Validation loss: 2.104439934094747

Epoch: 6| Step: 8
Training loss: 2.0231986045837402
Validation loss: 2.1086074113845825

Epoch: 6| Step: 9
Training loss: 2.1916933059692383
Validation loss: 2.103295604387919

Epoch: 6| Step: 10
Training loss: 1.6898951530456543
Validation loss: 2.11398055156072

Epoch: 6| Step: 11
Training loss: 1.4452180862426758
Validation loss: 2.11297740538915

Epoch: 6| Step: 12
Training loss: 1.5189573764801025
Validation loss: 2.108067492643992

Epoch: 6| Step: 13
Training loss: 2.12337064743042
Validation loss: 2.103972315788269

Epoch: 193| Step: 0
Training loss: 1.6919091939926147
Validation loss: 2.107840657234192

Epoch: 6| Step: 1
Training loss: 1.5398353338241577
Validation loss: 2.1222992738087973

Epoch: 6| Step: 2
Training loss: 2.342121124267578
Validation loss: 2.1015143990516663

Epoch: 6| Step: 3
Training loss: 1.8216049671173096
Validation loss: 2.108549733956655

Epoch: 6| Step: 4
Training loss: 1.7925944328308105
Validation loss: 2.1240670879681907

Epoch: 6| Step: 5
Training loss: 1.7016794681549072
Validation loss: 2.118559698263804

Epoch: 6| Step: 6
Training loss: 2.249228000640869
Validation loss: 2.1180683771769204

Epoch: 6| Step: 7
Training loss: 1.529964566230774
Validation loss: 2.114225526650747

Epoch: 6| Step: 8
Training loss: 1.2189819812774658
Validation loss: 2.1048059662183127

Epoch: 6| Step: 9
Training loss: 2.375109910964966
Validation loss: 2.1188559333483377

Epoch: 6| Step: 10
Training loss: 1.8619118928909302
Validation loss: 2.1084651748339334

Epoch: 6| Step: 11
Training loss: 2.6330251693725586
Validation loss: 2.1089405616124473

Epoch: 6| Step: 12
Training loss: 1.586862325668335
Validation loss: 2.1017480293909707

Epoch: 6| Step: 13
Training loss: 1.9918482303619385
Validation loss: 2.1170152028401694

Epoch: 194| Step: 0
Training loss: 1.8571412563323975
Validation loss: 2.1087467471758523

Epoch: 6| Step: 1
Training loss: 1.7250587940216064
Validation loss: 2.114866773287455

Epoch: 6| Step: 2
Training loss: 1.4596625566482544
Validation loss: 2.12502920627594

Epoch: 6| Step: 3
Training loss: 2.145329475402832
Validation loss: 2.117311259110769

Epoch: 6| Step: 4
Training loss: 1.5956926345825195
Validation loss: 2.1047333478927612

Epoch: 6| Step: 5
Training loss: 1.810370683670044
Validation loss: 2.1002575953801474

Epoch: 6| Step: 6
Training loss: 1.913456678390503
Validation loss: 2.119711975256602

Epoch: 6| Step: 7
Training loss: 1.9784655570983887
Validation loss: 2.1177924275398254

Epoch: 6| Step: 8
Training loss: 2.148118019104004
Validation loss: 2.119818607966105

Epoch: 6| Step: 9
Training loss: 1.808591365814209
Validation loss: 2.1183770100275674

Epoch: 6| Step: 10
Training loss: 1.7007946968078613
Validation loss: 2.1126341025034585

Epoch: 6| Step: 11
Training loss: 2.2890965938568115
Validation loss: 2.1149050196011863

Epoch: 6| Step: 12
Training loss: 1.6454284191131592
Validation loss: 2.102304518222809

Epoch: 6| Step: 13
Training loss: 2.289412021636963
Validation loss: 2.1205912629763284

Epoch: 195| Step: 0
Training loss: 1.518670916557312
Validation loss: 2.1019543608029685

Epoch: 6| Step: 1
Training loss: 1.3430200815200806
Validation loss: 2.100265602270762

Epoch: 6| Step: 2
Training loss: 1.6424214839935303
Validation loss: 2.1051722367604575

Epoch: 6| Step: 3
Training loss: 2.027825117111206
Validation loss: 2.111275374889374

Epoch: 6| Step: 4
Training loss: 1.9265612363815308
Validation loss: 2.107299288113912

Epoch: 6| Step: 5
Training loss: 2.0996475219726562
Validation loss: 2.1124825874964395

Epoch: 6| Step: 6
Training loss: 2.200676918029785
Validation loss: 2.103928009668986

Epoch: 6| Step: 7
Training loss: 1.87053382396698
Validation loss: 2.109784245491028

Epoch: 6| Step: 8
Training loss: 1.6054517030715942
Validation loss: 2.142726500829061

Epoch: 6| Step: 9
Training loss: 1.7817747592926025
Validation loss: 2.14441708723704

Epoch: 6| Step: 10
Training loss: 2.4912643432617188
Validation loss: 2.1605297923088074

Epoch: 6| Step: 11
Training loss: 1.762654185295105
Validation loss: 2.1526516477266946

Epoch: 6| Step: 12
Training loss: 2.4875566959381104
Validation loss: 2.121821641921997

Epoch: 6| Step: 13
Training loss: 1.8618906736373901
Validation loss: 2.1316508253415427

Epoch: 196| Step: 0
Training loss: 1.8698692321777344
Validation loss: 2.116795321305593

Epoch: 6| Step: 1
Training loss: 1.8355000019073486
Validation loss: 2.1113345623016357

Epoch: 6| Step: 2
Training loss: 1.327295184135437
Validation loss: 2.1064134438832602

Epoch: 6| Step: 3
Training loss: 2.2215356826782227
Validation loss: 2.0973766843477883

Epoch: 6| Step: 4
Training loss: 3.169793128967285
Validation loss: 2.086568236351013

Epoch: 6| Step: 5
Training loss: 2.2735037803649902
Validation loss: 2.096949895222982

Epoch: 6| Step: 6
Training loss: 1.8500597476959229
Validation loss: 2.0990187923113504

Epoch: 6| Step: 7
Training loss: 1.959850788116455
Validation loss: 2.1091426610946655

Epoch: 6| Step: 8
Training loss: 2.4177637100219727
Validation loss: 2.101940333843231

Epoch: 6| Step: 9
Training loss: 1.2196401357650757
Validation loss: 2.1025402545928955

Epoch: 6| Step: 10
Training loss: 2.0503907203674316
Validation loss: 2.1059561173121133

Epoch: 6| Step: 11
Training loss: 1.5126874446868896
Validation loss: 2.1052709023157754

Epoch: 6| Step: 12
Training loss: 1.4167697429656982
Validation loss: 2.1240649620691934

Epoch: 6| Step: 13
Training loss: 2.0874733924865723
Validation loss: 2.129737993081411

Epoch: 197| Step: 0
Training loss: 1.8587839603424072
Validation loss: 2.134589989980062

Epoch: 6| Step: 1
Training loss: 1.5445501804351807
Validation loss: 2.1251916686693826

Epoch: 6| Step: 2
Training loss: 2.299793243408203
Validation loss: 2.1393319964408875

Epoch: 6| Step: 3
Training loss: 1.8144170045852661
Validation loss: 2.137531598409017

Epoch: 6| Step: 4
Training loss: 1.3877782821655273
Validation loss: 2.127077261606852

Epoch: 6| Step: 5
Training loss: 2.251920700073242
Validation loss: 2.1393959522247314

Epoch: 6| Step: 6
Training loss: 1.5609968900680542
Validation loss: 2.1467459201812744

Epoch: 6| Step: 7
Training loss: 2.2337405681610107
Validation loss: 2.1289318005243936

Epoch: 6| Step: 8
Training loss: 3.171133041381836
Validation loss: 2.1075382232666016

Epoch: 6| Step: 9
Training loss: 1.5709452629089355
Validation loss: 2.114882151285807

Epoch: 6| Step: 10
Training loss: 2.056093215942383
Validation loss: 2.103804588317871

Epoch: 6| Step: 11
Training loss: 1.7364447116851807
Validation loss: 2.0858243902524314

Epoch: 6| Step: 12
Training loss: 1.5412888526916504
Validation loss: 2.086635112762451

Epoch: 6| Step: 13
Training loss: 1.6793123483657837
Validation loss: 2.0756821632385254

Epoch: 198| Step: 0
Training loss: 1.8526800870895386
Validation loss: 2.081735153992971

Epoch: 6| Step: 1
Training loss: 2.142441987991333
Validation loss: 2.0738680760065713

Epoch: 6| Step: 2
Training loss: 1.8065845966339111
Validation loss: 2.0781773130098977

Epoch: 6| Step: 3
Training loss: 2.052093505859375
Validation loss: 2.0900630950927734

Epoch: 6| Step: 4
Training loss: 1.8659099340438843
Validation loss: 2.0862905581792197

Epoch: 6| Step: 5
Training loss: 1.4533066749572754
Validation loss: 2.095791280269623

Epoch: 6| Step: 6
Training loss: 1.7551329135894775
Validation loss: 2.1179445385932922

Epoch: 6| Step: 7
Training loss: 1.6936438083648682
Validation loss: 2.1218433181444802

Epoch: 6| Step: 8
Training loss: 1.9978976249694824
Validation loss: 2.1313140590985618

Epoch: 6| Step: 9
Training loss: 1.4956908226013184
Validation loss: 2.1291287541389465

Epoch: 6| Step: 10
Training loss: 2.0088937282562256
Validation loss: 2.141440431276957

Epoch: 6| Step: 11
Training loss: 2.7601866722106934
Validation loss: 2.1329633394877114

Epoch: 6| Step: 12
Training loss: 1.6606682538986206
Validation loss: 2.1355623404184976

Epoch: 6| Step: 13
Training loss: 2.2973825931549072
Validation loss: 2.139607628186544

Epoch: 199| Step: 0
Training loss: 1.787116527557373
Validation loss: 2.1257590452829995

Epoch: 6| Step: 1
Training loss: 1.691933512687683
Validation loss: 2.128559728463491

Epoch: 6| Step: 2
Training loss: 2.526075839996338
Validation loss: 2.124570389588674

Epoch: 6| Step: 3
Training loss: 2.0948843955993652
Validation loss: 2.140396157900492

Epoch: 6| Step: 4
Training loss: 1.8032195568084717
Validation loss: 2.123433450857798

Epoch: 6| Step: 5
Training loss: 1.76528000831604
Validation loss: 2.1282884081204734

Epoch: 6| Step: 6
Training loss: 2.546760082244873
Validation loss: 2.1372684836387634

Epoch: 6| Step: 7
Training loss: 2.344076633453369
Validation loss: 2.123731871445974

Epoch: 6| Step: 8
Training loss: 1.5439845323562622
Validation loss: 2.1197516719500222

Epoch: 6| Step: 9
Training loss: 1.221387267112732
Validation loss: 2.1050251722335815

Epoch: 6| Step: 10
Training loss: 1.7324446439743042
Validation loss: 2.112917204697927

Epoch: 6| Step: 11
Training loss: 1.6841928958892822
Validation loss: 2.1091246406237283

Epoch: 6| Step: 12
Training loss: 1.2108687162399292
Validation loss: 2.1182073950767517

Epoch: 6| Step: 13
Training loss: 2.240326404571533
Validation loss: 2.1250545183817544

Epoch: 200| Step: 0
Training loss: 2.2197837829589844
Validation loss: 2.130511522293091

Epoch: 6| Step: 1
Training loss: 2.1466517448425293
Validation loss: 2.1157941023508706

Epoch: 6| Step: 2
Training loss: 1.765395164489746
Validation loss: 2.1284486254056296

Epoch: 6| Step: 3
Training loss: 1.345024824142456
Validation loss: 2.1295936504999795

Epoch: 6| Step: 4
Training loss: 1.6993458271026611
Validation loss: 2.149393598238627

Epoch: 6| Step: 5
Training loss: 2.251070737838745
Validation loss: 2.1183865865071616

Epoch: 6| Step: 6
Training loss: 2.088991641998291
Validation loss: 2.0936756134033203

Epoch: 6| Step: 7
Training loss: 1.6057918071746826
Validation loss: 2.1128633419672647

Epoch: 6| Step: 8
Training loss: 1.387686848640442
Validation loss: 2.12769349416097

Epoch: 6| Step: 9
Training loss: 1.7534480094909668
Validation loss: 2.1115397810935974

Epoch: 6| Step: 10
Training loss: 1.6387457847595215
Validation loss: 2.109669268131256

Epoch: 6| Step: 11
Training loss: 2.2202467918395996
Validation loss: 2.1077742179234824

Epoch: 6| Step: 12
Training loss: 1.8238389492034912
Validation loss: 2.103406310081482

Epoch: 6| Step: 13
Training loss: 2.54390549659729
Validation loss: 2.1018845240275064

Epoch: 201| Step: 0
Training loss: 1.909561276435852
Validation loss: 2.095428228378296

Epoch: 6| Step: 1
Training loss: 2.314431667327881
Validation loss: 2.0888176957766214

Epoch: 6| Step: 2
Training loss: 1.5777970552444458
Validation loss: 2.083030382792155

Epoch: 6| Step: 3
Training loss: 1.9458093643188477
Validation loss: 2.1057494282722473

Epoch: 6| Step: 4
Training loss: 1.9946725368499756
Validation loss: 2.0909070571263633

Epoch: 6| Step: 5
Training loss: 1.7936387062072754
Validation loss: 2.1092254320780435

Epoch: 6| Step: 6
Training loss: 2.666182279586792
Validation loss: 2.1061826944351196

Epoch: 6| Step: 7
Training loss: 1.977943778038025
Validation loss: 2.113243579864502

Epoch: 6| Step: 8
Training loss: 1.4624273777008057
Validation loss: 2.108601927757263

Epoch: 6| Step: 9
Training loss: 1.4897834062576294
Validation loss: 2.115957419077555

Epoch: 6| Step: 10
Training loss: 2.276642322540283
Validation loss: 2.1258368492126465

Epoch: 6| Step: 11
Training loss: 1.1733297109603882
Validation loss: 2.1288418968518577

Epoch: 6| Step: 12
Training loss: 1.7594084739685059
Validation loss: 2.1294718583424888

Epoch: 6| Step: 13
Training loss: 2.287620782852173
Validation loss: 2.1351361672083535

Epoch: 202| Step: 0
Training loss: 1.3917142152786255
Validation loss: 2.115463356177012

Epoch: 6| Step: 1
Training loss: 2.018001079559326
Validation loss: 2.133981784184774

Epoch: 6| Step: 2
Training loss: 2.830664873123169
Validation loss: 2.146274467309316

Epoch: 6| Step: 3
Training loss: 1.7733768224716187
Validation loss: 2.1181708176930747

Epoch: 6| Step: 4
Training loss: 2.16188907623291
Validation loss: 2.1276073853174844

Epoch: 6| Step: 5
Training loss: 2.2559361457824707
Validation loss: 2.1205902099609375

Epoch: 6| Step: 6
Training loss: 2.058900833129883
Validation loss: 2.1172486543655396

Epoch: 6| Step: 7
Training loss: 1.493095874786377
Validation loss: 2.1041253805160522

Epoch: 6| Step: 8
Training loss: 1.9108219146728516
Validation loss: 2.118585467338562

Epoch: 6| Step: 9
Training loss: 1.5068278312683105
Validation loss: 2.1131625175476074

Epoch: 6| Step: 10
Training loss: 1.5227826833724976
Validation loss: 2.1077547868092856

Epoch: 6| Step: 11
Training loss: 2.2413008213043213
Validation loss: 2.1266254782676697

Epoch: 6| Step: 12
Training loss: 1.4131741523742676
Validation loss: 2.1336105465888977

Epoch: 6| Step: 13
Training loss: 2.0652108192443848
Validation loss: 2.140791376431783

Epoch: 203| Step: 0
Training loss: 2.2794556617736816
Validation loss: 2.1352873047192893

Epoch: 6| Step: 1
Training loss: 2.020784378051758
Validation loss: 2.1597927014033

Epoch: 6| Step: 2
Training loss: 1.7799911499023438
Validation loss: 2.149470090866089

Epoch: 6| Step: 3
Training loss: 2.2257914543151855
Validation loss: 2.1234376629193625

Epoch: 6| Step: 4
Training loss: 1.8912410736083984
Validation loss: 2.13067497809728

Epoch: 6| Step: 5
Training loss: 1.8357818126678467
Validation loss: 2.1359647313753762

Epoch: 6| Step: 6
Training loss: 1.4878923892974854
Validation loss: 2.130317767461141

Epoch: 6| Step: 7
Training loss: 1.7477385997772217
Validation loss: 2.1171619296073914

Epoch: 6| Step: 8
Training loss: 1.097554087638855
Validation loss: 2.1302338441212973

Epoch: 6| Step: 9
Training loss: 2.131051778793335
Validation loss: 2.116091708342234

Epoch: 6| Step: 10
Training loss: 1.2676994800567627
Validation loss: 2.1158857941627502

Epoch: 6| Step: 11
Training loss: 1.907672643661499
Validation loss: 2.116015394528707

Epoch: 6| Step: 12
Training loss: 2.523503541946411
Validation loss: 2.1082906126976013

Epoch: 6| Step: 13
Training loss: 2.168898344039917
Validation loss: 2.1164254347483316

Epoch: 204| Step: 0
Training loss: 1.9195667505264282
Validation loss: 2.112426737944285

Epoch: 6| Step: 1
Training loss: 1.874720811843872
Validation loss: 2.120378255844116

Epoch: 6| Step: 2
Training loss: 2.295327663421631
Validation loss: 2.115787148475647

Epoch: 6| Step: 3
Training loss: 1.366924524307251
Validation loss: 2.1222175558408103

Epoch: 6| Step: 4
Training loss: 2.3190386295318604
Validation loss: 2.131174544493357

Epoch: 6| Step: 5
Training loss: 2.4476771354675293
Validation loss: 2.141834040482839

Epoch: 6| Step: 6
Training loss: 2.225755214691162
Validation loss: 2.1242095629374185

Epoch: 6| Step: 7
Training loss: 1.6271159648895264
Validation loss: 2.1152957677841187

Epoch: 6| Step: 8
Training loss: 1.9786099195480347
Validation loss: 2.130206743876139

Epoch: 6| Step: 9
Training loss: 2.071140766143799
Validation loss: 2.124554971853892

Epoch: 6| Step: 10
Training loss: 1.3847346305847168
Validation loss: 2.1317164301872253

Epoch: 6| Step: 11
Training loss: 1.2627665996551514
Validation loss: 2.121360997358958

Epoch: 6| Step: 12
Training loss: 2.031709671020508
Validation loss: 2.1150756080945334

Epoch: 6| Step: 13
Training loss: 1.3569607734680176
Validation loss: 2.1291277607282004

Epoch: 205| Step: 0
Training loss: 2.139451265335083
Validation loss: 2.125369052092234

Epoch: 6| Step: 1
Training loss: 1.3429560661315918
Validation loss: 2.1165248354276023

Epoch: 6| Step: 2
Training loss: 1.7789047956466675
Validation loss: 2.13145645459493

Epoch: 6| Step: 3
Training loss: 1.9664055109024048
Validation loss: 2.151298999786377

Epoch: 6| Step: 4
Training loss: 1.754140853881836
Validation loss: 2.145541866620382

Epoch: 6| Step: 5
Training loss: 1.7207145690917969
Validation loss: 2.1304931044578552

Epoch: 6| Step: 6
Training loss: 2.5055508613586426
Validation loss: 2.153558830420176

Epoch: 6| Step: 7
Training loss: 1.5564348697662354
Validation loss: 2.154266834259033

Epoch: 6| Step: 8
Training loss: 1.38974928855896
Validation loss: 2.145575006802877

Epoch: 6| Step: 9
Training loss: 2.3353919982910156
Validation loss: 2.1400848229726157

Epoch: 6| Step: 10
Training loss: 2.101675271987915
Validation loss: 2.12333212296168

Epoch: 6| Step: 11
Training loss: 1.7643964290618896
Validation loss: 2.1036694645881653

Epoch: 6| Step: 12
Training loss: 1.715624213218689
Validation loss: 2.1398795445760093

Epoch: 6| Step: 13
Training loss: 2.236159086227417
Validation loss: 2.1168596744537354

Epoch: 206| Step: 0
Training loss: 1.4638068675994873
Validation loss: 2.1143585046132407

Epoch: 6| Step: 1
Training loss: 1.7615766525268555
Validation loss: 2.116470376650492

Epoch: 6| Step: 2
Training loss: 2.164527654647827
Validation loss: 2.114102760950724

Epoch: 6| Step: 3
Training loss: 2.012937545776367
Validation loss: 2.128775874773661

Epoch: 6| Step: 4
Training loss: 1.7018139362335205
Validation loss: 2.135694742202759

Epoch: 6| Step: 5
Training loss: 1.7602946758270264
Validation loss: 2.132542828718821

Epoch: 6| Step: 6
Training loss: 1.9729845523834229
Validation loss: 2.1390697956085205

Epoch: 6| Step: 7
Training loss: 2.0802230834960938
Validation loss: 2.1254236300786338

Epoch: 6| Step: 8
Training loss: 1.9844409227371216
Validation loss: 2.1138349771499634

Epoch: 6| Step: 9
Training loss: 1.756272315979004
Validation loss: 2.1349002917607627

Epoch: 6| Step: 10
Training loss: 2.1895205974578857
Validation loss: 2.1543889244397483

Epoch: 6| Step: 11
Training loss: 2.069854497909546
Validation loss: 2.130991597970327

Epoch: 6| Step: 12
Training loss: 1.2736217975616455
Validation loss: 2.114489952723185

Epoch: 6| Step: 13
Training loss: 1.973008394241333
Validation loss: 2.1397958000501

Epoch: 207| Step: 0
Training loss: 1.6614935398101807
Validation loss: 2.121684710184733

Epoch: 6| Step: 1
Training loss: 1.0464396476745605
Validation loss: 2.130824347337087

Epoch: 6| Step: 2
Training loss: 1.7600919008255005
Validation loss: 2.1188738346099854

Epoch: 6| Step: 3
Training loss: 2.419658660888672
Validation loss: 2.12332151333491

Epoch: 6| Step: 4
Training loss: 1.5711784362792969
Validation loss: 2.1223455667495728

Epoch: 6| Step: 5
Training loss: 1.5436161756515503
Validation loss: 2.1012837092081704

Epoch: 6| Step: 6
Training loss: 2.114246368408203
Validation loss: 2.096325099468231

Epoch: 6| Step: 7
Training loss: 2.0050699710845947
Validation loss: 2.103569527467092

Epoch: 6| Step: 8
Training loss: 2.058521270751953
Validation loss: 2.107011159261068

Epoch: 6| Step: 9
Training loss: 2.4083573818206787
Validation loss: 2.1020967165629068

Epoch: 6| Step: 10
Training loss: 1.7651877403259277
Validation loss: 2.1045268376668296

Epoch: 6| Step: 11
Training loss: 1.766638159751892
Validation loss: 2.1290979782740274

Epoch: 6| Step: 12
Training loss: 2.311094284057617
Validation loss: 2.126216928164164

Epoch: 6| Step: 13
Training loss: 1.7332942485809326
Validation loss: 2.136869490146637

Epoch: 208| Step: 0
Training loss: 1.958292007446289
Validation loss: 2.1333529353141785

Epoch: 6| Step: 1
Training loss: 2.3285017013549805
Validation loss: 2.150990386803945

Epoch: 6| Step: 2
Training loss: 2.1374411582946777
Validation loss: 2.1442341009775796

Epoch: 6| Step: 3
Training loss: 1.654902458190918
Validation loss: 2.1316280364990234

Epoch: 6| Step: 4
Training loss: 1.4647045135498047
Validation loss: 2.1144661704699197

Epoch: 6| Step: 5
Training loss: 1.5686640739440918
Validation loss: 2.1234980821609497

Epoch: 6| Step: 6
Training loss: 1.5036425590515137
Validation loss: 2.111515482266744

Epoch: 6| Step: 7
Training loss: 1.8113962411880493
Validation loss: 2.1242757638295493

Epoch: 6| Step: 8
Training loss: 1.963667392730713
Validation loss: 2.110185146331787

Epoch: 6| Step: 9
Training loss: 1.8840484619140625
Validation loss: 2.119544247786204

Epoch: 6| Step: 10
Training loss: 1.6665856838226318
Validation loss: 2.126662532488505

Epoch: 6| Step: 11
Training loss: 2.183213233947754
Validation loss: 2.1052697896957397

Epoch: 6| Step: 12
Training loss: 1.5603723526000977
Validation loss: 2.1244183580080667

Epoch: 6| Step: 13
Training loss: 2.141097068786621
Validation loss: 2.1374168197313943

Epoch: 209| Step: 0
Training loss: 1.6260370016098022
Validation loss: 2.118304173151652

Epoch: 6| Step: 1
Training loss: 2.0729641914367676
Validation loss: 2.1230245431264243

Epoch: 6| Step: 2
Training loss: 2.0361287593841553
Validation loss: 2.140039344628652

Epoch: 6| Step: 3
Training loss: 1.7203341722488403
Validation loss: 2.130942980448405

Epoch: 6| Step: 4
Training loss: 2.066894054412842
Validation loss: 2.137985587120056

Epoch: 6| Step: 5
Training loss: 1.3217840194702148
Validation loss: 2.139390448729197

Epoch: 6| Step: 6
Training loss: 2.6518325805664062
Validation loss: 2.128952463467916

Epoch: 6| Step: 7
Training loss: 1.0312907695770264
Validation loss: 2.121885577837626

Epoch: 6| Step: 8
Training loss: 2.178675889968872
Validation loss: 2.131424387296041

Epoch: 6| Step: 9
Training loss: 2.152404546737671
Validation loss: 2.1045610706011453

Epoch: 6| Step: 10
Training loss: 1.4776277542114258
Validation loss: 2.1101356546084085

Epoch: 6| Step: 11
Training loss: 2.4078640937805176
Validation loss: 2.112415373325348

Epoch: 6| Step: 12
Training loss: 1.9272311925888062
Validation loss: 2.122901757558187

Epoch: 6| Step: 13
Training loss: 1.27776300907135
Validation loss: 2.1318538387616477

Epoch: 210| Step: 0
Training loss: 1.7517673969268799
Validation loss: 2.1402167280515036

Epoch: 6| Step: 1
Training loss: 1.6386158466339111
Validation loss: 2.1375256379445395

Epoch: 6| Step: 2
Training loss: 2.1411614418029785
Validation loss: 2.1335713466008506

Epoch: 6| Step: 3
Training loss: 1.7773823738098145
Validation loss: 2.15138570467631

Epoch: 6| Step: 4
Training loss: 1.8177709579467773
Validation loss: 2.1358434160550437

Epoch: 6| Step: 5
Training loss: 1.8796255588531494
Validation loss: 2.1480194330215454

Epoch: 6| Step: 6
Training loss: 1.834012508392334
Validation loss: 2.138910194238027

Epoch: 6| Step: 7
Training loss: 2.2615928649902344
Validation loss: 2.150678336620331

Epoch: 6| Step: 8
Training loss: 1.652238368988037
Validation loss: 2.1466626723607383

Epoch: 6| Step: 9
Training loss: 1.7064847946166992
Validation loss: 2.146936813990275

Epoch: 6| Step: 10
Training loss: 1.9139883518218994
Validation loss: 2.1277566949526467

Epoch: 6| Step: 11
Training loss: 1.9095854759216309
Validation loss: 2.129378835360209

Epoch: 6| Step: 12
Training loss: 1.4905321598052979
Validation loss: 2.1196274558703103

Epoch: 6| Step: 13
Training loss: 2.0380630493164062
Validation loss: 2.131796916325887

Epoch: 211| Step: 0
Training loss: 2.3211796283721924
Validation loss: 2.1137054165204368

Epoch: 6| Step: 1
Training loss: 1.3801257610321045
Validation loss: 2.1302976608276367

Epoch: 6| Step: 2
Training loss: 1.4557181596755981
Validation loss: 2.1282989780108132

Epoch: 6| Step: 3
Training loss: 2.9147558212280273
Validation loss: 2.1367128690083823

Epoch: 6| Step: 4
Training loss: 1.4331376552581787
Validation loss: 2.1306941310564675

Epoch: 6| Step: 5
Training loss: 2.273782730102539
Validation loss: 2.1216598749160767

Epoch: 6| Step: 6
Training loss: 2.1576833724975586
Validation loss: 2.1245001951853433

Epoch: 6| Step: 7
Training loss: 1.5371577739715576
Validation loss: 2.1287099719047546

Epoch: 6| Step: 8
Training loss: 1.3519058227539062
Validation loss: 2.1279075741767883

Epoch: 6| Step: 9
Training loss: 1.5114960670471191
Validation loss: 2.1393997271855674

Epoch: 6| Step: 10
Training loss: 2.1130261421203613
Validation loss: 2.1347312132517495

Epoch: 6| Step: 11
Training loss: 1.6660414934158325
Validation loss: 2.1177260478337607

Epoch: 6| Step: 12
Training loss: 1.819021463394165
Validation loss: 2.1178925236066184

Epoch: 6| Step: 13
Training loss: 2.007786273956299
Validation loss: 2.1213418841362

Epoch: 212| Step: 0
Training loss: 1.336857557296753
Validation loss: 2.109813948472341

Epoch: 6| Step: 1
Training loss: 1.9506561756134033
Validation loss: 2.120404322942098

Epoch: 6| Step: 2
Training loss: 1.5699471235275269
Validation loss: 2.1364816625912986

Epoch: 6| Step: 3
Training loss: 1.5038671493530273
Validation loss: 2.1337794860204062

Epoch: 6| Step: 4
Training loss: 1.8504526615142822
Validation loss: 2.118222693602244

Epoch: 6| Step: 5
Training loss: 1.3300087451934814
Validation loss: 2.133302390575409

Epoch: 6| Step: 6
Training loss: 3.1167678833007812
Validation loss: 2.1359097560246787

Epoch: 6| Step: 7
Training loss: 1.5418202877044678
Validation loss: 2.129758576552073

Epoch: 6| Step: 8
Training loss: 1.625090479850769
Validation loss: 2.1301128466924033

Epoch: 6| Step: 9
Training loss: 1.170762062072754
Validation loss: 2.145460526148478

Epoch: 6| Step: 10
Training loss: 2.000072479248047
Validation loss: 2.1381114522616067

Epoch: 6| Step: 11
Training loss: 2.354027271270752
Validation loss: 2.159292201201121

Epoch: 6| Step: 12
Training loss: 2.0649027824401855
Validation loss: 2.1477675835291543

Epoch: 6| Step: 13
Training loss: 2.1723923683166504
Validation loss: 2.1296596924463906

Epoch: 213| Step: 0
Training loss: 1.3950053453445435
Validation loss: 2.134438474973043

Epoch: 6| Step: 1
Training loss: 1.501640796661377
Validation loss: 2.1207276582717896

Epoch: 6| Step: 2
Training loss: 1.544424057006836
Validation loss: 2.128589471181234

Epoch: 6| Step: 3
Training loss: 2.2334237098693848
Validation loss: 2.118372102578481

Epoch: 6| Step: 4
Training loss: 1.5982215404510498
Validation loss: 2.107146402200063

Epoch: 6| Step: 5
Training loss: 1.665241003036499
Validation loss: 2.113246281941732

Epoch: 6| Step: 6
Training loss: 2.52628755569458
Validation loss: 2.1166623632113137

Epoch: 6| Step: 7
Training loss: 1.754962682723999
Validation loss: 2.1080418825149536

Epoch: 6| Step: 8
Training loss: 1.7734882831573486
Validation loss: 2.1119157473246255

Epoch: 6| Step: 9
Training loss: 2.096863031387329
Validation loss: 2.11667408545812

Epoch: 6| Step: 10
Training loss: 1.7553189992904663
Validation loss: 2.1295902132987976

Epoch: 6| Step: 11
Training loss: 2.0650997161865234
Validation loss: 2.1479423443476358

Epoch: 6| Step: 12
Training loss: 1.7345846891403198
Validation loss: 2.1317561666170755

Epoch: 6| Step: 13
Training loss: 2.0833897590637207
Validation loss: 2.1557372013727822

Epoch: 214| Step: 0
Training loss: 2.131981372833252
Validation loss: 2.139693478743235

Epoch: 6| Step: 1
Training loss: 2.2356154918670654
Validation loss: 2.1295306285222373

Epoch: 6| Step: 2
Training loss: 1.4455934762954712
Validation loss: 2.1463458935419717

Epoch: 6| Step: 3
Training loss: 1.8628565073013306
Validation loss: 2.132599115371704

Epoch: 6| Step: 4
Training loss: 1.920879602432251
Validation loss: 2.157174905141195

Epoch: 6| Step: 5
Training loss: 1.8762092590332031
Validation loss: 2.137129863103231

Epoch: 6| Step: 6
Training loss: 1.6262643337249756
Validation loss: 2.145742734273275

Epoch: 6| Step: 7
Training loss: 1.5467023849487305
Validation loss: 2.1431159377098083

Epoch: 6| Step: 8
Training loss: 2.156993865966797
Validation loss: 2.121773362159729

Epoch: 6| Step: 9
Training loss: 1.7635786533355713
Validation loss: 2.1000404357910156

Epoch: 6| Step: 10
Training loss: 2.3727400302886963
Validation loss: 2.1099140644073486

Epoch: 6| Step: 11
Training loss: 1.7943254709243774
Validation loss: 2.1039339900016785

Epoch: 6| Step: 12
Training loss: 1.803958535194397
Validation loss: 2.1123616298039756

Epoch: 6| Step: 13
Training loss: 2.054509162902832
Validation loss: 2.1139329274495444

Epoch: 215| Step: 0
Training loss: 1.820319414138794
Validation loss: 2.113153596719106

Epoch: 6| Step: 1
Training loss: 1.846431016921997
Validation loss: 2.1146691044171653

Epoch: 6| Step: 2
Training loss: 1.6012709140777588
Validation loss: 2.128536601861318

Epoch: 6| Step: 3
Training loss: 1.9508562088012695
Validation loss: 2.120299140612284

Epoch: 6| Step: 4
Training loss: 1.7993824481964111
Validation loss: 2.1206852992375693

Epoch: 6| Step: 5
Training loss: 2.009155511856079
Validation loss: 2.1078648368517556

Epoch: 6| Step: 6
Training loss: 1.5665971040725708
Validation loss: 2.1144429643948874

Epoch: 6| Step: 7
Training loss: 1.640963077545166
Validation loss: 2.1250716050465903

Epoch: 6| Step: 8
Training loss: 1.2691789865493774
Validation loss: 2.1228054761886597

Epoch: 6| Step: 9
Training loss: 2.810732841491699
Validation loss: 2.121867835521698

Epoch: 6| Step: 10
Training loss: 1.5794975757598877
Validation loss: 2.1230029265085855

Epoch: 6| Step: 11
Training loss: 1.47198486328125
Validation loss: 2.1239661375681558

Epoch: 6| Step: 12
Training loss: 2.0066444873809814
Validation loss: 2.1285189191500344

Epoch: 6| Step: 13
Training loss: 2.2983198165893555
Validation loss: 2.126783569653829

Epoch: 216| Step: 0
Training loss: 1.5377182960510254
Validation loss: 2.123189310232798

Epoch: 6| Step: 1
Training loss: 2.4222702980041504
Validation loss: 2.122945249080658

Epoch: 6| Step: 2
Training loss: 1.5308120250701904
Validation loss: 2.125465432802836

Epoch: 6| Step: 3
Training loss: 1.9412705898284912
Validation loss: 2.121821622053782

Epoch: 6| Step: 4
Training loss: 1.7301714420318604
Validation loss: 2.1294617851575217

Epoch: 6| Step: 5
Training loss: 1.7520408630371094
Validation loss: 2.126537322998047

Epoch: 6| Step: 6
Training loss: 1.3315999507904053
Validation loss: 2.113359789053599

Epoch: 6| Step: 7
Training loss: 2.723165988922119
Validation loss: 2.1307833393414817

Epoch: 6| Step: 8
Training loss: 1.134599208831787
Validation loss: 2.141842802365621

Epoch: 6| Step: 9
Training loss: 1.5202232599258423
Validation loss: 2.157812317212423

Epoch: 6| Step: 10
Training loss: 1.7467870712280273
Validation loss: 2.162863552570343

Epoch: 6| Step: 11
Training loss: 2.0168182849884033
Validation loss: 2.1737996339797974

Epoch: 6| Step: 12
Training loss: 1.8846604824066162
Validation loss: 2.1532183488210044

Epoch: 6| Step: 13
Training loss: 2.317296028137207
Validation loss: 2.156576911608378

Epoch: 217| Step: 0
Training loss: 2.1706457138061523
Validation loss: 2.1334595878918967

Epoch: 6| Step: 1
Training loss: 1.7919487953186035
Validation loss: 2.129085640112559

Epoch: 6| Step: 2
Training loss: 2.5231311321258545
Validation loss: 2.120117485523224

Epoch: 6| Step: 3
Training loss: 2.329981565475464
Validation loss: 2.134416699409485

Epoch: 6| Step: 4
Training loss: 1.5247671604156494
Validation loss: 2.1259252031644187

Epoch: 6| Step: 5
Training loss: 2.0064282417297363
Validation loss: 2.1252222657203674

Epoch: 6| Step: 6
Training loss: 1.3875176906585693
Validation loss: 2.1214075287183127

Epoch: 6| Step: 7
Training loss: 1.8346494436264038
Validation loss: 2.124395211537679

Epoch: 6| Step: 8
Training loss: 1.378178596496582
Validation loss: 2.1112417181332908

Epoch: 6| Step: 9
Training loss: 1.4307332038879395
Validation loss: 2.130741516749064

Epoch: 6| Step: 10
Training loss: 1.5757640600204468
Validation loss: 2.123399794101715

Epoch: 6| Step: 11
Training loss: 2.365997791290283
Validation loss: 2.1330031156539917

Epoch: 6| Step: 12
Training loss: 1.76593816280365
Validation loss: 2.1268687645594277

Epoch: 6| Step: 13
Training loss: 1.3056552410125732
Validation loss: 2.136640111605326

Epoch: 218| Step: 0
Training loss: 1.7586488723754883
Validation loss: 2.1257934967676797

Epoch: 6| Step: 1
Training loss: 1.7828890085220337
Validation loss: 2.130200147628784

Epoch: 6| Step: 2
Training loss: 2.1058456897735596
Validation loss: 2.1315001845359802

Epoch: 6| Step: 3
Training loss: 1.9036519527435303
Validation loss: 2.1335239013036094

Epoch: 6| Step: 4
Training loss: 1.5972424745559692
Validation loss: 2.130631764729818

Epoch: 6| Step: 5
Training loss: 1.762274146080017
Validation loss: 2.129637598991394

Epoch: 6| Step: 6
Training loss: 1.9197683334350586
Validation loss: 2.1271339058876038

Epoch: 6| Step: 7
Training loss: 1.1977267265319824
Validation loss: 2.129279891649882

Epoch: 6| Step: 8
Training loss: 2.0855212211608887
Validation loss: 2.1425708731015525

Epoch: 6| Step: 9
Training loss: 2.4931435585021973
Validation loss: 2.133695205052694

Epoch: 6| Step: 10
Training loss: 1.678229808807373
Validation loss: 2.1449460983276367

Epoch: 6| Step: 11
Training loss: 1.94126296043396
Validation loss: 2.1277493834495544

Epoch: 6| Step: 12
Training loss: 1.593601942062378
Validation loss: 2.1094839572906494

Epoch: 6| Step: 13
Training loss: 1.5387132167816162
Validation loss: 2.1302557786305747

Epoch: 219| Step: 0
Training loss: 2.0413694381713867
Validation loss: 2.140319267908732

Epoch: 6| Step: 1
Training loss: 1.5966286659240723
Validation loss: 2.127542734146118

Epoch: 6| Step: 2
Training loss: 1.818313717842102
Validation loss: 2.120549976825714

Epoch: 6| Step: 3
Training loss: 1.7573082447052002
Validation loss: 2.1174402038256326

Epoch: 6| Step: 4
Training loss: 1.8323040008544922
Validation loss: 2.134171744187673

Epoch: 6| Step: 5
Training loss: 1.8110804557800293
Validation loss: 2.1287410457928977

Epoch: 6| Step: 6
Training loss: 1.6276590824127197
Validation loss: 2.1389196713765464

Epoch: 6| Step: 7
Training loss: 1.6817141771316528
Validation loss: 2.156822621822357

Epoch: 6| Step: 8
Training loss: 2.0904316902160645
Validation loss: 2.140560964743296

Epoch: 6| Step: 9
Training loss: 1.6137452125549316
Validation loss: 2.135213394959768

Epoch: 6| Step: 10
Training loss: 1.6908921003341675
Validation loss: 2.1304839849472046

Epoch: 6| Step: 11
Training loss: 1.805283546447754
Validation loss: 2.1347151001294455

Epoch: 6| Step: 12
Training loss: 2.2866134643554688
Validation loss: 2.132183869679769

Epoch: 6| Step: 13
Training loss: 1.877694845199585
Validation loss: 2.1196261445681253

Epoch: 220| Step: 0
Training loss: 1.5235567092895508
Validation loss: 2.1212058067321777

Epoch: 6| Step: 1
Training loss: 1.3615175485610962
Validation loss: 2.110902984937032

Epoch: 6| Step: 2
Training loss: 1.829383134841919
Validation loss: 2.0986450711886087

Epoch: 6| Step: 3
Training loss: 2.181171417236328
Validation loss: 2.1207403937975564

Epoch: 6| Step: 4
Training loss: 2.5144429206848145
Validation loss: 2.124056359132131

Epoch: 6| Step: 5
Training loss: 2.0991251468658447
Validation loss: 2.1201040546099343

Epoch: 6| Step: 6
Training loss: 2.2813148498535156
Validation loss: 2.111779431502024

Epoch: 6| Step: 7
Training loss: 2.2265920639038086
Validation loss: 2.1071998278299966

Epoch: 6| Step: 8
Training loss: 1.9034960269927979
Validation loss: 2.1041384736696878

Epoch: 6| Step: 9
Training loss: 1.8972866535186768
Validation loss: 2.129711310068766

Epoch: 6| Step: 10
Training loss: 1.6346133947372437
Validation loss: 2.1278002858161926

Epoch: 6| Step: 11
Training loss: 1.8989636898040771
Validation loss: 2.1378461917241416

Epoch: 6| Step: 12
Training loss: 1.5888116359710693
Validation loss: 2.140064239501953

Epoch: 6| Step: 13
Training loss: 1.8232496976852417
Validation loss: 2.1632529497146606

Epoch: 221| Step: 0
Training loss: 2.426874876022339
Validation loss: 2.1723415851593018

Epoch: 6| Step: 1
Training loss: 1.7707679271697998
Validation loss: 2.187753140926361

Epoch: 6| Step: 2
Training loss: 1.89035964012146
Validation loss: 2.194127678871155

Epoch: 6| Step: 3
Training loss: 1.701865553855896
Validation loss: 2.1628835598627725

Epoch: 6| Step: 4
Training loss: 1.415814995765686
Validation loss: 2.1658859848976135

Epoch: 6| Step: 5
Training loss: 1.5776747465133667
Validation loss: 2.149287462234497

Epoch: 6| Step: 6
Training loss: 1.7513537406921387
Validation loss: 2.1387730836868286

Epoch: 6| Step: 7
Training loss: 1.2968182563781738
Validation loss: 2.1141695777575173

Epoch: 6| Step: 8
Training loss: 2.4534964561462402
Validation loss: 2.114470819632212

Epoch: 6| Step: 9
Training loss: 2.531254529953003
Validation loss: 2.12736052274704

Epoch: 6| Step: 10
Training loss: 2.168884515762329
Validation loss: 2.117445687452952

Epoch: 6| Step: 11
Training loss: 0.9735755920410156
Validation loss: 2.115135391553243

Epoch: 6| Step: 12
Training loss: 2.033189535140991
Validation loss: 2.1252390344937644

Epoch: 6| Step: 13
Training loss: 2.233130931854248
Validation loss: 2.128121574719747

Epoch: 222| Step: 0
Training loss: 1.9682388305664062
Validation loss: 2.1399616996447244

Epoch: 6| Step: 1
Training loss: 2.1185357570648193
Validation loss: 2.164676825205485

Epoch: 6| Step: 2
Training loss: 1.212095022201538
Validation loss: 2.1391495068868003

Epoch: 6| Step: 3
Training loss: 1.8033822774887085
Validation loss: 2.171807368596395

Epoch: 6| Step: 4
Training loss: 1.736581802368164
Validation loss: 2.16079451640447

Epoch: 6| Step: 5
Training loss: 1.8085798025131226
Validation loss: 2.154721478621165

Epoch: 6| Step: 6
Training loss: 2.464115858078003
Validation loss: 2.153719703356425

Epoch: 6| Step: 7
Training loss: 2.091320037841797
Validation loss: 2.1543532013893127

Epoch: 6| Step: 8
Training loss: 1.274282455444336
Validation loss: 2.1405149102211

Epoch: 6| Step: 9
Training loss: 1.4586632251739502
Validation loss: 2.1494574546813965

Epoch: 6| Step: 10
Training loss: 1.716763973236084
Validation loss: 2.1372819542884827

Epoch: 6| Step: 11
Training loss: 1.5908721685409546
Validation loss: 2.127320130666097

Epoch: 6| Step: 12
Training loss: 2.4206154346466064
Validation loss: 2.12912247578303

Epoch: 6| Step: 13
Training loss: 1.8079609870910645
Validation loss: 2.1356463630994162

Epoch: 223| Step: 0
Training loss: 2.553083658218384
Validation loss: 2.1271035075187683

Epoch: 6| Step: 1
Training loss: 2.2977514266967773
Validation loss: 2.1502984166145325

Epoch: 6| Step: 2
Training loss: 1.512424349784851
Validation loss: 2.1182945370674133

Epoch: 6| Step: 3
Training loss: 2.174741268157959
Validation loss: 2.1262944539388022

Epoch: 6| Step: 4
Training loss: 1.6475964784622192
Validation loss: 2.116307020187378

Epoch: 6| Step: 5
Training loss: 1.383903980255127
Validation loss: 2.1303980350494385

Epoch: 6| Step: 6
Training loss: 1.9095075130462646
Validation loss: 2.1274943550427756

Epoch: 6| Step: 7
Training loss: 2.2236409187316895
Validation loss: 2.1051854689915976

Epoch: 6| Step: 8
Training loss: 1.7526880502700806
Validation loss: 2.103212356567383

Epoch: 6| Step: 9
Training loss: 1.9021797180175781
Validation loss: 2.1079290310541787

Epoch: 6| Step: 10
Training loss: 1.5905689001083374
Validation loss: 2.119526485602061

Epoch: 6| Step: 11
Training loss: 1.971428394317627
Validation loss: 2.1081402699152627

Epoch: 6| Step: 12
Training loss: 1.2153912782669067
Validation loss: 2.1113677422205606

Epoch: 6| Step: 13
Training loss: 1.4378020763397217
Validation loss: 2.123502731323242

Epoch: 224| Step: 0
Training loss: 1.760711908340454
Validation loss: 2.1187321742375693

Epoch: 6| Step: 1
Training loss: 1.560564398765564
Validation loss: 2.116884628931681

Epoch: 6| Step: 2
Training loss: 1.1715941429138184
Validation loss: 2.123701790968577

Epoch: 6| Step: 3
Training loss: 1.8552807569503784
Validation loss: 2.1205932895342507

Epoch: 6| Step: 4
Training loss: 1.5379220247268677
Validation loss: 2.1269898414611816

Epoch: 6| Step: 5
Training loss: 1.3410067558288574
Validation loss: 2.122655729452769

Epoch: 6| Step: 6
Training loss: 1.751435399055481
Validation loss: 2.12160716454188

Epoch: 6| Step: 7
Training loss: 1.680849313735962
Validation loss: 2.1281960805257163

Epoch: 6| Step: 8
Training loss: 1.5002468824386597
Validation loss: 2.139053543408712

Epoch: 6| Step: 9
Training loss: 2.812516689300537
Validation loss: 2.1387533148129783

Epoch: 6| Step: 10
Training loss: 1.2050389051437378
Validation loss: 2.1518723169962564

Epoch: 6| Step: 11
Training loss: 2.500826358795166
Validation loss: 2.1543957591056824

Epoch: 6| Step: 12
Training loss: 2.2247328758239746
Validation loss: 2.1548629999160767

Epoch: 6| Step: 13
Training loss: 2.132767677307129
Validation loss: 2.1528362035751343

Epoch: 225| Step: 0
Training loss: 2.030771255493164
Validation loss: 2.1582820614178977

Epoch: 6| Step: 1
Training loss: 1.6434961557388306
Validation loss: 2.155091563860575

Epoch: 6| Step: 2
Training loss: 1.8210762739181519
Validation loss: 2.173027515411377

Epoch: 6| Step: 3
Training loss: 1.8492560386657715
Validation loss: 2.159688631693522

Epoch: 6| Step: 4
Training loss: 1.6253161430358887
Validation loss: 2.164244850476583

Epoch: 6| Step: 5
Training loss: 1.4846967458724976
Validation loss: 2.143055180708567

Epoch: 6| Step: 6
Training loss: 2.704397439956665
Validation loss: 2.1440566778182983

Epoch: 6| Step: 7
Training loss: 1.8432215452194214
Validation loss: 2.1269325415293374

Epoch: 6| Step: 8
Training loss: 2.0714895725250244
Validation loss: 2.1231589118639627

Epoch: 6| Step: 9
Training loss: 1.5305808782577515
Validation loss: 2.1273902654647827

Epoch: 6| Step: 10
Training loss: 1.4867135286331177
Validation loss: 2.1118916273117065

Epoch: 6| Step: 11
Training loss: 1.463393211364746
Validation loss: 2.1210777362187705

Epoch: 6| Step: 12
Training loss: 1.6605604887008667
Validation loss: 2.1464544932047525

Epoch: 6| Step: 13
Training loss: 2.1128358840942383
Validation loss: 2.1301358739535012

Epoch: 226| Step: 0
Training loss: 2.1670455932617188
Validation loss: 2.14003316561381

Epoch: 6| Step: 1
Training loss: 1.9442241191864014
Validation loss: 2.1497914592425027

Epoch: 6| Step: 2
Training loss: 2.5903592109680176
Validation loss: 2.185419499874115

Epoch: 6| Step: 3
Training loss: 1.4576008319854736
Validation loss: 2.1975005865097046

Epoch: 6| Step: 4
Training loss: 1.7302405834197998
Validation loss: 2.1819818019866943

Epoch: 6| Step: 5
Training loss: 1.8495866060256958
Validation loss: 2.1982472936312356

Epoch: 6| Step: 6
Training loss: 1.1617136001586914
Validation loss: 2.1806389490763345

Epoch: 6| Step: 7
Training loss: 1.9382719993591309
Validation loss: 2.1921141743659973

Epoch: 6| Step: 8
Training loss: 1.8493183851242065
Validation loss: 2.183308204015096

Epoch: 6| Step: 9
Training loss: 1.6007871627807617
Validation loss: 2.1640034715334573

Epoch: 6| Step: 10
Training loss: 1.4042150974273682
Validation loss: 2.1530712048212686

Epoch: 6| Step: 11
Training loss: 2.4314422607421875
Validation loss: 2.1590450604756675

Epoch: 6| Step: 12
Training loss: 1.5976426601409912
Validation loss: 2.143566687901815

Epoch: 6| Step: 13
Training loss: 1.4378139972686768
Validation loss: 2.1684879859288535

Epoch: 227| Step: 0
Training loss: 1.271558403968811
Validation loss: 2.1478015184402466

Epoch: 6| Step: 1
Training loss: 1.8184361457824707
Validation loss: 2.146053592363993

Epoch: 6| Step: 2
Training loss: 1.9103903770446777
Validation loss: 2.1226512591044107

Epoch: 6| Step: 3
Training loss: 2.1609206199645996
Validation loss: 2.1684115131696067

Epoch: 6| Step: 4
Training loss: 1.344552755355835
Validation loss: 2.149021029472351

Epoch: 6| Step: 5
Training loss: 1.5262370109558105
Validation loss: 2.143091320991516

Epoch: 6| Step: 6
Training loss: 2.2310121059417725
Validation loss: 2.1801277796427407

Epoch: 6| Step: 7
Training loss: 1.637216329574585
Validation loss: 2.1791934768358865

Epoch: 6| Step: 8
Training loss: 2.3376026153564453
Validation loss: 2.165797472000122

Epoch: 6| Step: 9
Training loss: 1.6098085641860962
Validation loss: 2.179529547691345

Epoch: 6| Step: 10
Training loss: 1.5737173557281494
Validation loss: 2.177725354830424

Epoch: 6| Step: 11
Training loss: 1.9180840253829956
Validation loss: 2.1416547497113547

Epoch: 6| Step: 12
Training loss: 1.8111116886138916
Validation loss: 2.162542998790741

Epoch: 6| Step: 13
Training loss: 1.9497902393341064
Validation loss: 2.14027202129364

Epoch: 228| Step: 0
Training loss: 2.0935397148132324
Validation loss: 2.138836900393168

Epoch: 6| Step: 1
Training loss: 2.0081310272216797
Validation loss: 2.152106980482737

Epoch: 6| Step: 2
Training loss: 1.9067726135253906
Validation loss: 2.1239443818728128

Epoch: 6| Step: 3
Training loss: 1.4067790508270264
Validation loss: 2.121111194292704

Epoch: 6| Step: 4
Training loss: 2.142209053039551
Validation loss: 2.1352137525876365

Epoch: 6| Step: 5
Training loss: 1.7470858097076416
Validation loss: 2.149668872356415

Epoch: 6| Step: 6
Training loss: 1.6538808345794678
Validation loss: 2.170719583829244

Epoch: 6| Step: 7
Training loss: 1.4428987503051758
Validation loss: 2.1777302424112954

Epoch: 6| Step: 8
Training loss: 1.1664314270019531
Validation loss: 2.165623446305593

Epoch: 6| Step: 9
Training loss: 1.503092885017395
Validation loss: 2.1753054658571878

Epoch: 6| Step: 10
Training loss: 1.4821287393569946
Validation loss: 2.1648430029551187

Epoch: 6| Step: 11
Training loss: 2.380565643310547
Validation loss: 2.1405927340189614

Epoch: 6| Step: 12
Training loss: 2.0842394828796387
Validation loss: 2.1364338795344033

Epoch: 6| Step: 13
Training loss: 2.097048044204712
Validation loss: 2.1363318959871926

Epoch: 229| Step: 0
Training loss: 1.988031268119812
Validation loss: 2.1402703126271567

Epoch: 6| Step: 1
Training loss: 1.1486756801605225
Validation loss: 2.1185170809427896

Epoch: 6| Step: 2
Training loss: 2.447338342666626
Validation loss: 2.1400319933891296

Epoch: 6| Step: 3
Training loss: 1.8160574436187744
Validation loss: 2.121948778629303

Epoch: 6| Step: 4
Training loss: 1.695776343345642
Validation loss: 2.116138835748037

Epoch: 6| Step: 5
Training loss: 1.9263689517974854
Validation loss: 2.1177260478337607

Epoch: 6| Step: 6
Training loss: 2.499811887741089
Validation loss: 2.1233115990956626

Epoch: 6| Step: 7
Training loss: 1.8939058780670166
Validation loss: 2.120396157105764

Epoch: 6| Step: 8
Training loss: 2.1810574531555176
Validation loss: 2.1156471967697144

Epoch: 6| Step: 9
Training loss: 1.7877099514007568
Validation loss: 2.1219216783841452

Epoch: 6| Step: 10
Training loss: 2.1979165077209473
Validation loss: 2.1159741481145224

Epoch: 6| Step: 11
Training loss: 1.2107789516448975
Validation loss: 2.123055120309194

Epoch: 6| Step: 12
Training loss: 1.2997758388519287
Validation loss: 2.1490556796391806

Epoch: 6| Step: 13
Training loss: 1.282614827156067
Validation loss: 2.1611769994099936

Epoch: 230| Step: 0
Training loss: 1.92912757396698
Validation loss: 2.13486381371816

Epoch: 6| Step: 1
Training loss: 1.5018458366394043
Validation loss: 2.126934826374054

Epoch: 6| Step: 2
Training loss: 1.4860546588897705
Validation loss: 2.135721961657206

Epoch: 6| Step: 3
Training loss: 1.651252031326294
Validation loss: 2.134892245133718

Epoch: 6| Step: 4
Training loss: 1.7391183376312256
Validation loss: 2.11766250928243

Epoch: 6| Step: 5
Training loss: 2.0932445526123047
Validation loss: 2.124117394288381

Epoch: 6| Step: 6
Training loss: 1.7522839307785034
Validation loss: 2.1316341956456504

Epoch: 6| Step: 7
Training loss: 1.558334469795227
Validation loss: 2.120038171609243

Epoch: 6| Step: 8
Training loss: 1.2143301963806152
Validation loss: 2.12739630540212

Epoch: 6| Step: 9
Training loss: 1.8777210712432861
Validation loss: 2.134697159131368

Epoch: 6| Step: 10
Training loss: 2.031104564666748
Validation loss: 2.1429083546002707

Epoch: 6| Step: 11
Training loss: 2.1162965297698975
Validation loss: 2.1689924399058023

Epoch: 6| Step: 12
Training loss: 2.1212306022644043
Validation loss: 2.183726112047831

Epoch: 6| Step: 13
Training loss: 2.654107093811035
Validation loss: 2.194458524386088

Epoch: 231| Step: 0
Training loss: 2.158524513244629
Validation loss: 2.19043231010437

Epoch: 6| Step: 1
Training loss: 2.0165719985961914
Validation loss: 2.191420535246531

Epoch: 6| Step: 2
Training loss: 1.9456089735031128
Validation loss: 2.1983855168024697

Epoch: 6| Step: 3
Training loss: 2.360119581222534
Validation loss: 2.1749669909477234

Epoch: 6| Step: 4
Training loss: 2.202204704284668
Validation loss: 2.1568965315818787

Epoch: 6| Step: 5
Training loss: 1.2117412090301514
Validation loss: 2.149239699045817

Epoch: 6| Step: 6
Training loss: 1.4610060453414917
Validation loss: 2.1408039132754006

Epoch: 6| Step: 7
Training loss: 1.811495065689087
Validation loss: 2.147283057371775

Epoch: 6| Step: 8
Training loss: 1.69648015499115
Validation loss: 2.141345461209615

Epoch: 6| Step: 9
Training loss: 1.424492597579956
Validation loss: 2.134582797686259

Epoch: 6| Step: 10
Training loss: 1.436029076576233
Validation loss: 2.142447908719381

Epoch: 6| Step: 11
Training loss: 2.147216320037842
Validation loss: 2.1283689737319946

Epoch: 6| Step: 12
Training loss: 1.4143949747085571
Validation loss: 2.133219043413798

Epoch: 6| Step: 13
Training loss: 1.965419054031372
Validation loss: 2.1286062002182007

Epoch: 232| Step: 0
Training loss: 1.940504789352417
Validation loss: 2.133071263631185

Epoch: 6| Step: 1
Training loss: 1.9880383014678955
Validation loss: 2.126073161760966

Epoch: 6| Step: 2
Training loss: 1.2074543237686157
Validation loss: 2.1281426747639975

Epoch: 6| Step: 3
Training loss: 2.811089515686035
Validation loss: 2.1321430007616677

Epoch: 6| Step: 4
Training loss: 1.780181884765625
Validation loss: 2.138835867245992

Epoch: 6| Step: 5
Training loss: 0.9942505955696106
Validation loss: 2.1478638450304666

Epoch: 6| Step: 6
Training loss: 1.9690734148025513
Validation loss: 2.152079244454702

Epoch: 6| Step: 7
Training loss: 1.7415332794189453
Validation loss: 2.1489869554837546

Epoch: 6| Step: 8
Training loss: 1.4166514873504639
Validation loss: 2.163731336593628

Epoch: 6| Step: 9
Training loss: 1.486499309539795
Validation loss: 2.1699718236923218

Epoch: 6| Step: 10
Training loss: 1.8567744493484497
Validation loss: 2.176698545614878

Epoch: 6| Step: 11
Training loss: 1.5470280647277832
Validation loss: 2.153271476427714

Epoch: 6| Step: 12
Training loss: 2.033707618713379
Validation loss: 2.1438021461168923

Epoch: 6| Step: 13
Training loss: 1.9960099458694458
Validation loss: 2.1576281785964966

Epoch: 233| Step: 0
Training loss: 1.2206594944000244
Validation loss: 2.1548662980397544

Epoch: 6| Step: 1
Training loss: 2.2065844535827637
Validation loss: 2.1483863989512124

Epoch: 6| Step: 2
Training loss: 1.4306213855743408
Validation loss: 2.155761241912842

Epoch: 6| Step: 3
Training loss: 2.4146015644073486
Validation loss: 2.1411753495534263

Epoch: 6| Step: 4
Training loss: 1.9203155040740967
Validation loss: 2.1402734319368997

Epoch: 6| Step: 5
Training loss: 1.52854323387146
Validation loss: 2.1422558426856995

Epoch: 6| Step: 6
Training loss: 1.474797248840332
Validation loss: 2.139858524004618

Epoch: 6| Step: 7
Training loss: 1.6190197467803955
Validation loss: 2.122901678085327

Epoch: 6| Step: 8
Training loss: 2.2373387813568115
Validation loss: 2.1306995948155723

Epoch: 6| Step: 9
Training loss: 1.763705849647522
Validation loss: 2.112000604470571

Epoch: 6| Step: 10
Training loss: 1.1943285465240479
Validation loss: 2.14200226465861

Epoch: 6| Step: 11
Training loss: 2.3734827041625977
Validation loss: 2.1221388975779214

Epoch: 6| Step: 12
Training loss: 1.6946237087249756
Validation loss: 2.131675640741984

Epoch: 6| Step: 13
Training loss: 1.5684980154037476
Validation loss: 2.162240227063497

Epoch: 234| Step: 0
Training loss: 2.238717555999756
Validation loss: 2.1827313701311746

Epoch: 6| Step: 1
Training loss: 1.6683852672576904
Validation loss: 2.1866827607154846

Epoch: 6| Step: 2
Training loss: 1.2863633632659912
Validation loss: 2.1962417364120483

Epoch: 6| Step: 3
Training loss: 2.3005027770996094
Validation loss: 2.1987707813580832

Epoch: 6| Step: 4
Training loss: 1.5956900119781494
Validation loss: 2.199418822924296

Epoch: 6| Step: 5
Training loss: 1.546262502670288
Validation loss: 2.189106265703837

Epoch: 6| Step: 6
Training loss: 2.0389957427978516
Validation loss: 2.1680641372998557

Epoch: 6| Step: 7
Training loss: 1.2348146438598633
Validation loss: 2.1580740412076316

Epoch: 6| Step: 8
Training loss: 2.412059783935547
Validation loss: 2.1371242801348367

Epoch: 6| Step: 9
Training loss: 1.1568232774734497
Validation loss: 2.141376237074534

Epoch: 6| Step: 10
Training loss: 2.1960067749023438
Validation loss: 2.1203149954477944

Epoch: 6| Step: 11
Training loss: 2.083730936050415
Validation loss: 2.131289760271708

Epoch: 6| Step: 12
Training loss: 2.2304649353027344
Validation loss: 2.120124598344167

Epoch: 6| Step: 13
Training loss: 1.271425485610962
Validation loss: 2.1230634649594626

Epoch: 235| Step: 0
Training loss: 1.6414132118225098
Validation loss: 2.1345306038856506

Epoch: 6| Step: 1
Training loss: 1.2377513647079468
Validation loss: 2.118496855099996

Epoch: 6| Step: 2
Training loss: 1.8953136205673218
Validation loss: 2.1459964513778687

Epoch: 6| Step: 3
Training loss: 1.9140307903289795
Validation loss: 2.150495092074076

Epoch: 6| Step: 4
Training loss: 1.9712159633636475
Validation loss: 2.1483319203058877

Epoch: 6| Step: 5
Training loss: 1.4287710189819336
Validation loss: 2.1697959105173745

Epoch: 6| Step: 6
Training loss: 1.9069920778274536
Validation loss: 2.1663341323534646

Epoch: 6| Step: 7
Training loss: 2.4050962924957275
Validation loss: 2.173722743988037

Epoch: 6| Step: 8
Training loss: 2.535475492477417
Validation loss: 2.1669245759646096

Epoch: 6| Step: 9
Training loss: 1.5059590339660645
Validation loss: 2.16185861825943

Epoch: 6| Step: 10
Training loss: 1.6136951446533203
Validation loss: 2.170687715212504

Epoch: 6| Step: 11
Training loss: 1.6504813432693481
Validation loss: 2.162770132223765

Epoch: 6| Step: 12
Training loss: 1.990220069885254
Validation loss: 2.1373906334241233

Epoch: 6| Step: 13
Training loss: 2.3186757564544678
Validation loss: 2.1274377703666687

Epoch: 236| Step: 0
Training loss: 2.3496646881103516
Validation loss: 2.123463789621989

Epoch: 6| Step: 1
Training loss: 1.8622503280639648
Validation loss: 2.13527504603068

Epoch: 6| Step: 2
Training loss: 2.7579545974731445
Validation loss: 2.114109973112742

Epoch: 6| Step: 3
Training loss: 1.511702537536621
Validation loss: 2.110086361567179

Epoch: 6| Step: 4
Training loss: 1.9310839176177979
Validation loss: 2.110982914765676

Epoch: 6| Step: 5
Training loss: 1.7203874588012695
Validation loss: 2.1147279342015586

Epoch: 6| Step: 6
Training loss: 2.105189323425293
Validation loss: 2.1158030033111572

Epoch: 6| Step: 7
Training loss: 1.7376163005828857
Validation loss: 2.1123532255490622

Epoch: 6| Step: 8
Training loss: 2.4968295097351074
Validation loss: 2.129395087560018

Epoch: 6| Step: 9
Training loss: 1.1113299131393433
Validation loss: 2.141167938709259

Epoch: 6| Step: 10
Training loss: 1.5632355213165283
Validation loss: 2.1545013189315796

Epoch: 6| Step: 11
Training loss: 1.5485395193099976
Validation loss: 2.1704440315564475

Epoch: 6| Step: 12
Training loss: 1.633886456489563
Validation loss: 2.172744115193685

Epoch: 6| Step: 13
Training loss: 1.8192839622497559
Validation loss: 2.168229858080546

Epoch: 237| Step: 0
Training loss: 1.3095307350158691
Validation loss: 2.1769972443580627

Epoch: 6| Step: 1
Training loss: 1.7628931999206543
Validation loss: 2.1695011854171753

Epoch: 6| Step: 2
Training loss: 2.205385208129883
Validation loss: 2.153262515862783

Epoch: 6| Step: 3
Training loss: 1.3783538341522217
Validation loss: 2.136473079522451

Epoch: 6| Step: 4
Training loss: 1.587449073791504
Validation loss: 2.134316325187683

Epoch: 6| Step: 5
Training loss: 2.093167304992676
Validation loss: 2.1027398904164634

Epoch: 6| Step: 6
Training loss: 1.7576063871383667
Validation loss: 2.136009434858958

Epoch: 6| Step: 7
Training loss: 2.2493739128112793
Validation loss: 2.126056492328644

Epoch: 6| Step: 8
Training loss: 1.965911865234375
Validation loss: 2.1292172273000083

Epoch: 6| Step: 9
Training loss: 2.073669910430908
Validation loss: 2.1311593453089395

Epoch: 6| Step: 10
Training loss: 1.6180212497711182
Validation loss: 2.116325835386912

Epoch: 6| Step: 11
Training loss: 1.8990453481674194
Validation loss: 2.132539470990499

Epoch: 6| Step: 12
Training loss: 1.4042502641677856
Validation loss: 2.1210559805234275

Epoch: 6| Step: 13
Training loss: 1.5643987655639648
Validation loss: 2.1374476552009583

Epoch: 238| Step: 0
Training loss: 1.462928295135498
Validation loss: 2.1383229692777

Epoch: 6| Step: 1
Training loss: 2.177649736404419
Validation loss: 2.1516389648119607

Epoch: 6| Step: 2
Training loss: 2.118950843811035
Validation loss: 2.1599148511886597

Epoch: 6| Step: 3
Training loss: 2.061514377593994
Validation loss: 2.1772387822469077

Epoch: 6| Step: 4
Training loss: 1.4600021839141846
Validation loss: 2.1885115702946982

Epoch: 6| Step: 5
Training loss: 1.8596105575561523
Validation loss: 2.1617929538091025

Epoch: 6| Step: 6
Training loss: 1.925581693649292
Validation loss: 2.143953561782837

Epoch: 6| Step: 7
Training loss: 1.622600793838501
Validation loss: 2.1530732115109763

Epoch: 6| Step: 8
Training loss: 1.2503695487976074
Validation loss: 2.1532244086265564

Epoch: 6| Step: 9
Training loss: 1.3512966632843018
Validation loss: 2.1341437300046286

Epoch: 6| Step: 10
Training loss: 1.7757835388183594
Validation loss: 2.1374885042508445

Epoch: 6| Step: 11
Training loss: 1.2526516914367676
Validation loss: 2.1381575067838035

Epoch: 6| Step: 12
Training loss: 2.249588966369629
Validation loss: 2.140315850575765

Epoch: 6| Step: 13
Training loss: 2.289240837097168
Validation loss: 2.11719540754954

Epoch: 239| Step: 0
Training loss: 1.6917481422424316
Validation loss: 2.127618193626404

Epoch: 6| Step: 1
Training loss: 1.9884092807769775
Validation loss: 2.1482192079226174

Epoch: 6| Step: 2
Training loss: 1.708413004875183
Validation loss: 2.1186356941858926

Epoch: 6| Step: 3
Training loss: 1.7091262340545654
Validation loss: 2.133689045906067

Epoch: 6| Step: 4
Training loss: 1.3627383708953857
Validation loss: 2.1322732170422873

Epoch: 6| Step: 5
Training loss: 2.133091688156128
Validation loss: 2.1738878885904946

Epoch: 6| Step: 6
Training loss: 1.285674810409546
Validation loss: 2.154807170232137

Epoch: 6| Step: 7
Training loss: 1.4168777465820312
Validation loss: 2.1687236626942954

Epoch: 6| Step: 8
Training loss: 1.6785354614257812
Validation loss: 2.168629805246989

Epoch: 6| Step: 9
Training loss: 1.8264861106872559
Validation loss: 2.1853744784990945

Epoch: 6| Step: 10
Training loss: 1.2995314598083496
Validation loss: 2.2078451116879783

Epoch: 6| Step: 11
Training loss: 2.7026207447052
Validation loss: 2.1713216503461203

Epoch: 6| Step: 12
Training loss: 1.644230842590332
Validation loss: 2.1684135794639587

Epoch: 6| Step: 13
Training loss: 1.9046159982681274
Validation loss: 2.167005638281504

Epoch: 240| Step: 0
Training loss: 2.031160831451416
Validation loss: 2.1711814204851785

Epoch: 6| Step: 1
Training loss: 1.4236844778060913
Validation loss: 2.1396143039067588

Epoch: 6| Step: 2
Training loss: 1.1485905647277832
Validation loss: 2.1542900005976358

Epoch: 6| Step: 3
Training loss: 1.7419030666351318
Validation loss: 2.1555685997009277

Epoch: 6| Step: 4
Training loss: 2.1969051361083984
Validation loss: 2.1395197113355002

Epoch: 6| Step: 5
Training loss: 1.2481913566589355
Validation loss: 2.142935554186503

Epoch: 6| Step: 6
Training loss: 1.7383307218551636
Validation loss: 2.15212349096934

Epoch: 6| Step: 7
Training loss: 1.7527257204055786
Validation loss: 2.1546486814816794

Epoch: 6| Step: 8
Training loss: 2.7176671028137207
Validation loss: 2.163078228632609

Epoch: 6| Step: 9
Training loss: 1.107852578163147
Validation loss: 2.1752501726150513

Epoch: 6| Step: 10
Training loss: 1.5766253471374512
Validation loss: 2.146319250265757

Epoch: 6| Step: 11
Training loss: 1.9381234645843506
Validation loss: 2.1885550022125244

Epoch: 6| Step: 12
Training loss: 2.350459098815918
Validation loss: 2.182847539583842

Epoch: 6| Step: 13
Training loss: 1.5877641439437866
Validation loss: 2.1695169607798257

Epoch: 241| Step: 0
Training loss: 1.4695905447006226
Validation loss: 2.1831435163815818

Epoch: 6| Step: 1
Training loss: 2.1563737392425537
Validation loss: 2.1652817726135254

Epoch: 6| Step: 2
Training loss: 1.143221139907837
Validation loss: 2.1585614879926047

Epoch: 6| Step: 3
Training loss: 1.880576252937317
Validation loss: 2.1697251001993814

Epoch: 6| Step: 4
Training loss: 1.1737713813781738
Validation loss: 2.1763081351915994

Epoch: 6| Step: 5
Training loss: 1.482433557510376
Validation loss: 2.175421138604482

Epoch: 6| Step: 6
Training loss: 0.9935142397880554
Validation loss: 2.159080525239309

Epoch: 6| Step: 7
Training loss: 1.9694149494171143
Validation loss: 2.168719251950582

Epoch: 6| Step: 8
Training loss: 2.0940358638763428
Validation loss: 2.1563645601272583

Epoch: 6| Step: 9
Training loss: 1.8959112167358398
Validation loss: 2.1370510260264077

Epoch: 6| Step: 10
Training loss: 1.843923807144165
Validation loss: 2.139838476975759

Epoch: 6| Step: 11
Training loss: 2.1671342849731445
Validation loss: 2.1489357550938926

Epoch: 6| Step: 12
Training loss: 1.9638161659240723
Validation loss: 2.18563578526179

Epoch: 6| Step: 13
Training loss: 2.202390670776367
Validation loss: 2.1704261302948

Epoch: 242| Step: 0
Training loss: 1.2196433544158936
Validation loss: 2.1643354892730713

Epoch: 6| Step: 1
Training loss: 1.181424856185913
Validation loss: 2.146128992239634

Epoch: 6| Step: 2
Training loss: 0.9508913159370422
Validation loss: 2.1618038415908813

Epoch: 6| Step: 3
Training loss: 2.2971444129943848
Validation loss: 2.1667199532190957

Epoch: 6| Step: 4
Training loss: 2.4604451656341553
Validation loss: 2.16245299577713

Epoch: 6| Step: 5
Training loss: 1.0419209003448486
Validation loss: 2.148744602998098

Epoch: 6| Step: 6
Training loss: 1.899851679801941
Validation loss: 2.1607077519098916

Epoch: 6| Step: 7
Training loss: 2.623650074005127
Validation loss: 2.180836796760559

Epoch: 6| Step: 8
Training loss: 2.043990135192871
Validation loss: 2.172212521235148

Epoch: 6| Step: 9
Training loss: 1.519768238067627
Validation loss: 2.1674711505572

Epoch: 6| Step: 10
Training loss: 1.5492262840270996
Validation loss: 2.1721460223197937

Epoch: 6| Step: 11
Training loss: 1.8190524578094482
Validation loss: 2.184408485889435

Epoch: 6| Step: 12
Training loss: 1.7715058326721191
Validation loss: 2.1629838148752847

Epoch: 6| Step: 13
Training loss: 1.697202444076538
Validation loss: 2.1614831686019897

Epoch: 243| Step: 0
Training loss: 2.05812406539917
Validation loss: 2.160538593928019

Epoch: 6| Step: 1
Training loss: 2.196967124938965
Validation loss: 2.1577686866124473

Epoch: 6| Step: 2
Training loss: 2.021231174468994
Validation loss: 2.144903600215912

Epoch: 6| Step: 3
Training loss: 1.660253643989563
Validation loss: 2.146769563357035

Epoch: 6| Step: 4
Training loss: 1.7164595127105713
Validation loss: 2.1217614014943442

Epoch: 6| Step: 5
Training loss: 1.8449450731277466
Validation loss: 2.1366740266482034

Epoch: 6| Step: 6
Training loss: 1.4893251657485962
Validation loss: 2.1439552108446756

Epoch: 6| Step: 7
Training loss: 1.3924717903137207
Validation loss: 2.1428448955217996

Epoch: 6| Step: 8
Training loss: 1.111965537071228
Validation loss: 2.1632498502731323

Epoch: 6| Step: 9
Training loss: 0.9833154082298279
Validation loss: 2.1825180053710938

Epoch: 6| Step: 10
Training loss: 2.2754619121551514
Validation loss: 2.1708279053370156

Epoch: 6| Step: 11
Training loss: 1.7781684398651123
Validation loss: 2.1632871627807617

Epoch: 6| Step: 12
Training loss: 1.6713035106658936
Validation loss: 2.1911672155062356

Epoch: 6| Step: 13
Training loss: 2.125129222869873
Validation loss: 2.176737368106842

Epoch: 244| Step: 0
Training loss: 2.176380157470703
Validation loss: 2.183156748612722

Epoch: 6| Step: 1
Training loss: 1.9435302019119263
Validation loss: 2.170617938041687

Epoch: 6| Step: 2
Training loss: 1.7924821376800537
Validation loss: 2.148366371790568

Epoch: 6| Step: 3
Training loss: 1.728501319885254
Validation loss: 2.1469813783963523

Epoch: 6| Step: 4
Training loss: 1.801260232925415
Validation loss: 2.1213796933492026

Epoch: 6| Step: 5
Training loss: 1.3709044456481934
Validation loss: 2.1279499332110086

Epoch: 6| Step: 6
Training loss: 1.4464797973632812
Validation loss: 2.1494267185529075

Epoch: 6| Step: 7
Training loss: 1.8926360607147217
Validation loss: 2.1344594160715737

Epoch: 6| Step: 8
Training loss: 2.2792344093322754
Validation loss: 2.127156595389048

Epoch: 6| Step: 9
Training loss: 1.2030432224273682
Validation loss: 2.124576131502787

Epoch: 6| Step: 10
Training loss: 1.8123810291290283
Validation loss: 2.1290201544761658

Epoch: 6| Step: 11
Training loss: 1.3571630716323853
Validation loss: 2.1332985957463584

Epoch: 6| Step: 12
Training loss: 1.9133126735687256
Validation loss: 2.1605925957361856

Epoch: 6| Step: 13
Training loss: 1.427678108215332
Validation loss: 2.1796966989835105

Epoch: 245| Step: 0
Training loss: 1.7930967807769775
Validation loss: 2.1323841412862143

Epoch: 6| Step: 1
Training loss: 1.7157337665557861
Validation loss: 2.170476794242859

Epoch: 6| Step: 2
Training loss: 1.4123179912567139
Validation loss: 2.1551338831583657

Epoch: 6| Step: 3
Training loss: 1.7411925792694092
Validation loss: 2.149566868940989

Epoch: 6| Step: 4
Training loss: 1.4673404693603516
Validation loss: 2.1457869609196982

Epoch: 6| Step: 5
Training loss: 2.0958871841430664
Validation loss: 2.1582910617192588

Epoch: 6| Step: 6
Training loss: 2.103367805480957
Validation loss: 2.14212828874588

Epoch: 6| Step: 7
Training loss: 1.2520023584365845
Validation loss: 2.1438909769058228

Epoch: 6| Step: 8
Training loss: 1.2636054754257202
Validation loss: 2.154044051965078

Epoch: 6| Step: 9
Training loss: 1.973055124282837
Validation loss: 2.138737738132477

Epoch: 6| Step: 10
Training loss: 2.563370943069458
Validation loss: 2.1353121995925903

Epoch: 6| Step: 11
Training loss: 2.0138418674468994
Validation loss: 2.1454474528630576

Epoch: 6| Step: 12
Training loss: 1.7491729259490967
Validation loss: 2.172924002011617

Epoch: 6| Step: 13
Training loss: 1.4552195072174072
Validation loss: 2.1632519563039145

Epoch: 246| Step: 0
Training loss: 1.3554284572601318
Validation loss: 2.167066733042399

Epoch: 6| Step: 1
Training loss: 1.339888572692871
Validation loss: 2.1932239929835

Epoch: 6| Step: 2
Training loss: 1.8030364513397217
Validation loss: 2.1944679816563926

Epoch: 6| Step: 3
Training loss: 1.1193841695785522
Validation loss: 2.1910121043523154

Epoch: 6| Step: 4
Training loss: 1.6176741123199463
Validation loss: 2.1892685890197754

Epoch: 6| Step: 5
Training loss: 1.7362724542617798
Validation loss: 2.1751546065012612

Epoch: 6| Step: 6
Training loss: 1.188860297203064
Validation loss: 2.1668681502342224

Epoch: 6| Step: 7
Training loss: 1.9588276147842407
Validation loss: 2.1842164993286133

Epoch: 6| Step: 8
Training loss: 1.7983626127243042
Validation loss: 2.1456549962361655

Epoch: 6| Step: 9
Training loss: 2.45615816116333
Validation loss: 2.1684011816978455

Epoch: 6| Step: 10
Training loss: 2.072779655456543
Validation loss: 2.1513912280400596

Epoch: 6| Step: 11
Training loss: 2.485684633255005
Validation loss: 2.1608460744222007

Epoch: 6| Step: 12
Training loss: 1.7052475214004517
Validation loss: 2.1385379632314048

Epoch: 6| Step: 13
Training loss: 1.8149726390838623
Validation loss: 2.148916323979696

Epoch: 247| Step: 0
Training loss: 2.5952398777008057
Validation loss: 2.151694436868032

Epoch: 6| Step: 1
Training loss: 1.4867844581604004
Validation loss: 2.1637627681096396

Epoch: 6| Step: 2
Training loss: 2.4180212020874023
Validation loss: 2.1735525329907737

Epoch: 6| Step: 3
Training loss: 1.4745407104492188
Validation loss: 2.1495726704597473

Epoch: 6| Step: 4
Training loss: 1.297405481338501
Validation loss: 2.186967750390371

Epoch: 6| Step: 5
Training loss: 1.5750813484191895
Validation loss: 2.1770806312561035

Epoch: 6| Step: 6
Training loss: 2.1464595794677734
Validation loss: 2.1715247432390847

Epoch: 6| Step: 7
Training loss: 1.7991381883621216
Validation loss: 2.165932019551595

Epoch: 6| Step: 8
Training loss: 1.7556531429290771
Validation loss: 2.184449553489685

Epoch: 6| Step: 9
Training loss: 1.7764363288879395
Validation loss: 2.178083598613739

Epoch: 6| Step: 10
Training loss: 1.9274334907531738
Validation loss: 2.145062784353892

Epoch: 6| Step: 11
Training loss: 1.551751971244812
Validation loss: 2.166201094786326

Epoch: 6| Step: 12
Training loss: 1.4044703245162964
Validation loss: 2.1532050172487893

Epoch: 6| Step: 13
Training loss: 1.3002487421035767
Validation loss: 2.1593222618103027

Epoch: 248| Step: 0
Training loss: 2.0607528686523438
Validation loss: 2.1542237401008606

Epoch: 6| Step: 1
Training loss: 2.368525505065918
Validation loss: 2.1415438254674277

Epoch: 6| Step: 2
Training loss: 1.3886020183563232
Validation loss: 2.1063932180404663

Epoch: 6| Step: 3
Training loss: 1.423470377922058
Validation loss: 2.125521461168925

Epoch: 6| Step: 4
Training loss: 1.7569947242736816
Validation loss: 2.146313786506653

Epoch: 6| Step: 5
Training loss: 2.16990327835083
Validation loss: 2.154221296310425

Epoch: 6| Step: 6
Training loss: 1.5202555656433105
Validation loss: 2.1677979826927185

Epoch: 6| Step: 7
Training loss: 1.5310407876968384
Validation loss: 2.117646872997284

Epoch: 6| Step: 8
Training loss: 1.9429723024368286
Validation loss: 2.098762353261312

Epoch: 6| Step: 9
Training loss: 1.276743769645691
Validation loss: 2.1192439993222556

Epoch: 6| Step: 10
Training loss: 1.6454566717147827
Validation loss: 2.109482487042745

Epoch: 6| Step: 11
Training loss: 1.52793288230896
Validation loss: 2.11948961019516

Epoch: 6| Step: 12
Training loss: 2.168623685836792
Validation loss: 2.0972864627838135

Epoch: 6| Step: 13
Training loss: 2.040996789932251
Validation loss: 2.1061464150746665

Epoch: 249| Step: 0
Training loss: 2.0261311531066895
Validation loss: 2.092622935771942

Epoch: 6| Step: 1
Training loss: 1.6267375946044922
Validation loss: 2.112563411394755

Epoch: 6| Step: 2
Training loss: 2.3059492111206055
Validation loss: 2.1155295968055725

Epoch: 6| Step: 3
Training loss: 1.5651445388793945
Validation loss: 2.1267179250717163

Epoch: 6| Step: 4
Training loss: 2.17997670173645
Validation loss: 2.1372812191645303

Epoch: 6| Step: 5
Training loss: 1.7766025066375732
Validation loss: 2.135154942671458

Epoch: 6| Step: 6
Training loss: 2.1441447734832764
Validation loss: 2.1434466441472373

Epoch: 6| Step: 7
Training loss: 1.4300800561904907
Validation loss: 2.1527943213780723

Epoch: 6| Step: 8
Training loss: 1.563064694404602
Validation loss: 2.1469496488571167

Epoch: 6| Step: 9
Training loss: 1.2223072052001953
Validation loss: 2.152814269065857

Epoch: 6| Step: 10
Training loss: 1.4186503887176514
Validation loss: 2.1698016921679177

Epoch: 6| Step: 11
Training loss: 1.3477262258529663
Validation loss: 2.14556884765625

Epoch: 6| Step: 12
Training loss: 1.7600938081741333
Validation loss: 2.165495216846466

Epoch: 6| Step: 13
Training loss: 1.4141037464141846
Validation loss: 2.1551015774408975

Epoch: 250| Step: 0
Training loss: 1.7291584014892578
Validation loss: 2.150961617628733

Epoch: 6| Step: 1
Training loss: 1.4059947729110718
Validation loss: 2.1325385769208274

Epoch: 6| Step: 2
Training loss: 1.8570420742034912
Validation loss: 2.1501656969388327

Epoch: 6| Step: 3
Training loss: 1.8058347702026367
Validation loss: 2.1660043199857077

Epoch: 6| Step: 4
Training loss: 2.6197149753570557
Validation loss: 2.1599496603012085

Epoch: 6| Step: 5
Training loss: 1.571859359741211
Validation loss: 2.1420873204867044

Epoch: 6| Step: 6
Training loss: 1.6019316911697388
Validation loss: 2.1560951471328735

Epoch: 6| Step: 7
Training loss: 2.171302318572998
Validation loss: 2.1877963145573935

Epoch: 6| Step: 8
Training loss: 1.736525535583496
Validation loss: 2.207202156384786

Epoch: 6| Step: 9
Training loss: 1.2979804277420044
Validation loss: 2.2068421244621277

Epoch: 6| Step: 10
Training loss: 1.4745182991027832
Validation loss: 2.1962941884994507

Epoch: 6| Step: 11
Training loss: 1.9886283874511719
Validation loss: 2.205405592918396

Epoch: 6| Step: 12
Training loss: 1.3701958656311035
Validation loss: 2.157831152280172

Epoch: 6| Step: 13
Training loss: 1.7484235763549805
Validation loss: 2.1654165585835776

Epoch: 251| Step: 0
Training loss: 2.7437222003936768
Validation loss: 2.1635801593462625

Epoch: 6| Step: 1
Training loss: 1.6731736660003662
Validation loss: 2.1545090277989707

Epoch: 6| Step: 2
Training loss: 1.7307987213134766
Validation loss: 2.139382282892863

Epoch: 6| Step: 3
Training loss: 1.2646605968475342
Validation loss: 2.1450326244036355

Epoch: 6| Step: 4
Training loss: 1.1407843828201294
Validation loss: 2.1137280265490213

Epoch: 6| Step: 5
Training loss: 1.4740190505981445
Validation loss: 2.11015651623408

Epoch: 6| Step: 6
Training loss: 1.8317179679870605
Validation loss: 2.1187607645988464

Epoch: 6| Step: 7
Training loss: 2.0849099159240723
Validation loss: 2.099475880463918

Epoch: 6| Step: 8
Training loss: 1.479591965675354
Validation loss: 2.1119231383005777

Epoch: 6| Step: 9
Training loss: 2.111245632171631
Validation loss: 2.1067283948262534

Epoch: 6| Step: 10
Training loss: 1.8605810403823853
Validation loss: 2.1191810170809426

Epoch: 6| Step: 11
Training loss: 1.6802634000778198
Validation loss: 2.113406757513682

Epoch: 6| Step: 12
Training loss: 1.5832228660583496
Validation loss: 2.1377151211102805

Epoch: 6| Step: 13
Training loss: 1.7275718450546265
Validation loss: 2.1468635400136313

Epoch: 252| Step: 0
Training loss: 1.9562686681747437
Validation loss: 2.1611903508504233

Epoch: 6| Step: 1
Training loss: 1.530362606048584
Validation loss: 2.1368703643480935

Epoch: 6| Step: 2
Training loss: 1.8913843631744385
Validation loss: 2.1786614855130515

Epoch: 6| Step: 3
Training loss: 1.7315115928649902
Validation loss: 2.1618356108665466

Epoch: 6| Step: 4
Training loss: 1.8668928146362305
Validation loss: 2.1649903655052185

Epoch: 6| Step: 5
Training loss: 2.0913281440734863
Validation loss: 2.152376135190328

Epoch: 6| Step: 6
Training loss: 2.340038299560547
Validation loss: 2.1461403568585715

Epoch: 6| Step: 7
Training loss: 1.3415924310684204
Validation loss: 2.1238830288251243

Epoch: 6| Step: 8
Training loss: 1.7997779846191406
Validation loss: 2.127182205518087

Epoch: 6| Step: 9
Training loss: 2.361755609512329
Validation loss: 2.123636523882548

Epoch: 6| Step: 10
Training loss: 1.6322537660598755
Validation loss: 2.134978989760081

Epoch: 6| Step: 11
Training loss: 1.9857231378555298
Validation loss: 2.1201826135317483

Epoch: 6| Step: 12
Training loss: 1.5224450826644897
Validation loss: 2.112778921922048

Epoch: 6| Step: 13
Training loss: 1.4422179460525513
Validation loss: 2.131669064362844

Epoch: 253| Step: 0
Training loss: 1.4256094694137573
Validation loss: 2.109898010889689

Epoch: 6| Step: 1
Training loss: 1.9488940238952637
Validation loss: 2.095151404539744

Epoch: 6| Step: 2
Training loss: 1.8743528127670288
Validation loss: 2.1146217385927835

Epoch: 6| Step: 3
Training loss: 1.4701122045516968
Validation loss: 2.0920111536979675

Epoch: 6| Step: 4
Training loss: 1.8088746070861816
Validation loss: 2.116528888543447

Epoch: 6| Step: 5
Training loss: 2.0595695972442627
Validation loss: 2.1591954231262207

Epoch: 6| Step: 6
Training loss: 1.9531981945037842
Validation loss: 2.1478482484817505

Epoch: 6| Step: 7
Training loss: 2.0602753162384033
Validation loss: 2.149674673875173

Epoch: 6| Step: 8
Training loss: 1.294582724571228
Validation loss: 2.155129611492157

Epoch: 6| Step: 9
Training loss: 2.2141852378845215
Validation loss: 2.1560858885447183

Epoch: 6| Step: 10
Training loss: 1.7604928016662598
Validation loss: 2.1467148264249167

Epoch: 6| Step: 11
Training loss: 1.5096678733825684
Validation loss: 2.1363611618677774

Epoch: 6| Step: 12
Training loss: 2.1319260597229004
Validation loss: 2.143144905567169

Epoch: 6| Step: 13
Training loss: 2.11195707321167
Validation loss: 2.149041493733724

Epoch: 254| Step: 0
Training loss: 1.4708269834518433
Validation loss: 2.1418442726135254

Epoch: 6| Step: 1
Training loss: 0.9620131850242615
Validation loss: 2.1498261292775473

Epoch: 6| Step: 2
Training loss: 2.2794721126556396
Validation loss: 2.1326906283696494

Epoch: 6| Step: 3
Training loss: 2.635051727294922
Validation loss: 2.1400166153907776

Epoch: 6| Step: 4
Training loss: 1.617843747138977
Validation loss: 2.130225578943888

Epoch: 6| Step: 5
Training loss: 1.6339919567108154
Validation loss: 2.1326047579447427

Epoch: 6| Step: 6
Training loss: 1.0631897449493408
Validation loss: 2.1225672165552774

Epoch: 6| Step: 7
Training loss: 2.1232240200042725
Validation loss: 2.137983739376068

Epoch: 6| Step: 8
Training loss: 1.7771738767623901
Validation loss: 2.130614221096039

Epoch: 6| Step: 9
Training loss: 1.930143117904663
Validation loss: 2.1267839868863425

Epoch: 6| Step: 10
Training loss: 1.6881794929504395
Validation loss: 2.1328143080075583

Epoch: 6| Step: 11
Training loss: 1.78373122215271
Validation loss: 2.1392114559809365

Epoch: 6| Step: 12
Training loss: 1.825821876525879
Validation loss: 2.1385372479756675

Epoch: 6| Step: 13
Training loss: 1.2013932466506958
Validation loss: 2.1748190919558206

Epoch: 255| Step: 0
Training loss: 1.7952834367752075
Validation loss: 2.1357057690620422

Epoch: 6| Step: 1
Training loss: 1.5922815799713135
Validation loss: 2.147627830505371

Epoch: 6| Step: 2
Training loss: 1.4640779495239258
Validation loss: 2.1637848218282065

Epoch: 6| Step: 3
Training loss: 1.8456785678863525
Validation loss: 2.15516996383667

Epoch: 6| Step: 4
Training loss: 2.1051058769226074
Validation loss: 2.1461973786354065

Epoch: 6| Step: 5
Training loss: 2.220876693725586
Validation loss: 2.1496792236963906

Epoch: 6| Step: 6
Training loss: 2.492537498474121
Validation loss: 2.1585663159688315

Epoch: 6| Step: 7
Training loss: 1.252181887626648
Validation loss: 2.1333940625190735

Epoch: 6| Step: 8
Training loss: 1.0860328674316406
Validation loss: 2.136675933996836

Epoch: 6| Step: 9
Training loss: 1.4918429851531982
Validation loss: 2.13489963610967

Epoch: 6| Step: 10
Training loss: 1.6977254152297974
Validation loss: 2.146474043528239

Epoch: 6| Step: 11
Training loss: 1.2466418743133545
Validation loss: 2.1392255624135337

Epoch: 6| Step: 12
Training loss: 1.927225112915039
Validation loss: 2.1498565475145974

Epoch: 6| Step: 13
Training loss: 1.469129204750061
Validation loss: 2.1459354162216187

Epoch: 256| Step: 0
Training loss: 0.9817662239074707
Validation loss: 2.1459463437398276

Epoch: 6| Step: 1
Training loss: 1.3595556020736694
Validation loss: 2.1392771204312644

Epoch: 6| Step: 2
Training loss: 1.5881154537200928
Validation loss: 2.1672724882761636

Epoch: 6| Step: 3
Training loss: 1.6067228317260742
Validation loss: 2.1801971793174744

Epoch: 6| Step: 4
Training loss: 2.429656505584717
Validation loss: 2.173303544521332

Epoch: 6| Step: 5
Training loss: 2.1179800033569336
Validation loss: 2.1682674884796143

Epoch: 6| Step: 6
Training loss: 1.7692431211471558
Validation loss: 2.166169842084249

Epoch: 6| Step: 7
Training loss: 2.0477428436279297
Validation loss: 2.1431801319122314

Epoch: 6| Step: 8
Training loss: 2.3916401863098145
Validation loss: 2.145412007967631

Epoch: 6| Step: 9
Training loss: 1.4490867853164673
Validation loss: 2.152924636999766

Epoch: 6| Step: 10
Training loss: 1.4012033939361572
Validation loss: 2.1620284716288247

Epoch: 6| Step: 11
Training loss: 1.2548309564590454
Validation loss: 2.165237625439962

Epoch: 6| Step: 12
Training loss: 1.8584487438201904
Validation loss: 2.1604051987330117

Epoch: 6| Step: 13
Training loss: 1.353536605834961
Validation loss: 2.170573075612386

Epoch: 257| Step: 0
Training loss: 2.313863515853882
Validation loss: 2.1740622520446777

Epoch: 6| Step: 1
Training loss: 1.540069580078125
Validation loss: 2.159749686717987

Epoch: 6| Step: 2
Training loss: 1.7205721139907837
Validation loss: 2.1586217880249023

Epoch: 6| Step: 3
Training loss: 2.0060880184173584
Validation loss: 2.171000917752584

Epoch: 6| Step: 4
Training loss: 1.645845890045166
Validation loss: 2.1540202299753823

Epoch: 6| Step: 5
Training loss: 1.6170066595077515
Validation loss: 2.180840492248535

Epoch: 6| Step: 6
Training loss: 0.9170300364494324
Validation loss: 2.167826294898987

Epoch: 6| Step: 7
Training loss: 1.656290054321289
Validation loss: 2.171791911125183

Epoch: 6| Step: 8
Training loss: 1.593519926071167
Validation loss: 2.1443199117978415

Epoch: 6| Step: 9
Training loss: 1.5411553382873535
Validation loss: 2.1431193947792053

Epoch: 6| Step: 10
Training loss: 1.3224244117736816
Validation loss: 2.143235425154368

Epoch: 6| Step: 11
Training loss: 1.265341877937317
Validation loss: 2.1572539607683816

Epoch: 6| Step: 12
Training loss: 2.3774361610412598
Validation loss: 2.1451088587443032

Epoch: 6| Step: 13
Training loss: 1.9509960412979126
Validation loss: 2.1396342118581138

Epoch: 258| Step: 0
Training loss: 1.270695447921753
Validation loss: 2.122116963068644

Epoch: 6| Step: 1
Training loss: 1.753800868988037
Validation loss: 2.1253443161646524

Epoch: 6| Step: 2
Training loss: 2.046544313430786
Validation loss: 2.1313674052556357

Epoch: 6| Step: 3
Training loss: 0.9178036451339722
Validation loss: 2.1558751463890076

Epoch: 6| Step: 4
Training loss: 1.6902668476104736
Validation loss: 2.1709226767222085

Epoch: 6| Step: 5
Training loss: 2.3348474502563477
Validation loss: 2.1768822272618613

Epoch: 6| Step: 6
Training loss: 1.9147306680679321
Validation loss: 2.176777164141337

Epoch: 6| Step: 7
Training loss: 1.8186936378479004
Validation loss: 2.1545666058858237

Epoch: 6| Step: 8
Training loss: 1.7840123176574707
Validation loss: 2.168377161026001

Epoch: 6| Step: 9
Training loss: 1.354838490486145
Validation loss: 2.1586903731028237

Epoch: 6| Step: 10
Training loss: 1.719486117362976
Validation loss: 2.1389033595720925

Epoch: 6| Step: 11
Training loss: 2.0760550498962402
Validation loss: 2.1009318033854165

Epoch: 6| Step: 12
Training loss: 2.2282681465148926
Validation loss: 2.120664417743683

Epoch: 6| Step: 13
Training loss: 1.1895540952682495
Validation loss: 2.1324044267336526

Epoch: 259| Step: 0
Training loss: 1.279238224029541
Validation loss: 2.136822998523712

Epoch: 6| Step: 1
Training loss: 1.7940982580184937
Validation loss: 2.149437745412191

Epoch: 6| Step: 2
Training loss: 1.6371077299118042
Validation loss: 2.137562910715739

Epoch: 6| Step: 3
Training loss: 1.703172206878662
Validation loss: 2.1363075176874795

Epoch: 6| Step: 4
Training loss: 1.839667797088623
Validation loss: 2.1395283540089927

Epoch: 6| Step: 5
Training loss: 2.1320576667785645
Validation loss: 2.125540792942047

Epoch: 6| Step: 6
Training loss: 1.9471086263656616
Validation loss: 2.127326250076294

Epoch: 6| Step: 7
Training loss: 1.9442163705825806
Validation loss: 2.141853411992391

Epoch: 6| Step: 8
Training loss: 1.9936244487762451
Validation loss: 2.138400753339132

Epoch: 6| Step: 9
Training loss: 1.6504346132278442
Validation loss: 2.1656609574953714

Epoch: 6| Step: 10
Training loss: 1.056931495666504
Validation loss: 2.161524216334025

Epoch: 6| Step: 11
Training loss: 1.5954898595809937
Validation loss: 2.1594587763150535

Epoch: 6| Step: 12
Training loss: 1.963326334953308
Validation loss: 2.120517690976461

Epoch: 6| Step: 13
Training loss: 1.9745190143585205
Validation loss: 2.142699182033539

Epoch: 260| Step: 0
Training loss: 2.120117664337158
Validation loss: 2.1393192410469055

Epoch: 6| Step: 1
Training loss: 1.806885004043579
Validation loss: 2.151979625225067

Epoch: 6| Step: 2
Training loss: 1.5006393194198608
Validation loss: 2.1612332860628762

Epoch: 6| Step: 3
Training loss: 1.7125329971313477
Validation loss: 2.1217482686042786

Epoch: 6| Step: 4
Training loss: 1.0371652841567993
Validation loss: 2.1454482277234397

Epoch: 6| Step: 5
Training loss: 2.413623094558716
Validation loss: 2.1299334168434143

Epoch: 6| Step: 6
Training loss: 1.8963862657546997
Validation loss: 2.1461553374926248

Epoch: 6| Step: 7
Training loss: 1.364771842956543
Validation loss: 2.1383655865987143

Epoch: 6| Step: 8
Training loss: 1.1270012855529785
Validation loss: 2.125947594642639

Epoch: 6| Step: 9
Training loss: 2.441835403442383
Validation loss: 2.112176835536957

Epoch: 6| Step: 10
Training loss: 2.1827526092529297
Validation loss: 2.143476982911428

Epoch: 6| Step: 11
Training loss: 1.9036823511123657
Validation loss: 2.126775105794271

Epoch: 6| Step: 12
Training loss: 1.6444733142852783
Validation loss: 2.1330469648043313

Epoch: 6| Step: 13
Training loss: 1.342540979385376
Validation loss: 2.1678922176361084

Epoch: 261| Step: 0
Training loss: 1.7308077812194824
Validation loss: 2.1828266382217407

Epoch: 6| Step: 1
Training loss: 1.1631338596343994
Validation loss: 2.1605219642321267

Epoch: 6| Step: 2
Training loss: 2.165348768234253
Validation loss: 2.1555680433909097

Epoch: 6| Step: 3
Training loss: 1.8042314052581787
Validation loss: 2.1771194338798523

Epoch: 6| Step: 4
Training loss: 1.9171168804168701
Validation loss: 2.1808126171429953

Epoch: 6| Step: 5
Training loss: 2.0070412158966064
Validation loss: 2.1917230685551963

Epoch: 6| Step: 6
Training loss: 1.7770299911499023
Validation loss: 2.1864932775497437

Epoch: 6| Step: 7
Training loss: 1.2772501707077026
Validation loss: 2.147460679213206

Epoch: 6| Step: 8
Training loss: 1.607693076133728
Validation loss: 2.1531028548876443

Epoch: 6| Step: 9
Training loss: 1.49155855178833
Validation loss: 2.1284185647964478

Epoch: 6| Step: 10
Training loss: 1.5504486560821533
Validation loss: 2.131879210472107

Epoch: 6| Step: 11
Training loss: 1.6130621433258057
Validation loss: 2.1449384888013205

Epoch: 6| Step: 12
Training loss: 1.838230848312378
Validation loss: 2.137038747469584

Epoch: 6| Step: 13
Training loss: 2.1347193717956543
Validation loss: 2.1658305128415427

Epoch: 262| Step: 0
Training loss: 1.4177783727645874
Validation loss: 2.158965289592743

Epoch: 6| Step: 1
Training loss: 2.1403932571411133
Validation loss: 2.197558840115865

Epoch: 6| Step: 2
Training loss: 1.436611533164978
Validation loss: 2.191727121671041

Epoch: 6| Step: 3
Training loss: 2.4046993255615234
Validation loss: 2.20602418979009

Epoch: 6| Step: 4
Training loss: 0.990736722946167
Validation loss: 2.1789461771647134

Epoch: 6| Step: 5
Training loss: 1.3461551666259766
Validation loss: 2.1767293214797974

Epoch: 6| Step: 6
Training loss: 1.841865062713623
Validation loss: 2.174081484476725

Epoch: 6| Step: 7
Training loss: 2.192814350128174
Validation loss: 2.1795947551727295

Epoch: 6| Step: 8
Training loss: 1.9594511985778809
Validation loss: 2.1748732924461365

Epoch: 6| Step: 9
Training loss: 2.190568685531616
Validation loss: 2.183124840259552

Epoch: 6| Step: 10
Training loss: 1.2200825214385986
Validation loss: 2.172517200311025

Epoch: 6| Step: 11
Training loss: 1.8297388553619385
Validation loss: 2.1421651244163513

Epoch: 6| Step: 12
Training loss: 1.569946527481079
Validation loss: 2.158804933230082

Epoch: 6| Step: 13
Training loss: 1.3204832077026367
Validation loss: 2.134518325328827

Epoch: 263| Step: 0
Training loss: 2.8299403190612793
Validation loss: 2.1267692844072976

Epoch: 6| Step: 1
Training loss: 1.1179842948913574
Validation loss: 2.136717220147451

Epoch: 6| Step: 2
Training loss: 1.0779792070388794
Validation loss: 2.1408873995145163

Epoch: 6| Step: 3
Training loss: 1.2118523120880127
Validation loss: 2.157849133014679

Epoch: 6| Step: 4
Training loss: 1.5781629085540771
Validation loss: 2.146263301372528

Epoch: 6| Step: 5
Training loss: 2.2812695503234863
Validation loss: 2.147845188776652

Epoch: 6| Step: 6
Training loss: 0.9896621704101562
Validation loss: 2.1389803091684976

Epoch: 6| Step: 7
Training loss: 1.8428232669830322
Validation loss: 2.1496363480885825

Epoch: 6| Step: 8
Training loss: 1.246118187904358
Validation loss: 2.167375604311625

Epoch: 6| Step: 9
Training loss: 1.907845139503479
Validation loss: 2.14105878273646

Epoch: 6| Step: 10
Training loss: 1.950479507446289
Validation loss: 2.141963243484497

Epoch: 6| Step: 11
Training loss: 1.6028050184249878
Validation loss: 2.1754742662111917

Epoch: 6| Step: 12
Training loss: 1.9098947048187256
Validation loss: 2.149765113989512

Epoch: 6| Step: 13
Training loss: 1.7916061878204346
Validation loss: 2.146857440471649

Epoch: 264| Step: 0
Training loss: 1.8221979141235352
Validation loss: 2.1388313372929892

Epoch: 6| Step: 1
Training loss: 1.3901281356811523
Validation loss: 2.167300542195638

Epoch: 6| Step: 2
Training loss: 1.2182210683822632
Validation loss: 2.1635576089223227

Epoch: 6| Step: 3
Training loss: 1.8226089477539062
Validation loss: 2.167224665482839

Epoch: 6| Step: 4
Training loss: 2.0009472370147705
Validation loss: 2.1607669989267984

Epoch: 6| Step: 5
Training loss: 1.934540033340454
Validation loss: 2.16862283150355

Epoch: 6| Step: 6
Training loss: 1.9664199352264404
Validation loss: 2.154404044151306

Epoch: 6| Step: 7
Training loss: 1.6148395538330078
Validation loss: 2.1454968452453613

Epoch: 6| Step: 8
Training loss: 1.1681735515594482
Validation loss: 2.145723124345144

Epoch: 6| Step: 9
Training loss: 1.452348232269287
Validation loss: 2.1614381869633994

Epoch: 6| Step: 10
Training loss: 2.0041725635528564
Validation loss: 2.1543455123901367

Epoch: 6| Step: 11
Training loss: 1.6443581581115723
Validation loss: 2.1746193567911782

Epoch: 6| Step: 12
Training loss: 1.3622181415557861
Validation loss: 2.165635426839193

Epoch: 6| Step: 13
Training loss: 1.7380025386810303
Validation loss: 2.169803738594055

Epoch: 265| Step: 0
Training loss: 0.9106918573379517
Validation loss: 2.1494021813074746

Epoch: 6| Step: 1
Training loss: 1.7954838275909424
Validation loss: 2.17186305920283

Epoch: 6| Step: 2
Training loss: 1.483945369720459
Validation loss: 2.1758017539978027

Epoch: 6| Step: 3
Training loss: 1.5441433191299438
Validation loss: 2.157728393872579

Epoch: 6| Step: 4
Training loss: 1.25291109085083
Validation loss: 2.148136337598165

Epoch: 6| Step: 5
Training loss: 1.8639566898345947
Validation loss: 2.1517710089683533

Epoch: 6| Step: 6
Training loss: 1.9582887887954712
Validation loss: 2.1394266486167908

Epoch: 6| Step: 7
Training loss: 1.8897984027862549
Validation loss: 2.1381329695383706

Epoch: 6| Step: 8
Training loss: 0.7876964211463928
Validation loss: 2.1554918686548867

Epoch: 6| Step: 9
Training loss: 2.1339008808135986
Validation loss: 2.137862821420034

Epoch: 6| Step: 10
Training loss: 1.5875966548919678
Validation loss: 2.1489570140838623

Epoch: 6| Step: 11
Training loss: 1.8804210424423218
Validation loss: 2.138049066066742

Epoch: 6| Step: 12
Training loss: 2.866487503051758
Validation loss: 2.1461207469304404

Epoch: 6| Step: 13
Training loss: 1.3371104001998901
Validation loss: 2.1672378182411194

Epoch: 266| Step: 0
Training loss: 1.0521512031555176
Validation loss: 2.178812623023987

Epoch: 6| Step: 1
Training loss: 1.7228635549545288
Validation loss: 2.181181569894155

Epoch: 6| Step: 2
Training loss: 1.5617767572402954
Validation loss: 2.2210237979888916

Epoch: 6| Step: 3
Training loss: 1.173020839691162
Validation loss: 2.2136261463165283

Epoch: 6| Step: 4
Training loss: 1.920712947845459
Validation loss: 2.2080596884091697

Epoch: 6| Step: 5
Training loss: 1.5006797313690186
Validation loss: 2.1910163362820945

Epoch: 6| Step: 6
Training loss: 1.5195046663284302
Validation loss: 2.1694419980049133

Epoch: 6| Step: 7
Training loss: 1.4840645790100098
Validation loss: 2.1680350502332053

Epoch: 6| Step: 8
Training loss: 1.551307201385498
Validation loss: 2.159394363562266

Epoch: 6| Step: 9
Training loss: 2.1933157444000244
Validation loss: 2.1514583428700766

Epoch: 6| Step: 10
Training loss: 2.3289546966552734
Validation loss: 2.150428036848704

Epoch: 6| Step: 11
Training loss: 1.856975793838501
Validation loss: 2.166929602622986

Epoch: 6| Step: 12
Training loss: 1.866504430770874
Validation loss: 2.1508129239082336

Epoch: 6| Step: 13
Training loss: 1.4923791885375977
Validation loss: 2.1309784849484763

Epoch: 267| Step: 0
Training loss: 1.5936965942382812
Validation loss: 2.170246720314026

Epoch: 6| Step: 1
Training loss: 1.549883246421814
Validation loss: 2.163460453351339

Epoch: 6| Step: 2
Training loss: 1.5093610286712646
Validation loss: 2.1676862835884094

Epoch: 6| Step: 3
Training loss: 1.5448143482208252
Validation loss: 2.1722169717152915

Epoch: 6| Step: 4
Training loss: 1.272912859916687
Validation loss: 2.196182052294413

Epoch: 6| Step: 5
Training loss: 1.6516315937042236
Validation loss: 2.178335964679718

Epoch: 6| Step: 6
Training loss: 2.1039199829101562
Validation loss: 2.192706604798635

Epoch: 6| Step: 7
Training loss: 1.6607245206832886
Validation loss: 2.194502035776774

Epoch: 6| Step: 8
Training loss: 1.822892189025879
Validation loss: 2.1916860540707908

Epoch: 6| Step: 9
Training loss: 1.9793177843093872
Validation loss: 2.2086906830469766

Epoch: 6| Step: 10
Training loss: 2.005347728729248
Validation loss: 2.1906710664431253

Epoch: 6| Step: 11
Training loss: 1.8562403917312622
Validation loss: 2.1551867524782815

Epoch: 6| Step: 12
Training loss: 1.4068965911865234
Validation loss: 2.1792522271474204

Epoch: 6| Step: 13
Training loss: 1.230249285697937
Validation loss: 2.1679082910219827

Epoch: 268| Step: 0
Training loss: 1.7563414573669434
Validation loss: 2.1563165187835693

Epoch: 6| Step: 1
Training loss: 1.9760011434555054
Validation loss: 2.1204697092374167

Epoch: 6| Step: 2
Training loss: 2.5713486671447754
Validation loss: 2.1382768750190735

Epoch: 6| Step: 3
Training loss: 2.1651201248168945
Validation loss: 2.1274577379226685

Epoch: 6| Step: 4
Training loss: 1.73277747631073
Validation loss: 2.119931141535441

Epoch: 6| Step: 5
Training loss: 1.3834283351898193
Validation loss: 2.126738667488098

Epoch: 6| Step: 6
Training loss: 1.4476642608642578
Validation loss: 2.129418353239695

Epoch: 6| Step: 7
Training loss: 1.6100184917449951
Validation loss: 2.1430335442225137

Epoch: 6| Step: 8
Training loss: 1.1011707782745361
Validation loss: 2.156232933203379

Epoch: 6| Step: 9
Training loss: 1.6533591747283936
Validation loss: 2.1242148677508035

Epoch: 6| Step: 10
Training loss: 1.8285640478134155
Validation loss: 2.129668871561686

Epoch: 6| Step: 11
Training loss: 1.7596713304519653
Validation loss: 2.110049247741699

Epoch: 6| Step: 12
Training loss: 1.4514367580413818
Validation loss: 2.115845739841461

Epoch: 6| Step: 13
Training loss: 1.5616905689239502
Validation loss: 2.1230517625808716

Epoch: 269| Step: 0
Training loss: 2.3843588829040527
Validation loss: 2.11132421096166

Epoch: 6| Step: 1
Training loss: 2.2633402347564697
Validation loss: 2.1184770464897156

Epoch: 6| Step: 2
Training loss: 1.3079482316970825
Validation loss: 2.14164145787557

Epoch: 6| Step: 3
Training loss: 1.1606132984161377
Validation loss: 2.1508079965909324

Epoch: 6| Step: 4
Training loss: 2.0040125846862793
Validation loss: 2.13741672039032

Epoch: 6| Step: 5
Training loss: 2.0850329399108887
Validation loss: 2.155478854974111

Epoch: 6| Step: 6
Training loss: 1.6865222454071045
Validation loss: 2.138038078943888

Epoch: 6| Step: 7
Training loss: 1.6973240375518799
Validation loss: 2.1447489658991494

Epoch: 6| Step: 8
Training loss: 1.0235683917999268
Validation loss: 2.152001202106476

Epoch: 6| Step: 9
Training loss: 0.8175109624862671
Validation loss: 2.151024659474691

Epoch: 6| Step: 10
Training loss: 1.2614989280700684
Validation loss: 2.1395407915115356

Epoch: 6| Step: 11
Training loss: 1.9144227504730225
Validation loss: 2.1778698364893594

Epoch: 6| Step: 12
Training loss: 2.078748941421509
Validation loss: 2.1860240499178567

Epoch: 6| Step: 13
Training loss: 1.4496750831604004
Validation loss: 2.1913236379623413

Epoch: 270| Step: 0
Training loss: 1.4334025382995605
Validation loss: 2.192576547463735

Epoch: 6| Step: 1
Training loss: 1.200123906135559
Validation loss: 2.1752968231836953

Epoch: 6| Step: 2
Training loss: 1.9399290084838867
Validation loss: 2.164512316385905

Epoch: 6| Step: 3
Training loss: 1.3163198232650757
Validation loss: 2.1734136740366616

Epoch: 6| Step: 4
Training loss: 1.7305165529251099
Validation loss: 2.159500300884247

Epoch: 6| Step: 5
Training loss: 1.3752143383026123
Validation loss: 2.164942999680837

Epoch: 6| Step: 6
Training loss: 1.5796186923980713
Validation loss: 2.1783089637756348

Epoch: 6| Step: 7
Training loss: 2.103426933288574
Validation loss: 2.125233014424642

Epoch: 6| Step: 8
Training loss: 1.6714414358139038
Validation loss: 2.1271985173225403

Epoch: 6| Step: 9
Training loss: 2.3017916679382324
Validation loss: 2.1232781211535134

Epoch: 6| Step: 10
Training loss: 1.9915117025375366
Validation loss: 2.1185130874315896

Epoch: 6| Step: 11
Training loss: 1.54885733127594
Validation loss: 2.1188038190205893

Epoch: 6| Step: 12
Training loss: 1.216151237487793
Validation loss: 2.098867734273275

Epoch: 6| Step: 13
Training loss: 1.528714895248413
Validation loss: 2.1249364217122397

Epoch: 271| Step: 0
Training loss: 1.2857160568237305
Validation loss: 2.1381943623224893

Epoch: 6| Step: 1
Training loss: 2.2870469093322754
Validation loss: 2.1493951280911765

Epoch: 6| Step: 2
Training loss: 2.3637051582336426
Validation loss: 2.1775726675987244

Epoch: 6| Step: 3
Training loss: 1.855862021446228
Validation loss: 2.1519072453180947

Epoch: 6| Step: 4
Training loss: 1.286714792251587
Validation loss: 2.1615887681643167

Epoch: 6| Step: 5
Training loss: 1.491964340209961
Validation loss: 2.168436845143636

Epoch: 6| Step: 6
Training loss: 1.322523593902588
Validation loss: 2.164925237496694

Epoch: 6| Step: 7
Training loss: 2.076817512512207
Validation loss: 2.182496507962545

Epoch: 6| Step: 8
Training loss: 1.9384962320327759
Validation loss: 2.1663026412328086

Epoch: 6| Step: 9
Training loss: 1.0305511951446533
Validation loss: 2.159696718056997

Epoch: 6| Step: 10
Training loss: 1.8365670442581177
Validation loss: 2.1609263817469277

Epoch: 6| Step: 11
Training loss: 1.748509407043457
Validation loss: 2.151750306288401

Epoch: 6| Step: 12
Training loss: 1.2574104070663452
Validation loss: 2.144208868344625

Epoch: 6| Step: 13
Training loss: 1.521978497505188
Validation loss: 2.1405488650004068

Epoch: 272| Step: 0
Training loss: 1.476557970046997
Validation loss: 2.1501783529917398

Epoch: 6| Step: 1
Training loss: 2.541037082672119
Validation loss: 2.1456889311472573

Epoch: 6| Step: 2
Training loss: 1.5869126319885254
Validation loss: 2.134439786275228

Epoch: 6| Step: 3
Training loss: 1.3243463039398193
Validation loss: 2.146830121676127

Epoch: 6| Step: 4
Training loss: 2.315469980239868
Validation loss: 2.149097482363383

Epoch: 6| Step: 5
Training loss: 2.3126463890075684
Validation loss: 2.128559132417043

Epoch: 6| Step: 6
Training loss: 1.415900707244873
Validation loss: 2.1193498770395913

Epoch: 6| Step: 7
Training loss: 1.2214614152908325
Validation loss: 2.115806301434835

Epoch: 6| Step: 8
Training loss: 1.5939550399780273
Validation loss: 2.126584013303121

Epoch: 6| Step: 9
Training loss: 0.6788603067398071
Validation loss: 2.140682260195414

Epoch: 6| Step: 10
Training loss: 1.715911865234375
Validation loss: 2.1390377084414163

Epoch: 6| Step: 11
Training loss: 1.721766471862793
Validation loss: 2.1546109716097512

Epoch: 6| Step: 12
Training loss: 1.4996135234832764
Validation loss: 2.159401595592499

Epoch: 6| Step: 13
Training loss: 1.5484678745269775
Validation loss: 2.1471625566482544

Epoch: 273| Step: 0
Training loss: 1.0273525714874268
Validation loss: 2.1497583985328674

Epoch: 6| Step: 1
Training loss: 1.3688384294509888
Validation loss: 2.1320454478263855

Epoch: 6| Step: 2
Training loss: 1.8094838857650757
Validation loss: 2.1731504996617637

Epoch: 6| Step: 3
Training loss: 2.167412281036377
Validation loss: 2.167972286542257

Epoch: 6| Step: 4
Training loss: 1.7177765369415283
Validation loss: 2.190021514892578

Epoch: 6| Step: 5
Training loss: 1.610987901687622
Validation loss: 2.180716633796692

Epoch: 6| Step: 6
Training loss: 1.8911586999893188
Validation loss: 2.1633570392926535

Epoch: 6| Step: 7
Training loss: 1.391524314880371
Validation loss: 2.193565388520559

Epoch: 6| Step: 8
Training loss: 1.707161784172058
Validation loss: 2.1561237374941506

Epoch: 6| Step: 9
Training loss: 1.2199214696884155
Validation loss: 2.199879984060923

Epoch: 6| Step: 10
Training loss: 2.1864120960235596
Validation loss: 2.1766135891278586

Epoch: 6| Step: 11
Training loss: 1.629831075668335
Validation loss: 2.1866941849390664

Epoch: 6| Step: 12
Training loss: 1.19260835647583
Validation loss: 2.164581000804901

Epoch: 6| Step: 13
Training loss: 1.6213223934173584
Validation loss: 2.1434431076049805

Epoch: 274| Step: 0
Training loss: 1.5459091663360596
Validation loss: 2.1333398818969727

Epoch: 6| Step: 1
Training loss: 2.21956205368042
Validation loss: 2.141343911488851

Epoch: 6| Step: 2
Training loss: 2.373669147491455
Validation loss: 2.170677602291107

Epoch: 6| Step: 3
Training loss: 1.302384853363037
Validation loss: 2.1713008483250937

Epoch: 6| Step: 4
Training loss: 2.449451446533203
Validation loss: 2.146372139453888

Epoch: 6| Step: 5
Training loss: 1.55641770362854
Validation loss: 2.174007991949717

Epoch: 6| Step: 6
Training loss: 1.5093114376068115
Validation loss: 2.192443033059438

Epoch: 6| Step: 7
Training loss: 1.3669341802597046
Validation loss: 2.195318798224131

Epoch: 6| Step: 8
Training loss: 2.023033618927002
Validation loss: 2.198388397693634

Epoch: 6| Step: 9
Training loss: 1.4644259214401245
Validation loss: 2.1811277866363525

Epoch: 6| Step: 10
Training loss: 1.1977190971374512
Validation loss: 2.156998097896576

Epoch: 6| Step: 11
Training loss: 1.1214486360549927
Validation loss: 2.159173011779785

Epoch: 6| Step: 12
Training loss: 1.0088138580322266
Validation loss: 2.1448147296905518

Epoch: 6| Step: 13
Training loss: 1.5367203950881958
Validation loss: 2.155296544233958

Epoch: 275| Step: 0
Training loss: 1.9172961711883545
Validation loss: 2.18041197458903

Epoch: 6| Step: 1
Training loss: 1.0833851099014282
Validation loss: 2.163876990477244

Epoch: 6| Step: 2
Training loss: 1.5679354667663574
Validation loss: 2.188951313495636

Epoch: 6| Step: 3
Training loss: 1.5423779487609863
Validation loss: 2.1919008096059165

Epoch: 6| Step: 4
Training loss: 1.3040862083435059
Validation loss: 2.1723278363545737

Epoch: 6| Step: 5
Training loss: 1.4941285848617554
Validation loss: 2.173033436139425

Epoch: 6| Step: 6
Training loss: 1.7318246364593506
Validation loss: 2.1468966404596963

Epoch: 6| Step: 7
Training loss: 2.022909641265869
Validation loss: 2.1560758352279663

Epoch: 6| Step: 8
Training loss: 1.7904030084609985
Validation loss: 2.1466981371243796

Epoch: 6| Step: 9
Training loss: 1.1873985528945923
Validation loss: 2.1521408756573996

Epoch: 6| Step: 10
Training loss: 1.3020243644714355
Validation loss: 2.1560744841893515

Epoch: 6| Step: 11
Training loss: 1.0825836658477783
Validation loss: 2.1459660132726035

Epoch: 6| Step: 12
Training loss: 2.1970667839050293
Validation loss: 2.151999016602834

Epoch: 6| Step: 13
Training loss: 2.005239486694336
Validation loss: 2.150841176509857

Epoch: 276| Step: 0
Training loss: 2.6267335414886475
Validation loss: 2.1784533262252808

Epoch: 6| Step: 1
Training loss: 0.8692118525505066
Validation loss: 2.1556031703948975

Epoch: 6| Step: 2
Training loss: 1.1802911758422852
Validation loss: 2.156757116317749

Epoch: 6| Step: 3
Training loss: 1.5426454544067383
Validation loss: 2.20267120997111

Epoch: 6| Step: 4
Training loss: 1.0183961391448975
Validation loss: 2.177302340666453

Epoch: 6| Step: 5
Training loss: 1.6227796077728271
Validation loss: 2.1835426092147827

Epoch: 6| Step: 6
Training loss: 1.5008649826049805
Validation loss: 2.1688060760498047

Epoch: 6| Step: 7
Training loss: 1.2372353076934814
Validation loss: 2.15838885307312

Epoch: 6| Step: 8
Training loss: 1.5144047737121582
Validation loss: 2.181215286254883

Epoch: 6| Step: 9
Training loss: 1.483002781867981
Validation loss: 2.16568915049235

Epoch: 6| Step: 10
Training loss: 1.2708005905151367
Validation loss: 2.178786337375641

Epoch: 6| Step: 11
Training loss: 1.9932146072387695
Validation loss: 2.1754661003748574

Epoch: 6| Step: 12
Training loss: 3.1727495193481445
Validation loss: 2.193324943383535

Epoch: 6| Step: 13
Training loss: 1.2090084552764893
Validation loss: 2.213809053103129

Epoch: 277| Step: 0
Training loss: 1.6863571405410767
Validation loss: 2.199811100959778

Epoch: 6| Step: 1
Training loss: 1.854830026626587
Validation loss: 2.199195305506388

Epoch: 6| Step: 2
Training loss: 1.3214972019195557
Validation loss: 2.1826115051905313

Epoch: 6| Step: 3
Training loss: 0.7000472545623779
Validation loss: 2.1915241479873657

Epoch: 6| Step: 4
Training loss: 1.840330719947815
Validation loss: 2.179998199144999

Epoch: 6| Step: 5
Training loss: 1.8035776615142822
Validation loss: 2.191388746102651

Epoch: 6| Step: 6
Training loss: 1.815009593963623
Validation loss: 2.1611597736676535

Epoch: 6| Step: 7
Training loss: 1.648404836654663
Validation loss: 2.1400183836619058

Epoch: 6| Step: 8
Training loss: 1.6535183191299438
Validation loss: 2.121124525864919

Epoch: 6| Step: 9
Training loss: 1.7874104976654053
Validation loss: 2.1289790670077005

Epoch: 6| Step: 10
Training loss: 1.0170971155166626
Validation loss: 2.119546969731649

Epoch: 6| Step: 11
Training loss: 1.4361196756362915
Validation loss: 2.118828852971395

Epoch: 6| Step: 12
Training loss: 2.3306925296783447
Validation loss: 2.1137375434239707

Epoch: 6| Step: 13
Training loss: 1.6347663402557373
Validation loss: 2.122249881426493

Epoch: 278| Step: 0
Training loss: 1.8272240161895752
Validation loss: 2.1537824670473733

Epoch: 6| Step: 1
Training loss: 1.6980465650558472
Validation loss: 2.1716285943984985

Epoch: 6| Step: 2
Training loss: 0.934084415435791
Validation loss: 2.163553833961487

Epoch: 6| Step: 3
Training loss: 1.5239217281341553
Validation loss: 2.1627312501271567

Epoch: 6| Step: 4
Training loss: 2.3473312854766846
Validation loss: 2.1380271712938943

Epoch: 6| Step: 5
Training loss: 1.2042158842086792
Validation loss: 2.104142189025879

Epoch: 6| Step: 6
Training loss: 1.2877618074417114
Validation loss: 2.104244351387024

Epoch: 6| Step: 7
Training loss: 1.689037799835205
Validation loss: 2.120216111342112

Epoch: 6| Step: 8
Training loss: 1.3868844509124756
Validation loss: 2.1246033112208047

Epoch: 6| Step: 9
Training loss: 2.1347410678863525
Validation loss: 2.1377296447753906

Epoch: 6| Step: 10
Training loss: 2.2419376373291016
Validation loss: 2.1342416803042092

Epoch: 6| Step: 11
Training loss: 1.5958276987075806
Validation loss: 2.173542340596517

Epoch: 6| Step: 12
Training loss: 1.11795175075531
Validation loss: 2.176668326059977

Epoch: 6| Step: 13
Training loss: 1.6704341173171997
Validation loss: 2.14629065990448

Epoch: 279| Step: 0
Training loss: 1.331458330154419
Validation loss: 2.1468199491500854

Epoch: 6| Step: 1
Training loss: 1.2131049633026123
Validation loss: 2.1382247606913247

Epoch: 6| Step: 2
Training loss: 1.6800808906555176
Validation loss: 2.161277194817861

Epoch: 6| Step: 3
Training loss: 0.9526690244674683
Validation loss: 2.1448403000831604

Epoch: 6| Step: 4
Training loss: 1.6055850982666016
Validation loss: 2.1887414256731668

Epoch: 6| Step: 5
Training loss: 1.8942723274230957
Validation loss: 2.2100579142570496

Epoch: 6| Step: 6
Training loss: 1.4621825218200684
Validation loss: 2.206133166948954

Epoch: 6| Step: 7
Training loss: 2.3485472202301025
Validation loss: 2.244162698586782

Epoch: 6| Step: 8
Training loss: 1.6267859935760498
Validation loss: 2.2313941717147827

Epoch: 6| Step: 9
Training loss: 1.5184149742126465
Validation loss: 2.2103153665860495

Epoch: 6| Step: 10
Training loss: 1.7713520526885986
Validation loss: 2.209582249323527

Epoch: 6| Step: 11
Training loss: 1.6685543060302734
Validation loss: 2.1689313650131226

Epoch: 6| Step: 12
Training loss: 1.8757731914520264
Validation loss: 2.1759018301963806

Epoch: 6| Step: 13
Training loss: 1.4511157274246216
Validation loss: 2.17639567454656

Epoch: 280| Step: 0
Training loss: 0.9011325836181641
Validation loss: 2.145789901415507

Epoch: 6| Step: 1
Training loss: 1.3679535388946533
Validation loss: 2.1598041454950967

Epoch: 6| Step: 2
Training loss: 2.1585936546325684
Validation loss: 2.1399443546930947

Epoch: 6| Step: 3
Training loss: 1.2965807914733887
Validation loss: 2.140273869037628

Epoch: 6| Step: 4
Training loss: 1.3263052701950073
Validation loss: 2.161550144354502

Epoch: 6| Step: 5
Training loss: 2.548536777496338
Validation loss: 2.1671378215154014

Epoch: 6| Step: 6
Training loss: 1.4917736053466797
Validation loss: 2.1799729466438293

Epoch: 6| Step: 7
Training loss: 1.7699716091156006
Validation loss: 2.167121469974518

Epoch: 6| Step: 8
Training loss: 1.742945671081543
Validation loss: 2.162644704182943

Epoch: 6| Step: 9
Training loss: 1.6415953636169434
Validation loss: 2.1630019148190818

Epoch: 6| Step: 10
Training loss: 0.9592433571815491
Validation loss: 2.1504870454470315

Epoch: 6| Step: 11
Training loss: 1.304236650466919
Validation loss: 2.1656294663747153

Epoch: 6| Step: 12
Training loss: 2.0684828758239746
Validation loss: 2.1615262826283774

Epoch: 6| Step: 13
Training loss: 1.429079294204712
Validation loss: 2.1488932967185974

Epoch: 281| Step: 0
Training loss: 1.6820812225341797
Validation loss: 2.1524290641148887

Epoch: 6| Step: 1
Training loss: 1.7066078186035156
Validation loss: 2.1391820510228476

Epoch: 6| Step: 2
Training loss: 1.6758533716201782
Validation loss: 2.1314032077789307

Epoch: 6| Step: 3
Training loss: 1.522378921508789
Validation loss: 2.1438382267951965

Epoch: 6| Step: 4
Training loss: 1.4013410806655884
Validation loss: 2.1471579869588218

Epoch: 6| Step: 5
Training loss: 1.2983970642089844
Validation loss: 2.146832446257273

Epoch: 6| Step: 6
Training loss: 1.7318439483642578
Validation loss: 2.131073772907257

Epoch: 6| Step: 7
Training loss: 1.399181604385376
Validation loss: 2.134127597014109

Epoch: 6| Step: 8
Training loss: 1.407333493232727
Validation loss: 2.1497464179992676

Epoch: 6| Step: 9
Training loss: 1.6034882068634033
Validation loss: 2.151775618394216

Epoch: 6| Step: 10
Training loss: 1.9795732498168945
Validation loss: 2.1669870416323342

Epoch: 6| Step: 11
Training loss: 1.1036990880966187
Validation loss: 2.154830495516459

Epoch: 6| Step: 12
Training loss: 2.6018600463867188
Validation loss: 2.170998771985372

Epoch: 6| Step: 13
Training loss: 1.5909430980682373
Validation loss: 2.2056146462758384

Epoch: 282| Step: 0
Training loss: 2.0834221839904785
Validation loss: 2.1651932199796042

Epoch: 6| Step: 1
Training loss: 1.066630244255066
Validation loss: 2.130615472793579

Epoch: 6| Step: 2
Training loss: 1.1274285316467285
Validation loss: 2.139791031678518

Epoch: 6| Step: 3
Training loss: 1.6943566799163818
Validation loss: 2.1355828444163003

Epoch: 6| Step: 4
Training loss: 1.3393521308898926
Validation loss: 2.1479702989260354

Epoch: 6| Step: 5
Training loss: 1.5984187126159668
Validation loss: 2.129996339480082

Epoch: 6| Step: 6
Training loss: 1.033252477645874
Validation loss: 2.173099935054779

Epoch: 6| Step: 7
Training loss: 1.9009087085723877
Validation loss: 2.171779195467631

Epoch: 6| Step: 8
Training loss: 1.5784006118774414
Validation loss: 2.197657505671183

Epoch: 6| Step: 9
Training loss: 2.3828742504119873
Validation loss: 2.178975542386373

Epoch: 6| Step: 10
Training loss: 1.4698456525802612
Validation loss: 2.1770029067993164

Epoch: 6| Step: 11
Training loss: 2.1342992782592773
Validation loss: 2.1726192831993103

Epoch: 6| Step: 12
Training loss: 1.792624831199646
Validation loss: 2.1535655856132507

Epoch: 6| Step: 13
Training loss: 1.44638192653656
Validation loss: 2.168847640355428

Epoch: 283| Step: 0
Training loss: 1.6402031183242798
Validation loss: 2.1559809843699136

Epoch: 6| Step: 1
Training loss: 0.9087399244308472
Validation loss: 2.1709320545196533

Epoch: 6| Step: 2
Training loss: 1.6920324563980103
Validation loss: 2.1526609460512796

Epoch: 6| Step: 3
Training loss: 2.153493881225586
Validation loss: 2.160548667112986

Epoch: 6| Step: 4
Training loss: 1.2766203880310059
Validation loss: 2.1601582964261374

Epoch: 6| Step: 5
Training loss: 1.082077145576477
Validation loss: 2.1541181008021035

Epoch: 6| Step: 6
Training loss: 1.2327988147735596
Validation loss: 2.1532897551854453

Epoch: 6| Step: 7
Training loss: 2.099013566970825
Validation loss: 2.1646575133005777

Epoch: 6| Step: 8
Training loss: 1.4854857921600342
Validation loss: 2.1749261220296225

Epoch: 6| Step: 9
Training loss: 1.2387397289276123
Validation loss: 2.165168543656667

Epoch: 6| Step: 10
Training loss: 1.5653010606765747
Validation loss: 2.174568156401316

Epoch: 6| Step: 11
Training loss: 1.6106266975402832
Validation loss: 2.1712382237116494

Epoch: 6| Step: 12
Training loss: 2.281219482421875
Validation loss: 2.1544774373372397

Epoch: 6| Step: 13
Training loss: 1.2498102188110352
Validation loss: 2.1508339246114097

Epoch: 284| Step: 0
Training loss: 2.233259677886963
Validation loss: 2.1297706365585327

Epoch: 6| Step: 1
Training loss: 1.7382649183273315
Validation loss: 2.1084852814674377

Epoch: 6| Step: 2
Training loss: 1.4704914093017578
Validation loss: 2.1095983584721885

Epoch: 6| Step: 3
Training loss: 1.0342862606048584
Validation loss: 2.1351054310798645

Epoch: 6| Step: 4
Training loss: 1.6456096172332764
Validation loss: 2.144660393397013

Epoch: 6| Step: 5
Training loss: 1.002434492111206
Validation loss: 2.1294758915901184

Epoch: 6| Step: 6
Training loss: 1.4434791803359985
Validation loss: 2.1541500091552734

Epoch: 6| Step: 7
Training loss: 1.2561625242233276
Validation loss: 2.125319540500641

Epoch: 6| Step: 8
Training loss: 2.221287965774536
Validation loss: 2.153018335501353

Epoch: 6| Step: 9
Training loss: 1.7598837614059448
Validation loss: 2.1617465813954673

Epoch: 6| Step: 10
Training loss: 1.419088363647461
Validation loss: 2.17356010278066

Epoch: 6| Step: 11
Training loss: 1.3435544967651367
Validation loss: 2.145566721757253

Epoch: 6| Step: 12
Training loss: 1.7722585201263428
Validation loss: 2.1344399054845176

Epoch: 6| Step: 13
Training loss: 1.669260025024414
Validation loss: 2.158027172088623

Epoch: 285| Step: 0
Training loss: 1.190009355545044
Validation loss: 2.161395490169525

Epoch: 6| Step: 1
Training loss: 1.5205612182617188
Validation loss: 2.1769172747929892

Epoch: 6| Step: 2
Training loss: 1.5557597875595093
Validation loss: 2.175041655699412

Epoch: 6| Step: 3
Training loss: 1.201357126235962
Validation loss: 2.2010954221089682

Epoch: 6| Step: 4
Training loss: 1.3578816652297974
Validation loss: 2.179766913255056

Epoch: 6| Step: 5
Training loss: 1.7773211002349854
Validation loss: 2.1919466058413186

Epoch: 6| Step: 6
Training loss: 1.9726247787475586
Validation loss: 2.1867136557896933

Epoch: 6| Step: 7
Training loss: 1.0010250806808472
Validation loss: 2.2016814549764

Epoch: 6| Step: 8
Training loss: 1.5465890169143677
Validation loss: 2.212774316469828

Epoch: 6| Step: 9
Training loss: 1.899773120880127
Validation loss: 2.2141818006833396

Epoch: 6| Step: 10
Training loss: 1.5534958839416504
Validation loss: 2.1986854473749795

Epoch: 6| Step: 11
Training loss: 1.5351285934448242
Validation loss: 2.2070302764574685

Epoch: 6| Step: 12
Training loss: 1.4959367513656616
Validation loss: 2.227508286635081

Epoch: 6| Step: 13
Training loss: 1.6787734031677246
Validation loss: 2.185495595137278

Epoch: 286| Step: 0
Training loss: 1.0894062519073486
Validation loss: 2.1940712134043374

Epoch: 6| Step: 1
Training loss: 1.0755459070205688
Validation loss: 2.199625571568807

Epoch: 6| Step: 2
Training loss: 2.067840576171875
Validation loss: 2.1849448482195535

Epoch: 6| Step: 3
Training loss: 1.426975131034851
Validation loss: 2.2079192797342935

Epoch: 6| Step: 4
Training loss: 1.7009170055389404
Validation loss: 2.196233093738556

Epoch: 6| Step: 5
Training loss: 1.089951515197754
Validation loss: 2.225443681081136

Epoch: 6| Step: 6
Training loss: 1.5636358261108398
Validation loss: 2.188759684562683

Epoch: 6| Step: 7
Training loss: 1.8653565645217896
Validation loss: 2.179309527079264

Epoch: 6| Step: 8
Training loss: 1.1331270933151245
Validation loss: 2.194841424624125

Epoch: 6| Step: 9
Training loss: 1.6998567581176758
Validation loss: 2.160480479399363

Epoch: 6| Step: 10
Training loss: 1.3526604175567627
Validation loss: 2.1715362270673118

Epoch: 6| Step: 11
Training loss: 1.3916881084442139
Validation loss: 2.175425966580709

Epoch: 6| Step: 12
Training loss: 2.333432197570801
Validation loss: 2.158691962560018

Epoch: 6| Step: 13
Training loss: 2.467148780822754
Validation loss: 2.176849087079366

Epoch: 287| Step: 0
Training loss: 1.3234833478927612
Validation loss: 2.1758012572924295

Epoch: 6| Step: 1
Training loss: 1.3880926370620728
Validation loss: 2.197898348172506

Epoch: 6| Step: 2
Training loss: 1.8767411708831787
Validation loss: 2.2025438149770102

Epoch: 6| Step: 3
Training loss: 2.149641752243042
Validation loss: 2.184490521748861

Epoch: 6| Step: 4
Training loss: 1.2224640846252441
Validation loss: 2.187905470530192

Epoch: 6| Step: 5
Training loss: 1.5882954597473145
Validation loss: 2.1659322579701743

Epoch: 6| Step: 6
Training loss: 1.3736921548843384
Validation loss: 2.1722826957702637

Epoch: 6| Step: 7
Training loss: 1.8253878355026245
Validation loss: 2.171781619389852

Epoch: 6| Step: 8
Training loss: 1.4389092922210693
Validation loss: 2.1970020532608032

Epoch: 6| Step: 9
Training loss: 1.8499196767807007
Validation loss: 2.189155399799347

Epoch: 6| Step: 10
Training loss: 1.832611322402954
Validation loss: 2.2222103277842202

Epoch: 6| Step: 11
Training loss: 1.0558964014053345
Validation loss: 2.201062281926473

Epoch: 6| Step: 12
Training loss: 1.0698201656341553
Validation loss: 2.2047598361968994

Epoch: 6| Step: 13
Training loss: 1.5037941932678223
Validation loss: 2.203963041305542

Epoch: 288| Step: 0
Training loss: 1.551080584526062
Validation loss: 2.209359606107076

Epoch: 6| Step: 1
Training loss: 1.1365876197814941
Validation loss: 2.2177216013272605

Epoch: 6| Step: 2
Training loss: 1.6254947185516357
Validation loss: 2.1951891779899597

Epoch: 6| Step: 3
Training loss: 1.5107094049453735
Validation loss: 2.2335307200749717

Epoch: 6| Step: 4
Training loss: 1.155602216720581
Validation loss: 2.205030103524526

Epoch: 6| Step: 5
Training loss: 1.9178435802459717
Validation loss: 2.186050216356913

Epoch: 6| Step: 6
Training loss: 1.7657465934753418
Validation loss: 2.1845948696136475

Epoch: 6| Step: 7
Training loss: 1.111086368560791
Validation loss: 2.1685343980789185

Epoch: 6| Step: 8
Training loss: 1.736956238746643
Validation loss: 2.149521211783091

Epoch: 6| Step: 9
Training loss: 1.3784288167953491
Validation loss: 2.13271035750707

Epoch: 6| Step: 10
Training loss: 1.6382273435592651
Validation loss: 2.1380391915639243

Epoch: 6| Step: 11
Training loss: 2.4006285667419434
Validation loss: 2.1318862438201904

Epoch: 6| Step: 12
Training loss: 1.9085348844528198
Validation loss: 2.1285235484441123

Epoch: 6| Step: 13
Training loss: 1.248077154159546
Validation loss: 2.1271985371907554

Epoch: 289| Step: 0
Training loss: 2.1636290550231934
Validation loss: 2.144045412540436

Epoch: 6| Step: 1
Training loss: 1.5041899681091309
Validation loss: 2.1346189379692078

Epoch: 6| Step: 2
Training loss: 1.7958433628082275
Validation loss: 2.1432745854059854

Epoch: 6| Step: 3
Training loss: 1.3172324895858765
Validation loss: 2.155155897140503

Epoch: 6| Step: 4
Training loss: 2.3693013191223145
Validation loss: 2.13767546415329

Epoch: 6| Step: 5
Training loss: 0.849297285079956
Validation loss: 2.1590346495310464

Epoch: 6| Step: 6
Training loss: 1.2628384828567505
Validation loss: 2.1245641311009726

Epoch: 6| Step: 7
Training loss: 1.6345138549804688
Validation loss: 2.1445387800534568

Epoch: 6| Step: 8
Training loss: 0.9435939788818359
Validation loss: 2.137852350870768

Epoch: 6| Step: 9
Training loss: 1.1214628219604492
Validation loss: 2.1285669803619385

Epoch: 6| Step: 10
Training loss: 1.422105312347412
Validation loss: 2.1405909856160483

Epoch: 6| Step: 11
Training loss: 1.4729197025299072
Validation loss: 2.153843661149343

Epoch: 6| Step: 12
Training loss: 1.5427814722061157
Validation loss: 2.183423082033793

Epoch: 6| Step: 13
Training loss: 2.3633928298950195
Validation loss: 2.1537028352419534

Epoch: 290| Step: 0
Training loss: 1.521627426147461
Validation loss: 2.1664327581723533

Epoch: 6| Step: 1
Training loss: 0.9937756061553955
Validation loss: 2.1923649509747825

Epoch: 6| Step: 2
Training loss: 1.1228216886520386
Validation loss: 2.171671152114868

Epoch: 6| Step: 3
Training loss: 2.2465529441833496
Validation loss: 2.180980920791626

Epoch: 6| Step: 4
Training loss: 1.6461758613586426
Validation loss: 2.179744223753611

Epoch: 6| Step: 5
Training loss: 1.3303909301757812
Validation loss: 2.172515014807383

Epoch: 6| Step: 6
Training loss: 1.818041443824768
Validation loss: 2.1577097376187644

Epoch: 6| Step: 7
Training loss: 2.0874133110046387
Validation loss: 2.14845609664917

Epoch: 6| Step: 8
Training loss: 1.2445627450942993
Validation loss: 2.1423014203707376

Epoch: 6| Step: 9
Training loss: 1.9973347187042236
Validation loss: 2.1344772974650064

Epoch: 6| Step: 10
Training loss: 1.7040326595306396
Validation loss: 2.1742180585861206

Epoch: 6| Step: 11
Training loss: 1.1306792497634888
Validation loss: 2.1425969203313193

Epoch: 6| Step: 12
Training loss: 1.5592010021209717
Validation loss: 2.1671694119771323

Epoch: 6| Step: 13
Training loss: 1.47060227394104
Validation loss: 2.164204994837443

Epoch: 291| Step: 0
Training loss: 1.3743581771850586
Validation loss: 2.1462009151776633

Epoch: 6| Step: 1
Training loss: 1.7819766998291016
Validation loss: 2.140973130861918

Epoch: 6| Step: 2
Training loss: 1.4316383600234985
Validation loss: 2.1616657773653665

Epoch: 6| Step: 3
Training loss: 1.7207149267196655
Validation loss: 2.1497089862823486

Epoch: 6| Step: 4
Training loss: 1.4109210968017578
Validation loss: 2.1693078875541687

Epoch: 6| Step: 5
Training loss: 1.8566042184829712
Validation loss: 2.173443853855133

Epoch: 6| Step: 6
Training loss: 2.102614402770996
Validation loss: 2.1716022888819375

Epoch: 6| Step: 7
Training loss: 0.8976876139640808
Validation loss: 2.170000950495402

Epoch: 6| Step: 8
Training loss: 1.7783162593841553
Validation loss: 2.18048103650411

Epoch: 6| Step: 9
Training loss: 1.2151153087615967
Validation loss: 2.17583829164505

Epoch: 6| Step: 10
Training loss: 1.1442439556121826
Validation loss: 2.2123807072639465

Epoch: 6| Step: 11
Training loss: 1.4257915019989014
Validation loss: 2.1932507356007895

Epoch: 6| Step: 12
Training loss: 1.965049147605896
Validation loss: 2.208739439646403

Epoch: 6| Step: 13
Training loss: 1.4191153049468994
Validation loss: 2.2162498831748962

Epoch: 292| Step: 0
Training loss: 1.4816241264343262
Validation loss: 2.1975833574930825

Epoch: 6| Step: 1
Training loss: 2.210993766784668
Validation loss: 2.1725839972496033

Epoch: 6| Step: 2
Training loss: 1.7233314514160156
Validation loss: 2.1901904940605164

Epoch: 6| Step: 3
Training loss: 1.8780083656311035
Validation loss: 2.1841651598612466

Epoch: 6| Step: 4
Training loss: 1.1206626892089844
Validation loss: 2.1944618026415506

Epoch: 6| Step: 5
Training loss: 1.4816703796386719
Validation loss: 2.191530247529348

Epoch: 6| Step: 6
Training loss: 1.5292229652404785
Validation loss: 2.1885419289271035

Epoch: 6| Step: 7
Training loss: 1.565202236175537
Validation loss: 2.1758585572242737

Epoch: 6| Step: 8
Training loss: 1.387345314025879
Validation loss: 2.190117915471395

Epoch: 6| Step: 9
Training loss: 1.5345227718353271
Validation loss: 2.1581552823384604

Epoch: 6| Step: 10
Training loss: 1.3791499137878418
Validation loss: 2.1531535188357034

Epoch: 6| Step: 11
Training loss: 1.1318506002426147
Validation loss: 2.168907423814138

Epoch: 6| Step: 12
Training loss: 1.372277021408081
Validation loss: 2.1705239613850913

Epoch: 6| Step: 13
Training loss: 1.235066294670105
Validation loss: 2.1779678662618003

Epoch: 293| Step: 0
Training loss: 1.2045371532440186
Validation loss: 2.1483667890230813

Epoch: 6| Step: 1
Training loss: 1.4561395645141602
Validation loss: 2.1732574701309204

Epoch: 6| Step: 2
Training loss: 1.9687752723693848
Validation loss: 2.1753671566645303

Epoch: 6| Step: 3
Training loss: 1.2382729053497314
Validation loss: 2.187961200873057

Epoch: 6| Step: 4
Training loss: 1.4358497858047485
Validation loss: 2.161419610182444

Epoch: 6| Step: 5
Training loss: 1.383352279663086
Validation loss: 2.1779372692108154

Epoch: 6| Step: 6
Training loss: 1.6803611516952515
Validation loss: 2.1814470092455545

Epoch: 6| Step: 7
Training loss: 2.043436050415039
Validation loss: 2.196427861849467

Epoch: 6| Step: 8
Training loss: 1.8776354789733887
Validation loss: 2.1556551456451416

Epoch: 6| Step: 9
Training loss: 1.4407517910003662
Validation loss: 2.1556317607561746

Epoch: 6| Step: 10
Training loss: 1.040397047996521
Validation loss: 2.1650774280230203

Epoch: 6| Step: 11
Training loss: 2.0812501907348633
Validation loss: 2.187746544679006

Epoch: 6| Step: 12
Training loss: 1.510735273361206
Validation loss: 2.151043256123861

Epoch: 6| Step: 13
Training loss: 1.2157543897628784
Validation loss: 2.170900305112203

Epoch: 294| Step: 0
Training loss: 1.2324533462524414
Validation loss: 2.167888363202413

Epoch: 6| Step: 1
Training loss: 1.6670570373535156
Validation loss: 2.1856335202852883

Epoch: 6| Step: 2
Training loss: 1.583128809928894
Validation loss: 2.1877777179082236

Epoch: 6| Step: 3
Training loss: 1.5797921419143677
Validation loss: 2.180729647477468

Epoch: 6| Step: 4
Training loss: 1.6464837789535522
Validation loss: 2.192106286684672

Epoch: 6| Step: 5
Training loss: 0.965206503868103
Validation loss: 2.1810630361239114

Epoch: 6| Step: 6
Training loss: 1.2169091701507568
Validation loss: 2.1828211347262063

Epoch: 6| Step: 7
Training loss: 2.0252838134765625
Validation loss: 2.1837252378463745

Epoch: 6| Step: 8
Training loss: 1.4030027389526367
Validation loss: 2.178346832593282

Epoch: 6| Step: 9
Training loss: 1.7346042394638062
Validation loss: 2.139992376168569

Epoch: 6| Step: 10
Training loss: 2.0249404907226562
Validation loss: 2.1666078170140586

Epoch: 6| Step: 11
Training loss: 1.1129224300384521
Validation loss: 2.1549220085144043

Epoch: 6| Step: 12
Training loss: 2.1916329860687256
Validation loss: 2.1630762020746865

Epoch: 6| Step: 13
Training loss: 1.8793339729309082
Validation loss: 2.185721437136332

Epoch: 295| Step: 0
Training loss: 2.319060802459717
Validation loss: 2.1735260486602783

Epoch: 6| Step: 1
Training loss: 1.774641990661621
Validation loss: 2.1722187598546348

Epoch: 6| Step: 2
Training loss: 1.076067566871643
Validation loss: 2.1507644057273865

Epoch: 6| Step: 3
Training loss: 0.9403421878814697
Validation loss: 2.147554417451223

Epoch: 6| Step: 4
Training loss: 1.185426115989685
Validation loss: 2.160335123538971

Epoch: 6| Step: 5
Training loss: 1.8784499168395996
Validation loss: 2.17363832394282

Epoch: 6| Step: 6
Training loss: 1.2455506324768066
Validation loss: 2.1712899406751

Epoch: 6| Step: 7
Training loss: 0.9342888593673706
Validation loss: 2.1642749905586243

Epoch: 6| Step: 8
Training loss: 1.2289118766784668
Validation loss: 2.1465717355410256

Epoch: 6| Step: 9
Training loss: 1.9557082653045654
Validation loss: 2.1735408902168274

Epoch: 6| Step: 10
Training loss: 1.3817874193191528
Validation loss: 2.1471890012423196

Epoch: 6| Step: 11
Training loss: 1.9070172309875488
Validation loss: 2.126224080721537

Epoch: 6| Step: 12
Training loss: 1.6191753149032593
Validation loss: 2.1175644199053445

Epoch: 6| Step: 13
Training loss: 1.8450067043304443
Validation loss: 2.1205811897913613

Epoch: 296| Step: 0
Training loss: 2.763484477996826
Validation loss: 2.1526031692822776

Epoch: 6| Step: 1
Training loss: 1.191867470741272
Validation loss: 2.1490930120150247

Epoch: 6| Step: 2
Training loss: 1.4087483882904053
Validation loss: 2.1621994972229004

Epoch: 6| Step: 3
Training loss: 1.5527300834655762
Validation loss: 2.176353911558787

Epoch: 6| Step: 4
Training loss: 1.010462760925293
Validation loss: 2.158154527346293

Epoch: 6| Step: 5
Training loss: 1.6721537113189697
Validation loss: 2.153885801633199

Epoch: 6| Step: 6
Training loss: 1.5569428205490112
Validation loss: 2.1537117759386697

Epoch: 6| Step: 7
Training loss: 1.7941620349884033
Validation loss: 2.1726362307866416

Epoch: 6| Step: 8
Training loss: 1.758061170578003
Validation loss: 2.165407121181488

Epoch: 6| Step: 9
Training loss: 1.3524410724639893
Validation loss: 2.16199654340744

Epoch: 6| Step: 10
Training loss: 1.236498475074768
Validation loss: 2.1710169315338135

Epoch: 6| Step: 11
Training loss: 1.6786935329437256
Validation loss: 2.142603874206543

Epoch: 6| Step: 12
Training loss: 1.688302755355835
Validation loss: 2.138816754023234

Epoch: 6| Step: 13
Training loss: 1.510218858718872
Validation loss: 2.1350841720898948

Epoch: 297| Step: 0
Training loss: 1.1892246007919312
Validation loss: 2.121399919191996

Epoch: 6| Step: 1
Training loss: 1.30619478225708
Validation loss: 2.0870371063550315

Epoch: 6| Step: 2
Training loss: 1.773429036140442
Validation loss: 2.1006455620129905

Epoch: 6| Step: 3
Training loss: 1.0730504989624023
Validation loss: 2.1169135570526123

Epoch: 6| Step: 4
Training loss: 1.1972122192382812
Validation loss: 2.1169093251228333

Epoch: 6| Step: 5
Training loss: 1.944725751876831
Validation loss: 2.154765546321869

Epoch: 6| Step: 6
Training loss: 1.3965184688568115
Validation loss: 2.1504027048746743

Epoch: 6| Step: 7
Training loss: 1.2889503240585327
Validation loss: 2.1664368510246277

Epoch: 6| Step: 8
Training loss: 1.9359875917434692
Validation loss: 2.1770384709040322

Epoch: 6| Step: 9
Training loss: 1.8260276317596436
Validation loss: 2.1682045261065164

Epoch: 6| Step: 10
Training loss: 2.2203545570373535
Validation loss: 2.169819176197052

Epoch: 6| Step: 11
Training loss: 1.2688026428222656
Validation loss: 2.184567908445994

Epoch: 6| Step: 12
Training loss: 1.9745872020721436
Validation loss: 2.152662436167399

Epoch: 6| Step: 13
Training loss: 1.5224239826202393
Validation loss: 2.219594498475393

Epoch: 298| Step: 0
Training loss: 1.4381266832351685
Validation loss: 2.1751525600751243

Epoch: 6| Step: 1
Training loss: 2.0559496879577637
Validation loss: 2.217219372590383

Epoch: 6| Step: 2
Training loss: 1.4395794868469238
Validation loss: 2.2023242513338723

Epoch: 6| Step: 3
Training loss: 0.7311033010482788
Validation loss: 2.180367648601532

Epoch: 6| Step: 4
Training loss: 1.2812761068344116
Validation loss: 2.1943166255950928

Epoch: 6| Step: 5
Training loss: 1.508108377456665
Validation loss: 2.202334443728129

Epoch: 6| Step: 6
Training loss: 1.0024876594543457
Validation loss: 2.1911238034566245

Epoch: 6| Step: 7
Training loss: 1.110384464263916
Validation loss: 2.20345272620519

Epoch: 6| Step: 8
Training loss: 1.4679558277130127
Validation loss: 2.20027756690979

Epoch: 6| Step: 9
Training loss: 1.6563067436218262
Validation loss: 2.19252739350001

Epoch: 6| Step: 10
Training loss: 2.410367250442505
Validation loss: 2.2131824493408203

Epoch: 6| Step: 11
Training loss: 1.549661636352539
Validation loss: 2.1971890727678933

Epoch: 6| Step: 12
Training loss: 2.0689432621002197
Validation loss: 2.229351202646891

Epoch: 6| Step: 13
Training loss: 1.272945761680603
Validation loss: 2.2071433464686074

Epoch: 299| Step: 0
Training loss: 0.943401575088501
Validation loss: 2.2027133901913962

Epoch: 6| Step: 1
Training loss: 1.3967845439910889
Validation loss: 2.2133823235829673

Epoch: 6| Step: 2
Training loss: 0.885870099067688
Validation loss: 2.2059327761332193

Epoch: 6| Step: 3
Training loss: 1.705072283744812
Validation loss: 2.2085375785827637

Epoch: 6| Step: 4
Training loss: 1.0422313213348389
Validation loss: 2.2258543968200684

Epoch: 6| Step: 5
Training loss: 1.276925802230835
Validation loss: 2.198536475499471

Epoch: 6| Step: 6
Training loss: 1.9568185806274414
Validation loss: 2.219104210535685

Epoch: 6| Step: 7
Training loss: 1.5574119091033936
Validation loss: 2.172510047753652

Epoch: 6| Step: 8
Training loss: 1.4262100458145142
Validation loss: 2.215944766998291

Epoch: 6| Step: 9
Training loss: 2.1047275066375732
Validation loss: 2.20647140343984

Epoch: 6| Step: 10
Training loss: 2.062208414077759
Validation loss: 2.2001092433929443

Epoch: 6| Step: 11
Training loss: 1.216481328010559
Validation loss: 2.198823650677999

Epoch: 6| Step: 12
Training loss: 1.600630283355713
Validation loss: 2.196059008439382

Epoch: 6| Step: 13
Training loss: 1.3139256238937378
Validation loss: 2.1939452091852822

Epoch: 300| Step: 0
Training loss: 2.462527275085449
Validation loss: 2.1767090559005737

Epoch: 6| Step: 1
Training loss: 1.177740216255188
Validation loss: 2.1945390502611795

Epoch: 6| Step: 2
Training loss: 1.6640934944152832
Validation loss: 2.1813199718793235

Epoch: 6| Step: 3
Training loss: 1.8052035570144653
Validation loss: 2.2026389241218567

Epoch: 6| Step: 4
Training loss: 1.6542226076126099
Validation loss: 2.2153408328692117

Epoch: 6| Step: 5
Training loss: 1.9562228918075562
Validation loss: 2.1810372471809387

Epoch: 6| Step: 6
Training loss: 1.4288078546524048
Validation loss: 2.198412756125132

Epoch: 6| Step: 7
Training loss: 1.4538509845733643
Validation loss: 2.226646145184835

Epoch: 6| Step: 8
Training loss: 1.060523271560669
Validation loss: 2.2147815028826394

Epoch: 6| Step: 9
Training loss: 0.9874635934829712
Validation loss: 2.1919928590456643

Epoch: 6| Step: 10
Training loss: 0.8991395831108093
Validation loss: 2.19368044535319

Epoch: 6| Step: 11
Training loss: 1.6174120903015137
Validation loss: 2.186551849047343

Epoch: 6| Step: 12
Training loss: 1.404344081878662
Validation loss: 2.1281919479370117

Epoch: 6| Step: 13
Training loss: 1.6649181842803955
Validation loss: 2.1296250224113464

Epoch: 301| Step: 0
Training loss: 1.8231720924377441
Validation loss: 2.1611927151679993

Epoch: 6| Step: 1
Training loss: 1.6363286972045898
Validation loss: 2.1441504756609597

Epoch: 6| Step: 2
Training loss: 1.4228708744049072
Validation loss: 2.1553263465563455

Epoch: 6| Step: 3
Training loss: 1.8278450965881348
Validation loss: 2.1801074544588723

Epoch: 6| Step: 4
Training loss: 1.4328508377075195
Validation loss: 2.1894906163215637

Epoch: 6| Step: 5
Training loss: 1.9664280414581299
Validation loss: 2.1838907599449158

Epoch: 6| Step: 6
Training loss: 1.2215063571929932
Validation loss: 2.169746160507202

Epoch: 6| Step: 7
Training loss: 2.346449375152588
Validation loss: 2.1456212600072226

Epoch: 6| Step: 8
Training loss: 2.0444726943969727
Validation loss: 2.160876452922821

Epoch: 6| Step: 9
Training loss: 1.6481997966766357
Validation loss: 2.1201006372769675

Epoch: 6| Step: 10
Training loss: 1.2852451801300049
Validation loss: 2.1214081048965454

Epoch: 6| Step: 11
Training loss: 1.1768279075622559
Validation loss: 2.1206129789352417

Epoch: 6| Step: 12
Training loss: 0.9352990388870239
Validation loss: 2.1344521244366965

Epoch: 6| Step: 13
Training loss: 1.0122095346450806
Validation loss: 2.1511041720708213

Epoch: 302| Step: 0
Training loss: 2.0510854721069336
Validation loss: 2.130881110827128

Epoch: 6| Step: 1
Training loss: 1.2839874029159546
Validation loss: 2.1324716210365295

Epoch: 6| Step: 2
Training loss: 0.9708362817764282
Validation loss: 2.159265617529551

Epoch: 6| Step: 3
Training loss: 0.940799355506897
Validation loss: 2.141641596953074

Epoch: 6| Step: 4
Training loss: 1.1696712970733643
Validation loss: 2.1490365664164224

Epoch: 6| Step: 5
Training loss: 1.1039555072784424
Validation loss: 2.145163277784983

Epoch: 6| Step: 6
Training loss: 2.078857421875
Validation loss: 2.192662298679352

Epoch: 6| Step: 7
Training loss: 1.4872068166732788
Validation loss: 2.1625409722328186

Epoch: 6| Step: 8
Training loss: 1.5893186330795288
Validation loss: 2.175791064898173

Epoch: 6| Step: 9
Training loss: 1.5584585666656494
Validation loss: 2.1786261995633445

Epoch: 6| Step: 10
Training loss: 1.3469057083129883
Validation loss: 2.174887200196584

Epoch: 6| Step: 11
Training loss: 1.4658865928649902
Validation loss: 2.1830150286356607

Epoch: 6| Step: 12
Training loss: 2.009122610092163
Validation loss: 2.1749773422876992

Epoch: 6| Step: 13
Training loss: 1.2688324451446533
Validation loss: 2.174123167991638

Epoch: 303| Step: 0
Training loss: 1.2388635873794556
Validation loss: 2.1802603602409363

Epoch: 6| Step: 1
Training loss: 1.9859825372695923
Validation loss: 2.1499772866566977

Epoch: 6| Step: 2
Training loss: 2.1174368858337402
Validation loss: 2.1384424567222595

Epoch: 6| Step: 3
Training loss: 1.2763988971710205
Validation loss: 2.15876297156016

Epoch: 6| Step: 4
Training loss: 0.5431216955184937
Validation loss: 2.1739367246627808

Epoch: 6| Step: 5
Training loss: 2.051494598388672
Validation loss: 2.169697880744934

Epoch: 6| Step: 6
Training loss: 1.1094491481781006
Validation loss: 2.17266309261322

Epoch: 6| Step: 7
Training loss: 1.3893957138061523
Validation loss: 2.1505104303359985

Epoch: 6| Step: 8
Training loss: 1.5582530498504639
Validation loss: 2.1670961578687034

Epoch: 6| Step: 9
Training loss: 1.6355934143066406
Validation loss: 2.1546053687731423

Epoch: 6| Step: 10
Training loss: 1.7213239669799805
Validation loss: 2.142679830392202

Epoch: 6| Step: 11
Training loss: 1.5236749649047852
Validation loss: 2.1556245485941568

Epoch: 6| Step: 12
Training loss: 1.0188872814178467
Validation loss: 2.198518435160319

Epoch: 6| Step: 13
Training loss: 1.799475908279419
Validation loss: 2.201579670111338

Epoch: 304| Step: 0
Training loss: 1.7688102722167969
Validation loss: 2.199321707089742

Epoch: 6| Step: 1
Training loss: 1.5043621063232422
Validation loss: 2.1926444371541343

Epoch: 6| Step: 2
Training loss: 1.5956014394760132
Validation loss: 2.239873250325521

Epoch: 6| Step: 3
Training loss: 1.716079831123352
Validation loss: 2.2224459846814475

Epoch: 6| Step: 4
Training loss: 2.1769134998321533
Validation loss: 2.2672409216562905

Epoch: 6| Step: 5
Training loss: 1.4087624549865723
Validation loss: 2.2758291165033975

Epoch: 6| Step: 6
Training loss: 0.9190587997436523
Validation loss: 2.255978763103485

Epoch: 6| Step: 7
Training loss: 1.2555217742919922
Validation loss: 2.2090064684549966

Epoch: 6| Step: 8
Training loss: 1.8239538669586182
Validation loss: 2.1587926944096885

Epoch: 6| Step: 9
Training loss: 1.4499804973602295
Validation loss: 2.167280435562134

Epoch: 6| Step: 10
Training loss: 1.2679355144500732
Validation loss: 2.17978169520696

Epoch: 6| Step: 11
Training loss: 1.1381714344024658
Validation loss: 2.17695552110672

Epoch: 6| Step: 12
Training loss: 1.811295509338379
Validation loss: 2.193948050340017

Epoch: 6| Step: 13
Training loss: 1.6210927963256836
Validation loss: 2.1887885530789695

Epoch: 305| Step: 0
Training loss: 1.936564326286316
Validation loss: 2.2120341857274375

Epoch: 6| Step: 1
Training loss: 1.4039280414581299
Validation loss: 2.230518023173014

Epoch: 6| Step: 2
Training loss: 1.2530035972595215
Validation loss: 2.2229467034339905

Epoch: 6| Step: 3
Training loss: 2.238436698913574
Validation loss: 2.1782788832982383

Epoch: 6| Step: 4
Training loss: 1.0435212850570679
Validation loss: 2.167228619257609

Epoch: 6| Step: 5
Training loss: 1.3722221851348877
Validation loss: 2.1650845209757485

Epoch: 6| Step: 6
Training loss: 1.7483375072479248
Validation loss: 2.1723246375719705

Epoch: 6| Step: 7
Training loss: 1.57505202293396
Validation loss: 2.1655507683753967

Epoch: 6| Step: 8
Training loss: 1.6087510585784912
Validation loss: 2.1740264296531677

Epoch: 6| Step: 9
Training loss: 1.0993614196777344
Validation loss: 2.156282921632131

Epoch: 6| Step: 10
Training loss: 1.3395421504974365
Validation loss: 2.1778292655944824

Epoch: 6| Step: 11
Training loss: 1.2903523445129395
Validation loss: 2.1853026151657104

Epoch: 6| Step: 12
Training loss: 1.395653247833252
Validation loss: 2.1783029635747275

Epoch: 6| Step: 13
Training loss: 1.611495852470398
Validation loss: 2.193285584449768

Epoch: 306| Step: 0
Training loss: 1.3956323862075806
Validation loss: 2.1961719195048013

Epoch: 6| Step: 1
Training loss: 1.745398998260498
Validation loss: 2.2064722379048667

Epoch: 6| Step: 2
Training loss: 1.4781945943832397
Validation loss: 2.2270534435908

Epoch: 6| Step: 3
Training loss: 1.5838441848754883
Validation loss: 2.2221357425053916

Epoch: 6| Step: 4
Training loss: 1.562312126159668
Validation loss: 2.2192410628000894

Epoch: 6| Step: 5
Training loss: 1.2197365760803223
Validation loss: 2.234071433544159

Epoch: 6| Step: 6
Training loss: 0.8718380331993103
Validation loss: 2.2204611897468567

Epoch: 6| Step: 7
Training loss: 1.7435879707336426
Validation loss: 2.252629359563192

Epoch: 6| Step: 8
Training loss: 1.6861268281936646
Validation loss: 2.2278658946355185

Epoch: 6| Step: 9
Training loss: 0.8304027915000916
Validation loss: 2.21019846200943

Epoch: 6| Step: 10
Training loss: 1.706507682800293
Validation loss: 2.207308351993561

Epoch: 6| Step: 11
Training loss: 1.6977105140686035
Validation loss: 2.225356419881185

Epoch: 6| Step: 12
Training loss: 1.2701990604400635
Validation loss: 2.219853639602661

Epoch: 6| Step: 13
Training loss: 1.769761323928833
Validation loss: 2.2174165646235147

Epoch: 307| Step: 0
Training loss: 1.5608811378479004
Validation loss: 2.218145708243052

Epoch: 6| Step: 1
Training loss: 1.5295650959014893
Validation loss: 2.2059189875920615

Epoch: 6| Step: 2
Training loss: 1.7720816135406494
Validation loss: 2.190844396750132

Epoch: 6| Step: 3
Training loss: 1.7074085474014282
Validation loss: 2.2079103589057922

Epoch: 6| Step: 4
Training loss: 1.1114203929901123
Validation loss: 2.1847215493520102

Epoch: 6| Step: 5
Training loss: 1.8558326959609985
Validation loss: 2.182316243648529

Epoch: 6| Step: 6
Training loss: 2.120068073272705
Validation loss: 2.1542559067408242

Epoch: 6| Step: 7
Training loss: 1.5844132900238037
Validation loss: 2.194452087084452

Epoch: 6| Step: 8
Training loss: 1.2792919874191284
Validation loss: 2.1751156051953635

Epoch: 6| Step: 9
Training loss: 1.7656714916229248
Validation loss: 2.220914681752523

Epoch: 6| Step: 10
Training loss: 0.9438828229904175
Validation loss: 2.2567281325658164

Epoch: 6| Step: 11
Training loss: 0.8982111215591431
Validation loss: 2.2232790986696878

Epoch: 6| Step: 12
Training loss: 1.3923035860061646
Validation loss: 2.2207754055658975

Epoch: 6| Step: 13
Training loss: 1.9265179634094238
Validation loss: 2.180584212144216

Epoch: 308| Step: 0
Training loss: 1.725051760673523
Validation loss: 2.1699177821477256

Epoch: 6| Step: 1
Training loss: 1.325553059577942
Validation loss: 2.1702378193537393

Epoch: 6| Step: 2
Training loss: 1.106204867362976
Validation loss: 2.1191665530204773

Epoch: 6| Step: 3
Training loss: 1.5543605089187622
Validation loss: 2.167993744214376

Epoch: 6| Step: 4
Training loss: 1.5336246490478516
Validation loss: 2.1574506163597107

Epoch: 6| Step: 5
Training loss: 1.933034896850586
Validation loss: 2.1638748248418174

Epoch: 6| Step: 6
Training loss: 1.033978819847107
Validation loss: 2.1615756948788962

Epoch: 6| Step: 7
Training loss: 1.7567954063415527
Validation loss: 2.179192821184794

Epoch: 6| Step: 8
Training loss: 2.0854640007019043
Validation loss: 2.1551403999328613

Epoch: 6| Step: 9
Training loss: 1.6083933115005493
Validation loss: 2.1682525873184204

Epoch: 6| Step: 10
Training loss: 1.926444411277771
Validation loss: 2.155816654364268

Epoch: 6| Step: 11
Training loss: 1.1282107830047607
Validation loss: 2.154953638712565

Epoch: 6| Step: 12
Training loss: 1.8386335372924805
Validation loss: 2.1323702335357666

Epoch: 6| Step: 13
Training loss: 0.6524549126625061
Validation loss: 2.148591081301371

Epoch: 309| Step: 0
Training loss: 1.3320649862289429
Validation loss: 2.1062065164248147

Epoch: 6| Step: 1
Training loss: 1.2004907131195068
Validation loss: 2.128860274950663

Epoch: 6| Step: 2
Training loss: 1.44649338722229
Validation loss: 2.1483482917149863

Epoch: 6| Step: 3
Training loss: 2.345928192138672
Validation loss: 2.1369630495707193

Epoch: 6| Step: 4
Training loss: 1.233717679977417
Validation loss: 2.1563740968704224

Epoch: 6| Step: 5
Training loss: 1.3557450771331787
Validation loss: 2.1828439831733704

Epoch: 6| Step: 6
Training loss: 2.1346426010131836
Validation loss: 2.175544798374176

Epoch: 6| Step: 7
Training loss: 0.9768697023391724
Validation loss: 2.187621076901754

Epoch: 6| Step: 8
Training loss: 1.4765886068344116
Validation loss: 2.18195116519928

Epoch: 6| Step: 9
Training loss: 1.4398677349090576
Validation loss: 2.1684573690096536

Epoch: 6| Step: 10
Training loss: 1.2558066844940186
Validation loss: 2.18509833017985

Epoch: 6| Step: 11
Training loss: 0.5748087167739868
Validation loss: 2.1858282486597695

Epoch: 6| Step: 12
Training loss: 2.135000705718994
Validation loss: 2.1951922178268433

Epoch: 6| Step: 13
Training loss: 1.4594794511795044
Validation loss: 2.208172619342804

Epoch: 310| Step: 0
Training loss: 1.3647866249084473
Validation loss: 2.187220593293508

Epoch: 6| Step: 1
Training loss: 1.0688865184783936
Validation loss: 2.182320535182953

Epoch: 6| Step: 2
Training loss: 1.6506797075271606
Validation loss: 2.1632439295450845

Epoch: 6| Step: 3
Training loss: 1.2013384103775024
Validation loss: 2.16790505250295

Epoch: 6| Step: 4
Training loss: 1.111565351486206
Validation loss: 2.1727139353752136

Epoch: 6| Step: 5
Training loss: 1.7531639337539673
Validation loss: 2.182595411936442

Epoch: 6| Step: 6
Training loss: 1.5297222137451172
Validation loss: 2.1674599051475525

Epoch: 6| Step: 7
Training loss: 1.4865809679031372
Validation loss: 2.182316780090332

Epoch: 6| Step: 8
Training loss: 1.066282033920288
Validation loss: 2.1717165311177573

Epoch: 6| Step: 9
Training loss: 1.5832788944244385
Validation loss: 2.1810768246650696

Epoch: 6| Step: 10
Training loss: 1.362264633178711
Validation loss: 2.2047811349232993

Epoch: 6| Step: 11
Training loss: 1.9480206966400146
Validation loss: 2.1976588368415833

Epoch: 6| Step: 12
Training loss: 1.4340546131134033
Validation loss: 2.185409108797709

Epoch: 6| Step: 13
Training loss: 1.452059268951416
Validation loss: 2.1712072094281516

Epoch: 311| Step: 0
Training loss: 1.1840283870697021
Validation loss: 2.1575138568878174

Epoch: 6| Step: 1
Training loss: 1.6259607076644897
Validation loss: 2.1575803756713867

Epoch: 6| Step: 2
Training loss: 1.2888314723968506
Validation loss: 2.1704986294110618

Epoch: 6| Step: 3
Training loss: 1.8957593441009521
Validation loss: 2.171000321706136

Epoch: 6| Step: 4
Training loss: 1.154639482498169
Validation loss: 2.1604113578796387

Epoch: 6| Step: 5
Training loss: 1.5935347080230713
Validation loss: 2.160576085249583

Epoch: 6| Step: 6
Training loss: 1.5633224248886108
Validation loss: 2.189156413078308

Epoch: 6| Step: 7
Training loss: 1.490451693534851
Validation loss: 2.153189202149709

Epoch: 6| Step: 8
Training loss: 1.2303776741027832
Validation loss: 2.200717031955719

Epoch: 6| Step: 9
Training loss: 1.7519207000732422
Validation loss: 2.171617945035299

Epoch: 6| Step: 10
Training loss: 1.6567150354385376
Validation loss: 2.1783374349276223

Epoch: 6| Step: 11
Training loss: 0.9357137680053711
Validation loss: 2.158802568912506

Epoch: 6| Step: 12
Training loss: 1.2479519844055176
Validation loss: 2.199472506841024

Epoch: 6| Step: 13
Training loss: 1.4309940338134766
Validation loss: 2.172608256340027

Epoch: 312| Step: 0
Training loss: 1.7437210083007812
Validation loss: 2.1956152518590293

Epoch: 6| Step: 1
Training loss: 1.5874803066253662
Validation loss: 2.1880218982696533

Epoch: 6| Step: 2
Training loss: 1.520545482635498
Validation loss: 2.1887426376342773

Epoch: 6| Step: 3
Training loss: 1.815300703048706
Validation loss: 2.1759723822275796

Epoch: 6| Step: 4
Training loss: 1.215315818786621
Validation loss: 2.1767859856287637

Epoch: 6| Step: 5
Training loss: 1.3905402421951294
Validation loss: 2.1586970686912537

Epoch: 6| Step: 6
Training loss: 1.5348255634307861
Validation loss: 2.20331339041392

Epoch: 6| Step: 7
Training loss: 1.634296178817749
Validation loss: 2.180828313032786

Epoch: 6| Step: 8
Training loss: 0.8654129505157471
Validation loss: 2.187101145585378

Epoch: 6| Step: 9
Training loss: 1.8956916332244873
Validation loss: 2.1754366954167685

Epoch: 6| Step: 10
Training loss: 0.6630122661590576
Validation loss: 2.2012609044710794

Epoch: 6| Step: 11
Training loss: 0.9117230772972107
Validation loss: 2.2148242394129434

Epoch: 6| Step: 12
Training loss: 1.5233579874038696
Validation loss: 2.23079913854599

Epoch: 6| Step: 13
Training loss: 1.1743555068969727
Validation loss: 2.223888377348582

Epoch: 313| Step: 0
Training loss: 1.2499003410339355
Validation loss: 2.236132860183716

Epoch: 6| Step: 1
Training loss: 0.7859268188476562
Validation loss: 2.2381919821103415

Epoch: 6| Step: 2
Training loss: 1.6200900077819824
Validation loss: 2.261391003926595

Epoch: 6| Step: 3
Training loss: 1.1976723670959473
Validation loss: 2.2567153374354043

Epoch: 6| Step: 4
Training loss: 1.4159101247787476
Validation loss: 2.250630338986715

Epoch: 6| Step: 5
Training loss: 2.093129873275757
Validation loss: 2.2375208934148154

Epoch: 6| Step: 6
Training loss: 2.1985397338867188
Validation loss: 2.2243316968282065

Epoch: 6| Step: 7
Training loss: 0.8770584464073181
Validation loss: 2.1914545694986978

Epoch: 6| Step: 8
Training loss: 1.3627572059631348
Validation loss: 2.2071398297945657

Epoch: 6| Step: 9
Training loss: 0.8379864692687988
Validation loss: 2.2170649766921997

Epoch: 6| Step: 10
Training loss: 2.134279251098633
Validation loss: 2.180424610773722

Epoch: 6| Step: 11
Training loss: 1.1996771097183228
Validation loss: 2.1961050629615784

Epoch: 6| Step: 12
Training loss: 1.350506067276001
Validation loss: 2.161531388759613

Epoch: 6| Step: 13
Training loss: 1.6645927429199219
Validation loss: 2.139087756474813

Epoch: 314| Step: 0
Training loss: 1.2665610313415527
Validation loss: 2.1572736303011575

Epoch: 6| Step: 1
Training loss: 1.096189260482788
Validation loss: 2.1307398478190103

Epoch: 6| Step: 2
Training loss: 1.4778203964233398
Validation loss: 2.0996724565823874

Epoch: 6| Step: 3
Training loss: 1.480006456375122
Validation loss: 2.0796448389689126

Epoch: 6| Step: 4
Training loss: 1.525212287902832
Validation loss: 2.1240696708361306

Epoch: 6| Step: 5
Training loss: 1.1593632698059082
Validation loss: 2.106510281562805

Epoch: 6| Step: 6
Training loss: 1.9919077157974243
Validation loss: 2.1346715490023294

Epoch: 6| Step: 7
Training loss: 0.9810677766799927
Validation loss: 2.1054505705833435

Epoch: 6| Step: 8
Training loss: 1.380251169204712
Validation loss: 2.129350205262502

Epoch: 6| Step: 9
Training loss: 1.4889965057373047
Validation loss: 2.116304953893026

Epoch: 6| Step: 10
Training loss: 1.3669564723968506
Validation loss: 2.147002160549164

Epoch: 6| Step: 11
Training loss: 1.5442806482315063
Validation loss: 2.1001251339912415

Epoch: 6| Step: 12
Training loss: 1.668455958366394
Validation loss: 2.1384217341740928

Epoch: 6| Step: 13
Training loss: 1.3662035465240479
Validation loss: 2.1327224572499595

Epoch: 315| Step: 0
Training loss: 1.8546805381774902
Validation loss: 2.155080040295919

Epoch: 6| Step: 1
Training loss: 1.2829961776733398
Validation loss: 2.1346382896105447

Epoch: 6| Step: 2
Training loss: 1.5180795192718506
Validation loss: 2.1507829427719116

Epoch: 6| Step: 3
Training loss: 1.4569594860076904
Validation loss: 2.1102484862009683

Epoch: 6| Step: 4
Training loss: 1.168505072593689
Validation loss: 2.123835504055023

Epoch: 6| Step: 5
Training loss: 1.123196005821228
Validation loss: 2.1362029314041138

Epoch: 6| Step: 6
Training loss: 2.1720499992370605
Validation loss: 2.141178627808889

Epoch: 6| Step: 7
Training loss: 1.2615786790847778
Validation loss: 2.1336816946665444

Epoch: 6| Step: 8
Training loss: 1.3921513557434082
Validation loss: 2.1563903292020163

Epoch: 6| Step: 9
Training loss: 1.4049979448318481
Validation loss: 2.1502340038617453

Epoch: 6| Step: 10
Training loss: 0.9751039743423462
Validation loss: 2.1611995895703635

Epoch: 6| Step: 11
Training loss: 1.5791701078414917
Validation loss: 2.1617013017336526

Epoch: 6| Step: 12
Training loss: 1.135886549949646
Validation loss: 2.15788068373998

Epoch: 6| Step: 13
Training loss: 1.297508716583252
Validation loss: 2.143932521343231

Epoch: 316| Step: 0
Training loss: 1.3094744682312012
Validation loss: 2.144114355246226

Epoch: 6| Step: 1
Training loss: 1.1446657180786133
Validation loss: 2.1745305260022483

Epoch: 6| Step: 2
Training loss: 1.3250941038131714
Validation loss: 2.1648053924242654

Epoch: 6| Step: 3
Training loss: 1.6855146884918213
Validation loss: 2.1587432622909546

Epoch: 6| Step: 4
Training loss: 1.82573401927948
Validation loss: 2.165488521258036

Epoch: 6| Step: 5
Training loss: 1.1914739608764648
Validation loss: 2.1478679180145264

Epoch: 6| Step: 6
Training loss: 0.8606442809104919
Validation loss: 2.197933077812195

Epoch: 6| Step: 7
Training loss: 1.4300694465637207
Validation loss: 2.180502971013387

Epoch: 6| Step: 8
Training loss: 1.4134516716003418
Validation loss: 2.185446858406067

Epoch: 6| Step: 9
Training loss: 1.3762857913970947
Validation loss: 2.1808162331581116

Epoch: 6| Step: 10
Training loss: 1.5067996978759766
Validation loss: 2.1481913328170776

Epoch: 6| Step: 11
Training loss: 1.2435753345489502
Validation loss: 2.121927281220754

Epoch: 6| Step: 12
Training loss: 1.9906702041625977
Validation loss: 2.141623238722483

Epoch: 6| Step: 13
Training loss: 1.1124370098114014
Validation loss: 2.1732062697410583

Epoch: 317| Step: 0
Training loss: 1.124957799911499
Validation loss: 2.1419971783955893

Epoch: 6| Step: 1
Training loss: 1.1758078336715698
Validation loss: 2.151669144630432

Epoch: 6| Step: 2
Training loss: 0.7809213399887085
Validation loss: 2.1496750116348267

Epoch: 6| Step: 3
Training loss: 0.8513506054878235
Validation loss: 2.151747544606527

Epoch: 6| Step: 4
Training loss: 1.8113688230514526
Validation loss: 2.1520970265070596

Epoch: 6| Step: 5
Training loss: 1.5689774751663208
Validation loss: 2.166682322820028

Epoch: 6| Step: 6
Training loss: 1.6311962604522705
Validation loss: 2.1919569770495095

Epoch: 6| Step: 7
Training loss: 1.8803247213363647
Validation loss: 2.1741260488828025

Epoch: 6| Step: 8
Training loss: 1.7561726570129395
Validation loss: 2.1741766730944314

Epoch: 6| Step: 9
Training loss: 1.2214536666870117
Validation loss: 2.1110968589782715

Epoch: 6| Step: 10
Training loss: 1.4054603576660156
Validation loss: 2.1529659430185952

Epoch: 6| Step: 11
Training loss: 1.748380422592163
Validation loss: 2.151157716910044

Epoch: 6| Step: 12
Training loss: 1.4960010051727295
Validation loss: 2.1234076619148254

Epoch: 6| Step: 13
Training loss: 1.3363672494888306
Validation loss: 2.1911664406458535

Epoch: 318| Step: 0
Training loss: 1.3871413469314575
Validation loss: 2.1826863487561545

Epoch: 6| Step: 1
Training loss: 1.199906349182129
Validation loss: 2.1760537226994834

Epoch: 6| Step: 2
Training loss: 1.1941337585449219
Validation loss: 2.183334787686666

Epoch: 6| Step: 3
Training loss: 1.476457118988037
Validation loss: 2.1736650466918945

Epoch: 6| Step: 4
Training loss: 2.227191925048828
Validation loss: 2.1767499446868896

Epoch: 6| Step: 5
Training loss: 1.7388014793395996
Validation loss: 2.1836458841959634

Epoch: 6| Step: 6
Training loss: 1.175308346748352
Validation loss: 2.193430165449778

Epoch: 6| Step: 7
Training loss: 1.1757065057754517
Validation loss: 2.1890785098075867

Epoch: 6| Step: 8
Training loss: 1.797789454460144
Validation loss: 2.155301868915558

Epoch: 6| Step: 9
Training loss: 0.624851644039154
Validation loss: 2.1580731670061746

Epoch: 6| Step: 10
Training loss: 1.4928476810455322
Validation loss: 2.190782984097799

Epoch: 6| Step: 11
Training loss: 0.7636623382568359
Validation loss: 2.1758684515953064

Epoch: 6| Step: 12
Training loss: 2.4062561988830566
Validation loss: 2.157392124334971

Epoch: 6| Step: 13
Training loss: 1.3016927242279053
Validation loss: 2.1587393283843994

Epoch: 319| Step: 0
Training loss: 2.041517972946167
Validation loss: 2.1653862794240317

Epoch: 6| Step: 1
Training loss: 1.5949994325637817
Validation loss: 2.158229430516561

Epoch: 6| Step: 2
Training loss: 1.216913104057312
Validation loss: 2.145208458105723

Epoch: 6| Step: 3
Training loss: 1.313094139099121
Validation loss: 2.1704736153284707

Epoch: 6| Step: 4
Training loss: 1.310178279876709
Validation loss: 2.170686105887095

Epoch: 6| Step: 5
Training loss: 1.4563764333724976
Validation loss: 2.1758828163146973

Epoch: 6| Step: 6
Training loss: 1.2713276147842407
Validation loss: 2.2025614182154336

Epoch: 6| Step: 7
Training loss: 0.712612509727478
Validation loss: 2.19050669670105

Epoch: 6| Step: 8
Training loss: 1.4470229148864746
Validation loss: 2.209420998891195

Epoch: 6| Step: 9
Training loss: 1.6750365495681763
Validation loss: 2.1946046352386475

Epoch: 6| Step: 10
Training loss: 1.3685803413391113
Validation loss: 2.1951350569725037

Epoch: 6| Step: 11
Training loss: 0.9335014820098877
Validation loss: 2.18383526802063

Epoch: 6| Step: 12
Training loss: 1.141998052597046
Validation loss: 2.194057524204254

Epoch: 6| Step: 13
Training loss: 1.6269222497940063
Validation loss: 2.182059903939565

Epoch: 320| Step: 0
Training loss: 0.8074160218238831
Validation loss: 2.1634615461031594

Epoch: 6| Step: 1
Training loss: 1.6061139106750488
Validation loss: 2.1692185203234353

Epoch: 6| Step: 2
Training loss: 1.6373069286346436
Validation loss: 2.1558202107747397

Epoch: 6| Step: 3
Training loss: 1.2837823629379272
Validation loss: 2.128064592679342

Epoch: 6| Step: 4
Training loss: 0.7841490507125854
Validation loss: 2.188968002796173

Epoch: 6| Step: 5
Training loss: 1.584173321723938
Validation loss: 2.164268732070923

Epoch: 6| Step: 6
Training loss: 0.8614401817321777
Validation loss: 2.1451439261436462

Epoch: 6| Step: 7
Training loss: 1.2907425165176392
Validation loss: 2.170233984788259

Epoch: 6| Step: 8
Training loss: 1.5195965766906738
Validation loss: 2.1712592442830405

Epoch: 6| Step: 9
Training loss: 1.762618064880371
Validation loss: 2.178609867890676

Epoch: 6| Step: 10
Training loss: 1.1499826908111572
Validation loss: 2.1655908823013306

Epoch: 6| Step: 11
Training loss: 0.9465248584747314
Validation loss: 2.152688225110372

Epoch: 6| Step: 12
Training loss: 1.3369660377502441
Validation loss: 2.157958706219991

Epoch: 6| Step: 13
Training loss: 2.351942300796509
Validation loss: 2.1524959802627563

Epoch: 321| Step: 0
Training loss: 1.258351445198059
Validation loss: 2.2011823654174805

Epoch: 6| Step: 1
Training loss: 1.4002957344055176
Validation loss: 2.18750262260437

Epoch: 6| Step: 2
Training loss: 1.396378993988037
Validation loss: 2.2266751527786255

Epoch: 6| Step: 3
Training loss: 1.6679697036743164
Validation loss: 2.2111586531003318

Epoch: 6| Step: 4
Training loss: 1.092848777770996
Validation loss: 2.219924569129944

Epoch: 6| Step: 5
Training loss: 2.294226884841919
Validation loss: 2.2016040484110513

Epoch: 6| Step: 6
Training loss: 1.348993182182312
Validation loss: 2.220306952794393

Epoch: 6| Step: 7
Training loss: 1.019355058670044
Validation loss: 2.228854457537333

Epoch: 6| Step: 8
Training loss: 1.4362943172454834
Validation loss: 2.20401531457901

Epoch: 6| Step: 9
Training loss: 1.1871281862258911
Validation loss: 2.2592567006746926

Epoch: 6| Step: 10
Training loss: 1.2899895906448364
Validation loss: 2.216210683186849

Epoch: 6| Step: 11
Training loss: 1.2959043979644775
Validation loss: 2.1806781689325967

Epoch: 6| Step: 12
Training loss: 1.2420915365219116
Validation loss: 2.1646140416463218

Epoch: 6| Step: 13
Training loss: 0.9667860269546509
Validation loss: 2.1585515340169272

Epoch: 322| Step: 0
Training loss: 1.4987828731536865
Validation loss: 2.137320657571157

Epoch: 6| Step: 1
Training loss: 1.4636187553405762
Validation loss: 2.147336264451345

Epoch: 6| Step: 2
Training loss: 1.3827862739562988
Validation loss: 2.1374515295028687

Epoch: 6| Step: 3
Training loss: 1.2274740934371948
Validation loss: 2.1526341438293457

Epoch: 6| Step: 4
Training loss: 1.6410999298095703
Validation loss: 2.1754510005315146

Epoch: 6| Step: 5
Training loss: 1.1998250484466553
Validation loss: 2.1730229258537292

Epoch: 6| Step: 6
Training loss: 0.7800421118736267
Validation loss: 2.1660372217496238

Epoch: 6| Step: 7
Training loss: 1.2879900932312012
Validation loss: 2.1526057521502175

Epoch: 6| Step: 8
Training loss: 1.9791831970214844
Validation loss: 2.1725775996843972

Epoch: 6| Step: 9
Training loss: 1.1666793823242188
Validation loss: 2.173021654287974

Epoch: 6| Step: 10
Training loss: 0.9919155240058899
Validation loss: 2.1619187196095786

Epoch: 6| Step: 11
Training loss: 1.0762115716934204
Validation loss: 2.1600189208984375

Epoch: 6| Step: 12
Training loss: 1.589355707168579
Validation loss: 2.135127325852712

Epoch: 6| Step: 13
Training loss: 1.6177427768707275
Validation loss: 2.1492079297701516

Epoch: 323| Step: 0
Training loss: 0.9864547252655029
Validation loss: 2.108462949593862

Epoch: 6| Step: 1
Training loss: 1.5595663785934448
Validation loss: 2.105014463265737

Epoch: 6| Step: 2
Training loss: 0.9480175971984863
Validation loss: 2.137611230214437

Epoch: 6| Step: 3
Training loss: 1.6219340562820435
Validation loss: 2.136267900466919

Epoch: 6| Step: 4
Training loss: 1.3530950546264648
Validation loss: 2.1365060011545816

Epoch: 6| Step: 5
Training loss: 0.9112470746040344
Validation loss: 2.121859927972158

Epoch: 6| Step: 6
Training loss: 0.7547391653060913
Validation loss: 2.1204641858736673

Epoch: 6| Step: 7
Training loss: 2.0204145908355713
Validation loss: 2.156452695528666

Epoch: 6| Step: 8
Training loss: 0.8382863402366638
Validation loss: 2.1718633572260537

Epoch: 6| Step: 9
Training loss: 1.1957288980484009
Validation loss: 2.173350751399994

Epoch: 6| Step: 10
Training loss: 1.6210017204284668
Validation loss: 2.156047821044922

Epoch: 6| Step: 11
Training loss: 1.2370860576629639
Validation loss: 2.192262649536133

Epoch: 6| Step: 12
Training loss: 2.231633186340332
Validation loss: 2.1691298683484397

Epoch: 6| Step: 13
Training loss: 1.3180205821990967
Validation loss: 2.1877808769543967

Epoch: 324| Step: 0
Training loss: 0.8633207082748413
Validation loss: 2.2131434281667075

Epoch: 6| Step: 1
Training loss: 1.027923583984375
Validation loss: 2.197565257549286

Epoch: 6| Step: 2
Training loss: 1.215902328491211
Validation loss: 2.1648049354553223

Epoch: 6| Step: 3
Training loss: 1.641187071800232
Validation loss: 2.192758937676748

Epoch: 6| Step: 4
Training loss: 1.2479467391967773
Validation loss: 2.2118966579437256

Epoch: 6| Step: 5
Training loss: 1.075458288192749
Validation loss: 2.172204077243805

Epoch: 6| Step: 6
Training loss: 1.0267720222473145
Validation loss: 2.1759498914082847

Epoch: 6| Step: 7
Training loss: 2.145659923553467
Validation loss: 2.1787264148394265

Epoch: 6| Step: 8
Training loss: 0.8950427770614624
Validation loss: 2.1923659443855286

Epoch: 6| Step: 9
Training loss: 1.7864409685134888
Validation loss: 2.1688724756240845

Epoch: 6| Step: 10
Training loss: 1.9586186408996582
Validation loss: 2.1710461179415383

Epoch: 6| Step: 11
Training loss: 1.2699353694915771
Validation loss: 2.1754466891288757

Epoch: 6| Step: 12
Training loss: 1.465816617012024
Validation loss: 2.1551092863082886

Epoch: 6| Step: 13
Training loss: 1.3368782997131348
Validation loss: 2.145530859629313

Epoch: 325| Step: 0
Training loss: 0.9553996324539185
Validation loss: 2.124590218067169

Epoch: 6| Step: 1
Training loss: 1.9058865308761597
Validation loss: 2.1621630986531577

Epoch: 6| Step: 2
Training loss: 1.5280718803405762
Validation loss: 2.1006293098131814

Epoch: 6| Step: 3
Training loss: 0.9871395230293274
Validation loss: 2.1035720904668174

Epoch: 6| Step: 4
Training loss: 1.2402576208114624
Validation loss: 2.1060074170430503

Epoch: 6| Step: 5
Training loss: 2.5981388092041016
Validation loss: 2.10153857866923

Epoch: 6| Step: 6
Training loss: 0.876737117767334
Validation loss: 2.1322818795839944

Epoch: 6| Step: 7
Training loss: 1.2693521976470947
Validation loss: 2.136697471141815

Epoch: 6| Step: 8
Training loss: 1.3744843006134033
Validation loss: 2.1352518995602927

Epoch: 6| Step: 9
Training loss: 1.4085956811904907
Validation loss: 2.0967983404795327

Epoch: 6| Step: 10
Training loss: 1.3544858694076538
Validation loss: 2.1034775972366333

Epoch: 6| Step: 11
Training loss: 1.306531310081482
Validation loss: 2.0994020899136863

Epoch: 6| Step: 12
Training loss: 1.5681748390197754
Validation loss: 2.098552485307058

Epoch: 6| Step: 13
Training loss: 0.8733896017074585
Validation loss: 2.136541485786438

Epoch: 326| Step: 0
Training loss: 1.0191515684127808
Validation loss: 2.1501912275950112

Epoch: 6| Step: 1
Training loss: 0.9202203154563904
Validation loss: 2.102235714594523

Epoch: 6| Step: 2
Training loss: 0.885367751121521
Validation loss: 2.1653671264648438

Epoch: 6| Step: 3
Training loss: 2.067178726196289
Validation loss: 2.1779284874598184

Epoch: 6| Step: 4
Training loss: 1.6356747150421143
Validation loss: 2.1508966088294983

Epoch: 6| Step: 5
Training loss: 1.6001605987548828
Validation loss: 2.149042864640554

Epoch: 6| Step: 6
Training loss: 1.1386430263519287
Validation loss: 2.1223646799723306

Epoch: 6| Step: 7
Training loss: 1.4022761583328247
Validation loss: 2.177285611629486

Epoch: 6| Step: 8
Training loss: 0.7490679025650024
Validation loss: 2.175266226132711

Epoch: 6| Step: 9
Training loss: 1.164961814880371
Validation loss: 2.1714529593785605

Epoch: 6| Step: 10
Training loss: 1.189202070236206
Validation loss: 2.1535964608192444

Epoch: 6| Step: 11
Training loss: 1.5084896087646484
Validation loss: 2.1465461254119873

Epoch: 6| Step: 12
Training loss: 1.377293586730957
Validation loss: 2.1892083287239075

Epoch: 6| Step: 13
Training loss: 1.8694789409637451
Validation loss: 2.1833610932032266

Epoch: 327| Step: 0
Training loss: 1.272386908531189
Validation loss: 2.2177803119023642

Epoch: 6| Step: 1
Training loss: 1.0196493864059448
Validation loss: 2.1522953708966575

Epoch: 6| Step: 2
Training loss: 1.7204581499099731
Validation loss: 2.174393355846405

Epoch: 6| Step: 3
Training loss: 1.0694096088409424
Validation loss: 2.1958200335502625

Epoch: 6| Step: 4
Training loss: 1.1054086685180664
Validation loss: 2.179447293281555

Epoch: 6| Step: 5
Training loss: 2.0361523628234863
Validation loss: 2.1654738982518515

Epoch: 6| Step: 6
Training loss: 1.1303610801696777
Validation loss: 2.170563558737437

Epoch: 6| Step: 7
Training loss: 1.162250280380249
Validation loss: 2.143427312374115

Epoch: 6| Step: 8
Training loss: 1.0848300457000732
Validation loss: 2.1523570815722146

Epoch: 6| Step: 9
Training loss: 1.8233180046081543
Validation loss: 2.1782740155855813

Epoch: 6| Step: 10
Training loss: 0.9802088737487793
Validation loss: 2.155127207438151

Epoch: 6| Step: 11
Training loss: 1.6729960441589355
Validation loss: 2.1470067898432412

Epoch: 6| Step: 12
Training loss: 1.2433955669403076
Validation loss: 2.1583825747172036

Epoch: 6| Step: 13
Training loss: 1.1002049446105957
Validation loss: 2.14176736275355

Epoch: 328| Step: 0
Training loss: 1.1236307621002197
Validation loss: 2.168733517328898

Epoch: 6| Step: 1
Training loss: 1.2895385026931763
Validation loss: 2.157492736975352

Epoch: 6| Step: 2
Training loss: 0.8216204643249512
Validation loss: 2.1261932055155435

Epoch: 6| Step: 3
Training loss: 0.877577543258667
Validation loss: 2.1662503480911255

Epoch: 6| Step: 4
Training loss: 1.5371782779693604
Validation loss: 2.1641876101493835

Epoch: 6| Step: 5
Training loss: 1.4427858591079712
Validation loss: 2.191760301589966

Epoch: 6| Step: 6
Training loss: 0.9973252415657043
Validation loss: 2.1695547898610434

Epoch: 6| Step: 7
Training loss: 2.070645570755005
Validation loss: 2.208892067273458

Epoch: 6| Step: 8
Training loss: 1.2960045337677002
Validation loss: 2.2019924322764077

Epoch: 6| Step: 9
Training loss: 0.7998490333557129
Validation loss: 2.1882205804189048

Epoch: 6| Step: 10
Training loss: 1.6112806797027588
Validation loss: 2.204148014386495

Epoch: 6| Step: 11
Training loss: 1.2133324146270752
Validation loss: 2.2288564840952554

Epoch: 6| Step: 12
Training loss: 1.5626907348632812
Validation loss: 2.19828466574351

Epoch: 6| Step: 13
Training loss: 1.3884645700454712
Validation loss: 2.2274663845698037

Epoch: 329| Step: 0
Training loss: 1.3229173421859741
Validation loss: 2.1996282935142517

Epoch: 6| Step: 1
Training loss: 1.4524693489074707
Validation loss: 2.1645743250846863

Epoch: 6| Step: 2
Training loss: 0.7707911729812622
Validation loss: 2.2118565440177917

Epoch: 6| Step: 3
Training loss: 1.3005542755126953
Validation loss: 2.197316805521647

Epoch: 6| Step: 4
Training loss: 2.299064874649048
Validation loss: 2.1706315080324807

Epoch: 6| Step: 5
Training loss: 1.1201773881912231
Validation loss: 2.1672915617624917

Epoch: 6| Step: 6
Training loss: 1.226431131362915
Validation loss: 2.1832812627156577

Epoch: 6| Step: 7
Training loss: 1.0497605800628662
Validation loss: 2.173856953779856

Epoch: 6| Step: 8
Training loss: 0.6915243864059448
Validation loss: 2.206554651260376

Epoch: 6| Step: 9
Training loss: 1.3323520421981812
Validation loss: 2.15779580672582

Epoch: 6| Step: 10
Training loss: 1.1288648843765259
Validation loss: 2.137112081050873

Epoch: 6| Step: 11
Training loss: 2.004439353942871
Validation loss: 2.1417070031166077

Epoch: 6| Step: 12
Training loss: 1.169357180595398
Validation loss: 2.1397337516148887

Epoch: 6| Step: 13
Training loss: 1.130096197128296
Validation loss: 2.1483986179033914

Epoch: 330| Step: 0
Training loss: 1.2132487297058105
Validation loss: 2.1232152779897056

Epoch: 6| Step: 1
Training loss: 1.1097121238708496
Validation loss: 2.1592083175977073

Epoch: 6| Step: 2
Training loss: 1.359665870666504
Validation loss: 2.1624487241109214

Epoch: 6| Step: 3
Training loss: 1.6435784101486206
Validation loss: 2.1422530810038247

Epoch: 6| Step: 4
Training loss: 0.9675114750862122
Validation loss: 2.1331371665000916

Epoch: 6| Step: 5
Training loss: 1.3342523574829102
Validation loss: 2.1713555256525674

Epoch: 6| Step: 6
Training loss: 1.0742026567459106
Validation loss: 2.1362314224243164

Epoch: 6| Step: 7
Training loss: 1.7627842426300049
Validation loss: 2.1354259252548218

Epoch: 6| Step: 8
Training loss: 1.562207579612732
Validation loss: 2.1082228223482766

Epoch: 6| Step: 9
Training loss: 0.8833364248275757
Validation loss: 2.110136250654856

Epoch: 6| Step: 10
Training loss: 1.390709400177002
Validation loss: 2.0733266274134317

Epoch: 6| Step: 11
Training loss: 0.9123114347457886
Validation loss: 2.067299743493398

Epoch: 6| Step: 12
Training loss: 1.2202714681625366
Validation loss: 2.087506135304769

Epoch: 6| Step: 13
Training loss: 1.9715410470962524
Validation loss: 2.0561962127685547

Epoch: 331| Step: 0
Training loss: 1.722664475440979
Validation loss: 2.0716015497843423

Epoch: 6| Step: 1
Training loss: 1.4016246795654297
Validation loss: 2.0963849623998008

Epoch: 6| Step: 2
Training loss: 1.3394787311553955
Validation loss: 2.111155172189077

Epoch: 6| Step: 3
Training loss: 1.3331315517425537
Validation loss: 2.137565473715464

Epoch: 6| Step: 4
Training loss: 1.5286688804626465
Validation loss: 2.1363425254821777

Epoch: 6| Step: 5
Training loss: 1.0996190309524536
Validation loss: 2.15425177415212

Epoch: 6| Step: 6
Training loss: 0.9250501394271851
Validation loss: 2.134147564570109

Epoch: 6| Step: 7
Training loss: 1.1073508262634277
Validation loss: 2.133642594019572

Epoch: 6| Step: 8
Training loss: 0.7985365986824036
Validation loss: 2.1204482515652976

Epoch: 6| Step: 9
Training loss: 1.4333330392837524
Validation loss: 2.1277182499567666

Epoch: 6| Step: 10
Training loss: 1.3692275285720825
Validation loss: 2.14576788743337

Epoch: 6| Step: 11
Training loss: 1.5460970401763916
Validation loss: 2.1842933297157288

Epoch: 6| Step: 12
Training loss: 1.326235294342041
Validation loss: 2.2087777058283486

Epoch: 6| Step: 13
Training loss: 1.4015092849731445
Validation loss: 2.2407626112302146

Epoch: 332| Step: 0
Training loss: 1.4848542213439941
Validation loss: 2.224108318487803

Epoch: 6| Step: 1
Training loss: 1.762331485748291
Validation loss: 2.2571007013320923

Epoch: 6| Step: 2
Training loss: 0.8975591659545898
Validation loss: 2.2403223315874734

Epoch: 6| Step: 3
Training loss: 1.5671690702438354
Validation loss: 2.20315291484197

Epoch: 6| Step: 4
Training loss: 1.0043468475341797
Validation loss: 2.201213300228119

Epoch: 6| Step: 5
Training loss: 0.9712150692939758
Validation loss: 2.2247631549835205

Epoch: 6| Step: 6
Training loss: 0.632320761680603
Validation loss: 2.149457852045695

Epoch: 6| Step: 7
Training loss: 1.6400507688522339
Validation loss: 2.2123780846595764

Epoch: 6| Step: 8
Training loss: 1.0817970037460327
Validation loss: 2.2208906610806785

Epoch: 6| Step: 9
Training loss: 1.447175145149231
Validation loss: 2.2010981241861978

Epoch: 6| Step: 10
Training loss: 1.2644295692443848
Validation loss: 2.171926816304525

Epoch: 6| Step: 11
Training loss: 1.1329784393310547
Validation loss: 2.1919953425725303

Epoch: 6| Step: 12
Training loss: 1.818708896636963
Validation loss: 2.1344252228736877

Epoch: 6| Step: 13
Training loss: 1.214280366897583
Validation loss: 2.1712434887886047

Epoch: 333| Step: 0
Training loss: 0.9732487797737122
Validation loss: 2.1017831762631736

Epoch: 6| Step: 1
Training loss: 1.2426116466522217
Validation loss: 2.1182032426198325

Epoch: 6| Step: 2
Training loss: 0.9465728402137756
Validation loss: 2.110181510448456

Epoch: 6| Step: 3
Training loss: 0.9940253496170044
Validation loss: 2.098200519879659

Epoch: 6| Step: 4
Training loss: 1.6106927394866943
Validation loss: 2.1098114252090454

Epoch: 6| Step: 5
Training loss: 0.6292811632156372
Validation loss: 2.0877058704694114

Epoch: 6| Step: 6
Training loss: 1.6774897575378418
Validation loss: 2.0836251974105835

Epoch: 6| Step: 7
Training loss: 1.3716397285461426
Validation loss: 2.068492333094279

Epoch: 6| Step: 8
Training loss: 1.0761935710906982
Validation loss: 2.0694947640101113

Epoch: 6| Step: 9
Training loss: 1.7862725257873535
Validation loss: 2.051312963167826

Epoch: 6| Step: 10
Training loss: 1.3582392930984497
Validation loss: 2.0984304547309875

Epoch: 6| Step: 11
Training loss: 1.1183176040649414
Validation loss: 2.0653234124183655

Epoch: 6| Step: 12
Training loss: 1.5585414171218872
Validation loss: 2.081559479236603

Epoch: 6| Step: 13
Training loss: 1.3067058324813843
Validation loss: 2.1036118865013123

Epoch: 334| Step: 0
Training loss: 1.3076808452606201
Validation loss: 2.105424960454305

Epoch: 6| Step: 1
Training loss: 1.9687527418136597
Validation loss: 2.138337016105652

Epoch: 6| Step: 2
Training loss: 1.2972557544708252
Validation loss: 2.123369336128235

Epoch: 6| Step: 3
Training loss: 0.9321286678314209
Validation loss: 2.1765631437301636

Epoch: 6| Step: 4
Training loss: 1.1320693492889404
Validation loss: 2.1409547130266824

Epoch: 6| Step: 5
Training loss: 1.4377143383026123
Validation loss: 2.1674540042877197

Epoch: 6| Step: 6
Training loss: 1.6019597053527832
Validation loss: 2.1670849323272705

Epoch: 6| Step: 7
Training loss: 0.7970080971717834
Validation loss: 2.139965991179148

Epoch: 6| Step: 8
Training loss: 0.8029923439025879
Validation loss: 2.1719236969947815

Epoch: 6| Step: 9
Training loss: 1.3290073871612549
Validation loss: 2.151871641476949

Epoch: 6| Step: 10
Training loss: 1.1431299448013306
Validation loss: 2.1210079987843833

Epoch: 6| Step: 11
Training loss: 1.3281052112579346
Validation loss: 2.1567702094713845

Epoch: 6| Step: 12
Training loss: 1.4097509384155273
Validation loss: 2.1410752336184182

Epoch: 6| Step: 13
Training loss: 1.18421471118927
Validation loss: 2.1509448289871216

Epoch: 335| Step: 0
Training loss: 1.7281701564788818
Validation loss: 2.189314623673757

Epoch: 6| Step: 1
Training loss: 0.9805123805999756
Validation loss: 2.1705742677052817

Epoch: 6| Step: 2
Training loss: 0.8044679164886475
Validation loss: 2.175049344698588

Epoch: 6| Step: 3
Training loss: 1.0735607147216797
Validation loss: 2.2149194876352944

Epoch: 6| Step: 4
Training loss: 1.5018346309661865
Validation loss: 2.154345134894053

Epoch: 6| Step: 5
Training loss: 1.3165267705917358
Validation loss: 2.1328548192977905

Epoch: 6| Step: 6
Training loss: 1.640310525894165
Validation loss: 2.142928878466288

Epoch: 6| Step: 7
Training loss: 0.6851186156272888
Validation loss: 2.157628138860067

Epoch: 6| Step: 8
Training loss: 1.647362470626831
Validation loss: 2.14132692416509

Epoch: 6| Step: 9
Training loss: 0.96905517578125
Validation loss: 2.1471912066141763

Epoch: 6| Step: 10
Training loss: 2.0821006298065186
Validation loss: 2.159891585508982

Epoch: 6| Step: 11
Training loss: 0.8994265794754028
Validation loss: 2.1509625911712646

Epoch: 6| Step: 12
Training loss: 1.2079354524612427
Validation loss: 2.2010549306869507

Epoch: 6| Step: 13
Training loss: 1.070859432220459
Validation loss: 2.214425524075826

Epoch: 336| Step: 0
Training loss: 1.2154691219329834
Validation loss: 2.2054826815923056

Epoch: 6| Step: 1
Training loss: 1.2090847492218018
Validation loss: 2.2083941102027893

Epoch: 6| Step: 2
Training loss: 0.41392868757247925
Validation loss: 2.204835911591848

Epoch: 6| Step: 3
Training loss: 2.0067965984344482
Validation loss: 2.237288018067678

Epoch: 6| Step: 4
Training loss: 1.2041895389556885
Validation loss: 2.2330335776011148

Epoch: 6| Step: 5
Training loss: 0.9454092383384705
Validation loss: 2.242731293042501

Epoch: 6| Step: 6
Training loss: 1.4150965213775635
Validation loss: 2.237160881360372

Epoch: 6| Step: 7
Training loss: 1.302605152130127
Validation loss: 2.2004836797714233

Epoch: 6| Step: 8
Training loss: 2.1065711975097656
Validation loss: 2.1697028080622354

Epoch: 6| Step: 9
Training loss: 1.0994008779525757
Validation loss: 2.1976860960324607

Epoch: 6| Step: 10
Training loss: 0.9601466655731201
Validation loss: 2.160817881425222

Epoch: 6| Step: 11
Training loss: 1.5294898748397827
Validation loss: 2.1489957571029663

Epoch: 6| Step: 12
Training loss: 1.0559295415878296
Validation loss: 2.1491434971491494

Epoch: 6| Step: 13
Training loss: 0.78954017162323
Validation loss: 2.143261273701986

Epoch: 337| Step: 0
Training loss: 1.104099988937378
Validation loss: 2.1446102062861123

Epoch: 6| Step: 1
Training loss: 1.5103739500045776
Validation loss: 2.1369921763738

Epoch: 6| Step: 2
Training loss: 0.4581345021724701
Validation loss: 2.1500964959462485

Epoch: 6| Step: 3
Training loss: 1.0466532707214355
Validation loss: 2.148852288722992

Epoch: 6| Step: 4
Training loss: 0.8748289942741394
Validation loss: 2.127368211746216

Epoch: 6| Step: 5
Training loss: 1.0571069717407227
Validation loss: 2.1237042943636575

Epoch: 6| Step: 6
Training loss: 1.1227405071258545
Validation loss: 2.1422888040542603

Epoch: 6| Step: 7
Training loss: 2.5933854579925537
Validation loss: 2.1802093585332236

Epoch: 6| Step: 8
Training loss: 0.7350006699562073
Validation loss: 2.1980107029279075

Epoch: 6| Step: 9
Training loss: 1.188502311706543
Validation loss: 2.196283280849457

Epoch: 6| Step: 10
Training loss: 1.788171648979187
Validation loss: 2.1959418853123984

Epoch: 6| Step: 11
Training loss: 0.9912525415420532
Validation loss: 2.210705598195394

Epoch: 6| Step: 12
Training loss: 1.6378960609436035
Validation loss: 2.213236073652903

Epoch: 6| Step: 13
Training loss: 1.2276344299316406
Validation loss: 2.207624912261963

Epoch: 338| Step: 0
Training loss: 1.1727619171142578
Validation loss: 2.205441872278849

Epoch: 6| Step: 1
Training loss: 0.6944801807403564
Validation loss: 2.2078009049097695

Epoch: 6| Step: 2
Training loss: 1.3300447463989258
Validation loss: 2.172800858815511

Epoch: 6| Step: 3
Training loss: 0.8951804637908936
Validation loss: 2.171716252962748

Epoch: 6| Step: 4
Training loss: 1.940645456314087
Validation loss: 2.152539551258087

Epoch: 6| Step: 5
Training loss: 1.745853304862976
Validation loss: 2.1275375882784524

Epoch: 6| Step: 6
Training loss: 0.7827204465866089
Validation loss: 2.1189327239990234

Epoch: 6| Step: 7
Training loss: 1.1017379760742188
Validation loss: 2.1126245260238647

Epoch: 6| Step: 8
Training loss: 0.7432779669761658
Validation loss: 2.120663503805796

Epoch: 6| Step: 9
Training loss: 1.5368961095809937
Validation loss: 2.117491364479065

Epoch: 6| Step: 10
Training loss: 1.567379355430603
Validation loss: 2.081989347934723

Epoch: 6| Step: 11
Training loss: 1.5593371391296387
Validation loss: 2.076585114002228

Epoch: 6| Step: 12
Training loss: 1.219826340675354
Validation loss: 2.0945472717285156

Epoch: 6| Step: 13
Training loss: 1.0005991458892822
Validation loss: 2.0914788246154785

Epoch: 339| Step: 0
Training loss: 0.9604381322860718
Validation loss: 2.111765702565511

Epoch: 6| Step: 1
Training loss: 1.5468530654907227
Validation loss: 2.1103336413701377

Epoch: 6| Step: 2
Training loss: 1.3631043434143066
Validation loss: 2.1084980567296348

Epoch: 6| Step: 3
Training loss: 1.8117793798446655
Validation loss: 2.1358839869499207

Epoch: 6| Step: 4
Training loss: 0.8514174818992615
Validation loss: 2.141970713933309

Epoch: 6| Step: 5
Training loss: 1.6621198654174805
Validation loss: 2.1231160958607993

Epoch: 6| Step: 6
Training loss: 0.8160618543624878
Validation loss: 2.12909597158432

Epoch: 6| Step: 7
Training loss: 1.0862597227096558
Validation loss: 2.1459519465764365

Epoch: 6| Step: 8
Training loss: 1.1168732643127441
Validation loss: 2.135263423124949

Epoch: 6| Step: 9
Training loss: 1.5972001552581787
Validation loss: 2.106375813484192

Epoch: 6| Step: 10
Training loss: 1.6122372150421143
Validation loss: 2.124707659085592

Epoch: 6| Step: 11
Training loss: 0.6856718063354492
Validation loss: 2.1219497124354043

Epoch: 6| Step: 12
Training loss: 1.1298216581344604
Validation loss: 2.103623549143473

Epoch: 6| Step: 13
Training loss: 1.1387677192687988
Validation loss: 2.0761377215385437

Epoch: 340| Step: 0
Training loss: 1.2276239395141602
Validation loss: 2.112716714541117

Epoch: 6| Step: 1
Training loss: 0.8907161951065063
Validation loss: 2.1440813342730203

Epoch: 6| Step: 2
Training loss: 1.460345983505249
Validation loss: 2.147450645764669

Epoch: 6| Step: 3
Training loss: 2.141833543777466
Validation loss: 2.1224889159202576

Epoch: 6| Step: 4
Training loss: 1.6450583934783936
Validation loss: 2.12946210304896

Epoch: 6| Step: 5
Training loss: 1.017492651939392
Validation loss: 2.144595444202423

Epoch: 6| Step: 6
Training loss: 1.1085485219955444
Validation loss: 2.107433299223582

Epoch: 6| Step: 7
Training loss: 0.9146677255630493
Validation loss: 2.116961717605591

Epoch: 6| Step: 8
Training loss: 0.7616314888000488
Validation loss: 2.1327569087346396

Epoch: 6| Step: 9
Training loss: 0.9763165712356567
Validation loss: 2.1144714752833047

Epoch: 6| Step: 10
Training loss: 1.0966613292694092
Validation loss: 2.152890980243683

Epoch: 6| Step: 11
Training loss: 1.2549676895141602
Validation loss: 2.2010428309440613

Epoch: 6| Step: 12
Training loss: 1.5044362545013428
Validation loss: 2.188724855581919

Epoch: 6| Step: 13
Training loss: 1.0787198543548584
Validation loss: 2.2076268394788108

Epoch: 341| Step: 0
Training loss: 1.98065185546875
Validation loss: 2.193199396133423

Epoch: 6| Step: 1
Training loss: 0.913708508014679
Validation loss: 2.2194447914759317

Epoch: 6| Step: 2
Training loss: 1.451532006263733
Validation loss: 2.2084414760271707

Epoch: 6| Step: 3
Training loss: 0.8926995992660522
Validation loss: 2.18676765759786

Epoch: 6| Step: 4
Training loss: 1.2588549852371216
Validation loss: 2.1566567023595176

Epoch: 6| Step: 5
Training loss: 1.2077473402023315
Validation loss: 2.139202058315277

Epoch: 6| Step: 6
Training loss: 1.496498703956604
Validation loss: 2.1321420669555664

Epoch: 6| Step: 7
Training loss: 1.1378517150878906
Validation loss: 2.0952254931131997

Epoch: 6| Step: 8
Training loss: 1.1881593465805054
Validation loss: 2.0995223919550576

Epoch: 6| Step: 9
Training loss: 1.8362452983856201
Validation loss: 2.0918414195378623

Epoch: 6| Step: 10
Training loss: 1.1750725507736206
Validation loss: 2.120537360509237

Epoch: 6| Step: 11
Training loss: 1.278233289718628
Validation loss: 2.11741175254186

Epoch: 6| Step: 12
Training loss: 1.1819700002670288
Validation loss: 2.154729942480723

Epoch: 6| Step: 13
Training loss: 1.137418270111084
Validation loss: 2.151359478632609

Epoch: 342| Step: 0
Training loss: 1.1102452278137207
Validation loss: 2.1776763002077737

Epoch: 6| Step: 1
Training loss: 0.5439084768295288
Validation loss: 2.1681397557258606

Epoch: 6| Step: 2
Training loss: 1.3651150465011597
Validation loss: 2.1674951712290444

Epoch: 6| Step: 3
Training loss: 1.283381700515747
Validation loss: 2.160211523373922

Epoch: 6| Step: 4
Training loss: 1.0692453384399414
Validation loss: 2.1859640876452127

Epoch: 6| Step: 5
Training loss: 1.5458451509475708
Validation loss: 2.1769167383511863

Epoch: 6| Step: 6
Training loss: 1.2013678550720215
Validation loss: 2.183995266755422

Epoch: 6| Step: 7
Training loss: 1.0767327547073364
Validation loss: 2.158494293689728

Epoch: 6| Step: 8
Training loss: 1.7658300399780273
Validation loss: 2.188366413116455

Epoch: 6| Step: 9
Training loss: 1.1083718538284302
Validation loss: 2.1727392872174582

Epoch: 6| Step: 10
Training loss: 1.1433377265930176
Validation loss: 2.241469363371531

Epoch: 6| Step: 11
Training loss: 1.7985782623291016
Validation loss: 2.211681286493937

Epoch: 6| Step: 12
Training loss: 1.0841343402862549
Validation loss: 2.197294374306997

Epoch: 6| Step: 13
Training loss: 1.3949530124664307
Validation loss: 2.2023415764172873

Epoch: 343| Step: 0
Training loss: 1.7080185413360596
Validation loss: 2.198988974094391

Epoch: 6| Step: 1
Training loss: 0.5801296234130859
Validation loss: 2.1732698678970337

Epoch: 6| Step: 2
Training loss: 1.6582735776901245
Validation loss: 2.1704455614089966

Epoch: 6| Step: 3
Training loss: 1.40531325340271
Validation loss: 2.156562169392904

Epoch: 6| Step: 4
Training loss: 1.0479435920715332
Validation loss: 2.137156367301941

Epoch: 6| Step: 5
Training loss: 0.5933728218078613
Validation loss: 2.1462228298187256

Epoch: 6| Step: 6
Training loss: 1.4992961883544922
Validation loss: 2.148937483628591

Epoch: 6| Step: 7
Training loss: 1.6200098991394043
Validation loss: 2.1566769083340964

Epoch: 6| Step: 8
Training loss: 1.2836461067199707
Validation loss: 2.104209780693054

Epoch: 6| Step: 9
Training loss: 1.0431532859802246
Validation loss: 2.1204758485158286

Epoch: 6| Step: 10
Training loss: 1.1315761804580688
Validation loss: 2.123267889022827

Epoch: 6| Step: 11
Training loss: 1.5274980068206787
Validation loss: 2.155427654584249

Epoch: 6| Step: 12
Training loss: 1.170365333557129
Validation loss: 2.1384193897247314

Epoch: 6| Step: 13
Training loss: 0.9632812142372131
Validation loss: 2.1725295782089233

Epoch: 344| Step: 0
Training loss: 0.7362505197525024
Validation loss: 2.184004286924998

Epoch: 6| Step: 1
Training loss: 1.4945781230926514
Validation loss: 2.1583366791407266

Epoch: 6| Step: 2
Training loss: 1.013122797012329
Validation loss: 2.147801478703817

Epoch: 6| Step: 3
Training loss: 1.176771879196167
Validation loss: 2.161360422770182

Epoch: 6| Step: 4
Training loss: 0.8280165791511536
Validation loss: 2.1704177061716714

Epoch: 6| Step: 5
Training loss: 1.440394639968872
Validation loss: 2.181862751642863

Epoch: 6| Step: 6
Training loss: 1.2243002653121948
Validation loss: 2.153092881043752

Epoch: 6| Step: 7
Training loss: 1.1202375888824463
Validation loss: 2.146243174870809

Epoch: 6| Step: 8
Training loss: 1.5267407894134521
Validation loss: 2.1701867977778115

Epoch: 6| Step: 9
Training loss: 1.0420551300048828
Validation loss: 2.164936125278473

Epoch: 6| Step: 10
Training loss: 1.3205108642578125
Validation loss: 2.1389426390329995

Epoch: 6| Step: 11
Training loss: 2.2085747718811035
Validation loss: 2.1497710943222046

Epoch: 6| Step: 12
Training loss: 1.01616632938385
Validation loss: 2.1539047757784524

Epoch: 6| Step: 13
Training loss: 1.065269947052002
Validation loss: 2.154966711997986

Epoch: 345| Step: 0
Training loss: 0.9986685514450073
Validation loss: 2.161131958166758

Epoch: 6| Step: 1
Training loss: 1.1101715564727783
Validation loss: 2.18092676003774

Epoch: 6| Step: 2
Training loss: 1.145769715309143
Validation loss: 2.18390820423762

Epoch: 6| Step: 3
Training loss: 0.7222273349761963
Validation loss: 2.186886707941691

Epoch: 6| Step: 4
Training loss: 1.8951759338378906
Validation loss: 2.204098184903463

Epoch: 6| Step: 5
Training loss: 1.574291467666626
Validation loss: 2.2432331641515098

Epoch: 6| Step: 6
Training loss: 1.4419251680374146
Validation loss: 2.1950035889943442

Epoch: 6| Step: 7
Training loss: 0.763127326965332
Validation loss: 2.2130537629127502

Epoch: 6| Step: 8
Training loss: 1.2354480028152466
Validation loss: 2.188212235768636

Epoch: 6| Step: 9
Training loss: 1.4049478769302368
Validation loss: 2.1830402414004006

Epoch: 6| Step: 10
Training loss: 0.8255367279052734
Validation loss: 2.15815407037735

Epoch: 6| Step: 11
Training loss: 1.1544849872589111
Validation loss: 2.1807398001352944

Epoch: 6| Step: 12
Training loss: 1.7316619157791138
Validation loss: 2.1767693559328714

Epoch: 6| Step: 13
Training loss: 0.8942784070968628
Validation loss: 2.1179644664128623

Epoch: 346| Step: 0
Training loss: 1.2403483390808105
Validation loss: 2.1562508742014566

Epoch: 6| Step: 1
Training loss: 1.0123730897903442
Validation loss: 2.142295797665914

Epoch: 6| Step: 2
Training loss: 1.7299373149871826
Validation loss: 2.198101500670115

Epoch: 6| Step: 3
Training loss: 0.7852047085762024
Validation loss: 2.137199103832245

Epoch: 6| Step: 4
Training loss: 2.58491849899292
Validation loss: 2.1714194416999817

Epoch: 6| Step: 5
Training loss: 0.8892518281936646
Validation loss: 2.1134339372316995

Epoch: 6| Step: 6
Training loss: 0.8660268783569336
Validation loss: 2.1718113819758096

Epoch: 6| Step: 7
Training loss: 1.2609453201293945
Validation loss: 2.1562917629877725

Epoch: 6| Step: 8
Training loss: 0.7412528395652771
Validation loss: 2.133114218711853

Epoch: 6| Step: 9
Training loss: 0.9791736602783203
Validation loss: 2.1358505884806314

Epoch: 6| Step: 10
Training loss: 0.8810813426971436
Validation loss: 2.183941106001536

Epoch: 6| Step: 11
Training loss: 0.8228373527526855
Validation loss: 2.1884938875834146

Epoch: 6| Step: 12
Training loss: 1.2516758441925049
Validation loss: 2.200887759526571

Epoch: 6| Step: 13
Training loss: 1.4075134992599487
Validation loss: 2.1947364807128906

Epoch: 347| Step: 0
Training loss: 1.2979307174682617
Validation loss: 2.1666075785954795

Epoch: 6| Step: 1
Training loss: 0.9958871603012085
Validation loss: 2.1685496966044107

Epoch: 6| Step: 2
Training loss: 1.5042158365249634
Validation loss: 2.175877888997396

Epoch: 6| Step: 3
Training loss: 0.382771372795105
Validation loss: 2.14625092347463

Epoch: 6| Step: 4
Training loss: 1.2634665966033936
Validation loss: 2.1607369780540466

Epoch: 6| Step: 5
Training loss: 1.9960222244262695
Validation loss: 2.17617134253184

Epoch: 6| Step: 6
Training loss: 1.211395025253296
Validation loss: 2.1670016646385193

Epoch: 6| Step: 7
Training loss: 1.1061336994171143
Validation loss: 2.1908547083536782

Epoch: 6| Step: 8
Training loss: 1.6738890409469604
Validation loss: 2.1736679871877036

Epoch: 6| Step: 9
Training loss: 0.6561487317085266
Validation loss: 2.138870894908905

Epoch: 6| Step: 10
Training loss: 1.613824486732483
Validation loss: 2.1626546581586203

Epoch: 6| Step: 11
Training loss: 1.1247092485427856
Validation loss: 2.1195974349975586

Epoch: 6| Step: 12
Training loss: 0.8853806257247925
Validation loss: 2.1291348139444985

Epoch: 6| Step: 13
Training loss: 0.8240358233451843
Validation loss: 2.098103404045105

Epoch: 348| Step: 0
Training loss: 1.9818437099456787
Validation loss: 2.124549627304077

Epoch: 6| Step: 1
Training loss: 1.2986862659454346
Validation loss: 2.131910185019175

Epoch: 6| Step: 2
Training loss: 1.6434273719787598
Validation loss: 2.092648228009542

Epoch: 6| Step: 3
Training loss: 1.2236535549163818
Validation loss: 2.0688740611076355

Epoch: 6| Step: 4
Training loss: 1.621417760848999
Validation loss: 2.0496063828468323

Epoch: 6| Step: 5
Training loss: 0.9092801809310913
Validation loss: 2.0441972414652505

Epoch: 6| Step: 6
Training loss: 1.2259480953216553
Validation loss: 2.064243415991465

Epoch: 6| Step: 7
Training loss: 1.2212759256362915
Validation loss: 2.0831803679466248

Epoch: 6| Step: 8
Training loss: 0.6021968126296997
Validation loss: 2.1010324160257974

Epoch: 6| Step: 9
Training loss: 1.0398390293121338
Validation loss: 2.1023343404134116

Epoch: 6| Step: 10
Training loss: 1.3895533084869385
Validation loss: 2.105540692806244

Epoch: 6| Step: 11
Training loss: 0.5983120203018188
Validation loss: 2.1319159865379333

Epoch: 6| Step: 12
Training loss: 1.3251533508300781
Validation loss: 2.1730758945147195

Epoch: 6| Step: 13
Training loss: 0.4169289767742157
Validation loss: 2.1720822850863137

Epoch: 349| Step: 0
Training loss: 0.9530901908874512
Validation loss: 2.1997755765914917

Epoch: 6| Step: 1
Training loss: 1.3994218111038208
Validation loss: 2.185845156510671

Epoch: 6| Step: 2
Training loss: 1.6973837614059448
Validation loss: 2.2445624669392905

Epoch: 6| Step: 3
Training loss: 1.2394713163375854
Validation loss: 2.2497229973475137

Epoch: 6| Step: 4
Training loss: 0.7140214443206787
Validation loss: 2.1783204078674316

Epoch: 6| Step: 5
Training loss: 0.6369180083274841
Validation loss: 2.1640363931655884

Epoch: 6| Step: 6
Training loss: 1.6634392738342285
Validation loss: 2.1333778500556946

Epoch: 6| Step: 7
Training loss: 0.9386308789253235
Validation loss: 2.125323017438253

Epoch: 6| Step: 8
Training loss: 1.1663509607315063
Validation loss: 2.104939619700114

Epoch: 6| Step: 9
Training loss: 1.0868314504623413
Validation loss: 2.1141103307406106

Epoch: 6| Step: 10
Training loss: 1.1599373817443848
Validation loss: 2.107625166575114

Epoch: 6| Step: 11
Training loss: 1.0036108493804932
Validation loss: 2.0963579416275024

Epoch: 6| Step: 12
Training loss: 1.3400485515594482
Validation loss: 2.1221054593722024

Epoch: 6| Step: 13
Training loss: 2.104658365249634
Validation loss: 2.0914077361424765

Epoch: 350| Step: 0
Training loss: 0.9826120138168335
Validation loss: 2.0681357979774475

Epoch: 6| Step: 1
Training loss: 1.1245135068893433
Validation loss: 2.0972604155540466

Epoch: 6| Step: 2
Training loss: 0.9075440764427185
Validation loss: 2.0877917806307473

Epoch: 6| Step: 3
Training loss: 1.1511075496673584
Validation loss: 2.087977707386017

Epoch: 6| Step: 4
Training loss: 1.6757218837738037
Validation loss: 2.116228461265564

Epoch: 6| Step: 5
Training loss: 1.299834132194519
Validation loss: 2.12469212214152

Epoch: 6| Step: 6
Training loss: 1.1341583728790283
Validation loss: 2.1490230560302734

Epoch: 6| Step: 7
Training loss: 0.8824933767318726
Validation loss: 2.1487955848375955

Epoch: 6| Step: 8
Training loss: 1.1924724578857422
Validation loss: 2.1708256800969443

Epoch: 6| Step: 9
Training loss: 1.3983899354934692
Validation loss: 2.2179373502731323

Epoch: 6| Step: 10
Training loss: 1.149668574333191
Validation loss: 2.1836074193318686

Epoch: 6| Step: 11
Training loss: 0.9559766054153442
Validation loss: 2.201756497224172

Epoch: 6| Step: 12
Training loss: 1.2900691032409668
Validation loss: 2.2095505396525064

Epoch: 6| Step: 13
Training loss: 1.7372901439666748
Validation loss: 2.178762118021647

Epoch: 351| Step: 0
Training loss: 1.9214439392089844
Validation loss: 2.19176975886027

Epoch: 6| Step: 1
Training loss: 0.752516508102417
Validation loss: 2.19863893588384

Epoch: 6| Step: 2
Training loss: 0.9468401670455933
Validation loss: 2.166376769542694

Epoch: 6| Step: 3
Training loss: 0.9395656585693359
Validation loss: 2.2257052858670554

Epoch: 6| Step: 4
Training loss: 0.8328909873962402
Validation loss: 2.1929256319999695

Epoch: 6| Step: 5
Training loss: 2.0769145488739014
Validation loss: 2.1627082228660583

Epoch: 6| Step: 6
Training loss: 1.551504135131836
Validation loss: 2.1808539032936096

Epoch: 6| Step: 7
Training loss: 1.1875379085540771
Validation loss: 2.1734424829483032

Epoch: 6| Step: 8
Training loss: 1.2374882698059082
Validation loss: 2.156791647275289

Epoch: 6| Step: 9
Training loss: 1.4290943145751953
Validation loss: 2.1332889993985495

Epoch: 6| Step: 10
Training loss: 1.121524453163147
Validation loss: 2.136452853679657

Epoch: 6| Step: 11
Training loss: 0.724449634552002
Validation loss: 2.153403957684835

Epoch: 6| Step: 12
Training loss: 1.3559627532958984
Validation loss: 2.0908769567807517

Epoch: 6| Step: 13
Training loss: 0.889191746711731
Validation loss: 2.1313177744547525

Epoch: 352| Step: 0
Training loss: 1.4203956127166748
Validation loss: 2.133564750353495

Epoch: 6| Step: 1
Training loss: 1.1142075061798096
Validation loss: 2.1094775994618735

Epoch: 6| Step: 2
Training loss: 0.9646363258361816
Validation loss: 2.1074748833974204

Epoch: 6| Step: 3
Training loss: 1.0009747743606567
Validation loss: 2.1137319008509317

Epoch: 6| Step: 4
Training loss: 1.2369308471679688
Validation loss: 2.1333019733428955

Epoch: 6| Step: 5
Training loss: 1.2636361122131348
Validation loss: 2.1292225122451782

Epoch: 6| Step: 6
Training loss: 1.35471773147583
Validation loss: 2.1367072661717734

Epoch: 6| Step: 7
Training loss: 1.1480941772460938
Validation loss: 2.147093872229258

Epoch: 6| Step: 8
Training loss: 1.1618125438690186
Validation loss: 2.1360096534093223

Epoch: 6| Step: 9
Training loss: 1.032297968864441
Validation loss: 2.1002742846806846

Epoch: 6| Step: 10
Training loss: 1.370048999786377
Validation loss: 2.1046488086382547

Epoch: 6| Step: 11
Training loss: 1.6362656354904175
Validation loss: 2.122364640235901

Epoch: 6| Step: 12
Training loss: 0.8563679456710815
Validation loss: 2.133569280306498

Epoch: 6| Step: 13
Training loss: 1.0013854503631592
Validation loss: 2.109934131304423

Epoch: 353| Step: 0
Training loss: 1.4773229360580444
Validation loss: 2.1397629181543985

Epoch: 6| Step: 1
Training loss: 1.2161242961883545
Validation loss: 2.1789260705312095

Epoch: 6| Step: 2
Training loss: 1.3269511461257935
Validation loss: 2.1723602414131165

Epoch: 6| Step: 3
Training loss: 1.2345134019851685
Validation loss: 2.160188396771749

Epoch: 6| Step: 4
Training loss: 1.332561731338501
Validation loss: 2.1734180649121604

Epoch: 6| Step: 5
Training loss: 1.2023439407348633
Validation loss: 2.178769846757253

Epoch: 6| Step: 6
Training loss: 1.6126892566680908
Validation loss: 2.197384158770243

Epoch: 6| Step: 7
Training loss: 1.6394516229629517
Validation loss: 2.1734294295310974

Epoch: 6| Step: 8
Training loss: 1.3769179582595825
Validation loss: 2.1762624184290567

Epoch: 6| Step: 9
Training loss: 0.7679440975189209
Validation loss: 2.1766135891278586

Epoch: 6| Step: 10
Training loss: 0.9417327046394348
Validation loss: 2.1969041426976523

Epoch: 6| Step: 11
Training loss: 0.600654661655426
Validation loss: 2.188645084698995

Epoch: 6| Step: 12
Training loss: 0.9254512190818787
Validation loss: 2.1883262991905212

Epoch: 6| Step: 13
Training loss: 0.7878122329711914
Validation loss: 2.191762606302897

Epoch: 354| Step: 0
Training loss: 1.4129886627197266
Validation loss: 2.164270003636678

Epoch: 6| Step: 1
Training loss: 0.6743912100791931
Validation loss: 2.1502041021982827

Epoch: 6| Step: 2
Training loss: 1.3985739946365356
Validation loss: 2.17948849995931

Epoch: 6| Step: 3
Training loss: 0.9504631161689758
Validation loss: 2.1567081809043884

Epoch: 6| Step: 4
Training loss: 1.0552603006362915
Validation loss: 2.1621301770210266

Epoch: 6| Step: 5
Training loss: 0.8186144828796387
Validation loss: 2.120973289012909

Epoch: 6| Step: 6
Training loss: 1.1259645223617554
Validation loss: 2.1436052719751992

Epoch: 6| Step: 7
Training loss: 1.253065586090088
Validation loss: 2.1314354141553244

Epoch: 6| Step: 8
Training loss: 1.1480472087860107
Validation loss: 2.1032341718673706

Epoch: 6| Step: 9
Training loss: 0.9428548216819763
Validation loss: 2.108678181966146

Epoch: 6| Step: 10
Training loss: 1.4199376106262207
Validation loss: 2.1234517097473145

Epoch: 6| Step: 11
Training loss: 1.5401670932769775
Validation loss: 2.101057509581248

Epoch: 6| Step: 12
Training loss: 0.7832356691360474
Validation loss: 2.0755205949147544

Epoch: 6| Step: 13
Training loss: 1.687787652015686
Validation loss: 2.1361802419026694

Epoch: 355| Step: 0
Training loss: 0.6482470631599426
Validation loss: 2.144376834233602

Epoch: 6| Step: 1
Training loss: 1.1884592771530151
Validation loss: 2.132209142049154

Epoch: 6| Step: 2
Training loss: 1.011864423751831
Validation loss: 2.1362892587979636

Epoch: 6| Step: 3
Training loss: 0.8153500556945801
Validation loss: 2.123100161552429

Epoch: 6| Step: 4
Training loss: 1.6404956579208374
Validation loss: 2.18360028664271

Epoch: 6| Step: 5
Training loss: 1.6894772052764893
Validation loss: 2.179604450861613

Epoch: 6| Step: 6
Training loss: 1.5538004636764526
Validation loss: 2.1360428730646768

Epoch: 6| Step: 7
Training loss: 1.3268193006515503
Validation loss: 2.1681342919667563

Epoch: 6| Step: 8
Training loss: 1.0318372249603271
Validation loss: 2.1683695713678994

Epoch: 6| Step: 9
Training loss: 1.1948620080947876
Validation loss: 2.1723472674687705

Epoch: 6| Step: 10
Training loss: 1.239087700843811
Validation loss: 2.1893524527549744

Epoch: 6| Step: 11
Training loss: 0.9220855236053467
Validation loss: 2.1575693686803183

Epoch: 6| Step: 12
Training loss: 1.2686307430267334
Validation loss: 2.199103077252706

Epoch: 6| Step: 13
Training loss: 1.2673574686050415
Validation loss: 2.1528444290161133

Epoch: 356| Step: 0
Training loss: 1.7404160499572754
Validation loss: 2.156131625175476

Epoch: 6| Step: 1
Training loss: 2.171982765197754
Validation loss: 2.151512384414673

Epoch: 6| Step: 2
Training loss: 0.7087016701698303
Validation loss: 2.1706267595291138

Epoch: 6| Step: 3
Training loss: 1.568816900253296
Validation loss: 2.205513139565786

Epoch: 6| Step: 4
Training loss: 1.2836103439331055
Validation loss: 2.2324636777242026

Epoch: 6| Step: 5
Training loss: 1.5213338136672974
Validation loss: 2.251788934071859

Epoch: 6| Step: 6
Training loss: 0.817721426486969
Validation loss: 2.2264009714126587

Epoch: 6| Step: 7
Training loss: 1.7780110836029053
Validation loss: 2.1796939174334207

Epoch: 6| Step: 8
Training loss: 1.506338119506836
Validation loss: 2.1617950797080994

Epoch: 6| Step: 9
Training loss: 0.8503966927528381
Validation loss: 2.173985004425049

Epoch: 6| Step: 10
Training loss: 0.5956783890724182
Validation loss: 2.1777567068735757

Epoch: 6| Step: 11
Training loss: 1.1948692798614502
Validation loss: 2.1234554648399353

Epoch: 6| Step: 12
Training loss: 0.8367182612419128
Validation loss: 2.1585496068000793

Epoch: 6| Step: 13
Training loss: 0.7755724191665649
Validation loss: 2.160303294658661

Epoch: 357| Step: 0
Training loss: 0.96196448802948
Validation loss: 2.1633969942728677

Epoch: 6| Step: 1
Training loss: 1.8782620429992676
Validation loss: 2.1950677235921225

Epoch: 6| Step: 2
Training loss: 0.9241988658905029
Validation loss: 2.1572842796643577

Epoch: 6| Step: 3
Training loss: 1.1479640007019043
Validation loss: 2.1976891358693442

Epoch: 6| Step: 4
Training loss: 0.8462498188018799
Validation loss: 2.149525503317515

Epoch: 6| Step: 5
Training loss: 0.8999267816543579
Validation loss: 2.1516780455907187

Epoch: 6| Step: 6
Training loss: 0.9411946535110474
Validation loss: 2.1921852429707847

Epoch: 6| Step: 7
Training loss: 0.6665929555892944
Validation loss: 2.1548328598340354

Epoch: 6| Step: 8
Training loss: 1.3358407020568848
Validation loss: 2.1939128637313843

Epoch: 6| Step: 9
Training loss: 1.602102279663086
Validation loss: 2.1923562486966452

Epoch: 6| Step: 10
Training loss: 0.7044812440872192
Validation loss: 2.1801984508832297

Epoch: 6| Step: 11
Training loss: 1.3627164363861084
Validation loss: 2.1783101558685303

Epoch: 6| Step: 12
Training loss: 1.4912605285644531
Validation loss: 2.1461896498998008

Epoch: 6| Step: 13
Training loss: 1.4039666652679443
Validation loss: 2.139889935652415

Epoch: 358| Step: 0
Training loss: 1.217862844467163
Validation loss: 2.146288057168325

Epoch: 6| Step: 1
Training loss: 1.0467489957809448
Validation loss: 2.155693749586741

Epoch: 6| Step: 2
Training loss: 0.7542370557785034
Validation loss: 2.1153903007507324

Epoch: 6| Step: 3
Training loss: 1.686108946800232
Validation loss: 2.124072511990865

Epoch: 6| Step: 4
Training loss: 0.9072819352149963
Validation loss: 2.1309672594070435

Epoch: 6| Step: 5
Training loss: 1.0347075462341309
Validation loss: 2.173339525858561

Epoch: 6| Step: 6
Training loss: 1.2433223724365234
Validation loss: 2.1544819275538125

Epoch: 6| Step: 7
Training loss: 1.7194942235946655
Validation loss: 2.150690774122874

Epoch: 6| Step: 8
Training loss: 1.166687250137329
Validation loss: 2.169248580932617

Epoch: 6| Step: 9
Training loss: 1.4968442916870117
Validation loss: 2.155159870783488

Epoch: 6| Step: 10
Training loss: 0.8579312562942505
Validation loss: 2.1836449901262918

Epoch: 6| Step: 11
Training loss: 1.1025259494781494
Validation loss: 2.173957129319509

Epoch: 6| Step: 12
Training loss: 1.6690737009048462
Validation loss: 2.1894650061925254

Epoch: 6| Step: 13
Training loss: 1.067978858947754
Validation loss: 2.1295695304870605

Epoch: 359| Step: 0
Training loss: 1.1222026348114014
Validation loss: 2.112160245577494

Epoch: 6| Step: 1
Training loss: 0.9431476593017578
Validation loss: 2.1348034342130027

Epoch: 6| Step: 2
Training loss: 1.2092070579528809
Validation loss: 2.123899221420288

Epoch: 6| Step: 3
Training loss: 1.0798039436340332
Validation loss: 2.083351651827494

Epoch: 6| Step: 4
Training loss: 0.5889730453491211
Validation loss: 2.0788581172625222

Epoch: 6| Step: 5
Training loss: 0.9671270847320557
Validation loss: 2.0675583481788635

Epoch: 6| Step: 6
Training loss: 1.432894229888916
Validation loss: 2.0370904008547464

Epoch: 6| Step: 7
Training loss: 1.7576677799224854
Validation loss: 2.0869675874710083

Epoch: 6| Step: 8
Training loss: 0.5809698104858398
Validation loss: 2.081964691480001

Epoch: 6| Step: 9
Training loss: 1.2114107608795166
Validation loss: 2.07077689965566

Epoch: 6| Step: 10
Training loss: 0.8471871614456177
Validation loss: 2.082376003265381

Epoch: 6| Step: 11
Training loss: 2.6658992767333984
Validation loss: 2.078931748867035

Epoch: 6| Step: 12
Training loss: 1.158921241760254
Validation loss: 2.078423778216044

Epoch: 6| Step: 13
Training loss: 1.176788091659546
Validation loss: 2.1252799232800803

Epoch: 360| Step: 0
Training loss: 1.2167572975158691
Validation loss: 2.109718839327494

Epoch: 6| Step: 1
Training loss: 1.9877691268920898
Validation loss: 2.1482189893722534

Epoch: 6| Step: 2
Training loss: 1.0009739398956299
Validation loss: 2.127387841542562

Epoch: 6| Step: 3
Training loss: 1.239674687385559
Validation loss: 2.143193085988363

Epoch: 6| Step: 4
Training loss: 1.327199935913086
Validation loss: 2.108412504196167

Epoch: 6| Step: 5
Training loss: 0.869598388671875
Validation loss: 2.1229153871536255

Epoch: 6| Step: 6
Training loss: 1.704514980316162
Validation loss: 2.1406813859939575

Epoch: 6| Step: 7
Training loss: 0.9051555395126343
Validation loss: 2.103357950846354

Epoch: 6| Step: 8
Training loss: 0.7980235815048218
Validation loss: 2.173693517843882

Epoch: 6| Step: 9
Training loss: 0.7339861392974854
Validation loss: 2.108078916867574

Epoch: 6| Step: 10
Training loss: 0.5120253562927246
Validation loss: 2.1308642824490867

Epoch: 6| Step: 11
Training loss: 1.8958046436309814
Validation loss: 2.1148483951886496

Epoch: 6| Step: 12
Training loss: 0.996232807636261
Validation loss: 2.099514603614807

Epoch: 6| Step: 13
Training loss: 1.3203155994415283
Validation loss: 2.1032761335372925

Epoch: 361| Step: 0
Training loss: 1.3937453031539917
Validation loss: 2.11422993739446

Epoch: 6| Step: 1
Training loss: 0.9435291886329651
Validation loss: 2.129948596159617

Epoch: 6| Step: 2
Training loss: 1.6175174713134766
Validation loss: 2.1368524034818015

Epoch: 6| Step: 3
Training loss: 1.442903995513916
Validation loss: 2.1337703267733255

Epoch: 6| Step: 4
Training loss: 0.42471185326576233
Validation loss: 2.1419911781946817

Epoch: 6| Step: 5
Training loss: 1.224865198135376
Validation loss: 2.1496179898579917

Epoch: 6| Step: 6
Training loss: 0.9639949202537537
Validation loss: 2.162409782409668

Epoch: 6| Step: 7
Training loss: 1.3963444232940674
Validation loss: 2.1782554388046265

Epoch: 6| Step: 8
Training loss: 1.217373013496399
Validation loss: 2.1589648922284446

Epoch: 6| Step: 9
Training loss: 0.8173837065696716
Validation loss: 2.1345472733179727

Epoch: 6| Step: 10
Training loss: 1.0653754472732544
Validation loss: 2.199923594792684

Epoch: 6| Step: 11
Training loss: 1.4830868244171143
Validation loss: 2.1860344807306924

Epoch: 6| Step: 12
Training loss: 1.2716941833496094
Validation loss: 2.212145984172821

Epoch: 6| Step: 13
Training loss: 2.0442354679107666
Validation loss: 2.1694251894950867

Epoch: 362| Step: 0
Training loss: 0.7063415050506592
Validation loss: 2.2072602907816568

Epoch: 6| Step: 1
Training loss: 0.823514461517334
Validation loss: 2.203771154085795

Epoch: 6| Step: 2
Training loss: 1.8377885818481445
Validation loss: 2.1697212855021157

Epoch: 6| Step: 3
Training loss: 0.6809435486793518
Validation loss: 2.202873190244039

Epoch: 6| Step: 4
Training loss: 1.0154753923416138
Validation loss: 2.215456942717234

Epoch: 6| Step: 5
Training loss: 1.027732253074646
Validation loss: 2.1925217509269714

Epoch: 6| Step: 6
Training loss: 1.1987096071243286
Validation loss: 2.2294923464457193

Epoch: 6| Step: 7
Training loss: 1.601994514465332
Validation loss: 2.189872602621714

Epoch: 6| Step: 8
Training loss: 0.8579984903335571
Validation loss: 2.176894247531891

Epoch: 6| Step: 9
Training loss: 1.1660571098327637
Validation loss: 2.11671374241511

Epoch: 6| Step: 10
Training loss: 0.8810673952102661
Validation loss: 2.128283202648163

Epoch: 6| Step: 11
Training loss: 1.4614486694335938
Validation loss: 2.1079782247543335

Epoch: 6| Step: 12
Training loss: 1.8767187595367432
Validation loss: 2.097204585870107

Epoch: 6| Step: 13
Training loss: 1.8026471138000488
Validation loss: 2.093787908554077

Epoch: 363| Step: 0
Training loss: 1.4926267862319946
Validation loss: 2.0722727378209433

Epoch: 6| Step: 1
Training loss: 0.8503953218460083
Validation loss: 2.0968185464541116

Epoch: 6| Step: 2
Training loss: 0.7556946277618408
Validation loss: 2.0669004122416177

Epoch: 6| Step: 3
Training loss: 1.5776714086532593
Validation loss: 2.121883273124695

Epoch: 6| Step: 4
Training loss: 1.851604700088501
Validation loss: 2.130994657675425

Epoch: 6| Step: 5
Training loss: 0.5097877383232117
Validation loss: 2.159389058748881

Epoch: 6| Step: 6
Training loss: 1.274909496307373
Validation loss: 2.2142462134361267

Epoch: 6| Step: 7
Training loss: 1.349853515625
Validation loss: 2.160527487595876

Epoch: 6| Step: 8
Training loss: 0.8526053428649902
Validation loss: 2.179656227429708

Epoch: 6| Step: 9
Training loss: 1.0217232704162598
Validation loss: 2.239003916581472

Epoch: 6| Step: 10
Training loss: 0.7940509915351868
Validation loss: 2.227252999941508

Epoch: 6| Step: 11
Training loss: 1.3048187494277954
Validation loss: 2.218974550565084

Epoch: 6| Step: 12
Training loss: 1.4716531038284302
Validation loss: 2.189241329828898

Epoch: 6| Step: 13
Training loss: 1.1484565734863281
Validation loss: 2.1861939231554666

Epoch: 364| Step: 0
Training loss: 1.2764570713043213
Validation loss: 2.13978640238444

Epoch: 6| Step: 1
Training loss: 1.829023003578186
Validation loss: 2.152761081854502

Epoch: 6| Step: 2
Training loss: 1.5881372690200806
Validation loss: 2.1399853428204856

Epoch: 6| Step: 3
Training loss: 0.5087496042251587
Validation loss: 2.1434754729270935

Epoch: 6| Step: 4
Training loss: 1.2277472019195557
Validation loss: 2.130222221215566

Epoch: 6| Step: 5
Training loss: 0.8283349275588989
Validation loss: 2.110016703605652

Epoch: 6| Step: 6
Training loss: 1.5769957304000854
Validation loss: 2.0787090063095093

Epoch: 6| Step: 7
Training loss: 1.2811249494552612
Validation loss: 2.1177566051483154

Epoch: 6| Step: 8
Training loss: 0.8881588578224182
Validation loss: 2.1223882834116616

Epoch: 6| Step: 9
Training loss: 1.3242841958999634
Validation loss: 2.1036996841430664

Epoch: 6| Step: 10
Training loss: 1.3408806324005127
Validation loss: 2.1008906960487366

Epoch: 6| Step: 11
Training loss: 0.4055161476135254
Validation loss: 2.084234356880188

Epoch: 6| Step: 12
Training loss: 0.874242901802063
Validation loss: 2.102664669354757

Epoch: 6| Step: 13
Training loss: 0.9338234066963196
Validation loss: 2.0942400892575583

Epoch: 365| Step: 0
Training loss: 0.6823698878288269
Validation loss: 2.1114245653152466

Epoch: 6| Step: 1
Training loss: 0.9108731746673584
Validation loss: 2.101170380910238

Epoch: 6| Step: 2
Training loss: 1.224719524383545
Validation loss: 2.0982185204823813

Epoch: 6| Step: 3
Training loss: 1.1135592460632324
Validation loss: 2.180167277654012

Epoch: 6| Step: 4
Training loss: 1.0134292840957642
Validation loss: 2.1113430062929788

Epoch: 6| Step: 5
Training loss: 1.3214818239212036
Validation loss: 2.1198511123657227

Epoch: 6| Step: 6
Training loss: 1.5201025009155273
Validation loss: 2.1562193830808005

Epoch: 6| Step: 7
Training loss: 1.2208778858184814
Validation loss: 2.1040493647257485

Epoch: 6| Step: 8
Training loss: 0.8425685167312622
Validation loss: 2.093749225139618

Epoch: 6| Step: 9
Training loss: 1.4591636657714844
Validation loss: 2.109445631504059

Epoch: 6| Step: 10
Training loss: 1.117633581161499
Validation loss: 2.0932783484458923

Epoch: 6| Step: 11
Training loss: 1.3361315727233887
Validation loss: 2.109281897544861

Epoch: 6| Step: 12
Training loss: 0.8253855109214783
Validation loss: 2.1480503479639688

Epoch: 6| Step: 13
Training loss: 1.278517484664917
Validation loss: 2.1120792428652444

Epoch: 366| Step: 0
Training loss: 1.0924887657165527
Validation loss: 2.1354129910469055

Epoch: 6| Step: 1
Training loss: 1.0976487398147583
Validation loss: 2.1120634277661643

Epoch: 6| Step: 2
Training loss: 0.8903764486312866
Validation loss: 2.111374100049337

Epoch: 6| Step: 3
Training loss: 0.9172441363334656
Validation loss: 2.1257622241973877

Epoch: 6| Step: 4
Training loss: 1.9697580337524414
Validation loss: 2.1153870224952698

Epoch: 6| Step: 5
Training loss: 1.658382534980774
Validation loss: 2.090946535269419

Epoch: 6| Step: 6
Training loss: 0.7290531396865845
Validation loss: 2.0904300014177957

Epoch: 6| Step: 7
Training loss: 0.987687349319458
Validation loss: 2.0913798610369363

Epoch: 6| Step: 8
Training loss: 1.072005033493042
Validation loss: 2.076117833455404

Epoch: 6| Step: 9
Training loss: 1.0904771089553833
Validation loss: 2.128633459409078

Epoch: 6| Step: 10
Training loss: 0.713969886302948
Validation loss: 2.1159587502479553

Epoch: 6| Step: 11
Training loss: 0.7542277574539185
Validation loss: 2.118090351422628

Epoch: 6| Step: 12
Training loss: 1.2450213432312012
Validation loss: 2.1138630906740823

Epoch: 6| Step: 13
Training loss: 1.5338048934936523
Validation loss: 2.101321498552958

Epoch: 367| Step: 0
Training loss: 0.9445345401763916
Validation loss: 2.1229774355888367

Epoch: 6| Step: 1
Training loss: 0.9915161728858948
Validation loss: 2.195255160331726

Epoch: 6| Step: 2
Training loss: 1.2120652198791504
Validation loss: 2.1831345756848655

Epoch: 6| Step: 3
Training loss: 1.3546533584594727
Validation loss: 2.178471326828003

Epoch: 6| Step: 4
Training loss: 1.0782564878463745
Validation loss: 2.2094096342722573

Epoch: 6| Step: 5
Training loss: 1.165062427520752
Validation loss: 2.1474137902259827

Epoch: 6| Step: 6
Training loss: 1.2515146732330322
Validation loss: 2.1638443072636924

Epoch: 6| Step: 7
Training loss: 1.485490322113037
Validation loss: 2.119489292303721

Epoch: 6| Step: 8
Training loss: 0.855404257774353
Validation loss: 2.1074215372403464

Epoch: 6| Step: 9
Training loss: 1.298525333404541
Validation loss: 2.12644499540329

Epoch: 6| Step: 10
Training loss: 0.7833212018013
Validation loss: 2.1037282745043435

Epoch: 6| Step: 11
Training loss: 1.500395655632019
Validation loss: 2.1137457489967346

Epoch: 6| Step: 12
Training loss: 1.43082594871521
Validation loss: 2.124126374721527

Epoch: 6| Step: 13
Training loss: 1.3398048877716064
Validation loss: 2.126843571662903

Epoch: 368| Step: 0
Training loss: 0.6450058817863464
Validation loss: 2.1209400494893393

Epoch: 6| Step: 1
Training loss: 1.258943796157837
Validation loss: 2.144278963406881

Epoch: 6| Step: 2
Training loss: 0.967582643032074
Validation loss: 2.1005366245905557

Epoch: 6| Step: 3
Training loss: 0.6346134543418884
Validation loss: 2.1218626896540322

Epoch: 6| Step: 4
Training loss: 1.6302790641784668
Validation loss: 2.128030081590017

Epoch: 6| Step: 5
Training loss: 1.2736554145812988
Validation loss: 2.122626304626465

Epoch: 6| Step: 6
Training loss: 2.0376179218292236
Validation loss: 2.1196912924448648

Epoch: 6| Step: 7
Training loss: 0.9229474663734436
Validation loss: 2.1645684838294983

Epoch: 6| Step: 8
Training loss: 1.0585567951202393
Validation loss: 2.1470348238945007

Epoch: 6| Step: 9
Training loss: 0.8628909587860107
Validation loss: 2.1639806230862937

Epoch: 6| Step: 10
Training loss: 1.0573103427886963
Validation loss: 2.1258002718289695

Epoch: 6| Step: 11
Training loss: 1.3222413063049316
Validation loss: 2.161360522111257

Epoch: 6| Step: 12
Training loss: 0.9662100076675415
Validation loss: 2.1357631285985312

Epoch: 6| Step: 13
Training loss: 1.3035554885864258
Validation loss: 2.1589982509613037

Epoch: 369| Step: 0
Training loss: 2.19167423248291
Validation loss: 2.0915155609448752

Epoch: 6| Step: 1
Training loss: 1.2509486675262451
Validation loss: 2.146579305330912

Epoch: 6| Step: 2
Training loss: 1.9072065353393555
Validation loss: 2.1362055937449136

Epoch: 6| Step: 3
Training loss: 1.2051143646240234
Validation loss: 2.148965040842692

Epoch: 6| Step: 4
Training loss: 0.6975868940353394
Validation loss: 2.1801377733548484

Epoch: 6| Step: 5
Training loss: 0.9116703867912292
Validation loss: 2.220689674218496

Epoch: 6| Step: 6
Training loss: 0.810446560382843
Validation loss: 2.197257955869039

Epoch: 6| Step: 7
Training loss: 0.9762680530548096
Validation loss: 2.2085439562797546

Epoch: 6| Step: 8
Training loss: 1.0578278303146362
Validation loss: 2.2275126377741494

Epoch: 6| Step: 9
Training loss: 0.7118838429450989
Validation loss: 2.22303440173467

Epoch: 6| Step: 10
Training loss: 0.7958288192749023
Validation loss: 2.1923640966415405

Epoch: 6| Step: 11
Training loss: 0.9006065130233765
Validation loss: 2.1946122646331787

Epoch: 6| Step: 12
Training loss: 1.3971376419067383
Validation loss: 2.2105989257494607

Epoch: 6| Step: 13
Training loss: 1.6985456943511963
Validation loss: 2.182041803995768

Epoch: 370| Step: 0
Training loss: 0.9445617198944092
Validation loss: 2.1596151987711587

Epoch: 6| Step: 1
Training loss: 1.1465833187103271
Validation loss: 2.158340414365133

Epoch: 6| Step: 2
Training loss: 1.2804557085037231
Validation loss: 2.110504229863485

Epoch: 6| Step: 3
Training loss: 0.7631154656410217
Validation loss: 2.0874701142311096

Epoch: 6| Step: 4
Training loss: 1.1407432556152344
Validation loss: 2.059260308742523

Epoch: 6| Step: 5
Training loss: 1.0641965866088867
Validation loss: 2.078421195348104

Epoch: 6| Step: 6
Training loss: 1.2960498332977295
Validation loss: 2.046484331289927

Epoch: 6| Step: 7
Training loss: 0.9481550455093384
Validation loss: 2.0354085564613342

Epoch: 6| Step: 8
Training loss: 0.7676444053649902
Validation loss: 2.049282650152842

Epoch: 6| Step: 9
Training loss: 2.089843988418579
Validation loss: 2.05504576365153

Epoch: 6| Step: 10
Training loss: 1.353670358657837
Validation loss: 2.049492518107096

Epoch: 6| Step: 11
Training loss: 0.5991849899291992
Validation loss: 2.0810254414876304

Epoch: 6| Step: 12
Training loss: 1.0547525882720947
Validation loss: 2.1026889085769653

Epoch: 6| Step: 13
Training loss: 1.5521105527877808
Validation loss: 2.0369450449943542

Epoch: 371| Step: 0
Training loss: 0.998585045337677
Validation loss: 2.107754409313202

Epoch: 6| Step: 1
Training loss: 1.261152982711792
Validation loss: 2.1102698842684426

Epoch: 6| Step: 2
Training loss: 1.629178524017334
Validation loss: 2.1282423734664917

Epoch: 6| Step: 3
Training loss: 0.9523375034332275
Validation loss: 2.155437151590983

Epoch: 6| Step: 4
Training loss: 1.2523951530456543
Validation loss: 2.092999597390493

Epoch: 6| Step: 5
Training loss: 0.7651832103729248
Validation loss: 2.1245139837265015

Epoch: 6| Step: 6
Training loss: 1.096381664276123
Validation loss: 2.103806495666504

Epoch: 6| Step: 7
Training loss: 1.0130274295806885
Validation loss: 2.137173851331075

Epoch: 6| Step: 8
Training loss: 1.1971683502197266
Validation loss: 2.1296367843945823

Epoch: 6| Step: 9
Training loss: 0.8461609482765198
Validation loss: 2.1324762304623923

Epoch: 6| Step: 10
Training loss: 1.2174879312515259
Validation loss: 2.140538215637207

Epoch: 6| Step: 11
Training loss: 1.3015046119689941
Validation loss: 2.116245965162913

Epoch: 6| Step: 12
Training loss: 0.8365336656570435
Validation loss: 2.143364429473877

Epoch: 6| Step: 13
Training loss: 1.1640900373458862
Validation loss: 2.10791015625

Epoch: 372| Step: 0
Training loss: 0.9976681470870972
Validation loss: 2.072392702102661

Epoch: 6| Step: 1
Training loss: 1.0965559482574463
Validation loss: 2.0784231225649514

Epoch: 6| Step: 2
Training loss: 0.9253948330879211
Validation loss: 2.0697046319643655

Epoch: 6| Step: 3
Training loss: 1.5217680931091309
Validation loss: 2.0670244693756104

Epoch: 6| Step: 4
Training loss: 0.8258504867553711
Validation loss: 2.067074716091156

Epoch: 6| Step: 5
Training loss: 0.8901997804641724
Validation loss: 2.0807644923528037

Epoch: 6| Step: 6
Training loss: 1.3168132305145264
Validation loss: 2.0688514709472656

Epoch: 6| Step: 7
Training loss: 1.6426992416381836
Validation loss: 2.108491082986196

Epoch: 6| Step: 8
Training loss: 0.8811630010604858
Validation loss: 2.0796509782473245

Epoch: 6| Step: 9
Training loss: 1.4388959407806396
Validation loss: 2.11201282342275

Epoch: 6| Step: 10
Training loss: 0.7079150676727295
Validation loss: 2.098339001337687

Epoch: 6| Step: 11
Training loss: 1.2347837686538696
Validation loss: 2.1586110591888428

Epoch: 6| Step: 12
Training loss: 1.378983736038208
Validation loss: 2.091699540615082

Epoch: 6| Step: 13
Training loss: 0.8513193726539612
Validation loss: 2.1882835030555725

Epoch: 373| Step: 0
Training loss: 0.9117236733436584
Validation loss: 2.1857203245162964

Epoch: 6| Step: 1
Training loss: 0.9690076112747192
Validation loss: 2.1755808194478354

Epoch: 6| Step: 2
Training loss: 1.1208596229553223
Validation loss: 2.208578904469808

Epoch: 6| Step: 3
Training loss: 1.4148727655410767
Validation loss: 2.163810670375824

Epoch: 6| Step: 4
Training loss: 1.5171775817871094
Validation loss: 2.1790857712427774

Epoch: 6| Step: 5
Training loss: 1.212072491645813
Validation loss: 2.1866161227226257

Epoch: 6| Step: 6
Training loss: 0.6723760366439819
Validation loss: 2.135922988255819

Epoch: 6| Step: 7
Training loss: 1.4048349857330322
Validation loss: 2.1397345264752707

Epoch: 6| Step: 8
Training loss: 0.7932906150817871
Validation loss: 2.118458648522695

Epoch: 6| Step: 9
Training loss: 1.3760093450546265
Validation loss: 2.1188479463259378

Epoch: 6| Step: 10
Training loss: 1.4351307153701782
Validation loss: 2.129514992237091

Epoch: 6| Step: 11
Training loss: 0.8688716292381287
Validation loss: 2.1450344125429788

Epoch: 6| Step: 12
Training loss: 1.4306892156600952
Validation loss: 2.1410349011421204

Epoch: 6| Step: 13
Training loss: 1.118499517440796
Validation loss: 2.1360283692677817

Epoch: 374| Step: 0
Training loss: 0.9431788921356201
Validation loss: 2.151575525601705

Epoch: 6| Step: 1
Training loss: 1.2791041135787964
Validation loss: 2.1898711721102395

Epoch: 6| Step: 2
Training loss: 1.4607651233673096
Validation loss: 2.1908262769381204

Epoch: 6| Step: 3
Training loss: 0.8044003248214722
Validation loss: 2.178354183832804

Epoch: 6| Step: 4
Training loss: 1.3790006637573242
Validation loss: 2.1799818674723306

Epoch: 6| Step: 5
Training loss: 0.8418729901313782
Validation loss: 2.157719294230143

Epoch: 6| Step: 6
Training loss: 0.905397891998291
Validation loss: 2.141597012678782

Epoch: 6| Step: 7
Training loss: 1.5201256275177002
Validation loss: 2.107378681500753

Epoch: 6| Step: 8
Training loss: 1.601256012916565
Validation loss: 2.1102131605148315

Epoch: 6| Step: 9
Training loss: 0.956684947013855
Validation loss: 2.1299129327138266

Epoch: 6| Step: 10
Training loss: 0.7777665853500366
Validation loss: 2.1029364864031472

Epoch: 6| Step: 11
Training loss: 1.0240111351013184
Validation loss: 2.1161078413327536

Epoch: 6| Step: 12
Training loss: 1.188361644744873
Validation loss: 2.0793698827425637

Epoch: 6| Step: 13
Training loss: 1.2131928205490112
Validation loss: 2.0739936033884683

Epoch: 375| Step: 0
Training loss: 0.4326045513153076
Validation loss: 2.0571606755256653

Epoch: 6| Step: 1
Training loss: 1.0658760070800781
Validation loss: 2.097026268641154

Epoch: 6| Step: 2
Training loss: 1.294053554534912
Validation loss: 2.089373290538788

Epoch: 6| Step: 3
Training loss: 0.9816195368766785
Validation loss: 2.095078925291697

Epoch: 6| Step: 4
Training loss: 0.6175746917724609
Validation loss: 2.072012106577555

Epoch: 6| Step: 5
Training loss: 1.302342176437378
Validation loss: 2.1255486806233725

Epoch: 6| Step: 6
Training loss: 1.7343634366989136
Validation loss: 2.08980256319046

Epoch: 6| Step: 7
Training loss: 0.842027485370636
Validation loss: 2.1024882197380066

Epoch: 6| Step: 8
Training loss: 1.0137501955032349
Validation loss: 2.1099053025245667

Epoch: 6| Step: 9
Training loss: 0.8974963426589966
Validation loss: 2.112151642640432

Epoch: 6| Step: 10
Training loss: 1.0599079132080078
Validation loss: 2.1168991923332214

Epoch: 6| Step: 11
Training loss: 1.711806058883667
Validation loss: 2.1308032274246216

Epoch: 6| Step: 12
Training loss: 0.7662301063537598
Validation loss: 2.141236146291097

Epoch: 6| Step: 13
Training loss: 1.628218173980713
Validation loss: 2.100520968437195

Epoch: 376| Step: 0
Training loss: 1.3137946128845215
Validation loss: 2.1347797314325967

Epoch: 6| Step: 1
Training loss: 1.1102272272109985
Validation loss: 2.1310372352600098

Epoch: 6| Step: 2
Training loss: 0.7681736350059509
Validation loss: 2.157372156778971

Epoch: 6| Step: 3
Training loss: 1.7804527282714844
Validation loss: 2.1451643109321594

Epoch: 6| Step: 4
Training loss: 0.8221151232719421
Validation loss: 2.141176184018453

Epoch: 6| Step: 5
Training loss: 0.71341872215271
Validation loss: 2.1305423974990845

Epoch: 6| Step: 6
Training loss: 0.8572885990142822
Validation loss: 2.1090057094891868

Epoch: 6| Step: 7
Training loss: 1.1952760219573975
Validation loss: 2.0826655427614846

Epoch: 6| Step: 8
Training loss: 1.3394320011138916
Validation loss: 2.1258262197176614

Epoch: 6| Step: 9
Training loss: 1.0961480140686035
Validation loss: 2.1108597914377847

Epoch: 6| Step: 10
Training loss: 0.4696504473686218
Validation loss: 2.104683220386505

Epoch: 6| Step: 11
Training loss: 0.802753210067749
Validation loss: 2.1164064009984336

Epoch: 6| Step: 12
Training loss: 1.7862331867218018
Validation loss: 2.108185867468516

Epoch: 6| Step: 13
Training loss: 0.7190314531326294
Validation loss: 2.0677274266878762

Epoch: 377| Step: 0
Training loss: 1.4441112279891968
Validation loss: 2.152071992556254

Epoch: 6| Step: 1
Training loss: 1.0264517068862915
Validation loss: 2.1590248147646585

Epoch: 6| Step: 2
Training loss: 0.5036315321922302
Validation loss: 2.1435703237851462

Epoch: 6| Step: 3
Training loss: 1.2709572315216064
Validation loss: 2.1698333819707236

Epoch: 6| Step: 4
Training loss: 0.6791317462921143
Validation loss: 2.171698808670044

Epoch: 6| Step: 5
Training loss: 0.7770614624023438
Validation loss: 2.1518539985020957

Epoch: 6| Step: 6
Training loss: 0.839769184589386
Validation loss: 2.165140231450399

Epoch: 6| Step: 7
Training loss: 1.3584904670715332
Validation loss: 2.1517159938812256

Epoch: 6| Step: 8
Training loss: 1.3298429250717163
Validation loss: 2.170082072416941

Epoch: 6| Step: 9
Training loss: 1.2510502338409424
Validation loss: 2.1562420129776

Epoch: 6| Step: 10
Training loss: 0.8423387408256531
Validation loss: 2.131816645463308

Epoch: 6| Step: 11
Training loss: 1.2171916961669922
Validation loss: 2.1798575123151145

Epoch: 6| Step: 12
Training loss: 0.9817003011703491
Validation loss: 2.1353253722190857

Epoch: 6| Step: 13
Training loss: 1.3957273960113525
Validation loss: 2.1044861872990928

Epoch: 378| Step: 0
Training loss: 1.4056780338287354
Validation loss: 2.156666020552317

Epoch: 6| Step: 1
Training loss: 0.9168581366539001
Validation loss: 2.1404568950335183

Epoch: 6| Step: 2
Training loss: 0.9705300331115723
Validation loss: 2.1672944823900857

Epoch: 6| Step: 3
Training loss: 0.7693292498588562
Validation loss: 2.1266260743141174

Epoch: 6| Step: 4
Training loss: 1.027557373046875
Validation loss: 2.1323200861612954

Epoch: 6| Step: 5
Training loss: 1.0703387260437012
Validation loss: 2.1545153657595315

Epoch: 6| Step: 6
Training loss: 1.8612864017486572
Validation loss: 2.1251110434532166

Epoch: 6| Step: 7
Training loss: 1.112862467765808
Validation loss: 2.1120697061220803

Epoch: 6| Step: 8
Training loss: 1.3152580261230469
Validation loss: 2.1230130195617676

Epoch: 6| Step: 9
Training loss: 0.7559915781021118
Validation loss: 2.1440632740656533

Epoch: 6| Step: 10
Training loss: 1.5614886283874512
Validation loss: 2.1125223636627197

Epoch: 6| Step: 11
Training loss: 0.6353416442871094
Validation loss: 2.140001038710276

Epoch: 6| Step: 12
Training loss: 0.5945897102355957
Validation loss: 2.109052280584971

Epoch: 6| Step: 13
Training loss: 1.0831853151321411
Validation loss: 2.104365070660909

Epoch: 379| Step: 0
Training loss: 0.5995703935623169
Validation loss: 2.1145764589309692

Epoch: 6| Step: 1
Training loss: 1.021572232246399
Validation loss: 2.1225239038467407

Epoch: 6| Step: 2
Training loss: 0.32603001594543457
Validation loss: 2.119475801785787

Epoch: 6| Step: 3
Training loss: 0.9337635636329651
Validation loss: 2.122403939565023

Epoch: 6| Step: 4
Training loss: 1.227405309677124
Validation loss: 2.179445823033651

Epoch: 6| Step: 5
Training loss: 0.9027338027954102
Validation loss: 2.123391648133596

Epoch: 6| Step: 6
Training loss: 0.5362057089805603
Validation loss: 2.1413193543752036

Epoch: 6| Step: 7
Training loss: 1.1273188591003418
Validation loss: 2.0931578278541565

Epoch: 6| Step: 8
Training loss: 0.48004841804504395
Validation loss: 2.111768384774526

Epoch: 6| Step: 9
Training loss: 1.5342652797698975
Validation loss: 2.1141122380892434

Epoch: 6| Step: 10
Training loss: 1.8349735736846924
Validation loss: 2.12194961309433

Epoch: 6| Step: 11
Training loss: 1.1818581819534302
Validation loss: 2.1296014189720154

Epoch: 6| Step: 12
Training loss: 1.4635542631149292
Validation loss: 2.1031341354052224

Epoch: 6| Step: 13
Training loss: 1.6751482486724854
Validation loss: 2.0984275142351785

Epoch: 380| Step: 0
Training loss: 0.833088755607605
Validation loss: 2.089535971482595

Epoch: 6| Step: 1
Training loss: 0.9911953806877136
Validation loss: 2.086488942305247

Epoch: 6| Step: 2
Training loss: 0.9138996601104736
Validation loss: 2.094510853290558

Epoch: 6| Step: 3
Training loss: 1.0771825313568115
Validation loss: 2.074921409289042

Epoch: 6| Step: 4
Training loss: 0.8830244541168213
Validation loss: 2.020450154940287

Epoch: 6| Step: 5
Training loss: 0.6007733941078186
Validation loss: 2.062231183052063

Epoch: 6| Step: 6
Training loss: 1.5957595109939575
Validation loss: 2.085662563641866

Epoch: 6| Step: 7
Training loss: 1.0309849977493286
Validation loss: 2.0872294108072915

Epoch: 6| Step: 8
Training loss: 1.2907178401947021
Validation loss: 2.0422340035438538

Epoch: 6| Step: 9
Training loss: 1.2109315395355225
Validation loss: 2.088408052921295

Epoch: 6| Step: 10
Training loss: 1.6621540784835815
Validation loss: 2.1056854923566184

Epoch: 6| Step: 11
Training loss: 0.5479483604431152
Validation loss: 2.040702223777771

Epoch: 6| Step: 12
Training loss: 1.1403467655181885
Validation loss: 2.0718916257222495

Epoch: 6| Step: 13
Training loss: 1.0579519271850586
Validation loss: 2.0725887020428977

Epoch: 381| Step: 0
Training loss: 1.2282179594039917
Validation loss: 2.1038439671198526

Epoch: 6| Step: 1
Training loss: 0.7799955606460571
Validation loss: 2.084699591000875

Epoch: 6| Step: 2
Training loss: 1.0763466358184814
Validation loss: 2.096920291582743

Epoch: 6| Step: 3
Training loss: 0.795167088508606
Validation loss: 2.0359973510106406

Epoch: 6| Step: 4
Training loss: 1.2624393701553345
Validation loss: 2.1063380440076194

Epoch: 6| Step: 5
Training loss: 1.4583756923675537
Validation loss: 2.115217089653015

Epoch: 6| Step: 6
Training loss: 0.8382365703582764
Validation loss: 2.0910704334576926

Epoch: 6| Step: 7
Training loss: 1.2307417392730713
Validation loss: 2.099057952562968

Epoch: 6| Step: 8
Training loss: 1.1869759559631348
Validation loss: 2.1165663798650107

Epoch: 6| Step: 9
Training loss: 1.1536091566085815
Validation loss: 2.1270438035329184

Epoch: 6| Step: 10
Training loss: 0.9978841543197632
Validation loss: 2.153376599152883

Epoch: 6| Step: 11
Training loss: 1.1828534603118896
Validation loss: 2.1377799908320108

Epoch: 6| Step: 12
Training loss: 1.0553597211837769
Validation loss: 2.170460283756256

Epoch: 6| Step: 13
Training loss: 0.7427787780761719
Validation loss: 2.13929812113444

Epoch: 382| Step: 0
Training loss: 1.0735924243927002
Validation loss: 2.156350016593933

Epoch: 6| Step: 1
Training loss: 1.6195645332336426
Validation loss: 2.1444970766703286

Epoch: 6| Step: 2
Training loss: 1.2595843076705933
Validation loss: 2.171384890874227

Epoch: 6| Step: 3
Training loss: 0.7450618147850037
Validation loss: 2.1591794888178506

Epoch: 6| Step: 4
Training loss: 1.8736035823822021
Validation loss: 2.1635241905848184

Epoch: 6| Step: 5
Training loss: 1.5000730752944946
Validation loss: 2.14883291721344

Epoch: 6| Step: 6
Training loss: 0.789212703704834
Validation loss: 2.1384229262669883

Epoch: 6| Step: 7
Training loss: 0.9635851383209229
Validation loss: 2.0833709239959717

Epoch: 6| Step: 8
Training loss: 1.5450323820114136
Validation loss: 2.124265452226003

Epoch: 6| Step: 9
Training loss: 0.8560340404510498
Validation loss: 2.081479251384735

Epoch: 6| Step: 10
Training loss: 1.1362621784210205
Validation loss: 2.094154973824819

Epoch: 6| Step: 11
Training loss: 0.652604877948761
Validation loss: 2.0931630531946817

Epoch: 6| Step: 12
Training loss: 0.9026817679405212
Validation loss: 2.0972097913424173

Epoch: 6| Step: 13
Training loss: 1.0517586469650269
Validation loss: 2.098989486694336

Epoch: 383| Step: 0
Training loss: 1.3249742984771729
Validation loss: 2.0746976733207703

Epoch: 6| Step: 1
Training loss: 1.084572672843933
Validation loss: 2.104853093624115

Epoch: 6| Step: 2
Training loss: 0.8825715780258179
Validation loss: 2.1193875273068747

Epoch: 6| Step: 3
Training loss: 1.5748775005340576
Validation loss: 2.084326148033142

Epoch: 6| Step: 4
Training loss: 1.2706128358840942
Validation loss: 2.1102576653162637

Epoch: 6| Step: 5
Training loss: 1.1090590953826904
Validation loss: 2.108224391937256

Epoch: 6| Step: 6
Training loss: 0.6231856346130371
Validation loss: 2.0845152934392295

Epoch: 6| Step: 7
Training loss: 1.272226095199585
Validation loss: 2.080473164717356

Epoch: 6| Step: 8
Training loss: 1.1628878116607666
Validation loss: 2.090914169947306

Epoch: 6| Step: 9
Training loss: 0.7848762273788452
Validation loss: 2.0474660197893777

Epoch: 6| Step: 10
Training loss: 0.8246711492538452
Validation loss: 2.040980875492096

Epoch: 6| Step: 11
Training loss: 1.1551560163497925
Validation loss: 2.032440483570099

Epoch: 6| Step: 12
Training loss: 0.9920402765274048
Validation loss: 2.0223357677459717

Epoch: 6| Step: 13
Training loss: 1.26668119430542
Validation loss: 2.0425320863723755

Epoch: 384| Step: 0
Training loss: 0.6483272314071655
Validation loss: 2.0482176542282104

Epoch: 6| Step: 1
Training loss: 1.067373514175415
Validation loss: 2.0295891960461936

Epoch: 6| Step: 2
Training loss: 0.9485257267951965
Validation loss: 2.0309720238049827

Epoch: 6| Step: 3
Training loss: 1.6776180267333984
Validation loss: 2.0798489650090537

Epoch: 6| Step: 4
Training loss: 1.2097028493881226
Validation loss: 2.075830658276876

Epoch: 6| Step: 5
Training loss: 0.5307992696762085
Validation loss: 2.088435928026835

Epoch: 6| Step: 6
Training loss: 0.9113022089004517
Validation loss: 2.114993453025818

Epoch: 6| Step: 7
Training loss: 0.8347424268722534
Validation loss: 2.111763139565786

Epoch: 6| Step: 8
Training loss: 0.8434824347496033
Validation loss: 2.127809743086497

Epoch: 6| Step: 9
Training loss: 2.070312023162842
Validation loss: 2.133312443892161

Epoch: 6| Step: 10
Training loss: 0.9871872663497925
Validation loss: 2.1098769505818686

Epoch: 6| Step: 11
Training loss: 1.1925339698791504
Validation loss: 2.0917115012804666

Epoch: 6| Step: 12
Training loss: 1.2016053199768066
Validation loss: 2.131158709526062

Epoch: 6| Step: 13
Training loss: 0.9230276346206665
Validation loss: 2.0766837000846863

Epoch: 385| Step: 0
Training loss: 1.3430469036102295
Validation loss: 2.072150627772013

Epoch: 6| Step: 1
Training loss: 1.5274982452392578
Validation loss: 2.1485215028127036

Epoch: 6| Step: 2
Training loss: 1.0155880451202393
Validation loss: 2.1161662340164185

Epoch: 6| Step: 3
Training loss: 0.6109066605567932
Validation loss: 2.1081263621648154

Epoch: 6| Step: 4
Training loss: 1.240050196647644
Validation loss: 2.0923702319463096

Epoch: 6| Step: 5
Training loss: 0.8814840316772461
Validation loss: 2.106325368086497

Epoch: 6| Step: 6
Training loss: 1.439574956893921
Validation loss: 2.068891942501068

Epoch: 6| Step: 7
Training loss: 0.5529910922050476
Validation loss: 2.0971226493517556

Epoch: 6| Step: 8
Training loss: 0.8325772285461426
Validation loss: 2.0835121273994446

Epoch: 6| Step: 9
Training loss: 1.7030317783355713
Validation loss: 2.1179664929707847

Epoch: 6| Step: 10
Training loss: 0.7576074600219727
Validation loss: 2.1088225841522217

Epoch: 6| Step: 11
Training loss: 1.1549246311187744
Validation loss: 2.108539879322052

Epoch: 6| Step: 12
Training loss: 0.6184327602386475
Validation loss: 2.13092573483785

Epoch: 6| Step: 13
Training loss: 1.4473918676376343
Validation loss: 2.112305005391439

Epoch: 386| Step: 0
Training loss: 0.8893427848815918
Validation loss: 2.1209805011749268

Epoch: 6| Step: 1
Training loss: 1.0285381078720093
Validation loss: 2.08922278881073

Epoch: 6| Step: 2
Training loss: 1.378464937210083
Validation loss: 2.116154591242472

Epoch: 6| Step: 3
Training loss: 1.343031644821167
Validation loss: 2.052791257699331

Epoch: 6| Step: 4
Training loss: 0.7291909456253052
Validation loss: 2.0692115227381387

Epoch: 6| Step: 5
Training loss: 1.6089205741882324
Validation loss: 2.0401880542437234

Epoch: 6| Step: 6
Training loss: 0.7210885882377625
Validation loss: 2.071008642514547

Epoch: 6| Step: 7
Training loss: 0.7180484533309937
Validation loss: 2.0741786559422812

Epoch: 6| Step: 8
Training loss: 1.8709583282470703
Validation loss: 2.0388352473576865

Epoch: 6| Step: 9
Training loss: 1.2970151901245117
Validation loss: 2.061442752679189

Epoch: 6| Step: 10
Training loss: 0.7480134963989258
Validation loss: 2.0580982168515525

Epoch: 6| Step: 11
Training loss: 1.302534580230713
Validation loss: 2.101635138193766

Epoch: 6| Step: 12
Training loss: 0.7177985906600952
Validation loss: 2.0977394382158914

Epoch: 6| Step: 13
Training loss: 0.6136743426322937
Validation loss: 2.1164045929908752

Epoch: 387| Step: 0
Training loss: 1.184475064277649
Validation loss: 2.0783032973607383

Epoch: 6| Step: 1
Training loss: 1.0360000133514404
Validation loss: 2.142028013865153

Epoch: 6| Step: 2
Training loss: 1.304740071296692
Validation loss: 2.1191627581914267

Epoch: 6| Step: 3
Training loss: 1.0088372230529785
Validation loss: 2.138934334119161

Epoch: 6| Step: 4
Training loss: 1.4329946041107178
Validation loss: 2.100194215774536

Epoch: 6| Step: 5
Training loss: 1.25314199924469
Validation loss: 2.130085527896881

Epoch: 6| Step: 6
Training loss: 0.9709723591804504
Validation loss: 2.111309031645457

Epoch: 6| Step: 7
Training loss: 0.5743744373321533
Validation loss: 2.110310196876526

Epoch: 6| Step: 8
Training loss: 1.2004578113555908
Validation loss: 2.133466064929962

Epoch: 6| Step: 9
Training loss: 0.8603676557540894
Validation loss: 2.089069426059723

Epoch: 6| Step: 10
Training loss: 0.9632758498191833
Validation loss: 2.078722059726715

Epoch: 6| Step: 11
Training loss: 0.9896244406700134
Validation loss: 2.1126864751180015

Epoch: 6| Step: 12
Training loss: 0.9248265624046326
Validation loss: 2.068234125773112

Epoch: 6| Step: 13
Training loss: 0.9028195142745972
Validation loss: 2.064945936203003

Epoch: 388| Step: 0
Training loss: 0.8208433389663696
Validation loss: 2.100655953089396

Epoch: 6| Step: 1
Training loss: 1.560041904449463
Validation loss: 2.0982301433881125

Epoch: 6| Step: 2
Training loss: 1.4022250175476074
Validation loss: 2.091706474622091

Epoch: 6| Step: 3
Training loss: 0.6481173038482666
Validation loss: 2.090779105822245

Epoch: 6| Step: 4
Training loss: 1.1661280393600464
Validation loss: 2.0442014932632446

Epoch: 6| Step: 5
Training loss: 1.0873934030532837
Validation loss: 2.0688417553901672

Epoch: 6| Step: 6
Training loss: 0.3388984203338623
Validation loss: 2.102376341819763

Epoch: 6| Step: 7
Training loss: 0.6286716461181641
Validation loss: 2.062601407368978

Epoch: 6| Step: 8
Training loss: 0.7704378366470337
Validation loss: 2.0881036122639975

Epoch: 6| Step: 9
Training loss: 1.256656289100647
Validation loss: 2.0430628856023154

Epoch: 6| Step: 10
Training loss: 0.9394738078117371
Validation loss: 2.0750269691149392

Epoch: 6| Step: 11
Training loss: 1.2484288215637207
Validation loss: 2.0729868412017822

Epoch: 6| Step: 12
Training loss: 1.1912367343902588
Validation loss: 2.141390879948934

Epoch: 6| Step: 13
Training loss: 1.6466325521469116
Validation loss: 2.1031798720359802

Epoch: 389| Step: 0
Training loss: 1.4166808128356934
Validation loss: 2.1186272700627646

Epoch: 6| Step: 1
Training loss: 1.3750377893447876
Validation loss: 2.0881319840749106

Epoch: 6| Step: 2
Training loss: 0.8778771162033081
Validation loss: 2.107626815636953

Epoch: 6| Step: 3
Training loss: 0.9135512113571167
Validation loss: 2.0978171825408936

Epoch: 6| Step: 4
Training loss: 1.3253610134124756
Validation loss: 2.1216331322987876

Epoch: 6| Step: 5
Training loss: 0.5950561761856079
Validation loss: 2.1019722620646157

Epoch: 6| Step: 6
Training loss: 0.9154290556907654
Validation loss: 2.153470059235891

Epoch: 6| Step: 7
Training loss: 1.2055623531341553
Validation loss: 2.1016790866851807

Epoch: 6| Step: 8
Training loss: 0.6152551174163818
Validation loss: 2.0987483064333596

Epoch: 6| Step: 9
Training loss: 1.1175775527954102
Validation loss: 2.0644346276919046

Epoch: 6| Step: 10
Training loss: 1.869935154914856
Validation loss: 2.070626715819041

Epoch: 6| Step: 11
Training loss: 0.5448582172393799
Validation loss: 2.0616447726885476

Epoch: 6| Step: 12
Training loss: 0.6918903589248657
Validation loss: 2.0754233797391257

Epoch: 6| Step: 13
Training loss: 0.7557016015052795
Validation loss: 2.058395187060038

Epoch: 390| Step: 0
Training loss: 0.4906455874443054
Validation loss: 2.0657227834065757

Epoch: 6| Step: 1
Training loss: 0.9556147456169128
Validation loss: 2.09471728404363

Epoch: 6| Step: 2
Training loss: 1.1829724311828613
Validation loss: 2.0993928710619607

Epoch: 6| Step: 3
Training loss: 1.1204530000686646
Validation loss: 2.0919830004374185

Epoch: 6| Step: 4
Training loss: 1.1970497369766235
Validation loss: 2.0619889299074807

Epoch: 6| Step: 5
Training loss: 0.827292263507843
Validation loss: 2.077019373575846

Epoch: 6| Step: 6
Training loss: 1.1651265621185303
Validation loss: 2.0837860902150473

Epoch: 6| Step: 7
Training loss: 1.667183756828308
Validation loss: 2.080603539943695

Epoch: 6| Step: 8
Training loss: 0.9518681168556213
Validation loss: 2.0603498816490173

Epoch: 6| Step: 9
Training loss: 1.174149513244629
Validation loss: 2.072053531805674

Epoch: 6| Step: 10
Training loss: 0.946006178855896
Validation loss: 2.040379365285238

Epoch: 6| Step: 11
Training loss: 0.7704055309295654
Validation loss: 2.0548385779062905

Epoch: 6| Step: 12
Training loss: 1.2713382244110107
Validation loss: 2.053024391333262

Epoch: 6| Step: 13
Training loss: 0.9994227886199951
Validation loss: 2.0839534799257913

Epoch: 391| Step: 0
Training loss: 1.3315849304199219
Validation loss: 2.0703473488489785

Epoch: 6| Step: 1
Training loss: 1.5147309303283691
Validation loss: 2.0876991351445517

Epoch: 6| Step: 2
Training loss: 0.8910239338874817
Validation loss: 2.01061475276947

Epoch: 6| Step: 3
Training loss: 1.3843364715576172
Validation loss: 2.053215483824412

Epoch: 6| Step: 4
Training loss: 0.7043747901916504
Validation loss: 2.07148943344752

Epoch: 6| Step: 5
Training loss: 0.9460783004760742
Validation loss: 2.052031854788462

Epoch: 6| Step: 6
Training loss: 1.2698626518249512
Validation loss: 2.0679784218470254

Epoch: 6| Step: 7
Training loss: 1.167128562927246
Validation loss: 2.080279588699341

Epoch: 6| Step: 8
Training loss: 1.4609193801879883
Validation loss: 2.1172099510828652

Epoch: 6| Step: 9
Training loss: 0.9193181991577148
Validation loss: 2.079458733399709

Epoch: 6| Step: 10
Training loss: 1.1304545402526855
Validation loss: 2.0786168376604715

Epoch: 6| Step: 11
Training loss: 0.5033126473426819
Validation loss: 2.08513081073761

Epoch: 6| Step: 12
Training loss: 1.1411762237548828
Validation loss: 2.0727593302726746

Epoch: 6| Step: 13
Training loss: 1.003128170967102
Validation loss: 2.106510559717814

Epoch: 392| Step: 0
Training loss: 0.7972650527954102
Validation loss: 2.0952985684076944

Epoch: 6| Step: 1
Training loss: 0.6699698567390442
Validation loss: 2.0970322688420615

Epoch: 6| Step: 2
Training loss: 1.878169298171997
Validation loss: 2.0903864105542502

Epoch: 6| Step: 3
Training loss: 1.6346702575683594
Validation loss: 2.0707903107007346

Epoch: 6| Step: 4
Training loss: 0.6193010807037354
Validation loss: 2.0981348156929016

Epoch: 6| Step: 5
Training loss: 0.825558602809906
Validation loss: 2.1088899771372476

Epoch: 6| Step: 6
Training loss: 1.0099260807037354
Validation loss: 2.139993687470754

Epoch: 6| Step: 7
Training loss: 1.7747135162353516
Validation loss: 2.135889013608297

Epoch: 6| Step: 8
Training loss: 2.012836456298828
Validation loss: 2.110184669494629

Epoch: 6| Step: 9
Training loss: 1.3510395288467407
Validation loss: 2.1489569942156472

Epoch: 6| Step: 10
Training loss: 0.7420018911361694
Validation loss: 2.147271772225698

Epoch: 6| Step: 11
Training loss: 0.5046166181564331
Validation loss: 2.1583296855290732

Epoch: 6| Step: 12
Training loss: 0.7813520431518555
Validation loss: 2.1276838183403015

Epoch: 6| Step: 13
Training loss: 0.7687680721282959
Validation loss: 2.192983865737915

Epoch: 393| Step: 0
Training loss: 1.3154828548431396
Validation loss: 2.123464584350586

Epoch: 6| Step: 1
Training loss: 1.0246925354003906
Validation loss: 2.152295708656311

Epoch: 6| Step: 2
Training loss: 0.8811633586883545
Validation loss: 2.1595683296521506

Epoch: 6| Step: 3
Training loss: 0.6917065978050232
Validation loss: 2.1680567264556885

Epoch: 6| Step: 4
Training loss: 1.4112358093261719
Validation loss: 2.1649882197380066

Epoch: 6| Step: 5
Training loss: 0.9277249574661255
Validation loss: 2.135948061943054

Epoch: 6| Step: 6
Training loss: 1.5379209518432617
Validation loss: 2.129593014717102

Epoch: 6| Step: 7
Training loss: 0.23834297060966492
Validation loss: 2.106245696544647

Epoch: 6| Step: 8
Training loss: 0.8943756818771362
Validation loss: 2.119040826956431

Epoch: 6| Step: 9
Training loss: 1.4224026203155518
Validation loss: 2.0787696043650308

Epoch: 6| Step: 10
Training loss: 0.9594598412513733
Validation loss: 2.126546303431193

Epoch: 6| Step: 11
Training loss: 1.0200769901275635
Validation loss: 2.163713256518046

Epoch: 6| Step: 12
Training loss: 1.16471529006958
Validation loss: 2.129416366418203

Epoch: 6| Step: 13
Training loss: 1.0664633512496948
Validation loss: 2.1401913166046143

Epoch: 394| Step: 0
Training loss: 1.0517520904541016
Validation loss: 2.172701100508372

Epoch: 6| Step: 1
Training loss: 1.181762456893921
Validation loss: 2.163872222105662

Epoch: 6| Step: 2
Training loss: 1.2828177213668823
Validation loss: 2.1707087755203247

Epoch: 6| Step: 3
Training loss: 0.7287707924842834
Validation loss: 2.172102967898051

Epoch: 6| Step: 4
Training loss: 0.9451500177383423
Validation loss: 2.137361546357473

Epoch: 6| Step: 5
Training loss: 1.0811432600021362
Validation loss: 2.1057565013567605

Epoch: 6| Step: 6
Training loss: 0.630495548248291
Validation loss: 2.1382118264834085

Epoch: 6| Step: 7
Training loss: 1.3580875396728516
Validation loss: 2.09638504187266

Epoch: 6| Step: 8
Training loss: 0.5938911437988281
Validation loss: 2.1066661874453225

Epoch: 6| Step: 9
Training loss: 0.9468473196029663
Validation loss: 2.08926393588384

Epoch: 6| Step: 10
Training loss: 1.3535284996032715
Validation loss: 2.1416128079096475

Epoch: 6| Step: 11
Training loss: 0.9756781458854675
Validation loss: 2.126004079977671

Epoch: 6| Step: 12
Training loss: 0.5508679151535034
Validation loss: 2.0909185806910195

Epoch: 6| Step: 13
Training loss: 1.6797912120819092
Validation loss: 2.1136809984842935

Epoch: 395| Step: 0
Training loss: 0.7697901725769043
Validation loss: 2.1267590125401816

Epoch: 6| Step: 1
Training loss: 1.035251259803772
Validation loss: 2.1354063550631204

Epoch: 6| Step: 2
Training loss: 1.049551010131836
Validation loss: 2.1016165812810264

Epoch: 6| Step: 3
Training loss: 1.0646902322769165
Validation loss: 2.0779544909795127

Epoch: 6| Step: 4
Training loss: 0.8410317897796631
Validation loss: 2.0638068517049155

Epoch: 6| Step: 5
Training loss: 1.3203444480895996
Validation loss: 2.0529289642969766

Epoch: 6| Step: 6
Training loss: 1.8165595531463623
Validation loss: 2.0346976121266684

Epoch: 6| Step: 7
Training loss: 0.5875265002250671
Validation loss: 2.062521775563558

Epoch: 6| Step: 8
Training loss: 1.5374430418014526
Validation loss: 2.1100736061731973

Epoch: 6| Step: 9
Training loss: 0.9144360423088074
Validation loss: 2.0852882266044617

Epoch: 6| Step: 10
Training loss: 0.9659736156463623
Validation loss: 2.1140060424804688

Epoch: 6| Step: 11
Training loss: 0.36728769540786743
Validation loss: 2.0995670557022095

Epoch: 6| Step: 12
Training loss: 0.9896961450576782
Validation loss: 2.1271165211995444

Epoch: 6| Step: 13
Training loss: 0.7518871426582336
Validation loss: 2.121957997481028

Epoch: 396| Step: 0
Training loss: 0.9772807955741882
Validation loss: 2.099529802799225

Epoch: 6| Step: 1
Training loss: 0.7268674373626709
Validation loss: 2.1245590448379517

Epoch: 6| Step: 2
Training loss: 1.2169396877288818
Validation loss: 2.0841527183850608

Epoch: 6| Step: 3
Training loss: 0.64813631772995
Validation loss: 2.0999903678894043

Epoch: 6| Step: 4
Training loss: 1.1964774131774902
Validation loss: 2.0481621424357095

Epoch: 6| Step: 5
Training loss: 1.5017671585083008
Validation loss: 2.0696829756100974

Epoch: 6| Step: 6
Training loss: 1.903559684753418
Validation loss: 2.052471876144409

Epoch: 6| Step: 7
Training loss: 0.8177359104156494
Validation loss: 2.0333513418833413

Epoch: 6| Step: 8
Training loss: 0.7329128384590149
Validation loss: 2.0677210291226706

Epoch: 6| Step: 9
Training loss: 1.4232220649719238
Validation loss: 2.0684279402097068

Epoch: 6| Step: 10
Training loss: 0.7803818583488464
Validation loss: 2.0507970253626504

Epoch: 6| Step: 11
Training loss: 1.154885172843933
Validation loss: 2.0606283148129783

Epoch: 6| Step: 12
Training loss: 0.7271960377693176
Validation loss: 2.139150857925415

Epoch: 6| Step: 13
Training loss: 0.52787846326828
Validation loss: 2.1179113586743674

Epoch: 397| Step: 0
Training loss: 1.5664187669754028
Validation loss: 2.1101969480514526

Epoch: 6| Step: 1
Training loss: 0.4541124105453491
Validation loss: 2.1698696613311768

Epoch: 6| Step: 2
Training loss: 0.7028675079345703
Validation loss: 2.148588995138804

Epoch: 6| Step: 3
Training loss: 0.5605677366256714
Validation loss: 2.180495103200277

Epoch: 6| Step: 4
Training loss: 0.9464187026023865
Validation loss: 2.183659811814626

Epoch: 6| Step: 5
Training loss: 1.7737162113189697
Validation loss: 2.1724894046783447

Epoch: 6| Step: 6
Training loss: 0.6565871834754944
Validation loss: 2.1604063510894775

Epoch: 6| Step: 7
Training loss: 1.4902160167694092
Validation loss: 2.1665762066841125

Epoch: 6| Step: 8
Training loss: 1.0868728160858154
Validation loss: 2.1550966699918113

Epoch: 6| Step: 9
Training loss: 1.0648903846740723
Validation loss: 2.140134950478872

Epoch: 6| Step: 10
Training loss: 1.0285868644714355
Validation loss: 2.148183504740397

Epoch: 6| Step: 11
Training loss: 1.1750948429107666
Validation loss: 2.1647464831670127

Epoch: 6| Step: 12
Training loss: 1.0110973119735718
Validation loss: 2.1209078629811606

Epoch: 6| Step: 13
Training loss: 0.9528313279151917
Validation loss: 2.0944764216740928

Epoch: 398| Step: 0
Training loss: 1.0854225158691406
Validation loss: 2.0598568518956504

Epoch: 6| Step: 1
Training loss: 1.1847259998321533
Validation loss: 2.0793863336245217

Epoch: 6| Step: 2
Training loss: 1.0875548124313354
Validation loss: 2.0353009700775146

Epoch: 6| Step: 3
Training loss: 1.3956739902496338
Validation loss: 2.0398218433062234

Epoch: 6| Step: 4
Training loss: 0.8209669589996338
Validation loss: 2.0559113224347434

Epoch: 6| Step: 5
Training loss: 1.0936601161956787
Validation loss: 2.0466899474461875

Epoch: 6| Step: 6
Training loss: 0.8843871355056763
Validation loss: 2.102325916290283

Epoch: 6| Step: 7
Training loss: 0.5119789838790894
Validation loss: 2.082896113395691

Epoch: 6| Step: 8
Training loss: 0.9807960987091064
Validation loss: 2.1041537125905356

Epoch: 6| Step: 9
Training loss: 0.9867823123931885
Validation loss: 2.0860612392425537

Epoch: 6| Step: 10
Training loss: 1.3147847652435303
Validation loss: 2.1445362170537314

Epoch: 6| Step: 11
Training loss: 0.5422956347465515
Validation loss: 2.1782195766766868

Epoch: 6| Step: 12
Training loss: 0.684037446975708
Validation loss: 2.2073511679967246

Epoch: 6| Step: 13
Training loss: 1.2099452018737793
Validation loss: 2.1947585940361023

Epoch: 399| Step: 0
Training loss: 0.6413319110870361
Validation loss: 2.1429531375567117

Epoch: 6| Step: 1
Training loss: 0.7318629026412964
Validation loss: 2.1629918416341147

Epoch: 6| Step: 2
Training loss: 0.9689228534698486
Validation loss: 2.145464777946472

Epoch: 6| Step: 3
Training loss: 0.6918882131576538
Validation loss: 2.132121662298838

Epoch: 6| Step: 4
Training loss: 0.544392466545105
Validation loss: 2.141118109226227

Epoch: 6| Step: 5
Training loss: 1.0018162727355957
Validation loss: 2.147230803966522

Epoch: 6| Step: 6
Training loss: 1.711359977722168
Validation loss: 2.079106330871582

Epoch: 6| Step: 7
Training loss: 1.4617919921875
Validation loss: 2.133111039797465

Epoch: 6| Step: 8
Training loss: 0.8314497470855713
Validation loss: 2.1259357730547586

Epoch: 6| Step: 9
Training loss: 0.8695687651634216
Validation loss: 2.125058134396871

Epoch: 6| Step: 10
Training loss: 1.443183183670044
Validation loss: 2.095240573088328

Epoch: 6| Step: 11
Training loss: 1.3764240741729736
Validation loss: 2.1035878658294678

Epoch: 6| Step: 12
Training loss: 0.4853229224681854
Validation loss: 2.0934302608172097

Epoch: 6| Step: 13
Training loss: 1.2907066345214844
Validation loss: 2.0600246588389077

Epoch: 400| Step: 0
Training loss: 0.7303621768951416
Validation loss: 2.098569909731547

Epoch: 6| Step: 1
Training loss: 1.020461916923523
Validation loss: 2.083873748779297

Epoch: 6| Step: 2
Training loss: 0.9988774657249451
Validation loss: 2.0750413735707602

Epoch: 6| Step: 3
Training loss: 1.0959419012069702
Validation loss: 2.129169523715973

Epoch: 6| Step: 4
Training loss: 1.2197169065475464
Validation loss: 2.1020623246828714

Epoch: 6| Step: 5
Training loss: 0.7067149877548218
Validation loss: 2.155409495035807

Epoch: 6| Step: 6
Training loss: 1.1720836162567139
Validation loss: 2.156152923901876

Epoch: 6| Step: 7
Training loss: 0.38417625427246094
Validation loss: 2.198438843091329

Epoch: 6| Step: 8
Training loss: 0.7314849495887756
Validation loss: 2.2219569285710654

Epoch: 6| Step: 9
Training loss: 1.5503337383270264
Validation loss: 2.192069331804911

Epoch: 6| Step: 10
Training loss: 1.0678950548171997
Validation loss: 2.1698489586512246

Epoch: 6| Step: 11
Training loss: 1.7131969928741455
Validation loss: 2.1442560156186423

Epoch: 6| Step: 12
Training loss: 0.784758985042572
Validation loss: 2.1172871192296348

Epoch: 6| Step: 13
Training loss: 1.2647433280944824
Validation loss: 2.1436745723088584

Epoch: 401| Step: 0
Training loss: 0.9357019066810608
Validation loss: 2.0860945781071982

Epoch: 6| Step: 1
Training loss: 1.1746774911880493
Validation loss: 2.12084432442983

Epoch: 6| Step: 2
Training loss: 0.8811523914337158
Validation loss: 2.1040601332982383

Epoch: 6| Step: 3
Training loss: 0.813042163848877
Validation loss: 2.104641536871592

Epoch: 6| Step: 4
Training loss: 0.6689798831939697
Validation loss: 2.0948251287142434

Epoch: 6| Step: 5
Training loss: 0.785897970199585
Validation loss: 2.111569325129191

Epoch: 6| Step: 6
Training loss: 0.9853684902191162
Validation loss: 2.107965568701426

Epoch: 6| Step: 7
Training loss: 2.065788984298706
Validation loss: 2.1621302564938865

Epoch: 6| Step: 8
Training loss: 1.9690606594085693
Validation loss: 2.126728435357412

Epoch: 6| Step: 9
Training loss: 1.041481852531433
Validation loss: 2.165159026781718

Epoch: 6| Step: 10
Training loss: 1.1713922023773193
Validation loss: 2.158482392628988

Epoch: 6| Step: 11
Training loss: 0.9151023030281067
Validation loss: 2.148260494073232

Epoch: 6| Step: 12
Training loss: 0.7066272497177124
Validation loss: 2.128324051698049

Epoch: 6| Step: 13
Training loss: 0.6787750720977783
Validation loss: 2.148968776067098

Epoch: 402| Step: 0
Training loss: 1.4859662055969238
Validation loss: 2.1783246994018555

Epoch: 6| Step: 1
Training loss: 0.7160967588424683
Validation loss: 2.185575842857361

Epoch: 6| Step: 2
Training loss: 1.4247472286224365
Validation loss: 2.149481932322184

Epoch: 6| Step: 3
Training loss: 1.0874735116958618
Validation loss: 2.1255248387654624

Epoch: 6| Step: 4
Training loss: 1.2356511354446411
Validation loss: 2.1367797454198203

Epoch: 6| Step: 5
Training loss: 0.9512261748313904
Validation loss: 2.0993179281552634

Epoch: 6| Step: 6
Training loss: 1.375786542892456
Validation loss: 2.099837144215902

Epoch: 6| Step: 7
Training loss: 0.7895529270172119
Validation loss: 2.0487059553464255

Epoch: 6| Step: 8
Training loss: 0.47251224517822266
Validation loss: 2.0692887902259827

Epoch: 6| Step: 9
Training loss: 0.8801953196525574
Validation loss: 2.092939297358195

Epoch: 6| Step: 10
Training loss: 1.0925066471099854
Validation loss: 2.1111327409744263

Epoch: 6| Step: 11
Training loss: 0.9258434176445007
Validation loss: 2.115758180618286

Epoch: 6| Step: 12
Training loss: 1.1434431076049805
Validation loss: 2.1015249689420066

Epoch: 6| Step: 13
Training loss: 0.7502223253250122
Validation loss: 2.10910826921463

Epoch: 403| Step: 0
Training loss: 0.5532612204551697
Validation loss: 2.1065253615379333

Epoch: 6| Step: 1
Training loss: 0.5963661670684814
Validation loss: 2.0866424441337585

Epoch: 6| Step: 2
Training loss: 1.3541476726531982
Validation loss: 2.030540883541107

Epoch: 6| Step: 3
Training loss: 1.714881420135498
Validation loss: 2.02673077583313

Epoch: 6| Step: 4
Training loss: 1.0891040563583374
Validation loss: 2.045624574025472

Epoch: 6| Step: 5
Training loss: 0.7021144032478333
Validation loss: 2.0258132219314575

Epoch: 6| Step: 6
Training loss: 1.1465238332748413
Validation loss: 2.0683559576670327

Epoch: 6| Step: 7
Training loss: 0.6200801134109497
Validation loss: 2.0933509469032288

Epoch: 6| Step: 8
Training loss: 1.0423182249069214
Validation loss: 2.129102269808451

Epoch: 6| Step: 9
Training loss: 0.7631909847259521
Validation loss: 2.121849616368612

Epoch: 6| Step: 10
Training loss: 1.0787559747695923
Validation loss: 2.1325740416844687

Epoch: 6| Step: 11
Training loss: 1.6656993627548218
Validation loss: 2.1178394158681235

Epoch: 6| Step: 12
Training loss: 1.472947597503662
Validation loss: 2.0988002816836038

Epoch: 6| Step: 13
Training loss: 0.7630822658538818
Validation loss: 2.0843507051467896

Epoch: 404| Step: 0
Training loss: 1.0552923679351807
Validation loss: 2.0660193165143332

Epoch: 6| Step: 1
Training loss: 1.4043066501617432
Validation loss: 2.0639062921206155

Epoch: 6| Step: 2
Training loss: 1.2859342098236084
Validation loss: 2.0520434379577637

Epoch: 6| Step: 3
Training loss: 0.8493267297744751
Validation loss: 2.0137717723846436

Epoch: 6| Step: 4
Training loss: 1.3742034435272217
Validation loss: 2.059908926486969

Epoch: 6| Step: 5
Training loss: 0.7147127389907837
Validation loss: 2.0712138613065085

Epoch: 6| Step: 6
Training loss: 0.516643762588501
Validation loss: 2.0453766783078513

Epoch: 6| Step: 7
Training loss: 0.8546252250671387
Validation loss: 2.077466527620951

Epoch: 6| Step: 8
Training loss: 1.4716140031814575
Validation loss: 2.0679405132929483

Epoch: 6| Step: 9
Training loss: 0.7576450109481812
Validation loss: 2.1125972270965576

Epoch: 6| Step: 10
Training loss: 0.8667213916778564
Validation loss: 2.081131637096405

Epoch: 6| Step: 11
Training loss: 1.0628248453140259
Validation loss: 2.108446220556895

Epoch: 6| Step: 12
Training loss: 0.6398383975028992
Validation loss: 2.1283613244692483

Epoch: 6| Step: 13
Training loss: 1.1501346826553345
Validation loss: 2.127878487110138

Epoch: 405| Step: 0
Training loss: 0.8659519553184509
Validation loss: 2.167666713396708

Epoch: 6| Step: 1
Training loss: 2.0533432960510254
Validation loss: 2.149465044339498

Epoch: 6| Step: 2
Training loss: 0.8890848755836487
Validation loss: 2.119514266649882

Epoch: 6| Step: 3
Training loss: 1.1403493881225586
Validation loss: 2.0940327246983848

Epoch: 6| Step: 4
Training loss: 0.6357390880584717
Validation loss: 2.096004327138265

Epoch: 6| Step: 5
Training loss: 0.5964773893356323
Validation loss: 2.11576517422994

Epoch: 6| Step: 6
Training loss: 0.8377667665481567
Validation loss: 2.0928293665250144

Epoch: 6| Step: 7
Training loss: 0.7969314455986023
Validation loss: 2.07899938027064

Epoch: 6| Step: 8
Training loss: 1.6472145318984985
Validation loss: 2.0547590851783752

Epoch: 6| Step: 9
Training loss: 0.9311074018478394
Validation loss: 2.0691370368003845

Epoch: 6| Step: 10
Training loss: 0.6903725266456604
Validation loss: 2.0650602181752524

Epoch: 6| Step: 11
Training loss: 0.9964044094085693
Validation loss: 2.08646297454834

Epoch: 6| Step: 12
Training loss: 0.8681437373161316
Validation loss: 2.065576672554016

Epoch: 6| Step: 13
Training loss: 0.9746183753013611
Validation loss: 2.134307026863098

Epoch: 406| Step: 0
Training loss: 0.7105717062950134
Validation loss: 2.089904010295868

Epoch: 6| Step: 1
Training loss: 0.7971796989440918
Validation loss: 2.1010688940684

Epoch: 6| Step: 2
Training loss: 0.7107060551643372
Validation loss: 2.1266587575276694

Epoch: 6| Step: 3
Training loss: 1.3726961612701416
Validation loss: 2.0963316361109414

Epoch: 6| Step: 4
Training loss: 0.8698723316192627
Validation loss: 2.080715795358022

Epoch: 6| Step: 5
Training loss: 0.4298025369644165
Validation loss: 2.106639484564463

Epoch: 6| Step: 6
Training loss: 0.9374500513076782
Validation loss: 2.0792089104652405

Epoch: 6| Step: 7
Training loss: 1.328967809677124
Validation loss: 2.0858443776766458

Epoch: 6| Step: 8
Training loss: 0.5682477355003357
Validation loss: 2.10715260108312

Epoch: 6| Step: 9
Training loss: 1.0220494270324707
Validation loss: 2.0906676054000854

Epoch: 6| Step: 10
Training loss: 1.3533573150634766
Validation loss: 2.086989402770996

Epoch: 6| Step: 11
Training loss: 1.1021430492401123
Validation loss: 2.0552176237106323

Epoch: 6| Step: 12
Training loss: 0.6168445348739624
Validation loss: 2.058629333972931

Epoch: 6| Step: 13
Training loss: 1.2259963750839233
Validation loss: 2.094281872113546

Epoch: 407| Step: 0
Training loss: 0.5518067479133606
Validation loss: 2.0909350514411926

Epoch: 6| Step: 1
Training loss: 0.9791857004165649
Validation loss: 2.0546473264694214

Epoch: 6| Step: 2
Training loss: 1.6362991333007812
Validation loss: 2.067774931589762

Epoch: 6| Step: 3
Training loss: 1.2955281734466553
Validation loss: 2.1132946213086448

Epoch: 6| Step: 4
Training loss: 0.5813860297203064
Validation loss: 2.093343178431193

Epoch: 6| Step: 5
Training loss: 1.1345078945159912
Validation loss: 2.0824327866236367

Epoch: 6| Step: 6
Training loss: 0.621587872505188
Validation loss: 2.069912095864614

Epoch: 6| Step: 7
Training loss: 0.8691273331642151
Validation loss: 2.11782576640447

Epoch: 6| Step: 8
Training loss: 1.3324384689331055
Validation loss: 2.114404082298279

Epoch: 6| Step: 9
Training loss: 1.1106200218200684
Validation loss: 2.0791321794191995

Epoch: 6| Step: 10
Training loss: 1.1906265020370483
Validation loss: 2.1488890250523887

Epoch: 6| Step: 11
Training loss: 1.070749282836914
Validation loss: 2.106846193472544

Epoch: 6| Step: 12
Training loss: 0.8951181769371033
Validation loss: 2.0630056063334146

Epoch: 6| Step: 13
Training loss: 0.8322791457176208
Validation loss: 2.0795249938964844

Epoch: 408| Step: 0
Training loss: 0.7628462910652161
Validation loss: 2.0378825863202414

Epoch: 6| Step: 1
Training loss: 0.7242664098739624
Validation loss: 2.098344703515371

Epoch: 6| Step: 2
Training loss: 1.036450743675232
Validation loss: 2.045208831628164

Epoch: 6| Step: 3
Training loss: 0.6449193954467773
Validation loss: 2.0667235255241394

Epoch: 6| Step: 4
Training loss: 2.072068691253662
Validation loss: 2.0855010946591697

Epoch: 6| Step: 5
Training loss: 0.4720439314842224
Validation loss: 2.0563265482584634

Epoch: 6| Step: 6
Training loss: 1.2547742128372192
Validation loss: 2.0666590134302774

Epoch: 6| Step: 7
Training loss: 0.9708946347236633
Validation loss: 2.094723085562388

Epoch: 6| Step: 8
Training loss: 1.1530537605285645
Validation loss: 2.1090614398320517

Epoch: 6| Step: 9
Training loss: 1.3962485790252686
Validation loss: 2.101505716641744

Epoch: 6| Step: 10
Training loss: 0.7671936750411987
Validation loss: 2.149181882540385

Epoch: 6| Step: 11
Training loss: 0.7843923568725586
Validation loss: 2.120225747426351

Epoch: 6| Step: 12
Training loss: 1.0702486038208008
Validation loss: 2.111201008160909

Epoch: 6| Step: 13
Training loss: 0.6017967462539673
Validation loss: 2.0971374909083047

Epoch: 409| Step: 0
Training loss: 0.6223593950271606
Validation loss: 2.11848916610082

Epoch: 6| Step: 1
Training loss: 1.5187041759490967
Validation loss: 2.1305657625198364

Epoch: 6| Step: 2
Training loss: 1.7262828350067139
Validation loss: 2.143495758374532

Epoch: 6| Step: 3
Training loss: 0.86733078956604
Validation loss: 2.1338097850481668

Epoch: 6| Step: 4
Training loss: 1.1775163412094116
Validation loss: 2.1377026637395224

Epoch: 6| Step: 5
Training loss: 0.5589649677276611
Validation loss: 2.1277525822321572

Epoch: 6| Step: 6
Training loss: 1.0020647048950195
Validation loss: 2.1292198101679483

Epoch: 6| Step: 7
Training loss: 0.8498297929763794
Validation loss: 2.127663711706797

Epoch: 6| Step: 8
Training loss: 0.8713550567626953
Validation loss: 2.1142541567484536

Epoch: 6| Step: 9
Training loss: 0.8577820062637329
Validation loss: 2.0928389628728232

Epoch: 6| Step: 10
Training loss: 1.327164888381958
Validation loss: 2.0635615984598794

Epoch: 6| Step: 11
Training loss: 0.3846466541290283
Validation loss: 2.0864250858624778

Epoch: 6| Step: 12
Training loss: 0.7217563390731812
Validation loss: 2.079572240511576

Epoch: 6| Step: 13
Training loss: 0.6842789649963379
Validation loss: 2.0989902218182883

Epoch: 410| Step: 0
Training loss: 1.2089323997497559
Validation loss: 2.119617998600006

Epoch: 6| Step: 1
Training loss: 0.5461456179618835
Validation loss: 2.16497935851415

Epoch: 6| Step: 2
Training loss: 0.598588764667511
Validation loss: 2.133292257785797

Epoch: 6| Step: 3
Training loss: 1.364748477935791
Validation loss: 2.126311182975769

Epoch: 6| Step: 4
Training loss: 0.7727429866790771
Validation loss: 2.1049439509709678

Epoch: 6| Step: 5
Training loss: 1.5576707124710083
Validation loss: 2.0473646124204

Epoch: 6| Step: 6
Training loss: 1.0842959880828857
Validation loss: 2.069153646628062

Epoch: 6| Step: 7
Training loss: 0.6738682389259338
Validation loss: 2.0406068166097007

Epoch: 6| Step: 8
Training loss: 1.018694519996643
Validation loss: 2.066494425137838

Epoch: 6| Step: 9
Training loss: 1.1721384525299072
Validation loss: 2.026959319909414

Epoch: 6| Step: 10
Training loss: 0.7295485734939575
Validation loss: 2.036252796649933

Epoch: 6| Step: 11
Training loss: 0.8342897891998291
Validation loss: 2.048464775085449

Epoch: 6| Step: 12
Training loss: 0.7556767463684082
Validation loss: 2.0261078476905823

Epoch: 6| Step: 13
Training loss: 1.4204161167144775
Validation loss: 2.028224309285482

Epoch: 411| Step: 0
Training loss: 1.3695906400680542
Validation loss: 2.021834452946981

Epoch: 6| Step: 1
Training loss: 0.3725919723510742
Validation loss: 2.01040917634964

Epoch: 6| Step: 2
Training loss: 1.7350648641586304
Validation loss: 2.0663666129112244

Epoch: 6| Step: 3
Training loss: 0.5586636066436768
Validation loss: 2.0703705747922263

Epoch: 6| Step: 4
Training loss: 0.27312028408050537
Validation loss: 2.1602142055829368

Epoch: 6| Step: 5
Training loss: 1.5656306743621826
Validation loss: 2.1780890623728433

Epoch: 6| Step: 6
Training loss: 0.9780729413032532
Validation loss: 2.1692576805750527

Epoch: 6| Step: 7
Training loss: 1.0288139581680298
Validation loss: 2.154758334159851

Epoch: 6| Step: 8
Training loss: 1.3398406505584717
Validation loss: 2.1602433919906616

Epoch: 6| Step: 9
Training loss: 0.8984202146530151
Validation loss: 2.136409044265747

Epoch: 6| Step: 10
Training loss: 1.421834111213684
Validation loss: 2.115047057469686

Epoch: 6| Step: 11
Training loss: 0.6293627619743347
Validation loss: 2.1128904223442078

Epoch: 6| Step: 12
Training loss: 0.5154881477355957
Validation loss: 2.0421780745188394

Epoch: 6| Step: 13
Training loss: 0.8358162045478821
Validation loss: 2.0807601610819497

Epoch: 412| Step: 0
Training loss: 1.2174062728881836
Validation loss: 2.060892164707184

Epoch: 6| Step: 1
Training loss: 0.9747467041015625
Validation loss: 2.0716801285743713

Epoch: 6| Step: 2
Training loss: 0.633648157119751
Validation loss: 2.0684451262156167

Epoch: 6| Step: 3
Training loss: 0.7755951285362244
Validation loss: 2.0205660263697305

Epoch: 6| Step: 4
Training loss: 1.2830419540405273
Validation loss: 2.0629387497901917

Epoch: 6| Step: 5
Training loss: 0.8249784708023071
Validation loss: 2.055779755115509

Epoch: 6| Step: 6
Training loss: 1.5175373554229736
Validation loss: 2.083130180835724

Epoch: 6| Step: 7
Training loss: 0.891006350517273
Validation loss: 2.0329128305117288

Epoch: 6| Step: 8
Training loss: 1.0698750019073486
Validation loss: 2.051534414291382

Epoch: 6| Step: 9
Training loss: 0.7541834115982056
Validation loss: 2.063733220100403

Epoch: 6| Step: 10
Training loss: 0.685151994228363
Validation loss: 2.0843734542528787

Epoch: 6| Step: 11
Training loss: 1.0584503412246704
Validation loss: 2.094174087047577

Epoch: 6| Step: 12
Training loss: 1.209839105606079
Validation loss: 2.1313068668047586

Epoch: 6| Step: 13
Training loss: 1.1895580291748047
Validation loss: 2.140610635280609

Epoch: 413| Step: 0
Training loss: 0.4697120189666748
Validation loss: 2.1598700086275735

Epoch: 6| Step: 1
Training loss: 1.3790028095245361
Validation loss: 2.1198031306266785

Epoch: 6| Step: 2
Training loss: 1.4867744445800781
Validation loss: 2.1690651178359985

Epoch: 6| Step: 3
Training loss: 1.331176996231079
Validation loss: 2.141882320245107

Epoch: 6| Step: 4
Training loss: 0.9924450516700745
Validation loss: 2.139876743157705

Epoch: 6| Step: 5
Training loss: 0.7261995077133179
Validation loss: 2.1203447779019675

Epoch: 6| Step: 6
Training loss: 0.6446027755737305
Validation loss: 2.0834633708000183

Epoch: 6| Step: 7
Training loss: 0.7539003491401672
Validation loss: 2.0549110174179077

Epoch: 6| Step: 8
Training loss: 0.8914358615875244
Validation loss: 2.0054143269856772

Epoch: 6| Step: 9
Training loss: 1.0993471145629883
Validation loss: 2.010133067766825

Epoch: 6| Step: 10
Training loss: 1.2179560661315918
Validation loss: 2.025974214076996

Epoch: 6| Step: 11
Training loss: 0.9550545811653137
Validation loss: 2.0352876385053

Epoch: 6| Step: 12
Training loss: 1.1897828578948975
Validation loss: 1.972497860590617

Epoch: 6| Step: 13
Training loss: 1.0437836647033691
Validation loss: 2.029511650403341

Epoch: 414| Step: 0
Training loss: 1.1400965452194214
Validation loss: 2.042230765024821

Epoch: 6| Step: 1
Training loss: 0.589568018913269
Validation loss: 2.0688575506210327

Epoch: 6| Step: 2
Training loss: 1.1375601291656494
Validation loss: 2.0569392840067544

Epoch: 6| Step: 3
Training loss: 1.199340581893921
Validation loss: 2.1157463987668357

Epoch: 6| Step: 4
Training loss: 0.8499006032943726
Validation loss: 2.0549363096555076

Epoch: 6| Step: 5
Training loss: 0.9514806270599365
Validation loss: 2.1195473273595176

Epoch: 6| Step: 6
Training loss: 1.196647047996521
Validation loss: 2.1043741703033447

Epoch: 6| Step: 7
Training loss: 0.7901942729949951
Validation loss: 2.0993979374567666

Epoch: 6| Step: 8
Training loss: 0.7372486591339111
Validation loss: 2.081431190172831

Epoch: 6| Step: 9
Training loss: 0.7719427347183228
Validation loss: 2.1421151161193848

Epoch: 6| Step: 10
Training loss: 0.8517181873321533
Validation loss: 2.118239382902781

Epoch: 6| Step: 11
Training loss: 0.7733820676803589
Validation loss: 2.12530126174291

Epoch: 6| Step: 12
Training loss: 0.8462129235267639
Validation loss: 2.0953967769940696

Epoch: 6| Step: 13
Training loss: 1.2003369331359863
Validation loss: 2.0742557048797607

Epoch: 415| Step: 0
Training loss: 1.263421893119812
Validation loss: 2.0935030778249106

Epoch: 6| Step: 1
Training loss: 1.320388674736023
Validation loss: 2.1054561336835227

Epoch: 6| Step: 2
Training loss: 0.6255837678909302
Validation loss: 2.0765843590100608

Epoch: 6| Step: 3
Training loss: 0.7976009249687195
Validation loss: 2.0458373626073203

Epoch: 6| Step: 4
Training loss: 1.2746140956878662
Validation loss: 2.0653326710065207

Epoch: 6| Step: 5
Training loss: 1.002880334854126
Validation loss: 2.033657511075338

Epoch: 6| Step: 6
Training loss: 1.2127044200897217
Validation loss: 2.039575219154358

Epoch: 6| Step: 7
Training loss: 0.6419240832328796
Validation loss: 2.046424706776937

Epoch: 6| Step: 8
Training loss: 0.8732888698577881
Validation loss: 2.048381984233856

Epoch: 6| Step: 9
Training loss: 0.5312857627868652
Validation loss: 2.022521952788035

Epoch: 6| Step: 10
Training loss: 0.6454163789749146
Validation loss: 2.088714083035787

Epoch: 6| Step: 11
Training loss: 0.6028025150299072
Validation loss: 2.084880272547404

Epoch: 6| Step: 12
Training loss: 0.8204293251037598
Validation loss: 2.148222347100576

Epoch: 6| Step: 13
Training loss: 1.180638313293457
Validation loss: 2.1431424220403037

Epoch: 416| Step: 0
Training loss: 0.6613175272941589
Validation loss: 2.1466917792956033

Epoch: 6| Step: 1
Training loss: 0.6771441698074341
Validation loss: 2.0986532966295877

Epoch: 6| Step: 2
Training loss: 0.8452168703079224
Validation loss: 2.1265342434247336

Epoch: 6| Step: 3
Training loss: 0.868777871131897
Validation loss: 2.070505062739054

Epoch: 6| Step: 4
Training loss: 1.0135066509246826
Validation loss: 2.048932989438375

Epoch: 6| Step: 5
Training loss: 1.33439040184021
Validation loss: 2.072990616162618

Epoch: 6| Step: 6
Training loss: 1.0808298587799072
Validation loss: 2.1149933536847434

Epoch: 6| Step: 7
Training loss: 0.5551812052726746
Validation loss: 2.0633602341016135

Epoch: 6| Step: 8
Training loss: 0.6734985113143921
Validation loss: 2.0281570752461753

Epoch: 6| Step: 9
Training loss: 0.48370662331581116
Validation loss: 2.0698009530703225

Epoch: 6| Step: 10
Training loss: 1.3297510147094727
Validation loss: 2.071587602297465

Epoch: 6| Step: 11
Training loss: 0.8978347182273865
Validation loss: 2.050854484240214

Epoch: 6| Step: 12
Training loss: 1.1987497806549072
Validation loss: 2.052985966205597

Epoch: 6| Step: 13
Training loss: 0.6372238397598267
Validation loss: 2.0476911862691245

Epoch: 417| Step: 0
Training loss: 0.9225683212280273
Validation loss: 2.0009644627571106

Epoch: 6| Step: 1
Training loss: 0.8966832160949707
Validation loss: 2.0029146671295166

Epoch: 6| Step: 2
Training loss: 1.4362070560455322
Validation loss: 1.9996782143910725

Epoch: 6| Step: 3
Training loss: 1.4741392135620117
Validation loss: 2.018402715524038

Epoch: 6| Step: 4
Training loss: 1.1747169494628906
Validation loss: 2.036669135093689

Epoch: 6| Step: 5
Training loss: 1.0280773639678955
Validation loss: 2.001411219437917

Epoch: 6| Step: 6
Training loss: 0.717995285987854
Validation loss: 2.0434146523475647

Epoch: 6| Step: 7
Training loss: 1.0976033210754395
Validation loss: 2.03140381971995

Epoch: 6| Step: 8
Training loss: 0.7236291766166687
Validation loss: 2.04892498254776

Epoch: 6| Step: 9
Training loss: 0.34880709648132324
Validation loss: 2.0565378268559775

Epoch: 6| Step: 10
Training loss: 0.7466060519218445
Validation loss: 2.0576480627059937

Epoch: 6| Step: 11
Training loss: 0.9291266202926636
Validation loss: 2.0802189310391745

Epoch: 6| Step: 12
Training loss: 0.7871106863021851
Validation loss: 2.1268168886502585

Epoch: 6| Step: 13
Training loss: 0.8878296613693237
Validation loss: 2.125330865383148

Epoch: 418| Step: 0
Training loss: 0.48988020420074463
Validation loss: 2.1052483916282654

Epoch: 6| Step: 1
Training loss: 0.9052969217300415
Validation loss: 2.0949904719988504

Epoch: 6| Step: 2
Training loss: 0.4852105975151062
Validation loss: 2.1087027390797934

Epoch: 6| Step: 3
Training loss: 0.7110843658447266
Validation loss: 2.1155713399251304

Epoch: 6| Step: 4
Training loss: 0.998309850692749
Validation loss: 2.0916948914527893

Epoch: 6| Step: 5
Training loss: 1.0186402797698975
Validation loss: 2.1281691988309226

Epoch: 6| Step: 6
Training loss: 0.6011813879013062
Validation loss: 2.108367919921875

Epoch: 6| Step: 7
Training loss: 1.09102201461792
Validation loss: 2.107077956199646

Epoch: 6| Step: 8
Training loss: 1.006935477256775
Validation loss: 2.1212522387504578

Epoch: 6| Step: 9
Training loss: 0.9165383577346802
Validation loss: 2.0870543122291565

Epoch: 6| Step: 10
Training loss: 0.7515830993652344
Validation loss: 2.1193262537320456

Epoch: 6| Step: 11
Training loss: 0.9522649645805359
Validation loss: 2.091688950856527

Epoch: 6| Step: 12
Training loss: 1.9657683372497559
Validation loss: 2.107471446196238

Epoch: 6| Step: 13
Training loss: 0.8832564353942871
Validation loss: 2.0911121368408203

Epoch: 419| Step: 0
Training loss: 1.0898000001907349
Validation loss: 2.0947420597076416

Epoch: 6| Step: 1
Training loss: 0.9894201159477234
Validation loss: 2.0965799689292908

Epoch: 6| Step: 2
Training loss: 1.9495936632156372
Validation loss: 2.098683714866638

Epoch: 6| Step: 3
Training loss: 0.7443100214004517
Validation loss: 2.079046448071798

Epoch: 6| Step: 4
Training loss: 0.6307127475738525
Validation loss: 2.1043983499209085

Epoch: 6| Step: 5
Training loss: 0.6477803587913513
Validation loss: 2.0731570521990457

Epoch: 6| Step: 6
Training loss: 0.7815375924110413
Validation loss: 2.0741122563680015

Epoch: 6| Step: 7
Training loss: 1.0085804462432861
Validation loss: 2.120673100153605

Epoch: 6| Step: 8
Training loss: 1.2717548608779907
Validation loss: 2.092418154080709

Epoch: 6| Step: 9
Training loss: 0.4358031153678894
Validation loss: 2.102959314982096

Epoch: 6| Step: 10
Training loss: 0.39547622203826904
Validation loss: 2.0815160870552063

Epoch: 6| Step: 11
Training loss: 0.5225547552108765
Validation loss: 2.1524600982666016

Epoch: 6| Step: 12
Training loss: 0.584420919418335
Validation loss: 2.150248865286509

Epoch: 6| Step: 13
Training loss: 1.1233229637145996
Validation loss: 2.1524137258529663

Epoch: 420| Step: 0
Training loss: 0.9166176915168762
Validation loss: 2.081809182961782

Epoch: 6| Step: 1
Training loss: 1.9360392093658447
Validation loss: 2.0807478030522666

Epoch: 6| Step: 2
Training loss: 0.44792598485946655
Validation loss: 2.0618855953216553

Epoch: 6| Step: 3
Training loss: 1.1234503984451294
Validation loss: 2.048156201839447

Epoch: 6| Step: 4
Training loss: 1.0000865459442139
Validation loss: 2.052730063597361

Epoch: 6| Step: 5
Training loss: 1.3368847370147705
Validation loss: 2.039827346801758

Epoch: 6| Step: 6
Training loss: 0.7354653477668762
Validation loss: 2.1158472299575806

Epoch: 6| Step: 7
Training loss: 0.9756354689598083
Validation loss: 2.0714062452316284

Epoch: 6| Step: 8
Training loss: 0.5265272259712219
Validation loss: 2.1435230573018393

Epoch: 6| Step: 9
Training loss: 0.42930659651756287
Validation loss: 2.1256450414657593

Epoch: 6| Step: 10
Training loss: 0.687981367111206
Validation loss: 2.151256501674652

Epoch: 6| Step: 11
Training loss: 1.1214202642440796
Validation loss: 2.1495554447174072

Epoch: 6| Step: 12
Training loss: 0.38662421703338623
Validation loss: 2.1266088287035623

Epoch: 6| Step: 13
Training loss: 0.915535569190979
Validation loss: 2.116754432519277

Epoch: 421| Step: 0
Training loss: 1.197967529296875
Validation loss: 2.161868453025818

Epoch: 6| Step: 1
Training loss: 0.47011902928352356
Validation loss: 2.116176664829254

Epoch: 6| Step: 2
Training loss: 0.8229265213012695
Validation loss: 2.107151468594869

Epoch: 6| Step: 3
Training loss: 0.7592802047729492
Validation loss: 2.1592339674631753

Epoch: 6| Step: 4
Training loss: 0.40682119131088257
Validation loss: 2.106376528739929

Epoch: 6| Step: 5
Training loss: 0.6791772246360779
Validation loss: 2.0575283964474997

Epoch: 6| Step: 6
Training loss: 0.974482536315918
Validation loss: 2.0490099589029946

Epoch: 6| Step: 7
Training loss: 1.1205626726150513
Validation loss: 2.0434463818868003

Epoch: 6| Step: 8
Training loss: 0.6799020767211914
Validation loss: 2.050621191660563

Epoch: 6| Step: 9
Training loss: 1.0830774307250977
Validation loss: 1.995690683523814

Epoch: 6| Step: 10
Training loss: 2.3220856189727783
Validation loss: 2.0310585101445517

Epoch: 6| Step: 11
Training loss: 0.509732186794281
Validation loss: 2.0461313128471375

Epoch: 6| Step: 12
Training loss: 0.9474918842315674
Validation loss: 2.0886226296424866

Epoch: 6| Step: 13
Training loss: 0.4868924021720886
Validation loss: 2.043632666269938

Epoch: 422| Step: 0
Training loss: 1.1372848749160767
Validation loss: 2.085603912671407

Epoch: 6| Step: 1
Training loss: 0.35041624307632446
Validation loss: 2.055047114690145

Epoch: 6| Step: 2
Training loss: 0.5687952041625977
Validation loss: 2.081018408139547

Epoch: 6| Step: 3
Training loss: 1.1307870149612427
Validation loss: 2.108103851477305

Epoch: 6| Step: 4
Training loss: 1.2523558139801025
Validation loss: 2.1161145170529685

Epoch: 6| Step: 5
Training loss: 0.869773805141449
Validation loss: 2.0966792901357016

Epoch: 6| Step: 6
Training loss: 0.6241262555122375
Validation loss: 2.0888623197873435

Epoch: 6| Step: 7
Training loss: 1.3148620128631592
Validation loss: 2.063199202219645

Epoch: 6| Step: 8
Training loss: 0.47128987312316895
Validation loss: 2.058424731095632

Epoch: 6| Step: 9
Training loss: 1.0458025932312012
Validation loss: 2.0910597244898477

Epoch: 6| Step: 10
Training loss: 1.0023126602172852
Validation loss: 2.0539438327153525

Epoch: 6| Step: 11
Training loss: 0.6075952053070068
Validation loss: 2.076215147972107

Epoch: 6| Step: 12
Training loss: 1.068773627281189
Validation loss: 2.0596777399381003

Epoch: 6| Step: 13
Training loss: 1.2442922592163086
Validation loss: 2.093916138013204

Epoch: 423| Step: 0
Training loss: 0.8674135804176331
Validation loss: 2.0419311126073203

Epoch: 6| Step: 1
Training loss: 0.5500062704086304
Validation loss: 2.1028186082839966

Epoch: 6| Step: 2
Training loss: 0.7776293754577637
Validation loss: 2.1035434206326804

Epoch: 6| Step: 3
Training loss: 0.9583428502082825
Validation loss: 2.068090478579203

Epoch: 6| Step: 4
Training loss: 0.7286363840103149
Validation loss: 2.0697202483812966

Epoch: 6| Step: 5
Training loss: 1.1472082138061523
Validation loss: 2.042443792025248

Epoch: 6| Step: 6
Training loss: 0.5180819630622864
Validation loss: 2.0460369984308877

Epoch: 6| Step: 7
Training loss: 0.9561123251914978
Validation loss: 2.0453559160232544

Epoch: 6| Step: 8
Training loss: 0.8950536847114563
Validation loss: 2.0410964091618857

Epoch: 6| Step: 9
Training loss: 1.5922448635101318
Validation loss: 2.0382195909818015

Epoch: 6| Step: 10
Training loss: 0.9088804125785828
Validation loss: 2.0766214529673257

Epoch: 6| Step: 11
Training loss: 0.6163955926895142
Validation loss: 2.1264761686325073

Epoch: 6| Step: 12
Training loss: 1.8911170959472656
Validation loss: 2.128263314565023

Epoch: 6| Step: 13
Training loss: 0.6166873574256897
Validation loss: 2.1306169827779136

Epoch: 424| Step: 0
Training loss: 0.7689257860183716
Validation loss: 2.1615437467892966

Epoch: 6| Step: 1
Training loss: 0.9214355945587158
Validation loss: 2.181777596473694

Epoch: 6| Step: 2
Training loss: 1.02135169506073
Validation loss: 2.1296931902567544

Epoch: 6| Step: 3
Training loss: 0.709755539894104
Validation loss: 2.1711256901423135

Epoch: 6| Step: 4
Training loss: 2.2362194061279297
Validation loss: 2.146050055821737

Epoch: 6| Step: 5
Training loss: 1.516350269317627
Validation loss: 2.1285380522410073

Epoch: 6| Step: 6
Training loss: 0.8215246200561523
Validation loss: 2.082896808783213

Epoch: 6| Step: 7
Training loss: 0.8115020990371704
Validation loss: 2.0726598302523294

Epoch: 6| Step: 8
Training loss: 0.9812395572662354
Validation loss: 2.088292439778646

Epoch: 6| Step: 9
Training loss: 0.49745601415634155
Validation loss: 1.9905055960019429

Epoch: 6| Step: 10
Training loss: 0.6679623126983643
Validation loss: 2.0196720560391745

Epoch: 6| Step: 11
Training loss: 0.8804981708526611
Validation loss: 2.0386470953623452

Epoch: 6| Step: 12
Training loss: 0.7695426344871521
Validation loss: 2.093133330345154

Epoch: 6| Step: 13
Training loss: 1.1747021675109863
Validation loss: 2.0760915875434875

Epoch: 425| Step: 0
Training loss: 0.6994597911834717
Validation loss: 2.1116732358932495

Epoch: 6| Step: 1
Training loss: 1.2743244171142578
Validation loss: 2.091730217138926

Epoch: 6| Step: 2
Training loss: 0.8792037963867188
Validation loss: 2.04177596171697

Epoch: 6| Step: 3
Training loss: 0.6786924004554749
Validation loss: 2.071949323018392

Epoch: 6| Step: 4
Training loss: 0.6242773532867432
Validation loss: 2.0665566523869834

Epoch: 6| Step: 5
Training loss: 0.8753189444541931
Validation loss: 2.0544488628705344

Epoch: 6| Step: 6
Training loss: 1.4176139831542969
Validation loss: 2.057172954082489

Epoch: 6| Step: 7
Training loss: 1.4231613874435425
Validation loss: 2.0840909679730735

Epoch: 6| Step: 8
Training loss: 0.7717925310134888
Validation loss: 2.1201101342837014

Epoch: 6| Step: 9
Training loss: 0.5012102127075195
Validation loss: 2.0700985193252563

Epoch: 6| Step: 10
Training loss: 0.6153032183647156
Validation loss: 2.0799799958864846

Epoch: 6| Step: 11
Training loss: 0.898816704750061
Validation loss: 2.0837170084317527

Epoch: 6| Step: 12
Training loss: 0.9791828989982605
Validation loss: 2.0729843974113464

Epoch: 6| Step: 13
Training loss: 1.1248066425323486
Validation loss: 2.061746339003245

Epoch: 426| Step: 0
Training loss: 0.9532996416091919
Validation loss: 2.1028992931048074

Epoch: 6| Step: 1
Training loss: 1.0847629308700562
Validation loss: 2.0703678528467813

Epoch: 6| Step: 2
Training loss: 0.8925514221191406
Validation loss: 2.0141931970914206

Epoch: 6| Step: 3
Training loss: 0.9938135147094727
Validation loss: 2.071965674559275

Epoch: 6| Step: 4
Training loss: 0.6123172640800476
Validation loss: 2.0153743028640747

Epoch: 6| Step: 5
Training loss: 1.3027392625808716
Validation loss: 2.0116385221481323

Epoch: 6| Step: 6
Training loss: 0.5961700677871704
Validation loss: 2.013988494873047

Epoch: 6| Step: 7
Training loss: 0.8437347412109375
Validation loss: 1.9952292044957478

Epoch: 6| Step: 8
Training loss: 0.5061786770820618
Validation loss: 1.9908967812856038

Epoch: 6| Step: 9
Training loss: 0.9607493877410889
Validation loss: 2.040866951147715

Epoch: 6| Step: 10
Training loss: 0.6376811265945435
Validation loss: 2.054802358150482

Epoch: 6| Step: 11
Training loss: 1.0873446464538574
Validation loss: 2.077222446600596

Epoch: 6| Step: 12
Training loss: 1.0814642906188965
Validation loss: 2.1068145831425986

Epoch: 6| Step: 13
Training loss: 1.1111328601837158
Validation loss: 2.1456156969070435

Epoch: 427| Step: 0
Training loss: 0.8655967712402344
Validation loss: 2.1138251026471457

Epoch: 6| Step: 1
Training loss: 0.44552916288375854
Validation loss: 2.1504657665888467

Epoch: 6| Step: 2
Training loss: 0.5906920433044434
Validation loss: 2.0809350411097207

Epoch: 6| Step: 3
Training loss: 0.5345931053161621
Validation loss: 2.0712320605913797

Epoch: 6| Step: 4
Training loss: 0.9608687162399292
Validation loss: 2.0827737847963967

Epoch: 6| Step: 5
Training loss: 1.3462344408035278
Validation loss: 2.0977215568224588

Epoch: 6| Step: 6
Training loss: 0.8489452600479126
Validation loss: 2.091656525929769

Epoch: 6| Step: 7
Training loss: 1.1270954608917236
Validation loss: 2.055461565653483

Epoch: 6| Step: 8
Training loss: 0.7686171531677246
Validation loss: 2.0850875775019326

Epoch: 6| Step: 9
Training loss: 1.3945724964141846
Validation loss: 2.108398119608561

Epoch: 6| Step: 10
Training loss: 1.2435102462768555
Validation loss: 2.1056050658226013

Epoch: 6| Step: 11
Training loss: 1.2651581764221191
Validation loss: 2.0990160504976907

Epoch: 6| Step: 12
Training loss: 0.8147192597389221
Validation loss: 2.121353030204773

Epoch: 6| Step: 13
Training loss: 0.6586378812789917
Validation loss: 2.0640800396601358

Epoch: 428| Step: 0
Training loss: 1.0272042751312256
Validation loss: 2.069813052813212

Epoch: 6| Step: 1
Training loss: 0.5602901577949524
Validation loss: 2.0563066601753235

Epoch: 6| Step: 2
Training loss: 1.07254958152771
Validation loss: 2.0550483862559

Epoch: 6| Step: 3
Training loss: 0.5576157569885254
Validation loss: 2.043789585431417

Epoch: 6| Step: 4
Training loss: 0.8460466861724854
Validation loss: 2.020719806353251

Epoch: 6| Step: 5
Training loss: 0.765119194984436
Validation loss: 2.0676395893096924

Epoch: 6| Step: 6
Training loss: 0.583630383014679
Validation loss: 2.0807286500930786

Epoch: 6| Step: 7
Training loss: 0.9144653081893921
Validation loss: 2.105036477247874

Epoch: 6| Step: 8
Training loss: 1.186420202255249
Validation loss: 2.1485058863957724

Epoch: 6| Step: 9
Training loss: 0.8850762844085693
Validation loss: 2.1063944697380066

Epoch: 6| Step: 10
Training loss: 0.5937544107437134
Validation loss: 2.140913665294647

Epoch: 6| Step: 11
Training loss: 1.3317186832427979
Validation loss: 2.176645596822103

Epoch: 6| Step: 12
Training loss: 1.1852641105651855
Validation loss: 2.1732031106948853

Epoch: 6| Step: 13
Training loss: 1.449399471282959
Validation loss: 2.180905818939209

Epoch: 429| Step: 0
Training loss: 1.5242106914520264
Validation loss: 2.135580579439799

Epoch: 6| Step: 1
Training loss: 1.2572051286697388
Validation loss: 2.132583419481913

Epoch: 6| Step: 2
Training loss: 1.3942400217056274
Validation loss: 2.121876279513041

Epoch: 6| Step: 3
Training loss: 0.8081285953521729
Validation loss: 2.0865983168284097

Epoch: 6| Step: 4
Training loss: 0.6157436370849609
Validation loss: 2.038731793562571

Epoch: 6| Step: 5
Training loss: 0.8684300780296326
Validation loss: 2.0091726581255593

Epoch: 6| Step: 6
Training loss: 0.8802168369293213
Validation loss: 2.0396370689074197

Epoch: 6| Step: 7
Training loss: 0.9888039827346802
Validation loss: 2.05188258488973

Epoch: 6| Step: 8
Training loss: 0.801235020160675
Validation loss: 2.036608556906382

Epoch: 6| Step: 9
Training loss: 0.9120122194290161
Validation loss: 2.042340358098348

Epoch: 6| Step: 10
Training loss: 0.7301434278488159
Validation loss: 2.0468334356943765

Epoch: 6| Step: 11
Training loss: 0.9459307193756104
Validation loss: 2.064820488293966

Epoch: 6| Step: 12
Training loss: 0.4891301989555359
Validation loss: 2.1026504834493003

Epoch: 6| Step: 13
Training loss: 0.4612720012664795
Validation loss: 2.123766779899597

Epoch: 430| Step: 0
Training loss: 1.0377212762832642
Validation loss: 2.1208744247754416

Epoch: 6| Step: 1
Training loss: 1.234731912612915
Validation loss: 2.122665286064148

Epoch: 6| Step: 2
Training loss: 0.9837245941162109
Validation loss: 2.111044426759084

Epoch: 6| Step: 3
Training loss: 0.721182107925415
Validation loss: 2.0896517833073935

Epoch: 6| Step: 4
Training loss: 1.3325490951538086
Validation loss: 2.116119086742401

Epoch: 6| Step: 5
Training loss: 0.7277169227600098
Validation loss: 2.083107133706411

Epoch: 6| Step: 6
Training loss: 0.9082270264625549
Validation loss: 2.105183402697245

Epoch: 6| Step: 7
Training loss: 0.6279059648513794
Validation loss: 2.0902183850606284

Epoch: 6| Step: 8
Training loss: 0.7590175271034241
Validation loss: 2.0422353744506836

Epoch: 6| Step: 9
Training loss: 0.676439642906189
Validation loss: 2.071823080380758

Epoch: 6| Step: 10
Training loss: 0.47425249218940735
Validation loss: 2.0698782205581665

Epoch: 6| Step: 11
Training loss: 0.7982537746429443
Validation loss: 2.0544782479604087

Epoch: 6| Step: 12
Training loss: 0.8837544918060303
Validation loss: 2.0856727759043374

Epoch: 6| Step: 13
Training loss: 0.9185715913772583
Validation loss: 2.089376747608185

Epoch: 431| Step: 0
Training loss: 0.6376345157623291
Validation loss: 2.1026731133461

Epoch: 6| Step: 1
Training loss: 0.6821574568748474
Validation loss: 2.1054212053616843

Epoch: 6| Step: 2
Training loss: 0.5931980013847351
Validation loss: 2.1294027964274087

Epoch: 6| Step: 3
Training loss: 0.6200518608093262
Validation loss: 2.122304936250051

Epoch: 6| Step: 4
Training loss: 0.7843390703201294
Validation loss: 2.124147971471151

Epoch: 6| Step: 5
Training loss: 0.8594235181808472
Validation loss: 2.1822426319122314

Epoch: 6| Step: 6
Training loss: 1.2019338607788086
Validation loss: 2.1380014220873513

Epoch: 6| Step: 7
Training loss: 0.7639845609664917
Validation loss: 2.1313655376434326

Epoch: 6| Step: 8
Training loss: 1.9309338331222534
Validation loss: 2.1177209417025247

Epoch: 6| Step: 9
Training loss: 0.9776966571807861
Validation loss: 2.0758062998453775

Epoch: 6| Step: 10
Training loss: 0.6751866340637207
Validation loss: 2.089773257573446

Epoch: 6| Step: 11
Training loss: 0.8170101642608643
Validation loss: 2.0661650896072388

Epoch: 6| Step: 12
Training loss: 0.49985623359680176
Validation loss: 2.003776709238688

Epoch: 6| Step: 13
Training loss: 1.9319061040878296
Validation loss: 2.0558774868647256

Epoch: 432| Step: 0
Training loss: 0.9031287431716919
Validation loss: 2.0360161463419595

Epoch: 6| Step: 1
Training loss: 0.8747477531433105
Validation loss: 1.9918804963429768

Epoch: 6| Step: 2
Training loss: 0.5894876718521118
Validation loss: 2.0660887360572815

Epoch: 6| Step: 3
Training loss: 0.41216206550598145
Validation loss: 2.0435456037521362

Epoch: 6| Step: 4
Training loss: 0.7970432043075562
Validation loss: 2.0307846069335938

Epoch: 6| Step: 5
Training loss: 1.030198097229004
Validation loss: 2.0440380970637

Epoch: 6| Step: 6
Training loss: 1.6529769897460938
Validation loss: 2.0350818634033203

Epoch: 6| Step: 7
Training loss: 1.170367956161499
Validation loss: 2.0443387428919473

Epoch: 6| Step: 8
Training loss: 1.207008719444275
Validation loss: 2.0266751845677695

Epoch: 6| Step: 9
Training loss: 1.1931688785552979
Validation loss: 2.0320892333984375

Epoch: 6| Step: 10
Training loss: 0.828129231929779
Validation loss: 2.0387135942777

Epoch: 6| Step: 11
Training loss: 0.7442448735237122
Validation loss: 2.0903647541999817

Epoch: 6| Step: 12
Training loss: 0.5657333135604858
Validation loss: 2.090359648068746

Epoch: 6| Step: 13
Training loss: 0.5617842674255371
Validation loss: 2.0821875731150308

Epoch: 433| Step: 0
Training loss: 0.6088246703147888
Validation loss: 2.1098350286483765

Epoch: 6| Step: 1
Training loss: 1.6008403301239014
Validation loss: 2.085896134376526

Epoch: 6| Step: 2
Training loss: 0.8000755310058594
Validation loss: 2.1040857434272766

Epoch: 6| Step: 3
Training loss: 0.7837501764297485
Validation loss: 2.088507294654846

Epoch: 6| Step: 4
Training loss: 0.6645432114601135
Validation loss: 2.044845779736837

Epoch: 6| Step: 5
Training loss: 0.7204726934432983
Validation loss: 2.037756542364756

Epoch: 6| Step: 6
Training loss: 0.8940138816833496
Validation loss: 2.055137852827708

Epoch: 6| Step: 7
Training loss: 1.1108503341674805
Validation loss: 2.022844970226288

Epoch: 6| Step: 8
Training loss: 0.8819957375526428
Validation loss: 2.003453175226847

Epoch: 6| Step: 9
Training loss: 0.6468201279640198
Validation loss: 2.02640438079834

Epoch: 6| Step: 10
Training loss: 0.9455568194389343
Validation loss: 2.0791999300320945

Epoch: 6| Step: 11
Training loss: 0.7842015027999878
Validation loss: 2.082461675008138

Epoch: 6| Step: 12
Training loss: 0.9747779369354248
Validation loss: 2.0974546670913696

Epoch: 6| Step: 13
Training loss: 0.7442944645881653
Validation loss: 2.084556261698405

Epoch: 434| Step: 0
Training loss: 0.6385687589645386
Validation loss: 2.050346851348877

Epoch: 6| Step: 1
Training loss: 0.9809632301330566
Validation loss: 2.0319762031237283

Epoch: 6| Step: 2
Training loss: 0.7524006366729736
Validation loss: 2.0513668855031333

Epoch: 6| Step: 3
Training loss: 1.0905718803405762
Validation loss: 2.0690479079882302

Epoch: 6| Step: 4
Training loss: 0.6105334162712097
Validation loss: 2.0505800445874534

Epoch: 6| Step: 5
Training loss: 1.059680461883545
Validation loss: 2.0910940567652383

Epoch: 6| Step: 6
Training loss: 0.7018669843673706
Validation loss: 2.105445981025696

Epoch: 6| Step: 7
Training loss: 0.6113237738609314
Validation loss: 2.097244381904602

Epoch: 6| Step: 8
Training loss: 1.4106941223144531
Validation loss: 2.1007347901662192

Epoch: 6| Step: 9
Training loss: 0.7839877605438232
Validation loss: 2.125351866086324

Epoch: 6| Step: 10
Training loss: 0.7085170745849609
Validation loss: 2.1344165404637656

Epoch: 6| Step: 11
Training loss: 1.3556218147277832
Validation loss: 2.114467183748881

Epoch: 6| Step: 12
Training loss: 0.8062949180603027
Validation loss: 2.0673973162968955

Epoch: 6| Step: 13
Training loss: 0.4111160933971405
Validation loss: 2.03287680943807

Epoch: 435| Step: 0
Training loss: 0.7172721028327942
Validation loss: 2.038645108540853

Epoch: 6| Step: 1
Training loss: 1.1487585306167603
Validation loss: 2.047233740488688

Epoch: 6| Step: 2
Training loss: 0.5889710187911987
Validation loss: 2.0305173993110657

Epoch: 6| Step: 3
Training loss: 0.5851801037788391
Validation loss: 2.0171910524368286

Epoch: 6| Step: 4
Training loss: 0.8409252166748047
Validation loss: 2.008331755797068

Epoch: 6| Step: 5
Training loss: 0.7966920733451843
Validation loss: 2.0361027121543884

Epoch: 6| Step: 6
Training loss: 0.8692727088928223
Validation loss: 2.0722565253575644

Epoch: 6| Step: 7
Training loss: 0.706470787525177
Validation loss: 2.04503987232844

Epoch: 6| Step: 8
Training loss: 0.7812134027481079
Validation loss: 2.028415640195211

Epoch: 6| Step: 9
Training loss: 0.8005130290985107
Validation loss: 2.049993912378947

Epoch: 6| Step: 10
Training loss: 0.44770869612693787
Validation loss: 2.0589386622111

Epoch: 6| Step: 11
Training loss: 1.3031179904937744
Validation loss: 2.076457897822062

Epoch: 6| Step: 12
Training loss: 1.2538890838623047
Validation loss: 2.083720942338308

Epoch: 6| Step: 13
Training loss: 0.8114287853240967
Validation loss: 2.1310089429219565

Epoch: 436| Step: 0
Training loss: 0.7328227758407593
Validation loss: 2.080045143763224

Epoch: 6| Step: 1
Training loss: 0.5731227397918701
Validation loss: 2.0894447962443032

Epoch: 6| Step: 2
Training loss: 1.785104751586914
Validation loss: 2.035055955251058

Epoch: 6| Step: 3
Training loss: 0.6212995052337646
Validation loss: 2.035606880982717

Epoch: 6| Step: 4
Training loss: 0.4342922866344452
Validation loss: 2.0168397227923074

Epoch: 6| Step: 5
Training loss: 0.5400679707527161
Validation loss: 2.0299336910247803

Epoch: 6| Step: 6
Training loss: 0.9906972646713257
Validation loss: 1.9974535306294758

Epoch: 6| Step: 7
Training loss: 0.46836361289024353
Validation loss: 2.0209985772768655

Epoch: 6| Step: 8
Training loss: 1.3111379146575928
Validation loss: 2.0026231010754905

Epoch: 6| Step: 9
Training loss: 0.9943283796310425
Validation loss: 2.027782062689463

Epoch: 6| Step: 10
Training loss: 1.1156266927719116
Validation loss: 2.0268030563990274

Epoch: 6| Step: 11
Training loss: 0.5926666259765625
Validation loss: 2.001911461353302

Epoch: 6| Step: 12
Training loss: 1.038020372390747
Validation loss: 2.0288732051849365

Epoch: 6| Step: 13
Training loss: 0.5176100730895996
Validation loss: 2.0236292481422424

Epoch: 437| Step: 0
Training loss: 0.484200119972229
Validation loss: 2.0379355351130166

Epoch: 6| Step: 1
Training loss: 0.827847957611084
Validation loss: 2.0650455355644226

Epoch: 6| Step: 2
Training loss: 0.4564061164855957
Validation loss: 2.0908565123875937

Epoch: 6| Step: 3
Training loss: 1.0406678915023804
Validation loss: 2.0802144010861716

Epoch: 6| Step: 4
Training loss: 1.1379773616790771
Validation loss: 2.07673450311025

Epoch: 6| Step: 5
Training loss: 0.6440483331680298
Validation loss: 2.0730011463165283

Epoch: 6| Step: 6
Training loss: 1.4402598142623901
Validation loss: 2.0691184401512146

Epoch: 6| Step: 7
Training loss: 0.3623411953449249
Validation loss: 2.0626702904701233

Epoch: 6| Step: 8
Training loss: 0.532795786857605
Validation loss: 2.071415682633718

Epoch: 6| Step: 9
Training loss: 1.1055219173431396
Validation loss: 2.03955086072286

Epoch: 6| Step: 10
Training loss: 0.6991642117500305
Validation loss: 2.010413428147634

Epoch: 6| Step: 11
Training loss: 1.4119234085083008
Validation loss: 2.0471228758494058

Epoch: 6| Step: 12
Training loss: 0.3772110342979431
Validation loss: 2.089520891507467

Epoch: 6| Step: 13
Training loss: 1.5059764385223389
Validation loss: 2.086979349454244

Epoch: 438| Step: 0
Training loss: 0.7338771224021912
Validation loss: 2.0741177797317505

Epoch: 6| Step: 1
Training loss: 1.130499243736267
Validation loss: 2.057064870993296

Epoch: 6| Step: 2
Training loss: 0.4871765971183777
Validation loss: 2.1215888460477195

Epoch: 6| Step: 3
Training loss: 0.6507362127304077
Validation loss: 2.0892784794171653

Epoch: 6| Step: 4
Training loss: 0.4010475277900696
Validation loss: 2.092997054258982

Epoch: 6| Step: 5
Training loss: 0.6335378885269165
Validation loss: 2.078930834929148

Epoch: 6| Step: 6
Training loss: 0.518339991569519
Validation loss: 2.090524355570475

Epoch: 6| Step: 7
Training loss: 1.0078299045562744
Validation loss: 2.0790194272994995

Epoch: 6| Step: 8
Training loss: 1.2233515977859497
Validation loss: 2.0810479323069253

Epoch: 6| Step: 9
Training loss: 1.3581969738006592
Validation loss: 2.080121417840322

Epoch: 6| Step: 10
Training loss: 0.9309757351875305
Validation loss: 2.06820015112559

Epoch: 6| Step: 11
Training loss: 0.6085786819458008
Validation loss: 2.097199499607086

Epoch: 6| Step: 12
Training loss: 1.3876076936721802
Validation loss: 2.0659491817156472

Epoch: 6| Step: 13
Training loss: 0.7494056224822998
Validation loss: 2.0410609046618142

Epoch: 439| Step: 0
Training loss: 1.3576794862747192
Validation loss: 2.018570383389791

Epoch: 6| Step: 1
Training loss: 0.6248798966407776
Validation loss: 2.0338239868481955

Epoch: 6| Step: 2
Training loss: 1.004604697227478
Validation loss: 2.056062380472819

Epoch: 6| Step: 3
Training loss: 0.6258678436279297
Validation loss: 1.9857084155082703

Epoch: 6| Step: 4
Training loss: 0.6949466466903687
Validation loss: 2.0269611477851868

Epoch: 6| Step: 5
Training loss: 1.19342839717865
Validation loss: 2.0237295031547546

Epoch: 6| Step: 6
Training loss: 0.7769066691398621
Validation loss: 1.9917218089103699

Epoch: 6| Step: 7
Training loss: 0.4637603163719177
Validation loss: 2.0346706906954446

Epoch: 6| Step: 8
Training loss: 1.3224352598190308
Validation loss: 2.0741606752077737

Epoch: 6| Step: 9
Training loss: 0.5207180380821228
Validation loss: 2.1134148438771567

Epoch: 6| Step: 10
Training loss: 0.5234448313713074
Validation loss: 2.1117193897565207

Epoch: 6| Step: 11
Training loss: 0.551543116569519
Validation loss: 2.0834752519925437

Epoch: 6| Step: 12
Training loss: 1.242377519607544
Validation loss: 2.0964512626330056

Epoch: 6| Step: 13
Training loss: 0.5750937461853027
Validation loss: 2.0489443143208823

Epoch: 440| Step: 0
Training loss: 0.4416131377220154
Validation loss: 2.068956474463145

Epoch: 6| Step: 1
Training loss: 0.3744567632675171
Validation loss: 2.0411484241485596

Epoch: 6| Step: 2
Training loss: 0.7658596038818359
Validation loss: 2.0248026053110757

Epoch: 6| Step: 3
Training loss: 1.1610357761383057
Validation loss: 2.000666836897532

Epoch: 6| Step: 4
Training loss: 0.8314876556396484
Validation loss: 1.9877938429514568

Epoch: 6| Step: 5
Training loss: 0.7394053339958191
Validation loss: 2.0231075485547385

Epoch: 6| Step: 6
Training loss: 0.5325896739959717
Validation loss: 2.038444995880127

Epoch: 6| Step: 7
Training loss: 0.5520267486572266
Validation loss: 2.0492746432622275

Epoch: 6| Step: 8
Training loss: 0.5462051630020142
Validation loss: 1.9706270694732666

Epoch: 6| Step: 9
Training loss: 1.643670678138733
Validation loss: 2.0278484225273132

Epoch: 6| Step: 10
Training loss: 0.7147424221038818
Validation loss: 2.0062891046206155

Epoch: 6| Step: 11
Training loss: 0.8304136395454407
Validation loss: 2.016632318496704

Epoch: 6| Step: 12
Training loss: 1.2302429676055908
Validation loss: 2.0255168676376343

Epoch: 6| Step: 13
Training loss: 1.1807003021240234
Validation loss: 2.0099847316741943

Epoch: 441| Step: 0
Training loss: 1.0788296461105347
Validation loss: 2.007407029469808

Epoch: 6| Step: 1
Training loss: 0.7450029253959656
Validation loss: 2.0295764009157815

Epoch: 6| Step: 2
Training loss: 0.5985232591629028
Validation loss: 2.0475926399230957

Epoch: 6| Step: 3
Training loss: 0.7448046803474426
Validation loss: 2.008714218934377

Epoch: 6| Step: 4
Training loss: 0.9441319704055786
Validation loss: 2.063633700211843

Epoch: 6| Step: 5
Training loss: 0.9602519273757935
Validation loss: 2.0088884234428406

Epoch: 6| Step: 6
Training loss: 0.9364206790924072
Validation loss: 2.0557820200920105

Epoch: 6| Step: 7
Training loss: 0.5915541648864746
Validation loss: 2.057290554046631

Epoch: 6| Step: 8
Training loss: 0.8171541094779968
Validation loss: 1.9938886364301045

Epoch: 6| Step: 9
Training loss: 0.531696081161499
Validation loss: 2.017250339190165

Epoch: 6| Step: 10
Training loss: 0.8262981176376343
Validation loss: 2.0633652806282043

Epoch: 6| Step: 11
Training loss: 0.8162123560905457
Validation loss: 2.0289241472880044

Epoch: 6| Step: 12
Training loss: 0.6382532715797424
Validation loss: 2.040959338347117

Epoch: 6| Step: 13
Training loss: 0.9478074312210083
Validation loss: 2.0158554116884866

Epoch: 442| Step: 0
Training loss: 0.5623915195465088
Validation loss: 2.0357325275739035

Epoch: 6| Step: 1
Training loss: 0.6294291615486145
Validation loss: 2.041333238283793

Epoch: 6| Step: 2
Training loss: 0.7305202484130859
Validation loss: 2.046310762564341

Epoch: 6| Step: 3
Training loss: 0.7201212644577026
Validation loss: 2.092028101285299

Epoch: 6| Step: 4
Training loss: 0.4191735088825226
Validation loss: 2.0326371788978577

Epoch: 6| Step: 5
Training loss: 0.8702902793884277
Validation loss: 2.0124959150950112

Epoch: 6| Step: 6
Training loss: 1.6651285886764526
Validation loss: 1.9990762670834858

Epoch: 6| Step: 7
Training loss: 0.5495339632034302
Validation loss: 2.007542530695597

Epoch: 6| Step: 8
Training loss: 1.0388890504837036
Validation loss: 2.0324095487594604

Epoch: 6| Step: 9
Training loss: 0.5583968162536621
Validation loss: 2.0257477164268494

Epoch: 6| Step: 10
Training loss: 1.2172865867614746
Validation loss: 2.014404773712158

Epoch: 6| Step: 11
Training loss: 0.8591321706771851
Validation loss: 2.0366283456484475

Epoch: 6| Step: 12
Training loss: 0.867385745048523
Validation loss: 2.045031110445658

Epoch: 6| Step: 13
Training loss: 0.4074866771697998
Validation loss: 2.021162450313568

Epoch: 443| Step: 0
Training loss: 1.0166616439819336
Validation loss: 2.0164161125818887

Epoch: 6| Step: 1
Training loss: 0.27579769492149353
Validation loss: 2.061977823575338

Epoch: 6| Step: 2
Training loss: 0.3878791332244873
Validation loss: 2.0828347206115723

Epoch: 6| Step: 3
Training loss: 0.41620081663131714
Validation loss: 2.077969551086426

Epoch: 6| Step: 4
Training loss: 0.5404425859451294
Validation loss: 2.0864199002583823

Epoch: 6| Step: 5
Training loss: 0.8449832201004028
Validation loss: 2.0775240858395896

Epoch: 6| Step: 6
Training loss: 1.0385147333145142
Validation loss: 2.0598606864611306

Epoch: 6| Step: 7
Training loss: 0.9164765477180481
Validation loss: 2.0770270228385925

Epoch: 6| Step: 8
Training loss: 0.36854931712150574
Validation loss: 2.0689873099327087

Epoch: 6| Step: 9
Training loss: 0.5715795755386353
Validation loss: 2.007917126019796

Epoch: 6| Step: 10
Training loss: 1.0280747413635254
Validation loss: 2.0049673318862915

Epoch: 6| Step: 11
Training loss: 1.8169488906860352
Validation loss: 2.0451380610466003

Epoch: 6| Step: 12
Training loss: 1.6071200370788574
Validation loss: 2.0539418856302896

Epoch: 6| Step: 13
Training loss: 0.5812621712684631
Validation loss: 2.048484663168589

Epoch: 444| Step: 0
Training loss: 0.9367422461509705
Validation loss: 2.0244783759117126

Epoch: 6| Step: 1
Training loss: 0.4195029139518738
Validation loss: 2.054346481959025

Epoch: 6| Step: 2
Training loss: 0.7965871691703796
Validation loss: 2.019949952761332

Epoch: 6| Step: 3
Training loss: 0.7679330706596375
Validation loss: 2.087860186894735

Epoch: 6| Step: 4
Training loss: 0.6809390783309937
Validation loss: 2.042908549308777

Epoch: 6| Step: 5
Training loss: 0.7278790473937988
Validation loss: 2.0332456628481546

Epoch: 6| Step: 6
Training loss: 0.7461265921592712
Validation loss: 2.019494116306305

Epoch: 6| Step: 7
Training loss: 0.3485744595527649
Validation loss: 2.0719743967056274

Epoch: 6| Step: 8
Training loss: 0.3019940257072449
Validation loss: 2.047674854596456

Epoch: 6| Step: 9
Training loss: 1.983410358428955
Validation loss: 2.0535203019777932

Epoch: 6| Step: 10
Training loss: 0.9018529653549194
Validation loss: 2.0683456460634866

Epoch: 6| Step: 11
Training loss: 0.9266036748886108
Validation loss: 2.084100286165873

Epoch: 6| Step: 12
Training loss: 1.2278212308883667
Validation loss: 2.0772140423456826

Epoch: 6| Step: 13
Training loss: 0.4942435622215271
Validation loss: 2.0150657892227173

Epoch: 445| Step: 0
Training loss: 0.7572329044342041
Validation loss: 2.0621681610743203

Epoch: 6| Step: 1
Training loss: 0.7823657393455505
Validation loss: 2.0849629441897073

Epoch: 6| Step: 2
Training loss: 0.32284408807754517
Validation loss: 2.04963227113088

Epoch: 6| Step: 3
Training loss: 1.0734176635742188
Validation loss: 2.0572750171025596

Epoch: 6| Step: 4
Training loss: 0.3022502660751343
Validation loss: 2.061056077480316

Epoch: 6| Step: 5
Training loss: 0.5992712378501892
Validation loss: 2.0928240219751992

Epoch: 6| Step: 6
Training loss: 0.9811580181121826
Validation loss: 2.0586901108423867

Epoch: 6| Step: 7
Training loss: 1.2119776010513306
Validation loss: 2.0854190985361734

Epoch: 6| Step: 8
Training loss: 0.8777980804443359
Validation loss: 2.0722698171933494

Epoch: 6| Step: 9
Training loss: 0.9349321126937866
Validation loss: 2.0800615350405374

Epoch: 6| Step: 10
Training loss: 0.430154025554657
Validation loss: 2.0586344599723816

Epoch: 6| Step: 11
Training loss: 0.7140785455703735
Validation loss: 2.0817530949910483

Epoch: 6| Step: 12
Training loss: 1.1982483863830566
Validation loss: 2.060449560483297

Epoch: 6| Step: 13
Training loss: 0.8111571669578552
Validation loss: 2.0542919834454856

Epoch: 446| Step: 0
Training loss: 0.8447372317314148
Validation loss: 2.0334648291269937

Epoch: 6| Step: 1
Training loss: 1.2606699466705322
Validation loss: 2.0545953710873923

Epoch: 6| Step: 2
Training loss: 0.38213157653808594
Validation loss: 2.0882588227589927

Epoch: 6| Step: 3
Training loss: 1.5198004245758057
Validation loss: 2.0661297837893167

Epoch: 6| Step: 4
Training loss: 1.1373322010040283
Validation loss: 2.064911365509033

Epoch: 6| Step: 5
Training loss: 0.6875042915344238
Validation loss: 2.077146808306376

Epoch: 6| Step: 6
Training loss: 0.5499720573425293
Validation loss: 2.067597488562266

Epoch: 6| Step: 7
Training loss: 0.5117637515068054
Validation loss: 2.0130128463109336

Epoch: 6| Step: 8
Training loss: 0.8113768696784973
Validation loss: 2.0319838921229043

Epoch: 6| Step: 9
Training loss: 0.35632097721099854
Validation loss: 2.0402670900026956

Epoch: 6| Step: 10
Training loss: 0.9261554479598999
Validation loss: 2.062973062197367

Epoch: 6| Step: 11
Training loss: 0.7022778987884521
Validation loss: 2.0929470459620156

Epoch: 6| Step: 12
Training loss: 0.8406044244766235
Validation loss: 2.063093582789103

Epoch: 6| Step: 13
Training loss: 0.32395440340042114
Validation loss: 2.0567710796991983

Epoch: 447| Step: 0
Training loss: 0.24155044555664062
Validation loss: 2.0031867623329163

Epoch: 6| Step: 1
Training loss: 0.7100840210914612
Validation loss: 2.0512963930765786

Epoch: 6| Step: 2
Training loss: 0.9956738948822021
Validation loss: 2.024660507837931

Epoch: 6| Step: 3
Training loss: 0.9078738689422607
Validation loss: 2.0491873820622764

Epoch: 6| Step: 4
Training loss: 0.603898286819458
Validation loss: 2.0349403818448386

Epoch: 6| Step: 5
Training loss: 0.21313121914863586
Validation loss: 2.0650220115979514

Epoch: 6| Step: 6
Training loss: 0.8134007453918457
Validation loss: 2.0448602437973022

Epoch: 6| Step: 7
Training loss: 0.7428745031356812
Validation loss: 2.0528444051742554

Epoch: 6| Step: 8
Training loss: 1.5840773582458496
Validation loss: 2.1142494479815164

Epoch: 6| Step: 9
Training loss: 0.48148101568222046
Validation loss: 2.062213142712911

Epoch: 6| Step: 10
Training loss: 0.7767107486724854
Validation loss: 2.0498307744661965

Epoch: 6| Step: 11
Training loss: 0.9503969550132751
Validation loss: 2.023144006729126

Epoch: 6| Step: 12
Training loss: 0.7952184081077576
Validation loss: 2.031328717867533

Epoch: 6| Step: 13
Training loss: 0.9828921556472778
Validation loss: 2.0338101784388223

Epoch: 448| Step: 0
Training loss: 0.7275521755218506
Validation loss: 2.0549261371294656

Epoch: 6| Step: 1
Training loss: 0.6849650144577026
Validation loss: 2.0137269099553428

Epoch: 6| Step: 2
Training loss: 0.35207849740982056
Validation loss: 2.0155498385429382

Epoch: 6| Step: 3
Training loss: 0.9190632104873657
Validation loss: 2.0008261998494468

Epoch: 6| Step: 4
Training loss: 0.7989546060562134
Validation loss: 2.0660128792126975

Epoch: 6| Step: 5
Training loss: 1.1662046909332275
Validation loss: 2.0170101523399353

Epoch: 6| Step: 6
Training loss: 0.5723844766616821
Validation loss: 2.0401637951533

Epoch: 6| Step: 7
Training loss: 0.9471577405929565
Validation loss: 2.0675959388415017

Epoch: 6| Step: 8
Training loss: 0.3755805492401123
Validation loss: 2.0564952294031777

Epoch: 6| Step: 9
Training loss: 2.0418264865875244
Validation loss: 2.0865654349327087

Epoch: 6| Step: 10
Training loss: 0.9658606648445129
Validation loss: 2.0753412445386252

Epoch: 6| Step: 11
Training loss: 0.8512882590293884
Validation loss: 2.031210203965505

Epoch: 6| Step: 12
Training loss: 0.451643705368042
Validation loss: 2.0493433078130088

Epoch: 6| Step: 13
Training loss: 0.6081938147544861
Validation loss: 2.043126702308655

Epoch: 449| Step: 0
Training loss: 0.46781229972839355
Validation loss: 2.014077603816986

Epoch: 6| Step: 1
Training loss: 0.8612196445465088
Validation loss: 2.0165975689888

Epoch: 6| Step: 2
Training loss: 0.6711956262588501
Validation loss: 2.04755961894989

Epoch: 6| Step: 3
Training loss: 1.5818525552749634
Validation loss: 2.0642616748809814

Epoch: 6| Step: 4
Training loss: 0.7225164771080017
Validation loss: 2.040668865044912

Epoch: 6| Step: 5
Training loss: 0.857737123966217
Validation loss: 2.0270781914393106

Epoch: 6| Step: 6
Training loss: 0.7023208141326904
Validation loss: 2.029487351576487

Epoch: 6| Step: 7
Training loss: 1.132226586341858
Validation loss: 2.002353390057882

Epoch: 6| Step: 8
Training loss: 0.9939221143722534
Validation loss: 2.0514233907063804

Epoch: 6| Step: 9
Training loss: 0.7822961807250977
Validation loss: 2.0631459951400757

Epoch: 6| Step: 10
Training loss: 1.2737956047058105
Validation loss: 2.078769544760386

Epoch: 6| Step: 11
Training loss: 0.6691371202468872
Validation loss: 2.0666842659314475

Epoch: 6| Step: 12
Training loss: 0.46591460704803467
Validation loss: 2.0312788486480713

Epoch: 6| Step: 13
Training loss: 0.5213101506233215
Validation loss: 2.0710106094678244

Epoch: 450| Step: 0
Training loss: 1.0145678520202637
Validation loss: 2.02436896165212

Epoch: 6| Step: 1
Training loss: 0.22003580629825592
Validation loss: 2.0069544116655984

Epoch: 6| Step: 2
Training loss: 0.5655665397644043
Validation loss: 2.0403159658114114

Epoch: 6| Step: 3
Training loss: 1.0802299976348877
Validation loss: 2.0399027665456138

Epoch: 6| Step: 4
Training loss: 1.3802175521850586
Validation loss: 2.0161778132120767

Epoch: 6| Step: 5
Training loss: 0.7099299430847168
Validation loss: 2.04457288980484

Epoch: 6| Step: 6
Training loss: 0.7089031934738159
Validation loss: 2.0634127457936606

Epoch: 6| Step: 7
Training loss: 0.7336077094078064
Validation loss: 2.0385575890541077

Epoch: 6| Step: 8
Training loss: 0.7378694415092468
Validation loss: 2.10507869720459

Epoch: 6| Step: 9
Training loss: 0.509984016418457
Validation loss: 2.0722670753796897

Epoch: 6| Step: 10
Training loss: 0.8325967788696289
Validation loss: 2.0557570258776345

Epoch: 6| Step: 11
Training loss: 1.3725899457931519
Validation loss: 2.0508804321289062

Epoch: 6| Step: 12
Training loss: 0.7004357576370239
Validation loss: 2.0277692476908364

Epoch: 6| Step: 13
Training loss: 0.6160018444061279
Validation loss: 2.0413273572921753

Epoch: 451| Step: 0
Training loss: 0.6883742213249207
Validation loss: 2.002349853515625

Epoch: 6| Step: 1
Training loss: 0.71220862865448
Validation loss: 1.9936517079671223

Epoch: 6| Step: 2
Training loss: 0.6227599382400513
Validation loss: 2.017198304335276

Epoch: 6| Step: 3
Training loss: 0.8947674632072449
Validation loss: 2.00984925031662

Epoch: 6| Step: 4
Training loss: 0.6214781403541565
Validation loss: 2.00614066918691

Epoch: 6| Step: 5
Training loss: 0.6119499802589417
Validation loss: 1.9895136555035908

Epoch: 6| Step: 6
Training loss: 1.414181113243103
Validation loss: 2.03073787689209

Epoch: 6| Step: 7
Training loss: 0.7406003475189209
Validation loss: 2.0247361858685813

Epoch: 6| Step: 8
Training loss: 0.35487568378448486
Validation loss: 2.0081153909365335

Epoch: 6| Step: 9
Training loss: 0.7818777561187744
Validation loss: 2.0867785016695657

Epoch: 6| Step: 10
Training loss: 0.9737001657485962
Validation loss: 2.1059864362080893

Epoch: 6| Step: 11
Training loss: 0.845786452293396
Validation loss: 2.1316445668538413

Epoch: 6| Step: 12
Training loss: 0.8789265751838684
Validation loss: 2.1001316905021667

Epoch: 6| Step: 13
Training loss: 1.0880777835845947
Validation loss: 2.1091360449790955

Epoch: 452| Step: 0
Training loss: 0.7470773458480835
Validation loss: 2.0496718287467957

Epoch: 6| Step: 1
Training loss: 0.5002180337905884
Validation loss: 2.0387479861577353

Epoch: 6| Step: 2
Training loss: 0.8536726236343384
Validation loss: 2.0418462554613748

Epoch: 6| Step: 3
Training loss: 0.4134690463542938
Validation loss: 2.0177307526270547

Epoch: 6| Step: 4
Training loss: 1.4011993408203125
Validation loss: 2.0680793722470603

Epoch: 6| Step: 5
Training loss: 1.1739038228988647
Validation loss: 2.092626452445984

Epoch: 6| Step: 6
Training loss: 1.2304317951202393
Validation loss: 2.0417182048161826

Epoch: 6| Step: 7
Training loss: 0.30178770422935486
Validation loss: 2.0499786337216697

Epoch: 6| Step: 8
Training loss: 0.40474382042884827
Validation loss: 2.018005887667338

Epoch: 6| Step: 9
Training loss: 0.4486026167869568
Validation loss: 2.0303454796473184

Epoch: 6| Step: 10
Training loss: 0.5407412648200989
Validation loss: 2.0568235317866006

Epoch: 6| Step: 11
Training loss: 0.7147156596183777
Validation loss: 1.9897779027620952

Epoch: 6| Step: 12
Training loss: 0.9270168542861938
Validation loss: 2.0095746715863547

Epoch: 6| Step: 13
Training loss: 0.9100589752197266
Validation loss: 2.0447692275047302

Epoch: 453| Step: 0
Training loss: 1.0141631364822388
Validation loss: 2.077239692211151

Epoch: 6| Step: 1
Training loss: 0.8387206792831421
Validation loss: 2.076925496260325

Epoch: 6| Step: 2
Training loss: 0.9296141862869263
Validation loss: 2.061141848564148

Epoch: 6| Step: 3
Training loss: 0.7661216259002686
Validation loss: 2.073105752468109

Epoch: 6| Step: 4
Training loss: 0.9146268963813782
Validation loss: 2.0640212297439575

Epoch: 6| Step: 5
Training loss: 0.7254381775856018
Validation loss: 1.9923239549001057

Epoch: 6| Step: 6
Training loss: 0.783443808555603
Validation loss: 2.002531905968984

Epoch: 6| Step: 7
Training loss: 0.854597806930542
Validation loss: 2.0029001434644065

Epoch: 6| Step: 8
Training loss: 1.1254560947418213
Validation loss: 1.9769022266070049

Epoch: 6| Step: 9
Training loss: 0.613249659538269
Validation loss: 2.041319946448008

Epoch: 6| Step: 10
Training loss: 0.5685769319534302
Validation loss: 2.038053035736084

Epoch: 6| Step: 11
Training loss: 0.5111182928085327
Validation loss: 2.076806346575419

Epoch: 6| Step: 12
Training loss: 1.0258541107177734
Validation loss: 2.0429235696792603

Epoch: 6| Step: 13
Training loss: 0.5953518152236938
Validation loss: 2.040913999080658

Epoch: 454| Step: 0
Training loss: 0.8712361454963684
Validation loss: 2.0494258205095925

Epoch: 6| Step: 1
Training loss: 0.4914016127586365
Validation loss: 2.0198431809743247

Epoch: 6| Step: 2
Training loss: 0.9630299806594849
Validation loss: 2.019941508769989

Epoch: 6| Step: 3
Training loss: 0.8067667484283447
Validation loss: 2.0444058179855347

Epoch: 6| Step: 4
Training loss: 0.8266696929931641
Validation loss: 2.039461334546407

Epoch: 6| Step: 5
Training loss: 0.6511052846908569
Validation loss: 2.077077070871989

Epoch: 6| Step: 6
Training loss: 0.38904720544815063
Validation loss: 2.0621989369392395

Epoch: 6| Step: 7
Training loss: 1.579087495803833
Validation loss: 2.0394078493118286

Epoch: 6| Step: 8
Training loss: 0.4555131793022156
Validation loss: 2.078353742758433

Epoch: 6| Step: 9
Training loss: 1.0682743787765503
Validation loss: 2.0377222299575806

Epoch: 6| Step: 10
Training loss: 0.8206024765968323
Validation loss: 2.0032056172688804

Epoch: 6| Step: 11
Training loss: 1.2185273170471191
Validation loss: 1.9752349654833476

Epoch: 6| Step: 12
Training loss: 0.4161671996116638
Validation loss: 1.9578022956848145

Epoch: 6| Step: 13
Training loss: 1.1539546251296997
Validation loss: 1.9950902462005615

Epoch: 455| Step: 0
Training loss: 1.095777988433838
Validation loss: 2.014837404092153

Epoch: 6| Step: 1
Training loss: 0.6409642100334167
Validation loss: 2.018368383248647

Epoch: 6| Step: 2
Training loss: 0.4364621639251709
Validation loss: 2.0283936063448587

Epoch: 6| Step: 3
Training loss: 0.863577127456665
Validation loss: 2.0158900022506714

Epoch: 6| Step: 4
Training loss: 1.2975038290023804
Validation loss: 2.0433011452356973

Epoch: 6| Step: 5
Training loss: 1.3943226337432861
Validation loss: 2.0597117145856223

Epoch: 6| Step: 6
Training loss: 0.8083539009094238
Validation loss: 2.0634615818659463

Epoch: 6| Step: 7
Training loss: 0.9424527287483215
Validation loss: 2.0926186243693032

Epoch: 6| Step: 8
Training loss: 0.6810341477394104
Validation loss: 2.1095979809761047

Epoch: 6| Step: 9
Training loss: 0.7429741024971008
Validation loss: 2.0579582850138345

Epoch: 6| Step: 10
Training loss: 0.5652056336402893
Validation loss: 2.078031599521637

Epoch: 6| Step: 11
Training loss: 0.6097896695137024
Validation loss: 2.1139157811800637

Epoch: 6| Step: 12
Training loss: 0.4535037577152252
Validation loss: 2.086823284626007

Epoch: 6| Step: 13
Training loss: 0.6394791603088379
Validation loss: 2.065987785657247

Epoch: 456| Step: 0
Training loss: 1.133434772491455
Validation loss: 2.060011088848114

Epoch: 6| Step: 1
Training loss: 0.37263739109039307
Validation loss: 2.076557238896688

Epoch: 6| Step: 2
Training loss: 0.8154737949371338
Validation loss: 2.072365403175354

Epoch: 6| Step: 3
Training loss: 0.4073125720024109
Validation loss: 2.0289602279663086

Epoch: 6| Step: 4
Training loss: 0.6958017349243164
Validation loss: 2.102327307065328

Epoch: 6| Step: 5
Training loss: 1.8816213607788086
Validation loss: 2.0707138180732727

Epoch: 6| Step: 6
Training loss: 0.6960959434509277
Validation loss: 2.092606842517853

Epoch: 6| Step: 7
Training loss: 0.4233282506465912
Validation loss: 2.0658963918685913

Epoch: 6| Step: 8
Training loss: 0.35584568977355957
Validation loss: 2.0531028111775718

Epoch: 6| Step: 9
Training loss: 0.715349555015564
Validation loss: 2.0841342409451804

Epoch: 6| Step: 10
Training loss: 0.5303084254264832
Validation loss: 2.0539751450220742

Epoch: 6| Step: 11
Training loss: 0.9187742471694946
Validation loss: 2.0631567239761353

Epoch: 6| Step: 12
Training loss: 0.4924785792827606
Validation loss: 2.04775063196818

Epoch: 6| Step: 13
Training loss: 0.9966716766357422
Validation loss: 2.0582173069318137

Epoch: 457| Step: 0
Training loss: 0.6839810609817505
Validation loss: 2.0760534207026162

Epoch: 6| Step: 1
Training loss: 0.9292598962783813
Validation loss: 2.026446799437205

Epoch: 6| Step: 2
Training loss: 0.7736184000968933
Validation loss: 2.024715801080068

Epoch: 6| Step: 3
Training loss: 0.972582995891571
Validation loss: 2.0641720493634543

Epoch: 6| Step: 4
Training loss: 0.5773072838783264
Validation loss: 2.0035529931386313

Epoch: 6| Step: 5
Training loss: 0.5872037410736084
Validation loss: 2.0011085073153176

Epoch: 6| Step: 6
Training loss: 1.0657439231872559
Validation loss: 1.9724145531654358

Epoch: 6| Step: 7
Training loss: 0.4954978823661804
Validation loss: 1.9589728713035583

Epoch: 6| Step: 8
Training loss: 0.6729183197021484
Validation loss: 2.0014439622561135

Epoch: 6| Step: 9
Training loss: 1.0440428256988525
Validation loss: 2.0069533387819924

Epoch: 6| Step: 10
Training loss: 0.8164039850234985
Validation loss: 2.0235276222229004

Epoch: 6| Step: 11
Training loss: 0.42358624935150146
Validation loss: 2.045539697011312

Epoch: 6| Step: 12
Training loss: 0.5618852376937866
Validation loss: 2.0160505771636963

Epoch: 6| Step: 13
Training loss: 0.9106849431991577
Validation loss: 2.0158128341039023

Epoch: 458| Step: 0
Training loss: 0.5432822704315186
Validation loss: 2.0504260659217834

Epoch: 6| Step: 1
Training loss: 0.8167273998260498
Validation loss: 2.060863276322683

Epoch: 6| Step: 2
Training loss: 1.115723967552185
Validation loss: 2.026169002056122

Epoch: 6| Step: 3
Training loss: 0.8747069835662842
Validation loss: 2.0498895247777305

Epoch: 6| Step: 4
Training loss: 0.45146697759628296
Validation loss: 2.0468810002009072

Epoch: 6| Step: 5
Training loss: 1.0924146175384521
Validation loss: 2.07459419965744

Epoch: 6| Step: 6
Training loss: 1.262131929397583
Validation loss: 2.08489857117335

Epoch: 6| Step: 7
Training loss: 0.5222969055175781
Validation loss: 2.102759083112081

Epoch: 6| Step: 8
Training loss: 0.8140614032745361
Validation loss: 2.052117188771566

Epoch: 6| Step: 9
Training loss: 0.4393088221549988
Validation loss: 2.0302422841389975

Epoch: 6| Step: 10
Training loss: 1.0055053234100342
Validation loss: 2.0656177004178367

Epoch: 6| Step: 11
Training loss: 0.3938746154308319
Validation loss: 2.041671355565389

Epoch: 6| Step: 12
Training loss: 0.5067456960678101
Validation loss: 2.045304218928019

Epoch: 6| Step: 13
Training loss: 0.7997336387634277
Validation loss: 2.0376935998598733

Epoch: 459| Step: 0
Training loss: 0.5879182815551758
Validation loss: 2.030799607435862

Epoch: 6| Step: 1
Training loss: 0.6576828360557556
Validation loss: 2.0378997524579368

Epoch: 6| Step: 2
Training loss: 0.46831291913986206
Validation loss: 2.0285178422927856

Epoch: 6| Step: 3
Training loss: 0.4365496039390564
Validation loss: 2.081849674383799

Epoch: 6| Step: 4
Training loss: 0.9194983243942261
Validation loss: 2.064907968044281

Epoch: 6| Step: 5
Training loss: 1.2713370323181152
Validation loss: 2.0958795746167502

Epoch: 6| Step: 6
Training loss: 0.6647152304649353
Validation loss: 2.080063541730245

Epoch: 6| Step: 7
Training loss: 0.29898521304130554
Validation loss: 2.1047954161961875

Epoch: 6| Step: 8
Training loss: 0.4906342625617981
Validation loss: 2.0962133010228476

Epoch: 6| Step: 9
Training loss: 1.0016310214996338
Validation loss: 2.1053338646888733

Epoch: 6| Step: 10
Training loss: 1.125488042831421
Validation loss: 2.1249893506368003

Epoch: 6| Step: 11
Training loss: 1.111036777496338
Validation loss: 2.110344409942627

Epoch: 6| Step: 12
Training loss: 0.9924424886703491
Validation loss: 2.05780827999115

Epoch: 6| Step: 13
Training loss: 1.06513249874115
Validation loss: 2.100574314594269

Epoch: 460| Step: 0
Training loss: 0.2895168662071228
Validation loss: 2.1271700263023376

Epoch: 6| Step: 1
Training loss: 0.8062362670898438
Validation loss: 2.1272093852361045

Epoch: 6| Step: 2
Training loss: 0.6252344250679016
Validation loss: 2.1542740066846213

Epoch: 6| Step: 3
Training loss: 0.4827183783054352
Validation loss: 2.131451884905497

Epoch: 6| Step: 4
Training loss: 0.40502193570137024
Validation loss: 2.075560669104258

Epoch: 6| Step: 5
Training loss: 0.7297306656837463
Validation loss: 2.062238415082296

Epoch: 6| Step: 6
Training loss: 0.9273666739463806
Validation loss: 2.056136647860209

Epoch: 6| Step: 7
Training loss: 0.9854129552841187
Validation loss: 2.0506639877955117

Epoch: 6| Step: 8
Training loss: 0.6831755638122559
Validation loss: 2.1023360093434653

Epoch: 6| Step: 9
Training loss: 1.3087742328643799
Validation loss: 2.1071242491404214

Epoch: 6| Step: 10
Training loss: 0.868084192276001
Validation loss: 2.0888890624046326

Epoch: 6| Step: 11
Training loss: 0.7238547205924988
Validation loss: 2.0904159347216287

Epoch: 6| Step: 12
Training loss: 0.9835124015808105
Validation loss: 2.100310742855072

Epoch: 6| Step: 13
Training loss: 1.3982608318328857
Validation loss: 2.088602582613627

Epoch: 461| Step: 0
Training loss: 0.44212275743484497
Validation loss: 2.1393288175264993

Epoch: 6| Step: 1
Training loss: 0.7625808715820312
Validation loss: 2.1212213039398193

Epoch: 6| Step: 2
Training loss: 0.662642240524292
Validation loss: 2.1074065367380777

Epoch: 6| Step: 3
Training loss: 0.476626992225647
Validation loss: 2.155855178833008

Epoch: 6| Step: 4
Training loss: 0.5756813287734985
Validation loss: 2.087470849355062

Epoch: 6| Step: 5
Training loss: 0.8498711585998535
Validation loss: 2.1432128151257834

Epoch: 6| Step: 6
Training loss: 2.3696699142456055
Validation loss: 2.0674055218696594

Epoch: 6| Step: 7
Training loss: 0.5567631721496582
Validation loss: 2.0545888940493264

Epoch: 6| Step: 8
Training loss: 0.5421379804611206
Validation loss: 2.013355294863383

Epoch: 6| Step: 9
Training loss: 0.8866682052612305
Validation loss: 2.011433939139048

Epoch: 6| Step: 10
Training loss: 1.2103466987609863
Validation loss: 1.9841530919075012

Epoch: 6| Step: 11
Training loss: 0.6183485984802246
Validation loss: 2.0416096846262612

Epoch: 6| Step: 12
Training loss: 0.4054967761039734
Validation loss: 2.0429284969965615

Epoch: 6| Step: 13
Training loss: 0.9144362211227417
Validation loss: 2.0310646494229636

Epoch: 462| Step: 0
Training loss: 0.4157067537307739
Validation loss: 1.988209883371989

Epoch: 6| Step: 1
Training loss: 0.8629596829414368
Validation loss: 2.046806037425995

Epoch: 6| Step: 2
Training loss: 1.3370628356933594
Validation loss: 2.096598962942759

Epoch: 6| Step: 3
Training loss: 1.584580421447754
Validation loss: 2.0828226804733276

Epoch: 6| Step: 4
Training loss: 0.38970041275024414
Validation loss: 2.0525956948598227

Epoch: 6| Step: 5
Training loss: 0.7861814498901367
Validation loss: 2.052267332871755

Epoch: 6| Step: 6
Training loss: 1.0676803588867188
Validation loss: 2.010956625143687

Epoch: 6| Step: 7
Training loss: 0.694381833076477
Validation loss: 2.0212994813919067

Epoch: 6| Step: 8
Training loss: 0.3066364824771881
Validation loss: 2.0001534819602966

Epoch: 6| Step: 9
Training loss: 0.8715763688087463
Validation loss: 2.041102389494578

Epoch: 6| Step: 10
Training loss: 0.5219879150390625
Validation loss: 2.0515180031458535

Epoch: 6| Step: 11
Training loss: 0.5725359916687012
Validation loss: 2.0477787454922995

Epoch: 6| Step: 12
Training loss: 0.5323914289474487
Validation loss: 2.005505164464315

Epoch: 6| Step: 13
Training loss: 0.7655787467956543
Validation loss: 2.031201263268789

Epoch: 463| Step: 0
Training loss: 0.7405279874801636
Validation loss: 2.057098309199015

Epoch: 6| Step: 1
Training loss: 0.5021169185638428
Validation loss: 2.0053546031316123

Epoch: 6| Step: 2
Training loss: 0.5128915309906006
Validation loss: 1.9944273630777996

Epoch: 6| Step: 3
Training loss: 0.3104749321937561
Validation loss: 2.0420174797376

Epoch: 6| Step: 4
Training loss: 0.42141997814178467
Validation loss: 2.060784618059794

Epoch: 6| Step: 5
Training loss: 0.5997748970985413
Validation loss: 2.0013769070307412

Epoch: 6| Step: 6
Training loss: 0.7464303374290466
Validation loss: 1.9939972162246704

Epoch: 6| Step: 7
Training loss: 1.1125879287719727
Validation loss: 2.051898936430613

Epoch: 6| Step: 8
Training loss: 1.4426523447036743
Validation loss: 2.025398770968119

Epoch: 6| Step: 9
Training loss: 1.6145923137664795
Validation loss: 1.9999919931093852

Epoch: 6| Step: 10
Training loss: 0.6750842332839966
Validation loss: 2.0528449217478433

Epoch: 6| Step: 11
Training loss: 0.9134202003479004
Validation loss: 1.9923896789550781

Epoch: 6| Step: 12
Training loss: 0.5127668380737305
Validation loss: 2.0101805925369263

Epoch: 6| Step: 13
Training loss: 0.3608841300010681
Validation loss: 2.0095778703689575

Epoch: 464| Step: 0
Training loss: 1.0328007936477661
Validation loss: 2.0613556702931723

Epoch: 6| Step: 1
Training loss: 0.434768944978714
Validation loss: 2.080821414788564

Epoch: 6| Step: 2
Training loss: 0.6052646636962891
Validation loss: 2.0683008432388306

Epoch: 6| Step: 3
Training loss: 0.2871280014514923
Validation loss: 2.048893928527832

Epoch: 6| Step: 4
Training loss: 0.8238714933395386
Validation loss: 2.0360050002733865

Epoch: 6| Step: 5
Training loss: 0.8093602061271667
Validation loss: 2.07670005162557

Epoch: 6| Step: 6
Training loss: 0.6594703793525696
Validation loss: 2.0216375390688577

Epoch: 6| Step: 7
Training loss: 0.476912260055542
Validation loss: 2.0542502204577127

Epoch: 6| Step: 8
Training loss: 1.294480323791504
Validation loss: 2.0618424812952676

Epoch: 6| Step: 9
Training loss: 1.554935336112976
Validation loss: 1.9979585409164429

Epoch: 6| Step: 10
Training loss: 0.5643861293792725
Validation loss: 2.0104695757230124

Epoch: 6| Step: 11
Training loss: 0.30713343620300293
Validation loss: 2.029913345972697

Epoch: 6| Step: 12
Training loss: 0.2944779694080353
Validation loss: 2.0192935268084207

Epoch: 6| Step: 13
Training loss: 0.9868018627166748
Validation loss: 2.053688327471415

Epoch: 465| Step: 0
Training loss: 0.5432957410812378
Validation loss: 1.9794871807098389

Epoch: 6| Step: 1
Training loss: 0.8103522062301636
Validation loss: 2.056938886642456

Epoch: 6| Step: 2
Training loss: 0.608957052230835
Validation loss: 1.9881249864896138

Epoch: 6| Step: 3
Training loss: 0.9965429902076721
Validation loss: 2.0259864131609597

Epoch: 6| Step: 4
Training loss: 0.4703138470649719
Validation loss: 1.9931218425432842

Epoch: 6| Step: 5
Training loss: 1.1518994569778442
Validation loss: 2.001465082168579

Epoch: 6| Step: 6
Training loss: 0.5291796922683716
Validation loss: 2.0260413885116577

Epoch: 6| Step: 7
Training loss: 0.4142385423183441
Validation loss: 2.0498397946357727

Epoch: 6| Step: 8
Training loss: 0.8147417306900024
Validation loss: 2.082073450088501

Epoch: 6| Step: 9
Training loss: 0.886070191860199
Validation loss: 2.0415887236595154

Epoch: 6| Step: 10
Training loss: 0.7454972863197327
Validation loss: 2.081129868825277

Epoch: 6| Step: 11
Training loss: 0.9148173928260803
Validation loss: 2.051003714402517

Epoch: 6| Step: 12
Training loss: 0.9219561219215393
Validation loss: 2.079517364501953

Epoch: 6| Step: 13
Training loss: 0.9202197790145874
Validation loss: 2.0377564430236816

Epoch: 466| Step: 0
Training loss: 0.9680445194244385
Validation loss: 2.058238466580709

Epoch: 6| Step: 1
Training loss: 0.5198411345481873
Validation loss: 2.0794179836908975

Epoch: 6| Step: 2
Training loss: 0.27167317271232605
Validation loss: 2.1058416167894998

Epoch: 6| Step: 3
Training loss: 0.6354659795761108
Validation loss: 2.038338621457418

Epoch: 6| Step: 4
Training loss: 0.7816281914710999
Validation loss: 2.0329990784327188

Epoch: 6| Step: 5
Training loss: 1.1560211181640625
Validation loss: 2.0092339714368186

Epoch: 6| Step: 6
Training loss: 1.460719347000122
Validation loss: 2.061152756214142

Epoch: 6| Step: 7
Training loss: 0.5048331618309021
Validation loss: 1.9994387030601501

Epoch: 6| Step: 8
Training loss: 0.3358367383480072
Validation loss: 2.0024300813674927

Epoch: 6| Step: 9
Training loss: 0.4926108717918396
Validation loss: 2.0249968767166138

Epoch: 6| Step: 10
Training loss: 0.7986520528793335
Validation loss: 2.031469762325287

Epoch: 6| Step: 11
Training loss: 0.6309165358543396
Validation loss: 1.9894416133562725

Epoch: 6| Step: 12
Training loss: 0.5973106622695923
Validation loss: 2.0057554642359414

Epoch: 6| Step: 13
Training loss: 1.075014352798462
Validation loss: 2.0143497586250305

Epoch: 467| Step: 0
Training loss: 0.7268844842910767
Validation loss: 1.9996466835339863

Epoch: 6| Step: 1
Training loss: 0.5928456783294678
Validation loss: 1.9933545192082722

Epoch: 6| Step: 2
Training loss: 0.8330328464508057
Validation loss: 2.005243440469106

Epoch: 6| Step: 3
Training loss: 0.881991446018219
Validation loss: 2.0355770786603293

Epoch: 6| Step: 4
Training loss: 0.604200541973114
Validation loss: 1.9615963697433472

Epoch: 6| Step: 5
Training loss: 0.6070333123207092
Validation loss: 1.9998558362325032

Epoch: 6| Step: 6
Training loss: 0.3808859884738922
Validation loss: 1.9964816967646282

Epoch: 6| Step: 7
Training loss: 0.6839628219604492
Validation loss: 1.9666565656661987

Epoch: 6| Step: 8
Training loss: 1.2775276899337769
Validation loss: 1.9724253018697102

Epoch: 6| Step: 9
Training loss: 0.6371623277664185
Validation loss: 1.9996251861254375

Epoch: 6| Step: 10
Training loss: 0.9024922847747803
Validation loss: 2.0043107072512307

Epoch: 6| Step: 11
Training loss: 0.38561731576919556
Validation loss: 2.0180504520734153

Epoch: 6| Step: 12
Training loss: 0.7994822859764099
Validation loss: 1.9848151803016663

Epoch: 6| Step: 13
Training loss: 1.0271800756454468
Validation loss: 2.0269303917884827

Epoch: 468| Step: 0
Training loss: 0.4518596827983856
Validation loss: 2.0287381609280906

Epoch: 6| Step: 1
Training loss: 0.38409602642059326
Validation loss: 2.0128231048583984

Epoch: 6| Step: 2
Training loss: 0.7057228684425354
Validation loss: 2.0561790664990744

Epoch: 6| Step: 3
Training loss: 0.8129115104675293
Validation loss: 2.0144147872924805

Epoch: 6| Step: 4
Training loss: 1.0884830951690674
Validation loss: 2.024808943271637

Epoch: 6| Step: 5
Training loss: 0.8843517899513245
Validation loss: 2.0252020557721457

Epoch: 6| Step: 6
Training loss: 0.8043870329856873
Validation loss: 2.02946404616038

Epoch: 6| Step: 7
Training loss: 0.6308428049087524
Validation loss: 1.9789435267448425

Epoch: 6| Step: 8
Training loss: 0.5510774254798889
Validation loss: 2.0557927886644998

Epoch: 6| Step: 9
Training loss: 0.25890690088272095
Validation loss: 1.9633098443349202

Epoch: 6| Step: 10
Training loss: 1.188554048538208
Validation loss: 2.047233541806539

Epoch: 6| Step: 11
Training loss: 0.9887650012969971
Validation loss: 2.040109614531199

Epoch: 6| Step: 12
Training loss: 1.0014585256576538
Validation loss: 2.0044754346211753

Epoch: 6| Step: 13
Training loss: 0.8833276033401489
Validation loss: 1.9702297647794087

Epoch: 469| Step: 0
Training loss: 0.5947292447090149
Validation loss: 1.9889792998631795

Epoch: 6| Step: 1
Training loss: 0.3903387784957886
Validation loss: 1.9403735597928364

Epoch: 6| Step: 2
Training loss: 0.21809518337249756
Validation loss: 1.9113860726356506

Epoch: 6| Step: 3
Training loss: 0.566663920879364
Validation loss: 1.9055866996447246

Epoch: 6| Step: 4
Training loss: 0.5840274691581726
Validation loss: 1.9406188527743022

Epoch: 6| Step: 5
Training loss: 1.01115083694458
Validation loss: 1.964822808901469

Epoch: 6| Step: 6
Training loss: 0.6285035610198975
Validation loss: 1.9674966136614482

Epoch: 6| Step: 7
Training loss: 1.5555946826934814
Validation loss: 1.9657064477602642

Epoch: 6| Step: 8
Training loss: 1.3278276920318604
Validation loss: 2.0101833740870156

Epoch: 6| Step: 9
Training loss: 0.4098186790943146
Validation loss: 1.9533035556475322

Epoch: 6| Step: 10
Training loss: 0.44656920433044434
Validation loss: 1.9782529671986897

Epoch: 6| Step: 11
Training loss: 0.9704086184501648
Validation loss: 2.029178202152252

Epoch: 6| Step: 12
Training loss: 0.6859099864959717
Validation loss: 2.034586509068807

Epoch: 6| Step: 13
Training loss: 0.8019038438796997
Validation loss: 1.979647934436798

Epoch: 470| Step: 0
Training loss: 1.4436254501342773
Validation loss: 2.0070941050847373

Epoch: 6| Step: 1
Training loss: 0.7065316438674927
Validation loss: 1.9706954558690388

Epoch: 6| Step: 2
Training loss: 0.4266626238822937
Validation loss: 1.982246994972229

Epoch: 6| Step: 3
Training loss: 0.5157405138015747
Validation loss: 2.0120562314987183

Epoch: 6| Step: 4
Training loss: 0.6205835938453674
Validation loss: 2.009268820285797

Epoch: 6| Step: 5
Training loss: 0.8259210586547852
Validation loss: 2.0309954285621643

Epoch: 6| Step: 6
Training loss: 0.8697795867919922
Validation loss: 2.0056170423825583

Epoch: 6| Step: 7
Training loss: 0.7028381824493408
Validation loss: 1.935910443464915

Epoch: 6| Step: 8
Training loss: 0.8491315245628357
Validation loss: 2.0028233329455056

Epoch: 6| Step: 9
Training loss: 0.5335652828216553
Validation loss: 1.9764814178148906

Epoch: 6| Step: 10
Training loss: 1.3581961393356323
Validation loss: 1.9847550789515178

Epoch: 6| Step: 11
Training loss: 0.5950043201446533
Validation loss: 2.0064549843470254

Epoch: 6| Step: 12
Training loss: 0.9480694532394409
Validation loss: 1.9813958207766216

Epoch: 6| Step: 13
Training loss: 0.6101434826850891
Validation loss: 2.0285834272702536

Epoch: 471| Step: 0
Training loss: 0.4996681809425354
Validation loss: 2.028221766153971

Epoch: 6| Step: 1
Training loss: 0.25689998269081116
Validation loss: 2.042304833730062

Epoch: 6| Step: 2
Training loss: 0.5829778909683228
Validation loss: 1.9992311596870422

Epoch: 6| Step: 3
Training loss: 0.6104015111923218
Validation loss: 1.9854989647865295

Epoch: 6| Step: 4
Training loss: 0.7196250557899475
Validation loss: 1.9599161346753438

Epoch: 6| Step: 5
Training loss: 0.772405207157135
Validation loss: 2.0296894311904907

Epoch: 6| Step: 6
Training loss: 0.39842522144317627
Validation loss: 1.9425815343856812

Epoch: 6| Step: 7
Training loss: 1.2158875465393066
Validation loss: 1.9885324438412983

Epoch: 6| Step: 8
Training loss: 1.6594148874282837
Validation loss: 1.9872167507807414

Epoch: 6| Step: 9
Training loss: 0.7843335866928101
Validation loss: 2.0492397348086038

Epoch: 6| Step: 10
Training loss: 0.7749960422515869
Validation loss: 2.0252841909726462

Epoch: 6| Step: 11
Training loss: 0.8318279981613159
Validation loss: 2.025821248690287

Epoch: 6| Step: 12
Training loss: 0.3548159599304199
Validation loss: 2.0376168688138327

Epoch: 6| Step: 13
Training loss: 0.7616544961929321
Validation loss: 2.0336168805758157

Epoch: 472| Step: 0
Training loss: 1.648658275604248
Validation loss: 2.0363495548566184

Epoch: 6| Step: 1
Training loss: 0.9303146004676819
Validation loss: 2.01300581296285

Epoch: 6| Step: 2
Training loss: 0.5636646151542664
Validation loss: 2.055267870426178

Epoch: 6| Step: 3
Training loss: 0.6055001020431519
Validation loss: 2.030523200829824

Epoch: 6| Step: 4
Training loss: 0.5062580108642578
Validation loss: 1.978486716747284

Epoch: 6| Step: 5
Training loss: 0.3668377995491028
Validation loss: 2.0165988405545554

Epoch: 6| Step: 6
Training loss: 0.6330589056015015
Validation loss: 2.0451703468958535

Epoch: 6| Step: 7
Training loss: 0.3451516032218933
Validation loss: 2.08559916416804

Epoch: 6| Step: 8
Training loss: 0.4348145127296448
Validation loss: 2.0644760131835938

Epoch: 6| Step: 9
Training loss: 0.6797900795936584
Validation loss: 2.0986483494440713

Epoch: 6| Step: 10
Training loss: 0.8667647838592529
Validation loss: 2.0367183883984885

Epoch: 6| Step: 11
Training loss: 1.0098158121109009
Validation loss: 2.0189034144083657

Epoch: 6| Step: 12
Training loss: 0.6673442125320435
Validation loss: 2.010721186796824

Epoch: 6| Step: 13
Training loss: 1.154742956161499
Validation loss: 2.0183507998784385

Epoch: 473| Step: 0
Training loss: 1.595835566520691
Validation loss: 2.0142997105916343

Epoch: 6| Step: 1
Training loss: 0.5066861510276794
Validation loss: 1.9598711530367534

Epoch: 6| Step: 2
Training loss: 0.9167284965515137
Validation loss: 1.9997092485427856

Epoch: 6| Step: 3
Training loss: 0.38695117831230164
Validation loss: 2.0113760034243264

Epoch: 6| Step: 4
Training loss: 0.8192018270492554
Validation loss: 1.97569344441096

Epoch: 6| Step: 5
Training loss: 0.8543586730957031
Validation loss: 1.962076723575592

Epoch: 6| Step: 6
Training loss: 0.6152302622795105
Validation loss: 2.0050963958104453

Epoch: 6| Step: 7
Training loss: 0.5101771354675293
Validation loss: 2.0033913056055703

Epoch: 6| Step: 8
Training loss: 0.9512674808502197
Validation loss: 2.03287680943807

Epoch: 6| Step: 9
Training loss: 0.7759227156639099
Validation loss: 2.0173799991607666

Epoch: 6| Step: 10
Training loss: 0.8841110467910767
Validation loss: 2.0305999914805093

Epoch: 6| Step: 11
Training loss: 0.5341665148735046
Validation loss: 1.9982389211654663

Epoch: 6| Step: 12
Training loss: 0.6450790166854858
Validation loss: 2.0527939796447754

Epoch: 6| Step: 13
Training loss: 0.32797473669052124
Validation loss: 1.9871898690859477

Epoch: 474| Step: 0
Training loss: 1.265697717666626
Validation loss: 2.0292654832204184

Epoch: 6| Step: 1
Training loss: 0.5687068700790405
Validation loss: 1.9774919152259827

Epoch: 6| Step: 2
Training loss: 0.6749180555343628
Validation loss: 1.9626323382059734

Epoch: 6| Step: 3
Training loss: 0.7985587120056152
Validation loss: 2.0746283729871116

Epoch: 6| Step: 4
Training loss: 0.5946266651153564
Validation loss: 2.067511339982351

Epoch: 6| Step: 5
Training loss: 0.45881256461143494
Validation loss: 2.071629802385966

Epoch: 6| Step: 6
Training loss: 0.9867644309997559
Validation loss: 2.030958275000254

Epoch: 6| Step: 7
Training loss: 0.7178311347961426
Validation loss: 2.0238088170687356

Epoch: 6| Step: 8
Training loss: 1.1513842344284058
Validation loss: 2.0020575722058616

Epoch: 6| Step: 9
Training loss: 0.8223315477371216
Validation loss: 2.0544127027193704

Epoch: 6| Step: 10
Training loss: 0.7057960629463196
Validation loss: 2.054476022720337

Epoch: 6| Step: 11
Training loss: 0.5610206127166748
Validation loss: 2.084000070889791

Epoch: 6| Step: 12
Training loss: 0.7548834085464478
Validation loss: 2.083161691824595

Epoch: 6| Step: 13
Training loss: 0.942798376083374
Validation loss: 2.0882361928621926

Epoch: 475| Step: 0
Training loss: 0.5515344142913818
Validation loss: 2.068730036417643

Epoch: 6| Step: 1
Training loss: 0.6757636070251465
Validation loss: 2.0703768730163574

Epoch: 6| Step: 2
Training loss: 0.7495571374893188
Validation loss: 2.053834080696106

Epoch: 6| Step: 3
Training loss: 0.628289520740509
Validation loss: 2.0063772002855935

Epoch: 6| Step: 4
Training loss: 0.5883074402809143
Validation loss: 2.010384500026703

Epoch: 6| Step: 5
Training loss: 1.6076260805130005
Validation loss: 1.9466223120689392

Epoch: 6| Step: 6
Training loss: 0.6441687345504761
Validation loss: 1.9574636220932007

Epoch: 6| Step: 7
Training loss: 0.46763941645622253
Validation loss: 2.0154563188552856

Epoch: 6| Step: 8
Training loss: 1.1936591863632202
Validation loss: 1.9659237464269002

Epoch: 6| Step: 9
Training loss: 0.9284720420837402
Validation loss: 1.9715172052383423

Epoch: 6| Step: 10
Training loss: 0.668397843837738
Validation loss: 1.981159269809723

Epoch: 6| Step: 11
Training loss: 0.7203676700592041
Validation loss: 1.9322114785512288

Epoch: 6| Step: 12
Training loss: 0.44084328413009644
Validation loss: 1.9800080060958862

Epoch: 6| Step: 13
Training loss: 0.8342194557189941
Validation loss: 2.020085334777832

Epoch: 476| Step: 0
Training loss: 0.35385429859161377
Validation loss: 1.984268844127655

Epoch: 6| Step: 1
Training loss: 0.7012812495231628
Validation loss: 1.9961920976638794

Epoch: 6| Step: 2
Training loss: 0.7792884111404419
Validation loss: 2.0259359081586203

Epoch: 6| Step: 3
Training loss: 1.0275254249572754
Validation loss: 2.02114737033844

Epoch: 6| Step: 4
Training loss: 0.9713218212127686
Validation loss: 2.0129175384839377

Epoch: 6| Step: 5
Training loss: 0.7467268705368042
Validation loss: 2.011970341205597

Epoch: 6| Step: 6
Training loss: 1.3519216775894165
Validation loss: 2.0371668934822083

Epoch: 6| Step: 7
Training loss: 0.5242455005645752
Validation loss: 2.017108142375946

Epoch: 6| Step: 8
Training loss: 0.7007933855056763
Validation loss: 1.9882287581761677

Epoch: 6| Step: 9
Training loss: 0.5233330130577087
Validation loss: 2.0704970757166543

Epoch: 6| Step: 10
Training loss: 0.3109744191169739
Validation loss: 2.026702364285787

Epoch: 6| Step: 11
Training loss: 0.5868426561355591
Validation loss: 2.0069005489349365

Epoch: 6| Step: 12
Training loss: 1.1631759405136108
Validation loss: 2.0470060110092163

Epoch: 6| Step: 13
Training loss: 0.7293599843978882
Validation loss: 2.058111866315206

Epoch: 477| Step: 0
Training loss: 0.4903141260147095
Validation loss: 2.0301919976870217

Epoch: 6| Step: 1
Training loss: 0.8246077299118042
Validation loss: 2.0438873767852783

Epoch: 6| Step: 2
Training loss: 0.48019760847091675
Validation loss: 1.9567970633506775

Epoch: 6| Step: 3
Training loss: 0.9470098614692688
Validation loss: 1.987503707408905

Epoch: 6| Step: 4
Training loss: 0.6885287761688232
Validation loss: 1.9855884909629822

Epoch: 6| Step: 5
Training loss: 0.9184051752090454
Validation loss: 2.0371867219607034

Epoch: 6| Step: 6
Training loss: 0.7188345789909363
Validation loss: 2.0362638036410012

Epoch: 6| Step: 7
Training loss: 0.5381496548652649
Validation loss: 1.9840375185012817

Epoch: 6| Step: 8
Training loss: 0.4648999571800232
Validation loss: 1.9806724985440571

Epoch: 6| Step: 9
Training loss: 0.4858502745628357
Validation loss: 2.048698385556539

Epoch: 6| Step: 10
Training loss: 0.9898827075958252
Validation loss: 2.029717961947123

Epoch: 6| Step: 11
Training loss: 0.8281871676445007
Validation loss: 2.0175670385360718

Epoch: 6| Step: 12
Training loss: 1.271167516708374
Validation loss: 1.9921213785807292

Epoch: 6| Step: 13
Training loss: 0.398176908493042
Validation loss: 2.0277169942855835

Epoch: 478| Step: 0
Training loss: 1.1204032897949219
Validation loss: 1.9912243088086445

Epoch: 6| Step: 1
Training loss: 0.523261308670044
Validation loss: 2.015562733014425

Epoch: 6| Step: 2
Training loss: 0.34439361095428467
Validation loss: 1.9977405667304993

Epoch: 6| Step: 3
Training loss: 0.3285540044307709
Validation loss: 1.9706217845280964

Epoch: 6| Step: 4
Training loss: 0.8999049663543701
Validation loss: 1.9517159859339397

Epoch: 6| Step: 5
Training loss: 1.116071105003357
Validation loss: 2.0087469021479287

Epoch: 6| Step: 6
Training loss: 0.6396547555923462
Validation loss: 1.9624590476353962

Epoch: 6| Step: 7
Training loss: 0.39983004331588745
Validation loss: 2.037763833999634

Epoch: 6| Step: 8
Training loss: 0.4190477132797241
Validation loss: 1.9959676663080852

Epoch: 6| Step: 9
Training loss: 0.6892584562301636
Validation loss: 2.034390648206075

Epoch: 6| Step: 10
Training loss: 1.1408852338790894
Validation loss: 2.0113227168718972

Epoch: 6| Step: 11
Training loss: 1.1832780838012695
Validation loss: 1.9947469433148701

Epoch: 6| Step: 12
Training loss: 0.638144850730896
Validation loss: 2.0610092083613076

Epoch: 6| Step: 13
Training loss: 0.41452300548553467
Validation loss: 2.0618669986724854

Epoch: 479| Step: 0
Training loss: 0.7328996062278748
Validation loss: 2.00923615694046

Epoch: 6| Step: 1
Training loss: 1.0912702083587646
Validation loss: 1.9399890104929607

Epoch: 6| Step: 2
Training loss: 0.8811582922935486
Validation loss: 1.991329272588094

Epoch: 6| Step: 3
Training loss: 1.4815702438354492
Validation loss: 2.00238835811615

Epoch: 6| Step: 4
Training loss: 0.5834872126579285
Validation loss: 2.009442130724589

Epoch: 6| Step: 5
Training loss: 0.49906259775161743
Validation loss: 1.961771051088969

Epoch: 6| Step: 6
Training loss: 0.5183939933776855
Validation loss: 2.0039955178896585

Epoch: 6| Step: 7
Training loss: 0.2807459235191345
Validation loss: 2.010234455267588

Epoch: 6| Step: 8
Training loss: 0.6439725160598755
Validation loss: 2.0482048193613687

Epoch: 6| Step: 9
Training loss: 0.7463586330413818
Validation loss: 2.029257078965505

Epoch: 6| Step: 10
Training loss: 0.3949984312057495
Validation loss: 2.008752147356669

Epoch: 6| Step: 11
Training loss: 0.8331842422485352
Validation loss: 2.022834281126658

Epoch: 6| Step: 12
Training loss: 0.5348740816116333
Validation loss: 2.04086434841156

Epoch: 6| Step: 13
Training loss: 0.4335402846336365
Validation loss: 2.034548580646515

Epoch: 480| Step: 0
Training loss: 0.45335108041763306
Validation loss: 2.0424259305000305

Epoch: 6| Step: 1
Training loss: 1.1252998113632202
Validation loss: 2.055916647116343

Epoch: 6| Step: 2
Training loss: 0.34898364543914795
Validation loss: 2.0452831784884133

Epoch: 6| Step: 3
Training loss: 0.7295383810997009
Validation loss: 2.068515717983246

Epoch: 6| Step: 4
Training loss: 0.9117281436920166
Validation loss: 2.0133918126424155

Epoch: 6| Step: 5
Training loss: 0.4797021448612213
Validation loss: 1.9863687753677368

Epoch: 6| Step: 6
Training loss: 0.28359073400497437
Validation loss: 2.0261828700701394

Epoch: 6| Step: 7
Training loss: 0.7074618339538574
Validation loss: 2.0387059251467385

Epoch: 6| Step: 8
Training loss: 1.3660166263580322
Validation loss: 2.037160873413086

Epoch: 6| Step: 9
Training loss: 0.8114112019538879
Validation loss: 2.0956024726231894

Epoch: 6| Step: 10
Training loss: 0.34755653142929077
Validation loss: 2.097292184829712

Epoch: 6| Step: 11
Training loss: 0.6480813026428223
Validation loss: 2.08340714375178

Epoch: 6| Step: 12
Training loss: 1.2176342010498047
Validation loss: 2.0738362669944763

Epoch: 6| Step: 13
Training loss: 0.9345141649246216
Validation loss: 1.9984209934870403

Epoch: 481| Step: 0
Training loss: 0.774687647819519
Validation loss: 2.03807802995046

Epoch: 6| Step: 1
Training loss: 1.219726324081421
Validation loss: 2.021012862523397

Epoch: 6| Step: 2
Training loss: 0.4996297359466553
Validation loss: 2.025248110294342

Epoch: 6| Step: 3
Training loss: 0.6503995656967163
Validation loss: 2.0007307132085166

Epoch: 6| Step: 4
Training loss: 1.2970597743988037
Validation loss: 2.016226271788279

Epoch: 6| Step: 5
Training loss: 0.43468013405799866
Validation loss: 2.0045143564542136

Epoch: 6| Step: 6
Training loss: 0.5577938556671143
Validation loss: 1.9454353253046672

Epoch: 6| Step: 7
Training loss: 0.9154523611068726
Validation loss: 2.038152754306793

Epoch: 6| Step: 8
Training loss: 0.5520679950714111
Validation loss: 2.013085345427195

Epoch: 6| Step: 9
Training loss: 0.38459041714668274
Validation loss: 2.013576626777649

Epoch: 6| Step: 10
Training loss: 1.0289181470870972
Validation loss: 2.0420557260513306

Epoch: 6| Step: 11
Training loss: 0.2990153431892395
Validation loss: 2.023300886154175

Epoch: 6| Step: 12
Training loss: 0.8112738132476807
Validation loss: 2.0149958729743958

Epoch: 6| Step: 13
Training loss: 0.34396564960479736
Validation loss: 2.0173330108324685

Epoch: 482| Step: 0
Training loss: 0.46619686484336853
Validation loss: 2.0196672479311624

Epoch: 6| Step: 1
Training loss: 0.6795335412025452
Validation loss: 2.043474872907003

Epoch: 6| Step: 2
Training loss: 0.5937402248382568
Validation loss: 2.029132684071859

Epoch: 6| Step: 3
Training loss: 1.0610265731811523
Validation loss: 1.9991989533106487

Epoch: 6| Step: 4
Training loss: 0.7715190649032593
Validation loss: 2.05337925752004

Epoch: 6| Step: 5
Training loss: 0.32370537519454956
Validation loss: 1.9947317242622375

Epoch: 6| Step: 6
Training loss: 0.7163563370704651
Validation loss: 2.0275634129842124

Epoch: 6| Step: 7
Training loss: 0.544869065284729
Validation loss: 1.9852806528409321

Epoch: 6| Step: 8
Training loss: 1.112067461013794
Validation loss: 1.9951926072438557

Epoch: 6| Step: 9
Training loss: 0.5267348289489746
Validation loss: 2.0123273531595864

Epoch: 6| Step: 10
Training loss: 0.37265610694885254
Validation loss: 2.0094465613365173

Epoch: 6| Step: 11
Training loss: 0.5246313810348511
Validation loss: 1.9819356799125671

Epoch: 6| Step: 12
Training loss: 1.2426947355270386
Validation loss: 1.9931286970774333

Epoch: 6| Step: 13
Training loss: 0.7438313961029053
Validation loss: 1.986857791741689

Epoch: 483| Step: 0
Training loss: 0.7941150069236755
Validation loss: 1.9984303712844849

Epoch: 6| Step: 1
Training loss: 0.3934245705604553
Validation loss: 2.0468969146410623

Epoch: 6| Step: 2
Training loss: 0.440507173538208
Validation loss: 2.0256031155586243

Epoch: 6| Step: 3
Training loss: 0.2590518593788147
Validation loss: 2.03779000043869

Epoch: 6| Step: 4
Training loss: 0.7401676177978516
Validation loss: 2.006179392337799

Epoch: 6| Step: 5
Training loss: 0.6683034896850586
Validation loss: 2.0305150747299194

Epoch: 6| Step: 6
Training loss: 0.6848523616790771
Validation loss: 2.0530815521876016

Epoch: 6| Step: 7
Training loss: 1.1450109481811523
Validation loss: 2.0308550000190735

Epoch: 6| Step: 8
Training loss: 0.9668024182319641
Validation loss: 2.015409608681997

Epoch: 6| Step: 9
Training loss: 0.904675304889679
Validation loss: 2.0137892365455627

Epoch: 6| Step: 10
Training loss: 0.45789164304733276
Validation loss: 2.0252663294474282

Epoch: 6| Step: 11
Training loss: 0.8701803684234619
Validation loss: 2.007754604021708

Epoch: 6| Step: 12
Training loss: 0.6903870701789856
Validation loss: 1.9957424600919087

Epoch: 6| Step: 13
Training loss: 0.7411781549453735
Validation loss: 1.9849382837613423

Epoch: 484| Step: 0
Training loss: 1.1120729446411133
Validation loss: 1.9853909413019817

Epoch: 6| Step: 1
Training loss: 0.5583097338676453
Validation loss: 2.0275434851646423

Epoch: 6| Step: 2
Training loss: 0.5478643774986267
Validation loss: 2.0440658728281655

Epoch: 6| Step: 3
Training loss: 0.46731850504875183
Validation loss: 2.0332372188568115

Epoch: 6| Step: 4
Training loss: 0.3261508345603943
Validation loss: 2.0477936466534934

Epoch: 6| Step: 5
Training loss: 1.1215119361877441
Validation loss: 2.0664455691973367

Epoch: 6| Step: 6
Training loss: 1.1548454761505127
Validation loss: 2.0777291655540466

Epoch: 6| Step: 7
Training loss: 0.36622339487075806
Validation loss: 2.070264220237732

Epoch: 6| Step: 8
Training loss: 1.001812219619751
Validation loss: 2.0844746033350625

Epoch: 6| Step: 9
Training loss: 0.3126155734062195
Validation loss: 2.0268286863962808

Epoch: 6| Step: 10
Training loss: 1.6080855131149292
Validation loss: 2.030394693215688

Epoch: 6| Step: 11
Training loss: 0.4104224741458893
Validation loss: 2.0278454224268594

Epoch: 6| Step: 12
Training loss: 0.3507007956504822
Validation loss: 2.0192585388819375

Epoch: 6| Step: 13
Training loss: 0.7233284711837769
Validation loss: 1.9954862395922344

Epoch: 485| Step: 0
Training loss: 2.0390267372131348
Validation loss: 2.0147505601247153

Epoch: 6| Step: 1
Training loss: 0.4528365433216095
Validation loss: 2.018438537915548

Epoch: 6| Step: 2
Training loss: 0.5627803802490234
Validation loss: 1.9896113276481628

Epoch: 6| Step: 3
Training loss: 0.7580017447471619
Validation loss: 2.050048033396403

Epoch: 6| Step: 4
Training loss: 0.42244964838027954
Validation loss: 1.9930833578109741

Epoch: 6| Step: 5
Training loss: 0.656869649887085
Validation loss: 2.033252696196238

Epoch: 6| Step: 6
Training loss: 0.9378470778465271
Validation loss: 1.991429090499878

Epoch: 6| Step: 7
Training loss: 0.41058188676834106
Validation loss: 2.0442441503206887

Epoch: 6| Step: 8
Training loss: 0.6325110197067261
Validation loss: 1.9955947399139404

Epoch: 6| Step: 9
Training loss: 0.5450026988983154
Validation loss: 2.0377450386683145

Epoch: 6| Step: 10
Training loss: 0.506792426109314
Validation loss: 2.0266520380973816

Epoch: 6| Step: 11
Training loss: 0.7879762053489685
Validation loss: 2.0055776238441467

Epoch: 6| Step: 12
Training loss: 0.8389356136322021
Validation loss: 2.0250178972880044

Epoch: 6| Step: 13
Training loss: 0.7248075008392334
Validation loss: 1.9698369701703389

Epoch: 486| Step: 0
Training loss: 0.4890645146369934
Validation loss: 1.9813961187998455

Epoch: 6| Step: 1
Training loss: 0.41621777415275574
Validation loss: 1.9293423096338909

Epoch: 6| Step: 2
Training loss: 0.6204916834831238
Validation loss: 1.961741050084432

Epoch: 6| Step: 3
Training loss: 0.32111483812332153
Validation loss: 2.015516936779022

Epoch: 6| Step: 4
Training loss: 1.5880823135375977
Validation loss: 1.954011599222819

Epoch: 6| Step: 5
Training loss: 0.8299622535705566
Validation loss: 1.9437566200892131

Epoch: 6| Step: 6
Training loss: 0.787083625793457
Validation loss: 1.961710552374522

Epoch: 6| Step: 7
Training loss: 1.4083127975463867
Validation loss: 1.9527564644813538

Epoch: 6| Step: 8
Training loss: 0.5246496796607971
Validation loss: 1.9462541143099468

Epoch: 6| Step: 9
Training loss: 0.5948059558868408
Validation loss: 1.9762200713157654

Epoch: 6| Step: 10
Training loss: 0.4247357249259949
Validation loss: 1.952147622903188

Epoch: 6| Step: 11
Training loss: 0.4688566029071808
Validation loss: 1.931290328502655

Epoch: 6| Step: 12
Training loss: 0.7405070066452026
Validation loss: 1.9607055187225342

Epoch: 6| Step: 13
Training loss: 0.7615551352500916
Validation loss: 1.9422731796900432

Epoch: 487| Step: 0
Training loss: 0.3618031442165375
Validation loss: 1.944084922472636

Epoch: 6| Step: 1
Training loss: 0.4258285164833069
Validation loss: 1.973835051059723

Epoch: 6| Step: 2
Training loss: 1.566054344177246
Validation loss: 2.028440614541372

Epoch: 6| Step: 3
Training loss: 0.6333060264587402
Validation loss: 2.0214813152949014

Epoch: 6| Step: 4
Training loss: 0.7098993062973022
Validation loss: 1.9968030452728271

Epoch: 6| Step: 5
Training loss: 0.2856612205505371
Validation loss: 1.9434132774670918

Epoch: 6| Step: 6
Training loss: 0.8063098192214966
Validation loss: 1.9488732814788818

Epoch: 6| Step: 7
Training loss: 0.4826531410217285
Validation loss: 1.9780031442642212

Epoch: 6| Step: 8
Training loss: 0.5257710218429565
Validation loss: 2.0314943393071494

Epoch: 6| Step: 9
Training loss: 0.6745333671569824
Validation loss: 1.9789995749791462

Epoch: 6| Step: 10
Training loss: 0.9724721908569336
Validation loss: 1.9616075952847798

Epoch: 6| Step: 11
Training loss: 0.5500357151031494
Validation loss: 2.018811345100403

Epoch: 6| Step: 12
Training loss: 0.8013626337051392
Validation loss: 1.9638570547103882

Epoch: 6| Step: 13
Training loss: 0.6539170742034912
Validation loss: 1.9977827072143555

Epoch: 488| Step: 0
Training loss: 0.7410042881965637
Validation loss: 2.0052263339360556

Epoch: 6| Step: 1
Training loss: 0.30157214403152466
Validation loss: 2.0480313698450723

Epoch: 6| Step: 2
Training loss: 0.9422564506530762
Validation loss: 2.023267944653829

Epoch: 6| Step: 3
Training loss: 0.8949143886566162
Validation loss: 2.036894162495931

Epoch: 6| Step: 4
Training loss: 1.254233479499817
Validation loss: 2.0074644883473716

Epoch: 6| Step: 5
Training loss: 0.24057775735855103
Validation loss: 1.9777637322743733

Epoch: 6| Step: 6
Training loss: 0.5720796585083008
Validation loss: 1.9833154082298279

Epoch: 6| Step: 7
Training loss: 0.9997578263282776
Validation loss: 1.9518330097198486

Epoch: 6| Step: 8
Training loss: 0.42271310091018677
Validation loss: 1.9523102442423503

Epoch: 6| Step: 9
Training loss: 0.8329218029975891
Validation loss: 1.9091113408406575

Epoch: 6| Step: 10
Training loss: 0.6416003108024597
Validation loss: 1.9650426308314006

Epoch: 6| Step: 11
Training loss: 0.5625841617584229
Validation loss: 1.9364251295725505

Epoch: 6| Step: 12
Training loss: 0.696022629737854
Validation loss: 1.9324584404627483

Epoch: 6| Step: 13
Training loss: 1.0141873359680176
Validation loss: 1.9644396503766377

Epoch: 489| Step: 0
Training loss: 0.6814079284667969
Validation loss: 1.9188361763954163

Epoch: 6| Step: 1
Training loss: 0.6767431497573853
Validation loss: 1.9803619782129924

Epoch: 6| Step: 2
Training loss: 0.619297444820404
Validation loss: 1.9969111680984497

Epoch: 6| Step: 3
Training loss: 0.27902501821517944
Validation loss: 1.9931105176607768

Epoch: 6| Step: 4
Training loss: 0.5383269786834717
Validation loss: 1.9565946062405903

Epoch: 6| Step: 5
Training loss: 0.3718858063220978
Validation loss: 1.9936947226524353

Epoch: 6| Step: 6
Training loss: 0.3386614918708801
Validation loss: 1.9286783536275227

Epoch: 6| Step: 7
Training loss: 1.9260584115982056
Validation loss: 1.9635697603225708

Epoch: 6| Step: 8
Training loss: 0.6202691197395325
Validation loss: 1.9311249454816182

Epoch: 6| Step: 9
Training loss: 0.41167500615119934
Validation loss: 1.9612844586372375

Epoch: 6| Step: 10
Training loss: 1.041893720626831
Validation loss: 1.9554001688957214

Epoch: 6| Step: 11
Training loss: 0.3514639139175415
Validation loss: 1.9112541476885478

Epoch: 6| Step: 12
Training loss: 0.47057440876960754
Validation loss: 1.9402963916460674

Epoch: 6| Step: 13
Training loss: 1.2492811679840088
Validation loss: 1.9738638003667195

Epoch: 490| Step: 0
Training loss: 0.8525744676589966
Validation loss: 2.0290602246920266

Epoch: 6| Step: 1
Training loss: 0.7912187576293945
Validation loss: 2.0412633617719016

Epoch: 6| Step: 2
Training loss: 0.18792080879211426
Validation loss: 2.0073496103286743

Epoch: 6| Step: 3
Training loss: 1.1530365943908691
Validation loss: 1.9999337196350098

Epoch: 6| Step: 4
Training loss: 1.3204532861709595
Validation loss: 1.9987323880195618

Epoch: 6| Step: 5
Training loss: 0.36470794677734375
Validation loss: 1.9957054058710735

Epoch: 6| Step: 6
Training loss: 0.42920660972595215
Validation loss: 2.026897748311361

Epoch: 6| Step: 7
Training loss: 0.33795714378356934
Validation loss: 1.9890324076016743

Epoch: 6| Step: 8
Training loss: 0.6068907380104065
Validation loss: 2.0272881984710693

Epoch: 6| Step: 9
Training loss: 0.33610427379608154
Validation loss: 2.001986344655355

Epoch: 6| Step: 10
Training loss: 1.0724875926971436
Validation loss: 2.0431726773579917

Epoch: 6| Step: 11
Training loss: 0.8002177476882935
Validation loss: 2.0326767365137735

Epoch: 6| Step: 12
Training loss: 0.38804230093955994
Validation loss: 2.019218941529592

Epoch: 6| Step: 13
Training loss: 0.5880318880081177
Validation loss: 2.0084975163141885

Epoch: 491| Step: 0
Training loss: 0.5142492055892944
Validation loss: 1.9628857572873433

Epoch: 6| Step: 1
Training loss: 0.822300374507904
Validation loss: 2.0658482909202576

Epoch: 6| Step: 2
Training loss: 0.2779295742511749
Validation loss: 2.033748507499695

Epoch: 6| Step: 3
Training loss: 0.777938723564148
Validation loss: 2.0076970060666404

Epoch: 6| Step: 4
Training loss: 0.3005652129650116
Validation loss: 2.03145968914032

Epoch: 6| Step: 5
Training loss: 1.1525373458862305
Validation loss: 2.045920968055725

Epoch: 6| Step: 6
Training loss: 0.7218096256256104
Validation loss: 2.0461437900861106

Epoch: 6| Step: 7
Training loss: 0.4222368896007538
Validation loss: 2.0100053747495017

Epoch: 6| Step: 8
Training loss: 1.1923496723175049
Validation loss: 1.9671174883842468

Epoch: 6| Step: 9
Training loss: 0.5323830842971802
Validation loss: 1.9785997867584229

Epoch: 6| Step: 10
Training loss: 0.484396368265152
Validation loss: 2.005931258201599

Epoch: 6| Step: 11
Training loss: 0.6638724207878113
Validation loss: 1.9910462101300557

Epoch: 6| Step: 12
Training loss: 0.9531370401382446
Validation loss: 1.9647454222043355

Epoch: 6| Step: 13
Training loss: 0.3269047141075134
Validation loss: 1.9980588754018147

Epoch: 492| Step: 0
Training loss: 0.22862479090690613
Validation loss: 1.9895058472951253

Epoch: 6| Step: 1
Training loss: 0.44430768489837646
Validation loss: 1.98898841937383

Epoch: 6| Step: 2
Training loss: 0.5714949369430542
Validation loss: 1.9775153398513794

Epoch: 6| Step: 3
Training loss: 0.7674509286880493
Validation loss: 1.9750958879788716

Epoch: 6| Step: 4
Training loss: 0.6811349391937256
Validation loss: 1.95505952835083

Epoch: 6| Step: 5
Training loss: 0.5072669982910156
Validation loss: 1.9325702985127766

Epoch: 6| Step: 6
Training loss: 0.5390229225158691
Validation loss: 1.9661834041277568

Epoch: 6| Step: 7
Training loss: 0.7900623083114624
Validation loss: 2.0113741159439087

Epoch: 6| Step: 8
Training loss: 0.839911699295044
Validation loss: 1.9865913391113281

Epoch: 6| Step: 9
Training loss: 0.5848002433776855
Validation loss: 2.0041205286979675

Epoch: 6| Step: 10
Training loss: 1.7490020990371704
Validation loss: 2.0097932616869607

Epoch: 6| Step: 11
Training loss: 0.3092595338821411
Validation loss: 2.005500912666321

Epoch: 6| Step: 12
Training loss: 0.5140153169631958
Validation loss: 1.9750130375226338

Epoch: 6| Step: 13
Training loss: 0.8726751804351807
Validation loss: 1.9974158604939778

Epoch: 493| Step: 0
Training loss: 0.3285529315471649
Validation loss: 2.008978029092153

Epoch: 6| Step: 1
Training loss: 0.7641195058822632
Validation loss: 2.0414075454076133

Epoch: 6| Step: 2
Training loss: 0.6395931243896484
Validation loss: 2.039210100968679

Epoch: 6| Step: 3
Training loss: 0.5636118650436401
Validation loss: 2.0260713497797647

Epoch: 6| Step: 4
Training loss: 0.2894900143146515
Validation loss: 1.9748214483261108

Epoch: 6| Step: 5
Training loss: 0.8353764414787292
Validation loss: 1.9732732971509297

Epoch: 6| Step: 6
Training loss: 1.193532943725586
Validation loss: 2.000990569591522

Epoch: 6| Step: 7
Training loss: 0.5960145592689514
Validation loss: 2.014119327068329

Epoch: 6| Step: 8
Training loss: 0.7110486626625061
Validation loss: 1.9616814653078716

Epoch: 6| Step: 9
Training loss: 0.7000522017478943
Validation loss: 1.9736413757006328

Epoch: 6| Step: 10
Training loss: 0.8257759213447571
Validation loss: 2.04632298151652

Epoch: 6| Step: 11
Training loss: 0.32498738169670105
Validation loss: 1.9664790232976277

Epoch: 6| Step: 12
Training loss: 0.6991880536079407
Validation loss: 2.0196996927261353

Epoch: 6| Step: 13
Training loss: 0.7490957975387573
Validation loss: 1.9764083623886108

Epoch: 494| Step: 0
Training loss: 0.9182311296463013
Validation loss: 2.0004440744717917

Epoch: 6| Step: 1
Training loss: 0.5080914497375488
Validation loss: 1.9997358719507854

Epoch: 6| Step: 2
Training loss: 1.0223572254180908
Validation loss: 1.9705100059509277

Epoch: 6| Step: 3
Training loss: 0.7837808728218079
Validation loss: 1.9306831161181133

Epoch: 6| Step: 4
Training loss: 0.3285733163356781
Validation loss: 2.0219464898109436

Epoch: 6| Step: 5
Training loss: 0.5062378644943237
Validation loss: 1.964558442433675

Epoch: 6| Step: 6
Training loss: 0.16058850288391113
Validation loss: 1.9618938167889912

Epoch: 6| Step: 7
Training loss: 0.8495528101921082
Validation loss: 1.9847126205762227

Epoch: 6| Step: 8
Training loss: 0.7923294901847839
Validation loss: 1.9862503210703533

Epoch: 6| Step: 9
Training loss: 0.2486094832420349
Validation loss: 1.9347133040428162

Epoch: 6| Step: 10
Training loss: 0.5224652290344238
Validation loss: 2.017755369345347

Epoch: 6| Step: 11
Training loss: 0.6321067810058594
Validation loss: 1.8962319095929463

Epoch: 6| Step: 12
Training loss: 1.1155297756195068
Validation loss: 1.9707958698272705

Epoch: 6| Step: 13
Training loss: 0.6310625076293945
Validation loss: 1.984476387500763

Epoch: 495| Step: 0
Training loss: 0.8647722005844116
Validation loss: 1.9936542113622029

Epoch: 6| Step: 1
Training loss: 0.37397515773773193
Validation loss: 1.950593372186025

Epoch: 6| Step: 2
Training loss: 0.6538392305374146
Validation loss: 1.9814121723175049

Epoch: 6| Step: 3
Training loss: 0.44782114028930664
Validation loss: 1.9870097041130066

Epoch: 6| Step: 4
Training loss: 0.7228113412857056
Validation loss: 2.040589233239492

Epoch: 6| Step: 5
Training loss: 0.38839513063430786
Validation loss: 2.0235002636909485

Epoch: 6| Step: 6
Training loss: 0.7584837675094604
Validation loss: 1.9951646327972412

Epoch: 6| Step: 7
Training loss: 0.34408432245254517
Validation loss: 1.9773812890052795

Epoch: 6| Step: 8
Training loss: 0.8130536079406738
Validation loss: 1.9741296172142029

Epoch: 6| Step: 9
Training loss: 0.8240394592285156
Validation loss: 1.967584987481435

Epoch: 6| Step: 10
Training loss: 0.40748652815818787
Validation loss: 1.9995352824529011

Epoch: 6| Step: 11
Training loss: 1.2132573127746582
Validation loss: 1.9459611972173054

Epoch: 6| Step: 12
Training loss: 0.49394476413726807
Validation loss: 1.939408044020335

Epoch: 6| Step: 13
Training loss: 0.8099371790885925
Validation loss: 1.964771290620168

Epoch: 496| Step: 0
Training loss: 0.5098649263381958
Validation loss: 2.0184127489725747

Epoch: 6| Step: 1
Training loss: 0.48760056495666504
Validation loss: 1.9968820412953694

Epoch: 6| Step: 2
Training loss: 0.34246721863746643
Validation loss: 2.0167860190073648

Epoch: 6| Step: 3
Training loss: 0.6657018661499023
Validation loss: 1.9882653156916301

Epoch: 6| Step: 4
Training loss: 0.6911324262619019
Validation loss: 1.9659673968950908

Epoch: 6| Step: 5
Training loss: 0.34154778718948364
Validation loss: 1.9292157491048176

Epoch: 6| Step: 6
Training loss: 0.7286343574523926
Validation loss: 2.0159144202868142

Epoch: 6| Step: 7
Training loss: 0.5920032858848572
Validation loss: 1.9895050923029582

Epoch: 6| Step: 8
Training loss: 1.2661066055297852
Validation loss: 1.9813154935836792

Epoch: 6| Step: 9
Training loss: 1.1978551149368286
Validation loss: 2.011057694753011

Epoch: 6| Step: 10
Training loss: 0.3190203011035919
Validation loss: 2.001932680606842

Epoch: 6| Step: 11
Training loss: 0.4808480143547058
Validation loss: 1.965581218401591

Epoch: 6| Step: 12
Training loss: 0.8731958270072937
Validation loss: 2.0158429940541587

Epoch: 6| Step: 13
Training loss: 0.673511266708374
Validation loss: 2.0335877537727356

Epoch: 497| Step: 0
Training loss: 0.3896257281303406
Validation loss: 2.0694828033447266

Epoch: 6| Step: 1
Training loss: 0.5844860672950745
Validation loss: 2.0068352023760476

Epoch: 6| Step: 2
Training loss: 0.5222580432891846
Validation loss: 2.0430376132329306

Epoch: 6| Step: 3
Training loss: 0.3347170352935791
Validation loss: 2.0246591567993164

Epoch: 6| Step: 4
Training loss: 0.9045521020889282
Validation loss: 1.9832367499669392

Epoch: 6| Step: 5
Training loss: 0.684444785118103
Validation loss: 1.9707236687342327

Epoch: 6| Step: 6
Training loss: 0.6860088109970093
Validation loss: 2.0059452056884766

Epoch: 6| Step: 7
Training loss: 0.8840764760971069
Validation loss: 1.9873359203338623

Epoch: 6| Step: 8
Training loss: 1.229987382888794
Validation loss: 1.9889839092890422

Epoch: 6| Step: 9
Training loss: 0.4393654465675354
Validation loss: 2.0318161249160767

Epoch: 6| Step: 10
Training loss: 0.6320022344589233
Validation loss: 2.023565491040548

Epoch: 6| Step: 11
Training loss: 0.4433997869491577
Validation loss: 2.0396028558413186

Epoch: 6| Step: 12
Training loss: 0.6731329560279846
Validation loss: 2.0064553022384644

Epoch: 6| Step: 13
Training loss: 0.8385869860649109
Validation loss: 1.973086675008138

Epoch: 498| Step: 0
Training loss: 0.31384313106536865
Validation loss: 2.0034378369649253

Epoch: 6| Step: 1
Training loss: 1.1071453094482422
Validation loss: 2.0138099193573

Epoch: 6| Step: 2
Training loss: 0.3381795883178711
Validation loss: 2.031117041905721

Epoch: 6| Step: 3
Training loss: 0.7149815559387207
Validation loss: 2.0358535647392273

Epoch: 6| Step: 4
Training loss: 0.6461808681488037
Validation loss: 2.005791405836741

Epoch: 6| Step: 5
Training loss: 1.0833659172058105
Validation loss: 2.03974711894989

Epoch: 6| Step: 6
Training loss: 0.4511532187461853
Validation loss: 2.0539426803588867

Epoch: 6| Step: 7
Training loss: 1.068649411201477
Validation loss: 1.9733263651529949

Epoch: 6| Step: 8
Training loss: 0.6025919914245605
Validation loss: 1.9747339884440105

Epoch: 6| Step: 9
Training loss: 1.0494906902313232
Validation loss: 2.004041393597921

Epoch: 6| Step: 10
Training loss: 0.8454924821853638
Validation loss: 1.9691880544026692

Epoch: 6| Step: 11
Training loss: 0.4753932058811188
Validation loss: 1.9794220328330994

Epoch: 6| Step: 12
Training loss: 0.2947113811969757
Validation loss: 1.9518397251764934

Epoch: 6| Step: 13
Training loss: 0.4871205687522888
Validation loss: 2.0023107727368674

Epoch: 499| Step: 0
Training loss: 0.5446337461471558
Validation loss: 2.0164586106936135

Epoch: 6| Step: 1
Training loss: 0.32347092032432556
Validation loss: 1.9257063269615173

Epoch: 6| Step: 2
Training loss: 0.3254678249359131
Validation loss: 1.9706907073656719

Epoch: 6| Step: 3
Training loss: 0.7180272340774536
Validation loss: 1.9864134589831035

Epoch: 6| Step: 4
Training loss: 0.3569009304046631
Validation loss: 1.9615817666053772

Epoch: 6| Step: 5
Training loss: 1.2851781845092773
Validation loss: 2.0130176345507302

Epoch: 6| Step: 6
Training loss: 0.40984368324279785
Validation loss: 2.015787661075592

Epoch: 6| Step: 7
Training loss: 1.5146410465240479
Validation loss: 1.9923656582832336

Epoch: 6| Step: 8
Training loss: 1.0571547746658325
Validation loss: 1.9849092364311218

Epoch: 6| Step: 9
Training loss: 0.38033586740493774
Validation loss: 1.9770150184631348

Epoch: 6| Step: 10
Training loss: 0.30779463052749634
Validation loss: 2.0297726591428122

Epoch: 6| Step: 11
Training loss: 0.6500841379165649
Validation loss: 2.0483662684758506

Epoch: 6| Step: 12
Training loss: 0.7294076085090637
Validation loss: 1.998916486899058

Epoch: 6| Step: 13
Training loss: 0.880810022354126
Validation loss: 2.0009071628252664

Epoch: 500| Step: 0
Training loss: 0.24870958924293518
Validation loss: 1.981803297996521

Epoch: 6| Step: 1
Training loss: 0.803320586681366
Validation loss: 1.9990179141362507

Epoch: 6| Step: 2
Training loss: 0.7055740356445312
Validation loss: 1.9484064380327861

Epoch: 6| Step: 3
Training loss: 0.6906819939613342
Validation loss: 1.976331094900767

Epoch: 6| Step: 4
Training loss: 0.17032495141029358
Validation loss: 1.998962640762329

Epoch: 6| Step: 5
Training loss: 0.38914692401885986
Validation loss: 2.0041675368944802

Epoch: 6| Step: 6
Training loss: 0.536950945854187
Validation loss: 1.9555123249689739

Epoch: 6| Step: 7
Training loss: 0.9475628733634949
Validation loss: 1.962894121805827

Epoch: 6| Step: 8
Training loss: 0.3907535672187805
Validation loss: 1.988508979479472

Epoch: 6| Step: 9
Training loss: 0.5638556480407715
Validation loss: 1.9921202262242634

Epoch: 6| Step: 10
Training loss: 0.8628730773925781
Validation loss: 2.01665993531545

Epoch: 6| Step: 11
Training loss: 1.240756630897522
Validation loss: 2.0155474742253623

Epoch: 6| Step: 12
Training loss: 0.5478755831718445
Validation loss: 2.0300578077634177

Epoch: 6| Step: 13
Training loss: 1.0512688159942627
Validation loss: 2.047406474749247

Testing loss: 2.0242341919768627
