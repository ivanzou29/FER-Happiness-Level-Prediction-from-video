Epoch: 1| Step: 0
Training loss: 5.998365879058838
Validation loss: 5.266124725341797

Epoch: 6| Step: 1
Training loss: 5.327574729919434
Validation loss: 5.263926982879639

Epoch: 6| Step: 2
Training loss: 5.981320858001709
Validation loss: 5.261738618214925

Epoch: 6| Step: 3
Training loss: 5.398399829864502
Validation loss: 5.259750525156657

Epoch: 6| Step: 4
Training loss: 4.833968639373779
Validation loss: 5.257696072260539

Epoch: 6| Step: 5
Training loss: 4.919767379760742
Validation loss: 5.255643765131633

Epoch: 6| Step: 6
Training loss: 5.441183567047119
Validation loss: 5.253554741541545

Epoch: 6| Step: 7
Training loss: 5.794553756713867
Validation loss: 5.251433610916138

Epoch: 6| Step: 8
Training loss: 5.176111221313477
Validation loss: 5.2493345737457275

Epoch: 6| Step: 9
Training loss: 5.803187370300293
Validation loss: 5.247071027755737

Epoch: 6| Step: 10
Training loss: 5.9408674240112305
Validation loss: 5.244687954584758

Epoch: 6| Step: 11
Training loss: 3.8272557258605957
Validation loss: 5.242320855458577

Epoch: 6| Step: 12
Training loss: 5.022296905517578
Validation loss: 5.239834785461426

Epoch: 6| Step: 13
Training loss: 5.040451526641846
Validation loss: 5.237313429514567

Epoch: 2| Step: 0
Training loss: 5.972272872924805
Validation loss: 5.234638770421346

Epoch: 6| Step: 1
Training loss: 5.385765075683594
Validation loss: 5.231956799825032

Epoch: 6| Step: 2
Training loss: 5.22274112701416
Validation loss: 5.228917519251506

Epoch: 6| Step: 3
Training loss: 4.731077194213867
Validation loss: 5.226029396057129

Epoch: 6| Step: 4
Training loss: 5.4714226722717285
Validation loss: 5.222915331522624

Epoch: 6| Step: 5
Training loss: 5.7820844650268555
Validation loss: 5.2195877234141035

Epoch: 6| Step: 6
Training loss: 5.1701812744140625
Validation loss: 5.21614933013916

Epoch: 6| Step: 7
Training loss: 5.755041122436523
Validation loss: 5.212587753931682

Epoch: 6| Step: 8
Training loss: 4.765529155731201
Validation loss: 5.2088948885599775

Epoch: 6| Step: 9
Training loss: 5.69556999206543
Validation loss: 5.2049949169158936

Epoch: 6| Step: 10
Training loss: 5.064571857452393
Validation loss: 5.200784921646118

Epoch: 6| Step: 11
Training loss: 5.7716779708862305
Validation loss: 5.196507056554158

Epoch: 6| Step: 12
Training loss: 4.2124505043029785
Validation loss: 5.19211729367574

Epoch: 6| Step: 13
Training loss: 4.955766201019287
Validation loss: 5.187209765116374

Epoch: 3| Step: 0
Training loss: 4.107123374938965
Validation loss: 5.182187954584758

Epoch: 6| Step: 1
Training loss: 5.589051723480225
Validation loss: 5.177131573359172

Epoch: 6| Step: 2
Training loss: 6.098206996917725
Validation loss: 5.171440760294597

Epoch: 6| Step: 3
Training loss: 5.361246109008789
Validation loss: 5.165788650512695

Epoch: 6| Step: 4
Training loss: 6.131396770477295
Validation loss: 5.15998101234436

Epoch: 6| Step: 5
Training loss: 5.553938865661621
Validation loss: 5.153810421625773

Epoch: 6| Step: 6
Training loss: 4.407042980194092
Validation loss: 5.1472682158152265

Epoch: 6| Step: 7
Training loss: 5.614664077758789
Validation loss: 5.140758752822876

Epoch: 6| Step: 8
Training loss: 5.744197368621826
Validation loss: 5.133717775344849

Epoch: 6| Step: 9
Training loss: 5.62775993347168
Validation loss: 5.126312096913655

Epoch: 6| Step: 10
Training loss: 4.246427536010742
Validation loss: 5.119240919748942

Epoch: 6| Step: 11
Training loss: 4.206442356109619
Validation loss: 5.11147665977478

Epoch: 6| Step: 12
Training loss: 4.848977565765381
Validation loss: 5.103620847066243

Epoch: 6| Step: 13
Training loss: 5.464179992675781
Validation loss: 5.095518747965495

Epoch: 4| Step: 0
Training loss: 5.448930740356445
Validation loss: 5.087173859278361

Epoch: 6| Step: 1
Training loss: 4.767449378967285
Validation loss: 5.07878851890564

Epoch: 6| Step: 2
Training loss: 4.899130821228027
Validation loss: 5.070011615753174

Epoch: 6| Step: 3
Training loss: 4.546588897705078
Validation loss: 5.060851573944092

Epoch: 6| Step: 4
Training loss: 4.874922752380371
Validation loss: 5.052107731501262

Epoch: 6| Step: 5
Training loss: 5.31010103225708
Validation loss: 5.042538404464722

Epoch: 6| Step: 6
Training loss: 4.866756916046143
Validation loss: 5.03343939781189

Epoch: 6| Step: 7
Training loss: 4.398096084594727
Validation loss: 5.023785948753357

Epoch: 6| Step: 8
Training loss: 4.362198829650879
Validation loss: 5.013903220494588

Epoch: 6| Step: 9
Training loss: 6.466071128845215
Validation loss: 5.003905137379964

Epoch: 6| Step: 10
Training loss: 4.6014604568481445
Validation loss: 4.994050979614258

Epoch: 6| Step: 11
Training loss: 5.827139377593994
Validation loss: 4.983350356419881

Epoch: 6| Step: 12
Training loss: 5.421511650085449
Validation loss: 4.97252345085144

Epoch: 6| Step: 13
Training loss: 5.674059867858887
Validation loss: 4.961682717005412

Epoch: 5| Step: 0
Training loss: 4.581840991973877
Validation loss: 4.950450579325358

Epoch: 6| Step: 1
Training loss: 3.8756227493286133
Validation loss: 4.939430475234985

Epoch: 6| Step: 2
Training loss: 5.701089382171631
Validation loss: 4.9284060796101885

Epoch: 6| Step: 3
Training loss: 5.781152725219727
Validation loss: 4.916690667470296

Epoch: 6| Step: 4
Training loss: 4.209489822387695
Validation loss: 4.90565037727356

Epoch: 6| Step: 5
Training loss: 5.483368873596191
Validation loss: 4.894493619600932

Epoch: 6| Step: 6
Training loss: 5.2668070793151855
Validation loss: 4.8832874695460005

Epoch: 6| Step: 7
Training loss: 4.9360432624816895
Validation loss: 4.872280677159627

Epoch: 6| Step: 8
Training loss: 3.7223973274230957
Validation loss: 4.861611286799113

Epoch: 6| Step: 9
Training loss: 4.685471057891846
Validation loss: 4.8510667483011884

Epoch: 6| Step: 10
Training loss: 5.225714683532715
Validation loss: 4.840741475423177

Epoch: 6| Step: 11
Training loss: 5.404009819030762
Validation loss: 4.82993745803833

Epoch: 6| Step: 12
Training loss: 5.201029300689697
Validation loss: 4.820080200831096

Epoch: 6| Step: 13
Training loss: 5.430043697357178
Validation loss: 4.81036901473999

Epoch: 6| Step: 0
Training loss: 4.088125228881836
Validation loss: 4.800807873408

Epoch: 6| Step: 1
Training loss: 6.229752540588379
Validation loss: 4.791081031163533

Epoch: 6| Step: 2
Training loss: 4.133579254150391
Validation loss: 4.781423886617024

Epoch: 6| Step: 3
Training loss: 6.0145769119262695
Validation loss: 4.771880149841309

Epoch: 6| Step: 4
Training loss: 3.950514316558838
Validation loss: 4.762728850046794

Epoch: 6| Step: 5
Training loss: 5.362003326416016
Validation loss: 4.753487189610799

Epoch: 6| Step: 6
Training loss: 4.854340553283691
Validation loss: 4.744311968485515

Epoch: 6| Step: 7
Training loss: 4.16535758972168
Validation loss: 4.734973510106404

Epoch: 6| Step: 8
Training loss: 3.99308443069458
Validation loss: 4.725864251454671

Epoch: 6| Step: 9
Training loss: 5.425519943237305
Validation loss: 4.716770092646281

Epoch: 6| Step: 10
Training loss: 5.327789783477783
Validation loss: 4.707066694895427

Epoch: 6| Step: 11
Training loss: 4.583498954772949
Validation loss: 4.697543541590373

Epoch: 6| Step: 12
Training loss: 4.948733329772949
Validation loss: 4.688157320022583

Epoch: 6| Step: 13
Training loss: 4.550683498382568
Validation loss: 4.678968588511149

Epoch: 7| Step: 0
Training loss: 5.213388442993164
Validation loss: 4.669496854146321

Epoch: 6| Step: 1
Training loss: 4.083460807800293
Validation loss: 4.660056471824646

Epoch: 6| Step: 2
Training loss: 5.177068710327148
Validation loss: 4.651121616363525

Epoch: 6| Step: 3
Training loss: 5.121259689331055
Validation loss: 4.641752441724141

Epoch: 6| Step: 4
Training loss: 3.9148566722869873
Validation loss: 4.632503906885783

Epoch: 6| Step: 5
Training loss: 4.988456726074219
Validation loss: 4.623581171035767

Epoch: 6| Step: 6
Training loss: 4.470392227172852
Validation loss: 4.614552974700928

Epoch: 6| Step: 7
Training loss: 5.432156085968018
Validation loss: 4.605647325515747

Epoch: 6| Step: 8
Training loss: 4.87015438079834
Validation loss: 4.596041599909465

Epoch: 6| Step: 9
Training loss: 3.8394887447357178
Validation loss: 4.587661385536194

Epoch: 6| Step: 10
Training loss: 5.313751697540283
Validation loss: 4.579119722048442

Epoch: 6| Step: 11
Training loss: 4.625639915466309
Validation loss: 4.570729335149129

Epoch: 6| Step: 12
Training loss: 4.866870880126953
Validation loss: 4.562684178352356

Epoch: 6| Step: 13
Training loss: 3.9930784702301025
Validation loss: 4.555846452713013

Epoch: 8| Step: 0
Training loss: 5.161705017089844
Validation loss: 4.547933538754781

Epoch: 6| Step: 1
Training loss: 4.586248397827148
Validation loss: 4.540489276250203

Epoch: 6| Step: 2
Training loss: 4.791610240936279
Validation loss: 4.534316460291545

Epoch: 6| Step: 3
Training loss: 5.051859378814697
Validation loss: 4.527623176574707

Epoch: 6| Step: 4
Training loss: 4.1428728103637695
Validation loss: 4.520806431770325

Epoch: 6| Step: 5
Training loss: 4.493014335632324
Validation loss: 4.5142620007197065

Epoch: 6| Step: 6
Training loss: 5.275574684143066
Validation loss: 4.508133172988892

Epoch: 6| Step: 7
Training loss: 4.556580543518066
Validation loss: 4.501328667004903

Epoch: 6| Step: 8
Training loss: 4.807299613952637
Validation loss: 4.495371739069621

Epoch: 6| Step: 9
Training loss: 4.568294525146484
Validation loss: 4.489748001098633

Epoch: 6| Step: 10
Training loss: 4.402172088623047
Validation loss: 4.483151117960612

Epoch: 6| Step: 11
Training loss: 3.8088302612304688
Validation loss: 4.477496186892192

Epoch: 6| Step: 12
Training loss: 3.8430299758911133
Validation loss: 4.4716161886851

Epoch: 6| Step: 13
Training loss: 5.083724021911621
Validation loss: 4.466158469518025

Epoch: 9| Step: 0
Training loss: 5.383996963500977
Validation loss: 4.459972699483235

Epoch: 6| Step: 1
Training loss: 3.928178310394287
Validation loss: 4.4533272584279375

Epoch: 6| Step: 2
Training loss: 5.457798480987549
Validation loss: 4.447553118069966

Epoch: 6| Step: 3
Training loss: 4.912452697753906
Validation loss: 4.441125512123108

Epoch: 6| Step: 4
Training loss: 4.493182182312012
Validation loss: 4.435093283653259

Epoch: 6| Step: 5
Training loss: 4.770825386047363
Validation loss: 4.428913831710815

Epoch: 6| Step: 6
Training loss: 4.511630058288574
Validation loss: 4.421641389528911

Epoch: 6| Step: 7
Training loss: 4.302495956420898
Validation loss: 4.415427088737488

Epoch: 6| Step: 8
Training loss: 5.135301113128662
Validation loss: 4.408730069796245

Epoch: 6| Step: 9
Training loss: 4.053677082061768
Validation loss: 4.402610659599304

Epoch: 6| Step: 10
Training loss: 5.035828113555908
Validation loss: 4.3959823449452715

Epoch: 6| Step: 11
Training loss: 4.882744312286377
Validation loss: 4.390329996744792

Epoch: 6| Step: 12
Training loss: 3.0069682598114014
Validation loss: 4.383693138758342

Epoch: 6| Step: 13
Training loss: 3.6234049797058105
Validation loss: 4.378084500630696

Epoch: 10| Step: 0
Training loss: 4.8961992263793945
Validation loss: 4.372589747111003

Epoch: 6| Step: 1
Training loss: 4.956910133361816
Validation loss: 4.366237163543701

Epoch: 6| Step: 2
Training loss: 3.183046817779541
Validation loss: 4.361283381779988

Epoch: 6| Step: 3
Training loss: 5.116508483886719
Validation loss: 4.354977607727051

Epoch: 6| Step: 4
Training loss: 4.473424911499023
Validation loss: 4.349851369857788

Epoch: 6| Step: 5
Training loss: 4.668770790100098
Validation loss: 4.343618988990784

Epoch: 6| Step: 6
Training loss: 3.446812868118286
Validation loss: 4.338426073392232

Epoch: 6| Step: 7
Training loss: 4.49216890335083
Validation loss: 4.332305828730266

Epoch: 6| Step: 8
Training loss: 5.314642429351807
Validation loss: 4.325671990712483

Epoch: 6| Step: 9
Training loss: 5.587471008300781
Validation loss: 4.32038935025533

Epoch: 6| Step: 10
Training loss: 4.099365234375
Validation loss: 4.314053932825725

Epoch: 6| Step: 11
Training loss: 3.68829083442688
Validation loss: 4.307145595550537

Epoch: 6| Step: 12
Training loss: 3.793621778488159
Validation loss: 4.300495704015096

Epoch: 6| Step: 13
Training loss: 4.679938316345215
Validation loss: 4.29405136903127

Epoch: 11| Step: 0
Training loss: 5.228824138641357
Validation loss: 4.287850975990295

Epoch: 6| Step: 1
Training loss: 3.574223756790161
Validation loss: 4.282100995381673

Epoch: 6| Step: 2
Training loss: 4.478752136230469
Validation loss: 4.2752483288447065

Epoch: 6| Step: 3
Training loss: 3.8949949741363525
Validation loss: 4.269702911376953

Epoch: 6| Step: 4
Training loss: 3.996079206466675
Validation loss: 4.263479312260945

Epoch: 6| Step: 5
Training loss: 4.829243183135986
Validation loss: 4.25783125559489

Epoch: 6| Step: 6
Training loss: 3.379307270050049
Validation loss: 4.251646876335144

Epoch: 6| Step: 7
Training loss: 5.296174049377441
Validation loss: 4.245610157648723

Epoch: 6| Step: 8
Training loss: 3.4217801094055176
Validation loss: 4.239741086959839

Epoch: 6| Step: 9
Training loss: 4.91539192199707
Validation loss: 4.233393430709839

Epoch: 6| Step: 10
Training loss: 4.692009925842285
Validation loss: 4.227147301038106

Epoch: 6| Step: 11
Training loss: 4.823232650756836
Validation loss: 4.222088813781738

Epoch: 6| Step: 12
Training loss: 4.022868633270264
Validation loss: 4.216450055440267

Epoch: 6| Step: 13
Training loss: 4.71461296081543
Validation loss: 4.2113527456919355

Epoch: 12| Step: 0
Training loss: 4.746366500854492
Validation loss: 4.205670078595479

Epoch: 6| Step: 1
Training loss: 3.9430623054504395
Validation loss: 4.200090924898784

Epoch: 6| Step: 2
Training loss: 3.5288031101226807
Validation loss: 4.193882783253987

Epoch: 6| Step: 3
Training loss: 4.97119140625
Validation loss: 4.189304788907369

Epoch: 6| Step: 4
Training loss: 3.2525312900543213
Validation loss: 4.184277415275574

Epoch: 6| Step: 5
Training loss: 4.662386894226074
Validation loss: 4.178313334782918

Epoch: 6| Step: 6
Training loss: 4.456220626831055
Validation loss: 4.173753221829732

Epoch: 6| Step: 7
Training loss: 4.805673599243164
Validation loss: 4.168320417404175

Epoch: 6| Step: 8
Training loss: 4.2137861251831055
Validation loss: 4.1629638671875

Epoch: 6| Step: 9
Training loss: 5.007863998413086
Validation loss: 4.158167918523152

Epoch: 6| Step: 10
Training loss: 3.7525432109832764
Validation loss: 4.152751684188843

Epoch: 6| Step: 11
Training loss: 4.006991386413574
Validation loss: 4.146358569463094

Epoch: 6| Step: 12
Training loss: 3.8671367168426514
Validation loss: 4.140220483144124

Epoch: 6| Step: 13
Training loss: 5.079884052276611
Validation loss: 4.13674795627594

Epoch: 13| Step: 0
Training loss: 3.9681966304779053
Validation loss: 4.130452593167623

Epoch: 6| Step: 1
Training loss: 5.07850980758667
Validation loss: 4.125101566314697

Epoch: 6| Step: 2
Training loss: 4.320897102355957
Validation loss: 4.1211934089660645

Epoch: 6| Step: 3
Training loss: 4.458367347717285
Validation loss: 4.116397539774577

Epoch: 6| Step: 4
Training loss: 3.6812751293182373
Validation loss: 4.111057202021281

Epoch: 6| Step: 5
Training loss: 4.209777355194092
Validation loss: 4.105461160341899

Epoch: 6| Step: 6
Training loss: 6.037563323974609
Validation loss: 4.099857370058696

Epoch: 6| Step: 7
Training loss: 3.435124158859253
Validation loss: 4.095452388127645

Epoch: 6| Step: 8
Training loss: 3.9655611515045166
Validation loss: 4.090987324714661

Epoch: 6| Step: 9
Training loss: 4.156501293182373
Validation loss: 4.084744373957316

Epoch: 6| Step: 10
Training loss: 4.314960479736328
Validation loss: 4.079909006754558

Epoch: 6| Step: 11
Training loss: 3.720217227935791
Validation loss: 4.073946952819824

Epoch: 6| Step: 12
Training loss: 3.361013889312744
Validation loss: 4.070937514305115

Epoch: 6| Step: 13
Training loss: 4.663803577423096
Validation loss: 4.0651670296986895

Epoch: 14| Step: 0
Training loss: 3.794710397720337
Validation loss: 4.0609809557596845

Epoch: 6| Step: 1
Training loss: 3.7167863845825195
Validation loss: 4.056215246518453

Epoch: 6| Step: 2
Training loss: 3.3101119995117188
Validation loss: 4.051983594894409

Epoch: 6| Step: 3
Training loss: 4.067276477813721
Validation loss: 4.046190500259399

Epoch: 6| Step: 4
Training loss: 4.007174491882324
Validation loss: 4.041197816530864

Epoch: 6| Step: 5
Training loss: 5.142682075500488
Validation loss: 4.038430293401082

Epoch: 6| Step: 6
Training loss: 3.4874119758605957
Validation loss: 4.033179521560669

Epoch: 6| Step: 7
Training loss: 4.514662742614746
Validation loss: 4.028077125549316

Epoch: 6| Step: 8
Training loss: 4.3698649406433105
Validation loss: 4.022833466529846

Epoch: 6| Step: 9
Training loss: 3.6885828971862793
Validation loss: 4.017326792081197

Epoch: 6| Step: 10
Training loss: 4.44513463973999
Validation loss: 4.0132540464401245

Epoch: 6| Step: 11
Training loss: 4.358278274536133
Validation loss: 4.0086008707682295

Epoch: 6| Step: 12
Training loss: 5.428732395172119
Validation loss: 4.003530462582906

Epoch: 6| Step: 13
Training loss: 4.0822248458862305
Validation loss: 3.998881459236145

Epoch: 15| Step: 0
Training loss: 4.1943678855896
Validation loss: 3.9951366980870566

Epoch: 6| Step: 1
Training loss: 3.9680349826812744
Validation loss: 3.989777445793152

Epoch: 6| Step: 2
Training loss: 3.7207448482513428
Validation loss: 3.983811140060425

Epoch: 6| Step: 3
Training loss: 4.260266304016113
Validation loss: 3.979386806488037

Epoch: 6| Step: 4
Training loss: 4.500816345214844
Validation loss: 3.975337326526642

Epoch: 6| Step: 5
Training loss: 3.907658576965332
Validation loss: 3.97101366519928

Epoch: 6| Step: 6
Training loss: 4.851521968841553
Validation loss: 3.9643391370773315

Epoch: 6| Step: 7
Training loss: 3.9779539108276367
Validation loss: 3.958484411239624

Epoch: 6| Step: 8
Training loss: 3.5219225883483887
Validation loss: 3.9538399378458657

Epoch: 6| Step: 9
Training loss: 3.6855058670043945
Validation loss: 3.949544668197632

Epoch: 6| Step: 10
Training loss: 3.9164133071899414
Validation loss: 3.9447340170542398

Epoch: 6| Step: 11
Training loss: 3.902031898498535
Validation loss: 3.939923723538717

Epoch: 6| Step: 12
Training loss: 4.291701316833496
Validation loss: 3.9348549842834473

Epoch: 6| Step: 13
Training loss: 4.840595245361328
Validation loss: 3.9299073219299316

Epoch: 16| Step: 0
Training loss: 5.3651580810546875
Validation loss: 3.9248902400334678

Epoch: 6| Step: 1
Training loss: 3.3673925399780273
Validation loss: 3.9206744035085044

Epoch: 6| Step: 2
Training loss: 2.8062381744384766
Validation loss: 3.9155110518137612

Epoch: 6| Step: 3
Training loss: 4.624135971069336
Validation loss: 3.910803437232971

Epoch: 6| Step: 4
Training loss: 4.880774974822998
Validation loss: 3.90676486492157

Epoch: 6| Step: 5
Training loss: 3.678762912750244
Validation loss: 3.901470422744751

Epoch: 6| Step: 6
Training loss: 4.449621200561523
Validation loss: 3.8973270654678345

Epoch: 6| Step: 7
Training loss: 3.416853904724121
Validation loss: 3.8935799996058145

Epoch: 6| Step: 8
Training loss: 4.682974338531494
Validation loss: 3.890501856803894

Epoch: 6| Step: 9
Training loss: 4.993895530700684
Validation loss: 3.8834309577941895

Epoch: 6| Step: 10
Training loss: 4.122097969055176
Validation loss: 3.8795915842056274

Epoch: 6| Step: 11
Training loss: 3.8965325355529785
Validation loss: 3.877117474873861

Epoch: 6| Step: 12
Training loss: 2.584664821624756
Validation loss: 3.87261970837911

Epoch: 6| Step: 13
Training loss: 3.765002727508545
Validation loss: 3.8671597639719644

Epoch: 17| Step: 0
Training loss: 4.417279243469238
Validation loss: 3.8615641593933105

Epoch: 6| Step: 1
Training loss: 3.2714333534240723
Validation loss: 3.856109619140625

Epoch: 6| Step: 2
Training loss: 4.752505302429199
Validation loss: 3.8519533475240073

Epoch: 6| Step: 3
Training loss: 3.7460293769836426
Validation loss: 3.8469650745391846

Epoch: 6| Step: 4
Training loss: 2.814568519592285
Validation loss: 3.8415157000223794

Epoch: 6| Step: 5
Training loss: 4.1538848876953125
Validation loss: 3.836995840072632

Epoch: 6| Step: 6
Training loss: 3.251089572906494
Validation loss: 3.8328417936960855

Epoch: 6| Step: 7
Training loss: 4.481265068054199
Validation loss: 3.829139788945516

Epoch: 6| Step: 8
Training loss: 5.118311882019043
Validation loss: 3.823043704032898

Epoch: 6| Step: 9
Training loss: 3.5184226036071777
Validation loss: 3.818216244379679

Epoch: 6| Step: 10
Training loss: 4.25172758102417
Validation loss: 3.8129924138387046

Epoch: 6| Step: 11
Training loss: 4.315822601318359
Validation loss: 3.810389598210653

Epoch: 6| Step: 12
Training loss: 4.230674743652344
Validation loss: 3.8085093100865683

Epoch: 6| Step: 13
Training loss: 3.483616352081299
Validation loss: 3.802605946858724

Epoch: 18| Step: 0
Training loss: 3.35323429107666
Validation loss: 3.797376592954

Epoch: 6| Step: 1
Training loss: 5.074715614318848
Validation loss: 3.794550975163778

Epoch: 6| Step: 2
Training loss: 4.599806308746338
Validation loss: 3.7867342631022134

Epoch: 6| Step: 3
Training loss: 4.320909023284912
Validation loss: 3.7823613484700522

Epoch: 6| Step: 4
Training loss: 3.4790356159210205
Validation loss: 3.7789287169774375

Epoch: 6| Step: 5
Training loss: 4.4458465576171875
Validation loss: 3.7755347887674966

Epoch: 6| Step: 6
Training loss: 3.0653419494628906
Validation loss: 3.770848353703817

Epoch: 6| Step: 7
Training loss: 2.862919807434082
Validation loss: 3.76520045598348

Epoch: 6| Step: 8
Training loss: 4.109640121459961
Validation loss: 3.7597424586613974

Epoch: 6| Step: 9
Training loss: 2.9853224754333496
Validation loss: 3.7558258771896362

Epoch: 6| Step: 10
Training loss: 3.598860025405884
Validation loss: 3.7523219188054404

Epoch: 6| Step: 11
Training loss: 4.242918014526367
Validation loss: 3.748055100440979

Epoch: 6| Step: 12
Training loss: 5.279974460601807
Validation loss: 3.7423322200775146

Epoch: 6| Step: 13
Training loss: 3.5372700691223145
Validation loss: 3.7392833630243936

Epoch: 19| Step: 0
Training loss: 4.73415470123291
Validation loss: 3.736345052719116

Epoch: 6| Step: 1
Training loss: 5.700375080108643
Validation loss: 3.7315961519877114

Epoch: 6| Step: 2
Training loss: 2.713149070739746
Validation loss: 3.726998209953308

Epoch: 6| Step: 3
Training loss: 2.5208280086517334
Validation loss: 3.721216320991516

Epoch: 6| Step: 4
Training loss: 3.382007122039795
Validation loss: 3.7158430417378745

Epoch: 6| Step: 5
Training loss: 3.6801180839538574
Validation loss: 3.712090531984965

Epoch: 6| Step: 6
Training loss: 4.6433424949646
Validation loss: 3.709362546602885

Epoch: 6| Step: 7
Training loss: 4.951999664306641
Validation loss: 3.702898939450582

Epoch: 6| Step: 8
Training loss: 4.499446868896484
Validation loss: 3.7008431355158486

Epoch: 6| Step: 9
Training loss: 3.9057750701904297
Validation loss: 3.6956305503845215

Epoch: 6| Step: 10
Training loss: 4.579703330993652
Validation loss: 3.6907848517100015

Epoch: 6| Step: 11
Training loss: 2.8726673126220703
Validation loss: 3.686527689297994

Epoch: 6| Step: 12
Training loss: 2.2383477687835693
Validation loss: 3.681918462117513

Epoch: 6| Step: 13
Training loss: 3.7193992137908936
Validation loss: 3.6785852511723838

Epoch: 20| Step: 0
Training loss: 4.1866631507873535
Validation loss: 3.6741100549697876

Epoch: 6| Step: 1
Training loss: 4.512982368469238
Validation loss: 3.668303926785787

Epoch: 6| Step: 2
Training loss: 4.266238212585449
Validation loss: 3.6617530981699624

Epoch: 6| Step: 3
Training loss: 3.3867177963256836
Validation loss: 3.6575735410054526

Epoch: 6| Step: 4
Training loss: 2.4190893173217773
Validation loss: 3.654457608858744

Epoch: 6| Step: 5
Training loss: 4.223155498504639
Validation loss: 3.6491591930389404

Epoch: 6| Step: 6
Training loss: 3.8518970012664795
Validation loss: 3.6447105407714844

Epoch: 6| Step: 7
Training loss: 4.029445648193359
Validation loss: 3.640501062075297

Epoch: 6| Step: 8
Training loss: 3.9291486740112305
Validation loss: 3.6356798807779946

Epoch: 6| Step: 9
Training loss: 3.4125518798828125
Validation loss: 3.629004120826721

Epoch: 6| Step: 10
Training loss: 3.3233377933502197
Validation loss: 3.6257829666137695

Epoch: 6| Step: 11
Training loss: 3.484368324279785
Validation loss: 3.621847947438558

Epoch: 6| Step: 12
Training loss: 3.8023664951324463
Validation loss: 3.6167574723561606

Epoch: 6| Step: 13
Training loss: 4.436776161193848
Validation loss: 3.6117272774378457

Epoch: 21| Step: 0
Training loss: 3.3270068168640137
Validation loss: 3.606996536254883

Epoch: 6| Step: 1
Training loss: 3.3462109565734863
Validation loss: 3.601741393407186

Epoch: 6| Step: 2
Training loss: 4.84635066986084
Validation loss: 3.599962910016378

Epoch: 6| Step: 3
Training loss: 4.222428321838379
Validation loss: 3.594353755315145

Epoch: 6| Step: 4
Training loss: 4.692716121673584
Validation loss: 3.5884142319361367

Epoch: 6| Step: 5
Training loss: 3.216501235961914
Validation loss: 3.5848522981007895

Epoch: 6| Step: 6
Training loss: 3.911848545074463
Validation loss: 3.579514225323995

Epoch: 6| Step: 7
Training loss: 3.7654106616973877
Validation loss: 3.5750288565953574

Epoch: 6| Step: 8
Training loss: 3.9663403034210205
Validation loss: 3.5692089398701987

Epoch: 6| Step: 9
Training loss: 3.601741313934326
Validation loss: 3.5643781820933023

Epoch: 6| Step: 10
Training loss: 3.8605704307556152
Validation loss: 3.558604637781779

Epoch: 6| Step: 11
Training loss: 3.3233206272125244
Validation loss: 3.5533047914505005

Epoch: 6| Step: 12
Training loss: 3.68247127532959
Validation loss: 3.5492481787999473

Epoch: 6| Step: 13
Training loss: 2.5920002460479736
Validation loss: 3.543691396713257

Epoch: 22| Step: 0
Training loss: 4.072109222412109
Validation loss: 3.5384654998779297

Epoch: 6| Step: 1
Training loss: 3.5535330772399902
Validation loss: 3.5323273340861

Epoch: 6| Step: 2
Training loss: 3.8770127296447754
Validation loss: 3.52798855304718

Epoch: 6| Step: 3
Training loss: 3.8551599979400635
Validation loss: 3.524063467979431

Epoch: 6| Step: 4
Training loss: 3.6258552074432373
Validation loss: 3.5193727016448975

Epoch: 6| Step: 5
Training loss: 3.3308939933776855
Validation loss: 3.513598322868347

Epoch: 6| Step: 6
Training loss: 3.893690586090088
Validation loss: 3.5073856910069785

Epoch: 6| Step: 7
Training loss: 3.603396415710449
Validation loss: 3.5008585850397744

Epoch: 6| Step: 8
Training loss: 2.52390193939209
Validation loss: 3.4936800400416055

Epoch: 6| Step: 9
Training loss: 4.276488780975342
Validation loss: 3.4861031770706177

Epoch: 6| Step: 10
Training loss: 3.7627038955688477
Validation loss: 3.481985012690226

Epoch: 6| Step: 11
Training loss: 3.8867430686950684
Validation loss: 3.474777658780416

Epoch: 6| Step: 12
Training loss: 3.4614481925964355
Validation loss: 3.4701850016911826

Epoch: 6| Step: 13
Training loss: 3.6372156143188477
Validation loss: 3.4644988377889

Epoch: 23| Step: 0
Training loss: 3.5005412101745605
Validation loss: 3.4591934283574424

Epoch: 6| Step: 1
Training loss: 3.613253593444824
Validation loss: 3.453481594721476

Epoch: 6| Step: 2
Training loss: 4.17287540435791
Validation loss: 3.4472009738286338

Epoch: 6| Step: 3
Training loss: 3.9636476039886475
Validation loss: 3.4435601234436035

Epoch: 6| Step: 4
Training loss: 3.56693172454834
Validation loss: 3.437442938486735

Epoch: 6| Step: 5
Training loss: 3.4252800941467285
Validation loss: 3.432524879773458

Epoch: 6| Step: 6
Training loss: 3.2570252418518066
Validation loss: 3.427181680997213

Epoch: 6| Step: 7
Training loss: 3.883526086807251
Validation loss: 3.421695113182068

Epoch: 6| Step: 8
Training loss: 3.012673854827881
Validation loss: 3.416242798169454

Epoch: 6| Step: 9
Training loss: 4.479426383972168
Validation loss: 3.4100617170333862

Epoch: 6| Step: 10
Training loss: 3.4338510036468506
Validation loss: 3.405332605044047

Epoch: 6| Step: 11
Training loss: 3.38057279586792
Validation loss: 3.4033024311065674

Epoch: 6| Step: 12
Training loss: 3.203493356704712
Validation loss: 3.398581584294637

Epoch: 6| Step: 13
Training loss: 3.420078754425049
Validation loss: 3.393648306528727

Epoch: 24| Step: 0
Training loss: 4.063034534454346
Validation loss: 3.3856937090555825

Epoch: 6| Step: 1
Training loss: 3.9360389709472656
Validation loss: 3.3808400630950928

Epoch: 6| Step: 2
Training loss: 3.142096757888794
Validation loss: 3.377339720726013

Epoch: 6| Step: 3
Training loss: 4.069821834564209
Validation loss: 3.374274174372355

Epoch: 6| Step: 4
Training loss: 4.2872314453125
Validation loss: 3.3696107864379883

Epoch: 6| Step: 5
Training loss: 3.4259719848632812
Validation loss: 3.3635948499043784

Epoch: 6| Step: 6
Training loss: 3.3802709579467773
Validation loss: 3.3567344347635903

Epoch: 6| Step: 7
Training loss: 3.717770576477051
Validation loss: 3.3526464700698853

Epoch: 6| Step: 8
Training loss: 3.033341884613037
Validation loss: 3.3465454975763955

Epoch: 6| Step: 9
Training loss: 3.7495434284210205
Validation loss: 3.34209144115448

Epoch: 6| Step: 10
Training loss: 2.3868117332458496
Validation loss: 3.335961898167928

Epoch: 6| Step: 11
Training loss: 2.826298475265503
Validation loss: 3.329928000768026

Epoch: 6| Step: 12
Training loss: 3.560957908630371
Validation loss: 3.3248126109441123

Epoch: 6| Step: 13
Training loss: 3.8170557022094727
Validation loss: 3.32023549079895

Epoch: 25| Step: 0
Training loss: 3.2318501472473145
Validation loss: 3.315462589263916

Epoch: 6| Step: 1
Training loss: 2.81123685836792
Validation loss: 3.3100639184316

Epoch: 6| Step: 2
Training loss: 3.3084301948547363
Validation loss: 3.305968403816223

Epoch: 6| Step: 3
Training loss: 4.04563570022583
Validation loss: 3.3018463452657065

Epoch: 6| Step: 4
Training loss: 3.175072193145752
Validation loss: 3.2977375984191895

Epoch: 6| Step: 5
Training loss: 4.034784317016602
Validation loss: 3.292264978090922

Epoch: 6| Step: 6
Training loss: 3.645552635192871
Validation loss: 3.2871199448903403

Epoch: 6| Step: 7
Training loss: 2.9809463024139404
Validation loss: 3.282124320665995

Epoch: 6| Step: 8
Training loss: 3.7510712146759033
Validation loss: 3.2785482009251914

Epoch: 6| Step: 9
Training loss: 3.766019105911255
Validation loss: 3.2731221119562783

Epoch: 6| Step: 10
Training loss: 3.0228233337402344
Validation loss: 3.2690160274505615

Epoch: 6| Step: 11
Training loss: 3.1717588901519775
Validation loss: 3.26406462987264

Epoch: 6| Step: 12
Training loss: 4.027504920959473
Validation loss: 3.259637792905172

Epoch: 6| Step: 13
Training loss: 3.4488449096679688
Validation loss: 3.2555085817972818

Epoch: 26| Step: 0
Training loss: 3.7784948348999023
Validation loss: 3.2491488456726074

Epoch: 6| Step: 1
Training loss: 3.1651017665863037
Validation loss: 3.2450633446375527

Epoch: 6| Step: 2
Training loss: 4.10774040222168
Validation loss: 3.2412525018056235

Epoch: 6| Step: 3
Training loss: 2.7403323650360107
Validation loss: 3.2366750637690225

Epoch: 6| Step: 4
Training loss: 3.4593276977539062
Validation loss: 3.233358065287272

Epoch: 6| Step: 5
Training loss: 2.972001791000366
Validation loss: 3.228089531262716

Epoch: 6| Step: 6
Training loss: 3.679940700531006
Validation loss: 3.2213001251220703

Epoch: 6| Step: 7
Training loss: 3.7921531200408936
Validation loss: 3.2151856422424316

Epoch: 6| Step: 8
Training loss: 3.1937313079833984
Validation loss: 3.211455742518107

Epoch: 6| Step: 9
Training loss: 3.1521413326263428
Validation loss: 3.206257700920105

Epoch: 6| Step: 10
Training loss: 3.112476110458374
Validation loss: 3.2021966775258384

Epoch: 6| Step: 11
Training loss: 3.383721351623535
Validation loss: 3.197196284929911

Epoch: 6| Step: 12
Training loss: 3.4999303817749023
Validation loss: 3.1932511727015176

Epoch: 6| Step: 13
Training loss: 3.512418746948242
Validation loss: 3.1871776580810547

Epoch: 27| Step: 0
Training loss: 4.291074752807617
Validation loss: 3.1863768100738525

Epoch: 6| Step: 1
Training loss: 3.7517151832580566
Validation loss: 3.1814207235972085

Epoch: 6| Step: 2
Training loss: 2.660841941833496
Validation loss: 3.174459934234619

Epoch: 6| Step: 3
Training loss: 2.4276554584503174
Validation loss: 3.1676875352859497

Epoch: 6| Step: 4
Training loss: 3.4337244033813477
Validation loss: 3.1640112002690635

Epoch: 6| Step: 5
Training loss: 3.7669644355773926
Validation loss: 3.1585071086883545

Epoch: 6| Step: 6
Training loss: 3.4712843894958496
Validation loss: 3.154363751411438

Epoch: 6| Step: 7
Training loss: 3.6639814376831055
Validation loss: 3.1479055881500244

Epoch: 6| Step: 8
Training loss: 2.49782657623291
Validation loss: 3.145630121231079

Epoch: 6| Step: 9
Training loss: 2.835411787033081
Validation loss: 3.140024463335673

Epoch: 6| Step: 10
Training loss: 3.7954819202423096
Validation loss: 3.1365796327590942

Epoch: 6| Step: 11
Training loss: 3.2911276817321777
Validation loss: 3.1277783314387

Epoch: 6| Step: 12
Training loss: 3.035186290740967
Validation loss: 3.1256139278411865

Epoch: 6| Step: 13
Training loss: 3.778864860534668
Validation loss: 3.121069391568502

Epoch: 28| Step: 0
Training loss: 3.6071527004241943
Validation loss: 3.113906820615133

Epoch: 6| Step: 1
Training loss: 2.720069408416748
Validation loss: 3.1104334195454917

Epoch: 6| Step: 2
Training loss: 3.907395839691162
Validation loss: 3.1080960830052695

Epoch: 6| Step: 3
Training loss: 3.1484246253967285
Validation loss: 3.1013038953145347

Epoch: 6| Step: 4
Training loss: 3.4997198581695557
Validation loss: 3.096166650454203

Epoch: 6| Step: 5
Training loss: 3.908226251602173
Validation loss: 3.0923845767974854

Epoch: 6| Step: 6
Training loss: 2.717055320739746
Validation loss: 3.0869454542795816

Epoch: 6| Step: 7
Training loss: 3.3873023986816406
Validation loss: 3.0852024952570596

Epoch: 6| Step: 8
Training loss: 3.718229293823242
Validation loss: 3.0814725955327353

Epoch: 6| Step: 9
Training loss: 3.260695695877075
Validation loss: 3.075396259625753

Epoch: 6| Step: 10
Training loss: 2.885756492614746
Validation loss: 3.0703019301096597

Epoch: 6| Step: 11
Training loss: 3.7357306480407715
Validation loss: 3.0666895707448325

Epoch: 6| Step: 12
Training loss: 2.3595612049102783
Validation loss: 3.0639826456705728

Epoch: 6| Step: 13
Training loss: 2.9640161991119385
Validation loss: 3.0592824618021646

Epoch: 29| Step: 0
Training loss: 2.998094081878662
Validation loss: 3.054410974184672

Epoch: 6| Step: 1
Training loss: 3.4880006313323975
Validation loss: 3.0500378608703613

Epoch: 6| Step: 2
Training loss: 3.3939995765686035
Validation loss: 3.045489470163981

Epoch: 6| Step: 3
Training loss: 2.4051294326782227
Validation loss: 3.0394603411356607

Epoch: 6| Step: 4
Training loss: 3.1748175621032715
Validation loss: 3.037423054377238

Epoch: 6| Step: 5
Training loss: 3.5099589824676514
Validation loss: 3.033095598220825

Epoch: 6| Step: 6
Training loss: 2.949550151824951
Validation loss: 3.0290785233179727

Epoch: 6| Step: 7
Training loss: 2.9952094554901123
Validation loss: 3.026738921801249

Epoch: 6| Step: 8
Training loss: 2.921846389770508
Validation loss: 3.0193373759587607

Epoch: 6| Step: 9
Training loss: 4.054080963134766
Validation loss: 3.0154128869374595

Epoch: 6| Step: 10
Training loss: 3.9844675064086914
Validation loss: 3.0118668476740518

Epoch: 6| Step: 11
Training loss: 3.4082589149475098
Validation loss: 3.006671667098999

Epoch: 6| Step: 12
Training loss: 2.9544873237609863
Validation loss: 3.0046046574910483

Epoch: 6| Step: 13
Training loss: 2.758267641067505
Validation loss: 3.000695506731669

Epoch: 30| Step: 0
Training loss: 3.0886623859405518
Validation loss: 2.995391607284546

Epoch: 6| Step: 1
Training loss: 3.0341501235961914
Validation loss: 2.993670701980591

Epoch: 6| Step: 2
Training loss: 3.8562183380126953
Validation loss: 2.9871644179026284

Epoch: 6| Step: 3
Training loss: 3.199436664581299
Validation loss: 2.982890566190084

Epoch: 6| Step: 4
Training loss: 3.052307367324829
Validation loss: 2.9775527715682983

Epoch: 6| Step: 5
Training loss: 3.506237268447876
Validation loss: 2.975405971209208

Epoch: 6| Step: 6
Training loss: 2.8653979301452637
Validation loss: 2.9716991186141968

Epoch: 6| Step: 7
Training loss: 2.6916146278381348
Validation loss: 2.9683274825414023

Epoch: 6| Step: 8
Training loss: 3.450779438018799
Validation loss: 2.965163230895996

Epoch: 6| Step: 9
Training loss: 3.003605604171753
Validation loss: 2.9607183933258057

Epoch: 6| Step: 10
Training loss: 3.0310208797454834
Validation loss: 2.9547382593154907

Epoch: 6| Step: 11
Training loss: 3.036844253540039
Validation loss: 2.9514838457107544

Epoch: 6| Step: 12
Training loss: 2.750469446182251
Validation loss: 2.9488316774368286

Epoch: 6| Step: 13
Training loss: 3.673496961593628
Validation loss: 2.945763905843099

Epoch: 31| Step: 0
Training loss: 3.5288727283477783
Validation loss: 2.9398188988367715

Epoch: 6| Step: 1
Training loss: 2.529745101928711
Validation loss: 2.9362014134724936

Epoch: 6| Step: 2
Training loss: 3.517458915710449
Validation loss: 2.9334784348805747

Epoch: 6| Step: 3
Training loss: 3.3851797580718994
Validation loss: 2.928430140018463

Epoch: 6| Step: 4
Training loss: 3.4064407348632812
Validation loss: 2.92313023408254

Epoch: 6| Step: 5
Training loss: 3.1428465843200684
Validation loss: 2.9202688137690225

Epoch: 6| Step: 6
Training loss: 3.816774368286133
Validation loss: 2.915347417195638

Epoch: 6| Step: 7
Training loss: 2.9172463417053223
Validation loss: 2.91171395778656

Epoch: 6| Step: 8
Training loss: 3.2479567527770996
Validation loss: 2.906810760498047

Epoch: 6| Step: 9
Training loss: 2.5934391021728516
Validation loss: 2.9041022459665933

Epoch: 6| Step: 10
Training loss: 3.0933384895324707
Validation loss: 2.9000432093938193

Epoch: 6| Step: 11
Training loss: 2.982429027557373
Validation loss: 2.896913727124532

Epoch: 6| Step: 12
Training loss: 1.7528703212738037
Validation loss: 2.892513910929362

Epoch: 6| Step: 13
Training loss: 3.6643238067626953
Validation loss: 2.88894776503245

Epoch: 32| Step: 0
Training loss: 3.5693812370300293
Validation loss: 2.8840278784434

Epoch: 6| Step: 1
Training loss: 2.631495475769043
Validation loss: 2.879198670387268

Epoch: 6| Step: 2
Training loss: 2.809396505355835
Validation loss: 2.8771270513534546

Epoch: 6| Step: 3
Training loss: 2.5608723163604736
Validation loss: 2.8736180861790976

Epoch: 6| Step: 4
Training loss: 3.3194687366485596
Validation loss: 2.8712671200434365

Epoch: 6| Step: 5
Training loss: 3.8241281509399414
Validation loss: 2.8637667894363403

Epoch: 6| Step: 6
Training loss: 2.503683567047119
Validation loss: 2.860297918319702

Epoch: 6| Step: 7
Training loss: 3.4495038986206055
Validation loss: 2.8564555247624717

Epoch: 6| Step: 8
Training loss: 3.0134592056274414
Validation loss: 2.853149096171061

Epoch: 6| Step: 9
Training loss: 3.2995848655700684
Validation loss: 2.8521127303441367

Epoch: 6| Step: 10
Training loss: 3.0594804286956787
Validation loss: 2.848223884900411

Epoch: 6| Step: 11
Training loss: 2.930324077606201
Validation loss: 2.843699554602305

Epoch: 6| Step: 12
Training loss: 3.4206786155700684
Validation loss: 2.838831305503845

Epoch: 6| Step: 13
Training loss: 2.5273633003234863
Validation loss: 2.834858854611715

Epoch: 33| Step: 0
Training loss: 3.621650218963623
Validation loss: 2.8297613064448037

Epoch: 6| Step: 1
Training loss: 3.0003161430358887
Validation loss: 2.8252402544021606

Epoch: 6| Step: 2
Training loss: 2.771426200866699
Validation loss: 2.8220258951187134

Epoch: 6| Step: 3
Training loss: 3.028371810913086
Validation loss: 2.822752078374227

Epoch: 6| Step: 4
Training loss: 3.2720320224761963
Validation loss: 2.8132822513580322

Epoch: 6| Step: 5
Training loss: 3.6391005516052246
Validation loss: 2.81320591767629

Epoch: 6| Step: 6
Training loss: 3.730785608291626
Validation loss: 2.8078084786732993

Epoch: 6| Step: 7
Training loss: 2.2578344345092773
Validation loss: 2.802094578742981

Epoch: 6| Step: 8
Training loss: 3.0200676918029785
Validation loss: 2.797653873761495

Epoch: 6| Step: 9
Training loss: 2.719974994659424
Validation loss: 2.796534697214762

Epoch: 6| Step: 10
Training loss: 2.492361545562744
Validation loss: 2.7910796801249185

Epoch: 6| Step: 11
Training loss: 3.0708677768707275
Validation loss: 2.788410226504008

Epoch: 6| Step: 12
Training loss: 2.7771220207214355
Validation loss: 2.791748801867167

Epoch: 6| Step: 13
Training loss: 2.8548996448516846
Validation loss: 2.7847083608309426

Epoch: 34| Step: 0
Training loss: 2.205759286880493
Validation loss: 2.7925947109858194

Epoch: 6| Step: 1
Training loss: 3.430428981781006
Validation loss: 2.8002379337946572

Epoch: 6| Step: 2
Training loss: 3.27266263961792
Validation loss: 2.7736507654190063

Epoch: 6| Step: 3
Training loss: 3.5631017684936523
Validation loss: 2.772417664527893

Epoch: 6| Step: 4
Training loss: 2.6518497467041016
Validation loss: 2.7892775932947793

Epoch: 6| Step: 5
Training loss: 2.3156728744506836
Validation loss: 2.778622031211853

Epoch: 6| Step: 6
Training loss: 2.9522433280944824
Validation loss: 2.772509435812632

Epoch: 6| Step: 7
Training loss: 3.419433355331421
Validation loss: 2.759764234224955

Epoch: 6| Step: 8
Training loss: 3.1819968223571777
Validation loss: 2.76133660475413

Epoch: 6| Step: 9
Training loss: 3.425279378890991
Validation loss: 2.752179265022278

Epoch: 6| Step: 10
Training loss: 3.194094657897949
Validation loss: 2.744904359181722

Epoch: 6| Step: 11
Training loss: 3.043283700942993
Validation loss: 2.747592647870382

Epoch: 6| Step: 12
Training loss: 2.9970409870147705
Validation loss: 2.7510127623875937

Epoch: 6| Step: 13
Training loss: 2.0663416385650635
Validation loss: 2.748356302579244

Epoch: 35| Step: 0
Training loss: 3.0601160526275635
Validation loss: 2.745578169822693

Epoch: 6| Step: 1
Training loss: 2.9790210723876953
Validation loss: 2.737976630528768

Epoch: 6| Step: 2
Training loss: 2.391162395477295
Validation loss: 2.734846830368042

Epoch: 6| Step: 3
Training loss: 2.125579595565796
Validation loss: 2.7302337487538657

Epoch: 6| Step: 4
Training loss: 3.3548455238342285
Validation loss: 2.725419561068217

Epoch: 6| Step: 5
Training loss: 3.416624069213867
Validation loss: 2.721895178159078

Epoch: 6| Step: 6
Training loss: 2.332826852798462
Validation loss: 2.718718489011129

Epoch: 6| Step: 7
Training loss: 3.262543201446533
Validation loss: 2.7150731484095254

Epoch: 6| Step: 8
Training loss: 3.077533721923828
Validation loss: 2.7116617361704507

Epoch: 6| Step: 9
Training loss: 3.161745071411133
Validation loss: 2.7104644775390625

Epoch: 6| Step: 10
Training loss: 3.156036853790283
Validation loss: 2.7082207997639975

Epoch: 6| Step: 11
Training loss: 3.202897071838379
Validation loss: 2.7011812130610147

Epoch: 6| Step: 12
Training loss: 2.666393995285034
Validation loss: 2.698038856188456

Epoch: 6| Step: 13
Training loss: 2.723400592803955
Validation loss: 2.6923531691233316

Epoch: 36| Step: 0
Training loss: 2.966179370880127
Validation loss: 2.6896154483159385

Epoch: 6| Step: 1
Training loss: 2.737776756286621
Validation loss: 2.6877644260724387

Epoch: 6| Step: 2
Training loss: 2.64929461479187
Validation loss: 2.6878159443537393

Epoch: 6| Step: 3
Training loss: 2.9527101516723633
Validation loss: 2.6892815033594766

Epoch: 6| Step: 4
Training loss: 3.126408338546753
Validation loss: 2.67832612991333

Epoch: 6| Step: 5
Training loss: 2.8494505882263184
Validation loss: 2.6710223952929177

Epoch: 6| Step: 6
Training loss: 2.6981568336486816
Validation loss: 2.6673311392466226

Epoch: 6| Step: 7
Training loss: 3.5303115844726562
Validation loss: 2.663840174674988

Epoch: 6| Step: 8
Training loss: 2.6589760780334473
Validation loss: 2.66153077284495

Epoch: 6| Step: 9
Training loss: 2.67948579788208
Validation loss: 2.6587520440419516

Epoch: 6| Step: 10
Training loss: 2.9847235679626465
Validation loss: 2.6569796800613403

Epoch: 6| Step: 11
Training loss: 2.7585244178771973
Validation loss: 2.64937957127889

Epoch: 6| Step: 12
Training loss: 3.0289604663848877
Validation loss: 2.6487863858540854

Epoch: 6| Step: 13
Training loss: 2.575166702270508
Validation loss: 2.6424930095672607

Epoch: 37| Step: 0
Training loss: 2.814981698989868
Validation loss: 2.6421360969543457

Epoch: 6| Step: 1
Training loss: 3.245388984680176
Validation loss: 2.6385792891184487

Epoch: 6| Step: 2
Training loss: 2.562178134918213
Validation loss: 2.634285648663839

Epoch: 6| Step: 3
Training loss: 3.36409330368042
Validation loss: 2.6312588850657144

Epoch: 6| Step: 4
Training loss: 2.8966879844665527
Validation loss: 2.629164934158325

Epoch: 6| Step: 5
Training loss: 2.6758549213409424
Validation loss: 2.6250420411427817

Epoch: 6| Step: 6
Training loss: 2.7661805152893066
Validation loss: 2.6230454444885254

Epoch: 6| Step: 7
Training loss: 2.8871421813964844
Validation loss: 2.6231505076090493

Epoch: 6| Step: 8
Training loss: 3.289255142211914
Validation loss: 2.618306795756022

Epoch: 6| Step: 9
Training loss: 2.508646011352539
Validation loss: 2.613500197728475

Epoch: 6| Step: 10
Training loss: 2.767979621887207
Validation loss: 2.6084732015927634

Epoch: 6| Step: 11
Training loss: 2.2748284339904785
Validation loss: 2.603934367497762

Epoch: 6| Step: 12
Training loss: 2.6612417697906494
Validation loss: 2.603548606236776

Epoch: 6| Step: 13
Training loss: 2.79246187210083
Validation loss: 2.5951189200083413

Epoch: 38| Step: 0
Training loss: 2.298377513885498
Validation loss: 2.593378702799479

Epoch: 6| Step: 1
Training loss: 2.7359633445739746
Validation loss: 2.588470379511515

Epoch: 6| Step: 2
Training loss: 2.818948984146118
Validation loss: 2.5840256611506143

Epoch: 6| Step: 3
Training loss: 2.5503883361816406
Validation loss: 2.583117445309957

Epoch: 6| Step: 4
Training loss: 2.0124032497406006
Validation loss: 2.578738490740458

Epoch: 6| Step: 5
Training loss: 2.7836763858795166
Validation loss: 2.5745466152826944

Epoch: 6| Step: 6
Training loss: 1.906607747077942
Validation loss: 2.574274738629659

Epoch: 6| Step: 7
Training loss: 3.613309144973755
Validation loss: 2.5750120083491006

Epoch: 6| Step: 8
Training loss: 3.2533323764801025
Validation loss: 2.5690382719039917

Epoch: 6| Step: 9
Training loss: 2.655463933944702
Validation loss: 2.563050548235575

Epoch: 6| Step: 10
Training loss: 4.098278999328613
Validation loss: 2.5569684505462646

Epoch: 6| Step: 11
Training loss: 2.8450396060943604
Validation loss: 2.555487255255381

Epoch: 6| Step: 12
Training loss: 2.412263870239258
Validation loss: 2.5524763266245523

Epoch: 6| Step: 13
Training loss: 2.818483352661133
Validation loss: 2.550114393234253

Epoch: 39| Step: 0
Training loss: 3.3729805946350098
Validation loss: 2.546946167945862

Epoch: 6| Step: 1
Training loss: 2.8210065364837646
Validation loss: 2.547286113103231

Epoch: 6| Step: 2
Training loss: 3.114931583404541
Validation loss: 2.5423137744267783

Epoch: 6| Step: 3
Training loss: 2.683260917663574
Validation loss: 2.540169358253479

Epoch: 6| Step: 4
Training loss: 2.3269166946411133
Validation loss: 2.5391809940338135

Epoch: 6| Step: 5
Training loss: 2.344316005706787
Validation loss: 2.535760521888733

Epoch: 6| Step: 6
Training loss: 2.745434284210205
Validation loss: 2.531761725743612

Epoch: 6| Step: 7
Training loss: 2.9489645957946777
Validation loss: 2.5306020975112915

Epoch: 6| Step: 8
Training loss: 2.626779794692993
Validation loss: 2.526720960934957

Epoch: 6| Step: 9
Training loss: 2.368114471435547
Validation loss: 2.5193869272867837

Epoch: 6| Step: 10
Training loss: 2.3740735054016113
Validation loss: 2.51404070854187

Epoch: 6| Step: 11
Training loss: 2.6176059246063232
Validation loss: 2.5110438664754233

Epoch: 6| Step: 12
Training loss: 3.145651340484619
Validation loss: 2.507843315601349

Epoch: 6| Step: 13
Training loss: 2.675895929336548
Validation loss: 2.506090203921

Epoch: 40| Step: 0
Training loss: 2.717388153076172
Validation loss: 2.5053521394729614

Epoch: 6| Step: 1
Training loss: 2.5453109741210938
Validation loss: 2.499870220820109

Epoch: 6| Step: 2
Training loss: 2.407320022583008
Validation loss: 2.4975098768870034

Epoch: 6| Step: 3
Training loss: 2.6884117126464844
Validation loss: 2.49298365910848

Epoch: 6| Step: 4
Training loss: 2.001704216003418
Validation loss: 2.4912878274917603

Epoch: 6| Step: 5
Training loss: 3.2434282302856445
Validation loss: 2.486271301905314

Epoch: 6| Step: 6
Training loss: 2.7647666931152344
Validation loss: 2.482131997744242

Epoch: 6| Step: 7
Training loss: 2.516309976577759
Validation loss: 2.4808808962504068

Epoch: 6| Step: 8
Training loss: 2.7920491695404053
Validation loss: 2.4759640296300254

Epoch: 6| Step: 9
Training loss: 2.5023534297943115
Validation loss: 2.4731488625208535

Epoch: 6| Step: 10
Training loss: 2.3479323387145996
Validation loss: 2.4698726336161294

Epoch: 6| Step: 11
Training loss: 2.690366744995117
Validation loss: 2.4663299322128296

Epoch: 6| Step: 12
Training loss: 3.3239197731018066
Validation loss: 2.465670903523763

Epoch: 6| Step: 13
Training loss: 2.923272132873535
Validation loss: 2.4628122647603354

Epoch: 41| Step: 0
Training loss: 1.9793845415115356
Validation loss: 2.4589685996373496

Epoch: 6| Step: 1
Training loss: 3.025805711746216
Validation loss: 2.4558319052060447

Epoch: 6| Step: 2
Training loss: 2.8842504024505615
Validation loss: 2.4538978735605874

Epoch: 6| Step: 3
Training loss: 2.716566801071167
Validation loss: 2.448913037776947

Epoch: 6| Step: 4
Training loss: 2.4098477363586426
Validation loss: 2.448304454485575

Epoch: 6| Step: 5
Training loss: 3.199343681335449
Validation loss: 2.4437993367513022

Epoch: 6| Step: 6
Training loss: 2.6275341510772705
Validation loss: 2.4462165435155234

Epoch: 6| Step: 7
Training loss: 2.537794589996338
Validation loss: 2.4429873625437417

Epoch: 6| Step: 8
Training loss: 2.4171085357666016
Validation loss: 2.439391295115153

Epoch: 6| Step: 9
Training loss: 3.1477158069610596
Validation loss: 2.436215400695801

Epoch: 6| Step: 10
Training loss: 2.7489562034606934
Validation loss: 2.4350139697392783

Epoch: 6| Step: 11
Training loss: 2.0640525817871094
Validation loss: 2.434059977531433

Epoch: 6| Step: 12
Training loss: 2.9876861572265625
Validation loss: 2.4297342697779336

Epoch: 6| Step: 13
Training loss: 2.139157772064209
Validation loss: 2.4240885972976685

Epoch: 42| Step: 0
Training loss: 2.4537930488586426
Validation loss: 2.4220253427823386

Epoch: 6| Step: 1
Training loss: 2.710789918899536
Validation loss: 2.4161630074183145

Epoch: 6| Step: 2
Training loss: 3.00388765335083
Validation loss: 2.4136834939320884

Epoch: 6| Step: 3
Training loss: 2.9963107109069824
Validation loss: 2.4112199942270913

Epoch: 6| Step: 4
Training loss: 2.3304715156555176
Validation loss: 2.4060539404551187

Epoch: 6| Step: 5
Training loss: 3.002558708190918
Validation loss: 2.407103419303894

Epoch: 6| Step: 6
Training loss: 2.6973347663879395
Validation loss: 2.4076252977053323

Epoch: 6| Step: 7
Training loss: 2.9326558113098145
Validation loss: 2.4005743265151978

Epoch: 6| Step: 8
Training loss: 2.4611477851867676
Validation loss: 2.3959072828292847

Epoch: 6| Step: 9
Training loss: 2.478466510772705
Validation loss: 2.394803782304128

Epoch: 6| Step: 10
Training loss: 2.994974136352539
Validation loss: 2.3925084273020425

Epoch: 6| Step: 11
Training loss: 2.086331844329834
Validation loss: 2.387553850809733

Epoch: 6| Step: 12
Training loss: 2.06553053855896
Validation loss: 2.3855586846669516

Epoch: 6| Step: 13
Training loss: 1.994322657585144
Validation loss: 2.382291555404663

Epoch: 43| Step: 0
Training loss: 2.3274292945861816
Validation loss: 2.382047255833944

Epoch: 6| Step: 1
Training loss: 2.5757875442504883
Validation loss: 2.3787115613619485

Epoch: 6| Step: 2
Training loss: 2.490882396697998
Validation loss: 2.377150615056356

Epoch: 6| Step: 3
Training loss: 2.4521484375
Validation loss: 2.372527321179708

Epoch: 6| Step: 4
Training loss: 2.050823926925659
Validation loss: 2.369576891263326

Epoch: 6| Step: 5
Training loss: 2.5062413215637207
Validation loss: 2.369252403577169

Epoch: 6| Step: 6
Training loss: 2.7533798217773438
Validation loss: 2.3679054776827493

Epoch: 6| Step: 7
Training loss: 2.91713547706604
Validation loss: 2.3634804089864097

Epoch: 6| Step: 8
Training loss: 2.3323402404785156
Validation loss: 2.360722462336222

Epoch: 6| Step: 9
Training loss: 2.6605796813964844
Validation loss: 2.356778939565023

Epoch: 6| Step: 10
Training loss: 2.733945846557617
Validation loss: 2.354327837626139

Epoch: 6| Step: 11
Training loss: 2.340479612350464
Validation loss: 2.352258324623108

Epoch: 6| Step: 12
Training loss: 2.472778081893921
Validation loss: 2.348755439122518

Epoch: 6| Step: 13
Training loss: 2.9622745513916016
Validation loss: 2.3468744357426963

Epoch: 44| Step: 0
Training loss: 1.6422374248504639
Validation loss: 2.3459405501683555

Epoch: 6| Step: 1
Training loss: 2.1655585765838623
Validation loss: 2.337429324785868

Epoch: 6| Step: 2
Training loss: 2.7511684894561768
Validation loss: 2.3443773984909058

Epoch: 6| Step: 3
Training loss: 2.9789276123046875
Validation loss: 2.3492013812065125

Epoch: 6| Step: 4
Training loss: 2.5683250427246094
Validation loss: 2.3698770006497702

Epoch: 6| Step: 5
Training loss: 2.7487449645996094
Validation loss: 2.3584953943888345

Epoch: 6| Step: 6
Training loss: 3.122653007507324
Validation loss: 2.3297701676686606

Epoch: 6| Step: 7
Training loss: 2.6038713455200195
Validation loss: 2.3231119314829507

Epoch: 6| Step: 8
Training loss: 2.797600269317627
Validation loss: 2.3267568747202554

Epoch: 6| Step: 9
Training loss: 2.444352388381958
Validation loss: 2.3347777128219604

Epoch: 6| Step: 10
Training loss: 2.776333808898926
Validation loss: 2.350825786590576

Epoch: 6| Step: 11
Training loss: 1.900097131729126
Validation loss: 2.3499219020207724

Epoch: 6| Step: 12
Training loss: 2.698923349380493
Validation loss: 2.3439310789108276

Epoch: 6| Step: 13
Training loss: 2.0296521186828613
Validation loss: 2.3336612780888877

Epoch: 45| Step: 0
Training loss: 2.812227487564087
Validation loss: 2.325480818748474

Epoch: 6| Step: 1
Training loss: 2.2363579273223877
Validation loss: 2.3146464427312217

Epoch: 6| Step: 2
Training loss: 2.1065659523010254
Validation loss: 2.3076173067092896

Epoch: 6| Step: 3
Training loss: 2.6415677070617676
Validation loss: 2.304050346215566

Epoch: 6| Step: 4
Training loss: 3.3358168601989746
Validation loss: 2.297948658466339

Epoch: 6| Step: 5
Training loss: 2.6753368377685547
Validation loss: 2.293456514676412

Epoch: 6| Step: 6
Training loss: 2.085075855255127
Validation loss: 2.2913803259531655

Epoch: 6| Step: 7
Training loss: 2.219989776611328
Validation loss: 2.3027401169141135

Epoch: 6| Step: 8
Training loss: 2.9464426040649414
Validation loss: 2.299052894115448

Epoch: 6| Step: 9
Training loss: 2.320195198059082
Validation loss: 2.2980767289797464

Epoch: 6| Step: 10
Training loss: 2.424341917037964
Validation loss: 2.289316455523173

Epoch: 6| Step: 11
Training loss: 2.7845282554626465
Validation loss: 2.2835559447606406

Epoch: 6| Step: 12
Training loss: 1.7144566774368286
Validation loss: 2.279771169026693

Epoch: 6| Step: 13
Training loss: 2.250096082687378
Validation loss: 2.278562605381012

Epoch: 46| Step: 0
Training loss: 2.468021869659424
Validation loss: 2.2772818207740784

Epoch: 6| Step: 1
Training loss: 1.9703706502914429
Validation loss: 2.274405002593994

Epoch: 6| Step: 2
Training loss: 1.868532419204712
Validation loss: 2.273065745830536

Epoch: 6| Step: 3
Training loss: 2.5469136238098145
Validation loss: 2.2719637552897134

Epoch: 6| Step: 4
Training loss: 2.337061882019043
Validation loss: 2.269198417663574

Epoch: 6| Step: 5
Training loss: 2.4382834434509277
Validation loss: 2.2658353646596274

Epoch: 6| Step: 6
Training loss: 2.8824281692504883
Validation loss: 2.2651657859484353

Epoch: 6| Step: 7
Training loss: 2.265854597091675
Validation loss: 2.259748895963033

Epoch: 6| Step: 8
Training loss: 2.907909631729126
Validation loss: 2.25869490702947

Epoch: 6| Step: 9
Training loss: 2.717984914779663
Validation loss: 2.25330384572347

Epoch: 6| Step: 10
Training loss: 2.1235251426696777
Validation loss: 2.2631083329518638

Epoch: 6| Step: 11
Training loss: 2.0849266052246094
Validation loss: 2.2558295925458274

Epoch: 6| Step: 12
Training loss: 2.5834975242614746
Validation loss: 2.2584235270818076

Epoch: 6| Step: 13
Training loss: 2.7089061737060547
Validation loss: 2.2635501821835837

Epoch: 47| Step: 0
Training loss: 2.374955892562866
Validation loss: 2.246275623639425

Epoch: 6| Step: 1
Training loss: 2.149496078491211
Validation loss: 2.247180422147115

Epoch: 6| Step: 2
Training loss: 1.7193775177001953
Validation loss: 2.262979725996653

Epoch: 6| Step: 3
Training loss: 2.6370644569396973
Validation loss: 2.2470703721046448

Epoch: 6| Step: 4
Training loss: 2.4353549480438232
Validation loss: 2.2286625504493713

Epoch: 6| Step: 5
Training loss: 2.132544994354248
Validation loss: 2.223953644434611

Epoch: 6| Step: 6
Training loss: 2.8174819946289062
Validation loss: 2.2278502782185874

Epoch: 6| Step: 7
Training loss: 2.7895150184631348
Validation loss: 2.234197417894999

Epoch: 6| Step: 8
Training loss: 2.078354835510254
Validation loss: 2.2341225147247314

Epoch: 6| Step: 9
Training loss: 3.250415802001953
Validation loss: 2.237942357858022

Epoch: 6| Step: 10
Training loss: 1.909147024154663
Validation loss: 2.2355409463246665

Epoch: 6| Step: 11
Training loss: 2.159789562225342
Validation loss: 2.230880339940389

Epoch: 6| Step: 12
Training loss: 2.6950161457061768
Validation loss: 2.2270137468973794

Epoch: 6| Step: 13
Training loss: 2.311563014984131
Validation loss: 2.220398783683777

Epoch: 48| Step: 0
Training loss: 1.9120756387710571
Validation loss: 2.217379570007324

Epoch: 6| Step: 1
Training loss: 2.3812689781188965
Validation loss: 2.213345011075338

Epoch: 6| Step: 2
Training loss: 2.3793394565582275
Validation loss: 2.2070053021113076

Epoch: 6| Step: 3
Training loss: 2.358595848083496
Validation loss: 2.203341543674469

Epoch: 6| Step: 4
Training loss: 2.0826892852783203
Validation loss: 2.2007369995117188

Epoch: 6| Step: 5
Training loss: 2.9877498149871826
Validation loss: 2.200565457344055

Epoch: 6| Step: 6
Training loss: 2.382378101348877
Validation loss: 2.1996239026387534

Epoch: 6| Step: 7
Training loss: 2.633328914642334
Validation loss: 2.1927987933158875

Epoch: 6| Step: 8
Training loss: 2.0104012489318848
Validation loss: 2.1942501068115234

Epoch: 6| Step: 9
Training loss: 2.2435250282287598
Validation loss: 2.1853005091349282

Epoch: 6| Step: 10
Training loss: 1.637431263923645
Validation loss: 2.182984213034312

Epoch: 6| Step: 11
Training loss: 2.5550477504730225
Validation loss: 2.1849355896313987

Epoch: 6| Step: 12
Training loss: 2.7955994606018066
Validation loss: 2.1805310249328613

Epoch: 6| Step: 13
Training loss: 2.5445525646209717
Validation loss: 2.1805421312650046

Epoch: 49| Step: 0
Training loss: 1.7904565334320068
Validation loss: 2.182144343852997

Epoch: 6| Step: 1
Training loss: 2.446199893951416
Validation loss: 2.177215496699015

Epoch: 6| Step: 2
Training loss: 2.202317953109741
Validation loss: 2.172202547391256

Epoch: 6| Step: 3
Training loss: 2.4589428901672363
Validation loss: 2.1752903064092

Epoch: 6| Step: 4
Training loss: 3.2599973678588867
Validation loss: 2.1687442461649575

Epoch: 6| Step: 5
Training loss: 2.7859718799591064
Validation loss: 2.171835780143738

Epoch: 6| Step: 6
Training loss: 2.6974074840545654
Validation loss: 2.1659259597460427

Epoch: 6| Step: 7
Training loss: 2.439028263092041
Validation loss: 2.1718682646751404

Epoch: 6| Step: 8
Training loss: 2.389406681060791
Validation loss: 2.1693735917409263

Epoch: 6| Step: 9
Training loss: 1.8878737688064575
Validation loss: 2.173512637615204

Epoch: 6| Step: 10
Training loss: 1.8743958473205566
Validation loss: 2.160143772761027

Epoch: 6| Step: 11
Training loss: 2.7799978256225586
Validation loss: 2.15805447101593

Epoch: 6| Step: 12
Training loss: 1.7862093448638916
Validation loss: 2.1572174628575644

Epoch: 6| Step: 13
Training loss: 1.6008384227752686
Validation loss: 2.150533457597097

Epoch: 50| Step: 0
Training loss: 2.29250431060791
Validation loss: 2.160577356815338

Epoch: 6| Step: 1
Training loss: 2.3505938053131104
Validation loss: 2.158978521823883

Epoch: 6| Step: 2
Training loss: 2.324211359024048
Validation loss: 2.1488250692685447

Epoch: 6| Step: 3
Training loss: 2.5404529571533203
Validation loss: 2.155905226866404

Epoch: 6| Step: 4
Training loss: 2.346639633178711
Validation loss: 2.1496773759524026

Epoch: 6| Step: 5
Training loss: 2.202622890472412
Validation loss: 2.1527015368143716

Epoch: 6| Step: 6
Training loss: 2.492724895477295
Validation loss: 2.154818594455719

Epoch: 6| Step: 7
Training loss: 2.2109456062316895
Validation loss: 2.1597408850987754

Epoch: 6| Step: 8
Training loss: 2.5154523849487305
Validation loss: 2.1605411966641745

Epoch: 6| Step: 9
Training loss: 2.287001132965088
Validation loss: 2.1639792124430337

Epoch: 6| Step: 10
Training loss: 1.8356536626815796
Validation loss: 2.160324772198995

Epoch: 6| Step: 11
Training loss: 2.6349058151245117
Validation loss: 2.1670549313227334

Epoch: 6| Step: 12
Training loss: 1.8462826013565063
Validation loss: 2.1615660587946572

Epoch: 6| Step: 13
Training loss: 2.563671827316284
Validation loss: 2.158894201119741

Epoch: 51| Step: 0
Training loss: 1.803429365158081
Validation loss: 2.156272749106089

Epoch: 6| Step: 1
Training loss: 1.9145914316177368
Validation loss: 2.1568835179011026

Epoch: 6| Step: 2
Training loss: 2.8421599864959717
Validation loss: 2.1529253721237183

Epoch: 6| Step: 3
Training loss: 2.3403420448303223
Validation loss: 2.1471508145332336

Epoch: 6| Step: 4
Training loss: 2.6153082847595215
Validation loss: 2.1464213530222573

Epoch: 6| Step: 5
Training loss: 2.791995048522949
Validation loss: 2.1427628993988037

Epoch: 6| Step: 6
Training loss: 1.7857508659362793
Validation loss: 2.1358614365259805

Epoch: 6| Step: 7
Training loss: 2.41024112701416
Validation loss: 2.137218713760376

Epoch: 6| Step: 8
Training loss: 2.7834830284118652
Validation loss: 2.12773859500885

Epoch: 6| Step: 9
Training loss: 1.8711776733398438
Validation loss: 2.1215492288271585

Epoch: 6| Step: 10
Training loss: 2.012979745864868
Validation loss: 2.1297677556673684

Epoch: 6| Step: 11
Training loss: 2.291347026824951
Validation loss: 2.14056388537089

Epoch: 6| Step: 12
Training loss: 2.6189053058624268
Validation loss: 2.1423793832461038

Epoch: 6| Step: 13
Training loss: 2.1888670921325684
Validation loss: 2.160526235898336

Epoch: 52| Step: 0
Training loss: 2.676853656768799
Validation loss: 2.150869905948639

Epoch: 6| Step: 1
Training loss: 2.2663068771362305
Validation loss: 2.1424347162246704

Epoch: 6| Step: 2
Training loss: 2.6619577407836914
Validation loss: 2.1452689170837402

Epoch: 6| Step: 3
Training loss: 2.1420140266418457
Validation loss: 2.1331544319788613

Epoch: 6| Step: 4
Training loss: 2.6102190017700195
Validation loss: 2.1173552870750427

Epoch: 6| Step: 5
Training loss: 2.2974162101745605
Validation loss: 2.116745630900065

Epoch: 6| Step: 6
Training loss: 2.350682497024536
Validation loss: 2.1206343173980713

Epoch: 6| Step: 7
Training loss: 2.060248613357544
Validation loss: 2.1180326739947

Epoch: 6| Step: 8
Training loss: 1.9009742736816406
Validation loss: 2.1163125236829123

Epoch: 6| Step: 9
Training loss: 1.47610342502594
Validation loss: 2.1168504556020102

Epoch: 6| Step: 10
Training loss: 2.1790261268615723
Validation loss: 2.1195908387502036

Epoch: 6| Step: 11
Training loss: 2.467362403869629
Validation loss: 2.1176830530166626

Epoch: 6| Step: 12
Training loss: 2.2659592628479004
Validation loss: 2.1127094626426697

Epoch: 6| Step: 13
Training loss: 2.633894681930542
Validation loss: 2.1145061254501343

Epoch: 53| Step: 0
Training loss: 2.4676129817962646
Validation loss: 2.105273485183716

Epoch: 6| Step: 1
Training loss: 2.4078197479248047
Validation loss: 2.103164851665497

Epoch: 6| Step: 2
Training loss: 1.8025765419006348
Validation loss: 2.1061009764671326

Epoch: 6| Step: 3
Training loss: 2.0996015071868896
Validation loss: 2.0991571148236594

Epoch: 6| Step: 4
Training loss: 2.7188687324523926
Validation loss: 2.100960294405619

Epoch: 6| Step: 5
Training loss: 2.2296035289764404
Validation loss: 2.1262476444244385

Epoch: 6| Step: 6
Training loss: 1.7101142406463623
Validation loss: 2.125506560007731

Epoch: 6| Step: 7
Training loss: 2.026193141937256
Validation loss: 2.1096599102020264

Epoch: 6| Step: 8
Training loss: 2.799570083618164
Validation loss: 2.117488423983256

Epoch: 6| Step: 9
Training loss: 3.052001476287842
Validation loss: 2.102309763431549

Epoch: 6| Step: 10
Training loss: 2.2058212757110596
Validation loss: 2.08951473236084

Epoch: 6| Step: 11
Training loss: 2.0511884689331055
Validation loss: 2.0903995037078857

Epoch: 6| Step: 12
Training loss: 2.8240694999694824
Validation loss: 2.1032264828681946

Epoch: 6| Step: 13
Training loss: 1.4756202697753906
Validation loss: 2.1157798568407693

Epoch: 54| Step: 0
Training loss: 2.3070068359375
Validation loss: 2.122682491938273

Epoch: 6| Step: 1
Training loss: 2.3596014976501465
Validation loss: 2.132804214954376

Epoch: 6| Step: 2
Training loss: 2.6725316047668457
Validation loss: 2.126228392124176

Epoch: 6| Step: 3
Training loss: 2.808027744293213
Validation loss: 2.133592148621877

Epoch: 6| Step: 4
Training loss: 1.983215093612671
Validation loss: 2.127134641011556

Epoch: 6| Step: 5
Training loss: 2.563054084777832
Validation loss: 2.121515373388926

Epoch: 6| Step: 6
Training loss: 2.1870250701904297
Validation loss: 2.1196629405021667

Epoch: 6| Step: 7
Training loss: 2.6098833084106445
Validation loss: 2.1076746582984924

Epoch: 6| Step: 8
Training loss: 1.6298973560333252
Validation loss: 2.105909526348114

Epoch: 6| Step: 9
Training loss: 2.722829818725586
Validation loss: 2.1008472045262656

Epoch: 6| Step: 10
Training loss: 2.0862534046173096
Validation loss: 2.096746544043223

Epoch: 6| Step: 11
Training loss: 1.8453187942504883
Validation loss: 2.095548093318939

Epoch: 6| Step: 12
Training loss: 1.7874412536621094
Validation loss: 2.0907755494117737

Epoch: 6| Step: 13
Training loss: 2.526087999343872
Validation loss: 2.0796013673146567

Epoch: 55| Step: 0
Training loss: 1.4873793125152588
Validation loss: 2.081576108932495

Epoch: 6| Step: 1
Training loss: 1.6457144021987915
Validation loss: 2.0838743845621743

Epoch: 6| Step: 2
Training loss: 2.3154191970825195
Validation loss: 2.0799880623817444

Epoch: 6| Step: 3
Training loss: 2.6011762619018555
Validation loss: 2.0815980434417725

Epoch: 6| Step: 4
Training loss: 1.7717175483703613
Validation loss: 2.0773828824361167

Epoch: 6| Step: 5
Training loss: 2.9890429973602295
Validation loss: 2.0762654542922974

Epoch: 6| Step: 6
Training loss: 2.5660390853881836
Validation loss: 2.073387066523234

Epoch: 6| Step: 7
Training loss: 1.9486722946166992
Validation loss: 2.0796096523602805

Epoch: 6| Step: 8
Training loss: 2.3636786937713623
Validation loss: 2.07671986023585

Epoch: 6| Step: 9
Training loss: 2.513903856277466
Validation loss: 2.0745943586031594

Epoch: 6| Step: 10
Training loss: 2.113955020904541
Validation loss: 2.073782523473104

Epoch: 6| Step: 11
Training loss: 2.718865394592285
Validation loss: 2.0812455217043557

Epoch: 6| Step: 12
Training loss: 2.656404972076416
Validation loss: 2.074966231981913

Epoch: 6| Step: 13
Training loss: 1.9459346532821655
Validation loss: 2.0713396668434143

Epoch: 56| Step: 0
Training loss: 2.080597162246704
Validation loss: 2.0720357497533164

Epoch: 6| Step: 1
Training loss: 1.9389890432357788
Validation loss: 2.075730085372925

Epoch: 6| Step: 2
Training loss: 1.9281723499298096
Validation loss: 2.0872331658999124

Epoch: 6| Step: 3
Training loss: 2.8803281784057617
Validation loss: 2.0894739826520285

Epoch: 6| Step: 4
Training loss: 3.169424057006836
Validation loss: 2.109036902586619

Epoch: 6| Step: 5
Training loss: 2.3995113372802734
Validation loss: 2.091391444206238

Epoch: 6| Step: 6
Training loss: 2.5652475357055664
Validation loss: 2.0886351466178894

Epoch: 6| Step: 7
Training loss: 2.2684144973754883
Validation loss: 2.0765671531359353

Epoch: 6| Step: 8
Training loss: 2.2888970375061035
Validation loss: 2.068222145239512

Epoch: 6| Step: 9
Training loss: 2.346041679382324
Validation loss: 2.0646039247512817

Epoch: 6| Step: 10
Training loss: 2.0159642696380615
Validation loss: 2.061042368412018

Epoch: 6| Step: 11
Training loss: 1.9090687036514282
Validation loss: 2.0734234054883323

Epoch: 6| Step: 12
Training loss: 2.438821792602539
Validation loss: 2.0731930335362754

Epoch: 6| Step: 13
Training loss: 1.483195185661316
Validation loss: 2.08562962214152

Epoch: 57| Step: 0
Training loss: 2.8770787715911865
Validation loss: 2.0932100812594094

Epoch: 6| Step: 1
Training loss: 2.058720588684082
Validation loss: 2.101656198501587

Epoch: 6| Step: 2
Training loss: 2.3763532638549805
Validation loss: 2.113766630490621

Epoch: 6| Step: 3
Training loss: 2.251162528991699
Validation loss: 2.1202652057011924

Epoch: 6| Step: 4
Training loss: 2.066843032836914
Validation loss: 2.1301604509353638

Epoch: 6| Step: 5
Training loss: 2.327080726623535
Validation loss: 2.133458058039347

Epoch: 6| Step: 6
Training loss: 2.2030014991760254
Validation loss: 2.1331262985865274

Epoch: 6| Step: 7
Training loss: 2.2099547386169434
Validation loss: 2.1323741475741067

Epoch: 6| Step: 8
Training loss: 1.7448474168777466
Validation loss: 2.1259939869244895

Epoch: 6| Step: 9
Training loss: 2.514632225036621
Validation loss: 2.1170669992764792

Epoch: 6| Step: 10
Training loss: 2.5717363357543945
Validation loss: 2.10379950205485

Epoch: 6| Step: 11
Training loss: 2.277968168258667
Validation loss: 2.0922210613886514

Epoch: 6| Step: 12
Training loss: 2.5120670795440674
Validation loss: 2.0747804045677185

Epoch: 6| Step: 13
Training loss: 1.904749870300293
Validation loss: 2.0633559226989746

Epoch: 58| Step: 0
Training loss: 2.19693922996521
Validation loss: 2.051621397336324

Epoch: 6| Step: 1
Training loss: 1.7270135879516602
Validation loss: 2.0531872510910034

Epoch: 6| Step: 2
Training loss: 2.239412307739258
Validation loss: 2.0643317699432373

Epoch: 6| Step: 3
Training loss: 1.465101957321167
Validation loss: 2.079271614551544

Epoch: 6| Step: 4
Training loss: 2.4056949615478516
Validation loss: 2.097689628601074

Epoch: 6| Step: 5
Training loss: 2.0163328647613525
Validation loss: 2.076221764087677

Epoch: 6| Step: 6
Training loss: 2.000833511352539
Validation loss: 2.0714444518089294

Epoch: 6| Step: 7
Training loss: 2.41133451461792
Validation loss: 2.0601951479911804

Epoch: 6| Step: 8
Training loss: 2.2139620780944824
Validation loss: 2.057371358076731

Epoch: 6| Step: 9
Training loss: 2.220984935760498
Validation loss: 2.053977449735006

Epoch: 6| Step: 10
Training loss: 2.939164638519287
Validation loss: 2.053366740544637

Epoch: 6| Step: 11
Training loss: 2.7305078506469727
Validation loss: 2.048739790916443

Epoch: 6| Step: 12
Training loss: 2.553037405014038
Validation loss: 2.0535950660705566

Epoch: 6| Step: 13
Training loss: 2.343993902206421
Validation loss: 2.048809746901194

Epoch: 59| Step: 0
Training loss: 2.098780393600464
Validation loss: 2.045093357563019

Epoch: 6| Step: 1
Training loss: 1.7259103059768677
Validation loss: 2.043492555618286

Epoch: 6| Step: 2
Training loss: 2.047971487045288
Validation loss: 2.049464484055837

Epoch: 6| Step: 3
Training loss: 2.972377061843872
Validation loss: 2.0473804076512656

Epoch: 6| Step: 4
Training loss: 2.270273208618164
Validation loss: 2.047927975654602

Epoch: 6| Step: 5
Training loss: 1.9612112045288086
Validation loss: 2.049855569998423

Epoch: 6| Step: 6
Training loss: 2.055361747741699
Validation loss: 2.049021005630493

Epoch: 6| Step: 7
Training loss: 2.2018425464630127
Validation loss: 2.043106516202291

Epoch: 6| Step: 8
Training loss: 2.0447258949279785
Validation loss: 2.0423224171002707

Epoch: 6| Step: 9
Training loss: 2.1158699989318848
Validation loss: 2.0373289783795676

Epoch: 6| Step: 10
Training loss: 1.8899897336959839
Validation loss: 2.034800867239634

Epoch: 6| Step: 11
Training loss: 2.161454200744629
Validation loss: 2.0329293608665466

Epoch: 6| Step: 12
Training loss: 3.026170015335083
Validation loss: 2.047582725683848

Epoch: 6| Step: 13
Training loss: 2.5908455848693848
Validation loss: 2.032817284266154

Epoch: 60| Step: 0
Training loss: 2.524972438812256
Validation loss: 2.0359060168266296

Epoch: 6| Step: 1
Training loss: 2.011725664138794
Validation loss: 2.0295318365097046

Epoch: 6| Step: 2
Training loss: 1.6242361068725586
Validation loss: 2.03077898422877

Epoch: 6| Step: 3
Training loss: 2.929278612136841
Validation loss: 2.027892311414083

Epoch: 6| Step: 4
Training loss: 2.0278537273406982
Validation loss: 2.0302334825197854

Epoch: 6| Step: 5
Training loss: 2.7802891731262207
Validation loss: 2.0358848671118417

Epoch: 6| Step: 6
Training loss: 2.0089187622070312
Validation loss: 2.0406373341878257

Epoch: 6| Step: 7
Training loss: 2.044321060180664
Validation loss: 2.0465081930160522

Epoch: 6| Step: 8
Training loss: 1.834442377090454
Validation loss: 2.0496894121170044

Epoch: 6| Step: 9
Training loss: 2.413670063018799
Validation loss: 2.0522621671358743

Epoch: 6| Step: 10
Training loss: 1.9641004800796509
Validation loss: 2.0508447885513306

Epoch: 6| Step: 11
Training loss: 2.524817943572998
Validation loss: 2.058408339818319

Epoch: 6| Step: 12
Training loss: 2.51509690284729
Validation loss: 2.0450822710990906

Epoch: 6| Step: 13
Training loss: 1.857731580734253
Validation loss: 2.035606245199839

Epoch: 61| Step: 0
Training loss: 2.2879161834716797
Validation loss: 2.038637081782023

Epoch: 6| Step: 1
Training loss: 2.3431081771850586
Validation loss: 2.0343632300694785

Epoch: 6| Step: 2
Training loss: 1.9322128295898438
Validation loss: 2.05169008175532

Epoch: 6| Step: 3
Training loss: 3.079794406890869
Validation loss: 2.0758896668752036

Epoch: 6| Step: 4
Training loss: 2.0229058265686035
Validation loss: 2.0852842926979065

Epoch: 6| Step: 5
Training loss: 2.3735432624816895
Validation loss: 2.0641072392463684

Epoch: 6| Step: 6
Training loss: 2.1581435203552246
Validation loss: 2.056283712387085

Epoch: 6| Step: 7
Training loss: 1.9777863025665283
Validation loss: 2.0296945770581565

Epoch: 6| Step: 8
Training loss: 2.2076797485351562
Validation loss: 2.0336055159568787

Epoch: 6| Step: 9
Training loss: 2.4373655319213867
Validation loss: 2.0119502941767373

Epoch: 6| Step: 10
Training loss: 2.218470573425293
Validation loss: 2.028000056743622

Epoch: 6| Step: 11
Training loss: 2.5072181224823
Validation loss: 2.0275456309318542

Epoch: 6| Step: 12
Training loss: 1.5686531066894531
Validation loss: 2.0280563831329346

Epoch: 6| Step: 13
Training loss: 2.187413215637207
Validation loss: 2.0303282141685486

Epoch: 62| Step: 0
Training loss: 1.8887593746185303
Validation loss: 2.0186918576558432

Epoch: 6| Step: 1
Training loss: 3.0190513134002686
Validation loss: 2.0226502617200217

Epoch: 6| Step: 2
Training loss: 1.8194329738616943
Validation loss: 2.0137096643447876

Epoch: 6| Step: 3
Training loss: 2.4607558250427246
Validation loss: 2.021771470705668

Epoch: 6| Step: 4
Training loss: 1.668487310409546
Validation loss: 2.028568208217621

Epoch: 6| Step: 5
Training loss: 2.2236859798431396
Validation loss: 2.040569563706716

Epoch: 6| Step: 6
Training loss: 2.0825910568237305
Validation loss: 2.030320386091868

Epoch: 6| Step: 7
Training loss: 1.937718152999878
Validation loss: 2.035421073436737

Epoch: 6| Step: 8
Training loss: 2.1274328231811523
Validation loss: 2.0328222711881003

Epoch: 6| Step: 9
Training loss: 2.6046295166015625
Validation loss: 2.0193217595418296

Epoch: 6| Step: 10
Training loss: 2.4211337566375732
Validation loss: 2.0256688396135965

Epoch: 6| Step: 11
Training loss: 2.5978188514709473
Validation loss: 2.0382389624913535

Epoch: 6| Step: 12
Training loss: 2.086291790008545
Validation loss: 2.047740121682485

Epoch: 6| Step: 13
Training loss: 1.846123456954956
Validation loss: 2.0477883418401084

Epoch: 63| Step: 0
Training loss: 2.3342342376708984
Validation loss: 2.0487239559491477

Epoch: 6| Step: 1
Training loss: 2.4408133029937744
Validation loss: 2.064615229765574

Epoch: 6| Step: 2
Training loss: 2.443148136138916
Validation loss: 2.0671647985776267

Epoch: 6| Step: 3
Training loss: 1.8372441530227661
Validation loss: 2.0746189951896667

Epoch: 6| Step: 4
Training loss: 2.118208169937134
Validation loss: 2.075519939263662

Epoch: 6| Step: 5
Training loss: 2.5027055740356445
Validation loss: 2.074320137500763

Epoch: 6| Step: 6
Training loss: 2.2671315670013428
Validation loss: 2.061881204446157

Epoch: 6| Step: 7
Training loss: 1.9524387121200562
Validation loss: 2.053574879964193

Epoch: 6| Step: 8
Training loss: 2.445798635482788
Validation loss: 2.047532399495443

Epoch: 6| Step: 9
Training loss: 2.253828763961792
Validation loss: 2.0458575089772544

Epoch: 6| Step: 10
Training loss: 2.595949649810791
Validation loss: 2.0333277185757956

Epoch: 6| Step: 11
Training loss: 2.347573757171631
Validation loss: 2.0299529234568277

Epoch: 6| Step: 12
Training loss: 1.7650609016418457
Validation loss: 2.027819275856018

Epoch: 6| Step: 13
Training loss: 1.9703491926193237
Validation loss: 2.02334056297938

Epoch: 64| Step: 0
Training loss: 1.9756141901016235
Validation loss: 2.020062208175659

Epoch: 6| Step: 1
Training loss: 1.6151564121246338
Validation loss: 2.012721359729767

Epoch: 6| Step: 2
Training loss: 2.3234050273895264
Validation loss: 2.02301025390625

Epoch: 6| Step: 3
Training loss: 2.8501317501068115
Validation loss: 2.0227945844332376

Epoch: 6| Step: 4
Training loss: 2.202146530151367
Validation loss: 2.0281447370847068

Epoch: 6| Step: 5
Training loss: 2.0721664428710938
Validation loss: 2.0232075651486716

Epoch: 6| Step: 6
Training loss: 2.2826290130615234
Validation loss: 2.01937464872996

Epoch: 6| Step: 7
Training loss: 2.4241738319396973
Validation loss: 2.019332150618235

Epoch: 6| Step: 8
Training loss: 2.0476207733154297
Validation loss: 2.028845191001892

Epoch: 6| Step: 9
Training loss: 1.9611775875091553
Validation loss: 2.020737648010254

Epoch: 6| Step: 10
Training loss: 2.552778720855713
Validation loss: 2.022619585196177

Epoch: 6| Step: 11
Training loss: 2.194654941558838
Validation loss: 2.013079841931661

Epoch: 6| Step: 12
Training loss: 2.2634265422821045
Validation loss: 2.0167155663172402

Epoch: 6| Step: 13
Training loss: 1.9215515851974487
Validation loss: 2.0135773619016013

Epoch: 65| Step: 0
Training loss: 2.092444896697998
Validation loss: 2.0144295493761697

Epoch: 6| Step: 1
Training loss: 1.9954755306243896
Validation loss: 2.0157754023869834

Epoch: 6| Step: 2
Training loss: 1.846827507019043
Validation loss: 2.023351013660431

Epoch: 6| Step: 3
Training loss: 2.5712461471557617
Validation loss: 2.0247790614763894

Epoch: 6| Step: 4
Training loss: 1.7291584014892578
Validation loss: 2.0268690387407937

Epoch: 6| Step: 5
Training loss: 2.05983304977417
Validation loss: 2.0332359870274863

Epoch: 6| Step: 6
Training loss: 2.1846132278442383
Validation loss: 2.036874850591024

Epoch: 6| Step: 7
Training loss: 1.739713191986084
Validation loss: 2.0249974131584167

Epoch: 6| Step: 8
Training loss: 2.960709810256958
Validation loss: 2.028189222017924

Epoch: 6| Step: 9
Training loss: 2.693887233734131
Validation loss: 2.0243813395500183

Epoch: 6| Step: 10
Training loss: 2.545755386352539
Validation loss: 2.0190325379371643

Epoch: 6| Step: 11
Training loss: 2.2882285118103027
Validation loss: 2.0148553450902305

Epoch: 6| Step: 12
Training loss: 2.060281276702881
Validation loss: 2.021100620428721

Epoch: 6| Step: 13
Training loss: 1.9504876136779785
Validation loss: 2.0203589598337808

Epoch: 66| Step: 0
Training loss: 2.14731502532959
Validation loss: 2.022281587123871

Epoch: 6| Step: 1
Training loss: 2.1393229961395264
Validation loss: 2.026831030845642

Epoch: 6| Step: 2
Training loss: 1.7048373222351074
Validation loss: 2.044087012608846

Epoch: 6| Step: 3
Training loss: 2.0251338481903076
Validation loss: 2.0402406454086304

Epoch: 6| Step: 4
Training loss: 1.9461417198181152
Validation loss: 2.0433419148127236

Epoch: 6| Step: 5
Training loss: 2.451904296875
Validation loss: 2.043404698371887

Epoch: 6| Step: 6
Training loss: 1.7698514461517334
Validation loss: 2.053057154019674

Epoch: 6| Step: 7
Training loss: 2.470767021179199
Validation loss: 2.0561150113741555

Epoch: 6| Step: 8
Training loss: 1.8964009284973145
Validation loss: 2.0515990257263184

Epoch: 6| Step: 9
Training loss: 2.1988959312438965
Validation loss: 2.0553330977757773

Epoch: 6| Step: 10
Training loss: 2.4250311851501465
Validation loss: 2.047310014565786

Epoch: 6| Step: 11
Training loss: 2.2289438247680664
Validation loss: 2.0264755884806314

Epoch: 6| Step: 12
Training loss: 2.6078624725341797
Validation loss: 2.0195525487264

Epoch: 6| Step: 13
Training loss: 2.6807315349578857
Validation loss: 2.0256919066111245

Epoch: 67| Step: 0
Training loss: 2.0587148666381836
Validation loss: 2.0258886019388833

Epoch: 6| Step: 1
Training loss: 1.7052124738693237
Validation loss: 2.0327998797098794

Epoch: 6| Step: 2
Training loss: 2.13948917388916
Validation loss: 2.042997976144155

Epoch: 6| Step: 3
Training loss: 2.12613582611084
Validation loss: 2.052401383717855

Epoch: 6| Step: 4
Training loss: 2.2070436477661133
Validation loss: 2.0552783012390137

Epoch: 6| Step: 5
Training loss: 1.75157630443573
Validation loss: 2.054995914300283

Epoch: 6| Step: 6
Training loss: 2.554474115371704
Validation loss: 2.0506056547164917

Epoch: 6| Step: 7
Training loss: 2.3092384338378906
Validation loss: 2.046817123889923

Epoch: 6| Step: 8
Training loss: 1.9984889030456543
Validation loss: 2.052930474281311

Epoch: 6| Step: 9
Training loss: 2.393585205078125
Validation loss: 2.044151226679484

Epoch: 6| Step: 10
Training loss: 2.4651947021484375
Validation loss: 2.042118012905121

Epoch: 6| Step: 11
Training loss: 1.8628767728805542
Validation loss: 2.0391887426376343

Epoch: 6| Step: 12
Training loss: 2.3593907356262207
Validation loss: 2.037820359071096

Epoch: 6| Step: 13
Training loss: 2.88407564163208
Validation loss: 2.027274568875631

Epoch: 68| Step: 0
Training loss: 2.4065024852752686
Validation loss: 2.016801198323568

Epoch: 6| Step: 1
Training loss: 1.940230369567871
Validation loss: 2.0043120781580606

Epoch: 6| Step: 2
Training loss: 2.5169754028320312
Validation loss: 2.0046249826749167

Epoch: 6| Step: 3
Training loss: 1.9146112203598022
Validation loss: 2.0188568830490112

Epoch: 6| Step: 4
Training loss: 1.718748927116394
Validation loss: 2.019856611887614

Epoch: 6| Step: 5
Training loss: 2.5196921825408936
Validation loss: 2.0281869173049927

Epoch: 6| Step: 6
Training loss: 2.136051893234253
Validation loss: 2.0382264256477356

Epoch: 6| Step: 7
Training loss: 1.8115062713623047
Validation loss: 2.0372714400291443

Epoch: 6| Step: 8
Training loss: 2.029158115386963
Validation loss: 2.03398988644282

Epoch: 6| Step: 9
Training loss: 2.4608471393585205
Validation loss: 2.0130265951156616

Epoch: 6| Step: 10
Training loss: 2.122047185897827
Validation loss: 2.007336894671122

Epoch: 6| Step: 11
Training loss: 2.7989466190338135
Validation loss: 2.0132641792297363

Epoch: 6| Step: 12
Training loss: 2.2630972862243652
Validation loss: 2.020704130331675

Epoch: 6| Step: 13
Training loss: 1.8264155387878418
Validation loss: 2.033999025821686

Epoch: 69| Step: 0
Training loss: 2.17641019821167
Validation loss: 2.0427818099657693

Epoch: 6| Step: 1
Training loss: 2.394484043121338
Validation loss: 2.043686827023824

Epoch: 6| Step: 2
Training loss: 1.771424651145935
Validation loss: 2.0439326763153076

Epoch: 6| Step: 3
Training loss: 2.1635773181915283
Validation loss: 2.0407684048016868

Epoch: 6| Step: 4
Training loss: 2.5516490936279297
Validation loss: 2.0436166723569236

Epoch: 6| Step: 5
Training loss: 2.7236971855163574
Validation loss: 2.042605936527252

Epoch: 6| Step: 6
Training loss: 2.3370044231414795
Validation loss: 2.0370880564053855

Epoch: 6| Step: 7
Training loss: 2.0755724906921387
Validation loss: 2.038031796614329

Epoch: 6| Step: 8
Training loss: 1.9031014442443848
Validation loss: 2.029203395048777

Epoch: 6| Step: 9
Training loss: 1.8134491443634033
Validation loss: 2.021347244580587

Epoch: 6| Step: 10
Training loss: 2.1386938095092773
Validation loss: 2.0052918791770935

Epoch: 6| Step: 11
Training loss: 1.8106917142868042
Validation loss: 2.017004072666168

Epoch: 6| Step: 12
Training loss: 2.677833080291748
Validation loss: 2.012321352958679

Epoch: 6| Step: 13
Training loss: 2.131837844848633
Validation loss: 2.029126842816671

Epoch: 70| Step: 0
Training loss: 2.048184633255005
Validation loss: 2.020920236905416

Epoch: 6| Step: 1
Training loss: 2.214932441711426
Validation loss: 2.0369678934415183

Epoch: 6| Step: 2
Training loss: 1.949792742729187
Validation loss: 2.0214725335439048

Epoch: 6| Step: 3
Training loss: 2.3156371116638184
Validation loss: 2.0284366607666016

Epoch: 6| Step: 4
Training loss: 2.649606227874756
Validation loss: 2.0149552822113037

Epoch: 6| Step: 5
Training loss: 2.386387825012207
Validation loss: 2.0266817013422647

Epoch: 6| Step: 6
Training loss: 2.580207347869873
Validation loss: 2.0268560647964478

Epoch: 6| Step: 7
Training loss: 2.495388984680176
Validation loss: 2.0128060976664224

Epoch: 6| Step: 8
Training loss: 1.976141095161438
Validation loss: 2.017230828603109

Epoch: 6| Step: 9
Training loss: 2.1180033683776855
Validation loss: 2.0143887996673584

Epoch: 6| Step: 10
Training loss: 1.3977148532867432
Validation loss: 2.0167810718218484

Epoch: 6| Step: 11
Training loss: 1.8833330869674683
Validation loss: 2.0131792028745017

Epoch: 6| Step: 12
Training loss: 2.3149056434631348
Validation loss: 2.0127816200256348

Epoch: 6| Step: 13
Training loss: 1.997226357460022
Validation loss: 2.011942903200785

Epoch: 71| Step: 0
Training loss: 1.736971139907837
Validation loss: 2.012763758500417

Epoch: 6| Step: 1
Training loss: 2.0386579036712646
Validation loss: 2.018610636393229

Epoch: 6| Step: 2
Training loss: 2.7383463382720947
Validation loss: 2.0401336948076882

Epoch: 6| Step: 3
Training loss: 1.3666386604309082
Validation loss: 2.028136730194092

Epoch: 6| Step: 4
Training loss: 2.348118305206299
Validation loss: 2.033023496468862

Epoch: 6| Step: 5
Training loss: 2.5170106887817383
Validation loss: 2.0242290695508323

Epoch: 6| Step: 6
Training loss: 1.8595629930496216
Validation loss: 2.0218063592910767

Epoch: 6| Step: 7
Training loss: 1.8452078104019165
Validation loss: 2.014375706513723

Epoch: 6| Step: 8
Training loss: 2.304703950881958
Validation loss: 2.002509911855062

Epoch: 6| Step: 9
Training loss: 1.957761287689209
Validation loss: 2.0086724162101746

Epoch: 6| Step: 10
Training loss: 2.0617828369140625
Validation loss: 1.9990575313568115

Epoch: 6| Step: 11
Training loss: 2.249913215637207
Validation loss: 2.004443804423014

Epoch: 6| Step: 12
Training loss: 2.6466760635375977
Validation loss: 2.0012086828549704

Epoch: 6| Step: 13
Training loss: 2.5857107639312744
Validation loss: 2.007580022017161

Epoch: 72| Step: 0
Training loss: 1.8849421739578247
Validation loss: 1.9987043937047322

Epoch: 6| Step: 1
Training loss: 2.550748586654663
Validation loss: 2.0082850654919944

Epoch: 6| Step: 2
Training loss: 1.7326186895370483
Validation loss: 1.9990870952606201

Epoch: 6| Step: 3
Training loss: 1.973637342453003
Validation loss: 1.997233251730601

Epoch: 6| Step: 4
Training loss: 2.576648235321045
Validation loss: 2.011233389377594

Epoch: 6| Step: 5
Training loss: 2.7414233684539795
Validation loss: 2.013509134451548

Epoch: 6| Step: 6
Training loss: 1.831695556640625
Validation loss: 2.0176581541697183

Epoch: 6| Step: 7
Training loss: 1.7935940027236938
Validation loss: 2.015874683856964

Epoch: 6| Step: 8
Training loss: 2.2530832290649414
Validation loss: 2.006599009037018

Epoch: 6| Step: 9
Training loss: 1.8182566165924072
Validation loss: 2.0071311394373574

Epoch: 6| Step: 10
Training loss: 2.1319456100463867
Validation loss: 2.013270676136017

Epoch: 6| Step: 11
Training loss: 2.3812432289123535
Validation loss: 2.0071297883987427

Epoch: 6| Step: 12
Training loss: 2.568722724914551
Validation loss: 2.0027602910995483

Epoch: 6| Step: 13
Training loss: 1.9117481708526611
Validation loss: 2.00871870915095

Epoch: 73| Step: 0
Training loss: 2.3067941665649414
Validation loss: 2.002377430597941

Epoch: 6| Step: 1
Training loss: 1.5112791061401367
Validation loss: 2.0124071637789407

Epoch: 6| Step: 2
Training loss: 1.627142310142517
Validation loss: 2.004596730073293

Epoch: 6| Step: 3
Training loss: 2.381410598754883
Validation loss: 2.0236576000849404

Epoch: 6| Step: 4
Training loss: 2.1631999015808105
Validation loss: 2.0197101632754006

Epoch: 6| Step: 5
Training loss: 2.47575044631958
Validation loss: 2.0370091001192727

Epoch: 6| Step: 6
Training loss: 2.558936834335327
Validation loss: 2.043778936068217

Epoch: 6| Step: 7
Training loss: 1.5269392728805542
Validation loss: 2.0920857191085815

Epoch: 6| Step: 8
Training loss: 2.4551398754119873
Validation loss: 2.131530205408732

Epoch: 6| Step: 9
Training loss: 2.8122622966766357
Validation loss: 2.1313818295796714

Epoch: 6| Step: 10
Training loss: 2.209242582321167
Validation loss: 2.0849156975746155

Epoch: 6| Step: 11
Training loss: 2.5857439041137695
Validation loss: 2.0319810907046

Epoch: 6| Step: 12
Training loss: 2.3165762424468994
Validation loss: 2.0109225312868753

Epoch: 6| Step: 13
Training loss: 2.2123444080352783
Validation loss: 2.0143805543581643

Epoch: 74| Step: 0
Training loss: 2.072050094604492
Validation loss: 2.0277180075645447

Epoch: 6| Step: 1
Training loss: 2.58485746383667
Validation loss: 2.0420680046081543

Epoch: 6| Step: 2
Training loss: 2.1707539558410645
Validation loss: 2.049169878164927

Epoch: 6| Step: 3
Training loss: 2.5801830291748047
Validation loss: 2.0522557894388833

Epoch: 6| Step: 4
Training loss: 2.8007516860961914
Validation loss: 2.0555440187454224

Epoch: 6| Step: 5
Training loss: 1.8683362007141113
Validation loss: 2.060838202635447

Epoch: 6| Step: 6
Training loss: 2.542099714279175
Validation loss: 2.064461668332418

Epoch: 6| Step: 7
Training loss: 1.9971297979354858
Validation loss: 2.0652981201807656

Epoch: 6| Step: 8
Training loss: 1.9201469421386719
Validation loss: 2.075934410095215

Epoch: 6| Step: 9
Training loss: 1.9207954406738281
Validation loss: 2.063653806845347

Epoch: 6| Step: 10
Training loss: 2.3131892681121826
Validation loss: 2.063928484916687

Epoch: 6| Step: 11
Training loss: 2.110658645629883
Validation loss: 2.058498799800873

Epoch: 6| Step: 12
Training loss: 2.121856212615967
Validation loss: 2.05520361661911

Epoch: 6| Step: 13
Training loss: 2.354787826538086
Validation loss: 2.0471466183662415

Epoch: 75| Step: 0
Training loss: 2.737816095352173
Validation loss: 2.0415839552879333

Epoch: 6| Step: 1
Training loss: 1.7073932886123657
Validation loss: 2.0381292700767517

Epoch: 6| Step: 2
Training loss: 2.23203182220459
Validation loss: 2.038816968599955

Epoch: 6| Step: 3
Training loss: 2.751878499984741
Validation loss: 2.035644312699636

Epoch: 6| Step: 4
Training loss: 1.6383006572723389
Validation loss: 2.030681927998861

Epoch: 6| Step: 5
Training loss: 1.9142022132873535
Validation loss: 2.029298424720764

Epoch: 6| Step: 6
Training loss: 2.4730801582336426
Validation loss: 2.0209574500719705

Epoch: 6| Step: 7
Training loss: 2.4032645225524902
Validation loss: 2.0236729780832925

Epoch: 6| Step: 8
Training loss: 2.809053897857666
Validation loss: 2.0397302707036338

Epoch: 6| Step: 9
Training loss: 2.0455145835876465
Validation loss: 2.031049907207489

Epoch: 6| Step: 10
Training loss: 2.1771223545074463
Validation loss: 2.0388333002726235

Epoch: 6| Step: 11
Training loss: 2.0986168384552
Validation loss: 2.0215612053871155

Epoch: 6| Step: 12
Training loss: 1.7388889789581299
Validation loss: 2.012021541595459

Epoch: 6| Step: 13
Training loss: 2.1747360229492188
Validation loss: 2.021771411101023

Epoch: 76| Step: 0
Training loss: 2.2465932369232178
Validation loss: 2.020697017510732

Epoch: 6| Step: 1
Training loss: 2.541952133178711
Validation loss: 2.0190762678782144

Epoch: 6| Step: 2
Training loss: 2.0474469661712646
Validation loss: 2.0160025159517923

Epoch: 6| Step: 3
Training loss: 2.0083870887756348
Validation loss: 2.01655783255895

Epoch: 6| Step: 4
Training loss: 2.7154526710510254
Validation loss: 2.025840997695923

Epoch: 6| Step: 5
Training loss: 1.6858681440353394
Validation loss: 2.016047775745392

Epoch: 6| Step: 6
Training loss: 2.0644445419311523
Validation loss: 2.018527567386627

Epoch: 6| Step: 7
Training loss: 2.593992233276367
Validation loss: 2.025936186313629

Epoch: 6| Step: 8
Training loss: 2.0540151596069336
Validation loss: 2.0281540552775064

Epoch: 6| Step: 9
Training loss: 1.674290418624878
Validation loss: 2.0164226492245994

Epoch: 6| Step: 10
Training loss: 2.0765347480773926
Validation loss: 2.0269598364830017

Epoch: 6| Step: 11
Training loss: 1.6496928930282593
Validation loss: 2.029334525267283

Epoch: 6| Step: 12
Training loss: 1.9368544816970825
Validation loss: 2.0291875998179116

Epoch: 6| Step: 13
Training loss: 2.8839762210845947
Validation loss: 2.0166496435801187

Epoch: 77| Step: 0
Training loss: 1.6936213970184326
Validation loss: 2.011415104071299

Epoch: 6| Step: 1
Training loss: 2.688875436782837
Validation loss: 2.0079972743988037

Epoch: 6| Step: 2
Training loss: 2.580941677093506
Validation loss: 2.0061179995536804

Epoch: 6| Step: 3
Training loss: 1.5617733001708984
Validation loss: 2.001057247320811

Epoch: 6| Step: 4
Training loss: 2.6602606773376465
Validation loss: 2.0044546326001487

Epoch: 6| Step: 5
Training loss: 2.0171494483947754
Validation loss: 2.0031453172365823

Epoch: 6| Step: 6
Training loss: 2.292823076248169
Validation loss: 2.00233922402064

Epoch: 6| Step: 7
Training loss: 2.2709176540374756
Validation loss: 2.002268155415853

Epoch: 6| Step: 8
Training loss: 1.9314851760864258
Validation loss: 2.0124961137771606

Epoch: 6| Step: 9
Training loss: 2.245654344558716
Validation loss: 1.9996320406595867

Epoch: 6| Step: 10
Training loss: 1.872179627418518
Validation loss: 2.0112226208051047

Epoch: 6| Step: 11
Training loss: 2.223055124282837
Validation loss: 2.0143579641977944

Epoch: 6| Step: 12
Training loss: 2.6829779148101807
Validation loss: 2.0163105130195618

Epoch: 6| Step: 13
Training loss: 1.5045030117034912
Validation loss: 2.0084230105082193

Epoch: 78| Step: 0
Training loss: 2.1936850547790527
Validation loss: 2.0174667835235596

Epoch: 6| Step: 1
Training loss: 1.6850762367248535
Validation loss: 2.009495794773102

Epoch: 6| Step: 2
Training loss: 1.969605803489685
Validation loss: 2.008441944917043

Epoch: 6| Step: 3
Training loss: 2.3285281658172607
Validation loss: 2.0071061054865518

Epoch: 6| Step: 4
Training loss: 2.6884031295776367
Validation loss: 2.0000582337379456

Epoch: 6| Step: 5
Training loss: 2.005824565887451
Validation loss: 2.0032483537991843

Epoch: 6| Step: 6
Training loss: 1.9593358039855957
Validation loss: 2.0052733620007834

Epoch: 6| Step: 7
Training loss: 2.3029026985168457
Validation loss: 2.0037582914034524

Epoch: 6| Step: 8
Training loss: 2.80116605758667
Validation loss: 1.9990437229474385

Epoch: 6| Step: 9
Training loss: 2.1429429054260254
Validation loss: 2.0009535749753318

Epoch: 6| Step: 10
Training loss: 1.9905993938446045
Validation loss: 2.0052225987116494

Epoch: 6| Step: 11
Training loss: 2.5381762981414795
Validation loss: 2.0032556653022766

Epoch: 6| Step: 12
Training loss: 1.9363285303115845
Validation loss: 2.006258487701416

Epoch: 6| Step: 13
Training loss: 1.6574459075927734
Validation loss: 1.9988774259885151

Epoch: 79| Step: 0
Training loss: 1.6801362037658691
Validation loss: 2.0093072652816772

Epoch: 6| Step: 1
Training loss: 2.5765678882598877
Validation loss: 2.024244765440623

Epoch: 6| Step: 2
Training loss: 2.2442269325256348
Validation loss: 2.016804655392965

Epoch: 6| Step: 3
Training loss: 1.7683855295181274
Validation loss: 2.0098315676053367

Epoch: 6| Step: 4
Training loss: 2.115495204925537
Validation loss: 2.01298717657725

Epoch: 6| Step: 5
Training loss: 2.1848652362823486
Validation loss: 2.0095481475194297

Epoch: 6| Step: 6
Training loss: 2.5627222061157227
Validation loss: 2.0030791958173118

Epoch: 6| Step: 7
Training loss: 2.0046346187591553
Validation loss: 1.9983742237091064

Epoch: 6| Step: 8
Training loss: 2.8121047019958496
Validation loss: 1.9974884986877441

Epoch: 6| Step: 9
Training loss: 2.2328598499298096
Validation loss: 2.007496257623037

Epoch: 6| Step: 10
Training loss: 1.7409992218017578
Validation loss: 2.007692813873291

Epoch: 6| Step: 11
Training loss: 2.187507152557373
Validation loss: 2.0138128797213235

Epoch: 6| Step: 12
Training loss: 1.8351831436157227
Validation loss: 2.0091166496276855

Epoch: 6| Step: 13
Training loss: 2.087139129638672
Validation loss: 2.006535212198893

Epoch: 80| Step: 0
Training loss: 2.220252513885498
Validation loss: 2.0067050457000732

Epoch: 6| Step: 1
Training loss: 1.6791784763336182
Validation loss: 2.0106342236200967

Epoch: 6| Step: 2
Training loss: 2.0988821983337402
Validation loss: 2.015248457590739

Epoch: 6| Step: 3
Training loss: 1.7343229055404663
Validation loss: 2.004507561524709

Epoch: 6| Step: 4
Training loss: 2.44954776763916
Validation loss: 2.0108124812444053

Epoch: 6| Step: 5
Training loss: 2.245431423187256
Validation loss: 2.016396145025889

Epoch: 6| Step: 6
Training loss: 1.8908214569091797
Validation loss: 2.0288690328598022

Epoch: 6| Step: 7
Training loss: 2.2793936729431152
Validation loss: 2.0276538928349814

Epoch: 6| Step: 8
Training loss: 2.6944923400878906
Validation loss: 2.031144460042318

Epoch: 6| Step: 9
Training loss: 2.4120047092437744
Validation loss: 2.028967797756195

Epoch: 6| Step: 10
Training loss: 2.3128714561462402
Validation loss: 2.0279531677563987

Epoch: 6| Step: 11
Training loss: 1.8195010423660278
Validation loss: 2.026594122250875

Epoch: 6| Step: 12
Training loss: 1.8780875205993652
Validation loss: 2.009117603302002

Epoch: 6| Step: 13
Training loss: 2.1213040351867676
Validation loss: 2.0105393131573996

Epoch: 81| Step: 0
Training loss: 2.332468271255493
Validation loss: 2.009145736694336

Epoch: 6| Step: 1
Training loss: 1.8968521356582642
Validation loss: 2.009246826171875

Epoch: 6| Step: 2
Training loss: 2.0547585487365723
Validation loss: 2.0147417783737183

Epoch: 6| Step: 3
Training loss: 1.468569278717041
Validation loss: 2.0090254743893943

Epoch: 6| Step: 4
Training loss: 2.121985912322998
Validation loss: 2.008347769578298

Epoch: 6| Step: 5
Training loss: 2.7190356254577637
Validation loss: 2.0115610162417092

Epoch: 6| Step: 6
Training loss: 2.3318328857421875
Validation loss: 2.014558811982473

Epoch: 6| Step: 7
Training loss: 1.8158292770385742
Validation loss: 2.0131551225980124

Epoch: 6| Step: 8
Training loss: 2.1722922325134277
Validation loss: 2.0169923504193625

Epoch: 6| Step: 9
Training loss: 1.6865371465682983
Validation loss: 2.0161705215771994

Epoch: 6| Step: 10
Training loss: 2.4324378967285156
Validation loss: 2.0277308026949563

Epoch: 6| Step: 11
Training loss: 2.1345818042755127
Validation loss: 2.0240744948387146

Epoch: 6| Step: 12
Training loss: 2.880162477493286
Validation loss: 2.0305599570274353

Epoch: 6| Step: 13
Training loss: 2.0528531074523926
Validation loss: 2.02870637178421

Epoch: 82| Step: 0
Training loss: 1.842173457145691
Validation loss: 2.0294432242711387

Epoch: 6| Step: 1
Training loss: 2.309476137161255
Validation loss: 2.028187334537506

Epoch: 6| Step: 2
Training loss: 1.9502408504486084
Validation loss: 2.024236778418223

Epoch: 6| Step: 3
Training loss: 2.4457778930664062
Validation loss: 2.011854807535807

Epoch: 6| Step: 4
Training loss: 2.2102108001708984
Validation loss: 2.0097566843032837

Epoch: 6| Step: 5
Training loss: 2.3454411029815674
Validation loss: 2.0117180347442627

Epoch: 6| Step: 6
Training loss: 2.0289862155914307
Validation loss: 2.0225643515586853

Epoch: 6| Step: 7
Training loss: 2.2722654342651367
Validation loss: 2.0156145890553794

Epoch: 6| Step: 8
Training loss: 1.7574893236160278
Validation loss: 2.0292789141337075

Epoch: 6| Step: 9
Training loss: 2.3826963901519775
Validation loss: 2.03026690085729

Epoch: 6| Step: 10
Training loss: 2.07915997505188
Validation loss: 2.0365851322809854

Epoch: 6| Step: 11
Training loss: 2.219245433807373
Validation loss: 2.02282722791036

Epoch: 6| Step: 12
Training loss: 2.0008225440979004
Validation loss: 2.0216456055641174

Epoch: 6| Step: 13
Training loss: 1.9680798053741455
Validation loss: 2.0278472701708474

Epoch: 83| Step: 0
Training loss: 1.5994250774383545
Validation loss: 2.030045727888743

Epoch: 6| Step: 1
Training loss: 2.2081782817840576
Validation loss: 2.021582464377085

Epoch: 6| Step: 2
Training loss: 2.3368797302246094
Validation loss: 2.023261606693268

Epoch: 6| Step: 3
Training loss: 2.0537829399108887
Validation loss: 2.0213106274604797

Epoch: 6| Step: 4
Training loss: 1.5576611757278442
Validation loss: 2.0230138699213662

Epoch: 6| Step: 5
Training loss: 2.138185977935791
Validation loss: 2.0115155378977456

Epoch: 6| Step: 6
Training loss: 2.8856444358825684
Validation loss: 2.0171255668004355

Epoch: 6| Step: 7
Training loss: 2.1640067100524902
Validation loss: 2.014018972714742

Epoch: 6| Step: 8
Training loss: 1.8678414821624756
Validation loss: 2.0118698676427207

Epoch: 6| Step: 9
Training loss: 2.006377696990967
Validation loss: 2.0193530321121216

Epoch: 6| Step: 10
Training loss: 2.008476495742798
Validation loss: 2.0179931918780007

Epoch: 6| Step: 11
Training loss: 2.8514068126678467
Validation loss: 2.0226129293441772

Epoch: 6| Step: 12
Training loss: 2.4116878509521484
Validation loss: 2.0147201816240945

Epoch: 6| Step: 13
Training loss: 1.798299789428711
Validation loss: 2.0233711997667947

Epoch: 84| Step: 0
Training loss: 2.284369468688965
Validation loss: 2.022763510545095

Epoch: 6| Step: 1
Training loss: 2.707084894180298
Validation loss: 2.0248092214266458

Epoch: 6| Step: 2
Training loss: 1.396972894668579
Validation loss: 2.014594475428263

Epoch: 6| Step: 3
Training loss: 2.2919631004333496
Validation loss: 2.018923044204712

Epoch: 6| Step: 4
Training loss: 1.7995638847351074
Validation loss: 2.0178492863972983

Epoch: 6| Step: 5
Training loss: 2.0750603675842285
Validation loss: 2.026278555393219

Epoch: 6| Step: 6
Training loss: 2.3934268951416016
Validation loss: 2.0346984267234802

Epoch: 6| Step: 7
Training loss: 1.9200620651245117
Validation loss: 2.038198093573252

Epoch: 6| Step: 8
Training loss: 2.0326125621795654
Validation loss: 2.044282595316569

Epoch: 6| Step: 9
Training loss: 2.158829689025879
Validation loss: 2.032159070173899

Epoch: 6| Step: 10
Training loss: 2.6138765811920166
Validation loss: 2.0266300638516745

Epoch: 6| Step: 11
Training loss: 1.397767186164856
Validation loss: 2.0228318174680076

Epoch: 6| Step: 12
Training loss: 2.149171829223633
Validation loss: 2.013604005177816

Epoch: 6| Step: 13
Training loss: 2.6892590522766113
Validation loss: 2.0160605112711587

Epoch: 85| Step: 0
Training loss: 2.3349385261535645
Validation loss: 2.0156517823537192

Epoch: 6| Step: 1
Training loss: 1.996695637702942
Validation loss: 2.023501753807068

Epoch: 6| Step: 2
Training loss: 2.259911060333252
Validation loss: 2.02133446931839

Epoch: 6| Step: 3
Training loss: 2.1762661933898926
Validation loss: 2.007878581682841

Epoch: 6| Step: 4
Training loss: 2.2271218299865723
Validation loss: 2.007637838522593

Epoch: 6| Step: 5
Training loss: 1.8207921981811523
Validation loss: 1.9975803295771282

Epoch: 6| Step: 6
Training loss: 2.2208194732666016
Validation loss: 1.998739500840505

Epoch: 6| Step: 7
Training loss: 1.4611005783081055
Validation loss: 2.016978402932485

Epoch: 6| Step: 8
Training loss: 1.960153341293335
Validation loss: 2.0350442926088967

Epoch: 6| Step: 9
Training loss: 2.444542169570923
Validation loss: 2.055341124534607

Epoch: 6| Step: 10
Training loss: 2.1047778129577637
Validation loss: 2.05606476465861

Epoch: 6| Step: 11
Training loss: 2.3730363845825195
Validation loss: 2.05877556403478

Epoch: 6| Step: 12
Training loss: 2.6740260124206543
Validation loss: 2.024178147315979

Epoch: 6| Step: 13
Training loss: 1.9261282682418823
Validation loss: 2.011979858080546

Epoch: 86| Step: 0
Training loss: 1.0672004222869873
Validation loss: 2.0162338415781655

Epoch: 6| Step: 1
Training loss: 1.7890416383743286
Validation loss: 1.9965678453445435

Epoch: 6| Step: 2
Training loss: 1.6425520181655884
Validation loss: 2.000376840432485

Epoch: 6| Step: 3
Training loss: 2.166027069091797
Validation loss: 2.014158070087433

Epoch: 6| Step: 4
Training loss: 2.4010071754455566
Validation loss: 2.023301283518473

Epoch: 6| Step: 5
Training loss: 1.536360502243042
Validation loss: 2.018647094567617

Epoch: 6| Step: 6
Training loss: 2.0470266342163086
Validation loss: 2.0220153530438743

Epoch: 6| Step: 7
Training loss: 2.8978352546691895
Validation loss: 2.031088133653005

Epoch: 6| Step: 8
Training loss: 2.6316757202148438
Validation loss: 2.0303301016489663

Epoch: 6| Step: 9
Training loss: 2.613952159881592
Validation loss: 2.025833865006765

Epoch: 6| Step: 10
Training loss: 2.4349191188812256
Validation loss: 2.0259397427241006

Epoch: 6| Step: 11
Training loss: 2.1656761169433594
Validation loss: 2.008152345816294

Epoch: 6| Step: 12
Training loss: 2.0242834091186523
Validation loss: 2.017304281393687

Epoch: 6| Step: 13
Training loss: 2.6451992988586426
Validation loss: 2.016392230987549

Epoch: 87| Step: 0
Training loss: 2.46522855758667
Validation loss: 2.0131378173828125

Epoch: 6| Step: 1
Training loss: 1.8198769092559814
Validation loss: 2.0175952514012656

Epoch: 6| Step: 2
Training loss: 1.8165185451507568
Validation loss: 2.023463408152262

Epoch: 6| Step: 3
Training loss: 3.144653797149658
Validation loss: 2.0327694614728293

Epoch: 6| Step: 4
Training loss: 1.877432107925415
Validation loss: 2.035782059033712

Epoch: 6| Step: 5
Training loss: 1.9605543613433838
Validation loss: 2.0442983309427896

Epoch: 6| Step: 6
Training loss: 2.18174147605896
Validation loss: 2.0266172885894775

Epoch: 6| Step: 7
Training loss: 1.4115391969680786
Validation loss: 2.012748897075653

Epoch: 6| Step: 8
Training loss: 2.2534356117248535
Validation loss: 2.003156284491221

Epoch: 6| Step: 9
Training loss: 1.8273319005966187
Validation loss: 2.008233288923899

Epoch: 6| Step: 10
Training loss: 2.216336727142334
Validation loss: 2.0081931153933206

Epoch: 6| Step: 11
Training loss: 2.307013988494873
Validation loss: 2.0089789231618247

Epoch: 6| Step: 12
Training loss: 2.6180343627929688
Validation loss: 2.0086296995480857

Epoch: 6| Step: 13
Training loss: 1.9993458986282349
Validation loss: 2.0078341166178384

Epoch: 88| Step: 0
Training loss: 2.168370246887207
Validation loss: 1.994475245475769

Epoch: 6| Step: 1
Training loss: 1.9925260543823242
Validation loss: 2.0053736766179404

Epoch: 6| Step: 2
Training loss: 2.3504135608673096
Validation loss: 2.020391325155894

Epoch: 6| Step: 3
Training loss: 2.0388121604919434
Validation loss: 2.0101406375567117

Epoch: 6| Step: 4
Training loss: 1.9072014093399048
Validation loss: 2.008740464846293

Epoch: 6| Step: 5
Training loss: 1.926133394241333
Validation loss: 2.015876809755961

Epoch: 6| Step: 6
Training loss: 2.5829882621765137
Validation loss: 2.0324031710624695

Epoch: 6| Step: 7
Training loss: 1.6038129329681396
Validation loss: 2.0116225481033325

Epoch: 6| Step: 8
Training loss: 1.8364770412445068
Validation loss: 2.011178414026896

Epoch: 6| Step: 9
Training loss: 2.0325446128845215
Validation loss: 2.0135416984558105

Epoch: 6| Step: 10
Training loss: 2.4281435012817383
Validation loss: 2.013599932193756

Epoch: 6| Step: 11
Training loss: 2.071625232696533
Validation loss: 2.013941248257955

Epoch: 6| Step: 12
Training loss: 2.4508471488952637
Validation loss: 2.0123400688171387

Epoch: 6| Step: 13
Training loss: 2.3207244873046875
Validation loss: 2.0210243463516235

Epoch: 89| Step: 0
Training loss: 2.5496482849121094
Validation loss: 2.0361289779345193

Epoch: 6| Step: 1
Training loss: 2.018721580505371
Validation loss: 2.0276528795560202

Epoch: 6| Step: 2
Training loss: 1.9142051935195923
Validation loss: 2.034573475519816

Epoch: 6| Step: 3
Training loss: 1.994999647140503
Validation loss: 2.0305992364883423

Epoch: 6| Step: 4
Training loss: 1.9207831621170044
Validation loss: 2.0510530869166055

Epoch: 6| Step: 5
Training loss: 2.528416872024536
Validation loss: 2.069291611512502

Epoch: 6| Step: 6
Training loss: 2.1859865188598633
Validation loss: 2.0751150846481323

Epoch: 6| Step: 7
Training loss: 1.9290838241577148
Validation loss: 2.0664019783337912

Epoch: 6| Step: 8
Training loss: 2.1860270500183105
Validation loss: 2.049875179926554

Epoch: 6| Step: 9
Training loss: 3.117650032043457
Validation loss: 2.0344814459482827

Epoch: 6| Step: 10
Training loss: 1.359623908996582
Validation loss: 2.018931527932485

Epoch: 6| Step: 11
Training loss: 1.4924342632293701
Validation loss: 2.0065899888674417

Epoch: 6| Step: 12
Training loss: 2.639998197555542
Validation loss: 2.0183540185292563

Epoch: 6| Step: 13
Training loss: 1.9044528007507324
Validation loss: 2.0247263312339783

Epoch: 90| Step: 0
Training loss: 2.252833366394043
Validation loss: 2.03907177845637

Epoch: 6| Step: 1
Training loss: 2.0235490798950195
Validation loss: 2.0333271423975625

Epoch: 6| Step: 2
Training loss: 2.3579189777374268
Validation loss: 2.045661469300588

Epoch: 6| Step: 3
Training loss: 2.409114360809326
Validation loss: 2.0477046966552734

Epoch: 6| Step: 4
Training loss: 2.1907153129577637
Validation loss: 2.049440642197927

Epoch: 6| Step: 5
Training loss: 2.8100733757019043
Validation loss: 2.0577794710795083

Epoch: 6| Step: 6
Training loss: 2.158583641052246
Validation loss: 2.055953065554301

Epoch: 6| Step: 7
Training loss: 2.3268227577209473
Validation loss: 2.0533068776130676

Epoch: 6| Step: 8
Training loss: 1.9586131572723389
Validation loss: 2.055122137069702

Epoch: 6| Step: 9
Training loss: 2.018923282623291
Validation loss: 2.0550991694132485

Epoch: 6| Step: 10
Training loss: 1.8608229160308838
Validation loss: 2.051886022090912

Epoch: 6| Step: 11
Training loss: 2.084684371948242
Validation loss: 2.0552404721577964

Epoch: 6| Step: 12
Training loss: 2.251025676727295
Validation loss: 2.0554577708244324

Epoch: 6| Step: 13
Training loss: 1.9148881435394287
Validation loss: 2.046699861685435

Epoch: 91| Step: 0
Training loss: 1.7083728313446045
Validation loss: 2.0445902744928994

Epoch: 6| Step: 1
Training loss: 2.501121759414673
Validation loss: 2.049090544382731

Epoch: 6| Step: 2
Training loss: 1.8481708765029907
Validation loss: 2.0387768944104514

Epoch: 6| Step: 3
Training loss: 2.484048843383789
Validation loss: 2.036601722240448

Epoch: 6| Step: 4
Training loss: 2.0559911727905273
Validation loss: 2.0339266061782837

Epoch: 6| Step: 5
Training loss: 2.5538170337677
Validation loss: 2.0302767554918923

Epoch: 6| Step: 6
Training loss: 2.3225455284118652
Validation loss: 2.019428869088491

Epoch: 6| Step: 7
Training loss: 2.3961992263793945
Validation loss: 2.0021727482477822

Epoch: 6| Step: 8
Training loss: 1.7242400646209717
Validation loss: 2.009810964266459

Epoch: 6| Step: 9
Training loss: 1.9918482303619385
Validation loss: 2.007050315539042

Epoch: 6| Step: 10
Training loss: 1.864795207977295
Validation loss: 2.0173282623291016

Epoch: 6| Step: 11
Training loss: 2.141970634460449
Validation loss: 2.0321404933929443

Epoch: 6| Step: 12
Training loss: 2.472655773162842
Validation loss: 2.0390520691871643

Epoch: 6| Step: 13
Training loss: 2.091817617416382
Validation loss: 2.0439619421958923

Epoch: 92| Step: 0
Training loss: 1.7456140518188477
Validation loss: 2.0369106928507485

Epoch: 6| Step: 1
Training loss: 2.7574496269226074
Validation loss: 2.046277105808258

Epoch: 6| Step: 2
Training loss: 2.595782995223999
Validation loss: 2.031803031762441

Epoch: 6| Step: 3
Training loss: 1.6012295484542847
Validation loss: 2.029975394407908

Epoch: 6| Step: 4
Training loss: 2.891017436981201
Validation loss: 2.0205055475234985

Epoch: 6| Step: 5
Training loss: 2.207766532897949
Validation loss: 2.0171126325925193

Epoch: 6| Step: 6
Training loss: 1.5382018089294434
Validation loss: 2.027356823285421

Epoch: 6| Step: 7
Training loss: 2.552666664123535
Validation loss: 2.0173115730285645

Epoch: 6| Step: 8
Training loss: 1.7519117593765259
Validation loss: 2.012709399064382

Epoch: 6| Step: 9
Training loss: 2.0590147972106934
Validation loss: 2.0071762601534524

Epoch: 6| Step: 10
Training loss: 2.3209166526794434
Validation loss: 2.0272281964619956

Epoch: 6| Step: 11
Training loss: 1.6447808742523193
Validation loss: 2.0127336780230203

Epoch: 6| Step: 12
Training loss: 2.0838232040405273
Validation loss: 2.019891639550527

Epoch: 6| Step: 13
Training loss: 1.588201642036438
Validation loss: 2.026221434275309

Epoch: 93| Step: 0
Training loss: 2.048562526702881
Validation loss: 2.0240285793940225

Epoch: 6| Step: 1
Training loss: 2.126791477203369
Validation loss: 2.026034951210022

Epoch: 6| Step: 2
Training loss: 1.9415473937988281
Validation loss: 2.0164049665133157

Epoch: 6| Step: 3
Training loss: 1.9250805377960205
Validation loss: 2.0274069706598916

Epoch: 6| Step: 4
Training loss: 2.4490418434143066
Validation loss: 2.041471779346466

Epoch: 6| Step: 5
Training loss: 1.532110571861267
Validation loss: 2.0284328063329062

Epoch: 6| Step: 6
Training loss: 2.215301513671875
Validation loss: 2.0309614737828574

Epoch: 6| Step: 7
Training loss: 2.567138671875
Validation loss: 2.0210476318995156

Epoch: 6| Step: 8
Training loss: 1.9020384550094604
Validation loss: 2.0166375835736594

Epoch: 6| Step: 9
Training loss: 2.182150363922119
Validation loss: 2.0129274328549704

Epoch: 6| Step: 10
Training loss: 2.984367609024048
Validation loss: 2.0113176902135215

Epoch: 6| Step: 11
Training loss: 1.571632742881775
Validation loss: 2.0160658756891885

Epoch: 6| Step: 12
Training loss: 2.029785633087158
Validation loss: 2.0124805768330893

Epoch: 6| Step: 13
Training loss: 2.1393113136291504
Validation loss: 2.0227781732877097

Epoch: 94| Step: 0
Training loss: 1.9164676666259766
Validation loss: 2.0149123072624207

Epoch: 6| Step: 1
Training loss: 2.0872063636779785
Validation loss: 2.0159402887026467

Epoch: 6| Step: 2
Training loss: 1.964052677154541
Validation loss: 2.014490485191345

Epoch: 6| Step: 3
Training loss: 2.139676094055176
Validation loss: 2.0120739142100015

Epoch: 6| Step: 4
Training loss: 2.229888439178467
Validation loss: 2.0191085934638977

Epoch: 6| Step: 5
Training loss: 1.7050788402557373
Validation loss: 2.0065805912017822

Epoch: 6| Step: 6
Training loss: 1.8896552324295044
Validation loss: 2.019204795360565

Epoch: 6| Step: 7
Training loss: 2.0292510986328125
Validation loss: 2.0240774154663086

Epoch: 6| Step: 8
Training loss: 2.4751498699188232
Validation loss: 2.0437742471694946

Epoch: 6| Step: 9
Training loss: 2.566023349761963
Validation loss: 2.0409327944119773

Epoch: 6| Step: 10
Training loss: 2.3789467811584473
Validation loss: 2.0402134458223977

Epoch: 6| Step: 11
Training loss: 1.4501395225524902
Validation loss: 2.0141318639119468

Epoch: 6| Step: 12
Training loss: 2.630361557006836
Validation loss: 2.0291824340820312

Epoch: 6| Step: 13
Training loss: 2.3738181591033936
Validation loss: 2.0190033316612244

Epoch: 95| Step: 0
Training loss: 1.873128890991211
Validation loss: 2.0178897778193154

Epoch: 6| Step: 1
Training loss: 2.271632671356201
Validation loss: 2.007609705130259

Epoch: 6| Step: 2
Training loss: 2.697427272796631
Validation loss: 2.0085271994272866

Epoch: 6| Step: 3
Training loss: 2.4611458778381348
Validation loss: 2.0029075543085733

Epoch: 6| Step: 4
Training loss: 1.9256761074066162
Validation loss: 2.010025938351949

Epoch: 6| Step: 5
Training loss: 1.6772916316986084
Validation loss: 2.015699287255605

Epoch: 6| Step: 6
Training loss: 2.4608874320983887
Validation loss: 2.016001125176748

Epoch: 6| Step: 7
Training loss: 2.1739871501922607
Validation loss: 2.0044090946515403

Epoch: 6| Step: 8
Training loss: 1.8597757816314697
Validation loss: 2.016284783681234

Epoch: 6| Step: 9
Training loss: 2.080075979232788
Validation loss: 2.0133850971857705

Epoch: 6| Step: 10
Training loss: 1.4087413549423218
Validation loss: 2.011840581893921

Epoch: 6| Step: 11
Training loss: 2.322272300720215
Validation loss: 2.013762970765432

Epoch: 6| Step: 12
Training loss: 2.234743118286133
Validation loss: 2.0204173723856607

Epoch: 6| Step: 13
Training loss: 2.0426013469696045
Validation loss: 2.033391992251078

Epoch: 96| Step: 0
Training loss: 2.477243661880493
Validation loss: 2.031217654546102

Epoch: 6| Step: 1
Training loss: 2.850701332092285
Validation loss: 2.0252491434415183

Epoch: 6| Step: 2
Training loss: 1.6229732036590576
Validation loss: 2.029450555642446

Epoch: 6| Step: 3
Training loss: 1.568048119544983
Validation loss: 2.052646259466807

Epoch: 6| Step: 4
Training loss: 2.7223567962646484
Validation loss: 2.0448692639668784

Epoch: 6| Step: 5
Training loss: 2.356706380844116
Validation loss: 2.0454195737838745

Epoch: 6| Step: 6
Training loss: 2.2223610877990723
Validation loss: 2.0581330259641013

Epoch: 6| Step: 7
Training loss: 2.015066385269165
Validation loss: 2.0543052156766257

Epoch: 6| Step: 8
Training loss: 1.8534808158874512
Validation loss: 2.05478173494339

Epoch: 6| Step: 9
Training loss: 1.679324984550476
Validation loss: 2.0454036394755044

Epoch: 6| Step: 10
Training loss: 1.5653069019317627
Validation loss: 2.049284557501475

Epoch: 6| Step: 11
Training loss: 2.137403726577759
Validation loss: 2.0458107193311057

Epoch: 6| Step: 12
Training loss: 2.074211597442627
Validation loss: 2.0407162507375083

Epoch: 6| Step: 13
Training loss: 2.165677070617676
Validation loss: 2.0401868422826133

Epoch: 97| Step: 0
Training loss: 2.072774887084961
Validation loss: 2.033778131008148

Epoch: 6| Step: 1
Training loss: 2.163896083831787
Validation loss: 2.0340599020322165

Epoch: 6| Step: 2
Training loss: 2.041790008544922
Validation loss: 2.0301448901494346

Epoch: 6| Step: 3
Training loss: 1.8796910047531128
Validation loss: 2.025550623734792

Epoch: 6| Step: 4
Training loss: 2.6453299522399902
Validation loss: 2.0293235580126443

Epoch: 6| Step: 5
Training loss: 1.7210028171539307
Validation loss: 2.0242682695388794

Epoch: 6| Step: 6
Training loss: 1.6871614456176758
Validation loss: 2.0305615266164145

Epoch: 6| Step: 7
Training loss: 1.6210225820541382
Validation loss: 2.022547443707784

Epoch: 6| Step: 8
Training loss: 2.2820096015930176
Validation loss: 2.0445675253868103

Epoch: 6| Step: 9
Training loss: 2.073843240737915
Validation loss: 2.0280313889185586

Epoch: 6| Step: 10
Training loss: 2.4819185733795166
Validation loss: 2.03336493174235

Epoch: 6| Step: 11
Training loss: 2.0421864986419678
Validation loss: 2.023096760114034

Epoch: 6| Step: 12
Training loss: 2.5807623863220215
Validation loss: 2.033446947733561

Epoch: 6| Step: 13
Training loss: 1.934454083442688
Validation loss: 2.0325016180674234

Epoch: 98| Step: 0
Training loss: 1.531198501586914
Validation loss: 2.03695019086202

Epoch: 6| Step: 1
Training loss: 2.3239667415618896
Validation loss: 2.0399612188339233

Epoch: 6| Step: 2
Training loss: 2.7896523475646973
Validation loss: 2.03890069325765

Epoch: 6| Step: 3
Training loss: 2.49336314201355
Validation loss: 2.030370354652405

Epoch: 6| Step: 4
Training loss: 1.882241129875183
Validation loss: 2.03844286998113

Epoch: 6| Step: 5
Training loss: 1.7797811031341553
Validation loss: 2.0259570678075156

Epoch: 6| Step: 6
Training loss: 1.7807269096374512
Validation loss: 2.0329026579856873

Epoch: 6| Step: 7
Training loss: 2.361898422241211
Validation loss: 2.0148632923762

Epoch: 6| Step: 8
Training loss: 1.973623275756836
Validation loss: 2.018884599208832

Epoch: 6| Step: 9
Training loss: 1.5613864660263062
Validation loss: 2.02040696144104

Epoch: 6| Step: 10
Training loss: 1.5444616079330444
Validation loss: 2.020477533340454

Epoch: 6| Step: 11
Training loss: 1.9522786140441895
Validation loss: 2.021558662255605

Epoch: 6| Step: 12
Training loss: 2.9374279975891113
Validation loss: 2.0248154401779175

Epoch: 6| Step: 13
Training loss: 2.326049566268921
Validation loss: 2.0239854057629905

Epoch: 99| Step: 0
Training loss: 1.3146629333496094
Validation loss: 2.0324788292249045

Epoch: 6| Step: 1
Training loss: 2.047488212585449
Validation loss: 2.0291672945022583

Epoch: 6| Step: 2
Training loss: 2.254115581512451
Validation loss: 2.0377471446990967

Epoch: 6| Step: 3
Training loss: 2.6358649730682373
Validation loss: 2.0362253983815513

Epoch: 6| Step: 4
Training loss: 1.6075735092163086
Validation loss: 2.0368259946505227

Epoch: 6| Step: 5
Training loss: 2.061695098876953
Validation loss: 2.035130262374878

Epoch: 6| Step: 6
Training loss: 1.7384402751922607
Validation loss: 2.033073842525482

Epoch: 6| Step: 7
Training loss: 2.1950440406799316
Validation loss: 2.0395999749501548

Epoch: 6| Step: 8
Training loss: 2.2635433673858643
Validation loss: 2.0363730788230896

Epoch: 6| Step: 9
Training loss: 2.7403430938720703
Validation loss: 2.041435937086741

Epoch: 6| Step: 10
Training loss: 2.6062393188476562
Validation loss: 2.0344019134839377

Epoch: 6| Step: 11
Training loss: 2.2415857315063477
Validation loss: 2.0283631483713784

Epoch: 6| Step: 12
Training loss: 2.1839025020599365
Validation loss: 2.026455521583557

Epoch: 6| Step: 13
Training loss: 2.046224594116211
Validation loss: 2.0256224075953164

Epoch: 100| Step: 0
Training loss: 1.7905261516571045
Validation loss: 2.0283719499905906

Epoch: 6| Step: 1
Training loss: 2.1276092529296875
Validation loss: 2.0331525603930154

Epoch: 6| Step: 2
Training loss: 2.1009361743927
Validation loss: 2.0317208568255105

Epoch: 6| Step: 3
Training loss: 1.3842476606369019
Validation loss: 2.0354156295458474

Epoch: 6| Step: 4
Training loss: 2.8055224418640137
Validation loss: 2.034696380297343

Epoch: 6| Step: 5
Training loss: 2.3329458236694336
Validation loss: 2.021215319633484

Epoch: 6| Step: 6
Training loss: 2.2005441188812256
Validation loss: 2.0401507019996643

Epoch: 6| Step: 7
Training loss: 2.109391927719116
Validation loss: 2.0324326554934182

Epoch: 6| Step: 8
Training loss: 1.42425537109375
Validation loss: 2.041242996851603

Epoch: 6| Step: 9
Training loss: 2.3635923862457275
Validation loss: 2.043555816014608

Epoch: 6| Step: 10
Training loss: 1.9043986797332764
Validation loss: 2.0456870794296265

Epoch: 6| Step: 11
Training loss: 2.3045148849487305
Validation loss: 2.067391355832418

Epoch: 6| Step: 12
Training loss: 2.022907018661499
Validation loss: 2.0512170791625977

Epoch: 6| Step: 13
Training loss: 2.4208879470825195
Validation loss: 2.0419798294703164

Epoch: 101| Step: 0
Training loss: 2.3593454360961914
Validation loss: 2.028506795565287

Epoch: 6| Step: 1
Training loss: 2.1594090461730957
Validation loss: 2.016527752081553

Epoch: 6| Step: 2
Training loss: 2.055294990539551
Validation loss: 2.011926809946696

Epoch: 6| Step: 3
Training loss: 2.1091318130493164
Validation loss: 2.0116129914919534

Epoch: 6| Step: 4
Training loss: 2.1020829677581787
Validation loss: 2.008179763952891

Epoch: 6| Step: 5
Training loss: 2.0311977863311768
Validation loss: 2.013887623945872

Epoch: 6| Step: 6
Training loss: 2.396350860595703
Validation loss: 2.014370640118917

Epoch: 6| Step: 7
Training loss: 1.9266583919525146
Validation loss: 2.0050101280212402

Epoch: 6| Step: 8
Training loss: 1.7827413082122803
Validation loss: 2.0148691733678183

Epoch: 6| Step: 9
Training loss: 1.8785640001296997
Validation loss: 2.006736636161804

Epoch: 6| Step: 10
Training loss: 2.5413475036621094
Validation loss: 2.009508232275645

Epoch: 6| Step: 11
Training loss: 1.387474536895752
Validation loss: 2.017946720123291

Epoch: 6| Step: 12
Training loss: 2.5505356788635254
Validation loss: 2.020041028658549

Epoch: 6| Step: 13
Training loss: 2.1076669692993164
Validation loss: 2.0175785024960837

Epoch: 102| Step: 0
Training loss: 2.391695976257324
Validation loss: 2.0407935976982117

Epoch: 6| Step: 1
Training loss: 2.472402572631836
Validation loss: 2.062030533949534

Epoch: 6| Step: 2
Training loss: 1.7310400009155273
Validation loss: 2.0888944466908774

Epoch: 6| Step: 3
Training loss: 2.6800947189331055
Validation loss: 2.1099820534388223

Epoch: 6| Step: 4
Training loss: 2.0077500343322754
Validation loss: 2.1191239953041077

Epoch: 6| Step: 5
Training loss: 2.2246477603912354
Validation loss: 2.0841426849365234

Epoch: 6| Step: 6
Training loss: 2.44608473777771
Validation loss: 2.0496082107226052

Epoch: 6| Step: 7
Training loss: 1.9034028053283691
Validation loss: 2.0394380688667297

Epoch: 6| Step: 8
Training loss: 1.915595531463623
Validation loss: 2.0209630330403647

Epoch: 6| Step: 9
Training loss: 1.5571545362472534
Validation loss: 2.018101155757904

Epoch: 6| Step: 10
Training loss: 2.518239974975586
Validation loss: 2.002487897872925

Epoch: 6| Step: 11
Training loss: 1.5037158727645874
Validation loss: 1.9915917317072551

Epoch: 6| Step: 12
Training loss: 2.4306297302246094
Validation loss: 1.9869054754575093

Epoch: 6| Step: 13
Training loss: 1.9651591777801514
Validation loss: 1.9903254707654316

Epoch: 103| Step: 0
Training loss: 1.9480164051055908
Validation loss: 1.9965710043907166

Epoch: 6| Step: 1
Training loss: 2.8779714107513428
Validation loss: 2.0025470654169717

Epoch: 6| Step: 2
Training loss: 2.258267402648926
Validation loss: 2.0117727518081665

Epoch: 6| Step: 3
Training loss: 1.9834563732147217
Validation loss: 2.020102024078369

Epoch: 6| Step: 4
Training loss: 1.905929446220398
Validation loss: 2.026708960533142

Epoch: 6| Step: 5
Training loss: 2.0135841369628906
Validation loss: 2.0240341822306314

Epoch: 6| Step: 6
Training loss: 1.789768934249878
Validation loss: 2.026915192604065

Epoch: 6| Step: 7
Training loss: 2.0200142860412598
Validation loss: 2.0234312613805137

Epoch: 6| Step: 8
Training loss: 2.2126426696777344
Validation loss: 2.035451869169871

Epoch: 6| Step: 9
Training loss: 1.85453462600708
Validation loss: 2.0249677896499634

Epoch: 6| Step: 10
Training loss: 1.9653738737106323
Validation loss: 2.0240043799082437

Epoch: 6| Step: 11
Training loss: 2.7542836666107178
Validation loss: 2.021857519944509

Epoch: 6| Step: 12
Training loss: 2.4122977256774902
Validation loss: 2.017643670241038

Epoch: 6| Step: 13
Training loss: 2.083045244216919
Validation loss: 2.00989423195521

Epoch: 104| Step: 0
Training loss: 2.2186837196350098
Validation loss: 2.0132500926653543

Epoch: 6| Step: 1
Training loss: 2.3047122955322266
Validation loss: 2.01396514972051

Epoch: 6| Step: 2
Training loss: 1.7287787199020386
Validation loss: 2.0128040313720703

Epoch: 6| Step: 3
Training loss: 2.257237434387207
Validation loss: 2.0040231943130493

Epoch: 6| Step: 4
Training loss: 2.765866279602051
Validation loss: 2.002449075380961

Epoch: 6| Step: 5
Training loss: 1.6447269916534424
Validation loss: 2.0132359067598977

Epoch: 6| Step: 6
Training loss: 2.5680809020996094
Validation loss: 2.0138822197914124

Epoch: 6| Step: 7
Training loss: 2.2721304893493652
Validation loss: 2.012743810812632

Epoch: 6| Step: 8
Training loss: 2.2238993644714355
Validation loss: 2.0109359423319497

Epoch: 6| Step: 9
Training loss: 1.2807259559631348
Validation loss: 2.0131499965985618

Epoch: 6| Step: 10
Training loss: 1.5337588787078857
Validation loss: 2.0209385752677917

Epoch: 6| Step: 11
Training loss: 2.2019662857055664
Validation loss: 2.0343715151151023

Epoch: 6| Step: 12
Training loss: 2.1734561920166016
Validation loss: 2.0635523796081543

Epoch: 6| Step: 13
Training loss: 2.183079481124878
Validation loss: 2.0908713340759277

Epoch: 105| Step: 0
Training loss: 2.4533567428588867
Validation loss: 2.110951781272888

Epoch: 6| Step: 1
Training loss: 2.4764223098754883
Validation loss: 2.107801298300425

Epoch: 6| Step: 2
Training loss: 2.402592182159424
Validation loss: 2.0757214029630027

Epoch: 6| Step: 3
Training loss: 2.367121696472168
Validation loss: 2.0460556944211326

Epoch: 6| Step: 4
Training loss: 2.040532112121582
Validation loss: 2.023874203364054

Epoch: 6| Step: 5
Training loss: 2.008084774017334
Validation loss: 2.0207992792129517

Epoch: 6| Step: 6
Training loss: 2.3123998641967773
Validation loss: 2.0143590370814004

Epoch: 6| Step: 7
Training loss: 1.8688124418258667
Validation loss: 2.009638945261637

Epoch: 6| Step: 8
Training loss: 1.9664561748504639
Validation loss: 2.0117497046788535

Epoch: 6| Step: 9
Training loss: 1.6919512748718262
Validation loss: 2.0274234811464944

Epoch: 6| Step: 10
Training loss: 2.0725107192993164
Validation loss: 2.0168014764785767

Epoch: 6| Step: 11
Training loss: 2.1016838550567627
Validation loss: 2.016032656033834

Epoch: 6| Step: 12
Training loss: 2.1831722259521484
Validation loss: 2.0127732356389365

Epoch: 6| Step: 13
Training loss: 1.9599144458770752
Validation loss: 2.008189876874288

Epoch: 106| Step: 0
Training loss: 1.823405146598816
Validation loss: 2.013547897338867

Epoch: 6| Step: 1
Training loss: 2.7702102661132812
Validation loss: 2.015923241774241

Epoch: 6| Step: 2
Training loss: 2.4808950424194336
Validation loss: 2.0177458922068277

Epoch: 6| Step: 3
Training loss: 2.1802425384521484
Validation loss: 2.0259397427241006

Epoch: 6| Step: 4
Training loss: 1.7076671123504639
Validation loss: 2.0235782861709595

Epoch: 6| Step: 5
Training loss: 2.032062530517578
Validation loss: 2.0345952113469443

Epoch: 6| Step: 6
Training loss: 1.6840468645095825
Validation loss: 2.051596999168396

Epoch: 6| Step: 7
Training loss: 1.9398630857467651
Validation loss: 2.0472392439842224

Epoch: 6| Step: 8
Training loss: 2.050443172454834
Validation loss: 2.044605334599813

Epoch: 6| Step: 9
Training loss: 1.8613085746765137
Validation loss: 2.0477223992347717

Epoch: 6| Step: 10
Training loss: 2.6651225090026855
Validation loss: 2.0645774801572165

Epoch: 6| Step: 11
Training loss: 2.095642328262329
Validation loss: 2.054089903831482

Epoch: 6| Step: 12
Training loss: 2.3084309101104736
Validation loss: 2.049457848072052

Epoch: 6| Step: 13
Training loss: 1.629154920578003
Validation loss: 2.0638182759284973

Epoch: 107| Step: 0
Training loss: 2.4079558849334717
Validation loss: 2.0488212505976358

Epoch: 6| Step: 1
Training loss: 2.4846792221069336
Validation loss: 2.0605169534683228

Epoch: 6| Step: 2
Training loss: 2.420827627182007
Validation loss: 2.0532737970352173

Epoch: 6| Step: 3
Training loss: 2.483976125717163
Validation loss: 2.04453839858373

Epoch: 6| Step: 4
Training loss: 1.230808138847351
Validation loss: 2.044144848982493

Epoch: 6| Step: 5
Training loss: 2.480685234069824
Validation loss: 2.043225646018982

Epoch: 6| Step: 6
Training loss: 1.5843855142593384
Validation loss: 2.038715680440267

Epoch: 6| Step: 7
Training loss: 1.9870041608810425
Validation loss: 2.0211703975995383

Epoch: 6| Step: 8
Training loss: 1.6848496198654175
Validation loss: 2.0166391730308533

Epoch: 6| Step: 9
Training loss: 2.2422192096710205
Validation loss: 2.0198891957600913

Epoch: 6| Step: 10
Training loss: 2.177150249481201
Validation loss: 2.025740921497345

Epoch: 6| Step: 11
Training loss: 2.5831241607666016
Validation loss: 2.027534544467926

Epoch: 6| Step: 12
Training loss: 1.8721015453338623
Validation loss: 2.0252310037612915

Epoch: 6| Step: 13
Training loss: 1.5474870204925537
Validation loss: 2.0462820331255593

Epoch: 108| Step: 0
Training loss: 2.468064785003662
Validation loss: 2.069765051205953

Epoch: 6| Step: 1
Training loss: 1.500480055809021
Validation loss: 2.0678751866022744

Epoch: 6| Step: 2
Training loss: 2.5179104804992676
Validation loss: 2.0891774694124856

Epoch: 6| Step: 3
Training loss: 2.0958218574523926
Validation loss: 2.0967881878217063

Epoch: 6| Step: 4
Training loss: 1.8146145343780518
Validation loss: 2.0680798093477883

Epoch: 6| Step: 5
Training loss: 2.583559989929199
Validation loss: 2.060983657836914

Epoch: 6| Step: 6
Training loss: 1.3640202283859253
Validation loss: 2.0534525513648987

Epoch: 6| Step: 7
Training loss: 1.9342000484466553
Validation loss: 2.042343000570933

Epoch: 6| Step: 8
Training loss: 2.8215484619140625
Validation loss: 2.0293052792549133

Epoch: 6| Step: 9
Training loss: 2.4498984813690186
Validation loss: 2.028678019841512

Epoch: 6| Step: 10
Training loss: 1.865206003189087
Validation loss: 2.0247005224227905

Epoch: 6| Step: 11
Training loss: 2.312704563140869
Validation loss: 2.0251129865646362

Epoch: 6| Step: 12
Training loss: 1.9389793872833252
Validation loss: 2.02612696091334

Epoch: 6| Step: 13
Training loss: 1.8692307472229004
Validation loss: 2.0407548745473227

Epoch: 109| Step: 0
Training loss: 2.6176843643188477
Validation loss: 2.0402329564094543

Epoch: 6| Step: 1
Training loss: 2.0632638931274414
Validation loss: 2.0335571567217507

Epoch: 6| Step: 2
Training loss: 2.2601099014282227
Validation loss: 2.046229521433512

Epoch: 6| Step: 3
Training loss: 2.711280345916748
Validation loss: 2.0597009460131326

Epoch: 6| Step: 4
Training loss: 1.6673983335494995
Validation loss: 2.0613991618156433

Epoch: 6| Step: 5
Training loss: 2.07183837890625
Validation loss: 2.082284907499949

Epoch: 6| Step: 6
Training loss: 1.7574281692504883
Validation loss: 2.0761871337890625

Epoch: 6| Step: 7
Training loss: 2.1347455978393555
Validation loss: 2.080540498097738

Epoch: 6| Step: 8
Training loss: 2.810230016708374
Validation loss: 2.0848817427953086

Epoch: 6| Step: 9
Training loss: 1.5285041332244873
Validation loss: 2.064217766125997

Epoch: 6| Step: 10
Training loss: 2.4704673290252686
Validation loss: 2.0543848474820456

Epoch: 6| Step: 11
Training loss: 1.7699604034423828
Validation loss: 2.047527492046356

Epoch: 6| Step: 12
Training loss: 1.5232932567596436
Validation loss: 2.0328674912452698

Epoch: 6| Step: 13
Training loss: 1.8359618186950684
Validation loss: 2.0372344652811685

Epoch: 110| Step: 0
Training loss: 2.341648578643799
Validation loss: 2.0244734287261963

Epoch: 6| Step: 1
Training loss: 1.8525183200836182
Validation loss: 2.0207363168398538

Epoch: 6| Step: 2
Training loss: 2.212944984436035
Validation loss: 2.0177311301231384

Epoch: 6| Step: 3
Training loss: 1.5914413928985596
Validation loss: 2.024701237678528

Epoch: 6| Step: 4
Training loss: 2.5333352088928223
Validation loss: 2.0231555700302124

Epoch: 6| Step: 5
Training loss: 2.026299238204956
Validation loss: 2.0198280215263367

Epoch: 6| Step: 6
Training loss: 1.4582114219665527
Validation loss: 2.0146597822507224

Epoch: 6| Step: 7
Training loss: 2.05947208404541
Validation loss: 2.0197908083597818

Epoch: 6| Step: 8
Training loss: 2.2463955879211426
Validation loss: 2.0222309827804565

Epoch: 6| Step: 9
Training loss: 2.1192538738250732
Validation loss: 2.018860956033071

Epoch: 6| Step: 10
Training loss: 1.9965600967407227
Validation loss: 2.027701814969381

Epoch: 6| Step: 11
Training loss: 2.3301584720611572
Validation loss: 2.0259983936945596

Epoch: 6| Step: 12
Training loss: 2.6198630332946777
Validation loss: 2.0252281626065574

Epoch: 6| Step: 13
Training loss: 1.681349515914917
Validation loss: 2.0396806399027505

Epoch: 111| Step: 0
Training loss: 2.4958386421203613
Validation loss: 2.0504122376441956

Epoch: 6| Step: 1
Training loss: 2.2270922660827637
Validation loss: 2.0539550383885703

Epoch: 6| Step: 2
Training loss: 1.6831859350204468
Validation loss: 2.074693957964579

Epoch: 6| Step: 3
Training loss: 1.8535878658294678
Validation loss: 2.0847073197364807

Epoch: 6| Step: 4
Training loss: 2.3349578380584717
Validation loss: 2.097966472307841

Epoch: 6| Step: 5
Training loss: 2.4156346321105957
Validation loss: 2.087751865386963

Epoch: 6| Step: 6
Training loss: 2.4985463619232178
Validation loss: 2.114877223968506

Epoch: 6| Step: 7
Training loss: 2.255979537963867
Validation loss: 2.0880425175031028

Epoch: 6| Step: 8
Training loss: 2.0045266151428223
Validation loss: 2.0851520895957947

Epoch: 6| Step: 9
Training loss: 1.8217717409133911
Validation loss: 2.0698327819506326

Epoch: 6| Step: 10
Training loss: 2.2094011306762695
Validation loss: 2.043618599573771

Epoch: 6| Step: 11
Training loss: 1.662807822227478
Validation loss: 2.043747385342916

Epoch: 6| Step: 12
Training loss: 1.6950807571411133
Validation loss: 2.0441698829332986

Epoch: 6| Step: 13
Training loss: 2.0599114894866943
Validation loss: 2.0361509720484414

Epoch: 112| Step: 0
Training loss: 2.1314516067504883
Validation loss: 2.0370550950368247

Epoch: 6| Step: 1
Training loss: 2.15824031829834
Validation loss: 2.0391525427500405

Epoch: 6| Step: 2
Training loss: 2.1040706634521484
Validation loss: 2.04994398355484

Epoch: 6| Step: 3
Training loss: 2.1800830364227295
Validation loss: 2.0375132163365683

Epoch: 6| Step: 4
Training loss: 1.7991770505905151
Validation loss: 2.0445351004600525

Epoch: 6| Step: 5
Training loss: 2.414553165435791
Validation loss: 2.0583393772443137

Epoch: 6| Step: 6
Training loss: 1.7920513153076172
Validation loss: 2.041503389676412

Epoch: 6| Step: 7
Training loss: 2.150861978530884
Validation loss: 2.0409995714823403

Epoch: 6| Step: 8
Training loss: 1.8035004138946533
Validation loss: 2.0339829524358115

Epoch: 6| Step: 9
Training loss: 2.56113338470459
Validation loss: 2.033597389856974

Epoch: 6| Step: 10
Training loss: 2.4773292541503906
Validation loss: 2.029183049996694

Epoch: 6| Step: 11
Training loss: 2.4155993461608887
Validation loss: 2.028603176275889

Epoch: 6| Step: 12
Training loss: 1.607837200164795
Validation loss: 2.0331884225209556

Epoch: 6| Step: 13
Training loss: 1.3949611186981201
Validation loss: 2.0411948760350547

Epoch: 113| Step: 0
Training loss: 2.712063789367676
Validation loss: 2.0526644786198935

Epoch: 6| Step: 1
Training loss: 1.6709246635437012
Validation loss: 2.0680969953536987

Epoch: 6| Step: 2
Training loss: 2.2454023361206055
Validation loss: 2.076465090115865

Epoch: 6| Step: 3
Training loss: 2.198695659637451
Validation loss: 2.076972782611847

Epoch: 6| Step: 4
Training loss: 2.673675537109375
Validation loss: 2.075848559538523

Epoch: 6| Step: 5
Training loss: 1.9377491474151611
Validation loss: 2.085894306500753

Epoch: 6| Step: 6
Training loss: 1.5363377332687378
Validation loss: 2.083116134007772

Epoch: 6| Step: 7
Training loss: 1.426919937133789
Validation loss: 2.0760010480880737

Epoch: 6| Step: 8
Training loss: 2.045625686645508
Validation loss: 2.06719301144282

Epoch: 6| Step: 9
Training loss: 1.8168915510177612
Validation loss: 2.0543982783953347

Epoch: 6| Step: 10
Training loss: 2.323970317840576
Validation loss: 2.0564079682032266

Epoch: 6| Step: 11
Training loss: 2.231077194213867
Validation loss: 2.068472743034363

Epoch: 6| Step: 12
Training loss: 1.8909028768539429
Validation loss: 2.067699750264486

Epoch: 6| Step: 13
Training loss: 2.1155481338500977
Validation loss: 2.070060352484385

Epoch: 114| Step: 0
Training loss: 1.7219613790512085
Validation loss: 2.0690561731656394

Epoch: 6| Step: 1
Training loss: 2.150514841079712
Validation loss: 2.062633196512858

Epoch: 6| Step: 2
Training loss: 1.5275168418884277
Validation loss: 2.0673118034998574

Epoch: 6| Step: 3
Training loss: 2.0475587844848633
Validation loss: 2.077384114265442

Epoch: 6| Step: 4
Training loss: 2.228766441345215
Validation loss: 2.085214376449585

Epoch: 6| Step: 5
Training loss: 2.007585287094116
Validation loss: 2.1023628314336142

Epoch: 6| Step: 6
Training loss: 1.7883398532867432
Validation loss: 2.089029610157013

Epoch: 6| Step: 7
Training loss: 1.8738309144973755
Validation loss: 2.0773465434710183

Epoch: 6| Step: 8
Training loss: 1.9709088802337646
Validation loss: 2.0941400726636252

Epoch: 6| Step: 9
Training loss: 2.583235025405884
Validation loss: 2.0648720065752664

Epoch: 6| Step: 10
Training loss: 2.486699104309082
Validation loss: 2.0620655020078025

Epoch: 6| Step: 11
Training loss: 1.9553874731063843
Validation loss: 2.050164520740509

Epoch: 6| Step: 12
Training loss: 1.9802634716033936
Validation loss: 2.039762238661448

Epoch: 6| Step: 13
Training loss: 2.507418632507324
Validation loss: 2.048978567123413

Epoch: 115| Step: 0
Training loss: 1.9518020153045654
Validation loss: 2.0392308433850608

Epoch: 6| Step: 1
Training loss: 2.104158401489258
Validation loss: 2.036797523498535

Epoch: 6| Step: 2
Training loss: 2.1857547760009766
Validation loss: 2.0495439171791077

Epoch: 6| Step: 3
Training loss: 2.2325143814086914
Validation loss: 2.046202818552653

Epoch: 6| Step: 4
Training loss: 1.9136312007904053
Validation loss: 2.042875051498413

Epoch: 6| Step: 5
Training loss: 2.0158917903900146
Validation loss: 2.0418002009391785

Epoch: 6| Step: 6
Training loss: 2.577998638153076
Validation loss: 2.037431538105011

Epoch: 6| Step: 7
Training loss: 2.286238670349121
Validation loss: 2.0429177482922873

Epoch: 6| Step: 8
Training loss: 1.5807210206985474
Validation loss: 2.052544891834259

Epoch: 6| Step: 9
Training loss: 2.2156758308410645
Validation loss: 2.03257421652476

Epoch: 6| Step: 10
Training loss: 2.2188973426818848
Validation loss: 2.05735445022583

Epoch: 6| Step: 11
Training loss: 1.7365076541900635
Validation loss: 2.061364710330963

Epoch: 6| Step: 12
Training loss: 1.5675511360168457
Validation loss: 2.0602334340413413

Epoch: 6| Step: 13
Training loss: 2.2072267532348633
Validation loss: 2.0787227153778076

Epoch: 116| Step: 0
Training loss: 1.4415557384490967
Validation loss: 2.085060795148214

Epoch: 6| Step: 1
Training loss: 2.1931662559509277
Validation loss: 2.087166905403137

Epoch: 6| Step: 2
Training loss: 2.1711645126342773
Validation loss: 2.0962751507759094

Epoch: 6| Step: 3
Training loss: 2.073107957839966
Validation loss: 2.0946000814437866

Epoch: 6| Step: 4
Training loss: 1.7168209552764893
Validation loss: 2.1105998357137046

Epoch: 6| Step: 5
Training loss: 2.4181275367736816
Validation loss: 2.0879465142885842

Epoch: 6| Step: 6
Training loss: 2.4249823093414307
Validation loss: 2.0890902876853943

Epoch: 6| Step: 7
Training loss: 2.260277271270752
Validation loss: 2.082206070423126

Epoch: 6| Step: 8
Training loss: 2.311453104019165
Validation loss: 2.077567537625631

Epoch: 6| Step: 9
Training loss: 1.9019156694412231
Validation loss: 2.061789949735006

Epoch: 6| Step: 10
Training loss: 1.9996654987335205
Validation loss: 2.065524617830912

Epoch: 6| Step: 11
Training loss: 1.6276919841766357
Validation loss: 2.0564823746681213

Epoch: 6| Step: 12
Training loss: 1.8088905811309814
Validation loss: 2.062809685866038

Epoch: 6| Step: 13
Training loss: 2.4387946128845215
Validation loss: 2.0505815744400024

Epoch: 117| Step: 0
Training loss: 2.191132068634033
Validation loss: 2.060412565867106

Epoch: 6| Step: 1
Training loss: 1.896479845046997
Validation loss: 2.061024526755015

Epoch: 6| Step: 2
Training loss: 2.3410229682922363
Validation loss: 2.073356290658315

Epoch: 6| Step: 3
Training loss: 2.512019157409668
Validation loss: 2.0944209893544516

Epoch: 6| Step: 4
Training loss: 2.617050886154175
Validation loss: 2.0915825764338174

Epoch: 6| Step: 5
Training loss: 2.2434022426605225
Validation loss: 2.0783468882242837

Epoch: 6| Step: 6
Training loss: 1.888545274734497
Validation loss: 2.0700851480166116

Epoch: 6| Step: 7
Training loss: 1.7955436706542969
Validation loss: 2.0791372060775757

Epoch: 6| Step: 8
Training loss: 2.3285624980926514
Validation loss: 2.075172265370687

Epoch: 6| Step: 9
Training loss: 1.728987693786621
Validation loss: 2.063589890797933

Epoch: 6| Step: 10
Training loss: 1.7519402503967285
Validation loss: 2.07596093416214

Epoch: 6| Step: 11
Training loss: 2.0457143783569336
Validation loss: 2.0741578936576843

Epoch: 6| Step: 12
Training loss: 1.1554088592529297
Validation loss: 2.07910563548406

Epoch: 6| Step: 13
Training loss: 1.9317326545715332
Validation loss: 2.0637224117914834

Epoch: 118| Step: 0
Training loss: 1.942299485206604
Validation loss: 2.0794147849082947

Epoch: 6| Step: 1
Training loss: 1.2903839349746704
Validation loss: 2.0675066908200583

Epoch: 6| Step: 2
Training loss: 1.890904188156128
Validation loss: 2.0878181060155234

Epoch: 6| Step: 3
Training loss: 1.8008027076721191
Validation loss: 2.0648313959439597

Epoch: 6| Step: 4
Training loss: 1.8347558975219727
Validation loss: 2.0825064380963645

Epoch: 6| Step: 5
Training loss: 1.783510446548462
Validation loss: 2.085249920686086

Epoch: 6| Step: 6
Training loss: 2.5250401496887207
Validation loss: 2.080677588780721

Epoch: 6| Step: 7
Training loss: 2.4065096378326416
Validation loss: 2.0943179925282798

Epoch: 6| Step: 8
Training loss: 1.876393437385559
Validation loss: 2.065696398417155

Epoch: 6| Step: 9
Training loss: 2.31441593170166
Validation loss: 2.064056932926178

Epoch: 6| Step: 10
Training loss: 2.183377265930176
Validation loss: 2.066266934076945

Epoch: 6| Step: 11
Training loss: 2.1533069610595703
Validation loss: 2.043451448281606

Epoch: 6| Step: 12
Training loss: 2.732445240020752
Validation loss: 2.038273334503174

Epoch: 6| Step: 13
Training loss: 1.8295997381210327
Validation loss: 2.0484430392583213

Epoch: 119| Step: 0
Training loss: 1.4991276264190674
Validation loss: 2.0513112545013428

Epoch: 6| Step: 1
Training loss: 1.9278215169906616
Validation loss: 2.059952517350515

Epoch: 6| Step: 2
Training loss: 2.869703769683838
Validation loss: 2.054821729660034

Epoch: 6| Step: 3
Training loss: 2.665470600128174
Validation loss: 2.063017944494883

Epoch: 6| Step: 4
Training loss: 2.1685068607330322
Validation loss: 2.058396657307943

Epoch: 6| Step: 5
Training loss: 2.039620876312256
Validation loss: 2.0631824135780334

Epoch: 6| Step: 6
Training loss: 1.3091745376586914
Validation loss: 2.0761170387268066

Epoch: 6| Step: 7
Training loss: 1.7540432214736938
Validation loss: 2.082587798436483

Epoch: 6| Step: 8
Training loss: 2.2434778213500977
Validation loss: 2.072912871837616

Epoch: 6| Step: 9
Training loss: 1.5192209482192993
Validation loss: 2.0736708839734397

Epoch: 6| Step: 10
Training loss: 2.0210137367248535
Validation loss: 2.0802902380625405

Epoch: 6| Step: 11
Training loss: 2.821957588195801
Validation loss: 2.083521087964376

Epoch: 6| Step: 12
Training loss: 1.8372893333435059
Validation loss: 2.073608636856079

Epoch: 6| Step: 13
Training loss: 1.7494624853134155
Validation loss: 2.0730706652005515

Epoch: 120| Step: 0
Training loss: 2.209887742996216
Validation loss: 2.060378392537435

Epoch: 6| Step: 1
Training loss: 1.6430890560150146
Validation loss: 2.0653764406840005

Epoch: 6| Step: 2
Training loss: 1.6862199306488037
Validation loss: 2.067586342493693

Epoch: 6| Step: 3
Training loss: 2.1371631622314453
Validation loss: 2.0655214190483093

Epoch: 6| Step: 4
Training loss: 1.4990670680999756
Validation loss: 2.062914550304413

Epoch: 6| Step: 5
Training loss: 1.8184624910354614
Validation loss: 2.0647079944610596

Epoch: 6| Step: 6
Training loss: 2.537205934524536
Validation loss: 2.0695115526517234

Epoch: 6| Step: 7
Training loss: 2.172609329223633
Validation loss: 2.074869612852732

Epoch: 6| Step: 8
Training loss: 1.6688417196273804
Validation loss: 2.0768339236577353

Epoch: 6| Step: 9
Training loss: 1.765043020248413
Validation loss: 2.089582363764445

Epoch: 6| Step: 10
Training loss: 1.9802383184432983
Validation loss: 2.0894784132639566

Epoch: 6| Step: 11
Training loss: 3.200331687927246
Validation loss: 2.0901236136754355

Epoch: 6| Step: 12
Training loss: 1.8427271842956543
Validation loss: 2.0918496449788413

Epoch: 6| Step: 13
Training loss: 2.1845929622650146
Validation loss: 2.084105292956034

Epoch: 121| Step: 0
Training loss: 2.5414319038391113
Validation loss: 2.079411427179972

Epoch: 6| Step: 1
Training loss: 1.710532307624817
Validation loss: 2.0738736589749656

Epoch: 6| Step: 2
Training loss: 2.1514694690704346
Validation loss: 2.0523750384648642

Epoch: 6| Step: 3
Training loss: 1.6478149890899658
Validation loss: 2.047975778579712

Epoch: 6| Step: 4
Training loss: 2.2383856773376465
Validation loss: 2.044402241706848

Epoch: 6| Step: 5
Training loss: 2.3323326110839844
Validation loss: 2.0370980699857077

Epoch: 6| Step: 6
Training loss: 1.9536633491516113
Validation loss: 2.041540543238322

Epoch: 6| Step: 7
Training loss: 2.1638050079345703
Validation loss: 2.044076124827067

Epoch: 6| Step: 8
Training loss: 1.8955334424972534
Validation loss: 2.0429938236872354

Epoch: 6| Step: 9
Training loss: 2.0083141326904297
Validation loss: 2.039736251036326

Epoch: 6| Step: 10
Training loss: 1.9059242010116577
Validation loss: 2.0424089233080545

Epoch: 6| Step: 11
Training loss: 2.564268112182617
Validation loss: 2.0528068939844766

Epoch: 6| Step: 12
Training loss: 1.7810349464416504
Validation loss: 2.0550265510876975

Epoch: 6| Step: 13
Training loss: 1.973083257675171
Validation loss: 2.064154585202535

Epoch: 122| Step: 0
Training loss: 1.618466854095459
Validation loss: 2.071275313695272

Epoch: 6| Step: 1
Training loss: 1.779697060585022
Validation loss: 2.0696025689442954

Epoch: 6| Step: 2
Training loss: 1.3252718448638916
Validation loss: 2.081320067246755

Epoch: 6| Step: 3
Training loss: 2.490779161453247
Validation loss: 2.08426026503245

Epoch: 6| Step: 4
Training loss: 2.105693817138672
Validation loss: 2.0801466504732766

Epoch: 6| Step: 5
Training loss: 1.501569151878357
Validation loss: 2.069771866003672

Epoch: 6| Step: 6
Training loss: 2.211956024169922
Validation loss: 2.069774866104126

Epoch: 6| Step: 7
Training loss: 2.9128453731536865
Validation loss: 2.0640831788380942

Epoch: 6| Step: 8
Training loss: 2.2413034439086914
Validation loss: 2.0562896728515625

Epoch: 6| Step: 9
Training loss: 1.8496462106704712
Validation loss: 2.0411187012990317

Epoch: 6| Step: 10
Training loss: 2.019075393676758
Validation loss: 2.0378252466519675

Epoch: 6| Step: 11
Training loss: 2.4561514854431152
Validation loss: 2.0441314578056335

Epoch: 6| Step: 12
Training loss: 1.9622387886047363
Validation loss: 2.0347231030464172

Epoch: 6| Step: 13
Training loss: 2.139604091644287
Validation loss: 2.0380162994066873

Epoch: 123| Step: 0
Training loss: 2.206486940383911
Validation loss: 2.0533378521601358

Epoch: 6| Step: 1
Training loss: 2.104933738708496
Validation loss: 2.0459840496381125

Epoch: 6| Step: 2
Training loss: 2.515843391418457
Validation loss: 2.04494700829188

Epoch: 6| Step: 3
Training loss: 1.8961586952209473
Validation loss: 2.0566564400990806

Epoch: 6| Step: 4
Training loss: 2.1466073989868164
Validation loss: 2.059540867805481

Epoch: 6| Step: 5
Training loss: 2.051090955734253
Validation loss: 2.0735962192217507

Epoch: 6| Step: 6
Training loss: 2.0604662895202637
Validation loss: 2.1023537317911782

Epoch: 6| Step: 7
Training loss: 2.250393867492676
Validation loss: 2.112508753935496

Epoch: 6| Step: 8
Training loss: 2.063214063644409
Validation loss: 2.110739827156067

Epoch: 6| Step: 9
Training loss: 2.0093369483947754
Validation loss: 2.116453170776367

Epoch: 6| Step: 10
Training loss: 1.4440292119979858
Validation loss: 2.0944180885950723

Epoch: 6| Step: 11
Training loss: 1.7967746257781982
Validation loss: 2.081033190091451

Epoch: 6| Step: 12
Training loss: 2.708998680114746
Validation loss: 2.0673479040463767

Epoch: 6| Step: 13
Training loss: 1.4745230674743652
Validation loss: 2.05898247162501

Epoch: 124| Step: 0
Training loss: 2.4255897998809814
Validation loss: 2.0627904534339905

Epoch: 6| Step: 1
Training loss: 1.7931692600250244
Validation loss: 2.0571267207463584

Epoch: 6| Step: 2
Training loss: 1.3379199504852295
Validation loss: 2.0524056951204934

Epoch: 6| Step: 3
Training loss: 2.28200101852417
Validation loss: 2.049117922782898

Epoch: 6| Step: 4
Training loss: 1.7394840717315674
Validation loss: 2.0503987669944763

Epoch: 6| Step: 5
Training loss: 2.7198147773742676
Validation loss: 2.052726944287618

Epoch: 6| Step: 6
Training loss: 1.9847347736358643
Validation loss: 2.05621999502182

Epoch: 6| Step: 7
Training loss: 2.1156983375549316
Validation loss: 2.0523683230082193

Epoch: 6| Step: 8
Training loss: 2.1099939346313477
Validation loss: 2.0520211855570474

Epoch: 6| Step: 9
Training loss: 2.291917324066162
Validation loss: 2.0568544467290244

Epoch: 6| Step: 10
Training loss: 1.406996726989746
Validation loss: 2.0637650887171426

Epoch: 6| Step: 11
Training loss: 1.9201712608337402
Validation loss: 2.0643770694732666

Epoch: 6| Step: 12
Training loss: 1.9413009881973267
Validation loss: 2.0685566465059915

Epoch: 6| Step: 13
Training loss: 2.478252649307251
Validation loss: 2.0676122307777405

Epoch: 125| Step: 0
Training loss: 2.071154832839966
Validation loss: 2.070883591969808

Epoch: 6| Step: 1
Training loss: 1.501939058303833
Validation loss: 2.0779486894607544

Epoch: 6| Step: 2
Training loss: 1.903865098953247
Validation loss: 2.07673970858256

Epoch: 6| Step: 3
Training loss: 3.280087947845459
Validation loss: 2.077628970146179

Epoch: 6| Step: 4
Training loss: 1.9454646110534668
Validation loss: 2.0807263056437173

Epoch: 6| Step: 5
Training loss: 1.8017070293426514
Validation loss: 2.079800625642141

Epoch: 6| Step: 6
Training loss: 1.743186354637146
Validation loss: 2.0676815708478293

Epoch: 6| Step: 7
Training loss: 1.9756274223327637
Validation loss: 2.0638204415639243

Epoch: 6| Step: 8
Training loss: 2.124783515930176
Validation loss: 2.069394071896871

Epoch: 6| Step: 9
Training loss: 1.9234671592712402
Validation loss: 2.0570072333017984

Epoch: 6| Step: 10
Training loss: 1.721336841583252
Validation loss: 2.055726687113444

Epoch: 6| Step: 11
Training loss: 2.3287241458892822
Validation loss: 2.0579742789268494

Epoch: 6| Step: 12
Training loss: 2.055156707763672
Validation loss: 2.061201333999634

Epoch: 6| Step: 13
Training loss: 1.9922235012054443
Validation loss: 2.067368447780609

Epoch: 126| Step: 0
Training loss: 1.4510211944580078
Validation loss: 2.067451457182566

Epoch: 6| Step: 1
Training loss: 1.88009774684906
Validation loss: 2.079560160636902

Epoch: 6| Step: 2
Training loss: 2.9575676918029785
Validation loss: 2.086377282937368

Epoch: 6| Step: 3
Training loss: 1.905676007270813
Validation loss: 2.0948599179585776

Epoch: 6| Step: 4
Training loss: 2.3905677795410156
Validation loss: 2.092865506807963

Epoch: 6| Step: 5
Training loss: 1.8666197061538696
Validation loss: 2.078244427839915

Epoch: 6| Step: 6
Training loss: 2.292250156402588
Validation loss: 2.090262512365977

Epoch: 6| Step: 7
Training loss: 2.060875415802002
Validation loss: 2.0875244140625

Epoch: 6| Step: 8
Training loss: 2.2917098999023438
Validation loss: 2.09131395816803

Epoch: 6| Step: 9
Training loss: 1.5237150192260742
Validation loss: 2.089273373285929

Epoch: 6| Step: 10
Training loss: 1.9645639657974243
Validation loss: 2.082332134246826

Epoch: 6| Step: 11
Training loss: 1.871547818183899
Validation loss: 2.057161569595337

Epoch: 6| Step: 12
Training loss: 1.4144055843353271
Validation loss: 2.0641799370447793

Epoch: 6| Step: 13
Training loss: 2.315822124481201
Validation loss: 2.054456969102224

Epoch: 127| Step: 0
Training loss: 2.5876622200012207
Validation loss: 2.0498324235280356

Epoch: 6| Step: 1
Training loss: 1.3310041427612305
Validation loss: 2.047284106413523

Epoch: 6| Step: 2
Training loss: 2.191721200942993
Validation loss: 2.0495612025260925

Epoch: 6| Step: 3
Training loss: 2.144911050796509
Validation loss: 2.050124188264211

Epoch: 6| Step: 4
Training loss: 2.156492233276367
Validation loss: 2.0573115746180215

Epoch: 6| Step: 5
Training loss: 2.25042724609375
Validation loss: 2.067345380783081

Epoch: 6| Step: 6
Training loss: 1.6855578422546387
Validation loss: 2.0664530197779336

Epoch: 6| Step: 7
Training loss: 1.5489180088043213
Validation loss: 2.0759435296058655

Epoch: 6| Step: 8
Training loss: 2.0957438945770264
Validation loss: 2.0981322129567466

Epoch: 6| Step: 9
Training loss: 2.3720738887786865
Validation loss: 2.1010244886080423

Epoch: 6| Step: 10
Training loss: 2.270524024963379
Validation loss: 2.0876673658688865

Epoch: 6| Step: 11
Training loss: 1.5899152755737305
Validation loss: 2.090413828690847

Epoch: 6| Step: 12
Training loss: 2.486452102661133
Validation loss: 2.099039375782013

Epoch: 6| Step: 13
Training loss: 1.6616932153701782
Validation loss: 2.0933367212613425

Epoch: 128| Step: 0
Training loss: 2.2543368339538574
Validation loss: 2.076735198497772

Epoch: 6| Step: 1
Training loss: 2.3247487545013428
Validation loss: 2.088417708873749

Epoch: 6| Step: 2
Training loss: 1.8253540992736816
Validation loss: 2.078755021095276

Epoch: 6| Step: 3
Training loss: 1.5684833526611328
Validation loss: 2.0733553568522134

Epoch: 6| Step: 4
Training loss: 2.0362987518310547
Validation loss: 2.0840161442756653

Epoch: 6| Step: 5
Training loss: 2.1288557052612305
Validation loss: 2.0687952041625977

Epoch: 6| Step: 6
Training loss: 2.4112143516540527
Validation loss: 2.0600513219833374

Epoch: 6| Step: 7
Training loss: 2.2906219959259033
Validation loss: 2.0638638734817505

Epoch: 6| Step: 8
Training loss: 1.935440182685852
Validation loss: 2.0549773375193277

Epoch: 6| Step: 9
Training loss: 1.9147932529449463
Validation loss: 2.0615961949030557

Epoch: 6| Step: 10
Training loss: 1.669987440109253
Validation loss: 2.0474361975987754

Epoch: 6| Step: 11
Training loss: 2.2779016494750977
Validation loss: 2.045358737309774

Epoch: 6| Step: 12
Training loss: 1.645688772201538
Validation loss: 2.0495817065238953

Epoch: 6| Step: 13
Training loss: 2.0239498615264893
Validation loss: 2.0502487818400064

Epoch: 129| Step: 0
Training loss: 2.0639986991882324
Validation loss: 2.0623494187990823

Epoch: 6| Step: 1
Training loss: 1.7720363140106201
Validation loss: 2.0648746689160666

Epoch: 6| Step: 2
Training loss: 1.8652803897857666
Validation loss: 2.0608591636021933

Epoch: 6| Step: 3
Training loss: 2.00476336479187
Validation loss: 2.0749876499176025

Epoch: 6| Step: 4
Training loss: 2.4876368045806885
Validation loss: 2.071619768937429

Epoch: 6| Step: 5
Training loss: 2.1922616958618164
Validation loss: 2.0605825185775757

Epoch: 6| Step: 6
Training loss: 2.1033921241760254
Validation loss: 2.076157510280609

Epoch: 6| Step: 7
Training loss: 1.073556900024414
Validation loss: 2.0657867590586343

Epoch: 6| Step: 8
Training loss: 1.993229866027832
Validation loss: 2.068150440851847

Epoch: 6| Step: 9
Training loss: 1.8961538076400757
Validation loss: 2.0793927113215127

Epoch: 6| Step: 10
Training loss: 2.097041368484497
Validation loss: 2.059503753980001

Epoch: 6| Step: 11
Training loss: 2.1704750061035156
Validation loss: 2.0784844557444253

Epoch: 6| Step: 12
Training loss: 1.9126217365264893
Validation loss: 2.077222545941671

Epoch: 6| Step: 13
Training loss: 2.419853448867798
Validation loss: 2.092885156472524

Epoch: 130| Step: 0
Training loss: 1.6362378597259521
Validation loss: 2.0940054655075073

Epoch: 6| Step: 1
Training loss: 2.352731466293335
Validation loss: 2.1058377822240195

Epoch: 6| Step: 2
Training loss: 1.7309356927871704
Validation loss: 2.1001432140668235

Epoch: 6| Step: 3
Training loss: 1.646698236465454
Validation loss: 2.1052035093307495

Epoch: 6| Step: 4
Training loss: 2.3783764839172363
Validation loss: 2.0773831407229104

Epoch: 6| Step: 5
Training loss: 1.8281962871551514
Validation loss: 2.0913525223731995

Epoch: 6| Step: 6
Training loss: 2.206033229827881
Validation loss: 2.0651681820551553

Epoch: 6| Step: 7
Training loss: 1.9856171607971191
Validation loss: 2.067179262638092

Epoch: 6| Step: 8
Training loss: 2.4539804458618164
Validation loss: 2.0630300045013428

Epoch: 6| Step: 9
Training loss: 2.1720807552337646
Validation loss: 2.0526480277379355

Epoch: 6| Step: 10
Training loss: 2.2927041053771973
Validation loss: 2.0395296613375344

Epoch: 6| Step: 11
Training loss: 1.963796854019165
Validation loss: 2.0531837145487466

Epoch: 6| Step: 12
Training loss: 1.5954830646514893
Validation loss: 2.0460707545280457

Epoch: 6| Step: 13
Training loss: 2.418041706085205
Validation loss: 2.0407145818074546

Epoch: 131| Step: 0
Training loss: 2.653075933456421
Validation loss: 2.041418433189392

Epoch: 6| Step: 1
Training loss: 1.568994402885437
Validation loss: 2.0526272455851235

Epoch: 6| Step: 2
Training loss: 1.7942171096801758
Validation loss: 2.054990569750468

Epoch: 6| Step: 3
Training loss: 2.1158058643341064
Validation loss: 2.059726814428965

Epoch: 6| Step: 4
Training loss: 2.0010228157043457
Validation loss: 2.063958783944448

Epoch: 6| Step: 5
Training loss: 2.1854286193847656
Validation loss: 2.0670436024665833

Epoch: 6| Step: 6
Training loss: 2.020009994506836
Validation loss: 2.067566434542338

Epoch: 6| Step: 7
Training loss: 1.7459628582000732
Validation loss: 2.06573353211085

Epoch: 6| Step: 8
Training loss: 1.9636540412902832
Validation loss: 2.070029338200887

Epoch: 6| Step: 9
Training loss: 2.7763798236846924
Validation loss: 2.0943153699239097

Epoch: 6| Step: 10
Training loss: 2.6215004920959473
Validation loss: 2.1081300576527915

Epoch: 6| Step: 11
Training loss: 1.6443982124328613
Validation loss: 2.1115974386533103

Epoch: 6| Step: 12
Training loss: 2.0214812755584717
Validation loss: 2.0962993502616882

Epoch: 6| Step: 13
Training loss: 1.5581929683685303
Validation loss: 2.104467729727427

Epoch: 132| Step: 0
Training loss: 2.271085739135742
Validation loss: 2.079633037249247

Epoch: 6| Step: 1
Training loss: 1.610926628112793
Validation loss: 2.0835970441500344

Epoch: 6| Step: 2
Training loss: 1.9187729358673096
Validation loss: 2.077727258205414

Epoch: 6| Step: 3
Training loss: 2.025728464126587
Validation loss: 2.0757631262143454

Epoch: 6| Step: 4
Training loss: 2.9837565422058105
Validation loss: 2.063887377580007

Epoch: 6| Step: 5
Training loss: 1.9248058795928955
Validation loss: 2.047811210155487

Epoch: 6| Step: 6
Training loss: 1.5030770301818848
Validation loss: 2.037568747997284

Epoch: 6| Step: 7
Training loss: 2.018541097640991
Validation loss: 2.0402675668398538

Epoch: 6| Step: 8
Training loss: 1.8548184633255005
Validation loss: 2.0487773219744363

Epoch: 6| Step: 9
Training loss: 2.5280323028564453
Validation loss: 2.0482349395751953

Epoch: 6| Step: 10
Training loss: 2.7030189037323
Validation loss: 2.0523390769958496

Epoch: 6| Step: 11
Training loss: 2.1839399337768555
Validation loss: 2.0485978523890176

Epoch: 6| Step: 12
Training loss: 1.5784220695495605
Validation loss: 2.04942786693573

Epoch: 6| Step: 13
Training loss: 1.4423763751983643
Validation loss: 2.0541473229726157

Epoch: 133| Step: 0
Training loss: 2.321986198425293
Validation loss: 2.0734558502833047

Epoch: 6| Step: 1
Training loss: 2.333854913711548
Validation loss: 2.0680530667304993

Epoch: 6| Step: 2
Training loss: 1.9932584762573242
Validation loss: 2.0829639037450156

Epoch: 6| Step: 3
Training loss: 1.7851505279541016
Validation loss: 2.1013551155726113

Epoch: 6| Step: 4
Training loss: 1.3997089862823486
Validation loss: 2.095414479573568

Epoch: 6| Step: 5
Training loss: 2.187171220779419
Validation loss: 2.1184182365735373

Epoch: 6| Step: 6
Training loss: 1.637657642364502
Validation loss: 2.107673386732737

Epoch: 6| Step: 7
Training loss: 2.0406713485717773
Validation loss: 2.11335696776708

Epoch: 6| Step: 8
Training loss: 1.8511898517608643
Validation loss: 2.111669381459554

Epoch: 6| Step: 9
Training loss: 1.373443365097046
Validation loss: 2.101231356461843

Epoch: 6| Step: 10
Training loss: 2.5488805770874023
Validation loss: 2.10136083761851

Epoch: 6| Step: 11
Training loss: 2.4299378395080566
Validation loss: 2.100669503211975

Epoch: 6| Step: 12
Training loss: 2.0495357513427734
Validation loss: 2.0977143049240112

Epoch: 6| Step: 13
Training loss: 2.0484275817871094
Validation loss: 2.1000471711158752

Epoch: 134| Step: 0
Training loss: 1.494797945022583
Validation loss: 2.091867446899414

Epoch: 6| Step: 1
Training loss: 1.6545270681381226
Validation loss: 2.0909350713094077

Epoch: 6| Step: 2
Training loss: 2.2920093536376953
Validation loss: 2.1037816603978476

Epoch: 6| Step: 3
Training loss: 1.507778286933899
Validation loss: 2.099010984102885

Epoch: 6| Step: 4
Training loss: 2.2638585567474365
Validation loss: 2.1112715204556785

Epoch: 6| Step: 5
Training loss: 1.7591431140899658
Validation loss: 2.120201071103414

Epoch: 6| Step: 6
Training loss: 2.1984708309173584
Validation loss: 2.1172672510147095

Epoch: 6| Step: 7
Training loss: 2.48557186126709
Validation loss: 2.109615703423818

Epoch: 6| Step: 8
Training loss: 2.4469175338745117
Validation loss: 2.102644662062327

Epoch: 6| Step: 9
Training loss: 2.379424810409546
Validation loss: 2.082909564177195

Epoch: 6| Step: 10
Training loss: 1.7956280708312988
Validation loss: 2.070853610833486

Epoch: 6| Step: 11
Training loss: 2.461862325668335
Validation loss: 2.0691230495770774

Epoch: 6| Step: 12
Training loss: 2.1639480590820312
Validation loss: 2.057745893796285

Epoch: 6| Step: 13
Training loss: 1.8426421880722046
Validation loss: 2.066875716050466

Epoch: 135| Step: 0
Training loss: 2.289374351501465
Validation loss: 2.049803098042806

Epoch: 6| Step: 1
Training loss: 2.0326485633850098
Validation loss: 2.0626297195752463

Epoch: 6| Step: 2
Training loss: 2.142792224884033
Validation loss: 2.060913383960724

Epoch: 6| Step: 3
Training loss: 2.1726531982421875
Validation loss: 2.0571978092193604

Epoch: 6| Step: 4
Training loss: 1.4756906032562256
Validation loss: 2.063199778397878

Epoch: 6| Step: 5
Training loss: 2.0934643745422363
Validation loss: 2.053318758805593

Epoch: 6| Step: 6
Training loss: 2.132622718811035
Validation loss: 2.0487552483876548

Epoch: 6| Step: 7
Training loss: 1.669614553451538
Validation loss: 2.0535587469736734

Epoch: 6| Step: 8
Training loss: 2.4590766429901123
Validation loss: 2.057723343372345

Epoch: 6| Step: 9
Training loss: 1.8037328720092773
Validation loss: 2.062690536181132

Epoch: 6| Step: 10
Training loss: 2.3533313274383545
Validation loss: 2.0547302961349487

Epoch: 6| Step: 11
Training loss: 2.552687168121338
Validation loss: 2.045525153477987

Epoch: 6| Step: 12
Training loss: 2.4827964305877686
Validation loss: 2.052339474360148

Epoch: 6| Step: 13
Training loss: 1.6971662044525146
Validation loss: 2.062479575475057

Epoch: 136| Step: 0
Training loss: 2.4181461334228516
Validation loss: 2.074156701564789

Epoch: 6| Step: 1
Training loss: 1.5817229747772217
Validation loss: 2.075137734413147

Epoch: 6| Step: 2
Training loss: 1.6761865615844727
Validation loss: 2.0758794943491616

Epoch: 6| Step: 3
Training loss: 2.616568088531494
Validation loss: 2.0884768962860107

Epoch: 6| Step: 4
Training loss: 2.0575265884399414
Validation loss: 2.1017462412516275

Epoch: 6| Step: 5
Training loss: 2.201479911804199
Validation loss: 2.105912168820699

Epoch: 6| Step: 6
Training loss: 1.543373942375183
Validation loss: 2.1051929195721946

Epoch: 6| Step: 7
Training loss: 2.2177834510803223
Validation loss: 2.112180511156718

Epoch: 6| Step: 8
Training loss: 2.882174491882324
Validation loss: 2.103510022163391

Epoch: 6| Step: 9
Training loss: 1.5806992053985596
Validation loss: 2.1215560038884482

Epoch: 6| Step: 10
Training loss: 1.589579701423645
Validation loss: 2.1257019639015198

Epoch: 6| Step: 11
Training loss: 2.1787502765655518
Validation loss: 2.1249417463938394

Epoch: 6| Step: 12
Training loss: 1.5966730117797852
Validation loss: 2.1239656607309976

Epoch: 6| Step: 13
Training loss: 1.8954814672470093
Validation loss: 2.1324337124824524

Epoch: 137| Step: 0
Training loss: 1.9646856784820557
Validation loss: 2.1171732544898987

Epoch: 6| Step: 1
Training loss: 1.4651371240615845
Validation loss: 2.100356340408325

Epoch: 6| Step: 2
Training loss: 1.7644752264022827
Validation loss: 2.0923002560933432

Epoch: 6| Step: 3
Training loss: 1.5912156105041504
Validation loss: 2.0841046969095864

Epoch: 6| Step: 4
Training loss: 1.8839974403381348
Validation loss: 2.068245788415273

Epoch: 6| Step: 5
Training loss: 2.3092732429504395
Validation loss: 2.0860700607299805

Epoch: 6| Step: 6
Training loss: 2.320941925048828
Validation loss: 2.077441910902659

Epoch: 6| Step: 7
Training loss: 1.8201631307601929
Validation loss: 2.076855262120565

Epoch: 6| Step: 8
Training loss: 2.7812612056732178
Validation loss: 2.0826849341392517

Epoch: 6| Step: 9
Training loss: 1.863290786743164
Validation loss: 2.1053061485290527

Epoch: 6| Step: 10
Training loss: 2.2656102180480957
Validation loss: 2.1070290009180703

Epoch: 6| Step: 11
Training loss: 1.9282220602035522
Validation loss: 2.1127345164616904

Epoch: 6| Step: 12
Training loss: 1.8889309167861938
Validation loss: 2.1112168232599893

Epoch: 6| Step: 13
Training loss: 2.4754953384399414
Validation loss: 2.115512748559316

Epoch: 138| Step: 0
Training loss: 1.7788357734680176
Validation loss: 2.120104948679606

Epoch: 6| Step: 1
Training loss: 2.296973705291748
Validation loss: 2.115693231423696

Epoch: 6| Step: 2
Training loss: 1.5922322273254395
Validation loss: 2.109556039174398

Epoch: 6| Step: 3
Training loss: 2.320680856704712
Validation loss: 2.0912240743637085

Epoch: 6| Step: 4
Training loss: 2.290008544921875
Validation loss: 2.077841877937317

Epoch: 6| Step: 5
Training loss: 2.156045436859131
Validation loss: 2.072722017765045

Epoch: 6| Step: 6
Training loss: 2.237074375152588
Validation loss: 2.0570563872655234

Epoch: 6| Step: 7
Training loss: 2.1697704792022705
Validation loss: 2.0646880865097046

Epoch: 6| Step: 8
Training loss: 1.9383654594421387
Validation loss: 2.06592849890391

Epoch: 6| Step: 9
Training loss: 1.8272392749786377
Validation loss: 2.067536254723867

Epoch: 6| Step: 10
Training loss: 2.018515110015869
Validation loss: 2.0857694943745932

Epoch: 6| Step: 11
Training loss: 1.8470098972320557
Validation loss: 2.0765634576479592

Epoch: 6| Step: 12
Training loss: 2.0830109119415283
Validation loss: 2.080244779586792

Epoch: 6| Step: 13
Training loss: 1.5620951652526855
Validation loss: 2.0880858103434243

Epoch: 139| Step: 0
Training loss: 2.0551950931549072
Validation loss: 2.0815667112668357

Epoch: 6| Step: 1
Training loss: 1.6925349235534668
Validation loss: 2.1023279825846353

Epoch: 6| Step: 2
Training loss: 2.0588583946228027
Validation loss: 2.0874284903208413

Epoch: 6| Step: 3
Training loss: 1.6742652654647827
Validation loss: 2.121650298436483

Epoch: 6| Step: 4
Training loss: 2.4303407669067383
Validation loss: 2.114962100982666

Epoch: 6| Step: 5
Training loss: 1.7329154014587402
Validation loss: 2.1288939317067466

Epoch: 6| Step: 6
Training loss: 1.7930552959442139
Validation loss: 2.1269102096557617

Epoch: 6| Step: 7
Training loss: 1.5720219612121582
Validation loss: 2.1121312975883484

Epoch: 6| Step: 8
Training loss: 2.0390281677246094
Validation loss: 2.1151775320370994

Epoch: 6| Step: 9
Training loss: 2.2929773330688477
Validation loss: 2.1018349528312683

Epoch: 6| Step: 10
Training loss: 2.7544116973876953
Validation loss: 2.102931102116903

Epoch: 6| Step: 11
Training loss: 2.313192129135132
Validation loss: 2.0848335425059

Epoch: 6| Step: 12
Training loss: 1.7520272731781006
Validation loss: 2.097826441129049

Epoch: 6| Step: 13
Training loss: 1.7761061191558838
Validation loss: 2.0820677280426025

Epoch: 140| Step: 0
Training loss: 2.144747257232666
Validation loss: 2.0808887680371604

Epoch: 6| Step: 1
Training loss: 1.6022064685821533
Validation loss: 2.0603392918904624

Epoch: 6| Step: 2
Training loss: 1.9804306030273438
Validation loss: 2.0731406211853027

Epoch: 6| Step: 3
Training loss: 1.7228424549102783
Validation loss: 2.074843088785807

Epoch: 6| Step: 4
Training loss: 2.732316017150879
Validation loss: 2.0781372785568237

Epoch: 6| Step: 5
Training loss: 1.887158751487732
Validation loss: 2.085287650426229

Epoch: 6| Step: 6
Training loss: 2.214738368988037
Validation loss: 2.075706958770752

Epoch: 6| Step: 7
Training loss: 1.5273269414901733
Validation loss: 2.0909306009610495

Epoch: 6| Step: 8
Training loss: 1.9636143445968628
Validation loss: 2.1047402024269104

Epoch: 6| Step: 9
Training loss: 2.839597225189209
Validation loss: 2.109528203805288

Epoch: 6| Step: 10
Training loss: 1.7649972438812256
Validation loss: 2.1062583128611245

Epoch: 6| Step: 11
Training loss: 1.6017184257507324
Validation loss: 2.099263350168864

Epoch: 6| Step: 12
Training loss: 2.3143954277038574
Validation loss: 2.097934106985728

Epoch: 6| Step: 13
Training loss: 1.784616470336914
Validation loss: 2.080089569091797

Epoch: 141| Step: 0
Training loss: 1.8649603128433228
Validation loss: 2.0738278230031333

Epoch: 6| Step: 1
Training loss: 2.4386682510375977
Validation loss: 2.069164792696635

Epoch: 6| Step: 2
Training loss: 1.5749106407165527
Validation loss: 2.0727758606274924

Epoch: 6| Step: 3
Training loss: 1.8404064178466797
Validation loss: 2.0799647172292075

Epoch: 6| Step: 4
Training loss: 1.4480918645858765
Validation loss: 2.0734050472577414

Epoch: 6| Step: 5
Training loss: 1.8076198101043701
Validation loss: 2.084839423497518

Epoch: 6| Step: 6
Training loss: 2.2485415935516357
Validation loss: 2.0847269892692566

Epoch: 6| Step: 7
Training loss: 1.7440487146377563
Validation loss: 2.0993731021881104

Epoch: 6| Step: 8
Training loss: 1.3339680433273315
Validation loss: 2.1123576164245605

Epoch: 6| Step: 9
Training loss: 2.34525990486145
Validation loss: 2.1248810291290283

Epoch: 6| Step: 10
Training loss: 2.409252643585205
Validation loss: 2.132838229338328

Epoch: 6| Step: 11
Training loss: 2.5121777057647705
Validation loss: 2.1256679693857827

Epoch: 6| Step: 12
Training loss: 1.9963493347167969
Validation loss: 2.139214555422465

Epoch: 6| Step: 13
Training loss: 2.7218704223632812
Validation loss: 2.1196023424466452

Epoch: 142| Step: 0
Training loss: 1.2592765092849731
Validation loss: 2.1101748744646707

Epoch: 6| Step: 1
Training loss: 2.5358939170837402
Validation loss: 2.1199989716211953

Epoch: 6| Step: 2
Training loss: 1.862755537033081
Validation loss: 2.0952422618865967

Epoch: 6| Step: 3
Training loss: 1.9075167179107666
Validation loss: 2.091432591279348

Epoch: 6| Step: 4
Training loss: 1.451960802078247
Validation loss: 2.0843737522761026

Epoch: 6| Step: 5
Training loss: 2.4671778678894043
Validation loss: 2.0865308245023093

Epoch: 6| Step: 6
Training loss: 1.972214937210083
Validation loss: 2.071526348590851

Epoch: 6| Step: 7
Training loss: 2.4824442863464355
Validation loss: 2.0827025373776755

Epoch: 6| Step: 8
Training loss: 1.398864984512329
Validation loss: 2.08278222878774

Epoch: 6| Step: 9
Training loss: 1.8416091203689575
Validation loss: 2.084811011950175

Epoch: 6| Step: 10
Training loss: 1.5527867078781128
Validation loss: 2.089035451412201

Epoch: 6| Step: 11
Training loss: 2.920642375946045
Validation loss: 2.0995030800501504

Epoch: 6| Step: 12
Training loss: 2.147022008895874
Validation loss: 2.086953421433767

Epoch: 6| Step: 13
Training loss: 2.1822457313537598
Validation loss: 2.100631833076477

Epoch: 143| Step: 0
Training loss: 1.4394285678863525
Validation loss: 2.1056562662124634

Epoch: 6| Step: 1
Training loss: 1.7141717672348022
Validation loss: 2.1090367436408997

Epoch: 6| Step: 2
Training loss: 1.788211464881897
Validation loss: 2.0825173060099282

Epoch: 6| Step: 3
Training loss: 1.9505515098571777
Validation loss: 2.098104417324066

Epoch: 6| Step: 4
Training loss: 1.9638161659240723
Validation loss: 2.1056614319483438

Epoch: 6| Step: 5
Training loss: 1.5101780891418457
Validation loss: 2.1177927056948342

Epoch: 6| Step: 6
Training loss: 2.462881088256836
Validation loss: 2.1031329234441123

Epoch: 6| Step: 7
Training loss: 1.8931931257247925
Validation loss: 2.1169954737027488

Epoch: 6| Step: 8
Training loss: 2.4523074626922607
Validation loss: 2.1014133294423423

Epoch: 6| Step: 9
Training loss: 1.6954126358032227
Validation loss: 2.0911816358566284

Epoch: 6| Step: 10
Training loss: 1.953446865081787
Validation loss: 2.082999368508657

Epoch: 6| Step: 11
Training loss: 2.2041492462158203
Validation loss: 2.0893237789471946

Epoch: 6| Step: 12
Training loss: 2.202862024307251
Validation loss: 2.086656848589579

Epoch: 6| Step: 13
Training loss: 2.3717503547668457
Validation loss: 2.0980151295661926

Epoch: 144| Step: 0
Training loss: 1.783371925354004
Validation loss: 2.0881912112236023

Epoch: 6| Step: 1
Training loss: 1.7642309665679932
Validation loss: 2.08327716588974

Epoch: 6| Step: 2
Training loss: 1.6757698059082031
Validation loss: 2.0918686191240945

Epoch: 6| Step: 3
Training loss: 1.99900484085083
Validation loss: 2.0961327950159707

Epoch: 6| Step: 4
Training loss: 1.6191622018814087
Validation loss: 2.0886985262235007

Epoch: 6| Step: 5
Training loss: 1.6205089092254639
Validation loss: 2.0980806946754456

Epoch: 6| Step: 6
Training loss: 2.6549055576324463
Validation loss: 2.104803502559662

Epoch: 6| Step: 7
Training loss: 1.6843295097351074
Validation loss: 2.1114049752553306

Epoch: 6| Step: 8
Training loss: 2.376859664916992
Validation loss: 2.112809101740519

Epoch: 6| Step: 9
Training loss: 2.691304922103882
Validation loss: 2.1092819770177207

Epoch: 6| Step: 10
Training loss: 2.2058064937591553
Validation loss: 2.104325592517853

Epoch: 6| Step: 11
Training loss: 1.8827117681503296
Validation loss: 2.0978747606277466

Epoch: 6| Step: 12
Training loss: 1.730400800704956
Validation loss: 2.0918137629826865

Epoch: 6| Step: 13
Training loss: 1.8817782402038574
Validation loss: 2.067130466302236

Epoch: 145| Step: 0
Training loss: 2.500147819519043
Validation loss: 2.070803721745809

Epoch: 6| Step: 1
Training loss: 2.1172118186950684
Validation loss: 2.0756775935490928

Epoch: 6| Step: 2
Training loss: 1.7529971599578857
Validation loss: 2.0744978388150535

Epoch: 6| Step: 3
Training loss: 1.7018024921417236
Validation loss: 2.0740907986958823

Epoch: 6| Step: 4
Training loss: 2.12247371673584
Validation loss: 2.0910109877586365

Epoch: 6| Step: 5
Training loss: 1.3872978687286377
Validation loss: 2.085322856903076

Epoch: 6| Step: 6
Training loss: 2.433716297149658
Validation loss: 2.0914490620295205

Epoch: 6| Step: 7
Training loss: 1.706406593322754
Validation loss: 2.0987171133359275

Epoch: 6| Step: 8
Training loss: 1.9215279817581177
Validation loss: 2.12132998307546

Epoch: 6| Step: 9
Training loss: 2.083820343017578
Validation loss: 2.1155887444814048

Epoch: 6| Step: 10
Training loss: 2.251762628555298
Validation loss: 2.1281018257141113

Epoch: 6| Step: 11
Training loss: 1.541155219078064
Validation loss: 2.130620320638021

Epoch: 6| Step: 12
Training loss: 2.423356056213379
Validation loss: 2.1202427546183267

Epoch: 6| Step: 13
Training loss: 1.7307593822479248
Validation loss: 2.103685180346171

Epoch: 146| Step: 0
Training loss: 1.7455899715423584
Validation loss: 2.0988739331563315

Epoch: 6| Step: 1
Training loss: 2.0217373371124268
Validation loss: 2.1127166748046875

Epoch: 6| Step: 2
Training loss: 2.749797821044922
Validation loss: 2.108215034008026

Epoch: 6| Step: 3
Training loss: 1.712472915649414
Validation loss: 2.08580215771993

Epoch: 6| Step: 4
Training loss: 2.134430170059204
Validation loss: 2.0731778144836426

Epoch: 6| Step: 5
Training loss: 1.7724961042404175
Validation loss: 2.0866020123163858

Epoch: 6| Step: 6
Training loss: 1.7695355415344238
Validation loss: 2.08892168601354

Epoch: 6| Step: 7
Training loss: 1.8803138732910156
Validation loss: 2.094345986843109

Epoch: 6| Step: 8
Training loss: 2.166027307510376
Validation loss: 2.0913148125012717

Epoch: 6| Step: 9
Training loss: 1.723850131034851
Validation loss: 2.0922378500302634

Epoch: 6| Step: 10
Training loss: 2.108029842376709
Validation loss: 2.0876073837280273

Epoch: 6| Step: 11
Training loss: 2.2117550373077393
Validation loss: 2.0918609301249185

Epoch: 6| Step: 12
Training loss: 1.4037361145019531
Validation loss: 2.1116861701011658

Epoch: 6| Step: 13
Training loss: 2.057178258895874
Validation loss: 2.100948750972748

Epoch: 147| Step: 0
Training loss: 2.223267078399658
Validation loss: 2.114756007989248

Epoch: 6| Step: 1
Training loss: 1.748706579208374
Validation loss: 2.1324897408485413

Epoch: 6| Step: 2
Training loss: 2.007225275039673
Validation loss: 2.103623926639557

Epoch: 6| Step: 3
Training loss: 2.4096107482910156
Validation loss: 2.1202020247777305

Epoch: 6| Step: 4
Training loss: 1.436314582824707
Validation loss: 2.109749913215637

Epoch: 6| Step: 5
Training loss: 2.143465280532837
Validation loss: 2.12338387966156

Epoch: 6| Step: 6
Training loss: 1.8190546035766602
Validation loss: 2.1444431940714517

Epoch: 6| Step: 7
Training loss: 2.2144079208374023
Validation loss: 2.1313474575678506

Epoch: 6| Step: 8
Training loss: 1.4172327518463135
Validation loss: 2.14382141828537

Epoch: 6| Step: 9
Training loss: 1.6062204837799072
Validation loss: 2.1400747497876487

Epoch: 6| Step: 10
Training loss: 2.0825300216674805
Validation loss: 2.1453119119008384

Epoch: 6| Step: 11
Training loss: 1.9031524658203125
Validation loss: 2.1099846959114075

Epoch: 6| Step: 12
Training loss: 2.222848892211914
Validation loss: 2.105159262816111

Epoch: 6| Step: 13
Training loss: 2.222116470336914
Validation loss: 2.1066244641939798

Epoch: 148| Step: 0
Training loss: 1.7934508323669434
Validation loss: 2.0815064708391824

Epoch: 6| Step: 1
Training loss: 1.3478310108184814
Validation loss: 2.091737528642019

Epoch: 6| Step: 2
Training loss: 2.0580902099609375
Validation loss: 2.092247188091278

Epoch: 6| Step: 3
Training loss: 2.528254508972168
Validation loss: 2.070012092590332

Epoch: 6| Step: 4
Training loss: 2.427590847015381
Validation loss: 2.079427738984426

Epoch: 6| Step: 5
Training loss: 1.88985276222229
Validation loss: 2.0780791441599527

Epoch: 6| Step: 6
Training loss: 1.921208143234253
Validation loss: 2.079287509123484

Epoch: 6| Step: 7
Training loss: 1.5311176776885986
Validation loss: 2.078524927298228

Epoch: 6| Step: 8
Training loss: 1.780350685119629
Validation loss: 2.074557979901632

Epoch: 6| Step: 9
Training loss: 2.648603677749634
Validation loss: 2.078907529513041

Epoch: 6| Step: 10
Training loss: 1.7041120529174805
Validation loss: 2.0899105270703635

Epoch: 6| Step: 11
Training loss: 1.8332971334457397
Validation loss: 2.0971054832140603

Epoch: 6| Step: 12
Training loss: 2.5511016845703125
Validation loss: 2.10151199499766

Epoch: 6| Step: 13
Training loss: 1.808154821395874
Validation loss: 2.1086838841438293

Epoch: 149| Step: 0
Training loss: 2.336287021636963
Validation loss: 2.12332550684611

Epoch: 6| Step: 1
Training loss: 1.988654613494873
Validation loss: 2.1134275992711387

Epoch: 6| Step: 2
Training loss: 1.3852159976959229
Validation loss: 2.1169163982073465

Epoch: 6| Step: 3
Training loss: 2.195847511291504
Validation loss: 2.129666328430176

Epoch: 6| Step: 4
Training loss: 1.909745216369629
Validation loss: 2.109937071800232

Epoch: 6| Step: 5
Training loss: 2.2325668334960938
Validation loss: 2.1166616678237915

Epoch: 6| Step: 6
Training loss: 1.9004757404327393
Validation loss: 2.110142191251119

Epoch: 6| Step: 7
Training loss: 1.731764554977417
Validation loss: 2.085175931453705

Epoch: 6| Step: 8
Training loss: 2.2739977836608887
Validation loss: 2.0823611418406167

Epoch: 6| Step: 9
Training loss: 1.7666512727737427
Validation loss: 2.088085174560547

Epoch: 6| Step: 10
Training loss: 1.7637462615966797
Validation loss: 2.0977287689844766

Epoch: 6| Step: 11
Training loss: 1.6436994075775146
Validation loss: 2.093009829521179

Epoch: 6| Step: 12
Training loss: 2.5900681018829346
Validation loss: 2.1032935778299966

Epoch: 6| Step: 13
Training loss: 1.801668643951416
Validation loss: 2.1115686893463135

Epoch: 150| Step: 0
Training loss: 2.84775972366333
Validation loss: 2.1265859603881836

Epoch: 6| Step: 1
Training loss: 1.891422152519226
Validation loss: 2.1212878823280334

Epoch: 6| Step: 2
Training loss: 1.9153938293457031
Validation loss: 2.1109832326571145

Epoch: 6| Step: 3
Training loss: 2.0471372604370117
Validation loss: 2.1312705874443054

Epoch: 6| Step: 4
Training loss: 1.927778720855713
Validation loss: 2.1321380734443665

Epoch: 6| Step: 5
Training loss: 1.8441637754440308
Validation loss: 2.140204985936483

Epoch: 6| Step: 6
Training loss: 2.192138671875
Validation loss: 2.1228036483128867

Epoch: 6| Step: 7
Training loss: 2.0808629989624023
Validation loss: 2.096427400906881

Epoch: 6| Step: 8
Training loss: 1.516787052154541
Validation loss: 2.0938149293263755

Epoch: 6| Step: 9
Training loss: 2.104111433029175
Validation loss: 2.101151943206787

Epoch: 6| Step: 10
Training loss: 1.6583797931671143
Validation loss: 2.0816331108411155

Epoch: 6| Step: 11
Training loss: 1.3700933456420898
Validation loss: 2.087623715400696

Epoch: 6| Step: 12
Training loss: 2.285203218460083
Validation loss: 2.100052217642466

Epoch: 6| Step: 13
Training loss: 1.6008474826812744
Validation loss: 2.0995055437088013

Epoch: 151| Step: 0
Training loss: 1.8814146518707275
Validation loss: 2.1047224203745523

Epoch: 6| Step: 1
Training loss: 1.5102880001068115
Validation loss: 2.098281184832255

Epoch: 6| Step: 2
Training loss: 2.052332878112793
Validation loss: 2.1071638464927673

Epoch: 6| Step: 3
Training loss: 1.6313412189483643
Validation loss: 2.113755146662394

Epoch: 6| Step: 4
Training loss: 1.4381417036056519
Validation loss: 2.1189060608545938

Epoch: 6| Step: 5
Training loss: 2.2309985160827637
Validation loss: 2.121574958165487

Epoch: 6| Step: 6
Training loss: 2.1364970207214355
Validation loss: 2.1174843311309814

Epoch: 6| Step: 7
Training loss: 2.2006304264068604
Validation loss: 2.105600893497467

Epoch: 6| Step: 8
Training loss: 1.9750871658325195
Validation loss: 2.0987696448961892

Epoch: 6| Step: 9
Training loss: 2.0178513526916504
Validation loss: 2.1120279828707376

Epoch: 6| Step: 10
Training loss: 1.7912147045135498
Validation loss: 2.087696293989817

Epoch: 6| Step: 11
Training loss: 2.116603374481201
Validation loss: 2.0927252173423767

Epoch: 6| Step: 12
Training loss: 1.7188720703125
Validation loss: 2.0950858195622764

Epoch: 6| Step: 13
Training loss: 2.7122297286987305
Validation loss: 2.090111553668976

Epoch: 152| Step: 0
Training loss: 2.226644515991211
Validation loss: 2.102250079313914

Epoch: 6| Step: 1
Training loss: 1.8860485553741455
Validation loss: 2.1037206848462424

Epoch: 6| Step: 2
Training loss: 1.848899483680725
Validation loss: 2.1170772711435952

Epoch: 6| Step: 3
Training loss: 2.063321113586426
Validation loss: 2.1200137535730996

Epoch: 6| Step: 4
Training loss: 1.7147016525268555
Validation loss: 2.124219218889872

Epoch: 6| Step: 5
Training loss: 2.2169318199157715
Validation loss: 2.1238236824671426

Epoch: 6| Step: 6
Training loss: 1.9349945783615112
Validation loss: 2.1223666667938232

Epoch: 6| Step: 7
Training loss: 1.7551138401031494
Validation loss: 2.1374751329421997

Epoch: 6| Step: 8
Training loss: 1.5114952325820923
Validation loss: 2.1181029081344604

Epoch: 6| Step: 9
Training loss: 1.7271963357925415
Validation loss: 2.1045539379119873

Epoch: 6| Step: 10
Training loss: 1.5852794647216797
Validation loss: 2.083138128121694

Epoch: 6| Step: 11
Training loss: 2.24198579788208
Validation loss: 2.076522171497345

Epoch: 6| Step: 12
Training loss: 2.2165427207946777
Validation loss: 2.076896071434021

Epoch: 6| Step: 13
Training loss: 2.198909282684326
Validation loss: 2.075692435105642

Epoch: 153| Step: 0
Training loss: 2.405930280685425
Validation loss: 2.0775938828786216

Epoch: 6| Step: 1
Training loss: 1.4130284786224365
Validation loss: 2.08294415473938

Epoch: 6| Step: 2
Training loss: 2.319122314453125
Validation loss: 2.080885390440623

Epoch: 6| Step: 3
Training loss: 1.4722185134887695
Validation loss: 2.070325255393982

Epoch: 6| Step: 4
Training loss: 1.8084733486175537
Validation loss: 2.0819848775863647

Epoch: 6| Step: 5
Training loss: 2.083740711212158
Validation loss: 2.0903842051823935

Epoch: 6| Step: 6
Training loss: 2.174604892730713
Validation loss: 2.0897297859191895

Epoch: 6| Step: 7
Training loss: 2.1382179260253906
Validation loss: 2.097802758216858

Epoch: 6| Step: 8
Training loss: 2.179258346557617
Validation loss: 2.1079023480415344

Epoch: 6| Step: 9
Training loss: 1.9582124948501587
Validation loss: 2.122716784477234

Epoch: 6| Step: 10
Training loss: 1.9532376527786255
Validation loss: 2.1327894727389016

Epoch: 6| Step: 11
Training loss: 1.9871505498886108
Validation loss: 2.1393693685531616

Epoch: 6| Step: 12
Training loss: 2.2177376747131348
Validation loss: 2.1298073331514993

Epoch: 6| Step: 13
Training loss: 1.5037641525268555
Validation loss: 2.1263683239618936

Epoch: 154| Step: 0
Training loss: 1.5792412757873535
Validation loss: 2.1188469727834067

Epoch: 6| Step: 1
Training loss: 2.1806397438049316
Validation loss: 2.117586155732473

Epoch: 6| Step: 2
Training loss: 1.6559703350067139
Validation loss: 2.0992165406545005

Epoch: 6| Step: 3
Training loss: 1.9400341510772705
Validation loss: 2.1025427182515464

Epoch: 6| Step: 4
Training loss: 1.874834656715393
Validation loss: 2.1172473231951394

Epoch: 6| Step: 5
Training loss: 2.450890302658081
Validation loss: 2.107786238193512

Epoch: 6| Step: 6
Training loss: 1.4775408506393433
Validation loss: 2.129505674044291

Epoch: 6| Step: 7
Training loss: 2.230459213256836
Validation loss: 2.117818911870321

Epoch: 6| Step: 8
Training loss: 1.7656053304672241
Validation loss: 2.1011957128842673

Epoch: 6| Step: 9
Training loss: 1.8975067138671875
Validation loss: 2.115226407845815

Epoch: 6| Step: 10
Training loss: 1.9770729541778564
Validation loss: 2.102799872557322

Epoch: 6| Step: 11
Training loss: 1.486560583114624
Validation loss: 2.1007384061813354

Epoch: 6| Step: 12
Training loss: 2.5871188640594482
Validation loss: 2.098739743232727

Epoch: 6| Step: 13
Training loss: 2.2245936393737793
Validation loss: 2.1149141589800515

Epoch: 155| Step: 0
Training loss: 1.9689617156982422
Validation loss: 2.1277614633242288

Epoch: 6| Step: 1
Training loss: 2.1707820892333984
Validation loss: 2.13529102007548

Epoch: 6| Step: 2
Training loss: 1.5532824993133545
Validation loss: 2.1316474278767905

Epoch: 6| Step: 3
Training loss: 2.3321707248687744
Validation loss: 2.1369128823280334

Epoch: 6| Step: 4
Training loss: 1.607253909111023
Validation loss: 2.141748050848643

Epoch: 6| Step: 5
Training loss: 1.3967173099517822
Validation loss: 2.1363575061162314

Epoch: 6| Step: 6
Training loss: 2.00544810295105
Validation loss: 2.141977588335673

Epoch: 6| Step: 7
Training loss: 1.5869724750518799
Validation loss: 2.1270594795544944

Epoch: 6| Step: 8
Training loss: 2.0068206787109375
Validation loss: 2.119464914004008

Epoch: 6| Step: 9
Training loss: 1.7110588550567627
Validation loss: 2.1006969014803567

Epoch: 6| Step: 10
Training loss: 2.203108549118042
Validation loss: 2.1103255351384482

Epoch: 6| Step: 11
Training loss: 1.9243097305297852
Validation loss: 2.0959123770395913

Epoch: 6| Step: 12
Training loss: 2.617910385131836
Validation loss: 2.10292116800944

Epoch: 6| Step: 13
Training loss: 2.010669469833374
Validation loss: 2.1007029016812644

Epoch: 156| Step: 0
Training loss: 2.195175886154175
Validation loss: 2.097738722960154

Epoch: 6| Step: 1
Training loss: 2.007836103439331
Validation loss: 2.1129093170166016

Epoch: 6| Step: 2
Training loss: 1.2218929529190063
Validation loss: 2.099690536657969

Epoch: 6| Step: 3
Training loss: 1.7714802026748657
Validation loss: 2.1132944027582803

Epoch: 6| Step: 4
Training loss: 1.8660759925842285
Validation loss: 2.1190787156422934

Epoch: 6| Step: 5
Training loss: 2.225358486175537
Validation loss: 2.1169144908587136

Epoch: 6| Step: 6
Training loss: 2.099762201309204
Validation loss: 2.122076094150543

Epoch: 6| Step: 7
Training loss: 2.6943063735961914
Validation loss: 2.126349151134491

Epoch: 6| Step: 8
Training loss: 2.052374839782715
Validation loss: 2.1147751609484353

Epoch: 6| Step: 9
Training loss: 1.5743021965026855
Validation loss: 2.100016991297404

Epoch: 6| Step: 10
Training loss: 1.7302955389022827
Validation loss: 2.1008426547050476

Epoch: 6| Step: 11
Training loss: 1.407220721244812
Validation loss: 2.10441384712855

Epoch: 6| Step: 12
Training loss: 2.3988723754882812
Validation loss: 2.085330625375112

Epoch: 6| Step: 13
Training loss: 1.6251702308654785
Validation loss: 2.1030710538228354

Epoch: 157| Step: 0
Training loss: 1.311720371246338
Validation loss: 2.104392389456431

Epoch: 6| Step: 1
Training loss: 1.636138677597046
Validation loss: 2.113334139188131

Epoch: 6| Step: 2
Training loss: 1.9637943506240845
Validation loss: 2.1068111856778464

Epoch: 6| Step: 3
Training loss: 2.1038994789123535
Validation loss: 2.130079170068105

Epoch: 6| Step: 4
Training loss: 2.0111031532287598
Validation loss: 2.1185798247655234

Epoch: 6| Step: 5
Training loss: 1.8388752937316895
Validation loss: 2.1369558572769165

Epoch: 6| Step: 6
Training loss: 1.9447298049926758
Validation loss: 2.1308894554773965

Epoch: 6| Step: 7
Training loss: 1.5391364097595215
Validation loss: 2.1362250049908957

Epoch: 6| Step: 8
Training loss: 1.836525559425354
Validation loss: 2.1430698235829673

Epoch: 6| Step: 9
Training loss: 1.969422698020935
Validation loss: 2.1271660327911377

Epoch: 6| Step: 10
Training loss: 2.20729660987854
Validation loss: 2.127005080382029

Epoch: 6| Step: 11
Training loss: 2.893630027770996
Validation loss: 2.1149082581202188

Epoch: 6| Step: 12
Training loss: 2.0283656120300293
Validation loss: 2.11334220568339

Epoch: 6| Step: 13
Training loss: 1.4302926063537598
Validation loss: 2.10005913178126

Epoch: 158| Step: 0
Training loss: 1.857330560684204
Validation loss: 2.099597414334615

Epoch: 6| Step: 1
Training loss: 2.1587576866149902
Validation loss: 2.112516979376475

Epoch: 6| Step: 2
Training loss: 1.6543657779693604
Validation loss: 2.1149194637934365

Epoch: 6| Step: 3
Training loss: 1.5641627311706543
Validation loss: 2.141923944155375

Epoch: 6| Step: 4
Training loss: 2.6265242099761963
Validation loss: 2.13456799586614

Epoch: 6| Step: 5
Training loss: 2.0104727745056152
Validation loss: 2.1375178893407187

Epoch: 6| Step: 6
Training loss: 1.5926403999328613
Validation loss: 2.1385377645492554

Epoch: 6| Step: 7
Training loss: 1.4718939065933228
Validation loss: 2.126022219657898

Epoch: 6| Step: 8
Training loss: 1.5075101852416992
Validation loss: 2.1083499987920127

Epoch: 6| Step: 9
Training loss: 1.8361279964447021
Validation loss: 2.1145025293032327

Epoch: 6| Step: 10
Training loss: 1.6600549221038818
Validation loss: 2.0999194582303367

Epoch: 6| Step: 11
Training loss: 2.0663087368011475
Validation loss: 2.092894196510315

Epoch: 6| Step: 12
Training loss: 2.2079718112945557
Validation loss: 2.1021496057510376

Epoch: 6| Step: 13
Training loss: 2.816169261932373
Validation loss: 2.0941742857297263

Epoch: 159| Step: 0
Training loss: 1.5667356252670288
Validation loss: 2.125459889570872

Epoch: 6| Step: 1
Training loss: 2.4196677207946777
Validation loss: 2.1006576220194497

Epoch: 6| Step: 2
Training loss: 2.2926855087280273
Validation loss: 2.112675150235494

Epoch: 6| Step: 3
Training loss: 1.9458316564559937
Validation loss: 2.101236422856649

Epoch: 6| Step: 4
Training loss: 1.6213793754577637
Validation loss: 2.1143762866655984

Epoch: 6| Step: 5
Training loss: 1.3149620294570923
Validation loss: 2.0902892549832663

Epoch: 6| Step: 6
Training loss: 1.9251759052276611
Validation loss: 2.097617030143738

Epoch: 6| Step: 7
Training loss: 1.7420547008514404
Validation loss: 2.0996795296669006

Epoch: 6| Step: 8
Training loss: 1.5085129737854004
Validation loss: 2.113923708597819

Epoch: 6| Step: 9
Training loss: 1.6499836444854736
Validation loss: 2.097807010014852

Epoch: 6| Step: 10
Training loss: 1.9314582347869873
Validation loss: 2.1120383540789285

Epoch: 6| Step: 11
Training loss: 2.9304256439208984
Validation loss: 2.120495061079661

Epoch: 6| Step: 12
Training loss: 1.8148207664489746
Validation loss: 2.1468545397122702

Epoch: 6| Step: 13
Training loss: 2.0985639095306396
Validation loss: 2.1642187436421714

Epoch: 160| Step: 0
Training loss: 2.041628360748291
Validation loss: 2.160579959551493

Epoch: 6| Step: 1
Training loss: 2.328188896179199
Validation loss: 2.1779114802678428

Epoch: 6| Step: 2
Training loss: 1.0951898097991943
Validation loss: 2.147109568119049

Epoch: 6| Step: 3
Training loss: 1.733412504196167
Validation loss: 2.1385921637217202

Epoch: 6| Step: 4
Training loss: 2.0895943641662598
Validation loss: 2.13683154185613

Epoch: 6| Step: 5
Training loss: 2.3598289489746094
Validation loss: 2.123225450515747

Epoch: 6| Step: 6
Training loss: 1.8368871212005615
Validation loss: 2.108645419279734

Epoch: 6| Step: 7
Training loss: 1.9717729091644287
Validation loss: 2.097669303417206

Epoch: 6| Step: 8
Training loss: 2.149064064025879
Validation loss: 2.1077410777409873

Epoch: 6| Step: 9
Training loss: 2.428494691848755
Validation loss: 2.0910749435424805

Epoch: 6| Step: 10
Training loss: 2.3991219997406006
Validation loss: 2.092051605383555

Epoch: 6| Step: 11
Training loss: 1.3146172761917114
Validation loss: 2.096453865369161

Epoch: 6| Step: 12
Training loss: 1.8037090301513672
Validation loss: 2.1030675570170083

Epoch: 6| Step: 13
Training loss: 1.6974345445632935
Validation loss: 2.093278189500173

Epoch: 161| Step: 0
Training loss: 1.7971879243850708
Validation loss: 2.1075223882993064

Epoch: 6| Step: 1
Training loss: 1.9194636344909668
Validation loss: 2.120872457822164

Epoch: 6| Step: 2
Training loss: 1.275740146636963
Validation loss: 2.130304455757141

Epoch: 6| Step: 3
Training loss: 1.6343812942504883
Validation loss: 2.1378328601519265

Epoch: 6| Step: 4
Training loss: 1.8889201879501343
Validation loss: 2.149341960748037

Epoch: 6| Step: 5
Training loss: 2.6619791984558105
Validation loss: 2.147144635518392

Epoch: 6| Step: 6
Training loss: 1.42896568775177
Validation loss: 2.1328428188959756

Epoch: 6| Step: 7
Training loss: 2.1348278522491455
Validation loss: 2.106103479862213

Epoch: 6| Step: 8
Training loss: 2.0409510135650635
Validation loss: 2.1173869570096335

Epoch: 6| Step: 9
Training loss: 2.2490670680999756
Validation loss: 2.0972288648287454

Epoch: 6| Step: 10
Training loss: 2.358856201171875
Validation loss: 2.098425030708313

Epoch: 6| Step: 11
Training loss: 2.383362293243408
Validation loss: 2.09213795264562

Epoch: 6| Step: 12
Training loss: 1.5590732097625732
Validation loss: 2.0881060560544333

Epoch: 6| Step: 13
Training loss: 1.8977282047271729
Validation loss: 2.074641148249308

Epoch: 162| Step: 0
Training loss: 1.5337533950805664
Validation loss: 2.085116684436798

Epoch: 6| Step: 1
Training loss: 2.547942876815796
Validation loss: 2.08563768863678

Epoch: 6| Step: 2
Training loss: 1.86094069480896
Validation loss: 2.090505381425222

Epoch: 6| Step: 3
Training loss: 1.7851529121398926
Validation loss: 2.0765512188275657

Epoch: 6| Step: 4
Training loss: 1.8291411399841309
Validation loss: 2.0808737874031067

Epoch: 6| Step: 5
Training loss: 1.5735764503479004
Validation loss: 2.098004082838694

Epoch: 6| Step: 6
Training loss: 1.8443093299865723
Validation loss: 2.088185807069143

Epoch: 6| Step: 7
Training loss: 1.933630108833313
Validation loss: 2.109062890211741

Epoch: 6| Step: 8
Training loss: 2.1060686111450195
Validation loss: 2.123650848865509

Epoch: 6| Step: 9
Training loss: 2.027759075164795
Validation loss: 2.1187767386436462

Epoch: 6| Step: 10
Training loss: 2.1237525939941406
Validation loss: 2.130085905392965

Epoch: 6| Step: 11
Training loss: 2.3621068000793457
Validation loss: 2.1271779537200928

Epoch: 6| Step: 12
Training loss: 1.8733667135238647
Validation loss: 2.1317895452181497

Epoch: 6| Step: 13
Training loss: 1.775102138519287
Validation loss: 2.1237552960713706

Epoch: 163| Step: 0
Training loss: 2.808781623840332
Validation loss: 2.1201910177866616

Epoch: 6| Step: 1
Training loss: 1.44891357421875
Validation loss: 2.1305145223935447

Epoch: 6| Step: 2
Training loss: 2.48093581199646
Validation loss: 2.123433510462443

Epoch: 6| Step: 3
Training loss: 1.9929115772247314
Validation loss: 2.1244179606437683

Epoch: 6| Step: 4
Training loss: 1.1706680059432983
Validation loss: 2.10927152633667

Epoch: 6| Step: 5
Training loss: 1.4542155265808105
Validation loss: 2.0991881291071572

Epoch: 6| Step: 6
Training loss: 1.69411039352417
Validation loss: 2.117392619450887

Epoch: 6| Step: 7
Training loss: 1.833986759185791
Validation loss: 2.1035589973131814

Epoch: 6| Step: 8
Training loss: 1.2937458753585815
Validation loss: 2.1073184410730996

Epoch: 6| Step: 9
Training loss: 2.5674848556518555
Validation loss: 2.095043659210205

Epoch: 6| Step: 10
Training loss: 1.5581417083740234
Validation loss: 2.11703230937322

Epoch: 6| Step: 11
Training loss: 2.1578245162963867
Validation loss: 2.1122982104619346

Epoch: 6| Step: 12
Training loss: 2.1469366550445557
Validation loss: 2.1135040124257407

Epoch: 6| Step: 13
Training loss: 2.1963400840759277
Validation loss: 2.121229827404022

Epoch: 164| Step: 0
Training loss: 1.9844989776611328
Validation loss: 2.135127325852712

Epoch: 6| Step: 1
Training loss: 1.6791119575500488
Validation loss: 2.1393006443977356

Epoch: 6| Step: 2
Training loss: 1.4810500144958496
Validation loss: 2.1446565985679626

Epoch: 6| Step: 3
Training loss: 1.4173336029052734
Validation loss: 2.144863029321035

Epoch: 6| Step: 4
Training loss: 1.5467541217803955
Validation loss: 2.1351027488708496

Epoch: 6| Step: 5
Training loss: 2.2465033531188965
Validation loss: 2.1275052626927695

Epoch: 6| Step: 6
Training loss: 1.9909731149673462
Validation loss: 2.1389402747154236

Epoch: 6| Step: 7
Training loss: 2.1255617141723633
Validation loss: 2.137211044629415

Epoch: 6| Step: 8
Training loss: 2.281782865524292
Validation loss: 2.1387656927108765

Epoch: 6| Step: 9
Training loss: 1.9682047367095947
Validation loss: 2.1203558246294656

Epoch: 6| Step: 10
Training loss: 1.8771257400512695
Validation loss: 2.117306967576345

Epoch: 6| Step: 11
Training loss: 1.8261334896087646
Validation loss: 2.123515009880066

Epoch: 6| Step: 12
Training loss: 2.207322835922241
Validation loss: 2.105109433333079

Epoch: 6| Step: 13
Training loss: 2.411118984222412
Validation loss: 2.1128304998079934

Epoch: 165| Step: 0
Training loss: 1.338318109512329
Validation loss: 2.121415615081787

Epoch: 6| Step: 1
Training loss: 1.862786054611206
Validation loss: 2.1172914505004883

Epoch: 6| Step: 2
Training loss: 1.5645699501037598
Validation loss: 2.141029973824819

Epoch: 6| Step: 3
Training loss: 1.985377311706543
Validation loss: 2.1523144443829856

Epoch: 6| Step: 4
Training loss: 2.0520453453063965
Validation loss: 2.154142657915751

Epoch: 6| Step: 5
Training loss: 1.8694775104522705
Validation loss: 2.1399819453557334

Epoch: 6| Step: 6
Training loss: 2.1000418663024902
Validation loss: 2.159956415494283

Epoch: 6| Step: 7
Training loss: 2.107544183731079
Validation loss: 2.1387826601664224

Epoch: 6| Step: 8
Training loss: 2.250145435333252
Validation loss: 2.142189701398214

Epoch: 6| Step: 9
Training loss: 2.0997321605682373
Validation loss: 2.1266168355941772

Epoch: 6| Step: 10
Training loss: 1.9542090892791748
Validation loss: 2.1142711440722146

Epoch: 6| Step: 11
Training loss: 1.7357442378997803
Validation loss: 2.1107040643692017

Epoch: 6| Step: 12
Training loss: 2.4828248023986816
Validation loss: 2.115537424882253

Epoch: 6| Step: 13
Training loss: 1.537624716758728
Validation loss: 2.1181178092956543

Epoch: 166| Step: 0
Training loss: 1.7317864894866943
Validation loss: 2.10882838567098

Epoch: 6| Step: 1
Training loss: 1.5852041244506836
Validation loss: 2.0858003298441568

Epoch: 6| Step: 2
Training loss: 2.039274215698242
Validation loss: 2.084391713142395

Epoch: 6| Step: 3
Training loss: 2.0072154998779297
Validation loss: 2.0977516571680703

Epoch: 6| Step: 4
Training loss: 1.6173512935638428
Validation loss: 2.092198153336843

Epoch: 6| Step: 5
Training loss: 2.405064582824707
Validation loss: 2.0954508781433105

Epoch: 6| Step: 6
Training loss: 1.897515892982483
Validation loss: 2.093682328859965

Epoch: 6| Step: 7
Training loss: 1.4681363105773926
Validation loss: 2.092596968015035

Epoch: 6| Step: 8
Training loss: 2.0169615745544434
Validation loss: 2.121068278948466

Epoch: 6| Step: 9
Training loss: 1.5318825244903564
Validation loss: 2.130182425181071

Epoch: 6| Step: 10
Training loss: 2.232837438583374
Validation loss: 2.1695250074068704

Epoch: 6| Step: 11
Training loss: 1.7420533895492554
Validation loss: 2.1822094122568765

Epoch: 6| Step: 12
Training loss: 2.2003211975097656
Validation loss: 2.166011333465576

Epoch: 6| Step: 13
Training loss: 2.353862762451172
Validation loss: 2.185622970263163

Epoch: 167| Step: 0
Training loss: 2.453500747680664
Validation loss: 2.1461549401283264

Epoch: 6| Step: 1
Training loss: 1.3462646007537842
Validation loss: 2.1410228610038757

Epoch: 6| Step: 2
Training loss: 2.214487075805664
Validation loss: 2.1213183403015137

Epoch: 6| Step: 3
Training loss: 2.463167428970337
Validation loss: 2.1081661581993103

Epoch: 6| Step: 4
Training loss: 1.5004734992980957
Validation loss: 2.10867569843928

Epoch: 6| Step: 5
Training loss: 1.7031447887420654
Validation loss: 2.0987408558527627

Epoch: 6| Step: 6
Training loss: 2.1000680923461914
Validation loss: 2.100462039311727

Epoch: 6| Step: 7
Training loss: 2.047351360321045
Validation loss: 2.094672600428263

Epoch: 6| Step: 8
Training loss: 1.7721580266952515
Validation loss: 2.096709132194519

Epoch: 6| Step: 9
Training loss: 2.105247974395752
Validation loss: 2.1047019362449646

Epoch: 6| Step: 10
Training loss: 1.6520988941192627
Validation loss: 2.117576281229655

Epoch: 6| Step: 11
Training loss: 1.6128690242767334
Validation loss: 2.113503019014994

Epoch: 6| Step: 12
Training loss: 2.0419762134552
Validation loss: 2.125230848789215

Epoch: 6| Step: 13
Training loss: 1.8480784893035889
Validation loss: 2.153132597605387

Epoch: 168| Step: 0
Training loss: 2.6487631797790527
Validation loss: 2.1783962647120156

Epoch: 6| Step: 1
Training loss: 1.7972548007965088
Validation loss: 2.179916501045227

Epoch: 6| Step: 2
Training loss: 1.660093069076538
Validation loss: 2.1878864566485086

Epoch: 6| Step: 3
Training loss: 2.022315740585327
Validation loss: 2.167888899644216

Epoch: 6| Step: 4
Training loss: 1.950876235961914
Validation loss: 2.171558698018392

Epoch: 6| Step: 5
Training loss: 1.5300179719924927
Validation loss: 2.1659002105394998

Epoch: 6| Step: 6
Training loss: 2.0405895709991455
Validation loss: 2.138537506262461

Epoch: 6| Step: 7
Training loss: 2.563469171524048
Validation loss: 2.1337352196375527

Epoch: 6| Step: 8
Training loss: 1.3783607482910156
Validation loss: 2.1233787139256797

Epoch: 6| Step: 9
Training loss: 1.763801097869873
Validation loss: 2.1093633572260537

Epoch: 6| Step: 10
Training loss: 2.7664682865142822
Validation loss: 2.1132012406984964

Epoch: 6| Step: 11
Training loss: 1.4863414764404297
Validation loss: 2.0984854698181152

Epoch: 6| Step: 12
Training loss: 1.6322212219238281
Validation loss: 2.0956395665804544

Epoch: 6| Step: 13
Training loss: 1.8986443281173706
Validation loss: 2.1386742989222207

Epoch: 169| Step: 0
Training loss: 1.7906060218811035
Validation loss: 2.135486980279287

Epoch: 6| Step: 1
Training loss: 1.732679009437561
Validation loss: 2.1114420692125955

Epoch: 6| Step: 2
Training loss: 1.3187317848205566
Validation loss: 2.1256061593691506

Epoch: 6| Step: 3
Training loss: 2.365025281906128
Validation loss: 2.1270999908447266

Epoch: 6| Step: 4
Training loss: 2.0797908306121826
Validation loss: 2.129646062850952

Epoch: 6| Step: 5
Training loss: 2.4060163497924805
Validation loss: 2.1569719513257346

Epoch: 6| Step: 6
Training loss: 1.5056514739990234
Validation loss: 2.150728424390157

Epoch: 6| Step: 7
Training loss: 1.6422245502471924
Validation loss: 2.1457364161809287

Epoch: 6| Step: 8
Training loss: 1.4347680807113647
Validation loss: 2.161211669445038

Epoch: 6| Step: 9
Training loss: 1.4517574310302734
Validation loss: 2.1496270298957825

Epoch: 6| Step: 10
Training loss: 1.8056650161743164
Validation loss: 2.1443980733553567

Epoch: 6| Step: 11
Training loss: 2.5536856651306152
Validation loss: 2.1343889832496643

Epoch: 6| Step: 12
Training loss: 2.469625473022461
Validation loss: 2.1414143443107605

Epoch: 6| Step: 13
Training loss: 2.255128860473633
Validation loss: 2.11508572101593

Epoch: 170| Step: 0
Training loss: 2.024541139602661
Validation loss: 2.1200620333353677

Epoch: 6| Step: 1
Training loss: 1.7498395442962646
Validation loss: 2.09791894753774

Epoch: 6| Step: 2
Training loss: 1.819688081741333
Validation loss: 2.0993308822313943

Epoch: 6| Step: 3
Training loss: 2.6028218269348145
Validation loss: 2.0971224109331765

Epoch: 6| Step: 4
Training loss: 1.7901808023452759
Validation loss: 2.103623906771342

Epoch: 6| Step: 5
Training loss: 1.6308398246765137
Validation loss: 2.094860593477885

Epoch: 6| Step: 6
Training loss: 1.8133375644683838
Validation loss: 2.0965967575709024

Epoch: 6| Step: 7
Training loss: 1.548620581626892
Validation loss: 2.1124752958615622

Epoch: 6| Step: 8
Training loss: 2.091729164123535
Validation loss: 2.1198969086011252

Epoch: 6| Step: 9
Training loss: 1.8986016511917114
Validation loss: 2.1354257663091025

Epoch: 6| Step: 10
Training loss: 1.4738366603851318
Validation loss: 2.135780692100525

Epoch: 6| Step: 11
Training loss: 2.4793291091918945
Validation loss: 2.150591711203257

Epoch: 6| Step: 12
Training loss: 1.8543312549591064
Validation loss: 2.1590214371681213

Epoch: 6| Step: 13
Training loss: 1.7638450860977173
Validation loss: 2.130265772342682

Epoch: 171| Step: 0
Training loss: 2.2411398887634277
Validation loss: 2.13318661848704

Epoch: 6| Step: 1
Training loss: 1.5950758457183838
Validation loss: 2.142801304658254

Epoch: 6| Step: 2
Training loss: 1.3749576807022095
Validation loss: 2.16485329469045

Epoch: 6| Step: 3
Training loss: 1.9377906322479248
Validation loss: 2.169384181499481

Epoch: 6| Step: 4
Training loss: 2.5235095024108887
Validation loss: 2.17067821820577

Epoch: 6| Step: 5
Training loss: 1.7970542907714844
Validation loss: 2.143545667330424

Epoch: 6| Step: 6
Training loss: 2.4091343879699707
Validation loss: 2.1474654277165732

Epoch: 6| Step: 7
Training loss: 2.1713027954101562
Validation loss: 2.131261189778646

Epoch: 6| Step: 8
Training loss: 1.8160218000411987
Validation loss: 2.1333178281784058

Epoch: 6| Step: 9
Training loss: 1.5309054851531982
Validation loss: 2.1453364292780557

Epoch: 6| Step: 10
Training loss: 1.55877685546875
Validation loss: 2.139021873474121

Epoch: 6| Step: 11
Training loss: 1.9293813705444336
Validation loss: 2.1142783959706626

Epoch: 6| Step: 12
Training loss: 1.8221948146820068
Validation loss: 2.1047556400299072

Epoch: 6| Step: 13
Training loss: 1.932494878768921
Validation loss: 2.1212053298950195

Epoch: 172| Step: 0
Training loss: 2.554175615310669
Validation loss: 2.1080581148465476

Epoch: 6| Step: 1
Training loss: 1.6865479946136475
Validation loss: 2.116727670033773

Epoch: 6| Step: 2
Training loss: 2.0895919799804688
Validation loss: 2.1235709190368652

Epoch: 6| Step: 3
Training loss: 2.007430076599121
Validation loss: 2.111033002535502

Epoch: 6| Step: 4
Training loss: 2.439775228500366
Validation loss: 2.1222707827885947

Epoch: 6| Step: 5
Training loss: 1.4288407564163208
Validation loss: 2.1434785525004068

Epoch: 6| Step: 6
Training loss: 1.2775942087173462
Validation loss: 2.1703136761983237

Epoch: 6| Step: 7
Training loss: 2.0086259841918945
Validation loss: 2.155296246210734

Epoch: 6| Step: 8
Training loss: 1.7557207345962524
Validation loss: 2.1908694903055825

Epoch: 6| Step: 9
Training loss: 1.7270761728286743
Validation loss: 2.166969279448191

Epoch: 6| Step: 10
Training loss: 1.857450246810913
Validation loss: 2.1669872601826987

Epoch: 6| Step: 11
Training loss: 1.7933030128479004
Validation loss: 2.1561436851819358

Epoch: 6| Step: 12
Training loss: 2.0397090911865234
Validation loss: 2.1378058989842734

Epoch: 6| Step: 13
Training loss: 1.7770178318023682
Validation loss: 2.1384358406066895

Epoch: 173| Step: 0
Training loss: 1.8810558319091797
Validation loss: 2.1482192079226174

Epoch: 6| Step: 1
Training loss: 1.8260037899017334
Validation loss: 2.1410155097643533

Epoch: 6| Step: 2
Training loss: 1.389001727104187
Validation loss: 2.1651015679041543

Epoch: 6| Step: 3
Training loss: 1.788563847541809
Validation loss: 2.1572176615397134

Epoch: 6| Step: 4
Training loss: 2.056222438812256
Validation loss: 2.16568116346995

Epoch: 6| Step: 5
Training loss: 1.9918831586837769
Validation loss: 2.1346372961997986

Epoch: 6| Step: 6
Training loss: 2.6502463817596436
Validation loss: 2.1203197042147317

Epoch: 6| Step: 7
Training loss: 2.2559216022491455
Validation loss: 2.1175071001052856

Epoch: 6| Step: 8
Training loss: 1.7228044271469116
Validation loss: 2.114873727162679

Epoch: 6| Step: 9
Training loss: 1.7721034288406372
Validation loss: 2.103156487147013

Epoch: 6| Step: 10
Training loss: 1.4011338949203491
Validation loss: 2.1065580248832703

Epoch: 6| Step: 11
Training loss: 3.242094039916992
Validation loss: 2.110714574654897

Epoch: 6| Step: 12
Training loss: 1.2535330057144165
Validation loss: 2.1033546924591064

Epoch: 6| Step: 13
Training loss: 1.4215784072875977
Validation loss: 2.1217424472173056

Epoch: 174| Step: 0
Training loss: 1.9477605819702148
Validation loss: 2.125087300936381

Epoch: 6| Step: 1
Training loss: 1.7641119956970215
Validation loss: 2.141421357790629

Epoch: 6| Step: 2
Training loss: 1.6525754928588867
Validation loss: 2.154728055000305

Epoch: 6| Step: 3
Training loss: 2.491055727005005
Validation loss: 2.1198925773302713

Epoch: 6| Step: 4
Training loss: 1.3840141296386719
Validation loss: 2.1347338358561196

Epoch: 6| Step: 5
Training loss: 1.8456138372421265
Validation loss: 2.1175849239031472

Epoch: 6| Step: 6
Training loss: 1.757690668106079
Validation loss: 2.122205456097921

Epoch: 6| Step: 7
Training loss: 1.834726333618164
Validation loss: 2.135253886381785

Epoch: 6| Step: 8
Training loss: 1.4768831729888916
Validation loss: 2.1366187731424966

Epoch: 6| Step: 9
Training loss: 2.1852598190307617
Validation loss: 2.1519051591555276

Epoch: 6| Step: 10
Training loss: 1.8065056800842285
Validation loss: 2.1375399430592856

Epoch: 6| Step: 11
Training loss: 1.452798843383789
Validation loss: 2.1196830670038858

Epoch: 6| Step: 12
Training loss: 1.8506507873535156
Validation loss: 2.138240873813629

Epoch: 6| Step: 13
Training loss: 2.5336785316467285
Validation loss: 2.1671680212020874

Epoch: 175| Step: 0
Training loss: 1.943936824798584
Validation loss: 2.154994328816732

Epoch: 6| Step: 1
Training loss: 1.9670705795288086
Validation loss: 2.160508473714193

Epoch: 6| Step: 2
Training loss: 1.4985036849975586
Validation loss: 2.157223701477051

Epoch: 6| Step: 3
Training loss: 2.0828490257263184
Validation loss: 2.163297096888224

Epoch: 6| Step: 4
Training loss: 1.1125202178955078
Validation loss: 2.141233185927073

Epoch: 6| Step: 5
Training loss: 1.9487462043762207
Validation loss: 2.1318039099375405

Epoch: 6| Step: 6
Training loss: 1.8231760263442993
Validation loss: 2.136647880077362

Epoch: 6| Step: 7
Training loss: 2.3198699951171875
Validation loss: 2.1508301893870034

Epoch: 6| Step: 8
Training loss: 1.6900920867919922
Validation loss: 2.1345372200012207

Epoch: 6| Step: 9
Training loss: 2.4646317958831787
Validation loss: 2.140814463297526

Epoch: 6| Step: 10
Training loss: 1.8192754983901978
Validation loss: 2.139389475186666

Epoch: 6| Step: 11
Training loss: 1.8149809837341309
Validation loss: 2.1515024503072104

Epoch: 6| Step: 12
Training loss: 1.8217318058013916
Validation loss: 2.1489582459131875

Epoch: 6| Step: 13
Training loss: 1.6794860363006592
Validation loss: 2.1589230497678122

Epoch: 176| Step: 0
Training loss: 2.657050848007202
Validation loss: 2.1345575054486594

Epoch: 6| Step: 1
Training loss: 1.2492094039916992
Validation loss: 2.1290157636006675

Epoch: 6| Step: 2
Training loss: 2.0232200622558594
Validation loss: 2.121765434741974

Epoch: 6| Step: 3
Training loss: 2.125361919403076
Validation loss: 2.1208073099454245

Epoch: 6| Step: 4
Training loss: 1.6768348217010498
Validation loss: 2.123546381791433

Epoch: 6| Step: 5
Training loss: 1.8812904357910156
Validation loss: 2.12487663825353

Epoch: 6| Step: 6
Training loss: 1.2457998991012573
Validation loss: 2.134987235069275

Epoch: 6| Step: 7
Training loss: 1.7099037170410156
Validation loss: 2.1397008895874023

Epoch: 6| Step: 8
Training loss: 1.8983267545700073
Validation loss: 2.1447324554125466

Epoch: 6| Step: 9
Training loss: 2.684889316558838
Validation loss: 2.1319477558135986

Epoch: 6| Step: 10
Training loss: 1.8853994607925415
Validation loss: 2.1539214054743447

Epoch: 6| Step: 11
Training loss: 1.048243761062622
Validation loss: 2.1671947638193765

Epoch: 6| Step: 12
Training loss: 1.9669710397720337
Validation loss: 2.1629625956217446

Epoch: 6| Step: 13
Training loss: 2.1869261264801025
Validation loss: 2.1649457017580667

Epoch: 177| Step: 0
Training loss: 2.1933107376098633
Validation loss: 2.1745834946632385

Epoch: 6| Step: 1
Training loss: 2.2802672386169434
Validation loss: 2.1570233702659607

Epoch: 6| Step: 2
Training loss: 1.4234774112701416
Validation loss: 2.1552178263664246

Epoch: 6| Step: 3
Training loss: 2.5122671127319336
Validation loss: 2.158715526262919

Epoch: 6| Step: 4
Training loss: 2.2248520851135254
Validation loss: 2.139208654562632

Epoch: 6| Step: 5
Training loss: 1.5204945802688599
Validation loss: 2.1323726177215576

Epoch: 6| Step: 6
Training loss: 1.8364472389221191
Validation loss: 2.1223931113878884

Epoch: 6| Step: 7
Training loss: 1.6382250785827637
Validation loss: 2.111334184805552

Epoch: 6| Step: 8
Training loss: 2.028092861175537
Validation loss: 2.127127170562744

Epoch: 6| Step: 9
Training loss: 2.0369296073913574
Validation loss: 2.109167456626892

Epoch: 6| Step: 10
Training loss: 1.7833901643753052
Validation loss: 2.1321409940719604

Epoch: 6| Step: 11
Training loss: 1.7134060859680176
Validation loss: 2.1255377531051636

Epoch: 6| Step: 12
Training loss: 1.9164023399353027
Validation loss: 2.1482388178507485

Epoch: 6| Step: 13
Training loss: 1.2299284934997559
Validation loss: 2.142660597960154

Epoch: 178| Step: 0
Training loss: 1.4801167249679565
Validation loss: 2.1504780054092407

Epoch: 6| Step: 1
Training loss: 1.4749138355255127
Validation loss: 2.176033635934194

Epoch: 6| Step: 2
Training loss: 2.0917444229125977
Validation loss: 2.1812655925750732

Epoch: 6| Step: 3
Training loss: 1.7616196870803833
Validation loss: 2.1794809103012085

Epoch: 6| Step: 4
Training loss: 2.1044230461120605
Validation loss: 2.175415654977163

Epoch: 6| Step: 5
Training loss: 1.7932279109954834
Validation loss: 2.1579460501670837

Epoch: 6| Step: 6
Training loss: 2.0514376163482666
Validation loss: 2.140143791834513

Epoch: 6| Step: 7
Training loss: 2.4179680347442627
Validation loss: 2.121426741282145

Epoch: 6| Step: 8
Training loss: 2.0453896522521973
Validation loss: 2.1226279735565186

Epoch: 6| Step: 9
Training loss: 1.4225261211395264
Validation loss: 2.1130994955698648

Epoch: 6| Step: 10
Training loss: 1.6535425186157227
Validation loss: 2.1092290679613748

Epoch: 6| Step: 11
Training loss: 2.125103712081909
Validation loss: 2.1147336761156716

Epoch: 6| Step: 12
Training loss: 1.8515286445617676
Validation loss: 2.1181702613830566

Epoch: 6| Step: 13
Training loss: 2.0632994174957275
Validation loss: 2.127095897992452

Epoch: 179| Step: 0
Training loss: 1.9584178924560547
Validation loss: 2.155915081501007

Epoch: 6| Step: 1
Training loss: 1.466721534729004
Validation loss: 2.167119006315867

Epoch: 6| Step: 2
Training loss: 1.9615209102630615
Validation loss: 2.1698573231697083

Epoch: 6| Step: 3
Training loss: 2.070769786834717
Validation loss: 2.1895882884661355

Epoch: 6| Step: 4
Training loss: 2.4676530361175537
Validation loss: 2.1924092769622803

Epoch: 6| Step: 5
Training loss: 1.2873133420944214
Validation loss: 2.176617999871572

Epoch: 6| Step: 6
Training loss: 1.7392288446426392
Validation loss: 2.165919760862986

Epoch: 6| Step: 7
Training loss: 1.3579788208007812
Validation loss: 2.1464733481407166

Epoch: 6| Step: 8
Training loss: 1.7183923721313477
Validation loss: 2.116025467713674

Epoch: 6| Step: 9
Training loss: 2.2462220191955566
Validation loss: 2.104661683241526

Epoch: 6| Step: 10
Training loss: 1.7999427318572998
Validation loss: 2.0993035634358725

Epoch: 6| Step: 11
Training loss: 1.6194838285446167
Validation loss: 2.1085604627927146

Epoch: 6| Step: 12
Training loss: 2.373225212097168
Validation loss: 2.1264020005861917

Epoch: 6| Step: 13
Training loss: 2.1928420066833496
Validation loss: 2.129782974720001

Epoch: 180| Step: 0
Training loss: 1.9578458070755005
Validation loss: 2.1371754010518393

Epoch: 6| Step: 1
Training loss: 2.084941864013672
Validation loss: 2.147706846396128

Epoch: 6| Step: 2
Training loss: 1.375274658203125
Validation loss: 2.1663937171300254

Epoch: 6| Step: 3
Training loss: 1.9199029207229614
Validation loss: 2.1467970808347068

Epoch: 6| Step: 4
Training loss: 2.3505702018737793
Validation loss: 2.1702123880386353

Epoch: 6| Step: 5
Training loss: 2.060492515563965
Validation loss: 2.1645315289497375

Epoch: 6| Step: 6
Training loss: 1.6151334047317505
Validation loss: 2.168988585472107

Epoch: 6| Step: 7
Training loss: 1.7486886978149414
Validation loss: 2.129061758518219

Epoch: 6| Step: 8
Training loss: 1.4650914669036865
Validation loss: 2.102345585823059

Epoch: 6| Step: 9
Training loss: 1.8554542064666748
Validation loss: 2.110923926035563

Epoch: 6| Step: 10
Training loss: 2.307743549346924
Validation loss: 2.10719096660614

Epoch: 6| Step: 11
Training loss: 2.355175018310547
Validation loss: 2.1124799251556396

Epoch: 6| Step: 12
Training loss: 1.7787225246429443
Validation loss: 2.10651965936025

Epoch: 6| Step: 13
Training loss: 1.8364102840423584
Validation loss: 2.099939783414205

Epoch: 181| Step: 0
Training loss: 1.7578595876693726
Validation loss: 2.1206387877464294

Epoch: 6| Step: 1
Training loss: 1.6344512701034546
Validation loss: 2.112199584643046

Epoch: 6| Step: 2
Training loss: 1.7151516675949097
Validation loss: 2.144244352976481

Epoch: 6| Step: 3
Training loss: 1.4606598615646362
Validation loss: 2.1325347423553467

Epoch: 6| Step: 4
Training loss: 1.4655625820159912
Validation loss: 2.152992864449819

Epoch: 6| Step: 5
Training loss: 2.9590234756469727
Validation loss: 2.1484778126080832

Epoch: 6| Step: 6
Training loss: 2.0097084045410156
Validation loss: 2.1714507937431335

Epoch: 6| Step: 7
Training loss: 1.5705845355987549
Validation loss: 2.1886473894119263

Epoch: 6| Step: 8
Training loss: 2.134458303451538
Validation loss: 2.188506523768107

Epoch: 6| Step: 9
Training loss: 1.8605915307998657
Validation loss: 2.184202949206034

Epoch: 6| Step: 10
Training loss: 2.191443920135498
Validation loss: 2.170206050078074

Epoch: 6| Step: 11
Training loss: 1.1551663875579834
Validation loss: 2.150784114996592

Epoch: 6| Step: 12
Training loss: 1.5232152938842773
Validation loss: 2.13986074924469

Epoch: 6| Step: 13
Training loss: 2.301506519317627
Validation loss: 2.1299081246058145

Epoch: 182| Step: 0
Training loss: 1.927030086517334
Validation loss: 2.1267730593681335

Epoch: 6| Step: 1
Training loss: 2.187986373901367
Validation loss: 2.127087970574697

Epoch: 6| Step: 2
Training loss: 1.9165964126586914
Validation loss: 2.1257946292559304

Epoch: 6| Step: 3
Training loss: 1.5757395029067993
Validation loss: 2.120524247487386

Epoch: 6| Step: 4
Training loss: 2.01904296875
Validation loss: 2.127366046110789

Epoch: 6| Step: 5
Training loss: 1.757094144821167
Validation loss: 2.1413732171058655

Epoch: 6| Step: 6
Training loss: 2.2949323654174805
Validation loss: 2.147443254788717

Epoch: 6| Step: 7
Training loss: 1.8212690353393555
Validation loss: 2.145179589589437

Epoch: 6| Step: 8
Training loss: 1.6788294315338135
Validation loss: 2.170976201693217

Epoch: 6| Step: 9
Training loss: 1.5215356349945068
Validation loss: 2.1621355414390564

Epoch: 6| Step: 10
Training loss: 1.654430627822876
Validation loss: 2.178821881612142

Epoch: 6| Step: 11
Training loss: 1.788557767868042
Validation loss: 2.1744415362675986

Epoch: 6| Step: 12
Training loss: 1.3471918106079102
Validation loss: 2.1792709032694497

Epoch: 6| Step: 13
Training loss: 2.248383045196533
Validation loss: 2.170347034931183

Epoch: 183| Step: 0
Training loss: 1.990244746208191
Validation loss: 2.167451719443003

Epoch: 6| Step: 1
Training loss: 1.6731715202331543
Validation loss: 2.1693437894185386

Epoch: 6| Step: 2
Training loss: 2.120549201965332
Validation loss: 2.1557067235310874

Epoch: 6| Step: 3
Training loss: 2.1262640953063965
Validation loss: 2.1471904714902244

Epoch: 6| Step: 4
Training loss: 1.8007491827011108
Validation loss: 2.1294118364652

Epoch: 6| Step: 5
Training loss: 1.6066830158233643
Validation loss: 2.143013914426168

Epoch: 6| Step: 6
Training loss: 1.6242890357971191
Validation loss: 2.146473149458567

Epoch: 6| Step: 7
Training loss: 1.5664710998535156
Validation loss: 2.1583239237467446

Epoch: 6| Step: 8
Training loss: 1.8897634744644165
Validation loss: 2.1691328287124634

Epoch: 6| Step: 9
Training loss: 1.6669586896896362
Validation loss: 2.1811073621114097

Epoch: 6| Step: 10
Training loss: 1.851965069770813
Validation loss: 2.178629537423452

Epoch: 6| Step: 11
Training loss: 1.607792615890503
Validation loss: 2.195363720258077

Epoch: 6| Step: 12
Training loss: 2.6224026679992676
Validation loss: 2.183612902959188

Epoch: 6| Step: 13
Training loss: 1.7745627164840698
Validation loss: 2.167680342992147

Epoch: 184| Step: 0
Training loss: 2.0162642002105713
Validation loss: 2.1659164428710938

Epoch: 6| Step: 1
Training loss: 2.1311964988708496
Validation loss: 2.1610111395517984

Epoch: 6| Step: 2
Training loss: 1.2918657064437866
Validation loss: 2.1496870517730713

Epoch: 6| Step: 3
Training loss: 2.5161311626434326
Validation loss: 2.1254753470420837

Epoch: 6| Step: 4
Training loss: 1.48231840133667
Validation loss: 2.14506063858668

Epoch: 6| Step: 5
Training loss: 1.555364727973938
Validation loss: 2.149825851122538

Epoch: 6| Step: 6
Training loss: 1.6367439031600952
Validation loss: 2.146386464436849

Epoch: 6| Step: 7
Training loss: 1.4342541694641113
Validation loss: 2.1535215775171914

Epoch: 6| Step: 8
Training loss: 1.8237104415893555
Validation loss: 2.1707709232966104

Epoch: 6| Step: 9
Training loss: 2.023420572280884
Validation loss: 2.1825218399365744

Epoch: 6| Step: 10
Training loss: 2.0781311988830566
Validation loss: 2.1812764008839927

Epoch: 6| Step: 11
Training loss: 1.790524959564209
Validation loss: 2.184499144554138

Epoch: 6| Step: 12
Training loss: 1.7864114046096802
Validation loss: 2.1911174654960632

Epoch: 6| Step: 13
Training loss: 2.313537836074829
Validation loss: 2.2105678717295327

Epoch: 185| Step: 0
Training loss: 1.9707244634628296
Validation loss: 2.208716571331024

Epoch: 6| Step: 1
Training loss: 2.0875473022460938
Validation loss: 2.173605223496755

Epoch: 6| Step: 2
Training loss: 1.7803514003753662
Validation loss: 2.175755818684896

Epoch: 6| Step: 3
Training loss: 2.6654610633850098
Validation loss: 2.17225444316864

Epoch: 6| Step: 4
Training loss: 1.3948451280593872
Validation loss: 2.181593040625254

Epoch: 6| Step: 5
Training loss: 1.4366137981414795
Validation loss: 2.1525545517603555

Epoch: 6| Step: 6
Training loss: 2.1912155151367188
Validation loss: 2.1473395029703775

Epoch: 6| Step: 7
Training loss: 1.4486429691314697
Validation loss: 2.171734313170115

Epoch: 6| Step: 8
Training loss: 1.4523696899414062
Validation loss: 2.1689202785491943

Epoch: 6| Step: 9
Training loss: 2.689284324645996
Validation loss: 2.186854382356008

Epoch: 6| Step: 10
Training loss: 1.7062864303588867
Validation loss: 2.1745355327924094

Epoch: 6| Step: 11
Training loss: 2.1315691471099854
Validation loss: 2.1868253151575723

Epoch: 6| Step: 12
Training loss: 1.1636784076690674
Validation loss: 2.1783936818440757

Epoch: 6| Step: 13
Training loss: 1.5206760168075562
Validation loss: 2.1972185174624124

Epoch: 186| Step: 0
Training loss: 1.953769326210022
Validation loss: 2.1711090008417764

Epoch: 6| Step: 1
Training loss: 1.4431732892990112
Validation loss: 2.1747116446495056

Epoch: 6| Step: 2
Training loss: 2.5056488513946533
Validation loss: 2.1666133602460227

Epoch: 6| Step: 3
Training loss: 2.6148488521575928
Validation loss: 2.158292015393575

Epoch: 6| Step: 4
Training loss: 1.3081330060958862
Validation loss: 2.1605367263158164

Epoch: 6| Step: 5
Training loss: 1.7805975675582886
Validation loss: 2.1614834666252136

Epoch: 6| Step: 6
Training loss: 1.881174921989441
Validation loss: 2.156632125377655

Epoch: 6| Step: 7
Training loss: 1.8184289932250977
Validation loss: 2.1485402584075928

Epoch: 6| Step: 8
Training loss: 1.9703235626220703
Validation loss: 2.1410834590593972

Epoch: 6| Step: 9
Training loss: 1.7851759195327759
Validation loss: 2.1446521083513894

Epoch: 6| Step: 10
Training loss: 2.1841557025909424
Validation loss: 2.1575865944226584

Epoch: 6| Step: 11
Training loss: 1.2865729331970215
Validation loss: 2.1813559333483377

Epoch: 6| Step: 12
Training loss: 1.6105585098266602
Validation loss: 2.190496881802877

Epoch: 6| Step: 13
Training loss: 1.4161715507507324
Validation loss: 2.248829503854116

Epoch: 187| Step: 0
Training loss: 2.3270931243896484
Validation loss: 2.2312474250793457

Epoch: 6| Step: 1
Training loss: 1.3864963054656982
Validation loss: 2.2472025950749717

Epoch: 6| Step: 2
Training loss: 2.3743581771850586
Validation loss: 2.2265159090360007

Epoch: 6| Step: 3
Training loss: 1.26610267162323
Validation loss: 2.2292653719584146

Epoch: 6| Step: 4
Training loss: 1.5466011762619019
Validation loss: 2.2063432931900024

Epoch: 6| Step: 5
Training loss: 1.5737121105194092
Validation loss: 2.1817651987075806

Epoch: 6| Step: 6
Training loss: 1.9829437732696533
Validation loss: 2.131900747617086

Epoch: 6| Step: 7
Training loss: 1.9698768854141235
Validation loss: 2.1368446747461953

Epoch: 6| Step: 8
Training loss: 2.629484176635742
Validation loss: 2.103250722090403

Epoch: 6| Step: 9
Training loss: 1.7282371520996094
Validation loss: 2.1154170831044516

Epoch: 6| Step: 10
Training loss: 1.9331330060958862
Validation loss: 2.1142555276552835

Epoch: 6| Step: 11
Training loss: 1.9434343576431274
Validation loss: 2.1242777903874717

Epoch: 6| Step: 12
Training loss: 2.2600152492523193
Validation loss: 2.106979191303253

Epoch: 6| Step: 13
Training loss: 1.8901158571243286
Validation loss: 2.1091583967208862

Epoch: 188| Step: 0
Training loss: 1.6655490398406982
Validation loss: 2.11322420835495

Epoch: 6| Step: 1
Training loss: 1.5231173038482666
Validation loss: 2.117886940638224

Epoch: 6| Step: 2
Training loss: 2.369784355163574
Validation loss: 2.126581390698751

Epoch: 6| Step: 3
Training loss: 1.9976036548614502
Validation loss: 2.134336014588674

Epoch: 6| Step: 4
Training loss: 1.720120906829834
Validation loss: 2.140370527903239

Epoch: 6| Step: 5
Training loss: 1.3711357116699219
Validation loss: 2.1515436371167502

Epoch: 6| Step: 6
Training loss: 1.9039182662963867
Validation loss: 2.1789978742599487

Epoch: 6| Step: 7
Training loss: 2.453563690185547
Validation loss: 2.158888896306356

Epoch: 6| Step: 8
Training loss: 1.3010681867599487
Validation loss: 2.180542747179667

Epoch: 6| Step: 9
Training loss: 1.7249794006347656
Validation loss: 2.1719921827316284

Epoch: 6| Step: 10
Training loss: 1.9278934001922607
Validation loss: 2.176860749721527

Epoch: 6| Step: 11
Training loss: 2.1847901344299316
Validation loss: 2.1725062131881714

Epoch: 6| Step: 12
Training loss: 1.9594085216522217
Validation loss: 2.1541451613108316

Epoch: 6| Step: 13
Training loss: 1.9397053718566895
Validation loss: 2.1516913572947183

Epoch: 189| Step: 0
Training loss: 2.3512401580810547
Validation loss: 2.1271972258885703

Epoch: 6| Step: 1
Training loss: 1.8708927631378174
Validation loss: 2.159845471382141

Epoch: 6| Step: 2
Training loss: 1.4543248414993286
Validation loss: 2.140401025613149

Epoch: 6| Step: 3
Training loss: 1.6792945861816406
Validation loss: 2.1612666050593057

Epoch: 6| Step: 4
Training loss: 1.9047054052352905
Validation loss: 2.1387075384457908

Epoch: 6| Step: 5
Training loss: 2.07891583442688
Validation loss: 2.1531447966893515

Epoch: 6| Step: 6
Training loss: 1.6413850784301758
Validation loss: 2.14743306239446

Epoch: 6| Step: 7
Training loss: 2.155679941177368
Validation loss: 2.1641902128855386

Epoch: 6| Step: 8
Training loss: 2.0525286197662354
Validation loss: 2.134811520576477

Epoch: 6| Step: 9
Training loss: 2.1060993671417236
Validation loss: 2.1621713240941367

Epoch: 6| Step: 10
Training loss: 1.0958609580993652
Validation loss: 2.1755473613739014

Epoch: 6| Step: 11
Training loss: 1.3695738315582275
Validation loss: 2.151883602142334

Epoch: 6| Step: 12
Training loss: 1.2717888355255127
Validation loss: 2.1858317057291665

Epoch: 6| Step: 13
Training loss: 2.4164223670959473
Validation loss: 2.1773011883099875

Epoch: 190| Step: 0
Training loss: 2.0724430084228516
Validation loss: 2.1751148104667664

Epoch: 6| Step: 1
Training loss: 1.6151968240737915
Validation loss: 2.1581871509552

Epoch: 6| Step: 2
Training loss: 3.0276384353637695
Validation loss: 2.2037552992502847

Epoch: 6| Step: 3
Training loss: 1.347478985786438
Validation loss: 2.2026740312576294

Epoch: 6| Step: 4
Training loss: 2.149071216583252
Validation loss: 2.2155833641688027

Epoch: 6| Step: 5
Training loss: 1.0626527070999146
Validation loss: 2.2125865817070007

Epoch: 6| Step: 6
Training loss: 2.4570608139038086
Validation loss: 2.1712950468063354

Epoch: 6| Step: 7
Training loss: 1.7248953580856323
Validation loss: 2.1814544200897217

Epoch: 6| Step: 8
Training loss: 1.7469197511672974
Validation loss: 2.154508630434672

Epoch: 6| Step: 9
Training loss: 1.401435136795044
Validation loss: 2.135598679383596

Epoch: 6| Step: 10
Training loss: 1.3530235290527344
Validation loss: 2.1482868591944375

Epoch: 6| Step: 11
Training loss: 2.0300726890563965
Validation loss: 2.1681975523630777

Epoch: 6| Step: 12
Training loss: 1.4311518669128418
Validation loss: 2.1682993372281394

Epoch: 6| Step: 13
Training loss: 1.9305310249328613
Validation loss: 2.1695908904075623

Epoch: 191| Step: 0
Training loss: 2.2954049110412598
Validation loss: 2.197667380174001

Epoch: 6| Step: 1
Training loss: 1.8952267169952393
Validation loss: 2.1885659098625183

Epoch: 6| Step: 2
Training loss: 1.6785833835601807
Validation loss: 2.1789642175038657

Epoch: 6| Step: 3
Training loss: 1.3344473838806152
Validation loss: 2.161817411581675

Epoch: 6| Step: 4
Training loss: 1.612399935722351
Validation loss: 2.1861073772112527

Epoch: 6| Step: 5
Training loss: 1.7686711549758911
Validation loss: 2.163265804449717

Epoch: 6| Step: 6
Training loss: 1.470108985900879
Validation loss: 2.15875897804896

Epoch: 6| Step: 7
Training loss: 2.2271432876586914
Validation loss: 2.1526914636294046

Epoch: 6| Step: 8
Training loss: 1.865911602973938
Validation loss: 2.1516584157943726

Epoch: 6| Step: 9
Training loss: 2.0008411407470703
Validation loss: 2.1404999693234763

Epoch: 6| Step: 10
Training loss: 1.8469929695129395
Validation loss: 2.153982083002726

Epoch: 6| Step: 11
Training loss: 1.8659313917160034
Validation loss: 2.161959171295166

Epoch: 6| Step: 12
Training loss: 2.3073220252990723
Validation loss: 2.14888064066569

Epoch: 6| Step: 13
Training loss: 1.4373304843902588
Validation loss: 2.1680278380711875

Epoch: 192| Step: 0
Training loss: 2.234363555908203
Validation loss: 2.1525535186131797

Epoch: 6| Step: 1
Training loss: 1.3064584732055664
Validation loss: 2.164550324281057

Epoch: 6| Step: 2
Training loss: 1.7082229852676392
Validation loss: 2.18138579527537

Epoch: 6| Step: 3
Training loss: 1.0273443460464478
Validation loss: 2.1844707131385803

Epoch: 6| Step: 4
Training loss: 1.9070698022842407
Validation loss: 2.1718939542770386

Epoch: 6| Step: 5
Training loss: 1.3714631795883179
Validation loss: 2.171534617741903

Epoch: 6| Step: 6
Training loss: 2.6524133682250977
Validation loss: 2.1605985363324485

Epoch: 6| Step: 7
Training loss: 2.0888869762420654
Validation loss: 2.133428076903025

Epoch: 6| Step: 8
Training loss: 1.7672812938690186
Validation loss: 2.1623644828796387

Epoch: 6| Step: 9
Training loss: 1.5512382984161377
Validation loss: 2.1276326378186545

Epoch: 6| Step: 10
Training loss: 2.67081356048584
Validation loss: 2.130411942799886

Epoch: 6| Step: 11
Training loss: 1.7906215190887451
Validation loss: 2.1444860895474753

Epoch: 6| Step: 12
Training loss: 1.877029299736023
Validation loss: 2.1385186314582825

Epoch: 6| Step: 13
Training loss: 2.1318745613098145
Validation loss: 2.140037735303243

Epoch: 193| Step: 0
Training loss: 1.7212426662445068
Validation loss: 2.1421837409337363

Epoch: 6| Step: 1
Training loss: 1.3741142749786377
Validation loss: 2.176981965700785

Epoch: 6| Step: 2
Training loss: 2.379159450531006
Validation loss: 2.1979990204175315

Epoch: 6| Step: 3
Training loss: 2.078439474105835
Validation loss: 2.2098723649978638

Epoch: 6| Step: 4
Training loss: 1.919518232345581
Validation loss: 2.2444655895233154

Epoch: 6| Step: 5
Training loss: 2.5289769172668457
Validation loss: 2.211645523707072

Epoch: 6| Step: 6
Training loss: 1.6158677339553833
Validation loss: 2.2223063707351685

Epoch: 6| Step: 7
Training loss: 1.8727235794067383
Validation loss: 2.2259809176127114

Epoch: 6| Step: 8
Training loss: 1.4197757244110107
Validation loss: 2.233826478322347

Epoch: 6| Step: 9
Training loss: 1.9556500911712646
Validation loss: 2.221824506918589

Epoch: 6| Step: 10
Training loss: 2.013209342956543
Validation loss: 2.213407834370931

Epoch: 6| Step: 11
Training loss: 1.6599950790405273
Validation loss: 2.195586343606313

Epoch: 6| Step: 12
Training loss: 0.8318002223968506
Validation loss: 2.1870075464248657

Epoch: 6| Step: 13
Training loss: 2.024930477142334
Validation loss: 2.164249380429586

Epoch: 194| Step: 0
Training loss: 1.7663402557373047
Validation loss: 2.1529611547787986

Epoch: 6| Step: 1
Training loss: 1.6214256286621094
Validation loss: 2.1482650438944497

Epoch: 6| Step: 2
Training loss: 1.7438243627548218
Validation loss: 2.1385536392529807

Epoch: 6| Step: 3
Training loss: 1.8590672016143799
Validation loss: 2.1187593738238015

Epoch: 6| Step: 4
Training loss: 2.3054566383361816
Validation loss: 2.136125385761261

Epoch: 6| Step: 5
Training loss: 1.9700905084609985
Validation loss: 2.1768916845321655

Epoch: 6| Step: 6
Training loss: 2.3073015213012695
Validation loss: 2.1809486746788025

Epoch: 6| Step: 7
Training loss: 1.5436497926712036
Validation loss: 2.1952277620633445

Epoch: 6| Step: 8
Training loss: 1.9481136798858643
Validation loss: 2.197132726510366

Epoch: 6| Step: 9
Training loss: 1.8910143375396729
Validation loss: 2.204781254132589

Epoch: 6| Step: 10
Training loss: 1.2291555404663086
Validation loss: 2.208399216334025

Epoch: 6| Step: 11
Training loss: 1.5403718948364258
Validation loss: 2.191717743873596

Epoch: 6| Step: 12
Training loss: 1.5704699754714966
Validation loss: 2.21900741259257

Epoch: 6| Step: 13
Training loss: 1.9972268342971802
Validation loss: 2.1681867837905884

Epoch: 195| Step: 0
Training loss: 1.3948562145233154
Validation loss: 2.193849186102549

Epoch: 6| Step: 1
Training loss: 2.2765374183654785
Validation loss: 2.1979209184646606

Epoch: 6| Step: 2
Training loss: 1.4314050674438477
Validation loss: 2.179737110932668

Epoch: 6| Step: 3
Training loss: 1.950424313545227
Validation loss: 2.195122480392456

Epoch: 6| Step: 4
Training loss: 1.5519458055496216
Validation loss: 2.2245994011561074

Epoch: 6| Step: 5
Training loss: 2.023275852203369
Validation loss: 2.2028518517812095

Epoch: 6| Step: 6
Training loss: 1.8812779188156128
Validation loss: 2.203512489795685

Epoch: 6| Step: 7
Training loss: 1.9391268491744995
Validation loss: 2.1914915641148887

Epoch: 6| Step: 8
Training loss: 1.0430797338485718
Validation loss: 2.197637061278025

Epoch: 6| Step: 9
Training loss: 1.497856855392456
Validation loss: 2.1889113982518515

Epoch: 6| Step: 10
Training loss: 1.6140758991241455
Validation loss: 2.1608707904815674

Epoch: 6| Step: 11
Training loss: 2.285614252090454
Validation loss: 2.1698396603266397

Epoch: 6| Step: 12
Training loss: 2.588895559310913
Validation loss: 2.1425652702649436

Epoch: 6| Step: 13
Training loss: 1.92576003074646
Validation loss: 2.1398104230562844

Epoch: 196| Step: 0
Training loss: 2.0978353023529053
Validation loss: 2.1603697538375854

Epoch: 6| Step: 1
Training loss: 1.4884765148162842
Validation loss: 2.152835965156555

Epoch: 6| Step: 2
Training loss: 1.970465898513794
Validation loss: 2.1937395135561624

Epoch: 6| Step: 3
Training loss: 1.605068325996399
Validation loss: 2.179679354031881

Epoch: 6| Step: 4
Training loss: 1.6853704452514648
Validation loss: 2.209824581940969

Epoch: 6| Step: 5
Training loss: 2.517313003540039
Validation loss: 2.228248198827108

Epoch: 6| Step: 6
Training loss: 1.570083498954773
Validation loss: 2.20437745253245

Epoch: 6| Step: 7
Training loss: 1.2664892673492432
Validation loss: 2.213042894999186

Epoch: 6| Step: 8
Training loss: 2.014065742492676
Validation loss: 2.195527493953705

Epoch: 6| Step: 9
Training loss: 1.827466368675232
Validation loss: 2.156540850798289

Epoch: 6| Step: 10
Training loss: 1.7629344463348389
Validation loss: 2.1621535817782083

Epoch: 6| Step: 11
Training loss: 1.6957366466522217
Validation loss: 2.166617433230082

Epoch: 6| Step: 12
Training loss: 1.850223422050476
Validation loss: 2.178751309712728

Epoch: 6| Step: 13
Training loss: 2.0693278312683105
Validation loss: 2.1827688614527383

Epoch: 197| Step: 0
Training loss: 1.1477991342544556
Validation loss: 2.1710061033566794

Epoch: 6| Step: 1
Training loss: 2.2764992713928223
Validation loss: 2.1661963065465293

Epoch: 6| Step: 2
Training loss: 1.807220220565796
Validation loss: 2.174629290898641

Epoch: 6| Step: 3
Training loss: 1.6518043279647827
Validation loss: 2.1776634454727173

Epoch: 6| Step: 4
Training loss: 1.4953794479370117
Validation loss: 2.1949931184450784

Epoch: 6| Step: 5
Training loss: 1.7918308973312378
Validation loss: 2.187393605709076

Epoch: 6| Step: 6
Training loss: 2.1883583068847656
Validation loss: 2.1868218183517456

Epoch: 6| Step: 7
Training loss: 2.492664337158203
Validation loss: 2.1940366625785828

Epoch: 6| Step: 8
Training loss: 1.6697874069213867
Validation loss: 2.1755699117978415

Epoch: 6| Step: 9
Training loss: 1.6446095705032349
Validation loss: 2.1828944087028503

Epoch: 6| Step: 10
Training loss: 1.7439148426055908
Validation loss: 2.195936600367228

Epoch: 6| Step: 11
Training loss: 2.1145708560943604
Validation loss: 2.2060344219207764

Epoch: 6| Step: 12
Training loss: 1.6009076833724976
Validation loss: 2.2002580960591636

Epoch: 6| Step: 13
Training loss: 1.4632015228271484
Validation loss: 2.191717743873596

Epoch: 198| Step: 0
Training loss: 2.6536426544189453
Validation loss: 2.180554449558258

Epoch: 6| Step: 1
Training loss: 1.5684247016906738
Validation loss: 2.1976720690727234

Epoch: 6| Step: 2
Training loss: 1.4281909465789795
Validation loss: 2.181681235631307

Epoch: 6| Step: 3
Training loss: 1.5691869258880615
Validation loss: 2.1836785475413003

Epoch: 6| Step: 4
Training loss: 1.4305627346038818
Validation loss: 2.163987159729004

Epoch: 6| Step: 5
Training loss: 1.9016145467758179
Validation loss: 2.1814292669296265

Epoch: 6| Step: 6
Training loss: 2.528384208679199
Validation loss: 2.157021224498749

Epoch: 6| Step: 7
Training loss: 1.6483192443847656
Validation loss: 2.1623077988624573

Epoch: 6| Step: 8
Training loss: 2.0976452827453613
Validation loss: 2.1438397765159607

Epoch: 6| Step: 9
Training loss: 1.2899292707443237
Validation loss: 2.1706863244374595

Epoch: 6| Step: 10
Training loss: 1.7326934337615967
Validation loss: 2.1744301120440164

Epoch: 6| Step: 11
Training loss: 1.3109210729599
Validation loss: 2.1817550460497537

Epoch: 6| Step: 12
Training loss: 1.730565071105957
Validation loss: 2.178526222705841

Epoch: 6| Step: 13
Training loss: 2.0189244747161865
Validation loss: 2.1743805209795632

Epoch: 199| Step: 0
Training loss: 1.5447232723236084
Validation loss: 2.184576710065206

Epoch: 6| Step: 1
Training loss: 2.2183520793914795
Validation loss: 2.191659847895304

Epoch: 6| Step: 2
Training loss: 1.2369029521942139
Validation loss: 2.1671685775121055

Epoch: 6| Step: 3
Training loss: 1.7459213733673096
Validation loss: 2.1869625647862754

Epoch: 6| Step: 4
Training loss: 2.2058568000793457
Validation loss: 2.213994840780894

Epoch: 6| Step: 5
Training loss: 1.864098310470581
Validation loss: 2.187493085861206

Epoch: 6| Step: 6
Training loss: 1.7210655212402344
Validation loss: 2.198946754137675

Epoch: 6| Step: 7
Training loss: 1.8261213302612305
Validation loss: 2.2107122341791787

Epoch: 6| Step: 8
Training loss: 2.2066004276275635
Validation loss: 2.1689600944519043

Epoch: 6| Step: 9
Training loss: 1.9914528131484985
Validation loss: 2.186237951119741

Epoch: 6| Step: 10
Training loss: 1.496290922164917
Validation loss: 2.1760873198509216

Epoch: 6| Step: 11
Training loss: 1.9849814176559448
Validation loss: 2.1559228698412576

Epoch: 6| Step: 12
Training loss: 1.2429770231246948
Validation loss: 2.151982625325521

Epoch: 6| Step: 13
Training loss: 1.6805250644683838
Validation loss: 2.1488970120747886

Epoch: 200| Step: 0
Training loss: 1.3904378414154053
Validation loss: 2.161131739616394

Epoch: 6| Step: 1
Training loss: 1.7638849020004272
Validation loss: 2.1753576596577964

Epoch: 6| Step: 2
Training loss: 2.373682975769043
Validation loss: 2.1732250452041626

Epoch: 6| Step: 3
Training loss: 2.04746150970459
Validation loss: 2.1548399925231934

Epoch: 6| Step: 4
Training loss: 1.8669843673706055
Validation loss: 2.187785565853119

Epoch: 6| Step: 5
Training loss: 1.811744213104248
Validation loss: 2.20473305384318

Epoch: 6| Step: 6
Training loss: 1.8886966705322266
Validation loss: 2.2374080220858255

Epoch: 6| Step: 7
Training loss: 2.0344619750976562
Validation loss: 2.249395191669464

Epoch: 6| Step: 8
Training loss: 1.8081555366516113
Validation loss: 2.291685461997986

Epoch: 6| Step: 9
Training loss: 1.5502469539642334
Validation loss: 2.2678197026252747

Epoch: 6| Step: 10
Training loss: 1.6007928848266602
Validation loss: 2.2629297574361167

Epoch: 6| Step: 11
Training loss: 2.2079551219940186
Validation loss: 2.291023015975952

Epoch: 6| Step: 12
Training loss: 1.4206068515777588
Validation loss: 2.240793506304423

Epoch: 6| Step: 13
Training loss: 1.8814046382904053
Validation loss: 2.227642218271891

Epoch: 201| Step: 0
Training loss: 1.4863300323486328
Validation loss: 2.2131346066792807

Epoch: 6| Step: 1
Training loss: 2.0986437797546387
Validation loss: 2.196067690849304

Epoch: 6| Step: 2
Training loss: 1.8167593479156494
Validation loss: 2.170769135157267

Epoch: 6| Step: 3
Training loss: 1.4227237701416016
Validation loss: 2.1619758208592734

Epoch: 6| Step: 4
Training loss: 2.2006819248199463
Validation loss: 2.1404655377070108

Epoch: 6| Step: 5
Training loss: 2.1367573738098145
Validation loss: 2.124594569206238

Epoch: 6| Step: 6
Training loss: 1.565247893333435
Validation loss: 2.129445274670919

Epoch: 6| Step: 7
Training loss: 1.295356035232544
Validation loss: 2.1304991443951926

Epoch: 6| Step: 8
Training loss: 2.0605640411376953
Validation loss: 2.1429401437441506

Epoch: 6| Step: 9
Training loss: 1.7692475318908691
Validation loss: 2.132477879524231

Epoch: 6| Step: 10
Training loss: 2.7433996200561523
Validation loss: 2.137462019920349

Epoch: 6| Step: 11
Training loss: 1.7708184719085693
Validation loss: 2.1539719899495444

Epoch: 6| Step: 12
Training loss: 1.6718699932098389
Validation loss: 2.1684558391571045

Epoch: 6| Step: 13
Training loss: 1.6418867111206055
Validation loss: 2.1752054691314697

Epoch: 202| Step: 0
Training loss: 1.6570651531219482
Validation loss: 2.2031193176905313

Epoch: 6| Step: 1
Training loss: 1.6898431777954102
Validation loss: 2.21287210782369

Epoch: 6| Step: 2
Training loss: 1.848188042640686
Validation loss: 2.2221787770589194

Epoch: 6| Step: 3
Training loss: 1.8258113861083984
Validation loss: 2.213994264602661

Epoch: 6| Step: 4
Training loss: 1.8876066207885742
Validation loss: 2.1998078425725303

Epoch: 6| Step: 5
Training loss: 2.552250385284424
Validation loss: 2.192173401514689

Epoch: 6| Step: 6
Training loss: 1.5456604957580566
Validation loss: 2.1902600725491843

Epoch: 6| Step: 7
Training loss: 2.037558078765869
Validation loss: 2.2047773202260337

Epoch: 6| Step: 8
Training loss: 1.8518180847167969
Validation loss: 2.208748698234558

Epoch: 6| Step: 9
Training loss: 2.2506327629089355
Validation loss: 2.2136895259221396

Epoch: 6| Step: 10
Training loss: 1.595758080482483
Validation loss: 2.2278560996055603

Epoch: 6| Step: 11
Training loss: 1.5869777202606201
Validation loss: 2.2255309224128723

Epoch: 6| Step: 12
Training loss: 1.7659251689910889
Validation loss: 2.2280406951904297

Epoch: 6| Step: 13
Training loss: 1.8471273183822632
Validation loss: 2.2296623587608337

Epoch: 203| Step: 0
Training loss: 1.7597756385803223
Validation loss: 2.218025863170624

Epoch: 6| Step: 1
Training loss: 1.559590220451355
Validation loss: 2.195957581202189

Epoch: 6| Step: 2
Training loss: 2.0472850799560547
Validation loss: 2.1842406193415322

Epoch: 6| Step: 3
Training loss: 1.2989439964294434
Validation loss: 2.1816763480504355

Epoch: 6| Step: 4
Training loss: 2.352126121520996
Validation loss: 2.1720168391863504

Epoch: 6| Step: 5
Training loss: 2.4103522300720215
Validation loss: 2.166691839694977

Epoch: 6| Step: 6
Training loss: 1.8360079526901245
Validation loss: 2.176866352558136

Epoch: 6| Step: 7
Training loss: 1.5940207242965698
Validation loss: 2.1606825391451516

Epoch: 6| Step: 8
Training loss: 1.4735302925109863
Validation loss: 2.153447409470876

Epoch: 6| Step: 9
Training loss: 2.066235065460205
Validation loss: 2.16407444079717

Epoch: 6| Step: 10
Training loss: 1.4319775104522705
Validation loss: 2.1500685811042786

Epoch: 6| Step: 11
Training loss: 1.6703009605407715
Validation loss: 2.1564454237620034

Epoch: 6| Step: 12
Training loss: 1.9662997722625732
Validation loss: 2.185406446456909

Epoch: 6| Step: 13
Training loss: 2.1330528259277344
Validation loss: 2.1758387883504233

Epoch: 204| Step: 0
Training loss: 2.1903607845306396
Validation loss: 2.188467860221863

Epoch: 6| Step: 1
Training loss: 1.76124906539917
Validation loss: 2.212834576765696

Epoch: 6| Step: 2
Training loss: 2.003812789916992
Validation loss: 2.2207139134407043

Epoch: 6| Step: 3
Training loss: 1.2576658725738525
Validation loss: 2.2020573218663535

Epoch: 6| Step: 4
Training loss: 2.6826095581054688
Validation loss: 2.1953426202138266

Epoch: 6| Step: 5
Training loss: 1.613713264465332
Validation loss: 2.184627572695414

Epoch: 6| Step: 6
Training loss: 1.761167287826538
Validation loss: 2.167926569779714

Epoch: 6| Step: 7
Training loss: 1.8166847229003906
Validation loss: 2.1725329955418906

Epoch: 6| Step: 8
Training loss: 2.3088393211364746
Validation loss: 2.1664891640345254

Epoch: 6| Step: 9
Training loss: 2.353759288787842
Validation loss: 2.159558415412903

Epoch: 6| Step: 10
Training loss: 1.258299708366394
Validation loss: 2.1508585810661316

Epoch: 6| Step: 11
Training loss: 1.4571051597595215
Validation loss: 2.1572777032852173

Epoch: 6| Step: 12
Training loss: 1.9185640811920166
Validation loss: 2.162589112917582

Epoch: 6| Step: 13
Training loss: 1.5396850109100342
Validation loss: 2.1576745311419168

Epoch: 205| Step: 0
Training loss: 2.1259264945983887
Validation loss: 2.155737300713857

Epoch: 6| Step: 1
Training loss: 1.3692587614059448
Validation loss: 2.189066251118978

Epoch: 6| Step: 2
Training loss: 1.7119954824447632
Validation loss: 2.190828482309977

Epoch: 6| Step: 3
Training loss: 1.3551520109176636
Validation loss: 2.2053468227386475

Epoch: 6| Step: 4
Training loss: 1.5443754196166992
Validation loss: 2.2311415870984397

Epoch: 6| Step: 5
Training loss: 2.2526988983154297
Validation loss: 2.2609692215919495

Epoch: 6| Step: 6
Training loss: 2.2528486251831055
Validation loss: 2.2705583373705545

Epoch: 6| Step: 7
Training loss: 1.4767838716506958
Validation loss: 2.2636084159215293

Epoch: 6| Step: 8
Training loss: 2.8131160736083984
Validation loss: 2.2389358282089233

Epoch: 6| Step: 9
Training loss: 1.433579921722412
Validation loss: 2.2407344381014505

Epoch: 6| Step: 10
Training loss: 1.683825969696045
Validation loss: 2.2281671365102134

Epoch: 6| Step: 11
Training loss: 1.569087028503418
Validation loss: 2.2258739868799844

Epoch: 6| Step: 12
Training loss: 1.6214278936386108
Validation loss: 2.195237616697947

Epoch: 6| Step: 13
Training loss: 2.044915199279785
Validation loss: 2.183697005112966

Epoch: 206| Step: 0
Training loss: 1.5608952045440674
Validation loss: 2.1910513639450073

Epoch: 6| Step: 1
Training loss: 1.8296194076538086
Validation loss: 2.1747423013051352

Epoch: 6| Step: 2
Training loss: 1.1587629318237305
Validation loss: 2.173838794231415

Epoch: 6| Step: 3
Training loss: 2.5178661346435547
Validation loss: 2.1715646386146545

Epoch: 6| Step: 4
Training loss: 1.7143380641937256
Validation loss: 2.1787747542063394

Epoch: 6| Step: 5
Training loss: 1.1198601722717285
Validation loss: 2.1926982601483664

Epoch: 6| Step: 6
Training loss: 1.6404656171798706
Validation loss: 2.1897318363189697

Epoch: 6| Step: 7
Training loss: 2.7284507751464844
Validation loss: 2.2064509789148965

Epoch: 6| Step: 8
Training loss: 2.053539991378784
Validation loss: 2.1936115026474

Epoch: 6| Step: 9
Training loss: 1.7623772621154785
Validation loss: 2.208093047142029

Epoch: 6| Step: 10
Training loss: 1.6484119892120361
Validation loss: 2.233924388885498

Epoch: 6| Step: 11
Training loss: 2.0795769691467285
Validation loss: 2.23003884156545

Epoch: 6| Step: 12
Training loss: 1.7125478982925415
Validation loss: 2.2480568091074624

Epoch: 6| Step: 13
Training loss: 1.5435693264007568
Validation loss: 2.2404714822769165

Epoch: 207| Step: 0
Training loss: 2.005199670791626
Validation loss: 2.2108702262242637

Epoch: 6| Step: 1
Training loss: 2.036419153213501
Validation loss: 2.1880152424176535

Epoch: 6| Step: 2
Training loss: 2.4574198722839355
Validation loss: 2.1846052606900535

Epoch: 6| Step: 3
Training loss: 1.2033495903015137
Validation loss: 2.191786289215088

Epoch: 6| Step: 4
Training loss: 1.3245056867599487
Validation loss: 2.190154035886129

Epoch: 6| Step: 5
Training loss: 1.456017255783081
Validation loss: 2.204361140727997

Epoch: 6| Step: 6
Training loss: 1.3498516082763672
Validation loss: 2.176400581995646

Epoch: 6| Step: 7
Training loss: 1.7959856986999512
Validation loss: 2.2188855608304343

Epoch: 6| Step: 8
Training loss: 1.526066780090332
Validation loss: 2.221149524052938

Epoch: 6| Step: 9
Training loss: 2.3165531158447266
Validation loss: 2.2265023986498513

Epoch: 6| Step: 10
Training loss: 1.3045423030853271
Validation loss: 2.180606206258138

Epoch: 6| Step: 11
Training loss: 2.20371150970459
Validation loss: 2.1883817315101624

Epoch: 6| Step: 12
Training loss: 1.4896965026855469
Validation loss: 2.1856961846351624

Epoch: 6| Step: 13
Training loss: 1.6813825368881226
Validation loss: 2.1870845953623452

Epoch: 208| Step: 0
Training loss: 1.2891396284103394
Validation loss: 2.202459394931793

Epoch: 6| Step: 1
Training loss: 2.8093554973602295
Validation loss: 2.206408460934957

Epoch: 6| Step: 2
Training loss: 2.053403377532959
Validation loss: 2.1954999963442483

Epoch: 6| Step: 3
Training loss: 2.0265896320343018
Validation loss: 2.2050718466440835

Epoch: 6| Step: 4
Training loss: 1.6882412433624268
Validation loss: 2.205682337284088

Epoch: 6| Step: 5
Training loss: 1.3355190753936768
Validation loss: 2.2261937657992044

Epoch: 6| Step: 6
Training loss: 1.3283449411392212
Validation loss: 2.2144287625948587

Epoch: 6| Step: 7
Training loss: 2.655553102493286
Validation loss: 2.225540518760681

Epoch: 6| Step: 8
Training loss: 1.8212233781814575
Validation loss: 2.208332896232605

Epoch: 6| Step: 9
Training loss: 1.6013503074645996
Validation loss: 2.209616502126058

Epoch: 6| Step: 10
Training loss: 1.3391506671905518
Validation loss: 2.2085421880086265

Epoch: 6| Step: 11
Training loss: 1.448163628578186
Validation loss: 2.2105294863382974

Epoch: 6| Step: 12
Training loss: 1.0925195217132568
Validation loss: 2.228953003883362

Epoch: 6| Step: 13
Training loss: 1.8507685661315918
Validation loss: 2.235096534093221

Epoch: 209| Step: 0
Training loss: 2.209838390350342
Validation loss: 2.233223477999369

Epoch: 6| Step: 1
Training loss: 1.677209734916687
Validation loss: 2.2204655607541404

Epoch: 6| Step: 2
Training loss: 1.3169169425964355
Validation loss: 2.2511949936548867

Epoch: 6| Step: 3
Training loss: 1.9472649097442627
Validation loss: 2.235034386316935

Epoch: 6| Step: 4
Training loss: 1.7483007907867432
Validation loss: 2.21463672320048

Epoch: 6| Step: 5
Training loss: 1.6365916728973389
Validation loss: 2.2008197704950967

Epoch: 6| Step: 6
Training loss: 1.5244464874267578
Validation loss: 2.188040792942047

Epoch: 6| Step: 7
Training loss: 1.8795480728149414
Validation loss: 2.1708279848098755

Epoch: 6| Step: 8
Training loss: 1.260556697845459
Validation loss: 2.1722306609153748

Epoch: 6| Step: 9
Training loss: 1.4864004850387573
Validation loss: 2.1739123662312827

Epoch: 6| Step: 10
Training loss: 1.7481355667114258
Validation loss: 2.1673765182495117

Epoch: 6| Step: 11
Training loss: 1.7558282613754272
Validation loss: 2.1741996804873147

Epoch: 6| Step: 12
Training loss: 2.1314167976379395
Validation loss: 2.176611344019572

Epoch: 6| Step: 13
Training loss: 1.7860782146453857
Validation loss: 2.22172619899114

Epoch: 210| Step: 0
Training loss: 1.9126660823822021
Validation loss: 2.205598473548889

Epoch: 6| Step: 1
Training loss: 1.535439133644104
Validation loss: 2.2159255544344583

Epoch: 6| Step: 2
Training loss: 1.2112905979156494
Validation loss: 2.2392703890800476

Epoch: 6| Step: 3
Training loss: 1.9141530990600586
Validation loss: 2.2196648716926575

Epoch: 6| Step: 4
Training loss: 2.384047031402588
Validation loss: 2.2226160963376365

Epoch: 6| Step: 5
Training loss: 2.416792392730713
Validation loss: 2.206430355707804

Epoch: 6| Step: 6
Training loss: 1.2348887920379639
Validation loss: 2.222478906313578

Epoch: 6| Step: 7
Training loss: 1.1208206415176392
Validation loss: 2.1952252984046936

Epoch: 6| Step: 8
Training loss: 1.9848170280456543
Validation loss: 2.209632476170858

Epoch: 6| Step: 9
Training loss: 1.2350261211395264
Validation loss: 2.1877453128496804

Epoch: 6| Step: 10
Training loss: 1.4053220748901367
Validation loss: 2.1716016133626304

Epoch: 6| Step: 11
Training loss: 2.250671863555908
Validation loss: 2.176099677880605

Epoch: 6| Step: 12
Training loss: 2.2280397415161133
Validation loss: 2.155251940091451

Epoch: 6| Step: 13
Training loss: 1.5063469409942627
Validation loss: 2.1689456899960837

Epoch: 211| Step: 0
Training loss: 1.3822916746139526
Validation loss: 2.1746174693107605

Epoch: 6| Step: 1
Training loss: 1.840439796447754
Validation loss: 2.1792439222335815

Epoch: 6| Step: 2
Training loss: 2.565847396850586
Validation loss: 2.1772073904673257

Epoch: 6| Step: 3
Training loss: 1.7003579139709473
Validation loss: 2.1863345305124917

Epoch: 6| Step: 4
Training loss: 1.8351943492889404
Validation loss: 2.198610246181488

Epoch: 6| Step: 5
Training loss: 1.2126901149749756
Validation loss: 2.235214869181315

Epoch: 6| Step: 6
Training loss: 2.323706865310669
Validation loss: 2.1982566912968955

Epoch: 6| Step: 7
Training loss: 1.7059595584869385
Validation loss: 2.209989627202352

Epoch: 6| Step: 8
Training loss: 2.0034074783325195
Validation loss: 2.2388694485028586

Epoch: 6| Step: 9
Training loss: 1.202226161956787
Validation loss: 2.246411124865214

Epoch: 6| Step: 10
Training loss: 2.194016218185425
Validation loss: 2.256420691808065

Epoch: 6| Step: 11
Training loss: 1.269587516784668
Validation loss: 2.224169929822286

Epoch: 6| Step: 12
Training loss: 2.1711668968200684
Validation loss: 2.202049732208252

Epoch: 6| Step: 13
Training loss: 1.3724768161773682
Validation loss: 2.1913565198580423

Epoch: 212| Step: 0
Training loss: 1.5153007507324219
Validation loss: 2.1744441787401834

Epoch: 6| Step: 1
Training loss: 1.4329010248184204
Validation loss: 2.160346825917562

Epoch: 6| Step: 2
Training loss: 2.103140354156494
Validation loss: 2.1597477793693542

Epoch: 6| Step: 3
Training loss: 2.139113664627075
Validation loss: 2.152302006880442

Epoch: 6| Step: 4
Training loss: 1.4278132915496826
Validation loss: 2.1384945710500083

Epoch: 6| Step: 5
Training loss: 2.2265024185180664
Validation loss: 2.158334493637085

Epoch: 6| Step: 6
Training loss: 2.2418065071105957
Validation loss: 2.176286220550537

Epoch: 6| Step: 7
Training loss: 1.4885023832321167
Validation loss: 2.1797068119049072

Epoch: 6| Step: 8
Training loss: 1.422124981880188
Validation loss: 2.2084458470344543

Epoch: 6| Step: 9
Training loss: 1.5116183757781982
Validation loss: 2.217845877011617

Epoch: 6| Step: 10
Training loss: 1.8985052108764648
Validation loss: 2.256157656510671

Epoch: 6| Step: 11
Training loss: 1.4684486389160156
Validation loss: 2.2619741757710776

Epoch: 6| Step: 12
Training loss: 1.9495577812194824
Validation loss: 2.244137624899546

Epoch: 6| Step: 13
Training loss: 1.9836349487304688
Validation loss: 2.257620652516683

Epoch: 213| Step: 0
Training loss: 1.6287493705749512
Validation loss: 2.278523623943329

Epoch: 6| Step: 1
Training loss: 2.0670995712280273
Validation loss: 2.260611891746521

Epoch: 6| Step: 2
Training loss: 1.854710578918457
Validation loss: 2.2370903690656028

Epoch: 6| Step: 3
Training loss: 1.6204339265823364
Validation loss: 2.2428241968154907

Epoch: 6| Step: 4
Training loss: 1.2666943073272705
Validation loss: 2.2220300436019897

Epoch: 6| Step: 5
Training loss: 1.2555899620056152
Validation loss: 2.2172271013259888

Epoch: 6| Step: 6
Training loss: 1.233029842376709
Validation loss: 2.184346934159597

Epoch: 6| Step: 7
Training loss: 2.0861716270446777
Validation loss: 2.1881829500198364

Epoch: 6| Step: 8
Training loss: 1.9502462148666382
Validation loss: 2.1618533531824746

Epoch: 6| Step: 9
Training loss: 2.2831523418426514
Validation loss: 2.176447629928589

Epoch: 6| Step: 10
Training loss: 1.98263418674469
Validation loss: 2.180942118167877

Epoch: 6| Step: 11
Training loss: 2.115814685821533
Validation loss: 2.1892717281977334

Epoch: 6| Step: 12
Training loss: 1.4637079238891602
Validation loss: 2.1720169385274253

Epoch: 6| Step: 13
Training loss: 1.6404411792755127
Validation loss: 2.178062299887339

Epoch: 214| Step: 0
Training loss: 2.4399614334106445
Validation loss: 2.158715844154358

Epoch: 6| Step: 1
Training loss: 1.797189712524414
Validation loss: 2.17180468638738

Epoch: 6| Step: 2
Training loss: 1.3627641201019287
Validation loss: 2.1915095249811807

Epoch: 6| Step: 3
Training loss: 0.8809391260147095
Validation loss: 2.1630257964134216

Epoch: 6| Step: 4
Training loss: 1.888886570930481
Validation loss: 2.1706067522366843

Epoch: 6| Step: 5
Training loss: 1.4494454860687256
Validation loss: 2.1864622036616006

Epoch: 6| Step: 6
Training loss: 1.4202041625976562
Validation loss: 2.1772898038228354

Epoch: 6| Step: 7
Training loss: 2.1895999908447266
Validation loss: 2.185759743054708

Epoch: 6| Step: 8
Training loss: 1.9885437488555908
Validation loss: 2.218118151028951

Epoch: 6| Step: 9
Training loss: 1.9675952196121216
Validation loss: 2.2001388669013977

Epoch: 6| Step: 10
Training loss: 2.101757526397705
Validation loss: 2.1927424669265747

Epoch: 6| Step: 11
Training loss: 1.5905420780181885
Validation loss: 2.174400250116984

Epoch: 6| Step: 12
Training loss: 1.4331142902374268
Validation loss: 2.182089606920878

Epoch: 6| Step: 13
Training loss: 1.6434571743011475
Validation loss: 2.1922417879104614

Epoch: 215| Step: 0
Training loss: 1.1295228004455566
Validation loss: 2.1559119621912637

Epoch: 6| Step: 1
Training loss: 1.724275827407837
Validation loss: 2.1634952227274575

Epoch: 6| Step: 2
Training loss: 1.5701335668563843
Validation loss: 2.1733115712801614

Epoch: 6| Step: 3
Training loss: 2.2037105560302734
Validation loss: 2.1622517704963684

Epoch: 6| Step: 4
Training loss: 1.4650137424468994
Validation loss: 2.1771304607391357

Epoch: 6| Step: 5
Training loss: 1.363318681716919
Validation loss: 2.1643932461738586

Epoch: 6| Step: 6
Training loss: 1.2221455574035645
Validation loss: 2.1864596605300903

Epoch: 6| Step: 7
Training loss: 1.4042384624481201
Validation loss: 2.2010602355003357

Epoch: 6| Step: 8
Training loss: 2.5277199745178223
Validation loss: 2.191787918408712

Epoch: 6| Step: 9
Training loss: 1.2594621181488037
Validation loss: 2.230044702688853

Epoch: 6| Step: 10
Training loss: 1.6939878463745117
Validation loss: 2.213758647441864

Epoch: 6| Step: 11
Training loss: 2.2220635414123535
Validation loss: 2.194952925046285

Epoch: 6| Step: 12
Training loss: 1.9177563190460205
Validation loss: 2.183664381504059

Epoch: 6| Step: 13
Training loss: 2.349794626235962
Validation loss: 2.177025298277537

Epoch: 216| Step: 0
Training loss: 1.5738959312438965
Validation loss: 2.1680596470832825

Epoch: 6| Step: 1
Training loss: 1.4075572490692139
Validation loss: 2.1988958517710366

Epoch: 6| Step: 2
Training loss: 1.692605972290039
Validation loss: 2.21416445573171

Epoch: 6| Step: 3
Training loss: 1.7948412895202637
Validation loss: 2.2503608862559

Epoch: 6| Step: 4
Training loss: 1.9645880460739136
Validation loss: 2.2738683025042215

Epoch: 6| Step: 5
Training loss: 1.8829824924468994
Validation loss: 2.2686753273010254

Epoch: 6| Step: 6
Training loss: 2.193727970123291
Validation loss: 2.252840439478556

Epoch: 6| Step: 7
Training loss: 1.3880270719528198
Validation loss: 2.2648787101109824

Epoch: 6| Step: 8
Training loss: 1.4501657485961914
Validation loss: 2.2620253960291543

Epoch: 6| Step: 9
Training loss: 1.249114990234375
Validation loss: 2.2381715774536133

Epoch: 6| Step: 10
Training loss: 2.1484487056732178
Validation loss: 2.2304640809694924

Epoch: 6| Step: 11
Training loss: 1.5660924911499023
Validation loss: 2.2197206020355225

Epoch: 6| Step: 12
Training loss: 1.59990656375885
Validation loss: 2.192180852095286

Epoch: 6| Step: 13
Training loss: 1.785552978515625
Validation loss: 2.2046712239583335

Epoch: 217| Step: 0
Training loss: 1.4730823040008545
Validation loss: 2.1830519636472068

Epoch: 6| Step: 1
Training loss: 1.1905252933502197
Validation loss: 2.1686845620473227

Epoch: 6| Step: 2
Training loss: 1.4067951440811157
Validation loss: 2.176154295603434

Epoch: 6| Step: 3
Training loss: 1.0038396120071411
Validation loss: 2.1720872720082602

Epoch: 6| Step: 4
Training loss: 1.2376922369003296
Validation loss: 2.1559462547302246

Epoch: 6| Step: 5
Training loss: 1.9877625703811646
Validation loss: 2.168624520301819

Epoch: 6| Step: 6
Training loss: 2.2754149436950684
Validation loss: 2.169145663579305

Epoch: 6| Step: 7
Training loss: 1.459137201309204
Validation loss: 2.1657913525899253

Epoch: 6| Step: 8
Training loss: 2.1942949295043945
Validation loss: 2.1670475006103516

Epoch: 6| Step: 9
Training loss: 2.320460081100464
Validation loss: 2.1654486060142517

Epoch: 6| Step: 10
Training loss: 2.1481995582580566
Validation loss: 2.1989000837008157

Epoch: 6| Step: 11
Training loss: 2.474398136138916
Validation loss: 2.1834057370821633

Epoch: 6| Step: 12
Training loss: 0.7087334394454956
Validation loss: 2.214799960454305

Epoch: 6| Step: 13
Training loss: 2.386770725250244
Validation loss: 2.1998285055160522

Epoch: 218| Step: 0
Training loss: 1.8020637035369873
Validation loss: 2.1999082962671914

Epoch: 6| Step: 1
Training loss: 1.6092963218688965
Validation loss: 2.189069449901581

Epoch: 6| Step: 2
Training loss: 2.1656742095947266
Validation loss: 2.2059165636698403

Epoch: 6| Step: 3
Training loss: 2.251007556915283
Validation loss: 2.2027751406033835

Epoch: 6| Step: 4
Training loss: 1.9228289127349854
Validation loss: 2.205989360809326

Epoch: 6| Step: 5
Training loss: 2.2606608867645264
Validation loss: 2.190767149130503

Epoch: 6| Step: 6
Training loss: 1.1356608867645264
Validation loss: 2.193343540032705

Epoch: 6| Step: 7
Training loss: 1.6334969997406006
Validation loss: 2.2038355469703674

Epoch: 6| Step: 8
Training loss: 2.101574420928955
Validation loss: 2.1850589513778687

Epoch: 6| Step: 9
Training loss: 1.5818779468536377
Validation loss: 2.201932191848755

Epoch: 6| Step: 10
Training loss: 0.9914758801460266
Validation loss: 2.208497683207194

Epoch: 6| Step: 11
Training loss: 1.1560282707214355
Validation loss: 2.173017919063568

Epoch: 6| Step: 12
Training loss: 1.7139637470245361
Validation loss: 2.1689980030059814

Epoch: 6| Step: 13
Training loss: 1.6918566226959229
Validation loss: 2.1807358264923096

Epoch: 219| Step: 0
Training loss: 2.860839366912842
Validation loss: 2.1403103868166604

Epoch: 6| Step: 1
Training loss: 1.1935410499572754
Validation loss: 2.17086931069692

Epoch: 6| Step: 2
Training loss: 1.6783432960510254
Validation loss: 2.1724390983581543

Epoch: 6| Step: 3
Training loss: 1.2965847253799438
Validation loss: 2.165932814280192

Epoch: 6| Step: 4
Training loss: 1.992317795753479
Validation loss: 2.202759404977163

Epoch: 6| Step: 5
Training loss: 1.3139164447784424
Validation loss: 2.216066896915436

Epoch: 6| Step: 6
Training loss: 1.8911571502685547
Validation loss: 2.2060861190160117

Epoch: 6| Step: 7
Training loss: 1.936259388923645
Validation loss: 2.217016259829203

Epoch: 6| Step: 8
Training loss: 1.2119255065917969
Validation loss: 2.2065885861714682

Epoch: 6| Step: 9
Training loss: 1.483327865600586
Validation loss: 2.1975775559743247

Epoch: 6| Step: 10
Training loss: 1.613980770111084
Validation loss: 2.182099163532257

Epoch: 6| Step: 11
Training loss: 1.6041582822799683
Validation loss: 2.1759580771128335

Epoch: 6| Step: 12
Training loss: 1.7241545915603638
Validation loss: 2.1870962381362915

Epoch: 6| Step: 13
Training loss: 2.0935113430023193
Validation loss: 2.1819555362065635

Epoch: 220| Step: 0
Training loss: 2.1704022884368896
Validation loss: 2.18388303120931

Epoch: 6| Step: 1
Training loss: 1.385690450668335
Validation loss: 2.1661287347475686

Epoch: 6| Step: 2
Training loss: 1.9733221530914307
Validation loss: 2.1563725074132285

Epoch: 6| Step: 3
Training loss: 1.5761818885803223
Validation loss: 2.156206786632538

Epoch: 6| Step: 4
Training loss: 1.7427029609680176
Validation loss: 2.160495420296987

Epoch: 6| Step: 5
Training loss: 1.3750934600830078
Validation loss: 2.1808551947275796

Epoch: 6| Step: 6
Training loss: 1.7698333263397217
Validation loss: 2.1877110401789346

Epoch: 6| Step: 7
Training loss: 1.8004937171936035
Validation loss: 2.1825884183247886

Epoch: 6| Step: 8
Training loss: 1.7205517292022705
Validation loss: 2.207377096017202

Epoch: 6| Step: 9
Training loss: 1.6959943771362305
Validation loss: 2.2122917572657266

Epoch: 6| Step: 10
Training loss: 1.5793393850326538
Validation loss: 2.184765855471293

Epoch: 6| Step: 11
Training loss: 1.2358639240264893
Validation loss: 2.177952508131663

Epoch: 6| Step: 12
Training loss: 2.2409465312957764
Validation loss: 2.197521766026815

Epoch: 6| Step: 13
Training loss: 1.5045762062072754
Validation loss: 2.1773207982381186

Epoch: 221| Step: 0
Training loss: 1.8584113121032715
Validation loss: 2.2184883753458657

Epoch: 6| Step: 1
Training loss: 2.2896292209625244
Validation loss: 2.194839576880137

Epoch: 6| Step: 2
Training loss: 1.5533605813980103
Validation loss: 2.193223218123118

Epoch: 6| Step: 3
Training loss: 1.0548961162567139
Validation loss: 2.2265751361846924

Epoch: 6| Step: 4
Training loss: 2.213984489440918
Validation loss: 2.24387796719869

Epoch: 6| Step: 5
Training loss: 1.2375541925430298
Validation loss: 2.227266033490499

Epoch: 6| Step: 6
Training loss: 1.6854599714279175
Validation loss: 2.2280641396840415

Epoch: 6| Step: 7
Training loss: 2.1004137992858887
Validation loss: 2.2534876664479575

Epoch: 6| Step: 8
Training loss: 1.0998632907867432
Validation loss: 2.228396475315094

Epoch: 6| Step: 9
Training loss: 2.363140821456909
Validation loss: 2.194482902685801

Epoch: 6| Step: 10
Training loss: 1.6870943307876587
Validation loss: 2.2229127089182534

Epoch: 6| Step: 11
Training loss: 1.0169674158096313
Validation loss: 2.232559939225515

Epoch: 6| Step: 12
Training loss: 1.9761019945144653
Validation loss: 2.2304881612459817

Epoch: 6| Step: 13
Training loss: 1.7387561798095703
Validation loss: 2.2411311070124307

Epoch: 222| Step: 0
Training loss: 2.4004013538360596
Validation loss: 2.2312097946802774

Epoch: 6| Step: 1
Training loss: 2.2302486896514893
Validation loss: 2.2040805220603943

Epoch: 6| Step: 2
Training loss: 1.1193959712982178
Validation loss: 2.219537377357483

Epoch: 6| Step: 3
Training loss: 1.503123164176941
Validation loss: 2.222557564576467

Epoch: 6| Step: 4
Training loss: 1.511911153793335
Validation loss: 2.191457768281301

Epoch: 6| Step: 5
Training loss: 2.5420565605163574
Validation loss: 2.1696617603302

Epoch: 6| Step: 6
Training loss: 1.6016967296600342
Validation loss: 2.1575125257174173

Epoch: 6| Step: 7
Training loss: 1.3733621835708618
Validation loss: 2.1744842330614724

Epoch: 6| Step: 8
Training loss: 1.493516206741333
Validation loss: 2.179229478041331

Epoch: 6| Step: 9
Training loss: 1.4563567638397217
Validation loss: 2.1866585413614907

Epoch: 6| Step: 10
Training loss: 1.1671898365020752
Validation loss: 2.1982719699541726

Epoch: 6| Step: 11
Training loss: 2.464437484741211
Validation loss: 2.2025877237319946

Epoch: 6| Step: 12
Training loss: 1.4496393203735352
Validation loss: 2.1969507336616516

Epoch: 6| Step: 13
Training loss: 1.1176130771636963
Validation loss: 2.2107801040013633

Epoch: 223| Step: 0
Training loss: 0.9623043537139893
Validation loss: 2.2063262859980264

Epoch: 6| Step: 1
Training loss: 1.0187780857086182
Validation loss: 2.226263483365377

Epoch: 6| Step: 2
Training loss: 2.324061870574951
Validation loss: 2.229922294616699

Epoch: 6| Step: 3
Training loss: 1.6443105936050415
Validation loss: 2.239247997601827

Epoch: 6| Step: 4
Training loss: 1.6927510499954224
Validation loss: 2.224897801876068

Epoch: 6| Step: 5
Training loss: 0.9687998294830322
Validation loss: 2.2157525022824607

Epoch: 6| Step: 6
Training loss: 1.8122024536132812
Validation loss: 2.207697053750356

Epoch: 6| Step: 7
Training loss: 1.3691771030426025
Validation loss: 2.1911545793215432

Epoch: 6| Step: 8
Training loss: 2.20175838470459
Validation loss: 2.1931898991266885

Epoch: 6| Step: 9
Training loss: 1.5766468048095703
Validation loss: 2.1781137188275657

Epoch: 6| Step: 10
Training loss: 1.9607162475585938
Validation loss: 2.1717023452123008

Epoch: 6| Step: 11
Training loss: 2.5260167121887207
Validation loss: 2.1935927669207254

Epoch: 6| Step: 12
Training loss: 1.659900426864624
Validation loss: 2.1774836579958596

Epoch: 6| Step: 13
Training loss: 1.9437084197998047
Validation loss: 2.180015802383423

Epoch: 224| Step: 0
Training loss: 1.7860443592071533
Validation loss: 2.1942374110221863

Epoch: 6| Step: 1
Training loss: 1.416182041168213
Validation loss: 2.1986053188641868

Epoch: 6| Step: 2
Training loss: 1.3268873691558838
Validation loss: 2.183142364025116

Epoch: 6| Step: 3
Training loss: 1.6543190479278564
Validation loss: 2.192993720372518

Epoch: 6| Step: 4
Training loss: 1.913170576095581
Validation loss: 2.1962153712908425

Epoch: 6| Step: 5
Training loss: 2.2135987281799316
Validation loss: 2.207155485947927

Epoch: 6| Step: 6
Training loss: 1.4111560583114624
Validation loss: 2.2391330798467

Epoch: 6| Step: 7
Training loss: 1.9969877004623413
Validation loss: 2.232037583986918

Epoch: 6| Step: 8
Training loss: 1.2937248945236206
Validation loss: 2.2505534092585244

Epoch: 6| Step: 9
Training loss: 1.9379377365112305
Validation loss: 2.2339110573132834

Epoch: 6| Step: 10
Training loss: 2.192017078399658
Validation loss: 2.264039953549703

Epoch: 6| Step: 11
Training loss: 1.9776456356048584
Validation loss: 2.250454763571421

Epoch: 6| Step: 12
Training loss: 1.6813331842422485
Validation loss: 2.2350152730941772

Epoch: 6| Step: 13
Training loss: 1.0330281257629395
Validation loss: 2.20615416765213

Epoch: 225| Step: 0
Training loss: 1.664176344871521
Validation loss: 2.1926395694414773

Epoch: 6| Step: 1
Training loss: 1.7859071493148804
Validation loss: 2.2092005014419556

Epoch: 6| Step: 2
Training loss: 2.4745736122131348
Validation loss: 2.196142077445984

Epoch: 6| Step: 3
Training loss: 1.1621348857879639
Validation loss: 2.156904697418213

Epoch: 6| Step: 4
Training loss: 2.4040446281433105
Validation loss: 2.165006101131439

Epoch: 6| Step: 5
Training loss: 1.9034032821655273
Validation loss: 2.152799447377523

Epoch: 6| Step: 6
Training loss: 1.8392491340637207
Validation loss: 2.151277701059977

Epoch: 6| Step: 7
Training loss: 1.263985514640808
Validation loss: 2.1537399689356485

Epoch: 6| Step: 8
Training loss: 1.6143238544464111
Validation loss: 2.15291166305542

Epoch: 6| Step: 9
Training loss: 1.485673189163208
Validation loss: 2.1798488895098367

Epoch: 6| Step: 10
Training loss: 1.2549344301223755
Validation loss: 2.1792624791463218

Epoch: 6| Step: 11
Training loss: 1.6332708597183228
Validation loss: 2.2419103384017944

Epoch: 6| Step: 12
Training loss: 1.580886721611023
Validation loss: 2.261893113454183

Epoch: 6| Step: 13
Training loss: 1.8559937477111816
Validation loss: 2.227957765261332

Epoch: 226| Step: 0
Training loss: 1.3957819938659668
Validation loss: 2.2466811537742615

Epoch: 6| Step: 1
Training loss: 1.8334801197052002
Validation loss: 2.2248387734095254

Epoch: 6| Step: 2
Training loss: 2.3371434211730957
Validation loss: 2.214272956053416

Epoch: 6| Step: 3
Training loss: 1.2885289192199707
Validation loss: 2.215299983819326

Epoch: 6| Step: 4
Training loss: 1.4536371231079102
Validation loss: 2.2234727144241333

Epoch: 6| Step: 5
Training loss: 1.5118968486785889
Validation loss: 2.22395787636439

Epoch: 6| Step: 6
Training loss: 1.585106611251831
Validation loss: 2.208738128344218

Epoch: 6| Step: 7
Training loss: 1.489800214767456
Validation loss: 2.2099569042523703

Epoch: 6| Step: 8
Training loss: 2.4505562782287598
Validation loss: 2.2328830560048423

Epoch: 6| Step: 9
Training loss: 1.9740047454833984
Validation loss: 2.253857513268789

Epoch: 6| Step: 10
Training loss: 0.9472837448120117
Validation loss: 2.2361737887064614

Epoch: 6| Step: 11
Training loss: 1.565914511680603
Validation loss: 2.2465117971102395

Epoch: 6| Step: 12
Training loss: 1.5311888456344604
Validation loss: 2.23795477549235

Epoch: 6| Step: 13
Training loss: 1.741914987564087
Validation loss: 2.2611827850341797

Epoch: 227| Step: 0
Training loss: 2.183199644088745
Validation loss: 2.245315949122111

Epoch: 6| Step: 1
Training loss: 1.3443728685379028
Validation loss: 2.2249876260757446

Epoch: 6| Step: 2
Training loss: 1.5472462177276611
Validation loss: 2.209943473339081

Epoch: 6| Step: 3
Training loss: 1.2673308849334717
Validation loss: 2.2063180804252625

Epoch: 6| Step: 4
Training loss: 2.3251285552978516
Validation loss: 2.218960444132487

Epoch: 6| Step: 5
Training loss: 1.493844985961914
Validation loss: 2.224802096684774

Epoch: 6| Step: 6
Training loss: 2.7698564529418945
Validation loss: 2.2108530600865683

Epoch: 6| Step: 7
Training loss: 1.6785885095596313
Validation loss: 2.2139530380566916

Epoch: 6| Step: 8
Training loss: 1.5523618459701538
Validation loss: 2.2212738593419394

Epoch: 6| Step: 9
Training loss: 0.8432060480117798
Validation loss: 2.2236056526501975

Epoch: 6| Step: 10
Training loss: 2.038815498352051
Validation loss: 2.2301762104034424

Epoch: 6| Step: 11
Training loss: 1.459766149520874
Validation loss: 2.218904972076416

Epoch: 6| Step: 12
Training loss: 1.4283525943756104
Validation loss: 2.196418841679891

Epoch: 6| Step: 13
Training loss: 1.2593104839324951
Validation loss: 2.222644090652466

Epoch: 228| Step: 0
Training loss: 1.049687385559082
Validation loss: 2.211322764555613

Epoch: 6| Step: 1
Training loss: 1.4293301105499268
Validation loss: 2.2182496388753257

Epoch: 6| Step: 2
Training loss: 2.149651527404785
Validation loss: 2.228263338406881

Epoch: 6| Step: 3
Training loss: 1.4595191478729248
Validation loss: 2.237917343775431

Epoch: 6| Step: 4
Training loss: 1.9726237058639526
Validation loss: 2.2507216731707254

Epoch: 6| Step: 5
Training loss: 1.5146605968475342
Validation loss: 2.21993488073349

Epoch: 6| Step: 6
Training loss: 1.1334342956542969
Validation loss: 2.226906895637512

Epoch: 6| Step: 7
Training loss: 2.350642204284668
Validation loss: 2.2357439597447715

Epoch: 6| Step: 8
Training loss: 1.7469427585601807
Validation loss: 2.2503387928009033

Epoch: 6| Step: 9
Training loss: 1.7569870948791504
Validation loss: 2.2054110368092856

Epoch: 6| Step: 10
Training loss: 1.4853099584579468
Validation loss: 2.197959244251251

Epoch: 6| Step: 11
Training loss: 2.0338189601898193
Validation loss: 2.219825287659963

Epoch: 6| Step: 12
Training loss: 1.7421910762786865
Validation loss: 2.206706782182058

Epoch: 6| Step: 13
Training loss: 1.4384105205535889
Validation loss: 2.1941869854927063

Epoch: 229| Step: 0
Training loss: 1.571388602256775
Validation loss: 2.1794992884000144

Epoch: 6| Step: 1
Training loss: 1.9799468517303467
Validation loss: 2.209039290746053

Epoch: 6| Step: 2
Training loss: 1.6543093919754028
Validation loss: 2.1919649243354797

Epoch: 6| Step: 3
Training loss: 1.9311500787734985
Validation loss: 2.2083218693733215

Epoch: 6| Step: 4
Training loss: 1.5128254890441895
Validation loss: 2.2182811498641968

Epoch: 6| Step: 5
Training loss: 1.4049007892608643
Validation loss: 2.2207790414492288

Epoch: 6| Step: 6
Training loss: 1.7428990602493286
Validation loss: 2.1716346939404807

Epoch: 6| Step: 7
Training loss: 1.724290370941162
Validation loss: 2.1841802398363748

Epoch: 6| Step: 8
Training loss: 1.4854296445846558
Validation loss: 2.1760430335998535

Epoch: 6| Step: 9
Training loss: 1.7623443603515625
Validation loss: 2.1623761852582297

Epoch: 6| Step: 10
Training loss: 1.6426326036453247
Validation loss: 2.157920479774475

Epoch: 6| Step: 11
Training loss: 1.8765838146209717
Validation loss: 2.1953993439674377

Epoch: 6| Step: 12
Training loss: 1.6451430320739746
Validation loss: 2.175635655721029

Epoch: 6| Step: 13
Training loss: 1.564004898071289
Validation loss: 2.1867387890815735

Epoch: 230| Step: 0
Training loss: 1.215132713317871
Validation loss: 2.1972952683766684

Epoch: 6| Step: 1
Training loss: 2.1231188774108887
Validation loss: 2.2148477037747702

Epoch: 6| Step: 2
Training loss: 1.307042121887207
Validation loss: 2.1894819339116416

Epoch: 6| Step: 3
Training loss: 1.1761834621429443
Validation loss: 2.2031257351239524

Epoch: 6| Step: 4
Training loss: 2.4466497898101807
Validation loss: 2.2209823727607727

Epoch: 6| Step: 5
Training loss: 2.0926904678344727
Validation loss: 2.2248453895250955

Epoch: 6| Step: 6
Training loss: 1.1053375005722046
Validation loss: 2.2504855394363403

Epoch: 6| Step: 7
Training loss: 2.3116962909698486
Validation loss: 2.2472787300745645

Epoch: 6| Step: 8
Training loss: 1.3242783546447754
Validation loss: 2.2488648494084678

Epoch: 6| Step: 9
Training loss: 1.5608532428741455
Validation loss: 2.2559112707773843

Epoch: 6| Step: 10
Training loss: 1.501011610031128
Validation loss: 2.2483156323432922

Epoch: 6| Step: 11
Training loss: 1.770444393157959
Validation loss: 2.256864150365194

Epoch: 6| Step: 12
Training loss: 1.876257061958313
Validation loss: 2.221365769704183

Epoch: 6| Step: 13
Training loss: 1.3700953722000122
Validation loss: 2.1954504251480103

Epoch: 231| Step: 0
Training loss: 1.5085597038269043
Validation loss: 2.216732660929362

Epoch: 6| Step: 1
Training loss: 1.5653038024902344
Validation loss: 2.192269424597422

Epoch: 6| Step: 2
Training loss: 1.9128538370132446
Validation loss: 2.2221051851908364

Epoch: 6| Step: 3
Training loss: 1.7056481838226318
Validation loss: 2.1935161352157593

Epoch: 6| Step: 4
Training loss: 1.927240252494812
Validation loss: 2.2127991318702698

Epoch: 6| Step: 5
Training loss: 1.7592133283615112
Validation loss: 2.2205723325411477

Epoch: 6| Step: 6
Training loss: 1.0856566429138184
Validation loss: 2.239742716153463

Epoch: 6| Step: 7
Training loss: 1.0021026134490967
Validation loss: 2.204517046610514

Epoch: 6| Step: 8
Training loss: 1.1347107887268066
Validation loss: 2.2309117515881858

Epoch: 6| Step: 9
Training loss: 2.029500722885132
Validation loss: 2.2128495375315347

Epoch: 6| Step: 10
Training loss: 1.9190449714660645
Validation loss: 2.192667305469513

Epoch: 6| Step: 11
Training loss: 1.7540439367294312
Validation loss: 2.1837082306543985

Epoch: 6| Step: 12
Training loss: 1.8913357257843018
Validation loss: 2.1986714204152427

Epoch: 6| Step: 13
Training loss: 1.7054698467254639
Validation loss: 2.1912132700284324

Epoch: 232| Step: 0
Training loss: 1.8760031461715698
Validation loss: 2.1795525550842285

Epoch: 6| Step: 1
Training loss: 1.8156015872955322
Validation loss: 2.1813313961029053

Epoch: 6| Step: 2
Training loss: 1.433783769607544
Validation loss: 2.1772579352060952

Epoch: 6| Step: 3
Training loss: 1.183199167251587
Validation loss: 2.173092842102051

Epoch: 6| Step: 4
Training loss: 1.8276716470718384
Validation loss: 2.1877716382344565

Epoch: 6| Step: 5
Training loss: 2.112250804901123
Validation loss: 2.17489226659139

Epoch: 6| Step: 6
Training loss: 1.8875596523284912
Validation loss: 2.1783608396848044

Epoch: 6| Step: 7
Training loss: 1.1053204536437988
Validation loss: 2.192534784475962

Epoch: 6| Step: 8
Training loss: 1.6343356370925903
Validation loss: 2.181877851486206

Epoch: 6| Step: 9
Training loss: 1.9280486106872559
Validation loss: 2.218271096547445

Epoch: 6| Step: 10
Training loss: 1.7252461910247803
Validation loss: 2.1903918584187827

Epoch: 6| Step: 11
Training loss: 1.6497429609298706
Validation loss: 2.197144031524658

Epoch: 6| Step: 12
Training loss: 1.5847547054290771
Validation loss: 2.183347225189209

Epoch: 6| Step: 13
Training loss: 1.6502830982208252
Validation loss: 2.211840053399404

Epoch: 233| Step: 0
Training loss: 2.084327220916748
Validation loss: 2.2329355279604592

Epoch: 6| Step: 1
Training loss: 1.3975975513458252
Validation loss: 2.2169161240259805

Epoch: 6| Step: 2
Training loss: 1.5297954082489014
Validation loss: 2.2135563691457114

Epoch: 6| Step: 3
Training loss: 2.0289077758789062
Validation loss: 2.2262649734814963

Epoch: 6| Step: 4
Training loss: 2.161177158355713
Validation loss: 2.200281103452047

Epoch: 6| Step: 5
Training loss: 1.778206467628479
Validation loss: 2.1793946822484336

Epoch: 6| Step: 6
Training loss: 2.3015267848968506
Validation loss: 2.172465701897939

Epoch: 6| Step: 7
Training loss: 1.7332277297973633
Validation loss: 2.1816030542055764

Epoch: 6| Step: 8
Training loss: 1.807791829109192
Validation loss: 2.1822375456492105

Epoch: 6| Step: 9
Training loss: 1.185220718383789
Validation loss: 2.1845936377843223

Epoch: 6| Step: 10
Training loss: 1.6553200483322144
Validation loss: 2.1661768356959024

Epoch: 6| Step: 11
Training loss: 1.9578955173492432
Validation loss: 2.1861876249313354

Epoch: 6| Step: 12
Training loss: 0.8348096013069153
Validation loss: 2.179042021433512

Epoch: 6| Step: 13
Training loss: 1.1678210496902466
Validation loss: 2.1889615853627524

Epoch: 234| Step: 0
Training loss: 1.511169195175171
Validation loss: 2.2090546687444053

Epoch: 6| Step: 1
Training loss: 2.1313252449035645
Validation loss: 2.2291809717814126

Epoch: 6| Step: 2
Training loss: 1.4418799877166748
Validation loss: 2.2385989228884378

Epoch: 6| Step: 3
Training loss: 2.010401487350464
Validation loss: 2.220906615257263

Epoch: 6| Step: 4
Training loss: 1.2544219493865967
Validation loss: 2.181830664475759

Epoch: 6| Step: 5
Training loss: 2.0396454334259033
Validation loss: 2.2038830717404685

Epoch: 6| Step: 6
Training loss: 1.0964076519012451
Validation loss: 2.2470598220825195

Epoch: 6| Step: 7
Training loss: 2.4957661628723145
Validation loss: 2.186083515485128

Epoch: 6| Step: 8
Training loss: 2.2064123153686523
Validation loss: 2.215062379837036

Epoch: 6| Step: 9
Training loss: 1.0382739305496216
Validation loss: 2.204871714115143

Epoch: 6| Step: 10
Training loss: 2.5032126903533936
Validation loss: 2.2014554738998413

Epoch: 6| Step: 11
Training loss: 1.7520363330841064
Validation loss: 2.206271171569824

Epoch: 6| Step: 12
Training loss: 1.5112667083740234
Validation loss: 2.195494810740153

Epoch: 6| Step: 13
Training loss: 1.4185411930084229
Validation loss: 2.199537217617035

Epoch: 235| Step: 0
Training loss: 1.5352333784103394
Validation loss: 2.2145297527313232

Epoch: 6| Step: 1
Training loss: 1.9409418106079102
Validation loss: 2.221624751885732

Epoch: 6| Step: 2
Training loss: 1.3560296297073364
Validation loss: 2.193788170814514

Epoch: 6| Step: 3
Training loss: 2.2553486824035645
Validation loss: 2.217863897482554

Epoch: 6| Step: 4
Training loss: 1.6040925979614258
Validation loss: 2.226431131362915

Epoch: 6| Step: 5
Training loss: 1.7381049394607544
Validation loss: 2.235900064309438

Epoch: 6| Step: 6
Training loss: 1.5753971338272095
Validation loss: 2.224719762802124

Epoch: 6| Step: 7
Training loss: 2.344278573989868
Validation loss: 2.242810845375061

Epoch: 6| Step: 8
Training loss: 1.9222197532653809
Validation loss: 2.2405331134796143

Epoch: 6| Step: 9
Training loss: 1.3784247636795044
Validation loss: 2.2285081148147583

Epoch: 6| Step: 10
Training loss: 1.426896095275879
Validation loss: 2.2628066539764404

Epoch: 6| Step: 11
Training loss: 0.9932984113693237
Validation loss: 2.203111946582794

Epoch: 6| Step: 12
Training loss: 1.5353870391845703
Validation loss: 2.221625248591105

Epoch: 6| Step: 13
Training loss: 1.238527774810791
Validation loss: 2.2207747101783752

Epoch: 236| Step: 0
Training loss: 2.182309150695801
Validation loss: 2.199854791164398

Epoch: 6| Step: 1
Training loss: 1.8589307069778442
Validation loss: 2.18813427289327

Epoch: 6| Step: 2
Training loss: 2.473236560821533
Validation loss: 2.188490112622579

Epoch: 6| Step: 3
Training loss: 1.6361992359161377
Validation loss: 2.1807256738344827

Epoch: 6| Step: 4
Training loss: 2.429936170578003
Validation loss: 2.207434336344401

Epoch: 6| Step: 5
Training loss: 1.5357232093811035
Validation loss: 2.19831383228302

Epoch: 6| Step: 6
Training loss: 1.8395015001296997
Validation loss: 2.2010934352874756

Epoch: 6| Step: 7
Training loss: 1.2279105186462402
Validation loss: 2.208364407221476

Epoch: 6| Step: 8
Training loss: 1.8810688257217407
Validation loss: 2.217946151892344

Epoch: 6| Step: 9
Training loss: 0.7640941739082336
Validation loss: 2.217296779155731

Epoch: 6| Step: 10
Training loss: 1.1122512817382812
Validation loss: 2.2293309768040976

Epoch: 6| Step: 11
Training loss: 1.6874712705612183
Validation loss: 2.2432479858398438

Epoch: 6| Step: 12
Training loss: 1.3890693187713623
Validation loss: 2.251164654890696

Epoch: 6| Step: 13
Training loss: 1.4552571773529053
Validation loss: 2.2628082434336343

Epoch: 237| Step: 0
Training loss: 1.5868544578552246
Validation loss: 2.225478788216909

Epoch: 6| Step: 1
Training loss: 1.2594666481018066
Validation loss: 2.2375250657399497

Epoch: 6| Step: 2
Training loss: 1.7772560119628906
Validation loss: 2.199910322825114

Epoch: 6| Step: 3
Training loss: 1.392488956451416
Validation loss: 2.2088570594787598

Epoch: 6| Step: 4
Training loss: 1.8238052129745483
Validation loss: 2.1933993299802146

Epoch: 6| Step: 5
Training loss: 2.1425180435180664
Validation loss: 2.196263154347738

Epoch: 6| Step: 6
Training loss: 1.5884978771209717
Validation loss: 2.200378100077311

Epoch: 6| Step: 7
Training loss: 1.8895143270492554
Validation loss: 2.1786500016848245

Epoch: 6| Step: 8
Training loss: 1.7059330940246582
Validation loss: 2.177981913089752

Epoch: 6| Step: 9
Training loss: 1.0947237014770508
Validation loss: 2.187681496143341

Epoch: 6| Step: 10
Training loss: 1.0073440074920654
Validation loss: 2.1872930924097695

Epoch: 6| Step: 11
Training loss: 1.40370774269104
Validation loss: 2.210411270459493

Epoch: 6| Step: 12
Training loss: 1.6987724304199219
Validation loss: 2.209110220273336

Epoch: 6| Step: 13
Training loss: 2.3582959175109863
Validation loss: 2.213802774747213

Epoch: 238| Step: 0
Training loss: 1.9485315084457397
Validation loss: 2.2396448453267417

Epoch: 6| Step: 1
Training loss: 1.3325575590133667
Validation loss: 2.264001409212748

Epoch: 6| Step: 2
Training loss: 1.4268028736114502
Validation loss: 2.275164703528086

Epoch: 6| Step: 3
Training loss: 1.5558042526245117
Validation loss: 2.2559046347935996

Epoch: 6| Step: 4
Training loss: 1.546992301940918
Validation loss: 2.2578232884407043

Epoch: 6| Step: 5
Training loss: 1.156374216079712
Validation loss: 2.273038923740387

Epoch: 6| Step: 6
Training loss: 1.9327508211135864
Validation loss: 2.258298377195994

Epoch: 6| Step: 7
Training loss: 2.474752426147461
Validation loss: 2.2683887481689453

Epoch: 6| Step: 8
Training loss: 1.6919506788253784
Validation loss: 2.2561184763908386

Epoch: 6| Step: 9
Training loss: 1.164448857307434
Validation loss: 2.220620274543762

Epoch: 6| Step: 10
Training loss: 2.1829049587249756
Validation loss: 2.2102455496788025

Epoch: 6| Step: 11
Training loss: 1.6178948879241943
Validation loss: 2.204876740773519

Epoch: 6| Step: 12
Training loss: 1.7153429985046387
Validation loss: 2.202640175819397

Epoch: 6| Step: 13
Training loss: 1.6312650442123413
Validation loss: 2.203749418258667

Epoch: 239| Step: 0
Training loss: 1.3026068210601807
Validation loss: 2.201080322265625

Epoch: 6| Step: 1
Training loss: 1.3560576438903809
Validation loss: 2.1849494179089866

Epoch: 6| Step: 2
Training loss: 2.025031566619873
Validation loss: 2.175944705804189

Epoch: 6| Step: 3
Training loss: 2.013396739959717
Validation loss: 2.1632814606030784

Epoch: 6| Step: 4
Training loss: 1.2724478244781494
Validation loss: 2.194023549556732

Epoch: 6| Step: 5
Training loss: 1.1008975505828857
Validation loss: 2.1928730408350625

Epoch: 6| Step: 6
Training loss: 1.4022051095962524
Validation loss: 2.1912829875946045

Epoch: 6| Step: 7
Training loss: 1.2312419414520264
Validation loss: 2.168825109799703

Epoch: 6| Step: 8
Training loss: 2.181591510772705
Validation loss: 2.201871673266093

Epoch: 6| Step: 9
Training loss: 2.2155966758728027
Validation loss: 2.2201156616210938

Epoch: 6| Step: 10
Training loss: 2.488802671432495
Validation loss: 2.1968709031740823

Epoch: 6| Step: 11
Training loss: 1.9437533617019653
Validation loss: 2.24492875734965

Epoch: 6| Step: 12
Training loss: 1.2690954208374023
Validation loss: 2.2550044457117715

Epoch: 6| Step: 13
Training loss: 1.111412525177002
Validation loss: 2.233881890773773

Epoch: 240| Step: 0
Training loss: 1.5927767753601074
Validation loss: 2.2317826747894287

Epoch: 6| Step: 1
Training loss: 1.0790841579437256
Validation loss: 2.2531144618988037

Epoch: 6| Step: 2
Training loss: 1.6937158107757568
Validation loss: 2.237047870953878

Epoch: 6| Step: 3
Training loss: 1.9458857774734497
Validation loss: 2.256843646367391

Epoch: 6| Step: 4
Training loss: 1.1245026588439941
Validation loss: 2.2565635442733765

Epoch: 6| Step: 5
Training loss: 1.3230054378509521
Validation loss: 2.2408240040143332

Epoch: 6| Step: 6
Training loss: 1.5008103847503662
Validation loss: 2.256484806537628

Epoch: 6| Step: 7
Training loss: 1.4209917783737183
Validation loss: 2.259510358174642

Epoch: 6| Step: 8
Training loss: 2.429060935974121
Validation loss: 2.2753308415412903

Epoch: 6| Step: 9
Training loss: 1.5274869203567505
Validation loss: 2.249537487824758

Epoch: 6| Step: 10
Training loss: 1.6307059526443481
Validation loss: 2.2499574224154153

Epoch: 6| Step: 11
Training loss: 2.139869213104248
Validation loss: 2.2358457843462625

Epoch: 6| Step: 12
Training loss: 2.081123113632202
Validation loss: 2.2376630703608194

Epoch: 6| Step: 13
Training loss: 1.1454826593399048
Validation loss: 2.2222084403038025

Epoch: 241| Step: 0
Training loss: 1.734156847000122
Validation loss: 2.2395273049672446

Epoch: 6| Step: 1
Training loss: 1.160839557647705
Validation loss: 2.2126133839289346

Epoch: 6| Step: 2
Training loss: 2.6078455448150635
Validation loss: 2.221399267514547

Epoch: 6| Step: 3
Training loss: 0.9891490936279297
Validation loss: 2.240742782751719

Epoch: 6| Step: 4
Training loss: 1.4424724578857422
Validation loss: 2.246584137280782

Epoch: 6| Step: 5
Training loss: 2.254490375518799
Validation loss: 2.2347575028737388

Epoch: 6| Step: 6
Training loss: 1.6475013494491577
Validation loss: 2.2239299615224204

Epoch: 6| Step: 7
Training loss: 1.5652644634246826
Validation loss: 2.238940338293711

Epoch: 6| Step: 8
Training loss: 1.9783982038497925
Validation loss: 2.252136468887329

Epoch: 6| Step: 9
Training loss: 1.357090711593628
Validation loss: 2.2306676308314004

Epoch: 6| Step: 10
Training loss: 1.986038327217102
Validation loss: 2.227282543977102

Epoch: 6| Step: 11
Training loss: 1.4321157932281494
Validation loss: 2.216980755329132

Epoch: 6| Step: 12
Training loss: 1.2124731540679932
Validation loss: 2.2105837066968284

Epoch: 6| Step: 13
Training loss: 1.3366637229919434
Validation loss: 2.2085301876068115

Epoch: 242| Step: 0
Training loss: 1.8230310678482056
Validation loss: 2.229724367459615

Epoch: 6| Step: 1
Training loss: 1.8610527515411377
Validation loss: 2.2189788619677224

Epoch: 6| Step: 2
Training loss: 1.4042563438415527
Validation loss: 2.216637929280599

Epoch: 6| Step: 3
Training loss: 2.356001615524292
Validation loss: 2.203782081604004

Epoch: 6| Step: 4
Training loss: 2.1443564891815186
Validation loss: 2.2009494304656982

Epoch: 6| Step: 5
Training loss: 1.8641579151153564
Validation loss: 2.193030039469401

Epoch: 6| Step: 6
Training loss: 1.3553855419158936
Validation loss: 2.1816887656847634

Epoch: 6| Step: 7
Training loss: 1.4915745258331299
Validation loss: 2.2225254575411477

Epoch: 6| Step: 8
Training loss: 1.1927099227905273
Validation loss: 2.2400534749031067

Epoch: 6| Step: 9
Training loss: 2.0890555381774902
Validation loss: 2.2524439493815103

Epoch: 6| Step: 10
Training loss: 1.3498283624649048
Validation loss: 2.2807140350341797

Epoch: 6| Step: 11
Training loss: 1.415529489517212
Validation loss: 2.2356433073679605

Epoch: 6| Step: 12
Training loss: 1.9899156093597412
Validation loss: 2.2213969628016152

Epoch: 6| Step: 13
Training loss: 0.9514532089233398
Validation loss: 2.231094161669413

Epoch: 243| Step: 0
Training loss: 1.7922455072402954
Validation loss: 2.2224886814753213

Epoch: 6| Step: 1
Training loss: 1.2795586585998535
Validation loss: 2.2341960072517395

Epoch: 6| Step: 2
Training loss: 2.0934667587280273
Validation loss: 2.247999350229899

Epoch: 6| Step: 3
Training loss: 2.002713918685913
Validation loss: 2.233202318350474

Epoch: 6| Step: 4
Training loss: 1.5553181171417236
Validation loss: 2.232212702433268

Epoch: 6| Step: 5
Training loss: 1.227805256843567
Validation loss: 2.26134725411733

Epoch: 6| Step: 6
Training loss: 1.6935300827026367
Validation loss: 2.224044144153595

Epoch: 6| Step: 7
Training loss: 2.2026588916778564
Validation loss: 2.2214300632476807

Epoch: 6| Step: 8
Training loss: 1.81256902217865
Validation loss: 2.2067647576332092

Epoch: 6| Step: 9
Training loss: 1.479076623916626
Validation loss: 2.208669066429138

Epoch: 6| Step: 10
Training loss: 1.172616958618164
Validation loss: 2.203950842221578

Epoch: 6| Step: 11
Training loss: 1.85837721824646
Validation loss: 2.2374902963638306

Epoch: 6| Step: 12
Training loss: 1.2303531169891357
Validation loss: 2.2249938249588013

Epoch: 6| Step: 13
Training loss: 1.369178056716919
Validation loss: 2.2313613891601562

Epoch: 244| Step: 0
Training loss: 1.3519244194030762
Validation loss: 2.248903671900431

Epoch: 6| Step: 1
Training loss: 2.3189334869384766
Validation loss: 2.2380508383115134

Epoch: 6| Step: 2
Training loss: 2.343174695968628
Validation loss: 2.2637029886245728

Epoch: 6| Step: 3
Training loss: 1.210108757019043
Validation loss: 2.2492493391036987

Epoch: 6| Step: 4
Training loss: 1.4064440727233887
Validation loss: 2.220691164334615

Epoch: 6| Step: 5
Training loss: 1.6985172033309937
Validation loss: 2.2187638878822327

Epoch: 6| Step: 6
Training loss: 1.523160696029663
Validation loss: 2.2401684125264487

Epoch: 6| Step: 7
Training loss: 1.8453874588012695
Validation loss: 2.2455262343088784

Epoch: 6| Step: 8
Training loss: 0.9798306226730347
Validation loss: 2.251876711845398

Epoch: 6| Step: 9
Training loss: 1.1737487316131592
Validation loss: 2.2337476015090942

Epoch: 6| Step: 10
Training loss: 1.6927618980407715
Validation loss: 2.260233203570048

Epoch: 6| Step: 11
Training loss: 1.274796962738037
Validation loss: 2.2431556781133017

Epoch: 6| Step: 12
Training loss: 1.6736117601394653
Validation loss: 2.2434263229370117

Epoch: 6| Step: 13
Training loss: 1.696457862854004
Validation loss: 2.2407784859339395

Epoch: 245| Step: 0
Training loss: 1.6505178213119507
Validation loss: 2.2091855804125466

Epoch: 6| Step: 1
Training loss: 1.297334909439087
Validation loss: 2.24598628282547

Epoch: 6| Step: 2
Training loss: 1.1022764444351196
Validation loss: 2.2370216449101767

Epoch: 6| Step: 3
Training loss: 1.8523859977722168
Validation loss: 2.2051764130592346

Epoch: 6| Step: 4
Training loss: 1.9420806169509888
Validation loss: 2.2299164732297263

Epoch: 6| Step: 5
Training loss: 2.2518889904022217
Validation loss: 2.2258134881655374

Epoch: 6| Step: 6
Training loss: 0.6359818577766418
Validation loss: 2.2541202902793884

Epoch: 6| Step: 7
Training loss: 1.9981434345245361
Validation loss: 2.2351152300834656

Epoch: 6| Step: 8
Training loss: 1.275364637374878
Validation loss: 2.2579856514930725

Epoch: 6| Step: 9
Training loss: 1.7266144752502441
Validation loss: 2.2166381080945334

Epoch: 6| Step: 10
Training loss: 2.3388919830322266
Validation loss: 2.2338486512502036

Epoch: 6| Step: 11
Training loss: 1.257542610168457
Validation loss: 2.2376352548599243

Epoch: 6| Step: 12
Training loss: 1.2699170112609863
Validation loss: 2.2374263803164163

Epoch: 6| Step: 13
Training loss: 1.6868743896484375
Validation loss: 2.2061467369397483

Epoch: 246| Step: 0
Training loss: 1.8318955898284912
Validation loss: 2.257928172747294

Epoch: 6| Step: 1
Training loss: 0.9727040529251099
Validation loss: 2.2382635871569314

Epoch: 6| Step: 2
Training loss: 0.8093816041946411
Validation loss: 2.2131794095039368

Epoch: 6| Step: 3
Training loss: 1.629478931427002
Validation loss: 2.2039037346839905

Epoch: 6| Step: 4
Training loss: 1.2767716646194458
Validation loss: 2.2025195558865867

Epoch: 6| Step: 5
Training loss: 2.484987258911133
Validation loss: 2.2113022208213806

Epoch: 6| Step: 6
Training loss: 0.9101961255073547
Validation loss: 2.2038886149724326

Epoch: 6| Step: 7
Training loss: 1.7269848585128784
Validation loss: 2.239282965660095

Epoch: 6| Step: 8
Training loss: 1.6338770389556885
Validation loss: 2.2147191961606345

Epoch: 6| Step: 9
Training loss: 1.5317578315734863
Validation loss: 2.2285858194033303

Epoch: 6| Step: 10
Training loss: 2.3718056678771973
Validation loss: 2.2467395861943564

Epoch: 6| Step: 11
Training loss: 1.1852757930755615
Validation loss: 2.2720444003740945

Epoch: 6| Step: 12
Training loss: 2.1312341690063477
Validation loss: 2.272130827109019

Epoch: 6| Step: 13
Training loss: 1.7135628461837769
Validation loss: 2.2858462731043496

Epoch: 247| Step: 0
Training loss: 1.3970478773117065
Validation loss: 2.2908496260643005

Epoch: 6| Step: 1
Training loss: 1.475923776626587
Validation loss: 2.3046515782674155

Epoch: 6| Step: 2
Training loss: 1.502481460571289
Validation loss: 2.2759962677955627

Epoch: 6| Step: 3
Training loss: 1.634489893913269
Validation loss: 2.273165464401245

Epoch: 6| Step: 4
Training loss: 1.521472454071045
Validation loss: 2.2891388535499573

Epoch: 6| Step: 5
Training loss: 1.1406302452087402
Validation loss: 2.2502989371617637

Epoch: 6| Step: 6
Training loss: 1.7949033975601196
Validation loss: 2.234252373377482

Epoch: 6| Step: 7
Training loss: 1.9930088520050049
Validation loss: 2.237197736899058

Epoch: 6| Step: 8
Training loss: 2.376166820526123
Validation loss: 2.239916523297628

Epoch: 6| Step: 9
Training loss: 1.2970924377441406
Validation loss: 2.2168710827827454

Epoch: 6| Step: 10
Training loss: 1.2382398843765259
Validation loss: 2.22381059328715

Epoch: 6| Step: 11
Training loss: 1.7728312015533447
Validation loss: 2.2257631421089172

Epoch: 6| Step: 12
Training loss: 1.5602794885635376
Validation loss: 2.2261427839597068

Epoch: 6| Step: 13
Training loss: 1.8252946138381958
Validation loss: 2.243837515513102

Epoch: 248| Step: 0
Training loss: 1.9174811840057373
Validation loss: 2.2419593731562295

Epoch: 6| Step: 1
Training loss: 1.9637964963912964
Validation loss: 2.254113574822744

Epoch: 6| Step: 2
Training loss: 1.1277930736541748
Validation loss: 2.224940379460653

Epoch: 6| Step: 3
Training loss: 1.693558931350708
Validation loss: 2.247577448685964

Epoch: 6| Step: 4
Training loss: 0.8685417175292969
Validation loss: 2.256536583105723

Epoch: 6| Step: 5
Training loss: 1.3483331203460693
Validation loss: 2.236674189567566

Epoch: 6| Step: 6
Training loss: 1.4705429077148438
Validation loss: 2.2502789298693338

Epoch: 6| Step: 7
Training loss: 1.2208033800125122
Validation loss: 2.229578693707784

Epoch: 6| Step: 8
Training loss: 1.1595152616500854
Validation loss: 2.233296195665995

Epoch: 6| Step: 9
Training loss: 1.3420417308807373
Validation loss: 2.2290871342023215

Epoch: 6| Step: 10
Training loss: 1.8368048667907715
Validation loss: 2.2209692001342773

Epoch: 6| Step: 11
Training loss: 2.2705554962158203
Validation loss: 2.2374587853749595

Epoch: 6| Step: 12
Training loss: 1.874847650527954
Validation loss: 2.2070714632670083

Epoch: 6| Step: 13
Training loss: 1.6756904125213623
Validation loss: 2.235131641228994

Epoch: 249| Step: 0
Training loss: 1.6937949657440186
Validation loss: 2.2471765677134194

Epoch: 6| Step: 1
Training loss: 1.8318108320236206
Validation loss: 2.2443447709083557

Epoch: 6| Step: 2
Training loss: 1.2214775085449219
Validation loss: 2.237282315889994

Epoch: 6| Step: 3
Training loss: 1.9012311697006226
Validation loss: 2.2325578331947327

Epoch: 6| Step: 4
Training loss: 1.9595439434051514
Validation loss: 2.224054217338562

Epoch: 6| Step: 5
Training loss: 2.2881088256835938
Validation loss: 2.2350920041402182

Epoch: 6| Step: 6
Training loss: 1.6977589130401611
Validation loss: 2.1969677011171975

Epoch: 6| Step: 7
Training loss: 1.2221661806106567
Validation loss: 2.227326512336731

Epoch: 6| Step: 8
Training loss: 1.4598631858825684
Validation loss: 2.2405741810798645

Epoch: 6| Step: 9
Training loss: 1.189951777458191
Validation loss: 2.2254043221473694

Epoch: 6| Step: 10
Training loss: 1.3647265434265137
Validation loss: 2.2125666538874307

Epoch: 6| Step: 11
Training loss: 0.96864914894104
Validation loss: 2.2030815879503884

Epoch: 6| Step: 12
Training loss: 1.5126729011535645
Validation loss: 2.210719962914785

Epoch: 6| Step: 13
Training loss: 1.5748038291931152
Validation loss: 2.2094651659329734

Epoch: 250| Step: 0
Training loss: 2.2295992374420166
Validation loss: 2.20839794476827

Epoch: 6| Step: 1
Training loss: 0.8241410255432129
Validation loss: 2.2156084974606833

Epoch: 6| Step: 2
Training loss: 1.4126850366592407
Validation loss: 2.2064958016077676

Epoch: 6| Step: 3
Training loss: 1.6404626369476318
Validation loss: 2.227440575758616

Epoch: 6| Step: 4
Training loss: 2.356518268585205
Validation loss: 2.228278636932373

Epoch: 6| Step: 5
Training loss: 1.1996996402740479
Validation loss: 2.2108985781669617

Epoch: 6| Step: 6
Training loss: 1.6537394523620605
Validation loss: 2.2168376644452414

Epoch: 6| Step: 7
Training loss: 1.9178102016448975
Validation loss: 2.2128922740618386

Epoch: 6| Step: 8
Training loss: 1.0024625062942505
Validation loss: 2.224598705768585

Epoch: 6| Step: 9
Training loss: 1.33101224899292
Validation loss: 2.219760557015737

Epoch: 6| Step: 10
Training loss: 0.9717189073562622
Validation loss: 2.2779131730397544

Epoch: 6| Step: 11
Training loss: 1.4307070970535278
Validation loss: 2.2607642809549966

Epoch: 6| Step: 12
Training loss: 1.7934762239456177
Validation loss: 2.250565528869629

Epoch: 6| Step: 13
Training loss: 1.7332080602645874
Validation loss: 2.269802967707316

Epoch: 251| Step: 0
Training loss: 1.9254701137542725
Validation loss: 2.25083057085673

Epoch: 6| Step: 1
Training loss: 0.9309267401695251
Validation loss: 2.2378034591674805

Epoch: 6| Step: 2
Training loss: 1.5179576873779297
Validation loss: 2.2388945817947388

Epoch: 6| Step: 3
Training loss: 1.6521623134613037
Validation loss: 2.2839372555414834

Epoch: 6| Step: 4
Training loss: 1.41793692111969
Validation loss: 2.240256388982137

Epoch: 6| Step: 5
Training loss: 1.5969572067260742
Validation loss: 2.246695876121521

Epoch: 6| Step: 6
Training loss: 1.8691434860229492
Validation loss: 2.2159777681032815

Epoch: 6| Step: 7
Training loss: 1.7474831342697144
Validation loss: 2.23184867699941

Epoch: 6| Step: 8
Training loss: 1.0853720903396606
Validation loss: 2.2552920381228128

Epoch: 6| Step: 9
Training loss: 1.4215507507324219
Validation loss: 2.203430712223053

Epoch: 6| Step: 10
Training loss: 1.7013826370239258
Validation loss: 2.2301079432169595

Epoch: 6| Step: 11
Training loss: 1.6855123043060303
Validation loss: 2.215814491113027

Epoch: 6| Step: 12
Training loss: 1.1969845294952393
Validation loss: 2.2094063560167947

Epoch: 6| Step: 13
Training loss: 1.531849980354309
Validation loss: 2.202414333820343

Epoch: 252| Step: 0
Training loss: 1.752204418182373
Validation loss: 2.2120635708173118

Epoch: 6| Step: 1
Training loss: 1.7575528621673584
Validation loss: 2.2066063483556113

Epoch: 6| Step: 2
Training loss: 1.6419135332107544
Validation loss: 2.2100253303845725

Epoch: 6| Step: 3
Training loss: 1.5546820163726807
Validation loss: 2.223708470662435

Epoch: 6| Step: 4
Training loss: 1.2447571754455566
Validation loss: 2.2103100220362344

Epoch: 6| Step: 5
Training loss: 1.2690906524658203
Validation loss: 2.203510304292043

Epoch: 6| Step: 6
Training loss: 1.279258370399475
Validation loss: 2.204037666320801

Epoch: 6| Step: 7
Training loss: 1.7379628419876099
Validation loss: 2.201959172884623

Epoch: 6| Step: 8
Training loss: 1.3132964372634888
Validation loss: 2.205043852329254

Epoch: 6| Step: 9
Training loss: 1.3078522682189941
Validation loss: 2.1975666085879006

Epoch: 6| Step: 10
Training loss: 2.078252077102661
Validation loss: 2.183259129524231

Epoch: 6| Step: 11
Training loss: 1.6100716590881348
Validation loss: 2.2101834615071616

Epoch: 6| Step: 12
Training loss: 1.5595111846923828
Validation loss: 2.2008376916249595

Epoch: 6| Step: 13
Training loss: 1.3935283422470093
Validation loss: 2.226225256919861

Epoch: 253| Step: 0
Training loss: 1.018358826637268
Validation loss: 2.212318778038025

Epoch: 6| Step: 1
Training loss: 1.4136343002319336
Validation loss: 2.218636473019918

Epoch: 6| Step: 2
Training loss: 1.1514943838119507
Validation loss: 2.2405890822410583

Epoch: 6| Step: 3
Training loss: 2.0368266105651855
Validation loss: 2.2424306074778237

Epoch: 6| Step: 4
Training loss: 0.8260858654975891
Validation loss: 2.2390264868736267

Epoch: 6| Step: 5
Training loss: 0.7168358564376831
Validation loss: 2.2520315249760947

Epoch: 6| Step: 6
Training loss: 1.530234932899475
Validation loss: 2.248743772506714

Epoch: 6| Step: 7
Training loss: 1.706496238708496
Validation loss: 2.2495434880256653

Epoch: 6| Step: 8
Training loss: 1.795569658279419
Validation loss: 2.257618546485901

Epoch: 6| Step: 9
Training loss: 1.9537090063095093
Validation loss: 2.27436101436615

Epoch: 6| Step: 10
Training loss: 2.8804240226745605
Validation loss: 2.2508948842684426

Epoch: 6| Step: 11
Training loss: 1.5550131797790527
Validation loss: 2.2400118112564087

Epoch: 6| Step: 12
Training loss: 1.4185731410980225
Validation loss: 2.21210785706838

Epoch: 6| Step: 13
Training loss: 1.288738489151001
Validation loss: 2.2109100023905435

Epoch: 254| Step: 0
Training loss: 0.95301353931427
Validation loss: 2.214601457118988

Epoch: 6| Step: 1
Training loss: 0.8982576727867126
Validation loss: 2.2194095452626548

Epoch: 6| Step: 2
Training loss: 1.2696869373321533
Validation loss: 2.196709235509237

Epoch: 6| Step: 3
Training loss: 1.7743027210235596
Validation loss: 2.1868455012639365

Epoch: 6| Step: 4
Training loss: 2.5443530082702637
Validation loss: 2.191906988620758

Epoch: 6| Step: 5
Training loss: 1.5947275161743164
Validation loss: 2.1892616152763367

Epoch: 6| Step: 6
Training loss: 1.0839283466339111
Validation loss: 2.178692122300466

Epoch: 6| Step: 7
Training loss: 1.7754216194152832
Validation loss: 2.177612086137136

Epoch: 6| Step: 8
Training loss: 1.583748698234558
Validation loss: 2.1873908837636313

Epoch: 6| Step: 9
Training loss: 1.9020681381225586
Validation loss: 2.190934956073761

Epoch: 6| Step: 10
Training loss: 1.8018455505371094
Validation loss: 2.206010937690735

Epoch: 6| Step: 11
Training loss: 1.7949538230895996
Validation loss: 2.193245510260264

Epoch: 6| Step: 12
Training loss: 0.953741729259491
Validation loss: 2.2314332127571106

Epoch: 6| Step: 13
Training loss: 1.9446141719818115
Validation loss: 2.220741113026937

Epoch: 255| Step: 0
Training loss: 1.0055625438690186
Validation loss: 2.243920087814331

Epoch: 6| Step: 1
Training loss: 1.491807460784912
Validation loss: 2.226041873296102

Epoch: 6| Step: 2
Training loss: 1.3048056364059448
Validation loss: 2.2308403650919595

Epoch: 6| Step: 3
Training loss: 1.3908565044403076
Validation loss: 2.2455294330914817

Epoch: 6| Step: 4
Training loss: 1.659653902053833
Validation loss: 2.2292768955230713

Epoch: 6| Step: 5
Training loss: 1.808893084526062
Validation loss: 2.255606452624003

Epoch: 6| Step: 6
Training loss: 1.7454192638397217
Validation loss: 2.262609283129374

Epoch: 6| Step: 7
Training loss: 1.8957254886627197
Validation loss: 2.265803058942159

Epoch: 6| Step: 8
Training loss: 1.2393206357955933
Validation loss: 2.2395392656326294

Epoch: 6| Step: 9
Training loss: 1.4249629974365234
Validation loss: 2.268113931020101

Epoch: 6| Step: 10
Training loss: 1.7448432445526123
Validation loss: 2.26358296473821

Epoch: 6| Step: 11
Training loss: 1.2177062034606934
Validation loss: 2.2647713820139566

Epoch: 6| Step: 12
Training loss: 1.9204281568527222
Validation loss: 2.258045772711436

Epoch: 6| Step: 13
Training loss: 1.206074833869934
Validation loss: 2.296472450097402

Epoch: 256| Step: 0
Training loss: 1.1390327215194702
Validation loss: 2.245956222216288

Epoch: 6| Step: 1
Training loss: 2.189518451690674
Validation loss: 2.237908681233724

Epoch: 6| Step: 2
Training loss: 1.1979732513427734
Validation loss: 2.2773338158925376

Epoch: 6| Step: 3
Training loss: 0.739165186882019
Validation loss: 2.2394604285558066

Epoch: 6| Step: 4
Training loss: 0.967376172542572
Validation loss: 2.2654728492101035

Epoch: 6| Step: 5
Training loss: 1.799547791481018
Validation loss: 2.2631850242614746

Epoch: 6| Step: 6
Training loss: 2.3213396072387695
Validation loss: 2.279235005378723

Epoch: 6| Step: 7
Training loss: 1.1525565385818481
Validation loss: 2.266535679499308

Epoch: 6| Step: 8
Training loss: 1.5394988059997559
Validation loss: 2.25840816895167

Epoch: 6| Step: 9
Training loss: 1.6470158100128174
Validation loss: 2.2794860204060874

Epoch: 6| Step: 10
Training loss: 1.5029323101043701
Validation loss: 2.246287186940511

Epoch: 6| Step: 11
Training loss: 1.8520668745040894
Validation loss: 2.240478277206421

Epoch: 6| Step: 12
Training loss: 1.7369654178619385
Validation loss: 2.2323572635650635

Epoch: 6| Step: 13
Training loss: 1.2582178115844727
Validation loss: 2.2320843935012817

Epoch: 257| Step: 0
Training loss: 1.0531697273254395
Validation loss: 2.1999635100364685

Epoch: 6| Step: 1
Training loss: 1.422534704208374
Validation loss: 2.2151238123575845

Epoch: 6| Step: 2
Training loss: 1.2566380500793457
Validation loss: 2.195528586705526

Epoch: 6| Step: 3
Training loss: 1.2172677516937256
Validation loss: 2.2280952533086142

Epoch: 6| Step: 4
Training loss: 1.1754982471466064
Validation loss: 2.218323806921641

Epoch: 6| Step: 5
Training loss: 1.5037223100662231
Validation loss: 2.221773624420166

Epoch: 6| Step: 6
Training loss: 2.0670218467712402
Validation loss: 2.21228019396464

Epoch: 6| Step: 7
Training loss: 1.713508129119873
Validation loss: 2.200684110323588

Epoch: 6| Step: 8
Training loss: 1.2162410020828247
Validation loss: 2.203524728616079

Epoch: 6| Step: 9
Training loss: 2.7019095420837402
Validation loss: 2.195668896039327

Epoch: 6| Step: 10
Training loss: 2.451097011566162
Validation loss: 2.2198315064112344

Epoch: 6| Step: 11
Training loss: 1.4170783758163452
Validation loss: 2.200398842493693

Epoch: 6| Step: 12
Training loss: 1.1588561534881592
Validation loss: 2.240277429421743

Epoch: 6| Step: 13
Training loss: 1.5053660869598389
Validation loss: 2.2281799713770547

Epoch: 258| Step: 0
Training loss: 1.1052565574645996
Validation loss: 2.219960709412893

Epoch: 6| Step: 1
Training loss: 2.071227550506592
Validation loss: 2.2294809818267822

Epoch: 6| Step: 2
Training loss: 1.670295238494873
Validation loss: 2.2052691181500754

Epoch: 6| Step: 3
Training loss: 1.2408454418182373
Validation loss: 2.2647976875305176

Epoch: 6| Step: 4
Training loss: 1.2292159795761108
Validation loss: 2.235751529534658

Epoch: 6| Step: 5
Training loss: 1.8449821472167969
Validation loss: 2.261967182159424

Epoch: 6| Step: 6
Training loss: 1.1460494995117188
Validation loss: 2.2353363037109375

Epoch: 6| Step: 7
Training loss: 1.3937844038009644
Validation loss: 2.225223501523336

Epoch: 6| Step: 8
Training loss: 1.0227330923080444
Validation loss: 2.2335883378982544

Epoch: 6| Step: 9
Training loss: 1.6475181579589844
Validation loss: 2.2468354900678

Epoch: 6| Step: 10
Training loss: 2.0337436199188232
Validation loss: 2.2447668512662253

Epoch: 6| Step: 11
Training loss: 1.1775718927383423
Validation loss: 2.2512797514597573

Epoch: 6| Step: 12
Training loss: 2.1199073791503906
Validation loss: 2.2357759873072305

Epoch: 6| Step: 13
Training loss: 2.130126953125
Validation loss: 2.2509886225064597

Epoch: 259| Step: 0
Training loss: 1.5941975116729736
Validation loss: 2.2467769781748452

Epoch: 6| Step: 1
Training loss: 1.3699455261230469
Validation loss: 2.227755606174469

Epoch: 6| Step: 2
Training loss: 1.0510108470916748
Validation loss: 2.2514869372049966

Epoch: 6| Step: 3
Training loss: 1.1228954792022705
Validation loss: 2.2629084984461465

Epoch: 6| Step: 4
Training loss: 1.3488942384719849
Validation loss: 2.2758443355560303

Epoch: 6| Step: 5
Training loss: 1.652730941772461
Validation loss: 2.2652923266092935

Epoch: 6| Step: 6
Training loss: 1.4507349729537964
Validation loss: 2.246274252732595

Epoch: 6| Step: 7
Training loss: 1.5283734798431396
Validation loss: 2.2385956247647605

Epoch: 6| Step: 8
Training loss: 1.5361652374267578
Validation loss: 2.253576397895813

Epoch: 6| Step: 9
Training loss: 2.41672682762146
Validation loss: 2.2666770021120706

Epoch: 6| Step: 10
Training loss: 0.9092510938644409
Validation loss: 2.2439205249150596

Epoch: 6| Step: 11
Training loss: 1.4912714958190918
Validation loss: 2.2160850763320923

Epoch: 6| Step: 12
Training loss: 1.4256173372268677
Validation loss: 2.2184784213701882

Epoch: 6| Step: 13
Training loss: 2.034792423248291
Validation loss: 2.205343246459961

Epoch: 260| Step: 0
Training loss: 1.8802173137664795
Validation loss: 2.230654001235962

Epoch: 6| Step: 1
Training loss: 1.616786003112793
Validation loss: 2.2306070725123086

Epoch: 6| Step: 2
Training loss: 2.2518153190612793
Validation loss: 2.211331864198049

Epoch: 6| Step: 3
Training loss: 1.126914620399475
Validation loss: 2.2414966225624084

Epoch: 6| Step: 4
Training loss: 1.1629464626312256
Validation loss: 2.2495044668515525

Epoch: 6| Step: 5
Training loss: 1.5348033905029297
Validation loss: 2.2325875759124756

Epoch: 6| Step: 6
Training loss: 2.304656744003296
Validation loss: 2.207467238108317

Epoch: 6| Step: 7
Training loss: 1.1240952014923096
Validation loss: 2.1979187726974487

Epoch: 6| Step: 8
Training loss: 2.3178842067718506
Validation loss: 2.2048316995302835

Epoch: 6| Step: 9
Training loss: 0.9960514307022095
Validation loss: 2.1992658376693726

Epoch: 6| Step: 10
Training loss: 2.183333396911621
Validation loss: 2.188515623410543

Epoch: 6| Step: 11
Training loss: 0.6808057427406311
Validation loss: 2.195767641067505

Epoch: 6| Step: 12
Training loss: 1.0518362522125244
Validation loss: 2.197416841983795

Epoch: 6| Step: 13
Training loss: 1.463571548461914
Validation loss: 2.1867653926213584

Epoch: 261| Step: 0
Training loss: 1.955335259437561
Validation loss: 2.216544210910797

Epoch: 6| Step: 1
Training loss: 2.096320629119873
Validation loss: 2.22607284784317

Epoch: 6| Step: 2
Training loss: 1.403597116470337
Validation loss: 2.2232162952423096

Epoch: 6| Step: 3
Training loss: 1.27437162399292
Validation loss: 2.2302792072296143

Epoch: 6| Step: 4
Training loss: 1.6417433023452759
Validation loss: 2.255675653616587

Epoch: 6| Step: 5
Training loss: 0.827546238899231
Validation loss: 2.2780521710713706

Epoch: 6| Step: 6
Training loss: 0.8950225710868835
Validation loss: 2.2618865966796875

Epoch: 6| Step: 7
Training loss: 2.072788715362549
Validation loss: 2.2807507316271463

Epoch: 6| Step: 8
Training loss: 1.6322412490844727
Validation loss: 2.2490002512931824

Epoch: 6| Step: 9
Training loss: 1.0063066482543945
Validation loss: 2.235814690589905

Epoch: 6| Step: 10
Training loss: 1.5689035654067993
Validation loss: 2.2050559719403586

Epoch: 6| Step: 11
Training loss: 1.6077730655670166
Validation loss: 2.2317761977513633

Epoch: 6| Step: 12
Training loss: 1.6182609796524048
Validation loss: 2.239314059416453

Epoch: 6| Step: 13
Training loss: 1.2349821329116821
Validation loss: 2.2573920488357544

Epoch: 262| Step: 0
Training loss: 1.7900385856628418
Validation loss: 2.231309692064921

Epoch: 6| Step: 1
Training loss: 2.486422538757324
Validation loss: 2.2210028966267905

Epoch: 6| Step: 2
Training loss: 1.297208309173584
Validation loss: 2.224279761314392

Epoch: 6| Step: 3
Training loss: 1.546037197113037
Validation loss: 2.2314019401868186

Epoch: 6| Step: 4
Training loss: 1.3415764570236206
Validation loss: 2.2323118249575296

Epoch: 6| Step: 5
Training loss: 1.4928025007247925
Validation loss: 2.231217940648397

Epoch: 6| Step: 6
Training loss: 1.9661071300506592
Validation loss: 2.22199555238088

Epoch: 6| Step: 7
Training loss: 1.0497088432312012
Validation loss: 2.2395183444023132

Epoch: 6| Step: 8
Training loss: 1.2896831035614014
Validation loss: 2.219097991784414

Epoch: 6| Step: 9
Training loss: 1.3211324214935303
Validation loss: 2.2433162331581116

Epoch: 6| Step: 10
Training loss: 0.985388994216919
Validation loss: 2.264454742272695

Epoch: 6| Step: 11
Training loss: 1.5791932344436646
Validation loss: 2.2143298983573914

Epoch: 6| Step: 12
Training loss: 1.5397064685821533
Validation loss: 2.240811268488566

Epoch: 6| Step: 13
Training loss: 1.5652084350585938
Validation loss: 2.239609738190969

Epoch: 263| Step: 0
Training loss: 0.7923623919487
Validation loss: 2.2466435035069785

Epoch: 6| Step: 1
Training loss: 1.169773817062378
Validation loss: 2.2433265447616577

Epoch: 6| Step: 2
Training loss: 1.4242359399795532
Validation loss: 2.225348432858785

Epoch: 6| Step: 3
Training loss: 1.2873390913009644
Validation loss: 2.2208301623662314

Epoch: 6| Step: 4
Training loss: 1.2369096279144287
Validation loss: 2.2084439992904663

Epoch: 6| Step: 5
Training loss: 1.8396635055541992
Validation loss: 2.213368058204651

Epoch: 6| Step: 6
Training loss: 1.4981935024261475
Validation loss: 2.218321760495504

Epoch: 6| Step: 7
Training loss: 1.7757762670516968
Validation loss: 2.2168506582578025

Epoch: 6| Step: 8
Training loss: 1.4272031784057617
Validation loss: 2.2109113136927285

Epoch: 6| Step: 9
Training loss: 1.2627702951431274
Validation loss: 2.229295233885447

Epoch: 6| Step: 10
Training loss: 2.0952863693237305
Validation loss: 2.2042747735977173

Epoch: 6| Step: 11
Training loss: 1.211366057395935
Validation loss: 2.242555340131124

Epoch: 6| Step: 12
Training loss: 2.1704049110412598
Validation loss: 2.267099936803182

Epoch: 6| Step: 13
Training loss: 1.5704138278961182
Validation loss: 2.262786348660787

Epoch: 264| Step: 0
Training loss: 1.3356907367706299
Validation loss: 2.2480910420417786

Epoch: 6| Step: 1
Training loss: 1.561445713043213
Validation loss: 2.237845857938131

Epoch: 6| Step: 2
Training loss: 1.2356033325195312
Validation loss: 2.2298523585001626

Epoch: 6| Step: 3
Training loss: 1.8028959035873413
Validation loss: 2.2347715894381204

Epoch: 6| Step: 4
Training loss: 1.294701099395752
Validation loss: 2.2260462840398154

Epoch: 6| Step: 5
Training loss: 1.4841704368591309
Validation loss: 2.2051252921422324

Epoch: 6| Step: 6
Training loss: 1.6400337219238281
Validation loss: 2.2168490886688232

Epoch: 6| Step: 7
Training loss: 0.9796770811080933
Validation loss: 2.1857502261797586

Epoch: 6| Step: 8
Training loss: 2.0492124557495117
Validation loss: 2.2155574361483255

Epoch: 6| Step: 9
Training loss: 1.7132036685943604
Validation loss: 2.2130658626556396

Epoch: 6| Step: 10
Training loss: 1.2321449518203735
Validation loss: 2.2387475768725076

Epoch: 6| Step: 11
Training loss: 1.8113954067230225
Validation loss: 2.2232505679130554

Epoch: 6| Step: 12
Training loss: 1.5059478282928467
Validation loss: 2.1854425271352134

Epoch: 6| Step: 13
Training loss: 1.4949122667312622
Validation loss: 2.2136290272076926

Epoch: 265| Step: 0
Training loss: 1.7244819402694702
Validation loss: 2.199653744697571

Epoch: 6| Step: 1
Training loss: 1.4929296970367432
Validation loss: 2.1785419384638467

Epoch: 6| Step: 2
Training loss: 1.0019495487213135
Validation loss: 2.177013556162516

Epoch: 6| Step: 3
Training loss: 1.5800321102142334
Validation loss: 2.248864452044169

Epoch: 6| Step: 4
Training loss: 1.500760793685913
Validation loss: 2.2211671272913613

Epoch: 6| Step: 5
Training loss: 1.4154168367385864
Validation loss: 2.225510319073995

Epoch: 6| Step: 6
Training loss: 1.5368653535842896
Validation loss: 2.2098538875579834

Epoch: 6| Step: 7
Training loss: 2.2000298500061035
Validation loss: 2.214927931626638

Epoch: 6| Step: 8
Training loss: 1.4863924980163574
Validation loss: 2.2165157794952393

Epoch: 6| Step: 9
Training loss: 1.7877665758132935
Validation loss: 2.225640813509623

Epoch: 6| Step: 10
Training loss: 1.5163185596466064
Validation loss: 2.2480969031651816

Epoch: 6| Step: 11
Training loss: 1.015386700630188
Validation loss: 2.2289859851201377

Epoch: 6| Step: 12
Training loss: 1.1459619998931885
Validation loss: 2.1980746189753213

Epoch: 6| Step: 13
Training loss: 1.5869381427764893
Validation loss: 2.2406561175982156

Epoch: 266| Step: 0
Training loss: 2.4107277393341064
Validation loss: 2.2384459177652993

Epoch: 6| Step: 1
Training loss: 1.4874117374420166
Validation loss: 2.2691356937090554

Epoch: 6| Step: 2
Training loss: 1.9368126392364502
Validation loss: 2.3273576498031616

Epoch: 6| Step: 3
Training loss: 1.6555031538009644
Validation loss: 2.286565442879995

Epoch: 6| Step: 4
Training loss: 1.5885125398635864
Validation loss: 2.3178880413373313

Epoch: 6| Step: 5
Training loss: 1.3799062967300415
Validation loss: 2.2647282083829245

Epoch: 6| Step: 6
Training loss: 1.9594299793243408
Validation loss: 2.2577208081881204

Epoch: 6| Step: 7
Training loss: 1.0095365047454834
Validation loss: 2.2329018910725913

Epoch: 6| Step: 8
Training loss: 1.5564281940460205
Validation loss: 2.2207778294881186

Epoch: 6| Step: 9
Training loss: 0.9533308148384094
Validation loss: 2.211731712023417

Epoch: 6| Step: 10
Training loss: 1.556356430053711
Validation loss: 2.205606778462728

Epoch: 6| Step: 11
Training loss: 1.5086922645568848
Validation loss: 2.1775752902030945

Epoch: 6| Step: 12
Training loss: 1.51707124710083
Validation loss: 2.165211101373037

Epoch: 6| Step: 13
Training loss: 1.3945242166519165
Validation loss: 2.2091712752978006

Epoch: 267| Step: 0
Training loss: 1.4313676357269287
Validation loss: 2.20627631743749

Epoch: 6| Step: 1
Training loss: 2.247931718826294
Validation loss: 2.207536240418752

Epoch: 6| Step: 2
Training loss: 1.2454299926757812
Validation loss: 2.2034281293551126

Epoch: 6| Step: 3
Training loss: 1.8242310285568237
Validation loss: 2.2478808164596558

Epoch: 6| Step: 4
Training loss: 1.3465402126312256
Validation loss: 2.2015168269475303

Epoch: 6| Step: 5
Training loss: 1.5371010303497314
Validation loss: 2.1970682938893638

Epoch: 6| Step: 6
Training loss: 1.2444443702697754
Validation loss: 2.2111751635869346

Epoch: 6| Step: 7
Training loss: 1.0799915790557861
Validation loss: 2.193543493747711

Epoch: 6| Step: 8
Training loss: 1.7025651931762695
Validation loss: 2.1879530350367227

Epoch: 6| Step: 9
Training loss: 1.5385446548461914
Validation loss: 2.2081449826558432

Epoch: 6| Step: 10
Training loss: 1.2775124311447144
Validation loss: 2.201880176862081

Epoch: 6| Step: 11
Training loss: 0.8881198763847351
Validation loss: 2.2043415904045105

Epoch: 6| Step: 12
Training loss: 1.136648416519165
Validation loss: 2.246613879998525

Epoch: 6| Step: 13
Training loss: 2.203695774078369
Validation loss: 2.254327098528544

Epoch: 268| Step: 0
Training loss: 1.2470778226852417
Validation loss: 2.230606516202291

Epoch: 6| Step: 1
Training loss: 1.3410208225250244
Validation loss: 2.223581294218699

Epoch: 6| Step: 2
Training loss: 1.898807406425476
Validation loss: 2.240406811237335

Epoch: 6| Step: 3
Training loss: 1.485140323638916
Validation loss: 2.218400518099467

Epoch: 6| Step: 4
Training loss: 1.1744232177734375
Validation loss: 2.2560526529947915

Epoch: 6| Step: 5
Training loss: 0.9998795986175537
Validation loss: 2.2782686154047647

Epoch: 6| Step: 6
Training loss: 2.514309883117676
Validation loss: 2.240666707356771

Epoch: 6| Step: 7
Training loss: 1.387979507446289
Validation loss: 2.2517639795939126

Epoch: 6| Step: 8
Training loss: 1.2373690605163574
Validation loss: 2.265098512172699

Epoch: 6| Step: 9
Training loss: 1.5921180248260498
Validation loss: 2.2487202088038125

Epoch: 6| Step: 10
Training loss: 1.5960332155227661
Validation loss: 2.2314122120539346

Epoch: 6| Step: 11
Training loss: 1.70124351978302
Validation loss: 2.2096301714579263

Epoch: 6| Step: 12
Training loss: 1.3916261196136475
Validation loss: 2.213875333468119

Epoch: 6| Step: 13
Training loss: 0.9533770680427551
Validation loss: 2.2028690775235495

Epoch: 269| Step: 0
Training loss: 1.5320770740509033
Validation loss: 2.2373872796694436

Epoch: 6| Step: 1
Training loss: 1.6814863681793213
Validation loss: 2.224111537138621

Epoch: 6| Step: 2
Training loss: 1.265973448753357
Validation loss: 2.2089735666910806

Epoch: 6| Step: 3
Training loss: 1.064272403717041
Validation loss: 2.225003639856974

Epoch: 6| Step: 4
Training loss: 1.5625559091567993
Validation loss: 2.2454251050949097

Epoch: 6| Step: 5
Training loss: 0.8764851093292236
Validation loss: 2.233468234539032

Epoch: 6| Step: 6
Training loss: 1.2882139682769775
Validation loss: 2.2243921955426535

Epoch: 6| Step: 7
Training loss: 1.8945534229278564
Validation loss: 2.224117120107015

Epoch: 6| Step: 8
Training loss: 1.3997299671173096
Validation loss: 2.258833090464274

Epoch: 6| Step: 9
Training loss: 2.4034416675567627
Validation loss: 2.2149338126182556

Epoch: 6| Step: 10
Training loss: 1.2182989120483398
Validation loss: 2.2372666200002036

Epoch: 6| Step: 11
Training loss: 1.4875494241714478
Validation loss: 2.2306460539499917

Epoch: 6| Step: 12
Training loss: 1.4288063049316406
Validation loss: 2.2515581448872886

Epoch: 6| Step: 13
Training loss: 1.6094472408294678
Validation loss: 2.2429891228675842

Epoch: 270| Step: 0
Training loss: 1.4322067499160767
Validation loss: 2.2388484279314675

Epoch: 6| Step: 1
Training loss: 1.7810909748077393
Validation loss: 2.214275856812795

Epoch: 6| Step: 2
Training loss: 1.310624361038208
Validation loss: 2.2115355928738913

Epoch: 6| Step: 3
Training loss: 1.2465527057647705
Validation loss: 2.2026154200236

Epoch: 6| Step: 4
Training loss: 2.078253746032715
Validation loss: 2.228419542312622

Epoch: 6| Step: 5
Training loss: 1.5263123512268066
Validation loss: 2.2011295755704245

Epoch: 6| Step: 6
Training loss: 1.3039469718933105
Validation loss: 2.220000942548116

Epoch: 6| Step: 7
Training loss: 1.1828957796096802
Validation loss: 2.2339277267456055

Epoch: 6| Step: 8
Training loss: 1.4919016361236572
Validation loss: 2.2260217666625977

Epoch: 6| Step: 9
Training loss: 1.513380527496338
Validation loss: 2.2198747595151267

Epoch: 6| Step: 10
Training loss: 1.209220051765442
Validation loss: 2.203276574611664

Epoch: 6| Step: 11
Training loss: 1.3125430345535278
Validation loss: 2.1801971991856894

Epoch: 6| Step: 12
Training loss: 1.9759173393249512
Validation loss: 2.2276561657587686

Epoch: 6| Step: 13
Training loss: 1.0740861892700195
Validation loss: 2.2330664793650308

Epoch: 271| Step: 0
Training loss: 1.1474395990371704
Validation loss: 2.197912077109019

Epoch: 6| Step: 1
Training loss: 1.3763415813446045
Validation loss: 2.2266421914100647

Epoch: 6| Step: 2
Training loss: 1.0103650093078613
Validation loss: 2.2128438552220664

Epoch: 6| Step: 3
Training loss: 1.5128697156906128
Validation loss: 2.187187989552816

Epoch: 6| Step: 4
Training loss: 1.5250298976898193
Validation loss: 2.207840085029602

Epoch: 6| Step: 5
Training loss: 1.4883164167404175
Validation loss: 2.222065250078837

Epoch: 6| Step: 6
Training loss: 1.3503479957580566
Validation loss: 2.231742799282074

Epoch: 6| Step: 7
Training loss: 1.2389397621154785
Validation loss: 2.225718319416046

Epoch: 6| Step: 8
Training loss: 1.5162739753723145
Validation loss: 2.2102282842000327

Epoch: 6| Step: 9
Training loss: 1.5443106889724731
Validation loss: 2.191013216972351

Epoch: 6| Step: 10
Training loss: 1.3375458717346191
Validation loss: 2.1982339223225913

Epoch: 6| Step: 11
Training loss: 1.3292595148086548
Validation loss: 2.2263315518697104

Epoch: 6| Step: 12
Training loss: 2.167764186859131
Validation loss: 2.2578711112340293

Epoch: 6| Step: 13
Training loss: 1.8816072940826416
Validation loss: 2.228469888369242

Epoch: 272| Step: 0
Training loss: 0.9910362362861633
Validation loss: 2.2462485233942666

Epoch: 6| Step: 1
Training loss: 2.1742730140686035
Validation loss: 2.248250404993693

Epoch: 6| Step: 2
Training loss: 1.649251937866211
Validation loss: 2.2725865244865417

Epoch: 6| Step: 3
Training loss: 1.4543930292129517
Validation loss: 2.2381327946980796

Epoch: 6| Step: 4
Training loss: 1.5889447927474976
Validation loss: 2.2497524420420327

Epoch: 6| Step: 5
Training loss: 1.432081937789917
Validation loss: 2.2098012566566467

Epoch: 6| Step: 6
Training loss: 1.2632381916046143
Validation loss: 2.25084255139033

Epoch: 6| Step: 7
Training loss: 1.7219862937927246
Validation loss: 2.261411984761556

Epoch: 6| Step: 8
Training loss: 1.4079598188400269
Validation loss: 2.2482756773630777

Epoch: 6| Step: 9
Training loss: 1.5175065994262695
Validation loss: 2.317293624083201

Epoch: 6| Step: 10
Training loss: 1.5943615436553955
Validation loss: 2.2715020179748535

Epoch: 6| Step: 11
Training loss: 1.6227830648422241
Validation loss: 2.2626893122990928

Epoch: 6| Step: 12
Training loss: 1.7153337001800537
Validation loss: 2.2587481141090393

Epoch: 6| Step: 13
Training loss: 1.6928110122680664
Validation loss: 2.2667289773623147

Epoch: 273| Step: 0
Training loss: 0.7171400785446167
Validation loss: 2.2439106702804565

Epoch: 6| Step: 1
Training loss: 0.8527817726135254
Validation loss: 2.264241337776184

Epoch: 6| Step: 2
Training loss: 1.307120680809021
Validation loss: 2.2789554595947266

Epoch: 6| Step: 3
Training loss: 1.6914403438568115
Validation loss: 2.2433438897132874

Epoch: 6| Step: 4
Training loss: 1.759537935256958
Validation loss: 2.243877391020457

Epoch: 6| Step: 5
Training loss: 1.808091402053833
Validation loss: 2.2276062965393066

Epoch: 6| Step: 6
Training loss: 1.9253380298614502
Validation loss: 2.2303820649782815

Epoch: 6| Step: 7
Training loss: 1.3159854412078857
Validation loss: 2.246209144592285

Epoch: 6| Step: 8
Training loss: 1.5856249332427979
Validation loss: 2.1746708353360495

Epoch: 6| Step: 9
Training loss: 1.4365640878677368
Validation loss: 2.219636102517446

Epoch: 6| Step: 10
Training loss: 1.7907108068466187
Validation loss: 2.2266890009244285

Epoch: 6| Step: 11
Training loss: 0.7346578240394592
Validation loss: 2.229488174120585

Epoch: 6| Step: 12
Training loss: 1.2870874404907227
Validation loss: 2.224879880746206

Epoch: 6| Step: 13
Training loss: 1.5953220129013062
Validation loss: 2.2384101947148642

Epoch: 274| Step: 0
Training loss: 1.0751538276672363
Validation loss: 2.2226595481236777

Epoch: 6| Step: 1
Training loss: 1.9764739274978638
Validation loss: 2.2224730849266052

Epoch: 6| Step: 2
Training loss: 1.8325304985046387
Validation loss: 2.2241963942845664

Epoch: 6| Step: 3
Training loss: 1.533168077468872
Validation loss: 2.2440765301386514

Epoch: 6| Step: 4
Training loss: 0.8677791357040405
Validation loss: 2.245838721593221

Epoch: 6| Step: 5
Training loss: 1.327645182609558
Validation loss: 2.2622629006703696

Epoch: 6| Step: 6
Training loss: 0.5792518854141235
Validation loss: 2.232374370098114

Epoch: 6| Step: 7
Training loss: 1.1235326528549194
Validation loss: 2.235413988431295

Epoch: 6| Step: 8
Training loss: 1.4439300298690796
Validation loss: 2.262619912624359

Epoch: 6| Step: 9
Training loss: 1.5202434062957764
Validation loss: 2.224989195664724

Epoch: 6| Step: 10
Training loss: 1.8297913074493408
Validation loss: 2.2514538168907166

Epoch: 6| Step: 11
Training loss: 1.7398364543914795
Validation loss: 2.197329342365265

Epoch: 6| Step: 12
Training loss: 1.4144985675811768
Validation loss: 2.2414621313412986

Epoch: 6| Step: 13
Training loss: 1.3513078689575195
Validation loss: 2.216589629650116

Epoch: 275| Step: 0
Training loss: 1.107238531112671
Validation loss: 2.20573620001475

Epoch: 6| Step: 1
Training loss: 1.3193798065185547
Validation loss: 2.222204864025116

Epoch: 6| Step: 2
Training loss: 1.9714818000793457
Validation loss: 2.2638381123542786

Epoch: 6| Step: 3
Training loss: 1.403977394104004
Validation loss: 2.2402799924214682

Epoch: 6| Step: 4
Training loss: 1.127551555633545
Validation loss: 2.2709429462750754

Epoch: 6| Step: 5
Training loss: 1.6718186140060425
Validation loss: 2.233737329641978

Epoch: 6| Step: 6
Training loss: 1.2094229459762573
Validation loss: 2.223568916320801

Epoch: 6| Step: 7
Training loss: 1.2989338636398315
Validation loss: 2.236076911290487

Epoch: 6| Step: 8
Training loss: 0.9620175361633301
Validation loss: 2.20539383093516

Epoch: 6| Step: 9
Training loss: 1.6347110271453857
Validation loss: 2.240670104821523

Epoch: 6| Step: 10
Training loss: 2.0601999759674072
Validation loss: 2.232001304626465

Epoch: 6| Step: 11
Training loss: 1.1310449838638306
Validation loss: 2.216354409853617

Epoch: 6| Step: 12
Training loss: 1.2035601139068604
Validation loss: 2.2150341272354126

Epoch: 6| Step: 13
Training loss: 2.0522537231445312
Validation loss: 2.2064157724380493

Epoch: 276| Step: 0
Training loss: 1.7987662553787231
Validation loss: 2.2262733379999795

Epoch: 6| Step: 1
Training loss: 1.5952327251434326
Validation loss: 2.234476168950399

Epoch: 6| Step: 2
Training loss: 1.6039366722106934
Validation loss: 2.243718465169271

Epoch: 6| Step: 3
Training loss: 1.4431664943695068
Validation loss: 2.1772202253341675

Epoch: 6| Step: 4
Training loss: 1.8607622385025024
Validation loss: 2.1803136467933655

Epoch: 6| Step: 5
Training loss: 1.250135898590088
Validation loss: 2.2072497606277466

Epoch: 6| Step: 6
Training loss: 1.0759379863739014
Validation loss: 2.16634202003479

Epoch: 6| Step: 7
Training loss: 1.3663712739944458
Validation loss: 2.1738126277923584

Epoch: 6| Step: 8
Training loss: 1.616053819656372
Validation loss: 2.190446754296621

Epoch: 6| Step: 9
Training loss: 1.2026197910308838
Validation loss: 2.1889808177948

Epoch: 6| Step: 10
Training loss: 1.3420207500457764
Validation loss: 2.178015410900116

Epoch: 6| Step: 11
Training loss: 1.142111897468567
Validation loss: 2.179910679658254

Epoch: 6| Step: 12
Training loss: 1.0818305015563965
Validation loss: 2.2087220748265586

Epoch: 6| Step: 13
Training loss: 1.5734044313430786
Validation loss: 2.20453413327535

Epoch: 277| Step: 0
Training loss: 1.1667581796646118
Validation loss: 2.212344308694204

Epoch: 6| Step: 1
Training loss: 2.010829448699951
Validation loss: 2.1941212018330893

Epoch: 6| Step: 2
Training loss: 1.0258162021636963
Validation loss: 2.2209513982137046

Epoch: 6| Step: 3
Training loss: 0.880671501159668
Validation loss: 2.22217849890391

Epoch: 6| Step: 4
Training loss: 1.0712755918502808
Validation loss: 2.2298662463823953

Epoch: 6| Step: 5
Training loss: 1.7369754314422607
Validation loss: 2.2264787952105203

Epoch: 6| Step: 6
Training loss: 1.0394840240478516
Validation loss: 2.2171355883280435

Epoch: 6| Step: 7
Training loss: 1.4753100872039795
Validation loss: 2.268385887145996

Epoch: 6| Step: 8
Training loss: 1.018972396850586
Validation loss: 2.2656140526135764

Epoch: 6| Step: 9
Training loss: 1.3432202339172363
Validation loss: 2.2678189675013223

Epoch: 6| Step: 10
Training loss: 2.0425026416778564
Validation loss: 2.238926569620768

Epoch: 6| Step: 11
Training loss: 1.2238470315933228
Validation loss: 2.243298431237539

Epoch: 6| Step: 12
Training loss: 1.9505107402801514
Validation loss: 2.1932952602704368

Epoch: 6| Step: 13
Training loss: 1.316367268562317
Validation loss: 2.205609222253164

Epoch: 278| Step: 0
Training loss: 1.2381560802459717
Validation loss: 2.193148612976074

Epoch: 6| Step: 1
Training loss: 1.0578230619430542
Validation loss: 2.2265607913335166

Epoch: 6| Step: 2
Training loss: 1.9907704591751099
Validation loss: 2.218553105990092

Epoch: 6| Step: 3
Training loss: 1.9249920845031738
Validation loss: 2.2087801496187844

Epoch: 6| Step: 4
Training loss: 1.4941695928573608
Validation loss: 2.211939056714376

Epoch: 6| Step: 5
Training loss: 0.7768568396568298
Validation loss: 2.199754059314728

Epoch: 6| Step: 6
Training loss: 1.1922584772109985
Validation loss: 2.2281812032063804

Epoch: 6| Step: 7
Training loss: 1.5075708627700806
Validation loss: 2.2488354245821633

Epoch: 6| Step: 8
Training loss: 1.3222475051879883
Validation loss: 2.216639836629232

Epoch: 6| Step: 9
Training loss: 1.163881540298462
Validation loss: 2.213162362575531

Epoch: 6| Step: 10
Training loss: 1.714394450187683
Validation loss: 2.2413259943326316

Epoch: 6| Step: 11
Training loss: 1.1136603355407715
Validation loss: 2.2064751784006753

Epoch: 6| Step: 12
Training loss: 1.4289207458496094
Validation loss: 2.213102142016093

Epoch: 6| Step: 13
Training loss: 1.2399306297302246
Validation loss: 2.209200700124105

Epoch: 279| Step: 0
Training loss: 1.4847540855407715
Validation loss: 2.2529643177986145

Epoch: 6| Step: 1
Training loss: 0.9464900493621826
Validation loss: 2.195774018764496

Epoch: 6| Step: 2
Training loss: 1.1743119955062866
Validation loss: 2.208301822344462

Epoch: 6| Step: 3
Training loss: 1.6672730445861816
Validation loss: 2.247867544492086

Epoch: 6| Step: 4
Training loss: 1.2526594400405884
Validation loss: 2.2362098693847656

Epoch: 6| Step: 5
Training loss: 1.3747241497039795
Validation loss: 2.247193197409312

Epoch: 6| Step: 6
Training loss: 1.6354386806488037
Validation loss: 2.2495153347651162

Epoch: 6| Step: 7
Training loss: 1.6007683277130127
Validation loss: 2.2539906899134317

Epoch: 6| Step: 8
Training loss: 1.687348484992981
Validation loss: 2.2662100394566855

Epoch: 6| Step: 9
Training loss: 1.5605509281158447
Validation loss: 2.2582419713338218

Epoch: 6| Step: 10
Training loss: 1.3471390008926392
Validation loss: 2.2612138390541077

Epoch: 6| Step: 11
Training loss: 0.8093997240066528
Validation loss: 2.25044322013855

Epoch: 6| Step: 12
Training loss: 1.2978569269180298
Validation loss: 2.249172031879425

Epoch: 6| Step: 13
Training loss: 1.3060506582260132
Validation loss: 2.276314596335093

Epoch: 280| Step: 0
Training loss: 1.638818621635437
Validation loss: 2.241493026415507

Epoch: 6| Step: 1
Training loss: 1.4590351581573486
Validation loss: 2.238685429096222

Epoch: 6| Step: 2
Training loss: 1.4652067422866821
Validation loss: 2.2324363390604653

Epoch: 6| Step: 3
Training loss: 1.3982422351837158
Validation loss: 2.270918528238932

Epoch: 6| Step: 4
Training loss: 1.2680950164794922
Validation loss: 2.2541611194610596

Epoch: 6| Step: 5
Training loss: 1.2734577655792236
Validation loss: 2.222853163878123

Epoch: 6| Step: 6
Training loss: 0.7835903167724609
Validation loss: 2.2592151959737143

Epoch: 6| Step: 7
Training loss: 1.8323390483856201
Validation loss: 2.270021835962931

Epoch: 6| Step: 8
Training loss: 1.1937531232833862
Validation loss: 2.2754744489987693

Epoch: 6| Step: 9
Training loss: 2.2660059928894043
Validation loss: 2.2529154618581138

Epoch: 6| Step: 10
Training loss: 0.835576057434082
Validation loss: 2.2341495354970298

Epoch: 6| Step: 11
Training loss: 1.3277761936187744
Validation loss: 2.2385398348172507

Epoch: 6| Step: 12
Training loss: 1.1079872846603394
Validation loss: 2.224160154660543

Epoch: 6| Step: 13
Training loss: 1.2182079553604126
Validation loss: 2.2142847975095115

Epoch: 281| Step: 0
Training loss: 1.6727087497711182
Validation loss: 2.2184741695721946

Epoch: 6| Step: 1
Training loss: 1.3019534349441528
Validation loss: 2.229275902112325

Epoch: 6| Step: 2
Training loss: 1.982885479927063
Validation loss: 2.2533684174219766

Epoch: 6| Step: 3
Training loss: 1.504062533378601
Validation loss: 2.2501599192619324

Epoch: 6| Step: 4
Training loss: 1.1638840436935425
Validation loss: 2.237004061539968

Epoch: 6| Step: 5
Training loss: 1.7183693647384644
Validation loss: 2.2377309600512185

Epoch: 6| Step: 6
Training loss: 2.250321626663208
Validation loss: 2.2128279209136963

Epoch: 6| Step: 7
Training loss: 1.4012706279754639
Validation loss: 2.184901495774587

Epoch: 6| Step: 8
Training loss: 1.1692231893539429
Validation loss: 2.2056466142336526

Epoch: 6| Step: 9
Training loss: 1.2517085075378418
Validation loss: 2.210137903690338

Epoch: 6| Step: 10
Training loss: 1.0432605743408203
Validation loss: 2.2160877188046775

Epoch: 6| Step: 11
Training loss: 1.2742938995361328
Validation loss: 2.228807508945465

Epoch: 6| Step: 12
Training loss: 1.1549108028411865
Validation loss: 2.2365944385528564

Epoch: 6| Step: 13
Training loss: 1.2079308032989502
Validation loss: 2.2618199586868286

Epoch: 282| Step: 0
Training loss: 1.9494003057479858
Validation loss: 2.23790180683136

Epoch: 6| Step: 1
Training loss: 1.1368048191070557
Validation loss: 2.234671692053477

Epoch: 6| Step: 2
Training loss: 1.0622913837432861
Validation loss: 2.224891463915507

Epoch: 6| Step: 3
Training loss: 2.35541033744812
Validation loss: 2.2198484341303506

Epoch: 6| Step: 4
Training loss: 2.026726245880127
Validation loss: 2.180944542090098

Epoch: 6| Step: 5
Training loss: 0.8821629285812378
Validation loss: 2.1854036847750344

Epoch: 6| Step: 6
Training loss: 1.2006864547729492
Validation loss: 2.2251009543736777

Epoch: 6| Step: 7
Training loss: 1.340402364730835
Validation loss: 2.200284500916799

Epoch: 6| Step: 8
Training loss: 1.716264247894287
Validation loss: 2.185026466846466

Epoch: 6| Step: 9
Training loss: 1.311835527420044
Validation loss: 2.2097533146540322

Epoch: 6| Step: 10
Training loss: 0.8663602471351624
Validation loss: 2.1977286537488303

Epoch: 6| Step: 11
Training loss: 1.4089722633361816
Validation loss: 2.245857894420624

Epoch: 6| Step: 12
Training loss: 1.3793708086013794
Validation loss: 2.1961576541264853

Epoch: 6| Step: 13
Training loss: 0.9709306955337524
Validation loss: 2.2312474250793457

Epoch: 283| Step: 0
Training loss: 1.5392274856567383
Validation loss: 2.2396293679873147

Epoch: 6| Step: 1
Training loss: 1.112062931060791
Validation loss: 2.256589114665985

Epoch: 6| Step: 2
Training loss: 0.8761334419250488
Validation loss: 2.22113573551178

Epoch: 6| Step: 3
Training loss: 1.4529955387115479
Validation loss: 2.2129953304926553

Epoch: 6| Step: 4
Training loss: 1.7431972026824951
Validation loss: 2.248771369457245

Epoch: 6| Step: 5
Training loss: 1.097327709197998
Validation loss: 2.2458401322364807

Epoch: 6| Step: 6
Training loss: 1.0386964082717896
Validation loss: 2.2242320577303567

Epoch: 6| Step: 7
Training loss: 1.8557006120681763
Validation loss: 2.2169449726740518

Epoch: 6| Step: 8
Training loss: 1.5567092895507812
Validation loss: 2.2274597883224487

Epoch: 6| Step: 9
Training loss: 1.643044114112854
Validation loss: 2.2173513770103455

Epoch: 6| Step: 10
Training loss: 1.4151002168655396
Validation loss: 2.2106643120447793

Epoch: 6| Step: 11
Training loss: 1.1882797479629517
Validation loss: 2.2063348094622293

Epoch: 6| Step: 12
Training loss: 1.4782376289367676
Validation loss: 2.2430883049964905

Epoch: 6| Step: 13
Training loss: 0.8247198462486267
Validation loss: 2.1922552784283957

Epoch: 284| Step: 0
Training loss: 1.4431053400039673
Validation loss: 2.2463947534561157

Epoch: 6| Step: 1
Training loss: 1.120686411857605
Validation loss: 2.225853204727173

Epoch: 6| Step: 2
Training loss: 1.7773407697677612
Validation loss: 2.2199636896451316

Epoch: 6| Step: 3
Training loss: 1.2352745532989502
Validation loss: 2.255453189214071

Epoch: 6| Step: 4
Training loss: 1.6056666374206543
Validation loss: 2.2086018721262612

Epoch: 6| Step: 5
Training loss: 1.227919340133667
Validation loss: 2.229223291079203

Epoch: 6| Step: 6
Training loss: 0.6354372501373291
Validation loss: 2.2611482540766397

Epoch: 6| Step: 7
Training loss: 1.432906985282898
Validation loss: 2.247433384259542

Epoch: 6| Step: 8
Training loss: 1.165942907333374
Validation loss: 2.2351298928260803

Epoch: 6| Step: 9
Training loss: 1.390655279159546
Validation loss: 2.2363233963648477

Epoch: 6| Step: 10
Training loss: 1.3102483749389648
Validation loss: 2.217370311419169

Epoch: 6| Step: 11
Training loss: 1.787074327468872
Validation loss: 2.2582960526148477

Epoch: 6| Step: 12
Training loss: 0.8698030710220337
Validation loss: 2.2216193477312722

Epoch: 6| Step: 13
Training loss: 1.6828943490982056
Validation loss: 2.218789060910543

Epoch: 285| Step: 0
Training loss: 1.2842048406600952
Validation loss: 2.227205296357473

Epoch: 6| Step: 1
Training loss: 2.0051441192626953
Validation loss: 2.251253883043925

Epoch: 6| Step: 2
Training loss: 1.6012099981307983
Validation loss: 2.237332503000895

Epoch: 6| Step: 3
Training loss: 1.0041477680206299
Validation loss: 2.229346533616384

Epoch: 6| Step: 4
Training loss: 1.037919044494629
Validation loss: 2.227346579233805

Epoch: 6| Step: 5
Training loss: 1.2449135780334473
Validation loss: 2.216805915037791

Epoch: 6| Step: 6
Training loss: 1.267547369003296
Validation loss: 2.23112424214681

Epoch: 6| Step: 7
Training loss: 1.1915533542633057
Validation loss: 2.1758746902147927

Epoch: 6| Step: 8
Training loss: 0.7684593796730042
Validation loss: 2.212395409742991

Epoch: 6| Step: 9
Training loss: 0.7339585423469543
Validation loss: 2.2391331791877747

Epoch: 6| Step: 10
Training loss: 2.0704822540283203
Validation loss: 2.232226014137268

Epoch: 6| Step: 11
Training loss: 1.534501552581787
Validation loss: 2.2633748054504395

Epoch: 6| Step: 12
Training loss: 1.6986745595932007
Validation loss: 2.2255006035168967

Epoch: 6| Step: 13
Training loss: 1.6221836805343628
Validation loss: 2.2511600653330484

Epoch: 286| Step: 0
Training loss: 1.537068486213684
Validation loss: 2.2613751888275146

Epoch: 6| Step: 1
Training loss: 0.6412386894226074
Validation loss: 2.227012276649475

Epoch: 6| Step: 2
Training loss: 0.9143763780593872
Validation loss: 2.1879164973894754

Epoch: 6| Step: 3
Training loss: 1.465989589691162
Validation loss: 2.2449291149775186

Epoch: 6| Step: 4
Training loss: 1.3009705543518066
Validation loss: 2.207793374856313

Epoch: 6| Step: 5
Training loss: 1.349052906036377
Validation loss: 2.206075926621755

Epoch: 6| Step: 6
Training loss: 1.8098647594451904
Validation loss: 2.231395979722341

Epoch: 6| Step: 7
Training loss: 1.9528212547302246
Validation loss: 2.2191350062688193

Epoch: 6| Step: 8
Training loss: 1.733555793762207
Validation loss: 2.1947151025136313

Epoch: 6| Step: 9
Training loss: 1.7106168270111084
Validation loss: 2.2013206680615744

Epoch: 6| Step: 10
Training loss: 0.815595805644989
Validation loss: 2.1986960967381797

Epoch: 6| Step: 11
Training loss: 1.1665058135986328
Validation loss: 2.1766662200291953

Epoch: 6| Step: 12
Training loss: 1.1316864490509033
Validation loss: 2.202436705430349

Epoch: 6| Step: 13
Training loss: 1.4146008491516113
Validation loss: 2.2098604242006936

Epoch: 287| Step: 0
Training loss: 1.253265619277954
Validation loss: 2.239467442035675

Epoch: 6| Step: 1
Training loss: 1.2659443616867065
Validation loss: 2.218835473060608

Epoch: 6| Step: 2
Training loss: 1.472572922706604
Validation loss: 2.2009637157122293

Epoch: 6| Step: 3
Training loss: 1.710495948791504
Validation loss: 2.2019225557645163

Epoch: 6| Step: 4
Training loss: 1.516209363937378
Validation loss: 2.185358703136444

Epoch: 6| Step: 5
Training loss: 0.9085351228713989
Validation loss: 2.19121923049291

Epoch: 6| Step: 6
Training loss: 1.849103331565857
Validation loss: 2.229861636956533

Epoch: 6| Step: 7
Training loss: 1.046101689338684
Validation loss: 2.2132425705591836

Epoch: 6| Step: 8
Training loss: 0.8830616474151611
Validation loss: 2.2108641465504966

Epoch: 6| Step: 9
Training loss: 1.6215837001800537
Validation loss: 2.210390349229177

Epoch: 6| Step: 10
Training loss: 0.7551831007003784
Validation loss: 2.2031381527582803

Epoch: 6| Step: 11
Training loss: 1.4125144481658936
Validation loss: 2.2045291463534036

Epoch: 6| Step: 12
Training loss: 1.3908517360687256
Validation loss: 2.205059071381887

Epoch: 6| Step: 13
Training loss: 1.4981694221496582
Validation loss: 2.2127570311228433

Epoch: 288| Step: 0
Training loss: 1.8806822299957275
Validation loss: 2.236242334047953

Epoch: 6| Step: 1
Training loss: 0.8397915363311768
Validation loss: 2.242884655793508

Epoch: 6| Step: 2
Training loss: 1.386335849761963
Validation loss: 2.243430435657501

Epoch: 6| Step: 3
Training loss: 0.8200582265853882
Validation loss: 2.215522050857544

Epoch: 6| Step: 4
Training loss: 1.770714521408081
Validation loss: 2.205891768137614

Epoch: 6| Step: 5
Training loss: 1.4535698890686035
Validation loss: 2.2006390492121377

Epoch: 6| Step: 6
Training loss: 1.822942852973938
Validation loss: 2.1956071853637695

Epoch: 6| Step: 7
Training loss: 1.151245355606079
Validation loss: 2.216703454653422

Epoch: 6| Step: 8
Training loss: 0.5927984714508057
Validation loss: 2.2057851950327554

Epoch: 6| Step: 9
Training loss: 1.2128453254699707
Validation loss: 2.195131162802378

Epoch: 6| Step: 10
Training loss: 0.9448376297950745
Validation loss: 2.208207448323568

Epoch: 6| Step: 11
Training loss: 1.116857647895813
Validation loss: 2.224493225415548

Epoch: 6| Step: 12
Training loss: 1.8792390823364258
Validation loss: 2.204627434412638

Epoch: 6| Step: 13
Training loss: 1.8530832529067993
Validation loss: 2.198276162147522

Epoch: 289| Step: 0
Training loss: 1.9480986595153809
Validation loss: 2.2133297125498452

Epoch: 6| Step: 1
Training loss: 1.3547101020812988
Validation loss: 2.1836978991826377

Epoch: 6| Step: 2
Training loss: 1.622133731842041
Validation loss: 2.2079720894495645

Epoch: 6| Step: 3
Training loss: 1.7968666553497314
Validation loss: 2.2350415190060935

Epoch: 6| Step: 4
Training loss: 1.0766756534576416
Validation loss: 2.2324857314427695

Epoch: 6| Step: 5
Training loss: 1.361620306968689
Validation loss: 2.236818790435791

Epoch: 6| Step: 6
Training loss: 1.1917015314102173
Validation loss: 2.238131860891978

Epoch: 6| Step: 7
Training loss: 1.7389047145843506
Validation loss: 2.216045399506887

Epoch: 6| Step: 8
Training loss: 1.317251205444336
Validation loss: 2.249449928601583

Epoch: 6| Step: 9
Training loss: 1.2290304899215698
Validation loss: 2.234212895234426

Epoch: 6| Step: 10
Training loss: 0.9359548091888428
Validation loss: 2.252553661664327

Epoch: 6| Step: 11
Training loss: 1.3979079723358154
Validation loss: 2.224596321582794

Epoch: 6| Step: 12
Training loss: 0.9820617437362671
Validation loss: 2.253189504146576

Epoch: 6| Step: 13
Training loss: 1.0195319652557373
Validation loss: 2.251662850379944

Epoch: 290| Step: 0
Training loss: 1.2091798782348633
Validation loss: 2.2482303380966187

Epoch: 6| Step: 1
Training loss: 1.5461127758026123
Validation loss: 2.2681588729222617

Epoch: 6| Step: 2
Training loss: 1.1926331520080566
Validation loss: 2.2550028959910073

Epoch: 6| Step: 3
Training loss: 1.8963857889175415
Validation loss: 2.248052736123403

Epoch: 6| Step: 4
Training loss: 1.300252079963684
Validation loss: 2.2426810264587402

Epoch: 6| Step: 5
Training loss: 1.3199363946914673
Validation loss: 2.2125001549720764

Epoch: 6| Step: 6
Training loss: 0.9541852474212646
Validation loss: 2.196458101272583

Epoch: 6| Step: 7
Training loss: 1.1808645725250244
Validation loss: 2.1844111680984497

Epoch: 6| Step: 8
Training loss: 2.0561044216156006
Validation loss: 2.179763356844584

Epoch: 6| Step: 9
Training loss: 1.3553791046142578
Validation loss: 2.1512938340504966

Epoch: 6| Step: 10
Training loss: 1.6194220781326294
Validation loss: 2.1787205139795938

Epoch: 6| Step: 11
Training loss: 1.436150074005127
Validation loss: 2.179686705271403

Epoch: 6| Step: 12
Training loss: 1.173606276512146
Validation loss: 2.190613865852356

Epoch: 6| Step: 13
Training loss: 1.030455470085144
Validation loss: 2.199455658594767

Epoch: 291| Step: 0
Training loss: 1.5702190399169922
Validation loss: 2.1939699252446494

Epoch: 6| Step: 1
Training loss: 1.690875768661499
Validation loss: 2.176437735557556

Epoch: 6| Step: 2
Training loss: 0.7291833162307739
Validation loss: 2.1774699886639914

Epoch: 6| Step: 3
Training loss: 1.260179042816162
Validation loss: 2.2075390021006265

Epoch: 6| Step: 4
Training loss: 0.9365848302841187
Validation loss: 2.1790875593821206

Epoch: 6| Step: 5
Training loss: 0.8976001739501953
Validation loss: 2.219003200531006

Epoch: 6| Step: 6
Training loss: 1.8272078037261963
Validation loss: 2.2209465305010476

Epoch: 6| Step: 7
Training loss: 1.2531181573867798
Validation loss: 2.225464423497518

Epoch: 6| Step: 8
Training loss: 2.050901412963867
Validation loss: 2.211627185344696

Epoch: 6| Step: 9
Training loss: 1.5924245119094849
Validation loss: 2.1984647115071616

Epoch: 6| Step: 10
Training loss: 1.1995928287506104
Validation loss: 2.217804253101349

Epoch: 6| Step: 11
Training loss: 1.7848494052886963
Validation loss: 2.2111491759618125

Epoch: 6| Step: 12
Training loss: 1.0814030170440674
Validation loss: 2.204928735891978

Epoch: 6| Step: 13
Training loss: 1.2171008586883545
Validation loss: 2.1913422346115112

Epoch: 292| Step: 0
Training loss: 1.895467758178711
Validation loss: 2.190367817878723

Epoch: 6| Step: 1
Training loss: 1.304094910621643
Validation loss: 2.2007139126459756

Epoch: 6| Step: 2
Training loss: 1.834249496459961
Validation loss: 2.2534892161687217

Epoch: 6| Step: 3
Training loss: 1.3319257497787476
Validation loss: 2.234941840171814

Epoch: 6| Step: 4
Training loss: 1.4035437107086182
Validation loss: 2.247746745745341

Epoch: 6| Step: 5
Training loss: 0.7471292018890381
Validation loss: 2.235187828540802

Epoch: 6| Step: 6
Training loss: 0.7954790592193604
Validation loss: 2.256496171156565

Epoch: 6| Step: 7
Training loss: 0.9972805380821228
Validation loss: 2.264898677666982

Epoch: 6| Step: 8
Training loss: 1.7044117450714111
Validation loss: 2.250403900941213

Epoch: 6| Step: 9
Training loss: 1.369805097579956
Validation loss: 2.2206725080808005

Epoch: 6| Step: 10
Training loss: 1.4197237491607666
Validation loss: 2.246681809425354

Epoch: 6| Step: 11
Training loss: 1.6988940238952637
Validation loss: 2.2230416536331177

Epoch: 6| Step: 12
Training loss: 0.4362066388130188
Validation loss: 2.217462480068207

Epoch: 6| Step: 13
Training loss: 1.556779384613037
Validation loss: 2.223330855369568

Epoch: 293| Step: 0
Training loss: 0.9283615946769714
Validation loss: 2.1942275762557983

Epoch: 6| Step: 1
Training loss: 1.3754254579544067
Validation loss: 2.262419799963633

Epoch: 6| Step: 2
Training loss: 1.2132740020751953
Validation loss: 2.1922674576441445

Epoch: 6| Step: 3
Training loss: 0.785740315914154
Validation loss: 2.2012218038241067

Epoch: 6| Step: 4
Training loss: 2.323734998703003
Validation loss: 2.2021488547325134

Epoch: 6| Step: 5
Training loss: 1.4246162176132202
Validation loss: 2.213915308316549

Epoch: 6| Step: 6
Training loss: 1.0120768547058105
Validation loss: 2.1796464125315347

Epoch: 6| Step: 7
Training loss: 1.7949665784835815
Validation loss: 2.207818845907847

Epoch: 6| Step: 8
Training loss: 1.2319550514221191
Validation loss: 2.2277384400367737

Epoch: 6| Step: 9
Training loss: 1.8047865629196167
Validation loss: 2.2044719457626343

Epoch: 6| Step: 10
Training loss: 1.6594524383544922
Validation loss: 2.2178232868512473

Epoch: 6| Step: 11
Training loss: 0.8548162579536438
Validation loss: 2.225804030895233

Epoch: 6| Step: 12
Training loss: 1.1015934944152832
Validation loss: 2.2456573247909546

Epoch: 6| Step: 13
Training loss: 1.023263692855835
Validation loss: 2.196812391281128

Epoch: 294| Step: 0
Training loss: 1.3161059617996216
Validation loss: 2.2018759648005166

Epoch: 6| Step: 1
Training loss: 2.113618850708008
Validation loss: 2.1907245914141336

Epoch: 6| Step: 2
Training loss: 1.157538652420044
Validation loss: 2.2091281016667685

Epoch: 6| Step: 3
Training loss: 1.0493223667144775
Validation loss: 2.2419841090838113

Epoch: 6| Step: 4
Training loss: 1.3382632732391357
Validation loss: 2.2127975622812905

Epoch: 6| Step: 5
Training loss: 1.1366887092590332
Validation loss: 2.2327057917912803

Epoch: 6| Step: 6
Training loss: 1.2982282638549805
Validation loss: 2.2242196003595986

Epoch: 6| Step: 7
Training loss: 1.9369406700134277
Validation loss: 2.2135705947875977

Epoch: 6| Step: 8
Training loss: 1.4340615272521973
Validation loss: 2.2391857902208963

Epoch: 6| Step: 9
Training loss: 0.9161363244056702
Validation loss: 2.211636165777842

Epoch: 6| Step: 10
Training loss: 1.1929864883422852
Validation loss: 2.2096073031425476

Epoch: 6| Step: 11
Training loss: 0.521306574344635
Validation loss: 2.2438592513402305

Epoch: 6| Step: 12
Training loss: 1.1241517066955566
Validation loss: 2.220737556616465

Epoch: 6| Step: 13
Training loss: 1.6993228197097778
Validation loss: 2.220604439576467

Epoch: 295| Step: 0
Training loss: 0.9701498746871948
Validation loss: 2.253729204336802

Epoch: 6| Step: 1
Training loss: 1.1270138025283813
Validation loss: 2.2324058413505554

Epoch: 6| Step: 2
Training loss: 1.4038325548171997
Validation loss: 2.264607866605123

Epoch: 6| Step: 3
Training loss: 0.8688265085220337
Validation loss: 2.2309690912564597

Epoch: 6| Step: 4
Training loss: 1.1594157218933105
Validation loss: 2.2461386720339456

Epoch: 6| Step: 5
Training loss: 1.4381157159805298
Validation loss: 2.228273848692576

Epoch: 6| Step: 6
Training loss: 1.7461215257644653
Validation loss: 2.1983213822046914

Epoch: 6| Step: 7
Training loss: 1.0102622509002686
Validation loss: 2.2236960530281067

Epoch: 6| Step: 8
Training loss: 1.6713364124298096
Validation loss: 2.1955966353416443

Epoch: 6| Step: 9
Training loss: 1.0463563203811646
Validation loss: 2.2103949387868247

Epoch: 6| Step: 10
Training loss: 1.266442060470581
Validation loss: 2.2474840879440308

Epoch: 6| Step: 11
Training loss: 1.2347749471664429
Validation loss: 2.2295923630396524

Epoch: 6| Step: 12
Training loss: 1.3595967292785645
Validation loss: 2.1919225056966147

Epoch: 6| Step: 13
Training loss: 1.5648773908615112
Validation loss: 2.187920331954956

Epoch: 296| Step: 0
Training loss: 1.6448373794555664
Validation loss: 2.2384400367736816

Epoch: 6| Step: 1
Training loss: 0.6358413100242615
Validation loss: 2.2244221568107605

Epoch: 6| Step: 2
Training loss: 1.2730761766433716
Validation loss: 2.2236971656481423

Epoch: 6| Step: 3
Training loss: 1.3083668947219849
Validation loss: 2.217384934425354

Epoch: 6| Step: 4
Training loss: 1.5477761030197144
Validation loss: 2.209413687388102

Epoch: 6| Step: 5
Training loss: 1.0917017459869385
Validation loss: 2.210055351257324

Epoch: 6| Step: 6
Training loss: 1.20542311668396
Validation loss: 2.217447360356649

Epoch: 6| Step: 7
Training loss: 1.2949774265289307
Validation loss: 2.2239950299263

Epoch: 6| Step: 8
Training loss: 1.4893982410430908
Validation loss: 2.258947710196177

Epoch: 6| Step: 9
Training loss: 1.1224271059036255
Validation loss: 2.2342504262924194

Epoch: 6| Step: 10
Training loss: 1.1121244430541992
Validation loss: 2.2097874085108438

Epoch: 6| Step: 11
Training loss: 1.1214014291763306
Validation loss: 2.250116487344106

Epoch: 6| Step: 12
Training loss: 1.0974849462509155
Validation loss: 2.226555089155833

Epoch: 6| Step: 13
Training loss: 1.548298954963684
Validation loss: 2.196233630180359

Epoch: 297| Step: 0
Training loss: 1.252026081085205
Validation loss: 2.1962737838427224

Epoch: 6| Step: 1
Training loss: 0.9076133966445923
Validation loss: 2.186741530895233

Epoch: 6| Step: 2
Training loss: 1.2305394411087036
Validation loss: 2.1896245082219443

Epoch: 6| Step: 3
Training loss: 1.2063121795654297
Validation loss: 2.1954106291135154

Epoch: 6| Step: 4
Training loss: 1.120672583580017
Validation loss: 2.2188329497973123

Epoch: 6| Step: 5
Training loss: 1.5623024702072144
Validation loss: 2.197763959566752

Epoch: 6| Step: 6
Training loss: 1.4050438404083252
Validation loss: 2.2148996790250144

Epoch: 6| Step: 7
Training loss: 0.9592118263244629
Validation loss: 2.2130372325579324

Epoch: 6| Step: 8
Training loss: 0.8833561539649963
Validation loss: 2.191397229830424

Epoch: 6| Step: 9
Training loss: 1.4953019618988037
Validation loss: 2.184671401977539

Epoch: 6| Step: 10
Training loss: 1.1696081161499023
Validation loss: 2.2182549039522805

Epoch: 6| Step: 11
Training loss: 1.1900017261505127
Validation loss: 2.25465194384257

Epoch: 6| Step: 12
Training loss: 1.8969560861587524
Validation loss: 2.2173081437746682

Epoch: 6| Step: 13
Training loss: 1.346928358078003
Validation loss: 2.2364532748858132

Epoch: 298| Step: 0
Training loss: 1.489542007446289
Validation loss: 2.1925840179125466

Epoch: 6| Step: 1
Training loss: 1.803253412246704
Validation loss: 2.2197000781695047

Epoch: 6| Step: 2
Training loss: 1.013454794883728
Validation loss: 2.221883753935496

Epoch: 6| Step: 3
Training loss: 0.8081598281860352
Validation loss: 2.2283459504445395

Epoch: 6| Step: 4
Training loss: 1.7643537521362305
Validation loss: 2.2480033238728843

Epoch: 6| Step: 5
Training loss: 1.079627513885498
Validation loss: 2.2309751311937966

Epoch: 6| Step: 6
Training loss: 2.0196127891540527
Validation loss: 2.2296590010325112

Epoch: 6| Step: 7
Training loss: 2.1480979919433594
Validation loss: 2.261367440223694

Epoch: 6| Step: 8
Training loss: 1.0184385776519775
Validation loss: 2.2683865626653037

Epoch: 6| Step: 9
Training loss: 0.9161080718040466
Validation loss: 2.2565046350161233

Epoch: 6| Step: 10
Training loss: 1.4165664911270142
Validation loss: 2.229613165060679

Epoch: 6| Step: 11
Training loss: 1.6001734733581543
Validation loss: 2.283855756123861

Epoch: 6| Step: 12
Training loss: 1.3386855125427246
Validation loss: 2.257438898086548

Epoch: 6| Step: 13
Training loss: 0.6587188839912415
Validation loss: 2.226196050643921

Epoch: 299| Step: 0
Training loss: 1.1833715438842773
Validation loss: 2.2066713174184165

Epoch: 6| Step: 1
Training loss: 0.8806942105293274
Validation loss: 2.1827536622683206

Epoch: 6| Step: 2
Training loss: 1.7794184684753418
Validation loss: 2.191752870877584

Epoch: 6| Step: 3
Training loss: 1.9100980758666992
Validation loss: 2.1820251742998757

Epoch: 6| Step: 4
Training loss: 1.3481225967407227
Validation loss: 2.1857075095176697

Epoch: 6| Step: 5
Training loss: 0.8922106027603149
Validation loss: 2.199077785015106

Epoch: 6| Step: 6
Training loss: 0.8656402230262756
Validation loss: 2.217037876447042

Epoch: 6| Step: 7
Training loss: 1.0838754177093506
Validation loss: 2.224775036176046

Epoch: 6| Step: 8
Training loss: 1.2925996780395508
Validation loss: 2.2290300925572715

Epoch: 6| Step: 9
Training loss: 1.3671929836273193
Validation loss: 2.2867695490519204

Epoch: 6| Step: 10
Training loss: 1.5906951427459717
Validation loss: 2.2694279154141745

Epoch: 6| Step: 11
Training loss: 1.6752421855926514
Validation loss: 2.263028621673584

Epoch: 6| Step: 12
Training loss: 0.9156244993209839
Validation loss: 2.2761661410331726

Epoch: 6| Step: 13
Training loss: 1.1850717067718506
Validation loss: 2.3100918928782144

Epoch: 300| Step: 0
Training loss: 0.9575142860412598
Validation loss: 2.2612786491711936

Epoch: 6| Step: 1
Training loss: 0.638237714767456
Validation loss: 2.26917827129364

Epoch: 6| Step: 2
Training loss: 0.56305992603302
Validation loss: 2.224376996358236

Epoch: 6| Step: 3
Training loss: 1.9582968950271606
Validation loss: 2.2245105107625327

Epoch: 6| Step: 4
Training loss: 0.7548810243606567
Validation loss: 2.2290053764979043

Epoch: 6| Step: 5
Training loss: 1.426710605621338
Validation loss: 2.2258265018463135

Epoch: 6| Step: 6
Training loss: 1.7215821743011475
Validation loss: 2.207972228527069

Epoch: 6| Step: 7
Training loss: 1.375864863395691
Validation loss: 2.215854068597158

Epoch: 6| Step: 8
Training loss: 1.4377480745315552
Validation loss: 2.172393004099528

Epoch: 6| Step: 9
Training loss: 1.3414087295532227
Validation loss: 2.2044812639554343

Epoch: 6| Step: 10
Training loss: 1.3303877115249634
Validation loss: 2.1807782848676047

Epoch: 6| Step: 11
Training loss: 1.4121570587158203
Validation loss: 2.1547271609306335

Epoch: 6| Step: 12
Training loss: 1.6866919994354248
Validation loss: 2.1796631813049316

Epoch: 6| Step: 13
Training loss: 1.0155155658721924
Validation loss: 2.1780556241671243

Epoch: 301| Step: 0
Training loss: 1.2715561389923096
Validation loss: 2.17568701505661

Epoch: 6| Step: 1
Training loss: 1.8613526821136475
Validation loss: 2.1776419083277383

Epoch: 6| Step: 2
Training loss: 0.9606436491012573
Validation loss: 2.1609814564387

Epoch: 6| Step: 3
Training loss: 1.176513433456421
Validation loss: 2.1825870076815286

Epoch: 6| Step: 4
Training loss: 1.580507516860962
Validation loss: 2.1970654129981995

Epoch: 6| Step: 5
Training loss: 0.8020851612091064
Validation loss: 2.1852270364761353

Epoch: 6| Step: 6
Training loss: 1.292373538017273
Validation loss: 2.207056701183319

Epoch: 6| Step: 7
Training loss: 1.3410131931304932
Validation loss: 2.250993331273397

Epoch: 6| Step: 8
Training loss: 0.8120759725570679
Validation loss: 2.202216923236847

Epoch: 6| Step: 9
Training loss: 1.0766648054122925
Validation loss: 2.2287681102752686

Epoch: 6| Step: 10
Training loss: 0.6962906122207642
Validation loss: 2.2276739279429116

Epoch: 6| Step: 11
Training loss: 1.819751262664795
Validation loss: 2.220011909802755

Epoch: 6| Step: 12
Training loss: 1.622780442237854
Validation loss: 2.21156511704127

Epoch: 6| Step: 13
Training loss: 0.9421670436859131
Validation loss: 2.1894304156303406

Epoch: 302| Step: 0
Training loss: 1.788046956062317
Validation loss: 2.2049574653307595

Epoch: 6| Step: 1
Training loss: 1.0999317169189453
Validation loss: 2.2010602355003357

Epoch: 6| Step: 2
Training loss: 1.4589970111846924
Validation loss: 2.183961351712545

Epoch: 6| Step: 3
Training loss: 0.6318371295928955
Validation loss: 2.171521226565043

Epoch: 6| Step: 4
Training loss: 1.1051466464996338
Validation loss: 2.235247254371643

Epoch: 6| Step: 5
Training loss: 1.584987759590149
Validation loss: 2.2208221356074014

Epoch: 6| Step: 6
Training loss: 1.481200098991394
Validation loss: 2.2262903451919556

Epoch: 6| Step: 7
Training loss: 0.9523906707763672
Validation loss: 2.2095120350519815

Epoch: 6| Step: 8
Training loss: 1.6795375347137451
Validation loss: 2.2157954573631287

Epoch: 6| Step: 9
Training loss: 1.811260461807251
Validation loss: 2.1984936793645224

Epoch: 6| Step: 10
Training loss: 0.6780753135681152
Validation loss: 2.221713662147522

Epoch: 6| Step: 11
Training loss: 0.9576849937438965
Validation loss: 2.2054797212282815

Epoch: 6| Step: 12
Training loss: 0.9519913196563721
Validation loss: 2.1754208405812583

Epoch: 6| Step: 13
Training loss: 1.3597849607467651
Validation loss: 2.212794999281565

Epoch: 303| Step: 0
Training loss: 1.4779725074768066
Validation loss: 2.2582107981046042

Epoch: 6| Step: 1
Training loss: 0.6962481737136841
Validation loss: 2.2317459185918174

Epoch: 6| Step: 2
Training loss: 0.7050155997276306
Validation loss: 2.2567766308784485

Epoch: 6| Step: 3
Training loss: 1.314077377319336
Validation loss: 2.242113947868347

Epoch: 6| Step: 4
Training loss: 0.9141401052474976
Validation loss: 2.281731426715851

Epoch: 6| Step: 5
Training loss: 1.5245795249938965
Validation loss: 2.280066649119059

Epoch: 6| Step: 6
Training loss: 0.721733808517456
Validation loss: 2.2740602691968284

Epoch: 6| Step: 7
Training loss: 1.956242322921753
Validation loss: 2.266803046067556

Epoch: 6| Step: 8
Training loss: 1.1749972105026245
Validation loss: 2.2819983959198

Epoch: 6| Step: 9
Training loss: 1.2252267599105835
Validation loss: 2.2849014004071555

Epoch: 6| Step: 10
Training loss: 1.851820707321167
Validation loss: 2.2506073117256165

Epoch: 6| Step: 11
Training loss: 1.3241312503814697
Validation loss: 2.241183896859487

Epoch: 6| Step: 12
Training loss: 0.8756347894668579
Validation loss: 2.243480304876963

Epoch: 6| Step: 13
Training loss: 1.9712324142456055
Validation loss: 2.234227101008097

Epoch: 304| Step: 0
Training loss: 0.987088680267334
Validation loss: 2.2140274047851562

Epoch: 6| Step: 1
Training loss: 1.0100980997085571
Validation loss: 2.1869450410207114

Epoch: 6| Step: 2
Training loss: 1.523622989654541
Validation loss: 2.250166177749634

Epoch: 6| Step: 3
Training loss: 1.165788173675537
Validation loss: 2.224076271057129

Epoch: 6| Step: 4
Training loss: 1.1826388835906982
Validation loss: 2.229742685953776

Epoch: 6| Step: 5
Training loss: 1.5926960706710815
Validation loss: 2.181453764438629

Epoch: 6| Step: 6
Training loss: 1.3889408111572266
Validation loss: 2.2077756921450296

Epoch: 6| Step: 7
Training loss: 1.1513831615447998
Validation loss: 2.2047507762908936

Epoch: 6| Step: 8
Training loss: 1.4673435688018799
Validation loss: 2.217955450216929

Epoch: 6| Step: 9
Training loss: 1.0176901817321777
Validation loss: 2.227579673131307

Epoch: 6| Step: 10
Training loss: 0.5153093338012695
Validation loss: 2.2147239446640015

Epoch: 6| Step: 11
Training loss: 1.8502320051193237
Validation loss: 2.2164200146993003

Epoch: 6| Step: 12
Training loss: 1.0704069137573242
Validation loss: 2.24684872229894

Epoch: 6| Step: 13
Training loss: 1.4062488079071045
Validation loss: 2.251086155573527

Epoch: 305| Step: 0
Training loss: 1.8643286228179932
Validation loss: 2.2461328705151877

Epoch: 6| Step: 1
Training loss: 1.6081093549728394
Validation loss: 2.2660706440607705

Epoch: 6| Step: 2
Training loss: 1.2950549125671387
Validation loss: 2.228861391544342

Epoch: 6| Step: 3
Training loss: 0.6859584450721741
Validation loss: 2.2022035320599875

Epoch: 6| Step: 4
Training loss: 1.2321816682815552
Validation loss: 2.181512931982676

Epoch: 6| Step: 5
Training loss: 0.8976845741271973
Validation loss: 2.2095700899759927

Epoch: 6| Step: 6
Training loss: 1.6928067207336426
Validation loss: 2.221104621887207

Epoch: 6| Step: 7
Training loss: 1.0069506168365479
Validation loss: 2.2078840931256614

Epoch: 6| Step: 8
Training loss: 1.2547813653945923
Validation loss: 2.2228528459866843

Epoch: 6| Step: 9
Training loss: 0.7896549701690674
Validation loss: 2.246280630429586

Epoch: 6| Step: 10
Training loss: 1.0361876487731934
Validation loss: 2.2438162763913474

Epoch: 6| Step: 11
Training loss: 1.28346586227417
Validation loss: 2.228999058405558

Epoch: 6| Step: 12
Training loss: 0.9761244654655457
Validation loss: 2.225930611292521

Epoch: 6| Step: 13
Training loss: 1.1120986938476562
Validation loss: 2.2486086885134378

Epoch: 306| Step: 0
Training loss: 0.8364339470863342
Validation loss: 2.235820194085439

Epoch: 6| Step: 1
Training loss: 1.3486108779907227
Validation loss: 2.2156508763631186

Epoch: 6| Step: 2
Training loss: 1.3475505113601685
Validation loss: 2.222271720568339

Epoch: 6| Step: 3
Training loss: 1.5928804874420166
Validation loss: 2.2219250798225403

Epoch: 6| Step: 4
Training loss: 1.235639214515686
Validation loss: 2.1817089716593423

Epoch: 6| Step: 5
Training loss: 1.3517557382583618
Validation loss: 2.2000359098116555

Epoch: 6| Step: 6
Training loss: 0.9275503158569336
Validation loss: 2.1870635747909546

Epoch: 6| Step: 7
Training loss: 1.446709156036377
Validation loss: 2.167550047238668

Epoch: 6| Step: 8
Training loss: 1.3862900733947754
Validation loss: 2.1638500690460205

Epoch: 6| Step: 9
Training loss: 1.1903173923492432
Validation loss: 2.1746054689089456

Epoch: 6| Step: 10
Training loss: 0.695927083492279
Validation loss: 2.173855185508728

Epoch: 6| Step: 11
Training loss: 1.6840472221374512
Validation loss: 2.189913193384806

Epoch: 6| Step: 12
Training loss: 1.4414063692092896
Validation loss: 2.203420042991638

Epoch: 6| Step: 13
Training loss: 0.8444369435310364
Validation loss: 2.2260276476542153

Epoch: 307| Step: 0
Training loss: 1.3723511695861816
Validation loss: 2.217066744963328

Epoch: 6| Step: 1
Training loss: 0.9575725793838501
Validation loss: 2.193833808104197

Epoch: 6| Step: 2
Training loss: 1.196470856666565
Validation loss: 2.2287872036298118

Epoch: 6| Step: 3
Training loss: 1.2352406978607178
Validation loss: 2.248611271381378

Epoch: 6| Step: 4
Training loss: 1.3224272727966309
Validation loss: 2.248789072036743

Epoch: 6| Step: 5
Training loss: 1.013071894645691
Validation loss: 2.2373016277949014

Epoch: 6| Step: 6
Training loss: 1.5336260795593262
Validation loss: 2.2659542163213096

Epoch: 6| Step: 7
Training loss: 0.9793310165405273
Validation loss: 2.2972397406895957

Epoch: 6| Step: 8
Training loss: 1.5930817127227783
Validation loss: 2.23644228776296

Epoch: 6| Step: 9
Training loss: 2.0414724349975586
Validation loss: 2.2224159638086953

Epoch: 6| Step: 10
Training loss: 0.8922081589698792
Validation loss: 2.226205746332804

Epoch: 6| Step: 11
Training loss: 1.0662840604782104
Validation loss: 2.2182899713516235

Epoch: 6| Step: 12
Training loss: 1.1976256370544434
Validation loss: 2.169088125228882

Epoch: 6| Step: 13
Training loss: 0.811072587966919
Validation loss: 2.18489017089208

Epoch: 308| Step: 0
Training loss: 0.9834246635437012
Validation loss: 2.1637677550315857

Epoch: 6| Step: 1
Training loss: 0.9293288588523865
Validation loss: 2.189617335796356

Epoch: 6| Step: 2
Training loss: 1.8285844326019287
Validation loss: 2.1835585832595825

Epoch: 6| Step: 3
Training loss: 2.0194194316864014
Validation loss: 2.165862560272217

Epoch: 6| Step: 4
Training loss: 1.3103314638137817
Validation loss: 2.1739978392918906

Epoch: 6| Step: 5
Training loss: 1.8131037950515747
Validation loss: 2.182347297668457

Epoch: 6| Step: 6
Training loss: 0.9657461643218994
Validation loss: 2.1861600478490195

Epoch: 6| Step: 7
Training loss: 1.3256347179412842
Validation loss: 2.20495198170344

Epoch: 6| Step: 8
Training loss: 0.8097869753837585
Validation loss: 2.196178356806437

Epoch: 6| Step: 9
Training loss: 1.1590272188186646
Validation loss: 2.1942690213521323

Epoch: 6| Step: 10
Training loss: 0.7725124359130859
Validation loss: 2.196147322654724

Epoch: 6| Step: 11
Training loss: 1.9987554550170898
Validation loss: 2.2211826046307883

Epoch: 6| Step: 12
Training loss: 0.888612687587738
Validation loss: 2.2588837146759033

Epoch: 6| Step: 13
Training loss: 0.7975137233734131
Validation loss: 2.2469979723294577

Epoch: 309| Step: 0
Training loss: 1.155712366104126
Validation loss: 2.2803262869517007

Epoch: 6| Step: 1
Training loss: 1.0594099760055542
Validation loss: 2.2602341175079346

Epoch: 6| Step: 2
Training loss: 0.8871657848358154
Validation loss: 2.253685633341471

Epoch: 6| Step: 3
Training loss: 1.1275725364685059
Validation loss: 2.258713881174723

Epoch: 6| Step: 4
Training loss: 1.24767005443573
Validation loss: 2.2549145221710205

Epoch: 6| Step: 5
Training loss: 0.7427504658699036
Validation loss: 2.2581223845481873

Epoch: 6| Step: 6
Training loss: 0.9627183079719543
Validation loss: 2.2448044220606485

Epoch: 6| Step: 7
Training loss: 2.3716976642608643
Validation loss: 2.255841294924418

Epoch: 6| Step: 8
Training loss: 1.0731189250946045
Validation loss: 2.2593430876731873

Epoch: 6| Step: 9
Training loss: 1.045482873916626
Validation loss: 2.263336261113485

Epoch: 6| Step: 10
Training loss: 1.0546422004699707
Validation loss: 2.204172690709432

Epoch: 6| Step: 11
Training loss: 1.3858166933059692
Validation loss: 2.2179420590400696

Epoch: 6| Step: 12
Training loss: 1.3626470565795898
Validation loss: 2.169752597808838

Epoch: 6| Step: 13
Training loss: 1.5056686401367188
Validation loss: 2.1595279375712075

Epoch: 310| Step: 0
Training loss: 1.6888082027435303
Validation loss: 2.156781097253164

Epoch: 6| Step: 1
Training loss: 1.2224040031433105
Validation loss: 2.1523049672444663

Epoch: 6| Step: 2
Training loss: 1.2578763961791992
Validation loss: 2.1565685868263245

Epoch: 6| Step: 3
Training loss: 0.956169843673706
Validation loss: 2.2004440824190774

Epoch: 6| Step: 4
Training loss: 0.8538120985031128
Validation loss: 2.175571620464325

Epoch: 6| Step: 5
Training loss: 1.6950867176055908
Validation loss: 2.1848836143811545

Epoch: 6| Step: 6
Training loss: 0.6641585826873779
Validation loss: 2.173075020313263

Epoch: 6| Step: 7
Training loss: 0.955116868019104
Validation loss: 2.164467533429464

Epoch: 6| Step: 8
Training loss: 1.03420090675354
Validation loss: 2.216750164826711

Epoch: 6| Step: 9
Training loss: 1.5526142120361328
Validation loss: 2.215241273244222

Epoch: 6| Step: 10
Training loss: 1.0888161659240723
Validation loss: 2.2312490542729697

Epoch: 6| Step: 11
Training loss: 1.5797386169433594
Validation loss: 2.195152839024862

Epoch: 6| Step: 12
Training loss: 1.4184350967407227
Validation loss: 2.277813673019409

Epoch: 6| Step: 13
Training loss: 1.288243293762207
Validation loss: 2.27508008480072

Epoch: 311| Step: 0
Training loss: 0.7543072700500488
Validation loss: 2.277117212613424

Epoch: 6| Step: 1
Training loss: 1.6185109615325928
Validation loss: 2.2331310311953225

Epoch: 6| Step: 2
Training loss: 1.02549409866333
Validation loss: 2.255788822968801

Epoch: 6| Step: 3
Training loss: 1.2791202068328857
Validation loss: 2.2387335499127707

Epoch: 6| Step: 4
Training loss: 1.3920526504516602
Validation loss: 2.2740043004353843

Epoch: 6| Step: 5
Training loss: 1.1336734294891357
Validation loss: 2.273183822631836

Epoch: 6| Step: 6
Training loss: 1.0926135778427124
Validation loss: 2.2353170116742453

Epoch: 6| Step: 7
Training loss: 1.2323026657104492
Validation loss: 2.199150582154592

Epoch: 6| Step: 8
Training loss: 1.2665547132492065
Validation loss: 2.1923999389012656

Epoch: 6| Step: 9
Training loss: 1.1217594146728516
Validation loss: 2.2092440724372864

Epoch: 6| Step: 10
Training loss: 1.3089452981948853
Validation loss: 2.2107233007748923

Epoch: 6| Step: 11
Training loss: 1.2354929447174072
Validation loss: 2.189731856187185

Epoch: 6| Step: 12
Training loss: 1.142140507698059
Validation loss: 2.231194019317627

Epoch: 6| Step: 13
Training loss: 1.4320120811462402
Validation loss: 2.194599429766337

Epoch: 312| Step: 0
Training loss: 1.9666898250579834
Validation loss: 2.193396747112274

Epoch: 6| Step: 1
Training loss: 0.5472678542137146
Validation loss: 2.2093690435091653

Epoch: 6| Step: 2
Training loss: 0.8142789602279663
Validation loss: 2.214922785758972

Epoch: 6| Step: 3
Training loss: 0.726813554763794
Validation loss: 2.2506057222684226

Epoch: 6| Step: 4
Training loss: 0.9986519813537598
Validation loss: 2.2413922548294067

Epoch: 6| Step: 5
Training loss: 2.235816717147827
Validation loss: 2.2146678368250527

Epoch: 6| Step: 6
Training loss: 1.4545018672943115
Validation loss: 2.1735774874687195

Epoch: 6| Step: 7
Training loss: 0.6909372806549072
Validation loss: 2.189043084780375

Epoch: 6| Step: 8
Training loss: 1.0779303312301636
Validation loss: 2.2155452569325766

Epoch: 6| Step: 9
Training loss: 1.0500876903533936
Validation loss: 2.161352554957072

Epoch: 6| Step: 10
Training loss: 1.307202935218811
Validation loss: 2.1601776480674744

Epoch: 6| Step: 11
Training loss: 0.8476009368896484
Validation loss: 2.2010642687479653

Epoch: 6| Step: 12
Training loss: 1.9667141437530518
Validation loss: 2.125350753466288

Epoch: 6| Step: 13
Training loss: 1.0465307235717773
Validation loss: 2.1336591641108194

Epoch: 313| Step: 0
Training loss: 1.2865179777145386
Validation loss: 2.1409849524497986

Epoch: 6| Step: 1
Training loss: 1.3099210262298584
Validation loss: 2.1848526000976562

Epoch: 6| Step: 2
Training loss: 1.513305902481079
Validation loss: 2.137264291445414

Epoch: 6| Step: 3
Training loss: 0.9917980432510376
Validation loss: 2.154736816883087

Epoch: 6| Step: 4
Training loss: 0.8181861639022827
Validation loss: 2.176328122615814

Epoch: 6| Step: 5
Training loss: 1.1717253923416138
Validation loss: 2.158174236615499

Epoch: 6| Step: 6
Training loss: 1.1330095529556274
Validation loss: 2.2124929428100586

Epoch: 6| Step: 7
Training loss: 1.0752627849578857
Validation loss: 2.2071614265441895

Epoch: 6| Step: 8
Training loss: 1.0635114908218384
Validation loss: 2.2198431491851807

Epoch: 6| Step: 9
Training loss: 0.8798066973686218
Validation loss: 2.240961730480194

Epoch: 6| Step: 10
Training loss: 1.6948306560516357
Validation loss: 2.259867548942566

Epoch: 6| Step: 11
Training loss: 0.9383975267410278
Validation loss: 2.2719874382019043

Epoch: 6| Step: 12
Training loss: 1.3882219791412354
Validation loss: 2.251568337281545

Epoch: 6| Step: 13
Training loss: 1.6650457382202148
Validation loss: 2.2196794946988425

Epoch: 314| Step: 0
Training loss: 1.2374166250228882
Validation loss: 2.2424697081247964

Epoch: 6| Step: 1
Training loss: 1.9353312253952026
Validation loss: 2.2272018988927207

Epoch: 6| Step: 2
Training loss: 1.5695853233337402
Validation loss: 2.2398744424184165

Epoch: 6| Step: 3
Training loss: 1.0066652297973633
Validation loss: 2.2431057492891946

Epoch: 6| Step: 4
Training loss: 1.3375201225280762
Validation loss: 2.1648966868718467

Epoch: 6| Step: 5
Training loss: 1.0517487525939941
Validation loss: 2.224230686823527

Epoch: 6| Step: 6
Training loss: 0.958579421043396
Validation loss: 2.236819605032603

Epoch: 6| Step: 7
Training loss: 1.4499320983886719
Validation loss: 2.238314231236776

Epoch: 6| Step: 8
Training loss: 1.0350341796875
Validation loss: 2.20239794254303

Epoch: 6| Step: 9
Training loss: 1.6614923477172852
Validation loss: 2.2221869627634683

Epoch: 6| Step: 10
Training loss: 0.7939227223396301
Validation loss: 2.1962968508402505

Epoch: 6| Step: 11
Training loss: 0.7502282857894897
Validation loss: 2.213232239087423

Epoch: 6| Step: 12
Training loss: 1.4495716094970703
Validation loss: 2.21674116452535

Epoch: 6| Step: 13
Training loss: 1.0137770175933838
Validation loss: 2.2242656151453652

Epoch: 315| Step: 0
Training loss: 1.1274564266204834
Validation loss: 2.2633010347684226

Epoch: 6| Step: 1
Training loss: 1.443187952041626
Validation loss: 2.2644267082214355

Epoch: 6| Step: 2
Training loss: 1.4855971336364746
Validation loss: 2.243393282095591

Epoch: 6| Step: 3
Training loss: 0.8093302249908447
Validation loss: 2.1887260278066

Epoch: 6| Step: 4
Training loss: 0.8636001348495483
Validation loss: 2.238887588183085

Epoch: 6| Step: 5
Training loss: 1.0155456066131592
Validation loss: 2.192758540312449

Epoch: 6| Step: 6
Training loss: 1.485328197479248
Validation loss: 2.1849772135416665

Epoch: 6| Step: 7
Training loss: 1.4498541355133057
Validation loss: 2.182343363761902

Epoch: 6| Step: 8
Training loss: 0.8022161722183228
Validation loss: 2.2155430714289346

Epoch: 6| Step: 9
Training loss: 1.1135002374649048
Validation loss: 2.177866538365682

Epoch: 6| Step: 10
Training loss: 1.0543495416641235
Validation loss: 2.205910007158915

Epoch: 6| Step: 11
Training loss: 1.5193344354629517
Validation loss: 2.2014952301979065

Epoch: 6| Step: 12
Training loss: 0.928869366645813
Validation loss: 2.1930187145868936

Epoch: 6| Step: 13
Training loss: 1.4162201881408691
Validation loss: 2.138762275377909

Epoch: 316| Step: 0
Training loss: 0.9259548783302307
Validation loss: 2.173600514729818

Epoch: 6| Step: 1
Training loss: 1.4546741247177124
Validation loss: 2.1911733547846475

Epoch: 6| Step: 2
Training loss: 1.3273117542266846
Validation loss: 2.2006590962409973

Epoch: 6| Step: 3
Training loss: 1.0732815265655518
Validation loss: 2.2072380781173706

Epoch: 6| Step: 4
Training loss: 0.8907369375228882
Validation loss: 2.1881515185038247

Epoch: 6| Step: 5
Training loss: 1.546279788017273
Validation loss: 2.1800583004951477

Epoch: 6| Step: 6
Training loss: 1.0185285806655884
Validation loss: 2.1993539333343506

Epoch: 6| Step: 7
Training loss: 1.17924165725708
Validation loss: 2.2226803302764893

Epoch: 6| Step: 8
Training loss: 1.6421774625778198
Validation loss: 2.2260039250055947

Epoch: 6| Step: 9
Training loss: 0.9342445135116577
Validation loss: 2.234509607156118

Epoch: 6| Step: 10
Training loss: 1.0791727304458618
Validation loss: 2.2326196829477944

Epoch: 6| Step: 11
Training loss: 0.7399488687515259
Validation loss: 2.2267067432403564

Epoch: 6| Step: 12
Training loss: 1.062790036201477
Validation loss: 2.20024182399114

Epoch: 6| Step: 13
Training loss: 1.4797980785369873
Validation loss: 2.199038088321686

Epoch: 317| Step: 0
Training loss: 1.0004034042358398
Validation loss: 2.2059015234311423

Epoch: 6| Step: 1
Training loss: 0.5662937760353088
Validation loss: 2.2014721830685935

Epoch: 6| Step: 2
Training loss: 1.5914571285247803
Validation loss: 2.198025902112325

Epoch: 6| Step: 3
Training loss: 1.3884563446044922
Validation loss: 2.2205947836240134

Epoch: 6| Step: 4
Training loss: 0.8306558132171631
Validation loss: 2.2009076277414956

Epoch: 6| Step: 5
Training loss: 1.7776638269424438
Validation loss: 2.1634561022122702

Epoch: 6| Step: 6
Training loss: 1.6084587574005127
Validation loss: 2.2486433188120523

Epoch: 6| Step: 7
Training loss: 0.995140790939331
Validation loss: 2.2259124318758645

Epoch: 6| Step: 8
Training loss: 0.6237440705299377
Validation loss: 2.226941684881846

Epoch: 6| Step: 9
Training loss: 1.019586443901062
Validation loss: 2.1988256374994912

Epoch: 6| Step: 10
Training loss: 1.4847149848937988
Validation loss: 2.2272103230158486

Epoch: 6| Step: 11
Training loss: 1.016831398010254
Validation loss: 2.20868710676829

Epoch: 6| Step: 12
Training loss: 1.5298279523849487
Validation loss: 2.1992175579071045

Epoch: 6| Step: 13
Training loss: 0.9472904205322266
Validation loss: 2.189398467540741

Epoch: 318| Step: 0
Training loss: 1.370755910873413
Validation loss: 2.179821868737539

Epoch: 6| Step: 1
Training loss: 1.3103888034820557
Validation loss: 2.196702222029368

Epoch: 6| Step: 2
Training loss: 2.1234753131866455
Validation loss: 2.217970132827759

Epoch: 6| Step: 3
Training loss: 0.8095248937606812
Validation loss: 2.229570508003235

Epoch: 6| Step: 4
Training loss: 0.8845563530921936
Validation loss: 2.256144185860952

Epoch: 6| Step: 5
Training loss: 0.9671404957771301
Validation loss: 2.22944176197052

Epoch: 6| Step: 6
Training loss: 0.6319386959075928
Validation loss: 2.228497306505839

Epoch: 6| Step: 7
Training loss: 1.4158992767333984
Validation loss: 2.245993892351786

Epoch: 6| Step: 8
Training loss: 1.5513525009155273
Validation loss: 2.250207503636678

Epoch: 6| Step: 9
Training loss: 1.1095435619354248
Validation loss: 2.2417582472165427

Epoch: 6| Step: 10
Training loss: 0.4853866696357727
Validation loss: 2.218862295150757

Epoch: 6| Step: 11
Training loss: 1.3307191133499146
Validation loss: 2.215895394484202

Epoch: 6| Step: 12
Training loss: 1.0517395734786987
Validation loss: 2.236076235771179

Epoch: 6| Step: 13
Training loss: 0.899681806564331
Validation loss: 2.1885769764582315

Epoch: 319| Step: 0
Training loss: 1.0501254796981812
Validation loss: 2.216332793235779

Epoch: 6| Step: 1
Training loss: 2.018051862716675
Validation loss: 2.2058327198028564

Epoch: 6| Step: 2
Training loss: 0.8760460615158081
Validation loss: 2.2231494585673013

Epoch: 6| Step: 3
Training loss: 1.0098607540130615
Validation loss: 2.221011757850647

Epoch: 6| Step: 4
Training loss: 1.165635108947754
Validation loss: 2.2048803170522056

Epoch: 6| Step: 5
Training loss: 0.8060411214828491
Validation loss: 2.2035469015439353

Epoch: 6| Step: 6
Training loss: 1.1034467220306396
Validation loss: 2.2236483295758567

Epoch: 6| Step: 7
Training loss: 1.0743401050567627
Validation loss: 2.2205453515052795

Epoch: 6| Step: 8
Training loss: 1.4225541353225708
Validation loss: 2.237565517425537

Epoch: 6| Step: 9
Training loss: 1.4027748107910156
Validation loss: 2.248251517613729

Epoch: 6| Step: 10
Training loss: 1.2821664810180664
Validation loss: 2.2427362203598022

Epoch: 6| Step: 11
Training loss: 0.9503107070922852
Validation loss: 2.2189791003863015

Epoch: 6| Step: 12
Training loss: 0.9780067801475525
Validation loss: 2.2192302544911704

Epoch: 6| Step: 13
Training loss: 0.527125895023346
Validation loss: 2.2092591722806296

Epoch: 320| Step: 0
Training loss: 0.6688185930252075
Validation loss: 2.210148016611735

Epoch: 6| Step: 1
Training loss: 1.374114990234375
Validation loss: 2.1921675403912864

Epoch: 6| Step: 2
Training loss: 0.9685642123222351
Validation loss: 2.180603305498759

Epoch: 6| Step: 3
Training loss: 1.6844481229782104
Validation loss: 2.221159060796102

Epoch: 6| Step: 4
Training loss: 1.205649733543396
Validation loss: 2.212632934252421

Epoch: 6| Step: 5
Training loss: 0.7513328194618225
Validation loss: 2.2258547941843667

Epoch: 6| Step: 6
Training loss: 1.24327552318573
Validation loss: 2.2049493988355002

Epoch: 6| Step: 7
Training loss: 1.196816325187683
Validation loss: 2.2161145210266113

Epoch: 6| Step: 8
Training loss: 1.7151734828948975
Validation loss: 2.2094139456748962

Epoch: 6| Step: 9
Training loss: 0.8861547112464905
Validation loss: 2.202583611011505

Epoch: 6| Step: 10
Training loss: 0.9677673578262329
Validation loss: 2.1695975263913474

Epoch: 6| Step: 11
Training loss: 1.3568006753921509
Validation loss: 2.1737930178642273

Epoch: 6| Step: 12
Training loss: 0.8209934830665588
Validation loss: 2.1799222230911255

Epoch: 6| Step: 13
Training loss: 0.7798287868499756
Validation loss: 2.2002257903416953

Epoch: 321| Step: 0
Training loss: 0.7397416830062866
Validation loss: 2.1982188622156777

Epoch: 6| Step: 1
Training loss: 0.813403308391571
Validation loss: 2.236781815687815

Epoch: 6| Step: 2
Training loss: 1.0530686378479004
Validation loss: 2.2304516633351645

Epoch: 6| Step: 3
Training loss: 1.2305164337158203
Validation loss: 2.187861422697703

Epoch: 6| Step: 4
Training loss: 0.7396783828735352
Validation loss: 2.2102651993433633

Epoch: 6| Step: 5
Training loss: 1.9683481454849243
Validation loss: 2.1954635779062905

Epoch: 6| Step: 6
Training loss: 0.8294962644577026
Validation loss: 2.195460875829061

Epoch: 6| Step: 7
Training loss: 1.1067135334014893
Validation loss: 2.234159509340922

Epoch: 6| Step: 8
Training loss: 1.0167688131332397
Validation loss: 2.2219382524490356

Epoch: 6| Step: 9
Training loss: 1.541458010673523
Validation loss: 2.232207934061686

Epoch: 6| Step: 10
Training loss: 1.287379264831543
Validation loss: 2.2240922848383584

Epoch: 6| Step: 11
Training loss: 1.1251050233840942
Validation loss: 2.2204470038414

Epoch: 6| Step: 12
Training loss: 1.267120122909546
Validation loss: 2.196059226989746

Epoch: 6| Step: 13
Training loss: 0.9736563563346863
Validation loss: 2.21785169839859

Epoch: 322| Step: 0
Training loss: 1.393810510635376
Validation loss: 2.1845815976460776

Epoch: 6| Step: 1
Training loss: 1.1756736040115356
Validation loss: 2.1654058496157327

Epoch: 6| Step: 2
Training loss: 1.4229354858398438
Validation loss: 2.193192481994629

Epoch: 6| Step: 3
Training loss: 0.8160301446914673
Validation loss: 2.1963781913121543

Epoch: 6| Step: 4
Training loss: 1.2570137977600098
Validation loss: 2.2146480679512024

Epoch: 6| Step: 5
Training loss: 0.834459125995636
Validation loss: 2.18074760834376

Epoch: 6| Step: 6
Training loss: 1.2324877977371216
Validation loss: 2.180198073387146

Epoch: 6| Step: 7
Training loss: 1.0079739093780518
Validation loss: 2.20293923219045

Epoch: 6| Step: 8
Training loss: 0.7821875810623169
Validation loss: 2.1744060118993125

Epoch: 6| Step: 9
Training loss: 1.3402539491653442
Validation loss: 2.1463646292686462

Epoch: 6| Step: 10
Training loss: 0.9498555660247803
Validation loss: 2.1683178345362344

Epoch: 6| Step: 11
Training loss: 0.9528101682662964
Validation loss: 2.1385781168937683

Epoch: 6| Step: 12
Training loss: 1.211380958557129
Validation loss: 2.1780844926834106

Epoch: 6| Step: 13
Training loss: 1.149789810180664
Validation loss: 2.141787588596344

Epoch: 323| Step: 0
Training loss: 1.2943024635314941
Validation loss: 2.171012898286184

Epoch: 6| Step: 1
Training loss: 1.0220980644226074
Validation loss: 2.178913493951162

Epoch: 6| Step: 2
Training loss: 1.1830651760101318
Validation loss: 2.2122817238171897

Epoch: 6| Step: 3
Training loss: 1.6291930675506592
Validation loss: 2.2011676828066506

Epoch: 6| Step: 4
Training loss: 0.8834283351898193
Validation loss: 2.175188978513082

Epoch: 6| Step: 5
Training loss: 1.0115625858306885
Validation loss: 2.217987616856893

Epoch: 6| Step: 6
Training loss: 0.9693398475646973
Validation loss: 2.149098495642344

Epoch: 6| Step: 7
Training loss: 1.563259243965149
Validation loss: 2.190780460834503

Epoch: 6| Step: 8
Training loss: 1.406299114227295
Validation loss: 2.19710510969162

Epoch: 6| Step: 9
Training loss: 1.0527091026306152
Validation loss: 2.216987748940786

Epoch: 6| Step: 10
Training loss: 0.7177131175994873
Validation loss: 2.2077296574910483

Epoch: 6| Step: 11
Training loss: 1.5896382331848145
Validation loss: 2.1650702754656472

Epoch: 6| Step: 12
Training loss: 1.0601141452789307
Validation loss: 2.2489209373792014

Epoch: 6| Step: 13
Training loss: 1.3888263702392578
Validation loss: 2.2301467657089233

Epoch: 324| Step: 0
Training loss: 1.2793776988983154
Validation loss: 2.240873694419861

Epoch: 6| Step: 1
Training loss: 1.195426344871521
Validation loss: 2.1720296343167624

Epoch: 6| Step: 2
Training loss: 1.5334681272506714
Validation loss: 2.185743729273478

Epoch: 6| Step: 3
Training loss: 0.6894158124923706
Validation loss: 2.176451484362284

Epoch: 6| Step: 4
Training loss: 1.371232271194458
Validation loss: 2.1664045453071594

Epoch: 6| Step: 5
Training loss: 1.7887048721313477
Validation loss: 2.165964682896932

Epoch: 6| Step: 6
Training loss: 1.0656993389129639
Validation loss: 2.190573970476786

Epoch: 6| Step: 7
Training loss: 1.1492640972137451
Validation loss: 2.184470017751058

Epoch: 6| Step: 8
Training loss: 0.8285177946090698
Validation loss: 2.1722399989763894

Epoch: 6| Step: 9
Training loss: 1.4392116069793701
Validation loss: 2.1873570879300437

Epoch: 6| Step: 10
Training loss: 0.9732332229614258
Validation loss: 2.1388307015101113

Epoch: 6| Step: 11
Training loss: 1.4882068634033203
Validation loss: 2.167863667011261

Epoch: 6| Step: 12
Training loss: 0.6369267702102661
Validation loss: 2.155620296796163

Epoch: 6| Step: 13
Training loss: 0.8189335465431213
Validation loss: 2.196355322996775

Epoch: 325| Step: 0
Training loss: 1.1276445388793945
Validation loss: 2.18987766901652

Epoch: 6| Step: 1
Training loss: 1.1717530488967896
Validation loss: 2.1880739331245422

Epoch: 6| Step: 2
Training loss: 0.6713567972183228
Validation loss: 2.191284934679667

Epoch: 6| Step: 3
Training loss: 0.5749384760856628
Validation loss: 2.199723462263743

Epoch: 6| Step: 4
Training loss: 0.8329320549964905
Validation loss: 2.199286699295044

Epoch: 6| Step: 5
Training loss: 0.8853754997253418
Validation loss: 2.1779675682385764

Epoch: 6| Step: 6
Training loss: 1.745980143547058
Validation loss: 2.2419939041137695

Epoch: 6| Step: 7
Training loss: 1.2755709886550903
Validation loss: 2.2330299019813538

Epoch: 6| Step: 8
Training loss: 1.8505244255065918
Validation loss: 2.21940412123998

Epoch: 6| Step: 9
Training loss: 1.3380272388458252
Validation loss: 2.2705049912134805

Epoch: 6| Step: 10
Training loss: 1.1633038520812988
Validation loss: 2.258787751197815

Epoch: 6| Step: 11
Training loss: 1.0685815811157227
Validation loss: 2.214914778868357

Epoch: 6| Step: 12
Training loss: 0.75074303150177
Validation loss: 2.2592035134633384

Epoch: 6| Step: 13
Training loss: 1.5533053874969482
Validation loss: 2.25364742676417

Epoch: 326| Step: 0
Training loss: 1.1127002239227295
Validation loss: 2.2267295718193054

Epoch: 6| Step: 1
Training loss: 1.4674513339996338
Validation loss: 2.2126954793930054

Epoch: 6| Step: 2
Training loss: 0.7340070009231567
Validation loss: 2.192521890004476

Epoch: 6| Step: 3
Training loss: 1.1061371564865112
Validation loss: 2.18969456354777

Epoch: 6| Step: 4
Training loss: 1.0602844953536987
Validation loss: 2.153973718484243

Epoch: 6| Step: 5
Training loss: 1.1215335130691528
Validation loss: 2.1415714422861734

Epoch: 6| Step: 6
Training loss: 2.0474441051483154
Validation loss: 2.1418681740760803

Epoch: 6| Step: 7
Training loss: 1.5602145195007324
Validation loss: 2.1478222608566284

Epoch: 6| Step: 8
Training loss: 0.8037006855010986
Validation loss: 2.171530286471049

Epoch: 6| Step: 9
Training loss: 0.7323909997940063
Validation loss: 2.1449872255325317

Epoch: 6| Step: 10
Training loss: 0.779442548751831
Validation loss: 2.128554960091909

Epoch: 6| Step: 11
Training loss: 1.1790181398391724
Validation loss: 2.151296397050222

Epoch: 6| Step: 12
Training loss: 1.111348271369934
Validation loss: 2.179924031098684

Epoch: 6| Step: 13
Training loss: 1.0750823020935059
Validation loss: 2.2010240952173867

Epoch: 327| Step: 0
Training loss: 1.381354808807373
Validation loss: 2.1811069448788962

Epoch: 6| Step: 1
Training loss: 0.5863983631134033
Validation loss: 2.188530226548513

Epoch: 6| Step: 2
Training loss: 1.8028273582458496
Validation loss: 2.170569578806559

Epoch: 6| Step: 3
Training loss: 1.1609537601470947
Validation loss: 2.182036896546682

Epoch: 6| Step: 4
Training loss: 1.3811397552490234
Validation loss: 2.136638124783834

Epoch: 6| Step: 5
Training loss: 1.5050160884857178
Validation loss: 2.1493616898854575

Epoch: 6| Step: 6
Training loss: 0.6081974506378174
Validation loss: 2.1609352231025696

Epoch: 6| Step: 7
Training loss: 1.0591480731964111
Validation loss: 2.1459989746411643

Epoch: 6| Step: 8
Training loss: 1.0202912092208862
Validation loss: 2.124906301498413

Epoch: 6| Step: 9
Training loss: 1.3016605377197266
Validation loss: 2.182566543420156

Epoch: 6| Step: 10
Training loss: 0.9504206776618958
Validation loss: 2.127735654513041

Epoch: 6| Step: 11
Training loss: 1.2287076711654663
Validation loss: 2.119102358818054

Epoch: 6| Step: 12
Training loss: 1.206598162651062
Validation loss: 2.1287861267725625

Epoch: 6| Step: 13
Training loss: 1.5314867496490479
Validation loss: 2.138897875944773

Epoch: 328| Step: 0
Training loss: 1.141516923904419
Validation loss: 2.1026023825009665

Epoch: 6| Step: 1
Training loss: 1.3573198318481445
Validation loss: 2.1425181229909263

Epoch: 6| Step: 2
Training loss: 1.0850211381912231
Validation loss: 2.1294273138046265

Epoch: 6| Step: 3
Training loss: 1.646925449371338
Validation loss: 2.165114919344584

Epoch: 6| Step: 4
Training loss: 1.2615039348602295
Validation loss: 2.182014544804891

Epoch: 6| Step: 5
Training loss: 0.8864016532897949
Validation loss: 2.136187116305033

Epoch: 6| Step: 6
Training loss: 0.6919032335281372
Validation loss: 2.1477448542912803

Epoch: 6| Step: 7
Training loss: 0.625831127166748
Validation loss: 2.1624287962913513

Epoch: 6| Step: 8
Training loss: 0.7438772320747375
Validation loss: 2.1677722334861755

Epoch: 6| Step: 9
Training loss: 1.281751275062561
Validation loss: 2.1849631865819297

Epoch: 6| Step: 10
Training loss: 0.8086398839950562
Validation loss: 2.1881770292917886

Epoch: 6| Step: 11
Training loss: 1.1714224815368652
Validation loss: 2.165709356466929

Epoch: 6| Step: 12
Training loss: 1.7631961107254028
Validation loss: 2.1907949248949685

Epoch: 6| Step: 13
Training loss: 1.6148006916046143
Validation loss: 2.2091060479482016

Epoch: 329| Step: 0
Training loss: 1.3782718181610107
Validation loss: 2.2014275590578714

Epoch: 6| Step: 1
Training loss: 1.9497854709625244
Validation loss: 2.230746865272522

Epoch: 6| Step: 2
Training loss: 1.3361022472381592
Validation loss: 2.211077034473419

Epoch: 6| Step: 3
Training loss: 0.500630795955658
Validation loss: 2.228825569152832

Epoch: 6| Step: 4
Training loss: 0.8754355311393738
Validation loss: 2.2217012643814087

Epoch: 6| Step: 5
Training loss: 0.9035297632217407
Validation loss: 2.2188841303189597

Epoch: 6| Step: 6
Training loss: 1.4101948738098145
Validation loss: 2.275960703690847

Epoch: 6| Step: 7
Training loss: 0.8916120529174805
Validation loss: 2.2456138531366983

Epoch: 6| Step: 8
Training loss: 1.571634292602539
Validation loss: 2.250597437222799

Epoch: 6| Step: 9
Training loss: 1.0042911767959595
Validation loss: 2.221905251344045

Epoch: 6| Step: 10
Training loss: 0.9181846380233765
Validation loss: 2.1871999303499856

Epoch: 6| Step: 11
Training loss: 1.197603702545166
Validation loss: 2.20997687180837

Epoch: 6| Step: 12
Training loss: 1.0801396369934082
Validation loss: 2.2210228641827903

Epoch: 6| Step: 13
Training loss: 1.315471887588501
Validation loss: 2.1879146099090576

Epoch: 330| Step: 0
Training loss: 0.7420226335525513
Validation loss: 2.218210995197296

Epoch: 6| Step: 1
Training loss: 0.945805549621582
Validation loss: 2.1897122462590537

Epoch: 6| Step: 2
Training loss: 1.1201467514038086
Validation loss: 2.1937478383382163

Epoch: 6| Step: 3
Training loss: 0.9635798931121826
Validation loss: 2.195767045021057

Epoch: 6| Step: 4
Training loss: 1.3592971563339233
Validation loss: 2.199942708015442

Epoch: 6| Step: 5
Training loss: 1.3940833806991577
Validation loss: 2.190096120039622

Epoch: 6| Step: 6
Training loss: 1.2384765148162842
Validation loss: 2.1698623299598694

Epoch: 6| Step: 7
Training loss: 0.9981963634490967
Validation loss: 2.17567241191864

Epoch: 6| Step: 8
Training loss: 1.7246522903442383
Validation loss: 2.179753045241038

Epoch: 6| Step: 9
Training loss: 0.6821675896644592
Validation loss: 2.186174233754476

Epoch: 6| Step: 10
Training loss: 1.0719106197357178
Validation loss: 2.193481981754303

Epoch: 6| Step: 11
Training loss: 1.3311412334442139
Validation loss: 2.149041930834452

Epoch: 6| Step: 12
Training loss: 1.4378981590270996
Validation loss: 2.12688014904658

Epoch: 6| Step: 13
Training loss: 1.0824930667877197
Validation loss: 2.11264697710673

Epoch: 331| Step: 0
Training loss: 0.8414090871810913
Validation loss: 2.153153657913208

Epoch: 6| Step: 1
Training loss: 1.142809271812439
Validation loss: 2.1728619734446206

Epoch: 6| Step: 2
Training loss: 1.1475026607513428
Validation loss: 2.199820657571157

Epoch: 6| Step: 3
Training loss: 1.2946248054504395
Validation loss: 2.153713643550873

Epoch: 6| Step: 4
Training loss: 1.089614987373352
Validation loss: 2.1490453084309897

Epoch: 6| Step: 5
Training loss: 1.1941053867340088
Validation loss: 2.1760424772898355

Epoch: 6| Step: 6
Training loss: 1.1852136850357056
Validation loss: 2.1820221543312073

Epoch: 6| Step: 7
Training loss: 1.3079659938812256
Validation loss: 2.1649696032206216

Epoch: 6| Step: 8
Training loss: 1.1077306270599365
Validation loss: 2.2043097416559854

Epoch: 6| Step: 9
Training loss: 1.096001148223877
Validation loss: 2.157943546772003

Epoch: 6| Step: 10
Training loss: 1.3643925189971924
Validation loss: 2.163943429787954

Epoch: 6| Step: 11
Training loss: 0.8198876976966858
Validation loss: 2.1743179758389792

Epoch: 6| Step: 12
Training loss: 0.5702645778656006
Validation loss: 2.184980571269989

Epoch: 6| Step: 13
Training loss: 1.1917400360107422
Validation loss: 2.204693873723348

Epoch: 332| Step: 0
Training loss: 0.7888680696487427
Validation loss: 2.2101685206095376

Epoch: 6| Step: 1
Training loss: 1.1892139911651611
Validation loss: 2.1841365496317544

Epoch: 6| Step: 2
Training loss: 0.532583475112915
Validation loss: 2.1784822742144265

Epoch: 6| Step: 3
Training loss: 1.1740444898605347
Validation loss: 2.2067178090413413

Epoch: 6| Step: 4
Training loss: 0.7005324363708496
Validation loss: 2.1987788875897727

Epoch: 6| Step: 5
Training loss: 1.065191626548767
Validation loss: 2.1914535760879517

Epoch: 6| Step: 6
Training loss: 1.0814342498779297
Validation loss: 2.19478044907252

Epoch: 6| Step: 7
Training loss: 0.8844388127326965
Validation loss: 2.2246305346488953

Epoch: 6| Step: 8
Training loss: 1.2959388494491577
Validation loss: 2.2009548942248025

Epoch: 6| Step: 9
Training loss: 1.132076382637024
Validation loss: 2.203973571459452

Epoch: 6| Step: 10
Training loss: 1.498317003250122
Validation loss: 2.1824902296066284

Epoch: 6| Step: 11
Training loss: 1.204891324043274
Validation loss: 2.230825901031494

Epoch: 6| Step: 12
Training loss: 1.1622679233551025
Validation loss: 2.2152365843454995

Epoch: 6| Step: 13
Training loss: 0.7948194146156311
Validation loss: 2.1818904479344687

Epoch: 333| Step: 0
Training loss: 0.7650924921035767
Validation loss: 2.1968462665875754

Epoch: 6| Step: 1
Training loss: 0.8860704302787781
Validation loss: 2.184034585952759

Epoch: 6| Step: 2
Training loss: 1.243969440460205
Validation loss: 2.201951185862223

Epoch: 6| Step: 3
Training loss: 1.2382771968841553
Validation loss: 2.195715049902598

Epoch: 6| Step: 4
Training loss: 0.5719244480133057
Validation loss: 2.188795288403829

Epoch: 6| Step: 5
Training loss: 1.5882247686386108
Validation loss: 2.2175324161847434

Epoch: 6| Step: 6
Training loss: 1.120064377784729
Validation loss: 2.2390792965888977

Epoch: 6| Step: 7
Training loss: 0.8842148780822754
Validation loss: 2.215490976969401

Epoch: 6| Step: 8
Training loss: 1.755875587463379
Validation loss: 2.2449891169865928

Epoch: 6| Step: 9
Training loss: 1.1282765865325928
Validation loss: 2.195282200972239

Epoch: 6| Step: 10
Training loss: 0.8240528106689453
Validation loss: 2.239022135734558

Epoch: 6| Step: 11
Training loss: 1.0396242141723633
Validation loss: 2.17810853322347

Epoch: 6| Step: 12
Training loss: 0.6374890804290771
Validation loss: 2.228182037671407

Epoch: 6| Step: 13
Training loss: 1.0367202758789062
Validation loss: 2.1621508995691934

Epoch: 334| Step: 0
Training loss: 1.233405590057373
Validation loss: 2.147437314192454

Epoch: 6| Step: 1
Training loss: 1.8709228038787842
Validation loss: 2.160114904244741

Epoch: 6| Step: 2
Training loss: 0.9528167247772217
Validation loss: 2.139256000518799

Epoch: 6| Step: 3
Training loss: 1.0444860458374023
Validation loss: 2.1810298363367715

Epoch: 6| Step: 4
Training loss: 0.9786011576652527
Validation loss: 2.172382116317749

Epoch: 6| Step: 5
Training loss: 1.034738302230835
Validation loss: 2.1375120282173157

Epoch: 6| Step: 6
Training loss: 1.153921365737915
Validation loss: 2.1510555942853293

Epoch: 6| Step: 7
Training loss: 1.026900291442871
Validation loss: 2.152677357196808

Epoch: 6| Step: 8
Training loss: 1.3688925504684448
Validation loss: 2.168562591075897

Epoch: 6| Step: 9
Training loss: 0.8119088411331177
Validation loss: 2.166803558667501

Epoch: 6| Step: 10
Training loss: 0.48476094007492065
Validation loss: 2.198909282684326

Epoch: 6| Step: 11
Training loss: 0.8128618001937866
Validation loss: 2.244416972001394

Epoch: 6| Step: 12
Training loss: 1.5296411514282227
Validation loss: 2.2183600068092346

Epoch: 6| Step: 13
Training loss: 0.8610225319862366
Validation loss: 2.22267484664917

Epoch: 335| Step: 0
Training loss: 1.5893715620040894
Validation loss: 2.1985563238461814

Epoch: 6| Step: 1
Training loss: 0.6052186489105225
Validation loss: 2.1872509519259133

Epoch: 6| Step: 2
Training loss: 0.6427343487739563
Validation loss: 2.1799305280049643

Epoch: 6| Step: 3
Training loss: 1.235718011856079
Validation loss: 2.1710572640101113

Epoch: 6| Step: 4
Training loss: 0.9457173347473145
Validation loss: 2.1936154961586

Epoch: 6| Step: 5
Training loss: 0.9659175276756287
Validation loss: 2.1807760198911033

Epoch: 6| Step: 6
Training loss: 1.172714114189148
Validation loss: 2.2043678164482117

Epoch: 6| Step: 7
Training loss: 1.322555422782898
Validation loss: 2.198755462964376

Epoch: 6| Step: 8
Training loss: 1.5171537399291992
Validation loss: 2.215559720993042

Epoch: 6| Step: 9
Training loss: 1.130103349685669
Validation loss: 2.1689745783805847

Epoch: 6| Step: 10
Training loss: 0.8088040351867676
Validation loss: 2.156670570373535

Epoch: 6| Step: 11
Training loss: 0.5103511214256287
Validation loss: 2.2044222156206765

Epoch: 6| Step: 12
Training loss: 1.2078303098678589
Validation loss: 2.1518288254737854

Epoch: 6| Step: 13
Training loss: 1.2853131294250488
Validation loss: 2.150552451610565

Epoch: 336| Step: 0
Training loss: 0.9891360998153687
Validation loss: 2.1949764291445413

Epoch: 6| Step: 1
Training loss: 1.1274045705795288
Validation loss: 2.165498693784078

Epoch: 6| Step: 2
Training loss: 2.043424606323242
Validation loss: 2.152733266353607

Epoch: 6| Step: 3
Training loss: 1.0605343580245972
Validation loss: 2.1944851179917655

Epoch: 6| Step: 4
Training loss: 1.0451059341430664
Validation loss: 2.179436186949412

Epoch: 6| Step: 5
Training loss: 0.8641476631164551
Validation loss: 2.1956474582354226

Epoch: 6| Step: 6
Training loss: 1.1908947229385376
Validation loss: 2.1799913247426352

Epoch: 6| Step: 7
Training loss: 1.1513934135437012
Validation loss: 2.201698342959086

Epoch: 6| Step: 8
Training loss: 0.4958159923553467
Validation loss: 2.1941614548365274

Epoch: 6| Step: 9
Training loss: 0.84419184923172
Validation loss: 2.19452573855718

Epoch: 6| Step: 10
Training loss: 1.496612787246704
Validation loss: 2.178966462612152

Epoch: 6| Step: 11
Training loss: 0.47611507773399353
Validation loss: 2.161587397257487

Epoch: 6| Step: 12
Training loss: 1.4788217544555664
Validation loss: 2.151297132174174

Epoch: 6| Step: 13
Training loss: 1.0028979778289795
Validation loss: 2.2040783961613974

Epoch: 337| Step: 0
Training loss: 0.977459192276001
Validation loss: 2.1772667368253074

Epoch: 6| Step: 1
Training loss: 1.123582124710083
Validation loss: 2.160369336605072

Epoch: 6| Step: 2
Training loss: 0.45019739866256714
Validation loss: 2.185521880785624

Epoch: 6| Step: 3
Training loss: 1.4593265056610107
Validation loss: 2.192256430784861

Epoch: 6| Step: 4
Training loss: 0.7447887659072876
Validation loss: 2.232034166653951

Epoch: 6| Step: 5
Training loss: 1.0128506422042847
Validation loss: 2.202536940574646

Epoch: 6| Step: 6
Training loss: 0.8402937650680542
Validation loss: 2.1963519056638083

Epoch: 6| Step: 7
Training loss: 1.2810004949569702
Validation loss: 2.174076735973358

Epoch: 6| Step: 8
Training loss: 0.7932643890380859
Validation loss: 2.1959648728370667

Epoch: 6| Step: 9
Training loss: 1.545079231262207
Validation loss: 2.224443475405375

Epoch: 6| Step: 10
Training loss: 1.4175266027450562
Validation loss: 2.246339499950409

Epoch: 6| Step: 11
Training loss: 0.7476034760475159
Validation loss: 2.1914654970169067

Epoch: 6| Step: 12
Training loss: 1.1019618511199951
Validation loss: 2.224339723587036

Epoch: 6| Step: 13
Training loss: 0.783767819404602
Validation loss: 2.2486451864242554

Epoch: 338| Step: 0
Training loss: 0.9208222031593323
Validation loss: 2.2047173182169595

Epoch: 6| Step: 1
Training loss: 1.173695683479309
Validation loss: 2.246359944343567

Epoch: 6| Step: 2
Training loss: 0.857535719871521
Validation loss: 2.2156583666801453

Epoch: 6| Step: 3
Training loss: 1.0854213237762451
Validation loss: 2.225435276826223

Epoch: 6| Step: 4
Training loss: 0.9359898567199707
Validation loss: 2.1847031712532043

Epoch: 6| Step: 5
Training loss: 0.8138718605041504
Validation loss: 2.2195658087730408

Epoch: 6| Step: 6
Training loss: 1.2208809852600098
Validation loss: 2.193429112434387

Epoch: 6| Step: 7
Training loss: 1.1646517515182495
Validation loss: 2.1753931442896524

Epoch: 6| Step: 8
Training loss: 1.0729814767837524
Validation loss: 2.192193071047465

Epoch: 6| Step: 9
Training loss: 1.2112467288970947
Validation loss: 2.179165860017141

Epoch: 6| Step: 10
Training loss: 1.160940408706665
Validation loss: 2.1843367318312326

Epoch: 6| Step: 11
Training loss: 0.6151168346405029
Validation loss: 2.1244287689526877

Epoch: 6| Step: 12
Training loss: 0.9220814108848572
Validation loss: 2.1396864851315818

Epoch: 6| Step: 13
Training loss: 0.7745599746704102
Validation loss: 2.1737818320592246

Epoch: 339| Step: 0
Training loss: 1.3047778606414795
Validation loss: 2.1961843172709146

Epoch: 6| Step: 1
Training loss: 1.1353154182434082
Validation loss: 2.1638965805371604

Epoch: 6| Step: 2
Training loss: 0.599035382270813
Validation loss: 2.133915066719055

Epoch: 6| Step: 3
Training loss: 0.8313817977905273
Validation loss: 2.1886818210283914

Epoch: 6| Step: 4
Training loss: 0.8418365716934204
Validation loss: 2.1775453686714172

Epoch: 6| Step: 5
Training loss: 1.1656079292297363
Validation loss: 2.1994829575220742

Epoch: 6| Step: 6
Training loss: 0.7054355144500732
Validation loss: 2.2143755753835044

Epoch: 6| Step: 7
Training loss: 1.1521193981170654
Validation loss: 2.212997297445933

Epoch: 6| Step: 8
Training loss: 1.2008917331695557
Validation loss: 2.207155187924703

Epoch: 6| Step: 9
Training loss: 0.8294901251792908
Validation loss: 2.2264066139856973

Epoch: 6| Step: 10
Training loss: 0.6599341630935669
Validation loss: 2.214041233062744

Epoch: 6| Step: 11
Training loss: 1.1876075267791748
Validation loss: 2.1964317758878074

Epoch: 6| Step: 12
Training loss: 0.5612223148345947
Validation loss: 2.1890240907669067

Epoch: 6| Step: 13
Training loss: 1.3997581005096436
Validation loss: 2.2030626138051352

Epoch: 340| Step: 0
Training loss: 0.7551959156990051
Validation loss: 2.2100963791211448

Epoch: 6| Step: 1
Training loss: 0.8296717405319214
Validation loss: 2.2600991328557334

Epoch: 6| Step: 2
Training loss: 0.8499559164047241
Validation loss: 2.1907101472218833

Epoch: 6| Step: 3
Training loss: 0.6496632695198059
Validation loss: 2.2452842394510903

Epoch: 6| Step: 4
Training loss: 0.8547825813293457
Validation loss: 2.2285373210906982

Epoch: 6| Step: 5
Training loss: 0.8667235970497131
Validation loss: 2.205548346042633

Epoch: 6| Step: 6
Training loss: 1.6110432147979736
Validation loss: 2.2462328473726907

Epoch: 6| Step: 7
Training loss: 1.2153747081756592
Validation loss: 2.2216150363286338

Epoch: 6| Step: 8
Training loss: 1.3047575950622559
Validation loss: 2.234922011693319

Epoch: 6| Step: 9
Training loss: 1.2088290452957153
Validation loss: 2.197936753431956

Epoch: 6| Step: 10
Training loss: 1.3336505889892578
Validation loss: 2.178618927796682

Epoch: 6| Step: 11
Training loss: 0.9304739832878113
Validation loss: 2.234708627065023

Epoch: 6| Step: 12
Training loss: 0.8166747093200684
Validation loss: 2.1867703596750894

Epoch: 6| Step: 13
Training loss: 1.2080755233764648
Validation loss: 2.1500238180160522

Epoch: 341| Step: 0
Training loss: 0.7417399883270264
Validation loss: 2.206671953201294

Epoch: 6| Step: 1
Training loss: 0.622063934803009
Validation loss: 2.159068206946055

Epoch: 6| Step: 2
Training loss: 1.2194688320159912
Validation loss: 2.157401700814565

Epoch: 6| Step: 3
Training loss: 0.8566974401473999
Validation loss: 2.158200979232788

Epoch: 6| Step: 4
Training loss: 1.4245740175247192
Validation loss: 2.1631886959075928

Epoch: 6| Step: 5
Training loss: 1.0953550338745117
Validation loss: 2.238355875015259

Epoch: 6| Step: 6
Training loss: 1.3553024530410767
Validation loss: 2.1757525205612183

Epoch: 6| Step: 7
Training loss: 1.095263957977295
Validation loss: 2.2180269956588745

Epoch: 6| Step: 8
Training loss: 0.9503310322761536
Validation loss: 2.1837882002194724

Epoch: 6| Step: 9
Training loss: 1.225088357925415
Validation loss: 2.1434515515963235

Epoch: 6| Step: 10
Training loss: 0.6917111277580261
Validation loss: 2.154537618160248

Epoch: 6| Step: 11
Training loss: 0.8518421053886414
Validation loss: 2.1774147550264993

Epoch: 6| Step: 12
Training loss: 0.6059727668762207
Validation loss: 2.1867848833402

Epoch: 6| Step: 13
Training loss: 1.5477832555770874
Validation loss: 2.1954075495402017

Epoch: 342| Step: 0
Training loss: 1.3419084548950195
Validation loss: 2.209496478239695

Epoch: 6| Step: 1
Training loss: 0.8126623630523682
Validation loss: 2.200693051020304

Epoch: 6| Step: 2
Training loss: 0.7510808110237122
Validation loss: 2.1943010687828064

Epoch: 6| Step: 3
Training loss: 1.3783891201019287
Validation loss: 2.2127544482549033

Epoch: 6| Step: 4
Training loss: 0.7054057717323303
Validation loss: 2.204812308152517

Epoch: 6| Step: 5
Training loss: 1.1375102996826172
Validation loss: 2.224398156007131

Epoch: 6| Step: 6
Training loss: 1.1643468141555786
Validation loss: 2.238774538040161

Epoch: 6| Step: 7
Training loss: 0.6706939339637756
Validation loss: 2.2051830093065896

Epoch: 6| Step: 8
Training loss: 0.8179689645767212
Validation loss: 2.192972779273987

Epoch: 6| Step: 9
Training loss: 2.1498830318450928
Validation loss: 2.2233562072118125

Epoch: 6| Step: 10
Training loss: 1.1702975034713745
Validation loss: 2.20311176776886

Epoch: 6| Step: 11
Training loss: 0.6102025508880615
Validation loss: 2.2058610121409097

Epoch: 6| Step: 12
Training loss: 0.8358014822006226
Validation loss: 2.2085832357406616

Epoch: 6| Step: 13
Training loss: 0.7984026074409485
Validation loss: 2.2111814618110657

Epoch: 343| Step: 0
Training loss: 1.0844300985336304
Validation loss: 2.158698777357737

Epoch: 6| Step: 1
Training loss: 1.5043004751205444
Validation loss: 2.177973687648773

Epoch: 6| Step: 2
Training loss: 0.9540363550186157
Validation loss: 2.2062730193138123

Epoch: 6| Step: 3
Training loss: 1.122598648071289
Validation loss: 2.153294622898102

Epoch: 6| Step: 4
Training loss: 1.0216158628463745
Validation loss: 2.1746352116266885

Epoch: 6| Step: 5
Training loss: 0.8139647245407104
Validation loss: 2.2086517214775085

Epoch: 6| Step: 6
Training loss: 0.5270845890045166
Validation loss: 2.152043104171753

Epoch: 6| Step: 7
Training loss: 0.8800731897354126
Validation loss: 2.177410821119944

Epoch: 6| Step: 8
Training loss: 1.06703782081604
Validation loss: 2.228384474913279

Epoch: 6| Step: 9
Training loss: 0.8529720902442932
Validation loss: 2.2191129128138223

Epoch: 6| Step: 10
Training loss: 0.7418069243431091
Validation loss: 2.2264057795206704

Epoch: 6| Step: 11
Training loss: 1.1677442789077759
Validation loss: 2.2154674530029297

Epoch: 6| Step: 12
Training loss: 1.2469013929367065
Validation loss: 2.1961586276690164

Epoch: 6| Step: 13
Training loss: 1.0622583627700806
Validation loss: 2.1763131419817605

Epoch: 344| Step: 0
Training loss: 0.6436095237731934
Validation loss: 2.1474878787994385

Epoch: 6| Step: 1
Training loss: 0.5845574736595154
Validation loss: 2.162742813428243

Epoch: 6| Step: 2
Training loss: 1.099075198173523
Validation loss: 2.1570988098780313

Epoch: 6| Step: 3
Training loss: 1.3402456045150757
Validation loss: 2.1583668192227683

Epoch: 6| Step: 4
Training loss: 0.7576832175254822
Validation loss: 2.183070500691732

Epoch: 6| Step: 5
Training loss: 0.7036005258560181
Validation loss: 2.1740243832270303

Epoch: 6| Step: 6
Training loss: 0.8513336181640625
Validation loss: 2.168152650197347

Epoch: 6| Step: 7
Training loss: 0.9479991793632507
Validation loss: 2.1865951220194497

Epoch: 6| Step: 8
Training loss: 0.8933820724487305
Validation loss: 2.2060959537823996

Epoch: 6| Step: 9
Training loss: 1.2239669561386108
Validation loss: 2.1984872817993164

Epoch: 6| Step: 10
Training loss: 1.0740630626678467
Validation loss: 2.1687453786532083

Epoch: 6| Step: 11
Training loss: 1.316861629486084
Validation loss: 2.2247812747955322

Epoch: 6| Step: 12
Training loss: 1.4106156826019287
Validation loss: 2.206765373547872

Epoch: 6| Step: 13
Training loss: 0.7841765880584717
Validation loss: 2.187207063039144

Epoch: 345| Step: 0
Training loss: 0.7798066139221191
Validation loss: 2.1822851101557412

Epoch: 6| Step: 1
Training loss: 1.098024606704712
Validation loss: 2.196968217690786

Epoch: 6| Step: 2
Training loss: 1.3923699855804443
Validation loss: 2.1867613395055137

Epoch: 6| Step: 3
Training loss: 1.3728777170181274
Validation loss: 2.2096128265062966

Epoch: 6| Step: 4
Training loss: 0.5352052450180054
Validation loss: 2.2161985437075296

Epoch: 6| Step: 5
Training loss: 0.9576548933982849
Validation loss: 2.1945199966430664

Epoch: 6| Step: 6
Training loss: 1.1545836925506592
Validation loss: 2.2020521561304727

Epoch: 6| Step: 7
Training loss: 0.868847668170929
Validation loss: 2.2090237935384116

Epoch: 6| Step: 8
Training loss: 1.1254804134368896
Validation loss: 2.2095103661219277

Epoch: 6| Step: 9
Training loss: 1.176491141319275
Validation loss: 2.1571795543034873

Epoch: 6| Step: 10
Training loss: 0.9243468642234802
Validation loss: 2.204581360022227

Epoch: 6| Step: 11
Training loss: 0.5298126935958862
Validation loss: 2.175142506758372

Epoch: 6| Step: 12
Training loss: 1.0557587146759033
Validation loss: 2.1880484024683633

Epoch: 6| Step: 13
Training loss: 0.9006141424179077
Validation loss: 2.1827355225880942

Epoch: 346| Step: 0
Training loss: 0.9212659597396851
Validation loss: 2.1699563463528952

Epoch: 6| Step: 1
Training loss: 0.6327044367790222
Validation loss: 2.141954223314921

Epoch: 6| Step: 2
Training loss: 1.2601583003997803
Validation loss: 2.1822429100672402

Epoch: 6| Step: 3
Training loss: 1.5363569259643555
Validation loss: 2.1211886405944824

Epoch: 6| Step: 4
Training loss: 1.046029806137085
Validation loss: 2.163013497988383

Epoch: 6| Step: 5
Training loss: 0.9406262636184692
Validation loss: 2.206212043762207

Epoch: 6| Step: 6
Training loss: 0.8964723348617554
Validation loss: 2.199773629506429

Epoch: 6| Step: 7
Training loss: 0.6727733016014099
Validation loss: 2.1944735248883567

Epoch: 6| Step: 8
Training loss: 1.0758320093154907
Validation loss: 2.2166712085405984

Epoch: 6| Step: 9
Training loss: 0.6057946681976318
Validation loss: 2.1719026366869607

Epoch: 6| Step: 10
Training loss: 1.1112689971923828
Validation loss: 2.188790480295817

Epoch: 6| Step: 11
Training loss: 1.2642894983291626
Validation loss: 2.188516537348429

Epoch: 6| Step: 12
Training loss: 0.8571757078170776
Validation loss: 2.193140129248301

Epoch: 6| Step: 13
Training loss: 0.8000668287277222
Validation loss: 2.1853850285212197

Epoch: 347| Step: 0
Training loss: 0.8748878240585327
Validation loss: 2.1739813884099326

Epoch: 6| Step: 1
Training loss: 0.9283593893051147
Validation loss: 2.1788171529769897

Epoch: 6| Step: 2
Training loss: 0.9714179039001465
Validation loss: 2.1719248493512473

Epoch: 6| Step: 3
Training loss: 0.9837064743041992
Validation loss: 2.1795668601989746

Epoch: 6| Step: 4
Training loss: 1.0706349611282349
Validation loss: 2.178559184074402

Epoch: 6| Step: 5
Training loss: 0.6448538899421692
Validation loss: 2.1791113217671714

Epoch: 6| Step: 6
Training loss: 1.2623658180236816
Validation loss: 2.1707388957341514

Epoch: 6| Step: 7
Training loss: 0.6450198888778687
Validation loss: 2.166726231575012

Epoch: 6| Step: 8
Training loss: 1.0974112749099731
Validation loss: 2.1773929794629416

Epoch: 6| Step: 9
Training loss: 1.2304902076721191
Validation loss: 2.182290494441986

Epoch: 6| Step: 10
Training loss: 0.8730777502059937
Validation loss: 2.2064512769381204

Epoch: 6| Step: 11
Training loss: 0.7918007969856262
Validation loss: 2.1479590137799582

Epoch: 6| Step: 12
Training loss: 1.4562852382659912
Validation loss: 2.1497763991355896

Epoch: 6| Step: 13
Training loss: 0.8496304154396057
Validation loss: 2.142539699872335

Epoch: 348| Step: 0
Training loss: 1.0071923732757568
Validation loss: 2.1834657986958823

Epoch: 6| Step: 1
Training loss: 1.0620768070220947
Validation loss: 2.1770049333572388

Epoch: 6| Step: 2
Training loss: 0.6542506217956543
Validation loss: 2.166290899117788

Epoch: 6| Step: 3
Training loss: 0.663991391658783
Validation loss: 2.1746753056844077

Epoch: 6| Step: 4
Training loss: 1.0709565877914429
Validation loss: 2.128878037134806

Epoch: 6| Step: 5
Training loss: 1.0700041055679321
Validation loss: 2.1877859830856323

Epoch: 6| Step: 6
Training loss: 0.7406764626502991
Validation loss: 2.2168185909589133

Epoch: 6| Step: 7
Training loss: 0.9751442670822144
Validation loss: 2.2315062085787454

Epoch: 6| Step: 8
Training loss: 0.9821427464485168
Validation loss: 2.217055638631185

Epoch: 6| Step: 9
Training loss: 1.191230058670044
Validation loss: 2.2307533820470176

Epoch: 6| Step: 10
Training loss: 1.0915813446044922
Validation loss: 2.22052009900411

Epoch: 6| Step: 11
Training loss: 1.3776644468307495
Validation loss: 2.2330886324246726

Epoch: 6| Step: 12
Training loss: 0.5321898460388184
Validation loss: 2.2321735421816506

Epoch: 6| Step: 13
Training loss: 1.2197459936141968
Validation loss: 2.2154834469159446

Epoch: 349| Step: 0
Training loss: 1.0515098571777344
Validation loss: 2.208697736263275

Epoch: 6| Step: 1
Training loss: 0.9958798885345459
Validation loss: 2.246299982070923

Epoch: 6| Step: 2
Training loss: 1.2445505857467651
Validation loss: 2.2329655488332114

Epoch: 6| Step: 3
Training loss: 0.8030799627304077
Validation loss: 2.236380616823832

Epoch: 6| Step: 4
Training loss: 1.5216894149780273
Validation loss: 2.1831616957982383

Epoch: 6| Step: 5
Training loss: 0.526538074016571
Validation loss: 2.1751644810040793

Epoch: 6| Step: 6
Training loss: 1.218933343887329
Validation loss: 2.20863006512324

Epoch: 6| Step: 7
Training loss: 0.7810603380203247
Validation loss: 2.190252204736074

Epoch: 6| Step: 8
Training loss: 0.8679088354110718
Validation loss: 2.2001317739486694

Epoch: 6| Step: 9
Training loss: 1.0389561653137207
Validation loss: 2.174198309580485

Epoch: 6| Step: 10
Training loss: 0.7322375774383545
Validation loss: 2.1850514014561973

Epoch: 6| Step: 11
Training loss: 0.8959571123123169
Validation loss: 2.1837241450945535

Epoch: 6| Step: 12
Training loss: 0.7365725636482239
Validation loss: 2.192206700642904

Epoch: 6| Step: 13
Training loss: 0.7555880546569824
Validation loss: 2.194048901398977

Epoch: 350| Step: 0
Training loss: 1.143123984336853
Validation loss: 2.1636921167373657

Epoch: 6| Step: 1
Training loss: 0.883285403251648
Validation loss: 2.1709580421447754

Epoch: 6| Step: 2
Training loss: 1.1861809492111206
Validation loss: 2.1454778909683228

Epoch: 6| Step: 3
Training loss: 1.0020605325698853
Validation loss: 2.160574754079183

Epoch: 6| Step: 4
Training loss: 0.9731613993644714
Validation loss: 2.132077217102051

Epoch: 6| Step: 5
Training loss: 1.3260838985443115
Validation loss: 2.2129091223080954

Epoch: 6| Step: 6
Training loss: 1.0316053628921509
Validation loss: 2.184187432130178

Epoch: 6| Step: 7
Training loss: 1.1979624032974243
Validation loss: 2.2129167914390564

Epoch: 6| Step: 8
Training loss: 1.0466831922531128
Validation loss: 2.222360293070475

Epoch: 6| Step: 9
Training loss: 0.6341531276702881
Validation loss: 2.2049387494723

Epoch: 6| Step: 10
Training loss: 1.1305878162384033
Validation loss: 2.207606097062429

Epoch: 6| Step: 11
Training loss: 1.1690566539764404
Validation loss: 2.209557374318441

Epoch: 6| Step: 12
Training loss: 0.8153470754623413
Validation loss: 2.200868308544159

Epoch: 6| Step: 13
Training loss: 1.1196792125701904
Validation loss: 2.1570107539494834

Epoch: 351| Step: 0
Training loss: 1.7178705930709839
Validation loss: 2.131914575894674

Epoch: 6| Step: 1
Training loss: 1.103028416633606
Validation loss: 2.196281890074412

Epoch: 6| Step: 2
Training loss: 0.8519843816757202
Validation loss: 2.1465336084365845

Epoch: 6| Step: 3
Training loss: 0.9705483317375183
Validation loss: 2.1265716552734375

Epoch: 6| Step: 4
Training loss: 0.63492751121521
Validation loss: 2.152669390042623

Epoch: 6| Step: 5
Training loss: 0.9825417399406433
Validation loss: 2.1542394558588662

Epoch: 6| Step: 6
Training loss: 0.7730745673179626
Validation loss: 2.184854785601298

Epoch: 6| Step: 7
Training loss: 1.0311031341552734
Validation loss: 2.169998606046041

Epoch: 6| Step: 8
Training loss: 0.8907430171966553
Validation loss: 2.150450428326925

Epoch: 6| Step: 9
Training loss: 1.7299286127090454
Validation loss: 2.198291798432668

Epoch: 6| Step: 10
Training loss: 1.0843786001205444
Validation loss: 2.1560611923535666

Epoch: 6| Step: 11
Training loss: 0.9838387966156006
Validation loss: 2.1633153160413108

Epoch: 6| Step: 12
Training loss: 0.9068623781204224
Validation loss: 2.150106966495514

Epoch: 6| Step: 13
Training loss: 0.899316668510437
Validation loss: 2.164522190888723

Epoch: 352| Step: 0
Training loss: 1.3929662704467773
Validation loss: 2.1708067258199057

Epoch: 6| Step: 1
Training loss: 0.4751393496990204
Validation loss: 2.164617041746775

Epoch: 6| Step: 2
Training loss: 1.2626698017120361
Validation loss: 2.192401707172394

Epoch: 6| Step: 3
Training loss: 0.6451472043991089
Validation loss: 2.171123524506887

Epoch: 6| Step: 4
Training loss: 1.0464516878128052
Validation loss: 2.204658647378286

Epoch: 6| Step: 5
Training loss: 0.5673166513442993
Validation loss: 2.1882638136545816

Epoch: 6| Step: 6
Training loss: 1.0635079145431519
Validation loss: 2.182365914185842

Epoch: 6| Step: 7
Training loss: 1.0035181045532227
Validation loss: 2.190298616886139

Epoch: 6| Step: 8
Training loss: 1.022295355796814
Validation loss: 2.1993486285209656

Epoch: 6| Step: 9
Training loss: 1.045430302619934
Validation loss: 2.1901025573412576

Epoch: 6| Step: 10
Training loss: 1.1643445491790771
Validation loss: 2.177176038424174

Epoch: 6| Step: 11
Training loss: 1.0558189153671265
Validation loss: 2.157001475493113

Epoch: 6| Step: 12
Training loss: 0.6700005531311035
Validation loss: 2.1561458706855774

Epoch: 6| Step: 13
Training loss: 0.7669148445129395
Validation loss: 2.1511025428771973

Epoch: 353| Step: 0
Training loss: 1.236281156539917
Validation loss: 2.1730598409970603

Epoch: 6| Step: 1
Training loss: 0.8803112506866455
Validation loss: 2.1706809997558594

Epoch: 6| Step: 2
Training loss: 0.6757787466049194
Validation loss: 2.178595761458079

Epoch: 6| Step: 3
Training loss: 1.0894761085510254
Validation loss: 2.182205597559611

Epoch: 6| Step: 4
Training loss: 0.6933555603027344
Validation loss: 2.1442497968673706

Epoch: 6| Step: 5
Training loss: 0.7602382898330688
Validation loss: 2.173915684223175

Epoch: 6| Step: 6
Training loss: 1.2382166385650635
Validation loss: 2.1619506080945334

Epoch: 6| Step: 7
Training loss: 0.5125725269317627
Validation loss: 2.1861499547958374

Epoch: 6| Step: 8
Training loss: 0.5051777958869934
Validation loss: 2.1756017208099365

Epoch: 6| Step: 9
Training loss: 0.8895860910415649
Validation loss: 2.1509680350621543

Epoch: 6| Step: 10
Training loss: 1.0481157302856445
Validation loss: 2.1887755592664084

Epoch: 6| Step: 11
Training loss: 1.2667474746704102
Validation loss: 2.1693044304847717

Epoch: 6| Step: 12
Training loss: 1.577704668045044
Validation loss: 2.184843977292379

Epoch: 6| Step: 13
Training loss: 0.6966871619224548
Validation loss: 2.216581185658773

Epoch: 354| Step: 0
Training loss: 0.730970561504364
Validation loss: 2.1875846783320108

Epoch: 6| Step: 1
Training loss: 1.198681354522705
Validation loss: 2.188551962375641

Epoch: 6| Step: 2
Training loss: 1.487992763519287
Validation loss: 2.164445956548055

Epoch: 6| Step: 3
Training loss: 1.010818600654602
Validation loss: 2.195431629816691

Epoch: 6| Step: 4
Training loss: 0.5075498819351196
Validation loss: 2.190401315689087

Epoch: 6| Step: 5
Training loss: 0.7022453546524048
Validation loss: 2.1754013299942017

Epoch: 6| Step: 6
Training loss: 1.1720027923583984
Validation loss: 2.17490291595459

Epoch: 6| Step: 7
Training loss: 1.1870635747909546
Validation loss: 2.194194952646891

Epoch: 6| Step: 8
Training loss: 0.8487321138381958
Validation loss: 2.147005259990692

Epoch: 6| Step: 9
Training loss: 0.6115629076957703
Validation loss: 2.192142963409424

Epoch: 6| Step: 10
Training loss: 0.8492906093597412
Validation loss: 2.135556479295095

Epoch: 6| Step: 11
Training loss: 1.0181139707565308
Validation loss: 2.1283829609553018

Epoch: 6| Step: 12
Training loss: 1.1668951511383057
Validation loss: 2.150647521018982

Epoch: 6| Step: 13
Training loss: 0.6750457286834717
Validation loss: 2.1454248825709024

Epoch: 355| Step: 0
Training loss: 0.6671751141548157
Validation loss: 2.1775736808776855

Epoch: 6| Step: 1
Training loss: 1.2877402305603027
Validation loss: 2.1643182833989463

Epoch: 6| Step: 2
Training loss: 0.9626007676124573
Validation loss: 2.1519568959871926

Epoch: 6| Step: 3
Training loss: 1.8930878639221191
Validation loss: 2.1472472747166953

Epoch: 6| Step: 4
Training loss: 0.9749939441680908
Validation loss: 2.16270782550176

Epoch: 6| Step: 5
Training loss: 0.6686936616897583
Validation loss: 2.133422036965688

Epoch: 6| Step: 6
Training loss: 0.7194184064865112
Validation loss: 2.1719911098480225

Epoch: 6| Step: 7
Training loss: 0.7080442905426025
Validation loss: 2.2279470761617026

Epoch: 6| Step: 8
Training loss: 0.8766794204711914
Validation loss: 2.2473912040392556

Epoch: 6| Step: 9
Training loss: 1.2778449058532715
Validation loss: 2.2318413257598877

Epoch: 6| Step: 10
Training loss: 1.3221588134765625
Validation loss: 2.2274961471557617

Epoch: 6| Step: 11
Training loss: 0.7881869673728943
Validation loss: 2.2196499506632485

Epoch: 6| Step: 12
Training loss: 1.6556978225708008
Validation loss: 2.2262357076009116

Epoch: 6| Step: 13
Training loss: 0.6343427300453186
Validation loss: 2.160684903462728

Epoch: 356| Step: 0
Training loss: 1.1912024021148682
Validation loss: 2.1808937788009644

Epoch: 6| Step: 1
Training loss: 0.5332366824150085
Validation loss: 2.1901660362879434

Epoch: 6| Step: 2
Training loss: 0.5197491645812988
Validation loss: 2.19575043519338

Epoch: 6| Step: 3
Training loss: 0.8934260606765747
Validation loss: 2.1704264879226685

Epoch: 6| Step: 4
Training loss: 0.8692299127578735
Validation loss: 2.1954302191734314

Epoch: 6| Step: 5
Training loss: 0.9808549284934998
Validation loss: 2.179874002933502

Epoch: 6| Step: 6
Training loss: 0.864206850528717
Validation loss: 2.199380079905192

Epoch: 6| Step: 7
Training loss: 0.9179068803787231
Validation loss: 2.1892382899920144

Epoch: 6| Step: 8
Training loss: 1.2809696197509766
Validation loss: 2.212737242380778

Epoch: 6| Step: 9
Training loss: 1.1469082832336426
Validation loss: 2.2219237883885703

Epoch: 6| Step: 10
Training loss: 1.2425117492675781
Validation loss: 2.202574670314789

Epoch: 6| Step: 11
Training loss: 0.7800739407539368
Validation loss: 2.2179877956708274

Epoch: 6| Step: 12
Training loss: 0.828254222869873
Validation loss: 2.1805202960968018

Epoch: 6| Step: 13
Training loss: 0.8851125240325928
Validation loss: 2.21220600605011

Epoch: 357| Step: 0
Training loss: 0.5701332092285156
Validation loss: 2.1935201485951743

Epoch: 6| Step: 1
Training loss: 0.5894201397895813
Validation loss: 2.1926700671513877

Epoch: 6| Step: 2
Training loss: 1.478387713432312
Validation loss: 2.18823778629303

Epoch: 6| Step: 3
Training loss: 1.209968090057373
Validation loss: 2.1954253911972046

Epoch: 6| Step: 4
Training loss: 0.9755049347877502
Validation loss: 2.193713068962097

Epoch: 6| Step: 5
Training loss: 0.43936991691589355
Validation loss: 2.1873114307721457

Epoch: 6| Step: 6
Training loss: 0.9224683046340942
Validation loss: 2.187143842379252

Epoch: 6| Step: 7
Training loss: 1.1725534200668335
Validation loss: 2.1602415243784585

Epoch: 6| Step: 8
Training loss: 1.245051383972168
Validation loss: 2.145765960216522

Epoch: 6| Step: 9
Training loss: 0.8583844900131226
Validation loss: 2.145299792289734

Epoch: 6| Step: 10
Training loss: 1.1899714469909668
Validation loss: 2.1636346777280173

Epoch: 6| Step: 11
Training loss: 0.8013097047805786
Validation loss: 2.1575786074002585

Epoch: 6| Step: 12
Training loss: 1.041674256324768
Validation loss: 2.1685611605644226

Epoch: 6| Step: 13
Training loss: 0.9338910579681396
Validation loss: 2.1488503019014993

Epoch: 358| Step: 0
Training loss: 1.2302391529083252
Validation loss: 2.1864712635676065

Epoch: 6| Step: 1
Training loss: 0.978242814540863
Validation loss: 2.17111599445343

Epoch: 6| Step: 2
Training loss: 0.46257102489471436
Validation loss: 2.1740426421165466

Epoch: 6| Step: 3
Training loss: 0.845237672328949
Validation loss: 2.183308223883311

Epoch: 6| Step: 4
Training loss: 1.0722434520721436
Validation loss: 2.2181273897488913

Epoch: 6| Step: 5
Training loss: 0.8674564361572266
Validation loss: 2.183976948261261

Epoch: 6| Step: 6
Training loss: 0.6690871715545654
Validation loss: 2.1522579391797385

Epoch: 6| Step: 7
Training loss: 0.48734503984451294
Validation loss: 2.1661541064580283

Epoch: 6| Step: 8
Training loss: 0.5649141669273376
Validation loss: 2.193079133828481

Epoch: 6| Step: 9
Training loss: 0.7513156533241272
Validation loss: 2.1797555486361184

Epoch: 6| Step: 10
Training loss: 0.6769261360168457
Validation loss: 2.2203334172566733

Epoch: 6| Step: 11
Training loss: 1.8339266777038574
Validation loss: 2.172075390815735

Epoch: 6| Step: 12
Training loss: 0.7137872576713562
Validation loss: 2.2015031973520913

Epoch: 6| Step: 13
Training loss: 1.2449733018875122
Validation loss: 2.164687673250834

Epoch: 359| Step: 0
Training loss: 0.6420689225196838
Validation loss: 2.1872986356417337

Epoch: 6| Step: 1
Training loss: 0.7884756326675415
Validation loss: 2.167267163594564

Epoch: 6| Step: 2
Training loss: 0.7500577569007874
Validation loss: 2.172851244608561

Epoch: 6| Step: 3
Training loss: 0.8511492013931274
Validation loss: 2.226661284764608

Epoch: 6| Step: 4
Training loss: 1.2575023174285889
Validation loss: 2.199769159158071

Epoch: 6| Step: 5
Training loss: 1.325074315071106
Validation loss: 2.2339443365732827

Epoch: 6| Step: 6
Training loss: 0.9209885597229004
Validation loss: 2.246066629886627

Epoch: 6| Step: 7
Training loss: 1.0928717851638794
Validation loss: 2.228486160437266

Epoch: 6| Step: 8
Training loss: 0.6367548704147339
Validation loss: 2.2203199664751687

Epoch: 6| Step: 9
Training loss: 0.9992800951004028
Validation loss: 2.2018654346466064

Epoch: 6| Step: 10
Training loss: 0.5083555579185486
Validation loss: 2.222627580165863

Epoch: 6| Step: 11
Training loss: 0.8146060705184937
Validation loss: 2.1699222524960837

Epoch: 6| Step: 12
Training loss: 0.8795669674873352
Validation loss: 2.185119847456614

Epoch: 6| Step: 13
Training loss: 0.9252234697341919
Validation loss: 2.1734917362531028

Epoch: 360| Step: 0
Training loss: 1.263775110244751
Validation loss: 2.1891404191652932

Epoch: 6| Step: 1
Training loss: 0.6633188724517822
Validation loss: 2.184548556804657

Epoch: 6| Step: 2
Training loss: 1.257711410522461
Validation loss: 2.1788956920305886

Epoch: 6| Step: 3
Training loss: 0.5541820526123047
Validation loss: 2.1552127599716187

Epoch: 6| Step: 4
Training loss: 0.7113139629364014
Validation loss: 2.2230041225751243

Epoch: 6| Step: 5
Training loss: 0.9278510808944702
Validation loss: 2.1912373304367065

Epoch: 6| Step: 6
Training loss: 1.3310952186584473
Validation loss: 2.2070292830467224

Epoch: 6| Step: 7
Training loss: 0.9774221181869507
Validation loss: 2.2124517361323037

Epoch: 6| Step: 8
Training loss: 0.9407001733779907
Validation loss: 2.2166640361150107

Epoch: 6| Step: 9
Training loss: 1.1944847106933594
Validation loss: 2.2277878324190774

Epoch: 6| Step: 10
Training loss: 1.407660961151123
Validation loss: 2.1985391974449158

Epoch: 6| Step: 11
Training loss: 1.1809468269348145
Validation loss: 2.20302681128184

Epoch: 6| Step: 12
Training loss: 0.8817617297172546
Validation loss: 2.234089970588684

Epoch: 6| Step: 13
Training loss: 0.5985226035118103
Validation loss: 2.2402822176615396

Epoch: 361| Step: 0
Training loss: 0.9920541644096375
Validation loss: 2.197610159715017

Epoch: 6| Step: 1
Training loss: 0.7030742764472961
Validation loss: 2.2188634276390076

Epoch: 6| Step: 2
Training loss: 0.7875435948371887
Validation loss: 2.187531848748525

Epoch: 6| Step: 3
Training loss: 0.9076354503631592
Validation loss: 2.1975924173990884

Epoch: 6| Step: 4
Training loss: 1.1598031520843506
Validation loss: 2.179117262363434

Epoch: 6| Step: 5
Training loss: 1.0645711421966553
Validation loss: 2.193117618560791

Epoch: 6| Step: 6
Training loss: 0.9781594276428223
Validation loss: 2.174860894680023

Epoch: 6| Step: 7
Training loss: 0.26675519347190857
Validation loss: 2.186093727747599

Epoch: 6| Step: 8
Training loss: 1.0865132808685303
Validation loss: 2.1775485078493753

Epoch: 6| Step: 9
Training loss: 0.9254834055900574
Validation loss: 2.2230820457140603

Epoch: 6| Step: 10
Training loss: 0.8086096048355103
Validation loss: 2.252492527167002

Epoch: 6| Step: 11
Training loss: 0.8807514905929565
Validation loss: 2.174462298552195

Epoch: 6| Step: 12
Training loss: 0.8625524640083313
Validation loss: 2.1955944101015725

Epoch: 6| Step: 13
Training loss: 0.9625604152679443
Validation loss: 2.1896979014078775

Epoch: 362| Step: 0
Training loss: 0.7779701948165894
Validation loss: 2.1590946118036904

Epoch: 6| Step: 1
Training loss: 1.3634576797485352
Validation loss: 2.177837371826172

Epoch: 6| Step: 2
Training loss: 0.9970784187316895
Validation loss: 2.1669201056162515

Epoch: 6| Step: 3
Training loss: 0.7436856627464294
Validation loss: 2.199823498725891

Epoch: 6| Step: 4
Training loss: 0.6937708258628845
Validation loss: 2.185668726762136

Epoch: 6| Step: 5
Training loss: 0.7227626442909241
Validation loss: 2.1776670018831887

Epoch: 6| Step: 6
Training loss: 0.8570407032966614
Validation loss: 2.198330561319987

Epoch: 6| Step: 7
Training loss: 0.7766029834747314
Validation loss: 2.2186623414357505

Epoch: 6| Step: 8
Training loss: 1.071094036102295
Validation loss: 2.2180535991986594

Epoch: 6| Step: 9
Training loss: 1.0140531063079834
Validation loss: 2.21835188070933

Epoch: 6| Step: 10
Training loss: 0.6386359930038452
Validation loss: 2.210892697175344

Epoch: 6| Step: 11
Training loss: 1.0768810510635376
Validation loss: 2.2200260361035666

Epoch: 6| Step: 12
Training loss: 0.4283066987991333
Validation loss: 2.20928684870402

Epoch: 6| Step: 13
Training loss: 1.1573024988174438
Validation loss: 2.1902366479237876

Epoch: 363| Step: 0
Training loss: 0.863287091255188
Validation loss: 2.2004907528559365

Epoch: 6| Step: 1
Training loss: 1.017652153968811
Validation loss: 2.2033065954844155

Epoch: 6| Step: 2
Training loss: 0.5677770972251892
Validation loss: 2.2332908709843955

Epoch: 6| Step: 3
Training loss: 0.8545752167701721
Validation loss: 2.175882856051127

Epoch: 6| Step: 4
Training loss: 0.7803722620010376
Validation loss: 2.165391723314921

Epoch: 6| Step: 5
Training loss: 0.6817880868911743
Validation loss: 2.1582321921984353

Epoch: 6| Step: 6
Training loss: 0.545141875743866
Validation loss: 2.1760895053545632

Epoch: 6| Step: 7
Training loss: 0.8398809432983398
Validation loss: 2.1546780268351235

Epoch: 6| Step: 8
Training loss: 0.5427345633506775
Validation loss: 2.174387534459432

Epoch: 6| Step: 9
Training loss: 0.9567186236381531
Validation loss: 2.1737901171048484

Epoch: 6| Step: 10
Training loss: 0.9345252513885498
Validation loss: 2.149479071299235

Epoch: 6| Step: 11
Training loss: 0.9585469961166382
Validation loss: 2.151828348636627

Epoch: 6| Step: 12
Training loss: 1.3674561977386475
Validation loss: 2.198566257953644

Epoch: 6| Step: 13
Training loss: 0.9961296319961548
Validation loss: 2.2071287830670676

Epoch: 364| Step: 0
Training loss: 1.2433509826660156
Validation loss: 2.1888432105382285

Epoch: 6| Step: 1
Training loss: 1.2633211612701416
Validation loss: 2.2155311902364097

Epoch: 6| Step: 2
Training loss: 0.7934212684631348
Validation loss: 2.187289277712504

Epoch: 6| Step: 3
Training loss: 0.7110892534255981
Validation loss: 2.1670831441879272

Epoch: 6| Step: 4
Training loss: 0.5694934129714966
Validation loss: 2.1604305704434714

Epoch: 6| Step: 5
Training loss: 1.0490257740020752
Validation loss: 2.153924306233724

Epoch: 6| Step: 6
Training loss: 0.6481673121452332
Validation loss: 2.172747711340586

Epoch: 6| Step: 7
Training loss: 0.7511645555496216
Validation loss: 2.159588932991028

Epoch: 6| Step: 8
Training loss: 1.13117516040802
Validation loss: 2.202482541402181

Epoch: 6| Step: 9
Training loss: 0.6424593925476074
Validation loss: 2.16927037636439

Epoch: 6| Step: 10
Training loss: 0.38978058099746704
Validation loss: 2.193402568499247

Epoch: 6| Step: 11
Training loss: 0.6830528974533081
Validation loss: 2.1708770990371704

Epoch: 6| Step: 12
Training loss: 1.6963460445404053
Validation loss: 2.168251951535543

Epoch: 6| Step: 13
Training loss: 0.7989970445632935
Validation loss: 2.2016430099805198

Epoch: 365| Step: 0
Training loss: 0.8527228832244873
Validation loss: 2.206580956776937

Epoch: 6| Step: 1
Training loss: 0.5130358934402466
Validation loss: 2.2165377140045166

Epoch: 6| Step: 2
Training loss: 0.9216867685317993
Validation loss: 2.1512052019437156

Epoch: 6| Step: 3
Training loss: 1.0876185894012451
Validation loss: 2.1423290570576987

Epoch: 6| Step: 4
Training loss: 0.8973431587219238
Validation loss: 2.164985497792562

Epoch: 6| Step: 5
Training loss: 0.6185827255249023
Validation loss: 2.174184282620748

Epoch: 6| Step: 6
Training loss: 0.4853726029396057
Validation loss: 2.1238152583440146

Epoch: 6| Step: 7
Training loss: 2.0679516792297363
Validation loss: 2.1345655719439187

Epoch: 6| Step: 8
Training loss: 0.7337654232978821
Validation loss: 2.1611536542574563

Epoch: 6| Step: 9
Training loss: 0.6227810382843018
Validation loss: 2.159035007158915

Epoch: 6| Step: 10
Training loss: 0.7106017470359802
Validation loss: 2.1942612131436667

Epoch: 6| Step: 11
Training loss: 0.5859644412994385
Validation loss: 2.1940078934033713

Epoch: 6| Step: 12
Training loss: 1.273784875869751
Validation loss: 2.2188592751820884

Epoch: 6| Step: 13
Training loss: 0.8695224523544312
Validation loss: 2.21316389242808

Epoch: 366| Step: 0
Training loss: 1.2074754238128662
Validation loss: 2.1826972166697183

Epoch: 6| Step: 1
Training loss: 0.5398945808410645
Validation loss: 2.1652918656667075

Epoch: 6| Step: 2
Training loss: 0.7428805828094482
Validation loss: 2.1705675522486367

Epoch: 6| Step: 3
Training loss: 0.4780208170413971
Validation loss: 2.1956411401430764

Epoch: 6| Step: 4
Training loss: 0.7566051483154297
Validation loss: 2.225300888220469

Epoch: 6| Step: 5
Training loss: 0.7258583307266235
Validation loss: 2.203528722127279

Epoch: 6| Step: 6
Training loss: 1.582846760749817
Validation loss: 2.192416508992513

Epoch: 6| Step: 7
Training loss: 0.6483616232872009
Validation loss: 2.181172808011373

Epoch: 6| Step: 8
Training loss: 0.9863342046737671
Validation loss: 2.188621997833252

Epoch: 6| Step: 9
Training loss: 0.8116669654846191
Validation loss: 2.15007746219635

Epoch: 6| Step: 10
Training loss: 0.8933544158935547
Validation loss: 2.2096439202626548

Epoch: 6| Step: 11
Training loss: 0.5246086120605469
Validation loss: 2.207841157913208

Epoch: 6| Step: 12
Training loss: 0.7907906174659729
Validation loss: 2.1862767338752747

Epoch: 6| Step: 13
Training loss: 1.4787126779556274
Validation loss: 2.1912355025609336

Epoch: 367| Step: 0
Training loss: 1.1773855686187744
Validation loss: 2.2350425720214844

Epoch: 6| Step: 1
Training loss: 1.6344178915023804
Validation loss: 2.2373728156089783

Epoch: 6| Step: 2
Training loss: 0.6431586742401123
Validation loss: 2.212986926237742

Epoch: 6| Step: 3
Training loss: 0.9182709455490112
Validation loss: 2.173584977785746

Epoch: 6| Step: 4
Training loss: 1.024421215057373
Validation loss: 2.175428112347921

Epoch: 6| Step: 5
Training loss: 0.7715978622436523
Validation loss: 2.157378613948822

Epoch: 6| Step: 6
Training loss: 0.821774423122406
Validation loss: 2.1887895663579306

Epoch: 6| Step: 7
Training loss: 0.6995317339897156
Validation loss: 2.129199186960856

Epoch: 6| Step: 8
Training loss: 0.538286566734314
Validation loss: 2.1918392976125083

Epoch: 6| Step: 9
Training loss: 0.9038577079772949
Validation loss: 2.181002914905548

Epoch: 6| Step: 10
Training loss: 0.9499723315238953
Validation loss: 2.1961636940638223

Epoch: 6| Step: 11
Training loss: 0.7132613658905029
Validation loss: 2.205497662226359

Epoch: 6| Step: 12
Training loss: 0.9671710729598999
Validation loss: 2.205725292364756

Epoch: 6| Step: 13
Training loss: 0.48757004737854004
Validation loss: 2.24420436223348

Epoch: 368| Step: 0
Training loss: 1.0731725692749023
Validation loss: 2.2139462431271872

Epoch: 6| Step: 1
Training loss: 0.5549004077911377
Validation loss: 2.2131494283676147

Epoch: 6| Step: 2
Training loss: 0.3461829721927643
Validation loss: 2.187517523765564

Epoch: 6| Step: 3
Training loss: 0.8933442831039429
Validation loss: 2.198698401451111

Epoch: 6| Step: 4
Training loss: 0.7764545679092407
Validation loss: 2.218850294748942

Epoch: 6| Step: 5
Training loss: 0.746665358543396
Validation loss: 2.187160392602285

Epoch: 6| Step: 6
Training loss: 0.9013516902923584
Validation loss: 2.177391827106476

Epoch: 6| Step: 7
Training loss: 0.7184280157089233
Validation loss: 2.172151962916056

Epoch: 6| Step: 8
Training loss: 1.2249505519866943
Validation loss: 2.2115482489267984

Epoch: 6| Step: 9
Training loss: 0.6675686836242676
Validation loss: 2.199521780014038

Epoch: 6| Step: 10
Training loss: 0.8804270029067993
Validation loss: 2.149542530377706

Epoch: 6| Step: 11
Training loss: 1.4105608463287354
Validation loss: 2.159823497136434

Epoch: 6| Step: 12
Training loss: 1.0402004718780518
Validation loss: 2.135961910088857

Epoch: 6| Step: 13
Training loss: 0.4053214192390442
Validation loss: 2.1735005577405295

Epoch: 369| Step: 0
Training loss: 0.8268757462501526
Validation loss: 2.1505055030186973

Epoch: 6| Step: 1
Training loss: 0.6862006783485413
Validation loss: 2.166230618953705

Epoch: 6| Step: 2
Training loss: 0.6955572366714478
Validation loss: 2.1568716963132224

Epoch: 6| Step: 3
Training loss: 1.0588752031326294
Validation loss: 2.1379816134770713

Epoch: 6| Step: 4
Training loss: 0.6257294416427612
Validation loss: 2.138845384120941

Epoch: 6| Step: 5
Training loss: 0.6791549921035767
Validation loss: 2.105161110560099

Epoch: 6| Step: 6
Training loss: 0.38770484924316406
Validation loss: 2.158596396446228

Epoch: 6| Step: 7
Training loss: 0.7718669176101685
Validation loss: 2.1500213543574014

Epoch: 6| Step: 8
Training loss: 0.7834089994430542
Validation loss: 2.161692718664805

Epoch: 6| Step: 9
Training loss: 0.9491716623306274
Validation loss: 2.1808669169743857

Epoch: 6| Step: 10
Training loss: 1.620667815208435
Validation loss: 2.1638633807500205

Epoch: 6| Step: 11
Training loss: 1.0296313762664795
Validation loss: 2.168281674385071

Epoch: 6| Step: 12
Training loss: 0.6966348886489868
Validation loss: 2.1490323146184287

Epoch: 6| Step: 13
Training loss: 0.8329488039016724
Validation loss: 2.139849285284678

Epoch: 370| Step: 0
Training loss: 1.0197808742523193
Validation loss: 2.1779392759005227

Epoch: 6| Step: 1
Training loss: 0.455274760723114
Validation loss: 2.158147692680359

Epoch: 6| Step: 2
Training loss: 0.5683618783950806
Validation loss: 2.180446664492289

Epoch: 6| Step: 3
Training loss: 0.802195131778717
Validation loss: 2.2017127672831216

Epoch: 6| Step: 4
Training loss: 0.7440598011016846
Validation loss: 2.1946545243263245

Epoch: 6| Step: 5
Training loss: 1.2531002759933472
Validation loss: 2.1971744894981384

Epoch: 6| Step: 6
Training loss: 0.39753448963165283
Validation loss: 2.183660010496775

Epoch: 6| Step: 7
Training loss: 0.4235715866088867
Validation loss: 2.1813688476880393

Epoch: 6| Step: 8
Training loss: 0.6990031003952026
Validation loss: 2.1725720365842185

Epoch: 6| Step: 9
Training loss: 1.171134352684021
Validation loss: 2.1637882788976035

Epoch: 6| Step: 10
Training loss: 1.0164780616760254
Validation loss: 2.1979349851608276

Epoch: 6| Step: 11
Training loss: 0.5505011081695557
Validation loss: 2.1884260376294455

Epoch: 6| Step: 12
Training loss: 1.4803290367126465
Validation loss: 2.1966745456059775

Epoch: 6| Step: 13
Training loss: 1.013378381729126
Validation loss: 2.213809529940287

Epoch: 371| Step: 0
Training loss: 1.2135565280914307
Validation loss: 2.208242893218994

Epoch: 6| Step: 1
Training loss: 0.820905864238739
Validation loss: 2.1920501391092935

Epoch: 6| Step: 2
Training loss: 1.0177912712097168
Validation loss: 2.165246844291687

Epoch: 6| Step: 3
Training loss: 1.1884469985961914
Validation loss: 2.1915680170059204

Epoch: 6| Step: 4
Training loss: 1.0545375347137451
Validation loss: 2.158314347267151

Epoch: 6| Step: 5
Training loss: 0.6828179359436035
Validation loss: 2.0995319286982217

Epoch: 6| Step: 6
Training loss: 1.1003079414367676
Validation loss: 2.1303529739379883

Epoch: 6| Step: 7
Training loss: 0.5232549905776978
Validation loss: 2.181390384833018

Epoch: 6| Step: 8
Training loss: 0.7176313400268555
Validation loss: 2.1072731812795005

Epoch: 6| Step: 9
Training loss: 0.5000392198562622
Validation loss: 2.1532259384791055

Epoch: 6| Step: 10
Training loss: 0.44786661863327026
Validation loss: 2.1131423910458884

Epoch: 6| Step: 11
Training loss: 0.36802592873573303
Validation loss: 2.1451132694880166

Epoch: 6| Step: 12
Training loss: 0.8562613129615784
Validation loss: 2.1667988300323486

Epoch: 6| Step: 13
Training loss: 1.0217559337615967
Validation loss: 2.1176554759343467

Epoch: 372| Step: 0
Training loss: 0.6482924818992615
Validation loss: 2.1842523415883384

Epoch: 6| Step: 1
Training loss: 0.7146724462509155
Validation loss: 2.1159293254216514

Epoch: 6| Step: 2
Training loss: 0.8752285242080688
Validation loss: 2.148598591486613

Epoch: 6| Step: 3
Training loss: 0.6818305253982544
Validation loss: 2.148321807384491

Epoch: 6| Step: 4
Training loss: 0.7530052661895752
Validation loss: 2.148660679658254

Epoch: 6| Step: 5
Training loss: 0.6193627119064331
Validation loss: 2.1620248556137085

Epoch: 6| Step: 6
Training loss: 1.0770155191421509
Validation loss: 2.1358867088953652

Epoch: 6| Step: 7
Training loss: 0.5763340592384338
Validation loss: 2.149673660596212

Epoch: 6| Step: 8
Training loss: 0.544863224029541
Validation loss: 2.1204276283582053

Epoch: 6| Step: 9
Training loss: 0.9471457600593567
Validation loss: 2.120411296685537

Epoch: 6| Step: 10
Training loss: 1.4071910381317139
Validation loss: 2.1862703363100686

Epoch: 6| Step: 11
Training loss: 0.910434365272522
Validation loss: 2.114073157310486

Epoch: 6| Step: 12
Training loss: 0.593543291091919
Validation loss: 2.1307161251703897

Epoch: 6| Step: 13
Training loss: 1.3467320203781128
Validation loss: 2.1339728434880576

Epoch: 373| Step: 0
Training loss: 0.3865112364292145
Validation loss: 2.1478851636250815

Epoch: 6| Step: 1
Training loss: 1.3783183097839355
Validation loss: 2.191600779692332

Epoch: 6| Step: 2
Training loss: 1.1632282733917236
Validation loss: 2.169571499029795

Epoch: 6| Step: 3
Training loss: 0.6830512285232544
Validation loss: 2.21245143810908

Epoch: 6| Step: 4
Training loss: 0.8875344395637512
Validation loss: 2.1974271138509116

Epoch: 6| Step: 5
Training loss: 0.6686042547225952
Validation loss: 2.1542596419652305

Epoch: 6| Step: 6
Training loss: 0.4613202214241028
Validation loss: 2.136049469312032

Epoch: 6| Step: 7
Training loss: 1.1542832851409912
Validation loss: 2.124653180440267

Epoch: 6| Step: 8
Training loss: 1.340356707572937
Validation loss: 2.1414169669151306

Epoch: 6| Step: 9
Training loss: 0.6611243486404419
Validation loss: 2.150342663129171

Epoch: 6| Step: 10
Training loss: 0.9570918679237366
Validation loss: 2.183699826399485

Epoch: 6| Step: 11
Training loss: 0.8922291994094849
Validation loss: 2.153216620286306

Epoch: 6| Step: 12
Training loss: 0.7238917350769043
Validation loss: 2.152013083299001

Epoch: 6| Step: 13
Training loss: 0.6109472513198853
Validation loss: 2.163952569166819

Epoch: 374| Step: 0
Training loss: 0.7867556214332581
Validation loss: 2.1862123211224875

Epoch: 6| Step: 1
Training loss: 0.3577430844306946
Validation loss: 2.2030805945396423

Epoch: 6| Step: 2
Training loss: 0.9887442588806152
Validation loss: 2.179494778315226

Epoch: 6| Step: 3
Training loss: 0.9155924320220947
Validation loss: 2.221394419670105

Epoch: 6| Step: 4
Training loss: 0.6941293478012085
Validation loss: 2.1739152471224465

Epoch: 6| Step: 5
Training loss: 0.5128801465034485
Validation loss: 2.1849446495374045

Epoch: 6| Step: 6
Training loss: 0.7260010242462158
Validation loss: 2.191708246866862

Epoch: 6| Step: 7
Training loss: 0.6647989749908447
Validation loss: 2.168277680873871

Epoch: 6| Step: 8
Training loss: 0.8405898213386536
Validation loss: 2.1557835936546326

Epoch: 6| Step: 9
Training loss: 1.2489748001098633
Validation loss: 2.156897703806559

Epoch: 6| Step: 10
Training loss: 0.7223528623580933
Validation loss: 2.120650808016459

Epoch: 6| Step: 11
Training loss: 0.7465282678604126
Validation loss: 2.157370150089264

Epoch: 6| Step: 12
Training loss: 1.4724315404891968
Validation loss: 2.160984973112742

Epoch: 6| Step: 13
Training loss: 1.095328688621521
Validation loss: 2.195526599884033

Epoch: 375| Step: 0
Training loss: 0.9347169995307922
Validation loss: 2.174397647380829

Epoch: 6| Step: 1
Training loss: 0.3894736170768738
Validation loss: 2.134201963742574

Epoch: 6| Step: 2
Training loss: 0.6985730528831482
Validation loss: 2.1891400814056396

Epoch: 6| Step: 3
Training loss: 0.9889535903930664
Validation loss: 2.1530170838038125

Epoch: 6| Step: 4
Training loss: 1.232426643371582
Validation loss: 2.159958223501841

Epoch: 6| Step: 5
Training loss: 0.6735222935676575
Validation loss: 2.1771716276804605

Epoch: 6| Step: 6
Training loss: 0.8714019060134888
Validation loss: 2.173646092414856

Epoch: 6| Step: 7
Training loss: 1.1574640274047852
Validation loss: 2.156192640463511

Epoch: 6| Step: 8
Training loss: 0.5142395496368408
Validation loss: 2.1933074792226157

Epoch: 6| Step: 9
Training loss: 0.7209978699684143
Validation loss: 2.2382750113805137

Epoch: 6| Step: 10
Training loss: 0.3711281418800354
Validation loss: 2.2399465243021646

Epoch: 6| Step: 11
Training loss: 0.865001916885376
Validation loss: 2.225013236204783

Epoch: 6| Step: 12
Training loss: 0.994997501373291
Validation loss: 2.2310832341512046

Epoch: 6| Step: 13
Training loss: 1.2691422700881958
Validation loss: 2.2326397697130838

Epoch: 376| Step: 0
Training loss: 0.6219730973243713
Validation loss: 2.172485033671061

Epoch: 6| Step: 1
Training loss: 0.420335590839386
Validation loss: 2.189189314842224

Epoch: 6| Step: 2
Training loss: 0.9801207780838013
Validation loss: 2.1727439761161804

Epoch: 6| Step: 3
Training loss: 0.3643966615200043
Validation loss: 2.2171201507250466

Epoch: 6| Step: 4
Training loss: 0.9032789468765259
Validation loss: 2.1756537755330405

Epoch: 6| Step: 5
Training loss: 0.8633441925048828
Validation loss: 2.16679455836614

Epoch: 6| Step: 6
Training loss: 1.6999926567077637
Validation loss: 2.150517463684082

Epoch: 6| Step: 7
Training loss: 0.6084549427032471
Validation loss: 2.160008351008097

Epoch: 6| Step: 8
Training loss: 0.4013388454914093
Validation loss: 2.15380064646403

Epoch: 6| Step: 9
Training loss: 0.44812214374542236
Validation loss: 2.185027082761129

Epoch: 6| Step: 10
Training loss: 0.6486414670944214
Validation loss: 2.1606223781903586

Epoch: 6| Step: 11
Training loss: 1.2001473903656006
Validation loss: 2.164584994316101

Epoch: 6| Step: 12
Training loss: 0.8916294574737549
Validation loss: 2.1422763069470725

Epoch: 6| Step: 13
Training loss: 0.7041903734207153
Validation loss: 2.1478381951649985

Epoch: 377| Step: 0
Training loss: 0.556751012802124
Validation loss: 2.1651721199353537

Epoch: 6| Step: 1
Training loss: 0.588826596736908
Validation loss: 2.194104850292206

Epoch: 6| Step: 2
Training loss: 0.3985424339771271
Validation loss: 2.2086902062098184

Epoch: 6| Step: 3
Training loss: 0.7310240268707275
Validation loss: 2.1611456076304116

Epoch: 6| Step: 4
Training loss: 1.0826175212860107
Validation loss: 2.146016279856364

Epoch: 6| Step: 5
Training loss: 1.0152995586395264
Validation loss: 2.130915939807892

Epoch: 6| Step: 6
Training loss: 0.8104979395866394
Validation loss: 2.1313938895861306

Epoch: 6| Step: 7
Training loss: 0.6465905904769897
Validation loss: 2.14841361840566

Epoch: 6| Step: 8
Training loss: 0.9139881134033203
Validation loss: 2.1133145292599997

Epoch: 6| Step: 9
Training loss: 0.5713822245597839
Validation loss: 2.180372933546702

Epoch: 6| Step: 10
Training loss: 0.4573962092399597
Validation loss: 2.18125973145167

Epoch: 6| Step: 11
Training loss: 1.5132391452789307
Validation loss: 2.177665034929911

Epoch: 6| Step: 12
Training loss: 0.8956891298294067
Validation loss: 2.207432508468628

Epoch: 6| Step: 13
Training loss: 0.8626092672348022
Validation loss: 2.2293551166852317

Epoch: 378| Step: 0
Training loss: 0.9611985683441162
Validation loss: 2.2378994623819985

Epoch: 6| Step: 1
Training loss: 1.1289923191070557
Validation loss: 2.249596575895945

Epoch: 6| Step: 2
Training loss: 0.7210326194763184
Validation loss: 2.142007132371267

Epoch: 6| Step: 3
Training loss: 0.8581864833831787
Validation loss: 2.152730385462443

Epoch: 6| Step: 4
Training loss: 1.2357183694839478
Validation loss: 2.159087896347046

Epoch: 6| Step: 5
Training loss: 1.1375972032546997
Validation loss: 2.1655349731445312

Epoch: 6| Step: 6
Training loss: 1.505511999130249
Validation loss: 2.181282182534536

Epoch: 6| Step: 7
Training loss: 1.2052669525146484
Validation loss: 2.1685781876246133

Epoch: 6| Step: 8
Training loss: 1.644156813621521
Validation loss: 2.13345605134964

Epoch: 6| Step: 9
Training loss: 0.7128279209136963
Validation loss: 2.146634797255198

Epoch: 6| Step: 10
Training loss: 0.7251344919204712
Validation loss: 2.1966272791226706

Epoch: 6| Step: 11
Training loss: 1.1129989624023438
Validation loss: 2.2617792884508767

Epoch: 6| Step: 12
Training loss: 1.2303860187530518
Validation loss: 2.3025374015172324

Epoch: 6| Step: 13
Training loss: 0.9230116605758667
Validation loss: 2.2701550722122192

Epoch: 379| Step: 0
Training loss: 1.0725986957550049
Validation loss: 2.2295750975608826

Epoch: 6| Step: 1
Training loss: 1.4169962406158447
Validation loss: 2.232840359210968

Epoch: 6| Step: 2
Training loss: 0.5788607597351074
Validation loss: 2.207300146420797

Epoch: 6| Step: 3
Training loss: 1.1296472549438477
Validation loss: 2.194712499777476

Epoch: 6| Step: 4
Training loss: 0.5243955850601196
Validation loss: 2.2067527572313943

Epoch: 6| Step: 5
Training loss: 1.308445692062378
Validation loss: 2.2182772159576416

Epoch: 6| Step: 6
Training loss: 0.7141103744506836
Validation loss: 2.1923826138178506

Epoch: 6| Step: 7
Training loss: 1.1959316730499268
Validation loss: 2.1780116160710654

Epoch: 6| Step: 8
Training loss: 0.33585020899772644
Validation loss: 2.1697596112887063

Epoch: 6| Step: 9
Training loss: 1.0140185356140137
Validation loss: 2.154077172279358

Epoch: 6| Step: 10
Training loss: 0.8402575254440308
Validation loss: 2.171549399693807

Epoch: 6| Step: 11
Training loss: 0.6615549921989441
Validation loss: 2.1446430484453836

Epoch: 6| Step: 12
Training loss: 0.43003222346305847
Validation loss: 2.2013827562332153

Epoch: 6| Step: 13
Training loss: 0.9013157486915588
Validation loss: 2.2095076044400535

Epoch: 380| Step: 0
Training loss: 0.84283047914505
Validation loss: 2.1820793549219766

Epoch: 6| Step: 1
Training loss: 0.45124244689941406
Validation loss: 2.186077098051707

Epoch: 6| Step: 2
Training loss: 1.8698030710220337
Validation loss: 2.1840075651804605

Epoch: 6| Step: 3
Training loss: 0.7760397791862488
Validation loss: 2.181235353151957

Epoch: 6| Step: 4
Training loss: 0.8198598027229309
Validation loss: 2.200299700101217

Epoch: 6| Step: 5
Training loss: 0.5753116607666016
Validation loss: 2.18976753950119

Epoch: 6| Step: 6
Training loss: 0.7083106637001038
Validation loss: 2.202320079008738

Epoch: 6| Step: 7
Training loss: 0.44298994541168213
Validation loss: 2.222794552644094

Epoch: 6| Step: 8
Training loss: 1.1606285572052002
Validation loss: 2.1921663085619607

Epoch: 6| Step: 9
Training loss: 0.6327660083770752
Validation loss: 2.234817306200663

Epoch: 6| Step: 10
Training loss: 0.4528745412826538
Validation loss: 2.193397502104441

Epoch: 6| Step: 11
Training loss: 1.0517857074737549
Validation loss: 2.18506520986557

Epoch: 6| Step: 12
Training loss: 0.6765495538711548
Validation loss: 2.167868991692861

Epoch: 6| Step: 13
Training loss: 0.5559799671173096
Validation loss: 2.1436317761739097

Epoch: 381| Step: 0
Training loss: 0.4819648861885071
Validation loss: 2.213780919710795

Epoch: 6| Step: 1
Training loss: 0.648849368095398
Validation loss: 2.189566751321157

Epoch: 6| Step: 2
Training loss: 0.7008541226387024
Validation loss: 2.166842599709829

Epoch: 6| Step: 3
Training loss: 1.0543922185897827
Validation loss: 2.0967761675516763

Epoch: 6| Step: 4
Training loss: 0.6556189060211182
Validation loss: 2.1654735008875527

Epoch: 6| Step: 5
Training loss: 0.390636146068573
Validation loss: 2.138973653316498

Epoch: 6| Step: 6
Training loss: 0.7703678011894226
Validation loss: 2.1383144656817117

Epoch: 6| Step: 7
Training loss: 0.6617639064788818
Validation loss: 2.13843564192454

Epoch: 6| Step: 8
Training loss: 0.44899970293045044
Validation loss: 2.1714240312576294

Epoch: 6| Step: 9
Training loss: 0.8272666931152344
Validation loss: 2.1718589862187705

Epoch: 6| Step: 10
Training loss: 0.9481884837150574
Validation loss: 2.119624396165212

Epoch: 6| Step: 11
Training loss: 0.49024567008018494
Validation loss: 2.1667837103207908

Epoch: 6| Step: 12
Training loss: 1.455607533454895
Validation loss: 2.1655842463175454

Epoch: 6| Step: 13
Training loss: 1.1654552221298218
Validation loss: 2.2230769793192544

Epoch: 382| Step: 0
Training loss: 0.7729511857032776
Validation loss: 2.177888790766398

Epoch: 6| Step: 1
Training loss: 0.8870170712471008
Validation loss: 2.211633563041687

Epoch: 6| Step: 2
Training loss: 0.58006751537323
Validation loss: 2.2601990699768066

Epoch: 6| Step: 3
Training loss: 1.0459085702896118
Validation loss: 2.224089562892914

Epoch: 6| Step: 4
Training loss: 0.8691376447677612
Validation loss: 2.2303744554519653

Epoch: 6| Step: 5
Training loss: 0.5462639331817627
Validation loss: 2.1733293732007346

Epoch: 6| Step: 6
Training loss: 0.7765632271766663
Validation loss: 2.1397170225779214

Epoch: 6| Step: 7
Training loss: 0.6813422441482544
Validation loss: 2.1822540760040283

Epoch: 6| Step: 8
Training loss: 1.5026390552520752
Validation loss: 2.1908392906188965

Epoch: 6| Step: 9
Training loss: 0.40571272373199463
Validation loss: 2.168167452017466

Epoch: 6| Step: 10
Training loss: 0.9650882482528687
Validation loss: 2.130130648612976

Epoch: 6| Step: 11
Training loss: 1.2947888374328613
Validation loss: 2.1396929224332175

Epoch: 6| Step: 12
Training loss: 0.36134758591651917
Validation loss: 2.181866407394409

Epoch: 6| Step: 13
Training loss: 0.5075421929359436
Validation loss: 2.1565405329068503

Epoch: 383| Step: 0
Training loss: 0.7634344100952148
Validation loss: 2.1848889787991843

Epoch: 6| Step: 1
Training loss: 0.5285691022872925
Validation loss: 2.2497429649035134

Epoch: 6| Step: 2
Training loss: 1.0514593124389648
Validation loss: 2.222849210103353

Epoch: 6| Step: 3
Training loss: 0.7685251235961914
Validation loss: 2.1862719456354776

Epoch: 6| Step: 4
Training loss: 0.6949219107627869
Validation loss: 2.18194850285848

Epoch: 6| Step: 5
Training loss: 0.725228488445282
Validation loss: 2.162451386451721

Epoch: 6| Step: 6
Training loss: 0.5078941583633423
Validation loss: 2.1688879330952964

Epoch: 6| Step: 7
Training loss: 1.2901567220687866
Validation loss: 2.1272092858950296

Epoch: 6| Step: 8
Training loss: 0.7304346561431885
Validation loss: 2.161789894104004

Epoch: 6| Step: 9
Training loss: 0.8813650608062744
Validation loss: 2.1412876645723977

Epoch: 6| Step: 10
Training loss: 0.4371255040168762
Validation loss: 2.165232499440511

Epoch: 6| Step: 11
Training loss: 0.43189236521720886
Validation loss: 2.17099928855896

Epoch: 6| Step: 12
Training loss: 1.4629343748092651
Validation loss: 2.151468575000763

Epoch: 6| Step: 13
Training loss: 0.4093207120895386
Validation loss: 2.169321894645691

Epoch: 384| Step: 0
Training loss: 0.7964332103729248
Validation loss: 2.1394723653793335

Epoch: 6| Step: 1
Training loss: 0.664944589138031
Validation loss: 2.1195512215296426

Epoch: 6| Step: 2
Training loss: 0.5270853638648987
Validation loss: 2.1618741154670715

Epoch: 6| Step: 3
Training loss: 0.7075135707855225
Validation loss: 2.148391624291738

Epoch: 6| Step: 4
Training loss: 1.2207220792770386
Validation loss: 2.1384438474973044

Epoch: 6| Step: 5
Training loss: 0.5251192450523376
Validation loss: 2.1465255419413247

Epoch: 6| Step: 6
Training loss: 1.0388946533203125
Validation loss: 2.1525146762530007

Epoch: 6| Step: 7
Training loss: 0.6678706407546997
Validation loss: 2.1856881380081177

Epoch: 6| Step: 8
Training loss: 0.6168323755264282
Validation loss: 2.1523595253626504

Epoch: 6| Step: 9
Training loss: 0.48386192321777344
Validation loss: 2.1929398576418557

Epoch: 6| Step: 10
Training loss: 0.9774080514907837
Validation loss: 2.171533207098643

Epoch: 6| Step: 11
Training loss: 1.2430226802825928
Validation loss: 2.2203885515530906

Epoch: 6| Step: 12
Training loss: 0.5448112487792969
Validation loss: 2.2189545234044394

Epoch: 6| Step: 13
Training loss: 0.6725354194641113
Validation loss: 2.1813925902048745

Epoch: 385| Step: 0
Training loss: 0.39725834131240845
Validation loss: 2.2056290109952292

Epoch: 6| Step: 1
Training loss: 0.34397804737091064
Validation loss: 2.2049192984898887

Epoch: 6| Step: 2
Training loss: 0.5448506474494934
Validation loss: 2.1895916859308877

Epoch: 6| Step: 3
Training loss: 0.524757981300354
Validation loss: 2.1479441126187644

Epoch: 6| Step: 4
Training loss: 0.4011238217353821
Validation loss: 2.1604692141215005

Epoch: 6| Step: 5
Training loss: 1.1723462343215942
Validation loss: 2.177580952644348

Epoch: 6| Step: 6
Training loss: 1.2223734855651855
Validation loss: 2.1853904724121094

Epoch: 6| Step: 7
Training loss: 1.0402132272720337
Validation loss: 2.1866034468015036

Epoch: 6| Step: 8
Training loss: 0.9417366981506348
Validation loss: 2.236610690752665

Epoch: 6| Step: 9
Training loss: 0.9529457092285156
Validation loss: 2.2116270462671914

Epoch: 6| Step: 10
Training loss: 0.6850447058677673
Validation loss: 2.179165502389272

Epoch: 6| Step: 11
Training loss: 0.7588386535644531
Validation loss: 2.157045900821686

Epoch: 6| Step: 12
Training loss: 0.9052697420120239
Validation loss: 2.122442881266276

Epoch: 6| Step: 13
Training loss: 0.7491582632064819
Validation loss: 2.147781550884247

Epoch: 386| Step: 0
Training loss: 0.47347956895828247
Validation loss: 2.113440136114756

Epoch: 6| Step: 1
Training loss: 0.6745456457138062
Validation loss: 2.1742708683013916

Epoch: 6| Step: 2
Training loss: 0.7676281332969666
Validation loss: 2.1847203373908997

Epoch: 6| Step: 3
Training loss: 0.6473771333694458
Validation loss: 2.140513062477112

Epoch: 6| Step: 4
Training loss: 0.63169264793396
Validation loss: 2.166848103205363

Epoch: 6| Step: 5
Training loss: 0.8120992183685303
Validation loss: 2.2135495940844216

Epoch: 6| Step: 6
Training loss: 0.6026445031166077
Validation loss: 2.1362765034039817

Epoch: 6| Step: 7
Training loss: 0.7490234375
Validation loss: 2.1608163913091025

Epoch: 6| Step: 8
Training loss: 0.6083908081054688
Validation loss: 2.152399718761444

Epoch: 6| Step: 9
Training loss: 0.8999965190887451
Validation loss: 2.1184029579162598

Epoch: 6| Step: 10
Training loss: 0.6402282118797302
Validation loss: 2.1670857469240823

Epoch: 6| Step: 11
Training loss: 0.9389476776123047
Validation loss: 2.146045426527659

Epoch: 6| Step: 12
Training loss: 0.9873735904693604
Validation loss: 2.161081393559774

Epoch: 6| Step: 13
Training loss: 0.7439348697662354
Validation loss: 2.149453123410543

Epoch: 387| Step: 0
Training loss: 0.5852587819099426
Validation loss: 2.1425190766652427

Epoch: 6| Step: 1
Training loss: 0.6526893973350525
Validation loss: 2.2392455339431763

Epoch: 6| Step: 2
Training loss: 0.7561150193214417
Validation loss: 2.1872804363568625

Epoch: 6| Step: 3
Training loss: 0.6731259822845459
Validation loss: 2.2227184176445007

Epoch: 6| Step: 4
Training loss: 0.7642089128494263
Validation loss: 2.2003167470296225

Epoch: 6| Step: 5
Training loss: 0.5581552982330322
Validation loss: 2.1808482011159263

Epoch: 6| Step: 6
Training loss: 0.7985625267028809
Validation loss: 2.2110212643941245

Epoch: 6| Step: 7
Training loss: 0.8287432789802551
Validation loss: 2.1940064628918967

Epoch: 6| Step: 8
Training loss: 0.564745306968689
Validation loss: 2.1988025506337485

Epoch: 6| Step: 9
Training loss: 0.9916965961456299
Validation loss: 2.2193493445714316

Epoch: 6| Step: 10
Training loss: 0.3979605734348297
Validation loss: 2.1895326574643454

Epoch: 6| Step: 11
Training loss: 0.6017670631408691
Validation loss: 2.1987274885177612

Epoch: 6| Step: 12
Training loss: 1.2615423202514648
Validation loss: 2.2234721978505454

Epoch: 6| Step: 13
Training loss: 0.43779128789901733
Validation loss: 2.1993931929270425

Epoch: 388| Step: 0
Training loss: 0.8136851787567139
Validation loss: 2.194365302721659

Epoch: 6| Step: 1
Training loss: 1.0712873935699463
Validation loss: 2.1673747301101685

Epoch: 6| Step: 2
Training loss: 0.5225440263748169
Validation loss: 2.1803272366523743

Epoch: 6| Step: 3
Training loss: 0.7401369214057922
Validation loss: 2.1971060037612915

Epoch: 6| Step: 4
Training loss: 0.5153051614761353
Validation loss: 2.1725231607755027

Epoch: 6| Step: 5
Training loss: 0.5432811379432678
Validation loss: 2.1756775975227356

Epoch: 6| Step: 6
Training loss: 0.5705755352973938
Validation loss: 2.1844470500946045

Epoch: 6| Step: 7
Training loss: 0.7263269424438477
Validation loss: 2.218929131825765

Epoch: 6| Step: 8
Training loss: 0.6338720917701721
Validation loss: 2.1813195745150247

Epoch: 6| Step: 9
Training loss: 0.9451607465744019
Validation loss: 2.185057739416758

Epoch: 6| Step: 10
Training loss: 0.9176580905914307
Validation loss: 2.1783741315205893

Epoch: 6| Step: 11
Training loss: 0.7046645879745483
Validation loss: 2.1673541267712912

Epoch: 6| Step: 12
Training loss: 0.704604983329773
Validation loss: 2.1486776471138

Epoch: 6| Step: 13
Training loss: 0.5459743142127991
Validation loss: 2.141529599825541

Epoch: 389| Step: 0
Training loss: 0.6444889903068542
Validation loss: 2.1852285861968994

Epoch: 6| Step: 1
Training loss: 0.2883005440235138
Validation loss: 2.1801310777664185

Epoch: 6| Step: 2
Training loss: 1.0374284982681274
Validation loss: 2.2067924340566

Epoch: 6| Step: 3
Training loss: 0.43058836460113525
Validation loss: 2.14271679520607

Epoch: 6| Step: 4
Training loss: 0.7512466907501221
Validation loss: 2.1302978793780007

Epoch: 6| Step: 5
Training loss: 0.5944845676422119
Validation loss: 2.177659253279368

Epoch: 6| Step: 6
Training loss: 1.0343388319015503
Validation loss: 2.1295291582743325

Epoch: 6| Step: 7
Training loss: 0.42552459239959717
Validation loss: 2.1211023330688477

Epoch: 6| Step: 8
Training loss: 0.9817458391189575
Validation loss: 2.1043759981791177

Epoch: 6| Step: 9
Training loss: 1.0219082832336426
Validation loss: 2.057147979736328

Epoch: 6| Step: 10
Training loss: 0.5023637413978577
Validation loss: 2.1162889202435813

Epoch: 6| Step: 11
Training loss: 0.8572355508804321
Validation loss: 2.1178319851557412

Epoch: 6| Step: 12
Training loss: 0.8754223585128784
Validation loss: 2.1120291352272034

Epoch: 6| Step: 13
Training loss: 0.833830714225769
Validation loss: 2.151148021221161

Epoch: 390| Step: 0
Training loss: 0.8185626268386841
Validation loss: 2.1138165394465127

Epoch: 6| Step: 1
Training loss: 0.5370478630065918
Validation loss: 2.1392797231674194

Epoch: 6| Step: 2
Training loss: 0.7177022695541382
Validation loss: 2.105739931265513

Epoch: 6| Step: 3
Training loss: 0.6722228527069092
Validation loss: 2.1370208263397217

Epoch: 6| Step: 4
Training loss: 0.8484081625938416
Validation loss: 2.166298270225525

Epoch: 6| Step: 5
Training loss: 0.6623761653900146
Validation loss: 2.166574716567993

Epoch: 6| Step: 6
Training loss: 0.6263352036476135
Validation loss: 2.17497718334198

Epoch: 6| Step: 7
Training loss: 1.4108543395996094
Validation loss: 2.1885071992874146

Epoch: 6| Step: 8
Training loss: 0.7954650521278381
Validation loss: 2.1414247155189514

Epoch: 6| Step: 9
Training loss: 0.604971170425415
Validation loss: 2.174119770526886

Epoch: 6| Step: 10
Training loss: 0.5724714994430542
Validation loss: 2.147136410077413

Epoch: 6| Step: 11
Training loss: 0.31722956895828247
Validation loss: 2.1557130416234336

Epoch: 6| Step: 12
Training loss: 0.9268240928649902
Validation loss: 2.183669904867808

Epoch: 6| Step: 13
Training loss: 1.0752782821655273
Validation loss: 2.153934061527252

Epoch: 391| Step: 0
Training loss: 0.5999088287353516
Validation loss: 2.1694523096084595

Epoch: 6| Step: 1
Training loss: 0.6686584949493408
Validation loss: 2.224776248137156

Epoch: 6| Step: 2
Training loss: 0.6981368064880371
Validation loss: 2.15481698513031

Epoch: 6| Step: 3
Training loss: 0.38868990540504456
Validation loss: 2.2024382750193277

Epoch: 6| Step: 4
Training loss: 1.0424902439117432
Validation loss: 2.1969156861305237

Epoch: 6| Step: 5
Training loss: 1.1364774703979492
Validation loss: 2.13952229420344

Epoch: 6| Step: 6
Training loss: 1.150479793548584
Validation loss: 2.19602370262146

Epoch: 6| Step: 7
Training loss: 0.5469356179237366
Validation loss: 2.1267950534820557

Epoch: 6| Step: 8
Training loss: 0.7572699189186096
Validation loss: 2.1831504901250205

Epoch: 6| Step: 9
Training loss: 0.4780605137348175
Validation loss: 2.121511240800222

Epoch: 6| Step: 10
Training loss: 0.9377731084823608
Validation loss: 2.178936183452606

Epoch: 6| Step: 11
Training loss: 0.4398036599159241
Validation loss: 2.1857387820879617

Epoch: 6| Step: 12
Training loss: 0.4514152705669403
Validation loss: 2.200462738672892

Epoch: 6| Step: 13
Training loss: 0.7634966373443604
Validation loss: 2.1546510656674704

Epoch: 392| Step: 0
Training loss: 0.4970572888851166
Validation loss: 2.1615076661109924

Epoch: 6| Step: 1
Training loss: 0.3749673366546631
Validation loss: 2.1616530815760293

Epoch: 6| Step: 2
Training loss: 0.7670484781265259
Validation loss: 2.166037698586782

Epoch: 6| Step: 3
Training loss: 0.5439663529396057
Validation loss: 2.1676189303398132

Epoch: 6| Step: 4
Training loss: 1.0847864151000977
Validation loss: 2.167022248109182

Epoch: 6| Step: 5
Training loss: 0.8112735152244568
Validation loss: 2.1364605824152627

Epoch: 6| Step: 6
Training loss: 1.001490592956543
Validation loss: 2.1758102973302207

Epoch: 6| Step: 7
Training loss: 1.2124748229980469
Validation loss: 2.1476597984631858

Epoch: 6| Step: 8
Training loss: 0.7446957230567932
Validation loss: 2.1518067916234336

Epoch: 6| Step: 9
Training loss: 0.6017457842826843
Validation loss: 2.2060935298601785

Epoch: 6| Step: 10
Training loss: 0.51296067237854
Validation loss: 2.214983503023783

Epoch: 6| Step: 11
Training loss: 0.7713255882263184
Validation loss: 2.1802145640055337

Epoch: 6| Step: 12
Training loss: 0.32227587699890137
Validation loss: 2.208334962526957

Epoch: 6| Step: 13
Training loss: 0.6559094190597534
Validation loss: 2.1808366775512695

Epoch: 393| Step: 0
Training loss: 0.5280089378356934
Validation loss: 2.1657064954439798

Epoch: 6| Step: 1
Training loss: 0.7815554738044739
Validation loss: 2.156572997570038

Epoch: 6| Step: 2
Training loss: 0.8029009103775024
Validation loss: 2.157885948816935

Epoch: 6| Step: 3
Training loss: 0.5894869565963745
Validation loss: 2.1460445125897727

Epoch: 6| Step: 4
Training loss: 0.9497259855270386
Validation loss: 2.174228290716807

Epoch: 6| Step: 5
Training loss: 1.281181812286377
Validation loss: 2.2173104683558145

Epoch: 6| Step: 6
Training loss: 0.45094189047813416
Validation loss: 2.2120673060417175

Epoch: 6| Step: 7
Training loss: 0.9167774319648743
Validation loss: 2.2231351931889853

Epoch: 6| Step: 8
Training loss: 0.5833438634872437
Validation loss: 2.2771755854288735

Epoch: 6| Step: 9
Training loss: 0.7597936987876892
Validation loss: 2.2361531853675842

Epoch: 6| Step: 10
Training loss: 0.7711941003799438
Validation loss: 2.2547483444213867

Epoch: 6| Step: 11
Training loss: 0.6593062877655029
Validation loss: 2.2144260803858438

Epoch: 6| Step: 12
Training loss: 0.7595515847206116
Validation loss: 2.2034636735916138

Epoch: 6| Step: 13
Training loss: 0.45316457748413086
Validation loss: 2.168524146080017

Epoch: 394| Step: 0
Training loss: 0.7161576151847839
Validation loss: 2.2411293188730874

Epoch: 6| Step: 1
Training loss: 0.7310488224029541
Validation loss: 2.173884610335032

Epoch: 6| Step: 2
Training loss: 0.6893247365951538
Validation loss: 2.223256270090739

Epoch: 6| Step: 3
Training loss: 0.7794689536094666
Validation loss: 2.2172465920448303

Epoch: 6| Step: 4
Training loss: 0.8267966508865356
Validation loss: 2.2394452492396035

Epoch: 6| Step: 5
Training loss: 0.5044094324111938
Validation loss: 2.240311026573181

Epoch: 6| Step: 6
Training loss: 0.9316140413284302
Validation loss: 2.2424837748209634

Epoch: 6| Step: 7
Training loss: 0.5902397632598877
Validation loss: 2.2220768332481384

Epoch: 6| Step: 8
Training loss: 0.589733362197876
Validation loss: 2.22932501633962

Epoch: 6| Step: 9
Training loss: 0.5668346881866455
Validation loss: 2.183599829673767

Epoch: 6| Step: 10
Training loss: 0.5952157974243164
Validation loss: 2.1773314674695334

Epoch: 6| Step: 11
Training loss: 0.47785401344299316
Validation loss: 2.1814275979995728

Epoch: 6| Step: 12
Training loss: 0.9259734749794006
Validation loss: 2.22781769434611

Epoch: 6| Step: 13
Training loss: 0.7509832382202148
Validation loss: 2.2107941309611

Epoch: 395| Step: 0
Training loss: 0.5242313742637634
Validation loss: 2.2364858587582908

Epoch: 6| Step: 1
Training loss: 0.6329571008682251
Validation loss: 2.230284591515859

Epoch: 6| Step: 2
Training loss: 1.0215152502059937
Validation loss: 2.242171068986257

Epoch: 6| Step: 3
Training loss: 1.0776207447052002
Validation loss: 2.294227878252665

Epoch: 6| Step: 4
Training loss: 0.8920208215713501
Validation loss: 2.300829807917277

Epoch: 6| Step: 5
Training loss: 0.7931743860244751
Validation loss: 2.2879044810930886

Epoch: 6| Step: 6
Training loss: 0.3379104733467102
Validation loss: 2.206412116686503

Epoch: 6| Step: 7
Training loss: 0.6881580352783203
Validation loss: 2.2397990624109902

Epoch: 6| Step: 8
Training loss: 0.9885067343711853
Validation loss: 2.2258050640424094

Epoch: 6| Step: 9
Training loss: 0.5242742300033569
Validation loss: 2.1652998129526773

Epoch: 6| Step: 10
Training loss: 0.673900842666626
Validation loss: 2.1908236742019653

Epoch: 6| Step: 11
Training loss: 0.4298199415206909
Validation loss: 2.162055710951487

Epoch: 6| Step: 12
Training loss: 0.45325592160224915
Validation loss: 2.165300806363424

Epoch: 6| Step: 13
Training loss: 0.9478427171707153
Validation loss: 2.17849071820577

Epoch: 396| Step: 0
Training loss: 0.5087239742279053
Validation loss: 2.2231194376945496

Epoch: 6| Step: 1
Training loss: 1.050821304321289
Validation loss: 2.1510206858317056

Epoch: 6| Step: 2
Training loss: 1.0588722229003906
Validation loss: 2.1692712704340615

Epoch: 6| Step: 3
Training loss: 0.35126033425331116
Validation loss: 2.1925328373908997

Epoch: 6| Step: 4
Training loss: 0.4712119698524475
Validation loss: 2.1900720794995627

Epoch: 6| Step: 5
Training loss: 0.9406501650810242
Validation loss: 2.1729762951533

Epoch: 6| Step: 6
Training loss: 0.6057138442993164
Validation loss: 2.1925205190976462

Epoch: 6| Step: 7
Training loss: 0.8322985172271729
Validation loss: 2.1330877343813577

Epoch: 6| Step: 8
Training loss: 0.7378271818161011
Validation loss: 2.186231275399526

Epoch: 6| Step: 9
Training loss: 0.4082913398742676
Validation loss: 2.169725855191549

Epoch: 6| Step: 10
Training loss: 0.6404157280921936
Validation loss: 2.163830359776815

Epoch: 6| Step: 11
Training loss: 1.065557599067688
Validation loss: 2.1869863669077554

Epoch: 6| Step: 12
Training loss: 0.4297711253166199
Validation loss: 2.1202064156532288

Epoch: 6| Step: 13
Training loss: 0.5895709991455078
Validation loss: 2.131770054499308

Epoch: 397| Step: 0
Training loss: 1.199394702911377
Validation loss: 2.175069789091746

Epoch: 6| Step: 1
Training loss: 0.7332289218902588
Validation loss: 2.1589505871136985

Epoch: 6| Step: 2
Training loss: 0.5828051567077637
Validation loss: 2.1669729749361673

Epoch: 6| Step: 3
Training loss: 0.5036346912384033
Validation loss: 2.1733899116516113

Epoch: 6| Step: 4
Training loss: 0.4556151032447815
Validation loss: 2.128412743409475

Epoch: 6| Step: 5
Training loss: 0.8860036730766296
Validation loss: 2.206355094909668

Epoch: 6| Step: 6
Training loss: 0.9435499906539917
Validation loss: 2.200781285762787

Epoch: 6| Step: 7
Training loss: 0.6001768112182617
Validation loss: 2.21073587735494

Epoch: 6| Step: 8
Training loss: 0.48519182205200195
Validation loss: 2.210725466410319

Epoch: 6| Step: 9
Training loss: 0.3829197883605957
Validation loss: 2.170483191808065

Epoch: 6| Step: 10
Training loss: 0.6604745388031006
Validation loss: 2.1981860200564065

Epoch: 6| Step: 11
Training loss: 0.6863148212432861
Validation loss: 2.1614314119021096

Epoch: 6| Step: 12
Training loss: 0.5758272409439087
Validation loss: 2.1769530177116394

Epoch: 6| Step: 13
Training loss: 0.9100099802017212
Validation loss: 2.162287394205729

Epoch: 398| Step: 0
Training loss: 0.898186445236206
Validation loss: 2.1578251918156943

Epoch: 6| Step: 1
Training loss: 0.5401319265365601
Validation loss: 2.162966867287954

Epoch: 6| Step: 2
Training loss: 0.6621264815330505
Validation loss: 2.1920814514160156

Epoch: 6| Step: 3
Training loss: 0.9233205318450928
Validation loss: 2.1712191303571067

Epoch: 6| Step: 4
Training loss: 0.4432988166809082
Validation loss: 2.0993674794832864

Epoch: 6| Step: 5
Training loss: 0.8282053470611572
Validation loss: 2.211406151453654

Epoch: 6| Step: 6
Training loss: 0.31696006655693054
Validation loss: 2.188357969125112

Epoch: 6| Step: 7
Training loss: 0.23490789532661438
Validation loss: 2.200886527697245

Epoch: 6| Step: 8
Training loss: 0.4368079602718353
Validation loss: 2.1680212219556174

Epoch: 6| Step: 9
Training loss: 0.9969727396965027
Validation loss: 2.167619268099467

Epoch: 6| Step: 10
Training loss: 0.7800709009170532
Validation loss: 2.19570263226827

Epoch: 6| Step: 11
Training loss: 0.7949951887130737
Validation loss: 2.153642197450002

Epoch: 6| Step: 12
Training loss: 0.48516181111335754
Validation loss: 2.132541080315908

Epoch: 6| Step: 13
Training loss: 0.7019566297531128
Validation loss: 2.138976573944092

Epoch: 399| Step: 0
Training loss: 0.5623993873596191
Validation loss: 2.1993677417437234

Epoch: 6| Step: 1
Training loss: 0.5516501665115356
Validation loss: 2.1715622345606485

Epoch: 6| Step: 2
Training loss: 0.699419379234314
Validation loss: 2.161983549594879

Epoch: 6| Step: 3
Training loss: 0.8118457794189453
Validation loss: 2.1770004431406655

Epoch: 6| Step: 4
Training loss: 0.40023165941238403
Validation loss: 2.193606376647949

Epoch: 6| Step: 5
Training loss: 0.4674365222454071
Validation loss: 2.203185041745504

Epoch: 6| Step: 6
Training loss: 0.8173730373382568
Validation loss: 2.1831865708033242

Epoch: 6| Step: 7
Training loss: 1.001220941543579
Validation loss: 2.145587146282196

Epoch: 6| Step: 8
Training loss: 0.45215651392936707
Validation loss: 2.1778765122095742

Epoch: 6| Step: 9
Training loss: 0.718912661075592
Validation loss: 2.178828159968058

Epoch: 6| Step: 10
Training loss: 0.5231850147247314
Validation loss: 2.1647837162017822

Epoch: 6| Step: 11
Training loss: 0.5317985415458679
Validation loss: 2.1948664784431458

Epoch: 6| Step: 12
Training loss: 0.7161662578582764
Validation loss: 2.174871246019999

Epoch: 6| Step: 13
Training loss: 0.5279631614685059
Validation loss: 2.1778324246406555

Epoch: 400| Step: 0
Training loss: 0.8074713945388794
Validation loss: 2.1721542874972024

Epoch: 6| Step: 1
Training loss: 0.5208297371864319
Validation loss: 2.1445926825205484

Epoch: 6| Step: 2
Training loss: 0.6463841795921326
Validation loss: 2.1577958265940347

Epoch: 6| Step: 3
Training loss: 0.7202927470207214
Validation loss: 2.1653956969579062

Epoch: 6| Step: 4
Training loss: 0.5696943998336792
Validation loss: 2.1432385643323264

Epoch: 6| Step: 5
Training loss: 0.6726051568984985
Validation loss: 2.189089516798655

Epoch: 6| Step: 6
Training loss: 0.48573654890060425
Validation loss: 2.1883814930915833

Epoch: 6| Step: 7
Training loss: 0.8668702840805054
Validation loss: 2.146217664082845

Epoch: 6| Step: 8
Training loss: 0.5820217728614807
Validation loss: 2.164475739002228

Epoch: 6| Step: 9
Training loss: 0.5347860455513
Validation loss: 2.167278508345286

Epoch: 6| Step: 10
Training loss: 0.8627785444259644
Validation loss: 2.2212762435277305

Epoch: 6| Step: 11
Training loss: 0.44996291399002075
Validation loss: 2.2299658060073853

Epoch: 6| Step: 12
Training loss: 0.8628256320953369
Validation loss: 2.1931450366973877

Epoch: 6| Step: 13
Training loss: 0.37098950147628784
Validation loss: 2.181993782520294

Epoch: 401| Step: 0
Training loss: 0.7469427585601807
Validation loss: 2.173770308494568

Epoch: 6| Step: 1
Training loss: 0.46365657448768616
Validation loss: 2.1478916009267173

Epoch: 6| Step: 2
Training loss: 0.3401194214820862
Validation loss: 2.170209268728892

Epoch: 6| Step: 3
Training loss: 0.5822279453277588
Validation loss: 2.1797313690185547

Epoch: 6| Step: 4
Training loss: 0.9674475193023682
Validation loss: 2.200401326020559

Epoch: 6| Step: 5
Training loss: 0.9312646389007568
Validation loss: 2.233113944530487

Epoch: 6| Step: 6
Training loss: 0.5683894753456116
Validation loss: 2.1829008062680564

Epoch: 6| Step: 7
Training loss: 0.5090843439102173
Validation loss: 2.208978255589803

Epoch: 6| Step: 8
Training loss: 0.9401448965072632
Validation loss: 2.2045257886250815

Epoch: 6| Step: 9
Training loss: 0.5490525960922241
Validation loss: 2.2171696027119956

Epoch: 6| Step: 10
Training loss: 0.41343140602111816
Validation loss: 2.149125357468923

Epoch: 6| Step: 11
Training loss: 0.8306216597557068
Validation loss: 2.1385650436083474

Epoch: 6| Step: 12
Training loss: 0.4846210777759552
Validation loss: 2.167047123114268

Epoch: 6| Step: 13
Training loss: 0.9424957036972046
Validation loss: 2.1747156381607056

Epoch: 402| Step: 0
Training loss: 0.7394908666610718
Validation loss: 2.172756314277649

Epoch: 6| Step: 1
Training loss: 0.49581846594810486
Validation loss: 2.153929034868876

Epoch: 6| Step: 2
Training loss: 0.6208246946334839
Validation loss: 2.1562703251838684

Epoch: 6| Step: 3
Training loss: 0.738614559173584
Validation loss: 2.1934310595194497

Epoch: 6| Step: 4
Training loss: 1.0188724994659424
Validation loss: 2.164185384909312

Epoch: 6| Step: 5
Training loss: 0.4186301827430725
Validation loss: 2.1296250025431314

Epoch: 6| Step: 6
Training loss: 0.6527789831161499
Validation loss: 2.1240808963775635

Epoch: 6| Step: 7
Training loss: 0.47904670238494873
Validation loss: 2.1598554849624634

Epoch: 6| Step: 8
Training loss: 0.6195101737976074
Validation loss: 2.1818752686182656

Epoch: 6| Step: 9
Training loss: 0.4619365334510803
Validation loss: 2.1748826106389365

Epoch: 6| Step: 10
Training loss: 0.3132919669151306
Validation loss: 2.1792392333348594

Epoch: 6| Step: 11
Training loss: 0.6983160972595215
Validation loss: 2.1478116313616433

Epoch: 6| Step: 12
Training loss: 0.9995989799499512
Validation loss: 2.143662750720978

Epoch: 6| Step: 13
Training loss: 0.6479895710945129
Validation loss: 2.155616283416748

Epoch: 403| Step: 0
Training loss: 0.8131306767463684
Validation loss: 2.1618278423945108

Epoch: 6| Step: 1
Training loss: 0.6009243726730347
Validation loss: 2.1298241019248962

Epoch: 6| Step: 2
Training loss: 0.4571768343448639
Validation loss: 2.1320074597994485

Epoch: 6| Step: 3
Training loss: 1.0582549571990967
Validation loss: 2.103231926759084

Epoch: 6| Step: 4
Training loss: 0.41117894649505615
Validation loss: 2.1162577470143638

Epoch: 6| Step: 5
Training loss: 0.8298065066337585
Validation loss: 2.1324300169944763

Epoch: 6| Step: 6
Training loss: 0.6048007011413574
Validation loss: 2.1185466845830283

Epoch: 6| Step: 7
Training loss: 0.6346334218978882
Validation loss: 2.087875545024872

Epoch: 6| Step: 8
Training loss: 0.7400628328323364
Validation loss: 2.126471698284149

Epoch: 6| Step: 9
Training loss: 0.486333966255188
Validation loss: 2.0486871004104614

Epoch: 6| Step: 10
Training loss: 0.6458757519721985
Validation loss: 2.0803898771603904

Epoch: 6| Step: 11
Training loss: 0.7442651391029358
Validation loss: 2.143680910269419

Epoch: 6| Step: 12
Training loss: 0.589564323425293
Validation loss: 2.121173004309336

Epoch: 6| Step: 13
Training loss: 0.7991467714309692
Validation loss: 2.1656814018885293

Epoch: 404| Step: 0
Training loss: 0.8725597262382507
Validation loss: 2.1931596795717874

Epoch: 6| Step: 1
Training loss: 0.6086304783821106
Validation loss: 2.2553624709447226

Epoch: 6| Step: 2
Training loss: 1.1248812675476074
Validation loss: 2.2356712023417153

Epoch: 6| Step: 3
Training loss: 1.0229802131652832
Validation loss: 2.2685904502868652

Epoch: 6| Step: 4
Training loss: 0.6647647619247437
Validation loss: 2.248293856779734

Epoch: 6| Step: 5
Training loss: 0.5026054978370667
Validation loss: 2.2600549459457397

Epoch: 6| Step: 6
Training loss: 0.5390758514404297
Validation loss: 2.214277982711792

Epoch: 6| Step: 7
Training loss: 0.6776974201202393
Validation loss: 2.188926100730896

Epoch: 6| Step: 8
Training loss: 0.8395339250564575
Validation loss: 2.166231691837311

Epoch: 6| Step: 9
Training loss: 1.058402180671692
Validation loss: 2.087637643019358

Epoch: 6| Step: 10
Training loss: 0.4924317002296448
Validation loss: 2.1266218225161233

Epoch: 6| Step: 11
Training loss: 0.4713243842124939
Validation loss: 2.1070050398508706

Epoch: 6| Step: 12
Training loss: 0.7919734716415405
Validation loss: 2.147076586882273

Epoch: 6| Step: 13
Training loss: 0.5049871206283569
Validation loss: 2.1389735539754233

Epoch: 405| Step: 0
Training loss: 0.6401129961013794
Validation loss: 2.12470535437266

Epoch: 6| Step: 1
Training loss: 0.5127993822097778
Validation loss: 2.123750944932302

Epoch: 6| Step: 2
Training loss: 0.47491148114204407
Validation loss: 2.171977718671163

Epoch: 6| Step: 3
Training loss: 0.7600120902061462
Validation loss: 2.1240954995155334

Epoch: 6| Step: 4
Training loss: 0.8495867252349854
Validation loss: 2.1664183934529624

Epoch: 6| Step: 5
Training loss: 0.6488991975784302
Validation loss: 2.179516832033793

Epoch: 6| Step: 6
Training loss: 0.5665839910507202
Validation loss: 2.150970379511515

Epoch: 6| Step: 7
Training loss: 1.3318970203399658
Validation loss: 2.1310283839702606

Epoch: 6| Step: 8
Training loss: 0.5260608196258545
Validation loss: 2.151503801345825

Epoch: 6| Step: 9
Training loss: 0.561175525188446
Validation loss: 2.137182672818502

Epoch: 6| Step: 10
Training loss: 1.0673660039901733
Validation loss: 2.1175219813982644

Epoch: 6| Step: 11
Training loss: 0.5968842506408691
Validation loss: 2.1620726784070334

Epoch: 6| Step: 12
Training loss: 0.38407039642333984
Validation loss: 2.1178292830785117

Epoch: 6| Step: 13
Training loss: 0.8134481906890869
Validation loss: 2.0980823834737143

Epoch: 406| Step: 0
Training loss: 0.30564969778060913
Validation loss: 2.1081893046696982

Epoch: 6| Step: 1
Training loss: 0.6404317021369934
Validation loss: 2.1178586880366006

Epoch: 6| Step: 2
Training loss: 0.4886643886566162
Validation loss: 2.108010172843933

Epoch: 6| Step: 3
Training loss: 0.5693638920783997
Validation loss: 2.134804288546244

Epoch: 6| Step: 4
Training loss: 0.47801506519317627
Validation loss: 2.0947614312171936

Epoch: 6| Step: 5
Training loss: 0.48853054642677307
Validation loss: 2.117934465408325

Epoch: 6| Step: 6
Training loss: 1.064889669418335
Validation loss: 2.1548027396202087

Epoch: 6| Step: 7
Training loss: 0.923033595085144
Validation loss: 2.162972172101339

Epoch: 6| Step: 8
Training loss: 0.5182992815971375
Validation loss: 2.1694291035334268

Epoch: 6| Step: 9
Training loss: 0.6086150407791138
Validation loss: 2.19376277923584

Epoch: 6| Step: 10
Training loss: 0.8968648910522461
Validation loss: 2.1649656295776367

Epoch: 6| Step: 11
Training loss: 0.6183390617370605
Validation loss: 2.16047739982605

Epoch: 6| Step: 12
Training loss: 0.3179015517234802
Validation loss: 2.204083244005839

Epoch: 6| Step: 13
Training loss: 0.9400790929794312
Validation loss: 2.205793003241221

Epoch: 407| Step: 0
Training loss: 0.9092901945114136
Validation loss: 2.1708771785100303

Epoch: 6| Step: 1
Training loss: 0.7521015405654907
Validation loss: 2.2027867635091147

Epoch: 6| Step: 2
Training loss: 0.18666940927505493
Validation loss: 2.1888174215952554

Epoch: 6| Step: 3
Training loss: 0.4565470814704895
Validation loss: 2.2016018629074097

Epoch: 6| Step: 4
Training loss: 0.5131148099899292
Validation loss: 2.1898709734280906

Epoch: 6| Step: 5
Training loss: 0.4859178960323334
Validation loss: 2.139599601427714

Epoch: 6| Step: 6
Training loss: 0.9686521887779236
Validation loss: 2.1772754192352295

Epoch: 6| Step: 7
Training loss: 0.7992627620697021
Validation loss: 2.1710211038589478

Epoch: 6| Step: 8
Training loss: 0.3394305109977722
Validation loss: 2.205827017625173

Epoch: 6| Step: 9
Training loss: 0.4734078049659729
Validation loss: 2.153286894162496

Epoch: 6| Step: 10
Training loss: 0.6412779688835144
Validation loss: 2.1650182207425437

Epoch: 6| Step: 11
Training loss: 0.5435405969619751
Validation loss: 2.1398204962412515

Epoch: 6| Step: 12
Training loss: 0.8583937287330627
Validation loss: 2.134276588757833

Epoch: 6| Step: 13
Training loss: 0.5401938557624817
Validation loss: 2.132949471473694

Epoch: 408| Step: 0
Training loss: 0.8277651071548462
Validation loss: 2.1419521967569985

Epoch: 6| Step: 1
Training loss: 0.6781176924705505
Validation loss: 2.1675442854563394

Epoch: 6| Step: 2
Training loss: 0.9573856592178345
Validation loss: 2.2015005151430764

Epoch: 6| Step: 3
Training loss: 0.25510430335998535
Validation loss: 2.1872840921084085

Epoch: 6| Step: 4
Training loss: 0.44229045510292053
Validation loss: 2.145594894886017

Epoch: 6| Step: 5
Training loss: 0.6570907235145569
Validation loss: 2.13102650642395

Epoch: 6| Step: 6
Training loss: 0.36896902322769165
Validation loss: 2.1860398650169373

Epoch: 6| Step: 7
Training loss: 0.6409028172492981
Validation loss: 2.1070530017217

Epoch: 6| Step: 8
Training loss: 0.5472384691238403
Validation loss: 2.1401447653770447

Epoch: 6| Step: 9
Training loss: 1.1150352954864502
Validation loss: 2.1790056029955545

Epoch: 6| Step: 10
Training loss: 0.6375113725662231
Validation loss: 2.128568867842356

Epoch: 6| Step: 11
Training loss: 0.6028503775596619
Validation loss: 2.1172590454419455

Epoch: 6| Step: 12
Training loss: 0.5610907673835754
Validation loss: 2.098568320274353

Epoch: 6| Step: 13
Training loss: 0.5802730321884155
Validation loss: 2.1432885924975076

Epoch: 409| Step: 0
Training loss: 0.6032869219779968
Validation loss: 2.2095707654953003

Epoch: 6| Step: 1
Training loss: 0.45958197116851807
Validation loss: 2.1811973651250205

Epoch: 6| Step: 2
Training loss: 1.1178791522979736
Validation loss: 2.21030592918396

Epoch: 6| Step: 3
Training loss: 0.6537254452705383
Validation loss: 2.222794512907664

Epoch: 6| Step: 4
Training loss: 0.5406373739242554
Validation loss: 2.2100870609283447

Epoch: 6| Step: 5
Training loss: 0.5524132251739502
Validation loss: 2.1580068469047546

Epoch: 6| Step: 6
Training loss: 0.3419506549835205
Validation loss: 2.178552786509196

Epoch: 6| Step: 7
Training loss: 0.7961866855621338
Validation loss: 2.129038373629252

Epoch: 6| Step: 8
Training loss: 0.7952700853347778
Validation loss: 2.1489065885543823

Epoch: 6| Step: 9
Training loss: 0.8674092292785645
Validation loss: 2.1637595891952515

Epoch: 6| Step: 10
Training loss: 0.334481418132782
Validation loss: 2.138410985469818

Epoch: 6| Step: 11
Training loss: 0.6734176874160767
Validation loss: 2.164932390054067

Epoch: 6| Step: 12
Training loss: 0.2866472005844116
Validation loss: 2.192737658818563

Epoch: 6| Step: 13
Training loss: 0.4526873230934143
Validation loss: 2.1712010900179544

Epoch: 410| Step: 0
Training loss: 0.457091748714447
Validation loss: 2.1484963297843933

Epoch: 6| Step: 1
Training loss: 0.590761125087738
Validation loss: 2.140705327192942

Epoch: 6| Step: 2
Training loss: 0.5944496393203735
Validation loss: 2.1564584771792092

Epoch: 6| Step: 3
Training loss: 0.5464411973953247
Validation loss: 2.1860554814338684

Epoch: 6| Step: 4
Training loss: 0.24274000525474548
Validation loss: 2.1527351339658103

Epoch: 6| Step: 5
Training loss: 0.8893083333969116
Validation loss: 2.1881551146507263

Epoch: 6| Step: 6
Training loss: 0.6827576160430908
Validation loss: 2.1213798920313516

Epoch: 6| Step: 7
Training loss: 0.9746750593185425
Validation loss: 2.123276968797048

Epoch: 6| Step: 8
Training loss: 0.39090847969055176
Validation loss: 2.1461248795191445

Epoch: 6| Step: 9
Training loss: 0.7250884771347046
Validation loss: 2.1549874941507974

Epoch: 6| Step: 10
Training loss: 0.6765190362930298
Validation loss: 2.184937516848246

Epoch: 6| Step: 11
Training loss: 0.47672638297080994
Validation loss: 2.1900049845377603

Epoch: 6| Step: 12
Training loss: 0.4243374168872833
Validation loss: 2.228097935517629

Epoch: 6| Step: 13
Training loss: 0.4638180732727051
Validation loss: 2.191037654876709

Epoch: 411| Step: 0
Training loss: 0.8572860360145569
Validation loss: 2.201226790746053

Epoch: 6| Step: 1
Training loss: 1.0765328407287598
Validation loss: 2.1865591406822205

Epoch: 6| Step: 2
Training loss: 0.48467347025871277
Validation loss: 2.2272210319836936

Epoch: 6| Step: 3
Training loss: 0.5394163727760315
Validation loss: 2.207091510295868

Epoch: 6| Step: 4
Training loss: 0.4039188027381897
Validation loss: 2.1649188796679177

Epoch: 6| Step: 5
Training loss: 0.6717019081115723
Validation loss: 2.1348085006078086

Epoch: 6| Step: 6
Training loss: 0.6594535112380981
Validation loss: 2.142363945643107

Epoch: 6| Step: 7
Training loss: 0.687299370765686
Validation loss: 2.163244664669037

Epoch: 6| Step: 8
Training loss: 0.35631874203681946
Validation loss: 2.182371656099955

Epoch: 6| Step: 9
Training loss: 0.5135989785194397
Validation loss: 2.209464430809021

Epoch: 6| Step: 10
Training loss: 0.6170594096183777
Validation loss: 2.2235830227533975

Epoch: 6| Step: 11
Training loss: 0.6532461643218994
Validation loss: 2.1945828994115195

Epoch: 6| Step: 12
Training loss: 0.8376699686050415
Validation loss: 2.1552937626838684

Epoch: 6| Step: 13
Training loss: 0.5637913942337036
Validation loss: 2.1604660550753274

Epoch: 412| Step: 0
Training loss: 0.8265310525894165
Validation loss: 2.134034276008606

Epoch: 6| Step: 1
Training loss: 0.33577486872673035
Validation loss: 2.105302631855011

Epoch: 6| Step: 2
Training loss: 1.0345557928085327
Validation loss: 2.1375757853190103

Epoch: 6| Step: 3
Training loss: 0.941669225692749
Validation loss: 2.141436596711477

Epoch: 6| Step: 4
Training loss: 0.42061251401901245
Validation loss: 2.1260924339294434

Epoch: 6| Step: 5
Training loss: 0.5735224485397339
Validation loss: 2.1207626461982727

Epoch: 6| Step: 6
Training loss: 0.41631513833999634
Validation loss: 2.171497106552124

Epoch: 6| Step: 7
Training loss: 0.3836473226547241
Validation loss: 2.167059282461802

Epoch: 6| Step: 8
Training loss: 0.4100818336009979
Validation loss: 2.2139200965563455

Epoch: 6| Step: 9
Training loss: 0.5601564049720764
Validation loss: 2.2536927461624146

Epoch: 6| Step: 10
Training loss: 0.6863918304443359
Validation loss: 2.2899278004964194

Epoch: 6| Step: 11
Training loss: 0.5887300372123718
Validation loss: 2.2376497387886047

Epoch: 6| Step: 12
Training loss: 0.6912855505943298
Validation loss: 2.200661599636078

Epoch: 6| Step: 13
Training loss: 0.464517742395401
Validation loss: 2.1953775882720947

Epoch: 413| Step: 0
Training loss: 0.5788916349411011
Validation loss: 2.1696157852808633

Epoch: 6| Step: 1
Training loss: 0.48326951265335083
Validation loss: 2.1350911458333335

Epoch: 6| Step: 2
Training loss: 0.36514273285865784
Validation loss: 2.1102082331975303

Epoch: 6| Step: 3
Training loss: 0.47416603565216064
Validation loss: 2.18328062693278

Epoch: 6| Step: 4
Training loss: 0.3748675584793091
Validation loss: 2.1584283312161765

Epoch: 6| Step: 5
Training loss: 0.5286063551902771
Validation loss: 2.17655082543691

Epoch: 6| Step: 6
Training loss: 0.8637970685958862
Validation loss: 2.2449999252955117

Epoch: 6| Step: 7
Training loss: 0.9140056371688843
Validation loss: 2.253995935122172

Epoch: 6| Step: 8
Training loss: 0.7568487524986267
Validation loss: 2.2295017639795938

Epoch: 6| Step: 9
Training loss: 0.9318276047706604
Validation loss: 2.2080064018567405

Epoch: 6| Step: 10
Training loss: 0.6111348867416382
Validation loss: 2.188640594482422

Epoch: 6| Step: 11
Training loss: 0.6674954891204834
Validation loss: 2.181543012460073

Epoch: 6| Step: 12
Training loss: 0.5798536539077759
Validation loss: 2.1494601567586265

Epoch: 6| Step: 13
Training loss: 0.39009982347488403
Validation loss: 2.1579222281773887

Epoch: 414| Step: 0
Training loss: 0.9377427101135254
Validation loss: 2.1560648679733276

Epoch: 6| Step: 1
Training loss: 0.4065176248550415
Validation loss: 2.1382394234339395

Epoch: 6| Step: 2
Training loss: 0.5081397891044617
Validation loss: 2.1487916111946106

Epoch: 6| Step: 3
Training loss: 0.3779483735561371
Validation loss: 2.11161474386851

Epoch: 6| Step: 4
Training loss: 0.648240327835083
Validation loss: 2.103279689947764

Epoch: 6| Step: 5
Training loss: 0.29555046558380127
Validation loss: 2.1256792147954306

Epoch: 6| Step: 6
Training loss: 0.3995080590248108
Validation loss: 2.134533862272898

Epoch: 6| Step: 7
Training loss: 0.6837977170944214
Validation loss: 2.1690165201822915

Epoch: 6| Step: 8
Training loss: 0.5134400129318237
Validation loss: 2.1539087295532227

Epoch: 6| Step: 9
Training loss: 0.7131471633911133
Validation loss: 2.123269259929657

Epoch: 6| Step: 10
Training loss: 0.3516964912414551
Validation loss: 2.1872010429700217

Epoch: 6| Step: 11
Training loss: 0.5282848477363586
Validation loss: 2.147514740626017

Epoch: 6| Step: 12
Training loss: 0.8564510941505432
Validation loss: 2.139583249886831

Epoch: 6| Step: 13
Training loss: 0.8313746452331543
Validation loss: 2.192583521207174

Epoch: 415| Step: 0
Training loss: 0.47674760222435
Validation loss: 2.1583798925081887

Epoch: 6| Step: 1
Training loss: 0.46169811487197876
Validation loss: 2.199174702167511

Epoch: 6| Step: 2
Training loss: 0.809436559677124
Validation loss: 2.2136951883633933

Epoch: 6| Step: 3
Training loss: 0.7060530185699463
Validation loss: 2.1792248487472534

Epoch: 6| Step: 4
Training loss: 0.6993808150291443
Validation loss: 2.217694083849589

Epoch: 6| Step: 5
Training loss: 0.5428009033203125
Validation loss: 2.2208811044692993

Epoch: 6| Step: 6
Training loss: 0.7429519295692444
Validation loss: 2.179028312365214

Epoch: 6| Step: 7
Training loss: 0.9931094646453857
Validation loss: 2.2058504025141397

Epoch: 6| Step: 8
Training loss: 0.19075244665145874
Validation loss: 2.1297374169031777

Epoch: 6| Step: 9
Training loss: 0.5121236443519592
Validation loss: 2.172805587450663

Epoch: 6| Step: 10
Training loss: 0.7787909507751465
Validation loss: 2.1706615885098777

Epoch: 6| Step: 11
Training loss: 0.5988958477973938
Validation loss: 2.122500697771708

Epoch: 6| Step: 12
Training loss: 0.3339987099170685
Validation loss: 2.178770124912262

Epoch: 6| Step: 13
Training loss: 0.5534138083457947
Validation loss: 2.1612124840418496

Epoch: 416| Step: 0
Training loss: 0.5317028760910034
Validation loss: 2.147710124651591

Epoch: 6| Step: 1
Training loss: 0.5602301955223083
Validation loss: 2.199881454308828

Epoch: 6| Step: 2
Training loss: 0.6338894963264465
Validation loss: 2.2423810958862305

Epoch: 6| Step: 3
Training loss: 0.559540331363678
Validation loss: 2.252930919329325

Epoch: 6| Step: 4
Training loss: 0.46149685978889465
Validation loss: 2.228282868862152

Epoch: 6| Step: 5
Training loss: 0.6976094245910645
Validation loss: 2.1845656832059226

Epoch: 6| Step: 6
Training loss: 0.8869141340255737
Validation loss: 2.154209554195404

Epoch: 6| Step: 7
Training loss: 0.809973955154419
Validation loss: 2.079535881678263

Epoch: 6| Step: 8
Training loss: 0.5885646939277649
Validation loss: 2.1199068228403726

Epoch: 6| Step: 9
Training loss: 0.49052610993385315
Validation loss: 2.1298319896062217

Epoch: 6| Step: 10
Training loss: 1.174102783203125
Validation loss: 2.1672322154045105

Epoch: 6| Step: 11
Training loss: 1.1109760999679565
Validation loss: 2.2013182242711387

Epoch: 6| Step: 12
Training loss: 0.35811519622802734
Validation loss: 2.128358542919159

Epoch: 6| Step: 13
Training loss: 0.577609121799469
Validation loss: 2.144630948702494

Epoch: 417| Step: 0
Training loss: 0.8697465062141418
Validation loss: 2.209227740764618

Epoch: 6| Step: 1
Training loss: 0.589167594909668
Validation loss: 2.181141972541809

Epoch: 6| Step: 2
Training loss: 0.8329987525939941
Validation loss: 2.2502604722976685

Epoch: 6| Step: 3
Training loss: 0.8796045780181885
Validation loss: 2.2721003691355386

Epoch: 6| Step: 4
Training loss: 0.9314709901809692
Validation loss: 2.2340325117111206

Epoch: 6| Step: 5
Training loss: 0.6034864187240601
Validation loss: 2.224352180957794

Epoch: 6| Step: 6
Training loss: 0.564867377281189
Validation loss: 2.1531607707341514

Epoch: 6| Step: 7
Training loss: 0.5291706323623657
Validation loss: 2.1583906014760337

Epoch: 6| Step: 8
Training loss: 0.9202239513397217
Validation loss: 2.1218010981877646

Epoch: 6| Step: 9
Training loss: 0.523368239402771
Validation loss: 2.1575326522191367

Epoch: 6| Step: 10
Training loss: 0.4791029393672943
Validation loss: 2.1191580494244895

Epoch: 6| Step: 11
Training loss: 0.8447141647338867
Validation loss: 2.1119397282600403

Epoch: 6| Step: 12
Training loss: 0.700971245765686
Validation loss: 2.140922566254934

Epoch: 6| Step: 13
Training loss: 0.4226621985435486
Validation loss: 2.2474658489227295

Epoch: 418| Step: 0
Training loss: 0.7295979857444763
Validation loss: 2.183446447054545

Epoch: 6| Step: 1
Training loss: 1.1126055717468262
Validation loss: 2.279966870943705

Epoch: 6| Step: 2
Training loss: 0.5509501099586487
Validation loss: 2.253263552983602

Epoch: 6| Step: 3
Training loss: 0.79775071144104
Validation loss: 2.2583175698916116

Epoch: 6| Step: 4
Training loss: 0.7733230590820312
Validation loss: 2.25062495470047

Epoch: 6| Step: 5
Training loss: 0.6364765763282776
Validation loss: 2.185864349206289

Epoch: 6| Step: 6
Training loss: 0.5975233316421509
Validation loss: 2.1535588105519614

Epoch: 6| Step: 7
Training loss: 0.42155739665031433
Validation loss: 2.165445645650228

Epoch: 6| Step: 8
Training loss: 0.39132654666900635
Validation loss: 2.1431636015574136

Epoch: 6| Step: 9
Training loss: 0.5105904340744019
Validation loss: 2.1023659308751426

Epoch: 6| Step: 10
Training loss: 0.384173184633255
Validation loss: 2.0960084597269693

Epoch: 6| Step: 11
Training loss: 0.49305301904678345
Validation loss: 2.121721883614858

Epoch: 6| Step: 12
Training loss: 0.4265899658203125
Validation loss: 2.1442964275678

Epoch: 6| Step: 13
Training loss: 0.7607955932617188
Validation loss: 2.1694501638412476

Epoch: 419| Step: 0
Training loss: 0.28867077827453613
Validation loss: 2.146726151307424

Epoch: 6| Step: 1
Training loss: 0.492056280374527
Validation loss: 2.1559675335884094

Epoch: 6| Step: 2
Training loss: 0.4462747871875763
Validation loss: 2.128844936688741

Epoch: 6| Step: 3
Training loss: 1.0533376932144165
Validation loss: 2.1722142497698465

Epoch: 6| Step: 4
Training loss: 1.3523540496826172
Validation loss: 2.178188681602478

Epoch: 6| Step: 5
Training loss: 0.6036339998245239
Validation loss: 2.2020039359728494

Epoch: 6| Step: 6
Training loss: 0.31946033239364624
Validation loss: 2.1807090838750205

Epoch: 6| Step: 7
Training loss: 0.5381672978401184
Validation loss: 2.1988180677096048

Epoch: 6| Step: 8
Training loss: 0.35953500866889954
Validation loss: 2.200855334599813

Epoch: 6| Step: 9
Training loss: 0.3003459572792053
Validation loss: 2.191983143488566

Epoch: 6| Step: 10
Training loss: 0.36505311727523804
Validation loss: 2.1681384841601052

Epoch: 6| Step: 11
Training loss: 0.49432632327079773
Validation loss: 2.1324772040049234

Epoch: 6| Step: 12
Training loss: 0.5474554300308228
Validation loss: 2.144384582837423

Epoch: 6| Step: 13
Training loss: 0.4694881737232208
Validation loss: 2.1534467140833535

Epoch: 420| Step: 0
Training loss: 0.3076690137386322
Validation loss: 2.206366539001465

Epoch: 6| Step: 1
Training loss: 0.48915034532546997
Validation loss: 2.1982481280962625

Epoch: 6| Step: 2
Training loss: 0.6489239931106567
Validation loss: 2.198846995830536

Epoch: 6| Step: 3
Training loss: 0.4676320552825928
Validation loss: 2.1979283889134726

Epoch: 6| Step: 4
Training loss: 1.28907310962677
Validation loss: 2.211206376552582

Epoch: 6| Step: 5
Training loss: 0.44503021240234375
Validation loss: 2.1906296610832214

Epoch: 6| Step: 6
Training loss: 0.5037379860877991
Validation loss: 2.213034451007843

Epoch: 6| Step: 7
Training loss: 0.6379362344741821
Validation loss: 2.2081836064656577

Epoch: 6| Step: 8
Training loss: 0.42611533403396606
Validation loss: 2.1702524622281394

Epoch: 6| Step: 9
Training loss: 0.8453279137611389
Validation loss: 2.1672020157178244

Epoch: 6| Step: 10
Training loss: 0.46562662720680237
Validation loss: 2.1888946493466697

Epoch: 6| Step: 11
Training loss: 0.3627443313598633
Validation loss: 2.141807476679484

Epoch: 6| Step: 12
Training loss: 0.6474055051803589
Validation loss: 2.2014141281445823

Epoch: 6| Step: 13
Training loss: 0.4024784564971924
Validation loss: 2.2080464164415994

Epoch: 421| Step: 0
Training loss: 0.4039602279663086
Validation loss: 2.1800522009531655

Epoch: 6| Step: 1
Training loss: 0.7389020919799805
Validation loss: 2.216317971547445

Epoch: 6| Step: 2
Training loss: 0.41061002016067505
Validation loss: 2.2081175247828164

Epoch: 6| Step: 3
Training loss: 0.35309645533561707
Validation loss: 2.1996212800343833

Epoch: 6| Step: 4
Training loss: 1.1028276681900024
Validation loss: 2.167368729909261

Epoch: 6| Step: 5
Training loss: 0.6789911389350891
Validation loss: 2.1459491848945618

Epoch: 6| Step: 6
Training loss: 0.5847649574279785
Validation loss: 2.185237546761831

Epoch: 6| Step: 7
Training loss: 0.4342274069786072
Validation loss: 2.151090939839681

Epoch: 6| Step: 8
Training loss: 0.58253014087677
Validation loss: 2.1681840419769287

Epoch: 6| Step: 9
Training loss: 0.33969274163246155
Validation loss: 2.142599622408549

Epoch: 6| Step: 10
Training loss: 0.6543666124343872
Validation loss: 2.2027278542518616

Epoch: 6| Step: 11
Training loss: 1.0232632160186768
Validation loss: 2.2258429527282715

Epoch: 6| Step: 12
Training loss: 0.32242804765701294
Validation loss: 2.1983483831087747

Epoch: 6| Step: 13
Training loss: 0.6298632621765137
Validation loss: 2.106756567955017

Epoch: 422| Step: 0
Training loss: 0.48054859042167664
Validation loss: 2.181997080643972

Epoch: 6| Step: 1
Training loss: 0.6052919626235962
Validation loss: 2.1575216253598533

Epoch: 6| Step: 2
Training loss: 0.6001496315002441
Validation loss: 2.0949582060178122

Epoch: 6| Step: 3
Training loss: 0.42347341775894165
Validation loss: 2.0965339144070945

Epoch: 6| Step: 4
Training loss: 1.003551721572876
Validation loss: 2.110728840033213

Epoch: 6| Step: 5
Training loss: 1.0779080390930176
Validation loss: 2.110303004582723

Epoch: 6| Step: 6
Training loss: 0.7999086380004883
Validation loss: 2.126387357711792

Epoch: 6| Step: 7
Training loss: 0.5322036743164062
Validation loss: 2.144290546576182

Epoch: 6| Step: 8
Training loss: 0.370662122964859
Validation loss: 2.1899262070655823

Epoch: 6| Step: 9
Training loss: 0.3711555004119873
Validation loss: 2.2211155692736306

Epoch: 6| Step: 10
Training loss: 0.8219372630119324
Validation loss: 2.1672314008076987

Epoch: 6| Step: 11
Training loss: 0.5000611543655396
Validation loss: 2.2189797163009644

Epoch: 6| Step: 12
Training loss: 0.5494356751441956
Validation loss: 2.2103596925735474

Epoch: 6| Step: 13
Training loss: 0.43542906641960144
Validation loss: 2.1722164154052734

Epoch: 423| Step: 0
Training loss: 0.6699100732803345
Validation loss: 2.1411407589912415

Epoch: 6| Step: 1
Training loss: 0.44059234857559204
Validation loss: 2.142723480860392

Epoch: 6| Step: 2
Training loss: 0.715033769607544
Validation loss: 2.0995566844940186

Epoch: 6| Step: 3
Training loss: 0.7013304233551025
Validation loss: 2.1143489678700766

Epoch: 6| Step: 4
Training loss: 0.5955526232719421
Validation loss: 2.083828111489614

Epoch: 6| Step: 5
Training loss: 1.2156071662902832
Validation loss: 2.0745060443878174

Epoch: 6| Step: 6
Training loss: 0.4878764748573303
Validation loss: 2.1179272333780923

Epoch: 6| Step: 7
Training loss: 0.6397361755371094
Validation loss: 2.17070734500885

Epoch: 6| Step: 8
Training loss: 0.5885104537010193
Validation loss: 2.303516070048014

Epoch: 6| Step: 9
Training loss: 0.8754636645317078
Validation loss: 2.312838912010193

Epoch: 6| Step: 10
Training loss: 0.853509783744812
Validation loss: 2.263469139734904

Epoch: 6| Step: 11
Training loss: 0.4067000150680542
Validation loss: 2.1798425912857056

Epoch: 6| Step: 12
Training loss: 0.7704444527626038
Validation loss: 2.1718400915463767

Epoch: 6| Step: 13
Training loss: 0.5442509055137634
Validation loss: 2.1785735487937927

Epoch: 424| Step: 0
Training loss: 0.45517295598983765
Validation loss: 2.1394529938697815

Epoch: 6| Step: 1
Training loss: 0.5261420607566833
Validation loss: 2.151660124460856

Epoch: 6| Step: 2
Training loss: 0.9975637197494507
Validation loss: 2.1629639863967896

Epoch: 6| Step: 3
Training loss: 0.9602118730545044
Validation loss: 2.1352535684903464

Epoch: 6| Step: 4
Training loss: 0.515819251537323
Validation loss: 2.124931832154592

Epoch: 6| Step: 5
Training loss: 0.3708644509315491
Validation loss: 2.125245908896128

Epoch: 6| Step: 6
Training loss: 0.623110830783844
Validation loss: 2.189533551534017

Epoch: 6| Step: 7
Training loss: 1.0258965492248535
Validation loss: 2.2841903964678445

Epoch: 6| Step: 8
Training loss: 0.6847681403160095
Validation loss: 2.280294974644979

Epoch: 6| Step: 9
Training loss: 0.5783084630966187
Validation loss: 2.310093581676483

Epoch: 6| Step: 10
Training loss: 0.7275713682174683
Validation loss: 2.277546246846517

Epoch: 6| Step: 11
Training loss: 0.6436057090759277
Validation loss: 2.2451636592547097

Epoch: 6| Step: 12
Training loss: 0.5748579502105713
Validation loss: 2.208489497502645

Epoch: 6| Step: 13
Training loss: 0.3719235956668854
Validation loss: 2.180437366167704

Epoch: 425| Step: 0
Training loss: 0.6168720722198486
Validation loss: 2.154214064280192

Epoch: 6| Step: 1
Training loss: 1.2346546649932861
Validation loss: 2.147123614947001

Epoch: 6| Step: 2
Training loss: 0.5434634685516357
Validation loss: 2.160872519016266

Epoch: 6| Step: 3
Training loss: 0.3214261531829834
Validation loss: 2.181256651878357

Epoch: 6| Step: 4
Training loss: 0.5313182473182678
Validation loss: 2.1640584071477256

Epoch: 6| Step: 5
Training loss: 0.9376399517059326
Validation loss: 2.1310261885325112

Epoch: 6| Step: 6
Training loss: 0.9082691073417664
Validation loss: 2.1759172081947327

Epoch: 6| Step: 7
Training loss: 0.35791391134262085
Validation loss: 2.159954011440277

Epoch: 6| Step: 8
Training loss: 0.8384720087051392
Validation loss: 2.1298482020696006

Epoch: 6| Step: 9
Training loss: 0.7600940465927124
Validation loss: 2.197438398996989

Epoch: 6| Step: 10
Training loss: 0.29866427183151245
Validation loss: 2.178217430909475

Epoch: 6| Step: 11
Training loss: 0.4494447112083435
Validation loss: 2.1746297677357993

Epoch: 6| Step: 12
Training loss: 0.2952333986759186
Validation loss: 2.155778467655182

Epoch: 6| Step: 13
Training loss: 0.2802639305591583
Validation loss: 2.1883108814557395

Epoch: 426| Step: 0
Training loss: 0.4609092175960541
Validation loss: 2.140821119149526

Epoch: 6| Step: 1
Training loss: 0.4794543385505676
Validation loss: 2.1119677225748696

Epoch: 6| Step: 2
Training loss: 0.43657705187797546
Validation loss: 2.158318022886912

Epoch: 6| Step: 3
Training loss: 0.419268399477005
Validation loss: 2.1408421198527017

Epoch: 6| Step: 4
Training loss: 0.6707233190536499
Validation loss: 2.2152265310287476

Epoch: 6| Step: 5
Training loss: 1.0061442852020264
Validation loss: 2.184087614218394

Epoch: 6| Step: 6
Training loss: 0.6040149331092834
Validation loss: 2.1819644967714944

Epoch: 6| Step: 7
Training loss: 0.6766518354415894
Validation loss: 2.203484316666921

Epoch: 6| Step: 8
Training loss: 0.5813498497009277
Validation loss: 2.20039435227712

Epoch: 6| Step: 9
Training loss: 0.850644052028656
Validation loss: 2.202385644117991

Epoch: 6| Step: 10
Training loss: 0.32540363073349
Validation loss: 2.1519296566645303

Epoch: 6| Step: 11
Training loss: 0.34929072856903076
Validation loss: 2.1514825224876404

Epoch: 6| Step: 12
Training loss: 0.43505725264549255
Validation loss: 2.1336642702420554

Epoch: 6| Step: 13
Training loss: 0.6812357306480408
Validation loss: 2.183697064717611

Epoch: 427| Step: 0
Training loss: 0.7195497155189514
Validation loss: 2.155188818772634

Epoch: 6| Step: 1
Training loss: 0.45423370599746704
Validation loss: 2.2027493715286255

Epoch: 6| Step: 2
Training loss: 0.42596951127052307
Validation loss: 2.178590476512909

Epoch: 6| Step: 3
Training loss: 0.6840320825576782
Validation loss: 2.1724337935447693

Epoch: 6| Step: 4
Training loss: 0.4237715005874634
Validation loss: 2.163808763027191

Epoch: 6| Step: 5
Training loss: 0.8108993768692017
Validation loss: 2.1247546672821045

Epoch: 6| Step: 6
Training loss: 0.37480562925338745
Validation loss: 2.172821303208669

Epoch: 6| Step: 7
Training loss: 0.6190717816352844
Validation loss: 2.153068403402964

Epoch: 6| Step: 8
Training loss: 0.37421852350234985
Validation loss: 2.2083369890848794

Epoch: 6| Step: 9
Training loss: 0.5445419549942017
Validation loss: 2.1929643154144287

Epoch: 6| Step: 10
Training loss: 0.9171249866485596
Validation loss: 2.1996264259020486

Epoch: 6| Step: 11
Training loss: 0.4418024718761444
Validation loss: 2.2381713589032493

Epoch: 6| Step: 12
Training loss: 0.5212125778198242
Validation loss: 2.228704651196798

Epoch: 6| Step: 13
Training loss: 0.52458256483078
Validation loss: 2.193825364112854

Epoch: 428| Step: 0
Training loss: 0.4424118101596832
Validation loss: 2.1712125738461814

Epoch: 6| Step: 1
Training loss: 0.49459022283554077
Validation loss: 2.1558226943016052

Epoch: 6| Step: 2
Training loss: 0.44448545575141907
Validation loss: 2.1239326198895774

Epoch: 6| Step: 3
Training loss: 1.1023755073547363
Validation loss: 2.1164729396502175

Epoch: 6| Step: 4
Training loss: 0.7772389650344849
Validation loss: 2.1294960975646973

Epoch: 6| Step: 5
Training loss: 0.37311363220214844
Validation loss: 2.106901446978251

Epoch: 6| Step: 6
Training loss: 0.44641274213790894
Validation loss: 2.1173086563746133

Epoch: 6| Step: 7
Training loss: 0.3385941982269287
Validation loss: 2.090683897336324

Epoch: 6| Step: 8
Training loss: 0.6494197845458984
Validation loss: 2.1016940077145896

Epoch: 6| Step: 9
Training loss: 0.6748358011245728
Validation loss: 2.130772272745768

Epoch: 6| Step: 10
Training loss: 0.34696507453918457
Validation loss: 2.146476407845815

Epoch: 6| Step: 11
Training loss: 0.7142051458358765
Validation loss: 2.1093329985936484

Epoch: 6| Step: 12
Training loss: 0.38340669870376587
Validation loss: 2.087384601434072

Epoch: 6| Step: 13
Training loss: 0.46377211809158325
Validation loss: 2.071250299612681

Epoch: 429| Step: 0
Training loss: 0.5759942531585693
Validation loss: 2.0951944986979165

Epoch: 6| Step: 1
Training loss: 0.5318883657455444
Validation loss: 2.1086120009422302

Epoch: 6| Step: 2
Training loss: 0.7402302622795105
Validation loss: 2.121305763721466

Epoch: 6| Step: 3
Training loss: 0.29205673933029175
Validation loss: 2.1009676655133567

Epoch: 6| Step: 4
Training loss: 0.4175345003604889
Validation loss: 2.0993946194648743

Epoch: 6| Step: 5
Training loss: 0.9405286312103271
Validation loss: 2.138113260269165

Epoch: 6| Step: 6
Training loss: 0.5864811539649963
Validation loss: 2.1788191000620523

Epoch: 6| Step: 7
Training loss: 0.5096195936203003
Validation loss: 2.2078667879104614

Epoch: 6| Step: 8
Training loss: 0.6306612491607666
Validation loss: 2.1722017923990884

Epoch: 6| Step: 9
Training loss: 0.3885575532913208
Validation loss: 2.1647852063179016

Epoch: 6| Step: 10
Training loss: 0.7792993783950806
Validation loss: 2.1656534075737

Epoch: 6| Step: 11
Training loss: 0.6520694494247437
Validation loss: 2.166627744833628

Epoch: 6| Step: 12
Training loss: 0.7125442028045654
Validation loss: 2.131031334400177

Epoch: 6| Step: 13
Training loss: 0.4545866847038269
Validation loss: 2.113073766231537

Epoch: 430| Step: 0
Training loss: 0.45236676931381226
Validation loss: 2.0818965832392373

Epoch: 6| Step: 1
Training loss: 0.7052019834518433
Validation loss: 2.1336366136868796

Epoch: 6| Step: 2
Training loss: 0.4812384843826294
Validation loss: 2.157403270403544

Epoch: 6| Step: 3
Training loss: 0.5219026803970337
Validation loss: 2.1308944622675576

Epoch: 6| Step: 4
Training loss: 0.35082900524139404
Validation loss: 2.1588660875956216

Epoch: 6| Step: 5
Training loss: 0.492088258266449
Validation loss: 2.1567017833391824

Epoch: 6| Step: 6
Training loss: 0.4867619276046753
Validation loss: 2.150622467199961

Epoch: 6| Step: 7
Training loss: 0.30995357036590576
Validation loss: 2.1523385842641196

Epoch: 6| Step: 8
Training loss: 0.6515508890151978
Validation loss: 2.1588241855303445

Epoch: 6| Step: 9
Training loss: 0.7127853035926819
Validation loss: 2.10187820593516

Epoch: 6| Step: 10
Training loss: 0.4728532135486603
Validation loss: 2.1468505263328552

Epoch: 6| Step: 11
Training loss: 0.8673499226570129
Validation loss: 2.1695205569267273

Epoch: 6| Step: 12
Training loss: 0.20983386039733887
Validation loss: 2.174135684967041

Epoch: 6| Step: 13
Training loss: 0.3937448561191559
Validation loss: 2.2137884497642517

Epoch: 431| Step: 0
Training loss: 0.4025880992412567
Validation loss: 2.1648645798365274

Epoch: 6| Step: 1
Training loss: 0.29437878727912903
Validation loss: 2.196574091911316

Epoch: 6| Step: 2
Training loss: 0.8609402775764465
Validation loss: 2.1829936106999717

Epoch: 6| Step: 3
Training loss: 0.453342080116272
Validation loss: 2.143083473046621

Epoch: 6| Step: 4
Training loss: 0.3347722291946411
Validation loss: 2.1436835328737893

Epoch: 6| Step: 5
Training loss: 0.5476261377334595
Validation loss: 2.121517618497213

Epoch: 6| Step: 6
Training loss: 1.2561886310577393
Validation loss: 2.122649391492208

Epoch: 6| Step: 7
Training loss: 0.4899180829524994
Validation loss: 2.0905739863713584

Epoch: 6| Step: 8
Training loss: 0.2984561026096344
Validation loss: 2.1753029425938926

Epoch: 6| Step: 9
Training loss: 0.46268582344055176
Validation loss: 2.2205371658007302

Epoch: 6| Step: 10
Training loss: 0.4226847290992737
Validation loss: 2.1560001770655313

Epoch: 6| Step: 11
Training loss: 0.3810040354728699
Validation loss: 2.180739422639211

Epoch: 6| Step: 12
Training loss: 0.4934205114841461
Validation loss: 2.1637152632077536

Epoch: 6| Step: 13
Training loss: 0.40937328338623047
Validation loss: 2.1235645413398743

Epoch: 432| Step: 0
Training loss: 0.22646324336528778
Validation loss: 2.113517085711161

Epoch: 6| Step: 1
Training loss: 0.40274763107299805
Validation loss: 2.143424113591512

Epoch: 6| Step: 2
Training loss: 0.6373101472854614
Validation loss: 2.1042859156926474

Epoch: 6| Step: 3
Training loss: 0.5623875856399536
Validation loss: 2.140264848868052

Epoch: 6| Step: 4
Training loss: 0.5665620565414429
Validation loss: 2.1786930362383523

Epoch: 6| Step: 5
Training loss: 0.5063111782073975
Validation loss: 2.2273330092430115

Epoch: 6| Step: 6
Training loss: 0.6156123280525208
Validation loss: 2.1973321040471396

Epoch: 6| Step: 7
Training loss: 0.4839443266391754
Validation loss: 2.202334443728129

Epoch: 6| Step: 8
Training loss: 0.3184330463409424
Validation loss: 2.176243861516317

Epoch: 6| Step: 9
Training loss: 0.6035025119781494
Validation loss: 2.207036634286245

Epoch: 6| Step: 10
Training loss: 0.34489119052886963
Validation loss: 2.128794550895691

Epoch: 6| Step: 11
Training loss: 1.0793776512145996
Validation loss: 2.14328267176946

Epoch: 6| Step: 12
Training loss: 0.3513919711112976
Validation loss: 2.09684689839681

Epoch: 6| Step: 13
Training loss: 0.38983383774757385
Validation loss: 2.1350977420806885

Epoch: 433| Step: 0
Training loss: 0.8221409320831299
Validation loss: 2.142134726047516

Epoch: 6| Step: 1
Training loss: 0.7054505348205566
Validation loss: 2.169974625110626

Epoch: 6| Step: 2
Training loss: 0.6027636528015137
Validation loss: 2.2294411659240723

Epoch: 6| Step: 3
Training loss: 0.5862467288970947
Validation loss: 2.1890405217806497

Epoch: 6| Step: 4
Training loss: 0.2934975028038025
Validation loss: 2.1871598164240518

Epoch: 6| Step: 5
Training loss: 0.45101198554039
Validation loss: 2.228807588418325

Epoch: 6| Step: 6
Training loss: 0.6398093700408936
Validation loss: 2.1681675910949707

Epoch: 6| Step: 7
Training loss: 0.5411909818649292
Validation loss: 2.1808032194773355

Epoch: 6| Step: 8
Training loss: 0.44054028391838074
Validation loss: 2.1587693293889365

Epoch: 6| Step: 9
Training loss: 0.4305691719055176
Validation loss: 2.17791211605072

Epoch: 6| Step: 10
Training loss: 0.6099314093589783
Validation loss: 2.1546213229497275

Epoch: 6| Step: 11
Training loss: 0.4333531856536865
Validation loss: 2.141805092493693

Epoch: 6| Step: 12
Training loss: 0.5329307317733765
Validation loss: 2.0816814303398132

Epoch: 6| Step: 13
Training loss: 0.7593719959259033
Validation loss: 2.1478720903396606

Epoch: 434| Step: 0
Training loss: 0.38507792353630066
Validation loss: 2.1349536180496216

Epoch: 6| Step: 1
Training loss: 0.7216311693191528
Validation loss: 2.2193331122398376

Epoch: 6| Step: 2
Training loss: 0.42719852924346924
Validation loss: 2.188819646835327

Epoch: 6| Step: 3
Training loss: 0.4919501543045044
Validation loss: 2.16883114973704

Epoch: 6| Step: 4
Training loss: 0.5100173354148865
Validation loss: 2.17597903807958

Epoch: 6| Step: 5
Training loss: 0.18698552250862122
Validation loss: 2.125017245610555

Epoch: 6| Step: 6
Training loss: 0.5903456211090088
Validation loss: 2.137120326360067

Epoch: 6| Step: 7
Training loss: 0.5064362287521362
Validation loss: 2.11960240205129

Epoch: 6| Step: 8
Training loss: 0.46521639823913574
Validation loss: 2.155534585316976

Epoch: 6| Step: 9
Training loss: 0.517275333404541
Validation loss: 2.160674254099528

Epoch: 6| Step: 10
Training loss: 0.4092538356781006
Validation loss: 2.135056217511495

Epoch: 6| Step: 11
Training loss: 0.8148738741874695
Validation loss: 2.1913405855496726

Epoch: 6| Step: 12
Training loss: 0.7684529423713684
Validation loss: 2.179912487665812

Epoch: 6| Step: 13
Training loss: 1.0430943965911865
Validation loss: 2.169515868028005

Epoch: 435| Step: 0
Training loss: 0.48304852843284607
Validation loss: 2.1790079474449158

Epoch: 6| Step: 1
Training loss: 1.067298412322998
Validation loss: 2.166093190511068

Epoch: 6| Step: 2
Training loss: 0.29153019189834595
Validation loss: 2.1445735891660056

Epoch: 6| Step: 3
Training loss: 0.7237770557403564
Validation loss: 2.1761856079101562

Epoch: 6| Step: 4
Training loss: 0.34211912751197815
Validation loss: 2.1193060874938965

Epoch: 6| Step: 5
Training loss: 0.3679131269454956
Validation loss: 2.1223113338152566

Epoch: 6| Step: 6
Training loss: 0.40920907258987427
Validation loss: 2.1317054828008017

Epoch: 6| Step: 7
Training loss: 0.4234596788883209
Validation loss: 2.15736718972524

Epoch: 6| Step: 8
Training loss: 0.6304610967636108
Validation loss: 2.116974115371704

Epoch: 6| Step: 9
Training loss: 0.3145541548728943
Validation loss: 2.1240882078806558

Epoch: 6| Step: 10
Training loss: 0.6524734497070312
Validation loss: 2.166142543156942

Epoch: 6| Step: 11
Training loss: 0.4392196536064148
Validation loss: 2.166530211766561

Epoch: 6| Step: 12
Training loss: 0.5554327964782715
Validation loss: 2.19088613986969

Epoch: 6| Step: 13
Training loss: 0.5723549127578735
Validation loss: 2.2499107122421265

Epoch: 436| Step: 0
Training loss: 0.6670287847518921
Validation loss: 2.2703851064046225

Epoch: 6| Step: 1
Training loss: 0.6820927858352661
Validation loss: 2.251858711242676

Epoch: 6| Step: 2
Training loss: 0.3619457185268402
Validation loss: 2.232825060685476

Epoch: 6| Step: 3
Training loss: 0.6108112335205078
Validation loss: 2.1623629331588745

Epoch: 6| Step: 4
Training loss: 0.48351263999938965
Validation loss: 2.1522679130236306

Epoch: 6| Step: 5
Training loss: 0.5936720967292786
Validation loss: 2.157446801662445

Epoch: 6| Step: 6
Training loss: 0.7567781805992126
Validation loss: 2.136219600836436

Epoch: 6| Step: 7
Training loss: 0.2931598424911499
Validation loss: 2.1888813773790994

Epoch: 6| Step: 8
Training loss: 0.39242076873779297
Validation loss: 2.1447213888168335

Epoch: 6| Step: 9
Training loss: 0.5124529004096985
Validation loss: 2.1924299001693726

Epoch: 6| Step: 10
Training loss: 0.7523044347763062
Validation loss: 2.163384119669596

Epoch: 6| Step: 11
Training loss: 0.5786709189414978
Validation loss: 2.182686746120453

Epoch: 6| Step: 12
Training loss: 0.6125077605247498
Validation loss: 2.1589067578315735

Epoch: 6| Step: 13
Training loss: 0.3491167426109314
Validation loss: 2.1743245323499045

Epoch: 437| Step: 0
Training loss: 0.3137291669845581
Validation loss: 2.151780664920807

Epoch: 6| Step: 1
Training loss: 0.2606513500213623
Validation loss: 2.146732052167257

Epoch: 6| Step: 2
Training loss: 0.3663986325263977
Validation loss: 2.1482444405555725

Epoch: 6| Step: 3
Training loss: 0.5286794900894165
Validation loss: 2.216736992200216

Epoch: 6| Step: 4
Training loss: 0.37875163555145264
Validation loss: 2.17988391717275

Epoch: 6| Step: 5
Training loss: 0.3616795539855957
Validation loss: 2.17054283618927

Epoch: 6| Step: 6
Training loss: 0.6159599423408508
Validation loss: 2.1431936422983804

Epoch: 6| Step: 7
Training loss: 0.7379196882247925
Validation loss: 2.1829223235448203

Epoch: 6| Step: 8
Training loss: 0.2987792491912842
Validation loss: 2.1626312732696533

Epoch: 6| Step: 9
Training loss: 0.46261683106422424
Validation loss: 2.1137622793515525

Epoch: 6| Step: 10
Training loss: 0.6687583923339844
Validation loss: 2.1288498640060425

Epoch: 6| Step: 11
Training loss: 0.5749703645706177
Validation loss: 2.15812611579895

Epoch: 6| Step: 12
Training loss: 0.4305100739002228
Validation loss: 2.1548556089401245

Epoch: 6| Step: 13
Training loss: 0.9452932476997375
Validation loss: 2.169467806816101

Epoch: 438| Step: 0
Training loss: 0.8807551264762878
Validation loss: 2.136135379473368

Epoch: 6| Step: 1
Training loss: 0.4893619120121002
Validation loss: 2.123674968878428

Epoch: 6| Step: 2
Training loss: 0.31351059675216675
Validation loss: 2.0967328548431396

Epoch: 6| Step: 3
Training loss: 0.5733125805854797
Validation loss: 2.1486448645591736

Epoch: 6| Step: 4
Training loss: 0.4108427166938782
Validation loss: 2.09429923693339

Epoch: 6| Step: 5
Training loss: 0.4313105046749115
Validation loss: 2.113762319087982

Epoch: 6| Step: 6
Training loss: 0.7723972797393799
Validation loss: 2.083800037701925

Epoch: 6| Step: 7
Training loss: 0.6982918381690979
Validation loss: 2.029039283593496

Epoch: 6| Step: 8
Training loss: 0.5375205278396606
Validation loss: 2.122390409310659

Epoch: 6| Step: 9
Training loss: 0.6839503049850464
Validation loss: 2.1225759188334146

Epoch: 6| Step: 10
Training loss: 0.2684108316898346
Validation loss: 2.1074268420537314

Epoch: 6| Step: 11
Training loss: 0.443697065114975
Validation loss: 2.160584807395935

Epoch: 6| Step: 12
Training loss: 0.5619983077049255
Validation loss: 2.1580063700675964

Epoch: 6| Step: 13
Training loss: 0.8387060165405273
Validation loss: 2.1741502483685813

Epoch: 439| Step: 0
Training loss: 0.3629366159439087
Validation loss: 2.165073871612549

Epoch: 6| Step: 1
Training loss: 0.47851088643074036
Validation loss: 2.135519027709961

Epoch: 6| Step: 2
Training loss: 1.0615839958190918
Validation loss: 2.139604409535726

Epoch: 6| Step: 3
Training loss: 0.45708245038986206
Validation loss: 2.180586576461792

Epoch: 6| Step: 4
Training loss: 0.682095468044281
Validation loss: 2.1170347929000854

Epoch: 6| Step: 5
Training loss: 0.33430615067481995
Validation loss: 2.1692376136779785

Epoch: 6| Step: 6
Training loss: 0.5388563871383667
Validation loss: 2.1751166582107544

Epoch: 6| Step: 7
Training loss: 0.42365673184394836
Validation loss: 2.20874685049057

Epoch: 6| Step: 8
Training loss: 0.9593055248260498
Validation loss: 2.2206836144129434

Epoch: 6| Step: 9
Training loss: 0.5369632840156555
Validation loss: 2.2630804975827536

Epoch: 6| Step: 10
Training loss: 0.5377559661865234
Validation loss: 2.21900204817454

Epoch: 6| Step: 11
Training loss: 0.5148321390151978
Validation loss: 2.203761180241903

Epoch: 6| Step: 12
Training loss: 0.4805442690849304
Validation loss: 2.157547573248545

Epoch: 6| Step: 13
Training loss: 0.5326677560806274
Validation loss: 2.1342304944992065

Epoch: 440| Step: 0
Training loss: 0.6990208625793457
Validation loss: 2.174409329891205

Epoch: 6| Step: 1
Training loss: 0.774181067943573
Validation loss: 2.140981992085775

Epoch: 6| Step: 2
Training loss: 0.44578495621681213
Validation loss: 2.127703150113424

Epoch: 6| Step: 3
Training loss: 0.3134697675704956
Validation loss: 2.142282406489054

Epoch: 6| Step: 4
Training loss: 0.3852901756763458
Validation loss: 2.1640941898028054

Epoch: 6| Step: 5
Training loss: 0.5188264846801758
Validation loss: 2.1889065702756247

Epoch: 6| Step: 6
Training loss: 1.172437071800232
Validation loss: 2.2045593857765198

Epoch: 6| Step: 7
Training loss: 0.3002314567565918
Validation loss: 2.210495193799337

Epoch: 6| Step: 8
Training loss: 0.25623515248298645
Validation loss: 2.1835901141166687

Epoch: 6| Step: 9
Training loss: 0.4067443609237671
Validation loss: 2.1217192808787027

Epoch: 6| Step: 10
Training loss: 0.5034016966819763
Validation loss: 2.124539057413737

Epoch: 6| Step: 11
Training loss: 0.4230748414993286
Validation loss: 2.147827764352163

Epoch: 6| Step: 12
Training loss: 0.7045984268188477
Validation loss: 2.1167455514272056

Epoch: 6| Step: 13
Training loss: 0.5203129053115845
Validation loss: 2.1371134519577026

Epoch: 441| Step: 0
Training loss: 0.3062133193016052
Validation loss: 2.131773074467977

Epoch: 6| Step: 1
Training loss: 0.6975429058074951
Validation loss: 2.1078803539276123

Epoch: 6| Step: 2
Training loss: 0.7966200709342957
Validation loss: 2.130792220433553

Epoch: 6| Step: 3
Training loss: 0.46781614422798157
Validation loss: 2.1882572571436563

Epoch: 6| Step: 4
Training loss: 0.8314930200576782
Validation loss: 2.2115319967269897

Epoch: 6| Step: 5
Training loss: 0.5237569808959961
Validation loss: 2.2112733523050943

Epoch: 6| Step: 6
Training loss: 0.34728896617889404
Validation loss: 2.1637520790100098

Epoch: 6| Step: 7
Training loss: 0.35453343391418457
Validation loss: 2.1527327497800193

Epoch: 6| Step: 8
Training loss: 0.5728989839553833
Validation loss: 2.175838887691498

Epoch: 6| Step: 9
Training loss: 0.4183545410633087
Validation loss: 2.0979378819465637

Epoch: 6| Step: 10
Training loss: 0.5467005968093872
Validation loss: 2.1370291113853455

Epoch: 6| Step: 11
Training loss: 0.32226189970970154
Validation loss: 2.1525952021280923

Epoch: 6| Step: 12
Training loss: 0.818658709526062
Validation loss: 2.112033406893412

Epoch: 6| Step: 13
Training loss: 0.5212233066558838
Validation loss: 2.1787956158320108

Epoch: 442| Step: 0
Training loss: 0.30453330278396606
Validation loss: 2.226595640182495

Epoch: 6| Step: 1
Training loss: 0.5251990556716919
Validation loss: 2.2437232732772827

Epoch: 6| Step: 2
Training loss: 0.5203099250793457
Validation loss: 2.2017298142115274

Epoch: 6| Step: 3
Training loss: 0.5916723608970642
Validation loss: 2.212968905766805

Epoch: 6| Step: 4
Training loss: 0.6382427215576172
Validation loss: 2.2161145011583963

Epoch: 6| Step: 5
Training loss: 0.6075339913368225
Validation loss: 2.1746163964271545

Epoch: 6| Step: 6
Training loss: 0.34578460454940796
Validation loss: 2.171843330065409

Epoch: 6| Step: 7
Training loss: 0.6130958199501038
Validation loss: 2.132010499636332

Epoch: 6| Step: 8
Training loss: 0.8243975043296814
Validation loss: 2.144785245259603

Epoch: 6| Step: 9
Training loss: 0.9253713488578796
Validation loss: 2.170532544453939

Epoch: 6| Step: 10
Training loss: 0.26855218410491943
Validation loss: 2.1693406899770102

Epoch: 6| Step: 11
Training loss: 0.32260575890541077
Validation loss: 2.1518768866856894

Epoch: 6| Step: 12
Training loss: 0.27897408604621887
Validation loss: 2.2662843068440757

Epoch: 6| Step: 13
Training loss: 0.4427763819694519
Validation loss: 2.2334354321161904

Epoch: 443| Step: 0
Training loss: 0.34960034489631653
Validation loss: 2.2904512882232666

Epoch: 6| Step: 1
Training loss: 0.5571286678314209
Validation loss: 2.308180113633474

Epoch: 6| Step: 2
Training loss: 0.34329476952552795
Validation loss: 2.2529642383257547

Epoch: 6| Step: 3
Training loss: 0.5418335199356079
Validation loss: 2.254591147104899

Epoch: 6| Step: 4
Training loss: 0.6744518280029297
Validation loss: 2.1863997975985208

Epoch: 6| Step: 5
Training loss: 0.37370046973228455
Validation loss: 2.1621090173721313

Epoch: 6| Step: 6
Training loss: 1.1908197402954102
Validation loss: 2.1113165815671286

Epoch: 6| Step: 7
Training loss: 1.0244641304016113
Validation loss: 2.131410837173462

Epoch: 6| Step: 8
Training loss: 0.3280273377895355
Validation loss: 2.1215161879857383

Epoch: 6| Step: 9
Training loss: 0.6113009452819824
Validation loss: 2.126756230990092

Epoch: 6| Step: 10
Training loss: 0.4430043399333954
Validation loss: 2.1661942402521768

Epoch: 6| Step: 11
Training loss: 0.4893542528152466
Validation loss: 2.164718727270762

Epoch: 6| Step: 12
Training loss: 0.3123248815536499
Validation loss: 2.1967904965082803

Epoch: 6| Step: 13
Training loss: 0.3834676742553711
Validation loss: 2.254219929377238

Epoch: 444| Step: 0
Training loss: 0.29634201526641846
Validation loss: 2.1874215404192605

Epoch: 6| Step: 1
Training loss: 0.8422755002975464
Validation loss: 2.1515974601109824

Epoch: 6| Step: 2
Training loss: 0.3249770700931549
Validation loss: 2.162248412768046

Epoch: 6| Step: 3
Training loss: 0.4655224680900574
Validation loss: 2.1705415447553

Epoch: 6| Step: 4
Training loss: 0.4684164524078369
Validation loss: 2.204898238182068

Epoch: 6| Step: 5
Training loss: 0.4654189944267273
Validation loss: 2.1951931516329446

Epoch: 6| Step: 6
Training loss: 0.3837745189666748
Validation loss: 2.182006597518921

Epoch: 6| Step: 7
Training loss: 0.5814180374145508
Validation loss: 2.1546154022216797

Epoch: 6| Step: 8
Training loss: 0.3587668538093567
Validation loss: 2.1909916003545127

Epoch: 6| Step: 9
Training loss: 0.8349472284317017
Validation loss: 2.2344855864842734

Epoch: 6| Step: 10
Training loss: 0.6075553894042969
Validation loss: 2.2149752179781594

Epoch: 6| Step: 11
Training loss: 0.40398234128952026
Validation loss: 2.2657358646392822

Epoch: 6| Step: 12
Training loss: 0.612174391746521
Validation loss: 2.2362966338793435

Epoch: 6| Step: 13
Training loss: 0.48188501596450806
Validation loss: 2.152834971745809

Epoch: 445| Step: 0
Training loss: 0.3181624710559845
Validation loss: 2.1455015540122986

Epoch: 6| Step: 1
Training loss: 0.5450494289398193
Validation loss: 2.101816157499949

Epoch: 6| Step: 2
Training loss: 0.8754155039787292
Validation loss: 2.116270740826925

Epoch: 6| Step: 3
Training loss: 0.28103381395339966
Validation loss: 2.141661206881205

Epoch: 6| Step: 4
Training loss: 0.4877326488494873
Validation loss: 2.163220524787903

Epoch: 6| Step: 5
Training loss: 0.861583948135376
Validation loss: 2.2102390130360923

Epoch: 6| Step: 6
Training loss: 0.35425910353660583
Validation loss: 2.193761467933655

Epoch: 6| Step: 7
Training loss: 0.24015620350837708
Validation loss: 2.164673705895742

Epoch: 6| Step: 8
Training loss: 0.6545804738998413
Validation loss: 2.2154455184936523

Epoch: 6| Step: 9
Training loss: 0.6057822704315186
Validation loss: 2.195537030696869

Epoch: 6| Step: 10
Training loss: 0.41096723079681396
Validation loss: 2.151009202003479

Epoch: 6| Step: 11
Training loss: 0.4738892912864685
Validation loss: 2.1628401478131614

Epoch: 6| Step: 12
Training loss: 0.4762318730354309
Validation loss: 2.164045592149099

Epoch: 6| Step: 13
Training loss: 0.6468633413314819
Validation loss: 2.145612140496572

Epoch: 446| Step: 0
Training loss: 0.28214359283447266
Validation loss: 2.1418029069900513

Epoch: 6| Step: 1
Training loss: 0.491390585899353
Validation loss: 2.1673482060432434

Epoch: 6| Step: 2
Training loss: 0.41578125953674316
Validation loss: 2.1112122734387717

Epoch: 6| Step: 3
Training loss: 0.3380867838859558
Validation loss: 2.12779309352239

Epoch: 6| Step: 4
Training loss: 0.41545990109443665
Validation loss: 2.138769487539927

Epoch: 6| Step: 5
Training loss: 0.5580127239227295
Validation loss: 2.135780314604441

Epoch: 6| Step: 6
Training loss: 0.815020740032196
Validation loss: 2.18358838558197

Epoch: 6| Step: 7
Training loss: 0.3668331503868103
Validation loss: 2.1730218728383384

Epoch: 6| Step: 8
Training loss: 0.3054119348526001
Validation loss: 2.1740718881289163

Epoch: 6| Step: 9
Training loss: 0.6362046003341675
Validation loss: 2.1676108837127686

Epoch: 6| Step: 10
Training loss: 1.1981987953186035
Validation loss: 2.1245223681131997

Epoch: 6| Step: 11
Training loss: 0.46397513151168823
Validation loss: 2.145085314909617

Epoch: 6| Step: 12
Training loss: 0.46990489959716797
Validation loss: 2.1192853649457297

Epoch: 6| Step: 13
Training loss: 0.3796687722206116
Validation loss: 2.1351333260536194

Epoch: 447| Step: 0
Training loss: 0.47517716884613037
Validation loss: 2.185895542303721

Epoch: 6| Step: 1
Training loss: 0.7680216431617737
Validation loss: 2.171036700407664

Epoch: 6| Step: 2
Training loss: 0.3397824168205261
Validation loss: 2.1720962127049765

Epoch: 6| Step: 3
Training loss: 0.9757170081138611
Validation loss: 2.196940779685974

Epoch: 6| Step: 4
Training loss: 0.43574559688568115
Validation loss: 2.1755974292755127

Epoch: 6| Step: 5
Training loss: 0.5005621910095215
Validation loss: 2.1826205253601074

Epoch: 6| Step: 6
Training loss: 0.48402321338653564
Validation loss: 2.1732661724090576

Epoch: 6| Step: 7
Training loss: 0.5257999897003174
Validation loss: 2.157652199268341

Epoch: 6| Step: 8
Training loss: 0.7527855634689331
Validation loss: 2.1946116288503013

Epoch: 6| Step: 9
Training loss: 0.393045037984848
Validation loss: 2.1622415582338967

Epoch: 6| Step: 10
Training loss: 0.3901742994785309
Validation loss: 2.1902783711751304

Epoch: 6| Step: 11
Training loss: 0.37680909037590027
Validation loss: 2.2367153763771057

Epoch: 6| Step: 12
Training loss: 0.42086243629455566
Validation loss: 2.193041364351908

Epoch: 6| Step: 13
Training loss: 0.26918959617614746
Validation loss: 2.244455416997274

Epoch: 448| Step: 0
Training loss: 0.4699001908302307
Validation loss: 2.1956730286280313

Epoch: 6| Step: 1
Training loss: 0.303224116563797
Validation loss: 2.2108042240142822

Epoch: 6| Step: 2
Training loss: 0.8740878701210022
Validation loss: 2.180384039878845

Epoch: 6| Step: 3
Training loss: 0.8223018646240234
Validation loss: 2.1835997700691223

Epoch: 6| Step: 4
Training loss: 0.4942470192909241
Validation loss: 2.2347394029299417

Epoch: 6| Step: 5
Training loss: 0.29828396439552307
Validation loss: 2.217865546544393

Epoch: 6| Step: 6
Training loss: 0.4298006296157837
Validation loss: 2.2675365209579468

Epoch: 6| Step: 7
Training loss: 0.30541688203811646
Validation loss: 2.3257083694140115

Epoch: 6| Step: 8
Training loss: 0.49395525455474854
Validation loss: 2.2897943258285522

Epoch: 6| Step: 9
Training loss: 0.5770179033279419
Validation loss: 2.2698919574419656

Epoch: 6| Step: 10
Training loss: 0.4352427124977112
Validation loss: 2.1929388840993247

Epoch: 6| Step: 11
Training loss: 0.3140220046043396
Validation loss: 2.1544443567593894

Epoch: 6| Step: 12
Training loss: 0.8854272961616516
Validation loss: 2.1702492237091064

Epoch: 6| Step: 13
Training loss: 0.6897324323654175
Validation loss: 2.0961796045303345

Epoch: 449| Step: 0
Training loss: 0.8024218678474426
Validation loss: 2.1258312861124673

Epoch: 6| Step: 1
Training loss: 0.5414035320281982
Validation loss: 2.1230913599332175

Epoch: 6| Step: 2
Training loss: 0.6186280846595764
Validation loss: 2.11906890074412

Epoch: 6| Step: 3
Training loss: 0.43199071288108826
Validation loss: 2.1704026460647583

Epoch: 6| Step: 4
Training loss: 0.23467117547988892
Validation loss: 2.2294241984685264

Epoch: 6| Step: 5
Training loss: 0.34092357754707336
Validation loss: 2.2578965624173484

Epoch: 6| Step: 6
Training loss: 0.5320069193840027
Validation loss: 2.240725020567576

Epoch: 6| Step: 7
Training loss: 0.6430062055587769
Validation loss: 2.253999392191569

Epoch: 6| Step: 8
Training loss: 0.5353906750679016
Validation loss: 2.227146089076996

Epoch: 6| Step: 9
Training loss: 0.6653659343719482
Validation loss: 2.143201231956482

Epoch: 6| Step: 10
Training loss: 0.5919389724731445
Validation loss: 2.173400580883026

Epoch: 6| Step: 11
Training loss: 0.4778919219970703
Validation loss: 2.1646116574605307

Epoch: 6| Step: 12
Training loss: 0.7404317855834961
Validation loss: 2.1234965324401855

Epoch: 6| Step: 13
Training loss: 0.5036303997039795
Validation loss: 2.1680065790812173

Epoch: 450| Step: 0
Training loss: 0.27985528111457825
Validation loss: 2.1555232803026834

Epoch: 6| Step: 1
Training loss: 0.39598822593688965
Validation loss: 2.1939855019251504

Epoch: 6| Step: 2
Training loss: 0.34452319145202637
Validation loss: 2.190107007821401

Epoch: 6| Step: 3
Training loss: 0.3420564532279968
Validation loss: 2.262751738230387

Epoch: 6| Step: 4
Training loss: 0.509765625
Validation loss: 2.241867264111837

Epoch: 6| Step: 5
Training loss: 0.47261524200439453
Validation loss: 2.241400420665741

Epoch: 6| Step: 6
Training loss: 0.5342628359794617
Validation loss: 2.2419750491778054

Epoch: 6| Step: 7
Training loss: 1.0218716859817505
Validation loss: 2.1833060582478843

Epoch: 6| Step: 8
Training loss: 0.6060672998428345
Validation loss: 2.180892030398051

Epoch: 6| Step: 9
Training loss: 0.5286718606948853
Validation loss: 2.1486615737279258

Epoch: 6| Step: 10
Training loss: 0.6955934762954712
Validation loss: 2.1108519633611045

Epoch: 6| Step: 11
Training loss: 0.8279221653938293
Validation loss: 2.1284464796384177

Epoch: 6| Step: 12
Training loss: 0.24421808123588562
Validation loss: 2.1797513167063394

Epoch: 6| Step: 13
Training loss: 0.7803856134414673
Validation loss: 2.1949456930160522

Epoch: 451| Step: 0
Training loss: 0.4760304391384125
Validation loss: 2.234092950820923

Epoch: 6| Step: 1
Training loss: 0.5084357261657715
Validation loss: 2.25333038965861

Epoch: 6| Step: 2
Training loss: 0.8119350671768188
Validation loss: 2.2496639688809714

Epoch: 6| Step: 3
Training loss: 0.4351321756839752
Validation loss: 2.2267113526662192

Epoch: 6| Step: 4
Training loss: 0.7247220873832703
Validation loss: 2.2830259799957275

Epoch: 6| Step: 5
Training loss: 0.44180989265441895
Validation loss: 2.2586589654286704

Epoch: 6| Step: 6
Training loss: 0.4836198091506958
Validation loss: 2.2084730664889016

Epoch: 6| Step: 7
Training loss: 0.47702378034591675
Validation loss: 2.180074135462443

Epoch: 6| Step: 8
Training loss: 0.313106894493103
Validation loss: 2.1612834334373474

Epoch: 6| Step: 9
Training loss: 0.37073105573654175
Validation loss: 2.1073205868403115

Epoch: 6| Step: 10
Training loss: 0.9533135890960693
Validation loss: 2.1388365030288696

Epoch: 6| Step: 11
Training loss: 0.30418604612350464
Validation loss: 2.1199366251627603

Epoch: 6| Step: 12
Training loss: 0.2378964126110077
Validation loss: 2.143441458543142

Epoch: 6| Step: 13
Training loss: 0.5026533603668213
Validation loss: 2.120657444000244

Epoch: 452| Step: 0
Training loss: 0.30720269680023193
Validation loss: 2.163287182648977

Epoch: 6| Step: 1
Training loss: 0.5720170736312866
Validation loss: 2.174030363559723

Epoch: 6| Step: 2
Training loss: 0.5105295777320862
Validation loss: 2.2329686482747397

Epoch: 6| Step: 3
Training loss: 0.46453869342803955
Validation loss: 2.1892078518867493

Epoch: 6| Step: 4
Training loss: 0.5135351419448853
Validation loss: 2.1941024462381997

Epoch: 6| Step: 5
Training loss: 0.4107603430747986
Validation loss: 2.1979053020477295

Epoch: 6| Step: 6
Training loss: 0.7430087327957153
Validation loss: 2.173531691233317

Epoch: 6| Step: 7
Training loss: 0.5457459092140198
Validation loss: 2.19520511229833

Epoch: 6| Step: 8
Training loss: 0.17365941405296326
Validation loss: 2.226646979649862

Epoch: 6| Step: 9
Training loss: 0.37378329038619995
Validation loss: 2.177497903505961

Epoch: 6| Step: 10
Training loss: 0.3774719834327698
Validation loss: 2.179192841053009

Epoch: 6| Step: 11
Training loss: 0.41191959381103516
Validation loss: 2.1830127437909446

Epoch: 6| Step: 12
Training loss: 0.43876028060913086
Validation loss: 2.1373618245124817

Epoch: 6| Step: 13
Training loss: 0.7895694971084595
Validation loss: 2.161527911822001

Epoch: 453| Step: 0
Training loss: 0.3955402374267578
Validation loss: 2.2114932934443154

Epoch: 6| Step: 1
Training loss: 0.44399380683898926
Validation loss: 2.240790764490763

Epoch: 6| Step: 2
Training loss: 0.2765352725982666
Validation loss: 2.2327613830566406

Epoch: 6| Step: 3
Training loss: 0.39416030049324036
Validation loss: 2.2271571358044944

Epoch: 6| Step: 4
Training loss: 0.4265367388725281
Validation loss: 2.183200200398763

Epoch: 6| Step: 5
Training loss: 0.6916864514350891
Validation loss: 2.1841594576835632

Epoch: 6| Step: 6
Training loss: 0.4803479015827179
Validation loss: 2.169787426789602

Epoch: 6| Step: 7
Training loss: 0.6957481503486633
Validation loss: 2.1696704824765525

Epoch: 6| Step: 8
Training loss: 0.4222075939178467
Validation loss: 2.2051887114842734

Epoch: 6| Step: 9
Training loss: 0.6549237966537476
Validation loss: 2.2456150452295938

Epoch: 6| Step: 10
Training loss: 0.9028830528259277
Validation loss: 2.2439478635787964

Epoch: 6| Step: 11
Training loss: 0.47271326184272766
Validation loss: 2.2288217544555664

Epoch: 6| Step: 12
Training loss: 0.336871862411499
Validation loss: 2.249850809574127

Epoch: 6| Step: 13
Training loss: 0.35154175758361816
Validation loss: 2.212815006573995

Epoch: 454| Step: 0
Training loss: 0.4832344651222229
Validation loss: 2.200503428777059

Epoch: 6| Step: 1
Training loss: 0.412922739982605
Validation loss: 2.179072995980581

Epoch: 6| Step: 2
Training loss: 0.6315556764602661
Validation loss: 2.1432606180508933

Epoch: 6| Step: 3
Training loss: 0.45206373929977417
Validation loss: 2.120661437511444

Epoch: 6| Step: 4
Training loss: 0.5192117691040039
Validation loss: 2.062574644883474

Epoch: 6| Step: 5
Training loss: 0.4133754372596741
Validation loss: 2.132564385732015

Epoch: 6| Step: 6
Training loss: 0.4546850323677063
Validation loss: 2.1362304091453552

Epoch: 6| Step: 7
Training loss: 0.7168228030204773
Validation loss: 2.1185081005096436

Epoch: 6| Step: 8
Training loss: 0.3456231653690338
Validation loss: 2.1840885082880654

Epoch: 6| Step: 9
Training loss: 0.555240273475647
Validation loss: 2.1782399813334146

Epoch: 6| Step: 10
Training loss: 0.34685251116752625
Validation loss: 2.24189958969752

Epoch: 6| Step: 11
Training loss: 0.34574538469314575
Validation loss: 2.237681786219279

Epoch: 6| Step: 12
Training loss: 0.7771801948547363
Validation loss: 2.240404963493347

Epoch: 6| Step: 13
Training loss: 0.3926713466644287
Validation loss: 2.244850754737854

Epoch: 455| Step: 0
Training loss: 0.5455684661865234
Validation loss: 2.22774330774943

Epoch: 6| Step: 1
Training loss: 0.349328875541687
Validation loss: 2.196456174055735

Epoch: 6| Step: 2
Training loss: 0.3980601727962494
Validation loss: 2.222081740697225

Epoch: 6| Step: 3
Training loss: 0.4964829683303833
Validation loss: 2.1956979036331177

Epoch: 6| Step: 4
Training loss: 0.4181841313838959
Validation loss: 2.180402994155884

Epoch: 6| Step: 5
Training loss: 0.3740520775318146
Validation loss: 2.1680797735850015

Epoch: 6| Step: 6
Training loss: 0.7786636352539062
Validation loss: 2.113400717576345

Epoch: 6| Step: 7
Training loss: 0.3815042972564697
Validation loss: 2.149551570415497

Epoch: 6| Step: 8
Training loss: 0.5505220293998718
Validation loss: 2.1030410130818686

Epoch: 6| Step: 9
Training loss: 0.3544818162918091
Validation loss: 2.1534804503122964

Epoch: 6| Step: 10
Training loss: 0.4399746060371399
Validation loss: 2.12848166624705

Epoch: 6| Step: 11
Training loss: 0.7074018120765686
Validation loss: 2.1498910586039224

Epoch: 6| Step: 12
Training loss: 0.44551384449005127
Validation loss: 2.1957225998242698

Epoch: 6| Step: 13
Training loss: 0.8617944717407227
Validation loss: 2.1577674945195517

Epoch: 456| Step: 0
Training loss: 0.49641522765159607
Validation loss: 2.161400536696116

Epoch: 6| Step: 1
Training loss: 0.594059944152832
Validation loss: 2.172748327255249

Epoch: 6| Step: 2
Training loss: 0.4764847755432129
Validation loss: 2.22022408246994

Epoch: 6| Step: 3
Training loss: 0.46584606170654297
Validation loss: 2.201518177986145

Epoch: 6| Step: 4
Training loss: 0.48298904299736023
Validation loss: 2.227594792842865

Epoch: 6| Step: 5
Training loss: 0.7432599067687988
Validation loss: 2.1964460213979087

Epoch: 6| Step: 6
Training loss: 0.39667317271232605
Validation loss: 2.230849027633667

Epoch: 6| Step: 7
Training loss: 0.4882756471633911
Validation loss: 2.246503710746765

Epoch: 6| Step: 8
Training loss: 0.33182331919670105
Validation loss: 2.248799721399943

Epoch: 6| Step: 9
Training loss: 0.28648149967193604
Validation loss: 2.2303189833958945

Epoch: 6| Step: 10
Training loss: 0.42949897050857544
Validation loss: 2.2196133534113565

Epoch: 6| Step: 11
Training loss: 0.3353956639766693
Validation loss: 2.226893345514933

Epoch: 6| Step: 12
Training loss: 0.5679478645324707
Validation loss: 2.17233677705129

Epoch: 6| Step: 13
Training loss: 0.4292546510696411
Validation loss: 2.1728631059328714

Epoch: 457| Step: 0
Training loss: 0.47253355383872986
Validation loss: 2.2035142381985984

Epoch: 6| Step: 1
Training loss: 0.5838896036148071
Validation loss: 2.1702187856038413

Epoch: 6| Step: 2
Training loss: 0.33876633644104004
Validation loss: 2.170208732287089

Epoch: 6| Step: 3
Training loss: 0.5405354499816895
Validation loss: 2.1716609795888266

Epoch: 6| Step: 4
Training loss: 0.5865907073020935
Validation loss: 2.1988893946011863

Epoch: 6| Step: 5
Training loss: 0.46128419041633606
Validation loss: 2.163208266099294

Epoch: 6| Step: 6
Training loss: 0.2936840057373047
Validation loss: 2.2033939560254416

Epoch: 6| Step: 7
Training loss: 0.6743543148040771
Validation loss: 2.2243335048357644

Epoch: 6| Step: 8
Training loss: 0.2098081111907959
Validation loss: 2.1471650203069053

Epoch: 6| Step: 9
Training loss: 0.7668574452400208
Validation loss: 2.167933940887451

Epoch: 6| Step: 10
Training loss: 0.4157566428184509
Validation loss: 2.130086918671926

Epoch: 6| Step: 11
Training loss: 0.3441793620586395
Validation loss: 2.13319331407547

Epoch: 6| Step: 12
Training loss: 0.4252678155899048
Validation loss: 2.119903047879537

Epoch: 6| Step: 13
Training loss: 0.4347636103630066
Validation loss: 2.1386704246203103

Epoch: 458| Step: 0
Training loss: 0.45482638478279114
Validation loss: 2.17424205938975

Epoch: 6| Step: 1
Training loss: 0.30963870882987976
Validation loss: 2.185025175412496

Epoch: 6| Step: 2
Training loss: 0.49559059739112854
Validation loss: 2.1977129578590393

Epoch: 6| Step: 3
Training loss: 0.45714619755744934
Validation loss: 2.2128570477167764

Epoch: 6| Step: 4
Training loss: 0.6397900581359863
Validation loss: 2.2210243344306946

Epoch: 6| Step: 5
Training loss: 0.4062865376472473
Validation loss: 2.1811697085698447

Epoch: 6| Step: 6
Training loss: 0.31886059045791626
Validation loss: 2.161095162232717

Epoch: 6| Step: 7
Training loss: 0.3210042715072632
Validation loss: 2.1239182154337564

Epoch: 6| Step: 8
Training loss: 0.33467891812324524
Validation loss: 2.156797170639038

Epoch: 6| Step: 9
Training loss: 0.5000196099281311
Validation loss: 2.1326297322909036

Epoch: 6| Step: 10
Training loss: 1.2368791103363037
Validation loss: 2.116117000579834

Epoch: 6| Step: 11
Training loss: 0.5123287439346313
Validation loss: 2.1193302869796753

Epoch: 6| Step: 12
Training loss: 0.4902217388153076
Validation loss: 2.179987132549286

Epoch: 6| Step: 13
Training loss: 0.40500766038894653
Validation loss: 2.172632952531179

Epoch: 459| Step: 0
Training loss: 0.5532499551773071
Validation loss: 2.2030442555745444

Epoch: 6| Step: 1
Training loss: 0.3563973307609558
Validation loss: 2.2310985128084817

Epoch: 6| Step: 2
Training loss: 0.7089113593101501
Validation loss: 2.233277956644694

Epoch: 6| Step: 3
Training loss: 0.3667668402194977
Validation loss: 2.2251452008883157

Epoch: 6| Step: 4
Training loss: 0.3222685754299164
Validation loss: 2.1970590154329934

Epoch: 6| Step: 5
Training loss: 0.2983919680118561
Validation loss: 2.2029530803362527

Epoch: 6| Step: 6
Training loss: 0.3820844888687134
Validation loss: 2.2066569328308105

Epoch: 6| Step: 7
Training loss: 0.2976699769496918
Validation loss: 2.2168445189793906

Epoch: 6| Step: 8
Training loss: 0.4974522590637207
Validation loss: 2.2229188283284507

Epoch: 6| Step: 9
Training loss: 0.9487292170524597
Validation loss: 2.205722908178965

Epoch: 6| Step: 10
Training loss: 0.7760612368583679
Validation loss: 2.262533704439799

Epoch: 6| Step: 11
Training loss: 0.5156228542327881
Validation loss: 2.248471220334371

Epoch: 6| Step: 12
Training loss: 0.44542819261550903
Validation loss: 2.256900986035665

Epoch: 6| Step: 13
Training loss: 0.43040788173675537
Validation loss: 2.247619311014811

Epoch: 460| Step: 0
Training loss: 0.2059933990240097
Validation loss: 2.269342541694641

Epoch: 6| Step: 1
Training loss: 0.3836732506752014
Validation loss: 2.2360050280888877

Epoch: 6| Step: 2
Training loss: 0.36983153223991394
Validation loss: 2.277680734793345

Epoch: 6| Step: 3
Training loss: 0.3673039972782135
Validation loss: 2.244348724683126

Epoch: 6| Step: 4
Training loss: 0.21839088201522827
Validation loss: 2.194681763648987

Epoch: 6| Step: 5
Training loss: 0.3944327235221863
Validation loss: 2.1615897019704184

Epoch: 6| Step: 6
Training loss: 0.44233959913253784
Validation loss: 2.192451993624369

Epoch: 6| Step: 7
Training loss: 0.5393393635749817
Validation loss: 2.2210646867752075

Epoch: 6| Step: 8
Training loss: 0.41796496510505676
Validation loss: 2.2181453506151834

Epoch: 6| Step: 9
Training loss: 0.4972066283226013
Validation loss: 2.248235026995341

Epoch: 6| Step: 10
Training loss: 0.38304898142814636
Validation loss: 2.1939453879992166

Epoch: 6| Step: 11
Training loss: 0.613308310508728
Validation loss: 2.2634376684824624

Epoch: 6| Step: 12
Training loss: 1.1243174076080322
Validation loss: 2.207444906234741

Epoch: 6| Step: 13
Training loss: 0.43440693616867065
Validation loss: 2.2100617488225303

Epoch: 461| Step: 0
Training loss: 0.6940344572067261
Validation loss: 2.1362810134887695

Epoch: 6| Step: 1
Training loss: 0.3964877426624298
Validation loss: 2.1773377458254495

Epoch: 6| Step: 2
Training loss: 0.4318867027759552
Validation loss: 2.1311323245366416

Epoch: 6| Step: 3
Training loss: 0.3606749176979065
Validation loss: 2.101255198319753

Epoch: 6| Step: 4
Training loss: 0.35045522451400757
Validation loss: 2.173364778359731

Epoch: 6| Step: 5
Training loss: 0.3832182288169861
Validation loss: 2.150346120198568

Epoch: 6| Step: 6
Training loss: 0.988623857498169
Validation loss: 2.156987170378367

Epoch: 6| Step: 7
Training loss: 0.48944079875946045
Validation loss: 2.1887757778167725

Epoch: 6| Step: 8
Training loss: 0.28115904331207275
Validation loss: 2.145050605138143

Epoch: 6| Step: 9
Training loss: 0.17775826156139374
Validation loss: 2.1768784324328103

Epoch: 6| Step: 10
Training loss: 0.22120797634124756
Validation loss: 2.2324580748875937

Epoch: 6| Step: 11
Training loss: 0.5296189785003662
Validation loss: 2.2707234223683677

Epoch: 6| Step: 12
Training loss: 0.51552414894104
Validation loss: 2.239644229412079

Epoch: 6| Step: 13
Training loss: 0.4163138270378113
Validation loss: 2.2216002543767295

Epoch: 462| Step: 0
Training loss: 0.5699363350868225
Validation loss: 2.1738827427228293

Epoch: 6| Step: 1
Training loss: 0.5853742361068726
Validation loss: 2.19683305422465

Epoch: 6| Step: 2
Training loss: 0.3213318884372711
Validation loss: 2.13546884059906

Epoch: 6| Step: 3
Training loss: 0.47269874811172485
Validation loss: 2.1525558829307556

Epoch: 6| Step: 4
Training loss: 0.32710856199264526
Validation loss: 2.1379363536834717

Epoch: 6| Step: 5
Training loss: 0.6020064353942871
Validation loss: 2.10791806379954

Epoch: 6| Step: 6
Training loss: 0.5372189879417419
Validation loss: 2.0815324584643045

Epoch: 6| Step: 7
Training loss: 0.7611499428749084
Validation loss: 2.145289103190104

Epoch: 6| Step: 8
Training loss: 0.577174723148346
Validation loss: 2.1610140403111777

Epoch: 6| Step: 9
Training loss: 0.3198179006576538
Validation loss: 2.21340940395991

Epoch: 6| Step: 10
Training loss: 0.28542211651802063
Validation loss: 2.1246426502863565

Epoch: 6| Step: 11
Training loss: 0.3994617462158203
Validation loss: 2.199394683043162

Epoch: 6| Step: 12
Training loss: 0.5416170954704285
Validation loss: 2.1836387713750205

Epoch: 6| Step: 13
Training loss: 0.5248643159866333
Validation loss: 2.1517348289489746

Epoch: 463| Step: 0
Training loss: 0.3094337284564972
Validation loss: 2.149823248386383

Epoch: 6| Step: 1
Training loss: 0.5171157717704773
Validation loss: 2.1395423809687295

Epoch: 6| Step: 2
Training loss: 0.7117085456848145
Validation loss: 2.119667629400889

Epoch: 6| Step: 3
Training loss: 0.32319629192352295
Validation loss: 2.1534822583198547

Epoch: 6| Step: 4
Training loss: 0.4429856538772583
Validation loss: 2.142191747824351

Epoch: 6| Step: 5
Training loss: 0.8433715105056763
Validation loss: 2.2195094426472983

Epoch: 6| Step: 6
Training loss: 0.4218284487724304
Validation loss: 2.1961934169133506

Epoch: 6| Step: 7
Training loss: 0.6383727788925171
Validation loss: 2.209035058816274

Epoch: 6| Step: 8
Training loss: 0.503282368183136
Validation loss: 2.2406946818033853

Epoch: 6| Step: 9
Training loss: 0.582905650138855
Validation loss: 2.230696757634481

Epoch: 6| Step: 10
Training loss: 0.8565205335617065
Validation loss: 2.181311845779419

Epoch: 6| Step: 11
Training loss: 0.6076647043228149
Validation loss: 2.165501892566681

Epoch: 6| Step: 12
Training loss: 0.5377469062805176
Validation loss: 2.1134255131085715

Epoch: 6| Step: 13
Training loss: 0.477222204208374
Validation loss: 2.070325255393982

Epoch: 464| Step: 0
Training loss: 0.5847502946853638
Validation loss: 2.065163314342499

Epoch: 6| Step: 1
Training loss: 0.6653540730476379
Validation loss: 2.088151276111603

Epoch: 6| Step: 2
Training loss: 0.2430211305618286
Validation loss: 2.148023168245951

Epoch: 6| Step: 3
Training loss: 0.4254082441329956
Validation loss: 2.1566549142201743

Epoch: 6| Step: 4
Training loss: 0.4868167042732239
Validation loss: 2.16501792271932

Epoch: 6| Step: 5
Training loss: 0.43799418210983276
Validation loss: 2.230375428994497

Epoch: 6| Step: 6
Training loss: 0.6733428239822388
Validation loss: 2.203997095425924

Epoch: 6| Step: 7
Training loss: 0.46750015020370483
Validation loss: 2.2276560266812644

Epoch: 6| Step: 8
Training loss: 0.7626140117645264
Validation loss: 2.2153639793395996

Epoch: 6| Step: 9
Training loss: 0.5051419734954834
Validation loss: 2.2805302143096924

Epoch: 6| Step: 10
Training loss: 0.5195803046226501
Validation loss: 2.2198470632235208

Epoch: 6| Step: 11
Training loss: 0.386106938123703
Validation loss: 2.23344091574351

Epoch: 6| Step: 12
Training loss: 0.38819772005081177
Validation loss: 2.166309356689453

Epoch: 6| Step: 13
Training loss: 0.33372801542282104
Validation loss: 2.244690457979838

Epoch: 465| Step: 0
Training loss: 0.7476422786712646
Validation loss: 2.213780244191488

Epoch: 6| Step: 1
Training loss: 0.3828788995742798
Validation loss: 2.2412925958633423

Epoch: 6| Step: 2
Training loss: 0.25808876752853394
Validation loss: 2.2486713329950967

Epoch: 6| Step: 3
Training loss: 0.4273267984390259
Validation loss: 2.1946871479352317

Epoch: 6| Step: 4
Training loss: 0.3783928453922272
Validation loss: 2.1492245395978293

Epoch: 6| Step: 5
Training loss: 0.4142383933067322
Validation loss: 2.1753730376561484

Epoch: 6| Step: 6
Training loss: 0.2415292114019394
Validation loss: 2.136178652445475

Epoch: 6| Step: 7
Training loss: 0.5722852945327759
Validation loss: 2.151274820168813

Epoch: 6| Step: 8
Training loss: 0.6983546018600464
Validation loss: 2.1672916809717813

Epoch: 6| Step: 9
Training loss: 0.3405104875564575
Validation loss: 2.1823832790056863

Epoch: 6| Step: 10
Training loss: 0.39406245946884155
Validation loss: 2.1534143884976706

Epoch: 6| Step: 11
Training loss: 0.33721625804901123
Validation loss: 2.18267560005188

Epoch: 6| Step: 12
Training loss: 0.46400976181030273
Validation loss: 2.1868099172910056

Epoch: 6| Step: 13
Training loss: 0.5563151836395264
Validation loss: 2.125607192516327

Epoch: 466| Step: 0
Training loss: 0.7585642337799072
Validation loss: 2.2152183453241983

Epoch: 6| Step: 1
Training loss: 0.7163213491439819
Validation loss: 2.206675887107849

Epoch: 6| Step: 2
Training loss: 0.5697885751724243
Validation loss: 2.242811918258667

Epoch: 6| Step: 3
Training loss: 0.582310676574707
Validation loss: 2.1975074807802835

Epoch: 6| Step: 4
Training loss: 0.48567116260528564
Validation loss: 2.1895240942637124

Epoch: 6| Step: 5
Training loss: 0.49500221014022827
Validation loss: 2.2082366943359375

Epoch: 6| Step: 6
Training loss: 0.3181556761264801
Validation loss: 2.144569436709086

Epoch: 6| Step: 7
Training loss: 0.3831152319908142
Validation loss: 2.1078426241874695

Epoch: 6| Step: 8
Training loss: 0.4230930805206299
Validation loss: 2.1436129411061606

Epoch: 6| Step: 9
Training loss: 0.19831012189388275
Validation loss: 2.1540661056836448

Epoch: 6| Step: 10
Training loss: 0.28043287992477417
Validation loss: 2.1868815422058105

Epoch: 6| Step: 11
Training loss: 0.30878186225891113
Validation loss: 2.2383156617482505

Epoch: 6| Step: 12
Training loss: 0.267755925655365
Validation loss: 2.23444002866745

Epoch: 6| Step: 13
Training loss: 0.5715113878250122
Validation loss: 2.218391398588816

Epoch: 467| Step: 0
Training loss: 0.4742066264152527
Validation loss: 2.2432274222373962

Epoch: 6| Step: 1
Training loss: 0.3244486451148987
Validation loss: 2.250410795211792

Epoch: 6| Step: 2
Training loss: 0.37574976682662964
Validation loss: 2.221678833166758

Epoch: 6| Step: 3
Training loss: 0.44791120290756226
Validation loss: 2.220808823903402

Epoch: 6| Step: 4
Training loss: 0.5751731991767883
Validation loss: 2.1854950189590454

Epoch: 6| Step: 5
Training loss: 0.415627121925354
Validation loss: 2.1594273249308267

Epoch: 6| Step: 6
Training loss: 0.7347052693367004
Validation loss: 2.129038314024607

Epoch: 6| Step: 7
Training loss: 0.4694660007953644
Validation loss: 2.1309017141660056

Epoch: 6| Step: 8
Training loss: 0.4052043557167053
Validation loss: 2.1175259749094644

Epoch: 6| Step: 9
Training loss: 0.676969051361084
Validation loss: 2.1382969419161477

Epoch: 6| Step: 10
Training loss: 0.45657262206077576
Validation loss: 2.1208811004956565

Epoch: 6| Step: 11
Training loss: 0.2948024868965149
Validation loss: 2.1728745698928833

Epoch: 6| Step: 12
Training loss: 0.30266693234443665
Validation loss: 2.2148890693982444

Epoch: 6| Step: 13
Training loss: 0.31411951780319214
Validation loss: 2.1842172145843506

Epoch: 468| Step: 0
Training loss: 0.3635496497154236
Validation loss: 2.170964161554972

Epoch: 6| Step: 1
Training loss: 0.3930596113204956
Validation loss: 2.2391587297121682

Epoch: 6| Step: 2
Training loss: 0.38272109627723694
Validation loss: 2.2479381958643594

Epoch: 6| Step: 3
Training loss: 0.39707067608833313
Validation loss: 2.2537927627563477

Epoch: 6| Step: 4
Training loss: 0.8099220991134644
Validation loss: 2.2300071318944297

Epoch: 6| Step: 5
Training loss: 0.30146440863609314
Validation loss: 2.243578791618347

Epoch: 6| Step: 6
Training loss: 0.5475437641143799
Validation loss: 2.285931388537089

Epoch: 6| Step: 7
Training loss: 0.4939497113227844
Validation loss: 2.288978656133016

Epoch: 6| Step: 8
Training loss: 0.7958201766014099
Validation loss: 2.2341514031092324

Epoch: 6| Step: 9
Training loss: 0.2542499899864197
Validation loss: 2.184006849924723

Epoch: 6| Step: 10
Training loss: 0.5502011179924011
Validation loss: 2.2028784354527793

Epoch: 6| Step: 11
Training loss: 0.511811375617981
Validation loss: 2.185280760129293

Epoch: 6| Step: 12
Training loss: 0.4615132212638855
Validation loss: 2.1485199530919394

Epoch: 6| Step: 13
Training loss: 0.25947263836860657
Validation loss: 2.1829538345336914

Epoch: 469| Step: 0
Training loss: 0.8623418211936951
Validation loss: 2.13346795241038

Epoch: 6| Step: 1
Training loss: 0.5743199586868286
Validation loss: 2.1771697402000427

Epoch: 6| Step: 2
Training loss: 0.6847873330116272
Validation loss: 2.162345747152964

Epoch: 6| Step: 3
Training loss: 0.38678503036499023
Validation loss: 2.152340829372406

Epoch: 6| Step: 4
Training loss: 0.5191025137901306
Validation loss: 2.1769136587778726

Epoch: 6| Step: 5
Training loss: 0.2649386525154114
Validation loss: 2.2016876538594565

Epoch: 6| Step: 6
Training loss: 0.4139028489589691
Validation loss: 2.2194177905718484

Epoch: 6| Step: 7
Training loss: 0.3531147837638855
Validation loss: 2.2565953532854715

Epoch: 6| Step: 8
Training loss: 0.26284581422805786
Validation loss: 2.1927496592203775

Epoch: 6| Step: 9
Training loss: 0.3099597096443176
Validation loss: 2.165596683820089

Epoch: 6| Step: 10
Training loss: 0.40300440788269043
Validation loss: 2.137167751789093

Epoch: 6| Step: 11
Training loss: 0.4965532124042511
Validation loss: 2.166790703932444

Epoch: 6| Step: 12
Training loss: 0.4089497923851013
Validation loss: 2.17709747950236

Epoch: 6| Step: 13
Training loss: 0.3242203891277313
Validation loss: 2.199522236982981

Epoch: 470| Step: 0
Training loss: 0.5844072699546814
Validation loss: 2.2266183694203696

Epoch: 6| Step: 1
Training loss: 0.4563552141189575
Validation loss: 2.1894837419191995

Epoch: 6| Step: 2
Training loss: 0.2849775552749634
Validation loss: 2.2184564073880515

Epoch: 6| Step: 3
Training loss: 0.395544171333313
Validation loss: 2.1878908276557922

Epoch: 6| Step: 4
Training loss: 0.28395891189575195
Validation loss: 2.1977399587631226

Epoch: 6| Step: 5
Training loss: 0.34133654832839966
Validation loss: 2.182531476020813

Epoch: 6| Step: 6
Training loss: 0.43172502517700195
Validation loss: 2.187387843926748

Epoch: 6| Step: 7
Training loss: 0.44320258498191833
Validation loss: 2.154372731844584

Epoch: 6| Step: 8
Training loss: 0.7695456147193909
Validation loss: 2.1598744789759317

Epoch: 6| Step: 9
Training loss: 0.38816311955451965
Validation loss: 2.181118110815684

Epoch: 6| Step: 10
Training loss: 0.3996688723564148
Validation loss: 2.165015002091726

Epoch: 6| Step: 11
Training loss: 0.38413387537002563
Validation loss: 2.2425010800361633

Epoch: 6| Step: 12
Training loss: 0.4382692873477936
Validation loss: 2.2137431701024375

Epoch: 6| Step: 13
Training loss: 0.9037429094314575
Validation loss: 2.2550772627194724

Epoch: 471| Step: 0
Training loss: 0.4023793339729309
Validation loss: 2.2511894504229226

Epoch: 6| Step: 1
Training loss: 0.584633469581604
Validation loss: 2.2538028359413147

Epoch: 6| Step: 2
Training loss: 0.8240454196929932
Validation loss: 2.2582366267840066

Epoch: 6| Step: 3
Training loss: 0.28446897864341736
Validation loss: 2.2147368590037027

Epoch: 6| Step: 4
Training loss: 1.0019245147705078
Validation loss: 2.2032798528671265

Epoch: 6| Step: 5
Training loss: 0.37848496437072754
Validation loss: 2.1693360408147178

Epoch: 6| Step: 6
Training loss: 0.4535890817642212
Validation loss: 2.1531291405359902

Epoch: 6| Step: 7
Training loss: 0.4517291784286499
Validation loss: 2.154686172803243

Epoch: 6| Step: 8
Training loss: 0.27134978771209717
Validation loss: 2.1699509024620056

Epoch: 6| Step: 9
Training loss: 0.37702202796936035
Validation loss: 2.153031587600708

Epoch: 6| Step: 10
Training loss: 0.27213436365127563
Validation loss: 2.1356924970944724

Epoch: 6| Step: 11
Training loss: 0.41581642627716064
Validation loss: 2.1744225025177

Epoch: 6| Step: 12
Training loss: 0.4358074367046356
Validation loss: 2.179917573928833

Epoch: 6| Step: 13
Training loss: 0.26563674211502075
Validation loss: 2.14337428410848

Epoch: 472| Step: 0
Training loss: 0.7658854722976685
Validation loss: 2.135662337144216

Epoch: 6| Step: 1
Training loss: 0.760586142539978
Validation loss: 2.122333347797394

Epoch: 6| Step: 2
Training loss: 0.5033183097839355
Validation loss: 2.1370374162991843

Epoch: 6| Step: 3
Training loss: 0.35940489172935486
Validation loss: 2.115005691846212

Epoch: 6| Step: 4
Training loss: 0.25779762864112854
Validation loss: 2.12908140818278

Epoch: 6| Step: 5
Training loss: 0.36323514580726624
Validation loss: 2.1967583497365317

Epoch: 6| Step: 6
Training loss: 0.6990876197814941
Validation loss: 2.207936147848765

Epoch: 6| Step: 7
Training loss: 0.3986107409000397
Validation loss: 2.216496308644613

Epoch: 6| Step: 8
Training loss: 0.3365516662597656
Validation loss: 2.231525500615438

Epoch: 6| Step: 9
Training loss: 0.4153936505317688
Validation loss: 2.2270567417144775

Epoch: 6| Step: 10
Training loss: 0.41909369826316833
Validation loss: 2.2441996335983276

Epoch: 6| Step: 11
Training loss: 0.5056347250938416
Validation loss: 2.2888564666112265

Epoch: 6| Step: 12
Training loss: 0.5256878137588501
Validation loss: 2.221637547016144

Epoch: 6| Step: 13
Training loss: 0.25358790159225464
Validation loss: 2.188830475012461

Epoch: 473| Step: 0
Training loss: 0.21141231060028076
Validation loss: 2.1346066991488137

Epoch: 6| Step: 1
Training loss: 0.4779101014137268
Validation loss: 2.1292948722839355

Epoch: 6| Step: 2
Training loss: 0.4863191843032837
Validation loss: 2.098636507987976

Epoch: 6| Step: 3
Training loss: 0.8014483451843262
Validation loss: 2.1408172448476157

Epoch: 6| Step: 4
Training loss: 0.476692259311676
Validation loss: 2.155721207459768

Epoch: 6| Step: 5
Training loss: 0.4310239255428314
Validation loss: 2.119909127553304

Epoch: 6| Step: 6
Training loss: 0.4517841935157776
Validation loss: 2.1704054474830627

Epoch: 6| Step: 7
Training loss: 0.2991201877593994
Validation loss: 2.2376978000005088

Epoch: 6| Step: 8
Training loss: 0.4378588795661926
Validation loss: 2.24570095539093

Epoch: 6| Step: 9
Training loss: 0.5245965123176575
Validation loss: 2.280520220597585

Epoch: 6| Step: 10
Training loss: 0.44071531295776367
Validation loss: 2.287209987640381

Epoch: 6| Step: 11
Training loss: 0.4072597026824951
Validation loss: 2.262616515159607

Epoch: 6| Step: 12
Training loss: 0.6453073024749756
Validation loss: 2.2816724379857383

Epoch: 6| Step: 13
Training loss: 0.35336223244667053
Validation loss: 2.221191108226776

Epoch: 474| Step: 0
Training loss: 0.3567368984222412
Validation loss: 2.1761083602905273

Epoch: 6| Step: 1
Training loss: 0.5638563632965088
Validation loss: 2.226139406363169

Epoch: 6| Step: 2
Training loss: 0.6919537782669067
Validation loss: 2.164340078830719

Epoch: 6| Step: 3
Training loss: 0.43893083930015564
Validation loss: 2.1672303477923074

Epoch: 6| Step: 4
Training loss: 0.2543148398399353
Validation loss: 2.1802212595939636

Epoch: 6| Step: 5
Training loss: 0.22382110357284546
Validation loss: 2.1545165379842124

Epoch: 6| Step: 6
Training loss: 0.32358476519584656
Validation loss: 2.1960177421569824

Epoch: 6| Step: 7
Training loss: 0.5078519582748413
Validation loss: 2.1842355926831565

Epoch: 6| Step: 8
Training loss: 0.33775532245635986
Validation loss: 2.1989360650380454

Epoch: 6| Step: 9
Training loss: 0.3460931181907654
Validation loss: 2.2228963971138

Epoch: 6| Step: 10
Training loss: 0.3971187472343445
Validation loss: 2.20921923716863

Epoch: 6| Step: 11
Training loss: 0.38177454471588135
Validation loss: 2.1934019128481546

Epoch: 6| Step: 12
Training loss: 0.4430311918258667
Validation loss: 2.2268815835316977

Epoch: 6| Step: 13
Training loss: 0.7932562232017517
Validation loss: 2.1825316548347473

Epoch: 475| Step: 0
Training loss: 0.6111820936203003
Validation loss: 2.178479234377543

Epoch: 6| Step: 1
Training loss: 0.35074812173843384
Validation loss: 2.1781481305758157

Epoch: 6| Step: 2
Training loss: 0.426766961812973
Validation loss: 2.2053460478782654

Epoch: 6| Step: 3
Training loss: 0.9343403577804565
Validation loss: 2.1630855997403464

Epoch: 6| Step: 4
Training loss: 0.4838704466819763
Validation loss: 2.198710481325785

Epoch: 6| Step: 5
Training loss: 0.26476919651031494
Validation loss: 2.1929933627446494

Epoch: 6| Step: 6
Training loss: 0.40827202796936035
Validation loss: 2.2376594146092734

Epoch: 6| Step: 7
Training loss: 0.2689930498600006
Validation loss: 2.254199127356211

Epoch: 6| Step: 8
Training loss: 0.47036492824554443
Validation loss: 2.2201905449231467

Epoch: 6| Step: 9
Training loss: 0.42304128408432007
Validation loss: 2.261207381884257

Epoch: 6| Step: 10
Training loss: 0.3675556778907776
Validation loss: 2.244286060333252

Epoch: 6| Step: 11
Training loss: 0.2551753520965576
Validation loss: 2.210325280825297

Epoch: 6| Step: 12
Training loss: 0.39154744148254395
Validation loss: 2.2234749595324197

Epoch: 6| Step: 13
Training loss: 0.7319914698600769
Validation loss: 2.1862694223721824

Epoch: 476| Step: 0
Training loss: 0.5240687727928162
Validation loss: 2.205240269502004

Epoch: 6| Step: 1
Training loss: 0.8289746046066284
Validation loss: 2.2424628337224326

Epoch: 6| Step: 2
Training loss: 0.13958731293678284
Validation loss: 2.2304133574167886

Epoch: 6| Step: 3
Training loss: 0.4936710000038147
Validation loss: 2.1498188575108848

Epoch: 6| Step: 4
Training loss: 0.3395996689796448
Validation loss: 2.1901135047276816

Epoch: 6| Step: 5
Training loss: 0.4969186782836914
Validation loss: 2.203486998875936

Epoch: 6| Step: 6
Training loss: 0.4769676923751831
Validation loss: 2.175890644391378

Epoch: 6| Step: 7
Training loss: 0.29013586044311523
Validation loss: 2.139370401700338

Epoch: 6| Step: 8
Training loss: 0.2763333320617676
Validation loss: 2.132263660430908

Epoch: 6| Step: 9
Training loss: 0.6342858076095581
Validation loss: 2.1420530478159585

Epoch: 6| Step: 10
Training loss: 0.2560887336730957
Validation loss: 2.148892800013224

Epoch: 6| Step: 11
Training loss: 0.4057808220386505
Validation loss: 2.1579346458117166

Epoch: 6| Step: 12
Training loss: 0.2678353786468506
Validation loss: 2.2308181126912436

Epoch: 6| Step: 13
Training loss: 0.3553234040737152
Validation loss: 2.211215535799662

Epoch: 477| Step: 0
Training loss: 0.5681898593902588
Validation loss: 2.2361020843187966

Epoch: 6| Step: 1
Training loss: 0.2692215144634247
Validation loss: 2.2328797578811646

Epoch: 6| Step: 2
Training loss: 0.48375028371810913
Validation loss: 2.2027309934298196

Epoch: 6| Step: 3
Training loss: 0.4459109306335449
Validation loss: 2.1718188325564065

Epoch: 6| Step: 4
Training loss: 0.6651172041893005
Validation loss: 2.2237102588017783

Epoch: 6| Step: 5
Training loss: 0.3657917380332947
Validation loss: 2.209613780180613

Epoch: 6| Step: 6
Training loss: 0.40841442346572876
Validation loss: 2.2422321240107217

Epoch: 6| Step: 7
Training loss: 0.2567833662033081
Validation loss: 2.1748600800832114

Epoch: 6| Step: 8
Training loss: 0.8263496160507202
Validation loss: 2.1876063545544944

Epoch: 6| Step: 9
Training loss: 0.21077412366867065
Validation loss: 2.1881224711736045

Epoch: 6| Step: 10
Training loss: 0.5204970240592957
Validation loss: 2.1801382303237915

Epoch: 6| Step: 11
Training loss: 0.38604414463043213
Validation loss: 2.188681125640869

Epoch: 6| Step: 12
Training loss: 0.19684654474258423
Validation loss: 2.2222920854886374

Epoch: 6| Step: 13
Training loss: 0.3918918967247009
Validation loss: 2.204742709795634

Epoch: 478| Step: 0
Training loss: 0.26925191283226013
Validation loss: 2.2674012780189514

Epoch: 6| Step: 1
Training loss: 0.43434858322143555
Validation loss: 2.203253189722697

Epoch: 6| Step: 2
Training loss: 0.6763815879821777
Validation loss: 2.1560919682184854

Epoch: 6| Step: 3
Training loss: 0.7679016590118408
Validation loss: 2.1818163990974426

Epoch: 6| Step: 4
Training loss: 0.2752304971218109
Validation loss: 2.1822308897972107

Epoch: 6| Step: 5
Training loss: 0.2935439944267273
Validation loss: 2.175847907861074

Epoch: 6| Step: 6
Training loss: 0.31825146079063416
Validation loss: 2.1590763131777444

Epoch: 6| Step: 7
Training loss: 0.42517709732055664
Validation loss: 2.149941901365916

Epoch: 6| Step: 8
Training loss: 0.46773025393486023
Validation loss: 2.16713547706604

Epoch: 6| Step: 9
Training loss: 0.6696410775184631
Validation loss: 2.204116483529409

Epoch: 6| Step: 10
Training loss: 0.21814939379692078
Validation loss: 2.1549255649248757

Epoch: 6| Step: 11
Training loss: 0.2746638059616089
Validation loss: 2.2092347145080566

Epoch: 6| Step: 12
Training loss: 0.24065858125686646
Validation loss: 2.2010364532470703

Epoch: 6| Step: 13
Training loss: 0.2780684232711792
Validation loss: 2.218173841635386

Epoch: 479| Step: 0
Training loss: 0.3848734200000763
Validation loss: 2.2045390804608664

Epoch: 6| Step: 1
Training loss: 0.36539721488952637
Validation loss: 2.216102878252665

Epoch: 6| Step: 2
Training loss: 0.25715339183807373
Validation loss: 2.2027567625045776

Epoch: 6| Step: 3
Training loss: 0.3319702744483948
Validation loss: 2.215668479601542

Epoch: 6| Step: 4
Training loss: 0.2459748089313507
Validation loss: 2.1762822469075522

Epoch: 6| Step: 5
Training loss: 0.2819240987300873
Validation loss: 2.1517349680264792

Epoch: 6| Step: 6
Training loss: 0.845853328704834
Validation loss: 2.197896401087443

Epoch: 6| Step: 7
Training loss: 0.6950712203979492
Validation loss: 2.167016585667928

Epoch: 6| Step: 8
Training loss: 0.21661430597305298
Validation loss: 2.1610562403996787

Epoch: 6| Step: 9
Training loss: 0.25712621212005615
Validation loss: 2.200821797053019

Epoch: 6| Step: 10
Training loss: 0.46621444821357727
Validation loss: 2.1969693501790366

Epoch: 6| Step: 11
Training loss: 0.2941933274269104
Validation loss: 2.1839158733685813

Epoch: 6| Step: 12
Training loss: 0.22205713391304016
Validation loss: 2.202428082625071

Epoch: 6| Step: 13
Training loss: 0.5711982250213623
Validation loss: 2.208310127258301

Epoch: 480| Step: 0
Training loss: 0.3451195955276489
Validation loss: 2.259824017683665

Epoch: 6| Step: 1
Training loss: 0.8289222121238708
Validation loss: 2.259063243865967

Epoch: 6| Step: 2
Training loss: 0.4095003008842468
Validation loss: 2.2447712421417236

Epoch: 6| Step: 3
Training loss: 0.4773100018501282
Validation loss: 2.2093781232833862

Epoch: 6| Step: 4
Training loss: 0.35707712173461914
Validation loss: 2.158427635828654

Epoch: 6| Step: 5
Training loss: 0.20205318927764893
Validation loss: 2.138670345147451

Epoch: 6| Step: 6
Training loss: 0.38280338048934937
Validation loss: 2.1302358508110046

Epoch: 6| Step: 7
Training loss: 0.31608420610427856
Validation loss: 2.112450977166494

Epoch: 6| Step: 8
Training loss: 0.5419279336929321
Validation loss: 2.140370786190033

Epoch: 6| Step: 9
Training loss: 0.6020897030830383
Validation loss: 2.0991020997365317

Epoch: 6| Step: 10
Training loss: 0.4007306694984436
Validation loss: 2.1527859767278037

Epoch: 6| Step: 11
Training loss: 0.546799898147583
Validation loss: 2.1654886603355408

Epoch: 6| Step: 12
Training loss: 0.4073471426963806
Validation loss: 2.1313464442888894

Epoch: 6| Step: 13
Training loss: 0.30554264783859253
Validation loss: 2.1428500612576804

Epoch: 481| Step: 0
Training loss: 0.48863789439201355
Validation loss: 2.14442108074824

Epoch: 6| Step: 1
Training loss: 0.49660661816596985
Validation loss: 2.2159404357274375

Epoch: 6| Step: 2
Training loss: 0.40476179122924805
Validation loss: 2.232041597366333

Epoch: 6| Step: 3
Training loss: 0.3100622892379761
Validation loss: 2.2390695015589395

Epoch: 6| Step: 4
Training loss: 0.5036659836769104
Validation loss: 2.1948222716649375

Epoch: 6| Step: 5
Training loss: 0.7017068266868591
Validation loss: 2.2050854166348777

Epoch: 6| Step: 6
Training loss: 0.5072345733642578
Validation loss: 2.208693047364553

Epoch: 6| Step: 7
Training loss: 0.3661556839942932
Validation loss: 2.22532711426417

Epoch: 6| Step: 8
Training loss: 0.23032253980636597
Validation loss: 2.242086430390676

Epoch: 6| Step: 9
Training loss: 0.27061647176742554
Validation loss: 2.2559033830960593

Epoch: 6| Step: 10
Training loss: 0.6930935978889465
Validation loss: 2.2193883657455444

Epoch: 6| Step: 11
Training loss: 0.24259847402572632
Validation loss: 2.164064804712931

Epoch: 6| Step: 12
Training loss: 0.3158016502857208
Validation loss: 2.170869509379069

Epoch: 6| Step: 13
Training loss: 0.39036041498184204
Validation loss: 2.1837937235832214

Epoch: 482| Step: 0
Training loss: 0.45240920782089233
Validation loss: 2.154825210571289

Epoch: 6| Step: 1
Training loss: 0.5621486902236938
Validation loss: 2.182893216609955

Epoch: 6| Step: 2
Training loss: 0.34718215465545654
Validation loss: 2.19255139430364

Epoch: 6| Step: 3
Training loss: 0.24012833833694458
Validation loss: 2.221455216407776

Epoch: 6| Step: 4
Training loss: 0.2897493541240692
Validation loss: 2.2145226995150247

Epoch: 6| Step: 5
Training loss: 0.29290980100631714
Validation loss: 2.3116981983184814

Epoch: 6| Step: 6
Training loss: 0.5156438946723938
Validation loss: 2.2687727212905884

Epoch: 6| Step: 7
Training loss: 0.3026300370693207
Validation loss: 2.215906500816345

Epoch: 6| Step: 8
Training loss: 0.25054270029067993
Validation loss: 2.226232906182607

Epoch: 6| Step: 9
Training loss: 0.429997980594635
Validation loss: 2.2233224312464395

Epoch: 6| Step: 10
Training loss: 0.3366870880126953
Validation loss: 2.2004255255063376

Epoch: 6| Step: 11
Training loss: 0.8285738825798035
Validation loss: 2.179526388645172

Epoch: 6| Step: 12
Training loss: 0.8264658451080322
Validation loss: 2.233701507250468

Epoch: 6| Step: 13
Training loss: 0.20607683062553406
Validation loss: 2.19686092933019

Epoch: 483| Step: 0
Training loss: 0.3343200087547302
Validation loss: 2.2235580682754517

Epoch: 6| Step: 1
Training loss: 0.3025329113006592
Validation loss: 2.1980509757995605

Epoch: 6| Step: 2
Training loss: 0.3095378875732422
Validation loss: 2.2185819347699485

Epoch: 6| Step: 3
Training loss: 0.41554272174835205
Validation loss: 2.2574366331100464

Epoch: 6| Step: 4
Training loss: 0.29492926597595215
Validation loss: 2.213153858979543

Epoch: 6| Step: 5
Training loss: 0.24183613061904907
Validation loss: 2.23164031902949

Epoch: 6| Step: 6
Training loss: 0.26592376828193665
Validation loss: 2.2346834937731423

Epoch: 6| Step: 7
Training loss: 1.1018422842025757
Validation loss: 2.207230051358541

Epoch: 6| Step: 8
Training loss: 0.4595857858657837
Validation loss: 2.27093243598938

Epoch: 6| Step: 9
Training loss: 0.43639254570007324
Validation loss: 2.231143514315287

Epoch: 6| Step: 10
Training loss: 0.6037593483924866
Validation loss: 2.277244806289673

Epoch: 6| Step: 11
Training loss: 0.23968881368637085
Validation loss: 2.2673885424931846

Epoch: 6| Step: 12
Training loss: 0.2798541486263275
Validation loss: 2.272232969601949

Epoch: 6| Step: 13
Training loss: 0.35169652104377747
Validation loss: 2.275485932826996

Epoch: 484| Step: 0
Training loss: 0.34482312202453613
Validation loss: 2.2720988988876343

Epoch: 6| Step: 1
Training loss: 0.34186357259750366
Validation loss: 2.2487415870030723

Epoch: 6| Step: 2
Training loss: 0.22811952233314514
Validation loss: 2.1900888284047446

Epoch: 6| Step: 3
Training loss: 0.31702959537506104
Validation loss: 2.182411034901937

Epoch: 6| Step: 4
Training loss: 0.4039728045463562
Validation loss: 2.2127227783203125

Epoch: 6| Step: 5
Training loss: 0.26149001717567444
Validation loss: 2.1933653752009072

Epoch: 6| Step: 6
Training loss: 0.8686456680297852
Validation loss: 2.1582495967547097

Epoch: 6| Step: 7
Training loss: 0.30768826603889465
Validation loss: 2.179039160410563

Epoch: 6| Step: 8
Training loss: 0.4290742874145508
Validation loss: 2.1394450267155967

Epoch: 6| Step: 9
Training loss: 0.614959716796875
Validation loss: 2.2081414063771567

Epoch: 6| Step: 10
Training loss: 0.26491332054138184
Validation loss: 2.2149462699890137

Epoch: 6| Step: 11
Training loss: 0.3643859028816223
Validation loss: 2.2043352524439492

Epoch: 6| Step: 12
Training loss: 0.49895918369293213
Validation loss: 2.2443127234776816

Epoch: 6| Step: 13
Training loss: 0.4448292553424835
Validation loss: 2.2609373331069946

Epoch: 485| Step: 0
Training loss: 0.242599219083786
Validation loss: 2.2009309927622476

Epoch: 6| Step: 1
Training loss: 0.23094463348388672
Validation loss: 2.1458795269330344

Epoch: 6| Step: 2
Training loss: 0.1192125454545021
Validation loss: 2.183505038420359

Epoch: 6| Step: 3
Training loss: 0.8212267160415649
Validation loss: 2.1575782100359597

Epoch: 6| Step: 4
Training loss: 0.2778966426849365
Validation loss: 2.2011449933052063

Epoch: 6| Step: 5
Training loss: 0.3480300307273865
Validation loss: 2.1968539357185364

Epoch: 6| Step: 6
Training loss: 0.5386060476303101
Validation loss: 2.2435238361358643

Epoch: 6| Step: 7
Training loss: 0.798509955406189
Validation loss: 2.241344471772512

Epoch: 6| Step: 8
Training loss: 0.34571295976638794
Validation loss: 2.2593947847684226

Epoch: 6| Step: 9
Training loss: 0.44558024406433105
Validation loss: 2.2817589243253074

Epoch: 6| Step: 10
Training loss: 0.5239812135696411
Validation loss: 2.2589906652768454

Epoch: 6| Step: 11
Training loss: 0.2870138883590698
Validation loss: 2.2387333512306213

Epoch: 6| Step: 12
Training loss: 0.2948252558708191
Validation loss: 2.235258142153422

Epoch: 6| Step: 13
Training loss: 0.36419737339019775
Validation loss: 2.2245760560035706

Epoch: 486| Step: 0
Training loss: 0.3413988947868347
Validation loss: 2.215967039267222

Epoch: 6| Step: 1
Training loss: 0.5653610825538635
Validation loss: 2.2134724458058677

Epoch: 6| Step: 2
Training loss: 0.31073498725891113
Validation loss: 2.19834836324056

Epoch: 6| Step: 3
Training loss: 0.3369326591491699
Validation loss: 2.191208779811859

Epoch: 6| Step: 4
Training loss: 0.30704885721206665
Validation loss: 2.2372920513153076

Epoch: 6| Step: 5
Training loss: 0.3638215661048889
Validation loss: 2.271319111188253

Epoch: 6| Step: 6
Training loss: 0.3353531062602997
Validation loss: 2.22835906346639

Epoch: 6| Step: 7
Training loss: 0.34266722202301025
Validation loss: 2.2306423584620156

Epoch: 6| Step: 8
Training loss: 0.44431179761886597
Validation loss: 2.2264930804570517

Epoch: 6| Step: 9
Training loss: 0.7401655912399292
Validation loss: 2.2163303097089133

Epoch: 6| Step: 10
Training loss: 0.39925405383110046
Validation loss: 2.215877652168274

Epoch: 6| Step: 11
Training loss: 0.5001442432403564
Validation loss: 2.2062034010887146

Epoch: 6| Step: 12
Training loss: 0.5153883099555969
Validation loss: 2.2229341665903726

Epoch: 6| Step: 13
Training loss: 0.300168514251709
Validation loss: 2.1392588218053183

Epoch: 487| Step: 0
Training loss: 0.23495817184448242
Validation loss: 2.1887181798617044

Epoch: 6| Step: 1
Training loss: 0.3036394417285919
Validation loss: 2.166724940141042

Epoch: 6| Step: 2
Training loss: 1.1287314891815186
Validation loss: 2.1456190745035806

Epoch: 6| Step: 3
Training loss: 0.5241191387176514
Validation loss: 2.156161665916443

Epoch: 6| Step: 4
Training loss: 0.3778442144393921
Validation loss: 2.1621869007746377

Epoch: 6| Step: 5
Training loss: 0.2913045883178711
Validation loss: 2.19068576892217

Epoch: 6| Step: 6
Training loss: 0.51835036277771
Validation loss: 2.1446241537729898

Epoch: 6| Step: 7
Training loss: 0.26867812871932983
Validation loss: 2.1439865827560425

Epoch: 6| Step: 8
Training loss: 0.3881330192089081
Validation loss: 2.1655594309171042

Epoch: 6| Step: 9
Training loss: 0.31693729758262634
Validation loss: 2.1785082618395486

Epoch: 6| Step: 10
Training loss: 0.4504127502441406
Validation loss: 2.2379541993141174

Epoch: 6| Step: 11
Training loss: 0.2975473999977112
Validation loss: 2.207316279411316

Epoch: 6| Step: 12
Training loss: 0.3549349308013916
Validation loss: 2.1949641704559326

Epoch: 6| Step: 13
Training loss: 0.3791049122810364
Validation loss: 2.1969287594159446

Epoch: 488| Step: 0
Training loss: 0.643508791923523
Validation loss: 2.243848979473114

Epoch: 6| Step: 1
Training loss: 0.3576613664627075
Validation loss: 2.2169679403305054

Epoch: 6| Step: 2
Training loss: 0.15466800332069397
Validation loss: 2.212010065714518

Epoch: 6| Step: 3
Training loss: 0.32261133193969727
Validation loss: 2.245725929737091

Epoch: 6| Step: 4
Training loss: 0.33874279260635376
Validation loss: 2.239230672518412

Epoch: 6| Step: 5
Training loss: 0.7478735446929932
Validation loss: 2.29764453570048

Epoch: 6| Step: 6
Training loss: 0.3282325863838196
Validation loss: 2.2538087169329324

Epoch: 6| Step: 7
Training loss: 0.3049556016921997
Validation loss: 2.2739179929097495

Epoch: 6| Step: 8
Training loss: 0.3230067491531372
Validation loss: 2.2737614711125693

Epoch: 6| Step: 9
Training loss: 0.4466363191604614
Validation loss: 2.2915274699529014

Epoch: 6| Step: 10
Training loss: 0.7121251821517944
Validation loss: 2.2662782271703086

Epoch: 6| Step: 11
Training loss: 0.41649383306503296
Validation loss: 2.2152382930119834

Epoch: 6| Step: 12
Training loss: 0.42580515146255493
Validation loss: 2.211556096871694

Epoch: 6| Step: 13
Training loss: 0.26133403182029724
Validation loss: 2.1809956630071006

Epoch: 489| Step: 0
Training loss: 0.2578977942466736
Validation loss: 2.192324241002401

Epoch: 6| Step: 1
Training loss: 0.36094778776168823
Validation loss: 2.162264426549276

Epoch: 6| Step: 2
Training loss: 0.27160531282424927
Validation loss: 2.1882452766100564

Epoch: 6| Step: 3
Training loss: 0.4844154715538025
Validation loss: 2.180452207724253

Epoch: 6| Step: 4
Training loss: 0.34653300046920776
Validation loss: 2.221831719080607

Epoch: 6| Step: 5
Training loss: 0.863764226436615
Validation loss: 2.253384212652842

Epoch: 6| Step: 6
Training loss: 0.4374636113643646
Validation loss: 2.2653753757476807

Epoch: 6| Step: 7
Training loss: 0.34549880027770996
Validation loss: 2.2488062381744385

Epoch: 6| Step: 8
Training loss: 0.43361371755599976
Validation loss: 2.2562817533810935

Epoch: 6| Step: 9
Training loss: 0.513424813747406
Validation loss: 2.253239075342814

Epoch: 6| Step: 10
Training loss: 0.3978518843650818
Validation loss: 2.216169794400533

Epoch: 6| Step: 11
Training loss: 0.4506818652153015
Validation loss: 2.1914020578066506

Epoch: 6| Step: 12
Training loss: 0.27132648229599
Validation loss: 2.202286640803019

Epoch: 6| Step: 13
Training loss: 0.4226798713207245
Validation loss: 2.1820905009905496

Epoch: 490| Step: 0
Training loss: 0.2604984939098358
Validation loss: 2.2370558381080627

Epoch: 6| Step: 1
Training loss: 0.2039702981710434
Validation loss: 2.182291587193807

Epoch: 6| Step: 2
Training loss: 0.39538395404815674
Validation loss: 2.176323731740316

Epoch: 6| Step: 3
Training loss: 0.2216998040676117
Validation loss: 2.150150418281555

Epoch: 6| Step: 4
Training loss: 0.4673738479614258
Validation loss: 2.2140048146247864

Epoch: 6| Step: 5
Training loss: 0.5774732828140259
Validation loss: 2.228535294532776

Epoch: 6| Step: 6
Training loss: 0.36736756563186646
Validation loss: 2.183816929658254

Epoch: 6| Step: 7
Training loss: 0.2890269160270691
Validation loss: 2.1895338694254556

Epoch: 6| Step: 8
Training loss: 0.6804425716400146
Validation loss: 2.155587991078695

Epoch: 6| Step: 9
Training loss: 0.4181627035140991
Validation loss: 2.155708372592926

Epoch: 6| Step: 10
Training loss: 0.2701803147792816
Validation loss: 2.1419834891955056

Epoch: 6| Step: 11
Training loss: 0.4134894907474518
Validation loss: 2.180682102839152

Epoch: 6| Step: 12
Training loss: 0.7417930364608765
Validation loss: 2.1872222423553467

Epoch: 6| Step: 13
Training loss: 0.2330537736415863
Validation loss: 2.20112677415212

Epoch: 491| Step: 0
Training loss: 0.20350226759910583
Validation loss: 2.158848782380422

Epoch: 6| Step: 1
Training loss: 0.47227922081947327
Validation loss: 2.217351218064626

Epoch: 6| Step: 2
Training loss: 0.368316113948822
Validation loss: 2.213210960229238

Epoch: 6| Step: 3
Training loss: 0.3765058219432831
Validation loss: 2.2476943135261536

Epoch: 6| Step: 4
Training loss: 0.43509066104888916
Validation loss: 2.2557727893193564

Epoch: 6| Step: 5
Training loss: 0.2399010807275772
Validation loss: 2.2530890305836997

Epoch: 6| Step: 6
Training loss: 0.5124263763427734
Validation loss: 2.2847289641698203

Epoch: 6| Step: 7
Training loss: 0.7615596652030945
Validation loss: 2.2583600282669067

Epoch: 6| Step: 8
Training loss: 0.3167543411254883
Validation loss: 2.3036530216534934

Epoch: 6| Step: 9
Training loss: 0.5491053462028503
Validation loss: 2.2508257826169333

Epoch: 6| Step: 10
Training loss: 0.23882587254047394
Validation loss: 2.230907599131266

Epoch: 6| Step: 11
Training loss: 0.2942568063735962
Validation loss: 2.2435695926348367

Epoch: 6| Step: 12
Training loss: 0.2981749475002289
Validation loss: 2.2321099440256753

Epoch: 6| Step: 13
Training loss: 0.23273639380931854
Validation loss: 2.230660557746887

Epoch: 492| Step: 0
Training loss: 0.3841513991355896
Validation loss: 2.177292545636495

Epoch: 6| Step: 1
Training loss: 0.2638782262802124
Validation loss: 2.2143642703692117

Epoch: 6| Step: 2
Training loss: 0.5023406744003296
Validation loss: 2.1470144788424173

Epoch: 6| Step: 3
Training loss: 0.8398773670196533
Validation loss: 2.183282971382141

Epoch: 6| Step: 4
Training loss: 0.2768111526966095
Validation loss: 2.204321304957072

Epoch: 6| Step: 5
Training loss: 0.3542383909225464
Validation loss: 2.2214678128560386

Epoch: 6| Step: 6
Training loss: 0.32159721851348877
Validation loss: 2.2161934773127236

Epoch: 6| Step: 7
Training loss: 0.28469938039779663
Validation loss: 2.2056827743848166

Epoch: 6| Step: 8
Training loss: 0.2901064157485962
Validation loss: 2.2184685667355857

Epoch: 6| Step: 9
Training loss: 0.32443493604660034
Validation loss: 2.2225754857063293

Epoch: 6| Step: 10
Training loss: 0.6644341945648193
Validation loss: 2.2353099385897317

Epoch: 6| Step: 11
Training loss: 0.17755654454231262
Validation loss: 2.181028167406718

Epoch: 6| Step: 12
Training loss: 0.3448212742805481
Validation loss: 2.2017213503519693

Epoch: 6| Step: 13
Training loss: 0.3690248131752014
Validation loss: 2.1119998494784036

Epoch: 493| Step: 0
Training loss: 0.5156422853469849
Validation loss: 2.141888896624247

Epoch: 6| Step: 1
Training loss: 0.26542922854423523
Validation loss: 2.1113859017690024

Epoch: 6| Step: 2
Training loss: 0.2289532572031021
Validation loss: 2.131890296936035

Epoch: 6| Step: 3
Training loss: 0.36172279715538025
Validation loss: 2.084246277809143

Epoch: 6| Step: 4
Training loss: 0.619314968585968
Validation loss: 2.154511789480845

Epoch: 6| Step: 5
Training loss: 0.2758290767669678
Validation loss: 2.159658133983612

Epoch: 6| Step: 6
Training loss: 0.22729597985744476
Validation loss: 2.253180225690206

Epoch: 6| Step: 7
Training loss: 0.2752336859703064
Validation loss: 2.2848227421442666

Epoch: 6| Step: 8
Training loss: 0.7205119729042053
Validation loss: 2.3027886549631753

Epoch: 6| Step: 9
Training loss: 0.40514254570007324
Validation loss: 2.401309331258138

Epoch: 6| Step: 10
Training loss: 0.5360175967216492
Validation loss: 2.3308277130126953

Epoch: 6| Step: 11
Training loss: 0.8583073616027832
Validation loss: 2.3321913679440818

Epoch: 6| Step: 12
Training loss: 0.33801010251045227
Validation loss: 2.2936336994171143

Epoch: 6| Step: 13
Training loss: 0.3068925142288208
Validation loss: 2.2490543524424234

Epoch: 494| Step: 0
Training loss: 0.6048052310943604
Validation loss: 2.224712332089742

Epoch: 6| Step: 1
Training loss: 0.35785508155822754
Validation loss: 2.170123020807902

Epoch: 6| Step: 2
Training loss: 0.52279132604599
Validation loss: 2.1586997310320535

Epoch: 6| Step: 3
Training loss: 0.3913452625274658
Validation loss: 2.1922953128814697

Epoch: 6| Step: 4
Training loss: 0.8046958446502686
Validation loss: 2.207528511683146

Epoch: 6| Step: 5
Training loss: 0.3708106279373169
Validation loss: 2.2511384089787803

Epoch: 6| Step: 6
Training loss: 0.3431470990180969
Validation loss: 2.2483114997545877

Epoch: 6| Step: 7
Training loss: 0.34947633743286133
Validation loss: 2.2218027114868164

Epoch: 6| Step: 8
Training loss: 0.3107559084892273
Validation loss: 2.2173812985420227

Epoch: 6| Step: 9
Training loss: 0.31542688608169556
Validation loss: 2.227213680744171

Epoch: 6| Step: 10
Training loss: 0.3084883987903595
Validation loss: 2.209218144416809

Epoch: 6| Step: 11
Training loss: 0.46864694356918335
Validation loss: 2.242557187875112

Epoch: 6| Step: 12
Training loss: 0.30951160192489624
Validation loss: 2.2723886171976724

Epoch: 6| Step: 13
Training loss: 0.3282316327095032
Validation loss: 2.2752727270126343

Epoch: 495| Step: 0
Training loss: 0.40643465518951416
Validation loss: 2.278154671192169

Epoch: 6| Step: 1
Training loss: 0.3010309934616089
Validation loss: 2.2566628058751426

Epoch: 6| Step: 2
Training loss: 0.28801894187927246
Validation loss: 2.2586206595102944

Epoch: 6| Step: 3
Training loss: 0.35345953702926636
Validation loss: 2.1950833598772683

Epoch: 6| Step: 4
Training loss: 0.32733267545700073
Validation loss: 2.1918679078420005

Epoch: 6| Step: 5
Training loss: 0.26719021797180176
Validation loss: 2.227000097433726

Epoch: 6| Step: 6
Training loss: 0.3441925346851349
Validation loss: 2.2020970582962036

Epoch: 6| Step: 7
Training loss: 0.22496667504310608
Validation loss: 2.1801296273867288

Epoch: 6| Step: 8
Training loss: 0.41177624464035034
Validation loss: 2.1956454316775003

Epoch: 6| Step: 9
Training loss: 0.3789348304271698
Validation loss: 2.2300498882929483

Epoch: 6| Step: 10
Training loss: 0.6366826295852661
Validation loss: 2.2321139772733054

Epoch: 6| Step: 11
Training loss: 0.37414538860321045
Validation loss: 2.2721095085144043

Epoch: 6| Step: 12
Training loss: 0.7184497117996216
Validation loss: 2.252503593762716

Epoch: 6| Step: 13
Training loss: 0.2518596649169922
Validation loss: 2.251687784989675

Epoch: 496| Step: 0
Training loss: 0.2820630669593811
Validation loss: 2.2559807499249778

Epoch: 6| Step: 1
Training loss: 0.2899788022041321
Validation loss: 2.2517754236857095

Epoch: 6| Step: 2
Training loss: 0.3098341226577759
Validation loss: 2.2141790191332498

Epoch: 6| Step: 3
Training loss: 0.4168001115322113
Validation loss: 2.226759950319926

Epoch: 6| Step: 4
Training loss: 0.8909740447998047
Validation loss: 2.1649803519248962

Epoch: 6| Step: 5
Training loss: 0.3172147274017334
Validation loss: 2.2040321628252664

Epoch: 6| Step: 6
Training loss: 0.38803333044052124
Validation loss: 2.2220698595046997

Epoch: 6| Step: 7
Training loss: 0.42746978998184204
Validation loss: 2.2575233976046243

Epoch: 6| Step: 8
Training loss: 0.24689511954784393
Validation loss: 2.2566857735315957

Epoch: 6| Step: 9
Training loss: 0.26213186979293823
Validation loss: 2.2586368719736734

Epoch: 6| Step: 10
Training loss: 0.4198933243751526
Validation loss: 2.3178241650263467

Epoch: 6| Step: 11
Training loss: 0.4040641784667969
Validation loss: 2.27350652217865

Epoch: 6| Step: 12
Training loss: 0.34061169624328613
Validation loss: 2.2268707354863486

Epoch: 6| Step: 13
Training loss: 0.5538768172264099
Validation loss: 2.194864352544149

Epoch: 497| Step: 0
Training loss: 0.3923528790473938
Validation loss: 2.169844845930735

Epoch: 6| Step: 1
Training loss: 0.34146982431411743
Validation loss: 2.129572093486786

Epoch: 6| Step: 2
Training loss: 0.9400345087051392
Validation loss: 2.1356436212857566

Epoch: 6| Step: 3
Training loss: 0.31165391206741333
Validation loss: 2.180865923563639

Epoch: 6| Step: 4
Training loss: 0.2432805448770523
Validation loss: 2.181440611680349

Epoch: 6| Step: 5
Training loss: 0.20452120900154114
Validation loss: 2.2295950055122375

Epoch: 6| Step: 6
Training loss: 0.533223032951355
Validation loss: 2.289092461268107

Epoch: 6| Step: 7
Training loss: 0.4415994882583618
Validation loss: 2.2425710757573447

Epoch: 6| Step: 8
Training loss: 0.36394309997558594
Validation loss: 2.2607248028119407

Epoch: 6| Step: 9
Training loss: 0.21645762026309967
Validation loss: 2.2108373244603476

Epoch: 6| Step: 10
Training loss: 0.396572470664978
Validation loss: 2.2030049363772073

Epoch: 6| Step: 11
Training loss: 0.3120720684528351
Validation loss: 2.1837011575698853

Epoch: 6| Step: 12
Training loss: 0.34234049916267395
Validation loss: 2.200880706310272

Epoch: 6| Step: 13
Training loss: 0.714745044708252
Validation loss: 2.237696965535482

Epoch: 498| Step: 0
Training loss: 0.3900492787361145
Validation loss: 2.2338674068450928

Epoch: 6| Step: 1
Training loss: 0.3508210778236389
Validation loss: 2.2000606656074524

Epoch: 6| Step: 2
Training loss: 0.21290799975395203
Validation loss: 2.235822776953379

Epoch: 6| Step: 3
Training loss: 0.31139570474624634
Validation loss: 2.232471764087677

Epoch: 6| Step: 4
Training loss: 0.29490190744400024
Validation loss: 2.251166661580404

Epoch: 6| Step: 5
Training loss: 0.3165055513381958
Validation loss: 2.240086555480957

Epoch: 6| Step: 6
Training loss: 0.3668394684791565
Validation loss: 2.2617842157681785

Epoch: 6| Step: 7
Training loss: 0.6980123519897461
Validation loss: 2.2904836535453796

Epoch: 6| Step: 8
Training loss: 0.26728183031082153
Validation loss: 2.241911987463633

Epoch: 6| Step: 9
Training loss: 0.37899279594421387
Validation loss: 2.246192991733551

Epoch: 6| Step: 10
Training loss: 0.32208311557769775
Validation loss: 2.2523402770360312

Epoch: 6| Step: 11
Training loss: 0.5806168913841248
Validation loss: 2.215091069539388

Epoch: 6| Step: 12
Training loss: 0.3534737825393677
Validation loss: 2.2130905787150064

Epoch: 6| Step: 13
Training loss: 0.5814713835716248
Validation loss: 2.1898358265558877

Epoch: 499| Step: 0
Training loss: 0.298500657081604
Validation loss: 2.164385994275411

Epoch: 6| Step: 1
Training loss: 0.3546949028968811
Validation loss: 2.1627172430356345

Epoch: 6| Step: 2
Training loss: 0.31685078144073486
Validation loss: 2.1655064026514688

Epoch: 6| Step: 3
Training loss: 0.4433167576789856
Validation loss: 2.2158083319664

Epoch: 6| Step: 4
Training loss: 0.26672059297561646
Validation loss: 2.2202767531077066

Epoch: 6| Step: 5
Training loss: 0.30987417697906494
Validation loss: 2.2629588643709817

Epoch: 6| Step: 6
Training loss: 0.341251015663147
Validation loss: 2.251144210497538

Epoch: 6| Step: 7
Training loss: 0.21354025602340698
Validation loss: 2.211825450261434

Epoch: 6| Step: 8
Training loss: 0.4881177842617035
Validation loss: 2.186721165974935

Epoch: 6| Step: 9
Training loss: 0.390372097492218
Validation loss: 2.1601105531056723

Epoch: 6| Step: 10
Training loss: 0.7566391229629517
Validation loss: 2.133261561393738

Epoch: 6| Step: 11
Training loss: 0.3732178211212158
Validation loss: 2.15278892715772

Epoch: 6| Step: 12
Training loss: 0.764174222946167
Validation loss: 2.1638379295667014

Epoch: 6| Step: 13
Training loss: 0.4826979637145996
Validation loss: 2.1813272833824158

Epoch: 500| Step: 0
Training loss: 0.6255102753639221
Validation loss: 2.168397009372711

Epoch: 6| Step: 1
Training loss: 0.2945352792739868
Validation loss: 2.2338464657465615

Epoch: 6| Step: 2
Training loss: 0.4219391345977783
Validation loss: 2.2738090356191

Epoch: 6| Step: 3
Training loss: 0.6897976994514465
Validation loss: 2.286189695199331

Epoch: 6| Step: 4
Training loss: 0.538956344127655
Validation loss: 2.231801132361094

Epoch: 6| Step: 5
Training loss: 0.24934905767440796
Validation loss: 2.232169965902964

Epoch: 6| Step: 6
Training loss: 0.3328559398651123
Validation loss: 2.2053224047025046

Epoch: 6| Step: 7
Training loss: 0.45569702982902527
Validation loss: 2.221033732096354

Epoch: 6| Step: 8
Training loss: 0.2054915428161621
Validation loss: 2.186711927254995

Epoch: 6| Step: 9
Training loss: 0.37980157136917114
Validation loss: 2.28786834081014

Epoch: 6| Step: 10
Training loss: 0.40990281105041504
Validation loss: 2.2284528811772666

Epoch: 6| Step: 11
Training loss: 0.19244271516799927
Validation loss: 2.2572197914123535

Epoch: 6| Step: 12
Training loss: 0.23814620077610016
Validation loss: 2.24688720703125

Epoch: 6| Step: 13
Training loss: 0.25375673174858093
Validation loss: 2.2708692153294883

Epoch: 501| Step: 0
Training loss: 0.3100705146789551
Validation loss: 2.238642454147339

Epoch: 6| Step: 1
Training loss: 0.12722083926200867
Validation loss: 2.2722143729527793

Epoch: 6| Step: 2
Training loss: 0.31922876834869385
Validation loss: 2.269999345143636

Epoch: 6| Step: 3
Training loss: 0.2418137788772583
Validation loss: 2.213300883769989

Epoch: 6| Step: 4
Training loss: 0.29629454016685486
Validation loss: 2.2557138800621033

Epoch: 6| Step: 5
Training loss: 0.21601302921772003
Validation loss: 2.151146650314331

Epoch: 6| Step: 6
Training loss: 0.3391932249069214
Validation loss: 2.185287078221639

Epoch: 6| Step: 7
Training loss: 0.32284656167030334
Validation loss: 2.1992383003234863

Epoch: 6| Step: 8
Training loss: 0.4480012059211731
Validation loss: 2.136539340019226

Epoch: 6| Step: 9
Training loss: 0.38894525170326233
Validation loss: 2.1900712847709656

Epoch: 6| Step: 10
Training loss: 0.3184143900871277
Validation loss: 2.177099585533142

Epoch: 6| Step: 11
Training loss: 0.3370122015476227
Validation loss: 2.1921446720759072

Epoch: 6| Step: 12
Training loss: 0.35648614168167114
Validation loss: 2.132197320461273

Epoch: 6| Step: 13
Training loss: 1.0199353694915771
Validation loss: 2.1479658087094626

Epoch: 502| Step: 0
Training loss: 0.2079651951789856
Validation loss: 2.149142781893412

Epoch: 6| Step: 1
Training loss: 0.2544519603252411
Validation loss: 2.1717695593833923

Epoch: 6| Step: 2
Training loss: 0.3320496082305908
Validation loss: 2.213905413945516

Epoch: 6| Step: 3
Training loss: 0.25032684206962585
Validation loss: 2.242280423641205

Epoch: 6| Step: 4
Training loss: 0.30369096994400024
Validation loss: 2.2372250159581504

Epoch: 6| Step: 5
Training loss: 0.767107367515564
Validation loss: 2.1854374607404075

Epoch: 6| Step: 6
Training loss: 0.2694869637489319
Validation loss: 2.212334950764974

Epoch: 6| Step: 7
Training loss: 0.3884561061859131
Validation loss: 2.2242496411005654

Epoch: 6| Step: 8
Training loss: 0.6252576112747192
Validation loss: 2.1976885398228965

Epoch: 6| Step: 9
Training loss: 0.43900755047798157
Validation loss: 2.1997729937235513

Epoch: 6| Step: 10
Training loss: 0.1873442530632019
Validation loss: 2.268784443537394

Epoch: 6| Step: 11
Training loss: 0.3342741131782532
Validation loss: 2.27700674533844

Epoch: 6| Step: 12
Training loss: 0.34976550936698914
Validation loss: 2.22307026386261

Epoch: 6| Step: 13
Training loss: 0.5089246034622192
Validation loss: 2.250852624575297

Epoch: 503| Step: 0
Training loss: 0.6981126666069031
Validation loss: 2.2430644830067954

Epoch: 6| Step: 1
Training loss: 0.2650585174560547
Validation loss: 2.2773895859718323

Epoch: 6| Step: 2
Training loss: 0.24628573656082153
Validation loss: 2.1870551705360413

Epoch: 6| Step: 3
Training loss: 0.19273634254932404
Validation loss: 2.221642633279165

Epoch: 6| Step: 4
Training loss: 0.19662319123744965
Validation loss: 2.220108171304067

Epoch: 6| Step: 5
Training loss: 0.49431777000427246
Validation loss: 2.180306911468506

Epoch: 6| Step: 6
Training loss: 0.33652207255363464
Validation loss: 2.168816884358724

Epoch: 6| Step: 7
Training loss: 0.3447679877281189
Validation loss: 2.217652122179667

Epoch: 6| Step: 8
Training loss: 0.28336644172668457
Validation loss: 2.2434075276056924

Epoch: 6| Step: 9
Training loss: 0.3907676935195923
Validation loss: 2.22117284933726

Epoch: 6| Step: 10
Training loss: 0.34631457924842834
Validation loss: 2.3053576747576394

Epoch: 6| Step: 11
Training loss: 0.7369940876960754
Validation loss: 2.282505214214325

Epoch: 6| Step: 12
Training loss: 0.3492652177810669
Validation loss: 2.2506429155667624

Epoch: 6| Step: 13
Training loss: 0.3629401624202728
Validation loss: 2.203316549460093

Epoch: 504| Step: 0
Training loss: 0.25692319869995117
Validation loss: 2.230116625626882

Epoch: 6| Step: 1
Training loss: 0.32069945335388184
Validation loss: 2.216987351576487

Epoch: 6| Step: 2
Training loss: 0.3613255023956299
Validation loss: 2.121483643849691

Epoch: 6| Step: 3
Training loss: 0.3465449810028076
Validation loss: 2.18508650859197

Epoch: 6| Step: 4
Training loss: 0.38214027881622314
Validation loss: 2.117738664150238

Epoch: 6| Step: 5
Training loss: 0.49600881338119507
Validation loss: 2.1494380036989846

Epoch: 6| Step: 6
Training loss: 0.5319129228591919
Validation loss: 2.2097494999567666

Epoch: 6| Step: 7
Training loss: 0.3087289333343506
Validation loss: 2.264828602472941

Epoch: 6| Step: 8
Training loss: 0.8622393012046814
Validation loss: 2.2860978643099465

Epoch: 6| Step: 9
Training loss: 0.2744314670562744
Validation loss: 2.2787133057912192

Epoch: 6| Step: 10
Training loss: 0.4735003113746643
Validation loss: 2.2734100421269736

Epoch: 6| Step: 11
Training loss: 0.2837573289871216
Validation loss: 2.268216888109843

Epoch: 6| Step: 12
Training loss: 0.4253614544868469
Validation loss: 2.2331120371818542

Epoch: 6| Step: 13
Training loss: 0.33891206979751587
Validation loss: 2.2090247869491577

Epoch: 505| Step: 0
Training loss: 0.7218621373176575
Validation loss: 2.1953676342964172

Epoch: 6| Step: 1
Training loss: 0.44089460372924805
Validation loss: 2.1510061025619507

Epoch: 6| Step: 2
Training loss: 0.6063462495803833
Validation loss: 2.189303437868754

Epoch: 6| Step: 3
Training loss: 0.5260879397392273
Validation loss: 2.1802612940470376

Epoch: 6| Step: 4
Training loss: 0.4713904857635498
Validation loss: 2.1908798813819885

Epoch: 6| Step: 5
Training loss: 0.311722993850708
Validation loss: 2.240471442540487

Epoch: 6| Step: 6
Training loss: 0.45653268694877625
Validation loss: 2.1995869477589927

Epoch: 6| Step: 7
Training loss: 0.22305618226528168
Validation loss: 2.238240599632263

Epoch: 6| Step: 8
Training loss: 0.42814770340919495
Validation loss: 2.247046172618866

Epoch: 6| Step: 9
Training loss: 0.3432549238204956
Validation loss: 2.296342154343923

Epoch: 6| Step: 10
Training loss: 0.7067334651947021
Validation loss: 2.2580678462982178

Epoch: 6| Step: 11
Training loss: 0.349719762802124
Validation loss: 2.30605677763621

Epoch: 6| Step: 12
Training loss: 0.3073675334453583
Validation loss: 2.1932772397994995

Epoch: 6| Step: 13
Training loss: 0.3220304846763611
Validation loss: 2.194232086340586

Epoch: 506| Step: 0
Training loss: 0.7418431043624878
Validation loss: 2.1748761932055154

Epoch: 6| Step: 1
Training loss: 0.487105131149292
Validation loss: 2.202330390612284

Epoch: 6| Step: 2
Training loss: 0.7982140779495239
Validation loss: 2.1726240714391074

Epoch: 6| Step: 3
Training loss: 0.3113498091697693
Validation loss: 2.1846224069595337

Epoch: 6| Step: 4
Training loss: 0.49728310108184814
Validation loss: 2.1734582781791687

Epoch: 6| Step: 5
Training loss: 0.3253670930862427
Validation loss: 2.2000178893407187

Epoch: 6| Step: 6
Training loss: 0.33952945470809937
Validation loss: 2.2437435388565063

Epoch: 6| Step: 7
Training loss: 0.39625656604766846
Validation loss: 2.268384794394175

Epoch: 6| Step: 8
Training loss: 0.2764580249786377
Validation loss: 2.3051751057306924

Epoch: 6| Step: 9
Training loss: 0.38429784774780273
Validation loss: 2.2702677051226297

Epoch: 6| Step: 10
Training loss: 0.3382648229598999
Validation loss: 2.2481911381085715

Epoch: 6| Step: 11
Training loss: 0.29446983337402344
Validation loss: 2.244387686252594

Epoch: 6| Step: 12
Training loss: 0.34514328837394714
Validation loss: 2.2302953402201333

Epoch: 6| Step: 13
Training loss: 0.4034581482410431
Validation loss: 2.2239889105161033

Epoch: 507| Step: 0
Training loss: 0.40907150506973267
Validation loss: 2.1786627769470215

Epoch: 6| Step: 1
Training loss: 0.23631437122821808
Validation loss: 2.194047470887502

Epoch: 6| Step: 2
Training loss: 0.38309967517852783
Validation loss: 2.168750007947286

Epoch: 6| Step: 3
Training loss: 0.40438222885131836
Validation loss: 2.1251535216967263

Epoch: 6| Step: 4
Training loss: 0.33304187655448914
Validation loss: 2.1692528327306113

Epoch: 6| Step: 5
Training loss: 0.3066936135292053
Validation loss: 2.162274738152822

Epoch: 6| Step: 6
Training loss: 0.3687659502029419
Validation loss: 2.172372301419576

Epoch: 6| Step: 7
Training loss: 0.5328561663627625
Validation loss: 2.2169344822565713

Epoch: 6| Step: 8
Training loss: 0.7209292650222778
Validation loss: 2.1622947653134665

Epoch: 6| Step: 9
Training loss: 0.24350237846374512
Validation loss: 2.2158579230308533

Epoch: 6| Step: 10
Training loss: 0.6369810104370117
Validation loss: 2.191809435685476

Epoch: 6| Step: 11
Training loss: 0.3162127137184143
Validation loss: 2.2448032895723977

Epoch: 6| Step: 12
Training loss: 0.31046706438064575
Validation loss: 2.2668344577153525

Epoch: 6| Step: 13
Training loss: 0.3655402660369873
Validation loss: 2.2219611207644143

Epoch: 508| Step: 0
Training loss: 0.2525983452796936
Validation loss: 2.2231770753860474

Epoch: 6| Step: 1
Training loss: 0.2853794991970062
Validation loss: 2.2599562605222068

Epoch: 6| Step: 2
Training loss: 0.3694351315498352
Validation loss: 2.25278772910436

Epoch: 6| Step: 3
Training loss: 0.6455457806587219
Validation loss: 2.2517107725143433

Epoch: 6| Step: 4
Training loss: 0.5584967136383057
Validation loss: 2.2016791303952536

Epoch: 6| Step: 5
Training loss: 0.27818894386291504
Validation loss: 2.2423598567644754

Epoch: 6| Step: 6
Training loss: 0.37325358390808105
Validation loss: 2.2584464152654014

Epoch: 6| Step: 7
Training loss: 0.2254919409751892
Validation loss: 2.265305995941162

Epoch: 6| Step: 8
Training loss: 0.32697242498397827
Validation loss: 2.2223134636878967

Epoch: 6| Step: 9
Training loss: 0.7054792642593384
Validation loss: 2.2572218577067056

Epoch: 6| Step: 10
Training loss: 0.2581915259361267
Validation loss: 2.2410318652788797

Epoch: 6| Step: 11
Training loss: 0.2508835196495056
Validation loss: 2.221350312232971

Epoch: 6| Step: 12
Training loss: 0.21477973461151123
Validation loss: 2.184243639310201

Epoch: 6| Step: 13
Training loss: 0.32905420660972595
Validation loss: 2.258641242980957

Epoch: 509| Step: 0
Training loss: 0.28643548488616943
Validation loss: 2.3089906573295593

Epoch: 6| Step: 1
Training loss: 0.5097487568855286
Validation loss: 2.2462037801742554

Epoch: 6| Step: 2
Training loss: 0.6822073459625244
Validation loss: 2.277751604715983

Epoch: 6| Step: 3
Training loss: 0.640915036201477
Validation loss: 2.227149804433187

Epoch: 6| Step: 4
Training loss: 0.23116785287857056
Validation loss: 2.1708298921585083

Epoch: 6| Step: 5
Training loss: 0.3916512429714203
Validation loss: 2.1834389368693032

Epoch: 6| Step: 6
Training loss: 0.42560532689094543
Validation loss: 2.2067752281824746

Epoch: 6| Step: 7
Training loss: 0.5851534605026245
Validation loss: 2.205246607462565

Epoch: 6| Step: 8
Training loss: 0.28901833295822144
Validation loss: 2.1740601658821106

Epoch: 6| Step: 9
Training loss: 0.3160402178764343
Validation loss: 2.199254333972931

Epoch: 6| Step: 10
Training loss: 0.3183826208114624
Validation loss: 2.2299088835716248

Epoch: 6| Step: 11
Training loss: 0.33777326345443726
Validation loss: 2.263208011786143

Epoch: 6| Step: 12
Training loss: 0.2257302701473236
Validation loss: 2.3110506534576416

Epoch: 6| Step: 13
Training loss: 0.4448583424091339
Validation loss: 2.3507636388142905

Epoch: 510| Step: 0
Training loss: 0.7402680516242981
Validation loss: 2.298200329144796

Epoch: 6| Step: 1
Training loss: 0.4169032871723175
Validation loss: 2.3465662002563477

Epoch: 6| Step: 2
Training loss: 0.4066357910633087
Validation loss: 2.307036598523458

Epoch: 6| Step: 3
Training loss: 0.3140588402748108
Validation loss: 2.3224727710088096

Epoch: 6| Step: 4
Training loss: 0.33696654438972473
Validation loss: 2.2786863446235657

Epoch: 6| Step: 5
Training loss: 0.2247907817363739
Validation loss: 2.2505773305892944

Epoch: 6| Step: 6
Training loss: 0.30142173171043396
Validation loss: 2.2554078499476113

Epoch: 6| Step: 7
Training loss: 0.5041292309761047
Validation loss: 2.2213778495788574

Epoch: 6| Step: 8
Training loss: 0.26793432235717773
Validation loss: 2.2334250013033548

Epoch: 6| Step: 9
Training loss: 0.2464291751384735
Validation loss: 2.266968329747518

Epoch: 6| Step: 10
Training loss: 0.4186256527900696
Validation loss: 2.2394282817840576

Epoch: 6| Step: 11
Training loss: 0.32379665970802307
Validation loss: 2.283253530661265

Epoch: 6| Step: 12
Training loss: 0.6203075051307678
Validation loss: 2.294945398966471

Epoch: 6| Step: 13
Training loss: 0.30942851305007935
Validation loss: 2.292563319206238

Epoch: 511| Step: 0
Training loss: 0.767200231552124
Validation loss: 2.3047302961349487

Epoch: 6| Step: 1
Training loss: 0.5065796971321106
Validation loss: 2.285326838493347

Epoch: 6| Step: 2
Training loss: 0.2678776681423187
Validation loss: 2.262999713420868

Epoch: 6| Step: 3
Training loss: 0.27530327439308167
Validation loss: 2.2108317414919534

Epoch: 6| Step: 4
Training loss: 0.3878115713596344
Validation loss: 2.180450896422068

Epoch: 6| Step: 5
Training loss: 0.2732067406177521
Validation loss: 2.163263261318207

Epoch: 6| Step: 6
Training loss: 0.24014762043952942
Validation loss: 2.1540380716323853

Epoch: 6| Step: 7
Training loss: 0.39075329899787903
Validation loss: 2.1862764954566956

Epoch: 6| Step: 8
Training loss: 0.40286171436309814
Validation loss: 2.1638140281041465

Epoch: 6| Step: 9
Training loss: 0.2963464558124542
Validation loss: 2.213233252366384

Epoch: 6| Step: 10
Training loss: 0.442867249250412
Validation loss: 2.2382214864095054

Epoch: 6| Step: 11
Training loss: 0.7796018719673157
Validation loss: 2.343241552511851

Epoch: 6| Step: 12
Training loss: 0.39786621928215027
Validation loss: 2.3035053809483848

Epoch: 6| Step: 13
Training loss: 0.4781951308250427
Validation loss: 2.365635931491852

Epoch: 512| Step: 0
Training loss: 0.6033023595809937
Validation loss: 2.3570206562678018

Epoch: 6| Step: 1
Training loss: 0.564767599105835
Validation loss: 2.349069436391195

Epoch: 6| Step: 2
Training loss: 0.30072298645973206
Validation loss: 2.306113123893738

Epoch: 6| Step: 3
Training loss: 0.3019581437110901
Validation loss: 2.263827641805013

Epoch: 6| Step: 4
Training loss: 0.42402470111846924
Validation loss: 2.24808806180954

Epoch: 6| Step: 5
Training loss: 1.2989263534545898
Validation loss: 2.24224716424942

Epoch: 6| Step: 6
Training loss: 0.333565890789032
Validation loss: 2.213536580403646

Epoch: 6| Step: 7
Training loss: 0.5007467865943909
Validation loss: 2.165096322695414

Epoch: 6| Step: 8
Training loss: 0.4548042416572571
Validation loss: 2.199464738368988

Epoch: 6| Step: 9
Training loss: 0.2110360711812973
Validation loss: 2.1797813773155212

Epoch: 6| Step: 10
Training loss: 0.31464776396751404
Validation loss: 2.2211986581484475

Epoch: 6| Step: 11
Training loss: 0.3396014869213104
Validation loss: 2.2617685794830322

Epoch: 6| Step: 12
Training loss: 0.5373333096504211
Validation loss: 2.2418148120244346

Epoch: 6| Step: 13
Training loss: 0.3575625419616699
Validation loss: 2.2305280367533364

Epoch: 513| Step: 0
Training loss: 0.3433520793914795
Validation loss: 2.225509742895762

Epoch: 6| Step: 1
Training loss: 0.3910098373889923
Validation loss: 2.1599804361661277

Epoch: 6| Step: 2
Training loss: 0.20759236812591553
Validation loss: 2.13277405500412

Epoch: 6| Step: 3
Training loss: 0.43919986486434937
Validation loss: 2.1533876260121665

Epoch: 6| Step: 4
Training loss: 0.23980167508125305
Validation loss: 2.159758726755778

Epoch: 6| Step: 5
Training loss: 0.32123860716819763
Validation loss: 2.1661919355392456

Epoch: 6| Step: 6
Training loss: 0.6436892747879028
Validation loss: 2.160702705383301

Epoch: 6| Step: 7
Training loss: 0.7537628412246704
Validation loss: 2.2007233103116355

Epoch: 6| Step: 8
Training loss: 0.3392929434776306
Validation loss: 2.2184535463651023

Epoch: 6| Step: 9
Training loss: 0.3618724048137665
Validation loss: 2.2089298168818154

Epoch: 6| Step: 10
Training loss: 0.25023484230041504
Validation loss: 2.214337964852651

Epoch: 6| Step: 11
Training loss: 0.2837783694267273
Validation loss: 2.213317036628723

Epoch: 6| Step: 12
Training loss: 0.17285802960395813
Validation loss: 2.2309351762135825

Epoch: 6| Step: 13
Training loss: 0.31927597522735596
Validation loss: 2.193838675816854

Epoch: 514| Step: 0
Training loss: 0.18062718212604523
Validation loss: 2.210782448450724

Epoch: 6| Step: 1
Training loss: 0.23805856704711914
Validation loss: 2.1641581853230796

Epoch: 6| Step: 2
Training loss: 0.35644498467445374
Validation loss: 2.2102349599202475

Epoch: 6| Step: 3
Training loss: 0.7635632753372192
Validation loss: 2.1472989916801453

Epoch: 6| Step: 4
Training loss: 0.4477882981300354
Validation loss: 2.149525841077169

Epoch: 6| Step: 5
Training loss: 0.37644481658935547
Validation loss: 2.1710291107495627

Epoch: 6| Step: 6
Training loss: 0.5089929103851318
Validation loss: 2.176196813583374

Epoch: 6| Step: 7
Training loss: 0.351760596036911
Validation loss: 2.1539399226506553

Epoch: 6| Step: 8
Training loss: 0.3608248829841614
Validation loss: 2.205180803934733

Epoch: 6| Step: 9
Training loss: 0.14267148077487946
Validation loss: 2.201512257258097

Epoch: 6| Step: 10
Training loss: 0.33706456422805786
Validation loss: 2.3376988569895425

Epoch: 6| Step: 11
Training loss: 0.38297393918037415
Validation loss: 2.2928638458251953

Epoch: 6| Step: 12
Training loss: 0.32701271772384644
Validation loss: 2.3098404010136924

Epoch: 6| Step: 13
Training loss: 0.7046440243721008
Validation loss: 2.32395738363266

Epoch: 515| Step: 0
Training loss: 0.40603387355804443
Validation loss: 2.2787486910820007

Epoch: 6| Step: 1
Training loss: 0.17004510760307312
Validation loss: 2.2866215308507285

Epoch: 6| Step: 2
Training loss: 0.35331523418426514
Validation loss: 2.2060933113098145

Epoch: 6| Step: 3
Training loss: 0.17899489402770996
Validation loss: 2.1403406063715615

Epoch: 6| Step: 4
Training loss: 0.3903651833534241
Validation loss: 2.1443932255109153

Epoch: 6| Step: 5
Training loss: 0.4575645923614502
Validation loss: 2.12028044462204

Epoch: 6| Step: 6
Training loss: 0.5892461538314819
Validation loss: 2.1566110849380493

Epoch: 6| Step: 7
Training loss: 0.4025109112262726
Validation loss: 2.1181283791859946

Epoch: 6| Step: 8
Training loss: 0.3105008602142334
Validation loss: 2.145629088083903

Epoch: 6| Step: 9
Training loss: 0.23608529567718506
Validation loss: 2.182307223478953

Epoch: 6| Step: 10
Training loss: 0.49730223417282104
Validation loss: 2.2182225386301675

Epoch: 6| Step: 11
Training loss: 0.6587880849838257
Validation loss: 2.2654183308283486

Epoch: 6| Step: 12
Training loss: 0.4742330312728882
Validation loss: 2.2963603734970093

Epoch: 6| Step: 13
Training loss: 0.6503907442092896
Validation loss: 2.208843946456909

Epoch: 516| Step: 0
Training loss: 0.2315407693386078
Validation loss: 2.2427017291386924

Epoch: 6| Step: 1
Training loss: 0.29641035199165344
Validation loss: 2.2226542830467224

Epoch: 6| Step: 2
Training loss: 0.3586733341217041
Validation loss: 2.2115169366200766

Epoch: 6| Step: 3
Training loss: 0.6128701567649841
Validation loss: 2.2138749162356057

Epoch: 6| Step: 4
Training loss: 0.33808720111846924
Validation loss: 2.256731410821279

Epoch: 6| Step: 5
Training loss: 0.6723601818084717
Validation loss: 2.300478716691335

Epoch: 6| Step: 6
Training loss: 0.29312336444854736
Validation loss: 2.2464118798573813

Epoch: 6| Step: 7
Training loss: 0.41119080781936646
Validation loss: 2.2315385142962136

Epoch: 6| Step: 8
Training loss: 0.6702159643173218
Validation loss: 2.229293723901113

Epoch: 6| Step: 9
Training loss: 0.35023021697998047
Validation loss: 2.2663197914759317

Epoch: 6| Step: 10
Training loss: 0.3893220126628876
Validation loss: 2.220785836378733

Epoch: 6| Step: 11
Training loss: 0.33886033296585083
Validation loss: 2.226653536160787

Epoch: 6| Step: 12
Training loss: 0.37486883997917175
Validation loss: 2.2162132263183594

Epoch: 6| Step: 13
Training loss: 0.32177332043647766
Validation loss: 2.198096434275309

Epoch: 517| Step: 0
Training loss: 0.2877318859100342
Validation loss: 2.231460928916931

Epoch: 6| Step: 1
Training loss: 0.26821988821029663
Validation loss: 2.188460369904836

Epoch: 6| Step: 2
Training loss: 0.3170732259750366
Validation loss: 2.2082615892092385

Epoch: 6| Step: 3
Training loss: 0.20679084956645966
Validation loss: 2.203973035017649

Epoch: 6| Step: 4
Training loss: 0.3259124755859375
Validation loss: 2.167029241720835

Epoch: 6| Step: 5
Training loss: 0.2233961820602417
Validation loss: 2.23484077056249

Epoch: 6| Step: 6
Training loss: 0.28824788331985474
Validation loss: 2.2559638818105063

Epoch: 6| Step: 7
Training loss: 0.5710436701774597
Validation loss: 2.2375765840212503

Epoch: 6| Step: 8
Training loss: 0.7361035943031311
Validation loss: 2.204476515452067

Epoch: 6| Step: 9
Training loss: 0.344229131937027
Validation loss: 2.190142591794332

Epoch: 6| Step: 10
Training loss: 0.28338417410850525
Validation loss: 2.1638565262158713

Epoch: 6| Step: 11
Training loss: 0.30127930641174316
Validation loss: 2.2165305614471436

Epoch: 6| Step: 12
Training loss: 0.2167224884033203
Validation loss: 2.1417234341303506

Epoch: 6| Step: 13
Training loss: 0.6384811997413635
Validation loss: 2.12876965602239

Epoch: 518| Step: 0
Training loss: 0.4342123568058014
Validation loss: 2.0938545862833657

Epoch: 6| Step: 1
Training loss: 0.38366007804870605
Validation loss: 2.161789139111837

Epoch: 6| Step: 2
Training loss: 0.32976070046424866
Validation loss: 2.1963206926981607

Epoch: 6| Step: 3
Training loss: 0.5802491903305054
Validation loss: 2.173644185066223

Epoch: 6| Step: 4
Training loss: 0.3790544271469116
Validation loss: 2.1794110337893167

Epoch: 6| Step: 5
Training loss: 0.2425653338432312
Validation loss: 2.2237369616826377

Epoch: 6| Step: 6
Training loss: 0.6813395619392395
Validation loss: 2.218047479788462

Epoch: 6| Step: 7
Training loss: 0.374428391456604
Validation loss: 2.265485326449076

Epoch: 6| Step: 8
Training loss: 0.3823999762535095
Validation loss: 2.217463652292887

Epoch: 6| Step: 9
Training loss: 0.29741039872169495
Validation loss: 2.2733826637268066

Epoch: 6| Step: 10
Training loss: 0.29213985800743103
Validation loss: 2.303986390431722

Epoch: 6| Step: 11
Training loss: 0.2510492503643036
Validation loss: 2.2853965759277344

Epoch: 6| Step: 12
Training loss: 0.4537622332572937
Validation loss: 2.3031490643819175

Epoch: 6| Step: 13
Training loss: 0.45915931463241577
Validation loss: 2.305211047331492

Epoch: 519| Step: 0
Training loss: 0.2897217869758606
Validation loss: 2.261815885702769

Epoch: 6| Step: 1
Training loss: 0.36951422691345215
Validation loss: 2.2476607958475747

Epoch: 6| Step: 2
Training loss: 0.28144437074661255
Validation loss: 2.2161711057027182

Epoch: 6| Step: 3
Training loss: 0.26021838188171387
Validation loss: 2.181948482990265

Epoch: 6| Step: 4
Training loss: 0.5213708281517029
Validation loss: 2.153445919354757

Epoch: 6| Step: 5
Training loss: 0.371052622795105
Validation loss: 2.1682156721750894

Epoch: 6| Step: 6
Training loss: 0.24438823759555817
Validation loss: 2.1619605223337808

Epoch: 6| Step: 7
Training loss: 0.6437391042709351
Validation loss: 2.204641838868459

Epoch: 6| Step: 8
Training loss: 0.3984498381614685
Validation loss: 2.17994232972463

Epoch: 6| Step: 9
Training loss: 0.5977306365966797
Validation loss: 2.1984603007634482

Epoch: 6| Step: 10
Training loss: 0.3677672743797302
Validation loss: 2.1537602742513022

Epoch: 6| Step: 11
Training loss: 0.4090734124183655
Validation loss: 2.2029105027516684

Epoch: 6| Step: 12
Training loss: 0.2974242568016052
Validation loss: 2.2502286036809287

Epoch: 6| Step: 13
Training loss: 0.23546051979064941
Validation loss: 2.2203789353370667

Epoch: 520| Step: 0
Training loss: 0.20086243748664856
Validation loss: 2.1801156997680664

Epoch: 6| Step: 1
Training loss: 0.28396937251091003
Validation loss: 2.187424659729004

Epoch: 6| Step: 2
Training loss: 0.6380629539489746
Validation loss: 2.2208333214124045

Epoch: 6| Step: 3
Training loss: 0.2836177349090576
Validation loss: 2.2255008618036904

Epoch: 6| Step: 4
Training loss: 0.2618187367916107
Validation loss: 2.2134599089622498

Epoch: 6| Step: 5
Training loss: 0.24840663373470306
Validation loss: 2.2040273745854697

Epoch: 6| Step: 6
Training loss: 0.5509976148605347
Validation loss: 2.1959002216657004

Epoch: 6| Step: 7
Training loss: 0.2219230830669403
Validation loss: 2.207628150780996

Epoch: 6| Step: 8
Training loss: 0.3730447292327881
Validation loss: 2.266066829363505

Epoch: 6| Step: 9
Training loss: 0.29575371742248535
Validation loss: 2.2397342721621194

Epoch: 6| Step: 10
Training loss: 0.3684532046318054
Validation loss: 2.2443809310595193

Epoch: 6| Step: 11
Training loss: 0.29423242807388306
Validation loss: 2.2458139260609946

Epoch: 6| Step: 12
Training loss: 0.2220650315284729
Validation loss: 2.213443875312805

Epoch: 6| Step: 13
Training loss: 0.5777689218521118
Validation loss: 2.26593287785848

Epoch: 521| Step: 0
Training loss: 0.31018030643463135
Validation loss: 2.239355762799581

Epoch: 6| Step: 1
Training loss: 0.3363218903541565
Validation loss: 2.2275696992874146

Epoch: 6| Step: 2
Training loss: 0.43653422594070435
Validation loss: 2.213909864425659

Epoch: 6| Step: 3
Training loss: 0.3611457347869873
Validation loss: 2.239545484383901

Epoch: 6| Step: 4
Training loss: 0.7711573243141174
Validation loss: 2.217038551966349

Epoch: 6| Step: 5
Training loss: 0.26786044239997864
Validation loss: 2.233211040496826

Epoch: 6| Step: 6
Training loss: 0.3440138101577759
Validation loss: 2.175629655520121

Epoch: 6| Step: 7
Training loss: 0.6439250707626343
Validation loss: 2.1743196646372476

Epoch: 6| Step: 8
Training loss: 0.2865796685218811
Validation loss: 2.187432805697123

Epoch: 6| Step: 9
Training loss: 0.2648589015007019
Validation loss: 2.1443668603897095

Epoch: 6| Step: 10
Training loss: 0.40712013840675354
Validation loss: 2.190330664316813

Epoch: 6| Step: 11
Training loss: 0.2212565839290619
Validation loss: 2.2008896867434182

Epoch: 6| Step: 12
Training loss: 0.3097575008869171
Validation loss: 2.221295793851217

Epoch: 6| Step: 13
Training loss: 0.2809518277645111
Validation loss: 2.2028798262278237

Epoch: 522| Step: 0
Training loss: 0.46794646978378296
Validation loss: 2.2656726638476052

Epoch: 6| Step: 1
Training loss: 0.3513515591621399
Validation loss: 2.261839210987091

Epoch: 6| Step: 2
Training loss: 0.3976743817329407
Validation loss: 2.2641392747561135

Epoch: 6| Step: 3
Training loss: 0.2179076075553894
Validation loss: 2.2528884013493857

Epoch: 6| Step: 4
Training loss: 0.2650337815284729
Validation loss: 2.190444548924764

Epoch: 6| Step: 5
Training loss: 0.3241080641746521
Validation loss: 2.2213514844576516

Epoch: 6| Step: 6
Training loss: 0.24055583775043488
Validation loss: 2.1800443530082703

Epoch: 6| Step: 7
Training loss: 0.6078711748123169
Validation loss: 2.1469675501187644

Epoch: 6| Step: 8
Training loss: 0.7155076861381531
Validation loss: 2.1462305188179016

Epoch: 6| Step: 9
Training loss: 0.2550181746482849
Validation loss: 2.1844380100568137

Epoch: 6| Step: 10
Training loss: 0.3119353950023651
Validation loss: 2.219911793867747

Epoch: 6| Step: 11
Training loss: 0.5396700501441956
Validation loss: 2.2232003211975098

Epoch: 6| Step: 12
Training loss: 0.29863694310188293
Validation loss: 2.2853524684906006

Epoch: 6| Step: 13
Training loss: 0.2874259352684021
Validation loss: 2.2710917790730796

Epoch: 523| Step: 0
Training loss: 0.3961530327796936
Validation loss: 2.266337752342224

Epoch: 6| Step: 1
Training loss: 0.2996004819869995
Validation loss: 2.257025361061096

Epoch: 6| Step: 2
Training loss: 0.3327687382698059
Validation loss: 2.2455078760782876

Epoch: 6| Step: 3
Training loss: 0.2891768217086792
Validation loss: 2.2025134762128196

Epoch: 6| Step: 4
Training loss: 0.7608500719070435
Validation loss: 2.1762593587239585

Epoch: 6| Step: 5
Training loss: 0.24038827419281006
Validation loss: 2.2015121976534524

Epoch: 6| Step: 6
Training loss: 0.5628554224967957
Validation loss: 2.2242326537768045

Epoch: 6| Step: 7
Training loss: 0.27650880813598633
Validation loss: 2.1956988175710044

Epoch: 6| Step: 8
Training loss: 0.2809494435787201
Validation loss: 2.23964661359787

Epoch: 6| Step: 9
Training loss: 0.20463812351226807
Validation loss: 2.189933160940806

Epoch: 6| Step: 10
Training loss: 0.45315924286842346
Validation loss: 2.19859117269516

Epoch: 6| Step: 11
Training loss: 0.4433281123638153
Validation loss: 2.2006145119667053

Epoch: 6| Step: 12
Training loss: 0.2275179773569107
Validation loss: 2.1996408899625144

Epoch: 6| Step: 13
Training loss: 0.2512971758842468
Validation loss: 2.1115938226381936

Epoch: 524| Step: 0
Training loss: 0.19702531397342682
Validation loss: 2.131431301434835

Epoch: 6| Step: 1
Training loss: 0.49059543013572693
Validation loss: 2.1257085601488748

Epoch: 6| Step: 2
Training loss: 0.10581628233194351
Validation loss: 2.0784006317456565

Epoch: 6| Step: 3
Training loss: 0.28218671679496765
Validation loss: 2.1148492296536765

Epoch: 6| Step: 4
Training loss: 0.36329275369644165
Validation loss: 2.12775057554245

Epoch: 6| Step: 5
Training loss: 0.36336687207221985
Validation loss: 2.1775337060292563

Epoch: 6| Step: 6
Training loss: 0.5902240872383118
Validation loss: 2.252167602380117

Epoch: 6| Step: 7
Training loss: 0.34516507387161255
Validation loss: 2.242646872997284

Epoch: 6| Step: 8
Training loss: 0.585257887840271
Validation loss: 2.2663625876108804

Epoch: 6| Step: 9
Training loss: 0.25207793712615967
Validation loss: 2.2575785517692566

Epoch: 6| Step: 10
Training loss: 0.430236279964447
Validation loss: 2.233718196551005

Epoch: 6| Step: 11
Training loss: 0.26219451427459717
Validation loss: 2.262626528739929

Epoch: 6| Step: 12
Training loss: 0.3703655004501343
Validation loss: 2.229298929373423

Epoch: 6| Step: 13
Training loss: 0.45209190249443054
Validation loss: 2.240096708138784

Epoch: 525| Step: 0
Training loss: 0.6037326455116272
Validation loss: 2.2001097202301025

Epoch: 6| Step: 1
Training loss: 0.40642645955085754
Validation loss: 2.2438801725705466

Epoch: 6| Step: 2
Training loss: 0.6148946285247803
Validation loss: 2.1720982591311135

Epoch: 6| Step: 3
Training loss: 0.31037017703056335
Validation loss: 2.218694508075714

Epoch: 6| Step: 4
Training loss: 0.21503034234046936
Validation loss: 2.2132464249928794

Epoch: 6| Step: 5
Training loss: 0.35177910327911377
Validation loss: 2.2198938926060996

Epoch: 6| Step: 6
Training loss: 0.27536019682884216
Validation loss: 2.194881776968638

Epoch: 6| Step: 7
Training loss: 0.21767346560955048
Validation loss: 2.185942014058431

Epoch: 6| Step: 8
Training loss: 0.3022302985191345
Validation loss: 2.1986558039983115

Epoch: 6| Step: 9
Training loss: 0.2444847971200943
Validation loss: 2.137494126955668

Epoch: 6| Step: 10
Training loss: 0.41149693727493286
Validation loss: 2.154942055543264

Epoch: 6| Step: 11
Training loss: 0.2691744565963745
Validation loss: 2.200780908266703

Epoch: 6| Step: 12
Training loss: 0.2094036191701889
Validation loss: 2.1525381406148276

Epoch: 6| Step: 13
Training loss: 0.3508693277835846
Validation loss: 2.2359992265701294

Epoch: 526| Step: 0
Training loss: 0.3036298155784607
Validation loss: 2.2343839009602866

Epoch: 6| Step: 1
Training loss: 0.3119382858276367
Validation loss: 2.1916903456052146

Epoch: 6| Step: 2
Training loss: 0.26985782384872437
Validation loss: 2.214680095513662

Epoch: 6| Step: 3
Training loss: 0.3058186173439026
Validation loss: 2.170072078704834

Epoch: 6| Step: 4
Training loss: 0.23346266150474548
Validation loss: 2.174352467060089

Epoch: 6| Step: 5
Training loss: 0.6877695322036743
Validation loss: 2.186309297879537

Epoch: 6| Step: 6
Training loss: 0.3416203260421753
Validation loss: 2.1741681694984436

Epoch: 6| Step: 7
Training loss: 0.3216390609741211
Validation loss: 2.1979862054189048

Epoch: 6| Step: 8
Training loss: 0.35298487544059753
Validation loss: 2.178091049194336

Epoch: 6| Step: 9
Training loss: 0.5280066132545471
Validation loss: 2.195724904537201

Epoch: 6| Step: 10
Training loss: 0.38533535599708557
Validation loss: 2.1844982703526816

Epoch: 6| Step: 11
Training loss: 0.16977742314338684
Validation loss: 2.1899332801500955

Epoch: 6| Step: 12
Training loss: 0.339292973279953
Validation loss: 2.2484750151634216

Epoch: 6| Step: 13
Training loss: 0.2838982343673706
Validation loss: 2.2144851088523865

Epoch: 527| Step: 0
Training loss: 0.2572978138923645
Validation loss: 2.2046111424764

Epoch: 6| Step: 1
Training loss: 0.2385345995426178
Validation loss: 2.1930728554725647

Epoch: 6| Step: 2
Training loss: 0.338866263628006
Validation loss: 2.2102391521135965

Epoch: 6| Step: 3
Training loss: 0.3753226101398468
Validation loss: 2.1942058006922402

Epoch: 6| Step: 4
Training loss: 0.6837185621261597
Validation loss: 2.2110293904940286

Epoch: 6| Step: 5
Training loss: 0.28973495960235596
Validation loss: 2.2330174247423806

Epoch: 6| Step: 6
Training loss: 0.32507097721099854
Validation loss: 2.192011813322703

Epoch: 6| Step: 7
Training loss: 0.22521522641181946
Validation loss: 2.2084407806396484

Epoch: 6| Step: 8
Training loss: 0.3819708824157715
Validation loss: 2.190701166788737

Epoch: 6| Step: 9
Training loss: 0.2541954219341278
Validation loss: 2.2562772830327353

Epoch: 6| Step: 10
Training loss: 0.24552321434020996
Validation loss: 2.2389924128850303

Epoch: 6| Step: 11
Training loss: 0.3266477882862091
Validation loss: 2.181081692377726

Epoch: 6| Step: 12
Training loss: 0.2519432604312897
Validation loss: 2.195134182771047

Epoch: 6| Step: 13
Training loss: 0.6194174885749817
Validation loss: 2.168337424596151

Epoch: 528| Step: 0
Training loss: 0.3287988603115082
Validation loss: 2.1933447122573853

Epoch: 6| Step: 1
Training loss: 0.2732332944869995
Validation loss: 2.206903417905172

Epoch: 6| Step: 2
Training loss: 0.23781126737594604
Validation loss: 2.204862952232361

Epoch: 6| Step: 3
Training loss: 0.7865071296691895
Validation loss: 2.2339119712511697

Epoch: 6| Step: 4
Training loss: 0.4120302200317383
Validation loss: 2.2655375003814697

Epoch: 6| Step: 5
Training loss: 0.63706374168396
Validation loss: 2.2964747150739035

Epoch: 6| Step: 6
Training loss: 0.3241084814071655
Validation loss: 2.255696793397268

Epoch: 6| Step: 7
Training loss: 0.22132936120033264
Validation loss: 2.278433163960775

Epoch: 6| Step: 8
Training loss: 0.2625567317008972
Validation loss: 2.218644102414449

Epoch: 6| Step: 9
Training loss: 0.2142154574394226
Validation loss: 2.1743617057800293

Epoch: 6| Step: 10
Training loss: 0.35738229751586914
Validation loss: 2.155622899532318

Epoch: 6| Step: 11
Training loss: 0.31990087032318115
Validation loss: 2.1412240465482077

Epoch: 6| Step: 12
Training loss: 0.37689530849456787
Validation loss: 2.200550099213918

Epoch: 6| Step: 13
Training loss: 0.2785392999649048
Validation loss: 2.149463733037313

Epoch: 529| Step: 0
Training loss: 0.37032416462898254
Validation loss: 2.125503500302633

Epoch: 6| Step: 1
Training loss: 0.26187220215797424
Validation loss: 2.181504249572754

Epoch: 6| Step: 2
Training loss: 0.24381262063980103
Validation loss: 2.1506470839182534

Epoch: 6| Step: 3
Training loss: 0.17261002957820892
Validation loss: 2.242183486620585

Epoch: 6| Step: 4
Training loss: 0.35237622261047363
Validation loss: 2.225667397181193

Epoch: 6| Step: 5
Training loss: 0.3392615020275116
Validation loss: 2.2164509097735086

Epoch: 6| Step: 6
Training loss: 0.6899786591529846
Validation loss: 2.1805484890937805

Epoch: 6| Step: 7
Training loss: 0.6307360529899597
Validation loss: 2.1617444952329

Epoch: 6| Step: 8
Training loss: 0.30692538619041443
Validation loss: 2.151486317316691

Epoch: 6| Step: 9
Training loss: 0.35514357686042786
Validation loss: 2.182575980822245

Epoch: 6| Step: 10
Training loss: 0.341333270072937
Validation loss: 2.2239297231038413

Epoch: 6| Step: 11
Training loss: 0.26724302768707275
Validation loss: 2.152162770430247

Epoch: 6| Step: 12
Training loss: 0.36654070019721985
Validation loss: 2.1835843920707703

Epoch: 6| Step: 13
Training loss: 0.29071128368377686
Validation loss: 2.198086142539978

Epoch: 530| Step: 0
Training loss: 0.23090992867946625
Validation loss: 2.2290807565053306

Epoch: 6| Step: 1
Training loss: 0.4110991060733795
Validation loss: 2.2812790870666504

Epoch: 6| Step: 2
Training loss: 0.17507411539554596
Validation loss: 2.2632859547932944

Epoch: 6| Step: 3
Training loss: 0.27467256784439087
Validation loss: 2.2981932759284973

Epoch: 6| Step: 4
Training loss: 0.3986962139606476
Validation loss: 2.2982893784840903

Epoch: 6| Step: 5
Training loss: 0.2526981830596924
Validation loss: 2.3157329161961875

Epoch: 6| Step: 6
Training loss: 0.5931141376495361
Validation loss: 2.2556082010269165

Epoch: 6| Step: 7
Training loss: 0.41806626319885254
Validation loss: 2.2945945064226785

Epoch: 6| Step: 8
Training loss: 0.34612488746643066
Validation loss: 2.2937748630841575

Epoch: 6| Step: 9
Training loss: 0.3776393234729767
Validation loss: 2.2491441766421

Epoch: 6| Step: 10
Training loss: 0.3094656467437744
Validation loss: 2.2297009229660034

Epoch: 6| Step: 11
Training loss: 0.34092795848846436
Validation loss: 2.218446691830953

Epoch: 6| Step: 12
Training loss: 0.25129514932632446
Validation loss: 2.21079287926356

Epoch: 6| Step: 13
Training loss: 0.5952971577644348
Validation loss: 2.266886532306671

Epoch: 531| Step: 0
Training loss: 0.21670855581760406
Validation loss: 2.287461241086324

Epoch: 6| Step: 1
Training loss: 0.2708665728569031
Validation loss: 2.2992127339045205

Epoch: 6| Step: 2
Training loss: 0.3464704751968384
Validation loss: 2.3338385423024497

Epoch: 6| Step: 3
Training loss: 0.3602345883846283
Validation loss: 2.299530784289042

Epoch: 6| Step: 4
Training loss: 0.18993443250656128
Validation loss: 2.2884082794189453

Epoch: 6| Step: 5
Training loss: 0.36635661125183105
Validation loss: 2.238148510456085

Epoch: 6| Step: 6
Training loss: 0.28121256828308105
Validation loss: 2.2261053323745728

Epoch: 6| Step: 7
Training loss: 0.3574136793613434
Validation loss: 2.1940977573394775

Epoch: 6| Step: 8
Training loss: 0.6527153253555298
Validation loss: 2.1677284638086953

Epoch: 6| Step: 9
Training loss: 0.6053293943405151
Validation loss: 2.139383375644684

Epoch: 6| Step: 10
Training loss: 0.386143296957016
Validation loss: 2.186280349890391

Epoch: 6| Step: 11
Training loss: 0.3099442720413208
Validation loss: 2.2008593678474426

Epoch: 6| Step: 12
Training loss: 0.18709442019462585
Validation loss: 2.2353805700937905

Epoch: 6| Step: 13
Training loss: 0.3605859577655792
Validation loss: 2.2444228331247964

Epoch: 532| Step: 0
Training loss: 0.24851316213607788
Validation loss: 2.31076842546463

Epoch: 6| Step: 1
Training loss: 0.24413299560546875
Validation loss: 2.3261006275812783

Epoch: 6| Step: 2
Training loss: 0.49711182713508606
Validation loss: 2.274463136990865

Epoch: 6| Step: 3
Training loss: 0.3926856517791748
Validation loss: 2.3091130455334983

Epoch: 6| Step: 4
Training loss: 0.38008296489715576
Validation loss: 2.3224133253097534

Epoch: 6| Step: 5
Training loss: 0.35171762108802795
Validation loss: 2.293048620223999

Epoch: 6| Step: 6
Training loss: 0.25861626863479614
Validation loss: 2.2652007738749185

Epoch: 6| Step: 7
Training loss: 0.3322819471359253
Validation loss: 2.2319669326146445

Epoch: 6| Step: 8
Training loss: 0.2346770465373993
Validation loss: 2.2013529936472573

Epoch: 6| Step: 9
Training loss: 0.6524893641471863
Validation loss: 2.160728136698405

Epoch: 6| Step: 10
Training loss: 0.4006255865097046
Validation loss: 2.1848653157552085

Epoch: 6| Step: 11
Training loss: 0.26525014638900757
Validation loss: 2.1618415117263794

Epoch: 6| Step: 12
Training loss: 0.28375956416130066
Validation loss: 2.196977436542511

Epoch: 6| Step: 13
Training loss: 0.6110285520553589
Validation loss: 2.3090457121531167

Epoch: 533| Step: 0
Training loss: 0.3627275824546814
Validation loss: 2.2362022002538047

Epoch: 6| Step: 1
Training loss: 0.2721836268901825
Validation loss: 2.288883368174235

Epoch: 6| Step: 2
Training loss: 0.32778024673461914
Validation loss: 2.2209010322888694

Epoch: 6| Step: 3
Training loss: 0.16902466118335724
Validation loss: 2.2666640281677246

Epoch: 6| Step: 4
Training loss: 0.38341060280799866
Validation loss: 2.263821800549825

Epoch: 6| Step: 5
Training loss: 0.6414145231246948
Validation loss: 2.2381701668103537

Epoch: 6| Step: 6
Training loss: 0.34542644023895264
Validation loss: 2.2339263757069907

Epoch: 6| Step: 7
Training loss: 0.1745770126581192
Validation loss: 2.271160066127777

Epoch: 6| Step: 8
Training loss: 0.2514456510543823
Validation loss: 2.214694877465566

Epoch: 6| Step: 9
Training loss: 0.2697819173336029
Validation loss: 2.228907505671183

Epoch: 6| Step: 10
Training loss: 0.3988453149795532
Validation loss: 2.2551813324292502

Epoch: 6| Step: 11
Training loss: 0.42003098130226135
Validation loss: 2.2449575662612915

Epoch: 6| Step: 12
Training loss: 0.5032494068145752
Validation loss: 2.243282993634542

Epoch: 6| Step: 13
Training loss: 0.661262571811676
Validation loss: 2.2261616388956704

Epoch: 534| Step: 0
Training loss: 0.2587762176990509
Validation loss: 2.221043507258097

Epoch: 6| Step: 1
Training loss: 0.636438250541687
Validation loss: 2.244202494621277

Epoch: 6| Step: 2
Training loss: 0.37501102685928345
Validation loss: 2.2902404069900513

Epoch: 6| Step: 3
Training loss: 0.6421091556549072
Validation loss: 2.242453614870707

Epoch: 6| Step: 4
Training loss: 0.38709431886672974
Validation loss: 2.276025176048279

Epoch: 6| Step: 5
Training loss: 0.38670581579208374
Validation loss: 2.319842259089152

Epoch: 6| Step: 6
Training loss: 0.31871622800827026
Validation loss: 2.307794193426768

Epoch: 6| Step: 7
Training loss: 0.38357871770858765
Validation loss: 2.246132572491964

Epoch: 6| Step: 8
Training loss: 0.1593046635389328
Validation loss: 2.253730316956838

Epoch: 6| Step: 9
Training loss: 0.41056790947914124
Validation loss: 2.27575675646464

Epoch: 6| Step: 10
Training loss: 0.24285180866718292
Validation loss: 2.270007312297821

Epoch: 6| Step: 11
Training loss: 0.3345976769924164
Validation loss: 2.283128559589386

Epoch: 6| Step: 12
Training loss: 0.18114441633224487
Validation loss: 2.2584121227264404

Epoch: 6| Step: 13
Training loss: 0.4687693119049072
Validation loss: 2.2623786528905234

Epoch: 535| Step: 0
Training loss: 0.2985159754753113
Validation loss: 2.2570822636286416

Epoch: 6| Step: 1
Training loss: 0.2358001172542572
Validation loss: 2.2353360652923584

Epoch: 6| Step: 2
Training loss: 0.6646222472190857
Validation loss: 2.2176433006922402

Epoch: 6| Step: 3
Training loss: 0.2939906716346741
Validation loss: 2.1764882802963257

Epoch: 6| Step: 4
Training loss: 0.6850678324699402
Validation loss: 2.188569704691569

Epoch: 6| Step: 5
Training loss: 0.3134791851043701
Validation loss: 2.172164718310038

Epoch: 6| Step: 6
Training loss: 0.21414850652217865
Validation loss: 2.151709179083506

Epoch: 6| Step: 7
Training loss: 0.30128973722457886
Validation loss: 2.204048136870066

Epoch: 6| Step: 8
Training loss: 0.2684653103351593
Validation loss: 2.219427148501078

Epoch: 6| Step: 9
Training loss: 0.4301545023918152
Validation loss: 2.204873959223429

Epoch: 6| Step: 10
Training loss: 0.27829620242118835
Validation loss: 2.1644964615503945

Epoch: 6| Step: 11
Training loss: 0.20455199480056763
Validation loss: 2.190988024075826

Epoch: 6| Step: 12
Training loss: 0.2127602994441986
Validation loss: 2.208301862080892

Epoch: 6| Step: 13
Training loss: 0.19870153069496155
Validation loss: 2.204415182272593

Epoch: 536| Step: 0
Training loss: 0.5473455786705017
Validation loss: 2.199522097905477

Epoch: 6| Step: 1
Training loss: 0.2572256028652191
Validation loss: 2.1961652437845864

Epoch: 6| Step: 2
Training loss: 0.22468195855617523
Validation loss: 2.181305408477783

Epoch: 6| Step: 3
Training loss: 0.26214995980262756
Validation loss: 2.202914039293925

Epoch: 6| Step: 4
Training loss: 0.5348619818687439
Validation loss: 2.242695947488149

Epoch: 6| Step: 5
Training loss: 0.2955787181854248
Validation loss: 2.3075976371765137

Epoch: 6| Step: 6
Training loss: 0.3224070966243744
Validation loss: 2.3299336433410645

Epoch: 6| Step: 7
Training loss: 0.30249568819999695
Validation loss: 2.3148833314577737

Epoch: 6| Step: 8
Training loss: 0.28232499957084656
Validation loss: 2.3067192435264587

Epoch: 6| Step: 9
Training loss: 0.3592386245727539
Validation loss: 2.263341724872589

Epoch: 6| Step: 10
Training loss: 0.30406785011291504
Validation loss: 2.3140736023585

Epoch: 6| Step: 11
Training loss: 0.22698935866355896
Validation loss: 2.2761772076288858

Epoch: 6| Step: 12
Training loss: 0.365059494972229
Validation loss: 2.271008054415385

Epoch: 6| Step: 13
Training loss: 0.28893646597862244
Validation loss: 2.2612446943918862

Epoch: 537| Step: 0
Training loss: 0.18793180584907532
Validation loss: 2.2609442472457886

Epoch: 6| Step: 1
Training loss: 0.17649337649345398
Validation loss: 2.208038012186686

Epoch: 6| Step: 2
Training loss: 0.24685046076774597
Validation loss: 2.175124168395996

Epoch: 6| Step: 3
Training loss: 0.3316981792449951
Validation loss: 2.160134514172872

Epoch: 6| Step: 4
Training loss: 0.3215806782245636
Validation loss: 2.173852483431498

Epoch: 6| Step: 5
Training loss: 0.3101419508457184
Validation loss: 2.201844274997711

Epoch: 6| Step: 6
Training loss: 0.3414928913116455
Validation loss: 2.2274255752563477

Epoch: 6| Step: 7
Training loss: 0.2834307551383972
Validation loss: 2.229500969250997

Epoch: 6| Step: 8
Training loss: 0.6982462406158447
Validation loss: 2.2715401649475098

Epoch: 6| Step: 9
Training loss: 0.2450675666332245
Validation loss: 2.246062397956848

Epoch: 6| Step: 10
Training loss: 0.18513253331184387
Validation loss: 2.2912347316741943

Epoch: 6| Step: 11
Training loss: 0.3996790647506714
Validation loss: 2.2108763058980307

Epoch: 6| Step: 12
Training loss: 0.5534437894821167
Validation loss: 2.2231992880503335

Epoch: 6| Step: 13
Training loss: 0.2113148272037506
Validation loss: 2.2169302304585776

Epoch: 538| Step: 0
Training loss: 0.2669668197631836
Validation loss: 2.1840455730756125

Epoch: 6| Step: 1
Training loss: 0.19075676798820496
Validation loss: 2.140605370203654

Epoch: 6| Step: 2
Training loss: 0.3844923973083496
Validation loss: 2.181596279144287

Epoch: 6| Step: 3
Training loss: 0.39139556884765625
Validation loss: 2.1824297507603965

Epoch: 6| Step: 4
Training loss: 0.16699416935443878
Validation loss: 2.251023272673289

Epoch: 6| Step: 5
Training loss: 0.2738223671913147
Validation loss: 2.2376321951548257

Epoch: 6| Step: 6
Training loss: 0.1704850196838379
Validation loss: 2.237772285938263

Epoch: 6| Step: 7
Training loss: 1.0553841590881348
Validation loss: 2.258113145828247

Epoch: 6| Step: 8
Training loss: 0.3107756972312927
Validation loss: 2.294130047162374

Epoch: 6| Step: 9
Training loss: 0.42266738414764404
Validation loss: 2.236902634302775

Epoch: 6| Step: 10
Training loss: 0.2393927276134491
Validation loss: 2.2540390888849893

Epoch: 6| Step: 11
Training loss: 0.27441462874412537
Validation loss: 2.2353433767954507

Epoch: 6| Step: 12
Training loss: 0.3144764304161072
Validation loss: 2.192082703113556

Epoch: 6| Step: 13
Training loss: 0.2595258355140686
Validation loss: 2.227027932802836

Epoch: 539| Step: 0
Training loss: 0.5830255746841431
Validation loss: 2.190416614214579

Epoch: 6| Step: 1
Training loss: 0.22716934978961945
Validation loss: 2.1956116557121277

Epoch: 6| Step: 2
Training loss: 0.31441056728363037
Validation loss: 2.236584961414337

Epoch: 6| Step: 3
Training loss: 0.2638743817806244
Validation loss: 2.19076273838679

Epoch: 6| Step: 4
Training loss: 0.20260319113731384
Validation loss: 2.15575510263443

Epoch: 6| Step: 5
Training loss: 0.2986498773097992
Validation loss: 2.1632519364356995

Epoch: 6| Step: 6
Training loss: 0.28665846586227417
Validation loss: 2.196013927459717

Epoch: 6| Step: 7
Training loss: 0.6632710695266724
Validation loss: 2.216812252998352

Epoch: 6| Step: 8
Training loss: 0.13342544436454773
Validation loss: 2.2120288411776223

Epoch: 6| Step: 9
Training loss: 0.29033637046813965
Validation loss: 2.2507320642471313

Epoch: 6| Step: 10
Training loss: 0.3943263292312622
Validation loss: 2.2665794094403586

Epoch: 6| Step: 11
Training loss: 0.2594848871231079
Validation loss: 2.2522353132565818

Epoch: 6| Step: 12
Training loss: 0.34877121448516846
Validation loss: 2.229985495408376

Epoch: 6| Step: 13
Training loss: 0.32632720470428467
Validation loss: 2.2484068075815835

Epoch: 540| Step: 0
Training loss: 0.18140281736850739
Validation loss: 2.193739891052246

Epoch: 6| Step: 1
Training loss: 0.8011257648468018
Validation loss: 2.2697775959968567

Epoch: 6| Step: 2
Training loss: 0.15699610114097595
Validation loss: 2.2877558867136636

Epoch: 6| Step: 3
Training loss: 0.3861861824989319
Validation loss: 2.281806707382202

Epoch: 6| Step: 4
Training loss: 0.37399011850357056
Validation loss: 2.3177558183670044

Epoch: 6| Step: 5
Training loss: 0.26738715171813965
Validation loss: 2.32445752620697

Epoch: 6| Step: 6
Training loss: 0.39764055609703064
Validation loss: 2.2568335135777793

Epoch: 6| Step: 7
Training loss: 0.4011077880859375
Validation loss: 2.220744530359904

Epoch: 6| Step: 8
Training loss: 0.31584346294403076
Validation loss: 2.1849953730901084

Epoch: 6| Step: 9
Training loss: 0.3636155128479004
Validation loss: 2.2206321159998574

Epoch: 6| Step: 10
Training loss: 0.2973271310329437
Validation loss: 2.195882240931193

Epoch: 6| Step: 11
Training loss: 0.6362618207931519
Validation loss: 2.2386350433031716

Epoch: 6| Step: 12
Training loss: 0.3355293273925781
Validation loss: 2.239097992579142

Epoch: 6| Step: 13
Training loss: 0.26806238293647766
Validation loss: 2.217380404472351

Epoch: 541| Step: 0
Training loss: 0.27659741044044495
Validation loss: 2.2338109612464905

Epoch: 6| Step: 1
Training loss: 0.6225568056106567
Validation loss: 2.2557801008224487

Epoch: 6| Step: 2
Training loss: 0.40377485752105713
Validation loss: 2.2730440696080527

Epoch: 6| Step: 3
Training loss: 0.19713586568832397
Validation loss: 2.2739658753077188

Epoch: 6| Step: 4
Training loss: 0.22700683772563934
Validation loss: 2.2534133990605674

Epoch: 6| Step: 5
Training loss: 0.3022276759147644
Validation loss: 2.2444700400034585

Epoch: 6| Step: 6
Training loss: 0.5913025140762329
Validation loss: 2.2333026925722756

Epoch: 6| Step: 7
Training loss: 0.19678351283073425
Validation loss: 2.2565410137176514

Epoch: 6| Step: 8
Training loss: 0.23079721629619598
Validation loss: 2.23974347114563

Epoch: 6| Step: 9
Training loss: 0.466571182012558
Validation loss: 2.2149802446365356

Epoch: 6| Step: 10
Training loss: 0.2989218831062317
Validation loss: 2.200509468714396

Epoch: 6| Step: 11
Training loss: 0.27083683013916016
Validation loss: 2.2162922024726868

Epoch: 6| Step: 12
Training loss: 0.3622916340827942
Validation loss: 2.2091169357299805

Epoch: 6| Step: 13
Training loss: 0.38321414589881897
Validation loss: 2.249413847923279

Epoch: 542| Step: 0
Training loss: 0.3284884989261627
Validation loss: 2.247239649295807

Epoch: 6| Step: 1
Training loss: 0.3200971484184265
Validation loss: 2.265238324801127

Epoch: 6| Step: 2
Training loss: 0.28651076555252075
Validation loss: 2.2114773988723755

Epoch: 6| Step: 3
Training loss: 0.15012063086032867
Validation loss: 2.261905550956726

Epoch: 6| Step: 4
Training loss: 0.24387359619140625
Validation loss: 2.2315869331359863

Epoch: 6| Step: 5
Training loss: 0.2935447692871094
Validation loss: 2.173551877339681

Epoch: 6| Step: 6
Training loss: 0.27179086208343506
Validation loss: 2.1788610418637595

Epoch: 6| Step: 7
Training loss: 0.21654248237609863
Validation loss: 2.176191508769989

Epoch: 6| Step: 8
Training loss: 0.6424229145050049
Validation loss: 2.1576157609621682

Epoch: 6| Step: 9
Training loss: 0.3675631284713745
Validation loss: 2.1523683269818625

Epoch: 6| Step: 10
Training loss: 0.27857208251953125
Validation loss: 2.200364271799723

Epoch: 6| Step: 11
Training loss: 0.19264474511146545
Validation loss: 2.2153284549713135

Epoch: 6| Step: 12
Training loss: 0.3471749424934387
Validation loss: 2.1696152488390603

Epoch: 6| Step: 13
Training loss: 0.6214449405670166
Validation loss: 2.1975953777631125

Epoch: 543| Step: 0
Training loss: 0.2585117816925049
Validation loss: 2.177208642164866

Epoch: 6| Step: 1
Training loss: 0.21461957693099976
Validation loss: 2.196765383084615

Epoch: 6| Step: 2
Training loss: 0.5022175312042236
Validation loss: 2.2024288376172385

Epoch: 6| Step: 3
Training loss: 0.22758235037326813
Validation loss: 2.209359129269918

Epoch: 6| Step: 4
Training loss: 0.21418845653533936
Validation loss: 2.20469339688619

Epoch: 6| Step: 5
Training loss: 0.25440627336502075
Validation loss: 2.224088708559672

Epoch: 6| Step: 6
Training loss: 0.23374219238758087
Validation loss: 2.1916651725769043

Epoch: 6| Step: 7
Training loss: 0.30874115228652954
Validation loss: 2.2361212174097695

Epoch: 6| Step: 8
Training loss: 0.33019232749938965
Validation loss: 2.2512451807657876

Epoch: 6| Step: 9
Training loss: 0.3030308187007904
Validation loss: 2.227427144845327

Epoch: 6| Step: 10
Training loss: 0.20354896783828735
Validation loss: 2.2229339877764382

Epoch: 6| Step: 11
Training loss: 0.20778150856494904
Validation loss: 2.233681082725525

Epoch: 6| Step: 12
Training loss: 0.2392507940530777
Validation loss: 2.2333590586980185

Epoch: 6| Step: 13
Training loss: 0.5052934885025024
Validation loss: 2.191309869289398

Epoch: 544| Step: 0
Training loss: 0.23231276869773865
Validation loss: 2.2103832562764487

Epoch: 6| Step: 1
Training loss: 0.17730219662189484
Validation loss: 2.214643955230713

Epoch: 6| Step: 2
Training loss: 0.3083255887031555
Validation loss: 2.183773398399353

Epoch: 6| Step: 3
Training loss: 0.28915250301361084
Validation loss: 2.1619035402933755

Epoch: 6| Step: 4
Training loss: 0.26818448305130005
Validation loss: 2.1217043002446494

Epoch: 6| Step: 5
Training loss: 0.7124723196029663
Validation loss: 2.0783789356549582

Epoch: 6| Step: 6
Training loss: 0.19158916175365448
Validation loss: 2.104596038659414

Epoch: 6| Step: 7
Training loss: 0.37237676978111267
Validation loss: 2.1997708280881247

Epoch: 6| Step: 8
Training loss: 0.26213496923446655
Validation loss: 2.1812598506609597

Epoch: 6| Step: 9
Training loss: 0.43084514141082764
Validation loss: 2.1628905137379966

Epoch: 6| Step: 10
Training loss: 0.25665992498397827
Validation loss: 2.1790143648783364

Epoch: 6| Step: 11
Training loss: 0.22875365614891052
Validation loss: 2.216116031010946

Epoch: 6| Step: 12
Training loss: 0.20201650261878967
Validation loss: 2.2345827420552573

Epoch: 6| Step: 13
Training loss: 0.26586633920669556
Validation loss: 2.195767899354299

Epoch: 545| Step: 0
Training loss: 0.25477135181427
Validation loss: 2.1874646147092185

Epoch: 6| Step: 1
Training loss: 0.28067171573638916
Validation loss: 2.1487495501836142

Epoch: 6| Step: 2
Training loss: 0.24742768704891205
Validation loss: 2.1913503408432007

Epoch: 6| Step: 3
Training loss: 0.18138502538204193
Validation loss: 2.1902074416478476

Epoch: 6| Step: 4
Training loss: 0.2151636779308319
Validation loss: 2.135688066482544

Epoch: 6| Step: 5
Training loss: 0.24873113632202148
Validation loss: 2.1490281224250793

Epoch: 6| Step: 6
Training loss: 0.5951008796691895
Validation loss: 2.156730810801188

Epoch: 6| Step: 7
Training loss: 0.4819682240486145
Validation loss: 2.167608141899109

Epoch: 6| Step: 8
Training loss: 0.3788892924785614
Validation loss: 2.161593973636627

Epoch: 6| Step: 9
Training loss: 0.26728808879852295
Validation loss: 2.1673067808151245

Epoch: 6| Step: 10
Training loss: 0.3222111463546753
Validation loss: 2.1459497610727944

Epoch: 6| Step: 11
Training loss: 0.25356525182724
Validation loss: 2.1776353120803833

Epoch: 6| Step: 12
Training loss: 0.31571531295776367
Validation loss: 2.1552380124727883

Epoch: 6| Step: 13
Training loss: 0.610556960105896
Validation loss: 2.1753854354222617

Epoch: 546| Step: 0
Training loss: 0.23450732231140137
Validation loss: 2.236334760983785

Epoch: 6| Step: 1
Training loss: 0.31720319390296936
Validation loss: 2.200259725252787

Epoch: 6| Step: 2
Training loss: 0.2651575803756714
Validation loss: 2.2051796118418374

Epoch: 6| Step: 3
Training loss: 0.3366192579269409
Validation loss: 2.180668075879415

Epoch: 6| Step: 4
Training loss: 0.4179876446723938
Validation loss: 2.2024649580319724

Epoch: 6| Step: 5
Training loss: 0.25465741753578186
Validation loss: 2.164579192797343

Epoch: 6| Step: 6
Training loss: 0.29757383465766907
Validation loss: 2.1618688702583313

Epoch: 6| Step: 7
Training loss: 0.24804940819740295
Validation loss: 2.1805597146352134

Epoch: 6| Step: 8
Training loss: 0.6881751418113708
Validation loss: 2.151345153649648

Epoch: 6| Step: 9
Training loss: 0.2475787103176117
Validation loss: 2.1423316995302835

Epoch: 6| Step: 10
Training loss: 0.2844487726688385
Validation loss: 2.1643660267194114

Epoch: 6| Step: 11
Training loss: 0.5314863324165344
Validation loss: 2.1890817483266196

Epoch: 6| Step: 12
Training loss: 0.2563580572605133
Validation loss: 2.1795271039009094

Epoch: 6| Step: 13
Training loss: 0.22995597124099731
Validation loss: 2.1859345038731894

Epoch: 547| Step: 0
Training loss: 0.18190790712833405
Validation loss: 2.2060123085975647

Epoch: 6| Step: 1
Training loss: 0.24730361998081207
Validation loss: 2.1454089283943176

Epoch: 6| Step: 2
Training loss: 0.194068044424057
Validation loss: 2.1796491344769797

Epoch: 6| Step: 3
Training loss: 0.5937039852142334
Validation loss: 2.1719585259755454

Epoch: 6| Step: 4
Training loss: 0.2905162274837494
Validation loss: 2.159778436024984

Epoch: 6| Step: 5
Training loss: 0.22420382499694824
Validation loss: 2.1587708592414856

Epoch: 6| Step: 6
Training loss: 0.235838383436203
Validation loss: 2.1684757471084595

Epoch: 6| Step: 7
Training loss: 0.5606911778450012
Validation loss: 2.173154095808665

Epoch: 6| Step: 8
Training loss: 0.36520642042160034
Validation loss: 2.2043474912643433

Epoch: 6| Step: 9
Training loss: 0.37367984652519226
Validation loss: 2.172436992327372

Epoch: 6| Step: 10
Training loss: 0.23882901668548584
Validation loss: 2.253007630507151

Epoch: 6| Step: 11
Training loss: 0.16975069046020508
Validation loss: 2.200480798880259

Epoch: 6| Step: 12
Training loss: 0.14226573705673218
Validation loss: 2.1767462690671286

Epoch: 6| Step: 13
Training loss: 0.2665478587150574
Validation loss: 2.222757558027903

Epoch: 548| Step: 0
Training loss: 0.33769094944000244
Validation loss: 2.19771941502889

Epoch: 6| Step: 1
Training loss: 0.19865155220031738
Validation loss: 2.2368627389272056

Epoch: 6| Step: 2
Training loss: 0.2764744162559509
Validation loss: 2.190328518549601

Epoch: 6| Step: 3
Training loss: 0.190594881772995
Validation loss: 2.232268969217936

Epoch: 6| Step: 4
Training loss: 0.2555716633796692
Validation loss: 2.2055448293685913

Epoch: 6| Step: 5
Training loss: 0.23334860801696777
Validation loss: 2.2369491259256997

Epoch: 6| Step: 6
Training loss: 0.30135872960090637
Validation loss: 2.2440711855888367

Epoch: 6| Step: 7
Training loss: 0.2100655436515808
Validation loss: 2.248795986175537

Epoch: 6| Step: 8
Training loss: 0.20868341624736786
Validation loss: 2.2625388900438943

Epoch: 6| Step: 9
Training loss: 0.17885516583919525
Validation loss: 2.2536511619885764

Epoch: 6| Step: 10
Training loss: 0.20652268826961517
Validation loss: 2.225158452987671

Epoch: 6| Step: 11
Training loss: 0.6933521628379822
Validation loss: 2.2011406819025674

Epoch: 6| Step: 12
Training loss: 0.30721038579940796
Validation loss: 2.183613419532776

Epoch: 6| Step: 13
Training loss: 0.5539067983627319
Validation loss: 2.225591460863749

Epoch: 549| Step: 0
Training loss: 0.27307361364364624
Validation loss: 2.223172148068746

Epoch: 6| Step: 1
Training loss: 0.3671148419380188
Validation loss: 2.1977153619130454

Epoch: 6| Step: 2
Training loss: 0.48922333121299744
Validation loss: 2.2343326012293496

Epoch: 6| Step: 3
Training loss: 0.297748863697052
Validation loss: 2.2483708262443542

Epoch: 6| Step: 4
Training loss: 0.24433279037475586
Validation loss: 2.252333660920461

Epoch: 6| Step: 5
Training loss: 0.24081040918827057
Validation loss: 2.2323185801506042

Epoch: 6| Step: 6
Training loss: 0.26787036657333374
Validation loss: 2.2242029507954917

Epoch: 6| Step: 7
Training loss: 0.4936401844024658
Validation loss: 2.173711915810903

Epoch: 6| Step: 8
Training loss: 0.3221457600593567
Validation loss: 2.1476115783055625

Epoch: 6| Step: 9
Training loss: 0.3948511481285095
Validation loss: 2.186716318130493

Epoch: 6| Step: 10
Training loss: 0.23029474914073944
Validation loss: 2.157244781653086

Epoch: 6| Step: 11
Training loss: 0.179317444562912
Validation loss: 2.213992635409037

Epoch: 6| Step: 12
Training loss: 0.2907295227050781
Validation loss: 2.2115930914878845

Epoch: 6| Step: 13
Training loss: 0.3199191093444824
Validation loss: 2.220492720603943

Epoch: 550| Step: 0
Training loss: 0.336687296628952
Validation loss: 2.1833002964655557

Epoch: 6| Step: 1
Training loss: 0.24024523794651031
Validation loss: 2.1825563510258994

Epoch: 6| Step: 2
Training loss: 0.08803960680961609
Validation loss: 2.2001324693361917

Epoch: 6| Step: 3
Training loss: 0.26320773363113403
Validation loss: 2.192171573638916

Epoch: 6| Step: 4
Training loss: 0.5177053809165955
Validation loss: 2.1973346869150796

Epoch: 6| Step: 5
Training loss: 0.20354914665222168
Validation loss: 2.183399021625519

Epoch: 6| Step: 6
Training loss: 0.34289395809173584
Validation loss: 2.208810011545817

Epoch: 6| Step: 7
Training loss: 0.3185873031616211
Validation loss: 2.221148451169332

Epoch: 6| Step: 8
Training loss: 0.25011974573135376
Validation loss: 2.2631720304489136

Epoch: 6| Step: 9
Training loss: 0.2480337917804718
Validation loss: 2.242133359114329

Epoch: 6| Step: 10
Training loss: 0.4408571720123291
Validation loss: 2.2738168040911355

Epoch: 6| Step: 11
Training loss: 0.2411561906337738
Validation loss: 2.2967777649561563

Epoch: 6| Step: 12
Training loss: 0.3165123462677002
Validation loss: 2.2920262614885965

Epoch: 6| Step: 13
Training loss: 0.35123196244239807
Validation loss: 2.267492413520813

Testing loss: 1.9488637490238216
