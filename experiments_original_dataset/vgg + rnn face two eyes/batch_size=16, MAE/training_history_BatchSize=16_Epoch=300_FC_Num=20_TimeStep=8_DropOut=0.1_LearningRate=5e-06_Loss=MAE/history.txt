Epoch: 1| Step: 0
Training loss: 4.743775844573975
Validation loss: 5.317755142847697

Epoch: 6| Step: 1
Training loss: 6.129679203033447
Validation loss: 5.3162055015563965

Epoch: 6| Step: 2
Training loss: 5.696780204772949
Validation loss: 5.314553896586101

Epoch: 6| Step: 3
Training loss: 6.713945388793945
Validation loss: 5.312832434972127

Epoch: 6| Step: 4
Training loss: 5.193053245544434
Validation loss: 5.311085303624471

Epoch: 6| Step: 5
Training loss: 5.373473167419434
Validation loss: 5.309292634328206

Epoch: 6| Step: 6
Training loss: 5.246677398681641
Validation loss: 5.307368119557698

Epoch: 6| Step: 7
Training loss: 5.820033550262451
Validation loss: 5.305426041285197

Epoch: 6| Step: 8
Training loss: 6.0221357345581055
Validation loss: 5.303428332010905

Epoch: 6| Step: 9
Training loss: 5.072666168212891
Validation loss: 5.301275412241618

Epoch: 6| Step: 10
Training loss: 4.507327556610107
Validation loss: 5.299021402994792

Epoch: 6| Step: 11
Training loss: 5.714348793029785
Validation loss: 5.296681483586629

Epoch: 6| Step: 12
Training loss: 4.82456111907959
Validation loss: 5.294095913569133

Epoch: 6| Step: 13
Training loss: 4.193235874176025
Validation loss: 5.291401624679565

Epoch: 2| Step: 0
Training loss: 5.073436260223389
Validation loss: 5.288684129714966

Epoch: 6| Step: 1
Training loss: 5.622676849365234
Validation loss: 5.285653273264567

Epoch: 6| Step: 2
Training loss: 4.663410663604736
Validation loss: 5.2825015385945635

Epoch: 6| Step: 3
Training loss: 5.50064754486084
Validation loss: 5.279093225797017

Epoch: 6| Step: 4
Training loss: 5.70521354675293
Validation loss: 5.275691032409668

Epoch: 6| Step: 5
Training loss: 5.439043998718262
Validation loss: 5.272045771280925

Epoch: 6| Step: 6
Training loss: 5.031613349914551
Validation loss: 5.268110116322835

Epoch: 6| Step: 7
Training loss: 6.091259956359863
Validation loss: 5.264068365097046

Epoch: 6| Step: 8
Training loss: 4.797494888305664
Validation loss: 5.25962479909261

Epoch: 6| Step: 9
Training loss: 6.145150661468506
Validation loss: 5.255248546600342

Epoch: 6| Step: 10
Training loss: 4.520503044128418
Validation loss: 5.250390291213989

Epoch: 6| Step: 11
Training loss: 5.747006416320801
Validation loss: 5.24543563524882

Epoch: 6| Step: 12
Training loss: 4.817748069763184
Validation loss: 5.240033308664958

Epoch: 6| Step: 13
Training loss: 5.514932155609131
Validation loss: 5.234374761581421

Epoch: 3| Step: 0
Training loss: 5.402233600616455
Validation loss: 5.228608767191569

Epoch: 6| Step: 1
Training loss: 5.15928316116333
Validation loss: 5.222342411677043

Epoch: 6| Step: 2
Training loss: 4.683799743652344
Validation loss: 5.215914646784465

Epoch: 6| Step: 3
Training loss: 4.278710842132568
Validation loss: 5.208902200063069

Epoch: 6| Step: 4
Training loss: 5.865396499633789
Validation loss: 5.20163877805074

Epoch: 6| Step: 5
Training loss: 3.579843521118164
Validation loss: 5.194043397903442

Epoch: 6| Step: 6
Training loss: 6.555239677429199
Validation loss: 5.186201969782512

Epoch: 6| Step: 7
Training loss: 5.766026496887207
Validation loss: 5.17784317334493

Epoch: 6| Step: 8
Training loss: 5.617295742034912
Validation loss: 5.169115940729777

Epoch: 6| Step: 9
Training loss: 6.182117938995361
Validation loss: 5.159924189249675

Epoch: 6| Step: 10
Training loss: 5.059024810791016
Validation loss: 5.150465567906697

Epoch: 6| Step: 11
Training loss: 4.674846649169922
Validation loss: 5.141218741734822

Epoch: 6| Step: 12
Training loss: 4.430395603179932
Validation loss: 5.1311477820078535

Epoch: 6| Step: 13
Training loss: 6.262957572937012
Validation loss: 5.120851039886475

Epoch: 4| Step: 0
Training loss: 5.91550350189209
Validation loss: 5.110517581303914

Epoch: 6| Step: 1
Training loss: 5.614975452423096
Validation loss: 5.100150903065999

Epoch: 6| Step: 2
Training loss: 5.351142883300781
Validation loss: 5.089176615079244

Epoch: 6| Step: 3
Training loss: 2.7659459114074707
Validation loss: 5.078380982081096

Epoch: 6| Step: 4
Training loss: 5.465401649475098
Validation loss: 5.067291100819905

Epoch: 6| Step: 5
Training loss: 6.431057929992676
Validation loss: 5.056047519048055

Epoch: 6| Step: 6
Training loss: 4.389780044555664
Validation loss: 5.044973770777385

Epoch: 6| Step: 7
Training loss: 4.714149475097656
Validation loss: 5.033684968948364

Epoch: 6| Step: 8
Training loss: 5.6334052085876465
Validation loss: 5.022549867630005

Epoch: 6| Step: 9
Training loss: 5.380892276763916
Validation loss: 5.0114955107371015

Epoch: 6| Step: 10
Training loss: 4.8933210372924805
Validation loss: 4.999812285105388

Epoch: 6| Step: 11
Training loss: 6.070858955383301
Validation loss: 4.988592306772868

Epoch: 6| Step: 12
Training loss: 4.750230312347412
Validation loss: 4.977203369140625

Epoch: 6| Step: 13
Training loss: 4.257671356201172
Validation loss: 4.965637445449829

Epoch: 5| Step: 0
Training loss: 5.0122175216674805
Validation loss: 4.9545637766520185

Epoch: 6| Step: 1
Training loss: 5.142156600952148
Validation loss: 4.9429144859313965

Epoch: 6| Step: 2
Training loss: 4.937636375427246
Validation loss: 4.931519508361816

Epoch: 6| Step: 3
Training loss: 3.883531332015991
Validation loss: 4.9198988278706866

Epoch: 6| Step: 4
Training loss: 4.725710868835449
Validation loss: 4.908601840337117

Epoch: 6| Step: 5
Training loss: 4.776638507843018
Validation loss: 4.897069851557414

Epoch: 6| Step: 6
Training loss: 6.163498878479004
Validation loss: 4.885804653167725

Epoch: 6| Step: 7
Training loss: 4.139249324798584
Validation loss: 4.874387741088867

Epoch: 6| Step: 8
Training loss: 6.570411682128906
Validation loss: 4.862977743148804

Epoch: 6| Step: 9
Training loss: 4.04127311706543
Validation loss: 4.851597229639689

Epoch: 6| Step: 10
Training loss: 4.715297222137451
Validation loss: 4.840390563011169

Epoch: 6| Step: 11
Training loss: 4.859245300292969
Validation loss: 4.8297385374705

Epoch: 6| Step: 12
Training loss: 5.663909912109375
Validation loss: 4.819375991821289

Epoch: 6| Step: 13
Training loss: 4.907991886138916
Validation loss: 4.808655659357707

Epoch: 6| Step: 0
Training loss: 5.137211322784424
Validation loss: 4.7984176476796465

Epoch: 6| Step: 1
Training loss: 5.944369316101074
Validation loss: 4.788675467173259

Epoch: 6| Step: 2
Training loss: 5.016837120056152
Validation loss: 4.7783535321553545

Epoch: 6| Step: 3
Training loss: 4.511180877685547
Validation loss: 4.76851224899292

Epoch: 6| Step: 4
Training loss: 4.272282600402832
Validation loss: 4.758971691131592

Epoch: 6| Step: 5
Training loss: 4.802183151245117
Validation loss: 4.748928467432658

Epoch: 6| Step: 6
Training loss: 4.569340705871582
Validation loss: 4.73917023340861

Epoch: 6| Step: 7
Training loss: 5.821714401245117
Validation loss: 4.729901870091756

Epoch: 6| Step: 8
Training loss: 3.34956955909729
Validation loss: 4.720857620239258

Epoch: 6| Step: 9
Training loss: 5.39368200302124
Validation loss: 4.711966355641683

Epoch: 6| Step: 10
Training loss: 5.476731300354004
Validation loss: 4.7033610343933105

Epoch: 6| Step: 11
Training loss: 5.6851301193237305
Validation loss: 4.695080041885376

Epoch: 6| Step: 12
Training loss: 3.5673351287841797
Validation loss: 4.686692555745442

Epoch: 6| Step: 13
Training loss: 4.052199840545654
Validation loss: 4.678514401117961

Epoch: 7| Step: 0
Training loss: 4.449832439422607
Validation loss: 4.670853575070699

Epoch: 6| Step: 1
Training loss: 4.283504962921143
Validation loss: 4.66264549891154

Epoch: 6| Step: 2
Training loss: 5.1461405754089355
Validation loss: 4.655002514521281

Epoch: 6| Step: 3
Training loss: 4.29327917098999
Validation loss: 4.647849082946777

Epoch: 6| Step: 4
Training loss: 4.455704689025879
Validation loss: 4.640270709991455

Epoch: 6| Step: 5
Training loss: 4.975721836090088
Validation loss: 4.632700284322103

Epoch: 6| Step: 6
Training loss: 3.649833917617798
Validation loss: 4.625254392623901

Epoch: 6| Step: 7
Training loss: 4.186223030090332
Validation loss: 4.618546565373738

Epoch: 6| Step: 8
Training loss: 5.507617950439453
Validation loss: 4.611608902613322

Epoch: 6| Step: 9
Training loss: 5.76406192779541
Validation loss: 4.60457718372345

Epoch: 6| Step: 10
Training loss: 3.340876817703247
Validation loss: 4.59816034634908

Epoch: 6| Step: 11
Training loss: 4.525416851043701
Validation loss: 4.59138838450114

Epoch: 6| Step: 12
Training loss: 5.783091068267822
Validation loss: 4.58452041943868

Epoch: 6| Step: 13
Training loss: 5.733056545257568
Validation loss: 4.578181664148967

Epoch: 8| Step: 0
Training loss: 4.048392295837402
Validation loss: 4.57150920232137

Epoch: 6| Step: 1
Training loss: 4.759545803070068
Validation loss: 4.564419984817505

Epoch: 6| Step: 2
Training loss: 4.592761039733887
Validation loss: 4.557934999465942

Epoch: 6| Step: 3
Training loss: 5.0306010246276855
Validation loss: 4.550808668136597

Epoch: 6| Step: 4
Training loss: 5.139074802398682
Validation loss: 4.54417097568512

Epoch: 6| Step: 5
Training loss: 4.160693645477295
Validation loss: 4.537620147069295

Epoch: 6| Step: 6
Training loss: 4.6212592124938965
Validation loss: 4.5313425461451216

Epoch: 6| Step: 7
Training loss: 5.520580291748047
Validation loss: 4.525031963984172

Epoch: 6| Step: 8
Training loss: 4.244260787963867
Validation loss: 4.518307169278462

Epoch: 6| Step: 9
Training loss: 4.14019250869751
Validation loss: 4.51228666305542

Epoch: 6| Step: 10
Training loss: 5.151278018951416
Validation loss: 4.505714813868205

Epoch: 6| Step: 11
Training loss: 4.655733108520508
Validation loss: 4.499642054239909

Epoch: 6| Step: 12
Training loss: 4.0092549324035645
Validation loss: 4.493119915326436

Epoch: 6| Step: 13
Training loss: 4.7898101806640625
Validation loss: 4.486740589141846

Epoch: 9| Step: 0
Training loss: 5.126801490783691
Validation loss: 4.479863405227661

Epoch: 6| Step: 1
Training loss: 4.488119125366211
Validation loss: 4.473254680633545

Epoch: 6| Step: 2
Training loss: 5.9503092765808105
Validation loss: 4.465943296750386

Epoch: 6| Step: 3
Training loss: 4.966127395629883
Validation loss: 4.458641529083252

Epoch: 6| Step: 4
Training loss: 4.224590301513672
Validation loss: 4.452389558156331

Epoch: 6| Step: 5
Training loss: 4.125332832336426
Validation loss: 4.44510817527771

Epoch: 6| Step: 6
Training loss: 4.325710773468018
Validation loss: 4.438274423281352

Epoch: 6| Step: 7
Training loss: 3.9523544311523438
Validation loss: 4.431763847668965

Epoch: 6| Step: 8
Training loss: 4.257513046264648
Validation loss: 4.424817442893982

Epoch: 6| Step: 9
Training loss: 4.473048686981201
Validation loss: 4.418260415395101

Epoch: 6| Step: 10
Training loss: 5.055809497833252
Validation loss: 4.41126823425293

Epoch: 6| Step: 11
Training loss: 5.612225532531738
Validation loss: 4.404320637385051

Epoch: 6| Step: 12
Training loss: 3.824453830718994
Validation loss: 4.39774215221405

Epoch: 6| Step: 13
Training loss: 3.275205135345459
Validation loss: 4.390994747479756

Epoch: 10| Step: 0
Training loss: 4.932323455810547
Validation loss: 4.384175380071004

Epoch: 6| Step: 1
Training loss: 3.737391233444214
Validation loss: 4.377496163050334

Epoch: 6| Step: 2
Training loss: 4.661947250366211
Validation loss: 4.37052047252655

Epoch: 6| Step: 3
Training loss: 3.614147663116455
Validation loss: 4.3639267683029175

Epoch: 6| Step: 4
Training loss: 4.982291221618652
Validation loss: 4.356838742891948

Epoch: 6| Step: 5
Training loss: 5.0953779220581055
Validation loss: 4.349522233009338

Epoch: 6| Step: 6
Training loss: 4.330846309661865
Validation loss: 4.341946522394816

Epoch: 6| Step: 7
Training loss: 3.798947811126709
Validation loss: 4.335009217262268

Epoch: 6| Step: 8
Training loss: 4.144556999206543
Validation loss: 4.32633638381958

Epoch: 6| Step: 9
Training loss: 3.463636636734009
Validation loss: 4.320186773935954

Epoch: 6| Step: 10
Training loss: 4.45336389541626
Validation loss: 4.314228971799214

Epoch: 6| Step: 11
Training loss: 4.779969692230225
Validation loss: 4.3067876895268755

Epoch: 6| Step: 12
Training loss: 4.929129123687744
Validation loss: 4.300534804662068

Epoch: 6| Step: 13
Training loss: 5.501077651977539
Validation loss: 4.29456639289856

Epoch: 11| Step: 0
Training loss: 4.91264533996582
Validation loss: 4.287854830423991

Epoch: 6| Step: 1
Training loss: 4.531007766723633
Validation loss: 4.281453490257263

Epoch: 6| Step: 2
Training loss: 4.060907363891602
Validation loss: 4.275063673655192

Epoch: 6| Step: 3
Training loss: 4.4129862785339355
Validation loss: 4.269858757654826

Epoch: 6| Step: 4
Training loss: 4.551758766174316
Validation loss: 4.263007044792175

Epoch: 6| Step: 5
Training loss: 4.721784591674805
Validation loss: 4.256118893623352

Epoch: 6| Step: 6
Training loss: 5.202639102935791
Validation loss: 4.2489480177561445

Epoch: 6| Step: 7
Training loss: 3.2456259727478027
Validation loss: 4.242594997088115

Epoch: 6| Step: 8
Training loss: 4.111386299133301
Validation loss: 4.23678716023763

Epoch: 6| Step: 9
Training loss: 4.1578216552734375
Validation loss: 4.231859008471171

Epoch: 6| Step: 10
Training loss: 3.986354351043701
Validation loss: 4.225295543670654

Epoch: 6| Step: 11
Training loss: 5.148004531860352
Validation loss: 4.218812942504883

Epoch: 6| Step: 12
Training loss: 4.023730754852295
Validation loss: 4.211801449457805

Epoch: 6| Step: 13
Training loss: 4.167725563049316
Validation loss: 4.205495556195577

Epoch: 12| Step: 0
Training loss: 4.387270927429199
Validation loss: 4.1988339026769

Epoch: 6| Step: 1
Training loss: 4.568909168243408
Validation loss: 4.192384719848633

Epoch: 6| Step: 2
Training loss: 4.144988536834717
Validation loss: 4.185492992401123

Epoch: 6| Step: 3
Training loss: 4.645347595214844
Validation loss: 4.178751428922017

Epoch: 6| Step: 4
Training loss: 3.8259897232055664
Validation loss: 4.172940055529277

Epoch: 6| Step: 5
Training loss: 4.142981052398682
Validation loss: 4.167290012041728

Epoch: 6| Step: 6
Training loss: 3.656177282333374
Validation loss: 4.16028110186259

Epoch: 6| Step: 7
Training loss: 4.059784889221191
Validation loss: 4.1540108521779375

Epoch: 6| Step: 8
Training loss: 4.145775318145752
Validation loss: 4.147505005200704

Epoch: 6| Step: 9
Training loss: 3.792440414428711
Validation loss: 4.142355402310689

Epoch: 6| Step: 10
Training loss: 4.931314468383789
Validation loss: 4.136659701665242

Epoch: 6| Step: 11
Training loss: 4.766450881958008
Validation loss: 4.130496342976888

Epoch: 6| Step: 12
Training loss: 4.881989479064941
Validation loss: 4.124602556228638

Epoch: 6| Step: 13
Training loss: 4.151942729949951
Validation loss: 4.118135531743367

Epoch: 13| Step: 0
Training loss: 4.803074836730957
Validation loss: 4.111912965774536

Epoch: 6| Step: 1
Training loss: 3.8825201988220215
Validation loss: 4.107607324918111

Epoch: 6| Step: 2
Training loss: 4.343400955200195
Validation loss: 4.100077549616496

Epoch: 6| Step: 3
Training loss: 4.049682140350342
Validation loss: 4.094470262527466

Epoch: 6| Step: 4
Training loss: 3.8250675201416016
Validation loss: 4.088880976041158

Epoch: 6| Step: 5
Training loss: 5.040058612823486
Validation loss: 4.083801825841268

Epoch: 6| Step: 6
Training loss: 3.135684013366699
Validation loss: 4.078502496083577

Epoch: 6| Step: 7
Training loss: 4.710078239440918
Validation loss: 4.073107361793518

Epoch: 6| Step: 8
Training loss: 4.619075298309326
Validation loss: 4.067925930023193

Epoch: 6| Step: 9
Training loss: 4.6518354415893555
Validation loss: 4.061166127522786

Epoch: 6| Step: 10
Training loss: 3.596813201904297
Validation loss: 4.055479367574056

Epoch: 6| Step: 11
Training loss: 4.078810691833496
Validation loss: 4.050069848696391

Epoch: 6| Step: 12
Training loss: 4.917891502380371
Validation loss: 4.045236110687256

Epoch: 6| Step: 13
Training loss: 3.3814072608947754
Validation loss: 4.040504574775696

Epoch: 14| Step: 0
Training loss: 4.532828330993652
Validation loss: 4.0347408056259155

Epoch: 6| Step: 1
Training loss: 4.655522346496582
Validation loss: 4.029877742131551

Epoch: 6| Step: 2
Training loss: 4.164555549621582
Validation loss: 4.023801207542419

Epoch: 6| Step: 3
Training loss: 3.731769323348999
Validation loss: 4.01878007253011

Epoch: 6| Step: 4
Training loss: 4.943169593811035
Validation loss: 4.013463894526164

Epoch: 6| Step: 5
Training loss: 4.690757751464844
Validation loss: 4.0081056753794355

Epoch: 6| Step: 6
Training loss: 3.862234592437744
Validation loss: 4.00335152943929

Epoch: 6| Step: 7
Training loss: 4.061090469360352
Validation loss: 3.99806801478068

Epoch: 6| Step: 8
Training loss: 4.169140815734863
Validation loss: 3.9919602076212564

Epoch: 6| Step: 9
Training loss: 3.4465603828430176
Validation loss: 3.9872860113779702

Epoch: 6| Step: 10
Training loss: 4.10248327255249
Validation loss: 3.982036511103312

Epoch: 6| Step: 11
Training loss: 4.702030181884766
Validation loss: 3.9764299392700195

Epoch: 6| Step: 12
Training loss: 4.229523181915283
Validation loss: 3.9712472756703696

Epoch: 6| Step: 13
Training loss: 2.750906467437744
Validation loss: 3.9663230180740356

Epoch: 15| Step: 0
Training loss: 3.2376651763916016
Validation loss: 3.961567838986715

Epoch: 6| Step: 1
Training loss: 4.5348405838012695
Validation loss: 3.9568724234898887

Epoch: 6| Step: 2
Training loss: 3.192002296447754
Validation loss: 3.951333165168762

Epoch: 6| Step: 3
Training loss: 4.539904594421387
Validation loss: 3.946497678756714

Epoch: 6| Step: 4
Training loss: 4.5443434715271
Validation loss: 3.941575527191162

Epoch: 6| Step: 5
Training loss: 3.292842388153076
Validation loss: 3.9369145234425864

Epoch: 6| Step: 6
Training loss: 3.365729570388794
Validation loss: 3.931771755218506

Epoch: 6| Step: 7
Training loss: 5.192800045013428
Validation loss: 3.926959196726481

Epoch: 6| Step: 8
Training loss: 4.595578193664551
Validation loss: 3.92234734694163

Epoch: 6| Step: 9
Training loss: 4.185155868530273
Validation loss: 3.9182600180308023

Epoch: 6| Step: 10
Training loss: 4.757551193237305
Validation loss: 3.9116292794545493

Epoch: 6| Step: 11
Training loss: 2.807097911834717
Validation loss: 3.9072571992874146

Epoch: 6| Step: 12
Training loss: 4.087453365325928
Validation loss: 3.902915358543396

Epoch: 6| Step: 13
Training loss: 4.739232540130615
Validation loss: 3.899667501449585

Epoch: 16| Step: 0
Training loss: 3.96947979927063
Validation loss: 3.8931767543156943

Epoch: 6| Step: 1
Training loss: 4.485420227050781
Validation loss: 3.8878698348999023

Epoch: 6| Step: 2
Training loss: 3.6976704597473145
Validation loss: 3.884749094645182

Epoch: 6| Step: 3
Training loss: 4.613351821899414
Validation loss: 3.881131887435913

Epoch: 6| Step: 4
Training loss: 4.381035804748535
Validation loss: 3.877504269282023

Epoch: 6| Step: 5
Training loss: 4.300503730773926
Validation loss: 3.8713123003641763

Epoch: 6| Step: 6
Training loss: 3.7251532077789307
Validation loss: 3.8653414646784463

Epoch: 6| Step: 7
Training loss: 3.49237060546875
Validation loss: 3.860198219617208

Epoch: 6| Step: 8
Training loss: 3.999934434890747
Validation loss: 3.854312300682068

Epoch: 6| Step: 9
Training loss: 4.405453681945801
Validation loss: 3.8495620489120483

Epoch: 6| Step: 10
Training loss: 3.7434463500976562
Validation loss: 3.845479965209961

Epoch: 6| Step: 11
Training loss: 4.5425519943237305
Validation loss: 3.8418271938959756

Epoch: 6| Step: 12
Training loss: 3.4184279441833496
Validation loss: 3.8355819384256997

Epoch: 6| Step: 13
Training loss: 3.4497499465942383
Validation loss: 3.832267999649048

Epoch: 17| Step: 0
Training loss: 4.361446380615234
Validation loss: 3.8293943802515664

Epoch: 6| Step: 1
Training loss: 2.4630494117736816
Validation loss: 3.8240169684092202

Epoch: 6| Step: 2
Training loss: 5.233336925506592
Validation loss: 3.820896108945211

Epoch: 6| Step: 3
Training loss: 4.315057277679443
Validation loss: 3.8153918584187827

Epoch: 6| Step: 4
Training loss: 3.671477794647217
Validation loss: 3.810749371846517

Epoch: 6| Step: 5
Training loss: 3.9392318725585938
Validation loss: 3.806551973025004

Epoch: 6| Step: 6
Training loss: 4.190523147583008
Validation loss: 3.8024131854375205

Epoch: 6| Step: 7
Training loss: 3.194451332092285
Validation loss: 3.7976346015930176

Epoch: 6| Step: 8
Training loss: 4.787017822265625
Validation loss: 3.7928691307703652

Epoch: 6| Step: 9
Training loss: 3.9159858226776123
Validation loss: 3.787938435872396

Epoch: 6| Step: 10
Training loss: 3.7206223011016846
Validation loss: 3.783158540725708

Epoch: 6| Step: 11
Training loss: 3.4434235095977783
Validation loss: 3.7786484162012735

Epoch: 6| Step: 12
Training loss: 4.340396881103516
Validation loss: 3.7743088404337564

Epoch: 6| Step: 13
Training loss: 3.7856435775756836
Validation loss: 3.7708073457082114

Epoch: 18| Step: 0
Training loss: 3.864708423614502
Validation loss: 3.7653932571411133

Epoch: 6| Step: 1
Training loss: 4.415661334991455
Validation loss: 3.7618571519851685

Epoch: 6| Step: 2
Training loss: 4.19627571105957
Validation loss: 3.7565314769744873

Epoch: 6| Step: 3
Training loss: 3.269195079803467
Validation loss: 3.7524881760279336

Epoch: 6| Step: 4
Training loss: 4.170469284057617
Validation loss: 3.7484494845072427

Epoch: 6| Step: 5
Training loss: 4.78120231628418
Validation loss: 3.7434523502985635

Epoch: 6| Step: 6
Training loss: 3.856529712677002
Validation loss: 3.73850949605306

Epoch: 6| Step: 7
Training loss: 3.7104172706604004
Validation loss: 3.73432449499766

Epoch: 6| Step: 8
Training loss: 3.567575454711914
Validation loss: 3.7290688355763755

Epoch: 6| Step: 9
Training loss: 3.4915695190429688
Validation loss: 3.7250129779179892

Epoch: 6| Step: 10
Training loss: 4.4912567138671875
Validation loss: 3.721104462941488

Epoch: 6| Step: 11
Training loss: 4.157492637634277
Validation loss: 3.717315753300985

Epoch: 6| Step: 12
Training loss: 3.6934380531311035
Validation loss: 3.7135437726974487

Epoch: 6| Step: 13
Training loss: 2.884364366531372
Validation loss: 3.7088874181111655

Epoch: 19| Step: 0
Training loss: 3.785067081451416
Validation loss: 3.704368472099304

Epoch: 6| Step: 1
Training loss: 2.325324535369873
Validation loss: 3.699809710184733

Epoch: 6| Step: 2
Training loss: 3.1477925777435303
Validation loss: 3.6950447956720986

Epoch: 6| Step: 3
Training loss: 2.8118131160736084
Validation loss: 3.692289113998413

Epoch: 6| Step: 4
Training loss: 3.499293804168701
Validation loss: 3.687385082244873

Epoch: 6| Step: 5
Training loss: 4.04224157333374
Validation loss: 3.6840904553731284

Epoch: 6| Step: 6
Training loss: 4.891131401062012
Validation loss: 3.6796538829803467

Epoch: 6| Step: 7
Training loss: 3.9891257286071777
Validation loss: 3.6755463679631553

Epoch: 6| Step: 8
Training loss: 3.820798397064209
Validation loss: 3.67179540793101

Epoch: 6| Step: 9
Training loss: 4.135851860046387
Validation loss: 3.666651487350464

Epoch: 6| Step: 10
Training loss: 3.8928914070129395
Validation loss: 3.6626654863357544

Epoch: 6| Step: 11
Training loss: 3.7945408821105957
Validation loss: 3.658276995023092

Epoch: 6| Step: 12
Training loss: 4.985029220581055
Validation loss: 3.6534635623296103

Epoch: 6| Step: 13
Training loss: 4.615572929382324
Validation loss: 3.650122324625651

Epoch: 20| Step: 0
Training loss: 4.074722766876221
Validation loss: 3.6457608143488565

Epoch: 6| Step: 1
Training loss: 4.165065288543701
Validation loss: 3.641532301902771

Epoch: 6| Step: 2
Training loss: 3.451186180114746
Validation loss: 3.637266198794047

Epoch: 6| Step: 3
Training loss: 5.29469108581543
Validation loss: 3.633598566055298

Epoch: 6| Step: 4
Training loss: 3.463475465774536
Validation loss: 3.6283966700236

Epoch: 6| Step: 5
Training loss: 3.459843397140503
Validation loss: 3.6248424847920737

Epoch: 6| Step: 6
Training loss: 3.7090916633605957
Validation loss: 3.620056390762329

Epoch: 6| Step: 7
Training loss: 3.362309455871582
Validation loss: 3.615312695503235

Epoch: 6| Step: 8
Training loss: 3.072324514389038
Validation loss: 3.611144781112671

Epoch: 6| Step: 9
Training loss: 2.978209972381592
Validation loss: 3.6065421104431152

Epoch: 6| Step: 10
Training loss: 3.811844825744629
Validation loss: 3.6030036211013794

Epoch: 6| Step: 11
Training loss: 3.7197604179382324
Validation loss: 3.5986788670221963

Epoch: 6| Step: 12
Training loss: 4.643425941467285
Validation loss: 3.5945012966791787

Epoch: 6| Step: 13
Training loss: 3.7357747554779053
Validation loss: 3.5899943908055625

Epoch: 21| Step: 0
Training loss: 3.279594898223877
Validation loss: 3.5857338507970176

Epoch: 6| Step: 1
Training loss: 3.5251083374023438
Validation loss: 3.581315199534098

Epoch: 6| Step: 2
Training loss: 3.9835519790649414
Validation loss: 3.577587087949117

Epoch: 6| Step: 3
Training loss: 3.6312789916992188
Validation loss: 3.5735907554626465

Epoch: 6| Step: 4
Training loss: 3.2115039825439453
Validation loss: 3.568939725557963

Epoch: 6| Step: 5
Training loss: 4.11605978012085
Validation loss: 3.56490421295166

Epoch: 6| Step: 6
Training loss: 3.6950478553771973
Validation loss: 3.56038498878479

Epoch: 6| Step: 7
Training loss: 3.2542760372161865
Validation loss: 3.5565382639567056

Epoch: 6| Step: 8
Training loss: 4.327324867248535
Validation loss: 3.5522116820017495

Epoch: 6| Step: 9
Training loss: 4.150154113769531
Validation loss: 3.548317233721415

Epoch: 6| Step: 10
Training loss: 3.963294744491577
Validation loss: 3.5434171756108603

Epoch: 6| Step: 11
Training loss: 3.8858492374420166
Validation loss: 3.53880767027537

Epoch: 6| Step: 12
Training loss: 2.8957619667053223
Validation loss: 3.5340209007263184

Epoch: 6| Step: 13
Training loss: 4.208293437957764
Validation loss: 3.5300947030385337

Epoch: 22| Step: 0
Training loss: 4.00778865814209
Validation loss: 3.525559107462565

Epoch: 6| Step: 1
Training loss: 3.1275200843811035
Validation loss: 3.5217015743255615

Epoch: 6| Step: 2
Training loss: 3.2098915576934814
Validation loss: 3.5165860255559287

Epoch: 6| Step: 3
Training loss: 3.4804327487945557
Validation loss: 3.5124990940093994

Epoch: 6| Step: 4
Training loss: 4.007217884063721
Validation loss: 3.5086052417755127

Epoch: 6| Step: 5
Training loss: 4.722501277923584
Validation loss: 3.5048800309499106

Epoch: 6| Step: 6
Training loss: 3.478200674057007
Validation loss: 3.5007354021072388

Epoch: 6| Step: 7
Training loss: 3.774383068084717
Validation loss: 3.497198541959127

Epoch: 6| Step: 8
Training loss: 3.264601707458496
Validation loss: 3.4919122060139975

Epoch: 6| Step: 9
Training loss: 3.670105218887329
Validation loss: 3.4876962502797446

Epoch: 6| Step: 10
Training loss: 3.864192485809326
Validation loss: 3.4837340911229453

Epoch: 6| Step: 11
Training loss: 2.963939905166626
Validation loss: 3.478621562321981

Epoch: 6| Step: 12
Training loss: 3.7717232704162598
Validation loss: 3.475269317626953

Epoch: 6| Step: 13
Training loss: 3.9665660858154297
Validation loss: 3.4712493817011514

Epoch: 23| Step: 0
Training loss: 3.172590732574463
Validation loss: 3.466683268547058

Epoch: 6| Step: 1
Training loss: 4.0226263999938965
Validation loss: 3.462425390879313

Epoch: 6| Step: 2
Training loss: 3.5810985565185547
Validation loss: 3.4583307107289634

Epoch: 6| Step: 3
Training loss: 2.943366050720215
Validation loss: 3.4544386068979898

Epoch: 6| Step: 4
Training loss: 3.8446762561798096
Validation loss: 3.450580636660258

Epoch: 6| Step: 5
Training loss: 3.8634145259857178
Validation loss: 3.445505936940511

Epoch: 6| Step: 6
Training loss: 3.377483367919922
Validation loss: 3.4417777856191

Epoch: 6| Step: 7
Training loss: 4.068246841430664
Validation loss: 3.437199592590332

Epoch: 6| Step: 8
Training loss: 4.036780834197998
Validation loss: 3.433075706164042

Epoch: 6| Step: 9
Training loss: 3.609853744506836
Validation loss: 3.4293206532796225

Epoch: 6| Step: 10
Training loss: 3.7869839668273926
Validation loss: 3.424360195795695

Epoch: 6| Step: 11
Training loss: 3.605750799179077
Validation loss: 3.4208614826202393

Epoch: 6| Step: 12
Training loss: 3.2352547645568848
Validation loss: 3.4163262049357095

Epoch: 6| Step: 13
Training loss: 3.347411632537842
Validation loss: 3.4121874968210855

Epoch: 24| Step: 0
Training loss: 3.2941317558288574
Validation loss: 3.4080855449040732

Epoch: 6| Step: 1
Training loss: 3.2936840057373047
Validation loss: 3.404539704322815

Epoch: 6| Step: 2
Training loss: 3.843897819519043
Validation loss: 3.4003791411717734

Epoch: 6| Step: 3
Training loss: 3.1624655723571777
Validation loss: 3.3967082103093467

Epoch: 6| Step: 4
Training loss: 3.065443992614746
Validation loss: 3.392828901608785

Epoch: 6| Step: 5
Training loss: 2.939291000366211
Validation loss: 3.388741970062256

Epoch: 6| Step: 6
Training loss: 3.402656078338623
Validation loss: 3.385013977686564

Epoch: 6| Step: 7
Training loss: 3.7197647094726562
Validation loss: 3.381186087926229

Epoch: 6| Step: 8
Training loss: 4.339262962341309
Validation loss: 3.3772964080174765

Epoch: 6| Step: 9
Training loss: 2.5342531204223633
Validation loss: 3.3736788431803384

Epoch: 6| Step: 10
Training loss: 3.644176721572876
Validation loss: 3.3695744276046753

Epoch: 6| Step: 11
Training loss: 4.430128574371338
Validation loss: 3.365313013394674

Epoch: 6| Step: 12
Training loss: 3.790637969970703
Validation loss: 3.3606158097585044

Epoch: 6| Step: 13
Training loss: 4.240536689758301
Validation loss: 3.3568479220072427

Epoch: 25| Step: 0
Training loss: 3.4562554359436035
Validation loss: 3.3521445194880166

Epoch: 6| Step: 1
Training loss: 3.091890811920166
Validation loss: 3.348179300626119

Epoch: 6| Step: 2
Training loss: 2.779487371444702
Validation loss: 3.3437372843424478

Epoch: 6| Step: 3
Training loss: 4.079827308654785
Validation loss: 3.3393653631210327

Epoch: 6| Step: 4
Training loss: 4.167763710021973
Validation loss: 3.334943413734436

Epoch: 6| Step: 5
Training loss: 3.93900465965271
Validation loss: 3.33053449789683

Epoch: 6| Step: 6
Training loss: 3.400327205657959
Validation loss: 3.3260468244552612

Epoch: 6| Step: 7
Training loss: 3.7551631927490234
Validation loss: 3.321596105893453

Epoch: 6| Step: 8
Training loss: 3.8670663833618164
Validation loss: 3.3170313835144043

Epoch: 6| Step: 9
Training loss: 3.01955509185791
Validation loss: 3.3128220240275064

Epoch: 6| Step: 10
Training loss: 4.088993072509766
Validation loss: 3.308554172515869

Epoch: 6| Step: 11
Training loss: 2.8768656253814697
Validation loss: 3.304249405860901

Epoch: 6| Step: 12
Training loss: 3.833590507507324
Validation loss: 3.2999104261398315

Epoch: 6| Step: 13
Training loss: 2.6223249435424805
Validation loss: 3.296302914619446

Epoch: 26| Step: 0
Training loss: 3.8846139907836914
Validation loss: 3.293302297592163

Epoch: 6| Step: 1
Training loss: 3.6517515182495117
Validation loss: 3.2891659339269004

Epoch: 6| Step: 2
Training loss: 3.419949769973755
Validation loss: 3.2856155236562095

Epoch: 6| Step: 3
Training loss: 3.4516611099243164
Validation loss: 3.2821679512659707

Epoch: 6| Step: 4
Training loss: 3.3806052207946777
Validation loss: 3.2777335246404014

Epoch: 6| Step: 5
Training loss: 2.8828182220458984
Validation loss: 3.2741020123163858

Epoch: 6| Step: 6
Training loss: 3.2834079265594482
Validation loss: 3.2702659169832864

Epoch: 6| Step: 7
Training loss: 3.8693959712982178
Validation loss: 3.266607085863749

Epoch: 6| Step: 8
Training loss: 3.439075469970703
Validation loss: 3.2623887062072754

Epoch: 6| Step: 9
Training loss: 2.738396167755127
Validation loss: 3.258098562558492

Epoch: 6| Step: 10
Training loss: 3.143583297729492
Validation loss: 3.254912773768107

Epoch: 6| Step: 11
Training loss: 4.0391106605529785
Validation loss: 3.251446843147278

Epoch: 6| Step: 12
Training loss: 3.8065848350524902
Validation loss: 3.2475904623667398

Epoch: 6| Step: 13
Training loss: 3.242222785949707
Validation loss: 3.243766268094381

Epoch: 27| Step: 0
Training loss: 3.8434104919433594
Validation loss: 3.2395464976628623

Epoch: 6| Step: 1
Training loss: 3.995269298553467
Validation loss: 3.235573728879293

Epoch: 6| Step: 2
Training loss: 3.8032584190368652
Validation loss: 3.231424887975057

Epoch: 6| Step: 3
Training loss: 3.0170750617980957
Validation loss: 3.2268640200297036

Epoch: 6| Step: 4
Training loss: 3.957094669342041
Validation loss: 3.2226224740346274

Epoch: 6| Step: 5
Training loss: 3.4967103004455566
Validation loss: 3.218580484390259

Epoch: 6| Step: 6
Training loss: 4.001049518585205
Validation loss: 3.215245763460795

Epoch: 6| Step: 7
Training loss: 3.486901044845581
Validation loss: 3.2116676568984985

Epoch: 6| Step: 8
Training loss: 2.7607240676879883
Validation loss: 3.207865516344706

Epoch: 6| Step: 9
Training loss: 2.6639089584350586
Validation loss: 3.2072333892186484

Epoch: 6| Step: 10
Training loss: 2.736882209777832
Validation loss: 3.2007663249969482

Epoch: 6| Step: 11
Training loss: 2.9697349071502686
Validation loss: 3.1965142488479614

Epoch: 6| Step: 12
Training loss: 3.530123233795166
Validation loss: 3.1922194560368857

Epoch: 6| Step: 13
Training loss: 3.272414445877075
Validation loss: 3.1893868843714395

Epoch: 28| Step: 0
Training loss: 3.0193257331848145
Validation loss: 3.1855715910593667

Epoch: 6| Step: 1
Training loss: 2.368044376373291
Validation loss: 3.183116356531779

Epoch: 6| Step: 2
Training loss: 3.596318244934082
Validation loss: 3.178698738416036

Epoch: 6| Step: 3
Training loss: 3.450248956680298
Validation loss: 3.174981872240702

Epoch: 6| Step: 4
Training loss: 3.8505029678344727
Validation loss: 3.17079496383667

Epoch: 6| Step: 5
Training loss: 3.633589744567871
Validation loss: 3.166678547859192

Epoch: 6| Step: 6
Training loss: 3.4138545989990234
Validation loss: 3.1628021796544394

Epoch: 6| Step: 7
Training loss: 3.4669711589813232
Validation loss: 3.158420284589132

Epoch: 6| Step: 8
Training loss: 4.016729354858398
Validation loss: 3.154374877611796

Epoch: 6| Step: 9
Training loss: 2.793851375579834
Validation loss: 3.1504012743631997

Epoch: 6| Step: 10
Training loss: 3.8124663829803467
Validation loss: 3.1468231280644736

Epoch: 6| Step: 11
Training loss: 2.8567802906036377
Validation loss: 3.143034060796102

Epoch: 6| Step: 12
Training loss: 2.4997401237487793
Validation loss: 3.1393233935038247

Epoch: 6| Step: 13
Training loss: 4.0732645988464355
Validation loss: 3.1360237995783486

Epoch: 29| Step: 0
Training loss: 2.7880730628967285
Validation loss: 3.132231871287028

Epoch: 6| Step: 1
Training loss: 3.8378677368164062
Validation loss: 3.1281255880991616

Epoch: 6| Step: 2
Training loss: 3.52955961227417
Validation loss: 3.1257787545522056

Epoch: 6| Step: 3
Training loss: 2.6330761909484863
Validation loss: 3.121114452679952

Epoch: 6| Step: 4
Training loss: 3.126534938812256
Validation loss: 3.1169877847035727

Epoch: 6| Step: 5
Training loss: 3.3466262817382812
Validation loss: 3.11394202709198

Epoch: 6| Step: 6
Training loss: 2.7337660789489746
Validation loss: 3.1098007758458457

Epoch: 6| Step: 7
Training loss: 2.7986900806427
Validation loss: 3.1055864095687866

Epoch: 6| Step: 8
Training loss: 3.4077486991882324
Validation loss: 3.102614641189575

Epoch: 6| Step: 9
Training loss: 3.242258310317993
Validation loss: 3.0992917815844216

Epoch: 6| Step: 10
Training loss: 3.5751242637634277
Validation loss: 3.0960174004236856

Epoch: 6| Step: 11
Training loss: 3.263317823410034
Validation loss: 3.092330813407898

Epoch: 6| Step: 12
Training loss: 3.4037206172943115
Validation loss: 3.0895256996154785

Epoch: 6| Step: 13
Training loss: 4.442407608032227
Validation loss: 3.0857431093851724

Epoch: 30| Step: 0
Training loss: 2.680659055709839
Validation loss: 3.0820438861846924

Epoch: 6| Step: 1
Training loss: 3.9968931674957275
Validation loss: 3.07865842183431

Epoch: 6| Step: 2
Training loss: 3.091986894607544
Validation loss: 3.074733336766561

Epoch: 6| Step: 3
Training loss: 3.2347264289855957
Validation loss: 3.0708009004592896

Epoch: 6| Step: 4
Training loss: 3.0286009311676025
Validation loss: 3.066718339920044

Epoch: 6| Step: 5
Training loss: 3.8675408363342285
Validation loss: 3.0629295905431113

Epoch: 6| Step: 6
Training loss: 3.981902599334717
Validation loss: 3.0598889191945395

Epoch: 6| Step: 7
Training loss: 3.3237342834472656
Validation loss: 3.0563449462254844

Epoch: 6| Step: 8
Training loss: 3.732691764831543
Validation loss: 3.053250233332316

Epoch: 6| Step: 9
Training loss: 3.9025726318359375
Validation loss: 3.0491979916890464

Epoch: 6| Step: 10
Training loss: 2.6078343391418457
Validation loss: 3.045565406481425

Epoch: 6| Step: 11
Training loss: 3.239011287689209
Validation loss: 3.0420737266540527

Epoch: 6| Step: 12
Training loss: 2.0710840225219727
Validation loss: 3.0381539265314736

Epoch: 6| Step: 13
Training loss: 2.745445728302002
Validation loss: 3.034864147504171

Epoch: 31| Step: 0
Training loss: 2.7849879264831543
Validation loss: 3.0315476258595786

Epoch: 6| Step: 1
Training loss: 3.074317693710327
Validation loss: 3.028618812561035

Epoch: 6| Step: 2
Training loss: 3.492600202560425
Validation loss: 3.025535821914673

Epoch: 6| Step: 3
Training loss: 3.853034257888794
Validation loss: 3.022251009941101

Epoch: 6| Step: 4
Training loss: 3.0922887325286865
Validation loss: 3.0205535888671875

Epoch: 6| Step: 5
Training loss: 4.023620128631592
Validation loss: 3.017373522122701

Epoch: 6| Step: 6
Training loss: 3.6094377040863037
Validation loss: 3.0135744412740073

Epoch: 6| Step: 7
Training loss: 2.9937825202941895
Validation loss: 3.008409261703491

Epoch: 6| Step: 8
Training loss: 2.788271903991699
Validation loss: 3.0047644774119058

Epoch: 6| Step: 9
Training loss: 2.4874510765075684
Validation loss: 3.000597357749939

Epoch: 6| Step: 10
Training loss: 2.5728132724761963
Validation loss: 2.9968112309773765

Epoch: 6| Step: 11
Training loss: 2.8185875415802
Validation loss: 2.9934885501861572

Epoch: 6| Step: 12
Training loss: 4.020143032073975
Validation loss: 2.990730126698812

Epoch: 6| Step: 13
Training loss: 3.237499237060547
Validation loss: 2.9872684876124063

Epoch: 32| Step: 0
Training loss: 3.6064767837524414
Validation loss: 2.9844285249710083

Epoch: 6| Step: 1
Training loss: 3.339792251586914
Validation loss: 2.980260690053304

Epoch: 6| Step: 2
Training loss: 3.393829822540283
Validation loss: 2.976858615875244

Epoch: 6| Step: 3
Training loss: 2.406630039215088
Validation loss: 2.9732350508371987

Epoch: 6| Step: 4
Training loss: 2.671719551086426
Validation loss: 2.9695550998051963

Epoch: 6| Step: 5
Training loss: 3.027496814727783
Validation loss: 2.9667698542277017

Epoch: 6| Step: 6
Training loss: 3.2471861839294434
Validation loss: 2.9637981255849204

Epoch: 6| Step: 7
Training loss: 2.393312692642212
Validation loss: 2.959492643674215

Epoch: 6| Step: 8
Training loss: 3.4634299278259277
Validation loss: 2.9566760460535684

Epoch: 6| Step: 9
Training loss: 3.0091135501861572
Validation loss: 2.9533880949020386

Epoch: 6| Step: 10
Training loss: 3.637049436569214
Validation loss: 2.9500264525413513

Epoch: 6| Step: 11
Training loss: 3.521979331970215
Validation loss: 2.9456262588500977

Epoch: 6| Step: 12
Training loss: 3.4275240898132324
Validation loss: 2.942699154218038

Epoch: 6| Step: 13
Training loss: 3.0885255336761475
Validation loss: 2.938535968462626

Epoch: 33| Step: 0
Training loss: 2.074326992034912
Validation loss: 2.9329903523127236

Epoch: 6| Step: 1
Training loss: 2.9756221771240234
Validation loss: 2.930073936780294

Epoch: 6| Step: 2
Training loss: 2.8474221229553223
Validation loss: 2.9263750513394675

Epoch: 6| Step: 3
Training loss: 3.239279270172119
Validation loss: 2.923684597015381

Epoch: 6| Step: 4
Training loss: 2.8963634967803955
Validation loss: 2.920245806376139

Epoch: 6| Step: 5
Training loss: 2.987399101257324
Validation loss: 2.9176799058914185

Epoch: 6| Step: 6
Training loss: 4.258178234100342
Validation loss: 2.9146741231282554

Epoch: 6| Step: 7
Training loss: 3.6138479709625244
Validation loss: 2.9102853536605835

Epoch: 6| Step: 8
Training loss: 3.4575705528259277
Validation loss: 2.907560110092163

Epoch: 6| Step: 9
Training loss: 3.0587377548217773
Validation loss: 2.9032323757807412

Epoch: 6| Step: 10
Training loss: 3.6076278686523438
Validation loss: 2.901729623476664

Epoch: 6| Step: 11
Training loss: 2.890753746032715
Validation loss: 2.8987514972686768

Epoch: 6| Step: 12
Training loss: 2.678187370300293
Validation loss: 2.9038613637288413

Epoch: 6| Step: 13
Training loss: 2.9970970153808594
Validation loss: 2.8999743858973184

Epoch: 34| Step: 0
Training loss: 3.723661422729492
Validation loss: 2.8870009183883667

Epoch: 6| Step: 1
Training loss: 3.362030506134033
Validation loss: 2.8837159872055054

Epoch: 6| Step: 2
Training loss: 3.637418746948242
Validation loss: 2.879231850306193

Epoch: 6| Step: 3
Training loss: 3.6116342544555664
Validation loss: 2.878148674964905

Epoch: 6| Step: 4
Training loss: 2.4087300300598145
Validation loss: 2.8767759005228677

Epoch: 6| Step: 5
Training loss: 3.597201108932495
Validation loss: 2.8747281432151794

Epoch: 6| Step: 6
Training loss: 2.6487083435058594
Validation loss: 2.868490735689799

Epoch: 6| Step: 7
Training loss: 3.5038270950317383
Validation loss: 2.8643566767374673

Epoch: 6| Step: 8
Training loss: 2.9272618293762207
Validation loss: 2.8602083921432495

Epoch: 6| Step: 9
Training loss: 2.3705663681030273
Validation loss: 2.8564093112945557

Epoch: 6| Step: 10
Training loss: 2.46852970123291
Validation loss: 2.8530873457590737

Epoch: 6| Step: 11
Training loss: 2.5684406757354736
Validation loss: 2.849983056386312

Epoch: 6| Step: 12
Training loss: 2.4281256198883057
Validation loss: 2.847669800122579

Epoch: 6| Step: 13
Training loss: 3.7394065856933594
Validation loss: 2.8456116120020547

Epoch: 35| Step: 0
Training loss: 2.6938705444335938
Validation loss: 2.8452541828155518

Epoch: 6| Step: 1
Training loss: 3.010737895965576
Validation loss: 2.84235680103302

Epoch: 6| Step: 2
Training loss: 3.339285373687744
Validation loss: 2.835996429125468

Epoch: 6| Step: 3
Training loss: 3.3375470638275146
Validation loss: 2.831869343916575

Epoch: 6| Step: 4
Training loss: 2.613727331161499
Validation loss: 2.8287742535273233

Epoch: 6| Step: 5
Training loss: 2.4876174926757812
Validation loss: 2.824092229207357

Epoch: 6| Step: 6
Training loss: 2.705338478088379
Validation loss: 2.821562965710958

Epoch: 6| Step: 7
Training loss: 4.130263328552246
Validation loss: 2.8179194132486978

Epoch: 6| Step: 8
Training loss: 2.870168924331665
Validation loss: 2.8137127161026

Epoch: 6| Step: 9
Training loss: 2.729950428009033
Validation loss: 2.8110984563827515

Epoch: 6| Step: 10
Training loss: 3.3740768432617188
Validation loss: 2.8084621826807656

Epoch: 6| Step: 11
Training loss: 2.915705919265747
Validation loss: 2.8054874738057456

Epoch: 6| Step: 12
Training loss: 2.951948881149292
Validation loss: 2.8021190563837686

Epoch: 6| Step: 13
Training loss: 3.2427473068237305
Validation loss: 2.7985156377156577

Epoch: 36| Step: 0
Training loss: 3.221957206726074
Validation loss: 2.7953863541285195

Epoch: 6| Step: 1
Training loss: 2.2739977836608887
Validation loss: 2.792569120724996

Epoch: 6| Step: 2
Training loss: 3.014092445373535
Validation loss: 2.789475440979004

Epoch: 6| Step: 3
Training loss: 3.522517204284668
Validation loss: 2.7872991959253945

Epoch: 6| Step: 4
Training loss: 2.7468461990356445
Validation loss: 2.7837256590525308

Epoch: 6| Step: 5
Training loss: 2.6444787979125977
Validation loss: 2.781440496444702

Epoch: 6| Step: 6
Training loss: 3.6311771869659424
Validation loss: 2.777685046195984

Epoch: 6| Step: 7
Training loss: 2.4861268997192383
Validation loss: 2.775295933087667

Epoch: 6| Step: 8
Training loss: 2.547694683074951
Validation loss: 2.7724978923797607

Epoch: 6| Step: 9
Training loss: 3.386319160461426
Validation loss: 2.7693196535110474

Epoch: 6| Step: 10
Training loss: 2.7862565517425537
Validation loss: 2.7662100791931152

Epoch: 6| Step: 11
Training loss: 3.509608507156372
Validation loss: 2.7635875145594277

Epoch: 6| Step: 12
Training loss: 3.187598705291748
Validation loss: 2.7607080936431885

Epoch: 6| Step: 13
Training loss: 2.8770508766174316
Validation loss: 2.757234732309977

Epoch: 37| Step: 0
Training loss: 2.552671194076538
Validation loss: 2.7538735071818032

Epoch: 6| Step: 1
Training loss: 3.171882152557373
Validation loss: 2.750284214814504

Epoch: 6| Step: 2
Training loss: 2.843705177307129
Validation loss: 2.74685271581014

Epoch: 6| Step: 3
Training loss: 3.3710415363311768
Validation loss: 2.7448755900065103

Epoch: 6| Step: 4
Training loss: 2.633552074432373
Validation loss: 2.7404499451319375

Epoch: 6| Step: 5
Training loss: 2.51591157913208
Validation loss: 2.7380760113398233

Epoch: 6| Step: 6
Training loss: 2.7770724296569824
Validation loss: 2.7340939044952393

Epoch: 6| Step: 7
Training loss: 3.1392412185668945
Validation loss: 2.7313501834869385

Epoch: 6| Step: 8
Training loss: 3.2451064586639404
Validation loss: 2.7298270066579184

Epoch: 6| Step: 9
Training loss: 2.648916006088257
Validation loss: 2.7259580294291177

Epoch: 6| Step: 10
Training loss: 3.378652572631836
Validation loss: 2.7244656880696616

Epoch: 6| Step: 11
Training loss: 2.974857807159424
Validation loss: 2.7258768479029336

Epoch: 6| Step: 12
Training loss: 2.579545259475708
Validation loss: 2.747164726257324

Epoch: 6| Step: 13
Training loss: 3.401264190673828
Validation loss: 2.713228146235148

Epoch: 38| Step: 0
Training loss: 2.324765205383301
Validation loss: 2.7114068269729614

Epoch: 6| Step: 1
Training loss: 3.144634962081909
Validation loss: 2.7094202438990274

Epoch: 6| Step: 2
Training loss: 3.1144795417785645
Validation loss: 2.7072869141896567

Epoch: 6| Step: 3
Training loss: 2.5859885215759277
Validation loss: 2.7238882780075073

Epoch: 6| Step: 4
Training loss: 3.228224754333496
Validation loss: 2.774262269337972

Epoch: 6| Step: 5
Training loss: 3.2644410133361816
Validation loss: 2.743224859237671

Epoch: 6| Step: 6
Training loss: 1.9770716428756714
Validation loss: 2.7201213041941323

Epoch: 6| Step: 7
Training loss: 2.383768081665039
Validation loss: 2.693818966547648

Epoch: 6| Step: 8
Training loss: 3.0400443077087402
Validation loss: 2.691702723503113

Epoch: 6| Step: 9
Training loss: 3.072331428527832
Validation loss: 2.6951374610265098

Epoch: 6| Step: 10
Training loss: 3.6301279067993164
Validation loss: 2.694547454516093

Epoch: 6| Step: 11
Training loss: 2.9147636890411377
Validation loss: 2.695971449216207

Epoch: 6| Step: 12
Training loss: 2.42087459564209
Validation loss: 2.6927252213160195

Epoch: 6| Step: 13
Training loss: 3.7934117317199707
Validation loss: 2.687805970509847

Epoch: 39| Step: 0
Training loss: 2.724612236022949
Validation loss: 2.6811786890029907

Epoch: 6| Step: 1
Training loss: 3.120443105697632
Validation loss: 2.674626628557841

Epoch: 6| Step: 2
Training loss: 3.146378993988037
Validation loss: 2.6718089977900186

Epoch: 6| Step: 3
Training loss: 3.659252643585205
Validation loss: 2.669153849283854

Epoch: 6| Step: 4
Training loss: 3.1152777671813965
Validation loss: 2.6654321352640786

Epoch: 6| Step: 5
Training loss: 2.92984676361084
Validation loss: 2.6619189977645874

Epoch: 6| Step: 6
Training loss: 1.8115503787994385
Validation loss: 2.658695181210836

Epoch: 6| Step: 7
Training loss: 3.531649589538574
Validation loss: 2.6554160515467324

Epoch: 6| Step: 8
Training loss: 2.6407556533813477
Validation loss: 2.6541179418563843

Epoch: 6| Step: 9
Training loss: 2.3805999755859375
Validation loss: 2.6506234804789224

Epoch: 6| Step: 10
Training loss: 2.332810401916504
Validation loss: 2.647992571194967

Epoch: 6| Step: 11
Training loss: 2.7537455558776855
Validation loss: 2.6433725357055664

Epoch: 6| Step: 12
Training loss: 3.012596368789673
Validation loss: 2.638999422391256

Epoch: 6| Step: 13
Training loss: 2.9263176918029785
Validation loss: 2.6358453035354614

Epoch: 40| Step: 0
Training loss: 2.9393632411956787
Validation loss: 2.632115364074707

Epoch: 6| Step: 1
Training loss: 2.3785386085510254
Validation loss: 2.627574324607849

Epoch: 6| Step: 2
Training loss: 3.1742420196533203
Validation loss: 2.6252729495366416

Epoch: 6| Step: 3
Training loss: 3.11295223236084
Validation loss: 2.6205114920934043

Epoch: 6| Step: 4
Training loss: 3.422865390777588
Validation loss: 2.6175846258799234

Epoch: 6| Step: 5
Training loss: 3.218184471130371
Validation loss: 2.61466113726298

Epoch: 6| Step: 6
Training loss: 2.0648515224456787
Validation loss: 2.6089539527893066

Epoch: 6| Step: 7
Training loss: 2.9578099250793457
Validation loss: 2.605183760325114

Epoch: 6| Step: 8
Training loss: 2.312502861022949
Validation loss: 2.6013326247533164

Epoch: 6| Step: 9
Training loss: 2.731605052947998
Validation loss: 2.6011359294255576

Epoch: 6| Step: 10
Training loss: 3.0871362686157227
Validation loss: 2.600594480832418

Epoch: 6| Step: 11
Training loss: 2.4254817962646484
Validation loss: 2.5984624226888022

Epoch: 6| Step: 12
Training loss: 3.0367870330810547
Validation loss: 2.596247434616089

Epoch: 6| Step: 13
Training loss: 2.4859232902526855
Validation loss: 2.5924885272979736

Epoch: 41| Step: 0
Training loss: 2.6487982273101807
Validation loss: 2.5888770818710327

Epoch: 6| Step: 1
Training loss: 2.578226327896118
Validation loss: 2.589634736378988

Epoch: 6| Step: 2
Training loss: 2.3280844688415527
Validation loss: 2.581195036570231

Epoch: 6| Step: 3
Training loss: 2.6068179607391357
Validation loss: 2.5788421432177224

Epoch: 6| Step: 4
Training loss: 2.8850488662719727
Validation loss: 2.57251246770223

Epoch: 6| Step: 5
Training loss: 2.4413936138153076
Validation loss: 2.5695653160413108

Epoch: 6| Step: 6
Training loss: 2.2485790252685547
Validation loss: 2.566724181175232

Epoch: 6| Step: 7
Training loss: 3.32781982421875
Validation loss: 2.5654130776723227

Epoch: 6| Step: 8
Training loss: 2.8701233863830566
Validation loss: 2.5605674982070923

Epoch: 6| Step: 9
Training loss: 2.1356632709503174
Validation loss: 2.5594269434611

Epoch: 6| Step: 10
Training loss: 3.180158853530884
Validation loss: 2.5615333716074624

Epoch: 6| Step: 11
Training loss: 3.278590202331543
Validation loss: 2.5603588024775186

Epoch: 6| Step: 12
Training loss: 3.0045418739318848
Validation loss: 2.55070165793101

Epoch: 6| Step: 13
Training loss: 3.224367618560791
Validation loss: 2.546852628389994

Epoch: 42| Step: 0
Training loss: 2.9219677448272705
Validation loss: 2.5438817342122397

Epoch: 6| Step: 1
Training loss: 3.0490970611572266
Validation loss: 2.544556478659312

Epoch: 6| Step: 2
Training loss: 2.783773422241211
Validation loss: 2.5406944155693054

Epoch: 6| Step: 3
Training loss: 2.5937626361846924
Validation loss: 2.5390188892682395

Epoch: 6| Step: 4
Training loss: 2.7192163467407227
Validation loss: 2.5374284982681274

Epoch: 6| Step: 5
Training loss: 3.136324405670166
Validation loss: 2.534570256868998

Epoch: 6| Step: 6
Training loss: 1.6293150186538696
Validation loss: 2.531275908152262

Epoch: 6| Step: 7
Training loss: 2.8115999698638916
Validation loss: 2.5296212832132974

Epoch: 6| Step: 8
Training loss: 2.9451847076416016
Validation loss: 2.5262104670206704

Epoch: 6| Step: 9
Training loss: 3.0439751148223877
Validation loss: 2.519550164540609

Epoch: 6| Step: 10
Training loss: 2.7352685928344727
Validation loss: 2.5180672804514566

Epoch: 6| Step: 11
Training loss: 2.495711088180542
Validation loss: 2.513067642847697

Epoch: 6| Step: 12
Training loss: 2.3562402725219727
Validation loss: 2.510503967603048

Epoch: 6| Step: 13
Training loss: 2.9267396926879883
Validation loss: 2.5073323249816895

Epoch: 43| Step: 0
Training loss: 2.6805853843688965
Validation loss: 2.507209300994873

Epoch: 6| Step: 1
Training loss: 2.566486358642578
Validation loss: 2.5009812116622925

Epoch: 6| Step: 2
Training loss: 3.019897937774658
Validation loss: 2.4993409315745034

Epoch: 6| Step: 3
Training loss: 2.5895681381225586
Validation loss: 2.493935306866964

Epoch: 6| Step: 4
Training loss: 2.965330123901367
Validation loss: 2.491542021433512

Epoch: 6| Step: 5
Training loss: 2.47869610786438
Validation loss: 2.4906062483787537

Epoch: 6| Step: 6
Training loss: 2.5869922637939453
Validation loss: 2.4898080031077066

Epoch: 6| Step: 7
Training loss: 2.8234362602233887
Validation loss: 2.4857091506322226

Epoch: 6| Step: 8
Training loss: 2.7704319953918457
Validation loss: 2.4839011828104653

Epoch: 6| Step: 9
Training loss: 2.7587616443634033
Validation loss: 2.4810805320739746

Epoch: 6| Step: 10
Training loss: 2.1774544715881348
Validation loss: 2.4761428038279214

Epoch: 6| Step: 11
Training loss: 3.181796073913574
Validation loss: 2.474132776260376

Epoch: 6| Step: 12
Training loss: 2.4426286220550537
Validation loss: 2.473519444465637

Epoch: 6| Step: 13
Training loss: 2.469773769378662
Validation loss: 2.469053308169047

Epoch: 44| Step: 0
Training loss: 1.9409470558166504
Validation loss: 2.4658565123875937

Epoch: 6| Step: 1
Training loss: 3.184612512588501
Validation loss: 2.466796557108561

Epoch: 6| Step: 2
Training loss: 2.4125471115112305
Validation loss: 2.460969607035319

Epoch: 6| Step: 3
Training loss: 2.871793746948242
Validation loss: 2.467691699663798

Epoch: 6| Step: 4
Training loss: 2.2424025535583496
Validation loss: 2.466324806213379

Epoch: 6| Step: 5
Training loss: 2.7259774208068848
Validation loss: 2.4546876748402915

Epoch: 6| Step: 6
Training loss: 2.514218807220459
Validation loss: 2.45199183622996

Epoch: 6| Step: 7
Training loss: 2.282928466796875
Validation loss: 2.4497149189313254

Epoch: 6| Step: 8
Training loss: 2.374852418899536
Validation loss: 2.4432584842046103

Epoch: 6| Step: 9
Training loss: 2.8635640144348145
Validation loss: 2.440873901049296

Epoch: 6| Step: 10
Training loss: 2.6801438331604004
Validation loss: 2.4405486583709717

Epoch: 6| Step: 11
Training loss: 2.9840688705444336
Validation loss: 2.437239388624827

Epoch: 6| Step: 12
Training loss: 3.0205390453338623
Validation loss: 2.434001604715983

Epoch: 6| Step: 13
Training loss: 2.812074661254883
Validation loss: 2.4343807299931846

Epoch: 45| Step: 0
Training loss: 2.9660894870758057
Validation loss: 2.4309123953183494

Epoch: 6| Step: 1
Training loss: 2.2178149223327637
Validation loss: 2.427559574445089

Epoch: 6| Step: 2
Training loss: 2.097409725189209
Validation loss: 2.424495816230774

Epoch: 6| Step: 3
Training loss: 2.803624153137207
Validation loss: 2.4204214811325073

Epoch: 6| Step: 4
Training loss: 2.9168648719787598
Validation loss: 2.4212292631467185

Epoch: 6| Step: 5
Training loss: 2.2909862995147705
Validation loss: 2.4174850583076477

Epoch: 6| Step: 6
Training loss: 2.8862743377685547
Validation loss: 2.4171188275019326

Epoch: 6| Step: 7
Training loss: 2.483907699584961
Validation loss: 2.4107340971628823

Epoch: 6| Step: 8
Training loss: 3.113466262817383
Validation loss: 2.4113563696543374

Epoch: 6| Step: 9
Training loss: 3.096341133117676
Validation loss: 2.406411608060201

Epoch: 6| Step: 10
Training loss: 1.8613704442977905
Validation loss: 2.3981234431266785

Epoch: 6| Step: 11
Training loss: 2.4664764404296875
Validation loss: 2.3994744221369424

Epoch: 6| Step: 12
Training loss: 2.5857090950012207
Validation loss: 2.3970807592074075

Epoch: 6| Step: 13
Training loss: 2.5392777919769287
Validation loss: 2.3979612588882446

Epoch: 46| Step: 0
Training loss: 2.276968479156494
Validation loss: 2.395532568295797

Epoch: 6| Step: 1
Training loss: 3.024020195007324
Validation loss: 2.3993870615959167

Epoch: 6| Step: 2
Training loss: 2.6100308895111084
Validation loss: 2.4015690088272095

Epoch: 6| Step: 3
Training loss: 2.80887508392334
Validation loss: 2.389959235986074

Epoch: 6| Step: 4
Training loss: 2.7647290229797363
Validation loss: 2.3901997804641724

Epoch: 6| Step: 5
Training loss: 2.5899338722229004
Validation loss: 2.384825030962626

Epoch: 6| Step: 6
Training loss: 2.622558116912842
Validation loss: 2.378206809361776

Epoch: 6| Step: 7
Training loss: 2.697404384613037
Validation loss: 2.3724942604700723

Epoch: 6| Step: 8
Training loss: 2.5431418418884277
Validation loss: 2.3726334969202676

Epoch: 6| Step: 9
Training loss: 2.8662867546081543
Validation loss: 2.3708077470461526

Epoch: 6| Step: 10
Training loss: 2.1087870597839355
Validation loss: 2.37148255109787

Epoch: 6| Step: 11
Training loss: 1.8866071701049805
Validation loss: 2.3658113876978555

Epoch: 6| Step: 12
Training loss: 2.5545692443847656
Validation loss: 2.3680279652277627

Epoch: 6| Step: 13
Training loss: 2.4618611335754395
Validation loss: 2.3634755412737527

Epoch: 47| Step: 0
Training loss: 3.05357027053833
Validation loss: 2.362826883792877

Epoch: 6| Step: 1
Training loss: 2.353555679321289
Validation loss: 2.3582648436228433

Epoch: 6| Step: 2
Training loss: 2.6298751831054688
Validation loss: 2.3579354484876

Epoch: 6| Step: 3
Training loss: 2.6187543869018555
Validation loss: 2.3535759250322976

Epoch: 6| Step: 4
Training loss: 2.4470930099487305
Validation loss: 2.3478121956189475

Epoch: 6| Step: 5
Training loss: 2.5203537940979004
Validation loss: 2.3464432756106057

Epoch: 6| Step: 6
Training loss: 3.3604607582092285
Validation loss: 2.341953535874685

Epoch: 6| Step: 7
Training loss: 2.9771342277526855
Validation loss: 2.3437299132347107

Epoch: 6| Step: 8
Training loss: 2.2817435264587402
Validation loss: 2.335409084955851

Epoch: 6| Step: 9
Training loss: 2.564854383468628
Validation loss: 2.332434594631195

Epoch: 6| Step: 10
Training loss: 1.6399033069610596
Validation loss: 2.3301943937937417

Epoch: 6| Step: 11
Training loss: 1.9628064632415771
Validation loss: 2.328290859858195

Epoch: 6| Step: 12
Training loss: 2.547865867614746
Validation loss: 2.3234099547068277

Epoch: 6| Step: 13
Training loss: 2.283729076385498
Validation loss: 2.324892441431681

Epoch: 48| Step: 0
Training loss: 2.3730337619781494
Validation loss: 2.320910612742106

Epoch: 6| Step: 1
Training loss: 2.642472267150879
Validation loss: 2.3195745944976807

Epoch: 6| Step: 2
Training loss: 2.5644867420196533
Validation loss: 2.31505020459493

Epoch: 6| Step: 3
Training loss: 2.859560489654541
Validation loss: 2.3116183280944824

Epoch: 6| Step: 4
Training loss: 2.670701026916504
Validation loss: 2.315931757291158

Epoch: 6| Step: 5
Training loss: 2.7085423469543457
Validation loss: 2.3059574365615845

Epoch: 6| Step: 6
Training loss: 2.2494056224823
Validation loss: 2.306022127469381

Epoch: 6| Step: 7
Training loss: 2.5396265983581543
Validation loss: 2.2986561059951782

Epoch: 6| Step: 8
Training loss: 2.420106887817383
Validation loss: 2.2991846203804016

Epoch: 6| Step: 9
Training loss: 2.567037582397461
Validation loss: 2.296490470568339

Epoch: 6| Step: 10
Training loss: 2.290989875793457
Validation loss: 2.2955243587493896

Epoch: 6| Step: 11
Training loss: 2.5627856254577637
Validation loss: 2.2938003738721213

Epoch: 6| Step: 12
Training loss: 2.214576482772827
Validation loss: 2.290541489919027

Epoch: 6| Step: 13
Training loss: 1.9803478717803955
Validation loss: 2.288940707842509

Epoch: 49| Step: 0
Training loss: 2.374361991882324
Validation loss: 2.2874784668286643

Epoch: 6| Step: 1
Training loss: 2.391458034515381
Validation loss: 2.2829173803329468

Epoch: 6| Step: 2
Training loss: 2.256194591522217
Validation loss: 2.288164575894674

Epoch: 6| Step: 3
Training loss: 2.864912271499634
Validation loss: 2.2793833216031394

Epoch: 6| Step: 4
Training loss: 1.370745301246643
Validation loss: 2.2740668654441833

Epoch: 6| Step: 5
Training loss: 2.5891265869140625
Validation loss: 2.271955211957296

Epoch: 6| Step: 6
Training loss: 2.604001522064209
Validation loss: 2.2691743771235147

Epoch: 6| Step: 7
Training loss: 2.8932199478149414
Validation loss: 2.2708323995272317

Epoch: 6| Step: 8
Training loss: 2.4559831619262695
Validation loss: 2.2719748616218567

Epoch: 6| Step: 9
Training loss: 2.2132062911987305
Validation loss: 2.268702983856201

Epoch: 6| Step: 10
Training loss: 2.185732364654541
Validation loss: 2.2632818023363748

Epoch: 6| Step: 11
Training loss: 2.802013635635376
Validation loss: 2.261603355407715

Epoch: 6| Step: 12
Training loss: 2.591456890106201
Validation loss: 2.259652853012085

Epoch: 6| Step: 13
Training loss: 2.453866958618164
Validation loss: 2.256389300028483

Epoch: 50| Step: 0
Training loss: 2.348355293273926
Validation loss: 2.2554867267608643

Epoch: 6| Step: 1
Training loss: 2.0398130416870117
Validation loss: 2.248420476913452

Epoch: 6| Step: 2
Training loss: 2.603520393371582
Validation loss: 2.254513740539551

Epoch: 6| Step: 3
Training loss: 2.5114197731018066
Validation loss: 2.2513903379440308

Epoch: 6| Step: 4
Training loss: 2.3315834999084473
Validation loss: 2.2443719704945884

Epoch: 6| Step: 5
Training loss: 2.1495673656463623
Validation loss: 2.242988169193268

Epoch: 6| Step: 6
Training loss: 2.780428171157837
Validation loss: 2.2376975417137146

Epoch: 6| Step: 7
Training loss: 2.4333207607269287
Validation loss: 2.2382320960362754

Epoch: 6| Step: 8
Training loss: 2.3403892517089844
Validation loss: 2.236042857170105

Epoch: 6| Step: 9
Training loss: 2.6495091915130615
Validation loss: 2.232427398363749

Epoch: 6| Step: 10
Training loss: 2.644836902618408
Validation loss: 2.240143835544586

Epoch: 6| Step: 11
Training loss: 2.6658153533935547
Validation loss: 2.2452640732129416

Epoch: 6| Step: 12
Training loss: 1.977006435394287
Validation loss: 2.231022079785665

Epoch: 6| Step: 13
Training loss: 2.1009631156921387
Validation loss: 2.223785618940989

Epoch: 51| Step: 0
Training loss: 2.4349653720855713
Validation loss: 2.2183753649393716

Epoch: 6| Step: 1
Training loss: 3.194357395172119
Validation loss: 2.217352251211802

Epoch: 6| Step: 2
Training loss: 1.7868409156799316
Validation loss: 2.2161075472831726

Epoch: 6| Step: 3
Training loss: 2.395939826965332
Validation loss: 2.2199789683024087

Epoch: 6| Step: 4
Training loss: 2.083735466003418
Validation loss: 2.221591075261434

Epoch: 6| Step: 5
Training loss: 2.989927291870117
Validation loss: 2.211497167746226

Epoch: 6| Step: 6
Training loss: 2.699038505554199
Validation loss: 2.212276339530945

Epoch: 6| Step: 7
Training loss: 2.472651720046997
Validation loss: 2.2122050722440085

Epoch: 6| Step: 8
Training loss: 1.3553942441940308
Validation loss: 2.211107055346171

Epoch: 6| Step: 9
Training loss: 2.33683443069458
Validation loss: 2.2084505756696067

Epoch: 6| Step: 10
Training loss: 2.1720218658447266
Validation loss: 2.205502967039744

Epoch: 6| Step: 11
Training loss: 2.6284337043762207
Validation loss: 2.2011160055796304

Epoch: 6| Step: 12
Training loss: 2.5747857093811035
Validation loss: 2.200995127360026

Epoch: 6| Step: 13
Training loss: 2.0123467445373535
Validation loss: 2.1968577106793723

Epoch: 52| Step: 0
Training loss: 2.094560146331787
Validation loss: 2.198767066001892

Epoch: 6| Step: 1
Training loss: 3.1201705932617188
Validation loss: 2.1966718236605325

Epoch: 6| Step: 2
Training loss: 2.3691067695617676
Validation loss: 2.194426198800405

Epoch: 6| Step: 3
Training loss: 2.2314016819000244
Validation loss: 2.1934247414271035

Epoch: 6| Step: 4
Training loss: 1.9030232429504395
Validation loss: 2.190808196862539

Epoch: 6| Step: 5
Training loss: 2.4509379863739014
Validation loss: 2.1889832417170205

Epoch: 6| Step: 6
Training loss: 2.406949043273926
Validation loss: 2.191487809022268

Epoch: 6| Step: 7
Training loss: 2.0709753036499023
Validation loss: 2.1831682324409485

Epoch: 6| Step: 8
Training loss: 2.300718069076538
Validation loss: 2.1812671025594077

Epoch: 6| Step: 9
Training loss: 2.543802261352539
Validation loss: 2.178527553876241

Epoch: 6| Step: 10
Training loss: 2.3146932125091553
Validation loss: 2.1776747703552246

Epoch: 6| Step: 11
Training loss: 2.0612165927886963
Validation loss: 2.1713398496309915

Epoch: 6| Step: 12
Training loss: 2.3414125442504883
Validation loss: 2.1739517052968345

Epoch: 6| Step: 13
Training loss: 2.59909987449646
Validation loss: 2.1678553422292075

Epoch: 53| Step: 0
Training loss: 2.3459420204162598
Validation loss: 2.1692459185918174

Epoch: 6| Step: 1
Training loss: 2.169205904006958
Validation loss: 2.16950786113739

Epoch: 6| Step: 2
Training loss: 2.258340358734131
Validation loss: 2.1696933706601462

Epoch: 6| Step: 3
Training loss: 2.166968584060669
Validation loss: 2.1646548906962075

Epoch: 6| Step: 4
Training loss: 2.5810484886169434
Validation loss: 2.165481150150299

Epoch: 6| Step: 5
Training loss: 1.5541037321090698
Validation loss: 2.16492227713267

Epoch: 6| Step: 6
Training loss: 2.250875473022461
Validation loss: 2.163011888662974

Epoch: 6| Step: 7
Training loss: 2.2969765663146973
Validation loss: 2.1581523617108664

Epoch: 6| Step: 8
Training loss: 1.9519412517547607
Validation loss: 2.151879131793976

Epoch: 6| Step: 9
Training loss: 2.0337915420532227
Validation loss: 2.1537248690923056

Epoch: 6| Step: 10
Training loss: 2.6875298023223877
Validation loss: 2.1539074182510376

Epoch: 6| Step: 11
Training loss: 3.088930130004883
Validation loss: 2.148950735727946

Epoch: 6| Step: 12
Training loss: 2.0537397861480713
Validation loss: 2.1549940506617227

Epoch: 6| Step: 13
Training loss: 3.0417137145996094
Validation loss: 2.1697989304860434

Epoch: 54| Step: 0
Training loss: 2.010347604751587
Validation loss: 2.1647187074025473

Epoch: 6| Step: 1
Training loss: 2.1294312477111816
Validation loss: 2.1482661962509155

Epoch: 6| Step: 2
Training loss: 2.106510639190674
Validation loss: 2.137324810028076

Epoch: 6| Step: 3
Training loss: 1.922996997833252
Validation loss: 2.1373512943585715

Epoch: 6| Step: 4
Training loss: 2.130570888519287
Validation loss: 2.1370630065600076

Epoch: 6| Step: 5
Training loss: 2.015377998352051
Validation loss: 2.134210705757141

Epoch: 6| Step: 6
Training loss: 2.677252769470215
Validation loss: 2.134701649347941

Epoch: 6| Step: 7
Training loss: 2.240386486053467
Validation loss: 2.137156049410502

Epoch: 6| Step: 8
Training loss: 2.278902053833008
Validation loss: 2.1321619351704917

Epoch: 6| Step: 9
Training loss: 2.168484926223755
Validation loss: 2.132279694080353

Epoch: 6| Step: 10
Training loss: 2.289133071899414
Validation loss: 2.1268945137659707

Epoch: 6| Step: 11
Training loss: 2.5727550983428955
Validation loss: 2.1272198955217996

Epoch: 6| Step: 12
Training loss: 3.4483344554901123
Validation loss: 2.1273883978525796

Epoch: 6| Step: 13
Training loss: 2.2109804153442383
Validation loss: 2.127929071585337

Epoch: 55| Step: 0
Training loss: 2.611603260040283
Validation loss: 2.1244751811027527

Epoch: 6| Step: 1
Training loss: 2.225651979446411
Validation loss: 2.1271416346232095

Epoch: 6| Step: 2
Training loss: 2.7480576038360596
Validation loss: 2.133966048558553

Epoch: 6| Step: 3
Training loss: 2.390516996383667
Validation loss: 2.1308103998502097

Epoch: 6| Step: 4
Training loss: 2.385446071624756
Validation loss: 2.1296435594558716

Epoch: 6| Step: 5
Training loss: 1.795487880706787
Validation loss: 2.1291202505429587

Epoch: 6| Step: 6
Training loss: 2.103672504425049
Validation loss: 2.1279062231381736

Epoch: 6| Step: 7
Training loss: 2.1337523460388184
Validation loss: 2.1275303761164346

Epoch: 6| Step: 8
Training loss: 2.435065269470215
Validation loss: 2.1279620130856833

Epoch: 6| Step: 9
Training loss: 1.8099232912063599
Validation loss: 2.131293296813965

Epoch: 6| Step: 10
Training loss: 3.1540186405181885
Validation loss: 2.1339943607648215

Epoch: 6| Step: 11
Training loss: 1.9358069896697998
Validation loss: 2.1238417824109397

Epoch: 6| Step: 12
Training loss: 1.8656141757965088
Validation loss: 2.120326201121012

Epoch: 6| Step: 13
Training loss: 2.3851914405822754
Validation loss: 2.114732245604197

Epoch: 56| Step: 0
Training loss: 2.4096217155456543
Validation loss: 2.1146519978841147

Epoch: 6| Step: 1
Training loss: 1.9643727540969849
Validation loss: 2.116238017876943

Epoch: 6| Step: 2
Training loss: 1.534616470336914
Validation loss: 2.1137945850690207

Epoch: 6| Step: 3
Training loss: 2.1588871479034424
Validation loss: 2.113402863343557

Epoch: 6| Step: 4
Training loss: 1.956188678741455
Validation loss: 2.111283262570699

Epoch: 6| Step: 5
Training loss: 2.186920642852783
Validation loss: 2.112817426522573

Epoch: 6| Step: 6
Training loss: 3.1413650512695312
Validation loss: 2.121864060560862

Epoch: 6| Step: 7
Training loss: 2.4282174110412598
Validation loss: 2.1275416016578674

Epoch: 6| Step: 8
Training loss: 2.4290146827697754
Validation loss: 2.113828639189402

Epoch: 6| Step: 9
Training loss: 2.7303450107574463
Validation loss: 2.115351696809133

Epoch: 6| Step: 10
Training loss: 2.406869411468506
Validation loss: 2.1042391260464988

Epoch: 6| Step: 11
Training loss: 2.6472465991973877
Validation loss: 2.105644861857096

Epoch: 6| Step: 12
Training loss: 2.030672073364258
Validation loss: 2.1088982423146567

Epoch: 6| Step: 13
Training loss: 1.8764420747756958
Validation loss: 2.1211502154668174

Epoch: 57| Step: 0
Training loss: 2.927191972732544
Validation loss: 2.1357600887616477

Epoch: 6| Step: 1
Training loss: 1.9245096445083618
Validation loss: 2.1348921855290732

Epoch: 6| Step: 2
Training loss: 2.1279749870300293
Validation loss: 2.135203003883362

Epoch: 6| Step: 3
Training loss: 2.2090234756469727
Validation loss: 2.1284389893213906

Epoch: 6| Step: 4
Training loss: 2.308837652206421
Validation loss: 2.118530253569285

Epoch: 6| Step: 5
Training loss: 2.4237356185913086
Validation loss: 2.1085851391156516

Epoch: 6| Step: 6
Training loss: 2.2114672660827637
Validation loss: 2.1037086645762124

Epoch: 6| Step: 7
Training loss: 2.430039644241333
Validation loss: 2.0980161229769387

Epoch: 6| Step: 8
Training loss: 2.0136094093322754
Validation loss: 2.0967713594436646

Epoch: 6| Step: 9
Training loss: 2.045698642730713
Validation loss: 2.0949084957440696

Epoch: 6| Step: 10
Training loss: 2.1387112140655518
Validation loss: 2.096453905105591

Epoch: 6| Step: 11
Training loss: 2.385186195373535
Validation loss: 2.0916693011919656

Epoch: 6| Step: 12
Training loss: 2.2018544673919678
Validation loss: 2.0878058274586997

Epoch: 6| Step: 13
Training loss: 2.7158517837524414
Validation loss: 2.086070636908213

Epoch: 58| Step: 0
Training loss: 1.8278133869171143
Validation loss: 2.089663485685984

Epoch: 6| Step: 1
Training loss: 1.5844448804855347
Validation loss: 2.091152826944987

Epoch: 6| Step: 2
Training loss: 1.8366711139678955
Validation loss: 2.0897080302238464

Epoch: 6| Step: 3
Training loss: 2.8118538856506348
Validation loss: 2.0858590404192605

Epoch: 6| Step: 4
Training loss: 1.5102052688598633
Validation loss: 2.0870710810025535

Epoch: 6| Step: 5
Training loss: 2.0637941360473633
Validation loss: 2.088062127431234

Epoch: 6| Step: 6
Training loss: 2.336638927459717
Validation loss: 2.0773982803026834

Epoch: 6| Step: 7
Training loss: 2.4671077728271484
Validation loss: 2.0862069924672446

Epoch: 6| Step: 8
Training loss: 2.8676295280456543
Validation loss: 2.0808709859848022

Epoch: 6| Step: 9
Training loss: 2.3093621730804443
Validation loss: 2.082813779513041

Epoch: 6| Step: 10
Training loss: 2.395427703857422
Validation loss: 2.080204725265503

Epoch: 6| Step: 11
Training loss: 2.1292428970336914
Validation loss: 2.0805567105611167

Epoch: 6| Step: 12
Training loss: 2.609999179840088
Validation loss: 2.0791794061660767

Epoch: 6| Step: 13
Training loss: 2.8418068885803223
Validation loss: 2.0774816473325095

Epoch: 59| Step: 0
Training loss: 2.751176118850708
Validation loss: 2.082598010698954

Epoch: 6| Step: 1
Training loss: 2.1330084800720215
Validation loss: 2.083461125691732

Epoch: 6| Step: 2
Training loss: 2.5314536094665527
Validation loss: 2.0747859676678977

Epoch: 6| Step: 3
Training loss: 2.5030481815338135
Validation loss: 2.078097720940908

Epoch: 6| Step: 4
Training loss: 1.8311550617218018
Validation loss: 2.0745341976483664

Epoch: 6| Step: 5
Training loss: 2.2608211040496826
Validation loss: 2.070338805516561

Epoch: 6| Step: 6
Training loss: 2.194878578186035
Validation loss: 2.0680649081865945

Epoch: 6| Step: 7
Training loss: 2.1335437297821045
Validation loss: 2.0560876727104187

Epoch: 6| Step: 8
Training loss: 1.9121921062469482
Validation loss: 2.0564573407173157

Epoch: 6| Step: 9
Training loss: 1.6722991466522217
Validation loss: 2.0653597513834634

Epoch: 6| Step: 10
Training loss: 2.5807409286499023
Validation loss: 2.0623996456464133

Epoch: 6| Step: 11
Training loss: 2.3493993282318115
Validation loss: 2.073380986849467

Epoch: 6| Step: 12
Training loss: 2.2109594345092773
Validation loss: 2.067106088002523

Epoch: 6| Step: 13
Training loss: 2.300389289855957
Validation loss: 2.058835029602051

Epoch: 60| Step: 0
Training loss: 1.7331386804580688
Validation loss: 2.0578074852625527

Epoch: 6| Step: 1
Training loss: 2.6965343952178955
Validation loss: 2.0558281342188516

Epoch: 6| Step: 2
Training loss: 2.450655937194824
Validation loss: 2.049567441145579

Epoch: 6| Step: 3
Training loss: 2.1196348667144775
Validation loss: 2.052167852719625

Epoch: 6| Step: 4
Training loss: 2.3397774696350098
Validation loss: 2.0455960035324097

Epoch: 6| Step: 5
Training loss: 1.9383152723312378
Validation loss: 2.048393448193868

Epoch: 6| Step: 6
Training loss: 2.5814239978790283
Validation loss: 2.0459324717521667

Epoch: 6| Step: 7
Training loss: 1.9886934757232666
Validation loss: 2.0526099602381387

Epoch: 6| Step: 8
Training loss: 2.028848886489868
Validation loss: 2.054031193256378

Epoch: 6| Step: 9
Training loss: 2.471863269805908
Validation loss: 2.0551225344340005

Epoch: 6| Step: 10
Training loss: 2.2396583557128906
Validation loss: 2.053836186726888

Epoch: 6| Step: 11
Training loss: 1.7924754619598389
Validation loss: 2.048958937327067

Epoch: 6| Step: 12
Training loss: 2.4297068119049072
Validation loss: 2.0483394265174866

Epoch: 6| Step: 13
Training loss: 2.417860507965088
Validation loss: 2.049073040485382

Epoch: 61| Step: 0
Training loss: 2.7703442573547363
Validation loss: 2.0461412270863852

Epoch: 6| Step: 1
Training loss: 2.584291696548462
Validation loss: 2.0457319219907126

Epoch: 6| Step: 2
Training loss: 1.6750640869140625
Validation loss: 2.050255755583445

Epoch: 6| Step: 3
Training loss: 2.124213695526123
Validation loss: 2.0461178620656333

Epoch: 6| Step: 4
Training loss: 2.413119316101074
Validation loss: 2.044805367787679

Epoch: 6| Step: 5
Training loss: 2.421903610229492
Validation loss: 2.046941260496775

Epoch: 6| Step: 6
Training loss: 2.002530097961426
Validation loss: 2.0438144405682883

Epoch: 6| Step: 7
Training loss: 2.739671230316162
Validation loss: 2.0451847910881042

Epoch: 6| Step: 8
Training loss: 1.793501615524292
Validation loss: 2.0451243122418723

Epoch: 6| Step: 9
Training loss: 2.376739501953125
Validation loss: 2.0410571297009787

Epoch: 6| Step: 10
Training loss: 1.6673014163970947
Validation loss: 2.0446274280548096

Epoch: 6| Step: 11
Training loss: 1.9097824096679688
Validation loss: 2.0383455952008567

Epoch: 6| Step: 12
Training loss: 2.0743093490600586
Validation loss: 2.0417957305908203

Epoch: 6| Step: 13
Training loss: 2.5579142570495605
Validation loss: 2.0428813894589744

Epoch: 62| Step: 0
Training loss: 1.9540684223175049
Validation loss: 2.04111909866333

Epoch: 6| Step: 1
Training loss: 2.58981990814209
Validation loss: 2.0463974277178445

Epoch: 6| Step: 2
Training loss: 2.1059324741363525
Validation loss: 2.0428786079088845

Epoch: 6| Step: 3
Training loss: 2.2703590393066406
Validation loss: 2.0488210916519165

Epoch: 6| Step: 4
Training loss: 2.2931532859802246
Validation loss: 2.0469412803649902

Epoch: 6| Step: 5
Training loss: 1.4721672534942627
Validation loss: 2.0461254715919495

Epoch: 6| Step: 6
Training loss: 2.700157403945923
Validation loss: 2.0554898977279663

Epoch: 6| Step: 7
Training loss: 2.0185365676879883
Validation loss: 2.0591450333595276

Epoch: 6| Step: 8
Training loss: 2.041567087173462
Validation loss: 2.0788244207700095

Epoch: 6| Step: 9
Training loss: 2.183288097381592
Validation loss: 2.0829469760258994

Epoch: 6| Step: 10
Training loss: 3.021195650100708
Validation loss: 2.089450458685557

Epoch: 6| Step: 11
Training loss: 2.311066150665283
Validation loss: 2.0794312755266824

Epoch: 6| Step: 12
Training loss: 2.3108623027801514
Validation loss: 2.0638986627260842

Epoch: 6| Step: 13
Training loss: 2.2018818855285645
Validation loss: 2.052549342314402

Epoch: 63| Step: 0
Training loss: 2.0564258098602295
Validation loss: 2.0377774834632874

Epoch: 6| Step: 1
Training loss: 2.7429280281066895
Validation loss: 2.045276621977488

Epoch: 6| Step: 2
Training loss: 2.848101854324341
Validation loss: 2.0543536146481833

Epoch: 6| Step: 3
Training loss: 1.9392781257629395
Validation loss: 2.0602281292279563

Epoch: 6| Step: 4
Training loss: 2.097774028778076
Validation loss: 2.060172696908315

Epoch: 6| Step: 5
Training loss: 2.641885280609131
Validation loss: 2.0647868315378823

Epoch: 6| Step: 6
Training loss: 1.8082987070083618
Validation loss: 2.0658695300420127

Epoch: 6| Step: 7
Training loss: 1.6550655364990234
Validation loss: 2.067553619543711

Epoch: 6| Step: 8
Training loss: 2.6674509048461914
Validation loss: 2.069106101989746

Epoch: 6| Step: 9
Training loss: 1.7773802280426025
Validation loss: 2.071144719918569

Epoch: 6| Step: 10
Training loss: 2.422687530517578
Validation loss: 2.0657270153363547

Epoch: 6| Step: 11
Training loss: 2.4104838371276855
Validation loss: 2.0669102668762207

Epoch: 6| Step: 12
Training loss: 2.313255786895752
Validation loss: 2.0700653791427612

Epoch: 6| Step: 13
Training loss: 1.9990406036376953
Validation loss: 2.0659453868865967

Epoch: 64| Step: 0
Training loss: 1.9748992919921875
Validation loss: 2.0597139994303384

Epoch: 6| Step: 1
Training loss: 1.992457628250122
Validation loss: 2.0574570894241333

Epoch: 6| Step: 2
Training loss: 2.477238178253174
Validation loss: 2.0510549743970237

Epoch: 6| Step: 3
Training loss: 2.1582958698272705
Validation loss: 2.052217404047648

Epoch: 6| Step: 4
Training loss: 2.9681215286254883
Validation loss: 2.047370751698812

Epoch: 6| Step: 5
Training loss: 2.2914538383483887
Validation loss: 2.0413488348325095

Epoch: 6| Step: 6
Training loss: 1.7085694074630737
Validation loss: 2.0414734482765198

Epoch: 6| Step: 7
Training loss: 2.438131809234619
Validation loss: 2.041223645210266

Epoch: 6| Step: 8
Training loss: 2.1559805870056152
Validation loss: 2.0329924623171487

Epoch: 6| Step: 9
Training loss: 2.3337931632995605
Validation loss: 2.0274051427841187

Epoch: 6| Step: 10
Training loss: 2.237238883972168
Validation loss: 2.024919331073761

Epoch: 6| Step: 11
Training loss: 2.602102756500244
Validation loss: 2.0330110987027488

Epoch: 6| Step: 12
Training loss: 2.296505928039551
Validation loss: 2.031635344028473

Epoch: 6| Step: 13
Training loss: 1.5284183025360107
Validation loss: 2.0249478816986084

Epoch: 65| Step: 0
Training loss: 2.07218337059021
Validation loss: 2.028228203455607

Epoch: 6| Step: 1
Training loss: 2.169112205505371
Validation loss: 2.0294971664746604

Epoch: 6| Step: 2
Training loss: 2.3707029819488525
Validation loss: 2.026136636734009

Epoch: 6| Step: 3
Training loss: 1.8882204294204712
Validation loss: 2.0258699456850686

Epoch: 6| Step: 4
Training loss: 1.3755639791488647
Validation loss: 2.019260128339132

Epoch: 6| Step: 5
Training loss: 2.7415058612823486
Validation loss: 2.0232194860776267

Epoch: 6| Step: 6
Training loss: 1.8111070394515991
Validation loss: 2.023501435915629

Epoch: 6| Step: 7
Training loss: 2.2715890407562256
Validation loss: 2.0301968852678933

Epoch: 6| Step: 8
Training loss: 2.492464065551758
Validation loss: 2.029976268609365

Epoch: 6| Step: 9
Training loss: 2.081953287124634
Validation loss: 2.030987004439036

Epoch: 6| Step: 10
Training loss: 2.702613592147827
Validation loss: 2.033344268798828

Epoch: 6| Step: 11
Training loss: 2.056671142578125
Validation loss: 2.0293328166007996

Epoch: 6| Step: 12
Training loss: 2.257357597351074
Validation loss: 2.0348355571428933

Epoch: 6| Step: 13
Training loss: 2.629030704498291
Validation loss: 2.0306517481803894

Epoch: 66| Step: 0
Training loss: 2.7000246047973633
Validation loss: 2.0276281436284385

Epoch: 6| Step: 1
Training loss: 1.3602967262268066
Validation loss: 2.035535752773285

Epoch: 6| Step: 2
Training loss: 2.5934903621673584
Validation loss: 2.0305753151575723

Epoch: 6| Step: 3
Training loss: 2.5309090614318848
Validation loss: 2.027443289756775

Epoch: 6| Step: 4
Training loss: 2.428584575653076
Validation loss: 2.0241243839263916

Epoch: 6| Step: 5
Training loss: 1.639050841331482
Validation loss: 2.0222065846125283

Epoch: 6| Step: 6
Training loss: 2.5606236457824707
Validation loss: 2.0199596087137857

Epoch: 6| Step: 7
Training loss: 2.1855697631835938
Validation loss: 2.020126382509867

Epoch: 6| Step: 8
Training loss: 2.267054796218872
Validation loss: 2.0173920392990112

Epoch: 6| Step: 9
Training loss: 2.3039650917053223
Validation loss: 2.023419717947642

Epoch: 6| Step: 10
Training loss: 2.3925304412841797
Validation loss: 2.024895409742991

Epoch: 6| Step: 11
Training loss: 2.4084267616271973
Validation loss: 2.0250728527704873

Epoch: 6| Step: 12
Training loss: 1.8962938785552979
Validation loss: 2.031945983568827

Epoch: 6| Step: 13
Training loss: 1.6406044960021973
Validation loss: 2.027577757835388

Epoch: 67| Step: 0
Training loss: 2.1356914043426514
Validation loss: 2.0217097798983255

Epoch: 6| Step: 1
Training loss: 1.731062650680542
Validation loss: 2.0235247214635215

Epoch: 6| Step: 2
Training loss: 2.238067865371704
Validation loss: 2.0272821187973022

Epoch: 6| Step: 3
Training loss: 2.546159505844116
Validation loss: 2.027248481909434

Epoch: 6| Step: 4
Training loss: 2.2255117893218994
Validation loss: 2.03265388806661

Epoch: 6| Step: 5
Training loss: 1.8610994815826416
Validation loss: 2.027164896329244

Epoch: 6| Step: 6
Training loss: 1.7715511322021484
Validation loss: 2.031375527381897

Epoch: 6| Step: 7
Training loss: 2.520369529724121
Validation loss: 2.0150511662165322

Epoch: 6| Step: 8
Training loss: 1.5828962326049805
Validation loss: 2.0131373206774392

Epoch: 6| Step: 9
Training loss: 2.8230559825897217
Validation loss: 2.0174361069997153

Epoch: 6| Step: 10
Training loss: 1.919173240661621
Validation loss: 2.0104521910349527

Epoch: 6| Step: 11
Training loss: 3.067455768585205
Validation loss: 2.0164055228233337

Epoch: 6| Step: 12
Training loss: 2.119734287261963
Validation loss: 2.011483351389567

Epoch: 6| Step: 13
Training loss: 2.1813533306121826
Validation loss: 2.0098214546839395

Epoch: 68| Step: 0
Training loss: 1.9557654857635498
Validation loss: 2.0172924598058066

Epoch: 6| Step: 1
Training loss: 2.1174395084381104
Validation loss: 2.010999083518982

Epoch: 6| Step: 2
Training loss: 1.8687649965286255
Validation loss: 2.016583780447642

Epoch: 6| Step: 3
Training loss: 1.7537962198257446
Validation loss: 2.0170947313308716

Epoch: 6| Step: 4
Training loss: 1.6304044723510742
Validation loss: 2.0150135358174643

Epoch: 6| Step: 5
Training loss: 2.7879722118377686
Validation loss: 2.013059119383494

Epoch: 6| Step: 6
Training loss: 2.3143632411956787
Validation loss: 2.014109512170156

Epoch: 6| Step: 7
Training loss: 2.0164451599121094
Validation loss: 2.0114497939745584

Epoch: 6| Step: 8
Training loss: 2.3079543113708496
Validation loss: 2.007856289545695

Epoch: 6| Step: 9
Training loss: 2.671365261077881
Validation loss: 2.0101305842399597

Epoch: 6| Step: 10
Training loss: 1.9877982139587402
Validation loss: 2.0061274568239846

Epoch: 6| Step: 11
Training loss: 2.304037570953369
Validation loss: 2.0089885195096335

Epoch: 6| Step: 12
Training loss: 2.370501756668091
Validation loss: 2.011103411515554

Epoch: 6| Step: 13
Training loss: 2.5252082347869873
Validation loss: 2.0096073746681213

Epoch: 69| Step: 0
Training loss: 2.118483066558838
Validation loss: 2.0076903303464255

Epoch: 6| Step: 1
Training loss: 2.5168166160583496
Validation loss: 2.011770745118459

Epoch: 6| Step: 2
Training loss: 2.267643451690674
Validation loss: 2.01008532444636

Epoch: 6| Step: 3
Training loss: 1.9062405824661255
Validation loss: 2.0118809739748635

Epoch: 6| Step: 4
Training loss: 1.418548822402954
Validation loss: 2.012947380542755

Epoch: 6| Step: 5
Training loss: 2.4543967247009277
Validation loss: 2.0169628858566284

Epoch: 6| Step: 6
Training loss: 2.182353973388672
Validation loss: 2.0175767143567405

Epoch: 6| Step: 7
Training loss: 2.244645595550537
Validation loss: 2.0201257268587747

Epoch: 6| Step: 8
Training loss: 2.023043155670166
Validation loss: 2.026117185751597

Epoch: 6| Step: 9
Training loss: 2.240898847579956
Validation loss: 2.0229477882385254

Epoch: 6| Step: 10
Training loss: 2.4934778213500977
Validation loss: 2.0231116016705832

Epoch: 6| Step: 11
Training loss: 1.9773023128509521
Validation loss: 2.0200204451878867

Epoch: 6| Step: 12
Training loss: 2.2047321796417236
Validation loss: 2.0219673315684

Epoch: 6| Step: 13
Training loss: 2.4052557945251465
Validation loss: 2.017707328001658

Epoch: 70| Step: 0
Training loss: 2.1203646659851074
Validation loss: 2.016687492529551

Epoch: 6| Step: 1
Training loss: 1.6907581090927124
Validation loss: 2.023334880669912

Epoch: 6| Step: 2
Training loss: 2.1850132942199707
Validation loss: 2.019863406817118

Epoch: 6| Step: 3
Training loss: 1.9128639698028564
Validation loss: 2.0163976152737937

Epoch: 6| Step: 4
Training loss: 1.8672089576721191
Validation loss: 2.0155380964279175

Epoch: 6| Step: 5
Training loss: 1.7540544271469116
Validation loss: 2.0101508696873984

Epoch: 6| Step: 6
Training loss: 2.3723745346069336
Validation loss: 2.012921690940857

Epoch: 6| Step: 7
Training loss: 2.4047694206237793
Validation loss: 2.01166961590449

Epoch: 6| Step: 8
Training loss: 1.9604343175888062
Validation loss: 2.0173978408177695

Epoch: 6| Step: 9
Training loss: 2.387996196746826
Validation loss: 2.0164490342140198

Epoch: 6| Step: 10
Training loss: 2.7641477584838867
Validation loss: 2.02242104212443

Epoch: 6| Step: 11
Training loss: 1.9915156364440918
Validation loss: 2.0125348567962646

Epoch: 6| Step: 12
Training loss: 2.2932398319244385
Validation loss: 2.0129700303077698

Epoch: 6| Step: 13
Training loss: 2.742215871810913
Validation loss: 2.0096237460772195

Epoch: 71| Step: 0
Training loss: 1.6037473678588867
Validation loss: 2.008867084980011

Epoch: 6| Step: 1
Training loss: 2.5160839557647705
Validation loss: 2.0186526775360107

Epoch: 6| Step: 2
Training loss: 2.0320961475372314
Validation loss: 2.020413319269816

Epoch: 6| Step: 3
Training loss: 2.517347812652588
Validation loss: 2.029057423273722

Epoch: 6| Step: 4
Training loss: 2.300246477127075
Validation loss: 2.0292062958081565

Epoch: 6| Step: 5
Training loss: 1.8788715600967407
Validation loss: 2.044394334157308

Epoch: 6| Step: 6
Training loss: 1.8813406229019165
Validation loss: 2.049856185913086

Epoch: 6| Step: 7
Training loss: 1.9375683069229126
Validation loss: 2.069064716498057

Epoch: 6| Step: 8
Training loss: 2.715639591217041
Validation loss: 2.092645049095154

Epoch: 6| Step: 9
Training loss: 2.5395994186401367
Validation loss: 2.0795969565709433

Epoch: 6| Step: 10
Training loss: 2.050264358520508
Validation loss: 2.0623296101888022

Epoch: 6| Step: 11
Training loss: 2.610030174255371
Validation loss: 2.0444984833399453

Epoch: 6| Step: 12
Training loss: 1.9619715213775635
Validation loss: 2.0305758913358054

Epoch: 6| Step: 13
Training loss: 2.631633996963501
Validation loss: 2.0173136393229165

Epoch: 72| Step: 0
Training loss: 1.5600125789642334
Validation loss: 2.008688827355703

Epoch: 6| Step: 1
Training loss: 2.6257081031799316
Validation loss: 2.007989823818207

Epoch: 6| Step: 2
Training loss: 2.1816353797912598
Validation loss: 2.0075719952583313

Epoch: 6| Step: 3
Training loss: 1.8091709613800049
Validation loss: 2.0087037682533264

Epoch: 6| Step: 4
Training loss: 2.6606032848358154
Validation loss: 2.012198587258657

Epoch: 6| Step: 5
Training loss: 2.2771356105804443
Validation loss: 2.015316446622213

Epoch: 6| Step: 6
Training loss: 2.386894702911377
Validation loss: 2.0146469473838806

Epoch: 6| Step: 7
Training loss: 1.9880847930908203
Validation loss: 2.0166584650675454

Epoch: 6| Step: 8
Training loss: 1.6983468532562256
Validation loss: 2.005098740259806

Epoch: 6| Step: 9
Training loss: 2.185391902923584
Validation loss: 2.001031776269277

Epoch: 6| Step: 10
Training loss: 2.1076407432556152
Validation loss: 2.0133073925971985

Epoch: 6| Step: 11
Training loss: 2.106673240661621
Validation loss: 2.005997121334076

Epoch: 6| Step: 12
Training loss: 2.447129249572754
Validation loss: 2.0121531883875527

Epoch: 6| Step: 13
Training loss: 2.4118423461914062
Validation loss: 2.007915476957957

Epoch: 73| Step: 0
Training loss: 1.745889663696289
Validation loss: 2.0053279598553977

Epoch: 6| Step: 1
Training loss: 1.7806715965270996
Validation loss: 2.0122764507929483

Epoch: 6| Step: 2
Training loss: 1.9959138631820679
Validation loss: 2.0048250555992126

Epoch: 6| Step: 3
Training loss: 2.085873603820801
Validation loss: 2.013556698958079

Epoch: 6| Step: 4
Training loss: 2.0391178131103516
Validation loss: 2.022806088129679

Epoch: 6| Step: 5
Training loss: 2.9899802207946777
Validation loss: 2.026913066705068

Epoch: 6| Step: 6
Training loss: 2.5168509483337402
Validation loss: 2.0187408129374185

Epoch: 6| Step: 7
Training loss: 1.7576401233673096
Validation loss: 2.0182193517684937

Epoch: 6| Step: 8
Training loss: 1.9988360404968262
Validation loss: 2.0180479288101196

Epoch: 6| Step: 9
Training loss: 1.9872479438781738
Validation loss: 2.0180437564849854

Epoch: 6| Step: 10
Training loss: 1.9889192581176758
Validation loss: 2.023223400115967

Epoch: 6| Step: 11
Training loss: 2.7455101013183594
Validation loss: 2.0170615315437317

Epoch: 6| Step: 12
Training loss: 2.6833558082580566
Validation loss: 2.020444671312968

Epoch: 6| Step: 13
Training loss: 2.034458875656128
Validation loss: 2.0148648023605347

Epoch: 74| Step: 0
Training loss: 1.6537789106369019
Validation loss: 2.01423313220342

Epoch: 6| Step: 1
Training loss: 2.6067161560058594
Validation loss: 2.0175838470458984

Epoch: 6| Step: 2
Training loss: 2.5643038749694824
Validation loss: 2.0110773841540017

Epoch: 6| Step: 3
Training loss: 2.382281541824341
Validation loss: 2.0091507037480674

Epoch: 6| Step: 4
Training loss: 1.586506724357605
Validation loss: 2.0194914738337197

Epoch: 6| Step: 5
Training loss: 1.7007532119750977
Validation loss: 2.014365017414093

Epoch: 6| Step: 6
Training loss: 2.7833633422851562
Validation loss: 2.023960073788961

Epoch: 6| Step: 7
Training loss: 1.5953516960144043
Validation loss: 2.018036941687266

Epoch: 6| Step: 8
Training loss: 1.830032467842102
Validation loss: 2.0165878335634866

Epoch: 6| Step: 9
Training loss: 1.6863199472427368
Validation loss: 2.0138854384422302

Epoch: 6| Step: 10
Training loss: 2.7646939754486084
Validation loss: 2.022851268450419

Epoch: 6| Step: 11
Training loss: 2.0268542766571045
Validation loss: 2.021773417790731

Epoch: 6| Step: 12
Training loss: 2.814816951751709
Validation loss: 2.0209118723869324

Epoch: 6| Step: 13
Training loss: 2.3736252784729004
Validation loss: 2.011829197406769

Epoch: 75| Step: 0
Training loss: 2.200610399246216
Validation loss: 2.024301747481028

Epoch: 6| Step: 1
Training loss: 2.5723233222961426
Validation loss: 2.0192234913508096

Epoch: 6| Step: 2
Training loss: 1.7670867443084717
Validation loss: 2.0218011935551963

Epoch: 6| Step: 3
Training loss: 1.9038975238800049
Validation loss: 2.0120074351628623

Epoch: 6| Step: 4
Training loss: 2.1432900428771973
Validation loss: 2.0134268403053284

Epoch: 6| Step: 5
Training loss: 2.406257152557373
Validation loss: 2.0105586647987366

Epoch: 6| Step: 6
Training loss: 2.2126553058624268
Validation loss: 2.0140109260876975

Epoch: 6| Step: 7
Training loss: 2.5162386894226074
Validation loss: 2.016325831413269

Epoch: 6| Step: 8
Training loss: 2.594499111175537
Validation loss: 2.0149484872817993

Epoch: 6| Step: 9
Training loss: 2.81428861618042
Validation loss: 2.015213906764984

Epoch: 6| Step: 10
Training loss: 1.7805347442626953
Validation loss: 2.015951613585154

Epoch: 6| Step: 11
Training loss: 1.6486082077026367
Validation loss: 2.013062755266825

Epoch: 6| Step: 12
Training loss: 1.2497811317443848
Validation loss: 2.008626937866211

Epoch: 6| Step: 13
Training loss: 2.4639058113098145
Validation loss: 2.0098386804262796

Epoch: 76| Step: 0
Training loss: 2.7123007774353027
Validation loss: 2.0090999205907187

Epoch: 6| Step: 1
Training loss: 2.039566993713379
Validation loss: 2.0085914731025696

Epoch: 6| Step: 2
Training loss: 1.8213227987289429
Validation loss: 2.01372496287028

Epoch: 6| Step: 3
Training loss: 2.18792462348938
Validation loss: 2.007942775885264

Epoch: 6| Step: 4
Training loss: 2.100804090499878
Validation loss: 2.01695183912913

Epoch: 6| Step: 5
Training loss: 2.456390142440796
Validation loss: 2.009476681550344

Epoch: 6| Step: 6
Training loss: 1.9372225999832153
Validation loss: 2.011299212773641

Epoch: 6| Step: 7
Training loss: 2.0750162601470947
Validation loss: 2.007323125998179

Epoch: 6| Step: 8
Training loss: 2.0677664279937744
Validation loss: 2.013910710811615

Epoch: 6| Step: 9
Training loss: 2.547551155090332
Validation loss: 2.0112988154093423

Epoch: 6| Step: 10
Training loss: 1.6881861686706543
Validation loss: 2.018070419629415

Epoch: 6| Step: 11
Training loss: 1.7195777893066406
Validation loss: 2.011144280433655

Epoch: 6| Step: 12
Training loss: 2.7939295768737793
Validation loss: 2.009601354598999

Epoch: 6| Step: 13
Training loss: 2.0701687335968018
Validation loss: 2.016512672106425

Epoch: 77| Step: 0
Training loss: 2.1103978157043457
Validation loss: 2.0176250338554382

Epoch: 6| Step: 1
Training loss: 2.1203603744506836
Validation loss: 2.02451761563619

Epoch: 6| Step: 2
Training loss: 1.8440566062927246
Validation loss: 2.022250533103943

Epoch: 6| Step: 3
Training loss: 2.3127710819244385
Validation loss: 2.027549425760905

Epoch: 6| Step: 4
Training loss: 1.808215856552124
Validation loss: 2.013041059176127

Epoch: 6| Step: 5
Training loss: 2.3510255813598633
Validation loss: 2.015679200490316

Epoch: 6| Step: 6
Training loss: 2.3221259117126465
Validation loss: 2.022928237915039

Epoch: 6| Step: 7
Training loss: 1.9332425594329834
Validation loss: 2.017689267794291

Epoch: 6| Step: 8
Training loss: 1.755203366279602
Validation loss: 2.017109533150991

Epoch: 6| Step: 9
Training loss: 1.7141714096069336
Validation loss: 2.01785139242808

Epoch: 6| Step: 10
Training loss: 2.589430332183838
Validation loss: 2.0101433595021567

Epoch: 6| Step: 11
Training loss: 2.3811419010162354
Validation loss: 2.019939382870992

Epoch: 6| Step: 12
Training loss: 2.4589710235595703
Validation loss: 2.0320915381113687

Epoch: 6| Step: 13
Training loss: 2.5669422149658203
Validation loss: 2.0328551729520163

Epoch: 78| Step: 0
Training loss: 1.736842393875122
Validation loss: 2.029590984185537

Epoch: 6| Step: 1
Training loss: 1.4678840637207031
Validation loss: 2.0227598349253335

Epoch: 6| Step: 2
Training loss: 2.6862943172454834
Validation loss: 2.0220847527186074

Epoch: 6| Step: 3
Training loss: 2.0031533241271973
Validation loss: 2.0174335837364197

Epoch: 6| Step: 4
Training loss: 2.133612632751465
Validation loss: 2.0158260067303977

Epoch: 6| Step: 5
Training loss: 2.0330419540405273
Validation loss: 2.0097137689590454

Epoch: 6| Step: 6
Training loss: 1.765353798866272
Validation loss: 2.0096263885498047

Epoch: 6| Step: 7
Training loss: 2.776583194732666
Validation loss: 2.0100998679796853

Epoch: 6| Step: 8
Training loss: 2.6403775215148926
Validation loss: 2.016017178694407

Epoch: 6| Step: 9
Training loss: 2.2035412788391113
Validation loss: 2.016127367814382

Epoch: 6| Step: 10
Training loss: 1.794127345085144
Validation loss: 2.0229422648747764

Epoch: 6| Step: 11
Training loss: 2.4806690216064453
Validation loss: 2.0115651885668435

Epoch: 6| Step: 12
Training loss: 2.5157461166381836
Validation loss: 2.0194892485936484

Epoch: 6| Step: 13
Training loss: 2.162705183029175
Validation loss: 2.0181525349617004

Epoch: 79| Step: 0
Training loss: 2.138164520263672
Validation loss: 2.0224324464797974

Epoch: 6| Step: 1
Training loss: 2.2803521156311035
Validation loss: 2.0197655161221824

Epoch: 6| Step: 2
Training loss: 2.595524311065674
Validation loss: 2.020225207010905

Epoch: 6| Step: 3
Training loss: 2.317932605743408
Validation loss: 2.015645901362101

Epoch: 6| Step: 4
Training loss: 1.7554296255111694
Validation loss: 2.0164382259051004

Epoch: 6| Step: 5
Training loss: 1.8457188606262207
Validation loss: 2.022420883178711

Epoch: 6| Step: 6
Training loss: 2.3328936100006104
Validation loss: 2.0251020789146423

Epoch: 6| Step: 7
Training loss: 2.3512916564941406
Validation loss: 2.018257280190786

Epoch: 6| Step: 8
Training loss: 1.8554610013961792
Validation loss: 2.0185561974843345

Epoch: 6| Step: 9
Training loss: 2.2525548934936523
Validation loss: 2.0108875830968223

Epoch: 6| Step: 10
Training loss: 1.8049633502960205
Validation loss: 2.0111252069473267

Epoch: 6| Step: 11
Training loss: 2.078751564025879
Validation loss: 2.006651004155477

Epoch: 6| Step: 12
Training loss: 2.061577081680298
Validation loss: 2.0020304123560586

Epoch: 6| Step: 13
Training loss: 2.5053086280822754
Validation loss: 2.003892958164215

Epoch: 80| Step: 0
Training loss: 2.336871385574341
Validation loss: 1.9994492530822754

Epoch: 6| Step: 1
Training loss: 2.1700637340545654
Validation loss: 2.011229952176412

Epoch: 6| Step: 2
Training loss: 2.0001277923583984
Validation loss: 2.0152719815572104

Epoch: 6| Step: 3
Training loss: 2.4064924716949463
Validation loss: 2.0143874684969583

Epoch: 6| Step: 4
Training loss: 2.0177974700927734
Validation loss: 2.0092727541923523

Epoch: 6| Step: 5
Training loss: 2.4033772945404053
Validation loss: 2.013212740421295

Epoch: 6| Step: 6
Training loss: 2.222782611846924
Validation loss: 2.0055963595708213

Epoch: 6| Step: 7
Training loss: 1.9668315649032593
Validation loss: 2.0017122824986777

Epoch: 6| Step: 8
Training loss: 2.3012685775756836
Validation loss: 2.000289718310038

Epoch: 6| Step: 9
Training loss: 2.5210981369018555
Validation loss: 2.006850262482961

Epoch: 6| Step: 10
Training loss: 1.575695276260376
Validation loss: 2.0113594134648642

Epoch: 6| Step: 11
Training loss: 1.9456418752670288
Validation loss: 2.0142491459846497

Epoch: 6| Step: 12
Training loss: 2.0828282833099365
Validation loss: 2.008825163046519

Epoch: 6| Step: 13
Training loss: 2.191779136657715
Validation loss: 2.0087817112604776

Epoch: 81| Step: 0
Training loss: 1.5119116306304932
Validation loss: 2.011144498984019

Epoch: 6| Step: 1
Training loss: 1.8404169082641602
Validation loss: 2.012675404548645

Epoch: 6| Step: 2
Training loss: 1.8700575828552246
Validation loss: 2.0117196639378867

Epoch: 6| Step: 3
Training loss: 2.1839704513549805
Validation loss: 2.0199154019355774

Epoch: 6| Step: 4
Training loss: 2.6942813396453857
Validation loss: 2.022641936937968

Epoch: 6| Step: 5
Training loss: 2.483391761779785
Validation loss: 2.031186044216156

Epoch: 6| Step: 6
Training loss: 1.8721024990081787
Validation loss: 2.030632813771566

Epoch: 6| Step: 7
Training loss: 1.8917124271392822
Validation loss: 2.0331459045410156

Epoch: 6| Step: 8
Training loss: 2.4887712001800537
Validation loss: 2.035208761692047

Epoch: 6| Step: 9
Training loss: 2.3545641899108887
Validation loss: 2.01374622186025

Epoch: 6| Step: 10
Training loss: 1.9603445529937744
Validation loss: 2.005760669708252

Epoch: 6| Step: 11
Training loss: 2.5515248775482178
Validation loss: 1.9984615246454875

Epoch: 6| Step: 12
Training loss: 2.276277780532837
Validation loss: 2.008303085962931

Epoch: 6| Step: 13
Training loss: 2.3588385581970215
Validation loss: 2.011357148488363

Epoch: 82| Step: 0
Training loss: 1.9471756219863892
Validation loss: 2.015536884466807

Epoch: 6| Step: 1
Training loss: 2.2656450271606445
Validation loss: 2.0186120669047036

Epoch: 6| Step: 2
Training loss: 2.0738983154296875
Validation loss: 2.010890563329061

Epoch: 6| Step: 3
Training loss: 1.8693037033081055
Validation loss: 2.0169051686922708

Epoch: 6| Step: 4
Training loss: 2.4934325218200684
Validation loss: 2.013074000676473

Epoch: 6| Step: 5
Training loss: 2.2296526432037354
Validation loss: 2.012765328089396

Epoch: 6| Step: 6
Training loss: 1.9826381206512451
Validation loss: 2.010698656241099

Epoch: 6| Step: 7
Training loss: 2.2551217079162598
Validation loss: 2.00948174794515

Epoch: 6| Step: 8
Training loss: 2.537956714630127
Validation loss: 2.0089786052703857

Epoch: 6| Step: 9
Training loss: 1.8673505783081055
Validation loss: 2.0099313259124756

Epoch: 6| Step: 10
Training loss: 2.2396328449249268
Validation loss: 2.0080155531565347

Epoch: 6| Step: 11
Training loss: 2.623936414718628
Validation loss: 2.0084637999534607

Epoch: 6| Step: 12
Training loss: 2.293065309524536
Validation loss: 2.001937905947367

Epoch: 6| Step: 13
Training loss: 1.612507700920105
Validation loss: 2.0001728534698486

Epoch: 83| Step: 0
Training loss: 2.3435964584350586
Validation loss: 2.003740886847178

Epoch: 6| Step: 1
Training loss: 2.5842738151550293
Validation loss: 2.0153807202974954

Epoch: 6| Step: 2
Training loss: 2.381049871444702
Validation loss: 2.0177390575408936

Epoch: 6| Step: 3
Training loss: 2.16532564163208
Validation loss: 2.0195701320966086

Epoch: 6| Step: 4
Training loss: 2.10231614112854
Validation loss: 2.0233535766601562

Epoch: 6| Step: 5
Training loss: 2.9617645740509033
Validation loss: 2.026461879412333

Epoch: 6| Step: 6
Training loss: 1.5084749460220337
Validation loss: 2.027349670728048

Epoch: 6| Step: 7
Training loss: 1.994112253189087
Validation loss: 2.0379751324653625

Epoch: 6| Step: 8
Training loss: 1.9734818935394287
Validation loss: 2.0287533601125083

Epoch: 6| Step: 9
Training loss: 1.6599397659301758
Validation loss: 2.028565526008606

Epoch: 6| Step: 10
Training loss: 2.764500141143799
Validation loss: 2.030656894048055

Epoch: 6| Step: 11
Training loss: 1.6041839122772217
Validation loss: 2.0248640974362693

Epoch: 6| Step: 12
Training loss: 1.7035605907440186
Validation loss: 2.022026777267456

Epoch: 6| Step: 13
Training loss: 2.4228909015655518
Validation loss: 2.0183451573053994

Epoch: 84| Step: 0
Training loss: 2.1464052200317383
Validation loss: 2.026778221130371

Epoch: 6| Step: 1
Training loss: 2.1408395767211914
Validation loss: 2.0201741456985474

Epoch: 6| Step: 2
Training loss: 1.8058714866638184
Validation loss: 2.011195639769236

Epoch: 6| Step: 3
Training loss: 2.062246799468994
Validation loss: 2.0100749333699546

Epoch: 6| Step: 4
Training loss: 2.069084644317627
Validation loss: 2.0053656101226807

Epoch: 6| Step: 5
Training loss: 2.3728504180908203
Validation loss: 2.0063266356786094

Epoch: 6| Step: 6
Training loss: 2.425053596496582
Validation loss: 2.0077764789263406

Epoch: 6| Step: 7
Training loss: 2.8195595741271973
Validation loss: 2.0135366916656494

Epoch: 6| Step: 8
Training loss: 1.7067008018493652
Validation loss: 2.0152730345726013

Epoch: 6| Step: 9
Training loss: 1.9023438692092896
Validation loss: 2.0088509917259216

Epoch: 6| Step: 10
Training loss: 2.421476364135742
Validation loss: 2.00630791982015

Epoch: 6| Step: 11
Training loss: 1.8325424194335938
Validation loss: 2.0071593523025513

Epoch: 6| Step: 12
Training loss: 2.6276559829711914
Validation loss: 2.0019198060035706

Epoch: 6| Step: 13
Training loss: 1.8110783100128174
Validation loss: 2.009394109249115

Epoch: 85| Step: 0
Training loss: 2.313976287841797
Validation loss: 2.011719763278961

Epoch: 6| Step: 1
Training loss: 1.9588632583618164
Validation loss: 2.012265423933665

Epoch: 6| Step: 2
Training loss: 1.9814273118972778
Validation loss: 2.0221391916275024

Epoch: 6| Step: 3
Training loss: 2.5995564460754395
Validation loss: 2.0319082140922546

Epoch: 6| Step: 4
Training loss: 2.154977798461914
Validation loss: 2.0338021715482077

Epoch: 6| Step: 5
Training loss: 2.228520154953003
Validation loss: 2.039395809173584

Epoch: 6| Step: 6
Training loss: 2.476912498474121
Validation loss: 2.0384355982144675

Epoch: 6| Step: 7
Training loss: 1.849158763885498
Validation loss: 2.0516093174616494

Epoch: 6| Step: 8
Training loss: 2.4253575801849365
Validation loss: 2.059045116106669

Epoch: 6| Step: 9
Training loss: 2.224055051803589
Validation loss: 2.0423917969067893

Epoch: 6| Step: 10
Training loss: 2.1805169582366943
Validation loss: 2.0427323381106057

Epoch: 6| Step: 11
Training loss: 1.8874322175979614
Validation loss: 2.0305159290631614

Epoch: 6| Step: 12
Training loss: 2.1225528717041016
Validation loss: 2.0146005153656006

Epoch: 6| Step: 13
Training loss: 1.9976005554199219
Validation loss: 2.004569113254547

Epoch: 86| Step: 0
Training loss: 1.6394460201263428
Validation loss: 2.004062275091807

Epoch: 6| Step: 1
Training loss: 2.137817859649658
Validation loss: 2.00557009379069

Epoch: 6| Step: 2
Training loss: 2.4742469787597656
Validation loss: 2.008853634198507

Epoch: 6| Step: 3
Training loss: 2.406498432159424
Validation loss: 2.0187363624572754

Epoch: 6| Step: 4
Training loss: 2.2876362800598145
Validation loss: 2.0064011017481485

Epoch: 6| Step: 5
Training loss: 2.0324223041534424
Validation loss: 2.0164140860239663

Epoch: 6| Step: 6
Training loss: 2.5277533531188965
Validation loss: 2.012705445289612

Epoch: 6| Step: 7
Training loss: 1.8728716373443604
Validation loss: 2.0110841194788613

Epoch: 6| Step: 8
Training loss: 2.0716471672058105
Validation loss: 2.0086185733477273

Epoch: 6| Step: 9
Training loss: 2.293477773666382
Validation loss: 2.011106252670288

Epoch: 6| Step: 10
Training loss: 2.42478609085083
Validation loss: 2.008742610613505

Epoch: 6| Step: 11
Training loss: 2.252636432647705
Validation loss: 2.005615750948588

Epoch: 6| Step: 12
Training loss: 2.074397563934326
Validation loss: 2.008832335472107

Epoch: 6| Step: 13
Training loss: 1.7676342725753784
Validation loss: 2.000537017981211

Epoch: 87| Step: 0
Training loss: 2.1588969230651855
Validation loss: 2.0052123069763184

Epoch: 6| Step: 1
Training loss: 2.0729329586029053
Validation loss: 2.0004512866338096

Epoch: 6| Step: 2
Training loss: 2.418855667114258
Validation loss: 2.006834695736567

Epoch: 6| Step: 3
Training loss: 2.5459890365600586
Validation loss: 2.002123475074768

Epoch: 6| Step: 4
Training loss: 1.1670494079589844
Validation loss: 2.0154563585917153

Epoch: 6| Step: 5
Training loss: 1.815285563468933
Validation loss: 2.0163253347078958

Epoch: 6| Step: 6
Training loss: 2.406090259552002
Validation loss: 2.015023628870646

Epoch: 6| Step: 7
Training loss: 2.4384255409240723
Validation loss: 2.0182852546374

Epoch: 6| Step: 8
Training loss: 2.1197190284729004
Validation loss: 2.0251455505688987

Epoch: 6| Step: 9
Training loss: 1.669097900390625
Validation loss: 2.0353563825289407

Epoch: 6| Step: 10
Training loss: 2.5744223594665527
Validation loss: 2.025955398877462

Epoch: 6| Step: 11
Training loss: 1.7139008045196533
Validation loss: 2.027783234914144

Epoch: 6| Step: 12
Training loss: 2.2116241455078125
Validation loss: 2.026746948560079

Epoch: 6| Step: 13
Training loss: 2.710639476776123
Validation loss: 2.0382321874300637

Epoch: 88| Step: 0
Training loss: 2.4150142669677734
Validation loss: 2.030263046423594

Epoch: 6| Step: 1
Training loss: 2.3524820804595947
Validation loss: 2.015816072622935

Epoch: 6| Step: 2
Training loss: 2.264293670654297
Validation loss: 2.0158738692601523

Epoch: 6| Step: 3
Training loss: 2.217339038848877
Validation loss: 2.0027294556299844

Epoch: 6| Step: 4
Training loss: 1.887073040008545
Validation loss: 2.006782909234365

Epoch: 6| Step: 5
Training loss: 2.7831344604492188
Validation loss: 2.0028425455093384

Epoch: 6| Step: 6
Training loss: 2.0534114837646484
Validation loss: 2.0046376983324685

Epoch: 6| Step: 7
Training loss: 1.526322603225708
Validation loss: 2.0068556865056357

Epoch: 6| Step: 8
Training loss: 2.388052225112915
Validation loss: 2.0057889421780906

Epoch: 6| Step: 9
Training loss: 2.1751580238342285
Validation loss: 2.00578244527181

Epoch: 6| Step: 10
Training loss: 2.2796926498413086
Validation loss: 2.005061089992523

Epoch: 6| Step: 11
Training loss: 1.8919110298156738
Validation loss: 2.0045149326324463

Epoch: 6| Step: 12
Training loss: 2.472090482711792
Validation loss: 1.9974563519159954

Epoch: 6| Step: 13
Training loss: 1.50054931640625
Validation loss: 2.0039653976758323

Epoch: 89| Step: 0
Training loss: 1.4761390686035156
Validation loss: 2.009161730607351

Epoch: 6| Step: 1
Training loss: 2.139821767807007
Validation loss: 2.015365739663442

Epoch: 6| Step: 2
Training loss: 2.412259101867676
Validation loss: 2.0249759753545127

Epoch: 6| Step: 3
Training loss: 1.5088858604431152
Validation loss: 2.0308621724446616

Epoch: 6| Step: 4
Training loss: 2.954333782196045
Validation loss: 2.0323747396469116

Epoch: 6| Step: 5
Training loss: 2.1908140182495117
Validation loss: 2.0264341235160828

Epoch: 6| Step: 6
Training loss: 2.498945474624634
Validation loss: 2.0305123925209045

Epoch: 6| Step: 7
Training loss: 1.6563129425048828
Validation loss: 2.0298451582590737

Epoch: 6| Step: 8
Training loss: 2.375981330871582
Validation loss: 2.025500992933909

Epoch: 6| Step: 9
Training loss: 2.2281787395477295
Validation loss: 2.0262081027030945

Epoch: 6| Step: 10
Training loss: 1.4927232265472412
Validation loss: 2.016817847887675

Epoch: 6| Step: 11
Training loss: 1.636397361755371
Validation loss: 2.023200730482737

Epoch: 6| Step: 12
Training loss: 2.9588005542755127
Validation loss: 2.0180722077687583

Epoch: 6| Step: 13
Training loss: 2.415651798248291
Validation loss: 2.01812607049942

Epoch: 90| Step: 0
Training loss: 2.34610652923584
Validation loss: 2.0066721041997275

Epoch: 6| Step: 1
Training loss: 1.905869960784912
Validation loss: 2.0059956113497415

Epoch: 6| Step: 2
Training loss: 1.9138405323028564
Validation loss: 2.0041489799817405

Epoch: 6| Step: 3
Training loss: 1.5523321628570557
Validation loss: 2.006220519542694

Epoch: 6| Step: 4
Training loss: 2.8412277698516846
Validation loss: 2.0098712841669717

Epoch: 6| Step: 5
Training loss: 1.973259449005127
Validation loss: 2.009569307168325

Epoch: 6| Step: 6
Training loss: 2.61419677734375
Validation loss: 2.004336675008138

Epoch: 6| Step: 7
Training loss: 2.150621175765991
Validation loss: 2.0072127183278403

Epoch: 6| Step: 8
Training loss: 2.4779551029205322
Validation loss: 2.0053316950798035

Epoch: 6| Step: 9
Training loss: 1.924199104309082
Validation loss: 2.0140750209490457

Epoch: 6| Step: 10
Training loss: 1.9608547687530518
Validation loss: 2.0164400537808738

Epoch: 6| Step: 11
Training loss: 2.3136391639709473
Validation loss: 2.0208688378334045

Epoch: 6| Step: 12
Training loss: 2.4627037048339844
Validation loss: 2.019628345966339

Epoch: 6| Step: 13
Training loss: 1.5550438165664673
Validation loss: 2.0192519426345825

Epoch: 91| Step: 0
Training loss: 2.208019971847534
Validation loss: 2.029661456743876

Epoch: 6| Step: 1
Training loss: 2.303410053253174
Validation loss: 2.032309671243032

Epoch: 6| Step: 2
Training loss: 1.6000573635101318
Validation loss: 2.04095866282781

Epoch: 6| Step: 3
Training loss: 2.3054633140563965
Validation loss: 2.020151118437449

Epoch: 6| Step: 4
Training loss: 2.291717052459717
Validation loss: 2.033282001813253

Epoch: 6| Step: 5
Training loss: 1.982246994972229
Validation loss: 2.0279018878936768

Epoch: 6| Step: 6
Training loss: 2.239990234375
Validation loss: 2.0224237044652305

Epoch: 6| Step: 7
Training loss: 1.6207941770553589
Validation loss: 2.032530983289083

Epoch: 6| Step: 8
Training loss: 2.3928451538085938
Validation loss: 2.0357847015062966

Epoch: 6| Step: 9
Training loss: 2.309917688369751
Validation loss: 2.0276050567626953

Epoch: 6| Step: 10
Training loss: 1.9829323291778564
Validation loss: 2.023737887541453

Epoch: 6| Step: 11
Training loss: 2.3639414310455322
Validation loss: 2.028213858604431

Epoch: 6| Step: 12
Training loss: 2.1476759910583496
Validation loss: 2.0230974555015564

Epoch: 6| Step: 13
Training loss: 2.13126540184021
Validation loss: 2.0255342721939087

Epoch: 92| Step: 0
Training loss: 2.246062994003296
Validation loss: 2.011757512887319

Epoch: 6| Step: 1
Training loss: 2.3016648292541504
Validation loss: 2.018819888432821

Epoch: 6| Step: 2
Training loss: 2.1321301460266113
Validation loss: 2.010612726211548

Epoch: 6| Step: 3
Training loss: 2.3978710174560547
Validation loss: 2.016359567642212

Epoch: 6| Step: 4
Training loss: 1.7718498706817627
Validation loss: 2.0118729869524636

Epoch: 6| Step: 5
Training loss: 2.2714548110961914
Validation loss: 2.0082505146662393

Epoch: 6| Step: 6
Training loss: 2.4839048385620117
Validation loss: 2.0147341887156167

Epoch: 6| Step: 7
Training loss: 2.5266048908233643
Validation loss: 2.023742437362671

Epoch: 6| Step: 8
Training loss: 1.7456310987472534
Validation loss: 2.015889346599579

Epoch: 6| Step: 9
Training loss: 1.867511510848999
Validation loss: 2.0255592664082847

Epoch: 6| Step: 10
Training loss: 2.0610904693603516
Validation loss: 2.0167888601620994

Epoch: 6| Step: 11
Training loss: 2.136383056640625
Validation loss: 2.0264732837677

Epoch: 6| Step: 12
Training loss: 1.754819393157959
Validation loss: 2.0187146067619324

Epoch: 6| Step: 13
Training loss: 2.2252049446105957
Validation loss: 2.019871413707733

Epoch: 93| Step: 0
Training loss: 1.821547031402588
Validation loss: 2.0058688521385193

Epoch: 6| Step: 1
Training loss: 1.964033842086792
Validation loss: 2.004078725973765

Epoch: 6| Step: 2
Training loss: 2.4711434841156006
Validation loss: 2.0027032693227134

Epoch: 6| Step: 3
Training loss: 2.3538007736206055
Validation loss: 1.999862273534139

Epoch: 6| Step: 4
Training loss: 1.9225735664367676
Validation loss: 2.0059569478034973

Epoch: 6| Step: 5
Training loss: 1.6087886095046997
Validation loss: 2.0026652018229165

Epoch: 6| Step: 6
Training loss: 2.5611705780029297
Validation loss: 2.0056034525235495

Epoch: 6| Step: 7
Training loss: 2.1624908447265625
Validation loss: 2.0030269622802734

Epoch: 6| Step: 8
Training loss: 2.2923338413238525
Validation loss: 2.0035723447799683

Epoch: 6| Step: 9
Training loss: 2.3501362800598145
Validation loss: 1.9974230726559956

Epoch: 6| Step: 10
Training loss: 1.9133647680282593
Validation loss: 2.0030861298243203

Epoch: 6| Step: 11
Training loss: 1.9961613416671753
Validation loss: 2.007535537083944

Epoch: 6| Step: 12
Training loss: 2.481276750564575
Validation loss: 2.009259661038717

Epoch: 6| Step: 13
Training loss: 2.106262445449829
Validation loss: 2.0129183530807495

Epoch: 94| Step: 0
Training loss: 1.5846428871154785
Validation loss: 2.0046664277712503

Epoch: 6| Step: 1
Training loss: 2.0917410850524902
Validation loss: 2.0100077390670776

Epoch: 6| Step: 2
Training loss: 2.316417694091797
Validation loss: 2.008152266343435

Epoch: 6| Step: 3
Training loss: 2.2857983112335205
Validation loss: 2.0123712023099265

Epoch: 6| Step: 4
Training loss: 2.287339210510254
Validation loss: 2.016257405281067

Epoch: 6| Step: 5
Training loss: 2.4677300453186035
Validation loss: 2.0163514018058777

Epoch: 6| Step: 6
Training loss: 2.1650938987731934
Validation loss: 2.009518265724182

Epoch: 6| Step: 7
Training loss: 2.3705859184265137
Validation loss: 2.0124855438868203

Epoch: 6| Step: 8
Training loss: 1.9677865505218506
Validation loss: 2.0111650228500366

Epoch: 6| Step: 9
Training loss: 1.5770987272262573
Validation loss: 2.0183578729629517

Epoch: 6| Step: 10
Training loss: 2.1375784873962402
Validation loss: 2.004177729288737

Epoch: 6| Step: 11
Training loss: 2.2722229957580566
Validation loss: 2.0142323772112527

Epoch: 6| Step: 12
Training loss: 1.813578724861145
Validation loss: 2.014179766178131

Epoch: 6| Step: 13
Training loss: 2.3412628173828125
Validation loss: 2.0099899768829346

Epoch: 95| Step: 0
Training loss: 2.586055040359497
Validation loss: 2.004912277062734

Epoch: 6| Step: 1
Training loss: 2.1616435050964355
Validation loss: 2.0134190917015076

Epoch: 6| Step: 2
Training loss: 2.0728230476379395
Validation loss: 2.0107934872309365

Epoch: 6| Step: 3
Training loss: 1.8560905456542969
Validation loss: 2.0118106802304587

Epoch: 6| Step: 4
Training loss: 1.801413655281067
Validation loss: 2.0052319963773093

Epoch: 6| Step: 5
Training loss: 2.0698084831237793
Validation loss: 2.012333611647288

Epoch: 6| Step: 6
Training loss: 2.3961987495422363
Validation loss: 2.019212086995443

Epoch: 6| Step: 7
Training loss: 2.2758235931396484
Validation loss: 2.0121954480806985

Epoch: 6| Step: 8
Training loss: 2.2309436798095703
Validation loss: 2.0144975980122886

Epoch: 6| Step: 9
Training loss: 1.160315752029419
Validation loss: 2.0126380721728006

Epoch: 6| Step: 10
Training loss: 1.8983958959579468
Validation loss: 2.023211439450582

Epoch: 6| Step: 11
Training loss: 2.5333609580993652
Validation loss: 2.0167475740114846

Epoch: 6| Step: 12
Training loss: 2.9673032760620117
Validation loss: 2.0214632153511047

Epoch: 6| Step: 13
Training loss: 1.706550121307373
Validation loss: 2.029780944188436

Epoch: 96| Step: 0
Training loss: 1.5258197784423828
Validation loss: 2.012440264225006

Epoch: 6| Step: 1
Training loss: 1.899209976196289
Validation loss: 2.015746454397837

Epoch: 6| Step: 2
Training loss: 2.111682415008545
Validation loss: 2.011755386988322

Epoch: 6| Step: 3
Training loss: 2.9201769828796387
Validation loss: 2.01746533314387

Epoch: 6| Step: 4
Training loss: 1.359241008758545
Validation loss: 2.0062615871429443

Epoch: 6| Step: 5
Training loss: 1.5946296453475952
Validation loss: 2.0137182076772056

Epoch: 6| Step: 6
Training loss: 2.3714728355407715
Validation loss: 2.0065061450004578

Epoch: 6| Step: 7
Training loss: 2.12692928314209
Validation loss: 1.9995716214179993

Epoch: 6| Step: 8
Training loss: 1.6460119485855103
Validation loss: 2.005581180254618

Epoch: 6| Step: 9
Training loss: 2.7960357666015625
Validation loss: 2.0105119546254477

Epoch: 6| Step: 10
Training loss: 2.736356019973755
Validation loss: 2.0092923641204834

Epoch: 6| Step: 11
Training loss: 2.0681169033050537
Validation loss: 2.005897104740143

Epoch: 6| Step: 12
Training loss: 1.901841640472412
Validation loss: 1.9970514575640361

Epoch: 6| Step: 13
Training loss: 2.598865509033203
Validation loss: 1.9975982308387756

Epoch: 97| Step: 0
Training loss: 2.0836315155029297
Validation loss: 1.997693121433258

Epoch: 6| Step: 1
Training loss: 2.2651541233062744
Validation loss: 1.9961403210957844

Epoch: 6| Step: 2
Training loss: 2.297943592071533
Validation loss: 1.9955809116363525

Epoch: 6| Step: 3
Training loss: 2.032217502593994
Validation loss: 1.991987665494283

Epoch: 6| Step: 4
Training loss: 2.344881534576416
Validation loss: 1.999724527200063

Epoch: 6| Step: 5
Training loss: 1.9727938175201416
Validation loss: 1.998262107372284

Epoch: 6| Step: 6
Training loss: 2.4723520278930664
Validation loss: 1.9983723163604736

Epoch: 6| Step: 7
Training loss: 2.257164478302002
Validation loss: 1.9928259650866191

Epoch: 6| Step: 8
Training loss: 2.2966461181640625
Validation loss: 1.99987796942393

Epoch: 6| Step: 9
Training loss: 2.516066074371338
Validation loss: 1.9957858522733052

Epoch: 6| Step: 10
Training loss: 2.0792195796966553
Validation loss: 1.994729499022166

Epoch: 6| Step: 11
Training loss: 2.0714492797851562
Validation loss: 1.9984134236971538

Epoch: 6| Step: 12
Training loss: 1.5252432823181152
Validation loss: 2.000120759010315

Epoch: 6| Step: 13
Training loss: 1.529970407485962
Validation loss: 2.0038028558095298

Epoch: 98| Step: 0
Training loss: 2.3355278968811035
Validation loss: 2.005728264649709

Epoch: 6| Step: 1
Training loss: 2.2892398834228516
Validation loss: 2.005576948324839

Epoch: 6| Step: 2
Training loss: 1.5821435451507568
Validation loss: 1.99947985013326

Epoch: 6| Step: 3
Training loss: 1.8840010166168213
Validation loss: 2.0038005312283835

Epoch: 6| Step: 4
Training loss: 1.9942879676818848
Validation loss: 2.004140019416809

Epoch: 6| Step: 5
Training loss: 2.5710816383361816
Validation loss: 2.0061099330584207

Epoch: 6| Step: 6
Training loss: 2.160369396209717
Validation loss: 2.0011789798736572

Epoch: 6| Step: 7
Training loss: 1.919585943222046
Validation loss: 2.0132521788279214

Epoch: 6| Step: 8
Training loss: 2.2462496757507324
Validation loss: 2.0148937900861106

Epoch: 6| Step: 9
Training loss: 1.5152575969696045
Validation loss: 2.0061975916226706

Epoch: 6| Step: 10
Training loss: 2.2046635150909424
Validation loss: 2.007849176724752

Epoch: 6| Step: 11
Training loss: 2.3740344047546387
Validation loss: 2.007073481877645

Epoch: 6| Step: 12
Training loss: 1.7487058639526367
Validation loss: 2.0095248222351074

Epoch: 6| Step: 13
Training loss: 2.623910903930664
Validation loss: 2.008202234903971

Epoch: 99| Step: 0
Training loss: 1.8887531757354736
Validation loss: 2.003170828024546

Epoch: 6| Step: 1
Training loss: 1.8907662630081177
Validation loss: 2.014589528242747

Epoch: 6| Step: 2
Training loss: 1.929144263267517
Validation loss: 2.018129845460256

Epoch: 6| Step: 3
Training loss: 2.1373560428619385
Validation loss: 2.0086334347724915

Epoch: 6| Step: 4
Training loss: 1.967292070388794
Validation loss: 2.0116752783457437

Epoch: 6| Step: 5
Training loss: 2.0188000202178955
Validation loss: 2.006730635960897

Epoch: 6| Step: 6
Training loss: 2.118241310119629
Validation loss: 2.003868261973063

Epoch: 6| Step: 7
Training loss: 2.512324094772339
Validation loss: 2.0119242469469705

Epoch: 6| Step: 8
Training loss: 1.675913691520691
Validation loss: 2.0062097112337747

Epoch: 6| Step: 9
Training loss: 2.2033963203430176
Validation loss: 2.011869569619497

Epoch: 6| Step: 10
Training loss: 1.901342511177063
Validation loss: 2.008750259876251

Epoch: 6| Step: 11
Training loss: 3.1099839210510254
Validation loss: 2.0115697383880615

Epoch: 6| Step: 12
Training loss: 2.3711657524108887
Validation loss: 2.006948093573252

Epoch: 6| Step: 13
Training loss: 1.6725764274597168
Validation loss: 2.012772818406423

Epoch: 100| Step: 0
Training loss: 2.2819056510925293
Validation loss: 2.006747921307882

Epoch: 6| Step: 1
Training loss: 1.894189476966858
Validation loss: 2.0040022134780884

Epoch: 6| Step: 2
Training loss: 2.0600905418395996
Validation loss: 2.0010079940160117

Epoch: 6| Step: 3
Training loss: 2.0189900398254395
Validation loss: 2.0044615864753723

Epoch: 6| Step: 4
Training loss: 1.9393216371536255
Validation loss: 2.008601188659668

Epoch: 6| Step: 5
Training loss: 2.197610855102539
Validation loss: 2.0063562790552774

Epoch: 6| Step: 6
Training loss: 1.8551453351974487
Validation loss: 2.0026206771532693

Epoch: 6| Step: 7
Training loss: 1.8970810174942017
Validation loss: 2.010117014249166

Epoch: 6| Step: 8
Training loss: 2.16787052154541
Validation loss: 2.0095598697662354

Epoch: 6| Step: 9
Training loss: 2.238661050796509
Validation loss: 2.019158363342285

Epoch: 6| Step: 10
Training loss: 2.2128255367279053
Validation loss: 2.0108267267545066

Epoch: 6| Step: 11
Training loss: 2.1029930114746094
Validation loss: 2.006932814915975

Epoch: 6| Step: 12
Training loss: 2.263652801513672
Validation loss: 2.008260985215505

Epoch: 6| Step: 13
Training loss: 2.336113929748535
Validation loss: 2.012258251508077

Epoch: 101| Step: 0
Training loss: 1.7595127820968628
Validation loss: 2.0039245883623757

Epoch: 6| Step: 1
Training loss: 2.204493522644043
Validation loss: 2.0075838565826416

Epoch: 6| Step: 2
Training loss: 1.901845097541809
Validation loss: 2.0031699736913047

Epoch: 6| Step: 3
Training loss: 2.168891429901123
Validation loss: 2.0044696927070618

Epoch: 6| Step: 4
Training loss: 2.299130916595459
Validation loss: 2.0010672211647034

Epoch: 6| Step: 5
Training loss: 2.17813777923584
Validation loss: 1.9965001344680786

Epoch: 6| Step: 6
Training loss: 2.003350257873535
Validation loss: 2.000834325949351

Epoch: 6| Step: 7
Training loss: 1.440302848815918
Validation loss: 1.9937496781349182

Epoch: 6| Step: 8
Training loss: 1.953835129737854
Validation loss: 1.995214839776357

Epoch: 6| Step: 9
Training loss: 2.7232582569122314
Validation loss: 1.994523823261261

Epoch: 6| Step: 10
Training loss: 2.483071804046631
Validation loss: 1.9986204107602437

Epoch: 6| Step: 11
Training loss: 2.55726957321167
Validation loss: 1.999208112557729

Epoch: 6| Step: 12
Training loss: 2.178138256072998
Validation loss: 1.997522234916687

Epoch: 6| Step: 13
Training loss: 1.8605353832244873
Validation loss: 1.9970068335533142

Epoch: 102| Step: 0
Training loss: 2.5344512462615967
Validation loss: 1.9967851241429646

Epoch: 6| Step: 1
Training loss: 1.4537020921707153
Validation loss: 1.9949923157691956

Epoch: 6| Step: 2
Training loss: 2.0020766258239746
Validation loss: 1.9996886452039082

Epoch: 6| Step: 3
Training loss: 2.94575834274292
Validation loss: 2.000171740849813

Epoch: 6| Step: 4
Training loss: 2.36650013923645
Validation loss: 2.0051962534586587

Epoch: 6| Step: 5
Training loss: 2.0319857597351074
Validation loss: 2.0103477835655212

Epoch: 6| Step: 6
Training loss: 2.1114416122436523
Validation loss: 2.0015275875727334

Epoch: 6| Step: 7
Training loss: 1.6304126977920532
Validation loss: 2.0082494417826333

Epoch: 6| Step: 8
Training loss: 2.021148204803467
Validation loss: 2.0060009161631265

Epoch: 6| Step: 9
Training loss: 1.8217631578445435
Validation loss: 2.0187509258588157

Epoch: 6| Step: 10
Training loss: 2.1001598834991455
Validation loss: 2.0228843291600547

Epoch: 6| Step: 11
Training loss: 1.8170024156570435
Validation loss: 2.0410540302594504

Epoch: 6| Step: 12
Training loss: 2.5487303733825684
Validation loss: 2.045720338821411

Epoch: 6| Step: 13
Training loss: 1.9984570741653442
Validation loss: 2.058122714360555

Epoch: 103| Step: 0
Training loss: 2.1318869590759277
Validation loss: 2.0509344935417175

Epoch: 6| Step: 1
Training loss: 2.3789730072021484
Validation loss: 2.053437908490499

Epoch: 6| Step: 2
Training loss: 1.853624701499939
Validation loss: 2.034128268559774

Epoch: 6| Step: 3
Training loss: 1.5662459135055542
Validation loss: 2.017707804838816

Epoch: 6| Step: 4
Training loss: 2.7747974395751953
Validation loss: 2.0145482222239175

Epoch: 6| Step: 5
Training loss: 1.871009111404419
Validation loss: 2.005407472451528

Epoch: 6| Step: 6
Training loss: 2.0886056423187256
Validation loss: 2.0090901255607605

Epoch: 6| Step: 7
Training loss: 1.2287359237670898
Validation loss: 2.0204142133394876

Epoch: 6| Step: 8
Training loss: 2.6485559940338135
Validation loss: 2.023094813028971

Epoch: 6| Step: 9
Training loss: 2.027693271636963
Validation loss: 2.032169202963511

Epoch: 6| Step: 10
Training loss: 2.312988758087158
Validation loss: 2.034383773803711

Epoch: 6| Step: 11
Training loss: 2.377401351928711
Validation loss: 2.0409897764523826

Epoch: 6| Step: 12
Training loss: 2.5658085346221924
Validation loss: 2.040367285410563

Epoch: 6| Step: 13
Training loss: 2.4089033603668213
Validation loss: 2.0379125078519187

Epoch: 104| Step: 0
Training loss: 2.36909818649292
Validation loss: 2.041706085205078

Epoch: 6| Step: 1
Training loss: 1.9325108528137207
Validation loss: 2.045096198717753

Epoch: 6| Step: 2
Training loss: 2.9619832038879395
Validation loss: 2.0432522098223367

Epoch: 6| Step: 3
Training loss: 2.079136610031128
Validation loss: 2.039560536543528

Epoch: 6| Step: 4
Training loss: 2.4820396900177
Validation loss: 2.0405680934588113

Epoch: 6| Step: 5
Training loss: 2.0546271800994873
Validation loss: 2.0347926020622253

Epoch: 6| Step: 6
Training loss: 1.418506383895874
Validation loss: 2.0337701042493186

Epoch: 6| Step: 7
Training loss: 2.191236734390259
Validation loss: 2.026803811391195

Epoch: 6| Step: 8
Training loss: 2.571424722671509
Validation loss: 2.025800089041392

Epoch: 6| Step: 9
Training loss: 2.686321973800659
Validation loss: 2.0244988799095154

Epoch: 6| Step: 10
Training loss: 1.7543809413909912
Validation loss: 2.011325180530548

Epoch: 6| Step: 11
Training loss: 1.7666354179382324
Validation loss: 2.0054805676142373

Epoch: 6| Step: 12
Training loss: 2.1068320274353027
Validation loss: 1.9937264919281006

Epoch: 6| Step: 13
Training loss: 2.10361385345459
Validation loss: 1.9916608532269795

Epoch: 105| Step: 0
Training loss: 2.075556755065918
Validation loss: 1.9917555054028828

Epoch: 6| Step: 1
Training loss: 1.7065784931182861
Validation loss: 1.9928030570348103

Epoch: 6| Step: 2
Training loss: 2.0132269859313965
Validation loss: 1.9981026252110798

Epoch: 6| Step: 3
Training loss: 2.1407923698425293
Validation loss: 2.015336891015371

Epoch: 6| Step: 4
Training loss: 2.379013776779175
Validation loss: 2.0343304872512817

Epoch: 6| Step: 5
Training loss: 2.5400922298431396
Validation loss: 2.0339218775431314

Epoch: 6| Step: 6
Training loss: 1.6680315732955933
Validation loss: 2.034114400545756

Epoch: 6| Step: 7
Training loss: 2.4476003646850586
Validation loss: 2.0370903412501016

Epoch: 6| Step: 8
Training loss: 2.850985288619995
Validation loss: 2.048132081826528

Epoch: 6| Step: 9
Training loss: 2.332892894744873
Validation loss: 2.0215629935264587

Epoch: 6| Step: 10
Training loss: 2.056797742843628
Validation loss: 2.0261954069137573

Epoch: 6| Step: 11
Training loss: 1.6656310558319092
Validation loss: 2.0296565095583596

Epoch: 6| Step: 12
Training loss: 1.703023910522461
Validation loss: 2.0137670040130615

Epoch: 6| Step: 13
Training loss: 2.0400750637054443
Validation loss: 2.0272763768831887

Epoch: 106| Step: 0
Training loss: 2.7136471271514893
Validation loss: 2.019952336947123

Epoch: 6| Step: 1
Training loss: 1.8547307252883911
Validation loss: 2.0143884420394897

Epoch: 6| Step: 2
Training loss: 1.8576674461364746
Validation loss: 2.016850312550863

Epoch: 6| Step: 3
Training loss: 1.9131484031677246
Validation loss: 2.0087983210881553

Epoch: 6| Step: 4
Training loss: 2.416707992553711
Validation loss: 2.016406257947286

Epoch: 6| Step: 5
Training loss: 1.66705322265625
Validation loss: 2.0155462622642517

Epoch: 6| Step: 6
Training loss: 2.0188217163085938
Validation loss: 2.026039262612661

Epoch: 6| Step: 7
Training loss: 2.3128161430358887
Validation loss: 2.0175653100013733

Epoch: 6| Step: 8
Training loss: 1.7408812046051025
Validation loss: 2.0211992661158242

Epoch: 6| Step: 9
Training loss: 2.2755160331726074
Validation loss: 2.025490462779999

Epoch: 6| Step: 10
Training loss: 1.7714097499847412
Validation loss: 2.014288385709127

Epoch: 6| Step: 11
Training loss: 2.30471134185791
Validation loss: 2.0099028746287027

Epoch: 6| Step: 12
Training loss: 2.230041980743408
Validation loss: 2.007058878739675

Epoch: 6| Step: 13
Training loss: 2.453075885772705
Validation loss: 2.008861859639486

Epoch: 107| Step: 0
Training loss: 1.6285316944122314
Validation loss: 2.015400012334188

Epoch: 6| Step: 1
Training loss: 2.2949204444885254
Validation loss: 2.0037256479263306

Epoch: 6| Step: 2
Training loss: 2.025855541229248
Validation loss: 2.005562424659729

Epoch: 6| Step: 3
Training loss: 2.531235933303833
Validation loss: 2.00730969508489

Epoch: 6| Step: 4
Training loss: 1.6326617002487183
Validation loss: 2.0169862508773804

Epoch: 6| Step: 5
Training loss: 2.3457517623901367
Validation loss: 2.016636848449707

Epoch: 6| Step: 6
Training loss: 2.1504526138305664
Validation loss: 2.014122207959493

Epoch: 6| Step: 7
Training loss: 2.5168416500091553
Validation loss: 2.0167209704717

Epoch: 6| Step: 8
Training loss: 2.457575559616089
Validation loss: 2.0196147759755454

Epoch: 6| Step: 9
Training loss: 2.3976564407348633
Validation loss: 2.0175335009892783

Epoch: 6| Step: 10
Training loss: 1.2603453397750854
Validation loss: 2.020420034726461

Epoch: 6| Step: 11
Training loss: 2.6769261360168457
Validation loss: 2.0219499468803406

Epoch: 6| Step: 12
Training loss: 1.5281414985656738
Validation loss: 2.0202081004778543

Epoch: 6| Step: 13
Training loss: 2.0099544525146484
Validation loss: 2.0219978292783103

Epoch: 108| Step: 0
Training loss: 1.7220792770385742
Validation loss: 2.022477130095164

Epoch: 6| Step: 1
Training loss: 1.8669825792312622
Validation loss: 2.013255556424459

Epoch: 6| Step: 2
Training loss: 2.086252212524414
Validation loss: 2.018214205900828

Epoch: 6| Step: 3
Training loss: 1.6140644550323486
Validation loss: 2.0215126474698386

Epoch: 6| Step: 4
Training loss: 2.4134483337402344
Validation loss: 2.016678432623545

Epoch: 6| Step: 5
Training loss: 2.013033390045166
Validation loss: 2.0173267920811973

Epoch: 6| Step: 6
Training loss: 2.097665786743164
Validation loss: 2.018243908882141

Epoch: 6| Step: 7
Training loss: 2.0368149280548096
Validation loss: 2.017926116784414

Epoch: 6| Step: 8
Training loss: 2.2222461700439453
Validation loss: 2.0214745799700418

Epoch: 6| Step: 9
Training loss: 1.858454704284668
Validation loss: 2.0129008491834006

Epoch: 6| Step: 10
Training loss: 2.551027297973633
Validation loss: 2.025915563106537

Epoch: 6| Step: 11
Training loss: 2.1992697715759277
Validation loss: 2.021196802457174

Epoch: 6| Step: 12
Training loss: 2.612391233444214
Validation loss: 2.020639975865682

Epoch: 6| Step: 13
Training loss: 1.8967210054397583
Validation loss: 2.0216071208318076

Epoch: 109| Step: 0
Training loss: 2.1540560722351074
Validation loss: 2.016973078250885

Epoch: 6| Step: 1
Training loss: 2.279088020324707
Validation loss: 2.014852066834768

Epoch: 6| Step: 2
Training loss: 2.6039319038391113
Validation loss: 2.018511116504669

Epoch: 6| Step: 3
Training loss: 2.0936598777770996
Validation loss: 2.014220972855886

Epoch: 6| Step: 4
Training loss: 1.4874839782714844
Validation loss: 2.022705316543579

Epoch: 6| Step: 5
Training loss: 1.7265030145645142
Validation loss: 2.035126268863678

Epoch: 6| Step: 6
Training loss: 2.460141658782959
Validation loss: 2.0294974048932395

Epoch: 6| Step: 7
Training loss: 2.0960147380828857
Validation loss: 2.025246481100718

Epoch: 6| Step: 8
Training loss: 2.1386823654174805
Validation loss: 2.0370335578918457

Epoch: 6| Step: 9
Training loss: 2.343266487121582
Validation loss: 2.0470223228136697

Epoch: 6| Step: 10
Training loss: 1.8934805393218994
Validation loss: 2.03667813539505

Epoch: 6| Step: 11
Training loss: 2.121730089187622
Validation loss: 2.0410017569859824

Epoch: 6| Step: 12
Training loss: 1.4497627019882202
Validation loss: 2.0267523725827536

Epoch: 6| Step: 13
Training loss: 2.5890111923217773
Validation loss: 2.0240022937456765

Epoch: 110| Step: 0
Training loss: 2.2650980949401855
Validation loss: 2.0125020146369934

Epoch: 6| Step: 1
Training loss: 2.511948585510254
Validation loss: 2.0109273393948874

Epoch: 6| Step: 2
Training loss: 1.7051390409469604
Validation loss: 2.001639803250631

Epoch: 6| Step: 3
Training loss: 1.7368594408035278
Validation loss: 2.002182046572367

Epoch: 6| Step: 4
Training loss: 2.4380764961242676
Validation loss: 2.008455276489258

Epoch: 6| Step: 5
Training loss: 1.7310506105422974
Validation loss: 2.0145705540974936

Epoch: 6| Step: 6
Training loss: 2.1503119468688965
Validation loss: 2.01245786746343

Epoch: 6| Step: 7
Training loss: 2.1738619804382324
Validation loss: 2.0168261528015137

Epoch: 6| Step: 8
Training loss: 2.7038793563842773
Validation loss: 2.016352633635203

Epoch: 6| Step: 9
Training loss: 1.3491532802581787
Validation loss: 2.0130178332328796

Epoch: 6| Step: 10
Training loss: 2.1347827911376953
Validation loss: 2.015417456626892

Epoch: 6| Step: 11
Training loss: 2.4988226890563965
Validation loss: 2.0154317220052085

Epoch: 6| Step: 12
Training loss: 2.3037729263305664
Validation loss: 2.0094617009162903

Epoch: 6| Step: 13
Training loss: 1.8700931072235107
Validation loss: 2.0169297059377036

Epoch: 111| Step: 0
Training loss: 1.9553872346878052
Validation loss: 2.0263158082962036

Epoch: 6| Step: 1
Training loss: 2.4151611328125
Validation loss: 2.0248843828837075

Epoch: 6| Step: 2
Training loss: 1.3670297861099243
Validation loss: 2.023655414581299

Epoch: 6| Step: 3
Training loss: 2.477169990539551
Validation loss: 2.039195636908213

Epoch: 6| Step: 4
Training loss: 1.9554792642593384
Validation loss: 2.0424359242121377

Epoch: 6| Step: 5
Training loss: 2.8744871616363525
Validation loss: 2.0499138633410134

Epoch: 6| Step: 6
Training loss: 2.2687911987304688
Validation loss: 2.0291900038719177

Epoch: 6| Step: 7
Training loss: 1.93984055519104
Validation loss: 2.0283195773760476

Epoch: 6| Step: 8
Training loss: 1.3554930686950684
Validation loss: 2.031991183757782

Epoch: 6| Step: 9
Training loss: 1.8143682479858398
Validation loss: 2.0285654067993164

Epoch: 6| Step: 10
Training loss: 2.0368921756744385
Validation loss: 2.0206968585650125

Epoch: 6| Step: 11
Training loss: 2.282486915588379
Validation loss: 2.0258387525876365

Epoch: 6| Step: 12
Training loss: 2.5648412704467773
Validation loss: 2.0187664230664573

Epoch: 6| Step: 13
Training loss: 1.8409616947174072
Validation loss: 2.014577547709147

Epoch: 112| Step: 0
Training loss: 2.1539804935455322
Validation loss: 2.0177255471547446

Epoch: 6| Step: 1
Training loss: 2.0797433853149414
Validation loss: 2.015948553880056

Epoch: 6| Step: 2
Training loss: 1.9427348375320435
Validation loss: 2.0180662473042807

Epoch: 6| Step: 3
Training loss: 1.8130981922149658
Validation loss: 2.0206363201141357

Epoch: 6| Step: 4
Training loss: 1.951390027999878
Validation loss: 2.0262858668963113

Epoch: 6| Step: 5
Training loss: 2.2639780044555664
Validation loss: 2.0255350271860757

Epoch: 6| Step: 6
Training loss: 2.4726200103759766
Validation loss: 2.03443177541097

Epoch: 6| Step: 7
Training loss: 2.0421321392059326
Validation loss: 2.0352509220441184

Epoch: 6| Step: 8
Training loss: 2.450814723968506
Validation loss: 2.0376791954040527

Epoch: 6| Step: 9
Training loss: 1.7925127744674683
Validation loss: 2.0288814902305603

Epoch: 6| Step: 10
Training loss: 2.183565378189087
Validation loss: 2.035403529802958

Epoch: 6| Step: 11
Training loss: 2.026655912399292
Validation loss: 2.0308738946914673

Epoch: 6| Step: 12
Training loss: 2.365382671356201
Validation loss: 2.037571907043457

Epoch: 6| Step: 13
Training loss: 1.6313045024871826
Validation loss: 2.0370044112205505

Epoch: 113| Step: 0
Training loss: 1.79179847240448
Validation loss: 2.0336498618125916

Epoch: 6| Step: 1
Training loss: 2.111395835876465
Validation loss: 2.0238821705182395

Epoch: 6| Step: 2
Training loss: 1.9062680006027222
Validation loss: 2.0186220010121665

Epoch: 6| Step: 3
Training loss: 2.709284543991089
Validation loss: 2.0190799832344055

Epoch: 6| Step: 4
Training loss: 1.720245361328125
Validation loss: 2.0218037764231362

Epoch: 6| Step: 5
Training loss: 2.631993293762207
Validation loss: 2.0255435506502786

Epoch: 6| Step: 6
Training loss: 2.156818151473999
Validation loss: 2.015953699747721

Epoch: 6| Step: 7
Training loss: 2.0635600090026855
Validation loss: 2.022073745727539

Epoch: 6| Step: 8
Training loss: 2.025751829147339
Validation loss: 2.019833246866862

Epoch: 6| Step: 9
Training loss: 1.7125582695007324
Validation loss: 2.021660884221395

Epoch: 6| Step: 10
Training loss: 1.400517463684082
Validation loss: 2.033506373564402

Epoch: 6| Step: 11
Training loss: 2.119715690612793
Validation loss: 2.0371705293655396

Epoch: 6| Step: 12
Training loss: 2.2709145545959473
Validation loss: 2.0395243763923645

Epoch: 6| Step: 13
Training loss: 2.431171417236328
Validation loss: 2.0471205711364746

Epoch: 114| Step: 0
Training loss: 1.7135448455810547
Validation loss: 2.063353717327118

Epoch: 6| Step: 1
Training loss: 1.9305438995361328
Validation loss: 2.0516980489095054

Epoch: 6| Step: 2
Training loss: 2.5454068183898926
Validation loss: 2.0366400678952536

Epoch: 6| Step: 3
Training loss: 2.949291229248047
Validation loss: 2.0368562738100686

Epoch: 6| Step: 4
Training loss: 1.3396246433258057
Validation loss: 2.0262640515963235

Epoch: 6| Step: 5
Training loss: 2.4739041328430176
Validation loss: 2.0148414174715676

Epoch: 6| Step: 6
Training loss: 1.9042376279830933
Validation loss: 2.0111635327339172

Epoch: 6| Step: 7
Training loss: 1.9962793588638306
Validation loss: 2.018060564994812

Epoch: 6| Step: 8
Training loss: 1.641420602798462
Validation loss: 2.0183790922164917

Epoch: 6| Step: 9
Training loss: 1.9800896644592285
Validation loss: 2.0206238627433777

Epoch: 6| Step: 10
Training loss: 1.7796239852905273
Validation loss: 2.027026653289795

Epoch: 6| Step: 11
Training loss: 2.152442693710327
Validation loss: 2.0232290824254355

Epoch: 6| Step: 12
Training loss: 2.5111870765686035
Validation loss: 2.0345635414123535

Epoch: 6| Step: 13
Training loss: 2.352464199066162
Validation loss: 2.043646057446798

Epoch: 115| Step: 0
Training loss: 1.7770400047302246
Validation loss: 2.039156218369802

Epoch: 6| Step: 1
Training loss: 2.027031421661377
Validation loss: 2.0526419281959534

Epoch: 6| Step: 2
Training loss: 2.4768452644348145
Validation loss: 2.058168649673462

Epoch: 6| Step: 3
Training loss: 2.071720600128174
Validation loss: 2.0529679656028748

Epoch: 6| Step: 4
Training loss: 2.1959762573242188
Validation loss: 2.044564704100291

Epoch: 6| Step: 5
Training loss: 1.5674166679382324
Validation loss: 2.0412046710650125

Epoch: 6| Step: 6
Training loss: 1.9393260478973389
Validation loss: 2.044063071409861

Epoch: 6| Step: 7
Training loss: 2.1790452003479004
Validation loss: 2.0281855861345925

Epoch: 6| Step: 8
Training loss: 2.3652868270874023
Validation loss: 2.0178699493408203

Epoch: 6| Step: 9
Training loss: 2.2930350303649902
Validation loss: 2.0162435372670493

Epoch: 6| Step: 10
Training loss: 2.721890449523926
Validation loss: 2.019201695919037

Epoch: 6| Step: 11
Training loss: 1.7473244667053223
Validation loss: 2.009828805923462

Epoch: 6| Step: 12
Training loss: 2.5309572219848633
Validation loss: 2.0177376667658486

Epoch: 6| Step: 13
Training loss: 1.311270833015442
Validation loss: 2.015328307946523

Epoch: 116| Step: 0
Training loss: 2.4340555667877197
Validation loss: 2.0213288267453513

Epoch: 6| Step: 1
Training loss: 2.1206908226013184
Validation loss: 2.0179506142934165

Epoch: 6| Step: 2
Training loss: 2.0737202167510986
Validation loss: 2.023614148298899

Epoch: 6| Step: 3
Training loss: 2.4592511653900146
Validation loss: 2.054711620012919

Epoch: 6| Step: 4
Training loss: 1.7471556663513184
Validation loss: 2.0507896343866983

Epoch: 6| Step: 5
Training loss: 1.6464245319366455
Validation loss: 2.057591279347738

Epoch: 6| Step: 6
Training loss: 1.956736445426941
Validation loss: 2.0622814098993936

Epoch: 6| Step: 7
Training loss: 2.0883665084838867
Validation loss: 2.064998904863993

Epoch: 6| Step: 8
Training loss: 2.3631045818328857
Validation loss: 2.0701969464619956

Epoch: 6| Step: 9
Training loss: 1.7747224569320679
Validation loss: 2.0687237977981567

Epoch: 6| Step: 10
Training loss: 2.23168683052063
Validation loss: 2.067302962144216

Epoch: 6| Step: 11
Training loss: 1.7314507961273193
Validation loss: 2.060036838054657

Epoch: 6| Step: 12
Training loss: 1.7819560766220093
Validation loss: 2.0586514671643577

Epoch: 6| Step: 13
Training loss: 2.819246292114258
Validation loss: 2.056554834047953

Epoch: 117| Step: 0
Training loss: 1.878032922744751
Validation loss: 2.047286411126455

Epoch: 6| Step: 1
Training loss: 1.6475439071655273
Validation loss: 2.0421108404795327

Epoch: 6| Step: 2
Training loss: 1.85768461227417
Validation loss: 2.0283679167429605

Epoch: 6| Step: 3
Training loss: 1.903679609298706
Validation loss: 2.031300644079844

Epoch: 6| Step: 4
Training loss: 2.379429817199707
Validation loss: 2.025407910346985

Epoch: 6| Step: 5
Training loss: 2.4188756942749023
Validation loss: 2.0244878133138022

Epoch: 6| Step: 6
Training loss: 2.142730236053467
Validation loss: 2.0275206565856934

Epoch: 6| Step: 7
Training loss: 1.9744020700454712
Validation loss: 2.0312886238098145

Epoch: 6| Step: 8
Training loss: 1.6267006397247314
Validation loss: 2.0229345162709556

Epoch: 6| Step: 9
Training loss: 2.3302764892578125
Validation loss: 2.022626837094625

Epoch: 6| Step: 10
Training loss: 2.0335092544555664
Validation loss: 2.028377095858256

Epoch: 6| Step: 11
Training loss: 1.8162715435028076
Validation loss: 2.034138103326162

Epoch: 6| Step: 12
Training loss: 2.436441659927368
Validation loss: 2.045606176058451

Epoch: 6| Step: 13
Training loss: 2.6190667152404785
Validation loss: 2.059546947479248

Epoch: 118| Step: 0
Training loss: 2.582526445388794
Validation loss: 2.054821014404297

Epoch: 6| Step: 1
Training loss: 2.290851354598999
Validation loss: 2.0644418199857077

Epoch: 6| Step: 2
Training loss: 1.668400764465332
Validation loss: 2.075180927912394

Epoch: 6| Step: 3
Training loss: 1.8108364343643188
Validation loss: 2.062934180100759

Epoch: 6| Step: 4
Training loss: 1.8103957176208496
Validation loss: 2.0674177606900535

Epoch: 6| Step: 5
Training loss: 2.039280414581299
Validation loss: 2.054061849912008

Epoch: 6| Step: 6
Training loss: 1.916017770767212
Validation loss: 2.0467304786046348

Epoch: 6| Step: 7
Training loss: 2.0506584644317627
Validation loss: 2.0409399271011353

Epoch: 6| Step: 8
Training loss: 2.1095900535583496
Validation loss: 2.038984497388204

Epoch: 6| Step: 9
Training loss: 2.5490119457244873
Validation loss: 2.0401116609573364

Epoch: 6| Step: 10
Training loss: 2.2254786491394043
Validation loss: 2.0278908014297485

Epoch: 6| Step: 11
Training loss: 1.9997495412826538
Validation loss: 2.0296523769696555

Epoch: 6| Step: 12
Training loss: 1.9556207656860352
Validation loss: 2.036810060342153

Epoch: 6| Step: 13
Training loss: 2.3169915676116943
Validation loss: 2.03776345650355

Epoch: 119| Step: 0
Training loss: 1.6410125494003296
Validation loss: 2.039191643397013

Epoch: 6| Step: 1
Training loss: 2.062640428543091
Validation loss: 2.0336602528889975

Epoch: 6| Step: 2
Training loss: 2.015540599822998
Validation loss: 2.03315669298172

Epoch: 6| Step: 3
Training loss: 2.087740898132324
Validation loss: 2.023046354452769

Epoch: 6| Step: 4
Training loss: 2.6399412155151367
Validation loss: 2.0238467256228128

Epoch: 6| Step: 5
Training loss: 2.2112529277801514
Validation loss: 2.028819759686788

Epoch: 6| Step: 6
Training loss: 2.2901875972747803
Validation loss: 2.0340627233187356

Epoch: 6| Step: 7
Training loss: 2.1541483402252197
Validation loss: 2.0347854097684226

Epoch: 6| Step: 8
Training loss: 1.8558375835418701
Validation loss: 2.033043642838796

Epoch: 6| Step: 9
Training loss: 1.9225904941558838
Validation loss: 2.0388107697168985

Epoch: 6| Step: 10
Training loss: 2.428445816040039
Validation loss: 2.047507325808207

Epoch: 6| Step: 11
Training loss: 1.8522804975509644
Validation loss: 2.050484041372935

Epoch: 6| Step: 12
Training loss: 2.188995361328125
Validation loss: 2.0590176781018577

Epoch: 6| Step: 13
Training loss: 1.9459214210510254
Validation loss: 2.0578868786493936

Epoch: 120| Step: 0
Training loss: 2.3610997200012207
Validation loss: 2.0492496887842813

Epoch: 6| Step: 1
Training loss: 2.0638277530670166
Validation loss: 2.037184397379557

Epoch: 6| Step: 2
Training loss: 2.560009479522705
Validation loss: 2.0577242175738015

Epoch: 6| Step: 3
Training loss: 2.1447839736938477
Validation loss: 2.047771076361338

Epoch: 6| Step: 4
Training loss: 2.2777390480041504
Validation loss: 2.0510764916737876

Epoch: 6| Step: 5
Training loss: 2.4498989582061768
Validation loss: 2.0590006510416665

Epoch: 6| Step: 6
Training loss: 1.2752102613449097
Validation loss: 2.049220383167267

Epoch: 6| Step: 7
Training loss: 2.3268814086914062
Validation loss: 2.0405633648236594

Epoch: 6| Step: 8
Training loss: 1.5722993612289429
Validation loss: 2.0383389592170715

Epoch: 6| Step: 9
Training loss: 1.367431640625
Validation loss: 2.0400662819544473

Epoch: 6| Step: 10
Training loss: 2.4415979385375977
Validation loss: 2.0372835199038186

Epoch: 6| Step: 11
Training loss: 2.1218435764312744
Validation loss: 2.035768151283264

Epoch: 6| Step: 12
Training loss: 2.0523242950439453
Validation loss: 2.029000540574392

Epoch: 6| Step: 13
Training loss: 1.7665960788726807
Validation loss: 2.031493822733561

Epoch: 121| Step: 0
Training loss: 1.9981173276901245
Validation loss: 2.0367342432339988

Epoch: 6| Step: 1
Training loss: 2.0980820655822754
Validation loss: 2.0300987561543784

Epoch: 6| Step: 2
Training loss: 2.2496938705444336
Validation loss: 2.0313300291697183

Epoch: 6| Step: 3
Training loss: 2.4191315174102783
Validation loss: 2.03488556543986

Epoch: 6| Step: 4
Training loss: 2.2999634742736816
Validation loss: 2.0338078339894614

Epoch: 6| Step: 5
Training loss: 1.9837634563446045
Validation loss: 2.0433416962623596

Epoch: 6| Step: 6
Training loss: 2.5449886322021484
Validation loss: 2.055413564046224

Epoch: 6| Step: 7
Training loss: 1.2879281044006348
Validation loss: 2.05343230565389

Epoch: 6| Step: 8
Training loss: 1.719689130783081
Validation loss: 2.0486909548441568

Epoch: 6| Step: 9
Training loss: 2.0720953941345215
Validation loss: 2.056838870048523

Epoch: 6| Step: 10
Training loss: 1.6591728925704956
Validation loss: 2.048063814640045

Epoch: 6| Step: 11
Training loss: 2.4055404663085938
Validation loss: 2.0499223470687866

Epoch: 6| Step: 12
Training loss: 2.297031879425049
Validation loss: 2.054756005605062

Epoch: 6| Step: 13
Training loss: 1.5880086421966553
Validation loss: 2.0480633974075317

Epoch: 122| Step: 0
Training loss: 2.308676242828369
Validation loss: 2.0376097162564597

Epoch: 6| Step: 1
Training loss: 2.0147314071655273
Validation loss: 2.0533235470453897

Epoch: 6| Step: 2
Training loss: 2.26951265335083
Validation loss: 2.0415899753570557

Epoch: 6| Step: 3
Training loss: 2.5640828609466553
Validation loss: 2.041424592336019

Epoch: 6| Step: 4
Training loss: 1.6148638725280762
Validation loss: 2.0491795937220254

Epoch: 6| Step: 5
Training loss: 2.1986427307128906
Validation loss: 2.067939281463623

Epoch: 6| Step: 6
Training loss: 1.4408631324768066
Validation loss: 2.0754966338475547

Epoch: 6| Step: 7
Training loss: 1.9642913341522217
Validation loss: 2.063496708869934

Epoch: 6| Step: 8
Training loss: 1.8025121688842773
Validation loss: 2.0450324217478433

Epoch: 6| Step: 9
Training loss: 1.843616247177124
Validation loss: 2.039146641890208

Epoch: 6| Step: 10
Training loss: 2.3042354583740234
Validation loss: 2.033187687397003

Epoch: 6| Step: 11
Training loss: 2.430601119995117
Validation loss: 2.040152609348297

Epoch: 6| Step: 12
Training loss: 1.9357373714447021
Validation loss: 2.0363108118375144

Epoch: 6| Step: 13
Training loss: 1.8688699007034302
Validation loss: 2.0368350545565286

Epoch: 123| Step: 0
Training loss: 2.3963356018066406
Validation loss: 2.0324628750483194

Epoch: 6| Step: 1
Training loss: 2.0532567501068115
Validation loss: 2.0365800062815347

Epoch: 6| Step: 2
Training loss: 2.0326876640319824
Validation loss: 2.0338240265846252

Epoch: 6| Step: 3
Training loss: 1.720245599746704
Validation loss: 2.033925791581472

Epoch: 6| Step: 4
Training loss: 2.116029739379883
Validation loss: 2.034690181414286

Epoch: 6| Step: 5
Training loss: 1.86863112449646
Validation loss: 2.0332298278808594

Epoch: 6| Step: 6
Training loss: 2.0313405990600586
Validation loss: 2.0373382767041526

Epoch: 6| Step: 7
Training loss: 2.3655409812927246
Validation loss: 2.0414549311002097

Epoch: 6| Step: 8
Training loss: 2.6959280967712402
Validation loss: 2.040573557217916

Epoch: 6| Step: 9
Training loss: 1.9541139602661133
Validation loss: 2.048701604207357

Epoch: 6| Step: 10
Training loss: 1.7618348598480225
Validation loss: 2.056571821371714

Epoch: 6| Step: 11
Training loss: 1.8219757080078125
Validation loss: 2.062074383099874

Epoch: 6| Step: 12
Training loss: 2.175107955932617
Validation loss: 2.0699098110198975

Epoch: 6| Step: 13
Training loss: 2.0491104125976562
Validation loss: 2.069471001625061

Epoch: 124| Step: 0
Training loss: 1.5160058736801147
Validation loss: 2.0475019812583923

Epoch: 6| Step: 1
Training loss: 1.96713125705719
Validation loss: 2.0434693892796836

Epoch: 6| Step: 2
Training loss: 1.7075679302215576
Validation loss: 2.0363367795944214

Epoch: 6| Step: 3
Training loss: 1.7752556800842285
Validation loss: 2.0443493525187173

Epoch: 6| Step: 4
Training loss: 2.031712055206299
Validation loss: 2.0317084193229675

Epoch: 6| Step: 5
Training loss: 2.370945930480957
Validation loss: 2.0383031765619912

Epoch: 6| Step: 6
Training loss: 1.9520503282546997
Validation loss: 2.0331629713376365

Epoch: 6| Step: 7
Training loss: 2.407870292663574
Validation loss: 2.036401371161143

Epoch: 6| Step: 8
Training loss: 2.5117745399475098
Validation loss: 2.0393183827400208

Epoch: 6| Step: 9
Training loss: 2.072420120239258
Validation loss: 2.0550644795099893

Epoch: 6| Step: 10
Training loss: 2.153341770172119
Validation loss: 2.052391072114309

Epoch: 6| Step: 11
Training loss: 2.3339571952819824
Validation loss: 2.057902197043101

Epoch: 6| Step: 12
Training loss: 2.2143006324768066
Validation loss: 2.067445158958435

Epoch: 6| Step: 13
Training loss: 1.8866283893585205
Validation loss: 2.0637250343958535

Epoch: 125| Step: 0
Training loss: 2.5705435276031494
Validation loss: 2.0687591632207236

Epoch: 6| Step: 1
Training loss: 1.3505675792694092
Validation loss: 2.063460111618042

Epoch: 6| Step: 2
Training loss: 1.2798714637756348
Validation loss: 2.0531249046325684

Epoch: 6| Step: 3
Training loss: 1.513079047203064
Validation loss: 2.05746336778005

Epoch: 6| Step: 4
Training loss: 2.3425474166870117
Validation loss: 2.0536481142044067

Epoch: 6| Step: 5
Training loss: 2.342543125152588
Validation loss: 2.0634544690450034

Epoch: 6| Step: 6
Training loss: 2.1832706928253174
Validation loss: 2.0497644941012063

Epoch: 6| Step: 7
Training loss: 1.9812580347061157
Validation loss: 2.0538586179415383

Epoch: 6| Step: 8
Training loss: 2.2751407623291016
Validation loss: 2.05051322778066

Epoch: 6| Step: 9
Training loss: 1.8782808780670166
Validation loss: 2.05473925669988

Epoch: 6| Step: 10
Training loss: 2.2022860050201416
Validation loss: 2.059255679448446

Epoch: 6| Step: 11
Training loss: 1.8771576881408691
Validation loss: 2.0596449176470437

Epoch: 6| Step: 12
Training loss: 2.249114513397217
Validation loss: 2.0522901018460593

Epoch: 6| Step: 13
Training loss: 2.56113338470459
Validation loss: 2.046526074409485

Epoch: 126| Step: 0
Training loss: 1.5283946990966797
Validation loss: 2.052994430065155

Epoch: 6| Step: 1
Training loss: 2.667764663696289
Validation loss: 2.051390528678894

Epoch: 6| Step: 2
Training loss: 1.8855078220367432
Validation loss: 2.058623512585958

Epoch: 6| Step: 3
Training loss: 2.2581851482391357
Validation loss: 2.0691216389338174

Epoch: 6| Step: 4
Training loss: 2.402125358581543
Validation loss: 2.0712486505508423

Epoch: 6| Step: 5
Training loss: 1.7833857536315918
Validation loss: 2.0680033961931863

Epoch: 6| Step: 6
Training loss: 2.411762237548828
Validation loss: 2.057743469874064

Epoch: 6| Step: 7
Training loss: 2.4107000827789307
Validation loss: 2.0431981881459556

Epoch: 6| Step: 8
Training loss: 2.0678982734680176
Validation loss: 2.0413782000541687

Epoch: 6| Step: 9
Training loss: 1.812893271446228
Validation loss: 2.0368714332580566

Epoch: 6| Step: 10
Training loss: 2.0811078548431396
Validation loss: 2.0352859497070312

Epoch: 6| Step: 11
Training loss: 1.8183743953704834
Validation loss: 2.041709760824839

Epoch: 6| Step: 12
Training loss: 1.8697547912597656
Validation loss: 2.0384216705958047

Epoch: 6| Step: 13
Training loss: 1.6800243854522705
Validation loss: 2.033775011698405

Epoch: 127| Step: 0
Training loss: 2.3538875579833984
Validation loss: 2.034401535987854

Epoch: 6| Step: 1
Training loss: 1.8191555738449097
Validation loss: 2.0279540419578552

Epoch: 6| Step: 2
Training loss: 1.5192761421203613
Validation loss: 2.035486857096354

Epoch: 6| Step: 3
Training loss: 1.9176864624023438
Validation loss: 2.034160017967224

Epoch: 6| Step: 4
Training loss: 2.1479625701904297
Validation loss: 2.0339305996894836

Epoch: 6| Step: 5
Training loss: 2.2210135459899902
Validation loss: 2.045620322227478

Epoch: 6| Step: 6
Training loss: 2.2659177780151367
Validation loss: 2.0438884099324546

Epoch: 6| Step: 7
Training loss: 2.193044662475586
Validation loss: 2.0471574664115906

Epoch: 6| Step: 8
Training loss: 1.9080843925476074
Validation loss: 2.064619541168213

Epoch: 6| Step: 9
Training loss: 2.0960805416107178
Validation loss: 2.064192056655884

Epoch: 6| Step: 10
Training loss: 1.781798243522644
Validation loss: 2.0526745518048606

Epoch: 6| Step: 11
Training loss: 2.474407196044922
Validation loss: 2.074505885442098

Epoch: 6| Step: 12
Training loss: 1.625270128250122
Validation loss: 2.0879411498705545

Epoch: 6| Step: 13
Training loss: 2.1546292304992676
Validation loss: 2.082190771897634

Epoch: 128| Step: 0
Training loss: 2.055671215057373
Validation loss: 2.074808100859324

Epoch: 6| Step: 1
Training loss: 2.2380361557006836
Validation loss: 2.07002717256546

Epoch: 6| Step: 2
Training loss: 1.8366942405700684
Validation loss: 2.0684475898742676

Epoch: 6| Step: 3
Training loss: 1.883079171180725
Validation loss: 2.066523869832357

Epoch: 6| Step: 4
Training loss: 2.4981794357299805
Validation loss: 2.0550819635391235

Epoch: 6| Step: 5
Training loss: 1.509305477142334
Validation loss: 2.0555395086606345

Epoch: 6| Step: 6
Training loss: 2.630270004272461
Validation loss: 2.044650355974833

Epoch: 6| Step: 7
Training loss: 1.7269182205200195
Validation loss: 2.0373809536298118

Epoch: 6| Step: 8
Training loss: 1.5071966648101807
Validation loss: 2.0412274400393167

Epoch: 6| Step: 9
Training loss: 2.2517318725585938
Validation loss: 2.0398633082707724

Epoch: 6| Step: 10
Training loss: 2.253603219985962
Validation loss: 2.044107437133789

Epoch: 6| Step: 11
Training loss: 2.870295524597168
Validation loss: 2.045747756958008

Epoch: 6| Step: 12
Training loss: 1.6424353122711182
Validation loss: 2.0446624557177224

Epoch: 6| Step: 13
Training loss: 1.9952775239944458
Validation loss: 2.0497674147288003

Epoch: 129| Step: 0
Training loss: 1.9468965530395508
Validation loss: 2.0534751415252686

Epoch: 6| Step: 1
Training loss: 2.273092746734619
Validation loss: 2.052306612332662

Epoch: 6| Step: 2
Training loss: 1.7577130794525146
Validation loss: 2.060473362604777

Epoch: 6| Step: 3
Training loss: 2.234156608581543
Validation loss: 2.065900444984436

Epoch: 6| Step: 4
Training loss: 2.5715513229370117
Validation loss: 2.0747827688852944

Epoch: 6| Step: 5
Training loss: 2.3145172595977783
Validation loss: 2.0669021805127463

Epoch: 6| Step: 6
Training loss: 1.918544888496399
Validation loss: 2.0584568778673806

Epoch: 6| Step: 7
Training loss: 1.8051302433013916
Validation loss: 2.055220603942871

Epoch: 6| Step: 8
Training loss: 2.135223865509033
Validation loss: 2.064832886060079

Epoch: 6| Step: 9
Training loss: 2.02173113822937
Validation loss: 2.0667618115743003

Epoch: 6| Step: 10
Training loss: 1.4277311563491821
Validation loss: 2.0621654192606607

Epoch: 6| Step: 11
Training loss: 2.4135212898254395
Validation loss: 2.0686886509259543

Epoch: 6| Step: 12
Training loss: 1.526158094406128
Validation loss: 2.0727093617121377

Epoch: 6| Step: 13
Training loss: 2.074199914932251
Validation loss: 2.064317981402079

Epoch: 130| Step: 0
Training loss: 1.468308448791504
Validation loss: 2.075725018978119

Epoch: 6| Step: 1
Training loss: 1.426532506942749
Validation loss: 2.059676249821981

Epoch: 6| Step: 2
Training loss: 1.9297034740447998
Validation loss: 2.054404079914093

Epoch: 6| Step: 3
Training loss: 2.063426971435547
Validation loss: 2.058505892753601

Epoch: 6| Step: 4
Training loss: 2.5400500297546387
Validation loss: 2.058749516805013

Epoch: 6| Step: 5
Training loss: 2.1481807231903076
Validation loss: 2.047492523988088

Epoch: 6| Step: 6
Training loss: 2.067009449005127
Validation loss: 2.0538748701413474

Epoch: 6| Step: 7
Training loss: 1.9136754274368286
Validation loss: 2.0480939944585166

Epoch: 6| Step: 8
Training loss: 2.0212903022766113
Validation loss: 2.066624402999878

Epoch: 6| Step: 9
Training loss: 1.9317086935043335
Validation loss: 2.082488159338633

Epoch: 6| Step: 10
Training loss: 1.9120616912841797
Validation loss: 2.0762222607930503

Epoch: 6| Step: 11
Training loss: 2.340650796890259
Validation loss: 2.098014752070109

Epoch: 6| Step: 12
Training loss: 2.6196627616882324
Validation loss: 2.076732893784841

Epoch: 6| Step: 13
Training loss: 2.2819952964782715
Validation loss: 2.099616269270579

Epoch: 131| Step: 0
Training loss: 2.0381312370300293
Validation loss: 2.0861677726109824

Epoch: 6| Step: 1
Training loss: 1.8211153745651245
Validation loss: 2.0873764157295227

Epoch: 6| Step: 2
Training loss: 1.7658052444458008
Validation loss: 2.0954695542653403

Epoch: 6| Step: 3
Training loss: 2.5596446990966797
Validation loss: 2.0957732597986856

Epoch: 6| Step: 4
Training loss: 2.271681547164917
Validation loss: 2.102259357770284

Epoch: 6| Step: 5
Training loss: 1.7851743698120117
Validation loss: 2.088915010293325

Epoch: 6| Step: 6
Training loss: 2.1839160919189453
Validation loss: 2.072148243586222

Epoch: 6| Step: 7
Training loss: 2.55684494972229
Validation loss: 2.067570666472117

Epoch: 6| Step: 8
Training loss: 1.7591418027877808
Validation loss: 2.07316263516744

Epoch: 6| Step: 9
Training loss: 2.226107120513916
Validation loss: 2.0729098518689475

Epoch: 6| Step: 10
Training loss: 1.5894317626953125
Validation loss: 2.0737367272377014

Epoch: 6| Step: 11
Training loss: 1.8611254692077637
Validation loss: 2.0598944822947183

Epoch: 6| Step: 12
Training loss: 1.8584258556365967
Validation loss: 2.066177229086558

Epoch: 6| Step: 13
Training loss: 1.9332880973815918
Validation loss: 2.0553104082743325

Epoch: 132| Step: 0
Training loss: 1.4696340560913086
Validation loss: 2.0499709447224936

Epoch: 6| Step: 1
Training loss: 1.8841941356658936
Validation loss: 2.061314423878988

Epoch: 6| Step: 2
Training loss: 1.9051463603973389
Validation loss: 2.060913364092509

Epoch: 6| Step: 3
Training loss: 2.2360734939575195
Validation loss: 2.044953465461731

Epoch: 6| Step: 4
Training loss: 2.7593390941619873
Validation loss: 2.047050138314565

Epoch: 6| Step: 5
Training loss: 1.5167665481567383
Validation loss: 2.0470536947250366

Epoch: 6| Step: 6
Training loss: 2.5246219635009766
Validation loss: 2.0434419910113015

Epoch: 6| Step: 7
Training loss: 1.7862889766693115
Validation loss: 2.045949379603068

Epoch: 6| Step: 8
Training loss: 1.7091091871261597
Validation loss: 2.0538310408592224

Epoch: 6| Step: 9
Training loss: 1.8071390390396118
Validation loss: 2.053741157054901

Epoch: 6| Step: 10
Training loss: 2.1360554695129395
Validation loss: 2.0600094397862754

Epoch: 6| Step: 11
Training loss: 2.2572171688079834
Validation loss: 2.0607158541679382

Epoch: 6| Step: 12
Training loss: 2.379755973815918
Validation loss: 2.0809914469718933

Epoch: 6| Step: 13
Training loss: 2.1110129356384277
Validation loss: 2.0910874803860984

Epoch: 133| Step: 0
Training loss: 2.2744157314300537
Validation loss: 2.091468592484792

Epoch: 6| Step: 1
Training loss: 1.9305284023284912
Validation loss: 2.0943506757418313

Epoch: 6| Step: 2
Training loss: 2.1726040840148926
Validation loss: 2.112809697786967

Epoch: 6| Step: 3
Training loss: 1.8765950202941895
Validation loss: 2.118773599465688

Epoch: 6| Step: 4
Training loss: 2.2395718097686768
Validation loss: 2.1050010919570923

Epoch: 6| Step: 5
Training loss: 2.0267014503479004
Validation loss: 2.109132548173269

Epoch: 6| Step: 6
Training loss: 2.4194495677948
Validation loss: 2.0966346661249795

Epoch: 6| Step: 7
Training loss: 1.5122694969177246
Validation loss: 2.082668960094452

Epoch: 6| Step: 8
Training loss: 1.5617481470108032
Validation loss: 2.0702481468518577

Epoch: 6| Step: 9
Training loss: 1.9369843006134033
Validation loss: 2.063818415006002

Epoch: 6| Step: 10
Training loss: 2.7861828804016113
Validation loss: 2.0568774938583374

Epoch: 6| Step: 11
Training loss: 1.7324292659759521
Validation loss: 2.059910476207733

Epoch: 6| Step: 12
Training loss: 2.0969953536987305
Validation loss: 2.053718407948812

Epoch: 6| Step: 13
Training loss: 2.0224862098693848
Validation loss: 2.053412139415741

Epoch: 134| Step: 0
Training loss: 1.8236801624298096
Validation loss: 2.060277243455251

Epoch: 6| Step: 1
Training loss: 1.9525448083877563
Validation loss: 2.0592825214068093

Epoch: 6| Step: 2
Training loss: 2.284275531768799
Validation loss: 2.0602418382962546

Epoch: 6| Step: 3
Training loss: 1.4575861692428589
Validation loss: 2.0669681231180825

Epoch: 6| Step: 4
Training loss: 2.1297240257263184
Validation loss: 2.072343389193217

Epoch: 6| Step: 5
Training loss: 2.1825790405273438
Validation loss: 2.079906642436981

Epoch: 6| Step: 6
Training loss: 1.6942960023880005
Validation loss: 2.084645469983419

Epoch: 6| Step: 7
Training loss: 2.1963539123535156
Validation loss: 2.1010202964146933

Epoch: 6| Step: 8
Training loss: 2.2261087894439697
Validation loss: 2.1025859316190085

Epoch: 6| Step: 9
Training loss: 1.9465299844741821
Validation loss: 2.1090166568756104

Epoch: 6| Step: 10
Training loss: 1.9717235565185547
Validation loss: 2.0954658587773642

Epoch: 6| Step: 11
Training loss: 2.194571018218994
Validation loss: 2.094025433063507

Epoch: 6| Step: 12
Training loss: 1.9074091911315918
Validation loss: 2.0892478624979653

Epoch: 6| Step: 13
Training loss: 2.4429163932800293
Validation loss: 2.0713419715563455

Epoch: 135| Step: 0
Training loss: 2.3354268074035645
Validation loss: 2.076618731021881

Epoch: 6| Step: 1
Training loss: 1.4839696884155273
Validation loss: 2.0702983339627585

Epoch: 6| Step: 2
Training loss: 1.832343578338623
Validation loss: 2.0736075043678284

Epoch: 6| Step: 3
Training loss: 2.088595390319824
Validation loss: 2.101720949014028

Epoch: 6| Step: 4
Training loss: 1.3242000341415405
Validation loss: 2.109755516052246

Epoch: 6| Step: 5
Training loss: 2.1695733070373535
Validation loss: 2.097110708554586

Epoch: 6| Step: 6
Training loss: 2.0766870975494385
Validation loss: 2.094044248263041

Epoch: 6| Step: 7
Training loss: 1.9755284786224365
Validation loss: 2.091146151224772

Epoch: 6| Step: 8
Training loss: 1.9896790981292725
Validation loss: 2.092053254445394

Epoch: 6| Step: 9
Training loss: 2.006239414215088
Validation loss: 2.087811509768168

Epoch: 6| Step: 10
Training loss: 1.871403694152832
Validation loss: 2.0658480723698935

Epoch: 6| Step: 11
Training loss: 2.5292365550994873
Validation loss: 2.0700824856758118

Epoch: 6| Step: 12
Training loss: 1.8235541582107544
Validation loss: 2.063457190990448

Epoch: 6| Step: 13
Training loss: 2.6914265155792236
Validation loss: 2.054834763209025

Epoch: 136| Step: 0
Training loss: 2.2020983695983887
Validation loss: 2.0479586124420166

Epoch: 6| Step: 1
Training loss: 2.6062350273132324
Validation loss: 2.053888281186422

Epoch: 6| Step: 2
Training loss: 1.7376055717468262
Validation loss: 2.0536107222239175

Epoch: 6| Step: 3
Training loss: 1.9844822883605957
Validation loss: 2.0493218104044595

Epoch: 6| Step: 4
Training loss: 2.011726140975952
Validation loss: 2.0651473999023438

Epoch: 6| Step: 5
Training loss: 1.721634864807129
Validation loss: 2.0701881647109985

Epoch: 6| Step: 6
Training loss: 1.8674821853637695
Validation loss: 2.0687174995740256

Epoch: 6| Step: 7
Training loss: 1.816341757774353
Validation loss: 2.0748385389645896

Epoch: 6| Step: 8
Training loss: 1.8146673440933228
Validation loss: 2.097694714864095

Epoch: 6| Step: 9
Training loss: 1.758240818977356
Validation loss: 2.090664784113566

Epoch: 6| Step: 10
Training loss: 2.716660499572754
Validation loss: 2.0956143736839294

Epoch: 6| Step: 11
Training loss: 2.380063772201538
Validation loss: 2.1038061380386353

Epoch: 6| Step: 12
Training loss: 1.3730255365371704
Validation loss: 2.1080338954925537

Epoch: 6| Step: 13
Training loss: 2.3321423530578613
Validation loss: 2.1007461547851562

Epoch: 137| Step: 0
Training loss: 1.775231122970581
Validation loss: 2.099291682243347

Epoch: 6| Step: 1
Training loss: 2.0687367916107178
Validation loss: 2.085849722226461

Epoch: 6| Step: 2
Training loss: 1.978362798690796
Validation loss: 2.077640970547994

Epoch: 6| Step: 3
Training loss: 1.8600150346755981
Validation loss: 2.0767733256022134

Epoch: 6| Step: 4
Training loss: 1.953965187072754
Validation loss: 2.07985782623291

Epoch: 6| Step: 5
Training loss: 2.4870872497558594
Validation loss: 2.063262701034546

Epoch: 6| Step: 6
Training loss: 1.8278950452804565
Validation loss: 2.056836108366648

Epoch: 6| Step: 7
Training loss: 2.2894129753112793
Validation loss: 2.053976595401764

Epoch: 6| Step: 8
Training loss: 2.0938520431518555
Validation loss: 2.0673649509747825

Epoch: 6| Step: 9
Training loss: 1.8760666847229004
Validation loss: 2.061100343863169

Epoch: 6| Step: 10
Training loss: 2.1115407943725586
Validation loss: 2.060730457305908

Epoch: 6| Step: 11
Training loss: 1.7329457998275757
Validation loss: 2.0607407689094543

Epoch: 6| Step: 12
Training loss: 2.1741185188293457
Validation loss: 2.068481465180715

Epoch: 6| Step: 13
Training loss: 1.7493925094604492
Validation loss: 2.0594645539919534

Epoch: 138| Step: 0
Training loss: 1.7866621017456055
Validation loss: 2.0745407144228616

Epoch: 6| Step: 1
Training loss: 1.5161467790603638
Validation loss: 2.0791623989741006

Epoch: 6| Step: 2
Training loss: 2.266514539718628
Validation loss: 2.090197046597799

Epoch: 6| Step: 3
Training loss: 2.0030810832977295
Validation loss: 2.0964107314745584

Epoch: 6| Step: 4
Training loss: 1.832287073135376
Validation loss: 2.106765925884247

Epoch: 6| Step: 5
Training loss: 2.7785539627075195
Validation loss: 2.1207337776819863

Epoch: 6| Step: 6
Training loss: 1.6485397815704346
Validation loss: 2.1065906484921775

Epoch: 6| Step: 7
Training loss: 1.21720290184021
Validation loss: 2.1004512707392373

Epoch: 6| Step: 8
Training loss: 2.3324153423309326
Validation loss: 2.0951768358548484

Epoch: 6| Step: 9
Training loss: 1.8465582132339478
Validation loss: 2.0707024534543357

Epoch: 6| Step: 10
Training loss: 2.2931480407714844
Validation loss: 2.0730737845102944

Epoch: 6| Step: 11
Training loss: 1.9906456470489502
Validation loss: 2.0532522598902383

Epoch: 6| Step: 12
Training loss: 2.4998531341552734
Validation loss: 2.0459021727244058

Epoch: 6| Step: 13
Training loss: 2.4492835998535156
Validation loss: 2.0492785573005676

Epoch: 139| Step: 0
Training loss: 1.9216792583465576
Validation loss: 2.0551841259002686

Epoch: 6| Step: 1
Training loss: 2.1177451610565186
Validation loss: 2.0509164134661355

Epoch: 6| Step: 2
Training loss: 2.076901435852051
Validation loss: 2.0495205521583557

Epoch: 6| Step: 3
Training loss: 2.0805864334106445
Validation loss: 2.0585349003473916

Epoch: 6| Step: 4
Training loss: 1.7757632732391357
Validation loss: 2.0561843713124595

Epoch: 6| Step: 5
Training loss: 1.4569547176361084
Validation loss: 2.059038976828257

Epoch: 6| Step: 6
Training loss: 2.1924800872802734
Validation loss: 2.068640947341919

Epoch: 6| Step: 7
Training loss: 2.2624216079711914
Validation loss: 2.066715975602468

Epoch: 6| Step: 8
Training loss: 2.0365750789642334
Validation loss: 2.0736663341522217

Epoch: 6| Step: 9
Training loss: 1.7137455940246582
Validation loss: 2.080950081348419

Epoch: 6| Step: 10
Training loss: 2.4083707332611084
Validation loss: 2.0914644996325173

Epoch: 6| Step: 11
Training loss: 2.4484057426452637
Validation loss: 2.081980566183726

Epoch: 6| Step: 12
Training loss: 2.065699815750122
Validation loss: 2.088379184405009

Epoch: 6| Step: 13
Training loss: 1.6059222221374512
Validation loss: 2.086981236934662

Epoch: 140| Step: 0
Training loss: 2.038750171661377
Validation loss: 2.0837072928746543

Epoch: 6| Step: 1
Training loss: 1.9130866527557373
Validation loss: 2.091295142968496

Epoch: 6| Step: 2
Training loss: 1.4080915451049805
Validation loss: 2.1046546697616577

Epoch: 6| Step: 3
Training loss: 2.1667323112487793
Validation loss: 2.0910818775494895

Epoch: 6| Step: 4
Training loss: 2.123157501220703
Validation loss: 2.093651910622915

Epoch: 6| Step: 5
Training loss: 2.184922933578491
Validation loss: 2.0949599742889404

Epoch: 6| Step: 6
Training loss: 1.9646210670471191
Validation loss: 2.0809802214304605

Epoch: 6| Step: 7
Training loss: 1.326143741607666
Validation loss: 2.0862698554992676

Epoch: 6| Step: 8
Training loss: 2.115307092666626
Validation loss: 2.08796497186025

Epoch: 6| Step: 9
Training loss: 2.207538604736328
Validation loss: 2.089283029238383

Epoch: 6| Step: 10
Training loss: 2.2746996879577637
Validation loss: 2.0905940532684326

Epoch: 6| Step: 11
Training loss: 1.9116425514221191
Validation loss: 2.084136744340261

Epoch: 6| Step: 12
Training loss: 1.8782168626785278
Validation loss: 2.07931254307429

Epoch: 6| Step: 13
Training loss: 2.3730809688568115
Validation loss: 2.0914169351259866

Epoch: 141| Step: 0
Training loss: 1.833203911781311
Validation loss: 2.093424161275228

Epoch: 6| Step: 1
Training loss: 1.6577430963516235
Validation loss: 2.0909595489501953

Epoch: 6| Step: 2
Training loss: 1.9361178874969482
Validation loss: 2.092692812283834

Epoch: 6| Step: 3
Training loss: 1.7657830715179443
Validation loss: 2.110067307949066

Epoch: 6| Step: 4
Training loss: 1.8479200601577759
Validation loss: 2.09948468208313

Epoch: 6| Step: 5
Training loss: 2.4417781829833984
Validation loss: 2.103396157423655

Epoch: 6| Step: 6
Training loss: 1.955979347229004
Validation loss: 2.097512364387512

Epoch: 6| Step: 7
Training loss: 1.8238545656204224
Validation loss: 2.115382115046183

Epoch: 6| Step: 8
Training loss: 2.1174769401550293
Validation loss: 2.093687375386556

Epoch: 6| Step: 9
Training loss: 2.3973915576934814
Validation loss: 2.0915429393450418

Epoch: 6| Step: 10
Training loss: 2.277883768081665
Validation loss: 2.084586441516876

Epoch: 6| Step: 11
Training loss: 1.8120522499084473
Validation loss: 2.0936667720476785

Epoch: 6| Step: 12
Training loss: 1.7506518363952637
Validation loss: 2.084217449029287

Epoch: 6| Step: 13
Training loss: 2.294041633605957
Validation loss: 2.0882604718208313

Epoch: 142| Step: 0
Training loss: 1.61336088180542
Validation loss: 2.0740140080451965

Epoch: 6| Step: 1
Training loss: 2.152520179748535
Validation loss: 2.0850104093551636

Epoch: 6| Step: 2
Training loss: 1.802045464515686
Validation loss: 2.0902729630470276

Epoch: 6| Step: 3
Training loss: 2.347013473510742
Validation loss: 2.0909289717674255

Epoch: 6| Step: 4
Training loss: 1.7163110971450806
Validation loss: 2.081100662549337

Epoch: 6| Step: 5
Training loss: 1.9776344299316406
Validation loss: 2.0896540681521096

Epoch: 6| Step: 6
Training loss: 2.127920389175415
Validation loss: 2.094416300455729

Epoch: 6| Step: 7
Training loss: 1.9016155004501343
Validation loss: 2.1039123137791953

Epoch: 6| Step: 8
Training loss: 2.010192394256592
Validation loss: 2.097637335459391

Epoch: 6| Step: 9
Training loss: 2.7721424102783203
Validation loss: 2.121004343032837

Epoch: 6| Step: 10
Training loss: 1.8522940874099731
Validation loss: 2.1119872331619263

Epoch: 6| Step: 11
Training loss: 2.36430287361145
Validation loss: 2.1254049936930337

Epoch: 6| Step: 12
Training loss: 1.70908784866333
Validation loss: 2.1174538930257163

Epoch: 6| Step: 13
Training loss: 1.6740126609802246
Validation loss: 2.1024301449457803

Epoch: 143| Step: 0
Training loss: 1.537825107574463
Validation loss: 2.099723299344381

Epoch: 6| Step: 1
Training loss: 2.335050582885742
Validation loss: 2.0855316122372947

Epoch: 6| Step: 2
Training loss: 1.7589027881622314
Validation loss: 2.080725312232971

Epoch: 6| Step: 3
Training loss: 2.607753038406372
Validation loss: 2.0760307709376016

Epoch: 6| Step: 4
Training loss: 1.5858761072158813
Validation loss: 2.076801876227061

Epoch: 6| Step: 5
Training loss: 1.9281253814697266
Validation loss: 2.072202146053314

Epoch: 6| Step: 6
Training loss: 1.70272696018219
Validation loss: 2.068834344546

Epoch: 6| Step: 7
Training loss: 2.553957462310791
Validation loss: 2.0761255025863647

Epoch: 6| Step: 8
Training loss: 2.2527096271514893
Validation loss: 2.070162316163381

Epoch: 6| Step: 9
Training loss: 2.0644853115081787
Validation loss: 2.0713329911231995

Epoch: 6| Step: 10
Training loss: 2.0200839042663574
Validation loss: 2.0632965564727783

Epoch: 6| Step: 11
Training loss: 1.8251771926879883
Validation loss: 2.0741791129112244

Epoch: 6| Step: 12
Training loss: 1.4393879175186157
Validation loss: 2.082017242908478

Epoch: 6| Step: 13
Training loss: 2.3626198768615723
Validation loss: 2.099024852116903

Epoch: 144| Step: 0
Training loss: 2.543029308319092
Validation loss: 2.095820188522339

Epoch: 6| Step: 1
Training loss: 1.7612619400024414
Validation loss: 2.104994793732961

Epoch: 6| Step: 2
Training loss: 1.704737663269043
Validation loss: 2.1033965746561685

Epoch: 6| Step: 3
Training loss: 1.8340450525283813
Validation loss: 2.1053274273872375

Epoch: 6| Step: 4
Training loss: 1.9219388961791992
Validation loss: 2.0979843537012735

Epoch: 6| Step: 5
Training loss: 1.9592227935791016
Validation loss: 2.0848198334376016

Epoch: 6| Step: 6
Training loss: 1.652557373046875
Validation loss: 2.085378646850586

Epoch: 6| Step: 7
Training loss: 2.067566156387329
Validation loss: 2.076259116331736

Epoch: 6| Step: 8
Training loss: 2.3215856552124023
Validation loss: 2.0785566568374634

Epoch: 6| Step: 9
Training loss: 2.070129156112671
Validation loss: 2.08185476064682

Epoch: 6| Step: 10
Training loss: 2.293091297149658
Validation loss: 2.0786869724591575

Epoch: 6| Step: 11
Training loss: 1.6563076972961426
Validation loss: 2.094816267490387

Epoch: 6| Step: 12
Training loss: 2.3710598945617676
Validation loss: 2.0849000811576843

Epoch: 6| Step: 13
Training loss: 1.629636287689209
Validation loss: 2.091171065966288

Epoch: 145| Step: 0
Training loss: 1.9990882873535156
Validation loss: 2.1067925890286765

Epoch: 6| Step: 1
Training loss: 2.251601219177246
Validation loss: 2.119383990764618

Epoch: 6| Step: 2
Training loss: 2.4645657539367676
Validation loss: 2.1252721548080444

Epoch: 6| Step: 3
Training loss: 2.111656665802002
Validation loss: 2.1384539206822715

Epoch: 6| Step: 4
Training loss: 1.697230577468872
Validation loss: 2.121645669142405

Epoch: 6| Step: 5
Training loss: 1.8416117429733276
Validation loss: 2.110306362311045

Epoch: 6| Step: 6
Training loss: 1.8524316549301147
Validation loss: 2.0928850173950195

Epoch: 6| Step: 7
Training loss: 2.006446361541748
Validation loss: 2.0783104499181113

Epoch: 6| Step: 8
Training loss: 1.7419785261154175
Validation loss: 2.078137675921122

Epoch: 6| Step: 9
Training loss: 2.2386350631713867
Validation loss: 2.0653929313023887

Epoch: 6| Step: 10
Training loss: 1.5960969924926758
Validation loss: 2.0483244260152182

Epoch: 6| Step: 11
Training loss: 2.588076114654541
Validation loss: 2.048568765322367

Epoch: 6| Step: 12
Training loss: 1.8592132329940796
Validation loss: 2.050334890683492

Epoch: 6| Step: 13
Training loss: 2.228522539138794
Validation loss: 2.0514658292134604

Epoch: 146| Step: 0
Training loss: 2.066071033477783
Validation loss: 2.0497008562088013

Epoch: 6| Step: 1
Training loss: 1.8408794403076172
Validation loss: 2.055910507837931

Epoch: 6| Step: 2
Training loss: 2.1972365379333496
Validation loss: 2.0542356769243875

Epoch: 6| Step: 3
Training loss: 1.608886480331421
Validation loss: 2.067583421866099

Epoch: 6| Step: 4
Training loss: 1.941701889038086
Validation loss: 2.078292508920034

Epoch: 6| Step: 5
Training loss: 2.220695972442627
Validation loss: 2.0865626335144043

Epoch: 6| Step: 6
Training loss: 2.273240089416504
Validation loss: 2.0947465101877847

Epoch: 6| Step: 7
Training loss: 1.9475427865982056
Validation loss: 2.1120010217030845

Epoch: 6| Step: 8
Training loss: 1.7505309581756592
Validation loss: 2.1009192864100137

Epoch: 6| Step: 9
Training loss: 1.5064505338668823
Validation loss: 2.125695804754893

Epoch: 6| Step: 10
Training loss: 2.3223509788513184
Validation loss: 2.1337132255236306

Epoch: 6| Step: 11
Training loss: 2.3154759407043457
Validation loss: 2.1371235847473145

Epoch: 6| Step: 12
Training loss: 2.347881555557251
Validation loss: 2.137143313884735

Epoch: 6| Step: 13
Training loss: 1.7845836877822876
Validation loss: 2.1426600217819214

Epoch: 147| Step: 0
Training loss: 2.2806777954101562
Validation loss: 2.1234960754712424

Epoch: 6| Step: 1
Training loss: 2.106905221939087
Validation loss: 2.1070223450660706

Epoch: 6| Step: 2
Training loss: 1.4292418956756592
Validation loss: 2.1031118035316467

Epoch: 6| Step: 3
Training loss: 2.4642810821533203
Validation loss: 2.1004026333491006

Epoch: 6| Step: 4
Training loss: 1.866296410560608
Validation loss: 2.104743758837382

Epoch: 6| Step: 5
Training loss: 2.0555338859558105
Validation loss: 2.119646648565928

Epoch: 6| Step: 6
Training loss: 2.141652822494507
Validation loss: 2.0995583732922873

Epoch: 6| Step: 7
Training loss: 1.659381628036499
Validation loss: 2.106890559196472

Epoch: 6| Step: 8
Training loss: 2.018663167953491
Validation loss: 2.1064369678497314

Epoch: 6| Step: 9
Training loss: 1.895195484161377
Validation loss: 2.0948321421941123

Epoch: 6| Step: 10
Training loss: 1.5278599262237549
Validation loss: 2.0906569560368857

Epoch: 6| Step: 11
Training loss: 1.945444107055664
Validation loss: 2.084502915541331

Epoch: 6| Step: 12
Training loss: 2.40653133392334
Validation loss: 2.082876682281494

Epoch: 6| Step: 13
Training loss: 1.8502451181411743
Validation loss: 2.0896475116411843

Epoch: 148| Step: 0
Training loss: 2.8485941886901855
Validation loss: 2.0917694568634033

Epoch: 6| Step: 1
Training loss: 2.008629560470581
Validation loss: 2.1107762853304544

Epoch: 6| Step: 2
Training loss: 1.1577913761138916
Validation loss: 2.110978841781616

Epoch: 6| Step: 3
Training loss: 1.4734522104263306
Validation loss: 2.1164064606030784

Epoch: 6| Step: 4
Training loss: 2.065606117248535
Validation loss: 2.1137086749076843

Epoch: 6| Step: 5
Training loss: 1.7302134037017822
Validation loss: 2.1342559258143106

Epoch: 6| Step: 6
Training loss: 2.6643245220184326
Validation loss: 2.1377729574839273

Epoch: 6| Step: 7
Training loss: 2.100308418273926
Validation loss: 2.132362484931946

Epoch: 6| Step: 8
Training loss: 2.245220184326172
Validation loss: 2.1226775646209717

Epoch: 6| Step: 9
Training loss: 2.1410412788391113
Validation loss: 2.120081643263499

Epoch: 6| Step: 10
Training loss: 1.91007661819458
Validation loss: 2.1011374592781067

Epoch: 6| Step: 11
Training loss: 1.6545498371124268
Validation loss: 2.0817357699076333

Epoch: 6| Step: 12
Training loss: 2.104612350463867
Validation loss: 2.0865210692087808

Epoch: 6| Step: 13
Training loss: 1.790060043334961
Validation loss: 2.082177778085073

Epoch: 149| Step: 0
Training loss: 1.8620262145996094
Validation loss: 2.0707138975461326

Epoch: 6| Step: 1
Training loss: 1.53989839553833
Validation loss: 2.071358303229014

Epoch: 6| Step: 2
Training loss: 1.6970391273498535
Validation loss: 2.0645132263501487

Epoch: 6| Step: 3
Training loss: 2.467480182647705
Validation loss: 2.0615614652633667

Epoch: 6| Step: 4
Training loss: 2.440005302429199
Validation loss: 2.061436712741852

Epoch: 6| Step: 5
Training loss: 2.128993034362793
Validation loss: 2.063578645388285

Epoch: 6| Step: 6
Training loss: 1.9964056015014648
Validation loss: 2.068794906139374

Epoch: 6| Step: 7
Training loss: 1.8629262447357178
Validation loss: 2.0750014583269754

Epoch: 6| Step: 8
Training loss: 2.4284274578094482
Validation loss: 2.0901902119318643

Epoch: 6| Step: 9
Training loss: 2.610992670059204
Validation loss: 2.0933662056922913

Epoch: 6| Step: 10
Training loss: 1.539168119430542
Validation loss: 2.1061690847078958

Epoch: 6| Step: 11
Training loss: 1.4359550476074219
Validation loss: 2.1085020303726196

Epoch: 6| Step: 12
Training loss: 1.4949437379837036
Validation loss: 2.117199420928955

Epoch: 6| Step: 13
Training loss: 2.4962358474731445
Validation loss: 2.1375858783721924

Epoch: 150| Step: 0
Training loss: 1.5804471969604492
Validation loss: 2.144068419933319

Epoch: 6| Step: 1
Training loss: 2.142651081085205
Validation loss: 2.16424290339152

Epoch: 6| Step: 2
Training loss: 2.057753562927246
Validation loss: 2.1555179754892984

Epoch: 6| Step: 3
Training loss: 1.8632965087890625
Validation loss: 2.1545977195103965

Epoch: 6| Step: 4
Training loss: 2.004946708679199
Validation loss: 2.1419597069422402

Epoch: 6| Step: 5
Training loss: 1.5753554105758667
Validation loss: 2.143855353196462

Epoch: 6| Step: 6
Training loss: 2.1426987648010254
Validation loss: 2.124137818813324

Epoch: 6| Step: 7
Training loss: 2.02437686920166
Validation loss: 2.108623425165812

Epoch: 6| Step: 8
Training loss: 1.9891457557678223
Validation loss: 2.0988612373669944

Epoch: 6| Step: 9
Training loss: 1.9878058433532715
Validation loss: 2.080414275328318

Epoch: 6| Step: 10
Training loss: 1.7184542417526245
Validation loss: 2.0761232376098633

Epoch: 6| Step: 11
Training loss: 2.8999974727630615
Validation loss: 2.0695496201515198

Epoch: 6| Step: 12
Training loss: 1.983553171157837
Validation loss: 2.061674873034159

Epoch: 6| Step: 13
Training loss: 1.9655232429504395
Validation loss: 2.0630698800086975

Epoch: 151| Step: 0
Training loss: 2.162670373916626
Validation loss: 2.070782482624054

Epoch: 6| Step: 1
Training loss: 2.2234129905700684
Validation loss: 2.0673235257466636

Epoch: 6| Step: 2
Training loss: 1.9083731174468994
Validation loss: 2.0707324743270874

Epoch: 6| Step: 3
Training loss: 1.6917130947113037
Validation loss: 2.0850995977719626

Epoch: 6| Step: 4
Training loss: 1.823981761932373
Validation loss: 2.084744652112325

Epoch: 6| Step: 5
Training loss: 1.8427014350891113
Validation loss: 2.1000680327415466

Epoch: 6| Step: 6
Training loss: 1.8163641691207886
Validation loss: 2.1067463556925454

Epoch: 6| Step: 7
Training loss: 2.265054225921631
Validation loss: 2.107661763827006

Epoch: 6| Step: 8
Training loss: 2.1381874084472656
Validation loss: 2.094452520211538

Epoch: 6| Step: 9
Training loss: 2.1215438842773438
Validation loss: 2.1031373540560403

Epoch: 6| Step: 10
Training loss: 1.8849151134490967
Validation loss: 2.1196739276250205

Epoch: 6| Step: 11
Training loss: 2.364341974258423
Validation loss: 2.10232013463974

Epoch: 6| Step: 12
Training loss: 2.1529130935668945
Validation loss: 2.1082754135131836

Epoch: 6| Step: 13
Training loss: 1.7018942832946777
Validation loss: 2.0969358881314597

Epoch: 152| Step: 0
Training loss: 1.6494288444519043
Validation loss: 2.1024630864461265

Epoch: 6| Step: 1
Training loss: 2.2779016494750977
Validation loss: 2.109425167242686

Epoch: 6| Step: 2
Training loss: 1.9119994640350342
Validation loss: 2.1045568784077964

Epoch: 6| Step: 3
Training loss: 2.626488208770752
Validation loss: 2.1188300251960754

Epoch: 6| Step: 4
Training loss: 1.632822036743164
Validation loss: 2.1092050870259604

Epoch: 6| Step: 5
Training loss: 1.8336243629455566
Validation loss: 2.110802253087362

Epoch: 6| Step: 6
Training loss: 2.2414774894714355
Validation loss: 2.101531664530436

Epoch: 6| Step: 7
Training loss: 1.6866472959518433
Validation loss: 2.0953526695569358

Epoch: 6| Step: 8
Training loss: 1.866593360900879
Validation loss: 2.088134229183197

Epoch: 6| Step: 9
Training loss: 2.0246288776397705
Validation loss: 2.080093046029409

Epoch: 6| Step: 10
Training loss: 1.7761753797531128
Validation loss: 2.0922801891962686

Epoch: 6| Step: 11
Training loss: 1.8327542543411255
Validation loss: 2.081331968307495

Epoch: 6| Step: 12
Training loss: 2.345856189727783
Validation loss: 2.0873019297917685

Epoch: 6| Step: 13
Training loss: 2.0077271461486816
Validation loss: 2.078319032986959

Epoch: 153| Step: 0
Training loss: 2.536250591278076
Validation loss: 2.0990158716837564

Epoch: 6| Step: 1
Training loss: 1.6589759588241577
Validation loss: 2.1022377610206604

Epoch: 6| Step: 2
Training loss: 1.8604601621627808
Validation loss: 2.0985120733579

Epoch: 6| Step: 3
Training loss: 1.4010417461395264
Validation loss: 2.1037836273511252

Epoch: 6| Step: 4
Training loss: 1.9610159397125244
Validation loss: 2.117442766825358

Epoch: 6| Step: 5
Training loss: 2.319200038909912
Validation loss: 2.107582986354828

Epoch: 6| Step: 6
Training loss: 2.3398303985595703
Validation loss: 2.0981602668762207

Epoch: 6| Step: 7
Training loss: 1.5215989351272583
Validation loss: 2.10042534271876

Epoch: 6| Step: 8
Training loss: 1.9418907165527344
Validation loss: 2.094703654448191

Epoch: 6| Step: 9
Training loss: 1.9157404899597168
Validation loss: 2.112625479698181

Epoch: 6| Step: 10
Training loss: 2.299872875213623
Validation loss: 2.0984397331873574

Epoch: 6| Step: 11
Training loss: 1.6891809701919556
Validation loss: 2.113378584384918

Epoch: 6| Step: 12
Training loss: 2.213696002960205
Validation loss: 2.1174384355545044

Epoch: 6| Step: 13
Training loss: 2.0763986110687256
Validation loss: 2.1063785950342813

Epoch: 154| Step: 0
Training loss: 1.827520728111267
Validation loss: 2.10351300239563

Epoch: 6| Step: 1
Training loss: 1.7648407220840454
Validation loss: 2.110100527604421

Epoch: 6| Step: 2
Training loss: 1.394113302230835
Validation loss: 2.1013657649358115

Epoch: 6| Step: 3
Training loss: 1.9359289407730103
Validation loss: 2.1177144249280295

Epoch: 6| Step: 4
Training loss: 1.2135934829711914
Validation loss: 2.1050788164138794

Epoch: 6| Step: 5
Training loss: 2.0488641262054443
Validation loss: 2.1023242274920144

Epoch: 6| Step: 6
Training loss: 1.9527713060379028
Validation loss: 2.099825700124105

Epoch: 6| Step: 7
Training loss: 1.6638357639312744
Validation loss: 2.08673632144928

Epoch: 6| Step: 8
Training loss: 2.420870542526245
Validation loss: 2.0834292570749917

Epoch: 6| Step: 9
Training loss: 2.408768653869629
Validation loss: 2.082984507083893

Epoch: 6| Step: 10
Training loss: 2.125948429107666
Validation loss: 2.0871166388193765

Epoch: 6| Step: 11
Training loss: 2.701786756515503
Validation loss: 2.0935059189796448

Epoch: 6| Step: 12
Training loss: 2.615302562713623
Validation loss: 2.104646702607473

Epoch: 6| Step: 13
Training loss: 1.6788618564605713
Validation loss: 2.1016913851102195

Epoch: 155| Step: 0
Training loss: 1.8148285150527954
Validation loss: 2.11325736840566

Epoch: 6| Step: 1
Training loss: 2.305203914642334
Validation loss: 2.11325333515803

Epoch: 6| Step: 2
Training loss: 2.0420734882354736
Validation loss: 2.1262703935305276

Epoch: 6| Step: 3
Training loss: 2.2157397270202637
Validation loss: 2.1504231691360474

Epoch: 6| Step: 4
Training loss: 2.6429309844970703
Validation loss: 2.1501049598058066

Epoch: 6| Step: 5
Training loss: 2.1941757202148438
Validation loss: 2.1560272177060447

Epoch: 6| Step: 6
Training loss: 1.58596670627594
Validation loss: 2.1446454524993896

Epoch: 6| Step: 7
Training loss: 2.288632392883301
Validation loss: 2.1361138621966043

Epoch: 6| Step: 8
Training loss: 1.557736873626709
Validation loss: 2.127546747525533

Epoch: 6| Step: 9
Training loss: 1.5101426839828491
Validation loss: 2.113093455632528

Epoch: 6| Step: 10
Training loss: 2.1739635467529297
Validation loss: 2.1007234851519265

Epoch: 6| Step: 11
Training loss: 2.1543705463409424
Validation loss: 2.0942624608675637

Epoch: 6| Step: 12
Training loss: 1.7802188396453857
Validation loss: 2.095322608947754

Epoch: 6| Step: 13
Training loss: 1.325334072113037
Validation loss: 2.089967747529348

Epoch: 156| Step: 0
Training loss: 2.0796616077423096
Validation loss: 2.100261708100637

Epoch: 6| Step: 1
Training loss: 1.9841777086257935
Validation loss: 2.102706789970398

Epoch: 6| Step: 2
Training loss: 1.5881133079528809
Validation loss: 2.085672398408254

Epoch: 6| Step: 3
Training loss: 1.8790771961212158
Validation loss: 2.090261459350586

Epoch: 6| Step: 4
Training loss: 1.8949793577194214
Validation loss: 2.1009554068247476

Epoch: 6| Step: 5
Training loss: 1.900721788406372
Validation loss: 2.1045927007993064

Epoch: 6| Step: 6
Training loss: 2.207395076751709
Validation loss: 2.1080334782600403

Epoch: 6| Step: 7
Training loss: 1.8514747619628906
Validation loss: 2.109852373600006

Epoch: 6| Step: 8
Training loss: 2.403918743133545
Validation loss: 2.1334421237309775

Epoch: 6| Step: 9
Training loss: 2.205549716949463
Validation loss: 2.137270152568817

Epoch: 6| Step: 10
Training loss: 2.293900966644287
Validation loss: 2.141987601915995

Epoch: 6| Step: 11
Training loss: 1.586710810661316
Validation loss: 2.1398791869481406

Epoch: 6| Step: 12
Training loss: 1.8058617115020752
Validation loss: 2.12254536151886

Epoch: 6| Step: 13
Training loss: 2.018874406814575
Validation loss: 2.1115927497545877

Epoch: 157| Step: 0
Training loss: 2.0855867862701416
Validation loss: 2.1096516450246177

Epoch: 6| Step: 1
Training loss: 2.0716373920440674
Validation loss: 2.0946661631266275

Epoch: 6| Step: 2
Training loss: 2.3950448036193848
Validation loss: 2.0852239529291787

Epoch: 6| Step: 3
Training loss: 1.6702799797058105
Validation loss: 2.084925413131714

Epoch: 6| Step: 4
Training loss: 2.0182642936706543
Validation loss: 2.0899317264556885

Epoch: 6| Step: 5
Training loss: 1.9851012229919434
Validation loss: 2.09750759601593

Epoch: 6| Step: 6
Training loss: 1.8625953197479248
Validation loss: 2.0838890075683594

Epoch: 6| Step: 7
Training loss: 2.287301540374756
Validation loss: 2.0930897990862527

Epoch: 6| Step: 8
Training loss: 1.833607792854309
Validation loss: 2.095526119073232

Epoch: 6| Step: 9
Training loss: 2.54055118560791
Validation loss: 2.1081650257110596

Epoch: 6| Step: 10
Training loss: 1.719820261001587
Validation loss: 2.109579781691233

Epoch: 6| Step: 11
Training loss: 1.6009138822555542
Validation loss: 2.105546216169993

Epoch: 6| Step: 12
Training loss: 1.9441472291946411
Validation loss: 2.105736792087555

Epoch: 6| Step: 13
Training loss: 1.773356318473816
Validation loss: 2.1118696133295694

Epoch: 158| Step: 0
Training loss: 2.3486485481262207
Validation loss: 2.109138011932373

Epoch: 6| Step: 1
Training loss: 2.1450488567352295
Validation loss: 2.103781839211782

Epoch: 6| Step: 2
Training loss: 1.5367189645767212
Validation loss: 2.112925668557485

Epoch: 6| Step: 3
Training loss: 1.948246955871582
Validation loss: 2.0983879764874778

Epoch: 6| Step: 4
Training loss: 2.021291732788086
Validation loss: 2.1123454570770264

Epoch: 6| Step: 5
Training loss: 1.87941575050354
Validation loss: 2.1002257466316223

Epoch: 6| Step: 6
Training loss: 1.9243388175964355
Validation loss: 2.0962578455607095

Epoch: 6| Step: 7
Training loss: 2.482848882675171
Validation loss: 2.1102051734924316

Epoch: 6| Step: 8
Training loss: 1.862455129623413
Validation loss: 2.0971702535947165

Epoch: 6| Step: 9
Training loss: 1.5956372022628784
Validation loss: 2.117603043715159

Epoch: 6| Step: 10
Training loss: 1.5525850057601929
Validation loss: 2.1178960601488748

Epoch: 6| Step: 11
Training loss: 1.8233916759490967
Validation loss: 2.118645985921224

Epoch: 6| Step: 12
Training loss: 2.0958213806152344
Validation loss: 2.136058290799459

Epoch: 6| Step: 13
Training loss: 2.087815999984741
Validation loss: 2.118262509504954

Epoch: 159| Step: 0
Training loss: 1.9182010889053345
Validation loss: 2.127522110939026

Epoch: 6| Step: 1
Training loss: 2.6080985069274902
Validation loss: 2.1156914631525674

Epoch: 6| Step: 2
Training loss: 1.8637279272079468
Validation loss: 2.1163307229677835

Epoch: 6| Step: 3
Training loss: 1.7620930671691895
Validation loss: 2.102740228176117

Epoch: 6| Step: 4
Training loss: 1.6780197620391846
Validation loss: 2.1071873108545938

Epoch: 6| Step: 5
Training loss: 2.3529703617095947
Validation loss: 2.104666610558828

Epoch: 6| Step: 6
Training loss: 2.312736749649048
Validation loss: 2.09500245253245

Epoch: 6| Step: 7
Training loss: 1.5118913650512695
Validation loss: 2.1051233410835266

Epoch: 6| Step: 8
Training loss: 2.0127696990966797
Validation loss: 2.100092053413391

Epoch: 6| Step: 9
Training loss: 1.7621824741363525
Validation loss: 2.0939598282178244

Epoch: 6| Step: 10
Training loss: 1.828261375427246
Validation loss: 2.1149769028027854

Epoch: 6| Step: 11
Training loss: 1.9767425060272217
Validation loss: 2.103089928627014

Epoch: 6| Step: 12
Training loss: 1.820346474647522
Validation loss: 2.1078988711039224

Epoch: 6| Step: 13
Training loss: 1.8542991876602173
Validation loss: 2.1266438364982605

Epoch: 160| Step: 0
Training loss: 2.0204732418060303
Validation loss: 2.139140526453654

Epoch: 6| Step: 1
Training loss: 1.9967496395111084
Validation loss: 2.132018228371938

Epoch: 6| Step: 2
Training loss: 1.9004749059677124
Validation loss: 2.1400994062423706

Epoch: 6| Step: 3
Training loss: 1.26235032081604
Validation loss: 2.1364381114641824

Epoch: 6| Step: 4
Training loss: 1.8632699251174927
Validation loss: 2.111538589000702

Epoch: 6| Step: 5
Training loss: 2.3862571716308594
Validation loss: 2.1199376384417215

Epoch: 6| Step: 6
Training loss: 2.230241060256958
Validation loss: 2.115430255730947

Epoch: 6| Step: 7
Training loss: 1.9608546495437622
Validation loss: 2.1022456685702005

Epoch: 6| Step: 8
Training loss: 1.8206318616867065
Validation loss: 2.0953862269719443

Epoch: 6| Step: 9
Training loss: 1.6885188817977905
Validation loss: 2.100351790587107

Epoch: 6| Step: 10
Training loss: 2.2039880752563477
Validation loss: 2.101881722609202

Epoch: 6| Step: 11
Training loss: 2.1254520416259766
Validation loss: 2.093469480673472

Epoch: 6| Step: 12
Training loss: 2.040109634399414
Validation loss: 2.084430237611135

Epoch: 6| Step: 13
Training loss: 1.659519910812378
Validation loss: 2.0870407223701477

Epoch: 161| Step: 0
Training loss: 1.7879327535629272
Validation loss: 2.082999606927236

Epoch: 6| Step: 1
Training loss: 2.0984785556793213
Validation loss: 2.082004507382711

Epoch: 6| Step: 2
Training loss: 1.6879832744598389
Validation loss: 2.082132617632548

Epoch: 6| Step: 3
Training loss: 2.292818069458008
Validation loss: 2.100760360558828

Epoch: 6| Step: 4
Training loss: 1.7513688802719116
Validation loss: 2.103964149951935

Epoch: 6| Step: 5
Training loss: 2.045757293701172
Validation loss: 2.1115563909212747

Epoch: 6| Step: 6
Training loss: 1.6272642612457275
Validation loss: 2.1017068227132163

Epoch: 6| Step: 7
Training loss: 1.9309983253479004
Validation loss: 2.115143875281016

Epoch: 6| Step: 8
Training loss: 1.536064624786377
Validation loss: 2.1390326619148254

Epoch: 6| Step: 9
Training loss: 1.6883833408355713
Validation loss: 2.127498964468638

Epoch: 6| Step: 10
Training loss: 2.570272445678711
Validation loss: 2.1146377126375833

Epoch: 6| Step: 11
Training loss: 1.924262523651123
Validation loss: 2.124566833178202

Epoch: 6| Step: 12
Training loss: 2.4596264362335205
Validation loss: 2.1222935120264688

Epoch: 6| Step: 13
Training loss: 2.141467571258545
Validation loss: 2.1198800007502236

Epoch: 162| Step: 0
Training loss: 2.410421371459961
Validation loss: 2.1138397455215454

Epoch: 6| Step: 1
Training loss: 2.2683892250061035
Validation loss: 2.120004733403524

Epoch: 6| Step: 2
Training loss: 1.8860359191894531
Validation loss: 2.103570878505707

Epoch: 6| Step: 3
Training loss: 1.6984643936157227
Validation loss: 2.1117021640141806

Epoch: 6| Step: 4
Training loss: 2.1825900077819824
Validation loss: 2.100942532221476

Epoch: 6| Step: 5
Training loss: 1.777923583984375
Validation loss: 2.103557507197062

Epoch: 6| Step: 6
Training loss: 2.4329934120178223
Validation loss: 2.1052568554878235

Epoch: 6| Step: 7
Training loss: 1.618233561515808
Validation loss: 2.1078238089879355

Epoch: 6| Step: 8
Training loss: 2.2624363899230957
Validation loss: 2.111692567666372

Epoch: 6| Step: 9
Training loss: 1.266137719154358
Validation loss: 2.11927459637324

Epoch: 6| Step: 10
Training loss: 1.9535554647445679
Validation loss: 2.1257262031237283

Epoch: 6| Step: 11
Training loss: 1.854202151298523
Validation loss: 2.1472515066464744

Epoch: 6| Step: 12
Training loss: 2.3568875789642334
Validation loss: 2.143551508585612

Epoch: 6| Step: 13
Training loss: 1.3154454231262207
Validation loss: 2.156297485033671

Epoch: 163| Step: 0
Training loss: 1.881159782409668
Validation loss: 2.149781505266825

Epoch: 6| Step: 1
Training loss: 2.280914306640625
Validation loss: 2.143238623936971

Epoch: 6| Step: 2
Training loss: 1.6465917825698853
Validation loss: 2.140301843484243

Epoch: 6| Step: 3
Training loss: 1.9634251594543457
Validation loss: 2.1334701776504517

Epoch: 6| Step: 4
Training loss: 1.7844836711883545
Validation loss: 2.144709825515747

Epoch: 6| Step: 5
Training loss: 2.0137720108032227
Validation loss: 2.132746398448944

Epoch: 6| Step: 6
Training loss: 2.3682053089141846
Validation loss: 2.132577955722809

Epoch: 6| Step: 7
Training loss: 2.108131170272827
Validation loss: 2.1355263392130532

Epoch: 6| Step: 8
Training loss: 1.6000456809997559
Validation loss: 2.1373605728149414

Epoch: 6| Step: 9
Training loss: 1.4591412544250488
Validation loss: 2.1294416387875876

Epoch: 6| Step: 10
Training loss: 1.974290132522583
Validation loss: 2.1381744146347046

Epoch: 6| Step: 11
Training loss: 2.4393181800842285
Validation loss: 2.125950813293457

Epoch: 6| Step: 12
Training loss: 1.4655355215072632
Validation loss: 2.1277520855267844

Epoch: 6| Step: 13
Training loss: 2.294905185699463
Validation loss: 2.1156516472498574

Epoch: 164| Step: 0
Training loss: 2.0181562900543213
Validation loss: 2.126847724119822

Epoch: 6| Step: 1
Training loss: 2.3763208389282227
Validation loss: 2.113349219163259

Epoch: 6| Step: 2
Training loss: 1.5614690780639648
Validation loss: 2.1048861145973206

Epoch: 6| Step: 3
Training loss: 1.6512447595596313
Validation loss: 2.1050056417783103

Epoch: 6| Step: 4
Training loss: 2.236823797225952
Validation loss: 2.0968466798464456

Epoch: 6| Step: 5
Training loss: 1.4382622241973877
Validation loss: 2.102811356385549

Epoch: 6| Step: 6
Training loss: 2.300292730331421
Validation loss: 2.0920592745145163

Epoch: 6| Step: 7
Training loss: 2.087749481201172
Validation loss: 2.0940284530321756

Epoch: 6| Step: 8
Training loss: 1.9111526012420654
Validation loss: 2.112218459447225

Epoch: 6| Step: 9
Training loss: 2.124617576599121
Validation loss: 2.109673023223877

Epoch: 6| Step: 10
Training loss: 1.6961581707000732
Validation loss: 2.1296682556470237

Epoch: 6| Step: 11
Training loss: 1.7810670137405396
Validation loss: 2.1389255921045938

Epoch: 6| Step: 12
Training loss: 2.386312484741211
Validation loss: 2.149745841821035

Epoch: 6| Step: 13
Training loss: 1.937543511390686
Validation loss: 2.1371610959370932

Epoch: 165| Step: 0
Training loss: 2.0402021408081055
Validation loss: 2.12370498975118

Epoch: 6| Step: 1
Training loss: 2.195321559906006
Validation loss: 2.133064925670624

Epoch: 6| Step: 2
Training loss: 2.562392234802246
Validation loss: 2.1244054436683655

Epoch: 6| Step: 3
Training loss: 1.3767478466033936
Validation loss: 2.1239954431851706

Epoch: 6| Step: 4
Training loss: 2.307511329650879
Validation loss: 2.120554784933726

Epoch: 6| Step: 5
Training loss: 2.455386161804199
Validation loss: 2.1236496965090432

Epoch: 6| Step: 6
Training loss: 2.127063274383545
Validation loss: 2.1177879174550376

Epoch: 6| Step: 7
Training loss: 1.2710540294647217
Validation loss: 2.114188770453135

Epoch: 6| Step: 8
Training loss: 1.4312700033187866
Validation loss: 2.1169633269309998

Epoch: 6| Step: 9
Training loss: 2.1768691539764404
Validation loss: 2.1319175362586975

Epoch: 6| Step: 10
Training loss: 1.4694936275482178
Validation loss: 2.1252700686454773

Epoch: 6| Step: 11
Training loss: 2.4257712364196777
Validation loss: 2.1339261134465537

Epoch: 6| Step: 12
Training loss: 1.5724977254867554
Validation loss: 2.1323702931404114

Epoch: 6| Step: 13
Training loss: 1.5391604900360107
Validation loss: 2.13575812180837

Epoch: 166| Step: 0
Training loss: 1.6996934413909912
Validation loss: 2.141286571820577

Epoch: 6| Step: 1
Training loss: 2.539534091949463
Validation loss: 2.121608853340149

Epoch: 6| Step: 2
Training loss: 2.325969696044922
Validation loss: 2.1157549023628235

Epoch: 6| Step: 3
Training loss: 1.7546288967132568
Validation loss: 2.1272225975990295

Epoch: 6| Step: 4
Training loss: 1.993172287940979
Validation loss: 2.1238739490509033

Epoch: 6| Step: 5
Training loss: 1.859033465385437
Validation loss: 2.128461162249247

Epoch: 6| Step: 6
Training loss: 2.2987606525421143
Validation loss: 2.119741062323252

Epoch: 6| Step: 7
Training loss: 1.9550002813339233
Validation loss: 2.121637006600698

Epoch: 6| Step: 8
Training loss: 1.7316224575042725
Validation loss: 2.1209661960601807

Epoch: 6| Step: 9
Training loss: 1.7555046081542969
Validation loss: 2.1093721191088357

Epoch: 6| Step: 10
Training loss: 2.067488670349121
Validation loss: 2.1102760434150696

Epoch: 6| Step: 11
Training loss: 1.415122389793396
Validation loss: 2.1056559880574546

Epoch: 6| Step: 12
Training loss: 1.6381645202636719
Validation loss: 2.11441179116567

Epoch: 6| Step: 13
Training loss: 2.203120708465576
Validation loss: 2.1212598284085593

Epoch: 167| Step: 0
Training loss: 2.1836891174316406
Validation loss: 2.133080780506134

Epoch: 6| Step: 1
Training loss: 1.6780707836151123
Validation loss: 2.1313663323720298

Epoch: 6| Step: 2
Training loss: 1.7888151407241821
Validation loss: 2.150050938129425

Epoch: 6| Step: 3
Training loss: 2.1076698303222656
Validation loss: 2.154478351275126

Epoch: 6| Step: 4
Training loss: 1.3055205345153809
Validation loss: 2.148341874281565

Epoch: 6| Step: 5
Training loss: 2.388624429702759
Validation loss: 2.1403836806615195

Epoch: 6| Step: 6
Training loss: 2.1787869930267334
Validation loss: 2.1552371780077615

Epoch: 6| Step: 7
Training loss: 2.226071834564209
Validation loss: 2.1328924894332886

Epoch: 6| Step: 8
Training loss: 1.7731094360351562
Validation loss: 2.1339624325434365

Epoch: 6| Step: 9
Training loss: 2.288050651550293
Validation loss: 2.129373788833618

Epoch: 6| Step: 10
Training loss: 2.013442039489746
Validation loss: 2.122239033381144

Epoch: 6| Step: 11
Training loss: 1.6372159719467163
Validation loss: 2.1463545163472495

Epoch: 6| Step: 12
Training loss: 2.0306360721588135
Validation loss: 2.1331249475479126

Epoch: 6| Step: 13
Training loss: 1.463613510131836
Validation loss: 2.1311569015185037

Epoch: 168| Step: 0
Training loss: 2.3188884258270264
Validation loss: 2.14571613073349

Epoch: 6| Step: 1
Training loss: 2.107595920562744
Validation loss: 2.1312812169392905

Epoch: 6| Step: 2
Training loss: 2.350590229034424
Validation loss: 2.138421813646952

Epoch: 6| Step: 3
Training loss: 2.3399548530578613
Validation loss: 2.13107430934906

Epoch: 6| Step: 4
Training loss: 1.7009007930755615
Validation loss: 2.134072999159495

Epoch: 6| Step: 5
Training loss: 1.8176243305206299
Validation loss: 2.1254906058311462

Epoch: 6| Step: 6
Training loss: 1.6139488220214844
Validation loss: 2.1256186167399087

Epoch: 6| Step: 7
Training loss: 1.5450921058654785
Validation loss: 2.118729372819265

Epoch: 6| Step: 8
Training loss: 2.0115232467651367
Validation loss: 2.115050117174784

Epoch: 6| Step: 9
Training loss: 1.6698570251464844
Validation loss: 2.1264665126800537

Epoch: 6| Step: 10
Training loss: 1.6097955703735352
Validation loss: 2.131827930609385

Epoch: 6| Step: 11
Training loss: 2.1376466751098633
Validation loss: 2.1210702657699585

Epoch: 6| Step: 12
Training loss: 2.023865222930908
Validation loss: 2.147900402545929

Epoch: 6| Step: 13
Training loss: 1.7516708374023438
Validation loss: 2.1419449051221213

Epoch: 169| Step: 0
Training loss: 2.5024843215942383
Validation loss: 2.152055859565735

Epoch: 6| Step: 1
Training loss: 1.99247407913208
Validation loss: 2.1462581952412925

Epoch: 6| Step: 2
Training loss: 2.3388805389404297
Validation loss: 2.1443368593851724

Epoch: 6| Step: 3
Training loss: 1.9136734008789062
Validation loss: 2.1260451078414917

Epoch: 6| Step: 4
Training loss: 1.8164211511611938
Validation loss: 2.1369868516921997

Epoch: 6| Step: 5
Training loss: 1.8180063962936401
Validation loss: 2.12154754002889

Epoch: 6| Step: 6
Training loss: 1.2185249328613281
Validation loss: 2.12538876136144

Epoch: 6| Step: 7
Training loss: 1.8175705671310425
Validation loss: 2.1161900560061135

Epoch: 6| Step: 8
Training loss: 2.311309576034546
Validation loss: 2.1111203829447427

Epoch: 6| Step: 9
Training loss: 2.061969757080078
Validation loss: 2.1186187267303467

Epoch: 6| Step: 10
Training loss: 1.2684760093688965
Validation loss: 2.1266359090805054

Epoch: 6| Step: 11
Training loss: 2.8233542442321777
Validation loss: 2.132511556148529

Epoch: 6| Step: 12
Training loss: 1.4165534973144531
Validation loss: 2.134890894095103

Epoch: 6| Step: 13
Training loss: 1.8622913360595703
Validation loss: 2.1409931580225625

Epoch: 170| Step: 0
Training loss: 1.5559587478637695
Validation loss: 2.1501499811808267

Epoch: 6| Step: 1
Training loss: 1.959319829940796
Validation loss: 2.1339686115582785

Epoch: 6| Step: 2
Training loss: 2.2505478858947754
Validation loss: 2.1525068084398904

Epoch: 6| Step: 3
Training loss: 1.539493203163147
Validation loss: 2.1733347177505493

Epoch: 6| Step: 4
Training loss: 2.136509895324707
Validation loss: 2.1410033106803894

Epoch: 6| Step: 5
Training loss: 2.305474281311035
Validation loss: 2.123277187347412

Epoch: 6| Step: 6
Training loss: 1.570962905883789
Validation loss: 2.1184521118799844

Epoch: 6| Step: 7
Training loss: 1.766340732574463
Validation loss: 2.1215896010398865

Epoch: 6| Step: 8
Training loss: 1.4441521167755127
Validation loss: 2.1142531434694924

Epoch: 6| Step: 9
Training loss: 1.6744327545166016
Validation loss: 2.1219491561253867

Epoch: 6| Step: 10
Training loss: 2.0806286334991455
Validation loss: 2.129421055316925

Epoch: 6| Step: 11
Training loss: 2.4931039810180664
Validation loss: 2.1290737787882485

Epoch: 6| Step: 12
Training loss: 2.0816168785095215
Validation loss: 2.120574136575063

Epoch: 6| Step: 13
Training loss: 2.174915075302124
Validation loss: 2.1195809841156006

Epoch: 171| Step: 0
Training loss: 1.8010289669036865
Validation loss: 2.134156346321106

Epoch: 6| Step: 1
Training loss: 2.15771222114563
Validation loss: 2.122193773587545

Epoch: 6| Step: 2
Training loss: 1.5926539897918701
Validation loss: 2.133954326311747

Epoch: 6| Step: 3
Training loss: 2.5023746490478516
Validation loss: 2.127140382925669

Epoch: 6| Step: 4
Training loss: 2.0162549018859863
Validation loss: 2.127234856287638

Epoch: 6| Step: 5
Training loss: 1.6034654378890991
Validation loss: 2.119290550549825

Epoch: 6| Step: 6
Training loss: 2.276193618774414
Validation loss: 2.125512659549713

Epoch: 6| Step: 7
Training loss: 2.041804790496826
Validation loss: 2.1491257349650064

Epoch: 6| Step: 8
Training loss: 2.1272337436676025
Validation loss: 2.141844709714254

Epoch: 6| Step: 9
Training loss: 1.7705097198486328
Validation loss: 2.1447108387947083

Epoch: 6| Step: 10
Training loss: 1.302690029144287
Validation loss: 2.1485364039738974

Epoch: 6| Step: 11
Training loss: 1.427595853805542
Validation loss: 2.1510921915372214

Epoch: 6| Step: 12
Training loss: 2.2097859382629395
Validation loss: 2.1579257448514304

Epoch: 6| Step: 13
Training loss: 2.1494908332824707
Validation loss: 2.1603300174077353

Epoch: 172| Step: 0
Training loss: 2.2844178676605225
Validation loss: 2.162541468938192

Epoch: 6| Step: 1
Training loss: 1.685415506362915
Validation loss: 2.1441849867502847

Epoch: 6| Step: 2
Training loss: 2.0561747550964355
Validation loss: 2.1296445727348328

Epoch: 6| Step: 3
Training loss: 2.2558891773223877
Validation loss: 2.1192254622777305

Epoch: 6| Step: 4
Training loss: 1.8826521635055542
Validation loss: 2.130206127961477

Epoch: 6| Step: 5
Training loss: 2.028212070465088
Validation loss: 2.114313085873922

Epoch: 6| Step: 6
Training loss: 2.146101951599121
Validation loss: 2.1220704317092896

Epoch: 6| Step: 7
Training loss: 1.7448805570602417
Validation loss: 2.1133741537729898

Epoch: 6| Step: 8
Training loss: 1.6844429969787598
Validation loss: 2.1423213283220925

Epoch: 6| Step: 9
Training loss: 1.6886086463928223
Validation loss: 2.1512157917022705

Epoch: 6| Step: 10
Training loss: 2.0637264251708984
Validation loss: 2.1852081616719565

Epoch: 6| Step: 11
Training loss: 2.0077242851257324
Validation loss: 2.1873292922973633

Epoch: 6| Step: 12
Training loss: 2.2333388328552246
Validation loss: 2.191369573275248

Epoch: 6| Step: 13
Training loss: 1.8454177379608154
Validation loss: 2.1863253315289817

Epoch: 173| Step: 0
Training loss: 1.827866554260254
Validation loss: 2.1766432325045266

Epoch: 6| Step: 1
Training loss: 2.3581244945526123
Validation loss: 2.1658971309661865

Epoch: 6| Step: 2
Training loss: 1.93975830078125
Validation loss: 2.1391865015029907

Epoch: 6| Step: 3
Training loss: 1.8617947101593018
Validation loss: 2.1279907822608948

Epoch: 6| Step: 4
Training loss: 1.6474838256835938
Validation loss: 2.1146886746088662

Epoch: 6| Step: 5
Training loss: 2.3497960567474365
Validation loss: 2.117061952749888

Epoch: 6| Step: 6
Training loss: 1.8391157388687134
Validation loss: 2.1000743309656777

Epoch: 6| Step: 7
Training loss: 1.745309591293335
Validation loss: 2.09975399573644

Epoch: 6| Step: 8
Training loss: 1.6065342426300049
Validation loss: 2.1080382068951926

Epoch: 6| Step: 9
Training loss: 2.132822275161743
Validation loss: 2.1172887285550437

Epoch: 6| Step: 10
Training loss: 2.380178928375244
Validation loss: 2.1059648990631104

Epoch: 6| Step: 11
Training loss: 1.570841670036316
Validation loss: 2.109907587369283

Epoch: 6| Step: 12
Training loss: 1.7747858762741089
Validation loss: 2.1080584128697715

Epoch: 6| Step: 13
Training loss: 2.2548937797546387
Validation loss: 2.1221910516421

Epoch: 174| Step: 0
Training loss: 1.845703363418579
Validation loss: 2.1154517928759256

Epoch: 6| Step: 1
Training loss: 2.0434651374816895
Validation loss: 2.1275819142659507

Epoch: 6| Step: 2
Training loss: 2.6077282428741455
Validation loss: 2.1358765761057534

Epoch: 6| Step: 3
Training loss: 1.688281774520874
Validation loss: 2.144687533378601

Epoch: 6| Step: 4
Training loss: 2.2596194744110107
Validation loss: 2.1365819374720254

Epoch: 6| Step: 5
Training loss: 1.8495702743530273
Validation loss: 2.159113625685374

Epoch: 6| Step: 6
Training loss: 2.1255035400390625
Validation loss: 2.1449918945630393

Epoch: 6| Step: 7
Training loss: 2.0739712715148926
Validation loss: 2.1533533930778503

Epoch: 6| Step: 8
Training loss: 1.1620111465454102
Validation loss: 2.1476975480715432

Epoch: 6| Step: 9
Training loss: 2.0824007987976074
Validation loss: 2.139662424723307

Epoch: 6| Step: 10
Training loss: 1.5758413076400757
Validation loss: 2.1486323277155557

Epoch: 6| Step: 11
Training loss: 2.350236415863037
Validation loss: 2.126120090484619

Epoch: 6| Step: 12
Training loss: 1.909865140914917
Validation loss: 2.1361348628997803

Epoch: 6| Step: 13
Training loss: 1.5217576026916504
Validation loss: 2.1226759354273477

Epoch: 175| Step: 0
Training loss: 1.7667348384857178
Validation loss: 2.1256192723910012

Epoch: 6| Step: 1
Training loss: 1.6952815055847168
Validation loss: 2.1183112064997354

Epoch: 6| Step: 2
Training loss: 2.0527329444885254
Validation loss: 2.1131775975227356

Epoch: 6| Step: 3
Training loss: 2.044646978378296
Validation loss: 2.1314263939857483

Epoch: 6| Step: 4
Training loss: 1.8006948232650757
Validation loss: 2.1306228041648865

Epoch: 6| Step: 5
Training loss: 1.6330113410949707
Validation loss: 2.121809403101603

Epoch: 6| Step: 6
Training loss: 2.338493824005127
Validation loss: 2.132833262284597

Epoch: 6| Step: 7
Training loss: 1.4661798477172852
Validation loss: 2.140671710173289

Epoch: 6| Step: 8
Training loss: 2.4700403213500977
Validation loss: 2.1588192780812583

Epoch: 6| Step: 9
Training loss: 2.118924140930176
Validation loss: 2.1446406046549478

Epoch: 6| Step: 10
Training loss: 2.548007011413574
Validation loss: 2.153326988220215

Epoch: 6| Step: 11
Training loss: 1.9970089197158813
Validation loss: 2.150278866291046

Epoch: 6| Step: 12
Training loss: 1.3757719993591309
Validation loss: 2.146622896194458

Epoch: 6| Step: 13
Training loss: 1.7190885543823242
Validation loss: 2.1605361898740134

Epoch: 176| Step: 0
Training loss: 1.1098909378051758
Validation loss: 2.166950265566508

Epoch: 6| Step: 1
Training loss: 2.720984697341919
Validation loss: 2.1680002013842263

Epoch: 6| Step: 2
Training loss: 1.8812997341156006
Validation loss: 2.1707764069239297

Epoch: 6| Step: 3
Training loss: 1.8397016525268555
Validation loss: 2.1637762586275735

Epoch: 6| Step: 4
Training loss: 2.376802921295166
Validation loss: 2.15658167997996

Epoch: 6| Step: 5
Training loss: 1.5581120252609253
Validation loss: 2.1540754636128745

Epoch: 6| Step: 6
Training loss: 2.291107177734375
Validation loss: 2.1397887667020163

Epoch: 6| Step: 7
Training loss: 2.143589496612549
Validation loss: 2.1458037892977395

Epoch: 6| Step: 8
Training loss: 2.5743649005889893
Validation loss: 2.1483214298884072

Epoch: 6| Step: 9
Training loss: 1.3423773050308228
Validation loss: 2.1455745697021484

Epoch: 6| Step: 10
Training loss: 1.7333892583847046
Validation loss: 2.1500695943832397

Epoch: 6| Step: 11
Training loss: 1.8416526317596436
Validation loss: 2.1470922430356345

Epoch: 6| Step: 12
Training loss: 1.5851523876190186
Validation loss: 2.145834525426229

Epoch: 6| Step: 13
Training loss: 1.7822345495224
Validation loss: 2.132246454556783

Epoch: 177| Step: 0
Training loss: 2.500887632369995
Validation loss: 2.129547735055288

Epoch: 6| Step: 1
Training loss: 1.8521236181259155
Validation loss: 2.1370758612950644

Epoch: 6| Step: 2
Training loss: 2.511779308319092
Validation loss: 2.125862419605255

Epoch: 6| Step: 3
Training loss: 2.868886947631836
Validation loss: 2.1264294584592185

Epoch: 6| Step: 4
Training loss: 1.3546745777130127
Validation loss: 2.117552876472473

Epoch: 6| Step: 5
Training loss: 1.827784538269043
Validation loss: 2.1285542845726013

Epoch: 6| Step: 6
Training loss: 1.8772001266479492
Validation loss: 2.121598223845164

Epoch: 6| Step: 7
Training loss: 2.0317487716674805
Validation loss: 2.1367268164952598

Epoch: 6| Step: 8
Training loss: 1.9206374883651733
Validation loss: 2.1286413868268332

Epoch: 6| Step: 9
Training loss: 2.123326063156128
Validation loss: 2.1277975837389627

Epoch: 6| Step: 10
Training loss: 1.1735670566558838
Validation loss: 2.1330631176630654

Epoch: 6| Step: 11
Training loss: 1.7562669515609741
Validation loss: 2.138714869817098

Epoch: 6| Step: 12
Training loss: 1.278153419494629
Validation loss: 2.141233503818512

Epoch: 6| Step: 13
Training loss: 1.850609302520752
Validation loss: 2.1526639660199485

Epoch: 178| Step: 0
Training loss: 1.715438723564148
Validation loss: 2.15742822488149

Epoch: 6| Step: 1
Training loss: 1.863715648651123
Validation loss: 2.1596827308336892

Epoch: 6| Step: 2
Training loss: 1.7042475938796997
Validation loss: 2.1586819291114807

Epoch: 6| Step: 3
Training loss: 1.8280532360076904
Validation loss: 2.1648802558581033

Epoch: 6| Step: 4
Training loss: 1.6020690202713013
Validation loss: 2.1512537399927774

Epoch: 6| Step: 5
Training loss: 1.7157416343688965
Validation loss: 2.1509925723075867

Epoch: 6| Step: 6
Training loss: 2.0608937740325928
Validation loss: 2.145930012067159

Epoch: 6| Step: 7
Training loss: 1.8945627212524414
Validation loss: 2.153835336367289

Epoch: 6| Step: 8
Training loss: 1.691112756729126
Validation loss: 2.15107262134552

Epoch: 6| Step: 9
Training loss: 2.5547103881835938
Validation loss: 2.145519574483236

Epoch: 6| Step: 10
Training loss: 1.9794753789901733
Validation loss: 2.164593736330668

Epoch: 6| Step: 11
Training loss: 1.5936899185180664
Validation loss: 2.1403698921203613

Epoch: 6| Step: 12
Training loss: 2.071406602859497
Validation loss: 2.1511764923731485

Epoch: 6| Step: 13
Training loss: 2.4105136394500732
Validation loss: 2.1458382606506348

Epoch: 179| Step: 0
Training loss: 1.5336694717407227
Validation loss: 2.143937369187673

Epoch: 6| Step: 1
Training loss: 2.3303937911987305
Validation loss: 2.1488060553868613

Epoch: 6| Step: 2
Training loss: 2.5811593532562256
Validation loss: 2.1282025973002114

Epoch: 6| Step: 3
Training loss: 1.130397081375122
Validation loss: 2.1402620474497476

Epoch: 6| Step: 4
Training loss: 1.9775772094726562
Validation loss: 2.13434491554896

Epoch: 6| Step: 5
Training loss: 2.177623748779297
Validation loss: 2.1414843996365867

Epoch: 6| Step: 6
Training loss: 2.1965789794921875
Validation loss: 2.138546625773112

Epoch: 6| Step: 7
Training loss: 1.6787086725234985
Validation loss: 2.1517022252082825

Epoch: 6| Step: 8
Training loss: 1.9883400201797485
Validation loss: 2.143998106320699

Epoch: 6| Step: 9
Training loss: 1.5457439422607422
Validation loss: 2.1425503492355347

Epoch: 6| Step: 10
Training loss: 1.336320161819458
Validation loss: 2.1388290921847024

Epoch: 6| Step: 11
Training loss: 1.7583415508270264
Validation loss: 2.1567355593045554

Epoch: 6| Step: 12
Training loss: 2.327732563018799
Validation loss: 2.1696332891782126

Epoch: 6| Step: 13
Training loss: 2.0942130088806152
Validation loss: 2.159065842628479

Epoch: 180| Step: 0
Training loss: 1.9744584560394287
Validation loss: 2.1601394414901733

Epoch: 6| Step: 1
Training loss: 1.566609501838684
Validation loss: 2.1704704562822976

Epoch: 6| Step: 2
Training loss: 2.303084135055542
Validation loss: 2.1837549209594727

Epoch: 6| Step: 3
Training loss: 2.098050594329834
Validation loss: 2.1748833457628884

Epoch: 6| Step: 4
Training loss: 1.6806271076202393
Validation loss: 2.1545979976654053

Epoch: 6| Step: 5
Training loss: 1.7010674476623535
Validation loss: 2.147158205509186

Epoch: 6| Step: 6
Training loss: 2.243648052215576
Validation loss: 2.146556874116262

Epoch: 6| Step: 7
Training loss: 1.5771453380584717
Validation loss: 2.1380258997281394

Epoch: 6| Step: 8
Training loss: 1.7118351459503174
Validation loss: 2.1344945430755615

Epoch: 6| Step: 9
Training loss: 1.6649103164672852
Validation loss: 2.1273870865503945

Epoch: 6| Step: 10
Training loss: 2.294339179992676
Validation loss: 2.123324235280355

Epoch: 6| Step: 11
Training loss: 1.890406847000122
Validation loss: 2.125772496064504

Epoch: 6| Step: 12
Training loss: 1.564063549041748
Validation loss: 2.1258339881896973

Epoch: 6| Step: 13
Training loss: 2.779632806777954
Validation loss: 2.1313554843266806

Epoch: 181| Step: 0
Training loss: 1.3468632698059082
Validation loss: 2.1319035490353904

Epoch: 6| Step: 1
Training loss: 2.1524808406829834
Validation loss: 2.142604867617289

Epoch: 6| Step: 2
Training loss: 2.3389317989349365
Validation loss: 2.13619198401769

Epoch: 6| Step: 3
Training loss: 2.3549294471740723
Validation loss: 2.153569062550863

Epoch: 6| Step: 4
Training loss: 1.6404194831848145
Validation loss: 2.146231532096863

Epoch: 6| Step: 5
Training loss: 1.779296875
Validation loss: 2.183993697166443

Epoch: 6| Step: 6
Training loss: 2.052885055541992
Validation loss: 2.194444994131724

Epoch: 6| Step: 7
Training loss: 1.8644800186157227
Validation loss: 2.1844902435938516

Epoch: 6| Step: 8
Training loss: 1.6716927289962769
Validation loss: 2.1728007793426514

Epoch: 6| Step: 9
Training loss: 1.8888951539993286
Validation loss: 2.1814451217651367

Epoch: 6| Step: 10
Training loss: 2.433851480484009
Validation loss: 2.1558095812797546

Epoch: 6| Step: 11
Training loss: 2.25919246673584
Validation loss: 2.134848495324453

Epoch: 6| Step: 12
Training loss: 1.7220940589904785
Validation loss: 2.132081766923269

Epoch: 6| Step: 13
Training loss: 1.5536999702453613
Validation loss: 2.137271304925283

Epoch: 182| Step: 0
Training loss: 2.0376908779144287
Validation loss: 2.1299309929211936

Epoch: 6| Step: 1
Training loss: 2.3664050102233887
Validation loss: 2.1302621364593506

Epoch: 6| Step: 2
Training loss: 1.829189419746399
Validation loss: 2.135139544804891

Epoch: 6| Step: 3
Training loss: 2.825162410736084
Validation loss: 2.130615850289663

Epoch: 6| Step: 4
Training loss: 1.214909553527832
Validation loss: 2.1591291228930154

Epoch: 6| Step: 5
Training loss: 1.9080922603607178
Validation loss: 2.1627491315205893

Epoch: 6| Step: 6
Training loss: 1.590593934059143
Validation loss: 2.160513977209727

Epoch: 6| Step: 7
Training loss: 1.6697334051132202
Validation loss: 2.1706824700037637

Epoch: 6| Step: 8
Training loss: 1.563597559928894
Validation loss: 2.180151383082072

Epoch: 6| Step: 9
Training loss: 1.6465033292770386
Validation loss: 2.1676851312319436

Epoch: 6| Step: 10
Training loss: 1.7354508638381958
Validation loss: 2.1697752873102822

Epoch: 6| Step: 11
Training loss: 2.03096866607666
Validation loss: 2.1607276598612466

Epoch: 6| Step: 12
Training loss: 1.9859428405761719
Validation loss: 2.1690168579419455

Epoch: 6| Step: 13
Training loss: 2.5239744186401367
Validation loss: 2.155097941557566

Epoch: 183| Step: 0
Training loss: 1.9198137521743774
Validation loss: 2.1589827140172324

Epoch: 6| Step: 1
Training loss: 1.8425296545028687
Validation loss: 2.1542246540387473

Epoch: 6| Step: 2
Training loss: 1.5711641311645508
Validation loss: 2.145882487297058

Epoch: 6| Step: 3
Training loss: 1.2380023002624512
Validation loss: 2.1622036695480347

Epoch: 6| Step: 4
Training loss: 1.799161672592163
Validation loss: 2.148243029912313

Epoch: 6| Step: 5
Training loss: 2.1887502670288086
Validation loss: 2.1567751367886863

Epoch: 6| Step: 6
Training loss: 1.9375351667404175
Validation loss: 2.1579980850219727

Epoch: 6| Step: 7
Training loss: 2.0801868438720703
Validation loss: 2.1696959336598716

Epoch: 6| Step: 8
Training loss: 2.4696884155273438
Validation loss: 2.1555189291636148

Epoch: 6| Step: 9
Training loss: 1.935106635093689
Validation loss: 2.1667108138402305

Epoch: 6| Step: 10
Training loss: 1.3593257665634155
Validation loss: 2.148602028687795

Epoch: 6| Step: 11
Training loss: 1.9736096858978271
Validation loss: 2.1450489362080893

Epoch: 6| Step: 12
Training loss: 1.7864642143249512
Validation loss: 2.1557715932528176

Epoch: 6| Step: 13
Training loss: 2.378207206726074
Validation loss: 2.1550630728403726

Epoch: 184| Step: 0
Training loss: 1.6206461191177368
Validation loss: 2.1620015303293862

Epoch: 6| Step: 1
Training loss: 2.1898772716522217
Validation loss: 2.1549755732218423

Epoch: 6| Step: 2
Training loss: 1.9019157886505127
Validation loss: 2.1564376950263977

Epoch: 6| Step: 3
Training loss: 2.2886557579040527
Validation loss: 2.171322464942932

Epoch: 6| Step: 4
Training loss: 2.1228246688842773
Validation loss: 2.1601256132125854

Epoch: 6| Step: 5
Training loss: 1.5552639961242676
Validation loss: 2.1461378931999207

Epoch: 6| Step: 6
Training loss: 1.1640604734420776
Validation loss: 2.1400914986928306

Epoch: 6| Step: 7
Training loss: 1.8884685039520264
Validation loss: 2.159530301888784

Epoch: 6| Step: 8
Training loss: 1.506691813468933
Validation loss: 2.1483304103215537

Epoch: 6| Step: 9
Training loss: 1.8215479850769043
Validation loss: 2.1377384265263877

Epoch: 6| Step: 10
Training loss: 1.968032956123352
Validation loss: 2.1387498577435813

Epoch: 6| Step: 11
Training loss: 2.7087063789367676
Validation loss: 2.131639222304026

Epoch: 6| Step: 12
Training loss: 1.742397427558899
Validation loss: 2.1413236459096274

Epoch: 6| Step: 13
Training loss: 2.209105968475342
Validation loss: 2.1463631987571716

Epoch: 185| Step: 0
Training loss: 2.2090859413146973
Validation loss: 2.149167537689209

Epoch: 6| Step: 1
Training loss: 2.0686020851135254
Validation loss: 2.1523539225260415

Epoch: 6| Step: 2
Training loss: 1.6658570766448975
Validation loss: 2.1636162598927817

Epoch: 6| Step: 3
Training loss: 1.472853422164917
Validation loss: 2.163946787516276

Epoch: 6| Step: 4
Training loss: 2.0761897563934326
Validation loss: 2.168968359629313

Epoch: 6| Step: 5
Training loss: 1.9969120025634766
Validation loss: 2.1690902709960938

Epoch: 6| Step: 6
Training loss: 1.6237714290618896
Validation loss: 2.171286463737488

Epoch: 6| Step: 7
Training loss: 1.452573299407959
Validation loss: 2.1692299842834473

Epoch: 6| Step: 8
Training loss: 2.2226133346557617
Validation loss: 2.169834017753601

Epoch: 6| Step: 9
Training loss: 2.3195371627807617
Validation loss: 2.1571871240933738

Epoch: 6| Step: 10
Training loss: 2.069429397583008
Validation loss: 2.1884599129358926

Epoch: 6| Step: 11
Training loss: 1.6939200162887573
Validation loss: 2.167927900950114

Epoch: 6| Step: 12
Training loss: 1.813838005065918
Validation loss: 2.188732624053955

Epoch: 6| Step: 13
Training loss: 1.7526202201843262
Validation loss: 2.1582354307174683

Epoch: 186| Step: 0
Training loss: 1.357424020767212
Validation loss: 2.156181832154592

Epoch: 6| Step: 1
Training loss: 2.3785905838012695
Validation loss: 2.1510168512662253

Epoch: 6| Step: 2
Training loss: 1.8824348449707031
Validation loss: 2.1309774518013

Epoch: 6| Step: 3
Training loss: 1.7609610557556152
Validation loss: 2.1211625138918557

Epoch: 6| Step: 4
Training loss: 2.5573577880859375
Validation loss: 2.136189659436544

Epoch: 6| Step: 5
Training loss: 1.6485172510147095
Validation loss: 2.1357173522313437

Epoch: 6| Step: 6
Training loss: 2.456303119659424
Validation loss: 2.1348886489868164

Epoch: 6| Step: 7
Training loss: 1.3080363273620605
Validation loss: 2.157290538152059

Epoch: 6| Step: 8
Training loss: 2.0940001010894775
Validation loss: 2.164731760819753

Epoch: 6| Step: 9
Training loss: 1.5264129638671875
Validation loss: 2.172083795070648

Epoch: 6| Step: 10
Training loss: 2.4323296546936035
Validation loss: 2.1962779561678567

Epoch: 6| Step: 11
Training loss: 1.8228760957717896
Validation loss: 2.199961245059967

Epoch: 6| Step: 12
Training loss: 1.9875816106796265
Validation loss: 2.187111258506775

Epoch: 6| Step: 13
Training loss: 1.5442005395889282
Validation loss: 2.174703141053518

Epoch: 187| Step: 0
Training loss: 1.8242225646972656
Validation loss: 2.172665456930796

Epoch: 6| Step: 1
Training loss: 1.7400426864624023
Validation loss: 2.1774694323539734

Epoch: 6| Step: 2
Training loss: 2.0669476985931396
Validation loss: 2.1706021229426065

Epoch: 6| Step: 3
Training loss: 2.2199251651763916
Validation loss: 2.149771253267924

Epoch: 6| Step: 4
Training loss: 1.6234352588653564
Validation loss: 2.161663234233856

Epoch: 6| Step: 5
Training loss: 2.3165977001190186
Validation loss: 2.1534469525019326

Epoch: 6| Step: 6
Training loss: 2.2396883964538574
Validation loss: 2.1370981534322104

Epoch: 6| Step: 7
Training loss: 1.3581488132476807
Validation loss: 2.135790685812632

Epoch: 6| Step: 8
Training loss: 1.4914355278015137
Validation loss: 2.139114737510681

Epoch: 6| Step: 9
Training loss: 2.04184627532959
Validation loss: 2.145708739757538

Epoch: 6| Step: 10
Training loss: 1.3176555633544922
Validation loss: 2.1337161660194397

Epoch: 6| Step: 11
Training loss: 2.045689582824707
Validation loss: 2.16398024559021

Epoch: 6| Step: 12
Training loss: 1.8055946826934814
Validation loss: 2.151836852232615

Epoch: 6| Step: 13
Training loss: 2.561851739883423
Validation loss: 2.1581398844718933

Epoch: 188| Step: 0
Training loss: 2.3919918537139893
Validation loss: 2.1691020131111145

Epoch: 6| Step: 1
Training loss: 1.8516714572906494
Validation loss: 2.16570907831192

Epoch: 6| Step: 2
Training loss: 1.9637901782989502
Validation loss: 2.164151748021444

Epoch: 6| Step: 3
Training loss: 1.3590234518051147
Validation loss: 2.1839623053868613

Epoch: 6| Step: 4
Training loss: 2.0383496284484863
Validation loss: 2.1898507873217263

Epoch: 6| Step: 5
Training loss: 1.808593988418579
Validation loss: 2.1738317211469016

Epoch: 6| Step: 6
Training loss: 1.8387666940689087
Validation loss: 2.1733054320017495

Epoch: 6| Step: 7
Training loss: 1.8257968425750732
Validation loss: 2.1673623522122702

Epoch: 6| Step: 8
Training loss: 1.823873519897461
Validation loss: 2.1675068537394204

Epoch: 6| Step: 9
Training loss: 2.4064831733703613
Validation loss: 2.1717228293418884

Epoch: 6| Step: 10
Training loss: 1.738052248954773
Validation loss: 2.1683480938275657

Epoch: 6| Step: 11
Training loss: 2.3855338096618652
Validation loss: 2.1612157026926675

Epoch: 6| Step: 12
Training loss: 1.4822217226028442
Validation loss: 2.1547420223553977

Epoch: 6| Step: 13
Training loss: 1.6470909118652344
Validation loss: 2.1654672622680664

Epoch: 189| Step: 0
Training loss: 1.3609919548034668
Validation loss: 2.1570702393849692

Epoch: 6| Step: 1
Training loss: 2.2334041595458984
Validation loss: 2.1629123091697693

Epoch: 6| Step: 2
Training loss: 1.9518625736236572
Validation loss: 2.1669113437334695

Epoch: 6| Step: 3
Training loss: 1.9449970722198486
Validation loss: 2.162432630856832

Epoch: 6| Step: 4
Training loss: 2.301032781600952
Validation loss: 2.172720193862915

Epoch: 6| Step: 5
Training loss: 2.2598352432250977
Validation loss: 2.183601180712382

Epoch: 6| Step: 6
Training loss: 1.6285113096237183
Validation loss: 2.1928349335988364

Epoch: 6| Step: 7
Training loss: 1.7531299591064453
Validation loss: 2.1934898098309836

Epoch: 6| Step: 8
Training loss: 1.6730072498321533
Validation loss: 2.204322636127472

Epoch: 6| Step: 9
Training loss: 1.7313241958618164
Validation loss: 2.201256215572357

Epoch: 6| Step: 10
Training loss: 1.8713288307189941
Validation loss: 2.1912217140197754

Epoch: 6| Step: 11
Training loss: 2.0055737495422363
Validation loss: 2.15676482518514

Epoch: 6| Step: 12
Training loss: 2.3077239990234375
Validation loss: 2.1712642908096313

Epoch: 6| Step: 13
Training loss: 1.7578065395355225
Validation loss: 2.160375992457072

Epoch: 190| Step: 0
Training loss: 1.6129564046859741
Validation loss: 2.154752492904663

Epoch: 6| Step: 1
Training loss: 1.9314650297164917
Validation loss: 2.1384665767351785

Epoch: 6| Step: 2
Training loss: 2.0870113372802734
Validation loss: 2.153717597325643

Epoch: 6| Step: 3
Training loss: 2.0893449783325195
Validation loss: 2.156278351942698

Epoch: 6| Step: 4
Training loss: 2.001861095428467
Validation loss: 2.147469937801361

Epoch: 6| Step: 5
Training loss: 1.5976437330245972
Validation loss: 2.153336544831594

Epoch: 6| Step: 6
Training loss: 1.7581409215927124
Validation loss: 2.1498303016026816

Epoch: 6| Step: 7
Training loss: 1.918035864830017
Validation loss: 2.1432368954022727

Epoch: 6| Step: 8
Training loss: 1.8624086380004883
Validation loss: 2.1539955536524453

Epoch: 6| Step: 9
Training loss: 1.7035003900527954
Validation loss: 2.167800029118856

Epoch: 6| Step: 10
Training loss: 2.1438863277435303
Validation loss: 2.1672544876734414

Epoch: 6| Step: 11
Training loss: 2.003066301345825
Validation loss: 2.1820751825968423

Epoch: 6| Step: 12
Training loss: 1.9413142204284668
Validation loss: 2.1868186394373574

Epoch: 6| Step: 13
Training loss: 1.8738627433776855
Validation loss: 2.1807846625645957

Epoch: 191| Step: 0
Training loss: 1.6909340620040894
Validation loss: 2.1684908469518027

Epoch: 6| Step: 1
Training loss: 0.9726572036743164
Validation loss: 2.1791895826657615

Epoch: 6| Step: 2
Training loss: 2.306239128112793
Validation loss: 2.167970657348633

Epoch: 6| Step: 3
Training loss: 1.7790228128433228
Validation loss: 2.178751210371653

Epoch: 6| Step: 4
Training loss: 2.1401119232177734
Validation loss: 2.1726397474606833

Epoch: 6| Step: 5
Training loss: 1.945965051651001
Validation loss: 2.1619691252708435

Epoch: 6| Step: 6
Training loss: 1.3040292263031006
Validation loss: 2.168790360291799

Epoch: 6| Step: 7
Training loss: 1.8343770503997803
Validation loss: 2.1555152535438538

Epoch: 6| Step: 8
Training loss: 2.0472121238708496
Validation loss: 2.166661500930786

Epoch: 6| Step: 9
Training loss: 1.7057691812515259
Validation loss: 2.1528758804003396

Epoch: 6| Step: 10
Training loss: 1.8464436531066895
Validation loss: 2.1694193283716836

Epoch: 6| Step: 11
Training loss: 1.9907383918762207
Validation loss: 2.163814981778463

Epoch: 6| Step: 12
Training loss: 2.069594621658325
Validation loss: 2.1554814179738364

Epoch: 6| Step: 13
Training loss: 2.6054015159606934
Validation loss: 2.1528831720352173

Epoch: 192| Step: 0
Training loss: 1.2330187559127808
Validation loss: 2.168085296948751

Epoch: 6| Step: 1
Training loss: 2.1052486896514893
Validation loss: 2.1856680313746133

Epoch: 6| Step: 2
Training loss: 1.4082223176956177
Validation loss: 2.166092256704966

Epoch: 6| Step: 3
Training loss: 1.3956091403961182
Validation loss: 2.1870413223902383

Epoch: 6| Step: 4
Training loss: 2.618170738220215
Validation loss: 2.1846823493639627

Epoch: 6| Step: 5
Training loss: 1.6189446449279785
Validation loss: 2.1848844289779663

Epoch: 6| Step: 6
Training loss: 1.809726357460022
Validation loss: 2.1844648122787476

Epoch: 6| Step: 7
Training loss: 2.319411277770996
Validation loss: 2.180789828300476

Epoch: 6| Step: 8
Training loss: 1.2080163955688477
Validation loss: 2.157797316710154

Epoch: 6| Step: 9
Training loss: 2.2948853969573975
Validation loss: 2.1552016337712607

Epoch: 6| Step: 10
Training loss: 1.4324334859848022
Validation loss: 2.134547015031179

Epoch: 6| Step: 11
Training loss: 2.7006165981292725
Validation loss: 2.1351494987805686

Epoch: 6| Step: 12
Training loss: 2.14340877532959
Validation loss: 2.135550598303477

Epoch: 6| Step: 13
Training loss: 2.2500767707824707
Validation loss: 2.139377156893412

Epoch: 193| Step: 0
Training loss: 1.700453281402588
Validation loss: 2.1416114568710327

Epoch: 6| Step: 1
Training loss: 2.0836150646209717
Validation loss: 2.1522617737452188

Epoch: 6| Step: 2
Training loss: 1.183823585510254
Validation loss: 2.1673388679822287

Epoch: 6| Step: 3
Training loss: 2.1210274696350098
Validation loss: 2.172624866167704

Epoch: 6| Step: 4
Training loss: 2.288255214691162
Validation loss: 2.181701978047689

Epoch: 6| Step: 5
Training loss: 1.4284179210662842
Validation loss: 2.194572925567627

Epoch: 6| Step: 6
Training loss: 2.048638105392456
Validation loss: 2.200825353463491

Epoch: 6| Step: 7
Training loss: 1.5981779098510742
Validation loss: 2.2105805476506553

Epoch: 6| Step: 8
Training loss: 2.030867576599121
Validation loss: 2.1985783775647483

Epoch: 6| Step: 9
Training loss: 2.1103427410125732
Validation loss: 2.1941699584325156

Epoch: 6| Step: 10
Training loss: 2.458838939666748
Validation loss: 2.1959877411524453

Epoch: 6| Step: 11
Training loss: 2.2356722354888916
Validation loss: 2.191279391447703

Epoch: 6| Step: 12
Training loss: 1.765836238861084
Validation loss: 2.185003956158956

Epoch: 6| Step: 13
Training loss: 1.7200491428375244
Validation loss: 2.1686968008677163

Epoch: 194| Step: 0
Training loss: 1.8000049591064453
Validation loss: 2.1531361738840737

Epoch: 6| Step: 1
Training loss: 1.9423879384994507
Validation loss: 2.1393821835517883

Epoch: 6| Step: 2
Training loss: 2.30989933013916
Validation loss: 2.123279571533203

Epoch: 6| Step: 3
Training loss: 2.2303874492645264
Validation loss: 2.118970433870951

Epoch: 6| Step: 4
Training loss: 1.63755202293396
Validation loss: 2.1231852968533835

Epoch: 6| Step: 5
Training loss: 1.7067418098449707
Validation loss: 2.111463785171509

Epoch: 6| Step: 6
Training loss: 2.424473285675049
Validation loss: 2.11655600865682

Epoch: 6| Step: 7
Training loss: 2.6870265007019043
Validation loss: 2.132525404294332

Epoch: 6| Step: 8
Training loss: 2.1572394371032715
Validation loss: 2.1123699943224588

Epoch: 6| Step: 9
Training loss: 1.5348764657974243
Validation loss: 2.117276926835378

Epoch: 6| Step: 10
Training loss: 1.6560468673706055
Validation loss: 2.120604952176412

Epoch: 6| Step: 11
Training loss: 1.9466710090637207
Validation loss: 2.1259242494901023

Epoch: 6| Step: 12
Training loss: 1.500469446182251
Validation loss: 2.1341720819473267

Epoch: 6| Step: 13
Training loss: 1.9945558309555054
Validation loss: 2.1585323214530945

Epoch: 195| Step: 0
Training loss: 2.231307029724121
Validation loss: 2.170204758644104

Epoch: 6| Step: 1
Training loss: 2.177126884460449
Validation loss: 2.185524503389994

Epoch: 6| Step: 2
Training loss: 2.4192872047424316
Validation loss: 2.1909521420796714

Epoch: 6| Step: 3
Training loss: 2.000418186187744
Validation loss: 2.2062335213025412

Epoch: 6| Step: 4
Training loss: 2.0418756008148193
Validation loss: 2.1977009971936545

Epoch: 6| Step: 5
Training loss: 1.4303851127624512
Validation loss: 2.2112650275230408

Epoch: 6| Step: 6
Training loss: 1.9295543432235718
Validation loss: 2.220684031645457

Epoch: 6| Step: 7
Training loss: 1.735823631286621
Validation loss: 2.2311777472496033

Epoch: 6| Step: 8
Training loss: 1.9617327451705933
Validation loss: 2.2272115349769592

Epoch: 6| Step: 9
Training loss: 1.8006019592285156
Validation loss: 2.2192565401395163

Epoch: 6| Step: 10
Training loss: 1.4333305358886719
Validation loss: 2.2226032416025796

Epoch: 6| Step: 11
Training loss: 1.944129228591919
Validation loss: 2.179418206214905

Epoch: 6| Step: 12
Training loss: 1.846491813659668
Validation loss: 2.1802082856496177

Epoch: 6| Step: 13
Training loss: 1.598678469657898
Validation loss: 2.1624428828557334

Epoch: 196| Step: 0
Training loss: 1.4909327030181885
Validation loss: 2.1589983105659485

Epoch: 6| Step: 1
Training loss: 1.7908656597137451
Validation loss: 2.147399445374807

Epoch: 6| Step: 2
Training loss: 1.1960577964782715
Validation loss: 2.1477874716122947

Epoch: 6| Step: 3
Training loss: 1.7101709842681885
Validation loss: 2.1398184100786843

Epoch: 6| Step: 4
Training loss: 1.9367072582244873
Validation loss: 2.1499151388804116

Epoch: 6| Step: 5
Training loss: 1.877073884010315
Validation loss: 2.1425328652064004

Epoch: 6| Step: 6
Training loss: 2.082303524017334
Validation loss: 2.13929945230484

Epoch: 6| Step: 7
Training loss: 2.367027759552002
Validation loss: 2.1390196681022644

Epoch: 6| Step: 8
Training loss: 2.5459091663360596
Validation loss: 2.1541326443354287

Epoch: 6| Step: 9
Training loss: 2.024970531463623
Validation loss: 2.1704089641571045

Epoch: 6| Step: 10
Training loss: 1.5007013082504272
Validation loss: 2.1781133810679116

Epoch: 6| Step: 11
Training loss: 2.172252655029297
Validation loss: 2.1717923879623413

Epoch: 6| Step: 12
Training loss: 2.065481424331665
Validation loss: 2.1861449480056763

Epoch: 6| Step: 13
Training loss: 1.9624807834625244
Validation loss: 2.200169245402018

Epoch: 197| Step: 0
Training loss: 1.7804027795791626
Validation loss: 2.1799117724100747

Epoch: 6| Step: 1
Training loss: 2.665679454803467
Validation loss: 2.2027685840924582

Epoch: 6| Step: 2
Training loss: 1.6803538799285889
Validation loss: 2.200676163037618

Epoch: 6| Step: 3
Training loss: 1.703701376914978
Validation loss: 2.1876513759295144

Epoch: 6| Step: 4
Training loss: 1.7864797115325928
Validation loss: 2.1904911597569785

Epoch: 6| Step: 5
Training loss: 2.136201858520508
Validation loss: 2.1749058961868286

Epoch: 6| Step: 6
Training loss: 2.178915023803711
Validation loss: 2.165655573209127

Epoch: 6| Step: 7
Training loss: 1.793635606765747
Validation loss: 2.1671974261601767

Epoch: 6| Step: 8
Training loss: 2.076812267303467
Validation loss: 2.1564072966575623

Epoch: 6| Step: 9
Training loss: 1.8146781921386719
Validation loss: 2.1632014910380044

Epoch: 6| Step: 10
Training loss: 2.1243443489074707
Validation loss: 2.156895319620768

Epoch: 6| Step: 11
Training loss: 1.5484708547592163
Validation loss: 2.1561022798220315

Epoch: 6| Step: 12
Training loss: 2.0125718116760254
Validation loss: 2.1637050906817117

Epoch: 6| Step: 13
Training loss: 1.4331270456314087
Validation loss: 2.1560020049413047

Epoch: 198| Step: 0
Training loss: 1.4656288623809814
Validation loss: 2.1566377878189087

Epoch: 6| Step: 1
Training loss: 1.9722708463668823
Validation loss: 2.145818372567495

Epoch: 6| Step: 2
Training loss: 1.9173240661621094
Validation loss: 2.1599830190340676

Epoch: 6| Step: 3
Training loss: 2.7454400062561035
Validation loss: 2.148389458656311

Epoch: 6| Step: 4
Training loss: 1.5911608934402466
Validation loss: 2.1532822052637735

Epoch: 6| Step: 5
Training loss: 1.6709983348846436
Validation loss: 2.163551469643911

Epoch: 6| Step: 6
Training loss: 2.341492176055908
Validation loss: 2.165217379728953

Epoch: 6| Step: 7
Training loss: 1.701969027519226
Validation loss: 2.1464667121569314

Epoch: 6| Step: 8
Training loss: 1.7733033895492554
Validation loss: 2.162652770678202

Epoch: 6| Step: 9
Training loss: 2.6854190826416016
Validation loss: 2.160494327545166

Epoch: 6| Step: 10
Training loss: 1.920252799987793
Validation loss: 2.1617785692214966

Epoch: 6| Step: 11
Training loss: 2.0301356315612793
Validation loss: 2.17139462629954

Epoch: 6| Step: 12
Training loss: 1.2324308156967163
Validation loss: 2.1945873498916626

Epoch: 6| Step: 13
Training loss: 1.3283627033233643
Validation loss: 2.197575648625692

Epoch: 199| Step: 0
Training loss: 1.4779622554779053
Validation loss: 2.184733827908834

Epoch: 6| Step: 1
Training loss: 1.5946309566497803
Validation loss: 2.2024791836738586

Epoch: 6| Step: 2
Training loss: 1.7161900997161865
Validation loss: 2.2066829204559326

Epoch: 6| Step: 3
Training loss: 2.0999321937561035
Validation loss: 2.187267561753591

Epoch: 6| Step: 4
Training loss: 1.2200350761413574
Validation loss: 2.1816866397857666

Epoch: 6| Step: 5
Training loss: 1.8445056676864624
Validation loss: 2.17698468764623

Epoch: 6| Step: 6
Training loss: 1.6453481912612915
Validation loss: 2.1651249527931213

Epoch: 6| Step: 7
Training loss: 2.59452486038208
Validation loss: 2.166847546895345

Epoch: 6| Step: 8
Training loss: 2.330854892730713
Validation loss: 2.166661540667216

Epoch: 6| Step: 9
Training loss: 2.538783550262451
Validation loss: 2.1653358340263367

Epoch: 6| Step: 10
Training loss: 1.726816177368164
Validation loss: 2.1668636401494346

Epoch: 6| Step: 11
Training loss: 1.2474777698516846
Validation loss: 2.1774514516194663

Epoch: 6| Step: 12
Training loss: 2.1106724739074707
Validation loss: 2.168151239554087

Epoch: 6| Step: 13
Training loss: 1.9114394187927246
Validation loss: 2.17172118028005

Epoch: 200| Step: 0
Training loss: 1.3145697116851807
Validation loss: 2.1623268524805703

Epoch: 6| Step: 1
Training loss: 1.7582861185073853
Validation loss: 2.169497867425283

Epoch: 6| Step: 2
Training loss: 1.2786753177642822
Validation loss: 2.1773460110028586

Epoch: 6| Step: 3
Training loss: 1.485571026802063
Validation loss: 2.1955190896987915

Epoch: 6| Step: 4
Training loss: 1.44850492477417
Validation loss: 2.191915194193522

Epoch: 6| Step: 5
Training loss: 2.750464916229248
Validation loss: 2.184562623500824

Epoch: 6| Step: 6
Training loss: 2.750720500946045
Validation loss: 2.1955246925354004

Epoch: 6| Step: 7
Training loss: 1.9350553750991821
Validation loss: 2.2024844884872437

Epoch: 6| Step: 8
Training loss: 1.5726239681243896
Validation loss: 2.2007559140523276

Epoch: 6| Step: 9
Training loss: 1.92653489112854
Validation loss: 2.199273427327474

Epoch: 6| Step: 10
Training loss: 2.6710660457611084
Validation loss: 2.209553857644399

Epoch: 6| Step: 11
Training loss: 1.9315625429153442
Validation loss: 2.1951152880986533

Epoch: 6| Step: 12
Training loss: 1.7776046991348267
Validation loss: 2.1935006578763327

Epoch: 6| Step: 13
Training loss: 1.4936354160308838
Validation loss: 2.2023670276006064

Epoch: 201| Step: 0
Training loss: 1.9185729026794434
Validation loss: 2.1655924717585244

Epoch: 6| Step: 1
Training loss: 2.7337496280670166
Validation loss: 2.1597476402918496

Epoch: 6| Step: 2
Training loss: 2.5024261474609375
Validation loss: 2.1617500384648642

Epoch: 6| Step: 3
Training loss: 1.2062524557113647
Validation loss: 2.179783364137014

Epoch: 6| Step: 4
Training loss: 1.456024408340454
Validation loss: 2.1903531153996787

Epoch: 6| Step: 5
Training loss: 2.47212290763855
Validation loss: 2.191968639691671

Epoch: 6| Step: 6
Training loss: 1.5262433290481567
Validation loss: 2.193745712439219

Epoch: 6| Step: 7
Training loss: 1.739885687828064
Validation loss: 2.21004851659139

Epoch: 6| Step: 8
Training loss: 1.5471925735473633
Validation loss: 2.2029913862546286

Epoch: 6| Step: 9
Training loss: 1.3798253536224365
Validation loss: 2.183713356653849

Epoch: 6| Step: 10
Training loss: 2.188002109527588
Validation loss: 2.1962955792744956

Epoch: 6| Step: 11
Training loss: 1.715230107307434
Validation loss: 2.192263344923655

Epoch: 6| Step: 12
Training loss: 2.225471019744873
Validation loss: 2.181209981441498

Epoch: 6| Step: 13
Training loss: 1.2893341779708862
Validation loss: 2.2109312415122986

Epoch: 202| Step: 0
Training loss: 1.995632529258728
Validation loss: 2.1943668921788535

Epoch: 6| Step: 1
Training loss: 2.0764212608337402
Validation loss: 2.20011568069458

Epoch: 6| Step: 2
Training loss: 1.5432448387145996
Validation loss: 2.199773848056793

Epoch: 6| Step: 3
Training loss: 1.902815580368042
Validation loss: 2.202661077181498

Epoch: 6| Step: 4
Training loss: 2.02555513381958
Validation loss: 2.17531019449234

Epoch: 6| Step: 5
Training loss: 1.286299228668213
Validation loss: 2.1729253133138022

Epoch: 6| Step: 6
Training loss: 1.7871514558792114
Validation loss: 2.170405069986979

Epoch: 6| Step: 7
Training loss: 1.6192071437835693
Validation loss: 2.176863133907318

Epoch: 6| Step: 8
Training loss: 2.368190288543701
Validation loss: 2.1779361764589944

Epoch: 6| Step: 9
Training loss: 2.2303709983825684
Validation loss: 2.19401087363561

Epoch: 6| Step: 10
Training loss: 1.4872766733169556
Validation loss: 2.1970046559969583

Epoch: 6| Step: 11
Training loss: 2.5395050048828125
Validation loss: 2.1817835569381714

Epoch: 6| Step: 12
Training loss: 1.4594227075576782
Validation loss: 2.199562390645345

Epoch: 6| Step: 13
Training loss: 1.6963356733322144
Validation loss: 2.1927242279052734

Epoch: 203| Step: 0
Training loss: 1.5614653825759888
Validation loss: 2.190016269683838

Epoch: 6| Step: 1
Training loss: 2.4338536262512207
Validation loss: 2.1857101122538247

Epoch: 6| Step: 2
Training loss: 1.7733285427093506
Validation loss: 2.19326780239741

Epoch: 6| Step: 3
Training loss: 2.1747288703918457
Validation loss: 2.190709630648295

Epoch: 6| Step: 4
Training loss: 1.1878224611282349
Validation loss: 2.1910272439320884

Epoch: 6| Step: 5
Training loss: 1.3751111030578613
Validation loss: 2.181797285874685

Epoch: 6| Step: 6
Training loss: 2.186861038208008
Validation loss: 2.183420976003011

Epoch: 6| Step: 7
Training loss: 1.821913242340088
Validation loss: 2.210507035255432

Epoch: 6| Step: 8
Training loss: 2.161520004272461
Validation loss: 2.2029196421305337

Epoch: 6| Step: 9
Training loss: 2.119874954223633
Validation loss: 2.204210122426351

Epoch: 6| Step: 10
Training loss: 1.7753472328186035
Validation loss: 2.1988033850987754

Epoch: 6| Step: 11
Training loss: 1.7984436750411987
Validation loss: 2.1981958945592246

Epoch: 6| Step: 12
Training loss: 2.150615930557251
Validation loss: 2.199069360891978

Epoch: 6| Step: 13
Training loss: 1.252051830291748
Validation loss: 2.2055984338124595

Epoch: 204| Step: 0
Training loss: 1.6057655811309814
Validation loss: 2.215506891409556

Epoch: 6| Step: 1
Training loss: 1.966194748878479
Validation loss: 2.194588283697764

Epoch: 6| Step: 2
Training loss: 2.364107370376587
Validation loss: 2.1796622276306152

Epoch: 6| Step: 3
Training loss: 2.220829486846924
Validation loss: 2.193640351295471

Epoch: 6| Step: 4
Training loss: 1.8816473484039307
Validation loss: 2.1973756551742554

Epoch: 6| Step: 5
Training loss: 1.7441844940185547
Validation loss: 2.184317429860433

Epoch: 6| Step: 6
Training loss: 1.8189034461975098
Validation loss: 2.1783116857210794

Epoch: 6| Step: 7
Training loss: 1.820402979850769
Validation loss: 2.1843707164128623

Epoch: 6| Step: 8
Training loss: 1.5296506881713867
Validation loss: 2.185772478580475

Epoch: 6| Step: 9
Training loss: 2.4331283569335938
Validation loss: 2.1801843444506326

Epoch: 6| Step: 10
Training loss: 1.636276364326477
Validation loss: 2.1927611430486045

Epoch: 6| Step: 11
Training loss: 1.6106452941894531
Validation loss: 2.19303168853124

Epoch: 6| Step: 12
Training loss: 1.766326665878296
Validation loss: 2.1927123069763184

Epoch: 6| Step: 13
Training loss: 1.5479527711868286
Validation loss: 2.211361885070801

Epoch: 205| Step: 0
Training loss: 1.8721272945404053
Validation loss: 2.213219424088796

Epoch: 6| Step: 1
Training loss: 2.05946683883667
Validation loss: 2.2103052934010825

Epoch: 6| Step: 2
Training loss: 2.4895009994506836
Validation loss: 2.221428712209066

Epoch: 6| Step: 3
Training loss: 1.8372410535812378
Validation loss: 2.2122538487116494

Epoch: 6| Step: 4
Training loss: 1.4268743991851807
Validation loss: 2.2176248033841452

Epoch: 6| Step: 5
Training loss: 1.7977511882781982
Validation loss: 2.1918535232543945

Epoch: 6| Step: 6
Training loss: 2.002289295196533
Validation loss: 2.196207424004873

Epoch: 6| Step: 7
Training loss: 1.9662904739379883
Validation loss: 2.1889009277025857

Epoch: 6| Step: 8
Training loss: 2.3234636783599854
Validation loss: 2.1958234906196594

Epoch: 6| Step: 9
Training loss: 1.4072966575622559
Validation loss: 2.19832452138265

Epoch: 6| Step: 10
Training loss: 2.4117226600646973
Validation loss: 2.19083571434021

Epoch: 6| Step: 11
Training loss: 1.8435827493667603
Validation loss: 2.204937736193339

Epoch: 6| Step: 12
Training loss: 1.4389017820358276
Validation loss: 2.2049101193745932

Epoch: 6| Step: 13
Training loss: 1.1133809089660645
Validation loss: 2.2125567396481833

Epoch: 206| Step: 0
Training loss: 1.9489332437515259
Validation loss: 2.20496141910553

Epoch: 6| Step: 1
Training loss: 1.3329540491104126
Validation loss: 2.236007551352183

Epoch: 6| Step: 2
Training loss: 1.66322922706604
Validation loss: 2.2152482668558755

Epoch: 6| Step: 3
Training loss: 1.9461734294891357
Validation loss: 2.2099520564079285

Epoch: 6| Step: 4
Training loss: 2.381831169128418
Validation loss: 2.1940267086029053

Epoch: 6| Step: 5
Training loss: 2.519164562225342
Validation loss: 2.2055524786313376

Epoch: 6| Step: 6
Training loss: 1.3050754070281982
Validation loss: 2.19815593957901

Epoch: 6| Step: 7
Training loss: 1.7300485372543335
Validation loss: 2.2042497992515564

Epoch: 6| Step: 8
Training loss: 2.0579376220703125
Validation loss: 2.1986361742019653

Epoch: 6| Step: 9
Training loss: 1.999472975730896
Validation loss: 2.2109464208285012

Epoch: 6| Step: 10
Training loss: 1.9555772542953491
Validation loss: 2.2153602242469788

Epoch: 6| Step: 11
Training loss: 1.4444000720977783
Validation loss: 2.1995737552642822

Epoch: 6| Step: 12
Training loss: 1.5300278663635254
Validation loss: 2.199697216351827

Epoch: 6| Step: 13
Training loss: 2.1250782012939453
Validation loss: 2.202223002910614

Epoch: 207| Step: 0
Training loss: 2.343059539794922
Validation loss: 2.2052929401397705

Epoch: 6| Step: 1
Training loss: 1.3532389402389526
Validation loss: 2.203633666038513

Epoch: 6| Step: 2
Training loss: 1.9402726888656616
Validation loss: 2.2044257720311484

Epoch: 6| Step: 3
Training loss: 1.80287504196167
Validation loss: 2.1964882016181946

Epoch: 6| Step: 4
Training loss: 2.3320186138153076
Validation loss: 2.204785704612732

Epoch: 6| Step: 5
Training loss: 1.5230677127838135
Validation loss: 2.2032899061838784

Epoch: 6| Step: 6
Training loss: 2.1700572967529297
Validation loss: 2.2018591165542603

Epoch: 6| Step: 7
Training loss: 1.1301538944244385
Validation loss: 2.1855162183443704

Epoch: 6| Step: 8
Training loss: 2.1417174339294434
Validation loss: 2.2121523221333823

Epoch: 6| Step: 9
Training loss: 1.856476068496704
Validation loss: 2.1937849521636963

Epoch: 6| Step: 10
Training loss: 1.4781850576400757
Validation loss: 2.1869107286135354

Epoch: 6| Step: 11
Training loss: 1.9891539812088013
Validation loss: 2.2040043671925864

Epoch: 6| Step: 12
Training loss: 2.027066230773926
Validation loss: 2.1886578798294067

Epoch: 6| Step: 13
Training loss: 1.5017225742340088
Validation loss: 2.201137681802114

Epoch: 208| Step: 0
Training loss: 1.351694941520691
Validation loss: 2.1977055072784424

Epoch: 6| Step: 1
Training loss: 2.1145026683807373
Validation loss: 2.203161358833313

Epoch: 6| Step: 2
Training loss: 2.235926866531372
Validation loss: 2.192947586377462

Epoch: 6| Step: 3
Training loss: 1.844901442527771
Validation loss: 2.2002378900845847

Epoch: 6| Step: 4
Training loss: 1.5819668769836426
Validation loss: 2.201735476652781

Epoch: 6| Step: 5
Training loss: 1.612920880317688
Validation loss: 2.1918323636054993

Epoch: 6| Step: 6
Training loss: 2.1853818893432617
Validation loss: 2.1856712897618613

Epoch: 6| Step: 7
Training loss: 1.6151809692382812
Validation loss: 2.19146990776062

Epoch: 6| Step: 8
Training loss: 2.806562662124634
Validation loss: 2.189959625403086

Epoch: 6| Step: 9
Training loss: 1.7784380912780762
Validation loss: 2.1877997517585754

Epoch: 6| Step: 10
Training loss: 1.139471411705017
Validation loss: 2.1585572759310403

Epoch: 6| Step: 11
Training loss: 1.946370244026184
Validation loss: 2.186878025531769

Epoch: 6| Step: 12
Training loss: 2.2091450691223145
Validation loss: 2.1866494019826255

Epoch: 6| Step: 13
Training loss: 1.630490779876709
Validation loss: 2.1747466723124185

Epoch: 209| Step: 0
Training loss: 2.7811379432678223
Validation loss: 2.193453629811605

Epoch: 6| Step: 1
Training loss: 1.7337052822113037
Validation loss: 2.19189989566803

Epoch: 6| Step: 2
Training loss: 1.9194426536560059
Validation loss: 2.2049716114997864

Epoch: 6| Step: 3
Training loss: 1.7988685369491577
Validation loss: 2.211049278577169

Epoch: 6| Step: 4
Training loss: 1.6659438610076904
Validation loss: 2.2244420051574707

Epoch: 6| Step: 5
Training loss: 1.518479347229004
Validation loss: 2.213940660158793

Epoch: 6| Step: 6
Training loss: 1.8621116876602173
Validation loss: 2.2230140566825867

Epoch: 6| Step: 7
Training loss: 1.8258739709854126
Validation loss: 2.210854252179464

Epoch: 6| Step: 8
Training loss: 2.0753557682037354
Validation loss: 2.208415230115255

Epoch: 6| Step: 9
Training loss: 1.1634244918823242
Validation loss: 2.193569004535675

Epoch: 6| Step: 10
Training loss: 1.95612633228302
Validation loss: 2.1914389928181968

Epoch: 6| Step: 11
Training loss: 1.8209545612335205
Validation loss: 2.184347709019979

Epoch: 6| Step: 12
Training loss: 2.283449172973633
Validation loss: 2.174335777759552

Epoch: 6| Step: 13
Training loss: 1.3767808675765991
Validation loss: 2.165315270423889

Epoch: 210| Step: 0
Training loss: 1.286393642425537
Validation loss: 2.1810964345932007

Epoch: 6| Step: 1
Training loss: 1.8083194494247437
Validation loss: 2.1600545843442283

Epoch: 6| Step: 2
Training loss: 1.4361035823822021
Validation loss: 2.1920987963676453

Epoch: 6| Step: 3
Training loss: 1.837967872619629
Validation loss: 2.198764761288961

Epoch: 6| Step: 4
Training loss: 2.2284157276153564
Validation loss: 2.1998910307884216

Epoch: 6| Step: 5
Training loss: 2.3380565643310547
Validation loss: 2.1976097424825034

Epoch: 6| Step: 6
Training loss: 1.6293240785598755
Validation loss: 2.194437325000763

Epoch: 6| Step: 7
Training loss: 1.889169454574585
Validation loss: 2.218687415122986

Epoch: 6| Step: 8
Training loss: 1.7771011590957642
Validation loss: 2.212264577547709

Epoch: 6| Step: 9
Training loss: 2.0885491371154785
Validation loss: 2.215761959552765

Epoch: 6| Step: 10
Training loss: 1.6744508743286133
Validation loss: 2.2154829502105713

Epoch: 6| Step: 11
Training loss: 1.8777166604995728
Validation loss: 2.2146337429682412

Epoch: 6| Step: 12
Training loss: 1.9557390213012695
Validation loss: 2.22371514638265

Epoch: 6| Step: 13
Training loss: 2.070561408996582
Validation loss: 2.2087688644727073

Epoch: 211| Step: 0
Training loss: 1.3231194019317627
Validation loss: 2.2044965426127114

Epoch: 6| Step: 1
Training loss: 1.4747967720031738
Validation loss: 2.2064968744913735

Epoch: 6| Step: 2
Training loss: 1.8370113372802734
Validation loss: 2.193389276663462

Epoch: 6| Step: 3
Training loss: 1.7938973903656006
Validation loss: 2.187772254149119

Epoch: 6| Step: 4
Training loss: 1.6032400131225586
Validation loss: 2.1798850893974304

Epoch: 6| Step: 5
Training loss: 2.510061264038086
Validation loss: 2.199543575445811

Epoch: 6| Step: 6
Training loss: 1.8915987014770508
Validation loss: 2.2040780782699585

Epoch: 6| Step: 7
Training loss: 1.4609010219573975
Validation loss: 2.204756955305735

Epoch: 6| Step: 8
Training loss: 2.1287922859191895
Validation loss: 2.2013022700945535

Epoch: 6| Step: 9
Training loss: 2.003899574279785
Validation loss: 2.2020164926846824

Epoch: 6| Step: 10
Training loss: 2.000195026397705
Validation loss: 2.2013906637827554

Epoch: 6| Step: 11
Training loss: 1.931086778640747
Validation loss: 2.2135265866915383

Epoch: 6| Step: 12
Training loss: 1.342655897140503
Validation loss: 2.220089534918467

Epoch: 6| Step: 13
Training loss: 2.34641432762146
Validation loss: 2.2229296962420144

Epoch: 212| Step: 0
Training loss: 1.6572084426879883
Validation loss: 2.2055261731147766

Epoch: 6| Step: 1
Training loss: 1.437973976135254
Validation loss: 2.1938412189483643

Epoch: 6| Step: 2
Training loss: 1.9899334907531738
Validation loss: 2.2150821685791016

Epoch: 6| Step: 3
Training loss: 1.8555623292922974
Validation loss: 2.2101468245188394

Epoch: 6| Step: 4
Training loss: 1.9511587619781494
Validation loss: 2.2116838892300925

Epoch: 6| Step: 5
Training loss: 1.8326228857040405
Validation loss: 2.2144511938095093

Epoch: 6| Step: 6
Training loss: 2.2385623455047607
Validation loss: 2.2231177488962808

Epoch: 6| Step: 7
Training loss: 2.017223358154297
Validation loss: 2.2214808066685996

Epoch: 6| Step: 8
Training loss: 1.9216530323028564
Validation loss: 2.211196700731913

Epoch: 6| Step: 9
Training loss: 1.2345659732818604
Validation loss: 2.207611362139384

Epoch: 6| Step: 10
Training loss: 1.3160701990127563
Validation loss: 2.2146575252215066

Epoch: 6| Step: 11
Training loss: 1.8524192571640015
Validation loss: 2.221269726753235

Epoch: 6| Step: 12
Training loss: 2.409928321838379
Validation loss: 2.2066338658332825

Epoch: 6| Step: 13
Training loss: 1.3738842010498047
Validation loss: 2.2183613777160645

Epoch: 213| Step: 0
Training loss: 1.2489545345306396
Validation loss: 2.211404323577881

Epoch: 6| Step: 1
Training loss: 2.682070016860962
Validation loss: 2.203708012898763

Epoch: 6| Step: 2
Training loss: 1.8754150867462158
Validation loss: 2.1991122166315713

Epoch: 6| Step: 3
Training loss: 2.3515820503234863
Validation loss: 2.1772294441858926

Epoch: 6| Step: 4
Training loss: 1.6686149835586548
Validation loss: 2.175865054130554

Epoch: 6| Step: 5
Training loss: 1.2237147092819214
Validation loss: 2.1857741872469583

Epoch: 6| Step: 6
Training loss: 2.2996623516082764
Validation loss: 2.180759072303772

Epoch: 6| Step: 7
Training loss: 1.6419551372528076
Validation loss: 2.1768086751302085

Epoch: 6| Step: 8
Training loss: 2.34416127204895
Validation loss: 2.1799093087514243

Epoch: 6| Step: 9
Training loss: 1.8853440284729004
Validation loss: 2.174790104230245

Epoch: 6| Step: 10
Training loss: 1.826995611190796
Validation loss: 2.1959566473960876

Epoch: 6| Step: 11
Training loss: 1.568479061126709
Validation loss: 2.210128049055735

Epoch: 6| Step: 12
Training loss: 1.4964773654937744
Validation loss: 2.2218539913495383

Epoch: 6| Step: 13
Training loss: 1.4560632705688477
Validation loss: 2.209067424138387

Epoch: 214| Step: 0
Training loss: 2.1957671642303467
Validation loss: 2.220242222150167

Epoch: 6| Step: 1
Training loss: 1.9673056602478027
Validation loss: 2.2128323316574097

Epoch: 6| Step: 2
Training loss: 1.2418229579925537
Validation loss: 2.2378565271695456

Epoch: 6| Step: 3
Training loss: 2.0201094150543213
Validation loss: 2.226475954055786

Epoch: 6| Step: 4
Training loss: 2.634432554244995
Validation loss: 2.2170045375823975

Epoch: 6| Step: 5
Training loss: 1.851645588874817
Validation loss: 2.2228575547536216

Epoch: 6| Step: 6
Training loss: 1.677755355834961
Validation loss: 2.2310403982798257

Epoch: 6| Step: 7
Training loss: 1.4382655620574951
Validation loss: 2.23390656709671

Epoch: 6| Step: 8
Training loss: 1.9317563772201538
Validation loss: 2.2267187436421714

Epoch: 6| Step: 9
Training loss: 1.5326063632965088
Validation loss: 2.2166026830673218

Epoch: 6| Step: 10
Training loss: 1.4394543170928955
Validation loss: 2.216372489929199

Epoch: 6| Step: 11
Training loss: 2.2819929122924805
Validation loss: 2.2348662614822388

Epoch: 6| Step: 12
Training loss: 1.7864694595336914
Validation loss: 2.2209776639938354

Epoch: 6| Step: 13
Training loss: 1.4194682836532593
Validation loss: 2.2123083670934043

Epoch: 215| Step: 0
Training loss: 2.163651943206787
Validation loss: 2.1764986912409463

Epoch: 6| Step: 1
Training loss: 2.0386924743652344
Validation loss: 2.1892262895902

Epoch: 6| Step: 2
Training loss: 2.5492186546325684
Validation loss: 2.179877499739329

Epoch: 6| Step: 3
Training loss: 1.0411367416381836
Validation loss: 2.1751592556635537

Epoch: 6| Step: 4
Training loss: 2.262458562850952
Validation loss: 2.1732890208562217

Epoch: 6| Step: 5
Training loss: 2.0007266998291016
Validation loss: 2.179042478402456

Epoch: 6| Step: 6
Training loss: 0.842136561870575
Validation loss: 2.182950417200724

Epoch: 6| Step: 7
Training loss: 1.847520351409912
Validation loss: 2.180613120396932

Epoch: 6| Step: 8
Training loss: 1.884129524230957
Validation loss: 2.186049779256185

Epoch: 6| Step: 9
Training loss: 1.4550725221633911
Validation loss: 2.192049026489258

Epoch: 6| Step: 10
Training loss: 1.539329171180725
Validation loss: 2.2130136092503867

Epoch: 6| Step: 11
Training loss: 1.826169729232788
Validation loss: 2.1984757781028748

Epoch: 6| Step: 12
Training loss: 1.6785180568695068
Validation loss: 2.2042905489603677

Epoch: 6| Step: 13
Training loss: 2.429075241088867
Validation loss: 2.2058822313944497

Epoch: 216| Step: 0
Training loss: 1.8645286560058594
Validation loss: 2.212311605612437

Epoch: 6| Step: 1
Training loss: 1.884056568145752
Validation loss: 2.221193770567576

Epoch: 6| Step: 2
Training loss: 1.3547241687774658
Validation loss: 2.2101186712582908

Epoch: 6| Step: 3
Training loss: 1.7321414947509766
Validation loss: 2.2199939688046775

Epoch: 6| Step: 4
Training loss: 1.710066795349121
Validation loss: 2.2097097833951316

Epoch: 6| Step: 5
Training loss: 1.5127341747283936
Validation loss: 2.2009421785672507

Epoch: 6| Step: 6
Training loss: 2.30613374710083
Validation loss: 2.180668592453003

Epoch: 6| Step: 7
Training loss: 1.9203612804412842
Validation loss: 2.196869174639384

Epoch: 6| Step: 8
Training loss: 1.5728957653045654
Validation loss: 2.1979729731877646

Epoch: 6| Step: 9
Training loss: 2.1680908203125
Validation loss: 2.1824574867884317

Epoch: 6| Step: 10
Training loss: 1.8909220695495605
Validation loss: 2.208341360092163

Epoch: 6| Step: 11
Training loss: 1.7744274139404297
Validation loss: 2.2001796762148538

Epoch: 6| Step: 12
Training loss: 2.278632164001465
Validation loss: 2.197055141131083

Epoch: 6| Step: 13
Training loss: 1.5659600496292114
Validation loss: 2.2000140150388083

Epoch: 217| Step: 0
Training loss: 1.6819789409637451
Validation loss: 2.204780717690786

Epoch: 6| Step: 1
Training loss: 0.8757243156433105
Validation loss: 2.212671478589376

Epoch: 6| Step: 2
Training loss: 1.554342269897461
Validation loss: 2.1879168351491294

Epoch: 6| Step: 3
Training loss: 2.3736648559570312
Validation loss: 2.223546087741852

Epoch: 6| Step: 4
Training loss: 1.8407618999481201
Validation loss: 2.2092974185943604

Epoch: 6| Step: 5
Training loss: 1.2477705478668213
Validation loss: 2.1944639682769775

Epoch: 6| Step: 6
Training loss: 2.1628870964050293
Validation loss: 2.1974212725957236

Epoch: 6| Step: 7
Training loss: 2.5117292404174805
Validation loss: 2.1872037251790366

Epoch: 6| Step: 8
Training loss: 1.7645211219787598
Validation loss: 2.202399651209513

Epoch: 6| Step: 9
Training loss: 1.951596975326538
Validation loss: 2.1959259112675986

Epoch: 6| Step: 10
Training loss: 1.8298282623291016
Validation loss: 2.199037233988444

Epoch: 6| Step: 11
Training loss: 2.1420013904571533
Validation loss: 2.194305141766866

Epoch: 6| Step: 12
Training loss: 2.0591206550598145
Validation loss: 2.193273921807607

Epoch: 6| Step: 13
Training loss: 1.70131254196167
Validation loss: 2.1996119022369385

Epoch: 218| Step: 0
Training loss: 1.982287883758545
Validation loss: 2.205186645189921

Epoch: 6| Step: 1
Training loss: 2.1975865364074707
Validation loss: 2.21648907661438

Epoch: 6| Step: 2
Training loss: 1.6263798475265503
Validation loss: 2.2111040353775024

Epoch: 6| Step: 3
Training loss: 1.6926943063735962
Validation loss: 2.2012813289960227

Epoch: 6| Step: 4
Training loss: 1.149426817893982
Validation loss: 2.195485254128774

Epoch: 6| Step: 5
Training loss: 2.08992075920105
Validation loss: 2.197206497192383

Epoch: 6| Step: 6
Training loss: 1.5833014249801636
Validation loss: 2.2118971149126687

Epoch: 6| Step: 7
Training loss: 1.9246443510055542
Validation loss: 2.2085662285486856

Epoch: 6| Step: 8
Training loss: 1.8934853076934814
Validation loss: 2.222966512044271

Epoch: 6| Step: 9
Training loss: 1.7271831035614014
Validation loss: 2.2230794032414756

Epoch: 6| Step: 10
Training loss: 2.1927804946899414
Validation loss: 2.2258686820665994

Epoch: 6| Step: 11
Training loss: 1.509913682937622
Validation loss: 2.2289907137552896

Epoch: 6| Step: 12
Training loss: 1.9808218479156494
Validation loss: 2.228904922803243

Epoch: 6| Step: 13
Training loss: 1.7728393077850342
Validation loss: 2.2484692136446633

Epoch: 219| Step: 0
Training loss: 1.5429476499557495
Validation loss: 2.2387459675470986

Epoch: 6| Step: 1
Training loss: 1.910328984260559
Validation loss: 2.2502617835998535

Epoch: 6| Step: 2
Training loss: 1.6453373432159424
Validation loss: 2.232200860977173

Epoch: 6| Step: 3
Training loss: 1.5841647386550903
Validation loss: 2.236202677090963

Epoch: 6| Step: 4
Training loss: 1.5795209407806396
Validation loss: 2.2174834609031677

Epoch: 6| Step: 5
Training loss: 1.556066632270813
Validation loss: 2.203263799349467

Epoch: 6| Step: 6
Training loss: 1.370626449584961
Validation loss: 2.207391103108724

Epoch: 6| Step: 7
Training loss: 1.9068617820739746
Validation loss: 2.201447824637095

Epoch: 6| Step: 8
Training loss: 2.4757399559020996
Validation loss: 2.206661661465963

Epoch: 6| Step: 9
Training loss: 2.8649885654449463
Validation loss: 2.1975360115369162

Epoch: 6| Step: 10
Training loss: 1.3107199668884277
Validation loss: 2.1827667355537415

Epoch: 6| Step: 11
Training loss: 2.1089394092559814
Validation loss: 2.195726990699768

Epoch: 6| Step: 12
Training loss: 1.426938772201538
Validation loss: 2.2090730468432107

Epoch: 6| Step: 13
Training loss: 2.297696828842163
Validation loss: 2.209219435850779

Epoch: 220| Step: 0
Training loss: 1.4901334047317505
Validation loss: 2.209696412086487

Epoch: 6| Step: 1
Training loss: 1.7250103950500488
Validation loss: 2.1970719496409097

Epoch: 6| Step: 2
Training loss: 1.870774507522583
Validation loss: 2.224342624346415

Epoch: 6| Step: 3
Training loss: 2.028785228729248
Validation loss: 2.2114680409431458

Epoch: 6| Step: 4
Training loss: 1.7899940013885498
Validation loss: 2.212436079978943

Epoch: 6| Step: 5
Training loss: 1.516605257987976
Validation loss: 2.216685394446055

Epoch: 6| Step: 6
Training loss: 1.4488065242767334
Validation loss: 2.2118592460950217

Epoch: 6| Step: 7
Training loss: 2.286858081817627
Validation loss: 2.209181269009908

Epoch: 6| Step: 8
Training loss: 1.744494915008545
Validation loss: 2.2099138498306274

Epoch: 6| Step: 9
Training loss: 2.5922977924346924
Validation loss: 2.2181263367335

Epoch: 6| Step: 10
Training loss: 1.8074414730072021
Validation loss: 2.2058098117510476

Epoch: 6| Step: 11
Training loss: 1.8315229415893555
Validation loss: 2.2103912830352783

Epoch: 6| Step: 12
Training loss: 1.704441785812378
Validation loss: 2.1965980927149453

Epoch: 6| Step: 13
Training loss: 1.1451332569122314
Validation loss: 2.2030547062555947

Epoch: 221| Step: 0
Training loss: 1.3604698181152344
Validation loss: 2.2180267175038657

Epoch: 6| Step: 1
Training loss: 1.7392767667770386
Validation loss: 2.206323285897573

Epoch: 6| Step: 2
Training loss: 1.8862438201904297
Validation loss: 2.21735010544459

Epoch: 6| Step: 3
Training loss: 2.1466331481933594
Validation loss: 2.2137874364852905

Epoch: 6| Step: 4
Training loss: 0.9695035815238953
Validation loss: 2.2213155031204224

Epoch: 6| Step: 5
Training loss: 1.8380401134490967
Validation loss: 2.2366849978764853

Epoch: 6| Step: 6
Training loss: 1.9766321182250977
Validation loss: 2.218514641125997

Epoch: 6| Step: 7
Training loss: 2.0448598861694336
Validation loss: 2.2186917463938394

Epoch: 6| Step: 8
Training loss: 1.8022063970565796
Validation loss: 2.2072344024976096

Epoch: 6| Step: 9
Training loss: 1.6912893056869507
Validation loss: 2.2321815689404807

Epoch: 6| Step: 10
Training loss: 2.951526403427124
Validation loss: 2.2196994026501975

Epoch: 6| Step: 11
Training loss: 1.7842411994934082
Validation loss: 2.2239163517951965

Epoch: 6| Step: 12
Training loss: 1.447332501411438
Validation loss: 2.217069983482361

Epoch: 6| Step: 13
Training loss: 1.5856149196624756
Validation loss: 2.2223239143689475

Epoch: 222| Step: 0
Training loss: 1.2497403621673584
Validation loss: 2.206867814064026

Epoch: 6| Step: 1
Training loss: 1.7775633335113525
Validation loss: 2.2354294657707214

Epoch: 6| Step: 2
Training loss: 2.484867572784424
Validation loss: 2.2065009276072183

Epoch: 6| Step: 3
Training loss: 1.658632516860962
Validation loss: 2.223232388496399

Epoch: 6| Step: 4
Training loss: 1.9953289031982422
Validation loss: 2.223214586575826

Epoch: 6| Step: 5
Training loss: 1.8043601512908936
Validation loss: 2.222938815752665

Epoch: 6| Step: 6
Training loss: 1.8394479751586914
Validation loss: 2.2264289458592734

Epoch: 6| Step: 7
Training loss: 2.2403039932250977
Validation loss: 2.2417587439219155

Epoch: 6| Step: 8
Training loss: 1.754323124885559
Validation loss: 2.255185047785441

Epoch: 6| Step: 9
Training loss: 2.0155458450317383
Validation loss: 2.2212204734484353

Epoch: 6| Step: 10
Training loss: 1.4858250617980957
Validation loss: 2.2216432293256125

Epoch: 6| Step: 11
Training loss: 1.5805641412734985
Validation loss: 2.2123709321022034

Epoch: 6| Step: 12
Training loss: 1.1885621547698975
Validation loss: 2.2160820166269937

Epoch: 6| Step: 13
Training loss: 2.219367504119873
Validation loss: 2.2291860580444336

Epoch: 223| Step: 0
Training loss: 1.6283849477767944
Validation loss: 2.1903953750928244

Epoch: 6| Step: 1
Training loss: 2.719266414642334
Validation loss: 2.1958807905515036

Epoch: 6| Step: 2
Training loss: 1.688761591911316
Validation loss: 2.1873680551846824

Epoch: 6| Step: 3
Training loss: 2.13739013671875
Validation loss: 2.186563034852346

Epoch: 6| Step: 4
Training loss: 1.7093302011489868
Validation loss: 2.1927207112312317

Epoch: 6| Step: 5
Training loss: 2.048956871032715
Validation loss: 2.2123926679293313

Epoch: 6| Step: 6
Training loss: 1.723315954208374
Validation loss: 2.1914512117703757

Epoch: 6| Step: 7
Training loss: 1.3963650465011597
Validation loss: 2.212709665298462

Epoch: 6| Step: 8
Training loss: 1.6742432117462158
Validation loss: 2.224209785461426

Epoch: 6| Step: 9
Training loss: 1.2959184646606445
Validation loss: 2.206548055013021

Epoch: 6| Step: 10
Training loss: 2.0730528831481934
Validation loss: 2.2128942608833313

Epoch: 6| Step: 11
Training loss: 1.6032843589782715
Validation loss: 2.22440238793691

Epoch: 6| Step: 12
Training loss: 1.8963755369186401
Validation loss: 2.2089277307192483

Epoch: 6| Step: 13
Training loss: 1.473069429397583
Validation loss: 2.2102420131365457

Epoch: 224| Step: 0
Training loss: 2.0577378273010254
Validation loss: 2.2068663438161216

Epoch: 6| Step: 1
Training loss: 1.8580749034881592
Validation loss: 2.2115816672643027

Epoch: 6| Step: 2
Training loss: 1.2014774084091187
Validation loss: 2.212966501712799

Epoch: 6| Step: 3
Training loss: 2.1154747009277344
Validation loss: 2.2045405308405557

Epoch: 6| Step: 4
Training loss: 1.6555885076522827
Validation loss: 2.202005763848623

Epoch: 6| Step: 5
Training loss: 2.060098648071289
Validation loss: 2.2035382191340127

Epoch: 6| Step: 6
Training loss: 1.5222394466400146
Validation loss: 2.217616160710653

Epoch: 6| Step: 7
Training loss: 1.154222011566162
Validation loss: 2.1893138686815896

Epoch: 6| Step: 8
Training loss: 2.054697036743164
Validation loss: 2.2091802755991616

Epoch: 6| Step: 9
Training loss: 1.1742457151412964
Validation loss: 2.2246281703313193

Epoch: 6| Step: 10
Training loss: 2.6435537338256836
Validation loss: 2.228646000226339

Epoch: 6| Step: 11
Training loss: 1.6891801357269287
Validation loss: 2.230954388777415

Epoch: 6| Step: 12
Training loss: 1.8948317766189575
Validation loss: 2.217604478200277

Epoch: 6| Step: 13
Training loss: 1.831454873085022
Validation loss: 2.2405922611554465

Epoch: 225| Step: 0
Training loss: 1.5376079082489014
Validation loss: 2.232395907243093

Epoch: 6| Step: 1
Training loss: 2.2176918983459473
Validation loss: 2.220296859741211

Epoch: 6| Step: 2
Training loss: 1.75203275680542
Validation loss: 2.2259095708529153

Epoch: 6| Step: 3
Training loss: 1.0973153114318848
Validation loss: 2.2151878674825034

Epoch: 6| Step: 4
Training loss: 1.7483770847320557
Validation loss: 2.2191577355066934

Epoch: 6| Step: 5
Training loss: 2.1052017211914062
Validation loss: 2.2032949129740396

Epoch: 6| Step: 6
Training loss: 1.5420472621917725
Validation loss: 2.2086989680926004

Epoch: 6| Step: 7
Training loss: 1.8026623725891113
Validation loss: 2.21617325146993

Epoch: 6| Step: 8
Training loss: 1.8715131282806396
Validation loss: 2.1998524268468223

Epoch: 6| Step: 9
Training loss: 2.094261646270752
Validation loss: 2.203715980052948

Epoch: 6| Step: 10
Training loss: 1.4549353122711182
Validation loss: 2.2087300618489585

Epoch: 6| Step: 11
Training loss: 1.4909878969192505
Validation loss: 2.2043453256289163

Epoch: 6| Step: 12
Training loss: 2.121983528137207
Validation loss: 2.2336778243382773

Epoch: 6| Step: 13
Training loss: 1.7906289100646973
Validation loss: 2.218648354212443

Epoch: 226| Step: 0
Training loss: 1.964056134223938
Validation loss: 2.2153450647989907

Epoch: 6| Step: 1
Training loss: 1.29643714427948
Validation loss: 2.2345710396766663

Epoch: 6| Step: 2
Training loss: 1.4365684986114502
Validation loss: 2.2121234138806662

Epoch: 6| Step: 3
Training loss: 1.503164529800415
Validation loss: 2.2084455688794455

Epoch: 6| Step: 4
Training loss: 1.42954683303833
Validation loss: 2.200368603070577

Epoch: 6| Step: 5
Training loss: 2.227612257003784
Validation loss: 2.2026619911193848

Epoch: 6| Step: 6
Training loss: 1.7382450103759766
Validation loss: 2.1643501122792563

Epoch: 6| Step: 7
Training loss: 1.5788037776947021
Validation loss: 2.1858168244361877

Epoch: 6| Step: 8
Training loss: 2.1497151851654053
Validation loss: 2.190942923227946

Epoch: 6| Step: 9
Training loss: 2.0238916873931885
Validation loss: 2.188957850138346

Epoch: 6| Step: 10
Training loss: 2.256294012069702
Validation loss: 2.1728859345118203

Epoch: 6| Step: 11
Training loss: 1.8861520290374756
Validation loss: 2.191476821899414

Epoch: 6| Step: 12
Training loss: 1.9372637271881104
Validation loss: 2.1849891543388367

Epoch: 6| Step: 13
Training loss: 1.6529864072799683
Validation loss: 2.1960306763648987

Epoch: 227| Step: 0
Training loss: 2.073472738265991
Validation loss: 2.198159078756968

Epoch: 6| Step: 1
Training loss: 1.3830559253692627
Validation loss: 2.2125624815622964

Epoch: 6| Step: 2
Training loss: 1.5817633867263794
Validation loss: 2.1915295720100403

Epoch: 6| Step: 3
Training loss: 1.697823405265808
Validation loss: 2.221179167429606

Epoch: 6| Step: 4
Training loss: 2.0380282402038574
Validation loss: 2.186870257059733

Epoch: 6| Step: 5
Training loss: 1.5498987436294556
Validation loss: 2.1907608111699424

Epoch: 6| Step: 6
Training loss: 1.2366738319396973
Validation loss: 2.19256599744161

Epoch: 6| Step: 7
Training loss: 1.4498260021209717
Validation loss: 2.203717589378357

Epoch: 6| Step: 8
Training loss: 1.2986302375793457
Validation loss: 2.2077168623606362

Epoch: 6| Step: 9
Training loss: 2.27858304977417
Validation loss: 2.214424212773641

Epoch: 6| Step: 10
Training loss: 3.2567317485809326
Validation loss: 2.204400340716044

Epoch: 6| Step: 11
Training loss: 1.372873067855835
Validation loss: 2.207178850968679

Epoch: 6| Step: 12
Training loss: 2.174936294555664
Validation loss: 2.22616316874822

Epoch: 6| Step: 13
Training loss: 1.519858479499817
Validation loss: 2.2237448692321777

Epoch: 228| Step: 0
Training loss: 1.2882449626922607
Validation loss: 2.2250465949376426

Epoch: 6| Step: 1
Training loss: 1.8949601650238037
Validation loss: 2.216018279393514

Epoch: 6| Step: 2
Training loss: 1.9430501461029053
Validation loss: 2.2265395124753318

Epoch: 6| Step: 3
Training loss: 2.000988483428955
Validation loss: 2.22724848985672

Epoch: 6| Step: 4
Training loss: 1.3707642555236816
Validation loss: 2.2248862981796265

Epoch: 6| Step: 5
Training loss: 1.691927433013916
Validation loss: 2.214770754178365

Epoch: 6| Step: 6
Training loss: 1.5243802070617676
Validation loss: 2.2126875718434653

Epoch: 6| Step: 7
Training loss: 2.06105899810791
Validation loss: 2.237048844496409

Epoch: 6| Step: 8
Training loss: 2.526689052581787
Validation loss: 2.2400139768918357

Epoch: 6| Step: 9
Training loss: 1.4880167245864868
Validation loss: 2.227085987726847

Epoch: 6| Step: 10
Training loss: 1.663928747177124
Validation loss: 2.2240401109059653

Epoch: 6| Step: 11
Training loss: 1.7320059537887573
Validation loss: 2.21597691377004

Epoch: 6| Step: 12
Training loss: 1.7879889011383057
Validation loss: 2.2047305703163147

Epoch: 6| Step: 13
Training loss: 1.7882297039031982
Validation loss: 2.203023672103882

Epoch: 229| Step: 0
Training loss: 1.4854776859283447
Validation loss: 2.208917558193207

Epoch: 6| Step: 1
Training loss: 1.830645203590393
Validation loss: 2.2310423453648887

Epoch: 6| Step: 2
Training loss: 1.870086908340454
Validation loss: 2.2362148761749268

Epoch: 6| Step: 3
Training loss: 1.9067403078079224
Validation loss: 2.20520281791687

Epoch: 6| Step: 4
Training loss: 1.8501110076904297
Validation loss: 2.2043261925379434

Epoch: 6| Step: 5
Training loss: 1.664064884185791
Validation loss: 2.2464696367581687

Epoch: 6| Step: 6
Training loss: 1.7208828926086426
Validation loss: 2.2104347546895347

Epoch: 6| Step: 7
Training loss: 1.078944444656372
Validation loss: 2.2374839782714844

Epoch: 6| Step: 8
Training loss: 2.0624303817749023
Validation loss: 2.2264839013417563

Epoch: 6| Step: 9
Training loss: 2.0031635761260986
Validation loss: 2.222983241081238

Epoch: 6| Step: 10
Training loss: 1.895038366317749
Validation loss: 2.2365599075953164

Epoch: 6| Step: 11
Training loss: 1.8805928230285645
Validation loss: 2.2112735907236734

Epoch: 6| Step: 12
Training loss: 1.716799020767212
Validation loss: 2.2253923416137695

Epoch: 6| Step: 13
Training loss: 1.3567794561386108
Validation loss: 2.2274992863337197

Epoch: 230| Step: 0
Training loss: 2.0201516151428223
Validation loss: 2.2355040510495505

Epoch: 6| Step: 1
Training loss: 1.4842005968093872
Validation loss: 2.246360937754313

Epoch: 6| Step: 2
Training loss: 1.8929240703582764
Validation loss: 2.231068730354309

Epoch: 6| Step: 3
Training loss: 1.6189603805541992
Validation loss: 2.2240135073661804

Epoch: 6| Step: 4
Training loss: 2.2146012783050537
Validation loss: 2.2125209967295327

Epoch: 6| Step: 5
Training loss: 1.5855507850646973
Validation loss: 2.2201686104138694

Epoch: 6| Step: 6
Training loss: 1.3688633441925049
Validation loss: 2.2106242179870605

Epoch: 6| Step: 7
Training loss: 1.4972903728485107
Validation loss: 2.2372093200683594

Epoch: 6| Step: 8
Training loss: 1.5797004699707031
Validation loss: 2.229516863822937

Epoch: 6| Step: 9
Training loss: 2.0291810035705566
Validation loss: 2.2406089703241983

Epoch: 6| Step: 10
Training loss: 2.2770462036132812
Validation loss: 2.2428613106409707

Epoch: 6| Step: 11
Training loss: 1.6773903369903564
Validation loss: 2.229967395464579

Epoch: 6| Step: 12
Training loss: 2.034186840057373
Validation loss: 2.2339603900909424

Epoch: 6| Step: 13
Training loss: 1.7783095836639404
Validation loss: 2.2477368315060935

Epoch: 231| Step: 0
Training loss: 1.8604682683944702
Validation loss: 2.2105786204338074

Epoch: 6| Step: 1
Training loss: 1.4909405708312988
Validation loss: 2.2256005803743997

Epoch: 6| Step: 2
Training loss: 1.772052526473999
Validation loss: 2.2274649143218994

Epoch: 6| Step: 3
Training loss: 1.955081820487976
Validation loss: 2.2364829182624817

Epoch: 6| Step: 4
Training loss: 1.7135231494903564
Validation loss: 2.221686085065206

Epoch: 6| Step: 5
Training loss: 2.1787109375
Validation loss: 2.2407628297805786

Epoch: 6| Step: 6
Training loss: 1.2470760345458984
Validation loss: 2.218927025794983

Epoch: 6| Step: 7
Training loss: 1.8237850666046143
Validation loss: 2.208326538403829

Epoch: 6| Step: 8
Training loss: 2.174590587615967
Validation loss: 2.2005353371302285

Epoch: 6| Step: 9
Training loss: 1.5503031015396118
Validation loss: 2.188608090082804

Epoch: 6| Step: 10
Training loss: 1.7929941415786743
Validation loss: 2.200301766395569

Epoch: 6| Step: 11
Training loss: 2.248450994491577
Validation loss: 2.2051901618639627

Epoch: 6| Step: 12
Training loss: 1.2724711894989014
Validation loss: 2.2001824378967285

Epoch: 6| Step: 13
Training loss: 1.4042636156082153
Validation loss: 2.222961107889811

Epoch: 232| Step: 0
Training loss: 2.267329216003418
Validation loss: 2.2169514497121177

Epoch: 6| Step: 1
Training loss: 1.970984935760498
Validation loss: 2.216472307840983

Epoch: 6| Step: 2
Training loss: 1.504311203956604
Validation loss: 2.207366128762563

Epoch: 6| Step: 3
Training loss: 2.0618577003479004
Validation loss: 2.2267689307530723

Epoch: 6| Step: 4
Training loss: 2.1223697662353516
Validation loss: 2.2300004363059998

Epoch: 6| Step: 5
Training loss: 1.5973786115646362
Validation loss: 2.2430732250213623

Epoch: 6| Step: 6
Training loss: 1.9345650672912598
Validation loss: 2.2354741295178733

Epoch: 6| Step: 7
Training loss: 1.4639368057250977
Validation loss: 2.2341485818227134

Epoch: 6| Step: 8
Training loss: 1.5864465236663818
Validation loss: 2.241714040438334

Epoch: 6| Step: 9
Training loss: 1.4307605028152466
Validation loss: 2.2050688664118447

Epoch: 6| Step: 10
Training loss: 1.6985772848129272
Validation loss: 2.218347946802775

Epoch: 6| Step: 11
Training loss: 2.042337656021118
Validation loss: 2.2121930519739785

Epoch: 6| Step: 12
Training loss: 1.4249138832092285
Validation loss: 2.205024858315786

Epoch: 6| Step: 13
Training loss: 1.5021857023239136
Validation loss: 2.187486469745636

Epoch: 233| Step: 0
Training loss: 1.6305391788482666
Validation loss: 2.204657872517904

Epoch: 6| Step: 1
Training loss: 2.16292667388916
Validation loss: 2.209385931491852

Epoch: 6| Step: 2
Training loss: 1.8194109201431274
Validation loss: 2.2014767130215964

Epoch: 6| Step: 3
Training loss: 1.6840167045593262
Validation loss: 2.218551596005758

Epoch: 6| Step: 4
Training loss: 1.4259405136108398
Validation loss: 2.2240082025527954

Epoch: 6| Step: 5
Training loss: 1.8147974014282227
Validation loss: 2.2056013345718384

Epoch: 6| Step: 6
Training loss: 1.3580741882324219
Validation loss: 2.191881994406382

Epoch: 6| Step: 7
Training loss: 1.9403655529022217
Validation loss: 2.206506907939911

Epoch: 6| Step: 8
Training loss: 1.380487322807312
Validation loss: 2.191537936528524

Epoch: 6| Step: 9
Training loss: 1.64947509765625
Validation loss: 2.188961982727051

Epoch: 6| Step: 10
Training loss: 1.6719917058944702
Validation loss: 2.2157749931017556

Epoch: 6| Step: 11
Training loss: 1.9147164821624756
Validation loss: 2.221526583035787

Epoch: 6| Step: 12
Training loss: 2.2677817344665527
Validation loss: 2.217672606309255

Epoch: 6| Step: 13
Training loss: 1.8600502014160156
Validation loss: 2.2223711212476096

Epoch: 234| Step: 0
Training loss: 1.4474406242370605
Validation loss: 2.2209675113360086

Epoch: 6| Step: 1
Training loss: 1.7125529050827026
Validation loss: 2.206713378429413

Epoch: 6| Step: 2
Training loss: 1.5758309364318848
Validation loss: 2.2136961817741394

Epoch: 6| Step: 3
Training loss: 1.7931246757507324
Validation loss: 2.208435813585917

Epoch: 6| Step: 4
Training loss: 1.699949860572815
Validation loss: 2.195317010084788

Epoch: 6| Step: 5
Training loss: 1.6170339584350586
Validation loss: 2.2002970774968467

Epoch: 6| Step: 6
Training loss: 1.8381884098052979
Validation loss: 2.193954646587372

Epoch: 6| Step: 7
Training loss: 1.6611815690994263
Validation loss: 2.1899532874425254

Epoch: 6| Step: 8
Training loss: 2.3167381286621094
Validation loss: 2.2147842049598694

Epoch: 6| Step: 9
Training loss: 1.4038327932357788
Validation loss: 2.2023813327153525

Epoch: 6| Step: 10
Training loss: 2.606877565383911
Validation loss: 2.2018895745277405

Epoch: 6| Step: 11
Training loss: 1.492466926574707
Validation loss: 2.227668742338816

Epoch: 6| Step: 12
Training loss: 1.4118623733520508
Validation loss: 2.194914003213247

Epoch: 6| Step: 13
Training loss: 1.8125016689300537
Validation loss: 2.220228592554728

Epoch: 235| Step: 0
Training loss: 1.3607146739959717
Validation loss: 2.2072336673736572

Epoch: 6| Step: 1
Training loss: 1.0084532499313354
Validation loss: 2.21738471587499

Epoch: 6| Step: 2
Training loss: 2.288729190826416
Validation loss: 2.2309298117955527

Epoch: 6| Step: 3
Training loss: 1.6058480739593506
Validation loss: 2.2239680091540017

Epoch: 6| Step: 4
Training loss: 1.3558987379074097
Validation loss: 2.219367563724518

Epoch: 6| Step: 5
Training loss: 1.6671617031097412
Validation loss: 2.2203776836395264

Epoch: 6| Step: 6
Training loss: 2.68404483795166
Validation loss: 2.226717452208201

Epoch: 6| Step: 7
Training loss: 1.5409634113311768
Validation loss: 2.2472782333691916

Epoch: 6| Step: 8
Training loss: 1.5815613269805908
Validation loss: 2.250487486521403

Epoch: 6| Step: 9
Training loss: 2.1347484588623047
Validation loss: 2.2359269062678018

Epoch: 6| Step: 10
Training loss: 1.7835267782211304
Validation loss: 2.233359932899475

Epoch: 6| Step: 11
Training loss: 1.3756437301635742
Validation loss: 2.242492198944092

Epoch: 6| Step: 12
Training loss: 2.625326633453369
Validation loss: 2.208009739716848

Epoch: 6| Step: 13
Training loss: 1.4137458801269531
Validation loss: 2.219819267590841

Epoch: 236| Step: 0
Training loss: 0.9552929401397705
Validation loss: 2.2221004565556846

Epoch: 6| Step: 1
Training loss: 1.7041616439819336
Validation loss: 2.2262353698412576

Epoch: 6| Step: 2
Training loss: 2.047414779663086
Validation loss: 2.2227187554041543

Epoch: 6| Step: 3
Training loss: 2.0486648082733154
Validation loss: 2.208418329556783

Epoch: 6| Step: 4
Training loss: 1.8610777854919434
Validation loss: 2.207935015360514

Epoch: 6| Step: 5
Training loss: 1.2894030809402466
Validation loss: 2.2272819876670837

Epoch: 6| Step: 6
Training loss: 1.7866473197937012
Validation loss: 2.2118510007858276

Epoch: 6| Step: 7
Training loss: 1.8304120302200317
Validation loss: 2.2310430804888406

Epoch: 6| Step: 8
Training loss: 2.2947702407836914
Validation loss: 2.217025319735209

Epoch: 6| Step: 9
Training loss: 2.294802188873291
Validation loss: 2.2278188467025757

Epoch: 6| Step: 10
Training loss: 1.7606046199798584
Validation loss: 2.2250088453292847

Epoch: 6| Step: 11
Training loss: 1.7488011121749878
Validation loss: 2.2425169150034585

Epoch: 6| Step: 12
Training loss: 1.4659029245376587
Validation loss: 2.2570467591285706

Epoch: 6| Step: 13
Training loss: 1.520235538482666
Validation loss: 2.2571088671684265

Epoch: 237| Step: 0
Training loss: 1.6396245956420898
Validation loss: 2.238927483558655

Epoch: 6| Step: 1
Training loss: 1.9391932487487793
Validation loss: 2.2079967657725015

Epoch: 6| Step: 2
Training loss: 1.660147786140442
Validation loss: 2.236830254395803

Epoch: 6| Step: 3
Training loss: 2.28003191947937
Validation loss: 2.2138105034828186

Epoch: 6| Step: 4
Training loss: 2.001132011413574
Validation loss: 2.23072882493337

Epoch: 6| Step: 5
Training loss: 1.0055862665176392
Validation loss: 2.2146471738815308

Epoch: 6| Step: 6
Training loss: 1.6776785850524902
Validation loss: 2.2265210350354514

Epoch: 6| Step: 7
Training loss: 1.582491397857666
Validation loss: 2.1985432704289756

Epoch: 6| Step: 8
Training loss: 1.7883762121200562
Validation loss: 2.2361061771710715

Epoch: 6| Step: 9
Training loss: 1.1189260482788086
Validation loss: 2.236454129219055

Epoch: 6| Step: 10
Training loss: 2.4905893802642822
Validation loss: 2.2647352615992227

Epoch: 6| Step: 11
Training loss: 1.4736710786819458
Validation loss: 2.2447142799695334

Epoch: 6| Step: 12
Training loss: 1.6877917051315308
Validation loss: 2.2482745250066123

Epoch: 6| Step: 13
Training loss: 1.821094274520874
Validation loss: 2.252519428730011

Epoch: 238| Step: 0
Training loss: 1.4042317867279053
Validation loss: 2.2620933651924133

Epoch: 6| Step: 1
Training loss: 1.7658252716064453
Validation loss: 2.252569874127706

Epoch: 6| Step: 2
Training loss: 2.0892374515533447
Validation loss: 2.2502832611401877

Epoch: 6| Step: 3
Training loss: 1.9802305698394775
Validation loss: 2.246597389380137

Epoch: 6| Step: 4
Training loss: 1.4149463176727295
Validation loss: 2.246216336886088

Epoch: 6| Step: 5
Training loss: 1.7911441326141357
Validation loss: 2.241132656733195

Epoch: 6| Step: 6
Training loss: 1.2781803607940674
Validation loss: 2.2510011394818625

Epoch: 6| Step: 7
Training loss: 1.8279281854629517
Validation loss: 2.2324246168136597

Epoch: 6| Step: 8
Training loss: 1.377855658531189
Validation loss: 2.2221633195877075

Epoch: 6| Step: 9
Training loss: 2.0024266242980957
Validation loss: 2.2369711995124817

Epoch: 6| Step: 10
Training loss: 1.7860667705535889
Validation loss: 2.2340537707010903

Epoch: 6| Step: 11
Training loss: 1.6276992559432983
Validation loss: 2.2393851280212402

Epoch: 6| Step: 12
Training loss: 1.8065481185913086
Validation loss: 2.2469208041826882

Epoch: 6| Step: 13
Training loss: 2.0229663848876953
Validation loss: 2.243024210135142

Epoch: 239| Step: 0
Training loss: 1.237273931503296
Validation loss: 2.2345308860143027

Epoch: 6| Step: 1
Training loss: 1.4940913915634155
Validation loss: 2.242710550626119

Epoch: 6| Step: 2
Training loss: 1.803349256515503
Validation loss: 2.233925938606262

Epoch: 6| Step: 3
Training loss: 1.63883638381958
Validation loss: 2.2275002797444663

Epoch: 6| Step: 4
Training loss: 2.349555492401123
Validation loss: 2.2203508218129477

Epoch: 6| Step: 5
Training loss: 1.8609108924865723
Validation loss: 2.2192057172457376

Epoch: 6| Step: 6
Training loss: 2.394470691680908
Validation loss: 2.2265710632006326

Epoch: 6| Step: 7
Training loss: 2.017620801925659
Validation loss: 2.239291548728943

Epoch: 6| Step: 8
Training loss: 1.7912324666976929
Validation loss: 2.246025562286377

Epoch: 6| Step: 9
Training loss: 1.8041118383407593
Validation loss: 2.2502274910608926

Epoch: 6| Step: 10
Training loss: 1.0249587297439575
Validation loss: 2.232399900754293

Epoch: 6| Step: 11
Training loss: 2.077676296234131
Validation loss: 2.2353883584340415

Epoch: 6| Step: 12
Training loss: 1.2040317058563232
Validation loss: 2.2515347798665366

Epoch: 6| Step: 13
Training loss: 1.9228453636169434
Validation loss: 2.23881725470225

Epoch: 240| Step: 0
Training loss: 1.8440489768981934
Validation loss: 2.2167066733042398

Epoch: 6| Step: 1
Training loss: 1.4718515872955322
Validation loss: 2.220318774382273

Epoch: 6| Step: 2
Training loss: 1.519164800643921
Validation loss: 2.2109064857165017

Epoch: 6| Step: 3
Training loss: 1.5423688888549805
Validation loss: 2.2197104493776956

Epoch: 6| Step: 4
Training loss: 2.06787371635437
Validation loss: 2.2134474515914917

Epoch: 6| Step: 5
Training loss: 1.7473564147949219
Validation loss: 2.2141236464182534

Epoch: 6| Step: 6
Training loss: 1.695970058441162
Validation loss: 2.236247499783834

Epoch: 6| Step: 7
Training loss: 2.083503484725952
Validation loss: 2.215816020965576

Epoch: 6| Step: 8
Training loss: 1.3802624940872192
Validation loss: 2.222635189692179

Epoch: 6| Step: 9
Training loss: 1.458809733390808
Validation loss: 2.253358542919159

Epoch: 6| Step: 10
Training loss: 2.0072717666625977
Validation loss: 2.236672858397166

Epoch: 6| Step: 11
Training loss: 2.302488327026367
Validation loss: 2.243784705797831

Epoch: 6| Step: 12
Training loss: 1.9578204154968262
Validation loss: 2.2526591221491494

Epoch: 6| Step: 13
Training loss: 1.5736026763916016
Validation loss: 2.2409943342208862

Epoch: 241| Step: 0
Training loss: 1.9896419048309326
Validation loss: 2.222811222076416

Epoch: 6| Step: 1
Training loss: 2.3909339904785156
Validation loss: 2.2229347030321756

Epoch: 6| Step: 2
Training loss: 2.0574750900268555
Validation loss: 2.225655118624369

Epoch: 6| Step: 3
Training loss: 2.051440715789795
Validation loss: 2.2239925463994346

Epoch: 6| Step: 4
Training loss: 1.1122627258300781
Validation loss: 2.2411675453186035

Epoch: 6| Step: 5
Training loss: 1.770340085029602
Validation loss: 2.235426127910614

Epoch: 6| Step: 6
Training loss: 1.5991551876068115
Validation loss: 2.2375519275665283

Epoch: 6| Step: 7
Training loss: 2.1592164039611816
Validation loss: 2.223476986090342

Epoch: 6| Step: 8
Training loss: 1.5432710647583008
Validation loss: 2.244275470574697

Epoch: 6| Step: 9
Training loss: 2.0380890369415283
Validation loss: 2.24286417166392

Epoch: 6| Step: 10
Training loss: 1.2098727226257324
Validation loss: 2.2528651555379233

Epoch: 6| Step: 11
Training loss: 1.3908573389053345
Validation loss: 2.2430514097213745

Epoch: 6| Step: 12
Training loss: 1.6354362964630127
Validation loss: 2.236062467098236

Epoch: 6| Step: 13
Training loss: 1.4738483428955078
Validation loss: 2.2348310947418213

Epoch: 242| Step: 0
Training loss: 2.2983736991882324
Validation loss: 2.2496188084284463

Epoch: 6| Step: 1
Training loss: 1.5400786399841309
Validation loss: 2.245066742102305

Epoch: 6| Step: 2
Training loss: 2.002227306365967
Validation loss: 2.248879154523214

Epoch: 6| Step: 3
Training loss: 2.126016616821289
Validation loss: 2.236183206240336

Epoch: 6| Step: 4
Training loss: 1.335248351097107
Validation loss: 2.2425459027290344

Epoch: 6| Step: 5
Training loss: 1.8351233005523682
Validation loss: 2.2013538479804993

Epoch: 6| Step: 6
Training loss: 1.5466580390930176
Validation loss: 2.224802831808726

Epoch: 6| Step: 7
Training loss: 1.3793230056762695
Validation loss: 2.2249402006467185

Epoch: 6| Step: 8
Training loss: 1.6416993141174316
Validation loss: 2.201523164908091

Epoch: 6| Step: 9
Training loss: 2.5558505058288574
Validation loss: 2.206783572832743

Epoch: 6| Step: 10
Training loss: 1.802803635597229
Validation loss: 2.190658926963806

Epoch: 6| Step: 11
Training loss: 1.6129679679870605
Validation loss: 2.2059357364972434

Epoch: 6| Step: 12
Training loss: 1.4125969409942627
Validation loss: 2.207826395829519

Epoch: 6| Step: 13
Training loss: 2.1329166889190674
Validation loss: 2.217154781023661

Epoch: 243| Step: 0
Training loss: 1.3566327095031738
Validation loss: 2.235885977745056

Epoch: 6| Step: 1
Training loss: 1.4468022584915161
Validation loss: 2.2161293029785156

Epoch: 6| Step: 2
Training loss: 2.395789384841919
Validation loss: 2.2176619370778403

Epoch: 6| Step: 3
Training loss: 1.4633681774139404
Validation loss: 2.2177528142929077

Epoch: 6| Step: 4
Training loss: 2.1513547897338867
Validation loss: 2.2376473546028137

Epoch: 6| Step: 5
Training loss: 1.1294903755187988
Validation loss: 2.267559905846914

Epoch: 6| Step: 6
Training loss: 1.792202115058899
Validation loss: 2.2414089242617288

Epoch: 6| Step: 7
Training loss: 1.2192327976226807
Validation loss: 2.250000834465027

Epoch: 6| Step: 8
Training loss: 1.83317232131958
Validation loss: 2.2390694618225098

Epoch: 6| Step: 9
Training loss: 1.5643832683563232
Validation loss: 2.2529008388519287

Epoch: 6| Step: 10
Training loss: 1.5000922679901123
Validation loss: 2.2466625372568765

Epoch: 6| Step: 11
Training loss: 2.030116558074951
Validation loss: 2.272116204102834

Epoch: 6| Step: 12
Training loss: 2.849386692047119
Validation loss: 2.2689828276634216

Epoch: 6| Step: 13
Training loss: 1.3730340003967285
Validation loss: 2.2500019470850625

Epoch: 244| Step: 0
Training loss: 2.1515073776245117
Validation loss: 2.2529929478963218

Epoch: 6| Step: 1
Training loss: 1.172438383102417
Validation loss: 2.2569343646367392

Epoch: 6| Step: 2
Training loss: 1.4353504180908203
Validation loss: 2.2576332688331604

Epoch: 6| Step: 3
Training loss: 1.5342620611190796
Validation loss: 2.2543532450993857

Epoch: 6| Step: 4
Training loss: 2.2943949699401855
Validation loss: 2.2260893185933432

Epoch: 6| Step: 5
Training loss: 1.5997389554977417
Validation loss: 2.2589391668637595

Epoch: 6| Step: 6
Training loss: 1.2231398820877075
Validation loss: 2.2419076760609946

Epoch: 6| Step: 7
Training loss: 2.723583698272705
Validation loss: 2.2261772950490317

Epoch: 6| Step: 8
Training loss: 1.9861161708831787
Validation loss: 2.244539976119995

Epoch: 6| Step: 9
Training loss: 1.4623132944107056
Validation loss: 2.2454877694447837

Epoch: 6| Step: 10
Training loss: 1.5964007377624512
Validation loss: 2.2147077719370523

Epoch: 6| Step: 11
Training loss: 2.232161045074463
Validation loss: 2.2429948647816977

Epoch: 6| Step: 12
Training loss: 1.5590357780456543
Validation loss: 2.2447831630706787

Epoch: 6| Step: 13
Training loss: 1.017411708831787
Validation loss: 2.237652838230133

Epoch: 245| Step: 0
Training loss: 1.3212555646896362
Validation loss: 2.24442321062088

Epoch: 6| Step: 1
Training loss: 2.285893440246582
Validation loss: 2.2344717184702554

Epoch: 6| Step: 2
Training loss: 1.7776604890823364
Validation loss: 2.261848827203115

Epoch: 6| Step: 3
Training loss: 1.820255994796753
Validation loss: 2.2455838322639465

Epoch: 6| Step: 4
Training loss: 1.7435393333435059
Validation loss: 2.2393550078074136

Epoch: 6| Step: 5
Training loss: 2.0770363807678223
Validation loss: 2.234817703564962

Epoch: 6| Step: 6
Training loss: 2.111217975616455
Validation loss: 2.2324968179066977

Epoch: 6| Step: 7
Training loss: 1.7803692817687988
Validation loss: 2.230012138684591

Epoch: 6| Step: 8
Training loss: 1.404509425163269
Validation loss: 2.2402677138646445

Epoch: 6| Step: 9
Training loss: 1.5518057346343994
Validation loss: 2.2324161529541016

Epoch: 6| Step: 10
Training loss: 1.7152175903320312
Validation loss: 2.2273716926574707

Epoch: 6| Step: 11
Training loss: 1.3376457691192627
Validation loss: 2.2307247122128806

Epoch: 6| Step: 12
Training loss: 1.2720980644226074
Validation loss: 2.227185328801473

Epoch: 6| Step: 13
Training loss: 1.7111380100250244
Validation loss: 2.2322512666384378

Epoch: 246| Step: 0
Training loss: 1.2102885246276855
Validation loss: 2.2344914277394614

Epoch: 6| Step: 1
Training loss: 1.9958133697509766
Validation loss: 2.249810218811035

Epoch: 6| Step: 2
Training loss: 1.6330188512802124
Validation loss: 2.2413987716039023

Epoch: 6| Step: 3
Training loss: 2.0109407901763916
Validation loss: 2.2296720345815024

Epoch: 6| Step: 4
Training loss: 1.6876006126403809
Validation loss: 2.2499038179715476

Epoch: 6| Step: 5
Training loss: 1.6180236339569092
Validation loss: 2.251990556716919

Epoch: 6| Step: 6
Training loss: 1.4516438245773315
Validation loss: 2.2456111113230386

Epoch: 6| Step: 7
Training loss: 1.8099138736724854
Validation loss: 2.243639270464579

Epoch: 6| Step: 8
Training loss: 1.8689335584640503
Validation loss: 2.256811559200287

Epoch: 6| Step: 9
Training loss: 1.676877737045288
Validation loss: 2.228766898314158

Epoch: 6| Step: 10
Training loss: 1.4810576438903809
Validation loss: 2.2416957219441733

Epoch: 6| Step: 11
Training loss: 1.9078789949417114
Validation loss: 2.251268664995829

Epoch: 6| Step: 12
Training loss: 2.0961618423461914
Validation loss: 2.2533739805221558

Epoch: 6| Step: 13
Training loss: 1.3273353576660156
Validation loss: 2.2508105635643005

Epoch: 247| Step: 0
Training loss: 1.7545113563537598
Validation loss: 2.215782562891642

Epoch: 6| Step: 1
Training loss: 2.1911520957946777
Validation loss: 2.232823371887207

Epoch: 6| Step: 2
Training loss: 1.6997404098510742
Validation loss: 2.236678342024485

Epoch: 6| Step: 3
Training loss: 2.2351202964782715
Validation loss: 2.254129409790039

Epoch: 6| Step: 4
Training loss: 1.4157371520996094
Validation loss: 2.2501790523529053

Epoch: 6| Step: 5
Training loss: 1.364434003829956
Validation loss: 2.26591024796168

Epoch: 6| Step: 6
Training loss: 1.2612100839614868
Validation loss: 2.2680055697758994

Epoch: 6| Step: 7
Training loss: 1.8015413284301758
Validation loss: 2.282466928164164

Epoch: 6| Step: 8
Training loss: 1.3578726053237915
Validation loss: 2.2403833667437234

Epoch: 6| Step: 9
Training loss: 1.9341421127319336
Validation loss: 2.2712635596593223

Epoch: 6| Step: 10
Training loss: 1.7563285827636719
Validation loss: 2.2523897687594094

Epoch: 6| Step: 11
Training loss: 1.683396577835083
Validation loss: 2.2304329872131348

Epoch: 6| Step: 12
Training loss: 1.854616641998291
Validation loss: 2.2374871969223022

Epoch: 6| Step: 13
Training loss: 1.6587120294570923
Validation loss: 2.2447325785954795

Epoch: 248| Step: 0
Training loss: 1.7202216386795044
Validation loss: 2.256937305132548

Epoch: 6| Step: 1
Training loss: 1.103108525276184
Validation loss: 2.224418818950653

Epoch: 6| Step: 2
Training loss: 1.9062014818191528
Validation loss: 2.2277484933535256

Epoch: 6| Step: 3
Training loss: 1.763780117034912
Validation loss: 2.2259401281674704

Epoch: 6| Step: 4
Training loss: 1.9081323146820068
Validation loss: 2.243081271648407

Epoch: 6| Step: 5
Training loss: 2.055311679840088
Validation loss: 2.239376942316691

Epoch: 6| Step: 6
Training loss: 1.9236130714416504
Validation loss: 2.2425634264945984

Epoch: 6| Step: 7
Training loss: 1.8588109016418457
Validation loss: 2.2379364569981894

Epoch: 6| Step: 8
Training loss: 2.1191279888153076
Validation loss: 2.2640386819839478

Epoch: 6| Step: 9
Training loss: 1.960707664489746
Validation loss: 2.239993135134379

Epoch: 6| Step: 10
Training loss: 1.2116804122924805
Validation loss: 2.2300528486569724

Epoch: 6| Step: 11
Training loss: 1.104154348373413
Validation loss: 2.2457553148269653

Epoch: 6| Step: 12
Training loss: 1.5687549114227295
Validation loss: 2.2516920963923135

Epoch: 6| Step: 13
Training loss: 1.547431230545044
Validation loss: 2.2498339215914407

Epoch: 249| Step: 0
Training loss: 1.631104826927185
Validation loss: 2.235859990119934

Epoch: 6| Step: 1
Training loss: 1.234100580215454
Validation loss: 2.2644792199134827

Epoch: 6| Step: 2
Training loss: 2.021332025527954
Validation loss: 2.238105575243632

Epoch: 6| Step: 3
Training loss: 1.6005709171295166
Validation loss: 2.220191995302836

Epoch: 6| Step: 4
Training loss: 1.9116992950439453
Validation loss: 2.229774216810862

Epoch: 6| Step: 5
Training loss: 2.128911018371582
Validation loss: 2.222623109817505

Epoch: 6| Step: 6
Training loss: 1.1590148210525513
Validation loss: 2.2255324920018515

Epoch: 6| Step: 7
Training loss: 1.9777289628982544
Validation loss: 2.2326331734657288

Epoch: 6| Step: 8
Training loss: 2.8330845832824707
Validation loss: 2.2326622804005942

Epoch: 6| Step: 9
Training loss: 2.228933811187744
Validation loss: 2.2329753239949546

Epoch: 6| Step: 10
Training loss: 1.6022684574127197
Validation loss: 2.2163100043932595

Epoch: 6| Step: 11
Training loss: 1.0707889795303345
Validation loss: 2.232321242491404

Epoch: 6| Step: 12
Training loss: 1.1968262195587158
Validation loss: 2.2373528679211936

Epoch: 6| Step: 13
Training loss: 1.291590929031372
Validation loss: 2.2373273372650146

Epoch: 250| Step: 0
Training loss: 1.4979114532470703
Validation loss: 2.24807862440745

Epoch: 6| Step: 1
Training loss: 1.7800517082214355
Validation loss: 2.2410614490509033

Epoch: 6| Step: 2
Training loss: 1.4938733577728271
Validation loss: 2.245961864789327

Epoch: 6| Step: 3
Training loss: 0.8147456645965576
Validation loss: 2.2434073090553284

Epoch: 6| Step: 4
Training loss: 2.0283780097961426
Validation loss: 2.232281764348348

Epoch: 6| Step: 5
Training loss: 1.8698667287826538
Validation loss: 2.253158211708069

Epoch: 6| Step: 6
Training loss: 1.902051329612732
Validation loss: 2.2511512835820517

Epoch: 6| Step: 7
Training loss: 1.7364444732666016
Validation loss: 2.251607120037079

Epoch: 6| Step: 8
Training loss: 1.381331443786621
Validation loss: 2.2361051638921103

Epoch: 6| Step: 9
Training loss: 3.1881723403930664
Validation loss: 2.243870973587036

Epoch: 6| Step: 10
Training loss: 1.8017892837524414
Validation loss: 2.215972622235616

Epoch: 6| Step: 11
Training loss: 1.3267433643341064
Validation loss: 2.2041216293970742

Epoch: 6| Step: 12
Training loss: 2.009225368499756
Validation loss: 2.20207550128301

Epoch: 6| Step: 13
Training loss: 1.3906877040863037
Validation loss: 2.1965986688931785

Epoch: 251| Step: 0
Training loss: 1.8408212661743164
Validation loss: 2.18578839302063

Epoch: 6| Step: 1
Training loss: 2.2278401851654053
Validation loss: 2.1730225483576455

Epoch: 6| Step: 2
Training loss: 2.005120277404785
Validation loss: 2.179157773653666

Epoch: 6| Step: 3
Training loss: 1.8796286582946777
Validation loss: 2.1795084873835244

Epoch: 6| Step: 4
Training loss: 1.776328682899475
Validation loss: 2.171053965886434

Epoch: 6| Step: 5
Training loss: 1.606446385383606
Validation loss: 2.1856290698051453

Epoch: 6| Step: 6
Training loss: 1.985964298248291
Validation loss: 2.209633986155192

Epoch: 6| Step: 7
Training loss: 1.227071762084961
Validation loss: 2.2072068452835083

Epoch: 6| Step: 8
Training loss: 1.738611102104187
Validation loss: 2.2081026434898376

Epoch: 6| Step: 9
Training loss: 1.2534589767456055
Validation loss: 2.232052485148112

Epoch: 6| Step: 10
Training loss: 1.8742904663085938
Validation loss: 2.249448815981547

Epoch: 6| Step: 11
Training loss: 2.1104609966278076
Validation loss: 2.2156371672948203

Epoch: 6| Step: 12
Training loss: 1.3170132637023926
Validation loss: 2.2553736567497253

Epoch: 6| Step: 13
Training loss: 1.882961392402649
Validation loss: 2.2152918775876365

Epoch: 252| Step: 0
Training loss: 1.920066475868225
Validation loss: 2.222183267275492

Epoch: 6| Step: 1
Training loss: 1.8879725933074951
Validation loss: 2.259686847527822

Epoch: 6| Step: 2
Training loss: 2.2660977840423584
Validation loss: 2.2533096075057983

Epoch: 6| Step: 3
Training loss: 1.3636467456817627
Validation loss: 2.2293198108673096

Epoch: 6| Step: 4
Training loss: 2.4604437351226807
Validation loss: 2.239874998728434

Epoch: 6| Step: 5
Training loss: 0.7502662539482117
Validation loss: 2.2356929779052734

Epoch: 6| Step: 6
Training loss: 1.7172209024429321
Validation loss: 2.2368452747662864

Epoch: 6| Step: 7
Training loss: 2.1213364601135254
Validation loss: 2.218906362851461

Epoch: 6| Step: 8
Training loss: 1.460781455039978
Validation loss: 2.229701578617096

Epoch: 6| Step: 9
Training loss: 1.8413712978363037
Validation loss: 2.2184067368507385

Epoch: 6| Step: 10
Training loss: 1.5535935163497925
Validation loss: 2.2400009632110596

Epoch: 6| Step: 11
Training loss: 1.4028024673461914
Validation loss: 2.2380197842915854

Epoch: 6| Step: 12
Training loss: 2.0379693508148193
Validation loss: 2.232140362262726

Epoch: 6| Step: 13
Training loss: 1.1603378057479858
Validation loss: 2.2176867723464966

Epoch: 253| Step: 0
Training loss: 1.8735331296920776
Validation loss: 2.2170857588450112

Epoch: 6| Step: 1
Training loss: 1.9160761833190918
Validation loss: 2.2103164394696555

Epoch: 6| Step: 2
Training loss: 2.08870267868042
Validation loss: 2.219095746676127

Epoch: 6| Step: 3
Training loss: 2.1197845935821533
Validation loss: 2.2259310483932495

Epoch: 6| Step: 4
Training loss: 1.3943369388580322
Validation loss: 2.2092715899149575

Epoch: 6| Step: 5
Training loss: 1.7577235698699951
Validation loss: 2.1984476447105408

Epoch: 6| Step: 6
Training loss: 1.8481512069702148
Validation loss: 2.1956467231114707

Epoch: 6| Step: 7
Training loss: 2.849682569503784
Validation loss: 2.1953115860621133

Epoch: 6| Step: 8
Training loss: 1.21016526222229
Validation loss: 2.190922657648722

Epoch: 6| Step: 9
Training loss: 1.7562477588653564
Validation loss: 2.2168218890825906

Epoch: 6| Step: 10
Training loss: 1.3815536499023438
Validation loss: 2.1841973066329956

Epoch: 6| Step: 11
Training loss: 1.2401041984558105
Validation loss: 2.199728310108185

Epoch: 6| Step: 12
Training loss: 1.7637265920639038
Validation loss: 2.215903023878733

Epoch: 6| Step: 13
Training loss: 0.9153021574020386
Validation loss: 2.237004121144613

Epoch: 254| Step: 0
Training loss: 1.8072974681854248
Validation loss: 2.2442067662874856

Epoch: 6| Step: 1
Training loss: 1.719037652015686
Validation loss: 2.233293294906616

Epoch: 6| Step: 2
Training loss: 1.8057544231414795
Validation loss: 2.2397486766179404

Epoch: 6| Step: 3
Training loss: 1.7782511711120605
Validation loss: 2.2428578535715737

Epoch: 6| Step: 4
Training loss: 1.493077278137207
Validation loss: 2.2234214345614114

Epoch: 6| Step: 5
Training loss: 1.965939998626709
Validation loss: 2.2280163963635764

Epoch: 6| Step: 6
Training loss: 1.9626883268356323
Validation loss: 2.2372985084851584

Epoch: 6| Step: 7
Training loss: 1.8440184593200684
Validation loss: 2.223369061946869

Epoch: 6| Step: 8
Training loss: 1.753187656402588
Validation loss: 2.207324763139089

Epoch: 6| Step: 9
Training loss: 0.9890841245651245
Validation loss: 2.2116284569104514

Epoch: 6| Step: 10
Training loss: 1.8995935916900635
Validation loss: 2.191595713297526

Epoch: 6| Step: 11
Training loss: 1.4746915102005005
Validation loss: 2.1885533531506858

Epoch: 6| Step: 12
Training loss: 0.8646417260169983
Validation loss: 2.1935367981592813

Epoch: 6| Step: 13
Training loss: 2.1929216384887695
Validation loss: 2.209528168042501

Epoch: 255| Step: 0
Training loss: 1.9739625453948975
Validation loss: 2.2025888562202454

Epoch: 6| Step: 1
Training loss: 2.0711240768432617
Validation loss: 2.2000542879104614

Epoch: 6| Step: 2
Training loss: 2.248018741607666
Validation loss: 2.2250619928042092

Epoch: 6| Step: 3
Training loss: 2.3014464378356934
Validation loss: 2.1941134929656982

Epoch: 6| Step: 4
Training loss: 1.2707226276397705
Validation loss: 2.1820021669069924

Epoch: 6| Step: 5
Training loss: 1.35396146774292
Validation loss: 2.1914830605189004

Epoch: 6| Step: 6
Training loss: 1.6975973844528198
Validation loss: 2.181887964407603

Epoch: 6| Step: 7
Training loss: 1.3933415412902832
Validation loss: 2.200085759162903

Epoch: 6| Step: 8
Training loss: 1.8547295331954956
Validation loss: 2.176645358403524

Epoch: 6| Step: 9
Training loss: 2.0852808952331543
Validation loss: 2.191482424736023

Epoch: 6| Step: 10
Training loss: 1.5074760913848877
Validation loss: 2.186859389146169

Epoch: 6| Step: 11
Training loss: 1.935713529586792
Validation loss: 2.1975446144739785

Epoch: 6| Step: 12
Training loss: 1.1047533750534058
Validation loss: 2.1975411574045816

Epoch: 6| Step: 13
Training loss: 1.9527394771575928
Validation loss: 2.1905657052993774

Epoch: 256| Step: 0
Training loss: 2.419492721557617
Validation loss: 2.19276229540507

Epoch: 6| Step: 1
Training loss: 2.379871368408203
Validation loss: 2.198719104131063

Epoch: 6| Step: 2
Training loss: 1.6182960271835327
Validation loss: 2.221007784207662

Epoch: 6| Step: 3
Training loss: 1.4838169813156128
Validation loss: 2.215118865172068

Epoch: 6| Step: 4
Training loss: 1.1770116090774536
Validation loss: 2.234808564186096

Epoch: 6| Step: 5
Training loss: 1.9356443881988525
Validation loss: 2.2350163062413535

Epoch: 6| Step: 6
Training loss: 1.2519526481628418
Validation loss: 2.2166507045427957

Epoch: 6| Step: 7
Training loss: 1.8658877611160278
Validation loss: 2.2364347179730735

Epoch: 6| Step: 8
Training loss: 1.1586682796478271
Validation loss: 2.231688459714254

Epoch: 6| Step: 9
Training loss: 1.8515923023223877
Validation loss: 2.2260838747024536

Epoch: 6| Step: 10
Training loss: 1.220116138458252
Validation loss: 2.2376499573389688

Epoch: 6| Step: 11
Training loss: 1.7408766746520996
Validation loss: 2.2308393319447837

Epoch: 6| Step: 12
Training loss: 2.1059651374816895
Validation loss: 2.207830230394999

Epoch: 6| Step: 13
Training loss: 1.638336181640625
Validation loss: 2.2069605588912964

Epoch: 257| Step: 0
Training loss: 1.0190231800079346
Validation loss: 2.20671417315801

Epoch: 6| Step: 1
Training loss: 1.2257070541381836
Validation loss: 2.22326252857844

Epoch: 6| Step: 2
Training loss: 1.943932056427002
Validation loss: 2.2362085779507956

Epoch: 6| Step: 3
Training loss: 2.276092529296875
Validation loss: 2.2342353065808616

Epoch: 6| Step: 4
Training loss: 1.8705012798309326
Validation loss: 2.2583023508389792

Epoch: 6| Step: 5
Training loss: 2.237603187561035
Validation loss: 2.236826539039612

Epoch: 6| Step: 6
Training loss: 1.9150173664093018
Validation loss: 2.2594467202822366

Epoch: 6| Step: 7
Training loss: 1.4626457691192627
Validation loss: 2.246699492136637

Epoch: 6| Step: 8
Training loss: 1.0649440288543701
Validation loss: 2.2468892137209573

Epoch: 6| Step: 9
Training loss: 1.081822156906128
Validation loss: 2.2281145254770913

Epoch: 6| Step: 10
Training loss: 2.2505125999450684
Validation loss: 2.2276328802108765

Epoch: 6| Step: 11
Training loss: 1.4751882553100586
Validation loss: 2.2219140926996865

Epoch: 6| Step: 12
Training loss: 1.713073968887329
Validation loss: 2.238685687383016

Epoch: 6| Step: 13
Training loss: 1.824428677558899
Validation loss: 2.2397484381993613

Epoch: 258| Step: 0
Training loss: 1.5663654804229736
Validation loss: 2.2281241615613303

Epoch: 6| Step: 1
Training loss: 1.758786678314209
Validation loss: 2.2720730900764465

Epoch: 6| Step: 2
Training loss: 1.111274242401123
Validation loss: 2.261785308519999

Epoch: 6| Step: 3
Training loss: 2.5811753273010254
Validation loss: 2.2658730149269104

Epoch: 6| Step: 4
Training loss: 1.6185595989227295
Validation loss: 2.260240395863851

Epoch: 6| Step: 5
Training loss: 1.8814491033554077
Validation loss: 2.2689977089564004

Epoch: 6| Step: 6
Training loss: 1.3137426376342773
Validation loss: 2.243835727373759

Epoch: 6| Step: 7
Training loss: 1.2183947563171387
Validation loss: 2.214275360107422

Epoch: 6| Step: 8
Training loss: 1.9004780054092407
Validation loss: 2.227112094561259

Epoch: 6| Step: 9
Training loss: 1.297070026397705
Validation loss: 2.22548238436381

Epoch: 6| Step: 10
Training loss: 2.0636379718780518
Validation loss: 2.2347931265830994

Epoch: 6| Step: 11
Training loss: 1.8115445375442505
Validation loss: 2.2288072307904563

Epoch: 6| Step: 12
Training loss: 1.6466244459152222
Validation loss: 2.2257919311523438

Epoch: 6| Step: 13
Training loss: 1.3602585792541504
Validation loss: 2.2257054448127747

Epoch: 259| Step: 0
Training loss: 1.7700952291488647
Validation loss: 2.235256314277649

Epoch: 6| Step: 1
Training loss: 1.7790203094482422
Validation loss: 2.2433624466260276

Epoch: 6| Step: 2
Training loss: 1.4521366357803345
Validation loss: 2.244824786980947

Epoch: 6| Step: 3
Training loss: 1.5710811614990234
Validation loss: 2.216343343257904

Epoch: 6| Step: 4
Training loss: 2.070901870727539
Validation loss: 2.255319595336914

Epoch: 6| Step: 5
Training loss: 1.7447878122329712
Validation loss: 2.237867077191671

Epoch: 6| Step: 6
Training loss: 1.477829933166504
Validation loss: 2.2478424112002053

Epoch: 6| Step: 7
Training loss: 1.699550747871399
Validation loss: 2.247049252192179

Epoch: 6| Step: 8
Training loss: 1.6162865161895752
Validation loss: 2.231256683667501

Epoch: 6| Step: 9
Training loss: 1.3169437646865845
Validation loss: 2.25288724899292

Epoch: 6| Step: 10
Training loss: 1.5156986713409424
Validation loss: 2.250318765640259

Epoch: 6| Step: 11
Training loss: 1.4500471353530884
Validation loss: 2.2577167749404907

Epoch: 6| Step: 12
Training loss: 1.913334608078003
Validation loss: 2.243507146835327

Epoch: 6| Step: 13
Training loss: 2.0484933853149414
Validation loss: 2.2523428400357566

Epoch: 260| Step: 0
Training loss: 1.6793056726455688
Validation loss: 2.2493653893470764

Epoch: 6| Step: 1
Training loss: 1.9372544288635254
Validation loss: 2.2385813196500144

Epoch: 6| Step: 2
Training loss: 1.529961347579956
Validation loss: 2.2491023540496826

Epoch: 6| Step: 3
Training loss: 1.95758056640625
Validation loss: 2.29950342575709

Epoch: 6| Step: 4
Training loss: 1.052370548248291
Validation loss: 2.246617575486501

Epoch: 6| Step: 5
Training loss: 2.213909149169922
Validation loss: 2.254476030667623

Epoch: 6| Step: 6
Training loss: 0.8848972320556641
Validation loss: 2.2410393158594766

Epoch: 6| Step: 7
Training loss: 2.3137097358703613
Validation loss: 2.2862886786460876

Epoch: 6| Step: 8
Training loss: 1.4484837055206299
Validation loss: 2.2635480960210166

Epoch: 6| Step: 9
Training loss: 1.106492280960083
Validation loss: 2.2857199907302856

Epoch: 6| Step: 10
Training loss: 1.9482064247131348
Validation loss: 2.2415109872817993

Epoch: 6| Step: 11
Training loss: 2.2672595977783203
Validation loss: 2.236837883790334

Epoch: 6| Step: 12
Training loss: 1.1976983547210693
Validation loss: 2.2469738721847534

Epoch: 6| Step: 13
Training loss: 2.211296796798706
Validation loss: 2.2357492049535117

Epoch: 261| Step: 0
Training loss: 1.6976009607315063
Validation loss: 2.2387144764264426

Epoch: 6| Step: 1
Training loss: 1.1288206577301025
Validation loss: 2.2822608153025308

Epoch: 6| Step: 2
Training loss: 1.174020767211914
Validation loss: 2.251450836658478

Epoch: 6| Step: 3
Training loss: 2.0508947372436523
Validation loss: 2.26640248298645

Epoch: 6| Step: 4
Training loss: 1.669675350189209
Validation loss: 2.3046390414237976

Epoch: 6| Step: 5
Training loss: 1.7902331352233887
Validation loss: 2.2687702576319375

Epoch: 6| Step: 6
Training loss: 2.0518927574157715
Validation loss: 2.258176863193512

Epoch: 6| Step: 7
Training loss: 2.1253602504730225
Validation loss: 2.2826033234596252

Epoch: 6| Step: 8
Training loss: 1.6211440563201904
Validation loss: 2.284531831741333

Epoch: 6| Step: 9
Training loss: 1.9247666597366333
Validation loss: 2.285750369230906

Epoch: 6| Step: 10
Training loss: 1.6384789943695068
Validation loss: 2.293211817741394

Epoch: 6| Step: 11
Training loss: 1.5961521863937378
Validation loss: 2.2665162086486816

Epoch: 6| Step: 12
Training loss: 1.8698582649230957
Validation loss: 2.2697921792666116

Epoch: 6| Step: 13
Training loss: 1.320883870124817
Validation loss: 2.2459837992986045

Epoch: 262| Step: 0
Training loss: 1.6135045289993286
Validation loss: 2.2443397641181946

Epoch: 6| Step: 1
Training loss: 1.8587195873260498
Validation loss: 2.2458796302477517

Epoch: 6| Step: 2
Training loss: 1.2657477855682373
Validation loss: 2.2393611073493958

Epoch: 6| Step: 3
Training loss: 2.0315890312194824
Validation loss: 2.253831605116526

Epoch: 6| Step: 4
Training loss: 1.2016820907592773
Validation loss: 2.248375137646993

Epoch: 6| Step: 5
Training loss: 2.3682823181152344
Validation loss: 2.268354376157125

Epoch: 6| Step: 6
Training loss: 1.4582009315490723
Validation loss: 2.269715984662374

Epoch: 6| Step: 7
Training loss: 1.6673399209976196
Validation loss: 2.256378789742788

Epoch: 6| Step: 8
Training loss: 1.3634388446807861
Validation loss: 2.2406457662582397

Epoch: 6| Step: 9
Training loss: 2.0769271850585938
Validation loss: 2.2251747449239097

Epoch: 6| Step: 10
Training loss: 1.6111255884170532
Validation loss: 2.252705534299215

Epoch: 6| Step: 11
Training loss: 1.9866701364517212
Validation loss: 2.223160227139791

Epoch: 6| Step: 12
Training loss: 2.015443801879883
Validation loss: 2.2127065658569336

Epoch: 6| Step: 13
Training loss: 1.2141499519348145
Validation loss: 2.2116557359695435

Epoch: 263| Step: 0
Training loss: 1.7133924961090088
Validation loss: 2.2215933005015054

Epoch: 6| Step: 1
Training loss: 1.5068607330322266
Validation loss: 2.217748840649923

Epoch: 6| Step: 2
Training loss: 1.7461273670196533
Validation loss: 2.2226782043774924

Epoch: 6| Step: 3
Training loss: 1.3351876735687256
Validation loss: 2.205487231413523

Epoch: 6| Step: 4
Training loss: 1.5025734901428223
Validation loss: 2.2216895818710327

Epoch: 6| Step: 5
Training loss: 1.4879571199417114
Validation loss: 2.2138845920562744

Epoch: 6| Step: 6
Training loss: 1.8133610486984253
Validation loss: 2.2242735425631204

Epoch: 6| Step: 7
Training loss: 2.1911823749542236
Validation loss: 2.224714716275533

Epoch: 6| Step: 8
Training loss: 2.359394073486328
Validation loss: 2.2237481673558555

Epoch: 6| Step: 9
Training loss: 1.1809520721435547
Validation loss: 2.209211309750875

Epoch: 6| Step: 10
Training loss: 1.8045440912246704
Validation loss: 2.216517964998881

Epoch: 6| Step: 11
Training loss: 1.3778560161590576
Validation loss: 2.216305216153463

Epoch: 6| Step: 12
Training loss: 1.335338830947876
Validation loss: 2.257817188898722

Epoch: 6| Step: 13
Training loss: 2.0092933177948
Validation loss: 2.23020201921463

Epoch: 264| Step: 0
Training loss: 1.0742168426513672
Validation loss: 2.2503074407577515

Epoch: 6| Step: 1
Training loss: 1.6661086082458496
Validation loss: 2.2442173759142556

Epoch: 6| Step: 2
Training loss: 1.6515294313430786
Validation loss: 2.2244874636332193

Epoch: 6| Step: 3
Training loss: 2.439324378967285
Validation loss: 2.2144705057144165

Epoch: 6| Step: 4
Training loss: 1.5562132596969604
Validation loss: 2.247988780339559

Epoch: 6| Step: 5
Training loss: 1.0297789573669434
Validation loss: 2.2428528865178428

Epoch: 6| Step: 6
Training loss: 1.3216619491577148
Validation loss: 2.245696504910787

Epoch: 6| Step: 7
Training loss: 1.6963090896606445
Validation loss: 2.24300479888916

Epoch: 6| Step: 8
Training loss: 1.9147181510925293
Validation loss: 2.2467183470726013

Epoch: 6| Step: 9
Training loss: 1.630772590637207
Validation loss: 2.267894128958384

Epoch: 6| Step: 10
Training loss: 2.0318222045898438
Validation loss: 2.2251839637756348

Epoch: 6| Step: 11
Training loss: 1.7702348232269287
Validation loss: 2.2656776110331216

Epoch: 6| Step: 12
Training loss: 1.7781654596328735
Validation loss: 2.242295801639557

Epoch: 6| Step: 13
Training loss: 1.9827595949172974
Validation loss: 2.247181018193563

Epoch: 265| Step: 0
Training loss: 1.721311330795288
Validation loss: 2.227742373943329

Epoch: 6| Step: 1
Training loss: 1.4765188694000244
Validation loss: 2.231201688448588

Epoch: 6| Step: 2
Training loss: 1.9124069213867188
Validation loss: 2.2316933075586953

Epoch: 6| Step: 3
Training loss: 1.505102515220642
Validation loss: 2.235086679458618

Epoch: 6| Step: 4
Training loss: 1.4110448360443115
Validation loss: 2.2115673820177713

Epoch: 6| Step: 5
Training loss: 1.8619407415390015
Validation loss: 2.2532668113708496

Epoch: 6| Step: 6
Training loss: 1.8096070289611816
Validation loss: 2.242208421230316

Epoch: 6| Step: 7
Training loss: 1.8284143209457397
Validation loss: 2.243618627389272

Epoch: 6| Step: 8
Training loss: 1.2990145683288574
Validation loss: 2.2507964372634888

Epoch: 6| Step: 9
Training loss: 1.0354604721069336
Validation loss: 2.239151974519094

Epoch: 6| Step: 10
Training loss: 1.9259765148162842
Validation loss: 2.2384698192278543

Epoch: 6| Step: 11
Training loss: 1.7731127738952637
Validation loss: 2.264898101488749

Epoch: 6| Step: 12
Training loss: 1.610774278640747
Validation loss: 2.249569833278656

Epoch: 6| Step: 13
Training loss: 1.6798436641693115
Validation loss: 2.236562649408976

Epoch: 266| Step: 0
Training loss: 2.145151376724243
Validation loss: 2.233611226081848

Epoch: 6| Step: 1
Training loss: 1.3904242515563965
Validation loss: 2.249061365922292

Epoch: 6| Step: 2
Training loss: 1.9348030090332031
Validation loss: 2.2526701291402182

Epoch: 6| Step: 3
Training loss: 1.6198359727859497
Validation loss: 2.2387794256210327

Epoch: 6| Step: 4
Training loss: 1.2205688953399658
Validation loss: 2.232097943623861

Epoch: 6| Step: 5
Training loss: 1.4002909660339355
Validation loss: 2.228063384691874

Epoch: 6| Step: 6
Training loss: 1.1427513360977173
Validation loss: 2.2321455478668213

Epoch: 6| Step: 7
Training loss: 1.3114795684814453
Validation loss: 2.21361651023229

Epoch: 6| Step: 8
Training loss: 2.3275206089019775
Validation loss: 2.230922222137451

Epoch: 6| Step: 9
Training loss: 1.9942208528518677
Validation loss: 2.238268772761027

Epoch: 6| Step: 10
Training loss: 1.2712748050689697
Validation loss: 2.2523935238520303

Epoch: 6| Step: 11
Training loss: 1.858392596244812
Validation loss: 2.244562109311422

Epoch: 6| Step: 12
Training loss: 1.2990164756774902
Validation loss: 2.233032842477163

Epoch: 6| Step: 13
Training loss: 1.865987777709961
Validation loss: 2.2580294609069824

Epoch: 267| Step: 0
Training loss: 1.5508365631103516
Validation loss: 2.2656965851783752

Epoch: 6| Step: 1
Training loss: 1.089460849761963
Validation loss: 2.2300671140352883

Epoch: 6| Step: 2
Training loss: 2.044711112976074
Validation loss: 2.2280337611834207

Epoch: 6| Step: 3
Training loss: 1.8050990104675293
Validation loss: 2.258918066819509

Epoch: 6| Step: 4
Training loss: 2.0858120918273926
Validation loss: 2.2300148407618203

Epoch: 6| Step: 5
Training loss: 1.7614654302597046
Validation loss: 2.2170820236206055

Epoch: 6| Step: 6
Training loss: 1.2083648443222046
Validation loss: 2.237431287765503

Epoch: 6| Step: 7
Training loss: 1.8396953344345093
Validation loss: 2.210850993792216

Epoch: 6| Step: 8
Training loss: 0.6480486392974854
Validation loss: 2.2104847033818564

Epoch: 6| Step: 9
Training loss: 2.0969977378845215
Validation loss: 2.2008228103319802

Epoch: 6| Step: 10
Training loss: 1.3287405967712402
Validation loss: 2.20935066541036

Epoch: 6| Step: 11
Training loss: 1.7897205352783203
Validation loss: 2.219092309474945

Epoch: 6| Step: 12
Training loss: 2.0738942623138428
Validation loss: 2.2202577590942383

Epoch: 6| Step: 13
Training loss: 1.8840727806091309
Validation loss: 2.220821499824524

Epoch: 268| Step: 0
Training loss: 1.288712739944458
Validation loss: 2.2154377698898315

Epoch: 6| Step: 1
Training loss: 1.7110172510147095
Validation loss: 2.237206757068634

Epoch: 6| Step: 2
Training loss: 1.023024559020996
Validation loss: 2.2523261507352195

Epoch: 6| Step: 3
Training loss: 2.2499539852142334
Validation loss: 2.2341574231783548

Epoch: 6| Step: 4
Training loss: 1.634886384010315
Validation loss: 2.2342737913131714

Epoch: 6| Step: 5
Training loss: 1.2966508865356445
Validation loss: 2.207246780395508

Epoch: 6| Step: 6
Training loss: 2.375201463699341
Validation loss: 2.2194941441218057

Epoch: 6| Step: 7
Training loss: 1.6070899963378906
Validation loss: 2.216536521911621

Epoch: 6| Step: 8
Training loss: 2.0006930828094482
Validation loss: 2.2361497481664023

Epoch: 6| Step: 9
Training loss: 1.5149667263031006
Validation loss: 2.23172789812088

Epoch: 6| Step: 10
Training loss: 1.2085964679718018
Validation loss: 2.242710610230764

Epoch: 6| Step: 11
Training loss: 1.7659189701080322
Validation loss: 2.2191323041915894

Epoch: 6| Step: 12
Training loss: 1.8681267499923706
Validation loss: 2.214584012826284

Epoch: 6| Step: 13
Training loss: 1.0873403549194336
Validation loss: 2.2439637382825217

Epoch: 269| Step: 0
Training loss: 1.7880017757415771
Validation loss: 2.2172905604044595

Epoch: 6| Step: 1
Training loss: 1.482000470161438
Validation loss: 2.2149620254834494

Epoch: 6| Step: 2
Training loss: 1.5076446533203125
Validation loss: 2.224747876326243

Epoch: 6| Step: 3
Training loss: 1.5408835411071777
Validation loss: 2.2417648832003274

Epoch: 6| Step: 4
Training loss: 2.34622859954834
Validation loss: 2.2406168381373086

Epoch: 6| Step: 5
Training loss: 1.3817769289016724
Validation loss: 2.249496797720591

Epoch: 6| Step: 6
Training loss: 1.324759602546692
Validation loss: 2.249755620956421

Epoch: 6| Step: 7
Training loss: 2.1293067932128906
Validation loss: 2.28563529253006

Epoch: 6| Step: 8
Training loss: 1.7219419479370117
Validation loss: 2.262456178665161

Epoch: 6| Step: 9
Training loss: 2.280322790145874
Validation loss: 2.273377517859141

Epoch: 6| Step: 10
Training loss: 1.173173427581787
Validation loss: 2.268675963083903

Epoch: 6| Step: 11
Training loss: 1.443979024887085
Validation loss: 2.27823007106781

Epoch: 6| Step: 12
Training loss: 1.1774570941925049
Validation loss: 2.2670900026957193

Epoch: 6| Step: 13
Training loss: 1.269059181213379
Validation loss: 2.2712422609329224

Epoch: 270| Step: 0
Training loss: 1.6040116548538208
Validation loss: 2.257416566212972

Epoch: 6| Step: 1
Training loss: 1.5289770364761353
Validation loss: 2.2372511625289917

Epoch: 6| Step: 2
Training loss: 1.6537699699401855
Validation loss: 2.202721277872721

Epoch: 6| Step: 3
Training loss: 1.2670199871063232
Validation loss: 2.2468238472938538

Epoch: 6| Step: 4
Training loss: 2.252567768096924
Validation loss: 2.237666606903076

Epoch: 6| Step: 5
Training loss: 1.221174716949463
Validation loss: 2.2644502321879068

Epoch: 6| Step: 6
Training loss: 1.8876792192459106
Validation loss: 2.271592458089193

Epoch: 6| Step: 7
Training loss: 2.071193218231201
Validation loss: 2.25022820631663

Epoch: 6| Step: 8
Training loss: 1.793323278427124
Validation loss: 2.2671817541122437

Epoch: 6| Step: 9
Training loss: 1.199320673942566
Validation loss: 2.270952502886454

Epoch: 6| Step: 10
Training loss: 1.4761722087860107
Validation loss: 2.249428153038025

Epoch: 6| Step: 11
Training loss: 2.052550792694092
Validation loss: 2.2644925514856973

Epoch: 6| Step: 12
Training loss: 1.5739225149154663
Validation loss: 2.2572932640711465

Epoch: 6| Step: 13
Training loss: 1.4268009662628174
Validation loss: 2.281655212243398

Epoch: 271| Step: 0
Training loss: 2.3844971656799316
Validation loss: 2.2621052265167236

Epoch: 6| Step: 1
Training loss: 1.615675449371338
Validation loss: 2.2134009997049966

Epoch: 6| Step: 2
Training loss: 1.9962334632873535
Validation loss: 2.2505226333936057

Epoch: 6| Step: 3
Training loss: 1.8483684062957764
Validation loss: 2.2292109529177346

Epoch: 6| Step: 4
Training loss: 1.3750919103622437
Validation loss: 2.2234307130177817

Epoch: 6| Step: 5
Training loss: 1.4058727025985718
Validation loss: 2.2194162607192993

Epoch: 6| Step: 6
Training loss: 1.4712188243865967
Validation loss: 2.20508348941803

Epoch: 6| Step: 7
Training loss: 1.6051533222198486
Validation loss: 2.2323228120803833

Epoch: 6| Step: 8
Training loss: 2.13956356048584
Validation loss: 2.199538509051005

Epoch: 6| Step: 9
Training loss: 0.9194140434265137
Validation loss: 2.222371757030487

Epoch: 6| Step: 10
Training loss: 1.0759103298187256
Validation loss: 2.223806063334147

Epoch: 6| Step: 11
Training loss: 1.4959564208984375
Validation loss: 2.2421669562657676

Epoch: 6| Step: 12
Training loss: 1.9927005767822266
Validation loss: 2.2418338656425476

Epoch: 6| Step: 13
Training loss: 1.8850520849227905
Validation loss: 2.206911484400431

Epoch: 272| Step: 0
Training loss: 1.6517829895019531
Validation loss: 2.244261384010315

Epoch: 6| Step: 1
Training loss: 1.5301803350448608
Validation loss: 2.2463117043177285

Epoch: 6| Step: 2
Training loss: 1.3262572288513184
Validation loss: 2.228727479775747

Epoch: 6| Step: 3
Training loss: 1.5956406593322754
Validation loss: 2.217850387096405

Epoch: 6| Step: 4
Training loss: 1.8960307836532593
Validation loss: 2.227008283138275

Epoch: 6| Step: 5
Training loss: 1.1930837631225586
Validation loss: 2.2360734740893045

Epoch: 6| Step: 6
Training loss: 1.8354606628417969
Validation loss: 2.2458215951919556

Epoch: 6| Step: 7
Training loss: 1.113722801208496
Validation loss: 2.2580231626828513

Epoch: 6| Step: 8
Training loss: 2.0142295360565186
Validation loss: 2.2187457283337912

Epoch: 6| Step: 9
Training loss: 1.612777590751648
Validation loss: 2.2305987079938254

Epoch: 6| Step: 10
Training loss: 2.868323802947998
Validation loss: 2.244820713996887

Epoch: 6| Step: 11
Training loss: 1.473609447479248
Validation loss: 2.2549238204956055

Epoch: 6| Step: 12
Training loss: 1.8895204067230225
Validation loss: 2.2420729994773865

Epoch: 6| Step: 13
Training loss: 1.1797738075256348
Validation loss: 2.253160238265991

Epoch: 273| Step: 0
Training loss: 1.7898688316345215
Validation loss: 2.2560536662737527

Epoch: 6| Step: 1
Training loss: 1.5017869472503662
Validation loss: 2.2348153392473855

Epoch: 6| Step: 2
Training loss: 1.1047910451889038
Validation loss: 2.2174110809961953

Epoch: 6| Step: 3
Training loss: 2.009242057800293
Validation loss: 2.2143277525901794

Epoch: 6| Step: 4
Training loss: 1.61891508102417
Validation loss: 2.22727765639623

Epoch: 6| Step: 5
Training loss: 1.5148943662643433
Validation loss: 2.218404173851013

Epoch: 6| Step: 6
Training loss: 1.3487191200256348
Validation loss: 2.2280198534329734

Epoch: 6| Step: 7
Training loss: 2.151723623275757
Validation loss: 2.221376637617747

Epoch: 6| Step: 8
Training loss: 1.7374485731124878
Validation loss: 2.2383458415667215

Epoch: 6| Step: 9
Training loss: 1.5018880367279053
Validation loss: 2.254714091618856

Epoch: 6| Step: 10
Training loss: 1.6179474592208862
Validation loss: 2.2428292433420816

Epoch: 6| Step: 11
Training loss: 1.8220638036727905
Validation loss: 2.267298479874929

Epoch: 6| Step: 12
Training loss: 1.2393872737884521
Validation loss: 2.2637433211008706

Epoch: 6| Step: 13
Training loss: 1.4937599897384644
Validation loss: 2.2637267311414084

Epoch: 274| Step: 0
Training loss: 1.2983187437057495
Validation loss: 2.2642276088396707

Epoch: 6| Step: 1
Training loss: 1.1312556266784668
Validation loss: 2.2455952167510986

Epoch: 6| Step: 2
Training loss: 1.040658950805664
Validation loss: 2.254463334878286

Epoch: 6| Step: 3
Training loss: 2.256884813308716
Validation loss: 2.2398639917373657

Epoch: 6| Step: 4
Training loss: 1.4409774541854858
Validation loss: 2.2640291651089988

Epoch: 6| Step: 5
Training loss: 1.9125828742980957
Validation loss: 2.241872509320577

Epoch: 6| Step: 6
Training loss: 1.1539947986602783
Validation loss: 2.2533589601516724

Epoch: 6| Step: 7
Training loss: 1.9008487462997437
Validation loss: 2.245549182097117

Epoch: 6| Step: 8
Training loss: 1.6372408866882324
Validation loss: 2.243304987748464

Epoch: 6| Step: 9
Training loss: 1.923970103263855
Validation loss: 2.22875448067983

Epoch: 6| Step: 10
Training loss: 1.720491886138916
Validation loss: 2.2147743503252664

Epoch: 6| Step: 11
Training loss: 1.5368945598602295
Validation loss: 2.227045933405558

Epoch: 6| Step: 12
Training loss: 2.647878646850586
Validation loss: 2.2324471473693848

Epoch: 6| Step: 13
Training loss: 0.9954316020011902
Validation loss: 2.2275392611821494

Epoch: 275| Step: 0
Training loss: 1.7335307598114014
Validation loss: 2.2349287072817483

Epoch: 6| Step: 1
Training loss: 1.216738224029541
Validation loss: 2.2370142340660095

Epoch: 6| Step: 2
Training loss: 1.505685806274414
Validation loss: 2.246906359990438

Epoch: 6| Step: 3
Training loss: 1.6227009296417236
Validation loss: 2.2271325985590615

Epoch: 6| Step: 4
Training loss: 1.3955345153808594
Validation loss: 2.2450198332468667

Epoch: 6| Step: 5
Training loss: 2.2188990116119385
Validation loss: 2.2264373699824014

Epoch: 6| Step: 6
Training loss: 2.0626306533813477
Validation loss: 2.2426268657048545

Epoch: 6| Step: 7
Training loss: 0.9525973200798035
Validation loss: 2.224381069342295

Epoch: 6| Step: 8
Training loss: 1.3746511936187744
Validation loss: 2.2183053294817605

Epoch: 6| Step: 9
Training loss: 1.2954580783843994
Validation loss: 2.2293065786361694

Epoch: 6| Step: 10
Training loss: 2.251613140106201
Validation loss: 2.2166367371877036

Epoch: 6| Step: 11
Training loss: 1.0479580163955688
Validation loss: 2.2348654866218567

Epoch: 6| Step: 12
Training loss: 1.7163540124893188
Validation loss: 2.206480344136556

Epoch: 6| Step: 13
Training loss: 1.8451064825057983
Validation loss: 2.2068846225738525

Epoch: 276| Step: 0
Training loss: 0.7772758603096008
Validation loss: 2.2293317914009094

Epoch: 6| Step: 1
Training loss: 1.3617061376571655
Validation loss: 2.243529518445333

Epoch: 6| Step: 2
Training loss: 1.3194857835769653
Validation loss: 2.226089676221212

Epoch: 6| Step: 3
Training loss: 1.7011134624481201
Validation loss: 2.234279195467631

Epoch: 6| Step: 4
Training loss: 1.2423735857009888
Validation loss: 2.232627809047699

Epoch: 6| Step: 5
Training loss: 1.8378697633743286
Validation loss: 2.2217907905578613

Epoch: 6| Step: 6
Training loss: 1.7929575443267822
Validation loss: 2.2446569005648294

Epoch: 6| Step: 7
Training loss: 1.3860278129577637
Validation loss: 2.2531182368596396

Epoch: 6| Step: 8
Training loss: 2.068096160888672
Validation loss: 2.245511790116628

Epoch: 6| Step: 9
Training loss: 2.3274707794189453
Validation loss: 2.256584127744039

Epoch: 6| Step: 10
Training loss: 1.47642183303833
Validation loss: 2.2270063956578574

Epoch: 6| Step: 11
Training loss: 1.1955201625823975
Validation loss: 2.2360432942708335

Epoch: 6| Step: 12
Training loss: 1.725738763809204
Validation loss: 2.232724448045095

Epoch: 6| Step: 13
Training loss: 2.0131306648254395
Validation loss: 2.257062534491221

Epoch: 277| Step: 0
Training loss: 0.899074912071228
Validation loss: 2.235981067021688

Epoch: 6| Step: 1
Training loss: 1.418464183807373
Validation loss: 2.2119274735450745

Epoch: 6| Step: 2
Training loss: 1.6000595092773438
Validation loss: 2.2301374077796936

Epoch: 6| Step: 3
Training loss: 1.350508689880371
Validation loss: 2.2169804175694785

Epoch: 6| Step: 4
Training loss: 1.9438834190368652
Validation loss: 2.207009255886078

Epoch: 6| Step: 5
Training loss: 1.6477367877960205
Validation loss: 2.2214603821436563

Epoch: 6| Step: 6
Training loss: 1.445904016494751
Validation loss: 2.21058181921641

Epoch: 6| Step: 7
Training loss: 1.8245584964752197
Validation loss: 2.224927028020223

Epoch: 6| Step: 8
Training loss: 2.404994487762451
Validation loss: 2.2311178048451743

Epoch: 6| Step: 9
Training loss: 2.351522922515869
Validation loss: 2.2270955244700112

Epoch: 6| Step: 10
Training loss: 1.5872762203216553
Validation loss: 2.1939252614974976

Epoch: 6| Step: 11
Training loss: 1.2582751512527466
Validation loss: 2.2172022064526877

Epoch: 6| Step: 12
Training loss: 1.713484764099121
Validation loss: 2.218787431716919

Epoch: 6| Step: 13
Training loss: 0.8265864849090576
Validation loss: 2.237231492996216

Epoch: 278| Step: 0
Training loss: 1.0196269750595093
Validation loss: 2.237398167451223

Epoch: 6| Step: 1
Training loss: 1.386108160018921
Validation loss: 2.24576473236084

Epoch: 6| Step: 2
Training loss: 1.2150357961654663
Validation loss: 2.2248851656913757

Epoch: 6| Step: 3
Training loss: 1.5435069799423218
Validation loss: 2.2501227060953775

Epoch: 6| Step: 4
Training loss: 1.5032017230987549
Validation loss: 2.2395336031913757

Epoch: 6| Step: 5
Training loss: 2.06467342376709
Validation loss: 2.2408559918403625

Epoch: 6| Step: 6
Training loss: 1.8624787330627441
Validation loss: 2.26975683371226

Epoch: 6| Step: 7
Training loss: 1.993814468383789
Validation loss: 2.263060768445333

Epoch: 6| Step: 8
Training loss: 1.1043994426727295
Validation loss: 2.240777850151062

Epoch: 6| Step: 9
Training loss: 1.1577305793762207
Validation loss: 2.245904246966044

Epoch: 6| Step: 10
Training loss: 2.3286168575286865
Validation loss: 2.25665146112442

Epoch: 6| Step: 11
Training loss: 1.6974937915802002
Validation loss: 2.230319003264109

Epoch: 6| Step: 12
Training loss: 1.4005773067474365
Validation loss: 2.2099194327990213

Epoch: 6| Step: 13
Training loss: 1.7134065628051758
Validation loss: 2.2128838300704956

Epoch: 279| Step: 0
Training loss: 0.761696994304657
Validation loss: 2.1994138956069946

Epoch: 6| Step: 1
Training loss: 1.0853205919265747
Validation loss: 2.1632224718729653

Epoch: 6| Step: 2
Training loss: 1.6198536157608032
Validation loss: 2.172575831413269

Epoch: 6| Step: 3
Training loss: 1.5667884349822998
Validation loss: 2.176379998524984

Epoch: 6| Step: 4
Training loss: 1.6548160314559937
Validation loss: 2.181159257888794

Epoch: 6| Step: 5
Training loss: 2.4597110748291016
Validation loss: 2.1859556237856546

Epoch: 6| Step: 6
Training loss: 1.4481513500213623
Validation loss: 2.1906818548838296

Epoch: 6| Step: 7
Training loss: 1.518219232559204
Validation loss: 2.1811635494232178

Epoch: 6| Step: 8
Training loss: 1.5884974002838135
Validation loss: 2.1702667474746704

Epoch: 6| Step: 9
Training loss: 1.910421371459961
Validation loss: 2.18315456310908

Epoch: 6| Step: 10
Training loss: 2.0803205966949463
Validation loss: 2.1904584566752114

Epoch: 6| Step: 11
Training loss: 1.5144081115722656
Validation loss: 2.2029951016108194

Epoch: 6| Step: 12
Training loss: 1.742978811264038
Validation loss: 2.2284072836240134

Epoch: 6| Step: 13
Training loss: 1.902907133102417
Validation loss: 2.261647621790568

Epoch: 280| Step: 0
Training loss: 1.7794508934020996
Validation loss: 2.281245847543081

Epoch: 6| Step: 1
Training loss: 1.4640555381774902
Validation loss: 2.2469552755355835

Epoch: 6| Step: 2
Training loss: 2.0959720611572266
Validation loss: 2.265519122282664

Epoch: 6| Step: 3
Training loss: 1.5798794031143188
Validation loss: 2.254956841468811

Epoch: 6| Step: 4
Training loss: 1.6764793395996094
Validation loss: 2.231455902258555

Epoch: 6| Step: 5
Training loss: 1.4119551181793213
Validation loss: 2.217866043249766

Epoch: 6| Step: 6
Training loss: 1.3861494064331055
Validation loss: 2.228383938471476

Epoch: 6| Step: 7
Training loss: 1.6741124391555786
Validation loss: 2.2145034869511924

Epoch: 6| Step: 8
Training loss: 2.151327610015869
Validation loss: 2.2093498905499778

Epoch: 6| Step: 9
Training loss: 1.0852251052856445
Validation loss: 2.206371307373047

Epoch: 6| Step: 10
Training loss: 1.1537138223648071
Validation loss: 2.211203694343567

Epoch: 6| Step: 11
Training loss: 1.3743398189544678
Validation loss: 2.1975197196006775

Epoch: 6| Step: 12
Training loss: 1.8215224742889404
Validation loss: 2.2289119561513266

Epoch: 6| Step: 13
Training loss: 1.5683023929595947
Validation loss: 2.2165768146514893

Epoch: 281| Step: 0
Training loss: 1.290680170059204
Validation loss: 2.2196035782496133

Epoch: 6| Step: 1
Training loss: 2.0165529251098633
Validation loss: 2.213366210460663

Epoch: 6| Step: 2
Training loss: 1.8116486072540283
Validation loss: 2.2308106819788613

Epoch: 6| Step: 3
Training loss: 0.9339972138404846
Validation loss: 2.238905211289724

Epoch: 6| Step: 4
Training loss: 1.3456157445907593
Validation loss: 2.2092747489611306

Epoch: 6| Step: 5
Training loss: 1.4785020351409912
Validation loss: 2.220526655515035

Epoch: 6| Step: 6
Training loss: 1.4427927732467651
Validation loss: 2.228700796763102

Epoch: 6| Step: 7
Training loss: 1.732381820678711
Validation loss: 2.2229859431584678

Epoch: 6| Step: 8
Training loss: 1.5128791332244873
Validation loss: 2.2028131087621055

Epoch: 6| Step: 9
Training loss: 1.6373331546783447
Validation loss: 2.1825329661369324

Epoch: 6| Step: 10
Training loss: 1.25212562084198
Validation loss: 2.1989510456720986

Epoch: 6| Step: 11
Training loss: 1.5093955993652344
Validation loss: 2.1932958364486694

Epoch: 6| Step: 12
Training loss: 1.9605071544647217
Validation loss: 2.18791929880778

Epoch: 6| Step: 13
Training loss: 1.93247652053833
Validation loss: 2.1890610257784524

Epoch: 282| Step: 0
Training loss: 1.5375251770019531
Validation loss: 2.174737016359965

Epoch: 6| Step: 1
Training loss: 1.8257739543914795
Validation loss: 2.166452685991923

Epoch: 6| Step: 2
Training loss: 1.6211962699890137
Validation loss: 2.1809229453404746

Epoch: 6| Step: 3
Training loss: 1.8363630771636963
Validation loss: 2.1894651850064597

Epoch: 6| Step: 4
Training loss: 1.1261471509933472
Validation loss: 2.194365163644155

Epoch: 6| Step: 5
Training loss: 1.4432188272476196
Validation loss: 2.199568053086599

Epoch: 6| Step: 6
Training loss: 1.7025401592254639
Validation loss: 2.200135668118795

Epoch: 6| Step: 7
Training loss: 1.853132724761963
Validation loss: 2.1875661611557007

Epoch: 6| Step: 8
Training loss: 1.9411135911941528
Validation loss: 2.2173181772232056

Epoch: 6| Step: 9
Training loss: 1.7976319789886475
Validation loss: 2.2045605580012

Epoch: 6| Step: 10
Training loss: 1.7026939392089844
Validation loss: 2.1989691058794656

Epoch: 6| Step: 11
Training loss: 2.2128660678863525
Validation loss: 2.20065309604009

Epoch: 6| Step: 12
Training loss: 1.1443488597869873
Validation loss: 2.206547737121582

Epoch: 6| Step: 13
Training loss: 0.9874550104141235
Validation loss: 2.2025625308354697

Epoch: 283| Step: 0
Training loss: 0.9378855228424072
Validation loss: 2.2099377512931824

Epoch: 6| Step: 1
Training loss: 1.15127432346344
Validation loss: 2.193486193815867

Epoch: 6| Step: 2
Training loss: 1.350705623626709
Validation loss: 2.1965200304985046

Epoch: 6| Step: 3
Training loss: 1.7907065153121948
Validation loss: 2.1914509932200112

Epoch: 6| Step: 4
Training loss: 1.8815536499023438
Validation loss: 2.2286675175031028

Epoch: 6| Step: 5
Training loss: 1.3789770603179932
Validation loss: 2.230583429336548

Epoch: 6| Step: 6
Training loss: 2.4908790588378906
Validation loss: 2.220164875189463

Epoch: 6| Step: 7
Training loss: 2.029376745223999
Validation loss: 2.2100473046302795

Epoch: 6| Step: 8
Training loss: 1.2090721130371094
Validation loss: 2.239240825176239

Epoch: 6| Step: 9
Training loss: 1.4061509370803833
Validation loss: 2.2074473102887473

Epoch: 6| Step: 10
Training loss: 0.9067033529281616
Validation loss: 2.22491588195165

Epoch: 6| Step: 11
Training loss: 1.874290943145752
Validation loss: 2.2214413483937583

Epoch: 6| Step: 12
Training loss: 1.7446396350860596
Validation loss: 2.2244085470835366

Epoch: 6| Step: 13
Training loss: 1.5381414890289307
Validation loss: 2.2010386188824973

Epoch: 284| Step: 0
Training loss: 1.876524806022644
Validation loss: 2.226382295290629

Epoch: 6| Step: 1
Training loss: 1.1361134052276611
Validation loss: 2.1937424341837564

Epoch: 6| Step: 2
Training loss: 1.6622602939605713
Validation loss: 2.1985637744267783

Epoch: 6| Step: 3
Training loss: 1.8045151233673096
Validation loss: 2.210094432036082

Epoch: 6| Step: 4
Training loss: 1.6347742080688477
Validation loss: 2.2147777875264487

Epoch: 6| Step: 5
Training loss: 1.8810285329818726
Validation loss: 2.214518666267395

Epoch: 6| Step: 6
Training loss: 1.5916098356246948
Validation loss: 2.1967967748641968

Epoch: 6| Step: 7
Training loss: 1.3475691080093384
Validation loss: 2.2280128399531045

Epoch: 6| Step: 8
Training loss: 1.9393068552017212
Validation loss: 2.228585143884023

Epoch: 6| Step: 9
Training loss: 1.079755187034607
Validation loss: 2.226877192656199

Epoch: 6| Step: 10
Training loss: 1.7440065145492554
Validation loss: 2.265095909436544

Epoch: 6| Step: 11
Training loss: 1.3753116130828857
Validation loss: 2.2252175410588584

Epoch: 6| Step: 12
Training loss: 1.632826566696167
Validation loss: 2.2414921124776206

Epoch: 6| Step: 13
Training loss: 0.9552169442176819
Validation loss: 2.249480346838633

Epoch: 285| Step: 0
Training loss: 1.6075959205627441
Validation loss: 2.2577877839406333

Epoch: 6| Step: 1
Training loss: 1.9628992080688477
Validation loss: 2.248469909032186

Epoch: 6| Step: 2
Training loss: 1.7475939989089966
Validation loss: 2.2547589937845864

Epoch: 6| Step: 3
Training loss: 0.864213764667511
Validation loss: 2.249027212460836

Epoch: 6| Step: 4
Training loss: 1.6218980550765991
Validation loss: 2.2659258445103965

Epoch: 6| Step: 5
Training loss: 1.5996602773666382
Validation loss: 2.244560877482096

Epoch: 6| Step: 6
Training loss: 0.8044235706329346
Validation loss: 2.2330867449442544

Epoch: 6| Step: 7
Training loss: 1.448107123374939
Validation loss: 2.2307551304499307

Epoch: 6| Step: 8
Training loss: 1.6113080978393555
Validation loss: 2.23678457736969

Epoch: 6| Step: 9
Training loss: 1.4132802486419678
Validation loss: 2.2466540733973184

Epoch: 6| Step: 10
Training loss: 1.8722331523895264
Validation loss: 2.248153785864512

Epoch: 6| Step: 11
Training loss: 1.02760648727417
Validation loss: 2.224267363548279

Epoch: 6| Step: 12
Training loss: 2.1478915214538574
Validation loss: 2.232435683409373

Epoch: 6| Step: 13
Training loss: 2.1227335929870605
Validation loss: 2.233001967271169

Epoch: 286| Step: 0
Training loss: 1.5695135593414307
Validation loss: 2.2294191320737204

Epoch: 6| Step: 1
Training loss: 2.0149950981140137
Validation loss: 2.224032719930013

Epoch: 6| Step: 2
Training loss: 1.646756887435913
Validation loss: 2.2106881141662598

Epoch: 6| Step: 3
Training loss: 1.1870604753494263
Validation loss: 2.21715247631073

Epoch: 6| Step: 4
Training loss: 0.702390193939209
Validation loss: 2.2062556743621826

Epoch: 6| Step: 5
Training loss: 2.0399115085601807
Validation loss: 2.183924674987793

Epoch: 6| Step: 6
Training loss: 1.3262619972229004
Validation loss: 2.1698118249575296

Epoch: 6| Step: 7
Training loss: 1.0306248664855957
Validation loss: 2.1753544012705484

Epoch: 6| Step: 8
Training loss: 1.7834795713424683
Validation loss: 2.207251270612081

Epoch: 6| Step: 9
Training loss: 1.3996046781539917
Validation loss: 2.167380233605703

Epoch: 6| Step: 10
Training loss: 2.111477851867676
Validation loss: 2.1860339045524597

Epoch: 6| Step: 11
Training loss: 1.8253827095031738
Validation loss: 2.167716105779012

Epoch: 6| Step: 12
Training loss: 1.7633556127548218
Validation loss: 2.170670449733734

Epoch: 6| Step: 13
Training loss: 1.8540546894073486
Validation loss: 2.19882599512736

Epoch: 287| Step: 0
Training loss: 1.7988476753234863
Validation loss: 2.165312667687734

Epoch: 6| Step: 1
Training loss: 1.519592046737671
Validation loss: 2.184789220492045

Epoch: 6| Step: 2
Training loss: 0.9653545022010803
Validation loss: 2.1656885544459024

Epoch: 6| Step: 3
Training loss: 1.3644182682037354
Validation loss: 2.1328887939453125

Epoch: 6| Step: 4
Training loss: 1.5104243755340576
Validation loss: 2.154938797156016

Epoch: 6| Step: 5
Training loss: 1.2020992040634155
Validation loss: 2.1756927967071533

Epoch: 6| Step: 6
Training loss: 1.610396385192871
Validation loss: 2.189351518948873

Epoch: 6| Step: 7
Training loss: 1.7287465333938599
Validation loss: 2.151702086130778

Epoch: 6| Step: 8
Training loss: 1.8387491703033447
Validation loss: 2.1514341235160828

Epoch: 6| Step: 9
Training loss: 1.197948694229126
Validation loss: 2.1808647314707437

Epoch: 6| Step: 10
Training loss: 1.8949166536331177
Validation loss: 2.1357689102490744

Epoch: 6| Step: 11
Training loss: 1.627901315689087
Validation loss: 2.1332842111587524

Epoch: 6| Step: 12
Training loss: 2.294098377227783
Validation loss: 2.1550709009170532

Epoch: 6| Step: 13
Training loss: 1.471971035003662
Validation loss: 2.166539192199707

Epoch: 288| Step: 0
Training loss: 1.4208030700683594
Validation loss: 2.15388552347819

Epoch: 6| Step: 1
Training loss: 2.154261827468872
Validation loss: 2.1586912473042807

Epoch: 6| Step: 2
Training loss: 1.1339349746704102
Validation loss: 2.16741943359375

Epoch: 6| Step: 3
Training loss: 1.652130365371704
Validation loss: 2.175628145535787

Epoch: 6| Step: 4
Training loss: 1.5845634937286377
Validation loss: 2.1563753883043923

Epoch: 6| Step: 5
Training loss: 1.8400611877441406
Validation loss: 2.1727088689804077

Epoch: 6| Step: 6
Training loss: 1.6067116260528564
Validation loss: 2.1821483771006265

Epoch: 6| Step: 7
Training loss: 1.823169469833374
Validation loss: 2.1997966965039573

Epoch: 6| Step: 8
Training loss: 1.943129539489746
Validation loss: 2.1768736243247986

Epoch: 6| Step: 9
Training loss: 1.131690502166748
Validation loss: 2.178998867670695

Epoch: 6| Step: 10
Training loss: 1.3653146028518677
Validation loss: 2.1838645140329995

Epoch: 6| Step: 11
Training loss: 1.3271124362945557
Validation loss: 2.205762028694153

Epoch: 6| Step: 12
Training loss: 1.546034812927246
Validation loss: 2.1655245224634805

Epoch: 6| Step: 13
Training loss: 1.2098002433776855
Validation loss: 2.210438370704651

Epoch: 289| Step: 0
Training loss: 1.263114333152771
Validation loss: 2.2229519287745156

Epoch: 6| Step: 1
Training loss: 1.5746080875396729
Validation loss: 2.1910818616549173

Epoch: 6| Step: 2
Training loss: 1.076141595840454
Validation loss: 2.199321707089742

Epoch: 6| Step: 3
Training loss: 2.762697219848633
Validation loss: 2.2150069077809653

Epoch: 6| Step: 4
Training loss: 1.1131439208984375
Validation loss: 2.1932676235834756

Epoch: 6| Step: 5
Training loss: 1.7759122848510742
Validation loss: 2.2064247528711953

Epoch: 6| Step: 6
Training loss: 1.2579941749572754
Validation loss: 2.2017621199289956

Epoch: 6| Step: 7
Training loss: 1.1927614212036133
Validation loss: 2.2122521003087363

Epoch: 6| Step: 8
Training loss: 2.2511086463928223
Validation loss: 2.2137205402056375

Epoch: 6| Step: 9
Training loss: 1.0786750316619873
Validation loss: 2.193729122479757

Epoch: 6| Step: 10
Training loss: 0.9231607913970947
Validation loss: 2.218442360560099

Epoch: 6| Step: 11
Training loss: 1.2035635709762573
Validation loss: 2.1959213813145957

Epoch: 6| Step: 12
Training loss: 1.865687608718872
Validation loss: 2.2366557518641152

Epoch: 6| Step: 13
Training loss: 1.9248806238174438
Validation loss: 2.238975783189138

Epoch: 290| Step: 0
Training loss: 1.6229050159454346
Validation loss: 2.246906320254008

Epoch: 6| Step: 1
Training loss: 1.7745083570480347
Validation loss: 2.2114574313163757

Epoch: 6| Step: 2
Training loss: 1.6619017124176025
Validation loss: 2.2382165789604187

Epoch: 6| Step: 3
Training loss: 1.3176605701446533
Validation loss: 2.2089718182881675

Epoch: 6| Step: 4
Training loss: 1.0213277339935303
Validation loss: 2.217870533466339

Epoch: 6| Step: 5
Training loss: 2.3208236694335938
Validation loss: 2.181057870388031

Epoch: 6| Step: 6
Training loss: 2.6603803634643555
Validation loss: 2.199044942855835

Epoch: 6| Step: 7
Training loss: 2.0129854679107666
Validation loss: 2.2116312781969705

Epoch: 6| Step: 8
Training loss: 1.2154160737991333
Validation loss: 2.21640153725942

Epoch: 6| Step: 9
Training loss: 1.6215102672576904
Validation loss: 2.2092541456222534

Epoch: 6| Step: 10
Training loss: 1.3350608348846436
Validation loss: 2.2166322668393454

Epoch: 6| Step: 11
Training loss: 1.2865662574768066
Validation loss: 2.2066641449928284

Epoch: 6| Step: 12
Training loss: 0.8686539530754089
Validation loss: 2.245048681894938

Epoch: 6| Step: 13
Training loss: 1.6712610721588135
Validation loss: 2.2114959359169006

Epoch: 291| Step: 0
Training loss: 1.7463150024414062
Validation loss: 2.233438491821289

Epoch: 6| Step: 1
Training loss: 1.4904885292053223
Validation loss: 2.2211984197298684

Epoch: 6| Step: 2
Training loss: 1.2020514011383057
Validation loss: 2.2197872400283813

Epoch: 6| Step: 3
Training loss: 1.341352939605713
Validation loss: 2.2295562823613486

Epoch: 6| Step: 4
Training loss: 1.0812547206878662
Validation loss: 2.213536540667216

Epoch: 6| Step: 5
Training loss: 1.5304651260375977
Validation loss: 2.230016271273295

Epoch: 6| Step: 6
Training loss: 1.735825777053833
Validation loss: 2.19878621896108

Epoch: 6| Step: 7
Training loss: 1.638431429862976
Validation loss: 2.1820579767227173

Epoch: 6| Step: 8
Training loss: 2.091421604156494
Validation loss: 2.1599987546602883

Epoch: 6| Step: 9
Training loss: 1.2485190629959106
Validation loss: 2.16347869237264

Epoch: 6| Step: 10
Training loss: 1.5046840906143188
Validation loss: 2.175046702226003

Epoch: 6| Step: 11
Training loss: 1.2240052223205566
Validation loss: 2.1611366669336953

Epoch: 6| Step: 12
Training loss: 1.6823464632034302
Validation loss: 2.1780975659688315

Epoch: 6| Step: 13
Training loss: 2.3801724910736084
Validation loss: 2.174308637777964

Epoch: 292| Step: 0
Training loss: 1.8277480602264404
Validation loss: 2.1977084477742515

Epoch: 6| Step: 1
Training loss: 1.7020421028137207
Validation loss: 2.200869143009186

Epoch: 6| Step: 2
Training loss: 1.1598261594772339
Validation loss: 2.1764556566874185

Epoch: 6| Step: 3
Training loss: 1.672046422958374
Validation loss: 2.2245115637779236

Epoch: 6| Step: 4
Training loss: 1.4627711772918701
Validation loss: 2.215775946776072

Epoch: 6| Step: 5
Training loss: 1.487037181854248
Validation loss: 2.1763461430867515

Epoch: 6| Step: 6
Training loss: 1.549892544746399
Validation loss: 2.246718148390452

Epoch: 6| Step: 7
Training loss: 1.5645599365234375
Validation loss: 2.2079883416493735

Epoch: 6| Step: 8
Training loss: 1.5775773525238037
Validation loss: 2.260166863600413

Epoch: 6| Step: 9
Training loss: 1.5286736488342285
Validation loss: 2.2306309739748635

Epoch: 6| Step: 10
Training loss: 1.7702275514602661
Validation loss: 2.1937357981999717

Epoch: 6| Step: 11
Training loss: 1.0673285722732544
Validation loss: 2.2015278736750283

Epoch: 6| Step: 12
Training loss: 1.4895066022872925
Validation loss: 2.2060109972953796

Epoch: 6| Step: 13
Training loss: 1.77773118019104
Validation loss: 2.189642330010732

Epoch: 293| Step: 0
Training loss: 1.179945707321167
Validation loss: 2.1918166081110635

Epoch: 6| Step: 1
Training loss: 2.0391905307769775
Validation loss: 2.208292841911316

Epoch: 6| Step: 2
Training loss: 2.1235671043395996
Validation loss: 2.2046314080556235

Epoch: 6| Step: 3
Training loss: 1.1754891872406006
Validation loss: 2.204751114050547

Epoch: 6| Step: 4
Training loss: 1.686177134513855
Validation loss: 2.229247291882833

Epoch: 6| Step: 5
Training loss: 1.4920259714126587
Validation loss: 2.2254016200701394

Epoch: 6| Step: 6
Training loss: 1.6392550468444824
Validation loss: 2.2178830901781716

Epoch: 6| Step: 7
Training loss: 1.7925550937652588
Validation loss: 2.200232287247976

Epoch: 6| Step: 8
Training loss: 1.382369041442871
Validation loss: 2.234894315401713

Epoch: 6| Step: 9
Training loss: 1.3664993047714233
Validation loss: 2.2316588163375854

Epoch: 6| Step: 10
Training loss: 1.334030032157898
Validation loss: 2.211037755012512

Epoch: 6| Step: 11
Training loss: 1.6053544282913208
Validation loss: 2.2090737422307334

Epoch: 6| Step: 12
Training loss: 1.1060359477996826
Validation loss: 2.2058045466740928

Epoch: 6| Step: 13
Training loss: 1.3265800476074219
Validation loss: 2.2298463185628257

Epoch: 294| Step: 0
Training loss: 0.9529358744621277
Validation loss: 2.2234732111295066

Epoch: 6| Step: 1
Training loss: 1.4956779479980469
Validation loss: 2.23226261138916

Epoch: 6| Step: 2
Training loss: 1.1061468124389648
Validation loss: 2.2613684137662253

Epoch: 6| Step: 3
Training loss: 1.415027141571045
Validation loss: 2.211915651957194

Epoch: 6| Step: 4
Training loss: 0.8801717758178711
Validation loss: 2.2258509397506714

Epoch: 6| Step: 5
Training loss: 2.0141098499298096
Validation loss: 2.236595332622528

Epoch: 6| Step: 6
Training loss: 1.0540475845336914
Validation loss: 2.2351327538490295

Epoch: 6| Step: 7
Training loss: 1.8414621353149414
Validation loss: 2.2141436338424683

Epoch: 6| Step: 8
Training loss: 1.4851758480072021
Validation loss: 2.240238825480143

Epoch: 6| Step: 9
Training loss: 2.2074127197265625
Validation loss: 2.201669613520304

Epoch: 6| Step: 10
Training loss: 1.4596469402313232
Validation loss: 2.23049267133077

Epoch: 6| Step: 11
Training loss: 1.4186068773269653
Validation loss: 2.2118323047955832

Epoch: 6| Step: 12
Training loss: 1.809084415435791
Validation loss: 2.2004543344179788

Epoch: 6| Step: 13
Training loss: 1.5910875797271729
Validation loss: 2.2009428342183432

Epoch: 295| Step: 0
Training loss: 1.7042157649993896
Validation loss: 2.20477561155955

Epoch: 6| Step: 1
Training loss: 1.3496229648590088
Validation loss: 2.206166764100393

Epoch: 6| Step: 2
Training loss: 0.7950910329818726
Validation loss: 2.1800676186879477

Epoch: 6| Step: 3
Training loss: 0.9571094512939453
Validation loss: 2.197381873925527

Epoch: 6| Step: 4
Training loss: 1.7921466827392578
Validation loss: 2.188730259736379

Epoch: 6| Step: 5
Training loss: 1.1964690685272217
Validation loss: 2.195439338684082

Epoch: 6| Step: 6
Training loss: 1.903127908706665
Validation loss: 2.2161638935407004

Epoch: 6| Step: 7
Training loss: 1.4400160312652588
Validation loss: 2.2006322145462036

Epoch: 6| Step: 8
Training loss: 2.0268590450286865
Validation loss: 2.173490325609843

Epoch: 6| Step: 9
Training loss: 1.6074432134628296
Validation loss: 2.187004248301188

Epoch: 6| Step: 10
Training loss: 1.4801663160324097
Validation loss: 2.211349606513977

Epoch: 6| Step: 11
Training loss: 1.008700966835022
Validation loss: 2.1935315132141113

Epoch: 6| Step: 12
Training loss: 2.0076112747192383
Validation loss: 2.1986512343088784

Epoch: 6| Step: 13
Training loss: 1.4838762283325195
Validation loss: 2.2076825499534607

Epoch: 296| Step: 0
Training loss: 2.597583532333374
Validation loss: 2.2013197541236877

Epoch: 6| Step: 1
Training loss: 2.1650094985961914
Validation loss: 2.196367700894674

Epoch: 6| Step: 2
Training loss: 1.0458310842514038
Validation loss: 2.1705013314882913

Epoch: 6| Step: 3
Training loss: 1.659400224685669
Validation loss: 2.1837143500645957

Epoch: 6| Step: 4
Training loss: 1.275895118713379
Validation loss: 2.2199872732162476

Epoch: 6| Step: 5
Training loss: 1.415177822113037
Validation loss: 2.1973097721735635

Epoch: 6| Step: 6
Training loss: 1.8734941482543945
Validation loss: 2.1880513032277427

Epoch: 6| Step: 7
Training loss: 1.2147457599639893
Validation loss: 2.1901249090830484

Epoch: 6| Step: 8
Training loss: 0.7716690897941589
Validation loss: 2.1756885051727295

Epoch: 6| Step: 9
Training loss: 1.9675769805908203
Validation loss: 2.1878970861434937

Epoch: 6| Step: 10
Training loss: 1.5181572437286377
Validation loss: 2.197730620702108

Epoch: 6| Step: 11
Training loss: 1.2065176963806152
Validation loss: 2.195839742819468

Epoch: 6| Step: 12
Training loss: 0.9013798236846924
Validation loss: 2.224583148956299

Epoch: 6| Step: 13
Training loss: 1.4017987251281738
Validation loss: 2.1988630096117654

Epoch: 297| Step: 0
Training loss: 1.7869179248809814
Validation loss: 2.2113985617955527

Epoch: 6| Step: 1
Training loss: 1.3806507587432861
Validation loss: 2.1797444820404053

Epoch: 6| Step: 2
Training loss: 1.491346836090088
Validation loss: 2.1864411433537803

Epoch: 6| Step: 3
Training loss: 1.4314414262771606
Validation loss: 2.1879846652348838

Epoch: 6| Step: 4
Training loss: 2.401682138442993
Validation loss: 2.1789029637972512

Epoch: 6| Step: 5
Training loss: 1.8128938674926758
Validation loss: 2.1891740957895913

Epoch: 6| Step: 6
Training loss: 1.5788428783416748
Validation loss: 2.1806920568148294

Epoch: 6| Step: 7
Training loss: 1.54536771774292
Validation loss: 2.1976243058840432

Epoch: 6| Step: 8
Training loss: 1.2137764692306519
Validation loss: 2.1876614491144815

Epoch: 6| Step: 9
Training loss: 1.1397228240966797
Validation loss: 2.1915215651194253

Epoch: 6| Step: 10
Training loss: 1.7033623456954956
Validation loss: 2.168650488058726

Epoch: 6| Step: 11
Training loss: 1.2465794086456299
Validation loss: 2.191409170627594

Epoch: 6| Step: 12
Training loss: 1.379927396774292
Validation loss: 2.1954356034596763

Epoch: 6| Step: 13
Training loss: 1.3039125204086304
Validation loss: 2.1634819308916726

Epoch: 298| Step: 0
Training loss: 1.1621448993682861
Validation loss: 2.1845581928888955

Epoch: 6| Step: 1
Training loss: 1.649144172668457
Validation loss: 2.2012025316556296

Epoch: 6| Step: 2
Training loss: 1.6212043762207031
Validation loss: 2.2040549516677856

Epoch: 6| Step: 3
Training loss: 1.580887794494629
Validation loss: 2.1986494263013205

Epoch: 6| Step: 4
Training loss: 1.2857470512390137
Validation loss: 2.225579837958018

Epoch: 6| Step: 5
Training loss: 1.322279691696167
Validation loss: 2.241204301516215

Epoch: 6| Step: 6
Training loss: 2.1977598667144775
Validation loss: 2.223814149697622

Epoch: 6| Step: 7
Training loss: 0.8032873868942261
Validation loss: 2.211160957813263

Epoch: 6| Step: 8
Training loss: 1.2911877632141113
Validation loss: 2.2246592044830322

Epoch: 6| Step: 9
Training loss: 1.9335873126983643
Validation loss: 2.224006175994873

Epoch: 6| Step: 10
Training loss: 1.1994158029556274
Validation loss: 2.183725575606028

Epoch: 6| Step: 11
Training loss: 1.4688135385513306
Validation loss: 2.2069743076960244

Epoch: 6| Step: 12
Training loss: 1.8352077007293701
Validation loss: 2.20313161611557

Epoch: 6| Step: 13
Training loss: 1.1938755512237549
Validation loss: 2.208169182141622

Epoch: 299| Step: 0
Training loss: 1.934426188468933
Validation loss: 2.19707053899765

Epoch: 6| Step: 1
Training loss: 1.3618943691253662
Validation loss: 2.194883147875468

Epoch: 6| Step: 2
Training loss: 1.5508792400360107
Validation loss: 2.2166303396224976

Epoch: 6| Step: 3
Training loss: 1.6771354675292969
Validation loss: 2.201320707798004

Epoch: 6| Step: 4
Training loss: 1.8622372150421143
Validation loss: 2.199166417121887

Epoch: 6| Step: 5
Training loss: 2.153276205062866
Validation loss: 2.2128638426462808

Epoch: 6| Step: 6
Training loss: 0.8908014893531799
Validation loss: 2.2042102416356406

Epoch: 6| Step: 7
Training loss: 1.1388030052185059
Validation loss: 2.2506277561187744

Epoch: 6| Step: 8
Training loss: 1.5401616096496582
Validation loss: 2.2117664217948914

Epoch: 6| Step: 9
Training loss: 1.1058293581008911
Validation loss: 2.192238370577494

Epoch: 6| Step: 10
Training loss: 1.9310568571090698
Validation loss: 2.226609210173289

Epoch: 6| Step: 11
Training loss: 1.2390811443328857
Validation loss: 2.2172521352767944

Epoch: 6| Step: 12
Training loss: 1.3655478954315186
Validation loss: 2.217930475870768

Epoch: 6| Step: 13
Training loss: 0.8705238699913025
Validation loss: 2.2163010835647583

Epoch: 300| Step: 0
Training loss: 2.139356851577759
Validation loss: 2.1915711959203086

Epoch: 6| Step: 1
Training loss: 1.3623040914535522
Validation loss: 2.1885661284128823

Epoch: 6| Step: 2
Training loss: 1.635513186454773
Validation loss: 2.197299897670746

Epoch: 6| Step: 3
Training loss: 1.3027054071426392
Validation loss: 2.182965556780497

Epoch: 6| Step: 4
Training loss: 1.6567447185516357
Validation loss: 2.191473682721456

Epoch: 6| Step: 5
Training loss: 1.7525267601013184
Validation loss: 2.1912909547487893

Epoch: 6| Step: 6
Training loss: 1.1015280485153198
Validation loss: 2.181249459584554

Epoch: 6| Step: 7
Training loss: 1.1344010829925537
Validation loss: 2.1929543018341064

Epoch: 6| Step: 8
Training loss: 1.5969175100326538
Validation loss: 2.182568609714508

Epoch: 6| Step: 9
Training loss: 0.9611101746559143
Validation loss: 2.2084121902783713

Epoch: 6| Step: 10
Training loss: 1.1079325675964355
Validation loss: 2.2027032574017844

Epoch: 6| Step: 11
Training loss: 2.073071002960205
Validation loss: 2.1941508849461875

Epoch: 6| Step: 12
Training loss: 1.8795151710510254
Validation loss: 2.2073335448900857

Epoch: 6| Step: 13
Training loss: 0.9324641227722168
Validation loss: 2.1871155500411987

Testing loss: 2.017034746760087
