Epoch: 1| Step: 0
Training loss: 6.233792304992676
Validation loss: 5.270252068837483

Epoch: 5| Step: 1
Training loss: 4.991841793060303
Validation loss: 5.268012642860413

Epoch: 5| Step: 2
Training loss: 4.17989444732666
Validation loss: 5.265929996967316

Epoch: 5| Step: 3
Training loss: 5.042893409729004
Validation loss: 5.264085868994395

Epoch: 5| Step: 4
Training loss: 5.485962867736816
Validation loss: 5.262295325597127

Epoch: 5| Step: 5
Training loss: 5.583856105804443
Validation loss: 5.260705471038818

Epoch: 5| Step: 6
Training loss: 5.443041801452637
Validation loss: 5.259052336215973

Epoch: 5| Step: 7
Training loss: 5.305689334869385
Validation loss: 5.257439037164052

Epoch: 5| Step: 8
Training loss: 5.259495258331299
Validation loss: 5.255902727444966

Epoch: 5| Step: 9
Training loss: 5.3377180099487305
Validation loss: 5.254306634267171

Epoch: 5| Step: 10
Training loss: 6.1567559242248535
Validation loss: 5.2526864012082415

Epoch: 5| Step: 11
Training loss: 3.389350414276123
Validation loss: 5.250983715057373

Epoch: 2| Step: 0
Training loss: 4.798085689544678
Validation loss: 5.249231855074565

Epoch: 5| Step: 1
Training loss: 5.850109100341797
Validation loss: 5.247479697068532

Epoch: 5| Step: 2
Training loss: 5.249319553375244
Validation loss: 5.245606084664662

Epoch: 5| Step: 3
Training loss: 6.267016410827637
Validation loss: 5.243695934613545

Epoch: 5| Step: 4
Training loss: 6.263223648071289
Validation loss: 5.241723358631134

Epoch: 5| Step: 5
Training loss: 5.254206657409668
Validation loss: 5.2395934065183

Epoch: 5| Step: 6
Training loss: 5.141151428222656
Validation loss: 5.237468222777049

Epoch: 5| Step: 7
Training loss: 4.204007148742676
Validation loss: 5.235127508640289

Epoch: 5| Step: 8
Training loss: 4.837992191314697
Validation loss: 5.232838273048401

Epoch: 5| Step: 9
Training loss: 5.063083171844482
Validation loss: 5.23038633664449

Epoch: 5| Step: 10
Training loss: 6.168726444244385
Validation loss: 5.227704226970673

Epoch: 5| Step: 11
Training loss: 1.8135242462158203
Validation loss: 5.225133279959361

Epoch: 3| Step: 0
Training loss: 5.936453819274902
Validation loss: 5.22241473197937

Epoch: 5| Step: 1
Training loss: 5.267962455749512
Validation loss: 5.219639778137207

Epoch: 5| Step: 2
Training loss: 4.785031318664551
Validation loss: 5.2166643142700195

Epoch: 5| Step: 3
Training loss: 4.2959208488464355
Validation loss: 5.213505069414775

Epoch: 5| Step: 4
Training loss: 5.6042070388793945
Validation loss: 5.210187951723735

Epoch: 5| Step: 5
Training loss: 4.438226222991943
Validation loss: 5.206648012002309

Epoch: 5| Step: 6
Training loss: 5.183158874511719
Validation loss: 5.203029195467631

Epoch: 5| Step: 7
Training loss: 5.988211154937744
Validation loss: 5.199054479598999

Epoch: 5| Step: 8
Training loss: 5.738099098205566
Validation loss: 5.194962799549103

Epoch: 5| Step: 9
Training loss: 4.8900465965271
Validation loss: 5.190510908762614

Epoch: 5| Step: 10
Training loss: 5.8114399909973145
Validation loss: 5.185845792293549

Epoch: 5| Step: 11
Training loss: 5.736639976501465
Validation loss: 5.181039015452067

Epoch: 4| Step: 0
Training loss: 5.818704128265381
Validation loss: 5.1759185791015625

Epoch: 5| Step: 1
Training loss: 4.416565895080566
Validation loss: 5.170531292756398

Epoch: 5| Step: 2
Training loss: 6.00319766998291
Validation loss: 5.164985795815785

Epoch: 5| Step: 3
Training loss: 6.237006187438965
Validation loss: 5.158769249916077

Epoch: 5| Step: 4
Training loss: 5.366847991943359
Validation loss: 5.152540544668834

Epoch: 5| Step: 5
Training loss: 4.634762763977051
Validation loss: 5.146126369635264

Epoch: 5| Step: 6
Training loss: 5.294808864593506
Validation loss: 5.139302571614583

Epoch: 5| Step: 7
Training loss: 4.853777885437012
Validation loss: 5.132066984971364

Epoch: 5| Step: 8
Training loss: 5.200072288513184
Validation loss: 5.12463794151942

Epoch: 5| Step: 9
Training loss: 4.6169114112854
Validation loss: 5.117226978143056

Epoch: 5| Step: 10
Training loss: 5.275313377380371
Validation loss: 5.109106779098511

Epoch: 5| Step: 11
Training loss: 3.580379009246826
Validation loss: 5.101033488909404

Epoch: 5| Step: 0
Training loss: 5.791409492492676
Validation loss: 5.092444101969401

Epoch: 5| Step: 1
Training loss: 5.101541996002197
Validation loss: 5.083755234877269

Epoch: 5| Step: 2
Training loss: 4.225883960723877
Validation loss: 5.074783702691396

Epoch: 5| Step: 3
Training loss: 5.726187705993652
Validation loss: 5.06507682800293

Epoch: 5| Step: 4
Training loss: 6.090404033660889
Validation loss: 5.055618802706401

Epoch: 5| Step: 5
Training loss: 5.776669979095459
Validation loss: 5.045276423295339

Epoch: 5| Step: 6
Training loss: 5.341104507446289
Validation loss: 5.03492659330368

Epoch: 5| Step: 7
Training loss: 5.639636039733887
Validation loss: 5.024374256531398

Epoch: 5| Step: 8
Training loss: 4.464907169342041
Validation loss: 5.0130051374435425

Epoch: 5| Step: 9
Training loss: 4.590880393981934
Validation loss: 5.001658956209819

Epoch: 5| Step: 10
Training loss: 3.802281141281128
Validation loss: 4.989732801914215

Epoch: 5| Step: 11
Training loss: 3.970172882080078
Validation loss: 4.9778211911519366

Epoch: 6| Step: 0
Training loss: 5.288102149963379
Validation loss: 4.96594242254893

Epoch: 5| Step: 1
Training loss: 4.394730567932129
Validation loss: 4.953655779361725

Epoch: 5| Step: 2
Training loss: 5.3367018699646
Validation loss: 4.941481331984202

Epoch: 5| Step: 3
Training loss: 4.723148822784424
Validation loss: 4.928905745347341

Epoch: 5| Step: 4
Training loss: 5.209395408630371
Validation loss: 4.916617035865784

Epoch: 5| Step: 5
Training loss: 4.680269718170166
Validation loss: 4.904943426450093

Epoch: 5| Step: 6
Training loss: 5.39639949798584
Validation loss: 4.893377780914307

Epoch: 5| Step: 7
Training loss: 6.190842151641846
Validation loss: 4.88220598300298

Epoch: 5| Step: 8
Training loss: 4.723117828369141
Validation loss: 4.871141692002614

Epoch: 5| Step: 9
Training loss: 3.907622814178467
Validation loss: 4.86000919342041

Epoch: 5| Step: 10
Training loss: 5.015401363372803
Validation loss: 4.84951235850652

Epoch: 5| Step: 11
Training loss: 5.107884407043457
Validation loss: 4.839241762955983

Epoch: 7| Step: 0
Training loss: 5.136043548583984
Validation loss: 4.828995565573375

Epoch: 5| Step: 1
Training loss: 5.686174392700195
Validation loss: 4.819016714890798

Epoch: 5| Step: 2
Training loss: 5.270983695983887
Validation loss: 4.8091721932093305

Epoch: 5| Step: 3
Training loss: 4.7021589279174805
Validation loss: 4.799620985984802

Epoch: 5| Step: 4
Training loss: 4.062981605529785
Validation loss: 4.789967775344849

Epoch: 5| Step: 5
Training loss: 4.273210048675537
Validation loss: 4.78057877222697

Epoch: 5| Step: 6
Training loss: 4.778824329376221
Validation loss: 4.771110415458679

Epoch: 5| Step: 7
Training loss: 5.124083518981934
Validation loss: 4.761997143427531

Epoch: 5| Step: 8
Training loss: 4.263636589050293
Validation loss: 4.752876242001851

Epoch: 5| Step: 9
Training loss: 4.728119850158691
Validation loss: 4.743336498737335

Epoch: 5| Step: 10
Training loss: 5.166937828063965
Validation loss: 4.7344144980112715

Epoch: 5| Step: 11
Training loss: 6.778409004211426
Validation loss: 4.724757929642995

Epoch: 8| Step: 0
Training loss: 5.350887298583984
Validation loss: 4.715718477964401

Epoch: 5| Step: 1
Training loss: 4.127552032470703
Validation loss: 4.706649859746297

Epoch: 5| Step: 2
Training loss: 4.917777061462402
Validation loss: 4.697732488314311

Epoch: 5| Step: 3
Training loss: 4.318199157714844
Validation loss: 4.688741683959961

Epoch: 5| Step: 4
Training loss: 5.099452495574951
Validation loss: 4.680116653442383

Epoch: 5| Step: 5
Training loss: 4.822504997253418
Validation loss: 4.671087900797526

Epoch: 5| Step: 6
Training loss: 4.25719690322876
Validation loss: 4.6626571615537005

Epoch: 5| Step: 7
Training loss: 4.0567522048950195
Validation loss: 4.654488245646159

Epoch: 5| Step: 8
Training loss: 4.8540520668029785
Validation loss: 4.64650375644366

Epoch: 5| Step: 9
Training loss: 4.810187339782715
Validation loss: 4.638578871885936

Epoch: 5| Step: 10
Training loss: 5.912890434265137
Validation loss: 4.630910197893779

Epoch: 5| Step: 11
Training loss: 4.377093315124512
Validation loss: 4.623184611399968

Epoch: 9| Step: 0
Training loss: 5.588822841644287
Validation loss: 4.616077641646068

Epoch: 5| Step: 1
Training loss: 5.1274800300598145
Validation loss: 4.608471632003784

Epoch: 5| Step: 2
Training loss: 3.8765952587127686
Validation loss: 4.601618746916453

Epoch: 5| Step: 3
Training loss: 4.293746471405029
Validation loss: 4.594689716895421

Epoch: 5| Step: 4
Training loss: 4.701350212097168
Validation loss: 4.587616840998332

Epoch: 5| Step: 5
Training loss: 5.097872257232666
Validation loss: 4.581491490205129

Epoch: 5| Step: 6
Training loss: 4.047157287597656
Validation loss: 4.574814518292745

Epoch: 5| Step: 7
Training loss: 4.334486484527588
Validation loss: 4.568675309419632

Epoch: 5| Step: 8
Training loss: 5.160717487335205
Validation loss: 4.562384446461995

Epoch: 5| Step: 9
Training loss: 4.709738731384277
Validation loss: 4.556090881427129

Epoch: 5| Step: 10
Training loss: 4.641853332519531
Validation loss: 4.55002083381017

Epoch: 5| Step: 11
Training loss: 4.399879455566406
Validation loss: 4.543428381284078

Epoch: 10| Step: 0
Training loss: 3.5810036659240723
Validation loss: 4.537532607714335

Epoch: 5| Step: 1
Training loss: 4.248326301574707
Validation loss: 4.53137332201004

Epoch: 5| Step: 2
Training loss: 4.640103340148926
Validation loss: 4.525598883628845

Epoch: 5| Step: 3
Training loss: 4.660731315612793
Validation loss: 4.51894336938858

Epoch: 5| Step: 4
Training loss: 5.406774044036865
Validation loss: 4.51363076766332

Epoch: 5| Step: 5
Training loss: 4.271848678588867
Validation loss: 4.507077872753143

Epoch: 5| Step: 6
Training loss: 4.760631084442139
Validation loss: 4.5011079510053

Epoch: 5| Step: 7
Training loss: 3.828756809234619
Validation loss: 4.495060741901398

Epoch: 5| Step: 8
Training loss: 4.503261566162109
Validation loss: 4.488967329263687

Epoch: 5| Step: 9
Training loss: 5.766995429992676
Validation loss: 4.483010649681091

Epoch: 5| Step: 10
Training loss: 5.238160610198975
Validation loss: 4.476986885070801

Epoch: 5| Step: 11
Training loss: 3.749739170074463
Validation loss: 4.470976193745931

Epoch: 11| Step: 0
Training loss: 4.488694190979004
Validation loss: 4.465541919072469

Epoch: 5| Step: 1
Training loss: 4.691465854644775
Validation loss: 4.459278245766957

Epoch: 5| Step: 2
Training loss: 3.5714802742004395
Validation loss: 4.453793366750081

Epoch: 5| Step: 3
Training loss: 5.826444149017334
Validation loss: 4.447998960812886

Epoch: 5| Step: 4
Training loss: 4.383620262145996
Validation loss: 4.442528148492177

Epoch: 5| Step: 5
Training loss: 3.8953330516815186
Validation loss: 4.4366089304288225

Epoch: 5| Step: 6
Training loss: 4.143240928649902
Validation loss: 4.431665976842244

Epoch: 5| Step: 7
Training loss: 5.116351127624512
Validation loss: 4.425702313582103

Epoch: 5| Step: 8
Training loss: 5.297555446624756
Validation loss: 4.420450528462728

Epoch: 5| Step: 9
Training loss: 4.61345911026001
Validation loss: 4.414566844701767

Epoch: 5| Step: 10
Training loss: 3.840075969696045
Validation loss: 4.409545928239822

Epoch: 5| Step: 11
Training loss: 5.420823097229004
Validation loss: 4.404037495454152

Epoch: 12| Step: 0
Training loss: 4.29177713394165
Validation loss: 4.398727148771286

Epoch: 5| Step: 1
Training loss: 4.685589790344238
Validation loss: 4.393146981795629

Epoch: 5| Step: 2
Training loss: 5.309691429138184
Validation loss: 4.388024051984151

Epoch: 5| Step: 3
Training loss: 5.040266513824463
Validation loss: 4.382835119962692

Epoch: 5| Step: 4
Training loss: 3.6969711780548096
Validation loss: 4.377045571804047

Epoch: 5| Step: 5
Training loss: 4.487284183502197
Validation loss: 4.371814449628194

Epoch: 5| Step: 6
Training loss: 5.16730260848999
Validation loss: 4.36691000064214

Epoch: 5| Step: 7
Training loss: 4.4647040367126465
Validation loss: 4.361703157424927

Epoch: 5| Step: 8
Training loss: 3.881267547607422
Validation loss: 4.356210013230641

Epoch: 5| Step: 9
Training loss: 4.312549591064453
Validation loss: 4.350952327251434

Epoch: 5| Step: 10
Training loss: 4.355525016784668
Validation loss: 4.346004247665405

Epoch: 5| Step: 11
Training loss: 3.0532491207122803
Validation loss: 4.34080845117569

Epoch: 13| Step: 0
Training loss: 3.5464580059051514
Validation loss: 4.335843900839488

Epoch: 5| Step: 1
Training loss: 4.149763584136963
Validation loss: 4.331406424442927

Epoch: 5| Step: 2
Training loss: 4.807490348815918
Validation loss: 4.326654732227325

Epoch: 5| Step: 3
Training loss: 4.3447699546813965
Validation loss: 4.321795503298442

Epoch: 5| Step: 4
Training loss: 4.295430660247803
Validation loss: 4.316749652226766

Epoch: 5| Step: 5
Training loss: 4.878233909606934
Validation loss: 4.311979432900746

Epoch: 5| Step: 6
Training loss: 4.454957008361816
Validation loss: 4.306836634874344

Epoch: 5| Step: 7
Training loss: 5.167274475097656
Validation loss: 4.302112619082133

Epoch: 5| Step: 8
Training loss: 4.404057502746582
Validation loss: 4.296899209419887

Epoch: 5| Step: 9
Training loss: 4.310051918029785
Validation loss: 4.291461745897929

Epoch: 5| Step: 10
Training loss: 4.542395114898682
Validation loss: 4.286430885394414

Epoch: 5| Step: 11
Training loss: 3.828186511993408
Validation loss: 4.280909180641174

Epoch: 14| Step: 0
Training loss: 5.0991597175598145
Validation loss: 4.27583967645963

Epoch: 5| Step: 1
Training loss: 3.769055128097534
Validation loss: 4.270339508851369

Epoch: 5| Step: 2
Training loss: 4.435305118560791
Validation loss: 4.2644950449466705

Epoch: 5| Step: 3
Training loss: 4.277285099029541
Validation loss: 4.258871932824452

Epoch: 5| Step: 4
Training loss: 4.433888912200928
Validation loss: 4.2537588973840075

Epoch: 5| Step: 5
Training loss: 4.1976318359375
Validation loss: 4.248240013917287

Epoch: 5| Step: 6
Training loss: 4.960177898406982
Validation loss: 4.24247674147288

Epoch: 5| Step: 7
Training loss: 4.324090003967285
Validation loss: 4.236988504727681

Epoch: 5| Step: 8
Training loss: 3.6984450817108154
Validation loss: 4.231298824151357

Epoch: 5| Step: 9
Training loss: 4.751307010650635
Validation loss: 4.2256084481875105

Epoch: 5| Step: 10
Training loss: 4.009502410888672
Validation loss: 4.219763259092967

Epoch: 5| Step: 11
Training loss: 5.281196594238281
Validation loss: 4.213732858498891

Epoch: 15| Step: 0
Training loss: 4.752799034118652
Validation loss: 4.207432717084885

Epoch: 5| Step: 1
Training loss: 4.243157386779785
Validation loss: 4.201050450404485

Epoch: 5| Step: 2
Training loss: 4.417499542236328
Validation loss: 4.1950028638045

Epoch: 5| Step: 3
Training loss: 4.560103416442871
Validation loss: 4.188606421152751

Epoch: 5| Step: 4
Training loss: 4.848945617675781
Validation loss: 4.182956745227178

Epoch: 5| Step: 5
Training loss: 3.9368579387664795
Validation loss: 4.176267862319946

Epoch: 5| Step: 6
Training loss: 5.2004075050354
Validation loss: 4.170247554779053

Epoch: 5| Step: 7
Training loss: 3.597583770751953
Validation loss: 4.163683305184047

Epoch: 5| Step: 8
Training loss: 4.220118045806885
Validation loss: 4.157265265782674

Epoch: 5| Step: 9
Training loss: 4.295657157897949
Validation loss: 4.150920142730077

Epoch: 5| Step: 10
Training loss: 3.4222748279571533
Validation loss: 4.145482798417409

Epoch: 5| Step: 11
Training loss: 3.9769415855407715
Validation loss: 4.138537883758545

Epoch: 16| Step: 0
Training loss: 4.346919059753418
Validation loss: 4.132971664269765

Epoch: 5| Step: 1
Training loss: 4.291073322296143
Validation loss: 4.127230137586594

Epoch: 5| Step: 2
Training loss: 4.6567559242248535
Validation loss: 4.121178100506465

Epoch: 5| Step: 3
Training loss: 4.3096113204956055
Validation loss: 4.114849746227264

Epoch: 5| Step: 4
Training loss: 4.441555023193359
Validation loss: 4.108927418788274

Epoch: 5| Step: 5
Training loss: 4.295870780944824
Validation loss: 4.101826697587967

Epoch: 5| Step: 6
Training loss: 4.276834487915039
Validation loss: 4.095718612273534

Epoch: 5| Step: 7
Training loss: 4.659886360168457
Validation loss: 4.088839262723923

Epoch: 5| Step: 8
Training loss: 3.2757182121276855
Validation loss: 4.082302033901215

Epoch: 5| Step: 9
Training loss: 4.505855560302734
Validation loss: 4.076700021823247

Epoch: 5| Step: 10
Training loss: 3.314525604248047
Validation loss: 4.070796112219493

Epoch: 5| Step: 11
Training loss: 5.640837669372559
Validation loss: 4.064111282428105

Epoch: 17| Step: 0
Training loss: 3.5903046131134033
Validation loss: 4.058158814907074

Epoch: 5| Step: 1
Training loss: 3.67352032661438
Validation loss: 4.051721980174382

Epoch: 5| Step: 2
Training loss: 4.233054161071777
Validation loss: 4.0472234189510345

Epoch: 5| Step: 3
Training loss: 4.839444160461426
Validation loss: 4.040702432394028

Epoch: 5| Step: 4
Training loss: 4.657591819763184
Validation loss: 4.03318805495898

Epoch: 5| Step: 5
Training loss: 4.717123508453369
Validation loss: 4.027622242768605

Epoch: 5| Step: 6
Training loss: 3.680112361907959
Validation loss: 4.022210905949275

Epoch: 5| Step: 7
Training loss: 4.3483781814575195
Validation loss: 4.01660230755806

Epoch: 5| Step: 8
Training loss: 3.9158661365509033
Validation loss: 4.01051448782285

Epoch: 5| Step: 9
Training loss: 4.586552619934082
Validation loss: 4.003629714250565

Epoch: 5| Step: 10
Training loss: 4.126497268676758
Validation loss: 3.998733013868332

Epoch: 5| Step: 11
Training loss: 1.714911699295044
Validation loss: 3.9930533369382224

Epoch: 18| Step: 0
Training loss: 4.46720552444458
Validation loss: 3.9881960451602936

Epoch: 5| Step: 1
Training loss: 3.8284270763397217
Validation loss: 3.9818846384684243

Epoch: 5| Step: 2
Training loss: 3.4011168479919434
Validation loss: 3.9753535191218057

Epoch: 5| Step: 3
Training loss: 4.9321064949035645
Validation loss: 3.968758285045624

Epoch: 5| Step: 4
Training loss: 4.471604824066162
Validation loss: 3.9638390044371286

Epoch: 5| Step: 5
Training loss: 4.342909812927246
Validation loss: 3.957751681407293

Epoch: 5| Step: 6
Training loss: 3.9471118450164795
Validation loss: 3.9515055318673453

Epoch: 5| Step: 7
Training loss: 3.992875576019287
Validation loss: 3.9461366335550943

Epoch: 5| Step: 8
Training loss: 3.284055233001709
Validation loss: 3.9406571686267853

Epoch: 5| Step: 9
Training loss: 4.91877555847168
Validation loss: 3.9349671502908072

Epoch: 5| Step: 10
Training loss: 3.6440155506134033
Validation loss: 3.9289534290631614

Epoch: 5| Step: 11
Training loss: 3.573080539703369
Validation loss: 3.9227485954761505

Epoch: 19| Step: 0
Training loss: 4.121059417724609
Validation loss: 3.9166411558787027

Epoch: 5| Step: 1
Training loss: 3.867309093475342
Validation loss: 3.9104911585648856

Epoch: 5| Step: 2
Training loss: 4.8959760665893555
Validation loss: 3.9047032992045083

Epoch: 5| Step: 3
Training loss: 4.620813846588135
Validation loss: 3.898554712533951

Epoch: 5| Step: 4
Training loss: 3.8809962272644043
Validation loss: 3.8936158219973245

Epoch: 5| Step: 5
Training loss: 4.245789527893066
Validation loss: 3.8890588184197745

Epoch: 5| Step: 6
Training loss: 3.9002795219421387
Validation loss: 3.8812244137128196

Epoch: 5| Step: 7
Training loss: 3.9174644947052
Validation loss: 3.8763171633084617

Epoch: 5| Step: 8
Training loss: 3.9970641136169434
Validation loss: 3.871326059103012

Epoch: 5| Step: 9
Training loss: 3.3384852409362793
Validation loss: 3.8662070830663047

Epoch: 5| Step: 10
Training loss: 3.8860039710998535
Validation loss: 3.859538654486338

Epoch: 5| Step: 11
Training loss: 2.713594436645508
Validation loss: 3.8532550036907196

Epoch: 20| Step: 0
Training loss: 4.390167236328125
Validation loss: 3.847820738951365

Epoch: 5| Step: 1
Training loss: 4.079497337341309
Validation loss: 3.842061926921209

Epoch: 5| Step: 2
Training loss: 3.7312042713165283
Validation loss: 3.8369614581267038

Epoch: 5| Step: 3
Training loss: 4.137877941131592
Validation loss: 3.8310870230197906

Epoch: 5| Step: 4
Training loss: 3.4206442832946777
Validation loss: 3.825450668732325

Epoch: 5| Step: 5
Training loss: 4.827378749847412
Validation loss: 3.8202109038829803

Epoch: 5| Step: 6
Training loss: 4.335396766662598
Validation loss: 3.8144181172053018

Epoch: 5| Step: 7
Training loss: 3.5779201984405518
Validation loss: 3.8095801870028176

Epoch: 5| Step: 8
Training loss: 4.1058149337768555
Validation loss: 3.8042629063129425

Epoch: 5| Step: 9
Training loss: 3.965111494064331
Validation loss: 3.7990226447582245

Epoch: 5| Step: 10
Training loss: 3.402125120162964
Validation loss: 3.7944225569566092

Epoch: 5| Step: 11
Training loss: 2.708904504776001
Validation loss: 3.788927545150121

Epoch: 21| Step: 0
Training loss: 3.405971050262451
Validation loss: 3.799354483683904

Epoch: 5| Step: 1
Training loss: 3.990355968475342
Validation loss: 3.78115784128507

Epoch: 5| Step: 2
Training loss: 3.82147479057312
Validation loss: 3.774439970652262

Epoch: 5| Step: 3
Training loss: 4.750019073486328
Validation loss: 3.773257037003835

Epoch: 5| Step: 4
Training loss: 4.291282653808594
Validation loss: 3.769486725330353

Epoch: 5| Step: 5
Training loss: 3.85406494140625
Validation loss: 3.762835363547007

Epoch: 5| Step: 6
Training loss: 4.544663906097412
Validation loss: 3.7559311787287393

Epoch: 5| Step: 7
Training loss: 2.9034249782562256
Validation loss: 3.7497429052988687

Epoch: 5| Step: 8
Training loss: 3.9197680950164795
Validation loss: 3.744461973508199

Epoch: 5| Step: 9
Training loss: 4.355557918548584
Validation loss: 3.740027666091919

Epoch: 5| Step: 10
Training loss: 3.2870864868164062
Validation loss: 3.7356562117735543

Epoch: 5| Step: 11
Training loss: 3.939352035522461
Validation loss: 3.731025824944178

Epoch: 22| Step: 0
Training loss: 3.9558730125427246
Validation loss: 3.7256804406642914

Epoch: 5| Step: 1
Training loss: 4.602326393127441
Validation loss: 3.7201093335946402

Epoch: 5| Step: 2
Training loss: 4.348616600036621
Validation loss: 3.7143457432587943

Epoch: 5| Step: 3
Training loss: 3.5413239002227783
Validation loss: 3.7098492085933685

Epoch: 5| Step: 4
Training loss: 3.9157299995422363
Validation loss: 3.705542961756388

Epoch: 5| Step: 5
Training loss: 3.559251308441162
Validation loss: 3.7016490002473197

Epoch: 5| Step: 6
Training loss: 3.116492509841919
Validation loss: 3.6976537704467773

Epoch: 5| Step: 7
Training loss: 4.217741966247559
Validation loss: 3.692735195159912

Epoch: 5| Step: 8
Training loss: 4.466915607452393
Validation loss: 3.687494069337845

Epoch: 5| Step: 9
Training loss: 3.104651689529419
Validation loss: 3.6818583806355796

Epoch: 5| Step: 10
Training loss: 4.155355453491211
Validation loss: 3.6768027742703757

Epoch: 5| Step: 11
Training loss: 1.2924176454544067
Validation loss: 3.6721987624963126

Epoch: 23| Step: 0
Training loss: 4.499891757965088
Validation loss: 3.6671809554100037

Epoch: 5| Step: 1
Training loss: 4.090446472167969
Validation loss: 3.6628125111262

Epoch: 5| Step: 2
Training loss: 4.004544258117676
Validation loss: 3.6568412284056344

Epoch: 5| Step: 3
Training loss: 3.477832794189453
Validation loss: 3.6526483396689096

Epoch: 5| Step: 4
Training loss: 4.150135517120361
Validation loss: 3.6465622385342917

Epoch: 5| Step: 5
Training loss: 3.448748826980591
Validation loss: 3.6427322030067444

Epoch: 5| Step: 6
Training loss: 3.3847618103027344
Validation loss: 3.6376033325990043

Epoch: 5| Step: 7
Training loss: 3.66743540763855
Validation loss: 3.63220206896464

Epoch: 5| Step: 8
Training loss: 3.699885845184326
Validation loss: 3.627756675084432

Epoch: 5| Step: 9
Training loss: 4.562003135681152
Validation loss: 3.6222557624181113

Epoch: 5| Step: 10
Training loss: 3.2643253803253174
Validation loss: 3.6173142989476523

Epoch: 5| Step: 11
Training loss: 1.7644078731536865
Validation loss: 3.6121948758761087

Epoch: 24| Step: 0
Training loss: 3.920976161956787
Validation loss: 3.606960008541743

Epoch: 5| Step: 1
Training loss: 3.5614559650421143
Validation loss: 3.6026512483755746

Epoch: 5| Step: 2
Training loss: 3.7913246154785156
Validation loss: 3.5969920655091605

Epoch: 5| Step: 3
Training loss: 3.431185245513916
Validation loss: 3.591714988152186

Epoch: 5| Step: 4
Training loss: 4.101688861846924
Validation loss: 3.586606780687968

Epoch: 5| Step: 5
Training loss: 3.9781479835510254
Validation loss: 3.582497258981069

Epoch: 5| Step: 6
Training loss: 4.491969108581543
Validation loss: 3.5772176583607993

Epoch: 5| Step: 7
Training loss: 3.96783447265625
Validation loss: 3.5723880330721536

Epoch: 5| Step: 8
Training loss: 3.389122724533081
Validation loss: 3.5671374996503196

Epoch: 5| Step: 9
Training loss: 3.8699440956115723
Validation loss: 3.5611744026343026

Epoch: 5| Step: 10
Training loss: 2.9771218299865723
Validation loss: 3.5562388400236764

Epoch: 5| Step: 11
Training loss: 2.3681297302246094
Validation loss: 3.5509455601374307

Epoch: 25| Step: 0
Training loss: 3.0536341667175293
Validation loss: 3.546542704105377

Epoch: 5| Step: 1
Training loss: 3.732487440109253
Validation loss: 3.5411740044752755

Epoch: 5| Step: 2
Training loss: 3.1855502128601074
Validation loss: 3.5353794495264688

Epoch: 5| Step: 3
Training loss: 3.8684539794921875
Validation loss: 3.5315729478995004

Epoch: 5| Step: 4
Training loss: 3.4718947410583496
Validation loss: 3.524970750013987

Epoch: 5| Step: 5
Training loss: 3.9901862144470215
Validation loss: 3.5206089516480765

Epoch: 5| Step: 6
Training loss: 3.482809543609619
Validation loss: 3.5153929690519967

Epoch: 5| Step: 7
Training loss: 4.331263542175293
Validation loss: 3.5106445252895355

Epoch: 5| Step: 8
Training loss: 3.5971126556396484
Validation loss: 3.505725691715876

Epoch: 5| Step: 9
Training loss: 3.410060167312622
Validation loss: 3.5004893441994986

Epoch: 5| Step: 10
Training loss: 3.879091739654541
Validation loss: 3.495873292287191

Epoch: 5| Step: 11
Training loss: 6.437514305114746
Validation loss: 3.4903914531071982

Epoch: 26| Step: 0
Training loss: 2.9761648178100586
Validation loss: 3.4858392576376596

Epoch: 5| Step: 1
Training loss: 4.114737033843994
Validation loss: 3.4812222123146057

Epoch: 5| Step: 2
Training loss: 4.441132545471191
Validation loss: 3.476128270228704

Epoch: 5| Step: 3
Training loss: 3.3037796020507812
Validation loss: 3.4705970088640847

Epoch: 5| Step: 4
Training loss: 3.9473471641540527
Validation loss: 3.4654859701792398

Epoch: 5| Step: 5
Training loss: 3.44169282913208
Validation loss: 3.4609183967113495

Epoch: 5| Step: 6
Training loss: 3.4309158325195312
Validation loss: 3.4557510217030845

Epoch: 5| Step: 7
Training loss: 3.4734394550323486
Validation loss: 3.450970451037089

Epoch: 5| Step: 8
Training loss: 4.057164192199707
Validation loss: 3.446449806292852

Epoch: 5| Step: 9
Training loss: 3.3246543407440186
Validation loss: 3.4410205086072287

Epoch: 5| Step: 10
Training loss: 3.434386730194092
Validation loss: 3.435876359542211

Epoch: 5| Step: 11
Training loss: 3.3475756645202637
Validation loss: 3.4315588772296906

Epoch: 27| Step: 0
Training loss: 4.024585247039795
Validation loss: 3.426448027292887

Epoch: 5| Step: 1
Training loss: 2.8003969192504883
Validation loss: 3.4218408266703286

Epoch: 5| Step: 2
Training loss: 3.582195997238159
Validation loss: 3.417612592379252

Epoch: 5| Step: 3
Training loss: 4.102767467498779
Validation loss: 3.412791689236959

Epoch: 5| Step: 4
Training loss: 3.6215081214904785
Validation loss: 3.408018330732981

Epoch: 5| Step: 5
Training loss: 2.9829647541046143
Validation loss: 3.403147200743357

Epoch: 5| Step: 6
Training loss: 3.686887741088867
Validation loss: 3.3981444338957467

Epoch: 5| Step: 7
Training loss: 3.541635036468506
Validation loss: 3.3932844003041587

Epoch: 5| Step: 8
Training loss: 3.0758261680603027
Validation loss: 3.3888962467511496

Epoch: 5| Step: 9
Training loss: 3.3628928661346436
Validation loss: 3.3834557930628457

Epoch: 5| Step: 10
Training loss: 4.328390121459961
Validation loss: 3.3792529702186584

Epoch: 5| Step: 11
Training loss: 4.350135803222656
Validation loss: 3.3744405806064606

Epoch: 28| Step: 0
Training loss: 2.754817008972168
Validation loss: 3.369249016046524

Epoch: 5| Step: 1
Training loss: 3.793701171875
Validation loss: 3.364036977291107

Epoch: 5| Step: 2
Training loss: 3.9791064262390137
Validation loss: 3.35859414935112

Epoch: 5| Step: 3
Training loss: 4.584291458129883
Validation loss: 3.354475647211075

Epoch: 5| Step: 4
Training loss: 3.849228620529175
Validation loss: 3.349712540705999

Epoch: 5| Step: 5
Training loss: 3.858163356781006
Validation loss: 3.344592442115148

Epoch: 5| Step: 6
Training loss: 3.157707691192627
Validation loss: 3.339744379123052

Epoch: 5| Step: 7
Training loss: 3.1726791858673096
Validation loss: 3.3345304230848947

Epoch: 5| Step: 8
Training loss: 2.975799322128296
Validation loss: 3.3291788399219513

Epoch: 5| Step: 9
Training loss: 3.495039463043213
Validation loss: 3.3246216972668967

Epoch: 5| Step: 10
Training loss: 3.49306058883667
Validation loss: 3.3195197383562722

Epoch: 5| Step: 11
Training loss: 1.3715137243270874
Validation loss: 3.3151907920837402

Epoch: 29| Step: 0
Training loss: 3.3609535694122314
Validation loss: 3.309896250565847

Epoch: 5| Step: 1
Training loss: 4.040600299835205
Validation loss: 3.3056835432847342

Epoch: 5| Step: 2
Training loss: 3.6251883506774902
Validation loss: 3.3006255825360618

Epoch: 5| Step: 3
Training loss: 3.2689342498779297
Validation loss: 3.296652764081955

Epoch: 5| Step: 4
Training loss: 3.4827017784118652
Validation loss: 3.2923870583375296

Epoch: 5| Step: 5
Training loss: 4.078381061553955
Validation loss: 3.288125773270925

Epoch: 5| Step: 6
Training loss: 3.3104209899902344
Validation loss: 3.2829351325829825

Epoch: 5| Step: 7
Training loss: 3.347424268722534
Validation loss: 3.279701441526413

Epoch: 5| Step: 8
Training loss: 3.4925312995910645
Validation loss: 3.2750014662742615

Epoch: 5| Step: 9
Training loss: 3.441584825515747
Validation loss: 3.270439768830935

Epoch: 5| Step: 10
Training loss: 2.778865337371826
Validation loss: 3.265691955884298

Epoch: 5| Step: 11
Training loss: 2.8462400436401367
Validation loss: 3.2610219419002533

Epoch: 30| Step: 0
Training loss: 3.8101508617401123
Validation loss: 3.257274409135183

Epoch: 5| Step: 1
Training loss: 3.2013511657714844
Validation loss: 3.253871649503708

Epoch: 5| Step: 2
Training loss: 4.092740535736084
Validation loss: 3.2486453553040824

Epoch: 5| Step: 3
Training loss: 3.6772513389587402
Validation loss: 3.2448755900065103

Epoch: 5| Step: 4
Training loss: 3.8700790405273438
Validation loss: 3.2397834161917367

Epoch: 5| Step: 5
Training loss: 2.810408115386963
Validation loss: 3.2363601128260293

Epoch: 5| Step: 6
Training loss: 2.883356809616089
Validation loss: 3.232049455245336

Epoch: 5| Step: 7
Training loss: 3.010131359100342
Validation loss: 3.227491796016693

Epoch: 5| Step: 8
Training loss: 3.3222908973693848
Validation loss: 3.223592629035314

Epoch: 5| Step: 9
Training loss: 3.52050518989563
Validation loss: 3.2188766499360404

Epoch: 5| Step: 10
Training loss: 3.5241596698760986
Validation loss: 3.2150310575962067

Epoch: 5| Step: 11
Training loss: 2.5923266410827637
Validation loss: 3.2103363374869027

Epoch: 31| Step: 0
Training loss: 3.804469585418701
Validation loss: 3.2069892088572183

Epoch: 5| Step: 1
Training loss: 3.2403457164764404
Validation loss: 3.2018047074476876

Epoch: 5| Step: 2
Training loss: 2.667858839035034
Validation loss: 3.19695774714152

Epoch: 5| Step: 3
Training loss: 3.54376482963562
Validation loss: 3.192546248435974

Epoch: 5| Step: 4
Training loss: 3.655302047729492
Validation loss: 3.1890372236569724

Epoch: 5| Step: 5
Training loss: 3.0620312690734863
Validation loss: 3.184820661942164

Epoch: 5| Step: 6
Training loss: 3.6145501136779785
Validation loss: 3.1809965471426644

Epoch: 5| Step: 7
Training loss: 3.602879047393799
Validation loss: 3.1770877043406167

Epoch: 5| Step: 8
Training loss: 3.4841513633728027
Validation loss: 3.1722889244556427

Epoch: 5| Step: 9
Training loss: 3.1488842964172363
Validation loss: 3.1673041184743247

Epoch: 5| Step: 10
Training loss: 3.1851890087127686
Validation loss: 3.162475893894831

Epoch: 5| Step: 11
Training loss: 3.4988059997558594
Validation loss: 3.157380312681198

Epoch: 32| Step: 0
Training loss: 3.8240408897399902
Validation loss: 3.1535578966140747

Epoch: 5| Step: 1
Training loss: 3.028151750564575
Validation loss: 3.1487375299135842

Epoch: 5| Step: 2
Training loss: 3.551029682159424
Validation loss: 3.144729902346929

Epoch: 5| Step: 3
Training loss: 3.1020541191101074
Validation loss: 3.1411428352197013

Epoch: 5| Step: 4
Training loss: 3.3507370948791504
Validation loss: 3.1369886497656503

Epoch: 5| Step: 5
Training loss: 3.358372211456299
Validation loss: 3.134035031000773

Epoch: 5| Step: 6
Training loss: 3.0674514770507812
Validation loss: 3.1312399009863534

Epoch: 5| Step: 7
Training loss: 3.696840286254883
Validation loss: 3.12732340892156

Epoch: 5| Step: 8
Training loss: 2.6406631469726562
Validation loss: 3.1198179721832275

Epoch: 5| Step: 9
Training loss: 4.351254940032959
Validation loss: 3.114989091952642

Epoch: 5| Step: 10
Training loss: 2.4826745986938477
Validation loss: 3.1113212605317435

Epoch: 5| Step: 11
Training loss: 3.612574577331543
Validation loss: 3.108113924662272

Epoch: 33| Step: 0
Training loss: 3.452746629714966
Validation loss: 3.104978303114573

Epoch: 5| Step: 1
Training loss: 2.544339895248413
Validation loss: 3.101238429546356

Epoch: 5| Step: 2
Training loss: 2.9602341651916504
Validation loss: 3.0973707834879556

Epoch: 5| Step: 3
Training loss: 4.182698726654053
Validation loss: 3.092819760243098

Epoch: 5| Step: 4
Training loss: 3.1137795448303223
Validation loss: 3.088538179794947

Epoch: 5| Step: 5
Training loss: 3.705852508544922
Validation loss: 3.0845156013965607

Epoch: 5| Step: 6
Training loss: 3.46148419380188
Validation loss: 3.080183287461599

Epoch: 5| Step: 7
Training loss: 3.316763401031494
Validation loss: 3.0767468015352883

Epoch: 5| Step: 8
Training loss: 3.7822906970977783
Validation loss: 3.071997950474421

Epoch: 5| Step: 9
Training loss: 2.559497356414795
Validation loss: 3.0684410432974496

Epoch: 5| Step: 10
Training loss: 2.6859824657440186
Validation loss: 3.065307686726252

Epoch: 5| Step: 11
Training loss: 4.61073112487793
Validation loss: 3.0603276193141937

Epoch: 34| Step: 0
Training loss: 4.145847797393799
Validation loss: 3.0574053823947906

Epoch: 5| Step: 1
Training loss: 3.1436352729797363
Validation loss: 3.052231788635254

Epoch: 5| Step: 2
Training loss: 2.6985745429992676
Validation loss: 3.0483429034550986

Epoch: 5| Step: 3
Training loss: 3.0070548057556152
Validation loss: 3.0458900729815164

Epoch: 5| Step: 4
Training loss: 3.3859856128692627
Validation loss: 3.0417699416478476

Epoch: 5| Step: 5
Training loss: 3.1202101707458496
Validation loss: 3.0379358927408853

Epoch: 5| Step: 6
Training loss: 3.156367063522339
Validation loss: 3.0340107580025992

Epoch: 5| Step: 7
Training loss: 3.051912307739258
Validation loss: 3.030181050300598

Epoch: 5| Step: 8
Training loss: 2.8775970935821533
Validation loss: 3.02618145942688

Epoch: 5| Step: 9
Training loss: 3.4183056354522705
Validation loss: 3.0226096411546073

Epoch: 5| Step: 10
Training loss: 3.529911756515503
Validation loss: 3.018738021453222

Epoch: 5| Step: 11
Training loss: 3.0784480571746826
Validation loss: 3.0132911602656045

Epoch: 35| Step: 0
Training loss: 2.8084473609924316
Validation loss: 3.0104602624972663

Epoch: 5| Step: 1
Training loss: 3.543154239654541
Validation loss: 3.006651242574056

Epoch: 5| Step: 2
Training loss: 3.728325366973877
Validation loss: 3.003217796484629

Epoch: 5| Step: 3
Training loss: 2.9275312423706055
Validation loss: 2.9981846511363983

Epoch: 5| Step: 4
Training loss: 2.7303013801574707
Validation loss: 2.9932819306850433

Epoch: 5| Step: 5
Training loss: 3.027554512023926
Validation loss: 2.9895297586917877

Epoch: 5| Step: 6
Training loss: 3.387065887451172
Validation loss: 2.9861419399579368

Epoch: 5| Step: 7
Training loss: 2.8449902534484863
Validation loss: 2.9829830527305603

Epoch: 5| Step: 8
Training loss: 3.1739635467529297
Validation loss: 2.9787434736887612

Epoch: 5| Step: 9
Training loss: 3.736220598220825
Validation loss: 2.975391228993734

Epoch: 5| Step: 10
Training loss: 3.291783571243286
Validation loss: 2.9712212880452475

Epoch: 5| Step: 11
Training loss: 2.329012155532837
Validation loss: 2.9668854077657065

Epoch: 36| Step: 0
Training loss: 3.3489060401916504
Validation loss: 2.9625395039717355

Epoch: 5| Step: 1
Training loss: 2.848395824432373
Validation loss: 2.958778142929077

Epoch: 5| Step: 2
Training loss: 3.87034273147583
Validation loss: 2.9554422398408255

Epoch: 5| Step: 3
Training loss: 2.4182159900665283
Validation loss: 2.9508575201034546

Epoch: 5| Step: 4
Training loss: 3.2100746631622314
Validation loss: 2.947466274102529

Epoch: 5| Step: 5
Training loss: 3.0620083808898926
Validation loss: 2.9442749321460724

Epoch: 5| Step: 6
Training loss: 2.8623762130737305
Validation loss: 2.9395037591457367

Epoch: 5| Step: 7
Training loss: 3.7356796264648438
Validation loss: 2.9352593620618186

Epoch: 5| Step: 8
Training loss: 2.7339141368865967
Validation loss: 2.930940717458725

Epoch: 5| Step: 9
Training loss: 3.582223415374756
Validation loss: 2.9282298187414804

Epoch: 5| Step: 10
Training loss: 2.6830430030822754
Validation loss: 2.9241144259770713

Epoch: 5| Step: 11
Training loss: 4.13486385345459
Validation loss: 2.9208964705467224

Epoch: 37| Step: 0
Training loss: 3.282932996749878
Validation loss: 2.916720579067866

Epoch: 5| Step: 1
Training loss: 3.177123785018921
Validation loss: 2.9118767182032266

Epoch: 5| Step: 2
Training loss: 2.8228721618652344
Validation loss: 2.907905916372935

Epoch: 5| Step: 3
Training loss: 3.4832763671875
Validation loss: 2.9044097860654197

Epoch: 5| Step: 4
Training loss: 3.850494384765625
Validation loss: 2.899988740682602

Epoch: 5| Step: 5
Training loss: 2.7461485862731934
Validation loss: 2.8954730729262033

Epoch: 5| Step: 6
Training loss: 3.1763644218444824
Validation loss: 2.891616235176722

Epoch: 5| Step: 7
Training loss: 2.7614264488220215
Validation loss: 2.8878102203210196

Epoch: 5| Step: 8
Training loss: 2.722187042236328
Validation loss: 2.8835851550102234

Epoch: 5| Step: 9
Training loss: 2.6080377101898193
Validation loss: 2.880602399508158

Epoch: 5| Step: 10
Training loss: 3.3827719688415527
Validation loss: 2.8773679435253143

Epoch: 5| Step: 11
Training loss: 3.6689469814300537
Validation loss: 2.874133030573527

Epoch: 38| Step: 0
Training loss: 3.420193910598755
Validation loss: 2.870241492986679

Epoch: 5| Step: 1
Training loss: 2.7320473194122314
Validation loss: 2.866906464099884

Epoch: 5| Step: 2
Training loss: 3.2301223278045654
Validation loss: 2.862310548623403

Epoch: 5| Step: 3
Training loss: 2.7784266471862793
Validation loss: 2.8597996135552726

Epoch: 5| Step: 4
Training loss: 3.5553138256073
Validation loss: 2.855457127094269

Epoch: 5| Step: 5
Training loss: 3.103684902191162
Validation loss: 2.8527831435203552

Epoch: 5| Step: 6
Training loss: 2.831585168838501
Validation loss: 2.848983198404312

Epoch: 5| Step: 7
Training loss: 3.4281325340270996
Validation loss: 2.845448245604833

Epoch: 5| Step: 8
Training loss: 2.718534469604492
Validation loss: 2.8419587512811026

Epoch: 5| Step: 9
Training loss: 3.0171074867248535
Validation loss: 2.838877479235331

Epoch: 5| Step: 10
Training loss: 2.9877238273620605
Validation loss: 2.8353205819924674

Epoch: 5| Step: 11
Training loss: 2.336693525314331
Validation loss: 2.8321277499198914

Epoch: 39| Step: 0
Training loss: 3.5605149269104004
Validation loss: 2.828043202559153

Epoch: 5| Step: 1
Training loss: 3.3129565715789795
Validation loss: 2.8255355854829154

Epoch: 5| Step: 2
Training loss: 2.3759398460388184
Validation loss: 2.821416676044464

Epoch: 5| Step: 3
Training loss: 3.4823451042175293
Validation loss: 2.8184205293655396

Epoch: 5| Step: 4
Training loss: 3.477252960205078
Validation loss: 2.815254330635071

Epoch: 5| Step: 5
Training loss: 2.275357961654663
Validation loss: 2.8113625943660736

Epoch: 5| Step: 6
Training loss: 2.86637282371521
Validation loss: 2.808472295602163

Epoch: 5| Step: 7
Training loss: 2.9275174140930176
Validation loss: 2.804753621419271

Epoch: 5| Step: 8
Training loss: 2.5606138706207275
Validation loss: 2.8031693498293557

Epoch: 5| Step: 9
Training loss: 2.9476535320281982
Validation loss: 2.7991594274838767

Epoch: 5| Step: 10
Training loss: 3.378584384918213
Validation loss: 2.7986295024553933

Epoch: 5| Step: 11
Training loss: 3.542954921722412
Validation loss: 2.7953488528728485

Epoch: 40| Step: 0
Training loss: 2.495553970336914
Validation loss: 2.8116495410601297

Epoch: 5| Step: 1
Training loss: 3.5615038871765137
Validation loss: 2.816784759362539

Epoch: 5| Step: 2
Training loss: 3.0619056224823
Validation loss: 2.804872969786326

Epoch: 5| Step: 3
Training loss: 3.1057872772216797
Validation loss: 2.7840873301029205

Epoch: 5| Step: 4
Training loss: 3.4605019092559814
Validation loss: 2.777392993370692

Epoch: 5| Step: 5
Training loss: 2.9895339012145996
Validation loss: 2.774788568417231

Epoch: 5| Step: 6
Training loss: 3.224961042404175
Validation loss: 2.772845874230067

Epoch: 5| Step: 7
Training loss: 2.987048625946045
Validation loss: 2.769706517457962

Epoch: 5| Step: 8
Training loss: 1.8324146270751953
Validation loss: 2.7670722703138986

Epoch: 5| Step: 9
Training loss: 3.18304443359375
Validation loss: 2.764027069012324

Epoch: 5| Step: 10
Training loss: 3.075817346572876
Validation loss: 2.760916749636332

Epoch: 5| Step: 11
Training loss: 2.764643430709839
Validation loss: 2.7564760645230613

Epoch: 41| Step: 0
Training loss: 3.4361166954040527
Validation loss: 2.754042605559031

Epoch: 5| Step: 1
Training loss: 3.0433952808380127
Validation loss: 2.750576357046763

Epoch: 5| Step: 2
Training loss: 2.790341854095459
Validation loss: 2.7464555501937866

Epoch: 5| Step: 3
Training loss: 2.9852375984191895
Validation loss: 2.7423688570658364

Epoch: 5| Step: 4
Training loss: 2.796987533569336
Validation loss: 2.7390373746554055

Epoch: 5| Step: 5
Training loss: 2.846911668777466
Validation loss: 2.736503074566523

Epoch: 5| Step: 6
Training loss: 3.2572906017303467
Validation loss: 2.732549955447515

Epoch: 5| Step: 7
Training loss: 2.838773488998413
Validation loss: 2.730501482884089

Epoch: 5| Step: 8
Training loss: 2.9256248474121094
Validation loss: 2.7272623976071677

Epoch: 5| Step: 9
Training loss: 3.0104293823242188
Validation loss: 2.7233938574790955

Epoch: 5| Step: 10
Training loss: 2.580873966217041
Validation loss: 2.7207614481449127

Epoch: 5| Step: 11
Training loss: 2.542426824569702
Validation loss: 2.7177228232224784

Epoch: 42| Step: 0
Training loss: 2.891040325164795
Validation loss: 2.7185456355412803

Epoch: 5| Step: 1
Training loss: 3.5005557537078857
Validation loss: 2.7330629428227744

Epoch: 5| Step: 2
Training loss: 3.280151844024658
Validation loss: 2.7106761435667672

Epoch: 5| Step: 3
Training loss: 2.904212236404419
Validation loss: 2.712357153495153

Epoch: 5| Step: 4
Training loss: 3.600008487701416
Validation loss: 2.7081064581871033

Epoch: 5| Step: 5
Training loss: 2.848407030105591
Validation loss: 2.7105843226114907

Epoch: 5| Step: 6
Training loss: 2.4498307704925537
Validation loss: 2.7030110160509744

Epoch: 5| Step: 7
Training loss: 2.569514036178589
Validation loss: 2.699176033337911

Epoch: 5| Step: 8
Training loss: 3.163353681564331
Validation loss: 2.696707854668299

Epoch: 5| Step: 9
Training loss: 2.2566604614257812
Validation loss: 2.692832370599111

Epoch: 5| Step: 10
Training loss: 2.848018169403076
Validation loss: 2.6882140735785165

Epoch: 5| Step: 11
Training loss: 1.480228066444397
Validation loss: 2.6843925019105277

Epoch: 43| Step: 0
Training loss: 2.695430278778076
Validation loss: 2.680463264385859

Epoch: 5| Step: 1
Training loss: 2.704171895980835
Validation loss: 2.676520496606827

Epoch: 5| Step: 2
Training loss: 2.706953525543213
Validation loss: 2.672263592481613

Epoch: 5| Step: 3
Training loss: 3.2266743183135986
Validation loss: 2.66763636469841

Epoch: 5| Step: 4
Training loss: 2.8469409942626953
Validation loss: 2.6643598874409995

Epoch: 5| Step: 5
Training loss: 2.9450576305389404
Validation loss: 2.662344684203466

Epoch: 5| Step: 6
Training loss: 2.9302680492401123
Validation loss: 2.6656313935915628

Epoch: 5| Step: 7
Training loss: 2.8164477348327637
Validation loss: 2.6703582604726157

Epoch: 5| Step: 8
Training loss: 2.9108798503875732
Validation loss: 2.680864711602529

Epoch: 5| Step: 9
Training loss: 3.208660840988159
Validation loss: 2.6453403532505035

Epoch: 5| Step: 10
Training loss: 2.2513108253479004
Validation loss: 2.6399983763694763

Epoch: 5| Step: 11
Training loss: 4.626269340515137
Validation loss: 2.6399914224942527

Epoch: 44| Step: 0
Training loss: 2.511500835418701
Validation loss: 2.640215421716372

Epoch: 5| Step: 1
Training loss: 3.222900867462158
Validation loss: 2.6432333489259086

Epoch: 5| Step: 2
Training loss: 2.7228708267211914
Validation loss: 2.644743412733078

Epoch: 5| Step: 3
Training loss: 2.7366905212402344
Validation loss: 2.641862471898397

Epoch: 5| Step: 4
Training loss: 2.304701566696167
Validation loss: 2.6363754073778787

Epoch: 5| Step: 5
Training loss: 2.870096206665039
Validation loss: 2.631572405497233

Epoch: 5| Step: 6
Training loss: 3.283658266067505
Validation loss: 2.6241849462191262

Epoch: 5| Step: 7
Training loss: 2.820713758468628
Validation loss: 2.619678874810537

Epoch: 5| Step: 8
Training loss: 3.214385509490967
Validation loss: 2.6124629577000937

Epoch: 5| Step: 9
Training loss: 2.5078043937683105
Validation loss: 2.606786827246348

Epoch: 5| Step: 10
Training loss: 2.8105037212371826
Validation loss: 2.600866357485453

Epoch: 5| Step: 11
Training loss: 3.5893123149871826
Validation loss: 2.596276263395945

Epoch: 45| Step: 0
Training loss: 2.9695651531219482
Validation loss: 2.591329981883367

Epoch: 5| Step: 1
Training loss: 2.3245956897735596
Validation loss: 2.587632934252421

Epoch: 5| Step: 2
Training loss: 3.0437569618225098
Validation loss: 2.5878932078679404

Epoch: 5| Step: 3
Training loss: 2.4083056449890137
Validation loss: 2.5810353060563407

Epoch: 5| Step: 4
Training loss: 2.8780224323272705
Validation loss: 2.581011801958084

Epoch: 5| Step: 5
Training loss: 2.7283036708831787
Validation loss: 2.5806455314159393

Epoch: 5| Step: 6
Training loss: 3.2279248237609863
Validation loss: 2.57858736316363

Epoch: 5| Step: 7
Training loss: 2.2180066108703613
Validation loss: 2.570721705754598

Epoch: 5| Step: 8
Training loss: 2.831662178039551
Validation loss: 2.566399226586024

Epoch: 5| Step: 9
Training loss: 3.215243101119995
Validation loss: 2.561052069067955

Epoch: 5| Step: 10
Training loss: 2.9186666011810303
Validation loss: 2.560268605748812

Epoch: 5| Step: 11
Training loss: 1.4916670322418213
Validation loss: 2.556268493334452

Epoch: 46| Step: 0
Training loss: 2.813837766647339
Validation loss: 2.5516924957434335

Epoch: 5| Step: 1
Training loss: 2.7278435230255127
Validation loss: 2.5474164883295694

Epoch: 5| Step: 2
Training loss: 2.843970537185669
Validation loss: 2.5430124203364053

Epoch: 5| Step: 3
Training loss: 2.633300304412842
Validation loss: 2.5386030077934265

Epoch: 5| Step: 4
Training loss: 2.8118221759796143
Validation loss: 2.5367478728294373

Epoch: 5| Step: 5
Training loss: 2.6236367225646973
Validation loss: 2.5351715783278146

Epoch: 5| Step: 6
Training loss: 3.55133056640625
Validation loss: 2.53202493985494

Epoch: 5| Step: 7
Training loss: 2.437246799468994
Validation loss: 2.525718867778778

Epoch: 5| Step: 8
Training loss: 2.1796648502349854
Validation loss: 2.5234163800875344

Epoch: 5| Step: 9
Training loss: 2.195768117904663
Validation loss: 2.5177449385325112

Epoch: 5| Step: 10
Training loss: 3.1586050987243652
Validation loss: 2.5167358616987863

Epoch: 5| Step: 11
Training loss: 2.7036843299865723
Validation loss: 2.5103967487812042

Epoch: 47| Step: 0
Training loss: 2.4637978076934814
Validation loss: 2.51082252462705

Epoch: 5| Step: 1
Training loss: 2.496896266937256
Validation loss: 2.5072050591309867

Epoch: 5| Step: 2
Training loss: 3.1433589458465576
Validation loss: 2.5066296656926474

Epoch: 5| Step: 3
Training loss: 2.479883909225464
Validation loss: 2.50227498014768

Epoch: 5| Step: 4
Training loss: 2.864748001098633
Validation loss: 2.497862925132116

Epoch: 5| Step: 5
Training loss: 2.5633325576782227
Validation loss: 2.4956248899300895

Epoch: 5| Step: 6
Training loss: 2.7626633644104004
Validation loss: 2.494502772887548

Epoch: 5| Step: 7
Training loss: 2.462747812271118
Validation loss: 2.48685551683108

Epoch: 5| Step: 8
Training loss: 2.5848851203918457
Validation loss: 2.486045161883036

Epoch: 5| Step: 9
Training loss: 2.653135299682617
Validation loss: 2.478775600592295

Epoch: 5| Step: 10
Training loss: 2.8234500885009766
Validation loss: 2.4778256018956504

Epoch: 5| Step: 11
Training loss: 4.005876541137695
Validation loss: 2.4714312503735223

Epoch: 48| Step: 0
Training loss: 2.2000491619110107
Validation loss: 2.468209554751714

Epoch: 5| Step: 1
Training loss: 2.4166767597198486
Validation loss: 2.4650086760520935

Epoch: 5| Step: 2
Training loss: 2.991027355194092
Validation loss: 2.4657047192255654

Epoch: 5| Step: 3
Training loss: 2.635625123977661
Validation loss: 2.4615294436613717

Epoch: 5| Step: 4
Training loss: 2.991279363632202
Validation loss: 2.4572013219197593

Epoch: 5| Step: 5
Training loss: 2.6677021980285645
Validation loss: 2.454804758230845

Epoch: 5| Step: 6
Training loss: 2.415092945098877
Validation loss: 2.452822138865789

Epoch: 5| Step: 7
Training loss: 3.0502731800079346
Validation loss: 2.4483325282732644

Epoch: 5| Step: 8
Training loss: 2.7847983837127686
Validation loss: 2.4429575304190316

Epoch: 5| Step: 9
Training loss: 2.349341869354248
Validation loss: 2.4425431986649833

Epoch: 5| Step: 10
Training loss: 2.5778934955596924
Validation loss: 2.4346481462319693

Epoch: 5| Step: 11
Training loss: 2.3581392765045166
Validation loss: 2.4347008168697357

Epoch: 49| Step: 0
Training loss: 2.4107937812805176
Validation loss: 2.429047246774038

Epoch: 5| Step: 1
Training loss: 2.8106648921966553
Validation loss: 2.425464312235514

Epoch: 5| Step: 2
Training loss: 3.0004711151123047
Validation loss: 2.424764965971311

Epoch: 5| Step: 3
Training loss: 2.756772994995117
Validation loss: 2.420668343702952

Epoch: 5| Step: 4
Training loss: 2.485825777053833
Validation loss: 2.4160601596037545

Epoch: 5| Step: 5
Training loss: 2.63909649848938
Validation loss: 2.4129595706860223

Epoch: 5| Step: 6
Training loss: 2.4784188270568848
Validation loss: 2.4106969982385635

Epoch: 5| Step: 7
Training loss: 2.4701168537139893
Validation loss: 2.4077596018711724

Epoch: 5| Step: 8
Training loss: 2.499767303466797
Validation loss: 2.4010372211535773

Epoch: 5| Step: 9
Training loss: 2.3221051692962646
Validation loss: 2.3958456615606942

Epoch: 5| Step: 10
Training loss: 2.6541531085968018
Validation loss: 2.396560480197271

Epoch: 5| Step: 11
Training loss: 2.646104097366333
Validation loss: 2.396256665388743

Epoch: 50| Step: 0
Training loss: 3.0049891471862793
Validation loss: 2.3906681885321936

Epoch: 5| Step: 1
Training loss: 2.771498441696167
Validation loss: 2.392496258020401

Epoch: 5| Step: 2
Training loss: 2.3159384727478027
Validation loss: 2.3919464747111

Epoch: 5| Step: 3
Training loss: 3.04545521736145
Validation loss: 2.3844573398431144

Epoch: 5| Step: 4
Training loss: 2.9471333026885986
Validation loss: 2.3858202000459037

Epoch: 5| Step: 5
Training loss: 2.4478085041046143
Validation loss: 2.385920991500219

Epoch: 5| Step: 6
Training loss: 2.1287240982055664
Validation loss: 2.3856004774570465

Epoch: 5| Step: 7
Training loss: 1.887616753578186
Validation loss: 2.3829626937707267

Epoch: 5| Step: 8
Training loss: 2.380662679672241
Validation loss: 2.3826120446125665

Epoch: 5| Step: 9
Training loss: 2.7280960083007812
Validation loss: 2.3772640327612558

Epoch: 5| Step: 10
Training loss: 2.2661240100860596
Validation loss: 2.3737378319104514

Epoch: 5| Step: 11
Training loss: 4.176844596862793
Validation loss: 2.370056301355362

Epoch: 51| Step: 0
Training loss: 1.843324065208435
Validation loss: 2.367112919688225

Epoch: 5| Step: 1
Training loss: 2.7285594940185547
Validation loss: 2.3620717426141105

Epoch: 5| Step: 2
Training loss: 2.627652645111084
Validation loss: 2.3589012722174325

Epoch: 5| Step: 3
Training loss: 2.3240807056427
Validation loss: 2.349551727374395

Epoch: 5| Step: 4
Training loss: 2.744974374771118
Validation loss: 2.347538967927297

Epoch: 5| Step: 5
Training loss: 2.8475403785705566
Validation loss: 2.3459443847338357

Epoch: 5| Step: 6
Training loss: 2.498591423034668
Validation loss: 2.3462667067845664

Epoch: 5| Step: 7
Training loss: 2.4833858013153076
Validation loss: 2.3491349716981254

Epoch: 5| Step: 8
Training loss: 2.8173089027404785
Validation loss: 2.3454302847385406

Epoch: 5| Step: 9
Training loss: 2.858510732650757
Validation loss: 2.3377924958864846

Epoch: 5| Step: 10
Training loss: 2.1879515647888184
Validation loss: 2.335781673590342

Epoch: 5| Step: 11
Training loss: 1.7636816501617432
Validation loss: 2.3268914918104806

Epoch: 52| Step: 0
Training loss: 3.433640956878662
Validation loss: 2.323985834916433

Epoch: 5| Step: 1
Training loss: 2.8885953426361084
Validation loss: 2.3244822720686593

Epoch: 5| Step: 2
Training loss: 2.4828383922576904
Validation loss: 2.323905090490977

Epoch: 5| Step: 3
Training loss: 2.936845541000366
Validation loss: 2.3193695147832236

Epoch: 5| Step: 4
Training loss: 2.1112518310546875
Validation loss: 2.319727768500646

Epoch: 5| Step: 5
Training loss: 2.3123059272766113
Validation loss: 2.3177469124396644

Epoch: 5| Step: 6
Training loss: 2.2398757934570312
Validation loss: 2.315228750308355

Epoch: 5| Step: 7
Training loss: 2.0293335914611816
Validation loss: 2.3136708736419678

Epoch: 5| Step: 8
Training loss: 2.7400457859039307
Validation loss: 2.311532268921534

Epoch: 5| Step: 9
Training loss: 2.747568130493164
Validation loss: 2.308449720342954

Epoch: 5| Step: 10
Training loss: 1.7382972240447998
Validation loss: 2.3050998648007712

Epoch: 5| Step: 11
Training loss: 0.8449259400367737
Validation loss: 2.2994265307982764

Epoch: 53| Step: 0
Training loss: 2.0766708850860596
Validation loss: 2.294207418958346

Epoch: 5| Step: 1
Training loss: 2.6529290676116943
Validation loss: 2.2897601326306662

Epoch: 5| Step: 2
Training loss: 2.3599116802215576
Validation loss: 2.2897452116012573

Epoch: 5| Step: 3
Training loss: 2.4605648517608643
Validation loss: 2.2888386944929757

Epoch: 5| Step: 4
Training loss: 1.9960235357284546
Validation loss: 2.282019923130671

Epoch: 5| Step: 5
Training loss: 2.293116807937622
Validation loss: 2.2836656073729196

Epoch: 5| Step: 6
Training loss: 2.811143398284912
Validation loss: 2.2820223569869995

Epoch: 5| Step: 7
Training loss: 2.701819896697998
Validation loss: 2.2767267525196075

Epoch: 5| Step: 8
Training loss: 2.5610337257385254
Validation loss: 2.2765231976906457

Epoch: 5| Step: 9
Training loss: 2.5215272903442383
Validation loss: 2.2742004791895547

Epoch: 5| Step: 10
Training loss: 2.7276041507720947
Validation loss: 2.2692147195339203

Epoch: 5| Step: 11
Training loss: 1.5544753074645996
Validation loss: 2.2641626596450806

Epoch: 54| Step: 0
Training loss: 2.9805660247802734
Validation loss: 2.2637097239494324

Epoch: 5| Step: 1
Training loss: 2.3999814987182617
Validation loss: 2.2640082190434136

Epoch: 5| Step: 2
Training loss: 2.3901257514953613
Validation loss: 2.261916389067968

Epoch: 5| Step: 3
Training loss: 2.676251173019409
Validation loss: 2.255153109629949

Epoch: 5| Step: 4
Training loss: 2.312746047973633
Validation loss: 2.2605802019437156

Epoch: 5| Step: 5
Training loss: 2.2606589794158936
Validation loss: 2.2549915462732315

Epoch: 5| Step: 6
Training loss: 2.215141773223877
Validation loss: 2.259941021601359

Epoch: 5| Step: 7
Training loss: 1.948105812072754
Validation loss: 2.2473666220903397

Epoch: 5| Step: 8
Training loss: 2.089092254638672
Validation loss: 2.2452277888854346

Epoch: 5| Step: 9
Training loss: 2.6655898094177246
Validation loss: 2.2416387101014457

Epoch: 5| Step: 10
Training loss: 2.4141478538513184
Validation loss: 2.240951359272003

Epoch: 5| Step: 11
Training loss: 3.2120468616485596
Validation loss: 2.2381387650966644

Epoch: 55| Step: 0
Training loss: 1.9425456523895264
Validation loss: 2.2360563377539315

Epoch: 5| Step: 1
Training loss: 2.8795876502990723
Validation loss: 2.234675481915474

Epoch: 5| Step: 2
Training loss: 2.1305503845214844
Validation loss: 2.226902405420939

Epoch: 5| Step: 3
Training loss: 2.2673606872558594
Validation loss: 2.2282157440980277

Epoch: 5| Step: 4
Training loss: 2.2997803688049316
Validation loss: 2.222517559925715

Epoch: 5| Step: 5
Training loss: 2.4428036212921143
Validation loss: 2.227422217528025

Epoch: 5| Step: 6
Training loss: 1.9994112253189087
Validation loss: 2.2306548804044724

Epoch: 5| Step: 7
Training loss: 2.8298628330230713
Validation loss: 2.2342780431111655

Epoch: 5| Step: 8
Training loss: 2.687894821166992
Validation loss: 2.2139936884244285

Epoch: 5| Step: 9
Training loss: 2.344107151031494
Validation loss: 2.2071211338043213

Epoch: 5| Step: 10
Training loss: 2.053732395172119
Validation loss: 2.2007295986016593

Epoch: 5| Step: 11
Training loss: 3.429518699645996
Validation loss: 2.1968726913134256

Epoch: 56| Step: 0
Training loss: 2.383150100708008
Validation loss: 2.20735165476799

Epoch: 5| Step: 1
Training loss: 2.4892585277557373
Validation loss: 2.204184979200363

Epoch: 5| Step: 2
Training loss: 1.963311791419983
Validation loss: 2.2057145833969116

Epoch: 5| Step: 3
Training loss: 2.1678099632263184
Validation loss: 2.2076190213362374

Epoch: 5| Step: 4
Training loss: 2.7228474617004395
Validation loss: 2.2049990594387054

Epoch: 5| Step: 5
Training loss: 2.746325969696045
Validation loss: 2.203435927629471

Epoch: 5| Step: 6
Training loss: 2.2940709590911865
Validation loss: 2.2007672687371573

Epoch: 5| Step: 7
Training loss: 2.7537436485290527
Validation loss: 2.1991591453552246

Epoch: 5| Step: 8
Training loss: 1.780588150024414
Validation loss: 2.189003278811773

Epoch: 5| Step: 9
Training loss: 2.125162363052368
Validation loss: 2.1902208477258682

Epoch: 5| Step: 10
Training loss: 2.5014877319335938
Validation loss: 2.1852592527866364

Epoch: 5| Step: 11
Training loss: 2.2166342735290527
Validation loss: 2.17933589220047

Epoch: 57| Step: 0
Training loss: 2.3381829261779785
Validation loss: 2.178130636612574

Epoch: 5| Step: 1
Training loss: 2.4208500385284424
Validation loss: 2.1749800642331443

Epoch: 5| Step: 2
Training loss: 2.4574246406555176
Validation loss: 2.1704335113366446

Epoch: 5| Step: 3
Training loss: 2.7582449913024902
Validation loss: 2.170731077591578

Epoch: 5| Step: 4
Training loss: 2.3393630981445312
Validation loss: 2.1675963451464972

Epoch: 5| Step: 5
Training loss: 2.063554286956787
Validation loss: 2.166509618361791

Epoch: 5| Step: 6
Training loss: 2.345869302749634
Validation loss: 2.1671217878659568

Epoch: 5| Step: 7
Training loss: 2.0789072513580322
Validation loss: 2.1634565691153207

Epoch: 5| Step: 8
Training loss: 2.5400755405426025
Validation loss: 2.1650918324788413

Epoch: 5| Step: 9
Training loss: 1.8695354461669922
Validation loss: 2.1631032675504684

Epoch: 5| Step: 10
Training loss: 2.140261650085449
Validation loss: 2.166499679287275

Epoch: 5| Step: 11
Training loss: 3.1321535110473633
Validation loss: 2.169664223988851

Epoch: 58| Step: 0
Training loss: 2.6261849403381348
Validation loss: 2.1646297772725425

Epoch: 5| Step: 1
Training loss: 2.0927319526672363
Validation loss: 2.1588951845963797

Epoch: 5| Step: 2
Training loss: 2.6684045791625977
Validation loss: 2.1505351861317954

Epoch: 5| Step: 3
Training loss: 2.0146777629852295
Validation loss: 2.153262843688329

Epoch: 5| Step: 4
Training loss: 2.6854963302612305
Validation loss: 2.153158778945605

Epoch: 5| Step: 5
Training loss: 2.4795825481414795
Validation loss: 2.14654033879439

Epoch: 5| Step: 6
Training loss: 2.4666008949279785
Validation loss: 2.151433691382408

Epoch: 5| Step: 7
Training loss: 2.1030449867248535
Validation loss: 2.148195748527845

Epoch: 5| Step: 8
Training loss: 2.4680938720703125
Validation loss: 2.1471653829018273

Epoch: 5| Step: 9
Training loss: 2.215372085571289
Validation loss: 2.1430515001217523

Epoch: 5| Step: 10
Training loss: 1.6704202890396118
Validation loss: 2.140308906634649

Epoch: 5| Step: 11
Training loss: 1.7501140832901
Validation loss: 2.135062982638677

Epoch: 59| Step: 0
Training loss: 1.7018448114395142
Validation loss: 2.135254884759585

Epoch: 5| Step: 1
Training loss: 1.9127391576766968
Validation loss: 2.1360593686501184

Epoch: 5| Step: 2
Training loss: 2.3833673000335693
Validation loss: 2.1341135601202645

Epoch: 5| Step: 3
Training loss: 2.8158211708068848
Validation loss: 2.1385672241449356

Epoch: 5| Step: 4
Training loss: 1.956934928894043
Validation loss: 2.143039792776108

Epoch: 5| Step: 5
Training loss: 2.1111838817596436
Validation loss: 2.1468186577161155

Epoch: 5| Step: 6
Training loss: 1.8787195682525635
Validation loss: 2.1345953792333603

Epoch: 5| Step: 7
Training loss: 2.0943408012390137
Validation loss: 2.1486244599024453

Epoch: 5| Step: 8
Training loss: 2.855172634124756
Validation loss: 2.1418743977944055

Epoch: 5| Step: 9
Training loss: 2.4708759784698486
Validation loss: 2.131653701265653

Epoch: 5| Step: 10
Training loss: 2.9538605213165283
Validation loss: 2.1311000138521194

Epoch: 5| Step: 11
Training loss: 2.1542110443115234
Validation loss: 2.1239752570788064

Epoch: 60| Step: 0
Training loss: 2.431211471557617
Validation loss: 2.122608279188474

Epoch: 5| Step: 1
Training loss: 2.4584646224975586
Validation loss: 2.1238456269105277

Epoch: 5| Step: 2
Training loss: 1.602425217628479
Validation loss: 2.120171849926313

Epoch: 5| Step: 3
Training loss: 1.7780563831329346
Validation loss: 2.1208239694436393

Epoch: 5| Step: 4
Training loss: 2.2269480228424072
Validation loss: 2.1153042316436768

Epoch: 5| Step: 5
Training loss: 2.523433208465576
Validation loss: 2.1167814234892526

Epoch: 5| Step: 6
Training loss: 2.4183802604675293
Validation loss: 2.1188403169314065

Epoch: 5| Step: 7
Training loss: 2.584414005279541
Validation loss: 2.1238644421100616

Epoch: 5| Step: 8
Training loss: 2.6484718322753906
Validation loss: 2.129080057144165

Epoch: 5| Step: 9
Training loss: 2.096024513244629
Validation loss: 2.126731644074122

Epoch: 5| Step: 10
Training loss: 2.3502144813537598
Validation loss: 2.1229375849167504

Epoch: 5| Step: 11
Training loss: 2.023013114929199
Validation loss: 2.114507014552752

Epoch: 61| Step: 0
Training loss: 1.963781714439392
Validation loss: 2.1117670138676963

Epoch: 5| Step: 1
Training loss: 1.825832724571228
Validation loss: 2.1049216041962304

Epoch: 5| Step: 2
Training loss: 2.625704050064087
Validation loss: 2.10744978984197

Epoch: 5| Step: 3
Training loss: 2.714123487472534
Validation loss: 2.107305015126864

Epoch: 5| Step: 4
Training loss: 2.276996612548828
Validation loss: 2.11121828854084

Epoch: 5| Step: 5
Training loss: 2.6822259426116943
Validation loss: 2.109379028280576

Epoch: 5| Step: 6
Training loss: 2.3435049057006836
Validation loss: 2.1103268365065255

Epoch: 5| Step: 7
Training loss: 1.7929489612579346
Validation loss: 2.1085547506809235

Epoch: 5| Step: 8
Training loss: 2.105888843536377
Validation loss: 2.1268768906593323

Epoch: 5| Step: 9
Training loss: 2.092780590057373
Validation loss: 2.1347512702147164

Epoch: 5| Step: 10
Training loss: 2.683537244796753
Validation loss: 2.1340985000133514

Epoch: 5| Step: 11
Training loss: 2.5703890323638916
Validation loss: 2.129480615258217

Epoch: 62| Step: 0
Training loss: 2.3092358112335205
Validation loss: 2.129193037748337

Epoch: 5| Step: 1
Training loss: 2.9611265659332275
Validation loss: 2.123109921813011

Epoch: 5| Step: 2
Training loss: 2.5472583770751953
Validation loss: 2.12092591325442

Epoch: 5| Step: 3
Training loss: 2.104698419570923
Validation loss: 2.1123323192199073

Epoch: 5| Step: 4
Training loss: 2.142975330352783
Validation loss: 2.1135247151056924

Epoch: 5| Step: 5
Training loss: 2.282283067703247
Validation loss: 2.1083215177059174

Epoch: 5| Step: 6
Training loss: 1.9062073230743408
Validation loss: 2.108717362085978

Epoch: 5| Step: 7
Training loss: 1.8848936557769775
Validation loss: 2.1108863105376563

Epoch: 5| Step: 8
Training loss: 1.9162811040878296
Validation loss: 2.103080009420713

Epoch: 5| Step: 9
Training loss: 2.7019097805023193
Validation loss: 2.113831008474032

Epoch: 5| Step: 10
Training loss: 1.989007592201233
Validation loss: 2.107048581043879

Epoch: 5| Step: 11
Training loss: 3.352592706680298
Validation loss: 2.114469806353251

Epoch: 63| Step: 0
Training loss: 2.3848423957824707
Validation loss: 2.106498211622238

Epoch: 5| Step: 1
Training loss: 2.492661952972412
Validation loss: 2.1045707712570825

Epoch: 5| Step: 2
Training loss: 2.1720428466796875
Validation loss: 2.1042912205060325

Epoch: 5| Step: 3
Training loss: 2.2717604637145996
Validation loss: 2.1044971694548926

Epoch: 5| Step: 4
Training loss: 2.1181085109710693
Validation loss: 2.1024444103240967

Epoch: 5| Step: 5
Training loss: 2.451813220977783
Validation loss: 2.0978077153364816

Epoch: 5| Step: 6
Training loss: 2.4032866954803467
Validation loss: 2.090169350306193

Epoch: 5| Step: 7
Training loss: 1.9764635562896729
Validation loss: 2.0873130162556968

Epoch: 5| Step: 8
Training loss: 1.8231046199798584
Validation loss: 2.076626941561699

Epoch: 5| Step: 9
Training loss: 2.4929919242858887
Validation loss: 2.0699893832206726

Epoch: 5| Step: 10
Training loss: 2.112705945968628
Validation loss: 2.0687653869390488

Epoch: 5| Step: 11
Training loss: 3.042900323867798
Validation loss: 2.0707369099060693

Epoch: 64| Step: 0
Training loss: 3.028550148010254
Validation loss: 2.0759271482626596

Epoch: 5| Step: 1
Training loss: 1.838767409324646
Validation loss: 2.058956657846769

Epoch: 5| Step: 2
Training loss: 2.3815815448760986
Validation loss: 2.074148967862129

Epoch: 5| Step: 3
Training loss: 2.2182908058166504
Validation loss: 2.072050745288531

Epoch: 5| Step: 4
Training loss: 2.6157124042510986
Validation loss: 2.070786252617836

Epoch: 5| Step: 5
Training loss: 2.3046493530273438
Validation loss: 2.062914421161016

Epoch: 5| Step: 6
Training loss: 1.7911933660507202
Validation loss: 2.0601874043544135

Epoch: 5| Step: 7
Training loss: 1.9196208715438843
Validation loss: 2.067424386739731

Epoch: 5| Step: 8
Training loss: 1.8750293254852295
Validation loss: 2.056193768978119

Epoch: 5| Step: 9
Training loss: 2.3060340881347656
Validation loss: 2.0634222676356635

Epoch: 5| Step: 10
Training loss: 2.0880465507507324
Validation loss: 2.066804066300392

Epoch: 5| Step: 11
Training loss: 2.513148069381714
Validation loss: 2.0673135171333947

Epoch: 65| Step: 0
Training loss: 2.02952241897583
Validation loss: 2.0827487905820212

Epoch: 5| Step: 1
Training loss: 2.7675626277923584
Validation loss: 2.082433596253395

Epoch: 5| Step: 2
Training loss: 2.1027588844299316
Validation loss: 2.0786526600519815

Epoch: 5| Step: 3
Training loss: 2.42936635017395
Validation loss: 2.070613756775856

Epoch: 5| Step: 4
Training loss: 1.4736621379852295
Validation loss: 2.0624202638864517

Epoch: 5| Step: 5
Training loss: 2.2181339263916016
Validation loss: 2.056474814812342

Epoch: 5| Step: 6
Training loss: 2.5954368114471436
Validation loss: 2.0539001574118934

Epoch: 5| Step: 7
Training loss: 2.4394659996032715
Validation loss: 2.050416981180509

Epoch: 5| Step: 8
Training loss: 2.0982327461242676
Validation loss: 2.054931412140528

Epoch: 5| Step: 9
Training loss: 2.3308658599853516
Validation loss: 2.0497536808252335

Epoch: 5| Step: 10
Training loss: 1.8896076679229736
Validation loss: 2.047457883755366

Epoch: 5| Step: 11
Training loss: 2.737072229385376
Validation loss: 2.044709468881289

Epoch: 66| Step: 0
Training loss: 2.2981178760528564
Validation loss: 2.0550196220477424

Epoch: 5| Step: 1
Training loss: 2.8003957271575928
Validation loss: 2.061755354205767

Epoch: 5| Step: 2
Training loss: 1.8343225717544556
Validation loss: 2.078158309062322

Epoch: 5| Step: 3
Training loss: 2.077120304107666
Validation loss: 2.079833130041758

Epoch: 5| Step: 4
Training loss: 2.3283400535583496
Validation loss: 2.121724382042885

Epoch: 5| Step: 5
Training loss: 2.424762487411499
Validation loss: 2.0913961629072824

Epoch: 5| Step: 6
Training loss: 2.3449575901031494
Validation loss: 2.107123156388601

Epoch: 5| Step: 7
Training loss: 2.4422006607055664
Validation loss: 2.0749482015768685

Epoch: 5| Step: 8
Training loss: 2.008596897125244
Validation loss: 2.055119956533114

Epoch: 5| Step: 9
Training loss: 2.0934817790985107
Validation loss: 2.048886775970459

Epoch: 5| Step: 10
Training loss: 1.9983875751495361
Validation loss: 2.045188849171003

Epoch: 5| Step: 11
Training loss: 1.8534544706344604
Validation loss: 2.0449713667233786

Epoch: 67| Step: 0
Training loss: 2.7902348041534424
Validation loss: 2.061971048514048

Epoch: 5| Step: 1
Training loss: 2.262979507446289
Validation loss: 2.0773616979519525

Epoch: 5| Step: 2
Training loss: 2.067572832107544
Validation loss: 2.093775138258934

Epoch: 5| Step: 3
Training loss: 2.1906871795654297
Validation loss: 2.1137667844692865

Epoch: 5| Step: 4
Training loss: 2.2746269702911377
Validation loss: 2.1106962114572525

Epoch: 5| Step: 5
Training loss: 1.8602073192596436
Validation loss: 2.111679196357727

Epoch: 5| Step: 6
Training loss: 2.446784019470215
Validation loss: 2.110260287920634

Epoch: 5| Step: 7
Training loss: 2.504323720932007
Validation loss: 2.110138247410456

Epoch: 5| Step: 8
Training loss: 2.558208703994751
Validation loss: 2.1014383981625238

Epoch: 5| Step: 9
Training loss: 2.2988781929016113
Validation loss: 2.0928269078334174

Epoch: 5| Step: 10
Training loss: 1.5795081853866577
Validation loss: 2.0853819847106934

Epoch: 5| Step: 11
Training loss: 3.462475299835205
Validation loss: 2.080713306864103

Epoch: 68| Step: 0
Training loss: 2.0239994525909424
Validation loss: 2.069575438896815

Epoch: 5| Step: 1
Training loss: 2.137756586074829
Validation loss: 2.066229855020841

Epoch: 5| Step: 2
Training loss: 2.3171639442443848
Validation loss: 2.0562274555365243

Epoch: 5| Step: 3
Training loss: 2.2875237464904785
Validation loss: 2.0560523122549057

Epoch: 5| Step: 4
Training loss: 1.9226020574569702
Validation loss: 2.0573397427797318

Epoch: 5| Step: 5
Training loss: 2.326587200164795
Validation loss: 2.055397480726242

Epoch: 5| Step: 6
Training loss: 2.101109027862549
Validation loss: 2.052070304751396

Epoch: 5| Step: 7
Training loss: 3.1429996490478516
Validation loss: 2.058443988362948

Epoch: 5| Step: 8
Training loss: 2.246345043182373
Validation loss: 2.0548438231150308

Epoch: 5| Step: 9
Training loss: 2.180022716522217
Validation loss: 2.0543071975310645

Epoch: 5| Step: 10
Training loss: 2.337632656097412
Validation loss: 2.049210617939631

Epoch: 5| Step: 11
Training loss: 0.6446857452392578
Validation loss: 2.0477800567944846

Epoch: 69| Step: 0
Training loss: 1.8879235982894897
Validation loss: 2.0481816679239273

Epoch: 5| Step: 1
Training loss: 2.5704731941223145
Validation loss: 2.0413152327140174

Epoch: 5| Step: 2
Training loss: 2.5954718589782715
Validation loss: 2.0382686207691827

Epoch: 5| Step: 3
Training loss: 2.1488735675811768
Validation loss: 2.034411390622457

Epoch: 5| Step: 4
Training loss: 2.423861026763916
Validation loss: 2.037134493390719

Epoch: 5| Step: 5
Training loss: 1.7011610269546509
Validation loss: 2.0298644651969275

Epoch: 5| Step: 6
Training loss: 2.4995479583740234
Validation loss: 2.0315124789873757

Epoch: 5| Step: 7
Training loss: 2.515442132949829
Validation loss: 2.0349164605140686

Epoch: 5| Step: 8
Training loss: 2.4849486351013184
Validation loss: 2.0426857322454453

Epoch: 5| Step: 9
Training loss: 1.6513572931289673
Validation loss: 2.041805386543274

Epoch: 5| Step: 10
Training loss: 1.8674700260162354
Validation loss: 2.0417334586381912

Epoch: 5| Step: 11
Training loss: 2.006119966506958
Validation loss: 2.0407701333363852

Epoch: 70| Step: 0
Training loss: 2.3731961250305176
Validation loss: 2.063754657904307

Epoch: 5| Step: 1
Training loss: 2.400402545928955
Validation loss: 2.0654207319021225

Epoch: 5| Step: 2
Training loss: 2.5307230949401855
Validation loss: 2.0643784354130426

Epoch: 5| Step: 3
Training loss: 1.9554851055145264
Validation loss: 2.0655497113863626

Epoch: 5| Step: 4
Training loss: 2.3526766300201416
Validation loss: 2.062302440404892

Epoch: 5| Step: 5
Training loss: 2.2415339946746826
Validation loss: 2.060955728093783

Epoch: 5| Step: 6
Training loss: 2.360621213912964
Validation loss: 2.056688686211904

Epoch: 5| Step: 7
Training loss: 2.3797097206115723
Validation loss: 2.054704964160919

Epoch: 5| Step: 8
Training loss: 1.751643419265747
Validation loss: 2.058631738026937

Epoch: 5| Step: 9
Training loss: 1.82193124294281
Validation loss: 2.054529512921969

Epoch: 5| Step: 10
Training loss: 2.2730865478515625
Validation loss: 2.0439189076423645

Epoch: 5| Step: 11
Training loss: 1.2483742237091064
Validation loss: 2.0366718024015427

Epoch: 71| Step: 0
Training loss: 2.92836856842041
Validation loss: 2.0300607085227966

Epoch: 5| Step: 1
Training loss: 2.1349451541900635
Validation loss: 2.029019206762314

Epoch: 5| Step: 2
Training loss: 2.0891401767730713
Validation loss: 2.026820292075475

Epoch: 5| Step: 3
Training loss: 2.4018311500549316
Validation loss: 2.0300286263227463

Epoch: 5| Step: 4
Training loss: 2.5341827869415283
Validation loss: 2.029059494535128

Epoch: 5| Step: 5
Training loss: 1.7018169164657593
Validation loss: 2.030655344327291

Epoch: 5| Step: 6
Training loss: 1.8756835460662842
Validation loss: 2.0252868284781775

Epoch: 5| Step: 7
Training loss: 1.3856737613677979
Validation loss: 2.02869842449824

Epoch: 5| Step: 8
Training loss: 2.2825515270233154
Validation loss: 2.026195988059044

Epoch: 5| Step: 9
Training loss: 2.062285900115967
Validation loss: 2.0253564765055976

Epoch: 5| Step: 10
Training loss: 2.572680711746216
Validation loss: 2.02435173590978

Epoch: 5| Step: 11
Training loss: 2.659555435180664
Validation loss: 2.0259679605563483

Epoch: 72| Step: 0
Training loss: 1.9372804164886475
Validation loss: 2.0250553290049234

Epoch: 5| Step: 1
Training loss: 2.0680110454559326
Validation loss: 2.0261988093455634

Epoch: 5| Step: 2
Training loss: 2.171926736831665
Validation loss: 2.022540509700775

Epoch: 5| Step: 3
Training loss: 2.4152252674102783
Validation loss: 2.025064930319786

Epoch: 5| Step: 4
Training loss: 2.3719170093536377
Validation loss: 2.0217353155215583

Epoch: 5| Step: 5
Training loss: 2.108076333999634
Validation loss: 2.0227417995532355

Epoch: 5| Step: 6
Training loss: 1.8183963298797607
Validation loss: 2.031717603405317

Epoch: 5| Step: 7
Training loss: 2.4726643562316895
Validation loss: 2.026039863626162

Epoch: 5| Step: 8
Training loss: 2.4856650829315186
Validation loss: 2.0287193606297174

Epoch: 5| Step: 9
Training loss: 1.6572465896606445
Validation loss: 2.0302106042702994

Epoch: 5| Step: 10
Training loss: 2.601792573928833
Validation loss: 2.0226110915342965

Epoch: 5| Step: 11
Training loss: 1.598891258239746
Validation loss: 2.042161683241526

Epoch: 73| Step: 0
Training loss: 2.1156840324401855
Validation loss: 2.045109430948893

Epoch: 5| Step: 1
Training loss: 2.2949717044830322
Validation loss: 2.057286813855171

Epoch: 5| Step: 2
Training loss: 1.6525287628173828
Validation loss: 2.055010293920835

Epoch: 5| Step: 3
Training loss: 2.2261767387390137
Validation loss: 2.0609975159168243

Epoch: 5| Step: 4
Training loss: 1.810344934463501
Validation loss: 2.0738230496644974

Epoch: 5| Step: 5
Training loss: 1.926966905593872
Validation loss: 2.0665556639432907

Epoch: 5| Step: 6
Training loss: 2.1939806938171387
Validation loss: 2.0562053124109902

Epoch: 5| Step: 7
Training loss: 2.882068395614624
Validation loss: 2.0496462235848107

Epoch: 5| Step: 8
Training loss: 2.666238307952881
Validation loss: 2.032667820652326

Epoch: 5| Step: 9
Training loss: 2.592562675476074
Validation loss: 2.028800676266352

Epoch: 5| Step: 10
Training loss: 1.6935898065567017
Validation loss: 2.0255484531323114

Epoch: 5| Step: 11
Training loss: 2.032661199569702
Validation loss: 2.0211781014998755

Epoch: 74| Step: 0
Training loss: 2.3946778774261475
Validation loss: 2.0292589714129767

Epoch: 5| Step: 1
Training loss: 2.1453497409820557
Validation loss: 2.0355326533317566

Epoch: 5| Step: 2
Training loss: 2.763657808303833
Validation loss: 2.0339538206656775

Epoch: 5| Step: 3
Training loss: 2.0803170204162598
Validation loss: 2.043593352039655

Epoch: 5| Step: 4
Training loss: 1.6889946460723877
Validation loss: 2.043840969602267

Epoch: 5| Step: 5
Training loss: 2.012213706970215
Validation loss: 2.0429829955101013

Epoch: 5| Step: 6
Training loss: 1.934185266494751
Validation loss: 2.045193483432134

Epoch: 5| Step: 7
Training loss: 1.9052696228027344
Validation loss: 2.0419440219799676

Epoch: 5| Step: 8
Training loss: 2.708299398422241
Validation loss: 2.0454981674750647

Epoch: 5| Step: 9
Training loss: 2.0986006259918213
Validation loss: 2.041683634122213

Epoch: 5| Step: 10
Training loss: 2.7985808849334717
Validation loss: 2.040216068426768

Epoch: 5| Step: 11
Training loss: 1.3182413578033447
Validation loss: 2.0341068555911384

Epoch: 75| Step: 0
Training loss: 2.0889475345611572
Validation loss: 2.0284503599007926

Epoch: 5| Step: 1
Training loss: 2.00954008102417
Validation loss: 2.0280278523763022

Epoch: 5| Step: 2
Training loss: 2.290686845779419
Validation loss: 2.0243311127026877

Epoch: 5| Step: 3
Training loss: 2.404212236404419
Validation loss: 2.0177848041057587

Epoch: 5| Step: 4
Training loss: 2.1408755779266357
Validation loss: 2.0116170942783356

Epoch: 5| Step: 5
Training loss: 2.344494342803955
Validation loss: 2.015815883874893

Epoch: 5| Step: 6
Training loss: 2.565258026123047
Validation loss: 2.0300612449645996

Epoch: 5| Step: 7
Training loss: 2.2220771312713623
Validation loss: 2.0394890904426575

Epoch: 5| Step: 8
Training loss: 1.942664384841919
Validation loss: 2.0412460615237555

Epoch: 5| Step: 9
Training loss: 1.921400785446167
Validation loss: 2.0357821782430015

Epoch: 5| Step: 10
Training loss: 2.0526676177978516
Validation loss: 2.040311058362325

Epoch: 5| Step: 11
Training loss: 2.6812186241149902
Validation loss: 2.0250478287537894

Epoch: 76| Step: 0
Training loss: 2.4442429542541504
Validation loss: 2.023919939994812

Epoch: 5| Step: 1
Training loss: 2.0739827156066895
Validation loss: 2.0226752112309136

Epoch: 5| Step: 2
Training loss: 2.1888210773468018
Validation loss: 2.0170699656009674

Epoch: 5| Step: 3
Training loss: 2.2366671562194824
Validation loss: 2.0176948457956314

Epoch: 5| Step: 4
Training loss: 2.4054269790649414
Validation loss: 2.0197282234827676

Epoch: 5| Step: 5
Training loss: 2.0612614154815674
Validation loss: 2.0192775080601373

Epoch: 5| Step: 6
Training loss: 2.0626511573791504
Validation loss: 2.0319324185450873

Epoch: 5| Step: 7
Training loss: 2.4379608631134033
Validation loss: 2.0474633276462555

Epoch: 5| Step: 8
Training loss: 2.302560567855835
Validation loss: 2.0586123764514923

Epoch: 5| Step: 9
Training loss: 1.7119462490081787
Validation loss: 2.040085112055143

Epoch: 5| Step: 10
Training loss: 2.1281020641326904
Validation loss: 2.044874126712481

Epoch: 5| Step: 11
Training loss: 1.9063396453857422
Validation loss: 2.0461835861206055

Epoch: 77| Step: 0
Training loss: 1.9584888219833374
Validation loss: 2.035148546099663

Epoch: 5| Step: 1
Training loss: 2.663815975189209
Validation loss: 2.0281434655189514

Epoch: 5| Step: 2
Training loss: 1.9251238107681274
Validation loss: 2.025780419508616

Epoch: 5| Step: 3
Training loss: 1.6897176504135132
Validation loss: 2.027884249885877

Epoch: 5| Step: 4
Training loss: 2.3151869773864746
Validation loss: 2.027535463372866

Epoch: 5| Step: 5
Training loss: 2.1396937370300293
Validation loss: 2.035388429959615

Epoch: 5| Step: 6
Training loss: 2.8818888664245605
Validation loss: 2.025869091351827

Epoch: 5| Step: 7
Training loss: 2.3325793743133545
Validation loss: 2.0234397699435553

Epoch: 5| Step: 8
Training loss: 1.8404185771942139
Validation loss: 2.0308852742115655

Epoch: 5| Step: 9
Training loss: 1.7380517721176147
Validation loss: 2.0250800301631293

Epoch: 5| Step: 10
Training loss: 2.1910758018493652
Validation loss: 2.011028324564298

Epoch: 5| Step: 11
Training loss: 2.689258575439453
Validation loss: 2.0198063254356384

Epoch: 78| Step: 0
Training loss: 2.3973007202148438
Validation loss: 2.022366056839625

Epoch: 5| Step: 1
Training loss: 2.028621196746826
Validation loss: 2.025127962231636

Epoch: 5| Step: 2
Training loss: 2.465926170349121
Validation loss: 2.022079110145569

Epoch: 5| Step: 3
Training loss: 1.8636184930801392
Validation loss: 2.0346203297376633

Epoch: 5| Step: 4
Training loss: 2.146453380584717
Validation loss: 2.0281320065259933

Epoch: 5| Step: 5
Training loss: 1.7476533651351929
Validation loss: 2.034984732667605

Epoch: 5| Step: 6
Training loss: 2.4362292289733887
Validation loss: 2.023199518521627

Epoch: 5| Step: 7
Training loss: 1.9701309204101562
Validation loss: 2.026512091358503

Epoch: 5| Step: 8
Training loss: 2.0931148529052734
Validation loss: 2.0290841658910117

Epoch: 5| Step: 9
Training loss: 2.2660980224609375
Validation loss: 2.0192726055781045

Epoch: 5| Step: 10
Training loss: 2.5873806476593018
Validation loss: 2.012171889344851

Epoch: 5| Step: 11
Training loss: 2.1718249320983887
Validation loss: 2.00475804011027

Epoch: 79| Step: 0
Training loss: 1.9278796911239624
Validation loss: 2.012532730897268

Epoch: 5| Step: 1
Training loss: 2.476670980453491
Validation loss: 2.0202460835377374

Epoch: 5| Step: 2
Training loss: 1.748101830482483
Validation loss: 2.0179615368445716

Epoch: 5| Step: 3
Training loss: 2.274697780609131
Validation loss: 2.0234761387109756

Epoch: 5| Step: 4
Training loss: 1.6325438022613525
Validation loss: 2.023920019467672

Epoch: 5| Step: 5
Training loss: 2.0097129344940186
Validation loss: 2.025481472412745

Epoch: 5| Step: 6
Training loss: 2.2350754737854004
Validation loss: 2.0271094044049582

Epoch: 5| Step: 7
Training loss: 1.9984519481658936
Validation loss: 2.035951167345047

Epoch: 5| Step: 8
Training loss: 2.9064316749572754
Validation loss: 2.0436504036188126

Epoch: 5| Step: 9
Training loss: 1.8289577960968018
Validation loss: 2.041392798225085

Epoch: 5| Step: 10
Training loss: 2.643916130065918
Validation loss: 2.046249901254972

Epoch: 5| Step: 11
Training loss: 3.6551895141601562
Validation loss: 2.0433901945749917

Epoch: 80| Step: 0
Training loss: 2.497349739074707
Validation loss: 2.0337727268536887

Epoch: 5| Step: 1
Training loss: 1.5567854642868042
Validation loss: 2.0247057725985846

Epoch: 5| Step: 2
Training loss: 1.8947029113769531
Validation loss: 2.0174064884583154

Epoch: 5| Step: 3
Training loss: 2.59875226020813
Validation loss: 2.0268971771001816

Epoch: 5| Step: 4
Training loss: 2.2603604793548584
Validation loss: 2.0318822910388312

Epoch: 5| Step: 5
Training loss: 1.8726478815078735
Validation loss: 2.035595248142878

Epoch: 5| Step: 6
Training loss: 1.8323278427124023
Validation loss: 2.038416584332784

Epoch: 5| Step: 7
Training loss: 3.0637364387512207
Validation loss: 2.036854773759842

Epoch: 5| Step: 8
Training loss: 2.1977388858795166
Validation loss: 2.036647563179334

Epoch: 5| Step: 9
Training loss: 1.6890935897827148
Validation loss: 2.041899318496386

Epoch: 5| Step: 10
Training loss: 2.4504358768463135
Validation loss: 2.039426172773043

Epoch: 5| Step: 11
Training loss: 1.4341840744018555
Validation loss: 2.0363203336795173

Epoch: 81| Step: 0
Training loss: 2.0424883365631104
Validation loss: 2.0292704850435257

Epoch: 5| Step: 1
Training loss: 1.8160419464111328
Validation loss: 2.025280604759852

Epoch: 5| Step: 2
Training loss: 2.2684898376464844
Validation loss: 2.022237151861191

Epoch: 5| Step: 3
Training loss: 2.102248191833496
Validation loss: 2.0191792150338492

Epoch: 5| Step: 4
Training loss: 2.439513683319092
Validation loss: 2.0162141919136047

Epoch: 5| Step: 5
Training loss: 2.0622777938842773
Validation loss: 2.0199455122152963

Epoch: 5| Step: 6
Training loss: 2.585766315460205
Validation loss: 2.023756061991056

Epoch: 5| Step: 7
Training loss: 1.8109499216079712
Validation loss: 2.0089826931556067

Epoch: 5| Step: 8
Training loss: 1.7631824016571045
Validation loss: 2.0262315422296524

Epoch: 5| Step: 9
Training loss: 1.9290058612823486
Validation loss: 2.036382019519806

Epoch: 5| Step: 10
Training loss: 3.1025848388671875
Validation loss: 2.0391264061133065

Epoch: 5| Step: 11
Training loss: 1.6820861101150513
Validation loss: 2.0270325342814126

Epoch: 82| Step: 0
Training loss: 2.539900302886963
Validation loss: 2.0162306328614554

Epoch: 5| Step: 1
Training loss: 2.3354649543762207
Validation loss: 2.019686515132586

Epoch: 5| Step: 2
Training loss: 2.144747495651245
Validation loss: 2.0239404092232385

Epoch: 5| Step: 3
Training loss: 2.193723201751709
Validation loss: 2.017730404933294

Epoch: 5| Step: 4
Training loss: 1.583176851272583
Validation loss: 2.021346772710482

Epoch: 5| Step: 5
Training loss: 2.6702423095703125
Validation loss: 2.0181546211242676

Epoch: 5| Step: 6
Training loss: 2.080965042114258
Validation loss: 2.0167507429917655

Epoch: 5| Step: 7
Training loss: 1.9955308437347412
Validation loss: 2.018180022637049

Epoch: 5| Step: 8
Training loss: 2.1950888633728027
Validation loss: 2.019986311594645

Epoch: 5| Step: 9
Training loss: 1.8254283666610718
Validation loss: 2.0164669354756675

Epoch: 5| Step: 10
Training loss: 2.189514636993408
Validation loss: 2.0237380117177963

Epoch: 5| Step: 11
Training loss: 2.2324838638305664
Validation loss: 2.029587542017301

Epoch: 83| Step: 0
Training loss: 1.8613150119781494
Validation loss: 2.038311700026194

Epoch: 5| Step: 1
Training loss: 2.5221409797668457
Validation loss: 2.0381861428419747

Epoch: 5| Step: 2
Training loss: 1.7138217687606812
Validation loss: 2.041675721605619

Epoch: 5| Step: 3
Training loss: 2.2821714878082275
Validation loss: 2.0583015332619348

Epoch: 5| Step: 4
Training loss: 2.3100674152374268
Validation loss: 2.0561426281929016

Epoch: 5| Step: 5
Training loss: 2.2940869331359863
Validation loss: 2.0490851998329163

Epoch: 5| Step: 6
Training loss: 2.4044597148895264
Validation loss: 2.0486449946959815

Epoch: 5| Step: 7
Training loss: 2.29870867729187
Validation loss: 2.047564153869947

Epoch: 5| Step: 8
Training loss: 2.3545632362365723
Validation loss: 2.041477476557096

Epoch: 5| Step: 9
Training loss: 1.361577033996582
Validation loss: 2.0319591412941613

Epoch: 5| Step: 10
Training loss: 2.1364192962646484
Validation loss: 2.0338576585054398

Epoch: 5| Step: 11
Training loss: 3.958101749420166
Validation loss: 2.0356276084979377

Epoch: 84| Step: 0
Training loss: 1.7997944355010986
Validation loss: 2.0261075695355735

Epoch: 5| Step: 1
Training loss: 2.116934299468994
Validation loss: 2.0328317085901895

Epoch: 5| Step: 2
Training loss: 2.4815521240234375
Validation loss: 2.034693568944931

Epoch: 5| Step: 3
Training loss: 1.9382158517837524
Validation loss: 2.046727811296781

Epoch: 5| Step: 4
Training loss: 1.6747747659683228
Validation loss: 2.048203061024348

Epoch: 5| Step: 5
Training loss: 2.111110210418701
Validation loss: 2.0529384265343347

Epoch: 5| Step: 6
Training loss: 2.112281322479248
Validation loss: 2.0704318384329476

Epoch: 5| Step: 7
Training loss: 1.9458396434783936
Validation loss: 2.0690689235925674

Epoch: 5| Step: 8
Training loss: 2.5787291526794434
Validation loss: 2.0662944316864014

Epoch: 5| Step: 9
Training loss: 2.422564744949341
Validation loss: 2.0651637812455497

Epoch: 5| Step: 10
Training loss: 2.341848850250244
Validation loss: 2.0515125642220178

Epoch: 5| Step: 11
Training loss: 2.4193387031555176
Validation loss: 2.0535264362891517

Epoch: 85| Step: 0
Training loss: 2.0716559886932373
Validation loss: 2.048916762073835

Epoch: 5| Step: 1
Training loss: 2.355672836303711
Validation loss: 2.0331570307413735

Epoch: 5| Step: 2
Training loss: 2.3609116077423096
Validation loss: 2.0314385344584784

Epoch: 5| Step: 3
Training loss: 2.0211145877838135
Validation loss: 2.0225105583667755

Epoch: 5| Step: 4
Training loss: 1.952781081199646
Validation loss: 2.0181246300538382

Epoch: 5| Step: 5
Training loss: 2.0789103507995605
Validation loss: 2.0212565263112388

Epoch: 5| Step: 6
Training loss: 2.22837495803833
Validation loss: 2.0293361047903695

Epoch: 5| Step: 7
Training loss: 2.1515135765075684
Validation loss: 2.028985475500425

Epoch: 5| Step: 8
Training loss: 2.4094653129577637
Validation loss: 2.0276418228944144

Epoch: 5| Step: 9
Training loss: 2.1997694969177246
Validation loss: 2.0294685860474906

Epoch: 5| Step: 10
Training loss: 2.0526885986328125
Validation loss: 2.0314923922220864

Epoch: 5| Step: 11
Training loss: 1.7383787631988525
Validation loss: 2.0204356412092843

Epoch: 86| Step: 0
Training loss: 2.143899917602539
Validation loss: 2.0221061607201896

Epoch: 5| Step: 1
Training loss: 2.275564670562744
Validation loss: 2.021740665038427

Epoch: 5| Step: 2
Training loss: 2.2475152015686035
Validation loss: 2.016902819275856

Epoch: 5| Step: 3
Training loss: 2.2080447673797607
Validation loss: 2.020728513598442

Epoch: 5| Step: 4
Training loss: 1.9923816919326782
Validation loss: 2.018465538819631

Epoch: 5| Step: 5
Training loss: 2.2421512603759766
Validation loss: 2.01874286433061

Epoch: 5| Step: 6
Training loss: 1.7146539688110352
Validation loss: 2.0153072824080787

Epoch: 5| Step: 7
Training loss: 1.8834359645843506
Validation loss: 2.0235278457403183

Epoch: 5| Step: 8
Training loss: 2.7952229976654053
Validation loss: 2.0210842142502465

Epoch: 5| Step: 9
Training loss: 2.382847309112549
Validation loss: 2.02557443579038

Epoch: 5| Step: 10
Training loss: 1.9159409999847412
Validation loss: 2.032202109694481

Epoch: 5| Step: 11
Training loss: 1.5770245790481567
Validation loss: 2.0473942110935845

Epoch: 87| Step: 0
Training loss: 2.381357192993164
Validation loss: 2.0524090081453323

Epoch: 5| Step: 1
Training loss: 2.2032530307769775
Validation loss: 2.0690530439217887

Epoch: 5| Step: 2
Training loss: 1.9147443771362305
Validation loss: 2.0662839661041894

Epoch: 5| Step: 3
Training loss: 2.304466724395752
Validation loss: 2.0736225495735803

Epoch: 5| Step: 4
Training loss: 1.9190070629119873
Validation loss: 2.074525475502014

Epoch: 5| Step: 5
Training loss: 1.9011976718902588
Validation loss: 2.0644773840904236

Epoch: 5| Step: 6
Training loss: 2.035733699798584
Validation loss: 2.0549582888682685

Epoch: 5| Step: 7
Training loss: 2.0947577953338623
Validation loss: 2.042541096607844

Epoch: 5| Step: 8
Training loss: 2.522808790206909
Validation loss: 2.03339284658432

Epoch: 5| Step: 9
Training loss: 2.1404476165771484
Validation loss: 2.0290708392858505

Epoch: 5| Step: 10
Training loss: 2.4682538509368896
Validation loss: 2.0184278190135956

Epoch: 5| Step: 11
Training loss: 1.7547953128814697
Validation loss: 2.009055515130361

Epoch: 88| Step: 0
Training loss: 1.6173194646835327
Validation loss: 2.020520180463791

Epoch: 5| Step: 1
Training loss: 2.9608898162841797
Validation loss: 2.024292543530464

Epoch: 5| Step: 2
Training loss: 2.5140812397003174
Validation loss: 2.0252904146909714

Epoch: 5| Step: 3
Training loss: 2.6592178344726562
Validation loss: 2.019717420140902

Epoch: 5| Step: 4
Training loss: 1.8668581247329712
Validation loss: 2.0260159770647683

Epoch: 5| Step: 5
Training loss: 1.6141836643218994
Validation loss: 2.028494973977407

Epoch: 5| Step: 6
Training loss: 2.4297618865966797
Validation loss: 2.027933677037557

Epoch: 5| Step: 7
Training loss: 1.8446003198623657
Validation loss: 2.0323203603426614

Epoch: 5| Step: 8
Training loss: 1.9793426990509033
Validation loss: 2.0211260418097177

Epoch: 5| Step: 9
Training loss: 2.307553768157959
Validation loss: 2.0238894522190094

Epoch: 5| Step: 10
Training loss: 1.9393094778060913
Validation loss: 2.0188206930955253

Epoch: 5| Step: 11
Training loss: 2.298421859741211
Validation loss: 2.015740007162094

Epoch: 89| Step: 0
Training loss: 1.992614984512329
Validation loss: 2.02516999344031

Epoch: 5| Step: 1
Training loss: 2.2222933769226074
Validation loss: 2.0173030147949853

Epoch: 5| Step: 2
Training loss: 1.6961774826049805
Validation loss: 2.022862195968628

Epoch: 5| Step: 3
Training loss: 2.113935708999634
Validation loss: 2.0170734773079553

Epoch: 5| Step: 4
Training loss: 2.0284762382507324
Validation loss: 2.019128908713659

Epoch: 5| Step: 5
Training loss: 2.489687919616699
Validation loss: 2.0152334024508796

Epoch: 5| Step: 6
Training loss: 2.207318067550659
Validation loss: 2.0264904350042343

Epoch: 5| Step: 7
Training loss: 2.292435884475708
Validation loss: 2.022924472888311

Epoch: 5| Step: 8
Training loss: 2.0462355613708496
Validation loss: 2.0256324658791223

Epoch: 5| Step: 9
Training loss: 2.1890921592712402
Validation loss: 2.028893232345581

Epoch: 5| Step: 10
Training loss: 2.3524534702301025
Validation loss: 2.0316098580757775

Epoch: 5| Step: 11
Training loss: 2.0317258834838867
Validation loss: 2.0282164762417474

Epoch: 90| Step: 0
Training loss: 2.591625690460205
Validation loss: 2.0235733340183892

Epoch: 5| Step: 1
Training loss: 2.0537607669830322
Validation loss: 2.0161532908678055

Epoch: 5| Step: 2
Training loss: 2.647308826446533
Validation loss: 2.023345078031222

Epoch: 5| Step: 3
Training loss: 2.313786029815674
Validation loss: 2.0193796704212823

Epoch: 5| Step: 4
Training loss: 2.3600268363952637
Validation loss: 2.0113900204499564

Epoch: 5| Step: 5
Training loss: 0.9988945126533508
Validation loss: 2.0181900709867477

Epoch: 5| Step: 6
Training loss: 2.3890388011932373
Validation loss: 2.0152675906817117

Epoch: 5| Step: 7
Training loss: 1.9127365350723267
Validation loss: 2.0159557461738586

Epoch: 5| Step: 8
Training loss: 2.1128463745117188
Validation loss: 2.0134668797254562

Epoch: 5| Step: 9
Training loss: 2.745375394821167
Validation loss: 2.0112479676802955

Epoch: 5| Step: 10
Training loss: 1.6584784984588623
Validation loss: 2.0190979540348053

Epoch: 5| Step: 11
Training loss: 0.8577003479003906
Validation loss: 2.0146811107794442

Epoch: 91| Step: 0
Training loss: 2.3711891174316406
Validation loss: 2.014003425836563

Epoch: 5| Step: 1
Training loss: 2.190258502960205
Validation loss: 2.019410476088524

Epoch: 5| Step: 2
Training loss: 2.3303849697113037
Validation loss: 2.018768310546875

Epoch: 5| Step: 3
Training loss: 2.213346242904663
Validation loss: 2.029190793633461

Epoch: 5| Step: 4
Training loss: 2.0442285537719727
Validation loss: 2.039045731226603

Epoch: 5| Step: 5
Training loss: 1.857107162475586
Validation loss: 2.045706624786059

Epoch: 5| Step: 6
Training loss: 2.0316243171691895
Validation loss: 2.0460854719082513

Epoch: 5| Step: 7
Training loss: 2.524284601211548
Validation loss: 2.0587187012036643

Epoch: 5| Step: 8
Training loss: 1.6348819732666016
Validation loss: 2.052756279706955

Epoch: 5| Step: 9
Training loss: 2.466630458831787
Validation loss: 2.0635324716567993

Epoch: 5| Step: 10
Training loss: 1.97101628780365
Validation loss: 2.0539967815081277

Epoch: 5| Step: 11
Training loss: 2.2581787109375
Validation loss: 2.048739403486252

Epoch: 92| Step: 0
Training loss: 1.7693204879760742
Validation loss: 2.0496642341216407

Epoch: 5| Step: 1
Training loss: 2.092567205429077
Validation loss: 2.043254186709722

Epoch: 5| Step: 2
Training loss: 2.108104705810547
Validation loss: 2.0446014354626336

Epoch: 5| Step: 3
Training loss: 2.6173548698425293
Validation loss: 2.038576513528824

Epoch: 5| Step: 4
Training loss: 1.9544585943222046
Validation loss: 2.0298882325490317

Epoch: 5| Step: 5
Training loss: 2.2026612758636475
Validation loss: 2.0242921312650046

Epoch: 5| Step: 6
Training loss: 2.4040234088897705
Validation loss: 2.0159121056397757

Epoch: 5| Step: 7
Training loss: 1.7619946002960205
Validation loss: 2.0165194322665534

Epoch: 5| Step: 8
Training loss: 2.1704132556915283
Validation loss: 2.026589587330818

Epoch: 5| Step: 9
Training loss: 2.409411907196045
Validation loss: 2.022341728210449

Epoch: 5| Step: 10
Training loss: 2.147372007369995
Validation loss: 2.019561087091764

Epoch: 5| Step: 11
Training loss: 1.6629966497421265
Validation loss: 2.018800506989161

Epoch: 93| Step: 0
Training loss: 2.4304299354553223
Validation loss: 2.023185208439827

Epoch: 5| Step: 1
Training loss: 1.9426288604736328
Validation loss: 2.026355763276418

Epoch: 5| Step: 2
Training loss: 1.915772795677185
Validation loss: 2.030066808064779

Epoch: 5| Step: 3
Training loss: 2.1273679733276367
Validation loss: 2.028732051452001

Epoch: 5| Step: 4
Training loss: 2.248403549194336
Validation loss: 2.0329450269540152

Epoch: 5| Step: 5
Training loss: 1.9293444156646729
Validation loss: 2.02536208430926

Epoch: 5| Step: 6
Training loss: 2.1938862800598145
Validation loss: 2.024335394303004

Epoch: 5| Step: 7
Training loss: 2.064206600189209
Validation loss: 2.0240193009376526

Epoch: 5| Step: 8
Training loss: 2.3183531761169434
Validation loss: 2.0232044061024985

Epoch: 5| Step: 9
Training loss: 1.8301341533660889
Validation loss: 2.040358061591784

Epoch: 5| Step: 10
Training loss: 2.506415843963623
Validation loss: 2.0394658694664636

Epoch: 5| Step: 11
Training loss: 2.719925880432129
Validation loss: 2.042862276236216

Epoch: 94| Step: 0
Training loss: 1.9601128101348877
Validation loss: 2.0405203700065613

Epoch: 5| Step: 1
Training loss: 1.5068539381027222
Validation loss: 2.050824840863546

Epoch: 5| Step: 2
Training loss: 2.2088937759399414
Validation loss: 2.0460835744937262

Epoch: 5| Step: 3
Training loss: 1.803389549255371
Validation loss: 2.0487197438875833

Epoch: 5| Step: 4
Training loss: 2.4328126907348633
Validation loss: 2.0503039260705314

Epoch: 5| Step: 5
Training loss: 2.4843361377716064
Validation loss: 2.043771723906199

Epoch: 5| Step: 6
Training loss: 2.7033534049987793
Validation loss: 2.040213957428932

Epoch: 5| Step: 7
Training loss: 1.646937608718872
Validation loss: 2.0381388813257217

Epoch: 5| Step: 8
Training loss: 2.4887166023254395
Validation loss: 2.0361859053373337

Epoch: 5| Step: 9
Training loss: 1.9728786945343018
Validation loss: 2.0327930798133216

Epoch: 5| Step: 10
Training loss: 2.2049801349639893
Validation loss: 2.0286702613035836

Epoch: 5| Step: 11
Training loss: 2.586831569671631
Validation loss: 2.0255070378383

Epoch: 95| Step: 0
Training loss: 1.9611459970474243
Validation loss: 2.0324182212352753

Epoch: 5| Step: 1
Training loss: 1.9986438751220703
Validation loss: 2.0382054348786673

Epoch: 5| Step: 2
Training loss: 1.6092805862426758
Validation loss: 2.0373844106992087

Epoch: 5| Step: 3
Training loss: 2.234724521636963
Validation loss: 2.0424111038446426

Epoch: 5| Step: 4
Training loss: 2.503539562225342
Validation loss: 2.0447357843319574

Epoch: 5| Step: 5
Training loss: 2.2430243492126465
Validation loss: 2.053171550234159

Epoch: 5| Step: 6
Training loss: 2.4607787132263184
Validation loss: 2.0504307001829147

Epoch: 5| Step: 7
Training loss: 2.4560818672180176
Validation loss: 2.058861111601194

Epoch: 5| Step: 8
Training loss: 1.4545767307281494
Validation loss: 2.0562462210655212

Epoch: 5| Step: 9
Training loss: 2.222618341445923
Validation loss: 2.0541597803433738

Epoch: 5| Step: 10
Training loss: 2.3953185081481934
Validation loss: 2.05500021080176

Epoch: 5| Step: 11
Training loss: 1.4476110935211182
Validation loss: 2.0538376669089

Epoch: 96| Step: 0
Training loss: 2.002938747406006
Validation loss: 2.0556246836980185

Epoch: 5| Step: 1
Training loss: 2.3627407550811768
Validation loss: 2.0551796158154807

Epoch: 5| Step: 2
Training loss: 2.127246856689453
Validation loss: 2.065239816904068

Epoch: 5| Step: 3
Training loss: 2.396212339401245
Validation loss: 2.0568292438983917

Epoch: 5| Step: 4
Training loss: 2.212214946746826
Validation loss: 2.0601448019345603

Epoch: 5| Step: 5
Training loss: 2.0295915603637695
Validation loss: 2.0589779913425446

Epoch: 5| Step: 6
Training loss: 2.1642680168151855
Validation loss: 2.0623574952284494

Epoch: 5| Step: 7
Training loss: 2.0756237506866455
Validation loss: 2.0581697771946588

Epoch: 5| Step: 8
Training loss: 2.0712084770202637
Validation loss: 2.0519723196824393

Epoch: 5| Step: 9
Training loss: 2.093130350112915
Validation loss: 2.0522580246130624

Epoch: 5| Step: 10
Training loss: 1.8320133686065674
Validation loss: 2.04270605246226

Epoch: 5| Step: 11
Training loss: 3.2270257472991943
Validation loss: 2.03242290019989

Epoch: 97| Step: 0
Training loss: 2.3166725635528564
Validation loss: 2.0179299811522164

Epoch: 5| Step: 1
Training loss: 1.820884108543396
Validation loss: 2.022952616214752

Epoch: 5| Step: 2
Training loss: 1.8189146518707275
Validation loss: 2.025759448607763

Epoch: 5| Step: 3
Training loss: 2.4100632667541504
Validation loss: 2.026921048760414

Epoch: 5| Step: 4
Training loss: 1.8469845056533813
Validation loss: 2.0276320576667786

Epoch: 5| Step: 5
Training loss: 2.6565802097320557
Validation loss: 2.034499684969584

Epoch: 5| Step: 6
Training loss: 2.0419907569885254
Validation loss: 2.0302135596672692

Epoch: 5| Step: 7
Training loss: 2.1529593467712402
Validation loss: 2.033807401855787

Epoch: 5| Step: 8
Training loss: 2.1840641498565674
Validation loss: 2.0303710053364434

Epoch: 5| Step: 9
Training loss: 2.5054831504821777
Validation loss: 2.025365114212036

Epoch: 5| Step: 10
Training loss: 2.1064257621765137
Validation loss: 2.0252700597047806

Epoch: 5| Step: 11
Training loss: 1.727630853652954
Validation loss: 2.021966407696406

Epoch: 98| Step: 0
Training loss: 1.7643604278564453
Validation loss: 2.0203589697678885

Epoch: 5| Step: 1
Training loss: 2.0887255668640137
Validation loss: 2.021417513489723

Epoch: 5| Step: 2
Training loss: 2.550654172897339
Validation loss: 2.0188385595877967

Epoch: 5| Step: 3
Training loss: 2.0904929637908936
Validation loss: 2.0130426237980523

Epoch: 5| Step: 4
Training loss: 2.1810827255249023
Validation loss: 2.0069850385189056

Epoch: 5| Step: 5
Training loss: 1.701972246170044
Validation loss: 2.00592103600502

Epoch: 5| Step: 6
Training loss: 2.570387363433838
Validation loss: 2.005798270304998

Epoch: 5| Step: 7
Training loss: 2.2542214393615723
Validation loss: 2.017424469192823

Epoch: 5| Step: 8
Training loss: 1.7756893634796143
Validation loss: 2.0172911485036216

Epoch: 5| Step: 9
Training loss: 2.260683298110962
Validation loss: 2.025287797053655

Epoch: 5| Step: 10
Training loss: 2.2145841121673584
Validation loss: 2.0203755547602973

Epoch: 5| Step: 11
Training loss: 2.7118148803710938
Validation loss: 2.0325443347295127

Epoch: 99| Step: 0
Training loss: 2.4628233909606934
Validation loss: 2.0331078469753265

Epoch: 5| Step: 1
Training loss: 2.1069624423980713
Validation loss: 2.0433651904265084

Epoch: 5| Step: 2
Training loss: 2.0242526531219482
Validation loss: 2.050078218181928

Epoch: 5| Step: 3
Training loss: 1.911949872970581
Validation loss: 2.049715439478556

Epoch: 5| Step: 4
Training loss: 2.3448574542999268
Validation loss: 2.051412751277288

Epoch: 5| Step: 5
Training loss: 2.063082218170166
Validation loss: 2.046860227982203

Epoch: 5| Step: 6
Training loss: 2.3775904178619385
Validation loss: 2.0522347390651703

Epoch: 5| Step: 7
Training loss: 1.6484884023666382
Validation loss: 2.057038977742195

Epoch: 5| Step: 8
Training loss: 2.039233446121216
Validation loss: 2.0468552162249884

Epoch: 5| Step: 9
Training loss: 2.416088581085205
Validation loss: 2.042178218563398

Epoch: 5| Step: 10
Training loss: 1.8230323791503906
Validation loss: 2.040262614687284

Epoch: 5| Step: 11
Training loss: 3.244344472885132
Validation loss: 2.0435660680135093

Epoch: 100| Step: 0
Training loss: 2.206268787384033
Validation loss: 2.032177577416102

Epoch: 5| Step: 1
Training loss: 2.0209662914276123
Validation loss: 2.0359592735767365

Epoch: 5| Step: 2
Training loss: 2.6059556007385254
Validation loss: 2.0312292675177255

Epoch: 5| Step: 3
Training loss: 1.6602833271026611
Validation loss: 2.0291004379590354

Epoch: 5| Step: 4
Training loss: 2.710728406906128
Validation loss: 2.035361036658287

Epoch: 5| Step: 5
Training loss: 1.4478651285171509
Validation loss: 2.0306481768687568

Epoch: 5| Step: 6
Training loss: 2.4560298919677734
Validation loss: 2.0315797477960587

Epoch: 5| Step: 7
Training loss: 2.6365771293640137
Validation loss: 2.0345101753870645

Epoch: 5| Step: 8
Training loss: 2.1492819786071777
Validation loss: 2.030870238939921

Epoch: 5| Step: 9
Training loss: 1.8862556219100952
Validation loss: 2.0352116028467813

Epoch: 5| Step: 10
Training loss: 1.5798718929290771
Validation loss: 2.0315838158130646

Epoch: 5| Step: 11
Training loss: 2.415578603744507
Validation loss: 2.0341458221276603

Testing loss: 1.7022910812775867
