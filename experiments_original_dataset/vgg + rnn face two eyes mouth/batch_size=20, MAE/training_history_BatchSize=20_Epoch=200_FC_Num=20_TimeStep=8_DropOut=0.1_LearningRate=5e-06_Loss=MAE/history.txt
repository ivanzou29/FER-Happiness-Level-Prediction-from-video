Epoch: 1| Step: 0
Training loss: 6.7916107177734375
Validation loss: 5.368156313896179

Epoch: 5| Step: 1
Training loss: 4.610041618347168
Validation loss: 5.366582612196605

Epoch: 5| Step: 2
Training loss: 5.543631553649902
Validation loss: 5.365026473999023

Epoch: 5| Step: 3
Training loss: 3.9173569679260254
Validation loss: 5.363502999146779

Epoch: 5| Step: 4
Training loss: 5.220422744750977
Validation loss: 5.361962656180064

Epoch: 5| Step: 5
Training loss: 4.7636542320251465
Validation loss: 5.36036604642868

Epoch: 5| Step: 6
Training loss: 6.5826416015625
Validation loss: 5.358742396036784

Epoch: 5| Step: 7
Training loss: 5.300702095031738
Validation loss: 5.357066631317139

Epoch: 5| Step: 8
Training loss: 4.794540882110596
Validation loss: 5.355342129866282

Epoch: 5| Step: 9
Training loss: 6.307154178619385
Validation loss: 5.353603521982829

Epoch: 5| Step: 10
Training loss: 5.880402565002441
Validation loss: 5.3518110911051435

Epoch: 5| Step: 11
Training loss: 5.462994575500488
Validation loss: 5.349942167599996

Epoch: 2| Step: 0
Training loss: 5.9564948081970215
Validation loss: 5.347895423571269

Epoch: 5| Step: 1
Training loss: 5.938319683074951
Validation loss: 5.3459042112032575

Epoch: 5| Step: 2
Training loss: 5.833394527435303
Validation loss: 5.343783299128215

Epoch: 5| Step: 3
Training loss: 4.989738464355469
Validation loss: 5.341542681058248

Epoch: 5| Step: 4
Training loss: 5.127592086791992
Validation loss: 5.339116394519806

Epoch: 5| Step: 5
Training loss: 5.063364028930664
Validation loss: 5.336659550666809

Epoch: 5| Step: 6
Training loss: 4.818472862243652
Validation loss: 5.334110736846924

Epoch: 5| Step: 7
Training loss: 5.032259941101074
Validation loss: 5.331400016943614

Epoch: 5| Step: 8
Training loss: 6.2126569747924805
Validation loss: 5.328418672084808

Epoch: 5| Step: 9
Training loss: 4.878911018371582
Validation loss: 5.325390378634135

Epoch: 5| Step: 10
Training loss: 5.604057788848877
Validation loss: 5.322234729925792

Epoch: 5| Step: 11
Training loss: 5.387255668640137
Validation loss: 5.318878591060638

Epoch: 3| Step: 0
Training loss: 5.765575408935547
Validation loss: 5.315285603205363

Epoch: 5| Step: 1
Training loss: 5.318976402282715
Validation loss: 5.311505675315857

Epoch: 5| Step: 2
Training loss: 4.724941253662109
Validation loss: 5.307444016138713

Epoch: 5| Step: 3
Training loss: 5.509666442871094
Validation loss: 5.303209662437439

Epoch: 5| Step: 4
Training loss: 4.743003845214844
Validation loss: 5.2985865871111555

Epoch: 5| Step: 5
Training loss: 6.044407367706299
Validation loss: 5.294026990731557

Epoch: 5| Step: 6
Training loss: 4.968870162963867
Validation loss: 5.289022624492645

Epoch: 5| Step: 7
Training loss: 5.177304267883301
Validation loss: 5.2835530042648315

Epoch: 5| Step: 8
Training loss: 5.1878581047058105
Validation loss: 5.277972380320231

Epoch: 5| Step: 9
Training loss: 5.737176418304443
Validation loss: 5.271757284800212

Epoch: 5| Step: 10
Training loss: 6.346585273742676
Validation loss: 5.265434960524241

Epoch: 5| Step: 11
Training loss: 2.5769636631011963
Validation loss: 5.258838613828023

Epoch: 4| Step: 0
Training loss: 5.2670135498046875
Validation loss: 5.25169825553894

Epoch: 5| Step: 1
Training loss: 5.227505207061768
Validation loss: 5.244393448034923

Epoch: 5| Step: 2
Training loss: 5.175869941711426
Validation loss: 5.236315707365672

Epoch: 5| Step: 3
Training loss: 5.525696754455566
Validation loss: 5.2282000581423445

Epoch: 5| Step: 4
Training loss: 5.023388862609863
Validation loss: 5.219663600126903

Epoch: 5| Step: 5
Training loss: 4.87509298324585
Validation loss: 5.2103867928187055

Epoch: 5| Step: 6
Training loss: 5.580927848815918
Validation loss: 5.200995028018951

Epoch: 5| Step: 7
Training loss: 5.599472522735596
Validation loss: 5.1914710601170855

Epoch: 5| Step: 8
Training loss: 5.806214332580566
Validation loss: 5.1814086238543196

Epoch: 5| Step: 9
Training loss: 4.930252552032471
Validation loss: 5.1711738506952925

Epoch: 5| Step: 10
Training loss: 5.23445463180542
Validation loss: 5.160590449968974

Epoch: 5| Step: 11
Training loss: 4.387599945068359
Validation loss: 5.149567623933156

Epoch: 5| Step: 0
Training loss: 5.215062141418457
Validation loss: 5.138527452945709

Epoch: 5| Step: 1
Training loss: 4.815989017486572
Validation loss: 5.127043724060059

Epoch: 5| Step: 2
Training loss: 4.9480719566345215
Validation loss: 5.116025189558665

Epoch: 5| Step: 3
Training loss: 5.595606803894043
Validation loss: 5.104307095209758

Epoch: 5| Step: 4
Training loss: 5.301870822906494
Validation loss: 5.092954576015472

Epoch: 5| Step: 5
Training loss: 4.911780834197998
Validation loss: 5.081903596719106

Epoch: 5| Step: 6
Training loss: 4.9912004470825195
Validation loss: 5.070464730262756

Epoch: 5| Step: 7
Training loss: 4.665286064147949
Validation loss: 5.059813320636749

Epoch: 5| Step: 8
Training loss: 5.3499226570129395
Validation loss: 5.048881908257802

Epoch: 5| Step: 9
Training loss: 5.986197471618652
Validation loss: 5.038095812002818

Epoch: 5| Step: 10
Training loss: 4.710400581359863
Validation loss: 5.027381400267283

Epoch: 5| Step: 11
Training loss: 6.404071807861328
Validation loss: 5.016959389050801

Epoch: 6| Step: 0
Training loss: 5.748641014099121
Validation loss: 5.006905535856883

Epoch: 5| Step: 1
Training loss: 5.663325309753418
Validation loss: 4.996596256891887

Epoch: 5| Step: 2
Training loss: 5.075659275054932
Validation loss: 4.986667970816295

Epoch: 5| Step: 3
Training loss: 4.576559543609619
Validation loss: 4.976496537526448

Epoch: 5| Step: 4
Training loss: 5.495323181152344
Validation loss: 4.966498633225759

Epoch: 5| Step: 5
Training loss: 4.620738983154297
Validation loss: 4.956918954849243

Epoch: 5| Step: 6
Training loss: 5.789952754974365
Validation loss: 4.946912884712219

Epoch: 5| Step: 7
Training loss: 4.44216251373291
Validation loss: 4.937328537305196

Epoch: 5| Step: 8
Training loss: 5.247069835662842
Validation loss: 4.927542984485626

Epoch: 5| Step: 9
Training loss: 4.23236608505249
Validation loss: 4.917965193589528

Epoch: 5| Step: 10
Training loss: 4.274115562438965
Validation loss: 4.908628880977631

Epoch: 5| Step: 11
Training loss: 6.384439945220947
Validation loss: 4.898843725522359

Epoch: 7| Step: 0
Training loss: 5.392197608947754
Validation loss: 4.889542937278748

Epoch: 5| Step: 1
Training loss: 4.6388139724731445
Validation loss: 4.879889349142711

Epoch: 5| Step: 2
Training loss: 4.949986934661865
Validation loss: 4.870546241601308

Epoch: 5| Step: 3
Training loss: 4.587288856506348
Validation loss: 4.860715985298157

Epoch: 5| Step: 4
Training loss: 5.260222434997559
Validation loss: 4.851636787255605

Epoch: 5| Step: 5
Training loss: 5.097782135009766
Validation loss: 4.841832925875981

Epoch: 5| Step: 6
Training loss: 4.1696319580078125
Validation loss: 4.832231849431992

Epoch: 5| Step: 7
Training loss: 5.4699907302856445
Validation loss: 4.823419213294983

Epoch: 5| Step: 8
Training loss: 4.390838146209717
Validation loss: 4.814412822326024

Epoch: 5| Step: 9
Training loss: 4.84539794921875
Validation loss: 4.805973211924235

Epoch: 5| Step: 10
Training loss: 5.169586181640625
Validation loss: 4.797148923079173

Epoch: 5| Step: 11
Training loss: 6.214652061462402
Validation loss: 4.789061685403188

Epoch: 8| Step: 0
Training loss: 5.418481349945068
Validation loss: 4.780603349208832

Epoch: 5| Step: 1
Training loss: 4.343214988708496
Validation loss: 4.772593388954799

Epoch: 5| Step: 2
Training loss: 4.9039716720581055
Validation loss: 4.764741082986196

Epoch: 5| Step: 3
Training loss: 6.277796268463135
Validation loss: 4.756789843241374

Epoch: 5| Step: 4
Training loss: 4.364855766296387
Validation loss: 4.748961309591929

Epoch: 5| Step: 5
Training loss: 4.441568374633789
Validation loss: 4.741225242614746

Epoch: 5| Step: 6
Training loss: 5.0614166259765625
Validation loss: 4.733522991339366

Epoch: 5| Step: 7
Training loss: 3.6776421070098877
Validation loss: 4.7258613506952925

Epoch: 5| Step: 8
Training loss: 4.274759769439697
Validation loss: 4.718451877435048

Epoch: 5| Step: 9
Training loss: 5.773608207702637
Validation loss: 4.710961401462555

Epoch: 5| Step: 10
Training loss: 5.2229084968566895
Validation loss: 4.703470408916473

Epoch: 5| Step: 11
Training loss: 1.8660600185394287
Validation loss: 4.696322808663051

Epoch: 9| Step: 0
Training loss: 5.394344329833984
Validation loss: 4.6887625853220625

Epoch: 5| Step: 1
Training loss: 4.862560272216797
Validation loss: 4.6811049083868665

Epoch: 5| Step: 2
Training loss: 3.9629225730895996
Validation loss: 4.673495968182881

Epoch: 5| Step: 3
Training loss: 3.9084808826446533
Validation loss: 4.665407796700795

Epoch: 5| Step: 4
Training loss: 4.401442527770996
Validation loss: 4.657902290423711

Epoch: 5| Step: 5
Training loss: 5.376569747924805
Validation loss: 4.649999499320984

Epoch: 5| Step: 6
Training loss: 4.747424602508545
Validation loss: 4.642291168371837

Epoch: 5| Step: 7
Training loss: 4.968841075897217
Validation loss: 4.63353955745697

Epoch: 5| Step: 8
Training loss: 4.373031139373779
Validation loss: 4.626227746407191

Epoch: 5| Step: 9
Training loss: 4.752902030944824
Validation loss: 4.618910173575084

Epoch: 5| Step: 10
Training loss: 5.451071739196777
Validation loss: 4.611462275187175

Epoch: 5| Step: 11
Training loss: 4.767333984375
Validation loss: 4.604088932275772

Epoch: 10| Step: 0
Training loss: 5.979077339172363
Validation loss: 4.595783432324727

Epoch: 5| Step: 1
Training loss: 3.0574440956115723
Validation loss: 4.588338087002437

Epoch: 5| Step: 2
Training loss: 5.225140571594238
Validation loss: 4.580520858367284

Epoch: 5| Step: 3
Training loss: 4.813774108886719
Validation loss: 4.572545985380809

Epoch: 5| Step: 4
Training loss: 4.237181186676025
Validation loss: 4.564737836519877

Epoch: 5| Step: 5
Training loss: 4.115365505218506
Validation loss: 4.557333211104075

Epoch: 5| Step: 6
Training loss: 4.970600128173828
Validation loss: 4.549524962902069

Epoch: 5| Step: 7
Training loss: 3.82572603225708
Validation loss: 4.542089521884918

Epoch: 5| Step: 8
Training loss: 4.27904748916626
Validation loss: 4.53416712085406

Epoch: 5| Step: 9
Training loss: 4.404417037963867
Validation loss: 4.526782115300496

Epoch: 5| Step: 10
Training loss: 5.965820789337158
Validation loss: 4.51895147562027

Epoch: 5| Step: 11
Training loss: 6.499554634094238
Validation loss: 4.511378586292267

Epoch: 11| Step: 0
Training loss: 4.886319160461426
Validation loss: 4.503867050011952

Epoch: 5| Step: 1
Training loss: 4.556986331939697
Validation loss: 4.496731281280518

Epoch: 5| Step: 2
Training loss: 3.5481972694396973
Validation loss: 4.48863673210144

Epoch: 5| Step: 3
Training loss: 4.149932861328125
Validation loss: 4.481485029061635

Epoch: 5| Step: 4
Training loss: 5.93740177154541
Validation loss: 4.473984618981679

Epoch: 5| Step: 5
Training loss: 4.85007905960083
Validation loss: 4.466602861881256

Epoch: 5| Step: 6
Training loss: 5.084734916687012
Validation loss: 4.458696673313777

Epoch: 5| Step: 7
Training loss: 4.930924415588379
Validation loss: 4.451187968254089

Epoch: 5| Step: 8
Training loss: 2.945070743560791
Validation loss: 4.443692584832509

Epoch: 5| Step: 9
Training loss: 4.726818084716797
Validation loss: 4.436288386583328

Epoch: 5| Step: 10
Training loss: 4.685691833496094
Validation loss: 4.429393231868744

Epoch: 5| Step: 11
Training loss: 4.741186618804932
Validation loss: 4.422684222459793

Epoch: 12| Step: 0
Training loss: 4.07621955871582
Validation loss: 4.415735026200612

Epoch: 5| Step: 1
Training loss: 4.954218864440918
Validation loss: 4.4100962082544966

Epoch: 5| Step: 2
Training loss: 4.724198341369629
Validation loss: 4.40398250023524

Epoch: 5| Step: 3
Training loss: 4.8012166023254395
Validation loss: 4.39740926027298

Epoch: 5| Step: 4
Training loss: 4.746205806732178
Validation loss: 4.3913852373758955

Epoch: 5| Step: 5
Training loss: 3.9569077491760254
Validation loss: 4.3853866557280226

Epoch: 5| Step: 6
Training loss: 5.042542934417725
Validation loss: 4.378902922074

Epoch: 5| Step: 7
Training loss: 4.570708274841309
Validation loss: 4.372598797082901

Epoch: 5| Step: 8
Training loss: 5.565125465393066
Validation loss: 4.366595953702927

Epoch: 5| Step: 9
Training loss: 3.3165996074676514
Validation loss: 4.359988858302434

Epoch: 5| Step: 10
Training loss: 3.6548244953155518
Validation loss: 4.3541121284166975

Epoch: 5| Step: 11
Training loss: 4.9972662925720215
Validation loss: 4.34801318248113

Epoch: 13| Step: 0
Training loss: 4.057188987731934
Validation loss: 4.34132319688797

Epoch: 5| Step: 1
Training loss: 4.051789283752441
Validation loss: 4.335503081480662

Epoch: 5| Step: 2
Training loss: 4.164975166320801
Validation loss: 4.3295592069625854

Epoch: 5| Step: 3
Training loss: 4.768099308013916
Validation loss: 4.324062426884969

Epoch: 5| Step: 4
Training loss: 4.794974327087402
Validation loss: 4.318462520837784

Epoch: 5| Step: 5
Training loss: 4.253709316253662
Validation loss: 4.312336027622223

Epoch: 5| Step: 6
Training loss: 4.557255744934082
Validation loss: 4.306217571099599

Epoch: 5| Step: 7
Training loss: 5.153160572052002
Validation loss: 4.299919446309407

Epoch: 5| Step: 8
Training loss: 4.011142253875732
Validation loss: 4.293748696645101

Epoch: 5| Step: 9
Training loss: 5.014212608337402
Validation loss: 4.287335475285848

Epoch: 5| Step: 10
Training loss: 3.822399139404297
Validation loss: 4.28149660428365

Epoch: 5| Step: 11
Training loss: 5.074862480163574
Validation loss: 4.275001287460327

Epoch: 14| Step: 0
Training loss: 4.610278129577637
Validation loss: 4.269306023915608

Epoch: 5| Step: 1
Training loss: 4.622191429138184
Validation loss: 4.263216465711594

Epoch: 5| Step: 2
Training loss: 4.365995407104492
Validation loss: 4.257222592830658

Epoch: 5| Step: 3
Training loss: 4.023952960968018
Validation loss: 4.251128375530243

Epoch: 5| Step: 4
Training loss: 5.066301345825195
Validation loss: 4.246175567309062

Epoch: 5| Step: 5
Training loss: 4.268499851226807
Validation loss: 4.240326543649037

Epoch: 5| Step: 6
Training loss: 3.975536346435547
Validation loss: 4.234792709350586

Epoch: 5| Step: 7
Training loss: 4.109869480133057
Validation loss: 4.2286912600199384

Epoch: 5| Step: 8
Training loss: 4.657630443572998
Validation loss: 4.222859998544057

Epoch: 5| Step: 9
Training loss: 4.481629371643066
Validation loss: 4.216368794441223

Epoch: 5| Step: 10
Training loss: 4.117739200592041
Validation loss: 4.21056987841924

Epoch: 5| Step: 11
Training loss: 3.1328070163726807
Validation loss: 4.204826811949412

Epoch: 15| Step: 0
Training loss: 4.132912635803223
Validation loss: 4.199415226777394

Epoch: 5| Step: 1
Training loss: 3.622445583343506
Validation loss: 4.193086554606755

Epoch: 5| Step: 2
Training loss: 4.822808265686035
Validation loss: 4.187628775835037

Epoch: 5| Step: 3
Training loss: 4.5110015869140625
Validation loss: 4.181509216626485

Epoch: 5| Step: 4
Training loss: 4.543410301208496
Validation loss: 4.1754933794339495

Epoch: 5| Step: 5
Training loss: 4.877810001373291
Validation loss: 4.169182111819585

Epoch: 5| Step: 6
Training loss: 4.456376075744629
Validation loss: 4.163446644941966

Epoch: 5| Step: 7
Training loss: 3.020200729370117
Validation loss: 4.15785139799118

Epoch: 5| Step: 8
Training loss: 4.8741774559021
Validation loss: 4.15200936794281

Epoch: 5| Step: 9
Training loss: 4.300148963928223
Validation loss: 4.145761768023173

Epoch: 5| Step: 10
Training loss: 4.026795864105225
Validation loss: 4.140081405639648

Epoch: 5| Step: 11
Training loss: 5.180021286010742
Validation loss: 4.134212970733643

Epoch: 16| Step: 0
Training loss: 3.6206154823303223
Validation loss: 4.128743847211202

Epoch: 5| Step: 1
Training loss: 3.584120988845825
Validation loss: 4.124084413051605

Epoch: 5| Step: 2
Training loss: 5.044561386108398
Validation loss: 4.118004123369853

Epoch: 5| Step: 3
Training loss: 4.45864200592041
Validation loss: 4.112577150265376

Epoch: 5| Step: 4
Training loss: 4.413134574890137
Validation loss: 4.107271363337834

Epoch: 5| Step: 5
Training loss: 3.76450777053833
Validation loss: 4.1014858682950335

Epoch: 5| Step: 6
Training loss: 4.053267478942871
Validation loss: 4.0963554581006365

Epoch: 5| Step: 7
Training loss: 4.482422351837158
Validation loss: 4.091412474711736

Epoch: 5| Step: 8
Training loss: 4.652319431304932
Validation loss: 4.085355222225189

Epoch: 5| Step: 9
Training loss: 3.667372226715088
Validation loss: 4.0794545610745745

Epoch: 5| Step: 10
Training loss: 5.277050971984863
Validation loss: 4.074335465828578

Epoch: 5| Step: 11
Training loss: 2.4462552070617676
Validation loss: 4.0693469643592834

Epoch: 17| Step: 0
Training loss: 4.5546674728393555
Validation loss: 4.064535588026047

Epoch: 5| Step: 1
Training loss: 4.052864074707031
Validation loss: 4.059346268574397

Epoch: 5| Step: 2
Training loss: 3.6733460426330566
Validation loss: 4.053376118342082

Epoch: 5| Step: 3
Training loss: 4.331829071044922
Validation loss: 4.048032959302266

Epoch: 5| Step: 4
Training loss: 5.202530860900879
Validation loss: 4.04274242122968

Epoch: 5| Step: 5
Training loss: 4.110537052154541
Validation loss: 4.037327766418457

Epoch: 5| Step: 6
Training loss: 5.01935338973999
Validation loss: 4.032371878623962

Epoch: 5| Step: 7
Training loss: 3.7331347465515137
Validation loss: 4.026810983816783

Epoch: 5| Step: 8
Training loss: 4.366138458251953
Validation loss: 4.021817793448766

Epoch: 5| Step: 9
Training loss: 3.5359854698181152
Validation loss: 4.0166210532188416

Epoch: 5| Step: 10
Training loss: 3.6573169231414795
Validation loss: 4.0115326543649035

Epoch: 5| Step: 11
Training loss: 2.9624176025390625
Validation loss: 4.006531198819478

Epoch: 18| Step: 0
Training loss: 4.30057430267334
Validation loss: 4.002260526021321

Epoch: 5| Step: 1
Training loss: 4.020704746246338
Validation loss: 3.9969978431860604

Epoch: 5| Step: 2
Training loss: 4.304060935974121
Validation loss: 3.9923546810944877

Epoch: 5| Step: 3
Training loss: 4.628365993499756
Validation loss: 3.987909197807312

Epoch: 5| Step: 4
Training loss: 3.827357530593872
Validation loss: 3.9831841389338174

Epoch: 5| Step: 5
Training loss: 3.5764355659484863
Validation loss: 3.9787464837233224

Epoch: 5| Step: 6
Training loss: 4.168030261993408
Validation loss: 3.974404772122701

Epoch: 5| Step: 7
Training loss: 3.805011034011841
Validation loss: 3.9688843886057534

Epoch: 5| Step: 8
Training loss: 4.207192897796631
Validation loss: 3.9648260275522866

Epoch: 5| Step: 9
Training loss: 4.007000923156738
Validation loss: 3.9601989487806954

Epoch: 5| Step: 10
Training loss: 4.704500675201416
Validation loss: 3.955754498640696

Epoch: 5| Step: 11
Training loss: 3.16046142578125
Validation loss: 3.9506102403004966

Epoch: 19| Step: 0
Training loss: 4.278358459472656
Validation loss: 3.945908308029175

Epoch: 5| Step: 1
Training loss: 4.770831108093262
Validation loss: 3.941731810569763

Epoch: 5| Step: 2
Training loss: 4.314591407775879
Validation loss: 3.9370349645614624

Epoch: 5| Step: 3
Training loss: 4.629778861999512
Validation loss: 3.9314493934313455

Epoch: 5| Step: 4
Training loss: 3.19024658203125
Validation loss: 3.926930328210195

Epoch: 5| Step: 5
Training loss: 3.7886054515838623
Validation loss: 3.921802838643392

Epoch: 5| Step: 6
Training loss: 4.12058162689209
Validation loss: 3.9180568158626556

Epoch: 5| Step: 7
Training loss: 4.531740665435791
Validation loss: 3.9131484925746918

Epoch: 5| Step: 8
Training loss: 3.5543434619903564
Validation loss: 3.9084035058816275

Epoch: 5| Step: 9
Training loss: 3.9451842308044434
Validation loss: 3.9036249121030173

Epoch: 5| Step: 10
Training loss: 3.5592129230499268
Validation loss: 3.898422727982203

Epoch: 5| Step: 11
Training loss: 4.526832580566406
Validation loss: 3.8940605918566384

Epoch: 20| Step: 0
Training loss: 5.187824249267578
Validation loss: 3.8895510733127594

Epoch: 5| Step: 1
Training loss: 3.907871961593628
Validation loss: 3.885184953610102

Epoch: 5| Step: 2
Training loss: 4.119441986083984
Validation loss: 3.8806904951731362

Epoch: 5| Step: 3
Training loss: 4.551926136016846
Validation loss: 3.876066933075587

Epoch: 5| Step: 4
Training loss: 4.187073707580566
Validation loss: 3.8714187343915305

Epoch: 5| Step: 5
Training loss: 3.943535327911377
Validation loss: 3.8664608895778656

Epoch: 5| Step: 6
Training loss: 3.6186344623565674
Validation loss: 3.8618680834770203

Epoch: 5| Step: 7
Training loss: 4.414702415466309
Validation loss: 3.8576559921105704

Epoch: 5| Step: 8
Training loss: 3.8285224437713623
Validation loss: 3.8528093794981637

Epoch: 5| Step: 9
Training loss: 3.173671007156372
Validation loss: 3.8478185137112937

Epoch: 5| Step: 10
Training loss: 3.5501046180725098
Validation loss: 3.843661924203237

Epoch: 5| Step: 11
Training loss: 2.6120495796203613
Validation loss: 3.838910569747289

Epoch: 21| Step: 0
Training loss: 3.7740142345428467
Validation loss: 3.8347664872805276

Epoch: 5| Step: 1
Training loss: 3.72900652885437
Validation loss: 3.8308837513128915

Epoch: 5| Step: 2
Training loss: 4.932214260101318
Validation loss: 3.8262840112050376

Epoch: 5| Step: 3
Training loss: 3.7039742469787598
Validation loss: 3.821994791428248

Epoch: 5| Step: 4
Training loss: 4.539125442504883
Validation loss: 3.8176136314868927

Epoch: 5| Step: 5
Training loss: 4.503750801086426
Validation loss: 3.813743611176809

Epoch: 5| Step: 6
Training loss: 3.988234281539917
Validation loss: 3.809710075457891

Epoch: 5| Step: 7
Training loss: 3.0455729961395264
Validation loss: 3.8054592410723367

Epoch: 5| Step: 8
Training loss: 3.719162702560425
Validation loss: 3.800629496574402

Epoch: 5| Step: 9
Training loss: 3.969245195388794
Validation loss: 3.796413669983546

Epoch: 5| Step: 10
Training loss: 3.491015911102295
Validation loss: 3.7920900881290436

Epoch: 5| Step: 11
Training loss: 5.255132675170898
Validation loss: 3.788306256135305

Epoch: 22| Step: 0
Training loss: 4.638857841491699
Validation loss: 3.7834944228331246

Epoch: 5| Step: 1
Training loss: 4.261697769165039
Validation loss: 3.7796416183312735

Epoch: 5| Step: 2
Training loss: 3.7234840393066406
Validation loss: 3.7754053473472595

Epoch: 5| Step: 3
Training loss: 3.620871067047119
Validation loss: 3.770969291528066

Epoch: 5| Step: 4
Training loss: 4.138594627380371
Validation loss: 3.766710788011551

Epoch: 5| Step: 5
Training loss: 4.659444332122803
Validation loss: 3.762577603260676

Epoch: 5| Step: 6
Training loss: 3.5893585681915283
Validation loss: 3.759199380874634

Epoch: 5| Step: 7
Training loss: 3.5795981884002686
Validation loss: 3.755282332499822

Epoch: 5| Step: 8
Training loss: 3.134584903717041
Validation loss: 3.750891367594401

Epoch: 5| Step: 9
Training loss: 3.5654590129852295
Validation loss: 3.7456126312414804

Epoch: 5| Step: 10
Training loss: 3.881843090057373
Validation loss: 3.741679698228836

Epoch: 5| Step: 11
Training loss: 5.618420600891113
Validation loss: 3.7371652722358704

Epoch: 23| Step: 0
Training loss: 3.6620635986328125
Validation loss: 3.732588072617849

Epoch: 5| Step: 1
Training loss: 4.422757625579834
Validation loss: 3.727929502725601

Epoch: 5| Step: 2
Training loss: 4.386481285095215
Validation loss: 3.7238427996635437

Epoch: 5| Step: 3
Training loss: 3.2024223804473877
Validation loss: 3.7195963660875955

Epoch: 5| Step: 4
Training loss: 4.370163917541504
Validation loss: 3.715377559264501

Epoch: 5| Step: 5
Training loss: 3.1333892345428467
Validation loss: 3.7114268640677133

Epoch: 5| Step: 6
Training loss: 3.583376407623291
Validation loss: 3.7071753243605294

Epoch: 5| Step: 7
Training loss: 4.303534030914307
Validation loss: 3.7028525869051614

Epoch: 5| Step: 8
Training loss: 3.6202919483184814
Validation loss: 3.6987571517626443

Epoch: 5| Step: 9
Training loss: 4.093369007110596
Validation loss: 3.6945324738820395

Epoch: 5| Step: 10
Training loss: 3.5082473754882812
Validation loss: 3.6903447608153024

Epoch: 5| Step: 11
Training loss: 5.3864850997924805
Validation loss: 3.6862967014312744

Epoch: 24| Step: 0
Training loss: 3.8282928466796875
Validation loss: 3.6829195419947305

Epoch: 5| Step: 1
Training loss: 3.5821807384490967
Validation loss: 3.6784318486849465

Epoch: 5| Step: 2
Training loss: 4.617305278778076
Validation loss: 3.674445221821467

Epoch: 5| Step: 3
Training loss: 3.9024932384490967
Validation loss: 3.669841388861338

Epoch: 5| Step: 4
Training loss: 3.1372952461242676
Validation loss: 3.6661263704299927

Epoch: 5| Step: 5
Training loss: 4.1322197914123535
Validation loss: 3.661997437477112

Epoch: 5| Step: 6
Training loss: 4.598625183105469
Validation loss: 3.65877835949262

Epoch: 5| Step: 7
Training loss: 3.160609483718872
Validation loss: 3.653487970431646

Epoch: 5| Step: 8
Training loss: 3.6756629943847656
Validation loss: 3.6489497423171997

Epoch: 5| Step: 9
Training loss: 3.1091740131378174
Validation loss: 3.6450068652629852

Epoch: 5| Step: 10
Training loss: 4.075312614440918
Validation loss: 3.641082396109899

Epoch: 5| Step: 11
Training loss: 5.03672981262207
Validation loss: 3.637573709090551

Epoch: 25| Step: 0
Training loss: 3.741856098175049
Validation loss: 3.6320902705192566

Epoch: 5| Step: 1
Training loss: 3.901871919631958
Validation loss: 3.628744771083196

Epoch: 5| Step: 2
Training loss: 2.893932342529297
Validation loss: 3.62364270289739

Epoch: 5| Step: 3
Training loss: 3.963054656982422
Validation loss: 3.6192510028680167

Epoch: 5| Step: 4
Training loss: 4.7176432609558105
Validation loss: 3.6147188444932303

Epoch: 5| Step: 5
Training loss: 4.014498233795166
Validation loss: 3.610372612873713

Epoch: 5| Step: 6
Training loss: 4.103818416595459
Validation loss: 3.6059924761454263

Epoch: 5| Step: 7
Training loss: 3.5730865001678467
Validation loss: 3.60127255320549

Epoch: 5| Step: 8
Training loss: 3.212596893310547
Validation loss: 3.5975645085175834

Epoch: 5| Step: 9
Training loss: 3.9396567344665527
Validation loss: 3.593031197786331

Epoch: 5| Step: 10
Training loss: 3.2914860248565674
Validation loss: 3.5886435210704803

Epoch: 5| Step: 11
Training loss: 4.590893745422363
Validation loss: 3.584456433852514

Epoch: 26| Step: 0
Training loss: 4.045651435852051
Validation loss: 3.58085705836614

Epoch: 5| Step: 1
Training loss: 4.305849552154541
Validation loss: 3.5758210023244223

Epoch: 5| Step: 2
Training loss: 3.693840503692627
Validation loss: 3.5712734957536063

Epoch: 5| Step: 3
Training loss: 3.733664035797119
Validation loss: 3.567043354113897

Epoch: 5| Step: 4
Training loss: 3.4610531330108643
Validation loss: 3.5619810819625854

Epoch: 5| Step: 5
Training loss: 3.7943954467773438
Validation loss: 3.5576814313729606

Epoch: 5| Step: 6
Training loss: 3.6720147132873535
Validation loss: 3.5538479884465537

Epoch: 5| Step: 7
Training loss: 3.113629102706909
Validation loss: 3.549615830183029

Epoch: 5| Step: 8
Training loss: 4.144251823425293
Validation loss: 3.5448821584383645

Epoch: 5| Step: 9
Training loss: 3.5023303031921387
Validation loss: 3.5400437911351523

Epoch: 5| Step: 10
Training loss: 3.16841197013855
Validation loss: 3.5357022682825723

Epoch: 5| Step: 11
Training loss: 5.270285129547119
Validation loss: 3.5320515036582947

Epoch: 27| Step: 0
Training loss: 3.84747052192688
Validation loss: 3.527891000111898

Epoch: 5| Step: 1
Training loss: 3.9292595386505127
Validation loss: 3.522312432527542

Epoch: 5| Step: 2
Training loss: 3.84399151802063
Validation loss: 3.518094152212143

Epoch: 5| Step: 3
Training loss: 4.1944427490234375
Validation loss: 3.5136041939258575

Epoch: 5| Step: 4
Training loss: 2.8224220275878906
Validation loss: 3.5088555415471396

Epoch: 5| Step: 5
Training loss: 3.525050401687622
Validation loss: 3.5050090750058494

Epoch: 5| Step: 6
Training loss: 3.8254127502441406
Validation loss: 3.5007842977841697

Epoch: 5| Step: 7
Training loss: 3.4015355110168457
Validation loss: 3.4959990084171295

Epoch: 5| Step: 8
Training loss: 4.253808498382568
Validation loss: 3.491656631231308

Epoch: 5| Step: 9
Training loss: 3.45784068107605
Validation loss: 3.487923930088679

Epoch: 5| Step: 10
Training loss: 2.947056531906128
Validation loss: 3.483365664879481

Epoch: 5| Step: 11
Training loss: 5.309802055358887
Validation loss: 3.478726933399836

Epoch: 28| Step: 0
Training loss: 2.938516616821289
Validation loss: 3.4738544523715973

Epoch: 5| Step: 1
Training loss: 4.226432800292969
Validation loss: 3.4701987206935883

Epoch: 5| Step: 2
Training loss: 2.8795084953308105
Validation loss: 3.465618441502253

Epoch: 5| Step: 3
Training loss: 4.538465976715088
Validation loss: 3.461874783039093

Epoch: 5| Step: 4
Training loss: 3.7212860584259033
Validation loss: 3.457436273495356

Epoch: 5| Step: 5
Training loss: 3.494938373565674
Validation loss: 3.4536772072315216

Epoch: 5| Step: 6
Training loss: 3.2633426189422607
Validation loss: 3.4493144849936166

Epoch: 5| Step: 7
Training loss: 3.093423366546631
Validation loss: 3.4437427719434104

Epoch: 5| Step: 8
Training loss: 3.9982211589813232
Validation loss: 3.440327217181524

Epoch: 5| Step: 9
Training loss: 3.003577709197998
Validation loss: 3.4365747769673667

Epoch: 5| Step: 10
Training loss: 4.468639373779297
Validation loss: 3.431321124235789

Epoch: 5| Step: 11
Training loss: 4.454304218292236
Validation loss: 3.426692624886831

Epoch: 29| Step: 0
Training loss: 3.3167564868927
Validation loss: 3.422347446282705

Epoch: 5| Step: 1
Training loss: 3.9020087718963623
Validation loss: 3.417644331852595

Epoch: 5| Step: 2
Training loss: 3.431919813156128
Validation loss: 3.413021355867386

Epoch: 5| Step: 3
Training loss: 3.184546947479248
Validation loss: 3.4084111154079437

Epoch: 5| Step: 4
Training loss: 3.8374545574188232
Validation loss: 3.403769542773565

Epoch: 5| Step: 5
Training loss: 3.121814012527466
Validation loss: 3.3986909588178

Epoch: 5| Step: 6
Training loss: 4.554518699645996
Validation loss: 3.392983873685201

Epoch: 5| Step: 7
Training loss: 3.8420493602752686
Validation loss: 3.387783666451772

Epoch: 5| Step: 8
Training loss: 3.50292706489563
Validation loss: 3.3822948733965554

Epoch: 5| Step: 9
Training loss: 2.9686756134033203
Validation loss: 3.3778714636961618

Epoch: 5| Step: 10
Training loss: 3.4191811084747314
Validation loss: 3.3740837772687278

Epoch: 5| Step: 11
Training loss: 4.3194732666015625
Validation loss: 3.3690175314744315

Epoch: 30| Step: 0
Training loss: 4.063820838928223
Validation loss: 3.3651911914348602

Epoch: 5| Step: 1
Training loss: 4.095646381378174
Validation loss: 3.3602976302305856

Epoch: 5| Step: 2
Training loss: 3.2729549407958984
Validation loss: 3.3564682404200235

Epoch: 5| Step: 3
Training loss: 3.487257719039917
Validation loss: 3.3508641918500266

Epoch: 5| Step: 4
Training loss: 3.7952048778533936
Validation loss: 3.3456108967463174

Epoch: 5| Step: 5
Training loss: 3.6988487243652344
Validation loss: 3.3419184585412345

Epoch: 5| Step: 6
Training loss: 4.127123832702637
Validation loss: 3.336250424385071

Epoch: 5| Step: 7
Training loss: 2.8451600074768066
Validation loss: 3.331654647986094

Epoch: 5| Step: 8
Training loss: 2.7426276206970215
Validation loss: 3.327607731024424

Epoch: 5| Step: 9
Training loss: 3.3517394065856934
Validation loss: 3.3234672248363495

Epoch: 5| Step: 10
Training loss: 3.0332162380218506
Validation loss: 3.3189679980278015

Epoch: 5| Step: 11
Training loss: 4.207973480224609
Validation loss: 3.314696421225866

Epoch: 31| Step: 0
Training loss: 3.6541953086853027
Validation loss: 3.3109131256739297

Epoch: 5| Step: 1
Training loss: 3.354736804962158
Validation loss: 3.306243727604548

Epoch: 5| Step: 2
Training loss: 3.6060707569122314
Validation loss: 3.301939755678177

Epoch: 5| Step: 3
Training loss: 3.2037582397460938
Validation loss: 3.298153688510259

Epoch: 5| Step: 4
Training loss: 3.3751683235168457
Validation loss: 3.293802718321482

Epoch: 5| Step: 5
Training loss: 3.597383499145508
Validation loss: 3.289526015520096

Epoch: 5| Step: 6
Training loss: 3.037140369415283
Validation loss: 3.2851469417413077

Epoch: 5| Step: 7
Training loss: 3.9368820190429688
Validation loss: 3.2810078064600625

Epoch: 5| Step: 8
Training loss: 3.7565200328826904
Validation loss: 3.277146408955256

Epoch: 5| Step: 9
Training loss: 3.7064623832702637
Validation loss: 3.2730893989404044

Epoch: 5| Step: 10
Training loss: 3.127861499786377
Validation loss: 3.269048680861791

Epoch: 5| Step: 11
Training loss: 2.368939161300659
Validation loss: 3.264704614877701

Epoch: 32| Step: 0
Training loss: 3.948307752609253
Validation loss: 3.2614685694376626

Epoch: 5| Step: 1
Training loss: 2.8866491317749023
Validation loss: 3.2573599914709725

Epoch: 5| Step: 2
Training loss: 3.579119920730591
Validation loss: 3.253717452287674

Epoch: 5| Step: 3
Training loss: 3.401970624923706
Validation loss: 3.2494084239006042

Epoch: 5| Step: 4
Training loss: 2.608722686767578
Validation loss: 3.245803713798523

Epoch: 5| Step: 5
Training loss: 3.4169769287109375
Validation loss: 3.2419165670871735

Epoch: 5| Step: 6
Training loss: 3.8237738609313965
Validation loss: 3.237957696119944

Epoch: 5| Step: 7
Training loss: 3.901218891143799
Validation loss: 3.234588086605072

Epoch: 5| Step: 8
Training loss: 3.769310712814331
Validation loss: 3.2309184968471527

Epoch: 5| Step: 9
Training loss: 2.581052780151367
Validation loss: 3.226497769355774

Epoch: 5| Step: 10
Training loss: 3.9580352306365967
Validation loss: 3.2227633396784463

Epoch: 5| Step: 11
Training loss: 2.1903934478759766
Validation loss: 3.2187082767486572

Epoch: 33| Step: 0
Training loss: 2.800090789794922
Validation loss: 3.214726448059082

Epoch: 5| Step: 1
Training loss: 2.980181932449341
Validation loss: 3.2106686929861703

Epoch: 5| Step: 2
Training loss: 3.769315242767334
Validation loss: 3.206656833489736

Epoch: 5| Step: 3
Training loss: 3.283339023590088
Validation loss: 3.2024269898732505

Epoch: 5| Step: 4
Training loss: 3.049915313720703
Validation loss: 3.198812315861384

Epoch: 5| Step: 5
Training loss: 3.764514207839966
Validation loss: 3.194574544827143

Epoch: 5| Step: 6
Training loss: 3.2818551063537598
Validation loss: 3.1908090114593506

Epoch: 5| Step: 7
Training loss: 3.2171261310577393
Validation loss: 3.18645108739535

Epoch: 5| Step: 8
Training loss: 3.5777580738067627
Validation loss: 3.1823912958304086

Epoch: 5| Step: 9
Training loss: 4.396628379821777
Validation loss: 3.1779811084270477

Epoch: 5| Step: 10
Training loss: 2.998541831970215
Validation loss: 3.1738020479679108

Epoch: 5| Step: 11
Training loss: 3.528080940246582
Validation loss: 3.1697946389516196

Epoch: 34| Step: 0
Training loss: 2.5020813941955566
Validation loss: 3.165717442830404

Epoch: 5| Step: 1
Training loss: 3.4920716285705566
Validation loss: 3.1617666482925415

Epoch: 5| Step: 2
Training loss: 3.9664466381073
Validation loss: 3.1583561400572457

Epoch: 5| Step: 3
Training loss: 3.0118355751037598
Validation loss: 3.154829611380895

Epoch: 5| Step: 4
Training loss: 3.4131550788879395
Validation loss: 3.15032696723938

Epoch: 5| Step: 5
Training loss: 2.927151679992676
Validation loss: 3.1479352513949075

Epoch: 5| Step: 6
Training loss: 3.82267689704895
Validation loss: 3.1431167821089425

Epoch: 5| Step: 7
Training loss: 3.149204969406128
Validation loss: 3.13882847627004

Epoch: 5| Step: 8
Training loss: 3.6689505577087402
Validation loss: 3.135248064994812

Epoch: 5| Step: 9
Training loss: 3.2560813426971436
Validation loss: 3.1310467620690665

Epoch: 5| Step: 10
Training loss: 3.3827595710754395
Validation loss: 3.12689678867658

Epoch: 5| Step: 11
Training loss: 3.6087512969970703
Validation loss: 3.122912218173345

Epoch: 35| Step: 0
Training loss: 3.761890411376953
Validation loss: 3.11815282702446

Epoch: 5| Step: 1
Training loss: 3.9558520317077637
Validation loss: 3.114412635564804

Epoch: 5| Step: 2
Training loss: 3.7252373695373535
Validation loss: 3.1102201541264853

Epoch: 5| Step: 3
Training loss: 2.7566604614257812
Validation loss: 3.105680763721466

Epoch: 5| Step: 4
Training loss: 2.604346752166748
Validation loss: 3.1011250714461007

Epoch: 5| Step: 5
Training loss: 3.0765562057495117
Validation loss: 3.097582330306371

Epoch: 5| Step: 6
Training loss: 2.9019439220428467
Validation loss: 3.0941466689109802

Epoch: 5| Step: 7
Training loss: 3.087960720062256
Validation loss: 3.0904669562975564

Epoch: 5| Step: 8
Training loss: 3.8010830879211426
Validation loss: 3.0867976446946463

Epoch: 5| Step: 9
Training loss: 3.5639195442199707
Validation loss: 3.083530475695928

Epoch: 5| Step: 10
Training loss: 2.5327117443084717
Validation loss: 3.079657475153605

Epoch: 5| Step: 11
Training loss: 5.23079776763916
Validation loss: 3.0761599640051522

Epoch: 36| Step: 0
Training loss: 3.470360279083252
Validation loss: 3.0722035070260367

Epoch: 5| Step: 1
Training loss: 2.4961516857147217
Validation loss: 3.0680277248223624

Epoch: 5| Step: 2
Training loss: 3.8836886882781982
Validation loss: 3.064119597276052

Epoch: 5| Step: 3
Training loss: 2.8943660259246826
Validation loss: 3.060058832168579

Epoch: 5| Step: 4
Training loss: 2.6063849925994873
Validation loss: 3.0560388366381326

Epoch: 5| Step: 5
Training loss: 3.6790924072265625
Validation loss: 3.052696923414866

Epoch: 5| Step: 6
Training loss: 2.8260884284973145
Validation loss: 3.048633029063543

Epoch: 5| Step: 7
Training loss: 3.222425937652588
Validation loss: 3.0452479223410287

Epoch: 5| Step: 8
Training loss: 4.051468372344971
Validation loss: 3.041464457909266

Epoch: 5| Step: 9
Training loss: 2.745166540145874
Validation loss: 3.037281413873037

Epoch: 5| Step: 10
Training loss: 3.8345627784729004
Validation loss: 3.0335768361886344

Epoch: 5| Step: 11
Training loss: 3.0485434532165527
Validation loss: 3.0297663708527884

Epoch: 37| Step: 0
Training loss: 2.984591007232666
Validation loss: 3.0262919068336487

Epoch: 5| Step: 1
Training loss: 3.1207520961761475
Validation loss: 3.023061523834864

Epoch: 5| Step: 2
Training loss: 2.919015407562256
Validation loss: 3.019410957892736

Epoch: 5| Step: 3
Training loss: 3.221090793609619
Validation loss: 3.016628513733546

Epoch: 5| Step: 4
Training loss: 3.562732219696045
Validation loss: 3.012650499741236

Epoch: 5| Step: 5
Training loss: 3.2495028972625732
Validation loss: 3.009220610062281

Epoch: 5| Step: 6
Training loss: 3.017059087753296
Validation loss: 3.0055730740229287

Epoch: 5| Step: 7
Training loss: 3.2946579456329346
Validation loss: 3.0020606915156045

Epoch: 5| Step: 8
Training loss: 3.4951281547546387
Validation loss: 2.99898690978686

Epoch: 5| Step: 9
Training loss: 3.266885280609131
Validation loss: 2.9953340788682303

Epoch: 5| Step: 10
Training loss: 2.8668293952941895
Validation loss: 2.9918565154075623

Epoch: 5| Step: 11
Training loss: 4.28005838394165
Validation loss: 2.9879069526990256

Epoch: 38| Step: 0
Training loss: 2.983670473098755
Validation loss: 2.983661154905955

Epoch: 5| Step: 1
Training loss: 2.6424100399017334
Validation loss: 2.979885369539261

Epoch: 5| Step: 2
Training loss: 2.763918399810791
Validation loss: 2.9761774937311807

Epoch: 5| Step: 3
Training loss: 3.1860663890838623
Validation loss: 2.9726310471693673

Epoch: 5| Step: 4
Training loss: 3.4366347789764404
Validation loss: 2.968185007572174

Epoch: 5| Step: 5
Training loss: 3.4977221488952637
Validation loss: 2.9644178052743277

Epoch: 5| Step: 6
Training loss: 3.9251294136047363
Validation loss: 2.9608750343322754

Epoch: 5| Step: 7
Training loss: 2.80987811088562
Validation loss: 2.9565652906894684

Epoch: 5| Step: 8
Training loss: 2.742845058441162
Validation loss: 2.9528210163116455

Epoch: 5| Step: 9
Training loss: 3.035754919052124
Validation loss: 2.9486820499102273

Epoch: 5| Step: 10
Training loss: 3.519129514694214
Validation loss: 2.9452601273854575

Epoch: 5| Step: 11
Training loss: 4.425485610961914
Validation loss: 2.941722571849823

Epoch: 39| Step: 0
Training loss: 3.1568844318389893
Validation loss: 2.938624123732249

Epoch: 5| Step: 1
Training loss: 3.0448756217956543
Validation loss: 2.934482196966807

Epoch: 5| Step: 2
Training loss: 4.198386192321777
Validation loss: 2.9318809807300568

Epoch: 5| Step: 3
Training loss: 3.0045340061187744
Validation loss: 2.928193767865499

Epoch: 5| Step: 4
Training loss: 3.0889639854431152
Validation loss: 2.924188713232676

Epoch: 5| Step: 5
Training loss: 2.25738263130188
Validation loss: 2.9228370090325675

Epoch: 5| Step: 6
Training loss: 3.2719168663024902
Validation loss: 2.92117832104365

Epoch: 5| Step: 7
Training loss: 3.8409152030944824
Validation loss: 2.9144695897897086

Epoch: 5| Step: 8
Training loss: 2.8651885986328125
Validation loss: 2.91029820839564

Epoch: 5| Step: 9
Training loss: 3.1189749240875244
Validation loss: 2.9066376984119415

Epoch: 5| Step: 10
Training loss: 2.7419772148132324
Validation loss: 2.9043407340844474

Epoch: 5| Step: 11
Training loss: 1.9218449592590332
Validation loss: 2.9048372209072113

Epoch: 40| Step: 0
Training loss: 3.6072609424591064
Validation loss: 2.9373672803243003

Epoch: 5| Step: 1
Training loss: 2.449716091156006
Validation loss: 2.9450082878271737

Epoch: 5| Step: 2
Training loss: 3.4901134967803955
Validation loss: 2.9298629264036813

Epoch: 5| Step: 3
Training loss: 2.70719838142395
Validation loss: 2.922089864810308

Epoch: 5| Step: 4
Training loss: 3.6144485473632812
Validation loss: 2.888815979162852

Epoch: 5| Step: 5
Training loss: 2.63139271736145
Validation loss: 2.8812258740266166

Epoch: 5| Step: 6
Training loss: 3.268463134765625
Validation loss: 2.879943529764811

Epoch: 5| Step: 7
Training loss: 3.4217286109924316
Validation loss: 2.8878172834714255

Epoch: 5| Step: 8
Training loss: 3.3864071369171143
Validation loss: 2.8764125406742096

Epoch: 5| Step: 9
Training loss: 3.1776325702667236
Validation loss: 2.874953349431356

Epoch: 5| Step: 10
Training loss: 2.7121024131774902
Validation loss: 2.871004750331243

Epoch: 5| Step: 11
Training loss: 1.1294975280761719
Validation loss: 2.863459900021553

Epoch: 41| Step: 0
Training loss: 3.51139760017395
Validation loss: 2.858201503753662

Epoch: 5| Step: 1
Training loss: 3.3550772666931152
Validation loss: 2.8546992937723794

Epoch: 5| Step: 2
Training loss: 2.285752534866333
Validation loss: 2.8520586291948953

Epoch: 5| Step: 3
Training loss: 3.301095962524414
Validation loss: 2.850553701321284

Epoch: 5| Step: 4
Training loss: 2.809738874435425
Validation loss: 2.8506267766157785

Epoch: 5| Step: 5
Training loss: 2.9373698234558105
Validation loss: 2.849394530057907

Epoch: 5| Step: 6
Training loss: 3.371675491333008
Validation loss: 2.84550212820371

Epoch: 5| Step: 7
Training loss: 3.035548686981201
Validation loss: 2.838445762793223

Epoch: 5| Step: 8
Training loss: 3.24700927734375
Validation loss: 2.8351467649141946

Epoch: 5| Step: 9
Training loss: 3.340970277786255
Validation loss: 2.8372484048207602

Epoch: 5| Step: 10
Training loss: 2.5867984294891357
Validation loss: 2.8263260424137115

Epoch: 5| Step: 11
Training loss: 2.1691625118255615
Validation loss: 2.8237008253733316

Epoch: 42| Step: 0
Training loss: 2.6512444019317627
Validation loss: 2.8183266123135886

Epoch: 5| Step: 1
Training loss: 2.4414772987365723
Validation loss: 2.8163400491078696

Epoch: 5| Step: 2
Training loss: 3.1849639415740967
Validation loss: 2.812485158443451

Epoch: 5| Step: 3
Training loss: 3.15885591506958
Validation loss: 2.8097267746925354

Epoch: 5| Step: 4
Training loss: 3.1319165229797363
Validation loss: 2.8075944582621255

Epoch: 5| Step: 5
Training loss: 2.969813346862793
Validation loss: 2.8047471841176352

Epoch: 5| Step: 6
Training loss: 3.292691707611084
Validation loss: 2.8011830945809684

Epoch: 5| Step: 7
Training loss: 2.9300873279571533
Validation loss: 2.7994326452414193

Epoch: 5| Step: 8
Training loss: 2.750614643096924
Validation loss: 2.7965886990229287

Epoch: 5| Step: 9
Training loss: 2.7384209632873535
Validation loss: 2.793986678123474

Epoch: 5| Step: 10
Training loss: 3.593776226043701
Validation loss: 2.790812889734904

Epoch: 5| Step: 11
Training loss: 4.484731674194336
Validation loss: 2.787294755379359

Epoch: 43| Step: 0
Training loss: 2.6497225761413574
Validation loss: 2.7829111417134604

Epoch: 5| Step: 1
Training loss: 2.6854701042175293
Validation loss: 2.7789346476395926

Epoch: 5| Step: 2
Training loss: 3.1027183532714844
Validation loss: 2.777104695638021

Epoch: 5| Step: 3
Training loss: 3.277906894683838
Validation loss: 2.7754644254843392

Epoch: 5| Step: 4
Training loss: 2.882887601852417
Validation loss: 2.780309796333313

Epoch: 5| Step: 5
Training loss: 3.448176622390747
Validation loss: 2.7661921977996826

Epoch: 5| Step: 6
Training loss: 3.2517433166503906
Validation loss: 2.7648455699284873

Epoch: 5| Step: 7
Training loss: 2.614220142364502
Validation loss: 2.760895242293676

Epoch: 5| Step: 8
Training loss: 4.215738773345947
Validation loss: 2.756917675336202

Epoch: 5| Step: 9
Training loss: 2.2895865440368652
Validation loss: 2.755787988503774

Epoch: 5| Step: 10
Training loss: 2.3860297203063965
Validation loss: 2.7529593209425607

Epoch: 5| Step: 11
Training loss: 2.579291820526123
Validation loss: 2.7502473294734955

Epoch: 44| Step: 0
Training loss: 3.271932601928711
Validation loss: 2.745045085748037

Epoch: 5| Step: 1
Training loss: 2.4020931720733643
Validation loss: 2.74315552910169

Epoch: 5| Step: 2
Training loss: 2.7985894680023193
Validation loss: 2.7388788958390555

Epoch: 5| Step: 3
Training loss: 2.9978389739990234
Validation loss: 2.7365079522132874

Epoch: 5| Step: 4
Training loss: 3.0065903663635254
Validation loss: 2.734014868736267

Epoch: 5| Step: 5
Training loss: 3.370960235595703
Validation loss: 2.739981551965078

Epoch: 5| Step: 6
Training loss: 2.987239122390747
Validation loss: 2.732500503460566

Epoch: 5| Step: 7
Training loss: 2.3623862266540527
Validation loss: 2.7268023987611136

Epoch: 5| Step: 8
Training loss: 3.1221680641174316
Validation loss: 2.7197454472382865

Epoch: 5| Step: 9
Training loss: 3.0974583625793457
Validation loss: 2.7162022391955056

Epoch: 5| Step: 10
Training loss: 2.6863393783569336
Validation loss: 2.712875892718633

Epoch: 5| Step: 11
Training loss: 3.923757791519165
Validation loss: 2.7107688089211783

Epoch: 45| Step: 0
Training loss: 2.541726589202881
Validation loss: 2.7090604404608407

Epoch: 5| Step: 1
Training loss: 3.1735196113586426
Validation loss: 2.7080306311448417

Epoch: 5| Step: 2
Training loss: 2.4989097118377686
Validation loss: 2.7057301104068756

Epoch: 5| Step: 3
Training loss: 3.035592555999756
Validation loss: 2.701272497574488

Epoch: 5| Step: 4
Training loss: 2.61873197555542
Validation loss: 2.6948027114073434

Epoch: 5| Step: 5
Training loss: 2.749160051345825
Validation loss: 2.691099762916565

Epoch: 5| Step: 6
Training loss: 3.199941873550415
Validation loss: 2.6870090663433075

Epoch: 5| Step: 7
Training loss: 3.2222800254821777
Validation loss: 2.6835887332757316

Epoch: 5| Step: 8
Training loss: 2.8512842655181885
Validation loss: 2.6820210913817086

Epoch: 5| Step: 9
Training loss: 2.8478877544403076
Validation loss: 2.677423050006231

Epoch: 5| Step: 10
Training loss: 3.0552546977996826
Validation loss: 2.6733759144941964

Epoch: 5| Step: 11
Training loss: 3.3243038654327393
Validation loss: 2.6720882256825766

Epoch: 46| Step: 0
Training loss: 2.4095141887664795
Validation loss: 2.666377286116282

Epoch: 5| Step: 1
Training loss: 2.3956634998321533
Validation loss: 2.6640630662441254

Epoch: 5| Step: 2
Training loss: 3.554950714111328
Validation loss: 2.660769204298655

Epoch: 5| Step: 3
Training loss: 2.517176389694214
Validation loss: 2.658249864975611

Epoch: 5| Step: 4
Training loss: 3.1024010181427
Validation loss: 2.6553947031497955

Epoch: 5| Step: 5
Training loss: 2.4323487281799316
Validation loss: 2.652016133069992

Epoch: 5| Step: 6
Training loss: 2.6125049591064453
Validation loss: 2.6521519819895425

Epoch: 5| Step: 7
Training loss: 3.630685806274414
Validation loss: 2.649480660756429

Epoch: 5| Step: 8
Training loss: 3.146584987640381
Validation loss: 2.6475327412287393

Epoch: 5| Step: 9
Training loss: 3.0551209449768066
Validation loss: 2.6419004996617637

Epoch: 5| Step: 10
Training loss: 2.5460057258605957
Validation loss: 2.6391975979010263

Epoch: 5| Step: 11
Training loss: 2.661860227584839
Validation loss: 2.636382579803467

Epoch: 47| Step: 0
Training loss: 2.8815245628356934
Validation loss: 2.637366900841395

Epoch: 5| Step: 1
Training loss: 2.6780343055725098
Validation loss: 2.630158632993698

Epoch: 5| Step: 2
Training loss: 2.714181423187256
Validation loss: 2.6264959275722504

Epoch: 5| Step: 3
Training loss: 3.3368446826934814
Validation loss: 2.62387885649999

Epoch: 5| Step: 4
Training loss: 2.8887155055999756
Validation loss: 2.619283229112625

Epoch: 5| Step: 5
Training loss: 2.8057053089141846
Validation loss: 2.6148264159758887

Epoch: 5| Step: 6
Training loss: 2.9445033073425293
Validation loss: 2.614203025897344

Epoch: 5| Step: 7
Training loss: 3.158527374267578
Validation loss: 2.6063758383194604

Epoch: 5| Step: 8
Training loss: 2.1996498107910156
Validation loss: 2.6025216380755105

Epoch: 5| Step: 9
Training loss: 2.3917953968048096
Validation loss: 2.599072515964508

Epoch: 5| Step: 10
Training loss: 3.027467966079712
Validation loss: 2.598015526930491

Epoch: 5| Step: 11
Training loss: 2.421092987060547
Validation loss: 2.591850996017456

Epoch: 48| Step: 0
Training loss: 3.130221366882324
Validation loss: 2.585898886124293

Epoch: 5| Step: 1
Training loss: 2.91825795173645
Validation loss: 2.5876007775465646

Epoch: 5| Step: 2
Training loss: 2.6904714107513428
Validation loss: 2.5856654892365136

Epoch: 5| Step: 3
Training loss: 2.5691134929656982
Validation loss: 2.601906711856524

Epoch: 5| Step: 4
Training loss: 2.927774667739868
Validation loss: 2.635211785634359

Epoch: 5| Step: 5
Training loss: 2.478999376296997
Validation loss: 2.5870289703210196

Epoch: 5| Step: 6
Training loss: 2.820432186126709
Validation loss: 2.57776415348053

Epoch: 5| Step: 7
Training loss: 2.8139195442199707
Validation loss: 2.5736446479956308

Epoch: 5| Step: 8
Training loss: 3.091948986053467
Validation loss: 2.5739470720291138

Epoch: 5| Step: 9
Training loss: 2.543107509613037
Validation loss: 2.5761655370394387

Epoch: 5| Step: 10
Training loss: 2.9306297302246094
Validation loss: 2.5735718409220376

Epoch: 5| Step: 11
Training loss: 0.8533711433410645
Validation loss: 2.5813376009464264

Epoch: 49| Step: 0
Training loss: 2.708263397216797
Validation loss: 2.622716506322225

Epoch: 5| Step: 1
Training loss: 3.22175931930542
Validation loss: 2.5874058107535043

Epoch: 5| Step: 2
Training loss: 2.537275791168213
Validation loss: 2.5693596601486206

Epoch: 5| Step: 3
Training loss: 3.40136456489563
Validation loss: 2.558154712120692

Epoch: 5| Step: 4
Training loss: 2.847626209259033
Validation loss: 2.549015204111735

Epoch: 5| Step: 5
Training loss: 2.454195022583008
Validation loss: 2.543874834974607

Epoch: 5| Step: 6
Training loss: 3.0193428993225098
Validation loss: 2.541171779235204

Epoch: 5| Step: 7
Training loss: 2.1960175037384033
Validation loss: 2.5388963520526886

Epoch: 5| Step: 8
Training loss: 2.281466007232666
Validation loss: 2.5361143251260123

Epoch: 5| Step: 9
Training loss: 2.7148468494415283
Validation loss: 2.5346998373667398

Epoch: 5| Step: 10
Training loss: 2.932929515838623
Validation loss: 2.534033089876175

Epoch: 5| Step: 11
Training loss: 2.193870782852173
Validation loss: 2.5356394549210868

Epoch: 50| Step: 0
Training loss: 2.8301589488983154
Validation loss: 2.535378565390905

Epoch: 5| Step: 1
Training loss: 2.9706215858459473
Validation loss: 2.5314296583334603

Epoch: 5| Step: 2
Training loss: 2.362881898880005
Validation loss: 2.525837242603302

Epoch: 5| Step: 3
Training loss: 2.5615220069885254
Validation loss: 2.5202919642130532

Epoch: 5| Step: 4
Training loss: 2.402097225189209
Validation loss: 2.5124872028827667

Epoch: 5| Step: 5
Training loss: 2.435999631881714
Validation loss: 2.5099585950374603

Epoch: 5| Step: 6
Training loss: 3.1787919998168945
Validation loss: 2.506212959686915

Epoch: 5| Step: 7
Training loss: 2.6222546100616455
Validation loss: 2.499129722515742

Epoch: 5| Step: 8
Training loss: 3.3987631797790527
Validation loss: 2.4975024461746216

Epoch: 5| Step: 9
Training loss: 2.0829670429229736
Validation loss: 2.4977712829907737

Epoch: 5| Step: 10
Training loss: 2.964414596557617
Validation loss: 2.4943370620409646

Epoch: 5| Step: 11
Training loss: 2.0357577800750732
Validation loss: 2.4888810018698373

Epoch: 51| Step: 0
Training loss: 2.9740242958068848
Validation loss: 2.4831469555695853

Epoch: 5| Step: 1
Training loss: 2.6839568614959717
Validation loss: 2.479712883631388

Epoch: 5| Step: 2
Training loss: 2.390023708343506
Validation loss: 2.4761255085468292

Epoch: 5| Step: 3
Training loss: 2.7143514156341553
Validation loss: 2.4713989198207855

Epoch: 5| Step: 4
Training loss: 2.702859878540039
Validation loss: 2.4684845556815467

Epoch: 5| Step: 5
Training loss: 2.579397201538086
Validation loss: 2.4677501916885376

Epoch: 5| Step: 6
Training loss: 3.3795249462127686
Validation loss: 2.4660315016905465

Epoch: 5| Step: 7
Training loss: 2.050816535949707
Validation loss: 2.4634951651096344

Epoch: 5| Step: 8
Training loss: 2.8158185482025146
Validation loss: 2.463334172964096

Epoch: 5| Step: 9
Training loss: 2.478146553039551
Validation loss: 2.460381329059601

Epoch: 5| Step: 10
Training loss: 2.19964599609375
Validation loss: 2.453168123960495

Epoch: 5| Step: 11
Training loss: 3.7868409156799316
Validation loss: 2.4491221805413566

Epoch: 52| Step: 0
Training loss: 2.1958096027374268
Validation loss: 2.4469721813996634

Epoch: 5| Step: 1
Training loss: 2.1178531646728516
Validation loss: 2.4430761337280273

Epoch: 5| Step: 2
Training loss: 3.054934501647949
Validation loss: 2.442110071579615

Epoch: 5| Step: 3
Training loss: 2.5094428062438965
Validation loss: 2.4380496442317963

Epoch: 5| Step: 4
Training loss: 2.6849751472473145
Validation loss: 2.437618618210157

Epoch: 5| Step: 5
Training loss: 3.013007402420044
Validation loss: 2.4350153505802155

Epoch: 5| Step: 6
Training loss: 2.9893620014190674
Validation loss: 2.4322648644447327

Epoch: 5| Step: 7
Training loss: 2.492652177810669
Validation loss: 2.4299162179231644

Epoch: 5| Step: 8
Training loss: 2.2479655742645264
Validation loss: 2.426262299219767

Epoch: 5| Step: 9
Training loss: 3.0124011039733887
Validation loss: 2.4219563603401184

Epoch: 5| Step: 10
Training loss: 2.5958824157714844
Validation loss: 2.4198749661445618

Epoch: 5| Step: 11
Training loss: 2.0979392528533936
Validation loss: 2.4186148047447205

Epoch: 53| Step: 0
Training loss: 2.7709343433380127
Validation loss: 2.4149318238099418

Epoch: 5| Step: 1
Training loss: 2.3443899154663086
Validation loss: 2.4082221686840057

Epoch: 5| Step: 2
Training loss: 2.292825698852539
Validation loss: 2.409052719672521

Epoch: 5| Step: 3
Training loss: 2.3602821826934814
Validation loss: 2.4070962568124137

Epoch: 5| Step: 4
Training loss: 2.7472198009490967
Validation loss: 2.4011990328629813

Epoch: 5| Step: 5
Training loss: 2.3224070072174072
Validation loss: 2.406233380238215

Epoch: 5| Step: 6
Training loss: 2.63814640045166
Validation loss: 2.3979200621445975

Epoch: 5| Step: 7
Training loss: 3.160430908203125
Validation loss: 2.3967137038707733

Epoch: 5| Step: 8
Training loss: 2.86152982711792
Validation loss: 2.4022478560606637

Epoch: 5| Step: 9
Training loss: 2.2388947010040283
Validation loss: 2.400655835866928

Epoch: 5| Step: 10
Training loss: 2.822962522506714
Validation loss: 2.3931632041931152

Epoch: 5| Step: 11
Training loss: 1.6025391817092896
Validation loss: 2.387026011943817

Epoch: 54| Step: 0
Training loss: 2.6824851036071777
Validation loss: 2.3792646725972495

Epoch: 5| Step: 1
Training loss: 2.6066012382507324
Validation loss: 2.375976468125979

Epoch: 5| Step: 2
Training loss: 2.5492196083068848
Validation loss: 2.3746044635772705

Epoch: 5| Step: 3
Training loss: 3.272634983062744
Validation loss: 2.372692962487539

Epoch: 5| Step: 4
Training loss: 2.6661953926086426
Validation loss: 2.3787214954694114

Epoch: 5| Step: 5
Training loss: 2.5360164642333984
Validation loss: 2.374178131421407

Epoch: 5| Step: 6
Training loss: 2.3102424144744873
Validation loss: 2.375897546609243

Epoch: 5| Step: 7
Training loss: 2.6230013370513916
Validation loss: 2.370749165614446

Epoch: 5| Step: 8
Training loss: 2.5854644775390625
Validation loss: 2.374183019002279

Epoch: 5| Step: 9
Training loss: 1.6409772634506226
Validation loss: 2.366816684603691

Epoch: 5| Step: 10
Training loss: 2.5375113487243652
Validation loss: 2.3604686756928763

Epoch: 5| Step: 11
Training loss: 2.320711612701416
Validation loss: 2.357165773709615

Epoch: 55| Step: 0
Training loss: 2.4425387382507324
Validation loss: 2.353267401456833

Epoch: 5| Step: 1
Training loss: 1.9013468027114868
Validation loss: 2.3468876679738364

Epoch: 5| Step: 2
Training loss: 2.523430347442627
Validation loss: 2.3449987173080444

Epoch: 5| Step: 3
Training loss: 2.6296005249023438
Validation loss: 2.3381024102369943

Epoch: 5| Step: 4
Training loss: 2.7450690269470215
Validation loss: 2.3394851138194404

Epoch: 5| Step: 5
Training loss: 2.431809902191162
Validation loss: 2.333039144674937

Epoch: 5| Step: 6
Training loss: 2.3897948265075684
Validation loss: 2.332201441129049

Epoch: 5| Step: 7
Training loss: 2.5029709339141846
Validation loss: 2.3285580774148307

Epoch: 5| Step: 8
Training loss: 2.3381104469299316
Validation loss: 2.332565486431122

Epoch: 5| Step: 9
Training loss: 2.2403011322021484
Validation loss: 2.3379310766855874

Epoch: 5| Step: 10
Training loss: 3.161296844482422
Validation loss: 2.3364789932966232

Epoch: 5| Step: 11
Training loss: 3.418254852294922
Validation loss: 2.3226590851942697

Epoch: 56| Step: 0
Training loss: 2.65165638923645
Validation loss: 2.3309400031963983

Epoch: 5| Step: 1
Training loss: 2.6718177795410156
Validation loss: 2.34419709444046

Epoch: 5| Step: 2
Training loss: 2.091902256011963
Validation loss: 2.336265504360199

Epoch: 5| Step: 3
Training loss: 2.4945342540740967
Validation loss: 2.3176689743995667

Epoch: 5| Step: 4
Training loss: 1.925976037979126
Validation loss: 2.310591305295626

Epoch: 5| Step: 5
Training loss: 2.2909836769104004
Validation loss: 2.3131375163793564

Epoch: 5| Step: 6
Training loss: 2.8199539184570312
Validation loss: 2.3148127496242523

Epoch: 5| Step: 7
Training loss: 2.231114149093628
Validation loss: 2.3167451322078705

Epoch: 5| Step: 8
Training loss: 2.757267713546753
Validation loss: 2.3136483132839203

Epoch: 5| Step: 9
Training loss: 3.0216970443725586
Validation loss: 2.3228038450082145

Epoch: 5| Step: 10
Training loss: 2.5217134952545166
Validation loss: 2.3246200680732727

Epoch: 5| Step: 11
Training loss: 2.378544569015503
Validation loss: 2.3185382187366486

Epoch: 57| Step: 0
Training loss: 2.5685698986053467
Validation loss: 2.311954160531362

Epoch: 5| Step: 1
Training loss: 1.9140937328338623
Validation loss: 2.3076946238676705

Epoch: 5| Step: 2
Training loss: 2.609907865524292
Validation loss: 2.298202782869339

Epoch: 5| Step: 3
Training loss: 2.5832738876342773
Validation loss: 2.2918503681818643

Epoch: 5| Step: 4
Training loss: 2.3792290687561035
Validation loss: 2.2854980130990348

Epoch: 5| Step: 5
Training loss: 2.941664934158325
Validation loss: 2.280239830414454

Epoch: 5| Step: 6
Training loss: 2.423100233078003
Validation loss: 2.2759408255418143

Epoch: 5| Step: 7
Training loss: 1.724016547203064
Validation loss: 2.276040494441986

Epoch: 5| Step: 8
Training loss: 2.2712676525115967
Validation loss: 2.270372206966082

Epoch: 5| Step: 9
Training loss: 2.6364102363586426
Validation loss: 2.267015049854914

Epoch: 5| Step: 10
Training loss: 2.9158830642700195
Validation loss: 2.263427803913752

Epoch: 5| Step: 11
Training loss: 2.0687255859375
Validation loss: 2.2602070420980453

Epoch: 58| Step: 0
Training loss: 2.4404971599578857
Validation loss: 2.2610181669394174

Epoch: 5| Step: 1
Training loss: 2.180847406387329
Validation loss: 2.255159775416056

Epoch: 5| Step: 2
Training loss: 2.5374245643615723
Validation loss: 2.252973606189092

Epoch: 5| Step: 3
Training loss: 2.733690023422241
Validation loss: 2.2483429511388144

Epoch: 5| Step: 4
Training loss: 2.579421281814575
Validation loss: 2.2462910314400992

Epoch: 5| Step: 5
Training loss: 1.5433366298675537
Validation loss: 2.246355414390564

Epoch: 5| Step: 6
Training loss: 2.6066558361053467
Validation loss: 2.240598897139231

Epoch: 5| Step: 7
Training loss: 2.5206234455108643
Validation loss: 2.2399375438690186

Epoch: 5| Step: 8
Training loss: 2.61360502243042
Validation loss: 2.2408432265122733

Epoch: 5| Step: 9
Training loss: 2.419999599456787
Validation loss: 2.2344921131928763

Epoch: 5| Step: 10
Training loss: 2.1966311931610107
Validation loss: 2.237151170770327

Epoch: 5| Step: 11
Training loss: 2.452549457550049
Validation loss: 2.226926272114118

Epoch: 59| Step: 0
Training loss: 2.3026435375213623
Validation loss: 2.233674089113871

Epoch: 5| Step: 1
Training loss: 2.9983479976654053
Validation loss: 2.229811797539393

Epoch: 5| Step: 2
Training loss: 2.269343614578247
Validation loss: 2.2306935091813407

Epoch: 5| Step: 3
Training loss: 1.870741605758667
Validation loss: 2.2371655901273093

Epoch: 5| Step: 4
Training loss: 2.082608938217163
Validation loss: 2.2335545122623444

Epoch: 5| Step: 5
Training loss: 2.514721632003784
Validation loss: 2.2387839257717133

Epoch: 5| Step: 6
Training loss: 3.007004737854004
Validation loss: 2.24235562980175

Epoch: 5| Step: 7
Training loss: 2.1167025566101074
Validation loss: 2.242826610803604

Epoch: 5| Step: 8
Training loss: 2.788517713546753
Validation loss: 2.2473261952400208

Epoch: 5| Step: 9
Training loss: 1.760308861732483
Validation loss: 2.2495289544264474

Epoch: 5| Step: 10
Training loss: 2.3392531871795654
Validation loss: 2.2408045331637063

Epoch: 5| Step: 11
Training loss: 3.207904100418091
Validation loss: 2.2333160837491355

Epoch: 60| Step: 0
Training loss: 2.103630542755127
Validation loss: 2.221770832935969

Epoch: 5| Step: 1
Training loss: 2.3804774284362793
Validation loss: 2.2107397466897964

Epoch: 5| Step: 2
Training loss: 2.315749406814575
Validation loss: 2.2049800157546997

Epoch: 5| Step: 3
Training loss: 2.5738449096679688
Validation loss: 2.200991819302241

Epoch: 5| Step: 4
Training loss: 2.765798568725586
Validation loss: 2.19669970870018

Epoch: 5| Step: 5
Training loss: 2.5086467266082764
Validation loss: 2.1876427630583444

Epoch: 5| Step: 6
Training loss: 1.5558357238769531
Validation loss: 2.1905832240978875

Epoch: 5| Step: 7
Training loss: 1.8661314249038696
Validation loss: 2.188861533999443

Epoch: 5| Step: 8
Training loss: 3.103938102722168
Validation loss: 2.1859433203935623

Epoch: 5| Step: 9
Training loss: 1.7645900249481201
Validation loss: 2.1821929266055426

Epoch: 5| Step: 10
Training loss: 2.791459560394287
Validation loss: 2.177772661050161

Epoch: 5| Step: 11
Training loss: 2.539144515991211
Validation loss: 2.1767790218194327

Epoch: 61| Step: 0
Training loss: 2.6109046936035156
Validation loss: 2.1815070708592734

Epoch: 5| Step: 1
Training loss: 2.5650248527526855
Validation loss: 2.21181250611941

Epoch: 5| Step: 2
Training loss: 2.2913107872009277
Validation loss: 2.2089510460694632

Epoch: 5| Step: 3
Training loss: 2.6539769172668457
Validation loss: 2.1963716248671212

Epoch: 5| Step: 4
Training loss: 2.2709546089172363
Validation loss: 2.1770222584406533

Epoch: 5| Step: 5
Training loss: 1.9140764474868774
Validation loss: 2.166377698381742

Epoch: 5| Step: 6
Training loss: 2.4620234966278076
Validation loss: 2.166508764028549

Epoch: 5| Step: 7
Training loss: 2.3756020069122314
Validation loss: 2.168546492854754

Epoch: 5| Step: 8
Training loss: 2.366318702697754
Validation loss: 2.1667112509409585

Epoch: 5| Step: 9
Training loss: 1.9252628087997437
Validation loss: 2.167303259174029

Epoch: 5| Step: 10
Training loss: 2.191082715988159
Validation loss: 2.16343588133653

Epoch: 5| Step: 11
Training loss: 2.109218120574951
Validation loss: 2.1654573480288186

Epoch: 62| Step: 0
Training loss: 1.6547260284423828
Validation loss: 2.1588537643353143

Epoch: 5| Step: 1
Training loss: 2.6258506774902344
Validation loss: 2.1556229492028556

Epoch: 5| Step: 2
Training loss: 2.052131175994873
Validation loss: 2.1592003603776297

Epoch: 5| Step: 3
Training loss: 2.6549079418182373
Validation loss: 2.151942809422811

Epoch: 5| Step: 4
Training loss: 1.7477343082427979
Validation loss: 2.1643461287021637

Epoch: 5| Step: 5
Training loss: 2.5655646324157715
Validation loss: 2.167994201183319

Epoch: 5| Step: 6
Training loss: 2.4896223545074463
Validation loss: 2.1678929229577384

Epoch: 5| Step: 7
Training loss: 2.2172255516052246
Validation loss: 2.1739857296148934

Epoch: 5| Step: 8
Training loss: 2.630012035369873
Validation loss: 2.1582971612612405

Epoch: 5| Step: 9
Training loss: 2.278144359588623
Validation loss: 2.1452889492114386

Epoch: 5| Step: 10
Training loss: 2.568835735321045
Validation loss: 2.1408150295416513

Epoch: 5| Step: 11
Training loss: 1.5786396265029907
Validation loss: 2.1444466412067413

Epoch: 63| Step: 0
Training loss: 1.5775907039642334
Validation loss: 2.1458944380283356

Epoch: 5| Step: 1
Training loss: 1.8192336559295654
Validation loss: 2.1450291524330773

Epoch: 5| Step: 2
Training loss: 2.357417106628418
Validation loss: 2.145405481259028

Epoch: 5| Step: 3
Training loss: 2.476966142654419
Validation loss: 2.146262750029564

Epoch: 5| Step: 4
Training loss: 2.6319541931152344
Validation loss: 2.1490216751893363

Epoch: 5| Step: 5
Training loss: 2.6857943534851074
Validation loss: 2.1407621602217355

Epoch: 5| Step: 6
Training loss: 2.967986583709717
Validation loss: 2.143668015797933

Epoch: 5| Step: 7
Training loss: 2.1240394115448
Validation loss: 2.1413745284080505

Epoch: 5| Step: 8
Training loss: 1.9285227060317993
Validation loss: 2.142773906389872

Epoch: 5| Step: 9
Training loss: 2.3843984603881836
Validation loss: 2.137350767850876

Epoch: 5| Step: 10
Training loss: 2.2304797172546387
Validation loss: 2.1361818810304007

Epoch: 5| Step: 11
Training loss: 2.7634990215301514
Validation loss: 2.1365330715974173

Epoch: 64| Step: 0
Training loss: 2.376483201980591
Validation loss: 2.125956272085508

Epoch: 5| Step: 1
Training loss: 2.3947560787200928
Validation loss: 2.1276171853144965

Epoch: 5| Step: 2
Training loss: 2.055915355682373
Validation loss: 2.122157394886017

Epoch: 5| Step: 3
Training loss: 2.54201078414917
Validation loss: 2.119089966018995

Epoch: 5| Step: 4
Training loss: 2.059558153152466
Validation loss: 2.1203353901704154

Epoch: 5| Step: 5
Training loss: 2.3709683418273926
Validation loss: 2.119354709982872

Epoch: 5| Step: 6
Training loss: 2.404003143310547
Validation loss: 2.123907372355461

Epoch: 5| Step: 7
Training loss: 1.7896461486816406
Validation loss: 2.1292020082473755

Epoch: 5| Step: 8
Training loss: 2.459139347076416
Validation loss: 2.1269032955169678

Epoch: 5| Step: 9
Training loss: 2.4607093334198
Validation loss: 2.139024684826533

Epoch: 5| Step: 10
Training loss: 2.4664225578308105
Validation loss: 2.1274645229180655

Epoch: 5| Step: 11
Training loss: 1.2712676525115967
Validation loss: 2.1201910277207694

Epoch: 65| Step: 0
Training loss: 2.4457132816314697
Validation loss: 2.11215810974439

Epoch: 5| Step: 1
Training loss: 1.5559443235397339
Validation loss: 2.1141563008228936

Epoch: 5| Step: 2
Training loss: 2.6835761070251465
Validation loss: 2.1083102573951087

Epoch: 5| Step: 3
Training loss: 2.61007022857666
Validation loss: 2.111543814341227

Epoch: 5| Step: 4
Training loss: 2.3193514347076416
Validation loss: 2.1073158582051597

Epoch: 5| Step: 5
Training loss: 2.113537311553955
Validation loss: 2.1083931227525077

Epoch: 5| Step: 6
Training loss: 1.9812450408935547
Validation loss: 2.106455718477567

Epoch: 5| Step: 7
Training loss: 2.751112461090088
Validation loss: 2.107522885004679

Epoch: 5| Step: 8
Training loss: 2.2517001628875732
Validation loss: 2.1090212762355804

Epoch: 5| Step: 9
Training loss: 2.190648078918457
Validation loss: 2.099043548107147

Epoch: 5| Step: 10
Training loss: 2.2346909046173096
Validation loss: 2.1044441709915795

Epoch: 5| Step: 11
Training loss: 1.038484811782837
Validation loss: 2.09267458319664

Epoch: 66| Step: 0
Training loss: 2.5574285984039307
Validation loss: 2.0989020268122354

Epoch: 5| Step: 1
Training loss: 1.9649336338043213
Validation loss: 2.0973016172647476

Epoch: 5| Step: 2
Training loss: 2.0915634632110596
Validation loss: 2.0989013413588204

Epoch: 5| Step: 3
Training loss: 1.954262137413025
Validation loss: 2.097722594936689

Epoch: 5| Step: 4
Training loss: 2.163008213043213
Validation loss: 2.110134497284889

Epoch: 5| Step: 5
Training loss: 2.5320630073547363
Validation loss: 2.1038566678762436

Epoch: 5| Step: 6
Training loss: 2.145920753479004
Validation loss: 2.1059483140707016

Epoch: 5| Step: 7
Training loss: 2.286893367767334
Validation loss: 2.1183803230524063

Epoch: 5| Step: 8
Training loss: 2.2246015071868896
Validation loss: 2.113312855362892

Epoch: 5| Step: 9
Training loss: 2.233027935028076
Validation loss: 2.1174605935811996

Epoch: 5| Step: 10
Training loss: 2.670647144317627
Validation loss: 2.1181358893712363

Epoch: 5| Step: 11
Training loss: 2.1027722358703613
Validation loss: 2.107845594485601

Epoch: 67| Step: 0
Training loss: 1.7468688488006592
Validation loss: 2.119571809967359

Epoch: 5| Step: 1
Training loss: 2.3921802043914795
Validation loss: 2.116907278696696

Epoch: 5| Step: 2
Training loss: 1.8486897945404053
Validation loss: 2.1325116753578186

Epoch: 5| Step: 3
Training loss: 2.52769136428833
Validation loss: 2.1416548093159995

Epoch: 5| Step: 4
Training loss: 3.147019147872925
Validation loss: 2.142228811979294

Epoch: 5| Step: 5
Training loss: 1.979175329208374
Validation loss: 2.1217872202396393

Epoch: 5| Step: 6
Training loss: 2.199103593826294
Validation loss: 2.1025876303513846

Epoch: 5| Step: 7
Training loss: 2.280527353286743
Validation loss: 2.0916609267393746

Epoch: 5| Step: 8
Training loss: 2.141401767730713
Validation loss: 2.0923632979393005

Epoch: 5| Step: 9
Training loss: 1.938399076461792
Validation loss: 2.07962699731191

Epoch: 5| Step: 10
Training loss: 2.5291595458984375
Validation loss: 2.078377977013588

Epoch: 5| Step: 11
Training loss: 2.7470951080322266
Validation loss: 2.0752693762381873

Epoch: 68| Step: 0
Training loss: 1.882368803024292
Validation loss: 2.074917569756508

Epoch: 5| Step: 1
Training loss: 1.8890851736068726
Validation loss: 2.078762869040171

Epoch: 5| Step: 2
Training loss: 2.620215892791748
Validation loss: 2.0685642759005227

Epoch: 5| Step: 3
Training loss: 2.4069321155548096
Validation loss: 2.0719106942415237

Epoch: 5| Step: 4
Training loss: 2.267179012298584
Validation loss: 2.075289706389109

Epoch: 5| Step: 5
Training loss: 2.0478293895721436
Validation loss: 2.0673770854870477

Epoch: 5| Step: 6
Training loss: 2.4087302684783936
Validation loss: 2.0632814268271127

Epoch: 5| Step: 7
Training loss: 2.183781147003174
Validation loss: 2.067393441994985

Epoch: 5| Step: 8
Training loss: 2.2451376914978027
Validation loss: 2.0671658317248025

Epoch: 5| Step: 9
Training loss: 2.575812816619873
Validation loss: 2.06005131204923

Epoch: 5| Step: 10
Training loss: 2.2314252853393555
Validation loss: 2.0703373700380325

Epoch: 5| Step: 11
Training loss: 1.060453176498413
Validation loss: 2.070268968741099

Epoch: 69| Step: 0
Training loss: 2.78420352935791
Validation loss: 2.0567969332138696

Epoch: 5| Step: 1
Training loss: 1.9685436487197876
Validation loss: 2.066554069519043

Epoch: 5| Step: 2
Training loss: 2.240993022918701
Validation loss: 2.059702624877294

Epoch: 5| Step: 3
Training loss: 2.3202786445617676
Validation loss: 2.0575298418601355

Epoch: 5| Step: 4
Training loss: 2.644843578338623
Validation loss: 2.0594345927238464

Epoch: 5| Step: 5
Training loss: 1.4317024946212769
Validation loss: 2.0637040038903556

Epoch: 5| Step: 6
Training loss: 2.3356363773345947
Validation loss: 2.0535019685824714

Epoch: 5| Step: 7
Training loss: 1.7561241388320923
Validation loss: 2.058465451002121

Epoch: 5| Step: 8
Training loss: 2.538149118423462
Validation loss: 2.0591107656558356

Epoch: 5| Step: 9
Training loss: 2.4749112129211426
Validation loss: 2.0580488791068396

Epoch: 5| Step: 10
Training loss: 2.2103426456451416
Validation loss: 2.068308557073275

Epoch: 5| Step: 11
Training loss: 0.9496413469314575
Validation loss: 2.058687503139178

Epoch: 70| Step: 0
Training loss: 2.5880513191223145
Validation loss: 2.0564501682917276

Epoch: 5| Step: 1
Training loss: 1.4919191598892212
Validation loss: 2.05802953739961

Epoch: 5| Step: 2
Training loss: 1.8910051584243774
Validation loss: 2.0590632607539496

Epoch: 5| Step: 3
Training loss: 1.9192588329315186
Validation loss: 2.06115530927976

Epoch: 5| Step: 4
Training loss: 2.553091526031494
Validation loss: 2.0564111918210983

Epoch: 5| Step: 5
Training loss: 2.4115664958953857
Validation loss: 2.0536908010641732

Epoch: 5| Step: 6
Training loss: 2.617410659790039
Validation loss: 2.0603581964969635

Epoch: 5| Step: 7
Training loss: 2.1822476387023926
Validation loss: 2.056108608841896

Epoch: 5| Step: 8
Training loss: 2.1540467739105225
Validation loss: 2.0618761579195657

Epoch: 5| Step: 9
Training loss: 2.343505382537842
Validation loss: 2.068902462720871

Epoch: 5| Step: 10
Training loss: 2.0796451568603516
Validation loss: 2.0741898318131766

Epoch: 5| Step: 11
Training loss: 2.247614860534668
Validation loss: 2.0575367361307144

Epoch: 71| Step: 0
Training loss: 1.8365768194198608
Validation loss: 2.068709676464399

Epoch: 5| Step: 1
Training loss: 2.1218056678771973
Validation loss: 2.0753857791423798

Epoch: 5| Step: 2
Training loss: 2.239936351776123
Validation loss: 2.0810412218173346

Epoch: 5| Step: 3
Training loss: 2.0084831714630127
Validation loss: 2.079279993971189

Epoch: 5| Step: 4
Training loss: 2.349796772003174
Validation loss: 2.0795977115631104

Epoch: 5| Step: 5
Training loss: 1.7685247659683228
Validation loss: 2.072637379169464

Epoch: 5| Step: 6
Training loss: 2.562105655670166
Validation loss: 2.0732074230909348

Epoch: 5| Step: 7
Training loss: 2.4513046741485596
Validation loss: 2.072990501920382

Epoch: 5| Step: 8
Training loss: 2.211474895477295
Validation loss: 2.060872142513593

Epoch: 5| Step: 9
Training loss: 2.431110382080078
Validation loss: 2.064946939547857

Epoch: 5| Step: 10
Training loss: 2.2917368412017822
Validation loss: 2.058782940109571

Epoch: 5| Step: 11
Training loss: 1.535723090171814
Validation loss: 2.064069777727127

Epoch: 72| Step: 0
Training loss: 2.6550796031951904
Validation loss: 2.0535393357276917

Epoch: 5| Step: 1
Training loss: 2.3466134071350098
Validation loss: 2.059582069516182

Epoch: 5| Step: 2
Training loss: 1.820608139038086
Validation loss: 2.0532327741384506

Epoch: 5| Step: 3
Training loss: 1.9052588939666748
Validation loss: 2.058979317545891

Epoch: 5| Step: 4
Training loss: 2.431880474090576
Validation loss: 2.0615984747807183

Epoch: 5| Step: 5
Training loss: 2.0916526317596436
Validation loss: 2.0674266815185547

Epoch: 5| Step: 6
Training loss: 2.5435290336608887
Validation loss: 2.063571517666181

Epoch: 5| Step: 7
Training loss: 2.123201370239258
Validation loss: 2.0580213566621146

Epoch: 5| Step: 8
Training loss: 1.9758522510528564
Validation loss: 2.0742376993099847

Epoch: 5| Step: 9
Training loss: 2.2578301429748535
Validation loss: 2.0787599434455237

Epoch: 5| Step: 10
Training loss: 2.091104030609131
Validation loss: 2.0763279298941293

Epoch: 5| Step: 11
Training loss: 2.217722177505493
Validation loss: 2.07878186305364

Epoch: 73| Step: 0
Training loss: 1.8034366369247437
Validation loss: 2.072190821170807

Epoch: 5| Step: 1
Training loss: 2.8961093425750732
Validation loss: 2.0809836983680725

Epoch: 5| Step: 2
Training loss: 2.0675559043884277
Validation loss: 2.0696862439314523

Epoch: 5| Step: 3
Training loss: 1.7133572101593018
Validation loss: 2.0669343123833337

Epoch: 5| Step: 4
Training loss: 2.2155187129974365
Validation loss: 2.0721543778975806

Epoch: 5| Step: 5
Training loss: 2.277559518814087
Validation loss: 2.0659422626098

Epoch: 5| Step: 6
Training loss: 2.316127061843872
Validation loss: 2.074512854218483

Epoch: 5| Step: 7
Training loss: 2.0841920375823975
Validation loss: 2.080632741252581

Epoch: 5| Step: 8
Training loss: 2.262281894683838
Validation loss: 2.0777496000130973

Epoch: 5| Step: 9
Training loss: 2.122802734375
Validation loss: 2.0655772387981415

Epoch: 5| Step: 10
Training loss: 2.6078708171844482
Validation loss: 2.0626241813103356

Epoch: 5| Step: 11
Training loss: 1.428187370300293
Validation loss: 2.048773075143496

Epoch: 74| Step: 0
Training loss: 1.7538076639175415
Validation loss: 2.043820232152939

Epoch: 5| Step: 1
Training loss: 2.2147088050842285
Validation loss: 2.0433911432822547

Epoch: 5| Step: 2
Training loss: 2.1310553550720215
Validation loss: 2.04957078397274

Epoch: 5| Step: 3
Training loss: 2.5312142372131348
Validation loss: 2.050020491083463

Epoch: 5| Step: 4
Training loss: 2.7077088356018066
Validation loss: 2.047959287961324

Epoch: 5| Step: 5
Training loss: 2.5754690170288086
Validation loss: 2.0528620133797326

Epoch: 5| Step: 6
Training loss: 1.4623523950576782
Validation loss: 2.054913545648257

Epoch: 5| Step: 7
Training loss: 2.631272554397583
Validation loss: 2.0521730134884515

Epoch: 5| Step: 8
Training loss: 2.213263750076294
Validation loss: 2.0500727544228234

Epoch: 5| Step: 9
Training loss: 2.3072543144226074
Validation loss: 2.0503563483556113

Epoch: 5| Step: 10
Training loss: 1.945535659790039
Validation loss: 2.046369438370069

Epoch: 5| Step: 11
Training loss: 2.2964978218078613
Validation loss: 2.044956331451734

Epoch: 75| Step: 0
Training loss: 2.302616596221924
Validation loss: 2.049316088358561

Epoch: 5| Step: 1
Training loss: 2.6955056190490723
Validation loss: 2.0462799817323685

Epoch: 5| Step: 2
Training loss: 2.5572779178619385
Validation loss: 2.047257885336876

Epoch: 5| Step: 3
Training loss: 2.2188098430633545
Validation loss: 2.0455365230639777

Epoch: 5| Step: 4
Training loss: 2.055866241455078
Validation loss: 2.0488166213035583

Epoch: 5| Step: 5
Training loss: 2.1366806030273438
Validation loss: 2.0492393374443054

Epoch: 5| Step: 6
Training loss: 2.3409552574157715
Validation loss: 2.040647566318512

Epoch: 5| Step: 7
Training loss: 2.224513530731201
Validation loss: 2.0398856898148856

Epoch: 5| Step: 8
Training loss: 1.4930293560028076
Validation loss: 2.0370896458625793

Epoch: 5| Step: 9
Training loss: 2.321840763092041
Validation loss: 2.0436176309982934

Epoch: 5| Step: 10
Training loss: 2.258293867111206
Validation loss: 2.0504834751288095

Epoch: 5| Step: 11
Training loss: 0.9499255418777466
Validation loss: 2.054324726263682

Epoch: 76| Step: 0
Training loss: 2.190403699874878
Validation loss: 2.0511746207873025

Epoch: 5| Step: 1
Training loss: 1.6748478412628174
Validation loss: 2.0533461570739746

Epoch: 5| Step: 2
Training loss: 2.248483657836914
Validation loss: 2.048882474501928

Epoch: 5| Step: 3
Training loss: 2.4762661457061768
Validation loss: 2.054459869861603

Epoch: 5| Step: 4
Training loss: 1.6402864456176758
Validation loss: 2.05654039978981

Epoch: 5| Step: 5
Training loss: 2.103787660598755
Validation loss: 2.054575026035309

Epoch: 5| Step: 6
Training loss: 2.6163289546966553
Validation loss: 2.045310467481613

Epoch: 5| Step: 7
Training loss: 2.199392795562744
Validation loss: 2.043848772843679

Epoch: 5| Step: 8
Training loss: 2.375730037689209
Validation loss: 2.0391639520724616

Epoch: 5| Step: 9
Training loss: 2.421816349029541
Validation loss: 2.036723494529724

Epoch: 5| Step: 10
Training loss: 2.2935242652893066
Validation loss: 2.0334283659855523

Epoch: 5| Step: 11
Training loss: 1.1411011219024658
Validation loss: 2.0337853034337363

Epoch: 77| Step: 0
Training loss: 2.220273494720459
Validation loss: 2.0359365145365396

Epoch: 5| Step: 1
Training loss: 2.3536112308502197
Validation loss: 2.032482291261355

Epoch: 5| Step: 2
Training loss: 2.536076068878174
Validation loss: 2.0396882593631744

Epoch: 5| Step: 3
Training loss: 1.904483437538147
Validation loss: 2.033359612027804

Epoch: 5| Step: 4
Training loss: 2.0102486610412598
Validation loss: 2.0425460239251456

Epoch: 5| Step: 5
Training loss: 2.1886284351348877
Validation loss: 2.0409422516822815

Epoch: 5| Step: 6
Training loss: 1.825683832168579
Validation loss: 2.0421612511078515

Epoch: 5| Step: 7
Training loss: 2.1150336265563965
Validation loss: 2.046388645966848

Epoch: 5| Step: 8
Training loss: 2.1351819038391113
Validation loss: 2.043777013818423

Epoch: 5| Step: 9
Training loss: 2.2644479274749756
Validation loss: 2.047800029317538

Epoch: 5| Step: 10
Training loss: 2.114124298095703
Validation loss: 2.041736756761869

Epoch: 5| Step: 11
Training loss: 2.9727487564086914
Validation loss: 2.0447435875733695

Epoch: 78| Step: 0
Training loss: 1.9586845636367798
Validation loss: 2.043331970771154

Epoch: 5| Step: 1
Training loss: 2.2650437355041504
Validation loss: 2.0380898863077164

Epoch: 5| Step: 2
Training loss: 1.8499294519424438
Validation loss: 2.0477030326922736

Epoch: 5| Step: 3
Training loss: 1.965460181236267
Validation loss: 2.0500069757302604

Epoch: 5| Step: 4
Training loss: 2.4755501747131348
Validation loss: 2.0594223737716675

Epoch: 5| Step: 5
Training loss: 1.9587332010269165
Validation loss: 2.0569872558116913

Epoch: 5| Step: 6
Training loss: 1.5419615507125854
Validation loss: 2.0727016727129617

Epoch: 5| Step: 7
Training loss: 2.8355953693389893
Validation loss: 2.078634927670161

Epoch: 5| Step: 8
Training loss: 2.4558277130126953
Validation loss: 2.063348094622294

Epoch: 5| Step: 9
Training loss: 2.40746808052063
Validation loss: 2.06271168589592

Epoch: 5| Step: 10
Training loss: 2.221724271774292
Validation loss: 2.0490293949842453

Epoch: 5| Step: 11
Training loss: 2.4492313861846924
Validation loss: 2.0398639887571335

Epoch: 79| Step: 0
Training loss: 2.4625163078308105
Validation loss: 2.0365384171406427

Epoch: 5| Step: 1
Training loss: 2.0983738899230957
Validation loss: 2.0405832082033157

Epoch: 5| Step: 2
Training loss: 1.863539457321167
Validation loss: 2.0455303539832435

Epoch: 5| Step: 3
Training loss: 2.6467349529266357
Validation loss: 2.0676689694325128

Epoch: 5| Step: 4
Training loss: 2.2580251693725586
Validation loss: 2.074264720082283

Epoch: 5| Step: 5
Training loss: 2.27356219291687
Validation loss: 2.0973183810710907

Epoch: 5| Step: 6
Training loss: 2.2184741497039795
Validation loss: 2.1014418403307595

Epoch: 5| Step: 7
Training loss: 1.4988142251968384
Validation loss: 2.115497281153997

Epoch: 5| Step: 8
Training loss: 2.2699434757232666
Validation loss: 2.131692757209142

Epoch: 5| Step: 9
Training loss: 2.884754180908203
Validation loss: 2.1397150456905365

Epoch: 5| Step: 10
Training loss: 2.2877471446990967
Validation loss: 2.1462577482064567

Epoch: 5| Step: 11
Training loss: 1.7862030267715454
Validation loss: 2.1383670518795648

Epoch: 80| Step: 0
Training loss: 2.2668449878692627
Validation loss: 2.1369296610355377

Epoch: 5| Step: 1
Training loss: 2.130589723587036
Validation loss: 2.1356885582208633

Epoch: 5| Step: 2
Training loss: 2.5319931507110596
Validation loss: 2.123665541410446

Epoch: 5| Step: 3
Training loss: 2.1272690296173096
Validation loss: 2.129675661524137

Epoch: 5| Step: 4
Training loss: 1.8125919103622437
Validation loss: 2.1119261582692466

Epoch: 5| Step: 5
Training loss: 2.4706692695617676
Validation loss: 2.1161360690991082

Epoch: 5| Step: 6
Training loss: 2.102677822113037
Validation loss: 2.1126790195703506

Epoch: 5| Step: 7
Training loss: 2.749152421951294
Validation loss: 2.109666640559832

Epoch: 5| Step: 8
Training loss: 2.247581958770752
Validation loss: 2.110920106371244

Epoch: 5| Step: 9
Training loss: 2.6964752674102783
Validation loss: 2.1024919201930365

Epoch: 5| Step: 10
Training loss: 2.1744322776794434
Validation loss: 2.0937706530094147

Epoch: 5| Step: 11
Training loss: 1.9319487810134888
Validation loss: 2.0888682852188745

Epoch: 81| Step: 0
Training loss: 2.2976231575012207
Validation loss: 2.0858953396479287

Epoch: 5| Step: 1
Training loss: 2.0973994731903076
Validation loss: 2.081028168400129

Epoch: 5| Step: 2
Training loss: 2.4245142936706543
Validation loss: 2.0699234505494437

Epoch: 5| Step: 3
Training loss: 2.460559129714966
Validation loss: 2.0656015078226724

Epoch: 5| Step: 4
Training loss: 2.723844528198242
Validation loss: 2.0629828572273254

Epoch: 5| Step: 5
Training loss: 2.123345375061035
Validation loss: 2.0631445397933326

Epoch: 5| Step: 6
Training loss: 2.4394211769104004
Validation loss: 2.056725059946378

Epoch: 5| Step: 7
Training loss: 2.1831140518188477
Validation loss: 2.0501794864734015

Epoch: 5| Step: 8
Training loss: 1.8747994899749756
Validation loss: 2.0447949866453805

Epoch: 5| Step: 9
Training loss: 2.5063443183898926
Validation loss: 2.0445386320352554

Epoch: 5| Step: 10
Training loss: 1.5484976768493652
Validation loss: 2.0383058041334152

Epoch: 5| Step: 11
Training loss: 2.804394483566284
Validation loss: 2.0390566686789193

Epoch: 82| Step: 0
Training loss: 2.080502986907959
Validation loss: 2.035657445589701

Epoch: 5| Step: 1
Training loss: 2.3111491203308105
Validation loss: 2.037282516558965

Epoch: 5| Step: 2
Training loss: 2.6973280906677246
Validation loss: 2.0329244285821915

Epoch: 5| Step: 3
Training loss: 1.8012778759002686
Validation loss: 2.0265403936306634

Epoch: 5| Step: 4
Training loss: 2.1046860218048096
Validation loss: 2.0316122174263

Epoch: 5| Step: 5
Training loss: 2.231259822845459
Validation loss: 2.0308048029740653

Epoch: 5| Step: 6
Training loss: 2.254141330718994
Validation loss: 2.02375328540802

Epoch: 5| Step: 7
Training loss: 2.7895078659057617
Validation loss: 2.0195389141639075

Epoch: 5| Step: 8
Training loss: 2.1042277812957764
Validation loss: 2.0196307053168616

Epoch: 5| Step: 9
Training loss: 1.8959014415740967
Validation loss: 2.016333724061648

Epoch: 5| Step: 10
Training loss: 1.8652088642120361
Validation loss: 2.008308236797651

Epoch: 5| Step: 11
Training loss: 2.1500706672668457
Validation loss: 2.023338263233503

Epoch: 83| Step: 0
Training loss: 2.453909397125244
Validation loss: 2.0228773107131324

Epoch: 5| Step: 1
Training loss: 2.410691499710083
Validation loss: 2.049300422271093

Epoch: 5| Step: 2
Training loss: 2.7324061393737793
Validation loss: 2.059066951274872

Epoch: 5| Step: 3
Training loss: 1.6570255756378174
Validation loss: 2.054602012038231

Epoch: 5| Step: 4
Training loss: 1.7881892919540405
Validation loss: 2.048158104221026

Epoch: 5| Step: 5
Training loss: 2.08205246925354
Validation loss: 2.050077552596728

Epoch: 5| Step: 6
Training loss: 2.6446986198425293
Validation loss: 2.0412037670612335

Epoch: 5| Step: 7
Training loss: 2.124946117401123
Validation loss: 2.0375391642252603

Epoch: 5| Step: 8
Training loss: 1.95375657081604
Validation loss: 2.0329629431168237

Epoch: 5| Step: 9
Training loss: 2.600865125656128
Validation loss: 2.0182384749253592

Epoch: 5| Step: 10
Training loss: 1.601348876953125
Validation loss: 2.018754372994105

Epoch: 5| Step: 11
Training loss: 2.0067076683044434
Validation loss: 2.023286739985148

Epoch: 84| Step: 0
Training loss: 1.928688645362854
Validation loss: 2.0285193026065826

Epoch: 5| Step: 1
Training loss: 2.279650926589966
Validation loss: 2.0310964783032737

Epoch: 5| Step: 2
Training loss: 2.449237108230591
Validation loss: 2.029431035121282

Epoch: 5| Step: 3
Training loss: 2.179426908493042
Validation loss: 2.029545694589615

Epoch: 5| Step: 4
Training loss: 2.3498170375823975
Validation loss: 2.0294392108917236

Epoch: 5| Step: 5
Training loss: 1.8505080938339233
Validation loss: 2.0348567565282187

Epoch: 5| Step: 6
Training loss: 2.4831976890563965
Validation loss: 2.0301370372374854

Epoch: 5| Step: 7
Training loss: 2.0698254108428955
Validation loss: 2.0327966858943305

Epoch: 5| Step: 8
Training loss: 2.4117050170898438
Validation loss: 2.030244062344233

Epoch: 5| Step: 9
Training loss: 2.2309999465942383
Validation loss: 2.0369327863057456

Epoch: 5| Step: 10
Training loss: 1.8444674015045166
Validation loss: 2.037217100461324

Epoch: 5| Step: 11
Training loss: 1.9248825311660767
Validation loss: 2.0400075018405914

Epoch: 85| Step: 0
Training loss: 2.422476053237915
Validation loss: 2.0324434091647468

Epoch: 5| Step: 1
Training loss: 1.9288123846054077
Validation loss: 2.0284474740425744

Epoch: 5| Step: 2
Training loss: 1.9789924621582031
Validation loss: 2.0206378400325775

Epoch: 5| Step: 3
Training loss: 2.125798225402832
Validation loss: 2.0187064558267593

Epoch: 5| Step: 4
Training loss: 2.5496182441711426
Validation loss: 2.0248148987690606

Epoch: 5| Step: 5
Training loss: 1.824570894241333
Validation loss: 2.036805346608162

Epoch: 5| Step: 6
Training loss: 1.8725216388702393
Validation loss: 2.037613516052564

Epoch: 5| Step: 7
Training loss: 2.16709303855896
Validation loss: 2.0431354691584906

Epoch: 5| Step: 8
Training loss: 2.088704824447632
Validation loss: 2.0393245120843253

Epoch: 5| Step: 9
Training loss: 2.588928461074829
Validation loss: 2.0399872859319053

Epoch: 5| Step: 10
Training loss: 2.2299067974090576
Validation loss: 2.041900098323822

Epoch: 5| Step: 11
Training loss: 2.8893558979034424
Validation loss: 2.0387063920497894

Epoch: 86| Step: 0
Training loss: 2.273306131362915
Validation loss: 2.0325973679622016

Epoch: 5| Step: 1
Training loss: 2.584974765777588
Validation loss: 2.0285646269718804

Epoch: 5| Step: 2
Training loss: 1.7395662069320679
Validation loss: 2.034696489572525

Epoch: 5| Step: 3
Training loss: 2.1961135864257812
Validation loss: 2.037113214532534

Epoch: 5| Step: 4
Training loss: 2.184372663497925
Validation loss: 2.0373701006174088

Epoch: 5| Step: 5
Training loss: 2.3458616733551025
Validation loss: 2.0303701758384705

Epoch: 5| Step: 6
Training loss: 1.826570749282837
Validation loss: 2.0315814912319183

Epoch: 5| Step: 7
Training loss: 1.9135900735855103
Validation loss: 2.0302653908729553

Epoch: 5| Step: 8
Training loss: 2.620518207550049
Validation loss: 2.0319929917653403

Epoch: 5| Step: 9
Training loss: 2.019261121749878
Validation loss: 2.0333212862412133

Epoch: 5| Step: 10
Training loss: 2.1339893341064453
Validation loss: 2.0235073963801065

Epoch: 5| Step: 11
Training loss: 2.9984846115112305
Validation loss: 2.026326671242714

Epoch: 87| Step: 0
Training loss: 2.206049680709839
Validation loss: 2.0262208680311837

Epoch: 5| Step: 1
Training loss: 2.237501621246338
Validation loss: 2.0214143842458725

Epoch: 5| Step: 2
Training loss: 2.1030499935150146
Validation loss: 2.0297394891579947

Epoch: 5| Step: 3
Training loss: 2.3008103370666504
Validation loss: 2.0266221463680267

Epoch: 5| Step: 4
Training loss: 2.3071959018707275
Validation loss: 2.0266319612661996

Epoch: 5| Step: 5
Training loss: 1.9545570611953735
Validation loss: 2.0308993508418403

Epoch: 5| Step: 6
Training loss: 2.0643601417541504
Validation loss: 2.0237851291894913

Epoch: 5| Step: 7
Training loss: 1.8564618825912476
Validation loss: 2.0178825358549752

Epoch: 5| Step: 8
Training loss: 2.1238133907318115
Validation loss: 2.018865962823232

Epoch: 5| Step: 9
Training loss: 2.3718459606170654
Validation loss: 2.024387573202451

Epoch: 5| Step: 10
Training loss: 2.2758114337921143
Validation loss: 2.0283346424500146

Epoch: 5| Step: 11
Training loss: 2.067131757736206
Validation loss: 2.036750684181849

Epoch: 88| Step: 0
Training loss: 2.020233631134033
Validation loss: 2.038035199046135

Epoch: 5| Step: 1
Training loss: 2.0923702716827393
Validation loss: 2.0427704602479935

Epoch: 5| Step: 2
Training loss: 2.206071376800537
Validation loss: 2.039866874615351

Epoch: 5| Step: 3
Training loss: 2.36769437789917
Validation loss: 2.0528901517391205

Epoch: 5| Step: 4
Training loss: 2.2810966968536377
Validation loss: 2.0388356496890387

Epoch: 5| Step: 5
Training loss: 1.7689323425292969
Validation loss: 2.0431206971406937

Epoch: 5| Step: 6
Training loss: 2.1521809101104736
Validation loss: 2.053729236125946

Epoch: 5| Step: 7
Training loss: 2.125969886779785
Validation loss: 2.0376252084970474

Epoch: 5| Step: 8
Training loss: 1.6506307125091553
Validation loss: 2.0333767185608544

Epoch: 5| Step: 9
Training loss: 2.585681200027466
Validation loss: 2.0313960909843445

Epoch: 5| Step: 10
Training loss: 2.3013033866882324
Validation loss: 2.031236415108045

Epoch: 5| Step: 11
Training loss: 2.787623882293701
Validation loss: 2.026826779047648

Epoch: 89| Step: 0
Training loss: 2.1966724395751953
Validation loss: 2.038865397373835

Epoch: 5| Step: 1
Training loss: 1.9978563785552979
Validation loss: 2.037821739912033

Epoch: 5| Step: 2
Training loss: 2.150858163833618
Validation loss: 2.0347045958042145

Epoch: 5| Step: 3
Training loss: 2.1241421699523926
Validation loss: 2.0354696114857993

Epoch: 5| Step: 4
Training loss: 2.3605875968933105
Validation loss: 2.026434669891993

Epoch: 5| Step: 5
Training loss: 1.8354079723358154
Validation loss: 2.0325420051813126

Epoch: 5| Step: 6
Training loss: 2.5925707817077637
Validation loss: 2.018913760781288

Epoch: 5| Step: 7
Training loss: 1.9639081954956055
Validation loss: 2.023739899198214

Epoch: 5| Step: 8
Training loss: 2.4330971240997314
Validation loss: 2.0258220583200455

Epoch: 5| Step: 9
Training loss: 2.15339732170105
Validation loss: 2.0239942421515784

Epoch: 5| Step: 10
Training loss: 2.025545358657837
Validation loss: 2.0373211155335107

Epoch: 5| Step: 11
Training loss: 2.21340274810791
Validation loss: 2.0429139584302902

Epoch: 90| Step: 0
Training loss: 2.5438549518585205
Validation loss: 2.03547033170859

Epoch: 5| Step: 1
Training loss: 1.6132415533065796
Validation loss: 2.030720720688502

Epoch: 5| Step: 2
Training loss: 2.2085094451904297
Validation loss: 2.0372850596904755

Epoch: 5| Step: 3
Training loss: 1.9994901418685913
Validation loss: 2.032864769299825

Epoch: 5| Step: 4
Training loss: 2.452198028564453
Validation loss: 2.041769822438558

Epoch: 5| Step: 5
Training loss: 2.085864543914795
Validation loss: 2.0403069059054055

Epoch: 5| Step: 6
Training loss: 2.4959845542907715
Validation loss: 2.0449046343564987

Epoch: 5| Step: 7
Training loss: 2.2338311672210693
Validation loss: 2.056326081355413

Epoch: 5| Step: 8
Training loss: 2.497101306915283
Validation loss: 2.051115726431211

Epoch: 5| Step: 9
Training loss: 1.570176362991333
Validation loss: 2.0429300516843796

Epoch: 5| Step: 10
Training loss: 1.9885075092315674
Validation loss: 2.0366484026114144

Epoch: 5| Step: 11
Training loss: 1.7062040567398071
Validation loss: 2.0463006049394608

Epoch: 91| Step: 0
Training loss: 1.8011271953582764
Validation loss: 2.058229441444079

Epoch: 5| Step: 1
Training loss: 2.0252685546875
Validation loss: 2.048455352584521

Epoch: 5| Step: 2
Training loss: 2.125296115875244
Validation loss: 2.042933622996012

Epoch: 5| Step: 3
Training loss: 2.01328706741333
Validation loss: 2.032511497537295

Epoch: 5| Step: 4
Training loss: 2.6534781455993652
Validation loss: 2.0399717638889947

Epoch: 5| Step: 5
Training loss: 2.1005752086639404
Validation loss: 2.0333383480707803

Epoch: 5| Step: 6
Training loss: 2.094524383544922
Validation loss: 2.025737856825193

Epoch: 5| Step: 7
Training loss: 2.237400531768799
Validation loss: 2.031223699450493

Epoch: 5| Step: 8
Training loss: 2.0202815532684326
Validation loss: 2.021475767095884

Epoch: 5| Step: 9
Training loss: 2.3460628986358643
Validation loss: 2.0309607485930123

Epoch: 5| Step: 10
Training loss: 2.2042407989501953
Validation loss: 2.0324295262495675

Epoch: 5| Step: 11
Training loss: 2.2912702560424805
Validation loss: 2.0423567642768226

Epoch: 92| Step: 0
Training loss: 2.154641628265381
Validation loss: 2.0332154432932534

Epoch: 5| Step: 1
Training loss: 2.5104994773864746
Validation loss: 2.0374660193920135

Epoch: 5| Step: 2
Training loss: 2.8159847259521484
Validation loss: 2.0366996824741364

Epoch: 5| Step: 3
Training loss: 1.877529501914978
Validation loss: 2.0361493726571402

Epoch: 5| Step: 4
Training loss: 2.397754192352295
Validation loss: 2.0344257801771164

Epoch: 5| Step: 5
Training loss: 1.7929439544677734
Validation loss: 2.035555218656858

Epoch: 5| Step: 6
Training loss: 2.2422471046447754
Validation loss: 2.0303276777267456

Epoch: 5| Step: 7
Training loss: 2.0162110328674316
Validation loss: 2.034419685602188

Epoch: 5| Step: 8
Training loss: 1.680633544921875
Validation loss: 2.0378511250019073

Epoch: 5| Step: 9
Training loss: 2.068500518798828
Validation loss: 2.049158518513044

Epoch: 5| Step: 10
Training loss: 2.148693084716797
Validation loss: 2.0420141319433847

Epoch: 5| Step: 11
Training loss: 2.049659490585327
Validation loss: 2.0457101414601007

Epoch: 93| Step: 0
Training loss: 2.698427677154541
Validation loss: 2.0490994453430176

Epoch: 5| Step: 1
Training loss: 2.1086649894714355
Validation loss: 2.043925181031227

Epoch: 5| Step: 2
Training loss: 1.7473468780517578
Validation loss: 2.061432659626007

Epoch: 5| Step: 3
Training loss: 1.9910409450531006
Validation loss: 2.0600036730368934

Epoch: 5| Step: 4
Training loss: 1.7496492862701416
Validation loss: 2.052218437194824

Epoch: 5| Step: 5
Training loss: 2.3166356086730957
Validation loss: 2.0413301587104797

Epoch: 5| Step: 6
Training loss: 2.655430316925049
Validation loss: 2.0434532314538956

Epoch: 5| Step: 7
Training loss: 2.21016263961792
Validation loss: 2.042776202162107

Epoch: 5| Step: 8
Training loss: 2.193777561187744
Validation loss: 2.0401264677445092

Epoch: 5| Step: 9
Training loss: 1.953101396560669
Validation loss: 2.025844087203344

Epoch: 5| Step: 10
Training loss: 1.9965362548828125
Validation loss: 2.0320000698169074

Epoch: 5| Step: 11
Training loss: 2.238780975341797
Validation loss: 2.0356122304995856

Epoch: 94| Step: 0
Training loss: 2.5546092987060547
Validation loss: 2.0378852089246116

Epoch: 5| Step: 1
Training loss: 2.4552369117736816
Validation loss: 2.0502782265345254

Epoch: 5| Step: 2
Training loss: 2.1172804832458496
Validation loss: 2.0399736563364663

Epoch: 5| Step: 3
Training loss: 1.5536662340164185
Validation loss: 2.032147169113159

Epoch: 5| Step: 4
Training loss: 1.3167794942855835
Validation loss: 2.035912642876307

Epoch: 5| Step: 5
Training loss: 2.649885416030884
Validation loss: 2.041350136200587

Epoch: 5| Step: 6
Training loss: 2.166621446609497
Validation loss: 2.038913036386172

Epoch: 5| Step: 7
Training loss: 2.048779249191284
Validation loss: 2.034451345602671

Epoch: 5| Step: 8
Training loss: 2.4332118034362793
Validation loss: 2.024637664357821

Epoch: 5| Step: 9
Training loss: 2.2333600521087646
Validation loss: 2.044687191645304

Epoch: 5| Step: 10
Training loss: 2.216062545776367
Validation loss: 2.0353529353936515

Epoch: 5| Step: 11
Training loss: 1.4876102209091187
Validation loss: 2.034603794415792

Epoch: 95| Step: 0
Training loss: 2.284477949142456
Validation loss: 2.049465780456861

Epoch: 5| Step: 1
Training loss: 2.565568447113037
Validation loss: 2.0573648562033973

Epoch: 5| Step: 2
Training loss: 2.479992389678955
Validation loss: 2.069817046324412

Epoch: 5| Step: 3
Training loss: 2.291449546813965
Validation loss: 2.0748743216196694

Epoch: 5| Step: 4
Training loss: 1.8734239339828491
Validation loss: 2.0745273431142173

Epoch: 5| Step: 5
Training loss: 2.5367138385772705
Validation loss: 2.077014903227488

Epoch: 5| Step: 6
Training loss: 1.3213516473770142
Validation loss: 2.06794410943985

Epoch: 5| Step: 7
Training loss: 1.9813941717147827
Validation loss: 2.051087409257889

Epoch: 5| Step: 8
Training loss: 2.676487445831299
Validation loss: 2.0432667483886084

Epoch: 5| Step: 9
Training loss: 2.124786376953125
Validation loss: 2.03878382841746

Epoch: 5| Step: 10
Training loss: 1.7616266012191772
Validation loss: 2.0264191329479218

Epoch: 5| Step: 11
Training loss: 2.137078046798706
Validation loss: 2.019099071621895

Epoch: 96| Step: 0
Training loss: 2.928313732147217
Validation loss: 2.0262669026851654

Epoch: 5| Step: 1
Training loss: 2.141834020614624
Validation loss: 2.0280115654071174

Epoch: 5| Step: 2
Training loss: 1.612281084060669
Validation loss: 2.029531459013621

Epoch: 5| Step: 3
Training loss: 2.2550933361053467
Validation loss: 2.0289076566696167

Epoch: 5| Step: 4
Training loss: 2.284168243408203
Validation loss: 2.0266270339488983

Epoch: 5| Step: 5
Training loss: 1.8232015371322632
Validation loss: 2.0319481740395227

Epoch: 5| Step: 6
Training loss: 2.3662383556365967
Validation loss: 2.0306269228458405

Epoch: 5| Step: 7
Training loss: 1.9458515644073486
Validation loss: 2.0310680071512857

Epoch: 5| Step: 8
Training loss: 2.5196285247802734
Validation loss: 2.0295479595661163

Epoch: 5| Step: 9
Training loss: 1.894958257675171
Validation loss: 2.031993865966797

Epoch: 5| Step: 10
Training loss: 2.3811194896698
Validation loss: 2.0381285001834235

Epoch: 5| Step: 11
Training loss: 1.9840950965881348
Validation loss: 2.0377327303091683

Epoch: 97| Step: 0
Training loss: 1.610788106918335
Validation loss: 2.0431601057449975

Epoch: 5| Step: 1
Training loss: 2.0327095985412598
Validation loss: 2.0383956333001456

Epoch: 5| Step: 2
Training loss: 2.5259454250335693
Validation loss: 2.0360007683436074

Epoch: 5| Step: 3
Training loss: 2.777721643447876
Validation loss: 2.0385449131329856

Epoch: 5| Step: 4
Training loss: 2.17242431640625
Validation loss: 2.037583460410436

Epoch: 5| Step: 5
Training loss: 1.4662823677062988
Validation loss: 2.031412402788798

Epoch: 5| Step: 6
Training loss: 1.9508424997329712
Validation loss: 2.0299809128046036

Epoch: 5| Step: 7
Training loss: 2.579308271408081
Validation loss: 2.0216658463080726

Epoch: 5| Step: 8
Training loss: 2.6071524620056152
Validation loss: 2.026601791381836

Epoch: 5| Step: 9
Training loss: 2.4319262504577637
Validation loss: 2.0201385468244553

Epoch: 5| Step: 10
Training loss: 1.982568383216858
Validation loss: 2.027374818921089

Epoch: 5| Step: 11
Training loss: 2.193115472793579
Validation loss: 2.019670287768046

Epoch: 98| Step: 0
Training loss: 2.0007424354553223
Validation loss: 2.031208331386248

Epoch: 5| Step: 1
Training loss: 2.0674052238464355
Validation loss: 2.028276026248932

Epoch: 5| Step: 2
Training loss: 2.5385591983795166
Validation loss: 2.023426021138827

Epoch: 5| Step: 3
Training loss: 2.3118038177490234
Validation loss: 2.0194011926651

Epoch: 5| Step: 4
Training loss: 2.0189270973205566
Validation loss: 2.0224760870138803

Epoch: 5| Step: 5
Training loss: 2.7844138145446777
Validation loss: 2.0247165064016976

Epoch: 5| Step: 6
Training loss: 2.284839391708374
Validation loss: 2.021864910920461

Epoch: 5| Step: 7
Training loss: 1.968600869178772
Validation loss: 2.0234495451052985

Epoch: 5| Step: 8
Training loss: 1.3185850381851196
Validation loss: 2.022850121061007

Epoch: 5| Step: 9
Training loss: 2.2332661151885986
Validation loss: 2.025763844450315

Epoch: 5| Step: 10
Training loss: 2.2177562713623047
Validation loss: 2.02736034989357

Epoch: 5| Step: 11
Training loss: 2.0631706714630127
Validation loss: 2.0238759269316993

Epoch: 99| Step: 0
Training loss: 1.6029783487319946
Validation loss: 2.032704864939054

Epoch: 5| Step: 1
Training loss: 2.411640167236328
Validation loss: 2.0315686762332916

Epoch: 5| Step: 2
Training loss: 2.497981548309326
Validation loss: 2.038484806815783

Epoch: 5| Step: 3
Training loss: 2.233227252960205
Validation loss: 2.0401660750309625

Epoch: 5| Step: 4
Training loss: 1.7331279516220093
Validation loss: 2.034351338942846

Epoch: 5| Step: 5
Training loss: 1.7975590229034424
Validation loss: 2.0291068702936172

Epoch: 5| Step: 6
Training loss: 1.476291298866272
Validation loss: 2.0360409021377563

Epoch: 5| Step: 7
Training loss: 2.84098482131958
Validation loss: 2.0326569179693856

Epoch: 5| Step: 8
Training loss: 1.7715648412704468
Validation loss: 2.023022621870041

Epoch: 5| Step: 9
Training loss: 2.6991615295410156
Validation loss: 2.033380369345347

Epoch: 5| Step: 10
Training loss: 2.5306167602539062
Validation loss: 2.0280046264330545

Epoch: 5| Step: 11
Training loss: 2.1776726245880127
Validation loss: 2.033524220188459

Epoch: 100| Step: 0
Training loss: 2.643256664276123
Validation loss: 2.0296169022719064

Epoch: 5| Step: 1
Training loss: 2.0342612266540527
Validation loss: 2.0242173820734024

Epoch: 5| Step: 2
Training loss: 2.121842622756958
Validation loss: 2.0335491796334586

Epoch: 5| Step: 3
Training loss: 2.2868220806121826
Validation loss: 2.022927686572075

Epoch: 5| Step: 4
Training loss: 2.0521740913391113
Validation loss: 2.027828941742579

Epoch: 5| Step: 5
Training loss: 2.0525012016296387
Validation loss: 2.0247014462947845

Epoch: 5| Step: 6
Training loss: 2.4669437408447266
Validation loss: 2.0252653708060584

Epoch: 5| Step: 7
Training loss: 1.8193317651748657
Validation loss: 2.0296470522880554

Epoch: 5| Step: 8
Training loss: 2.1723523139953613
Validation loss: 2.028943041960398

Epoch: 5| Step: 9
Training loss: 2.285245656967163
Validation loss: 2.0348074237505593

Epoch: 5| Step: 10
Training loss: 1.7821896076202393
Validation loss: 2.029387906193733

Epoch: 5| Step: 11
Training loss: 1.3663357496261597
Validation loss: 2.036095624168714

Epoch: 101| Step: 0
Training loss: 1.5628552436828613
Validation loss: 2.044704327980677

Epoch: 5| Step: 1
Training loss: 1.742611289024353
Validation loss: 2.065267860889435

Epoch: 5| Step: 2
Training loss: 2.6845309734344482
Validation loss: 2.067040284474691

Epoch: 5| Step: 3
Training loss: 1.943539023399353
Validation loss: 2.0823176552851996

Epoch: 5| Step: 4
Training loss: 2.0465221405029297
Validation loss: 2.0814100553592048

Epoch: 5| Step: 5
Training loss: 2.7827935218811035
Validation loss: 2.0796864132086434

Epoch: 5| Step: 6
Training loss: 2.439854145050049
Validation loss: 2.085937018195788

Epoch: 5| Step: 7
Training loss: 2.0895824432373047
Validation loss: 2.0638526479403176

Epoch: 5| Step: 8
Training loss: 2.3976213932037354
Validation loss: 2.0603837768236795

Epoch: 5| Step: 9
Training loss: 2.148293972015381
Validation loss: 2.0399541705846786

Epoch: 5| Step: 10
Training loss: 1.7349754571914673
Validation loss: 2.047147755821546

Epoch: 5| Step: 11
Training loss: 2.9183859825134277
Validation loss: 2.03363669415315

Epoch: 102| Step: 0
Training loss: 2.381899833679199
Validation loss: 2.0344311942656836

Epoch: 5| Step: 1
Training loss: 2.1640782356262207
Validation loss: 2.0386578738689423

Epoch: 5| Step: 2
Training loss: 1.906905174255371
Validation loss: 2.0326930036147437

Epoch: 5| Step: 3
Training loss: 2.1011343002319336
Validation loss: 2.0278278241554895

Epoch: 5| Step: 4
Training loss: 2.344791889190674
Validation loss: 2.0264865358670554

Epoch: 5| Step: 5
Training loss: 2.4749605655670166
Validation loss: 2.03047222395738

Epoch: 5| Step: 6
Training loss: 1.7728601694107056
Validation loss: 2.0267926255861917

Epoch: 5| Step: 7
Training loss: 1.7231327295303345
Validation loss: 2.0262412329514823

Epoch: 5| Step: 8
Training loss: 2.180549383163452
Validation loss: 2.0341684172550836

Epoch: 5| Step: 9
Training loss: 2.184154510498047
Validation loss: 2.0238688637812934

Epoch: 5| Step: 10
Training loss: 2.425779104232788
Validation loss: 2.0288579364617667

Epoch: 5| Step: 11
Training loss: 1.8233145475387573
Validation loss: 2.0335109333197274

Epoch: 103| Step: 0
Training loss: 2.0249547958374023
Validation loss: 2.033584177494049

Epoch: 5| Step: 1
Training loss: 2.3495399951934814
Validation loss: 2.0288542956113815

Epoch: 5| Step: 2
Training loss: 2.556716203689575
Validation loss: 2.03300608197848

Epoch: 5| Step: 3
Training loss: 1.6847870349884033
Validation loss: 2.030490835507711

Epoch: 5| Step: 4
Training loss: 1.7871204614639282
Validation loss: 2.032199442386627

Epoch: 5| Step: 5
Training loss: 2.2950797080993652
Validation loss: 2.0336456149816513

Epoch: 5| Step: 6
Training loss: 2.7598063945770264
Validation loss: 2.0432226856549582

Epoch: 5| Step: 7
Training loss: 1.586919903755188
Validation loss: 2.0459090123573938

Epoch: 5| Step: 8
Training loss: 1.7345924377441406
Validation loss: 2.0544648865858712

Epoch: 5| Step: 9
Training loss: 2.5151398181915283
Validation loss: 2.0407779117425284

Epoch: 5| Step: 10
Training loss: 2.090151071548462
Validation loss: 2.041504090030988

Epoch: 5| Step: 11
Training loss: 2.5740411281585693
Validation loss: 2.0364764680465064

Epoch: 104| Step: 0
Training loss: 2.387833595275879
Validation loss: 2.031500667333603

Epoch: 5| Step: 1
Training loss: 1.735205054283142
Validation loss: 2.0430700331926346

Epoch: 5| Step: 2
Training loss: 2.6192753314971924
Validation loss: 2.0450641016165414

Epoch: 5| Step: 3
Training loss: 2.328556776046753
Validation loss: 2.037341167529424

Epoch: 5| Step: 4
Training loss: 2.487905740737915
Validation loss: 2.0244517227013907

Epoch: 5| Step: 5
Training loss: 1.9202187061309814
Validation loss: 2.028662323951721

Epoch: 5| Step: 6
Training loss: 2.091278553009033
Validation loss: 2.0255942940711975

Epoch: 5| Step: 7
Training loss: 2.4830965995788574
Validation loss: 2.020338719089826

Epoch: 5| Step: 8
Training loss: 1.5723453760147095
Validation loss: 2.036507397890091

Epoch: 5| Step: 9
Training loss: 2.1600887775421143
Validation loss: 2.03041901687781

Epoch: 5| Step: 10
Training loss: 1.8694289922714233
Validation loss: 2.0290858447551727

Epoch: 5| Step: 11
Training loss: 1.5145792961120605
Validation loss: 2.0230306684970856

Epoch: 105| Step: 0
Training loss: 2.1771132946014404
Validation loss: 2.0320461094379425

Epoch: 5| Step: 1
Training loss: 2.441056966781616
Validation loss: 2.048828125

Epoch: 5| Step: 2
Training loss: 2.7018792629241943
Validation loss: 2.0504253208637238

Epoch: 5| Step: 3
Training loss: 1.376704454421997
Validation loss: 2.0496057868003845

Epoch: 5| Step: 4
Training loss: 2.123755931854248
Validation loss: 2.0469375550746918

Epoch: 5| Step: 5
Training loss: 2.0235190391540527
Validation loss: 2.039986257751783

Epoch: 5| Step: 6
Training loss: 2.3914072513580322
Validation loss: 2.037919193506241

Epoch: 5| Step: 7
Training loss: 2.14351487159729
Validation loss: 2.0400540182987847

Epoch: 5| Step: 8
Training loss: 2.324977397918701
Validation loss: 2.0374015867710114

Epoch: 5| Step: 9
Training loss: 2.1998438835144043
Validation loss: 2.0246734420458474

Epoch: 5| Step: 10
Training loss: 1.7223708629608154
Validation loss: 2.0223965793848038

Epoch: 5| Step: 11
Training loss: 2.097309112548828
Validation loss: 2.024089296658834

Epoch: 106| Step: 0
Training loss: 2.216686248779297
Validation loss: 2.0404388209184012

Epoch: 5| Step: 1
Training loss: 2.1653363704681396
Validation loss: 2.0336754322052

Epoch: 5| Step: 2
Training loss: 2.031609535217285
Validation loss: 2.0306252936522164

Epoch: 5| Step: 3
Training loss: 2.075120210647583
Validation loss: 2.0382748593886695

Epoch: 5| Step: 4
Training loss: 2.156362533569336
Validation loss: 2.042967215180397

Epoch: 5| Step: 5
Training loss: 2.122885227203369
Validation loss: 2.0334640940030417

Epoch: 5| Step: 6
Training loss: 2.5993218421936035
Validation loss: 2.0352247456709542

Epoch: 5| Step: 7
Training loss: 2.160870313644409
Validation loss: 2.0433353036642075

Epoch: 5| Step: 8
Training loss: 2.029902935028076
Validation loss: 2.053154190381368

Epoch: 5| Step: 9
Training loss: 2.1133294105529785
Validation loss: 2.0368760575850806

Epoch: 5| Step: 10
Training loss: 1.7670873403549194
Validation loss: 2.043073813120524

Epoch: 5| Step: 11
Training loss: 2.3587770462036133
Validation loss: 2.04228741923968

Epoch: 107| Step: 0
Training loss: 2.6219899654388428
Validation loss: 2.033748040596644

Epoch: 5| Step: 1
Training loss: 2.4176769256591797
Validation loss: 2.0483766744534173

Epoch: 5| Step: 2
Training loss: 2.025054693222046
Validation loss: 2.043882350126902

Epoch: 5| Step: 3
Training loss: 2.1382927894592285
Validation loss: 2.0457868725061417

Epoch: 5| Step: 4
Training loss: 2.0496554374694824
Validation loss: 2.0375293691953025

Epoch: 5| Step: 5
Training loss: 1.6864738464355469
Validation loss: 2.0397835026184716

Epoch: 5| Step: 6
Training loss: 2.2339892387390137
Validation loss: 2.031603624423345

Epoch: 5| Step: 7
Training loss: 2.655351161956787
Validation loss: 2.035635749499003

Epoch: 5| Step: 8
Training loss: 1.648319959640503
Validation loss: 2.0258766214052835

Epoch: 5| Step: 9
Training loss: 2.346393585205078
Validation loss: 2.024661456545194

Epoch: 5| Step: 10
Training loss: 1.8562091588974
Validation loss: 2.0233551065127053

Epoch: 5| Step: 11
Training loss: 1.741641879081726
Validation loss: 2.023414740959803

Epoch: 108| Step: 0
Training loss: 1.848410964012146
Validation loss: 2.0319218039512634

Epoch: 5| Step: 1
Training loss: 2.371504306793213
Validation loss: 2.024748275677363

Epoch: 5| Step: 2
Training loss: 1.9218486547470093
Validation loss: 2.030276676019033

Epoch: 5| Step: 3
Training loss: 2.55439829826355
Validation loss: 2.0289674748977027

Epoch: 5| Step: 4
Training loss: 2.3540897369384766
Validation loss: 2.0341822604338327

Epoch: 5| Step: 5
Training loss: 1.855665922164917
Validation loss: 2.029998222986857

Epoch: 5| Step: 6
Training loss: 2.1068062782287598
Validation loss: 2.0301276544729867

Epoch: 5| Step: 7
Training loss: 2.2981390953063965
Validation loss: 2.0221436570088067

Epoch: 5| Step: 8
Training loss: 1.6506589651107788
Validation loss: 2.0256361166636148

Epoch: 5| Step: 9
Training loss: 2.7241339683532715
Validation loss: 2.0306516935427985

Epoch: 5| Step: 10
Training loss: 1.9339561462402344
Validation loss: 2.0259083906809487

Epoch: 5| Step: 11
Training loss: 1.1720049381256104
Validation loss: 2.0306320587793985

Epoch: 109| Step: 0
Training loss: 2.3947060108184814
Validation loss: 2.032147909204165

Epoch: 5| Step: 1
Training loss: 1.8153793811798096
Validation loss: 2.03181025882562

Epoch: 5| Step: 2
Training loss: 2.0741689205169678
Validation loss: 2.0420299818118415

Epoch: 5| Step: 3
Training loss: 2.103144645690918
Validation loss: 2.0368253936370215

Epoch: 5| Step: 4
Training loss: 1.9435310363769531
Validation loss: 2.0267591327428818

Epoch: 5| Step: 5
Training loss: 2.156975507736206
Validation loss: 2.0322705109914145

Epoch: 5| Step: 6
Training loss: 2.236459493637085
Validation loss: 2.0261741081873574

Epoch: 5| Step: 7
Training loss: 1.5936180353164673
Validation loss: 2.025160734852155

Epoch: 5| Step: 8
Training loss: 2.5553102493286133
Validation loss: 2.029616892337799

Epoch: 5| Step: 9
Training loss: 2.17179012298584
Validation loss: 2.0260865141948066

Epoch: 5| Step: 10
Training loss: 2.511002779006958
Validation loss: 2.036891038219134

Epoch: 5| Step: 11
Training loss: 1.6181132793426514
Validation loss: 2.034175689021746

Epoch: 110| Step: 0
Training loss: 1.9720672369003296
Validation loss: 2.03251188993454

Epoch: 5| Step: 1
Training loss: 1.7555696964263916
Validation loss: 2.0438248962163925

Epoch: 5| Step: 2
Training loss: 1.7519969940185547
Validation loss: 2.0361253917217255

Epoch: 5| Step: 3
Training loss: 1.7963440418243408
Validation loss: 2.038694833715757

Epoch: 5| Step: 4
Training loss: 3.013181209564209
Validation loss: 2.0409367134173713

Epoch: 5| Step: 5
Training loss: 2.1146156787872314
Validation loss: 2.0473351577917733

Epoch: 5| Step: 6
Training loss: 2.2561771869659424
Validation loss: 2.0355101823806763

Epoch: 5| Step: 7
Training loss: 2.6621906757354736
Validation loss: 2.0398493160804114

Epoch: 5| Step: 8
Training loss: 1.9129711389541626
Validation loss: 2.0378152330716452

Epoch: 5| Step: 9
Training loss: 2.0577991008758545
Validation loss: 2.038320610920588

Epoch: 5| Step: 10
Training loss: 2.1783862113952637
Validation loss: 2.0215743084748587

Epoch: 5| Step: 11
Training loss: 2.120377540588379
Validation loss: 2.0347730914751687

Epoch: 111| Step: 0
Training loss: 2.5002269744873047
Validation loss: 2.0309051324923835

Epoch: 5| Step: 1
Training loss: 2.471546173095703
Validation loss: 2.0424994031588235

Epoch: 5| Step: 2
Training loss: 1.5103384256362915
Validation loss: 2.0451820294062295

Epoch: 5| Step: 3
Training loss: 1.9468002319335938
Validation loss: 2.0487310190995536

Epoch: 5| Step: 4
Training loss: 2.0421082973480225
Validation loss: 2.0560587445894876

Epoch: 5| Step: 5
Training loss: 1.9555362462997437
Validation loss: 2.0550831059614816

Epoch: 5| Step: 6
Training loss: 2.699190139770508
Validation loss: 2.0660422146320343

Epoch: 5| Step: 7
Training loss: 2.081742286682129
Validation loss: 2.055284544825554

Epoch: 5| Step: 8
Training loss: 1.9433002471923828
Validation loss: 2.047400802373886

Epoch: 5| Step: 9
Training loss: 1.8609983921051025
Validation loss: 2.038850615421931

Epoch: 5| Step: 10
Training loss: 2.5213747024536133
Validation loss: 2.029546116789182

Epoch: 5| Step: 11
Training loss: 2.3470239639282227
Validation loss: 2.035728638370832

Epoch: 112| Step: 0
Training loss: 2.1532835960388184
Validation loss: 2.0364636182785034

Epoch: 5| Step: 1
Training loss: 1.6476719379425049
Validation loss: 2.0426936695973077

Epoch: 5| Step: 2
Training loss: 2.5310239791870117
Validation loss: 2.0362790673971176

Epoch: 5| Step: 3
Training loss: 2.3477783203125
Validation loss: 2.053367927670479

Epoch: 5| Step: 4
Training loss: 1.8506643772125244
Validation loss: 2.0451431572437286

Epoch: 5| Step: 5
Training loss: 2.1812491416931152
Validation loss: 2.0478088557720184

Epoch: 5| Step: 6
Training loss: 1.9208377599716187
Validation loss: 2.0453770955403647

Epoch: 5| Step: 7
Training loss: 1.976008415222168
Validation loss: 2.049028769135475

Epoch: 5| Step: 8
Training loss: 2.417893648147583
Validation loss: 2.0489638298749924

Epoch: 5| Step: 9
Training loss: 1.9939018487930298
Validation loss: 2.0453555434942245

Epoch: 5| Step: 10
Training loss: 2.4428648948669434
Validation loss: 2.046707754333814

Epoch: 5| Step: 11
Training loss: 1.9671592712402344
Validation loss: 2.055563986301422

Epoch: 113| Step: 0
Training loss: 1.6622438430786133
Validation loss: 2.048254276315371

Epoch: 5| Step: 1
Training loss: 2.612372875213623
Validation loss: 2.0603030771017075

Epoch: 5| Step: 2
Training loss: 1.9379675388336182
Validation loss: 2.064730331301689

Epoch: 5| Step: 3
Training loss: 1.9784139394760132
Validation loss: 2.0626286268234253

Epoch: 5| Step: 4
Training loss: 2.0905888080596924
Validation loss: 2.049644803007444

Epoch: 5| Step: 5
Training loss: 2.776357650756836
Validation loss: 2.0378607511520386

Epoch: 5| Step: 6
Training loss: 1.7777467966079712
Validation loss: 2.021690006057421

Epoch: 5| Step: 7
Training loss: 2.203514814376831
Validation loss: 2.024708832303683

Epoch: 5| Step: 8
Training loss: 2.4646573066711426
Validation loss: 2.0312829862038293

Epoch: 5| Step: 9
Training loss: 1.9346437454223633
Validation loss: 2.028946205973625

Epoch: 5| Step: 10
Training loss: 2.015958547592163
Validation loss: 2.028365651766459

Epoch: 5| Step: 11
Training loss: 2.1524863243103027
Validation loss: 2.0156135509411492

Epoch: 114| Step: 0
Training loss: 2.366363525390625
Validation loss: 2.033043106396993

Epoch: 5| Step: 1
Training loss: 2.060072422027588
Validation loss: 2.02635250488917

Epoch: 5| Step: 2
Training loss: 2.013713836669922
Validation loss: 2.029950365424156

Epoch: 5| Step: 3
Training loss: 2.0378990173339844
Validation loss: 2.0349816034237542

Epoch: 5| Step: 4
Training loss: 2.351672887802124
Validation loss: 2.0370113303263984

Epoch: 5| Step: 5
Training loss: 1.822718858718872
Validation loss: 2.039521892865499

Epoch: 5| Step: 6
Training loss: 2.310934543609619
Validation loss: 2.034323513507843

Epoch: 5| Step: 7
Training loss: 2.3030896186828613
Validation loss: 2.0299968123435974

Epoch: 5| Step: 8
Training loss: 1.9718866348266602
Validation loss: 2.0260180632273355

Epoch: 5| Step: 9
Training loss: 2.3772010803222656
Validation loss: 2.025799050927162

Epoch: 5| Step: 10
Training loss: 2.1012959480285645
Validation loss: 2.0318602869908013

Epoch: 5| Step: 11
Training loss: 1.8311126232147217
Validation loss: 2.0269897133111954

Epoch: 115| Step: 0
Training loss: 2.5594940185546875
Validation loss: 2.0352335969607034

Epoch: 5| Step: 1
Training loss: 2.0505118370056152
Validation loss: 2.0362354616324105

Epoch: 5| Step: 2
Training loss: 1.5977582931518555
Validation loss: 2.0356669276952744

Epoch: 5| Step: 3
Training loss: 1.8905365467071533
Validation loss: 2.039691830674807

Epoch: 5| Step: 4
Training loss: 2.473893642425537
Validation loss: 2.0354078312714896

Epoch: 5| Step: 5
Training loss: 2.270594358444214
Validation loss: 2.0435008903344474

Epoch: 5| Step: 6
Training loss: 2.136646270751953
Validation loss: 2.0532775272925696

Epoch: 5| Step: 7
Training loss: 1.77802312374115
Validation loss: 2.051102047165235

Epoch: 5| Step: 8
Training loss: 1.6662992238998413
Validation loss: 2.0578278402487435

Epoch: 5| Step: 9
Training loss: 2.761105537414551
Validation loss: 2.0525732139746347

Epoch: 5| Step: 10
Training loss: 2.1978373527526855
Validation loss: 2.0618391782045364

Epoch: 5| Step: 11
Training loss: 1.3587782382965088
Validation loss: 2.058035890261332

Epoch: 116| Step: 0
Training loss: 2.2506327629089355
Validation loss: 2.049151822924614

Epoch: 5| Step: 1
Training loss: 1.993872046470642
Validation loss: 2.064881205558777

Epoch: 5| Step: 2
Training loss: 2.4843485355377197
Validation loss: 2.062681496143341

Epoch: 5| Step: 3
Training loss: 1.8394858837127686
Validation loss: 2.0774949491024017

Epoch: 5| Step: 4
Training loss: 2.3537707328796387
Validation loss: 2.072737395763397

Epoch: 5| Step: 5
Training loss: 2.3752598762512207
Validation loss: 2.0733282466729483

Epoch: 5| Step: 6
Training loss: 1.9693104028701782
Validation loss: 2.0640944838523865

Epoch: 5| Step: 7
Training loss: 1.4551498889923096
Validation loss: 2.0583018312851586

Epoch: 5| Step: 8
Training loss: 2.268465995788574
Validation loss: 2.0643238872289658

Epoch: 5| Step: 9
Training loss: 2.495820999145508
Validation loss: 2.053531010945638

Epoch: 5| Step: 10
Training loss: 2.1237151622772217
Validation loss: 2.0661725600560508

Epoch: 5| Step: 11
Training loss: 1.1462029218673706
Validation loss: 2.0493668566147485

Epoch: 117| Step: 0
Training loss: 2.2420146465301514
Validation loss: 2.0497283240159354

Epoch: 5| Step: 1
Training loss: 2.220792293548584
Validation loss: 2.0467787037293115

Epoch: 5| Step: 2
Training loss: 2.016984462738037
Validation loss: 2.0417770544687905

Epoch: 5| Step: 3
Training loss: 2.266021728515625
Validation loss: 2.0341797222693763

Epoch: 5| Step: 4
Training loss: 2.026115655899048
Validation loss: 2.0358904053767524

Epoch: 5| Step: 5
Training loss: 2.2310597896575928
Validation loss: 2.0328449507554374

Epoch: 5| Step: 6
Training loss: 1.7902069091796875
Validation loss: 2.031426494320234

Epoch: 5| Step: 7
Training loss: 1.8602144718170166
Validation loss: 2.0365929951270423

Epoch: 5| Step: 8
Training loss: 2.506530284881592
Validation loss: 2.0407215704520545

Epoch: 5| Step: 9
Training loss: 1.8565223217010498
Validation loss: 2.037113373478254

Epoch: 5| Step: 10
Training loss: 2.500642776489258
Validation loss: 2.0335315068562827

Epoch: 5| Step: 11
Training loss: 1.208052635192871
Validation loss: 2.033273383975029

Epoch: 118| Step: 0
Training loss: 2.038642644882202
Validation loss: 2.0341714272896447

Epoch: 5| Step: 1
Training loss: 2.206345558166504
Validation loss: 2.0349408636490502

Epoch: 5| Step: 2
Training loss: 1.6071125268936157
Validation loss: 2.034280369679133

Epoch: 5| Step: 3
Training loss: 2.236219882965088
Validation loss: 2.036306848128637

Epoch: 5| Step: 4
Training loss: 2.044849395751953
Validation loss: 2.051693548758825

Epoch: 5| Step: 5
Training loss: 2.0239157676696777
Validation loss: 2.037460500995318

Epoch: 5| Step: 6
Training loss: 2.5797624588012695
Validation loss: 2.049561788638433

Epoch: 5| Step: 7
Training loss: 1.7743148803710938
Validation loss: 2.0613322953383126

Epoch: 5| Step: 8
Training loss: 2.3990187644958496
Validation loss: 2.0690733591715493

Epoch: 5| Step: 9
Training loss: 2.432833194732666
Validation loss: 2.0751681675513587

Epoch: 5| Step: 10
Training loss: 2.4122254848480225
Validation loss: 2.068320726354917

Epoch: 5| Step: 11
Training loss: 1.6562093496322632
Validation loss: 2.0575965891281762

Epoch: 119| Step: 0
Training loss: 2.281315326690674
Validation loss: 2.0478305915991464

Epoch: 5| Step: 1
Training loss: 2.0604989528656006
Validation loss: 2.0329626699288688

Epoch: 5| Step: 2
Training loss: 2.0248892307281494
Validation loss: 2.0307489136854806

Epoch: 5| Step: 3
Training loss: 2.5310707092285156
Validation loss: 2.0194232861200967

Epoch: 5| Step: 4
Training loss: 2.1781513690948486
Validation loss: 2.0311346600453057

Epoch: 5| Step: 5
Training loss: 2.1035103797912598
Validation loss: 2.0306756794452667

Epoch: 5| Step: 6
Training loss: 2.215312957763672
Validation loss: 2.0363169759511948

Epoch: 5| Step: 7
Training loss: 1.9203218221664429
Validation loss: 2.0341716011365256

Epoch: 5| Step: 8
Training loss: 2.2988476753234863
Validation loss: 2.034621626138687

Epoch: 5| Step: 9
Training loss: 2.058215618133545
Validation loss: 2.042317589124044

Epoch: 5| Step: 10
Training loss: 1.9801185131072998
Validation loss: 2.0373422304789224

Epoch: 5| Step: 11
Training loss: 1.7386467456817627
Validation loss: 2.0383182018995285

Epoch: 120| Step: 0
Training loss: 2.0670619010925293
Validation loss: 2.0338959048191705

Epoch: 5| Step: 1
Training loss: 2.792963743209839
Validation loss: 2.030572156111399

Epoch: 5| Step: 2
Training loss: 2.078643798828125
Validation loss: 2.0400255819161734

Epoch: 5| Step: 3
Training loss: 2.6165034770965576
Validation loss: 2.038610269625982

Epoch: 5| Step: 4
Training loss: 1.7538602352142334
Validation loss: 2.036248137553533

Epoch: 5| Step: 5
Training loss: 2.399207592010498
Validation loss: 2.0323198239008584

Epoch: 5| Step: 6
Training loss: 2.2528295516967773
Validation loss: 2.031199802954992

Epoch: 5| Step: 7
Training loss: 1.4289276599884033
Validation loss: 2.019137293100357

Epoch: 5| Step: 8
Training loss: 2.1443238258361816
Validation loss: 2.0307847758134208

Epoch: 5| Step: 9
Training loss: 2.1490797996520996
Validation loss: 2.0374291141827903

Epoch: 5| Step: 10
Training loss: 1.9048388004302979
Validation loss: 2.0262629886468253

Epoch: 5| Step: 11
Training loss: 1.3056185245513916
Validation loss: 2.0211874147256217

Epoch: 121| Step: 0
Training loss: 2.426969051361084
Validation loss: 2.032673954963684

Epoch: 5| Step: 1
Training loss: 2.327582359313965
Validation loss: 2.0341696391503015

Epoch: 5| Step: 2
Training loss: 2.130821704864502
Validation loss: 2.0410530467828116

Epoch: 5| Step: 3
Training loss: 2.094949722290039
Validation loss: 2.0487618297338486

Epoch: 5| Step: 4
Training loss: 2.8095505237579346
Validation loss: 2.0455669263998666

Epoch: 5| Step: 5
Training loss: 1.7564897537231445
Validation loss: 2.051487684249878

Epoch: 5| Step: 6
Training loss: 1.4327528476715088
Validation loss: 2.056563754876455

Epoch: 5| Step: 7
Training loss: 2.127103328704834
Validation loss: 2.035429894924164

Epoch: 5| Step: 8
Training loss: 2.085226058959961
Validation loss: 2.0383074382940927

Epoch: 5| Step: 9
Training loss: 1.944075584411621
Validation loss: 2.0457459489504495

Epoch: 5| Step: 10
Training loss: 1.992217779159546
Validation loss: 2.0312503327926

Epoch: 5| Step: 11
Training loss: 3.313504695892334
Validation loss: 2.040347600976626

Epoch: 122| Step: 0
Training loss: 1.786953330039978
Validation loss: 2.037638564904531

Epoch: 5| Step: 1
Training loss: 2.439309597015381
Validation loss: 2.0361648350954056

Epoch: 5| Step: 2
Training loss: 2.0964629650115967
Validation loss: 2.0269022285938263

Epoch: 5| Step: 3
Training loss: 1.8492170572280884
Validation loss: 2.0315416852633157

Epoch: 5| Step: 4
Training loss: 2.264047145843506
Validation loss: 2.0243306954701743

Epoch: 5| Step: 5
Training loss: 2.2968807220458984
Validation loss: 2.028682370980581

Epoch: 5| Step: 6
Training loss: 2.259556531906128
Validation loss: 2.0342322091261544

Epoch: 5| Step: 7
Training loss: 2.3574090003967285
Validation loss: 2.0336192597945533

Epoch: 5| Step: 8
Training loss: 1.6646575927734375
Validation loss: 2.0323681036631265

Epoch: 5| Step: 9
Training loss: 2.2404677867889404
Validation loss: 2.028261105219523

Epoch: 5| Step: 10
Training loss: 2.2754101753234863
Validation loss: 2.017652009924253

Epoch: 5| Step: 11
Training loss: 1.2049187421798706
Validation loss: 2.02790201207002

Epoch: 123| Step: 0
Training loss: 1.8539015054702759
Validation loss: 2.0225712656974792

Epoch: 5| Step: 1
Training loss: 1.7413562536239624
Validation loss: 2.030119394262632

Epoch: 5| Step: 2
Training loss: 2.243157148361206
Validation loss: 2.027765989303589

Epoch: 5| Step: 3
Training loss: 2.193765163421631
Validation loss: 2.0362672954797745

Epoch: 5| Step: 4
Training loss: 1.872625708580017
Validation loss: 2.0461030304431915

Epoch: 5| Step: 5
Training loss: 2.649409770965576
Validation loss: 2.0365781436363855

Epoch: 5| Step: 6
Training loss: 1.7153011560440063
Validation loss: 2.034737393260002

Epoch: 5| Step: 7
Training loss: 2.1307456493377686
Validation loss: 2.042071277896563

Epoch: 5| Step: 8
Training loss: 2.5153605937957764
Validation loss: 2.0399180551369986

Epoch: 5| Step: 9
Training loss: 2.567908763885498
Validation loss: 2.046690280238787

Epoch: 5| Step: 10
Training loss: 1.673340082168579
Validation loss: 2.024427612622579

Epoch: 5| Step: 11
Training loss: 2.8989057540893555
Validation loss: 2.0280084013938904

Epoch: 124| Step: 0
Training loss: 2.385523796081543
Validation loss: 2.0277757147947946

Epoch: 5| Step: 1
Training loss: 2.1051504611968994
Validation loss: 2.0092462400595346

Epoch: 5| Step: 2
Training loss: 1.8258476257324219
Validation loss: 2.013133933146795

Epoch: 5| Step: 3
Training loss: 2.081336498260498
Validation loss: 2.004617378115654

Epoch: 5| Step: 4
Training loss: 2.222116231918335
Validation loss: 2.0132295936346054

Epoch: 5| Step: 5
Training loss: 1.520979881286621
Validation loss: 2.011790449420611

Epoch: 5| Step: 6
Training loss: 2.3413851261138916
Validation loss: 2.0052612821261087

Epoch: 5| Step: 7
Training loss: 2.3157496452331543
Validation loss: 2.009521315495173

Epoch: 5| Step: 8
Training loss: 2.0432322025299072
Validation loss: 2.013775110244751

Epoch: 5| Step: 9
Training loss: 2.3932628631591797
Validation loss: 2.0164850503206253

Epoch: 5| Step: 10
Training loss: 2.184246778488159
Validation loss: 2.017961968978246

Epoch: 5| Step: 11
Training loss: 1.9240168333053589
Validation loss: 2.020845055580139

Epoch: 125| Step: 0
Training loss: 2.0478248596191406
Validation loss: 2.021954054633776

Epoch: 5| Step: 1
Training loss: 2.1833133697509766
Validation loss: 2.0253416200478873

Epoch: 5| Step: 2
Training loss: 1.870239019393921
Validation loss: 2.026289169987043

Epoch: 5| Step: 3
Training loss: 1.898665428161621
Validation loss: 2.0160084068775177

Epoch: 5| Step: 4
Training loss: 2.2269866466522217
Validation loss: 2.0150043268998465

Epoch: 5| Step: 5
Training loss: 2.7959694862365723
Validation loss: 2.0172895938158035

Epoch: 5| Step: 6
Training loss: 2.267303943634033
Validation loss: 2.0271175801754

Epoch: 5| Step: 7
Training loss: 1.809012770652771
Validation loss: 2.0298650513092675

Epoch: 5| Step: 8
Training loss: 1.6450380086898804
Validation loss: 2.024148533741633

Epoch: 5| Step: 9
Training loss: 2.371978759765625
Validation loss: 2.021433929602305

Epoch: 5| Step: 10
Training loss: 2.2332205772399902
Validation loss: 2.04020365079244

Epoch: 5| Step: 11
Training loss: 1.9011666774749756
Validation loss: 2.0300980856021247

Epoch: 126| Step: 0
Training loss: 2.1983306407928467
Validation loss: 2.0302091240882874

Epoch: 5| Step: 1
Training loss: 2.0488810539245605
Validation loss: 2.030892883737882

Epoch: 5| Step: 2
Training loss: 1.6033613681793213
Validation loss: 2.044039582212766

Epoch: 5| Step: 3
Training loss: 1.8060781955718994
Validation loss: 2.0429197947184243

Epoch: 5| Step: 4
Training loss: 1.7262210845947266
Validation loss: 2.034813250104586

Epoch: 5| Step: 5
Training loss: 2.4898734092712402
Validation loss: 2.0429340402285256

Epoch: 5| Step: 6
Training loss: 2.6015408039093018
Validation loss: 2.04338701069355

Epoch: 5| Step: 7
Training loss: 2.269437313079834
Validation loss: 2.040384570757548

Epoch: 5| Step: 8
Training loss: 2.3748340606689453
Validation loss: 2.0572639058033624

Epoch: 5| Step: 9
Training loss: 2.208618640899658
Validation loss: 2.0569004913171134

Epoch: 5| Step: 10
Training loss: 1.9916105270385742
Validation loss: 2.0375722547372184

Epoch: 5| Step: 11
Training loss: 2.313906192779541
Validation loss: 2.0524525940418243

Epoch: 127| Step: 0
Training loss: 2.5087997913360596
Validation loss: 2.0342770516872406

Epoch: 5| Step: 1
Training loss: 1.673398733139038
Validation loss: 2.0192794501781464

Epoch: 5| Step: 2
Training loss: 2.2784476280212402
Validation loss: 2.033497671286265

Epoch: 5| Step: 3
Training loss: 1.9159743785858154
Validation loss: 2.0479132682085037

Epoch: 5| Step: 4
Training loss: 2.194489002227783
Validation loss: 2.0573435872793198

Epoch: 5| Step: 5
Training loss: 2.3338446617126465
Validation loss: 2.050733005007108

Epoch: 5| Step: 6
Training loss: 1.7282289266586304
Validation loss: 2.0481843998034797

Epoch: 5| Step: 7
Training loss: 2.2246997356414795
Validation loss: 2.0561775217453637

Epoch: 5| Step: 8
Training loss: 2.3826138973236084
Validation loss: 2.0556859026352563

Epoch: 5| Step: 9
Training loss: 2.2187328338623047
Validation loss: 2.0562215050061545

Epoch: 5| Step: 10
Training loss: 2.338761329650879
Validation loss: 2.060352012515068

Epoch: 5| Step: 11
Training loss: 2.6544241905212402
Validation loss: 2.053643132249514

Epoch: 128| Step: 0
Training loss: 2.164520025253296
Validation loss: 2.0577490677436194

Epoch: 5| Step: 1
Training loss: 2.8301618099212646
Validation loss: 2.0563639948765435

Epoch: 5| Step: 2
Training loss: 1.7682052850723267
Validation loss: 2.0606406231721244

Epoch: 5| Step: 3
Training loss: 2.037842273712158
Validation loss: 2.0544848144054413

Epoch: 5| Step: 4
Training loss: 2.079132318496704
Validation loss: 2.061668942372004

Epoch: 5| Step: 5
Training loss: 2.0207035541534424
Validation loss: 2.056640719374021

Epoch: 5| Step: 6
Training loss: 1.89154052734375
Validation loss: 2.0495575914780297

Epoch: 5| Step: 7
Training loss: 2.054874897003174
Validation loss: 2.0502348840236664

Epoch: 5| Step: 8
Training loss: 2.8156769275665283
Validation loss: 2.049661392966906

Epoch: 5| Step: 9
Training loss: 2.0110175609588623
Validation loss: 2.052745749553045

Epoch: 5| Step: 10
Training loss: 2.599438428878784
Validation loss: 2.0552703589200974

Epoch: 5| Step: 11
Training loss: 1.6844321489334106
Validation loss: 2.046361356973648

Epoch: 129| Step: 0
Training loss: 1.3283679485321045
Validation loss: 2.0490394781033197

Epoch: 5| Step: 1
Training loss: 2.190237522125244
Validation loss: 2.045952801903089

Epoch: 5| Step: 2
Training loss: 2.6452019214630127
Validation loss: 2.041045218706131

Epoch: 5| Step: 3
Training loss: 1.8862648010253906
Validation loss: 2.034522811571757

Epoch: 5| Step: 4
Training loss: 2.7787997722625732
Validation loss: 2.025034636259079

Epoch: 5| Step: 5
Training loss: 2.5123157501220703
Validation loss: 2.0239393959442773

Epoch: 5| Step: 6
Training loss: 2.1194608211517334
Validation loss: 2.01703812678655

Epoch: 5| Step: 7
Training loss: 1.8432413339614868
Validation loss: 2.014682670434316

Epoch: 5| Step: 8
Training loss: 2.0013370513916016
Validation loss: 2.0202376395463943

Epoch: 5| Step: 9
Training loss: 2.058335542678833
Validation loss: 2.019347051779429

Epoch: 5| Step: 10
Training loss: 2.439466953277588
Validation loss: 2.029222473502159

Epoch: 5| Step: 11
Training loss: 1.2905956506729126
Validation loss: 2.0274319648742676

Epoch: 130| Step: 0
Training loss: 2.9478461742401123
Validation loss: 2.0374835381905236

Epoch: 5| Step: 1
Training loss: 2.275230884552002
Validation loss: 2.051626279950142

Epoch: 5| Step: 2
Training loss: 1.8673940896987915
Validation loss: 2.0504006147384644

Epoch: 5| Step: 3
Training loss: 1.9157129526138306
Validation loss: 2.0370261470476785

Epoch: 5| Step: 4
Training loss: 1.0129332542419434
Validation loss: 2.044745534658432

Epoch: 5| Step: 5
Training loss: 1.8158642053604126
Validation loss: 2.0397370706001916

Epoch: 5| Step: 6
Training loss: 2.429861307144165
Validation loss: 2.0422039131323495

Epoch: 5| Step: 7
Training loss: 2.4852213859558105
Validation loss: 2.046191265185674

Epoch: 5| Step: 8
Training loss: 2.114960193634033
Validation loss: 2.037344366312027

Epoch: 5| Step: 9
Training loss: 1.8458316326141357
Validation loss: 2.0399612337350845

Epoch: 5| Step: 10
Training loss: 2.357748508453369
Validation loss: 2.0354253401358924

Epoch: 5| Step: 11
Training loss: 3.0756468772888184
Validation loss: 2.0354137619336448

Epoch: 131| Step: 0
Training loss: 1.944819450378418
Validation loss: 2.0403852065404258

Epoch: 5| Step: 1
Training loss: 2.4347474575042725
Validation loss: 2.033858055869738

Epoch: 5| Step: 2
Training loss: 2.1947760581970215
Validation loss: 2.03054279088974

Epoch: 5| Step: 3
Training loss: 1.9117017984390259
Validation loss: 2.024019405245781

Epoch: 5| Step: 4
Training loss: 2.1148197650909424
Validation loss: 2.0138026823600135

Epoch: 5| Step: 5
Training loss: 2.2165675163269043
Validation loss: 2.0247467209895453

Epoch: 5| Step: 6
Training loss: 2.095808506011963
Validation loss: 2.0245146801074347

Epoch: 5| Step: 7
Training loss: 2.249763011932373
Validation loss: 2.0284243126710257

Epoch: 5| Step: 8
Training loss: 2.0317797660827637
Validation loss: 2.0254445473353067

Epoch: 5| Step: 9
Training loss: 1.999767541885376
Validation loss: 2.0327683885892234

Epoch: 5| Step: 10
Training loss: 2.18544864654541
Validation loss: 2.034024635950724

Epoch: 5| Step: 11
Training loss: 1.690420150756836
Validation loss: 2.0366152226924896

Epoch: 132| Step: 0
Training loss: 2.1363377571105957
Validation loss: 2.0374185889959335

Epoch: 5| Step: 1
Training loss: 2.1003355979919434
Validation loss: 2.046011835336685

Epoch: 5| Step: 2
Training loss: 1.9039885997772217
Validation loss: 2.04097518324852

Epoch: 5| Step: 3
Training loss: 2.687731981277466
Validation loss: 2.0411403477191925

Epoch: 5| Step: 4
Training loss: 1.8680031299591064
Validation loss: 2.043394759297371

Epoch: 5| Step: 5
Training loss: 2.3262882232666016
Validation loss: 2.037139048178991

Epoch: 5| Step: 6
Training loss: 2.1690335273742676
Validation loss: 2.046082943677902

Epoch: 5| Step: 7
Training loss: 1.992733359336853
Validation loss: 2.0423967192570367

Epoch: 5| Step: 8
Training loss: 1.7972793579101562
Validation loss: 2.0505673587322235

Epoch: 5| Step: 9
Training loss: 2.1549556255340576
Validation loss: 2.037336344520251

Epoch: 5| Step: 10
Training loss: 1.9467642307281494
Validation loss: 2.035965621471405

Epoch: 5| Step: 11
Training loss: 2.5230674743652344
Validation loss: 2.0297937194506326

Epoch: 133| Step: 0
Training loss: 1.9199447631835938
Validation loss: 2.0514145642518997

Epoch: 5| Step: 1
Training loss: 1.7797119617462158
Validation loss: 2.0375890036424003

Epoch: 5| Step: 2
Training loss: 2.7029030323028564
Validation loss: 2.038813203573227

Epoch: 5| Step: 3
Training loss: 2.291121244430542
Validation loss: 2.054327686627706

Epoch: 5| Step: 4
Training loss: 1.5058355331420898
Validation loss: 2.04186541835467

Epoch: 5| Step: 5
Training loss: 2.1071715354919434
Validation loss: 2.04068860411644

Epoch: 5| Step: 6
Training loss: 2.1029160022735596
Validation loss: 2.0380065739154816

Epoch: 5| Step: 7
Training loss: 1.724644660949707
Validation loss: 2.044084141651789

Epoch: 5| Step: 8
Training loss: 2.528346538543701
Validation loss: 2.0363642424345016

Epoch: 5| Step: 9
Training loss: 1.9088294506072998
Validation loss: 2.039751057823499

Epoch: 5| Step: 10
Training loss: 2.289292812347412
Validation loss: 2.037736346324285

Epoch: 5| Step: 11
Training loss: 2.736072063446045
Validation loss: 2.0221959551175437

Epoch: 134| Step: 0
Training loss: 2.262023687362671
Validation loss: 2.03243022163709

Epoch: 5| Step: 1
Training loss: 1.9649591445922852
Validation loss: 2.0499001294374466

Epoch: 5| Step: 2
Training loss: 1.9593219757080078
Validation loss: 2.03896331290404

Epoch: 5| Step: 3
Training loss: 1.9644101858139038
Validation loss: 2.0456070949633918

Epoch: 5| Step: 4
Training loss: 1.9381687641143799
Validation loss: 2.046125670274099

Epoch: 5| Step: 5
Training loss: 2.0717999935150146
Validation loss: 2.039902925491333

Epoch: 5| Step: 6
Training loss: 2.457965135574341
Validation loss: 2.035465801755587

Epoch: 5| Step: 7
Training loss: 2.2058544158935547
Validation loss: 2.0491340110699334

Epoch: 5| Step: 8
Training loss: 2.343613386154175
Validation loss: 2.043854852517446

Epoch: 5| Step: 9
Training loss: 2.1260287761688232
Validation loss: 2.0208606024583182

Epoch: 5| Step: 10
Training loss: 2.0579569339752197
Validation loss: 2.0248336295286813

Epoch: 5| Step: 11
Training loss: 0.4326062500476837
Validation loss: 2.0362515846888223

Epoch: 135| Step: 0
Training loss: 2.493752956390381
Validation loss: 2.0248718559741974

Epoch: 5| Step: 1
Training loss: 2.0995852947235107
Validation loss: 2.0408833970626197

Epoch: 5| Step: 2
Training loss: 2.0456924438476562
Validation loss: 2.031818449497223

Epoch: 5| Step: 3
Training loss: 2.2705321311950684
Validation loss: 2.0351069072882333

Epoch: 5| Step: 4
Training loss: 2.002840518951416
Validation loss: 2.0316257923841476

Epoch: 5| Step: 5
Training loss: 1.6453911066055298
Validation loss: 2.02995365858078

Epoch: 5| Step: 6
Training loss: 2.61198091506958
Validation loss: 2.0271999587615332

Epoch: 5| Step: 7
Training loss: 1.7860246896743774
Validation loss: 2.026554445425669

Epoch: 5| Step: 8
Training loss: 2.5102038383483887
Validation loss: 2.0258142550786338

Epoch: 5| Step: 9
Training loss: 2.0716395378112793
Validation loss: 2.022580216328303

Epoch: 5| Step: 10
Training loss: 1.7983869314193726
Validation loss: 2.0244356294473014

Epoch: 5| Step: 11
Training loss: 1.4514871835708618
Validation loss: 2.0319316188494363

Epoch: 136| Step: 0
Training loss: 2.2207095623016357
Validation loss: 2.02735927204291

Epoch: 5| Step: 1
Training loss: 2.23241925239563
Validation loss: 2.025202209750811

Epoch: 5| Step: 2
Training loss: 1.6337095499038696
Validation loss: 2.026639719804128

Epoch: 5| Step: 3
Training loss: 1.6570758819580078
Validation loss: 2.0172267158826194

Epoch: 5| Step: 4
Training loss: 2.00045108795166
Validation loss: 2.032450800140699

Epoch: 5| Step: 5
Training loss: 2.1581947803497314
Validation loss: 2.0242444425821304

Epoch: 5| Step: 6
Training loss: 2.116088628768921
Validation loss: 2.0430520673592887

Epoch: 5| Step: 7
Training loss: 2.340115785598755
Validation loss: 2.042095268766085

Epoch: 5| Step: 8
Training loss: 2.0117785930633545
Validation loss: 2.028033822774887

Epoch: 5| Step: 9
Training loss: 2.189607620239258
Validation loss: 2.040188173453013

Epoch: 5| Step: 10
Training loss: 2.2485134601593018
Validation loss: 2.04148497680823

Epoch: 5| Step: 11
Training loss: 2.9100277423858643
Validation loss: 2.033855587244034

Epoch: 137| Step: 0
Training loss: 1.886047601699829
Validation loss: 2.0444995164871216

Epoch: 5| Step: 1
Training loss: 1.720841646194458
Validation loss: 2.040178636709849

Epoch: 5| Step: 2
Training loss: 2.547008991241455
Validation loss: 2.0386392076810202

Epoch: 5| Step: 3
Training loss: 1.8359380960464478
Validation loss: 2.0340581089258194

Epoch: 5| Step: 4
Training loss: 1.7112083435058594
Validation loss: 2.0282757778962455

Epoch: 5| Step: 5
Training loss: 2.3382961750030518
Validation loss: 2.03495783607165

Epoch: 5| Step: 6
Training loss: 2.183101177215576
Validation loss: 2.033498615026474

Epoch: 5| Step: 7
Training loss: 2.2933456897735596
Validation loss: 2.033305754264196

Epoch: 5| Step: 8
Training loss: 2.493417978286743
Validation loss: 2.0328908413648605

Epoch: 5| Step: 9
Training loss: 2.104607105255127
Validation loss: 2.039978116750717

Epoch: 5| Step: 10
Training loss: 2.217413902282715
Validation loss: 2.0347837656736374

Epoch: 5| Step: 11
Training loss: 2.0634679794311523
Validation loss: 2.0234843095143638

Epoch: 138| Step: 0
Training loss: 2.230123281478882
Validation loss: 2.0349109868208566

Epoch: 5| Step: 1
Training loss: 1.9216769933700562
Validation loss: 2.0294164468844733

Epoch: 5| Step: 2
Training loss: 1.9013030529022217
Validation loss: 2.028585215409597

Epoch: 5| Step: 3
Training loss: 1.7701828479766846
Validation loss: 2.0287233690420785

Epoch: 5| Step: 4
Training loss: 1.5695514678955078
Validation loss: 2.0364436308542886

Epoch: 5| Step: 5
Training loss: 2.030517816543579
Validation loss: 2.0234429935614267

Epoch: 5| Step: 6
Training loss: 2.0774922370910645
Validation loss: 2.0312970827023187

Epoch: 5| Step: 7
Training loss: 2.873671054840088
Validation loss: 2.036762018998464

Epoch: 5| Step: 8
Training loss: 2.5301918983459473
Validation loss: 2.0305412163337073

Epoch: 5| Step: 9
Training loss: 2.5171360969543457
Validation loss: 2.050793985525767

Epoch: 5| Step: 10
Training loss: 1.8462677001953125
Validation loss: 2.046855424841245

Epoch: 5| Step: 11
Training loss: 1.3357324600219727
Validation loss: 2.0465579827626548

Epoch: 139| Step: 0
Training loss: 2.5544278621673584
Validation loss: 2.039353763063749

Epoch: 5| Step: 1
Training loss: 2.3983874320983887
Validation loss: 2.027370477716128

Epoch: 5| Step: 2
Training loss: 1.6439177989959717
Validation loss: 2.0278687129418054

Epoch: 5| Step: 3
Training loss: 2.1162989139556885
Validation loss: 2.0361575881640115

Epoch: 5| Step: 4
Training loss: 1.913967490196228
Validation loss: 2.0294497907161713

Epoch: 5| Step: 5
Training loss: 1.8791879415512085
Validation loss: 2.0358638763427734

Epoch: 5| Step: 6
Training loss: 2.5936341285705566
Validation loss: 2.042996267477671

Epoch: 5| Step: 7
Training loss: 2.5159640312194824
Validation loss: 2.0305911352237067

Epoch: 5| Step: 8
Training loss: 2.327383279800415
Validation loss: 2.03433133661747

Epoch: 5| Step: 9
Training loss: 1.7800405025482178
Validation loss: 2.031068339943886

Epoch: 5| Step: 10
Training loss: 1.7300758361816406
Validation loss: 2.0279687692721686

Epoch: 5| Step: 11
Training loss: 1.3279335498809814
Validation loss: 2.0183285772800446

Epoch: 140| Step: 0
Training loss: 2.720649480819702
Validation loss: 2.0306602170070014

Epoch: 5| Step: 1
Training loss: 1.919886827468872
Validation loss: 2.0244914094607034

Epoch: 5| Step: 2
Training loss: 2.2228713035583496
Validation loss: 2.0291486382484436

Epoch: 5| Step: 3
Training loss: 2.2096800804138184
Validation loss: 2.0282404770453772

Epoch: 5| Step: 4
Training loss: 2.0493807792663574
Validation loss: 2.0288367867469788

Epoch: 5| Step: 5
Training loss: 2.3135266304016113
Validation loss: 2.0257578740517297

Epoch: 5| Step: 6
Training loss: 2.290916919708252
Validation loss: 2.0295903186003366

Epoch: 5| Step: 7
Training loss: 2.102856397628784
Validation loss: 2.0271054605642953

Epoch: 5| Step: 8
Training loss: 1.7154268026351929
Validation loss: 2.028788690765699

Epoch: 5| Step: 9
Training loss: 2.079852342605591
Validation loss: 2.0426554481188455

Epoch: 5| Step: 10
Training loss: 1.4115960597991943
Validation loss: 2.0476117680470147

Epoch: 5| Step: 11
Training loss: 2.0620949268341064
Validation loss: 2.0504218389590583

Epoch: 141| Step: 0
Training loss: 2.550180196762085
Validation loss: 2.047108287612597

Epoch: 5| Step: 1
Training loss: 2.298358917236328
Validation loss: 2.047147194544474

Epoch: 5| Step: 2
Training loss: 1.5534038543701172
Validation loss: 2.0500157922506332

Epoch: 5| Step: 3
Training loss: 2.191394567489624
Validation loss: 2.0484180947144828

Epoch: 5| Step: 4
Training loss: 1.9401710033416748
Validation loss: 2.05969829360644

Epoch: 5| Step: 5
Training loss: 1.9975700378417969
Validation loss: 2.0435807754596076

Epoch: 5| Step: 6
Training loss: 1.3685503005981445
Validation loss: 2.0529446254173913

Epoch: 5| Step: 7
Training loss: 2.4075632095336914
Validation loss: 2.0515330086151757

Epoch: 5| Step: 8
Training loss: 2.6147685050964355
Validation loss: 2.0459095487991967

Epoch: 5| Step: 9
Training loss: 2.088865041732788
Validation loss: 2.0366632839043937

Epoch: 5| Step: 10
Training loss: 2.0059866905212402
Validation loss: 2.0422849158445993

Epoch: 5| Step: 11
Training loss: 1.9881223440170288
Validation loss: 2.0376751720905304

Epoch: 142| Step: 0
Training loss: 2.1751017570495605
Validation loss: 2.0253602117300034

Epoch: 5| Step: 1
Training loss: 1.916750192642212
Validation loss: 2.0343826363484063

Epoch: 5| Step: 2
Training loss: 1.8394393920898438
Validation loss: 2.0339282800753913

Epoch: 5| Step: 3
Training loss: 2.068488597869873
Validation loss: 2.0288256804148355

Epoch: 5| Step: 4
Training loss: 2.1340112686157227
Validation loss: 2.0343027214209237

Epoch: 5| Step: 5
Training loss: 2.0641989707946777
Validation loss: 2.028888061642647

Epoch: 5| Step: 6
Training loss: 2.276745080947876
Validation loss: 2.023209353288015

Epoch: 5| Step: 7
Training loss: 1.9681799411773682
Validation loss: 2.026549071073532

Epoch: 5| Step: 8
Training loss: 1.8110263347625732
Validation loss: 2.0244272301594415

Epoch: 5| Step: 9
Training loss: 1.9632593393325806
Validation loss: 2.0223378439744315

Epoch: 5| Step: 10
Training loss: 2.6641933917999268
Validation loss: 2.031149134039879

Epoch: 5| Step: 11
Training loss: 1.9574869871139526
Validation loss: 2.024768670399984

Epoch: 143| Step: 0
Training loss: 1.969700813293457
Validation loss: 2.0291525522867837

Epoch: 5| Step: 1
Training loss: 2.428480625152588
Validation loss: 2.0287454773982367

Epoch: 5| Step: 2
Training loss: 2.2743797302246094
Validation loss: 2.0252326677242913

Epoch: 5| Step: 3
Training loss: 2.3408913612365723
Validation loss: 2.02953473230203

Epoch: 5| Step: 4
Training loss: 1.6830079555511475
Validation loss: 2.028060808777809

Epoch: 5| Step: 5
Training loss: 1.9278675317764282
Validation loss: 2.0290982077519097

Epoch: 5| Step: 6
Training loss: 2.6814827919006348
Validation loss: 2.0300654470920563

Epoch: 5| Step: 7
Training loss: 1.8004920482635498
Validation loss: 2.03184246023496

Epoch: 5| Step: 8
Training loss: 1.968003511428833
Validation loss: 2.0325204730033875

Epoch: 5| Step: 9
Training loss: 1.9455894231796265
Validation loss: 2.040741821130117

Epoch: 5| Step: 10
Training loss: 1.9187259674072266
Validation loss: 2.035357783238093

Epoch: 5| Step: 11
Training loss: 1.711173415184021
Validation loss: 2.032824178536733

Epoch: 144| Step: 0
Training loss: 2.2590630054473877
Validation loss: 2.0378421346346536

Epoch: 5| Step: 1
Training loss: 1.8549816608428955
Validation loss: 2.0327270328998566

Epoch: 5| Step: 2
Training loss: 2.1439621448516846
Validation loss: 2.027205303311348

Epoch: 5| Step: 3
Training loss: 2.001674175262451
Validation loss: 2.0236249764760337

Epoch: 5| Step: 4
Training loss: 2.2727646827697754
Validation loss: 2.031877820690473

Epoch: 5| Step: 5
Training loss: 1.520050287246704
Validation loss: 2.0266867130994797

Epoch: 5| Step: 6
Training loss: 2.511812448501587
Validation loss: 2.0269859433174133

Epoch: 5| Step: 7
Training loss: 2.357172727584839
Validation loss: 2.0231471955776215

Epoch: 5| Step: 8
Training loss: 1.6228291988372803
Validation loss: 2.026506225268046

Epoch: 5| Step: 9
Training loss: 2.241237163543701
Validation loss: 2.0245358447233834

Epoch: 5| Step: 10
Training loss: 2.0899131298065186
Validation loss: 2.0397350738445916

Epoch: 5| Step: 11
Training loss: 2.869842052459717
Validation loss: 2.0381047278642654

Epoch: 145| Step: 0
Training loss: 1.8551334142684937
Validation loss: 2.0405678351720176

Epoch: 5| Step: 1
Training loss: 2.422619581222534
Validation loss: 2.04149762292703

Epoch: 5| Step: 2
Training loss: 1.8195502758026123
Validation loss: 2.0344424148400626

Epoch: 5| Step: 3
Training loss: 2.0663208961486816
Validation loss: 2.0412723273038864

Epoch: 5| Step: 4
Training loss: 1.9938592910766602
Validation loss: 2.0538913706938424

Epoch: 5| Step: 5
Training loss: 1.92388117313385
Validation loss: 2.054219752550125

Epoch: 5| Step: 6
Training loss: 2.187591075897217
Validation loss: 2.0538551261027655

Epoch: 5| Step: 7
Training loss: 1.716630220413208
Validation loss: 2.055747722585996

Epoch: 5| Step: 8
Training loss: 2.288212537765503
Validation loss: 2.043054943283399

Epoch: 5| Step: 9
Training loss: 2.315361738204956
Validation loss: 2.0490659922361374

Epoch: 5| Step: 10
Training loss: 2.042379856109619
Validation loss: 2.0335571815570197

Epoch: 5| Step: 11
Training loss: 3.323110342025757
Validation loss: 2.045421322186788

Epoch: 146| Step: 0
Training loss: 1.8540127277374268
Validation loss: 2.043159693479538

Epoch: 5| Step: 1
Training loss: 1.6142046451568604
Validation loss: 2.051440715789795

Epoch: 5| Step: 2
Training loss: 2.1552977561950684
Validation loss: 2.0457250773906708

Epoch: 5| Step: 3
Training loss: 2.0525527000427246
Validation loss: 2.0277037024497986

Epoch: 5| Step: 4
Training loss: 2.581040143966675
Validation loss: 2.0288179318110147

Epoch: 5| Step: 5
Training loss: 2.2368457317352295
Validation loss: 2.035623292128245

Epoch: 5| Step: 6
Training loss: 1.6842100620269775
Validation loss: 2.033551037311554

Epoch: 5| Step: 7
Training loss: 2.382636308670044
Validation loss: 2.0362381686766944

Epoch: 5| Step: 8
Training loss: 1.877706527709961
Validation loss: 2.039438476165136

Epoch: 5| Step: 9
Training loss: 2.3927998542785645
Validation loss: 2.040446033080419

Epoch: 5| Step: 10
Training loss: 2.1102986335754395
Validation loss: 2.031129409869512

Epoch: 5| Step: 11
Training loss: 1.0752702951431274
Validation loss: 2.0337011963129044

Epoch: 147| Step: 0
Training loss: 2.0456490516662598
Validation loss: 2.0324306041002274

Epoch: 5| Step: 1
Training loss: 2.8420238494873047
Validation loss: 2.0407485365867615

Epoch: 5| Step: 2
Training loss: 1.5860933065414429
Validation loss: 2.0373219549655914

Epoch: 5| Step: 3
Training loss: 1.963965654373169
Validation loss: 2.043642222881317

Epoch: 5| Step: 4
Training loss: 2.070040225982666
Validation loss: 2.0427878201007843

Epoch: 5| Step: 5
Training loss: 1.951533555984497
Validation loss: 2.043399194876353

Epoch: 5| Step: 6
Training loss: 2.240072727203369
Validation loss: 2.03087871770064

Epoch: 5| Step: 7
Training loss: 1.750008225440979
Validation loss: 2.034914200504621

Epoch: 5| Step: 8
Training loss: 2.3191847801208496
Validation loss: 2.0373328824838004

Epoch: 5| Step: 9
Training loss: 1.510474443435669
Validation loss: 2.0351882676283517

Epoch: 5| Step: 10
Training loss: 2.5245888233184814
Validation loss: 2.0431668907403946

Epoch: 5| Step: 11
Training loss: 2.0058608055114746
Validation loss: 2.0237433264652886

Epoch: 148| Step: 0
Training loss: 2.054389476776123
Validation loss: 2.041651929418246

Epoch: 5| Step: 1
Training loss: 2.3326611518859863
Validation loss: 2.029527316490809

Epoch: 5| Step: 2
Training loss: 1.9382833242416382
Validation loss: 2.0477210134267807

Epoch: 5| Step: 3
Training loss: 1.6403605937957764
Validation loss: 2.0466436048348746

Epoch: 5| Step: 4
Training loss: 2.091606616973877
Validation loss: 2.0517276525497437

Epoch: 5| Step: 5
Training loss: 2.2297229766845703
Validation loss: 2.0472112546364465

Epoch: 5| Step: 6
Training loss: 1.974551796913147
Validation loss: 2.05650794506073

Epoch: 5| Step: 7
Training loss: 2.2897555828094482
Validation loss: 2.0467033982276917

Epoch: 5| Step: 8
Training loss: 2.091646194458008
Validation loss: 2.0608075161774955

Epoch: 5| Step: 9
Training loss: 2.5008163452148438
Validation loss: 2.0543666929006577

Epoch: 5| Step: 10
Training loss: 1.508545160293579
Validation loss: 2.0447120318810144

Epoch: 5| Step: 11
Training loss: 2.9332289695739746
Validation loss: 2.0525637765725455

Epoch: 149| Step: 0
Training loss: 2.0751419067382812
Validation loss: 2.047756607333819

Epoch: 5| Step: 1
Training loss: 2.4110922813415527
Validation loss: 2.0451351602872214

Epoch: 5| Step: 2
Training loss: 2.415853977203369
Validation loss: 2.0500140388806662

Epoch: 5| Step: 3
Training loss: 2.6530871391296387
Validation loss: 2.05046912531058

Epoch: 5| Step: 4
Training loss: 1.2552733421325684
Validation loss: 2.0459934920072556

Epoch: 5| Step: 5
Training loss: 1.9854587316513062
Validation loss: 2.0447822511196136

Epoch: 5| Step: 6
Training loss: 2.1075644493103027
Validation loss: 2.044052412112554

Epoch: 5| Step: 7
Training loss: 1.9479109048843384
Validation loss: 2.0388265599807105

Epoch: 5| Step: 8
Training loss: 2.3226451873779297
Validation loss: 2.0486480494340262

Epoch: 5| Step: 9
Training loss: 1.960715889930725
Validation loss: 2.0503993183374405

Epoch: 5| Step: 10
Training loss: 1.9150480031967163
Validation loss: 2.044893816113472

Epoch: 5| Step: 11
Training loss: 0.9385471940040588
Validation loss: 2.030739943186442

Epoch: 150| Step: 0
Training loss: 1.9245178699493408
Validation loss: 2.0484029899040856

Epoch: 5| Step: 1
Training loss: 1.6416524648666382
Validation loss: 2.0293345699707666

Epoch: 5| Step: 2
Training loss: 1.9027738571166992
Validation loss: 2.0535909235477448

Epoch: 5| Step: 3
Training loss: 1.9965568780899048
Validation loss: 2.040095329284668

Epoch: 5| Step: 4
Training loss: 1.9391720294952393
Validation loss: 2.0484648446242013

Epoch: 5| Step: 5
Training loss: 2.1961915493011475
Validation loss: 2.037417153517405

Epoch: 5| Step: 6
Training loss: 2.25162410736084
Validation loss: 2.0458982586860657

Epoch: 5| Step: 7
Training loss: 2.000046491622925
Validation loss: 2.042486305038134

Epoch: 5| Step: 8
Training loss: 2.367513656616211
Validation loss: 2.038987169663111

Epoch: 5| Step: 9
Training loss: 2.3214545249938965
Validation loss: 2.0334992011388144

Epoch: 5| Step: 10
Training loss: 2.323690891265869
Validation loss: 2.0294576585292816

Epoch: 5| Step: 11
Training loss: 2.2770612239837646
Validation loss: 2.032133082548777

Epoch: 151| Step: 0
Training loss: 2.4076924324035645
Validation loss: 2.0269399881362915

Epoch: 5| Step: 1
Training loss: 2.133605480194092
Validation loss: 2.035392185052236

Epoch: 5| Step: 2
Training loss: 2.4094576835632324
Validation loss: 2.0353142072757087

Epoch: 5| Step: 3
Training loss: 1.9059978723526
Validation loss: 2.0357810209194818

Epoch: 5| Step: 4
Training loss: 2.5324838161468506
Validation loss: 2.0561233907938004

Epoch: 5| Step: 5
Training loss: 1.8655773401260376
Validation loss: 2.0631686399380365

Epoch: 5| Step: 6
Training loss: 1.9968831539154053
Validation loss: 2.0740007162094116

Epoch: 5| Step: 7
Training loss: 1.6790056228637695
Validation loss: 2.056321049729983

Epoch: 5| Step: 8
Training loss: 2.5198349952697754
Validation loss: 2.0352711230516434

Epoch: 5| Step: 9
Training loss: 2.047673463821411
Validation loss: 2.044677257537842

Epoch: 5| Step: 10
Training loss: 1.448901891708374
Validation loss: 2.0389630844195685

Epoch: 5| Step: 11
Training loss: 1.7795417308807373
Validation loss: 2.0351566274960837

Epoch: 152| Step: 0
Training loss: 1.7650789022445679
Validation loss: 2.036179944872856

Epoch: 5| Step: 1
Training loss: 1.9052629470825195
Validation loss: 2.0220678945382438

Epoch: 5| Step: 2
Training loss: 2.4505810737609863
Validation loss: 2.034556413690249

Epoch: 5| Step: 3
Training loss: 2.0597665309906006
Validation loss: 2.034767508506775

Epoch: 5| Step: 4
Training loss: 1.5892977714538574
Validation loss: 2.0458768159151077

Epoch: 5| Step: 5
Training loss: 1.8390998840332031
Validation loss: 2.0488051772117615

Epoch: 5| Step: 6
Training loss: 2.36030650138855
Validation loss: 2.0460582425196967

Epoch: 5| Step: 7
Training loss: 1.8404064178466797
Validation loss: 2.069032669067383

Epoch: 5| Step: 8
Training loss: 2.334071636199951
Validation loss: 2.049025391538938

Epoch: 5| Step: 9
Training loss: 2.210933208465576
Validation loss: 2.054166649778684

Epoch: 5| Step: 10
Training loss: 2.4806599617004395
Validation loss: 2.0475388318300247

Epoch: 5| Step: 11
Training loss: 2.234088659286499
Validation loss: 2.0514712979396186

Epoch: 153| Step: 0
Training loss: 2.6247353553771973
Validation loss: 2.032470295826594

Epoch: 5| Step: 1
Training loss: 1.7342727184295654
Validation loss: 2.0543279399474463

Epoch: 5| Step: 2
Training loss: 1.9968143701553345
Validation loss: 2.0363377183675766

Epoch: 5| Step: 3
Training loss: 1.7013874053955078
Validation loss: 2.0438048988580704

Epoch: 5| Step: 4
Training loss: 1.8647476434707642
Validation loss: 2.035436744491259

Epoch: 5| Step: 5
Training loss: 1.8038963079452515
Validation loss: 2.0327188024918237

Epoch: 5| Step: 6
Training loss: 2.483959674835205
Validation loss: 2.018235832452774

Epoch: 5| Step: 7
Training loss: 2.063772678375244
Validation loss: 2.025885055462519

Epoch: 5| Step: 8
Training loss: 2.007424831390381
Validation loss: 2.0306500097115836

Epoch: 5| Step: 9
Training loss: 1.964766263961792
Validation loss: 2.026084860165914

Epoch: 5| Step: 10
Training loss: 2.4116790294647217
Validation loss: 2.022577996055285

Epoch: 5| Step: 11
Training loss: 2.1777777671813965
Validation loss: 2.0280922253926597

Epoch: 154| Step: 0
Training loss: 2.196854591369629
Validation loss: 2.0352136939764023

Epoch: 5| Step: 1
Training loss: 2.1684412956237793
Validation loss: 2.0264349579811096

Epoch: 5| Step: 2
Training loss: 2.4839348793029785
Validation loss: 2.0308627088864646

Epoch: 5| Step: 3
Training loss: 1.708400011062622
Validation loss: 2.033450424671173

Epoch: 5| Step: 4
Training loss: 2.7068896293640137
Validation loss: 2.0321835776170096

Epoch: 5| Step: 5
Training loss: 1.8198333978652954
Validation loss: 2.037590796748797

Epoch: 5| Step: 6
Training loss: 1.4707562923431396
Validation loss: 2.0276477883259454

Epoch: 5| Step: 7
Training loss: 1.7921699285507202
Validation loss: 2.0305886616309485

Epoch: 5| Step: 8
Training loss: 1.6775131225585938
Validation loss: 2.028783162434896

Epoch: 5| Step: 9
Training loss: 2.5570690631866455
Validation loss: 2.0301820735136666

Epoch: 5| Step: 10
Training loss: 2.284654140472412
Validation loss: 2.02902057270209

Epoch: 5| Step: 11
Training loss: 2.158985137939453
Validation loss: 2.030878891547521

Epoch: 155| Step: 0
Training loss: 1.9041095972061157
Validation loss: 2.0432912756999335

Epoch: 5| Step: 1
Training loss: 1.9227087497711182
Validation loss: 2.0668938159942627

Epoch: 5| Step: 2
Training loss: 2.1126365661621094
Validation loss: 2.079528421163559

Epoch: 5| Step: 3
Training loss: 2.212979793548584
Validation loss: 2.1024838387966156

Epoch: 5| Step: 4
Training loss: 2.5054945945739746
Validation loss: 2.1012368301550546

Epoch: 5| Step: 5
Training loss: 2.1822636127471924
Validation loss: 2.0864847600460052

Epoch: 5| Step: 6
Training loss: 2.106436252593994
Validation loss: 2.068792665998141

Epoch: 5| Step: 7
Training loss: 1.6888134479522705
Validation loss: 2.0653943866491318

Epoch: 5| Step: 8
Training loss: 2.2648117542266846
Validation loss: 2.0411791702111564

Epoch: 5| Step: 9
Training loss: 2.6025421619415283
Validation loss: 2.0397059321403503

Epoch: 5| Step: 10
Training loss: 1.809322714805603
Validation loss: 2.0432595709959664

Epoch: 5| Step: 11
Training loss: 1.8410731554031372
Validation loss: 2.0416793823242188

Epoch: 156| Step: 0
Training loss: 2.1544392108917236
Validation loss: 2.040730635325114

Epoch: 5| Step: 1
Training loss: 2.3808200359344482
Validation loss: 2.0466982324918113

Epoch: 5| Step: 2
Training loss: 1.8571103811264038
Validation loss: 2.038151020805041

Epoch: 5| Step: 3
Training loss: 2.12754225730896
Validation loss: 2.0402796069780984

Epoch: 5| Step: 4
Training loss: 2.141801357269287
Validation loss: 2.0506051182746887

Epoch: 5| Step: 5
Training loss: 2.08892560005188
Validation loss: 2.0361972202857337

Epoch: 5| Step: 6
Training loss: 2.2059948444366455
Validation loss: 2.057419334848722

Epoch: 5| Step: 7
Training loss: 1.6587088108062744
Validation loss: 2.0444761564334235

Epoch: 5| Step: 8
Training loss: 1.9738292694091797
Validation loss: 2.0446164111296334

Epoch: 5| Step: 9
Training loss: 1.953525185585022
Validation loss: 2.0515453120072684

Epoch: 5| Step: 10
Training loss: 2.3115978240966797
Validation loss: 2.0586308538913727

Epoch: 5| Step: 11
Training loss: 1.1008719205856323
Validation loss: 2.060259302457174

Epoch: 157| Step: 0
Training loss: 1.5604896545410156
Validation loss: 2.0542403012514114

Epoch: 5| Step: 1
Training loss: 1.5006616115570068
Validation loss: 2.0570917427539825

Epoch: 5| Step: 2
Training loss: 2.0659682750701904
Validation loss: 2.055605257550875

Epoch: 5| Step: 3
Training loss: 2.813070297241211
Validation loss: 2.03922571738561

Epoch: 5| Step: 4
Training loss: 2.49674916267395
Validation loss: 2.0550256619850793

Epoch: 5| Step: 5
Training loss: 1.926967978477478
Validation loss: 2.047879030307134

Epoch: 5| Step: 6
Training loss: 1.8555164337158203
Validation loss: 2.045778880516688

Epoch: 5| Step: 7
Training loss: 2.0272393226623535
Validation loss: 2.0461607376734414

Epoch: 5| Step: 8
Training loss: 2.4821810722351074
Validation loss: 2.049396201968193

Epoch: 5| Step: 9
Training loss: 1.882468819618225
Validation loss: 2.0409295757611594

Epoch: 5| Step: 10
Training loss: 2.110468626022339
Validation loss: 2.053987910350164

Epoch: 5| Step: 11
Training loss: 2.063445568084717
Validation loss: 2.0480992197990417

Epoch: 158| Step: 0
Training loss: 1.409645676612854
Validation loss: 2.04990682999293

Epoch: 5| Step: 1
Training loss: 2.5322811603546143
Validation loss: 2.0532200783491135

Epoch: 5| Step: 2
Training loss: 2.570446491241455
Validation loss: 2.0535900642474494

Epoch: 5| Step: 3
Training loss: 1.7918847799301147
Validation loss: 2.0390879611174264

Epoch: 5| Step: 4
Training loss: 2.3954858779907227
Validation loss: 2.043855130672455

Epoch: 5| Step: 5
Training loss: 2.1471662521362305
Validation loss: 2.0537143598000207

Epoch: 5| Step: 6
Training loss: 2.149726390838623
Validation loss: 2.037842055161794

Epoch: 5| Step: 7
Training loss: 2.098128080368042
Validation loss: 2.059641937414805

Epoch: 5| Step: 8
Training loss: 1.6424745321273804
Validation loss: 2.0606744289398193

Epoch: 5| Step: 9
Training loss: 2.0616869926452637
Validation loss: 2.0601087709267936

Epoch: 5| Step: 10
Training loss: 1.2880942821502686
Validation loss: 2.0412499060233436

Epoch: 5| Step: 11
Training loss: 4.3474836349487305
Validation loss: 2.033119256297747

Epoch: 159| Step: 0
Training loss: 2.681734800338745
Validation loss: 2.0580976208051047

Epoch: 5| Step: 1
Training loss: 2.3358850479125977
Validation loss: 2.0447810341914496

Epoch: 5| Step: 2
Training loss: 1.4349946975708008
Validation loss: 2.0483956982692084

Epoch: 5| Step: 3
Training loss: 1.9617235660552979
Validation loss: 2.042514388759931

Epoch: 5| Step: 4
Training loss: 2.343466281890869
Validation loss: 2.0421804090340934

Epoch: 5| Step: 5
Training loss: 1.8625080585479736
Validation loss: 2.043777570128441

Epoch: 5| Step: 6
Training loss: 1.9818458557128906
Validation loss: 2.045556182662646

Epoch: 5| Step: 7
Training loss: 2.5811116695404053
Validation loss: 2.033645376563072

Epoch: 5| Step: 8
Training loss: 1.8406846523284912
Validation loss: 2.0267898390690484

Epoch: 5| Step: 9
Training loss: 1.9879153966903687
Validation loss: 2.0348774592081704

Epoch: 5| Step: 10
Training loss: 1.915893793106079
Validation loss: 2.034088656306267

Epoch: 5| Step: 11
Training loss: 1.461238145828247
Validation loss: 2.041095092892647

Epoch: 160| Step: 0
Training loss: 2.474382162094116
Validation loss: 2.0350941071907678

Epoch: 5| Step: 1
Training loss: 2.6017773151397705
Validation loss: 2.0314754048983255

Epoch: 5| Step: 2
Training loss: 1.507494330406189
Validation loss: 2.0385164817174277

Epoch: 5| Step: 3
Training loss: 2.2804858684539795
Validation loss: 2.038208986322085

Epoch: 5| Step: 4
Training loss: 1.9912830591201782
Validation loss: 2.0356004933516183

Epoch: 5| Step: 5
Training loss: 1.8783115148544312
Validation loss: 2.0386147052049637

Epoch: 5| Step: 6
Training loss: 1.4346606731414795
Validation loss: 2.042895312110583

Epoch: 5| Step: 7
Training loss: 2.1383309364318848
Validation loss: 2.0354420443375907

Epoch: 5| Step: 8
Training loss: 2.2249507904052734
Validation loss: 2.0646945337454476

Epoch: 5| Step: 9
Training loss: 1.9402568340301514
Validation loss: 2.0577309230963388

Epoch: 5| Step: 10
Training loss: 2.1640076637268066
Validation loss: 2.0658060560623803

Epoch: 5| Step: 11
Training loss: 1.9181932210922241
Validation loss: 2.079773038625717

Epoch: 161| Step: 0
Training loss: 1.8991444110870361
Validation loss: 2.070124184091886

Epoch: 5| Step: 1
Training loss: 2.2056660652160645
Validation loss: 2.0537791550159454

Epoch: 5| Step: 2
Training loss: 1.9749641418457031
Validation loss: 2.05085788667202

Epoch: 5| Step: 3
Training loss: 2.652268171310425
Validation loss: 2.031066174308459

Epoch: 5| Step: 4
Training loss: 2.1966514587402344
Validation loss: 2.0233450531959534

Epoch: 5| Step: 5
Training loss: 2.505594253540039
Validation loss: 2.008054569363594

Epoch: 5| Step: 6
Training loss: 1.9174511432647705
Validation loss: 2.018488888939222

Epoch: 5| Step: 7
Training loss: 2.032871961593628
Validation loss: 2.0142057836055756

Epoch: 5| Step: 8
Training loss: 1.9753252267837524
Validation loss: 2.0179839730262756

Epoch: 5| Step: 9
Training loss: 1.9301351308822632
Validation loss: 2.0253532926241555

Epoch: 5| Step: 10
Training loss: 1.6457202434539795
Validation loss: 2.02448932826519

Epoch: 5| Step: 11
Training loss: 1.9559389352798462
Validation loss: 2.0162604997555413

Epoch: 162| Step: 0
Training loss: 2.453442096710205
Validation loss: 2.042456646760305

Epoch: 5| Step: 1
Training loss: 2.344184160232544
Validation loss: 2.030114675561587

Epoch: 5| Step: 2
Training loss: 2.1807522773742676
Validation loss: 2.0396745850642524

Epoch: 5| Step: 3
Training loss: 1.4527431726455688
Validation loss: 2.037161032358805

Epoch: 5| Step: 4
Training loss: 2.2288455963134766
Validation loss: 2.0290917406479516

Epoch: 5| Step: 5
Training loss: 1.6366121768951416
Validation loss: 2.036834234992663

Epoch: 5| Step: 6
Training loss: 1.839019536972046
Validation loss: 2.033184458812078

Epoch: 5| Step: 7
Training loss: 2.5056591033935547
Validation loss: 2.039138068755468

Epoch: 5| Step: 8
Training loss: 1.7440226078033447
Validation loss: 2.0371208687623343

Epoch: 5| Step: 9
Training loss: 1.7643009424209595
Validation loss: 2.049175058801969

Epoch: 5| Step: 10
Training loss: 2.352090358734131
Validation loss: 2.0564599533875785

Epoch: 5| Step: 11
Training loss: 2.322756290435791
Validation loss: 2.0744428237279258

Epoch: 163| Step: 0
Training loss: 2.638701915740967
Validation loss: 2.0435392757256827

Epoch: 5| Step: 1
Training loss: 1.5804946422576904
Validation loss: 2.0548396855592728

Epoch: 5| Step: 2
Training loss: 3.0400168895721436
Validation loss: 2.0344659139712653

Epoch: 5| Step: 3
Training loss: 2.297823905944824
Validation loss: 2.0396746595700583

Epoch: 5| Step: 4
Training loss: 1.9606059789657593
Validation loss: 2.039831022421519

Epoch: 5| Step: 5
Training loss: 1.5113341808319092
Validation loss: 2.039478744069735

Epoch: 5| Step: 6
Training loss: 2.2684342861175537
Validation loss: 2.0473945339520774

Epoch: 5| Step: 7
Training loss: 1.8171837329864502
Validation loss: 2.044981141885122

Epoch: 5| Step: 8
Training loss: 2.124617099761963
Validation loss: 2.04853489001592

Epoch: 5| Step: 9
Training loss: 1.8604940176010132
Validation loss: 2.0296797305345535

Epoch: 5| Step: 10
Training loss: 1.7306194305419922
Validation loss: 2.044989302754402

Epoch: 5| Step: 11
Training loss: 1.8778306245803833
Validation loss: 2.043147176504135

Epoch: 164| Step: 0
Training loss: 2.1928763389587402
Validation loss: 2.046736220518748

Epoch: 5| Step: 1
Training loss: 1.7544593811035156
Validation loss: 2.042617534597715

Epoch: 5| Step: 2
Training loss: 2.3544907569885254
Validation loss: 2.0614144057035446

Epoch: 5| Step: 3
Training loss: 2.3276915550231934
Validation loss: 2.0650082180897393

Epoch: 5| Step: 4
Training loss: 1.8197416067123413
Validation loss: 2.0765369534492493

Epoch: 5| Step: 5
Training loss: 2.207070827484131
Validation loss: 2.0778740545113883

Epoch: 5| Step: 6
Training loss: 2.0439329147338867
Validation loss: 2.048934981226921

Epoch: 5| Step: 7
Training loss: 2.5554206371307373
Validation loss: 2.040186588962873

Epoch: 5| Step: 8
Training loss: 1.6855958700180054
Validation loss: 2.034172569712003

Epoch: 5| Step: 9
Training loss: 2.218564510345459
Validation loss: 2.0220762143532434

Epoch: 5| Step: 10
Training loss: 1.9326965808868408
Validation loss: 2.016233041882515

Epoch: 5| Step: 11
Training loss: 1.324637770652771
Validation loss: 2.0257814675569534

Epoch: 165| Step: 0
Training loss: 1.69308340549469
Validation loss: 2.0178317526976266

Epoch: 5| Step: 1
Training loss: 1.5170304775238037
Validation loss: 2.020407502849897

Epoch: 5| Step: 2
Training loss: 2.066476821899414
Validation loss: 2.029354085524877

Epoch: 5| Step: 3
Training loss: 2.3659005165100098
Validation loss: 2.0234277049700418

Epoch: 5| Step: 4
Training loss: 2.3213164806365967
Validation loss: 2.0297010441621146

Epoch: 5| Step: 5
Training loss: 1.9806413650512695
Validation loss: 2.02549210190773

Epoch: 5| Step: 6
Training loss: 2.112205982208252
Validation loss: 2.030287136634191

Epoch: 5| Step: 7
Training loss: 2.7523481845855713
Validation loss: 2.0384422888358436

Epoch: 5| Step: 8
Training loss: 1.8153598308563232
Validation loss: 2.039260908961296

Epoch: 5| Step: 9
Training loss: 2.201559066772461
Validation loss: 2.0424562444289527

Epoch: 5| Step: 10
Training loss: 1.967087984085083
Validation loss: 2.0426700711250305

Epoch: 5| Step: 11
Training loss: 2.0347111225128174
Validation loss: 2.0451507916053138

Epoch: 166| Step: 0
Training loss: 1.7948520183563232
Validation loss: 2.0457414935032525

Epoch: 5| Step: 1
Training loss: 2.5104281902313232
Validation loss: 2.067225063840548

Epoch: 5| Step: 2
Training loss: 2.368196964263916
Validation loss: 2.0911998798449836

Epoch: 5| Step: 3
Training loss: 1.7891067266464233
Validation loss: 2.084386497735977

Epoch: 5| Step: 4
Training loss: 2.3418097496032715
Validation loss: 2.0768838673830032

Epoch: 5| Step: 5
Training loss: 2.032992124557495
Validation loss: 2.089523250857989

Epoch: 5| Step: 6
Training loss: 2.356405258178711
Validation loss: 2.0637832234303155

Epoch: 5| Step: 7
Training loss: 2.086012601852417
Validation loss: 2.0660505493481955

Epoch: 5| Step: 8
Training loss: 1.7443679571151733
Validation loss: 2.0579216678937278

Epoch: 5| Step: 9
Training loss: 2.163090229034424
Validation loss: 2.0471476217110953

Epoch: 5| Step: 10
Training loss: 1.7271473407745361
Validation loss: 2.0481539765993753

Epoch: 5| Step: 11
Training loss: 2.3521547317504883
Validation loss: 2.034867897629738

Epoch: 167| Step: 0
Training loss: 2.052091360092163
Validation loss: 2.0235765129327774

Epoch: 5| Step: 1
Training loss: 2.1543612480163574
Validation loss: 2.0311671992142997

Epoch: 5| Step: 2
Training loss: 1.705976128578186
Validation loss: 2.04653666416804

Epoch: 5| Step: 3
Training loss: 2.0348129272460938
Validation loss: 2.0463774700959525

Epoch: 5| Step: 4
Training loss: 2.119121551513672
Validation loss: 2.052489712834358

Epoch: 5| Step: 5
Training loss: 2.1942458152770996
Validation loss: 2.0573216527700424

Epoch: 5| Step: 6
Training loss: 2.1206445693969727
Validation loss: 2.0546416689952216

Epoch: 5| Step: 7
Training loss: 2.215846061706543
Validation loss: 2.064662287632624

Epoch: 5| Step: 8
Training loss: 2.604823589324951
Validation loss: 2.051490659515063

Epoch: 5| Step: 9
Training loss: 1.5224330425262451
Validation loss: 2.055107985933622

Epoch: 5| Step: 10
Training loss: 2.1510894298553467
Validation loss: 2.051404669880867

Epoch: 5| Step: 11
Training loss: 2.9732213020324707
Validation loss: 2.053149998188019

Epoch: 168| Step: 0
Training loss: 1.9505008459091187
Validation loss: 2.043732225894928

Epoch: 5| Step: 1
Training loss: 2.585134744644165
Validation loss: 2.0387415488560996

Epoch: 5| Step: 2
Training loss: 1.7477452754974365
Validation loss: 2.031823347012202

Epoch: 5| Step: 3
Training loss: 1.766493558883667
Validation loss: 2.042392169435819

Epoch: 5| Step: 4
Training loss: 2.3722472190856934
Validation loss: 2.0476900140444436

Epoch: 5| Step: 5
Training loss: 2.162365436553955
Validation loss: 2.057674542069435

Epoch: 5| Step: 6
Training loss: 2.1638379096984863
Validation loss: 2.0485176692406335

Epoch: 5| Step: 7
Training loss: 2.41505765914917
Validation loss: 2.0445591608683267

Epoch: 5| Step: 8
Training loss: 1.5858652591705322
Validation loss: 2.069436420996984

Epoch: 5| Step: 9
Training loss: 1.0351040363311768
Validation loss: 2.049105534950892

Epoch: 5| Step: 10
Training loss: 2.8913791179656982
Validation loss: 2.073880841334661

Epoch: 5| Step: 11
Training loss: 1.443516731262207
Validation loss: 2.0639351656039557

Epoch: 169| Step: 0
Training loss: 2.32163667678833
Validation loss: 2.045651599764824

Epoch: 5| Step: 1
Training loss: 1.8861057758331299
Validation loss: 2.0451248486836753

Epoch: 5| Step: 2
Training loss: 1.796993613243103
Validation loss: 2.0442430476347604

Epoch: 5| Step: 3
Training loss: 1.9640400409698486
Validation loss: 2.053248792886734

Epoch: 5| Step: 4
Training loss: 2.1633267402648926
Validation loss: 2.044525757431984

Epoch: 5| Step: 5
Training loss: 2.075533866882324
Validation loss: 2.045271689693133

Epoch: 5| Step: 6
Training loss: 1.6635878086090088
Validation loss: 2.042037303249041

Epoch: 5| Step: 7
Training loss: 2.2340457439422607
Validation loss: 2.0291458467642465

Epoch: 5| Step: 8
Training loss: 2.1315293312072754
Validation loss: 2.0470689684152603

Epoch: 5| Step: 9
Training loss: 1.8255382776260376
Validation loss: 2.0361387928326926

Epoch: 5| Step: 10
Training loss: 2.185547351837158
Validation loss: 2.0371115307013192

Epoch: 5| Step: 11
Training loss: 1.7413711547851562
Validation loss: 2.0398351748784385

Epoch: 170| Step: 0
Training loss: 1.8228305578231812
Validation loss: 2.045421004295349

Epoch: 5| Step: 1
Training loss: 1.7049068212509155
Validation loss: 2.0443079471588135

Epoch: 5| Step: 2
Training loss: 1.9757254123687744
Validation loss: 2.0445755471785865

Epoch: 5| Step: 3
Training loss: 1.8937288522720337
Validation loss: 2.052154372135798

Epoch: 5| Step: 4
Training loss: 1.958004355430603
Validation loss: 2.03985159099102

Epoch: 5| Step: 5
Training loss: 1.666367769241333
Validation loss: 2.054807032148043

Epoch: 5| Step: 6
Training loss: 2.7770073413848877
Validation loss: 2.0636265327533088

Epoch: 5| Step: 7
Training loss: 2.6373226642608643
Validation loss: 2.0532508939504623

Epoch: 5| Step: 8
Training loss: 2.413996696472168
Validation loss: 2.054494028290113

Epoch: 5| Step: 9
Training loss: 1.7035620212554932
Validation loss: 2.047957812746366

Epoch: 5| Step: 10
Training loss: 1.7921139001846313
Validation loss: 2.0478366315364838

Epoch: 5| Step: 11
Training loss: 1.3178364038467407
Validation loss: 2.050876960158348

Epoch: 171| Step: 0
Training loss: 2.4727094173431396
Validation loss: 2.0613178412119546

Epoch: 5| Step: 1
Training loss: 1.7765824794769287
Validation loss: 2.061907708644867

Epoch: 5| Step: 2
Training loss: 2.8564372062683105
Validation loss: 2.062056909004847

Epoch: 5| Step: 3
Training loss: 2.021432399749756
Validation loss: 2.069621334473292

Epoch: 5| Step: 4
Training loss: 1.7694085836410522
Validation loss: 2.070524071653684

Epoch: 5| Step: 5
Training loss: 2.210175037384033
Validation loss: 2.067118297020594

Epoch: 5| Step: 6
Training loss: 1.6503870487213135
Validation loss: 2.075413237015406

Epoch: 5| Step: 7
Training loss: 1.6076425313949585
Validation loss: 2.076623817284902

Epoch: 5| Step: 8
Training loss: 1.992246389389038
Validation loss: 2.0591750144958496

Epoch: 5| Step: 9
Training loss: 1.8467597961425781
Validation loss: 2.047047182917595

Epoch: 5| Step: 10
Training loss: 2.253899335861206
Validation loss: 2.0492264181375504

Epoch: 5| Step: 11
Training loss: 1.5325042009353638
Validation loss: 2.049157520135244

Epoch: 172| Step: 0
Training loss: 2.456862211227417
Validation loss: 2.056627710660299

Epoch: 5| Step: 1
Training loss: 2.154505729675293
Validation loss: 2.063648889462153

Epoch: 5| Step: 2
Training loss: 1.5127038955688477
Validation loss: 2.0499188701311746

Epoch: 5| Step: 3
Training loss: 1.7080051898956299
Validation loss: 2.049783100684484

Epoch: 5| Step: 4
Training loss: 1.8686485290527344
Validation loss: 2.0468643655379615

Epoch: 5| Step: 5
Training loss: 2.1753716468811035
Validation loss: 2.0540674179792404

Epoch: 5| Step: 6
Training loss: 2.467552900314331
Validation loss: 2.0443605283896127

Epoch: 5| Step: 7
Training loss: 1.6760742664337158
Validation loss: 2.045825779438019

Epoch: 5| Step: 8
Training loss: 2.16306209564209
Validation loss: 2.0466663986444473

Epoch: 5| Step: 9
Training loss: 2.1401119232177734
Validation loss: 2.040656179189682

Epoch: 5| Step: 10
Training loss: 2.174150228500366
Validation loss: 2.0333828975756965

Epoch: 5| Step: 11
Training loss: 2.7519726753234863
Validation loss: 2.0410145272811255

Epoch: 173| Step: 0
Training loss: 2.3077502250671387
Validation loss: 2.035830686489741

Epoch: 5| Step: 1
Training loss: 2.187472105026245
Validation loss: 2.043462783098221

Epoch: 5| Step: 2
Training loss: 2.351285219192505
Validation loss: 2.0421007772286734

Epoch: 5| Step: 3
Training loss: 1.8382631540298462
Validation loss: 2.0545102854569754

Epoch: 5| Step: 4
Training loss: 1.5358790159225464
Validation loss: 2.0495818157990775

Epoch: 5| Step: 5
Training loss: 1.6252472400665283
Validation loss: 2.049367000659307

Epoch: 5| Step: 6
Training loss: 2.1651663780212402
Validation loss: 2.063989525039991

Epoch: 5| Step: 7
Training loss: 2.477294445037842
Validation loss: 2.0601137528816857

Epoch: 5| Step: 8
Training loss: 1.8002135753631592
Validation loss: 2.066143810749054

Epoch: 5| Step: 9
Training loss: 1.9637874364852905
Validation loss: 2.0844548841317496

Epoch: 5| Step: 10
Training loss: 2.0302255153656006
Validation loss: 2.0912234038114548

Epoch: 5| Step: 11
Training loss: 2.916109800338745
Validation loss: 2.0991046776374183

Epoch: 174| Step: 0
Training loss: 2.422698736190796
Validation loss: 2.087013840675354

Epoch: 5| Step: 1
Training loss: 2.214725971221924
Validation loss: 2.0801451603571572

Epoch: 5| Step: 2
Training loss: 2.005650043487549
Validation loss: 2.0855867862701416

Epoch: 5| Step: 3
Training loss: 2.419556140899658
Validation loss: 2.052723045150439

Epoch: 5| Step: 4
Training loss: 2.320244312286377
Validation loss: 2.057491287589073

Epoch: 5| Step: 5
Training loss: 1.7288854122161865
Validation loss: 2.0494733850161233

Epoch: 5| Step: 6
Training loss: 1.6197773218154907
Validation loss: 2.0523107250531516

Epoch: 5| Step: 7
Training loss: 2.011709690093994
Validation loss: 2.0513378232717514

Epoch: 5| Step: 8
Training loss: 2.403083086013794
Validation loss: 2.0446744561195374

Epoch: 5| Step: 9
Training loss: 1.7696056365966797
Validation loss: 2.049413651227951

Epoch: 5| Step: 10
Training loss: 1.4957600831985474
Validation loss: 2.052947292725245

Epoch: 5| Step: 11
Training loss: 2.446460485458374
Validation loss: 2.049836054444313

Epoch: 175| Step: 0
Training loss: 1.9943130016326904
Validation loss: 2.0452756037314734

Epoch: 5| Step: 1
Training loss: 2.527202606201172
Validation loss: 2.0568158427874246

Epoch: 5| Step: 2
Training loss: 1.7117319107055664
Validation loss: 2.0396998624006906

Epoch: 5| Step: 3
Training loss: 1.779004693031311
Validation loss: 2.050678531328837

Epoch: 5| Step: 4
Training loss: 1.9955476522445679
Validation loss: 2.0496020317077637

Epoch: 5| Step: 5
Training loss: 2.000886917114258
Validation loss: 2.0553324222564697

Epoch: 5| Step: 6
Training loss: 1.9045655727386475
Validation loss: 2.0592827200889587

Epoch: 5| Step: 7
Training loss: 2.0928726196289062
Validation loss: 2.060317446788152

Epoch: 5| Step: 8
Training loss: 2.49231219291687
Validation loss: 2.0761213848988214

Epoch: 5| Step: 9
Training loss: 1.9019759893417358
Validation loss: 2.064314832290014

Epoch: 5| Step: 10
Training loss: 2.0967934131622314
Validation loss: 2.0664807756741843

Epoch: 5| Step: 11
Training loss: 1.1910135746002197
Validation loss: 2.0584678749243417

Epoch: 176| Step: 0
Training loss: 2.0776872634887695
Validation loss: 2.0553745925426483

Epoch: 5| Step: 1
Training loss: 2.2901339530944824
Validation loss: 2.045966237783432

Epoch: 5| Step: 2
Training loss: 2.5492312908172607
Validation loss: 2.046841025352478

Epoch: 5| Step: 3
Training loss: 1.9080045223236084
Validation loss: 2.0418587923049927

Epoch: 5| Step: 4
Training loss: 1.781073808670044
Validation loss: 2.0451019505659738

Epoch: 5| Step: 5
Training loss: 1.9615827798843384
Validation loss: 2.046466792623202

Epoch: 5| Step: 6
Training loss: 1.857342004776001
Validation loss: 2.0534881750742593

Epoch: 5| Step: 7
Training loss: 1.9004833698272705
Validation loss: 2.053746779759725

Epoch: 5| Step: 8
Training loss: 1.741983413696289
Validation loss: 2.0529062151908875

Epoch: 5| Step: 9
Training loss: 1.8566930294036865
Validation loss: 2.0468176901340485

Epoch: 5| Step: 10
Training loss: 2.5179736614227295
Validation loss: 2.0460060139497123

Epoch: 5| Step: 11
Training loss: 1.1382583379745483
Validation loss: 2.0572356084982553

Epoch: 177| Step: 0
Training loss: 2.303952693939209
Validation loss: 2.049867659807205

Epoch: 5| Step: 1
Training loss: 2.3547141551971436
Validation loss: 2.0540766616662345

Epoch: 5| Step: 2
Training loss: 1.8217006921768188
Validation loss: 2.0637235393126807

Epoch: 5| Step: 3
Training loss: 1.7113116979599
Validation loss: 2.0810382614533105

Epoch: 5| Step: 4
Training loss: 1.289370059967041
Validation loss: 2.0882049153248468

Epoch: 5| Step: 5
Training loss: 2.3001914024353027
Validation loss: 2.0846487234036126

Epoch: 5| Step: 6
Training loss: 2.3123722076416016
Validation loss: 2.0687302350997925

Epoch: 5| Step: 7
Training loss: 2.0551083087921143
Validation loss: 2.083298588792483

Epoch: 5| Step: 8
Training loss: 1.8177235126495361
Validation loss: 2.0864680061737695

Epoch: 5| Step: 9
Training loss: 1.8998464345932007
Validation loss: 2.0476218909025192

Epoch: 5| Step: 10
Training loss: 2.239837169647217
Validation loss: 2.055423746506373

Epoch: 5| Step: 11
Training loss: 2.561471700668335
Validation loss: 2.0485906898975372

Epoch: 178| Step: 0
Training loss: 2.257642984390259
Validation loss: 2.0476844112078347

Epoch: 5| Step: 1
Training loss: 2.1050169467926025
Validation loss: 2.046556457877159

Epoch: 5| Step: 2
Training loss: 2.154151201248169
Validation loss: 2.0420553783575692

Epoch: 5| Step: 3
Training loss: 1.3941831588745117
Validation loss: 2.044460728764534

Epoch: 5| Step: 4
Training loss: 1.8248134851455688
Validation loss: 2.0392710318168006

Epoch: 5| Step: 5
Training loss: 2.2602219581604004
Validation loss: 2.0573826978603997

Epoch: 5| Step: 6
Training loss: 1.7790019512176514
Validation loss: 2.0491919418176017

Epoch: 5| Step: 7
Training loss: 1.9359667301177979
Validation loss: 2.043388361732165

Epoch: 5| Step: 8
Training loss: 2.0300917625427246
Validation loss: 2.0418618520100913

Epoch: 5| Step: 9
Training loss: 2.2250120639801025
Validation loss: 2.048584962884585

Epoch: 5| Step: 10
Training loss: 2.981095790863037
Validation loss: 2.0522713462511697

Epoch: 5| Step: 11
Training loss: 1.8709722757339478
Validation loss: 2.047279864549637

Epoch: 179| Step: 0
Training loss: 1.9748703241348267
Validation loss: 2.0466749717791877

Epoch: 5| Step: 1
Training loss: 1.9851630926132202
Validation loss: 2.0529226859410605

Epoch: 5| Step: 2
Training loss: 2.187359571456909
Validation loss: 2.0538968642552695

Epoch: 5| Step: 3
Training loss: 2.454603672027588
Validation loss: 2.071288744608561

Epoch: 5| Step: 4
Training loss: 1.8916124105453491
Validation loss: 2.0725194166103997

Epoch: 5| Step: 5
Training loss: 2.4392459392547607
Validation loss: 2.0673597951730094

Epoch: 5| Step: 6
Training loss: 0.9488113522529602
Validation loss: 2.0747324029604592

Epoch: 5| Step: 7
Training loss: 2.239851951599121
Validation loss: 2.082376549641291

Epoch: 5| Step: 8
Training loss: 1.728703260421753
Validation loss: 2.0794440706570945

Epoch: 5| Step: 9
Training loss: 2.6886584758758545
Validation loss: 2.0756990959246955

Epoch: 5| Step: 10
Training loss: 1.8657705783843994
Validation loss: 2.063919708132744

Epoch: 5| Step: 11
Training loss: 1.403217077255249
Validation loss: 2.057787557442983

Epoch: 180| Step: 0
Training loss: 2.544292449951172
Validation loss: 2.0549276173114777

Epoch: 5| Step: 1
Training loss: 2.0670132637023926
Validation loss: 2.0519507626692453

Epoch: 5| Step: 2
Training loss: 1.6120388507843018
Validation loss: 2.0557385136683783

Epoch: 5| Step: 3
Training loss: 1.9050445556640625
Validation loss: 2.0517005970080695

Epoch: 5| Step: 4
Training loss: 2.3328680992126465
Validation loss: 2.0557660857836404

Epoch: 5| Step: 5
Training loss: 2.01464581489563
Validation loss: 2.0595267017682395

Epoch: 5| Step: 6
Training loss: 2.1434807777404785
Validation loss: 2.0541795740524926

Epoch: 5| Step: 7
Training loss: 2.348050594329834
Validation loss: 2.0575697273015976

Epoch: 5| Step: 8
Training loss: 1.9283850193023682
Validation loss: 2.059173882007599

Epoch: 5| Step: 9
Training loss: 1.9626274108886719
Validation loss: 2.049150968591372

Epoch: 5| Step: 10
Training loss: 2.126136302947998
Validation loss: 2.043302744626999

Epoch: 5| Step: 11
Training loss: 1.1498985290527344
Validation loss: 2.038977781931559

Epoch: 181| Step: 0
Training loss: 2.047192096710205
Validation loss: 2.046611964702606

Epoch: 5| Step: 1
Training loss: 2.2056376934051514
Validation loss: 2.0506935069958367

Epoch: 5| Step: 2
Training loss: 1.956199288368225
Validation loss: 2.059610679745674

Epoch: 5| Step: 3
Training loss: 2.367366075515747
Validation loss: 2.0769543796777725

Epoch: 5| Step: 4
Training loss: 1.7490813732147217
Validation loss: 2.1143271823724112

Epoch: 5| Step: 5
Training loss: 2.709231376647949
Validation loss: 2.0935863653818765

Epoch: 5| Step: 6
Training loss: 1.2758610248565674
Validation loss: 2.1027053197224936

Epoch: 5| Step: 7
Training loss: 2.09431791305542
Validation loss: 2.1151340355475745

Epoch: 5| Step: 8
Training loss: 1.7609479427337646
Validation loss: 2.104094222187996

Epoch: 5| Step: 9
Training loss: 1.8925139904022217
Validation loss: 2.082689508795738

Epoch: 5| Step: 10
Training loss: 2.4010374546051025
Validation loss: 2.0842077136039734

Epoch: 5| Step: 11
Training loss: 1.8533774614334106
Validation loss: 2.0566422591606774

Epoch: 182| Step: 0
Training loss: 1.4949915409088135
Validation loss: 2.058428148428599

Epoch: 5| Step: 1
Training loss: 1.8978580236434937
Validation loss: 2.0574436684449515

Epoch: 5| Step: 2
Training loss: 2.2738423347473145
Validation loss: 2.050240079561869

Epoch: 5| Step: 3
Training loss: 2.2587876319885254
Validation loss: 2.05029658973217

Epoch: 5| Step: 4
Training loss: 2.0821545124053955
Validation loss: 2.064828301469485

Epoch: 5| Step: 5
Training loss: 2.3953113555908203
Validation loss: 2.061852882305781

Epoch: 5| Step: 6
Training loss: 1.8648971319198608
Validation loss: 2.063161144653956

Epoch: 5| Step: 7
Training loss: 1.676600456237793
Validation loss: 2.0607603241999946

Epoch: 5| Step: 8
Training loss: 2.8434901237487793
Validation loss: 2.0603272020816803

Epoch: 5| Step: 9
Training loss: 2.483673095703125
Validation loss: 2.0453925281763077

Epoch: 5| Step: 10
Training loss: 1.6901328563690186
Validation loss: 2.0528740088144937

Epoch: 5| Step: 11
Training loss: 1.0840673446655273
Validation loss: 2.056446895003319

Epoch: 183| Step: 0
Training loss: 1.7403881549835205
Validation loss: 2.0597217231988907

Epoch: 5| Step: 1
Training loss: 2.2228052616119385
Validation loss: 2.0564492692550025

Epoch: 5| Step: 2
Training loss: 1.631129264831543
Validation loss: 2.05140350262324

Epoch: 5| Step: 3
Training loss: 1.9949573278427124
Validation loss: 2.091494699319204

Epoch: 5| Step: 4
Training loss: 2.621854782104492
Validation loss: 2.097610756754875

Epoch: 5| Step: 5
Training loss: 1.7456035614013672
Validation loss: 2.104560981194178

Epoch: 5| Step: 6
Training loss: 2.3570194244384766
Validation loss: 2.1172372698783875

Epoch: 5| Step: 7
Training loss: 2.6110293865203857
Validation loss: 2.1409152348836265

Epoch: 5| Step: 8
Training loss: 2.576711654663086
Validation loss: 2.1117311914761863

Epoch: 5| Step: 9
Training loss: 1.9242976903915405
Validation loss: 2.1131761024395623

Epoch: 5| Step: 10
Training loss: 1.6185144186019897
Validation loss: 2.076376130183538

Epoch: 5| Step: 11
Training loss: 1.3500765562057495
Validation loss: 2.0633683999379477

Epoch: 184| Step: 0
Training loss: 1.9253818988800049
Validation loss: 2.069709286093712

Epoch: 5| Step: 1
Training loss: 2.1581544876098633
Validation loss: 2.044904962182045

Epoch: 5| Step: 2
Training loss: 1.9905974864959717
Validation loss: 2.0539477368195853

Epoch: 5| Step: 3
Training loss: 1.971726655960083
Validation loss: 2.069302568833033

Epoch: 5| Step: 4
Training loss: 1.9925559759140015
Validation loss: 2.063542991876602

Epoch: 5| Step: 5
Training loss: 1.5753594636917114
Validation loss: 2.065525437394778

Epoch: 5| Step: 6
Training loss: 1.7898966073989868
Validation loss: 2.066999594370524

Epoch: 5| Step: 7
Training loss: 2.0804550647735596
Validation loss: 2.066402345895767

Epoch: 5| Step: 8
Training loss: 2.0713388919830322
Validation loss: 2.0722815791765847

Epoch: 5| Step: 9
Training loss: 2.86669921875
Validation loss: 2.0642286191383996

Epoch: 5| Step: 10
Training loss: 2.093414783477783
Validation loss: 2.074951852361361

Epoch: 5| Step: 11
Training loss: 3.4663033485412598
Validation loss: 2.0644043932358422

Epoch: 185| Step: 0
Training loss: 1.4300026893615723
Validation loss: 2.069944848616918

Epoch: 5| Step: 1
Training loss: 2.6027743816375732
Validation loss: 2.074869920810064

Epoch: 5| Step: 2
Training loss: 2.213646411895752
Validation loss: 2.0600554744402566

Epoch: 5| Step: 3
Training loss: 2.4841580390930176
Validation loss: 2.053455183903376

Epoch: 5| Step: 4
Training loss: 1.9335638284683228
Validation loss: 2.051457464694977

Epoch: 5| Step: 5
Training loss: 2.454714298248291
Validation loss: 2.067170098423958

Epoch: 5| Step: 6
Training loss: 2.0764458179473877
Validation loss: 2.0678354601065316

Epoch: 5| Step: 7
Training loss: 2.1088109016418457
Validation loss: 2.0874030937751136

Epoch: 5| Step: 8
Training loss: 2.0763115882873535
Validation loss: 2.0847913175821304

Epoch: 5| Step: 9
Training loss: 1.5925785303115845
Validation loss: 2.0978237837553024

Epoch: 5| Step: 10
Training loss: 1.8537534475326538
Validation loss: 2.100799729426702

Epoch: 5| Step: 11
Training loss: 1.866045355796814
Validation loss: 2.0788800666729608

Epoch: 186| Step: 0
Training loss: 2.4217560291290283
Validation loss: 2.063512295484543

Epoch: 5| Step: 1
Training loss: 2.6947386264801025
Validation loss: 2.0590712279081345

Epoch: 5| Step: 2
Training loss: 1.7458385229110718
Validation loss: 2.0558502972126007

Epoch: 5| Step: 3
Training loss: 2.0310444831848145
Validation loss: 2.047361671924591

Epoch: 5| Step: 4
Training loss: 1.83058762550354
Validation loss: 2.0563613921403885

Epoch: 5| Step: 5
Training loss: 2.0216784477233887
Validation loss: 2.05313803255558

Epoch: 5| Step: 6
Training loss: 1.7876613140106201
Validation loss: 2.061747138698896

Epoch: 5| Step: 7
Training loss: 1.9479566812515259
Validation loss: 2.065009295940399

Epoch: 5| Step: 8
Training loss: 1.7940547466278076
Validation loss: 2.0584360460440316

Epoch: 5| Step: 9
Training loss: 1.8000688552856445
Validation loss: 2.065060243010521

Epoch: 5| Step: 10
Training loss: 1.9807621240615845
Validation loss: 2.0672115484873452

Epoch: 5| Step: 11
Training loss: 2.392336368560791
Validation loss: 2.071717917919159

Epoch: 187| Step: 0
Training loss: 1.9820630550384521
Validation loss: 2.0646778444449105

Epoch: 5| Step: 1
Training loss: 1.640197515487671
Validation loss: 2.0785761376221976

Epoch: 5| Step: 2
Training loss: 2.3549530506134033
Validation loss: 2.0805705189704895

Epoch: 5| Step: 3
Training loss: 1.4831311702728271
Validation loss: 2.097539926568667

Epoch: 5| Step: 4
Training loss: 1.8007150888442993
Validation loss: 2.086207260688146

Epoch: 5| Step: 5
Training loss: 2.2437808513641357
Validation loss: 2.104779581228892

Epoch: 5| Step: 6
Training loss: 2.120777130126953
Validation loss: 2.0984112471342087

Epoch: 5| Step: 7
Training loss: 2.5530858039855957
Validation loss: 2.09081377585729

Epoch: 5| Step: 8
Training loss: 2.550032377243042
Validation loss: 2.0844699343045554

Epoch: 5| Step: 9
Training loss: 1.8756656646728516
Validation loss: 2.0686723987261453

Epoch: 5| Step: 10
Training loss: 1.6877384185791016
Validation loss: 2.0594446261723838

Epoch: 5| Step: 11
Training loss: 2.4930295944213867
Validation loss: 2.0572607765595117

Epoch: 188| Step: 0
Training loss: 1.6474454402923584
Validation loss: 2.0588814119497933

Epoch: 5| Step: 1
Training loss: 1.946422815322876
Validation loss: 2.0562702864408493

Epoch: 5| Step: 2
Training loss: 1.9648940563201904
Validation loss: 2.0582983593146005

Epoch: 5| Step: 3
Training loss: 2.1587653160095215
Validation loss: 2.04857030014197

Epoch: 5| Step: 4
Training loss: 2.1981537342071533
Validation loss: 2.054317439595858

Epoch: 5| Step: 5
Training loss: 1.945533037185669
Validation loss: 2.0534292459487915

Epoch: 5| Step: 6
Training loss: 2.1416406631469727
Validation loss: 2.057302638888359

Epoch: 5| Step: 7
Training loss: 1.6536318063735962
Validation loss: 2.0532609075307846

Epoch: 5| Step: 8
Training loss: 2.6469085216522217
Validation loss: 2.044974833726883

Epoch: 5| Step: 9
Training loss: 2.080681324005127
Validation loss: 2.0430559118588767

Epoch: 5| Step: 10
Training loss: 2.020051956176758
Validation loss: 2.0509212017059326

Epoch: 5| Step: 11
Training loss: 1.856764793395996
Validation loss: 2.0540421257416406

Epoch: 189| Step: 0
Training loss: 1.8412624597549438
Validation loss: 2.059741973876953

Epoch: 5| Step: 1
Training loss: 1.5096298456192017
Validation loss: 2.055313309033712

Epoch: 5| Step: 2
Training loss: 1.8480758666992188
Validation loss: 2.0562431812286377

Epoch: 5| Step: 3
Training loss: 1.634199857711792
Validation loss: 2.070484126607577

Epoch: 5| Step: 4
Training loss: 2.302596092224121
Validation loss: 2.0657246708869934

Epoch: 5| Step: 5
Training loss: 1.92677903175354
Validation loss: 2.0616582532723746

Epoch: 5| Step: 6
Training loss: 2.3712539672851562
Validation loss: 2.072730431954066

Epoch: 5| Step: 7
Training loss: 1.8211405277252197
Validation loss: 2.061873589952787

Epoch: 5| Step: 8
Training loss: 2.261268138885498
Validation loss: 2.0634340892235437

Epoch: 5| Step: 9
Training loss: 1.9318161010742188
Validation loss: 2.0544236401716867

Epoch: 5| Step: 10
Training loss: 2.3565056324005127
Validation loss: 2.0500661929448447

Epoch: 5| Step: 11
Training loss: 3.240325927734375
Validation loss: 2.0614224821329117

Epoch: 190| Step: 0
Training loss: 1.9500091075897217
Validation loss: 2.0533970246712365

Epoch: 5| Step: 1
Training loss: 2.117070198059082
Validation loss: 2.0542533298333487

Epoch: 5| Step: 2
Training loss: 2.2362804412841797
Validation loss: 2.055642386277517

Epoch: 5| Step: 3
Training loss: 1.9596058130264282
Validation loss: 2.0541005432605743

Epoch: 5| Step: 4
Training loss: 2.5764384269714355
Validation loss: 2.0642789552609124

Epoch: 5| Step: 5
Training loss: 2.4397835731506348
Validation loss: 2.0591543714205423

Epoch: 5| Step: 6
Training loss: 1.066076636314392
Validation loss: 2.0746183693408966

Epoch: 5| Step: 7
Training loss: 1.6259517669677734
Validation loss: 2.066496253013611

Epoch: 5| Step: 8
Training loss: 2.5701541900634766
Validation loss: 2.0676709661881127

Epoch: 5| Step: 9
Training loss: 1.5401785373687744
Validation loss: 2.070653865734736

Epoch: 5| Step: 10
Training loss: 1.7874046564102173
Validation loss: 2.062489499648412

Epoch: 5| Step: 11
Training loss: 2.4991555213928223
Validation loss: 2.0711709509293237

Epoch: 191| Step: 0
Training loss: 2.382439136505127
Validation loss: 2.08250725766023

Epoch: 5| Step: 1
Training loss: 2.0315401554107666
Validation loss: 2.066721503933271

Epoch: 5| Step: 2
Training loss: 1.7304178476333618
Validation loss: 2.075677995880445

Epoch: 5| Step: 3
Training loss: 1.999394416809082
Validation loss: 2.0693437109390893

Epoch: 5| Step: 4
Training loss: 2.200129508972168
Validation loss: 2.072329580783844

Epoch: 5| Step: 5
Training loss: 1.4740108251571655
Validation loss: 2.068481812874476

Epoch: 5| Step: 6
Training loss: 2.2991530895233154
Validation loss: 2.0757172306378684

Epoch: 5| Step: 7
Training loss: 1.4894596338272095
Validation loss: 2.06184691687425

Epoch: 5| Step: 8
Training loss: 2.0496745109558105
Validation loss: 2.0786476532618203

Epoch: 5| Step: 9
Training loss: 2.250810384750366
Validation loss: 2.068593735496203

Epoch: 5| Step: 10
Training loss: 2.379671573638916
Validation loss: 2.0578820208708444

Epoch: 5| Step: 11
Training loss: 2.14920711517334
Validation loss: 2.0691190858682

Epoch: 192| Step: 0
Training loss: 2.3511345386505127
Validation loss: 2.0619549999634423

Epoch: 5| Step: 1
Training loss: 2.026702880859375
Validation loss: 2.054740230242411

Epoch: 5| Step: 2
Training loss: 1.87506103515625
Validation loss: 2.0660375356674194

Epoch: 5| Step: 3
Training loss: 1.549102544784546
Validation loss: 2.0640659232934317

Epoch: 5| Step: 4
Training loss: 2.2545597553253174
Validation loss: 2.06386728088061

Epoch: 5| Step: 5
Training loss: 1.8356428146362305
Validation loss: 2.0691755513350167

Epoch: 5| Step: 6
Training loss: 2.222334623336792
Validation loss: 2.053727775812149

Epoch: 5| Step: 7
Training loss: 1.8630253076553345
Validation loss: 2.0648221323887506

Epoch: 5| Step: 8
Training loss: 2.144502639770508
Validation loss: 2.0652583638827005

Epoch: 5| Step: 9
Training loss: 1.8666083812713623
Validation loss: 2.0667450577020645

Epoch: 5| Step: 10
Training loss: 2.188292980194092
Validation loss: 2.062313601374626

Epoch: 5| Step: 11
Training loss: 2.2529385089874268
Validation loss: 2.0636939654747644

Epoch: 193| Step: 0
Training loss: 2.0298380851745605
Validation loss: 2.0747317473093667

Epoch: 5| Step: 1
Training loss: 2.1115002632141113
Validation loss: 2.079336484273275

Epoch: 5| Step: 2
Training loss: 2.2851994037628174
Validation loss: 2.0664083113272986

Epoch: 5| Step: 3
Training loss: 2.2173562049865723
Validation loss: 2.068818584084511

Epoch: 5| Step: 4
Training loss: 1.4632141590118408
Validation loss: 2.074623634417852

Epoch: 5| Step: 5
Training loss: 2.7479443550109863
Validation loss: 2.074735457698504

Epoch: 5| Step: 6
Training loss: 1.8151676654815674
Validation loss: 2.0687519957621894

Epoch: 5| Step: 7
Training loss: 2.2176144123077393
Validation loss: 2.0623734990755715

Epoch: 5| Step: 8
Training loss: 1.6737210750579834
Validation loss: 2.067331145207087

Epoch: 5| Step: 9
Training loss: 1.8447345495224
Validation loss: 2.054259111483892

Epoch: 5| Step: 10
Training loss: 1.7685728073120117
Validation loss: 2.0668762077887854

Epoch: 5| Step: 11
Training loss: 1.9621243476867676
Validation loss: 2.0659502098957696

Epoch: 194| Step: 0
Training loss: 1.6015621423721313
Validation loss: 2.064542909463247

Epoch: 5| Step: 1
Training loss: 1.8661409616470337
Validation loss: 2.0750900407632193

Epoch: 5| Step: 2
Training loss: 2.53424334526062
Validation loss: 2.065463826060295

Epoch: 5| Step: 3
Training loss: 2.864473819732666
Validation loss: 2.061922699213028

Epoch: 5| Step: 4
Training loss: 2.032017469406128
Validation loss: 2.061079586545626

Epoch: 5| Step: 5
Training loss: 1.8642399311065674
Validation loss: 2.0691990653673806

Epoch: 5| Step: 6
Training loss: 1.795891523361206
Validation loss: 2.0647204567988715

Epoch: 5| Step: 7
Training loss: 1.8339475393295288
Validation loss: 2.068986545006434

Epoch: 5| Step: 8
Training loss: 1.767465591430664
Validation loss: 2.064095218976339

Epoch: 5| Step: 9
Training loss: 1.728989601135254
Validation loss: 2.064897576967875

Epoch: 5| Step: 10
Training loss: 2.0855910778045654
Validation loss: 2.0719721764326096

Epoch: 5| Step: 11
Training loss: 2.0384583473205566
Validation loss: 2.0756100763877234

Epoch: 195| Step: 0
Training loss: 1.9730799198150635
Validation loss: 2.0743755449851355

Epoch: 5| Step: 1
Training loss: 2.2398695945739746
Validation loss: 2.0784939924875894

Epoch: 5| Step: 2
Training loss: 1.6689436435699463
Validation loss: 2.0752186526854834

Epoch: 5| Step: 3
Training loss: 2.072436809539795
Validation loss: 2.0667282044887543

Epoch: 5| Step: 4
Training loss: 1.7983163595199585
Validation loss: 2.0577745089928308

Epoch: 5| Step: 5
Training loss: 1.6011072397232056
Validation loss: 2.0505386541287103

Epoch: 5| Step: 6
Training loss: 2.2618253231048584
Validation loss: 2.0602017690738044

Epoch: 5| Step: 7
Training loss: 2.4178147315979004
Validation loss: 2.05401303867499

Epoch: 5| Step: 8
Training loss: 1.8200994729995728
Validation loss: 2.0458311339219413

Epoch: 5| Step: 9
Training loss: 1.6885707378387451
Validation loss: 2.0477746774752936

Epoch: 5| Step: 10
Training loss: 2.278419017791748
Validation loss: 2.0421215693155923

Epoch: 5| Step: 11
Training loss: 3.1296145915985107
Validation loss: 2.0598546912272773

Epoch: 196| Step: 0
Training loss: 1.3660176992416382
Validation loss: 2.0551053484280906

Epoch: 5| Step: 1
Training loss: 2.2905631065368652
Validation loss: 2.0640800148248672

Epoch: 5| Step: 2
Training loss: 2.2630085945129395
Validation loss: 2.0506550719340644

Epoch: 5| Step: 3
Training loss: 2.080070972442627
Validation loss: 2.0436650017897287

Epoch: 5| Step: 4
Training loss: 2.39123272895813
Validation loss: 2.057523106535276

Epoch: 5| Step: 5
Training loss: 1.976559042930603
Validation loss: 2.0533386717240014

Epoch: 5| Step: 6
Training loss: 2.282864809036255
Validation loss: 2.057523419459661

Epoch: 5| Step: 7
Training loss: 1.7548459768295288
Validation loss: 2.0600843727588654

Epoch: 5| Step: 8
Training loss: 1.6199041604995728
Validation loss: 2.058269197742144

Epoch: 5| Step: 9
Training loss: 2.0731396675109863
Validation loss: 2.0478083044290543

Epoch: 5| Step: 10
Training loss: 2.2244160175323486
Validation loss: 2.0497364352146783

Epoch: 5| Step: 11
Training loss: 1.7920575141906738
Validation loss: 2.0542108764251075

Epoch: 197| Step: 0
Training loss: 2.0382466316223145
Validation loss: 2.064909557501475

Epoch: 5| Step: 1
Training loss: 1.8163859844207764
Validation loss: 2.0631425231695175

Epoch: 5| Step: 2
Training loss: 2.262434244155884
Validation loss: 2.05913574496905

Epoch: 5| Step: 3
Training loss: 1.9593560695648193
Validation loss: 2.081837445497513

Epoch: 5| Step: 4
Training loss: 2.338123321533203
Validation loss: 2.069837659597397

Epoch: 5| Step: 5
Training loss: 2.2332427501678467
Validation loss: 2.0699602365493774

Epoch: 5| Step: 6
Training loss: 1.8175594806671143
Validation loss: 2.053877115249634

Epoch: 5| Step: 7
Training loss: 2.313087224960327
Validation loss: 2.063402613004049

Epoch: 5| Step: 8
Training loss: 2.250182867050171
Validation loss: 2.0750538359085717

Epoch: 5| Step: 9
Training loss: 1.820288896560669
Validation loss: 2.0636399934689202

Epoch: 5| Step: 10
Training loss: 1.2868865728378296
Validation loss: 2.0603049943844476

Epoch: 5| Step: 11
Training loss: 1.65494966506958
Validation loss: 2.072216515739759

Epoch: 198| Step: 0
Training loss: 1.9583326578140259
Validation loss: 2.0779158075650535

Epoch: 5| Step: 1
Training loss: 2.0189216136932373
Validation loss: 2.0736846178770065

Epoch: 5| Step: 2
Training loss: 2.476996898651123
Validation loss: 2.1155040760835013

Epoch: 5| Step: 3
Training loss: 1.7984673976898193
Validation loss: 2.120084504286448

Epoch: 5| Step: 4
Training loss: 1.9503986835479736
Validation loss: 2.1118169675270715

Epoch: 5| Step: 5
Training loss: 1.29170823097229
Validation loss: 2.094516545534134

Epoch: 5| Step: 6
Training loss: 2.125623941421509
Validation loss: 2.0925269375244775

Epoch: 5| Step: 7
Training loss: 2.0098977088928223
Validation loss: 2.09000397225221

Epoch: 5| Step: 8
Training loss: 2.378568172454834
Validation loss: 2.0739611983299255

Epoch: 5| Step: 9
Training loss: 1.9925626516342163
Validation loss: 2.0676336139440536

Epoch: 5| Step: 10
Training loss: 1.9939228296279907
Validation loss: 2.06243064502875

Epoch: 5| Step: 11
Training loss: 2.524721622467041
Validation loss: 2.068675766388575

Epoch: 199| Step: 0
Training loss: 2.1602253913879395
Validation loss: 2.0749824245770774

Epoch: 5| Step: 1
Training loss: 2.117558479309082
Validation loss: 2.056749607125918

Epoch: 5| Step: 2
Training loss: 1.8799877166748047
Validation loss: 2.0567719638347626

Epoch: 5| Step: 3
Training loss: 1.4320340156555176
Validation loss: 2.058963507413864

Epoch: 5| Step: 4
Training loss: 2.4083151817321777
Validation loss: 2.068133383989334

Epoch: 5| Step: 5
Training loss: 1.9217731952667236
Validation loss: 2.0588898162047067

Epoch: 5| Step: 6
Training loss: 2.0768489837646484
Validation loss: 2.0596395432949066

Epoch: 5| Step: 7
Training loss: 1.9570188522338867
Validation loss: 2.0584456821282706

Epoch: 5| Step: 8
Training loss: 1.8286415338516235
Validation loss: 2.07511438926061

Epoch: 5| Step: 9
Training loss: 2.1989574432373047
Validation loss: 2.064036717017492

Epoch: 5| Step: 10
Training loss: 1.7541484832763672
Validation loss: 2.069529707233111

Epoch: 5| Step: 11
Training loss: 2.6112561225891113
Validation loss: 2.066084365049998

Epoch: 200| Step: 0
Training loss: 2.0422704219818115
Validation loss: 2.0654061436653137

Epoch: 5| Step: 1
Training loss: 2.234490394592285
Validation loss: 2.0640960335731506

Epoch: 5| Step: 2
Training loss: 1.9128239154815674
Validation loss: 2.0591047952572503

Epoch: 5| Step: 3
Training loss: 1.7565253973007202
Validation loss: 2.0768188337484994

Epoch: 5| Step: 4
Training loss: 1.8087894916534424
Validation loss: 2.0642884572347007

Epoch: 5| Step: 5
Training loss: 2.3153107166290283
Validation loss: 2.0696037809054055

Epoch: 5| Step: 6
Training loss: 1.540035367012024
Validation loss: 2.065671220421791

Epoch: 5| Step: 7
Training loss: 1.8954541683197021
Validation loss: 2.0714038560787835

Epoch: 5| Step: 8
Training loss: 1.6307485103607178
Validation loss: 2.0693746705849967

Epoch: 5| Step: 9
Training loss: 2.4913716316223145
Validation loss: 2.0812211086352668

Epoch: 5| Step: 10
Training loss: 2.158802032470703
Validation loss: 2.085969477891922

Epoch: 5| Step: 11
Training loss: 1.931348443031311
Validation loss: 2.0830595095952353

Testing loss: 1.7097700422616313
