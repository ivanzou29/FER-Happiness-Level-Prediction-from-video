Epoch: 1| Step: 0
Training loss: 5.1729207038879395
Validation loss: 5.374162832895915

Epoch: 5| Step: 1
Training loss: 5.800368309020996
Validation loss: 5.371785799662272

Epoch: 5| Step: 2
Training loss: 6.283099174499512
Validation loss: 5.369458456834157

Epoch: 5| Step: 3
Training loss: 5.810749053955078
Validation loss: 5.367161313692729

Epoch: 5| Step: 4
Training loss: 5.299173831939697
Validation loss: 5.364940345287323

Epoch: 5| Step: 5
Training loss: 5.76603889465332
Validation loss: 5.362740854422252

Epoch: 5| Step: 6
Training loss: 5.662554740905762
Validation loss: 5.36063136657079

Epoch: 5| Step: 7
Training loss: 5.415049076080322
Validation loss: 5.358452836672465

Epoch: 5| Step: 8
Training loss: 4.931039333343506
Validation loss: 5.356207430362701

Epoch: 5| Step: 9
Training loss: 4.5797014236450195
Validation loss: 5.353897591431935

Epoch: 5| Step: 10
Training loss: 5.169981002807617
Validation loss: 5.351592222849528

Epoch: 5| Step: 11
Training loss: 4.710592269897461
Validation loss: 5.3491896986961365

Epoch: 2| Step: 0
Training loss: 3.849252700805664
Validation loss: 5.34675661722819

Epoch: 5| Step: 1
Training loss: 5.552526950836182
Validation loss: 5.344121674696605

Epoch: 5| Step: 2
Training loss: 5.53740930557251
Validation loss: 5.341524402300517

Epoch: 5| Step: 3
Training loss: 5.931951522827148
Validation loss: 5.338626066843669

Epoch: 5| Step: 4
Training loss: 4.610659599304199
Validation loss: 5.3357319831848145

Epoch: 5| Step: 5
Training loss: 4.818343639373779
Validation loss: 5.332710087299347

Epoch: 5| Step: 6
Training loss: 5.167787075042725
Validation loss: 5.329514066378276

Epoch: 5| Step: 7
Training loss: 5.58072566986084
Validation loss: 5.326164543628693

Epoch: 5| Step: 8
Training loss: 6.563772678375244
Validation loss: 5.322735885779063

Epoch: 5| Step: 9
Training loss: 5.54738712310791
Validation loss: 5.318972150484721

Epoch: 5| Step: 10
Training loss: 6.193120002746582
Validation loss: 5.315172950426738

Epoch: 5| Step: 11
Training loss: 5.664828777313232
Validation loss: 5.3111550609270735

Epoch: 3| Step: 0
Training loss: 5.6929755210876465
Validation loss: 5.306993107000987

Epoch: 5| Step: 1
Training loss: 4.991878032684326
Validation loss: 5.3022701640923815

Epoch: 5| Step: 2
Training loss: 4.716179370880127
Validation loss: 5.297576208909352

Epoch: 5| Step: 3
Training loss: 4.772372245788574
Validation loss: 5.292488892873128

Epoch: 5| Step: 4
Training loss: 5.461391448974609
Validation loss: 5.287472168604533

Epoch: 5| Step: 5
Training loss: 5.986734390258789
Validation loss: 5.281768004099528

Epoch: 5| Step: 6
Training loss: 5.656737327575684
Validation loss: 5.276060402393341

Epoch: 5| Step: 7
Training loss: 4.2632927894592285
Validation loss: 5.270126601060231

Epoch: 5| Step: 8
Training loss: 6.330710411071777
Validation loss: 5.263470967610677

Epoch: 5| Step: 9
Training loss: 5.831732749938965
Validation loss: 5.256693045298259

Epoch: 5| Step: 10
Training loss: 5.41001033782959
Validation loss: 5.24967094262441

Epoch: 5| Step: 11
Training loss: 3.9941744804382324
Validation loss: 5.24199503660202

Epoch: 4| Step: 0
Training loss: 5.190766334533691
Validation loss: 5.233962277571361

Epoch: 5| Step: 1
Training loss: 4.865860939025879
Validation loss: 5.225585758686066

Epoch: 5| Step: 2
Training loss: 5.026557922363281
Validation loss: 5.217051645119985

Epoch: 5| Step: 3
Training loss: 5.386530876159668
Validation loss: 5.207846979300181

Epoch: 5| Step: 4
Training loss: 4.722298622131348
Validation loss: 5.19801922639211

Epoch: 5| Step: 5
Training loss: 5.276416301727295
Validation loss: 5.188176532586415

Epoch: 5| Step: 6
Training loss: 5.36620569229126
Validation loss: 5.177696446577708

Epoch: 5| Step: 7
Training loss: 5.359661102294922
Validation loss: 5.1664372483889265

Epoch: 5| Step: 8
Training loss: 5.7212395668029785
Validation loss: 5.155176560084025

Epoch: 5| Step: 9
Training loss: 5.317035675048828
Validation loss: 5.143620590368907

Epoch: 5| Step: 10
Training loss: 5.555616855621338
Validation loss: 5.1315451463063555

Epoch: 5| Step: 11
Training loss: 5.361899375915527
Validation loss: 5.118939161300659

Epoch: 5| Step: 0
Training loss: 3.9984047412872314
Validation loss: 5.1066121856371565

Epoch: 5| Step: 1
Training loss: 4.75876522064209
Validation loss: 5.093711674213409

Epoch: 5| Step: 2
Training loss: 5.165218353271484
Validation loss: 5.08083192507426

Epoch: 5| Step: 3
Training loss: 5.420920372009277
Validation loss: 5.067888577779134

Epoch: 5| Step: 4
Training loss: 5.503074645996094
Validation loss: 5.054811457792918

Epoch: 5| Step: 5
Training loss: 5.510737419128418
Validation loss: 5.042187472184499

Epoch: 5| Step: 6
Training loss: 4.995766639709473
Validation loss: 5.029032826423645

Epoch: 5| Step: 7
Training loss: 4.82988166809082
Validation loss: 5.015783607959747

Epoch: 5| Step: 8
Training loss: 4.520634651184082
Validation loss: 5.003010829289754

Epoch: 5| Step: 9
Training loss: 5.7983574867248535
Validation loss: 4.990227063496907

Epoch: 5| Step: 10
Training loss: 5.917569637298584
Validation loss: 4.97721403837204

Epoch: 5| Step: 11
Training loss: 4.530505657196045
Validation loss: 4.9650027851263685

Epoch: 6| Step: 0
Training loss: 4.260128974914551
Validation loss: 4.95233682791392

Epoch: 5| Step: 1
Training loss: 4.8775434494018555
Validation loss: 4.939760347207387

Epoch: 5| Step: 2
Training loss: 5.042227745056152
Validation loss: 4.927890837192535

Epoch: 5| Step: 3
Training loss: 4.788386344909668
Validation loss: 4.915889581044515

Epoch: 5| Step: 4
Training loss: 4.677728176116943
Validation loss: 4.904276072978973

Epoch: 5| Step: 5
Training loss: 4.760354042053223
Validation loss: 4.892577052116394

Epoch: 5| Step: 6
Training loss: 3.9897117614746094
Validation loss: 4.8812865018844604

Epoch: 5| Step: 7
Training loss: 5.829506874084473
Validation loss: 4.870130956172943

Epoch: 5| Step: 8
Training loss: 5.488061428070068
Validation loss: 4.859647611776988

Epoch: 5| Step: 9
Training loss: 5.889853477478027
Validation loss: 4.849520047505696

Epoch: 5| Step: 10
Training loss: 4.815245628356934
Validation loss: 4.8400777379671736

Epoch: 5| Step: 11
Training loss: 6.708590984344482
Validation loss: 4.830706556638082

Epoch: 7| Step: 0
Training loss: 3.8267242908477783
Validation loss: 4.821474532286326

Epoch: 5| Step: 1
Training loss: 4.585012912750244
Validation loss: 4.812887728214264

Epoch: 5| Step: 2
Training loss: 5.442337989807129
Validation loss: 4.804287075996399

Epoch: 5| Step: 3
Training loss: 5.296184062957764
Validation loss: 4.796016136805217

Epoch: 5| Step: 4
Training loss: 5.1212263107299805
Validation loss: 4.787878553072612

Epoch: 5| Step: 5
Training loss: 4.750327110290527
Validation loss: 4.779575526714325

Epoch: 5| Step: 6
Training loss: 4.424916744232178
Validation loss: 4.771517276763916

Epoch: 5| Step: 7
Training loss: 6.012225151062012
Validation loss: 4.7638877630233765

Epoch: 5| Step: 8
Training loss: 4.605130195617676
Validation loss: 4.7557898461818695

Epoch: 5| Step: 9
Training loss: 4.531800270080566
Validation loss: 4.747873683770497

Epoch: 5| Step: 10
Training loss: 4.648921012878418
Validation loss: 4.740420113007228

Epoch: 5| Step: 11
Training loss: 6.434779167175293
Validation loss: 4.73271831870079

Epoch: 8| Step: 0
Training loss: 4.382218837738037
Validation loss: 4.724561403195064

Epoch: 5| Step: 1
Training loss: 5.03069543838501
Validation loss: 4.7167525092760725

Epoch: 5| Step: 2
Training loss: 4.933885097503662
Validation loss: 4.708999077479045

Epoch: 5| Step: 3
Training loss: 4.658591270446777
Validation loss: 4.701641201972961

Epoch: 5| Step: 4
Training loss: 4.192301273345947
Validation loss: 4.693947265545527

Epoch: 5| Step: 5
Training loss: 5.7577104568481445
Validation loss: 4.68633438150088

Epoch: 5| Step: 6
Training loss: 5.5728654861450195
Validation loss: 4.6788991292317705

Epoch: 5| Step: 7
Training loss: 4.161396026611328
Validation loss: 4.671039521694183

Epoch: 5| Step: 8
Training loss: 4.906327247619629
Validation loss: 4.664102792739868

Epoch: 5| Step: 9
Training loss: 4.961449146270752
Validation loss: 4.6566793123881025

Epoch: 5| Step: 10
Training loss: 4.067836284637451
Validation loss: 4.649049739042918

Epoch: 5| Step: 11
Training loss: 4.538222789764404
Validation loss: 4.64195328950882

Epoch: 9| Step: 0
Training loss: 4.317570686340332
Validation loss: 4.635010917981465

Epoch: 5| Step: 1
Training loss: 4.535710334777832
Validation loss: 4.627755304177602

Epoch: 5| Step: 2
Training loss: 4.703585147857666
Validation loss: 4.621000230312347

Epoch: 5| Step: 3
Training loss: 5.342551231384277
Validation loss: 4.614157736301422

Epoch: 5| Step: 4
Training loss: 4.810242652893066
Validation loss: 4.607070962587993

Epoch: 5| Step: 5
Training loss: 5.222727298736572
Validation loss: 4.60067876180013

Epoch: 5| Step: 6
Training loss: 3.8529834747314453
Validation loss: 4.593521555264791

Epoch: 5| Step: 7
Training loss: 4.6986083984375
Validation loss: 4.586733361085256

Epoch: 5| Step: 8
Training loss: 5.094871520996094
Validation loss: 4.580223927895228

Epoch: 5| Step: 9
Training loss: 4.540699005126953
Validation loss: 4.573649714390437

Epoch: 5| Step: 10
Training loss: 4.884852886199951
Validation loss: 4.567092587550481

Epoch: 5| Step: 11
Training loss: 3.1289219856262207
Validation loss: 4.559987465540568

Epoch: 10| Step: 0
Training loss: 5.083676338195801
Validation loss: 4.553527444601059

Epoch: 5| Step: 1
Training loss: 4.577095985412598
Validation loss: 4.546812315781911

Epoch: 5| Step: 2
Training loss: 4.388261318206787
Validation loss: 4.539551198482513

Epoch: 5| Step: 3
Training loss: 5.335515975952148
Validation loss: 4.5321424802144366

Epoch: 5| Step: 4
Training loss: 5.8556365966796875
Validation loss: 4.5252010623614

Epoch: 5| Step: 5
Training loss: 4.953719139099121
Validation loss: 4.517527302106221

Epoch: 5| Step: 6
Training loss: 4.327447414398193
Validation loss: 4.51054459810257

Epoch: 5| Step: 7
Training loss: 4.428745269775391
Validation loss: 4.503142058849335

Epoch: 5| Step: 8
Training loss: 4.02532434463501
Validation loss: 4.496053576469421

Epoch: 5| Step: 9
Training loss: 3.719926357269287
Validation loss: 4.4883982340494795

Epoch: 5| Step: 10
Training loss: 4.1814093589782715
Validation loss: 4.4810769359270735

Epoch: 5| Step: 11
Training loss: 4.571615695953369
Validation loss: 4.474695722262065

Epoch: 11| Step: 0
Training loss: 3.9597275257110596
Validation loss: 4.468431035677592

Epoch: 5| Step: 1
Training loss: 4.735102653503418
Validation loss: 4.462467670440674

Epoch: 5| Step: 2
Training loss: 4.664216041564941
Validation loss: 4.456441551446915

Epoch: 5| Step: 3
Training loss: 4.632053375244141
Validation loss: 4.449870586395264

Epoch: 5| Step: 4
Training loss: 4.020306587219238
Validation loss: 4.442973514397939

Epoch: 5| Step: 5
Training loss: 4.762886047363281
Validation loss: 4.436730106671651

Epoch: 5| Step: 6
Training loss: 4.612609386444092
Validation loss: 4.429883639017741

Epoch: 5| Step: 7
Training loss: 5.184645175933838
Validation loss: 4.423072298367818

Epoch: 5| Step: 8
Training loss: 4.105153560638428
Validation loss: 4.4169580439726515

Epoch: 5| Step: 9
Training loss: 4.341808319091797
Validation loss: 4.409897804260254

Epoch: 5| Step: 10
Training loss: 5.133483409881592
Validation loss: 4.402267684539159

Epoch: 5| Step: 11
Training loss: 3.897177219390869
Validation loss: 4.395176549752553

Epoch: 12| Step: 0
Training loss: 5.479936599731445
Validation loss: 4.388380130132039

Epoch: 5| Step: 1
Training loss: 3.9251761436462402
Validation loss: 4.381072302659352

Epoch: 5| Step: 2
Training loss: 4.140353202819824
Validation loss: 4.374459793170293

Epoch: 5| Step: 3
Training loss: 4.755786895751953
Validation loss: 4.368338803450267

Epoch: 5| Step: 4
Training loss: 4.279360294342041
Validation loss: 4.360954771439235

Epoch: 5| Step: 5
Training loss: 4.323807716369629
Validation loss: 4.354027668635051

Epoch: 5| Step: 6
Training loss: 4.311034202575684
Validation loss: 4.348255753517151

Epoch: 5| Step: 7
Training loss: 4.782784461975098
Validation loss: 4.342300266027451

Epoch: 5| Step: 8
Training loss: 4.123662948608398
Validation loss: 4.33566493789355

Epoch: 5| Step: 9
Training loss: 4.775250434875488
Validation loss: 4.328142801920573

Epoch: 5| Step: 10
Training loss: 4.356844902038574
Validation loss: 4.322047332922618

Epoch: 5| Step: 11
Training loss: 4.340259552001953
Validation loss: 4.316364844640096

Epoch: 13| Step: 0
Training loss: 4.952159404754639
Validation loss: 4.308993359406789

Epoch: 5| Step: 1
Training loss: 4.2852888107299805
Validation loss: 4.301531334718068

Epoch: 5| Step: 2
Training loss: 3.8717498779296875
Validation loss: 4.295385996500651

Epoch: 5| Step: 3
Training loss: 5.1523308753967285
Validation loss: 4.290001799662908

Epoch: 5| Step: 4
Training loss: 4.718033790588379
Validation loss: 4.283665438493093

Epoch: 5| Step: 5
Training loss: 4.152271747589111
Validation loss: 4.278073946634929

Epoch: 5| Step: 6
Training loss: 4.765078544616699
Validation loss: 4.271782586971919

Epoch: 5| Step: 7
Training loss: 2.9761996269226074
Validation loss: 4.26573587457339

Epoch: 5| Step: 8
Training loss: 5.279873371124268
Validation loss: 4.260737836360931

Epoch: 5| Step: 9
Training loss: 4.5581254959106445
Validation loss: 4.2540918191274

Epoch: 5| Step: 10
Training loss: 3.5756542682647705
Validation loss: 4.249194175004959

Epoch: 5| Step: 11
Training loss: 5.248004913330078
Validation loss: 4.244480162858963

Epoch: 14| Step: 0
Training loss: 4.596619606018066
Validation loss: 4.239428003629048

Epoch: 5| Step: 1
Training loss: 3.9896750450134277
Validation loss: 4.2333511511484785

Epoch: 5| Step: 2
Training loss: 4.671727657318115
Validation loss: 4.227161606152852

Epoch: 5| Step: 3
Training loss: 3.9454703330993652
Validation loss: 4.221893688042958

Epoch: 5| Step: 4
Training loss: 3.8285446166992188
Validation loss: 4.216717938582103

Epoch: 5| Step: 5
Training loss: 4.884807109832764
Validation loss: 4.212134073177974

Epoch: 5| Step: 6
Training loss: 3.8579559326171875
Validation loss: 4.205158293247223

Epoch: 5| Step: 7
Training loss: 3.6300384998321533
Validation loss: 4.200566867987315

Epoch: 5| Step: 8
Training loss: 4.116545677185059
Validation loss: 4.196349134047826

Epoch: 5| Step: 9
Training loss: 4.9412031173706055
Validation loss: 4.191021124521892

Epoch: 5| Step: 10
Training loss: 5.164973258972168
Validation loss: 4.184792002042134

Epoch: 5| Step: 11
Training loss: 5.129045486450195
Validation loss: 4.178632775942485

Epoch: 15| Step: 0
Training loss: 4.144085884094238
Validation loss: 4.173135608434677

Epoch: 5| Step: 1
Training loss: 4.160564422607422
Validation loss: 4.167922496795654

Epoch: 5| Step: 2
Training loss: 4.2753987312316895
Validation loss: 4.164250403642654

Epoch: 5| Step: 3
Training loss: 3.999265670776367
Validation loss: 4.1571637988090515

Epoch: 5| Step: 4
Training loss: 4.997555732727051
Validation loss: 4.1516808172067

Epoch: 5| Step: 5
Training loss: 3.4601008892059326
Validation loss: 4.147298018137614

Epoch: 5| Step: 6
Training loss: 4.655499458312988
Validation loss: 4.141673823197682

Epoch: 5| Step: 7
Training loss: 4.522316932678223
Validation loss: 4.136579692363739

Epoch: 5| Step: 8
Training loss: 3.92911958694458
Validation loss: 4.131751050551732

Epoch: 5| Step: 9
Training loss: 4.74037504196167
Validation loss: 4.126121799151103

Epoch: 5| Step: 10
Training loss: 3.9233908653259277
Validation loss: 4.1220376789569855

Epoch: 5| Step: 11
Training loss: 5.922599792480469
Validation loss: 4.117351651191711

Epoch: 16| Step: 0
Training loss: 4.280616283416748
Validation loss: 4.111515710751216

Epoch: 5| Step: 1
Training loss: 3.4376251697540283
Validation loss: 4.106113165616989

Epoch: 5| Step: 2
Training loss: 3.130507707595825
Validation loss: 4.100940763950348

Epoch: 5| Step: 3
Training loss: 4.3934807777404785
Validation loss: 4.095927317937215

Epoch: 5| Step: 4
Training loss: 3.8537659645080566
Validation loss: 4.0907599826653795

Epoch: 5| Step: 5
Training loss: 4.881242275238037
Validation loss: 4.084843734900157

Epoch: 5| Step: 6
Training loss: 3.9700636863708496
Validation loss: 4.079898993174235

Epoch: 5| Step: 7
Training loss: 3.880171298980713
Validation loss: 4.076348453760147

Epoch: 5| Step: 8
Training loss: 5.1941704750061035
Validation loss: 4.070024490356445

Epoch: 5| Step: 9
Training loss: 4.470752716064453
Validation loss: 4.0673699875672655

Epoch: 5| Step: 10
Training loss: 4.9269795417785645
Validation loss: 4.063760191202164

Epoch: 5| Step: 11
Training loss: 4.615744590759277
Validation loss: 4.0573849976062775

Epoch: 17| Step: 0
Training loss: 5.513189315795898
Validation loss: 4.051560054222743

Epoch: 5| Step: 1
Training loss: 3.8117785453796387
Validation loss: 4.0458488663037615

Epoch: 5| Step: 2
Training loss: 4.373366832733154
Validation loss: 4.041196336348851

Epoch: 5| Step: 3
Training loss: 4.1080780029296875
Validation loss: 4.0358855326970415

Epoch: 5| Step: 4
Training loss: 4.882260322570801
Validation loss: 4.030697514613469

Epoch: 5| Step: 5
Training loss: 3.0667567253112793
Validation loss: 4.025734265645345

Epoch: 5| Step: 6
Training loss: 4.267632484436035
Validation loss: 4.019871890544891

Epoch: 5| Step: 7
Training loss: 4.064617156982422
Validation loss: 4.015121201674144

Epoch: 5| Step: 8
Training loss: 3.22322154045105
Validation loss: 4.010382721821467

Epoch: 5| Step: 9
Training loss: 4.39495849609375
Validation loss: 4.005257497231166

Epoch: 5| Step: 10
Training loss: 4.097942352294922
Validation loss: 3.999713361263275

Epoch: 5| Step: 11
Training loss: 4.492733478546143
Validation loss: 3.994905094305674

Epoch: 18| Step: 0
Training loss: 4.159495830535889
Validation loss: 3.9897725880146027

Epoch: 5| Step: 1
Training loss: 3.2840957641601562
Validation loss: 3.9847837388515472

Epoch: 5| Step: 2
Training loss: 5.088428497314453
Validation loss: 3.9794165790081024

Epoch: 5| Step: 3
Training loss: 3.93976092338562
Validation loss: 3.9743592043717704

Epoch: 5| Step: 4
Training loss: 4.0987653732299805
Validation loss: 3.9685059189796448

Epoch: 5| Step: 5
Training loss: 4.551259517669678
Validation loss: 3.964080939690272

Epoch: 5| Step: 6
Training loss: 3.8537936210632324
Validation loss: 3.958698113759359

Epoch: 5| Step: 7
Training loss: 4.193283557891846
Validation loss: 3.953166047732035

Epoch: 5| Step: 8
Training loss: 4.824538230895996
Validation loss: 3.947863439718882

Epoch: 5| Step: 9
Training loss: 4.170066833496094
Validation loss: 3.9427513082822165

Epoch: 5| Step: 10
Training loss: 2.9124674797058105
Validation loss: 3.936924785375595

Epoch: 5| Step: 11
Training loss: 4.758213043212891
Validation loss: 3.931268791357676

Epoch: 19| Step: 0
Training loss: 4.092177391052246
Validation loss: 3.925132781267166

Epoch: 5| Step: 1
Training loss: 3.713000774383545
Validation loss: 3.9201702872912088

Epoch: 5| Step: 2
Training loss: 3.6527163982391357
Validation loss: 3.914941966533661

Epoch: 5| Step: 3
Training loss: 3.70344614982605
Validation loss: 3.909402052561442

Epoch: 5| Step: 4
Training loss: 3.8319296836853027
Validation loss: 3.904173860947291

Epoch: 5| Step: 5
Training loss: 5.200572490692139
Validation loss: 3.8987703919410706

Epoch: 5| Step: 6
Training loss: 3.2642688751220703
Validation loss: 3.893296172221502

Epoch: 5| Step: 7
Training loss: 4.709647178649902
Validation loss: 3.888451357682546

Epoch: 5| Step: 8
Training loss: 4.510044574737549
Validation loss: 3.883624573548635

Epoch: 5| Step: 9
Training loss: 4.303292751312256
Validation loss: 3.8781783282756805

Epoch: 5| Step: 10
Training loss: 3.486924648284912
Validation loss: 3.8736669222513833

Epoch: 5| Step: 11
Training loss: 4.281705856323242
Validation loss: 3.8685302138328552

Epoch: 20| Step: 0
Training loss: 4.054364204406738
Validation loss: 3.862857768932978

Epoch: 5| Step: 1
Training loss: 3.7620723247528076
Validation loss: 3.8579578002293906

Epoch: 5| Step: 2
Training loss: 3.626171827316284
Validation loss: 3.8521823585033417

Epoch: 5| Step: 3
Training loss: 4.890066146850586
Validation loss: 3.8472804129123688

Epoch: 5| Step: 4
Training loss: 3.6009459495544434
Validation loss: 3.8421326776345572

Epoch: 5| Step: 5
Training loss: 3.6700470447540283
Validation loss: 3.8379174172878265

Epoch: 5| Step: 6
Training loss: 4.230863094329834
Validation loss: 3.8317933877309165

Epoch: 5| Step: 7
Training loss: 5.1903791427612305
Validation loss: 3.826669583717982

Epoch: 5| Step: 8
Training loss: 3.753696918487549
Validation loss: 3.8218098282814026

Epoch: 5| Step: 9
Training loss: 3.6499381065368652
Validation loss: 3.8168957233428955

Epoch: 5| Step: 10
Training loss: 3.5145440101623535
Validation loss: 3.811883499224981

Epoch: 5| Step: 11
Training loss: 3.649785280227661
Validation loss: 3.806894540786743

Epoch: 21| Step: 0
Training loss: 3.321837902069092
Validation loss: 3.8024337788422904

Epoch: 5| Step: 1
Training loss: 4.660335063934326
Validation loss: 3.796885311603546

Epoch: 5| Step: 2
Training loss: 4.176318168640137
Validation loss: 3.792397985855738

Epoch: 5| Step: 3
Training loss: 3.6258301734924316
Validation loss: 3.7883396645387015

Epoch: 5| Step: 4
Training loss: 3.7369353771209717
Validation loss: 3.7829101582368216

Epoch: 5| Step: 5
Training loss: 3.6114342212677
Validation loss: 3.7779801984628043

Epoch: 5| Step: 6
Training loss: 4.02931022644043
Validation loss: 3.7746796707312265

Epoch: 5| Step: 7
Training loss: 3.0065133571624756
Validation loss: 3.7697981695334115

Epoch: 5| Step: 8
Training loss: 4.774294853210449
Validation loss: 3.76388485232989

Epoch: 5| Step: 9
Training loss: 4.19455623626709
Validation loss: 3.7591033776601157

Epoch: 5| Step: 10
Training loss: 4.305789470672607
Validation loss: 3.7544713616371155

Epoch: 5| Step: 11
Training loss: 3.0136828422546387
Validation loss: 3.750043441851934

Epoch: 22| Step: 0
Training loss: 3.7331714630126953
Validation loss: 3.7448699176311493

Epoch: 5| Step: 1
Training loss: 4.013873100280762
Validation loss: 3.7395535906155906

Epoch: 5| Step: 2
Training loss: 3.465658664703369
Validation loss: 3.7349293927351632

Epoch: 5| Step: 3
Training loss: 5.096134185791016
Validation loss: 3.7301544745763144

Epoch: 5| Step: 4
Training loss: 4.473628997802734
Validation loss: 3.7240917881329856

Epoch: 5| Step: 5
Training loss: 3.7010700702667236
Validation loss: 3.7186912894248962

Epoch: 5| Step: 6
Training loss: 2.9550845623016357
Validation loss: 3.713686376810074

Epoch: 5| Step: 7
Training loss: 3.728527784347534
Validation loss: 3.7121517757574716

Epoch: 5| Step: 8
Training loss: 4.193511962890625
Validation loss: 3.706815997759501

Epoch: 5| Step: 9
Training loss: 3.8971781730651855
Validation loss: 3.7004763782024384

Epoch: 5| Step: 10
Training loss: 3.5983104705810547
Validation loss: 3.6968007683753967

Epoch: 5| Step: 11
Training loss: 3.0775909423828125
Validation loss: 3.693803916374842

Epoch: 23| Step: 0
Training loss: 2.7691402435302734
Validation loss: 3.68755179643631

Epoch: 5| Step: 1
Training loss: 4.364567756652832
Validation loss: 3.6837630371252694

Epoch: 5| Step: 2
Training loss: 3.936443328857422
Validation loss: 3.6799191435178122

Epoch: 5| Step: 3
Training loss: 4.149176597595215
Validation loss: 3.6763482987880707

Epoch: 5| Step: 4
Training loss: 4.096847057342529
Validation loss: 3.671704808870951

Epoch: 5| Step: 5
Training loss: 4.08951997756958
Validation loss: 3.667301972707113

Epoch: 5| Step: 6
Training loss: 2.6769113540649414
Validation loss: 3.6616784731547036

Epoch: 5| Step: 7
Training loss: 4.196260929107666
Validation loss: 3.6567813654740653

Epoch: 5| Step: 8
Training loss: 3.491586208343506
Validation loss: 3.6521435976028442

Epoch: 5| Step: 9
Training loss: 4.340335369110107
Validation loss: 3.6480273604393005

Epoch: 5| Step: 10
Training loss: 3.9919700622558594
Validation loss: 3.643669327100118

Epoch: 5| Step: 11
Training loss: 3.8254811763763428
Validation loss: 3.640242983897527

Epoch: 24| Step: 0
Training loss: 3.384361743927002
Validation loss: 3.6357354124387107

Epoch: 5| Step: 1
Training loss: 4.095232963562012
Validation loss: 3.62925523519516

Epoch: 5| Step: 2
Training loss: 3.515516996383667
Validation loss: 3.625794986883799

Epoch: 5| Step: 3
Training loss: 3.858333110809326
Validation loss: 3.620296140511831

Epoch: 5| Step: 4
Training loss: 3.6516711711883545
Validation loss: 3.6171164512634277

Epoch: 5| Step: 5
Training loss: 3.6117634773254395
Validation loss: 3.613480120897293

Epoch: 5| Step: 6
Training loss: 4.17017936706543
Validation loss: 3.6080899834632874

Epoch: 5| Step: 7
Training loss: 3.8010010719299316
Validation loss: 3.602538247903188

Epoch: 5| Step: 8
Training loss: 3.286015272140503
Validation loss: 3.5990597307682037

Epoch: 5| Step: 9
Training loss: 4.060877323150635
Validation loss: 3.5943674941857657

Epoch: 5| Step: 10
Training loss: 3.781104564666748
Validation loss: 3.589352309703827

Epoch: 5| Step: 11
Training loss: 5.236060619354248
Validation loss: 3.585253268480301

Epoch: 25| Step: 0
Training loss: 3.7420639991760254
Validation loss: 3.5795102020104728

Epoch: 5| Step: 1
Training loss: 3.702085018157959
Validation loss: 3.575480451186498

Epoch: 5| Step: 2
Training loss: 4.3854241371154785
Validation loss: 3.570341020822525

Epoch: 5| Step: 3
Training loss: 4.04351806640625
Validation loss: 3.5652687350908914

Epoch: 5| Step: 4
Training loss: 3.8144683837890625
Validation loss: 3.560909936825434

Epoch: 5| Step: 5
Training loss: 3.812842607498169
Validation loss: 3.5555409292380014

Epoch: 5| Step: 6
Training loss: 3.7566094398498535
Validation loss: 3.55113422870636

Epoch: 5| Step: 7
Training loss: 4.033572196960449
Validation loss: 3.5461971163749695

Epoch: 5| Step: 8
Training loss: 3.0704164505004883
Validation loss: 3.5411452651023865

Epoch: 5| Step: 9
Training loss: 3.483107805252075
Validation loss: 3.536939928929011

Epoch: 5| Step: 10
Training loss: 2.8842520713806152
Validation loss: 3.531774163246155

Epoch: 5| Step: 11
Training loss: 4.761992454528809
Validation loss: 3.5276605784893036

Epoch: 26| Step: 0
Training loss: 3.3995299339294434
Validation loss: 3.522615522146225

Epoch: 5| Step: 1
Training loss: 3.638232469558716
Validation loss: 3.5173850655555725

Epoch: 5| Step: 2
Training loss: 3.846245527267456
Validation loss: 3.512624810139338

Epoch: 5| Step: 3
Training loss: 3.900707244873047
Validation loss: 3.508217066526413

Epoch: 5| Step: 4
Training loss: 3.7175471782684326
Validation loss: 3.502812614043554

Epoch: 5| Step: 5
Training loss: 3.1405434608459473
Validation loss: 3.49817685286204

Epoch: 5| Step: 6
Training loss: 4.510627746582031
Validation loss: 3.493646651506424

Epoch: 5| Step: 7
Training loss: 3.1594066619873047
Validation loss: 3.4890032211939492

Epoch: 5| Step: 8
Training loss: 3.6885688304901123
Validation loss: 3.4852265616257987

Epoch: 5| Step: 9
Training loss: 3.7087173461914062
Validation loss: 3.4793893794218698

Epoch: 5| Step: 10
Training loss: 3.690206527709961
Validation loss: 3.473640243212382

Epoch: 5| Step: 11
Training loss: 3.203220844268799
Validation loss: 3.4695608814557395

Epoch: 27| Step: 0
Training loss: 2.848580837249756
Validation loss: 3.4772044320901236

Epoch: 5| Step: 1
Training loss: 4.3555707931518555
Validation loss: 3.4663299123446145

Epoch: 5| Step: 2
Training loss: 3.370687961578369
Validation loss: 3.4553992251555123

Epoch: 5| Step: 3
Training loss: 3.7183144092559814
Validation loss: 3.449022799730301

Epoch: 5| Step: 4
Training loss: 4.0242600440979
Validation loss: 3.447115878264109

Epoch: 5| Step: 5
Training loss: 3.8384013175964355
Validation loss: 3.4472402234872184

Epoch: 5| Step: 6
Training loss: 3.4631943702697754
Validation loss: 3.438659946123759

Epoch: 5| Step: 7
Training loss: 3.525996685028076
Validation loss: 3.433183401823044

Epoch: 5| Step: 8
Training loss: 3.993056535720825
Validation loss: 3.4329363207022348

Epoch: 5| Step: 9
Training loss: 3.16398549079895
Validation loss: 3.4306666254997253

Epoch: 5| Step: 10
Training loss: 3.5489208698272705
Validation loss: 3.424168288707733

Epoch: 5| Step: 11
Training loss: 2.855384349822998
Validation loss: 3.4148131608963013

Epoch: 28| Step: 0
Training loss: 3.6999740600585938
Validation loss: 3.4088345170021057

Epoch: 5| Step: 1
Training loss: 3.35754132270813
Validation loss: 3.403535415728887

Epoch: 5| Step: 2
Training loss: 3.233060836791992
Validation loss: 3.3992421130339303

Epoch: 5| Step: 3
Training loss: 3.8941280841827393
Validation loss: 3.3960800071557364

Epoch: 5| Step: 4
Training loss: 3.6146836280822754
Validation loss: 3.3911524514357247

Epoch: 5| Step: 5
Training loss: 2.5940775871276855
Validation loss: 3.3872251311937966

Epoch: 5| Step: 6
Training loss: 4.064207553863525
Validation loss: 3.381599575281143

Epoch: 5| Step: 7
Training loss: 4.147008895874023
Validation loss: 3.3778309722741446

Epoch: 5| Step: 8
Training loss: 4.221831321716309
Validation loss: 3.3718802332878113

Epoch: 5| Step: 9
Training loss: 3.3808398246765137
Validation loss: 3.3675105273723602

Epoch: 5| Step: 10
Training loss: 2.669686794281006
Validation loss: 3.362298587958018

Epoch: 5| Step: 11
Training loss: 4.615357875823975
Validation loss: 3.3591232895851135

Epoch: 29| Step: 0
Training loss: 3.4620463848114014
Validation loss: 3.353744904200236

Epoch: 5| Step: 1
Training loss: 3.1637001037597656
Validation loss: 3.349261979262034

Epoch: 5| Step: 2
Training loss: 2.9617919921875
Validation loss: 3.3444681068261466

Epoch: 5| Step: 3
Training loss: 3.289036512374878
Validation loss: 3.340339650710424

Epoch: 5| Step: 4
Training loss: 3.802943468093872
Validation loss: 3.3359636068344116

Epoch: 5| Step: 5
Training loss: 3.1827101707458496
Validation loss: 3.3315280179182687

Epoch: 5| Step: 6
Training loss: 3.7106235027313232
Validation loss: 3.3270558416843414

Epoch: 5| Step: 7
Training loss: 3.630340576171875
Validation loss: 3.323137958844503

Epoch: 5| Step: 8
Training loss: 3.9799981117248535
Validation loss: 3.3180386622746787

Epoch: 5| Step: 9
Training loss: 3.8996944427490234
Validation loss: 3.313773681720098

Epoch: 5| Step: 10
Training loss: 3.3508830070495605
Validation loss: 3.3089007437229156

Epoch: 5| Step: 11
Training loss: 3.9271411895751953
Validation loss: 3.304985831181208

Epoch: 30| Step: 0
Training loss: 3.2086663246154785
Validation loss: 3.3006194035212197

Epoch: 5| Step: 1
Training loss: 3.284987688064575
Validation loss: 3.2953497568766275

Epoch: 5| Step: 2
Training loss: 3.9442856311798096
Validation loss: 3.291970749696096

Epoch: 5| Step: 3
Training loss: 3.5761947631835938
Validation loss: 3.2882892787456512

Epoch: 5| Step: 4
Training loss: 3.060028314590454
Validation loss: 3.2829390863577523

Epoch: 5| Step: 5
Training loss: 3.5296452045440674
Validation loss: 3.2803427378336587

Epoch: 5| Step: 6
Training loss: 3.2708001136779785
Validation loss: 3.2743686040242515

Epoch: 5| Step: 7
Training loss: 3.785524845123291
Validation loss: 3.2702447275320687

Epoch: 5| Step: 8
Training loss: 3.0911190509796143
Validation loss: 3.266460418701172

Epoch: 5| Step: 9
Training loss: 4.5862321853637695
Validation loss: 3.2619404594103494

Epoch: 5| Step: 10
Training loss: 2.821495532989502
Validation loss: 3.258552591005961

Epoch: 5| Step: 11
Training loss: 2.6430842876434326
Validation loss: 3.254204958677292

Epoch: 31| Step: 0
Training loss: 4.302427291870117
Validation loss: 3.249538133541743

Epoch: 5| Step: 1
Training loss: 2.481027841567993
Validation loss: 3.246718148390452

Epoch: 5| Step: 2
Training loss: 3.9447898864746094
Validation loss: 3.2423604925473533

Epoch: 5| Step: 3
Training loss: 3.1237621307373047
Validation loss: 3.238633245229721

Epoch: 5| Step: 4
Training loss: 3.7432150840759277
Validation loss: 3.2345998883247375

Epoch: 5| Step: 5
Training loss: 2.860665798187256
Validation loss: 3.230811725060145

Epoch: 5| Step: 6
Training loss: 3.1024537086486816
Validation loss: 3.2264598508675895

Epoch: 5| Step: 7
Training loss: 2.7743587493896484
Validation loss: 3.2234897216161094

Epoch: 5| Step: 8
Training loss: 3.445565700531006
Validation loss: 3.2208858728408813

Epoch: 5| Step: 9
Training loss: 3.0072360038757324
Validation loss: 3.2151485085487366

Epoch: 5| Step: 10
Training loss: 4.668800354003906
Validation loss: 3.211510350306829

Epoch: 5| Step: 11
Training loss: 3.565439224243164
Validation loss: 3.2079322040081024

Epoch: 32| Step: 0
Training loss: 3.7210001945495605
Validation loss: 3.2048375805219016

Epoch: 5| Step: 1
Training loss: 4.20961856842041
Validation loss: 3.2019968132177987

Epoch: 5| Step: 2
Training loss: 3.884716033935547
Validation loss: 3.1985333363215127

Epoch: 5| Step: 3
Training loss: 4.061200141906738
Validation loss: 3.1946501235167184

Epoch: 5| Step: 4
Training loss: 2.814493179321289
Validation loss: 3.190431962410609

Epoch: 5| Step: 5
Training loss: 3.1436328887939453
Validation loss: 3.1860718031724296

Epoch: 5| Step: 6
Training loss: 2.8715672492980957
Validation loss: 3.1821138163407645

Epoch: 5| Step: 7
Training loss: 3.0973095893859863
Validation loss: 3.1790332595507302

Epoch: 5| Step: 8
Training loss: 3.123337745666504
Validation loss: 3.176458259423574

Epoch: 5| Step: 9
Training loss: 3.7092220783233643
Validation loss: 3.178337742884954

Epoch: 5| Step: 10
Training loss: 2.557091474533081
Validation loss: 3.1742411851882935

Epoch: 5| Step: 11
Training loss: 2.676191568374634
Validation loss: 3.1683459679285684

Epoch: 33| Step: 0
Training loss: 3.585941791534424
Validation loss: 3.161489556233088

Epoch: 5| Step: 1
Training loss: 3.348254680633545
Validation loss: 3.1570069591204324

Epoch: 5| Step: 2
Training loss: 3.674041748046875
Validation loss: 3.1541225711504617

Epoch: 5| Step: 3
Training loss: 3.282463550567627
Validation loss: 3.1521825989087424

Epoch: 5| Step: 4
Training loss: 3.4871935844421387
Validation loss: 3.1517840325832367

Epoch: 5| Step: 5
Training loss: 3.0004148483276367
Validation loss: 3.1453235844771066

Epoch: 5| Step: 6
Training loss: 2.6695473194122314
Validation loss: 3.1421817243099213

Epoch: 5| Step: 7
Training loss: 3.0257725715637207
Validation loss: 3.137069175640742

Epoch: 5| Step: 8
Training loss: 3.3344473838806152
Validation loss: 3.1319037477175393

Epoch: 5| Step: 9
Training loss: 3.182440996170044
Validation loss: 3.128338207801183

Epoch: 5| Step: 10
Training loss: 3.7781481742858887
Validation loss: 3.1243264178435006

Epoch: 5| Step: 11
Training loss: 4.613051414489746
Validation loss: 3.120081971089045

Epoch: 34| Step: 0
Training loss: 3.961531162261963
Validation loss: 3.1166545252005258

Epoch: 5| Step: 1
Training loss: 2.9220664501190186
Validation loss: 3.1130809485912323

Epoch: 5| Step: 2
Training loss: 3.025190591812134
Validation loss: 3.109458267688751

Epoch: 5| Step: 3
Training loss: 2.1954550743103027
Validation loss: 3.105326473712921

Epoch: 5| Step: 4
Training loss: 2.83821439743042
Validation loss: 3.100994964440664

Epoch: 5| Step: 5
Training loss: 3.6454148292541504
Validation loss: 3.0979665021101632

Epoch: 5| Step: 6
Training loss: 2.9031569957733154
Validation loss: 3.0947023828824363

Epoch: 5| Step: 7
Training loss: 2.945000171661377
Validation loss: 3.0913680096467337

Epoch: 5| Step: 8
Training loss: 3.986731767654419
Validation loss: 3.087859799464544

Epoch: 5| Step: 9
Training loss: 3.724695920944214
Validation loss: 3.08449458082517

Epoch: 5| Step: 10
Training loss: 4.068671226501465
Validation loss: 3.0810378789901733

Epoch: 5| Step: 11
Training loss: 3.0301692485809326
Validation loss: 3.0778540869553885

Epoch: 35| Step: 0
Training loss: 3.3542656898498535
Validation loss: 3.0744787553946176

Epoch: 5| Step: 1
Training loss: 3.0257039070129395
Validation loss: 3.0713364481925964

Epoch: 5| Step: 2
Training loss: 3.4224212169647217
Validation loss: 3.0694197018941245

Epoch: 5| Step: 3
Training loss: 3.3130288124084473
Validation loss: 3.068620224793752

Epoch: 5| Step: 4
Training loss: 3.5647544860839844
Validation loss: 3.0635938942432404

Epoch: 5| Step: 5
Training loss: 2.7385661602020264
Validation loss: 3.059613605340322

Epoch: 5| Step: 6
Training loss: 3.1426265239715576
Validation loss: 3.0554918348789215

Epoch: 5| Step: 7
Training loss: 3.866527557373047
Validation loss: 3.052323410908381

Epoch: 5| Step: 8
Training loss: 2.9387736320495605
Validation loss: 3.0488407413164773

Epoch: 5| Step: 9
Training loss: 3.2924675941467285
Validation loss: 3.045799603064855

Epoch: 5| Step: 10
Training loss: 3.2046523094177246
Validation loss: 3.041906068722407

Epoch: 5| Step: 11
Training loss: 2.5111348628997803
Validation loss: 3.039291183153788

Epoch: 36| Step: 0
Training loss: 3.2147419452667236
Validation loss: 3.0354530215263367

Epoch: 5| Step: 1
Training loss: 2.8614723682403564
Validation loss: 3.032161275545756

Epoch: 5| Step: 2
Training loss: 3.095111131668091
Validation loss: 3.02903683980306

Epoch: 5| Step: 3
Training loss: 3.8354220390319824
Validation loss: 3.025337745745977

Epoch: 5| Step: 4
Training loss: 3.9483489990234375
Validation loss: 3.0224352180957794

Epoch: 5| Step: 5
Training loss: 2.571188449859619
Validation loss: 3.0188847382863364

Epoch: 5| Step: 6
Training loss: 3.0833656787872314
Validation loss: 3.015576332807541

Epoch: 5| Step: 7
Training loss: 3.081839084625244
Validation loss: 3.0123799045880637

Epoch: 5| Step: 8
Training loss: 3.4048538208007812
Validation loss: 3.0089476009209952

Epoch: 5| Step: 9
Training loss: 3.823625087738037
Validation loss: 3.0056696037451425

Epoch: 5| Step: 10
Training loss: 2.80712628364563
Validation loss: 3.003439098596573

Epoch: 5| Step: 11
Training loss: 1.1183992624282837
Validation loss: 3.0020058949788413

Epoch: 37| Step: 0
Training loss: 3.152230739593506
Validation loss: 3.0002019703388214

Epoch: 5| Step: 1
Training loss: 4.037313938140869
Validation loss: 2.999580591917038

Epoch: 5| Step: 2
Training loss: 2.207918643951416
Validation loss: 3.002262622117996

Epoch: 5| Step: 3
Training loss: 3.817037582397461
Validation loss: 3.0001815458138785

Epoch: 5| Step: 4
Training loss: 3.112037181854248
Validation loss: 2.9852402806282043

Epoch: 5| Step: 5
Training loss: 2.568006992340088
Validation loss: 2.98090723156929

Epoch: 5| Step: 6
Training loss: 2.365199089050293
Validation loss: 2.9787025849024453

Epoch: 5| Step: 7
Training loss: 2.442187786102295
Validation loss: 2.977813353141149

Epoch: 5| Step: 8
Training loss: 3.687432050704956
Validation loss: 2.9764895935853324

Epoch: 5| Step: 9
Training loss: 3.974729061126709
Validation loss: 2.976023664077123

Epoch: 5| Step: 10
Training loss: 3.4440860748291016
Validation loss: 2.970472494761149

Epoch: 5| Step: 11
Training loss: 3.7534635066986084
Validation loss: 2.967559595902761

Epoch: 38| Step: 0
Training loss: 3.215428113937378
Validation loss: 2.9637567897637687

Epoch: 5| Step: 1
Training loss: 3.667285203933716
Validation loss: 2.9606797297795615

Epoch: 5| Step: 2
Training loss: 3.125056505203247
Validation loss: 2.9569746553897858

Epoch: 5| Step: 3
Training loss: 2.5023856163024902
Validation loss: 2.9550390044848123

Epoch: 5| Step: 4
Training loss: 3.1633543968200684
Validation loss: 2.9563209315141044

Epoch: 5| Step: 5
Training loss: 2.7600741386413574
Validation loss: 2.954303115606308

Epoch: 5| Step: 6
Training loss: 3.6955113410949707
Validation loss: 2.9456081489721933

Epoch: 5| Step: 7
Training loss: 2.949044704437256
Validation loss: 2.9392922719319663

Epoch: 5| Step: 8
Training loss: 3.5398011207580566
Validation loss: 2.9358010987440744

Epoch: 5| Step: 9
Training loss: 2.897181272506714
Validation loss: 2.9333644807338715

Epoch: 5| Step: 10
Training loss: 2.8794350624084473
Validation loss: 2.9309860368569693

Epoch: 5| Step: 11
Training loss: 4.254226207733154
Validation loss: 2.929560959339142

Epoch: 39| Step: 0
Training loss: 3.67578125
Validation loss: 2.9246268967787423

Epoch: 5| Step: 1
Training loss: 3.398155927658081
Validation loss: 2.9197708467642465

Epoch: 5| Step: 2
Training loss: 2.958449125289917
Validation loss: 2.9152490496635437

Epoch: 5| Step: 3
Training loss: 2.4877049922943115
Validation loss: 2.911702811717987

Epoch: 5| Step: 4
Training loss: 3.9163780212402344
Validation loss: 2.9078554610411325

Epoch: 5| Step: 5
Training loss: 2.809436321258545
Validation loss: 2.9041130344072976

Epoch: 5| Step: 6
Training loss: 2.4870688915252686
Validation loss: 2.899395634730657

Epoch: 5| Step: 7
Training loss: 2.587721824645996
Validation loss: 2.8966245154539743

Epoch: 5| Step: 8
Training loss: 2.8854217529296875
Validation loss: 2.894547084967295

Epoch: 5| Step: 9
Training loss: 3.0269064903259277
Validation loss: 2.8922411302725473

Epoch: 5| Step: 10
Training loss: 3.9861748218536377
Validation loss: 2.890958825747172

Epoch: 5| Step: 11
Training loss: 2.9948554039001465
Validation loss: 2.886401653289795

Epoch: 40| Step: 0
Training loss: 3.4842820167541504
Validation loss: 2.909262736638387

Epoch: 5| Step: 1
Training loss: 3.9112815856933594
Validation loss: 2.8902317583560944

Epoch: 5| Step: 2
Training loss: 2.4293339252471924
Validation loss: 2.8745286663373313

Epoch: 5| Step: 3
Training loss: 3.5082061290740967
Validation loss: 2.8711556792259216

Epoch: 5| Step: 4
Training loss: 3.1944196224212646
Validation loss: 2.869650512933731

Epoch: 5| Step: 5
Training loss: 2.958864688873291
Validation loss: 2.8675414820512137

Epoch: 5| Step: 6
Training loss: 3.0724215507507324
Validation loss: 2.867195705572764

Epoch: 5| Step: 7
Training loss: 3.093635082244873
Validation loss: 2.8646664718786874

Epoch: 5| Step: 8
Training loss: 3.17602276802063
Validation loss: 2.8620649774869285

Epoch: 5| Step: 9
Training loss: 2.361602783203125
Validation loss: 2.856826603412628

Epoch: 5| Step: 10
Training loss: 3.0476603507995605
Validation loss: 2.8531321982542672

Epoch: 5| Step: 11
Training loss: 1.3282344341278076
Validation loss: 2.851385861635208

Epoch: 41| Step: 0
Training loss: 3.023247003555298
Validation loss: 2.850417544444402

Epoch: 5| Step: 1
Training loss: 3.173539638519287
Validation loss: 2.852447032928467

Epoch: 5| Step: 2
Training loss: 3.4078993797302246
Validation loss: 2.8539139330387115

Epoch: 5| Step: 3
Training loss: 2.7654480934143066
Validation loss: 2.8490527073542276

Epoch: 5| Step: 4
Training loss: 2.7961578369140625
Validation loss: 2.844858984152476

Epoch: 5| Step: 5
Training loss: 3.0277259349823
Validation loss: 2.8361600935459137

Epoch: 5| Step: 6
Training loss: 2.9600746631622314
Validation loss: 2.8333317836125693

Epoch: 5| Step: 7
Training loss: 3.455770969390869
Validation loss: 2.8310880064964294

Epoch: 5| Step: 8
Training loss: 3.83439302444458
Validation loss: 2.8285594383875527

Epoch: 5| Step: 9
Training loss: 2.4141829013824463
Validation loss: 2.825049618879954

Epoch: 5| Step: 10
Training loss: 2.79604172706604
Validation loss: 2.8227569659550986

Epoch: 5| Step: 11
Training loss: 2.1197733879089355
Validation loss: 2.822477161884308

Epoch: 42| Step: 0
Training loss: 2.2230324745178223
Validation loss: 2.821694831053416

Epoch: 5| Step: 1
Training loss: 3.5075221061706543
Validation loss: 2.8285086999336877

Epoch: 5| Step: 2
Training loss: 3.3543906211853027
Validation loss: 2.8309839963912964

Epoch: 5| Step: 3
Training loss: 2.925516366958618
Validation loss: 2.81144388516744

Epoch: 5| Step: 4
Training loss: 3.1958580017089844
Validation loss: 2.8098368545373282

Epoch: 5| Step: 5
Training loss: 2.811474323272705
Validation loss: 2.811594525973002

Epoch: 5| Step: 6
Training loss: 3.149930477142334
Validation loss: 2.813764919837316

Epoch: 5| Step: 7
Training loss: 3.0183682441711426
Validation loss: 2.80589160323143

Epoch: 5| Step: 8
Training loss: 3.117896318435669
Validation loss: 2.803915490706762

Epoch: 5| Step: 9
Training loss: 3.1671979427337646
Validation loss: 2.8008148968219757

Epoch: 5| Step: 10
Training loss: 2.8114707469940186
Validation loss: 2.797643005847931

Epoch: 5| Step: 11
Training loss: 2.946803092956543
Validation loss: 2.792571028073629

Epoch: 43| Step: 0
Training loss: 2.888110637664795
Validation loss: 2.7888991932074227

Epoch: 5| Step: 1
Training loss: 3.162646770477295
Validation loss: 2.785722484191259

Epoch: 5| Step: 2
Training loss: 2.078477382659912
Validation loss: 2.783080259958903

Epoch: 5| Step: 3
Training loss: 2.8964734077453613
Validation loss: 2.7808279991149902

Epoch: 5| Step: 4
Training loss: 2.330183506011963
Validation loss: 2.777530938386917

Epoch: 5| Step: 5
Training loss: 3.1864562034606934
Validation loss: 2.7779743671417236

Epoch: 5| Step: 6
Training loss: 2.7335753440856934
Validation loss: 2.77598429719607

Epoch: 5| Step: 7
Training loss: 3.0356690883636475
Validation loss: 2.7703315913677216

Epoch: 5| Step: 8
Training loss: 3.413236141204834
Validation loss: 2.768377145131429

Epoch: 5| Step: 9
Training loss: 3.3087196350097656
Validation loss: 2.767083098491033

Epoch: 5| Step: 10
Training loss: 3.6046783924102783
Validation loss: 2.770182321468989

Epoch: 5| Step: 11
Training loss: 3.8239800930023193
Validation loss: 2.7594289084275565

Epoch: 44| Step: 0
Training loss: 2.9533228874206543
Validation loss: 2.7884450554847717

Epoch: 5| Step: 1
Training loss: 3.404169797897339
Validation loss: 2.757494181394577

Epoch: 5| Step: 2
Training loss: 2.691035747528076
Validation loss: 2.7505997021993003

Epoch: 5| Step: 3
Training loss: 2.6644484996795654
Validation loss: 2.749521424372991

Epoch: 5| Step: 4
Training loss: 3.019648551940918
Validation loss: 2.746057669321696

Epoch: 5| Step: 5
Training loss: 2.585540294647217
Validation loss: 2.744767208894094

Epoch: 5| Step: 6
Training loss: 2.6337668895721436
Validation loss: 2.7430751025676727

Epoch: 5| Step: 7
Training loss: 3.5791335105895996
Validation loss: 2.7431221902370453

Epoch: 5| Step: 8
Training loss: 3.2726337909698486
Validation loss: 2.744067887465159

Epoch: 5| Step: 9
Training loss: 2.636122226715088
Validation loss: 2.7413267393906913

Epoch: 5| Step: 10
Training loss: 3.036839246749878
Validation loss: 2.7358248233795166

Epoch: 5| Step: 11
Training loss: 3.0375843048095703
Validation loss: 2.736609677473704

Epoch: 45| Step: 0
Training loss: 3.4827466011047363
Validation loss: 2.7339195013046265

Epoch: 5| Step: 1
Training loss: 3.305569887161255
Validation loss: 2.7294883529345193

Epoch: 5| Step: 2
Training loss: 3.144066333770752
Validation loss: 2.725414276123047

Epoch: 5| Step: 3
Training loss: 3.0071558952331543
Validation loss: 2.7221622665723166

Epoch: 5| Step: 4
Training loss: 2.445242404937744
Validation loss: 2.7183574934800467

Epoch: 5| Step: 5
Training loss: 3.1533360481262207
Validation loss: 2.7147231797377267

Epoch: 5| Step: 6
Training loss: 2.909999132156372
Validation loss: 2.7112879355748496

Epoch: 5| Step: 7
Training loss: 2.80320405960083
Validation loss: 2.7071102460225425

Epoch: 5| Step: 8
Training loss: 2.4458885192871094
Validation loss: 2.704904536406199

Epoch: 5| Step: 9
Training loss: 2.9110896587371826
Validation loss: 2.701657404502233

Epoch: 5| Step: 10
Training loss: 2.7382054328918457
Validation loss: 2.6982025802135468

Epoch: 5| Step: 11
Training loss: 1.92091965675354
Validation loss: 2.694769303003947

Epoch: 46| Step: 0
Training loss: 3.0323681831359863
Validation loss: 2.6929557720820108

Epoch: 5| Step: 1
Training loss: 2.9220640659332275
Validation loss: 2.688869913419088

Epoch: 5| Step: 2
Training loss: 2.5989537239074707
Validation loss: 2.68590314189593

Epoch: 5| Step: 3
Training loss: 3.1143381595611572
Validation loss: 2.6829411884148917

Epoch: 5| Step: 4
Training loss: 3.518644332885742
Validation loss: 2.683403660853704

Epoch: 5| Step: 5
Training loss: 2.495548725128174
Validation loss: 2.6801038086414337

Epoch: 5| Step: 6
Training loss: 2.4252495765686035
Validation loss: 2.6763287782669067

Epoch: 5| Step: 7
Training loss: 2.773879051208496
Validation loss: 2.674785335858663

Epoch: 5| Step: 8
Training loss: 3.277418613433838
Validation loss: 2.6712056696414948

Epoch: 5| Step: 9
Training loss: 2.9924609661102295
Validation loss: 2.674365073442459

Epoch: 5| Step: 10
Training loss: 2.6966192722320557
Validation loss: 2.6726972460746765

Epoch: 5| Step: 11
Training loss: 2.2576355934143066
Validation loss: 2.6735786497592926

Epoch: 47| Step: 0
Training loss: 2.4757895469665527
Validation loss: 2.6742063462734222

Epoch: 5| Step: 1
Training loss: 2.9093544483184814
Validation loss: 2.6585985322793326

Epoch: 5| Step: 2
Training loss: 2.9249565601348877
Validation loss: 2.653598795334498

Epoch: 5| Step: 3
Training loss: 2.3678722381591797
Validation loss: 2.649739235639572

Epoch: 5| Step: 4
Training loss: 2.3615596294403076
Validation loss: 2.648837069670359

Epoch: 5| Step: 5
Training loss: 3.1980128288269043
Validation loss: 2.647573322057724

Epoch: 5| Step: 6
Training loss: 2.0765767097473145
Validation loss: 2.645190437634786

Epoch: 5| Step: 7
Training loss: 3.249082088470459
Validation loss: 2.6439972519874573

Epoch: 5| Step: 8
Training loss: 3.3398807048797607
Validation loss: 2.6422252158323922

Epoch: 5| Step: 9
Training loss: 2.7202138900756836
Validation loss: 2.6403907934824624

Epoch: 5| Step: 10
Training loss: 3.6956710815429688
Validation loss: 2.639649912714958

Epoch: 5| Step: 11
Training loss: 3.1541788578033447
Validation loss: 2.6363360782464347

Epoch: 48| Step: 0
Training loss: 2.736994743347168
Validation loss: 2.6327970822652182

Epoch: 5| Step: 1
Training loss: 3.1265625953674316
Validation loss: 2.6291149258613586

Epoch: 5| Step: 2
Training loss: 2.604898452758789
Validation loss: 2.623709132273992

Epoch: 5| Step: 3
Training loss: 1.987862229347229
Validation loss: 2.6215546429157257

Epoch: 5| Step: 4
Training loss: 3.278902530670166
Validation loss: 2.618267943461736

Epoch: 5| Step: 5
Training loss: 2.6822381019592285
Validation loss: 2.6142976780732474

Epoch: 5| Step: 6
Training loss: 2.6755611896514893
Validation loss: 2.6123234629631042

Epoch: 5| Step: 7
Training loss: 3.109431743621826
Validation loss: 2.609934384624163

Epoch: 5| Step: 8
Training loss: 3.488147258758545
Validation loss: 2.6091175079345703

Epoch: 5| Step: 9
Training loss: 2.1792874336242676
Validation loss: 2.606459687153498

Epoch: 5| Step: 10
Training loss: 3.11491060256958
Validation loss: 2.6043932735919952

Epoch: 5| Step: 11
Training loss: 2.905005931854248
Validation loss: 2.5993001659711203

Epoch: 49| Step: 0
Training loss: 2.9510951042175293
Validation loss: 2.5955977042516074

Epoch: 5| Step: 1
Training loss: 2.7837955951690674
Validation loss: 2.5945344467957816

Epoch: 5| Step: 2
Training loss: 2.977116823196411
Validation loss: 2.5953105886777244

Epoch: 5| Step: 3
Training loss: 3.1023573875427246
Validation loss: 2.5909492671489716

Epoch: 5| Step: 4
Training loss: 2.6993892192840576
Validation loss: 2.5887520213921866

Epoch: 5| Step: 5
Training loss: 2.769806385040283
Validation loss: 2.5846521159013114

Epoch: 5| Step: 6
Training loss: 2.467550039291382
Validation loss: 2.581090231736501

Epoch: 5| Step: 7
Training loss: 3.0092129707336426
Validation loss: 2.57888396581014

Epoch: 5| Step: 8
Training loss: 2.809091567993164
Validation loss: 2.5780177414417267

Epoch: 5| Step: 9
Training loss: 2.776618242263794
Validation loss: 2.573351263999939

Epoch: 5| Step: 10
Training loss: 2.5453732013702393
Validation loss: 2.571964353322983

Epoch: 5| Step: 11
Training loss: 1.5117709636688232
Validation loss: 2.570339173078537

Epoch: 50| Step: 0
Training loss: 3.08793306350708
Validation loss: 2.568236460288366

Epoch: 5| Step: 1
Training loss: 2.436598300933838
Validation loss: 2.5684288442134857

Epoch: 5| Step: 2
Training loss: 2.9211106300354004
Validation loss: 2.5658080776532493

Epoch: 5| Step: 3
Training loss: 2.219499111175537
Validation loss: 2.561003784338633

Epoch: 5| Step: 4
Training loss: 2.4742023944854736
Validation loss: 2.5598283608754477

Epoch: 5| Step: 5
Training loss: 2.805685043334961
Validation loss: 2.5591944456100464

Epoch: 5| Step: 6
Training loss: 3.0159389972686768
Validation loss: 2.5568720599015555

Epoch: 5| Step: 7
Training loss: 2.895246982574463
Validation loss: 2.5586802462736764

Epoch: 5| Step: 8
Training loss: 2.5013365745544434
Validation loss: 2.555495192607244

Epoch: 5| Step: 9
Training loss: 2.9715185165405273
Validation loss: 2.5528783897558847

Epoch: 5| Step: 10
Training loss: 2.9900217056274414
Validation loss: 2.5456051528453827

Epoch: 5| Step: 11
Training loss: 2.844135284423828
Validation loss: 2.5445211033026376

Epoch: 51| Step: 0
Training loss: 1.9732269048690796
Validation loss: 2.557640631993612

Epoch: 5| Step: 1
Training loss: 2.755948305130005
Validation loss: 2.571811298529307

Epoch: 5| Step: 2
Training loss: 2.6140263080596924
Validation loss: 2.559897134701411

Epoch: 5| Step: 3
Training loss: 3.021879196166992
Validation loss: 2.539239635070165

Epoch: 5| Step: 4
Training loss: 2.7784676551818848
Validation loss: 2.53345450758934

Epoch: 5| Step: 5
Training loss: 2.5569913387298584
Validation loss: 2.535270075003306

Epoch: 5| Step: 6
Training loss: 2.647130250930786
Validation loss: 2.5395843982696533

Epoch: 5| Step: 7
Training loss: 2.811818838119507
Validation loss: 2.5423750380674996

Epoch: 5| Step: 8
Training loss: 3.0570106506347656
Validation loss: 2.545591026544571

Epoch: 5| Step: 9
Training loss: 3.2986767292022705
Validation loss: 2.5389151871204376

Epoch: 5| Step: 10
Training loss: 2.8000686168670654
Validation loss: 2.533960690100988

Epoch: 5| Step: 11
Training loss: 1.612870693206787
Validation loss: 2.5288775265216827

Epoch: 52| Step: 0
Training loss: 2.426023483276367
Validation loss: 2.5249239106973014

Epoch: 5| Step: 1
Training loss: 2.77099609375
Validation loss: 2.5225743452707925

Epoch: 5| Step: 2
Training loss: 2.1107020378112793
Validation loss: 2.5157562494277954

Epoch: 5| Step: 3
Training loss: 2.8381662368774414
Validation loss: 2.512919227282206

Epoch: 5| Step: 4
Training loss: 2.9488635063171387
Validation loss: 2.5113991796970367

Epoch: 5| Step: 5
Training loss: 2.796339511871338
Validation loss: 2.509099225203196

Epoch: 5| Step: 6
Training loss: 2.952789068222046
Validation loss: 2.504202296336492

Epoch: 5| Step: 7
Training loss: 2.6494081020355225
Validation loss: 2.501682758331299

Epoch: 5| Step: 8
Training loss: 3.1323964595794678
Validation loss: 2.500701983769735

Epoch: 5| Step: 9
Training loss: 2.6210830211639404
Validation loss: 2.4959113399187722

Epoch: 5| Step: 10
Training loss: 2.325841188430786
Validation loss: 2.493972818056742

Epoch: 5| Step: 11
Training loss: 3.3504068851470947
Validation loss: 2.489843169848124

Epoch: 53| Step: 0
Training loss: 2.990727663040161
Validation loss: 2.488224764664968

Epoch: 5| Step: 1
Training loss: 2.703794002532959
Validation loss: 2.4868703186511993

Epoch: 5| Step: 2
Training loss: 2.6114747524261475
Validation loss: 2.4868761897087097

Epoch: 5| Step: 3
Training loss: 1.9872963428497314
Validation loss: 2.482036610444387

Epoch: 5| Step: 4
Training loss: 2.8553545475006104
Validation loss: 2.478372206290563

Epoch: 5| Step: 5
Training loss: 2.6608004570007324
Validation loss: 2.4763096968332925

Epoch: 5| Step: 6
Training loss: 2.207667827606201
Validation loss: 2.4742630422115326

Epoch: 5| Step: 7
Training loss: 2.8221583366394043
Validation loss: 2.4700390299161277

Epoch: 5| Step: 8
Training loss: 3.0364315509796143
Validation loss: 2.466070741415024

Epoch: 5| Step: 9
Training loss: 2.632000207901001
Validation loss: 2.4667921662330627

Epoch: 5| Step: 10
Training loss: 2.843924045562744
Validation loss: 2.4633856813112893

Epoch: 5| Step: 11
Training loss: 2.6014294624328613
Validation loss: 2.4615126649538674

Epoch: 54| Step: 0
Training loss: 2.5269546508789062
Validation loss: 2.4600509901841483

Epoch: 5| Step: 1
Training loss: 2.5568361282348633
Validation loss: 2.4562729001045227

Epoch: 5| Step: 2
Training loss: 2.146631956100464
Validation loss: 2.457069863875707

Epoch: 5| Step: 3
Training loss: 2.5027127265930176
Validation loss: 2.4516153037548065

Epoch: 5| Step: 4
Training loss: 2.7506392002105713
Validation loss: 2.4497295220692954

Epoch: 5| Step: 5
Training loss: 2.4697420597076416
Validation loss: 2.4458967049916587

Epoch: 5| Step: 6
Training loss: 2.722799777984619
Validation loss: 2.4450999101003013

Epoch: 5| Step: 7
Training loss: 3.006970167160034
Validation loss: 2.4430899620056152

Epoch: 5| Step: 8
Training loss: 2.720040798187256
Validation loss: 2.4424586991469064

Epoch: 5| Step: 9
Training loss: 2.780425548553467
Validation loss: 2.442450314760208

Epoch: 5| Step: 10
Training loss: 2.63731050491333
Validation loss: 2.434769948323568

Epoch: 5| Step: 11
Training loss: 3.4210405349731445
Validation loss: 2.43683552245299

Epoch: 55| Step: 0
Training loss: 2.541442394256592
Validation loss: 2.433048665523529

Epoch: 5| Step: 1
Training loss: 3.2990546226501465
Validation loss: 2.4299762348333993

Epoch: 5| Step: 2
Training loss: 2.423917531967163
Validation loss: 2.428665111462275

Epoch: 5| Step: 3
Training loss: 2.6741061210632324
Validation loss: 2.4254874934752784

Epoch: 5| Step: 4
Training loss: 2.561758041381836
Validation loss: 2.422146071990331

Epoch: 5| Step: 5
Training loss: 2.374080181121826
Validation loss: 2.417954459786415

Epoch: 5| Step: 6
Training loss: 2.743495225906372
Validation loss: 2.4187020460764566

Epoch: 5| Step: 7
Training loss: 2.692512035369873
Validation loss: 2.4177808860937753

Epoch: 5| Step: 8
Training loss: 2.358825206756592
Validation loss: 2.411362946033478

Epoch: 5| Step: 9
Training loss: 2.181358575820923
Validation loss: 2.4156226217746735

Epoch: 5| Step: 10
Training loss: 2.908625841140747
Validation loss: 2.4076984971761703

Epoch: 5| Step: 11
Training loss: 1.740280032157898
Validation loss: 2.407287081082662

Epoch: 56| Step: 0
Training loss: 2.3231053352355957
Validation loss: 2.415047516425451

Epoch: 5| Step: 1
Training loss: 2.6552553176879883
Validation loss: 2.4244289795557656

Epoch: 5| Step: 2
Training loss: 2.5778985023498535
Validation loss: 2.417035683989525

Epoch: 5| Step: 3
Training loss: 3.095853805541992
Validation loss: 2.401782274246216

Epoch: 5| Step: 4
Training loss: 2.15687894821167
Validation loss: 2.396133894721667

Epoch: 5| Step: 5
Training loss: 2.609495162963867
Validation loss: 2.395765711863836

Epoch: 5| Step: 6
Training loss: 2.4849321842193604
Validation loss: 2.3935980200767517

Epoch: 5| Step: 7
Training loss: 2.643350124359131
Validation loss: 2.3924190998077393

Epoch: 5| Step: 8
Training loss: 2.0899124145507812
Validation loss: 2.3880951205889382

Epoch: 5| Step: 9
Training loss: 2.9653525352478027
Validation loss: 2.3874705036481223

Epoch: 5| Step: 10
Training loss: 2.994488000869751
Validation loss: 2.3866261889537177

Epoch: 5| Step: 11
Training loss: 1.1761424541473389
Validation loss: 2.3854176700115204

Epoch: 57| Step: 0
Training loss: 2.7429800033569336
Validation loss: 2.383965700864792

Epoch: 5| Step: 1
Training loss: 2.654902696609497
Validation loss: 2.3824475506941476

Epoch: 5| Step: 2
Training loss: 2.5094432830810547
Validation loss: 2.381022185087204

Epoch: 5| Step: 3
Training loss: 2.336456298828125
Validation loss: 2.377674619356791

Epoch: 5| Step: 4
Training loss: 3.3886349201202393
Validation loss: 2.3767721752325692

Epoch: 5| Step: 5
Training loss: 2.13433837890625
Validation loss: 2.374251345793406

Epoch: 5| Step: 6
Training loss: 2.8901209831237793
Validation loss: 2.370360324780146

Epoch: 5| Step: 7
Training loss: 2.5493667125701904
Validation loss: 2.3703067104021707

Epoch: 5| Step: 8
Training loss: 2.4863810539245605
Validation loss: 2.3679258078336716

Epoch: 5| Step: 9
Training loss: 2.454343318939209
Validation loss: 2.368013153473536

Epoch: 5| Step: 10
Training loss: 2.2271344661712646
Validation loss: 2.361560901006063

Epoch: 5| Step: 11
Training loss: 1.0452640056610107
Validation loss: 2.3636535505453744

Epoch: 58| Step: 0
Training loss: 2.813502073287964
Validation loss: 2.3593026200930276

Epoch: 5| Step: 1
Training loss: 2.8860244750976562
Validation loss: 2.3554488817850747

Epoch: 5| Step: 2
Training loss: 2.55916690826416
Validation loss: 2.364956180254618

Epoch: 5| Step: 3
Training loss: 2.8991341590881348
Validation loss: 2.364406834046046

Epoch: 5| Step: 4
Training loss: 2.3646721839904785
Validation loss: 2.360306203365326

Epoch: 5| Step: 5
Training loss: 2.490008592605591
Validation loss: 2.356001893679301

Epoch: 5| Step: 6
Training loss: 2.7556307315826416
Validation loss: 2.348549336194992

Epoch: 5| Step: 7
Training loss: 2.7233517169952393
Validation loss: 2.340103651086489

Epoch: 5| Step: 8
Training loss: 2.117332935333252
Validation loss: 2.336856335401535

Epoch: 5| Step: 9
Training loss: 2.614135265350342
Validation loss: 2.3349826683600745

Epoch: 5| Step: 10
Training loss: 1.7345540523529053
Validation loss: 2.332255482673645

Epoch: 5| Step: 11
Training loss: 1.5480690002441406
Validation loss: 2.3351989338795343

Epoch: 59| Step: 0
Training loss: 2.594151020050049
Validation loss: 2.3352703352769217

Epoch: 5| Step: 1
Training loss: 2.7965614795684814
Validation loss: 2.333528608083725

Epoch: 5| Step: 2
Training loss: 2.611823558807373
Validation loss: 2.328472157319387

Epoch: 5| Step: 3
Training loss: 2.2501392364501953
Validation loss: 2.3240062395731607

Epoch: 5| Step: 4
Training loss: 2.2766757011413574
Validation loss: 2.322274441520373

Epoch: 5| Step: 5
Training loss: 2.3301587104797363
Validation loss: 2.3234799802303314

Epoch: 5| Step: 6
Training loss: 2.4971253871917725
Validation loss: 2.3135918329159417

Epoch: 5| Step: 7
Training loss: 2.4671576023101807
Validation loss: 2.315695211291313

Epoch: 5| Step: 8
Training loss: 2.8390045166015625
Validation loss: 2.316395789384842

Epoch: 5| Step: 9
Training loss: 2.7777411937713623
Validation loss: 2.3129230737686157

Epoch: 5| Step: 10
Training loss: 2.1337780952453613
Validation loss: 2.3101855417092643

Epoch: 5| Step: 11
Training loss: 1.8315174579620361
Validation loss: 2.3111207485198975

Epoch: 60| Step: 0
Training loss: 2.5258703231811523
Validation loss: 2.316324253877004

Epoch: 5| Step: 1
Training loss: 2.1818671226501465
Validation loss: 2.3123871833086014

Epoch: 5| Step: 2
Training loss: 1.9516159296035767
Validation loss: 2.303064296642939

Epoch: 5| Step: 3
Training loss: 2.6001627445220947
Validation loss: 2.309185986717542

Epoch: 5| Step: 4
Training loss: 2.895543336868286
Validation loss: 2.30284974972407

Epoch: 5| Step: 5
Training loss: 2.6324915885925293
Validation loss: 2.298470367987951

Epoch: 5| Step: 6
Training loss: 2.1138181686401367
Validation loss: 2.3021664122740426

Epoch: 5| Step: 7
Training loss: 2.7437984943389893
Validation loss: 2.29358180363973

Epoch: 5| Step: 8
Training loss: 2.2480530738830566
Validation loss: 2.2920052905877433

Epoch: 5| Step: 9
Training loss: 2.3522791862487793
Validation loss: 2.295982211828232

Epoch: 5| Step: 10
Training loss: 2.763801097869873
Validation loss: 2.28842356801033

Epoch: 5| Step: 11
Training loss: 3.2118091583251953
Validation loss: 2.289493272701899

Epoch: 61| Step: 0
Training loss: 2.6727967262268066
Validation loss: 2.2880815168221793

Epoch: 5| Step: 1
Training loss: 2.287583112716675
Validation loss: 2.2882375915845237

Epoch: 5| Step: 2
Training loss: 2.4325783252716064
Validation loss: 2.279526243607203

Epoch: 5| Step: 3
Training loss: 1.9991527795791626
Validation loss: 2.2860285937786102

Epoch: 5| Step: 4
Training loss: 2.7462410926818848
Validation loss: 2.2846780717372894

Epoch: 5| Step: 5
Training loss: 2.5101799964904785
Validation loss: 2.2810328900814056

Epoch: 5| Step: 6
Training loss: 2.8019471168518066
Validation loss: 2.2787858992815018

Epoch: 5| Step: 7
Training loss: 1.8453518152236938
Validation loss: 2.274003287156423

Epoch: 5| Step: 8
Training loss: 2.614887237548828
Validation loss: 2.2699357072512307

Epoch: 5| Step: 9
Training loss: 2.186738967895508
Validation loss: 2.266611228386561

Epoch: 5| Step: 10
Training loss: 2.758612871170044
Validation loss: 2.259751339753469

Epoch: 5| Step: 11
Training loss: 2.39551043510437
Validation loss: 2.259951819976171

Epoch: 62| Step: 0
Training loss: 2.380859136581421
Validation loss: 2.2548717906077704

Epoch: 5| Step: 1
Training loss: 2.4046497344970703
Validation loss: 2.2642630636692047

Epoch: 5| Step: 2
Training loss: 2.2326583862304688
Validation loss: 2.267513871192932

Epoch: 5| Step: 3
Training loss: 2.1248741149902344
Validation loss: 2.2533020079135895

Epoch: 5| Step: 4
Training loss: 2.3863253593444824
Validation loss: 2.2553727527459464

Epoch: 5| Step: 5
Training loss: 2.881950855255127
Validation loss: 2.249922732512156

Epoch: 5| Step: 6
Training loss: 2.3789899349212646
Validation loss: 2.2515794138113656

Epoch: 5| Step: 7
Training loss: 2.629093647003174
Validation loss: 2.2497671147187552

Epoch: 5| Step: 8
Training loss: 2.7724623680114746
Validation loss: 2.2472092608610788

Epoch: 5| Step: 9
Training loss: 2.2664010524749756
Validation loss: 2.2503915975491204

Epoch: 5| Step: 10
Training loss: 2.408207416534424
Validation loss: 2.2485030641158423

Epoch: 5| Step: 11
Training loss: 0.4521745443344116
Validation loss: 2.2469941079616547

Epoch: 63| Step: 0
Training loss: 3.0409464836120605
Validation loss: 2.2489523788293204

Epoch: 5| Step: 1
Training loss: 1.809888482093811
Validation loss: 2.246742849548658

Epoch: 5| Step: 2
Training loss: 1.7976194620132446
Validation loss: 2.2477550705273948

Epoch: 5| Step: 3
Training loss: 2.6402010917663574
Validation loss: 2.242168366909027

Epoch: 5| Step: 4
Training loss: 2.2811801433563232
Validation loss: 2.2435706853866577

Epoch: 5| Step: 5
Training loss: 2.375544309616089
Validation loss: 2.242364525794983

Epoch: 5| Step: 6
Training loss: 2.8625648021698
Validation loss: 2.237391859292984

Epoch: 5| Step: 7
Training loss: 2.8919832706451416
Validation loss: 2.2381798227628074

Epoch: 5| Step: 8
Training loss: 2.2057764530181885
Validation loss: 2.236276606718699

Epoch: 5| Step: 9
Training loss: 2.502775192260742
Validation loss: 2.231426556905111

Epoch: 5| Step: 10
Training loss: 2.1179375648498535
Validation loss: 2.231875866651535

Epoch: 5| Step: 11
Training loss: 1.6131178140640259
Validation loss: 2.228185683488846

Epoch: 64| Step: 0
Training loss: 2.1856703758239746
Validation loss: 2.228558192650477

Epoch: 5| Step: 1
Training loss: 2.5756916999816895
Validation loss: 2.225931386152903

Epoch: 5| Step: 2
Training loss: 1.8928169012069702
Validation loss: 2.222673624753952

Epoch: 5| Step: 3
Training loss: 1.7983815670013428
Validation loss: 2.2182534486055374

Epoch: 5| Step: 4
Training loss: 2.119093656539917
Validation loss: 2.208185166120529

Epoch: 5| Step: 5
Training loss: 2.5217041969299316
Validation loss: 2.2098531325658164

Epoch: 5| Step: 6
Training loss: 2.661754846572876
Validation loss: 2.2169403036435447

Epoch: 5| Step: 7
Training loss: 2.0089337825775146
Validation loss: 2.208562562863032

Epoch: 5| Step: 8
Training loss: 2.470534086227417
Validation loss: 2.2101951042811074

Epoch: 5| Step: 9
Training loss: 3.0096726417541504
Validation loss: 2.2047745833794274

Epoch: 5| Step: 10
Training loss: 2.8128726482391357
Validation loss: 2.2066062738498053

Epoch: 5| Step: 11
Training loss: 2.7461137771606445
Validation loss: 2.2032619019349418

Epoch: 65| Step: 0
Training loss: 2.7538578510284424
Validation loss: 2.208856691916784

Epoch: 5| Step: 1
Training loss: 2.102199077606201
Validation loss: 2.2124897837638855

Epoch: 5| Step: 2
Training loss: 2.2262799739837646
Validation loss: 2.215125948190689

Epoch: 5| Step: 3
Training loss: 2.26897931098938
Validation loss: 2.2127536733945212

Epoch: 5| Step: 4
Training loss: 2.2972259521484375
Validation loss: 2.2111398528019586

Epoch: 5| Step: 5
Training loss: 1.7988964319229126
Validation loss: 2.209650456905365

Epoch: 5| Step: 6
Training loss: 2.799910306930542
Validation loss: 2.204498916864395

Epoch: 5| Step: 7
Training loss: 2.1635994911193848
Validation loss: 2.2027259916067123

Epoch: 5| Step: 8
Training loss: 2.4687702655792236
Validation loss: 2.2046008308728537

Epoch: 5| Step: 9
Training loss: 2.6671478748321533
Validation loss: 2.1981844504674277

Epoch: 5| Step: 10
Training loss: 2.070582389831543
Validation loss: 2.200562760233879

Epoch: 5| Step: 11
Training loss: 4.1695876121521
Validation loss: 2.1967970778544745

Epoch: 66| Step: 0
Training loss: 1.758086919784546
Validation loss: 2.1940210858980813

Epoch: 5| Step: 1
Training loss: 1.6689239740371704
Validation loss: 2.189699833591779

Epoch: 5| Step: 2
Training loss: 1.8081567287445068
Validation loss: 2.188690265019735

Epoch: 5| Step: 3
Training loss: 2.8624019622802734
Validation loss: 2.1860764026641846

Epoch: 5| Step: 4
Training loss: 1.9743831157684326
Validation loss: 2.184059609969457

Epoch: 5| Step: 5
Training loss: 2.6867034435272217
Validation loss: 2.1835953444242477

Epoch: 5| Step: 6
Training loss: 2.7176260948181152
Validation loss: 2.178058847784996

Epoch: 5| Step: 7
Training loss: 2.861023426055908
Validation loss: 2.1713092774152756

Epoch: 5| Step: 8
Training loss: 2.4769837856292725
Validation loss: 2.174999386072159

Epoch: 5| Step: 9
Training loss: 2.859031915664673
Validation loss: 2.170260339975357

Epoch: 5| Step: 10
Training loss: 2.189199924468994
Validation loss: 2.1806518733501434

Epoch: 5| Step: 11
Training loss: 1.7376797199249268
Validation loss: 2.1704212774833045

Epoch: 67| Step: 0
Training loss: 2.5674164295196533
Validation loss: 2.1791297694047294

Epoch: 5| Step: 1
Training loss: 2.074868679046631
Validation loss: 2.1799089163541794

Epoch: 5| Step: 2
Training loss: 2.855759382247925
Validation loss: 2.181209981441498

Epoch: 5| Step: 3
Training loss: 1.8444026708602905
Validation loss: 2.183566893140475

Epoch: 5| Step: 4
Training loss: 1.842350959777832
Validation loss: 2.1846121648947396

Epoch: 5| Step: 5
Training loss: 2.2875607013702393
Validation loss: 2.18607430656751

Epoch: 5| Step: 6
Training loss: 2.563037157058716
Validation loss: 2.1825535794099173

Epoch: 5| Step: 7
Training loss: 2.186159610748291
Validation loss: 2.180309697985649

Epoch: 5| Step: 8
Training loss: 2.1594772338867188
Validation loss: 2.1753046115239463

Epoch: 5| Step: 9
Training loss: 3.2777411937713623
Validation loss: 2.175621216495832

Epoch: 5| Step: 10
Training loss: 2.0683341026306152
Validation loss: 2.172467996676763

Epoch: 5| Step: 11
Training loss: 2.125812530517578
Validation loss: 2.174828141927719

Epoch: 68| Step: 0
Training loss: 2.052237033843994
Validation loss: 2.1713761438926062

Epoch: 5| Step: 1
Training loss: 2.3287582397460938
Validation loss: 2.175177569190661

Epoch: 5| Step: 2
Training loss: 2.2268359661102295
Validation loss: 2.1683878799279532

Epoch: 5| Step: 3
Training loss: 2.2336618900299072
Validation loss: 2.1674484312534332

Epoch: 5| Step: 4
Training loss: 2.2054786682128906
Validation loss: 2.165718744198481

Epoch: 5| Step: 5
Training loss: 2.367478847503662
Validation loss: 2.168409302830696

Epoch: 5| Step: 6
Training loss: 3.1286168098449707
Validation loss: 2.164104163646698

Epoch: 5| Step: 7
Training loss: 2.373041868209839
Validation loss: 2.160947029789289

Epoch: 5| Step: 8
Training loss: 2.454184055328369
Validation loss: 2.1569298108418784

Epoch: 5| Step: 9
Training loss: 2.3552632331848145
Validation loss: 2.1549729655186334

Epoch: 5| Step: 10
Training loss: 1.7345364093780518
Validation loss: 2.1513837029536567

Epoch: 5| Step: 11
Training loss: 2.808292865753174
Validation loss: 2.14599347114563

Epoch: 69| Step: 0
Training loss: 2.657522678375244
Validation loss: 2.1451359391212463

Epoch: 5| Step: 1
Training loss: 2.528822660446167
Validation loss: 2.144395033518473

Epoch: 5| Step: 2
Training loss: 1.9953269958496094
Validation loss: 2.1481480300426483

Epoch: 5| Step: 3
Training loss: 2.1317741870880127
Validation loss: 2.137920767068863

Epoch: 5| Step: 4
Training loss: 2.3489389419555664
Validation loss: 2.145292431116104

Epoch: 5| Step: 5
Training loss: 1.9606029987335205
Validation loss: 2.1532813062270484

Epoch: 5| Step: 6
Training loss: 2.3045103549957275
Validation loss: 2.153613934914271

Epoch: 5| Step: 7
Training loss: 2.519171714782715
Validation loss: 2.156509041786194

Epoch: 5| Step: 8
Training loss: 2.171166181564331
Validation loss: 2.155851105848948

Epoch: 5| Step: 9
Training loss: 2.54563045501709
Validation loss: 2.141603300968806

Epoch: 5| Step: 10
Training loss: 1.982845664024353
Validation loss: 2.1311889539162316

Epoch: 5| Step: 11
Training loss: 2.922361373901367
Validation loss: 2.137670248746872

Epoch: 70| Step: 0
Training loss: 2.735947847366333
Validation loss: 2.135535717010498

Epoch: 5| Step: 1
Training loss: 2.8515114784240723
Validation loss: 2.143161177635193

Epoch: 5| Step: 2
Training loss: 2.0437355041503906
Validation loss: 2.1527442236741385

Epoch: 5| Step: 3
Training loss: 1.5183732509613037
Validation loss: 2.152963956197103

Epoch: 5| Step: 4
Training loss: 2.3512895107269287
Validation loss: 2.1559786895910897

Epoch: 5| Step: 5
Training loss: 1.785241723060608
Validation loss: 2.160424843430519

Epoch: 5| Step: 6
Training loss: 2.0764801502227783
Validation loss: 2.157512371738752

Epoch: 5| Step: 7
Training loss: 2.1629106998443604
Validation loss: 2.161708494027456

Epoch: 5| Step: 8
Training loss: 2.665208578109741
Validation loss: 2.156980499625206

Epoch: 5| Step: 9
Training loss: 2.281311511993408
Validation loss: 2.153871322671572

Epoch: 5| Step: 10
Training loss: 2.7655587196350098
Validation loss: 2.149839927752813

Epoch: 5| Step: 11
Training loss: 3.8188207149505615
Validation loss: 2.146346921722094

Epoch: 71| Step: 0
Training loss: 2.690556764602661
Validation loss: 2.145632281899452

Epoch: 5| Step: 1
Training loss: 2.7770206928253174
Validation loss: 2.1411841164032617

Epoch: 5| Step: 2
Training loss: 2.454294204711914
Validation loss: 2.1345797330141068

Epoch: 5| Step: 3
Training loss: 1.863037109375
Validation loss: 2.1347141762574515

Epoch: 5| Step: 4
Training loss: 2.279336452484131
Validation loss: 2.1289707124233246

Epoch: 5| Step: 5
Training loss: 2.1585919857025146
Validation loss: 2.1210553348064423

Epoch: 5| Step: 6
Training loss: 2.0715019702911377
Validation loss: 2.124847580989202

Epoch: 5| Step: 7
Training loss: 2.5651156902313232
Validation loss: 2.1208154757817588

Epoch: 5| Step: 8
Training loss: 2.2953295707702637
Validation loss: 2.1159384548664093

Epoch: 5| Step: 9
Training loss: 1.6524944305419922
Validation loss: 2.118985886375109

Epoch: 5| Step: 10
Training loss: 2.5843639373779297
Validation loss: 2.1127382467190423

Epoch: 5| Step: 11
Training loss: 1.6345059871673584
Validation loss: 2.108171915014585

Epoch: 72| Step: 0
Training loss: 2.299574375152588
Validation loss: 2.110400145252546

Epoch: 5| Step: 1
Training loss: 2.2406134605407715
Validation loss: 2.114220301310221

Epoch: 5| Step: 2
Training loss: 2.693152904510498
Validation loss: 2.1169990599155426

Epoch: 5| Step: 3
Training loss: 2.3600499629974365
Validation loss: 2.122598206003507

Epoch: 5| Step: 4
Training loss: 2.466782331466675
Validation loss: 2.1217508912086487

Epoch: 5| Step: 5
Training loss: 2.4981822967529297
Validation loss: 2.110679085055987

Epoch: 5| Step: 6
Training loss: 2.0079195499420166
Validation loss: 2.1169405579566956

Epoch: 5| Step: 7
Training loss: 2.4454498291015625
Validation loss: 2.107555935780207

Epoch: 5| Step: 8
Training loss: 2.155055522918701
Validation loss: 2.105007608731588

Epoch: 5| Step: 9
Training loss: 1.8940117359161377
Validation loss: 2.108437711993853

Epoch: 5| Step: 10
Training loss: 2.084965229034424
Validation loss: 2.107366527120272

Epoch: 5| Step: 11
Training loss: 2.630905866622925
Validation loss: 2.100329712033272

Epoch: 73| Step: 0
Training loss: 1.9853436946868896
Validation loss: 2.10703152914842

Epoch: 5| Step: 1
Training loss: 2.299597978591919
Validation loss: 2.0986669758955636

Epoch: 5| Step: 2
Training loss: 2.0075771808624268
Validation loss: 2.1082590172688165

Epoch: 5| Step: 3
Training loss: 2.3854029178619385
Validation loss: 2.1139865716298423

Epoch: 5| Step: 4
Training loss: 1.406097650527954
Validation loss: 2.112459277113279

Epoch: 5| Step: 5
Training loss: 2.1364808082580566
Validation loss: 2.128886580467224

Epoch: 5| Step: 6
Training loss: 3.0787856578826904
Validation loss: 2.162808100382487

Epoch: 5| Step: 7
Training loss: 2.8819663524627686
Validation loss: 2.201671669880549

Epoch: 5| Step: 8
Training loss: 1.985347032546997
Validation loss: 2.1757703572511673

Epoch: 5| Step: 9
Training loss: 2.1097941398620605
Validation loss: 2.1174077888329825

Epoch: 5| Step: 10
Training loss: 2.9660568237304688
Validation loss: 2.1001315265893936

Epoch: 5| Step: 11
Training loss: 3.174198865890503
Validation loss: 2.1005355964104333

Epoch: 74| Step: 0
Training loss: 2.080503225326538
Validation loss: 2.1087897519270578

Epoch: 5| Step: 1
Training loss: 2.185875415802002
Validation loss: 2.109889974196752

Epoch: 5| Step: 2
Training loss: 2.0074474811553955
Validation loss: 2.1173249731461206

Epoch: 5| Step: 3
Training loss: 2.5618960857391357
Validation loss: 2.121724550922712

Epoch: 5| Step: 4
Training loss: 2.444344997406006
Validation loss: 2.1287614703178406

Epoch: 5| Step: 5
Training loss: 2.259497880935669
Validation loss: 2.133589824040731

Epoch: 5| Step: 6
Training loss: 2.3867526054382324
Validation loss: 2.1404294768969216

Epoch: 5| Step: 7
Training loss: 2.212801933288574
Validation loss: 2.1495603074630103

Epoch: 5| Step: 8
Training loss: 2.3317019939422607
Validation loss: 2.1480850676695504

Epoch: 5| Step: 9
Training loss: 2.050778388977051
Validation loss: 2.1478559176127114

Epoch: 5| Step: 10
Training loss: 2.576423406600952
Validation loss: 2.1478829383850098

Epoch: 5| Step: 11
Training loss: 3.5955090522766113
Validation loss: 2.1400308360656104

Epoch: 75| Step: 0
Training loss: 2.345609426498413
Validation loss: 2.1239964365959167

Epoch: 5| Step: 1
Training loss: 2.345480442047119
Validation loss: 2.118636121352514

Epoch: 5| Step: 2
Training loss: 2.308750629425049
Validation loss: 2.11216247578462

Epoch: 5| Step: 3
Training loss: 2.266526699066162
Validation loss: 2.1089763144652047

Epoch: 5| Step: 4
Training loss: 2.262488842010498
Validation loss: 2.103972852230072

Epoch: 5| Step: 5
Training loss: 1.5642123222351074
Validation loss: 2.0918176968892417

Epoch: 5| Step: 6
Training loss: 2.1741833686828613
Validation loss: 2.0887049535910287

Epoch: 5| Step: 7
Training loss: 2.301215887069702
Validation loss: 2.0883634785811105

Epoch: 5| Step: 8
Training loss: 2.7221641540527344
Validation loss: 2.0880546073118844

Epoch: 5| Step: 9
Training loss: 2.1646878719329834
Validation loss: 2.077917903661728

Epoch: 5| Step: 10
Training loss: 2.549337148666382
Validation loss: 2.08243898053964

Epoch: 5| Step: 11
Training loss: 2.6654610633850098
Validation loss: 2.081526810924212

Epoch: 76| Step: 0
Training loss: 2.3812952041625977
Validation loss: 2.0842215170462928

Epoch: 5| Step: 1
Training loss: 2.487839460372925
Validation loss: 2.094660704334577

Epoch: 5| Step: 2
Training loss: 2.0041821002960205
Validation loss: 2.1054141024748483

Epoch: 5| Step: 3
Training loss: 2.561723232269287
Validation loss: 2.0955849836270013

Epoch: 5| Step: 4
Training loss: 2.217311143875122
Validation loss: 2.0867696553468704

Epoch: 5| Step: 5
Training loss: 2.910632848739624
Validation loss: 2.0861091067393622

Epoch: 5| Step: 6
Training loss: 2.0285675525665283
Validation loss: 2.0755839496850967

Epoch: 5| Step: 7
Training loss: 2.2747323513031006
Validation loss: 2.0681531925996146

Epoch: 5| Step: 8
Training loss: 1.7102272510528564
Validation loss: 2.070220410823822

Epoch: 5| Step: 9
Training loss: 2.1407742500305176
Validation loss: 2.069144452611605

Epoch: 5| Step: 10
Training loss: 2.2862391471862793
Validation loss: 2.0776569296916327

Epoch: 5| Step: 11
Training loss: 1.3643734455108643
Validation loss: 2.0676112373669944

Epoch: 77| Step: 0
Training loss: 2.758310317993164
Validation loss: 2.0706349660952887

Epoch: 5| Step: 1
Training loss: 2.3012986183166504
Validation loss: 2.0632179776827493

Epoch: 5| Step: 2
Training loss: 2.0428152084350586
Validation loss: 2.0621864795684814

Epoch: 5| Step: 3
Training loss: 2.5185694694519043
Validation loss: 2.0569862127304077

Epoch: 5| Step: 4
Training loss: 1.7892429828643799
Validation loss: 2.0588326503833136

Epoch: 5| Step: 5
Training loss: 2.619899272918701
Validation loss: 2.0614167352517447

Epoch: 5| Step: 6
Training loss: 2.602560520172119
Validation loss: 2.0621551225582757

Epoch: 5| Step: 7
Training loss: 2.1167092323303223
Validation loss: 2.0666173795859017

Epoch: 5| Step: 8
Training loss: 1.771017074584961
Validation loss: 2.064367860555649

Epoch: 5| Step: 9
Training loss: 2.156175136566162
Validation loss: 2.056599830587705

Epoch: 5| Step: 10
Training loss: 2.1354870796203613
Validation loss: 2.0505319386720657

Epoch: 5| Step: 11
Training loss: 2.0149896144866943
Validation loss: 2.047167877356211

Epoch: 78| Step: 0
Training loss: 1.667921781539917
Validation loss: 2.0652711987495422

Epoch: 5| Step: 1
Training loss: 2.0486385822296143
Validation loss: 2.0670574257771173

Epoch: 5| Step: 2
Training loss: 2.509711742401123
Validation loss: 2.070876657962799

Epoch: 5| Step: 3
Training loss: 1.9796380996704102
Validation loss: 2.0754441370566687

Epoch: 5| Step: 4
Training loss: 2.679940938949585
Validation loss: 2.073042626182238

Epoch: 5| Step: 5
Training loss: 1.96627676486969
Validation loss: 2.073873887459437

Epoch: 5| Step: 6
Training loss: 2.3708651065826416
Validation loss: 2.0728506495555243

Epoch: 5| Step: 7
Training loss: 2.3934319019317627
Validation loss: 2.070970276991526

Epoch: 5| Step: 8
Training loss: 2.062593936920166
Validation loss: 2.069610724846522

Epoch: 5| Step: 9
Training loss: 2.2780914306640625
Validation loss: 2.068401272098223

Epoch: 5| Step: 10
Training loss: 2.573951482772827
Validation loss: 2.0685852269331613

Epoch: 5| Step: 11
Training loss: 3.4941024780273438
Validation loss: 2.06428699195385

Epoch: 79| Step: 0
Training loss: 2.3036088943481445
Validation loss: 2.0691492905219397

Epoch: 5| Step: 1
Training loss: 2.1349549293518066
Validation loss: 2.0608608573675156

Epoch: 5| Step: 2
Training loss: 2.0840554237365723
Validation loss: 2.0634091645479202

Epoch: 5| Step: 3
Training loss: 2.0657589435577393
Validation loss: 2.0593325247367225

Epoch: 5| Step: 4
Training loss: 2.107477903366089
Validation loss: 2.0546266734600067

Epoch: 5| Step: 5
Training loss: 2.4475088119506836
Validation loss: 2.0500136663516364

Epoch: 5| Step: 6
Training loss: 2.184302806854248
Validation loss: 2.0459747910499573

Epoch: 5| Step: 7
Training loss: 2.0563902854919434
Validation loss: 2.044831231236458

Epoch: 5| Step: 8
Training loss: 2.185460329055786
Validation loss: 2.0359505265951157

Epoch: 5| Step: 9
Training loss: 2.372398853302002
Validation loss: 2.0459948827823005

Epoch: 5| Step: 10
Training loss: 2.5824670791625977
Validation loss: 2.046438535054525

Epoch: 5| Step: 11
Training loss: 2.3334028720855713
Validation loss: 2.038671846191088

Epoch: 80| Step: 0
Training loss: 2.0068647861480713
Validation loss: 2.0432642052570977

Epoch: 5| Step: 1
Training loss: 2.167050838470459
Validation loss: 2.0435847838719687

Epoch: 5| Step: 2
Training loss: 2.148503541946411
Validation loss: 2.055622731645902

Epoch: 5| Step: 3
Training loss: 2.399384021759033
Validation loss: 2.0526461005210876

Epoch: 5| Step: 4
Training loss: 2.2339720726013184
Validation loss: 2.0606655975182853

Epoch: 5| Step: 5
Training loss: 1.5099526643753052
Validation loss: 2.043633500734965

Epoch: 5| Step: 6
Training loss: 2.5937154293060303
Validation loss: 2.0496868789196014

Epoch: 5| Step: 7
Training loss: 3.0400009155273438
Validation loss: 2.0485008458296456

Epoch: 5| Step: 8
Training loss: 1.6969406604766846
Validation loss: 2.047528773546219

Epoch: 5| Step: 9
Training loss: 2.7891316413879395
Validation loss: 2.0485467513402305

Epoch: 5| Step: 10
Training loss: 2.0695040225982666
Validation loss: 2.0585914154847464

Epoch: 5| Step: 11
Training loss: 1.9859557151794434
Validation loss: 2.053874040643374

Epoch: 81| Step: 0
Training loss: 1.9590526819229126
Validation loss: 2.0573935359716415

Epoch: 5| Step: 1
Training loss: 2.0731701850891113
Validation loss: 2.053386082251867

Epoch: 5| Step: 2
Training loss: 1.8070427179336548
Validation loss: 2.054224342107773

Epoch: 5| Step: 3
Training loss: 2.0064857006073
Validation loss: 2.050023431579272

Epoch: 5| Step: 4
Training loss: 2.3641891479492188
Validation loss: 2.052329882979393

Epoch: 5| Step: 5
Training loss: 2.6791110038757324
Validation loss: 2.045286998152733

Epoch: 5| Step: 6
Training loss: 2.243447780609131
Validation loss: 2.0394773731629052

Epoch: 5| Step: 7
Training loss: 1.92791748046875
Validation loss: 2.0388586769501367

Epoch: 5| Step: 8
Training loss: 2.7078659534454346
Validation loss: 2.0360626528660455

Epoch: 5| Step: 9
Training loss: 2.4998903274536133
Validation loss: 2.0404416819413504

Epoch: 5| Step: 10
Training loss: 2.3862175941467285
Validation loss: 2.0456831753253937

Epoch: 5| Step: 11
Training loss: 1.8583176136016846
Validation loss: 2.0434598177671432

Epoch: 82| Step: 0
Training loss: 2.299623966217041
Validation loss: 2.034206951657931

Epoch: 5| Step: 1
Training loss: 1.8019300699234009
Validation loss: 2.039547602335612

Epoch: 5| Step: 2
Training loss: 2.084801435470581
Validation loss: 2.0418117344379425

Epoch: 5| Step: 3
Training loss: 2.3519694805145264
Validation loss: 2.0513109068075814

Epoch: 5| Step: 4
Training loss: 2.172560214996338
Validation loss: 2.0432356546322503

Epoch: 5| Step: 5
Training loss: 2.1098456382751465
Validation loss: 2.0391065378983817

Epoch: 5| Step: 6
Training loss: 1.9531981945037842
Validation loss: 2.0371456891298294

Epoch: 5| Step: 7
Training loss: 2.644853115081787
Validation loss: 2.035462165872256

Epoch: 5| Step: 8
Training loss: 2.3152692317962646
Validation loss: 2.02584200600783

Epoch: 5| Step: 9
Training loss: 2.2942092418670654
Validation loss: 2.025991107026736

Epoch: 5| Step: 10
Training loss: 2.49306583404541
Validation loss: 2.03068745136261

Epoch: 5| Step: 11
Training loss: 1.4879653453826904
Validation loss: 2.036330223083496

Epoch: 83| Step: 0
Training loss: 2.249138593673706
Validation loss: 2.0320080320040383

Epoch: 5| Step: 1
Training loss: 1.9908485412597656
Validation loss: 2.03617529074351

Epoch: 5| Step: 2
Training loss: 1.8550233840942383
Validation loss: 2.0270352512598038

Epoch: 5| Step: 3
Training loss: 2.3427464962005615
Validation loss: 2.0381812304258347

Epoch: 5| Step: 4
Training loss: 2.5853381156921387
Validation loss: 2.031363551815351

Epoch: 5| Step: 5
Training loss: 2.064552068710327
Validation loss: 2.0274705986181893

Epoch: 5| Step: 6
Training loss: 1.9894527196884155
Validation loss: 2.02689491212368

Epoch: 5| Step: 7
Training loss: 2.3742616176605225
Validation loss: 2.026342029372851

Epoch: 5| Step: 8
Training loss: 2.3033463954925537
Validation loss: 2.028539006908735

Epoch: 5| Step: 9
Training loss: 2.692420482635498
Validation loss: 2.0269361088673272

Epoch: 5| Step: 10
Training loss: 2.0392134189605713
Validation loss: 2.0322886258363724

Epoch: 5| Step: 11
Training loss: 1.4329627752304077
Validation loss: 2.0244131038586297

Epoch: 84| Step: 0
Training loss: 2.5322818756103516
Validation loss: 2.0184044937292733

Epoch: 5| Step: 1
Training loss: 2.732250928878784
Validation loss: 2.0249193658431373

Epoch: 5| Step: 2
Training loss: 2.390681505203247
Validation loss: 2.029803310831388

Epoch: 5| Step: 3
Training loss: 1.610277533531189
Validation loss: 2.038395722707113

Epoch: 5| Step: 4
Training loss: 2.4514307975769043
Validation loss: 2.0459030071894326

Epoch: 5| Step: 5
Training loss: 1.8367722034454346
Validation loss: 2.0423954129219055

Epoch: 5| Step: 6
Training loss: 2.3166353702545166
Validation loss: 2.0475478569666543

Epoch: 5| Step: 7
Training loss: 1.7675220966339111
Validation loss: 2.0455982834100723

Epoch: 5| Step: 8
Training loss: 2.381417751312256
Validation loss: 2.0487696329752603

Epoch: 5| Step: 9
Training loss: 2.453917980194092
Validation loss: 2.042563552657763

Epoch: 5| Step: 10
Training loss: 1.8111724853515625
Validation loss: 2.040264974037806

Epoch: 5| Step: 11
Training loss: 2.990777015686035
Validation loss: 2.0382566899061203

Epoch: 85| Step: 0
Training loss: 2.2723374366760254
Validation loss: 2.0321787695089975

Epoch: 5| Step: 1
Training loss: 2.193068265914917
Validation loss: 2.032218108574549

Epoch: 5| Step: 2
Training loss: 1.7415138483047485
Validation loss: 2.0294274588425956

Epoch: 5| Step: 3
Training loss: 2.3605263233184814
Validation loss: 2.0321432749430337

Epoch: 5| Step: 4
Training loss: 2.0600080490112305
Validation loss: 2.015631064772606

Epoch: 5| Step: 5
Training loss: 2.204378843307495
Validation loss: 2.010849580168724

Epoch: 5| Step: 6
Training loss: 1.8510639667510986
Validation loss: 2.0205125560363135

Epoch: 5| Step: 7
Training loss: 2.0580666065216064
Validation loss: 2.0181276500225067

Epoch: 5| Step: 8
Training loss: 2.047855854034424
Validation loss: 2.030000532666842

Epoch: 5| Step: 9
Training loss: 2.5549120903015137
Validation loss: 2.030843198299408

Epoch: 5| Step: 10
Training loss: 2.3752987384796143
Validation loss: 2.0342141538858414

Epoch: 5| Step: 11
Training loss: 4.375615119934082
Validation loss: 2.029764244953791

Epoch: 86| Step: 0
Training loss: 2.4798359870910645
Validation loss: 2.0339876264333725

Epoch: 5| Step: 1
Training loss: 2.367997646331787
Validation loss: 2.0201545308033624

Epoch: 5| Step: 2
Training loss: 2.1480135917663574
Validation loss: 2.0249485870202384

Epoch: 5| Step: 3
Training loss: 2.4328272342681885
Validation loss: 2.0221610367298126

Epoch: 5| Step: 4
Training loss: 2.066098213195801
Validation loss: 2.027812123298645

Epoch: 5| Step: 5
Training loss: 2.478813886642456
Validation loss: 2.0219642370939255

Epoch: 5| Step: 6
Training loss: 1.6156097650527954
Validation loss: 2.019172817468643

Epoch: 5| Step: 7
Training loss: 1.9239015579223633
Validation loss: 2.0236078649759293

Epoch: 5| Step: 8
Training loss: 2.1825246810913086
Validation loss: 2.0150496512651443

Epoch: 5| Step: 9
Training loss: 2.203975200653076
Validation loss: 2.016963024934133

Epoch: 5| Step: 10
Training loss: 2.0653340816497803
Validation loss: 2.0235463132460914

Epoch: 5| Step: 11
Training loss: 2.758009910583496
Validation loss: 2.0368660738070807

Epoch: 87| Step: 0
Training loss: 1.9942524433135986
Validation loss: 2.0390378584464393

Epoch: 5| Step: 1
Training loss: 2.414665699005127
Validation loss: 2.062186355392138

Epoch: 5| Step: 2
Training loss: 2.279855251312256
Validation loss: 2.0852477749188743

Epoch: 5| Step: 3
Training loss: 1.8415958881378174
Validation loss: 2.0744407226641974

Epoch: 5| Step: 4
Training loss: 2.385040760040283
Validation loss: 2.053538352251053

Epoch: 5| Step: 5
Training loss: 2.4204165935516357
Validation loss: 2.0294555127620697

Epoch: 5| Step: 6
Training loss: 2.168461561203003
Validation loss: 2.0237603187561035

Epoch: 5| Step: 7
Training loss: 2.0605850219726562
Validation loss: 2.033636142810186

Epoch: 5| Step: 8
Training loss: 2.3851304054260254
Validation loss: 2.0474095741907754

Epoch: 5| Step: 9
Training loss: 1.97931706905365
Validation loss: 2.0418488482634225

Epoch: 5| Step: 10
Training loss: 2.41339111328125
Validation loss: 2.049362396200498

Epoch: 5| Step: 11
Training loss: 2.730205535888672
Validation loss: 2.0573827226956687

Epoch: 88| Step: 0
Training loss: 2.451878070831299
Validation loss: 2.0595268607139587

Epoch: 5| Step: 1
Training loss: 2.0828418731689453
Validation loss: 2.055955802400907

Epoch: 5| Step: 2
Training loss: 2.1278679370880127
Validation loss: 2.055901274085045

Epoch: 5| Step: 3
Training loss: 2.0993990898132324
Validation loss: 2.0617606043815613

Epoch: 5| Step: 4
Training loss: 2.269374132156372
Validation loss: 2.0550778607527413

Epoch: 5| Step: 5
Training loss: 2.3928916454315186
Validation loss: 2.052825773755709

Epoch: 5| Step: 6
Training loss: 2.0590929985046387
Validation loss: 2.04875348508358

Epoch: 5| Step: 7
Training loss: 2.3656468391418457
Validation loss: 2.050126224756241

Epoch: 5| Step: 8
Training loss: 1.914282202720642
Validation loss: 2.0438010642925897

Epoch: 5| Step: 9
Training loss: 2.8194727897644043
Validation loss: 2.042562668522199

Epoch: 5| Step: 10
Training loss: 2.115720272064209
Validation loss: 2.0401967267195382

Epoch: 5| Step: 11
Training loss: 1.5537011623382568
Validation loss: 2.040334552526474

Epoch: 89| Step: 0
Training loss: 2.3918063640594482
Validation loss: 2.0370539724826813

Epoch: 5| Step: 1
Training loss: 2.363196849822998
Validation loss: 2.039097120364507

Epoch: 5| Step: 2
Training loss: 2.361708879470825
Validation loss: 2.034174924095472

Epoch: 5| Step: 3
Training loss: 1.9860498905181885
Validation loss: 2.029177496830622

Epoch: 5| Step: 4
Training loss: 2.183018207550049
Validation loss: 2.0249660263458886

Epoch: 5| Step: 5
Training loss: 2.047989845275879
Validation loss: 2.0123580346504846

Epoch: 5| Step: 6
Training loss: 1.639868140220642
Validation loss: 2.0170814295609794

Epoch: 5| Step: 7
Training loss: 2.8224937915802
Validation loss: 2.0179640601078668

Epoch: 5| Step: 8
Training loss: 2.2312214374542236
Validation loss: 2.030290871858597

Epoch: 5| Step: 9
Training loss: 1.9057613611221313
Validation loss: 2.024156148235003

Epoch: 5| Step: 10
Training loss: 2.3256494998931885
Validation loss: 2.0415349354346595

Epoch: 5| Step: 11
Training loss: 1.9503740072250366
Validation loss: 2.0395831018686295

Epoch: 90| Step: 0
Training loss: 1.703616738319397
Validation loss: 2.0316099325815835

Epoch: 5| Step: 1
Training loss: 2.059300422668457
Validation loss: 2.0128260304530463

Epoch: 5| Step: 2
Training loss: 2.2381794452667236
Validation loss: 2.023582473397255

Epoch: 5| Step: 3
Training loss: 2.1688802242279053
Validation loss: 2.0324154049158096

Epoch: 5| Step: 4
Training loss: 2.4280529022216797
Validation loss: 2.037972405552864

Epoch: 5| Step: 5
Training loss: 2.228455066680908
Validation loss: 2.0460996131102243

Epoch: 5| Step: 6
Training loss: 2.233588695526123
Validation loss: 2.047719284892082

Epoch: 5| Step: 7
Training loss: 2.442265748977661
Validation loss: 2.0492655634880066

Epoch: 5| Step: 8
Training loss: 1.950116753578186
Validation loss: 2.050605535507202

Epoch: 5| Step: 9
Training loss: 2.2884929180145264
Validation loss: 2.0480065643787384

Epoch: 5| Step: 10
Training loss: 2.4155304431915283
Validation loss: 2.051101023952166

Epoch: 5| Step: 11
Training loss: 2.683347702026367
Validation loss: 2.04791068037351

Epoch: 91| Step: 0
Training loss: 2.155820608139038
Validation loss: 2.0511070837577186

Epoch: 5| Step: 1
Training loss: 2.716582775115967
Validation loss: 2.0517861247062683

Epoch: 5| Step: 2
Training loss: 2.3726370334625244
Validation loss: 2.045785660545031

Epoch: 5| Step: 3
Training loss: 2.062613010406494
Validation loss: 2.0436488737662635

Epoch: 5| Step: 4
Training loss: 2.111220598220825
Validation loss: 2.0363343407710395

Epoch: 5| Step: 5
Training loss: 2.5329649448394775
Validation loss: 2.0325627078612647

Epoch: 5| Step: 6
Training loss: 2.369156837463379
Validation loss: 2.0259465873241425

Epoch: 5| Step: 7
Training loss: 1.9849506616592407
Validation loss: 2.0212640712658563

Epoch: 5| Step: 8
Training loss: 2.2957804203033447
Validation loss: 2.008076310157776

Epoch: 5| Step: 9
Training loss: 1.835810661315918
Validation loss: 2.015871971845627

Epoch: 5| Step: 10
Training loss: 1.6860239505767822
Validation loss: 2.032149533430735

Epoch: 5| Step: 11
Training loss: 2.1745448112487793
Validation loss: 2.0490339199701944

Epoch: 92| Step: 0
Training loss: 1.7299792766571045
Validation loss: 2.0324149330457053

Epoch: 5| Step: 1
Training loss: 2.467682361602783
Validation loss: 2.027004823088646

Epoch: 5| Step: 2
Training loss: 2.151228666305542
Validation loss: 2.0346516768137612

Epoch: 5| Step: 3
Training loss: 2.4467880725860596
Validation loss: 2.0281179547309875

Epoch: 5| Step: 4
Training loss: 2.168827533721924
Validation loss: 2.034451484680176

Epoch: 5| Step: 5
Training loss: 1.6358150243759155
Validation loss: 2.030172015229861

Epoch: 5| Step: 6
Training loss: 2.494593858718872
Validation loss: 2.026765743891398

Epoch: 5| Step: 7
Training loss: 2.1424927711486816
Validation loss: 2.0181611875693

Epoch: 5| Step: 8
Training loss: 2.248164653778076
Validation loss: 2.0191014260053635

Epoch: 5| Step: 9
Training loss: 1.8288676738739014
Validation loss: 2.0232105553150177

Epoch: 5| Step: 10
Training loss: 2.627763271331787
Validation loss: 2.0220850308736167

Epoch: 5| Step: 11
Training loss: 1.362871527671814
Validation loss: 2.0205575774113336

Epoch: 93| Step: 0
Training loss: 1.8276512622833252
Validation loss: 2.021805932124456

Epoch: 5| Step: 1
Training loss: 1.694632887840271
Validation loss: 2.0291355897982917

Epoch: 5| Step: 2
Training loss: 2.194878101348877
Validation loss: 2.020584558447202

Epoch: 5| Step: 3
Training loss: 2.352038621902466
Validation loss: 2.0214387625455856

Epoch: 5| Step: 4
Training loss: 1.678283452987671
Validation loss: 2.0164533158143363

Epoch: 5| Step: 5
Training loss: 2.2939932346343994
Validation loss: 2.022129148244858

Epoch: 5| Step: 6
Training loss: 2.053342580795288
Validation loss: 2.0264417082071304

Epoch: 5| Step: 7
Training loss: 2.6421875953674316
Validation loss: 2.026637683312098

Epoch: 5| Step: 8
Training loss: 2.1110496520996094
Validation loss: 2.0188405414422355

Epoch: 5| Step: 9
Training loss: 2.3920249938964844
Validation loss: 2.012434105078379

Epoch: 5| Step: 10
Training loss: 2.2218356132507324
Validation loss: 2.01582695543766

Epoch: 5| Step: 11
Training loss: 3.3456456661224365
Validation loss: 2.008587827285131

Epoch: 94| Step: 0
Training loss: 2.4105467796325684
Validation loss: 2.0136285722255707

Epoch: 5| Step: 1
Training loss: 2.217916488647461
Validation loss: 2.013847216963768

Epoch: 5| Step: 2
Training loss: 2.237013339996338
Validation loss: 2.0185376405715942

Epoch: 5| Step: 3
Training loss: 1.9573312997817993
Validation loss: 2.0128314793109894

Epoch: 5| Step: 4
Training loss: 2.410701036453247
Validation loss: 2.013134146730105

Epoch: 5| Step: 5
Training loss: 1.725926160812378
Validation loss: 2.0161129285891852

Epoch: 5| Step: 6
Training loss: 2.012421131134033
Validation loss: 2.0079705913861594

Epoch: 5| Step: 7
Training loss: 2.1098015308380127
Validation loss: 2.0175923258066177

Epoch: 5| Step: 8
Training loss: 2.179274559020996
Validation loss: 2.037366271018982

Epoch: 5| Step: 9
Training loss: 1.9218778610229492
Validation loss: 2.043887029091517

Epoch: 5| Step: 10
Training loss: 2.4043147563934326
Validation loss: 2.0541381935278573

Epoch: 5| Step: 11
Training loss: 3.219470500946045
Validation loss: 2.056019221742948

Epoch: 95| Step: 0
Training loss: 1.9119491577148438
Validation loss: 2.0400084257125854

Epoch: 5| Step: 1
Training loss: 2.4157650470733643
Validation loss: 2.0243760844071708

Epoch: 5| Step: 2
Training loss: 1.9424149990081787
Validation loss: 2.010642647743225

Epoch: 5| Step: 3
Training loss: 1.771240472793579
Validation loss: 2.012253686785698

Epoch: 5| Step: 4
Training loss: 3.084648847579956
Validation loss: 2.0105412801106772

Epoch: 5| Step: 5
Training loss: 2.165431261062622
Validation loss: 2.0337608406941095

Epoch: 5| Step: 6
Training loss: 1.982301950454712
Validation loss: 2.0330022474129996

Epoch: 5| Step: 7
Training loss: 2.0198235511779785
Validation loss: 2.0403093844652176

Epoch: 5| Step: 8
Training loss: 2.589111089706421
Validation loss: 2.0270125418901443

Epoch: 5| Step: 9
Training loss: 2.2395718097686768
Validation loss: 2.03564190864563

Epoch: 5| Step: 10
Training loss: 1.8283815383911133
Validation loss: 2.031401053071022

Epoch: 5| Step: 11
Training loss: 1.8409650325775146
Validation loss: 2.0262774527072906

Epoch: 96| Step: 0
Training loss: 1.8356224298477173
Validation loss: 2.0314612289269767

Epoch: 5| Step: 1
Training loss: 2.2245821952819824
Validation loss: 2.039087528983752

Epoch: 5| Step: 2
Training loss: 2.788142681121826
Validation loss: 2.041135847568512

Epoch: 5| Step: 3
Training loss: 2.7575831413269043
Validation loss: 2.0397078593571982

Epoch: 5| Step: 4
Training loss: 1.5913952589035034
Validation loss: 2.0399625500043235

Epoch: 5| Step: 5
Training loss: 1.6584453582763672
Validation loss: 2.0259430408477783

Epoch: 5| Step: 6
Training loss: 2.4052987098693848
Validation loss: 2.027389948566755

Epoch: 5| Step: 7
Training loss: 2.0171310901641846
Validation loss: 2.017815053462982

Epoch: 5| Step: 8
Training loss: 2.374037504196167
Validation loss: 2.0182655851046243

Epoch: 5| Step: 9
Training loss: 1.5066969394683838
Validation loss: 2.015587235490481

Epoch: 5| Step: 10
Training loss: 2.9224276542663574
Validation loss: 2.011621798078219

Epoch: 5| Step: 11
Training loss: 2.4453115463256836
Validation loss: 2.0126393735408783

Epoch: 97| Step: 0
Training loss: 2.111806869506836
Validation loss: 2.0086672653754554

Epoch: 5| Step: 1
Training loss: 2.343900203704834
Validation loss: 2.0116939544677734

Epoch: 5| Step: 2
Training loss: 2.127164363861084
Validation loss: 2.011737366517385

Epoch: 5| Step: 3
Training loss: 2.2408995628356934
Validation loss: 2.0225187490383782

Epoch: 5| Step: 4
Training loss: 1.6644036769866943
Validation loss: 2.024151782194773

Epoch: 5| Step: 5
Training loss: 2.867225170135498
Validation loss: 2.0363680173953376

Epoch: 5| Step: 6
Training loss: 1.9634300470352173
Validation loss: 2.0224705636501312

Epoch: 5| Step: 7
Training loss: 2.0003418922424316
Validation loss: 2.0357118099927902

Epoch: 5| Step: 8
Training loss: 1.5655238628387451
Validation loss: 2.026297410329183

Epoch: 5| Step: 9
Training loss: 2.6056480407714844
Validation loss: 2.025328134497007

Epoch: 5| Step: 10
Training loss: 2.264374256134033
Validation loss: 2.0445946554342904

Epoch: 5| Step: 11
Training loss: 1.8202890157699585
Validation loss: 2.0375576118628183

Epoch: 98| Step: 0
Training loss: 1.9027698040008545
Validation loss: 2.0364059011141458

Epoch: 5| Step: 1
Training loss: 1.7861320972442627
Validation loss: 2.0263057748476663

Epoch: 5| Step: 2
Training loss: 2.4188854694366455
Validation loss: 2.023468032479286

Epoch: 5| Step: 3
Training loss: 2.047396421432495
Validation loss: 2.022439365585645

Epoch: 5| Step: 4
Training loss: 2.1371376514434814
Validation loss: 2.031605064868927

Epoch: 5| Step: 5
Training loss: 2.3888301849365234
Validation loss: 2.0137705405553183

Epoch: 5| Step: 6
Training loss: 2.544020175933838
Validation loss: 2.0118312935034433

Epoch: 5| Step: 7
Training loss: 1.667020559310913
Validation loss: 2.005379026134809

Epoch: 5| Step: 8
Training loss: 2.3444042205810547
Validation loss: 2.009773517648379

Epoch: 5| Step: 9
Training loss: 2.12591814994812
Validation loss: 2.0098402003447213

Epoch: 5| Step: 10
Training loss: 2.285435914993286
Validation loss: 2.0093255937099457

Epoch: 5| Step: 11
Training loss: 1.9842904806137085
Validation loss: 2.003972257177035

Epoch: 99| Step: 0
Training loss: 2.673015832901001
Validation loss: 2.0070985853672028

Epoch: 5| Step: 1
Training loss: 2.2685539722442627
Validation loss: 2.0115662862857184

Epoch: 5| Step: 2
Training loss: 2.2690768241882324
Validation loss: 2.0063686072826385

Epoch: 5| Step: 3
Training loss: 1.791045904159546
Validation loss: 2.0084529668092728

Epoch: 5| Step: 4
Training loss: 2.2076058387756348
Validation loss: 2.0053223818540573

Epoch: 5| Step: 5
Training loss: 1.3721320629119873
Validation loss: 2.013221820195516

Epoch: 5| Step: 6
Training loss: 1.7893987894058228
Validation loss: 2.03023698925972

Epoch: 5| Step: 7
Training loss: 2.2380192279815674
Validation loss: 2.036925529440244

Epoch: 5| Step: 8
Training loss: 2.40692138671875
Validation loss: 2.055923859278361

Epoch: 5| Step: 9
Training loss: 2.0286448001861572
Validation loss: 2.0299589286247888

Epoch: 5| Step: 10
Training loss: 2.4169108867645264
Validation loss: 2.0575456470251083

Epoch: 5| Step: 11
Training loss: 3.406135082244873
Validation loss: 2.0481185565392175

Epoch: 100| Step: 0
Training loss: 2.51499342918396
Validation loss: 2.0280958662430444

Epoch: 5| Step: 1
Training loss: 2.3361434936523438
Validation loss: 2.019902010758718

Epoch: 5| Step: 2
Training loss: 2.2166714668273926
Validation loss: 1.9998851368824642

Epoch: 5| Step: 3
Training loss: 2.134350299835205
Validation loss: 2.010666529337565

Epoch: 5| Step: 4
Training loss: 1.9903643131256104
Validation loss: 2.0252830733855567

Epoch: 5| Step: 5
Training loss: 1.7399990558624268
Validation loss: 2.0356481273969016

Epoch: 5| Step: 6
Training loss: 2.4380366802215576
Validation loss: 2.036418080329895

Epoch: 5| Step: 7
Training loss: 2.2216603755950928
Validation loss: 2.032012258966764

Epoch: 5| Step: 8
Training loss: 2.411345958709717
Validation loss: 2.024580473701159

Epoch: 5| Step: 9
Training loss: 1.910858154296875
Validation loss: 2.0279570519924164

Epoch: 5| Step: 10
Training loss: 1.8833423852920532
Validation loss: 2.0266376733779907

Epoch: 5| Step: 11
Training loss: 3.0854568481445312
Validation loss: 2.014785513281822

Epoch: 101| Step: 0
Training loss: 2.0873870849609375
Validation loss: 2.0100041975577674

Epoch: 5| Step: 1
Training loss: 1.9031941890716553
Validation loss: 2.0088465164105096

Epoch: 5| Step: 2
Training loss: 2.099828004837036
Validation loss: 2.0058993250131607

Epoch: 5| Step: 3
Training loss: 2.409348726272583
Validation loss: 2.006607582171758

Epoch: 5| Step: 4
Training loss: 1.8686158657073975
Validation loss: 2.0134328653415046

Epoch: 5| Step: 5
Training loss: 2.3823747634887695
Validation loss: 2.0188648402690887

Epoch: 5| Step: 6
Training loss: 2.229879140853882
Validation loss: 2.0121410687764487

Epoch: 5| Step: 7
Training loss: 1.965174913406372
Validation loss: 2.018512641390165

Epoch: 5| Step: 8
Training loss: 2.4903111457824707
Validation loss: 2.022395317753156

Epoch: 5| Step: 9
Training loss: 1.8560270071029663
Validation loss: 2.0272091825803122

Epoch: 5| Step: 10
Training loss: 2.499803066253662
Validation loss: 2.0200780431429544

Epoch: 5| Step: 11
Training loss: 1.3290696144104004
Validation loss: 2.0298993537823358

Epoch: 102| Step: 0
Training loss: 1.8311134576797485
Validation loss: 2.0408159295717874

Epoch: 5| Step: 1
Training loss: 2.1699700355529785
Validation loss: 2.04312264919281

Epoch: 5| Step: 2
Training loss: 2.361898422241211
Validation loss: 2.0547679315010705

Epoch: 5| Step: 3
Training loss: 2.5199146270751953
Validation loss: 2.0387402921915054

Epoch: 5| Step: 4
Training loss: 1.775498628616333
Validation loss: 2.0245312501986823

Epoch: 5| Step: 5
Training loss: 2.140287399291992
Validation loss: 2.0150569081306458

Epoch: 5| Step: 6
Training loss: 2.192556619644165
Validation loss: 2.0091450015703836

Epoch: 5| Step: 7
Training loss: 2.311354875564575
Validation loss: 2.0262187073628106

Epoch: 5| Step: 8
Training loss: 2.5540387630462646
Validation loss: 2.0379293163617453

Epoch: 5| Step: 9
Training loss: 1.9065077304840088
Validation loss: 2.044028008977572

Epoch: 5| Step: 10
Training loss: 2.3888776302337646
Validation loss: 2.0447218169768653

Epoch: 5| Step: 11
Training loss: 2.06973934173584
Validation loss: 2.0441049287716546

Epoch: 103| Step: 0
Training loss: 2.0033907890319824
Validation loss: 2.0398545265197754

Epoch: 5| Step: 1
Training loss: 2.3501200675964355
Validation loss: 2.0430731227000556

Epoch: 5| Step: 2
Training loss: 2.387082576751709
Validation loss: 2.0356900890668235

Epoch: 5| Step: 3
Training loss: 2.5233120918273926
Validation loss: 2.0325150191783905

Epoch: 5| Step: 4
Training loss: 1.9072113037109375
Validation loss: 2.037528693675995

Epoch: 5| Step: 5
Training loss: 2.258871555328369
Validation loss: 2.0304444233576455

Epoch: 5| Step: 6
Training loss: 2.223968029022217
Validation loss: 2.0276598632335663

Epoch: 5| Step: 7
Training loss: 1.9670066833496094
Validation loss: 2.0275292098522186

Epoch: 5| Step: 8
Training loss: 1.7002168893814087
Validation loss: 2.016468127568563

Epoch: 5| Step: 9
Training loss: 2.265922784805298
Validation loss: 2.0085444202025733

Epoch: 5| Step: 10
Training loss: 2.4602150917053223
Validation loss: 2.0017736504475274

Epoch: 5| Step: 11
Training loss: 0.8896740674972534
Validation loss: 2.0109225809574127

Epoch: 104| Step: 0
Training loss: 2.3768186569213867
Validation loss: 2.027842342853546

Epoch: 5| Step: 1
Training loss: 1.7286659479141235
Validation loss: 2.058957656224569

Epoch: 5| Step: 2
Training loss: 2.1982407569885254
Validation loss: 2.086205313603083

Epoch: 5| Step: 3
Training loss: 2.353994369506836
Validation loss: 2.1245738516251245

Epoch: 5| Step: 4
Training loss: 1.7344610691070557
Validation loss: 2.1162415643533072

Epoch: 5| Step: 5
Training loss: 2.2046799659729004
Validation loss: 2.110925962527593

Epoch: 5| Step: 6
Training loss: 2.443985939025879
Validation loss: 2.0992912550767264

Epoch: 5| Step: 7
Training loss: 2.0879807472229004
Validation loss: 2.0844693183898926

Epoch: 5| Step: 8
Training loss: 2.766470432281494
Validation loss: 2.0532075415054956

Epoch: 5| Step: 9
Training loss: 2.403207302093506
Validation loss: 2.0272483130296073

Epoch: 5| Step: 10
Training loss: 1.9617223739624023
Validation loss: 2.0103950649499893

Epoch: 5| Step: 11
Training loss: 2.065487861633301
Validation loss: 2.023336132367452

Epoch: 105| Step: 0
Training loss: 1.7473382949829102
Validation loss: 2.0289176305135093

Epoch: 5| Step: 1
Training loss: 1.7384710311889648
Validation loss: 2.0283259451389313

Epoch: 5| Step: 2
Training loss: 2.4029712677001953
Validation loss: 2.0324402302503586

Epoch: 5| Step: 3
Training loss: 2.3872008323669434
Validation loss: 2.0359052369991937

Epoch: 5| Step: 4
Training loss: 2.683967351913452
Validation loss: 2.0380567808945975

Epoch: 5| Step: 5
Training loss: 2.2282326221466064
Validation loss: 2.0405964155991874

Epoch: 5| Step: 6
Training loss: 1.9744148254394531
Validation loss: 2.0462865779797235

Epoch: 5| Step: 7
Training loss: 2.3432369232177734
Validation loss: 2.0393753200769424

Epoch: 5| Step: 8
Training loss: 2.0697224140167236
Validation loss: 2.038481985529264

Epoch: 5| Step: 9
Training loss: 1.7578147649765015
Validation loss: 2.035763904452324

Epoch: 5| Step: 10
Training loss: 2.834749221801758
Validation loss: 2.0382947524388633

Epoch: 5| Step: 11
Training loss: 2.4410481452941895
Validation loss: 2.0326370894908905

Epoch: 106| Step: 0
Training loss: 2.8049185276031494
Validation loss: 2.0302503804365792

Epoch: 5| Step: 1
Training loss: 1.9864740371704102
Validation loss: 2.0292226721843085

Epoch: 5| Step: 2
Training loss: 1.8087791204452515
Validation loss: 2.0261011819044747

Epoch: 5| Step: 3
Training loss: 2.4353058338165283
Validation loss: 2.0279787381490073

Epoch: 5| Step: 4
Training loss: 2.1111607551574707
Validation loss: 2.0244527707497277

Epoch: 5| Step: 5
Training loss: 2.241161346435547
Validation loss: 2.019096940755844

Epoch: 5| Step: 6
Training loss: 2.2035672664642334
Validation loss: 2.0091129541397095

Epoch: 5| Step: 7
Training loss: 1.793109655380249
Validation loss: 2.0059658686319985

Epoch: 5| Step: 8
Training loss: 2.2660858631134033
Validation loss: 2.016502598921458

Epoch: 5| Step: 9
Training loss: 2.1772141456604004
Validation loss: 2.027691880861918

Epoch: 5| Step: 10
Training loss: 1.7445240020751953
Validation loss: 2.0428802917400994

Epoch: 5| Step: 11
Training loss: 2.363891839981079
Validation loss: 2.062072734038035

Epoch: 107| Step: 0
Training loss: 2.0656075477600098
Validation loss: 2.060408482948939

Epoch: 5| Step: 1
Training loss: 2.5157277584075928
Validation loss: 2.040733903646469

Epoch: 5| Step: 2
Training loss: 2.0307400226593018
Validation loss: 2.024349053700765

Epoch: 5| Step: 3
Training loss: 2.356959581375122
Validation loss: 2.0306087086598077

Epoch: 5| Step: 4
Training loss: 2.1722660064697266
Validation loss: 2.019822915395101

Epoch: 5| Step: 5
Training loss: 1.8964744806289673
Validation loss: 2.01806877553463

Epoch: 5| Step: 6
Training loss: 1.8620147705078125
Validation loss: 2.013602524995804

Epoch: 5| Step: 7
Training loss: 2.0436902046203613
Validation loss: 2.0180497020483017

Epoch: 5| Step: 8
Training loss: 2.5237832069396973
Validation loss: 2.014996146162351

Epoch: 5| Step: 9
Training loss: 2.483144760131836
Validation loss: 2.016862610975901

Epoch: 5| Step: 10
Training loss: 1.787644624710083
Validation loss: 2.02299332122008

Epoch: 5| Step: 11
Training loss: 1.508901596069336
Validation loss: 2.012818858027458

Epoch: 108| Step: 0
Training loss: 2.2531180381774902
Validation loss: 2.0165256957213082

Epoch: 5| Step: 1
Training loss: 2.297898292541504
Validation loss: 2.020770480235418

Epoch: 5| Step: 2
Training loss: 2.6324751377105713
Validation loss: 2.0072941730419793

Epoch: 5| Step: 3
Training loss: 2.3708081245422363
Validation loss: 2.016063163677851

Epoch: 5| Step: 4
Training loss: 2.3248438835144043
Validation loss: 2.00524640083313

Epoch: 5| Step: 5
Training loss: 2.329221248626709
Validation loss: 2.012441928188006

Epoch: 5| Step: 6
Training loss: 1.884075403213501
Validation loss: 2.0069430569807687

Epoch: 5| Step: 7
Training loss: 2.169265031814575
Validation loss: 2.012948607405027

Epoch: 5| Step: 8
Training loss: 2.0423245429992676
Validation loss: 2.020137151082357

Epoch: 5| Step: 9
Training loss: 1.7484283447265625
Validation loss: 2.02421701947848

Epoch: 5| Step: 10
Training loss: 1.865053415298462
Validation loss: 2.027385870615641

Epoch: 5| Step: 11
Training loss: 0.2663908004760742
Validation loss: 2.0407428592443466

Epoch: 109| Step: 0
Training loss: 2.6506705284118652
Validation loss: 2.0619362642367682

Epoch: 5| Step: 1
Training loss: 1.6231281757354736
Validation loss: 2.0679240127404532

Epoch: 5| Step: 2
Training loss: 2.472179651260376
Validation loss: 2.0432167251904807

Epoch: 5| Step: 3
Training loss: 2.044630527496338
Validation loss: 2.0397493292888007

Epoch: 5| Step: 4
Training loss: 2.1018476486206055
Validation loss: 2.0455907682577767

Epoch: 5| Step: 5
Training loss: 2.3105006217956543
Validation loss: 2.047886406381925

Epoch: 5| Step: 6
Training loss: 2.034557819366455
Validation loss: 2.044499566157659

Epoch: 5| Step: 7
Training loss: 2.212955951690674
Validation loss: 2.0410543580849967

Epoch: 5| Step: 8
Training loss: 1.7300529479980469
Validation loss: 2.0293807834386826

Epoch: 5| Step: 9
Training loss: 2.182694673538208
Validation loss: 2.016529361406962

Epoch: 5| Step: 10
Training loss: 2.1433138847351074
Validation loss: 2.009975184996923

Epoch: 5| Step: 11
Training loss: 2.8601012229919434
Validation loss: 2.007728934288025

Epoch: 110| Step: 0
Training loss: 1.8527015447616577
Validation loss: 2.0130417545636496

Epoch: 5| Step: 1
Training loss: 2.54685640335083
Validation loss: 2.017986238002777

Epoch: 5| Step: 2
Training loss: 1.89878249168396
Validation loss: 2.0145563582579293

Epoch: 5| Step: 3
Training loss: 2.2251579761505127
Validation loss: 2.0196027358373008

Epoch: 5| Step: 4
Training loss: 1.4674890041351318
Validation loss: 2.006887132922808

Epoch: 5| Step: 5
Training loss: 2.2349696159362793
Validation loss: 2.0129248797893524

Epoch: 5| Step: 6
Training loss: 2.277556896209717
Validation loss: 2.0181686729192734

Epoch: 5| Step: 7
Training loss: 2.1844801902770996
Validation loss: 2.0119355618953705

Epoch: 5| Step: 8
Training loss: 1.9614747762680054
Validation loss: 2.0148717164993286

Epoch: 5| Step: 9
Training loss: 2.436415195465088
Validation loss: 2.0132573743661246

Epoch: 5| Step: 10
Training loss: 2.2491085529327393
Validation loss: 2.021399900317192

Epoch: 5| Step: 11
Training loss: 2.30108642578125
Validation loss: 2.015925402442614

Epoch: 111| Step: 0
Training loss: 2.050858736038208
Validation loss: 2.0195542524258294

Epoch: 5| Step: 1
Training loss: 1.9346908330917358
Validation loss: 2.0335900286833444

Epoch: 5| Step: 2
Training loss: 1.9091863632202148
Validation loss: 2.016380935907364

Epoch: 5| Step: 3
Training loss: 2.4650256633758545
Validation loss: 2.0236775080362954

Epoch: 5| Step: 4
Training loss: 2.3103647232055664
Validation loss: 2.033583347996076

Epoch: 5| Step: 5
Training loss: 1.8602908849716187
Validation loss: 2.0314396818478904

Epoch: 5| Step: 6
Training loss: 2.614445686340332
Validation loss: 2.0250371346871057

Epoch: 5| Step: 7
Training loss: 2.410602569580078
Validation loss: 2.0209451764822006

Epoch: 5| Step: 8
Training loss: 2.238801956176758
Validation loss: 2.0112892935673394

Epoch: 5| Step: 9
Training loss: 1.2993782758712769
Validation loss: 2.0162952641646066

Epoch: 5| Step: 10
Training loss: 2.2470431327819824
Validation loss: 2.016921783487002

Epoch: 5| Step: 11
Training loss: 2.176649808883667
Validation loss: 2.0123593558867774

Epoch: 112| Step: 0
Training loss: 1.805169701576233
Validation loss: 2.019602914651235

Epoch: 5| Step: 1
Training loss: 2.037630558013916
Validation loss: 2.009043042858442

Epoch: 5| Step: 2
Training loss: 2.026505947113037
Validation loss: 2.004022245605787

Epoch: 5| Step: 3
Training loss: 1.8583084344863892
Validation loss: 1.997558777530988

Epoch: 5| Step: 4
Training loss: 1.8043489456176758
Validation loss: 2.0146451691786447

Epoch: 5| Step: 5
Training loss: 2.12016224861145
Validation loss: 2.013951525092125

Epoch: 5| Step: 6
Training loss: 2.433295965194702
Validation loss: 2.017156034708023

Epoch: 5| Step: 7
Training loss: 2.309704303741455
Validation loss: 1.999594733119011

Epoch: 5| Step: 8
Training loss: 2.6536967754364014
Validation loss: 2.020313705007235

Epoch: 5| Step: 9
Training loss: 1.9884014129638672
Validation loss: 2.029764990011851

Epoch: 5| Step: 10
Training loss: 2.1491751670837402
Validation loss: 2.029515335957209

Epoch: 5| Step: 11
Training loss: 3.0998692512512207
Validation loss: 2.024140020211538

Epoch: 113| Step: 0
Training loss: 2.2565979957580566
Validation loss: 2.0175026953220367

Epoch: 5| Step: 1
Training loss: 1.9102733135223389
Validation loss: 2.0119675745566687

Epoch: 5| Step: 2
Training loss: 2.077981472015381
Validation loss: 2.0118834922711053

Epoch: 5| Step: 3
Training loss: 1.964529275894165
Validation loss: 2.0107789834340415

Epoch: 5| Step: 4
Training loss: 2.004772424697876
Validation loss: 2.0177624821662903

Epoch: 5| Step: 5
Training loss: 2.682741403579712
Validation loss: 2.0220957348744073

Epoch: 5| Step: 6
Training loss: 1.9204308986663818
Validation loss: 2.0126427908738456

Epoch: 5| Step: 7
Training loss: 1.9625740051269531
Validation loss: 2.020713140567144

Epoch: 5| Step: 8
Training loss: 2.2894062995910645
Validation loss: 2.0120732386906943

Epoch: 5| Step: 9
Training loss: 2.2808003425598145
Validation loss: 2.0225880245367684

Epoch: 5| Step: 10
Training loss: 2.173689603805542
Validation loss: 2.0089766879876456

Epoch: 5| Step: 11
Training loss: 2.264464855194092
Validation loss: 2.003451536099116

Epoch: 114| Step: 0
Training loss: 1.8765805959701538
Validation loss: 2.0100265741348267

Epoch: 5| Step: 1
Training loss: 2.2244834899902344
Validation loss: 2.006223812699318

Epoch: 5| Step: 2
Training loss: 2.315706491470337
Validation loss: 1.9989973803361256

Epoch: 5| Step: 3
Training loss: 2.913853645324707
Validation loss: 2.006321460008621

Epoch: 5| Step: 4
Training loss: 2.1588635444641113
Validation loss: 1.9970263242721558

Epoch: 5| Step: 5
Training loss: 2.4061410427093506
Validation loss: 1.9934883962074916

Epoch: 5| Step: 6
Training loss: 1.812186598777771
Validation loss: 1.9960309714078903

Epoch: 5| Step: 7
Training loss: 1.905946969985962
Validation loss: 1.9959586958090465

Epoch: 5| Step: 8
Training loss: 1.8613201379776
Validation loss: 2.009062190850576

Epoch: 5| Step: 9
Training loss: 1.8968740701675415
Validation loss: 2.013460954030355

Epoch: 5| Step: 10
Training loss: 1.9934965372085571
Validation loss: 2.0239783227443695

Epoch: 5| Step: 11
Training loss: 2.2808938026428223
Validation loss: 2.0359833985567093

Epoch: 115| Step: 0
Training loss: 1.9002546072006226
Validation loss: 2.056451211373011

Epoch: 5| Step: 1
Training loss: 2.529447317123413
Validation loss: 2.056359753012657

Epoch: 5| Step: 2
Training loss: 2.664914846420288
Validation loss: 2.0387045492728553

Epoch: 5| Step: 3
Training loss: 2.052719831466675
Validation loss: 2.0447658002376556

Epoch: 5| Step: 4
Training loss: 2.0340638160705566
Validation loss: 2.048070400953293

Epoch: 5| Step: 5
Training loss: 1.6815967559814453
Validation loss: 2.034451554218928

Epoch: 5| Step: 6
Training loss: 2.246748447418213
Validation loss: 2.037850191195806

Epoch: 5| Step: 7
Training loss: 2.892859935760498
Validation loss: 2.0215978672107062

Epoch: 5| Step: 8
Training loss: 1.9197962284088135
Validation loss: 2.0172606656948724

Epoch: 5| Step: 9
Training loss: 1.9903888702392578
Validation loss: 2.0191482504208884

Epoch: 5| Step: 10
Training loss: 1.673424482345581
Validation loss: 2.0108244915803275

Epoch: 5| Step: 11
Training loss: 1.1938202381134033
Validation loss: 2.009505664308866

Epoch: 116| Step: 0
Training loss: 2.2251410484313965
Validation loss: 2.006981228788694

Epoch: 5| Step: 1
Training loss: 2.322655200958252
Validation loss: 2.0091722855965295

Epoch: 5| Step: 2
Training loss: 2.2551398277282715
Validation loss: 2.013065124551455

Epoch: 5| Step: 3
Training loss: 2.315946578979492
Validation loss: 2.0060426940520606

Epoch: 5| Step: 4
Training loss: 2.101349353790283
Validation loss: 2.0080547829469046

Epoch: 5| Step: 5
Training loss: 2.0899479389190674
Validation loss: 1.999236638347308

Epoch: 5| Step: 6
Training loss: 2.2910170555114746
Validation loss: 2.0164719025293985

Epoch: 5| Step: 7
Training loss: 1.9706073999404907
Validation loss: 2.024795278906822

Epoch: 5| Step: 8
Training loss: 2.651654005050659
Validation loss: 2.022550195455551

Epoch: 5| Step: 9
Training loss: 2.2491438388824463
Validation loss: 2.020440066854159

Epoch: 5| Step: 10
Training loss: 1.314220905303955
Validation loss: 2.0185025483369827

Epoch: 5| Step: 11
Training loss: 1.0859692096710205
Validation loss: 2.019207686185837

Epoch: 117| Step: 0
Training loss: 2.2697887420654297
Validation loss: 2.021673063437144

Epoch: 5| Step: 1
Training loss: 2.206279993057251
Validation loss: 2.0273805807034173

Epoch: 5| Step: 2
Training loss: 1.7648662328720093
Validation loss: 2.015173022945722

Epoch: 5| Step: 3
Training loss: 2.204838514328003
Validation loss: 2.0125137815872827

Epoch: 5| Step: 4
Training loss: 2.0190014839172363
Validation loss: 2.0189811438322067

Epoch: 5| Step: 5
Training loss: 2.219539165496826
Validation loss: 2.0109641502300897

Epoch: 5| Step: 6
Training loss: 2.2150495052337646
Validation loss: 2.021132543683052

Epoch: 5| Step: 7
Training loss: 2.43656849861145
Validation loss: 2.0187083780765533

Epoch: 5| Step: 8
Training loss: 2.164489269256592
Validation loss: 2.0071406066417694

Epoch: 5| Step: 9
Training loss: 1.9676029682159424
Validation loss: 2.0103541215260825

Epoch: 5| Step: 10
Training loss: 1.9859020709991455
Validation loss: 2.0197343081235886

Epoch: 5| Step: 11
Training loss: 2.250473976135254
Validation loss: 2.0256955176591873

Epoch: 118| Step: 0
Training loss: 1.8961246013641357
Validation loss: 2.0362772593895593

Epoch: 5| Step: 1
Training loss: 2.421168804168701
Validation loss: 2.0333582758903503

Epoch: 5| Step: 2
Training loss: 2.1563334465026855
Validation loss: 2.0442649821440377

Epoch: 5| Step: 3
Training loss: 2.2317299842834473
Validation loss: 2.038562774658203

Epoch: 5| Step: 4
Training loss: 1.789228081703186
Validation loss: 2.036224658290545

Epoch: 5| Step: 5
Training loss: 2.181600332260132
Validation loss: 2.0374627808729806

Epoch: 5| Step: 6
Training loss: 2.820056915283203
Validation loss: 2.0386834343274436

Epoch: 5| Step: 7
Training loss: 2.1708717346191406
Validation loss: 2.028115446368853

Epoch: 5| Step: 8
Training loss: 2.1552274227142334
Validation loss: 2.0138329217831292

Epoch: 5| Step: 9
Training loss: 1.7484146356582642
Validation loss: 2.0142536213000617

Epoch: 5| Step: 10
Training loss: 1.9274791479110718
Validation loss: 2.0067810912926993

Epoch: 5| Step: 11
Training loss: 2.1980035305023193
Validation loss: 2.0060231536626816

Epoch: 119| Step: 0
Training loss: 2.0553064346313477
Validation loss: 2.0018522391716638

Epoch: 5| Step: 1
Training loss: 2.2095463275909424
Validation loss: 2.0040778070688248

Epoch: 5| Step: 2
Training loss: 2.122798204421997
Validation loss: 2.0122391978899636

Epoch: 5| Step: 3
Training loss: 2.5637645721435547
Validation loss: 2.0091745754083

Epoch: 5| Step: 4
Training loss: 2.1154375076293945
Validation loss: 2.011619637409846

Epoch: 5| Step: 5
Training loss: 2.5406250953674316
Validation loss: 2.011864239970843

Epoch: 5| Step: 6
Training loss: 2.0459861755371094
Validation loss: 2.0135198632876077

Epoch: 5| Step: 7
Training loss: 2.6460845470428467
Validation loss: 2.008710021773974

Epoch: 5| Step: 8
Training loss: 1.585196852684021
Validation loss: 2.0114894807338715

Epoch: 5| Step: 9
Training loss: 1.6723601818084717
Validation loss: 2.0018243541320166

Epoch: 5| Step: 10
Training loss: 1.9342820644378662
Validation loss: 1.9985108971595764

Epoch: 5| Step: 11
Training loss: 2.4337353706359863
Validation loss: 2.012629434466362

Epoch: 120| Step: 0
Training loss: 2.254481554031372
Validation loss: 2.009985754887263

Epoch: 5| Step: 1
Training loss: 2.3600077629089355
Validation loss: 2.0155594845612845

Epoch: 5| Step: 2
Training loss: 1.8942432403564453
Validation loss: 2.0237043599287667

Epoch: 5| Step: 3
Training loss: 1.8734601736068726
Validation loss: 2.033010184764862

Epoch: 5| Step: 4
Training loss: 1.5614537000656128
Validation loss: 2.0229093184073768

Epoch: 5| Step: 5
Training loss: 1.946563720703125
Validation loss: 2.019601364930471

Epoch: 5| Step: 6
Training loss: 2.114717721939087
Validation loss: 2.020428607861201

Epoch: 5| Step: 7
Training loss: 2.7123427391052246
Validation loss: 2.0254162897666297

Epoch: 5| Step: 8
Training loss: 2.0837578773498535
Validation loss: 2.028839851419131

Epoch: 5| Step: 9
Training loss: 2.0220322608947754
Validation loss: 2.0211983223756156

Epoch: 5| Step: 10
Training loss: 2.2980499267578125
Validation loss: 2.0319837729136148

Epoch: 5| Step: 11
Training loss: 2.9746298789978027
Validation loss: 2.0248754968245826

Epoch: 121| Step: 0
Training loss: 2.3374078273773193
Validation loss: 2.0065587908029556

Epoch: 5| Step: 1
Training loss: 2.479300022125244
Validation loss: 2.00364883740743

Epoch: 5| Step: 2
Training loss: 1.597203254699707
Validation loss: 2.0108972787857056

Epoch: 5| Step: 3
Training loss: 2.21012544631958
Validation loss: 2.0092068016529083

Epoch: 5| Step: 4
Training loss: 2.2092337608337402
Validation loss: 2.014459023873011

Epoch: 5| Step: 5
Training loss: 1.6569408178329468
Validation loss: 2.0173814495404563

Epoch: 5| Step: 6
Training loss: 1.9168729782104492
Validation loss: 2.0139911572138467

Epoch: 5| Step: 7
Training loss: 2.4584710597991943
Validation loss: 2.008802125851313

Epoch: 5| Step: 8
Training loss: 2.703428030014038
Validation loss: 2.0187627573808036

Epoch: 5| Step: 9
Training loss: 1.8234790563583374
Validation loss: 2.011993169784546

Epoch: 5| Step: 10
Training loss: 2.1732277870178223
Validation loss: 1.9959313124418259

Epoch: 5| Step: 11
Training loss: 1.9525065422058105
Validation loss: 2.0073669652144113

Epoch: 122| Step: 0
Training loss: 2.343815565109253
Validation loss: 2.0044991026322045

Epoch: 5| Step: 1
Training loss: 2.433140993118286
Validation loss: 1.999686951438586

Epoch: 5| Step: 2
Training loss: 1.8162271976470947
Validation loss: 1.9952994734048843

Epoch: 5| Step: 3
Training loss: 2.425638437271118
Validation loss: 2.0118382573127747

Epoch: 5| Step: 4
Training loss: 2.198291778564453
Validation loss: 2.017608270049095

Epoch: 5| Step: 5
Training loss: 1.933598279953003
Validation loss: 2.0141717990239463

Epoch: 5| Step: 6
Training loss: 2.798739194869995
Validation loss: 2.0174166162808738

Epoch: 5| Step: 7
Training loss: 2.0040242671966553
Validation loss: 2.0080154488484063

Epoch: 5| Step: 8
Training loss: 1.7832229137420654
Validation loss: 2.0106422007083893

Epoch: 5| Step: 9
Training loss: 1.703499436378479
Validation loss: 2.011540765563647

Epoch: 5| Step: 10
Training loss: 1.8428504467010498
Validation loss: 2.019722660382589

Epoch: 5| Step: 11
Training loss: 2.4845759868621826
Validation loss: 2.0123175183931985

Epoch: 123| Step: 0
Training loss: 2.1769556999206543
Validation loss: 2.01710652311643

Epoch: 5| Step: 1
Training loss: 2.2555110454559326
Validation loss: 2.006682053208351

Epoch: 5| Step: 2
Training loss: 2.280857801437378
Validation loss: 2.0182470877965293

Epoch: 5| Step: 3
Training loss: 1.9651906490325928
Validation loss: 2.0118095676104226

Epoch: 5| Step: 4
Training loss: 1.573992371559143
Validation loss: 2.0085336665312448

Epoch: 5| Step: 5
Training loss: 1.7000020742416382
Validation loss: 2.013725866874059

Epoch: 5| Step: 6
Training loss: 2.447658061981201
Validation loss: 2.016487623254458

Epoch: 5| Step: 7
Training loss: 2.107187509536743
Validation loss: 2.0320065915584564

Epoch: 5| Step: 8
Training loss: 1.7373688220977783
Validation loss: 2.0264493773380914

Epoch: 5| Step: 9
Training loss: 2.4853596687316895
Validation loss: 2.0277023563782373

Epoch: 5| Step: 10
Training loss: 2.5550856590270996
Validation loss: 2.048657238483429

Epoch: 5| Step: 11
Training loss: 2.635739803314209
Validation loss: 2.0446287045876184

Epoch: 124| Step: 0
Training loss: 1.7726116180419922
Validation loss: 2.04716794192791

Epoch: 5| Step: 1
Training loss: 2.7877776622772217
Validation loss: 2.0424849142630896

Epoch: 5| Step: 2
Training loss: 2.987103223800659
Validation loss: 2.0490843653678894

Epoch: 5| Step: 3
Training loss: 1.6217073202133179
Validation loss: 2.0574837823708854

Epoch: 5| Step: 4
Training loss: 2.0208163261413574
Validation loss: 2.055571268002192

Epoch: 5| Step: 5
Training loss: 1.6943778991699219
Validation loss: 2.0340702633062997

Epoch: 5| Step: 6
Training loss: 2.309778928756714
Validation loss: 2.0216110895077386

Epoch: 5| Step: 7
Training loss: 2.1858229637145996
Validation loss: 2.0105300645033517

Epoch: 5| Step: 8
Training loss: 1.9096801280975342
Validation loss: 2.013576408227285

Epoch: 5| Step: 9
Training loss: 2.202775478363037
Validation loss: 2.0140741169452667

Epoch: 5| Step: 10
Training loss: 1.7929519414901733
Validation loss: 2.0126873006423316

Epoch: 5| Step: 11
Training loss: 2.5821549892425537
Validation loss: 2.0206622878710427

Epoch: 125| Step: 0
Training loss: 2.240090847015381
Validation loss: 2.013039986292521

Epoch: 5| Step: 1
Training loss: 2.2837142944335938
Validation loss: 2.013073349992434

Epoch: 5| Step: 2
Training loss: 2.0064101219177246
Validation loss: 2.0077529897292457

Epoch: 5| Step: 3
Training loss: 1.864210844039917
Validation loss: 2.008389934897423

Epoch: 5| Step: 4
Training loss: 2.832413673400879
Validation loss: 2.017267574866613

Epoch: 5| Step: 5
Training loss: 2.1487784385681152
Validation loss: 2.0120734771092734

Epoch: 5| Step: 6
Training loss: 1.7906707525253296
Validation loss: 2.0165412227312722

Epoch: 5| Step: 7
Training loss: 2.3238794803619385
Validation loss: 2.0063349455595016

Epoch: 5| Step: 8
Training loss: 2.033369541168213
Validation loss: 2.0176893870035806

Epoch: 5| Step: 9
Training loss: 2.0959630012512207
Validation loss: 2.0105514029661813

Epoch: 5| Step: 10
Training loss: 1.6990587711334229
Validation loss: 2.003016844391823

Epoch: 5| Step: 11
Training loss: 2.2815465927124023
Validation loss: 2.0169106920560202

Epoch: 126| Step: 0
Training loss: 2.3632874488830566
Validation loss: 2.0256997644901276

Epoch: 5| Step: 1
Training loss: 1.918695092201233
Validation loss: 2.0282996694246926

Epoch: 5| Step: 2
Training loss: 2.0831592082977295
Validation loss: 2.022816186149915

Epoch: 5| Step: 3
Training loss: 2.1674418449401855
Validation loss: 2.024866297841072

Epoch: 5| Step: 4
Training loss: 1.656205415725708
Validation loss: 2.0141407499710717

Epoch: 5| Step: 5
Training loss: 2.414564609527588
Validation loss: 2.0149441907803216

Epoch: 5| Step: 6
Training loss: 1.9698377847671509
Validation loss: 2.0140374849239984

Epoch: 5| Step: 7
Training loss: 1.986109733581543
Validation loss: 2.0170134951670966

Epoch: 5| Step: 8
Training loss: 1.8388969898223877
Validation loss: 2.0195904870827994

Epoch: 5| Step: 9
Training loss: 2.35516095161438
Validation loss: 2.0222818652788797

Epoch: 5| Step: 10
Training loss: 2.285818338394165
Validation loss: 2.0403674840927124

Epoch: 5| Step: 11
Training loss: 2.7616372108459473
Validation loss: 2.0504751056432724

Epoch: 127| Step: 0
Training loss: 1.6226650476455688
Validation loss: 2.0529518028100333

Epoch: 5| Step: 1
Training loss: 2.0814337730407715
Validation loss: 2.037289227048556

Epoch: 5| Step: 2
Training loss: 2.4091625213623047
Validation loss: 2.043250799179077

Epoch: 5| Step: 3
Training loss: 1.9354274272918701
Validation loss: 2.0435952643553414

Epoch: 5| Step: 4
Training loss: 2.1968514919281006
Validation loss: 2.0370177974303565

Epoch: 5| Step: 5
Training loss: 1.9796323776245117
Validation loss: 2.034313182036082

Epoch: 5| Step: 6
Training loss: 2.4551167488098145
Validation loss: 2.0278095453977585

Epoch: 5| Step: 7
Training loss: 1.966963529586792
Validation loss: 2.0246840566396713

Epoch: 5| Step: 8
Training loss: 2.1585915088653564
Validation loss: 2.0165204604466758

Epoch: 5| Step: 9
Training loss: 2.1117992401123047
Validation loss: 2.0114563405513763

Epoch: 5| Step: 10
Training loss: 2.163278341293335
Validation loss: 2.0100074460109076

Epoch: 5| Step: 11
Training loss: 2.538731575012207
Validation loss: 2.011273687084516

Epoch: 128| Step: 0
Training loss: 2.3117542266845703
Validation loss: 2.0116861760616302

Epoch: 5| Step: 1
Training loss: 2.2319247722625732
Validation loss: 2.015996361772219

Epoch: 5| Step: 2
Training loss: 2.416393756866455
Validation loss: 2.0133227656284967

Epoch: 5| Step: 3
Training loss: 2.059586763381958
Validation loss: 2.0166132201751075

Epoch: 5| Step: 4
Training loss: 2.1278185844421387
Validation loss: 2.0189296354850135

Epoch: 5| Step: 5
Training loss: 1.8218557834625244
Validation loss: 2.0126275966564813

Epoch: 5| Step: 6
Training loss: 2.72153902053833
Validation loss: 2.0044324845075607

Epoch: 5| Step: 7
Training loss: 1.7956947088241577
Validation loss: 2.0123198330402374

Epoch: 5| Step: 8
Training loss: 1.613313913345337
Validation loss: 2.0108144929011664

Epoch: 5| Step: 9
Training loss: 1.8665666580200195
Validation loss: 2.0169599105914435

Epoch: 5| Step: 10
Training loss: 2.358170509338379
Validation loss: 2.007948170105616

Epoch: 5| Step: 11
Training loss: 1.8424866199493408
Validation loss: 2.0403472930192947

Epoch: 129| Step: 0
Training loss: 2.053819179534912
Validation loss: 2.0186176747083664

Epoch: 5| Step: 1
Training loss: 1.8750801086425781
Validation loss: 2.0088006456693015

Epoch: 5| Step: 2
Training loss: 2.1368720531463623
Validation loss: 2.013529305656751

Epoch: 5| Step: 3
Training loss: 1.8435341119766235
Validation loss: 2.0076813101768494

Epoch: 5| Step: 4
Training loss: 2.079962730407715
Validation loss: 2.006098667780558

Epoch: 5| Step: 5
Training loss: 1.9475986957550049
Validation loss: 2.0115411480267844

Epoch: 5| Step: 6
Training loss: 2.5902647972106934
Validation loss: 2.012959912419319

Epoch: 5| Step: 7
Training loss: 2.297731876373291
Validation loss: 2.008346493045489

Epoch: 5| Step: 8
Training loss: 2.1961426734924316
Validation loss: 2.0156146784623465

Epoch: 5| Step: 9
Training loss: 2.3010811805725098
Validation loss: 2.022783170143763

Epoch: 5| Step: 10
Training loss: 1.9454326629638672
Validation loss: 2.0187032719453177

Epoch: 5| Step: 11
Training loss: 1.4312165975570679
Validation loss: 2.0220360358556113

Epoch: 130| Step: 0
Training loss: 2.4693236351013184
Validation loss: 2.0116644352674484

Epoch: 5| Step: 1
Training loss: 2.456249713897705
Validation loss: 2.0227028528849282

Epoch: 5| Step: 2
Training loss: 2.0649027824401855
Validation loss: 2.0201747665802636

Epoch: 5| Step: 3
Training loss: 2.0262911319732666
Validation loss: 2.02101768553257

Epoch: 5| Step: 4
Training loss: 1.868282675743103
Validation loss: 2.030340477824211

Epoch: 5| Step: 5
Training loss: 2.639822483062744
Validation loss: 2.02773309747378

Epoch: 5| Step: 6
Training loss: 1.747520089149475
Validation loss: 2.033238708972931

Epoch: 5| Step: 7
Training loss: 1.8621044158935547
Validation loss: 2.019892876346906

Epoch: 5| Step: 8
Training loss: 2.0339503288269043
Validation loss: 2.0165487925211587

Epoch: 5| Step: 9
Training loss: 1.9096187353134155
Validation loss: 2.0230321933825812

Epoch: 5| Step: 10
Training loss: 2.1666553020477295
Validation loss: 2.0309245387713113

Epoch: 5| Step: 11
Training loss: 1.314860224723816
Validation loss: 2.023601879676183

Epoch: 131| Step: 0
Training loss: 1.8663066625595093
Validation loss: 2.0277306040128074

Epoch: 5| Step: 1
Training loss: 2.012974262237549
Validation loss: 2.0297977974017463

Epoch: 5| Step: 2
Training loss: 2.0604088306427
Validation loss: 2.0409144361813865

Epoch: 5| Step: 3
Training loss: 2.7479705810546875
Validation loss: 2.0388360619544983

Epoch: 5| Step: 4
Training loss: 2.3523528575897217
Validation loss: 2.05387951930364

Epoch: 5| Step: 5
Training loss: 1.8410279750823975
Validation loss: 2.0490307956933975

Epoch: 5| Step: 6
Training loss: 1.9394127130508423
Validation loss: 2.0592050005992255

Epoch: 5| Step: 7
Training loss: 2.623142957687378
Validation loss: 2.0646203060944877

Epoch: 5| Step: 8
Training loss: 1.945760726928711
Validation loss: 2.0555159797271094

Epoch: 5| Step: 9
Training loss: 1.886117935180664
Validation loss: 2.0491732160250344

Epoch: 5| Step: 10
Training loss: 1.987696647644043
Validation loss: 2.036114662885666

Epoch: 5| Step: 11
Training loss: 1.4652292728424072
Validation loss: 2.0319781601428986

Epoch: 132| Step: 0
Training loss: 2.244966506958008
Validation loss: 2.0293790300687156

Epoch: 5| Step: 1
Training loss: 2.076387882232666
Validation loss: 2.0281981577475867

Epoch: 5| Step: 2
Training loss: 1.9413814544677734
Validation loss: 2.029121329387029

Epoch: 5| Step: 3
Training loss: 1.9961118698120117
Validation loss: 2.026809900999069

Epoch: 5| Step: 4
Training loss: 2.163501262664795
Validation loss: 2.03207499285539

Epoch: 5| Step: 5
Training loss: 2.1780340671539307
Validation loss: 2.033027172088623

Epoch: 5| Step: 6
Training loss: 2.2786943912506104
Validation loss: 2.0355074405670166

Epoch: 5| Step: 7
Training loss: 1.936914086341858
Validation loss: 2.021849344174067

Epoch: 5| Step: 8
Training loss: 1.7290210723876953
Validation loss: 2.032616009314855

Epoch: 5| Step: 9
Training loss: 2.0927791595458984
Validation loss: 2.0285986264546714

Epoch: 5| Step: 10
Training loss: 2.328479051589966
Validation loss: 2.0237287282943726

Epoch: 5| Step: 11
Training loss: 2.4485559463500977
Validation loss: 2.047083482146263

Epoch: 133| Step: 0
Training loss: 1.8748939037322998
Validation loss: 2.0376313626766205

Epoch: 5| Step: 1
Training loss: 2.4607174396514893
Validation loss: 2.019466628630956

Epoch: 5| Step: 2
Training loss: 2.566828966140747
Validation loss: 2.0230492105086646

Epoch: 5| Step: 3
Training loss: 1.8942844867706299
Validation loss: 2.023456091682116

Epoch: 5| Step: 4
Training loss: 2.262859344482422
Validation loss: 2.021947751442591

Epoch: 5| Step: 5
Training loss: 2.5283050537109375
Validation loss: 2.020560085773468

Epoch: 5| Step: 6
Training loss: 2.0291647911071777
Validation loss: 2.024683877825737

Epoch: 5| Step: 7
Training loss: 2.1357734203338623
Validation loss: 2.019867276151975

Epoch: 5| Step: 8
Training loss: 1.3781185150146484
Validation loss: 2.028203268845876

Epoch: 5| Step: 9
Training loss: 1.571665644645691
Validation loss: 2.030177891254425

Epoch: 5| Step: 10
Training loss: 1.8851110935211182
Validation loss: 2.032875915368398

Epoch: 5| Step: 11
Training loss: 3.679825782775879
Validation loss: 2.035731573899587

Epoch: 134| Step: 0
Training loss: 2.0786004066467285
Validation loss: 2.031385153532028

Epoch: 5| Step: 1
Training loss: 2.184242010116577
Validation loss: 2.0252917359272637

Epoch: 5| Step: 2
Training loss: 1.833390235900879
Validation loss: 2.0267936487992606

Epoch: 5| Step: 3
Training loss: 2.0330452919006348
Validation loss: 2.0268672009309134

Epoch: 5| Step: 4
Training loss: 1.9973875284194946
Validation loss: 2.020473842819532

Epoch: 5| Step: 5
Training loss: 2.4282212257385254
Validation loss: 2.0326360166072845

Epoch: 5| Step: 6
Training loss: 2.275001049041748
Validation loss: 2.0330266108115516

Epoch: 5| Step: 7
Training loss: 2.2033214569091797
Validation loss: 2.0367329120635986

Epoch: 5| Step: 8
Training loss: 2.1117637157440186
Validation loss: 2.0345803250869117

Epoch: 5| Step: 9
Training loss: 1.8933336734771729
Validation loss: 2.048378308614095

Epoch: 5| Step: 10
Training loss: 2.2410292625427246
Validation loss: 2.046726862589518

Epoch: 5| Step: 11
Training loss: 0.7939186096191406
Validation loss: 2.0519487410783768

Epoch: 135| Step: 0
Training loss: 1.7434673309326172
Validation loss: 2.047471592823664

Epoch: 5| Step: 1
Training loss: 2.1545562744140625
Validation loss: 2.0493532568216324

Epoch: 5| Step: 2
Training loss: 2.6003286838531494
Validation loss: 2.04534782965978

Epoch: 5| Step: 3
Training loss: 2.241960287094116
Validation loss: 2.0367601613203683

Epoch: 5| Step: 4
Training loss: 2.3332607746124268
Validation loss: 2.031263808409373

Epoch: 5| Step: 5
Training loss: 1.8265247344970703
Validation loss: 2.0312391817569733

Epoch: 5| Step: 6
Training loss: 2.2579615116119385
Validation loss: 2.0339042395353317

Epoch: 5| Step: 7
Training loss: 1.926688551902771
Validation loss: 2.0247474958499274

Epoch: 5| Step: 8
Training loss: 1.8997701406478882
Validation loss: 2.03293439745903

Epoch: 5| Step: 9
Training loss: 1.579935073852539
Validation loss: 2.0314874748388925

Epoch: 5| Step: 10
Training loss: 2.408175468444824
Validation loss: 2.035589267810186

Epoch: 5| Step: 11
Training loss: 2.7733969688415527
Validation loss: 2.0386259059111276

Epoch: 136| Step: 0
Training loss: 2.30051851272583
Validation loss: 2.034733086824417

Epoch: 5| Step: 1
Training loss: 2.367701292037964
Validation loss: 2.0314964652061462

Epoch: 5| Step: 2
Training loss: 2.058178424835205
Validation loss: 2.0314322412014008

Epoch: 5| Step: 3
Training loss: 1.7039053440093994
Validation loss: 2.036741172273954

Epoch: 5| Step: 4
Training loss: 1.953763723373413
Validation loss: 2.0271657506624856

Epoch: 5| Step: 5
Training loss: 2.2475178241729736
Validation loss: 2.038749262690544

Epoch: 5| Step: 6
Training loss: 1.7389450073242188
Validation loss: 2.039466549952825

Epoch: 5| Step: 7
Training loss: 2.5348238945007324
Validation loss: 2.0576165318489075

Epoch: 5| Step: 8
Training loss: 2.1938834190368652
Validation loss: 2.0675892929236093

Epoch: 5| Step: 9
Training loss: 1.899449110031128
Validation loss: 2.055236265063286

Epoch: 5| Step: 10
Training loss: 2.099879026412964
Validation loss: 2.052705133954684

Epoch: 5| Step: 11
Training loss: 2.092707633972168
Validation loss: 2.0471038222312927

Epoch: 137| Step: 0
Training loss: 2.026674747467041
Validation loss: 2.0424903134504953

Epoch: 5| Step: 1
Training loss: 1.7742061614990234
Validation loss: 2.0296014100313187

Epoch: 5| Step: 2
Training loss: 2.039226770401001
Validation loss: 2.035623292128245

Epoch: 5| Step: 3
Training loss: 1.947248101234436
Validation loss: 2.0395453770955405

Epoch: 5| Step: 4
Training loss: 2.253962993621826
Validation loss: 2.028716911872228

Epoch: 5| Step: 5
Training loss: 2.3863940238952637
Validation loss: 2.0391016006469727

Epoch: 5| Step: 6
Training loss: 2.0269336700439453
Validation loss: 2.0409662822882333

Epoch: 5| Step: 7
Training loss: 2.0678932666778564
Validation loss: 2.0397526373465857

Epoch: 5| Step: 8
Training loss: 1.9846919775009155
Validation loss: 2.034229298432668

Epoch: 5| Step: 9
Training loss: 2.1380176544189453
Validation loss: 2.0407885313034058

Epoch: 5| Step: 10
Training loss: 2.473215103149414
Validation loss: 2.0249373813470206

Epoch: 5| Step: 11
Training loss: 1.395503282546997
Validation loss: 2.0294327239195504

Epoch: 138| Step: 0
Training loss: 1.6645984649658203
Validation loss: 2.0233431855837503

Epoch: 5| Step: 1
Training loss: 1.7087873220443726
Validation loss: 2.0226250986258187

Epoch: 5| Step: 2
Training loss: 2.382779598236084
Validation loss: 2.0231898923714957

Epoch: 5| Step: 3
Training loss: 2.0467312335968018
Validation loss: 2.0198542922735214

Epoch: 5| Step: 4
Training loss: 2.2399494647979736
Validation loss: 2.02158156534036

Epoch: 5| Step: 5
Training loss: 2.9523017406463623
Validation loss: 2.020587687691053

Epoch: 5| Step: 6
Training loss: 2.8380141258239746
Validation loss: 2.0244399110476174

Epoch: 5| Step: 7
Training loss: 1.9598915576934814
Validation loss: 2.0321393062671027

Epoch: 5| Step: 8
Training loss: 1.8230276107788086
Validation loss: 2.023249715566635

Epoch: 5| Step: 9
Training loss: 1.8213040828704834
Validation loss: 2.0269190122683844

Epoch: 5| Step: 10
Training loss: 1.6024744510650635
Validation loss: 2.047062794367472

Epoch: 5| Step: 11
Training loss: 1.3543938398361206
Validation loss: 2.054409076770147

Epoch: 139| Step: 0
Training loss: 1.988732099533081
Validation loss: 2.077382410566012

Epoch: 5| Step: 1
Training loss: 2.634923219680786
Validation loss: 2.0923685232798257

Epoch: 5| Step: 2
Training loss: 2.1736018657684326
Validation loss: 2.115300883849462

Epoch: 5| Step: 3
Training loss: 1.8852484226226807
Validation loss: 2.116629128654798

Epoch: 5| Step: 4
Training loss: 1.7003440856933594
Validation loss: 2.103183244665464

Epoch: 5| Step: 5
Training loss: 2.136272430419922
Validation loss: 2.0984938889741898

Epoch: 5| Step: 6
Training loss: 2.1626741886138916
Validation loss: 2.0858784914016724

Epoch: 5| Step: 7
Training loss: 2.1878914833068848
Validation loss: 2.054697945713997

Epoch: 5| Step: 8
Training loss: 2.157794952392578
Validation loss: 2.036220063765844

Epoch: 5| Step: 9
Training loss: 1.9916967153549194
Validation loss: 2.026230752468109

Epoch: 5| Step: 10
Training loss: 1.946518898010254
Validation loss: 2.0162961035966873

Epoch: 5| Step: 11
Training loss: 2.8307113647460938
Validation loss: 2.0103424340486526

Epoch: 140| Step: 0
Training loss: 2.5723800659179688
Validation loss: 2.015528549750646

Epoch: 5| Step: 1
Training loss: 2.3667407035827637
Validation loss: 2.0141972402731576

Epoch: 5| Step: 2
Training loss: 1.9877784252166748
Validation loss: 2.0137702425320945

Epoch: 5| Step: 3
Training loss: 2.182607650756836
Validation loss: 2.0152961015701294

Epoch: 5| Step: 4
Training loss: 2.056292772293091
Validation loss: 2.0216155499219894

Epoch: 5| Step: 5
Training loss: 2.0267863273620605
Validation loss: 2.014783635735512

Epoch: 5| Step: 6
Training loss: 2.30391788482666
Validation loss: 2.012940918405851

Epoch: 5| Step: 7
Training loss: 2.3212833404541016
Validation loss: 1.9983621140321095

Epoch: 5| Step: 8
Training loss: 1.9040292501449585
Validation loss: 2.007290388147036

Epoch: 5| Step: 9
Training loss: 1.7247555255889893
Validation loss: 2.0160999993483224

Epoch: 5| Step: 10
Training loss: 1.8705222606658936
Validation loss: 2.029743174711863

Epoch: 5| Step: 11
Training loss: 1.7943555116653442
Validation loss: 2.032605364918709

Epoch: 141| Step: 0
Training loss: 1.4977976083755493
Validation loss: 2.047801891962687

Epoch: 5| Step: 1
Training loss: 1.6757233142852783
Validation loss: 2.0459328393141427

Epoch: 5| Step: 2
Training loss: 2.0567307472229004
Validation loss: 2.043638527393341

Epoch: 5| Step: 3
Training loss: 1.6741416454315186
Validation loss: 2.0309876650571823

Epoch: 5| Step: 4
Training loss: 2.0173089504241943
Validation loss: 2.022056832909584

Epoch: 5| Step: 5
Training loss: 2.39189076423645
Validation loss: 2.017106225093206

Epoch: 5| Step: 6
Training loss: 2.618617534637451
Validation loss: 2.0213818748792014

Epoch: 5| Step: 7
Training loss: 2.1452267169952393
Validation loss: 2.0158702433109283

Epoch: 5| Step: 8
Training loss: 2.0518441200256348
Validation loss: 2.0092123548189798

Epoch: 5| Step: 9
Training loss: 2.5513267517089844
Validation loss: 2.010654146472613

Epoch: 5| Step: 10
Training loss: 2.2215988636016846
Validation loss: 2.0089621394872665

Epoch: 5| Step: 11
Training loss: 2.46537446975708
Validation loss: 2.010015254219373

Epoch: 142| Step: 0
Training loss: 1.914467453956604
Validation loss: 2.013632302482923

Epoch: 5| Step: 1
Training loss: 1.5170551538467407
Validation loss: 2.029389351606369

Epoch: 5| Step: 2
Training loss: 1.3615044355392456
Validation loss: 2.038856938481331

Epoch: 5| Step: 3
Training loss: 2.421268939971924
Validation loss: 2.052706703543663

Epoch: 5| Step: 4
Training loss: 2.401000499725342
Validation loss: 2.0625012516975403

Epoch: 5| Step: 5
Training loss: 2.06526517868042
Validation loss: 2.06609516342481

Epoch: 5| Step: 6
Training loss: 2.6446382999420166
Validation loss: 2.050734872619311

Epoch: 5| Step: 7
Training loss: 2.375697374343872
Validation loss: 2.055761381983757

Epoch: 5| Step: 8
Training loss: 1.8944408893585205
Validation loss: 2.061765452226003

Epoch: 5| Step: 9
Training loss: 2.429002523422241
Validation loss: 2.0486497282981873

Epoch: 5| Step: 10
Training loss: 2.2168571949005127
Validation loss: 2.0466637164354324

Epoch: 5| Step: 11
Training loss: 1.0730836391448975
Validation loss: 2.03669536113739

Epoch: 143| Step: 0
Training loss: 1.8349250555038452
Validation loss: 2.0426308810710907

Epoch: 5| Step: 1
Training loss: 1.8296998739242554
Validation loss: 2.040809993942579

Epoch: 5| Step: 2
Training loss: 2.12420916557312
Validation loss: 2.037595550219218

Epoch: 5| Step: 3
Training loss: 2.556117296218872
Validation loss: 2.0298499166965485

Epoch: 5| Step: 4
Training loss: 2.0285511016845703
Validation loss: 2.025560493270556

Epoch: 5| Step: 5
Training loss: 1.777395248413086
Validation loss: 2.024155562122663

Epoch: 5| Step: 6
Training loss: 2.0048635005950928
Validation loss: 2.0261327673991523

Epoch: 5| Step: 7
Training loss: 2.5792224407196045
Validation loss: 2.0307850490013757

Epoch: 5| Step: 8
Training loss: 2.039263963699341
Validation loss: 2.033795863389969

Epoch: 5| Step: 9
Training loss: 2.0273067951202393
Validation loss: 2.0418788492679596

Epoch: 5| Step: 10
Training loss: 2.026973247528076
Validation loss: 2.0293393433094025

Epoch: 5| Step: 11
Training loss: 2.905269145965576
Validation loss: 2.029670054713885

Epoch: 144| Step: 0
Training loss: 2.20214581489563
Validation loss: 2.0550034095843634

Epoch: 5| Step: 1
Training loss: 1.6257236003875732
Validation loss: 2.0749298731486

Epoch: 5| Step: 2
Training loss: 2.4142801761627197
Validation loss: 2.131135200460752

Epoch: 5| Step: 3
Training loss: 2.127202272415161
Validation loss: 2.17847116291523

Epoch: 5| Step: 4
Training loss: 2.2718780040740967
Validation loss: 2.180356020728747

Epoch: 5| Step: 5
Training loss: 2.5536141395568848
Validation loss: 2.1544796029726663

Epoch: 5| Step: 6
Training loss: 2.4712915420532227
Validation loss: 2.1582750578721366

Epoch: 5| Step: 7
Training loss: 1.8587265014648438
Validation loss: 2.1322526931762695

Epoch: 5| Step: 8
Training loss: 2.1237587928771973
Validation loss: 2.136594384908676

Epoch: 5| Step: 9
Training loss: 2.2097792625427246
Validation loss: 2.101200059056282

Epoch: 5| Step: 10
Training loss: 1.8949110507965088
Validation loss: 2.101694588859876

Epoch: 5| Step: 11
Training loss: 1.4673784971237183
Validation loss: 2.060925379395485

Epoch: 145| Step: 0
Training loss: 2.138803720474243
Validation loss: 2.044604460398356

Epoch: 5| Step: 1
Training loss: 1.7777938842773438
Validation loss: 2.029240444302559

Epoch: 5| Step: 2
Training loss: 2.532963275909424
Validation loss: 2.024814094106356

Epoch: 5| Step: 3
Training loss: 2.385005235671997
Validation loss: 2.028053065141042

Epoch: 5| Step: 4
Training loss: 2.0283122062683105
Validation loss: 2.026246969898542

Epoch: 5| Step: 5
Training loss: 2.4381115436553955
Validation loss: 2.0327889223893485

Epoch: 5| Step: 6
Training loss: 1.7066586017608643
Validation loss: 2.0305552780628204

Epoch: 5| Step: 7
Training loss: 1.7516734600067139
Validation loss: 2.03634845217069

Epoch: 5| Step: 8
Training loss: 2.699406385421753
Validation loss: 2.0287171602249146

Epoch: 5| Step: 9
Training loss: 2.1680550575256348
Validation loss: 2.0260741263628006

Epoch: 5| Step: 10
Training loss: 1.7805309295654297
Validation loss: 2.024246484041214

Epoch: 5| Step: 11
Training loss: 1.8499784469604492
Validation loss: 2.0282271752754846

Epoch: 146| Step: 0
Training loss: 1.6768455505371094
Validation loss: 2.0285844653844833

Epoch: 5| Step: 1
Training loss: 2.2947134971618652
Validation loss: 2.0295737584431968

Epoch: 5| Step: 2
Training loss: 1.9901689291000366
Validation loss: 2.035023724039396

Epoch: 5| Step: 3
Training loss: 2.307039499282837
Validation loss: 2.0507038285334906

Epoch: 5| Step: 4
Training loss: 2.5367271900177
Validation loss: 2.058492441972097

Epoch: 5| Step: 5
Training loss: 1.4574382305145264
Validation loss: 2.0596243093411126

Epoch: 5| Step: 6
Training loss: 1.8050695657730103
Validation loss: 2.0771294136842093

Epoch: 5| Step: 7
Training loss: 1.872976303100586
Validation loss: 2.103070323665937

Epoch: 5| Step: 8
Training loss: 1.9127552509307861
Validation loss: 2.1021124720573425

Epoch: 5| Step: 9
Training loss: 2.430331230163574
Validation loss: 2.116803149382273

Epoch: 5| Step: 10
Training loss: 2.796593427658081
Validation loss: 2.121869678298632

Epoch: 5| Step: 11
Training loss: 0.8604896068572998
Validation loss: 2.1294599721829095

Epoch: 147| Step: 0
Training loss: 1.377655267715454
Validation loss: 2.112377569079399

Epoch: 5| Step: 1
Training loss: 2.2577431201934814
Validation loss: 2.1083338260650635

Epoch: 5| Step: 2
Training loss: 2.0494961738586426
Validation loss: 2.0922942409912744

Epoch: 5| Step: 3
Training loss: 2.6530661582946777
Validation loss: 2.090942899386088

Epoch: 5| Step: 4
Training loss: 2.5312271118164062
Validation loss: 2.071777790784836

Epoch: 5| Step: 5
Training loss: 2.1948740482330322
Validation loss: 2.056973169247309

Epoch: 5| Step: 6
Training loss: 2.3394901752471924
Validation loss: 2.049265513817469

Epoch: 5| Step: 7
Training loss: 1.7021663188934326
Validation loss: 2.0293302784363427

Epoch: 5| Step: 8
Training loss: 1.9361803531646729
Validation loss: 2.028601219256719

Epoch: 5| Step: 9
Training loss: 1.6579616069793701
Validation loss: 2.029080639282862

Epoch: 5| Step: 10
Training loss: 2.3316783905029297
Validation loss: 2.0215232521295547

Epoch: 5| Step: 11
Training loss: 2.26936411857605
Validation loss: 2.0308769146601358

Epoch: 148| Step: 0
Training loss: 2.7944514751434326
Validation loss: 2.0317856073379517

Epoch: 5| Step: 1
Training loss: 2.5366859436035156
Validation loss: 2.038079639275869

Epoch: 5| Step: 2
Training loss: 2.031951427459717
Validation loss: 2.0324122607707977

Epoch: 5| Step: 3
Training loss: 1.9399915933609009
Validation loss: 2.033639962474505

Epoch: 5| Step: 4
Training loss: 1.9312083721160889
Validation loss: 2.035220896204313

Epoch: 5| Step: 5
Training loss: 2.15386700630188
Validation loss: 2.0265167206525803

Epoch: 5| Step: 6
Training loss: 2.1666054725646973
Validation loss: 2.0277116099993386

Epoch: 5| Step: 7
Training loss: 2.2922399044036865
Validation loss: 2.0294733146826425

Epoch: 5| Step: 8
Training loss: 1.582643747329712
Validation loss: 2.0211936136086783

Epoch: 5| Step: 9
Training loss: 1.7327232360839844
Validation loss: 2.026878386735916

Epoch: 5| Step: 10
Training loss: 1.8388595581054688
Validation loss: 2.0387016783157983

Epoch: 5| Step: 11
Training loss: 2.6946330070495605
Validation loss: 2.0525733480850854

Epoch: 149| Step: 0
Training loss: 2.913714647293091
Validation loss: 2.046408717830976

Epoch: 5| Step: 1
Training loss: 1.4890110492706299
Validation loss: 2.0493565599123635

Epoch: 5| Step: 2
Training loss: 1.6682207584381104
Validation loss: 2.046975006659826

Epoch: 5| Step: 3
Training loss: 1.9704704284667969
Validation loss: 2.0507752895355225

Epoch: 5| Step: 4
Training loss: 2.7817959785461426
Validation loss: 2.0451648583014808

Epoch: 5| Step: 5
Training loss: 1.9747798442840576
Validation loss: 2.0439403553803763

Epoch: 5| Step: 6
Training loss: 2.3249905109405518
Validation loss: 2.042150134841601

Epoch: 5| Step: 7
Training loss: 1.6770298480987549
Validation loss: 2.033711771170298

Epoch: 5| Step: 8
Training loss: 1.73434579372406
Validation loss: 2.036263237396876

Epoch: 5| Step: 9
Training loss: 2.4501101970672607
Validation loss: 2.043012246489525

Epoch: 5| Step: 10
Training loss: 1.811405897140503
Validation loss: 2.039866268634796

Epoch: 5| Step: 11
Training loss: 2.2538299560546875
Validation loss: 2.0430628259976706

Epoch: 150| Step: 0
Training loss: 2.2415051460266113
Validation loss: 2.053313056627909

Epoch: 5| Step: 1
Training loss: 1.7032766342163086
Validation loss: 2.064050073424975

Epoch: 5| Step: 2
Training loss: 2.193848133087158
Validation loss: 2.064946840206782

Epoch: 5| Step: 3
Training loss: 1.860175371170044
Validation loss: 2.0922417292992272

Epoch: 5| Step: 4
Training loss: 2.53210186958313
Validation loss: 2.1034310360749564

Epoch: 5| Step: 5
Training loss: 2.433900833129883
Validation loss: 2.099885885914167

Epoch: 5| Step: 6
Training loss: 1.9601538181304932
Validation loss: 2.1071372975905738

Epoch: 5| Step: 7
Training loss: 1.7974621057510376
Validation loss: 2.1188373615344367

Epoch: 5| Step: 8
Training loss: 2.2361533641815186
Validation loss: 2.101111908753713

Epoch: 5| Step: 9
Training loss: 2.0747227668762207
Validation loss: 2.08398267130057

Epoch: 5| Step: 10
Training loss: 1.8977057933807373
Validation loss: 2.062574873367945

Epoch: 5| Step: 11
Training loss: 2.265296459197998
Validation loss: 2.0591745724280677

Epoch: 151| Step: 0
Training loss: 1.6582458019256592
Validation loss: 2.0472321063280106

Epoch: 5| Step: 1
Training loss: 2.114964008331299
Validation loss: 2.028654625018438

Epoch: 5| Step: 2
Training loss: 2.4436869621276855
Validation loss: 2.0185275028149285

Epoch: 5| Step: 3
Training loss: 1.6751819849014282
Validation loss: 2.0154705146948495

Epoch: 5| Step: 4
Training loss: 2.1418023109436035
Validation loss: 2.0202993055184684

Epoch: 5| Step: 5
Training loss: 2.0235042572021484
Validation loss: 2.0161117166280746

Epoch: 5| Step: 6
Training loss: 2.2026190757751465
Validation loss: 2.0244734585285187

Epoch: 5| Step: 7
Training loss: 2.4393327236175537
Validation loss: 2.0289559761683145

Epoch: 5| Step: 8
Training loss: 2.4490253925323486
Validation loss: 2.0336197863022485

Epoch: 5| Step: 9
Training loss: 1.6224323511123657
Validation loss: 2.0378144085407257

Epoch: 5| Step: 10
Training loss: 2.0366203784942627
Validation loss: 2.0434161573648453

Epoch: 5| Step: 11
Training loss: 1.9559786319732666
Validation loss: 2.0464415500561395

Epoch: 152| Step: 0
Training loss: 1.8823623657226562
Validation loss: 2.0687408993641534

Epoch: 5| Step: 1
Training loss: 1.8636353015899658
Validation loss: 2.0745736360549927

Epoch: 5| Step: 2
Training loss: 2.426248073577881
Validation loss: 2.0922079732020697

Epoch: 5| Step: 3
Training loss: 2.164839267730713
Validation loss: 2.079303334156672

Epoch: 5| Step: 4
Training loss: 2.096054792404175
Validation loss: 2.08823299407959

Epoch: 5| Step: 5
Training loss: 1.7161157131195068
Validation loss: 2.0541630188624063

Epoch: 5| Step: 6
Training loss: 2.2371439933776855
Validation loss: 2.0631690422693887

Epoch: 5| Step: 7
Training loss: 2.345768451690674
Validation loss: 2.064281071225802

Epoch: 5| Step: 8
Training loss: 2.1512961387634277
Validation loss: 2.0756381203730903

Epoch: 5| Step: 9
Training loss: 2.0327658653259277
Validation loss: 2.062006543080012

Epoch: 5| Step: 10
Training loss: 2.0348174571990967
Validation loss: 2.0707610696554184

Epoch: 5| Step: 11
Training loss: 1.2288492918014526
Validation loss: 2.061628336707751

Epoch: 153| Step: 0
Training loss: 2.1099369525909424
Validation loss: 2.057460457086563

Epoch: 5| Step: 1
Training loss: 1.8996784687042236
Validation loss: 2.0461445401112237

Epoch: 5| Step: 2
Training loss: 1.9157406091690063
Validation loss: 2.03732339044412

Epoch: 5| Step: 3
Training loss: 2.1376521587371826
Validation loss: 2.031079019109408

Epoch: 5| Step: 4
Training loss: 2.3787643909454346
Validation loss: 2.0302310585975647

Epoch: 5| Step: 5
Training loss: 2.0051827430725098
Validation loss: 2.0273303190867105

Epoch: 5| Step: 6
Training loss: 2.326993465423584
Validation loss: 2.03122012813886

Epoch: 5| Step: 7
Training loss: 2.1335437297821045
Validation loss: 2.0351473887761435

Epoch: 5| Step: 8
Training loss: 1.7422754764556885
Validation loss: 2.030858596165975

Epoch: 5| Step: 9
Training loss: 2.4453377723693848
Validation loss: 2.0310520082712173

Epoch: 5| Step: 10
Training loss: 1.9787458181381226
Validation loss: 2.028706486026446

Epoch: 5| Step: 11
Training loss: 2.0884413719177246
Validation loss: 2.025275523463885

Epoch: 154| Step: 0
Training loss: 1.7954328060150146
Validation loss: 2.0271257708470025

Epoch: 5| Step: 1
Training loss: 2.125190019607544
Validation loss: 2.02241642276446

Epoch: 5| Step: 2
Training loss: 2.19659423828125
Validation loss: 2.0296815087397895

Epoch: 5| Step: 3
Training loss: 1.8529201745986938
Validation loss: 2.0354082385698953

Epoch: 5| Step: 4
Training loss: 2.2745323181152344
Validation loss: 2.03055747350057

Epoch: 5| Step: 5
Training loss: 2.0621273517608643
Validation loss: 2.0338919907808304

Epoch: 5| Step: 6
Training loss: 1.8435742855072021
Validation loss: 2.0291727085908255

Epoch: 5| Step: 7
Training loss: 2.5151448249816895
Validation loss: 2.0357794562975564

Epoch: 5| Step: 8
Training loss: 2.0813815593719482
Validation loss: 2.040602147579193

Epoch: 5| Step: 9
Training loss: 2.1964111328125
Validation loss: 2.0440450310707092

Epoch: 5| Step: 10
Training loss: 1.913397192955017
Validation loss: 2.0576747755209603

Epoch: 5| Step: 11
Training loss: 1.9714003801345825
Validation loss: 2.073294162750244

Epoch: 155| Step: 0
Training loss: 2.125384569168091
Validation loss: 2.0815648237864175

Epoch: 5| Step: 1
Training loss: 2.6678872108459473
Validation loss: 2.0814585785071054

Epoch: 5| Step: 2
Training loss: 2.0189414024353027
Validation loss: 2.0734801342089972

Epoch: 5| Step: 3
Training loss: 2.231661319732666
Validation loss: 2.0657644271850586

Epoch: 5| Step: 4
Training loss: 1.789797067642212
Validation loss: 2.05136771996816

Epoch: 5| Step: 5
Training loss: 1.7093496322631836
Validation loss: 2.048211614290873

Epoch: 5| Step: 6
Training loss: 1.532351016998291
Validation loss: 2.035905361175537

Epoch: 5| Step: 7
Training loss: 2.18485689163208
Validation loss: 2.042045091589292

Epoch: 5| Step: 8
Training loss: 2.462311029434204
Validation loss: 2.039905831217766

Epoch: 5| Step: 9
Training loss: 2.2288379669189453
Validation loss: 2.031606217225393

Epoch: 5| Step: 10
Training loss: 1.7673423290252686
Validation loss: 2.040964126586914

Epoch: 5| Step: 11
Training loss: 2.6251416206359863
Validation loss: 2.041298359632492

Epoch: 156| Step: 0
Training loss: 2.407677412033081
Validation loss: 2.0293232848246894

Epoch: 5| Step: 1
Training loss: 2.419668436050415
Validation loss: 2.031645546356837

Epoch: 5| Step: 2
Training loss: 1.9513657093048096
Validation loss: 2.0301018307606378

Epoch: 5| Step: 3
Training loss: 1.8746477365493774
Validation loss: 2.0374098469813666

Epoch: 5| Step: 4
Training loss: 2.664975643157959
Validation loss: 2.047267104188601

Epoch: 5| Step: 5
Training loss: 2.0980570316314697
Validation loss: 2.0335418482621512

Epoch: 5| Step: 6
Training loss: 1.7762291431427002
Validation loss: 2.0420382916927338

Epoch: 5| Step: 7
Training loss: 2.159447431564331
Validation loss: 2.0478382954994836

Epoch: 5| Step: 8
Training loss: 1.670142412185669
Validation loss: 2.057011062900225

Epoch: 5| Step: 9
Training loss: 1.699366807937622
Validation loss: 2.0782303164402642

Epoch: 5| Step: 10
Training loss: 1.7772077322006226
Validation loss: 2.0879082530736923

Epoch: 5| Step: 11
Training loss: 2.6556968688964844
Validation loss: 2.094420333703359

Epoch: 157| Step: 0
Training loss: 2.111342668533325
Validation loss: 2.0641983300447464

Epoch: 5| Step: 1
Training loss: 1.778637170791626
Validation loss: 2.076925535996755

Epoch: 5| Step: 2
Training loss: 2.0812530517578125
Validation loss: 2.0687571416298547

Epoch: 5| Step: 3
Training loss: 1.8169937133789062
Validation loss: 2.0622627089420953

Epoch: 5| Step: 4
Training loss: 2.234408140182495
Validation loss: 2.0628457367420197

Epoch: 5| Step: 5
Training loss: 1.836281418800354
Validation loss: 2.041912019252777

Epoch: 5| Step: 6
Training loss: 2.490598678588867
Validation loss: 2.0488030314445496

Epoch: 5| Step: 7
Training loss: 2.101667881011963
Validation loss: 2.052692557374636

Epoch: 5| Step: 8
Training loss: 2.277873992919922
Validation loss: 2.057025363047918

Epoch: 5| Step: 9
Training loss: 1.7321316003799438
Validation loss: 2.0396419068177543

Epoch: 5| Step: 10
Training loss: 2.1171793937683105
Validation loss: 2.056538517276446

Epoch: 5| Step: 11
Training loss: 2.225368022918701
Validation loss: 2.047581066687902

Epoch: 158| Step: 0
Training loss: 2.2207961082458496
Validation loss: 2.0411399006843567

Epoch: 5| Step: 1
Training loss: 2.195518732070923
Validation loss: 2.0414802034695945

Epoch: 5| Step: 2
Training loss: 1.8811924457550049
Validation loss: 2.035143787662188

Epoch: 5| Step: 3
Training loss: 1.9323946237564087
Validation loss: 2.05362760523955

Epoch: 5| Step: 4
Training loss: 2.0544910430908203
Validation loss: 2.0541813373565674

Epoch: 5| Step: 5
Training loss: 1.972314476966858
Validation loss: 2.066278134783109

Epoch: 5| Step: 6
Training loss: 1.9283115863800049
Validation loss: 2.0606574565172195

Epoch: 5| Step: 7
Training loss: 2.0070998668670654
Validation loss: 2.0691125690937042

Epoch: 5| Step: 8
Training loss: 2.312788724899292
Validation loss: 2.0542050848404565

Epoch: 5| Step: 9
Training loss: 1.861215591430664
Validation loss: 2.06182994445165

Epoch: 5| Step: 10
Training loss: 1.9565629959106445
Validation loss: 2.0581440726915994

Epoch: 5| Step: 11
Training loss: 3.161454677581787
Validation loss: 2.054257407784462

Epoch: 159| Step: 0
Training loss: 1.6765626668930054
Validation loss: 2.0446590234835944

Epoch: 5| Step: 1
Training loss: 2.2614521980285645
Validation loss: 2.052930270632108

Epoch: 5| Step: 2
Training loss: 2.5137429237365723
Validation loss: 2.053610180815061

Epoch: 5| Step: 3
Training loss: 2.1685118675231934
Validation loss: 2.035896430412928

Epoch: 5| Step: 4
Training loss: 1.8345355987548828
Validation loss: 2.0478150993585587

Epoch: 5| Step: 5
Training loss: 2.0586228370666504
Validation loss: 2.0300850669542947

Epoch: 5| Step: 6
Training loss: 2.1241860389709473
Validation loss: 2.052461644013723

Epoch: 5| Step: 7
Training loss: 1.5963456630706787
Validation loss: 2.0488607237736383

Epoch: 5| Step: 8
Training loss: 2.292079448699951
Validation loss: 2.0612826198339462

Epoch: 5| Step: 9
Training loss: 2.0735981464385986
Validation loss: 2.0513537575801215

Epoch: 5| Step: 10
Training loss: 1.8843488693237305
Validation loss: 2.065909201900164

Epoch: 5| Step: 11
Training loss: 2.225904703140259
Validation loss: 2.0756001621484756

Epoch: 160| Step: 0
Training loss: 1.7194147109985352
Validation loss: 2.087646355231603

Epoch: 5| Step: 1
Training loss: 2.175476312637329
Validation loss: 2.0818299452463784

Epoch: 5| Step: 2
Training loss: 2.4340591430664062
Validation loss: 2.0850456108649573

Epoch: 5| Step: 3
Training loss: 1.843258261680603
Validation loss: 2.085889255007108

Epoch: 5| Step: 4
Training loss: 1.7414062023162842
Validation loss: 2.0679027885198593

Epoch: 5| Step: 5
Training loss: 2.0743913650512695
Validation loss: 2.074588338534037

Epoch: 5| Step: 6
Training loss: 2.237609624862671
Validation loss: 2.0833074202140174

Epoch: 5| Step: 7
Training loss: 2.043123960494995
Validation loss: 2.0800077617168427

Epoch: 5| Step: 8
Training loss: 2.147282600402832
Validation loss: 2.0684727976719537

Epoch: 5| Step: 9
Training loss: 2.110527515411377
Validation loss: 2.0588302363952002

Epoch: 5| Step: 10
Training loss: 2.1250758171081543
Validation loss: 2.051216950019201

Epoch: 5| Step: 11
Training loss: 1.2829017639160156
Validation loss: 2.041332190235456

Epoch: 161| Step: 0
Training loss: 1.6790517568588257
Validation loss: 2.036346743504206

Epoch: 5| Step: 1
Training loss: 2.3765501976013184
Validation loss: 2.0378390004237494

Epoch: 5| Step: 2
Training loss: 2.1985068321228027
Validation loss: 2.028189609448115

Epoch: 5| Step: 3
Training loss: 1.5379345417022705
Validation loss: 2.0330245792865753

Epoch: 5| Step: 4
Training loss: 2.512605667114258
Validation loss: 2.0366513778765998

Epoch: 5| Step: 5
Training loss: 2.142164945602417
Validation loss: 2.0291874607404075

Epoch: 5| Step: 6
Training loss: 1.4004243612289429
Validation loss: 2.0326568881670632

Epoch: 5| Step: 7
Training loss: 2.0335726737976074
Validation loss: 2.0495241284370422

Epoch: 5| Step: 8
Training loss: 1.885288953781128
Validation loss: 2.055819963415464

Epoch: 5| Step: 9
Training loss: 2.4046225547790527
Validation loss: 2.0598578403393426

Epoch: 5| Step: 10
Training loss: 2.420597553253174
Validation loss: 2.0630787909030914

Epoch: 5| Step: 11
Training loss: 2.2737133502960205
Validation loss: 2.0618196030457816

Epoch: 162| Step: 0
Training loss: 2.014709949493408
Validation loss: 2.068184033036232

Epoch: 5| Step: 1
Training loss: 2.1636338233947754
Validation loss: 2.0486036986112595

Epoch: 5| Step: 2
Training loss: 1.8381767272949219
Validation loss: 2.0532818088928857

Epoch: 5| Step: 3
Training loss: 1.683650255203247
Validation loss: 2.054991682370504

Epoch: 5| Step: 4
Training loss: 1.9285638332366943
Validation loss: 2.05679481724898

Epoch: 5| Step: 5
Training loss: 1.909691572189331
Validation loss: 2.0574847757816315

Epoch: 5| Step: 6
Training loss: 1.9697227478027344
Validation loss: 2.054279794295629

Epoch: 5| Step: 7
Training loss: 2.61722731590271
Validation loss: 2.044715772072474

Epoch: 5| Step: 8
Training loss: 1.499492883682251
Validation loss: 2.053611715634664

Epoch: 5| Step: 9
Training loss: 2.3571488857269287
Validation loss: 2.050757418076197

Epoch: 5| Step: 10
Training loss: 2.3162810802459717
Validation loss: 2.0379414707422256

Epoch: 5| Step: 11
Training loss: 2.511795997619629
Validation loss: 2.0455286850531897

Epoch: 163| Step: 0
Training loss: 2.131453037261963
Validation loss: 2.05596232910951

Epoch: 5| Step: 1
Training loss: 1.3642971515655518
Validation loss: 2.0565162698427835

Epoch: 5| Step: 2
Training loss: 1.9333213567733765
Validation loss: 2.0631655355294547

Epoch: 5| Step: 3
Training loss: 2.049649715423584
Validation loss: 2.066976790626844

Epoch: 5| Step: 4
Training loss: 1.6701122522354126
Validation loss: 2.0692939360936484

Epoch: 5| Step: 5
Training loss: 1.949444055557251
Validation loss: 2.0625137637058892

Epoch: 5| Step: 6
Training loss: 2.5032787322998047
Validation loss: 2.0683201402425766

Epoch: 5| Step: 7
Training loss: 2.412858247756958
Validation loss: 2.0720489422480264

Epoch: 5| Step: 8
Training loss: 2.206005573272705
Validation loss: 2.0762751499811807

Epoch: 5| Step: 9
Training loss: 2.1531739234924316
Validation loss: 2.0596780329942703

Epoch: 5| Step: 10
Training loss: 1.7207015752792358
Validation loss: 2.0633923510710397

Epoch: 5| Step: 11
Training loss: 2.294848918914795
Validation loss: 2.076415921250979

Epoch: 164| Step: 0
Training loss: 1.9353179931640625
Validation loss: 2.0757051209608712

Epoch: 5| Step: 1
Training loss: 1.9759366512298584
Validation loss: 2.0758290588855743

Epoch: 5| Step: 2
Training loss: 2.1360745429992676
Validation loss: 2.083633373181025

Epoch: 5| Step: 3
Training loss: 2.391267776489258
Validation loss: 2.0875403781731925

Epoch: 5| Step: 4
Training loss: 1.9059797525405884
Validation loss: 2.071861192584038

Epoch: 5| Step: 5
Training loss: 1.9851328134536743
Validation loss: 2.0692259867986045

Epoch: 5| Step: 6
Training loss: 2.153338670730591
Validation loss: 2.056972856322924

Epoch: 5| Step: 7
Training loss: 1.9986517429351807
Validation loss: 2.061692143479983

Epoch: 5| Step: 8
Training loss: 1.822786569595337
Validation loss: 2.050951754053434

Epoch: 5| Step: 9
Training loss: 2.2795252799987793
Validation loss: 2.0478459745645523

Epoch: 5| Step: 10
Training loss: 1.8704220056533813
Validation loss: 2.0342749853928885

Epoch: 5| Step: 11
Training loss: 2.0328612327575684
Validation loss: 2.0428651372591653

Epoch: 165| Step: 0
Training loss: 1.9013423919677734
Validation loss: 2.0384424030780792

Epoch: 5| Step: 1
Training loss: 2.2156639099121094
Validation loss: 2.03510390718778

Epoch: 5| Step: 2
Training loss: 2.0585644245147705
Validation loss: 2.036421626806259

Epoch: 5| Step: 3
Training loss: 2.6117377281188965
Validation loss: 2.047226995229721

Epoch: 5| Step: 4
Training loss: 2.4262473583221436
Validation loss: 2.037840336561203

Epoch: 5| Step: 5
Training loss: 1.7855157852172852
Validation loss: 2.0549018184343972

Epoch: 5| Step: 6
Training loss: 2.017972946166992
Validation loss: 2.048226942618688

Epoch: 5| Step: 7
Training loss: 2.0714194774627686
Validation loss: 2.044006352623304

Epoch: 5| Step: 8
Training loss: 1.7204551696777344
Validation loss: 2.057439232865969

Epoch: 5| Step: 9
Training loss: 1.8333419561386108
Validation loss: 2.0732049693663916

Epoch: 5| Step: 10
Training loss: 1.5962293148040771
Validation loss: 2.078267922004064

Epoch: 5| Step: 11
Training loss: 2.4034318923950195
Validation loss: 2.0779914806286492

Epoch: 166| Step: 0
Training loss: 1.788153886795044
Validation loss: 2.0731287399927774

Epoch: 5| Step: 1
Training loss: 2.304365396499634
Validation loss: 2.0619056771198907

Epoch: 5| Step: 2
Training loss: 2.4014954566955566
Validation loss: 2.064229597647985

Epoch: 5| Step: 3
Training loss: 2.1212384700775146
Validation loss: 2.0643733888864517

Epoch: 5| Step: 4
Training loss: 2.095569133758545
Validation loss: 2.0469658821821213

Epoch: 5| Step: 5
Training loss: 1.8902981281280518
Validation loss: 2.0382935454448066

Epoch: 5| Step: 6
Training loss: 2.001556873321533
Validation loss: 2.0396696080764136

Epoch: 5| Step: 7
Training loss: 2.092024326324463
Validation loss: 2.040611063440641

Epoch: 5| Step: 8
Training loss: 2.5419507026672363
Validation loss: 2.0396503657102585

Epoch: 5| Step: 9
Training loss: 1.903680443763733
Validation loss: 2.0413668056329093

Epoch: 5| Step: 10
Training loss: 1.7883793115615845
Validation loss: 2.0367981692155204

Epoch: 5| Step: 11
Training loss: 0.7453634738922119
Validation loss: 2.0468644152084985

Epoch: 167| Step: 0
Training loss: 2.2029097080230713
Validation loss: 2.04679644604524

Epoch: 5| Step: 1
Training loss: 2.085604190826416
Validation loss: 2.0780981282393136

Epoch: 5| Step: 2
Training loss: 2.1379201412200928
Validation loss: 2.066743637124697

Epoch: 5| Step: 3
Training loss: 2.4114990234375
Validation loss: 2.062515909473101

Epoch: 5| Step: 4
Training loss: 1.7303040027618408
Validation loss: 2.0819240560134253

Epoch: 5| Step: 5
Training loss: 1.8580129146575928
Validation loss: 2.065015052755674

Epoch: 5| Step: 6
Training loss: 2.485499858856201
Validation loss: 2.0701946516831717

Epoch: 5| Step: 7
Training loss: 1.755677580833435
Validation loss: 2.0713877926270166

Epoch: 5| Step: 8
Training loss: 1.7785313129425049
Validation loss: 2.059903770685196

Epoch: 5| Step: 9
Training loss: 1.871656060218811
Validation loss: 2.0584892630577087

Epoch: 5| Step: 10
Training loss: 2.0543365478515625
Validation loss: 2.062823474407196

Epoch: 5| Step: 11
Training loss: 2.7425498962402344
Validation loss: 2.063597097992897

Epoch: 168| Step: 0
Training loss: 2.2045516967773438
Validation loss: 2.069111386934916

Epoch: 5| Step: 1
Training loss: 1.8568201065063477
Validation loss: 2.0631797214349112

Epoch: 5| Step: 2
Training loss: 1.7258144617080688
Validation loss: 2.0707413405179977

Epoch: 5| Step: 3
Training loss: 2.1413536071777344
Validation loss: 2.0756521423657737

Epoch: 5| Step: 4
Training loss: 2.47833514213562
Validation loss: 2.064918706814448

Epoch: 5| Step: 5
Training loss: 1.7866134643554688
Validation loss: 2.0773599495490394

Epoch: 5| Step: 6
Training loss: 1.8470313549041748
Validation loss: 2.0724891126155853

Epoch: 5| Step: 7
Training loss: 1.7374448776245117
Validation loss: 2.074592957894007

Epoch: 5| Step: 8
Training loss: 1.82001531124115
Validation loss: 2.086232473452886

Epoch: 5| Step: 9
Training loss: 2.4180660247802734
Validation loss: 2.06552787621816

Epoch: 5| Step: 10
Training loss: 2.3473424911499023
Validation loss: 2.069167137145996

Epoch: 5| Step: 11
Training loss: 1.8702659606933594
Validation loss: 2.067113866408666

Epoch: 169| Step: 0
Training loss: 1.439818263053894
Validation loss: 2.0754853884379068

Epoch: 5| Step: 1
Training loss: 2.4425392150878906
Validation loss: 2.0840280006329217

Epoch: 5| Step: 2
Training loss: 2.279049873352051
Validation loss: 2.0761397878328958

Epoch: 5| Step: 3
Training loss: 1.655570387840271
Validation loss: 2.093140165011088

Epoch: 5| Step: 4
Training loss: 2.514348268508911
Validation loss: 2.086608091990153

Epoch: 5| Step: 5
Training loss: 2.5081334114074707
Validation loss: 2.0846047103405

Epoch: 5| Step: 6
Training loss: 1.8430331945419312
Validation loss: 2.0726959109306335

Epoch: 5| Step: 7
Training loss: 1.6608574390411377
Validation loss: 2.0699802935123444

Epoch: 5| Step: 8
Training loss: 2.2678258419036865
Validation loss: 2.0684649546941123

Epoch: 5| Step: 9
Training loss: 2.326904535293579
Validation loss: 2.0562366793553033

Epoch: 5| Step: 10
Training loss: 1.521831750869751
Validation loss: 2.0556525041659675

Epoch: 5| Step: 11
Training loss: 2.2172927856445312
Validation loss: 2.040787845849991

Epoch: 170| Step: 0
Training loss: 2.2485976219177246
Validation loss: 2.03482315937678

Epoch: 5| Step: 1
Training loss: 2.2215888500213623
Validation loss: 2.0401872098445892

Epoch: 5| Step: 2
Training loss: 1.9429305791854858
Validation loss: 2.040672332048416

Epoch: 5| Step: 3
Training loss: 2.081885576248169
Validation loss: 2.0390589982271194

Epoch: 5| Step: 4
Training loss: 1.9027175903320312
Validation loss: 2.0436916450659433

Epoch: 5| Step: 5
Training loss: 2.2020325660705566
Validation loss: 2.04624076684316

Epoch: 5| Step: 6
Training loss: 1.9256891012191772
Validation loss: 2.04068852464358

Epoch: 5| Step: 7
Training loss: 2.199631452560425
Validation loss: 2.0376799553632736

Epoch: 5| Step: 8
Training loss: 2.026546001434326
Validation loss: 2.0409559458494186

Epoch: 5| Step: 9
Training loss: 2.106409788131714
Validation loss: 2.0366598864396415

Epoch: 5| Step: 10
Training loss: 1.940537691116333
Validation loss: 2.0303078244129815

Epoch: 5| Step: 11
Training loss: 2.494582176208496
Validation loss: 2.030899832646052

Epoch: 171| Step: 0
Training loss: 2.037724018096924
Validation loss: 2.044408212105433

Epoch: 5| Step: 1
Training loss: 2.030961513519287
Validation loss: 2.0384438782930374

Epoch: 5| Step: 2
Training loss: 2.3999626636505127
Validation loss: 2.0618271827697754

Epoch: 5| Step: 3
Training loss: 1.9380714893341064
Validation loss: 2.068243225415548

Epoch: 5| Step: 4
Training loss: 1.918810486793518
Validation loss: 2.068557694554329

Epoch: 5| Step: 5
Training loss: 1.498430848121643
Validation loss: 2.043434113264084

Epoch: 5| Step: 6
Training loss: 2.1102542877197266
Validation loss: 2.0697215845187507

Epoch: 5| Step: 7
Training loss: 1.8230018615722656
Validation loss: 2.0685324470202127

Epoch: 5| Step: 8
Training loss: 2.2725486755371094
Validation loss: 2.081552435954412

Epoch: 5| Step: 9
Training loss: 2.4354002475738525
Validation loss: 2.0747526437044144

Epoch: 5| Step: 10
Training loss: 1.939389944076538
Validation loss: 2.090228796005249

Epoch: 5| Step: 11
Training loss: 2.665829658508301
Validation loss: 2.0883494516213736

Epoch: 172| Step: 0
Training loss: 2.2265143394470215
Validation loss: 2.092900718251864

Epoch: 5| Step: 1
Training loss: 2.3866941928863525
Validation loss: 2.0927237470944724

Epoch: 5| Step: 2
Training loss: 1.9490253925323486
Validation loss: 2.0884038557608924

Epoch: 5| Step: 3
Training loss: 2.182028293609619
Validation loss: 2.079746127128601

Epoch: 5| Step: 4
Training loss: 1.8084396123886108
Validation loss: 2.0707087318102517

Epoch: 5| Step: 5
Training loss: 1.8663718700408936
Validation loss: 2.073671832680702

Epoch: 5| Step: 6
Training loss: 1.6561228036880493
Validation loss: 2.0754383206367493

Epoch: 5| Step: 7
Training loss: 2.1385929584503174
Validation loss: 2.07219497859478

Epoch: 5| Step: 8
Training loss: 2.1686959266662598
Validation loss: 2.0738658209641776

Epoch: 5| Step: 9
Training loss: 1.7067219018936157
Validation loss: 2.0701186805963516

Epoch: 5| Step: 10
Training loss: 2.2286903858184814
Validation loss: 2.0675411770741143

Epoch: 5| Step: 11
Training loss: 1.3498802185058594
Validation loss: 2.066290413339933

Epoch: 173| Step: 0
Training loss: 1.6600459814071655
Validation loss: 2.071482722957929

Epoch: 5| Step: 1
Training loss: 1.7593994140625
Validation loss: 2.071727439761162

Epoch: 5| Step: 2
Training loss: 1.9783741235733032
Validation loss: 2.0831305931011834

Epoch: 5| Step: 3
Training loss: 2.5524513721466064
Validation loss: 2.087140997250875

Epoch: 5| Step: 4
Training loss: 2.104034900665283
Validation loss: 2.090714951356252

Epoch: 5| Step: 5
Training loss: 2.3776626586914062
Validation loss: 2.0952945550282798

Epoch: 5| Step: 6
Training loss: 1.9955995082855225
Validation loss: 2.095989132920901

Epoch: 5| Step: 7
Training loss: 1.6215689182281494
Validation loss: 2.1013671159744263

Epoch: 5| Step: 8
Training loss: 2.0067391395568848
Validation loss: 2.1041562805573144

Epoch: 5| Step: 9
Training loss: 1.8370918035507202
Validation loss: 2.086634556452433

Epoch: 5| Step: 10
Training loss: 2.3956055641174316
Validation loss: 2.1004712134599686

Epoch: 5| Step: 11
Training loss: 2.0948829650878906
Validation loss: 2.0885745088259378

Epoch: 174| Step: 0
Training loss: 1.627709984779358
Validation loss: 2.068479835987091

Epoch: 5| Step: 1
Training loss: 1.467175006866455
Validation loss: 2.063174769282341

Epoch: 5| Step: 2
Training loss: 2.2690720558166504
Validation loss: 2.056083853046099

Epoch: 5| Step: 3
Training loss: 2.2393076419830322
Validation loss: 2.0421453615029654

Epoch: 5| Step: 4
Training loss: 2.4511141777038574
Validation loss: 2.032534991701444

Epoch: 5| Step: 5
Training loss: 1.578936219215393
Validation loss: 2.0385095874468484

Epoch: 5| Step: 6
Training loss: 2.2874951362609863
Validation loss: 2.0381655196348825

Epoch: 5| Step: 7
Training loss: 2.1817920207977295
Validation loss: 2.0352690716584525

Epoch: 5| Step: 8
Training loss: 2.0403831005096436
Validation loss: 2.038886532187462

Epoch: 5| Step: 9
Training loss: 1.9100908041000366
Validation loss: 2.0448647290468216

Epoch: 5| Step: 10
Training loss: 2.479031801223755
Validation loss: 2.045261765519778

Epoch: 5| Step: 11
Training loss: 2.331836223602295
Validation loss: 2.0544039756059647

Epoch: 175| Step: 0
Training loss: 2.015223979949951
Validation loss: 2.0639284004767737

Epoch: 5| Step: 1
Training loss: 2.2241406440734863
Validation loss: 2.0739190926154456

Epoch: 5| Step: 2
Training loss: 1.9432134628295898
Validation loss: 2.0686499724785485

Epoch: 5| Step: 3
Training loss: 1.8598663806915283
Validation loss: 2.080408255259196

Epoch: 5| Step: 4
Training loss: 1.9077818393707275
Validation loss: 2.071306675672531

Epoch: 5| Step: 5
Training loss: 1.4891716241836548
Validation loss: 2.088011622428894

Epoch: 5| Step: 6
Training loss: 2.696218729019165
Validation loss: 2.094852477312088

Epoch: 5| Step: 7
Training loss: 2.200221300125122
Validation loss: 2.079695830742518

Epoch: 5| Step: 8
Training loss: 2.168710231781006
Validation loss: 2.085922355453173

Epoch: 5| Step: 9
Training loss: 1.671476125717163
Validation loss: 2.072322721282641

Epoch: 5| Step: 10
Training loss: 1.8994572162628174
Validation loss: 2.07250984509786

Epoch: 5| Step: 11
Training loss: 2.265653610229492
Validation loss: 2.0654617697000504

Epoch: 176| Step: 0
Training loss: 1.9186853170394897
Validation loss: 2.070485865076383

Epoch: 5| Step: 1
Training loss: 1.9823627471923828
Validation loss: 2.0547470500071845

Epoch: 5| Step: 2
Training loss: 1.7426506280899048
Validation loss: 2.061622048417727

Epoch: 5| Step: 3
Training loss: 2.4419753551483154
Validation loss: 2.0603145211935043

Epoch: 5| Step: 4
Training loss: 1.301189661026001
Validation loss: 2.060982863108317

Epoch: 5| Step: 5
Training loss: 2.1955106258392334
Validation loss: 2.062108298142751

Epoch: 5| Step: 6
Training loss: 2.513054370880127
Validation loss: 2.060366998116175

Epoch: 5| Step: 7
Training loss: 1.5950274467468262
Validation loss: 2.0665236860513687

Epoch: 5| Step: 8
Training loss: 1.8186153173446655
Validation loss: 2.068486894170443

Epoch: 5| Step: 9
Training loss: 2.254683494567871
Validation loss: 2.086294407645861

Epoch: 5| Step: 10
Training loss: 2.181311845779419
Validation loss: 2.0878203958272934

Epoch: 5| Step: 11
Training loss: 2.9299492835998535
Validation loss: 2.0781177332003913

Epoch: 177| Step: 0
Training loss: 2.1886260509490967
Validation loss: 2.0780696123838425

Epoch: 5| Step: 1
Training loss: 1.7360016107559204
Validation loss: 2.076800763607025

Epoch: 5| Step: 2
Training loss: 2.134096145629883
Validation loss: 2.0774002075195312

Epoch: 5| Step: 3
Training loss: 1.2766666412353516
Validation loss: 2.077949563662211

Epoch: 5| Step: 4
Training loss: 2.1325416564941406
Validation loss: 2.0670523097117743

Epoch: 5| Step: 5
Training loss: 2.180037260055542
Validation loss: 2.0713652620712915

Epoch: 5| Step: 6
Training loss: 2.047654151916504
Validation loss: 2.071864585081736

Epoch: 5| Step: 7
Training loss: 2.1745543479919434
Validation loss: 2.0684979309638343

Epoch: 5| Step: 8
Training loss: 1.6061136722564697
Validation loss: 2.0688279072443643

Epoch: 5| Step: 9
Training loss: 2.5768094062805176
Validation loss: 2.0567289690176644

Epoch: 5| Step: 10
Training loss: 2.030757427215576
Validation loss: 2.053121194243431

Epoch: 5| Step: 11
Training loss: 1.868207335472107
Validation loss: 2.0616963853438697

Epoch: 178| Step: 0
Training loss: 1.5848190784454346
Validation loss: 2.06881016989549

Epoch: 5| Step: 1
Training loss: 1.2295526266098022
Validation loss: 2.060210640231768

Epoch: 5| Step: 2
Training loss: 1.833683729171753
Validation loss: 2.0607848217089972

Epoch: 5| Step: 3
Training loss: 2.3171420097351074
Validation loss: 2.061591515938441

Epoch: 5| Step: 4
Training loss: 2.30234956741333
Validation loss: 2.0509051928917565

Epoch: 5| Step: 5
Training loss: 2.339202404022217
Validation loss: 2.0555557211240134

Epoch: 5| Step: 6
Training loss: 1.9674179553985596
Validation loss: 2.0756650269031525

Epoch: 5| Step: 7
Training loss: 2.2731850147247314
Validation loss: 2.0753576258818307

Epoch: 5| Step: 8
Training loss: 2.2375807762145996
Validation loss: 2.070887719591459

Epoch: 5| Step: 9
Training loss: 1.8206278085708618
Validation loss: 2.0927106042702994

Epoch: 5| Step: 10
Training loss: 2.187138080596924
Validation loss: 2.0943923890590668

Epoch: 5| Step: 11
Training loss: 1.7125964164733887
Validation loss: 2.08207838733991

Epoch: 179| Step: 0
Training loss: 1.74745774269104
Validation loss: 2.083991860349973

Epoch: 5| Step: 1
Training loss: 2.1855711936950684
Validation loss: 2.0896489371856055

Epoch: 5| Step: 2
Training loss: 2.104020833969116
Validation loss: 2.0726777066787085

Epoch: 5| Step: 3
Training loss: 2.3766329288482666
Validation loss: 2.0669306268294654

Epoch: 5| Step: 4
Training loss: 2.5021557807922363
Validation loss: 2.049626757701238

Epoch: 5| Step: 5
Training loss: 1.676257848739624
Validation loss: 2.0689507325490317

Epoch: 5| Step: 6
Training loss: 2.16875958442688
Validation loss: 2.051010246078173

Epoch: 5| Step: 7
Training loss: 1.819406270980835
Validation loss: 2.0514267086982727

Epoch: 5| Step: 8
Training loss: 1.6886953115463257
Validation loss: 2.0683358361323676

Epoch: 5| Step: 9
Training loss: 1.9219577312469482
Validation loss: 2.0645059843858085

Epoch: 5| Step: 10
Training loss: 2.3814597129821777
Validation loss: 2.0771040668090186

Epoch: 5| Step: 11
Training loss: 0.9697847366333008
Validation loss: 2.0674974570671716

Epoch: 180| Step: 0
Training loss: 1.5735591650009155
Validation loss: 2.056312695145607

Epoch: 5| Step: 1
Training loss: 2.358166456222534
Validation loss: 2.065634990731875

Epoch: 5| Step: 2
Training loss: 1.9108924865722656
Validation loss: 2.0629716962575912

Epoch: 5| Step: 3
Training loss: 1.4173452854156494
Validation loss: 2.064807112018267

Epoch: 5| Step: 4
Training loss: 1.9503257274627686
Validation loss: 2.0730567077795663

Epoch: 5| Step: 5
Training loss: 2.135956048965454
Validation loss: 2.0699303448200226

Epoch: 5| Step: 6
Training loss: 1.9892761707305908
Validation loss: 2.072816848754883

Epoch: 5| Step: 7
Training loss: 2.417485475540161
Validation loss: 2.072325477997462

Epoch: 5| Step: 8
Training loss: 1.9075157642364502
Validation loss: 2.070191433032354

Epoch: 5| Step: 9
Training loss: 2.0500717163085938
Validation loss: 2.072887400786082

Epoch: 5| Step: 10
Training loss: 2.3776049613952637
Validation loss: 2.0761266549428306

Epoch: 5| Step: 11
Training loss: 2.5409579277038574
Validation loss: 2.073368728160858

Epoch: 181| Step: 0
Training loss: 2.179611921310425
Validation loss: 2.059569517771403

Epoch: 5| Step: 1
Training loss: 2.162302255630493
Validation loss: 2.0562242716550827

Epoch: 5| Step: 2
Training loss: 1.6793127059936523
Validation loss: 2.0514473219712577

Epoch: 5| Step: 3
Training loss: 2.3766865730285645
Validation loss: 2.051325852672259

Epoch: 5| Step: 4
Training loss: 1.6443783044815063
Validation loss: 2.0499875595172248

Epoch: 5| Step: 5
Training loss: 2.3005967140197754
Validation loss: 2.0531292259693146

Epoch: 5| Step: 6
Training loss: 1.7092711925506592
Validation loss: 2.0390461136897406

Epoch: 5| Step: 7
Training loss: 2.462998151779175
Validation loss: 2.0460717231035233

Epoch: 5| Step: 8
Training loss: 2.1669974327087402
Validation loss: 2.0342764953772225

Epoch: 5| Step: 9
Training loss: 2.320435047149658
Validation loss: 2.038484940926234

Epoch: 5| Step: 10
Training loss: 2.2463207244873047
Validation loss: 2.040168950955073

Epoch: 5| Step: 11
Training loss: 1.8236795663833618
Validation loss: 2.0376447240511575

Epoch: 182| Step: 0
Training loss: 1.9337797164916992
Validation loss: 2.042083670695623

Epoch: 5| Step: 1
Training loss: 2.5234832763671875
Validation loss: 2.044434274236361

Epoch: 5| Step: 2
Training loss: 1.983901023864746
Validation loss: 2.0537663201491037

Epoch: 5| Step: 3
Training loss: 1.9450950622558594
Validation loss: 2.045739561319351

Epoch: 5| Step: 4
Training loss: 1.87526535987854
Validation loss: 2.05055000881354

Epoch: 5| Step: 5
Training loss: 2.3673255443573
Validation loss: 2.053386847178141

Epoch: 5| Step: 6
Training loss: 1.7043006420135498
Validation loss: 2.0641112526257834

Epoch: 5| Step: 7
Training loss: 2.064457416534424
Validation loss: 2.067828873793284

Epoch: 5| Step: 8
Training loss: 1.7730541229248047
Validation loss: 2.0644749899705253

Epoch: 5| Step: 9
Training loss: 2.5587821006774902
Validation loss: 2.0491487284501395

Epoch: 5| Step: 10
Training loss: 2.2031733989715576
Validation loss: 2.053026204307874

Epoch: 5| Step: 11
Training loss: 1.8279693126678467
Validation loss: 2.0724203238884606

Epoch: 183| Step: 0
Training loss: 1.4934712648391724
Validation loss: 2.0686706006526947

Epoch: 5| Step: 1
Training loss: 1.9952853918075562
Validation loss: 2.0736623456080756

Epoch: 5| Step: 2
Training loss: 2.0207996368408203
Validation loss: 2.0826013485590615

Epoch: 5| Step: 3
Training loss: 2.129822254180908
Validation loss: 2.0688864489396415

Epoch: 5| Step: 4
Training loss: 1.8425731658935547
Validation loss: 2.0702150762081146

Epoch: 5| Step: 5
Training loss: 2.2495360374450684
Validation loss: 2.0635895232359567

Epoch: 5| Step: 6
Training loss: 1.9523422718048096
Validation loss: 2.0706093311309814

Epoch: 5| Step: 7
Training loss: 2.175973892211914
Validation loss: 2.058797617753347

Epoch: 5| Step: 8
Training loss: 2.035118341445923
Validation loss: 2.0656295865774155

Epoch: 5| Step: 9
Training loss: 2.522988796234131
Validation loss: 2.0670148034890494

Epoch: 5| Step: 10
Training loss: 1.8983392715454102
Validation loss: 2.069271852572759

Epoch: 5| Step: 11
Training loss: 2.4352173805236816
Validation loss: 2.068242698907852

Epoch: 184| Step: 0
Training loss: 2.3396763801574707
Validation loss: 2.0801336665948233

Epoch: 5| Step: 1
Training loss: 2.18287992477417
Validation loss: 2.071128711104393

Epoch: 5| Step: 2
Training loss: 1.6484514474868774
Validation loss: 2.0833638856808343

Epoch: 5| Step: 3
Training loss: 1.754786491394043
Validation loss: 2.0859722197055817

Epoch: 5| Step: 4
Training loss: 2.0230743885040283
Validation loss: 2.0833931267261505

Epoch: 5| Step: 5
Training loss: 2.4444780349731445
Validation loss: 2.0814607987801232

Epoch: 5| Step: 6
Training loss: 1.9761947393417358
Validation loss: 2.078115130464236

Epoch: 5| Step: 7
Training loss: 2.4352622032165527
Validation loss: 2.0885507563749948

Epoch: 5| Step: 8
Training loss: 1.916866660118103
Validation loss: 2.1208950529495874

Epoch: 5| Step: 9
Training loss: 1.9374405145645142
Validation loss: 2.1108600993951163

Epoch: 5| Step: 10
Training loss: 1.7981979846954346
Validation loss: 2.11371581753095

Epoch: 5| Step: 11
Training loss: 0.8606564998626709
Validation loss: 2.121308038632075

Epoch: 185| Step: 0
Training loss: 1.5336086750030518
Validation loss: 2.13221404949824

Epoch: 5| Step: 1
Training loss: 2.616661310195923
Validation loss: 2.1264364620049796

Epoch: 5| Step: 2
Training loss: 2.0734505653381348
Validation loss: 2.122456729412079

Epoch: 5| Step: 3
Training loss: 2.136540651321411
Validation loss: 2.1086479127407074

Epoch: 5| Step: 4
Training loss: 1.977644681930542
Validation loss: 2.1220338692267737

Epoch: 5| Step: 5
Training loss: 1.6196749210357666
Validation loss: 2.105571066339811

Epoch: 5| Step: 6
Training loss: 1.867040991783142
Validation loss: 2.1104425291220346

Epoch: 5| Step: 7
Training loss: 2.056140899658203
Validation loss: 2.097596819202105

Epoch: 5| Step: 8
Training loss: 1.8568928241729736
Validation loss: 2.0938366055488586

Epoch: 5| Step: 9
Training loss: 2.12013840675354
Validation loss: 2.08724578221639

Epoch: 5| Step: 10
Training loss: 2.231109142303467
Validation loss: 2.0935623397429786

Epoch: 5| Step: 11
Training loss: 1.6101428270339966
Validation loss: 2.0802675684293113

Epoch: 186| Step: 0
Training loss: 2.25185489654541
Validation loss: 2.0817311902840934

Epoch: 5| Step: 1
Training loss: 2.0581717491149902
Validation loss: 2.0710629423459372

Epoch: 5| Step: 2
Training loss: 1.719177007675171
Validation loss: 2.082724407315254

Epoch: 5| Step: 3
Training loss: 2.126304864883423
Validation loss: 2.0904011527697244

Epoch: 5| Step: 4
Training loss: 2.1479926109313965
Validation loss: 2.1053358564774194

Epoch: 5| Step: 5
Training loss: 1.6702905893325806
Validation loss: 2.1106588343779245

Epoch: 5| Step: 6
Training loss: 1.4782999753952026
Validation loss: 2.1117046177387238

Epoch: 5| Step: 7
Training loss: 2.329613208770752
Validation loss: 2.1128820925951004

Epoch: 5| Step: 8
Training loss: 2.0021870136260986
Validation loss: 2.105929970741272

Epoch: 5| Step: 9
Training loss: 2.5884580612182617
Validation loss: 2.1126345495382943

Epoch: 5| Step: 10
Training loss: 1.574171543121338
Validation loss: 2.0889497150977454

Epoch: 5| Step: 11
Training loss: 2.2673635482788086
Validation loss: 2.093829706311226

Epoch: 187| Step: 0
Training loss: 1.888763427734375
Validation loss: 2.0978925625483194

Epoch: 5| Step: 1
Training loss: 1.640323281288147
Validation loss: 2.0948415249586105

Epoch: 5| Step: 2
Training loss: 1.8741556406021118
Validation loss: 2.1110593477884927

Epoch: 5| Step: 3
Training loss: 2.5349349975585938
Validation loss: 2.108967592318853

Epoch: 5| Step: 4
Training loss: 2.271467685699463
Validation loss: 2.10094886024793

Epoch: 5| Step: 5
Training loss: 2.148498058319092
Validation loss: 2.1106880952914557

Epoch: 5| Step: 6
Training loss: 1.66183602809906
Validation loss: 2.102830876906713

Epoch: 5| Step: 7
Training loss: 1.8999412059783936
Validation loss: 2.1043715129295983

Epoch: 5| Step: 8
Training loss: 1.8085076808929443
Validation loss: 2.099367136756579

Epoch: 5| Step: 9
Training loss: 2.131446361541748
Validation loss: 2.0967204868793488

Epoch: 5| Step: 10
Training loss: 2.1396987438201904
Validation loss: 2.092236747344335

Epoch: 5| Step: 11
Training loss: 1.853955626487732
Validation loss: 2.0893057386080423

Epoch: 188| Step: 0
Training loss: 1.7849235534667969
Validation loss: 2.05752066274484

Epoch: 5| Step: 1
Training loss: 1.7002627849578857
Validation loss: 2.0644902288913727

Epoch: 5| Step: 2
Training loss: 2.3282313346862793
Validation loss: 2.0557602643966675

Epoch: 5| Step: 3
Training loss: 1.6280629634857178
Validation loss: 2.0602015455563865

Epoch: 5| Step: 4
Training loss: 2.4161763191223145
Validation loss: 2.0625024239222207

Epoch: 5| Step: 5
Training loss: 2.2371790409088135
Validation loss: 2.0590587655703225

Epoch: 5| Step: 6
Training loss: 1.6376746892929077
Validation loss: 2.05983238418897

Epoch: 5| Step: 7
Training loss: 2.6630470752716064
Validation loss: 2.06399933497111

Epoch: 5| Step: 8
Training loss: 1.5253361463546753
Validation loss: 2.0626605252424874

Epoch: 5| Step: 9
Training loss: 2.317455291748047
Validation loss: 2.0847919285297394

Epoch: 5| Step: 10
Training loss: 1.9774668216705322
Validation loss: 2.0879043440024057

Epoch: 5| Step: 11
Training loss: 1.2801486253738403
Validation loss: 2.100959748029709

Epoch: 189| Step: 0
Training loss: 1.950068473815918
Validation loss: 2.1117423623800278

Epoch: 5| Step: 1
Training loss: 2.019939422607422
Validation loss: 2.1201916684707007

Epoch: 5| Step: 2
Training loss: 1.767163634300232
Validation loss: 2.1244389613469443

Epoch: 5| Step: 3
Training loss: 1.6680800914764404
Validation loss: 2.146898925304413

Epoch: 5| Step: 4
Training loss: 2.9878766536712646
Validation loss: 2.1558108727137246

Epoch: 5| Step: 5
Training loss: 2.2509913444519043
Validation loss: 2.135662923256556

Epoch: 5| Step: 6
Training loss: 2.2141060829162598
Validation loss: 2.1317490289608636

Epoch: 5| Step: 7
Training loss: 2.3427090644836426
Validation loss: 2.102732722957929

Epoch: 5| Step: 8
Training loss: 1.5704292058944702
Validation loss: 2.102292686700821

Epoch: 5| Step: 9
Training loss: 1.5050456523895264
Validation loss: 2.09002493818601

Epoch: 5| Step: 10
Training loss: 1.8590707778930664
Validation loss: 2.0767565170923867

Epoch: 5| Step: 11
Training loss: 2.8133678436279297
Validation loss: 2.0726528614759445

Epoch: 190| Step: 0
Training loss: 2.4380152225494385
Validation loss: 2.075127894679705

Epoch: 5| Step: 1
Training loss: 2.3181674480438232
Validation loss: 2.065351570645968

Epoch: 5| Step: 2
Training loss: 1.58400559425354
Validation loss: 2.059174582362175

Epoch: 5| Step: 3
Training loss: 2.16009783744812
Validation loss: 2.058800478776296

Epoch: 5| Step: 4
Training loss: 1.4919651746749878
Validation loss: 2.0562552958726883

Epoch: 5| Step: 5
Training loss: 2.515885353088379
Validation loss: 2.0562335153420768

Epoch: 5| Step: 6
Training loss: 2.399480104446411
Validation loss: 2.0630620568990707

Epoch: 5| Step: 7
Training loss: 1.84521484375
Validation loss: 2.066496709982554

Epoch: 5| Step: 8
Training loss: 1.6547126770019531
Validation loss: 2.069672296444575

Epoch: 5| Step: 9
Training loss: 2.519883632659912
Validation loss: 2.0806367148955665

Epoch: 5| Step: 10
Training loss: 1.398632526397705
Validation loss: 2.0775238325198493

Epoch: 5| Step: 11
Training loss: 1.6472735404968262
Validation loss: 2.0988663186629615

Epoch: 191| Step: 0
Training loss: 2.110340118408203
Validation loss: 2.113331660628319

Epoch: 5| Step: 1
Training loss: 1.7302430868148804
Validation loss: 2.124199683467547

Epoch: 5| Step: 2
Training loss: 1.947906732559204
Validation loss: 2.114909599224726

Epoch: 5| Step: 3
Training loss: 2.365110158920288
Validation loss: 2.121640125910441

Epoch: 5| Step: 4
Training loss: 2.0947229862213135
Validation loss: 2.1269584745168686

Epoch: 5| Step: 5
Training loss: 2.3220551013946533
Validation loss: 2.1199360887209573

Epoch: 5| Step: 6
Training loss: 1.850954294204712
Validation loss: 2.0961427887280784

Epoch: 5| Step: 7
Training loss: 2.042250871658325
Validation loss: 2.10055381556352

Epoch: 5| Step: 8
Training loss: 2.0692782402038574
Validation loss: 2.093728999296824

Epoch: 5| Step: 9
Training loss: 1.61544668674469
Validation loss: 2.104758302370707

Epoch: 5| Step: 10
Training loss: 2.0248942375183105
Validation loss: 2.096659153699875

Epoch: 5| Step: 11
Training loss: 1.465688943862915
Validation loss: 2.0885776430368423

Epoch: 192| Step: 0
Training loss: 2.0566534996032715
Validation loss: 2.0796770602464676

Epoch: 5| Step: 1
Training loss: 2.0560755729675293
Validation loss: 2.0668682952721915

Epoch: 5| Step: 2
Training loss: 2.0061657428741455
Validation loss: 2.065419708689054

Epoch: 5| Step: 3
Training loss: 2.0358688831329346
Validation loss: 2.074258213241895

Epoch: 5| Step: 4
Training loss: 1.6418962478637695
Validation loss: 2.065754617253939

Epoch: 5| Step: 5
Training loss: 2.189343214035034
Validation loss: 2.0696555574735007

Epoch: 5| Step: 6
Training loss: 1.9196449518203735
Validation loss: 2.0656908651192984

Epoch: 5| Step: 7
Training loss: 2.323173761367798
Validation loss: 2.0715912779172263

Epoch: 5| Step: 8
Training loss: 2.0307719707489014
Validation loss: 2.0680586993694305

Epoch: 5| Step: 9
Training loss: 2.448112726211548
Validation loss: 2.061347375313441

Epoch: 5| Step: 10
Training loss: 1.9699729681015015
Validation loss: 2.0701977064212165

Epoch: 5| Step: 11
Training loss: 1.8636140823364258
Validation loss: 2.0932896584272385

Epoch: 193| Step: 0
Training loss: 1.9344100952148438
Validation loss: 2.089253311355909

Epoch: 5| Step: 1
Training loss: 1.8773272037506104
Validation loss: 2.0885929415623345

Epoch: 5| Step: 2
Training loss: 1.687880277633667
Validation loss: 2.098708227276802

Epoch: 5| Step: 3
Training loss: 2.2494354248046875
Validation loss: 2.1164313654104867

Epoch: 5| Step: 4
Training loss: 2.205822467803955
Validation loss: 2.116246312856674

Epoch: 5| Step: 5
Training loss: 1.7781931161880493
Validation loss: 2.109152297178904

Epoch: 5| Step: 6
Training loss: 1.771977424621582
Validation loss: 2.1189370354016623

Epoch: 5| Step: 7
Training loss: 2.422776222229004
Validation loss: 2.114686061938604

Epoch: 5| Step: 8
Training loss: 2.51013445854187
Validation loss: 2.1276805102825165

Epoch: 5| Step: 9
Training loss: 1.584047794342041
Validation loss: 2.109079286456108

Epoch: 5| Step: 10
Training loss: 1.7432626485824585
Validation loss: 2.1052083174387612

Epoch: 5| Step: 11
Training loss: 3.0319113731384277
Validation loss: 2.10882838567098

Epoch: 194| Step: 0
Training loss: 2.33648943901062
Validation loss: 2.0952463100353875

Epoch: 5| Step: 1
Training loss: 1.5871877670288086
Validation loss: 2.0934828023115792

Epoch: 5| Step: 2
Training loss: 2.0736639499664307
Validation loss: 2.08458681901296

Epoch: 5| Step: 3
Training loss: 1.931182861328125
Validation loss: 2.0843570480744043

Epoch: 5| Step: 4
Training loss: 1.7386162281036377
Validation loss: 2.084313854575157

Epoch: 5| Step: 5
Training loss: 2.212573528289795
Validation loss: 2.0750800172487893

Epoch: 5| Step: 6
Training loss: 1.8429458141326904
Validation loss: 2.075763205687205

Epoch: 5| Step: 7
Training loss: 1.7403295040130615
Validation loss: 2.0694219718376794

Epoch: 5| Step: 8
Training loss: 2.183067798614502
Validation loss: 2.0737887720266976

Epoch: 5| Step: 9
Training loss: 2.2696080207824707
Validation loss: 2.079820826649666

Epoch: 5| Step: 10
Training loss: 2.0226759910583496
Validation loss: 2.0809388756752014

Epoch: 5| Step: 11
Training loss: 1.7885229587554932
Validation loss: 2.0825918217500052

Epoch: 195| Step: 0
Training loss: 2.349691152572632
Validation loss: 2.0900630950927734

Epoch: 5| Step: 1
Training loss: 2.020322799682617
Validation loss: 2.092148651679357

Epoch: 5| Step: 2
Training loss: 1.7026269435882568
Validation loss: 2.0874977161486945

Epoch: 5| Step: 3
Training loss: 1.837774634361267
Validation loss: 2.0977861930926642

Epoch: 5| Step: 4
Training loss: 2.560757875442505
Validation loss: 2.1122165669997535

Epoch: 5| Step: 5
Training loss: 1.5241832733154297
Validation loss: 2.1200845340887704

Epoch: 5| Step: 6
Training loss: 1.6881812810897827
Validation loss: 2.073367948333422

Epoch: 5| Step: 7
Training loss: 2.1818289756774902
Validation loss: 2.0761324216922126

Epoch: 5| Step: 8
Training loss: 2.461324453353882
Validation loss: 2.05335200826327

Epoch: 5| Step: 9
Training loss: 1.8560714721679688
Validation loss: 2.051434506972631

Epoch: 5| Step: 10
Training loss: 2.2461941242218018
Validation loss: 2.039344678322474

Epoch: 5| Step: 11
Training loss: 1.49800705909729
Validation loss: 2.0353812277317047

Epoch: 196| Step: 0
Training loss: 1.7478822469711304
Validation loss: 2.0506439010302224

Epoch: 5| Step: 1
Training loss: 2.2620837688446045
Validation loss: 2.0571965326865516

Epoch: 5| Step: 2
Training loss: 2.281775951385498
Validation loss: 2.043918624520302

Epoch: 5| Step: 3
Training loss: 1.8270946741104126
Validation loss: 2.0387972394625344

Epoch: 5| Step: 4
Training loss: 1.58356511592865
Validation loss: 2.045832003156344

Epoch: 5| Step: 5
Training loss: 2.6431548595428467
Validation loss: 2.0432538439830146

Epoch: 5| Step: 6
Training loss: 2.0246741771698
Validation loss: 2.0399430890878043

Epoch: 5| Step: 7
Training loss: 1.8668524026870728
Validation loss: 2.0468513717254004

Epoch: 5| Step: 8
Training loss: 1.8598401546478271
Validation loss: 2.0493543446063995

Epoch: 5| Step: 9
Training loss: 2.0516390800476074
Validation loss: 2.054040397206942

Epoch: 5| Step: 10
Training loss: 1.8586366176605225
Validation loss: 2.049680928389231

Epoch: 5| Step: 11
Training loss: 2.5088815689086914
Validation loss: 2.057953188816706

Epoch: 197| Step: 0
Training loss: 2.071235179901123
Validation loss: 2.055429677168528

Epoch: 5| Step: 1
Training loss: 2.0026984214782715
Validation loss: 2.061549256245295

Epoch: 5| Step: 2
Training loss: 1.6697765588760376
Validation loss: 2.0866011530160904

Epoch: 5| Step: 3
Training loss: 1.855144739151001
Validation loss: 2.082807868719101

Epoch: 5| Step: 4
Training loss: 2.3196158409118652
Validation loss: 2.0892366220553718

Epoch: 5| Step: 5
Training loss: 2.1571669578552246
Validation loss: 2.1048825879891715

Epoch: 5| Step: 6
Training loss: 1.7830810546875
Validation loss: 2.108978827794393

Epoch: 5| Step: 7
Training loss: 1.5804955959320068
Validation loss: 2.101560334364573

Epoch: 5| Step: 8
Training loss: 2.3851265907287598
Validation loss: 2.069850981235504

Epoch: 5| Step: 9
Training loss: 1.8341505527496338
Validation loss: 2.08084208269914

Epoch: 5| Step: 10
Training loss: 2.179286479949951
Validation loss: 2.0696571369965873

Epoch: 5| Step: 11
Training loss: 2.818331241607666
Validation loss: 2.077688773473104

Epoch: 198| Step: 0
Training loss: 1.8666635751724243
Validation loss: 2.0709965775410333

Epoch: 5| Step: 1
Training loss: 1.7014248371124268
Validation loss: 2.0717210421959558

Epoch: 5| Step: 2
Training loss: 1.9677972793579102
Validation loss: 2.0661161790291467

Epoch: 5| Step: 3
Training loss: 1.8028215169906616
Validation loss: 2.076692004998525

Epoch: 5| Step: 4
Training loss: 2.402700424194336
Validation loss: 2.0888220369815826

Epoch: 5| Step: 5
Training loss: 1.9850070476531982
Validation loss: 2.0986319333314896

Epoch: 5| Step: 6
Training loss: 1.944047212600708
Validation loss: 2.1000608454147973

Epoch: 5| Step: 7
Training loss: 2.25089955329895
Validation loss: 2.112611874938011

Epoch: 5| Step: 8
Training loss: 1.976593255996704
Validation loss: 2.1201430012782416

Epoch: 5| Step: 9
Training loss: 2.403731107711792
Validation loss: 2.101416975259781

Epoch: 5| Step: 10
Training loss: 1.6629842519760132
Validation loss: 2.1165362497170768

Epoch: 5| Step: 11
Training loss: 1.994036316871643
Validation loss: 2.1419845720132193

Epoch: 199| Step: 0
Training loss: 2.5493743419647217
Validation loss: 2.1186736275752387

Epoch: 5| Step: 1
Training loss: 2.1846108436584473
Validation loss: 2.098082239429156

Epoch: 5| Step: 2
Training loss: 2.379936695098877
Validation loss: 2.095882693926493

Epoch: 5| Step: 3
Training loss: 1.9466403722763062
Validation loss: 2.1015482395887375

Epoch: 5| Step: 4
Training loss: 1.8778305053710938
Validation loss: 2.094346582889557

Epoch: 5| Step: 5
Training loss: 2.098184108734131
Validation loss: 2.1031347761551538

Epoch: 5| Step: 6
Training loss: 1.8174192905426025
Validation loss: 2.099869668483734

Epoch: 5| Step: 7
Training loss: 1.661603331565857
Validation loss: 2.1032896290222802

Epoch: 5| Step: 8
Training loss: 1.5338819026947021
Validation loss: 2.1236492097377777

Epoch: 5| Step: 9
Training loss: 2.0469717979431152
Validation loss: 2.121157184243202

Epoch: 5| Step: 10
Training loss: 1.917991280555725
Validation loss: 2.1170411854982376

Epoch: 5| Step: 11
Training loss: 1.583161473274231
Validation loss: 2.125125269095103

Epoch: 200| Step: 0
Training loss: 2.313981533050537
Validation loss: 2.1419180035591125

Epoch: 5| Step: 1
Training loss: 2.157919406890869
Validation loss: 2.128451327482859

Epoch: 5| Step: 2
Training loss: 1.8062541484832764
Validation loss: 2.1325431962807975

Epoch: 5| Step: 3
Training loss: 2.609086513519287
Validation loss: 2.1241783599058786

Epoch: 5| Step: 4
Training loss: 1.5337554216384888
Validation loss: 2.122948075334231

Epoch: 5| Step: 5
Training loss: 1.8582592010498047
Validation loss: 2.122037092844645

Epoch: 5| Step: 6
Training loss: 2.0223515033721924
Validation loss: 2.1281347473462424

Epoch: 5| Step: 7
Training loss: 1.9043519496917725
Validation loss: 2.121185933550199

Epoch: 5| Step: 8
Training loss: 2.0129685401916504
Validation loss: 2.1152663826942444

Epoch: 5| Step: 9
Training loss: 1.6852489709854126
Validation loss: 2.117599035302798

Epoch: 5| Step: 10
Training loss: 2.2003250122070312
Validation loss: 2.1162382066249847

Epoch: 5| Step: 11
Training loss: 1.5368777513504028
Validation loss: 2.1271054297685623

Epoch: 201| Step: 0
Training loss: 1.7694460153579712
Validation loss: 2.1356835663318634

Epoch: 5| Step: 1
Training loss: 2.0973892211914062
Validation loss: 2.1329299807548523

Epoch: 5| Step: 2
Training loss: 2.287198543548584
Validation loss: 2.143938551346461

Epoch: 5| Step: 3
Training loss: 1.6369520425796509
Validation loss: 2.1388485431671143

Epoch: 5| Step: 4
Training loss: 2.436302900314331
Validation loss: 2.149044762055079

Epoch: 5| Step: 5
Training loss: 2.1997318267822266
Validation loss: 2.1488262712955475

Epoch: 5| Step: 6
Training loss: 1.6090164184570312
Validation loss: 2.1247562170028687

Epoch: 5| Step: 7
Training loss: 2.1037323474884033
Validation loss: 2.1302909354368844

Epoch: 5| Step: 8
Training loss: 1.5288214683532715
Validation loss: 2.1014836132526398

Epoch: 5| Step: 9
Training loss: 2.3125503063201904
Validation loss: 2.098751485347748

Epoch: 5| Step: 10
Training loss: 1.9269177913665771
Validation loss: 2.098712593317032

Epoch: 5| Step: 11
Training loss: 1.8360095024108887
Validation loss: 2.0880011369784675

Epoch: 202| Step: 0
Training loss: 1.5782558917999268
Validation loss: 2.1060575197140374

Epoch: 5| Step: 1
Training loss: 1.5885876417160034
Validation loss: 2.107740436991056

Epoch: 5| Step: 2
Training loss: 1.9185577630996704
Validation loss: 2.129186689853668

Epoch: 5| Step: 3
Training loss: 1.894051194190979
Validation loss: 2.145138442516327

Epoch: 5| Step: 4
Training loss: 2.185692310333252
Validation loss: 2.1070874283711114

Epoch: 5| Step: 5
Training loss: 2.1287307739257812
Validation loss: 2.1449917405843735

Epoch: 5| Step: 6
Training loss: 2.2774245738983154
Validation loss: 2.143249193827311

Epoch: 5| Step: 7
Training loss: 2.272965669631958
Validation loss: 2.155417243639628

Epoch: 5| Step: 8
Training loss: 2.1130473613739014
Validation loss: 2.142761747042338

Epoch: 5| Step: 9
Training loss: 2.0669608116149902
Validation loss: 2.1346539855003357

Epoch: 5| Step: 10
Training loss: 1.849608063697815
Validation loss: 2.0976547400156655

Epoch: 5| Step: 11
Training loss: 1.8057489395141602
Validation loss: 2.112424204746882

Epoch: 203| Step: 0
Training loss: 2.049884557723999
Validation loss: 2.112183769543966

Epoch: 5| Step: 1
Training loss: 2.261322259902954
Validation loss: 2.103070924679438

Epoch: 5| Step: 2
Training loss: 2.0818228721618652
Validation loss: 2.08595002690951

Epoch: 5| Step: 3
Training loss: 2.678039789199829
Validation loss: 2.0717519174019494

Epoch: 5| Step: 4
Training loss: 1.7380335330963135
Validation loss: 2.0750294774770737

Epoch: 5| Step: 5
Training loss: 2.1534934043884277
Validation loss: 2.0805370012919107

Epoch: 5| Step: 6
Training loss: 1.8458303213119507
Validation loss: 2.089755396048228

Epoch: 5| Step: 7
Training loss: 1.9332208633422852
Validation loss: 2.08496917784214

Epoch: 5| Step: 8
Training loss: 1.819210410118103
Validation loss: 2.0962918400764465

Epoch: 5| Step: 9
Training loss: 1.4754096269607544
Validation loss: 2.099852959314982

Epoch: 5| Step: 10
Training loss: 1.821897268295288
Validation loss: 2.086581602692604

Epoch: 5| Step: 11
Training loss: 2.831718683242798
Validation loss: 2.114011804262797

Epoch: 204| Step: 0
Training loss: 1.8849847316741943
Validation loss: 2.1162228087584176

Epoch: 5| Step: 1
Training loss: 1.7829294204711914
Validation loss: 2.1186822950839996

Epoch: 5| Step: 2
Training loss: 2.421968460083008
Validation loss: 2.131691033641497

Epoch: 5| Step: 3
Training loss: 2.457967519760132
Validation loss: 2.127005875110626

Epoch: 5| Step: 4
Training loss: 1.6996742486953735
Validation loss: 2.1307014375925064

Epoch: 5| Step: 5
Training loss: 1.8824050426483154
Validation loss: 2.1112486521402993

Epoch: 5| Step: 6
Training loss: 1.1998978853225708
Validation loss: 2.123354564110438

Epoch: 5| Step: 7
Training loss: 1.64984130859375
Validation loss: 2.1159234046936035

Epoch: 5| Step: 8
Training loss: 2.2797226905822754
Validation loss: 2.1118186513582864

Epoch: 5| Step: 9
Training loss: 1.8710410594940186
Validation loss: 2.1119323869546256

Epoch: 5| Step: 10
Training loss: 2.3639986515045166
Validation loss: 2.1048176983992257

Epoch: 5| Step: 11
Training loss: 2.638260841369629
Validation loss: 2.114204317331314

Epoch: 205| Step: 0
Training loss: 2.3108878135681152
Validation loss: 2.1181405782699585

Epoch: 5| Step: 1
Training loss: 1.9358470439910889
Validation loss: 2.1168045898278556

Epoch: 5| Step: 2
Training loss: 1.1978261470794678
Validation loss: 2.1064641177654266

Epoch: 5| Step: 3
Training loss: 2.4311516284942627
Validation loss: 2.100744128227234

Epoch: 5| Step: 4
Training loss: 1.6229480504989624
Validation loss: 2.1144111106793084

Epoch: 5| Step: 5
Training loss: 1.762563943862915
Validation loss: 2.118065223097801

Epoch: 5| Step: 6
Training loss: 2.3988852500915527
Validation loss: 2.1275006979703903

Epoch: 5| Step: 7
Training loss: 1.7538344860076904
Validation loss: 2.1123259911934533

Epoch: 5| Step: 8
Training loss: 1.902803659439087
Validation loss: 2.1309313575426736

Epoch: 5| Step: 9
Training loss: 2.3102829456329346
Validation loss: 2.1122560252745948

Epoch: 5| Step: 10
Training loss: 1.8436295986175537
Validation loss: 2.108357091744741

Epoch: 5| Step: 11
Training loss: 2.307027816772461
Validation loss: 2.1007499545812607

Epoch: 206| Step: 0
Training loss: 2.318340301513672
Validation loss: 2.0853185007969537

Epoch: 5| Step: 1
Training loss: 2.3014426231384277
Validation loss: 2.09567458430926

Epoch: 5| Step: 2
Training loss: 1.7022428512573242
Validation loss: 2.085879256327947

Epoch: 5| Step: 3
Training loss: 1.9522581100463867
Validation loss: 2.0863092641035714

Epoch: 5| Step: 4
Training loss: 1.7905480861663818
Validation loss: 2.091851050655047

Epoch: 5| Step: 5
Training loss: 2.0099010467529297
Validation loss: 2.1036674628655114

Epoch: 5| Step: 6
Training loss: 2.1497721672058105
Validation loss: 2.098215639591217

Epoch: 5| Step: 7
Training loss: 1.4705452919006348
Validation loss: 2.1144689122835794

Epoch: 5| Step: 8
Training loss: 1.6372044086456299
Validation loss: 2.1033586263656616

Epoch: 5| Step: 9
Training loss: 2.2023627758026123
Validation loss: 2.110476021965345

Epoch: 5| Step: 10
Training loss: 2.008924961090088
Validation loss: 2.118419031302134

Epoch: 5| Step: 11
Training loss: 1.9414738416671753
Validation loss: 2.1321856528520584

Epoch: 207| Step: 0
Training loss: 1.876137137413025
Validation loss: 2.1177210807800293

Epoch: 5| Step: 1
Training loss: 2.090510606765747
Validation loss: 2.128365844488144

Epoch: 5| Step: 2
Training loss: 2.4823145866394043
Validation loss: 2.112139339248339

Epoch: 5| Step: 3
Training loss: 1.9973735809326172
Validation loss: 2.113797202706337

Epoch: 5| Step: 4
Training loss: 1.3782665729522705
Validation loss: 2.115121215581894

Epoch: 5| Step: 5
Training loss: 1.4671417474746704
Validation loss: 2.117819587389628

Epoch: 5| Step: 6
Training loss: 1.9289023876190186
Validation loss: 2.1171641449133554

Epoch: 5| Step: 7
Training loss: 2.200294256210327
Validation loss: 2.1129586696624756

Epoch: 5| Step: 8
Training loss: 1.7514463663101196
Validation loss: 2.0980122139056525

Epoch: 5| Step: 9
Training loss: 2.3465213775634766
Validation loss: 2.08906526863575

Epoch: 5| Step: 10
Training loss: 2.156200885772705
Validation loss: 2.0961870799462

Epoch: 5| Step: 11
Training loss: 1.7571312189102173
Validation loss: 2.1083751966555915

Epoch: 208| Step: 0
Training loss: 1.7688210010528564
Validation loss: 2.102416584889094

Epoch: 5| Step: 1
Training loss: 2.283188581466675
Validation loss: 2.112615098555883

Epoch: 5| Step: 2
Training loss: 1.6872098445892334
Validation loss: 2.1129616647958755

Epoch: 5| Step: 3
Training loss: 1.6705455780029297
Validation loss: 2.1071114192406335

Epoch: 5| Step: 4
Training loss: 1.995600700378418
Validation loss: 2.1067658911148706

Epoch: 5| Step: 5
Training loss: 2.0343141555786133
Validation loss: 2.116655260324478

Epoch: 5| Step: 6
Training loss: 1.753967523574829
Validation loss: 2.132588744163513

Epoch: 5| Step: 7
Training loss: 2.276218891143799
Validation loss: 2.1205167869726815

Epoch: 5| Step: 8
Training loss: 2.3591384887695312
Validation loss: 2.125329926609993

Epoch: 5| Step: 9
Training loss: 1.8315423727035522
Validation loss: 2.119466265042623

Epoch: 5| Step: 10
Training loss: 2.11430287361145
Validation loss: 2.1205774744351706

Epoch: 5| Step: 11
Training loss: 1.965226173400879
Validation loss: 2.106166362762451

Epoch: 209| Step: 0
Training loss: 2.119581699371338
Validation loss: 2.121580570936203

Epoch: 5| Step: 1
Training loss: 2.0392661094665527
Validation loss: 2.116414229075114

Epoch: 5| Step: 2
Training loss: 1.9161701202392578
Validation loss: 2.1063640813032785

Epoch: 5| Step: 3
Training loss: 1.6993377208709717
Validation loss: 2.1139441231886544

Epoch: 5| Step: 4
Training loss: 1.5322500467300415
Validation loss: 2.1109863022963204

Epoch: 5| Step: 5
Training loss: 2.3766555786132812
Validation loss: 2.1048711091279984

Epoch: 5| Step: 6
Training loss: 1.79294753074646
Validation loss: 2.1198834081490836

Epoch: 5| Step: 7
Training loss: 1.7724602222442627
Validation loss: 2.1300623764594397

Epoch: 5| Step: 8
Training loss: 1.7630212306976318
Validation loss: 2.1151235103607178

Epoch: 5| Step: 9
Training loss: 2.588700771331787
Validation loss: 2.106172025203705

Epoch: 5| Step: 10
Training loss: 2.011334180831909
Validation loss: 2.1148803681135178

Epoch: 5| Step: 11
Training loss: 2.344359874725342
Validation loss: 2.084708114465078

Epoch: 210| Step: 0
Training loss: 2.3827648162841797
Validation loss: 2.096045101682345

Epoch: 5| Step: 1
Training loss: 2.043325901031494
Validation loss: 2.0891311268011727

Epoch: 5| Step: 2
Training loss: 1.9517654180526733
Validation loss: 2.075749233365059

Epoch: 5| Step: 3
Training loss: 2.0827341079711914
Validation loss: 2.0681926558415094

Epoch: 5| Step: 4
Training loss: 1.9258906841278076
Validation loss: 2.0797291696071625

Epoch: 5| Step: 5
Training loss: 2.176027774810791
Validation loss: 2.088780631621679

Epoch: 5| Step: 6
Training loss: 2.169410228729248
Validation loss: 2.077213098605474

Epoch: 5| Step: 7
Training loss: 1.945081114768982
Validation loss: 2.0764127373695374

Epoch: 5| Step: 8
Training loss: 2.3816025257110596
Validation loss: 2.078912248214086

Epoch: 5| Step: 9
Training loss: 1.7303069829940796
Validation loss: 2.0858551065127053

Epoch: 5| Step: 10
Training loss: 1.9092252254486084
Validation loss: 2.073975329597791

Epoch: 5| Step: 11
Training loss: 2.035256862640381
Validation loss: 2.081238771478335

Epoch: 211| Step: 0
Training loss: 2.3350894451141357
Validation loss: 2.0793525129556656

Epoch: 5| Step: 1
Training loss: 1.7385971546173096
Validation loss: 2.082131082812945

Epoch: 5| Step: 2
Training loss: 2.183359146118164
Validation loss: 2.0770291090011597

Epoch: 5| Step: 3
Training loss: 2.048668384552002
Validation loss: 2.0794463555018106

Epoch: 5| Step: 4
Training loss: 1.5254799127578735
Validation loss: 2.0859098533789315

Epoch: 5| Step: 5
Training loss: 1.917117714881897
Validation loss: 2.0869377156098685

Epoch: 5| Step: 6
Training loss: 1.993560552597046
Validation loss: 2.0816509425640106

Epoch: 5| Step: 7
Training loss: 1.8643169403076172
Validation loss: 2.0867255181074142

Epoch: 5| Step: 8
Training loss: 1.9534566402435303
Validation loss: 2.0968609054883323

Epoch: 5| Step: 9
Training loss: 1.9935081005096436
Validation loss: 2.0820614993572235

Epoch: 5| Step: 10
Training loss: 2.5328528881073
Validation loss: 2.1018962313731513

Epoch: 5| Step: 11
Training loss: 2.293074607849121
Validation loss: 2.0954986860354743

Epoch: 212| Step: 0
Training loss: 1.5562649965286255
Validation loss: 2.0935643712679544

Epoch: 5| Step: 1
Training loss: 1.54513680934906
Validation loss: 2.1096850434939065

Epoch: 5| Step: 2
Training loss: 1.729050636291504
Validation loss: 2.105045422911644

Epoch: 5| Step: 3
Training loss: 1.7436431646347046
Validation loss: 2.1130654364824295

Epoch: 5| Step: 4
Training loss: 1.9344600439071655
Validation loss: 2.1048587958017984

Epoch: 5| Step: 5
Training loss: 2.329029083251953
Validation loss: 2.109315608938535

Epoch: 5| Step: 6
Training loss: 2.6326770782470703
Validation loss: 2.110588620106379

Epoch: 5| Step: 7
Training loss: 2.0224053859710693
Validation loss: 2.101764569679896

Epoch: 5| Step: 8
Training loss: 1.663511872291565
Validation loss: 2.098425264159838

Epoch: 5| Step: 9
Training loss: 2.1732735633850098
Validation loss: 2.0960875948270163

Epoch: 5| Step: 10
Training loss: 2.3534469604492188
Validation loss: 2.1032699048519135

Epoch: 5| Step: 11
Training loss: 2.655911922454834
Validation loss: 2.1113268236319223

Epoch: 213| Step: 0
Training loss: 1.7657668590545654
Validation loss: 2.1009759853283563

Epoch: 5| Step: 1
Training loss: 2.5277957916259766
Validation loss: 2.1113988359769187

Epoch: 5| Step: 2
Training loss: 1.8220106363296509
Validation loss: 2.1166068464517593

Epoch: 5| Step: 3
Training loss: 2.2081048488616943
Validation loss: 2.133684366941452

Epoch: 5| Step: 4
Training loss: 1.9790213108062744
Validation loss: 2.137796754638354

Epoch: 5| Step: 5
Training loss: 2.018756151199341
Validation loss: 2.1321560045083365

Epoch: 5| Step: 6
Training loss: 2.4757771492004395
Validation loss: 2.1171127259731293

Epoch: 5| Step: 7
Training loss: 1.8485902547836304
Validation loss: 2.1131463001171746

Epoch: 5| Step: 8
Training loss: 1.9600318670272827
Validation loss: 2.1220425367355347

Epoch: 5| Step: 9
Training loss: 1.368382215499878
Validation loss: 2.1038326720396676

Epoch: 5| Step: 10
Training loss: 1.8942079544067383
Validation loss: 2.1157856782277427

Epoch: 5| Step: 11
Training loss: 0.9312842488288879
Validation loss: 2.1102012594540915

Epoch: 214| Step: 0
Training loss: 1.8671586513519287
Validation loss: 2.125282829006513

Epoch: 5| Step: 1
Training loss: 1.672628402709961
Validation loss: 2.1132348428169885

Epoch: 5| Step: 2
Training loss: 2.0932681560516357
Validation loss: 2.1228238940238953

Epoch: 5| Step: 3
Training loss: 1.6389381885528564
Validation loss: 2.1195053160190582

Epoch: 5| Step: 4
Training loss: 2.090453624725342
Validation loss: 2.1181370665629706

Epoch: 5| Step: 5
Training loss: 1.500853419303894
Validation loss: 2.1079076131184897

Epoch: 5| Step: 6
Training loss: 1.6734317541122437
Validation loss: 2.1331994384527206

Epoch: 5| Step: 7
Training loss: 2.1847493648529053
Validation loss: 2.1228690346082053

Epoch: 5| Step: 8
Training loss: 2.040351390838623
Validation loss: 2.1303978661696115

Epoch: 5| Step: 9
Training loss: 2.5287013053894043
Validation loss: 2.127047141393026

Epoch: 5| Step: 10
Training loss: 1.7721939086914062
Validation loss: 2.1383011688788733

Epoch: 5| Step: 11
Training loss: 2.967111110687256
Validation loss: 2.1394761900107064

Epoch: 215| Step: 0
Training loss: 2.187187433242798
Validation loss: 2.144857332110405

Epoch: 5| Step: 1
Training loss: 2.069462776184082
Validation loss: 2.1577043732007346

Epoch: 5| Step: 2
Training loss: 2.0168800354003906
Validation loss: 2.1236771692832312

Epoch: 5| Step: 3
Training loss: 2.262599229812622
Validation loss: 2.1451154251893363

Epoch: 5| Step: 4
Training loss: 1.9010026454925537
Validation loss: 2.141797423362732

Epoch: 5| Step: 5
Training loss: 1.7556240558624268
Validation loss: 2.1456866562366486

Epoch: 5| Step: 6
Training loss: 1.9278310537338257
Validation loss: 2.141550689935684

Epoch: 5| Step: 7
Training loss: 1.5917518138885498
Validation loss: 2.1256100833415985

Epoch: 5| Step: 8
Training loss: 1.4989428520202637
Validation loss: 2.127054437994957

Epoch: 5| Step: 9
Training loss: 1.7563070058822632
Validation loss: 2.1219676733016968

Epoch: 5| Step: 10
Training loss: 2.3191394805908203
Validation loss: 2.119854266444842

Epoch: 5| Step: 11
Training loss: 2.4914512634277344
Validation loss: 2.1248502482970557

Epoch: 216| Step: 0
Training loss: 2.166646957397461
Validation loss: 2.0955701718727746

Epoch: 5| Step: 1
Training loss: 2.252260208129883
Validation loss: 2.0998895466327667

Epoch: 5| Step: 2
Training loss: 1.9470908641815186
Validation loss: 2.0995815296967826

Epoch: 5| Step: 3
Training loss: 1.576231837272644
Validation loss: 2.0928095479806266

Epoch: 5| Step: 4
Training loss: 2.1929430961608887
Validation loss: 2.0993912716706595

Epoch: 5| Step: 5
Training loss: 2.1234538555145264
Validation loss: 2.0911800314982734

Epoch: 5| Step: 6
Training loss: 1.6080844402313232
Validation loss: 2.099871183435122

Epoch: 5| Step: 7
Training loss: 1.662083387374878
Validation loss: 2.1013742685317993

Epoch: 5| Step: 8
Training loss: 2.3816096782684326
Validation loss: 2.1179394920667014

Epoch: 5| Step: 9
Training loss: 2.0119221210479736
Validation loss: 2.1264365961154303

Epoch: 5| Step: 10
Training loss: 1.9166322946548462
Validation loss: 2.1249049554268518

Epoch: 5| Step: 11
Training loss: 2.0336010456085205
Validation loss: 2.1309177577495575

Epoch: 217| Step: 0
Training loss: 1.9279009103775024
Validation loss: 2.161455273628235

Epoch: 5| Step: 1
Training loss: 2.03020977973938
Validation loss: 2.1556709110736847

Epoch: 5| Step: 2
Training loss: 1.5672980546951294
Validation loss: 2.1538698424895606

Epoch: 5| Step: 3
Training loss: 1.8405548334121704
Validation loss: 2.1684535493453345

Epoch: 5| Step: 4
Training loss: 2.389219284057617
Validation loss: 2.163553774356842

Epoch: 5| Step: 5
Training loss: 1.834102988243103
Validation loss: 2.1711098551750183

Epoch: 5| Step: 6
Training loss: 2.5098326206207275
Validation loss: 2.1544139832258224

Epoch: 5| Step: 7
Training loss: 1.9490134716033936
Validation loss: 2.1479654063781104

Epoch: 5| Step: 8
Training loss: 1.5391855239868164
Validation loss: 2.117792159318924

Epoch: 5| Step: 9
Training loss: 1.8855602741241455
Validation loss: 2.114755009611448

Epoch: 5| Step: 10
Training loss: 2.2661542892456055
Validation loss: 2.1038138220707574

Epoch: 5| Step: 11
Training loss: 1.420935034751892
Validation loss: 2.098306049903234

Epoch: 218| Step: 0
Training loss: 1.930230736732483
Validation loss: 2.0925060411294303

Epoch: 5| Step: 1
Training loss: 1.764240026473999
Validation loss: 2.1065262258052826

Epoch: 5| Step: 2
Training loss: 1.7611385583877563
Validation loss: 2.118129938840866

Epoch: 5| Step: 3
Training loss: 1.70832097530365
Validation loss: 2.121205061674118

Epoch: 5| Step: 4
Training loss: 1.9169483184814453
Validation loss: 2.125472148259481

Epoch: 5| Step: 5
Training loss: 1.8130810260772705
Validation loss: 2.137304733196894

Epoch: 5| Step: 6
Training loss: 2.445786952972412
Validation loss: 2.147489791115125

Epoch: 5| Step: 7
Training loss: 1.80044686794281
Validation loss: 2.152541230122248

Epoch: 5| Step: 8
Training loss: 1.9503988027572632
Validation loss: 2.1638052513202033

Epoch: 5| Step: 9
Training loss: 1.922909140586853
Validation loss: 2.167649139960607

Epoch: 5| Step: 10
Training loss: 2.340874195098877
Validation loss: 2.164568761984507

Epoch: 5| Step: 11
Training loss: 1.3328098058700562
Validation loss: 2.1647327840328217

Epoch: 219| Step: 0
Training loss: 2.0422167778015137
Validation loss: 2.1638170232375464

Epoch: 5| Step: 1
Training loss: 2.462564468383789
Validation loss: 2.19803516070048

Epoch: 5| Step: 2
Training loss: 1.666825294494629
Validation loss: 2.1930348674456277

Epoch: 5| Step: 3
Training loss: 2.396052598953247
Validation loss: 2.1926677425702414

Epoch: 5| Step: 4
Training loss: 1.6931222677230835
Validation loss: 2.1673670411109924

Epoch: 5| Step: 5
Training loss: 2.2544710636138916
Validation loss: 2.149600639939308

Epoch: 5| Step: 6
Training loss: 1.7562811374664307
Validation loss: 2.135095496972402

Epoch: 5| Step: 7
Training loss: 2.2504782676696777
Validation loss: 2.1397538483142853

Epoch: 5| Step: 8
Training loss: 1.4563308954238892
Validation loss: 2.1212752213080726

Epoch: 5| Step: 9
Training loss: 1.7353527545928955
Validation loss: 2.116543710231781

Epoch: 5| Step: 10
Training loss: 2.0842177867889404
Validation loss: 2.121691624323527

Epoch: 5| Step: 11
Training loss: 1.3554766178131104
Validation loss: 2.1194454977909722

Epoch: 220| Step: 0
Training loss: 2.2803077697753906
Validation loss: 2.1181124498446784

Epoch: 5| Step: 1
Training loss: 1.988732099533081
Validation loss: 2.144048089782397

Epoch: 5| Step: 2
Training loss: 1.730767011642456
Validation loss: 2.13978610932827

Epoch: 5| Step: 3
Training loss: 2.2264952659606934
Validation loss: 2.157874663670858

Epoch: 5| Step: 4
Training loss: 1.6728376150131226
Validation loss: 2.171693275372187

Epoch: 5| Step: 5
Training loss: 1.6988662481307983
Validation loss: 2.1617699613173804

Epoch: 5| Step: 6
Training loss: 1.9084317684173584
Validation loss: 2.1547894825538

Epoch: 5| Step: 7
Training loss: 2.1573030948638916
Validation loss: 2.1461536089579263

Epoch: 5| Step: 8
Training loss: 1.5230953693389893
Validation loss: 2.143109699090322

Epoch: 5| Step: 9
Training loss: 2.1337201595306396
Validation loss: 2.1156522234280906

Epoch: 5| Step: 10
Training loss: 2.0934743881225586
Validation loss: 2.1253837843736014

Epoch: 5| Step: 11
Training loss: 2.6074955463409424
Validation loss: 2.124160682161649

Epoch: 221| Step: 0
Training loss: 1.4487897157669067
Validation loss: 2.100984901189804

Epoch: 5| Step: 1
Training loss: 2.4151203632354736
Validation loss: 2.1030613432327905

Epoch: 5| Step: 2
Training loss: 1.4962836503982544
Validation loss: 2.099529335896174

Epoch: 5| Step: 3
Training loss: 1.9120689630508423
Validation loss: 2.099221130212148

Epoch: 5| Step: 4
Training loss: 1.9057972431182861
Validation loss: 2.099716156721115

Epoch: 5| Step: 5
Training loss: 1.785447359085083
Validation loss: 2.0987315674622855

Epoch: 5| Step: 6
Training loss: 2.522322177886963
Validation loss: 2.096495822072029

Epoch: 5| Step: 7
Training loss: 1.6870195865631104
Validation loss: 2.110973820090294

Epoch: 5| Step: 8
Training loss: 2.1587886810302734
Validation loss: 2.1086000204086304

Epoch: 5| Step: 9
Training loss: 2.2861504554748535
Validation loss: 2.1098004231850305

Epoch: 5| Step: 10
Training loss: 1.8030033111572266
Validation loss: 2.12002066274484

Epoch: 5| Step: 11
Training loss: 2.7415614128112793
Validation loss: 2.121444582939148

Epoch: 222| Step: 0
Training loss: 2.0690364837646484
Validation loss: 2.1225550919771194

Epoch: 5| Step: 1
Training loss: 2.4165501594543457
Validation loss: 2.1121779133876166

Epoch: 5| Step: 2
Training loss: 1.809975266456604
Validation loss: 2.1200790852308273

Epoch: 5| Step: 3
Training loss: 1.866421103477478
Validation loss: 2.1300037999947867

Epoch: 5| Step: 4
Training loss: 1.4912643432617188
Validation loss: 2.130183055996895

Epoch: 5| Step: 5
Training loss: 2.1920969486236572
Validation loss: 2.117479850848516

Epoch: 5| Step: 6
Training loss: 2.077193260192871
Validation loss: 2.115879019101461

Epoch: 5| Step: 7
Training loss: 2.549581289291382
Validation loss: 2.122231662273407

Epoch: 5| Step: 8
Training loss: 1.4926191568374634
Validation loss: 2.1075695902109146

Epoch: 5| Step: 9
Training loss: 1.5831577777862549
Validation loss: 2.108494848012924

Epoch: 5| Step: 10
Training loss: 2.073310375213623
Validation loss: 2.1060672799746194

Epoch: 5| Step: 11
Training loss: 1.4160867929458618
Validation loss: 2.1136946181456246

Epoch: 223| Step: 0
Training loss: 1.3830595016479492
Validation loss: 2.1032294233640036

Epoch: 5| Step: 1
Training loss: 1.6214622259140015
Validation loss: 2.1108303566773734

Epoch: 5| Step: 2
Training loss: 1.7032461166381836
Validation loss: 2.116617833574613

Epoch: 5| Step: 3
Training loss: 2.437488079071045
Validation loss: 2.1233253379662833

Epoch: 5| Step: 4
Training loss: 2.4129223823547363
Validation loss: 2.1254727294047675

Epoch: 5| Step: 5
Training loss: 1.9764846563339233
Validation loss: 2.1300363143285117

Epoch: 5| Step: 6
Training loss: 1.7608006000518799
Validation loss: 2.1360370566447577

Epoch: 5| Step: 7
Training loss: 2.4530909061431885
Validation loss: 2.13825815419356

Epoch: 5| Step: 8
Training loss: 1.6338863372802734
Validation loss: 2.127571096022924

Epoch: 5| Step: 9
Training loss: 2.0756821632385254
Validation loss: 2.132036194205284

Epoch: 5| Step: 10
Training loss: 1.975124716758728
Validation loss: 2.1415930837392807

Epoch: 5| Step: 11
Training loss: 1.9116020202636719
Validation loss: 2.1285011370976767

Epoch: 224| Step: 0
Training loss: 2.1540074348449707
Validation loss: 2.1316479295492172

Epoch: 5| Step: 1
Training loss: 1.7018873691558838
Validation loss: 2.1261958281199136

Epoch: 5| Step: 2
Training loss: 2.170668840408325
Validation loss: 2.1145524382591248

Epoch: 5| Step: 3
Training loss: 2.3007826805114746
Validation loss: 2.1108807921409607

Epoch: 5| Step: 4
Training loss: 1.5055142641067505
Validation loss: 2.1281962941090264

Epoch: 5| Step: 5
Training loss: 1.747391939163208
Validation loss: 2.1105904976526895

Epoch: 5| Step: 6
Training loss: 2.248427152633667
Validation loss: 2.1074039041996

Epoch: 5| Step: 7
Training loss: 1.8983465433120728
Validation loss: 2.0994230657815933

Epoch: 5| Step: 8
Training loss: 2.0265426635742188
Validation loss: 2.1179347236951194

Epoch: 5| Step: 9
Training loss: 1.522308588027954
Validation loss: 2.11954003572464

Epoch: 5| Step: 10
Training loss: 2.351529598236084
Validation loss: 2.1261084377765656

Epoch: 5| Step: 11
Training loss: 1.4209741353988647
Validation loss: 2.132410784562429

Epoch: 225| Step: 0
Training loss: 1.7562850713729858
Validation loss: 2.132401550809542

Epoch: 5| Step: 1
Training loss: 1.804861068725586
Validation loss: 2.140499239166578

Epoch: 5| Step: 2
Training loss: 2.07684588432312
Validation loss: 2.137273704012235

Epoch: 5| Step: 3
Training loss: 2.0971367359161377
Validation loss: 2.136967897415161

Epoch: 5| Step: 4
Training loss: 1.6869189739227295
Validation loss: 2.134391958514849

Epoch: 5| Step: 5
Training loss: 2.122678279876709
Validation loss: 2.1558408985535302

Epoch: 5| Step: 6
Training loss: 1.936344861984253
Validation loss: 2.1413253446420035

Epoch: 5| Step: 7
Training loss: 1.4062087535858154
Validation loss: 2.1467846582333245

Epoch: 5| Step: 8
Training loss: 2.4771430492401123
Validation loss: 2.163065180182457

Epoch: 5| Step: 9
Training loss: 2.1168880462646484
Validation loss: 2.1432060599327087

Epoch: 5| Step: 10
Training loss: 1.611006498336792
Validation loss: 2.1482027620077133

Epoch: 5| Step: 11
Training loss: 1.2914644479751587
Validation loss: 2.1474746763706207

Epoch: 226| Step: 0
Training loss: 1.9163475036621094
Validation loss: 2.129108041524887

Epoch: 5| Step: 1
Training loss: 2.002869129180908
Validation loss: 2.119483162959417

Epoch: 5| Step: 2
Training loss: 1.9132457971572876
Validation loss: 2.1143246541420617

Epoch: 5| Step: 3
Training loss: 1.7929548025131226
Validation loss: 2.110892578959465

Epoch: 5| Step: 4
Training loss: 2.097877264022827
Validation loss: 2.1127250095208487

Epoch: 5| Step: 5
Training loss: 1.830190658569336
Validation loss: 2.1106282770633698

Epoch: 5| Step: 6
Training loss: 1.8615487813949585
Validation loss: 2.1218547920385995

Epoch: 5| Step: 7
Training loss: 1.7993717193603516
Validation loss: 2.1336710254351297

Epoch: 5| Step: 8
Training loss: 1.4497292041778564
Validation loss: 2.1314047376314798

Epoch: 5| Step: 9
Training loss: 2.599867582321167
Validation loss: 2.145113835732142

Epoch: 5| Step: 10
Training loss: 2.297874927520752
Validation loss: 2.153059740861257

Epoch: 5| Step: 11
Training loss: 1.8881362676620483
Validation loss: 2.162128195166588

Epoch: 227| Step: 0
Training loss: 1.7894079685211182
Validation loss: 2.143405278523763

Epoch: 5| Step: 1
Training loss: 1.968096137046814
Validation loss: 2.1354249815146127

Epoch: 5| Step: 2
Training loss: 1.626654863357544
Validation loss: 2.1268825978040695

Epoch: 5| Step: 3
Training loss: 2.1238393783569336
Validation loss: 2.112009654442469

Epoch: 5| Step: 4
Training loss: 2.2024831771850586
Validation loss: 2.117994869748751

Epoch: 5| Step: 5
Training loss: 2.428067445755005
Validation loss: 2.1171604792277017

Epoch: 5| Step: 6
Training loss: 1.9694499969482422
Validation loss: 2.116946811477343

Epoch: 5| Step: 7
Training loss: 2.2744898796081543
Validation loss: 2.1159109820922217

Epoch: 5| Step: 8
Training loss: 1.8205478191375732
Validation loss: 2.124855717023214

Epoch: 5| Step: 9
Training loss: 2.0237021446228027
Validation loss: 2.1252009322245917

Epoch: 5| Step: 10
Training loss: 1.6406099796295166
Validation loss: 2.1400202810764313

Epoch: 5| Step: 11
Training loss: 0.8586745262145996
Validation loss: 2.1384670734405518

Epoch: 228| Step: 0
Training loss: 1.925493597984314
Validation loss: 2.138021469116211

Epoch: 5| Step: 1
Training loss: 2.1707003116607666
Validation loss: 2.124202092488607

Epoch: 5| Step: 2
Training loss: 2.105656147003174
Validation loss: 2.127932459115982

Epoch: 5| Step: 3
Training loss: 2.1416308879852295
Validation loss: 2.1068752308686576

Epoch: 5| Step: 4
Training loss: 2.164623260498047
Validation loss: 2.110720694065094

Epoch: 5| Step: 5
Training loss: 1.7861406803131104
Validation loss: 2.1088239004214606

Epoch: 5| Step: 6
Training loss: 1.2071746587753296
Validation loss: 2.109987194339434

Epoch: 5| Step: 7
Training loss: 1.9892642498016357
Validation loss: 2.0963942309220633

Epoch: 5| Step: 8
Training loss: 1.7895196676254272
Validation loss: 2.1088716089725494

Epoch: 5| Step: 9
Training loss: 2.292964220046997
Validation loss: 2.115322560071945

Epoch: 5| Step: 10
Training loss: 2.0463147163391113
Validation loss: 2.110335518916448

Epoch: 5| Step: 11
Training loss: 1.83125901222229
Validation loss: 2.111112415790558

Epoch: 229| Step: 0
Training loss: 1.367147445678711
Validation loss: 2.124160647392273

Epoch: 5| Step: 1
Training loss: 1.6168310642242432
Validation loss: 2.128479907910029

Epoch: 5| Step: 2
Training loss: 2.3271355628967285
Validation loss: 2.1278290251890817

Epoch: 5| Step: 3
Training loss: 2.1815433502197266
Validation loss: 2.1365698128938675

Epoch: 5| Step: 4
Training loss: 1.6516036987304688
Validation loss: 2.1382318834463754

Epoch: 5| Step: 5
Training loss: 1.961700201034546
Validation loss: 2.1530916492144265

Epoch: 5| Step: 6
Training loss: 2.1660208702087402
Validation loss: 2.1636343051989875

Epoch: 5| Step: 7
Training loss: 1.665888786315918
Validation loss: 2.169589971502622

Epoch: 5| Step: 8
Training loss: 2.4589695930480957
Validation loss: 2.166507492462794

Epoch: 5| Step: 9
Training loss: 2.0403151512145996
Validation loss: 2.2024081895748773

Epoch: 5| Step: 10
Training loss: 1.7596441507339478
Validation loss: 2.206193208694458

Epoch: 5| Step: 11
Training loss: 1.6924993991851807
Validation loss: 2.2029226819674173

Epoch: 230| Step: 0
Training loss: 1.3755466938018799
Validation loss: 2.1591622084379196

Epoch: 5| Step: 1
Training loss: 2.525899648666382
Validation loss: 2.160315374533335

Epoch: 5| Step: 2
Training loss: 1.6326205730438232
Validation loss: 2.1597686956326165

Epoch: 5| Step: 3
Training loss: 2.03637433052063
Validation loss: 2.1493819455305734

Epoch: 5| Step: 4
Training loss: 1.7550194263458252
Validation loss: 2.146835833787918

Epoch: 5| Step: 5
Training loss: 1.7576061487197876
Validation loss: 2.131890664498011

Epoch: 5| Step: 6
Training loss: 1.7196769714355469
Validation loss: 2.129032075405121

Epoch: 5| Step: 7
Training loss: 1.8260256052017212
Validation loss: 2.148293341199557

Epoch: 5| Step: 8
Training loss: 1.9430477619171143
Validation loss: 2.1340897927681604

Epoch: 5| Step: 9
Training loss: 2.671077013015747
Validation loss: 2.1543720861275992

Epoch: 5| Step: 10
Training loss: 1.829206109046936
Validation loss: 2.1510788102944693

Epoch: 5| Step: 11
Training loss: 1.5563372373580933
Validation loss: 2.1565043379863105

Epoch: 231| Step: 0
Training loss: 2.0469462871551514
Validation loss: 2.1457498222589493

Epoch: 5| Step: 1
Training loss: 1.8574495315551758
Validation loss: 2.14165752629439

Epoch: 5| Step: 2
Training loss: 2.068552017211914
Validation loss: 2.1507529268662133

Epoch: 5| Step: 3
Training loss: 1.3515008687973022
Validation loss: 2.1384106377760568

Epoch: 5| Step: 4
Training loss: 2.144047260284424
Validation loss: 2.144181877374649

Epoch: 5| Step: 5
Training loss: 1.7055362462997437
Validation loss: 2.1426717142264047

Epoch: 5| Step: 6
Training loss: 1.9262406826019287
Validation loss: 2.1463103592395782

Epoch: 5| Step: 7
Training loss: 1.9051601886749268
Validation loss: 2.1534542938073478

Epoch: 5| Step: 8
Training loss: 2.69356107711792
Validation loss: 2.168807099262873

Epoch: 5| Step: 9
Training loss: 1.5553029775619507
Validation loss: 2.152378877003988

Epoch: 5| Step: 10
Training loss: 1.6968826055526733
Validation loss: 2.1664271305004754

Epoch: 5| Step: 11
Training loss: 2.1189732551574707
Validation loss: 2.1591957410176597

Epoch: 232| Step: 0
Training loss: 1.9295202493667603
Validation loss: 2.1681566139062247

Epoch: 5| Step: 1
Training loss: 1.8276029825210571
Validation loss: 2.1614443759123483

Epoch: 5| Step: 2
Training loss: 1.4301618337631226
Validation loss: 2.1781620234251022

Epoch: 5| Step: 3
Training loss: 2.270219564437866
Validation loss: 2.179677739739418

Epoch: 5| Step: 4
Training loss: 2.138077974319458
Validation loss: 2.1845997273921967

Epoch: 5| Step: 5
Training loss: 2.1895997524261475
Validation loss: 2.193993697563807

Epoch: 5| Step: 6
Training loss: 2.408262252807617
Validation loss: 2.1662285725275674

Epoch: 5| Step: 7
Training loss: 1.8546510934829712
Validation loss: 2.1707092920939126

Epoch: 5| Step: 8
Training loss: 1.641871690750122
Validation loss: 2.1738190402587256

Epoch: 5| Step: 9
Training loss: 1.8394253253936768
Validation loss: 2.1730504234631858

Epoch: 5| Step: 10
Training loss: 1.6187442541122437
Validation loss: 2.1530425945917764

Epoch: 5| Step: 11
Training loss: 1.676558256149292
Validation loss: 2.155997102459272

Epoch: 233| Step: 0
Training loss: 2.447964906692505
Validation loss: 2.142278417944908

Epoch: 5| Step: 1
Training loss: 2.4477152824401855
Validation loss: 2.1284110248088837

Epoch: 5| Step: 2
Training loss: 1.9038465023040771
Validation loss: 2.1258832762638726

Epoch: 5| Step: 3
Training loss: 1.5931612253189087
Validation loss: 2.132557362318039

Epoch: 5| Step: 4
Training loss: 1.7579472064971924
Validation loss: 2.1429298569758735

Epoch: 5| Step: 5
Training loss: 1.503757357597351
Validation loss: 2.1274479975303016

Epoch: 5| Step: 6
Training loss: 1.753787636756897
Validation loss: 2.1423333485921225

Epoch: 5| Step: 7
Training loss: 1.8986809253692627
Validation loss: 2.1456554532051086

Epoch: 5| Step: 8
Training loss: 2.188007354736328
Validation loss: 2.1553984383742013

Epoch: 5| Step: 9
Training loss: 1.4553683996200562
Validation loss: 2.15685827533404

Epoch: 5| Step: 10
Training loss: 2.079526901245117
Validation loss: 2.172240450978279

Epoch: 5| Step: 11
Training loss: 3.288015365600586
Validation loss: 2.180930366118749

Epoch: 234| Step: 0
Training loss: 1.9930775165557861
Validation loss: 2.187158520023028

Epoch: 5| Step: 1
Training loss: 1.614553689956665
Validation loss: 2.2060107787450156

Epoch: 5| Step: 2
Training loss: 1.9041591882705688
Validation loss: 2.1865967412789664

Epoch: 5| Step: 3
Training loss: 1.7146230936050415
Validation loss: 2.179486925403277

Epoch: 5| Step: 4
Training loss: 2.072674512863159
Validation loss: 2.1707800328731537

Epoch: 5| Step: 5
Training loss: 1.6661176681518555
Validation loss: 2.164398436745008

Epoch: 5| Step: 6
Training loss: 2.1178410053253174
Validation loss: 2.1461895803610482

Epoch: 5| Step: 7
Training loss: 2.3918371200561523
Validation loss: 2.158379832903544

Epoch: 5| Step: 8
Training loss: 1.955824851989746
Validation loss: 2.161598558227221

Epoch: 5| Step: 9
Training loss: 2.031608819961548
Validation loss: 2.151326537132263

Epoch: 5| Step: 10
Training loss: 1.5998080968856812
Validation loss: 2.1577147046724954

Epoch: 5| Step: 11
Training loss: 1.2709429264068604
Validation loss: 2.1737130681673684

Epoch: 235| Step: 0
Training loss: 1.8449974060058594
Validation loss: 2.1693450709184012

Epoch: 5| Step: 1
Training loss: 1.9583184719085693
Validation loss: 2.177334874868393

Epoch: 5| Step: 2
Training loss: 1.7431271076202393
Validation loss: 2.189560423294703

Epoch: 5| Step: 3
Training loss: 1.6462526321411133
Validation loss: 2.196641425291697

Epoch: 5| Step: 4
Training loss: 2.085765838623047
Validation loss: 2.19303930302461

Epoch: 5| Step: 5
Training loss: 1.5561168193817139
Validation loss: 2.1942512691020966

Epoch: 5| Step: 6
Training loss: 1.8316481113433838
Validation loss: 2.192040130496025

Epoch: 5| Step: 7
Training loss: 2.0204195976257324
Validation loss: 2.189760441581408

Epoch: 5| Step: 8
Training loss: 2.472452402114868
Validation loss: 2.1838422616322837

Epoch: 5| Step: 9
Training loss: 1.7548863887786865
Validation loss: 2.1879563331604004

Epoch: 5| Step: 10
Training loss: 1.9155292510986328
Validation loss: 2.1889119942982993

Epoch: 5| Step: 11
Training loss: 1.8578414916992188
Validation loss: 2.2027290562788644

Epoch: 236| Step: 0
Training loss: 1.7261253595352173
Validation loss: 2.180747782190641

Epoch: 5| Step: 1
Training loss: 1.6879212856292725
Validation loss: 2.198206514120102

Epoch: 5| Step: 2
Training loss: 1.625063180923462
Validation loss: 2.183192571004232

Epoch: 5| Step: 3
Training loss: 2.2430777549743652
Validation loss: 2.1770032048225403

Epoch: 5| Step: 4
Training loss: 2.254162311553955
Validation loss: 2.165429358681043

Epoch: 5| Step: 5
Training loss: 2.0860238075256348
Validation loss: 2.1601096789042153

Epoch: 5| Step: 6
Training loss: 1.8871116638183594
Validation loss: 2.140000397960345

Epoch: 5| Step: 7
Training loss: 1.5018212795257568
Validation loss: 2.1445158620675406

Epoch: 5| Step: 8
Training loss: 1.7978929281234741
Validation loss: 2.151971146464348

Epoch: 5| Step: 9
Training loss: 2.731614589691162
Validation loss: 2.1524117290973663

Epoch: 5| Step: 10
Training loss: 1.452754020690918
Validation loss: 2.1469023724397025

Epoch: 5| Step: 11
Training loss: 1.7319022417068481
Validation loss: 2.1480931838353476

Epoch: 237| Step: 0
Training loss: 1.6066226959228516
Validation loss: 2.1457522014776864

Epoch: 5| Step: 1
Training loss: 1.7550313472747803
Validation loss: 2.1741002897421517

Epoch: 5| Step: 2
Training loss: 2.264935255050659
Validation loss: 2.177477757136027

Epoch: 5| Step: 3
Training loss: 1.6313040256500244
Validation loss: 2.1789650271336236

Epoch: 5| Step: 4
Training loss: 1.2676594257354736
Validation loss: 2.1805709848801293

Epoch: 5| Step: 5
Training loss: 1.7999824285507202
Validation loss: 2.1695783585309982

Epoch: 5| Step: 6
Training loss: 2.074706792831421
Validation loss: 2.1771778662999473

Epoch: 5| Step: 7
Training loss: 1.8518511056900024
Validation loss: 2.1679503669341407

Epoch: 5| Step: 8
Training loss: 2.220313787460327
Validation loss: 2.168570121129354

Epoch: 5| Step: 9
Training loss: 2.2548813819885254
Validation loss: 2.1730946799119315

Epoch: 5| Step: 10
Training loss: 1.9551541805267334
Validation loss: 2.170397778352102

Epoch: 5| Step: 11
Training loss: 2.0519485473632812
Validation loss: 2.169258584578832

Epoch: 238| Step: 0
Training loss: 2.377951145172119
Validation loss: 2.1687441070874534

Epoch: 5| Step: 1
Training loss: 1.579481601715088
Validation loss: 2.1651541342337928

Epoch: 5| Step: 2
Training loss: 2.032252311706543
Validation loss: 2.151040400067965

Epoch: 5| Step: 3
Training loss: 2.1635026931762695
Validation loss: 2.143804038564364

Epoch: 5| Step: 4
Training loss: 2.0369837284088135
Validation loss: 2.1514923870563507

Epoch: 5| Step: 5
Training loss: 1.5178735256195068
Validation loss: 2.147206867734591

Epoch: 5| Step: 6
Training loss: 1.5602210760116577
Validation loss: 2.166797568400701

Epoch: 5| Step: 7
Training loss: 2.3082664012908936
Validation loss: 2.1693313817183175

Epoch: 5| Step: 8
Training loss: 1.8876125812530518
Validation loss: 2.1749973942836127

Epoch: 5| Step: 9
Training loss: 1.5294891595840454
Validation loss: 2.1715135176976523

Epoch: 5| Step: 10
Training loss: 1.9301164150238037
Validation loss: 2.182563597957293

Epoch: 5| Step: 11
Training loss: 2.3646535873413086
Validation loss: 2.227851167321205

Epoch: 239| Step: 0
Training loss: 1.6739130020141602
Validation loss: 2.1991199453671775

Epoch: 5| Step: 1
Training loss: 2.415163993835449
Validation loss: 2.192298094431559

Epoch: 5| Step: 2
Training loss: 2.0456550121307373
Validation loss: 2.1842479755481086

Epoch: 5| Step: 3
Training loss: 1.6668426990509033
Validation loss: 2.1751669396956763

Epoch: 5| Step: 4
Training loss: 1.407005786895752
Validation loss: 2.181037500500679

Epoch: 5| Step: 5
Training loss: 2.34580659866333
Validation loss: 2.159569169084231

Epoch: 5| Step: 6
Training loss: 1.9532299041748047
Validation loss: 2.1700746764739356

Epoch: 5| Step: 7
Training loss: 1.6961380243301392
Validation loss: 2.1596666276454926

Epoch: 5| Step: 8
Training loss: 2.0422616004943848
Validation loss: 2.1646160185337067

Epoch: 5| Step: 9
Training loss: 1.8351869583129883
Validation loss: 2.168575863043467

Epoch: 5| Step: 10
Training loss: 1.7673002481460571
Validation loss: 2.1570761303106942

Epoch: 5| Step: 11
Training loss: 3.226656436920166
Validation loss: 2.169666330019633

Epoch: 240| Step: 0
Training loss: 1.7926706075668335
Validation loss: 2.1724004248778024

Epoch: 5| Step: 1
Training loss: 1.9095890522003174
Validation loss: 2.177560339371363

Epoch: 5| Step: 2
Training loss: 2.040139675140381
Validation loss: 2.180690030256907

Epoch: 5| Step: 3
Training loss: 1.922925353050232
Validation loss: 2.1666713456312814

Epoch: 5| Step: 4
Training loss: 1.9479414224624634
Validation loss: 2.1748355577389398

Epoch: 5| Step: 5
Training loss: 2.066678047180176
Validation loss: 2.1644531885782876

Epoch: 5| Step: 6
Training loss: 2.0728812217712402
Validation loss: 2.1709707280000052

Epoch: 5| Step: 7
Training loss: 2.050879716873169
Validation loss: 2.165748273332914

Epoch: 5| Step: 8
Training loss: 1.6238008737564087
Validation loss: 2.1782435476779938

Epoch: 5| Step: 9
Training loss: 1.505312204360962
Validation loss: 2.1557247638702393

Epoch: 5| Step: 10
Training loss: 1.7399810552597046
Validation loss: 2.172657852371534

Epoch: 5| Step: 11
Training loss: 2.657416582107544
Validation loss: 2.151389648516973

Epoch: 241| Step: 0
Training loss: 2.2640857696533203
Validation loss: 2.1564579059680304

Epoch: 5| Step: 1
Training loss: 1.546690821647644
Validation loss: 2.161955699324608

Epoch: 5| Step: 2
Training loss: 1.746072769165039
Validation loss: 2.158956597248713

Epoch: 5| Step: 3
Training loss: 2.3169620037078857
Validation loss: 2.1604999750852585

Epoch: 5| Step: 4
Training loss: 2.628347873687744
Validation loss: 2.1750646829605103

Epoch: 5| Step: 5
Training loss: 1.469435691833496
Validation loss: 2.1680314044157663

Epoch: 5| Step: 6
Training loss: 1.6769659519195557
Validation loss: 2.178947225213051

Epoch: 5| Step: 7
Training loss: 1.6088016033172607
Validation loss: 2.181613261500994

Epoch: 5| Step: 8
Training loss: 1.7943859100341797
Validation loss: 2.1743047535419464

Epoch: 5| Step: 9
Training loss: 2.146273136138916
Validation loss: 2.170911361773809

Epoch: 5| Step: 10
Training loss: 1.5861245393753052
Validation loss: 2.178032477696737

Epoch: 5| Step: 11
Training loss: 1.5674047470092773
Validation loss: 2.1825882345438004

Epoch: 242| Step: 0
Training loss: 1.960288643836975
Validation loss: 2.177569235364596

Epoch: 5| Step: 1
Training loss: 1.8786779642105103
Validation loss: 2.1929614543914795

Epoch: 5| Step: 2
Training loss: 1.5885602235794067
Validation loss: 2.1840996791919074

Epoch: 5| Step: 3
Training loss: 1.7880773544311523
Validation loss: 2.177786166469256

Epoch: 5| Step: 4
Training loss: 1.997933030128479
Validation loss: 2.1808727929989495

Epoch: 5| Step: 5
Training loss: 1.7899959087371826
Validation loss: 2.181807984908422

Epoch: 5| Step: 6
Training loss: 2.0046772956848145
Validation loss: 2.1713687678178153

Epoch: 5| Step: 7
Training loss: 1.611111044883728
Validation loss: 2.1711826970179877

Epoch: 5| Step: 8
Training loss: 2.400320291519165
Validation loss: 2.1805606285730996

Epoch: 5| Step: 9
Training loss: 1.564138412475586
Validation loss: 2.174626037478447

Epoch: 5| Step: 10
Training loss: 2.0460126399993896
Validation loss: 2.1682558904091516

Epoch: 5| Step: 11
Training loss: 2.144601345062256
Validation loss: 2.1869554966688156

Epoch: 243| Step: 0
Training loss: 1.9327129125595093
Validation loss: 2.1783818155527115

Epoch: 5| Step: 1
Training loss: 2.434821605682373
Validation loss: 2.166768083969752

Epoch: 5| Step: 2
Training loss: 1.5248163938522339
Validation loss: 2.191022684176763

Epoch: 5| Step: 3
Training loss: 1.9834619760513306
Validation loss: 2.196188747882843

Epoch: 5| Step: 4
Training loss: 1.8505122661590576
Validation loss: 2.1841384172439575

Epoch: 5| Step: 5
Training loss: 2.3894667625427246
Validation loss: 2.186143159866333

Epoch: 5| Step: 6
Training loss: 1.6435260772705078
Validation loss: 2.1926943361759186

Epoch: 5| Step: 7
Training loss: 1.6190860271453857
Validation loss: 2.1771186888217926

Epoch: 5| Step: 8
Training loss: 1.752427101135254
Validation loss: 2.191121151049932

Epoch: 5| Step: 9
Training loss: 1.6928790807724
Validation loss: 2.187432567278544

Epoch: 5| Step: 10
Training loss: 1.731020212173462
Validation loss: 2.197895665963491

Epoch: 5| Step: 11
Training loss: 1.9545668363571167
Validation loss: 2.196758950750033

Epoch: 244| Step: 0
Training loss: 2.042675733566284
Validation loss: 2.188017929593722

Epoch: 5| Step: 1
Training loss: 1.3628336191177368
Validation loss: 2.1753126283486686

Epoch: 5| Step: 2
Training loss: 1.7443110942840576
Validation loss: 2.194653257727623

Epoch: 5| Step: 3
Training loss: 2.7109107971191406
Validation loss: 2.1938048154115677

Epoch: 5| Step: 4
Training loss: 1.6463861465454102
Validation loss: 2.2034125179052353

Epoch: 5| Step: 5
Training loss: 1.5483849048614502
Validation loss: 2.2105215589205423

Epoch: 5| Step: 6
Training loss: 1.9605575799942017
Validation loss: 2.201697419087092

Epoch: 5| Step: 7
Training loss: 1.8319085836410522
Validation loss: 2.1895175079504647

Epoch: 5| Step: 8
Training loss: 1.4043961763381958
Validation loss: 2.2039005855719247

Epoch: 5| Step: 9
Training loss: 2.341843843460083
Validation loss: 2.199631462494532

Epoch: 5| Step: 10
Training loss: 1.5427405834197998
Validation loss: 2.193539023399353

Epoch: 5| Step: 11
Training loss: 3.18947696685791
Validation loss: 2.206075683236122

Epoch: 245| Step: 0
Training loss: 1.5890862941741943
Validation loss: 2.171534260114034

Epoch: 5| Step: 1
Training loss: 1.9592111110687256
Validation loss: 2.1961238036553064

Epoch: 5| Step: 2
Training loss: 1.9258180856704712
Validation loss: 2.186492105325063

Epoch: 5| Step: 3
Training loss: 2.2416927814483643
Validation loss: 2.195495376984278

Epoch: 5| Step: 4
Training loss: 1.7113679647445679
Validation loss: 2.206922486424446

Epoch: 5| Step: 5
Training loss: 1.8973827362060547
Validation loss: 2.1980902006228766

Epoch: 5| Step: 6
Training loss: 1.4826555252075195
Validation loss: 2.1989384094874063

Epoch: 5| Step: 7
Training loss: 1.8617839813232422
Validation loss: 2.2014089077711105

Epoch: 5| Step: 8
Training loss: 1.9633327722549438
Validation loss: 2.184227560957273

Epoch: 5| Step: 9
Training loss: 2.1174020767211914
Validation loss: 2.188015788793564

Epoch: 5| Step: 10
Training loss: 1.6075223684310913
Validation loss: 2.201058785120646

Epoch: 5| Step: 11
Training loss: 2.90726375579834
Validation loss: 2.183459927638372

Epoch: 246| Step: 0
Training loss: 1.5722825527191162
Validation loss: 2.18923648695151

Epoch: 5| Step: 1
Training loss: 1.66826593875885
Validation loss: 2.1819320619106293

Epoch: 5| Step: 2
Training loss: 2.211423635482788
Validation loss: 2.196461409330368

Epoch: 5| Step: 3
Training loss: 1.884749174118042
Validation loss: 2.2015086909135184

Epoch: 5| Step: 4
Training loss: 1.6722171306610107
Validation loss: 2.2153246104717255

Epoch: 5| Step: 5
Training loss: 2.263082504272461
Validation loss: 2.1826078693072

Epoch: 5| Step: 6
Training loss: 1.8903754949569702
Validation loss: 2.191005860765775

Epoch: 5| Step: 7
Training loss: 1.646958351135254
Validation loss: 2.193402191003164

Epoch: 5| Step: 8
Training loss: 1.6764106750488281
Validation loss: 2.1780313005050025

Epoch: 5| Step: 9
Training loss: 2.003884792327881
Validation loss: 2.1781605978806815

Epoch: 5| Step: 10
Training loss: 1.946455717086792
Validation loss: 2.159523775180181

Epoch: 5| Step: 11
Training loss: 1.3503355979919434
Validation loss: 2.165641481677691

Epoch: 247| Step: 0
Training loss: 1.3291971683502197
Validation loss: 2.178891201814016

Epoch: 5| Step: 1
Training loss: 2.1760902404785156
Validation loss: 2.161639079451561

Epoch: 5| Step: 2
Training loss: 1.5524823665618896
Validation loss: 2.1725218147039413

Epoch: 5| Step: 3
Training loss: 2.1713175773620605
Validation loss: 2.1745442400376

Epoch: 5| Step: 4
Training loss: 2.4056382179260254
Validation loss: 2.182343304157257

Epoch: 5| Step: 5
Training loss: 2.649245500564575
Validation loss: 2.1735238830248513

Epoch: 5| Step: 6
Training loss: 1.8192529678344727
Validation loss: 2.1760521233081818

Epoch: 5| Step: 7
Training loss: 1.6271454095840454
Validation loss: 2.17028716703256

Epoch: 5| Step: 8
Training loss: 2.293393611907959
Validation loss: 2.178291916847229

Epoch: 5| Step: 9
Training loss: 1.227360486984253
Validation loss: 2.170556142926216

Epoch: 5| Step: 10
Training loss: 1.267600655555725
Validation loss: 2.171200489004453

Epoch: 5| Step: 11
Training loss: 0.8676045536994934
Validation loss: 2.1818216294050217

Epoch: 248| Step: 0
Training loss: 2.184793472290039
Validation loss: 2.200173169374466

Epoch: 5| Step: 1
Training loss: 1.5544319152832031
Validation loss: 2.2060477832953134

Epoch: 5| Step: 2
Training loss: 1.7347888946533203
Validation loss: 2.2172993222872415

Epoch: 5| Step: 3
Training loss: 2.0290627479553223
Validation loss: 2.226053853829702

Epoch: 5| Step: 4
Training loss: 2.0755484104156494
Validation loss: 2.2235104391972222

Epoch: 5| Step: 5
Training loss: 2.1010096073150635
Validation loss: 2.202462042371432

Epoch: 5| Step: 6
Training loss: 1.7132699489593506
Validation loss: 2.199150467912356

Epoch: 5| Step: 7
Training loss: 1.7539472579956055
Validation loss: 2.190247356891632

Epoch: 5| Step: 8
Training loss: 2.038020610809326
Validation loss: 2.1736289262771606

Epoch: 5| Step: 9
Training loss: 1.9139471054077148
Validation loss: 2.1483400762081146

Epoch: 5| Step: 10
Training loss: 2.0715866088867188
Validation loss: 2.1635479579369226

Epoch: 5| Step: 11
Training loss: 1.273228645324707
Validation loss: 2.14646045366923

Epoch: 249| Step: 0
Training loss: 1.7895572185516357
Validation loss: 2.143243690331777

Epoch: 5| Step: 1
Training loss: 1.9352054595947266
Validation loss: 2.1436045368512473

Epoch: 5| Step: 2
Training loss: 1.6110420227050781
Validation loss: 2.1438631812731423

Epoch: 5| Step: 3
Training loss: 1.6367413997650146
Validation loss: 2.1492537210385003

Epoch: 5| Step: 4
Training loss: 1.6476796865463257
Validation loss: 2.1579826970895133

Epoch: 5| Step: 5
Training loss: 2.6452388763427734
Validation loss: 2.1678941746552787

Epoch: 5| Step: 6
Training loss: 1.4684293270111084
Validation loss: 2.170299152533213

Epoch: 5| Step: 7
Training loss: 2.065901041030884
Validation loss: 2.1673186272382736

Epoch: 5| Step: 8
Training loss: 2.215640068054199
Validation loss: 2.17140061656634

Epoch: 5| Step: 9
Training loss: 1.8646656274795532
Validation loss: 2.1880582869052887

Epoch: 5| Step: 10
Training loss: 1.6917123794555664
Validation loss: 2.1724043786525726

Epoch: 5| Step: 11
Training loss: 1.4674170017242432
Validation loss: 2.180452545483907

Epoch: 250| Step: 0
Training loss: 1.5441254377365112
Validation loss: 2.189750308791796

Epoch: 5| Step: 1
Training loss: 1.948243498802185
Validation loss: 2.181265115737915

Epoch: 5| Step: 2
Training loss: 2.330130100250244
Validation loss: 2.181246260801951

Epoch: 5| Step: 3
Training loss: 1.6680724620819092
Validation loss: 2.1839486757914224

Epoch: 5| Step: 4
Training loss: 2.0401909351348877
Validation loss: 2.174436499675115

Epoch: 5| Step: 5
Training loss: 1.7612985372543335
Validation loss: 2.171491007010142

Epoch: 5| Step: 6
Training loss: 1.4684600830078125
Validation loss: 2.177796463171641

Epoch: 5| Step: 7
Training loss: 1.7096974849700928
Validation loss: 2.158427596092224

Epoch: 5| Step: 8
Training loss: 1.8616533279418945
Validation loss: 2.182898983359337

Epoch: 5| Step: 9
Training loss: 1.3957079648971558
Validation loss: 2.1785360872745514

Epoch: 5| Step: 10
Training loss: 2.605198383331299
Validation loss: 2.197910318771998

Epoch: 5| Step: 11
Training loss: 1.2121528387069702
Validation loss: 2.17864998181661

Epoch: 251| Step: 0
Training loss: 1.7347158193588257
Validation loss: 2.212152903278669

Epoch: 5| Step: 1
Training loss: 1.3458575010299683
Validation loss: 2.225204279025396

Epoch: 5| Step: 2
Training loss: 1.8696365356445312
Validation loss: 2.22905196249485

Epoch: 5| Step: 3
Training loss: 1.7155163288116455
Validation loss: 2.187936623891195

Epoch: 5| Step: 4
Training loss: 1.8074867725372314
Validation loss: 2.2065410365660987

Epoch: 5| Step: 5
Training loss: 1.6650276184082031
Validation loss: 2.2060033281644187

Epoch: 5| Step: 6
Training loss: 2.1395103931427
Validation loss: 2.1951125313838324

Epoch: 5| Step: 7
Training loss: 2.3745198249816895
Validation loss: 2.180424988269806

Epoch: 5| Step: 8
Training loss: 1.8848469257354736
Validation loss: 2.1940018037954965

Epoch: 5| Step: 9
Training loss: 2.227735996246338
Validation loss: 2.179746021827062

Epoch: 5| Step: 10
Training loss: 1.7566983699798584
Validation loss: 2.17748686671257

Epoch: 5| Step: 11
Training loss: 0.7627472281455994
Validation loss: 2.1853159765402475

Epoch: 252| Step: 0
Training loss: 1.7322604656219482
Validation loss: 2.1739408671855927

Epoch: 5| Step: 1
Training loss: 1.7692512273788452
Validation loss: 2.1910128543774285

Epoch: 5| Step: 2
Training loss: 2.1592860221862793
Validation loss: 2.172391032179197

Epoch: 5| Step: 3
Training loss: 1.7867399454116821
Validation loss: 2.1822874744733176

Epoch: 5| Step: 4
Training loss: 1.6949892044067383
Validation loss: 2.1867915292580924

Epoch: 5| Step: 5
Training loss: 2.04221510887146
Validation loss: 2.1896289537350335

Epoch: 5| Step: 6
Training loss: 1.8421268463134766
Validation loss: 2.200981209675471

Epoch: 5| Step: 7
Training loss: 1.71207594871521
Validation loss: 2.2004082202911377

Epoch: 5| Step: 8
Training loss: 1.7216917276382446
Validation loss: 2.171124349037806

Epoch: 5| Step: 9
Training loss: 1.5150178670883179
Validation loss: 2.1612510631481805

Epoch: 5| Step: 10
Training loss: 2.1987740993499756
Validation loss: 2.1693962762753167

Epoch: 5| Step: 11
Training loss: 2.9414284229278564
Validation loss: 2.1696776847044625

Epoch: 253| Step: 0
Training loss: 1.6916640996932983
Validation loss: 2.168913965423902

Epoch: 5| Step: 1
Training loss: 1.777599573135376
Validation loss: 2.1712458233038583

Epoch: 5| Step: 2
Training loss: 1.8860365152359009
Validation loss: 2.1674432456493378

Epoch: 5| Step: 3
Training loss: 1.7524325847625732
Validation loss: 2.1670376559098563

Epoch: 5| Step: 4
Training loss: 1.620771050453186
Validation loss: 2.1683994978666306

Epoch: 5| Step: 5
Training loss: 2.0174877643585205
Validation loss: 2.1698781102895737

Epoch: 5| Step: 6
Training loss: 2.0738022327423096
Validation loss: 2.1722395022710166

Epoch: 5| Step: 7
Training loss: 1.6650711297988892
Validation loss: 2.1743299265702567

Epoch: 5| Step: 8
Training loss: 1.6363048553466797
Validation loss: 2.2117442886034646

Epoch: 5| Step: 9
Training loss: 2.2044878005981445
Validation loss: 2.211104765534401

Epoch: 5| Step: 10
Training loss: 1.6756387948989868
Validation loss: 2.219416235884031

Epoch: 5| Step: 11
Training loss: 2.9739973545074463
Validation loss: 2.2200676997502646

Epoch: 254| Step: 0
Training loss: 1.8765188455581665
Validation loss: 2.2486118376255035

Epoch: 5| Step: 1
Training loss: 1.4461419582366943
Validation loss: 2.2348800698916116

Epoch: 5| Step: 2
Training loss: 1.9175446033477783
Validation loss: 2.2575318068265915

Epoch: 5| Step: 3
Training loss: 1.6601600646972656
Validation loss: 2.2311440209547677

Epoch: 5| Step: 4
Training loss: 2.289716958999634
Validation loss: 2.2097826500733695

Epoch: 5| Step: 5
Training loss: 1.6694023609161377
Validation loss: 2.1847616732120514

Epoch: 5| Step: 6
Training loss: 1.9759689569473267
Validation loss: 2.200559139251709

Epoch: 5| Step: 7
Training loss: 1.8659206628799438
Validation loss: 2.174838980038961

Epoch: 5| Step: 8
Training loss: 1.405668020248413
Validation loss: 2.192701001962026

Epoch: 5| Step: 9
Training loss: 2.3794105052948
Validation loss: 2.1832142770290375

Epoch: 5| Step: 10
Training loss: 1.9643446207046509
Validation loss: 2.1954124669233956

Epoch: 5| Step: 11
Training loss: 1.6847238540649414
Validation loss: 2.1850182314713797

Epoch: 255| Step: 0
Training loss: 2.0285708904266357
Validation loss: 2.1840317646662393

Epoch: 5| Step: 1
Training loss: 1.4595863819122314
Validation loss: 2.1954517463843026

Epoch: 5| Step: 2
Training loss: 1.6906585693359375
Validation loss: 2.1935954044262567

Epoch: 5| Step: 3
Training loss: 1.8145053386688232
Validation loss: 2.196231186389923

Epoch: 5| Step: 4
Training loss: 1.5633050203323364
Validation loss: 2.2043969432512918

Epoch: 5| Step: 5
Training loss: 2.131084442138672
Validation loss: 2.187955836455027

Epoch: 5| Step: 6
Training loss: 1.8068023920059204
Validation loss: 2.183746332923571

Epoch: 5| Step: 7
Training loss: 1.917607069015503
Validation loss: 2.1797647923231125

Epoch: 5| Step: 8
Training loss: 2.3470563888549805
Validation loss: 2.190288374821345

Epoch: 5| Step: 9
Training loss: 1.7321914434432983
Validation loss: 2.164398267865181

Epoch: 5| Step: 10
Training loss: 2.020298957824707
Validation loss: 2.191305160522461

Epoch: 5| Step: 11
Training loss: 1.4331125020980835
Validation loss: 2.1991207549969354

Epoch: 256| Step: 0
Training loss: 1.6261661052703857
Validation loss: 2.199505110581716

Epoch: 5| Step: 1
Training loss: 1.7361074686050415
Validation loss: 2.2134245534737906

Epoch: 5| Step: 2
Training loss: 1.4309993982315063
Validation loss: 2.20643741885821

Epoch: 5| Step: 3
Training loss: 2.089825391769409
Validation loss: 2.210864841938019

Epoch: 5| Step: 4
Training loss: 2.104357957839966
Validation loss: 2.2255590558052063

Epoch: 5| Step: 5
Training loss: 1.8539520502090454
Validation loss: 2.2036115328470864

Epoch: 5| Step: 6
Training loss: 2.200623035430908
Validation loss: 2.2108567655086517

Epoch: 5| Step: 7
Training loss: 1.500201940536499
Validation loss: 2.2186083495616913

Epoch: 5| Step: 8
Training loss: 1.9775774478912354
Validation loss: 2.223883440097173

Epoch: 5| Step: 9
Training loss: 1.652165412902832
Validation loss: 2.226178323229154

Epoch: 5| Step: 10
Training loss: 1.5977632999420166
Validation loss: 2.186097393433253

Epoch: 5| Step: 11
Training loss: 3.36781644821167
Validation loss: 2.195032149553299

Epoch: 257| Step: 0
Training loss: 1.9370378255844116
Validation loss: 2.1912290950616202

Epoch: 5| Step: 1
Training loss: 1.8794376850128174
Validation loss: 2.187195340792338

Epoch: 5| Step: 2
Training loss: 1.6541945934295654
Validation loss: 2.1868983109792075

Epoch: 5| Step: 3
Training loss: 0.9890556335449219
Validation loss: 2.1848687678575516

Epoch: 5| Step: 4
Training loss: 1.7132132053375244
Validation loss: 2.185519610842069

Epoch: 5| Step: 5
Training loss: 2.0656116008758545
Validation loss: 2.168657804528872

Epoch: 5| Step: 6
Training loss: 1.8761417865753174
Validation loss: 2.1554770867029824

Epoch: 5| Step: 7
Training loss: 1.599300503730774
Validation loss: 2.1797654380400977

Epoch: 5| Step: 8
Training loss: 2.5788722038269043
Validation loss: 2.1730688561995826

Epoch: 5| Step: 9
Training loss: 2.162565231323242
Validation loss: 2.168743217984835

Epoch: 5| Step: 10
Training loss: 1.6812280416488647
Validation loss: 2.173434962828954

Epoch: 5| Step: 11
Training loss: 2.993917942047119
Validation loss: 2.163781409462293

Epoch: 258| Step: 0
Training loss: 1.4924670457839966
Validation loss: 2.181124563018481

Epoch: 5| Step: 1
Training loss: 1.5411418676376343
Validation loss: 2.163189649581909

Epoch: 5| Step: 2
Training loss: 1.8143959045410156
Validation loss: 2.1892648736635842

Epoch: 5| Step: 3
Training loss: 1.661498785018921
Validation loss: 2.2053669591744742

Epoch: 5| Step: 4
Training loss: 1.9946914911270142
Validation loss: 2.2108854254086814

Epoch: 5| Step: 5
Training loss: 1.8914903402328491
Validation loss: 2.230187396208445

Epoch: 5| Step: 6
Training loss: 2.0799427032470703
Validation loss: 2.251060644785563

Epoch: 5| Step: 7
Training loss: 1.7964022159576416
Validation loss: 2.2395673791567483

Epoch: 5| Step: 8
Training loss: 1.8646080493927002
Validation loss: 2.236497551202774

Epoch: 5| Step: 9
Training loss: 2.0980489253997803
Validation loss: 2.2190681844949722

Epoch: 5| Step: 10
Training loss: 2.0101990699768066
Validation loss: 2.2053315242131553

Epoch: 5| Step: 11
Training loss: 1.8037400245666504
Validation loss: 2.1668291489283242

Epoch: 259| Step: 0
Training loss: 1.3460594415664673
Validation loss: 2.1905956864356995

Epoch: 5| Step: 1
Training loss: 1.8960838317871094
Validation loss: 2.1622228771448135

Epoch: 5| Step: 2
Training loss: 1.7123504877090454
Validation loss: 2.1612018992503486

Epoch: 5| Step: 3
Training loss: 2.0100269317626953
Validation loss: 2.147907391190529

Epoch: 5| Step: 4
Training loss: 1.9515819549560547
Validation loss: 2.1603591491778693

Epoch: 5| Step: 5
Training loss: 2.2704663276672363
Validation loss: 2.1462513208389282

Epoch: 5| Step: 6
Training loss: 2.336108446121216
Validation loss: 2.158366690079371

Epoch: 5| Step: 7
Training loss: 2.095583438873291
Validation loss: 2.1741259396076202

Epoch: 5| Step: 8
Training loss: 1.281111717224121
Validation loss: 2.1740502218405404

Epoch: 5| Step: 9
Training loss: 1.5649621486663818
Validation loss: 2.232932905356089

Epoch: 5| Step: 10
Training loss: 2.2375519275665283
Validation loss: 2.238266199827194

Epoch: 5| Step: 11
Training loss: 2.5043556690216064
Validation loss: 2.2579415440559387

Epoch: 260| Step: 0
Training loss: 1.7295811176300049
Validation loss: 2.2800412078698478

Epoch: 5| Step: 1
Training loss: 1.9895588159561157
Validation loss: 2.2736261983712516

Epoch: 5| Step: 2
Training loss: 2.0042026042938232
Validation loss: 2.278208980957667

Epoch: 5| Step: 3
Training loss: 1.9782136678695679
Validation loss: 2.2531441996494928

Epoch: 5| Step: 4
Training loss: 1.6023051738739014
Validation loss: 2.2362409830093384

Epoch: 5| Step: 5
Training loss: 2.380354404449463
Validation loss: 2.1989025125900903

Epoch: 5| Step: 6
Training loss: 2.285794734954834
Validation loss: 2.1660461922486625

Epoch: 5| Step: 7
Training loss: 2.320831775665283
Validation loss: 2.1476120750109353

Epoch: 5| Step: 8
Training loss: 2.065109968185425
Validation loss: 2.144665241241455

Epoch: 5| Step: 9
Training loss: 1.488503336906433
Validation loss: 2.1479327380657196

Epoch: 5| Step: 10
Training loss: 1.583806037902832
Validation loss: 2.1426176925500235

Epoch: 5| Step: 11
Training loss: 1.1677851676940918
Validation loss: 2.1440694332122803

Epoch: 261| Step: 0
Training loss: 1.5179147720336914
Validation loss: 2.138522227605184

Epoch: 5| Step: 1
Training loss: 1.561328411102295
Validation loss: 2.154949257771174

Epoch: 5| Step: 2
Training loss: 2.312828302383423
Validation loss: 2.1572116216023765

Epoch: 5| Step: 3
Training loss: 2.8907065391540527
Validation loss: 2.1633704900741577

Epoch: 5| Step: 4
Training loss: 2.092329502105713
Validation loss: 2.193649629751841

Epoch: 5| Step: 5
Training loss: 1.9205795526504517
Validation loss: 2.2213260531425476

Epoch: 5| Step: 6
Training loss: 1.4932388067245483
Validation loss: 2.2552558332681656

Epoch: 5| Step: 7
Training loss: 1.7897402048110962
Validation loss: 2.2276698648929596

Epoch: 5| Step: 8
Training loss: 2.104241371154785
Validation loss: 2.2177556604146957

Epoch: 5| Step: 9
Training loss: 1.4024651050567627
Validation loss: 2.2085187137126923

Epoch: 5| Step: 10
Training loss: 1.6434484720230103
Validation loss: 2.196339433391889

Epoch: 5| Step: 11
Training loss: 1.8268201351165771
Validation loss: 2.1723691870768866

Epoch: 262| Step: 0
Training loss: 1.4360271692276
Validation loss: 2.1612816005945206

Epoch: 5| Step: 1
Training loss: 1.9460827112197876
Validation loss: 2.1835677127043405

Epoch: 5| Step: 2
Training loss: 2.055227279663086
Validation loss: 2.1543249686559043

Epoch: 5| Step: 3
Training loss: 1.9455267190933228
Validation loss: 2.152270659804344

Epoch: 5| Step: 4
Training loss: 2.478043794631958
Validation loss: 2.1561135947704315

Epoch: 5| Step: 5
Training loss: 1.6202924251556396
Validation loss: 2.170458734035492

Epoch: 5| Step: 6
Training loss: 2.026298761367798
Validation loss: 2.1693627387285233

Epoch: 5| Step: 7
Training loss: 1.5680723190307617
Validation loss: 2.158470024665197

Epoch: 5| Step: 8
Training loss: 1.6123580932617188
Validation loss: 2.1785183399915695

Epoch: 5| Step: 9
Training loss: 2.0817160606384277
Validation loss: 2.1944374392429986

Epoch: 5| Step: 10
Training loss: 1.9122726917266846
Validation loss: 2.221559857328733

Epoch: 5| Step: 11
Training loss: 1.4379762411117554
Validation loss: 2.242778251568476

Epoch: 263| Step: 0
Training loss: 1.8716373443603516
Validation loss: 2.229081134001414

Epoch: 5| Step: 1
Training loss: 1.8146461248397827
Validation loss: 2.226038853327433

Epoch: 5| Step: 2
Training loss: 1.9003713130950928
Validation loss: 2.2158786753813424

Epoch: 5| Step: 3
Training loss: 2.180713176727295
Validation loss: 2.2062410712242126

Epoch: 5| Step: 4
Training loss: 2.149386167526245
Validation loss: 2.191172569990158

Epoch: 5| Step: 5
Training loss: 1.8159573078155518
Validation loss: 2.188069502512614

Epoch: 5| Step: 6
Training loss: 2.1010594367980957
Validation loss: 2.1790740936994553

Epoch: 5| Step: 7
Training loss: 2.1092965602874756
Validation loss: 2.163136343161265

Epoch: 5| Step: 8
Training loss: 1.718520164489746
Validation loss: 2.1599300503730774

Epoch: 5| Step: 9
Training loss: 1.4177494049072266
Validation loss: 2.1560100466012955

Epoch: 5| Step: 10
Training loss: 1.1613996028900146
Validation loss: 2.1558267325162888

Epoch: 5| Step: 11
Training loss: 2.0044240951538086
Validation loss: 2.1474987069765725

Epoch: 264| Step: 0
Training loss: 2.1926558017730713
Validation loss: 2.1608986208836236

Epoch: 5| Step: 1
Training loss: 1.215302586555481
Validation loss: 2.1777446617682776

Epoch: 5| Step: 2
Training loss: 1.7202917337417603
Validation loss: 2.177575627962748

Epoch: 5| Step: 3
Training loss: 2.063241481781006
Validation loss: 2.2012667655944824

Epoch: 5| Step: 4
Training loss: 1.9165408611297607
Validation loss: 2.2115775297085443

Epoch: 5| Step: 5
Training loss: 1.902519941329956
Validation loss: 2.24271696805954

Epoch: 5| Step: 6
Training loss: 1.816860556602478
Validation loss: 2.2469357351462045

Epoch: 5| Step: 7
Training loss: 2.007972478866577
Validation loss: 2.2534139454364777

Epoch: 5| Step: 8
Training loss: 1.7706445455551147
Validation loss: 2.2308283746242523

Epoch: 5| Step: 9
Training loss: 2.1061418056488037
Validation loss: 2.2112541248401008

Epoch: 5| Step: 10
Training loss: 1.7064101696014404
Validation loss: 2.214240774512291

Epoch: 5| Step: 11
Training loss: 1.0367012023925781
Validation loss: 2.1930049459139505

Epoch: 265| Step: 0
Training loss: 1.4165469408035278
Validation loss: 2.2083885769049325

Epoch: 5| Step: 1
Training loss: 1.846967339515686
Validation loss: 2.2247754832108817

Epoch: 5| Step: 2
Training loss: 1.6848876476287842
Validation loss: 2.2121013402938843

Epoch: 5| Step: 3
Training loss: 1.9743648767471313
Validation loss: 2.2245872914791107

Epoch: 5| Step: 4
Training loss: 1.1354910135269165
Validation loss: 2.2283720870812735

Epoch: 5| Step: 5
Training loss: 2.16542387008667
Validation loss: 2.2339770744244256

Epoch: 5| Step: 6
Training loss: 2.336113452911377
Validation loss: 2.231832966208458

Epoch: 5| Step: 7
Training loss: 1.9684159755706787
Validation loss: 2.230311304330826

Epoch: 5| Step: 8
Training loss: 1.3905916213989258
Validation loss: 2.241134767731031

Epoch: 5| Step: 9
Training loss: 2.118162155151367
Validation loss: 2.2135899464289346

Epoch: 5| Step: 10
Training loss: 1.716881513595581
Validation loss: 2.2092680484056473

Epoch: 5| Step: 11
Training loss: 2.271904468536377
Validation loss: 2.2072386840979257

Epoch: 266| Step: 0
Training loss: 1.7996546030044556
Validation loss: 2.2128323912620544

Epoch: 5| Step: 1
Training loss: 2.1915996074676514
Validation loss: 2.195333326856295

Epoch: 5| Step: 2
Training loss: 1.598530650138855
Validation loss: 2.204653725028038

Epoch: 5| Step: 3
Training loss: 1.8943891525268555
Validation loss: 2.207293430964152

Epoch: 5| Step: 4
Training loss: 1.3979326486587524
Validation loss: 2.1869665582974753

Epoch: 5| Step: 5
Training loss: 1.8068978786468506
Validation loss: 2.191606968641281

Epoch: 5| Step: 6
Training loss: 1.9595130681991577
Validation loss: 2.1984350979328156

Epoch: 5| Step: 7
Training loss: 2.042112112045288
Validation loss: 2.192323942979177

Epoch: 5| Step: 8
Training loss: 1.7051995992660522
Validation loss: 2.1998497198025384

Epoch: 5| Step: 9
Training loss: 1.7580726146697998
Validation loss: 2.19744045039018

Epoch: 5| Step: 10
Training loss: 2.0965161323547363
Validation loss: 2.2084278662999473

Epoch: 5| Step: 11
Training loss: 1.0750070810317993
Validation loss: 2.1936527689297995

Epoch: 267| Step: 0
Training loss: 2.402564525604248
Validation loss: 2.2131848335266113

Epoch: 5| Step: 1
Training loss: 1.9487384557724
Validation loss: 2.228123406569163

Epoch: 5| Step: 2
Training loss: 1.358231544494629
Validation loss: 2.2390924940506616

Epoch: 5| Step: 3
Training loss: 1.865317940711975
Validation loss: 2.221009055773417

Epoch: 5| Step: 4
Training loss: 1.9761402606964111
Validation loss: 2.2273113429546356

Epoch: 5| Step: 5
Training loss: 1.7955509424209595
Validation loss: 2.2377133270104728

Epoch: 5| Step: 6
Training loss: 1.4980747699737549
Validation loss: 2.212358350555102

Epoch: 5| Step: 7
Training loss: 1.9579252004623413
Validation loss: 2.1908793598413467

Epoch: 5| Step: 8
Training loss: 1.7751729488372803
Validation loss: 2.1589336693286896

Epoch: 5| Step: 9
Training loss: 2.038818597793579
Validation loss: 2.1590445886055627

Epoch: 5| Step: 10
Training loss: 2.018375873565674
Validation loss: 2.159750218192736

Epoch: 5| Step: 11
Training loss: 2.2915046215057373
Validation loss: 2.1627852420012155

Epoch: 268| Step: 0
Training loss: 1.697418212890625
Validation loss: 2.1582195361455283

Epoch: 5| Step: 1
Training loss: 0.9750421643257141
Validation loss: 2.1779941618442535

Epoch: 5| Step: 2
Training loss: 1.3436706066131592
Validation loss: 2.188781584302584

Epoch: 5| Step: 3
Training loss: 1.8833410739898682
Validation loss: 2.207281246781349

Epoch: 5| Step: 4
Training loss: 2.0165650844573975
Validation loss: 2.229262183109919

Epoch: 5| Step: 5
Training loss: 1.9631469249725342
Validation loss: 2.26768351594607

Epoch: 5| Step: 6
Training loss: 2.0203487873077393
Validation loss: 2.258441617091497

Epoch: 5| Step: 7
Training loss: 2.374439001083374
Validation loss: 2.276521454254786

Epoch: 5| Step: 8
Training loss: 1.7363191843032837
Validation loss: 2.2778602143128714

Epoch: 5| Step: 9
Training loss: 2.098510265350342
Validation loss: 2.294127494096756

Epoch: 5| Step: 10
Training loss: 1.787475347518921
Validation loss: 2.2756321728229523

Epoch: 5| Step: 11
Training loss: 2.590636730194092
Validation loss: 2.239491894841194

Epoch: 269| Step: 0
Training loss: 1.9067436456680298
Validation loss: 2.2387021481990814

Epoch: 5| Step: 1
Training loss: 1.4237921237945557
Validation loss: 2.2077572544415793

Epoch: 5| Step: 2
Training loss: 1.8451690673828125
Validation loss: 2.170105293393135

Epoch: 5| Step: 3
Training loss: 2.197509288787842
Validation loss: 2.1830304513374963

Epoch: 5| Step: 4
Training loss: 1.6724073886871338
Validation loss: 2.1512457032998404

Epoch: 5| Step: 5
Training loss: 1.818389654159546
Validation loss: 2.1722770581642785

Epoch: 5| Step: 6
Training loss: 1.8145555257797241
Validation loss: 2.1646529336770377

Epoch: 5| Step: 7
Training loss: 1.7887418270111084
Validation loss: 2.151844342549642

Epoch: 5| Step: 8
Training loss: 1.345528244972229
Validation loss: 2.1554597318172455

Epoch: 5| Step: 9
Training loss: 2.140498638153076
Validation loss: 2.1561407844225564

Epoch: 5| Step: 10
Training loss: 1.732574462890625
Validation loss: 2.1676635493834815

Epoch: 5| Step: 11
Training loss: 2.7924702167510986
Validation loss: 2.205908934275309

Epoch: 270| Step: 0
Training loss: 1.9937410354614258
Validation loss: 2.227723404765129

Epoch: 5| Step: 1
Training loss: 1.6542856693267822
Validation loss: 2.2619612365961075

Epoch: 5| Step: 2
Training loss: 2.1594769954681396
Validation loss: 2.2518598288297653

Epoch: 5| Step: 3
Training loss: 1.7267391681671143
Validation loss: 2.253092428048452

Epoch: 5| Step: 4
Training loss: 1.439594030380249
Validation loss: 2.220136284828186

Epoch: 5| Step: 5
Training loss: 1.3255631923675537
Validation loss: 2.2081642150878906

Epoch: 5| Step: 6
Training loss: 1.5994304418563843
Validation loss: 2.213154971599579

Epoch: 5| Step: 7
Training loss: 1.6778030395507812
Validation loss: 2.2090756048758826

Epoch: 5| Step: 8
Training loss: 1.7975280284881592
Validation loss: 2.2031164218982062

Epoch: 5| Step: 9
Training loss: 2.619863986968994
Validation loss: 2.2062864750623703

Epoch: 5| Step: 10
Training loss: 2.2481093406677246
Validation loss: 2.207042912642161

Epoch: 5| Step: 11
Training loss: 0.7901940941810608
Validation loss: 2.200154259800911

Epoch: 271| Step: 0
Training loss: 2.007291078567505
Validation loss: 2.217308590809504

Epoch: 5| Step: 1
Training loss: 2.2399795055389404
Validation loss: 2.2309638410806656

Epoch: 5| Step: 2
Training loss: 2.4303646087646484
Validation loss: 2.2567011465628943

Epoch: 5| Step: 3
Training loss: 2.1151363849639893
Validation loss: 2.262448102235794

Epoch: 5| Step: 4
Training loss: 1.992518424987793
Validation loss: 2.2560038616259894

Epoch: 5| Step: 5
Training loss: 1.6278674602508545
Validation loss: 2.2338942488034568

Epoch: 5| Step: 6
Training loss: 1.1143826246261597
Validation loss: 2.214493691921234

Epoch: 5| Step: 7
Training loss: 1.4007973670959473
Validation loss: 2.1826207041740417

Epoch: 5| Step: 8
Training loss: 1.6185486316680908
Validation loss: 2.1602569073438644

Epoch: 5| Step: 9
Training loss: 1.6490780115127563
Validation loss: 2.147693162163099

Epoch: 5| Step: 10
Training loss: 1.60550057888031
Validation loss: 2.1660901258389154

Epoch: 5| Step: 11
Training loss: 2.668499708175659
Validation loss: 2.153302272160848

Epoch: 272| Step: 0
Training loss: 1.9871032238006592
Validation loss: 2.1599524915218353

Epoch: 5| Step: 1
Training loss: 1.1193236112594604
Validation loss: 2.163451055685679

Epoch: 5| Step: 2
Training loss: 1.7391316890716553
Validation loss: 2.1584401627381644

Epoch: 5| Step: 3
Training loss: 1.9045031070709229
Validation loss: 2.156109243631363

Epoch: 5| Step: 4
Training loss: 1.6876857280731201
Validation loss: 2.163924068212509

Epoch: 5| Step: 5
Training loss: 2.0375404357910156
Validation loss: 2.172381192445755

Epoch: 5| Step: 6
Training loss: 2.372276782989502
Validation loss: 2.160762220621109

Epoch: 5| Step: 7
Training loss: 1.4001973867416382
Validation loss: 2.1806469162305198

Epoch: 5| Step: 8
Training loss: 2.194441080093384
Validation loss: 2.1747332513332367

Epoch: 5| Step: 9
Training loss: 1.8005586862564087
Validation loss: 2.194152389963468

Epoch: 5| Step: 10
Training loss: 1.8698704242706299
Validation loss: 2.2218124171098075

Epoch: 5| Step: 11
Training loss: 1.5404510498046875
Validation loss: 2.224779407183329

Epoch: 273| Step: 0
Training loss: 1.7818572521209717
Validation loss: 2.2741377502679825

Epoch: 5| Step: 1
Training loss: 1.9270856380462646
Validation loss: 2.2928433815638223

Epoch: 5| Step: 2
Training loss: 2.1215779781341553
Validation loss: 2.254329025745392

Epoch: 5| Step: 3
Training loss: 2.2468090057373047
Validation loss: 2.2948132952054343

Epoch: 5| Step: 4
Training loss: 2.0218429565429688
Validation loss: 2.2701295812924704

Epoch: 5| Step: 5
Training loss: 2.0732603073120117
Validation loss: 2.255948916077614

Epoch: 5| Step: 6
Training loss: 1.5921748876571655
Validation loss: 2.227881749471029

Epoch: 5| Step: 7
Training loss: 1.6223466396331787
Validation loss: 2.2223690946896872

Epoch: 5| Step: 8
Training loss: 1.818334937095642
Validation loss: 2.192333127061526

Epoch: 5| Step: 9
Training loss: 1.6565401554107666
Validation loss: 2.1637292752663293

Epoch: 5| Step: 10
Training loss: 1.8293864727020264
Validation loss: 2.1608977019786835

Epoch: 5| Step: 11
Training loss: 0.9766018986701965
Validation loss: 2.178149163722992

Epoch: 274| Step: 0
Training loss: 1.769862174987793
Validation loss: 2.1801618884007135

Epoch: 5| Step: 1
Training loss: 2.1296467781066895
Validation loss: 2.1975712974866233

Epoch: 5| Step: 2
Training loss: 1.6600768566131592
Validation loss: 2.2162132064501443

Epoch: 5| Step: 3
Training loss: 1.6768848896026611
Validation loss: 2.2195065518220267

Epoch: 5| Step: 4
Training loss: 2.2616584300994873
Validation loss: 2.2309534599383674

Epoch: 5| Step: 5
Training loss: 1.4879493713378906
Validation loss: 2.2701334257920585

Epoch: 5| Step: 6
Training loss: 1.6900818347930908
Validation loss: 2.265271246433258

Epoch: 5| Step: 7
Training loss: 2.458523988723755
Validation loss: 2.250078648328781

Epoch: 5| Step: 8
Training loss: 1.7641369104385376
Validation loss: 2.2660058736801147

Epoch: 5| Step: 9
Training loss: 1.5668983459472656
Validation loss: 2.2721567153930664

Epoch: 5| Step: 10
Training loss: 1.5326108932495117
Validation loss: 2.2520124514897666

Epoch: 5| Step: 11
Training loss: 1.8087667226791382
Validation loss: 2.224918082356453

Epoch: 275| Step: 0
Training loss: 2.0278477668762207
Validation loss: 2.242152323325475

Epoch: 5| Step: 1
Training loss: 1.710860013961792
Validation loss: 2.2142224510510764

Epoch: 5| Step: 2
Training loss: 2.267458200454712
Validation loss: 2.199984297156334

Epoch: 5| Step: 3
Training loss: 1.1997953653335571
Validation loss: 2.1863120645284653

Epoch: 5| Step: 4
Training loss: 1.9041640758514404
Validation loss: 2.17513200143973

Epoch: 5| Step: 5
Training loss: 2.0493111610412598
Validation loss: 2.1924059987068176

Epoch: 5| Step: 6
Training loss: 2.318634271621704
Validation loss: 2.202650010585785

Epoch: 5| Step: 7
Training loss: 1.9279568195343018
Validation loss: 2.2119813511768975

Epoch: 5| Step: 8
Training loss: 1.240566611289978
Validation loss: 2.1784108678499856

Epoch: 5| Step: 9
Training loss: 1.7397915124893188
Validation loss: 2.1841847896575928

Epoch: 5| Step: 10
Training loss: 1.9494355916976929
Validation loss: 2.177619223793348

Epoch: 5| Step: 11
Training loss: 2.8195347785949707
Validation loss: 2.182410458723704

Epoch: 276| Step: 0
Training loss: 2.097503900527954
Validation loss: 2.191546897093455

Epoch: 5| Step: 1
Training loss: 1.6729762554168701
Validation loss: 2.1786634773015976

Epoch: 5| Step: 2
Training loss: 1.8385035991668701
Validation loss: 2.175547882914543

Epoch: 5| Step: 3
Training loss: 1.647552490234375
Validation loss: 2.1799076348543167

Epoch: 5| Step: 4
Training loss: 2.405526638031006
Validation loss: 2.191989461580912

Epoch: 5| Step: 5
Training loss: 1.4356878995895386
Validation loss: 2.17846209804217

Epoch: 5| Step: 6
Training loss: 1.63461434841156
Validation loss: 2.186194787422816

Epoch: 5| Step: 7
Training loss: 1.9362056255340576
Validation loss: 2.1852715214093528

Epoch: 5| Step: 8
Training loss: 1.4154784679412842
Validation loss: 2.1767061203718185

Epoch: 5| Step: 9
Training loss: 2.159900665283203
Validation loss: 2.1805584828058877

Epoch: 5| Step: 10
Training loss: 1.7837635278701782
Validation loss: 2.1812503337860107

Epoch: 5| Step: 11
Training loss: 1.6813974380493164
Validation loss: 2.190571034948031

Epoch: 277| Step: 0
Training loss: 1.7274068593978882
Validation loss: 2.1918050398429236

Epoch: 5| Step: 1
Training loss: 1.950669527053833
Validation loss: 2.198580657442411

Epoch: 5| Step: 2
Training loss: 1.6016786098480225
Validation loss: 2.196062679092089

Epoch: 5| Step: 3
Training loss: 1.7039579153060913
Validation loss: 2.218747546275457

Epoch: 5| Step: 4
Training loss: 1.3643052577972412
Validation loss: 2.228631312648455

Epoch: 5| Step: 5
Training loss: 1.9061830043792725
Validation loss: 2.2273319363594055

Epoch: 5| Step: 6
Training loss: 1.3118479251861572
Validation loss: 2.2028456926345825

Epoch: 5| Step: 7
Training loss: 2.0003719329833984
Validation loss: 2.2115156749884286

Epoch: 5| Step: 8
Training loss: 2.3404669761657715
Validation loss: 2.19147327542305

Epoch: 5| Step: 9
Training loss: 2.2129034996032715
Validation loss: 2.1791881322860718

Epoch: 5| Step: 10
Training loss: 1.5459787845611572
Validation loss: 2.1978520303964615

Epoch: 5| Step: 11
Training loss: 2.022129535675049
Validation loss: 2.1785318007071814

Epoch: 278| Step: 0
Training loss: 1.7606713771820068
Validation loss: 2.182815675934156

Epoch: 5| Step: 1
Training loss: 1.3173301219940186
Validation loss: 2.165952980518341

Epoch: 5| Step: 2
Training loss: 1.8702481985092163
Validation loss: 2.1874030580123267

Epoch: 5| Step: 3
Training loss: 1.790024757385254
Validation loss: 2.1730806479851403

Epoch: 5| Step: 4
Training loss: 2.0692954063415527
Validation loss: 2.1732704788446426

Epoch: 5| Step: 5
Training loss: 1.769004464149475
Validation loss: 2.209973379969597

Epoch: 5| Step: 6
Training loss: 2.1295552253723145
Validation loss: 2.2269014418125153

Epoch: 5| Step: 7
Training loss: 2.1620233058929443
Validation loss: 2.2769931753476462

Epoch: 5| Step: 8
Training loss: 1.7613708972930908
Validation loss: 2.284941628575325

Epoch: 5| Step: 9
Training loss: 1.8902097940444946
Validation loss: 2.2649187246958413

Epoch: 5| Step: 10
Training loss: 2.0687716007232666
Validation loss: 2.283697798848152

Epoch: 5| Step: 11
Training loss: 1.9684085845947266
Validation loss: 2.302703559398651

Epoch: 279| Step: 0
Training loss: 1.6330658197402954
Validation loss: 2.276287337144216

Epoch: 5| Step: 1
Training loss: 1.5805193185806274
Validation loss: 2.264151374499003

Epoch: 5| Step: 2
Training loss: 1.736947774887085
Validation loss: 2.237546056509018

Epoch: 5| Step: 3
Training loss: 1.7494385242462158
Validation loss: 2.1915874083836875

Epoch: 5| Step: 4
Training loss: 1.3962041139602661
Validation loss: 2.2055952896674476

Epoch: 5| Step: 5
Training loss: 2.042273998260498
Validation loss: 2.1926657309134803

Epoch: 5| Step: 6
Training loss: 2.310039758682251
Validation loss: 2.1866646061340966

Epoch: 5| Step: 7
Training loss: 1.8171873092651367
Validation loss: 2.1659546295801797

Epoch: 5| Step: 8
Training loss: 1.7374366521835327
Validation loss: 2.1570755193630853

Epoch: 5| Step: 9
Training loss: 2.642104387283325
Validation loss: 2.160597359140714

Epoch: 5| Step: 10
Training loss: 1.640784502029419
Validation loss: 2.1772775451342263

Epoch: 5| Step: 11
Training loss: 1.514519453048706
Validation loss: 2.2063571761051812

Epoch: 280| Step: 0
Training loss: 1.8050111532211304
Validation loss: 2.205664947628975

Epoch: 5| Step: 1
Training loss: 1.8802430629730225
Validation loss: 2.2252989610036216

Epoch: 5| Step: 2
Training loss: 1.7671403884887695
Validation loss: 2.219090128938357

Epoch: 5| Step: 3
Training loss: 2.09428071975708
Validation loss: 2.220781226952871

Epoch: 5| Step: 4
Training loss: 1.6019079685211182
Validation loss: 2.28401517868042

Epoch: 5| Step: 5
Training loss: 1.9540863037109375
Validation loss: 2.256655295689901

Epoch: 5| Step: 6
Training loss: 2.240572452545166
Validation loss: 2.2494739840428033

Epoch: 5| Step: 7
Training loss: 1.8842980861663818
Validation loss: 2.2632684409618378

Epoch: 5| Step: 8
Training loss: 1.658776044845581
Validation loss: 2.2386448979377747

Epoch: 5| Step: 9
Training loss: 1.8471311330795288
Validation loss: 2.2249092062314353

Epoch: 5| Step: 10
Training loss: 1.787410020828247
Validation loss: 2.2082183013359704

Epoch: 5| Step: 11
Training loss: 1.7986027002334595
Validation loss: 2.1989512344201407

Epoch: 281| Step: 0
Training loss: 1.7597382068634033
Validation loss: 2.1993375718593597

Epoch: 5| Step: 1
Training loss: 1.9089457988739014
Validation loss: 2.1816704471906028

Epoch: 5| Step: 2
Training loss: 1.628330945968628
Validation loss: 2.177941709756851

Epoch: 5| Step: 3
Training loss: 2.331359386444092
Validation loss: 2.1745493710041046

Epoch: 5| Step: 4
Training loss: 1.3887447118759155
Validation loss: 2.179911434650421

Epoch: 5| Step: 5
Training loss: 1.7951768636703491
Validation loss: 2.1961488177378974

Epoch: 5| Step: 6
Training loss: 1.819763422012329
Validation loss: 2.1898793230454126

Epoch: 5| Step: 7
Training loss: 1.8608086109161377
Validation loss: 2.212398593624433

Epoch: 5| Step: 8
Training loss: 2.2923526763916016
Validation loss: 2.213510582844416

Epoch: 5| Step: 9
Training loss: 1.9462053775787354
Validation loss: 2.2367679675420127

Epoch: 5| Step: 10
Training loss: 2.166451930999756
Validation loss: 2.2183136443297067

Epoch: 5| Step: 11
Training loss: 1.7863534688949585
Validation loss: 2.210756907860438

Epoch: 282| Step: 0
Training loss: 2.1870880126953125
Validation loss: 2.2184958855311074

Epoch: 5| Step: 1
Training loss: 1.6030199527740479
Validation loss: 2.2266849478085837

Epoch: 5| Step: 2
Training loss: 2.0041728019714355
Validation loss: 2.217560907204946

Epoch: 5| Step: 3
Training loss: 1.6416774988174438
Validation loss: 2.2315995196501413

Epoch: 5| Step: 4
Training loss: 2.0789754390716553
Validation loss: 2.2108362913131714

Epoch: 5| Step: 5
Training loss: 1.5558961629867554
Validation loss: 2.2164119432369866

Epoch: 5| Step: 6
Training loss: 1.6746593713760376
Validation loss: 2.2188150684038797

Epoch: 5| Step: 7
Training loss: 2.007776975631714
Validation loss: 2.205011119445165

Epoch: 5| Step: 8
Training loss: 1.8092176914215088
Validation loss: 2.2195074359575906

Epoch: 5| Step: 9
Training loss: 1.3744293451309204
Validation loss: 2.2280350724856057

Epoch: 5| Step: 10
Training loss: 1.7793956995010376
Validation loss: 2.2143970976273217

Epoch: 5| Step: 11
Training loss: 1.2741639614105225
Validation loss: 2.1947716971238456

Epoch: 283| Step: 0
Training loss: 2.1775107383728027
Validation loss: 2.209239130218824

Epoch: 5| Step: 1
Training loss: 1.8503282070159912
Validation loss: 2.1968133747577667

Epoch: 5| Step: 2
Training loss: 1.1907492876052856
Validation loss: 2.2073167065779367

Epoch: 5| Step: 3
Training loss: 2.060896635055542
Validation loss: 2.1967430313428244

Epoch: 5| Step: 4
Training loss: 2.138566017150879
Validation loss: 2.1991638938585916

Epoch: 5| Step: 5
Training loss: 1.2514234781265259
Validation loss: 2.190786212682724

Epoch: 5| Step: 6
Training loss: 1.448359489440918
Validation loss: 2.208416481812795

Epoch: 5| Step: 7
Training loss: 1.758556604385376
Validation loss: 2.2234623432159424

Epoch: 5| Step: 8
Training loss: 1.6085481643676758
Validation loss: 2.2279248336950936

Epoch: 5| Step: 9
Training loss: 1.4961178302764893
Validation loss: 2.220071569085121

Epoch: 5| Step: 10
Training loss: 1.9630718231201172
Validation loss: 2.2257161984841027

Epoch: 5| Step: 11
Training loss: 3.4062981605529785
Validation loss: 2.20851660768191

Epoch: 284| Step: 0
Training loss: 1.4785603284835815
Validation loss: 2.2278401454289756

Epoch: 5| Step: 1
Training loss: 1.8936712741851807
Validation loss: 2.2437357107798257

Epoch: 5| Step: 2
Training loss: 1.986510992050171
Validation loss: 2.240411549806595

Epoch: 5| Step: 3
Training loss: 1.5590211153030396
Validation loss: 2.2268455028533936

Epoch: 5| Step: 4
Training loss: 1.6926113367080688
Validation loss: 2.233966956535975

Epoch: 5| Step: 5
Training loss: 1.8643165826797485
Validation loss: 2.221003532409668

Epoch: 5| Step: 6
Training loss: 2.066110610961914
Validation loss: 2.218379939595858

Epoch: 5| Step: 7
Training loss: 1.7617652416229248
Validation loss: 2.227101316054662

Epoch: 5| Step: 8
Training loss: 1.474151849746704
Validation loss: 2.2451020181179047

Epoch: 5| Step: 9
Training loss: 1.6152719259262085
Validation loss: 2.2314847856760025

Epoch: 5| Step: 10
Training loss: 1.8033698797225952
Validation loss: 2.2495135267575583

Epoch: 5| Step: 11
Training loss: 1.04160737991333
Validation loss: 2.2140415708223977

Epoch: 285| Step: 0
Training loss: 1.304720163345337
Validation loss: 2.2134848088026047

Epoch: 5| Step: 1
Training loss: 1.8510843515396118
Validation loss: 2.2250313411156335

Epoch: 5| Step: 2
Training loss: 1.3637834787368774
Validation loss: 2.226426104704539

Epoch: 5| Step: 3
Training loss: 1.9719902276992798
Validation loss: 2.2295221388339996

Epoch: 5| Step: 4
Training loss: 1.4281713962554932
Validation loss: 2.23506228129069

Epoch: 5| Step: 5
Training loss: 1.546194076538086
Validation loss: 2.215600778659185

Epoch: 5| Step: 6
Training loss: 1.7231626510620117
Validation loss: 2.2218996981779733

Epoch: 5| Step: 7
Training loss: 1.8016926050186157
Validation loss: 2.2169454296429953

Epoch: 5| Step: 8
Training loss: 2.499830722808838
Validation loss: 2.2177197436491647

Epoch: 5| Step: 9
Training loss: 2.1227524280548096
Validation loss: 2.2024671534697213

Epoch: 5| Step: 10
Training loss: 1.9365583658218384
Validation loss: 2.216914087533951

Epoch: 5| Step: 11
Training loss: 2.1203718185424805
Validation loss: 2.207612762848536

Epoch: 286| Step: 0
Training loss: 1.5579181909561157
Validation loss: 2.1782250503698983

Epoch: 5| Step: 1
Training loss: 1.2631795406341553
Validation loss: 2.1923361967007318

Epoch: 5| Step: 2
Training loss: 2.2726340293884277
Validation loss: 2.1836588382720947

Epoch: 5| Step: 3
Training loss: 1.5612831115722656
Validation loss: 2.186556875705719

Epoch: 5| Step: 4
Training loss: 1.7243435382843018
Validation loss: 2.187526434659958

Epoch: 5| Step: 5
Training loss: 2.125654697418213
Validation loss: 2.196368137995402

Epoch: 5| Step: 6
Training loss: 1.896874189376831
Validation loss: 2.2113080819447837

Epoch: 5| Step: 7
Training loss: 2.1630094051361084
Validation loss: 2.245404760042826

Epoch: 5| Step: 8
Training loss: 1.8887805938720703
Validation loss: 2.264573166767756

Epoch: 5| Step: 9
Training loss: 1.5588953495025635
Validation loss: 2.2991328040758767

Epoch: 5| Step: 10
Training loss: 2.1382644176483154
Validation loss: 2.2850655863682428

Epoch: 5| Step: 11
Training loss: 1.5890734195709229
Validation loss: 2.308340400457382

Epoch: 287| Step: 0
Training loss: 1.634412407875061
Validation loss: 2.2987938026587167

Epoch: 5| Step: 1
Training loss: 1.7603371143341064
Validation loss: 2.2980184853076935

Epoch: 5| Step: 2
Training loss: 1.4730079174041748
Validation loss: 2.283863072594007

Epoch: 5| Step: 3
Training loss: 1.9738714694976807
Validation loss: 2.2475629349549613

Epoch: 5| Step: 4
Training loss: 2.006040573120117
Validation loss: 2.2563456843296685

Epoch: 5| Step: 5
Training loss: 2.0283796787261963
Validation loss: 2.2393648823102317

Epoch: 5| Step: 6
Training loss: 1.9686806201934814
Validation loss: 2.216012870272001

Epoch: 5| Step: 7
Training loss: 1.6848589181900024
Validation loss: 2.20904973646005

Epoch: 5| Step: 8
Training loss: 2.4558498859405518
Validation loss: 2.196388895312945

Epoch: 5| Step: 9
Training loss: 1.513841986656189
Validation loss: 2.209996595978737

Epoch: 5| Step: 10
Training loss: 1.1589710712432861
Validation loss: 2.1937794983386993

Epoch: 5| Step: 11
Training loss: 1.0492651462554932
Validation loss: 2.166877736647924

Epoch: 288| Step: 0
Training loss: 1.6795246601104736
Validation loss: 2.1913534750541053

Epoch: 5| Step: 1
Training loss: 1.6118930578231812
Validation loss: 2.213311721881231

Epoch: 5| Step: 2
Training loss: 1.6307847499847412
Validation loss: 2.2081834971904755

Epoch: 5| Step: 3
Training loss: 1.9440504312515259
Validation loss: 2.197608172893524

Epoch: 5| Step: 4
Training loss: 1.6348727941513062
Validation loss: 2.232870558897654

Epoch: 5| Step: 5
Training loss: 1.931236982345581
Validation loss: 2.2427395284175873

Epoch: 5| Step: 6
Training loss: 1.681727647781372
Validation loss: 2.2410155137379966

Epoch: 5| Step: 7
Training loss: 2.644052267074585
Validation loss: 2.250259757041931

Epoch: 5| Step: 8
Training loss: 1.4177764654159546
Validation loss: 2.2124240696430206

Epoch: 5| Step: 9
Training loss: 1.6768054962158203
Validation loss: 2.214580883582433

Epoch: 5| Step: 10
Training loss: 1.6776081323623657
Validation loss: 2.225130185484886

Epoch: 5| Step: 11
Training loss: 2.0352418422698975
Validation loss: 2.219168022274971

Epoch: 289| Step: 0
Training loss: 1.47760009765625
Validation loss: 2.2120510240395865

Epoch: 5| Step: 1
Training loss: 2.0938103199005127
Validation loss: 2.184081887205442

Epoch: 5| Step: 2
Training loss: 1.506024718284607
Validation loss: 2.1691483010848365

Epoch: 5| Step: 3
Training loss: 1.6409311294555664
Validation loss: 2.1614583084980645

Epoch: 5| Step: 4
Training loss: 1.7716976404190063
Validation loss: 2.153097997109095

Epoch: 5| Step: 5
Training loss: 1.7448701858520508
Validation loss: 2.1605463375647864

Epoch: 5| Step: 6
Training loss: 1.8793351650238037
Validation loss: 2.175910914937655

Epoch: 5| Step: 7
Training loss: 1.6043907403945923
Validation loss: 2.1486024061838784

Epoch: 5| Step: 8
Training loss: 2.8226747512817383
Validation loss: 2.151870126525561

Epoch: 5| Step: 9
Training loss: 2.0293285846710205
Validation loss: 2.175626809398333

Epoch: 5| Step: 10
Training loss: 1.6717555522918701
Validation loss: 2.16603946685791

Epoch: 5| Step: 11
Training loss: 0.896101176738739
Validation loss: 2.1920995116233826

Epoch: 290| Step: 0
Training loss: 1.2117302417755127
Validation loss: 2.197188620766004

Epoch: 5| Step: 1
Training loss: 1.4015976190567017
Validation loss: 2.190544754266739

Epoch: 5| Step: 2
Training loss: 1.6236493587493896
Validation loss: 2.1891053269306817

Epoch: 5| Step: 3
Training loss: 1.3861333131790161
Validation loss: 2.212127317984899

Epoch: 5| Step: 4
Training loss: 1.5565046072006226
Validation loss: 2.2134944796562195

Epoch: 5| Step: 5
Training loss: 2.461055040359497
Validation loss: 2.2022787431875863

Epoch: 5| Step: 6
Training loss: 1.5164543390274048
Validation loss: 2.21094910800457

Epoch: 5| Step: 7
Training loss: 1.9141639471054077
Validation loss: 2.2046131988366446

Epoch: 5| Step: 8
Training loss: 1.926802635192871
Validation loss: 2.2228015462557473

Epoch: 5| Step: 9
Training loss: 1.7739053964614868
Validation loss: 2.2173957427342734

Epoch: 5| Step: 10
Training loss: 2.552107095718384
Validation loss: 2.2392125527064004

Epoch: 5| Step: 11
Training loss: 1.872469425201416
Validation loss: 2.2244875927766166

Epoch: 291| Step: 0
Training loss: 1.6374810934066772
Validation loss: 2.181308383742968

Epoch: 5| Step: 1
Training loss: 1.6526235342025757
Validation loss: 2.155849347511927

Epoch: 5| Step: 2
Training loss: 1.5704681873321533
Validation loss: 2.1516009320815406

Epoch: 5| Step: 3
Training loss: 2.2539308071136475
Validation loss: 2.1439888924360275

Epoch: 5| Step: 4
Training loss: 1.6134523153305054
Validation loss: 2.1604340275128684

Epoch: 5| Step: 5
Training loss: 2.562380313873291
Validation loss: 2.182094151775042

Epoch: 5| Step: 6
Training loss: 1.720987319946289
Validation loss: 2.1611368556817374

Epoch: 5| Step: 7
Training loss: 1.8065894842147827
Validation loss: 2.1814660678307214

Epoch: 5| Step: 8
Training loss: 1.3577451705932617
Validation loss: 2.195238212744395

Epoch: 5| Step: 9
Training loss: 2.130063533782959
Validation loss: 2.216269572575887

Epoch: 5| Step: 10
Training loss: 1.8796300888061523
Validation loss: 2.271319111188253

Epoch: 5| Step: 11
Training loss: 2.043358325958252
Validation loss: 2.258957326412201

Epoch: 292| Step: 0
Training loss: 1.9490934610366821
Validation loss: 2.2729865411917367

Epoch: 5| Step: 1
Training loss: 1.8460328578948975
Validation loss: 2.252790709336599

Epoch: 5| Step: 2
Training loss: 1.5380542278289795
Validation loss: 2.2560170044501624

Epoch: 5| Step: 3
Training loss: 2.082183361053467
Validation loss: 2.251040150721868

Epoch: 5| Step: 4
Training loss: 1.8748127222061157
Validation loss: 2.2226487894852958

Epoch: 5| Step: 5
Training loss: 2.6731314659118652
Validation loss: 2.197106202443441

Epoch: 5| Step: 6
Training loss: 1.3890883922576904
Validation loss: 2.2098539024591446

Epoch: 5| Step: 7
Training loss: 1.3613630533218384
Validation loss: 2.184265340367953

Epoch: 5| Step: 8
Training loss: 1.5569894313812256
Validation loss: 2.179564038912455

Epoch: 5| Step: 9
Training loss: 1.4248058795928955
Validation loss: 2.167038877805074

Epoch: 5| Step: 10
Training loss: 1.9222183227539062
Validation loss: 2.1671963781118393

Epoch: 5| Step: 11
Training loss: 2.2924985885620117
Validation loss: 2.194665173689524

Epoch: 293| Step: 0
Training loss: 1.5854504108428955
Validation loss: 2.2036702732245126

Epoch: 5| Step: 1
Training loss: 1.8480068445205688
Validation loss: 2.196830838918686

Epoch: 5| Step: 2
Training loss: 1.3357480764389038
Validation loss: 2.2033605575561523

Epoch: 5| Step: 3
Training loss: 1.6173263788223267
Validation loss: 2.2185553908348083

Epoch: 5| Step: 4
Training loss: 2.181455135345459
Validation loss: 2.243738462527593

Epoch: 5| Step: 5
Training loss: 1.6873458623886108
Validation loss: 2.2418689032395682

Epoch: 5| Step: 6
Training loss: 2.031172752380371
Validation loss: 2.2618153244256973

Epoch: 5| Step: 7
Training loss: 1.6640522480010986
Validation loss: 2.2629000494877496

Epoch: 5| Step: 8
Training loss: 1.6332576274871826
Validation loss: 2.2966823081175485

Epoch: 5| Step: 9
Training loss: 1.7280244827270508
Validation loss: 2.2675350308418274

Epoch: 5| Step: 10
Training loss: 1.9853988885879517
Validation loss: 2.2663284838199615

Epoch: 5| Step: 11
Training loss: 1.982199788093567
Validation loss: 2.225726013382276

Epoch: 294| Step: 0
Training loss: 1.8516006469726562
Validation loss: 2.2129058241844177

Epoch: 5| Step: 1
Training loss: 1.5885660648345947
Validation loss: 2.1929774383703866

Epoch: 5| Step: 2
Training loss: 2.011267900466919
Validation loss: 2.145531823237737

Epoch: 5| Step: 3
Training loss: 1.326111078262329
Validation loss: 2.161743640899658

Epoch: 5| Step: 4
Training loss: 2.6160106658935547
Validation loss: 2.145969808101654

Epoch: 5| Step: 5
Training loss: 1.846592903137207
Validation loss: 2.150347034136454

Epoch: 5| Step: 6
Training loss: 1.8207498788833618
Validation loss: 2.1715989957253137

Epoch: 5| Step: 7
Training loss: 1.6284993886947632
Validation loss: 2.1969416638215384

Epoch: 5| Step: 8
Training loss: 1.6850216388702393
Validation loss: 2.2238509158293405

Epoch: 5| Step: 9
Training loss: 1.9995006322860718
Validation loss: 2.1905342737833657

Epoch: 5| Step: 10
Training loss: 1.4531269073486328
Validation loss: 2.2158252795537314

Epoch: 5| Step: 11
Training loss: 1.2544634342193604
Validation loss: 2.2136679887771606

Epoch: 295| Step: 0
Training loss: 1.5155532360076904
Validation loss: 2.235355203350385

Epoch: 5| Step: 1
Training loss: 1.441850185394287
Validation loss: 2.209161266684532

Epoch: 5| Step: 2
Training loss: 1.7488048076629639
Validation loss: 2.250748172402382

Epoch: 5| Step: 3
Training loss: 1.3826631307601929
Validation loss: 2.2317189623912177

Epoch: 5| Step: 4
Training loss: 1.6997859477996826
Validation loss: 2.253310869137446

Epoch: 5| Step: 5
Training loss: 1.7547037601470947
Validation loss: 2.2300829887390137

Epoch: 5| Step: 6
Training loss: 1.863816261291504
Validation loss: 2.208024183909098

Epoch: 5| Step: 7
Training loss: 1.8143056631088257
Validation loss: 2.206838528315226

Epoch: 5| Step: 8
Training loss: 1.736020803451538
Validation loss: 2.1960797806580863

Epoch: 5| Step: 9
Training loss: 1.9793760776519775
Validation loss: 2.179052919149399

Epoch: 5| Step: 10
Training loss: 2.566121816635132
Validation loss: 2.171699891487757

Epoch: 5| Step: 11
Training loss: 0.7762289047241211
Validation loss: 2.160805573066076

Epoch: 296| Step: 0
Training loss: 1.509844422340393
Validation loss: 2.1654773553212485

Epoch: 5| Step: 1
Training loss: 1.8455522060394287
Validation loss: 2.1483182658751807

Epoch: 5| Step: 2
Training loss: 1.7061628103256226
Validation loss: 2.167945454518

Epoch: 5| Step: 3
Training loss: 1.756377935409546
Validation loss: 2.1751197973887124

Epoch: 5| Step: 4
Training loss: 1.6678941249847412
Validation loss: 2.2069059113661447

Epoch: 5| Step: 5
Training loss: 1.878737211227417
Validation loss: 2.208405996362368

Epoch: 5| Step: 6
Training loss: 2.0468385219573975
Validation loss: 2.2252707878748574

Epoch: 5| Step: 7
Training loss: 2.0972254276275635
Validation loss: 2.218165914217631

Epoch: 5| Step: 8
Training loss: 1.9728702306747437
Validation loss: 2.252767413854599

Epoch: 5| Step: 9
Training loss: 1.9557663202285767
Validation loss: 2.2701242566108704

Epoch: 5| Step: 10
Training loss: 1.4804353713989258
Validation loss: 2.242100785175959

Epoch: 5| Step: 11
Training loss: 1.468611478805542
Validation loss: 2.260774622360865

Epoch: 297| Step: 0
Training loss: 1.6421951055526733
Validation loss: 2.2817256351312003

Epoch: 5| Step: 1
Training loss: 2.02653169631958
Validation loss: 2.2258527080217996

Epoch: 5| Step: 2
Training loss: 1.8942114114761353
Validation loss: 2.2480669071276984

Epoch: 5| Step: 3
Training loss: 1.6588855981826782
Validation loss: 2.2481837769349418

Epoch: 5| Step: 4
Training loss: 1.9848287105560303
Validation loss: 2.256513088941574

Epoch: 5| Step: 5
Training loss: 1.9620529413223267
Validation loss: 2.258797084291776

Epoch: 5| Step: 6
Training loss: 0.9916065335273743
Validation loss: 2.2540103644132614

Epoch: 5| Step: 7
Training loss: 1.421246886253357
Validation loss: 2.2381939391295114

Epoch: 5| Step: 8
Training loss: 2.4216036796569824
Validation loss: 2.2035511334737143

Epoch: 5| Step: 9
Training loss: 1.783644676208496
Validation loss: 2.19559479256471

Epoch: 5| Step: 10
Training loss: 1.8457510471343994
Validation loss: 2.189820056160291

Epoch: 5| Step: 11
Training loss: 2.106895923614502
Validation loss: 2.198766643802325

Epoch: 298| Step: 0
Training loss: 1.9182865619659424
Validation loss: 2.2319355656703315

Epoch: 5| Step: 1
Training loss: 1.49648118019104
Validation loss: 2.271209786335627

Epoch: 5| Step: 2
Training loss: 1.968589425086975
Validation loss: 2.275058622161547

Epoch: 5| Step: 3
Training loss: 2.3091988563537598
Validation loss: 2.2690782050291696

Epoch: 5| Step: 4
Training loss: 1.9083316326141357
Validation loss: 2.306482950846354

Epoch: 5| Step: 5
Training loss: 1.7845971584320068
Validation loss: 2.291788856188456

Epoch: 5| Step: 6
Training loss: 1.943398118019104
Validation loss: 2.262068510055542

Epoch: 5| Step: 7
Training loss: 1.7149884700775146
Validation loss: 2.258450632294019

Epoch: 5| Step: 8
Training loss: 1.2164485454559326
Validation loss: 2.2482443700234094

Epoch: 5| Step: 9
Training loss: 2.0280115604400635
Validation loss: 2.2257480174303055

Epoch: 5| Step: 10
Training loss: 1.838249921798706
Validation loss: 2.2079513669013977

Epoch: 5| Step: 11
Training loss: 1.5974873304367065
Validation loss: 2.190617819627126

Epoch: 299| Step: 0
Training loss: 1.6670364141464233
Validation loss: 2.178767204284668

Epoch: 5| Step: 1
Training loss: 2.2234129905700684
Validation loss: 2.1728609104951224

Epoch: 5| Step: 2
Training loss: 2.135146379470825
Validation loss: 2.160076310237249

Epoch: 5| Step: 3
Training loss: 2.0058608055114746
Validation loss: 2.14896352092425

Epoch: 5| Step: 4
Training loss: 2.4299752712249756
Validation loss: 2.15260740617911

Epoch: 5| Step: 5
Training loss: 1.5922706127166748
Validation loss: 2.162063886721929

Epoch: 5| Step: 6
Training loss: 1.7945213317871094
Validation loss: 2.1616810808579126

Epoch: 5| Step: 7
Training loss: 1.3785133361816406
Validation loss: 2.175381044546763

Epoch: 5| Step: 8
Training loss: 1.0558745861053467
Validation loss: 2.1915283550818763

Epoch: 5| Step: 9
Training loss: 1.2937839031219482
Validation loss: 2.1800053467353186

Epoch: 5| Step: 10
Training loss: 1.9890848398208618
Validation loss: 2.2065039724111557

Epoch: 5| Step: 11
Training loss: 2.5597763061523438
Validation loss: 2.196935305992762

Epoch: 300| Step: 0
Training loss: 1.6584389209747314
Validation loss: 2.2168297171592712

Epoch: 5| Step: 1
Training loss: 1.8169772624969482
Validation loss: 2.198759247859319

Epoch: 5| Step: 2
Training loss: 1.2601747512817383
Validation loss: 2.1988539745410285

Epoch: 5| Step: 3
Training loss: 1.7439531087875366
Validation loss: 2.17481259504954

Epoch: 5| Step: 4
Training loss: 1.6369212865829468
Validation loss: 2.1783620615800223

Epoch: 5| Step: 5
Training loss: 1.990861177444458
Validation loss: 2.183276151617368

Epoch: 5| Step: 6
Training loss: 1.8062604665756226
Validation loss: 2.186511362592379

Epoch: 5| Step: 7
Training loss: 1.884696364402771
Validation loss: 2.1980043152968087

Epoch: 5| Step: 8
Training loss: 1.8748328685760498
Validation loss: 2.2046574453512826

Epoch: 5| Step: 9
Training loss: 1.5094759464263916
Validation loss: 2.201436847448349

Epoch: 5| Step: 10
Training loss: 1.8611738681793213
Validation loss: 2.2270423571268716

Epoch: 5| Step: 11
Training loss: 1.9083607196807861
Validation loss: 2.230572745203972

Epoch: 301| Step: 0
Training loss: 1.52962327003479
Validation loss: 2.2369915743668876

Epoch: 5| Step: 1
Training loss: 2.239471912384033
Validation loss: 2.231349607308706

Epoch: 5| Step: 2
Training loss: 1.3982471227645874
Validation loss: 2.2713713397582374

Epoch: 5| Step: 3
Training loss: 1.1564249992370605
Validation loss: 2.2705090989669166

Epoch: 5| Step: 4
Training loss: 1.3101915121078491
Validation loss: 2.2816367546717324

Epoch: 5| Step: 5
Training loss: 2.128673553466797
Validation loss: 2.254804184039434

Epoch: 5| Step: 6
Training loss: 1.8008174896240234
Validation loss: 2.281817634900411

Epoch: 5| Step: 7
Training loss: 1.636096715927124
Validation loss: 2.2843310087919235

Epoch: 5| Step: 8
Training loss: 1.8134005069732666
Validation loss: 2.25297345717748

Epoch: 5| Step: 9
Training loss: 1.9075801372528076
Validation loss: 2.248495042324066

Epoch: 5| Step: 10
Training loss: 2.1668272018432617
Validation loss: 2.2382765412330627

Epoch: 5| Step: 11
Training loss: 1.699038028717041
Validation loss: 2.2318907976150513

Epoch: 302| Step: 0
Training loss: 2.1342716217041016
Validation loss: 2.2072374671697617

Epoch: 5| Step: 1
Training loss: 1.5830663442611694
Validation loss: 2.222720131278038

Epoch: 5| Step: 2
Training loss: 1.5828664302825928
Validation loss: 2.2016588151454926

Epoch: 5| Step: 3
Training loss: 1.661842942237854
Validation loss: 2.2111249615748725

Epoch: 5| Step: 4
Training loss: 1.1840572357177734
Validation loss: 2.2197772761185965

Epoch: 5| Step: 5
Training loss: 2.1374988555908203
Validation loss: 2.222290575504303

Epoch: 5| Step: 6
Training loss: 1.639868974685669
Validation loss: 2.219997455676397

Epoch: 5| Step: 7
Training loss: 1.7410036325454712
Validation loss: 2.23011947174867

Epoch: 5| Step: 8
Training loss: 1.7017574310302734
Validation loss: 2.2356923818588257

Epoch: 5| Step: 9
Training loss: 2.045664072036743
Validation loss: 2.2259827752908072

Epoch: 5| Step: 10
Training loss: 1.5472246408462524
Validation loss: 2.2243623584508896

Epoch: 5| Step: 11
Training loss: 1.1208487749099731
Validation loss: 2.238250916202863

Epoch: 303| Step: 0
Training loss: 1.2218787670135498
Validation loss: 2.2238280375798545

Epoch: 5| Step: 1
Training loss: 1.842206597328186
Validation loss: 2.2289832681417465

Epoch: 5| Step: 2
Training loss: 1.233629822731018
Validation loss: 2.255771135290464

Epoch: 5| Step: 3
Training loss: 2.136157512664795
Validation loss: 2.239943395058314

Epoch: 5| Step: 4
Training loss: 2.474592447280884
Validation loss: 2.265101586778959

Epoch: 5| Step: 5
Training loss: 1.5924880504608154
Validation loss: 2.2822434107462564

Epoch: 5| Step: 6
Training loss: 1.8571481704711914
Validation loss: 2.2625215152899423

Epoch: 5| Step: 7
Training loss: 1.5241353511810303
Validation loss: 2.2816898226737976

Epoch: 5| Step: 8
Training loss: 1.531462550163269
Validation loss: 2.2383874555428824

Epoch: 5| Step: 9
Training loss: 1.815818190574646
Validation loss: 2.2750986566146216

Epoch: 5| Step: 10
Training loss: 1.9721781015396118
Validation loss: 2.269183710217476

Epoch: 5| Step: 11
Training loss: 0.5056977272033691
Validation loss: 2.2686634759108224

Epoch: 304| Step: 0
Training loss: 1.839794397354126
Validation loss: 2.2387768626213074

Epoch: 5| Step: 1
Training loss: 1.4602134227752686
Validation loss: 2.220168044169744

Epoch: 5| Step: 2
Training loss: 1.2631276845932007
Validation loss: 2.2270614306131997

Epoch: 5| Step: 3
Training loss: 1.8248428106307983
Validation loss: 2.2426048517227173

Epoch: 5| Step: 4
Training loss: 1.5042846202850342
Validation loss: 2.220910350481669

Epoch: 5| Step: 5
Training loss: 1.9934751987457275
Validation loss: 2.2268435657024384

Epoch: 5| Step: 6
Training loss: 1.2867143154144287
Validation loss: 2.2211419542630515

Epoch: 5| Step: 7
Training loss: 2.0817465782165527
Validation loss: 2.2445767174164453

Epoch: 5| Step: 8
Training loss: 2.0730371475219727
Validation loss: 2.242405186096827

Epoch: 5| Step: 9
Training loss: 1.5023345947265625
Validation loss: 2.2585968176523843

Epoch: 5| Step: 10
Training loss: 1.9145675897598267
Validation loss: 2.2750877290964127

Epoch: 5| Step: 11
Training loss: 1.4458069801330566
Validation loss: 2.241273194551468

Epoch: 305| Step: 0
Training loss: 1.7921085357666016
Validation loss: 2.235090618332227

Epoch: 5| Step: 1
Training loss: 1.3596073389053345
Validation loss: 2.2373283356428146

Epoch: 5| Step: 2
Training loss: 1.915604591369629
Validation loss: 2.237679491440455

Epoch: 5| Step: 3
Training loss: 1.6657378673553467
Validation loss: 2.219218204418818

Epoch: 5| Step: 4
Training loss: 1.2122849225997925
Validation loss: 2.2163559645414352

Epoch: 5| Step: 5
Training loss: 2.1394824981689453
Validation loss: 2.2364782989025116

Epoch: 5| Step: 6
Training loss: 2.2325406074523926
Validation loss: 2.2163270314534507

Epoch: 5| Step: 7
Training loss: 1.6184616088867188
Validation loss: 2.2161351641019187

Epoch: 5| Step: 8
Training loss: 1.5643869638442993
Validation loss: 2.2044334560632706

Epoch: 5| Step: 9
Training loss: 1.7479610443115234
Validation loss: 2.2050430128971734

Epoch: 5| Step: 10
Training loss: 1.5799829959869385
Validation loss: 2.1894872983296714

Epoch: 5| Step: 11
Training loss: 1.2192553281784058
Validation loss: 2.2077769140402475

Epoch: 306| Step: 0
Training loss: 1.9440782070159912
Validation loss: 2.2170995076497397

Epoch: 5| Step: 1
Training loss: 2.346977949142456
Validation loss: 2.2283771336078644

Epoch: 5| Step: 2
Training loss: 0.9857972860336304
Validation loss: 2.2379188537597656

Epoch: 5| Step: 3
Training loss: 1.4203087091445923
Validation loss: 2.234713524580002

Epoch: 5| Step: 4
Training loss: 1.762322187423706
Validation loss: 2.255751142899195

Epoch: 5| Step: 5
Training loss: 1.980942964553833
Validation loss: 2.270534172654152

Epoch: 5| Step: 6
Training loss: 1.9670778512954712
Validation loss: 2.225121637185415

Epoch: 5| Step: 7
Training loss: 1.3198738098144531
Validation loss: 2.2203867783149085

Epoch: 5| Step: 8
Training loss: 1.5636491775512695
Validation loss: 2.2228677173455558

Epoch: 5| Step: 9
Training loss: 2.107800006866455
Validation loss: 2.2122413565715155

Epoch: 5| Step: 10
Training loss: 1.505821704864502
Validation loss: 2.2152045915524163

Epoch: 5| Step: 11
Training loss: 1.245573878288269
Validation loss: 2.201485445102056

Epoch: 307| Step: 0
Training loss: 1.3646886348724365
Validation loss: 2.209717775384585

Epoch: 5| Step: 1
Training loss: 1.5808870792388916
Validation loss: 2.20604877670606

Epoch: 5| Step: 2
Training loss: 1.3899515867233276
Validation loss: 2.213592439889908

Epoch: 5| Step: 3
Training loss: 1.6498275995254517
Validation loss: 2.2265538374582925

Epoch: 5| Step: 4
Training loss: 1.1846435070037842
Validation loss: 2.231069892644882

Epoch: 5| Step: 5
Training loss: 1.5313446521759033
Validation loss: 2.206602911154429

Epoch: 5| Step: 6
Training loss: 2.6177010536193848
Validation loss: 2.2200895647207894

Epoch: 5| Step: 7
Training loss: 1.6676057577133179
Validation loss: 2.2228903621435165

Epoch: 5| Step: 8
Training loss: 1.7581665515899658
Validation loss: 2.2455369333426156

Epoch: 5| Step: 9
Training loss: 1.969308853149414
Validation loss: 2.252007707953453

Epoch: 5| Step: 10
Training loss: 1.6339900493621826
Validation loss: 2.2782750725746155

Epoch: 5| Step: 11
Training loss: 2.6284985542297363
Validation loss: 2.2782894670963287

Epoch: 308| Step: 0
Training loss: 1.537785530090332
Validation loss: 2.2720556457837424

Epoch: 5| Step: 1
Training loss: 1.8623456954956055
Validation loss: 2.278149033586184

Epoch: 5| Step: 2
Training loss: 1.275937557220459
Validation loss: 2.2662522296110788

Epoch: 5| Step: 3
Training loss: 1.2148630619049072
Validation loss: 2.2790101021528244

Epoch: 5| Step: 4
Training loss: 1.2986068725585938
Validation loss: 2.253659278154373

Epoch: 5| Step: 5
Training loss: 1.8079373836517334
Validation loss: 2.2376561214526496

Epoch: 5| Step: 6
Training loss: 1.5575058460235596
Validation loss: 2.2309340288241706

Epoch: 5| Step: 7
Training loss: 2.029130697250366
Validation loss: 2.1868550976117453

Epoch: 5| Step: 8
Training loss: 1.7509256601333618
Validation loss: 2.1678140461444855

Epoch: 5| Step: 9
Training loss: 1.8730170726776123
Validation loss: 2.194788450996081

Epoch: 5| Step: 10
Training loss: 2.7450523376464844
Validation loss: 2.213823363184929

Epoch: 5| Step: 11
Training loss: 2.226182699203491
Validation loss: 2.217448035875956

Epoch: 309| Step: 0
Training loss: 1.2365500926971436
Validation loss: 2.237453227241834

Epoch: 5| Step: 1
Training loss: 1.7958139181137085
Validation loss: 2.2800386399030685

Epoch: 5| Step: 2
Training loss: 2.081120252609253
Validation loss: 2.3214485396941504

Epoch: 5| Step: 3
Training loss: 2.1918294429779053
Validation loss: 2.300355742375056

Epoch: 5| Step: 4
Training loss: 1.6722431182861328
Validation loss: 2.33204980691274

Epoch: 5| Step: 5
Training loss: 2.1015758514404297
Validation loss: 2.2829899390538535

Epoch: 5| Step: 6
Training loss: 1.4877147674560547
Validation loss: 2.2911525766054788

Epoch: 5| Step: 7
Training loss: 1.6563959121704102
Validation loss: 2.2989282508691153

Epoch: 5| Step: 8
Training loss: 1.4085915088653564
Validation loss: 2.273690183957418

Epoch: 5| Step: 9
Training loss: 1.2113902568817139
Validation loss: 2.2297227581342063

Epoch: 5| Step: 10
Training loss: 1.6422210931777954
Validation loss: 2.198516974846522

Epoch: 5| Step: 11
Training loss: 2.8210763931274414
Validation loss: 2.1708009441693625

Epoch: 310| Step: 0
Training loss: 1.566936731338501
Validation loss: 2.1694559504588447

Epoch: 5| Step: 1
Training loss: 3.058845281600952
Validation loss: 2.1689498076836267

Epoch: 5| Step: 2
Training loss: 1.808053731918335
Validation loss: 2.1581425070762634

Epoch: 5| Step: 3
Training loss: 1.015183448791504
Validation loss: 2.162829448779424

Epoch: 5| Step: 4
Training loss: 1.4539873600006104
Validation loss: 2.1826888223489127

Epoch: 5| Step: 5
Training loss: 1.8562452793121338
Validation loss: 2.192650074760119

Epoch: 5| Step: 6
Training loss: 1.4869452714920044
Validation loss: 2.217667172352473

Epoch: 5| Step: 7
Training loss: 1.5299475193023682
Validation loss: 2.2142319132884345

Epoch: 5| Step: 8
Training loss: 1.880480170249939
Validation loss: 2.2305909941593804

Epoch: 5| Step: 9
Training loss: 2.098860025405884
Validation loss: 2.241965721050898

Epoch: 5| Step: 10
Training loss: 1.6139163970947266
Validation loss: 2.252891500790914

Epoch: 5| Step: 11
Training loss: 1.6553930044174194
Validation loss: 2.2908972154061

Epoch: 311| Step: 0
Training loss: 1.8532047271728516
Validation loss: 2.270754059155782

Epoch: 5| Step: 1
Training loss: 1.6344763040542603
Validation loss: 2.276974896589915

Epoch: 5| Step: 2
Training loss: 1.7584224939346313
Validation loss: 2.2875408828258514

Epoch: 5| Step: 3
Training loss: 2.1169230937957764
Validation loss: 2.248047649860382

Epoch: 5| Step: 4
Training loss: 1.2979166507720947
Validation loss: 2.2293950666983924

Epoch: 5| Step: 5
Training loss: 1.5323010683059692
Validation loss: 2.2002180914084115

Epoch: 5| Step: 6
Training loss: 2.350069046020508
Validation loss: 2.175596922636032

Epoch: 5| Step: 7
Training loss: 1.0394268035888672
Validation loss: 2.1933470020691552

Epoch: 5| Step: 8
Training loss: 1.8482325077056885
Validation loss: 2.1730903734763465

Epoch: 5| Step: 9
Training loss: 1.772395133972168
Validation loss: 2.173925146460533

Epoch: 5| Step: 10
Training loss: 1.6449031829833984
Validation loss: 2.1804806143045425

Epoch: 5| Step: 11
Training loss: 2.3115344047546387
Validation loss: 2.1779093146324158

Epoch: 312| Step: 0
Training loss: 1.8197330236434937
Validation loss: 2.201556940873464

Epoch: 5| Step: 1
Training loss: 1.54909348487854
Validation loss: 2.2237663815418878

Epoch: 5| Step: 2
Training loss: 1.3554725646972656
Validation loss: 2.2248719731966653

Epoch: 5| Step: 3
Training loss: 1.663783311843872
Validation loss: 2.236660902698835

Epoch: 5| Step: 4
Training loss: 1.7005958557128906
Validation loss: 2.2415329913298288

Epoch: 5| Step: 5
Training loss: 1.199541449546814
Validation loss: 2.260920057694117

Epoch: 5| Step: 6
Training loss: 1.0024017095565796
Validation loss: 2.242922102411588

Epoch: 5| Step: 7
Training loss: 1.5472638607025146
Validation loss: 2.2410750637451806

Epoch: 5| Step: 8
Training loss: 2.6079084873199463
Validation loss: 2.242888112862905

Epoch: 5| Step: 9
Training loss: 2.4400696754455566
Validation loss: 2.2257307320833206

Epoch: 5| Step: 10
Training loss: 2.129441261291504
Validation loss: 2.2295056084791818

Epoch: 5| Step: 11
Training loss: 1.1170594692230225
Validation loss: 2.227153331041336

Epoch: 313| Step: 0
Training loss: 1.5480631589889526
Validation loss: 2.2234485000371933

Epoch: 5| Step: 1
Training loss: 1.6523759365081787
Validation loss: 2.2104277908802032

Epoch: 5| Step: 2
Training loss: 1.6775524616241455
Validation loss: 2.218751937150955

Epoch: 5| Step: 3
Training loss: 2.0522425174713135
Validation loss: 2.1974336008230844

Epoch: 5| Step: 4
Training loss: 1.4344525337219238
Validation loss: 2.214337850610415

Epoch: 5| Step: 5
Training loss: 1.3145335912704468
Validation loss: 2.2413243452707925

Epoch: 5| Step: 6
Training loss: 1.9532461166381836
Validation loss: 2.2482693791389465

Epoch: 5| Step: 7
Training loss: 2.166426420211792
Validation loss: 2.253087878227234

Epoch: 5| Step: 8
Training loss: 1.523638129234314
Validation loss: 2.2393352588017783

Epoch: 5| Step: 9
Training loss: 1.5698683261871338
Validation loss: 2.2598292529582977

Epoch: 5| Step: 10
Training loss: 1.9479376077651978
Validation loss: 2.249905144174894

Epoch: 5| Step: 11
Training loss: 1.660264492034912
Validation loss: 2.23450859884421

Epoch: 314| Step: 0
Training loss: 1.7707531452178955
Validation loss: 2.22787573436896

Epoch: 5| Step: 1
Training loss: 1.752261757850647
Validation loss: 2.2278600285450616

Epoch: 5| Step: 2
Training loss: 1.2171094417572021
Validation loss: 2.2548195322354636

Epoch: 5| Step: 3
Training loss: 1.883646011352539
Validation loss: 2.2403568476438522

Epoch: 5| Step: 4
Training loss: 1.5223246812820435
Validation loss: 2.240716407696406

Epoch: 5| Step: 5
Training loss: 1.4899612665176392
Validation loss: 2.220027203361193

Epoch: 5| Step: 6
Training loss: 1.4632775783538818
Validation loss: 2.211696982383728

Epoch: 5| Step: 7
Training loss: 0.9817203283309937
Validation loss: 2.2098299115896225

Epoch: 5| Step: 8
Training loss: 1.9419790506362915
Validation loss: 2.200113515059153

Epoch: 5| Step: 9
Training loss: 2.5357608795166016
Validation loss: 2.1696963061889014

Epoch: 5| Step: 10
Training loss: 1.8236640691757202
Validation loss: 2.1712109247843423

Epoch: 5| Step: 11
Training loss: 1.2723829746246338
Validation loss: 2.1763564199209213

Epoch: 315| Step: 0
Training loss: 1.5534284114837646
Validation loss: 2.172975033521652

Epoch: 5| Step: 1
Training loss: 1.386461615562439
Validation loss: 2.201005667448044

Epoch: 5| Step: 2
Training loss: 1.7485790252685547
Validation loss: 2.2406565646330514

Epoch: 5| Step: 3
Training loss: 1.4262549877166748
Validation loss: 2.2268624107042947

Epoch: 5| Step: 4
Training loss: 1.3053287267684937
Validation loss: 2.2166062146425247

Epoch: 5| Step: 5
Training loss: 2.3369758129119873
Validation loss: 2.239653319120407

Epoch: 5| Step: 6
Training loss: 2.1594345569610596
Validation loss: 2.2326801121234894

Epoch: 5| Step: 7
Training loss: 1.5934832096099854
Validation loss: 2.2591263155142465

Epoch: 5| Step: 8
Training loss: 1.5794519186019897
Validation loss: 2.248792956272761

Epoch: 5| Step: 9
Training loss: 1.8172454833984375
Validation loss: 2.233927701910337

Epoch: 5| Step: 10
Training loss: 1.5940160751342773
Validation loss: 2.2461166828870773

Epoch: 5| Step: 11
Training loss: 2.2196359634399414
Validation loss: 2.242575670282046

Epoch: 316| Step: 0
Training loss: 1.417187213897705
Validation loss: 2.2439994513988495

Epoch: 5| Step: 1
Training loss: 2.040679454803467
Validation loss: 2.241728996237119

Epoch: 5| Step: 2
Training loss: 1.4409584999084473
Validation loss: 2.2132969001928964

Epoch: 5| Step: 3
Training loss: 2.1682231426239014
Validation loss: 2.244511380791664

Epoch: 5| Step: 4
Training loss: 1.9653234481811523
Validation loss: 2.2171550393104553

Epoch: 5| Step: 5
Training loss: 1.406099557876587
Validation loss: 2.1999297191699347

Epoch: 5| Step: 6
Training loss: 1.587213397026062
Validation loss: 2.2008578181266785

Epoch: 5| Step: 7
Training loss: 2.166012763977051
Validation loss: 2.2060815592606864

Epoch: 5| Step: 8
Training loss: 1.8824275732040405
Validation loss: 2.231943259636561

Epoch: 5| Step: 9
Training loss: 1.1216909885406494
Validation loss: 2.254331097006798

Epoch: 5| Step: 10
Training loss: 1.710383653640747
Validation loss: 2.252833848198255

Epoch: 5| Step: 11
Training loss: 0.5496420860290527
Validation loss: 2.2734186003605523

Epoch: 317| Step: 0
Training loss: 1.465918779373169
Validation loss: 2.2651325166225433

Epoch: 5| Step: 1
Training loss: 1.7357590198516846
Validation loss: 2.25304846962293

Epoch: 5| Step: 2
Training loss: 1.6682703495025635
Validation loss: 2.260561282436053

Epoch: 5| Step: 3
Training loss: 1.3254585266113281
Validation loss: 2.227962185939153

Epoch: 5| Step: 4
Training loss: 1.5320501327514648
Validation loss: 2.219186246395111

Epoch: 5| Step: 5
Training loss: 1.2790592908859253
Validation loss: 2.223813459277153

Epoch: 5| Step: 6
Training loss: 2.2136378288269043
Validation loss: 2.2162329057852426

Epoch: 5| Step: 7
Training loss: 2.0445923805236816
Validation loss: 2.1948927491903305

Epoch: 5| Step: 8
Training loss: 2.1469550132751465
Validation loss: 2.2040067662795386

Epoch: 5| Step: 9
Training loss: 1.414811134338379
Validation loss: 2.19528495768706

Epoch: 5| Step: 10
Training loss: 1.687530755996704
Validation loss: 2.2216586470603943

Epoch: 5| Step: 11
Training loss: 1.7383735179901123
Validation loss: 2.19508495926857

Epoch: 318| Step: 0
Training loss: 1.3602107763290405
Validation loss: 2.2041234771410623

Epoch: 5| Step: 1
Training loss: 2.337923765182495
Validation loss: 2.1974576165278754

Epoch: 5| Step: 2
Training loss: 1.7420265674591064
Validation loss: 2.198854386806488

Epoch: 5| Step: 3
Training loss: 1.5050491094589233
Validation loss: 2.182961573203405

Epoch: 5| Step: 4
Training loss: 1.6643779277801514
Validation loss: 2.1976796140273414

Epoch: 5| Step: 5
Training loss: 2.336592435836792
Validation loss: 2.2098259925842285

Epoch: 5| Step: 6
Training loss: 1.556513786315918
Validation loss: 2.205940236647924

Epoch: 5| Step: 7
Training loss: 0.9959006309509277
Validation loss: 2.2162536084651947

Epoch: 5| Step: 8
Training loss: 1.73077392578125
Validation loss: 2.2167193392912545

Epoch: 5| Step: 9
Training loss: 1.723052978515625
Validation loss: 2.237079367041588

Epoch: 5| Step: 10
Training loss: 1.3825008869171143
Validation loss: 2.2202297002077103

Epoch: 5| Step: 11
Training loss: 0.4931861162185669
Validation loss: 2.226033260424932

Epoch: 319| Step: 0
Training loss: 1.8125388622283936
Validation loss: 2.2282921075820923

Epoch: 5| Step: 1
Training loss: 1.2937525510787964
Validation loss: 2.2102848639090857

Epoch: 5| Step: 2
Training loss: 1.615788221359253
Validation loss: 2.2019407947858176

Epoch: 5| Step: 3
Training loss: 1.8645236492156982
Validation loss: 2.2127521534760795

Epoch: 5| Step: 4
Training loss: 2.6768672466278076
Validation loss: 2.1948274771372476

Epoch: 5| Step: 5
Training loss: 1.4572727680206299
Validation loss: 2.2201407303412757

Epoch: 5| Step: 6
Training loss: 1.2500228881835938
Validation loss: 2.2356279492378235

Epoch: 5| Step: 7
Training loss: 1.457744836807251
Validation loss: 2.2356580644845963

Epoch: 5| Step: 8
Training loss: 1.567010521888733
Validation loss: 2.243325491746267

Epoch: 5| Step: 9
Training loss: 1.718553900718689
Validation loss: 2.232901786764463

Epoch: 5| Step: 10
Training loss: 1.8019260168075562
Validation loss: 2.2628381301959357

Epoch: 5| Step: 11
Training loss: 2.7081830501556396
Validation loss: 2.2644509077072144

Epoch: 320| Step: 0
Training loss: 1.7857334613800049
Validation loss: 2.27112478017807

Epoch: 5| Step: 1
Training loss: 1.820829153060913
Validation loss: 2.276254485050837

Epoch: 5| Step: 2
Training loss: 1.604373574256897
Validation loss: 2.289448082447052

Epoch: 5| Step: 3
Training loss: 1.8588626384735107
Validation loss: 2.248105759421984

Epoch: 5| Step: 4
Training loss: 1.670764684677124
Validation loss: 2.2421816488107047

Epoch: 5| Step: 5
Training loss: 1.7432177066802979
Validation loss: 2.222209165493647

Epoch: 5| Step: 6
Training loss: 1.5164048671722412
Validation loss: 2.21302796403567

Epoch: 5| Step: 7
Training loss: 1.8713611364364624
Validation loss: 2.1943138192097345

Epoch: 5| Step: 8
Training loss: 1.6870191097259521
Validation loss: 2.184593046704928

Epoch: 5| Step: 9
Training loss: 1.8252665996551514
Validation loss: 2.1763949294885

Epoch: 5| Step: 10
Training loss: 1.4981329441070557
Validation loss: 2.198345551888148

Epoch: 5| Step: 11
Training loss: 0.42169833183288574
Validation loss: 2.1924396256605783

Epoch: 321| Step: 0
Training loss: 1.4918158054351807
Validation loss: 2.2124181588490806

Epoch: 5| Step: 1
Training loss: 1.775011658668518
Validation loss: 2.215855911374092

Epoch: 5| Step: 2
Training loss: 1.3637571334838867
Validation loss: 2.2326246400674186

Epoch: 5| Step: 3
Training loss: 2.1839966773986816
Validation loss: 2.277475282549858

Epoch: 5| Step: 4
Training loss: 2.1909046173095703
Validation loss: 2.286827767888705

Epoch: 5| Step: 5
Training loss: 1.516615867614746
Validation loss: 2.321652909119924

Epoch: 5| Step: 6
Training loss: 1.8183956146240234
Validation loss: 2.354141136010488

Epoch: 5| Step: 7
Training loss: 2.079458713531494
Validation loss: 2.3353830724954605

Epoch: 5| Step: 8
Training loss: 1.1652352809906006
Validation loss: 2.3334199637174606

Epoch: 5| Step: 9
Training loss: 1.5489747524261475
Validation loss: 2.276868760585785

Epoch: 5| Step: 10
Training loss: 1.6200697422027588
Validation loss: 2.2944965263207755

Epoch: 5| Step: 11
Training loss: 1.6654162406921387
Validation loss: 2.257459203402201

Epoch: 322| Step: 0
Training loss: 1.5398004055023193
Validation loss: 2.247780372699102

Epoch: 5| Step: 1
Training loss: 1.6902720928192139
Validation loss: 2.2118805845578513

Epoch: 5| Step: 2
Training loss: 1.637762427330017
Validation loss: 2.2130282471577325

Epoch: 5| Step: 3
Training loss: 1.5474388599395752
Validation loss: 2.2103754927714667

Epoch: 5| Step: 4
Training loss: 2.1496589183807373
Validation loss: 2.2179957876602807

Epoch: 5| Step: 5
Training loss: 1.393958330154419
Validation loss: 2.1932665407657623

Epoch: 5| Step: 6
Training loss: 1.3160492181777954
Validation loss: 2.2125378797451654

Epoch: 5| Step: 7
Training loss: 1.3909614086151123
Validation loss: 2.212844262520472

Epoch: 5| Step: 8
Training loss: 2.0227761268615723
Validation loss: 2.2046460757652917

Epoch: 5| Step: 9
Training loss: 1.7324714660644531
Validation loss: 2.208452800909678

Epoch: 5| Step: 10
Training loss: 1.88332200050354
Validation loss: 2.2093360920747123

Epoch: 5| Step: 11
Training loss: 2.373924732208252
Validation loss: 2.223476842045784

Epoch: 323| Step: 0
Training loss: 1.2569836378097534
Validation loss: 2.220915009578069

Epoch: 5| Step: 1
Training loss: 2.100119113922119
Validation loss: 2.2423503547906876

Epoch: 5| Step: 2
Training loss: 1.7237465381622314
Validation loss: 2.233307123184204

Epoch: 5| Step: 3
Training loss: 2.1782350540161133
Validation loss: 2.229278013110161

Epoch: 5| Step: 4
Training loss: 1.9009191989898682
Validation loss: 2.2296572029590607

Epoch: 5| Step: 5
Training loss: 1.5695849657058716
Validation loss: 2.1918786615133286

Epoch: 5| Step: 6
Training loss: 1.6837393045425415
Validation loss: 2.2331973910331726

Epoch: 5| Step: 7
Training loss: 1.2179629802703857
Validation loss: 2.234595383207003

Epoch: 5| Step: 8
Training loss: 1.1995394229888916
Validation loss: 2.2434160858392715

Epoch: 5| Step: 9
Training loss: 1.81966233253479
Validation loss: 2.2053275108337402

Epoch: 5| Step: 10
Training loss: 1.514134168624878
Validation loss: 2.1976257463296256

Epoch: 5| Step: 11
Training loss: 2.1486334800720215
Validation loss: 2.2066776106754937

Epoch: 324| Step: 0
Training loss: 1.8500837087631226
Validation loss: 2.2067294220129647

Epoch: 5| Step: 1
Training loss: 1.609552025794983
Validation loss: 2.2008808851242065

Epoch: 5| Step: 2
Training loss: 1.6428664922714233
Validation loss: 2.208403358856837

Epoch: 5| Step: 3
Training loss: 1.4165607690811157
Validation loss: 2.221169034639994

Epoch: 5| Step: 4
Training loss: 1.9396766424179077
Validation loss: 2.2440679172674813

Epoch: 5| Step: 5
Training loss: 1.411285638809204
Validation loss: 2.262091134985288

Epoch: 5| Step: 6
Training loss: 1.872174859046936
Validation loss: 2.280072698990504

Epoch: 5| Step: 7
Training loss: 1.7335307598114014
Validation loss: 2.271136795481046

Epoch: 5| Step: 8
Training loss: 1.6233879327774048
Validation loss: 2.274790734052658

Epoch: 5| Step: 9
Training loss: 1.9252941608428955
Validation loss: 2.285336514314016

Epoch: 5| Step: 10
Training loss: 1.3403732776641846
Validation loss: 2.2850416004657745

Epoch: 5| Step: 11
Training loss: 3.3477845191955566
Validation loss: 2.275227884451548

Epoch: 325| Step: 0
Training loss: 1.131292700767517
Validation loss: 2.2623119801282883

Epoch: 5| Step: 1
Training loss: 1.7161928415298462
Validation loss: 2.2497097651163735

Epoch: 5| Step: 2
Training loss: 1.6978542804718018
Validation loss: 2.272129555543264

Epoch: 5| Step: 3
Training loss: 1.312838077545166
Validation loss: 2.245150938630104

Epoch: 5| Step: 4
Training loss: 2.1906380653381348
Validation loss: 2.2689387748638787

Epoch: 5| Step: 5
Training loss: 1.5952759981155396
Validation loss: 2.295642703771591

Epoch: 5| Step: 6
Training loss: 1.710889458656311
Validation loss: 2.259532098968824

Epoch: 5| Step: 7
Training loss: 1.4220447540283203
Validation loss: 2.2913637856642404

Epoch: 5| Step: 8
Training loss: 1.919053316116333
Validation loss: 2.29261921842893

Epoch: 5| Step: 9
Training loss: 2.2891855239868164
Validation loss: 2.285434474547704

Epoch: 5| Step: 10
Training loss: 1.238508939743042
Validation loss: 2.2776656101147332

Epoch: 5| Step: 11
Training loss: 1.1496875286102295
Validation loss: 2.249921535452207

Epoch: 326| Step: 0
Training loss: 1.4699443578720093
Validation loss: 2.299718290567398

Epoch: 5| Step: 1
Training loss: 2.4052321910858154
Validation loss: 2.2546273469924927

Epoch: 5| Step: 2
Training loss: 1.3099392652511597
Validation loss: 2.2552371819814048

Epoch: 5| Step: 3
Training loss: 1.5114898681640625
Validation loss: 2.2479887505372367

Epoch: 5| Step: 4
Training loss: 1.3303006887435913
Validation loss: 2.255387713511785

Epoch: 5| Step: 5
Training loss: 2.087381362915039
Validation loss: 2.240410561362902

Epoch: 5| Step: 6
Training loss: 1.4344887733459473
Validation loss: 2.255233292778333

Epoch: 5| Step: 7
Training loss: 1.4762524366378784
Validation loss: 2.2329300890366235

Epoch: 5| Step: 8
Training loss: 1.105221152305603
Validation loss: 2.2322197606166205

Epoch: 5| Step: 9
Training loss: 2.318798780441284
Validation loss: 2.244648555914561

Epoch: 5| Step: 10
Training loss: 1.7572526931762695
Validation loss: 2.227635463078817

Epoch: 5| Step: 11
Training loss: 1.343508005142212
Validation loss: 2.2290032456318536

Epoch: 327| Step: 0
Training loss: 2.1812193393707275
Validation loss: 2.2734998365243277

Epoch: 5| Step: 1
Training loss: 2.23134446144104
Validation loss: 2.2315056870381036

Epoch: 5| Step: 2
Training loss: 1.5130072832107544
Validation loss: 2.2549404998620353

Epoch: 5| Step: 3
Training loss: 1.5738859176635742
Validation loss: 2.2378750443458557

Epoch: 5| Step: 4
Training loss: 1.3029361963272095
Validation loss: 2.2319224178791046

Epoch: 5| Step: 5
Training loss: 0.9458001852035522
Validation loss: 2.261228879292806

Epoch: 5| Step: 6
Training loss: 1.6916961669921875
Validation loss: 2.256573438644409

Epoch: 5| Step: 7
Training loss: 1.608188271522522
Validation loss: 2.23290220896403

Epoch: 5| Step: 8
Training loss: 1.8158537149429321
Validation loss: 2.2445472280184426

Epoch: 5| Step: 9
Training loss: 1.7555952072143555
Validation loss: 2.229794830083847

Epoch: 5| Step: 10
Training loss: 1.5122934579849243
Validation loss: 2.21871218085289

Epoch: 5| Step: 11
Training loss: 1.218239665031433
Validation loss: 2.2335740476846695

Epoch: 328| Step: 0
Training loss: 1.7680108547210693
Validation loss: 2.253566324710846

Epoch: 5| Step: 1
Training loss: 1.1838852167129517
Validation loss: 2.235236555337906

Epoch: 5| Step: 2
Training loss: 1.700937032699585
Validation loss: 2.2282697757085166

Epoch: 5| Step: 3
Training loss: 1.1564314365386963
Validation loss: 2.244713455438614

Epoch: 5| Step: 4
Training loss: 1.817420244216919
Validation loss: 2.2254385451475778

Epoch: 5| Step: 5
Training loss: 1.1789456605911255
Validation loss: 2.2272858321666718

Epoch: 5| Step: 6
Training loss: 1.7406154870986938
Validation loss: 2.2480642199516296

Epoch: 5| Step: 7
Training loss: 1.4371757507324219
Validation loss: 2.233619992931684

Epoch: 5| Step: 8
Training loss: 1.7333170175552368
Validation loss: 2.2243818938732147

Epoch: 5| Step: 9
Training loss: 2.2245421409606934
Validation loss: 2.2560631732145944

Epoch: 5| Step: 10
Training loss: 1.8411222696304321
Validation loss: 2.2368917167186737

Epoch: 5| Step: 11
Training loss: 1.1940515041351318
Validation loss: 2.232545773188273

Epoch: 329| Step: 0
Training loss: 1.2935739755630493
Validation loss: 2.2504957020282745

Epoch: 5| Step: 1
Training loss: 2.4531209468841553
Validation loss: 2.2591049124797187

Epoch: 5| Step: 2
Training loss: 1.328643798828125
Validation loss: 2.2557070503632226

Epoch: 5| Step: 3
Training loss: 1.5150136947631836
Validation loss: 2.257540225982666

Epoch: 5| Step: 4
Training loss: 1.7933290004730225
Validation loss: 2.24108724296093

Epoch: 5| Step: 5
Training loss: 1.1718108654022217
Validation loss: 2.266066938638687

Epoch: 5| Step: 6
Training loss: 1.3799855709075928
Validation loss: 2.2646398693323135

Epoch: 5| Step: 7
Training loss: 1.6297614574432373
Validation loss: 2.2699442356824875

Epoch: 5| Step: 8
Training loss: 1.9655815362930298
Validation loss: 2.254282608628273

Epoch: 5| Step: 9
Training loss: 1.9985374212265015
Validation loss: 2.252460926771164

Epoch: 5| Step: 10
Training loss: 1.5311580896377563
Validation loss: 2.2540191610654197

Epoch: 5| Step: 11
Training loss: 0.8181490898132324
Validation loss: 2.2414260307947793

Epoch: 330| Step: 0
Training loss: 1.6455910205841064
Validation loss: 2.2415117820103965

Epoch: 5| Step: 1
Training loss: 1.0700504779815674
Validation loss: 2.2100785026947656

Epoch: 5| Step: 2
Training loss: 1.6928107738494873
Validation loss: 2.2273251513640084

Epoch: 5| Step: 3
Training loss: 2.045348644256592
Validation loss: 2.1962192008892694

Epoch: 5| Step: 4
Training loss: 1.413278341293335
Validation loss: 2.1880771120389304

Epoch: 5| Step: 5
Training loss: 1.4167792797088623
Validation loss: 2.1958292921384177

Epoch: 5| Step: 6
Training loss: 1.705285668373108
Validation loss: 2.1969019770622253

Epoch: 5| Step: 7
Training loss: 2.0915486812591553
Validation loss: 2.1840212593475976

Epoch: 5| Step: 8
Training loss: 1.6323131322860718
Validation loss: 2.1846632013718286

Epoch: 5| Step: 9
Training loss: 1.6426441669464111
Validation loss: 2.184567153453827

Epoch: 5| Step: 10
Training loss: 1.4635025262832642
Validation loss: 2.198098435997963

Epoch: 5| Step: 11
Training loss: 2.164205551147461
Validation loss: 2.200891822576523

Epoch: 331| Step: 0
Training loss: 1.5473802089691162
Validation loss: 2.199743628501892

Epoch: 5| Step: 1
Training loss: 1.457047939300537
Validation loss: 2.222815374533335

Epoch: 5| Step: 2
Training loss: 1.4006052017211914
Validation loss: 2.1918941040833793

Epoch: 5| Step: 3
Training loss: 1.571944236755371
Validation loss: 2.1845621466636658

Epoch: 5| Step: 4
Training loss: 1.7084481716156006
Validation loss: 2.2491210599740348

Epoch: 5| Step: 5
Training loss: 1.5820283889770508
Validation loss: 2.2281521360079446

Epoch: 5| Step: 6
Training loss: 1.5285742282867432
Validation loss: 2.2505966474612555

Epoch: 5| Step: 7
Training loss: 1.588876485824585
Validation loss: 2.279126907388369

Epoch: 5| Step: 8
Training loss: 1.7134062051773071
Validation loss: 2.3215563744306564

Epoch: 5| Step: 9
Training loss: 1.8984180688858032
Validation loss: 2.324453761180242

Epoch: 5| Step: 10
Training loss: 1.8794397115707397
Validation loss: 2.3195345203081765

Epoch: 5| Step: 11
Training loss: 2.097372531890869
Validation loss: 2.328898916641871

Epoch: 332| Step: 0
Training loss: 1.2516305446624756
Validation loss: 2.300479382276535

Epoch: 5| Step: 1
Training loss: 1.8550386428833008
Validation loss: 2.283224215110143

Epoch: 5| Step: 2
Training loss: 1.9869213104248047
Validation loss: 2.2607539196809134

Epoch: 5| Step: 3
Training loss: 1.5410244464874268
Validation loss: 2.21218378841877

Epoch: 5| Step: 4
Training loss: 1.293919324874878
Validation loss: 2.2150526344776154

Epoch: 5| Step: 5
Training loss: 1.5135259628295898
Validation loss: 2.1921271830797195

Epoch: 5| Step: 6
Training loss: 2.382514476776123
Validation loss: 2.1944215993086496

Epoch: 5| Step: 7
Training loss: 1.953616738319397
Validation loss: 2.1937880516052246

Epoch: 5| Step: 8
Training loss: 1.294242262840271
Validation loss: 2.2019053995609283

Epoch: 5| Step: 9
Training loss: 2.0109548568725586
Validation loss: 2.190228442351023

Epoch: 5| Step: 10
Training loss: 1.337086796760559
Validation loss: 2.1924089392026267

Epoch: 5| Step: 11
Training loss: 0.9171732664108276
Validation loss: 2.2122310549020767

Epoch: 333| Step: 0
Training loss: 1.6015102863311768
Validation loss: 2.2172823200623193

Epoch: 5| Step: 1
Training loss: 1.5133686065673828
Validation loss: 2.2465426176786423

Epoch: 5| Step: 2
Training loss: 1.8148730993270874
Validation loss: 2.2338050107161203

Epoch: 5| Step: 3
Training loss: 1.6775662899017334
Validation loss: 2.2655765215555825

Epoch: 5| Step: 4
Training loss: 1.7359145879745483
Validation loss: 2.273052324851354

Epoch: 5| Step: 5
Training loss: 1.5030275583267212
Validation loss: 2.2984325289726257

Epoch: 5| Step: 6
Training loss: 1.7354686260223389
Validation loss: 2.2812783618768058

Epoch: 5| Step: 7
Training loss: 1.5666985511779785
Validation loss: 2.217439144849777

Epoch: 5| Step: 8
Training loss: 1.6265697479248047
Validation loss: 2.2373031278451285

Epoch: 5| Step: 9
Training loss: 0.9089870452880859
Validation loss: 2.228073075413704

Epoch: 5| Step: 10
Training loss: 1.9359016418457031
Validation loss: 2.225264087319374

Epoch: 5| Step: 11
Training loss: 0.9186159372329712
Validation loss: 2.193331907192866

Epoch: 334| Step: 0
Training loss: 1.8730703592300415
Validation loss: 2.190487672885259

Epoch: 5| Step: 1
Training loss: 1.5724729299545288
Validation loss: 2.1930313209692636

Epoch: 5| Step: 2
Training loss: 1.792884111404419
Validation loss: 2.1776033540566764

Epoch: 5| Step: 3
Training loss: 2.2406888008117676
Validation loss: 2.217342883348465

Epoch: 5| Step: 4
Training loss: 1.3638198375701904
Validation loss: 2.208481341600418

Epoch: 5| Step: 5
Training loss: 1.7319132089614868
Validation loss: 2.1800034691890082

Epoch: 5| Step: 6
Training loss: 1.5851956605911255
Validation loss: 2.22129296263059

Epoch: 5| Step: 7
Training loss: 2.1110544204711914
Validation loss: 2.2320111195246377

Epoch: 5| Step: 8
Training loss: 1.8880491256713867
Validation loss: 2.2820621778567634

Epoch: 5| Step: 9
Training loss: 1.429282307624817
Validation loss: 2.26662939786911

Epoch: 5| Step: 10
Training loss: 1.5651401281356812
Validation loss: 2.2705973784128823

Epoch: 5| Step: 11
Training loss: 1.0793509483337402
Validation loss: 2.2991874118645987

Epoch: 335| Step: 0
Training loss: 1.491080641746521
Validation loss: 2.2859365542729697

Epoch: 5| Step: 1
Training loss: 2.2457633018493652
Validation loss: 2.2594706068436303

Epoch: 5| Step: 2
Training loss: 1.767480492591858
Validation loss: 2.2630379796028137

Epoch: 5| Step: 3
Training loss: 1.5608866214752197
Validation loss: 2.2617452144622803

Epoch: 5| Step: 4
Training loss: 1.501007318496704
Validation loss: 2.249784012635549

Epoch: 5| Step: 5
Training loss: 2.0259077548980713
Validation loss: 2.2397961715857186

Epoch: 5| Step: 6
Training loss: 1.630497694015503
Validation loss: 2.230080470442772

Epoch: 5| Step: 7
Training loss: 0.968754768371582
Validation loss: 2.2168464064598083

Epoch: 5| Step: 8
Training loss: 1.2782552242279053
Validation loss: 2.2429121683041253

Epoch: 5| Step: 9
Training loss: 1.7715953588485718
Validation loss: 2.2366648068030677

Epoch: 5| Step: 10
Training loss: 1.644250512123108
Validation loss: 2.223913222551346

Epoch: 5| Step: 11
Training loss: 0.691956639289856
Validation loss: 2.2552008777856827

Epoch: 336| Step: 0
Training loss: 1.2007004022598267
Validation loss: 2.248221526543299

Epoch: 5| Step: 1
Training loss: 1.5748696327209473
Validation loss: 2.266527091463407

Epoch: 5| Step: 2
Training loss: 1.2861483097076416
Validation loss: 2.267962788542112

Epoch: 5| Step: 3
Training loss: 1.8498246669769287
Validation loss: 2.255455583333969

Epoch: 5| Step: 4
Training loss: 1.5180130004882812
Validation loss: 2.266852150360743

Epoch: 5| Step: 5
Training loss: 1.638228416442871
Validation loss: 2.2943458010752997

Epoch: 5| Step: 6
Training loss: 1.573338508605957
Validation loss: 2.286703566710154

Epoch: 5| Step: 7
Training loss: 1.8454921245574951
Validation loss: 2.2777892698844275

Epoch: 5| Step: 8
Training loss: 1.9774144887924194
Validation loss: 2.25351012746493

Epoch: 5| Step: 9
Training loss: 2.0442333221435547
Validation loss: 2.261367936929067

Epoch: 5| Step: 10
Training loss: 1.1156820058822632
Validation loss: 2.2533364792664847

Epoch: 5| Step: 11
Training loss: 0.9825138449668884
Validation loss: 2.241065889596939

Epoch: 337| Step: 0
Training loss: 1.021813988685608
Validation loss: 2.2479223360617957

Epoch: 5| Step: 1
Training loss: 1.5407911539077759
Validation loss: 2.234574099381765

Epoch: 5| Step: 2
Training loss: 1.816245436668396
Validation loss: 2.2748245894908905

Epoch: 5| Step: 3
Training loss: 1.6823699474334717
Validation loss: 2.262922296921412

Epoch: 5| Step: 4
Training loss: 2.150878429412842
Validation loss: 2.242499421040217

Epoch: 5| Step: 5
Training loss: 1.5369679927825928
Validation loss: 2.2511615554491677

Epoch: 5| Step: 6
Training loss: 2.3443381786346436
Validation loss: 2.254658525188764

Epoch: 5| Step: 7
Training loss: 1.4139087200164795
Validation loss: 2.2443855106830597

Epoch: 5| Step: 8
Training loss: 1.129258394241333
Validation loss: 2.2510365148385367

Epoch: 5| Step: 9
Training loss: 1.0782568454742432
Validation loss: 2.2597788274288177

Epoch: 5| Step: 10
Training loss: 1.5617018938064575
Validation loss: 2.2499122669299445

Epoch: 5| Step: 11
Training loss: 1.512279748916626
Validation loss: 2.278919219970703

Epoch: 338| Step: 0
Training loss: 1.0604995489120483
Validation loss: 2.2386461397012076

Epoch: 5| Step: 1
Training loss: 1.6266189813613892
Validation loss: 2.2373273074626923

Epoch: 5| Step: 2
Training loss: 1.4691510200500488
Validation loss: 2.235052506128947

Epoch: 5| Step: 3
Training loss: 2.2426745891571045
Validation loss: 2.2420757015546164

Epoch: 5| Step: 4
Training loss: 1.4047224521636963
Validation loss: 2.244951546192169

Epoch: 5| Step: 5
Training loss: 1.7101236581802368
Validation loss: 2.20779058833917

Epoch: 5| Step: 6
Training loss: 1.5656975507736206
Validation loss: 2.2109843591849008

Epoch: 5| Step: 7
Training loss: 1.9022020101547241
Validation loss: 2.2376133650541306

Epoch: 5| Step: 8
Training loss: 1.6316169500350952
Validation loss: 2.2164859076340995

Epoch: 5| Step: 9
Training loss: 2.1592354774475098
Validation loss: 2.241109018524488

Epoch: 5| Step: 10
Training loss: 1.3630287647247314
Validation loss: 2.236356814702352

Epoch: 5| Step: 11
Training loss: 1.2674051523208618
Validation loss: 2.2500398407379785

Epoch: 339| Step: 0
Training loss: 1.8329616785049438
Validation loss: 2.24973164498806

Epoch: 5| Step: 1
Training loss: 1.6485204696655273
Validation loss: 2.2495987017949424

Epoch: 5| Step: 2
Training loss: 1.7330162525177002
Validation loss: 2.2720396916071572

Epoch: 5| Step: 3
Training loss: 1.4606529474258423
Validation loss: 2.2509966492652893

Epoch: 5| Step: 4
Training loss: 0.9920442700386047
Validation loss: 2.261185179154078

Epoch: 5| Step: 5
Training loss: 1.4550222158432007
Validation loss: 2.2690416226784387

Epoch: 5| Step: 6
Training loss: 1.592525839805603
Validation loss: 2.289377053578695

Epoch: 5| Step: 7
Training loss: 1.7407951354980469
Validation loss: 2.2553958346446357

Epoch: 5| Step: 8
Training loss: 1.908837080001831
Validation loss: 2.2445942213137946

Epoch: 5| Step: 9
Training loss: 2.0565154552459717
Validation loss: 2.224674642086029

Epoch: 5| Step: 10
Training loss: 1.4492796659469604
Validation loss: 2.2530766824881234

Epoch: 5| Step: 11
Training loss: 1.4189527034759521
Validation loss: 2.215915153423945

Epoch: 340| Step: 0
Training loss: 1.266146183013916
Validation loss: 2.216612766186396

Epoch: 5| Step: 1
Training loss: 1.8775583505630493
Validation loss: 2.2003861367702484

Epoch: 5| Step: 2
Training loss: 1.3492963314056396
Validation loss: 2.1845826307932534

Epoch: 5| Step: 3
Training loss: 1.354142665863037
Validation loss: 2.2213930090268454

Epoch: 5| Step: 4
Training loss: 1.9158909320831299
Validation loss: 2.2175479978322983

Epoch: 5| Step: 5
Training loss: 1.893805742263794
Validation loss: 2.2217523554960885

Epoch: 5| Step: 6
Training loss: 1.5513118505477905
Validation loss: 2.2473884522914886

Epoch: 5| Step: 7
Training loss: 1.862334966659546
Validation loss: 2.243676250179609

Epoch: 5| Step: 8
Training loss: 1.891257643699646
Validation loss: 2.3048684199651084

Epoch: 5| Step: 9
Training loss: 1.8488247394561768
Validation loss: 2.3137193421522775

Epoch: 5| Step: 10
Training loss: 1.46502685546875
Validation loss: 2.309181888898214

Epoch: 5| Step: 11
Training loss: 1.9364047050476074
Validation loss: 2.2955020368099213

Epoch: 341| Step: 0
Training loss: 1.5469752550125122
Validation loss: 2.3028102417786918

Epoch: 5| Step: 1
Training loss: 1.5583409070968628
Validation loss: 2.2995168368021646

Epoch: 5| Step: 2
Training loss: 1.1710617542266846
Validation loss: 2.2880085110664368

Epoch: 5| Step: 3
Training loss: 1.4048665761947632
Validation loss: 2.2694820314645767

Epoch: 5| Step: 4
Training loss: 1.923718810081482
Validation loss: 2.2705013851324716

Epoch: 5| Step: 5
Training loss: 2.0953526496887207
Validation loss: 2.227450504899025

Epoch: 5| Step: 6
Training loss: 1.3109838962554932
Validation loss: 2.1998034914334617

Epoch: 5| Step: 7
Training loss: 1.826849341392517
Validation loss: 2.2094474087158837

Epoch: 5| Step: 8
Training loss: 1.4378162622451782
Validation loss: 2.217523549993833

Epoch: 5| Step: 9
Training loss: 2.2471346855163574
Validation loss: 2.209027796983719

Epoch: 5| Step: 10
Training loss: 1.4650115966796875
Validation loss: 2.1977819999059043

Epoch: 5| Step: 11
Training loss: 1.1638429164886475
Validation loss: 2.20715502401193

Epoch: 342| Step: 0
Training loss: 1.3365534543991089
Validation loss: 2.188511664668719

Epoch: 5| Step: 1
Training loss: 1.5062050819396973
Validation loss: 2.2209670344988504

Epoch: 5| Step: 2
Training loss: 1.5179922580718994
Validation loss: 2.217418854435285

Epoch: 5| Step: 3
Training loss: 2.2675178050994873
Validation loss: 2.2222165763378143

Epoch: 5| Step: 4
Training loss: 0.9225032925605774
Validation loss: 2.2269665946563086

Epoch: 5| Step: 5
Training loss: 1.6607192754745483
Validation loss: 2.2226130614678064

Epoch: 5| Step: 6
Training loss: 1.928951621055603
Validation loss: 2.2312699407339096

Epoch: 5| Step: 7
Training loss: 1.6598341464996338
Validation loss: 2.2473666022221246

Epoch: 5| Step: 8
Training loss: 1.2754377126693726
Validation loss: 2.270645394921303

Epoch: 5| Step: 9
Training loss: 1.686876654624939
Validation loss: 2.2657393515110016

Epoch: 5| Step: 10
Training loss: 1.6352096796035767
Validation loss: 2.2565621733665466

Epoch: 5| Step: 11
Training loss: 1.1854820251464844
Validation loss: 2.280461629231771

Epoch: 343| Step: 0
Training loss: 1.1085385084152222
Validation loss: 2.254846453666687

Epoch: 5| Step: 1
Training loss: 1.9201549291610718
Validation loss: 2.2405284345149994

Epoch: 5| Step: 2
Training loss: 1.12631094455719
Validation loss: 2.242614264289538

Epoch: 5| Step: 3
Training loss: 2.1795735359191895
Validation loss: 2.247959931691488

Epoch: 5| Step: 4
Training loss: 1.3301870822906494
Validation loss: 2.2293357451756797

Epoch: 5| Step: 5
Training loss: 1.5191705226898193
Validation loss: 2.2250411113103232

Epoch: 5| Step: 6
Training loss: 1.8571338653564453
Validation loss: 2.225001206000646

Epoch: 5| Step: 7
Training loss: 1.4925730228424072
Validation loss: 2.2211645245552063

Epoch: 5| Step: 8
Training loss: 1.9847358465194702
Validation loss: 2.2320152719815574

Epoch: 5| Step: 9
Training loss: 1.1596850156784058
Validation loss: 2.230593050519625

Epoch: 5| Step: 10
Training loss: 1.6569675207138062
Validation loss: 2.213250016172727

Epoch: 5| Step: 11
Training loss: 0.644635796546936
Validation loss: 2.212145298719406

Epoch: 344| Step: 0
Training loss: 1.787384271621704
Validation loss: 2.218700925509135

Epoch: 5| Step: 1
Training loss: 1.5999089479446411
Validation loss: 2.221544325351715

Epoch: 5| Step: 2
Training loss: 1.352513074874878
Validation loss: 2.2421828409036

Epoch: 5| Step: 3
Training loss: 1.7514979839324951
Validation loss: 2.2112381060918174

Epoch: 5| Step: 4
Training loss: 1.8561627864837646
Validation loss: 2.2138467927773795

Epoch: 5| Step: 5
Training loss: 1.3723151683807373
Validation loss: 2.2124518702427545

Epoch: 5| Step: 6
Training loss: 1.5832042694091797
Validation loss: 2.2285364866256714

Epoch: 5| Step: 7
Training loss: 1.8394581079483032
Validation loss: 2.1937970221042633

Epoch: 5| Step: 8
Training loss: 1.007371187210083
Validation loss: 2.2125472923119864

Epoch: 5| Step: 9
Training loss: 1.1058337688446045
Validation loss: 2.2079187085231147

Epoch: 5| Step: 10
Training loss: 1.6268081665039062
Validation loss: 2.1977034906546273

Epoch: 5| Step: 11
Training loss: 3.3390908241271973
Validation loss: 2.1808205942312875

Epoch: 345| Step: 0
Training loss: 1.7209007740020752
Validation loss: 2.2067759533723197

Epoch: 5| Step: 1
Training loss: 1.662744164466858
Validation loss: 2.215162461002668

Epoch: 5| Step: 2
Training loss: 1.6171348094940186
Validation loss: 2.2081329921881356

Epoch: 5| Step: 3
Training loss: 1.3577901124954224
Validation loss: 2.1957095762093863

Epoch: 5| Step: 4
Training loss: 1.952090859413147
Validation loss: 2.1851560970147452

Epoch: 5| Step: 5
Training loss: 1.3225646018981934
Validation loss: 2.210507611433665

Epoch: 5| Step: 6
Training loss: 1.096523642539978
Validation loss: 2.2077655444542565

Epoch: 5| Step: 7
Training loss: 1.4997520446777344
Validation loss: 2.203944519162178

Epoch: 5| Step: 8
Training loss: 1.5791995525360107
Validation loss: 2.212655648589134

Epoch: 5| Step: 9
Training loss: 1.3047128915786743
Validation loss: 2.2034618059794107

Epoch: 5| Step: 10
Training loss: 1.8437855243682861
Validation loss: 2.2070867270231247

Epoch: 5| Step: 11
Training loss: 1.5101139545440674
Validation loss: 2.2162030736605325

Epoch: 346| Step: 0
Training loss: 1.3756468296051025
Validation loss: 2.2365336219469705

Epoch: 5| Step: 1
Training loss: 1.618475317955017
Validation loss: 2.1933042407035828

Epoch: 5| Step: 2
Training loss: 1.5033676624298096
Validation loss: 2.214915523926417

Epoch: 5| Step: 3
Training loss: 1.481830358505249
Validation loss: 2.2027992059787116

Epoch: 5| Step: 4
Training loss: 1.701599359512329
Validation loss: 2.2154738008975983

Epoch: 5| Step: 5
Training loss: 1.7383334636688232
Validation loss: 2.1932289799054465

Epoch: 5| Step: 6
Training loss: 1.505903720855713
Validation loss: 2.203250676393509

Epoch: 5| Step: 7
Training loss: 1.8685123920440674
Validation loss: 2.2188752790292106

Epoch: 5| Step: 8
Training loss: 1.060511589050293
Validation loss: 2.222919503847758

Epoch: 5| Step: 9
Training loss: 1.62661874294281
Validation loss: 2.198511282602946

Epoch: 5| Step: 10
Training loss: 1.4726556539535522
Validation loss: 2.2255894045035043

Epoch: 5| Step: 11
Training loss: 1.1370881795883179
Validation loss: 2.214316283663114

Epoch: 347| Step: 0
Training loss: 2.507551908493042
Validation loss: 2.242832899093628

Epoch: 5| Step: 1
Training loss: 1.3666911125183105
Validation loss: 2.244753291209539

Epoch: 5| Step: 2
Training loss: 1.4026013612747192
Validation loss: 2.215891649325689

Epoch: 5| Step: 3
Training loss: 1.3132059574127197
Validation loss: 2.2364662935336432

Epoch: 5| Step: 4
Training loss: 1.1731016635894775
Validation loss: 2.243243550260862

Epoch: 5| Step: 5
Training loss: 2.2128138542175293
Validation loss: 2.2501912464698157

Epoch: 5| Step: 6
Training loss: 1.216626524925232
Validation loss: 2.2664051751295724

Epoch: 5| Step: 7
Training loss: 1.6554405689239502
Validation loss: 2.246991813182831

Epoch: 5| Step: 8
Training loss: 1.1794192790985107
Validation loss: 2.2036181688308716

Epoch: 5| Step: 9
Training loss: 1.747870683670044
Validation loss: 2.2394831279913583

Epoch: 5| Step: 10
Training loss: 0.9835551977157593
Validation loss: 2.245840455094973

Epoch: 5| Step: 11
Training loss: 1.0898516178131104
Validation loss: 2.2438607017199197

Epoch: 348| Step: 0
Training loss: 2.762180805206299
Validation loss: 2.2401435375213623

Epoch: 5| Step: 1
Training loss: 1.240058183670044
Validation loss: 2.2476600110530853

Epoch: 5| Step: 2
Training loss: 2.050043821334839
Validation loss: 2.2438190281391144

Epoch: 5| Step: 3
Training loss: 1.4308046102523804
Validation loss: 2.250415116548538

Epoch: 5| Step: 4
Training loss: 1.1636687517166138
Validation loss: 2.256077229976654

Epoch: 5| Step: 5
Training loss: 1.245134711265564
Validation loss: 2.236415132880211

Epoch: 5| Step: 6
Training loss: 1.4590458869934082
Validation loss: 2.208111176888148

Epoch: 5| Step: 7
Training loss: 1.6261392831802368
Validation loss: 2.2111989011367164

Epoch: 5| Step: 8
Training loss: 2.1235547065734863
Validation loss: 2.216859742999077

Epoch: 5| Step: 9
Training loss: 1.0702998638153076
Validation loss: 2.205636113882065

Epoch: 5| Step: 10
Training loss: 1.1101676225662231
Validation loss: 2.2047289659579596

Epoch: 5| Step: 11
Training loss: 2.006920337677002
Validation loss: 2.195845032731692

Epoch: 349| Step: 0
Training loss: 1.7098846435546875
Validation loss: 2.205696920553843

Epoch: 5| Step: 1
Training loss: 1.4728292226791382
Validation loss: 2.2032884508371353

Epoch: 5| Step: 2
Training loss: 1.7059381008148193
Validation loss: 2.2153649975856147

Epoch: 5| Step: 3
Training loss: 0.9596578478813171
Validation loss: 2.2484154601891837

Epoch: 5| Step: 4
Training loss: 1.8758684396743774
Validation loss: 2.2684474835793176

Epoch: 5| Step: 5
Training loss: 1.5308641195297241
Validation loss: 2.2694092392921448

Epoch: 5| Step: 6
Training loss: 1.19756281375885
Validation loss: 2.2625292936960855

Epoch: 5| Step: 7
Training loss: 1.1967504024505615
Validation loss: 2.266319582859675

Epoch: 5| Step: 8
Training loss: 1.726388692855835
Validation loss: 2.2520471115907035

Epoch: 5| Step: 9
Training loss: 1.3547556400299072
Validation loss: 2.2246459076801934

Epoch: 5| Step: 10
Training loss: 2.232187032699585
Validation loss: 2.2494513789812722

Epoch: 5| Step: 11
Training loss: 1.9092851877212524
Validation loss: 2.2228868504365287

Epoch: 350| Step: 0
Training loss: 1.6557466983795166
Validation loss: 2.2724804083506265

Epoch: 5| Step: 1
Training loss: 1.3109897375106812
Validation loss: 2.244103858868281

Epoch: 5| Step: 2
Training loss: 1.641025185585022
Validation loss: 2.235792100429535

Epoch: 5| Step: 3
Training loss: 1.6106834411621094
Validation loss: 2.248971606294314

Epoch: 5| Step: 4
Training loss: 1.4937951564788818
Validation loss: 2.24027152856191

Epoch: 5| Step: 5
Training loss: 1.3010681867599487
Validation loss: 2.2316349893808365

Epoch: 5| Step: 6
Training loss: 1.5510927438735962
Validation loss: 2.2849959482749305

Epoch: 5| Step: 7
Training loss: 1.6329351663589478
Validation loss: 2.235638956228892

Epoch: 5| Step: 8
Training loss: 1.4533182382583618
Validation loss: 2.2281643450260162

Epoch: 5| Step: 9
Training loss: 1.675999402999878
Validation loss: 2.2285983661810556

Epoch: 5| Step: 10
Training loss: 1.8235305547714233
Validation loss: 2.2120699087778726

Epoch: 5| Step: 11
Training loss: 0.43190640211105347
Validation loss: 2.202416772643725

Epoch: 351| Step: 0
Training loss: 1.5927150249481201
Validation loss: 2.1753487586975098

Epoch: 5| Step: 1
Training loss: 1.8464568853378296
Validation loss: 2.1892002125581107

Epoch: 5| Step: 2
Training loss: 1.2994496822357178
Validation loss: 2.2002025147279105

Epoch: 5| Step: 3
Training loss: 1.1451208591461182
Validation loss: 2.2001037945350013

Epoch: 5| Step: 4
Training loss: 1.719799280166626
Validation loss: 2.179866070548693

Epoch: 5| Step: 5
Training loss: 2.125178337097168
Validation loss: 2.204354832569758

Epoch: 5| Step: 6
Training loss: 1.348104476928711
Validation loss: 2.183697059750557

Epoch: 5| Step: 7
Training loss: 1.0233588218688965
Validation loss: 2.189567337433497

Epoch: 5| Step: 8
Training loss: 1.3947088718414307
Validation loss: 2.206925501426061

Epoch: 5| Step: 9
Training loss: 1.8603874444961548
Validation loss: 2.219554752111435

Epoch: 5| Step: 10
Training loss: 1.7456104755401611
Validation loss: 2.2347190976142883

Epoch: 5| Step: 11
Training loss: 2.3638381958007812
Validation loss: 2.2256658573945365

Epoch: 352| Step: 0
Training loss: 1.4047749042510986
Validation loss: 2.2362686097621918

Epoch: 5| Step: 1
Training loss: 1.8443981409072876
Validation loss: 2.206029931704203

Epoch: 5| Step: 2
Training loss: 1.2166810035705566
Validation loss: 2.1997679670651755

Epoch: 5| Step: 3
Training loss: 1.648901343345642
Validation loss: 2.197222779194514

Epoch: 5| Step: 4
Training loss: 1.6965620517730713
Validation loss: 2.1776200433572135

Epoch: 5| Step: 5
Training loss: 1.6667957305908203
Validation loss: 2.1640520791212716

Epoch: 5| Step: 6
Training loss: 1.7409194707870483
Validation loss: 2.19820569952329

Epoch: 5| Step: 7
Training loss: 1.6334025859832764
Validation loss: 2.206701551874479

Epoch: 5| Step: 8
Training loss: 1.460963249206543
Validation loss: 2.1985248227914176

Epoch: 5| Step: 9
Training loss: 1.247026801109314
Validation loss: 2.2094190617402396

Epoch: 5| Step: 10
Training loss: 1.433654546737671
Validation loss: 2.1931674828131995

Epoch: 5| Step: 11
Training loss: 0.6253908276557922
Validation loss: 2.207220936814944

Epoch: 353| Step: 0
Training loss: 1.6839771270751953
Validation loss: 2.1964417000611625

Epoch: 5| Step: 1
Training loss: 1.417009949684143
Validation loss: 2.197984511653582

Epoch: 5| Step: 2
Training loss: 1.7519124746322632
Validation loss: 2.1650498459736505

Epoch: 5| Step: 3
Training loss: 1.8644777536392212
Validation loss: 2.2058663964271545

Epoch: 5| Step: 4
Training loss: 1.3231799602508545
Validation loss: 2.2016854137182236

Epoch: 5| Step: 5
Training loss: 1.905745506286621
Validation loss: 2.201084077358246

Epoch: 5| Step: 6
Training loss: 1.6193478107452393
Validation loss: 2.215180218219757

Epoch: 5| Step: 7
Training loss: 2.197343349456787
Validation loss: 2.240481734275818

Epoch: 5| Step: 8
Training loss: 1.3317437171936035
Validation loss: 2.231412167350451

Epoch: 5| Step: 9
Training loss: 1.1652042865753174
Validation loss: 2.249001274506251

Epoch: 5| Step: 10
Training loss: 1.642803430557251
Validation loss: 2.2445773084958396

Epoch: 5| Step: 11
Training loss: 1.5231494903564453
Validation loss: 2.214397817850113

Epoch: 354| Step: 0
Training loss: 1.3957765102386475
Validation loss: 2.234908491373062

Epoch: 5| Step: 1
Training loss: 1.4321236610412598
Validation loss: 2.2395936449368796

Epoch: 5| Step: 2
Training loss: 1.3134658336639404
Validation loss: 2.2376045137643814

Epoch: 5| Step: 3
Training loss: 1.4064006805419922
Validation loss: 2.249474292000135

Epoch: 5| Step: 4
Training loss: 1.321312665939331
Validation loss: 2.218831638495127

Epoch: 5| Step: 5
Training loss: 1.3552742004394531
Validation loss: 2.211848015586535

Epoch: 5| Step: 6
Training loss: 1.3197542428970337
Validation loss: 2.232546091079712

Epoch: 5| Step: 7
Training loss: 1.6681352853775024
Validation loss: 2.233899732430776

Epoch: 5| Step: 8
Training loss: 1.534967064857483
Validation loss: 2.236587037642797

Epoch: 5| Step: 9
Training loss: 1.4624494314193726
Validation loss: 2.232415129741033

Epoch: 5| Step: 10
Training loss: 2.298006534576416
Validation loss: 2.246351659297943

Epoch: 5| Step: 11
Training loss: 1.0462467670440674
Validation loss: 2.284861614306768

Epoch: 355| Step: 0
Training loss: 1.5930869579315186
Validation loss: 2.264406844973564

Epoch: 5| Step: 1
Training loss: 1.208113431930542
Validation loss: 2.2345315416653952

Epoch: 5| Step: 2
Training loss: 1.2733380794525146
Validation loss: 2.2213347752889

Epoch: 5| Step: 3
Training loss: 2.290879726409912
Validation loss: 2.183658172686895

Epoch: 5| Step: 4
Training loss: 1.967786431312561
Validation loss: 2.181424895922343

Epoch: 5| Step: 5
Training loss: 2.1621532440185547
Validation loss: 2.217366854349772

Epoch: 5| Step: 6
Training loss: 1.2792099714279175
Validation loss: 2.1960739890734353

Epoch: 5| Step: 7
Training loss: 1.1095101833343506
Validation loss: 2.189123421907425

Epoch: 5| Step: 8
Training loss: 0.934090793132782
Validation loss: 2.176458259423574

Epoch: 5| Step: 9
Training loss: 1.7863399982452393
Validation loss: 2.221487437685331

Epoch: 5| Step: 10
Training loss: 1.4016335010528564
Validation loss: 2.232151453693708

Epoch: 5| Step: 11
Training loss: 1.2181057929992676
Validation loss: 2.290150905648867

Epoch: 356| Step: 0
Training loss: 2.0854477882385254
Validation loss: 2.2982973953088126

Epoch: 5| Step: 1
Training loss: 1.0439341068267822
Validation loss: 2.306799372037252

Epoch: 5| Step: 2
Training loss: 1.6463165283203125
Validation loss: 2.3213920891284943

Epoch: 5| Step: 3
Training loss: 1.4995653629302979
Validation loss: 2.303609073162079

Epoch: 5| Step: 4
Training loss: 0.6988701820373535
Validation loss: 2.290405198931694

Epoch: 5| Step: 5
Training loss: 1.849382996559143
Validation loss: 2.263154869278272

Epoch: 5| Step: 6
Training loss: 1.0756285190582275
Validation loss: 2.228817865252495

Epoch: 5| Step: 7
Training loss: 1.5963366031646729
Validation loss: 2.2146944850683212

Epoch: 5| Step: 8
Training loss: 2.165541887283325
Validation loss: 2.195532277226448

Epoch: 5| Step: 9
Training loss: 1.9274393320083618
Validation loss: 2.1952130496501923

Epoch: 5| Step: 10
Training loss: 1.943711519241333
Validation loss: 2.19336965183417

Epoch: 5| Step: 11
Training loss: 0.6459817886352539
Validation loss: 2.205274060368538

Epoch: 357| Step: 0
Training loss: 1.7123939990997314
Validation loss: 2.2192662407954535

Epoch: 5| Step: 1
Training loss: 1.6477689743041992
Validation loss: 2.225060691436132

Epoch: 5| Step: 2
Training loss: 1.9421287775039673
Validation loss: 2.2424524972836175

Epoch: 5| Step: 3
Training loss: 1.507558822631836
Validation loss: 2.2421097656091056

Epoch: 5| Step: 4
Training loss: 1.5516672134399414
Validation loss: 2.2437211175759635

Epoch: 5| Step: 5
Training loss: 1.3588812351226807
Validation loss: 2.272263596455256

Epoch: 5| Step: 6
Training loss: 2.0186543464660645
Validation loss: 2.2567831377188363

Epoch: 5| Step: 7
Training loss: 1.5284457206726074
Validation loss: 2.2518759866555533

Epoch: 5| Step: 8
Training loss: 1.843340277671814
Validation loss: 2.2750930537780127

Epoch: 5| Step: 9
Training loss: 1.270745873451233
Validation loss: 2.2918553253014884

Epoch: 5| Step: 10
Training loss: 1.26539146900177
Validation loss: 2.3013634781042733

Epoch: 5| Step: 11
Training loss: 0.8717285394668579
Validation loss: 2.2790383398532867

Epoch: 358| Step: 0
Training loss: 1.6528629064559937
Validation loss: 2.2525808811187744

Epoch: 5| Step: 1
Training loss: 1.5464069843292236
Validation loss: 2.275119811296463

Epoch: 5| Step: 2
Training loss: 0.9664714932441711
Validation loss: 2.249120205640793

Epoch: 5| Step: 3
Training loss: 1.6251312494277954
Validation loss: 2.233925978342692

Epoch: 5| Step: 4
Training loss: 1.9376513957977295
Validation loss: 2.227622558673223

Epoch: 5| Step: 5
Training loss: 1.5501978397369385
Validation loss: 2.248336707552274

Epoch: 5| Step: 6
Training loss: 1.707480788230896
Validation loss: 2.2431740363438926

Epoch: 5| Step: 7
Training loss: 2.0356740951538086
Validation loss: 2.2486382921536765

Epoch: 5| Step: 8
Training loss: 1.1589019298553467
Validation loss: 2.249336083730062

Epoch: 5| Step: 9
Training loss: 1.852250099182129
Validation loss: 2.2883502145608268

Epoch: 5| Step: 10
Training loss: 1.3134076595306396
Validation loss: 2.2903981804847717

Epoch: 5| Step: 11
Training loss: 2.2682418823242188
Validation loss: 2.2906536161899567

Epoch: 359| Step: 0
Training loss: 1.7027003765106201
Validation loss: 2.292126625776291

Epoch: 5| Step: 1
Training loss: 1.3719491958618164
Validation loss: 2.2719430724779763

Epoch: 5| Step: 2
Training loss: 1.575873851776123
Validation loss: 2.256422758102417

Epoch: 5| Step: 3
Training loss: 1.3701374530792236
Validation loss: 2.248164117336273

Epoch: 5| Step: 4
Training loss: 1.453421950340271
Validation loss: 2.23969529569149

Epoch: 5| Step: 5
Training loss: 1.904840111732483
Validation loss: 2.2471055388450623

Epoch: 5| Step: 6
Training loss: 0.9899234771728516
Validation loss: 2.240695968270302

Epoch: 5| Step: 7
Training loss: 1.304917812347412
Validation loss: 2.225222498178482

Epoch: 5| Step: 8
Training loss: 1.733999252319336
Validation loss: 2.246091698606809

Epoch: 5| Step: 9
Training loss: 1.4424461126327515
Validation loss: 2.240936502814293

Epoch: 5| Step: 10
Training loss: 1.5969403982162476
Validation loss: 2.252138843139013

Epoch: 5| Step: 11
Training loss: 1.155989646911621
Validation loss: 2.272196119030317

Epoch: 360| Step: 0
Training loss: 2.3379340171813965
Validation loss: 2.232418696085612

Epoch: 5| Step: 1
Training loss: 1.3945947885513306
Validation loss: 2.2401376267274222

Epoch: 5| Step: 2
Training loss: 1.9912607669830322
Validation loss: 2.198951597015063

Epoch: 5| Step: 3
Training loss: 1.4039561748504639
Validation loss: 2.211907813946406

Epoch: 5| Step: 4
Training loss: 1.5252494812011719
Validation loss: 2.224263976017634

Epoch: 5| Step: 5
Training loss: 0.7954079508781433
Validation loss: 2.205956220626831

Epoch: 5| Step: 6
Training loss: 1.1783599853515625
Validation loss: 2.2440228164196014

Epoch: 5| Step: 7
Training loss: 1.036988615989685
Validation loss: 2.2616500159104667

Epoch: 5| Step: 8
Training loss: 1.7496392726898193
Validation loss: 2.2659038305282593

Epoch: 5| Step: 9
Training loss: 1.4854161739349365
Validation loss: 2.2585730155309043

Epoch: 5| Step: 10
Training loss: 1.544692873954773
Validation loss: 2.2580328236023584

Epoch: 5| Step: 11
Training loss: 1.374429702758789
Validation loss: 2.2488940457503

Epoch: 361| Step: 0
Training loss: 1.7439098358154297
Validation loss: 2.228522857030233

Epoch: 5| Step: 1
Training loss: 1.3125629425048828
Validation loss: 2.255126337210337

Epoch: 5| Step: 2
Training loss: 1.1629558801651
Validation loss: 2.226106291015943

Epoch: 5| Step: 3
Training loss: 1.6162484884262085
Validation loss: 2.246484855810801

Epoch: 5| Step: 4
Training loss: 1.41062331199646
Validation loss: 2.235121339559555

Epoch: 5| Step: 5
Training loss: 1.1420618295669556
Validation loss: 2.250207563241323

Epoch: 5| Step: 6
Training loss: 1.5778086185455322
Validation loss: 2.233270933230718

Epoch: 5| Step: 7
Training loss: 1.2089625597000122
Validation loss: 2.229414254426956

Epoch: 5| Step: 8
Training loss: 2.3306450843811035
Validation loss: 2.251825471719106

Epoch: 5| Step: 9
Training loss: 1.4433491230010986
Validation loss: 2.2505459686120353

Epoch: 5| Step: 10
Training loss: 1.6714321374893188
Validation loss: 2.2517276406288147

Epoch: 5| Step: 11
Training loss: 1.2768141031265259
Validation loss: 2.241297274827957

Epoch: 362| Step: 0
Training loss: 1.7730731964111328
Validation loss: 2.2379919588565826

Epoch: 5| Step: 1
Training loss: 1.4899139404296875
Validation loss: 2.2108762115240097

Epoch: 5| Step: 2
Training loss: 1.4755619764328003
Validation loss: 2.2302419145902

Epoch: 5| Step: 3
Training loss: 1.5847070217132568
Validation loss: 2.232677678267161

Epoch: 5| Step: 4
Training loss: 1.568719744682312
Validation loss: 2.2216598292191825

Epoch: 5| Step: 5
Training loss: 1.6880171298980713
Validation loss: 2.1927174627780914

Epoch: 5| Step: 6
Training loss: 1.2516286373138428
Validation loss: 2.22092475493749

Epoch: 5| Step: 7
Training loss: 1.530799388885498
Validation loss: 2.2168944428364434

Epoch: 5| Step: 8
Training loss: 1.683326005935669
Validation loss: 2.2444166789452233

Epoch: 5| Step: 9
Training loss: 1.1889342069625854
Validation loss: 2.2288455963134766

Epoch: 5| Step: 10
Training loss: 1.4974358081817627
Validation loss: 2.217113827665647

Epoch: 5| Step: 11
Training loss: 0.8419449925422668
Validation loss: 2.228618875145912

Epoch: 363| Step: 0
Training loss: 1.7331689596176147
Validation loss: 2.2576744755109153

Epoch: 5| Step: 1
Training loss: 1.82889723777771
Validation loss: 2.2600438743829727

Epoch: 5| Step: 2
Training loss: 1.4386703968048096
Validation loss: 2.2701574017604194

Epoch: 5| Step: 3
Training loss: 1.7549965381622314
Validation loss: 2.2742584447065988

Epoch: 5| Step: 4
Training loss: 1.3490917682647705
Validation loss: 2.281792784730593

Epoch: 5| Step: 5
Training loss: 1.8965415954589844
Validation loss: 2.2900790770848594

Epoch: 5| Step: 6
Training loss: 1.2650963068008423
Validation loss: 2.2758106688658395

Epoch: 5| Step: 7
Training loss: 1.5133156776428223
Validation loss: 2.237570196390152

Epoch: 5| Step: 8
Training loss: 1.6409660577774048
Validation loss: 2.221946661671003

Epoch: 5| Step: 9
Training loss: 1.1140823364257812
Validation loss: 2.2246590852737427

Epoch: 5| Step: 10
Training loss: 1.737203598022461
Validation loss: 2.215149243672689

Epoch: 5| Step: 11
Training loss: 1.0596444606781006
Validation loss: 2.2184214343627295

Epoch: 364| Step: 0
Training loss: 1.1851826906204224
Validation loss: 2.231298645337423

Epoch: 5| Step: 1
Training loss: 1.1873172521591187
Validation loss: 2.2311520874500275

Epoch: 5| Step: 2
Training loss: 1.5179674625396729
Validation loss: 2.2062527537345886

Epoch: 5| Step: 3
Training loss: 2.3678982257843018
Validation loss: 2.203853194912275

Epoch: 5| Step: 4
Training loss: 1.030566930770874
Validation loss: 2.239062716563543

Epoch: 5| Step: 5
Training loss: 1.4639110565185547
Validation loss: 2.2631433506806693

Epoch: 5| Step: 6
Training loss: 1.919074296951294
Validation loss: 2.27917388578256

Epoch: 5| Step: 7
Training loss: 1.4099547863006592
Validation loss: 2.287164037426313

Epoch: 5| Step: 8
Training loss: 1.5830878019332886
Validation loss: 2.2713009119033813

Epoch: 5| Step: 9
Training loss: 1.291595697402954
Validation loss: 2.3212461918592453

Epoch: 5| Step: 10
Training loss: 1.826004981994629
Validation loss: 2.298791085680326

Epoch: 5| Step: 11
Training loss: 1.5839455127716064
Validation loss: 2.294459799925486

Epoch: 365| Step: 0
Training loss: 0.8775548934936523
Validation loss: 2.23802258570989

Epoch: 5| Step: 1
Training loss: 1.4653375148773193
Validation loss: 2.2166395485401154

Epoch: 5| Step: 2
Training loss: 2.104353427886963
Validation loss: 2.243660400311152

Epoch: 5| Step: 3
Training loss: 1.307310938835144
Validation loss: 2.2180070082346597

Epoch: 5| Step: 4
Training loss: 1.409754991531372
Validation loss: 2.208584249019623

Epoch: 5| Step: 5
Training loss: 1.6415493488311768
Validation loss: 2.2186971604824066

Epoch: 5| Step: 6
Training loss: 1.9924535751342773
Validation loss: 2.2060163418451944

Epoch: 5| Step: 7
Training loss: 1.4441710710525513
Validation loss: 2.2072244783242545

Epoch: 5| Step: 8
Training loss: 2.151754856109619
Validation loss: 2.2435548504193625

Epoch: 5| Step: 9
Training loss: 1.0974780321121216
Validation loss: 2.257266571124395

Epoch: 5| Step: 10
Training loss: 1.5287786722183228
Validation loss: 2.2574301064014435

Epoch: 5| Step: 11
Training loss: 1.8181629180908203
Validation loss: 2.279333010315895

Epoch: 366| Step: 0
Training loss: 1.6514323949813843
Validation loss: 2.275873601436615

Epoch: 5| Step: 1
Training loss: 1.8449857234954834
Validation loss: 2.2891418635845184

Epoch: 5| Step: 2
Training loss: 1.3087096214294434
Validation loss: 2.314187784989675

Epoch: 5| Step: 3
Training loss: 1.5277388095855713
Validation loss: 2.285287708044052

Epoch: 5| Step: 4
Training loss: 1.639743447303772
Validation loss: 2.272130459547043

Epoch: 5| Step: 5
Training loss: 1.129169225692749
Validation loss: 2.24760336180528

Epoch: 5| Step: 6
Training loss: 1.470123529434204
Validation loss: 2.2052160501480103

Epoch: 5| Step: 7
Training loss: 1.4991090297698975
Validation loss: 2.2132974763711295

Epoch: 5| Step: 8
Training loss: 1.8449370861053467
Validation loss: 2.2014514108498893

Epoch: 5| Step: 9
Training loss: 1.0663602352142334
Validation loss: 2.191410223642985

Epoch: 5| Step: 10
Training loss: 1.3467944860458374
Validation loss: 2.2163982590039573

Epoch: 5| Step: 11
Training loss: 2.4137840270996094
Validation loss: 2.1994482030471167

Epoch: 367| Step: 0
Training loss: 1.3966065645217896
Validation loss: 2.174417103330294

Epoch: 5| Step: 1
Training loss: 2.6624417304992676
Validation loss: 2.171589175860087

Epoch: 5| Step: 2
Training loss: 1.303789496421814
Validation loss: 2.1587274620930352

Epoch: 5| Step: 3
Training loss: 1.625950574874878
Validation loss: 2.140984982252121

Epoch: 5| Step: 4
Training loss: 1.2962796688079834
Validation loss: 2.1546963651974997

Epoch: 5| Step: 5
Training loss: 1.190464973449707
Validation loss: 2.134335766235987

Epoch: 5| Step: 6
Training loss: 1.1871016025543213
Validation loss: 2.1418709258238473

Epoch: 5| Step: 7
Training loss: 1.4733306169509888
Validation loss: 2.165616442759832

Epoch: 5| Step: 8
Training loss: 1.3163002729415894
Validation loss: 2.2073565224806466

Epoch: 5| Step: 9
Training loss: 1.877650260925293
Validation loss: 2.184322734673818

Epoch: 5| Step: 10
Training loss: 1.6969401836395264
Validation loss: 2.160332282384237

Epoch: 5| Step: 11
Training loss: 0.6646075248718262
Validation loss: 2.21897399922212

Epoch: 368| Step: 0
Training loss: 1.6531215906143188
Validation loss: 2.149951954682668

Epoch: 5| Step: 1
Training loss: 1.0549319982528687
Validation loss: 2.2033790349960327

Epoch: 5| Step: 2
Training loss: 1.6787970066070557
Validation loss: 2.233118270834287

Epoch: 5| Step: 3
Training loss: 1.8852866888046265
Validation loss: 2.234104245901108

Epoch: 5| Step: 4
Training loss: 1.8464857339859009
Validation loss: 2.2431612809499106

Epoch: 5| Step: 5
Training loss: 2.047475814819336
Validation loss: 2.2411712259054184

Epoch: 5| Step: 6
Training loss: 2.0546770095825195
Validation loss: 2.242797762155533

Epoch: 5| Step: 7
Training loss: 1.7297651767730713
Validation loss: 2.233813385168711

Epoch: 5| Step: 8
Training loss: 1.9774792194366455
Validation loss: 2.1959513127803802

Epoch: 5| Step: 9
Training loss: 1.2127985954284668
Validation loss: 2.1771230896313987

Epoch: 5| Step: 10
Training loss: 1.5701448917388916
Validation loss: 2.175552030404409

Epoch: 5| Step: 11
Training loss: 1.3438278436660767
Validation loss: 2.1953150828679404

Epoch: 369| Step: 0
Training loss: 0.9668224453926086
Validation loss: 2.212747568885485

Epoch: 5| Step: 1
Training loss: 1.4941112995147705
Validation loss: 2.218346575895945

Epoch: 5| Step: 2
Training loss: 1.7806717157363892
Validation loss: 2.235030988852183

Epoch: 5| Step: 3
Training loss: 1.4308470487594604
Validation loss: 2.254545365770658

Epoch: 5| Step: 4
Training loss: 1.4532524347305298
Validation loss: 2.302002787590027

Epoch: 5| Step: 5
Training loss: 1.3569539785385132
Validation loss: 2.2734384735425315

Epoch: 5| Step: 6
Training loss: 2.0029258728027344
Validation loss: 2.29738213121891

Epoch: 5| Step: 7
Training loss: 1.1823536157608032
Validation loss: 2.269904966155688

Epoch: 5| Step: 8
Training loss: 1.9641921520233154
Validation loss: 2.23678882420063

Epoch: 5| Step: 9
Training loss: 1.5095713138580322
Validation loss: 2.215828930338224

Epoch: 5| Step: 10
Training loss: 1.20742928981781
Validation loss: 2.1889279236396155

Epoch: 5| Step: 11
Training loss: 2.369985580444336
Validation loss: 2.201614737510681

Epoch: 370| Step: 0
Training loss: 1.338435411453247
Validation loss: 2.249879131714503

Epoch: 5| Step: 1
Training loss: 1.7477613687515259
Validation loss: 2.2053602039813995

Epoch: 5| Step: 2
Training loss: 1.071916937828064
Validation loss: 2.2386139035224915

Epoch: 5| Step: 3
Training loss: 1.2330644130706787
Validation loss: 2.2246495137612023

Epoch: 5| Step: 4
Training loss: 1.5326207876205444
Validation loss: 2.2492688993612924

Epoch: 5| Step: 5
Training loss: 1.4473609924316406
Validation loss: 2.2471209168434143

Epoch: 5| Step: 6
Training loss: 1.6603631973266602
Validation loss: 2.3000436822573342

Epoch: 5| Step: 7
Training loss: 1.9259392023086548
Validation loss: 2.2644918958346048

Epoch: 5| Step: 8
Training loss: 2.179851531982422
Validation loss: 2.2743028650681176

Epoch: 5| Step: 9
Training loss: 1.2031755447387695
Validation loss: 2.2679219841957092

Epoch: 5| Step: 10
Training loss: 1.2175464630126953
Validation loss: 2.249467914303144

Epoch: 5| Step: 11
Training loss: 0.7899205684661865
Validation loss: 2.239604885379473

Epoch: 371| Step: 0
Training loss: 1.422676682472229
Validation loss: 2.2503639856974282

Epoch: 5| Step: 1
Training loss: 1.210739016532898
Validation loss: 2.269191558162371

Epoch: 5| Step: 2
Training loss: 2.182868480682373
Validation loss: 2.2373825858036676

Epoch: 5| Step: 3
Training loss: 1.3021941184997559
Validation loss: 2.2269975741704306

Epoch: 5| Step: 4
Training loss: 1.696141004562378
Validation loss: 2.250072881579399

Epoch: 5| Step: 5
Training loss: 1.2936508655548096
Validation loss: 2.2220720102389655

Epoch: 5| Step: 6
Training loss: 1.2818913459777832
Validation loss: 2.2368756284316382

Epoch: 5| Step: 7
Training loss: 1.352785348892212
Validation loss: 2.2393468767404556

Epoch: 5| Step: 8
Training loss: 1.1242632865905762
Validation loss: 2.2635293006896973

Epoch: 5| Step: 9
Training loss: 1.422219157218933
Validation loss: 2.234412749608358

Epoch: 5| Step: 10
Training loss: 1.5044591426849365
Validation loss: 2.27969100077947

Epoch: 5| Step: 11
Training loss: 1.0306240320205688
Validation loss: 2.3000937898953757

Epoch: 372| Step: 0
Training loss: 1.7199316024780273
Validation loss: 2.2819067488114038

Epoch: 5| Step: 1
Training loss: 1.2571876049041748
Validation loss: 2.3061698327461877

Epoch: 5| Step: 2
Training loss: 1.6382482051849365
Validation loss: 2.3204614023367562

Epoch: 5| Step: 3
Training loss: 1.3110692501068115
Validation loss: 2.307405357559522

Epoch: 5| Step: 4
Training loss: 1.0880038738250732
Validation loss: 2.288410872220993

Epoch: 5| Step: 5
Training loss: 1.2811689376831055
Validation loss: 2.2685180604457855

Epoch: 5| Step: 6
Training loss: 1.6175930500030518
Validation loss: 2.2421356389919915

Epoch: 5| Step: 7
Training loss: 1.0993938446044922
Validation loss: 2.2449352045853934

Epoch: 5| Step: 8
Training loss: 2.5243046283721924
Validation loss: 2.24223060409228

Epoch: 5| Step: 9
Training loss: 1.3240954875946045
Validation loss: 2.2339136799176535

Epoch: 5| Step: 10
Training loss: 1.182908296585083
Validation loss: 2.2354604502518973

Epoch: 5| Step: 11
Training loss: 1.0026116371154785
Validation loss: 2.258627583583196

Epoch: 373| Step: 0
Training loss: 1.2820676565170288
Validation loss: 2.227655773361524

Epoch: 5| Step: 1
Training loss: 1.082079291343689
Validation loss: 2.221673756837845

Epoch: 5| Step: 2
Training loss: 2.292505979537964
Validation loss: 2.265456606944402

Epoch: 5| Step: 3
Training loss: 1.7407439947128296
Validation loss: 2.244700382153193

Epoch: 5| Step: 4
Training loss: 1.3307685852050781
Validation loss: 2.2404212752978006

Epoch: 5| Step: 5
Training loss: 1.1500165462493896
Validation loss: 2.2485880653063455

Epoch: 5| Step: 6
Training loss: 1.5635677576065063
Validation loss: 2.234040379524231

Epoch: 5| Step: 7
Training loss: 1.477099061012268
Validation loss: 2.247120668490728

Epoch: 5| Step: 8
Training loss: 1.3675121068954468
Validation loss: 2.256335069735845

Epoch: 5| Step: 9
Training loss: 1.3884646892547607
Validation loss: 2.2514948894580207

Epoch: 5| Step: 10
Training loss: 1.1185479164123535
Validation loss: 2.2505905628204346

Epoch: 5| Step: 11
Training loss: 1.4304896593093872
Validation loss: 2.267054637273153

Epoch: 374| Step: 0
Training loss: 1.6784908771514893
Validation loss: 2.2806015610694885

Epoch: 5| Step: 1
Training loss: 1.6513621807098389
Validation loss: 2.275222589572271

Epoch: 5| Step: 2
Training loss: 1.2738096714019775
Validation loss: 2.2470159232616425

Epoch: 5| Step: 3
Training loss: 1.00382399559021
Validation loss: 2.2434927423795066

Epoch: 5| Step: 4
Training loss: 0.9660506248474121
Validation loss: 2.2461399088303247

Epoch: 5| Step: 5
Training loss: 2.2019433975219727
Validation loss: 2.246013099948565

Epoch: 5| Step: 6
Training loss: 1.3257966041564941
Validation loss: 2.259089862306913

Epoch: 5| Step: 7
Training loss: 0.9058272242546082
Validation loss: 2.2261140048503876

Epoch: 5| Step: 8
Training loss: 1.7249044179916382
Validation loss: 2.2491433918476105

Epoch: 5| Step: 9
Training loss: 1.3057148456573486
Validation loss: 2.2512042224407196

Epoch: 5| Step: 10
Training loss: 1.4925711154937744
Validation loss: 2.2649699250857034

Epoch: 5| Step: 11
Training loss: 1.9372739791870117
Validation loss: 2.270482450723648

Epoch: 375| Step: 0
Training loss: 1.3054559230804443
Validation loss: 2.344668358564377

Epoch: 5| Step: 1
Training loss: 1.9138542413711548
Validation loss: 2.351946363846461

Epoch: 5| Step: 2
Training loss: 1.4029948711395264
Validation loss: 2.3398007849852243

Epoch: 5| Step: 3
Training loss: 1.6254017353057861
Validation loss: 2.3401829500993094

Epoch: 5| Step: 4
Training loss: 1.7960426807403564
Validation loss: 2.2855500876903534

Epoch: 5| Step: 5
Training loss: 1.6768720149993896
Validation loss: 2.2521932224432626

Epoch: 5| Step: 6
Training loss: 1.351027488708496
Validation loss: 2.280625601609548

Epoch: 5| Step: 7
Training loss: 1.4175381660461426
Validation loss: 2.2459205289681754

Epoch: 5| Step: 8
Training loss: 1.0837081670761108
Validation loss: 2.255127966403961

Epoch: 5| Step: 9
Training loss: 1.4558985233306885
Validation loss: 2.2772985100746155

Epoch: 5| Step: 10
Training loss: 1.651214599609375
Validation loss: 2.2756806313991547

Epoch: 5| Step: 11
Training loss: 0.9843348264694214
Validation loss: 2.2730691333611808

Epoch: 376| Step: 0
Training loss: 1.3663084506988525
Validation loss: 2.258680373430252

Epoch: 5| Step: 1
Training loss: 1.5537233352661133
Validation loss: 2.2628378768761954

Epoch: 5| Step: 2
Training loss: 0.9176254272460938
Validation loss: 2.3166483690341315

Epoch: 5| Step: 3
Training loss: 1.5532156229019165
Validation loss: 2.3652200599511466

Epoch: 5| Step: 4
Training loss: 1.6204169988632202
Validation loss: 2.3551091104745865

Epoch: 5| Step: 5
Training loss: 1.6018621921539307
Validation loss: 2.3354604691267014

Epoch: 5| Step: 6
Training loss: 0.7988278269767761
Validation loss: 2.329476778705915

Epoch: 5| Step: 7
Training loss: 1.5819851160049438
Validation loss: 2.2821608434120813

Epoch: 5| Step: 8
Training loss: 1.070673942565918
Validation loss: 2.239879791935285

Epoch: 5| Step: 9
Training loss: 2.359440326690674
Validation loss: 2.2383307814598083

Epoch: 5| Step: 10
Training loss: 1.9715874195098877
Validation loss: 2.2729734430710473

Epoch: 5| Step: 11
Training loss: 2.4728848934173584
Validation loss: 2.2504251450300217

Epoch: 377| Step: 0
Training loss: 2.366837978363037
Validation loss: 2.242934172352155

Epoch: 5| Step: 1
Training loss: 1.3540194034576416
Validation loss: 2.233227868874868

Epoch: 5| Step: 2
Training loss: 1.1424421072006226
Validation loss: 2.2388819505771003

Epoch: 5| Step: 3
Training loss: 0.9195753335952759
Validation loss: 2.2264628211657205

Epoch: 5| Step: 4
Training loss: 1.7575613260269165
Validation loss: 2.193610375126203

Epoch: 5| Step: 5
Training loss: 1.5036816596984863
Validation loss: 2.2373141845067344

Epoch: 5| Step: 6
Training loss: 1.2773590087890625
Validation loss: 2.245259756843249

Epoch: 5| Step: 7
Training loss: 1.1203012466430664
Validation loss: 2.2490205665429435

Epoch: 5| Step: 8
Training loss: 1.5767439603805542
Validation loss: 2.253501132130623

Epoch: 5| Step: 9
Training loss: 1.8334019184112549
Validation loss: 2.208075707157453

Epoch: 5| Step: 10
Training loss: 1.4610183238983154
Validation loss: 2.2412609606981277

Epoch: 5| Step: 11
Training loss: 2.0891246795654297
Validation loss: 2.2331193139155707

Epoch: 378| Step: 0
Training loss: 1.6799548864364624
Validation loss: 2.2546301732460656

Epoch: 5| Step: 1
Training loss: 1.726056456565857
Validation loss: 2.2516347418228784

Epoch: 5| Step: 2
Training loss: 1.4961187839508057
Validation loss: 2.2756629635890326

Epoch: 5| Step: 3
Training loss: 1.1039148569107056
Validation loss: 2.216523269812266

Epoch: 5| Step: 4
Training loss: 1.1739225387573242
Validation loss: 2.25121533870697

Epoch: 5| Step: 5
Training loss: 1.7776405811309814
Validation loss: 2.2439122994740806

Epoch: 5| Step: 6
Training loss: 1.0141268968582153
Validation loss: 2.2458150883515677

Epoch: 5| Step: 7
Training loss: 1.6148818731307983
Validation loss: 2.2366284132003784

Epoch: 5| Step: 8
Training loss: 1.567252516746521
Validation loss: 2.239745924870173

Epoch: 5| Step: 9
Training loss: 0.9975131750106812
Validation loss: 2.2193290889263153

Epoch: 5| Step: 10
Training loss: 1.1773536205291748
Validation loss: 2.2291682759920755

Epoch: 5| Step: 11
Training loss: 1.2267942428588867
Validation loss: 2.2536939779917398

Epoch: 379| Step: 0
Training loss: 1.1666650772094727
Validation loss: 2.234201669692993

Epoch: 5| Step: 1
Training loss: 1.1685302257537842
Validation loss: 2.2402971188227334

Epoch: 5| Step: 2
Training loss: 1.6515758037567139
Validation loss: 2.2650501181681952

Epoch: 5| Step: 3
Training loss: 1.2730907201766968
Validation loss: 2.274413585662842

Epoch: 5| Step: 4
Training loss: 1.6068718433380127
Validation loss: 2.261474589506785

Epoch: 5| Step: 5
Training loss: 1.6639773845672607
Validation loss: 2.2418185075124106

Epoch: 5| Step: 6
Training loss: 1.515014886856079
Validation loss: 2.260312298933665

Epoch: 5| Step: 7
Training loss: 1.1645803451538086
Validation loss: 2.2826881259679794

Epoch: 5| Step: 8
Training loss: 1.209719181060791
Validation loss: 2.250642200311025

Epoch: 5| Step: 9
Training loss: 1.1520612239837646
Validation loss: 2.2867844700813293

Epoch: 5| Step: 10
Training loss: 1.772804856300354
Validation loss: 2.2569284588098526

Epoch: 5| Step: 11
Training loss: 0.6632887721061707
Validation loss: 2.262647027770678

Epoch: 380| Step: 0
Training loss: 1.2432596683502197
Validation loss: 2.234229306379954

Epoch: 5| Step: 1
Training loss: 1.4506052732467651
Validation loss: 2.2225529650847116

Epoch: 5| Step: 2
Training loss: 1.1049530506134033
Validation loss: 2.220241596301397

Epoch: 5| Step: 3
Training loss: 1.2042948007583618
Validation loss: 2.2128272453943887

Epoch: 5| Step: 4
Training loss: 1.1952617168426514
Validation loss: 2.254788170258204

Epoch: 5| Step: 5
Training loss: 2.149367332458496
Validation loss: 2.2240495632092157

Epoch: 5| Step: 6
Training loss: 1.4235622882843018
Validation loss: 2.2616504629453025

Epoch: 5| Step: 7
Training loss: 1.1564586162567139
Validation loss: 2.2439906150102615

Epoch: 5| Step: 8
Training loss: 1.3372968435287476
Validation loss: 2.233722686767578

Epoch: 5| Step: 9
Training loss: 1.4346624612808228
Validation loss: 2.2645090272029242

Epoch: 5| Step: 10
Training loss: 1.9072622060775757
Validation loss: 2.231221000353495

Epoch: 5| Step: 11
Training loss: 0.3469123840332031
Validation loss: 2.2355926434199014

Epoch: 381| Step: 0
Training loss: 1.4419242143630981
Validation loss: 2.2327168186505637

Epoch: 5| Step: 1
Training loss: 1.5384128093719482
Validation loss: 2.2097949286301932

Epoch: 5| Step: 2
Training loss: 0.743085503578186
Validation loss: 2.240989406903585

Epoch: 5| Step: 3
Training loss: 1.6176507472991943
Validation loss: 2.2303297966718674

Epoch: 5| Step: 4
Training loss: 1.0201947689056396
Validation loss: 2.227656841278076

Epoch: 5| Step: 5
Training loss: 1.5913116931915283
Validation loss: 2.2481047809123993

Epoch: 5| Step: 6
Training loss: 1.107948899269104
Validation loss: 2.2511304865280786

Epoch: 5| Step: 7
Training loss: 1.851082444190979
Validation loss: 2.2483194768428802

Epoch: 5| Step: 8
Training loss: 1.4396874904632568
Validation loss: 2.259489273031553

Epoch: 5| Step: 9
Training loss: 1.08818781375885
Validation loss: 2.274294689297676

Epoch: 5| Step: 10
Training loss: 1.7831881046295166
Validation loss: 2.232750634352366

Epoch: 5| Step: 11
Training loss: 0.7256869673728943
Validation loss: 2.236309766769409

Epoch: 382| Step: 0
Training loss: 2.1548073291778564
Validation loss: 2.264429956674576

Epoch: 5| Step: 1
Training loss: 1.2369613647460938
Validation loss: 2.2623669505119324

Epoch: 5| Step: 2
Training loss: 1.1131255626678467
Validation loss: 2.281135936578115

Epoch: 5| Step: 3
Training loss: 1.4617011547088623
Validation loss: 2.262023458878199

Epoch: 5| Step: 4
Training loss: 1.7597033977508545
Validation loss: 2.2671840488910675

Epoch: 5| Step: 5
Training loss: 0.999367356300354
Validation loss: 2.2514178852240243

Epoch: 5| Step: 6
Training loss: 1.929260492324829
Validation loss: 2.254647046327591

Epoch: 5| Step: 7
Training loss: 1.0861238241195679
Validation loss: 2.2176971087853112

Epoch: 5| Step: 8
Training loss: 1.284540057182312
Validation loss: 2.233990410963694

Epoch: 5| Step: 9
Training loss: 1.136866807937622
Validation loss: 2.2434908350308738

Epoch: 5| Step: 10
Training loss: 1.1642701625823975
Validation loss: 2.2303255796432495

Epoch: 5| Step: 11
Training loss: 0.852107048034668
Validation loss: 2.2514768640200296

Epoch: 383| Step: 0
Training loss: 1.3211610317230225
Validation loss: 2.239068309466044

Epoch: 5| Step: 1
Training loss: 1.2505592107772827
Validation loss: 2.222967882951101

Epoch: 5| Step: 2
Training loss: 1.5445489883422852
Validation loss: 2.245686814188957

Epoch: 5| Step: 3
Training loss: 1.2292227745056152
Validation loss: 2.2089204539855323

Epoch: 5| Step: 4
Training loss: 1.8132312297821045
Validation loss: 2.240530545512835

Epoch: 5| Step: 5
Training loss: 1.4556055068969727
Validation loss: 2.234728510181109

Epoch: 5| Step: 6
Training loss: 1.6786350011825562
Validation loss: 2.2541834662357965

Epoch: 5| Step: 7
Training loss: 1.2164579629898071
Validation loss: 2.218121220668157

Epoch: 5| Step: 8
Training loss: 1.5255372524261475
Validation loss: 2.234316423535347

Epoch: 5| Step: 9
Training loss: 1.0581620931625366
Validation loss: 2.2572203278541565

Epoch: 5| Step: 10
Training loss: 1.424281358718872
Validation loss: 2.2285305658976235

Epoch: 5| Step: 11
Training loss: 1.0098484754562378
Validation loss: 2.231240729490916

Epoch: 384| Step: 0
Training loss: 1.1699984073638916
Validation loss: 2.212257812420527

Epoch: 5| Step: 1
Training loss: 1.5316791534423828
Validation loss: 2.2157927602529526

Epoch: 5| Step: 2
Training loss: 1.0337142944335938
Validation loss: 2.2283953726291656

Epoch: 5| Step: 3
Training loss: 1.7127742767333984
Validation loss: 2.2342114051183066

Epoch: 5| Step: 4
Training loss: 1.890555739402771
Validation loss: 2.2109348674615226

Epoch: 5| Step: 5
Training loss: 1.0529837608337402
Validation loss: 2.187038853764534

Epoch: 5| Step: 6
Training loss: 1.184358835220337
Validation loss: 2.196205665667852

Epoch: 5| Step: 7
Training loss: 1.3877493143081665
Validation loss: 2.2086256245772042

Epoch: 5| Step: 8
Training loss: 1.9406566619873047
Validation loss: 2.1952747901280723

Epoch: 5| Step: 9
Training loss: 1.1393283605575562
Validation loss: 2.207255939642588

Epoch: 5| Step: 10
Training loss: 0.9687101244926453
Validation loss: 2.2457860112190247

Epoch: 5| Step: 11
Training loss: 2.544590473175049
Validation loss: 2.253338118394216

Epoch: 385| Step: 0
Training loss: 1.6703319549560547
Validation loss: 2.2198182543118796

Epoch: 5| Step: 1
Training loss: 1.054487943649292
Validation loss: 2.232398599386215

Epoch: 5| Step: 2
Training loss: 1.343686819076538
Validation loss: 2.2093528707822165

Epoch: 5| Step: 3
Training loss: 0.9481278657913208
Validation loss: 2.2318589041630426

Epoch: 5| Step: 4
Training loss: 1.6457188129425049
Validation loss: 2.2228361467520394

Epoch: 5| Step: 5
Training loss: 1.6726936101913452
Validation loss: 2.2400080462296805

Epoch: 5| Step: 6
Training loss: 1.5596790313720703
Validation loss: 2.2495062251885733

Epoch: 5| Step: 7
Training loss: 1.0424044132232666
Validation loss: 2.250309815009435

Epoch: 5| Step: 8
Training loss: 1.4869658946990967
Validation loss: 2.2553945581118264

Epoch: 5| Step: 9
Training loss: 1.2186057567596436
Validation loss: 2.2640261550744376

Epoch: 5| Step: 10
Training loss: 1.2665818929672241
Validation loss: 2.27125475804011

Epoch: 5| Step: 11
Training loss: 1.4381372928619385
Validation loss: 2.272953152656555

Epoch: 386| Step: 0
Training loss: 0.6706418991088867
Validation loss: 2.2550718188285828

Epoch: 5| Step: 1
Training loss: 0.8093239665031433
Validation loss: 2.2470816373825073

Epoch: 5| Step: 2
Training loss: 1.023557424545288
Validation loss: 2.227954000234604

Epoch: 5| Step: 3
Training loss: 1.3019742965698242
Validation loss: 2.2410985430081687

Epoch: 5| Step: 4
Training loss: 1.2635061740875244
Validation loss: 2.2191516955693564

Epoch: 5| Step: 5
Training loss: 1.0503889322280884
Validation loss: 2.2232908407847085

Epoch: 5| Step: 6
Training loss: 2.3087756633758545
Validation loss: 2.2139230966567993

Epoch: 5| Step: 7
Training loss: 1.3680927753448486
Validation loss: 2.225001633167267

Epoch: 5| Step: 8
Training loss: 1.3098104000091553
Validation loss: 2.2337324172258377

Epoch: 5| Step: 9
Training loss: 2.201585054397583
Validation loss: 2.254513700803121

Epoch: 5| Step: 10
Training loss: 1.692305564880371
Validation loss: 2.257118746638298

Epoch: 5| Step: 11
Training loss: 2.1021127700805664
Validation loss: 2.249435633420944

Epoch: 387| Step: 0
Training loss: 1.1163297891616821
Validation loss: 2.218965137998263

Epoch: 5| Step: 1
Training loss: 1.3429081439971924
Validation loss: 2.2433270514011383

Epoch: 5| Step: 2
Training loss: 1.5188792943954468
Validation loss: 2.248732700943947

Epoch: 5| Step: 3
Training loss: 1.1949348449707031
Validation loss: 2.2404955526192984

Epoch: 5| Step: 4
Training loss: 1.9053024053573608
Validation loss: 2.197652886311213

Epoch: 5| Step: 5
Training loss: 1.2561942338943481
Validation loss: 2.1984960238138833

Epoch: 5| Step: 6
Training loss: 0.9695125818252563
Validation loss: 2.221635783712069

Epoch: 5| Step: 7
Training loss: 2.455232620239258
Validation loss: 2.2167696207761765

Epoch: 5| Step: 8
Training loss: 1.2334777116775513
Validation loss: 2.245516965786616

Epoch: 5| Step: 9
Training loss: 1.3696882724761963
Validation loss: 2.2399601290623345

Epoch: 5| Step: 10
Training loss: 1.807790756225586
Validation loss: 2.281582454840342

Epoch: 5| Step: 11
Training loss: 0.30790674686431885
Validation loss: 2.2135350902875266

Epoch: 388| Step: 0
Training loss: 1.560389757156372
Validation loss: 2.229132910569509

Epoch: 5| Step: 1
Training loss: 1.383826494216919
Validation loss: 2.2449122766653695

Epoch: 5| Step: 2
Training loss: 1.1210460662841797
Validation loss: 2.275056153535843

Epoch: 5| Step: 3
Training loss: 1.0900299549102783
Validation loss: 2.19876421491305

Epoch: 5| Step: 4
Training loss: 0.9969190359115601
Validation loss: 2.221878468990326

Epoch: 5| Step: 5
Training loss: 1.6751539707183838
Validation loss: 2.2205281058947244

Epoch: 5| Step: 6
Training loss: 1.186251163482666
Validation loss: 2.236948549747467

Epoch: 5| Step: 7
Training loss: 1.6272823810577393
Validation loss: 2.2134783069292703

Epoch: 5| Step: 8
Training loss: 0.8579502105712891
Validation loss: 2.183170964320501

Epoch: 5| Step: 9
Training loss: 2.475085973739624
Validation loss: 2.1777972827355065

Epoch: 5| Step: 10
Training loss: 1.108843445777893
Validation loss: 2.1778668661912284

Epoch: 5| Step: 11
Training loss: 1.011646032333374
Validation loss: 2.181338498989741

Epoch: 389| Step: 0
Training loss: 1.642279863357544
Validation loss: 2.182003835837046

Epoch: 5| Step: 1
Training loss: 1.292285680770874
Validation loss: 2.1989451249440513

Epoch: 5| Step: 2
Training loss: 1.7273623943328857
Validation loss: 2.1917781084775925

Epoch: 5| Step: 3
Training loss: 1.1622499227523804
Validation loss: 2.207596853375435

Epoch: 5| Step: 4
Training loss: 1.1204636096954346
Validation loss: 2.177021304766337

Epoch: 5| Step: 5
Training loss: 1.2197271585464478
Validation loss: 2.1975832978884378

Epoch: 5| Step: 6
Training loss: 1.2306007146835327
Validation loss: 2.16616619626681

Epoch: 5| Step: 7
Training loss: 1.5878660678863525
Validation loss: 2.192564696073532

Epoch: 5| Step: 8
Training loss: 1.2409982681274414
Validation loss: 2.248336131374041

Epoch: 5| Step: 9
Training loss: 0.9458918571472168
Validation loss: 2.2596481442451477

Epoch: 5| Step: 10
Training loss: 2.3866164684295654
Validation loss: 2.2826699366172156

Epoch: 5| Step: 11
Training loss: 1.3987064361572266
Validation loss: 2.240884025891622

Epoch: 390| Step: 0
Training loss: 1.3414006233215332
Validation loss: 2.2816895047823587

Epoch: 5| Step: 1
Training loss: 1.4219783544540405
Validation loss: 2.2616002360979715

Epoch: 5| Step: 2
Training loss: 1.3536269664764404
Validation loss: 2.280549496412277

Epoch: 5| Step: 3
Training loss: 1.476845145225525
Validation loss: 2.26907608906428

Epoch: 5| Step: 4
Training loss: 1.3855693340301514
Validation loss: 2.230834717551867

Epoch: 5| Step: 5
Training loss: 1.5847856998443604
Validation loss: 2.251581887404124

Epoch: 5| Step: 6
Training loss: 1.306350588798523
Validation loss: 2.2370169858137765

Epoch: 5| Step: 7
Training loss: 1.4018762111663818
Validation loss: 2.2624999235073724

Epoch: 5| Step: 8
Training loss: 1.06485116481781
Validation loss: 2.262522170941035

Epoch: 5| Step: 9
Training loss: 1.0630496740341187
Validation loss: 2.261860574285189

Epoch: 5| Step: 10
Training loss: 1.8660640716552734
Validation loss: 2.2516311208407083

Epoch: 5| Step: 11
Training loss: 1.015891194343567
Validation loss: 2.287658934791883

Epoch: 391| Step: 0
Training loss: 2.3144657611846924
Validation loss: 2.2672698150078454

Epoch: 5| Step: 1
Training loss: 1.0004990100860596
Validation loss: 2.300112326939901

Epoch: 5| Step: 2
Training loss: 1.3195364475250244
Validation loss: 2.303281416495641

Epoch: 5| Step: 3
Training loss: 1.3389694690704346
Validation loss: 2.250629186630249

Epoch: 5| Step: 4
Training loss: 1.9322044849395752
Validation loss: 2.237521747748057

Epoch: 5| Step: 5
Training loss: 1.099137306213379
Validation loss: 2.1911067167917886

Epoch: 5| Step: 6
Training loss: 0.9459560513496399
Validation loss: 2.163854723175367

Epoch: 5| Step: 7
Training loss: 1.6310116052627563
Validation loss: 2.1447260727485022

Epoch: 5| Step: 8
Training loss: 1.388425588607788
Validation loss: 2.1251693964004517

Epoch: 5| Step: 9
Training loss: 1.8735939264297485
Validation loss: 2.1629390319188437

Epoch: 5| Step: 10
Training loss: 1.2546250820159912
Validation loss: 2.136104866862297

Epoch: 5| Step: 11
Training loss: 0.6945977210998535
Validation loss: 2.159794583916664

Epoch: 392| Step: 0
Training loss: 1.705914855003357
Validation loss: 2.1616102904081345

Epoch: 5| Step: 1
Training loss: 1.7323424816131592
Validation loss: 2.1462088177601495

Epoch: 5| Step: 2
Training loss: 1.363432765007019
Validation loss: 2.142888307571411

Epoch: 5| Step: 3
Training loss: 1.1548486948013306
Validation loss: 2.2497599124908447

Epoch: 5| Step: 4
Training loss: 1.2427669763565063
Validation loss: 2.249048719803492

Epoch: 5| Step: 5
Training loss: 1.6614776849746704
Validation loss: 2.26936141649882

Epoch: 5| Step: 6
Training loss: 1.3680123090744019
Validation loss: 2.273354927698771

Epoch: 5| Step: 7
Training loss: 0.9892465472221375
Validation loss: 2.243192474047343

Epoch: 5| Step: 8
Training loss: 1.4867392778396606
Validation loss: 2.230621720353762

Epoch: 5| Step: 9
Training loss: 1.7725883722305298
Validation loss: 2.185129980246226

Epoch: 5| Step: 10
Training loss: 1.264338493347168
Validation loss: 2.2033809274435043

Epoch: 5| Step: 11
Training loss: 0.754231333732605
Validation loss: 2.220861186583837

Epoch: 393| Step: 0
Training loss: 1.3679676055908203
Validation loss: 2.213153307636579

Epoch: 5| Step: 1
Training loss: 0.7179611325263977
Validation loss: 2.2334321439266205

Epoch: 5| Step: 2
Training loss: 1.394140601158142
Validation loss: 2.2427269170681634

Epoch: 5| Step: 3
Training loss: 1.3636555671691895
Validation loss: 2.200508177280426

Epoch: 5| Step: 4
Training loss: 1.4118192195892334
Validation loss: 2.235423823197683

Epoch: 5| Step: 5
Training loss: 1.0167585611343384
Validation loss: 2.2191370328267417

Epoch: 5| Step: 6
Training loss: 1.6542894840240479
Validation loss: 2.206974431872368

Epoch: 5| Step: 7
Training loss: 1.7313941717147827
Validation loss: 2.2260924577713013

Epoch: 5| Step: 8
Training loss: 1.6815996170043945
Validation loss: 2.237158531943957

Epoch: 5| Step: 9
Training loss: 1.3977471590042114
Validation loss: 2.25324414173762

Epoch: 5| Step: 10
Training loss: 1.07561457157135
Validation loss: 2.320378596584002

Epoch: 5| Step: 11
Training loss: 2.2254796028137207
Validation loss: 2.2832440932591758

Epoch: 394| Step: 0
Training loss: 1.776963233947754
Validation loss: 2.29594878355662

Epoch: 5| Step: 1
Training loss: 1.3812004327774048
Validation loss: 2.2828503449757895

Epoch: 5| Step: 2
Training loss: 1.2173502445220947
Validation loss: 2.3244780749082565

Epoch: 5| Step: 3
Training loss: 1.6960828304290771
Validation loss: 2.267358804742495

Epoch: 5| Step: 4
Training loss: 1.3413053750991821
Validation loss: 2.291494290033976

Epoch: 5| Step: 5
Training loss: 1.4463403224945068
Validation loss: 2.2428601682186127

Epoch: 5| Step: 6
Training loss: 1.3615717887878418
Validation loss: 2.2124974379936853

Epoch: 5| Step: 7
Training loss: 1.3455610275268555
Validation loss: 2.2326302329699197

Epoch: 5| Step: 8
Training loss: 1.4475654363632202
Validation loss: 2.2299479146798453

Epoch: 5| Step: 9
Training loss: 1.588958501815796
Validation loss: 2.2384082674980164

Epoch: 5| Step: 10
Training loss: 0.8888319730758667
Validation loss: 2.255197654167811

Epoch: 5| Step: 11
Training loss: 0.5809797048568726
Validation loss: 2.2276136626799903

Epoch: 395| Step: 0
Training loss: 1.6360962390899658
Validation loss: 2.194559077421824

Epoch: 5| Step: 1
Training loss: 1.6581310033798218
Validation loss: 2.2099021275838218

Epoch: 5| Step: 2
Training loss: 0.9102077484130859
Validation loss: 2.185846914847692

Epoch: 5| Step: 3
Training loss: 1.0233113765716553
Validation loss: 2.170400192340215

Epoch: 5| Step: 4
Training loss: 1.4085652828216553
Validation loss: 2.2181410839160285

Epoch: 5| Step: 5
Training loss: 1.9263222217559814
Validation loss: 2.1875130931536355

Epoch: 5| Step: 6
Training loss: 1.2086538076400757
Validation loss: 2.1858371247847876

Epoch: 5| Step: 7
Training loss: 1.0756460428237915
Validation loss: 2.1842797795931497

Epoch: 5| Step: 8
Training loss: 0.8585955500602722
Validation loss: 2.185885821779569

Epoch: 5| Step: 9
Training loss: 2.209317684173584
Validation loss: 2.233778933684031

Epoch: 5| Step: 10
Training loss: 1.6817493438720703
Validation loss: 2.210668315490087

Epoch: 5| Step: 11
Training loss: 1.5256917476654053
Validation loss: 2.2462432831525803

Epoch: 396| Step: 0
Training loss: 1.1925690174102783
Validation loss: 2.2687378426392875

Epoch: 5| Step: 1
Training loss: 1.4712097644805908
Validation loss: 2.245001291235288

Epoch: 5| Step: 2
Training loss: 1.0796531438827515
Validation loss: 2.213685472806295

Epoch: 5| Step: 3
Training loss: 1.1815170049667358
Validation loss: 2.215623825788498

Epoch: 5| Step: 4
Training loss: 1.2196900844573975
Validation loss: 2.2384109099706015

Epoch: 5| Step: 5
Training loss: 1.5583455562591553
Validation loss: 2.201362897952398

Epoch: 5| Step: 6
Training loss: 0.9963963627815247
Validation loss: 2.250006432334582

Epoch: 5| Step: 7
Training loss: 1.8875234127044678
Validation loss: 2.230541840195656

Epoch: 5| Step: 8
Training loss: 1.7087074518203735
Validation loss: 2.2098872860272727

Epoch: 5| Step: 9
Training loss: 1.3554866313934326
Validation loss: 2.1912004301945367

Epoch: 5| Step: 10
Training loss: 1.2291710376739502
Validation loss: 2.221864382425944

Epoch: 5| Step: 11
Training loss: 0.8048098087310791
Validation loss: 2.244848152001699

Epoch: 397| Step: 0
Training loss: 0.9437864422798157
Validation loss: 2.2355376134316125

Epoch: 5| Step: 1
Training loss: 1.1358213424682617
Validation loss: 2.2378819485505423

Epoch: 5| Step: 2
Training loss: 1.5690383911132812
Validation loss: 2.2049979120492935

Epoch: 5| Step: 3
Training loss: 1.7288795709609985
Validation loss: 2.248924712340037

Epoch: 5| Step: 4
Training loss: 1.393460750579834
Validation loss: 2.1824487845102944

Epoch: 5| Step: 5
Training loss: 1.225493311882019
Validation loss: 2.2208083868026733

Epoch: 5| Step: 6
Training loss: 2.165339946746826
Validation loss: 2.166429797808329

Epoch: 5| Step: 7
Training loss: 1.0080195665359497
Validation loss: 2.185716132322947

Epoch: 5| Step: 8
Training loss: 1.0204722881317139
Validation loss: 2.190473437309265

Epoch: 5| Step: 9
Training loss: 1.1569700241088867
Validation loss: 2.1766744951407113

Epoch: 5| Step: 10
Training loss: 2.02180552482605
Validation loss: 2.1738115549087524

Epoch: 5| Step: 11
Training loss: 1.6188355684280396
Validation loss: 2.1875380923350654

Epoch: 398| Step: 0
Training loss: 1.2546147108078003
Validation loss: 2.2201631466547647

Epoch: 5| Step: 1
Training loss: 1.4315433502197266
Validation loss: 2.21891380349795

Epoch: 5| Step: 2
Training loss: 1.4528906345367432
Validation loss: 2.2151038149992623

Epoch: 5| Step: 3
Training loss: 1.7921510934829712
Validation loss: 2.2478270332018533

Epoch: 5| Step: 4
Training loss: 1.7113078832626343
Validation loss: 2.2860926737387977

Epoch: 5| Step: 5
Training loss: 1.345172643661499
Validation loss: 2.2601439704497657

Epoch: 5| Step: 6
Training loss: 1.0939791202545166
Validation loss: 2.2872122327486673

Epoch: 5| Step: 7
Training loss: 1.546735405921936
Validation loss: 2.2352312356233597

Epoch: 5| Step: 8
Training loss: 1.492967128753662
Validation loss: 2.2439099649588266

Epoch: 5| Step: 9
Training loss: 0.7876027822494507
Validation loss: 2.1890607426563897

Epoch: 5| Step: 10
Training loss: 1.3147224187850952
Validation loss: 2.2037651191155114

Epoch: 5| Step: 11
Training loss: 1.0232222080230713
Validation loss: 2.1925284465154014

Epoch: 399| Step: 0
Training loss: 1.5013682842254639
Validation loss: 2.22888453801473

Epoch: 5| Step: 1
Training loss: 0.9153730273246765
Validation loss: 2.203699916601181

Epoch: 5| Step: 2
Training loss: 1.1222889423370361
Validation loss: 2.212468072772026

Epoch: 5| Step: 3
Training loss: 1.0406649112701416
Validation loss: 2.203863571087519

Epoch: 5| Step: 4
Training loss: 1.6494308710098267
Validation loss: 2.1898306161165237

Epoch: 5| Step: 5
Training loss: 1.1672327518463135
Validation loss: 2.1799111713965735

Epoch: 5| Step: 6
Training loss: 1.4079880714416504
Validation loss: 2.1418462991714478

Epoch: 5| Step: 7
Training loss: 1.530072569847107
Validation loss: 2.187638466556867

Epoch: 5| Step: 8
Training loss: 1.0456066131591797
Validation loss: 2.2271679242451987

Epoch: 5| Step: 9
Training loss: 1.6151187419891357
Validation loss: 2.2109691202640533

Epoch: 5| Step: 10
Training loss: 1.7375093698501587
Validation loss: 2.1835654576619468

Epoch: 5| Step: 11
Training loss: 2.360758066177368
Validation loss: 2.1759328792492547

Epoch: 400| Step: 0
Training loss: 1.4293155670166016
Validation loss: 2.158391982316971

Epoch: 5| Step: 1
Training loss: 1.6676448583602905
Validation loss: 2.2174766957759857

Epoch: 5| Step: 2
Training loss: 1.861261010169983
Validation loss: 2.2263641506433487

Epoch: 5| Step: 3
Training loss: 1.2419860363006592
Validation loss: 2.2176888287067413

Epoch: 5| Step: 4
Training loss: 1.350836992263794
Validation loss: 2.2166334986686707

Epoch: 5| Step: 5
Training loss: 0.8217626810073853
Validation loss: 2.2259245167175927

Epoch: 5| Step: 6
Training loss: 1.9493913650512695
Validation loss: 2.2081305434306464

Epoch: 5| Step: 7
Training loss: 1.1792762279510498
Validation loss: 2.2338058402140937

Epoch: 5| Step: 8
Training loss: 0.723837673664093
Validation loss: 2.2042850206295648

Epoch: 5| Step: 9
Training loss: 0.8096967935562134
Validation loss: 2.2161761075258255

Epoch: 5| Step: 10
Training loss: 1.529165267944336
Validation loss: 2.2126830170551934

Epoch: 5| Step: 11
Training loss: 1.787956714630127
Validation loss: 2.248026887575785

Epoch: 401| Step: 0
Training loss: 1.4914957284927368
Validation loss: 2.2086138278245926

Epoch: 5| Step: 1
Training loss: 1.4394384622573853
Validation loss: 2.194085697333018

Epoch: 5| Step: 2
Training loss: 1.2220507860183716
Validation loss: 2.1625720411539078

Epoch: 5| Step: 3
Training loss: 1.3582381010055542
Validation loss: 2.200648700197538

Epoch: 5| Step: 4
Training loss: 1.0391364097595215
Validation loss: 2.167474389076233

Epoch: 5| Step: 5
Training loss: 1.4162428379058838
Validation loss: 2.1878697176774344

Epoch: 5| Step: 6
Training loss: 1.2674988508224487
Validation loss: 2.2011196662982306

Epoch: 5| Step: 7
Training loss: 1.8848419189453125
Validation loss: 2.2248321572939553

Epoch: 5| Step: 8
Training loss: 0.995591938495636
Validation loss: 2.2651735991239548

Epoch: 5| Step: 9
Training loss: 1.5481704473495483
Validation loss: 2.2452889581521354

Epoch: 5| Step: 10
Training loss: 1.3982408046722412
Validation loss: 2.264699622988701

Epoch: 5| Step: 11
Training loss: 0.9853265285491943
Validation loss: 2.2482347985108695

Epoch: 402| Step: 0
Training loss: 1.094685435295105
Validation loss: 2.207206795612971

Epoch: 5| Step: 1
Training loss: 1.6567986011505127
Validation loss: 2.193719963232676

Epoch: 5| Step: 2
Training loss: 1.4173204898834229
Validation loss: 2.230072240034739

Epoch: 5| Step: 3
Training loss: 1.341059923171997
Validation loss: 2.2337995221217475

Epoch: 5| Step: 4
Training loss: 1.6350666284561157
Validation loss: 2.236175308624903

Epoch: 5| Step: 5
Training loss: 1.5702141523361206
Validation loss: 2.2321377247571945

Epoch: 5| Step: 6
Training loss: 1.7962846755981445
Validation loss: 2.20977775255839

Epoch: 5| Step: 7
Training loss: 1.7943115234375
Validation loss: 2.1969858407974243

Epoch: 5| Step: 8
Training loss: 0.9477838277816772
Validation loss: 2.201344112555186

Epoch: 5| Step: 9
Training loss: 1.7518657445907593
Validation loss: 2.212019423643748

Epoch: 5| Step: 10
Training loss: 1.1588656902313232
Validation loss: 2.244711627562841

Epoch: 5| Step: 11
Training loss: 2.3852481842041016
Validation loss: 2.2335414240757623

Epoch: 403| Step: 0
Training loss: 1.7437703609466553
Validation loss: 2.241511195898056

Epoch: 5| Step: 1
Training loss: 1.1705961227416992
Validation loss: 2.2365988244613013

Epoch: 5| Step: 2
Training loss: 1.2876341342926025
Validation loss: 2.272039830684662

Epoch: 5| Step: 3
Training loss: 1.6747817993164062
Validation loss: 2.2593606263399124

Epoch: 5| Step: 4
Training loss: 1.1774910688400269
Validation loss: 2.248053024212519

Epoch: 5| Step: 5
Training loss: 1.7230215072631836
Validation loss: 2.2137372891108194

Epoch: 5| Step: 6
Training loss: 1.7584717273712158
Validation loss: 2.2118266075849533

Epoch: 5| Step: 7
Training loss: 1.1308636665344238
Validation loss: 2.2087435324986777

Epoch: 5| Step: 8
Training loss: 1.5174428224563599
Validation loss: 2.234519198536873

Epoch: 5| Step: 9
Training loss: 0.8575685620307922
Validation loss: 2.238733778397242

Epoch: 5| Step: 10
Training loss: 1.1154727935791016
Validation loss: 2.2103177507718406

Epoch: 5| Step: 11
Training loss: 2.751487970352173
Validation loss: 2.2197874039411545

Epoch: 404| Step: 0
Training loss: 2.0386803150177
Validation loss: 2.227723558743795

Epoch: 5| Step: 1
Training loss: 1.0504934787750244
Validation loss: 2.182586262623469

Epoch: 5| Step: 2
Training loss: 1.1241984367370605
Validation loss: 2.162077695131302

Epoch: 5| Step: 3
Training loss: 1.8118135929107666
Validation loss: 2.1585480173428855

Epoch: 5| Step: 4
Training loss: 1.3283628225326538
Validation loss: 2.153725783030192

Epoch: 5| Step: 5
Training loss: 1.9010818004608154
Validation loss: 2.1570677210887275

Epoch: 5| Step: 6
Training loss: 1.5783309936523438
Validation loss: 2.144722749789556

Epoch: 5| Step: 7
Training loss: 1.3270905017852783
Validation loss: 2.1583605209986367

Epoch: 5| Step: 8
Training loss: 1.2217578887939453
Validation loss: 2.132281541824341

Epoch: 5| Step: 9
Training loss: 1.1991604566574097
Validation loss: 2.151124601562818

Epoch: 5| Step: 10
Training loss: 1.1064205169677734
Validation loss: 2.1266406079133353

Epoch: 5| Step: 11
Training loss: 0.4594731330871582
Validation loss: 2.127934545278549

Epoch: 405| Step: 0
Training loss: 1.531564474105835
Validation loss: 2.1558421701192856

Epoch: 5| Step: 1
Training loss: 1.9389584064483643
Validation loss: 2.180699641505877

Epoch: 5| Step: 2
Training loss: 1.5052578449249268
Validation loss: 2.168350179990133

Epoch: 5| Step: 3
Training loss: 1.4578241109848022
Validation loss: 2.1687636276086173

Epoch: 5| Step: 4
Training loss: 1.0752589702606201
Validation loss: 2.181974266966184

Epoch: 5| Step: 5
Training loss: 1.345308542251587
Validation loss: 2.179601510365804

Epoch: 5| Step: 6
Training loss: 1.3788013458251953
Validation loss: 2.2013907382885614

Epoch: 5| Step: 7
Training loss: 1.023593783378601
Validation loss: 2.1675153225660324

Epoch: 5| Step: 8
Training loss: 0.6963309645652771
Validation loss: 2.1795769234498343

Epoch: 5| Step: 9
Training loss: 1.7446458339691162
Validation loss: 2.2442713578542075

Epoch: 5| Step: 10
Training loss: 1.2462489604949951
Validation loss: 2.2656357089678445

Epoch: 5| Step: 11
Training loss: 1.4457242488861084
Validation loss: 2.2578760782877603

Epoch: 406| Step: 0
Training loss: 1.7184633016586304
Validation loss: 2.2209586997826896

Epoch: 5| Step: 1
Training loss: 1.4786468744277954
Validation loss: 2.1769636968771615

Epoch: 5| Step: 2
Training loss: 1.9032046794891357
Validation loss: 2.164765308300654

Epoch: 5| Step: 3
Training loss: 1.5156618356704712
Validation loss: 2.180266246199608

Epoch: 5| Step: 4
Training loss: 1.4151904582977295
Validation loss: 2.117086246609688

Epoch: 5| Step: 5
Training loss: 1.2747598886489868
Validation loss: 2.1226864655812583

Epoch: 5| Step: 6
Training loss: 1.167348861694336
Validation loss: 2.1307847698529563

Epoch: 5| Step: 7
Training loss: 0.8687265515327454
Validation loss: 2.1181275844573975

Epoch: 5| Step: 8
Training loss: 0.7571966052055359
Validation loss: 2.14140177766482

Epoch: 5| Step: 9
Training loss: 1.10719895362854
Validation loss: 2.13981556892395

Epoch: 5| Step: 10
Training loss: 1.2072253227233887
Validation loss: 2.1570592323939004

Epoch: 5| Step: 11
Training loss: 1.7074989080429077
Validation loss: 2.1760893364747367

Epoch: 407| Step: 0
Training loss: 1.5253204107284546
Validation loss: 2.1945422490437827

Epoch: 5| Step: 1
Training loss: 1.5747562646865845
Validation loss: 2.2150220523277917

Epoch: 5| Step: 2
Training loss: 1.127648949623108
Validation loss: 2.237348973751068

Epoch: 5| Step: 3
Training loss: 1.1471315622329712
Validation loss: 2.2504635055859885

Epoch: 5| Step: 4
Training loss: 1.2962543964385986
Validation loss: 2.22512678305308

Epoch: 5| Step: 5
Training loss: 1.15681791305542
Validation loss: 2.216033195455869

Epoch: 5| Step: 6
Training loss: 1.3194527626037598
Validation loss: 2.274322897195816

Epoch: 5| Step: 7
Training loss: 1.5326017141342163
Validation loss: 2.2658592760562897

Epoch: 5| Step: 8
Training loss: 1.2782119512557983
Validation loss: 2.305519382158915

Epoch: 5| Step: 9
Training loss: 1.1140018701553345
Validation loss: 2.299700826406479

Epoch: 5| Step: 10
Training loss: 1.812379240989685
Validation loss: 2.3305011490980783

Epoch: 5| Step: 11
Training loss: 3.552011728286743
Validation loss: 2.3024293581644693

Epoch: 408| Step: 0
Training loss: 1.1034247875213623
Validation loss: 2.3028981188933053

Epoch: 5| Step: 1
Training loss: 1.5039739608764648
Validation loss: 2.299799164136251

Epoch: 5| Step: 2
Training loss: 1.6862558126449585
Validation loss: 2.243188406030337

Epoch: 5| Step: 3
Training loss: 1.1963926553726196
Validation loss: 2.2439667781194053

Epoch: 5| Step: 4
Training loss: 1.4055505990982056
Validation loss: 2.2347915520270667

Epoch: 5| Step: 5
Training loss: 1.5589689016342163
Validation loss: 2.2349143822987876

Epoch: 5| Step: 6
Training loss: 1.0269702672958374
Validation loss: 2.248931363224983

Epoch: 5| Step: 7
Training loss: 1.2850780487060547
Validation loss: 2.230269884069761

Epoch: 5| Step: 8
Training loss: 1.2131779193878174
Validation loss: 2.23312375942866

Epoch: 5| Step: 9
Training loss: 1.2039871215820312
Validation loss: 2.240659713745117

Epoch: 5| Step: 10
Training loss: 1.5303618907928467
Validation loss: 2.2322949717442193

Epoch: 5| Step: 11
Training loss: 0.4733541011810303
Validation loss: 2.2681694477796555

Epoch: 409| Step: 0
Training loss: 1.5800431966781616
Validation loss: 2.2668973406155906

Epoch: 5| Step: 1
Training loss: 0.9231616258621216
Validation loss: 2.312475244204203

Epoch: 5| Step: 2
Training loss: 1.1950870752334595
Validation loss: 2.3351351569096246

Epoch: 5| Step: 3
Training loss: 1.5473860502243042
Validation loss: 2.2857381204764047

Epoch: 5| Step: 4
Training loss: 0.9360033869743347
Validation loss: 2.25610243777434

Epoch: 5| Step: 5
Training loss: 1.0016028881072998
Validation loss: 2.2486173709233603

Epoch: 5| Step: 6
Training loss: 1.5996078252792358
Validation loss: 2.23629621664683

Epoch: 5| Step: 7
Training loss: 1.280077576637268
Validation loss: 2.2082842687765756

Epoch: 5| Step: 8
Training loss: 1.1269378662109375
Validation loss: 2.239240055282911

Epoch: 5| Step: 9
Training loss: 1.3520842790603638
Validation loss: 2.2413067122300467

Epoch: 5| Step: 10
Training loss: 1.7581474781036377
Validation loss: 2.2539628396431604

Epoch: 5| Step: 11
Training loss: 2.483704090118408
Validation loss: 2.2308203279972076

Epoch: 410| Step: 0
Training loss: 1.2433427572250366
Validation loss: 2.274265463153521

Epoch: 5| Step: 1
Training loss: 1.736112356185913
Validation loss: 2.2679090748230615

Epoch: 5| Step: 2
Training loss: 1.2519824504852295
Validation loss: 2.2367748419443765

Epoch: 5| Step: 3
Training loss: 1.232407808303833
Validation loss: 2.2320057352383933

Epoch: 5| Step: 4
Training loss: 1.9140819311141968
Validation loss: 2.2519859870274863

Epoch: 5| Step: 5
Training loss: 0.6385753750801086
Validation loss: 2.227575267354647

Epoch: 5| Step: 6
Training loss: 1.294266939163208
Validation loss: 2.212701936562856

Epoch: 5| Step: 7
Training loss: 1.1364576816558838
Validation loss: 2.231112003326416

Epoch: 5| Step: 8
Training loss: 1.282800316810608
Validation loss: 2.2187163680791855

Epoch: 5| Step: 9
Training loss: 1.8945930004119873
Validation loss: 2.2393147895733514

Epoch: 5| Step: 10
Training loss: 1.328439474105835
Validation loss: 2.225628654162089

Epoch: 5| Step: 11
Training loss: 2.4687538146972656
Validation loss: 2.215493639310201

Epoch: 411| Step: 0
Training loss: 1.604758858680725
Validation loss: 2.231056183576584

Epoch: 5| Step: 1
Training loss: 1.068083643913269
Validation loss: 2.2210028370221457

Epoch: 5| Step: 2
Training loss: 1.0630418062210083
Validation loss: 2.168498049179713

Epoch: 5| Step: 3
Training loss: 1.8097963333129883
Validation loss: 2.2234898060560226

Epoch: 5| Step: 4
Training loss: 0.890046238899231
Validation loss: 2.1749372829993567

Epoch: 5| Step: 5
Training loss: 1.2292691469192505
Validation loss: 2.207247942686081

Epoch: 5| Step: 6
Training loss: 1.1753523349761963
Validation loss: 2.202273885409037

Epoch: 5| Step: 7
Training loss: 1.5034795999526978
Validation loss: 2.193410187959671

Epoch: 5| Step: 8
Training loss: 1.539196252822876
Validation loss: 2.1894539097944894

Epoch: 5| Step: 9
Training loss: 1.0370075702667236
Validation loss: 2.2075205544630685

Epoch: 5| Step: 10
Training loss: 1.1211390495300293
Validation loss: 2.192529574036598

Epoch: 5| Step: 11
Training loss: 2.3252925872802734
Validation loss: 2.183070013920466

Epoch: 412| Step: 0
Training loss: 1.2878990173339844
Validation loss: 2.187668025493622

Epoch: 5| Step: 1
Training loss: 0.7373435497283936
Validation loss: 2.1899811973174415

Epoch: 5| Step: 2
Training loss: 2.012990951538086
Validation loss: 2.2040987759828568

Epoch: 5| Step: 3
Training loss: 1.7076022624969482
Validation loss: 2.2243558963139853

Epoch: 5| Step: 4
Training loss: 0.9469305276870728
Validation loss: 2.267918442686399

Epoch: 5| Step: 5
Training loss: 1.2220261096954346
Validation loss: 2.2167575508356094

Epoch: 5| Step: 6
Training loss: 1.2235143184661865
Validation loss: 2.2195064624150596

Epoch: 5| Step: 7
Training loss: 1.2628329992294312
Validation loss: 2.233719219764074

Epoch: 5| Step: 8
Training loss: 1.2137629985809326
Validation loss: 2.2268744905789695

Epoch: 5| Step: 9
Training loss: 1.0843346118927002
Validation loss: 2.214949061473211

Epoch: 5| Step: 10
Training loss: 1.208945870399475
Validation loss: 2.190254588921865

Epoch: 5| Step: 11
Training loss: 1.1977969408035278
Validation loss: 2.2062582721312842

Epoch: 413| Step: 0
Training loss: 0.9632309079170227
Validation loss: 2.2183935840924582

Epoch: 5| Step: 1
Training loss: 1.1871477365493774
Validation loss: 2.2211648722489676

Epoch: 5| Step: 2
Training loss: 1.6031463146209717
Validation loss: 2.228557139635086

Epoch: 5| Step: 3
Training loss: 1.5389972925186157
Validation loss: 2.190238098303477

Epoch: 5| Step: 4
Training loss: 0.9592543840408325
Validation loss: 2.2135538856188455

Epoch: 5| Step: 5
Training loss: 1.1175193786621094
Validation loss: 2.1706295708815255

Epoch: 5| Step: 6
Training loss: 1.1495413780212402
Validation loss: 2.1521562536557517

Epoch: 5| Step: 7
Training loss: 1.997396469116211
Validation loss: 2.163961797952652

Epoch: 5| Step: 8
Training loss: 1.8557466268539429
Validation loss: 2.179130896925926

Epoch: 5| Step: 9
Training loss: 1.0585839748382568
Validation loss: 2.155912001927694

Epoch: 5| Step: 10
Training loss: 0.912884533405304
Validation loss: 2.223986640572548

Epoch: 5| Step: 11
Training loss: 0.6246774196624756
Validation loss: 2.1838841090599694

Epoch: 414| Step: 0
Training loss: 1.7740373611450195
Validation loss: 2.21015435953935

Epoch: 5| Step: 1
Training loss: 0.9176977276802063
Validation loss: 2.243613282839457

Epoch: 5| Step: 2
Training loss: 1.4185426235198975
Validation loss: 2.1938686023155847

Epoch: 5| Step: 3
Training loss: 1.225182056427002
Validation loss: 2.234999711314837

Epoch: 5| Step: 4
Training loss: 0.6784945726394653
Validation loss: 2.23120841383934

Epoch: 5| Step: 5
Training loss: 1.3217155933380127
Validation loss: 2.1897660990556083

Epoch: 5| Step: 6
Training loss: 1.2190560102462769
Validation loss: 2.177202671766281

Epoch: 5| Step: 7
Training loss: 1.6198232173919678
Validation loss: 2.1575930217901864

Epoch: 5| Step: 8
Training loss: 1.2427045106887817
Validation loss: 2.164307643969854

Epoch: 5| Step: 9
Training loss: 1.3580166101455688
Validation loss: 2.186934972802798

Epoch: 5| Step: 10
Training loss: 1.431145429611206
Validation loss: 2.205652376015981

Epoch: 5| Step: 11
Training loss: 2.0231857299804688
Validation loss: 2.183326984445254

Epoch: 415| Step: 0
Training loss: 1.433182954788208
Validation loss: 2.1947788447141647

Epoch: 5| Step: 1
Training loss: 1.0175106525421143
Validation loss: 2.200985307494799

Epoch: 5| Step: 2
Training loss: 1.6356351375579834
Validation loss: 2.2130436847607293

Epoch: 5| Step: 3
Training loss: 1.1831488609313965
Validation loss: 2.248803357283274

Epoch: 5| Step: 4
Training loss: 1.1658170223236084
Validation loss: 2.2448206692934036

Epoch: 5| Step: 5
Training loss: 1.1441407203674316
Validation loss: 2.2331091860930123

Epoch: 5| Step: 6
Training loss: 1.0398056507110596
Validation loss: 2.2498110135396323

Epoch: 5| Step: 7
Training loss: 1.5416195392608643
Validation loss: 2.240016599496206

Epoch: 5| Step: 8
Training loss: 1.757236123085022
Validation loss: 2.2056296467781067

Epoch: 5| Step: 9
Training loss: 1.1345221996307373
Validation loss: 2.1669771124919257

Epoch: 5| Step: 10
Training loss: 1.1493589878082275
Validation loss: 2.165033757686615

Epoch: 5| Step: 11
Training loss: 1.239184856414795
Validation loss: 2.184283211827278

Epoch: 416| Step: 0
Training loss: 1.2319000959396362
Validation loss: 2.204108402132988

Epoch: 5| Step: 1
Training loss: 1.0672218799591064
Validation loss: 2.1914968291918435

Epoch: 5| Step: 2
Training loss: 1.5403457880020142
Validation loss: 2.16370681921641

Epoch: 5| Step: 3
Training loss: 1.8586078882217407
Validation loss: 2.174407497048378

Epoch: 5| Step: 4
Training loss: 1.9713175296783447
Validation loss: 2.165459548433622

Epoch: 5| Step: 5
Training loss: 0.9046674966812134
Validation loss: 2.1785123447577157

Epoch: 5| Step: 6
Training loss: 1.3351246118545532
Validation loss: 2.1684285004933677

Epoch: 5| Step: 7
Training loss: 1.4792680740356445
Validation loss: 2.1985908647378287

Epoch: 5| Step: 8
Training loss: 0.915337085723877
Validation loss: 2.2028963565826416

Epoch: 5| Step: 9
Training loss: 0.9462677836418152
Validation loss: 2.2204701801141105

Epoch: 5| Step: 10
Training loss: 1.2252171039581299
Validation loss: 2.209047794342041

Epoch: 5| Step: 11
Training loss: 0.6419630646705627
Validation loss: 2.2181294759114585

Epoch: 417| Step: 0
Training loss: 1.344232201576233
Validation loss: 2.153207669655482

Epoch: 5| Step: 1
Training loss: 0.867242693901062
Validation loss: 2.1870946486790976

Epoch: 5| Step: 2
Training loss: 1.5496912002563477
Validation loss: 2.1935006827116013

Epoch: 5| Step: 3
Training loss: 0.8851029276847839
Validation loss: 2.21284511188666

Epoch: 5| Step: 4
Training loss: 1.2031660079956055
Validation loss: 2.1880970398585

Epoch: 5| Step: 5
Training loss: 1.220013976097107
Validation loss: 2.199462736646334

Epoch: 5| Step: 6
Training loss: 1.4559701681137085
Validation loss: 2.2079519828160605

Epoch: 5| Step: 7
Training loss: 1.1987978219985962
Validation loss: 2.2102979024251304

Epoch: 5| Step: 8
Training loss: 1.212777853012085
Validation loss: 2.2044380207856498

Epoch: 5| Step: 9
Training loss: 2.1540775299072266
Validation loss: 2.223523477713267

Epoch: 5| Step: 10
Training loss: 1.146472692489624
Validation loss: 2.175561601916949

Epoch: 5| Step: 11
Training loss: 0.4411720335483551
Validation loss: 2.187383328874906

Epoch: 418| Step: 0
Training loss: 1.138123869895935
Validation loss: 2.2168770283460617

Epoch: 5| Step: 1
Training loss: 1.6504106521606445
Validation loss: 2.2067701121171317

Epoch: 5| Step: 2
Training loss: 1.826171875
Validation loss: 2.2358162303765616

Epoch: 5| Step: 3
Training loss: 0.8405383825302124
Validation loss: 2.2112604478995004

Epoch: 5| Step: 4
Training loss: 1.2665317058563232
Validation loss: 2.1784700949986777

Epoch: 5| Step: 5
Training loss: 1.1269009113311768
Validation loss: 2.1933711965878806

Epoch: 5| Step: 6
Training loss: 1.3331167697906494
Validation loss: 2.159647578994433

Epoch: 5| Step: 7
Training loss: 1.0950877666473389
Validation loss: 2.1706401457389197

Epoch: 5| Step: 8
Training loss: 0.7059398889541626
Validation loss: 2.1391471723715463

Epoch: 5| Step: 9
Training loss: 1.0163891315460205
Validation loss: 2.144105409582456

Epoch: 5| Step: 10
Training loss: 1.3183226585388184
Validation loss: 2.143062859773636

Epoch: 5| Step: 11
Training loss: 4.019131660461426
Validation loss: 2.129089504480362

Epoch: 419| Step: 0
Training loss: 1.2748849391937256
Validation loss: 2.1641629884640374

Epoch: 5| Step: 1
Training loss: 0.8545137643814087
Validation loss: 2.148861621816953

Epoch: 5| Step: 2
Training loss: 1.0454822778701782
Validation loss: 2.15369447072347

Epoch: 5| Step: 3
Training loss: 0.9428995251655579
Validation loss: 2.15874678393205

Epoch: 5| Step: 4
Training loss: 1.4188711643218994
Validation loss: 2.1772690812746682

Epoch: 5| Step: 5
Training loss: 1.40913987159729
Validation loss: 2.2137965311606727

Epoch: 5| Step: 6
Training loss: 1.6211954355239868
Validation loss: 2.1802837451299033

Epoch: 5| Step: 7
Training loss: 1.7632777690887451
Validation loss: 2.2623444199562073

Epoch: 5| Step: 8
Training loss: 1.0365664958953857
Validation loss: 2.2369409799575806

Epoch: 5| Step: 9
Training loss: 1.1951093673706055
Validation loss: 2.1930662939945855

Epoch: 5| Step: 10
Training loss: 1.4123014211654663
Validation loss: 2.216668595870336

Epoch: 5| Step: 11
Training loss: 0.33657899498939514
Validation loss: 2.180504853526751

Epoch: 420| Step: 0
Training loss: 1.4705485105514526
Validation loss: 2.175322170058886

Epoch: 5| Step: 1
Training loss: 0.8947871327400208
Validation loss: 2.1516799132029214

Epoch: 5| Step: 2
Training loss: 0.9589710235595703
Validation loss: 2.188630223274231

Epoch: 5| Step: 3
Training loss: 1.4059041738510132
Validation loss: 2.195249781012535

Epoch: 5| Step: 4
Training loss: 0.936098575592041
Validation loss: 2.174103026588758

Epoch: 5| Step: 5
Training loss: 1.154998540878296
Validation loss: 2.1908437261978784

Epoch: 5| Step: 6
Training loss: 1.103729486465454
Validation loss: 2.20155431330204

Epoch: 5| Step: 7
Training loss: 1.0264437198638916
Validation loss: 2.1988427539666495

Epoch: 5| Step: 8
Training loss: 1.6773650646209717
Validation loss: 2.2041240632534027

Epoch: 5| Step: 9
Training loss: 1.7993724346160889
Validation loss: 2.1876685420672097

Epoch: 5| Step: 10
Training loss: 1.239896535873413
Validation loss: 2.2321506092945733

Epoch: 5| Step: 11
Training loss: 0.558617115020752
Validation loss: 2.1887192726135254

Epoch: 421| Step: 0
Training loss: 0.8728033304214478
Validation loss: 2.192287335793177

Epoch: 5| Step: 1
Training loss: 1.2963447570800781
Validation loss: 2.223295032978058

Epoch: 5| Step: 2
Training loss: 0.7207282185554504
Validation loss: 2.189771960179011

Epoch: 5| Step: 3
Training loss: 1.311983585357666
Validation loss: 2.1681900123755136

Epoch: 5| Step: 4
Training loss: 1.9242544174194336
Validation loss: 2.2012815475463867

Epoch: 5| Step: 5
Training loss: 1.1061451435089111
Validation loss: 2.2196239034334817

Epoch: 5| Step: 6
Training loss: 1.5687692165374756
Validation loss: 2.1794013430674872

Epoch: 5| Step: 7
Training loss: 1.7379486560821533
Validation loss: 2.179945026834806

Epoch: 5| Step: 8
Training loss: 0.5956429243087769
Validation loss: 2.1573493778705597

Epoch: 5| Step: 9
Training loss: 1.0864155292510986
Validation loss: 2.15564227104187

Epoch: 5| Step: 10
Training loss: 1.1667224168777466
Validation loss: 2.1861568242311478

Epoch: 5| Step: 11
Training loss: 1.8723375797271729
Validation loss: 2.1713812251885733

Epoch: 422| Step: 0
Training loss: 1.660491704940796
Validation loss: 2.140562598903974

Epoch: 5| Step: 1
Training loss: 1.2077182531356812
Validation loss: 2.1586756507555642

Epoch: 5| Step: 2
Training loss: 1.3549880981445312
Validation loss: 2.1350916226704917

Epoch: 5| Step: 3
Training loss: 0.9852764010429382
Validation loss: 2.164403408765793

Epoch: 5| Step: 4
Training loss: 1.0501823425292969
Validation loss: 2.1434192756811776

Epoch: 5| Step: 5
Training loss: 1.2094907760620117
Validation loss: 2.1995582282543182

Epoch: 5| Step: 6
Training loss: 1.1191380023956299
Validation loss: 2.1564796368281045

Epoch: 5| Step: 7
Training loss: 0.824750542640686
Validation loss: 2.135840058326721

Epoch: 5| Step: 8
Training loss: 1.5162121057510376
Validation loss: 2.1471340407927832

Epoch: 5| Step: 9
Training loss: 1.7309560775756836
Validation loss: 2.1810574581225715

Epoch: 5| Step: 10
Training loss: 0.9162716865539551
Validation loss: 2.1556486785411835

Epoch: 5| Step: 11
Training loss: 1.706822156906128
Validation loss: 2.236512919267019

Epoch: 423| Step: 0
Training loss: 1.272640585899353
Validation loss: 2.2118742913007736

Epoch: 5| Step: 1
Training loss: 0.9052807092666626
Validation loss: 2.2363088528315225

Epoch: 5| Step: 2
Training loss: 0.787577748298645
Validation loss: 2.1989305317401886

Epoch: 5| Step: 3
Training loss: 1.880040168762207
Validation loss: 2.2120986680189767

Epoch: 5| Step: 4
Training loss: 1.13381826877594
Validation loss: 2.2394654353459678

Epoch: 5| Step: 5
Training loss: 1.2413785457611084
Validation loss: 2.231034278869629

Epoch: 5| Step: 6
Training loss: 1.58060622215271
Validation loss: 2.2697922438383102

Epoch: 5| Step: 7
Training loss: 1.2989102602005005
Validation loss: 2.2507544457912445

Epoch: 5| Step: 8
Training loss: 1.6221004724502563
Validation loss: 2.25540063281854

Epoch: 5| Step: 9
Training loss: 1.3071810007095337
Validation loss: 2.240878234306971

Epoch: 5| Step: 10
Training loss: 1.0959386825561523
Validation loss: 2.2500215272108712

Epoch: 5| Step: 11
Training loss: 0.8454433083534241
Validation loss: 2.2908833622932434

Epoch: 424| Step: 0
Training loss: 0.9942376017570496
Validation loss: 2.2841101388136544

Epoch: 5| Step: 1
Training loss: 1.340280294418335
Validation loss: 2.2671240468819938

Epoch: 5| Step: 2
Training loss: 1.358057975769043
Validation loss: 2.3023028622070947

Epoch: 5| Step: 3
Training loss: 1.432268738746643
Validation loss: 2.258227527141571

Epoch: 5| Step: 4
Training loss: 1.7851192951202393
Validation loss: 2.219460278749466

Epoch: 5| Step: 5
Training loss: 1.1859123706817627
Validation loss: 2.2033236622810364

Epoch: 5| Step: 6
Training loss: 1.4372539520263672
Validation loss: 2.1843750327825546

Epoch: 5| Step: 7
Training loss: 1.2764447927474976
Validation loss: 2.2410520811875663

Epoch: 5| Step: 8
Training loss: 1.3441736698150635
Validation loss: 2.2660929014285407

Epoch: 5| Step: 9
Training loss: 1.9252277612686157
Validation loss: 2.275761937101682

Epoch: 5| Step: 10
Training loss: 1.7357542514801025
Validation loss: 2.23461189866066

Epoch: 5| Step: 11
Training loss: 1.3964977264404297
Validation loss: 2.2170970191558204

Epoch: 425| Step: 0
Training loss: 1.075142502784729
Validation loss: 2.1920844316482544

Epoch: 5| Step: 1
Training loss: 1.528868317604065
Validation loss: 2.1852757930755615

Epoch: 5| Step: 2
Training loss: 1.4268124103546143
Validation loss: 2.185705711444219

Epoch: 5| Step: 3
Training loss: 1.5231096744537354
Validation loss: 2.185946131745974

Epoch: 5| Step: 4
Training loss: 1.0591024160385132
Validation loss: 2.2131601373354592

Epoch: 5| Step: 5
Training loss: 1.216922402381897
Validation loss: 2.2579721212387085

Epoch: 5| Step: 6
Training loss: 1.6611335277557373
Validation loss: 2.288917124271393

Epoch: 5| Step: 7
Training loss: 1.2313560247421265
Validation loss: 2.2557250410318375

Epoch: 5| Step: 8
Training loss: 1.615884780883789
Validation loss: 2.219212000568708

Epoch: 5| Step: 9
Training loss: 1.1062405109405518
Validation loss: 2.233634183804194

Epoch: 5| Step: 10
Training loss: 1.2250556945800781
Validation loss: 2.212981700897217

Epoch: 5| Step: 11
Training loss: 0.8282723426818848
Validation loss: 2.1959844827651978

Epoch: 426| Step: 0
Training loss: 2.012795925140381
Validation loss: 2.1972277959187827

Epoch: 5| Step: 1
Training loss: 1.6711845397949219
Validation loss: 2.2452004651228585

Epoch: 5| Step: 2
Training loss: 1.491611361503601
Validation loss: 2.2317675948143005

Epoch: 5| Step: 3
Training loss: 0.9708294868469238
Validation loss: 2.219833344221115

Epoch: 5| Step: 4
Training loss: 1.412035584449768
Validation loss: 2.2406386335690818

Epoch: 5| Step: 5
Training loss: 1.7299690246582031
Validation loss: 2.2443318913380303

Epoch: 5| Step: 6
Training loss: 0.6428297758102417
Validation loss: 2.2183771232763925

Epoch: 5| Step: 7
Training loss: 1.4457494020462036
Validation loss: 2.2299284438292184

Epoch: 5| Step: 8
Training loss: 0.8453885912895203
Validation loss: 2.2068868478139243

Epoch: 5| Step: 9
Training loss: 0.9861048460006714
Validation loss: 2.221536546945572

Epoch: 5| Step: 10
Training loss: 1.0812926292419434
Validation loss: 2.213678389787674

Epoch: 5| Step: 11
Training loss: 0.3259812593460083
Validation loss: 2.206258396307627

Epoch: 427| Step: 0
Training loss: 1.0466053485870361
Validation loss: 2.210896611213684

Epoch: 5| Step: 1
Training loss: 1.0863215923309326
Validation loss: 2.195080190896988

Epoch: 5| Step: 2
Training loss: 0.7618271112442017
Validation loss: 2.175873359044393

Epoch: 5| Step: 3
Training loss: 1.0041420459747314
Validation loss: 2.1515646278858185

Epoch: 5| Step: 4
Training loss: 1.4759318828582764
Validation loss: 2.1426830341418586

Epoch: 5| Step: 5
Training loss: 1.5150340795516968
Validation loss: 2.1099114616711936

Epoch: 5| Step: 6
Training loss: 1.5169165134429932
Validation loss: 2.1525625040133796

Epoch: 5| Step: 7
Training loss: 2.0295231342315674
Validation loss: 2.1087915698687234

Epoch: 5| Step: 8
Training loss: 0.8192436099052429
Validation loss: 2.1542869408925376

Epoch: 5| Step: 9
Training loss: 1.236677885055542
Validation loss: 2.154733886321386

Epoch: 5| Step: 10
Training loss: 1.0176900625228882
Validation loss: 2.1604626973470054

Epoch: 5| Step: 11
Training loss: 0.9447492361068726
Validation loss: 2.1339602122704187

Epoch: 428| Step: 0
Training loss: 1.7206916809082031
Validation loss: 2.183435633778572

Epoch: 5| Step: 1
Training loss: 0.8924999237060547
Validation loss: 2.1708925714095435

Epoch: 5| Step: 2
Training loss: 1.3393921852111816
Validation loss: 2.188083529472351

Epoch: 5| Step: 3
Training loss: 1.186320424079895
Validation loss: 2.1465276380379996

Epoch: 5| Step: 4
Training loss: 1.4533666372299194
Validation loss: 2.1563816467920938

Epoch: 5| Step: 5
Training loss: 0.7778387665748596
Validation loss: 2.16843681037426

Epoch: 5| Step: 6
Training loss: 0.8046106100082397
Validation loss: 2.154078851143519

Epoch: 5| Step: 7
Training loss: 1.6386163234710693
Validation loss: 2.2211854507525763

Epoch: 5| Step: 8
Training loss: 1.3632807731628418
Validation loss: 2.188339024782181

Epoch: 5| Step: 9
Training loss: 0.7143932580947876
Validation loss: 2.147314409414927

Epoch: 5| Step: 10
Training loss: 1.4038962125778198
Validation loss: 2.180821110804876

Epoch: 5| Step: 11
Training loss: 0.6844972372055054
Validation loss: 2.1762493352095285

Epoch: 429| Step: 0
Training loss: 0.8739126324653625
Validation loss: 2.186378632982572

Epoch: 5| Step: 1
Training loss: 1.3467212915420532
Validation loss: 2.1810087660948434

Epoch: 5| Step: 2
Training loss: 1.335620403289795
Validation loss: 2.1751320163408914

Epoch: 5| Step: 3
Training loss: 1.4807531833648682
Validation loss: 2.175004983941714

Epoch: 5| Step: 4
Training loss: 1.077834129333496
Validation loss: 2.130397001902262

Epoch: 5| Step: 5
Training loss: 1.0493189096450806
Validation loss: 2.1833784878253937

Epoch: 5| Step: 6
Training loss: 1.1424142122268677
Validation loss: 2.1923911770184836

Epoch: 5| Step: 7
Training loss: 1.254120111465454
Validation loss: 2.2069261272748313

Epoch: 5| Step: 8
Training loss: 1.1000611782073975
Validation loss: 2.2066593070824942

Epoch: 5| Step: 9
Training loss: 1.0938451290130615
Validation loss: 2.2401882211367288

Epoch: 5| Step: 10
Training loss: 1.1569238901138306
Validation loss: 2.225359479586283

Epoch: 5| Step: 11
Training loss: 1.7191354036331177
Validation loss: 2.2144047617912292

Epoch: 430| Step: 0
Training loss: 0.7685753703117371
Validation loss: 2.189584175745646

Epoch: 5| Step: 1
Training loss: 1.2157186269760132
Validation loss: 2.1541686058044434

Epoch: 5| Step: 2
Training loss: 0.8578664660453796
Validation loss: 2.1587054481108985

Epoch: 5| Step: 3
Training loss: 1.6659252643585205
Validation loss: 2.1511009434858956

Epoch: 5| Step: 4
Training loss: 1.1617377996444702
Validation loss: 2.192183484633764

Epoch: 5| Step: 5
Training loss: 1.8111757040023804
Validation loss: 2.168968826532364

Epoch: 5| Step: 6
Training loss: 1.1253464221954346
Validation loss: 2.1352205673853555

Epoch: 5| Step: 7
Training loss: 1.3151007890701294
Validation loss: 2.1471856236457825

Epoch: 5| Step: 8
Training loss: 1.3293983936309814
Validation loss: 2.1738817592461905

Epoch: 5| Step: 9
Training loss: 0.724688708782196
Validation loss: 2.1546473801136017

Epoch: 5| Step: 10
Training loss: 1.2371785640716553
Validation loss: 2.1697453260421753

Epoch: 5| Step: 11
Training loss: 0.5099155306816101
Validation loss: 2.156227335333824

Epoch: 431| Step: 0
Training loss: 0.975994884967804
Validation loss: 2.1591978619496026

Epoch: 5| Step: 1
Training loss: 1.1397449970245361
Validation loss: 2.1883541544278464

Epoch: 5| Step: 2
Training loss: 1.3962461948394775
Validation loss: 2.1864715814590454

Epoch: 5| Step: 3
Training loss: 0.9092807769775391
Validation loss: 2.166692078113556

Epoch: 5| Step: 4
Training loss: 1.2423200607299805
Validation loss: 2.1612409204244614

Epoch: 5| Step: 5
Training loss: 1.6213788986206055
Validation loss: 2.2298777053753533

Epoch: 5| Step: 6
Training loss: 0.985246479511261
Validation loss: 2.193032756447792

Epoch: 5| Step: 7
Training loss: 1.3998887538909912
Validation loss: 2.1931713620821633

Epoch: 5| Step: 8
Training loss: 1.0346920490264893
Validation loss: 2.1763703376054764

Epoch: 5| Step: 9
Training loss: 1.767228364944458
Validation loss: 2.1842436492443085

Epoch: 5| Step: 10
Training loss: 0.8292158842086792
Validation loss: 2.164619947473208

Epoch: 5| Step: 11
Training loss: 0.6582708358764648
Validation loss: 2.15469000240167

Epoch: 432| Step: 0
Training loss: 1.0651123523712158
Validation loss: 2.173279802004496

Epoch: 5| Step: 1
Training loss: 0.8028732538223267
Validation loss: 2.158678169051806

Epoch: 5| Step: 2
Training loss: 1.027173638343811
Validation loss: 2.185158923268318

Epoch: 5| Step: 3
Training loss: 1.0761171579360962
Validation loss: 2.2083086172739663

Epoch: 5| Step: 4
Training loss: 1.5617576837539673
Validation loss: 2.1870247622330985

Epoch: 5| Step: 5
Training loss: 1.2140601873397827
Validation loss: 2.21408120294412

Epoch: 5| Step: 6
Training loss: 1.0157556533813477
Validation loss: 2.224665785829226

Epoch: 5| Step: 7
Training loss: 1.4023520946502686
Validation loss: 2.2246715823809304

Epoch: 5| Step: 8
Training loss: 1.015364170074463
Validation loss: 2.2071627924839654

Epoch: 5| Step: 9
Training loss: 1.1518863439559937
Validation loss: 2.1848234782616296

Epoch: 5| Step: 10
Training loss: 1.4963886737823486
Validation loss: 2.174251606067022

Epoch: 5| Step: 11
Training loss: 0.2169203758239746
Validation loss: 2.199060544371605

Epoch: 433| Step: 0
Training loss: 0.7334367632865906
Validation loss: 2.1852443168560662

Epoch: 5| Step: 1
Training loss: 1.8143113851547241
Validation loss: 2.2006446719169617

Epoch: 5| Step: 2
Training loss: 1.3929067850112915
Validation loss: 2.1939609746138253

Epoch: 5| Step: 3
Training loss: 1.8263890743255615
Validation loss: 2.226168990135193

Epoch: 5| Step: 4
Training loss: 1.0822746753692627
Validation loss: 2.2049477895100913

Epoch: 5| Step: 5
Training loss: 1.3214458227157593
Validation loss: 2.1868266810973487

Epoch: 5| Step: 6
Training loss: 0.9255220293998718
Validation loss: 2.200726807117462

Epoch: 5| Step: 7
Training loss: 0.8693777322769165
Validation loss: 2.2484222650527954

Epoch: 5| Step: 8
Training loss: 0.970909595489502
Validation loss: 2.198494255542755

Epoch: 5| Step: 9
Training loss: 1.1400595903396606
Validation loss: 2.2030489395062127

Epoch: 5| Step: 10
Training loss: 1.4974777698516846
Validation loss: 2.218303680419922

Epoch: 5| Step: 11
Training loss: 0.6706396341323853
Validation loss: 2.21856897075971

Epoch: 434| Step: 0
Training loss: 0.6523374319076538
Validation loss: 2.1607708434263864

Epoch: 5| Step: 1
Training loss: 1.8127424716949463
Validation loss: 2.17849799990654

Epoch: 5| Step: 2
Training loss: 1.5440142154693604
Validation loss: 2.142290691534678

Epoch: 5| Step: 3
Training loss: 1.344961166381836
Validation loss: 2.18836476902167

Epoch: 5| Step: 4
Training loss: 1.4463602304458618
Validation loss: 2.1576332400242486

Epoch: 5| Step: 5
Training loss: 0.8505937457084656
Validation loss: 2.1683092514673867

Epoch: 5| Step: 6
Training loss: 1.437103509902954
Validation loss: 2.1679484049479165

Epoch: 5| Step: 7
Training loss: 0.9857836961746216
Validation loss: 2.1518181612094245

Epoch: 5| Step: 8
Training loss: 0.7616981267929077
Validation loss: 2.1622895846764245

Epoch: 5| Step: 9
Training loss: 1.2904293537139893
Validation loss: 2.162063419818878

Epoch: 5| Step: 10
Training loss: 1.8463516235351562
Validation loss: 2.1896435618400574

Epoch: 5| Step: 11
Training loss: 0.2796149253845215
Validation loss: 2.214538410305977

Epoch: 435| Step: 0
Training loss: 0.8098821640014648
Validation loss: 2.1879508992036185

Epoch: 5| Step: 1
Training loss: 0.9387980699539185
Validation loss: 2.1883447964986167

Epoch: 5| Step: 2
Training loss: 0.8367406725883484
Validation loss: 2.1413914412260056

Epoch: 5| Step: 3
Training loss: 2.155467987060547
Validation loss: 2.1825469384590783

Epoch: 5| Step: 4
Training loss: 0.9355951547622681
Validation loss: 2.167801707983017

Epoch: 5| Step: 5
Training loss: 1.7295777797698975
Validation loss: 2.1820165713628135

Epoch: 5| Step: 6
Training loss: 0.7130296230316162
Validation loss: 2.1855666687091193

Epoch: 5| Step: 7
Training loss: 0.9026336669921875
Validation loss: 2.173330863316854

Epoch: 5| Step: 8
Training loss: 1.3961684703826904
Validation loss: 2.1913895855347314

Epoch: 5| Step: 9
Training loss: 1.3821475505828857
Validation loss: 2.154583985606829

Epoch: 5| Step: 10
Training loss: 1.4016309976577759
Validation loss: 2.186286156376203

Epoch: 5| Step: 11
Training loss: 1.4586575031280518
Validation loss: 2.164074808359146

Epoch: 436| Step: 0
Training loss: 1.7003034353256226
Validation loss: 2.154070725043615

Epoch: 5| Step: 1
Training loss: 0.9591175317764282
Validation loss: 2.1441801637411118

Epoch: 5| Step: 2
Training loss: 0.8270300030708313
Validation loss: 2.150098592042923

Epoch: 5| Step: 3
Training loss: 0.6347247362136841
Validation loss: 2.1327152450879416

Epoch: 5| Step: 4
Training loss: 0.957068920135498
Validation loss: 2.135525236527125

Epoch: 5| Step: 5
Training loss: 1.1901483535766602
Validation loss: 2.1398394107818604

Epoch: 5| Step: 6
Training loss: 1.1978868246078491
Validation loss: 2.1275389343500137

Epoch: 5| Step: 7
Training loss: 1.1214258670806885
Validation loss: 2.1583373695611954

Epoch: 5| Step: 8
Training loss: 1.325818657875061
Validation loss: 2.1020845721165338

Epoch: 5| Step: 9
Training loss: 1.4067589044570923
Validation loss: 2.123613953590393

Epoch: 5| Step: 10
Training loss: 1.7319841384887695
Validation loss: 2.1375024765729904

Epoch: 5| Step: 11
Training loss: 0.8330347537994385
Validation loss: 2.153650244077047

Epoch: 437| Step: 0
Training loss: 0.7856945395469666
Validation loss: 2.1379003524780273

Epoch: 5| Step: 1
Training loss: 1.2201919555664062
Validation loss: 2.129595617453257

Epoch: 5| Step: 2
Training loss: 1.0576266050338745
Validation loss: 2.167827159166336

Epoch: 5| Step: 3
Training loss: 1.032630205154419
Validation loss: 2.1611023594935737

Epoch: 5| Step: 4
Training loss: 1.3234121799468994
Validation loss: 2.2002746562163034

Epoch: 5| Step: 5
Training loss: 1.3785054683685303
Validation loss: 2.215252235531807

Epoch: 5| Step: 6
Training loss: 1.4595232009887695
Validation loss: 2.2332265973091125

Epoch: 5| Step: 7
Training loss: 1.3256447315216064
Validation loss: 2.23338919878006

Epoch: 5| Step: 8
Training loss: 1.034785509109497
Validation loss: 2.227070525288582

Epoch: 5| Step: 9
Training loss: 1.1369990110397339
Validation loss: 2.20160706837972

Epoch: 5| Step: 10
Training loss: 1.7861884832382202
Validation loss: 2.2315748433272042

Epoch: 5| Step: 11
Training loss: 0.9485236406326294
Validation loss: 2.189378798007965

Epoch: 438| Step: 0
Training loss: 1.0644484758377075
Validation loss: 2.209533895055453

Epoch: 5| Step: 1
Training loss: 0.653990626335144
Validation loss: 2.20747380455335

Epoch: 5| Step: 2
Training loss: 1.397955298423767
Validation loss: 2.2190536757310233

Epoch: 5| Step: 3
Training loss: 1.0361214876174927
Validation loss: 2.2017723321914673

Epoch: 5| Step: 4
Training loss: 0.981993556022644
Validation loss: 2.23092782497406

Epoch: 5| Step: 5
Training loss: 1.2799330949783325
Validation loss: 2.206537981828054

Epoch: 5| Step: 6
Training loss: 0.9745932817459106
Validation loss: 2.1750470052162805

Epoch: 5| Step: 7
Training loss: 1.1810057163238525
Validation loss: 2.189955939849218

Epoch: 5| Step: 8
Training loss: 1.3329578638076782
Validation loss: 2.224540268381437

Epoch: 5| Step: 9
Training loss: 1.8062851428985596
Validation loss: 2.1819381962219873

Epoch: 5| Step: 10
Training loss: 1.209166407585144
Validation loss: 2.1666363974412284

Epoch: 5| Step: 11
Training loss: 1.92685067653656
Validation loss: 2.1359010189771652

Epoch: 439| Step: 0
Training loss: 0.6158884167671204
Validation loss: 2.141729344924291

Epoch: 5| Step: 1
Training loss: 0.9981423616409302
Validation loss: 2.1325356562932334

Epoch: 5| Step: 2
Training loss: 0.827012836933136
Validation loss: 2.12336931626002

Epoch: 5| Step: 3
Training loss: 1.1936147212982178
Validation loss: 2.152472938100497

Epoch: 5| Step: 4
Training loss: 1.453761339187622
Validation loss: 2.1441265692313514

Epoch: 5| Step: 5
Training loss: 1.2439380884170532
Validation loss: 2.1408577809731164

Epoch: 5| Step: 6
Training loss: 1.2258741855621338
Validation loss: 2.1349955648183823

Epoch: 5| Step: 7
Training loss: 1.2097312211990356
Validation loss: 2.132254267732302

Epoch: 5| Step: 8
Training loss: 1.4412864446640015
Validation loss: 2.1557650019725165

Epoch: 5| Step: 9
Training loss: 1.2940200567245483
Validation loss: 2.1394565949837365

Epoch: 5| Step: 10
Training loss: 1.1019861698150635
Validation loss: 2.1996040493249893

Epoch: 5| Step: 11
Training loss: 2.2288434505462646
Validation loss: 2.202710911631584

Epoch: 440| Step: 0
Training loss: 1.1636269092559814
Validation loss: 2.1567081163326898

Epoch: 5| Step: 1
Training loss: 0.6074475646018982
Validation loss: 2.1681564301252365

Epoch: 5| Step: 2
Training loss: 0.973048210144043
Validation loss: 2.1481669594844184

Epoch: 5| Step: 3
Training loss: 1.19136643409729
Validation loss: 2.186295668284098

Epoch: 5| Step: 4
Training loss: 1.2653580904006958
Validation loss: 2.2010856668154397

Epoch: 5| Step: 5
Training loss: 1.2516632080078125
Validation loss: 2.1916020611921945

Epoch: 5| Step: 6
Training loss: 1.3572285175323486
Validation loss: 2.1596169223388038

Epoch: 5| Step: 7
Training loss: 0.6102203130722046
Validation loss: 2.1686129669348397

Epoch: 5| Step: 8
Training loss: 1.187544584274292
Validation loss: 2.165295640627543

Epoch: 5| Step: 9
Training loss: 1.3794755935668945
Validation loss: 2.169138421614965

Epoch: 5| Step: 10
Training loss: 1.361310362815857
Validation loss: 2.14770899216334

Epoch: 5| Step: 11
Training loss: 3.4694409370422363
Validation loss: 2.1910442958275476

Epoch: 441| Step: 0
Training loss: 1.1319644451141357
Validation loss: 2.1979931195576987

Epoch: 5| Step: 1
Training loss: 1.454073190689087
Validation loss: 2.226548050840696

Epoch: 5| Step: 2
Training loss: 1.87332022190094
Validation loss: 2.316151648759842

Epoch: 5| Step: 3
Training loss: 1.5966342687606812
Validation loss: 2.2533668329318366

Epoch: 5| Step: 4
Training loss: 1.5178722143173218
Validation loss: 2.177959675590197

Epoch: 5| Step: 5
Training loss: 1.2643640041351318
Validation loss: 2.07052672902743

Epoch: 5| Step: 6
Training loss: 1.059303879737854
Validation loss: 2.109117493033409

Epoch: 5| Step: 7
Training loss: 1.735853910446167
Validation loss: 2.1293674806753793

Epoch: 5| Step: 8
Training loss: 1.2900841236114502
Validation loss: 2.140210141738256

Epoch: 5| Step: 9
Training loss: 1.073390245437622
Validation loss: 2.182675157984098

Epoch: 5| Step: 10
Training loss: 1.508751392364502
Validation loss: 2.1934011230866113

Epoch: 5| Step: 11
Training loss: 1.559135913848877
Validation loss: 2.2288362085819244

Epoch: 442| Step: 0
Training loss: 1.649125099182129
Validation loss: 2.190389479200045

Epoch: 5| Step: 1
Training loss: 1.2936675548553467
Validation loss: 2.1837732940912247

Epoch: 5| Step: 2
Training loss: 1.3781598806381226
Validation loss: 2.1441974292198815

Epoch: 5| Step: 3
Training loss: 1.2205007076263428
Validation loss: 2.1386333256959915

Epoch: 5| Step: 4
Training loss: 1.1289550065994263
Validation loss: 2.185583839813868

Epoch: 5| Step: 5
Training loss: 1.4314875602722168
Validation loss: 2.165522118409475

Epoch: 5| Step: 6
Training loss: 1.0711629390716553
Validation loss: 2.1278357207775116

Epoch: 5| Step: 7
Training loss: 1.6173700094223022
Validation loss: 2.1486009458700814

Epoch: 5| Step: 8
Training loss: 1.2011349201202393
Validation loss: 2.180419832468033

Epoch: 5| Step: 9
Training loss: 1.1347492933273315
Validation loss: 2.144679600993792

Epoch: 5| Step: 10
Training loss: 0.8388756513595581
Validation loss: 2.147334764401118

Epoch: 5| Step: 11
Training loss: 1.2174549102783203
Validation loss: 2.143520732720693

Epoch: 443| Step: 0
Training loss: 1.0543463230133057
Validation loss: 2.129616712530454

Epoch: 5| Step: 1
Training loss: 0.7005594968795776
Validation loss: 2.1449015587568283

Epoch: 5| Step: 2
Training loss: 2.070396900177002
Validation loss: 2.1274116138617196

Epoch: 5| Step: 3
Training loss: 1.2994418144226074
Validation loss: 2.14408444861571

Epoch: 5| Step: 4
Training loss: 1.4348703622817993
Validation loss: 2.1556447446346283

Epoch: 5| Step: 5
Training loss: 0.9990485310554504
Validation loss: 2.127524584531784

Epoch: 5| Step: 6
Training loss: 0.8993505239486694
Validation loss: 2.1305191417535148

Epoch: 5| Step: 7
Training loss: 1.437888503074646
Validation loss: 2.144613022605578

Epoch: 5| Step: 8
Training loss: 0.8048275113105774
Validation loss: 2.1803711652755737

Epoch: 5| Step: 9
Training loss: 1.0543930530548096
Validation loss: 2.18706347544988

Epoch: 5| Step: 10
Training loss: 1.0046941041946411
Validation loss: 2.171843950947126

Epoch: 5| Step: 11
Training loss: 0.3349655270576477
Validation loss: 2.193408345182737

Epoch: 444| Step: 0
Training loss: 0.9097993969917297
Validation loss: 2.19989579419295

Epoch: 5| Step: 1
Training loss: 0.569349467754364
Validation loss: 2.1733382244904837

Epoch: 5| Step: 2
Training loss: 0.8648762702941895
Validation loss: 2.176278536518415

Epoch: 5| Step: 3
Training loss: 1.5134427547454834
Validation loss: 2.205218975742658

Epoch: 5| Step: 4
Training loss: 1.8320491313934326
Validation loss: 2.1851601699988046

Epoch: 5| Step: 5
Training loss: 0.9589370489120483
Validation loss: 2.1858282337586084

Epoch: 5| Step: 6
Training loss: 1.209545373916626
Validation loss: 2.177998329202334

Epoch: 5| Step: 7
Training loss: 1.1353658437728882
Validation loss: 2.1866115729014077

Epoch: 5| Step: 8
Training loss: 1.0039608478546143
Validation loss: 2.1642764806747437

Epoch: 5| Step: 9
Training loss: 1.3836227655410767
Validation loss: 2.1799685458342233

Epoch: 5| Step: 10
Training loss: 1.2060785293579102
Validation loss: 2.187909558415413

Epoch: 5| Step: 11
Training loss: 1.916544795036316
Validation loss: 2.1461519598960876

Epoch: 445| Step: 0
Training loss: 1.0818569660186768
Validation loss: 2.1568877349297204

Epoch: 5| Step: 1
Training loss: 1.007736325263977
Validation loss: 2.1601043989260993

Epoch: 5| Step: 2
Training loss: 1.4167662858963013
Validation loss: 2.205535093943278

Epoch: 5| Step: 3
Training loss: 1.4047937393188477
Validation loss: 2.1645279824733734

Epoch: 5| Step: 4
Training loss: 1.025909662246704
Validation loss: 2.174173523982366

Epoch: 5| Step: 5
Training loss: 1.735282301902771
Validation loss: 2.131658434867859

Epoch: 5| Step: 6
Training loss: 1.061586856842041
Validation loss: 2.1495055804649987

Epoch: 5| Step: 7
Training loss: 0.8728375434875488
Validation loss: 2.1432000398635864

Epoch: 5| Step: 8
Training loss: 0.9984019994735718
Validation loss: 2.124335899949074

Epoch: 5| Step: 9
Training loss: 0.8585680723190308
Validation loss: 2.146551991502444

Epoch: 5| Step: 10
Training loss: 1.056591510772705
Validation loss: 2.1795783936977386

Epoch: 5| Step: 11
Training loss: 0.9983915090560913
Validation loss: 2.1571892897288003

Epoch: 446| Step: 0
Training loss: 1.361461877822876
Validation loss: 2.172875240445137

Epoch: 5| Step: 1
Training loss: 1.5769470930099487
Validation loss: 2.154752363761266

Epoch: 5| Step: 2
Training loss: 1.1363074779510498
Validation loss: 2.17951762676239

Epoch: 5| Step: 3
Training loss: 1.222033977508545
Validation loss: 2.1466153413057327

Epoch: 5| Step: 4
Training loss: 0.9690240621566772
Validation loss: 2.161073992649714

Epoch: 5| Step: 5
Training loss: 0.9365394711494446
Validation loss: 2.1593534449736276

Epoch: 5| Step: 6
Training loss: 0.7062022089958191
Validation loss: 2.176167661945025

Epoch: 5| Step: 7
Training loss: 0.9545707702636719
Validation loss: 2.141420046488444

Epoch: 5| Step: 8
Training loss: 1.614558458328247
Validation loss: 2.1907559583584466

Epoch: 5| Step: 9
Training loss: 1.2726900577545166
Validation loss: 2.1890488266944885

Epoch: 5| Step: 10
Training loss: 0.9097089767456055
Validation loss: 2.180920327703158

Epoch: 5| Step: 11
Training loss: 0.2580335736274719
Validation loss: 2.179612676302592

Epoch: 447| Step: 0
Training loss: 0.8444122076034546
Validation loss: 2.177120417356491

Epoch: 5| Step: 1
Training loss: 0.7681430578231812
Validation loss: 2.1878039787213006

Epoch: 5| Step: 2
Training loss: 0.8802791833877563
Validation loss: 2.163726190725962

Epoch: 5| Step: 3
Training loss: 1.114601731300354
Validation loss: 2.1660093565781913

Epoch: 5| Step: 4
Training loss: 1.2099825143814087
Validation loss: 2.149830644329389

Epoch: 5| Step: 5
Training loss: 1.492563247680664
Validation loss: 2.140390714009603

Epoch: 5| Step: 6
Training loss: 1.1887884140014648
Validation loss: 2.132041503985723

Epoch: 5| Step: 7
Training loss: 1.522066593170166
Validation loss: 2.1344807843367257

Epoch: 5| Step: 8
Training loss: 1.4855983257293701
Validation loss: 2.1511512945095697

Epoch: 5| Step: 9
Training loss: 0.6712204217910767
Validation loss: 2.164980188012123

Epoch: 5| Step: 10
Training loss: 0.9014393091201782
Validation loss: 2.1427516539891562

Epoch: 5| Step: 11
Training loss: 2.224738836288452
Validation loss: 2.1741533428430557

Epoch: 448| Step: 0
Training loss: 0.984026312828064
Validation loss: 2.1815662533044815

Epoch: 5| Step: 1
Training loss: 0.740483283996582
Validation loss: 2.195303718249003

Epoch: 5| Step: 2
Training loss: 1.6480515003204346
Validation loss: 2.198057989279429

Epoch: 5| Step: 3
Training loss: 1.591437578201294
Validation loss: 2.2187475115060806

Epoch: 5| Step: 4
Training loss: 1.1142141819000244
Validation loss: 2.202011078596115

Epoch: 5| Step: 5
Training loss: 1.0594727993011475
Validation loss: 2.2538623809814453

Epoch: 5| Step: 6
Training loss: 1.1734836101531982
Validation loss: 2.159419506788254

Epoch: 5| Step: 7
Training loss: 1.133467674255371
Validation loss: 2.2161162396272025

Epoch: 5| Step: 8
Training loss: 1.5392818450927734
Validation loss: 2.173962781826655

Epoch: 5| Step: 9
Training loss: 1.2530678510665894
Validation loss: 2.2405570447444916

Epoch: 5| Step: 10
Training loss: 1.0047895908355713
Validation loss: 2.1556649804115295

Epoch: 5| Step: 11
Training loss: 0.4711957573890686
Validation loss: 2.181483750542005

Epoch: 449| Step: 0
Training loss: 1.0965496301651
Validation loss: 2.1479902217785516

Epoch: 5| Step: 1
Training loss: 1.4961507320404053
Validation loss: 2.1940196057160697

Epoch: 5| Step: 2
Training loss: 0.9548534154891968
Validation loss: 2.162496715784073

Epoch: 5| Step: 3
Training loss: 1.2929532527923584
Validation loss: 2.1575015435616174

Epoch: 5| Step: 4
Training loss: 1.1294136047363281
Validation loss: 2.159773642818133

Epoch: 5| Step: 5
Training loss: 0.9452020525932312
Validation loss: 2.1559112668037415

Epoch: 5| Step: 6
Training loss: 1.2760192155838013
Validation loss: 2.1396928876638412

Epoch: 5| Step: 7
Training loss: 1.3538357019424438
Validation loss: 2.140690878033638

Epoch: 5| Step: 8
Training loss: 1.908980131149292
Validation loss: 2.147527535756429

Epoch: 5| Step: 9
Training loss: 0.8785728216171265
Validation loss: 2.1549861431121826

Epoch: 5| Step: 10
Training loss: 1.4146029949188232
Validation loss: 2.181577354669571

Epoch: 5| Step: 11
Training loss: 3.2226099967956543
Validation loss: 2.1981313824653625

Epoch: 450| Step: 0
Training loss: 1.458254098892212
Validation loss: 2.181863700350126

Epoch: 5| Step: 1
Training loss: 1.2025842666625977
Validation loss: 2.2023895929257074

Epoch: 5| Step: 2
Training loss: 1.1187224388122559
Validation loss: 2.1748493909835815

Epoch: 5| Step: 3
Training loss: 0.9125370979309082
Validation loss: 2.1797926078240075

Epoch: 5| Step: 4
Training loss: 0.9875921010971069
Validation loss: 2.1576446692148843

Epoch: 5| Step: 5
Training loss: 0.911507248878479
Validation loss: 2.1868668595949807

Epoch: 5| Step: 6
Training loss: 2.2142741680145264
Validation loss: 2.2010244727134705

Epoch: 5| Step: 7
Training loss: 1.0937026739120483
Validation loss: 2.186921795209249

Epoch: 5| Step: 8
Training loss: 1.1836001873016357
Validation loss: 2.167180155714353

Epoch: 5| Step: 9
Training loss: 1.0984604358673096
Validation loss: 2.1490855614344277

Epoch: 5| Step: 10
Training loss: 1.8678489923477173
Validation loss: 2.1221148719390235

Epoch: 5| Step: 11
Training loss: 1.0520193576812744
Validation loss: 2.137517457207044

Testing loss: 1.8894629452725966
