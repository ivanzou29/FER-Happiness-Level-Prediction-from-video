Epoch: 1| Step: 0
Training loss: 5.252900123596191
Validation loss: 5.3045474489529925

Epoch: 5| Step: 1
Training loss: 4.956686496734619
Validation loss: 5.302517553170522

Epoch: 5| Step: 2
Training loss: 6.69855260848999
Validation loss: 5.300460378328959

Epoch: 5| Step: 3
Training loss: 5.806792259216309
Validation loss: 5.298270165920258

Epoch: 5| Step: 4
Training loss: 4.886025905609131
Validation loss: 5.296103437741597

Epoch: 5| Step: 5
Training loss: 6.141982078552246
Validation loss: 5.293895920117696

Epoch: 5| Step: 6
Training loss: 4.814699649810791
Validation loss: 5.291601677735646

Epoch: 5| Step: 7
Training loss: 5.407083988189697
Validation loss: 5.289289355278015

Epoch: 5| Step: 8
Training loss: 4.580475807189941
Validation loss: 5.286819616953532

Epoch: 5| Step: 9
Training loss: 5.274594306945801
Validation loss: 5.284343878428142

Epoch: 5| Step: 10
Training loss: 5.127488136291504
Validation loss: 5.281757493813832

Epoch: 5| Step: 11
Training loss: 5.565106391906738
Validation loss: 5.279061158498128

Epoch: 2| Step: 0
Training loss: 6.055366516113281
Validation loss: 5.276260455449422

Epoch: 5| Step: 1
Training loss: 5.3018670082092285
Validation loss: 5.273291250069936

Epoch: 5| Step: 2
Training loss: 5.5944952964782715
Validation loss: 5.270191689332326

Epoch: 5| Step: 3
Training loss: 4.243018627166748
Validation loss: 5.26702622572581

Epoch: 5| Step: 4
Training loss: 4.454079627990723
Validation loss: 5.263709843158722

Epoch: 5| Step: 5
Training loss: 5.5388994216918945
Validation loss: 5.260361909866333

Epoch: 5| Step: 6
Training loss: 4.704148292541504
Validation loss: 5.25665549437205

Epoch: 5| Step: 7
Training loss: 5.965279579162598
Validation loss: 5.252845148245494

Epoch: 5| Step: 8
Training loss: 5.831556797027588
Validation loss: 5.248767813046773

Epoch: 5| Step: 9
Training loss: 5.91580867767334
Validation loss: 5.2445476452509565

Epoch: 5| Step: 10
Training loss: 5.105522632598877
Validation loss: 5.240323523680369

Epoch: 5| Step: 11
Training loss: 4.837018013000488
Validation loss: 5.2357071240743

Epoch: 3| Step: 0
Training loss: 5.728740215301514
Validation loss: 5.230900605519612

Epoch: 5| Step: 1
Training loss: 5.3923020362854
Validation loss: 5.225958406925201

Epoch: 5| Step: 2
Training loss: 6.0666093826293945
Validation loss: 5.220682680606842

Epoch: 5| Step: 3
Training loss: 5.526882648468018
Validation loss: 5.215230484803517

Epoch: 5| Step: 4
Training loss: 4.927401542663574
Validation loss: 5.209511578083038

Epoch: 5| Step: 5
Training loss: 6.170145511627197
Validation loss: 5.203634838263194

Epoch: 5| Step: 6
Training loss: 4.305074691772461
Validation loss: 5.197383423646291

Epoch: 5| Step: 7
Training loss: 4.560538291931152
Validation loss: 5.191098848978679

Epoch: 5| Step: 8
Training loss: 4.290346622467041
Validation loss: 5.1844625274340315

Epoch: 5| Step: 9
Training loss: 5.228411674499512
Validation loss: 5.177832822004954

Epoch: 5| Step: 10
Training loss: 5.594651222229004
Validation loss: 5.170533696810405

Epoch: 5| Step: 11
Training loss: 6.270407199859619
Validation loss: 5.163213690121968

Epoch: 4| Step: 0
Training loss: 5.971475124359131
Validation loss: 5.155730724334717

Epoch: 5| Step: 1
Training loss: 4.814919948577881
Validation loss: 5.148100038369496

Epoch: 5| Step: 2
Training loss: 4.8944878578186035
Validation loss: 5.140170454978943

Epoch: 5| Step: 3
Training loss: 5.663722515106201
Validation loss: 5.132344623406728

Epoch: 5| Step: 4
Training loss: 4.19401741027832
Validation loss: 5.124240358670552

Epoch: 5| Step: 5
Training loss: 5.763207912445068
Validation loss: 5.115959604581197

Epoch: 5| Step: 6
Training loss: 4.182679176330566
Validation loss: 5.1075878739356995

Epoch: 5| Step: 7
Training loss: 5.6240010261535645
Validation loss: 5.09927241007487

Epoch: 5| Step: 8
Training loss: 5.718067169189453
Validation loss: 5.090528786182404

Epoch: 5| Step: 9
Training loss: 4.9194016456604
Validation loss: 5.081916709740956

Epoch: 5| Step: 10
Training loss: 5.51906681060791
Validation loss: 5.073096175988515

Epoch: 5| Step: 11
Training loss: 4.22422981262207
Validation loss: 5.06429402033488

Epoch: 5| Step: 0
Training loss: 4.218973159790039
Validation loss: 5.055105050404866

Epoch: 5| Step: 1
Training loss: 4.924893856048584
Validation loss: 5.046277582645416

Epoch: 5| Step: 2
Training loss: 5.316361427307129
Validation loss: 5.037271161874135

Epoch: 5| Step: 3
Training loss: 5.268021106719971
Validation loss: 5.027998546759288

Epoch: 5| Step: 4
Training loss: 6.396100044250488
Validation loss: 5.018785814444224

Epoch: 5| Step: 5
Training loss: 4.041806697845459
Validation loss: 5.009325802326202

Epoch: 5| Step: 6
Training loss: 5.024308204650879
Validation loss: 4.999749104181926

Epoch: 5| Step: 7
Training loss: 5.463259696960449
Validation loss: 4.99024514357249

Epoch: 5| Step: 8
Training loss: 4.668464183807373
Validation loss: 4.980858504772186

Epoch: 5| Step: 9
Training loss: 5.181333065032959
Validation loss: 4.971197525660197

Epoch: 5| Step: 10
Training loss: 5.582108497619629
Validation loss: 4.961652835210164

Epoch: 5| Step: 11
Training loss: 4.523795127868652
Validation loss: 4.952307383219401

Epoch: 6| Step: 0
Training loss: 5.302424430847168
Validation loss: 4.942981441815694

Epoch: 5| Step: 1
Training loss: 5.5776777267456055
Validation loss: 4.933933198451996

Epoch: 5| Step: 2
Training loss: 4.169759273529053
Validation loss: 4.925364375114441

Epoch: 5| Step: 3
Training loss: 5.25864315032959
Validation loss: 4.9162652889887495

Epoch: 5| Step: 4
Training loss: 5.6336774826049805
Validation loss: 4.907563130060832

Epoch: 5| Step: 5
Training loss: 4.936440467834473
Validation loss: 4.898819883664449

Epoch: 5| Step: 6
Training loss: 4.887111663818359
Validation loss: 4.890511194864909

Epoch: 5| Step: 7
Training loss: 4.9945478439331055
Validation loss: 4.882004717985789

Epoch: 5| Step: 8
Training loss: 5.177554607391357
Validation loss: 4.87334190805753

Epoch: 5| Step: 9
Training loss: 4.540552616119385
Validation loss: 4.864941497643788

Epoch: 5| Step: 10
Training loss: 4.637338161468506
Validation loss: 4.856265564759572

Epoch: 5| Step: 11
Training loss: 3.518953800201416
Validation loss: 4.84784734249115

Epoch: 7| Step: 0
Training loss: 5.427821159362793
Validation loss: 4.83953442176183

Epoch: 5| Step: 1
Training loss: 4.937424182891846
Validation loss: 4.830970287322998

Epoch: 5| Step: 2
Training loss: 5.801926136016846
Validation loss: 4.822814385096232

Epoch: 5| Step: 3
Training loss: 4.713864803314209
Validation loss: 4.814686020215352

Epoch: 5| Step: 4
Training loss: 3.4156556129455566
Validation loss: 4.806929747263591

Epoch: 5| Step: 5
Training loss: 5.022478103637695
Validation loss: 4.799448450406392

Epoch: 5| Step: 6
Training loss: 4.910269260406494
Validation loss: 4.792145669460297

Epoch: 5| Step: 7
Training loss: 4.794125556945801
Validation loss: 4.7847544352213545

Epoch: 5| Step: 8
Training loss: 4.063228130340576
Validation loss: 4.777614990870158

Epoch: 5| Step: 9
Training loss: 4.755281448364258
Validation loss: 4.769834419091542

Epoch: 5| Step: 10
Training loss: 6.04677677154541
Validation loss: 4.762668073177338

Epoch: 5| Step: 11
Training loss: 4.350727081298828
Validation loss: 4.754947106043498

Epoch: 8| Step: 0
Training loss: 4.639298915863037
Validation loss: 4.747411509354909

Epoch: 5| Step: 1
Training loss: 4.663176536560059
Validation loss: 4.7405573924382525

Epoch: 5| Step: 2
Training loss: 5.715902805328369
Validation loss: 4.733549396197001

Epoch: 5| Step: 3
Training loss: 5.456410884857178
Validation loss: 4.72640394171079

Epoch: 5| Step: 4
Training loss: 4.915687561035156
Validation loss: 4.719363749027252

Epoch: 5| Step: 5
Training loss: 3.9026057720184326
Validation loss: 4.712593376636505

Epoch: 5| Step: 6
Training loss: 5.043573379516602
Validation loss: 4.705558866262436

Epoch: 5| Step: 7
Training loss: 5.2772393226623535
Validation loss: 4.698549389839172

Epoch: 5| Step: 8
Training loss: 4.63607120513916
Validation loss: 4.691747526327769

Epoch: 5| Step: 9
Training loss: 3.9725069999694824
Validation loss: 4.685074865818024

Epoch: 5| Step: 10
Training loss: 4.667449951171875
Validation loss: 4.678368965784709

Epoch: 5| Step: 11
Training loss: 4.835998058319092
Validation loss: 4.671848565340042

Epoch: 9| Step: 0
Training loss: 4.453271389007568
Validation loss: 4.665363848209381

Epoch: 5| Step: 1
Training loss: 4.457144260406494
Validation loss: 4.658360054095586

Epoch: 5| Step: 2
Training loss: 5.411872863769531
Validation loss: 4.651218295097351

Epoch: 5| Step: 3
Training loss: 5.411067962646484
Validation loss: 4.64409742752711

Epoch: 5| Step: 4
Training loss: 4.337515354156494
Validation loss: 4.636995216210683

Epoch: 5| Step: 5
Training loss: 4.579590797424316
Validation loss: 4.629325707753499

Epoch: 5| Step: 6
Training loss: 4.627685070037842
Validation loss: 4.621590882539749

Epoch: 5| Step: 7
Training loss: 4.135926246643066
Validation loss: 4.613981336355209

Epoch: 5| Step: 8
Training loss: 4.861714839935303
Validation loss: 4.605740348498027

Epoch: 5| Step: 9
Training loss: 4.415602684020996
Validation loss: 4.59763087828954

Epoch: 5| Step: 10
Training loss: 5.064117908477783
Validation loss: 4.588994999726613

Epoch: 5| Step: 11
Training loss: 5.945878982543945
Validation loss: 4.580909788608551

Epoch: 10| Step: 0
Training loss: 5.120216369628906
Validation loss: 4.572600364685059

Epoch: 5| Step: 1
Training loss: 4.0197954177856445
Validation loss: 4.564231514930725

Epoch: 5| Step: 2
Training loss: 4.55010986328125
Validation loss: 4.556302030881246

Epoch: 5| Step: 3
Training loss: 5.1043314933776855
Validation loss: 4.548476278781891

Epoch: 5| Step: 4
Training loss: 5.038244724273682
Validation loss: 4.54041263461113

Epoch: 5| Step: 5
Training loss: 4.258781433105469
Validation loss: 4.532844980557759

Epoch: 5| Step: 6
Training loss: 5.820999622344971
Validation loss: 4.525047938028972

Epoch: 5| Step: 7
Training loss: 4.1868181228637695
Validation loss: 4.51732583840688

Epoch: 5| Step: 8
Training loss: 5.0375518798828125
Validation loss: 4.509378254413605

Epoch: 5| Step: 9
Training loss: 4.692760944366455
Validation loss: 4.501710613568624

Epoch: 5| Step: 10
Training loss: 3.7408759593963623
Validation loss: 4.4947691559791565

Epoch: 5| Step: 11
Training loss: 1.864969253540039
Validation loss: 4.487778931856155

Epoch: 11| Step: 0
Training loss: 5.44101619720459
Validation loss: 4.480858117341995

Epoch: 5| Step: 1
Training loss: 4.2975969314575195
Validation loss: 4.474212805430095

Epoch: 5| Step: 2
Training loss: 3.896249771118164
Validation loss: 4.467662225166957

Epoch: 5| Step: 3
Training loss: 4.711836814880371
Validation loss: 4.461351970831553

Epoch: 5| Step: 4
Training loss: 4.208232879638672
Validation loss: 4.454294403394063

Epoch: 5| Step: 5
Training loss: 4.710324764251709
Validation loss: 4.447645882765452

Epoch: 5| Step: 6
Training loss: 4.954583168029785
Validation loss: 4.439993719259898

Epoch: 5| Step: 7
Training loss: 5.084977149963379
Validation loss: 4.43288787206014

Epoch: 5| Step: 8
Training loss: 3.8255836963653564
Validation loss: 4.4261084000269575

Epoch: 5| Step: 9
Training loss: 5.556003570556641
Validation loss: 4.419107695420583

Epoch: 5| Step: 10
Training loss: 3.723824977874756
Validation loss: 4.41207613547643

Epoch: 5| Step: 11
Training loss: 3.2195777893066406
Validation loss: 4.40462593237559

Epoch: 12| Step: 0
Training loss: 5.009527683258057
Validation loss: 4.3984971443812055

Epoch: 5| Step: 1
Training loss: 3.651310443878174
Validation loss: 4.391802807648976

Epoch: 5| Step: 2
Training loss: 4.894082069396973
Validation loss: 4.384823143482208

Epoch: 5| Step: 3
Training loss: 4.742020606994629
Validation loss: 4.37794812520345

Epoch: 5| Step: 4
Training loss: 4.8830885887146
Validation loss: 4.371141264835994

Epoch: 5| Step: 5
Training loss: 3.6026973724365234
Validation loss: 4.364397873481114

Epoch: 5| Step: 6
Training loss: 4.890835762023926
Validation loss: 4.3578475415706635

Epoch: 5| Step: 7
Training loss: 4.531838417053223
Validation loss: 4.35191426674525

Epoch: 5| Step: 8
Training loss: 5.0809526443481445
Validation loss: 4.345450778802236

Epoch: 5| Step: 9
Training loss: 4.1805853843688965
Validation loss: 4.338644017775853

Epoch: 5| Step: 10
Training loss: 4.109932899475098
Validation loss: 4.332676122585933

Epoch: 5| Step: 11
Training loss: 3.3319475650787354
Validation loss: 4.326476176579793

Epoch: 13| Step: 0
Training loss: 4.263810157775879
Validation loss: 4.320549815893173

Epoch: 5| Step: 1
Training loss: 4.899820327758789
Validation loss: 4.314434776703517

Epoch: 5| Step: 2
Training loss: 4.651245594024658
Validation loss: 4.308078388373057

Epoch: 5| Step: 3
Training loss: 4.279447078704834
Validation loss: 4.301816205183665

Epoch: 5| Step: 4
Training loss: 4.044456481933594
Validation loss: 4.2958803077538805

Epoch: 5| Step: 5
Training loss: 4.761470317840576
Validation loss: 4.289800902207692

Epoch: 5| Step: 6
Training loss: 3.784083604812622
Validation loss: 4.2829055686791735

Epoch: 5| Step: 7
Training loss: 4.448405742645264
Validation loss: 4.277220209439595

Epoch: 5| Step: 8
Training loss: 3.8161673545837402
Validation loss: 4.271378775437673

Epoch: 5| Step: 9
Training loss: 5.05560827255249
Validation loss: 4.264837334553401

Epoch: 5| Step: 10
Training loss: 4.493655681610107
Validation loss: 4.258629898230235

Epoch: 5| Step: 11
Training loss: 4.841180324554443
Validation loss: 4.252015709877014

Epoch: 14| Step: 0
Training loss: 3.624729871749878
Validation loss: 4.246023009220759

Epoch: 5| Step: 1
Training loss: 4.899859428405762
Validation loss: 4.240077575047811

Epoch: 5| Step: 2
Training loss: 4.156927108764648
Validation loss: 4.233216375112534

Epoch: 5| Step: 3
Training loss: 4.403782844543457
Validation loss: 4.226819445689519

Epoch: 5| Step: 4
Training loss: 4.246417045593262
Validation loss: 4.220271627108256

Epoch: 5| Step: 5
Training loss: 4.408782005310059
Validation loss: 4.214521040519078

Epoch: 5| Step: 6
Training loss: 4.482419013977051
Validation loss: 4.2092145184675855

Epoch: 5| Step: 7
Training loss: 3.8514766693115234
Validation loss: 4.203695456186931

Epoch: 5| Step: 8
Training loss: 5.123775959014893
Validation loss: 4.196229149897893

Epoch: 5| Step: 9
Training loss: 4.928057670593262
Validation loss: 4.190105865399043

Epoch: 5| Step: 10
Training loss: 3.636435031890869
Validation loss: 4.1853010058403015

Epoch: 5| Step: 11
Training loss: 4.670526504516602
Validation loss: 4.180024822552999

Epoch: 15| Step: 0
Training loss: 4.3982110023498535
Validation loss: 4.172101606925328

Epoch: 5| Step: 1
Training loss: 3.6037986278533936
Validation loss: 4.16508690516154

Epoch: 5| Step: 2
Training loss: 4.083053112030029
Validation loss: 4.159670094648997

Epoch: 5| Step: 3
Training loss: 3.7958340644836426
Validation loss: 4.153268416722615

Epoch: 5| Step: 4
Training loss: 4.762848854064941
Validation loss: 4.147364636262258

Epoch: 5| Step: 5
Training loss: 5.017939567565918
Validation loss: 4.140628377596538

Epoch: 5| Step: 6
Training loss: 4.448550224304199
Validation loss: 4.133904576301575

Epoch: 5| Step: 7
Training loss: 4.313073635101318
Validation loss: 4.128411163886388

Epoch: 5| Step: 8
Training loss: 4.253091812133789
Validation loss: 4.122673501571019

Epoch: 5| Step: 9
Training loss: 4.075903415679932
Validation loss: 4.116521716117859

Epoch: 5| Step: 10
Training loss: 3.9116427898406982
Validation loss: 4.110466301441193

Epoch: 5| Step: 11
Training loss: 6.339321136474609
Validation loss: 4.103691170612971

Epoch: 16| Step: 0
Training loss: 4.517651557922363
Validation loss: 4.097816050052643

Epoch: 5| Step: 1
Training loss: 4.160219669342041
Validation loss: 4.092715531587601

Epoch: 5| Step: 2
Training loss: 4.0643391609191895
Validation loss: 4.085816631714503

Epoch: 5| Step: 3
Training loss: 3.2472946643829346
Validation loss: 4.078689595063527

Epoch: 5| Step: 4
Training loss: 4.544719696044922
Validation loss: 4.071627269188563

Epoch: 5| Step: 5
Training loss: 3.9654831886291504
Validation loss: 4.066306074460347

Epoch: 5| Step: 6
Training loss: 3.2854256629943848
Validation loss: 4.061880896488826

Epoch: 5| Step: 7
Training loss: 4.579499244689941
Validation loss: 4.057712544997533

Epoch: 5| Step: 8
Training loss: 4.707225322723389
Validation loss: 4.0503765145937605

Epoch: 5| Step: 9
Training loss: 4.419467449188232
Validation loss: 4.0435081124305725

Epoch: 5| Step: 10
Training loss: 4.592602252960205
Validation loss: 4.035943100849788

Epoch: 5| Step: 11
Training loss: 5.3385772705078125
Validation loss: 4.030041913191478

Epoch: 17| Step: 0
Training loss: 4.452083587646484
Validation loss: 4.025019357601802

Epoch: 5| Step: 1
Training loss: 4.1527204513549805
Validation loss: 4.01894677678744

Epoch: 5| Step: 2
Training loss: 4.777217388153076
Validation loss: 4.012465526660283

Epoch: 5| Step: 3
Training loss: 4.96252965927124
Validation loss: 4.006387084722519

Epoch: 5| Step: 4
Training loss: 3.48612904548645
Validation loss: 4.000809580087662

Epoch: 5| Step: 5
Training loss: 2.6683404445648193
Validation loss: 3.9961634278297424

Epoch: 5| Step: 6
Training loss: 3.6985511779785156
Validation loss: 3.989569664001465

Epoch: 5| Step: 7
Training loss: 4.647037506103516
Validation loss: 3.98409296075503

Epoch: 5| Step: 8
Training loss: 3.8255257606506348
Validation loss: 3.977376172939936

Epoch: 5| Step: 9
Training loss: 4.497472763061523
Validation loss: 3.970193008581797

Epoch: 5| Step: 10
Training loss: 4.431901931762695
Validation loss: 3.966228206952413

Epoch: 5| Step: 11
Training loss: 3.8131160736083984
Validation loss: 3.9600099126497903

Epoch: 18| Step: 0
Training loss: 4.063897132873535
Validation loss: 3.9535498221715293

Epoch: 5| Step: 1
Training loss: 3.480363130569458
Validation loss: 3.9476953645547233

Epoch: 5| Step: 2
Training loss: 3.8274788856506348
Validation loss: 3.9430891076723733

Epoch: 5| Step: 3
Training loss: 4.651110649108887
Validation loss: 3.937071532011032

Epoch: 5| Step: 4
Training loss: 3.7390053272247314
Validation loss: 3.9301868279774985

Epoch: 5| Step: 5
Training loss: 4.14099645614624
Validation loss: 3.9238921900590262

Epoch: 5| Step: 6
Training loss: 3.966046094894409
Validation loss: 3.9176770448684692

Epoch: 5| Step: 7
Training loss: 3.7150180339813232
Validation loss: 3.91262956460317

Epoch: 5| Step: 8
Training loss: 5.002494812011719
Validation loss: 3.9060835440953574

Epoch: 5| Step: 9
Training loss: 4.314692497253418
Validation loss: 3.901020963986715

Epoch: 5| Step: 10
Training loss: 3.8888936042785645
Validation loss: 3.896031657854716

Epoch: 5| Step: 11
Training loss: 4.137679576873779
Validation loss: 3.890858848889669

Epoch: 19| Step: 0
Training loss: 4.254055500030518
Validation loss: 3.884085992972056

Epoch: 5| Step: 1
Training loss: 4.11467981338501
Validation loss: 3.878376026948293

Epoch: 5| Step: 2
Training loss: 4.112961769104004
Validation loss: 3.8719032406806946

Epoch: 5| Step: 3
Training loss: 4.459273338317871
Validation loss: 3.8664203584194183

Epoch: 5| Step: 4
Training loss: 3.9391684532165527
Validation loss: 3.8608546058336892

Epoch: 5| Step: 5
Training loss: 4.187554836273193
Validation loss: 3.856114794810613

Epoch: 5| Step: 6
Training loss: 4.263043403625488
Validation loss: 3.850325951973597

Epoch: 5| Step: 7
Training loss: 2.804743528366089
Validation loss: 3.8445111314455667

Epoch: 5| Step: 8
Training loss: 4.356436252593994
Validation loss: 3.8402938644091287

Epoch: 5| Step: 9
Training loss: 3.748220920562744
Validation loss: 3.835191031297048

Epoch: 5| Step: 10
Training loss: 3.781106948852539
Validation loss: 3.829513281583786

Epoch: 5| Step: 11
Training loss: 4.2922749519348145
Validation loss: 3.824068854252497

Epoch: 20| Step: 0
Training loss: 3.779364824295044
Validation loss: 3.818540543317795

Epoch: 5| Step: 1
Training loss: 3.861550807952881
Validation loss: 3.813674042622248

Epoch: 5| Step: 2
Training loss: 4.3158040046691895
Validation loss: 3.808624267578125

Epoch: 5| Step: 3
Training loss: 4.304365158081055
Validation loss: 3.8028710981210074

Epoch: 5| Step: 4
Training loss: 3.7278506755828857
Validation loss: 3.7981046537558236

Epoch: 5| Step: 5
Training loss: 4.938192844390869
Validation loss: 3.792555719614029

Epoch: 5| Step: 6
Training loss: 3.035907745361328
Validation loss: 3.7876870930194855

Epoch: 5| Step: 7
Training loss: 4.72417688369751
Validation loss: 3.782764712969462

Epoch: 5| Step: 8
Training loss: 4.0238142013549805
Validation loss: 3.7777205208937326

Epoch: 5| Step: 9
Training loss: 2.925856828689575
Validation loss: 3.772655099630356

Epoch: 5| Step: 10
Training loss: 3.958712339401245
Validation loss: 3.7678573032220206

Epoch: 5| Step: 11
Training loss: 3.11369252204895
Validation loss: 3.763066033522288

Epoch: 21| Step: 0
Training loss: 4.532992362976074
Validation loss: 3.757640322049459

Epoch: 5| Step: 1
Training loss: 4.697343826293945
Validation loss: 3.752592305342356

Epoch: 5| Step: 2
Training loss: 4.079733848571777
Validation loss: 3.748278150955836

Epoch: 5| Step: 3
Training loss: 2.8361995220184326
Validation loss: 3.742907702922821

Epoch: 5| Step: 4
Training loss: 3.662970781326294
Validation loss: 3.7382460037867227

Epoch: 5| Step: 5
Training loss: 2.686774730682373
Validation loss: 3.734003782272339

Epoch: 5| Step: 6
Training loss: 3.724147081375122
Validation loss: 3.7291650772094727

Epoch: 5| Step: 7
Training loss: 3.9681477546691895
Validation loss: 3.72404815753301

Epoch: 5| Step: 8
Training loss: 4.4724016189575195
Validation loss: 3.7193378110726676

Epoch: 5| Step: 9
Training loss: 3.506141185760498
Validation loss: 3.714389363924662

Epoch: 5| Step: 10
Training loss: 4.383713722229004
Validation loss: 3.7090054154396057

Epoch: 5| Step: 11
Training loss: 5.221619606018066
Validation loss: 3.703871021668116

Epoch: 22| Step: 0
Training loss: 4.237542629241943
Validation loss: 3.6991061170895896

Epoch: 5| Step: 1
Training loss: 3.7422232627868652
Validation loss: 3.693728735049566

Epoch: 5| Step: 2
Training loss: 3.8121249675750732
Validation loss: 3.6886890133221946

Epoch: 5| Step: 3
Training loss: 2.7115511894226074
Validation loss: 3.683440327644348

Epoch: 5| Step: 4
Training loss: 4.404305458068848
Validation loss: 3.6782477597395578

Epoch: 5| Step: 5
Training loss: 3.7822036743164062
Validation loss: 3.6725857853889465

Epoch: 5| Step: 6
Training loss: 4.022719383239746
Validation loss: 3.6673923830191293

Epoch: 5| Step: 7
Training loss: 3.98516845703125
Validation loss: 3.66321524977684

Epoch: 5| Step: 8
Training loss: 2.834364414215088
Validation loss: 3.657016267379125

Epoch: 5| Step: 9
Training loss: 4.36644172668457
Validation loss: 3.654102255900701

Epoch: 5| Step: 10
Training loss: 4.067858695983887
Validation loss: 3.6482815047105155

Epoch: 5| Step: 11
Training loss: 4.830992221832275
Validation loss: 3.642767528692881

Epoch: 23| Step: 0
Training loss: 2.5292258262634277
Validation loss: 3.638066361347834

Epoch: 5| Step: 1
Training loss: 3.4506289958953857
Validation loss: 3.6371028820673623

Epoch: 5| Step: 2
Training loss: 3.3565444946289062
Validation loss: 3.6345530351003013

Epoch: 5| Step: 3
Training loss: 3.984236240386963
Validation loss: 3.628573606411616

Epoch: 5| Step: 4
Training loss: 4.81969690322876
Validation loss: 3.6220182180404663

Epoch: 5| Step: 5
Training loss: 3.809286117553711
Validation loss: 3.615423321723938

Epoch: 5| Step: 6
Training loss: 3.7187042236328125
Validation loss: 3.610069990158081

Epoch: 5| Step: 7
Training loss: 4.593851089477539
Validation loss: 3.6058309574921927

Epoch: 5| Step: 8
Training loss: 3.713576555252075
Validation loss: 3.6003666718800864

Epoch: 5| Step: 9
Training loss: 4.317465782165527
Validation loss: 3.5956801374753318

Epoch: 5| Step: 10
Training loss: 3.434286594390869
Validation loss: 3.5894164443016052

Epoch: 5| Step: 11
Training loss: 2.8747060298919678
Validation loss: 3.5845916469891868

Epoch: 24| Step: 0
Training loss: 3.5307140350341797
Validation loss: 3.5805654327074685

Epoch: 5| Step: 1
Training loss: 3.5526816844940186
Validation loss: 3.5764515499273934

Epoch: 5| Step: 2
Training loss: 3.933454990386963
Validation loss: 3.5724411606788635

Epoch: 5| Step: 3
Training loss: 4.1638336181640625
Validation loss: 3.565503944953283

Epoch: 5| Step: 4
Training loss: 3.21966552734375
Validation loss: 3.5599091053009033

Epoch: 5| Step: 5
Training loss: 4.014753818511963
Validation loss: 3.554669181505839

Epoch: 5| Step: 6
Training loss: 3.4522273540496826
Validation loss: 3.550445189078649

Epoch: 5| Step: 7
Training loss: 3.739931583404541
Validation loss: 3.545883367458979

Epoch: 5| Step: 8
Training loss: 3.1935489177703857
Validation loss: 3.5409988363583884

Epoch: 5| Step: 9
Training loss: 3.8599772453308105
Validation loss: 3.5363172590732574

Epoch: 5| Step: 10
Training loss: 4.1805291175842285
Validation loss: 3.531140923500061

Epoch: 5| Step: 11
Training loss: 4.073432445526123
Validation loss: 3.5259129305680594

Epoch: 25| Step: 0
Training loss: 3.7296249866485596
Validation loss: 3.5213003357251487

Epoch: 5| Step: 1
Training loss: 3.3240818977355957
Validation loss: 3.516492952903112

Epoch: 5| Step: 2
Training loss: 4.426626682281494
Validation loss: 3.511969198783239

Epoch: 5| Step: 3
Training loss: 4.6802592277526855
Validation loss: 3.50722270210584

Epoch: 5| Step: 4
Training loss: 4.273797035217285
Validation loss: 3.5021680494149527

Epoch: 5| Step: 5
Training loss: 3.219749927520752
Validation loss: 3.4986069401105246

Epoch: 5| Step: 6
Training loss: 2.973938465118408
Validation loss: 3.494569033384323

Epoch: 5| Step: 7
Training loss: 3.9406960010528564
Validation loss: 3.491380453109741

Epoch: 5| Step: 8
Training loss: 3.527212142944336
Validation loss: 3.484287997086843

Epoch: 5| Step: 9
Training loss: 3.595867156982422
Validation loss: 3.477942258119583

Epoch: 5| Step: 10
Training loss: 3.23943829536438
Validation loss: 3.4731089373429618

Epoch: 5| Step: 11
Training loss: 0.6382855176925659
Validation loss: 3.4693590501944223

Epoch: 26| Step: 0
Training loss: 2.8849704265594482
Validation loss: 3.465987046559652

Epoch: 5| Step: 1
Training loss: 4.396324157714844
Validation loss: 3.4633929828802743

Epoch: 5| Step: 2
Training loss: 3.924788236618042
Validation loss: 3.4574472109476724

Epoch: 5| Step: 3
Training loss: 2.7123939990997314
Validation loss: 3.451899766921997

Epoch: 5| Step: 4
Training loss: 3.9462623596191406
Validation loss: 3.447140177090963

Epoch: 5| Step: 5
Training loss: 3.479253053665161
Validation loss: 3.442906767129898

Epoch: 5| Step: 6
Training loss: 4.138383388519287
Validation loss: 3.4391030768553414

Epoch: 5| Step: 7
Training loss: 3.893803358078003
Validation loss: 3.434877614180247

Epoch: 5| Step: 8
Training loss: 3.418923854827881
Validation loss: 3.430616627136866

Epoch: 5| Step: 9
Training loss: 3.261798143386841
Validation loss: 3.426590939362844

Epoch: 5| Step: 10
Training loss: 3.851666212081909
Validation loss: 3.4213758607705436

Epoch: 5| Step: 11
Training loss: 2.5605320930480957
Validation loss: 3.416030704975128

Epoch: 27| Step: 0
Training loss: 4.336283206939697
Validation loss: 3.4108202159404755

Epoch: 5| Step: 1
Training loss: 2.8505501747131348
Validation loss: 3.405875643094381

Epoch: 5| Step: 2
Training loss: 3.2030863761901855
Validation loss: 3.402019510666529

Epoch: 5| Step: 3
Training loss: 3.9733784198760986
Validation loss: 3.397007018327713

Epoch: 5| Step: 4
Training loss: 2.5598597526550293
Validation loss: 3.3928081591924033

Epoch: 5| Step: 5
Training loss: 4.419615268707275
Validation loss: 3.3877746562163034

Epoch: 5| Step: 6
Training loss: 3.871013641357422
Validation loss: 3.3837233781814575

Epoch: 5| Step: 7
Training loss: 3.5879340171813965
Validation loss: 3.378444085518519

Epoch: 5| Step: 8
Training loss: 2.9970836639404297
Validation loss: 3.373404989639918

Epoch: 5| Step: 9
Training loss: 3.741123676300049
Validation loss: 3.3691260317961373

Epoch: 5| Step: 10
Training loss: 3.7030787467956543
Validation loss: 3.365186850229899

Epoch: 5| Step: 11
Training loss: 2.9612574577331543
Validation loss: 3.3603981037934623

Epoch: 28| Step: 0
Training loss: 3.0645477771759033
Validation loss: 3.35661917924881

Epoch: 5| Step: 1
Training loss: 3.626028060913086
Validation loss: 3.351834774017334

Epoch: 5| Step: 2
Training loss: 2.962418556213379
Validation loss: 3.3475008507569632

Epoch: 5| Step: 3
Training loss: 3.3752129077911377
Validation loss: 3.34300297498703

Epoch: 5| Step: 4
Training loss: 3.528271436691284
Validation loss: 3.338188499212265

Epoch: 5| Step: 5
Training loss: 3.1661789417266846
Validation loss: 3.333849330743154

Epoch: 5| Step: 6
Training loss: 3.7718772888183594
Validation loss: 3.329266846179962

Epoch: 5| Step: 7
Training loss: 4.453207969665527
Validation loss: 3.3248099386692047

Epoch: 5| Step: 8
Training loss: 3.8423609733581543
Validation loss: 3.3204522331555686

Epoch: 5| Step: 9
Training loss: 3.2827320098876953
Validation loss: 3.31532550851504

Epoch: 5| Step: 10
Training loss: 3.532052516937256
Validation loss: 3.310777018467585

Epoch: 5| Step: 11
Training loss: 3.251744270324707
Validation loss: 3.3059873282909393

Epoch: 29| Step: 0
Training loss: 3.081944704055786
Validation loss: 3.301685651143392

Epoch: 5| Step: 1
Training loss: 3.8106560707092285
Validation loss: 3.2967515687147775

Epoch: 5| Step: 2
Training loss: 3.535069704055786
Validation loss: 3.293432891368866

Epoch: 5| Step: 3
Training loss: 3.4401168823242188
Validation loss: 3.2892135083675385

Epoch: 5| Step: 4
Training loss: 3.9098548889160156
Validation loss: 3.285310576359431

Epoch: 5| Step: 5
Training loss: 3.3099541664123535
Validation loss: 3.2809735337893167

Epoch: 5| Step: 6
Training loss: 3.328329086303711
Validation loss: 3.277660608291626

Epoch: 5| Step: 7
Training loss: 3.6301090717315674
Validation loss: 3.2737905184427896

Epoch: 5| Step: 8
Training loss: 2.384840965270996
Validation loss: 3.2698735098044076

Epoch: 5| Step: 9
Training loss: 3.286879062652588
Validation loss: 3.265723576148351

Epoch: 5| Step: 10
Training loss: 4.096987247467041
Validation loss: 3.262472619613012

Epoch: 5| Step: 11
Training loss: 4.482616424560547
Validation loss: 3.2577077051003775

Epoch: 30| Step: 0
Training loss: 3.5385756492614746
Validation loss: 3.253315359354019

Epoch: 5| Step: 1
Training loss: 3.2983269691467285
Validation loss: 3.2491287191708884

Epoch: 5| Step: 2
Training loss: 3.52604603767395
Validation loss: 3.2451519866784415

Epoch: 5| Step: 3
Training loss: 3.824272871017456
Validation loss: 3.24093829592069

Epoch: 5| Step: 4
Training loss: 4.432094573974609
Validation loss: 3.2364136377970376

Epoch: 5| Step: 5
Training loss: 3.3734688758850098
Validation loss: 3.232260455687841

Epoch: 5| Step: 6
Training loss: 3.4396393299102783
Validation loss: 3.2280911107858024

Epoch: 5| Step: 7
Training loss: 3.3730907440185547
Validation loss: 3.223162829875946

Epoch: 5| Step: 8
Training loss: 3.6716346740722656
Validation loss: 3.219044953584671

Epoch: 5| Step: 9
Training loss: 2.433126926422119
Validation loss: 3.2148931324481964

Epoch: 5| Step: 10
Training loss: 2.8812339305877686
Validation loss: 3.210301319758097

Epoch: 5| Step: 11
Training loss: 2.05591082572937
Validation loss: 3.20621395111084

Epoch: 31| Step: 0
Training loss: 3.0518689155578613
Validation loss: 3.2023806075255075

Epoch: 5| Step: 1
Training loss: 3.9633078575134277
Validation loss: 3.1985274950663247

Epoch: 5| Step: 2
Training loss: 3.817429304122925
Validation loss: 3.1947014729181924

Epoch: 5| Step: 3
Training loss: 3.211378574371338
Validation loss: 3.190134714047114

Epoch: 5| Step: 4
Training loss: 3.651170253753662
Validation loss: 3.1870216131210327

Epoch: 5| Step: 5
Training loss: 3.4923129081726074
Validation loss: 3.181928257147471

Epoch: 5| Step: 6
Training loss: 2.967618465423584
Validation loss: 3.178033004204432

Epoch: 5| Step: 7
Training loss: 3.2405216693878174
Validation loss: 3.1737963358561196

Epoch: 5| Step: 8
Training loss: 3.549238920211792
Validation loss: 3.1695095002651215

Epoch: 5| Step: 9
Training loss: 3.548609495162964
Validation loss: 3.1657916208108268

Epoch: 5| Step: 10
Training loss: 2.848684310913086
Validation loss: 3.162008692820867

Epoch: 5| Step: 11
Training loss: 1.7884242534637451
Validation loss: 3.1576041082541146

Epoch: 32| Step: 0
Training loss: 3.0609474182128906
Validation loss: 3.1538334091504416

Epoch: 5| Step: 1
Training loss: 3.3731353282928467
Validation loss: 3.150148610273997

Epoch: 5| Step: 2
Training loss: 3.376142978668213
Validation loss: 3.1467105944951377

Epoch: 5| Step: 3
Training loss: 2.994731903076172
Validation loss: 3.1434050798416138

Epoch: 5| Step: 4
Training loss: 3.167466402053833
Validation loss: 3.139504164457321

Epoch: 5| Step: 5
Training loss: 2.6120424270629883
Validation loss: 3.1350503961245217

Epoch: 5| Step: 6
Training loss: 3.254756450653076
Validation loss: 3.131796419620514

Epoch: 5| Step: 7
Training loss: 4.29238748550415
Validation loss: 3.1283735732237496

Epoch: 5| Step: 8
Training loss: 3.5715508460998535
Validation loss: 3.123956392208735

Epoch: 5| Step: 9
Training loss: 2.9327077865600586
Validation loss: 3.1199897130330405

Epoch: 5| Step: 10
Training loss: 3.768944501876831
Validation loss: 3.116139511267344

Epoch: 5| Step: 11
Training loss: 3.963717460632324
Validation loss: 3.11260520418485

Epoch: 33| Step: 0
Training loss: 3.509661912918091
Validation loss: 3.108359922965368

Epoch: 5| Step: 1
Training loss: 3.6231606006622314
Validation loss: 3.1037068367004395

Epoch: 5| Step: 2
Training loss: 2.7499420642852783
Validation loss: 3.0995524326960244

Epoch: 5| Step: 3
Training loss: 3.6187686920166016
Validation loss: 3.0959805846214294

Epoch: 5| Step: 4
Training loss: 3.6517882347106934
Validation loss: 3.0916615426540375

Epoch: 5| Step: 5
Training loss: 3.7856438159942627
Validation loss: 3.087167263031006

Epoch: 5| Step: 6
Training loss: 3.2987570762634277
Validation loss: 3.0834716260433197

Epoch: 5| Step: 7
Training loss: 2.588705539703369
Validation loss: 3.079160670439402

Epoch: 5| Step: 8
Training loss: 2.7995944023132324
Validation loss: 3.0754811465740204

Epoch: 5| Step: 9
Training loss: 3.9238338470458984
Validation loss: 3.0715025862058005

Epoch: 5| Step: 10
Training loss: 2.714554786682129
Validation loss: 3.0682607889175415

Epoch: 5| Step: 11
Training loss: 2.348371982574463
Validation loss: 3.0654077529907227

Epoch: 34| Step: 0
Training loss: 2.411332368850708
Validation loss: 3.06199645002683

Epoch: 5| Step: 1
Training loss: 3.0418076515197754
Validation loss: 3.057597746451696

Epoch: 5| Step: 2
Training loss: 3.139824390411377
Validation loss: 3.0549857318401337

Epoch: 5| Step: 3
Training loss: 2.910031318664551
Validation loss: 3.05051722129186

Epoch: 5| Step: 4
Training loss: 3.6151440143585205
Validation loss: 3.0472089648246765

Epoch: 5| Step: 5
Training loss: 3.971621036529541
Validation loss: 3.0440041422843933

Epoch: 5| Step: 6
Training loss: 2.848191261291504
Validation loss: 3.0402762591838837

Epoch: 5| Step: 7
Training loss: 3.243968963623047
Validation loss: 3.0369760195414224

Epoch: 5| Step: 8
Training loss: 3.443502902984619
Validation loss: 3.0337627828121185

Epoch: 5| Step: 9
Training loss: 3.497793197631836
Validation loss: 3.0294113556543985

Epoch: 5| Step: 10
Training loss: 3.4100863933563232
Validation loss: 3.0255022843678794

Epoch: 5| Step: 11
Training loss: 3.3977460861206055
Validation loss: 3.0222178300221763

Epoch: 35| Step: 0
Training loss: 2.5765140056610107
Validation loss: 3.018336594104767

Epoch: 5| Step: 1
Training loss: 2.9189319610595703
Validation loss: 3.01424577832222

Epoch: 5| Step: 2
Training loss: 3.508774518966675
Validation loss: 3.010625720024109

Epoch: 5| Step: 3
Training loss: 2.873436450958252
Validation loss: 3.0070558885733285

Epoch: 5| Step: 4
Training loss: 3.4745967388153076
Validation loss: 3.0038366119066873

Epoch: 5| Step: 5
Training loss: 3.1691396236419678
Validation loss: 2.999711960554123

Epoch: 5| Step: 6
Training loss: 3.2070682048797607
Validation loss: 2.996247629324595

Epoch: 5| Step: 7
Training loss: 3.4784228801727295
Validation loss: 2.9918210804462433

Epoch: 5| Step: 8
Training loss: 3.083253860473633
Validation loss: 2.988621066013972

Epoch: 5| Step: 9
Training loss: 3.2330422401428223
Validation loss: 2.9843889077504477

Epoch: 5| Step: 10
Training loss: 3.470574140548706
Validation loss: 2.980702737967173

Epoch: 5| Step: 11
Training loss: 3.846356153488159
Validation loss: 2.977233658234278

Epoch: 36| Step: 0
Training loss: 3.1742236614227295
Validation loss: 2.973683794339498

Epoch: 5| Step: 1
Training loss: 3.2972209453582764
Validation loss: 2.969804674386978

Epoch: 5| Step: 2
Training loss: 3.4236464500427246
Validation loss: 2.966830720504125

Epoch: 5| Step: 3
Training loss: 2.812004566192627
Validation loss: 2.9629767537117004

Epoch: 5| Step: 4
Training loss: 3.6019039154052734
Validation loss: 2.9593678017457328

Epoch: 5| Step: 5
Training loss: 3.4775962829589844
Validation loss: 2.956242630879084

Epoch: 5| Step: 6
Training loss: 2.3409264087677
Validation loss: 2.9519062538941703

Epoch: 5| Step: 7
Training loss: 2.9008126258850098
Validation loss: 2.9486085375150046

Epoch: 5| Step: 8
Training loss: 3.0796332359313965
Validation loss: 2.944734593232473

Epoch: 5| Step: 9
Training loss: 3.062825918197632
Validation loss: 2.941519339879354

Epoch: 5| Step: 10
Training loss: 3.639411449432373
Validation loss: 2.9378513991832733

Epoch: 5| Step: 11
Training loss: 2.6432416439056396
Validation loss: 2.9382051626841226

Epoch: 37| Step: 0
Training loss: 3.273024082183838
Validation loss: 2.9348978201548257

Epoch: 5| Step: 1
Training loss: 2.8698723316192627
Validation loss: 2.937871962785721

Epoch: 5| Step: 2
Training loss: 2.94987154006958
Validation loss: 2.9238863388697305

Epoch: 5| Step: 3
Training loss: 2.5305628776550293
Validation loss: 2.9209396839141846

Epoch: 5| Step: 4
Training loss: 3.064608573913574
Validation loss: 2.9179697831471763

Epoch: 5| Step: 5
Training loss: 3.232957124710083
Validation loss: 2.9172591269016266

Epoch: 5| Step: 6
Training loss: 3.964353084564209
Validation loss: 2.922278513511022

Epoch: 5| Step: 7
Training loss: 3.295740842819214
Validation loss: 2.9086769819259644

Epoch: 5| Step: 8
Training loss: 3.1459250450134277
Validation loss: 2.9058719277381897

Epoch: 5| Step: 9
Training loss: 2.668692111968994
Validation loss: 2.9051847755908966

Epoch: 5| Step: 10
Training loss: 3.715947389602661
Validation loss: 2.9048353334267936

Epoch: 5| Step: 11
Training loss: 1.303222894668579
Validation loss: 2.904101034005483

Epoch: 38| Step: 0
Training loss: 2.6327974796295166
Validation loss: 2.899343599875768

Epoch: 5| Step: 1
Training loss: 2.5144996643066406
Validation loss: 2.8949457705020905

Epoch: 5| Step: 2
Training loss: 2.5682296752929688
Validation loss: 2.8915224770704904

Epoch: 5| Step: 3
Training loss: 3.453401565551758
Validation loss: 2.8915417393048606

Epoch: 5| Step: 4
Training loss: 3.431117534637451
Validation loss: 2.8909255266189575

Epoch: 5| Step: 5
Training loss: 2.9610421657562256
Validation loss: 2.885627289613088

Epoch: 5| Step: 6
Training loss: 3.097790479660034
Validation loss: 2.879106958707174

Epoch: 5| Step: 7
Training loss: 2.926072120666504
Validation loss: 2.8747412463029227

Epoch: 5| Step: 8
Training loss: 3.6380488872528076
Validation loss: 2.871368855237961

Epoch: 5| Step: 9
Training loss: 3.1633949279785156
Validation loss: 2.867945432662964

Epoch: 5| Step: 10
Training loss: 3.6176934242248535
Validation loss: 2.864509572585424

Epoch: 5| Step: 11
Training loss: 2.8199105262756348
Validation loss: 2.8608483572800956

Epoch: 39| Step: 0
Training loss: 3.02282977104187
Validation loss: 2.856971651315689

Epoch: 5| Step: 1
Training loss: 3.533224105834961
Validation loss: 2.8532070418198905

Epoch: 5| Step: 2
Training loss: 2.0817036628723145
Validation loss: 2.8502423564592996

Epoch: 5| Step: 3
Training loss: 3.67132568359375
Validation loss: 2.8469230830669403

Epoch: 5| Step: 4
Training loss: 2.8458428382873535
Validation loss: 2.843754311402639

Epoch: 5| Step: 5
Training loss: 3.2735512256622314
Validation loss: 2.8396272361278534

Epoch: 5| Step: 6
Training loss: 3.2064144611358643
Validation loss: 2.8363627990086875

Epoch: 5| Step: 7
Training loss: 3.259220600128174
Validation loss: 2.833323915799459

Epoch: 5| Step: 8
Training loss: 3.127075672149658
Validation loss: 2.8299264709154763

Epoch: 5| Step: 9
Training loss: 2.2816805839538574
Validation loss: 2.8266373574733734

Epoch: 5| Step: 10
Training loss: 3.2258315086364746
Validation loss: 2.8227302630742392

Epoch: 5| Step: 11
Training loss: 3.0767464637756348
Validation loss: 2.8194143374760947

Epoch: 40| Step: 0
Training loss: 3.3196158409118652
Validation loss: 2.8166027665138245

Epoch: 5| Step: 1
Training loss: 3.0183634757995605
Validation loss: 2.8127598464488983

Epoch: 5| Step: 2
Training loss: 2.6627697944641113
Validation loss: 2.8096357782681785

Epoch: 5| Step: 3
Training loss: 3.048788547515869
Validation loss: 2.8067634999752045

Epoch: 5| Step: 4
Training loss: 3.2527987957000732
Validation loss: 2.8030970295270285

Epoch: 5| Step: 5
Training loss: 3.3123786449432373
Validation loss: 2.7999529242515564

Epoch: 5| Step: 6
Training loss: 3.1446640491485596
Validation loss: 2.7974636952082315

Epoch: 5| Step: 7
Training loss: 2.577268123626709
Validation loss: 2.7951196432113647

Epoch: 5| Step: 8
Training loss: 3.5433692932128906
Validation loss: 2.791941155989965

Epoch: 5| Step: 9
Training loss: 2.419011354446411
Validation loss: 2.789229025443395

Epoch: 5| Step: 10
Training loss: 2.6191697120666504
Validation loss: 2.7856101393699646

Epoch: 5| Step: 11
Training loss: 4.16500997543335
Validation loss: 2.784104456504186

Epoch: 41| Step: 0
Training loss: 2.9952118396759033
Validation loss: 2.7804148097833

Epoch: 5| Step: 1
Training loss: 2.769381046295166
Validation loss: 2.777196874221166

Epoch: 5| Step: 2
Training loss: 3.3052616119384766
Validation loss: 2.7741249104340873

Epoch: 5| Step: 3
Training loss: 2.9818036556243896
Validation loss: 2.7693247695763907

Epoch: 5| Step: 4
Training loss: 3.0291147232055664
Validation loss: 2.7670230766137442

Epoch: 5| Step: 5
Training loss: 2.6540112495422363
Validation loss: 2.763667662938436

Epoch: 5| Step: 6
Training loss: 3.1200618743896484
Validation loss: 2.761175980170568

Epoch: 5| Step: 7
Training loss: 2.9967074394226074
Validation loss: 2.758586178223292

Epoch: 5| Step: 8
Training loss: 2.885141134262085
Validation loss: 2.755790869394938

Epoch: 5| Step: 9
Training loss: 2.8990774154663086
Validation loss: 2.7524257202943168

Epoch: 5| Step: 10
Training loss: 3.3464043140411377
Validation loss: 2.7501418193181357

Epoch: 5| Step: 11
Training loss: 1.7062286138534546
Validation loss: 2.747889826695124

Epoch: 42| Step: 0
Training loss: 2.611489772796631
Validation loss: 2.7449105083942413

Epoch: 5| Step: 1
Training loss: 2.7947194576263428
Validation loss: 2.739942987759908

Epoch: 5| Step: 2
Training loss: 2.780269145965576
Validation loss: 2.737656384706497

Epoch: 5| Step: 3
Training loss: 2.3595759868621826
Validation loss: 2.7347564697265625

Epoch: 5| Step: 4
Training loss: 3.173262119293213
Validation loss: 2.7313494284947715

Epoch: 5| Step: 5
Training loss: 3.309570789337158
Validation loss: 2.728364020586014

Epoch: 5| Step: 6
Training loss: 3.105187177658081
Validation loss: 2.724813828865687

Epoch: 5| Step: 7
Training loss: 2.6199729442596436
Validation loss: 2.7232855955759683

Epoch: 5| Step: 8
Training loss: 3.1919593811035156
Validation loss: 2.718619465827942

Epoch: 5| Step: 9
Training loss: 3.115527629852295
Validation loss: 2.718262235323588

Epoch: 5| Step: 10
Training loss: 3.2878785133361816
Validation loss: 2.7152239084243774

Epoch: 5| Step: 11
Training loss: 2.7844886779785156
Validation loss: 2.711995005607605

Epoch: 43| Step: 0
Training loss: 2.3400256633758545
Validation loss: 2.709040413300196

Epoch: 5| Step: 1
Training loss: 2.8654491901397705
Validation loss: 2.706176981329918

Epoch: 5| Step: 2
Training loss: 2.5255661010742188
Validation loss: 2.701229433218638

Epoch: 5| Step: 3
Training loss: 2.9000906944274902
Validation loss: 2.6986686289310455

Epoch: 5| Step: 4
Training loss: 2.470923662185669
Validation loss: 2.6966172456741333

Epoch: 5| Step: 5
Training loss: 2.5368449687957764
Validation loss: 2.694729745388031

Epoch: 5| Step: 6
Training loss: 2.95759654045105
Validation loss: 2.6919621328512826

Epoch: 5| Step: 7
Training loss: 3.5828299522399902
Validation loss: 2.6883894205093384

Epoch: 5| Step: 8
Training loss: 3.3526313304901123
Validation loss: 2.6857928037643433

Epoch: 5| Step: 9
Training loss: 2.780914306640625
Validation loss: 2.682905296484629

Epoch: 5| Step: 10
Training loss: 3.6483445167541504
Validation loss: 2.6807141502698264

Epoch: 5| Step: 11
Training loss: 2.6791183948516846
Validation loss: 2.6767055292924247

Epoch: 44| Step: 0
Training loss: 3.1399917602539062
Validation loss: 2.6727248330911

Epoch: 5| Step: 1
Training loss: 2.9314045906066895
Validation loss: 2.6699138979117074

Epoch: 5| Step: 2
Training loss: 2.9783103466033936
Validation loss: 2.6674938251574836

Epoch: 5| Step: 3
Training loss: 3.1412174701690674
Validation loss: 2.6664799600839615

Epoch: 5| Step: 4
Training loss: 1.8916294574737549
Validation loss: 2.6584576616684594

Epoch: 5| Step: 5
Training loss: 2.816032648086548
Validation loss: 2.65559450785319

Epoch: 5| Step: 6
Training loss: 2.9983978271484375
Validation loss: 2.6513493061065674

Epoch: 5| Step: 7
Training loss: 2.739842653274536
Validation loss: 2.6509190499782562

Epoch: 5| Step: 8
Training loss: 2.8916871547698975
Validation loss: 2.6463895738124847

Epoch: 5| Step: 9
Training loss: 2.889652967453003
Validation loss: 2.6438637723525367

Epoch: 5| Step: 10
Training loss: 3.104863405227661
Validation loss: 2.6416484713554382

Epoch: 5| Step: 11
Training loss: 2.7045156955718994
Validation loss: 2.6367857356866202

Epoch: 45| Step: 0
Training loss: 2.809138298034668
Validation loss: 2.6328563491503396

Epoch: 5| Step: 1
Training loss: 2.832939863204956
Validation loss: 2.6321761508782706

Epoch: 5| Step: 2
Training loss: 2.25657057762146
Validation loss: 2.6324958304564157

Epoch: 5| Step: 3
Training loss: 2.2500293254852295
Validation loss: 2.626833309729894

Epoch: 5| Step: 4
Training loss: 2.5427846908569336
Validation loss: 2.622275561094284

Epoch: 5| Step: 5
Training loss: 3.0758018493652344
Validation loss: 2.6209231118361154

Epoch: 5| Step: 6
Training loss: 2.9879631996154785
Validation loss: 2.6160577535629272

Epoch: 5| Step: 7
Training loss: 3.3979506492614746
Validation loss: 2.612870305776596

Epoch: 5| Step: 8
Training loss: 3.10481333732605
Validation loss: 2.6107484300931296

Epoch: 5| Step: 9
Training loss: 2.9594218730926514
Validation loss: 2.6078532338142395

Epoch: 5| Step: 10
Training loss: 2.6478610038757324
Validation loss: 2.603636691967646

Epoch: 5| Step: 11
Training loss: 3.6291213035583496
Validation loss: 2.60147163271904

Epoch: 46| Step: 0
Training loss: 2.8286495208740234
Validation loss: 2.597422609726588

Epoch: 5| Step: 1
Training loss: 2.6752266883850098
Validation loss: 2.593747357527415

Epoch: 5| Step: 2
Training loss: 2.9582247734069824
Validation loss: 2.590188374121984

Epoch: 5| Step: 3
Training loss: 2.5919690132141113
Validation loss: 2.58696057399114

Epoch: 5| Step: 4
Training loss: 2.871239185333252
Validation loss: 2.5843925376733146

Epoch: 5| Step: 5
Training loss: 2.979750871658325
Validation loss: 2.5818958282470703

Epoch: 5| Step: 6
Training loss: 3.3140838146209717
Validation loss: 2.577540636062622

Epoch: 5| Step: 7
Training loss: 2.5246827602386475
Validation loss: 2.575929512580236

Epoch: 5| Step: 8
Training loss: 3.038125991821289
Validation loss: 2.5704406201839447

Epoch: 5| Step: 9
Training loss: 2.281918525695801
Validation loss: 2.566520571708679

Epoch: 5| Step: 10
Training loss: 2.4809532165527344
Validation loss: 2.5687961081663766

Epoch: 5| Step: 11
Training loss: 3.1192071437835693
Validation loss: 2.5628441671530404

Epoch: 47| Step: 0
Training loss: 2.5245800018310547
Validation loss: 2.566309670607249

Epoch: 5| Step: 1
Training loss: 2.5470879077911377
Validation loss: 2.5683870116869607

Epoch: 5| Step: 2
Training loss: 2.851937770843506
Validation loss: 2.559096574783325

Epoch: 5| Step: 3
Training loss: 3.202326536178589
Validation loss: 2.5511395732561746

Epoch: 5| Step: 4
Training loss: 2.7231497764587402
Validation loss: 2.5478342473506927

Epoch: 5| Step: 5
Training loss: 2.395005941390991
Validation loss: 2.545244887471199

Epoch: 5| Step: 6
Training loss: 3.035400867462158
Validation loss: 2.5431007742881775

Epoch: 5| Step: 7
Training loss: 1.997615098953247
Validation loss: 2.539265771706899

Epoch: 5| Step: 8
Training loss: 2.8081321716308594
Validation loss: 2.53716712196668

Epoch: 5| Step: 9
Training loss: 2.7750027179718018
Validation loss: 2.535896420478821

Epoch: 5| Step: 10
Training loss: 3.229137897491455
Validation loss: 2.531872828801473

Epoch: 5| Step: 11
Training loss: 3.318905830383301
Validation loss: 2.5302015940348306

Epoch: 48| Step: 0
Training loss: 3.2907652854919434
Validation loss: 2.5262518425782523

Epoch: 5| Step: 1
Training loss: 2.3548617362976074
Validation loss: 2.5235197444756827

Epoch: 5| Step: 2
Training loss: 2.3827614784240723
Validation loss: 2.520176202058792

Epoch: 5| Step: 3
Training loss: 2.5685372352600098
Validation loss: 2.5173593362172446

Epoch: 5| Step: 4
Training loss: 3.0734314918518066
Validation loss: 2.513895054658254

Epoch: 5| Step: 5
Training loss: 2.560716152191162
Validation loss: 2.5125511387983956

Epoch: 5| Step: 6
Training loss: 2.5278334617614746
Validation loss: 2.5087008277575173

Epoch: 5| Step: 7
Training loss: 2.6308157444000244
Validation loss: 2.506518006324768

Epoch: 5| Step: 8
Training loss: 2.5913095474243164
Validation loss: 2.507119834423065

Epoch: 5| Step: 9
Training loss: 3.1476337909698486
Validation loss: 2.5029298464457193

Epoch: 5| Step: 10
Training loss: 2.479396343231201
Validation loss: 2.503928244113922

Epoch: 5| Step: 11
Training loss: 3.552966594696045
Validation loss: 2.4996262391408286

Epoch: 49| Step: 0
Training loss: 2.0761666297912598
Validation loss: 2.492643783489863

Epoch: 5| Step: 1
Training loss: 3.059678554534912
Validation loss: 2.4899777273337045

Epoch: 5| Step: 2
Training loss: 2.7306137084960938
Validation loss: 2.4892377257347107

Epoch: 5| Step: 3
Training loss: 2.6242456436157227
Validation loss: 2.4853301346302032

Epoch: 5| Step: 4
Training loss: 3.6260485649108887
Validation loss: 2.485210915406545

Epoch: 5| Step: 5
Training loss: 2.6496670246124268
Validation loss: 2.482212722301483

Epoch: 5| Step: 6
Training loss: 2.866121292114258
Validation loss: 2.478519876797994

Epoch: 5| Step: 7
Training loss: 2.2048466205596924
Validation loss: 2.4762994845708213

Epoch: 5| Step: 8
Training loss: 2.8262410163879395
Validation loss: 2.473261992136637

Epoch: 5| Step: 9
Training loss: 2.5845067501068115
Validation loss: 2.468144486347834

Epoch: 5| Step: 10
Training loss: 2.0360682010650635
Validation loss: 2.4674484630425773

Epoch: 5| Step: 11
Training loss: 3.2231152057647705
Validation loss: 2.463384677966436

Epoch: 50| Step: 0
Training loss: 2.9197402000427246
Validation loss: 2.4631420969963074

Epoch: 5| Step: 1
Training loss: 3.0271573066711426
Validation loss: 2.4610398014386496

Epoch: 5| Step: 2
Training loss: 2.703800678253174
Validation loss: 2.457898259162903

Epoch: 5| Step: 3
Training loss: 2.5963451862335205
Validation loss: 2.4533142348130546

Epoch: 5| Step: 4
Training loss: 2.6199817657470703
Validation loss: 2.446678320566813

Epoch: 5| Step: 5
Training loss: 3.2502079010009766
Validation loss: 2.448379432161649

Epoch: 5| Step: 6
Training loss: 2.547269344329834
Validation loss: 2.4442778478066125

Epoch: 5| Step: 7
Training loss: 2.1881327629089355
Validation loss: 2.4425001045068107

Epoch: 5| Step: 8
Training loss: 3.0098209381103516
Validation loss: 2.4369721114635468

Epoch: 5| Step: 9
Training loss: 1.9556214809417725
Validation loss: 2.4366656690835953

Epoch: 5| Step: 10
Training loss: 2.1564033031463623
Validation loss: 2.4330649822950363

Epoch: 5| Step: 11
Training loss: 2.9631218910217285
Validation loss: 2.4330855011940002

Epoch: 51| Step: 0
Training loss: 2.780041456222534
Validation loss: 2.4330974022547402

Epoch: 5| Step: 1
Training loss: 2.1931934356689453
Validation loss: 2.425700689355532

Epoch: 5| Step: 2
Training loss: 2.2795779705047607
Validation loss: 2.424773653348287

Epoch: 5| Step: 3
Training loss: 3.266946315765381
Validation loss: 2.4228100081284842

Epoch: 5| Step: 4
Training loss: 2.557185649871826
Validation loss: 2.419628848632177

Epoch: 5| Step: 5
Training loss: 2.6050074100494385
Validation loss: 2.415374825398127

Epoch: 5| Step: 6
Training loss: 2.984680652618408
Validation loss: 2.4165262281894684

Epoch: 5| Step: 7
Training loss: 2.229565382003784
Validation loss: 2.4124391178290048

Epoch: 5| Step: 8
Training loss: 2.327226161956787
Validation loss: 2.4115534027417502

Epoch: 5| Step: 9
Training loss: 2.5159101486206055
Validation loss: 2.406943400700887

Epoch: 5| Step: 10
Training loss: 3.0137832164764404
Validation loss: 2.407604475816091

Epoch: 5| Step: 11
Training loss: 1.9225146770477295
Validation loss: 2.4036226073900857

Epoch: 52| Step: 0
Training loss: 2.59318208694458
Validation loss: 2.402571981151899

Epoch: 5| Step: 1
Training loss: 3.1505348682403564
Validation loss: 2.397345374027888

Epoch: 5| Step: 2
Training loss: 2.8634915351867676
Validation loss: 2.396100401878357

Epoch: 5| Step: 3
Training loss: 2.5180485248565674
Validation loss: 2.3930144210656485

Epoch: 5| Step: 4
Training loss: 2.7565410137176514
Validation loss: 2.3901447057724

Epoch: 5| Step: 5
Training loss: 1.6790730953216553
Validation loss: 2.386718511581421

Epoch: 5| Step: 6
Training loss: 2.92472767829895
Validation loss: 2.390478869279226

Epoch: 5| Step: 7
Training loss: 2.4712536334991455
Validation loss: 2.38632270693779

Epoch: 5| Step: 8
Training loss: 2.590846538543701
Validation loss: 2.3838835954666138

Epoch: 5| Step: 9
Training loss: 2.310575246810913
Validation loss: 2.381727397441864

Epoch: 5| Step: 10
Training loss: 2.322425365447998
Validation loss: 2.3806534856557846

Epoch: 5| Step: 11
Training loss: 3.2759604454040527
Validation loss: 2.3744205087423325

Epoch: 53| Step: 0
Training loss: 2.4603939056396484
Validation loss: 2.374083479245504

Epoch: 5| Step: 1
Training loss: 2.2461466789245605
Validation loss: 2.3698394993940988

Epoch: 5| Step: 2
Training loss: 2.6392874717712402
Validation loss: 2.371236115694046

Epoch: 5| Step: 3
Training loss: 2.6478123664855957
Validation loss: 2.3666072885195413

Epoch: 5| Step: 4
Training loss: 2.349273681640625
Validation loss: 2.358820140361786

Epoch: 5| Step: 5
Training loss: 2.6897177696228027
Validation loss: 2.356980820496877

Epoch: 5| Step: 6
Training loss: 2.418398380279541
Validation loss: 2.3564016918341317

Epoch: 5| Step: 7
Training loss: 2.633791446685791
Validation loss: 2.3539088368415833

Epoch: 5| Step: 8
Training loss: 2.5370595455169678
Validation loss: 2.3504798909028373

Epoch: 5| Step: 9
Training loss: 2.9220657348632812
Validation loss: 2.3541185359160104

Epoch: 5| Step: 10
Training loss: 2.2925846576690674
Validation loss: 2.346134533484777

Epoch: 5| Step: 11
Training loss: 2.9751765727996826
Validation loss: 2.3437744677066803

Epoch: 54| Step: 0
Training loss: 2.851513385772705
Validation loss: 2.3413537442684174

Epoch: 5| Step: 1
Training loss: 2.6258456707000732
Validation loss: 2.3376601388057074

Epoch: 5| Step: 2
Training loss: 2.669675350189209
Validation loss: 2.3385912626981735

Epoch: 5| Step: 3
Training loss: 2.4455113410949707
Validation loss: 2.336257830262184

Epoch: 5| Step: 4
Training loss: 2.5603270530700684
Validation loss: 2.3341822624206543

Epoch: 5| Step: 5
Training loss: 2.1841471195220947
Validation loss: 2.3304053445657096

Epoch: 5| Step: 6
Training loss: 2.784329652786255
Validation loss: 2.330877502759298

Epoch: 5| Step: 7
Training loss: 2.439661741256714
Validation loss: 2.3261448244253793

Epoch: 5| Step: 8
Training loss: 2.2729411125183105
Validation loss: 2.325145830710729

Epoch: 5| Step: 9
Training loss: 2.6952877044677734
Validation loss: 2.321499685446421

Epoch: 5| Step: 10
Training loss: 1.9660499095916748
Validation loss: 2.3214206794897714

Epoch: 5| Step: 11
Training loss: 2.808309316635132
Validation loss: 2.3150748312473297

Epoch: 55| Step: 0
Training loss: 2.5329525470733643
Validation loss: 2.313596948981285

Epoch: 5| Step: 1
Training loss: 2.12553334236145
Validation loss: 2.3126767675081887

Epoch: 5| Step: 2
Training loss: 2.5608839988708496
Validation loss: 2.3101260562737784

Epoch: 5| Step: 3
Training loss: 3.0936405658721924
Validation loss: 2.310279925664266

Epoch: 5| Step: 4
Training loss: 2.183753490447998
Validation loss: 2.303603872656822

Epoch: 5| Step: 5
Training loss: 1.7183507680892944
Validation loss: 2.304208298524221

Epoch: 5| Step: 6
Training loss: 2.7302379608154297
Validation loss: 2.304873729745547

Epoch: 5| Step: 7
Training loss: 2.452747344970703
Validation loss: 2.3011579314867654

Epoch: 5| Step: 8
Training loss: 2.7682671546936035
Validation loss: 2.2972523073355355

Epoch: 5| Step: 9
Training loss: 2.840226411819458
Validation loss: 2.293397009372711

Epoch: 5| Step: 10
Training loss: 1.8389228582382202
Validation loss: 2.289085408051809

Epoch: 5| Step: 11
Training loss: 4.075830459594727
Validation loss: 2.2888292322556176

Epoch: 56| Step: 0
Training loss: 2.4291653633117676
Validation loss: 2.2882011979818344

Epoch: 5| Step: 1
Training loss: 2.3416569232940674
Validation loss: 2.281772881746292

Epoch: 5| Step: 2
Training loss: 2.377403736114502
Validation loss: 2.278372198343277

Epoch: 5| Step: 3
Training loss: 2.553450107574463
Validation loss: 2.281524876753489

Epoch: 5| Step: 4
Training loss: 2.0839972496032715
Validation loss: 2.2797576636075974

Epoch: 5| Step: 5
Training loss: 2.957019329071045
Validation loss: 2.278517002860705

Epoch: 5| Step: 6
Training loss: 2.417118549346924
Validation loss: 2.2743740578492484

Epoch: 5| Step: 7
Training loss: 2.307709217071533
Validation loss: 2.272652824719747

Epoch: 5| Step: 8
Training loss: 2.4842615127563477
Validation loss: 2.270120620727539

Epoch: 5| Step: 9
Training loss: 2.3834762573242188
Validation loss: 2.2696442852417626

Epoch: 5| Step: 10
Training loss: 2.4696450233459473
Validation loss: 2.2700619995594025

Epoch: 5| Step: 11
Training loss: 3.0559091567993164
Validation loss: 2.2665277471144996

Epoch: 57| Step: 0
Training loss: 2.641791820526123
Validation loss: 2.2625489433606467

Epoch: 5| Step: 1
Training loss: 2.641066312789917
Validation loss: 2.2531855404376984

Epoch: 5| Step: 2
Training loss: 2.271789789199829
Validation loss: 2.2567155162493386

Epoch: 5| Step: 3
Training loss: 2.2357282638549805
Validation loss: 2.253059431910515

Epoch: 5| Step: 4
Training loss: 1.978742241859436
Validation loss: 2.2480295101801553

Epoch: 5| Step: 5
Training loss: 2.6806344985961914
Validation loss: 2.2485523174206414

Epoch: 5| Step: 6
Training loss: 2.5323197841644287
Validation loss: 2.239422763387362

Epoch: 5| Step: 7
Training loss: 2.200629711151123
Validation loss: 2.2422391027212143

Epoch: 5| Step: 8
Training loss: 2.2769923210144043
Validation loss: 2.250076582034429

Epoch: 5| Step: 9
Training loss: 2.804105758666992
Validation loss: 2.259852886199951

Epoch: 5| Step: 10
Training loss: 2.287950038909912
Validation loss: 2.2496986985206604

Epoch: 5| Step: 11
Training loss: 2.0251989364624023
Validation loss: 2.249981294075648

Epoch: 58| Step: 0
Training loss: 2.557105302810669
Validation loss: 2.270067483186722

Epoch: 5| Step: 1
Training loss: 2.8620877265930176
Validation loss: 2.2862763156493506

Epoch: 5| Step: 2
Training loss: 2.938263416290283
Validation loss: 2.3419766823450723

Epoch: 5| Step: 3
Training loss: 2.2770614624023438
Validation loss: 2.2932428369919458

Epoch: 5| Step: 4
Training loss: 2.832632303237915
Validation loss: 2.271113852659861

Epoch: 5| Step: 5
Training loss: 1.8540821075439453
Validation loss: 2.2513001014788947

Epoch: 5| Step: 6
Training loss: 2.5085275173187256
Validation loss: 2.2364220718542733

Epoch: 5| Step: 7
Training loss: 2.3326144218444824
Validation loss: 2.24094595015049

Epoch: 5| Step: 8
Training loss: 2.2382450103759766
Validation loss: 2.2412628829479218

Epoch: 5| Step: 9
Training loss: 2.0044713020324707
Validation loss: 2.2462686697642007

Epoch: 5| Step: 10
Training loss: 2.3679873943328857
Validation loss: 2.242254227399826

Epoch: 5| Step: 11
Training loss: 1.944818377494812
Validation loss: 2.230325629313787

Epoch: 59| Step: 0
Training loss: 2.3536975383758545
Validation loss: 2.218169172604879

Epoch: 5| Step: 1
Training loss: 2.278661012649536
Validation loss: 2.212531199057897

Epoch: 5| Step: 2
Training loss: 2.184673547744751
Validation loss: 2.2122851510842643

Epoch: 5| Step: 3
Training loss: 2.6306300163269043
Validation loss: 2.2054984271526337

Epoch: 5| Step: 4
Training loss: 2.5353026390075684
Validation loss: 2.203310618797938

Epoch: 5| Step: 5
Training loss: 2.1322643756866455
Validation loss: 2.201768845319748

Epoch: 5| Step: 6
Training loss: 2.417924165725708
Validation loss: 2.1995884478092194

Epoch: 5| Step: 7
Training loss: 2.9552764892578125
Validation loss: 2.197568287452062

Epoch: 5| Step: 8
Training loss: 2.5243003368377686
Validation loss: 2.199656138817469

Epoch: 5| Step: 9
Training loss: 1.922838568687439
Validation loss: 2.1904537280400596

Epoch: 5| Step: 10
Training loss: 1.89413321018219
Validation loss: 2.1922579606374106

Epoch: 5| Step: 11
Training loss: 3.059547185897827
Validation loss: 2.1927022536595664

Epoch: 60| Step: 0
Training loss: 2.618115186691284
Validation loss: 2.1886879752079644

Epoch: 5| Step: 1
Training loss: 1.8700523376464844
Validation loss: 2.2023386110862098

Epoch: 5| Step: 2
Training loss: 2.529017448425293
Validation loss: 2.218234027425448

Epoch: 5| Step: 3
Training loss: 1.9940284490585327
Validation loss: 2.2371920148531594

Epoch: 5| Step: 4
Training loss: 3.003859043121338
Validation loss: 2.2152975648641586

Epoch: 5| Step: 5
Training loss: 2.7198092937469482
Validation loss: 2.197364419698715

Epoch: 5| Step: 6
Training loss: 2.3068675994873047
Validation loss: 2.175936241944631

Epoch: 5| Step: 7
Training loss: 2.1215591430664062
Validation loss: 2.1736844182014465

Epoch: 5| Step: 8
Training loss: 2.323477268218994
Validation loss: 2.1723927011092505

Epoch: 5| Step: 9
Training loss: 2.037726879119873
Validation loss: 2.169441362222036

Epoch: 5| Step: 10
Training loss: 2.356428384780884
Validation loss: 2.167407770951589

Epoch: 5| Step: 11
Training loss: 2.5836341381073
Validation loss: 2.1703827579816184

Epoch: 61| Step: 0
Training loss: 2.2967283725738525
Validation loss: 2.166824907064438

Epoch: 5| Step: 1
Training loss: 2.177783727645874
Validation loss: 2.1729796131451926

Epoch: 5| Step: 2
Training loss: 2.4523181915283203
Validation loss: 2.1748873541752496

Epoch: 5| Step: 3
Training loss: 2.326404094696045
Validation loss: 2.17826018234094

Epoch: 5| Step: 4
Training loss: 2.1637721061706543
Validation loss: 2.170364727576574

Epoch: 5| Step: 5
Training loss: 2.09748911857605
Validation loss: 2.1658614526192346

Epoch: 5| Step: 6
Training loss: 2.4822769165039062
Validation loss: 2.1627791126569114

Epoch: 5| Step: 7
Training loss: 2.300402879714966
Validation loss: 2.1630955984195075

Epoch: 5| Step: 8
Training loss: 2.7290236949920654
Validation loss: 2.160806640982628

Epoch: 5| Step: 9
Training loss: 2.0674264430999756
Validation loss: 2.1585406760374704

Epoch: 5| Step: 10
Training loss: 2.412421464920044
Validation loss: 2.1609969238440194

Epoch: 5| Step: 11
Training loss: 3.129896402359009
Validation loss: 2.163021077712377

Epoch: 62| Step: 0
Training loss: 2.3483808040618896
Validation loss: 2.1579147229592004

Epoch: 5| Step: 1
Training loss: 2.188877820968628
Validation loss: 2.1565287659565606

Epoch: 5| Step: 2
Training loss: 2.3575031757354736
Validation loss: 2.1508445044358573

Epoch: 5| Step: 3
Training loss: 2.5531609058380127
Validation loss: 2.1472295373678207

Epoch: 5| Step: 4
Training loss: 2.0280895233154297
Validation loss: 2.1447634796301522

Epoch: 5| Step: 5
Training loss: 2.7632076740264893
Validation loss: 2.1406058420737586

Epoch: 5| Step: 6
Training loss: 1.852057695388794
Validation loss: 2.1403599629799523

Epoch: 5| Step: 7
Training loss: 2.3896641731262207
Validation loss: 2.142632653315862

Epoch: 5| Step: 8
Training loss: 1.8982881307601929
Validation loss: 2.137022942304611

Epoch: 5| Step: 9
Training loss: 2.4499428272247314
Validation loss: 2.1423891335725784

Epoch: 5| Step: 10
Training loss: 2.5930569171905518
Validation loss: 2.142973060409228

Epoch: 5| Step: 11
Training loss: 2.0264341831207275
Validation loss: 2.1456185777982077

Epoch: 63| Step: 0
Training loss: 2.2170543670654297
Validation loss: 2.1557727654774985

Epoch: 5| Step: 1
Training loss: 2.3197054862976074
Validation loss: 2.16108567516009

Epoch: 5| Step: 2
Training loss: 1.8390098810195923
Validation loss: 2.1591280500094094

Epoch: 5| Step: 3
Training loss: 2.7919232845306396
Validation loss: 2.1616714199384055

Epoch: 5| Step: 4
Training loss: 2.5365865230560303
Validation loss: 2.148611764113108

Epoch: 5| Step: 5
Training loss: 2.3906302452087402
Validation loss: 2.148252914349238

Epoch: 5| Step: 6
Training loss: 2.056648015975952
Validation loss: 2.141190156340599

Epoch: 5| Step: 7
Training loss: 2.225947380065918
Validation loss: 2.131698747475942

Epoch: 5| Step: 8
Training loss: 2.2642576694488525
Validation loss: 2.1296387811501822

Epoch: 5| Step: 9
Training loss: 2.3443729877471924
Validation loss: 2.128558397293091

Epoch: 5| Step: 10
Training loss: 2.4812114238739014
Validation loss: 2.127399429678917

Epoch: 5| Step: 11
Training loss: 2.63875150680542
Validation loss: 2.125023772319158

Epoch: 64| Step: 0
Training loss: 2.187894105911255
Validation loss: 2.1264345198869705

Epoch: 5| Step: 1
Training loss: 2.097432851791382
Validation loss: 2.123872255285581

Epoch: 5| Step: 2
Training loss: 2.0851922035217285
Validation loss: 2.1248711943626404

Epoch: 5| Step: 3
Training loss: 2.3853116035461426
Validation loss: 2.1227302501598992

Epoch: 5| Step: 4
Training loss: 2.3290693759918213
Validation loss: 2.1158794909715652

Epoch: 5| Step: 5
Training loss: 2.0476303100585938
Validation loss: 2.118511140346527

Epoch: 5| Step: 6
Training loss: 2.2261619567871094
Validation loss: 2.1183714916308722

Epoch: 5| Step: 7
Training loss: 2.8244922161102295
Validation loss: 2.111903349558512

Epoch: 5| Step: 8
Training loss: 2.4200711250305176
Validation loss: 2.1136429607868195

Epoch: 5| Step: 9
Training loss: 2.228851079940796
Validation loss: 2.1067266364892325

Epoch: 5| Step: 10
Training loss: 2.303375720977783
Validation loss: 2.1088080257177353

Epoch: 5| Step: 11
Training loss: 2.3124594688415527
Validation loss: 2.108293980360031

Epoch: 65| Step: 0
Training loss: 2.024000406265259
Validation loss: 2.111797725160917

Epoch: 5| Step: 1
Training loss: 2.3089869022369385
Validation loss: 2.1128731071949005

Epoch: 5| Step: 2
Training loss: 2.200623035430908
Validation loss: 2.11034964521726

Epoch: 5| Step: 3
Training loss: 2.357738971710205
Validation loss: 2.110388368368149

Epoch: 5| Step: 4
Training loss: 2.7753422260284424
Validation loss: 2.105375722050667

Epoch: 5| Step: 5
Training loss: 2.201704263687134
Validation loss: 2.103139822681745

Epoch: 5| Step: 6
Training loss: 2.6127641201019287
Validation loss: 2.1046115458011627

Epoch: 5| Step: 7
Training loss: 2.32881760597229
Validation loss: 2.1072288950284324

Epoch: 5| Step: 8
Training loss: 2.5623204708099365
Validation loss: 2.0975473572810492

Epoch: 5| Step: 9
Training loss: 1.7774289846420288
Validation loss: 2.103443533182144

Epoch: 5| Step: 10
Training loss: 2.1207563877105713
Validation loss: 2.1002102394898734

Epoch: 5| Step: 11
Training loss: 1.9414252042770386
Validation loss: 2.0999942868947983

Epoch: 66| Step: 0
Training loss: 2.2015411853790283
Validation loss: 2.099810764193535

Epoch: 5| Step: 1
Training loss: 2.2826004028320312
Validation loss: 2.0970988819996514

Epoch: 5| Step: 2
Training loss: 2.135683536529541
Validation loss: 2.1117023130257926

Epoch: 5| Step: 3
Training loss: 2.378223419189453
Validation loss: 2.1139325499534607

Epoch: 5| Step: 4
Training loss: 1.69247305393219
Validation loss: 2.1098621735970178

Epoch: 5| Step: 5
Training loss: 2.5173022747039795
Validation loss: 2.1027830044428506

Epoch: 5| Step: 6
Training loss: 2.8082985877990723
Validation loss: 2.094735006491343

Epoch: 5| Step: 7
Training loss: 2.136125087738037
Validation loss: 2.0834753761688867

Epoch: 5| Step: 8
Training loss: 2.4260342121124268
Validation loss: 2.089335779349009

Epoch: 5| Step: 9
Training loss: 2.1498000621795654
Validation loss: 2.09051521619161

Epoch: 5| Step: 10
Training loss: 2.526841640472412
Validation loss: 2.0902269085248313

Epoch: 5| Step: 11
Training loss: 1.4018175601959229
Validation loss: 2.0898886372645697

Epoch: 67| Step: 0
Training loss: 2.3794169425964355
Validation loss: 2.0911486943562827

Epoch: 5| Step: 1
Training loss: 2.0399556159973145
Validation loss: 2.091803659995397

Epoch: 5| Step: 2
Training loss: 2.841782331466675
Validation loss: 2.0890373090902963

Epoch: 5| Step: 3
Training loss: 2.409184217453003
Validation loss: 2.086797207593918

Epoch: 5| Step: 4
Training loss: 1.9957878589630127
Validation loss: 2.0846680154403052

Epoch: 5| Step: 5
Training loss: 2.232100248336792
Validation loss: 2.080969606836637

Epoch: 5| Step: 6
Training loss: 2.3709444999694824
Validation loss: 2.082787404457728

Epoch: 5| Step: 7
Training loss: 2.4502243995666504
Validation loss: 2.0786646405855813

Epoch: 5| Step: 8
Training loss: 1.7972562313079834
Validation loss: 2.0770650506019592

Epoch: 5| Step: 9
Training loss: 2.42773699760437
Validation loss: 2.080048163731893

Epoch: 5| Step: 10
Training loss: 2.052267551422119
Validation loss: 2.0744425108035407

Epoch: 5| Step: 11
Training loss: 1.5179063081741333
Validation loss: 2.078081965446472

Epoch: 68| Step: 0
Training loss: 2.521146297454834
Validation loss: 2.071948374311129

Epoch: 5| Step: 1
Training loss: 2.2918143272399902
Validation loss: 2.084484482804934

Epoch: 5| Step: 2
Training loss: 2.2428882122039795
Validation loss: 2.082825164000193

Epoch: 5| Step: 3
Training loss: 1.8956983089447021
Validation loss: 2.0784728278716407

Epoch: 5| Step: 4
Training loss: 2.431649923324585
Validation loss: 2.078061814109484

Epoch: 5| Step: 5
Training loss: 2.604647636413574
Validation loss: 2.0702985177437463

Epoch: 5| Step: 6
Training loss: 2.3316431045532227
Validation loss: 2.0709110498428345

Epoch: 5| Step: 7
Training loss: 2.307701826095581
Validation loss: 2.070330669482549

Epoch: 5| Step: 8
Training loss: 1.7903778553009033
Validation loss: 2.0745377043883004

Epoch: 5| Step: 9
Training loss: 2.298943042755127
Validation loss: 2.0735903084278107

Epoch: 5| Step: 10
Training loss: 2.049530029296875
Validation loss: 2.073082849383354

Epoch: 5| Step: 11
Training loss: 2.3697428703308105
Validation loss: 2.0717698434988656

Epoch: 69| Step: 0
Training loss: 1.5123183727264404
Validation loss: 2.066153421998024

Epoch: 5| Step: 1
Training loss: 2.8532016277313232
Validation loss: 2.06496890882651

Epoch: 5| Step: 2
Training loss: 2.1666059494018555
Validation loss: 2.065121923883756

Epoch: 5| Step: 3
Training loss: 2.196721076965332
Validation loss: 2.0651643723249435

Epoch: 5| Step: 4
Training loss: 1.7131690979003906
Validation loss: 2.069372852643331

Epoch: 5| Step: 5
Training loss: 2.772024631500244
Validation loss: 2.0582849284013114

Epoch: 5| Step: 6
Training loss: 2.11030912399292
Validation loss: 2.0595356225967407

Epoch: 5| Step: 7
Training loss: 2.146226644515991
Validation loss: 2.0599666982889175

Epoch: 5| Step: 8
Training loss: 2.025390625
Validation loss: 2.0596857269605002

Epoch: 5| Step: 9
Training loss: 2.4309773445129395
Validation loss: 2.0725882252057395

Epoch: 5| Step: 10
Training loss: 2.7286598682403564
Validation loss: 2.072144697109858

Epoch: 5| Step: 11
Training loss: 2.689446210861206
Validation loss: 2.0683548698822656

Epoch: 70| Step: 0
Training loss: 2.0803518295288086
Validation loss: 2.0669782857100167

Epoch: 5| Step: 1
Training loss: 1.957624077796936
Validation loss: 2.05822092294693

Epoch: 5| Step: 2
Training loss: 2.15779972076416
Validation loss: 2.0573453505833945

Epoch: 5| Step: 3
Training loss: 2.2610244750976562
Validation loss: 2.0489361584186554

Epoch: 5| Step: 4
Training loss: 2.2362053394317627
Validation loss: 2.0565777172644935

Epoch: 5| Step: 5
Training loss: 1.8012707233428955
Validation loss: 2.0499196151892343

Epoch: 5| Step: 6
Training loss: 2.821201801300049
Validation loss: 2.0507688919703164

Epoch: 5| Step: 7
Training loss: 2.4842028617858887
Validation loss: 2.0518715629975

Epoch: 5| Step: 8
Training loss: 2.303391695022583
Validation loss: 2.0571285784244537

Epoch: 5| Step: 9
Training loss: 2.328434467315674
Validation loss: 2.06723760565122

Epoch: 5| Step: 10
Training loss: 2.343090295791626
Validation loss: 2.066006655494372

Epoch: 5| Step: 11
Training loss: 1.5789169073104858
Validation loss: 2.064102421204249

Epoch: 71| Step: 0
Training loss: 2.316218614578247
Validation loss: 2.064623867472013

Epoch: 5| Step: 1
Training loss: 1.9238722324371338
Validation loss: 2.0610969215631485

Epoch: 5| Step: 2
Training loss: 1.986031174659729
Validation loss: 2.0555002888043723

Epoch: 5| Step: 3
Training loss: 2.0981414318084717
Validation loss: 2.0554986000061035

Epoch: 5| Step: 4
Training loss: 1.7442480325698853
Validation loss: 2.0554534594217935

Epoch: 5| Step: 5
Training loss: 2.1447091102600098
Validation loss: 2.0438316067059836

Epoch: 5| Step: 6
Training loss: 2.0727548599243164
Validation loss: 2.0382757435242334

Epoch: 5| Step: 7
Training loss: 1.9549649953842163
Validation loss: 2.0450309962034225

Epoch: 5| Step: 8
Training loss: 2.607626438140869
Validation loss: 2.0610102812449136

Epoch: 5| Step: 9
Training loss: 3.109983205795288
Validation loss: 2.056190863251686

Epoch: 5| Step: 10
Training loss: 2.6306824684143066
Validation loss: 2.0541324615478516

Epoch: 5| Step: 11
Training loss: 2.712599277496338
Validation loss: 2.042190288503965

Epoch: 72| Step: 0
Training loss: 2.267721176147461
Validation loss: 2.0430636455615363

Epoch: 5| Step: 1
Training loss: 2.1417343616485596
Validation loss: 2.0362577935059867

Epoch: 5| Step: 2
Training loss: 2.147296190261841
Validation loss: 2.0402380178372064

Epoch: 5| Step: 3
Training loss: 2.4450278282165527
Validation loss: 2.040062556664149

Epoch: 5| Step: 4
Training loss: 2.4008231163024902
Validation loss: 2.037560820579529

Epoch: 5| Step: 5
Training loss: 2.1802637577056885
Validation loss: 2.0451275954643884

Epoch: 5| Step: 6
Training loss: 1.5837280750274658
Validation loss: 2.040788695216179

Epoch: 5| Step: 7
Training loss: 2.2766449451446533
Validation loss: 2.0382157961527505

Epoch: 5| Step: 8
Training loss: 2.0541629791259766
Validation loss: 2.035669212539991

Epoch: 5| Step: 9
Training loss: 2.434142589569092
Validation loss: 2.0423991034428277

Epoch: 5| Step: 10
Training loss: 2.4828834533691406
Validation loss: 2.035010283191999

Epoch: 5| Step: 11
Training loss: 2.223254919052124
Validation loss: 2.037368173400561

Epoch: 73| Step: 0
Training loss: 2.688054084777832
Validation loss: 2.0383635461330414

Epoch: 5| Step: 1
Training loss: 2.522460699081421
Validation loss: 2.0315887232621512

Epoch: 5| Step: 2
Training loss: 2.1147913932800293
Validation loss: 2.0386306097110114

Epoch: 5| Step: 3
Training loss: 2.1484858989715576
Validation loss: 2.036716009179751

Epoch: 5| Step: 4
Training loss: 2.4787983894348145
Validation loss: 2.034276550014814

Epoch: 5| Step: 5
Training loss: 2.4097390174865723
Validation loss: 2.0389394213755927

Epoch: 5| Step: 6
Training loss: 2.2262020111083984
Validation loss: 2.0329501827557883

Epoch: 5| Step: 7
Training loss: 1.9921855926513672
Validation loss: 2.0376198341449103

Epoch: 5| Step: 8
Training loss: 1.968705415725708
Validation loss: 2.0394449084997177

Epoch: 5| Step: 9
Training loss: 2.1535587310791016
Validation loss: 2.0339033206303916

Epoch: 5| Step: 10
Training loss: 1.73432195186615
Validation loss: 2.0313963194688163

Epoch: 5| Step: 11
Training loss: 1.6793794631958008
Validation loss: 2.022745832800865

Epoch: 74| Step: 0
Training loss: 2.243218183517456
Validation loss: 2.0251449942588806

Epoch: 5| Step: 1
Training loss: 2.624279499053955
Validation loss: 2.03496844569842

Epoch: 5| Step: 2
Training loss: 1.925419569015503
Validation loss: 2.042948216199875

Epoch: 5| Step: 3
Training loss: 1.6926910877227783
Validation loss: 2.045213977495829

Epoch: 5| Step: 4
Training loss: 2.218019723892212
Validation loss: 2.0448731730381646

Epoch: 5| Step: 5
Training loss: 2.2003612518310547
Validation loss: 2.0483428140481315

Epoch: 5| Step: 6
Training loss: 2.509883165359497
Validation loss: 2.0470211605230966

Epoch: 5| Step: 7
Training loss: 2.377443313598633
Validation loss: 2.0475653956333795

Epoch: 5| Step: 8
Training loss: 1.9362576007843018
Validation loss: 2.047515034675598

Epoch: 5| Step: 9
Training loss: 2.317857027053833
Validation loss: 2.0476615726947784

Epoch: 5| Step: 10
Training loss: 2.333603620529175
Validation loss: 2.046957388520241

Epoch: 5| Step: 11
Training loss: 2.4637017250061035
Validation loss: 2.044961377978325

Epoch: 75| Step: 0
Training loss: 2.2698283195495605
Validation loss: 2.0467627743879953

Epoch: 5| Step: 1
Training loss: 2.442654609680176
Validation loss: 2.038663143912951

Epoch: 5| Step: 2
Training loss: 2.0005736351013184
Validation loss: 2.04066667954127

Epoch: 5| Step: 3
Training loss: 2.1015915870666504
Validation loss: 2.0372496843338013

Epoch: 5| Step: 4
Training loss: 2.2172553539276123
Validation loss: 2.0339836726586022

Epoch: 5| Step: 5
Training loss: 1.7281506061553955
Validation loss: 2.0261726528406143

Epoch: 5| Step: 6
Training loss: 2.649946928024292
Validation loss: 2.0238631268342337

Epoch: 5| Step: 7
Training loss: 1.7510350942611694
Validation loss: 2.0222897132237754

Epoch: 5| Step: 8
Training loss: 2.6015219688415527
Validation loss: 2.024813940127691

Epoch: 5| Step: 9
Training loss: 1.8821079730987549
Validation loss: 2.0427990158398948

Epoch: 5| Step: 10
Training loss: 2.518132448196411
Validation loss: 2.0566436449686685

Epoch: 5| Step: 11
Training loss: 3.7127275466918945
Validation loss: 2.0470702747503915

Testing loss: 1.6466363960032842
