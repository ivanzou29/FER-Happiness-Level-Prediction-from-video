Epoch: 1| Step: 0
Training loss: 5.416723728179932
Validation loss: 5.2629616260528564

Epoch: 5| Step: 1
Training loss: 4.399755477905273
Validation loss: 5.261256158351898

Epoch: 5| Step: 2
Training loss: 5.548312187194824
Validation loss: 5.259640216827393

Epoch: 5| Step: 3
Training loss: 5.1068315505981445
Validation loss: 5.257990439732869

Epoch: 5| Step: 4
Training loss: 5.230505466461182
Validation loss: 5.256415585676829

Epoch: 5| Step: 5
Training loss: 5.238302230834961
Validation loss: 5.254892865816752

Epoch: 5| Step: 6
Training loss: 5.506495475769043
Validation loss: 5.253362933794658

Epoch: 5| Step: 7
Training loss: 5.2245659828186035
Validation loss: 5.251789470513661

Epoch: 5| Step: 8
Training loss: 5.428995609283447
Validation loss: 5.250248968601227

Epoch: 5| Step: 9
Training loss: 5.952940464019775
Validation loss: 5.248707175254822

Epoch: 5| Step: 10
Training loss: 5.286492347717285
Validation loss: 5.2472019990285235

Epoch: 5| Step: 11
Training loss: 6.457150459289551
Validation loss: 5.245628575483958

Epoch: 2| Step: 0
Training loss: 6.128049373626709
Validation loss: 5.2439338366190595

Epoch: 5| Step: 1
Training loss: 3.6839840412139893
Validation loss: 5.242304503917694

Epoch: 5| Step: 2
Training loss: 5.6931986808776855
Validation loss: 5.240589777628581

Epoch: 5| Step: 3
Training loss: 5.50917387008667
Validation loss: 5.238815585772197

Epoch: 5| Step: 4
Training loss: 5.8965253829956055
Validation loss: 5.2370113134384155

Epoch: 5| Step: 5
Training loss: 5.664939880371094
Validation loss: 5.235128025213878

Epoch: 5| Step: 6
Training loss: 4.970658779144287
Validation loss: 5.233153402805328

Epoch: 5| Step: 7
Training loss: 4.4965949058532715
Validation loss: 5.231088260809581

Epoch: 5| Step: 8
Training loss: 5.475495338439941
Validation loss: 5.2290188272794085

Epoch: 5| Step: 9
Training loss: 4.736677646636963
Validation loss: 5.226759433746338

Epoch: 5| Step: 10
Training loss: 5.933157444000244
Validation loss: 5.224459012349446

Epoch: 5| Step: 11
Training loss: 6.1066575050354
Validation loss: 5.2220955689748125

Epoch: 3| Step: 0
Training loss: 4.034852504730225
Validation loss: 5.2196763555208845

Epoch: 5| Step: 1
Training loss: 6.194759845733643
Validation loss: 5.216938237349193

Epoch: 5| Step: 2
Training loss: 4.86963415145874
Validation loss: 5.214266300201416

Epoch: 5| Step: 3
Training loss: 4.814720153808594
Validation loss: 5.2113077044487

Epoch: 5| Step: 4
Training loss: 4.909985542297363
Validation loss: 5.2082028190294904

Epoch: 5| Step: 5
Training loss: 5.85634708404541
Validation loss: 5.204994757970174

Epoch: 5| Step: 6
Training loss: 5.645432472229004
Validation loss: 5.201591829458873

Epoch: 5| Step: 7
Training loss: 6.4984025955200195
Validation loss: 5.198130528132121

Epoch: 5| Step: 8
Training loss: 4.753217697143555
Validation loss: 5.194317738215129

Epoch: 5| Step: 9
Training loss: 4.743025779724121
Validation loss: 5.190583596626918

Epoch: 5| Step: 10
Training loss: 5.572131156921387
Validation loss: 5.18655667702357

Epoch: 5| Step: 11
Training loss: 5.88306999206543
Validation loss: 5.182116985321045

Epoch: 4| Step: 0
Training loss: 6.172530174255371
Validation loss: 5.1776134967803955

Epoch: 5| Step: 1
Training loss: 4.9210524559021
Validation loss: 5.172960778077443

Epoch: 5| Step: 2
Training loss: 5.358376979827881
Validation loss: 5.168028871218364

Epoch: 5| Step: 3
Training loss: 5.5611748695373535
Validation loss: 5.1629647215207415

Epoch: 5| Step: 4
Training loss: 4.343514442443848
Validation loss: 5.157590826352437

Epoch: 5| Step: 5
Training loss: 4.907082557678223
Validation loss: 5.152139047781627

Epoch: 5| Step: 6
Training loss: 6.543550968170166
Validation loss: 5.146386782328288

Epoch: 5| Step: 7
Training loss: 5.281294822692871
Validation loss: 5.140351434548696

Epoch: 5| Step: 8
Training loss: 4.289832592010498
Validation loss: 5.134164949258168

Epoch: 5| Step: 9
Training loss: 4.47537899017334
Validation loss: 5.127923945585887

Epoch: 5| Step: 10
Training loss: 5.589622497558594
Validation loss: 5.121322274208069

Epoch: 5| Step: 11
Training loss: 5.253296852111816
Validation loss: 5.11465726296107

Epoch: 5| Step: 0
Training loss: 4.5738115310668945
Validation loss: 5.1080692410469055

Epoch: 5| Step: 1
Training loss: 5.079256057739258
Validation loss: 5.101482351620992

Epoch: 5| Step: 2
Training loss: 6.028990268707275
Validation loss: 5.094846248626709

Epoch: 5| Step: 3
Training loss: 5.015625953674316
Validation loss: 5.087687720855077

Epoch: 5| Step: 4
Training loss: 5.591763496398926
Validation loss: 5.080678105354309

Epoch: 5| Step: 5
Training loss: 4.851972579956055
Validation loss: 5.073406358559926

Epoch: 5| Step: 6
Training loss: 6.198594570159912
Validation loss: 5.066081206003825

Epoch: 5| Step: 7
Training loss: 5.30081844329834
Validation loss: 5.058432201544444

Epoch: 5| Step: 8
Training loss: 4.674681186676025
Validation loss: 5.050947070121765

Epoch: 5| Step: 9
Training loss: 4.974220275878906
Validation loss: 5.043235103289287

Epoch: 5| Step: 10
Training loss: 4.59322452545166
Validation loss: 5.035370886325836

Epoch: 5| Step: 11
Training loss: 3.840362071990967
Validation loss: 5.027355094750722

Epoch: 6| Step: 0
Training loss: 5.829534530639648
Validation loss: 5.019065340360005

Epoch: 5| Step: 1
Training loss: 5.5541582107543945
Validation loss: 5.010748942693074

Epoch: 5| Step: 2
Training loss: 4.956275463104248
Validation loss: 5.002505699793498

Epoch: 5| Step: 3
Training loss: 5.761384010314941
Validation loss: 4.9937600294748945

Epoch: 5| Step: 4
Training loss: 5.0520806312561035
Validation loss: 4.985323468844096

Epoch: 5| Step: 5
Training loss: 5.884089469909668
Validation loss: 4.976546724637349

Epoch: 5| Step: 6
Training loss: 4.2508955001831055
Validation loss: 4.967864712079366

Epoch: 5| Step: 7
Training loss: 3.79960560798645
Validation loss: 4.9592434366544085

Epoch: 5| Step: 8
Training loss: 4.930294990539551
Validation loss: 4.951171795527141

Epoch: 5| Step: 9
Training loss: 5.894663333892822
Validation loss: 4.9429542024930315

Epoch: 5| Step: 10
Training loss: 4.09684944152832
Validation loss: 4.93461271127065

Epoch: 5| Step: 11
Training loss: 3.168003797531128
Validation loss: 4.926473955313365

Epoch: 7| Step: 0
Training loss: 6.240971565246582
Validation loss: 4.9182446002960205

Epoch: 5| Step: 1
Training loss: 4.234415054321289
Validation loss: 4.9101564685503645

Epoch: 5| Step: 2
Training loss: 4.470736503601074
Validation loss: 4.902525266011556

Epoch: 5| Step: 3
Training loss: 5.507204532623291
Validation loss: 4.894485255082448

Epoch: 5| Step: 4
Training loss: 4.438681602478027
Validation loss: 4.886437098185222

Epoch: 5| Step: 5
Training loss: 4.715979099273682
Validation loss: 4.87868332862854

Epoch: 5| Step: 6
Training loss: 4.884058952331543
Validation loss: 4.870933214823405

Epoch: 5| Step: 7
Training loss: 5.218751430511475
Validation loss: 4.862930774688721

Epoch: 5| Step: 8
Training loss: 4.8429155349731445
Validation loss: 4.855117579301198

Epoch: 5| Step: 9
Training loss: 4.779597759246826
Validation loss: 4.847131162881851

Epoch: 5| Step: 10
Training loss: 5.164283752441406
Validation loss: 4.839747945467631

Epoch: 5| Step: 11
Training loss: 5.4913787841796875
Validation loss: 4.8320558071136475

Epoch: 8| Step: 0
Training loss: 4.691082954406738
Validation loss: 4.824278235435486

Epoch: 5| Step: 1
Training loss: 5.507073402404785
Validation loss: 4.816604038079579

Epoch: 5| Step: 2
Training loss: 4.93230676651001
Validation loss: 4.80907020966212

Epoch: 5| Step: 3
Training loss: 4.854720592498779
Validation loss: 4.801155626773834

Epoch: 5| Step: 4
Training loss: 4.994830131530762
Validation loss: 4.793326755364736

Epoch: 5| Step: 5
Training loss: 4.380664825439453
Validation loss: 4.7855503757794695

Epoch: 5| Step: 6
Training loss: 3.92103910446167
Validation loss: 4.777746776739757

Epoch: 5| Step: 7
Training loss: 4.976230144500732
Validation loss: 4.770505179961522

Epoch: 5| Step: 8
Training loss: 5.380394458770752
Validation loss: 4.763668417930603

Epoch: 5| Step: 9
Training loss: 5.202106952667236
Validation loss: 4.756717622280121

Epoch: 5| Step: 10
Training loss: 5.368662357330322
Validation loss: 4.74945342540741

Epoch: 5| Step: 11
Training loss: 1.9979114532470703
Validation loss: 4.742887447277705

Epoch: 9| Step: 0
Training loss: 4.268395900726318
Validation loss: 4.736073295275371

Epoch: 5| Step: 1
Training loss: 5.1631879806518555
Validation loss: 4.72920686006546

Epoch: 5| Step: 2
Training loss: 5.24423360824585
Validation loss: 4.722750226656596

Epoch: 5| Step: 3
Training loss: 5.055014610290527
Validation loss: 4.7159402171770735

Epoch: 5| Step: 4
Training loss: 4.511260509490967
Validation loss: 4.7091392278671265

Epoch: 5| Step: 5
Training loss: 4.858818054199219
Validation loss: 4.701895634333293

Epoch: 5| Step: 6
Training loss: 3.9548416137695312
Validation loss: 4.695164104302724

Epoch: 5| Step: 7
Training loss: 4.790627956390381
Validation loss: 4.688233484824498

Epoch: 5| Step: 8
Training loss: 4.986138343811035
Validation loss: 4.681186735630035

Epoch: 5| Step: 9
Training loss: 4.669306755065918
Validation loss: 4.674094080924988

Epoch: 5| Step: 10
Training loss: 5.062067985534668
Validation loss: 4.666792094707489

Epoch: 5| Step: 11
Training loss: 5.707340240478516
Validation loss: 4.659378349781036

Epoch: 10| Step: 0
Training loss: 4.823554515838623
Validation loss: 4.651962637901306

Epoch: 5| Step: 1
Training loss: 3.851172924041748
Validation loss: 4.644646108150482

Epoch: 5| Step: 2
Training loss: 4.865841388702393
Validation loss: 4.637770781914393

Epoch: 5| Step: 3
Training loss: 3.8334083557128906
Validation loss: 4.630818198124568

Epoch: 5| Step: 4
Training loss: 5.4942522048950195
Validation loss: 4.624245593945186

Epoch: 5| Step: 5
Training loss: 3.902554988861084
Validation loss: 4.616959830125173

Epoch: 5| Step: 6
Training loss: 4.877367973327637
Validation loss: 4.610088606675466

Epoch: 5| Step: 7
Training loss: 5.404932975769043
Validation loss: 4.603249718745549

Epoch: 5| Step: 8
Training loss: 4.817788600921631
Validation loss: 4.596908609072368

Epoch: 5| Step: 9
Training loss: 5.272088050842285
Validation loss: 4.590532680352529

Epoch: 5| Step: 10
Training loss: 4.952850818634033
Validation loss: 4.584661662578583

Epoch: 5| Step: 11
Training loss: 3.5802254676818848
Validation loss: 4.578661282857259

Epoch: 11| Step: 0
Training loss: 4.629051208496094
Validation loss: 4.5726311802864075

Epoch: 5| Step: 1
Training loss: 4.40614128112793
Validation loss: 4.5666250586509705

Epoch: 5| Step: 2
Training loss: 5.224056720733643
Validation loss: 4.5600139399369555

Epoch: 5| Step: 3
Training loss: 3.761627197265625
Validation loss: 4.553908268610637

Epoch: 5| Step: 4
Training loss: 4.120467185974121
Validation loss: 4.547529260317485

Epoch: 5| Step: 5
Training loss: 5.176174163818359
Validation loss: 4.541408737500508

Epoch: 5| Step: 6
Training loss: 4.633333683013916
Validation loss: 4.535237371921539

Epoch: 5| Step: 7
Training loss: 4.673760890960693
Validation loss: 4.528501311937968

Epoch: 5| Step: 8
Training loss: 5.193073272705078
Validation loss: 4.522125621636708

Epoch: 5| Step: 9
Training loss: 4.073874473571777
Validation loss: 4.5155384341875715

Epoch: 5| Step: 10
Training loss: 5.157176494598389
Validation loss: 4.509118189414342

Epoch: 5| Step: 11
Training loss: 4.763815402984619
Validation loss: 4.502671857674916

Epoch: 12| Step: 0
Training loss: 4.786584854125977
Validation loss: 4.496142476797104

Epoch: 5| Step: 1
Training loss: 3.652539014816284
Validation loss: 4.490073531866074

Epoch: 5| Step: 2
Training loss: 4.63611364364624
Validation loss: 4.483653833468755

Epoch: 5| Step: 3
Training loss: 5.271963596343994
Validation loss: 4.4771687388420105

Epoch: 5| Step: 4
Training loss: 4.780249118804932
Validation loss: 4.471506953239441

Epoch: 5| Step: 5
Training loss: 4.146075248718262
Validation loss: 4.465564866860707

Epoch: 5| Step: 6
Training loss: 4.401139736175537
Validation loss: 4.459670841693878

Epoch: 5| Step: 7
Training loss: 4.417267799377441
Validation loss: 4.453933507204056

Epoch: 5| Step: 8
Training loss: 4.254004001617432
Validation loss: 4.447467565536499

Epoch: 5| Step: 9
Training loss: 5.001376152038574
Validation loss: 4.441113630930583

Epoch: 5| Step: 10
Training loss: 4.616559982299805
Validation loss: 4.435067256291707

Epoch: 5| Step: 11
Training loss: 6.373394012451172
Validation loss: 4.429920633633931

Epoch: 13| Step: 0
Training loss: 4.195410251617432
Validation loss: 4.423295646905899

Epoch: 5| Step: 1
Training loss: 4.9696173667907715
Validation loss: 4.417669067780177

Epoch: 5| Step: 2
Training loss: 5.245543956756592
Validation loss: 4.411687990029653

Epoch: 5| Step: 3
Training loss: 3.986394166946411
Validation loss: 4.406213690837224

Epoch: 5| Step: 4
Training loss: 4.515525817871094
Validation loss: 4.400551597277324

Epoch: 5| Step: 5
Training loss: 4.551565647125244
Validation loss: 4.395210484663646

Epoch: 5| Step: 6
Training loss: 4.058124542236328
Validation loss: 4.389557580153148

Epoch: 5| Step: 7
Training loss: 4.018456935882568
Validation loss: 4.383958180745442

Epoch: 5| Step: 8
Training loss: 4.093950271606445
Validation loss: 4.378337760766347

Epoch: 5| Step: 9
Training loss: 5.144593238830566
Validation loss: 4.373173952102661

Epoch: 5| Step: 10
Training loss: 4.921627521514893
Validation loss: 4.367809812227885

Epoch: 5| Step: 11
Training loss: 4.1507344245910645
Validation loss: 4.362062990665436

Epoch: 14| Step: 0
Training loss: 4.731202602386475
Validation loss: 4.357408314943314

Epoch: 5| Step: 1
Training loss: 5.129762172698975
Validation loss: 4.351825624704361

Epoch: 5| Step: 2
Training loss: 4.998725891113281
Validation loss: 4.346921781698863

Epoch: 5| Step: 3
Training loss: 5.0608391761779785
Validation loss: 4.341381748517354

Epoch: 5| Step: 4
Training loss: 4.317257881164551
Validation loss: 4.335924724737803

Epoch: 5| Step: 5
Training loss: 4.015929222106934
Validation loss: 4.3308312594890594

Epoch: 5| Step: 6
Training loss: 4.801037788391113
Validation loss: 4.325426389773686

Epoch: 5| Step: 7
Training loss: 3.334451675415039
Validation loss: 4.320007801055908

Epoch: 5| Step: 8
Training loss: 3.7009143829345703
Validation loss: 4.316528489192327

Epoch: 5| Step: 9
Training loss: 4.509978771209717
Validation loss: 4.310318112373352

Epoch: 5| Step: 10
Training loss: 4.800148963928223
Validation loss: 4.306493779023488

Epoch: 5| Step: 11
Training loss: 2.431663751602173
Validation loss: 4.302424679199855

Epoch: 15| Step: 0
Training loss: 5.116970539093018
Validation loss: 4.301607807477315

Epoch: 5| Step: 1
Training loss: 3.5842907428741455
Validation loss: 4.2926134665807085

Epoch: 5| Step: 2
Training loss: 4.616749286651611
Validation loss: 4.28697423140208

Epoch: 5| Step: 3
Training loss: 4.290389060974121
Validation loss: 4.282528777917226

Epoch: 5| Step: 4
Training loss: 4.735787868499756
Validation loss: 4.277411252260208

Epoch: 5| Step: 5
Training loss: 3.985477924346924
Validation loss: 4.2714177668094635

Epoch: 5| Step: 6
Training loss: 4.613402843475342
Validation loss: 4.267472485701243

Epoch: 5| Step: 7
Training loss: 5.166097164154053
Validation loss: 4.2623574535051985

Epoch: 5| Step: 8
Training loss: 4.436391353607178
Validation loss: 4.2566946148872375

Epoch: 5| Step: 9
Training loss: 4.705284118652344
Validation loss: 4.2515813906987505

Epoch: 5| Step: 10
Training loss: 3.477607250213623
Validation loss: 4.2463394701480865

Epoch: 5| Step: 11
Training loss: 2.815253734588623
Validation loss: 4.241335153579712

Epoch: 16| Step: 0
Training loss: 4.127240180969238
Validation loss: 4.237260768810908

Epoch: 5| Step: 1
Training loss: 4.899615287780762
Validation loss: 4.232886413733165

Epoch: 5| Step: 2
Training loss: 3.9250121116638184
Validation loss: 4.228049596150716

Epoch: 5| Step: 3
Training loss: 4.027775764465332
Validation loss: 4.2230164706707

Epoch: 5| Step: 4
Training loss: 4.28067684173584
Validation loss: 4.2175171573956804

Epoch: 5| Step: 5
Training loss: 4.100305557250977
Validation loss: 4.212346663077672

Epoch: 5| Step: 6
Training loss: 3.990049362182617
Validation loss: 4.206659247477849

Epoch: 5| Step: 7
Training loss: 4.463244915008545
Validation loss: 4.201656778653462

Epoch: 5| Step: 8
Training loss: 5.280078887939453
Validation loss: 4.197318623463313

Epoch: 5| Step: 9
Training loss: 4.139241695404053
Validation loss: 4.1928768654664355

Epoch: 5| Step: 10
Training loss: 4.401691913604736
Validation loss: 4.187545796235402

Epoch: 5| Step: 11
Training loss: 5.162640571594238
Validation loss: 4.1830224593480425

Epoch: 17| Step: 0
Training loss: 4.464069843292236
Validation loss: 4.178697278102239

Epoch: 5| Step: 1
Training loss: 3.876448392868042
Validation loss: 4.174049615859985

Epoch: 5| Step: 2
Training loss: 4.103529453277588
Validation loss: 4.168834358453751

Epoch: 5| Step: 3
Training loss: 3.8491859436035156
Validation loss: 4.163625071446101

Epoch: 5| Step: 4
Training loss: 4.457601070404053
Validation loss: 4.1583437621593475

Epoch: 5| Step: 5
Training loss: 4.780106544494629
Validation loss: 4.153560946385066

Epoch: 5| Step: 6
Training loss: 5.305512428283691
Validation loss: 4.14844810962677

Epoch: 5| Step: 7
Training loss: 5.534628391265869
Validation loss: 4.1437502801418304

Epoch: 5| Step: 8
Training loss: 3.096956729888916
Validation loss: 4.138324320316315

Epoch: 5| Step: 9
Training loss: 3.5722389221191406
Validation loss: 4.133548577626546

Epoch: 5| Step: 10
Training loss: 4.195257186889648
Validation loss: 4.128226846456528

Epoch: 5| Step: 11
Training loss: 4.171612739562988
Validation loss: 4.124646375576655

Epoch: 18| Step: 0
Training loss: 4.500324249267578
Validation loss: 4.120768556992213

Epoch: 5| Step: 1
Training loss: 5.4927873611450195
Validation loss: 4.117025633653005

Epoch: 5| Step: 2
Training loss: 4.514706134796143
Validation loss: 4.111904164155324

Epoch: 5| Step: 3
Training loss: 4.22697639465332
Validation loss: 4.107533087333043

Epoch: 5| Step: 4
Training loss: 4.561851501464844
Validation loss: 4.102376331885655

Epoch: 5| Step: 5
Training loss: 3.9148178100585938
Validation loss: 4.097936779260635

Epoch: 5| Step: 6
Training loss: 4.329700469970703
Validation loss: 4.09199579556783

Epoch: 5| Step: 7
Training loss: 4.017856121063232
Validation loss: 4.087100913127263

Epoch: 5| Step: 8
Training loss: 3.758693218231201
Validation loss: 4.082075695196788

Epoch: 5| Step: 9
Training loss: 4.296637058258057
Validation loss: 4.075866639614105

Epoch: 5| Step: 10
Training loss: 3.4295272827148438
Validation loss: 4.072094887495041

Epoch: 5| Step: 11
Training loss: 2.0757157802581787
Validation loss: 4.068119049072266

Epoch: 19| Step: 0
Training loss: 5.376239776611328
Validation loss: 4.063975691795349

Epoch: 5| Step: 1
Training loss: 3.7940192222595215
Validation loss: 4.058096528053284

Epoch: 5| Step: 2
Training loss: 4.854846954345703
Validation loss: 4.054177105426788

Epoch: 5| Step: 3
Training loss: 3.906848192214966
Validation loss: 4.048173228899638

Epoch: 5| Step: 4
Training loss: 4.918124198913574
Validation loss: 4.043399532636006

Epoch: 5| Step: 5
Training loss: 3.5768165588378906
Validation loss: 4.038656145334244

Epoch: 5| Step: 6
Training loss: 3.488478183746338
Validation loss: 4.032996704181035

Epoch: 5| Step: 7
Training loss: 4.530470848083496
Validation loss: 4.029340296983719

Epoch: 5| Step: 8
Training loss: 3.1820781230926514
Validation loss: 4.023129254579544

Epoch: 5| Step: 9
Training loss: 4.622310638427734
Validation loss: 4.019720534483592

Epoch: 5| Step: 10
Training loss: 3.9984004497528076
Validation loss: 4.015838871399562

Epoch: 5| Step: 11
Training loss: 2.9890267848968506
Validation loss: 4.012127310037613

Epoch: 20| Step: 0
Training loss: 4.790560245513916
Validation loss: 4.009239266316096

Epoch: 5| Step: 1
Training loss: 4.2057905197143555
Validation loss: 4.002041111389796

Epoch: 5| Step: 2
Training loss: 2.912611246109009
Validation loss: 3.995354503393173

Epoch: 5| Step: 3
Training loss: 3.9056639671325684
Validation loss: 3.990594506263733

Epoch: 5| Step: 4
Training loss: 4.340123653411865
Validation loss: 3.984697163105011

Epoch: 5| Step: 5
Training loss: 3.5528368949890137
Validation loss: 3.9789681235949197

Epoch: 5| Step: 6
Training loss: 4.473272800445557
Validation loss: 3.9729266365369162

Epoch: 5| Step: 7
Training loss: 4.474959373474121
Validation loss: 3.9666344026724496

Epoch: 5| Step: 8
Training loss: 4.879228115081787
Validation loss: 3.961871494849523

Epoch: 5| Step: 9
Training loss: 4.243417739868164
Validation loss: 3.956536670525869

Epoch: 5| Step: 10
Training loss: 3.870574951171875
Validation loss: 3.9495710333188376

Epoch: 5| Step: 11
Training loss: 2.695916175842285
Validation loss: 3.9444304704666138

Epoch: 21| Step: 0
Training loss: 4.523255348205566
Validation loss: 3.9386619528134665

Epoch: 5| Step: 1
Training loss: 4.2882843017578125
Validation loss: 3.933725287516912

Epoch: 5| Step: 2
Training loss: 3.449647903442383
Validation loss: 3.9287892083326974

Epoch: 5| Step: 3
Training loss: 3.786891222000122
Validation loss: 3.9231199423472085

Epoch: 5| Step: 4
Training loss: 3.989154100418091
Validation loss: 3.9171357452869415

Epoch: 5| Step: 5
Training loss: 4.101771354675293
Validation loss: 3.9118214746316275

Epoch: 5| Step: 6
Training loss: 3.344052791595459
Validation loss: 3.9080788095792136

Epoch: 5| Step: 7
Training loss: 4.408502578735352
Validation loss: 3.9023177723089852

Epoch: 5| Step: 8
Training loss: 4.780883312225342
Validation loss: 3.8968372543652854

Epoch: 5| Step: 9
Training loss: 4.0604963302612305
Validation loss: 3.890892972548803

Epoch: 5| Step: 10
Training loss: 4.013224124908447
Validation loss: 3.8872324327627816

Epoch: 5| Step: 11
Training loss: 3.6739325523376465
Validation loss: 3.8824653228123984

Epoch: 22| Step: 0
Training loss: 4.177462577819824
Validation loss: 3.8750843604405723

Epoch: 5| Step: 1
Training loss: 4.02058744430542
Validation loss: 3.869321624437968

Epoch: 5| Step: 2
Training loss: 3.4534709453582764
Validation loss: 3.864664832750956

Epoch: 5| Step: 3
Training loss: 3.7604193687438965
Validation loss: 3.86105415225029

Epoch: 5| Step: 4
Training loss: 5.278746128082275
Validation loss: 3.8551398118336997

Epoch: 5| Step: 5
Training loss: 3.782191038131714
Validation loss: 3.8491232792536416

Epoch: 5| Step: 6
Training loss: 4.195391654968262
Validation loss: 3.8443208932876587

Epoch: 5| Step: 7
Training loss: 3.9725069999694824
Validation loss: 3.841047396262487

Epoch: 5| Step: 8
Training loss: 3.388350248336792
Validation loss: 3.8333569268385568

Epoch: 5| Step: 9
Training loss: 3.5850563049316406
Validation loss: 3.828084776798884

Epoch: 5| Step: 10
Training loss: 4.5392866134643555
Validation loss: 3.8225209017594657

Epoch: 5| Step: 11
Training loss: 3.2437405586242676
Validation loss: 3.8173560897509256

Epoch: 23| Step: 0
Training loss: 3.996297836303711
Validation loss: 3.812324196100235

Epoch: 5| Step: 1
Training loss: 3.483067750930786
Validation loss: 3.8065624833106995

Epoch: 5| Step: 2
Training loss: 4.516424179077148
Validation loss: 3.8019657731056213

Epoch: 5| Step: 3
Training loss: 3.2555251121520996
Validation loss: 3.796876609325409

Epoch: 5| Step: 4
Training loss: 3.872135639190674
Validation loss: 3.7913100918134055

Epoch: 5| Step: 5
Training loss: 4.404003143310547
Validation loss: 3.787290414174398

Epoch: 5| Step: 6
Training loss: 3.984743118286133
Validation loss: 3.782925844192505

Epoch: 5| Step: 7
Training loss: 4.217723369598389
Validation loss: 3.7771832247575126

Epoch: 5| Step: 8
Training loss: 4.091115474700928
Validation loss: 3.771192193031311

Epoch: 5| Step: 9
Training loss: 3.9143874645233154
Validation loss: 3.76565549770991

Epoch: 5| Step: 10
Training loss: 3.5670089721679688
Validation loss: 3.7610421578089395

Epoch: 5| Step: 11
Training loss: 4.208827018737793
Validation loss: 3.755503018697103

Epoch: 24| Step: 0
Training loss: 4.162910461425781
Validation loss: 3.75089297691981

Epoch: 5| Step: 1
Training loss: 3.8778762817382812
Validation loss: 3.745813657840093

Epoch: 5| Step: 2
Training loss: 4.6227192878723145
Validation loss: 3.7412646412849426

Epoch: 5| Step: 3
Training loss: 3.522745132446289
Validation loss: 3.7344868083794913

Epoch: 5| Step: 4
Training loss: 4.093779563903809
Validation loss: 3.73001096645991

Epoch: 5| Step: 5
Training loss: 3.941149950027466
Validation loss: 3.7252574066321054

Epoch: 5| Step: 6
Training loss: 3.8910396099090576
Validation loss: 3.7209168473879495

Epoch: 5| Step: 7
Training loss: 3.556231737136841
Validation loss: 3.7161071797211966

Epoch: 5| Step: 8
Training loss: 3.7399277687072754
Validation loss: 3.711351066827774

Epoch: 5| Step: 9
Training loss: 2.778390407562256
Validation loss: 3.7066213488578796

Epoch: 5| Step: 10
Training loss: 4.5110344886779785
Validation loss: 3.7023375431696572

Epoch: 5| Step: 11
Training loss: 4.137742042541504
Validation loss: 3.6965404649575553

Epoch: 25| Step: 0
Training loss: 4.050940990447998
Validation loss: 3.691834976275762

Epoch: 5| Step: 1
Training loss: 5.211710453033447
Validation loss: 3.687443216641744

Epoch: 5| Step: 2
Training loss: 3.8198609352111816
Validation loss: 3.681721270084381

Epoch: 5| Step: 3
Training loss: 3.29243540763855
Validation loss: 3.677109638849894

Epoch: 5| Step: 4
Training loss: 3.7278411388397217
Validation loss: 3.6720504462718964

Epoch: 5| Step: 5
Training loss: 4.683736324310303
Validation loss: 3.666507432858149

Epoch: 5| Step: 6
Training loss: 2.9401323795318604
Validation loss: 3.661675105492274

Epoch: 5| Step: 7
Training loss: 3.6735024452209473
Validation loss: 3.656612495581309

Epoch: 5| Step: 8
Training loss: 2.8142409324645996
Validation loss: 3.6520394484202066

Epoch: 5| Step: 9
Training loss: 3.795527696609497
Validation loss: 3.646599074204763

Epoch: 5| Step: 10
Training loss: 3.8413562774658203
Validation loss: 3.640951414903005

Epoch: 5| Step: 11
Training loss: 5.1250152587890625
Validation loss: 3.6356565356254578

Epoch: 26| Step: 0
Training loss: 4.098686695098877
Validation loss: 3.630813052256902

Epoch: 5| Step: 1
Training loss: 3.488574981689453
Validation loss: 3.6260734498500824

Epoch: 5| Step: 2
Training loss: 3.758942127227783
Validation loss: 3.620982050895691

Epoch: 5| Step: 3
Training loss: 3.900317668914795
Validation loss: 3.6153704722722373

Epoch: 5| Step: 4
Training loss: 4.472551345825195
Validation loss: 3.6097546219825745

Epoch: 5| Step: 5
Training loss: 3.81394624710083
Validation loss: 3.6040057837963104

Epoch: 5| Step: 6
Training loss: 3.9520010948181152
Validation loss: 3.5993463893731437

Epoch: 5| Step: 7
Training loss: 3.708012342453003
Validation loss: 3.5933849811553955

Epoch: 5| Step: 8
Training loss: 3.169524669647217
Validation loss: 3.587908685207367

Epoch: 5| Step: 9
Training loss: 3.6368002891540527
Validation loss: 3.5834923485914865

Epoch: 5| Step: 10
Training loss: 3.5879852771759033
Validation loss: 3.5780038833618164

Epoch: 5| Step: 11
Training loss: 3.144181251525879
Validation loss: 3.57371778289477

Epoch: 27| Step: 0
Training loss: 3.1214325428009033
Validation loss: 3.5686929722627005

Epoch: 5| Step: 1
Training loss: 4.416774749755859
Validation loss: 3.5641431907812753

Epoch: 5| Step: 2
Training loss: 3.081277847290039
Validation loss: 3.5591863095760345

Epoch: 5| Step: 3
Training loss: 4.099329471588135
Validation loss: 3.554051657517751

Epoch: 5| Step: 4
Training loss: 3.4027206897735596
Validation loss: 3.549563338359197

Epoch: 5| Step: 5
Training loss: 3.5882651805877686
Validation loss: 3.54395400484403

Epoch: 5| Step: 6
Training loss: 3.3413302898406982
Validation loss: 3.5391800900300345

Epoch: 5| Step: 7
Training loss: 4.138294219970703
Validation loss: 3.534280389547348

Epoch: 5| Step: 8
Training loss: 4.091813087463379
Validation loss: 3.529444694519043

Epoch: 5| Step: 9
Training loss: 3.550419569015503
Validation loss: 3.5242732067902884

Epoch: 5| Step: 10
Training loss: 3.962085008621216
Validation loss: 3.51853076616923

Epoch: 5| Step: 11
Training loss: 3.675549030303955
Validation loss: 3.5145776172478995

Epoch: 28| Step: 0
Training loss: 4.285349369049072
Validation loss: 3.508391112089157

Epoch: 5| Step: 1
Training loss: 3.6998629570007324
Validation loss: 3.5035791794459024

Epoch: 5| Step: 2
Training loss: 2.0755889415740967
Validation loss: 3.498085637887319

Epoch: 5| Step: 3
Training loss: 3.7280478477478027
Validation loss: 3.494602253039678

Epoch: 5| Step: 4
Training loss: 3.9486916065216064
Validation loss: 3.4884562293688455

Epoch: 5| Step: 5
Training loss: 3.0349040031433105
Validation loss: 3.484126995007197

Epoch: 5| Step: 6
Training loss: 4.321719646453857
Validation loss: 3.479290703932444

Epoch: 5| Step: 7
Training loss: 3.551191806793213
Validation loss: 3.474470486243566

Epoch: 5| Step: 8
Training loss: 4.160854339599609
Validation loss: 3.469643880923589

Epoch: 5| Step: 9
Training loss: 4.438930034637451
Validation loss: 3.4645412266254425

Epoch: 5| Step: 10
Training loss: 2.883608341217041
Validation loss: 3.4595255156358085

Epoch: 5| Step: 11
Training loss: 3.724449634552002
Validation loss: 3.454920103152593

Epoch: 29| Step: 0
Training loss: 3.1261909008026123
Validation loss: 3.4514558712641397

Epoch: 5| Step: 1
Training loss: 3.5385563373565674
Validation loss: 3.4578815599282584

Epoch: 5| Step: 2
Training loss: 3.1646275520324707
Validation loss: 3.443788001934687

Epoch: 5| Step: 3
Training loss: 4.670620441436768
Validation loss: 3.4376089572906494

Epoch: 5| Step: 4
Training loss: 3.580308198928833
Validation loss: 3.431346515814463

Epoch: 5| Step: 5
Training loss: 3.545607805252075
Validation loss: 3.4268681009610495

Epoch: 5| Step: 6
Training loss: 3.7731540203094482
Validation loss: 3.4226440489292145

Epoch: 5| Step: 7
Training loss: 3.6187942028045654
Validation loss: 3.419695178667704

Epoch: 5| Step: 8
Training loss: 3.7830028533935547
Validation loss: 3.4148643612861633

Epoch: 5| Step: 9
Training loss: 3.143876552581787
Validation loss: 3.4108618398507438

Epoch: 5| Step: 10
Training loss: 4.126939296722412
Validation loss: 3.4053241113821664

Epoch: 5| Step: 11
Training loss: 1.0702085494995117
Validation loss: 3.400084465742111

Epoch: 30| Step: 0
Training loss: 3.921532154083252
Validation loss: 3.394065578778585

Epoch: 5| Step: 1
Training loss: 3.4908194541931152
Validation loss: 3.3882630268732705

Epoch: 5| Step: 2
Training loss: 3.1431007385253906
Validation loss: 3.3830610315004983

Epoch: 5| Step: 3
Training loss: 3.5424721240997314
Validation loss: 3.378215750058492

Epoch: 5| Step: 4
Training loss: 3.6329848766326904
Validation loss: 3.3734331727027893

Epoch: 5| Step: 5
Training loss: 3.7914557456970215
Validation loss: 3.369308809439341

Epoch: 5| Step: 6
Training loss: 4.009272575378418
Validation loss: 3.363515794277191

Epoch: 5| Step: 7
Training loss: 3.307715892791748
Validation loss: 3.359404901663462

Epoch: 5| Step: 8
Training loss: 3.0300488471984863
Validation loss: 3.3541020353635154

Epoch: 5| Step: 9
Training loss: 2.7838826179504395
Validation loss: 3.3495549062887826

Epoch: 5| Step: 10
Training loss: 4.123664855957031
Validation loss: 3.343898038069407

Epoch: 5| Step: 11
Training loss: 4.277107238769531
Validation loss: 3.3382603923479715

Epoch: 31| Step: 0
Training loss: 3.1642231941223145
Validation loss: 3.3334588607152305

Epoch: 5| Step: 1
Training loss: 4.232060432434082
Validation loss: 3.328119307756424

Epoch: 5| Step: 2
Training loss: 3.07167649269104
Validation loss: 3.322402666012446

Epoch: 5| Step: 3
Training loss: 3.794872760772705
Validation loss: 3.3175437450408936

Epoch: 5| Step: 4
Training loss: 2.941357135772705
Validation loss: 3.3129675090312958

Epoch: 5| Step: 5
Training loss: 3.5475082397460938
Validation loss: 3.308663715918859

Epoch: 5| Step: 6
Training loss: 3.202368974685669
Validation loss: 3.303805689016978

Epoch: 5| Step: 7
Training loss: 3.8274078369140625
Validation loss: 3.299395203590393

Epoch: 5| Step: 8
Training loss: 3.6228275299072266
Validation loss: 3.2954589227835336

Epoch: 5| Step: 9
Training loss: 3.555919647216797
Validation loss: 3.290305475393931

Epoch: 5| Step: 10
Training loss: 3.487339735031128
Validation loss: 3.2853659888108573

Epoch: 5| Step: 11
Training loss: 2.7329893112182617
Validation loss: 3.2809872031211853

Epoch: 32| Step: 0
Training loss: 3.3548426628112793
Validation loss: 3.276897688706716

Epoch: 5| Step: 1
Training loss: 4.184416770935059
Validation loss: 3.2723947763442993

Epoch: 5| Step: 2
Training loss: 3.4852898120880127
Validation loss: 3.269146651029587

Epoch: 5| Step: 3
Training loss: 3.1862988471984863
Validation loss: 3.2677630186080933

Epoch: 5| Step: 4
Training loss: 3.3594298362731934
Validation loss: 3.26089741786321

Epoch: 5| Step: 5
Training loss: 3.364737033843994
Validation loss: 3.254280149936676

Epoch: 5| Step: 6
Training loss: 3.165645122528076
Validation loss: 3.2498349944750466

Epoch: 5| Step: 7
Training loss: 3.2011685371398926
Validation loss: 3.2462455133597055

Epoch: 5| Step: 8
Training loss: 3.34849214553833
Validation loss: 3.242674320936203

Epoch: 5| Step: 9
Training loss: 3.2168312072753906
Validation loss: 3.237862080335617

Epoch: 5| Step: 10
Training loss: 3.5809547901153564
Validation loss: 3.233753283818563

Epoch: 5| Step: 11
Training loss: 4.942072868347168
Validation loss: 3.2298169136047363

Epoch: 33| Step: 0
Training loss: 3.535155773162842
Validation loss: 3.2241898079713187

Epoch: 5| Step: 1
Training loss: 3.266376495361328
Validation loss: 3.21934782465299

Epoch: 5| Step: 2
Training loss: 3.3517372608184814
Validation loss: 3.2154920200506845

Epoch: 5| Step: 3
Training loss: 3.477220058441162
Validation loss: 3.2108289500077567

Epoch: 5| Step: 4
Training loss: 3.4168343544006348
Validation loss: 3.2070246040821075

Epoch: 5| Step: 5
Training loss: 3.840855360031128
Validation loss: 3.2025691072146096

Epoch: 5| Step: 6
Training loss: 3.182638645172119
Validation loss: 3.1976799964904785

Epoch: 5| Step: 7
Training loss: 3.3557960987091064
Validation loss: 3.1930902302265167

Epoch: 5| Step: 8
Training loss: 3.7984585762023926
Validation loss: 3.1886799037456512

Epoch: 5| Step: 9
Training loss: 3.243809938430786
Validation loss: 3.1841745177904763

Epoch: 5| Step: 10
Training loss: 2.6615569591522217
Validation loss: 3.1794267197450004

Epoch: 5| Step: 11
Training loss: 3.765028476715088
Validation loss: 3.1751119593779245

Epoch: 34| Step: 0
Training loss: 3.517075300216675
Validation loss: 3.170212378104528

Epoch: 5| Step: 1
Training loss: 3.554259777069092
Validation loss: 3.165597915649414

Epoch: 5| Step: 2
Training loss: 2.756240129470825
Validation loss: 3.1609691778818765

Epoch: 5| Step: 3
Training loss: 4.208347320556641
Validation loss: 3.1561773220698037

Epoch: 5| Step: 4
Training loss: 3.3160901069641113
Validation loss: 3.1517785290877023

Epoch: 5| Step: 5
Training loss: 3.0697388648986816
Validation loss: 3.1471821665763855

Epoch: 5| Step: 6
Training loss: 3.3279366493225098
Validation loss: 3.143362432718277

Epoch: 5| Step: 7
Training loss: 3.052760124206543
Validation loss: 3.1399194796880088

Epoch: 5| Step: 8
Training loss: 2.663079023361206
Validation loss: 3.134933272997538

Epoch: 5| Step: 9
Training loss: 3.094849109649658
Validation loss: 3.130686938762665

Epoch: 5| Step: 10
Training loss: 3.8902359008789062
Validation loss: 3.127084344625473

Epoch: 5| Step: 11
Training loss: 4.375077247619629
Validation loss: 3.1233264108498893

Epoch: 35| Step: 0
Training loss: 2.554536819458008
Validation loss: 3.1186782717704773

Epoch: 5| Step: 1
Training loss: 3.4768128395080566
Validation loss: 3.1135426064332328

Epoch: 5| Step: 2
Training loss: 3.847736358642578
Validation loss: 3.10954749584198

Epoch: 5| Step: 3
Training loss: 2.8748621940612793
Validation loss: 3.104421009620031

Epoch: 5| Step: 4
Training loss: 2.4946587085723877
Validation loss: 3.100568801164627

Epoch: 5| Step: 5
Training loss: 3.4819629192352295
Validation loss: 3.096198091904322

Epoch: 5| Step: 6
Training loss: 3.483374834060669
Validation loss: 3.09229044119517

Epoch: 5| Step: 7
Training loss: 3.1700351238250732
Validation loss: 3.0892016192277274

Epoch: 5| Step: 8
Training loss: 3.494534969329834
Validation loss: 3.084438592195511

Epoch: 5| Step: 9
Training loss: 3.533238172531128
Validation loss: 3.080536554257075

Epoch: 5| Step: 10
Training loss: 3.4887828826904297
Validation loss: 3.0776016116142273

Epoch: 5| Step: 11
Training loss: 4.448258399963379
Validation loss: 3.0734804371992746

Epoch: 36| Step: 0
Training loss: 3.739661455154419
Validation loss: 3.069175193707148

Epoch: 5| Step: 1
Training loss: 3.1576201915740967
Validation loss: 3.0648587544759116

Epoch: 5| Step: 2
Training loss: 3.7631747722625732
Validation loss: 3.0614736676216125

Epoch: 5| Step: 3
Training loss: 2.970766067504883
Validation loss: 3.0570462346076965

Epoch: 5| Step: 4
Training loss: 3.778409242630005
Validation loss: 3.053128490845362

Epoch: 5| Step: 5
Training loss: 2.99296498298645
Validation loss: 3.049095024665197

Epoch: 5| Step: 6
Training loss: 3.555785655975342
Validation loss: 3.045254478851954

Epoch: 5| Step: 7
Training loss: 2.7518362998962402
Validation loss: 3.041079839070638

Epoch: 5| Step: 8
Training loss: 3.3179931640625
Validation loss: 3.037552217642466

Epoch: 5| Step: 9
Training loss: 2.885361433029175
Validation loss: 3.033584942420324

Epoch: 5| Step: 10
Training loss: 2.876631736755371
Validation loss: 3.029942641655604

Epoch: 5| Step: 11
Training loss: 2.501068115234375
Validation loss: 3.026073227326075

Epoch: 37| Step: 0
Training loss: 2.25547194480896
Validation loss: 3.0224474668502808

Epoch: 5| Step: 1
Training loss: 4.041153430938721
Validation loss: 3.019007762273153

Epoch: 5| Step: 2
Training loss: 3.1038460731506348
Validation loss: 3.015861223141352

Epoch: 5| Step: 3
Training loss: 2.780125141143799
Validation loss: 3.012436330318451

Epoch: 5| Step: 4
Training loss: 3.2100441455841064
Validation loss: 3.0087084571520486

Epoch: 5| Step: 5
Training loss: 3.0550458431243896
Validation loss: 3.0059545934200287

Epoch: 5| Step: 6
Training loss: 2.8589017391204834
Validation loss: 3.0025384426116943

Epoch: 5| Step: 7
Training loss: 3.7571139335632324
Validation loss: 2.9993417859077454

Epoch: 5| Step: 8
Training loss: 3.330873966217041
Validation loss: 2.9953794380029044

Epoch: 5| Step: 9
Training loss: 3.535165309906006
Validation loss: 2.99197726448377

Epoch: 5| Step: 10
Training loss: 3.2284836769104004
Validation loss: 2.9882524013519287

Epoch: 5| Step: 11
Training loss: 3.2758588790893555
Validation loss: 2.985414127508799

Epoch: 38| Step: 0
Training loss: 2.8820302486419678
Validation loss: 2.9825875659783683

Epoch: 5| Step: 1
Training loss: 3.1188530921936035
Validation loss: 2.977756897608439

Epoch: 5| Step: 2
Training loss: 3.4912350177764893
Validation loss: 2.9761625230312347

Epoch: 5| Step: 3
Training loss: 3.0302722454071045
Validation loss: 2.9717676838239035

Epoch: 5| Step: 4
Training loss: 3.145364284515381
Validation loss: 2.969010204076767

Epoch: 5| Step: 5
Training loss: 3.3418705463409424
Validation loss: 2.964945286512375

Epoch: 5| Step: 6
Training loss: 3.2985129356384277
Validation loss: 2.962011198202769

Epoch: 5| Step: 7
Training loss: 2.8721330165863037
Validation loss: 2.95808415611585

Epoch: 5| Step: 8
Training loss: 2.5892484188079834
Validation loss: 2.9552704095840454

Epoch: 5| Step: 9
Training loss: 3.4034817218780518
Validation loss: 2.951739956935247

Epoch: 5| Step: 10
Training loss: 3.9390501976013184
Validation loss: 2.9485138952732086

Epoch: 5| Step: 11
Training loss: 1.4645133018493652
Validation loss: 2.9444148540496826

Epoch: 39| Step: 0
Training loss: 3.539714813232422
Validation loss: 2.941496709982554

Epoch: 5| Step: 1
Training loss: 3.0011630058288574
Validation loss: 2.9384565353393555

Epoch: 5| Step: 2
Training loss: 2.3778891563415527
Validation loss: 2.935199727614721

Epoch: 5| Step: 3
Training loss: 3.273324489593506
Validation loss: 2.9321768283843994

Epoch: 5| Step: 4
Training loss: 3.317671298980713
Validation loss: 2.928457885980606

Epoch: 5| Step: 5
Training loss: 2.8512778282165527
Validation loss: 2.926080822944641

Epoch: 5| Step: 6
Training loss: 3.5303966999053955
Validation loss: 2.921735425790151

Epoch: 5| Step: 7
Training loss: 3.0219931602478027
Validation loss: 2.9198882281780243

Epoch: 5| Step: 8
Training loss: 2.947418212890625
Validation loss: 2.920334299405416

Epoch: 5| Step: 9
Training loss: 3.3169689178466797
Validation loss: 2.914329578479131

Epoch: 5| Step: 10
Training loss: 2.784738063812256
Validation loss: 2.909813702106476

Epoch: 5| Step: 11
Training loss: 5.229887962341309
Validation loss: 2.9074028631051383

Epoch: 40| Step: 0
Training loss: 3.065725088119507
Validation loss: 2.9027558863162994

Epoch: 5| Step: 1
Training loss: 2.919797420501709
Validation loss: 2.8999870816866555

Epoch: 5| Step: 2
Training loss: 3.406581401824951
Validation loss: 2.8969249029954276

Epoch: 5| Step: 3
Training loss: 3.8655478954315186
Validation loss: 2.8930060664812722

Epoch: 5| Step: 4
Training loss: 2.5979671478271484
Validation loss: 2.8889480928579965

Epoch: 5| Step: 5
Training loss: 3.2308590412139893
Validation loss: 2.885711203018824

Epoch: 5| Step: 6
Training loss: 2.836146831512451
Validation loss: 2.8816377321879068

Epoch: 5| Step: 7
Training loss: 2.742208480834961
Validation loss: 2.878310134013494

Epoch: 5| Step: 8
Training loss: 2.948946475982666
Validation loss: 2.8753305772940316

Epoch: 5| Step: 9
Training loss: 2.707984447479248
Validation loss: 2.8716995120048523

Epoch: 5| Step: 10
Training loss: 3.4860968589782715
Validation loss: 2.8699364165465036

Epoch: 5| Step: 11
Training loss: 4.0739336013793945
Validation loss: 2.864870766798655

Epoch: 41| Step: 0
Training loss: 2.548410177230835
Validation loss: 2.8626133501529694

Epoch: 5| Step: 1
Training loss: 3.2829558849334717
Validation loss: 2.858085403839747

Epoch: 5| Step: 2
Training loss: 2.9839589595794678
Validation loss: 2.8550818065802255

Epoch: 5| Step: 3
Training loss: 3.4154205322265625
Validation loss: 2.85264919201533

Epoch: 5| Step: 4
Training loss: 2.4565155506134033
Validation loss: 2.8520473142464957

Epoch: 5| Step: 5
Training loss: 2.7223217487335205
Validation loss: 2.8564887990554175

Epoch: 5| Step: 6
Training loss: 2.902008056640625
Validation loss: 2.8414205461740494

Epoch: 5| Step: 7
Training loss: 3.4983017444610596
Validation loss: 2.8388556639353433

Epoch: 5| Step: 8
Training loss: 3.407003402709961
Validation loss: 2.8362475434939065

Epoch: 5| Step: 9
Training loss: 2.930488109588623
Validation loss: 2.8343010445435843

Epoch: 5| Step: 10
Training loss: 3.2351016998291016
Validation loss: 2.833811362584432

Epoch: 5| Step: 11
Training loss: 4.146787643432617
Validation loss: 2.8302570482095084

Epoch: 42| Step: 0
Training loss: 3.813396453857422
Validation loss: 2.8264930148919425

Epoch: 5| Step: 1
Training loss: 2.6692376136779785
Validation loss: 2.822268714507421

Epoch: 5| Step: 2
Training loss: 3.0234808921813965
Validation loss: 2.818750709295273

Epoch: 5| Step: 3
Training loss: 2.945767641067505
Validation loss: 2.814567198355993

Epoch: 5| Step: 4
Training loss: 3.354457378387451
Validation loss: 2.811447113752365

Epoch: 5| Step: 5
Training loss: 2.620944023132324
Validation loss: 2.80758069952329

Epoch: 5| Step: 6
Training loss: 2.805140256881714
Validation loss: 2.8049132029215493

Epoch: 5| Step: 7
Training loss: 2.5386126041412354
Validation loss: 2.802271455526352

Epoch: 5| Step: 8
Training loss: 2.914118766784668
Validation loss: 2.7995668053627014

Epoch: 5| Step: 9
Training loss: 3.134826898574829
Validation loss: 2.7967332005500793

Epoch: 5| Step: 10
Training loss: 3.4941604137420654
Validation loss: 2.7943790753682456

Epoch: 5| Step: 11
Training loss: 2.4794445037841797
Validation loss: 2.790176103512446

Epoch: 43| Step: 0
Training loss: 2.7106685638427734
Validation loss: 2.786699563264847

Epoch: 5| Step: 1
Training loss: 2.9898362159729004
Validation loss: 2.783666064341863

Epoch: 5| Step: 2
Training loss: 2.9143192768096924
Validation loss: 2.780845691760381

Epoch: 5| Step: 3
Training loss: 2.8495705127716064
Validation loss: 2.7778566678365073

Epoch: 5| Step: 4
Training loss: 3.1543617248535156
Validation loss: 2.7724923690160117

Epoch: 5| Step: 5
Training loss: 3.4199154376983643
Validation loss: 2.769843578338623

Epoch: 5| Step: 6
Training loss: 3.0049614906311035
Validation loss: 2.7663799226284027

Epoch: 5| Step: 7
Training loss: 3.2887489795684814
Validation loss: 2.76341183980306

Epoch: 5| Step: 8
Training loss: 2.675089120864868
Validation loss: 2.760420391956965

Epoch: 5| Step: 9
Training loss: 2.7816996574401855
Validation loss: 2.756584112842878

Epoch: 5| Step: 10
Training loss: 2.9408302307128906
Validation loss: 2.753618687391281

Epoch: 5| Step: 11
Training loss: 3.2542994022369385
Validation loss: 2.750724951426188

Epoch: 44| Step: 0
Training loss: 2.8374030590057373
Validation loss: 2.746966232856115

Epoch: 5| Step: 1
Training loss: 3.0944972038269043
Validation loss: 2.745176543792089

Epoch: 5| Step: 2
Training loss: 2.5697739124298096
Validation loss: 2.7421843806902566

Epoch: 5| Step: 3
Training loss: 2.819261074066162
Validation loss: 2.739871551593145

Epoch: 5| Step: 4
Training loss: 4.025906562805176
Validation loss: 2.7369030813376107

Epoch: 5| Step: 5
Training loss: 3.1337196826934814
Validation loss: 2.7342678209145865

Epoch: 5| Step: 6
Training loss: 2.6336891651153564
Validation loss: 2.730829139550527

Epoch: 5| Step: 7
Training loss: 2.727442979812622
Validation loss: 2.7276207705338797

Epoch: 5| Step: 8
Training loss: 2.7080483436584473
Validation loss: 2.7238938311735788

Epoch: 5| Step: 9
Training loss: 3.2032322883605957
Validation loss: 2.721622556447983

Epoch: 5| Step: 10
Training loss: 2.7462410926818848
Validation loss: 2.718569576740265

Epoch: 5| Step: 11
Training loss: 2.2635860443115234
Validation loss: 2.7155664563179016

Epoch: 45| Step: 0
Training loss: 2.928492546081543
Validation loss: 2.7126901745796204

Epoch: 5| Step: 1
Training loss: 2.3871383666992188
Validation loss: 2.7086081306139627

Epoch: 5| Step: 2
Training loss: 3.3741679191589355
Validation loss: 2.7055543959140778

Epoch: 5| Step: 3
Training loss: 2.9004554748535156
Validation loss: 2.703286737203598

Epoch: 5| Step: 4
Training loss: 3.376934766769409
Validation loss: 2.7003256380558014

Epoch: 5| Step: 5
Training loss: 3.0732903480529785
Validation loss: 2.6990685164928436

Epoch: 5| Step: 6
Training loss: 2.785521984100342
Validation loss: 2.695641666650772

Epoch: 5| Step: 7
Training loss: 3.0703189373016357
Validation loss: 2.6916255553563437

Epoch: 5| Step: 8
Training loss: 2.992265224456787
Validation loss: 2.690275937318802

Epoch: 5| Step: 9
Training loss: 2.78926157951355
Validation loss: 2.6861556569735208

Epoch: 5| Step: 10
Training loss: 2.672806978225708
Validation loss: 2.6837683022022247

Epoch: 5| Step: 11
Training loss: 0.9513061046600342
Validation loss: 2.6811088919639587

Epoch: 46| Step: 0
Training loss: 2.7247002124786377
Validation loss: 2.67893323302269

Epoch: 5| Step: 1
Training loss: 3.0733189582824707
Validation loss: 2.6826197107632956

Epoch: 5| Step: 2
Training loss: 2.5930533409118652
Validation loss: 2.67308176557223

Epoch: 5| Step: 3
Training loss: 2.1874983310699463
Validation loss: 2.6682073126236596

Epoch: 5| Step: 4
Training loss: 3.152160167694092
Validation loss: 2.666355619827906

Epoch: 5| Step: 5
Training loss: 2.951733350753784
Validation loss: 2.6657306849956512

Epoch: 5| Step: 6
Training loss: 2.7336184978485107
Validation loss: 2.6645180881023407

Epoch: 5| Step: 7
Training loss: 3.519146680831909
Validation loss: 2.6635649303595224

Epoch: 5| Step: 8
Training loss: 3.118765354156494
Validation loss: 2.6613125602404275

Epoch: 5| Step: 9
Training loss: 2.6417653560638428
Validation loss: 2.660272538661957

Epoch: 5| Step: 10
Training loss: 2.8615338802337646
Validation loss: 2.656845102707545

Epoch: 5| Step: 11
Training loss: 3.171766757965088
Validation loss: 2.650972525278727

Epoch: 47| Step: 0
Training loss: 2.5437541007995605
Validation loss: 2.6473023494084678

Epoch: 5| Step: 1
Training loss: 2.8837032318115234
Validation loss: 2.6433851619561515

Epoch: 5| Step: 2
Training loss: 2.8281590938568115
Validation loss: 2.6404367089271545

Epoch: 5| Step: 3
Training loss: 3.3100483417510986
Validation loss: 2.6362667183081308

Epoch: 5| Step: 4
Training loss: 2.973844051361084
Validation loss: 2.632290552059809

Epoch: 5| Step: 5
Training loss: 3.071690082550049
Validation loss: 2.629719932874044

Epoch: 5| Step: 6
Training loss: 2.9253852367401123
Validation loss: 2.626780112584432

Epoch: 5| Step: 7
Training loss: 2.977957248687744
Validation loss: 2.6246388653914132

Epoch: 5| Step: 8
Training loss: 2.4022557735443115
Validation loss: 2.626566936572393

Epoch: 5| Step: 9
Training loss: 2.233891248703003
Validation loss: 2.6235848367214203

Epoch: 5| Step: 10
Training loss: 3.285335063934326
Validation loss: 2.6224766770998635

Epoch: 5| Step: 11
Training loss: 1.6485161781311035
Validation loss: 2.609327644109726

Epoch: 48| Step: 0
Training loss: 3.391291379928589
Validation loss: 2.6095243791739144

Epoch: 5| Step: 1
Training loss: 2.7687087059020996
Validation loss: 2.6108454366525016

Epoch: 5| Step: 2
Training loss: 3.2061660289764404
Validation loss: 2.6139914194742837

Epoch: 5| Step: 3
Training loss: 3.114501714706421
Validation loss: 2.6113443821668625

Epoch: 5| Step: 4
Training loss: 2.8397269248962402
Validation loss: 2.620641221602758

Epoch: 5| Step: 5
Training loss: 2.4421229362487793
Validation loss: 2.607693980137507

Epoch: 5| Step: 6
Training loss: 2.4757657051086426
Validation loss: 2.6005043188730874

Epoch: 5| Step: 7
Training loss: 2.7020316123962402
Validation loss: 2.5964044531186423

Epoch: 5| Step: 8
Training loss: 2.1657028198242188
Validation loss: 2.593035807212194

Epoch: 5| Step: 9
Training loss: 2.9766688346862793
Validation loss: 2.591418037811915

Epoch: 5| Step: 10
Training loss: 2.9838638305664062
Validation loss: 2.5892977317174277

Epoch: 5| Step: 11
Training loss: 1.8355858325958252
Validation loss: 2.5863693356513977

Epoch: 49| Step: 0
Training loss: 2.4785780906677246
Validation loss: 2.58283269405365

Epoch: 5| Step: 1
Training loss: 3.19364595413208
Validation loss: 2.5793504615624747

Epoch: 5| Step: 2
Training loss: 2.9192752838134766
Validation loss: 2.5774015486240387

Epoch: 5| Step: 3
Training loss: 3.034414291381836
Validation loss: 2.572814573844274

Epoch: 5| Step: 4
Training loss: 2.631470203399658
Validation loss: 2.57341797153155

Epoch: 5| Step: 5
Training loss: 2.129793643951416
Validation loss: 2.5703120778004327

Epoch: 5| Step: 6
Training loss: 2.8623507022857666
Validation loss: 2.5691528817017875

Epoch: 5| Step: 7
Training loss: 2.8090176582336426
Validation loss: 2.564618468284607

Epoch: 5| Step: 8
Training loss: 2.987576723098755
Validation loss: 2.559955765803655

Epoch: 5| Step: 9
Training loss: 2.558603286743164
Validation loss: 2.5584942996501923

Epoch: 5| Step: 10
Training loss: 2.6272425651550293
Validation loss: 2.5557425916194916

Epoch: 5| Step: 11
Training loss: 3.966503143310547
Validation loss: 2.5527078807353973

Epoch: 50| Step: 0
Training loss: 2.547403335571289
Validation loss: 2.550586332877477

Epoch: 5| Step: 1
Training loss: 3.1654694080352783
Validation loss: 2.5478451251983643

Epoch: 5| Step: 2
Training loss: 3.221283435821533
Validation loss: 2.5456390380859375

Epoch: 5| Step: 3
Training loss: 2.753298282623291
Validation loss: 2.542678793271383

Epoch: 5| Step: 4
Training loss: 2.5583152770996094
Validation loss: 2.5404994189739227

Epoch: 5| Step: 5
Training loss: 3.1322579383850098
Validation loss: 2.53702312707901

Epoch: 5| Step: 6
Training loss: 2.6916046142578125
Validation loss: 2.533830483754476

Epoch: 5| Step: 7
Training loss: 2.6181042194366455
Validation loss: 2.531712621450424

Epoch: 5| Step: 8
Training loss: 1.8894065618515015
Validation loss: 2.5298287123441696

Epoch: 5| Step: 9
Training loss: 2.8010873794555664
Validation loss: 2.5259316861629486

Epoch: 5| Step: 10
Training loss: 2.7036170959472656
Validation loss: 2.5235142906506858

Epoch: 5| Step: 11
Training loss: 2.69735050201416
Validation loss: 2.5214236080646515

Epoch: 51| Step: 0
Training loss: 2.3631370067596436
Validation loss: 2.5166698644558587

Epoch: 5| Step: 1
Training loss: 2.5484604835510254
Validation loss: 2.5160394410292306

Epoch: 5| Step: 2
Training loss: 2.4667716026306152
Validation loss: 2.514459023873011

Epoch: 5| Step: 3
Training loss: 3.045907497406006
Validation loss: 2.5113986233870187

Epoch: 5| Step: 4
Training loss: 2.440934896469116
Validation loss: 2.508781065543493

Epoch: 5| Step: 5
Training loss: 2.139944076538086
Validation loss: 2.504611983895302

Epoch: 5| Step: 6
Training loss: 3.066534996032715
Validation loss: 2.502272069454193

Epoch: 5| Step: 7
Training loss: 3.241360902786255
Validation loss: 2.501027504603068

Epoch: 5| Step: 8
Training loss: 2.925097703933716
Validation loss: 2.498038500547409

Epoch: 5| Step: 9
Training loss: 2.875359058380127
Validation loss: 2.494200348854065

Epoch: 5| Step: 10
Training loss: 2.752272844314575
Validation loss: 2.49192076921463

Epoch: 5| Step: 11
Training loss: 1.9110279083251953
Validation loss: 2.490461121002833

Epoch: 52| Step: 0
Training loss: 3.385974884033203
Validation loss: 2.4943851033846536

Epoch: 5| Step: 1
Training loss: 2.407473564147949
Validation loss: 2.4952738881111145

Epoch: 5| Step: 2
Training loss: 2.128999948501587
Validation loss: 2.4961520781119666

Epoch: 5| Step: 3
Training loss: 2.6445140838623047
Validation loss: 2.49409227569898

Epoch: 5| Step: 4
Training loss: 3.0523736476898193
Validation loss: 2.4848503371079764

Epoch: 5| Step: 5
Training loss: 2.650160551071167
Validation loss: 2.4791443149248757

Epoch: 5| Step: 6
Training loss: 2.7645843029022217
Validation loss: 2.474054753780365

Epoch: 5| Step: 7
Training loss: 2.2468457221984863
Validation loss: 2.473158280054728

Epoch: 5| Step: 8
Training loss: 2.762697458267212
Validation loss: 2.4732116709152856

Epoch: 5| Step: 9
Training loss: 3.2328076362609863
Validation loss: 2.4716972410678864

Epoch: 5| Step: 10
Training loss: 2.1543846130371094
Validation loss: 2.471405585606893

Epoch: 5| Step: 11
Training loss: 2.647994041442871
Validation loss: 2.467747539281845

Epoch: 53| Step: 0
Training loss: 3.1365890502929688
Validation loss: 2.4663288295269012

Epoch: 5| Step: 1
Training loss: 2.3664021492004395
Validation loss: 2.4636378288269043

Epoch: 5| Step: 2
Training loss: 3.147387981414795
Validation loss: 2.4608164280653

Epoch: 5| Step: 3
Training loss: 2.589721202850342
Validation loss: 2.460071583588918

Epoch: 5| Step: 4
Training loss: 3.165097951889038
Validation loss: 2.4572429160277047

Epoch: 5| Step: 5
Training loss: 2.8493752479553223
Validation loss: 2.455107718706131

Epoch: 5| Step: 6
Training loss: 2.7429146766662598
Validation loss: 2.451295534769694

Epoch: 5| Step: 7
Training loss: 1.9987716674804688
Validation loss: 2.4480595141649246

Epoch: 5| Step: 8
Training loss: 2.0674073696136475
Validation loss: 2.4465461870034537

Epoch: 5| Step: 9
Training loss: 2.125836133956909
Validation loss: 2.443927804629008

Epoch: 5| Step: 10
Training loss: 2.6563892364501953
Validation loss: 2.4409594734509787

Epoch: 5| Step: 11
Training loss: 3.8475730419158936
Validation loss: 2.4400856494903564

Epoch: 54| Step: 0
Training loss: 2.9972140789031982
Validation loss: 2.438179741303126

Epoch: 5| Step: 1
Training loss: 2.6934611797332764
Validation loss: 2.4345548848311105

Epoch: 5| Step: 2
Training loss: 2.7905325889587402
Validation loss: 2.430401533842087

Epoch: 5| Step: 3
Training loss: 3.1234750747680664
Validation loss: 2.4288282692432404

Epoch: 5| Step: 4
Training loss: 2.578726291656494
Validation loss: 2.423974722623825

Epoch: 5| Step: 5
Training loss: 2.5275661945343018
Validation loss: 2.4235121508439383

Epoch: 5| Step: 6
Training loss: 1.7763429880142212
Validation loss: 2.4202172656853995

Epoch: 5| Step: 7
Training loss: 2.2810921669006348
Validation loss: 2.4170226951440177

Epoch: 5| Step: 8
Training loss: 2.3550047874450684
Validation loss: 2.4162229200204215

Epoch: 5| Step: 9
Training loss: 2.801431655883789
Validation loss: 2.4114893674850464

Epoch: 5| Step: 10
Training loss: 2.8230607509613037
Validation loss: 2.4122427801291146

Epoch: 5| Step: 11
Training loss: 2.573452949523926
Validation loss: 2.410308544834455

Epoch: 55| Step: 0
Training loss: 2.396547317504883
Validation loss: 2.4059742093086243

Epoch: 5| Step: 1
Training loss: 2.706364870071411
Validation loss: 2.403701514005661

Epoch: 5| Step: 2
Training loss: 2.3211374282836914
Validation loss: 2.4019604523976645

Epoch: 5| Step: 3
Training loss: 2.739776372909546
Validation loss: 2.3978305955727897

Epoch: 5| Step: 4
Training loss: 2.3279809951782227
Validation loss: 2.3980206648508706

Epoch: 5| Step: 5
Training loss: 2.513414144515991
Validation loss: 2.3950427075227103

Epoch: 5| Step: 6
Training loss: 2.881685733795166
Validation loss: 2.3916019101937613

Epoch: 5| Step: 7
Training loss: 2.4673800468444824
Validation loss: 2.3888575633366904

Epoch: 5| Step: 8
Training loss: 3.09700608253479
Validation loss: 2.3861922721068063

Epoch: 5| Step: 9
Training loss: 2.6785194873809814
Validation loss: 2.3856425434350967

Epoch: 5| Step: 10
Training loss: 2.172390937805176
Validation loss: 2.3837641775608063

Epoch: 5| Step: 11
Training loss: 2.9100096225738525
Validation loss: 2.381062537431717

Epoch: 56| Step: 0
Training loss: 2.7813973426818848
Validation loss: 2.377680003643036

Epoch: 5| Step: 1
Training loss: 2.612947940826416
Validation loss: 2.376974195241928

Epoch: 5| Step: 2
Training loss: 2.9719550609588623
Validation loss: 2.3730110029379525

Epoch: 5| Step: 3
Training loss: 2.5873453617095947
Validation loss: 2.374337524175644

Epoch: 5| Step: 4
Training loss: 2.663466691970825
Validation loss: 2.3675624827543893

Epoch: 5| Step: 5
Training loss: 2.595548152923584
Validation loss: 2.3663562138875327

Epoch: 5| Step: 6
Training loss: 2.190498113632202
Validation loss: 2.363985523581505

Epoch: 5| Step: 7
Training loss: 2.1093826293945312
Validation loss: 2.361939380566279

Epoch: 5| Step: 8
Training loss: 2.470578670501709
Validation loss: 2.3605583906173706

Epoch: 5| Step: 9
Training loss: 2.566470146179199
Validation loss: 2.359184900919596

Epoch: 5| Step: 10
Training loss: 2.5531344413757324
Validation loss: 2.354790190855662

Epoch: 5| Step: 11
Training loss: 2.1906192302703857
Validation loss: 2.3541163553794227

Epoch: 57| Step: 0
Training loss: 2.4054107666015625
Validation loss: 2.352399761478106

Epoch: 5| Step: 1
Training loss: 2.9443178176879883
Validation loss: 2.3492798109849296

Epoch: 5| Step: 2
Training loss: 2.7278618812561035
Validation loss: 2.3446191251277924

Epoch: 5| Step: 3
Training loss: 2.6923775672912598
Validation loss: 2.3436862925688424

Epoch: 5| Step: 4
Training loss: 2.170140266418457
Validation loss: 2.341807226339976

Epoch: 5| Step: 5
Training loss: 2.0859875679016113
Validation loss: 2.339180509249369

Epoch: 5| Step: 6
Training loss: 2.2379002571105957
Validation loss: 2.3363154232501984

Epoch: 5| Step: 7
Training loss: 2.922285795211792
Validation loss: 2.3359706103801727

Epoch: 5| Step: 8
Training loss: 2.8435592651367188
Validation loss: 2.3328117231527963

Epoch: 5| Step: 9
Training loss: 1.9628206491470337
Validation loss: 2.3326578736305237

Epoch: 5| Step: 10
Training loss: 2.6777942180633545
Validation loss: 2.332250783840815

Epoch: 5| Step: 11
Training loss: 2.927760601043701
Validation loss: 2.3315419356028237

Epoch: 58| Step: 0
Training loss: 2.5368692874908447
Validation loss: 2.326371282339096

Epoch: 5| Step: 1
Training loss: 2.222303867340088
Validation loss: 2.3211924731731415

Epoch: 5| Step: 2
Training loss: 2.6134512424468994
Validation loss: 2.321762502193451

Epoch: 5| Step: 3
Training loss: 2.7293810844421387
Validation loss: 2.3244884610176086

Epoch: 5| Step: 4
Training loss: 2.5228512287139893
Validation loss: 2.3234711488087973

Epoch: 5| Step: 5
Training loss: 2.7817845344543457
Validation loss: 2.3246484100818634

Epoch: 5| Step: 6
Training loss: 1.9337819814682007
Validation loss: 2.3102691968282065

Epoch: 5| Step: 7
Training loss: 2.5933029651641846
Validation loss: 2.3076545149087906

Epoch: 5| Step: 8
Training loss: 2.7467799186706543
Validation loss: 2.309610426425934

Epoch: 5| Step: 9
Training loss: 2.9929442405700684
Validation loss: 2.306794156630834

Epoch: 5| Step: 10
Training loss: 1.783628225326538
Validation loss: 2.305012355248133

Epoch: 5| Step: 11
Training loss: 2.378488779067993
Validation loss: 2.304817885160446

Epoch: 59| Step: 0
Training loss: 2.8027381896972656
Validation loss: 2.3007259418567023

Epoch: 5| Step: 1
Training loss: 2.2110331058502197
Validation loss: 2.3001625140508017

Epoch: 5| Step: 2
Training loss: 1.9539821147918701
Validation loss: 2.2990550994873047

Epoch: 5| Step: 3
Training loss: 2.0722508430480957
Validation loss: 2.30076934893926

Epoch: 5| Step: 4
Training loss: 2.3818931579589844
Validation loss: 2.30311311284701

Epoch: 5| Step: 5
Training loss: 2.6331779956817627
Validation loss: 2.2941001703341803

Epoch: 5| Step: 6
Training loss: 2.516977310180664
Validation loss: 2.2893781512975693

Epoch: 5| Step: 7
Training loss: 2.2931344509124756
Validation loss: 2.28823188940684

Epoch: 5| Step: 8
Training loss: 3.109513759613037
Validation loss: 2.288085386157036

Epoch: 5| Step: 9
Training loss: 3.22663950920105
Validation loss: 2.294940948486328

Epoch: 5| Step: 10
Training loss: 1.870473861694336
Validation loss: 2.289895330866178

Epoch: 5| Step: 11
Training loss: 2.4057106971740723
Validation loss: 2.298464079697927

Epoch: 60| Step: 0
Training loss: 2.1264774799346924
Validation loss: 2.2830514709154763

Epoch: 5| Step: 1
Training loss: 2.0248143672943115
Validation loss: 2.278693879644076

Epoch: 5| Step: 2
Training loss: 2.3099961280822754
Validation loss: 2.2704680065313974

Epoch: 5| Step: 3
Training loss: 2.21321439743042
Validation loss: 2.2691749135653176

Epoch: 5| Step: 4
Training loss: 2.4801766872406006
Validation loss: 2.2685649941364923

Epoch: 5| Step: 5
Training loss: 2.4638991355895996
Validation loss: 2.2689788937568665

Epoch: 5| Step: 6
Training loss: 2.2902896404266357
Validation loss: 2.2646081944306693

Epoch: 5| Step: 7
Training loss: 3.159951686859131
Validation loss: 2.260623812675476

Epoch: 5| Step: 8
Training loss: 2.7930612564086914
Validation loss: 2.258642464876175

Epoch: 5| Step: 9
Training loss: 2.7511422634124756
Validation loss: 2.2585835059483848

Epoch: 5| Step: 10
Training loss: 2.2546706199645996
Validation loss: 2.2577237635850906

Epoch: 5| Step: 11
Training loss: 1.7638838291168213
Validation loss: 2.2580508242050805

Epoch: 61| Step: 0
Training loss: 2.372727870941162
Validation loss: 2.2587690353393555

Epoch: 5| Step: 1
Training loss: 2.4051201343536377
Validation loss: 2.2551089823246

Epoch: 5| Step: 2
Training loss: 2.273228883743286
Validation loss: 2.2551498313744864

Epoch: 5| Step: 3
Training loss: 2.9597363471984863
Validation loss: 2.2548014422257743

Epoch: 5| Step: 4
Training loss: 2.6658685207366943
Validation loss: 2.251863554120064

Epoch: 5| Step: 5
Training loss: 2.7176709175109863
Validation loss: 2.24322838584582

Epoch: 5| Step: 6
Training loss: 2.5162816047668457
Validation loss: 2.2487110048532486

Epoch: 5| Step: 7
Training loss: 2.539257526397705
Validation loss: 2.247712180018425

Epoch: 5| Step: 8
Training loss: 1.6694843769073486
Validation loss: 2.2467540204524994

Epoch: 5| Step: 9
Training loss: 1.852959394454956
Validation loss: 2.2484437227249146

Epoch: 5| Step: 10
Training loss: 2.6382617950439453
Validation loss: 2.2492532382408776

Epoch: 5| Step: 11
Training loss: 2.0042872428894043
Validation loss: 2.2447288433710733

Epoch: 62| Step: 0
Training loss: 1.8002007007598877
Validation loss: 2.2381466130415597

Epoch: 5| Step: 1
Training loss: 2.3775036334991455
Validation loss: 2.228731627265612

Epoch: 5| Step: 2
Training loss: 2.245316982269287
Validation loss: 2.2246775329113007

Epoch: 5| Step: 3
Training loss: 2.7771098613739014
Validation loss: 2.2250712464253106

Epoch: 5| Step: 4
Training loss: 1.9201911687850952
Validation loss: 2.2300396958986917

Epoch: 5| Step: 5
Training loss: 2.26958966255188
Validation loss: 2.2261399378379187

Epoch: 5| Step: 6
Training loss: 2.0906059741973877
Validation loss: 2.2250964591900506

Epoch: 5| Step: 7
Training loss: 2.7547507286071777
Validation loss: 2.221179490288099

Epoch: 5| Step: 8
Training loss: 2.754843235015869
Validation loss: 2.2223180532455444

Epoch: 5| Step: 9
Training loss: 2.973680019378662
Validation loss: 2.2162412305672965

Epoch: 5| Step: 10
Training loss: 2.1555845737457275
Validation loss: 2.2176881780227027

Epoch: 5| Step: 11
Training loss: 3.082218647003174
Validation loss: 2.2154186268647513

Epoch: 63| Step: 0
Training loss: 2.8147943019866943
Validation loss: 2.2112247198820114

Epoch: 5| Step: 1
Training loss: 2.7104363441467285
Validation loss: 2.2127679884433746

Epoch: 5| Step: 2
Training loss: 2.491842746734619
Validation loss: 2.2099147886037827

Epoch: 5| Step: 3
Training loss: 2.4251465797424316
Validation loss: 2.2062292297681174

Epoch: 5| Step: 4
Training loss: 1.8400542736053467
Validation loss: 2.2053023676077523

Epoch: 5| Step: 5
Training loss: 2.1230366230010986
Validation loss: 2.2057097603877387

Epoch: 5| Step: 6
Training loss: 3.1766810417175293
Validation loss: 2.2043146888415017

Epoch: 5| Step: 7
Training loss: 1.9904050827026367
Validation loss: 2.2024328311284385

Epoch: 5| Step: 8
Training loss: 1.9599745273590088
Validation loss: 2.2027870615323386

Epoch: 5| Step: 9
Training loss: 2.735908031463623
Validation loss: 2.202810058991114

Epoch: 5| Step: 10
Training loss: 1.9659950733184814
Validation loss: 2.2000300089518228

Epoch: 5| Step: 11
Training loss: 1.3293975591659546
Validation loss: 2.1990764488776526

Epoch: 64| Step: 0
Training loss: 2.8539907932281494
Validation loss: 2.195971796909968

Epoch: 5| Step: 1
Training loss: 1.2347626686096191
Validation loss: 2.1917013873656592

Epoch: 5| Step: 2
Training loss: 2.1468162536621094
Validation loss: 2.1929717113574347

Epoch: 5| Step: 3
Training loss: 2.7219882011413574
Validation loss: 2.189605340361595

Epoch: 5| Step: 4
Training loss: 2.0192809104919434
Validation loss: 2.1886829336484275

Epoch: 5| Step: 5
Training loss: 2.4752728939056396
Validation loss: 2.1855433781941733

Epoch: 5| Step: 6
Training loss: 2.085292339324951
Validation loss: 2.1889046182235083

Epoch: 5| Step: 7
Training loss: 2.717189311981201
Validation loss: 2.1838101744651794

Epoch: 5| Step: 8
Training loss: 2.4686784744262695
Validation loss: 2.1854695777098336

Epoch: 5| Step: 9
Training loss: 2.2604482173919678
Validation loss: 2.1812482376893363

Epoch: 5| Step: 10
Training loss: 2.697059154510498
Validation loss: 2.185315797726313

Epoch: 5| Step: 11
Training loss: 2.836596965789795
Validation loss: 2.1819600760936737

Epoch: 65| Step: 0
Training loss: 2.5719685554504395
Validation loss: 2.1800613502661386

Epoch: 5| Step: 1
Training loss: 2.6935629844665527
Validation loss: 2.1811000953118005

Epoch: 5| Step: 2
Training loss: 2.1868855953216553
Validation loss: 2.176635896166166

Epoch: 5| Step: 3
Training loss: 2.0789847373962402
Validation loss: 2.1723973055680594

Epoch: 5| Step: 4
Training loss: 2.229469060897827
Validation loss: 2.172970642646154

Epoch: 5| Step: 5
Training loss: 1.981026291847229
Validation loss: 2.1729440788427987

Epoch: 5| Step: 6
Training loss: 2.0895237922668457
Validation loss: 2.1720596055189767

Epoch: 5| Step: 7
Training loss: 2.431572675704956
Validation loss: 2.1733402013778687

Epoch: 5| Step: 8
Training loss: 2.650001049041748
Validation loss: 2.176505208015442

Epoch: 5| Step: 9
Training loss: 2.3052287101745605
Validation loss: 2.171409249305725

Epoch: 5| Step: 10
Training loss: 2.680908679962158
Validation loss: 2.1643070181210837

Epoch: 5| Step: 11
Training loss: 1.540009617805481
Validation loss: 2.1649233053127923

Epoch: 66| Step: 0
Training loss: 2.5138192176818848
Validation loss: 2.169421061873436

Epoch: 5| Step: 1
Training loss: 2.946045398712158
Validation loss: 2.171091139316559

Epoch: 5| Step: 2
Training loss: 2.569791316986084
Validation loss: 2.184282730023066

Epoch: 5| Step: 3
Training loss: 2.1577885150909424
Validation loss: 2.2016628185908

Epoch: 5| Step: 4
Training loss: 2.4466257095336914
Validation loss: 2.2153112490971885

Epoch: 5| Step: 5
Training loss: 2.6576180458068848
Validation loss: 2.213323950767517

Epoch: 5| Step: 6
Training loss: 2.182582139968872
Validation loss: 2.205183525880178

Epoch: 5| Step: 7
Training loss: 2.149599552154541
Validation loss: 2.201640769839287

Epoch: 5| Step: 8
Training loss: 2.0664424896240234
Validation loss: 2.1959577848513923

Epoch: 5| Step: 9
Training loss: 2.644961357116699
Validation loss: 2.180113931496938

Epoch: 5| Step: 10
Training loss: 1.748988389968872
Validation loss: 2.1781900376081467

Epoch: 5| Step: 11
Training loss: 1.3019428253173828
Validation loss: 2.173678999145826

Epoch: 67| Step: 0
Training loss: 1.9070055484771729
Validation loss: 2.1701000332832336

Epoch: 5| Step: 1
Training loss: 2.613610029220581
Validation loss: 2.168102736274401

Epoch: 5| Step: 2
Training loss: 1.6711689233779907
Validation loss: 2.167038455605507

Epoch: 5| Step: 3
Training loss: 2.437955856323242
Validation loss: 2.167467554410299

Epoch: 5| Step: 4
Training loss: 2.466862440109253
Validation loss: 2.162614092230797

Epoch: 5| Step: 5
Training loss: 2.1986899375915527
Validation loss: 2.160947248339653

Epoch: 5| Step: 6
Training loss: 2.575969696044922
Validation loss: 2.15835340321064

Epoch: 5| Step: 7
Training loss: 2.123940944671631
Validation loss: 2.155144363641739

Epoch: 5| Step: 8
Training loss: 2.677091121673584
Validation loss: 2.1584191222985587

Epoch: 5| Step: 9
Training loss: 2.649155616760254
Validation loss: 2.157793253660202

Epoch: 5| Step: 10
Training loss: 2.21240234375
Validation loss: 2.1543273429075875

Epoch: 5| Step: 11
Training loss: 2.1786422729492188
Validation loss: 2.1529150754213333

Epoch: 68| Step: 0
Training loss: 1.8098952770233154
Validation loss: 2.1403077046076455

Epoch: 5| Step: 1
Training loss: 2.31856107711792
Validation loss: 2.143703947464625

Epoch: 5| Step: 2
Training loss: 2.8514621257781982
Validation loss: 2.1424442877372107

Epoch: 5| Step: 3
Training loss: 2.678406238555908
Validation loss: 2.142136995991071

Epoch: 5| Step: 4
Training loss: 2.4136064052581787
Validation loss: 2.141934727629026

Epoch: 5| Step: 5
Training loss: 1.9076656103134155
Validation loss: 2.1456724305947623

Epoch: 5| Step: 6
Training loss: 2.2264130115509033
Validation loss: 2.1381678581237793

Epoch: 5| Step: 7
Training loss: 2.400803327560425
Validation loss: 2.139027252793312

Epoch: 5| Step: 8
Training loss: 2.2313625812530518
Validation loss: 2.1361850649118423

Epoch: 5| Step: 9
Training loss: 2.660520076751709
Validation loss: 2.136759862303734

Epoch: 5| Step: 10
Training loss: 2.0606560707092285
Validation loss: 2.132499486207962

Epoch: 5| Step: 11
Training loss: 1.332843542098999
Validation loss: 2.1386579275131226

Epoch: 69| Step: 0
Training loss: 1.7153784036636353
Validation loss: 2.1374768565098443

Epoch: 5| Step: 1
Training loss: 2.245060682296753
Validation loss: 2.1495437075694404

Epoch: 5| Step: 2
Training loss: 2.645500659942627
Validation loss: 2.152815038959185

Epoch: 5| Step: 3
Training loss: 2.8962485790252686
Validation loss: 2.153831804792086

Epoch: 5| Step: 4
Training loss: 2.6034255027770996
Validation loss: 2.1380649457375207

Epoch: 5| Step: 5
Training loss: 2.12808895111084
Validation loss: 2.1348730524381003

Epoch: 5| Step: 6
Training loss: 2.380220413208008
Validation loss: 2.1266256968180337

Epoch: 5| Step: 7
Training loss: 2.0809717178344727
Validation loss: 2.122148940960566

Epoch: 5| Step: 8
Training loss: 2.298017978668213
Validation loss: 2.1234569350878396

Epoch: 5| Step: 9
Training loss: 2.57534122467041
Validation loss: 2.121902714172999

Epoch: 5| Step: 10
Training loss: 1.6141573190689087
Validation loss: 2.1219593236843743

Epoch: 5| Step: 11
Training loss: 3.24819278717041
Validation loss: 2.1184089134136834

Epoch: 70| Step: 0
Training loss: 2.4217352867126465
Validation loss: 2.123172104358673

Epoch: 5| Step: 1
Training loss: 2.222698450088501
Validation loss: 2.1210602025190988

Epoch: 5| Step: 2
Training loss: 2.155181407928467
Validation loss: 2.1196730732917786

Epoch: 5| Step: 3
Training loss: 2.085742473602295
Validation loss: 2.1204492151737213

Epoch: 5| Step: 4
Training loss: 2.5587620735168457
Validation loss: 2.1197230021158853

Epoch: 5| Step: 5
Training loss: 2.1621556282043457
Validation loss: 2.119233881433805

Epoch: 5| Step: 6
Training loss: 2.3039863109588623
Validation loss: 2.1195126324892044

Epoch: 5| Step: 7
Training loss: 2.5805857181549072
Validation loss: 2.1189924677213035

Epoch: 5| Step: 8
Training loss: 2.382026195526123
Validation loss: 2.112849156061808

Epoch: 5| Step: 9
Training loss: 2.2243266105651855
Validation loss: 2.1119039207696915

Epoch: 5| Step: 10
Training loss: 2.026179075241089
Validation loss: 2.1082643469174704

Epoch: 5| Step: 11
Training loss: 2.3958492279052734
Validation loss: 2.1075805524984994

Epoch: 71| Step: 0
Training loss: 2.520362377166748
Validation loss: 2.105670894185702

Epoch: 5| Step: 1
Training loss: 2.0447545051574707
Validation loss: 2.106480141480764

Epoch: 5| Step: 2
Training loss: 2.3609721660614014
Validation loss: 2.1143764654795327

Epoch: 5| Step: 3
Training loss: 2.987414836883545
Validation loss: 2.110922709107399

Epoch: 5| Step: 4
Training loss: 2.736549139022827
Validation loss: 2.1030649642149606

Epoch: 5| Step: 5
Training loss: 1.7877357006072998
Validation loss: 2.0985379219055176

Epoch: 5| Step: 6
Training loss: 2.098456859588623
Validation loss: 2.098640908797582

Epoch: 5| Step: 7
Training loss: 1.548105001449585
Validation loss: 2.1021367659171424

Epoch: 5| Step: 8
Training loss: 2.4374234676361084
Validation loss: 2.1044453928867974

Epoch: 5| Step: 9
Training loss: 2.3440983295440674
Validation loss: 2.1059022744496665

Epoch: 5| Step: 10
Training loss: 2.211782455444336
Validation loss: 2.1049527525901794

Epoch: 5| Step: 11
Training loss: 1.908318281173706
Validation loss: 2.1050116618474326

Epoch: 72| Step: 0
Training loss: 2.153449296951294
Validation loss: 2.1047529031833014

Epoch: 5| Step: 1
Training loss: 2.5419678688049316
Validation loss: 2.1019184043010077

Epoch: 5| Step: 2
Training loss: 2.5238254070281982
Validation loss: 2.1013264805078506

Epoch: 5| Step: 3
Training loss: 2.2711145877838135
Validation loss: 2.102539613842964

Epoch: 5| Step: 4
Training loss: 2.557541608810425
Validation loss: 2.096097558736801

Epoch: 5| Step: 5
Training loss: 1.9769716262817383
Validation loss: 2.1032460729281106

Epoch: 5| Step: 6
Training loss: 2.415783405303955
Validation loss: 2.0991155256827674

Epoch: 5| Step: 7
Training loss: 1.621930718421936
Validation loss: 2.0971851646900177

Epoch: 5| Step: 8
Training loss: 2.828122138977051
Validation loss: 2.0818100770314536

Epoch: 5| Step: 9
Training loss: 1.846207618713379
Validation loss: 2.0767116298278174

Epoch: 5| Step: 10
Training loss: 2.1457104682922363
Validation loss: 2.089727426568667

Epoch: 5| Step: 11
Training loss: 1.8875548839569092
Validation loss: 2.085934321085612

Epoch: 73| Step: 0
Training loss: 2.427046298980713
Validation loss: 2.0902642558018365

Epoch: 5| Step: 1
Training loss: 2.63527250289917
Validation loss: 2.091820860902468

Epoch: 5| Step: 2
Training loss: 1.969008207321167
Validation loss: 2.08756976823012

Epoch: 5| Step: 3
Training loss: 2.3738818168640137
Validation loss: 2.080476721127828

Epoch: 5| Step: 4
Training loss: 2.083524227142334
Validation loss: 2.0878628889719644

Epoch: 5| Step: 5
Training loss: 2.4244608879089355
Validation loss: 2.0896995961666107

Epoch: 5| Step: 6
Training loss: 1.8602802753448486
Validation loss: 2.0910840133825936

Epoch: 5| Step: 7
Training loss: 2.3672046661376953
Validation loss: 2.08985344072183

Epoch: 5| Step: 8
Training loss: 1.7429996728897095
Validation loss: 2.0900341471036277

Epoch: 5| Step: 9
Training loss: 2.2970480918884277
Validation loss: 2.087466781338056

Epoch: 5| Step: 10
Training loss: 3.0101590156555176
Validation loss: 2.096703519423803

Epoch: 5| Step: 11
Training loss: 1.7949681282043457
Validation loss: 2.0868286738793054

Epoch: 74| Step: 0
Training loss: 2.5729289054870605
Validation loss: 2.09000493089358

Epoch: 5| Step: 1
Training loss: 2.345172882080078
Validation loss: 2.0988251715898514

Epoch: 5| Step: 2
Training loss: 2.1373753547668457
Validation loss: 2.098969275752703

Epoch: 5| Step: 3
Training loss: 2.3823108673095703
Validation loss: 2.0984779447317123

Epoch: 5| Step: 4
Training loss: 1.8321033716201782
Validation loss: 2.0722500483194985

Epoch: 5| Step: 5
Training loss: 1.9897329807281494
Validation loss: 2.072286307811737

Epoch: 5| Step: 6
Training loss: 2.6428463459014893
Validation loss: 2.0647288113832474

Epoch: 5| Step: 7
Training loss: 2.160947322845459
Validation loss: 2.0669433176517487

Epoch: 5| Step: 8
Training loss: 2.222743511199951
Validation loss: 2.065414478381475

Epoch: 5| Step: 9
Training loss: 2.4575092792510986
Validation loss: 2.0618733018636703

Epoch: 5| Step: 10
Training loss: 2.2815020084381104
Validation loss: 2.057007302840551

Epoch: 5| Step: 11
Training loss: 1.3564934730529785
Validation loss: 2.0633668353160224

Epoch: 75| Step: 0
Training loss: 2.097726821899414
Validation loss: 2.05715041855971

Epoch: 5| Step: 1
Training loss: 2.519366502761841
Validation loss: 2.0636481742064157

Epoch: 5| Step: 2
Training loss: 2.4909310340881348
Validation loss: 2.054933855930964

Epoch: 5| Step: 3
Training loss: 1.8494545221328735
Validation loss: 2.0585621694723764

Epoch: 5| Step: 4
Training loss: 2.0740249156951904
Validation loss: 2.055278887351354

Epoch: 5| Step: 5
Training loss: 2.6178348064422607
Validation loss: 2.0549792597691217

Epoch: 5| Step: 6
Training loss: 2.239551067352295
Validation loss: 2.0589230010906854

Epoch: 5| Step: 7
Training loss: 2.2958617210388184
Validation loss: 2.056144639849663

Epoch: 5| Step: 8
Training loss: 2.200911045074463
Validation loss: 2.0607798347870507

Epoch: 5| Step: 9
Training loss: 2.1894588470458984
Validation loss: 2.067682594060898

Epoch: 5| Step: 10
Training loss: 2.2383742332458496
Validation loss: 2.063655823469162

Epoch: 5| Step: 11
Training loss: 1.1527949571609497
Validation loss: 2.0630152821540833

Epoch: 76| Step: 0
Training loss: 2.1435749530792236
Validation loss: 2.060452163219452

Epoch: 5| Step: 1
Training loss: 2.9333701133728027
Validation loss: 2.063828319311142

Epoch: 5| Step: 2
Training loss: 2.296287775039673
Validation loss: 2.0661878138780594

Epoch: 5| Step: 3
Training loss: 2.1094748973846436
Validation loss: 2.086081216732661

Epoch: 5| Step: 4
Training loss: 2.532517671585083
Validation loss: 2.0776812583208084

Epoch: 5| Step: 5
Training loss: 2.1165096759796143
Validation loss: 2.0778285761674247

Epoch: 5| Step: 6
Training loss: 2.7349283695220947
Validation loss: 2.0864500602086387

Epoch: 5| Step: 7
Training loss: 1.737560510635376
Validation loss: 2.0729435086250305

Epoch: 5| Step: 8
Training loss: 2.012896776199341
Validation loss: 2.0665964831908545

Epoch: 5| Step: 9
Training loss: 2.019774913787842
Validation loss: 2.068877711892128

Epoch: 5| Step: 10
Training loss: 1.988861322402954
Validation loss: 2.055127441883087

Epoch: 5| Step: 11
Training loss: 2.2976322174072266
Validation loss: 2.04888416826725

Epoch: 77| Step: 0
Training loss: 2.335136651992798
Validation loss: 2.0630806585152945

Epoch: 5| Step: 1
Training loss: 2.2174715995788574
Validation loss: 2.056237364808718

Epoch: 5| Step: 2
Training loss: 2.7818570137023926
Validation loss: 2.056658978263537

Epoch: 5| Step: 3
Training loss: 1.6877046823501587
Validation loss: 2.052882562081019

Epoch: 5| Step: 4
Training loss: 2.005692481994629
Validation loss: 2.053803861141205

Epoch: 5| Step: 5
Training loss: 2.594973087310791
Validation loss: 2.054257477323214

Epoch: 5| Step: 6
Training loss: 1.7039148807525635
Validation loss: 2.051423599322637

Epoch: 5| Step: 7
Training loss: 1.8141653537750244
Validation loss: 2.0526776959498725

Epoch: 5| Step: 8
Training loss: 2.5950369834899902
Validation loss: 2.0485880076885223

Epoch: 5| Step: 9
Training loss: 2.403550148010254
Validation loss: 2.045198683937391

Epoch: 5| Step: 10
Training loss: 2.3347723484039307
Validation loss: 2.048713445663452

Epoch: 5| Step: 11
Training loss: 2.0518300533294678
Validation loss: 2.0499495565891266

Epoch: 78| Step: 0
Training loss: 2.4467406272888184
Validation loss: 2.046594431002935

Epoch: 5| Step: 1
Training loss: 2.481172800064087
Validation loss: 2.047071412205696

Epoch: 5| Step: 2
Training loss: 1.6730680465698242
Validation loss: 2.0413896640141806

Epoch: 5| Step: 3
Training loss: 2.2184536457061768
Validation loss: 2.063054069876671

Epoch: 5| Step: 4
Training loss: 2.448333978652954
Validation loss: 2.073668117324511

Epoch: 5| Step: 5
Training loss: 2.2500698566436768
Validation loss: 2.0634156465530396

Epoch: 5| Step: 6
Training loss: 2.015673875808716
Validation loss: 2.0543244034051895

Epoch: 5| Step: 7
Training loss: 2.3695151805877686
Validation loss: 2.047822301586469

Epoch: 5| Step: 8
Training loss: 1.9996941089630127
Validation loss: 2.039017453789711

Epoch: 5| Step: 9
Training loss: 1.6490440368652344
Validation loss: 2.043642153342565

Epoch: 5| Step: 10
Training loss: 2.758554458618164
Validation loss: 2.0356027533610663

Epoch: 5| Step: 11
Training loss: 2.7377891540527344
Validation loss: 2.034385790427526

Epoch: 79| Step: 0
Training loss: 1.860883116722107
Validation loss: 2.0437432130177817

Epoch: 5| Step: 1
Training loss: 2.5820376873016357
Validation loss: 2.0635772744814553

Epoch: 5| Step: 2
Training loss: 1.83930242061615
Validation loss: 2.0923984001080194

Epoch: 5| Step: 3
Training loss: 2.192957639694214
Validation loss: 2.096316859126091

Epoch: 5| Step: 4
Training loss: 2.4719948768615723
Validation loss: 2.1236053109169006

Epoch: 5| Step: 5
Training loss: 2.3556246757507324
Validation loss: 2.1276148358980813

Epoch: 5| Step: 6
Training loss: 2.2888331413269043
Validation loss: 2.110978752374649

Epoch: 5| Step: 7
Training loss: 2.1638426780700684
Validation loss: 2.1074033280213675

Epoch: 5| Step: 8
Training loss: 2.3454432487487793
Validation loss: 2.0833673576513925

Epoch: 5| Step: 9
Training loss: 2.173703670501709
Validation loss: 2.0571161806583405

Epoch: 5| Step: 10
Training loss: 2.743453025817871
Validation loss: 2.0352943440278373

Epoch: 5| Step: 11
Training loss: 1.943489670753479
Validation loss: 2.0294614831606546

Epoch: 80| Step: 0
Training loss: 2.5788943767547607
Validation loss: 2.0402210702498755

Epoch: 5| Step: 1
Training loss: 1.9717731475830078
Validation loss: 2.050699830055237

Epoch: 5| Step: 2
Training loss: 2.3009562492370605
Validation loss: 2.0563101271788278

Epoch: 5| Step: 3
Training loss: 2.0507442951202393
Validation loss: 2.059353838364283

Epoch: 5| Step: 4
Training loss: 2.4050395488739014
Validation loss: 2.068869099020958

Epoch: 5| Step: 5
Training loss: 1.8629181385040283
Validation loss: 2.0798193315664926

Epoch: 5| Step: 6
Training loss: 2.2345292568206787
Validation loss: 2.0775499989589057

Epoch: 5| Step: 7
Training loss: 2.384613513946533
Validation loss: 2.076313316822052

Epoch: 5| Step: 8
Training loss: 2.10375714302063
Validation loss: 2.0689787566661835

Epoch: 5| Step: 9
Training loss: 2.1715121269226074
Validation loss: 2.076015368103981

Epoch: 5| Step: 10
Training loss: 2.6456563472747803
Validation loss: 2.0710572401682534

Epoch: 5| Step: 11
Training loss: 2.686707019805908
Validation loss: 2.0666740188995996

Epoch: 81| Step: 0
Training loss: 1.8892419338226318
Validation loss: 2.0666950245698295

Epoch: 5| Step: 1
Training loss: 2.3668782711029053
Validation loss: 2.0603456497192383

Epoch: 5| Step: 2
Training loss: 2.4202823638916016
Validation loss: 2.0568157931168876

Epoch: 5| Step: 3
Training loss: 2.1080222129821777
Validation loss: 2.0486343850692115

Epoch: 5| Step: 4
Training loss: 2.5001490116119385
Validation loss: 2.052157317598661

Epoch: 5| Step: 5
Training loss: 2.298495292663574
Validation loss: 2.049428701400757

Epoch: 5| Step: 6
Training loss: 1.6567338705062866
Validation loss: 2.042666186889013

Epoch: 5| Step: 7
Training loss: 2.160452365875244
Validation loss: 2.033818950255712

Epoch: 5| Step: 8
Training loss: 2.6946187019348145
Validation loss: 2.0302648892005286

Epoch: 5| Step: 9
Training loss: 1.895066499710083
Validation loss: 2.034800132115682

Epoch: 5| Step: 10
Training loss: 2.390120029449463
Validation loss: 2.0367179612318673

Epoch: 5| Step: 11
Training loss: 2.8701343536376953
Validation loss: 2.037110542257627

Epoch: 82| Step: 0
Training loss: 1.5898534059524536
Validation loss: 2.039419253667196

Epoch: 5| Step: 1
Training loss: 2.4128575325012207
Validation loss: 2.038018614053726

Epoch: 5| Step: 2
Training loss: 1.9978570938110352
Validation loss: 2.0349667916695275

Epoch: 5| Step: 3
Training loss: 2.4857563972473145
Validation loss: 2.032476638754209

Epoch: 5| Step: 4
Training loss: 2.402055263519287
Validation loss: 2.0341046154499054

Epoch: 5| Step: 5
Training loss: 2.775744915008545
Validation loss: 2.022097791234652

Epoch: 5| Step: 6
Training loss: 2.076533079147339
Validation loss: 2.022181734442711

Epoch: 5| Step: 7
Training loss: 1.8386332988739014
Validation loss: 2.023373325665792

Epoch: 5| Step: 8
Training loss: 2.2219326496124268
Validation loss: 2.021955112616221

Epoch: 5| Step: 9
Training loss: 2.296616315841675
Validation loss: 2.027502899368604

Epoch: 5| Step: 10
Training loss: 2.4305760860443115
Validation loss: 2.027874077359835

Epoch: 5| Step: 11
Training loss: 1.220726728439331
Validation loss: 2.021413574616114

Epoch: 83| Step: 0
Training loss: 2.5617311000823975
Validation loss: 2.0354393124580383

Epoch: 5| Step: 1
Training loss: 1.9587287902832031
Validation loss: 2.030944565931956

Epoch: 5| Step: 2
Training loss: 2.935784101486206
Validation loss: 2.039611359437307

Epoch: 5| Step: 3
Training loss: 2.352308988571167
Validation loss: 2.041445483764013

Epoch: 5| Step: 4
Training loss: 2.241245746612549
Validation loss: 2.0437562266985574

Epoch: 5| Step: 5
Training loss: 1.6443039178848267
Validation loss: 2.044371043642362

Epoch: 5| Step: 6
Training loss: 2.109386444091797
Validation loss: 2.036562199393908

Epoch: 5| Step: 7
Training loss: 1.5724776983261108
Validation loss: 2.026019791762034

Epoch: 5| Step: 8
Training loss: 2.634121894836426
Validation loss: 2.035270338257154

Epoch: 5| Step: 9
Training loss: 1.9887069463729858
Validation loss: 2.0273890693982444

Epoch: 5| Step: 10
Training loss: 2.1388680934906006
Validation loss: 2.0329193423191705

Epoch: 5| Step: 11
Training loss: 2.6293113231658936
Validation loss: 2.024066905180613

Epoch: 84| Step: 0
Training loss: 2.324686050415039
Validation loss: 2.0346168329318366

Epoch: 5| Step: 1
Training loss: 2.235443592071533
Validation loss: 2.031966229279836

Epoch: 5| Step: 2
Training loss: 2.3423776626586914
Validation loss: 2.0430877904097238

Epoch: 5| Step: 3
Training loss: 1.8840816020965576
Validation loss: 2.053262566526731

Epoch: 5| Step: 4
Training loss: 2.2481629848480225
Validation loss: 2.0527143478393555

Epoch: 5| Step: 5
Training loss: 2.800886631011963
Validation loss: 2.054630994796753

Epoch: 5| Step: 6
Training loss: 2.3829033374786377
Validation loss: 2.0416706601778665

Epoch: 5| Step: 7
Training loss: 1.698500633239746
Validation loss: 2.0428826808929443

Epoch: 5| Step: 8
Training loss: 1.820490837097168
Validation loss: 2.028760939836502

Epoch: 5| Step: 9
Training loss: 2.407472848892212
Validation loss: 2.0296355336904526

Epoch: 5| Step: 10
Training loss: 2.0386159420013428
Validation loss: 2.023857206106186

Epoch: 5| Step: 11
Training loss: 2.035428524017334
Validation loss: 2.0221360524495444

Epoch: 85| Step: 0
Training loss: 1.8392765522003174
Validation loss: 2.0215630332628884

Epoch: 5| Step: 1
Training loss: 2.8894240856170654
Validation loss: 2.027522931496302

Epoch: 5| Step: 2
Training loss: 2.2258810997009277
Validation loss: 2.030808592836062

Epoch: 5| Step: 3
Training loss: 2.359456777572632
Validation loss: 2.0320673286914825

Epoch: 5| Step: 4
Training loss: 1.6890265941619873
Validation loss: 2.0345344692468643

Epoch: 5| Step: 5
Training loss: 1.7273216247558594
Validation loss: 2.0304453521966934

Epoch: 5| Step: 6
Training loss: 2.5665552616119385
Validation loss: 2.0294787287712097

Epoch: 5| Step: 7
Training loss: 2.7669880390167236
Validation loss: 2.0336486597855887

Epoch: 5| Step: 8
Training loss: 2.232835292816162
Validation loss: 2.030562768379847

Epoch: 5| Step: 9
Training loss: 2.0295581817626953
Validation loss: 2.0283488631248474

Epoch: 5| Step: 10
Training loss: 1.9107754230499268
Validation loss: 2.026598254839579

Epoch: 5| Step: 11
Training loss: 1.9639966487884521
Validation loss: 2.0231754879156747

Epoch: 86| Step: 0
Training loss: 2.1406784057617188
Validation loss: 2.022795836130778

Epoch: 5| Step: 1
Training loss: 2.4405102729797363
Validation loss: 2.016903633872668

Epoch: 5| Step: 2
Training loss: 2.3717098236083984
Validation loss: 2.0198618471622467

Epoch: 5| Step: 3
Training loss: 2.3785293102264404
Validation loss: 2.0291194121042886

Epoch: 5| Step: 4
Training loss: 2.078406810760498
Validation loss: 2.0330742547909417

Epoch: 5| Step: 5
Training loss: 2.2838897705078125
Validation loss: 2.034442534049352

Epoch: 5| Step: 6
Training loss: 1.5852060317993164
Validation loss: 2.027502382795016

Epoch: 5| Step: 7
Training loss: 2.0566792488098145
Validation loss: 2.035452976822853

Epoch: 5| Step: 8
Training loss: 2.3601908683776855
Validation loss: 2.0414937684933343

Epoch: 5| Step: 9
Training loss: 2.5810494422912598
Validation loss: 2.0371606846650443

Epoch: 5| Step: 10
Training loss: 1.552911400794983
Validation loss: 2.0361659675836563

Epoch: 5| Step: 11
Training loss: 2.4151153564453125
Validation loss: 2.035785675048828

Epoch: 87| Step: 0
Training loss: 1.8493776321411133
Validation loss: 2.0309581557909646

Epoch: 5| Step: 1
Training loss: 2.2392213344573975
Validation loss: 2.0293221473693848

Epoch: 5| Step: 2
Training loss: 2.4034576416015625
Validation loss: 2.031598443786303

Epoch: 5| Step: 3
Training loss: 2.022090196609497
Validation loss: 2.041425123810768

Epoch: 5| Step: 4
Training loss: 2.0545339584350586
Validation loss: 2.028107057015101

Epoch: 5| Step: 5
Training loss: 1.7164762020111084
Validation loss: 2.031318654616674

Epoch: 5| Step: 6
Training loss: 2.2428317070007324
Validation loss: 2.0304571638504663

Epoch: 5| Step: 7
Training loss: 2.3248348236083984
Validation loss: 2.0263308584690094

Epoch: 5| Step: 8
Training loss: 2.2005133628845215
Validation loss: 2.0322915265957513

Epoch: 5| Step: 9
Training loss: 2.586249589920044
Validation loss: 2.03382208943367

Epoch: 5| Step: 10
Training loss: 2.135892629623413
Validation loss: 2.03630738457044

Epoch: 5| Step: 11
Training loss: 2.3668839931488037
Validation loss: 2.0167132963736853

Epoch: 88| Step: 0
Training loss: 2.1890811920166016
Validation loss: 2.032966196537018

Epoch: 5| Step: 1
Training loss: 1.5084588527679443
Validation loss: 2.0242471198240914

Epoch: 5| Step: 2
Training loss: 2.331132173538208
Validation loss: 2.0333420832951865

Epoch: 5| Step: 3
Training loss: 2.047091245651245
Validation loss: 2.026346335808436

Epoch: 5| Step: 4
Training loss: 1.9522368907928467
Validation loss: 2.031544258197149

Epoch: 5| Step: 5
Training loss: 1.9761021137237549
Validation loss: 2.0272027204434075

Epoch: 5| Step: 6
Training loss: 2.4969584941864014
Validation loss: 2.047690972685814

Epoch: 5| Step: 7
Training loss: 2.4149184226989746
Validation loss: 2.0464305778344474

Epoch: 5| Step: 8
Training loss: 2.1104209423065186
Validation loss: 2.0444886883099875

Epoch: 5| Step: 9
Training loss: 2.475515604019165
Validation loss: 2.0357412745555243

Epoch: 5| Step: 10
Training loss: 2.3768391609191895
Validation loss: 2.0315466225147247

Epoch: 5| Step: 11
Training loss: 2.798429489135742
Validation loss: 2.0185277412335076

Epoch: 89| Step: 0
Training loss: 2.530453681945801
Validation loss: 2.018342783053716

Epoch: 5| Step: 1
Training loss: 1.8647654056549072
Validation loss: 2.0277696599562964

Epoch: 5| Step: 2
Training loss: 1.5877422094345093
Validation loss: 2.0309842079877853

Epoch: 5| Step: 3
Training loss: 2.294738292694092
Validation loss: 2.032362848520279

Epoch: 5| Step: 4
Training loss: 2.0226871967315674
Validation loss: 2.0319550186395645

Epoch: 5| Step: 5
Training loss: 1.8588975667953491
Validation loss: 2.035578911503156

Epoch: 5| Step: 6
Training loss: 2.3026652336120605
Validation loss: 2.0345533887545266

Epoch: 5| Step: 7
Training loss: 2.1976449489593506
Validation loss: 2.031453013420105

Epoch: 5| Step: 8
Training loss: 2.3130428791046143
Validation loss: 2.0306781828403473

Epoch: 5| Step: 9
Training loss: 2.329651355743408
Validation loss: 2.0310563991467157

Epoch: 5| Step: 10
Training loss: 2.556313991546631
Validation loss: 2.0328558683395386

Epoch: 5| Step: 11
Training loss: 3.2252464294433594
Validation loss: 2.029252842068672

Epoch: 90| Step: 0
Training loss: 2.2946441173553467
Validation loss: 2.0246413548787436

Epoch: 5| Step: 1
Training loss: 2.3523659706115723
Validation loss: 2.021465023358663

Epoch: 5| Step: 2
Training loss: 1.781813383102417
Validation loss: 2.0129521588484445

Epoch: 5| Step: 3
Training loss: 2.2955009937286377
Validation loss: 2.0153293758630753

Epoch: 5| Step: 4
Training loss: 2.30218768119812
Validation loss: 2.014019658168157

Epoch: 5| Step: 5
Training loss: 1.7999756336212158
Validation loss: 2.0151567409435907

Epoch: 5| Step: 6
Training loss: 2.5259711742401123
Validation loss: 2.011836717526118

Epoch: 5| Step: 7
Training loss: 1.8776733875274658
Validation loss: 2.0216168016195297

Epoch: 5| Step: 8
Training loss: 1.9507243633270264
Validation loss: 2.0208063274621964

Epoch: 5| Step: 9
Training loss: 2.4868860244750977
Validation loss: 2.0315930296977363

Epoch: 5| Step: 10
Training loss: 2.0140528678894043
Validation loss: 2.046803742647171

Epoch: 5| Step: 11
Training loss: 3.4142403602600098
Validation loss: 2.0351765205462775

Epoch: 91| Step: 0
Training loss: 2.138071060180664
Validation loss: 2.060924157500267

Epoch: 5| Step: 1
Training loss: 1.8720619678497314
Validation loss: 2.0657332142194114

Epoch: 5| Step: 2
Training loss: 2.2632014751434326
Validation loss: 2.0847799479961395

Epoch: 5| Step: 3
Training loss: 2.600433826446533
Validation loss: 2.0839262704054513

Epoch: 5| Step: 4
Training loss: 1.9432016611099243
Validation loss: 2.0842402279376984

Epoch: 5| Step: 5
Training loss: 2.3969101905822754
Validation loss: 2.0800663779179254

Epoch: 5| Step: 6
Training loss: 2.3594930171966553
Validation loss: 2.0556819240252175

Epoch: 5| Step: 7
Training loss: 2.2247986793518066
Validation loss: 2.0384877175092697

Epoch: 5| Step: 8
Training loss: 2.279306650161743
Validation loss: 2.028604914744695

Epoch: 5| Step: 9
Training loss: 1.2790132761001587
Validation loss: 2.0213907212018967

Epoch: 5| Step: 10
Training loss: 2.7237706184387207
Validation loss: 2.0098440051078796

Epoch: 5| Step: 11
Training loss: 2.664283275604248
Validation loss: 2.013404573003451

Epoch: 92| Step: 0
Training loss: 2.445568799972534
Validation loss: 2.016718124349912

Epoch: 5| Step: 1
Training loss: 2.37831974029541
Validation loss: 2.0220282127459845

Epoch: 5| Step: 2
Training loss: 2.1451926231384277
Validation loss: 2.0205723444620767

Epoch: 5| Step: 3
Training loss: 2.5004360675811768
Validation loss: 2.019415944814682

Epoch: 5| Step: 4
Training loss: 1.9416167736053467
Validation loss: 2.024664670228958

Epoch: 5| Step: 5
Training loss: 2.0342929363250732
Validation loss: 2.025157312552134

Epoch: 5| Step: 6
Training loss: 1.7670007944107056
Validation loss: 2.018738349278768

Epoch: 5| Step: 7
Training loss: 2.369781017303467
Validation loss: 2.0182222028573356

Epoch: 5| Step: 8
Training loss: 1.8969745635986328
Validation loss: 2.0226221283276877

Epoch: 5| Step: 9
Training loss: 2.4944605827331543
Validation loss: 2.0117642482121787

Epoch: 5| Step: 10
Training loss: 2.0132975578308105
Validation loss: 2.0202481697003045

Epoch: 5| Step: 11
Training loss: 1.342885136604309
Validation loss: 2.025146668155988

Epoch: 93| Step: 0
Training loss: 1.9211056232452393
Validation loss: 2.0276182095209756

Epoch: 5| Step: 1
Training loss: 2.1785402297973633
Validation loss: 2.025917520125707

Epoch: 5| Step: 2
Training loss: 2.456068515777588
Validation loss: 2.0289918929338455

Epoch: 5| Step: 3
Training loss: 2.042088270187378
Validation loss: 2.029098004102707

Epoch: 5| Step: 4
Training loss: 2.39601469039917
Validation loss: 2.0302185912926993

Epoch: 5| Step: 5
Training loss: 1.7924349308013916
Validation loss: 2.0365468660990396

Epoch: 5| Step: 6
Training loss: 1.9670995473861694
Validation loss: 2.0295825650294623

Epoch: 5| Step: 7
Training loss: 2.6102497577667236
Validation loss: 2.0261584570010505

Epoch: 5| Step: 8
Training loss: 2.9316282272338867
Validation loss: 2.0353069454431534

Epoch: 5| Step: 9
Training loss: 1.9535558223724365
Validation loss: 2.02535218000412

Epoch: 5| Step: 10
Training loss: 1.8026487827301025
Validation loss: 2.022725149989128

Epoch: 5| Step: 11
Training loss: 0.8396062850952148
Validation loss: 2.0224862098693848

Epoch: 94| Step: 0
Training loss: 2.6425271034240723
Validation loss: 2.019667163491249

Epoch: 5| Step: 1
Training loss: 2.310739278793335
Validation loss: 2.012998720010122

Epoch: 5| Step: 2
Training loss: 2.3407483100891113
Validation loss: 2.011042525370916

Epoch: 5| Step: 3
Training loss: 1.978316068649292
Validation loss: 2.014922325809797

Epoch: 5| Step: 4
Training loss: 2.685202121734619
Validation loss: 2.009471779068311

Epoch: 5| Step: 5
Training loss: 1.7817316055297852
Validation loss: 2.009534473220507

Epoch: 5| Step: 6
Training loss: 1.7135921716690063
Validation loss: 2.0115212748448053

Epoch: 5| Step: 7
Training loss: 2.5289158821105957
Validation loss: 2.0135818322499595

Epoch: 5| Step: 8
Training loss: 2.1317687034606934
Validation loss: 2.009072278936704

Epoch: 5| Step: 9
Training loss: 2.013084888458252
Validation loss: 2.007491181294123

Epoch: 5| Step: 10
Training loss: 1.769147515296936
Validation loss: 2.0081113626559577

Epoch: 5| Step: 11
Training loss: 1.3029624223709106
Validation loss: 2.011230160792669

Epoch: 95| Step: 0
Training loss: 2.498857259750366
Validation loss: 2.0175211081902185

Epoch: 5| Step: 1
Training loss: 3.0271923542022705
Validation loss: 2.018262361486753

Epoch: 5| Step: 2
Training loss: 1.4751275777816772
Validation loss: 2.023375858863195

Epoch: 5| Step: 3
Training loss: 2.001560688018799
Validation loss: 2.026157339413961

Epoch: 5| Step: 4
Training loss: 2.322864532470703
Validation loss: 2.0184251417716346

Epoch: 5| Step: 5
Training loss: 2.0943820476531982
Validation loss: 2.019736816485723

Epoch: 5| Step: 6
Training loss: 1.9681003093719482
Validation loss: 2.0400401701529822

Epoch: 5| Step: 7
Training loss: 2.363032579421997
Validation loss: 2.0370443761348724

Epoch: 5| Step: 8
Training loss: 2.2909979820251465
Validation loss: 2.0385582397381463

Epoch: 5| Step: 9
Training loss: 2.0787086486816406
Validation loss: 2.0418370018402734

Epoch: 5| Step: 10
Training loss: 1.6236194372177124
Validation loss: 2.028480276465416

Epoch: 5| Step: 11
Training loss: 1.9052666425704956
Validation loss: 2.031585698326429

Epoch: 96| Step: 0
Training loss: 1.8731387853622437
Validation loss: 2.026310702164968

Epoch: 5| Step: 1
Training loss: 2.4821712970733643
Validation loss: 2.021169900894165

Epoch: 5| Step: 2
Training loss: 2.0702695846557617
Validation loss: 2.0133313884337745

Epoch: 5| Step: 3
Training loss: 2.3836374282836914
Validation loss: 2.016928811868032

Epoch: 5| Step: 4
Training loss: 1.8506934642791748
Validation loss: 2.010942911108335

Epoch: 5| Step: 5
Training loss: 2.816533327102661
Validation loss: 2.0063616782426834

Epoch: 5| Step: 6
Training loss: 2.33638072013855
Validation loss: 2.0074276278416314

Epoch: 5| Step: 7
Training loss: 1.8843872547149658
Validation loss: 2.007852017879486

Epoch: 5| Step: 8
Training loss: 1.6618282794952393
Validation loss: 2.0132846434911094

Epoch: 5| Step: 9
Training loss: 1.5758510828018188
Validation loss: 2.010344942410787

Epoch: 5| Step: 10
Training loss: 2.487778425216675
Validation loss: 2.0121093740065894

Epoch: 5| Step: 11
Training loss: 3.0649328231811523
Validation loss: 2.013009915749232

Epoch: 97| Step: 0
Training loss: 2.093550443649292
Validation loss: 2.0110016067822776

Epoch: 5| Step: 1
Training loss: 2.068626880645752
Validation loss: 2.014510696132978

Epoch: 5| Step: 2
Training loss: 1.9924958944320679
Validation loss: 2.0097538928190866

Epoch: 5| Step: 3
Training loss: 1.9610878229141235
Validation loss: 2.015587732195854

Epoch: 5| Step: 4
Training loss: 2.328911542892456
Validation loss: 2.0149518052736917

Epoch: 5| Step: 5
Training loss: 2.2403342723846436
Validation loss: 2.018808270494143

Epoch: 5| Step: 6
Training loss: 2.6048591136932373
Validation loss: 2.023311987519264

Epoch: 5| Step: 7
Training loss: 2.2566943168640137
Validation loss: 2.0267471273740134

Epoch: 5| Step: 8
Training loss: 1.5820132493972778
Validation loss: 2.0293598423401513

Epoch: 5| Step: 9
Training loss: 2.0220816135406494
Validation loss: 2.0327071895202002

Epoch: 5| Step: 10
Training loss: 2.544771671295166
Validation loss: 2.0437108874320984

Epoch: 5| Step: 11
Training loss: 1.8153717517852783
Validation loss: 2.046599874893824

Epoch: 98| Step: 0
Training loss: 1.8930988311767578
Validation loss: 2.0294736325740814

Epoch: 5| Step: 1
Training loss: 2.3532328605651855
Validation loss: 2.034797504544258

Epoch: 5| Step: 2
Training loss: 1.9398505687713623
Validation loss: 2.024583568175634

Epoch: 5| Step: 3
Training loss: 2.282545328140259
Validation loss: 2.0174004981915155

Epoch: 5| Step: 4
Training loss: 2.8179473876953125
Validation loss: 2.019712378581365

Epoch: 5| Step: 5
Training loss: 2.247249126434326
Validation loss: 2.013655742009481

Epoch: 5| Step: 6
Training loss: 1.5318347215652466
Validation loss: 2.013383467992147

Epoch: 5| Step: 7
Training loss: 2.4236228466033936
Validation loss: 2.0145577838023505

Epoch: 5| Step: 8
Training loss: 1.809017539024353
Validation loss: 2.014126573999723

Epoch: 5| Step: 9
Training loss: 2.3976516723632812
Validation loss: 2.019013598561287

Epoch: 5| Step: 10
Training loss: 1.9681895971298218
Validation loss: 2.0164261907339096

Epoch: 5| Step: 11
Training loss: 2.682647466659546
Validation loss: 2.014998992284139

Epoch: 99| Step: 0
Training loss: 2.4975128173828125
Validation loss: 2.0189519971609116

Epoch: 5| Step: 1
Training loss: 2.3435981273651123
Validation loss: 2.0242896626393

Epoch: 5| Step: 2
Training loss: 1.7051246166229248
Validation loss: 2.01948381960392

Epoch: 5| Step: 3
Training loss: 1.6708705425262451
Validation loss: 2.027687912185987

Epoch: 5| Step: 4
Training loss: 2.3497238159179688
Validation loss: 2.0223232805728912

Epoch: 5| Step: 5
Training loss: 2.235893487930298
Validation loss: 2.0201715330282846

Epoch: 5| Step: 6
Training loss: 2.0954060554504395
Validation loss: 2.020038917660713

Epoch: 5| Step: 7
Training loss: 2.205519199371338
Validation loss: 2.019099031885465

Epoch: 5| Step: 8
Training loss: 1.941470742225647
Validation loss: 2.0244306375583014

Epoch: 5| Step: 9
Training loss: 2.0458381175994873
Validation loss: 2.0223531772693

Epoch: 5| Step: 10
Training loss: 2.4578795433044434
Validation loss: 2.0199073950449624

Epoch: 5| Step: 11
Training loss: 2.699483871459961
Validation loss: 2.0202634731928506

Epoch: 100| Step: 0
Training loss: 2.189396619796753
Validation loss: 2.0205673525730767

Epoch: 5| Step: 1
Training loss: 2.3126120567321777
Validation loss: 2.0149354338645935

Epoch: 5| Step: 2
Training loss: 2.014179229736328
Validation loss: 2.0115356942017875

Epoch: 5| Step: 3
Training loss: 1.9022518396377563
Validation loss: 2.0137607802947364

Epoch: 5| Step: 4
Training loss: 1.5738215446472168
Validation loss: 2.021952822804451

Epoch: 5| Step: 5
Training loss: 2.1955361366271973
Validation loss: 2.0240416675806046

Epoch: 5| Step: 6
Training loss: 2.4953160285949707
Validation loss: 2.0266751845677695

Epoch: 5| Step: 7
Training loss: 1.8796215057373047
Validation loss: 2.0222109456857047

Epoch: 5| Step: 8
Training loss: 2.477041721343994
Validation loss: 2.018534262975057

Epoch: 5| Step: 9
Training loss: 2.0602664947509766
Validation loss: 2.021893541018168

Epoch: 5| Step: 10
Training loss: 2.353184223175049
Validation loss: 2.018509248892466

Epoch: 5| Step: 11
Training loss: 2.977369785308838
Validation loss: 2.0168728083372116

Epoch: 101| Step: 0
Training loss: 1.9716129302978516
Validation loss: 2.0265933175881705

Epoch: 5| Step: 1
Training loss: 1.8724759817123413
Validation loss: 2.0325792680184045

Epoch: 5| Step: 2
Training loss: 2.460855007171631
Validation loss: 2.032599687576294

Epoch: 5| Step: 3
Training loss: 2.3641490936279297
Validation loss: 2.0482516835133233

Epoch: 5| Step: 4
Training loss: 2.433093547821045
Validation loss: 2.0470419079065323

Epoch: 5| Step: 5
Training loss: 1.9230709075927734
Validation loss: 2.048842211564382

Epoch: 5| Step: 6
Training loss: 2.412099599838257
Validation loss: 2.047109911839167

Epoch: 5| Step: 7
Training loss: 2.1419413089752197
Validation loss: 2.0446020563443503

Epoch: 5| Step: 8
Training loss: 1.6419775485992432
Validation loss: 2.0339139650265374

Epoch: 5| Step: 9
Training loss: 2.2255313396453857
Validation loss: 2.030770326654116

Epoch: 5| Step: 10
Training loss: 2.036482572555542
Validation loss: 2.016262556115786

Epoch: 5| Step: 11
Training loss: 3.167336940765381
Validation loss: 2.0221106757720313

Epoch: 102| Step: 0
Training loss: 2.086308002471924
Validation loss: 2.025792439778646

Epoch: 5| Step: 1
Training loss: 2.5826103687286377
Validation loss: 2.019544154405594

Epoch: 5| Step: 2
Training loss: 2.4260265827178955
Validation loss: 2.01368910074234

Epoch: 5| Step: 3
Training loss: 2.1484715938568115
Validation loss: 2.011907637119293

Epoch: 5| Step: 4
Training loss: 1.8072831630706787
Validation loss: 2.014072517553965

Epoch: 5| Step: 5
Training loss: 2.0076637268066406
Validation loss: 2.013261541724205

Epoch: 5| Step: 6
Training loss: 1.6635973453521729
Validation loss: 2.0095308025678

Epoch: 5| Step: 7
Training loss: 2.4989542961120605
Validation loss: 2.012812147537867

Epoch: 5| Step: 8
Training loss: 1.525590181350708
Validation loss: 2.0109011083841324

Epoch: 5| Step: 9
Training loss: 2.2618002891540527
Validation loss: 2.000014911095301

Epoch: 5| Step: 10
Training loss: 2.468594789505005
Validation loss: 2.0143615156412125

Epoch: 5| Step: 11
Training loss: 2.2842626571655273
Validation loss: 2.0073381265004477

Epoch: 103| Step: 0
Training loss: 2.1059138774871826
Validation loss: 2.0225574473539987

Epoch: 5| Step: 1
Training loss: 2.018857479095459
Validation loss: 2.022872030735016

Epoch: 5| Step: 2
Training loss: 2.530888319015503
Validation loss: 2.022368316849073

Epoch: 5| Step: 3
Training loss: 2.3905417919158936
Validation loss: 2.030587986111641

Epoch: 5| Step: 4
Training loss: 1.9983768463134766
Validation loss: 2.0190048664808273

Epoch: 5| Step: 5
Training loss: 1.731736183166504
Validation loss: 2.0230664958556495

Epoch: 5| Step: 6
Training loss: 2.209782123565674
Validation loss: 2.017964467406273

Epoch: 5| Step: 7
Training loss: 2.5065741539001465
Validation loss: 2.014771744608879

Epoch: 5| Step: 8
Training loss: 1.7355825901031494
Validation loss: 2.012330651283264

Epoch: 5| Step: 9
Training loss: 2.5017993450164795
Validation loss: 2.012402301033338

Epoch: 5| Step: 10
Training loss: 1.8642408847808838
Validation loss: 2.0188483546177545

Epoch: 5| Step: 11
Training loss: 2.060734272003174
Validation loss: 2.013842433691025

Epoch: 104| Step: 0
Training loss: 2.2728304862976074
Validation loss: 2.0237383395433426

Epoch: 5| Step: 1
Training loss: 1.9768997430801392
Validation loss: 2.01054747402668

Epoch: 5| Step: 2
Training loss: 2.134507894515991
Validation loss: 2.016089061896006

Epoch: 5| Step: 3
Training loss: 1.9735124111175537
Validation loss: 2.0128609587748847

Epoch: 5| Step: 4
Training loss: 2.5686120986938477
Validation loss: 2.0235426078240075

Epoch: 5| Step: 5
Training loss: 1.698387861251831
Validation loss: 2.017996445298195

Epoch: 5| Step: 6
Training loss: 2.464538097381592
Validation loss: 2.023801232377688

Epoch: 5| Step: 7
Training loss: 2.2243895530700684
Validation loss: 2.0276640206575394

Epoch: 5| Step: 8
Training loss: 2.1789064407348633
Validation loss: 2.0264995644489923

Epoch: 5| Step: 9
Training loss: 2.2685389518737793
Validation loss: 2.029438406229019

Epoch: 5| Step: 10
Training loss: 1.8746731281280518
Validation loss: 2.0277866820494332

Epoch: 5| Step: 11
Training loss: 1.4054172039031982
Validation loss: 2.0251124699910483

Epoch: 105| Step: 0
Training loss: 2.368802547454834
Validation loss: 2.0162997047106423

Epoch: 5| Step: 1
Training loss: 2.2360949516296387
Validation loss: 2.0161064167817435

Epoch: 5| Step: 2
Training loss: 2.615678310394287
Validation loss: 2.028269430001577

Epoch: 5| Step: 3
Training loss: 1.7049291133880615
Validation loss: 2.0172783682743707

Epoch: 5| Step: 4
Training loss: 1.5126107931137085
Validation loss: 2.0147914588451385

Epoch: 5| Step: 5
Training loss: 1.8667991161346436
Validation loss: 2.0157302816708884

Epoch: 5| Step: 6
Training loss: 2.491494655609131
Validation loss: 2.019326309363047

Epoch: 5| Step: 7
Training loss: 2.0332448482513428
Validation loss: 2.0296575178702674

Epoch: 5| Step: 8
Training loss: 2.0756232738494873
Validation loss: 2.0185000697771707

Epoch: 5| Step: 9
Training loss: 2.036714553833008
Validation loss: 2.0227673053741455

Epoch: 5| Step: 10
Training loss: 2.483062744140625
Validation loss: 2.016585330168406

Epoch: 5| Step: 11
Training loss: 2.5254602432250977
Validation loss: 2.0240653604269028

Epoch: 106| Step: 0
Training loss: 1.8640425205230713
Validation loss: 2.0187636415163674

Epoch: 5| Step: 1
Training loss: 2.055088758468628
Validation loss: 2.0183768967787423

Epoch: 5| Step: 2
Training loss: 2.312701463699341
Validation loss: 2.018782695134481

Epoch: 5| Step: 3
Training loss: 1.8873745203018188
Validation loss: 2.0337740828593573

Epoch: 5| Step: 4
Training loss: 1.9394340515136719
Validation loss: 2.020739162961642

Epoch: 5| Step: 5
Training loss: 1.730474829673767
Validation loss: 2.0193478912115097

Epoch: 5| Step: 6
Training loss: 2.148688316345215
Validation loss: 2.0254051784674325

Epoch: 5| Step: 7
Training loss: 2.557107448577881
Validation loss: 2.0232213586568832

Epoch: 5| Step: 8
Training loss: 2.673584461212158
Validation loss: 2.0275611778100333

Epoch: 5| Step: 9
Training loss: 2.209820032119751
Validation loss: 2.0185935348272324

Epoch: 5| Step: 10
Training loss: 2.207911491394043
Validation loss: 2.0203981697559357

Epoch: 5| Step: 11
Training loss: 1.6585280895233154
Validation loss: 2.0153600176175437

Epoch: 107| Step: 0
Training loss: 2.0801937580108643
Validation loss: 2.012118319670359

Epoch: 5| Step: 1
Training loss: 2.1913864612579346
Validation loss: 2.018185034394264

Epoch: 5| Step: 2
Training loss: 2.7479312419891357
Validation loss: 2.013677770892779

Epoch: 5| Step: 3
Training loss: 1.827720284461975
Validation loss: 2.0188183337450027

Epoch: 5| Step: 4
Training loss: 2.016528606414795
Validation loss: 2.021704206864039

Epoch: 5| Step: 5
Training loss: 2.1679561138153076
Validation loss: 2.0156782964865365

Epoch: 5| Step: 6
Training loss: 2.104919672012329
Validation loss: 2.01825820406278

Epoch: 5| Step: 7
Training loss: 1.7912874221801758
Validation loss: 2.020816052953402

Epoch: 5| Step: 8
Training loss: 2.6978259086608887
Validation loss: 2.015780652562777

Epoch: 5| Step: 9
Training loss: 1.805863380432129
Validation loss: 2.013196269671122

Epoch: 5| Step: 10
Training loss: 1.9719717502593994
Validation loss: 2.0173301001389823

Epoch: 5| Step: 11
Training loss: 1.8006597757339478
Validation loss: 2.0169221262137094

Epoch: 108| Step: 0
Training loss: 2.1338765621185303
Validation loss: 2.012649635473887

Epoch: 5| Step: 1
Training loss: 2.1920623779296875
Validation loss: 2.013584072391192

Epoch: 5| Step: 2
Training loss: 1.9103326797485352
Validation loss: 2.0140386124451957

Epoch: 5| Step: 3
Training loss: 1.8147598505020142
Validation loss: 2.020811622341474

Epoch: 5| Step: 4
Training loss: 2.213698625564575
Validation loss: 2.024316757917404

Epoch: 5| Step: 5
Training loss: 1.8142837285995483
Validation loss: 2.028567542632421

Epoch: 5| Step: 6
Training loss: 1.7285410165786743
Validation loss: 2.0372069776058197

Epoch: 5| Step: 7
Training loss: 2.3185906410217285
Validation loss: 2.0205595791339874

Epoch: 5| Step: 8
Training loss: 2.5067832469940186
Validation loss: 2.0252284655968347

Epoch: 5| Step: 9
Training loss: 2.3093879222869873
Validation loss: 2.021590302387873

Epoch: 5| Step: 10
Training loss: 2.437711477279663
Validation loss: 2.0172692636648812

Epoch: 5| Step: 11
Training loss: 1.9350675344467163
Validation loss: 2.018135830760002

Epoch: 109| Step: 0
Training loss: 2.5255541801452637
Validation loss: 2.0101484805345535

Epoch: 5| Step: 1
Training loss: 2.0522501468658447
Validation loss: 2.0102721452713013

Epoch: 5| Step: 2
Training loss: 2.557452917098999
Validation loss: 2.0120848963658013

Epoch: 5| Step: 3
Training loss: 2.2946131229400635
Validation loss: 2.0056316753228507

Epoch: 5| Step: 4
Training loss: 2.0983078479766846
Validation loss: 2.004398991664251

Epoch: 5| Step: 5
Training loss: 2.0137572288513184
Validation loss: 2.0055006792147956

Epoch: 5| Step: 6
Training loss: 1.8830829858779907
Validation loss: 2.0045862247546515

Epoch: 5| Step: 7
Training loss: 2.0778164863586426
Validation loss: 2.004121238986651

Epoch: 5| Step: 8
Training loss: 1.907200574874878
Validation loss: 2.0033687204122543

Epoch: 5| Step: 9
Training loss: 2.1815905570983887
Validation loss: 2.0071140229701996

Epoch: 5| Step: 10
Training loss: 1.953345537185669
Validation loss: 2.0304996172587075

Epoch: 5| Step: 11
Training loss: 2.0021512508392334
Validation loss: 2.015156457821528

Epoch: 110| Step: 0
Training loss: 1.9577707052230835
Validation loss: 2.029097999135653

Epoch: 5| Step: 1
Training loss: 2.3352749347686768
Validation loss: 2.030336484313011

Epoch: 5| Step: 2
Training loss: 1.9450480937957764
Validation loss: 2.018694654107094

Epoch: 5| Step: 3
Training loss: 2.177861213684082
Validation loss: 2.0156143407026925

Epoch: 5| Step: 4
Training loss: 2.3165793418884277
Validation loss: 2.027326688170433

Epoch: 5| Step: 5
Training loss: 2.1000912189483643
Validation loss: 2.020505661765734

Epoch: 5| Step: 6
Training loss: 2.9336352348327637
Validation loss: 2.027594178915024

Epoch: 5| Step: 7
Training loss: 2.072361946105957
Validation loss: 2.0108829339345298

Epoch: 5| Step: 8
Training loss: 1.5119819641113281
Validation loss: 2.013003850976626

Epoch: 5| Step: 9
Training loss: 1.9174559116363525
Validation loss: 2.0095775574445724

Epoch: 5| Step: 10
Training loss: 1.9252796173095703
Validation loss: 2.0109065175056458

Epoch: 5| Step: 11
Training loss: 3.038172483444214
Validation loss: 2.0009733736515045

Epoch: 111| Step: 0
Training loss: 2.1541929244995117
Validation loss: 2.000022475918134

Epoch: 5| Step: 1
Training loss: 2.572067975997925
Validation loss: 2.0031643410523734

Epoch: 5| Step: 2
Training loss: 1.915933609008789
Validation loss: 2.0106220295031867

Epoch: 5| Step: 3
Training loss: 2.056105136871338
Validation loss: 2.0073685397704444

Epoch: 5| Step: 4
Training loss: 2.168839931488037
Validation loss: 2.0101634562015533

Epoch: 5| Step: 5
Training loss: 1.7892993688583374
Validation loss: 2.002904161810875

Epoch: 5| Step: 6
Training loss: 1.6031506061553955
Validation loss: 2.006654923160871

Epoch: 5| Step: 7
Training loss: 2.45391583442688
Validation loss: 2.005137806137403

Epoch: 5| Step: 8
Training loss: 2.431704521179199
Validation loss: 2.0067947655916214

Epoch: 5| Step: 9
Training loss: 2.1567842960357666
Validation loss: 2.0089628348747888

Epoch: 5| Step: 10
Training loss: 1.9919722080230713
Validation loss: 2.0120429744323096

Epoch: 5| Step: 11
Training loss: 2.4076223373413086
Validation loss: 2.014755035440127

Epoch: 112| Step: 0
Training loss: 1.469784140586853
Validation loss: 2.0173456917206445

Epoch: 5| Step: 1
Training loss: 2.5024261474609375
Validation loss: 2.018735026319822

Epoch: 5| Step: 2
Training loss: 2.425316572189331
Validation loss: 2.0132907132307687

Epoch: 5| Step: 3
Training loss: 1.5839768648147583
Validation loss: 2.018649473786354

Epoch: 5| Step: 4
Training loss: 1.7987492084503174
Validation loss: 2.008093719681104

Epoch: 5| Step: 5
Training loss: 1.7842403650283813
Validation loss: 2.004401678840319

Epoch: 5| Step: 6
Training loss: 2.1357879638671875
Validation loss: 1.9984441151221592

Epoch: 5| Step: 7
Training loss: 2.6763670444488525
Validation loss: 2.0052013049523034

Epoch: 5| Step: 8
Training loss: 2.1152970790863037
Validation loss: 2.0037254989147186

Epoch: 5| Step: 9
Training loss: 2.4933009147644043
Validation loss: 2.000187670191129

Epoch: 5| Step: 10
Training loss: 2.344031810760498
Validation loss: 2.003054305911064

Epoch: 5| Step: 11
Training loss: 1.618036150932312
Validation loss: 2.0073557794094086

Epoch: 113| Step: 0
Training loss: 2.423797130584717
Validation loss: 2.00619013607502

Epoch: 5| Step: 1
Training loss: 1.8802944421768188
Validation loss: 2.0113843778769174

Epoch: 5| Step: 2
Training loss: 2.175626754760742
Validation loss: 2.004558245340983

Epoch: 5| Step: 3
Training loss: 1.6382267475128174
Validation loss: 2.0102013995250068

Epoch: 5| Step: 4
Training loss: 2.137216091156006
Validation loss: 2.00937153895696

Epoch: 5| Step: 5
Training loss: 2.1398582458496094
Validation loss: 2.019791901111603

Epoch: 5| Step: 6
Training loss: 2.289625644683838
Validation loss: 2.0238265097141266

Epoch: 5| Step: 7
Training loss: 2.6363582611083984
Validation loss: 2.016799290974935

Epoch: 5| Step: 8
Training loss: 1.4435551166534424
Validation loss: 2.0098018447558084

Epoch: 5| Step: 9
Training loss: 2.5144646167755127
Validation loss: 2.0150169680515924

Epoch: 5| Step: 10
Training loss: 2.02571964263916
Validation loss: 2.012746517856916

Epoch: 5| Step: 11
Training loss: 2.496359348297119
Validation loss: 2.011447081963221

Epoch: 114| Step: 0
Training loss: 1.9154688119888306
Validation loss: 2.011246681213379

Epoch: 5| Step: 1
Training loss: 2.0535831451416016
Validation loss: 2.0068700363238654

Epoch: 5| Step: 2
Training loss: 2.403940439224243
Validation loss: 2.0075565526882806

Epoch: 5| Step: 3
Training loss: 1.8899691104888916
Validation loss: 2.0066543420155845

Epoch: 5| Step: 4
Training loss: 2.435842990875244
Validation loss: 2.0039237986008325

Epoch: 5| Step: 5
Training loss: 1.8480422496795654
Validation loss: 1.9995477298895519

Epoch: 5| Step: 6
Training loss: 2.1803958415985107
Validation loss: 1.9992479234933853

Epoch: 5| Step: 7
Training loss: 2.4527833461761475
Validation loss: 2.0003591030836105

Epoch: 5| Step: 8
Training loss: 1.5607401132583618
Validation loss: 2.0084784577290216

Epoch: 5| Step: 9
Training loss: 2.766939640045166
Validation loss: 2.008899971842766

Epoch: 5| Step: 10
Training loss: 2.0100629329681396
Validation loss: 2.009667620062828

Epoch: 5| Step: 11
Training loss: 1.2070024013519287
Validation loss: 2.004349256555239

Epoch: 115| Step: 0
Training loss: 2.209056854248047
Validation loss: 2.015466650327047

Epoch: 5| Step: 1
Training loss: 2.4325637817382812
Validation loss: 2.0142426739136376

Epoch: 5| Step: 2
Training loss: 1.9512630701065063
Validation loss: 2.0301251908143363

Epoch: 5| Step: 3
Training loss: 2.252589702606201
Validation loss: 2.0284745395183563

Epoch: 5| Step: 4
Training loss: 1.9798622131347656
Validation loss: 2.0193419456481934

Epoch: 5| Step: 5
Training loss: 2.62459135055542
Validation loss: 2.0110409508148828

Epoch: 5| Step: 6
Training loss: 1.821303129196167
Validation loss: 2.0069737434387207

Epoch: 5| Step: 7
Training loss: 2.1944549083709717
Validation loss: 2.004649723569552

Epoch: 5| Step: 8
Training loss: 2.0119235515594482
Validation loss: 2.006391887863477

Epoch: 5| Step: 9
Training loss: 1.8266561031341553
Validation loss: 2.002353236079216

Epoch: 5| Step: 10
Training loss: 1.98391854763031
Validation loss: 2.0068128208319345

Epoch: 5| Step: 11
Training loss: 2.4394352436065674
Validation loss: 2.00287634630998

Epoch: 116| Step: 0
Training loss: 2.072249412536621
Validation loss: 2.00508846839269

Epoch: 5| Step: 1
Training loss: 2.4029412269592285
Validation loss: 2.0021047542492547

Epoch: 5| Step: 2
Training loss: 2.2641665935516357
Validation loss: 2.007516081134478

Epoch: 5| Step: 3
Training loss: 1.7600761651992798
Validation loss: 2.0016770710547767

Epoch: 5| Step: 4
Training loss: 1.9834438562393188
Validation loss: 2.004854987064997

Epoch: 5| Step: 5
Training loss: 2.566338062286377
Validation loss: 2.009231984615326

Epoch: 5| Step: 6
Training loss: 2.3397140502929688
Validation loss: 2.0116251607735953

Epoch: 5| Step: 7
Training loss: 2.160092353820801
Validation loss: 2.0184212575356164

Epoch: 5| Step: 8
Training loss: 2.240438938140869
Validation loss: 2.0066465536753335

Epoch: 5| Step: 9
Training loss: 1.6915090084075928
Validation loss: 1.998897597193718

Epoch: 5| Step: 10
Training loss: 2.046022415161133
Validation loss: 2.0111258874336877

Epoch: 5| Step: 11
Training loss: 1.196721076965332
Validation loss: 2.0188439339399338

Epoch: 117| Step: 0
Training loss: 2.387328863143921
Validation loss: 2.022482921679815

Epoch: 5| Step: 1
Training loss: 1.6805721521377563
Validation loss: 2.0142468015352883

Epoch: 5| Step: 2
Training loss: 2.886347532272339
Validation loss: 2.019848331809044

Epoch: 5| Step: 3
Training loss: 2.1194965839385986
Validation loss: 2.0186645885308585

Epoch: 5| Step: 4
Training loss: 1.884381651878357
Validation loss: 2.0439810206492743

Epoch: 5| Step: 5
Training loss: 2.4275527000427246
Validation loss: 2.0400843421618142

Epoch: 5| Step: 6
Training loss: 2.4621615409851074
Validation loss: 2.0222144424915314

Epoch: 5| Step: 7
Training loss: 2.374328136444092
Validation loss: 2.0315270721912384

Epoch: 5| Step: 8
Training loss: 1.6666457653045654
Validation loss: 2.0245848149061203

Epoch: 5| Step: 9
Training loss: 1.4281259775161743
Validation loss: 2.0139949023723602

Epoch: 5| Step: 10
Training loss: 1.9602972269058228
Validation loss: 2.01701228817304

Epoch: 5| Step: 11
Training loss: 2.404482126235962
Validation loss: 2.0107574413220086

Epoch: 118| Step: 0
Training loss: 1.941046953201294
Validation loss: 2.008512462178866

Epoch: 5| Step: 1
Training loss: 2.0242881774902344
Validation loss: 2.014313911398252

Epoch: 5| Step: 2
Training loss: 2.7038464546203613
Validation loss: 2.022030626734098

Epoch: 5| Step: 3
Training loss: 2.0657012462615967
Validation loss: 2.0256820370753608

Epoch: 5| Step: 4
Training loss: 2.0939133167266846
Validation loss: 2.025536303718885

Epoch: 5| Step: 5
Training loss: 2.4437108039855957
Validation loss: 2.0242579827706018

Epoch: 5| Step: 6
Training loss: 2.2509818077087402
Validation loss: 2.01666696369648

Epoch: 5| Step: 7
Training loss: 1.8964557647705078
Validation loss: 2.0176917215188346

Epoch: 5| Step: 8
Training loss: 2.1281771659851074
Validation loss: 2.019819771250089

Epoch: 5| Step: 9
Training loss: 1.8721745014190674
Validation loss: 2.0128653198480606

Epoch: 5| Step: 10
Training loss: 2.1292686462402344
Validation loss: 2.010328456759453

Epoch: 5| Step: 11
Training loss: 2.732243537902832
Validation loss: 2.0040088494618735

Epoch: 119| Step: 0
Training loss: 1.919797658920288
Validation loss: 2.009047195315361

Epoch: 5| Step: 1
Training loss: 1.9973423480987549
Validation loss: 2.009668027361234

Epoch: 5| Step: 2
Training loss: 1.3979392051696777
Validation loss: 2.0080975691477456

Epoch: 5| Step: 3
Training loss: 1.7959368228912354
Validation loss: 2.013155629237493

Epoch: 5| Step: 4
Training loss: 2.232372760772705
Validation loss: 2.021242772539457

Epoch: 5| Step: 5
Training loss: 1.978550910949707
Validation loss: 2.0246357321739197

Epoch: 5| Step: 6
Training loss: 2.6816062927246094
Validation loss: 2.0398026953140893

Epoch: 5| Step: 7
Training loss: 2.0300850868225098
Validation loss: 2.056632628043493

Epoch: 5| Step: 8
Training loss: 2.223606586456299
Validation loss: 2.0655135214328766

Epoch: 5| Step: 9
Training loss: 2.686516761779785
Validation loss: 2.0610888451337814

Epoch: 5| Step: 10
Training loss: 2.66207218170166
Validation loss: 2.04410882294178

Epoch: 5| Step: 11
Training loss: 2.103688955307007
Validation loss: 2.024204909801483

Epoch: 120| Step: 0
Training loss: 2.4652657508850098
Validation loss: 2.014254078269005

Epoch: 5| Step: 1
Training loss: 2.35546875
Validation loss: 2.00984126329422

Epoch: 5| Step: 2
Training loss: 2.0055477619171143
Validation loss: 2.01165871322155

Epoch: 5| Step: 3
Training loss: 1.8478431701660156
Validation loss: 2.0062229285637536

Epoch: 5| Step: 4
Training loss: 1.7879760265350342
Validation loss: 2.0035679638385773

Epoch: 5| Step: 5
Training loss: 2.614173412322998
Validation loss: 2.0069121619065604

Epoch: 5| Step: 6
Training loss: 1.7803466320037842
Validation loss: 2.0173600564400354

Epoch: 5| Step: 7
Training loss: 2.151761531829834
Validation loss: 2.016323134303093

Epoch: 5| Step: 8
Training loss: 1.6497539281845093
Validation loss: 2.0079309940338135

Epoch: 5| Step: 9
Training loss: 2.457474946975708
Validation loss: 2.007987936337789

Epoch: 5| Step: 10
Training loss: 2.1912097930908203
Validation loss: 1.9982431332270305

Epoch: 5| Step: 11
Training loss: 2.555302619934082
Validation loss: 1.9955632090568542

Epoch: 121| Step: 0
Training loss: 2.037416458129883
Validation loss: 1.9979433566331863

Epoch: 5| Step: 1
Training loss: 2.3593578338623047
Validation loss: 1.9919262031714122

Epoch: 5| Step: 2
Training loss: 2.49241042137146
Validation loss: 1.9960664361715317

Epoch: 5| Step: 3
Training loss: 1.6402666568756104
Validation loss: 1.9988013257582982

Epoch: 5| Step: 4
Training loss: 2.186821699142456
Validation loss: 1.9957167108853657

Epoch: 5| Step: 5
Training loss: 2.276216983795166
Validation loss: 1.9957809696594875

Epoch: 5| Step: 6
Training loss: 2.1843183040618896
Validation loss: 2.00901693602403

Epoch: 5| Step: 7
Training loss: 1.4151767492294312
Validation loss: 2.0138086726268134

Epoch: 5| Step: 8
Training loss: 1.7671029567718506
Validation loss: 2.0244004130363464

Epoch: 5| Step: 9
Training loss: 2.2123475074768066
Validation loss: 2.0080440094073615

Epoch: 5| Step: 10
Training loss: 2.685110569000244
Validation loss: 2.0099096645911536

Epoch: 5| Step: 11
Training loss: 2.621891736984253
Validation loss: 2.0031182070573172

Epoch: 122| Step: 0
Training loss: 2.2852022647857666
Validation loss: 2.0044660617907843

Epoch: 5| Step: 1
Training loss: 2.5055675506591797
Validation loss: 2.003346269329389

Epoch: 5| Step: 2
Training loss: 2.599172592163086
Validation loss: 1.996978983283043

Epoch: 5| Step: 3
Training loss: 1.4216574430465698
Validation loss: 1.9984478404124577

Epoch: 5| Step: 4
Training loss: 2.170013666152954
Validation loss: 2.0051905065774918

Epoch: 5| Step: 5
Training loss: 2.0264735221862793
Validation loss: 1.9990314642588298

Epoch: 5| Step: 6
Training loss: 1.9663454294204712
Validation loss: 2.000180179874102

Epoch: 5| Step: 7
Training loss: 2.0519440174102783
Validation loss: 2.0065434277057648

Epoch: 5| Step: 8
Training loss: 2.271085262298584
Validation loss: 2.0138082007567086

Epoch: 5| Step: 9
Training loss: 1.8696181774139404
Validation loss: 2.007913510004679

Epoch: 5| Step: 10
Training loss: 1.6827465295791626
Validation loss: 2.010827193657557

Epoch: 5| Step: 11
Training loss: 3.3847925662994385
Validation loss: 2.0190674662590027

Epoch: 123| Step: 0
Training loss: 2.0249619483947754
Validation loss: 2.018692433834076

Epoch: 5| Step: 1
Training loss: 2.257995128631592
Validation loss: 2.0260688811540604

Epoch: 5| Step: 2
Training loss: 2.302004814147949
Validation loss: 2.0191630025704703

Epoch: 5| Step: 3
Training loss: 2.0558252334594727
Validation loss: 2.019422729810079

Epoch: 5| Step: 4
Training loss: 2.431807518005371
Validation loss: 2.0234233190615973

Epoch: 5| Step: 5
Training loss: 1.8715509176254272
Validation loss: 2.012922157843908

Epoch: 5| Step: 6
Training loss: 2.0378880500793457
Validation loss: 2.01706970234712

Epoch: 5| Step: 7
Training loss: 2.4784533977508545
Validation loss: 2.0146373907725015

Epoch: 5| Step: 8
Training loss: 1.88480544090271
Validation loss: 2.007630616426468

Epoch: 5| Step: 9
Training loss: 1.4575637578964233
Validation loss: 2.0214066406091056

Epoch: 5| Step: 10
Training loss: 2.5662765502929688
Validation loss: 2.014009286959966

Epoch: 5| Step: 11
Training loss: 0.7979655265808105
Validation loss: 2.013528525829315

Epoch: 124| Step: 0
Training loss: 2.7064108848571777
Validation loss: 2.0178995728492737

Epoch: 5| Step: 1
Training loss: 2.0912671089172363
Validation loss: 2.022404208779335

Epoch: 5| Step: 2
Training loss: 2.096151828765869
Validation loss: 2.01484906176726

Epoch: 5| Step: 3
Training loss: 2.3823318481445312
Validation loss: 2.013563593228658

Epoch: 5| Step: 4
Training loss: 1.971125602722168
Validation loss: 2.007633005579313

Epoch: 5| Step: 5
Training loss: 2.278132677078247
Validation loss: 2.010705828666687

Epoch: 5| Step: 6
Training loss: 2.636870861053467
Validation loss: 2.0207098921140036

Epoch: 5| Step: 7
Training loss: 1.679735541343689
Validation loss: 2.017452468474706

Epoch: 5| Step: 8
Training loss: 1.8228152990341187
Validation loss: 2.0231888194878898

Epoch: 5| Step: 9
Training loss: 1.6568577289581299
Validation loss: 2.0109052658081055

Epoch: 5| Step: 10
Training loss: 1.6276023387908936
Validation loss: 2.0099646796782813

Epoch: 5| Step: 11
Training loss: 2.498453378677368
Validation loss: 2.018053357799848

Epoch: 125| Step: 0
Training loss: 2.07513165473938
Validation loss: 2.0158049215873084

Epoch: 5| Step: 1
Training loss: 1.835942029953003
Validation loss: 2.0113839407761893

Epoch: 5| Step: 2
Training loss: 2.625412702560425
Validation loss: 2.0103064278761544

Epoch: 5| Step: 3
Training loss: 1.8948888778686523
Validation loss: 2.009516383210818

Epoch: 5| Step: 4
Training loss: 2.2919960021972656
Validation loss: 2.013234794139862

Epoch: 5| Step: 5
Training loss: 1.9281574487686157
Validation loss: 2.0116033454736075

Epoch: 5| Step: 6
Training loss: 2.1516528129577637
Validation loss: 2.012056584159533

Epoch: 5| Step: 7
Training loss: 2.040605306625366
Validation loss: 2.016116807858149

Epoch: 5| Step: 8
Training loss: 2.1417856216430664
Validation loss: 2.0093757112820945

Epoch: 5| Step: 9
Training loss: 1.9124481678009033
Validation loss: 2.014574388662974

Epoch: 5| Step: 10
Training loss: 2.127122163772583
Validation loss: 2.014145309726397

Epoch: 5| Step: 11
Training loss: 2.3885750770568848
Validation loss: 2.0144638617833457

Epoch: 126| Step: 0
Training loss: 2.1610100269317627
Validation loss: 2.0105262249708176

Epoch: 5| Step: 1
Training loss: 2.444995403289795
Validation loss: 2.006945714354515

Epoch: 5| Step: 2
Training loss: 1.637396216392517
Validation loss: 2.005111043651899

Epoch: 5| Step: 3
Training loss: 1.7304461002349854
Validation loss: 2.0085488508145013

Epoch: 5| Step: 4
Training loss: 2.451988935470581
Validation loss: 2.0146825859944024

Epoch: 5| Step: 5
Training loss: 2.275587558746338
Validation loss: 2.003568450609843

Epoch: 5| Step: 6
Training loss: 2.154414415359497
Validation loss: 2.008754869302114

Epoch: 5| Step: 7
Training loss: 2.180224895477295
Validation loss: 2.0062981049219766

Epoch: 5| Step: 8
Training loss: 1.5519946813583374
Validation loss: 2.006288175781568

Epoch: 5| Step: 9
Training loss: 2.5044898986816406
Validation loss: 2.0010547737280526

Epoch: 5| Step: 10
Training loss: 1.921966552734375
Validation loss: 2.004271556933721

Epoch: 5| Step: 11
Training loss: 1.91398024559021
Validation loss: 1.9975207597017288

Epoch: 127| Step: 0
Training loss: 1.5766956806182861
Validation loss: 2.006656438112259

Epoch: 5| Step: 1
Training loss: 1.832482099533081
Validation loss: 2.001890773574511

Epoch: 5| Step: 2
Training loss: 2.2195897102355957
Validation loss: 2.009151811401049

Epoch: 5| Step: 3
Training loss: 2.5045859813690186
Validation loss: 2.0064833660920462

Epoch: 5| Step: 4
Training loss: 2.329432249069214
Validation loss: 2.008510500192642

Epoch: 5| Step: 5
Training loss: 1.9545269012451172
Validation loss: 2.0048473179340363

Epoch: 5| Step: 6
Training loss: 1.8866815567016602
Validation loss: 2.0137664725383124

Epoch: 5| Step: 7
Training loss: 2.1620564460754395
Validation loss: 2.0032567232847214

Epoch: 5| Step: 8
Training loss: 2.143599271774292
Validation loss: 2.011094108223915

Epoch: 5| Step: 9
Training loss: 2.5239949226379395
Validation loss: 2.004927635192871

Epoch: 5| Step: 10
Training loss: 2.1685128211975098
Validation loss: 2.0035291761159897

Epoch: 5| Step: 11
Training loss: 0.6914254426956177
Validation loss: 2.012272834777832

Epoch: 128| Step: 0
Training loss: 2.138375759124756
Validation loss: 2.0011016875505447

Epoch: 5| Step: 1
Training loss: 1.7942339181900024
Validation loss: 2.0008513927459717

Epoch: 5| Step: 2
Training loss: 2.8850505352020264
Validation loss: 1.9953709344069164

Epoch: 5| Step: 3
Training loss: 1.7516437768936157
Validation loss: 1.9980732252200444

Epoch: 5| Step: 4
Training loss: 2.575512170791626
Validation loss: 1.9962087869644165

Epoch: 5| Step: 5
Training loss: 2.28059983253479
Validation loss: 2.0108626633882523

Epoch: 5| Step: 6
Training loss: 1.9330260753631592
Validation loss: 2.001610060532888

Epoch: 5| Step: 7
Training loss: 2.0073580741882324
Validation loss: 2.00723663965861

Epoch: 5| Step: 8
Training loss: 2.3709800243377686
Validation loss: 2.0143982768058777

Epoch: 5| Step: 9
Training loss: 1.8950544595718384
Validation loss: 2.0124844113985696

Epoch: 5| Step: 10
Training loss: 1.7994941473007202
Validation loss: 2.01479438940684

Epoch: 5| Step: 11
Training loss: 1.6324589252471924
Validation loss: 2.0010618766148887

Epoch: 129| Step: 0
Training loss: 2.54417085647583
Validation loss: 2.009805679321289

Epoch: 5| Step: 1
Training loss: 2.140890121459961
Validation loss: 2.017302170395851

Epoch: 5| Step: 2
Training loss: 1.8904107809066772
Validation loss: 2.0142040054003396

Epoch: 5| Step: 3
Training loss: 1.920753836631775
Validation loss: 2.0172998855511346

Epoch: 5| Step: 4
Training loss: 1.8706550598144531
Validation loss: 2.023617908358574

Epoch: 5| Step: 5
Training loss: 1.8943891525268555
Validation loss: 2.0266066094239554

Epoch: 5| Step: 6
Training loss: 2.0039424896240234
Validation loss: 2.027809798717499

Epoch: 5| Step: 7
Training loss: 1.9061530828475952
Validation loss: 2.022411117951075

Epoch: 5| Step: 8
Training loss: 2.1414573192596436
Validation loss: 2.0264252722263336

Epoch: 5| Step: 9
Training loss: 2.1778345108032227
Validation loss: 2.017498051126798

Epoch: 5| Step: 10
Training loss: 2.638516902923584
Validation loss: 2.013508061567942

Epoch: 5| Step: 11
Training loss: 2.1627113819122314
Validation loss: 2.0118052065372467

Epoch: 130| Step: 0
Training loss: 1.7921974658966064
Validation loss: 2.0098641316095986

Epoch: 5| Step: 1
Training loss: 1.7225046157836914
Validation loss: 2.00909831126531

Epoch: 5| Step: 2
Training loss: 2.403690814971924
Validation loss: 2.011667639017105

Epoch: 5| Step: 3
Training loss: 2.41961407661438
Validation loss: 2.011390969157219

Epoch: 5| Step: 4
Training loss: 2.4790844917297363
Validation loss: 2.0164590378602347

Epoch: 5| Step: 5
Training loss: 2.453291654586792
Validation loss: 2.012327179312706

Epoch: 5| Step: 6
Training loss: 1.671950340270996
Validation loss: 2.008642792701721

Epoch: 5| Step: 7
Training loss: 1.977971076965332
Validation loss: 2.015704716245333

Epoch: 5| Step: 8
Training loss: 2.431511402130127
Validation loss: 2.0121767620245614

Epoch: 5| Step: 9
Training loss: 1.8571827411651611
Validation loss: 2.0141701797644296

Epoch: 5| Step: 10
Training loss: 1.6755850315093994
Validation loss: 2.0178006291389465

Epoch: 5| Step: 11
Training loss: 2.6499578952789307
Validation loss: 2.0304828385512033

Epoch: 131| Step: 0
Training loss: 2.1473050117492676
Validation loss: 2.0208207964897156

Epoch: 5| Step: 1
Training loss: 2.288275957107544
Validation loss: 2.034289921323458

Epoch: 5| Step: 2
Training loss: 1.8671871423721313
Validation loss: 2.0360980530579886

Epoch: 5| Step: 3
Training loss: 1.9958572387695312
Validation loss: 2.0232441474994025

Epoch: 5| Step: 4
Training loss: 2.1787495613098145
Validation loss: 2.037155970931053

Epoch: 5| Step: 5
Training loss: 2.20202898979187
Validation loss: 2.0133879482746124

Epoch: 5| Step: 6
Training loss: 1.8450801372528076
Validation loss: 2.0190817018349967

Epoch: 5| Step: 7
Training loss: 2.2994816303253174
Validation loss: 2.0172635863224664

Epoch: 5| Step: 8
Training loss: 2.0963706970214844
Validation loss: 2.021367684006691

Epoch: 5| Step: 9
Training loss: 2.01271390914917
Validation loss: 2.015856017669042

Epoch: 5| Step: 10
Training loss: 2.2320351600646973
Validation loss: 2.0303815801938376

Epoch: 5| Step: 11
Training loss: 1.273169994354248
Validation loss: 2.021719058354696

Epoch: 132| Step: 0
Training loss: 1.9823353290557861
Validation loss: 2.0223737259705863

Epoch: 5| Step: 1
Training loss: 2.046060562133789
Validation loss: 2.020188262065252

Epoch: 5| Step: 2
Training loss: 1.643028974533081
Validation loss: 2.013651271661123

Epoch: 5| Step: 3
Training loss: 2.21212100982666
Validation loss: 2.0236510634422302

Epoch: 5| Step: 4
Training loss: 2.4920175075531006
Validation loss: 2.01770448187987

Epoch: 5| Step: 5
Training loss: 2.55478572845459
Validation loss: 2.015724688768387

Epoch: 5| Step: 6
Training loss: 2.3033788204193115
Validation loss: 2.017503927151362

Epoch: 5| Step: 7
Training loss: 1.9881784915924072
Validation loss: 2.013751129309336

Epoch: 5| Step: 8
Training loss: 1.746761679649353
Validation loss: 2.015034705400467

Epoch: 5| Step: 9
Training loss: 2.3768296241760254
Validation loss: 2.0246006896098456

Epoch: 5| Step: 10
Training loss: 1.731971025466919
Validation loss: 2.016424606243769

Epoch: 5| Step: 11
Training loss: 2.5338916778564453
Validation loss: 2.0243091136217117

Epoch: 133| Step: 0
Training loss: 2.7102484703063965
Validation loss: 2.015240634481112

Epoch: 5| Step: 1
Training loss: 2.0035436153411865
Validation loss: 2.0149258772532144

Epoch: 5| Step: 2
Training loss: 2.400378704071045
Validation loss: 2.016440734267235

Epoch: 5| Step: 3
Training loss: 2.4660611152648926
Validation loss: 2.025639295578003

Epoch: 5| Step: 4
Training loss: 2.1351728439331055
Validation loss: 2.016617715358734

Epoch: 5| Step: 5
Training loss: 1.4119371175765991
Validation loss: 2.0153978765010834

Epoch: 5| Step: 6
Training loss: 1.9928991794586182
Validation loss: 2.0221626460552216

Epoch: 5| Step: 7
Training loss: 1.9481070041656494
Validation loss: 2.019934286673864

Epoch: 5| Step: 8
Training loss: 1.9225413799285889
Validation loss: 2.0212535709142685

Epoch: 5| Step: 9
Training loss: 1.8173348903656006
Validation loss: 2.022077058752378

Epoch: 5| Step: 10
Training loss: 2.128910541534424
Validation loss: 2.0121728579203286

Epoch: 5| Step: 11
Training loss: 1.5186069011688232
Validation loss: 2.02224799990654

Epoch: 134| Step: 0
Training loss: 1.5246760845184326
Validation loss: 2.0082878172397614

Epoch: 5| Step: 1
Training loss: 2.61694073677063
Validation loss: 2.0120178014039993

Epoch: 5| Step: 2
Training loss: 2.1569957733154297
Validation loss: 2.014844869573911

Epoch: 5| Step: 3
Training loss: 1.6950852870941162
Validation loss: 2.012443333864212

Epoch: 5| Step: 4
Training loss: 2.489009380340576
Validation loss: 2.0239651948213577

Epoch: 5| Step: 5
Training loss: 1.9052677154541016
Validation loss: 2.0157047460476556

Epoch: 5| Step: 6
Training loss: 2.226848840713501
Validation loss: 2.017628028988838

Epoch: 5| Step: 7
Training loss: 2.9087486267089844
Validation loss: 2.012923335035642

Epoch: 5| Step: 8
Training loss: 2.1282496452331543
Validation loss: 2.0119227220614753

Epoch: 5| Step: 9
Training loss: 1.6095043420791626
Validation loss: 2.014663577079773

Epoch: 5| Step: 10
Training loss: 1.936771035194397
Validation loss: 2.0133214394251504

Epoch: 5| Step: 11
Training loss: 1.224887490272522
Validation loss: 2.010420391956965

Epoch: 135| Step: 0
Training loss: 1.6892589330673218
Validation loss: 2.0130477199951806

Epoch: 5| Step: 1
Training loss: 1.5624778270721436
Validation loss: 2.0237958331902823

Epoch: 5| Step: 2
Training loss: 2.6481776237487793
Validation loss: 2.025973454117775

Epoch: 5| Step: 3
Training loss: 2.3052096366882324
Validation loss: 2.017382855216662

Epoch: 5| Step: 4
Training loss: 2.1898813247680664
Validation loss: 2.0184094508488974

Epoch: 5| Step: 5
Training loss: 2.317115068435669
Validation loss: 2.0256946086883545

Epoch: 5| Step: 6
Training loss: 2.328821897506714
Validation loss: 2.0212092945973077

Epoch: 5| Step: 7
Training loss: 1.6663230657577515
Validation loss: 2.0243616104125977

Epoch: 5| Step: 8
Training loss: 2.0550544261932373
Validation loss: 2.0239683985710144

Epoch: 5| Step: 9
Training loss: 1.8509935140609741
Validation loss: 2.0262327939271927

Epoch: 5| Step: 10
Training loss: 1.9818980693817139
Validation loss: 2.029524932305018

Epoch: 5| Step: 11
Training loss: 3.6739416122436523
Validation loss: 2.019197568297386

Epoch: 136| Step: 0
Training loss: 1.9323623180389404
Validation loss: 2.0196229765812554

Epoch: 5| Step: 1
Training loss: 1.98883855342865
Validation loss: 2.026499648888906

Epoch: 5| Step: 2
Training loss: 1.9646520614624023
Validation loss: 2.0256913105646768

Epoch: 5| Step: 3
Training loss: 2.634964942932129
Validation loss: 2.0200674533843994

Epoch: 5| Step: 4
Training loss: 2.386314630508423
Validation loss: 2.043433735768

Epoch: 5| Step: 5
Training loss: 1.8028209209442139
Validation loss: 2.0356464982032776

Epoch: 5| Step: 6
Training loss: 2.1686787605285645
Validation loss: 2.03726027905941

Epoch: 5| Step: 7
Training loss: 1.8950145244598389
Validation loss: 2.031315048535665

Epoch: 5| Step: 8
Training loss: 2.0775351524353027
Validation loss: 2.034072528282801

Epoch: 5| Step: 9
Training loss: 2.162872314453125
Validation loss: 2.029390513896942

Epoch: 5| Step: 10
Training loss: 1.6980177164077759
Validation loss: 2.03378356496493

Epoch: 5| Step: 11
Training loss: 2.594738483428955
Validation loss: 2.026731704672178

Epoch: 137| Step: 0
Training loss: 2.552635431289673
Validation loss: 2.020290349920591

Epoch: 5| Step: 1
Training loss: 2.250748872756958
Validation loss: 2.0164215862751007

Epoch: 5| Step: 2
Training loss: 2.0993258953094482
Validation loss: 2.0089046408732734

Epoch: 5| Step: 3
Training loss: 1.9557565450668335
Validation loss: 2.018548160791397

Epoch: 5| Step: 4
Training loss: 2.2430055141448975
Validation loss: 2.0106133023897805

Epoch: 5| Step: 5
Training loss: 2.249899387359619
Validation loss: 2.0152962605158486

Epoch: 5| Step: 6
Training loss: 1.5783137083053589
Validation loss: 2.0135406106710434

Epoch: 5| Step: 7
Training loss: 2.068254232406616
Validation loss: 2.029226467013359

Epoch: 5| Step: 8
Training loss: 2.1570022106170654
Validation loss: 2.0242306143045425

Epoch: 5| Step: 9
Training loss: 1.7917883396148682
Validation loss: 2.019451066851616

Epoch: 5| Step: 10
Training loss: 2.150364398956299
Validation loss: 2.030336211125056

Epoch: 5| Step: 11
Training loss: 1.5344271659851074
Validation loss: 2.0281585256258645

Epoch: 138| Step: 0
Training loss: 1.7482868432998657
Validation loss: 2.032281666994095

Epoch: 5| Step: 1
Training loss: 1.6911418437957764
Validation loss: 2.031656041741371

Epoch: 5| Step: 2
Training loss: 2.242888927459717
Validation loss: 2.035593365629514

Epoch: 5| Step: 3
Training loss: 2.2746644020080566
Validation loss: 2.0360215504964194

Epoch: 5| Step: 4
Training loss: 2.3825676441192627
Validation loss: 2.0255094915628433

Epoch: 5| Step: 5
Training loss: 2.072777271270752
Validation loss: 2.028790444135666

Epoch: 5| Step: 6
Training loss: 1.8703447580337524
Validation loss: 2.021576076745987

Epoch: 5| Step: 7
Training loss: 1.6453574895858765
Validation loss: 2.0228975117206573

Epoch: 5| Step: 8
Training loss: 2.5658648014068604
Validation loss: 2.024841472506523

Epoch: 5| Step: 9
Training loss: 2.12156343460083
Validation loss: 2.0185290475686393

Epoch: 5| Step: 10
Training loss: 2.1444694995880127
Validation loss: 2.025178705652555

Epoch: 5| Step: 11
Training loss: 2.159149408340454
Validation loss: 2.0151832848787308

Epoch: 139| Step: 0
Training loss: 2.2687442302703857
Validation loss: 2.0125572184721627

Epoch: 5| Step: 1
Training loss: 2.355752468109131
Validation loss: 2.0177113860845566

Epoch: 5| Step: 2
Training loss: 2.133626937866211
Validation loss: 2.0208370933930078

Epoch: 5| Step: 3
Training loss: 1.8782554864883423
Validation loss: 2.019615093866984

Epoch: 5| Step: 4
Training loss: 2.4496495723724365
Validation loss: 2.023864204684893

Epoch: 5| Step: 5
Training loss: 1.7485930919647217
Validation loss: 2.0228604773680368

Epoch: 5| Step: 6
Training loss: 1.9292665719985962
Validation loss: 2.0228386223316193

Epoch: 5| Step: 7
Training loss: 2.2861833572387695
Validation loss: 2.014678418636322

Epoch: 5| Step: 8
Training loss: 2.0471694469451904
Validation loss: 2.0167289028565087

Epoch: 5| Step: 9
Training loss: 1.7985477447509766
Validation loss: 2.021073376139005

Epoch: 5| Step: 10
Training loss: 1.8085052967071533
Validation loss: 2.0204648474852243

Epoch: 5| Step: 11
Training loss: 2.7044403553009033
Validation loss: 2.030265972018242

Epoch: 140| Step: 0
Training loss: 2.761533260345459
Validation loss: 2.037624498208364

Epoch: 5| Step: 1
Training loss: 1.6576181650161743
Validation loss: 2.0489114175240197

Epoch: 5| Step: 2
Training loss: 1.924665093421936
Validation loss: 2.0444181660811105

Epoch: 5| Step: 3
Training loss: 2.0439839363098145
Validation loss: 2.0576545546452203

Epoch: 5| Step: 4
Training loss: 1.3563363552093506
Validation loss: 2.0435762057701745

Epoch: 5| Step: 5
Training loss: 2.4142937660217285
Validation loss: 2.0534091889858246

Epoch: 5| Step: 6
Training loss: 2.0887296199798584
Validation loss: 2.041233385602633

Epoch: 5| Step: 7
Training loss: 2.0150654315948486
Validation loss: 2.0433627714713416

Epoch: 5| Step: 8
Training loss: 2.2317891120910645
Validation loss: 2.047820915778478

Epoch: 5| Step: 9
Training loss: 2.001950740814209
Validation loss: 2.034332106510798

Epoch: 5| Step: 10
Training loss: 2.568342924118042
Validation loss: 2.020757178465525

Epoch: 5| Step: 11
Training loss: 2.063652753829956
Validation loss: 2.0196984807650247

Epoch: 141| Step: 0
Training loss: 2.0461504459381104
Validation loss: 2.0062167247136435

Epoch: 5| Step: 1
Training loss: 1.873012900352478
Validation loss: 2.019241670767466

Epoch: 5| Step: 2
Training loss: 2.2799792289733887
Validation loss: 2.007603625456492

Epoch: 5| Step: 3
Training loss: 2.086677074432373
Validation loss: 2.0156329870224

Epoch: 5| Step: 4
Training loss: 1.8198215961456299
Validation loss: 2.019342174132665

Epoch: 5| Step: 5
Training loss: 2.112288236618042
Validation loss: 2.0216805885235467

Epoch: 5| Step: 6
Training loss: 2.166513442993164
Validation loss: 2.016475031773249

Epoch: 5| Step: 7
Training loss: 2.196375608444214
Validation loss: 2.0101592739423118

Epoch: 5| Step: 8
Training loss: 1.657402753829956
Validation loss: 2.015164087216059

Epoch: 5| Step: 9
Training loss: 2.383498430252075
Validation loss: 2.013968989253044

Epoch: 5| Step: 10
Training loss: 1.8803333044052124
Validation loss: 2.016906460126241

Epoch: 5| Step: 11
Training loss: 3.241905689239502
Validation loss: 2.017261544863383

Epoch: 142| Step: 0
Training loss: 2.1243362426757812
Validation loss: 2.0246148705482483

Epoch: 5| Step: 1
Training loss: 1.3940417766571045
Validation loss: 2.0254220763842263

Epoch: 5| Step: 2
Training loss: 2.195061683654785
Validation loss: 2.0155869722366333

Epoch: 5| Step: 3
Training loss: 2.098388195037842
Validation loss: 2.0220893969138465

Epoch: 5| Step: 4
Training loss: 1.6470420360565186
Validation loss: 2.017973909775416

Epoch: 5| Step: 5
Training loss: 3.048165798187256
Validation loss: 2.027938957015673

Epoch: 5| Step: 6
Training loss: 2.168388843536377
Validation loss: 2.0180072436730065

Epoch: 5| Step: 7
Training loss: 2.4851698875427246
Validation loss: 2.0149543633063636

Epoch: 5| Step: 8
Training loss: 1.9289451837539673
Validation loss: 2.026290848851204

Epoch: 5| Step: 9
Training loss: 1.7201429605484009
Validation loss: 2.0188272347052894

Epoch: 5| Step: 10
Training loss: 1.89931321144104
Validation loss: 2.017393464843432

Epoch: 5| Step: 11
Training loss: 2.214972496032715
Validation loss: 2.0243050853411355

Epoch: 143| Step: 0
Training loss: 2.5696914196014404
Validation loss: 2.0200769305229187

Epoch: 5| Step: 1
Training loss: 2.578366279602051
Validation loss: 2.0225142389535904

Epoch: 5| Step: 2
Training loss: 1.9056488275527954
Validation loss: 2.014879564444224

Epoch: 5| Step: 3
Training loss: 2.5055794715881348
Validation loss: 2.028841480612755

Epoch: 5| Step: 4
Training loss: 1.9695425033569336
Validation loss: 2.024174173672994

Epoch: 5| Step: 5
Training loss: 2.006885528564453
Validation loss: 2.0305028557777405

Epoch: 5| Step: 6
Training loss: 1.408557415008545
Validation loss: 2.0271634558836618

Epoch: 5| Step: 7
Training loss: 2.0465962886810303
Validation loss: 2.0168440441290536

Epoch: 5| Step: 8
Training loss: 1.8750978708267212
Validation loss: 2.035414387782415

Epoch: 5| Step: 9
Training loss: 2.3727498054504395
Validation loss: 2.0301068127155304

Epoch: 5| Step: 10
Training loss: 1.5333608388900757
Validation loss: 2.037976304690043

Epoch: 5| Step: 11
Training loss: 1.9006484746932983
Validation loss: 2.050769110520681

Epoch: 144| Step: 0
Training loss: 2.452613353729248
Validation loss: 2.043383404612541

Epoch: 5| Step: 1
Training loss: 1.8443777561187744
Validation loss: 2.03434257209301

Epoch: 5| Step: 2
Training loss: 2.4443845748901367
Validation loss: 2.039370665947596

Epoch: 5| Step: 3
Training loss: 2.076875686645508
Validation loss: 2.0313449601332345

Epoch: 5| Step: 4
Training loss: 2.0934665203094482
Validation loss: 2.046484405795733

Epoch: 5| Step: 5
Training loss: 1.532596468925476
Validation loss: 2.031895716985067

Epoch: 5| Step: 6
Training loss: 1.406402826309204
Validation loss: 2.0270339846611023

Epoch: 5| Step: 7
Training loss: 1.600980520248413
Validation loss: 2.025113398830096

Epoch: 5| Step: 8
Training loss: 2.102785110473633
Validation loss: 2.0214712570110955

Epoch: 5| Step: 9
Training loss: 2.4664759635925293
Validation loss: 2.023509239157041

Epoch: 5| Step: 10
Training loss: 2.5387039184570312
Validation loss: 2.0319536129633584

Epoch: 5| Step: 11
Training loss: 2.117305278778076
Validation loss: 2.024253636598587

Epoch: 145| Step: 0
Training loss: 2.3184614181518555
Validation loss: 2.02098315457503

Epoch: 5| Step: 1
Training loss: 2.085442543029785
Validation loss: 2.0213490774234137

Epoch: 5| Step: 2
Training loss: 1.7614549398422241
Validation loss: 2.029196466008822

Epoch: 5| Step: 3
Training loss: 1.9980859756469727
Validation loss: 2.0220727870861688

Epoch: 5| Step: 4
Training loss: 1.7820987701416016
Validation loss: 2.019479518135389

Epoch: 5| Step: 5
Training loss: 2.0526108741760254
Validation loss: 2.023652916153272

Epoch: 5| Step: 6
Training loss: 2.1407535076141357
Validation loss: 2.0141809235016503

Epoch: 5| Step: 7
Training loss: 2.168071985244751
Validation loss: 2.024668609102567

Epoch: 5| Step: 8
Training loss: 2.1099331378936768
Validation loss: 2.0290287832419076

Epoch: 5| Step: 9
Training loss: 1.967205286026001
Validation loss: 2.019951025644938

Epoch: 5| Step: 10
Training loss: 2.1557750701904297
Validation loss: 2.018138602375984

Epoch: 5| Step: 11
Training loss: 1.7765352725982666
Validation loss: 2.0298771212498345

Epoch: 146| Step: 0
Training loss: 1.8145322799682617
Validation loss: 2.0258889446655908

Epoch: 5| Step: 1
Training loss: 1.8134914636611938
Validation loss: 2.037944739063581

Epoch: 5| Step: 2
Training loss: 2.2894387245178223
Validation loss: 2.0497787992159524

Epoch: 5| Step: 3
Training loss: 2.1789169311523438
Validation loss: 2.0372968365748725

Epoch: 5| Step: 4
Training loss: 2.620953321456909
Validation loss: 2.046437054872513

Epoch: 5| Step: 5
Training loss: 1.9569936990737915
Validation loss: 2.030104140440623

Epoch: 5| Step: 6
Training loss: 1.709313988685608
Validation loss: 2.0126361598571143

Epoch: 5| Step: 7
Training loss: 1.8815784454345703
Validation loss: 2.0268551210562387

Epoch: 5| Step: 8
Training loss: 2.0129427909851074
Validation loss: 2.0337918450435004

Epoch: 5| Step: 9
Training loss: 2.2446093559265137
Validation loss: 2.026412228743235

Epoch: 5| Step: 10
Training loss: 2.2829155921936035
Validation loss: 2.035966152946154

Epoch: 5| Step: 11
Training loss: 1.7331644296646118
Validation loss: 2.0334408978621163

Epoch: 147| Step: 0
Training loss: 1.7045485973358154
Validation loss: 2.0413294285535812

Epoch: 5| Step: 1
Training loss: 2.1892127990722656
Validation loss: 2.034248247742653

Epoch: 5| Step: 2
Training loss: 1.8188514709472656
Validation loss: 2.0478629618883133

Epoch: 5| Step: 3
Training loss: 2.1513009071350098
Validation loss: 2.0550096382697425

Epoch: 5| Step: 4
Training loss: 2.436042308807373
Validation loss: 2.045853619774183

Epoch: 5| Step: 5
Training loss: 2.435641050338745
Validation loss: 2.043675517042478

Epoch: 5| Step: 6
Training loss: 2.358222484588623
Validation loss: 2.038108463088671

Epoch: 5| Step: 7
Training loss: 2.3289337158203125
Validation loss: 2.034649913509687

Epoch: 5| Step: 8
Training loss: 1.4347459077835083
Validation loss: 2.0301213562488556

Epoch: 5| Step: 9
Training loss: 1.914935827255249
Validation loss: 2.023356040318807

Epoch: 5| Step: 10
Training loss: 2.127190351486206
Validation loss: 2.0186622738838196

Epoch: 5| Step: 11
Training loss: 1.3486806154251099
Validation loss: 2.0201765100161233

Epoch: 148| Step: 0
Training loss: 1.82696533203125
Validation loss: 2.015089521805445

Epoch: 5| Step: 1
Training loss: 1.746236801147461
Validation loss: 2.0225515415271125

Epoch: 5| Step: 2
Training loss: 2.147939682006836
Validation loss: 2.023820141951243

Epoch: 5| Step: 3
Training loss: 2.0629348754882812
Validation loss: 2.018441657225291

Epoch: 5| Step: 4
Training loss: 2.138012647628784
Validation loss: 2.021256849169731

Epoch: 5| Step: 5
Training loss: 2.062598466873169
Validation loss: 2.034103214740753

Epoch: 5| Step: 6
Training loss: 2.164916515350342
Validation loss: 2.0302112102508545

Epoch: 5| Step: 7
Training loss: 1.8047335147857666
Validation loss: 2.0319780757029853

Epoch: 5| Step: 8
Training loss: 1.6997005939483643
Validation loss: 2.020845135052999

Epoch: 5| Step: 9
Training loss: 2.3043532371520996
Validation loss: 2.021965578198433

Epoch: 5| Step: 10
Training loss: 2.360873222351074
Validation loss: 2.0327885945638022

Epoch: 5| Step: 11
Training loss: 2.9642224311828613
Validation loss: 2.0272779762744904

Epoch: 149| Step: 0
Training loss: 1.901929497718811
Validation loss: 2.0240599662065506

Epoch: 5| Step: 1
Training loss: 2.0826525688171387
Validation loss: 2.0286880930264792

Epoch: 5| Step: 2
Training loss: 1.6287355422973633
Validation loss: 2.020969366033872

Epoch: 5| Step: 3
Training loss: 2.3204050064086914
Validation loss: 2.0248798529307046

Epoch: 5| Step: 4
Training loss: 1.8583743572235107
Validation loss: 2.036606897910436

Epoch: 5| Step: 5
Training loss: 1.9703506231307983
Validation loss: 2.038131902615229

Epoch: 5| Step: 6
Training loss: 2.043071746826172
Validation loss: 2.039319396018982

Epoch: 5| Step: 7
Training loss: 1.9298045635223389
Validation loss: 2.040309692422549

Epoch: 5| Step: 8
Training loss: 2.4046308994293213
Validation loss: 2.041716272632281

Epoch: 5| Step: 9
Training loss: 2.3786091804504395
Validation loss: 2.0332830796639123

Epoch: 5| Step: 10
Training loss: 1.6714179515838623
Validation loss: 2.0345162451267242

Epoch: 5| Step: 11
Training loss: 3.1924691200256348
Validation loss: 2.0316727310419083

Epoch: 150| Step: 0
Training loss: 2.12217378616333
Validation loss: 2.021199251214663

Epoch: 5| Step: 1
Training loss: 1.4944432973861694
Validation loss: 2.0285620788733163

Epoch: 5| Step: 2
Training loss: 1.9554059505462646
Validation loss: 2.029399052262306

Epoch: 5| Step: 3
Training loss: 2.0625033378601074
Validation loss: 2.027062773704529

Epoch: 5| Step: 4
Training loss: 2.6465506553649902
Validation loss: 2.03005779782931

Epoch: 5| Step: 5
Training loss: 1.8749077320098877
Validation loss: 2.0244253973166146

Epoch: 5| Step: 6
Training loss: 1.9851396083831787
Validation loss: 2.027025173107783

Epoch: 5| Step: 7
Training loss: 1.743910789489746
Validation loss: 2.023660202821096

Epoch: 5| Step: 8
Training loss: 2.012352466583252
Validation loss: 2.017194559176763

Epoch: 5| Step: 9
Training loss: 2.378232717514038
Validation loss: 2.0151981761058173

Epoch: 5| Step: 10
Training loss: 2.1480867862701416
Validation loss: 2.018762876590093

Epoch: 5| Step: 11
Training loss: 2.628488540649414
Validation loss: 2.0279510567585626

Epoch: 151| Step: 0
Training loss: 1.929595947265625
Validation loss: 2.0239869157473245

Epoch: 5| Step: 1
Training loss: 2.345332622528076
Validation loss: 2.024873356024424

Epoch: 5| Step: 2
Training loss: 1.7953048944473267
Validation loss: 2.020065118869146

Epoch: 5| Step: 3
Training loss: 1.8366540670394897
Validation loss: 2.033266772826513

Epoch: 5| Step: 4
Training loss: 2.323983669281006
Validation loss: 2.036162922779719

Epoch: 5| Step: 5
Training loss: 2.365438461303711
Validation loss: 2.051176036397616

Epoch: 5| Step: 6
Training loss: 1.6993049383163452
Validation loss: 2.0417836606502533

Epoch: 5| Step: 7
Training loss: 2.3324365615844727
Validation loss: 2.0552881558736167

Epoch: 5| Step: 8
Training loss: 1.731679916381836
Validation loss: 2.03843691945076

Epoch: 5| Step: 9
Training loss: 2.0801122188568115
Validation loss: 2.0337685694297156

Epoch: 5| Step: 10
Training loss: 1.9480575323104858
Validation loss: 2.047652622063955

Epoch: 5| Step: 11
Training loss: 2.8767662048339844
Validation loss: 2.0354232837756476

Epoch: 152| Step: 0
Training loss: 1.9433543682098389
Validation loss: 2.0361716200908027

Epoch: 5| Step: 1
Training loss: 2.496211290359497
Validation loss: 2.0376507937908173

Epoch: 5| Step: 2
Training loss: 2.2855517864227295
Validation loss: 2.0385030259688697

Epoch: 5| Step: 3
Training loss: 2.0492260456085205
Validation loss: 2.0276704281568527

Epoch: 5| Step: 4
Training loss: 1.585413932800293
Validation loss: 2.0296654254198074

Epoch: 5| Step: 5
Training loss: 1.8692762851715088
Validation loss: 2.035327578584353

Epoch: 5| Step: 6
Training loss: 2.7510857582092285
Validation loss: 2.0256030211846032

Epoch: 5| Step: 7
Training loss: 1.7895294427871704
Validation loss: 2.0257043689489365

Epoch: 5| Step: 8
Training loss: 1.9905996322631836
Validation loss: 2.0305984715620675

Epoch: 5| Step: 9
Training loss: 1.6052944660186768
Validation loss: 2.0289559861024222

Epoch: 5| Step: 10
Training loss: 2.3539185523986816
Validation loss: 2.0174280057350793

Epoch: 5| Step: 11
Training loss: 2.734262466430664
Validation loss: 2.024906873703003

Epoch: 153| Step: 0
Training loss: 1.833808183670044
Validation loss: 2.0162692119677863

Epoch: 5| Step: 1
Training loss: 2.224181652069092
Validation loss: 2.0229739050070443

Epoch: 5| Step: 2
Training loss: 2.260793685913086
Validation loss: 2.0163777222236

Epoch: 5| Step: 3
Training loss: 1.7888065576553345
Validation loss: 2.0220983872811

Epoch: 5| Step: 4
Training loss: 2.4893572330474854
Validation loss: 2.0323528548081717

Epoch: 5| Step: 5
Training loss: 2.0698156356811523
Validation loss: 2.040784319241842

Epoch: 5| Step: 6
Training loss: 1.8310668468475342
Validation loss: 2.029566983381907

Epoch: 5| Step: 7
Training loss: 2.5404300689697266
Validation loss: 2.0312211563189826

Epoch: 5| Step: 8
Training loss: 2.050865888595581
Validation loss: 2.0395464499791465

Epoch: 5| Step: 9
Training loss: 1.449479103088379
Validation loss: 2.0297980904579163

Epoch: 5| Step: 10
Training loss: 2.0234100818634033
Validation loss: 2.017648314436277

Epoch: 5| Step: 11
Training loss: 1.429089903831482
Validation loss: 2.032186985015869

Epoch: 154| Step: 0
Training loss: 2.1012516021728516
Validation loss: 2.0279363294442496

Epoch: 5| Step: 1
Training loss: 2.047996997833252
Validation loss: 2.0361191034317017

Epoch: 5| Step: 2
Training loss: 2.21455717086792
Validation loss: 2.0401780704657235

Epoch: 5| Step: 3
Training loss: 1.7072150707244873
Validation loss: 2.0452265540758767

Epoch: 5| Step: 4
Training loss: 2.198169708251953
Validation loss: 2.028988594810168

Epoch: 5| Step: 5
Training loss: 2.147597074508667
Validation loss: 2.0245898365974426

Epoch: 5| Step: 6
Training loss: 2.0466582775115967
Validation loss: 2.026700163880984

Epoch: 5| Step: 7
Training loss: 1.6868031024932861
Validation loss: 2.032194639245669

Epoch: 5| Step: 8
Training loss: 2.4533090591430664
Validation loss: 2.0287497540314994

Epoch: 5| Step: 9
Training loss: 2.1855037212371826
Validation loss: 2.0339599351088204

Epoch: 5| Step: 10
Training loss: 1.6061773300170898
Validation loss: 2.0309553146362305

Epoch: 5| Step: 11
Training loss: 2.1521048545837402
Validation loss: 2.0318793753782907

Epoch: 155| Step: 0
Training loss: 2.4393839836120605
Validation loss: 2.038549989461899

Epoch: 5| Step: 1
Training loss: 2.014683246612549
Validation loss: 2.0276233156522117

Epoch: 5| Step: 2
Training loss: 2.123941421508789
Validation loss: 2.0382176538308463

Epoch: 5| Step: 3
Training loss: 1.8552436828613281
Validation loss: 2.035818432768186

Epoch: 5| Step: 4
Training loss: 1.9912914037704468
Validation loss: 2.0437842905521393

Epoch: 5| Step: 5
Training loss: 2.456028699874878
Validation loss: 2.036135589083036

Epoch: 5| Step: 6
Training loss: 2.1332221031188965
Validation loss: 2.0371271669864655

Epoch: 5| Step: 7
Training loss: 1.878726601600647
Validation loss: 2.0355369548002877

Epoch: 5| Step: 8
Training loss: 2.1415390968322754
Validation loss: 2.035128931204478

Epoch: 5| Step: 9
Training loss: 1.7420828342437744
Validation loss: 2.0355230818192163

Epoch: 5| Step: 10
Training loss: 1.719225525856018
Validation loss: 2.0443508376677832

Epoch: 5| Step: 11
Training loss: 1.605483889579773
Validation loss: 2.032787412405014

Epoch: 156| Step: 0
Training loss: 1.9646482467651367
Validation loss: 2.036075403292974

Epoch: 5| Step: 1
Training loss: 1.8752648830413818
Validation loss: 2.055106818675995

Epoch: 5| Step: 2
Training loss: 1.864964246749878
Validation loss: 2.050424108902613

Epoch: 5| Step: 3
Training loss: 2.2736551761627197
Validation loss: 2.045349672436714

Epoch: 5| Step: 4
Training loss: 2.0459706783294678
Validation loss: 2.0514649947484336

Epoch: 5| Step: 5
Training loss: 2.0128400325775146
Validation loss: 2.059134930372238

Epoch: 5| Step: 6
Training loss: 2.1437137126922607
Validation loss: 2.06280010441939

Epoch: 5| Step: 7
Training loss: 1.77992844581604
Validation loss: 2.079983711242676

Epoch: 5| Step: 8
Training loss: 2.227877616882324
Validation loss: 2.0883623460928598

Epoch: 5| Step: 9
Training loss: 2.1755805015563965
Validation loss: 2.089544509847959

Epoch: 5| Step: 10
Training loss: 2.2461183071136475
Validation loss: 2.0930337011814117

Epoch: 5| Step: 11
Training loss: 1.411655306816101
Validation loss: 2.0689258774121604

Epoch: 157| Step: 0
Training loss: 2.3577075004577637
Validation loss: 2.049664984146754

Epoch: 5| Step: 1
Training loss: 1.52207350730896
Validation loss: 2.0591483463843665

Epoch: 5| Step: 2
Training loss: 2.156783103942871
Validation loss: 2.05082576473554

Epoch: 5| Step: 3
Training loss: 2.0309948921203613
Validation loss: 2.052604784568151

Epoch: 5| Step: 4
Training loss: 2.179001808166504
Validation loss: 2.048177182674408

Epoch: 5| Step: 5
Training loss: 2.500006914138794
Validation loss: 2.0428320417801538

Epoch: 5| Step: 6
Training loss: 1.6288906335830688
Validation loss: 2.0429431349039078

Epoch: 5| Step: 7
Training loss: 1.6250606775283813
Validation loss: 2.048353001475334

Epoch: 5| Step: 8
Training loss: 1.819915533065796
Validation loss: 2.058758646249771

Epoch: 5| Step: 9
Training loss: 2.104279041290283
Validation loss: 2.0560369888941445

Epoch: 5| Step: 10
Training loss: 2.6147618293762207
Validation loss: 2.059500058492025

Epoch: 5| Step: 11
Training loss: 1.1126925945281982
Validation loss: 2.057486812273661

Epoch: 158| Step: 0
Training loss: 1.7932220697402954
Validation loss: 2.05856487651666

Epoch: 5| Step: 1
Training loss: 1.872566819190979
Validation loss: 2.057756612698237

Epoch: 5| Step: 2
Training loss: 2.787473201751709
Validation loss: 2.0626364399989447

Epoch: 5| Step: 3
Training loss: 2.0318002700805664
Validation loss: 2.061751142144203

Epoch: 5| Step: 4
Training loss: 1.6321464776992798
Validation loss: 2.056192343433698

Epoch: 5| Step: 5
Training loss: 1.8121845722198486
Validation loss: 2.052489091952642

Epoch: 5| Step: 6
Training loss: 2.573685884475708
Validation loss: 2.0590969920158386

Epoch: 5| Step: 7
Training loss: 2.0752172470092773
Validation loss: 2.064103643099467

Epoch: 5| Step: 8
Training loss: 1.8106229305267334
Validation loss: 2.069079374273618

Epoch: 5| Step: 9
Training loss: 1.717430830001831
Validation loss: 2.067455823222796

Epoch: 5| Step: 10
Training loss: 1.9551541805267334
Validation loss: 2.0823081185420356

Epoch: 5| Step: 11
Training loss: 3.1528143882751465
Validation loss: 2.0633897185325623

Epoch: 159| Step: 0
Training loss: 2.1412694454193115
Validation loss: 2.0798313270012536

Epoch: 5| Step: 1
Training loss: 2.349013566970825
Validation loss: 2.075867682695389

Epoch: 5| Step: 2
Training loss: 1.8354480266571045
Validation loss: 2.0783115128676095

Epoch: 5| Step: 3
Training loss: 1.9047552347183228
Validation loss: 2.0797859082619348

Epoch: 5| Step: 4
Training loss: 2.056645631790161
Validation loss: 2.074352353811264

Epoch: 5| Step: 5
Training loss: 2.254141092300415
Validation loss: 2.0651265730460486

Epoch: 5| Step: 6
Training loss: 2.478147029876709
Validation loss: 2.0720414320627847

Epoch: 5| Step: 7
Training loss: 2.2762041091918945
Validation loss: 2.0601598223050437

Epoch: 5| Step: 8
Training loss: 1.7994235754013062
Validation loss: 2.067160258690516

Epoch: 5| Step: 9
Training loss: 2.0244898796081543
Validation loss: 2.0559067825476327

Epoch: 5| Step: 10
Training loss: 1.4597234725952148
Validation loss: 2.051503295699755

Epoch: 5| Step: 11
Training loss: 1.1798959970474243
Validation loss: 2.04373229543368

Epoch: 160| Step: 0
Training loss: 1.6169281005859375
Validation loss: 2.0388309756914773

Epoch: 5| Step: 1
Training loss: 1.7913738489151
Validation loss: 2.048211619257927

Epoch: 5| Step: 2
Training loss: 2.03039288520813
Validation loss: 2.03608172138532

Epoch: 5| Step: 3
Training loss: 1.915580153465271
Validation loss: 2.031032681465149

Epoch: 5| Step: 4
Training loss: 2.4550907611846924
Validation loss: 2.0426438599824905

Epoch: 5| Step: 5
Training loss: 2.0680997371673584
Validation loss: 2.046398416161537

Epoch: 5| Step: 6
Training loss: 1.897850751876831
Validation loss: 2.04788143436114

Epoch: 5| Step: 7
Training loss: 3.0034234523773193
Validation loss: 2.028202364842097

Epoch: 5| Step: 8
Training loss: 2.0126218795776367
Validation loss: 2.03310094277064

Epoch: 5| Step: 9
Training loss: 2.099872350692749
Validation loss: 2.0356411238511405

Epoch: 5| Step: 10
Training loss: 1.770843505859375
Validation loss: 2.0396751811107

Epoch: 5| Step: 11
Training loss: 0.8434968590736389
Validation loss: 2.0439143627882004

Epoch: 161| Step: 0
Training loss: 2.6875834465026855
Validation loss: 2.0350707471370697

Epoch: 5| Step: 1
Training loss: 1.6149466037750244
Validation loss: 2.032948598265648

Epoch: 5| Step: 2
Training loss: 1.9950573444366455
Validation loss: 2.0248072197039924

Epoch: 5| Step: 3
Training loss: 2.0882551670074463
Validation loss: 2.0322501808404922

Epoch: 5| Step: 4
Training loss: 1.7457784414291382
Validation loss: 2.0346719622612

Epoch: 5| Step: 5
Training loss: 1.6689996719360352
Validation loss: 2.0387547065814338

Epoch: 5| Step: 6
Training loss: 2.176815986633301
Validation loss: 2.0369346191485724

Epoch: 5| Step: 7
Training loss: 2.4733805656433105
Validation loss: 2.0365440249443054

Epoch: 5| Step: 8
Training loss: 2.1196553707122803
Validation loss: 2.036767785747846

Epoch: 5| Step: 9
Training loss: 1.865255355834961
Validation loss: 2.0326787581046424

Epoch: 5| Step: 10
Training loss: 2.107062816619873
Validation loss: 2.0352065662542977

Epoch: 5| Step: 11
Training loss: 1.4996368885040283
Validation loss: 2.0277981758117676

Epoch: 162| Step: 0
Training loss: 2.335108995437622
Validation loss: 2.051075259844462

Epoch: 5| Step: 1
Training loss: 2.2165558338165283
Validation loss: 2.053833474715551

Epoch: 5| Step: 2
Training loss: 2.272536516189575
Validation loss: 2.051074360807737

Epoch: 5| Step: 3
Training loss: 1.96625554561615
Validation loss: 2.0490883737802505

Epoch: 5| Step: 4
Training loss: 1.494771957397461
Validation loss: 2.0418574015299478

Epoch: 5| Step: 5
Training loss: 2.4800961017608643
Validation loss: 2.0599851608276367

Epoch: 5| Step: 6
Training loss: 2.009737491607666
Validation loss: 2.0445698698361716

Epoch: 5| Step: 7
Training loss: 1.9125198125839233
Validation loss: 2.0493395775556564

Epoch: 5| Step: 8
Training loss: 1.550377607345581
Validation loss: 2.0525673429171243

Epoch: 5| Step: 9
Training loss: 1.5899633169174194
Validation loss: 2.062995274861654

Epoch: 5| Step: 10
Training loss: 2.382267951965332
Validation loss: 2.0421753575404487

Epoch: 5| Step: 11
Training loss: 2.032409906387329
Validation loss: 2.0530673613150916

Epoch: 163| Step: 0
Training loss: 1.6256881952285767
Validation loss: 2.0471702963113785

Epoch: 5| Step: 1
Training loss: 2.2963829040527344
Validation loss: 2.0515622595945993

Epoch: 5| Step: 2
Training loss: 2.139925003051758
Validation loss: 2.047791009147962

Epoch: 5| Step: 3
Training loss: 1.7289615869522095
Validation loss: 2.053142324090004

Epoch: 5| Step: 4
Training loss: 1.7065057754516602
Validation loss: 2.046208754181862

Epoch: 5| Step: 5
Training loss: 1.7919604778289795
Validation loss: 2.0522438883781433

Epoch: 5| Step: 6
Training loss: 1.491092324256897
Validation loss: 2.0495870858430862

Epoch: 5| Step: 7
Training loss: 2.2283787727355957
Validation loss: 2.0582788040240607

Epoch: 5| Step: 8
Training loss: 2.021850824356079
Validation loss: 2.0660533805688224

Epoch: 5| Step: 9
Training loss: 2.9082882404327393
Validation loss: 2.0629959354797998

Epoch: 5| Step: 10
Training loss: 2.406038761138916
Validation loss: 2.073213199774424

Epoch: 5| Step: 11
Training loss: 1.467745065689087
Validation loss: 2.08126492301623

Epoch: 164| Step: 0
Training loss: 1.7975482940673828
Validation loss: 2.082735682527224

Epoch: 5| Step: 1
Training loss: 2.5416042804718018
Validation loss: 2.09203232328097

Epoch: 5| Step: 2
Training loss: 1.6225109100341797
Validation loss: 2.076062113046646

Epoch: 5| Step: 3
Training loss: 2.339066982269287
Validation loss: 2.0813264747460685

Epoch: 5| Step: 4
Training loss: 2.106055974960327
Validation loss: 2.0705127318700156

Epoch: 5| Step: 5
Training loss: 2.0941271781921387
Validation loss: 2.059462775786718

Epoch: 5| Step: 6
Training loss: 2.326451539993286
Validation loss: 2.042961989839872

Epoch: 5| Step: 7
Training loss: 1.2316522598266602
Validation loss: 2.052591472864151

Epoch: 5| Step: 8
Training loss: 1.9930801391601562
Validation loss: 2.0473222583532333

Epoch: 5| Step: 9
Training loss: 2.239992618560791
Validation loss: 2.0626571824153266

Epoch: 5| Step: 10
Training loss: 2.21665620803833
Validation loss: 2.0685892403125763

Epoch: 5| Step: 11
Training loss: 1.013006329536438
Validation loss: 2.0604280680418015

Epoch: 165| Step: 0
Training loss: 2.1555449962615967
Validation loss: 2.081725776195526

Epoch: 5| Step: 1
Training loss: 2.354728937149048
Validation loss: 2.0697327057520547

Epoch: 5| Step: 2
Training loss: 1.9084259271621704
Validation loss: 2.072758227586746

Epoch: 5| Step: 3
Training loss: 1.8813072443008423
Validation loss: 2.071397602558136

Epoch: 5| Step: 4
Training loss: 2.592099189758301
Validation loss: 2.0570689787467322

Epoch: 5| Step: 5
Training loss: 2.2122719287872314
Validation loss: 2.0620583643515906

Epoch: 5| Step: 6
Training loss: 1.9393208026885986
Validation loss: 2.0468187828858695

Epoch: 5| Step: 7
Training loss: 2.0162601470947266
Validation loss: 2.026023730635643

Epoch: 5| Step: 8
Training loss: 1.6082630157470703
Validation loss: 2.04207115372022

Epoch: 5| Step: 9
Training loss: 1.4243100881576538
Validation loss: 2.037420555949211

Epoch: 5| Step: 10
Training loss: 2.244091510772705
Validation loss: 2.026714180906614

Epoch: 5| Step: 11
Training loss: 2.6726746559143066
Validation loss: 2.0304081539312997

Epoch: 166| Step: 0
Training loss: 2.1865382194519043
Validation loss: 2.0482499500115714

Epoch: 5| Step: 1
Training loss: 1.7109849452972412
Validation loss: 2.0345286279916763

Epoch: 5| Step: 2
Training loss: 1.8858896493911743
Validation loss: 2.0510857005914054

Epoch: 5| Step: 3
Training loss: 1.5826963186264038
Validation loss: 2.0420289784669876

Epoch: 5| Step: 4
Training loss: 1.8341598510742188
Validation loss: 2.0517920752366385

Epoch: 5| Step: 5
Training loss: 1.7898290157318115
Validation loss: 2.0469615707794824

Epoch: 5| Step: 6
Training loss: 2.368767738342285
Validation loss: 2.08036307990551

Epoch: 5| Step: 7
Training loss: 2.044893980026245
Validation loss: 2.07256126900514

Epoch: 5| Step: 8
Training loss: 2.203139543533325
Validation loss: 2.0641733606656394

Epoch: 5| Step: 9
Training loss: 2.1441781520843506
Validation loss: 2.06253748635451

Epoch: 5| Step: 10
Training loss: 2.175133466720581
Validation loss: 2.059929981827736

Epoch: 5| Step: 11
Training loss: 2.7874350547790527
Validation loss: 2.060748482743899

Epoch: 167| Step: 0
Training loss: 2.0190367698669434
Validation loss: 2.056331147750219

Epoch: 5| Step: 1
Training loss: 1.7974942922592163
Validation loss: 2.0581550697485604

Epoch: 5| Step: 2
Training loss: 1.8551292419433594
Validation loss: 2.0423642794291177

Epoch: 5| Step: 3
Training loss: 1.6647535562515259
Validation loss: 2.047618955373764

Epoch: 5| Step: 4
Training loss: 1.746514081954956
Validation loss: 2.045545846223831

Epoch: 5| Step: 5
Training loss: 1.82672119140625
Validation loss: 2.045719708005587

Epoch: 5| Step: 6
Training loss: 2.643047571182251
Validation loss: 2.0457080652316413

Epoch: 5| Step: 7
Training loss: 1.5856373310089111
Validation loss: 2.048243169983228

Epoch: 5| Step: 8
Training loss: 2.621509075164795
Validation loss: 2.0471722880999246

Epoch: 5| Step: 9
Training loss: 2.642394542694092
Validation loss: 2.0481862276792526

Epoch: 5| Step: 10
Training loss: 1.9239022731781006
Validation loss: 2.0600613902012506

Epoch: 5| Step: 11
Training loss: 3.0547943115234375
Validation loss: 2.0644205460945764

Epoch: 168| Step: 0
Training loss: 2.0958735942840576
Validation loss: 2.0663371682167053

Epoch: 5| Step: 1
Training loss: 1.7963926792144775
Validation loss: 2.0638443926970163

Epoch: 5| Step: 2
Training loss: 1.879176378250122
Validation loss: 2.064027567704519

Epoch: 5| Step: 3
Training loss: 2.0748682022094727
Validation loss: 2.0561158110698066

Epoch: 5| Step: 4
Training loss: 2.271327018737793
Validation loss: 2.0601824671030045

Epoch: 5| Step: 5
Training loss: 1.659912109375
Validation loss: 2.052151416738828

Epoch: 5| Step: 6
Training loss: 1.7350342273712158
Validation loss: 2.059359903136889

Epoch: 5| Step: 7
Training loss: 2.1283822059631348
Validation loss: 2.058424174785614

Epoch: 5| Step: 8
Training loss: 2.164008140563965
Validation loss: 2.0512591302394867

Epoch: 5| Step: 9
Training loss: 2.0452942848205566
Validation loss: 2.0487502763668695

Epoch: 5| Step: 10
Training loss: 1.976200819015503
Validation loss: 2.060214951634407

Epoch: 5| Step: 11
Training loss: 2.732295513153076
Validation loss: 2.0530704706907272

Epoch: 169| Step: 0
Training loss: 2.7017643451690674
Validation loss: 2.0606013188759484

Epoch: 5| Step: 1
Training loss: 1.611528992652893
Validation loss: 2.047313208381335

Epoch: 5| Step: 2
Training loss: 2.227968692779541
Validation loss: 2.0404139012098312

Epoch: 5| Step: 3
Training loss: 2.17036771774292
Validation loss: 2.024649595220884

Epoch: 5| Step: 4
Training loss: 2.0494160652160645
Validation loss: 2.0267949352661767

Epoch: 5| Step: 5
Training loss: 1.9111099243164062
Validation loss: 2.0242372999588647

Epoch: 5| Step: 6
Training loss: 2.191185712814331
Validation loss: 2.018477479616801

Epoch: 5| Step: 7
Training loss: 2.162426471710205
Validation loss: 2.0222518096367517

Epoch: 5| Step: 8
Training loss: 1.9529082775115967
Validation loss: 2.033491626381874

Epoch: 5| Step: 9
Training loss: 1.7108157873153687
Validation loss: 2.020447184642156

Epoch: 5| Step: 10
Training loss: 2.082205295562744
Validation loss: 2.035723845163981

Epoch: 5| Step: 11
Training loss: 0.6356154680252075
Validation loss: 2.0285091201464334

Epoch: 170| Step: 0
Training loss: 1.7859532833099365
Validation loss: 2.0221676925818124

Epoch: 5| Step: 1
Training loss: 2.0019333362579346
Validation loss: 2.0260944267114005

Epoch: 5| Step: 2
Training loss: 2.6546993255615234
Validation loss: 2.0256534119447074

Epoch: 5| Step: 3
Training loss: 1.9233884811401367
Validation loss: 2.0255702237288156

Epoch: 5| Step: 4
Training loss: 2.2363271713256836
Validation loss: 2.0261630713939667

Epoch: 5| Step: 5
Training loss: 2.150214910507202
Validation loss: 2.032334566116333

Epoch: 5| Step: 6
Training loss: 2.286032199859619
Validation loss: 2.042438507080078

Epoch: 5| Step: 7
Training loss: 1.9549840688705444
Validation loss: 2.037114222844442

Epoch: 5| Step: 8
Training loss: 1.9965225458145142
Validation loss: 2.0368008514245353

Epoch: 5| Step: 9
Training loss: 1.8120523691177368
Validation loss: 2.0459805031617484

Epoch: 5| Step: 10
Training loss: 1.7005536556243896
Validation loss: 2.0413916955391564

Epoch: 5| Step: 11
Training loss: 1.746263861656189
Validation loss: 2.0534391701221466

Epoch: 171| Step: 0
Training loss: 2.4636425971984863
Validation loss: 2.0528782109419503

Epoch: 5| Step: 1
Training loss: 2.0668423175811768
Validation loss: 2.0499171167612076

Epoch: 5| Step: 2
Training loss: 1.6428115367889404
Validation loss: 2.0529403537511826

Epoch: 5| Step: 3
Training loss: 1.9467939138412476
Validation loss: 2.0688282599051795

Epoch: 5| Step: 4
Training loss: 2.258119821548462
Validation loss: 2.0677639991045

Epoch: 5| Step: 5
Training loss: 1.9261102676391602
Validation loss: 2.05206897854805

Epoch: 5| Step: 6
Training loss: 1.993766188621521
Validation loss: 2.0418665607770285

Epoch: 5| Step: 7
Training loss: 1.9810888767242432
Validation loss: 2.04437617957592

Epoch: 5| Step: 8
Training loss: 2.5473787784576416
Validation loss: 2.04269407192866

Epoch: 5| Step: 9
Training loss: 1.9593292474746704
Validation loss: 2.05317755540212

Epoch: 5| Step: 10
Training loss: 1.899757742881775
Validation loss: 2.039510021607081

Epoch: 5| Step: 11
Training loss: 0.25351738929748535
Validation loss: 2.049319972594579

Epoch: 172| Step: 0
Training loss: 1.6482740640640259
Validation loss: 2.052151322364807

Epoch: 5| Step: 1
Training loss: 1.5657325983047485
Validation loss: 2.0478773713111877

Epoch: 5| Step: 2
Training loss: 1.6892048120498657
Validation loss: 2.0546367168426514

Epoch: 5| Step: 3
Training loss: 2.26957631111145
Validation loss: 2.0550725062688193

Epoch: 5| Step: 4
Training loss: 2.3552796840667725
Validation loss: 2.048051272829374

Epoch: 5| Step: 5
Training loss: 2.0850000381469727
Validation loss: 2.0580268452564874

Epoch: 5| Step: 6
Training loss: 2.4359073638916016
Validation loss: 2.0639055222272873

Epoch: 5| Step: 7
Training loss: 1.7514686584472656
Validation loss: 2.0651330898205438

Epoch: 5| Step: 8
Training loss: 1.880958914756775
Validation loss: 2.0751207172870636

Epoch: 5| Step: 9
Training loss: 1.9285131692886353
Validation loss: 2.0655005127191544

Epoch: 5| Step: 10
Training loss: 2.3019461631774902
Validation loss: 2.0711295505364737

Epoch: 5| Step: 11
Training loss: 2.9202117919921875
Validation loss: 2.0578317642211914

Epoch: 173| Step: 0
Training loss: 2.2463676929473877
Validation loss: 2.0429955224196115

Epoch: 5| Step: 1
Training loss: 2.353259325027466
Validation loss: 2.0428648541371026

Epoch: 5| Step: 2
Training loss: 2.091470956802368
Validation loss: 2.0454218089580536

Epoch: 5| Step: 3
Training loss: 1.7962074279785156
Validation loss: 2.042855739593506

Epoch: 5| Step: 4
Training loss: 1.822869896888733
Validation loss: 2.0477741410334906

Epoch: 5| Step: 5
Training loss: 2.192732572555542
Validation loss: 2.039831886688868

Epoch: 5| Step: 6
Training loss: 1.9116512537002563
Validation loss: 2.0581062883138657

Epoch: 5| Step: 7
Training loss: 2.666726589202881
Validation loss: 2.0623718996842704

Epoch: 5| Step: 8
Training loss: 1.4658323526382446
Validation loss: 2.0608867506186166

Epoch: 5| Step: 9
Training loss: 1.9630348682403564
Validation loss: 2.0754157851139703

Epoch: 5| Step: 10
Training loss: 1.6095854043960571
Validation loss: 2.0823798129955926

Epoch: 5| Step: 11
Training loss: 1.3023085594177246
Validation loss: 2.076675370335579

Epoch: 174| Step: 0
Training loss: 2.2522804737091064
Validation loss: 2.0667535911003747

Epoch: 5| Step: 1
Training loss: 1.959084153175354
Validation loss: 2.0706975956757865

Epoch: 5| Step: 2
Training loss: 2.2179417610168457
Validation loss: 2.0890187124411264

Epoch: 5| Step: 3
Training loss: 2.0327601432800293
Validation loss: 2.083755741516749

Epoch: 5| Step: 4
Training loss: 1.8514492511749268
Validation loss: 2.088529368241628

Epoch: 5| Step: 5
Training loss: 1.9194015264511108
Validation loss: 2.0688304205735526

Epoch: 5| Step: 6
Training loss: 2.3581650257110596
Validation loss: 2.0754523624976478

Epoch: 5| Step: 7
Training loss: 2.1407198905944824
Validation loss: 2.065611978371938

Epoch: 5| Step: 8
Training loss: 2.152259111404419
Validation loss: 2.0607311526934304

Epoch: 5| Step: 9
Training loss: 1.745284080505371
Validation loss: 2.06495393315951

Epoch: 5| Step: 10
Training loss: 1.3217027187347412
Validation loss: 2.052093277374903

Epoch: 5| Step: 11
Training loss: 2.9201579093933105
Validation loss: 2.061081036925316

Epoch: 175| Step: 0
Training loss: 1.7164132595062256
Validation loss: 2.067968169848124

Epoch: 5| Step: 1
Training loss: 1.707542061805725
Validation loss: 2.06188236673673

Epoch: 5| Step: 2
Training loss: 2.126347303390503
Validation loss: 2.070250635345777

Epoch: 5| Step: 3
Training loss: 2.1350722312927246
Validation loss: 2.0775381277004876

Epoch: 5| Step: 4
Training loss: 1.6797561645507812
Validation loss: 2.079519748687744

Epoch: 5| Step: 5
Training loss: 2.476173162460327
Validation loss: 2.0665565033753714

Epoch: 5| Step: 6
Training loss: 2.2092716693878174
Validation loss: 2.0785207400719323

Epoch: 5| Step: 7
Training loss: 1.9144678115844727
Validation loss: 2.076966012517611

Epoch: 5| Step: 8
Training loss: 1.8427181243896484
Validation loss: 2.075443908572197

Epoch: 5| Step: 9
Training loss: 2.1186065673828125
Validation loss: 2.081946740547816

Epoch: 5| Step: 10
Training loss: 2.1156394481658936
Validation loss: 2.0554472108682

Epoch: 5| Step: 11
Training loss: 2.2591261863708496
Validation loss: 2.0659233182668686

Epoch: 176| Step: 0
Training loss: 1.8997421264648438
Validation loss: 2.0614042381445565

Epoch: 5| Step: 1
Training loss: 2.406317710876465
Validation loss: 2.0811312844355903

Epoch: 5| Step: 2
Training loss: 1.7285465002059937
Validation loss: 2.0706173479557037

Epoch: 5| Step: 3
Training loss: 2.3552193641662598
Validation loss: 2.0597501943508782

Epoch: 5| Step: 4
Training loss: 2.464370012283325
Validation loss: 2.062107945481936

Epoch: 5| Step: 5
Training loss: 1.9567844867706299
Validation loss: 2.05765167872111

Epoch: 5| Step: 6
Training loss: 2.0883376598358154
Validation loss: 2.0653508404890695

Epoch: 5| Step: 7
Training loss: 2.1183993816375732
Validation loss: 2.066134144862493

Epoch: 5| Step: 8
Training loss: 1.7167848348617554
Validation loss: 2.0565632383028665

Epoch: 5| Step: 9
Training loss: 1.4333312511444092
Validation loss: 2.0641518185536065

Epoch: 5| Step: 10
Training loss: 1.8049319982528687
Validation loss: 2.0707498490810394

Epoch: 5| Step: 11
Training loss: 1.5799565315246582
Validation loss: 2.0763276865084968

Epoch: 177| Step: 0
Training loss: 1.5917484760284424
Validation loss: 2.0691937108834586

Epoch: 5| Step: 1
Training loss: 1.9122730493545532
Validation loss: 2.0637900084257126

Epoch: 5| Step: 2
Training loss: 2.1605887413024902
Validation loss: 2.0584124525388083

Epoch: 5| Step: 3
Training loss: 2.007612466812134
Validation loss: 2.0865869224071503

Epoch: 5| Step: 4
Training loss: 2.5353341102600098
Validation loss: 2.0742198874553046

Epoch: 5| Step: 5
Training loss: 1.7978547811508179
Validation loss: 2.058624987800916

Epoch: 5| Step: 6
Training loss: 1.9191612005233765
Validation loss: 2.071142370502154

Epoch: 5| Step: 7
Training loss: 1.8192294836044312
Validation loss: 2.064175317684809

Epoch: 5| Step: 8
Training loss: 2.078657865524292
Validation loss: 2.0632811884085336

Epoch: 5| Step: 9
Training loss: 1.9831657409667969
Validation loss: 2.076412389675776

Epoch: 5| Step: 10
Training loss: 2.0400779247283936
Validation loss: 2.057909538348516

Epoch: 5| Step: 11
Training loss: 2.0164642333984375
Validation loss: 2.06283375620842

Epoch: 178| Step: 0
Training loss: 2.626208782196045
Validation loss: 2.0723034093777337

Epoch: 5| Step: 1
Training loss: 1.5164605379104614
Validation loss: 2.078615576028824

Epoch: 5| Step: 2
Training loss: 1.981818437576294
Validation loss: 2.0747214555740356

Epoch: 5| Step: 3
Training loss: 1.7231931686401367
Validation loss: 2.0763943990071616

Epoch: 5| Step: 4
Training loss: 1.3442232608795166
Validation loss: 2.0841015378634133

Epoch: 5| Step: 5
Training loss: 2.168578863143921
Validation loss: 2.0736054331064224

Epoch: 5| Step: 6
Training loss: 2.540168523788452
Validation loss: 2.0796145498752594

Epoch: 5| Step: 7
Training loss: 1.9842071533203125
Validation loss: 2.0602967888116837

Epoch: 5| Step: 8
Training loss: 2.2792458534240723
Validation loss: 2.075319230556488

Epoch: 5| Step: 9
Training loss: 2.248850107192993
Validation loss: 2.068444455663363

Epoch: 5| Step: 10
Training loss: 1.515470266342163
Validation loss: 2.0859765857458115

Epoch: 5| Step: 11
Training loss: 1.7872226238250732
Validation loss: 2.0813563019037247

Epoch: 179| Step: 0
Training loss: 2.054950714111328
Validation loss: 2.0785580029090247

Epoch: 5| Step: 1
Training loss: 1.9617630243301392
Validation loss: 2.0795697073141732

Epoch: 5| Step: 2
Training loss: 1.7692501544952393
Validation loss: 2.0832634369532266

Epoch: 5| Step: 3
Training loss: 1.8602666854858398
Validation loss: 2.0783395916223526

Epoch: 5| Step: 4
Training loss: 1.8727391958236694
Validation loss: 2.0869929442803064

Epoch: 5| Step: 5
Training loss: 2.561286211013794
Validation loss: 2.086932664116224

Epoch: 5| Step: 6
Training loss: 2.018364667892456
Validation loss: 2.0805417398611703

Epoch: 5| Step: 7
Training loss: 2.5086684226989746
Validation loss: 2.1004994958639145

Epoch: 5| Step: 8
Training loss: 1.9110615253448486
Validation loss: 2.0971537828445435

Epoch: 5| Step: 9
Training loss: 1.4223062992095947
Validation loss: 2.097000097235044

Epoch: 5| Step: 10
Training loss: 1.753154993057251
Validation loss: 2.09572563568751

Epoch: 5| Step: 11
Training loss: 2.0012564659118652
Validation loss: 2.1021784295638404

Epoch: 180| Step: 0
Training loss: 2.201918840408325
Validation loss: 2.0993081529935202

Epoch: 5| Step: 1
Training loss: 2.0834708213806152
Validation loss: 2.088033899664879

Epoch: 5| Step: 2
Training loss: 1.9974994659423828
Validation loss: 2.0796951949596405

Epoch: 5| Step: 3
Training loss: 2.166409969329834
Validation loss: 2.0883488754431405

Epoch: 5| Step: 4
Training loss: 2.0415501594543457
Validation loss: 2.0861209432284036

Epoch: 5| Step: 5
Training loss: 1.6876262426376343
Validation loss: 2.0728578716516495

Epoch: 5| Step: 6
Training loss: 2.283834457397461
Validation loss: 2.0788714488347373

Epoch: 5| Step: 7
Training loss: 1.633150339126587
Validation loss: 2.0673861652612686

Epoch: 5| Step: 8
Training loss: 2.034587860107422
Validation loss: 2.0841649174690247

Epoch: 5| Step: 9
Training loss: 2.035620927810669
Validation loss: 2.080101658900579

Epoch: 5| Step: 10
Training loss: 1.7594177722930908
Validation loss: 2.0770118832588196

Epoch: 5| Step: 11
Training loss: 1.3016958236694336
Validation loss: 2.07934699455897

Epoch: 181| Step: 0
Training loss: 2.411078929901123
Validation loss: 2.108619978030523

Epoch: 5| Step: 1
Training loss: 1.718595266342163
Validation loss: 2.1176456908384957

Epoch: 5| Step: 2
Training loss: 2.136138916015625
Validation loss: 2.12348942955335

Epoch: 5| Step: 3
Training loss: 1.7659457921981812
Validation loss: 2.145038684209188

Epoch: 5| Step: 4
Training loss: 2.1493422985076904
Validation loss: 2.1274452010790506

Epoch: 5| Step: 5
Training loss: 1.875867486000061
Validation loss: 2.144626627365748

Epoch: 5| Step: 6
Training loss: 2.1238090991973877
Validation loss: 2.1177110026280084

Epoch: 5| Step: 7
Training loss: 1.8675053119659424
Validation loss: 2.0993409554163613

Epoch: 5| Step: 8
Training loss: 2.024583101272583
Validation loss: 2.0758885542551675

Epoch: 5| Step: 9
Training loss: 2.2655391693115234
Validation loss: 2.0567183593908944

Epoch: 5| Step: 10
Training loss: 1.795600175857544
Validation loss: 2.064372107386589

Epoch: 5| Step: 11
Training loss: 1.734604001045227
Validation loss: 2.0575699508190155

Epoch: 182| Step: 0
Training loss: 2.445324420928955
Validation loss: 2.056721324721972

Epoch: 5| Step: 1
Training loss: 2.3048477172851562
Validation loss: 2.066967104872068

Epoch: 5| Step: 2
Training loss: 1.8013770580291748
Validation loss: 2.0739342967669168

Epoch: 5| Step: 3
Training loss: 1.4948508739471436
Validation loss: 2.0718006640672684

Epoch: 5| Step: 4
Training loss: 1.9677890539169312
Validation loss: 2.07789180179437

Epoch: 5| Step: 5
Training loss: 1.3283617496490479
Validation loss: 2.1010971715052924

Epoch: 5| Step: 6
Training loss: 1.6610132455825806
Validation loss: 2.116716052095095

Epoch: 5| Step: 7
Training loss: 2.18392014503479
Validation loss: 2.102864811817805

Epoch: 5| Step: 8
Training loss: 1.9706051349639893
Validation loss: 2.131516312559446

Epoch: 5| Step: 9
Training loss: 2.256641387939453
Validation loss: 2.115298956632614

Epoch: 5| Step: 10
Training loss: 2.4601635932922363
Validation loss: 2.0966155926386514

Epoch: 5| Step: 11
Training loss: 2.5980734825134277
Validation loss: 2.0728734731674194

Epoch: 183| Step: 0
Training loss: 1.8070682287216187
Validation loss: 2.066688949863116

Epoch: 5| Step: 1
Training loss: 1.9703972339630127
Validation loss: 2.0630914866924286

Epoch: 5| Step: 2
Training loss: 2.5700976848602295
Validation loss: 2.0614507645368576

Epoch: 5| Step: 3
Training loss: 2.2263877391815186
Validation loss: 2.050285041332245

Epoch: 5| Step: 4
Training loss: 2.4202206134796143
Validation loss: 2.060812453428904

Epoch: 5| Step: 5
Training loss: 2.0501883029937744
Validation loss: 2.06556029121081

Epoch: 5| Step: 6
Training loss: 1.9864311218261719
Validation loss: 2.0709976851940155

Epoch: 5| Step: 7
Training loss: 1.6898584365844727
Validation loss: 2.082257404923439

Epoch: 5| Step: 8
Training loss: 1.9584957361221313
Validation loss: 2.065178652604421

Epoch: 5| Step: 9
Training loss: 1.8510996103286743
Validation loss: 2.0686260710159936

Epoch: 5| Step: 10
Training loss: 2.320067882537842
Validation loss: 2.0680021494627

Epoch: 5| Step: 11
Training loss: 1.6878373622894287
Validation loss: 2.0579686711231866

Epoch: 184| Step: 0
Training loss: 1.7908645868301392
Validation loss: 2.0602067708969116

Epoch: 5| Step: 1
Training loss: 1.7858848571777344
Validation loss: 2.053487092256546

Epoch: 5| Step: 2
Training loss: 1.7377824783325195
Validation loss: 2.055162494381269

Epoch: 5| Step: 3
Training loss: 2.481766939163208
Validation loss: 2.048318102955818

Epoch: 5| Step: 4
Training loss: 2.014101505279541
Validation loss: 2.062122921148936

Epoch: 5| Step: 5
Training loss: 2.6306183338165283
Validation loss: 2.047019749879837

Epoch: 5| Step: 6
Training loss: 1.4985718727111816
Validation loss: 2.066726674636205

Epoch: 5| Step: 7
Training loss: 1.9637203216552734
Validation loss: 2.0734836210807166

Epoch: 5| Step: 8
Training loss: 1.976837158203125
Validation loss: 2.0806328554948172

Epoch: 5| Step: 9
Training loss: 2.490077495574951
Validation loss: 2.0734597891569138

Epoch: 5| Step: 10
Training loss: 1.9341695308685303
Validation loss: 2.071488991379738

Epoch: 5| Step: 11
Training loss: 1.9089983701705933
Validation loss: 2.088814362883568

Epoch: 185| Step: 0
Training loss: 1.0451771020889282
Validation loss: 2.0762155453364053

Epoch: 5| Step: 1
Training loss: 1.5237376689910889
Validation loss: 2.086315487821897

Epoch: 5| Step: 2
Training loss: 2.3263068199157715
Validation loss: 2.071424588561058

Epoch: 5| Step: 3
Training loss: 2.323701858520508
Validation loss: 2.061300883690516

Epoch: 5| Step: 4
Training loss: 2.072563648223877
Validation loss: 2.0629013180732727

Epoch: 5| Step: 5
Training loss: 1.925176978111267
Validation loss: 2.068000311652819

Epoch: 5| Step: 6
Training loss: 1.5910316705703735
Validation loss: 2.0598854571580887

Epoch: 5| Step: 7
Training loss: 1.9542672634124756
Validation loss: 2.044239188234011

Epoch: 5| Step: 8
Training loss: 2.7433993816375732
Validation loss: 2.0463693539301553

Epoch: 5| Step: 9
Training loss: 2.227046251296997
Validation loss: 2.04770490527153

Epoch: 5| Step: 10
Training loss: 2.014735221862793
Validation loss: 2.072445039947828

Epoch: 5| Step: 11
Training loss: 2.4409430027008057
Validation loss: 2.049375201265017

Epoch: 186| Step: 0
Training loss: 2.3742122650146484
Validation loss: 2.0431541204452515

Epoch: 5| Step: 1
Training loss: 2.143075466156006
Validation loss: 2.051833142836889

Epoch: 5| Step: 2
Training loss: 2.4145865440368652
Validation loss: 2.048437828818957

Epoch: 5| Step: 3
Training loss: 1.9461414813995361
Validation loss: 2.0672987550497055

Epoch: 5| Step: 4
Training loss: 1.5654783248901367
Validation loss: 2.0644761274258294

Epoch: 5| Step: 5
Training loss: 1.8195879459381104
Validation loss: 2.0701939860979715

Epoch: 5| Step: 6
Training loss: 1.4336544275283813
Validation loss: 2.0823672314484916

Epoch: 5| Step: 7
Training loss: 1.921160101890564
Validation loss: 2.090460161368052

Epoch: 5| Step: 8
Training loss: 2.475271701812744
Validation loss: 2.089612861474355

Epoch: 5| Step: 9
Training loss: 1.8076251745224
Validation loss: 2.077038735151291

Epoch: 5| Step: 10
Training loss: 1.9333016872406006
Validation loss: 2.0801770140727363

Epoch: 5| Step: 11
Training loss: 2.904540538787842
Validation loss: 2.071953296661377

Epoch: 187| Step: 0
Training loss: 1.871877670288086
Validation loss: 2.059231455127398

Epoch: 5| Step: 1
Training loss: 2.248687982559204
Validation loss: 2.0532772094011307

Epoch: 5| Step: 2
Training loss: 2.2216711044311523
Validation loss: 2.064878135919571

Epoch: 5| Step: 3
Training loss: 1.9485785961151123
Validation loss: 2.045665522416433

Epoch: 5| Step: 4
Training loss: 1.8775752782821655
Validation loss: 2.0630900164445243

Epoch: 5| Step: 5
Training loss: 1.6662051677703857
Validation loss: 2.0607885271310806

Epoch: 5| Step: 6
Training loss: 2.0464675426483154
Validation loss: 2.058129663268725

Epoch: 5| Step: 7
Training loss: 2.106140375137329
Validation loss: 2.0645271042982736

Epoch: 5| Step: 8
Training loss: 1.7444570064544678
Validation loss: 2.0660137782494226

Epoch: 5| Step: 9
Training loss: 2.2492051124572754
Validation loss: 2.0664723217487335

Epoch: 5| Step: 10
Training loss: 1.616228699684143
Validation loss: 2.0694029728571572

Epoch: 5| Step: 11
Training loss: 1.640578269958496
Validation loss: 2.0592939953009286

Epoch: 188| Step: 0
Training loss: 1.3260284662246704
Validation loss: 2.072304238875707

Epoch: 5| Step: 1
Training loss: 2.2273619174957275
Validation loss: 2.0792742570241294

Epoch: 5| Step: 2
Training loss: 1.9869105815887451
Validation loss: 2.0727425465981164

Epoch: 5| Step: 3
Training loss: 2.703216552734375
Validation loss: 2.0747250020504

Epoch: 5| Step: 4
Training loss: 1.7415043115615845
Validation loss: 2.1005366891622543

Epoch: 5| Step: 5
Training loss: 2.1350960731506348
Validation loss: 2.0789066751797995

Epoch: 5| Step: 6
Training loss: 2.116732120513916
Validation loss: 2.087712744871775

Epoch: 5| Step: 7
Training loss: 2.3381500244140625
Validation loss: 2.0682805875937142

Epoch: 5| Step: 8
Training loss: 1.5040117502212524
Validation loss: 2.0478772272666297

Epoch: 5| Step: 9
Training loss: 2.010593891143799
Validation loss: 2.059747045238813

Epoch: 5| Step: 10
Training loss: 1.7614481449127197
Validation loss: 2.057943900426229

Epoch: 5| Step: 11
Training loss: 1.3595010042190552
Validation loss: 2.051919957002004

Epoch: 189| Step: 0
Training loss: 2.040771007537842
Validation loss: 2.0455644180377326

Epoch: 5| Step: 1
Training loss: 1.5717580318450928
Validation loss: 2.039123555024465

Epoch: 5| Step: 2
Training loss: 1.6796340942382812
Validation loss: 2.067384421825409

Epoch: 5| Step: 3
Training loss: 2.2055044174194336
Validation loss: 2.0548975268999734

Epoch: 5| Step: 4
Training loss: 1.859521508216858
Validation loss: 2.0661452462275824

Epoch: 5| Step: 5
Training loss: 2.099632740020752
Validation loss: 2.064747949441274

Epoch: 5| Step: 6
Training loss: 2.5579612255096436
Validation loss: 2.068050518631935

Epoch: 5| Step: 7
Training loss: 1.8109924793243408
Validation loss: 2.0677755822738013

Epoch: 5| Step: 8
Training loss: 1.8158916234970093
Validation loss: 2.095105101664861

Epoch: 5| Step: 9
Training loss: 1.9737060070037842
Validation loss: 2.0944636464118958

Epoch: 5| Step: 10
Training loss: 1.8939310312271118
Validation loss: 2.0830980042616525

Epoch: 5| Step: 11
Training loss: 2.092262029647827
Validation loss: 2.0758533974488578

Epoch: 190| Step: 0
Training loss: 2.0976994037628174
Validation loss: 2.08088426788648

Epoch: 5| Step: 1
Training loss: 1.5520045757293701
Validation loss: 2.0794965624809265

Epoch: 5| Step: 2
Training loss: 2.071871042251587
Validation loss: 2.0707480212052665

Epoch: 5| Step: 3
Training loss: 1.8978357315063477
Validation loss: 2.068562631805738

Epoch: 5| Step: 4
Training loss: 2.173394203186035
Validation loss: 2.072325905164083

Epoch: 5| Step: 5
Training loss: 1.7018747329711914
Validation loss: 2.067476679881414

Epoch: 5| Step: 6
Training loss: 2.204050064086914
Validation loss: 2.0776427338520684

Epoch: 5| Step: 7
Training loss: 2.033133029937744
Validation loss: 2.0929767191410065

Epoch: 5| Step: 8
Training loss: 1.6230131387710571
Validation loss: 2.0670006424188614

Epoch: 5| Step: 9
Training loss: 1.9151103496551514
Validation loss: 2.0783160477876663

Epoch: 5| Step: 10
Training loss: 2.189840078353882
Validation loss: 2.074361731608709

Epoch: 5| Step: 11
Training loss: 2.1243584156036377
Validation loss: 2.0721076329549155

Epoch: 191| Step: 0
Training loss: 2.1188390254974365
Validation loss: 2.0702608227729797

Epoch: 5| Step: 1
Training loss: 1.9327418804168701
Validation loss: 2.076122080286344

Epoch: 5| Step: 2
Training loss: 1.6249666213989258
Validation loss: 2.086507553855578

Epoch: 5| Step: 3
Training loss: 2.69291353225708
Validation loss: 2.1016121904055276

Epoch: 5| Step: 4
Training loss: 1.6682647466659546
Validation loss: 2.079910784959793

Epoch: 5| Step: 5
Training loss: 1.1466931104660034
Validation loss: 2.0727863709131875

Epoch: 5| Step: 6
Training loss: 2.234846591949463
Validation loss: 2.0852663020292916

Epoch: 5| Step: 7
Training loss: 1.728028655052185
Validation loss: 2.076456626256307

Epoch: 5| Step: 8
Training loss: 2.2451303005218506
Validation loss: 2.0681841323773065

Epoch: 5| Step: 9
Training loss: 2.1896777153015137
Validation loss: 2.072705845038096

Epoch: 5| Step: 10
Training loss: 2.057997703552246
Validation loss: 2.0678924272457757

Epoch: 5| Step: 11
Training loss: 2.689973831176758
Validation loss: 2.054996242125829

Epoch: 192| Step: 0
Training loss: 2.2189948558807373
Validation loss: 2.06454074382782

Epoch: 5| Step: 1
Training loss: 1.8613744974136353
Validation loss: 2.0626775920391083

Epoch: 5| Step: 2
Training loss: 1.6976468563079834
Validation loss: 2.047761549552282

Epoch: 5| Step: 3
Training loss: 1.7504068613052368
Validation loss: 2.0514797369639077

Epoch: 5| Step: 4
Training loss: 2.3297886848449707
Validation loss: 2.0524583210547767

Epoch: 5| Step: 5
Training loss: 1.8385471105575562
Validation loss: 2.0584899832805

Epoch: 5| Step: 6
Training loss: 1.983766794204712
Validation loss: 2.0721777578194938

Epoch: 5| Step: 7
Training loss: 1.4378547668457031
Validation loss: 2.0765067090590796

Epoch: 5| Step: 8
Training loss: 2.491068124771118
Validation loss: 2.0933232506116233

Epoch: 5| Step: 9
Training loss: 1.942873239517212
Validation loss: 2.0963514149188995

Epoch: 5| Step: 10
Training loss: 2.143935441970825
Validation loss: 2.083726088205973

Epoch: 5| Step: 11
Training loss: 2.5772438049316406
Validation loss: 2.098355323076248

Epoch: 193| Step: 0
Training loss: 1.9307180643081665
Validation loss: 2.0794425308704376

Epoch: 5| Step: 1
Training loss: 2.2431800365448
Validation loss: 2.0667764047781625

Epoch: 5| Step: 2
Training loss: 2.3758747577667236
Validation loss: 2.0622154772281647

Epoch: 5| Step: 3
Training loss: 1.7969005107879639
Validation loss: 2.076438784599304

Epoch: 5| Step: 4
Training loss: 2.117159843444824
Validation loss: 2.0573394993940988

Epoch: 5| Step: 5
Training loss: 2.287393093109131
Validation loss: 2.0513554414113364

Epoch: 5| Step: 6
Training loss: 2.3672595024108887
Validation loss: 2.043754736582438

Epoch: 5| Step: 7
Training loss: 1.4992663860321045
Validation loss: 2.051918869217237

Epoch: 5| Step: 8
Training loss: 1.9648115634918213
Validation loss: 2.064344341556231

Epoch: 5| Step: 9
Training loss: 1.6052318811416626
Validation loss: 2.058765466014544

Epoch: 5| Step: 10
Training loss: 1.5863488912582397
Validation loss: 2.0603793362776437

Epoch: 5| Step: 11
Training loss: 1.8801369667053223
Validation loss: 2.0552529990673065

Epoch: 194| Step: 0
Training loss: 2.023359775543213
Validation loss: 2.0596229334672294

Epoch: 5| Step: 1
Training loss: 1.797692894935608
Validation loss: 2.0743587563435235

Epoch: 5| Step: 2
Training loss: 1.6766904592514038
Validation loss: 2.064664512872696

Epoch: 5| Step: 3
Training loss: 2.5177206993103027
Validation loss: 2.0724973678588867

Epoch: 5| Step: 4
Training loss: 1.8672754764556885
Validation loss: 2.062849134206772

Epoch: 5| Step: 5
Training loss: 1.8715740442276
Validation loss: 2.065527617931366

Epoch: 5| Step: 6
Training loss: 2.167942762374878
Validation loss: 2.0636171996593475

Epoch: 5| Step: 7
Training loss: 1.7083556652069092
Validation loss: 2.0704046487808228

Epoch: 5| Step: 8
Training loss: 2.2108752727508545
Validation loss: 2.067745784918467

Epoch: 5| Step: 9
Training loss: 1.876774787902832
Validation loss: 2.072411298751831

Epoch: 5| Step: 10
Training loss: 1.7236709594726562
Validation loss: 2.0722052405277886

Epoch: 5| Step: 11
Training loss: 2.2183830738067627
Validation loss: 2.086250886321068

Epoch: 195| Step: 0
Training loss: 2.270397901535034
Validation loss: 2.1310752431551614

Epoch: 5| Step: 1
Training loss: 2.4947445392608643
Validation loss: 2.156347076098124

Epoch: 5| Step: 2
Training loss: 1.9066896438598633
Validation loss: 2.1389091511567435

Epoch: 5| Step: 3
Training loss: 2.2159323692321777
Validation loss: 2.1305175373951593

Epoch: 5| Step: 4
Training loss: 2.102093458175659
Validation loss: 2.116603900988897

Epoch: 5| Step: 5
Training loss: 2.1395740509033203
Validation loss: 2.131275326013565

Epoch: 5| Step: 6
Training loss: 2.2622814178466797
Validation loss: 2.1162608762582145

Epoch: 5| Step: 7
Training loss: 2.019954204559326
Validation loss: 2.0910042375326157

Epoch: 5| Step: 8
Training loss: 1.9172567129135132
Validation loss: 2.082556828856468

Epoch: 5| Step: 9
Training loss: 1.506230354309082
Validation loss: 2.0569141109784446

Epoch: 5| Step: 10
Training loss: 1.6940749883651733
Validation loss: 2.059993495543798

Epoch: 5| Step: 11
Training loss: 1.3957983255386353
Validation loss: 2.0460595339536667

Epoch: 196| Step: 0
Training loss: 2.8230035305023193
Validation loss: 2.0566859990358353

Epoch: 5| Step: 1
Training loss: 1.935529112815857
Validation loss: 2.050978268186251

Epoch: 5| Step: 2
Training loss: 1.7312694787979126
Validation loss: 2.0604773461818695

Epoch: 5| Step: 3
Training loss: 1.7517637014389038
Validation loss: 2.056775147716204

Epoch: 5| Step: 4
Training loss: 1.8449618816375732
Validation loss: 2.073513706525167

Epoch: 5| Step: 5
Training loss: 1.6380516290664673
Validation loss: 2.0837996006011963

Epoch: 5| Step: 6
Training loss: 2.7621817588806152
Validation loss: 2.094508950908979

Epoch: 5| Step: 7
Training loss: 1.9480829238891602
Validation loss: 2.099626198410988

Epoch: 5| Step: 8
Training loss: 2.2804317474365234
Validation loss: 2.1071326533953347

Epoch: 5| Step: 9
Training loss: 1.6088473796844482
Validation loss: 2.1150857905546823

Epoch: 5| Step: 10
Training loss: 1.4344902038574219
Validation loss: 2.123118907213211

Epoch: 5| Step: 11
Training loss: 2.5121090412139893
Validation loss: 2.109986995657285

Epoch: 197| Step: 0
Training loss: 2.104936122894287
Validation loss: 2.1172919472058616

Epoch: 5| Step: 1
Training loss: 1.7877376079559326
Validation loss: 2.1018464267253876

Epoch: 5| Step: 2
Training loss: 1.5516884326934814
Validation loss: 2.088651185234388

Epoch: 5| Step: 3
Training loss: 1.959080696105957
Validation loss: 2.0966722120841346

Epoch: 5| Step: 4
Training loss: 1.72456955909729
Validation loss: 2.0808060665925345

Epoch: 5| Step: 5
Training loss: 1.9816367626190186
Validation loss: 2.077906588713328

Epoch: 5| Step: 6
Training loss: 1.6146472692489624
Validation loss: 2.073102648059527

Epoch: 5| Step: 7
Training loss: 1.5402476787567139
Validation loss: 2.0662394762039185

Epoch: 5| Step: 8
Training loss: 2.0568766593933105
Validation loss: 2.075935944914818

Epoch: 5| Step: 9
Training loss: 1.9497184753417969
Validation loss: 2.0868154019117355

Epoch: 5| Step: 10
Training loss: 2.9333646297454834
Validation loss: 2.0932353685299554

Epoch: 5| Step: 11
Training loss: 3.8290200233459473
Validation loss: 2.0886402825514474

Epoch: 198| Step: 0
Training loss: 1.8104082345962524
Validation loss: 2.0962394227584205

Epoch: 5| Step: 1
Training loss: 1.6521145105361938
Validation loss: 2.081929460167885

Epoch: 5| Step: 2
Training loss: 1.6740363836288452
Validation loss: 2.078070789575577

Epoch: 5| Step: 3
Training loss: 2.3833115100860596
Validation loss: 2.0828625609477363

Epoch: 5| Step: 4
Training loss: 2.029418468475342
Validation loss: 2.0846407612164817

Epoch: 5| Step: 5
Training loss: 1.541144609451294
Validation loss: 2.081147402524948

Epoch: 5| Step: 6
Training loss: 1.7762153148651123
Validation loss: 2.091670587658882

Epoch: 5| Step: 7
Training loss: 1.9604365825653076
Validation loss: 2.0688491066296897

Epoch: 5| Step: 8
Training loss: 1.9528357982635498
Validation loss: 2.088406185309092

Epoch: 5| Step: 9
Training loss: 2.650435209274292
Validation loss: 2.084965243935585

Epoch: 5| Step: 10
Training loss: 2.0763893127441406
Validation loss: 2.1000749121109643

Epoch: 5| Step: 11
Training loss: 2.012515068054199
Validation loss: 2.0829791724681854

Epoch: 199| Step: 0
Training loss: 1.9560953378677368
Validation loss: 2.089950442314148

Epoch: 5| Step: 1
Training loss: 1.847068428993225
Validation loss: 2.091299166282018

Epoch: 5| Step: 2
Training loss: 2.2277779579162598
Validation loss: 2.109577322999636

Epoch: 5| Step: 3
Training loss: 2.1637253761291504
Validation loss: 2.089308023452759

Epoch: 5| Step: 4
Training loss: 1.8940222263336182
Validation loss: 2.115704973538717

Epoch: 5| Step: 5
Training loss: 1.766345739364624
Validation loss: 2.1070616046587625

Epoch: 5| Step: 6
Training loss: 1.6675806045532227
Validation loss: 2.0762172639369965

Epoch: 5| Step: 7
Training loss: 2.4810919761657715
Validation loss: 2.0853367100159326

Epoch: 5| Step: 8
Training loss: 1.2370582818984985
Validation loss: 2.0678380529085794

Epoch: 5| Step: 9
Training loss: 2.134631395339966
Validation loss: 2.0615088244279227

Epoch: 5| Step: 10
Training loss: 2.5090768337249756
Validation loss: 2.066841055949529

Epoch: 5| Step: 11
Training loss: 1.0318233966827393
Validation loss: 2.075742940107981

Epoch: 200| Step: 0
Training loss: 1.8270280361175537
Validation loss: 2.06770525376002

Epoch: 5| Step: 1
Training loss: 1.9280732870101929
Validation loss: 2.0732502539952598

Epoch: 5| Step: 2
Training loss: 1.9752438068389893
Validation loss: 2.059104045232137

Epoch: 5| Step: 3
Training loss: 2.064908742904663
Validation loss: 2.0749017546574273

Epoch: 5| Step: 4
Training loss: 1.8159096240997314
Validation loss: 2.0737784753243127

Epoch: 5| Step: 5
Training loss: 2.1236605644226074
Validation loss: 2.0839325239260993

Epoch: 5| Step: 6
Training loss: 1.8989508152008057
Validation loss: 2.095093990365664

Epoch: 5| Step: 7
Training loss: 1.2194993495941162
Validation loss: 2.096826175848643

Epoch: 5| Step: 8
Training loss: 2.107781410217285
Validation loss: 2.099505623181661

Epoch: 5| Step: 9
Training loss: 2.281585216522217
Validation loss: 2.1240167717138925

Epoch: 5| Step: 10
Training loss: 2.459864377975464
Validation loss: 2.138386900226275

Epoch: 5| Step: 11
Training loss: 2.0437936782836914
Validation loss: 2.123834808667501

Epoch: 201| Step: 0
Training loss: 2.279466152191162
Validation loss: 2.13828976949056

Epoch: 5| Step: 1
Training loss: 1.9012504816055298
Validation loss: 2.1171317597230277

Epoch: 5| Step: 2
Training loss: 2.8398852348327637
Validation loss: 2.129548668861389

Epoch: 5| Step: 3
Training loss: 1.6580181121826172
Validation loss: 2.116077264149984

Epoch: 5| Step: 4
Training loss: 1.6110531091690063
Validation loss: 2.1129988630612693

Epoch: 5| Step: 5
Training loss: 2.1234538555145264
Validation loss: 2.1068138629198074

Epoch: 5| Step: 6
Training loss: 1.6981713771820068
Validation loss: 2.0930854131778083

Epoch: 5| Step: 7
Training loss: 1.7922554016113281
Validation loss: 2.0970560957988105

Epoch: 5| Step: 8
Training loss: 2.3156075477600098
Validation loss: 2.0917168160279593

Epoch: 5| Step: 9
Training loss: 1.4164928197860718
Validation loss: 2.0801386584838233

Epoch: 5| Step: 10
Training loss: 1.6854251623153687
Validation loss: 2.093308930595716

Epoch: 5| Step: 11
Training loss: 2.5001535415649414
Validation loss: 2.0907341887553534

Epoch: 202| Step: 0
Training loss: 2.299696207046509
Validation loss: 2.091669052839279

Epoch: 5| Step: 1
Training loss: 1.9558273553848267
Validation loss: 2.1002935071786246

Epoch: 5| Step: 2
Training loss: 2.2816970348358154
Validation loss: 2.1001841028531394

Epoch: 5| Step: 3
Training loss: 1.7518894672393799
Validation loss: 2.1144486169020333

Epoch: 5| Step: 4
Training loss: 1.7072522640228271
Validation loss: 2.105918342868487

Epoch: 5| Step: 5
Training loss: 2.287959575653076
Validation loss: 2.110599641998609

Epoch: 5| Step: 6
Training loss: 2.128607749938965
Validation loss: 2.105053464571635

Epoch: 5| Step: 7
Training loss: 1.9732685089111328
Validation loss: 2.111527959505717

Epoch: 5| Step: 8
Training loss: 1.8973621129989624
Validation loss: 2.122028445204099

Epoch: 5| Step: 9
Training loss: 1.79656982421875
Validation loss: 2.1238365868727365

Epoch: 5| Step: 10
Training loss: 1.4262031316757202
Validation loss: 2.1164349168539047

Epoch: 5| Step: 11
Training loss: 1.7393420934677124
Validation loss: 2.1121029208103814

Epoch: 203| Step: 0
Training loss: 2.7381622791290283
Validation loss: 2.099154685934385

Epoch: 5| Step: 1
Training loss: 1.249544382095337
Validation loss: 2.1021604984998703

Epoch: 5| Step: 2
Training loss: 1.989082932472229
Validation loss: 2.108240266640981

Epoch: 5| Step: 3
Training loss: 1.9328171014785767
Validation loss: 2.0975280751784644

Epoch: 5| Step: 4
Training loss: 1.6592581272125244
Validation loss: 2.099390218655268

Epoch: 5| Step: 5
Training loss: 1.8170158863067627
Validation loss: 2.0892129043738046

Epoch: 5| Step: 6
Training loss: 2.1137681007385254
Validation loss: 2.111369267106056

Epoch: 5| Step: 7
Training loss: 2.191450595855713
Validation loss: 2.0951161632935205

Epoch: 5| Step: 8
Training loss: 1.9171396493911743
Validation loss: 2.1014700829982758

Epoch: 5| Step: 9
Training loss: 1.6423909664154053
Validation loss: 2.110593616962433

Epoch: 5| Step: 10
Training loss: 1.8995529413223267
Validation loss: 2.106669286886851

Epoch: 5| Step: 11
Training loss: 2.370884895324707
Validation loss: 2.102343186736107

Epoch: 204| Step: 0
Training loss: 1.832080602645874
Validation loss: 2.114959165453911

Epoch: 5| Step: 1
Training loss: 1.602313756942749
Validation loss: 2.1157058676083884

Epoch: 5| Step: 2
Training loss: 2.624788761138916
Validation loss: 2.106554036339124

Epoch: 5| Step: 3
Training loss: 1.8916149139404297
Validation loss: 2.1264466643333435

Epoch: 5| Step: 4
Training loss: 1.6754982471466064
Validation loss: 2.126492222150167

Epoch: 5| Step: 5
Training loss: 1.9836750030517578
Validation loss: 2.1175733655691147

Epoch: 5| Step: 6
Training loss: 2.0909910202026367
Validation loss: 2.1091745793819427

Epoch: 5| Step: 7
Training loss: 1.4978691339492798
Validation loss: 2.1294554819663367

Epoch: 5| Step: 8
Training loss: 1.810612440109253
Validation loss: 2.1334986786047616

Epoch: 5| Step: 9
Training loss: 1.9966270923614502
Validation loss: 2.1131020983060202

Epoch: 5| Step: 10
Training loss: 2.237079620361328
Validation loss: 2.099694793423017

Epoch: 5| Step: 11
Training loss: 1.8012869358062744
Validation loss: 2.1167492071787515

Epoch: 205| Step: 0
Training loss: 1.52286696434021
Validation loss: 2.0894090781609216

Epoch: 5| Step: 1
Training loss: 1.6295650005340576
Validation loss: 2.091973682244619

Epoch: 5| Step: 2
Training loss: 1.8126189708709717
Validation loss: 2.081093187133471

Epoch: 5| Step: 3
Training loss: 2.8194096088409424
Validation loss: 2.090593362847964

Epoch: 5| Step: 4
Training loss: 1.9181888103485107
Validation loss: 2.0788425654172897

Epoch: 5| Step: 5
Training loss: 1.9415203332901
Validation loss: 2.0863308707873025

Epoch: 5| Step: 6
Training loss: 2.134228467941284
Validation loss: 2.0708015263080597

Epoch: 5| Step: 7
Training loss: 2.0371479988098145
Validation loss: 2.092986524105072

Epoch: 5| Step: 8
Training loss: 1.6479301452636719
Validation loss: 2.0884999682505927

Epoch: 5| Step: 9
Training loss: 1.664520025253296
Validation loss: 2.093877757589022

Epoch: 5| Step: 10
Training loss: 2.522066593170166
Validation loss: 2.0837392807006836

Epoch: 5| Step: 11
Training loss: 1.4812473058700562
Validation loss: 2.1065881898005805

Epoch: 206| Step: 0
Training loss: 1.7247148752212524
Validation loss: 2.107688913742701

Epoch: 5| Step: 1
Training loss: 2.1062138080596924
Validation loss: 2.1214494705200195

Epoch: 5| Step: 2
Training loss: 1.6492503881454468
Validation loss: 2.116819197932879

Epoch: 5| Step: 3
Training loss: 1.5836998224258423
Validation loss: 2.125565359989802

Epoch: 5| Step: 4
Training loss: 1.995844841003418
Validation loss: 2.119488308827082

Epoch: 5| Step: 5
Training loss: 1.6936495304107666
Validation loss: 2.1227436860402427

Epoch: 5| Step: 6
Training loss: 2.312300682067871
Validation loss: 2.1234731674194336

Epoch: 5| Step: 7
Training loss: 2.1502487659454346
Validation loss: 2.1172910730044046

Epoch: 5| Step: 8
Training loss: 2.2265849113464355
Validation loss: 2.1146284888188043

Epoch: 5| Step: 9
Training loss: 1.8908748626708984
Validation loss: 2.106292019287745

Epoch: 5| Step: 10
Training loss: 1.7777951955795288
Validation loss: 2.1078268041213355

Epoch: 5| Step: 11
Training loss: 2.508861541748047
Validation loss: 2.094204972187678

Epoch: 207| Step: 0
Training loss: 1.7735294103622437
Validation loss: 2.1011819342772164

Epoch: 5| Step: 1
Training loss: 1.87710702419281
Validation loss: 2.0779895037412643

Epoch: 5| Step: 2
Training loss: 1.7746589183807373
Validation loss: 2.083164796233177

Epoch: 5| Step: 3
Training loss: 2.3227429389953613
Validation loss: 2.099099636077881

Epoch: 5| Step: 4
Training loss: 1.7201954126358032
Validation loss: 2.0923715233802795

Epoch: 5| Step: 5
Training loss: 2.7522130012512207
Validation loss: 2.080360546708107

Epoch: 5| Step: 6
Training loss: 1.5648645162582397
Validation loss: 2.081047390898069

Epoch: 5| Step: 7
Training loss: 2.400812864303589
Validation loss: 2.079738641778628

Epoch: 5| Step: 8
Training loss: 2.4151723384857178
Validation loss: 2.08113465209802

Epoch: 5| Step: 9
Training loss: 2.19429087638855
Validation loss: 2.0734230428934097

Epoch: 5| Step: 10
Training loss: 1.8416659832000732
Validation loss: 2.0695256491502128

Epoch: 5| Step: 11
Training loss: 1.8300472497940063
Validation loss: 2.0745804409186044

Epoch: 208| Step: 0
Training loss: 2.13511323928833
Validation loss: 2.0767695754766464

Epoch: 5| Step: 1
Training loss: 1.6072232723236084
Validation loss: 2.085069308678309

Epoch: 5| Step: 2
Training loss: 1.7237573862075806
Validation loss: 2.09851765135924

Epoch: 5| Step: 3
Training loss: 1.8036251068115234
Validation loss: 2.1284337441126504

Epoch: 5| Step: 4
Training loss: 2.0971319675445557
Validation loss: 2.1125537008047104

Epoch: 5| Step: 5
Training loss: 1.6665775775909424
Validation loss: 2.126813073952993

Epoch: 5| Step: 6
Training loss: 2.622025966644287
Validation loss: 2.1243363271156945

Epoch: 5| Step: 7
Training loss: 2.102855920791626
Validation loss: 2.1165978610515594

Epoch: 5| Step: 8
Training loss: 1.8806453943252563
Validation loss: 2.0935792326927185

Epoch: 5| Step: 9
Training loss: 2.2550606727600098
Validation loss: 2.109649787346522

Epoch: 5| Step: 10
Training loss: 1.9804834127426147
Validation loss: 2.1006311724583306

Epoch: 5| Step: 11
Training loss: 2.2448954582214355
Validation loss: 2.0867990404367447

Epoch: 209| Step: 0
Training loss: 2.873765468597412
Validation loss: 2.087431564927101

Epoch: 5| Step: 1
Training loss: 1.121269941329956
Validation loss: 2.0808365096648536

Epoch: 5| Step: 2
Training loss: 1.5510175228118896
Validation loss: 2.0863527605930963

Epoch: 5| Step: 3
Training loss: 2.022836685180664
Validation loss: 2.069811522960663

Epoch: 5| Step: 4
Training loss: 2.11750864982605
Validation loss: 2.079080179333687

Epoch: 5| Step: 5
Training loss: 1.6054881811141968
Validation loss: 2.065680051843325

Epoch: 5| Step: 6
Training loss: 2.130222797393799
Validation loss: 2.074343204498291

Epoch: 5| Step: 7
Training loss: 2.093966007232666
Validation loss: 2.0735369523366294

Epoch: 5| Step: 8
Training loss: 1.8590681552886963
Validation loss: 2.0753031025330224

Epoch: 5| Step: 9
Training loss: 2.11769437789917
Validation loss: 2.0753674606482186

Epoch: 5| Step: 10
Training loss: 2.1052775382995605
Validation loss: 2.080819288889567

Epoch: 5| Step: 11
Training loss: 1.2714000940322876
Validation loss: 2.0715959519147873

Epoch: 210| Step: 0
Training loss: 1.8309015035629272
Validation loss: 2.0945888261000314

Epoch: 5| Step: 1
Training loss: 1.717820167541504
Validation loss: 2.0867558469374976

Epoch: 5| Step: 2
Training loss: 2.0767719745635986
Validation loss: 2.089111477136612

Epoch: 5| Step: 3
Training loss: 2.105705976486206
Validation loss: 2.0942226499319077

Epoch: 5| Step: 4
Training loss: 2.0779311656951904
Validation loss: 2.0915946116050086

Epoch: 5| Step: 5
Training loss: 1.889986276626587
Validation loss: 2.086020812392235

Epoch: 5| Step: 6
Training loss: 2.080352306365967
Validation loss: 2.087078422307968

Epoch: 5| Step: 7
Training loss: 1.7251348495483398
Validation loss: 2.1142107347647348

Epoch: 5| Step: 8
Training loss: 2.5445985794067383
Validation loss: 2.093072379628817

Epoch: 5| Step: 9
Training loss: 1.593423843383789
Validation loss: 2.098104457060496

Epoch: 5| Step: 10
Training loss: 1.7430684566497803
Validation loss: 2.0808357894420624

Epoch: 5| Step: 11
Training loss: 1.578906536102295
Validation loss: 2.101736307144165

Epoch: 211| Step: 0
Training loss: 1.69167160987854
Validation loss: 2.0883730153242746

Epoch: 5| Step: 1
Training loss: 2.35703182220459
Validation loss: 2.0779743641614914

Epoch: 5| Step: 2
Training loss: 1.9636284112930298
Validation loss: 2.079471011956533

Epoch: 5| Step: 3
Training loss: 1.7714054584503174
Validation loss: 2.081088458498319

Epoch: 5| Step: 4
Training loss: 2.0194573402404785
Validation loss: 2.0778133223454156

Epoch: 5| Step: 5
Training loss: 1.9363634586334229
Validation loss: 2.0653319507837296

Epoch: 5| Step: 6
Training loss: 1.9445056915283203
Validation loss: 2.0908052722613015

Epoch: 5| Step: 7
Training loss: 1.493390679359436
Validation loss: 2.0907529145479202

Epoch: 5| Step: 8
Training loss: 2.2095470428466797
Validation loss: 2.0881408701340356

Epoch: 5| Step: 9
Training loss: 1.7518059015274048
Validation loss: 2.082209606965383

Epoch: 5| Step: 10
Training loss: 1.9795806407928467
Validation loss: 2.09431358675162

Epoch: 5| Step: 11
Training loss: 2.3664917945861816
Validation loss: 2.103186865647634

Epoch: 212| Step: 0
Training loss: 2.2577433586120605
Validation loss: 2.10367559393247

Epoch: 5| Step: 1
Training loss: 1.9336938858032227
Validation loss: 2.101257527867953

Epoch: 5| Step: 2
Training loss: 2.0616536140441895
Validation loss: 2.1016018788019815

Epoch: 5| Step: 3
Training loss: 1.8239656686782837
Validation loss: 2.09694966673851

Epoch: 5| Step: 4
Training loss: 1.9972717761993408
Validation loss: 2.092924560109774

Epoch: 5| Step: 5
Training loss: 1.7705742120742798
Validation loss: 2.0886390656232834

Epoch: 5| Step: 6
Training loss: 1.631719946861267
Validation loss: 2.085183322429657

Epoch: 5| Step: 7
Training loss: 2.139273166656494
Validation loss: 2.0965490142504373

Epoch: 5| Step: 8
Training loss: 1.7325336933135986
Validation loss: 2.1000642428795495

Epoch: 5| Step: 9
Training loss: 1.6302955150604248
Validation loss: 2.0930867393811545

Epoch: 5| Step: 10
Training loss: 2.0210652351379395
Validation loss: 2.083424001932144

Epoch: 5| Step: 11
Training loss: 2.6983933448791504
Validation loss: 2.0891429781913757

Epoch: 213| Step: 0
Training loss: 1.5983787775039673
Validation loss: 2.0827164500951767

Epoch: 5| Step: 1
Training loss: 1.3399484157562256
Validation loss: 2.1007997194925943

Epoch: 5| Step: 2
Training loss: 2.2795064449310303
Validation loss: 2.0949558913707733

Epoch: 5| Step: 3
Training loss: 1.9154895544052124
Validation loss: 2.089516301949819

Epoch: 5| Step: 4
Training loss: 1.7996412515640259
Validation loss: 2.112044637401899

Epoch: 5| Step: 5
Training loss: 2.5883078575134277
Validation loss: 2.1081632375717163

Epoch: 5| Step: 6
Training loss: 1.9086692333221436
Validation loss: 2.109198292096456

Epoch: 5| Step: 7
Training loss: 2.5626273155212402
Validation loss: 2.1046969890594482

Epoch: 5| Step: 8
Training loss: 1.6535885334014893
Validation loss: 2.101421743631363

Epoch: 5| Step: 9
Training loss: 1.4652704000473022
Validation loss: 2.1085043996572495

Epoch: 5| Step: 10
Training loss: 2.0192182064056396
Validation loss: 2.1098609467347464

Epoch: 5| Step: 11
Training loss: 1.3710131645202637
Validation loss: 2.1124923328558602

Epoch: 214| Step: 0
Training loss: 1.7555344104766846
Validation loss: 2.11701500415802

Epoch: 5| Step: 1
Training loss: 2.4106929302215576
Validation loss: 2.1160681943098703

Epoch: 5| Step: 2
Training loss: 1.4017975330352783
Validation loss: 2.135485142469406

Epoch: 5| Step: 3
Training loss: 1.7259271144866943
Validation loss: 2.142428105076154

Epoch: 5| Step: 4
Training loss: 1.7435252666473389
Validation loss: 2.1408221075932183

Epoch: 5| Step: 5
Training loss: 1.709161400794983
Validation loss: 2.121656507253647

Epoch: 5| Step: 6
Training loss: 2.0767428874969482
Validation loss: 2.1136488020420074

Epoch: 5| Step: 7
Training loss: 2.4229485988616943
Validation loss: 2.108613689740499

Epoch: 5| Step: 8
Training loss: 2.082791566848755
Validation loss: 2.116991311311722

Epoch: 5| Step: 9
Training loss: 2.0020711421966553
Validation loss: 2.1078722774982452

Epoch: 5| Step: 10
Training loss: 1.8580353260040283
Validation loss: 2.081834693749746

Epoch: 5| Step: 11
Training loss: 1.8544764518737793
Validation loss: 2.112615466117859

Epoch: 215| Step: 0
Training loss: 2.218869686126709
Validation loss: 2.121462345123291

Epoch: 5| Step: 1
Training loss: 2.085188865661621
Validation loss: 2.1359691520531974

Epoch: 5| Step: 2
Training loss: 1.942164421081543
Validation loss: 2.1335509717464447

Epoch: 5| Step: 3
Training loss: 1.8696908950805664
Validation loss: 2.130472163359324

Epoch: 5| Step: 4
Training loss: 1.7114531993865967
Validation loss: 2.122437432408333

Epoch: 5| Step: 5
Training loss: 1.0229424238204956
Validation loss: 2.117108369867007

Epoch: 5| Step: 6
Training loss: 2.3686561584472656
Validation loss: 2.100497603416443

Epoch: 5| Step: 7
Training loss: 1.5684814453125
Validation loss: 2.100470076004664

Epoch: 5| Step: 8
Training loss: 2.604260206222534
Validation loss: 2.0975304941336312

Epoch: 5| Step: 9
Training loss: 1.871374487876892
Validation loss: 2.107316702604294

Epoch: 5| Step: 10
Training loss: 1.7445234060287476
Validation loss: 2.1054022908210754

Epoch: 5| Step: 11
Training loss: 1.6668975353240967
Validation loss: 2.0950551281372705

Epoch: 216| Step: 0
Training loss: 1.2634170055389404
Validation loss: 2.0900847762823105

Epoch: 5| Step: 1
Training loss: 2.0043039321899414
Validation loss: 2.0880038191874823

Epoch: 5| Step: 2
Training loss: 1.9418714046478271
Validation loss: 2.0925003538529077

Epoch: 5| Step: 3
Training loss: 2.123163938522339
Validation loss: 2.093394751350085

Epoch: 5| Step: 4
Training loss: 1.8702783584594727
Validation loss: 2.0973800172408423

Epoch: 5| Step: 5
Training loss: 1.9541339874267578
Validation loss: 2.101960683862368

Epoch: 5| Step: 6
Training loss: 1.6812736988067627
Validation loss: 2.104677895704905

Epoch: 5| Step: 7
Training loss: 1.981864333152771
Validation loss: 2.1044411609570184

Epoch: 5| Step: 8
Training loss: 1.6714897155761719
Validation loss: 2.107730269432068

Epoch: 5| Step: 9
Training loss: 2.5640389919281006
Validation loss: 2.104441856344541

Epoch: 5| Step: 10
Training loss: 2.222162961959839
Validation loss: 2.1110780040423074

Epoch: 5| Step: 11
Training loss: 0.8846262693405151
Validation loss: 2.1067781895399094

Epoch: 217| Step: 0
Training loss: 2.2154831886291504
Validation loss: 2.1375987927118936

Epoch: 5| Step: 1
Training loss: 2.0175251960754395
Validation loss: 2.12812506655852

Epoch: 5| Step: 2
Training loss: 1.7741243839263916
Validation loss: 2.1315436561902366

Epoch: 5| Step: 3
Training loss: 1.6491988897323608
Validation loss: 2.13256765405337

Epoch: 5| Step: 4
Training loss: 2.158437728881836
Validation loss: 2.127030978600184

Epoch: 5| Step: 5
Training loss: 1.6163619756698608
Validation loss: 2.125358834862709

Epoch: 5| Step: 6
Training loss: 1.1897704601287842
Validation loss: 2.132364645600319

Epoch: 5| Step: 7
Training loss: 2.2502682209014893
Validation loss: 2.128692631920179

Epoch: 5| Step: 8
Training loss: 1.9352680444717407
Validation loss: 2.1323678145805993

Epoch: 5| Step: 9
Training loss: 1.9634872674942017
Validation loss: 2.154940610130628

Epoch: 5| Step: 10
Training loss: 2.1561567783355713
Validation loss: 2.134246418873469

Epoch: 5| Step: 11
Training loss: 1.698233723640442
Validation loss: 2.111608554919561

Epoch: 218| Step: 0
Training loss: 1.9916452169418335
Validation loss: 2.105848083893458

Epoch: 5| Step: 1
Training loss: 1.1851308345794678
Validation loss: 2.100972294807434

Epoch: 5| Step: 2
Training loss: 2.743483304977417
Validation loss: 2.0934447397788367

Epoch: 5| Step: 3
Training loss: 1.9799950122833252
Validation loss: 2.0953019311030707

Epoch: 5| Step: 4
Training loss: 1.9777978658676147
Validation loss: 2.0800020347038903

Epoch: 5| Step: 5
Training loss: 1.6188303232192993
Validation loss: 2.0858956575393677

Epoch: 5| Step: 6
Training loss: 2.2122788429260254
Validation loss: 2.08661879102389

Epoch: 5| Step: 7
Training loss: 1.9931046962738037
Validation loss: 2.0923151870568595

Epoch: 5| Step: 8
Training loss: 2.1578755378723145
Validation loss: 2.089972640077273

Epoch: 5| Step: 9
Training loss: 1.849586844444275
Validation loss: 2.066559667388598

Epoch: 5| Step: 10
Training loss: 2.1728568077087402
Validation loss: 2.087644562125206

Epoch: 5| Step: 11
Training loss: 2.9990367889404297
Validation loss: 2.086377407113711

Epoch: 219| Step: 0
Training loss: 1.8380016088485718
Validation loss: 2.111165697375933

Epoch: 5| Step: 1
Training loss: 1.928052544593811
Validation loss: 2.1333998094002404

Epoch: 5| Step: 2
Training loss: 1.9613723754882812
Validation loss: 2.147578706343969

Epoch: 5| Step: 3
Training loss: 2.1266930103302
Validation loss: 2.145221322774887

Epoch: 5| Step: 4
Training loss: 1.759128212928772
Validation loss: 2.146105503042539

Epoch: 5| Step: 5
Training loss: 1.7996959686279297
Validation loss: 2.143046130736669

Epoch: 5| Step: 6
Training loss: 2.0558626651763916
Validation loss: 2.1289980014165244

Epoch: 5| Step: 7
Training loss: 2.525238275527954
Validation loss: 2.1157863388458886

Epoch: 5| Step: 8
Training loss: 1.7304420471191406
Validation loss: 2.132630859812101

Epoch: 5| Step: 9
Training loss: 1.5787067413330078
Validation loss: 2.113421772917112

Epoch: 5| Step: 10
Training loss: 2.1812686920166016
Validation loss: 2.1190108557542167

Epoch: 5| Step: 11
Training loss: 1.7161154747009277
Validation loss: 2.124484896659851

Epoch: 220| Step: 0
Training loss: 2.4046170711517334
Validation loss: 2.120743210117022

Epoch: 5| Step: 1
Training loss: 1.701425552368164
Validation loss: 2.129710147778193

Epoch: 5| Step: 2
Training loss: 2.0933480262756348
Validation loss: 2.1258835146824517

Epoch: 5| Step: 3
Training loss: 2.331160068511963
Validation loss: 2.1172069807847342

Epoch: 5| Step: 4
Training loss: 1.2386009693145752
Validation loss: 2.136703739563624

Epoch: 5| Step: 5
Training loss: 2.080127239227295
Validation loss: 2.1268493235111237

Epoch: 5| Step: 6
Training loss: 1.7306197881698608
Validation loss: 2.1381044735511145

Epoch: 5| Step: 7
Training loss: 2.1394195556640625
Validation loss: 2.129184345404307

Epoch: 5| Step: 8
Training loss: 1.6529649496078491
Validation loss: 2.135182032982508

Epoch: 5| Step: 9
Training loss: 1.8051989078521729
Validation loss: 2.1203376253445945

Epoch: 5| Step: 10
Training loss: 1.7480865716934204
Validation loss: 2.126784766713778

Epoch: 5| Step: 11
Training loss: 1.0836181640625
Validation loss: 2.108564322193464

Epoch: 221| Step: 0
Training loss: 1.8441661596298218
Validation loss: 2.1167868425448737

Epoch: 5| Step: 1
Training loss: 2.500384569168091
Validation loss: 2.1172166665395102

Epoch: 5| Step: 2
Training loss: 1.1923930644989014
Validation loss: 2.1168155570824942

Epoch: 5| Step: 3
Training loss: 1.841841697692871
Validation loss: 2.0922532081604004

Epoch: 5| Step: 4
Training loss: 2.164501667022705
Validation loss: 2.0977349231640496

Epoch: 5| Step: 5
Training loss: 2.1535792350769043
Validation loss: 2.0984908441702523

Epoch: 5| Step: 6
Training loss: 2.068880558013916
Validation loss: 2.1106401731570563

Epoch: 5| Step: 7
Training loss: 1.9783973693847656
Validation loss: 2.1002127279837928

Epoch: 5| Step: 8
Training loss: 1.9215301275253296
Validation loss: 2.092683623234431

Epoch: 5| Step: 9
Training loss: 1.3160319328308105
Validation loss: 2.1095356146494546

Epoch: 5| Step: 10
Training loss: 1.640203833580017
Validation loss: 2.1070065249999366

Epoch: 5| Step: 11
Training loss: 3.245896816253662
Validation loss: 2.0951710641384125

Epoch: 222| Step: 0
Training loss: 1.7611799240112305
Validation loss: 2.093167409300804

Epoch: 5| Step: 1
Training loss: 2.0159687995910645
Validation loss: 2.0954620043436685

Epoch: 5| Step: 2
Training loss: 1.8594844341278076
Validation loss: 2.081815242767334

Epoch: 5| Step: 3
Training loss: 1.6386102437973022
Validation loss: 2.1031252443790436

Epoch: 5| Step: 4
Training loss: 1.710242509841919
Validation loss: 2.1058026303847632

Epoch: 5| Step: 5
Training loss: 1.7189912796020508
Validation loss: 2.0987878342469535

Epoch: 5| Step: 6
Training loss: 2.128005266189575
Validation loss: 2.1003083686033883

Epoch: 5| Step: 7
Training loss: 2.0691494941711426
Validation loss: 2.1046107908089957

Epoch: 5| Step: 8
Training loss: 1.8728997707366943
Validation loss: 2.1065219144026437

Epoch: 5| Step: 9
Training loss: 1.9016221761703491
Validation loss: 2.116256207227707

Epoch: 5| Step: 10
Training loss: 1.933290719985962
Validation loss: 2.1044244468212128

Epoch: 5| Step: 11
Training loss: 2.914459466934204
Validation loss: 2.1046885500351586

Epoch: 223| Step: 0
Training loss: 2.091219425201416
Validation loss: 2.1048566897710166

Epoch: 5| Step: 1
Training loss: 1.3810436725616455
Validation loss: 2.108739654223124

Epoch: 5| Step: 2
Training loss: 1.7930141687393188
Validation loss: 2.1325308134158454

Epoch: 5| Step: 3
Training loss: 1.502831220626831
Validation loss: 2.132016251484553

Epoch: 5| Step: 4
Training loss: 1.9001985788345337
Validation loss: 2.1150054236253104

Epoch: 5| Step: 5
Training loss: 1.4043017625808716
Validation loss: 2.1234184255202613

Epoch: 5| Step: 6
Training loss: 2.29256272315979
Validation loss: 2.1237498919169107

Epoch: 5| Step: 7
Training loss: 2.0163867473602295
Validation loss: 2.1337931950887046

Epoch: 5| Step: 8
Training loss: 1.625736951828003
Validation loss: 2.1400822599728904

Epoch: 5| Step: 9
Training loss: 1.9853031635284424
Validation loss: 2.118276983499527

Epoch: 5| Step: 10
Training loss: 2.411334991455078
Validation loss: 2.128447418411573

Epoch: 5| Step: 11
Training loss: 2.517971992492676
Validation loss: 2.12739867468675

Epoch: 224| Step: 0
Training loss: 2.0260720252990723
Validation loss: 2.1099847555160522

Epoch: 5| Step: 1
Training loss: 1.1878122091293335
Validation loss: 2.111129621664683

Epoch: 5| Step: 2
Training loss: 2.0912277698516846
Validation loss: 2.0974648793538413

Epoch: 5| Step: 3
Training loss: 1.7428947687149048
Validation loss: 2.0938855161269507

Epoch: 5| Step: 4
Training loss: 1.9153436422348022
Validation loss: 2.113558769226074

Epoch: 5| Step: 5
Training loss: 1.7900879383087158
Validation loss: 2.1136899491151175

Epoch: 5| Step: 6
Training loss: 1.8036006689071655
Validation loss: 2.1099701126416526

Epoch: 5| Step: 7
Training loss: 1.8029981851577759
Validation loss: 2.0990604162216187

Epoch: 5| Step: 8
Training loss: 2.260704755783081
Validation loss: 2.0909071316321692

Epoch: 5| Step: 9
Training loss: 1.5844074487686157
Validation loss: 2.1080370346705117

Epoch: 5| Step: 10
Training loss: 2.61985445022583
Validation loss: 2.112656816840172

Epoch: 5| Step: 11
Training loss: 1.1025222539901733
Validation loss: 2.104683135946592

Epoch: 225| Step: 0
Training loss: 1.6628576517105103
Validation loss: 2.118334804972013

Epoch: 5| Step: 1
Training loss: 1.7785358428955078
Validation loss: 2.1296923458576202

Epoch: 5| Step: 2
Training loss: 2.2524735927581787
Validation loss: 2.1156257490317025

Epoch: 5| Step: 3
Training loss: 2.2763333320617676
Validation loss: 2.138231744368871

Epoch: 5| Step: 4
Training loss: 2.281019687652588
Validation loss: 2.1364861180384955

Epoch: 5| Step: 5
Training loss: 2.035651445388794
Validation loss: 2.141179084777832

Epoch: 5| Step: 6
Training loss: 2.2031924724578857
Validation loss: 2.158223882317543

Epoch: 5| Step: 7
Training loss: 2.181760311126709
Validation loss: 2.1372195333242416

Epoch: 5| Step: 8
Training loss: 1.1823259592056274
Validation loss: 2.1426346947749457

Epoch: 5| Step: 9
Training loss: 1.9841800928115845
Validation loss: 2.1107264707485833

Epoch: 5| Step: 10
Training loss: 1.3283612728118896
Validation loss: 2.1090552310148873

Epoch: 5| Step: 11
Training loss: 1.1518017053604126
Validation loss: 2.098602443933487

Epoch: 226| Step: 0
Training loss: 1.6281769275665283
Validation loss: 2.0975522150595984

Epoch: 5| Step: 1
Training loss: 1.802503228187561
Validation loss: 2.092233935991923

Epoch: 5| Step: 2
Training loss: 1.7092838287353516
Validation loss: 2.1132001280784607

Epoch: 5| Step: 3
Training loss: 1.5130398273468018
Validation loss: 2.112181603908539

Epoch: 5| Step: 4
Training loss: 1.5805637836456299
Validation loss: 2.099625900387764

Epoch: 5| Step: 5
Training loss: 1.7974315881729126
Validation loss: 2.103347599506378

Epoch: 5| Step: 6
Training loss: 1.9603074789047241
Validation loss: 2.115824138124784

Epoch: 5| Step: 7
Training loss: 2.1362290382385254
Validation loss: 2.109219799439112

Epoch: 5| Step: 8
Training loss: 2.1657874584198
Validation loss: 2.1230871180693307

Epoch: 5| Step: 9
Training loss: 2.2488465309143066
Validation loss: 2.130930870771408

Epoch: 5| Step: 10
Training loss: 2.242204189300537
Validation loss: 2.114569365978241

Epoch: 5| Step: 11
Training loss: 0.9184542894363403
Validation loss: 2.1100188891092935

Epoch: 227| Step: 0
Training loss: 2.2656800746917725
Validation loss: 2.1360231737295785

Epoch: 5| Step: 1
Training loss: 2.448082685470581
Validation loss: 2.1303799400726953

Epoch: 5| Step: 2
Training loss: 1.7603365182876587
Validation loss: 2.1323516070842743

Epoch: 5| Step: 3
Training loss: 1.6413424015045166
Validation loss: 2.1178692281246185

Epoch: 5| Step: 4
Training loss: 1.9249147176742554
Validation loss: 2.1198185086250305

Epoch: 5| Step: 5
Training loss: 2.2712759971618652
Validation loss: 2.1132102062304816

Epoch: 5| Step: 6
Training loss: 1.7816118001937866
Validation loss: 2.0973342756430307

Epoch: 5| Step: 7
Training loss: 1.9915157556533813
Validation loss: 2.0885618875424066

Epoch: 5| Step: 8
Training loss: 1.7433326244354248
Validation loss: 2.099405214190483

Epoch: 5| Step: 9
Training loss: 1.2064396142959595
Validation loss: 2.0845442563295364

Epoch: 5| Step: 10
Training loss: 1.9764848947525024
Validation loss: 2.0940277775128684

Epoch: 5| Step: 11
Training loss: 1.6234376430511475
Validation loss: 2.1017146507898965

Epoch: 228| Step: 0
Training loss: 1.6459935903549194
Validation loss: 2.091725746790568

Epoch: 5| Step: 1
Training loss: 1.762478232383728
Validation loss: 2.0898231168588004

Epoch: 5| Step: 2
Training loss: 1.7788188457489014
Validation loss: 2.1089083502689996

Epoch: 5| Step: 3
Training loss: 2.1107258796691895
Validation loss: 2.1040217181046805

Epoch: 5| Step: 4
Training loss: 1.4034833908081055
Validation loss: 2.0964912374814353

Epoch: 5| Step: 5
Training loss: 1.931836724281311
Validation loss: 2.1097407738367715

Epoch: 5| Step: 6
Training loss: 1.8787927627563477
Validation loss: 2.095551609992981

Epoch: 5| Step: 7
Training loss: 2.3638720512390137
Validation loss: 2.1022886435190835

Epoch: 5| Step: 8
Training loss: 1.8893191814422607
Validation loss: 2.081245869398117

Epoch: 5| Step: 9
Training loss: 1.8358001708984375
Validation loss: 2.1148484895626702

Epoch: 5| Step: 10
Training loss: 2.157904624938965
Validation loss: 2.121747781833013

Epoch: 5| Step: 11
Training loss: 2.329944372177124
Validation loss: 2.131331423918406

Epoch: 229| Step: 0
Training loss: 2.0942280292510986
Validation loss: 2.1120263189077377

Epoch: 5| Step: 1
Training loss: 2.1330995559692383
Validation loss: 2.1244163811206818

Epoch: 5| Step: 2
Training loss: 1.8534539937973022
Validation loss: 2.1075141032536826

Epoch: 5| Step: 3
Training loss: 1.7318570613861084
Validation loss: 2.107104554772377

Epoch: 5| Step: 4
Training loss: 1.7095342874526978
Validation loss: 2.120637704928716

Epoch: 5| Step: 5
Training loss: 1.7774394750595093
Validation loss: 2.114332213997841

Epoch: 5| Step: 6
Training loss: 2.1309080123901367
Validation loss: 2.121799965699514

Epoch: 5| Step: 7
Training loss: 1.6084178686141968
Validation loss: 2.1105698545773826

Epoch: 5| Step: 8
Training loss: 1.3782364130020142
Validation loss: 2.1184001117944717

Epoch: 5| Step: 9
Training loss: 2.0335686206817627
Validation loss: 2.1056163012981415

Epoch: 5| Step: 10
Training loss: 2.1117188930511475
Validation loss: 2.120304117600123

Epoch: 5| Step: 11
Training loss: 1.5521469116210938
Validation loss: 2.1251187225182853

Epoch: 230| Step: 0
Training loss: 1.6286237239837646
Validation loss: 2.1434522519508996

Epoch: 5| Step: 1
Training loss: 1.7674989700317383
Validation loss: 2.118159055709839

Epoch: 5| Step: 2
Training loss: 1.4989919662475586
Validation loss: 2.130778024593989

Epoch: 5| Step: 3
Training loss: 1.9536731243133545
Validation loss: 2.1121635188659034

Epoch: 5| Step: 4
Training loss: 2.1584391593933105
Validation loss: 2.1189924081166587

Epoch: 5| Step: 5
Training loss: 2.1620032787323
Validation loss: 2.1276476780573526

Epoch: 5| Step: 6
Training loss: 1.714318871498108
Validation loss: 2.1123183220624924

Epoch: 5| Step: 7
Training loss: 1.7627369165420532
Validation loss: 2.1121556560198465

Epoch: 5| Step: 8
Training loss: 2.2649643421173096
Validation loss: 2.114598532517751

Epoch: 5| Step: 9
Training loss: 1.695373296737671
Validation loss: 2.10847806930542

Epoch: 5| Step: 10
Training loss: 1.957313895225525
Validation loss: 2.1143363068501153

Epoch: 5| Step: 11
Training loss: 1.922463059425354
Validation loss: 2.1158183415730796

Epoch: 231| Step: 0
Training loss: 2.0199475288391113
Validation loss: 2.107867792248726

Epoch: 5| Step: 1
Training loss: 2.1583704948425293
Validation loss: 2.1003622263669968

Epoch: 5| Step: 2
Training loss: 1.92106032371521
Validation loss: 2.1276339987913766

Epoch: 5| Step: 3
Training loss: 1.5382827520370483
Validation loss: 2.1323282718658447

Epoch: 5| Step: 4
Training loss: 1.8654342889785767
Validation loss: 2.122146785259247

Epoch: 5| Step: 5
Training loss: 2.432422399520874
Validation loss: 2.101620450615883

Epoch: 5| Step: 6
Training loss: 1.6665246486663818
Validation loss: 2.1324452807505927

Epoch: 5| Step: 7
Training loss: 1.9432363510131836
Validation loss: 2.117716391881307

Epoch: 5| Step: 8
Training loss: 1.4202340841293335
Validation loss: 2.122110197941462

Epoch: 5| Step: 9
Training loss: 1.7067521810531616
Validation loss: 2.108010878165563

Epoch: 5| Step: 10
Training loss: 1.7571346759796143
Validation loss: 2.1107215881347656

Epoch: 5| Step: 11
Training loss: 1.8500332832336426
Validation loss: 2.1193182120720544

Epoch: 232| Step: 0
Training loss: 1.9973777532577515
Validation loss: 2.128903031349182

Epoch: 5| Step: 1
Training loss: 1.7603212594985962
Validation loss: 2.1249416023492813

Epoch: 5| Step: 2
Training loss: 1.7237573862075806
Validation loss: 2.142127647995949

Epoch: 5| Step: 3
Training loss: 1.8790267705917358
Validation loss: 2.140386422475179

Epoch: 5| Step: 4
Training loss: 1.4180301427841187
Validation loss: 2.1161758402983346

Epoch: 5| Step: 5
Training loss: 2.1012887954711914
Validation loss: 2.1083344519138336

Epoch: 5| Step: 6
Training loss: 1.5859202146530151
Validation loss: 2.112326646844546

Epoch: 5| Step: 7
Training loss: 2.0733001232147217
Validation loss: 2.113301823536555

Epoch: 5| Step: 8
Training loss: 2.311342477798462
Validation loss: 2.0999869058529534

Epoch: 5| Step: 9
Training loss: 2.124729633331299
Validation loss: 2.1087052673101425

Epoch: 5| Step: 10
Training loss: 1.7833747863769531
Validation loss: 2.0985894352197647

Epoch: 5| Step: 11
Training loss: 1.6083762645721436
Validation loss: 2.12137134373188

Epoch: 233| Step: 0
Training loss: 2.0326809883117676
Validation loss: 2.1069188714027405

Epoch: 5| Step: 1
Training loss: 1.9182647466659546
Validation loss: 2.107104649146398

Epoch: 5| Step: 2
Training loss: 1.1184868812561035
Validation loss: 2.1218364536762238

Epoch: 5| Step: 3
Training loss: 2.5251240730285645
Validation loss: 2.1196270237366357

Epoch: 5| Step: 4
Training loss: 1.6361879110336304
Validation loss: 2.130616784095764

Epoch: 5| Step: 5
Training loss: 2.0465188026428223
Validation loss: 2.1460199852784476

Epoch: 5| Step: 6
Training loss: 1.849869966506958
Validation loss: 2.1445015370845795

Epoch: 5| Step: 7
Training loss: 2.353590726852417
Validation loss: 2.137457937002182

Epoch: 5| Step: 8
Training loss: 1.5285732746124268
Validation loss: 2.115638787547747

Epoch: 5| Step: 9
Training loss: 1.8130680322647095
Validation loss: 2.1376132567723594

Epoch: 5| Step: 10
Training loss: 1.9724853038787842
Validation loss: 2.1230125625928244

Epoch: 5| Step: 11
Training loss: 0.9559028744697571
Validation loss: 2.1124794681866965

Epoch: 234| Step: 0
Training loss: 2.2550642490386963
Validation loss: 2.1141263296206794

Epoch: 5| Step: 1
Training loss: 1.359867811203003
Validation loss: 2.1107651442289352

Epoch: 5| Step: 2
Training loss: 2.4116663932800293
Validation loss: 2.1179694732030234

Epoch: 5| Step: 3
Training loss: 1.6728137731552124
Validation loss: 2.126740942398707

Epoch: 5| Step: 4
Training loss: 1.9080498218536377
Validation loss: 2.1162678052981696

Epoch: 5| Step: 5
Training loss: 2.3771049976348877
Validation loss: 2.1186747451623282

Epoch: 5| Step: 6
Training loss: 1.5287338495254517
Validation loss: 2.1217016528050103

Epoch: 5| Step: 7
Training loss: 1.8050645589828491
Validation loss: 2.1034390032291412

Epoch: 5| Step: 8
Training loss: 1.751474142074585
Validation loss: 2.1157900989055634

Epoch: 5| Step: 9
Training loss: 1.4545514583587646
Validation loss: 2.0983285953601203

Epoch: 5| Step: 10
Training loss: 1.9190174341201782
Validation loss: 2.1215958247582116

Epoch: 5| Step: 11
Training loss: 0.9323136806488037
Validation loss: 2.111291393637657

Epoch: 235| Step: 0
Training loss: 1.9367475509643555
Validation loss: 2.116901139418284

Epoch: 5| Step: 1
Training loss: 1.4064959287643433
Validation loss: 2.1031690537929535

Epoch: 5| Step: 2
Training loss: 2.143028497695923
Validation loss: 2.0966409047444663

Epoch: 5| Step: 3
Training loss: 2.2847328186035156
Validation loss: 2.114657108982404

Epoch: 5| Step: 4
Training loss: 1.30373215675354
Validation loss: 2.1225945254166922

Epoch: 5| Step: 5
Training loss: 2.07987380027771
Validation loss: 2.122495025396347

Epoch: 5| Step: 6
Training loss: 1.7774311304092407
Validation loss: 2.1066089272499084

Epoch: 5| Step: 7
Training loss: 1.4516327381134033
Validation loss: 2.136159971356392

Epoch: 5| Step: 8
Training loss: 1.7957398891448975
Validation loss: 2.1088071912527084

Epoch: 5| Step: 9
Training loss: 2.135707139968872
Validation loss: 2.118458236257235

Epoch: 5| Step: 10
Training loss: 1.8454360961914062
Validation loss: 2.1200154622395835

Epoch: 5| Step: 11
Training loss: 2.978151798248291
Validation loss: 2.114336773753166

Epoch: 236| Step: 0
Training loss: 1.7307335138320923
Validation loss: 2.128720283508301

Epoch: 5| Step: 1
Training loss: 1.6198937892913818
Validation loss: 2.1434451589981713

Epoch: 5| Step: 2
Training loss: 2.095343589782715
Validation loss: 2.129475404818853

Epoch: 5| Step: 3
Training loss: 2.4202897548675537
Validation loss: 2.118687371412913

Epoch: 5| Step: 4
Training loss: 1.597036600112915
Validation loss: 2.1114668200413385

Epoch: 5| Step: 5
Training loss: 1.582263708114624
Validation loss: 2.109997401634852

Epoch: 5| Step: 6
Training loss: 2.0659027099609375
Validation loss: 2.119492386778196

Epoch: 5| Step: 7
Training loss: 2.122983932495117
Validation loss: 2.1333165715138116

Epoch: 5| Step: 8
Training loss: 2.009829044342041
Validation loss: 2.1266864836215973

Epoch: 5| Step: 9
Training loss: 1.5701005458831787
Validation loss: 2.121671582261721

Epoch: 5| Step: 10
Training loss: 1.7563676834106445
Validation loss: 2.133634159962336

Epoch: 5| Step: 11
Training loss: 1.1198956966400146
Validation loss: 2.1276154220104218

Epoch: 237| Step: 0
Training loss: 1.575716257095337
Validation loss: 2.1511725236972175

Epoch: 5| Step: 1
Training loss: 2.103724718093872
Validation loss: 2.1469042847553887

Epoch: 5| Step: 2
Training loss: 1.8503925800323486
Validation loss: 2.156788239876429

Epoch: 5| Step: 3
Training loss: 1.8205493688583374
Validation loss: 2.164533426364263

Epoch: 5| Step: 4
Training loss: 2.031470537185669
Validation loss: 2.178560197353363

Epoch: 5| Step: 5
Training loss: 2.3140158653259277
Validation loss: 2.150927891333898

Epoch: 5| Step: 6
Training loss: 1.3137562274932861
Validation loss: 2.146284724275271

Epoch: 5| Step: 7
Training loss: 1.7650444507598877
Validation loss: 2.1335604886213937

Epoch: 5| Step: 8
Training loss: 2.0608110427856445
Validation loss: 2.117982412377993

Epoch: 5| Step: 9
Training loss: 1.8515102863311768
Validation loss: 2.1190619270006814

Epoch: 5| Step: 10
Training loss: 1.7212474346160889
Validation loss: 2.1048791706562042

Epoch: 5| Step: 11
Training loss: 2.805877685546875
Validation loss: 2.1026472647984824

Epoch: 238| Step: 0
Training loss: 1.6504112482070923
Validation loss: 2.111086070537567

Epoch: 5| Step: 1
Training loss: 2.166827440261841
Validation loss: 2.1163137555122375

Epoch: 5| Step: 2
Training loss: 1.6390806436538696
Validation loss: 2.1096353431542716

Epoch: 5| Step: 3
Training loss: 1.9661887884140015
Validation loss: 2.1125859717528024

Epoch: 5| Step: 4
Training loss: 1.9946033954620361
Validation loss: 2.1149493157863617

Epoch: 5| Step: 5
Training loss: 1.7677981853485107
Validation loss: 2.1065198332071304

Epoch: 5| Step: 6
Training loss: 2.308927536010742
Validation loss: 2.132277642687162

Epoch: 5| Step: 7
Training loss: 1.7484782934188843
Validation loss: 2.1368865221738815

Epoch: 5| Step: 8
Training loss: 1.9778757095336914
Validation loss: 2.142286409934362

Epoch: 5| Step: 9
Training loss: 1.817686676979065
Validation loss: 2.149734929203987

Epoch: 5| Step: 10
Training loss: 1.6542091369628906
Validation loss: 2.1652746498584747

Epoch: 5| Step: 11
Training loss: 2.3345835208892822
Validation loss: 2.160908281803131

Epoch: 239| Step: 0
Training loss: 1.6576368808746338
Validation loss: 2.1364340682824454

Epoch: 5| Step: 1
Training loss: 1.4754579067230225
Validation loss: 2.0991730938355126

Epoch: 5| Step: 2
Training loss: 2.321030855178833
Validation loss: 2.1130130191644034

Epoch: 5| Step: 3
Training loss: 2.055305004119873
Validation loss: 2.1108373502890267

Epoch: 5| Step: 4
Training loss: 1.4496862888336182
Validation loss: 2.104227210084597

Epoch: 5| Step: 5
Training loss: 1.7185131311416626
Validation loss: 2.1033319731553397

Epoch: 5| Step: 6
Training loss: 2.046766757965088
Validation loss: 2.0795078376928964

Epoch: 5| Step: 7
Training loss: 1.591017246246338
Validation loss: 2.08576799929142

Epoch: 5| Step: 8
Training loss: 1.8916915655136108
Validation loss: 2.0920976996421814

Epoch: 5| Step: 9
Training loss: 2.638024091720581
Validation loss: 2.0900978296995163

Epoch: 5| Step: 10
Training loss: 1.7838952541351318
Validation loss: 2.0959009528160095

Epoch: 5| Step: 11
Training loss: 2.0224246978759766
Validation loss: 2.090728312730789

Epoch: 240| Step: 0
Training loss: 2.134860038757324
Validation loss: 2.0837387641270957

Epoch: 5| Step: 1
Training loss: 2.131934881210327
Validation loss: 2.096933280428251

Epoch: 5| Step: 2
Training loss: 1.5862643718719482
Validation loss: 2.075650910536448

Epoch: 5| Step: 3
Training loss: 1.9735320806503296
Validation loss: 2.0858897119760513

Epoch: 5| Step: 4
Training loss: 1.6419941186904907
Validation loss: 2.0853035151958466

Epoch: 5| Step: 5
Training loss: 2.017289638519287
Validation loss: 2.1006986846526465

Epoch: 5| Step: 6
Training loss: 1.5628770589828491
Validation loss: 2.084456836183866

Epoch: 5| Step: 7
Training loss: 1.910735845565796
Validation loss: 2.1011672616004944

Epoch: 5| Step: 8
Training loss: 1.8332115411758423
Validation loss: 2.098186587293943

Epoch: 5| Step: 9
Training loss: 2.085880994796753
Validation loss: 2.09160785873731

Epoch: 5| Step: 10
Training loss: 1.6771303415298462
Validation loss: 2.1117207060257592

Epoch: 5| Step: 11
Training loss: 2.2301976680755615
Validation loss: 2.1048434575398765

Epoch: 241| Step: 0
Training loss: 1.7601203918457031
Validation loss: 2.1268197993437448

Epoch: 5| Step: 1
Training loss: 2.0201148986816406
Validation loss: 2.1507536470890045

Epoch: 5| Step: 2
Training loss: 2.100358247756958
Validation loss: 2.1594769855340323

Epoch: 5| Step: 3
Training loss: 1.8031845092773438
Validation loss: 2.170415739218394

Epoch: 5| Step: 4
Training loss: 2.0648486614227295
Validation loss: 2.166836450497309

Epoch: 5| Step: 5
Training loss: 2.0490994453430176
Validation loss: 2.1388332893451056

Epoch: 5| Step: 6
Training loss: 2.0964114665985107
Validation loss: 2.1255384335915246

Epoch: 5| Step: 7
Training loss: 1.9025325775146484
Validation loss: 2.1244809478521347

Epoch: 5| Step: 8
Training loss: 1.9181461334228516
Validation loss: 2.1314491033554077

Epoch: 5| Step: 9
Training loss: 1.41676926612854
Validation loss: 2.1243170549472175

Epoch: 5| Step: 10
Training loss: 1.6540886163711548
Validation loss: 2.1101746360460916

Epoch: 5| Step: 11
Training loss: 0.9527270793914795
Validation loss: 2.1215139677127204

Epoch: 242| Step: 0
Training loss: 1.5970665216445923
Validation loss: 2.131853530804316

Epoch: 5| Step: 1
Training loss: 1.6745092868804932
Validation loss: 2.1232333133618035

Epoch: 5| Step: 2
Training loss: 1.8089189529418945
Validation loss: 2.1275215297937393

Epoch: 5| Step: 3
Training loss: 1.9839344024658203
Validation loss: 2.157484511534373

Epoch: 5| Step: 4
Training loss: 1.2900865077972412
Validation loss: 2.1437959720691047

Epoch: 5| Step: 5
Training loss: 2.093406915664673
Validation loss: 2.1312806804974875

Epoch: 5| Step: 6
Training loss: 1.8862972259521484
Validation loss: 2.1286556323369346

Epoch: 5| Step: 7
Training loss: 2.111487865447998
Validation loss: 2.143628110488256

Epoch: 5| Step: 8
Training loss: 1.6720705032348633
Validation loss: 2.133121828238169

Epoch: 5| Step: 9
Training loss: 1.6940408945083618
Validation loss: 2.1312020421028137

Epoch: 5| Step: 10
Training loss: 2.4485111236572266
Validation loss: 2.119484066963196

Epoch: 5| Step: 11
Training loss: 1.287150263786316
Validation loss: 2.1391612191994986

Epoch: 243| Step: 0
Training loss: 1.7506866455078125
Validation loss: 2.1380206843217215

Epoch: 5| Step: 1
Training loss: 1.4315259456634521
Validation loss: 2.129648213585218

Epoch: 5| Step: 2
Training loss: 1.8576686382293701
Validation loss: 2.140976125995318

Epoch: 5| Step: 3
Training loss: 1.7855613231658936
Validation loss: 2.1299262940883636

Epoch: 5| Step: 4
Training loss: 1.8069050312042236
Validation loss: 2.134823590517044

Epoch: 5| Step: 5
Training loss: 1.2009403705596924
Validation loss: 2.1404229601224265

Epoch: 5| Step: 6
Training loss: 1.5145797729492188
Validation loss: 2.133571738998095

Epoch: 5| Step: 7
Training loss: 2.227430820465088
Validation loss: 2.1417813102404275

Epoch: 5| Step: 8
Training loss: 2.1499886512756348
Validation loss: 2.1471937000751495

Epoch: 5| Step: 9
Training loss: 1.9247825145721436
Validation loss: 2.1508049219846725

Epoch: 5| Step: 10
Training loss: 2.2369577884674072
Validation loss: 2.1277155578136444

Epoch: 5| Step: 11
Training loss: 3.170443058013916
Validation loss: 2.1410960406064987

Epoch: 244| Step: 0
Training loss: 1.809173583984375
Validation loss: 2.1145625015099845

Epoch: 5| Step: 1
Training loss: 1.9104335308074951
Validation loss: 2.134134734670321

Epoch: 5| Step: 2
Training loss: 1.8048839569091797
Validation loss: 2.1270603239536285

Epoch: 5| Step: 3
Training loss: 2.3292806148529053
Validation loss: 2.127789949377378

Epoch: 5| Step: 4
Training loss: 1.8596423864364624
Validation loss: 2.11980410416921

Epoch: 5| Step: 5
Training loss: 1.6942541599273682
Validation loss: 2.116590435306231

Epoch: 5| Step: 6
Training loss: 1.5471808910369873
Validation loss: 2.113863622148832

Epoch: 5| Step: 7
Training loss: 2.4833874702453613
Validation loss: 2.1211100021998086

Epoch: 5| Step: 8
Training loss: 1.8731857538223267
Validation loss: 2.122493878006935

Epoch: 5| Step: 9
Training loss: 2.1903319358825684
Validation loss: 2.1169339219729104

Epoch: 5| Step: 10
Training loss: 1.7172260284423828
Validation loss: 2.130822037657102

Epoch: 5| Step: 11
Training loss: 0.7646472454071045
Validation loss: 2.157381981611252

Epoch: 245| Step: 0
Training loss: 1.7113100290298462
Validation loss: 2.1401639580726624

Epoch: 5| Step: 1
Training loss: 1.7298953533172607
Validation loss: 2.1700233618418374

Epoch: 5| Step: 2
Training loss: 1.6655410528182983
Validation loss: 2.172286649545034

Epoch: 5| Step: 3
Training loss: 2.29825496673584
Validation loss: 2.1579209566116333

Epoch: 5| Step: 4
Training loss: 2.008441209793091
Validation loss: 2.168698956569036

Epoch: 5| Step: 5
Training loss: 2.0999972820281982
Validation loss: 2.132193664709727

Epoch: 5| Step: 6
Training loss: 2.0298550128936768
Validation loss: 2.1386599391698837

Epoch: 5| Step: 7
Training loss: 2.0640711784362793
Validation loss: 2.1112549354632697

Epoch: 5| Step: 8
Training loss: 2.3789222240448
Validation loss: 2.079077402750651

Epoch: 5| Step: 9
Training loss: 1.8911216259002686
Validation loss: 2.095200846592585

Epoch: 5| Step: 10
Training loss: 1.9453281164169312
Validation loss: 2.080602581302325

Epoch: 5| Step: 11
Training loss: 1.788228988647461
Validation loss: 2.0723264068365097

Epoch: 246| Step: 0
Training loss: 1.8965303897857666
Validation loss: 2.079408491651217

Epoch: 5| Step: 1
Training loss: 2.2533974647521973
Validation loss: 2.0800456553697586

Epoch: 5| Step: 2
Training loss: 1.7076040506362915
Validation loss: 2.0754249890645347

Epoch: 5| Step: 3
Training loss: 2.3759825229644775
Validation loss: 2.0768195192019143

Epoch: 5| Step: 4
Training loss: 1.4154627323150635
Validation loss: 2.0893535564343133

Epoch: 5| Step: 5
Training loss: 1.5360572338104248
Validation loss: 2.094347278277079

Epoch: 5| Step: 6
Training loss: 1.7650814056396484
Validation loss: 2.111871153116226

Epoch: 5| Step: 7
Training loss: 2.0842576026916504
Validation loss: 2.112353970607122

Epoch: 5| Step: 8
Training loss: 1.9320297241210938
Validation loss: 2.122035473585129

Epoch: 5| Step: 9
Training loss: 1.804128646850586
Validation loss: 2.126157691081365

Epoch: 5| Step: 10
Training loss: 2.103445529937744
Validation loss: 2.124977558851242

Epoch: 5| Step: 11
Training loss: 1.2655322551727295
Validation loss: 2.1231756458679834

Epoch: 247| Step: 0
Training loss: 1.908612847328186
Validation loss: 2.1318175743023553

Epoch: 5| Step: 1
Training loss: 1.8227609395980835
Validation loss: 2.1195475856463113

Epoch: 5| Step: 2
Training loss: 1.3735809326171875
Validation loss: 2.1162277261416116

Epoch: 5| Step: 3
Training loss: 2.6217756271362305
Validation loss: 2.128354102373123

Epoch: 5| Step: 4
Training loss: 1.9286826848983765
Validation loss: 2.115462670723597

Epoch: 5| Step: 5
Training loss: 1.9099117517471313
Validation loss: 2.1186404625574746

Epoch: 5| Step: 6
Training loss: 1.49471116065979
Validation loss: 2.117154320081075

Epoch: 5| Step: 7
Training loss: 1.622759461402893
Validation loss: 2.1219398031632104

Epoch: 5| Step: 8
Training loss: 1.939217209815979
Validation loss: 2.115839277704557

Epoch: 5| Step: 9
Training loss: 1.771625280380249
Validation loss: 2.1121463775634766

Epoch: 5| Step: 10
Training loss: 1.8771836757659912
Validation loss: 2.117484132448832

Epoch: 5| Step: 11
Training loss: 1.6277176141738892
Validation loss: 2.110300357143084

Epoch: 248| Step: 0
Training loss: 1.6853752136230469
Validation loss: 2.1207191795110703

Epoch: 5| Step: 1
Training loss: 1.9267784357070923
Validation loss: 2.108937626083692

Epoch: 5| Step: 2
Training loss: 2.2483954429626465
Validation loss: 2.1280102878808975

Epoch: 5| Step: 3
Training loss: 1.8585984706878662
Validation loss: 2.1318871527910233

Epoch: 5| Step: 4
Training loss: 1.3776682615280151
Validation loss: 2.122946431239446

Epoch: 5| Step: 5
Training loss: 1.749788522720337
Validation loss: 2.1040212512016296

Epoch: 5| Step: 6
Training loss: 2.090871810913086
Validation loss: 2.1387165834506354

Epoch: 5| Step: 7
Training loss: 1.9308383464813232
Validation loss: 2.1333920061588287

Epoch: 5| Step: 8
Training loss: 1.8212743997573853
Validation loss: 2.1235949297746024

Epoch: 5| Step: 9
Training loss: 2.051848888397217
Validation loss: 2.130466570456823

Epoch: 5| Step: 10
Training loss: 1.8798635005950928
Validation loss: 2.1236459761857986

Epoch: 5| Step: 11
Training loss: 0.5932451486587524
Validation loss: 2.1413191060225167

Epoch: 249| Step: 0
Training loss: 1.453905701637268
Validation loss: 2.1207071344057717

Epoch: 5| Step: 1
Training loss: 2.050896406173706
Validation loss: 2.1224750528732934

Epoch: 5| Step: 2
Training loss: 1.8159068822860718
Validation loss: 2.1333725104729333

Epoch: 5| Step: 3
Training loss: 1.8659824132919312
Validation loss: 2.126993308464686

Epoch: 5| Step: 4
Training loss: 1.339333415031433
Validation loss: 2.133428538839022

Epoch: 5| Step: 5
Training loss: 2.0043323040008545
Validation loss: 2.1290868620077767

Epoch: 5| Step: 6
Training loss: 1.787065863609314
Validation loss: 2.1440834949413934

Epoch: 5| Step: 7
Training loss: 1.7036393880844116
Validation loss: 2.126258745789528

Epoch: 5| Step: 8
Training loss: 2.2588417530059814
Validation loss: 2.1437135438124337

Epoch: 5| Step: 9
Training loss: 2.036372661590576
Validation loss: 2.1464412907759347

Epoch: 5| Step: 10
Training loss: 1.9329875707626343
Validation loss: 2.139955143133799

Epoch: 5| Step: 11
Training loss: 2.8590075969696045
Validation loss: 2.130648543437322

Epoch: 250| Step: 0
Training loss: 1.8662971258163452
Validation loss: 2.1250267773866653

Epoch: 5| Step: 1
Training loss: 2.1968348026275635
Validation loss: 2.121809939543406

Epoch: 5| Step: 2
Training loss: 1.5237575769424438
Validation loss: 2.115068480372429

Epoch: 5| Step: 3
Training loss: 1.776546835899353
Validation loss: 2.1097164104382196

Epoch: 5| Step: 4
Training loss: 1.98490309715271
Validation loss: 2.097305883963903

Epoch: 5| Step: 5
Training loss: 1.6909879446029663
Validation loss: 2.1035463313261666

Epoch: 5| Step: 6
Training loss: 1.813830018043518
Validation loss: 2.11754517753919

Epoch: 5| Step: 7
Training loss: 1.9743735790252686
Validation loss: 2.1201281448205314

Epoch: 5| Step: 8
Training loss: 1.5323517322540283
Validation loss: 2.1047555953264236

Epoch: 5| Step: 9
Training loss: 2.291424512863159
Validation loss: 2.1181346575419107

Epoch: 5| Step: 10
Training loss: 2.181704044342041
Validation loss: 2.104564815759659

Epoch: 5| Step: 11
Training loss: 1.051774501800537
Validation loss: 2.130092685421308

Epoch: 251| Step: 0
Training loss: 2.0711939334869385
Validation loss: 2.137784868478775

Epoch: 5| Step: 1
Training loss: 2.258223533630371
Validation loss: 2.1493332336346307

Epoch: 5| Step: 2
Training loss: 1.839575171470642
Validation loss: 2.1760047574838004

Epoch: 5| Step: 3
Training loss: 1.8442274332046509
Validation loss: 2.1685451765855155

Epoch: 5| Step: 4
Training loss: 1.5136209726333618
Validation loss: 2.1724635660648346

Epoch: 5| Step: 5
Training loss: 1.625354528427124
Validation loss: 2.1708585222562156

Epoch: 5| Step: 6
Training loss: 1.803017020225525
Validation loss: 2.150795966386795

Epoch: 5| Step: 7
Training loss: 1.8573729991912842
Validation loss: 2.1367539316415787

Epoch: 5| Step: 8
Training loss: 1.6789604425430298
Validation loss: 2.1259742428859076

Epoch: 5| Step: 9
Training loss: 1.9857383966445923
Validation loss: 2.1116068164507547

Epoch: 5| Step: 10
Training loss: 1.565220832824707
Validation loss: 2.1140708227952323

Epoch: 5| Step: 11
Training loss: 1.1792025566101074
Validation loss: 2.0928419083356857

Epoch: 252| Step: 0
Training loss: 1.3874831199645996
Validation loss: 2.1250606079896293

Epoch: 5| Step: 1
Training loss: 2.294062376022339
Validation loss: 2.0951682130495706

Epoch: 5| Step: 2
Training loss: 2.106708288192749
Validation loss: 2.111571580171585

Epoch: 5| Step: 3
Training loss: 1.9216458797454834
Validation loss: 2.1171463827292123

Epoch: 5| Step: 4
Training loss: 1.8082565069198608
Validation loss: 2.1271687944730124

Epoch: 5| Step: 5
Training loss: 1.9074757099151611
Validation loss: 2.1080265939235687

Epoch: 5| Step: 6
Training loss: 2.0541958808898926
Validation loss: 2.122906213005384

Epoch: 5| Step: 7
Training loss: 1.3448870182037354
Validation loss: 2.1247320075829825

Epoch: 5| Step: 8
Training loss: 1.5976474285125732
Validation loss: 2.1351940631866455

Epoch: 5| Step: 9
Training loss: 1.14899480342865
Validation loss: 2.1531153321266174

Epoch: 5| Step: 10
Training loss: 2.0603106021881104
Validation loss: 2.1611110071341195

Epoch: 5| Step: 11
Training loss: 2.818575859069824
Validation loss: 2.1546891580025354

Epoch: 253| Step: 0
Training loss: 2.2451112270355225
Validation loss: 2.1643599520126977

Epoch: 5| Step: 1
Training loss: 1.9858105182647705
Validation loss: 2.1346388210852942

Epoch: 5| Step: 2
Training loss: 1.594956636428833
Validation loss: 2.1015982627868652

Epoch: 5| Step: 3
Training loss: 1.9755260944366455
Validation loss: 2.1120262344678244

Epoch: 5| Step: 4
Training loss: 1.8002580404281616
Validation loss: 2.09642002483209

Epoch: 5| Step: 5
Training loss: 1.6731421947479248
Validation loss: 2.11540379623572

Epoch: 5| Step: 6
Training loss: 1.6540254354476929
Validation loss: 2.116047963500023

Epoch: 5| Step: 7
Training loss: 1.461730718612671
Validation loss: 2.107176105181376

Epoch: 5| Step: 8
Training loss: 1.1578590869903564
Validation loss: 2.101375083128611

Epoch: 5| Step: 9
Training loss: 2.296339511871338
Validation loss: 2.093317141135534

Epoch: 5| Step: 10
Training loss: 2.5848097801208496
Validation loss: 2.1092105209827423

Epoch: 5| Step: 11
Training loss: 1.21864652633667
Validation loss: 2.0986276268959045

Epoch: 254| Step: 0
Training loss: 1.948857069015503
Validation loss: 2.114104226231575

Epoch: 5| Step: 1
Training loss: 1.34835684299469
Validation loss: 2.113528251647949

Epoch: 5| Step: 2
Training loss: 2.7983932495117188
Validation loss: 2.120247612396876

Epoch: 5| Step: 3
Training loss: 1.5820748805999756
Validation loss: 2.130336786309878

Epoch: 5| Step: 4
Training loss: 1.3988449573516846
Validation loss: 2.1523761997620263

Epoch: 5| Step: 5
Training loss: 2.0644450187683105
Validation loss: 2.1426392098267875

Epoch: 5| Step: 6
Training loss: 2.544121742248535
Validation loss: 2.1397027522325516

Epoch: 5| Step: 7
Training loss: 1.3728656768798828
Validation loss: 2.138274590174357

Epoch: 5| Step: 8
Training loss: 1.692477822303772
Validation loss: 2.1502700746059418

Epoch: 5| Step: 9
Training loss: 1.5943520069122314
Validation loss: 2.138884648680687

Epoch: 5| Step: 10
Training loss: 1.6838287115097046
Validation loss: 2.1378016571203866

Epoch: 5| Step: 11
Training loss: 1.7469055652618408
Validation loss: 2.145865390698115

Epoch: 255| Step: 0
Training loss: 1.5918852090835571
Validation loss: 2.1496410171190896

Epoch: 5| Step: 1
Training loss: 1.9281280040740967
Validation loss: 2.1531215061744056

Epoch: 5| Step: 2
Training loss: 1.8226165771484375
Validation loss: 2.1498186687628427

Epoch: 5| Step: 3
Training loss: 1.862367868423462
Validation loss: 2.165008137623469

Epoch: 5| Step: 4
Training loss: 1.4718427658081055
Validation loss: 2.1524780640999475

Epoch: 5| Step: 5
Training loss: 1.582639217376709
Validation loss: 2.142793590823809

Epoch: 5| Step: 6
Training loss: 2.186378002166748
Validation loss: 2.1375279426574707

Epoch: 5| Step: 7
Training loss: 1.7342246770858765
Validation loss: 2.1283885737260184

Epoch: 5| Step: 8
Training loss: 1.8159176111221313
Validation loss: 2.12272909283638

Epoch: 5| Step: 9
Training loss: 1.312583327293396
Validation loss: 2.1314053535461426

Epoch: 5| Step: 10
Training loss: 2.5026893615722656
Validation loss: 2.1149742901325226

Epoch: 5| Step: 11
Training loss: 1.2126811742782593
Validation loss: 2.109853367010752

Epoch: 256| Step: 0
Training loss: 2.67457914352417
Validation loss: 2.1088035106658936

Epoch: 5| Step: 1
Training loss: 1.6110670566558838
Validation loss: 2.116903285185496

Epoch: 5| Step: 2
Training loss: 1.4220261573791504
Validation loss: 2.1269130259752274

Epoch: 5| Step: 3
Training loss: 2.209733486175537
Validation loss: 2.1223991264899573

Epoch: 5| Step: 4
Training loss: 1.4386080503463745
Validation loss: 2.101411685347557

Epoch: 5| Step: 5
Training loss: 1.9515612125396729
Validation loss: 2.10455551246802

Epoch: 5| Step: 6
Training loss: 1.5286487340927124
Validation loss: 2.1013717552026114

Epoch: 5| Step: 7
Training loss: 2.071786403656006
Validation loss: 2.092220346132914

Epoch: 5| Step: 8
Training loss: 1.580519199371338
Validation loss: 2.097747817635536

Epoch: 5| Step: 9
Training loss: 1.5181876420974731
Validation loss: 2.0998514741659164

Epoch: 5| Step: 10
Training loss: 2.1821374893188477
Validation loss: 2.097380737463633

Epoch: 5| Step: 11
Training loss: 3.2889151573181152
Validation loss: 2.125951344768206

Epoch: 257| Step: 0
Training loss: 1.741172194480896
Validation loss: 2.109765350818634

Epoch: 5| Step: 1
Training loss: 1.7636539936065674
Validation loss: 2.137048363685608

Epoch: 5| Step: 2
Training loss: 1.6315507888793945
Validation loss: 2.124380220969518

Epoch: 5| Step: 3
Training loss: 2.2214415073394775
Validation loss: 2.122255429625511

Epoch: 5| Step: 4
Training loss: 1.9312498569488525
Validation loss: 2.1319886495669684

Epoch: 5| Step: 5
Training loss: 1.290126085281372
Validation loss: 2.133040343721708

Epoch: 5| Step: 6
Training loss: 1.5079796314239502
Validation loss: 2.134219159682592

Epoch: 5| Step: 7
Training loss: 1.8160655498504639
Validation loss: 2.1421860655148826

Epoch: 5| Step: 8
Training loss: 2.130312919616699
Validation loss: 2.124662439028422

Epoch: 5| Step: 9
Training loss: 1.594811201095581
Validation loss: 2.160627454519272

Epoch: 5| Step: 10
Training loss: 2.0092692375183105
Validation loss: 2.1823358635107675

Epoch: 5| Step: 11
Training loss: 1.6930406093597412
Validation loss: 2.1695798337459564

Epoch: 258| Step: 0
Training loss: 1.7399839162826538
Validation loss: 2.1968048562606177

Epoch: 5| Step: 1
Training loss: 1.5977586507797241
Validation loss: 2.160042251149813

Epoch: 5| Step: 2
Training loss: 1.7185999155044556
Validation loss: 2.1554924050966897

Epoch: 5| Step: 3
Training loss: 1.7159801721572876
Validation loss: 2.1604439318180084

Epoch: 5| Step: 4
Training loss: 2.3412868976593018
Validation loss: 2.1369088838497796

Epoch: 5| Step: 5
Training loss: 1.5717099905014038
Validation loss: 2.1319439808527627

Epoch: 5| Step: 6
Training loss: 2.1698951721191406
Validation loss: 2.104742705821991

Epoch: 5| Step: 7
Training loss: 1.8997207880020142
Validation loss: 2.1000155260165534

Epoch: 5| Step: 8
Training loss: 1.5883384943008423
Validation loss: 2.1015175928672156

Epoch: 5| Step: 9
Training loss: 1.9534832239151
Validation loss: 2.090001662572225

Epoch: 5| Step: 10
Training loss: 1.6536080837249756
Validation loss: 2.103443294763565

Epoch: 5| Step: 11
Training loss: 2.8263063430786133
Validation loss: 2.1004244536161423

Epoch: 259| Step: 0
Training loss: 2.2580080032348633
Validation loss: 2.1045106252034507

Epoch: 5| Step: 1
Training loss: 1.6157619953155518
Validation loss: 2.114927589893341

Epoch: 5| Step: 2
Training loss: 2.3186798095703125
Validation loss: 2.101825778683027

Epoch: 5| Step: 3
Training loss: 1.740584373474121
Validation loss: 2.103396018346151

Epoch: 5| Step: 4
Training loss: 2.4136130809783936
Validation loss: 2.115732356905937

Epoch: 5| Step: 5
Training loss: 2.080378770828247
Validation loss: 2.108294074734052

Epoch: 5| Step: 6
Training loss: 1.8721050024032593
Validation loss: 2.115402658780416

Epoch: 5| Step: 7
Training loss: 1.995261549949646
Validation loss: 2.088501453399658

Epoch: 5| Step: 8
Training loss: 1.3467438220977783
Validation loss: 2.1148425936698914

Epoch: 5| Step: 9
Training loss: 1.662418007850647
Validation loss: 2.129761944214503

Epoch: 5| Step: 10
Training loss: 1.826551079750061
Validation loss: 2.131464794278145

Epoch: 5| Step: 11
Training loss: 1.8052268028259277
Validation loss: 2.1292920112609863

Epoch: 260| Step: 0
Training loss: 2.60908842086792
Validation loss: 2.1438588996728263

Epoch: 5| Step: 1
Training loss: 1.7621959447860718
Validation loss: 2.156900723775228

Epoch: 5| Step: 2
Training loss: 1.7786709070205688
Validation loss: 2.155056431889534

Epoch: 5| Step: 3
Training loss: 1.61565363407135
Validation loss: 2.144126986463865

Epoch: 5| Step: 4
Training loss: 1.4010965824127197
Validation loss: 2.139507999022802

Epoch: 5| Step: 5
Training loss: 1.7787147760391235
Validation loss: 2.1195993026097617

Epoch: 5| Step: 6
Training loss: 2.1154744625091553
Validation loss: 2.129990816116333

Epoch: 5| Step: 7
Training loss: 2.344897508621216
Validation loss: 2.1172852317492166

Epoch: 5| Step: 8
Training loss: 1.301439881324768
Validation loss: 2.114262049396833

Epoch: 5| Step: 9
Training loss: 1.4515635967254639
Validation loss: 2.122185895840327

Epoch: 5| Step: 10
Training loss: 1.8710310459136963
Validation loss: 2.1219804088274636

Epoch: 5| Step: 11
Training loss: 3.1664278507232666
Validation loss: 2.1450764189163842

Epoch: 261| Step: 0
Training loss: 1.7553085088729858
Validation loss: 2.133758991956711

Epoch: 5| Step: 1
Training loss: 1.7374576330184937
Validation loss: 2.1569630404313407

Epoch: 5| Step: 2
Training loss: 1.7203454971313477
Validation loss: 2.151161640882492

Epoch: 5| Step: 3
Training loss: 2.103719711303711
Validation loss: 2.1399669150511422

Epoch: 5| Step: 4
Training loss: 2.3030872344970703
Validation loss: 2.120992213487625

Epoch: 5| Step: 5
Training loss: 1.7357069253921509
Validation loss: 2.1244167933861413

Epoch: 5| Step: 6
Training loss: 1.2037986516952515
Validation loss: 2.137999395529429

Epoch: 5| Step: 7
Training loss: 1.440312385559082
Validation loss: 2.1133144795894623

Epoch: 5| Step: 8
Training loss: 1.9070427417755127
Validation loss: 2.130206589897474

Epoch: 5| Step: 9
Training loss: 2.0939040184020996
Validation loss: 2.129511555035909

Epoch: 5| Step: 10
Training loss: 1.5968472957611084
Validation loss: 2.1384842693805695

Epoch: 5| Step: 11
Training loss: 1.5313464403152466
Validation loss: 2.1069428573052087

Epoch: 262| Step: 0
Training loss: 2.149479389190674
Validation loss: 2.1135348677635193

Epoch: 5| Step: 1
Training loss: 2.2737653255462646
Validation loss: 2.1110208928585052

Epoch: 5| Step: 2
Training loss: 1.7656627893447876
Validation loss: 2.122162620226542

Epoch: 5| Step: 3
Training loss: 1.8556238412857056
Validation loss: 2.1268327981233597

Epoch: 5| Step: 4
Training loss: 1.5273630619049072
Validation loss: 2.1297248850266137

Epoch: 5| Step: 5
Training loss: 1.8556482791900635
Validation loss: 2.1335150549809136

Epoch: 5| Step: 6
Training loss: 1.2694600820541382
Validation loss: 2.1345500449339547

Epoch: 5| Step: 7
Training loss: 1.6992391347885132
Validation loss: 2.138804107904434

Epoch: 5| Step: 8
Training loss: 1.589953064918518
Validation loss: 2.1461295783519745

Epoch: 5| Step: 9
Training loss: 1.768183708190918
Validation loss: 2.150258556008339

Epoch: 5| Step: 10
Training loss: 2.1244020462036133
Validation loss: 2.1550575544436774

Epoch: 5| Step: 11
Training loss: 1.604207992553711
Validation loss: 2.155523498853048

Epoch: 263| Step: 0
Training loss: 1.9360090494155884
Validation loss: 2.160340984662374

Epoch: 5| Step: 1
Training loss: 1.7537120580673218
Validation loss: 2.1532852898041406

Epoch: 5| Step: 2
Training loss: 2.2557473182678223
Validation loss: 2.136007477839788

Epoch: 5| Step: 3
Training loss: 2.1610374450683594
Validation loss: 2.147984360655149

Epoch: 5| Step: 4
Training loss: 1.7008049488067627
Validation loss: 2.148264472683271

Epoch: 5| Step: 5
Training loss: 2.032867908477783
Validation loss: 2.142186552286148

Epoch: 5| Step: 6
Training loss: 2.0529704093933105
Validation loss: 2.1325538208087287

Epoch: 5| Step: 7
Training loss: 1.0592893362045288
Validation loss: 2.139150381088257

Epoch: 5| Step: 8
Training loss: 1.1612071990966797
Validation loss: 2.1216996014118195

Epoch: 5| Step: 9
Training loss: 1.7408411502838135
Validation loss: 2.1462724208831787

Epoch: 5| Step: 10
Training loss: 1.7731304168701172
Validation loss: 2.1412786543369293

Epoch: 5| Step: 11
Training loss: 0.5649093985557556
Validation loss: 2.1552955309549966

Epoch: 264| Step: 0
Training loss: 1.9179832935333252
Validation loss: 2.1418748001257577

Epoch: 5| Step: 1
Training loss: 1.5505354404449463
Validation loss: 2.140764743089676

Epoch: 5| Step: 2
Training loss: 1.5722110271453857
Validation loss: 2.1606272210677466

Epoch: 5| Step: 3
Training loss: 1.44918954372406
Validation loss: 2.1668416460355124

Epoch: 5| Step: 4
Training loss: 1.743064522743225
Validation loss: 2.1601191461086273

Epoch: 5| Step: 5
Training loss: 1.705270767211914
Validation loss: 2.1501759042342505

Epoch: 5| Step: 6
Training loss: 2.206480026245117
Validation loss: 2.154671475291252

Epoch: 5| Step: 7
Training loss: 1.698908805847168
Validation loss: 2.134838064511617

Epoch: 5| Step: 8
Training loss: 2.1699836254119873
Validation loss: 2.125930825869242

Epoch: 5| Step: 9
Training loss: 1.7423921823501587
Validation loss: 2.119247461358706

Epoch: 5| Step: 10
Training loss: 1.7279434204101562
Validation loss: 2.1343582471211753

Epoch: 5| Step: 11
Training loss: 1.3144721984863281
Validation loss: 2.1302251120408378

Epoch: 265| Step: 0
Training loss: 1.8105682134628296
Validation loss: 2.113612875342369

Epoch: 5| Step: 1
Training loss: 1.3460958003997803
Validation loss: 2.126666004459063

Epoch: 5| Step: 2
Training loss: 1.8666967153549194
Validation loss: 2.1332457214593887

Epoch: 5| Step: 3
Training loss: 2.2576217651367188
Validation loss: 2.151550908883413

Epoch: 5| Step: 4
Training loss: 1.3080189228057861
Validation loss: 2.1157351533571878

Epoch: 5| Step: 5
Training loss: 1.9290450811386108
Validation loss: 2.131703734397888

Epoch: 5| Step: 6
Training loss: 1.7062928676605225
Validation loss: 2.1329579253991446

Epoch: 5| Step: 7
Training loss: 1.5754504203796387
Validation loss: 2.118040273586909

Epoch: 5| Step: 8
Training loss: 2.3465752601623535
Validation loss: 2.1137517591317496

Epoch: 5| Step: 9
Training loss: 1.3835350275039673
Validation loss: 2.1389988462130227

Epoch: 5| Step: 10
Training loss: 1.8900279998779297
Validation loss: 2.1251059969266257

Epoch: 5| Step: 11
Training loss: 1.4659276008605957
Validation loss: 2.132455895344416

Epoch: 266| Step: 0
Training loss: 1.211395263671875
Validation loss: 2.118713637193044

Epoch: 5| Step: 1
Training loss: 1.631412148475647
Validation loss: 2.1146993786096573

Epoch: 5| Step: 2
Training loss: 1.9490253925323486
Validation loss: 2.115446016192436

Epoch: 5| Step: 3
Training loss: 1.3057124614715576
Validation loss: 2.1078732162714005

Epoch: 5| Step: 4
Training loss: 2.2752273082733154
Validation loss: 2.108298440774282

Epoch: 5| Step: 5
Training loss: 1.5080163478851318
Validation loss: 2.101262013117472

Epoch: 5| Step: 6
Training loss: 1.636265516281128
Validation loss: 2.123140051960945

Epoch: 5| Step: 7
Training loss: 2.259546995162964
Validation loss: 2.132523755232493

Epoch: 5| Step: 8
Training loss: 1.9030075073242188
Validation loss: 2.138224999109904

Epoch: 5| Step: 9
Training loss: 1.7983970642089844
Validation loss: 2.127324640750885

Epoch: 5| Step: 10
Training loss: 2.2298200130462646
Validation loss: 2.144984016815821

Epoch: 5| Step: 11
Training loss: 1.1482458114624023
Validation loss: 2.134784077604612

Epoch: 267| Step: 0
Training loss: 1.7030376195907593
Validation loss: 2.1441744764645896

Epoch: 5| Step: 1
Training loss: 1.7581866979599
Validation loss: 2.151916896303495

Epoch: 5| Step: 2
Training loss: 2.0670104026794434
Validation loss: 2.1450852851072946

Epoch: 5| Step: 3
Training loss: 1.860338807106018
Validation loss: 2.148335114121437

Epoch: 5| Step: 4
Training loss: 1.784339189529419
Validation loss: 2.149235333005587

Epoch: 5| Step: 5
Training loss: 1.3647692203521729
Validation loss: 2.1397525469462075

Epoch: 5| Step: 6
Training loss: 1.9508765935897827
Validation loss: 2.1215257396300635

Epoch: 5| Step: 7
Training loss: 1.4414732456207275
Validation loss: 2.133676052093506

Epoch: 5| Step: 8
Training loss: 2.2021753787994385
Validation loss: 2.1442680259545646

Epoch: 5| Step: 9
Training loss: 1.7331688404083252
Validation loss: 2.140485386053721

Epoch: 5| Step: 10
Training loss: 1.4810782670974731
Validation loss: 2.1489740212758384

Epoch: 5| Step: 11
Training loss: 2.908447504043579
Validation loss: 2.129008690516154

Epoch: 268| Step: 0
Training loss: 1.1773736476898193
Validation loss: 2.11517841120561

Epoch: 5| Step: 1
Training loss: 2.0009922981262207
Validation loss: 2.125086093942324

Epoch: 5| Step: 2
Training loss: 1.8244091272354126
Validation loss: 2.1263629347085953

Epoch: 5| Step: 3
Training loss: 1.9730602502822876
Validation loss: 2.129665498932203

Epoch: 5| Step: 4
Training loss: 1.9872909784317017
Validation loss: 2.142545407017072

Epoch: 5| Step: 5
Training loss: 1.4867674112319946
Validation loss: 2.132487306992213

Epoch: 5| Step: 6
Training loss: 1.6081136465072632
Validation loss: 2.1645560761292777

Epoch: 5| Step: 7
Training loss: 1.8537237644195557
Validation loss: 2.1400786389907203

Epoch: 5| Step: 8
Training loss: 1.879981279373169
Validation loss: 2.1510782738526664

Epoch: 5| Step: 9
Training loss: 1.7158451080322266
Validation loss: 2.137316515048345

Epoch: 5| Step: 10
Training loss: 2.1209518909454346
Validation loss: 2.150803193449974

Epoch: 5| Step: 11
Training loss: 0.8901704549789429
Validation loss: 2.137450695037842

Epoch: 269| Step: 0
Training loss: 1.281773567199707
Validation loss: 2.1221261024475098

Epoch: 5| Step: 1
Training loss: 2.552980422973633
Validation loss: 2.1252155005931854

Epoch: 5| Step: 2
Training loss: 1.8728835582733154
Validation loss: 2.1236294358968735

Epoch: 5| Step: 3
Training loss: 1.6691749095916748
Validation loss: 2.127820466955503

Epoch: 5| Step: 4
Training loss: 1.7760788202285767
Validation loss: 2.1245216727256775

Epoch: 5| Step: 5
Training loss: 2.0854296684265137
Validation loss: 2.1161198069651923

Epoch: 5| Step: 6
Training loss: 1.9228423833847046
Validation loss: 2.113647386431694

Epoch: 5| Step: 7
Training loss: 1.5779415369033813
Validation loss: 2.1366380751132965

Epoch: 5| Step: 8
Training loss: 1.5233900547027588
Validation loss: 2.126026357213656

Epoch: 5| Step: 9
Training loss: 1.6818091869354248
Validation loss: 2.1400878727436066

Epoch: 5| Step: 10
Training loss: 1.781221628189087
Validation loss: 2.1575519889593124

Epoch: 5| Step: 11
Training loss: 0.9615625143051147
Validation loss: 2.168563505013784

Epoch: 270| Step: 0
Training loss: 1.9314254522323608
Validation loss: 2.184484531482061

Epoch: 5| Step: 1
Training loss: 1.571697473526001
Validation loss: 2.208374852935473

Epoch: 5| Step: 2
Training loss: 2.092689037322998
Validation loss: 2.2020918428897858

Epoch: 5| Step: 3
Training loss: 1.6485296487808228
Validation loss: 2.190416450301806

Epoch: 5| Step: 4
Training loss: 1.7858613729476929
Validation loss: 2.164867694179217

Epoch: 5| Step: 5
Training loss: 1.8219432830810547
Validation loss: 2.1422065248092017

Epoch: 5| Step: 6
Training loss: 1.3543721437454224
Validation loss: 2.128377149502436

Epoch: 5| Step: 7
Training loss: 1.4995931386947632
Validation loss: 2.1248891005913415

Epoch: 5| Step: 8
Training loss: 1.8168799877166748
Validation loss: 2.1391316999991736

Epoch: 5| Step: 9
Training loss: 2.4500932693481445
Validation loss: 2.1297650883595147

Epoch: 5| Step: 10
Training loss: 1.6379743814468384
Validation loss: 2.105002999305725

Epoch: 5| Step: 11
Training loss: 0.6770297288894653
Validation loss: 2.105168412129084

Epoch: 271| Step: 0
Training loss: 1.5521959066390991
Validation loss: 2.119169076283773

Epoch: 5| Step: 1
Training loss: 1.6885721683502197
Validation loss: 2.1147738844156265

Epoch: 5| Step: 2
Training loss: 1.4878647327423096
Validation loss: 2.119651213288307

Epoch: 5| Step: 3
Training loss: 1.8473345041275024
Validation loss: 2.1356617212295532

Epoch: 5| Step: 4
Training loss: 1.5522915124893188
Validation loss: 2.123715028166771

Epoch: 5| Step: 5
Training loss: 1.6333892345428467
Validation loss: 2.1401180773973465

Epoch: 5| Step: 6
Training loss: 2.347881555557251
Validation loss: 2.1416969001293182

Epoch: 5| Step: 7
Training loss: 1.1817277669906616
Validation loss: 2.144131620724996

Epoch: 5| Step: 8
Training loss: 2.555880546569824
Validation loss: 2.1384997268517814

Epoch: 5| Step: 9
Training loss: 1.3951035737991333
Validation loss: 2.12906921406587

Epoch: 5| Step: 10
Training loss: 1.7496665716171265
Validation loss: 2.1457909643650055

Epoch: 5| Step: 11
Training loss: 2.259193181991577
Validation loss: 2.1485543747742972

Epoch: 272| Step: 0
Training loss: 1.5922644138336182
Validation loss: 2.146457006533941

Epoch: 5| Step: 1
Training loss: 1.544065237045288
Validation loss: 2.1437734812498093

Epoch: 5| Step: 2
Training loss: 2.6280369758605957
Validation loss: 2.1103881498177848

Epoch: 5| Step: 3
Training loss: 1.8676650524139404
Validation loss: 2.1399867137273154

Epoch: 5| Step: 4
Training loss: 1.6906408071517944
Validation loss: 2.148386831084887

Epoch: 5| Step: 5
Training loss: 1.2458195686340332
Validation loss: 2.132603421807289

Epoch: 5| Step: 6
Training loss: 1.6249864101409912
Validation loss: 2.1540544678767524

Epoch: 5| Step: 7
Training loss: 1.7879451513290405
Validation loss: 2.135781372586886

Epoch: 5| Step: 8
Training loss: 1.5304945707321167
Validation loss: 2.1317296226819358

Epoch: 5| Step: 9
Training loss: 1.6987876892089844
Validation loss: 2.1371753811836243

Epoch: 5| Step: 10
Training loss: 1.704174280166626
Validation loss: 2.113783766825994

Epoch: 5| Step: 11
Training loss: 2.7599964141845703
Validation loss: 2.14572636783123

Epoch: 273| Step: 0
Training loss: 2.108104705810547
Validation loss: 2.1292579621076584

Epoch: 5| Step: 1
Training loss: 1.5119916200637817
Validation loss: 2.1297516425450644

Epoch: 5| Step: 2
Training loss: 1.2757213115692139
Validation loss: 2.12574910124143

Epoch: 5| Step: 3
Training loss: 1.7115366458892822
Validation loss: 2.126417100429535

Epoch: 5| Step: 4
Training loss: 2.4740376472473145
Validation loss: 2.1444617410500846

Epoch: 5| Step: 5
Training loss: 1.414241075515747
Validation loss: 2.1604379614194236

Epoch: 5| Step: 6
Training loss: 1.3052350282669067
Validation loss: 2.1540704667568207

Epoch: 5| Step: 7
Training loss: 2.0311737060546875
Validation loss: 2.179833789666494

Epoch: 5| Step: 8
Training loss: 1.4917651414871216
Validation loss: 2.16873200237751

Epoch: 5| Step: 9
Training loss: 1.8114721775054932
Validation loss: 2.1750389287869134

Epoch: 5| Step: 10
Training loss: 1.920859932899475
Validation loss: 2.1630571484565735

Epoch: 5| Step: 11
Training loss: 2.514051914215088
Validation loss: 2.139789784948031

Epoch: 274| Step: 0
Training loss: 2.4552230834960938
Validation loss: 2.1469888587792716

Epoch: 5| Step: 1
Training loss: 2.144575834274292
Validation loss: 2.1683903137842813

Epoch: 5| Step: 2
Training loss: 1.5389902591705322
Validation loss: 2.1905446549256644

Epoch: 5| Step: 3
Training loss: 1.6537424325942993
Validation loss: 2.1870500991741815

Epoch: 5| Step: 4
Training loss: 1.2558988332748413
Validation loss: 2.2051707804203033

Epoch: 5| Step: 5
Training loss: 1.81134831905365
Validation loss: 2.1897336492935815

Epoch: 5| Step: 6
Training loss: 2.083235263824463
Validation loss: 2.20588755607605

Epoch: 5| Step: 7
Training loss: 1.4578027725219727
Validation loss: 2.213281288743019

Epoch: 5| Step: 8
Training loss: 1.633188009262085
Validation loss: 2.156679814060529

Epoch: 5| Step: 9
Training loss: 1.3877089023590088
Validation loss: 2.1585720032453537

Epoch: 5| Step: 10
Training loss: 1.8633254766464233
Validation loss: 2.136137291789055

Epoch: 5| Step: 11
Training loss: 1.6706314086914062
Validation loss: 2.129805877804756

Epoch: 275| Step: 0
Training loss: 1.7345964908599854
Validation loss: 2.1299935380617776

Epoch: 5| Step: 1
Training loss: 1.9176400899887085
Validation loss: 2.1339857329924903

Epoch: 5| Step: 2
Training loss: 1.4958384037017822
Validation loss: 2.115832214554151

Epoch: 5| Step: 3
Training loss: 1.6604408025741577
Validation loss: 2.128861725330353

Epoch: 5| Step: 4
Training loss: 1.668168067932129
Validation loss: 2.128853435317675

Epoch: 5| Step: 5
Training loss: 1.864916205406189
Validation loss: 2.11924746632576

Epoch: 5| Step: 6
Training loss: 1.6157957315444946
Validation loss: 2.1347352415323257

Epoch: 5| Step: 7
Training loss: 1.3898544311523438
Validation loss: 2.147005101044973

Epoch: 5| Step: 8
Training loss: 1.2517478466033936
Validation loss: 2.1376871864000955

Epoch: 5| Step: 9
Training loss: 1.8627731800079346
Validation loss: 2.129462038477262

Epoch: 5| Step: 10
Training loss: 2.575056314468384
Validation loss: 2.1094998915990195

Epoch: 5| Step: 11
Training loss: 2.3062398433685303
Validation loss: 2.1313505123058953

Epoch: 276| Step: 0
Training loss: 2.2316012382507324
Validation loss: 2.1231472541888556

Epoch: 5| Step: 1
Training loss: 1.2923377752304077
Validation loss: 2.103875438372294

Epoch: 5| Step: 2
Training loss: 1.4702730178833008
Validation loss: 2.124818275372187

Epoch: 5| Step: 3
Training loss: 1.5488452911376953
Validation loss: 2.103247736891111

Epoch: 5| Step: 4
Training loss: 2.0548267364501953
Validation loss: 2.11309743920962

Epoch: 5| Step: 5
Training loss: 1.7173182964324951
Validation loss: 2.098444620768229

Epoch: 5| Step: 6
Training loss: 1.9355636835098267
Validation loss: 2.0908539245525994

Epoch: 5| Step: 7
Training loss: 1.945111870765686
Validation loss: 2.1080128798882165

Epoch: 5| Step: 8
Training loss: 1.9512519836425781
Validation loss: 2.100545530517896

Epoch: 5| Step: 9
Training loss: 1.3517324924468994
Validation loss: 2.1058454364538193

Epoch: 5| Step: 10
Training loss: 1.809511423110962
Validation loss: 2.10883762439092

Epoch: 5| Step: 11
Training loss: 1.7689456939697266
Validation loss: 2.107355276743571

Epoch: 277| Step: 0
Training loss: 2.173093795776367
Validation loss: 2.106663649280866

Epoch: 5| Step: 1
Training loss: 1.7275092601776123
Validation loss: 2.1184903979301453

Epoch: 5| Step: 2
Training loss: 1.472414493560791
Validation loss: 2.12010229130586

Epoch: 5| Step: 3
Training loss: 1.9268653392791748
Validation loss: 2.1133390069007874

Epoch: 5| Step: 4
Training loss: 2.3250207901000977
Validation loss: 2.126899093389511

Epoch: 5| Step: 5
Training loss: 1.8129228353500366
Validation loss: 2.125835100809733

Epoch: 5| Step: 6
Training loss: 1.3614146709442139
Validation loss: 2.1209691017866135

Epoch: 5| Step: 7
Training loss: 1.6176869869232178
Validation loss: 2.147518113255501

Epoch: 5| Step: 8
Training loss: 1.609541654586792
Validation loss: 2.1373857905467353

Epoch: 5| Step: 9
Training loss: 1.4496538639068604
Validation loss: 2.1517800192038217

Epoch: 5| Step: 10
Training loss: 1.835450530052185
Validation loss: 2.1612671613693237

Epoch: 5| Step: 11
Training loss: 1.8985873460769653
Validation loss: 2.167940636475881

Epoch: 278| Step: 0
Training loss: 2.035893440246582
Validation loss: 2.1519822676976523

Epoch: 5| Step: 1
Training loss: 1.3289620876312256
Validation loss: 2.167099952697754

Epoch: 5| Step: 2
Training loss: 1.7445347309112549
Validation loss: 2.123181695739428

Epoch: 5| Step: 3
Training loss: 1.5404417514801025
Validation loss: 2.111527373393377

Epoch: 5| Step: 4
Training loss: 1.4187867641448975
Validation loss: 2.136228789885839

Epoch: 5| Step: 5
Training loss: 1.9992969036102295
Validation loss: 2.1242103477319083

Epoch: 5| Step: 6
Training loss: 1.742437720298767
Validation loss: 2.128635749220848

Epoch: 5| Step: 7
Training loss: 1.5765103101730347
Validation loss: 2.12358325223128

Epoch: 5| Step: 8
Training loss: 1.973836898803711
Validation loss: 2.1233777503172555

Epoch: 5| Step: 9
Training loss: 1.7702356576919556
Validation loss: 2.1116165965795517

Epoch: 5| Step: 10
Training loss: 1.853642463684082
Validation loss: 2.1307303607463837

Epoch: 5| Step: 11
Training loss: 1.4575181007385254
Validation loss: 2.1314561863740287

Epoch: 279| Step: 0
Training loss: 2.002366065979004
Validation loss: 2.1364136040210724

Epoch: 5| Step: 1
Training loss: 1.3322532176971436
Validation loss: 2.1298310856024423

Epoch: 5| Step: 2
Training loss: 1.694719672203064
Validation loss: 2.1257158368825912

Epoch: 5| Step: 3
Training loss: 2.1293387413024902
Validation loss: 2.120693509777387

Epoch: 5| Step: 4
Training loss: 1.6390883922576904
Validation loss: 2.1432708700497947

Epoch: 5| Step: 5
Training loss: 1.6486196517944336
Validation loss: 2.12961013118426

Epoch: 5| Step: 6
Training loss: 1.4253190755844116
Validation loss: 2.1493306308984756

Epoch: 5| Step: 7
Training loss: 1.3953872919082642
Validation loss: 2.1674271573623023

Epoch: 5| Step: 8
Training loss: 1.7075402736663818
Validation loss: 2.155185749133428

Epoch: 5| Step: 9
Training loss: 1.9673445224761963
Validation loss: 2.1405642529328666

Epoch: 5| Step: 10
Training loss: 2.0894362926483154
Validation loss: 2.1933118204275766

Epoch: 5| Step: 11
Training loss: 1.2128756046295166
Validation loss: 2.171953390041987

Epoch: 280| Step: 0
Training loss: 1.6204833984375
Validation loss: 2.1803642312685647

Epoch: 5| Step: 1
Training loss: 1.7045618295669556
Validation loss: 2.1730734606583915

Epoch: 5| Step: 2
Training loss: 1.45485258102417
Validation loss: 2.1723122149705887

Epoch: 5| Step: 3
Training loss: 1.4897058010101318
Validation loss: 2.172862937053045

Epoch: 5| Step: 4
Training loss: 1.8899753093719482
Validation loss: 2.1342493693033853

Epoch: 5| Step: 5
Training loss: 2.0656535625457764
Validation loss: 2.1306677560011544

Epoch: 5| Step: 6
Training loss: 1.5649793148040771
Validation loss: 2.129059096177419

Epoch: 5| Step: 7
Training loss: 1.6874103546142578
Validation loss: 2.0989696085453033

Epoch: 5| Step: 8
Training loss: 1.9941585063934326
Validation loss: 2.1266977886358895

Epoch: 5| Step: 9
Training loss: 1.7645143270492554
Validation loss: 2.1284107168515525

Epoch: 5| Step: 10
Training loss: 1.672471046447754
Validation loss: 2.143730029463768

Epoch: 5| Step: 11
Training loss: 2.624311923980713
Validation loss: 2.142012064655622

Epoch: 281| Step: 0
Training loss: 1.9762327671051025
Validation loss: 2.1668105721473694

Epoch: 5| Step: 1
Training loss: 1.4770889282226562
Validation loss: 2.1521118730306625

Epoch: 5| Step: 2
Training loss: 1.9195137023925781
Validation loss: 2.1667155822118125

Epoch: 5| Step: 3
Training loss: 1.630488634109497
Validation loss: 2.1449411610762277

Epoch: 5| Step: 4
Training loss: 1.4677118062973022
Validation loss: 2.1372034549713135

Epoch: 5| Step: 5
Training loss: 2.48079252243042
Validation loss: 2.1099555045366287

Epoch: 5| Step: 6
Training loss: 2.021562099456787
Validation loss: 2.12280343969663

Epoch: 5| Step: 7
Training loss: 1.9335530996322632
Validation loss: 2.109941447774569

Epoch: 5| Step: 8
Training loss: 1.6286776065826416
Validation loss: 2.0921272287766137

Epoch: 5| Step: 9
Training loss: 1.3733603954315186
Validation loss: 2.0978996455669403

Epoch: 5| Step: 10
Training loss: 1.7719895839691162
Validation loss: 2.1052381644646325

Epoch: 5| Step: 11
Training loss: 1.3600541353225708
Validation loss: 2.1013277620077133

Epoch: 282| Step: 0
Training loss: 1.4976780414581299
Validation loss: 2.1084782977898917

Epoch: 5| Step: 1
Training loss: 1.5870311260223389
Validation loss: 2.095905289053917

Epoch: 5| Step: 2
Training loss: 2.4631128311157227
Validation loss: 2.098031759262085

Epoch: 5| Step: 3
Training loss: 2.0088064670562744
Validation loss: 2.1259407798449197

Epoch: 5| Step: 4
Training loss: 1.6327688694000244
Validation loss: 2.1463632782300315

Epoch: 5| Step: 5
Training loss: 1.8448641300201416
Validation loss: 2.16182087858518

Epoch: 5| Step: 6
Training loss: 1.6495052576065063
Validation loss: 2.160563424229622

Epoch: 5| Step: 7
Training loss: 2.1271307468414307
Validation loss: 2.1384242375691733

Epoch: 5| Step: 8
Training loss: 1.7292972803115845
Validation loss: 2.1359273145596185

Epoch: 5| Step: 9
Training loss: 1.5714662075042725
Validation loss: 2.1115226298570633

Epoch: 5| Step: 10
Training loss: 1.5552526712417603
Validation loss: 2.1005464444557824

Epoch: 5| Step: 11
Training loss: 1.7930327653884888
Validation loss: 2.1247740586598716

Epoch: 283| Step: 0
Training loss: 2.3292887210845947
Validation loss: 2.1190849443276725

Epoch: 5| Step: 1
Training loss: 1.1706923246383667
Validation loss: 2.114036331574122

Epoch: 5| Step: 2
Training loss: 1.9709354639053345
Validation loss: 2.123722583055496

Epoch: 5| Step: 3
Training loss: 1.1469686031341553
Validation loss: 2.111916477481524

Epoch: 5| Step: 4
Training loss: 1.6175788640975952
Validation loss: 2.1251213053862252

Epoch: 5| Step: 5
Training loss: 2.0201315879821777
Validation loss: 2.117070272564888

Epoch: 5| Step: 6
Training loss: 1.5212504863739014
Validation loss: 2.106506089369456

Epoch: 5| Step: 7
Training loss: 2.090599536895752
Validation loss: 2.14351516465346

Epoch: 5| Step: 8
Training loss: 2.2399444580078125
Validation loss: 2.1237333764632544

Epoch: 5| Step: 9
Training loss: 1.6398961544036865
Validation loss: 2.1129458049933114

Epoch: 5| Step: 10
Training loss: 2.2120144367218018
Validation loss: 2.116752798358599

Epoch: 5| Step: 11
Training loss: 1.1200568675994873
Validation loss: 2.134548286596934

Epoch: 284| Step: 0
Training loss: 1.5509685277938843
Validation loss: 2.1548911233743033

Epoch: 5| Step: 1
Training loss: 1.6052993535995483
Validation loss: 2.133739878733953

Epoch: 5| Step: 2
Training loss: 1.7664085626602173
Validation loss: 2.1576795428991318

Epoch: 5| Step: 3
Training loss: 1.7985236644744873
Validation loss: 2.147773047288259

Epoch: 5| Step: 4
Training loss: 2.0643248558044434
Validation loss: 2.1563929468393326

Epoch: 5| Step: 5
Training loss: 1.7292912006378174
Validation loss: 2.13501945634683

Epoch: 5| Step: 6
Training loss: 1.8459383249282837
Validation loss: 2.1410814424355826

Epoch: 5| Step: 7
Training loss: 1.6743618249893188
Validation loss: 2.124482254187266

Epoch: 5| Step: 8
Training loss: 1.8239949941635132
Validation loss: 2.1531875232855477

Epoch: 5| Step: 9
Training loss: 1.3503857851028442
Validation loss: 2.1513868967692056

Epoch: 5| Step: 10
Training loss: 1.8798706531524658
Validation loss: 2.1720276872316995

Epoch: 5| Step: 11
Training loss: 1.0297106504440308
Validation loss: 2.184545800089836

Epoch: 285| Step: 0
Training loss: 2.2116551399230957
Validation loss: 2.1820849627256393

Epoch: 5| Step: 1
Training loss: 1.4480702877044678
Validation loss: 2.217005744576454

Epoch: 5| Step: 2
Training loss: 1.9614261388778687
Validation loss: 2.2074564695358276

Epoch: 5| Step: 3
Training loss: 1.6728893518447876
Validation loss: 2.218191981315613

Epoch: 5| Step: 4
Training loss: 1.642919898033142
Validation loss: 2.192681680123011

Epoch: 5| Step: 5
Training loss: 1.8409522771835327
Validation loss: 2.1819027860959372

Epoch: 5| Step: 6
Training loss: 1.7559196949005127
Validation loss: 2.1511368453502655

Epoch: 5| Step: 7
Training loss: 1.6859115362167358
Validation loss: 2.133016566435496

Epoch: 5| Step: 8
Training loss: 1.2907739877700806
Validation loss: 2.12482450902462

Epoch: 5| Step: 9
Training loss: 1.9260915517807007
Validation loss: 2.140136962135633

Epoch: 5| Step: 10
Training loss: 1.753549337387085
Validation loss: 2.107417936126391

Epoch: 5| Step: 11
Training loss: 1.5843491554260254
Validation loss: 2.111106753349304

Epoch: 286| Step: 0
Training loss: 1.666343092918396
Validation loss: 2.1195340951283774

Epoch: 5| Step: 1
Training loss: 1.5867998600006104
Validation loss: 2.1275347570578256

Epoch: 5| Step: 2
Training loss: 1.8337284326553345
Validation loss: 2.1302422086397805

Epoch: 5| Step: 3
Training loss: 1.2548596858978271
Validation loss: 2.1310432851314545

Epoch: 5| Step: 4
Training loss: 1.2655301094055176
Validation loss: 2.118559643626213

Epoch: 5| Step: 5
Training loss: 2.2299089431762695
Validation loss: 2.1717460503180823

Epoch: 5| Step: 6
Training loss: 1.4698065519332886
Validation loss: 2.1655119011799493

Epoch: 5| Step: 7
Training loss: 1.3081810474395752
Validation loss: 2.1380396286646524

Epoch: 5| Step: 8
Training loss: 2.026966094970703
Validation loss: 2.146781121691068

Epoch: 5| Step: 9
Training loss: 1.9917843341827393
Validation loss: 2.1546456714471183

Epoch: 5| Step: 10
Training loss: 2.033168315887451
Validation loss: 2.1417221128940582

Epoch: 5| Step: 11
Training loss: 1.0977630615234375
Validation loss: 2.1529758175214133

Epoch: 287| Step: 0
Training loss: 1.442260503768921
Validation loss: 2.2125927110513053

Epoch: 5| Step: 1
Training loss: 2.1267826557159424
Validation loss: 2.188789193828901

Epoch: 5| Step: 2
Training loss: 2.1271116733551025
Validation loss: 2.176122561097145

Epoch: 5| Step: 3
Training loss: 1.640385389328003
Validation loss: 2.1979426642258963

Epoch: 5| Step: 4
Training loss: 1.6645294427871704
Validation loss: 2.159425973892212

Epoch: 5| Step: 5
Training loss: 1.4823567867279053
Validation loss: 2.178368945916494

Epoch: 5| Step: 6
Training loss: 2.3694610595703125
Validation loss: 2.16281529267629

Epoch: 5| Step: 7
Training loss: 1.7220379114151
Validation loss: 2.1767586370309195

Epoch: 5| Step: 8
Training loss: 1.9314607381820679
Validation loss: 2.158001095056534

Epoch: 5| Step: 9
Training loss: 1.7367191314697266
Validation loss: 2.170222371816635

Epoch: 5| Step: 10
Training loss: 1.1706299781799316
Validation loss: 2.1726280202468238

Epoch: 5| Step: 11
Training loss: 0.34704047441482544
Validation loss: 2.163701812426249

Epoch: 288| Step: 0
Training loss: 1.8248217105865479
Validation loss: 2.1686425606409707

Epoch: 5| Step: 1
Training loss: 1.1037938594818115
Validation loss: 2.176242639621099

Epoch: 5| Step: 2
Training loss: 1.7299531698226929
Validation loss: 2.220893273750941

Epoch: 5| Step: 3
Training loss: 1.5428259372711182
Validation loss: 2.1979724715153375

Epoch: 5| Step: 4
Training loss: 1.8901195526123047
Validation loss: 2.225604703028997

Epoch: 5| Step: 5
Training loss: 1.7987689971923828
Validation loss: 2.201991235216459

Epoch: 5| Step: 6
Training loss: 1.8118553161621094
Validation loss: 2.1783799529075623

Epoch: 5| Step: 7
Training loss: 1.477691411972046
Validation loss: 2.171395773688952

Epoch: 5| Step: 8
Training loss: 1.6099779605865479
Validation loss: 2.1716839174429574

Epoch: 5| Step: 9
Training loss: 2.2207071781158447
Validation loss: 2.154642234245936

Epoch: 5| Step: 10
Training loss: 1.98281991481781
Validation loss: 2.171960934996605

Epoch: 5| Step: 11
Training loss: 1.9747134447097778
Validation loss: 2.158690462509791

Epoch: 289| Step: 0
Training loss: 1.3309814929962158
Validation loss: 2.148381322622299

Epoch: 5| Step: 1
Training loss: 1.6681692600250244
Validation loss: 2.1800206353267035

Epoch: 5| Step: 2
Training loss: 2.266043186187744
Validation loss: 2.1985453565915427

Epoch: 5| Step: 3
Training loss: 1.6699641942977905
Validation loss: 2.1835385163625083

Epoch: 5| Step: 4
Training loss: 1.8282922506332397
Validation loss: 2.195508688688278

Epoch: 5| Step: 5
Training loss: 2.079167604446411
Validation loss: 2.192711835106214

Epoch: 5| Step: 6
Training loss: 1.1447662115097046
Validation loss: 2.1870692322651544

Epoch: 5| Step: 7
Training loss: 2.0289392471313477
Validation loss: 2.1822506735722222

Epoch: 5| Step: 8
Training loss: 1.856728196144104
Validation loss: 2.1719885567824044

Epoch: 5| Step: 9
Training loss: 1.302776575088501
Validation loss: 2.1615089426438012

Epoch: 5| Step: 10
Training loss: 1.5465143918991089
Validation loss: 2.1780819992224374

Epoch: 5| Step: 11
Training loss: 2.6123709678649902
Validation loss: 2.1598757753769555

Epoch: 290| Step: 0
Training loss: 1.9259687662124634
Validation loss: 2.1795348028341928

Epoch: 5| Step: 1
Training loss: 2.004023790359497
Validation loss: 2.1439357797304788

Epoch: 5| Step: 2
Training loss: 2.0613722801208496
Validation loss: 2.177925318479538

Epoch: 5| Step: 3
Training loss: 1.3925703763961792
Validation loss: 2.168010781208674

Epoch: 5| Step: 4
Training loss: 2.043268918991089
Validation loss: 2.19293375313282

Epoch: 5| Step: 5
Training loss: 1.2337323427200317
Validation loss: 2.176501323779424

Epoch: 5| Step: 6
Training loss: 1.519130825996399
Validation loss: 2.1717566649119058

Epoch: 5| Step: 7
Training loss: 1.4358983039855957
Validation loss: 2.1696265737215676

Epoch: 5| Step: 8
Training loss: 1.7015851736068726
Validation loss: 2.159975677728653

Epoch: 5| Step: 9
Training loss: 1.804758071899414
Validation loss: 2.1488324999809265

Epoch: 5| Step: 10
Training loss: 1.4730168581008911
Validation loss: 2.139585331082344

Epoch: 5| Step: 11
Training loss: 1.7134157419204712
Validation loss: 2.1449639896551767

Epoch: 291| Step: 0
Training loss: 1.5455231666564941
Validation loss: 2.1414181341727576

Epoch: 5| Step: 1
Training loss: 1.6667184829711914
Validation loss: 2.134992629289627

Epoch: 5| Step: 2
Training loss: 1.3820945024490356
Validation loss: 2.1591407457987466

Epoch: 5| Step: 3
Training loss: 1.7835829257965088
Validation loss: 2.160816619793574

Epoch: 5| Step: 4
Training loss: 1.3737744092941284
Validation loss: 2.18002720673879

Epoch: 5| Step: 5
Training loss: 1.953478455543518
Validation loss: 2.157302995522817

Epoch: 5| Step: 6
Training loss: 2.200085163116455
Validation loss: 2.17813507715861

Epoch: 5| Step: 7
Training loss: 1.5942062139511108
Validation loss: 2.1543865899244943

Epoch: 5| Step: 8
Training loss: 2.2701621055603027
Validation loss: 2.165809472401937

Epoch: 5| Step: 9
Training loss: 1.4891116619110107
Validation loss: 2.158055325349172

Epoch: 5| Step: 10
Training loss: 1.8536888360977173
Validation loss: 2.1560005644957223

Epoch: 5| Step: 11
Training loss: 0.4280284643173218
Validation loss: 2.1640495459238687

Epoch: 292| Step: 0
Training loss: 1.4491374492645264
Validation loss: 2.1736954152584076

Epoch: 5| Step: 1
Training loss: 2.206791400909424
Validation loss: 2.154143293698629

Epoch: 5| Step: 2
Training loss: 2.007753610610962
Validation loss: 2.1531581779321036

Epoch: 5| Step: 3
Training loss: 2.1080644130706787
Validation loss: 2.1607341120640435

Epoch: 5| Step: 4
Training loss: 1.6654882431030273
Validation loss: 2.1525009870529175

Epoch: 5| Step: 5
Training loss: 1.4253641366958618
Validation loss: 2.1419171889623008

Epoch: 5| Step: 6
Training loss: 1.463634729385376
Validation loss: 2.169043098886808

Epoch: 5| Step: 7
Training loss: 1.9383577108383179
Validation loss: 2.15166367093722

Epoch: 5| Step: 8
Training loss: 1.3060716390609741
Validation loss: 2.178013031681379

Epoch: 5| Step: 9
Training loss: 1.5966637134552002
Validation loss: 2.193957949678103

Epoch: 5| Step: 10
Training loss: 1.8804175853729248
Validation loss: 2.203951984643936

Epoch: 5| Step: 11
Training loss: 1.4685338735580444
Validation loss: 2.188463265697161

Epoch: 293| Step: 0
Training loss: 1.5964282751083374
Validation loss: 2.1860728760560355

Epoch: 5| Step: 1
Training loss: 1.1468702554702759
Validation loss: 2.2030354142189026

Epoch: 5| Step: 2
Training loss: 1.3418296575546265
Validation loss: 2.18154909213384

Epoch: 5| Step: 3
Training loss: 1.5462238788604736
Validation loss: 2.210794369379679

Epoch: 5| Step: 4
Training loss: 1.3979191780090332
Validation loss: 2.184436112642288

Epoch: 5| Step: 5
Training loss: 1.7735732793807983
Validation loss: 2.144274413585663

Epoch: 5| Step: 6
Training loss: 1.8546199798583984
Validation loss: 2.1491662710905075

Epoch: 5| Step: 7
Training loss: 2.461345672607422
Validation loss: 2.15538160999616

Epoch: 5| Step: 8
Training loss: 1.8406118154525757
Validation loss: 2.131360491116842

Epoch: 5| Step: 9
Training loss: 1.7279945611953735
Validation loss: 2.158653443058332

Epoch: 5| Step: 10
Training loss: 2.299145221710205
Validation loss: 2.1405345698197684

Epoch: 5| Step: 11
Training loss: 1.688770055770874
Validation loss: 2.1587898830572763

Epoch: 294| Step: 0
Training loss: 2.197252035140991
Validation loss: 2.1403853992621102

Epoch: 5| Step: 1
Training loss: 2.445641040802002
Validation loss: 2.147529035806656

Epoch: 5| Step: 2
Training loss: 1.232753038406372
Validation loss: 2.1218060702085495

Epoch: 5| Step: 3
Training loss: 1.5388538837432861
Validation loss: 2.1140788892904916

Epoch: 5| Step: 4
Training loss: 1.5962454080581665
Validation loss: 2.1203723351160684

Epoch: 5| Step: 5
Training loss: 1.7949529886245728
Validation loss: 2.1320561468601227

Epoch: 5| Step: 6
Training loss: 1.68014657497406
Validation loss: 2.161575978000959

Epoch: 5| Step: 7
Training loss: 1.624337911605835
Validation loss: 2.1442544559637704

Epoch: 5| Step: 8
Training loss: 1.2126226425170898
Validation loss: 2.1489932040373483

Epoch: 5| Step: 9
Training loss: 2.0485785007476807
Validation loss: 2.153632561365763

Epoch: 5| Step: 10
Training loss: 1.2876389026641846
Validation loss: 2.1187704553206763

Epoch: 5| Step: 11
Training loss: 1.0954954624176025
Validation loss: 2.1464274575312934

Epoch: 295| Step: 0
Training loss: 1.8402751684188843
Validation loss: 2.127543846766154

Epoch: 5| Step: 1
Training loss: 2.3103621006011963
Validation loss: 2.1251313438018165

Epoch: 5| Step: 2
Training loss: 1.5497106313705444
Validation loss: 2.13870906829834

Epoch: 5| Step: 3
Training loss: 2.065735340118408
Validation loss: 2.145099769035975

Epoch: 5| Step: 4
Training loss: 1.641863226890564
Validation loss: 2.1351832101742425

Epoch: 5| Step: 5
Training loss: 1.5263636112213135
Validation loss: 2.1325315038363137

Epoch: 5| Step: 6
Training loss: 1.3353512287139893
Validation loss: 2.1595085163911185

Epoch: 5| Step: 7
Training loss: 2.120262622833252
Validation loss: 2.1700482914845147

Epoch: 5| Step: 8
Training loss: 1.7820276021957397
Validation loss: 2.1739168912172318

Epoch: 5| Step: 9
Training loss: 1.6236131191253662
Validation loss: 2.2079719801743827

Epoch: 5| Step: 10
Training loss: 1.26435124874115
Validation loss: 2.1936909755071006

Epoch: 5| Step: 11
Training loss: 2.0698447227478027
Validation loss: 2.1830781400203705

Epoch: 296| Step: 0
Training loss: 1.6429744958877563
Validation loss: 2.163975397745768

Epoch: 5| Step: 1
Training loss: 1.232810616493225
Validation loss: 2.1591510474681854

Epoch: 5| Step: 2
Training loss: 1.88066828250885
Validation loss: 2.154406170050303

Epoch: 5| Step: 3
Training loss: 1.5081074237823486
Validation loss: 2.152420868476232

Epoch: 5| Step: 4
Training loss: 1.7317829132080078
Validation loss: 2.1589380502700806

Epoch: 5| Step: 5
Training loss: 2.033724308013916
Validation loss: 2.161491736769676

Epoch: 5| Step: 6
Training loss: 1.4611177444458008
Validation loss: 2.142029285430908

Epoch: 5| Step: 7
Training loss: 2.0909056663513184
Validation loss: 2.1496766855319343

Epoch: 5| Step: 8
Training loss: 2.0637285709381104
Validation loss: 2.1513668398062387

Epoch: 5| Step: 9
Training loss: 1.1026026010513306
Validation loss: 2.156929890314738

Epoch: 5| Step: 10
Training loss: 1.4629781246185303
Validation loss: 2.1672833959261575

Epoch: 5| Step: 11
Training loss: 2.420403480529785
Validation loss: 2.1428781052430472

Epoch: 297| Step: 0
Training loss: 1.2466135025024414
Validation loss: 2.145503302415212

Epoch: 5| Step: 1
Training loss: 1.1395620107650757
Validation loss: 2.1469042698542276

Epoch: 5| Step: 2
Training loss: 1.736350655555725
Validation loss: 2.1610511442025504

Epoch: 5| Step: 3
Training loss: 2.2147631645202637
Validation loss: 2.1702828258275986

Epoch: 5| Step: 4
Training loss: 1.5673325061798096
Validation loss: 2.165263682603836

Epoch: 5| Step: 5
Training loss: 1.8676255941390991
Validation loss: 2.144744689265887

Epoch: 5| Step: 6
Training loss: 1.450148344039917
Validation loss: 2.1496388912200928

Epoch: 5| Step: 7
Training loss: 1.9168144464492798
Validation loss: 2.1453299025694528

Epoch: 5| Step: 8
Training loss: 1.8070189952850342
Validation loss: 2.1654227624336877

Epoch: 5| Step: 9
Training loss: 1.6900949478149414
Validation loss: 2.154359981417656

Epoch: 5| Step: 10
Training loss: 1.4544508457183838
Validation loss: 2.175242066383362

Epoch: 5| Step: 11
Training loss: 2.628227472305298
Validation loss: 2.1534834255774817

Epoch: 298| Step: 0
Training loss: 2.2306010723114014
Validation loss: 2.1476135601600013

Epoch: 5| Step: 1
Training loss: 2.2029623985290527
Validation loss: 2.1791269779205322

Epoch: 5| Step: 2
Training loss: 1.845191240310669
Validation loss: 2.1574666599432626

Epoch: 5| Step: 3
Training loss: 1.3960293531417847
Validation loss: 2.159940019249916

Epoch: 5| Step: 4
Training loss: 1.4872944355010986
Validation loss: 2.1067863752444587

Epoch: 5| Step: 5
Training loss: 1.7287161350250244
Validation loss: 2.123722439010938

Epoch: 5| Step: 6
Training loss: 1.5923601388931274
Validation loss: 2.1393526991208396

Epoch: 5| Step: 7
Training loss: 1.1597692966461182
Validation loss: 2.1255069375038147

Epoch: 5| Step: 8
Training loss: 1.4137096405029297
Validation loss: 2.1577969938516617

Epoch: 5| Step: 9
Training loss: 1.5216704607009888
Validation loss: 2.1667042275269828

Epoch: 5| Step: 10
Training loss: 1.8721609115600586
Validation loss: 2.1557613710562387

Epoch: 5| Step: 11
Training loss: 1.2228037118911743
Validation loss: 2.12164314587911

Epoch: 299| Step: 0
Training loss: 1.425668716430664
Validation loss: 2.1438854138056436

Epoch: 5| Step: 1
Training loss: 1.5398030281066895
Validation loss: 2.1535324454307556

Epoch: 5| Step: 2
Training loss: 1.4210622310638428
Validation loss: 2.1382471919059753

Epoch: 5| Step: 3
Training loss: 1.5637834072113037
Validation loss: 2.1274221539497375

Epoch: 5| Step: 4
Training loss: 2.908264636993408
Validation loss: 2.132768601179123

Epoch: 5| Step: 5
Training loss: 1.5782670974731445
Validation loss: 2.1247847179571786

Epoch: 5| Step: 6
Training loss: 2.0144877433776855
Validation loss: 2.125144491593043

Epoch: 5| Step: 7
Training loss: 1.5921623706817627
Validation loss: 2.112697263558706

Epoch: 5| Step: 8
Training loss: 1.6295652389526367
Validation loss: 2.099702204267184

Epoch: 5| Step: 9
Training loss: 1.9402351379394531
Validation loss: 2.1297511557737985

Epoch: 5| Step: 10
Training loss: 1.0097486972808838
Validation loss: 2.1325460076332092

Epoch: 5| Step: 11
Training loss: 1.7968876361846924
Validation loss: 2.1428599655628204

Epoch: 300| Step: 0
Training loss: 1.9225835800170898
Validation loss: 2.1612511525551477

Epoch: 5| Step: 1
Training loss: 1.4733712673187256
Validation loss: 2.1283348202705383

Epoch: 5| Step: 2
Training loss: 1.3348376750946045
Validation loss: 2.1358298460642495

Epoch: 5| Step: 3
Training loss: 1.4912173748016357
Validation loss: 2.132692893346151

Epoch: 5| Step: 4
Training loss: 1.0183274745941162
Validation loss: 2.139392167329788

Epoch: 5| Step: 5
Training loss: 1.6020424365997314
Validation loss: 2.132809097568194

Epoch: 5| Step: 6
Training loss: 1.8646284341812134
Validation loss: 2.128959536552429

Epoch: 5| Step: 7
Training loss: 1.561607003211975
Validation loss: 2.1495690246423087

Epoch: 5| Step: 8
Training loss: 2.2750251293182373
Validation loss: 2.146084874868393

Epoch: 5| Step: 9
Training loss: 2.1961898803710938
Validation loss: 2.1349168767531714

Epoch: 5| Step: 10
Training loss: 1.8217674493789673
Validation loss: 2.148729145526886

Epoch: 5| Step: 11
Training loss: 1.478415608406067
Validation loss: 2.1516966422398887

Epoch: 301| Step: 0
Training loss: 2.3533120155334473
Validation loss: 2.138421982526779

Epoch: 5| Step: 1
Training loss: 1.3613795042037964
Validation loss: 2.138410732150078

Epoch: 5| Step: 2
Training loss: 1.459669828414917
Validation loss: 2.1384339183568954

Epoch: 5| Step: 3
Training loss: 1.36866295337677
Validation loss: 2.131428062915802

Epoch: 5| Step: 4
Training loss: 1.3012847900390625
Validation loss: 2.129978363712629

Epoch: 5| Step: 5
Training loss: 1.5367190837860107
Validation loss: 2.133558675646782

Epoch: 5| Step: 6
Training loss: 2.4251224994659424
Validation loss: 2.149247775475184

Epoch: 5| Step: 7
Training loss: 1.7594220638275146
Validation loss: 2.1361324886480966

Epoch: 5| Step: 8
Training loss: 1.8140900135040283
Validation loss: 2.1494606932004294

Epoch: 5| Step: 9
Training loss: 1.2725417613983154
Validation loss: 2.1666214168071747

Epoch: 5| Step: 10
Training loss: 1.9666944742202759
Validation loss: 2.152742991844813

Epoch: 5| Step: 11
Training loss: 1.0326547622680664
Validation loss: 2.1708006064097085

Epoch: 302| Step: 0
Training loss: 1.3191713094711304
Validation loss: 2.175047586361567

Epoch: 5| Step: 1
Training loss: 2.288118839263916
Validation loss: 2.1381525496641793

Epoch: 5| Step: 2
Training loss: 1.2872776985168457
Validation loss: 2.1538618753353753

Epoch: 5| Step: 3
Training loss: 1.540432095527649
Validation loss: 2.1600180665651956

Epoch: 5| Step: 4
Training loss: 1.6360028982162476
Validation loss: 2.158609723051389

Epoch: 5| Step: 5
Training loss: 1.9817711114883423
Validation loss: 2.146590684851011

Epoch: 5| Step: 6
Training loss: 1.6323992013931274
Validation loss: 2.1564091791709266

Epoch: 5| Step: 7
Training loss: 1.238849401473999
Validation loss: 2.158770114183426

Epoch: 5| Step: 8
Training loss: 1.885460615158081
Validation loss: 2.1587410817543664

Epoch: 5| Step: 9
Training loss: 2.1826369762420654
Validation loss: 2.1446399688720703

Epoch: 5| Step: 10
Training loss: 1.1798747777938843
Validation loss: 2.16776371995608

Epoch: 5| Step: 11
Training loss: 1.383565902709961
Validation loss: 2.1576218803723655

Epoch: 303| Step: 0
Training loss: 2.041945695877075
Validation loss: 2.1896208077669144

Epoch: 5| Step: 1
Training loss: 1.3906196355819702
Validation loss: 2.1718770215908685

Epoch: 5| Step: 2
Training loss: 1.6565303802490234
Validation loss: 2.2070485800504684

Epoch: 5| Step: 3
Training loss: 1.3560702800750732
Validation loss: 2.175634483496348

Epoch: 5| Step: 4
Training loss: 1.091509461402893
Validation loss: 2.1904780517021814

Epoch: 5| Step: 5
Training loss: 1.9189716577529907
Validation loss: 2.1770008355379105

Epoch: 5| Step: 6
Training loss: 1.700735092163086
Validation loss: 2.169550821185112

Epoch: 5| Step: 7
Training loss: 1.531686544418335
Validation loss: 2.154702360431353

Epoch: 5| Step: 8
Training loss: 1.290238380432129
Validation loss: 2.1389364451169968

Epoch: 5| Step: 9
Training loss: 2.3925552368164062
Validation loss: 2.1129093964894614

Epoch: 5| Step: 10
Training loss: 1.9650344848632812
Validation loss: 2.125222682952881

Epoch: 5| Step: 11
Training loss: 0.8503240942955017
Validation loss: 2.114057262738546

Epoch: 304| Step: 0
Training loss: 1.8692958354949951
Validation loss: 2.1237671871980033

Epoch: 5| Step: 1
Training loss: 1.4915201663970947
Validation loss: 2.1310107012589774

Epoch: 5| Step: 2
Training loss: 1.4729098081588745
Validation loss: 2.138620143135389

Epoch: 5| Step: 3
Training loss: 1.5809961557388306
Validation loss: 2.1078517685333886

Epoch: 5| Step: 4
Training loss: 1.5308847427368164
Validation loss: 2.123465230067571

Epoch: 5| Step: 5
Training loss: 1.9681310653686523
Validation loss: 2.1253967682520547

Epoch: 5| Step: 6
Training loss: 2.2969565391540527
Validation loss: 2.1250442812840142

Epoch: 5| Step: 7
Training loss: 1.3070693016052246
Validation loss: 2.1338907182216644

Epoch: 5| Step: 8
Training loss: 1.6745147705078125
Validation loss: 2.164581835269928

Epoch: 5| Step: 9
Training loss: 1.5181564092636108
Validation loss: 2.1658720622460046

Epoch: 5| Step: 10
Training loss: 1.9186261892318726
Validation loss: 2.168658678730329

Epoch: 5| Step: 11
Training loss: 1.8720332384109497
Validation loss: 2.156447316209475

Epoch: 305| Step: 0
Training loss: 1.4018365144729614
Validation loss: 2.1463131606578827

Epoch: 5| Step: 1
Training loss: 1.1738401651382446
Validation loss: 2.145700757702192

Epoch: 5| Step: 2
Training loss: 2.747178316116333
Validation loss: 2.1470450361569724

Epoch: 5| Step: 3
Training loss: 1.5826091766357422
Validation loss: 2.162930722037951

Epoch: 5| Step: 4
Training loss: 1.268903136253357
Validation loss: 2.128101353844007

Epoch: 5| Step: 5
Training loss: 2.1234021186828613
Validation loss: 2.128683472673098

Epoch: 5| Step: 6
Training loss: 1.6425024271011353
Validation loss: 2.1569345047076545

Epoch: 5| Step: 7
Training loss: 1.5049960613250732
Validation loss: 2.168925235668818

Epoch: 5| Step: 8
Training loss: 1.7101036310195923
Validation loss: 2.129392594099045

Epoch: 5| Step: 9
Training loss: 2.0344531536102295
Validation loss: 2.167376538117727

Epoch: 5| Step: 10
Training loss: 1.2472041845321655
Validation loss: 2.160348415374756

Epoch: 5| Step: 11
Training loss: 0.5679290294647217
Validation loss: 2.1394802381594977

Epoch: 306| Step: 0
Training loss: 1.4395153522491455
Validation loss: 2.178880820671717

Epoch: 5| Step: 1
Training loss: 1.767490029335022
Validation loss: 2.190073867638906

Epoch: 5| Step: 2
Training loss: 1.9641311168670654
Validation loss: 2.2018636713425317

Epoch: 5| Step: 3
Training loss: 1.8127520084381104
Validation loss: 2.2158166468143463

Epoch: 5| Step: 4
Training loss: 1.0285770893096924
Validation loss: 2.2099282244841256

Epoch: 5| Step: 5
Training loss: 1.7238502502441406
Validation loss: 2.172661170363426

Epoch: 5| Step: 6
Training loss: 1.9303127527236938
Validation loss: 2.1698696513970694

Epoch: 5| Step: 7
Training loss: 1.418355941772461
Validation loss: 2.1607715785503387

Epoch: 5| Step: 8
Training loss: 1.1783645153045654
Validation loss: 2.149809867143631

Epoch: 5| Step: 9
Training loss: 1.7328996658325195
Validation loss: 2.1468378057082496

Epoch: 5| Step: 10
Training loss: 1.586377739906311
Validation loss: 2.148589273293813

Epoch: 5| Step: 11
Training loss: 3.0264675617218018
Validation loss: 2.1523856967687607

Epoch: 307| Step: 0
Training loss: 1.827629804611206
Validation loss: 2.1573719332615533

Epoch: 5| Step: 1
Training loss: 1.2490386962890625
Validation loss: 2.1286524484554925

Epoch: 5| Step: 2
Training loss: 2.024928569793701
Validation loss: 2.1384752045075097

Epoch: 5| Step: 3
Training loss: 1.2774052619934082
Validation loss: 2.1564038892587027

Epoch: 5| Step: 4
Training loss: 1.7646458148956299
Validation loss: 2.144504482547442

Epoch: 5| Step: 5
Training loss: 2.3142058849334717
Validation loss: 2.1466117004553475

Epoch: 5| Step: 6
Training loss: 1.2292194366455078
Validation loss: 2.107080931464831

Epoch: 5| Step: 7
Training loss: 1.7689682245254517
Validation loss: 2.1004091054201126

Epoch: 5| Step: 8
Training loss: 1.2778334617614746
Validation loss: 2.121267428000768

Epoch: 5| Step: 9
Training loss: 1.7317308187484741
Validation loss: 2.1090997705856958

Epoch: 5| Step: 10
Training loss: 1.7178189754486084
Validation loss: 2.1161318669716516

Epoch: 5| Step: 11
Training loss: 2.331303119659424
Validation loss: 2.127987653017044

Epoch: 308| Step: 0
Training loss: 2.1182780265808105
Validation loss: 2.136411597331365

Epoch: 5| Step: 1
Training loss: 1.9554545879364014
Validation loss: 2.1261168966690698

Epoch: 5| Step: 2
Training loss: 1.2634550333023071
Validation loss: 2.1511796414852142

Epoch: 5| Step: 3
Training loss: 1.7578389644622803
Validation loss: 2.1636313994725547

Epoch: 5| Step: 4
Training loss: 1.4022436141967773
Validation loss: 2.1802170177300773

Epoch: 5| Step: 5
Training loss: 1.9047901630401611
Validation loss: 2.1665618121623993

Epoch: 5| Step: 6
Training loss: 1.6626466512680054
Validation loss: 2.200570528705915

Epoch: 5| Step: 7
Training loss: 1.2404489517211914
Validation loss: 2.185282066464424

Epoch: 5| Step: 8
Training loss: 1.8181604146957397
Validation loss: 2.1702158749103546

Epoch: 5| Step: 9
Training loss: 1.3257572650909424
Validation loss: 2.1778845886389413

Epoch: 5| Step: 10
Training loss: 1.550323486328125
Validation loss: 2.1588873863220215

Epoch: 5| Step: 11
Training loss: 2.343080997467041
Validation loss: 2.141116480032603

Epoch: 309| Step: 0
Training loss: 2.164707660675049
Validation loss: 2.1215843558311462

Epoch: 5| Step: 1
Training loss: 1.88998544216156
Validation loss: 2.1599615265925727

Epoch: 5| Step: 2
Training loss: 1.8863948583602905
Validation loss: 2.1478473047415414

Epoch: 5| Step: 3
Training loss: 1.2699699401855469
Validation loss: 2.1450790415207543

Epoch: 5| Step: 4
Training loss: 1.2642277479171753
Validation loss: 2.115068028370539

Epoch: 5| Step: 5
Training loss: 2.0936765670776367
Validation loss: 2.1453753858804703

Epoch: 5| Step: 6
Training loss: 1.3717447519302368
Validation loss: 2.1295010248819985

Epoch: 5| Step: 7
Training loss: 1.8818576335906982
Validation loss: 2.132528230547905

Epoch: 5| Step: 8
Training loss: 1.2233070135116577
Validation loss: 2.139097327987353

Epoch: 5| Step: 9
Training loss: 1.3560594320297241
Validation loss: 2.1221486926078796

Epoch: 5| Step: 10
Training loss: 1.3725146055221558
Validation loss: 2.1334680368502936

Epoch: 5| Step: 11
Training loss: 2.4968695640563965
Validation loss: 2.144634336233139

Epoch: 310| Step: 0
Training loss: 1.4155876636505127
Validation loss: 2.1290893455346427

Epoch: 5| Step: 1
Training loss: 2.151477098464966
Validation loss: 2.1314435799916587

Epoch: 5| Step: 2
Training loss: 1.4792321920394897
Validation loss: 2.1414478719234467

Epoch: 5| Step: 3
Training loss: 1.8240973949432373
Validation loss: 2.146131237347921

Epoch: 5| Step: 4
Training loss: 1.4523826837539673
Validation loss: 2.147873640060425

Epoch: 5| Step: 5
Training loss: 1.587477684020996
Validation loss: 2.1733625580867133

Epoch: 5| Step: 6
Training loss: 1.9682302474975586
Validation loss: 2.195587605237961

Epoch: 5| Step: 7
Training loss: 1.1629759073257446
Validation loss: 2.194125990072886

Epoch: 5| Step: 8
Training loss: 1.5648504495620728
Validation loss: 2.170032491286596

Epoch: 5| Step: 9
Training loss: 1.13899564743042
Validation loss: 2.168253943324089

Epoch: 5| Step: 10
Training loss: 1.8874046802520752
Validation loss: 2.1346938212712607

Epoch: 5| Step: 11
Training loss: 2.9844062328338623
Validation loss: 2.138093193372091

Epoch: 311| Step: 0
Training loss: 1.2132757902145386
Validation loss: 2.1104906648397446

Epoch: 5| Step: 1
Training loss: 1.0358928442001343
Validation loss: 2.1214557141065598

Epoch: 5| Step: 2
Training loss: 1.1808487176895142
Validation loss: 2.1511401534080505

Epoch: 5| Step: 3
Training loss: 2.375959873199463
Validation loss: 2.1519740571578345

Epoch: 5| Step: 4
Training loss: 1.8024381399154663
Validation loss: 2.174943223595619

Epoch: 5| Step: 5
Training loss: 2.2654268741607666
Validation loss: 2.1494912604490914

Epoch: 5| Step: 6
Training loss: 1.5334854125976562
Validation loss: 2.183288206656774

Epoch: 5| Step: 7
Training loss: 1.3930811882019043
Validation loss: 2.1380669673283896

Epoch: 5| Step: 8
Training loss: 1.859278917312622
Validation loss: 2.153529475132624

Epoch: 5| Step: 9
Training loss: 2.016415596008301
Validation loss: 2.1386940677960715

Epoch: 5| Step: 10
Training loss: 1.646247148513794
Validation loss: 2.139451026916504

Epoch: 5| Step: 11
Training loss: 0.265031099319458
Validation loss: 2.142137348651886

Epoch: 312| Step: 0
Training loss: 1.6845639944076538
Validation loss: 2.1604179640611014

Epoch: 5| Step: 1
Training loss: 1.4969260692596436
Validation loss: 2.1172727197408676

Epoch: 5| Step: 2
Training loss: 1.640312910079956
Validation loss: 2.1421219458182654

Epoch: 5| Step: 3
Training loss: 2.0969438552856445
Validation loss: 2.1293925344944

Epoch: 5| Step: 4
Training loss: 1.432213544845581
Validation loss: 2.1199865639209747

Epoch: 5| Step: 5
Training loss: 1.2488073110580444
Validation loss: 2.1091645061969757

Epoch: 5| Step: 6
Training loss: 1.965411901473999
Validation loss: 2.1224759618441262

Epoch: 5| Step: 7
Training loss: 1.6200218200683594
Validation loss: 2.1122054954369864

Epoch: 5| Step: 8
Training loss: 1.2146775722503662
Validation loss: 2.130377540985743

Epoch: 5| Step: 9
Training loss: 1.6392457485198975
Validation loss: 2.1190317968527475

Epoch: 5| Step: 10
Training loss: 2.3299319744110107
Validation loss: 2.1354677925507226

Epoch: 5| Step: 11
Training loss: 0.3426153063774109
Validation loss: 2.1445147146781287

Epoch: 313| Step: 0
Training loss: 1.5559576749801636
Validation loss: 2.140997529029846

Epoch: 5| Step: 1
Training loss: 1.690871000289917
Validation loss: 2.1403760462999344

Epoch: 5| Step: 2
Training loss: 1.8508847951889038
Validation loss: 2.117025757829348

Epoch: 5| Step: 3
Training loss: 1.4415339231491089
Validation loss: 2.1192499498526254

Epoch: 5| Step: 4
Training loss: 2.3703033924102783
Validation loss: 2.1257051080465317

Epoch: 5| Step: 5
Training loss: 2.108222723007202
Validation loss: 2.1439944903055825

Epoch: 5| Step: 6
Training loss: 2.101686477661133
Validation loss: 2.1476525316635766

Epoch: 5| Step: 7
Training loss: 1.8685880899429321
Validation loss: 2.137303156157335

Epoch: 5| Step: 8
Training loss: 1.3616650104522705
Validation loss: 2.132793272535006

Epoch: 5| Step: 9
Training loss: 1.6177600622177124
Validation loss: 2.1233416547377906

Epoch: 5| Step: 10
Training loss: 1.0753376483917236
Validation loss: 2.0975773483514786

Epoch: 5| Step: 11
Training loss: 1.5009995698928833
Validation loss: 2.139089971780777

Epoch: 314| Step: 0
Training loss: 1.5385518074035645
Validation loss: 2.13388392329216

Epoch: 5| Step: 1
Training loss: 1.1044151782989502
Validation loss: 2.147849847873052

Epoch: 5| Step: 2
Training loss: 1.3911845684051514
Validation loss: 2.1666312565406165

Epoch: 5| Step: 3
Training loss: 1.6690715551376343
Validation loss: 2.140300929546356

Epoch: 5| Step: 4
Training loss: 2.2204718589782715
Validation loss: 2.1414188941319785

Epoch: 5| Step: 5
Training loss: 1.9468421936035156
Validation loss: 2.1650971422592797

Epoch: 5| Step: 6
Training loss: 2.1346867084503174
Validation loss: 2.144319067398707

Epoch: 5| Step: 7
Training loss: 1.8286203145980835
Validation loss: 2.1429054935773215

Epoch: 5| Step: 8
Training loss: 1.6082813739776611
Validation loss: 2.152719254295031

Epoch: 5| Step: 9
Training loss: 1.6284682750701904
Validation loss: 2.1608340789874396

Epoch: 5| Step: 10
Training loss: 1.2751691341400146
Validation loss: 2.1633319556713104

Epoch: 5| Step: 11
Training loss: 0.9613954424858093
Validation loss: 2.144171347220739

Epoch: 315| Step: 0
Training loss: 1.1771821975708008
Validation loss: 2.13652503490448

Epoch: 5| Step: 1
Training loss: 1.6086804866790771
Validation loss: 2.159479940931002

Epoch: 5| Step: 2
Training loss: 1.6814091205596924
Validation loss: 2.173691521088282

Epoch: 5| Step: 3
Training loss: 1.6080348491668701
Validation loss: 2.125345086057981

Epoch: 5| Step: 4
Training loss: 1.4857008457183838
Validation loss: 2.1410183062156043

Epoch: 5| Step: 5
Training loss: 1.6523878574371338
Validation loss: 2.1731270054976144

Epoch: 5| Step: 6
Training loss: 1.853764295578003
Validation loss: 2.1434351007143655

Epoch: 5| Step: 7
Training loss: 1.4927828311920166
Validation loss: 2.1402161767085395

Epoch: 5| Step: 8
Training loss: 1.4358949661254883
Validation loss: 2.1473582287629447

Epoch: 5| Step: 9
Training loss: 1.981959342956543
Validation loss: 2.1327682733535767

Epoch: 5| Step: 10
Training loss: 1.5397398471832275
Validation loss: 2.1580674896637597

Epoch: 5| Step: 11
Training loss: 3.4949164390563965
Validation loss: 2.1411756922801337

Epoch: 316| Step: 0
Training loss: 1.4285500049591064
Validation loss: 2.1407854904731116

Epoch: 5| Step: 1
Training loss: 1.2846333980560303
Validation loss: 2.133705715338389

Epoch: 5| Step: 2
Training loss: 1.5582292079925537
Validation loss: 2.145328680674235

Epoch: 5| Step: 3
Training loss: 1.5754820108413696
Validation loss: 2.144927288095156

Epoch: 5| Step: 4
Training loss: 1.022200584411621
Validation loss: 2.1399327317873635

Epoch: 5| Step: 5
Training loss: 2.0500431060791016
Validation loss: 2.135491187373797

Epoch: 5| Step: 6
Training loss: 1.5814409255981445
Validation loss: 2.153423920273781

Epoch: 5| Step: 7
Training loss: 1.6301409006118774
Validation loss: 2.1579363445440927

Epoch: 5| Step: 8
Training loss: 1.5772264003753662
Validation loss: 2.1363736391067505

Epoch: 5| Step: 9
Training loss: 1.3619673252105713
Validation loss: 2.160358731945356

Epoch: 5| Step: 10
Training loss: 2.5211596488952637
Validation loss: 2.1853888779878616

Epoch: 5| Step: 11
Training loss: 1.6499736309051514
Validation loss: 2.1655876636505127

Epoch: 317| Step: 0
Training loss: 1.0792121887207031
Validation loss: 2.1412457625071206

Epoch: 5| Step: 1
Training loss: 2.155785083770752
Validation loss: 2.147014116247495

Epoch: 5| Step: 2
Training loss: 1.3796972036361694
Validation loss: 2.1226520041624704

Epoch: 5| Step: 3
Training loss: 1.0426347255706787
Validation loss: 2.14450474580129

Epoch: 5| Step: 4
Training loss: 1.6596508026123047
Validation loss: 2.134156033396721

Epoch: 5| Step: 5
Training loss: 1.9611492156982422
Validation loss: 2.141162941853205

Epoch: 5| Step: 6
Training loss: 1.6896425485610962
Validation loss: 2.1339811931053796

Epoch: 5| Step: 7
Training loss: 2.353060483932495
Validation loss: 2.1259909520546594

Epoch: 5| Step: 8
Training loss: 1.8958991765975952
Validation loss: 2.1175642013549805

Epoch: 5| Step: 9
Training loss: 1.447435736656189
Validation loss: 2.1235903004805246

Epoch: 5| Step: 10
Training loss: 1.4906988143920898
Validation loss: 2.130815530816714

Epoch: 5| Step: 11
Training loss: 2.455982208251953
Validation loss: 2.126775046189626

Epoch: 318| Step: 0
Training loss: 1.709964394569397
Validation loss: 2.1367836942275367

Epoch: 5| Step: 1
Training loss: 1.8946678638458252
Validation loss: 2.127439931035042

Epoch: 5| Step: 2
Training loss: 1.5215835571289062
Validation loss: 2.148103266954422

Epoch: 5| Step: 3
Training loss: 1.4520795345306396
Validation loss: 2.1506188611189523

Epoch: 5| Step: 4
Training loss: 1.1420994997024536
Validation loss: 2.132583503921827

Epoch: 5| Step: 5
Training loss: 1.3733965158462524
Validation loss: 2.1283992379903793

Epoch: 5| Step: 6
Training loss: 1.2882646322250366
Validation loss: 2.106934368610382

Epoch: 5| Step: 7
Training loss: 1.883131742477417
Validation loss: 2.1376544584830603

Epoch: 5| Step: 8
Training loss: 2.4277098178863525
Validation loss: 2.146822859843572

Epoch: 5| Step: 9
Training loss: 1.3224509954452515
Validation loss: 2.1366543571154275

Epoch: 5| Step: 10
Training loss: 1.9595305919647217
Validation loss: 2.1184848695993423

Epoch: 5| Step: 11
Training loss: 1.833280086517334
Validation loss: 2.137094040711721

Epoch: 319| Step: 0
Training loss: 2.092670440673828
Validation loss: 2.1343076825141907

Epoch: 5| Step: 1
Training loss: 1.369805932044983
Validation loss: 2.133826643228531

Epoch: 5| Step: 2
Training loss: 1.1088533401489258
Validation loss: 2.1542536318302155

Epoch: 5| Step: 3
Training loss: 1.6124407052993774
Validation loss: 2.1572244664033255

Epoch: 5| Step: 4
Training loss: 2.0682153701782227
Validation loss: 2.185780500372251

Epoch: 5| Step: 5
Training loss: 1.559395432472229
Validation loss: 2.1141954958438873

Epoch: 5| Step: 6
Training loss: 1.736767053604126
Validation loss: 2.148524989684423

Epoch: 5| Step: 7
Training loss: 1.295943021774292
Validation loss: 2.129368707537651

Epoch: 5| Step: 8
Training loss: 1.3338115215301514
Validation loss: 2.140179008245468

Epoch: 5| Step: 9
Training loss: 2.003667116165161
Validation loss: 2.1423612435658774

Epoch: 5| Step: 10
Training loss: 2.1801631450653076
Validation loss: 2.1363048553466797

Epoch: 5| Step: 11
Training loss: 1.3146015405654907
Validation loss: 2.148367484410604

Epoch: 320| Step: 0
Training loss: 1.4961947202682495
Validation loss: 2.1449905236562095

Epoch: 5| Step: 1
Training loss: 1.2738163471221924
Validation loss: 2.140809560815493

Epoch: 5| Step: 2
Training loss: 1.26986563205719
Validation loss: 2.156943142414093

Epoch: 5| Step: 3
Training loss: 2.128657579421997
Validation loss: 2.137152468164762

Epoch: 5| Step: 4
Training loss: 1.385627031326294
Validation loss: 2.1575029840071998

Epoch: 5| Step: 5
Training loss: 2.011240005493164
Validation loss: 2.160678595304489

Epoch: 5| Step: 6
Training loss: 1.4661662578582764
Validation loss: 2.152108778556188

Epoch: 5| Step: 7
Training loss: 1.8233588933944702
Validation loss: 2.175898234049479

Epoch: 5| Step: 8
Training loss: 1.5897928476333618
Validation loss: 2.1582299967606864

Epoch: 5| Step: 9
Training loss: 1.5979503393173218
Validation loss: 2.1560873091220856

Epoch: 5| Step: 10
Training loss: 1.786466360092163
Validation loss: 2.1547707120577493

Epoch: 5| Step: 11
Training loss: 1.3856009244918823
Validation loss: 2.150678262114525

Epoch: 321| Step: 0
Training loss: 1.5553133487701416
Validation loss: 2.152933895587921

Epoch: 5| Step: 1
Training loss: 1.3817088603973389
Validation loss: 2.1518898010253906

Epoch: 5| Step: 2
Training loss: 2.04426908493042
Validation loss: 2.1648763914903006

Epoch: 5| Step: 3
Training loss: 1.774696946144104
Validation loss: 2.1589936514695487

Epoch: 5| Step: 4
Training loss: 2.367422580718994
Validation loss: 2.171979775031408

Epoch: 5| Step: 5
Training loss: 1.7417089939117432
Validation loss: 2.2003296265999475

Epoch: 5| Step: 6
Training loss: 0.8666437864303589
Validation loss: 2.178441653649012

Epoch: 5| Step: 7
Training loss: 1.5300652980804443
Validation loss: 2.197880908846855

Epoch: 5| Step: 8
Training loss: 0.8859143257141113
Validation loss: 2.2427936494350433

Epoch: 5| Step: 9
Training loss: 2.2183094024658203
Validation loss: 2.2557537158330283

Epoch: 5| Step: 10
Training loss: 1.8727670907974243
Validation loss: 2.2911815146605172

Epoch: 5| Step: 11
Training loss: 2.413414716720581
Validation loss: 2.281781574090322

Epoch: 322| Step: 0
Training loss: 1.6497561931610107
Validation loss: 2.2649032274881997

Epoch: 5| Step: 1
Training loss: 1.3361018896102905
Validation loss: 2.2301594018936157

Epoch: 5| Step: 2
Training loss: 1.918312668800354
Validation loss: 2.1657707691192627

Epoch: 5| Step: 3
Training loss: 1.774989366531372
Validation loss: 2.178359697262446

Epoch: 5| Step: 4
Training loss: 1.4628077745437622
Validation loss: 2.1481608152389526

Epoch: 5| Step: 5
Training loss: 2.0928192138671875
Validation loss: 2.1568946490685144

Epoch: 5| Step: 6
Training loss: 1.687779426574707
Validation loss: 2.1835774083932242

Epoch: 5| Step: 7
Training loss: 2.0451111793518066
Validation loss: 2.198895146449407

Epoch: 5| Step: 8
Training loss: 1.487548589706421
Validation loss: 2.180467481414477

Epoch: 5| Step: 9
Training loss: 1.8810487985610962
Validation loss: 2.1580784171819687

Epoch: 5| Step: 10
Training loss: 1.5142643451690674
Validation loss: 2.1577548533678055

Epoch: 5| Step: 11
Training loss: 1.3462132215499878
Validation loss: 2.139118547240893

Epoch: 323| Step: 0
Training loss: 1.3643581867218018
Validation loss: 2.168467948834101

Epoch: 5| Step: 1
Training loss: 1.5552809238433838
Validation loss: 2.1624322831630707

Epoch: 5| Step: 2
Training loss: 1.6863632202148438
Validation loss: 2.1644184589385986

Epoch: 5| Step: 3
Training loss: 1.6675984859466553
Validation loss: 2.167738303542137

Epoch: 5| Step: 4
Training loss: 1.315780758857727
Validation loss: 2.1565838158130646

Epoch: 5| Step: 5
Training loss: 1.551729440689087
Validation loss: 2.1591152399778366

Epoch: 5| Step: 6
Training loss: 1.9883369207382202
Validation loss: 2.157752126455307

Epoch: 5| Step: 7
Training loss: 2.5228030681610107
Validation loss: 2.162709653377533

Epoch: 5| Step: 8
Training loss: 1.7597358226776123
Validation loss: 2.15739776690801

Epoch: 5| Step: 9
Training loss: 1.6546013355255127
Validation loss: 2.1385724196831384

Epoch: 5| Step: 10
Training loss: 1.2033491134643555
Validation loss: 2.124334841966629

Epoch: 5| Step: 11
Training loss: 1.5886150598526
Validation loss: 2.1576963315407434

Epoch: 324| Step: 0
Training loss: 1.6658258438110352
Validation loss: 2.1560866783062616

Epoch: 5| Step: 1
Training loss: 1.2354410886764526
Validation loss: 2.1546694089969

Epoch: 5| Step: 2
Training loss: 1.630833387374878
Validation loss: 2.1411972592274346

Epoch: 5| Step: 3
Training loss: 1.57710599899292
Validation loss: 2.150218258301417

Epoch: 5| Step: 4
Training loss: 2.0338358879089355
Validation loss: 2.1597760717074075

Epoch: 5| Step: 5
Training loss: 1.2153270244598389
Validation loss: 2.1544765681028366

Epoch: 5| Step: 6
Training loss: 1.4735578298568726
Validation loss: 2.158604701360067

Epoch: 5| Step: 7
Training loss: 1.8304550647735596
Validation loss: 2.1774074733257294

Epoch: 5| Step: 8
Training loss: 2.1158642768859863
Validation loss: 2.1899156471093497

Epoch: 5| Step: 9
Training loss: 1.3113443851470947
Validation loss: 2.169755607843399

Epoch: 5| Step: 10
Training loss: 1.6963386535644531
Validation loss: 2.172503570715586

Epoch: 5| Step: 11
Training loss: 1.3415579795837402
Validation loss: 2.143840769926707

Epoch: 325| Step: 0
Training loss: 1.3231005668640137
Validation loss: 2.182704582810402

Epoch: 5| Step: 1
Training loss: 1.5354238748550415
Validation loss: 2.155244549115499

Epoch: 5| Step: 2
Training loss: 1.2565829753875732
Validation loss: 2.193517714738846

Epoch: 5| Step: 3
Training loss: 1.729114294052124
Validation loss: 2.187230591972669

Epoch: 5| Step: 4
Training loss: 1.5594279766082764
Validation loss: 2.193147763609886

Epoch: 5| Step: 5
Training loss: 1.8316446542739868
Validation loss: 2.1864498605330787

Epoch: 5| Step: 6
Training loss: 1.815219521522522
Validation loss: 2.1848078121741614

Epoch: 5| Step: 7
Training loss: 1.710381269454956
Validation loss: 2.192084461450577

Epoch: 5| Step: 8
Training loss: 1.7375710010528564
Validation loss: 2.1682202269633613

Epoch: 5| Step: 9
Training loss: 1.7131450176239014
Validation loss: 2.1805986811717353

Epoch: 5| Step: 10
Training loss: 1.2551798820495605
Validation loss: 2.1631261855363846

Epoch: 5| Step: 11
Training loss: 1.1342346668243408
Validation loss: 2.1485834817091622

Epoch: 326| Step: 0
Training loss: 2.3718209266662598
Validation loss: 2.135257894794146

Epoch: 5| Step: 1
Training loss: 1.3907109498977661
Validation loss: 2.163141831755638

Epoch: 5| Step: 2
Training loss: 1.6258869171142578
Validation loss: 2.1418920854727426

Epoch: 5| Step: 3
Training loss: 2.1393187046051025
Validation loss: 2.154733141263326

Epoch: 5| Step: 4
Training loss: 1.5529638528823853
Validation loss: 2.1398498862981796

Epoch: 5| Step: 5
Training loss: 1.7835865020751953
Validation loss: 2.130961537361145

Epoch: 5| Step: 6
Training loss: 1.4001213312149048
Validation loss: 2.118236263593038

Epoch: 5| Step: 7
Training loss: 1.6162443161010742
Validation loss: 2.129640519618988

Epoch: 5| Step: 8
Training loss: 1.4424270391464233
Validation loss: 2.1440185805161796

Epoch: 5| Step: 9
Training loss: 1.601507544517517
Validation loss: 2.126144990324974

Epoch: 5| Step: 10
Training loss: 1.2026222944259644
Validation loss: 2.1294834266106286

Epoch: 5| Step: 11
Training loss: 1.9605512619018555
Validation loss: 2.1292812327543893

Epoch: 327| Step: 0
Training loss: 1.8512508869171143
Validation loss: 2.1400960286458335

Epoch: 5| Step: 1
Training loss: 1.5643666982650757
Validation loss: 2.128229111433029

Epoch: 5| Step: 2
Training loss: 2.1387553215026855
Validation loss: 2.1253795673449836

Epoch: 5| Step: 3
Training loss: 1.3440873622894287
Validation loss: 2.1549831479787827

Epoch: 5| Step: 4
Training loss: 2.081300735473633
Validation loss: 2.15125901500384

Epoch: 5| Step: 5
Training loss: 1.5865501165390015
Validation loss: 2.137013783057531

Epoch: 5| Step: 6
Training loss: 1.5875089168548584
Validation loss: 2.140150641401609

Epoch: 5| Step: 7
Training loss: 1.1230862140655518
Validation loss: 2.171114762624105

Epoch: 5| Step: 8
Training loss: 1.5366147756576538
Validation loss: 2.161256035168966

Epoch: 5| Step: 9
Training loss: 1.4384338855743408
Validation loss: 2.1563409666220346

Epoch: 5| Step: 10
Training loss: 1.0893306732177734
Validation loss: 2.1709098666906357

Epoch: 5| Step: 11
Training loss: 2.301236629486084
Validation loss: 2.1851863861083984

Epoch: 328| Step: 0
Training loss: 1.7937999963760376
Validation loss: 2.1762117743492126

Epoch: 5| Step: 1
Training loss: 1.7251068353652954
Validation loss: 2.182237908244133

Epoch: 5| Step: 2
Training loss: 1.5204660892486572
Validation loss: 2.1788956920305886

Epoch: 5| Step: 3
Training loss: 1.8312591314315796
Validation loss: 2.1979231437047324

Epoch: 5| Step: 4
Training loss: 1.8455371856689453
Validation loss: 2.1688492794831595

Epoch: 5| Step: 5
Training loss: 2.0153965950012207
Validation loss: 2.1746407598257065

Epoch: 5| Step: 6
Training loss: 1.7989400625228882
Validation loss: 2.1644825637340546

Epoch: 5| Step: 7
Training loss: 1.4541435241699219
Validation loss: 2.1540240148703256

Epoch: 5| Step: 8
Training loss: 1.2201805114746094
Validation loss: 2.142113119363785

Epoch: 5| Step: 9
Training loss: 1.673195481300354
Validation loss: 2.1505164802074432

Epoch: 5| Step: 10
Training loss: 0.9149171710014343
Validation loss: 2.138029764095942

Epoch: 5| Step: 11
Training loss: 1.6047074794769287
Validation loss: 2.1354304353396096

Epoch: 329| Step: 0
Training loss: 0.9067903757095337
Validation loss: 2.1353030701478324

Epoch: 5| Step: 1
Training loss: 1.7362096309661865
Validation loss: 2.13864329457283

Epoch: 5| Step: 2
Training loss: 1.2370853424072266
Validation loss: 2.1368838598330817

Epoch: 5| Step: 3
Training loss: 1.8668699264526367
Validation loss: 2.152973239620527

Epoch: 5| Step: 4
Training loss: 1.2161509990692139
Validation loss: 2.139537384112676

Epoch: 5| Step: 5
Training loss: 1.1698631048202515
Validation loss: 2.1335723797480264

Epoch: 5| Step: 6
Training loss: 1.8116042613983154
Validation loss: 2.145720769961675

Epoch: 5| Step: 7
Training loss: 1.8843313455581665
Validation loss: 2.1190712551275888

Epoch: 5| Step: 8
Training loss: 1.0964852571487427
Validation loss: 2.1325599749883017

Epoch: 5| Step: 9
Training loss: 2.4454662799835205
Validation loss: 2.128298764427503

Epoch: 5| Step: 10
Training loss: 1.7317638397216797
Validation loss: 2.14518041908741

Epoch: 5| Step: 11
Training loss: 2.378674030303955
Validation loss: 2.1540489196777344

Epoch: 330| Step: 0
Training loss: 1.521112084388733
Validation loss: 2.14692855377992

Epoch: 5| Step: 1
Training loss: 1.8309657573699951
Validation loss: 2.1529677659273148

Epoch: 5| Step: 2
Training loss: 1.6023681163787842
Validation loss: 2.172372574607531

Epoch: 5| Step: 3
Training loss: 1.4734662771224976
Validation loss: 2.1550338764985404

Epoch: 5| Step: 4
Training loss: 1.9330768585205078
Validation loss: 2.164126137892405

Epoch: 5| Step: 5
Training loss: 1.5064373016357422
Validation loss: 2.1661234696706138

Epoch: 5| Step: 6
Training loss: 1.8027598857879639
Validation loss: 2.1659224331378937

Epoch: 5| Step: 7
Training loss: 1.3977773189544678
Validation loss: 2.1698046972354255

Epoch: 5| Step: 8
Training loss: 1.6525557041168213
Validation loss: 2.2012194643417993

Epoch: 5| Step: 9
Training loss: 1.5590827465057373
Validation loss: 2.2060937881469727

Epoch: 5| Step: 10
Training loss: 1.218093752861023
Validation loss: 2.209689438343048

Epoch: 5| Step: 11
Training loss: 1.5574530363082886
Validation loss: 2.2063473761081696

Epoch: 331| Step: 0
Training loss: 1.5839511156082153
Validation loss: 2.2024795909722648

Epoch: 5| Step: 1
Training loss: 1.2081620693206787
Validation loss: 2.2423288424809775

Epoch: 5| Step: 2
Training loss: 1.0785009860992432
Validation loss: 2.213927686214447

Epoch: 5| Step: 3
Training loss: 1.1160337924957275
Validation loss: 2.2060822745164237

Epoch: 5| Step: 4
Training loss: 2.304675817489624
Validation loss: 2.176404078801473

Epoch: 5| Step: 5
Training loss: 1.5431900024414062
Validation loss: 2.1825218995412192

Epoch: 5| Step: 6
Training loss: 1.7008174657821655
Validation loss: 2.1925818622112274

Epoch: 5| Step: 7
Training loss: 1.4449325799942017
Validation loss: 2.1708919952313104

Epoch: 5| Step: 8
Training loss: 1.7012923955917358
Validation loss: 2.1794250706831613

Epoch: 5| Step: 9
Training loss: 2.0069425106048584
Validation loss: 2.163968116044998

Epoch: 5| Step: 10
Training loss: 1.6936771869659424
Validation loss: 2.1771299888690314

Epoch: 5| Step: 11
Training loss: 0.803999662399292
Validation loss: 2.1645481288433075

Epoch: 332| Step: 0
Training loss: 1.4209034442901611
Validation loss: 2.1658457120259604

Epoch: 5| Step: 1
Training loss: 1.3948920965194702
Validation loss: 2.178600480159124

Epoch: 5| Step: 2
Training loss: 1.625800371170044
Validation loss: 2.1809727400541306

Epoch: 5| Step: 3
Training loss: 1.9603761434555054
Validation loss: 2.184343715508779

Epoch: 5| Step: 4
Training loss: 1.3879122734069824
Validation loss: 2.1626954674720764

Epoch: 5| Step: 5
Training loss: 1.3373491764068604
Validation loss: 2.182207077741623

Epoch: 5| Step: 6
Training loss: 1.7791389226913452
Validation loss: 2.1847212811311087

Epoch: 5| Step: 7
Training loss: 1.8265750408172607
Validation loss: 2.1936515867710114

Epoch: 5| Step: 8
Training loss: 1.8172671794891357
Validation loss: 2.180957088867823

Epoch: 5| Step: 9
Training loss: 1.4549949169158936
Validation loss: 2.149518763025602

Epoch: 5| Step: 10
Training loss: 1.8035331964492798
Validation loss: 2.1730322937170663

Epoch: 5| Step: 11
Training loss: 0.7151297330856323
Validation loss: 2.169410079717636

Epoch: 333| Step: 0
Training loss: 1.0288898944854736
Validation loss: 2.1596601406733194

Epoch: 5| Step: 1
Training loss: 1.9085572957992554
Validation loss: 2.166396905978521

Epoch: 5| Step: 2
Training loss: 1.9487478733062744
Validation loss: 2.1720390071471534

Epoch: 5| Step: 3
Training loss: 2.122565746307373
Validation loss: 2.170636693636576

Epoch: 5| Step: 4
Training loss: 1.7912555932998657
Validation loss: 2.1523830940326056

Epoch: 5| Step: 5
Training loss: 1.703171968460083
Validation loss: 2.179472421606382

Epoch: 5| Step: 6
Training loss: 1.3417857885360718
Validation loss: 2.159646396835645

Epoch: 5| Step: 7
Training loss: 1.3547711372375488
Validation loss: 2.186471104621887

Epoch: 5| Step: 8
Training loss: 2.1089415550231934
Validation loss: 2.1595099518696466

Epoch: 5| Step: 9
Training loss: 0.8380199670791626
Validation loss: 2.1901241838932037

Epoch: 5| Step: 10
Training loss: 1.4328533411026
Validation loss: 2.1749036014080048

Epoch: 5| Step: 11
Training loss: 1.022092580795288
Validation loss: 2.1952389081319175

Epoch: 334| Step: 0
Training loss: 1.1479238271713257
Validation loss: 2.164073720574379

Epoch: 5| Step: 1
Training loss: 1.0003077983856201
Validation loss: 2.1856859425703683

Epoch: 5| Step: 2
Training loss: 1.3849834203720093
Validation loss: 2.158613180120786

Epoch: 5| Step: 3
Training loss: 1.4258190393447876
Validation loss: 2.1799152493476868

Epoch: 5| Step: 4
Training loss: 1.5487486124038696
Validation loss: 2.180431048075358

Epoch: 5| Step: 5
Training loss: 1.487256646156311
Validation loss: 2.184298425912857

Epoch: 5| Step: 6
Training loss: 1.4130970239639282
Validation loss: 2.173495128750801

Epoch: 5| Step: 7
Training loss: 2.041848659515381
Validation loss: 2.1906518936157227

Epoch: 5| Step: 8
Training loss: 2.116792917251587
Validation loss: 2.1868003010749817

Epoch: 5| Step: 9
Training loss: 2.279414415359497
Validation loss: 2.193011293808619

Epoch: 5| Step: 10
Training loss: 1.1690785884857178
Validation loss: 2.178032865126928

Epoch: 5| Step: 11
Training loss: 0.9200055003166199
Validation loss: 2.1660864551862082

Epoch: 335| Step: 0
Training loss: 1.8424301147460938
Validation loss: 2.1979659299055734

Epoch: 5| Step: 1
Training loss: 1.3856439590454102
Validation loss: 2.148687874277433

Epoch: 5| Step: 2
Training loss: 0.9472677111625671
Validation loss: 2.1745847860972085

Epoch: 5| Step: 3
Training loss: 1.2552525997161865
Validation loss: 2.1485141664743423

Epoch: 5| Step: 4
Training loss: 1.7908786535263062
Validation loss: 2.1426382263501487

Epoch: 5| Step: 5
Training loss: 1.2706692218780518
Validation loss: 2.160023108124733

Epoch: 5| Step: 6
Training loss: 1.3226234912872314
Validation loss: 2.1727346926927567

Epoch: 5| Step: 7
Training loss: 1.7070976495742798
Validation loss: 2.1442130307356515

Epoch: 5| Step: 8
Training loss: 1.946175217628479
Validation loss: 2.177320510149002

Epoch: 5| Step: 9
Training loss: 1.68086838722229
Validation loss: 2.1483004887898765

Epoch: 5| Step: 10
Training loss: 1.9536523818969727
Validation loss: 2.161428620417913

Epoch: 5| Step: 11
Training loss: 0.9008227586746216
Validation loss: 2.158602630098661

Epoch: 336| Step: 0
Training loss: 1.9371089935302734
Validation loss: 2.161364530523618

Epoch: 5| Step: 1
Training loss: 1.347910761833191
Validation loss: 2.149941941102346

Epoch: 5| Step: 2
Training loss: 1.9098008871078491
Validation loss: 2.149012645085653

Epoch: 5| Step: 3
Training loss: 1.605818510055542
Validation loss: 2.161063348253568

Epoch: 5| Step: 4
Training loss: 1.6557986736297607
Validation loss: 2.147693266471227

Epoch: 5| Step: 5
Training loss: 1.275023341178894
Validation loss: 2.162184158960978

Epoch: 5| Step: 6
Training loss: 1.123887538909912
Validation loss: 2.1974635620911918

Epoch: 5| Step: 7
Training loss: 1.3420627117156982
Validation loss: 2.1593902756770453

Epoch: 5| Step: 8
Training loss: 2.3420119285583496
Validation loss: 2.1628518849611282

Epoch: 5| Step: 9
Training loss: 1.3156074285507202
Validation loss: 2.1628751705090203

Epoch: 5| Step: 10
Training loss: 1.6123899221420288
Validation loss: 2.183450331290563

Epoch: 5| Step: 11
Training loss: 0.44066470861434937
Validation loss: 2.155384292205175

Epoch: 337| Step: 0
Training loss: 1.9645551443099976
Validation loss: 2.1750524739424386

Epoch: 5| Step: 1
Training loss: 1.4864944219589233
Validation loss: 2.1640774607658386

Epoch: 5| Step: 2
Training loss: 1.0404731035232544
Validation loss: 2.171195829908053

Epoch: 5| Step: 3
Training loss: 1.230202317237854
Validation loss: 2.1851316491762796

Epoch: 5| Step: 4
Training loss: 0.875580906867981
Validation loss: 2.1567395528157554

Epoch: 5| Step: 5
Training loss: 2.0015714168548584
Validation loss: 2.168785870075226

Epoch: 5| Step: 6
Training loss: 1.7980026006698608
Validation loss: 2.165221114953359

Epoch: 5| Step: 7
Training loss: 1.3383935689926147
Validation loss: 2.1594643543163934

Epoch: 5| Step: 8
Training loss: 1.0756982564926147
Validation loss: 2.1614285111427307

Epoch: 5| Step: 9
Training loss: 1.707392692565918
Validation loss: 2.162151873111725

Epoch: 5| Step: 10
Training loss: 2.118051767349243
Validation loss: 2.173883373538653

Epoch: 5| Step: 11
Training loss: 2.1834921836853027
Validation loss: 2.167745848496755

Epoch: 338| Step: 0
Training loss: 1.918448805809021
Validation loss: 2.166324401895205

Epoch: 5| Step: 1
Training loss: 1.9143335819244385
Validation loss: 2.1903095742066703

Epoch: 5| Step: 2
Training loss: 1.2951663732528687
Validation loss: 2.158635661005974

Epoch: 5| Step: 3
Training loss: 1.1076167821884155
Validation loss: 2.166307508945465

Epoch: 5| Step: 4
Training loss: 0.8801051378250122
Validation loss: 2.153239289919535

Epoch: 5| Step: 5
Training loss: 1.0706242322921753
Validation loss: 2.1692530115445456

Epoch: 5| Step: 6
Training loss: 1.5945278406143188
Validation loss: 2.1705931474765143

Epoch: 5| Step: 7
Training loss: 1.9278523921966553
Validation loss: 2.180769066015879

Epoch: 5| Step: 8
Training loss: 2.086726665496826
Validation loss: 2.17463356256485

Epoch: 5| Step: 9
Training loss: 1.7995576858520508
Validation loss: 2.1919114540020623

Epoch: 5| Step: 10
Training loss: 1.3885506391525269
Validation loss: 2.20070273677508

Epoch: 5| Step: 11
Training loss: 2.216435432434082
Validation loss: 2.1961953788995743

Epoch: 339| Step: 0
Training loss: 1.762855887413025
Validation loss: 2.208868866165479

Epoch: 5| Step: 1
Training loss: 2.162087917327881
Validation loss: 2.1676473766565323

Epoch: 5| Step: 2
Training loss: 1.3487789630889893
Validation loss: 2.1753776917854943

Epoch: 5| Step: 3
Training loss: 1.338654637336731
Validation loss: 2.1640368700027466

Epoch: 5| Step: 4
Training loss: 1.6180671453475952
Validation loss: 2.166860431432724

Epoch: 5| Step: 5
Training loss: 0.908360481262207
Validation loss: 2.164248466491699

Epoch: 5| Step: 6
Training loss: 1.3262481689453125
Validation loss: 2.1648648530244827

Epoch: 5| Step: 7
Training loss: 1.6313940286636353
Validation loss: 2.141277785102526

Epoch: 5| Step: 8
Training loss: 1.3405433893203735
Validation loss: 2.163692678014437

Epoch: 5| Step: 9
Training loss: 1.2274179458618164
Validation loss: 2.1613945762316384

Epoch: 5| Step: 10
Training loss: 1.977031946182251
Validation loss: 2.1382454882065454

Epoch: 5| Step: 11
Training loss: 1.1425541639328003
Validation loss: 2.1489892452955246

Epoch: 340| Step: 0
Training loss: 1.1068487167358398
Validation loss: 2.149688641230265

Epoch: 5| Step: 1
Training loss: 1.4278433322906494
Validation loss: 2.1429458558559418

Epoch: 5| Step: 2
Training loss: 1.4869866371154785
Validation loss: 2.1430756002664566

Epoch: 5| Step: 3
Training loss: 1.125056505203247
Validation loss: 2.143635263045629

Epoch: 5| Step: 4
Training loss: 2.328913688659668
Validation loss: 2.1492259254058204

Epoch: 5| Step: 5
Training loss: 1.7701423168182373
Validation loss: 2.149692172805468

Epoch: 5| Step: 6
Training loss: 1.1437245607376099
Validation loss: 2.12520099679629

Epoch: 5| Step: 7
Training loss: 1.4522632360458374
Validation loss: 2.1390212078889212

Epoch: 5| Step: 8
Training loss: 1.7184938192367554
Validation loss: 2.134316702683767

Epoch: 5| Step: 9
Training loss: 1.7240171432495117
Validation loss: 2.1629687349001565

Epoch: 5| Step: 10
Training loss: 1.1752007007598877
Validation loss: 2.1890008598566055

Epoch: 5| Step: 11
Training loss: 2.1188864707946777
Validation loss: 2.183403973778089

Epoch: 341| Step: 0
Training loss: 1.4555387496948242
Validation loss: 2.1945232848326364

Epoch: 5| Step: 1
Training loss: 1.7377064228057861
Validation loss: 2.192042052745819

Epoch: 5| Step: 2
Training loss: 1.7892568111419678
Validation loss: 2.1732444763183594

Epoch: 5| Step: 3
Training loss: 1.378972053527832
Validation loss: 2.194200982650121

Epoch: 5| Step: 4
Training loss: 1.3686096668243408
Validation loss: 2.1842891623576484

Epoch: 5| Step: 5
Training loss: 1.2750873565673828
Validation loss: 2.1896022905906043

Epoch: 5| Step: 6
Training loss: 1.422248125076294
Validation loss: 2.1881678998470306

Epoch: 5| Step: 7
Training loss: 2.3064494132995605
Validation loss: 2.1937392254670462

Epoch: 5| Step: 8
Training loss: 1.6261003017425537
Validation loss: 2.1772698213656745

Epoch: 5| Step: 9
Training loss: 1.0515639781951904
Validation loss: 2.169943859179815

Epoch: 5| Step: 10
Training loss: 1.6839452981948853
Validation loss: 2.1433531443277993

Epoch: 5| Step: 11
Training loss: 1.233879566192627
Validation loss: 2.1536529709895453

Epoch: 342| Step: 0
Training loss: 2.258899211883545
Validation loss: 2.1573634495337806

Epoch: 5| Step: 1
Training loss: 1.5456178188323975
Validation loss: 2.1673808296521506

Epoch: 5| Step: 2
Training loss: 1.6394920349121094
Validation loss: 2.1766568422317505

Epoch: 5| Step: 3
Training loss: 1.8715260028839111
Validation loss: 2.1805939177672067

Epoch: 5| Step: 4
Training loss: 1.5566465854644775
Validation loss: 2.139991963903109

Epoch: 5| Step: 5
Training loss: 1.4096872806549072
Validation loss: 2.1363799472649894

Epoch: 5| Step: 6
Training loss: 1.989811658859253
Validation loss: 2.1671833246946335

Epoch: 5| Step: 7
Training loss: 1.8000894784927368
Validation loss: 2.1270989179611206

Epoch: 5| Step: 8
Training loss: 1.0204226970672607
Validation loss: 2.140120178461075

Epoch: 5| Step: 9
Training loss: 1.3561608791351318
Validation loss: 2.1393684347470603

Epoch: 5| Step: 10
Training loss: 0.9539324045181274
Validation loss: 2.142264644304911

Epoch: 5| Step: 11
Training loss: 1.0237162113189697
Validation loss: 2.1325008422136307

Epoch: 343| Step: 0
Training loss: 1.7094882726669312
Validation loss: 2.151673525571823

Epoch: 5| Step: 1
Training loss: 1.6007297039031982
Validation loss: 2.1345606297254562

Epoch: 5| Step: 2
Training loss: 1.6773353815078735
Validation loss: 2.15214674671491

Epoch: 5| Step: 3
Training loss: 1.5047327280044556
Validation loss: 2.1543775151173272

Epoch: 5| Step: 4
Training loss: 1.4620416164398193
Validation loss: 2.1531127095222473

Epoch: 5| Step: 5
Training loss: 0.9159278869628906
Validation loss: 2.182273209095001

Epoch: 5| Step: 6
Training loss: 1.432929515838623
Validation loss: 2.175409217675527

Epoch: 5| Step: 7
Training loss: 1.166537880897522
Validation loss: 2.1499919990698495

Epoch: 5| Step: 8
Training loss: 2.120835304260254
Validation loss: 2.158776601155599

Epoch: 5| Step: 9
Training loss: 1.4982540607452393
Validation loss: 2.1743926852941513

Epoch: 5| Step: 10
Training loss: 2.0559704303741455
Validation loss: 2.1937421411275864

Epoch: 5| Step: 11
Training loss: 1.5173487663269043
Validation loss: 2.212857907017072

Epoch: 344| Step: 0
Training loss: 1.4481773376464844
Validation loss: 2.2180276413758597

Epoch: 5| Step: 1
Training loss: 2.0142741203308105
Validation loss: 2.174885501464208

Epoch: 5| Step: 2
Training loss: 2.484645366668701
Validation loss: 2.2140466223160424

Epoch: 5| Step: 3
Training loss: 1.3638614416122437
Validation loss: 2.147388289372126

Epoch: 5| Step: 4
Training loss: 1.1747190952301025
Validation loss: 2.177544414997101

Epoch: 5| Step: 5
Training loss: 0.48943910002708435
Validation loss: 2.1597011536359787

Epoch: 5| Step: 6
Training loss: 1.8544092178344727
Validation loss: 2.159259165326754

Epoch: 5| Step: 7
Training loss: 1.349612832069397
Validation loss: 2.158559982975324

Epoch: 5| Step: 8
Training loss: 2.023573875427246
Validation loss: 2.1522565384705863

Epoch: 5| Step: 9
Training loss: 1.5195276737213135
Validation loss: 2.181038811802864

Epoch: 5| Step: 10
Training loss: 1.6957757472991943
Validation loss: 2.169215346376101

Epoch: 5| Step: 11
Training loss: 2.350020408630371
Validation loss: 2.1250513245662055

Epoch: 345| Step: 0
Training loss: 1.5344574451446533
Validation loss: 2.129559710621834

Epoch: 5| Step: 1
Training loss: 1.3482393026351929
Validation loss: 2.1424353420734406

Epoch: 5| Step: 2
Training loss: 1.9518836736679077
Validation loss: 2.1014068325360618

Epoch: 5| Step: 3
Training loss: 1.4962856769561768
Validation loss: 2.132755011320114

Epoch: 5| Step: 4
Training loss: 1.3766906261444092
Validation loss: 2.176900714635849

Epoch: 5| Step: 5
Training loss: 2.205280065536499
Validation loss: 2.1978718986113868

Epoch: 5| Step: 6
Training loss: 1.450365662574768
Validation loss: 2.2076985587676368

Epoch: 5| Step: 7
Training loss: 1.0581918954849243
Validation loss: 2.217812572916349

Epoch: 5| Step: 8
Training loss: 1.6987457275390625
Validation loss: 2.2265865008036294

Epoch: 5| Step: 9
Training loss: 1.1088602542877197
Validation loss: 2.2121441761652627

Epoch: 5| Step: 10
Training loss: 1.5623661279678345
Validation loss: 2.217468877633413

Epoch: 5| Step: 11
Training loss: 1.634418249130249
Validation loss: 2.2381031016508737

Epoch: 346| Step: 0
Training loss: 1.9650481939315796
Validation loss: 2.2389837950468063

Epoch: 5| Step: 1
Training loss: 1.134392499923706
Validation loss: 2.2110853493213654

Epoch: 5| Step: 2
Training loss: 1.2047597169876099
Validation loss: 2.1831155717372894

Epoch: 5| Step: 3
Training loss: 1.9571597576141357
Validation loss: 2.1847223738829293

Epoch: 5| Step: 4
Training loss: 0.9531489610671997
Validation loss: 2.17729751765728

Epoch: 5| Step: 5
Training loss: 2.110356569290161
Validation loss: 2.156769926349322

Epoch: 5| Step: 6
Training loss: 1.5947182178497314
Validation loss: 2.132852708299955

Epoch: 5| Step: 7
Training loss: 2.1155037879943848
Validation loss: 2.138358702262243

Epoch: 5| Step: 8
Training loss: 1.0085086822509766
Validation loss: 2.143100991845131

Epoch: 5| Step: 9
Training loss: 1.164275884628296
Validation loss: 2.1278922955195108

Epoch: 5| Step: 10
Training loss: 1.550998568534851
Validation loss: 2.130454182624817

Epoch: 5| Step: 11
Training loss: 1.1096285581588745
Validation loss: 2.1186981797218323

Epoch: 347| Step: 0
Training loss: 0.9287967681884766
Validation loss: 2.130687326192856

Epoch: 5| Step: 1
Training loss: 1.5997668504714966
Validation loss: 2.1217993646860123

Epoch: 5| Step: 2
Training loss: 1.122200846672058
Validation loss: 2.109175761540731

Epoch: 5| Step: 3
Training loss: 2.0613467693328857
Validation loss: 2.1088695377111435

Epoch: 5| Step: 4
Training loss: 1.6649539470672607
Validation loss: 2.1241703629493713

Epoch: 5| Step: 5
Training loss: 1.5315618515014648
Validation loss: 2.136125549674034

Epoch: 5| Step: 6
Training loss: 1.36692214012146
Validation loss: 2.115099017818769

Epoch: 5| Step: 7
Training loss: 1.126683235168457
Validation loss: 2.122624302903811

Epoch: 5| Step: 8
Training loss: 1.9559879302978516
Validation loss: 2.1229620575904846

Epoch: 5| Step: 9
Training loss: 1.1851590871810913
Validation loss: 2.1312718391418457

Epoch: 5| Step: 10
Training loss: 1.7778263092041016
Validation loss: 2.11080310245355

Epoch: 5| Step: 11
Training loss: 2.0884947776794434
Validation loss: 2.1061996022860208

Epoch: 348| Step: 0
Training loss: 1.6761432886123657
Validation loss: 2.1240154256423316

Epoch: 5| Step: 1
Training loss: 1.2011617422103882
Validation loss: 2.1404567460219064

Epoch: 5| Step: 2
Training loss: 1.0410561561584473
Validation loss: 2.122349808613459

Epoch: 5| Step: 3
Training loss: 1.5540177822113037
Validation loss: 2.1296541144450507

Epoch: 5| Step: 4
Training loss: 1.677660584449768
Validation loss: 2.126001367966334

Epoch: 5| Step: 5
Training loss: 1.6912376880645752
Validation loss: 2.1225560158491135

Epoch: 5| Step: 6
Training loss: 1.71853506565094
Validation loss: 2.1435923973719277

Epoch: 5| Step: 7
Training loss: 1.330744981765747
Validation loss: 2.1258581628402076

Epoch: 5| Step: 8
Training loss: 1.4053242206573486
Validation loss: 2.1117119441429772

Epoch: 5| Step: 9
Training loss: 1.3138333559036255
Validation loss: 2.1110884894927344

Epoch: 5| Step: 10
Training loss: 1.4573097229003906
Validation loss: 2.13290606935819

Epoch: 5| Step: 11
Training loss: 1.6644254922866821
Validation loss: 2.129783426721891

Epoch: 349| Step: 0
Training loss: 1.2732350826263428
Validation loss: 2.144988472263018

Epoch: 5| Step: 1
Training loss: 1.8309803009033203
Validation loss: 2.132599929968516

Epoch: 5| Step: 2
Training loss: 0.9152620434761047
Validation loss: 2.1519183168808618

Epoch: 5| Step: 3
Training loss: 1.3737356662750244
Validation loss: 2.1342160453399024

Epoch: 5| Step: 4
Training loss: 1.7693612575531006
Validation loss: 2.115716169277827

Epoch: 5| Step: 5
Training loss: 1.305942177772522
Validation loss: 2.1390863160292306

Epoch: 5| Step: 6
Training loss: 1.5457834005355835
Validation loss: 2.1190204471349716

Epoch: 5| Step: 7
Training loss: 1.341130018234253
Validation loss: 2.1625142693519592

Epoch: 5| Step: 8
Training loss: 1.4957834482192993
Validation loss: 2.155498186747233

Epoch: 5| Step: 9
Training loss: 1.6445255279541016
Validation loss: 2.1571246087551117

Epoch: 5| Step: 10
Training loss: 1.7512996196746826
Validation loss: 2.148277133703232

Epoch: 5| Step: 11
Training loss: 0.879136860370636
Validation loss: 2.1733287970225015

Epoch: 350| Step: 0
Training loss: 1.3289896249771118
Validation loss: 2.191566785176595

Epoch: 5| Step: 1
Training loss: 1.430740475654602
Validation loss: 2.1444402635097504

Epoch: 5| Step: 2
Training loss: 1.7767919301986694
Validation loss: 2.162630081176758

Epoch: 5| Step: 3
Training loss: 1.4953491687774658
Validation loss: 2.1656231929858527

Epoch: 5| Step: 4
Training loss: 1.5764243602752686
Validation loss: 2.186595102151235

Epoch: 5| Step: 5
Training loss: 1.4202848672866821
Validation loss: 2.155080571770668

Epoch: 5| Step: 6
Training loss: 1.2383610010147095
Validation loss: 2.2172001202901206

Epoch: 5| Step: 7
Training loss: 2.0428664684295654
Validation loss: 2.1399016280968985

Epoch: 5| Step: 8
Training loss: 1.584459900856018
Validation loss: 2.173483267426491

Epoch: 5| Step: 9
Training loss: 1.5290337800979614
Validation loss: 2.1756164928277335

Epoch: 5| Step: 10
Training loss: 1.1093366146087646
Validation loss: 2.1527332911888757

Epoch: 5| Step: 11
Training loss: 0.72248375415802
Validation loss: 2.1818446119626365

Epoch: 351| Step: 0
Training loss: 1.611019492149353
Validation loss: 2.1764407803614936

Epoch: 5| Step: 1
Training loss: 1.0080430507659912
Validation loss: 2.1990013072888055

Epoch: 5| Step: 2
Training loss: 1.8431615829467773
Validation loss: 2.1956809957822165

Epoch: 5| Step: 3
Training loss: 1.759662389755249
Validation loss: 2.1755444606145224

Epoch: 5| Step: 4
Training loss: 1.4877166748046875
Validation loss: 2.1685901880264282

Epoch: 5| Step: 5
Training loss: 1.2578999996185303
Validation loss: 2.140887970725695

Epoch: 5| Step: 6
Training loss: 1.0822385549545288
Validation loss: 2.162970761458079

Epoch: 5| Step: 7
Training loss: 1.1978490352630615
Validation loss: 2.1654173930486045

Epoch: 5| Step: 8
Training loss: 2.111949920654297
Validation loss: 2.1512232522169747

Epoch: 5| Step: 9
Training loss: 1.9382994174957275
Validation loss: 2.1724323431650796

Epoch: 5| Step: 10
Training loss: 1.0098392963409424
Validation loss: 2.164291267593702

Epoch: 5| Step: 11
Training loss: 0.5672872066497803
Validation loss: 2.1322198063135147

Epoch: 352| Step: 0
Training loss: 1.6825077533721924
Validation loss: 2.137636070450147

Epoch: 5| Step: 1
Training loss: 1.3196288347244263
Validation loss: 2.103491092721621

Epoch: 5| Step: 2
Training loss: 2.0231072902679443
Validation loss: 2.141045947869619

Epoch: 5| Step: 3
Training loss: 1.505569338798523
Validation loss: 2.134505187471708

Epoch: 5| Step: 4
Training loss: 1.3978025913238525
Validation loss: 2.1203687439362207

Epoch: 5| Step: 5
Training loss: 1.5615415573120117
Validation loss: 2.1273340632518134

Epoch: 5| Step: 6
Training loss: 1.1104810237884521
Validation loss: 2.141597996155421

Epoch: 5| Step: 7
Training loss: 1.769248366355896
Validation loss: 2.1678684701522193

Epoch: 5| Step: 8
Training loss: 1.2032142877578735
Validation loss: 2.1595969448486962

Epoch: 5| Step: 9
Training loss: 1.522761344909668
Validation loss: 2.2185113628705344

Epoch: 5| Step: 10
Training loss: 1.2157918214797974
Validation loss: 2.1738047947486243

Epoch: 5| Step: 11
Training loss: 2.714324474334717
Validation loss: 2.1670320282379785

Epoch: 353| Step: 0
Training loss: 1.5979976654052734
Validation loss: 2.1561410377422967

Epoch: 5| Step: 1
Training loss: 1.1967023611068726
Validation loss: 2.1433943857749305

Epoch: 5| Step: 2
Training loss: 1.4171000719070435
Validation loss: 2.1445949176947274

Epoch: 5| Step: 3
Training loss: 1.0115101337432861
Validation loss: 2.139777511358261

Epoch: 5| Step: 4
Training loss: 1.2318508625030518
Validation loss: 2.1493806590636573

Epoch: 5| Step: 5
Training loss: 1.4042824506759644
Validation loss: 2.147303745150566

Epoch: 5| Step: 6
Training loss: 1.2412745952606201
Validation loss: 2.1542990853389106

Epoch: 5| Step: 7
Training loss: 2.454960584640503
Validation loss: 2.120702773332596

Epoch: 5| Step: 8
Training loss: 1.6276543140411377
Validation loss: 2.1381560216347375

Epoch: 5| Step: 9
Training loss: 1.6888806819915771
Validation loss: 2.116266225775083

Epoch: 5| Step: 10
Training loss: 1.3226814270019531
Validation loss: 2.1249909649292626

Epoch: 5| Step: 11
Training loss: 1.4187805652618408
Validation loss: 2.1210835029681525

Epoch: 354| Step: 0
Training loss: 1.3893280029296875
Validation loss: 2.1424232025941214

Epoch: 5| Step: 1
Training loss: 1.1491981744766235
Validation loss: 2.131330211957296

Epoch: 5| Step: 2
Training loss: 1.6118557453155518
Validation loss: 2.1374401450157166

Epoch: 5| Step: 3
Training loss: 1.6496686935424805
Validation loss: 2.157987649242083

Epoch: 5| Step: 4
Training loss: 1.342259407043457
Validation loss: 2.129840224981308

Epoch: 5| Step: 5
Training loss: 1.3554474115371704
Validation loss: 2.135503520568212

Epoch: 5| Step: 6
Training loss: 1.457728385925293
Validation loss: 2.1667068799336753

Epoch: 5| Step: 7
Training loss: 1.9441823959350586
Validation loss: 2.1806222200393677

Epoch: 5| Step: 8
Training loss: 0.961296558380127
Validation loss: 2.1744567851225534

Epoch: 5| Step: 9
Training loss: 1.5356425046920776
Validation loss: 2.1835312048594155

Epoch: 5| Step: 10
Training loss: 1.7017751932144165
Validation loss: 2.1553555577993393

Epoch: 5| Step: 11
Training loss: 2.0008223056793213
Validation loss: 2.175555740793546

Epoch: 355| Step: 0
Training loss: 1.1003024578094482
Validation loss: 2.180191606283188

Epoch: 5| Step: 1
Training loss: 0.9096555709838867
Validation loss: 2.1586521665255227

Epoch: 5| Step: 2
Training loss: 2.079047679901123
Validation loss: 2.1689825554688773

Epoch: 5| Step: 3
Training loss: 1.3834105730056763
Validation loss: 2.1698265423377356

Epoch: 5| Step: 4
Training loss: 1.3316292762756348
Validation loss: 2.1650377213954926

Epoch: 5| Step: 5
Training loss: 1.7409915924072266
Validation loss: 2.1536933978398642

Epoch: 5| Step: 6
Training loss: 1.5003695487976074
Validation loss: 2.182717194159826

Epoch: 5| Step: 7
Training loss: 1.4858858585357666
Validation loss: 2.1534432023763657

Epoch: 5| Step: 8
Training loss: 1.8055976629257202
Validation loss: 2.109676162401835

Epoch: 5| Step: 9
Training loss: 1.5933972597122192
Validation loss: 2.151186520854632

Epoch: 5| Step: 10
Training loss: 1.0583449602127075
Validation loss: 2.1292655616998672

Epoch: 5| Step: 11
Training loss: 1.867175817489624
Validation loss: 2.1119116693735123

Epoch: 356| Step: 0
Training loss: 1.3374344110488892
Validation loss: 2.1216989954312644

Epoch: 5| Step: 1
Training loss: 1.3784611225128174
Validation loss: 2.1241196393966675

Epoch: 5| Step: 2
Training loss: 1.0863282680511475
Validation loss: 2.114287167787552

Epoch: 5| Step: 3
Training loss: 1.0749156475067139
Validation loss: 2.1148169289032617

Epoch: 5| Step: 4
Training loss: 1.3956700563430786
Validation loss: 2.138904641071955

Epoch: 5| Step: 5
Training loss: 1.5275846719741821
Validation loss: 2.1592846363782883

Epoch: 5| Step: 6
Training loss: 1.8466695547103882
Validation loss: 2.136081740260124

Epoch: 5| Step: 7
Training loss: 1.8560478687286377
Validation loss: 2.140953297416369

Epoch: 5| Step: 8
Training loss: 1.5485365390777588
Validation loss: 2.0956712464491525

Epoch: 5| Step: 9
Training loss: 1.4196522235870361
Validation loss: 2.130214715997378

Epoch: 5| Step: 10
Training loss: 1.442384123802185
Validation loss: 2.1343715836604438

Epoch: 5| Step: 11
Training loss: 2.0734081268310547
Validation loss: 2.112925479809443

Epoch: 357| Step: 0
Training loss: 1.302276372909546
Validation loss: 2.1020471254984536

Epoch: 5| Step: 1
Training loss: 1.672144889831543
Validation loss: 2.1066938440004983

Epoch: 5| Step: 2
Training loss: 1.4290136098861694
Validation loss: 2.093185971180598

Epoch: 5| Step: 3
Training loss: 1.477211356163025
Validation loss: 2.122177670399348

Epoch: 5| Step: 4
Training loss: 1.3933935165405273
Validation loss: 2.155962809920311

Epoch: 5| Step: 5
Training loss: 1.6762912273406982
Validation loss: 2.128220950563749

Epoch: 5| Step: 6
Training loss: 1.8083245754241943
Validation loss: 2.150400683283806

Epoch: 5| Step: 7
Training loss: 1.1407822370529175
Validation loss: 2.177496612071991

Epoch: 5| Step: 8
Training loss: 1.7135164737701416
Validation loss: 2.1670263608296714

Epoch: 5| Step: 9
Training loss: 1.3622503280639648
Validation loss: 2.1386486490567527

Epoch: 5| Step: 10
Training loss: 1.0777279138565063
Validation loss: 2.135243927439054

Epoch: 5| Step: 11
Training loss: 2.1592674255371094
Validation loss: 2.1297824531793594

Epoch: 358| Step: 0
Training loss: 1.1145250797271729
Validation loss: 2.157909611860911

Epoch: 5| Step: 1
Training loss: 1.3816486597061157
Validation loss: 2.1273303578297296

Epoch: 5| Step: 2
Training loss: 1.2889710664749146
Validation loss: 2.1540037194887796

Epoch: 5| Step: 3
Training loss: 1.70598566532135
Validation loss: 2.1750320941209793

Epoch: 5| Step: 4
Training loss: 1.5854488611221313
Validation loss: 2.1671078900496163

Epoch: 5| Step: 5
Training loss: 1.8800313472747803
Validation loss: 2.160298074285189

Epoch: 5| Step: 6
Training loss: 1.3739687204360962
Validation loss: 2.15420367817084

Epoch: 5| Step: 7
Training loss: 1.2872408628463745
Validation loss: 2.12874927620093

Epoch: 5| Step: 8
Training loss: 1.7177985906600952
Validation loss: 2.13087464372317

Epoch: 5| Step: 9
Training loss: 1.312570571899414
Validation loss: 2.1471426089604697

Epoch: 5| Step: 10
Training loss: 1.7120323181152344
Validation loss: 2.139410828550657

Epoch: 5| Step: 11
Training loss: 1.7634105682373047
Validation loss: 2.197207679351171

Epoch: 359| Step: 0
Training loss: 1.6665689945220947
Validation loss: 2.2145251830418906

Epoch: 5| Step: 1
Training loss: 1.6375772953033447
Validation loss: 2.2636821071306863

Epoch: 5| Step: 2
Training loss: 1.5710774660110474
Validation loss: 2.2615546882152557

Epoch: 5| Step: 3
Training loss: 1.2898350954055786
Validation loss: 2.2240780542294183

Epoch: 5| Step: 4
Training loss: 1.492272138595581
Validation loss: 2.2090692122777305

Epoch: 5| Step: 5
Training loss: 1.8494644165039062
Validation loss: 2.1909648378690085

Epoch: 5| Step: 6
Training loss: 1.1824631690979004
Validation loss: 2.2119174698988595

Epoch: 5| Step: 7
Training loss: 1.1702117919921875
Validation loss: 2.1967881123224893

Epoch: 5| Step: 8
Training loss: 1.509735107421875
Validation loss: 2.196199506521225

Epoch: 5| Step: 9
Training loss: 1.5677764415740967
Validation loss: 2.2073740512132645

Epoch: 5| Step: 10
Training loss: 2.0253326892852783
Validation loss: 2.1778573592503867

Epoch: 5| Step: 11
Training loss: 3.0267457962036133
Validation loss: 2.202239215373993

Epoch: 360| Step: 0
Training loss: 0.7601850032806396
Validation loss: 2.182709733645121

Epoch: 5| Step: 1
Training loss: 1.8580982685089111
Validation loss: 2.187389721473058

Epoch: 5| Step: 2
Training loss: 0.8715621829032898
Validation loss: 2.179836889108022

Epoch: 5| Step: 3
Training loss: 1.1837657690048218
Validation loss: 2.121201813220978

Epoch: 5| Step: 4
Training loss: 1.3624781370162964
Validation loss: 2.1673538188139596

Epoch: 5| Step: 5
Training loss: 1.5043011903762817
Validation loss: 2.144030143817266

Epoch: 5| Step: 6
Training loss: 1.707187294960022
Validation loss: 2.1580952207247415

Epoch: 5| Step: 7
Training loss: 0.9736698269844055
Validation loss: 2.186249161760012

Epoch: 5| Step: 8
Training loss: 1.5904901027679443
Validation loss: 2.169140617052714

Epoch: 5| Step: 9
Training loss: 2.355128765106201
Validation loss: 2.1715953052043915

Epoch: 5| Step: 10
Training loss: 1.4771144390106201
Validation loss: 2.1674048950274787

Epoch: 5| Step: 11
Training loss: 0.5961160063743591
Validation loss: 2.1739826599756875

Epoch: 361| Step: 0
Training loss: 0.8853989839553833
Validation loss: 2.1647989253203073

Epoch: 5| Step: 1
Training loss: 0.8860588073730469
Validation loss: 2.1677306294441223

Epoch: 5| Step: 2
Training loss: 1.258339762687683
Validation loss: 2.1946604450543723

Epoch: 5| Step: 3
Training loss: 1.6766183376312256
Validation loss: 2.1750490814447403

Epoch: 5| Step: 4
Training loss: 1.6727535724639893
Validation loss: 2.1935928414265313

Epoch: 5| Step: 5
Training loss: 1.5289647579193115
Validation loss: 2.2177370339632034

Epoch: 5| Step: 6
Training loss: 1.4490456581115723
Validation loss: 2.216109270850817

Epoch: 5| Step: 7
Training loss: 2.380063772201538
Validation loss: 2.2069649497667947

Epoch: 5| Step: 8
Training loss: 1.4916828870773315
Validation loss: 2.22865783671538

Epoch: 5| Step: 9
Training loss: 1.30833101272583
Validation loss: 2.233773559331894

Epoch: 5| Step: 10
Training loss: 1.7330137491226196
Validation loss: 2.21063698331515

Epoch: 5| Step: 11
Training loss: 1.2770216464996338
Validation loss: 2.1999754309654236

Epoch: 362| Step: 0
Training loss: 1.4969065189361572
Validation loss: 2.195726379752159

Epoch: 5| Step: 1
Training loss: 1.3588697910308838
Validation loss: 2.2271738251050315

Epoch: 5| Step: 2
Training loss: 2.5981104373931885
Validation loss: 2.2314454515775046

Epoch: 5| Step: 3
Training loss: 1.8110071420669556
Validation loss: 2.2395567993323007

Epoch: 5| Step: 4
Training loss: 1.3747836351394653
Validation loss: 2.2240575651327767

Epoch: 5| Step: 5
Training loss: 1.8399337530136108
Validation loss: 2.232996260126432

Epoch: 5| Step: 6
Training loss: 1.7883415222167969
Validation loss: 2.189823900659879

Epoch: 5| Step: 7
Training loss: 1.9203342199325562
Validation loss: 2.176894873380661

Epoch: 5| Step: 8
Training loss: 1.3552734851837158
Validation loss: 2.170539677143097

Epoch: 5| Step: 9
Training loss: 2.049790143966675
Validation loss: 2.1452910006046295

Epoch: 5| Step: 10
Training loss: 1.352843999862671
Validation loss: 2.1094928830862045

Epoch: 5| Step: 11
Training loss: 2.6569149494171143
Validation loss: 2.1291545927524567

Epoch: 363| Step: 0
Training loss: 1.7299234867095947
Validation loss: 2.119797388712565

Epoch: 5| Step: 1
Training loss: 1.5056779384613037
Validation loss: 2.135897343357404

Epoch: 5| Step: 2
Training loss: 1.769021987915039
Validation loss: 2.1574192692836127

Epoch: 5| Step: 3
Training loss: 1.4828128814697266
Validation loss: 2.141516163945198

Epoch: 5| Step: 4
Training loss: 1.1574692726135254
Validation loss: 2.149545510609945

Epoch: 5| Step: 5
Training loss: 1.6734039783477783
Validation loss: 2.1359751572211585

Epoch: 5| Step: 6
Training loss: 1.197416067123413
Validation loss: 2.136417324344317

Epoch: 5| Step: 7
Training loss: 1.6499541997909546
Validation loss: 2.1562079389890036

Epoch: 5| Step: 8
Training loss: 1.9790849685668945
Validation loss: 2.160138577222824

Epoch: 5| Step: 9
Training loss: 1.956861138343811
Validation loss: 2.150218904018402

Epoch: 5| Step: 10
Training loss: 1.2066384553909302
Validation loss: 2.1183104266723

Epoch: 5| Step: 11
Training loss: 2.2597179412841797
Validation loss: 2.124469518661499

Epoch: 364| Step: 0
Training loss: 1.1708614826202393
Validation loss: 2.159843842188517

Epoch: 5| Step: 1
Training loss: 1.6293128728866577
Validation loss: 2.186425323287646

Epoch: 5| Step: 2
Training loss: 2.556128978729248
Validation loss: 2.161785994966825

Epoch: 5| Step: 3
Training loss: 1.3924376964569092
Validation loss: 2.2011387745539346

Epoch: 5| Step: 4
Training loss: 2.03108549118042
Validation loss: 2.1835799316565194

Epoch: 5| Step: 5
Training loss: 1.3149956464767456
Validation loss: 2.123015304406484

Epoch: 5| Step: 6
Training loss: 1.5144257545471191
Validation loss: 2.162385250131289

Epoch: 5| Step: 7
Training loss: 1.4419969320297241
Validation loss: 2.1697601079940796

Epoch: 5| Step: 8
Training loss: 1.4935195446014404
Validation loss: 2.182130351662636

Epoch: 5| Step: 9
Training loss: 0.8203012347221375
Validation loss: 2.1867368717988334

Epoch: 5| Step: 10
Training loss: 1.1882011890411377
Validation loss: 2.184065500895182

Epoch: 5| Step: 11
Training loss: 1.5989259481430054
Validation loss: 2.17165199915568

Epoch: 365| Step: 0
Training loss: 1.213364601135254
Validation loss: 2.1665364106496177

Epoch: 5| Step: 1
Training loss: 1.2743237018585205
Validation loss: 2.1701567471027374

Epoch: 5| Step: 2
Training loss: 1.123402714729309
Validation loss: 2.2182016472021737

Epoch: 5| Step: 3
Training loss: 1.5700829029083252
Validation loss: 2.2265402177969613

Epoch: 5| Step: 4
Training loss: 1.6024932861328125
Validation loss: 2.2602091133594513

Epoch: 5| Step: 5
Training loss: 1.4368460178375244
Validation loss: 2.261295586824417

Epoch: 5| Step: 6
Training loss: 1.540554404258728
Validation loss: 2.1960774064064026

Epoch: 5| Step: 7
Training loss: 2.300212860107422
Validation loss: 2.193252608180046

Epoch: 5| Step: 8
Training loss: 2.2559866905212402
Validation loss: 2.1781130731105804

Epoch: 5| Step: 9
Training loss: 1.411277174949646
Validation loss: 2.193853735923767

Epoch: 5| Step: 10
Training loss: 1.139486312866211
Validation loss: 2.201944023370743

Epoch: 5| Step: 11
Training loss: 1.128568172454834
Validation loss: 2.21419965227445

Epoch: 366| Step: 0
Training loss: 1.588975191116333
Validation loss: 2.1894045869509378

Epoch: 5| Step: 1
Training loss: 1.568639874458313
Validation loss: 2.1750298788150153

Epoch: 5| Step: 2
Training loss: 0.9644691348075867
Validation loss: 2.1771644155184426

Epoch: 5| Step: 3
Training loss: 0.9361270070075989
Validation loss: 2.1484588285287223

Epoch: 5| Step: 4
Training loss: 1.5300252437591553
Validation loss: 2.1528398990631104

Epoch: 5| Step: 5
Training loss: 1.5123610496520996
Validation loss: 2.1501981069644294

Epoch: 5| Step: 6
Training loss: 1.3344879150390625
Validation loss: 2.171523302793503

Epoch: 5| Step: 7
Training loss: 1.98318612575531
Validation loss: 2.186337575316429

Epoch: 5| Step: 8
Training loss: 2.0094547271728516
Validation loss: 2.1787557701269784

Epoch: 5| Step: 9
Training loss: 1.2929105758666992
Validation loss: 2.178702399134636

Epoch: 5| Step: 10
Training loss: 1.523709774017334
Validation loss: 2.1421661178270974

Epoch: 5| Step: 11
Training loss: 0.6472837924957275
Validation loss: 2.150713841120402

Epoch: 367| Step: 0
Training loss: 1.7357447147369385
Validation loss: 2.1620719730854034

Epoch: 5| Step: 1
Training loss: 1.5644983053207397
Validation loss: 2.2036366959412894

Epoch: 5| Step: 2
Training loss: 1.72176992893219
Validation loss: 2.1881262312332788

Epoch: 5| Step: 3
Training loss: 1.2810064554214478
Validation loss: 2.1539690593878427

Epoch: 5| Step: 4
Training loss: 1.6800556182861328
Validation loss: 2.1540499726931253

Epoch: 5| Step: 5
Training loss: 1.1510069370269775
Validation loss: 2.1524361421664557

Epoch: 5| Step: 6
Training loss: 1.1385043859481812
Validation loss: 2.18989659845829

Epoch: 5| Step: 7
Training loss: 1.2498109340667725
Validation loss: 2.156432787577311

Epoch: 5| Step: 8
Training loss: 1.4210755825042725
Validation loss: 2.159492075443268

Epoch: 5| Step: 9
Training loss: 1.294041633605957
Validation loss: 2.1789116064707437

Epoch: 5| Step: 10
Training loss: 1.98385488986969
Validation loss: 2.141677295168241

Epoch: 5| Step: 11
Training loss: 1.1387271881103516
Validation loss: 2.18030908703804

Epoch: 368| Step: 0
Training loss: 1.0504993200302124
Validation loss: 2.1584313164154687

Epoch: 5| Step: 1
Training loss: 1.1225879192352295
Validation loss: 2.170107444127401

Epoch: 5| Step: 2
Training loss: 1.2743059396743774
Validation loss: 2.134679079055786

Epoch: 5| Step: 3
Training loss: 1.6254669427871704
Validation loss: 2.1569033761819205

Epoch: 5| Step: 4
Training loss: 1.5179582834243774
Validation loss: 2.153832177321116

Epoch: 5| Step: 5
Training loss: 1.3246710300445557
Validation loss: 2.143686220049858

Epoch: 5| Step: 6
Training loss: 1.7280641794204712
Validation loss: 2.128662660717964

Epoch: 5| Step: 7
Training loss: 0.9396853446960449
Validation loss: 2.1369491269191108

Epoch: 5| Step: 8
Training loss: 1.4162076711654663
Validation loss: 2.1481297314167023

Epoch: 5| Step: 9
Training loss: 2.236381769180298
Validation loss: 2.139286905527115

Epoch: 5| Step: 10
Training loss: 1.4798295497894287
Validation loss: 2.144042213757833

Epoch: 5| Step: 11
Training loss: 2.3033580780029297
Validation loss: 2.1545709123214087

Epoch: 369| Step: 0
Training loss: 1.1121790409088135
Validation loss: 2.13726336757342

Epoch: 5| Step: 1
Training loss: 1.0945419073104858
Validation loss: 2.1864515046278634

Epoch: 5| Step: 2
Training loss: 1.0521118640899658
Validation loss: 2.1273110459248223

Epoch: 5| Step: 3
Training loss: 1.8839887380599976
Validation loss: 2.154359514514605

Epoch: 5| Step: 4
Training loss: 2.180912971496582
Validation loss: 2.1604791482289634

Epoch: 5| Step: 5
Training loss: 1.6270147562026978
Validation loss: 2.15743750333786

Epoch: 5| Step: 6
Training loss: 1.341742753982544
Validation loss: 2.169865826765696

Epoch: 5| Step: 7
Training loss: 1.1577680110931396
Validation loss: 2.1692709227403006

Epoch: 5| Step: 8
Training loss: 0.9305061101913452
Validation loss: 2.148974304397901

Epoch: 5| Step: 9
Training loss: 1.4027528762817383
Validation loss: 2.1630264073610306

Epoch: 5| Step: 10
Training loss: 1.9304622411727905
Validation loss: 2.120766113201777

Epoch: 5| Step: 11
Training loss: 0.6930885314941406
Validation loss: 2.1468259543180466

Epoch: 370| Step: 0
Training loss: 1.450855016708374
Validation loss: 2.135217030843099

Epoch: 5| Step: 1
Training loss: 1.2787503004074097
Validation loss: 2.126871958374977

Epoch: 5| Step: 2
Training loss: 1.0613324642181396
Validation loss: 2.1215798954168954

Epoch: 5| Step: 3
Training loss: 1.5775558948516846
Validation loss: 2.1236002345879874

Epoch: 5| Step: 4
Training loss: 1.3763916492462158
Validation loss: 2.1436051477988562

Epoch: 5| Step: 5
Training loss: 1.6126813888549805
Validation loss: 2.12847105662028

Epoch: 5| Step: 6
Training loss: 1.462269902229309
Validation loss: 2.1206065664688745

Epoch: 5| Step: 7
Training loss: 1.1197508573532104
Validation loss: 2.1469582666953406

Epoch: 5| Step: 8
Training loss: 1.6075719594955444
Validation loss: 2.128742297490438

Epoch: 5| Step: 9
Training loss: 2.1658833026885986
Validation loss: 2.1244149655103683

Epoch: 5| Step: 10
Training loss: 1.0123951435089111
Validation loss: 2.146864945689837

Epoch: 5| Step: 11
Training loss: 1.1182278394699097
Validation loss: 2.130522151788076

Epoch: 371| Step: 0
Training loss: 1.712154746055603
Validation loss: 2.156068444252014

Epoch: 5| Step: 1
Training loss: 0.6325803995132446
Validation loss: 2.1392614791790643

Epoch: 5| Step: 2
Training loss: 1.175500512123108
Validation loss: 2.155879149834315

Epoch: 5| Step: 3
Training loss: 1.7115952968597412
Validation loss: 2.1448770066102347

Epoch: 5| Step: 4
Training loss: 1.6618545055389404
Validation loss: 2.174902707338333

Epoch: 5| Step: 5
Training loss: 1.7831752300262451
Validation loss: 2.1519409120082855

Epoch: 5| Step: 6
Training loss: 1.834263801574707
Validation loss: 2.160611550013224

Epoch: 5| Step: 7
Training loss: 0.9529750943183899
Validation loss: 2.1467812756697335

Epoch: 5| Step: 8
Training loss: 1.7220500707626343
Validation loss: 2.162726506590843

Epoch: 5| Step: 9
Training loss: 1.3056542873382568
Validation loss: 2.1499130527178445

Epoch: 5| Step: 10
Training loss: 0.9088321924209595
Validation loss: 2.1362378299236298

Epoch: 5| Step: 11
Training loss: 1.484006404876709
Validation loss: 2.1096003353595734

Epoch: 372| Step: 0
Training loss: 1.3898355960845947
Validation loss: 2.1201911320288978

Epoch: 5| Step: 1
Training loss: 1.0901873111724854
Validation loss: 2.137309660514196

Epoch: 5| Step: 2
Training loss: 1.833751916885376
Validation loss: 2.1050969660282135

Epoch: 5| Step: 3
Training loss: 1.2637720108032227
Validation loss: 2.157352094848951

Epoch: 5| Step: 4
Training loss: 1.2479884624481201
Validation loss: 2.083365559577942

Epoch: 5| Step: 5
Training loss: 1.6075446605682373
Validation loss: 2.113923877477646

Epoch: 5| Step: 6
Training loss: 1.11516273021698
Validation loss: 2.1024806598822274

Epoch: 5| Step: 7
Training loss: 1.5757153034210205
Validation loss: 2.1183771193027496

Epoch: 5| Step: 8
Training loss: 1.3832156658172607
Validation loss: 2.1262457917133966

Epoch: 5| Step: 9
Training loss: 1.6284765005111694
Validation loss: 2.1421934763590493

Epoch: 5| Step: 10
Training loss: 1.4360488653182983
Validation loss: 2.1336900293827057

Epoch: 5| Step: 11
Training loss: 0.30821800231933594
Validation loss: 2.161237587531408

Epoch: 373| Step: 0
Training loss: 0.9946606755256653
Validation loss: 2.1698543975750604

Epoch: 5| Step: 1
Training loss: 1.5666048526763916
Validation loss: 2.145237768689791

Epoch: 5| Step: 2
Training loss: 1.272416114807129
Validation loss: 2.129893014828364

Epoch: 5| Step: 3
Training loss: 1.9387925863265991
Validation loss: 2.0922118673721948

Epoch: 5| Step: 4
Training loss: 0.9901841878890991
Validation loss: 2.164232909679413

Epoch: 5| Step: 5
Training loss: 1.4858477115631104
Validation loss: 2.1582392950852713

Epoch: 5| Step: 6
Training loss: 1.260016679763794
Validation loss: 2.1345477600892386

Epoch: 5| Step: 7
Training loss: 1.448335886001587
Validation loss: 2.1557807127634683

Epoch: 5| Step: 8
Training loss: 1.4668976068496704
Validation loss: 2.180035814642906

Epoch: 5| Step: 9
Training loss: 1.5074844360351562
Validation loss: 2.1454793761173883

Epoch: 5| Step: 10
Training loss: 2.2026255130767822
Validation loss: 2.1403825183709464

Epoch: 5| Step: 11
Training loss: 1.0267863273620605
Validation loss: 2.1245989948511124

Epoch: 374| Step: 0
Training loss: 1.2429096698760986
Validation loss: 2.138017629583677

Epoch: 5| Step: 1
Training loss: 1.1090527772903442
Validation loss: 2.173963651061058

Epoch: 5| Step: 2
Training loss: 1.5381025075912476
Validation loss: 2.129132221142451

Epoch: 5| Step: 3
Training loss: 0.8037588000297546
Validation loss: 2.1600080927213035

Epoch: 5| Step: 4
Training loss: 1.8261497020721436
Validation loss: 2.1593960970640182

Epoch: 5| Step: 5
Training loss: 1.0027821063995361
Validation loss: 2.1903534134229026

Epoch: 5| Step: 6
Training loss: 1.6906734704971313
Validation loss: 2.175873637199402

Epoch: 5| Step: 7
Training loss: 1.5298740863800049
Validation loss: 2.1924459834893546

Epoch: 5| Step: 8
Training loss: 1.4691022634506226
Validation loss: 2.1931988100210824

Epoch: 5| Step: 9
Training loss: 1.7531627416610718
Validation loss: 2.1770642399787903

Epoch: 5| Step: 10
Training loss: 1.6904271841049194
Validation loss: 2.1473492284615836

Epoch: 5| Step: 11
Training loss: 0.8162156343460083
Validation loss: 2.1537647048632302

Epoch: 375| Step: 0
Training loss: 1.153891921043396
Validation loss: 2.168483833471934

Epoch: 5| Step: 1
Training loss: 1.52437424659729
Validation loss: 2.1701151778300605

Epoch: 5| Step: 2
Training loss: 1.2423676252365112
Validation loss: 2.207223226626714

Epoch: 5| Step: 3
Training loss: 1.19217848777771
Validation loss: 2.166537339488665

Epoch: 5| Step: 4
Training loss: 2.0078811645507812
Validation loss: 2.2137260337670646

Epoch: 5| Step: 5
Training loss: 1.3945066928863525
Validation loss: 2.198045089840889

Epoch: 5| Step: 6
Training loss: 1.932127594947815
Validation loss: 2.172513484954834

Epoch: 5| Step: 7
Training loss: 1.7996938228607178
Validation loss: 2.174858197569847

Epoch: 5| Step: 8
Training loss: 1.0418970584869385
Validation loss: 2.173626869916916

Epoch: 5| Step: 9
Training loss: 2.1093170642852783
Validation loss: 2.1896876146396003

Epoch: 5| Step: 10
Training loss: 0.7757488489151001
Validation loss: 2.1682796428600946

Epoch: 5| Step: 11
Training loss: 1.1297883987426758
Validation loss: 2.168730527162552

Epoch: 376| Step: 0
Training loss: 1.293993353843689
Validation loss: 2.1665268689393997

Epoch: 5| Step: 1
Training loss: 1.103094458580017
Validation loss: 2.1908378452062607

Epoch: 5| Step: 2
Training loss: 1.670800805091858
Validation loss: 2.1820151110490165

Epoch: 5| Step: 3
Training loss: 1.45223867893219
Validation loss: 2.156619355082512

Epoch: 5| Step: 4
Training loss: 1.335493803024292
Validation loss: 2.1589732269446054

Epoch: 5| Step: 5
Training loss: 1.3670272827148438
Validation loss: 2.174734349052111

Epoch: 5| Step: 6
Training loss: 2.1699962615966797
Validation loss: 2.174594759941101

Epoch: 5| Step: 7
Training loss: 1.2639604806900024
Validation loss: 2.2214432756106057

Epoch: 5| Step: 8
Training loss: 1.2380768060684204
Validation loss: 2.1978940268357596

Epoch: 5| Step: 9
Training loss: 1.2156627178192139
Validation loss: 2.2326497435569763

Epoch: 5| Step: 10
Training loss: 1.6309106349945068
Validation loss: 2.213169982035955

Epoch: 5| Step: 11
Training loss: 0.23217490315437317
Validation loss: 2.2029143273830414

Epoch: 377| Step: 0
Training loss: 1.056799054145813
Validation loss: 2.1960421254237494

Epoch: 5| Step: 1
Training loss: 1.0551047325134277
Validation loss: 2.1852295895417533

Epoch: 5| Step: 2
Training loss: 1.5458844900131226
Validation loss: 2.218613783518473

Epoch: 5| Step: 3
Training loss: 1.5005781650543213
Validation loss: 2.1965723733107247

Epoch: 5| Step: 4
Training loss: 1.715227484703064
Validation loss: 2.1643685549497604

Epoch: 5| Step: 5
Training loss: 1.726636528968811
Validation loss: 2.1855919460455575

Epoch: 5| Step: 6
Training loss: 1.5033462047576904
Validation loss: 2.1611873358488083

Epoch: 5| Step: 7
Training loss: 0.784795343875885
Validation loss: 2.1687167237202325

Epoch: 5| Step: 8
Training loss: 0.8700519800186157
Validation loss: 2.133199473222097

Epoch: 5| Step: 9
Training loss: 1.338257908821106
Validation loss: 2.1482849021752677

Epoch: 5| Step: 10
Training loss: 2.1019833087921143
Validation loss: 2.1587367355823517

Epoch: 5| Step: 11
Training loss: 1.4061717987060547
Validation loss: 2.173253824313482

Epoch: 378| Step: 0
Training loss: 1.4677411317825317
Validation loss: 2.1683605213960013

Epoch: 5| Step: 1
Training loss: 1.7171459197998047
Validation loss: 2.2047275404135385

Epoch: 5| Step: 2
Training loss: 1.5250195264816284
Validation loss: 2.1766582876443863

Epoch: 5| Step: 3
Training loss: 1.473152995109558
Validation loss: 2.1776982843875885

Epoch: 5| Step: 4
Training loss: 1.3102174997329712
Validation loss: 2.182328393061956

Epoch: 5| Step: 5
Training loss: 1.2438249588012695
Validation loss: 2.1904380917549133

Epoch: 5| Step: 6
Training loss: 2.0489277839660645
Validation loss: 2.1977366010348

Epoch: 5| Step: 7
Training loss: 1.4021559953689575
Validation loss: 2.2170806427796683

Epoch: 5| Step: 8
Training loss: 1.1361316442489624
Validation loss: 2.2175947427749634

Epoch: 5| Step: 9
Training loss: 1.4462188482284546
Validation loss: 2.2161358992258706

Epoch: 5| Step: 10
Training loss: 1.0277156829833984
Validation loss: 2.1858897109826407

Epoch: 5| Step: 11
Training loss: 1.5147274732589722
Validation loss: 2.190004587173462

Epoch: 379| Step: 0
Training loss: 1.280796766281128
Validation loss: 2.1677507857481637

Epoch: 5| Step: 1
Training loss: 1.8184974193572998
Validation loss: 2.2057184179623923

Epoch: 5| Step: 2
Training loss: 1.0619105100631714
Validation loss: 2.1938357651233673

Epoch: 5| Step: 3
Training loss: 1.8365663290023804
Validation loss: 2.2085301876068115

Epoch: 5| Step: 4
Training loss: 1.3800088167190552
Validation loss: 2.1633137315511703

Epoch: 5| Step: 5
Training loss: 1.5306655168533325
Validation loss: 2.16163577636083

Epoch: 5| Step: 6
Training loss: 0.841063380241394
Validation loss: 2.1562483658393226

Epoch: 5| Step: 7
Training loss: 1.610608696937561
Validation loss: 2.143508702516556

Epoch: 5| Step: 8
Training loss: 1.5071313381195068
Validation loss: 2.1163564572731652

Epoch: 5| Step: 9
Training loss: 1.4692447185516357
Validation loss: 2.139802724123001

Epoch: 5| Step: 10
Training loss: 1.2549803256988525
Validation loss: 2.1261073599259057

Epoch: 5| Step: 11
Training loss: 1.55660080909729
Validation loss: 2.1278171638647714

Epoch: 380| Step: 0
Training loss: 1.6195627450942993
Validation loss: 2.135798583428065

Epoch: 5| Step: 1
Training loss: 1.0987495183944702
Validation loss: 2.144157479206721

Epoch: 5| Step: 2
Training loss: 1.7462962865829468
Validation loss: 2.1556926667690277

Epoch: 5| Step: 3
Training loss: 1.1669299602508545
Validation loss: 2.17404734591643

Epoch: 5| Step: 4
Training loss: 1.7505162954330444
Validation loss: 2.1773848682641983

Epoch: 5| Step: 5
Training loss: 0.9884780049324036
Validation loss: 2.163750544190407

Epoch: 5| Step: 6
Training loss: 1.4402413368225098
Validation loss: 2.189204439520836

Epoch: 5| Step: 7
Training loss: 1.375905990600586
Validation loss: 2.128002569079399

Epoch: 5| Step: 8
Training loss: 1.64565908908844
Validation loss: 2.1794584741195044

Epoch: 5| Step: 9
Training loss: 1.4137579202651978
Validation loss: 2.142343988021215

Epoch: 5| Step: 10
Training loss: 1.0188014507293701
Validation loss: 2.1566606760025024

Epoch: 5| Step: 11
Training loss: 2.863349676132202
Validation loss: 2.1455573042233786

Epoch: 381| Step: 0
Training loss: 2.336496591567993
Validation loss: 2.1535195310910544

Epoch: 5| Step: 1
Training loss: 1.3550554513931274
Validation loss: 2.1838257163763046

Epoch: 5| Step: 2
Training loss: 1.254706621170044
Validation loss: 2.1859742204348245

Epoch: 5| Step: 3
Training loss: 1.5619810819625854
Validation loss: 2.196866288781166

Epoch: 5| Step: 4
Training loss: 1.8914611339569092
Validation loss: 2.163351153333982

Epoch: 5| Step: 5
Training loss: 1.5630220174789429
Validation loss: 2.1397800892591476

Epoch: 5| Step: 6
Training loss: 1.3653050661087036
Validation loss: 2.1450888564189277

Epoch: 5| Step: 7
Training loss: 1.5481302738189697
Validation loss: 2.125151515007019

Epoch: 5| Step: 8
Training loss: 1.479980230331421
Validation loss: 2.148465429743131

Epoch: 5| Step: 9
Training loss: 0.9133203625679016
Validation loss: 2.1599808633327484

Epoch: 5| Step: 10
Training loss: 1.7097513675689697
Validation loss: 2.1417095760504403

Epoch: 5| Step: 11
Training loss: 1.4046744108200073
Validation loss: 2.1453856776158013

Epoch: 382| Step: 0
Training loss: 1.4567867517471313
Validation loss: 2.176621521512667

Epoch: 5| Step: 1
Training loss: 1.3866426944732666
Validation loss: 2.1865160365899405

Epoch: 5| Step: 2
Training loss: 1.649125099182129
Validation loss: 2.1410118093093238

Epoch: 5| Step: 3
Training loss: 1.8503506183624268
Validation loss: 2.1377529750267663

Epoch: 5| Step: 4
Training loss: 1.2298359870910645
Validation loss: 2.1485660076141357

Epoch: 5| Step: 5
Training loss: 1.9683490991592407
Validation loss: 2.134082704782486

Epoch: 5| Step: 6
Training loss: 1.1656070947647095
Validation loss: 2.161898692448934

Epoch: 5| Step: 7
Training loss: 1.2632485628128052
Validation loss: 2.117742324868838

Epoch: 5| Step: 8
Training loss: 1.3885737657546997
Validation loss: 2.142421027024587

Epoch: 5| Step: 9
Training loss: 1.153181791305542
Validation loss: 2.139125486214956

Epoch: 5| Step: 10
Training loss: 1.0339226722717285
Validation loss: 2.1674965620040894

Epoch: 5| Step: 11
Training loss: 1.6611299514770508
Validation loss: 2.168641338745753

Epoch: 383| Step: 0
Training loss: 1.5302178859710693
Validation loss: 2.1898192167282104

Epoch: 5| Step: 1
Training loss: 1.4859669208526611
Validation loss: 2.18365686138471

Epoch: 5| Step: 2
Training loss: 1.9520432949066162
Validation loss: 2.180426210165024

Epoch: 5| Step: 3
Training loss: 1.5296657085418701
Validation loss: 2.1338914732138314

Epoch: 5| Step: 4
Training loss: 1.8878872394561768
Validation loss: 2.1397776106993356

Epoch: 5| Step: 5
Training loss: 1.4781196117401123
Validation loss: 2.1544351279735565

Epoch: 5| Step: 6
Training loss: 1.2808781862258911
Validation loss: 2.1212297628323236

Epoch: 5| Step: 7
Training loss: 1.4651397466659546
Validation loss: 2.1268852253754935

Epoch: 5| Step: 8
Training loss: 1.216347098350525
Validation loss: 2.1421761959791183

Epoch: 5| Step: 9
Training loss: 1.0244911909103394
Validation loss: 2.1609090814987817

Epoch: 5| Step: 10
Training loss: 0.6038001775741577
Validation loss: 2.1560033013423285

Epoch: 5| Step: 11
Training loss: 0.40723490715026855
Validation loss: 2.159707168738047

Epoch: 384| Step: 0
Training loss: 0.7491410374641418
Validation loss: 2.2008358786503472

Epoch: 5| Step: 1
Training loss: 1.0189141035079956
Validation loss: 2.2121447026729584

Epoch: 5| Step: 2
Training loss: 1.9447253942489624
Validation loss: 2.232429181536039

Epoch: 5| Step: 3
Training loss: 2.1638786792755127
Validation loss: 2.2494737207889557

Epoch: 5| Step: 4
Training loss: 1.9468923807144165
Validation loss: 2.233522812525431

Epoch: 5| Step: 5
Training loss: 1.359601378440857
Validation loss: 2.247749408086141

Epoch: 5| Step: 6
Training loss: 1.479555368423462
Validation loss: 2.214427500963211

Epoch: 5| Step: 7
Training loss: 2.258305072784424
Validation loss: 2.2045343468586602

Epoch: 5| Step: 8
Training loss: 0.858561635017395
Validation loss: 2.150901382168134

Epoch: 5| Step: 9
Training loss: 1.56718909740448
Validation loss: 2.134927749633789

Epoch: 5| Step: 10
Training loss: 1.7055257558822632
Validation loss: 2.153041293223699

Epoch: 5| Step: 11
Training loss: 0.654517412185669
Validation loss: 2.11345474421978

Epoch: 385| Step: 0
Training loss: 1.5919420719146729
Validation loss: 2.1354124198357263

Epoch: 5| Step: 1
Training loss: 1.605201005935669
Validation loss: 2.1271670361359916

Epoch: 5| Step: 2
Training loss: 1.5570839643478394
Validation loss: 2.125652641057968

Epoch: 5| Step: 3
Training loss: 1.3785574436187744
Validation loss: 2.096111367146174

Epoch: 5| Step: 4
Training loss: 1.3765665292739868
Validation loss: 2.1382932712634406

Epoch: 5| Step: 5
Training loss: 1.0366740226745605
Validation loss: 2.10507462422053

Epoch: 5| Step: 6
Training loss: 1.4813352823257446
Validation loss: 2.1548652152220407

Epoch: 5| Step: 7
Training loss: 1.0570380687713623
Validation loss: 2.1465344230333963

Epoch: 5| Step: 8
Training loss: 1.1638250350952148
Validation loss: 2.1648795902729034

Epoch: 5| Step: 9
Training loss: 1.5650198459625244
Validation loss: 2.157092203696569

Epoch: 5| Step: 10
Training loss: 1.8844964504241943
Validation loss: 2.1699509819348655

Epoch: 5| Step: 11
Training loss: 2.5657756328582764
Validation loss: 2.188347260157267

Epoch: 386| Step: 0
Training loss: 0.8011173009872437
Validation loss: 2.1848343511422477

Epoch: 5| Step: 1
Training loss: 1.080521821975708
Validation loss: 2.1697501639525094

Epoch: 5| Step: 2
Training loss: 1.278154969215393
Validation loss: 2.2099708219369254

Epoch: 5| Step: 3
Training loss: 1.404926061630249
Validation loss: 2.178860237201055

Epoch: 5| Step: 4
Training loss: 1.5477759838104248
Validation loss: 2.2083563208580017

Epoch: 5| Step: 5
Training loss: 1.0530080795288086
Validation loss: 2.173415074745814

Epoch: 5| Step: 6
Training loss: 1.964862585067749
Validation loss: 2.169168790181478

Epoch: 5| Step: 7
Training loss: 1.2061703205108643
Validation loss: 2.144623880585035

Epoch: 5| Step: 8
Training loss: 2.1421761512756348
Validation loss: 2.1791266600290933

Epoch: 5| Step: 9
Training loss: 1.605905294418335
Validation loss: 2.1529021859169006

Epoch: 5| Step: 10
Training loss: 1.5105892419815063
Validation loss: 2.148300657669703

Epoch: 5| Step: 11
Training loss: 0.8848845362663269
Validation loss: 2.1776664753754935

Epoch: 387| Step: 0
Training loss: 1.3258934020996094
Validation loss: 2.169902339577675

Epoch: 5| Step: 1
Training loss: 0.793702244758606
Validation loss: 2.1903217832247415

Epoch: 5| Step: 2
Training loss: 1.5223591327667236
Validation loss: 2.1858588457107544

Epoch: 5| Step: 3
Training loss: 1.3844516277313232
Validation loss: 2.2005173911650977

Epoch: 5| Step: 4
Training loss: 1.211276650428772
Validation loss: 2.1846039394537606

Epoch: 5| Step: 5
Training loss: 2.0289692878723145
Validation loss: 2.172773758570353

Epoch: 5| Step: 6
Training loss: 1.5377750396728516
Validation loss: 2.197926163673401

Epoch: 5| Step: 7
Training loss: 1.1917219161987305
Validation loss: 2.201793760061264

Epoch: 5| Step: 8
Training loss: 1.335054636001587
Validation loss: 2.2105311254660287

Epoch: 5| Step: 9
Training loss: 2.1106925010681152
Validation loss: 2.1942002177238464

Epoch: 5| Step: 10
Training loss: 1.1778779029846191
Validation loss: 2.199846734603246

Epoch: 5| Step: 11
Training loss: 2.635686159133911
Validation loss: 2.2220247785250344

Epoch: 388| Step: 0
Training loss: 1.4117332696914673
Validation loss: 2.2133145878712335

Epoch: 5| Step: 1
Training loss: 1.7753875255584717
Validation loss: 2.2078367322683334

Epoch: 5| Step: 2
Training loss: 1.5407971143722534
Validation loss: 2.168736626704534

Epoch: 5| Step: 3
Training loss: 1.0047684907913208
Validation loss: 2.192992647488912

Epoch: 5| Step: 4
Training loss: 1.4643208980560303
Validation loss: 2.1869996190071106

Epoch: 5| Step: 5
Training loss: 1.2846310138702393
Validation loss: 2.181245739261309

Epoch: 5| Step: 6
Training loss: 1.0725226402282715
Validation loss: 2.1910766661167145

Epoch: 5| Step: 7
Training loss: 1.5927636623382568
Validation loss: 2.2035331577062607

Epoch: 5| Step: 8
Training loss: 1.552847981452942
Validation loss: 2.151370257139206

Epoch: 5| Step: 9
Training loss: 0.8972266316413879
Validation loss: 2.134980708360672

Epoch: 5| Step: 10
Training loss: 1.7691329717636108
Validation loss: 2.167023370663325

Epoch: 5| Step: 11
Training loss: 0.29164326190948486
Validation loss: 2.1881337066491446

Epoch: 389| Step: 0
Training loss: 1.368494987487793
Validation loss: 2.1965829730033875

Epoch: 5| Step: 1
Training loss: 1.6091018915176392
Validation loss: 2.215790947278341

Epoch: 5| Step: 2
Training loss: 1.5430593490600586
Validation loss: 2.2122423400481543

Epoch: 5| Step: 3
Training loss: 1.475735068321228
Validation loss: 2.1923892498016357

Epoch: 5| Step: 4
Training loss: 1.5294253826141357
Validation loss: 2.1805305977662406

Epoch: 5| Step: 5
Training loss: 1.3784711360931396
Validation loss: 2.1542811691761017

Epoch: 5| Step: 6
Training loss: 1.6242055892944336
Validation loss: 2.1714792946974435

Epoch: 5| Step: 7
Training loss: 1.4227384328842163
Validation loss: 2.140355572104454

Epoch: 5| Step: 8
Training loss: 1.4182815551757812
Validation loss: 2.1055980126063027

Epoch: 5| Step: 9
Training loss: 1.627930998802185
Validation loss: 2.097472916046778

Epoch: 5| Step: 10
Training loss: 1.4245080947875977
Validation loss: 2.1075078348318734

Epoch: 5| Step: 11
Training loss: 1.005704402923584
Validation loss: 2.14470711350441

Epoch: 390| Step: 0
Training loss: 1.1751340627670288
Validation loss: 2.128706321120262

Epoch: 5| Step: 1
Training loss: 1.0032306909561157
Validation loss: 2.1377993673086166

Epoch: 5| Step: 2
Training loss: 1.600227952003479
Validation loss: 2.16279869278272

Epoch: 5| Step: 3
Training loss: 1.5022690296173096
Validation loss: 2.1718243261178336

Epoch: 5| Step: 4
Training loss: 1.9010165929794312
Validation loss: 2.149438723921776

Epoch: 5| Step: 5
Training loss: 1.4757096767425537
Validation loss: 2.1394181102514267

Epoch: 5| Step: 6
Training loss: 1.703997254371643
Validation loss: 2.1247274776299796

Epoch: 5| Step: 7
Training loss: 1.2243167161941528
Validation loss: 2.182901148994764

Epoch: 5| Step: 8
Training loss: 1.3910413980484009
Validation loss: 2.1614676813284555

Epoch: 5| Step: 9
Training loss: 1.3218717575073242
Validation loss: 2.144747177759806

Epoch: 5| Step: 10
Training loss: 2.0038115978240967
Validation loss: 2.151422450939814

Epoch: 5| Step: 11
Training loss: 1.1320658922195435
Validation loss: 2.1560640235741935

Epoch: 391| Step: 0
Training loss: 1.0757524967193604
Validation loss: 2.127962132294973

Epoch: 5| Step: 1
Training loss: 1.4335825443267822
Validation loss: 2.1877462615569434

Epoch: 5| Step: 2
Training loss: 1.53347647190094
Validation loss: 2.16153754790624

Epoch: 5| Step: 3
Training loss: 1.5062239170074463
Validation loss: 2.163260837395986

Epoch: 5| Step: 4
Training loss: 1.0971840620040894
Validation loss: 2.172040656208992

Epoch: 5| Step: 5
Training loss: 1.4941136837005615
Validation loss: 2.1645026157299676

Epoch: 5| Step: 6
Training loss: 2.0312843322753906
Validation loss: 2.1593590329090753

Epoch: 5| Step: 7
Training loss: 2.0271573066711426
Validation loss: 2.1701360940933228

Epoch: 5| Step: 8
Training loss: 1.5211479663848877
Validation loss: 2.148248185714086

Epoch: 5| Step: 9
Training loss: 1.068273901939392
Validation loss: 2.138936455051104

Epoch: 5| Step: 10
Training loss: 1.013375997543335
Validation loss: 2.1614657640457153

Epoch: 5| Step: 11
Training loss: 0.8933364152908325
Validation loss: 2.1311600605646768

Epoch: 392| Step: 0
Training loss: 1.7548106908798218
Validation loss: 2.1792050898075104

Epoch: 5| Step: 1
Training loss: 1.6781715154647827
Validation loss: 2.123533363143603

Epoch: 5| Step: 2
Training loss: 1.7375142574310303
Validation loss: 2.087635646263758

Epoch: 5| Step: 3
Training loss: 1.6989587545394897
Validation loss: 2.1207032004992166

Epoch: 5| Step: 4
Training loss: 1.1330668926239014
Validation loss: 2.1103483140468597

Epoch: 5| Step: 5
Training loss: 0.7930136919021606
Validation loss: 2.1523074756066003

Epoch: 5| Step: 6
Training loss: 1.343636155128479
Validation loss: 2.1196276446183524

Epoch: 5| Step: 7
Training loss: 1.2128931283950806
Validation loss: 2.1506753961245217

Epoch: 5| Step: 8
Training loss: 1.6930614709854126
Validation loss: 2.1352442453304925

Epoch: 5| Step: 9
Training loss: 1.3668628931045532
Validation loss: 2.1492153952519097

Epoch: 5| Step: 10
Training loss: 1.2178512811660767
Validation loss: 2.1551348070303598

Epoch: 5| Step: 11
Training loss: 0.4045224189758301
Validation loss: 2.186210493246714

Epoch: 393| Step: 0
Training loss: 1.1729145050048828
Validation loss: 2.2228709757328033

Epoch: 5| Step: 1
Training loss: 1.94672429561615
Validation loss: 2.1778379728396735

Epoch: 5| Step: 2
Training loss: 1.7794735431671143
Validation loss: 2.169342741370201

Epoch: 5| Step: 3
Training loss: 1.3562556505203247
Validation loss: 2.177816798289617

Epoch: 5| Step: 4
Training loss: 1.7419649362564087
Validation loss: 2.1773981899023056

Epoch: 5| Step: 5
Training loss: 1.14510178565979
Validation loss: 2.1145763943592706

Epoch: 5| Step: 6
Training loss: 0.9143838882446289
Validation loss: 2.0974600315093994

Epoch: 5| Step: 7
Training loss: 1.681758165359497
Validation loss: 2.031171848376592

Epoch: 5| Step: 8
Training loss: 1.5858871936798096
Validation loss: 2.0184163401524224

Epoch: 5| Step: 9
Training loss: 1.5297915935516357
Validation loss: 2.0535814811786017

Epoch: 5| Step: 10
Training loss: 1.2884100675582886
Validation loss: 2.042930170893669

Epoch: 5| Step: 11
Training loss: 0.377133309841156
Validation loss: 2.0452154030402503

Epoch: 394| Step: 0
Training loss: 1.7472641468048096
Validation loss: 2.01052318016688

Epoch: 5| Step: 1
Training loss: 1.1408686637878418
Validation loss: 2.01848595837752

Epoch: 5| Step: 2
Training loss: 1.4955517053604126
Validation loss: 2.0716604193051658

Epoch: 5| Step: 3
Training loss: 1.7759931087493896
Validation loss: 2.11455603937308

Epoch: 5| Step: 4
Training loss: 1.9349422454833984
Validation loss: 2.133525292078654

Epoch: 5| Step: 5
Training loss: 0.9618832468986511
Validation loss: 2.1278881231943765

Epoch: 5| Step: 6
Training loss: 0.7451649904251099
Validation loss: 2.153634841243426

Epoch: 5| Step: 7
Training loss: 1.4420835971832275
Validation loss: 2.161826108892759

Epoch: 5| Step: 8
Training loss: 1.5651880502700806
Validation loss: 2.1427612702051797

Epoch: 5| Step: 9
Training loss: 1.2231266498565674
Validation loss: 2.1427388737599053

Epoch: 5| Step: 10
Training loss: 1.4757429361343384
Validation loss: 2.15340448419253

Epoch: 5| Step: 11
Training loss: 0.052497148513793945
Validation loss: 2.1407606502374015

Epoch: 395| Step: 0
Training loss: 2.0862464904785156
Validation loss: 2.1490144630273185

Epoch: 5| Step: 1
Training loss: 1.181380033493042
Validation loss: 2.159986029068629

Epoch: 5| Step: 2
Training loss: 1.4676834344863892
Validation loss: 2.183140347401301

Epoch: 5| Step: 3
Training loss: 1.1764684915542603
Validation loss: 2.1746422350406647

Epoch: 5| Step: 4
Training loss: 0.7180832624435425
Validation loss: 2.2184291382630668

Epoch: 5| Step: 5
Training loss: 1.8765472173690796
Validation loss: 2.1862242817878723

Epoch: 5| Step: 6
Training loss: 0.9290041923522949
Validation loss: 2.194279730319977

Epoch: 5| Step: 7
Training loss: 0.9849567413330078
Validation loss: 2.2402983804543815

Epoch: 5| Step: 8
Training loss: 1.8059074878692627
Validation loss: 2.2173523902893066

Epoch: 5| Step: 9
Training loss: 1.3953602313995361
Validation loss: 2.1994355767965317

Epoch: 5| Step: 10
Training loss: 0.6620146036148071
Validation loss: 2.187739133834839

Epoch: 5| Step: 11
Training loss: 3.5141234397888184
Validation loss: 2.1766071071227393

Epoch: 396| Step: 0
Training loss: 1.0412914752960205
Validation loss: 2.1751314401626587

Epoch: 5| Step: 1
Training loss: 1.1644647121429443
Validation loss: 2.215511163075765

Epoch: 5| Step: 2
Training loss: 1.6653213500976562
Validation loss: 2.1779431204001107

Epoch: 5| Step: 3
Training loss: 1.357257604598999
Validation loss: 2.230429927508036

Epoch: 5| Step: 4
Training loss: 1.4146068096160889
Validation loss: 2.187338709831238

Epoch: 5| Step: 5
Training loss: 1.6572372913360596
Validation loss: 2.2199622044960656

Epoch: 5| Step: 6
Training loss: 1.0650031566619873
Validation loss: 2.2177770137786865

Epoch: 5| Step: 7
Training loss: 1.0995700359344482
Validation loss: 2.1621184051036835

Epoch: 5| Step: 8
Training loss: 1.508752703666687
Validation loss: 2.1743397365013757

Epoch: 5| Step: 9
Training loss: 1.7619997262954712
Validation loss: 2.1877771466970444

Epoch: 5| Step: 10
Training loss: 1.1251243352890015
Validation loss: 2.205512990554174

Epoch: 5| Step: 11
Training loss: 0.46388745307922363
Validation loss: 2.24189954996109

Epoch: 397| Step: 0
Training loss: 1.2292258739471436
Validation loss: 2.2345467507839203

Epoch: 5| Step: 1
Training loss: 1.3608468770980835
Validation loss: 2.198849012454351

Epoch: 5| Step: 2
Training loss: 0.9872010946273804
Validation loss: 2.223041663567225

Epoch: 5| Step: 3
Training loss: 1.3151131868362427
Validation loss: 2.229337831338247

Epoch: 5| Step: 4
Training loss: 1.3721647262573242
Validation loss: 2.2029773940642676

Epoch: 5| Step: 5
Training loss: 1.0511815547943115
Validation loss: 2.187363555034002

Epoch: 5| Step: 6
Training loss: 1.248740553855896
Validation loss: 2.2133572697639465

Epoch: 5| Step: 7
Training loss: 1.7186952829360962
Validation loss: 2.2236113945643106

Epoch: 5| Step: 8
Training loss: 1.558104157447815
Validation loss: 2.2371675074100494

Epoch: 5| Step: 9
Training loss: 1.4762194156646729
Validation loss: 2.1805785099665322

Epoch: 5| Step: 10
Training loss: 1.0712945461273193
Validation loss: 2.1712663620710373

Epoch: 5| Step: 11
Training loss: 0.6116492748260498
Validation loss: 2.1893475701411567

Epoch: 398| Step: 0
Training loss: 0.8722966909408569
Validation loss: 2.168650910258293

Epoch: 5| Step: 1
Training loss: 1.1638902425765991
Validation loss: 2.2108204066753387

Epoch: 5| Step: 2
Training loss: 1.6660058498382568
Validation loss: 2.19523786008358

Epoch: 5| Step: 3
Training loss: 0.9675087928771973
Validation loss: 2.216140245397886

Epoch: 5| Step: 4
Training loss: 1.0024304389953613
Validation loss: 2.1890398412942886

Epoch: 5| Step: 5
Training loss: 1.1747006177902222
Validation loss: 2.188161393006643

Epoch: 5| Step: 6
Training loss: 0.899750828742981
Validation loss: 2.1926393260558448

Epoch: 5| Step: 7
Training loss: 1.8458255529403687
Validation loss: 2.184277211626371

Epoch: 5| Step: 8
Training loss: 1.254563331604004
Validation loss: 2.218844542900721

Epoch: 5| Step: 9
Training loss: 1.4007184505462646
Validation loss: 2.2116166402896247

Epoch: 5| Step: 10
Training loss: 2.250354290008545
Validation loss: 2.19626647233963

Epoch: 5| Step: 11
Training loss: 1.2300529479980469
Validation loss: 2.225668932000796

Epoch: 399| Step: 0
Training loss: 1.4951355457305908
Validation loss: 2.1824468473593392

Epoch: 5| Step: 1
Training loss: 0.8207902908325195
Validation loss: 2.182012289762497

Epoch: 5| Step: 2
Training loss: 1.5408891439437866
Validation loss: 2.264907658100128

Epoch: 5| Step: 3
Training loss: 1.462066888809204
Validation loss: 2.264175057411194

Epoch: 5| Step: 4
Training loss: 2.0562148094177246
Validation loss: 2.2313342789808908

Epoch: 5| Step: 5
Training loss: 1.2002980709075928
Validation loss: 2.253783588608106

Epoch: 5| Step: 6
Training loss: 0.839438259601593
Validation loss: 2.236846665541331

Epoch: 5| Step: 7
Training loss: 1.945966124534607
Validation loss: 2.249761939048767

Epoch: 5| Step: 8
Training loss: 2.397023916244507
Validation loss: 2.235139861702919

Epoch: 5| Step: 9
Training loss: 1.586493730545044
Validation loss: 2.228115662932396

Epoch: 5| Step: 10
Training loss: 1.5886355638504028
Validation loss: 2.243174448609352

Epoch: 5| Step: 11
Training loss: 0.6994310617446899
Validation loss: 2.2170551816622415

Epoch: 400| Step: 0
Training loss: 1.736935019493103
Validation loss: 2.1839756866296134

Epoch: 5| Step: 1
Training loss: 1.3448859453201294
Validation loss: 2.222570369640986

Epoch: 5| Step: 2
Training loss: 1.4417482614517212
Validation loss: 2.176785488923391

Epoch: 5| Step: 3
Training loss: 1.3174508810043335
Validation loss: 2.216643045345942

Epoch: 5| Step: 4
Training loss: 1.3346868753433228
Validation loss: 2.213189497590065

Epoch: 5| Step: 5
Training loss: 1.2112667560577393
Validation loss: 2.1952694108088813

Epoch: 5| Step: 6
Training loss: 0.9751432538032532
Validation loss: 2.202297310034434

Epoch: 5| Step: 7
Training loss: 1.1554429531097412
Validation loss: 2.170712853471438

Epoch: 5| Step: 8
Training loss: 1.0492405891418457
Validation loss: 2.150865321358045

Epoch: 5| Step: 9
Training loss: 1.1160304546356201
Validation loss: 2.1927466889222464

Epoch: 5| Step: 10
Training loss: 1.912102460861206
Validation loss: 2.1899389078219733

Epoch: 5| Step: 11
Training loss: 0.8541563749313354
Validation loss: 2.1713990767796836

Epoch: 401| Step: 0
Training loss: 1.3192987442016602
Validation loss: 2.1677978138128915

Epoch: 5| Step: 1
Training loss: 1.2603254318237305
Validation loss: 2.136628031730652

Epoch: 5| Step: 2
Training loss: 1.525536298751831
Validation loss: 2.1831683963537216

Epoch: 5| Step: 3
Training loss: 1.0907701253890991
Validation loss: 2.149159679810206

Epoch: 5| Step: 4
Training loss: 1.2368217706680298
Validation loss: 2.116156612833341

Epoch: 5| Step: 5
Training loss: 1.3829419612884521
Validation loss: 2.1622584660847983

Epoch: 5| Step: 6
Training loss: 1.1834156513214111
Validation loss: 2.1480835477511087

Epoch: 5| Step: 7
Training loss: 1.8049606084823608
Validation loss: 2.185018241405487

Epoch: 5| Step: 8
Training loss: 1.0656356811523438
Validation loss: 2.1680361231168113

Epoch: 5| Step: 9
Training loss: 1.3070415258407593
Validation loss: 2.1930456161499023

Epoch: 5| Step: 10
Training loss: 1.4360971450805664
Validation loss: 2.204534942905108

Epoch: 5| Step: 11
Training loss: 0.5644906759262085
Validation loss: 2.1615894635518393

Epoch: 402| Step: 0
Training loss: 1.5526155233383179
Validation loss: 2.1804754783709845

Epoch: 5| Step: 1
Training loss: 0.8363114595413208
Validation loss: 2.14384255806605

Epoch: 5| Step: 2
Training loss: 1.1069755554199219
Validation loss: 2.135628496607145

Epoch: 5| Step: 3
Training loss: 1.421380639076233
Validation loss: 2.1077014754215875

Epoch: 5| Step: 4
Training loss: 1.1486088037490845
Validation loss: 2.1255928774674735

Epoch: 5| Step: 5
Training loss: 1.120174765586853
Validation loss: 2.1635696490605674

Epoch: 5| Step: 6
Training loss: 1.0206539630889893
Validation loss: 2.12893815835317

Epoch: 5| Step: 7
Training loss: 1.2460439205169678
Validation loss: 2.147522489229838

Epoch: 5| Step: 8
Training loss: 1.4250410795211792
Validation loss: 2.13305072983106

Epoch: 5| Step: 9
Training loss: 1.5352989435195923
Validation loss: 2.1114611824353537

Epoch: 5| Step: 10
Training loss: 1.6632769107818604
Validation loss: 2.1462944944699607

Epoch: 5| Step: 11
Training loss: 1.2786240577697754
Validation loss: 2.121604844927788

Epoch: 403| Step: 0
Training loss: 1.2491710186004639
Validation loss: 2.1036754101514816

Epoch: 5| Step: 1
Training loss: 1.2622690200805664
Validation loss: 2.086360424757004

Epoch: 5| Step: 2
Training loss: 1.0959866046905518
Validation loss: 2.1138166089852652

Epoch: 5| Step: 3
Training loss: 2.055011749267578
Validation loss: 2.1333475708961487

Epoch: 5| Step: 4
Training loss: 1.6468967199325562
Validation loss: 2.1250039587418237

Epoch: 5| Step: 5
Training loss: 1.001571774482727
Validation loss: 2.143808290362358

Epoch: 5| Step: 6
Training loss: 1.1946645975112915
Validation loss: 2.1342699428399405

Epoch: 5| Step: 7
Training loss: 1.271242618560791
Validation loss: 2.139101246992747

Epoch: 5| Step: 8
Training loss: 1.2662500143051147
Validation loss: 2.162916382153829

Epoch: 5| Step: 9
Training loss: 1.2255542278289795
Validation loss: 2.1805486977100372

Epoch: 5| Step: 10
Training loss: 1.381592035293579
Validation loss: 2.1687443405389786

Epoch: 5| Step: 11
Training loss: 1.0379607677459717
Validation loss: 2.1658179511626563

Epoch: 404| Step: 0
Training loss: 0.866795539855957
Validation loss: 2.1894677927096686

Epoch: 5| Step: 1
Training loss: 1.2611204385757446
Validation loss: 2.1517764727274575

Epoch: 5| Step: 2
Training loss: 1.648565649986267
Validation loss: 2.16641532878081

Epoch: 5| Step: 3
Training loss: 1.6322253942489624
Validation loss: 2.144450585047404

Epoch: 5| Step: 4
Training loss: 0.9583532214164734
Validation loss: 2.17124272386233

Epoch: 5| Step: 5
Training loss: 1.2449989318847656
Validation loss: 2.1756281157334647

Epoch: 5| Step: 6
Training loss: 1.3756214380264282
Validation loss: 2.168887178103129

Epoch: 5| Step: 7
Training loss: 0.861962616443634
Validation loss: 2.1844771206378937

Epoch: 5| Step: 8
Training loss: 1.7944469451904297
Validation loss: 2.178389569123586

Epoch: 5| Step: 9
Training loss: 1.2297265529632568
Validation loss: 2.1706078896919885

Epoch: 5| Step: 10
Training loss: 1.3286832571029663
Validation loss: 2.1611201564470925

Epoch: 5| Step: 11
Training loss: 0.8077991008758545
Validation loss: 2.1251337428887687

Epoch: 405| Step: 0
Training loss: 1.8990809917449951
Validation loss: 2.142850344379743

Epoch: 5| Step: 1
Training loss: 1.0061203241348267
Validation loss: 2.169647991657257

Epoch: 5| Step: 2
Training loss: 1.2151132822036743
Validation loss: 2.154914061228434

Epoch: 5| Step: 3
Training loss: 1.5033502578735352
Validation loss: 2.151678745945295

Epoch: 5| Step: 4
Training loss: 1.3423116207122803
Validation loss: 2.1469383537769318

Epoch: 5| Step: 5
Training loss: 1.5787804126739502
Validation loss: 2.1322413235902786

Epoch: 5| Step: 6
Training loss: 1.087795615196228
Validation loss: 2.139367938041687

Epoch: 5| Step: 7
Training loss: 1.680359125137329
Validation loss: 2.156502217054367

Epoch: 5| Step: 8
Training loss: 0.8301717638969421
Validation loss: 2.2006299197673798

Epoch: 5| Step: 9
Training loss: 0.8929129838943481
Validation loss: 2.1933829387029014

Epoch: 5| Step: 10
Training loss: 0.9598725438117981
Validation loss: 2.1815789292256036

Epoch: 5| Step: 11
Training loss: 0.8041622638702393
Validation loss: 2.2191147903601327

Epoch: 406| Step: 0
Training loss: 1.2706124782562256
Validation loss: 2.216035157442093

Epoch: 5| Step: 1
Training loss: 1.8106706142425537
Validation loss: 2.2084760268529258

Epoch: 5| Step: 2
Training loss: 1.6545997858047485
Validation loss: 2.247390627861023

Epoch: 5| Step: 3
Training loss: 1.6669244766235352
Validation loss: 2.2364349514245987

Epoch: 5| Step: 4
Training loss: 1.299375295639038
Validation loss: 2.2497064222892127

Epoch: 5| Step: 5
Training loss: 1.6284160614013672
Validation loss: 2.225347896416982

Epoch: 5| Step: 6
Training loss: 1.5316028594970703
Validation loss: 2.2006262143452964

Epoch: 5| Step: 7
Training loss: 1.3122092485427856
Validation loss: 2.211366961399714

Epoch: 5| Step: 8
Training loss: 0.8054655194282532
Validation loss: 2.1732711295286813

Epoch: 5| Step: 9
Training loss: 1.2780150175094604
Validation loss: 2.181785757342974

Epoch: 5| Step: 10
Training loss: 0.9614874720573425
Validation loss: 2.1744794646898904

Epoch: 5| Step: 11
Training loss: 1.426291584968567
Validation loss: 2.167962392171224

Epoch: 407| Step: 0
Training loss: 1.0236423015594482
Validation loss: 2.171194518605868

Epoch: 5| Step: 1
Training loss: 1.311755895614624
Validation loss: 2.152782380580902

Epoch: 5| Step: 2
Training loss: 1.0300581455230713
Validation loss: 2.130899647871653

Epoch: 5| Step: 3
Training loss: 1.1902244091033936
Validation loss: 2.126577759782473

Epoch: 5| Step: 4
Training loss: 1.7059762477874756
Validation loss: 2.171851764122645

Epoch: 5| Step: 5
Training loss: 0.9391121864318848
Validation loss: 2.1559754262367883

Epoch: 5| Step: 6
Training loss: 1.7704805135726929
Validation loss: 2.140647917985916

Epoch: 5| Step: 7
Training loss: 1.268689513206482
Validation loss: 2.109037900964419

Epoch: 5| Step: 8
Training loss: 1.354146122932434
Validation loss: 2.133904899160067

Epoch: 5| Step: 9
Training loss: 1.2423386573791504
Validation loss: 2.1389905512332916

Epoch: 5| Step: 10
Training loss: 1.2289201021194458
Validation loss: 2.176746110121409

Epoch: 5| Step: 11
Training loss: 1.1469635963439941
Validation loss: 2.152714282274246

Epoch: 408| Step: 0
Training loss: 1.1771272420883179
Validation loss: 2.1575852036476135

Epoch: 5| Step: 1
Training loss: 0.8826826810836792
Validation loss: 2.1297274281581244

Epoch: 5| Step: 2
Training loss: 1.2943909168243408
Validation loss: 2.147236148516337

Epoch: 5| Step: 3
Training loss: 1.2464520931243896
Validation loss: 2.161702588200569

Epoch: 5| Step: 4
Training loss: 1.2610496282577515
Validation loss: 2.186553011337916

Epoch: 5| Step: 5
Training loss: 1.342763066291809
Validation loss: 2.1184756656487784

Epoch: 5| Step: 6
Training loss: 1.243137001991272
Validation loss: 2.125797748565674

Epoch: 5| Step: 7
Training loss: 1.771702766418457
Validation loss: 2.1846324851115546

Epoch: 5| Step: 8
Training loss: 0.5350787043571472
Validation loss: 2.1306971261898675

Epoch: 5| Step: 9
Training loss: 1.1766265630722046
Validation loss: 2.1690861533085504

Epoch: 5| Step: 10
Training loss: 1.7490692138671875
Validation loss: 2.190107042590777

Epoch: 5| Step: 11
Training loss: 0.49785226583480835
Validation loss: 2.1522333721319833

Epoch: 409| Step: 0
Training loss: 1.5645034313201904
Validation loss: 2.1551715979973474

Epoch: 5| Step: 1
Training loss: 0.8753581047058105
Validation loss: 2.1480242758989334

Epoch: 5| Step: 2
Training loss: 0.8944050073623657
Validation loss: 2.1441619048515954

Epoch: 5| Step: 3
Training loss: 1.233762502670288
Validation loss: 2.2034727384646735

Epoch: 5| Step: 4
Training loss: 1.109148383140564
Validation loss: 2.1781027416388192

Epoch: 5| Step: 5
Training loss: 1.227102518081665
Validation loss: 2.1601349910100303

Epoch: 5| Step: 6
Training loss: 1.7232487201690674
Validation loss: 2.180426220099131

Epoch: 5| Step: 7
Training loss: 1.2246863842010498
Validation loss: 2.1704024225473404

Epoch: 5| Step: 8
Training loss: 1.3115628957748413
Validation loss: 2.2056078811486564

Epoch: 5| Step: 9
Training loss: 1.475042700767517
Validation loss: 2.1547941466172538

Epoch: 5| Step: 10
Training loss: 1.645331621170044
Validation loss: 2.206125557422638

Epoch: 5| Step: 11
Training loss: 0.6318504810333252
Validation loss: 2.205567146341006

Epoch: 410| Step: 0
Training loss: 1.3880375623703003
Validation loss: 2.221093932787577

Epoch: 5| Step: 1
Training loss: 0.9470396041870117
Validation loss: 2.188285936911901

Epoch: 5| Step: 2
Training loss: 2.1490659713745117
Validation loss: 2.1547974397738776

Epoch: 5| Step: 3
Training loss: 0.9955471754074097
Validation loss: 2.1815034399429956

Epoch: 5| Step: 4
Training loss: 1.1938705444335938
Validation loss: 2.170200308163961

Epoch: 5| Step: 5
Training loss: 1.6014888286590576
Validation loss: 2.1579977770646415

Epoch: 5| Step: 6
Training loss: 1.6296144723892212
Validation loss: 2.138411139448484

Epoch: 5| Step: 7
Training loss: 1.3446242809295654
Validation loss: 2.143439913789431

Epoch: 5| Step: 8
Training loss: 1.0972412824630737
Validation loss: 2.1395773142576218

Epoch: 5| Step: 9
Training loss: 0.9825060963630676
Validation loss: 2.1095918715000153

Epoch: 5| Step: 10
Training loss: 1.1536157131195068
Validation loss: 2.124715492129326

Epoch: 5| Step: 11
Training loss: 1.5612221956253052
Validation loss: 2.128010352452596

Epoch: 411| Step: 0
Training loss: 1.4703466892242432
Validation loss: 2.1343995879093804

Epoch: 5| Step: 1
Training loss: 0.7833729982376099
Validation loss: 2.1204199890295663

Epoch: 5| Step: 2
Training loss: 1.2240076065063477
Validation loss: 2.1401382982730865

Epoch: 5| Step: 3
Training loss: 1.3397190570831299
Validation loss: 2.1317600111166635

Epoch: 5| Step: 4
Training loss: 1.8431199789047241
Validation loss: 2.1117312759160995

Epoch: 5| Step: 5
Training loss: 0.9642040133476257
Validation loss: 2.099110280474027

Epoch: 5| Step: 6
Training loss: 1.912907361984253
Validation loss: 2.096639573574066

Epoch: 5| Step: 7
Training loss: 1.3262041807174683
Validation loss: 2.064954693118731

Epoch: 5| Step: 8
Training loss: 1.6881649494171143
Validation loss: 2.0866774767637253

Epoch: 5| Step: 9
Training loss: 1.4258434772491455
Validation loss: 2.0773521959781647

Epoch: 5| Step: 10
Training loss: 0.9612659215927124
Validation loss: 2.1203274528185525

Epoch: 5| Step: 11
Training loss: 0.756766676902771
Validation loss: 2.1111834396918616

Epoch: 412| Step: 0
Training loss: 1.258410930633545
Validation loss: 2.061412423849106

Epoch: 5| Step: 1
Training loss: 1.7932831048965454
Validation loss: 2.108481561144193

Epoch: 5| Step: 2
Training loss: 1.3914413452148438
Validation loss: 2.103709121545156

Epoch: 5| Step: 3
Training loss: 1.0633728504180908
Validation loss: 2.1549284855524697

Epoch: 5| Step: 4
Training loss: 1.5290015935897827
Validation loss: 2.1572859783967337

Epoch: 5| Step: 5
Training loss: 1.198538064956665
Validation loss: 2.152996684114138

Epoch: 5| Step: 6
Training loss: 1.133439064025879
Validation loss: 2.1771983156601586

Epoch: 5| Step: 7
Training loss: 1.3270829916000366
Validation loss: 2.1256685753663382

Epoch: 5| Step: 8
Training loss: 1.2464735507965088
Validation loss: 2.18149134516716

Epoch: 5| Step: 9
Training loss: 1.2896754741668701
Validation loss: 2.1874743600686393

Epoch: 5| Step: 10
Training loss: 1.1476322412490845
Validation loss: 2.204892744620641

Epoch: 5| Step: 11
Training loss: 0.30717718601226807
Validation loss: 2.142376477519671

Epoch: 413| Step: 0
Training loss: 1.2175284624099731
Validation loss: 2.1532430797815323

Epoch: 5| Step: 1
Training loss: 1.2255454063415527
Validation loss: 2.174228568871816

Epoch: 5| Step: 2
Training loss: 1.140200138092041
Validation loss: 2.1882691284020743

Epoch: 5| Step: 3
Training loss: 1.056990623474121
Validation loss: 2.127431333065033

Epoch: 5| Step: 4
Training loss: 1.601336121559143
Validation loss: 2.1712397933006287

Epoch: 5| Step: 5
Training loss: 1.705073595046997
Validation loss: 2.2069628487030664

Epoch: 5| Step: 6
Training loss: 0.7228139638900757
Validation loss: 2.2047504484653473

Epoch: 5| Step: 7
Training loss: 0.9794505834579468
Validation loss: 2.2094780802726746

Epoch: 5| Step: 8
Training loss: 1.323366403579712
Validation loss: 2.190854380528132

Epoch: 5| Step: 9
Training loss: 1.7775501012802124
Validation loss: 2.1974206616481147

Epoch: 5| Step: 10
Training loss: 1.1933101415634155
Validation loss: 2.2241136133670807

Epoch: 5| Step: 11
Training loss: 1.2261219024658203
Validation loss: 2.225132634242376

Epoch: 414| Step: 0
Training loss: 1.309298038482666
Validation loss: 2.2485198080539703

Epoch: 5| Step: 1
Training loss: 1.1629464626312256
Validation loss: 2.266514162222544

Epoch: 5| Step: 2
Training loss: 1.5519087314605713
Validation loss: 2.222002307573954

Epoch: 5| Step: 3
Training loss: 1.0995584726333618
Validation loss: 2.198916311065356

Epoch: 5| Step: 4
Training loss: 1.6158335208892822
Validation loss: 2.210378885269165

Epoch: 5| Step: 5
Training loss: 1.2484419345855713
Validation loss: 2.222743645310402

Epoch: 5| Step: 6
Training loss: 1.3147674798965454
Validation loss: 2.236607496937116

Epoch: 5| Step: 7
Training loss: 0.9394139051437378
Validation loss: 2.2100590566794076

Epoch: 5| Step: 8
Training loss: 0.9832502603530884
Validation loss: 2.2110424439112344

Epoch: 5| Step: 9
Training loss: 1.1756794452667236
Validation loss: 2.2430831293265023

Epoch: 5| Step: 10
Training loss: 1.0395057201385498
Validation loss: 2.174759248892466

Epoch: 5| Step: 11
Training loss: 2.0737967491149902
Validation loss: 2.172732502222061

Epoch: 415| Step: 0
Training loss: 0.9739764332771301
Validation loss: 2.1740413904190063

Epoch: 5| Step: 1
Training loss: 0.8948634266853333
Validation loss: 2.2013053794701896

Epoch: 5| Step: 2
Training loss: 1.152005910873413
Validation loss: 2.1862798432509103

Epoch: 5| Step: 3
Training loss: 1.3253533840179443
Validation loss: 2.153564448157946

Epoch: 5| Step: 4
Training loss: 1.113235592842102
Validation loss: 2.15536892414093

Epoch: 5| Step: 5
Training loss: 1.2417324781417847
Validation loss: 2.1254750192165375

Epoch: 5| Step: 6
Training loss: 1.2835464477539062
Validation loss: 2.1469664027293525

Epoch: 5| Step: 7
Training loss: 0.7488731145858765
Validation loss: 2.145283410946528

Epoch: 5| Step: 8
Training loss: 1.941817045211792
Validation loss: 2.141522392630577

Epoch: 5| Step: 9
Training loss: 1.325052261352539
Validation loss: 2.145387351512909

Epoch: 5| Step: 10
Training loss: 1.761487603187561
Validation loss: 2.1345967203378677

Epoch: 5| Step: 11
Training loss: 0.7194846868515015
Validation loss: 2.155022362867991

Epoch: 416| Step: 0
Training loss: 1.137142539024353
Validation loss: 2.1667385598023734

Epoch: 5| Step: 1
Training loss: 1.1944831609725952
Validation loss: 2.1913528591394424

Epoch: 5| Step: 2
Training loss: 1.3171697854995728
Validation loss: 2.1711739897727966

Epoch: 5| Step: 3
Training loss: 1.3700871467590332
Validation loss: 2.1430731614430747

Epoch: 5| Step: 4
Training loss: 1.4402893781661987
Validation loss: 2.181540677944819

Epoch: 5| Step: 5
Training loss: 1.1833187341690063
Validation loss: 2.188959355155627

Epoch: 5| Step: 6
Training loss: 1.0287840366363525
Validation loss: 2.1626636733611426

Epoch: 5| Step: 7
Training loss: 0.8564910888671875
Validation loss: 2.1568432996670404

Epoch: 5| Step: 8
Training loss: 1.4049925804138184
Validation loss: 2.1437200804551444

Epoch: 5| Step: 9
Training loss: 1.6966946125030518
Validation loss: 2.144733508427938

Epoch: 5| Step: 10
Training loss: 0.8434730768203735
Validation loss: 2.116065646211306

Epoch: 5| Step: 11
Training loss: 1.465259313583374
Validation loss: 2.103016714255015

Epoch: 417| Step: 0
Training loss: 1.2125942707061768
Validation loss: 2.1520684361457825

Epoch: 5| Step: 1
Training loss: 1.05476975440979
Validation loss: 2.132460797826449

Epoch: 5| Step: 2
Training loss: 1.265528917312622
Validation loss: 2.1344328820705414

Epoch: 5| Step: 3
Training loss: 0.6807527542114258
Validation loss: 2.161506414413452

Epoch: 5| Step: 4
Training loss: 1.4188435077667236
Validation loss: 2.162786230444908

Epoch: 5| Step: 5
Training loss: 1.1177637577056885
Validation loss: 2.139366075396538

Epoch: 5| Step: 6
Training loss: 0.6809078454971313
Validation loss: 2.1551106919844947

Epoch: 5| Step: 7
Training loss: 1.0624752044677734
Validation loss: 2.1487194101015725

Epoch: 5| Step: 8
Training loss: 2.0595552921295166
Validation loss: 2.1392056892315545

Epoch: 5| Step: 9
Training loss: 1.2254009246826172
Validation loss: 2.1274540623029075

Epoch: 5| Step: 10
Training loss: 1.3994381427764893
Validation loss: 2.1659870793422065

Epoch: 5| Step: 11
Training loss: 0.9241021275520325
Validation loss: 2.1531986941893897

Epoch: 418| Step: 0
Training loss: 1.6715624332427979
Validation loss: 2.147177591919899

Epoch: 5| Step: 1
Training loss: 0.7474387288093567
Validation loss: 2.168679714202881

Epoch: 5| Step: 2
Training loss: 1.2840522527694702
Validation loss: 2.1682648956775665

Epoch: 5| Step: 3
Training loss: 1.416013479232788
Validation loss: 2.163093144694964

Epoch: 5| Step: 4
Training loss: 1.3397189378738403
Validation loss: 2.1615291784207025

Epoch: 5| Step: 5
Training loss: 1.1733119487762451
Validation loss: 2.1644175897041955

Epoch: 5| Step: 6
Training loss: 1.122396469116211
Validation loss: 2.190427298347155

Epoch: 5| Step: 7
Training loss: 1.3791730403900146
Validation loss: 2.1723498006661734

Epoch: 5| Step: 8
Training loss: 1.6506812572479248
Validation loss: 2.197574923435847

Epoch: 5| Step: 9
Training loss: 1.560927152633667
Validation loss: 2.1948214073975882

Epoch: 5| Step: 10
Training loss: 1.4498982429504395
Validation loss: 2.209576040506363

Epoch: 5| Step: 11
Training loss: 0.3929203152656555
Validation loss: 2.255453273653984

Epoch: 419| Step: 0
Training loss: 1.4535268545150757
Validation loss: 2.212675536672274

Epoch: 5| Step: 1
Training loss: 0.810162365436554
Validation loss: 2.1705132027467093

Epoch: 5| Step: 2
Training loss: 0.9504085779190063
Validation loss: 2.173633644978205

Epoch: 5| Step: 3
Training loss: 1.4424974918365479
Validation loss: 2.212436710794767

Epoch: 5| Step: 4
Training loss: 1.3721539974212646
Validation loss: 2.186299870411555

Epoch: 5| Step: 5
Training loss: 1.2294063568115234
Validation loss: 2.174894710381826

Epoch: 5| Step: 6
Training loss: 1.992868185043335
Validation loss: 2.1995940854152045

Epoch: 5| Step: 7
Training loss: 1.4197758436203003
Validation loss: 2.144000838200251

Epoch: 5| Step: 8
Training loss: 1.324682354927063
Validation loss: 2.209159185489019

Epoch: 5| Step: 9
Training loss: 1.2832592725753784
Validation loss: 2.1670184979836145

Epoch: 5| Step: 10
Training loss: 0.7293382287025452
Validation loss: 2.183080439766248

Epoch: 5| Step: 11
Training loss: 0.9399157762527466
Validation loss: 2.164211948712667

Epoch: 420| Step: 0
Training loss: 0.9487172961235046
Validation loss: 2.153957982858022

Epoch: 5| Step: 1
Training loss: 1.1739566326141357
Validation loss: 2.1301122357447944

Epoch: 5| Step: 2
Training loss: 1.2581113576889038
Validation loss: 2.173510874311129

Epoch: 5| Step: 3
Training loss: 1.2493995428085327
Validation loss: 2.1778692305088043

Epoch: 5| Step: 4
Training loss: 1.4408214092254639
Validation loss: 2.1719315697749457

Epoch: 5| Step: 5
Training loss: 0.9761703610420227
Validation loss: 2.150636211037636

Epoch: 5| Step: 6
Training loss: 1.2993825674057007
Validation loss: 2.1704942882061005

Epoch: 5| Step: 7
Training loss: 1.537959337234497
Validation loss: 2.178075725833575

Epoch: 5| Step: 8
Training loss: 0.7479698657989502
Validation loss: 2.1645001272360482

Epoch: 5| Step: 9
Training loss: 1.3782098293304443
Validation loss: 2.1763113290071487

Epoch: 5| Step: 10
Training loss: 1.4161598682403564
Validation loss: 2.2022953182458878

Epoch: 5| Step: 11
Training loss: 2.1514792442321777
Validation loss: 2.190598656733831

Epoch: 421| Step: 0
Training loss: 1.386490821838379
Validation loss: 2.1772528986136117

Epoch: 5| Step: 1
Training loss: 1.5709004402160645
Validation loss: 2.1967870791753135

Epoch: 5| Step: 2
Training loss: 1.0690481662750244
Validation loss: 2.1791928708553314

Epoch: 5| Step: 3
Training loss: 1.0366599559783936
Validation loss: 2.133694221576055

Epoch: 5| Step: 4
Training loss: 1.6609094142913818
Validation loss: 2.205837065974871

Epoch: 5| Step: 5
Training loss: 0.8986223340034485
Validation loss: 2.180095617969831

Epoch: 5| Step: 6
Training loss: 0.9931235313415527
Validation loss: 2.165835509697596

Epoch: 5| Step: 7
Training loss: 1.3034263849258423
Validation loss: 2.1942417869965234

Epoch: 5| Step: 8
Training loss: 1.2557328939437866
Validation loss: 2.2001922875642776

Epoch: 5| Step: 9
Training loss: 1.3611657619476318
Validation loss: 2.1697679261366525

Epoch: 5| Step: 10
Training loss: 0.6905443072319031
Validation loss: 2.200270136197408

Epoch: 5| Step: 11
Training loss: 1.9639679193496704
Validation loss: 2.184079478184382

Epoch: 422| Step: 0
Training loss: 1.5309582948684692
Validation loss: 2.1789938559134803

Epoch: 5| Step: 1
Training loss: 1.5227395296096802
Validation loss: 2.17397769788901

Epoch: 5| Step: 2
Training loss: 1.0034756660461426
Validation loss: 2.1790153831243515

Epoch: 5| Step: 3
Training loss: 0.6687278151512146
Validation loss: 2.175675501426061

Epoch: 5| Step: 4
Training loss: 1.2651219367980957
Validation loss: 2.2131662319103875

Epoch: 5| Step: 5
Training loss: 0.6574724912643433
Validation loss: 2.164547845721245

Epoch: 5| Step: 6
Training loss: 1.3902784585952759
Validation loss: 2.1357718308766684

Epoch: 5| Step: 7
Training loss: 0.731121838092804
Validation loss: 2.1605558892091117

Epoch: 5| Step: 8
Training loss: 1.3382956981658936
Validation loss: 2.1426661958297095

Epoch: 5| Step: 9
Training loss: 2.0889315605163574
Validation loss: 2.1409816245237985

Epoch: 5| Step: 10
Training loss: 1.4658070802688599
Validation loss: 2.153353691101074

Epoch: 5| Step: 11
Training loss: 0.4901474714279175
Validation loss: 2.1351220309734344

Epoch: 423| Step: 0
Training loss: 1.552761197090149
Validation loss: 2.0949474970499673

Epoch: 5| Step: 1
Training loss: 1.3304693698883057
Validation loss: 2.0715765953063965

Epoch: 5| Step: 2
Training loss: 1.0289435386657715
Validation loss: 2.091785262028376

Epoch: 5| Step: 3
Training loss: 1.220479965209961
Validation loss: 2.08145572245121

Epoch: 5| Step: 4
Training loss: 1.422450304031372
Validation loss: 2.1296001027027764

Epoch: 5| Step: 5
Training loss: 0.9447504878044128
Validation loss: 2.1226537823677063

Epoch: 5| Step: 6
Training loss: 1.0037333965301514
Validation loss: 2.150723566611608

Epoch: 5| Step: 7
Training loss: 1.1232064962387085
Validation loss: 2.160106728474299

Epoch: 5| Step: 8
Training loss: 1.7536731958389282
Validation loss: 2.1900865137577057

Epoch: 5| Step: 9
Training loss: 0.7337341904640198
Validation loss: 2.1735690285762153

Epoch: 5| Step: 10
Training loss: 1.645849585533142
Validation loss: 2.1789275805155435

Epoch: 5| Step: 11
Training loss: 1.7212245464324951
Validation loss: 2.2028845945994058

Epoch: 424| Step: 0
Training loss: 1.0765769481658936
Validation loss: 2.1602476090192795

Epoch: 5| Step: 1
Training loss: 1.2783604860305786
Validation loss: 2.154109999537468

Epoch: 5| Step: 2
Training loss: 1.2971765995025635
Validation loss: 2.1357146998246512

Epoch: 5| Step: 3
Training loss: 1.1439136266708374
Validation loss: 2.1364946166674295

Epoch: 5| Step: 4
Training loss: 1.1591228246688843
Validation loss: 2.1467690666516623

Epoch: 5| Step: 5
Training loss: 1.5628783702850342
Validation loss: 2.1435205886761346

Epoch: 5| Step: 6
Training loss: 0.9440473318099976
Validation loss: 2.154541383186976

Epoch: 5| Step: 7
Training loss: 1.0780004262924194
Validation loss: 2.1254295061031976

Epoch: 5| Step: 8
Training loss: 1.0276477336883545
Validation loss: 2.109840760628382

Epoch: 5| Step: 9
Training loss: 1.3286473751068115
Validation loss: 2.126971165339152

Epoch: 5| Step: 10
Training loss: 1.2303507328033447
Validation loss: 2.1397576381762824

Epoch: 5| Step: 11
Training loss: 0.6899474859237671
Validation loss: 2.138785103956858

Epoch: 425| Step: 0
Training loss: 1.03523850440979
Validation loss: 2.1283631275097528

Epoch: 5| Step: 1
Training loss: 1.1145188808441162
Validation loss: 2.134832486510277

Epoch: 5| Step: 2
Training loss: 0.7934389114379883
Validation loss: 2.123965948820114

Epoch: 5| Step: 3
Training loss: 1.8347381353378296
Validation loss: 2.1715771555900574

Epoch: 5| Step: 4
Training loss: 1.7324845790863037
Validation loss: 2.1587270945310593

Epoch: 5| Step: 5
Training loss: 0.8439663052558899
Validation loss: 2.21161421140035

Epoch: 5| Step: 6
Training loss: 0.8961653709411621
Validation loss: 2.2012746582428613

Epoch: 5| Step: 7
Training loss: 0.7416644096374512
Validation loss: 2.2158612807591758

Epoch: 5| Step: 8
Training loss: 1.3600457906723022
Validation loss: 2.2058122555414834

Epoch: 5| Step: 9
Training loss: 1.5003604888916016
Validation loss: 2.1760865847269693

Epoch: 5| Step: 10
Training loss: 1.024236798286438
Validation loss: 2.208239436149597

Epoch: 5| Step: 11
Training loss: 1.224759817123413
Validation loss: 2.1880446672439575

Epoch: 426| Step: 0
Training loss: 1.3317241668701172
Validation loss: 2.170424699783325

Epoch: 5| Step: 1
Training loss: 1.3773553371429443
Validation loss: 2.174360836545626

Epoch: 5| Step: 2
Training loss: 1.6007368564605713
Validation loss: 2.168331856528918

Epoch: 5| Step: 3
Training loss: 1.0706532001495361
Validation loss: 2.1136031299829483

Epoch: 5| Step: 4
Training loss: 1.40802001953125
Validation loss: 2.1375723282496133

Epoch: 5| Step: 5
Training loss: 0.9544277191162109
Validation loss: 2.1506032148996987

Epoch: 5| Step: 6
Training loss: 0.9907941818237305
Validation loss: 2.18015918135643

Epoch: 5| Step: 7
Training loss: 1.336566686630249
Validation loss: 2.153058707714081

Epoch: 5| Step: 8
Training loss: 1.1109172105789185
Validation loss: 2.1480299135049186

Epoch: 5| Step: 9
Training loss: 1.1535792350769043
Validation loss: 2.229171544313431

Epoch: 5| Step: 10
Training loss: 1.2573363780975342
Validation loss: 2.202871243158976

Epoch: 5| Step: 11
Training loss: 0.41405510902404785
Validation loss: 2.2015039871136346

Epoch: 427| Step: 0
Training loss: 1.7331117391586304
Validation loss: 2.220907906691233

Epoch: 5| Step: 1
Training loss: 0.8847448229789734
Validation loss: 2.185643578569094

Epoch: 5| Step: 2
Training loss: 1.0495885610580444
Validation loss: 2.2196065882841745

Epoch: 5| Step: 3
Training loss: 1.023000955581665
Validation loss: 2.21381043891112

Epoch: 5| Step: 4
Training loss: 0.8951624035835266
Validation loss: 2.2387527376413345

Epoch: 5| Step: 5
Training loss: 1.1751024723052979
Validation loss: 2.2469839652379355

Epoch: 5| Step: 6
Training loss: 0.9031278491020203
Validation loss: 2.206539655725161

Epoch: 5| Step: 7
Training loss: 1.334356665611267
Validation loss: 2.261421968539556

Epoch: 5| Step: 8
Training loss: 1.1585123538970947
Validation loss: 2.2363136559724808

Epoch: 5| Step: 9
Training loss: 1.2556283473968506
Validation loss: 2.21558545033137

Epoch: 5| Step: 10
Training loss: 1.378111720085144
Validation loss: 2.2405947546164193

Epoch: 5| Step: 11
Training loss: 2.1495132446289062
Validation loss: 2.219166020552317

Epoch: 428| Step: 0
Training loss: 1.0979576110839844
Validation loss: 2.194694538911184

Epoch: 5| Step: 1
Training loss: 1.36099112033844
Validation loss: 2.1883259614308677

Epoch: 5| Step: 2
Training loss: 1.0125534534454346
Validation loss: 2.2100104093551636

Epoch: 5| Step: 3
Training loss: 1.357532024383545
Validation loss: 2.2044520477453866

Epoch: 5| Step: 4
Training loss: 0.7981606721878052
Validation loss: 2.1881866653760276

Epoch: 5| Step: 5
Training loss: 1.5883219242095947
Validation loss: 2.174216240644455

Epoch: 5| Step: 6
Training loss: 1.6377747058868408
Validation loss: 2.1601828138033548

Epoch: 5| Step: 7
Training loss: 1.2942918539047241
Validation loss: 2.181658690174421

Epoch: 5| Step: 8
Training loss: 1.3984735012054443
Validation loss: 2.1356420715649924

Epoch: 5| Step: 9
Training loss: 1.4060816764831543
Validation loss: 2.123351658384005

Epoch: 5| Step: 10
Training loss: 1.214929461479187
Validation loss: 2.1694424003362656

Epoch: 5| Step: 11
Training loss: 1.8026598691940308
Validation loss: 2.139145871003469

Epoch: 429| Step: 0
Training loss: 1.1440000534057617
Validation loss: 2.123878891269366

Epoch: 5| Step: 1
Training loss: 0.94511479139328
Validation loss: 2.162032276391983

Epoch: 5| Step: 2
Training loss: 1.0439035892486572
Validation loss: 2.159623011946678

Epoch: 5| Step: 3
Training loss: 1.230302095413208
Validation loss: 2.1587958484888077

Epoch: 5| Step: 4
Training loss: 0.9227298498153687
Validation loss: 2.199812720219294

Epoch: 5| Step: 5
Training loss: 1.193477988243103
Validation loss: 2.160839627186457

Epoch: 5| Step: 6
Training loss: 1.9289413690567017
Validation loss: 2.2232156793276467

Epoch: 5| Step: 7
Training loss: 1.1356805562973022
Validation loss: 2.2302659501632056

Epoch: 5| Step: 8
Training loss: 1.5023797750473022
Validation loss: 2.197655498981476

Epoch: 5| Step: 9
Training loss: 0.878005862236023
Validation loss: 2.181648999452591

Epoch: 5| Step: 10
Training loss: 0.8651548624038696
Validation loss: 2.163343538840612

Epoch: 5| Step: 11
Training loss: 2.636230945587158
Validation loss: 2.187202046314875

Epoch: 430| Step: 0
Training loss: 1.159968614578247
Validation loss: 2.1901653657356897

Epoch: 5| Step: 1
Training loss: 1.5539239645004272
Validation loss: 2.225430428981781

Epoch: 5| Step: 2
Training loss: 1.5688502788543701
Validation loss: 2.227050339182218

Epoch: 5| Step: 3
Training loss: 1.117446780204773
Validation loss: 2.1968581626812616

Epoch: 5| Step: 4
Training loss: 0.6593329310417175
Validation loss: 2.2507949074109397

Epoch: 5| Step: 5
Training loss: 1.0474755764007568
Validation loss: 2.220360964536667

Epoch: 5| Step: 6
Training loss: 1.2005982398986816
Validation loss: 2.21200430393219

Epoch: 5| Step: 7
Training loss: 1.4970512390136719
Validation loss: 2.218549514810244

Epoch: 5| Step: 8
Training loss: 1.129277229309082
Validation loss: 2.171454300483068

Epoch: 5| Step: 9
Training loss: 0.9119096994400024
Validation loss: 2.1661595851182938

Epoch: 5| Step: 10
Training loss: 1.323639988899231
Validation loss: 2.165840486685435

Epoch: 5| Step: 11
Training loss: 0.47775790095329285
Validation loss: 2.1683773497740426

Epoch: 431| Step: 0
Training loss: 0.742619514465332
Validation loss: 2.1657662143309913

Epoch: 5| Step: 1
Training loss: 1.3572756052017212
Validation loss: 2.1491199831167855

Epoch: 5| Step: 2
Training loss: 1.3576371669769287
Validation loss: 2.155793607234955

Epoch: 5| Step: 3
Training loss: 1.9001115560531616
Validation loss: 2.179302508632342

Epoch: 5| Step: 4
Training loss: 0.7547537088394165
Validation loss: 2.156766951084137

Epoch: 5| Step: 5
Training loss: 1.2298529148101807
Validation loss: 2.135340561469396

Epoch: 5| Step: 6
Training loss: 1.2831857204437256
Validation loss: 2.1485871076583862

Epoch: 5| Step: 7
Training loss: 1.2670209407806396
Validation loss: 2.1411555806795755

Epoch: 5| Step: 8
Training loss: 0.7996507287025452
Validation loss: 2.1438334584236145

Epoch: 5| Step: 9
Training loss: 1.1086719036102295
Validation loss: 2.1553242107232413

Epoch: 5| Step: 10
Training loss: 1.4593536853790283
Validation loss: 2.1250017285346985

Epoch: 5| Step: 11
Training loss: 1.0556535720825195
Validation loss: 2.154187887907028

Epoch: 432| Step: 0
Training loss: 1.1247284412384033
Validation loss: 2.1793018331130347

Epoch: 5| Step: 1
Training loss: 1.6699683666229248
Validation loss: 2.2002838999032974

Epoch: 5| Step: 2
Training loss: 0.7342690229415894
Validation loss: 2.167230933904648

Epoch: 5| Step: 3
Training loss: 1.3985780477523804
Validation loss: 2.175184185306231

Epoch: 5| Step: 4
Training loss: 1.545098900794983
Validation loss: 2.2151296635468802

Epoch: 5| Step: 5
Training loss: 1.3777151107788086
Validation loss: 2.2079333513975143

Epoch: 5| Step: 6
Training loss: 0.9759567379951477
Validation loss: 2.1828604886929193

Epoch: 5| Step: 7
Training loss: 1.0259993076324463
Validation loss: 2.218599264820417

Epoch: 5| Step: 8
Training loss: 0.8197491765022278
Validation loss: 2.1727893948554993

Epoch: 5| Step: 9
Training loss: 0.5619548559188843
Validation loss: 2.210032264391581

Epoch: 5| Step: 10
Training loss: 1.8178459405899048
Validation loss: 2.1858427226543427

Epoch: 5| Step: 11
Training loss: 0.6588243246078491
Validation loss: 2.1813224405050278

Epoch: 433| Step: 0
Training loss: 0.7722920179367065
Validation loss: 2.1983261853456497

Epoch: 5| Step: 1
Training loss: 1.0873615741729736
Validation loss: 2.2036130925019584

Epoch: 5| Step: 2
Training loss: 1.6138885021209717
Validation loss: 2.2205793062845864

Epoch: 5| Step: 3
Training loss: 1.5578526258468628
Validation loss: 2.2509523183107376

Epoch: 5| Step: 4
Training loss: 0.47536700963974
Validation loss: 2.214485635360082

Epoch: 5| Step: 5
Training loss: 1.5580648183822632
Validation loss: 2.2255227317412696

Epoch: 5| Step: 6
Training loss: 1.6437091827392578
Validation loss: 2.194632569948832

Epoch: 5| Step: 7
Training loss: 1.2355585098266602
Validation loss: 2.2056796799103418

Epoch: 5| Step: 8
Training loss: 1.6595615148544312
Validation loss: 2.2134728332360587

Epoch: 5| Step: 9
Training loss: 1.0814075469970703
Validation loss: 2.208797867099444

Epoch: 5| Step: 10
Training loss: 1.2590612173080444
Validation loss: 2.165892779827118

Epoch: 5| Step: 11
Training loss: 0.3818984031677246
Validation loss: 2.20388592282931

Epoch: 434| Step: 0
Training loss: 1.0653834342956543
Validation loss: 2.1560118595759072

Epoch: 5| Step: 1
Training loss: 1.15711510181427
Validation loss: 2.1687880059083304

Epoch: 5| Step: 2
Training loss: 0.700367271900177
Validation loss: 2.17283163468043

Epoch: 5| Step: 3
Training loss: 1.4003636837005615
Validation loss: 2.1420837144056954

Epoch: 5| Step: 4
Training loss: 1.5707772970199585
Validation loss: 2.1671930054823556

Epoch: 5| Step: 5
Training loss: 1.2554175853729248
Validation loss: 2.128811086217562

Epoch: 5| Step: 6
Training loss: 1.0963952541351318
Validation loss: 2.1441093534231186

Epoch: 5| Step: 7
Training loss: 0.9866102337837219
Validation loss: 2.130216732621193

Epoch: 5| Step: 8
Training loss: 0.8531371355056763
Validation loss: 2.1768522361914315

Epoch: 5| Step: 9
Training loss: 1.431916356086731
Validation loss: 2.1798072109619775

Epoch: 5| Step: 10
Training loss: 1.1146225929260254
Validation loss: 2.2014572074015937

Epoch: 5| Step: 11
Training loss: 0.16893571615219116
Validation loss: 2.1754583219687142

Epoch: 435| Step: 0
Training loss: 0.7812892198562622
Validation loss: 2.214141940077146

Epoch: 5| Step: 1
Training loss: 1.6641261577606201
Validation loss: 2.1765290101369223

Epoch: 5| Step: 2
Training loss: 0.9327859878540039
Validation loss: 2.221731593211492

Epoch: 5| Step: 3
Training loss: 1.4509780406951904
Validation loss: 2.2075172861417136

Epoch: 5| Step: 4
Training loss: 1.0757511854171753
Validation loss: 2.1610692838827767

Epoch: 5| Step: 5
Training loss: 0.7776675820350647
Validation loss: 2.150325655937195

Epoch: 5| Step: 6
Training loss: 1.3843910694122314
Validation loss: 2.2057159741719565

Epoch: 5| Step: 7
Training loss: 1.159470558166504
Validation loss: 2.1893495122591653

Epoch: 5| Step: 8
Training loss: 1.1617587804794312
Validation loss: 2.188666269183159

Epoch: 5| Step: 9
Training loss: 0.8350698351860046
Validation loss: 2.2169974793990455

Epoch: 5| Step: 10
Training loss: 1.1764581203460693
Validation loss: 2.2162393728892007

Epoch: 5| Step: 11
Training loss: 1.3009507656097412
Validation loss: 2.1994499961535134

Epoch: 436| Step: 0
Training loss: 1.4184585809707642
Validation loss: 2.2174524863560996

Epoch: 5| Step: 1
Training loss: 0.9462335705757141
Validation loss: 2.1703361719846725

Epoch: 5| Step: 2
Training loss: 0.9543291926383972
Validation loss: 2.204484134912491

Epoch: 5| Step: 3
Training loss: 0.6974953413009644
Validation loss: 2.183496798078219

Epoch: 5| Step: 4
Training loss: 0.944430947303772
Validation loss: 2.2026748806238174

Epoch: 5| Step: 5
Training loss: 1.9579194784164429
Validation loss: 2.176258757710457

Epoch: 5| Step: 6
Training loss: 1.4262018203735352
Validation loss: 2.14986918369929

Epoch: 5| Step: 7
Training loss: 0.7173826694488525
Validation loss: 2.179104894399643

Epoch: 5| Step: 8
Training loss: 0.7351808547973633
Validation loss: 2.1546006401379905

Epoch: 5| Step: 9
Training loss: 1.0506017208099365
Validation loss: 2.153676152229309

Epoch: 5| Step: 10
Training loss: 1.4719277620315552
Validation loss: 2.1432488560676575

Epoch: 5| Step: 11
Training loss: 3.0122671127319336
Validation loss: 2.1915793071190515

Epoch: 437| Step: 0
Training loss: 0.8605319261550903
Validation loss: 2.1957046488920846

Epoch: 5| Step: 1
Training loss: 0.789568305015564
Validation loss: 2.1988460371891656

Epoch: 5| Step: 2
Training loss: 0.7733729481697083
Validation loss: 2.1984580556551614

Epoch: 5| Step: 3
Training loss: 1.011198878288269
Validation loss: 2.184092029929161

Epoch: 5| Step: 4
Training loss: 1.1148968935012817
Validation loss: 2.222942198316256

Epoch: 5| Step: 5
Training loss: 1.3982104063034058
Validation loss: 2.214684009552002

Epoch: 5| Step: 6
Training loss: 1.485472559928894
Validation loss: 2.244972348213196

Epoch: 5| Step: 7
Training loss: 1.8711553812026978
Validation loss: 2.226638292272886

Epoch: 5| Step: 8
Training loss: 0.785507082939148
Validation loss: 2.2441569020350776

Epoch: 5| Step: 9
Training loss: 1.0785192251205444
Validation loss: 2.21536722779274

Epoch: 5| Step: 10
Training loss: 1.2877025604248047
Validation loss: 2.2428599248329797

Epoch: 5| Step: 11
Training loss: 0.8638299703598022
Validation loss: 2.201590910553932

Epoch: 438| Step: 0
Training loss: 1.1218403577804565
Validation loss: 2.21743243932724

Epoch: 5| Step: 1
Training loss: 0.7421247959136963
Validation loss: 2.1994132647911706

Epoch: 5| Step: 2
Training loss: 1.1748321056365967
Validation loss: 2.2061147491137185

Epoch: 5| Step: 3
Training loss: 1.3490341901779175
Validation loss: 2.1582625806331635

Epoch: 5| Step: 4
Training loss: 0.839462399482727
Validation loss: 2.15886756281058

Epoch: 5| Step: 5
Training loss: 1.7182588577270508
Validation loss: 2.201658790310224

Epoch: 5| Step: 6
Training loss: 0.9308058023452759
Validation loss: 2.1841483414173126

Epoch: 5| Step: 7
Training loss: 0.7379777431488037
Validation loss: 2.2212264090776443

Epoch: 5| Step: 8
Training loss: 1.970062017440796
Validation loss: 2.201894069711367

Epoch: 5| Step: 9
Training loss: 0.9602786302566528
Validation loss: 2.212608893712362

Epoch: 5| Step: 10
Training loss: 1.1727477312088013
Validation loss: 2.2702270448207855

Epoch: 5| Step: 11
Training loss: 0.648309051990509
Validation loss: 2.2309687385956445

Epoch: 439| Step: 0
Training loss: 1.184532880783081
Validation loss: 2.1777703066666922

Epoch: 5| Step: 1
Training loss: 1.3061113357543945
Validation loss: 2.194695790608724

Epoch: 5| Step: 2
Training loss: 0.99365234375
Validation loss: 2.17950701713562

Epoch: 5| Step: 3
Training loss: 1.453359603881836
Validation loss: 2.178007553021113

Epoch: 5| Step: 4
Training loss: 1.0686073303222656
Validation loss: 2.163961033026377

Epoch: 5| Step: 5
Training loss: 1.8294551372528076
Validation loss: 2.1537125259637833

Epoch: 5| Step: 6
Training loss: 1.0420812368392944
Validation loss: 2.1535716702540717

Epoch: 5| Step: 7
Training loss: 0.9231321215629578
Validation loss: 2.1600982497135797

Epoch: 5| Step: 8
Training loss: 1.2881627082824707
Validation loss: 2.141878217458725

Epoch: 5| Step: 9
Training loss: 0.9018081426620483
Validation loss: 2.163802390297254

Epoch: 5| Step: 10
Training loss: 1.1872546672821045
Validation loss: 2.1292478144168854

Epoch: 5| Step: 11
Training loss: 0.9145646095275879
Validation loss: 2.1242752373218536

Epoch: 440| Step: 0
Training loss: 1.1931846141815186
Validation loss: 2.1366120179494223

Epoch: 5| Step: 1
Training loss: 0.9768207669258118
Validation loss: 2.1241269409656525

Epoch: 5| Step: 2
Training loss: 1.3212430477142334
Validation loss: 2.1509792506694794

Epoch: 5| Step: 3
Training loss: 1.4869314432144165
Validation loss: 2.133177454272906

Epoch: 5| Step: 4
Training loss: 1.049460530281067
Validation loss: 2.102273796995481

Epoch: 5| Step: 5
Training loss: 0.6371219754219055
Validation loss: 2.1470129440228143

Epoch: 5| Step: 6
Training loss: 1.401665210723877
Validation loss: 2.1433433145284653

Epoch: 5| Step: 7
Training loss: 1.3907018899917603
Validation loss: 2.2024534394343696

Epoch: 5| Step: 8
Training loss: 1.0287611484527588
Validation loss: 2.2076187431812286

Epoch: 5| Step: 9
Training loss: 1.899026870727539
Validation loss: 2.148975670337677

Epoch: 5| Step: 10
Training loss: 0.7081771492958069
Validation loss: 2.206030602256457

Epoch: 5| Step: 11
Training loss: 2.0913238525390625
Validation loss: 2.149833709001541

Epoch: 441| Step: 0
Training loss: 0.6779748201370239
Validation loss: 2.186235561966896

Epoch: 5| Step: 1
Training loss: 0.9090162515640259
Validation loss: 2.184821665287018

Epoch: 5| Step: 2
Training loss: 1.027936339378357
Validation loss: 2.176602393388748

Epoch: 5| Step: 3
Training loss: 1.6432502269744873
Validation loss: 2.1835562586784363

Epoch: 5| Step: 4
Training loss: 0.890101432800293
Validation loss: 2.159220059712728

Epoch: 5| Step: 5
Training loss: 0.8914481997489929
Validation loss: 2.12510554989179

Epoch: 5| Step: 6
Training loss: 1.121063232421875
Validation loss: 2.1558198680480323

Epoch: 5| Step: 7
Training loss: 1.412380576133728
Validation loss: 2.136206944783529

Epoch: 5| Step: 8
Training loss: 0.8729969263076782
Validation loss: 2.155832886695862

Epoch: 5| Step: 9
Training loss: 0.9179186820983887
Validation loss: 2.144641806681951

Epoch: 5| Step: 10
Training loss: 1.459075689315796
Validation loss: 2.161448508501053

Epoch: 5| Step: 11
Training loss: 1.8947378396987915
Validation loss: 2.1459243496259055

Epoch: 442| Step: 0
Training loss: 1.0360920429229736
Validation loss: 2.1464296032985053

Epoch: 5| Step: 1
Training loss: 1.2597118616104126
Validation loss: 2.1357727348804474

Epoch: 5| Step: 2
Training loss: 1.568145990371704
Validation loss: 2.1534874538580575

Epoch: 5| Step: 3
Training loss: 1.0265640020370483
Validation loss: 2.1256989439328513

Epoch: 5| Step: 4
Training loss: 0.9435938596725464
Validation loss: 2.1393028497695923

Epoch: 5| Step: 5
Training loss: 1.2565196752548218
Validation loss: 2.1461930771668754

Epoch: 5| Step: 6
Training loss: 1.2220438718795776
Validation loss: 2.1396997968355813

Epoch: 5| Step: 7
Training loss: 0.8994659185409546
Validation loss: 2.1479448775450387

Epoch: 5| Step: 8
Training loss: 1.050082802772522
Validation loss: 2.167112171649933

Epoch: 5| Step: 9
Training loss: 0.9866260290145874
Validation loss: 2.1815902292728424

Epoch: 5| Step: 10
Training loss: 1.1129858493804932
Validation loss: 2.175506442785263

Epoch: 5| Step: 11
Training loss: 0.3645738959312439
Validation loss: 2.169018199046453

Epoch: 443| Step: 0
Training loss: 0.8309780955314636
Validation loss: 2.189321835835775

Epoch: 5| Step: 1
Training loss: 0.9632505178451538
Validation loss: 2.226370478669802

Epoch: 5| Step: 2
Training loss: 1.3483686447143555
Validation loss: 2.2051056027412415

Epoch: 5| Step: 3
Training loss: 0.9527233242988586
Validation loss: 2.2566697547833123

Epoch: 5| Step: 4
Training loss: 0.9678534269332886
Validation loss: 2.2000949680805206

Epoch: 5| Step: 5
Training loss: 1.3017163276672363
Validation loss: 2.1829925378163657

Epoch: 5| Step: 6
Training loss: 0.6437300443649292
Validation loss: 2.200195829073588

Epoch: 5| Step: 7
Training loss: 1.0667519569396973
Validation loss: 2.2341366906960807

Epoch: 5| Step: 8
Training loss: 1.5197561979293823
Validation loss: 2.2217563688755035

Epoch: 5| Step: 9
Training loss: 1.5323173999786377
Validation loss: 2.2489861150582633

Epoch: 5| Step: 10
Training loss: 1.1149044036865234
Validation loss: 2.2008797228336334

Epoch: 5| Step: 11
Training loss: 2.1276707649230957
Validation loss: 2.1996257652839026

Epoch: 444| Step: 0
Training loss: 0.7411788702011108
Validation loss: 2.220626880725225

Epoch: 5| Step: 1
Training loss: 1.0842803716659546
Validation loss: 2.1837132424116135

Epoch: 5| Step: 2
Training loss: 0.8253352046012878
Validation loss: 2.185021867354711

Epoch: 5| Step: 3
Training loss: 0.7335733771324158
Validation loss: 2.178990880648295

Epoch: 5| Step: 4
Training loss: 1.2562839984893799
Validation loss: 2.169494445125262

Epoch: 5| Step: 5
Training loss: 1.3500697612762451
Validation loss: 2.186283523837725

Epoch: 5| Step: 6
Training loss: 1.4284203052520752
Validation loss: 2.1972897301117578

Epoch: 5| Step: 7
Training loss: 1.144073724746704
Validation loss: 2.181003659963608

Epoch: 5| Step: 8
Training loss: 1.0720477104187012
Validation loss: 2.209823618332545

Epoch: 5| Step: 9
Training loss: 1.3885345458984375
Validation loss: 2.2330576876799264

Epoch: 5| Step: 10
Training loss: 1.1858621835708618
Validation loss: 2.185700078805288

Epoch: 5| Step: 11
Training loss: 1.4520421028137207
Validation loss: 2.1819174190362296

Epoch: 445| Step: 0
Training loss: 1.2523990869522095
Validation loss: 2.179134786128998

Epoch: 5| Step: 1
Training loss: 1.0297534465789795
Validation loss: 2.1769314060608544

Epoch: 5| Step: 2
Training loss: 1.4409291744232178
Validation loss: 2.1690518309672675

Epoch: 5| Step: 3
Training loss: 0.6664246320724487
Validation loss: 2.195162524779638

Epoch: 5| Step: 4
Training loss: 1.0925440788269043
Validation loss: 2.138516277074814

Epoch: 5| Step: 5
Training loss: 0.9094012379646301
Validation loss: 2.1691184490919113

Epoch: 5| Step: 6
Training loss: 0.7882977724075317
Validation loss: 2.185284440716108

Epoch: 5| Step: 7
Training loss: 1.3204355239868164
Validation loss: 2.1827739427487054

Epoch: 5| Step: 8
Training loss: 0.9694271087646484
Validation loss: 2.150684028863907

Epoch: 5| Step: 9
Training loss: 1.351187825202942
Validation loss: 2.1874171743790307

Epoch: 5| Step: 10
Training loss: 0.9497905969619751
Validation loss: 2.1410186489423118

Epoch: 5| Step: 11
Training loss: 0.46522057056427
Validation loss: 2.1757938911517463

Epoch: 446| Step: 0
Training loss: 1.390255331993103
Validation loss: 2.1705700208743415

Epoch: 5| Step: 1
Training loss: 1.6015039682388306
Validation loss: 2.1149481187264123

Epoch: 5| Step: 2
Training loss: 1.0267002582550049
Validation loss: 2.153471445043882

Epoch: 5| Step: 3
Training loss: 0.8684528470039368
Validation loss: 2.2011385957400003

Epoch: 5| Step: 4
Training loss: 0.989306628704071
Validation loss: 2.146587078770002

Epoch: 5| Step: 5
Training loss: 0.9115589261054993
Validation loss: 2.1679356346527734

Epoch: 5| Step: 6
Training loss: 1.1911118030548096
Validation loss: 2.1383488376935325

Epoch: 5| Step: 7
Training loss: 1.5149707794189453
Validation loss: 2.13614185154438

Epoch: 5| Step: 8
Training loss: 0.7687404751777649
Validation loss: 2.169917941093445

Epoch: 5| Step: 9
Training loss: 1.2409851551055908
Validation loss: 2.1318079928557077

Epoch: 5| Step: 10
Training loss: 0.5108362436294556
Validation loss: 2.106092909971873

Epoch: 5| Step: 11
Training loss: 0.9723926186561584
Validation loss: 2.1457323879003525

Epoch: 447| Step: 0
Training loss: 1.690622091293335
Validation loss: 2.1131816804409027

Epoch: 5| Step: 1
Training loss: 0.9049776196479797
Validation loss: 2.1153185913960137

Epoch: 5| Step: 2
Training loss: 1.215315341949463
Validation loss: 2.1241747438907623

Epoch: 5| Step: 3
Training loss: 1.3330836296081543
Validation loss: 2.1020416965087256

Epoch: 5| Step: 4
Training loss: 0.8133312463760376
Validation loss: 2.1651174128055573

Epoch: 5| Step: 5
Training loss: 1.1126940250396729
Validation loss: 2.108324408531189

Epoch: 5| Step: 6
Training loss: 0.7308038473129272
Validation loss: 2.158083106080691

Epoch: 5| Step: 7
Training loss: 1.0349053144454956
Validation loss: 2.1977500716845193

Epoch: 5| Step: 8
Training loss: 1.6011078357696533
Validation loss: 2.184775491555532

Epoch: 5| Step: 9
Training loss: 1.3015060424804688
Validation loss: 2.207888881365458

Epoch: 5| Step: 10
Training loss: 1.3786003589630127
Validation loss: 2.216952368617058

Epoch: 5| Step: 11
Training loss: 0.9433404207229614
Validation loss: 2.195215384165446

Epoch: 448| Step: 0
Training loss: 1.25229811668396
Validation loss: 2.1777152121067047

Epoch: 5| Step: 1
Training loss: 0.9875040054321289
Validation loss: 2.211948191126188

Epoch: 5| Step: 2
Training loss: 1.070521354675293
Validation loss: 2.206593488653501

Epoch: 5| Step: 3
Training loss: 0.5349132418632507
Validation loss: 2.1346618135770163

Epoch: 5| Step: 4
Training loss: 1.2411835193634033
Validation loss: 2.2139776945114136

Epoch: 5| Step: 5
Training loss: 1.407481074333191
Validation loss: 2.189785664280256

Epoch: 5| Step: 6
Training loss: 0.9344029426574707
Validation loss: 2.1926964124043784

Epoch: 5| Step: 7
Training loss: 1.158229112625122
Validation loss: 2.2001069635152817

Epoch: 5| Step: 8
Training loss: 1.471571683883667
Validation loss: 2.1927049458026886

Epoch: 5| Step: 9
Training loss: 1.060703992843628
Validation loss: 2.2219879925251007

Epoch: 5| Step: 10
Training loss: 1.1477442979812622
Validation loss: 2.2162744949261346

Epoch: 5| Step: 11
Training loss: 1.3582854270935059
Validation loss: 2.2265609304110208

Epoch: 449| Step: 0
Training loss: 1.1840903759002686
Validation loss: 2.222846125562986

Epoch: 5| Step: 1
Training loss: 1.1518142223358154
Validation loss: 2.1765863597393036

Epoch: 5| Step: 2
Training loss: 1.2671457529067993
Validation loss: 2.1966833770275116

Epoch: 5| Step: 3
Training loss: 0.7424576878547668
Validation loss: 2.170901447534561

Epoch: 5| Step: 4
Training loss: 0.7753912210464478
Validation loss: 2.1603240172068277

Epoch: 5| Step: 5
Training loss: 1.6180999279022217
Validation loss: 2.18478125333786

Epoch: 5| Step: 6
Training loss: 0.8483686447143555
Validation loss: 2.1605804165204368

Epoch: 5| Step: 7
Training loss: 1.5591800212860107
Validation loss: 2.1758638123671212

Epoch: 5| Step: 8
Training loss: 1.3195087909698486
Validation loss: 2.192051649093628

Epoch: 5| Step: 9
Training loss: 0.7944245338439941
Validation loss: 2.19830222427845

Epoch: 5| Step: 10
Training loss: 1.5679317712783813
Validation loss: 2.202042058110237

Epoch: 5| Step: 11
Training loss: 0.9809426069259644
Validation loss: 2.2100473940372467

Epoch: 450| Step: 0
Training loss: 0.9407144784927368
Validation loss: 2.2268111358086267

Epoch: 5| Step: 1
Training loss: 0.8050843477249146
Validation loss: 2.2792300830284753

Epoch: 5| Step: 2
Training loss: 1.6516746282577515
Validation loss: 2.2918101052443185

Epoch: 5| Step: 3
Training loss: 0.819403350353241
Validation loss: 2.1935444275538125

Epoch: 5| Step: 4
Training loss: 1.2905317544937134
Validation loss: 2.212243581811587

Epoch: 5| Step: 5
Training loss: 1.0413683652877808
Validation loss: 2.180375317732493

Epoch: 5| Step: 6
Training loss: 1.0909149646759033
Validation loss: 2.1859155098597207

Epoch: 5| Step: 7
Training loss: 1.1838093996047974
Validation loss: 2.1992128690083823

Epoch: 5| Step: 8
Training loss: 1.0310776233673096
Validation loss: 2.1708543399969735

Epoch: 5| Step: 9
Training loss: 0.7427670359611511
Validation loss: 2.1775084882974625

Epoch: 5| Step: 10
Training loss: 1.0991854667663574
Validation loss: 2.1858595460653305

Epoch: 5| Step: 11
Training loss: 1.169217824935913
Validation loss: 2.15896903971831

Epoch: 451| Step: 0
Training loss: 0.6277331113815308
Validation loss: 2.168803264697393

Epoch: 5| Step: 1
Training loss: 0.9094030261039734
Validation loss: 2.168852130572001

Epoch: 5| Step: 2
Training loss: 0.7727137804031372
Validation loss: 2.1833616296450296

Epoch: 5| Step: 3
Training loss: 1.3129839897155762
Validation loss: 2.232157349586487

Epoch: 5| Step: 4
Training loss: 1.627866506576538
Validation loss: 2.197838688890139

Epoch: 5| Step: 5
Training loss: 0.9913972616195679
Validation loss: 2.1961085548003516

Epoch: 5| Step: 6
Training loss: 1.2177293300628662
Validation loss: 2.181665301322937

Epoch: 5| Step: 7
Training loss: 1.1198323965072632
Validation loss: 2.1697460959355035

Epoch: 5| Step: 8
Training loss: 1.0798964500427246
Validation loss: 2.2016615768273673

Epoch: 5| Step: 9
Training loss: 1.4382511377334595
Validation loss: 2.1580075323581696

Epoch: 5| Step: 10
Training loss: 1.6291635036468506
Validation loss: 2.17370775838693

Epoch: 5| Step: 11
Training loss: 1.2478970289230347
Validation loss: 2.1522229264179864

Epoch: 452| Step: 0
Training loss: 1.0293872356414795
Validation loss: 2.157731771469116

Epoch: 5| Step: 1
Training loss: 1.0187854766845703
Validation loss: 2.1397151003281274

Epoch: 5| Step: 2
Training loss: 0.760961651802063
Validation loss: 2.0878714124361673

Epoch: 5| Step: 3
Training loss: 1.0751737356185913
Validation loss: 2.094819203019142

Epoch: 5| Step: 4
Training loss: 1.2570748329162598
Validation loss: 2.1368956118822098

Epoch: 5| Step: 5
Training loss: 1.766770601272583
Validation loss: 2.1745832363764444

Epoch: 5| Step: 6
Training loss: 1.0371285676956177
Validation loss: 2.153225223223368

Epoch: 5| Step: 7
Training loss: 0.9415334463119507
Validation loss: 2.171732102831205

Epoch: 5| Step: 8
Training loss: 1.335370421409607
Validation loss: 2.1744201382001243

Epoch: 5| Step: 9
Training loss: 1.5035343170166016
Validation loss: 2.1429634590943656

Epoch: 5| Step: 10
Training loss: 1.0017224550247192
Validation loss: 2.113237977027893

Epoch: 5| Step: 11
Training loss: 1.7238941192626953
Validation loss: 2.1227495968341827

Epoch: 453| Step: 0
Training loss: 0.8847419619560242
Validation loss: 2.1509289195140204

Epoch: 5| Step: 1
Training loss: 1.3128864765167236
Validation loss: 2.1906172782182693

Epoch: 5| Step: 2
Training loss: 1.3408803939819336
Validation loss: 2.1717233856519065

Epoch: 5| Step: 3
Training loss: 0.6845971345901489
Validation loss: 2.208273564775785

Epoch: 5| Step: 4
Training loss: 1.0600255727767944
Validation loss: 2.1873035579919815

Epoch: 5| Step: 5
Training loss: 0.7046434283256531
Validation loss: 2.2171024481455484

Epoch: 5| Step: 6
Training loss: 1.6278982162475586
Validation loss: 2.1969023793935776

Epoch: 5| Step: 7
Training loss: 0.6755110621452332
Validation loss: 2.225495676199595

Epoch: 5| Step: 8
Training loss: 0.6248241662979126
Validation loss: 2.2166384160518646

Epoch: 5| Step: 9
Training loss: 1.2162977457046509
Validation loss: 2.232310434182485

Epoch: 5| Step: 10
Training loss: 1.044837236404419
Validation loss: 2.2010218302408853

Epoch: 5| Step: 11
Training loss: 2.1564273834228516
Validation loss: 2.1967689295609794

Epoch: 454| Step: 0
Training loss: 0.8409433364868164
Validation loss: 2.1879878640174866

Epoch: 5| Step: 1
Training loss: 1.0403416156768799
Validation loss: 2.176174153884252

Epoch: 5| Step: 2
Training loss: 1.1370224952697754
Validation loss: 2.243998557329178

Epoch: 5| Step: 3
Training loss: 1.4091980457305908
Validation loss: 2.1598934630552926

Epoch: 5| Step: 4
Training loss: 1.139946460723877
Validation loss: 2.1916834513346353

Epoch: 5| Step: 5
Training loss: 1.1330246925354004
Validation loss: 2.224656601746877

Epoch: 5| Step: 6
Training loss: 0.9038235545158386
Validation loss: 2.1821157882610955

Epoch: 5| Step: 7
Training loss: 1.1081323623657227
Validation loss: 2.2035606304804483

Epoch: 5| Step: 8
Training loss: 0.6979919672012329
Validation loss: 2.234800269206365

Epoch: 5| Step: 9
Training loss: 1.0679528713226318
Validation loss: 2.2164771358172097

Epoch: 5| Step: 10
Training loss: 1.4299863576889038
Validation loss: 2.197728211681048

Epoch: 5| Step: 11
Training loss: 0.6219462752342224
Validation loss: 2.1994471102952957

Epoch: 455| Step: 0
Training loss: 1.0066243410110474
Validation loss: 2.219242145617803

Epoch: 5| Step: 1
Training loss: 0.7550563812255859
Validation loss: 2.1621124098698297

Epoch: 5| Step: 2
Training loss: 0.7790064811706543
Validation loss: 2.180822099248568

Epoch: 5| Step: 3
Training loss: 0.9189403653144836
Validation loss: 2.2138975858688354

Epoch: 5| Step: 4
Training loss: 1.126882553100586
Validation loss: 2.1683404048283896

Epoch: 5| Step: 5
Training loss: 1.358349323272705
Validation loss: 2.184223175048828

Epoch: 5| Step: 6
Training loss: 1.4487206935882568
Validation loss: 2.1719444493452706

Epoch: 5| Step: 7
Training loss: 1.617367148399353
Validation loss: 2.1531503399213157

Epoch: 5| Step: 8
Training loss: 1.7173442840576172
Validation loss: 2.127764195203781

Epoch: 5| Step: 9
Training loss: 0.65137779712677
Validation loss: 2.102819482485453

Epoch: 5| Step: 10
Training loss: 0.8788143396377563
Validation loss: 2.1386902878681817

Epoch: 5| Step: 11
Training loss: 0.9150400161743164
Validation loss: 2.0872960090637207

Epoch: 456| Step: 0
Training loss: 0.9796165227890015
Validation loss: 2.187586302558581

Epoch: 5| Step: 1
Training loss: 1.3690704107284546
Validation loss: 2.1264047622680664

Epoch: 5| Step: 2
Training loss: 0.9495201110839844
Validation loss: 2.1339423259099326

Epoch: 5| Step: 3
Training loss: 1.0326224565505981
Validation loss: 2.145816038052241

Epoch: 5| Step: 4
Training loss: 0.7174761295318604
Validation loss: 2.12095282971859

Epoch: 5| Step: 5
Training loss: 1.2193785905838013
Validation loss: 2.110306978225708

Epoch: 5| Step: 6
Training loss: 0.6769260168075562
Validation loss: 2.0935381849606833

Epoch: 5| Step: 7
Training loss: 0.9526453018188477
Validation loss: 2.1355070024728775

Epoch: 5| Step: 8
Training loss: 1.3867146968841553
Validation loss: 2.1722112794717154

Epoch: 5| Step: 9
Training loss: 2.0620322227478027
Validation loss: 2.1465359032154083

Epoch: 5| Step: 10
Training loss: 0.7545145750045776
Validation loss: 2.196478138367335

Epoch: 5| Step: 11
Training loss: 0.5077865123748779
Validation loss: 2.1968383193016052

Epoch: 457| Step: 0
Training loss: 1.2719414234161377
Validation loss: 2.208022659023603

Epoch: 5| Step: 1
Training loss: 1.0052285194396973
Validation loss: 2.219026024142901

Epoch: 5| Step: 2
Training loss: 1.1152575016021729
Validation loss: 2.250990569591522

Epoch: 5| Step: 3
Training loss: 1.06734299659729
Validation loss: 2.205303192138672

Epoch: 5| Step: 4
Training loss: 0.7825812697410583
Validation loss: 2.201098307967186

Epoch: 5| Step: 5
Training loss: 1.0536601543426514
Validation loss: 2.2443439761797586

Epoch: 5| Step: 6
Training loss: 1.3586556911468506
Validation loss: 2.2314517895380654

Epoch: 5| Step: 7
Training loss: 0.7828665971755981
Validation loss: 2.176535134514173

Epoch: 5| Step: 8
Training loss: 1.2236180305480957
Validation loss: 2.221368730068207

Epoch: 5| Step: 9
Training loss: 0.9074283838272095
Validation loss: 2.1703441540400186

Epoch: 5| Step: 10
Training loss: 0.6955286264419556
Validation loss: 2.163785328467687

Epoch: 5| Step: 11
Training loss: 2.5900039672851562
Validation loss: 2.1490196883678436

Epoch: 458| Step: 0
Training loss: 1.1670198440551758
Validation loss: 2.130457987387975

Epoch: 5| Step: 1
Training loss: 1.1257432699203491
Validation loss: 2.1392920364936194

Epoch: 5| Step: 2
Training loss: 1.4946218729019165
Validation loss: 2.1406399259964624

Epoch: 5| Step: 3
Training loss: 1.0541621446609497
Validation loss: 2.108503580093384

Epoch: 5| Step: 4
Training loss: 0.8757575154304504
Validation loss: 2.13260555267334

Epoch: 5| Step: 5
Training loss: 0.7547736167907715
Validation loss: 2.0612985342741013

Epoch: 5| Step: 6
Training loss: 0.9273598790168762
Validation loss: 2.0680565536022186

Epoch: 5| Step: 7
Training loss: 1.1676089763641357
Validation loss: 2.0752535363038382

Epoch: 5| Step: 8
Training loss: 1.3420395851135254
Validation loss: 2.080876628557841

Epoch: 5| Step: 9
Training loss: 0.6770961880683899
Validation loss: 2.054258093237877

Epoch: 5| Step: 10
Training loss: 1.0917562246322632
Validation loss: 2.0957872718572617

Epoch: 5| Step: 11
Training loss: 0.5901278257369995
Validation loss: 2.0943547189235687

Epoch: 459| Step: 0
Training loss: 0.9117075800895691
Validation loss: 2.145390048623085

Epoch: 5| Step: 1
Training loss: 0.7255433201789856
Validation loss: 2.1665461560090384

Epoch: 5| Step: 2
Training loss: 0.7504598498344421
Validation loss: 2.194862643877665

Epoch: 5| Step: 3
Training loss: 0.8427730798721313
Validation loss: 2.1660525550444922

Epoch: 5| Step: 4
Training loss: 1.1930862665176392
Validation loss: 2.2262413452068963

Epoch: 5| Step: 5
Training loss: 1.2295923233032227
Validation loss: 2.17995656033357

Epoch: 5| Step: 6
Training loss: 1.2350311279296875
Validation loss: 2.225180834531784

Epoch: 5| Step: 7
Training loss: 1.0269144773483276
Validation loss: 2.2315398255983987

Epoch: 5| Step: 8
Training loss: 1.7248239517211914
Validation loss: 2.193573534488678

Epoch: 5| Step: 9
Training loss: 0.9351238012313843
Validation loss: 2.220132529735565

Epoch: 5| Step: 10
Training loss: 0.8064010739326477
Validation loss: 2.1808863629897437

Epoch: 5| Step: 11
Training loss: 0.566291093826294
Validation loss: 2.214489152034124

Epoch: 460| Step: 0
Training loss: 1.158893346786499
Validation loss: 2.199507012963295

Epoch: 5| Step: 1
Training loss: 0.6047567129135132
Validation loss: 2.1745443493127823

Epoch: 5| Step: 2
Training loss: 0.6810657382011414
Validation loss: 2.181228776772817

Epoch: 5| Step: 3
Training loss: 1.419548511505127
Validation loss: 2.1545235564311347

Epoch: 5| Step: 4
Training loss: 0.7691424489021301
Validation loss: 2.172983944416046

Epoch: 5| Step: 5
Training loss: 0.8574636578559875
Validation loss: 2.210462565223376

Epoch: 5| Step: 6
Training loss: 1.0564810037612915
Validation loss: 2.1526569426059723

Epoch: 5| Step: 7
Training loss: 1.465364694595337
Validation loss: 2.200491815805435

Epoch: 5| Step: 8
Training loss: 1.0815577507019043
Validation loss: 2.206986496845881

Epoch: 5| Step: 9
Training loss: 1.3333990573883057
Validation loss: 2.2291036446889243

Epoch: 5| Step: 10
Training loss: 0.9628421664237976
Validation loss: 2.1678262452284494

Epoch: 5| Step: 11
Training loss: 0.1707611083984375
Validation loss: 2.1654124408960342

Epoch: 461| Step: 0
Training loss: 0.9927714467048645
Validation loss: 2.1768873234589896

Epoch: 5| Step: 1
Training loss: 1.036100149154663
Validation loss: 2.1403589298327765

Epoch: 5| Step: 2
Training loss: 1.3946433067321777
Validation loss: 2.1211375097433725

Epoch: 5| Step: 3
Training loss: 1.023476004600525
Validation loss: 2.1318525274594626

Epoch: 5| Step: 4
Training loss: 0.9959805607795715
Validation loss: 2.101254627108574

Epoch: 5| Step: 5
Training loss: 1.2158281803131104
Validation loss: 2.112152467171351

Epoch: 5| Step: 6
Training loss: 0.6898735761642456
Validation loss: 2.1167136828104653

Epoch: 5| Step: 7
Training loss: 1.2552706003189087
Validation loss: 2.1009067048629126

Epoch: 5| Step: 8
Training loss: 0.8250364065170288
Validation loss: 2.0952682346105576

Epoch: 5| Step: 9
Training loss: 1.0672225952148438
Validation loss: 2.1172184695800147

Epoch: 5| Step: 10
Training loss: 1.4935377836227417
Validation loss: 2.131084789832433

Epoch: 5| Step: 11
Training loss: 0.6085731983184814
Validation loss: 2.1184292435646057

Epoch: 462| Step: 0
Training loss: 0.7599059343338013
Validation loss: 2.1611839632193246

Epoch: 5| Step: 1
Training loss: 1.5240912437438965
Validation loss: 2.160018190741539

Epoch: 5| Step: 2
Training loss: 1.1416866779327393
Validation loss: 2.157299588123957

Epoch: 5| Step: 3
Training loss: 1.3369629383087158
Validation loss: 2.152601972222328

Epoch: 5| Step: 4
Training loss: 0.9672855138778687
Validation loss: 2.1744198898474374

Epoch: 5| Step: 5
Training loss: 0.7607700228691101
Validation loss: 2.1752771933873496

Epoch: 5| Step: 6
Training loss: 1.9300658702850342
Validation loss: 2.2188021391630173

Epoch: 5| Step: 7
Training loss: 0.9040240049362183
Validation loss: 2.1861205647389093

Epoch: 5| Step: 8
Training loss: 0.8482652902603149
Validation loss: 2.1727110346158347

Epoch: 5| Step: 9
Training loss: 0.7228648662567139
Validation loss: 2.188169022401174

Epoch: 5| Step: 10
Training loss: 0.9521023035049438
Validation loss: 2.184609899918238

Epoch: 5| Step: 11
Training loss: 0.5563784837722778
Validation loss: 2.171231190363566

Epoch: 463| Step: 0
Training loss: 1.1494511365890503
Validation loss: 2.161287268002828

Epoch: 5| Step: 1
Training loss: 0.9334456324577332
Validation loss: 2.1847311357657113

Epoch: 5| Step: 2
Training loss: 1.1763973236083984
Validation loss: 2.217788497606913

Epoch: 5| Step: 3
Training loss: 0.9737443923950195
Validation loss: 2.1450537790854773

Epoch: 5| Step: 4
Training loss: 1.1111948490142822
Validation loss: 2.1144472559293113

Epoch: 5| Step: 5
Training loss: 0.8600757718086243
Validation loss: 2.1372656722863517

Epoch: 5| Step: 6
Training loss: 1.208167314529419
Validation loss: 2.1580765644709268

Epoch: 5| Step: 7
Training loss: 1.0344120264053345
Validation loss: 2.125919113556544

Epoch: 5| Step: 8
Training loss: 1.2203620672225952
Validation loss: 2.1339764992396035

Epoch: 5| Step: 9
Training loss: 0.8122226595878601
Validation loss: 2.1016869097948074

Epoch: 5| Step: 10
Training loss: 1.1103713512420654
Validation loss: 2.1423849811156592

Epoch: 5| Step: 11
Training loss: 0.4599754810333252
Validation loss: 2.071648418903351

Epoch: 464| Step: 0
Training loss: 1.1039302349090576
Validation loss: 2.137710710366567

Epoch: 5| Step: 1
Training loss: 1.123483657836914
Validation loss: 2.142666826645533

Epoch: 5| Step: 2
Training loss: 0.9738556742668152
Validation loss: 2.1590334375699363

Epoch: 5| Step: 3
Training loss: 0.8970807790756226
Validation loss: 2.1777250518401465

Epoch: 5| Step: 4
Training loss: 0.7067035436630249
Validation loss: 2.132525324821472

Epoch: 5| Step: 5
Training loss: 1.1973445415496826
Validation loss: 2.177492300669352

Epoch: 5| Step: 6
Training loss: 1.0178745985031128
Validation loss: 2.161317840218544

Epoch: 5| Step: 7
Training loss: 1.1967220306396484
Validation loss: 2.172879214088122

Epoch: 5| Step: 8
Training loss: 0.8953788876533508
Validation loss: 2.2026712199052176

Epoch: 5| Step: 9
Training loss: 0.8579496145248413
Validation loss: 2.1754072109858194

Epoch: 5| Step: 10
Training loss: 0.6142036318778992
Validation loss: 2.201013962427775

Epoch: 5| Step: 11
Training loss: 1.8373057842254639
Validation loss: 2.2044221262137094

Epoch: 465| Step: 0
Training loss: 0.7754615545272827
Validation loss: 2.1738267044226327

Epoch: 5| Step: 1
Training loss: 1.2428405284881592
Validation loss: 2.14662034312884

Epoch: 5| Step: 2
Training loss: 0.9176070094108582
Validation loss: 2.179152190685272

Epoch: 5| Step: 3
Training loss: 1.5744662284851074
Validation loss: 2.162238210439682

Epoch: 5| Step: 4
Training loss: 1.2503430843353271
Validation loss: 2.191758915781975

Epoch: 5| Step: 5
Training loss: 0.63862144947052
Validation loss: 2.1767903765042624

Epoch: 5| Step: 6
Training loss: 0.5913384556770325
Validation loss: 2.202736109495163

Epoch: 5| Step: 7
Training loss: 0.746192991733551
Validation loss: 2.2083640545606613

Epoch: 5| Step: 8
Training loss: 1.3493478298187256
Validation loss: 2.2172239124774933

Epoch: 5| Step: 9
Training loss: 0.9830158352851868
Validation loss: 2.2091990311940513

Epoch: 5| Step: 10
Training loss: 0.9167835116386414
Validation loss: 2.197388087709745

Epoch: 5| Step: 11
Training loss: 1.0514769554138184
Validation loss: 2.203364526232084

Epoch: 466| Step: 0
Training loss: 1.3609002828598022
Validation loss: 2.1828126857678094

Epoch: 5| Step: 1
Training loss: 0.7021797895431519
Validation loss: 2.1807056665420532

Epoch: 5| Step: 2
Training loss: 0.8306112289428711
Validation loss: 2.162594551841418

Epoch: 5| Step: 3
Training loss: 0.622495174407959
Validation loss: 2.1673021614551544

Epoch: 5| Step: 4
Training loss: 1.3643302917480469
Validation loss: 2.1423000593980155

Epoch: 5| Step: 5
Training loss: 1.0466352701187134
Validation loss: 2.202415535847346

Epoch: 5| Step: 6
Training loss: 1.5960617065429688
Validation loss: 2.1509191542863846

Epoch: 5| Step: 7
Training loss: 1.1881510019302368
Validation loss: 2.1790438443422318

Epoch: 5| Step: 8
Training loss: 0.894989013671875
Validation loss: 2.1941625475883484

Epoch: 5| Step: 9
Training loss: 0.9383861422538757
Validation loss: 2.147743205229441

Epoch: 5| Step: 10
Training loss: 1.3817492723464966
Validation loss: 2.145341614882151

Epoch: 5| Step: 11
Training loss: 0.5414853096008301
Validation loss: 2.1254315773646035

Epoch: 467| Step: 0
Training loss: 1.184853434562683
Validation loss: 2.100794568657875

Epoch: 5| Step: 1
Training loss: 1.3205032348632812
Validation loss: 2.067417030533155

Epoch: 5| Step: 2
Training loss: 0.9546236991882324
Validation loss: 2.047105257709821

Epoch: 5| Step: 3
Training loss: 1.1847378015518188
Validation loss: 2.0682013481855392

Epoch: 5| Step: 4
Training loss: 0.9403417706489563
Validation loss: 2.113704259196917

Epoch: 5| Step: 5
Training loss: 0.912082314491272
Validation loss: 2.1003161668777466

Epoch: 5| Step: 6
Training loss: 0.6282193064689636
Validation loss: 2.1180435170729957

Epoch: 5| Step: 7
Training loss: 0.7344087362289429
Validation loss: 2.1167859186728797

Epoch: 5| Step: 8
Training loss: 0.7276055216789246
Validation loss: 2.126330703496933

Epoch: 5| Step: 9
Training loss: 1.5498430728912354
Validation loss: 2.1577666054169335

Epoch: 5| Step: 10
Training loss: 1.0017664432525635
Validation loss: 2.161536306142807

Epoch: 5| Step: 11
Training loss: 2.3900504112243652
Validation loss: 2.141007939974467

Epoch: 468| Step: 0
Training loss: 1.1223480701446533
Validation loss: 2.1950824360052743

Epoch: 5| Step: 1
Training loss: 1.0949748754501343
Validation loss: 2.169063230355581

Epoch: 5| Step: 2
Training loss: 0.6616603136062622
Validation loss: 2.1229714353879294

Epoch: 5| Step: 3
Training loss: 1.0996373891830444
Validation loss: 2.1154886136452355

Epoch: 5| Step: 4
Training loss: 1.2570135593414307
Validation loss: 2.1410016467173896

Epoch: 5| Step: 5
Training loss: 1.1321017742156982
Validation loss: 2.1401355614264808

Epoch: 5| Step: 6
Training loss: 0.8373888731002808
Validation loss: 2.130516524116198

Epoch: 5| Step: 7
Training loss: 1.1428576707839966
Validation loss: 2.1478287428617477

Epoch: 5| Step: 8
Training loss: 1.2164955139160156
Validation loss: 2.1259250740210214

Epoch: 5| Step: 9
Training loss: 0.7062690854072571
Validation loss: 2.1665452967087426

Epoch: 5| Step: 10
Training loss: 0.9111571311950684
Validation loss: 2.182077646255493

Epoch: 5| Step: 11
Training loss: 0.6078733801841736
Validation loss: 2.1525093962748847

Epoch: 469| Step: 0
Training loss: 0.5877140164375305
Validation loss: 2.1698272079229355

Epoch: 5| Step: 1
Training loss: 0.8016873598098755
Validation loss: 2.1910771975914636

Epoch: 5| Step: 2
Training loss: 0.9539403915405273
Validation loss: 2.184544781843821

Epoch: 5| Step: 3
Training loss: 0.8036378026008606
Validation loss: 2.1777384330828986

Epoch: 5| Step: 4
Training loss: 0.5715447664260864
Validation loss: 2.2005585630734763

Epoch: 5| Step: 5
Training loss: 0.9109307527542114
Validation loss: 2.1901325434446335

Epoch: 5| Step: 6
Training loss: 1.170122742652893
Validation loss: 2.1457846959431968

Epoch: 5| Step: 7
Training loss: 0.7454735040664673
Validation loss: 2.170631542801857

Epoch: 5| Step: 8
Training loss: 1.7207361459732056
Validation loss: 2.2029596666495004

Epoch: 5| Step: 9
Training loss: 1.2437255382537842
Validation loss: 2.1515954236189523

Epoch: 5| Step: 10
Training loss: 1.0672463178634644
Validation loss: 2.1626635243495307

Epoch: 5| Step: 11
Training loss: 1.5207536220550537
Validation loss: 2.133561929066976

Epoch: 470| Step: 0
Training loss: 0.7998443841934204
Validation loss: 2.124736169974009

Epoch: 5| Step: 1
Training loss: 0.904151439666748
Validation loss: 2.119524066646894

Epoch: 5| Step: 2
Training loss: 1.256835699081421
Validation loss: 2.1376581390698752

Epoch: 5| Step: 3
Training loss: 1.4854097366333008
Validation loss: 2.1367561320463815

Epoch: 5| Step: 4
Training loss: 0.9421926736831665
Validation loss: 2.1358385930458703

Epoch: 5| Step: 5
Training loss: 1.0318416357040405
Validation loss: 2.131342882911364

Epoch: 5| Step: 6
Training loss: 1.2626304626464844
Validation loss: 2.1083396077156067

Epoch: 5| Step: 7
Training loss: 0.802110493183136
Validation loss: 2.1320154120524726

Epoch: 5| Step: 8
Training loss: 0.9123722910881042
Validation loss: 2.1524244596560798

Epoch: 5| Step: 9
Training loss: 0.6968362927436829
Validation loss: 2.1362277617057166

Epoch: 5| Step: 10
Training loss: 0.7053357362747192
Validation loss: 2.1811173359553018

Epoch: 5| Step: 11
Training loss: 0.3114053010940552
Validation loss: 2.20322984457016

Epoch: 471| Step: 0
Training loss: 1.0333975553512573
Validation loss: 2.1832553346951804

Epoch: 5| Step: 1
Training loss: 0.45471248030662537
Validation loss: 2.1652841567993164

Epoch: 5| Step: 2
Training loss: 0.9596241116523743
Validation loss: 2.173841362198194

Epoch: 5| Step: 3
Training loss: 0.6602133512496948
Validation loss: 2.1789165238539376

Epoch: 5| Step: 4
Training loss: 0.8414185643196106
Validation loss: 2.1805640310049057

Epoch: 5| Step: 5
Training loss: 1.386054277420044
Validation loss: 2.1677363018194833

Epoch: 5| Step: 6
Training loss: 0.967107892036438
Validation loss: 2.2116832037766776

Epoch: 5| Step: 7
Training loss: 0.9054768681526184
Validation loss: 2.2061869353055954

Epoch: 5| Step: 8
Training loss: 1.4715044498443604
Validation loss: 2.16662035882473

Epoch: 5| Step: 9
Training loss: 1.0146551132202148
Validation loss: 2.1832673648993173

Epoch: 5| Step: 10
Training loss: 1.002373456954956
Validation loss: 2.1546562115351358

Epoch: 5| Step: 11
Training loss: 0.5938518047332764
Validation loss: 2.1364797254403434

Epoch: 472| Step: 0
Training loss: 1.1788172721862793
Validation loss: 2.1253381272157035

Epoch: 5| Step: 1
Training loss: 0.8760050535202026
Validation loss: 2.164863030115763

Epoch: 5| Step: 2
Training loss: 1.4435465335845947
Validation loss: 2.112528309226036

Epoch: 5| Step: 3
Training loss: 0.9324892163276672
Validation loss: 2.1317299753427505

Epoch: 5| Step: 4
Training loss: 1.106062650680542
Validation loss: 2.1448271572589874

Epoch: 5| Step: 5
Training loss: 0.590481162071228
Validation loss: 2.0876613656679788

Epoch: 5| Step: 6
Training loss: 0.55846107006073
Validation loss: 2.088473071654638

Epoch: 5| Step: 7
Training loss: 0.7912362217903137
Validation loss: 2.151856159170469

Epoch: 5| Step: 8
Training loss: 0.7688182592391968
Validation loss: 2.1367328763008118

Epoch: 5| Step: 9
Training loss: 0.9220263361930847
Validation loss: 2.1474365244309106

Epoch: 5| Step: 10
Training loss: 1.2590107917785645
Validation loss: 2.1675222714742026

Epoch: 5| Step: 11
Training loss: 1.9350882768630981
Validation loss: 2.169247716665268

Epoch: 473| Step: 0
Training loss: 1.0091216564178467
Validation loss: 2.2186370491981506

Epoch: 5| Step: 1
Training loss: 0.628332257270813
Validation loss: 2.165379971265793

Epoch: 5| Step: 2
Training loss: 0.4972592294216156
Validation loss: 2.1867761810620627

Epoch: 5| Step: 3
Training loss: 1.0925582647323608
Validation loss: 2.167725538214048

Epoch: 5| Step: 4
Training loss: 1.003515362739563
Validation loss: 2.1574032257000604

Epoch: 5| Step: 5
Training loss: 1.1493852138519287
Validation loss: 2.1333637287219367

Epoch: 5| Step: 6
Training loss: 1.4349020719528198
Validation loss: 2.1620401591062546

Epoch: 5| Step: 7
Training loss: 1.147312879562378
Validation loss: 2.1545996169249215

Epoch: 5| Step: 8
Training loss: 1.0139491558074951
Validation loss: 2.152933736642202

Epoch: 5| Step: 9
Training loss: 0.5931686162948608
Validation loss: 2.1742238650719323

Epoch: 5| Step: 10
Training loss: 0.8618707656860352
Validation loss: 2.1802487721045813

Epoch: 5| Step: 11
Training loss: 1.349928617477417
Validation loss: 2.1754675010840097

Epoch: 474| Step: 0
Training loss: 0.9218384623527527
Validation loss: 2.1776404778162637

Epoch: 5| Step: 1
Training loss: 1.48624587059021
Validation loss: 2.1721566865841546

Epoch: 5| Step: 2
Training loss: 1.0476465225219727
Validation loss: 2.1661915431420007

Epoch: 5| Step: 3
Training loss: 1.240204095840454
Validation loss: 2.1505886067946753

Epoch: 5| Step: 4
Training loss: 0.6047571897506714
Validation loss: 2.156399890780449

Epoch: 5| Step: 5
Training loss: 1.2714896202087402
Validation loss: 2.152385657032331

Epoch: 5| Step: 6
Training loss: 0.9266713857650757
Validation loss: 2.1571884701649346

Epoch: 5| Step: 7
Training loss: 0.9329416155815125
Validation loss: 2.1190280665953956

Epoch: 5| Step: 8
Training loss: 0.9489862322807312
Validation loss: 2.138008256753286

Epoch: 5| Step: 9
Training loss: 1.3142406940460205
Validation loss: 2.167701095342636

Epoch: 5| Step: 10
Training loss: 0.804400622844696
Validation loss: 2.1540024280548096

Epoch: 5| Step: 11
Training loss: 0.40310895442962646
Validation loss: 2.2137677470842996

Epoch: 475| Step: 0
Training loss: 1.6695201396942139
Validation loss: 2.180851106842359

Epoch: 5| Step: 1
Training loss: 1.321413278579712
Validation loss: 2.1770027776559195

Epoch: 5| Step: 2
Training loss: 1.057119607925415
Validation loss: 2.188572585582733

Epoch: 5| Step: 3
Training loss: 1.0836822986602783
Validation loss: 2.192384327451388

Epoch: 5| Step: 4
Training loss: 1.1785075664520264
Validation loss: 2.1563874880472818

Epoch: 5| Step: 5
Training loss: 0.7119573354721069
Validation loss: 2.1212267180283866

Epoch: 5| Step: 6
Training loss: 0.5347473621368408
Validation loss: 2.0916882356007895

Epoch: 5| Step: 7
Training loss: 1.1363532543182373
Validation loss: 2.078661705056826

Epoch: 5| Step: 8
Training loss: 1.2426716089248657
Validation loss: 2.1066005180279412

Epoch: 5| Step: 9
Training loss: 1.003466248512268
Validation loss: 2.080089141925176

Epoch: 5| Step: 10
Training loss: 0.994334876537323
Validation loss: 2.0713145385185876

Epoch: 5| Step: 11
Training loss: 1.0559360980987549
Validation loss: 2.103373870253563

Epoch: 476| Step: 0
Training loss: 0.9013740420341492
Validation loss: 2.074617177248001

Epoch: 5| Step: 1
Training loss: 1.273249626159668
Validation loss: 2.0766343077023826

Epoch: 5| Step: 2
Training loss: 0.647818922996521
Validation loss: 2.0970328549544015

Epoch: 5| Step: 3
Training loss: 0.5204187631607056
Validation loss: 2.0874866942564645

Epoch: 5| Step: 4
Training loss: 1.4159724712371826
Validation loss: 2.0953377236922583

Epoch: 5| Step: 5
Training loss: 1.3948932886123657
Validation loss: 2.087996189792951

Epoch: 5| Step: 6
Training loss: 0.6014221906661987
Validation loss: 2.086597273747126

Epoch: 5| Step: 7
Training loss: 1.030564785003662
Validation loss: 2.0836216509342194

Epoch: 5| Step: 8
Training loss: 1.1162408590316772
Validation loss: 2.0580284198125205

Epoch: 5| Step: 9
Training loss: 0.641417384147644
Validation loss: 2.1003770480553308

Epoch: 5| Step: 10
Training loss: 0.8923584818840027
Validation loss: 2.1213476856549582

Epoch: 5| Step: 11
Training loss: 0.6909229755401611
Validation loss: 2.074975381294886

Epoch: 477| Step: 0
Training loss: 1.4767487049102783
Validation loss: 2.111472229162852

Epoch: 5| Step: 1
Training loss: 0.681374192237854
Validation loss: 2.1182827999194465

Epoch: 5| Step: 2
Training loss: 0.7977460622787476
Validation loss: 2.1633960704008737

Epoch: 5| Step: 3
Training loss: 0.8260170817375183
Validation loss: 2.1342920064926147

Epoch: 5| Step: 4
Training loss: 1.721314787864685
Validation loss: 2.142195557554563

Epoch: 5| Step: 5
Training loss: 1.0322000980377197
Validation loss: 2.180093541741371

Epoch: 5| Step: 6
Training loss: 0.6903233528137207
Validation loss: 2.1696550846099854

Epoch: 5| Step: 7
Training loss: 1.1412734985351562
Validation loss: 2.1770660181840262

Epoch: 5| Step: 8
Training loss: 0.8821557760238647
Validation loss: 2.17411174873511

Epoch: 5| Step: 9
Training loss: 0.6087149381637573
Validation loss: 2.1599792391061783

Epoch: 5| Step: 10
Training loss: 0.6451951265335083
Validation loss: 2.1596760600805283

Epoch: 5| Step: 11
Training loss: 0.2950127124786377
Validation loss: 2.1919631510972977

Epoch: 478| Step: 0
Training loss: 0.748887300491333
Validation loss: 2.2233389765024185

Epoch: 5| Step: 1
Training loss: 1.1356337070465088
Validation loss: 2.2128838499387107

Epoch: 5| Step: 2
Training loss: 1.4959522485733032
Validation loss: 2.240940590699514

Epoch: 5| Step: 3
Training loss: 1.6875663995742798
Validation loss: 2.2288615355889

Epoch: 5| Step: 4
Training loss: 0.5802142024040222
Validation loss: 2.203439717491468

Epoch: 5| Step: 5
Training loss: 1.2841150760650635
Validation loss: 2.1628150840600333

Epoch: 5| Step: 6
Training loss: 0.7968759536743164
Validation loss: 2.162818064292272

Epoch: 5| Step: 7
Training loss: 0.8632245063781738
Validation loss: 2.1252392381429672

Epoch: 5| Step: 8
Training loss: 1.2728077173233032
Validation loss: 2.1738436420758567

Epoch: 5| Step: 9
Training loss: 1.093929648399353
Validation loss: 2.1552372376124063

Epoch: 5| Step: 10
Training loss: 0.708767294883728
Validation loss: 2.151954064766566

Epoch: 5| Step: 11
Training loss: 0.5679320096969604
Validation loss: 2.2369645039240518

Epoch: 479| Step: 0
Training loss: 0.8316434025764465
Validation loss: 2.159160162011782

Epoch: 5| Step: 1
Training loss: 0.8162635564804077
Validation loss: 2.213210880756378

Epoch: 5| Step: 2
Training loss: 1.5944952964782715
Validation loss: 2.190505931774775

Epoch: 5| Step: 3
Training loss: 0.8234769701957703
Validation loss: 2.20104510585467

Epoch: 5| Step: 4
Training loss: 1.1008447408676147
Validation loss: 2.18162177503109

Epoch: 5| Step: 5
Training loss: 1.2243940830230713
Validation loss: 2.153935174147288

Epoch: 5| Step: 6
Training loss: 1.1129133701324463
Validation loss: 2.1488297631343207

Epoch: 5| Step: 7
Training loss: 0.5530984997749329
Validation loss: 2.1502935737371445

Epoch: 5| Step: 8
Training loss: 0.8242597579956055
Validation loss: 2.178278530637423

Epoch: 5| Step: 9
Training loss: 0.9777339696884155
Validation loss: 2.180974597732226

Epoch: 5| Step: 10
Training loss: 0.8267228007316589
Validation loss: 2.1581628968318305

Epoch: 5| Step: 11
Training loss: 0.7629997730255127
Validation loss: 2.165364017089208

Epoch: 480| Step: 0
Training loss: 0.7733668088912964
Validation loss: 2.168275753657023

Epoch: 5| Step: 1
Training loss: 1.1019151210784912
Validation loss: 2.191169520219167

Epoch: 5| Step: 2
Training loss: 0.7981935739517212
Validation loss: 2.1461341828107834

Epoch: 5| Step: 3
Training loss: 1.0450979471206665
Validation loss: 2.1255249828100204

Epoch: 5| Step: 4
Training loss: 0.6698092222213745
Validation loss: 2.1566711316506066

Epoch: 5| Step: 5
Training loss: 1.4174058437347412
Validation loss: 2.1427206794420877

Epoch: 5| Step: 6
Training loss: 0.9615495800971985
Validation loss: 2.092555825908979

Epoch: 5| Step: 7
Training loss: 0.8053557276725769
Validation loss: 2.1223139266173043

Epoch: 5| Step: 8
Training loss: 1.0029932260513306
Validation loss: 2.1024439185857773

Epoch: 5| Step: 9
Training loss: 1.0966535806655884
Validation loss: 2.1255254546801248

Epoch: 5| Step: 10
Training loss: 0.8982976675033569
Validation loss: 2.1146203527847924

Epoch: 5| Step: 11
Training loss: 1.5858134031295776
Validation loss: 2.1138202448685965

Epoch: 481| Step: 0
Training loss: 1.0702991485595703
Validation loss: 2.1460475822289786

Epoch: 5| Step: 1
Training loss: 1.0495102405548096
Validation loss: 2.1405428846677146

Epoch: 5| Step: 2
Training loss: 1.5519310235977173
Validation loss: 2.135961264371872

Epoch: 5| Step: 3
Training loss: 0.7616696357727051
Validation loss: 2.1534299552440643

Epoch: 5| Step: 4
Training loss: 1.3569592237472534
Validation loss: 2.196258162458738

Epoch: 5| Step: 5
Training loss: 0.5922443866729736
Validation loss: 2.169983451565107

Epoch: 5| Step: 6
Training loss: 0.6603986024856567
Validation loss: 2.1602203945318856

Epoch: 5| Step: 7
Training loss: 0.8430219888687134
Validation loss: 2.1160063495238624

Epoch: 5| Step: 8
Training loss: 0.7193801999092102
Validation loss: 2.1888714532057443

Epoch: 5| Step: 9
Training loss: 1.1271803379058838
Validation loss: 2.1995447476704917

Epoch: 5| Step: 10
Training loss: 0.94329833984375
Validation loss: 2.1628209998210273

Epoch: 5| Step: 11
Training loss: 0.517363965511322
Validation loss: 2.170016805330912

Epoch: 482| Step: 0
Training loss: 0.746517539024353
Validation loss: 2.151356890797615

Epoch: 5| Step: 1
Training loss: 0.6889790296554565
Validation loss: 2.162484884262085

Epoch: 5| Step: 2
Training loss: 1.2385776042938232
Validation loss: 2.1643387377262115

Epoch: 5| Step: 3
Training loss: 0.8901851773262024
Validation loss: 2.155072679122289

Epoch: 5| Step: 4
Training loss: 1.0711075067520142
Validation loss: 2.1233181953430176

Epoch: 5| Step: 5
Training loss: 0.7850991487503052
Validation loss: 2.1639305104811988

Epoch: 5| Step: 6
Training loss: 0.878038763999939
Validation loss: 2.1706805874904

Epoch: 5| Step: 7
Training loss: 0.7902008295059204
Validation loss: 2.162300705909729

Epoch: 5| Step: 8
Training loss: 0.9534805417060852
Validation loss: 2.1969384054342904

Epoch: 5| Step: 9
Training loss: 1.2148085832595825
Validation loss: 2.1768898516893387

Epoch: 5| Step: 10
Training loss: 0.8645550012588501
Validation loss: 2.184986039996147

Epoch: 5| Step: 11
Training loss: 0.4722996950149536
Validation loss: 2.17245444158713

Epoch: 483| Step: 0
Training loss: 1.2245889902114868
Validation loss: 2.1295337080955505

Epoch: 5| Step: 1
Training loss: 1.060675859451294
Validation loss: 2.13060869773229

Epoch: 5| Step: 2
Training loss: 0.7164708375930786
Validation loss: 2.108390594522158

Epoch: 5| Step: 3
Training loss: 0.8927443623542786
Validation loss: 2.1469828486442566

Epoch: 5| Step: 4
Training loss: 0.7355034947395325
Validation loss: 2.157841593027115

Epoch: 5| Step: 5
Training loss: 0.7923474311828613
Validation loss: 2.1303058018287024

Epoch: 5| Step: 6
Training loss: 0.9192653894424438
Validation loss: 2.1268554031848907

Epoch: 5| Step: 7
Training loss: 0.6624993085861206
Validation loss: 2.1132783542076745

Epoch: 5| Step: 8
Training loss: 0.6854602694511414
Validation loss: 2.0551854769388833

Epoch: 5| Step: 9
Training loss: 0.7487270832061768
Validation loss: 2.078508049249649

Epoch: 5| Step: 10
Training loss: 1.160020112991333
Validation loss: 2.0900876025358834

Epoch: 5| Step: 11
Training loss: 2.1401329040527344
Validation loss: 2.1315307368834815

Epoch: 484| Step: 0
Training loss: 0.576076865196228
Validation loss: 2.1156409879525504

Epoch: 5| Step: 1
Training loss: 1.4746439456939697
Validation loss: 2.146126707394918

Epoch: 5| Step: 2
Training loss: 0.628547728061676
Validation loss: 2.142882560690244

Epoch: 5| Step: 3
Training loss: 0.6980832815170288
Validation loss: 2.1904393086830773

Epoch: 5| Step: 4
Training loss: 0.4403735101222992
Validation loss: 2.2306549151738486

Epoch: 5| Step: 5
Training loss: 1.2626731395721436
Validation loss: 2.178658738732338

Epoch: 5| Step: 6
Training loss: 1.0497289896011353
Validation loss: 2.215171759327253

Epoch: 5| Step: 7
Training loss: 0.8529450297355652
Validation loss: 2.254670331875483

Epoch: 5| Step: 8
Training loss: 1.3373992443084717
Validation loss: 2.1790115336577096

Epoch: 5| Step: 9
Training loss: 1.1657531261444092
Validation loss: 2.197098270058632

Epoch: 5| Step: 10
Training loss: 0.5243962407112122
Validation loss: 2.2285388112068176

Epoch: 5| Step: 11
Training loss: 0.9571938514709473
Validation loss: 2.202969491481781

Epoch: 485| Step: 0
Training loss: 0.665523886680603
Validation loss: 2.2051380624373755

Epoch: 5| Step: 1
Training loss: 1.277712106704712
Validation loss: 2.237725426753362

Epoch: 5| Step: 2
Training loss: 0.984521746635437
Validation loss: 2.1804279337326684

Epoch: 5| Step: 3
Training loss: 0.7189683318138123
Validation loss: 2.194032311439514

Epoch: 5| Step: 4
Training loss: 1.4599257707595825
Validation loss: 2.2029234766960144

Epoch: 5| Step: 5
Training loss: 1.0811669826507568
Validation loss: 2.2522654036680856

Epoch: 5| Step: 6
Training loss: 0.9744136929512024
Validation loss: 2.19614743689696

Epoch: 5| Step: 7
Training loss: 0.8357232809066772
Validation loss: 2.1802548368771872

Epoch: 5| Step: 8
Training loss: 1.0590187311172485
Validation loss: 2.169427494208018

Epoch: 5| Step: 9
Training loss: 0.8729346394538879
Validation loss: 2.200463126103083

Epoch: 5| Step: 10
Training loss: 0.8659930229187012
Validation loss: 2.18592103322347

Epoch: 5| Step: 11
Training loss: 0.8562735319137573
Validation loss: 2.188128039240837

Epoch: 486| Step: 0
Training loss: 0.8588418960571289
Validation loss: 2.1576426029205322

Epoch: 5| Step: 1
Training loss: 1.614187240600586
Validation loss: 2.204326942563057

Epoch: 5| Step: 2
Training loss: 0.9079305529594421
Validation loss: 2.145962586005529

Epoch: 5| Step: 3
Training loss: 0.8908876180648804
Validation loss: 2.154875655968984

Epoch: 5| Step: 4
Training loss: 0.9369605183601379
Validation loss: 2.1370727022488913

Epoch: 5| Step: 5
Training loss: 1.0370992422103882
Validation loss: 2.1580499708652496

Epoch: 5| Step: 6
Training loss: 0.7475430369377136
Validation loss: 2.155472606420517

Epoch: 5| Step: 7
Training loss: 0.7586868405342102
Validation loss: 2.1668061216672263

Epoch: 5| Step: 8
Training loss: 0.9125868082046509
Validation loss: 2.1572486609220505

Epoch: 5| Step: 9
Training loss: 0.9425090551376343
Validation loss: 2.1815051635106406

Epoch: 5| Step: 10
Training loss: 0.7710443735122681
Validation loss: 2.1580753922462463

Epoch: 5| Step: 11
Training loss: 0.4610830545425415
Validation loss: 2.137212092677752

Epoch: 487| Step: 0
Training loss: 0.5176051259040833
Validation loss: 2.1556444515784583

Epoch: 5| Step: 1
Training loss: 0.8783203959465027
Validation loss: 2.1377456883589425

Epoch: 5| Step: 2
Training loss: 1.07394278049469
Validation loss: 2.172462930281957

Epoch: 5| Step: 3
Training loss: 1.1741950511932373
Validation loss: 2.198636790116628

Epoch: 5| Step: 4
Training loss: 0.9363774061203003
Validation loss: 2.1429409434398017

Epoch: 5| Step: 5
Training loss: 1.5638493299484253
Validation loss: 2.2443582663933435

Epoch: 5| Step: 6
Training loss: 0.744983434677124
Validation loss: 2.2372868110736213

Epoch: 5| Step: 7
Training loss: 0.9663265347480774
Validation loss: 2.2280117173989615

Epoch: 5| Step: 8
Training loss: 0.7341517210006714
Validation loss: 2.173485671480497

Epoch: 5| Step: 9
Training loss: 0.6191699504852295
Validation loss: 2.201664169629415

Epoch: 5| Step: 10
Training loss: 0.8471970558166504
Validation loss: 2.1964794447024665

Epoch: 5| Step: 11
Training loss: 0.3922855854034424
Validation loss: 2.201004962126414

Epoch: 488| Step: 0
Training loss: 0.8349181413650513
Validation loss: 2.223276416460673

Epoch: 5| Step: 1
Training loss: 0.7660923004150391
Validation loss: 2.227423911293348

Epoch: 5| Step: 2
Training loss: 0.8208349347114563
Validation loss: 2.2037759025891623

Epoch: 5| Step: 3
Training loss: 0.6521807909011841
Validation loss: 2.14682308336099

Epoch: 5| Step: 4
Training loss: 1.0808722972869873
Validation loss: 2.1695611824591956

Epoch: 5| Step: 5
Training loss: 0.8361479043960571
Validation loss: 2.1466429382562637

Epoch: 5| Step: 6
Training loss: 1.3689260482788086
Validation loss: 2.142801051338514

Epoch: 5| Step: 7
Training loss: 0.5803678631782532
Validation loss: 2.118737757205963

Epoch: 5| Step: 8
Training loss: 0.8490959405899048
Validation loss: 2.1136281887690225

Epoch: 5| Step: 9
Training loss: 1.45757257938385
Validation loss: 2.120064144333204

Epoch: 5| Step: 10
Training loss: 0.6212748289108276
Validation loss: 2.1259094029664993

Epoch: 5| Step: 11
Training loss: 0.3635372519493103
Validation loss: 2.1539941926797233

Epoch: 489| Step: 0
Training loss: 0.5618165731430054
Validation loss: 2.156248172124227

Epoch: 5| Step: 1
Training loss: 0.8831464052200317
Validation loss: 2.180188382665316

Epoch: 5| Step: 2
Training loss: 0.6545664668083191
Validation loss: 2.220040594538053

Epoch: 5| Step: 3
Training loss: 1.3686048984527588
Validation loss: 2.1577743838230767

Epoch: 5| Step: 4
Training loss: 0.7503830194473267
Validation loss: 2.1992751558621726

Epoch: 5| Step: 5
Training loss: 1.2556917667388916
Validation loss: 2.1597011188666024

Epoch: 5| Step: 6
Training loss: 1.0527851581573486
Validation loss: 2.1825105597575507

Epoch: 5| Step: 7
Training loss: 0.8019694089889526
Validation loss: 2.1796291172504425

Epoch: 5| Step: 8
Training loss: 0.8095596432685852
Validation loss: 2.198779881000519

Epoch: 5| Step: 9
Training loss: 1.0316752195358276
Validation loss: 2.184687669078509

Epoch: 5| Step: 10
Training loss: 0.9874991178512573
Validation loss: 2.1951753944158554

Epoch: 5| Step: 11
Training loss: 1.1124966144561768
Validation loss: 2.213148385286331

Epoch: 490| Step: 0
Training loss: 1.1302895545959473
Validation loss: 2.2345865666866302

Epoch: 5| Step: 1
Training loss: 0.5722273588180542
Validation loss: 2.2392406910657883

Epoch: 5| Step: 2
Training loss: 0.9864950180053711
Validation loss: 2.1701533844073615

Epoch: 5| Step: 3
Training loss: 0.8717266321182251
Validation loss: 2.1648900906244912

Epoch: 5| Step: 4
Training loss: 0.6064702868461609
Validation loss: 2.187157486875852

Epoch: 5| Step: 5
Training loss: 1.0313711166381836
Validation loss: 2.1682377606630325

Epoch: 5| Step: 6
Training loss: 0.7788575887680054
Validation loss: 2.1507355670134225

Epoch: 5| Step: 7
Training loss: 1.0941005945205688
Validation loss: 2.206766347090403

Epoch: 5| Step: 8
Training loss: 0.6628284454345703
Validation loss: 2.1943883150815964

Epoch: 5| Step: 9
Training loss: 1.0932773351669312
Validation loss: 2.172686735788981

Epoch: 5| Step: 10
Training loss: 0.9547456502914429
Validation loss: 2.213474825024605

Epoch: 5| Step: 11
Training loss: 1.8524779081344604
Validation loss: 2.2357588410377502

Epoch: 491| Step: 0
Training loss: 0.8147479891777039
Validation loss: 2.251714547475179

Epoch: 5| Step: 1
Training loss: 1.2105534076690674
Validation loss: 2.2327762643496194

Epoch: 5| Step: 2
Training loss: 0.9138745069503784
Validation loss: 2.2272638281186423

Epoch: 5| Step: 3
Training loss: 0.6310495138168335
Validation loss: 2.2511748323837915

Epoch: 5| Step: 4
Training loss: 0.5758711099624634
Validation loss: 2.2283357282479606

Epoch: 5| Step: 5
Training loss: 1.6006195545196533
Validation loss: 2.212275748451551

Epoch: 5| Step: 6
Training loss: 1.1525022983551025
Validation loss: 2.2311523209015527

Epoch: 5| Step: 7
Training loss: 0.7865917682647705
Validation loss: 2.20765088001887

Epoch: 5| Step: 8
Training loss: 0.5261653661727905
Validation loss: 2.2293869256973267

Epoch: 5| Step: 9
Training loss: 0.7774885892868042
Validation loss: 2.163723890980085

Epoch: 5| Step: 10
Training loss: 1.1769747734069824
Validation loss: 2.1920295655727386

Epoch: 5| Step: 11
Training loss: 1.4630266427993774
Validation loss: 2.136656438310941

Epoch: 492| Step: 0
Training loss: 0.9931430816650391
Validation loss: 2.147009462118149

Epoch: 5| Step: 1
Training loss: 1.320881962776184
Validation loss: 2.1599484582742057

Epoch: 5| Step: 2
Training loss: 1.170641303062439
Validation loss: 2.114883398016294

Epoch: 5| Step: 3
Training loss: 0.6571295261383057
Validation loss: 2.0945622473955154

Epoch: 5| Step: 4
Training loss: 0.786842942237854
Validation loss: 2.1147135396798453

Epoch: 5| Step: 5
Training loss: 0.6885331273078918
Validation loss: 2.1503869891166687

Epoch: 5| Step: 6
Training loss: 0.8562482595443726
Validation loss: 2.1462391316890717

Epoch: 5| Step: 7
Training loss: 1.0274807214736938
Validation loss: 2.1768856147925058

Epoch: 5| Step: 8
Training loss: 0.4276682436466217
Validation loss: 2.165325885017713

Epoch: 5| Step: 9
Training loss: 1.1767606735229492
Validation loss: 2.1545295317967734

Epoch: 5| Step: 10
Training loss: 1.008655309677124
Validation loss: 2.1305739184220633

Epoch: 5| Step: 11
Training loss: 1.364989161491394
Validation loss: 2.106930439670881

Epoch: 493| Step: 0
Training loss: 0.7021938562393188
Validation loss: 2.117153058449427

Epoch: 5| Step: 1
Training loss: 0.9312261343002319
Validation loss: 2.1939961910247803

Epoch: 5| Step: 2
Training loss: 1.1467890739440918
Validation loss: 2.1287818551063538

Epoch: 5| Step: 3
Training loss: 0.9809082746505737
Validation loss: 2.156907930970192

Epoch: 5| Step: 4
Training loss: 1.1503920555114746
Validation loss: 2.223982403675715

Epoch: 5| Step: 5
Training loss: 1.4248077869415283
Validation loss: 2.210883299509684

Epoch: 5| Step: 6
Training loss: 0.7880091071128845
Validation loss: 2.229230046272278

Epoch: 5| Step: 7
Training loss: 1.033108115196228
Validation loss: 2.216075753172239

Epoch: 5| Step: 8
Training loss: 0.8181163668632507
Validation loss: 2.2163467506567636

Epoch: 5| Step: 9
Training loss: 0.8886393308639526
Validation loss: 2.215395669142405

Epoch: 5| Step: 10
Training loss: 0.9011470675468445
Validation loss: 2.2040365238984427

Epoch: 5| Step: 11
Training loss: 0.7829200029373169
Validation loss: 2.1867534766594567

Epoch: 494| Step: 0
Training loss: 1.5861741304397583
Validation loss: 2.189202696084976

Epoch: 5| Step: 1
Training loss: 1.0986168384552002
Validation loss: 2.1895157297452292

Epoch: 5| Step: 2
Training loss: 1.0560047626495361
Validation loss: 2.1490764717260995

Epoch: 5| Step: 3
Training loss: 0.8746833801269531
Validation loss: 2.1588648011287055

Epoch: 5| Step: 4
Training loss: 1.2900335788726807
Validation loss: 2.155453527967135

Epoch: 5| Step: 5
Training loss: 0.7068460583686829
Validation loss: 2.1731243977944055

Epoch: 5| Step: 6
Training loss: 0.48874083161354065
Validation loss: 2.1990543405214944

Epoch: 5| Step: 7
Training loss: 1.055179238319397
Validation loss: 2.1979150970776877

Epoch: 5| Step: 8
Training loss: 0.9479799270629883
Validation loss: 2.234533061583837

Epoch: 5| Step: 9
Training loss: 0.8030570149421692
Validation loss: 2.2817617853482566

Epoch: 5| Step: 10
Training loss: 0.7031632661819458
Validation loss: 2.251950735847155

Epoch: 5| Step: 11
Training loss: 2.369596481323242
Validation loss: 2.27978844443957

Epoch: 495| Step: 0
Training loss: 1.1013000011444092
Validation loss: 2.2328163534402847

Epoch: 5| Step: 1
Training loss: 1.4572193622589111
Validation loss: 2.1875619838635125

Epoch: 5| Step: 2
Training loss: 0.9486934542655945
Validation loss: 2.1182158390680947

Epoch: 5| Step: 3
Training loss: 0.8546358346939087
Validation loss: 2.115033263961474

Epoch: 5| Step: 4
Training loss: 0.7336844205856323
Validation loss: 2.085768217841784

Epoch: 5| Step: 5
Training loss: 1.2287414073944092
Validation loss: 2.123063584168752

Epoch: 5| Step: 6
Training loss: 0.8927894830703735
Validation loss: 2.042987053593

Epoch: 5| Step: 7
Training loss: 1.1652581691741943
Validation loss: 2.040368065237999

Epoch: 5| Step: 8
Training loss: 0.7115275859832764
Validation loss: 2.0760061343510947

Epoch: 5| Step: 9
Training loss: 0.817378044128418
Validation loss: 2.1099794109662375

Epoch: 5| Step: 10
Training loss: 1.064291000366211
Validation loss: 2.1324473470449448

Epoch: 5| Step: 11
Training loss: 1.392957329750061
Validation loss: 2.162183324495951

Epoch: 496| Step: 0
Training loss: 0.8871251940727234
Validation loss: 2.1653179277976355

Epoch: 5| Step: 1
Training loss: 1.1317429542541504
Validation loss: 2.1526194562514624

Epoch: 5| Step: 2
Training loss: 1.4656709432601929
Validation loss: 2.131631702184677

Epoch: 5| Step: 3
Training loss: 0.688855767250061
Validation loss: 2.1194700400034585

Epoch: 5| Step: 4
Training loss: 1.116896390914917
Validation loss: 2.1557223151127496

Epoch: 5| Step: 5
Training loss: 0.8302919268608093
Validation loss: 2.1115040481090546

Epoch: 5| Step: 6
Training loss: 0.5547484159469604
Validation loss: 2.1187728494405746

Epoch: 5| Step: 7
Training loss: 0.9715522527694702
Validation loss: 2.1535112659136453

Epoch: 5| Step: 8
Training loss: 1.086523413658142
Validation loss: 2.17285248140494

Epoch: 5| Step: 9
Training loss: 0.715746283531189
Validation loss: 2.1864854196707406

Epoch: 5| Step: 10
Training loss: 0.8177083730697632
Validation loss: 2.16304641465346

Epoch: 5| Step: 11
Training loss: 0.8647605180740356
Validation loss: 2.1654409716526666

Epoch: 497| Step: 0
Training loss: 0.9162120819091797
Validation loss: 2.140502095222473

Epoch: 5| Step: 1
Training loss: 0.9462032318115234
Validation loss: 2.194521129131317

Epoch: 5| Step: 2
Training loss: 1.1305999755859375
Validation loss: 2.1970625519752502

Epoch: 5| Step: 3
Training loss: 0.8502814173698425
Validation loss: 2.169744059443474

Epoch: 5| Step: 4
Training loss: 0.6241349577903748
Validation loss: 2.179135868946711

Epoch: 5| Step: 5
Training loss: 0.5167174935340881
Validation loss: 2.203108489513397

Epoch: 5| Step: 6
Training loss: 0.9723993539810181
Validation loss: 2.1930662989616394

Epoch: 5| Step: 7
Training loss: 0.841387927532196
Validation loss: 2.151188929875692

Epoch: 5| Step: 8
Training loss: 1.6164690256118774
Validation loss: 2.1806507110595703

Epoch: 5| Step: 9
Training loss: 0.7885567545890808
Validation loss: 2.1654015431801477

Epoch: 5| Step: 10
Training loss: 0.8717517852783203
Validation loss: 2.2059850146373114

Epoch: 5| Step: 11
Training loss: 0.45162761211395264
Validation loss: 2.207519898811976

Epoch: 498| Step: 0
Training loss: 0.9775872230529785
Validation loss: 2.183920363585154

Epoch: 5| Step: 1
Training loss: 0.8992170095443726
Validation loss: 2.2068129181861877

Epoch: 5| Step: 2
Training loss: 1.0510501861572266
Validation loss: 2.1950580527385077

Epoch: 5| Step: 3
Training loss: 0.9973889589309692
Validation loss: 2.17391304175059

Epoch: 5| Step: 4
Training loss: 0.7679619789123535
Validation loss: 2.187998687227567

Epoch: 5| Step: 5
Training loss: 0.6416742205619812
Validation loss: 2.1871567020813623

Epoch: 5| Step: 6
Training loss: 0.609891951084137
Validation loss: 2.1588107446829476

Epoch: 5| Step: 7
Training loss: 0.8127349019050598
Validation loss: 2.1783685286839805

Epoch: 5| Step: 8
Training loss: 0.9976399540901184
Validation loss: 2.1448893199364343

Epoch: 5| Step: 9
Training loss: 1.370368242263794
Validation loss: 2.1106176922718682

Epoch: 5| Step: 10
Training loss: 0.6346006989479065
Validation loss: 2.129327525695165

Epoch: 5| Step: 11
Training loss: 0.6167165637016296
Validation loss: 2.141668384273847

Epoch: 499| Step: 0
Training loss: 1.201132893562317
Validation loss: 2.104534928997358

Epoch: 5| Step: 1
Training loss: 0.6967958211898804
Validation loss: 2.0865791589021683

Epoch: 5| Step: 2
Training loss: 0.7004794478416443
Validation loss: 2.047462433576584

Epoch: 5| Step: 3
Training loss: 0.7216130495071411
Validation loss: 2.0904396573702493

Epoch: 5| Step: 4
Training loss: 1.0310258865356445
Validation loss: 2.0843355307976403

Epoch: 5| Step: 5
Training loss: 0.9928945302963257
Validation loss: 2.0673218369483948

Epoch: 5| Step: 6
Training loss: 0.8394756317138672
Validation loss: 2.0655753761529922

Epoch: 5| Step: 7
Training loss: 0.9311056137084961
Validation loss: 2.092588171362877

Epoch: 5| Step: 8
Training loss: 0.6278702616691589
Validation loss: 2.145747423171997

Epoch: 5| Step: 9
Training loss: 1.220497488975525
Validation loss: 2.2020902037620544

Epoch: 5| Step: 10
Training loss: 1.1658543348312378
Validation loss: 2.171625559528669

Epoch: 5| Step: 11
Training loss: 0.4726320505142212
Validation loss: 2.198897197842598

Epoch: 500| Step: 0
Training loss: 0.7274757027626038
Validation loss: 2.200373947620392

Epoch: 5| Step: 1
Training loss: 1.1176396608352661
Validation loss: 2.16889717678229

Epoch: 5| Step: 2
Training loss: 0.4544827938079834
Validation loss: 2.1730695217847824

Epoch: 5| Step: 3
Training loss: 0.8689403533935547
Validation loss: 2.2131635198990502

Epoch: 5| Step: 4
Training loss: 1.1404898166656494
Validation loss: 2.180820087591807

Epoch: 5| Step: 5
Training loss: 1.0509613752365112
Validation loss: 2.173168728748957

Epoch: 5| Step: 6
Training loss: 0.47918978333473206
Validation loss: 2.203133915861448

Epoch: 5| Step: 7
Training loss: 0.7993308901786804
Validation loss: 2.147406190633774

Epoch: 5| Step: 8
Training loss: 0.739395260810852
Validation loss: 2.1919759015242257

Epoch: 5| Step: 9
Training loss: 0.6295986771583557
Validation loss: 2.177495280901591

Epoch: 5| Step: 10
Training loss: 1.3109819889068604
Validation loss: 2.1454620560010276

Epoch: 5| Step: 11
Training loss: 0.9262349605560303
Validation loss: 2.1152460922797522

Epoch: 501| Step: 0
Training loss: 0.4934847950935364
Validation loss: 2.115050420165062

Epoch: 5| Step: 1
Training loss: 1.0524158477783203
Validation loss: 2.1623159845670066

Epoch: 5| Step: 2
Training loss: 1.1427887678146362
Validation loss: 2.1255794962247214

Epoch: 5| Step: 3
Training loss: 0.9068692922592163
Validation loss: 2.1829156279563904

Epoch: 5| Step: 4
Training loss: 0.9996150135993958
Validation loss: 2.1345764497915902

Epoch: 5| Step: 5
Training loss: 1.33345627784729
Validation loss: 2.180430367588997

Epoch: 5| Step: 6
Training loss: 0.5040526390075684
Validation loss: 2.1825288583834968

Epoch: 5| Step: 7
Training loss: 0.6698623299598694
Validation loss: 2.1773579021294913

Epoch: 5| Step: 8
Training loss: 0.8160454630851746
Validation loss: 2.1716010173161826

Epoch: 5| Step: 9
Training loss: 0.7431090474128723
Validation loss: 2.135218227903048

Epoch: 5| Step: 10
Training loss: 0.8320086598396301
Validation loss: 2.144717186689377

Epoch: 5| Step: 11
Training loss: 1.774284839630127
Validation loss: 2.150352110465368

Epoch: 502| Step: 0
Training loss: 0.7508655786514282
Validation loss: 2.147710084915161

Epoch: 5| Step: 1
Training loss: 0.6949359774589539
Validation loss: 2.13275774816672

Epoch: 5| Step: 2
Training loss: 0.8089982867240906
Validation loss: 2.136187821626663

Epoch: 5| Step: 3
Training loss: 0.819126307964325
Validation loss: 2.168951839208603

Epoch: 5| Step: 4
Training loss: 1.2104532718658447
Validation loss: 2.1172254383563995

Epoch: 5| Step: 5
Training loss: 1.0683248043060303
Validation loss: 2.1320928980906806

Epoch: 5| Step: 6
Training loss: 0.9186422228813171
Validation loss: 2.1387823025385537

Epoch: 5| Step: 7
Training loss: 0.8097308874130249
Validation loss: 2.1380748053391776

Epoch: 5| Step: 8
Training loss: 0.8127197027206421
Validation loss: 2.177963803211848

Epoch: 5| Step: 9
Training loss: 0.6704303622245789
Validation loss: 2.120998685558637

Epoch: 5| Step: 10
Training loss: 0.7175129652023315
Validation loss: 2.1318361361821494

Epoch: 5| Step: 11
Training loss: 2.1674740314483643
Validation loss: 2.1682725151379905

Epoch: 503| Step: 0
Training loss: 0.7382296919822693
Validation loss: 2.1545417507489524

Epoch: 5| Step: 1
Training loss: 0.693803608417511
Validation loss: 2.1686958372592926

Epoch: 5| Step: 2
Training loss: 0.6490747332572937
Validation loss: 2.2241035203138986

Epoch: 5| Step: 3
Training loss: 0.6525500416755676
Validation loss: 2.168127655982971

Epoch: 5| Step: 4
Training loss: 1.1101667881011963
Validation loss: 2.215795318285624

Epoch: 5| Step: 5
Training loss: 0.9906904101371765
Validation loss: 2.1561849862337112

Epoch: 5| Step: 6
Training loss: 0.7672368884086609
Validation loss: 2.164918581644694

Epoch: 5| Step: 7
Training loss: 1.00492262840271
Validation loss: 2.20682862897714

Epoch: 5| Step: 8
Training loss: 0.8394249677658081
Validation loss: 2.1801567524671555

Epoch: 5| Step: 9
Training loss: 0.5948413610458374
Validation loss: 2.1288064370552697

Epoch: 5| Step: 10
Training loss: 1.0635497570037842
Validation loss: 2.207699030637741

Epoch: 5| Step: 11
Training loss: 1.9501173496246338
Validation loss: 2.171382561326027

Epoch: 504| Step: 0
Training loss: 0.8312989473342896
Validation loss: 2.1875919699668884

Epoch: 5| Step: 1
Training loss: 0.8852568864822388
Validation loss: 2.1513055165608725

Epoch: 5| Step: 2
Training loss: 0.6924893260002136
Validation loss: 2.2146141976118088

Epoch: 5| Step: 3
Training loss: 1.2209036350250244
Validation loss: 2.1761893729368844

Epoch: 5| Step: 4
Training loss: 0.7589104175567627
Validation loss: 2.1877488642930984

Epoch: 5| Step: 5
Training loss: 0.5460728406906128
Validation loss: 2.21299147605896

Epoch: 5| Step: 6
Training loss: 0.6759673357009888
Validation loss: 2.168634449442228

Epoch: 5| Step: 7
Training loss: 0.8272780179977417
Validation loss: 2.1354225426912308

Epoch: 5| Step: 8
Training loss: 0.6155656576156616
Validation loss: 2.12466291586558

Epoch: 5| Step: 9
Training loss: 1.204603910446167
Validation loss: 2.1674070755640664

Epoch: 5| Step: 10
Training loss: 1.444464921951294
Validation loss: 2.1451409657796225

Epoch: 5| Step: 11
Training loss: 0.46170294284820557
Validation loss: 2.1326033075650535

Epoch: 505| Step: 0
Training loss: 1.1965068578720093
Validation loss: 2.133941113948822

Epoch: 5| Step: 1
Training loss: 0.6422311067581177
Validation loss: 2.143544152379036

Epoch: 5| Step: 2
Training loss: 0.8840214610099792
Validation loss: 2.1080989936987558

Epoch: 5| Step: 3
Training loss: 1.3931303024291992
Validation loss: 2.1500369012355804

Epoch: 5| Step: 4
Training loss: 1.0094796419143677
Validation loss: 2.158856506148974

Epoch: 5| Step: 5
Training loss: 0.575034499168396
Validation loss: 2.1344855477412543

Epoch: 5| Step: 6
Training loss: 0.7606092095375061
Validation loss: 2.1658804515997567

Epoch: 5| Step: 7
Training loss: 0.7974410057067871
Validation loss: 2.1154605795939765

Epoch: 5| Step: 8
Training loss: 0.8559833765029907
Validation loss: 2.181954632202784

Epoch: 5| Step: 9
Training loss: 0.7616021037101746
Validation loss: 2.173414592941602

Epoch: 5| Step: 10
Training loss: 0.8618162870407104
Validation loss: 2.1800144016742706

Epoch: 5| Step: 11
Training loss: 0.09427827596664429
Validation loss: 2.1698434551556907

Epoch: 506| Step: 0
Training loss: 0.7319644093513489
Validation loss: 2.1768815169731774

Epoch: 5| Step: 1
Training loss: 1.029754400253296
Validation loss: 2.1775505046049752

Epoch: 5| Step: 2
Training loss: 1.2768974304199219
Validation loss: 2.180877904097239

Epoch: 5| Step: 3
Training loss: 0.9928804636001587
Validation loss: 2.157212495803833

Epoch: 5| Step: 4
Training loss: 1.0056672096252441
Validation loss: 2.1398916840553284

Epoch: 5| Step: 5
Training loss: 0.6308172345161438
Validation loss: 2.1581122279167175

Epoch: 5| Step: 6
Training loss: 0.64378821849823
Validation loss: 2.1352804700533548

Epoch: 5| Step: 7
Training loss: 0.9776498675346375
Validation loss: 2.153225968281428

Epoch: 5| Step: 8
Training loss: 0.8992347717285156
Validation loss: 2.1629821012417474

Epoch: 5| Step: 9
Training loss: 0.9308831095695496
Validation loss: 2.1458383401234946

Epoch: 5| Step: 10
Training loss: 0.7405155897140503
Validation loss: 2.140738993883133

Epoch: 5| Step: 11
Training loss: 0.2208004742860794
Validation loss: 2.1687869081894555

Epoch: 507| Step: 0
Training loss: 0.7186106443405151
Validation loss: 2.1690324495236077

Epoch: 5| Step: 1
Training loss: 0.843331515789032
Validation loss: 2.1697670022646585

Epoch: 5| Step: 2
Training loss: 0.9349703788757324
Validation loss: 2.1629991829395294

Epoch: 5| Step: 3
Training loss: 0.6559746861457825
Validation loss: 2.152113378047943

Epoch: 5| Step: 4
Training loss: 1.2716621160507202
Validation loss: 2.195268750190735

Epoch: 5| Step: 5
Training loss: 0.640544056892395
Validation loss: 2.1748450497786203

Epoch: 5| Step: 6
Training loss: 1.064039945602417
Validation loss: 2.1789756963650384

Epoch: 5| Step: 7
Training loss: 0.47204989194869995
Validation loss: 2.183419773976008

Epoch: 5| Step: 8
Training loss: 0.42769020795822144
Validation loss: 2.196607917547226

Epoch: 5| Step: 9
Training loss: 0.7001942992210388
Validation loss: 2.153908595442772

Epoch: 5| Step: 10
Training loss: 1.7652209997177124
Validation loss: 2.098583976427714

Epoch: 5| Step: 11
Training loss: 0.29845112562179565
Validation loss: 2.0950614164272943

Epoch: 508| Step: 0
Training loss: 0.8952411413192749
Validation loss: 2.102224479118983

Epoch: 5| Step: 1
Training loss: 1.5022538900375366
Validation loss: 2.0988284945487976

Epoch: 5| Step: 2
Training loss: 0.8533775210380554
Validation loss: 2.1129664480686188

Epoch: 5| Step: 3
Training loss: 0.7770487070083618
Validation loss: 2.094039350748062

Epoch: 5| Step: 4
Training loss: 0.5516077280044556
Validation loss: 2.0697682748238244

Epoch: 5| Step: 5
Training loss: 0.7975789308547974
Validation loss: 2.124411771694819

Epoch: 5| Step: 6
Training loss: 0.5414478778839111
Validation loss: 2.117646719018618

Epoch: 5| Step: 7
Training loss: 0.6511145830154419
Validation loss: 2.0856168965498605

Epoch: 5| Step: 8
Training loss: 0.7106783986091614
Validation loss: 2.132059892018636

Epoch: 5| Step: 9
Training loss: 1.0125095844268799
Validation loss: 2.106649562716484

Epoch: 5| Step: 10
Training loss: 0.7430763244628906
Validation loss: 2.11220221221447

Epoch: 5| Step: 11
Training loss: 1.6796321868896484
Validation loss: 2.1328612317641578

Epoch: 509| Step: 0
Training loss: 0.8882419466972351
Validation loss: 2.1285206178824105

Epoch: 5| Step: 1
Training loss: 0.6012728810310364
Validation loss: 2.0496813158194223

Epoch: 5| Step: 2
Training loss: 0.5949724912643433
Validation loss: 2.023472045858701

Epoch: 5| Step: 3
Training loss: 0.974040150642395
Validation loss: 2.0532072285811105

Epoch: 5| Step: 4
Training loss: 0.5301749110221863
Validation loss: 2.0498493214448295

Epoch: 5| Step: 5
Training loss: 0.6443678140640259
Validation loss: 2.0639421194791794

Epoch: 5| Step: 6
Training loss: 1.4055299758911133
Validation loss: 2.0605116238196692

Epoch: 5| Step: 7
Training loss: 0.5549813508987427
Validation loss: 2.0968239257733026

Epoch: 5| Step: 8
Training loss: 1.2056840658187866
Validation loss: 2.098390519618988

Epoch: 5| Step: 9
Training loss: 0.6634289622306824
Validation loss: 2.0646054446697235

Epoch: 5| Step: 10
Training loss: 1.062273383140564
Validation loss: 2.0748490442832312

Epoch: 5| Step: 11
Training loss: 0.6916408538818359
Validation loss: 2.1325639486312866

Epoch: 510| Step: 0
Training loss: 0.9304205179214478
Validation loss: 2.1516658465067544

Epoch: 5| Step: 1
Training loss: 0.7664685845375061
Validation loss: 2.143989602724711

Epoch: 5| Step: 2
Training loss: 1.4373105764389038
Validation loss: 2.187369147936503

Epoch: 5| Step: 3
Training loss: 0.7344196438789368
Validation loss: 2.1579509526491165

Epoch: 5| Step: 4
Training loss: 0.7455424666404724
Validation loss: 2.1280444860458374

Epoch: 5| Step: 5
Training loss: 0.7487532496452332
Validation loss: 2.1055508305629096

Epoch: 5| Step: 6
Training loss: 0.7724625468254089
Validation loss: 2.150290389855703

Epoch: 5| Step: 7
Training loss: 0.7250950932502747
Validation loss: 2.1473129838705063

Epoch: 5| Step: 8
Training loss: 0.988758385181427
Validation loss: 2.07834500571092

Epoch: 5| Step: 9
Training loss: 1.0343303680419922
Validation loss: 2.09386183321476

Epoch: 5| Step: 10
Training loss: 0.799069881439209
Validation loss: 2.0615002810955048

Epoch: 5| Step: 11
Training loss: 0.5407665967941284
Validation loss: 2.1348151763280234

Epoch: 511| Step: 0
Training loss: 1.1085965633392334
Validation loss: 2.1228793064753213

Epoch: 5| Step: 1
Training loss: 0.9132512807846069
Validation loss: 2.176478380958239

Epoch: 5| Step: 2
Training loss: 0.685137927532196
Validation loss: 2.1585011035203934

Epoch: 5| Step: 3
Training loss: 1.3171424865722656
Validation loss: 2.1462065974871316

Epoch: 5| Step: 4
Training loss: 1.0515391826629639
Validation loss: 2.0776943961779275

Epoch: 5| Step: 5
Training loss: 0.8478955030441284
Validation loss: 2.177460342645645

Epoch: 5| Step: 6
Training loss: 0.9508382678031921
Validation loss: 2.151099512974421

Epoch: 5| Step: 7
Training loss: 1.195426344871521
Validation loss: 2.1482788771390915

Epoch: 5| Step: 8
Training loss: 0.7870108485221863
Validation loss: 2.139842599630356

Epoch: 5| Step: 9
Training loss: 0.4813530445098877
Validation loss: 2.1257260690132775

Epoch: 5| Step: 10
Training loss: 0.5335494875907898
Validation loss: 2.137402872244517

Epoch: 5| Step: 11
Training loss: 1.1204900741577148
Validation loss: 2.147848129272461

Epoch: 512| Step: 0
Training loss: 1.4583090543746948
Validation loss: 2.15071007112662

Epoch: 5| Step: 1
Training loss: 1.125503420829773
Validation loss: 2.1256163666645684

Epoch: 5| Step: 2
Training loss: 0.5188015699386597
Validation loss: 2.099834993481636

Epoch: 5| Step: 3
Training loss: 0.6296600103378296
Validation loss: 2.114467993378639

Epoch: 5| Step: 4
Training loss: 1.0186975002288818
Validation loss: 2.1275944858789444

Epoch: 5| Step: 5
Training loss: 0.8651233911514282
Validation loss: 2.1734982331593833

Epoch: 5| Step: 6
Training loss: 0.6813386678695679
Validation loss: 2.1336869349082312

Epoch: 5| Step: 7
Training loss: 0.8766236305236816
Validation loss: 2.154953569173813

Epoch: 5| Step: 8
Training loss: 0.5837596654891968
Validation loss: 2.163510501384735

Epoch: 5| Step: 9
Training loss: 0.823779284954071
Validation loss: 2.1335437993208566

Epoch: 5| Step: 10
Training loss: 0.6366938352584839
Validation loss: 2.1389204263687134

Epoch: 5| Step: 11
Training loss: 1.1692975759506226
Validation loss: 2.159593557318052

Epoch: 513| Step: 0
Training loss: 0.7319431304931641
Validation loss: 2.1401603370904922

Epoch: 5| Step: 1
Training loss: 0.5701573491096497
Validation loss: 2.1194916466871896

Epoch: 5| Step: 2
Training loss: 0.8923354148864746
Validation loss: 2.0611451268196106

Epoch: 5| Step: 3
Training loss: 0.9459151029586792
Validation loss: 2.0675152291854224

Epoch: 5| Step: 4
Training loss: 0.5217810273170471
Validation loss: 2.0935507963101068

Epoch: 5| Step: 5
Training loss: 0.8372081518173218
Validation loss: 2.059179057677587

Epoch: 5| Step: 6
Training loss: 0.6970747709274292
Validation loss: 2.0625171860059104

Epoch: 5| Step: 7
Training loss: 1.1120532751083374
Validation loss: 2.1158003956079483

Epoch: 5| Step: 8
Training loss: 1.1530072689056396
Validation loss: 2.0788948386907578

Epoch: 5| Step: 9
Training loss: 0.6819291114807129
Validation loss: 2.0772025833527246

Epoch: 5| Step: 10
Training loss: 0.8856877088546753
Validation loss: 2.1169546941916146

Epoch: 5| Step: 11
Training loss: 0.5576684474945068
Validation loss: 2.0968640645345054

Epoch: 514| Step: 0
Training loss: 0.9696218371391296
Validation loss: 2.1017118593057

Epoch: 5| Step: 1
Training loss: 1.0560071468353271
Validation loss: 2.131549080212911

Epoch: 5| Step: 2
Training loss: 0.5824366211891174
Validation loss: 2.0968911896149316

Epoch: 5| Step: 3
Training loss: 0.9838935136795044
Validation loss: 2.104616637031237

Epoch: 5| Step: 4
Training loss: 0.7305582761764526
Validation loss: 2.1266301224629083

Epoch: 5| Step: 5
Training loss: 0.6751357913017273
Validation loss: 2.1338921586672464

Epoch: 5| Step: 6
Training loss: 1.2941887378692627
Validation loss: 2.1047193656365075

Epoch: 5| Step: 7
Training loss: 0.8673364520072937
Validation loss: 2.088866720596949

Epoch: 5| Step: 8
Training loss: 0.6357960104942322
Validation loss: 2.1067658066749573

Epoch: 5| Step: 9
Training loss: 0.6612805128097534
Validation loss: 2.15832112232844

Epoch: 5| Step: 10
Training loss: 0.7514660358428955
Validation loss: 2.134263500571251

Epoch: 5| Step: 11
Training loss: 2.2616963386535645
Validation loss: 2.131290376186371

Epoch: 515| Step: 0
Training loss: 0.7277818918228149
Validation loss: 2.0915600260098777

Epoch: 5| Step: 1
Training loss: 0.46221503615379333
Validation loss: 2.091911589105924

Epoch: 5| Step: 2
Training loss: 0.6990330815315247
Validation loss: 2.0564832985401154

Epoch: 5| Step: 3
Training loss: 0.9118913412094116
Validation loss: 2.0956269750992456

Epoch: 5| Step: 4
Training loss: 0.7989269495010376
Validation loss: 2.0572677105665207

Epoch: 5| Step: 5
Training loss: 0.8213874697685242
Validation loss: 2.1150895009438195

Epoch: 5| Step: 6
Training loss: 1.657395362854004
Validation loss: 2.0885440011819205

Epoch: 5| Step: 7
Training loss: 0.863463282585144
Validation loss: 2.080874035755793

Epoch: 5| Step: 8
Training loss: 0.8367363214492798
Validation loss: 2.0811238437891006

Epoch: 5| Step: 9
Training loss: 1.5766241550445557
Validation loss: 2.128335411349932

Epoch: 5| Step: 10
Training loss: 0.7298884987831116
Validation loss: 2.221003790696462

Epoch: 5| Step: 11
Training loss: 1.0121160745620728
Validation loss: 2.2129729787508645

Epoch: 516| Step: 0
Training loss: 1.2762887477874756
Validation loss: 2.227955470482508

Epoch: 5| Step: 1
Training loss: 0.7213234305381775
Validation loss: 2.1812446216742196

Epoch: 5| Step: 2
Training loss: 1.0579513311386108
Validation loss: 2.2050959368546805

Epoch: 5| Step: 3
Training loss: 0.5063053369522095
Validation loss: 2.0991411159435907

Epoch: 5| Step: 4
Training loss: 0.7357348799705505
Validation loss: 2.1800191899140677

Epoch: 5| Step: 5
Training loss: 1.222313642501831
Validation loss: 2.156746059656143

Epoch: 5| Step: 6
Training loss: 0.6786594390869141
Validation loss: 2.1927169611056647

Epoch: 5| Step: 7
Training loss: 1.0202339887619019
Validation loss: 2.148035908738772

Epoch: 5| Step: 8
Training loss: 0.623979926109314
Validation loss: 2.1355645805597305

Epoch: 5| Step: 9
Training loss: 0.7929690480232239
Validation loss: 2.1459269722302756

Epoch: 5| Step: 10
Training loss: 1.2232706546783447
Validation loss: 2.165405750274658

Epoch: 5| Step: 11
Training loss: 0.6018528938293457
Validation loss: 2.1725399792194366

Epoch: 517| Step: 0
Training loss: 0.7530649304389954
Validation loss: 2.2051590184370675

Epoch: 5| Step: 1
Training loss: 0.9625495672225952
Validation loss: 2.1692227522532144

Epoch: 5| Step: 2
Training loss: 1.027439832687378
Validation loss: 2.223433514436086

Epoch: 5| Step: 3
Training loss: 0.5885602235794067
Validation loss: 2.172694837053617

Epoch: 5| Step: 4
Training loss: 1.1492760181427002
Validation loss: 2.175218790769577

Epoch: 5| Step: 5
Training loss: 0.7853920459747314
Validation loss: 2.1155375937620797

Epoch: 5| Step: 6
Training loss: 0.821026623249054
Validation loss: 2.1594053457180657

Epoch: 5| Step: 7
Training loss: 0.9125935435295105
Validation loss: 2.1822044601043067

Epoch: 5| Step: 8
Training loss: 0.8365494012832642
Validation loss: 2.153055946032206

Epoch: 5| Step: 9
Training loss: 1.1585584878921509
Validation loss: 2.1597724507252374

Epoch: 5| Step: 10
Training loss: 0.7628132104873657
Validation loss: 2.141027440627416

Epoch: 5| Step: 11
Training loss: 0.45145559310913086
Validation loss: 2.1632068157196045

Epoch: 518| Step: 0
Training loss: 0.8335399627685547
Validation loss: 2.1469370077053704

Epoch: 5| Step: 1
Training loss: 0.6016556024551392
Validation loss: 2.1919912795225778

Epoch: 5| Step: 2
Training loss: 0.7008484601974487
Validation loss: 2.1541981597741446

Epoch: 5| Step: 3
Training loss: 1.4439938068389893
Validation loss: 2.1612995664278665

Epoch: 5| Step: 4
Training loss: 1.1124581098556519
Validation loss: 2.1736554354429245

Epoch: 5| Step: 5
Training loss: 0.5661254525184631
Validation loss: 2.1475028494993844

Epoch: 5| Step: 6
Training loss: 0.43354567885398865
Validation loss: 2.1622620671987534

Epoch: 5| Step: 7
Training loss: 0.5106479525566101
Validation loss: 2.1239251593748727

Epoch: 5| Step: 8
Training loss: 0.9802106022834778
Validation loss: 2.091151550412178

Epoch: 5| Step: 9
Training loss: 0.8953741788864136
Validation loss: 2.0662871350844703

Epoch: 5| Step: 10
Training loss: 0.9609678387641907
Validation loss: 2.082119181752205

Epoch: 5| Step: 11
Training loss: 0.2404840588569641
Validation loss: 2.039923051993052

Epoch: 519| Step: 0
Training loss: 0.5849407315254211
Validation loss: 2.097126548488935

Epoch: 5| Step: 1
Training loss: 0.5591285228729248
Validation loss: 2.0852960298458734

Epoch: 5| Step: 2
Training loss: 0.8671897649765015
Validation loss: 2.1389388144016266

Epoch: 5| Step: 3
Training loss: 0.745559811592102
Validation loss: 2.1588541318972907

Epoch: 5| Step: 4
Training loss: 0.5000236630439758
Validation loss: 2.176663984855016

Epoch: 5| Step: 5
Training loss: 0.5218722820281982
Validation loss: 2.209776143232981

Epoch: 5| Step: 6
Training loss: 1.0489933490753174
Validation loss: 2.229078988234202

Epoch: 5| Step: 7
Training loss: 0.8252059817314148
Validation loss: 2.240264187256495

Epoch: 5| Step: 8
Training loss: 1.167551875114441
Validation loss: 2.2018388162056604

Epoch: 5| Step: 9
Training loss: 1.2148855924606323
Validation loss: 2.194020683566729

Epoch: 5| Step: 10
Training loss: 0.8299964070320129
Validation loss: 2.165691167116165

Epoch: 5| Step: 11
Training loss: 1.1440364122390747
Validation loss: 2.175172304113706

Epoch: 520| Step: 0
Training loss: 0.8421964645385742
Validation loss: 2.1572870115439096

Epoch: 5| Step: 1
Training loss: 0.7421913146972656
Validation loss: 2.158786733945211

Epoch: 5| Step: 2
Training loss: 1.0639402866363525
Validation loss: 2.1534919341405234

Epoch: 5| Step: 3
Training loss: 0.5779014825820923
Validation loss: 2.1247023542722068

Epoch: 5| Step: 4
Training loss: 0.6751543283462524
Validation loss: 2.1110923488934836

Epoch: 5| Step: 5
Training loss: 0.8804934620857239
Validation loss: 2.1482986013094583

Epoch: 5| Step: 6
Training loss: 0.9333711862564087
Validation loss: 2.0819270809491477

Epoch: 5| Step: 7
Training loss: 1.3137462139129639
Validation loss: 2.16827230155468

Epoch: 5| Step: 8
Training loss: 0.8753399848937988
Validation loss: 2.1533312648534775

Epoch: 5| Step: 9
Training loss: 0.9402830004692078
Validation loss: 2.124697372317314

Epoch: 5| Step: 10
Training loss: 0.7022040486335754
Validation loss: 2.161133815844854

Epoch: 5| Step: 11
Training loss: 0.43447810411453247
Validation loss: 2.137113481760025

Epoch: 521| Step: 0
Training loss: 0.49334102869033813
Validation loss: 2.1556733399629593

Epoch: 5| Step: 1
Training loss: 0.6397820711135864
Validation loss: 2.181185632944107

Epoch: 5| Step: 2
Training loss: 0.6805205345153809
Validation loss: 2.1896135906378427

Epoch: 5| Step: 3
Training loss: 0.6504379510879517
Validation loss: 2.16932546099027

Epoch: 5| Step: 4
Training loss: 1.724303960800171
Validation loss: 2.1684850802024207

Epoch: 5| Step: 5
Training loss: 0.7710176706314087
Validation loss: 2.1779671013355255

Epoch: 5| Step: 6
Training loss: 1.209094762802124
Validation loss: 2.1621232827504477

Epoch: 5| Step: 7
Training loss: 0.4509885311126709
Validation loss: 2.196976234515508

Epoch: 5| Step: 8
Training loss: 0.4297407567501068
Validation loss: 2.16145791610082

Epoch: 5| Step: 9
Training loss: 0.9164255261421204
Validation loss: 2.1407622744639716

Epoch: 5| Step: 10
Training loss: 1.1023728847503662
Validation loss: 2.1455279191335044

Epoch: 5| Step: 11
Training loss: 0.28450655937194824
Validation loss: 2.133381967743238

Epoch: 522| Step: 0
Training loss: 0.6305374503135681
Validation loss: 2.1131108601888022

Epoch: 5| Step: 1
Training loss: 0.7232013940811157
Validation loss: 2.148526589075724

Epoch: 5| Step: 2
Training loss: 0.2989516258239746
Validation loss: 2.140623395641645

Epoch: 5| Step: 3
Training loss: 1.1627585887908936
Validation loss: 2.1525820096333823

Epoch: 5| Step: 4
Training loss: 0.8088352084159851
Validation loss: 2.1247062385082245

Epoch: 5| Step: 5
Training loss: 0.8965506553649902
Validation loss: 2.092299461364746

Epoch: 5| Step: 6
Training loss: 0.8404361605644226
Validation loss: 2.1174671252568564

Epoch: 5| Step: 7
Training loss: 0.9351605176925659
Validation loss: 2.0998468597730002

Epoch: 5| Step: 8
Training loss: 0.4870637059211731
Validation loss: 2.129210352897644

Epoch: 5| Step: 9
Training loss: 1.1205554008483887
Validation loss: 2.0779745876789093

Epoch: 5| Step: 10
Training loss: 0.679754376411438
Validation loss: 2.126649414499601

Epoch: 5| Step: 11
Training loss: 0.445797324180603
Validation loss: 2.1179084877173104

Epoch: 523| Step: 0
Training loss: 1.0792102813720703
Validation loss: 2.1138382852077484

Epoch: 5| Step: 1
Training loss: 0.8477883338928223
Validation loss: 2.0870270232359567

Epoch: 5| Step: 2
Training loss: 1.193930983543396
Validation loss: 2.0967858682076135

Epoch: 5| Step: 3
Training loss: 0.3647306561470032
Validation loss: 2.0744849195082984

Epoch: 5| Step: 4
Training loss: 0.8879467248916626
Validation loss: 2.0555947571992874

Epoch: 5| Step: 5
Training loss: 0.8182026743888855
Validation loss: 1.9927279353141785

Epoch: 5| Step: 6
Training loss: 0.7826476693153381
Validation loss: 2.005995790163676

Epoch: 5| Step: 7
Training loss: 1.1148288249969482
Validation loss: 2.0484455674886703

Epoch: 5| Step: 8
Training loss: 0.5159468650817871
Validation loss: 2.0313473592201867

Epoch: 5| Step: 9
Training loss: 0.4714335501194
Validation loss: 2.022128855188688

Epoch: 5| Step: 10
Training loss: 0.927406907081604
Validation loss: 2.0693575541178384

Epoch: 5| Step: 11
Training loss: 0.44175463914871216
Validation loss: 2.062590812643369

Epoch: 524| Step: 0
Training loss: 1.5525479316711426
Validation loss: 2.0875630428393683

Epoch: 5| Step: 1
Training loss: 0.37306636571884155
Validation loss: 2.1111180633306503

Epoch: 5| Step: 2
Training loss: 0.8110138773918152
Validation loss: 2.1424694110949836

Epoch: 5| Step: 3
Training loss: 0.7258938550949097
Validation loss: 2.096961716810862

Epoch: 5| Step: 4
Training loss: 0.6402985453605652
Validation loss: 2.1201009154319763

Epoch: 5| Step: 5
Training loss: 0.7446523904800415
Validation loss: 2.1161377330621085

Epoch: 5| Step: 6
Training loss: 0.9367624521255493
Validation loss: 2.155076116323471

Epoch: 5| Step: 7
Training loss: 1.1951369047164917
Validation loss: 2.1040634214878082

Epoch: 5| Step: 8
Training loss: 0.6068853139877319
Validation loss: 2.146775404612223

Epoch: 5| Step: 9
Training loss: 0.8822132349014282
Validation loss: 2.1455460687478385

Epoch: 5| Step: 10
Training loss: 0.5022218227386475
Validation loss: 2.116094986597697

Epoch: 5| Step: 11
Training loss: 0.5021397471427917
Validation loss: 2.1214001526435218

Epoch: 525| Step: 0
Training loss: 0.7318475246429443
Validation loss: 2.1354329586029053

Epoch: 5| Step: 1
Training loss: 0.5989047884941101
Validation loss: 2.1405862222115197

Epoch: 5| Step: 2
Training loss: 1.076981782913208
Validation loss: 2.145563264687856

Epoch: 5| Step: 3
Training loss: 0.9520284533500671
Validation loss: 2.144189770023028

Epoch: 5| Step: 4
Training loss: 0.8095356225967407
Validation loss: 2.1258664727211

Epoch: 5| Step: 5
Training loss: 1.1231143474578857
Validation loss: 2.099738910794258

Epoch: 5| Step: 6
Training loss: 0.2685003876686096
Validation loss: 2.161337966720263

Epoch: 5| Step: 7
Training loss: 1.0758835077285767
Validation loss: 2.1250027269124985

Epoch: 5| Step: 8
Training loss: 1.0151684284210205
Validation loss: 2.173069477081299

Epoch: 5| Step: 9
Training loss: 0.3862431049346924
Validation loss: 2.146563937266668

Epoch: 5| Step: 10
Training loss: 0.7060548067092896
Validation loss: 2.0913658241430917

Epoch: 5| Step: 11
Training loss: 0.798052191734314
Validation loss: 2.0564552346865335

Epoch: 526| Step: 0
Training loss: 0.7106592059135437
Validation loss: 2.0582321137189865

Epoch: 5| Step: 1
Training loss: 0.4623964726924896
Validation loss: 2.0286883811155954

Epoch: 5| Step: 2
Training loss: 0.8171035647392273
Validation loss: 2.030168021718661

Epoch: 5| Step: 3
Training loss: 0.7680498361587524
Validation loss: 2.074474041660627

Epoch: 5| Step: 4
Training loss: 0.5742653012275696
Validation loss: 2.030408814549446

Epoch: 5| Step: 5
Training loss: 1.266591191291809
Validation loss: 2.0375890682140985

Epoch: 5| Step: 6
Training loss: 0.6068710088729858
Validation loss: 2.0396210104227066

Epoch: 5| Step: 7
Training loss: 0.4864470362663269
Validation loss: 2.0385315914948783

Epoch: 5| Step: 8
Training loss: 0.5870250463485718
Validation loss: 2.0257058888673782

Epoch: 5| Step: 9
Training loss: 0.7062088847160339
Validation loss: 2.0347685118516288

Epoch: 5| Step: 10
Training loss: 1.277504324913025
Validation loss: 2.035900349418322

Epoch: 5| Step: 11
Training loss: 2.0745320320129395
Validation loss: 2.065410479903221

Epoch: 527| Step: 0
Training loss: 1.3233097791671753
Validation loss: 2.0417486230532327

Epoch: 5| Step: 1
Training loss: 0.6029618978500366
Validation loss: 2.0756169656912484

Epoch: 5| Step: 2
Training loss: 0.8374505043029785
Validation loss: 2.0585556775331497

Epoch: 5| Step: 3
Training loss: 0.4897506833076477
Validation loss: 2.097944527864456

Epoch: 5| Step: 4
Training loss: 0.7939637899398804
Validation loss: 2.087874328096708

Epoch: 5| Step: 5
Training loss: 0.39776432514190674
Validation loss: 2.0491634060939155

Epoch: 5| Step: 6
Training loss: 0.6544417142868042
Validation loss: 2.1001089165608087

Epoch: 5| Step: 7
Training loss: 0.6617358326911926
Validation loss: 2.055841197570165

Epoch: 5| Step: 8
Training loss: 0.5932307243347168
Validation loss: 2.069939057032267

Epoch: 5| Step: 9
Training loss: 1.1088218688964844
Validation loss: 2.045898675918579

Epoch: 5| Step: 10
Training loss: 1.0591081380844116
Validation loss: 2.1462577233711877

Epoch: 5| Step: 11
Training loss: 0.7001527547836304
Validation loss: 2.130055626233419

Epoch: 528| Step: 0
Training loss: 0.6567522287368774
Validation loss: 2.1397889455159507

Epoch: 5| Step: 1
Training loss: 0.49982061982154846
Validation loss: 2.12879678606987

Epoch: 5| Step: 2
Training loss: 0.8924428820610046
Validation loss: 2.110824038585027

Epoch: 5| Step: 3
Training loss: 0.5085709691047668
Validation loss: 2.143321464459101

Epoch: 5| Step: 4
Training loss: 0.8273245096206665
Validation loss: 2.159325917561849

Epoch: 5| Step: 5
Training loss: 1.2407411336898804
Validation loss: 2.14344285428524

Epoch: 5| Step: 6
Training loss: 0.7784245610237122
Validation loss: 2.1354984442392984

Epoch: 5| Step: 7
Training loss: 0.5513166189193726
Validation loss: 2.122195859750112

Epoch: 5| Step: 8
Training loss: 0.7286024689674377
Validation loss: 2.1301678270101547

Epoch: 5| Step: 9
Training loss: 1.1220461130142212
Validation loss: 2.1510274509588876

Epoch: 5| Step: 10
Training loss: 0.8203364610671997
Validation loss: 2.1603332459926605

Epoch: 5| Step: 11
Training loss: 0.72840416431427
Validation loss: 2.1673830995957055

Epoch: 529| Step: 0
Training loss: 0.6412109136581421
Validation loss: 2.144013444582621

Epoch: 5| Step: 1
Training loss: 0.7440104484558105
Validation loss: 2.143792003393173

Epoch: 5| Step: 2
Training loss: 0.620303750038147
Validation loss: 2.093447277943293

Epoch: 5| Step: 3
Training loss: 0.8447723388671875
Validation loss: 2.144135465224584

Epoch: 5| Step: 4
Training loss: 0.9630396962165833
Validation loss: 2.095092460513115

Epoch: 5| Step: 5
Training loss: 0.6055949926376343
Validation loss: 2.1097139169772468

Epoch: 5| Step: 6
Training loss: 0.6678928732872009
Validation loss: 2.079520583152771

Epoch: 5| Step: 7
Training loss: 0.8663075566291809
Validation loss: 2.0734932820002236

Epoch: 5| Step: 8
Training loss: 0.885151207447052
Validation loss: 2.037412171562513

Epoch: 5| Step: 9
Training loss: 0.856916069984436
Validation loss: 2.0724570900201797

Epoch: 5| Step: 10
Training loss: 0.5698096752166748
Validation loss: 2.081829776366552

Epoch: 5| Step: 11
Training loss: 2.1225438117980957
Validation loss: 2.0769650091727576

Epoch: 530| Step: 0
Training loss: 0.716988205909729
Validation loss: 2.0849731663862863

Epoch: 5| Step: 1
Training loss: 0.8014476895332336
Validation loss: 2.0817543069521585

Epoch: 5| Step: 2
Training loss: 0.626217246055603
Validation loss: 2.0401698301235833

Epoch: 5| Step: 3
Training loss: 0.929272472858429
Validation loss: 2.1117328852415085

Epoch: 5| Step: 4
Training loss: 1.0163333415985107
Validation loss: 2.0983076294263205

Epoch: 5| Step: 5
Training loss: 0.6363779306411743
Validation loss: 2.0727758755286536

Epoch: 5| Step: 6
Training loss: 0.6986898183822632
Validation loss: 2.0358745008707047

Epoch: 5| Step: 7
Training loss: 0.6644160747528076
Validation loss: 2.098434805870056

Epoch: 5| Step: 8
Training loss: 0.7831467390060425
Validation loss: 2.1206467549006143

Epoch: 5| Step: 9
Training loss: 0.6713687777519226
Validation loss: 2.149313618739446

Epoch: 5| Step: 10
Training loss: 1.1275346279144287
Validation loss: 2.121688097715378

Epoch: 5| Step: 11
Training loss: 0.4660235643386841
Validation loss: 2.141026313106219

Epoch: 531| Step: 0
Training loss: 0.5776752233505249
Validation loss: 2.12103204925855

Epoch: 5| Step: 1
Training loss: 0.7050241231918335
Validation loss: 2.0829024414221444

Epoch: 5| Step: 2
Training loss: 0.8240448236465454
Validation loss: 2.09214981396993

Epoch: 5| Step: 3
Training loss: 0.8111405372619629
Validation loss: 2.1438307811816535

Epoch: 5| Step: 4
Training loss: 0.5214154124259949
Validation loss: 2.1229688276847205

Epoch: 5| Step: 5
Training loss: 0.9945670962333679
Validation loss: 2.069948280851046

Epoch: 5| Step: 6
Training loss: 1.0008156299591064
Validation loss: 2.0912523368994393

Epoch: 5| Step: 7
Training loss: 0.746292769908905
Validation loss: 2.066250517964363

Epoch: 5| Step: 8
Training loss: 0.6853330731391907
Validation loss: 2.098813141385714

Epoch: 5| Step: 9
Training loss: 0.7245672345161438
Validation loss: 2.0920581817626953

Epoch: 5| Step: 10
Training loss: 0.6449691653251648
Validation loss: 2.114388629794121

Epoch: 5| Step: 11
Training loss: 0.5219813585281372
Validation loss: 2.146320809920629

Epoch: 532| Step: 0
Training loss: 0.8582043647766113
Validation loss: 2.0762153019507728

Epoch: 5| Step: 1
Training loss: 1.3514690399169922
Validation loss: 2.0454068978627524

Epoch: 5| Step: 2
Training loss: 0.7916398644447327
Validation loss: 2.090176905194918

Epoch: 5| Step: 3
Training loss: 0.8326429128646851
Validation loss: 2.1000592509905496

Epoch: 5| Step: 4
Training loss: 0.34459295868873596
Validation loss: 2.102675730983416

Epoch: 5| Step: 5
Training loss: 0.5554973483085632
Validation loss: 2.070305680235227

Epoch: 5| Step: 6
Training loss: 0.5280117988586426
Validation loss: 2.036803017059962

Epoch: 5| Step: 7
Training loss: 0.8792420625686646
Validation loss: 2.031456117828687

Epoch: 5| Step: 8
Training loss: 1.1675736904144287
Validation loss: 2.0634207675854364

Epoch: 5| Step: 9
Training loss: 0.5925956964492798
Validation loss: 2.066157802939415

Epoch: 5| Step: 10
Training loss: 0.6749318242073059
Validation loss: 2.086960876981417

Epoch: 5| Step: 11
Training loss: 0.7955518960952759
Validation loss: 2.0616095860799155

Epoch: 533| Step: 0
Training loss: 1.3575036525726318
Validation loss: 2.121282011270523

Epoch: 5| Step: 1
Training loss: 0.6663144826889038
Validation loss: 2.1420773615439734

Epoch: 5| Step: 2
Training loss: 0.9419881105422974
Validation loss: 2.177995204925537

Epoch: 5| Step: 3
Training loss: 0.8695478439331055
Validation loss: 2.150925268729528

Epoch: 5| Step: 4
Training loss: 0.5174696445465088
Validation loss: 2.1501365353663764

Epoch: 5| Step: 5
Training loss: 0.6080164909362793
Validation loss: 2.0971536934375763

Epoch: 5| Step: 6
Training loss: 0.4386025369167328
Validation loss: 2.076721414923668

Epoch: 5| Step: 7
Training loss: 0.8180200457572937
Validation loss: 2.1011322240034738

Epoch: 5| Step: 8
Training loss: 0.9932041168212891
Validation loss: 2.106656218568484

Epoch: 5| Step: 9
Training loss: 0.7916821241378784
Validation loss: 2.0578479866186776

Epoch: 5| Step: 10
Training loss: 0.62724769115448
Validation loss: 2.0784752368927

Epoch: 5| Step: 11
Training loss: 0.4712035655975342
Validation loss: 2.0296079218387604

Epoch: 534| Step: 0
Training loss: 0.7139015793800354
Validation loss: 2.030468463897705

Epoch: 5| Step: 1
Training loss: 0.8541544079780579
Validation loss: 2.0217435906330743

Epoch: 5| Step: 2
Training loss: 0.7014104723930359
Validation loss: 2.022754445672035

Epoch: 5| Step: 3
Training loss: 0.7213387489318848
Validation loss: 2.0587936540444693

Epoch: 5| Step: 4
Training loss: 0.8893766403198242
Validation loss: 1.985806331038475

Epoch: 5| Step: 5
Training loss: 0.8158055543899536
Validation loss: 2.0443482349316278

Epoch: 5| Step: 6
Training loss: 0.28965815901756287
Validation loss: 2.032366762558619

Epoch: 5| Step: 7
Training loss: 0.5615525245666504
Validation loss: 2.064576322833697

Epoch: 5| Step: 8
Training loss: 0.8588066101074219
Validation loss: 2.1064108312129974

Epoch: 5| Step: 9
Training loss: 0.7510356903076172
Validation loss: 2.1491126914819083

Epoch: 5| Step: 10
Training loss: 0.6484796404838562
Validation loss: 2.098196178674698

Epoch: 5| Step: 11
Training loss: 0.762515664100647
Validation loss: 2.108232945203781

Epoch: 535| Step: 0
Training loss: 0.6622213125228882
Validation loss: 2.0980393340190253

Epoch: 5| Step: 1
Training loss: 0.37603816390037537
Validation loss: 2.0783990770578384

Epoch: 5| Step: 2
Training loss: 0.937125563621521
Validation loss: 2.077397952477137

Epoch: 5| Step: 3
Training loss: 0.6890928149223328
Validation loss: 2.0536781599124274

Epoch: 5| Step: 4
Training loss: 0.9538154602050781
Validation loss: 2.07549986243248

Epoch: 5| Step: 5
Training loss: 0.9967845678329468
Validation loss: 2.0641591250896454

Epoch: 5| Step: 6
Training loss: 0.4127657413482666
Validation loss: 2.0790756245454154

Epoch: 5| Step: 7
Training loss: 0.7120054960250854
Validation loss: 2.065394878387451

Epoch: 5| Step: 8
Training loss: 0.7145985960960388
Validation loss: 2.0864430318276086

Epoch: 5| Step: 9
Training loss: 0.822484016418457
Validation loss: 2.092242325345675

Epoch: 5| Step: 10
Training loss: 0.6821987628936768
Validation loss: 2.093800658981005

Epoch: 5| Step: 11
Training loss: 0.49236631393432617
Validation loss: 2.1129258573055267

Epoch: 536| Step: 0
Training loss: 1.0223418474197388
Validation loss: 2.0945601960023246

Epoch: 5| Step: 1
Training loss: 0.7615890502929688
Validation loss: 2.189255326986313

Epoch: 5| Step: 2
Training loss: 1.2631276845932007
Validation loss: 2.0991802712281546

Epoch: 5| Step: 3
Training loss: 0.5379411578178406
Validation loss: 2.135526860753695

Epoch: 5| Step: 4
Training loss: 0.6182152032852173
Validation loss: 2.0987528761227927

Epoch: 5| Step: 5
Training loss: 0.9061959981918335
Validation loss: 2.090211734175682

Epoch: 5| Step: 6
Training loss: 0.7019172310829163
Validation loss: 2.103966439763705

Epoch: 5| Step: 7
Training loss: 0.466248095035553
Validation loss: 2.0376246919234595

Epoch: 5| Step: 8
Training loss: 0.6993848085403442
Validation loss: 2.060294434428215

Epoch: 5| Step: 9
Training loss: 0.5907648205757141
Validation loss: 2.0585300624370575

Epoch: 5| Step: 10
Training loss: 0.7133551239967346
Validation loss: 2.051732470591863

Epoch: 5| Step: 11
Training loss: 0.46557700634002686
Validation loss: 2.0518102447191873

Epoch: 537| Step: 0
Training loss: 0.5938559770584106
Validation loss: 2.0571205466985703

Epoch: 5| Step: 1
Training loss: 1.0148398876190186
Validation loss: 2.12066542605559

Epoch: 5| Step: 2
Training loss: 0.6245296597480774
Validation loss: 2.0883817921082177

Epoch: 5| Step: 3
Training loss: 0.567620038986206
Validation loss: 2.1180724104245505

Epoch: 5| Step: 4
Training loss: 0.6436862349510193
Validation loss: 2.1079143633445105

Epoch: 5| Step: 5
Training loss: 1.2700748443603516
Validation loss: 2.1291493574778237

Epoch: 5| Step: 6
Training loss: 0.4874933362007141
Validation loss: 2.103524327278137

Epoch: 5| Step: 7
Training loss: 0.7236987352371216
Validation loss: 2.076579843958219

Epoch: 5| Step: 8
Training loss: 0.7411482930183411
Validation loss: 2.071045915285746

Epoch: 5| Step: 9
Training loss: 0.7018914222717285
Validation loss: 2.1334998408953347

Epoch: 5| Step: 10
Training loss: 0.3849833905696869
Validation loss: 2.10692768295606

Epoch: 5| Step: 11
Training loss: 0.810707688331604
Validation loss: 2.1205331087112427

Epoch: 538| Step: 0
Training loss: 0.7516969442367554
Validation loss: 2.0844733069340386

Epoch: 5| Step: 1
Training loss: 0.6899306774139404
Validation loss: 2.0807849913835526

Epoch: 5| Step: 2
Training loss: 0.5431956052780151
Validation loss: 2.0771347184975943

Epoch: 5| Step: 3
Training loss: 0.6829274892807007
Validation loss: 2.1176988035440445

Epoch: 5| Step: 4
Training loss: 0.9555310010910034
Validation loss: 2.1242990295092263

Epoch: 5| Step: 5
Training loss: 0.9699374437332153
Validation loss: 2.108925069371859

Epoch: 5| Step: 6
Training loss: 0.5316190123558044
Validation loss: 2.1234686026970544

Epoch: 5| Step: 7
Training loss: 1.073921799659729
Validation loss: 2.152239665389061

Epoch: 5| Step: 8
Training loss: 0.820110023021698
Validation loss: 2.1473523527383804

Epoch: 5| Step: 9
Training loss: 0.5587044358253479
Validation loss: 2.178429370125135

Epoch: 5| Step: 10
Training loss: 0.8114314079284668
Validation loss: 2.202545548478762

Epoch: 5| Step: 11
Training loss: 1.5211840867996216
Validation loss: 2.1842537373304367

Epoch: 539| Step: 0
Training loss: 0.6609542369842529
Validation loss: 2.224267835418383

Epoch: 5| Step: 1
Training loss: 0.7146681547164917
Validation loss: 2.1483443826436996

Epoch: 5| Step: 2
Training loss: 0.4550725817680359
Validation loss: 2.183450842897097

Epoch: 5| Step: 3
Training loss: 0.6560763120651245
Validation loss: 2.1634173691272736

Epoch: 5| Step: 4
Training loss: 0.6412596702575684
Validation loss: 2.1132830530405045

Epoch: 5| Step: 5
Training loss: 0.7011159658432007
Validation loss: 2.1364327371120453

Epoch: 5| Step: 6
Training loss: 0.921517014503479
Validation loss: 2.094988246758779

Epoch: 5| Step: 7
Training loss: 0.9086520075798035
Validation loss: 2.063814510901769

Epoch: 5| Step: 8
Training loss: 0.3203561305999756
Validation loss: 2.0345289756854377

Epoch: 5| Step: 9
Training loss: 1.2505457401275635
Validation loss: 2.0703654289245605

Epoch: 5| Step: 10
Training loss: 0.9190425872802734
Validation loss: 2.0178654889265695

Epoch: 5| Step: 11
Training loss: 0.17880842089653015
Validation loss: 2.062316060066223

Epoch: 540| Step: 0
Training loss: 0.6076096892356873
Validation loss: 2.0325271487236023

Epoch: 5| Step: 1
Training loss: 1.375745415687561
Validation loss: 2.0413651516040168

Epoch: 5| Step: 2
Training loss: 0.8611184358596802
Validation loss: 2.0580933143695197

Epoch: 5| Step: 3
Training loss: 0.37417274713516235
Validation loss: 2.0243802865346274

Epoch: 5| Step: 4
Training loss: 0.6819416284561157
Validation loss: 2.0490893572568893

Epoch: 5| Step: 5
Training loss: 0.7553778290748596
Validation loss: 2.0947418908278146

Epoch: 5| Step: 6
Training loss: 1.3128539323806763
Validation loss: 2.066926230986913

Epoch: 5| Step: 7
Training loss: 0.45451074838638306
Validation loss: 2.1219928016265235

Epoch: 5| Step: 8
Training loss: 0.7984797358512878
Validation loss: 2.0892652769883475

Epoch: 5| Step: 9
Training loss: 0.4409312307834625
Validation loss: 2.1535263657569885

Epoch: 5| Step: 10
Training loss: 0.48053330183029175
Validation loss: 2.0812638898690543

Epoch: 5| Step: 11
Training loss: 1.3279755115509033
Validation loss: 2.1116064488887787

Epoch: 541| Step: 0
Training loss: 0.5172923803329468
Validation loss: 2.0889567782481513

Epoch: 5| Step: 1
Training loss: 0.5741145610809326
Validation loss: 2.09047902127107

Epoch: 5| Step: 2
Training loss: 0.6868489384651184
Validation loss: 2.1185019512971244

Epoch: 5| Step: 3
Training loss: 0.39239218831062317
Validation loss: 2.0901046842336655

Epoch: 5| Step: 4
Training loss: 0.6489218473434448
Validation loss: 2.1194694389899573

Epoch: 5| Step: 5
Training loss: 0.7906330227851868
Validation loss: 2.141866241892179

Epoch: 5| Step: 6
Training loss: 0.943926990032196
Validation loss: 2.099179004629453

Epoch: 5| Step: 7
Training loss: 0.7112852931022644
Validation loss: 2.0953524063030877

Epoch: 5| Step: 8
Training loss: 0.6110878586769104
Validation loss: 2.0737892041603723

Epoch: 5| Step: 9
Training loss: 0.8858059048652649
Validation loss: 2.0644731173912683

Epoch: 5| Step: 10
Training loss: 0.941491425037384
Validation loss: 2.1068380922079086

Epoch: 5| Step: 11
Training loss: 0.631472110748291
Validation loss: 2.156074116627375

Epoch: 542| Step: 0
Training loss: 0.5330986380577087
Validation loss: 2.100511461496353

Epoch: 5| Step: 1
Training loss: 0.617168128490448
Validation loss: 2.101250544190407

Epoch: 5| Step: 2
Training loss: 1.1837244033813477
Validation loss: 2.1017316033442817

Epoch: 5| Step: 3
Training loss: 0.8871585726737976
Validation loss: 2.1255446523427963

Epoch: 5| Step: 4
Training loss: 0.5744484663009644
Validation loss: 2.125679483016332

Epoch: 5| Step: 5
Training loss: 0.4756163954734802
Validation loss: 2.13362717628479

Epoch: 5| Step: 6
Training loss: 0.9479466676712036
Validation loss: 2.1049425651629767

Epoch: 5| Step: 7
Training loss: 0.699801504611969
Validation loss: 2.142283042271932

Epoch: 5| Step: 8
Training loss: 0.8113375902175903
Validation loss: 2.1570005218187966

Epoch: 5| Step: 9
Training loss: 0.4411209523677826
Validation loss: 2.120459238688151

Epoch: 5| Step: 10
Training loss: 0.9616729617118835
Validation loss: 2.1512830555438995

Epoch: 5| Step: 11
Training loss: 0.9817709922790527
Validation loss: 2.1289228796958923

Epoch: 543| Step: 0
Training loss: 0.8412612080574036
Validation loss: 2.17816424369812

Epoch: 5| Step: 1
Training loss: 0.6552672386169434
Validation loss: 2.1745538910230002

Epoch: 5| Step: 2
Training loss: 0.706135094165802
Validation loss: 2.125316008925438

Epoch: 5| Step: 3
Training loss: 0.9659783244132996
Validation loss: 2.094652126232783

Epoch: 5| Step: 4
Training loss: 0.6267187595367432
Validation loss: 2.1251442233721414

Epoch: 5| Step: 5
Training loss: 0.8843919634819031
Validation loss: 2.063221221168836

Epoch: 5| Step: 6
Training loss: 0.7201508283615112
Validation loss: 2.142709255218506

Epoch: 5| Step: 7
Training loss: 0.726477861404419
Validation loss: 2.0506846557060876

Epoch: 5| Step: 8
Training loss: 0.8910598754882812
Validation loss: 2.1172322829564414

Epoch: 5| Step: 9
Training loss: 0.7303460836410522
Validation loss: 2.0996276289224625

Epoch: 5| Step: 10
Training loss: 0.6537655591964722
Validation loss: 2.0797290156284967

Epoch: 5| Step: 11
Training loss: 0.4840753972530365
Validation loss: 2.102616677681605

Epoch: 544| Step: 0
Training loss: 1.0520844459533691
Validation loss: 2.140498807032903

Epoch: 5| Step: 1
Training loss: 0.6873698234558105
Validation loss: 2.1338513692220054

Epoch: 5| Step: 2
Training loss: 1.4915874004364014
Validation loss: 2.14851051568985

Epoch: 5| Step: 3
Training loss: 0.8524460792541504
Validation loss: 2.1290486504634223

Epoch: 5| Step: 4
Training loss: 0.4986301064491272
Validation loss: 2.098384921749433

Epoch: 5| Step: 5
Training loss: 0.7555172443389893
Validation loss: 2.073306073745092

Epoch: 5| Step: 6
Training loss: 0.6656426787376404
Validation loss: 2.0839122931162515

Epoch: 5| Step: 7
Training loss: 0.7520605325698853
Validation loss: 2.1111439963181815

Epoch: 5| Step: 8
Training loss: 0.5920470356941223
Validation loss: 2.1443735460440316

Epoch: 5| Step: 9
Training loss: 0.730330228805542
Validation loss: 2.133103604118029

Epoch: 5| Step: 10
Training loss: 0.7528473734855652
Validation loss: 2.0673745522896447

Epoch: 5| Step: 11
Training loss: 0.20249536633491516
Validation loss: 2.1368808646996817

Epoch: 545| Step: 0
Training loss: 1.03682541847229
Validation loss: 2.1314459343751273

Epoch: 5| Step: 1
Training loss: 0.752134382724762
Validation loss: 2.1469770123561225

Epoch: 5| Step: 2
Training loss: 1.0187021493911743
Validation loss: 2.1319159070650735

Epoch: 5| Step: 3
Training loss: 0.4996398985385895
Validation loss: 2.1220672925313315

Epoch: 5| Step: 4
Training loss: 1.0725773572921753
Validation loss: 2.0858987073103585

Epoch: 5| Step: 5
Training loss: 0.5849727392196655
Validation loss: 2.0509092956781387

Epoch: 5| Step: 6
Training loss: 0.5860227942466736
Validation loss: 2.1019730816284814

Epoch: 5| Step: 7
Training loss: 0.8511083722114563
Validation loss: 2.0838945358991623

Epoch: 5| Step: 8
Training loss: 0.42689019441604614
Validation loss: 2.145303795735041

Epoch: 5| Step: 9
Training loss: 0.6786513924598694
Validation loss: 2.1091334025065103

Epoch: 5| Step: 10
Training loss: 0.7033787369728088
Validation loss: 2.0978829662005105

Epoch: 5| Step: 11
Training loss: 0.5866143703460693
Validation loss: 2.1324695299069085

Epoch: 546| Step: 0
Training loss: 0.5606846809387207
Validation loss: 2.109533170859019

Epoch: 5| Step: 1
Training loss: 0.6378677487373352
Validation loss: 2.10045662522316

Epoch: 5| Step: 2
Training loss: 0.5236333608627319
Validation loss: 2.127268294493357

Epoch: 5| Step: 3
Training loss: 0.555057168006897
Validation loss: 2.1203895211219788

Epoch: 5| Step: 4
Training loss: 0.7521807551383972
Validation loss: 2.0783068339029946

Epoch: 5| Step: 5
Training loss: 0.4632355272769928
Validation loss: 2.0813537687063217

Epoch: 5| Step: 6
Training loss: 0.7117694020271301
Validation loss: 2.063201904296875

Epoch: 5| Step: 7
Training loss: 0.695827841758728
Validation loss: 2.1046654880046844

Epoch: 5| Step: 8
Training loss: 1.051342487335205
Validation loss: 2.0776967952648797

Epoch: 5| Step: 9
Training loss: 0.5495713949203491
Validation loss: 2.1244563311338425

Epoch: 5| Step: 10
Training loss: 1.2746628522872925
Validation loss: 2.055042122801145

Epoch: 5| Step: 11
Training loss: 0.7485293745994568
Validation loss: 2.0752226213614144

Epoch: 547| Step: 0
Training loss: 0.5307314991950989
Validation loss: 2.1013093441724777

Epoch: 5| Step: 1
Training loss: 0.9621309041976929
Validation loss: 2.080006574591001

Epoch: 5| Step: 2
Training loss: 0.448386013507843
Validation loss: 2.0644136319557824

Epoch: 5| Step: 3
Training loss: 0.70992511510849
Validation loss: 2.0339003801345825

Epoch: 5| Step: 4
Training loss: 0.5918982028961182
Validation loss: 2.03639018535614

Epoch: 5| Step: 5
Training loss: 0.6800438165664673
Validation loss: 2.0441446006298065

Epoch: 5| Step: 6
Training loss: 0.7081220149993896
Validation loss: 2.0694667945305505

Epoch: 5| Step: 7
Training loss: 0.8266820907592773
Validation loss: 2.0372610638538995

Epoch: 5| Step: 8
Training loss: 0.5215137600898743
Validation loss: 2.033256694674492

Epoch: 5| Step: 9
Training loss: 0.6085835695266724
Validation loss: 2.023354098200798

Epoch: 5| Step: 10
Training loss: 1.1041810512542725
Validation loss: 2.0490762243668237

Epoch: 5| Step: 11
Training loss: 0.24392163753509521
Validation loss: 2.0813075403372445

Epoch: 548| Step: 0
Training loss: 0.5993987917900085
Validation loss: 2.0221495827039084

Epoch: 5| Step: 1
Training loss: 0.4875200390815735
Validation loss: 2.0600945204496384

Epoch: 5| Step: 2
Training loss: 0.6495863199234009
Validation loss: 2.077469219764074

Epoch: 5| Step: 3
Training loss: 0.6419100761413574
Validation loss: 2.0815524756908417

Epoch: 5| Step: 4
Training loss: 0.43196535110473633
Validation loss: 2.106424684325854

Epoch: 5| Step: 5
Training loss: 0.5638729333877563
Validation loss: 2.0832775433858237

Epoch: 5| Step: 6
Training loss: 0.8133841753005981
Validation loss: 2.1512108792861304

Epoch: 5| Step: 7
Training loss: 0.8068097829818726
Validation loss: 2.1093711306651435

Epoch: 5| Step: 8
Training loss: 0.6741289496421814
Validation loss: 2.152801195780436

Epoch: 5| Step: 9
Training loss: 0.5429753065109253
Validation loss: 2.1668370366096497

Epoch: 5| Step: 10
Training loss: 0.8545524477958679
Validation loss: 2.1478440364201865

Epoch: 5| Step: 11
Training loss: 2.4528450965881348
Validation loss: 2.1341593513886132

Epoch: 549| Step: 0
Training loss: 0.9515711069107056
Validation loss: 2.16147980093956

Epoch: 5| Step: 1
Training loss: 1.051595687866211
Validation loss: 2.173645332455635

Epoch: 5| Step: 2
Training loss: 0.4250103831291199
Validation loss: 2.1742656230926514

Epoch: 5| Step: 3
Training loss: 0.9134587049484253
Validation loss: 2.132426227132479

Epoch: 5| Step: 4
Training loss: 0.7410238981246948
Validation loss: 2.13099604845047

Epoch: 5| Step: 5
Training loss: 0.45531219244003296
Validation loss: 2.096693361798922

Epoch: 5| Step: 6
Training loss: 0.7644342184066772
Validation loss: 2.088271662592888

Epoch: 5| Step: 7
Training loss: 0.6067416667938232
Validation loss: 2.102058837811152

Epoch: 5| Step: 8
Training loss: 0.8237409591674805
Validation loss: 2.0744787752628326

Epoch: 5| Step: 9
Training loss: 0.7954369783401489
Validation loss: 2.1387839913368225

Epoch: 5| Step: 10
Training loss: 0.5143739581108093
Validation loss: 2.0906633784373603

Epoch: 5| Step: 11
Training loss: 0.5065829753875732
Validation loss: 2.107884402076403

Epoch: 550| Step: 0
Training loss: 1.0150907039642334
Validation loss: 2.1310936907927194

Epoch: 5| Step: 1
Training loss: 0.97088623046875
Validation loss: 2.1748416423797607

Epoch: 5| Step: 2
Training loss: 0.8391705751419067
Validation loss: 2.2112679382165275

Epoch: 5| Step: 3
Training loss: 0.6545175313949585
Validation loss: 2.245128611723582

Epoch: 5| Step: 4
Training loss: 0.3597608506679535
Validation loss: 2.191626787185669

Epoch: 5| Step: 5
Training loss: 0.5110573768615723
Validation loss: 2.1382238417863846

Epoch: 5| Step: 6
Training loss: 0.6966545581817627
Validation loss: 2.134042431910833

Epoch: 5| Step: 7
Training loss: 0.6502628326416016
Validation loss: 2.1259948164224625

Epoch: 5| Step: 8
Training loss: 0.3830799460411072
Validation loss: 2.1239347209533057

Epoch: 5| Step: 9
Training loss: 0.8437343835830688
Validation loss: 2.1266561299562454

Epoch: 5| Step: 10
Training loss: 0.8181601762771606
Validation loss: 2.1213850528001785

Epoch: 5| Step: 11
Training loss: 2.5394015312194824
Validation loss: 2.0674806982278824

Testing loss: 1.8915835147281346
