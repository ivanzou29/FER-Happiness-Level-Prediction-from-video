Epoch: 1| Step: 0
Training loss: 5.224154472351074
Validation loss: 5.281996329625447

Epoch: 6| Step: 1
Training loss: 5.555899620056152
Validation loss: 5.2802674770355225

Epoch: 6| Step: 2
Training loss: 4.386590957641602
Validation loss: 5.278556029001872

Epoch: 6| Step: 3
Training loss: 4.671300888061523
Validation loss: 5.276837189992269

Epoch: 6| Step: 4
Training loss: 5.389982223510742
Validation loss: 5.2750701904296875

Epoch: 6| Step: 5
Training loss: 5.54287576675415
Validation loss: 5.273239493370056

Epoch: 6| Step: 6
Training loss: 4.797913074493408
Validation loss: 5.271435658137004

Epoch: 6| Step: 7
Training loss: 4.909762382507324
Validation loss: 5.269482692082723

Epoch: 6| Step: 8
Training loss: 5.210782527923584
Validation loss: 5.267556190490723

Epoch: 6| Step: 9
Training loss: 4.823480129241943
Validation loss: 5.265435218811035

Epoch: 6| Step: 10
Training loss: 5.926560401916504
Validation loss: 5.263291517893474

Epoch: 6| Step: 11
Training loss: 6.256107330322266
Validation loss: 5.261065721511841

Epoch: 6| Step: 12
Training loss: 6.020443439483643
Validation loss: 5.25875186920166

Epoch: 6| Step: 13
Training loss: 6.031310558319092
Validation loss: 5.2561936378479

Epoch: 2| Step: 0
Training loss: 4.456973075866699
Validation loss: 5.253686587015788

Epoch: 6| Step: 1
Training loss: 4.346262454986572
Validation loss: 5.25100048383077

Epoch: 6| Step: 2
Training loss: 4.531571388244629
Validation loss: 5.2481420040130615

Epoch: 6| Step: 3
Training loss: 6.510285377502441
Validation loss: 5.245262702306111

Epoch: 6| Step: 4
Training loss: 4.9751081466674805
Validation loss: 5.242071231206258

Epoch: 6| Step: 5
Training loss: 5.942285537719727
Validation loss: 5.238749186197917

Epoch: 6| Step: 6
Training loss: 5.648967742919922
Validation loss: 5.235315799713135

Epoch: 6| Step: 7
Training loss: 6.507890701293945
Validation loss: 5.2316146691640215

Epoch: 6| Step: 8
Training loss: 5.184629440307617
Validation loss: 5.2278032302856445

Epoch: 6| Step: 9
Training loss: 5.4604291915893555
Validation loss: 5.223718166351318

Epoch: 6| Step: 10
Training loss: 5.612965106964111
Validation loss: 5.21960695584615

Epoch: 6| Step: 11
Training loss: 4.999822616577148
Validation loss: 5.2149481773376465

Epoch: 6| Step: 12
Training loss: 5.190287113189697
Validation loss: 5.210198799769084

Epoch: 6| Step: 13
Training loss: 4.860143661499023
Validation loss: 5.2054628531138105

Epoch: 3| Step: 0
Training loss: 5.612175464630127
Validation loss: 5.2000406583150225

Epoch: 6| Step: 1
Training loss: 5.500274658203125
Validation loss: 5.194610516230266

Epoch: 6| Step: 2
Training loss: 6.000607490539551
Validation loss: 5.188718398412068

Epoch: 6| Step: 3
Training loss: 4.184332370758057
Validation loss: 5.182746529579163

Epoch: 6| Step: 4
Training loss: 4.613985538482666
Validation loss: 5.1764834721883135

Epoch: 6| Step: 5
Training loss: 6.034788608551025
Validation loss: 5.169816176096599

Epoch: 6| Step: 6
Training loss: 5.068088531494141
Validation loss: 5.1629288991292315

Epoch: 6| Step: 7
Training loss: 5.661458969116211
Validation loss: 5.155644377072652

Epoch: 6| Step: 8
Training loss: 4.420985221862793
Validation loss: 5.148145993550618

Epoch: 6| Step: 9
Training loss: 5.798243045806885
Validation loss: 5.140386343002319

Epoch: 6| Step: 10
Training loss: 5.031158924102783
Validation loss: 5.132353703180949

Epoch: 6| Step: 11
Training loss: 4.988167762756348
Validation loss: 5.1242759227752686

Epoch: 6| Step: 12
Training loss: 5.407966136932373
Validation loss: 5.115585009256999

Epoch: 6| Step: 13
Training loss: 4.897837162017822
Validation loss: 5.107119878133138

Epoch: 4| Step: 0
Training loss: 5.433244705200195
Validation loss: 5.098157485326131

Epoch: 6| Step: 1
Training loss: 4.296639442443848
Validation loss: 5.089139461517334

Epoch: 6| Step: 2
Training loss: 5.0607171058654785
Validation loss: 5.079967737197876

Epoch: 6| Step: 3
Training loss: 4.799829483032227
Validation loss: 5.070719083150228

Epoch: 6| Step: 4
Training loss: 5.31801700592041
Validation loss: 5.0611608028411865

Epoch: 6| Step: 5
Training loss: 5.685268878936768
Validation loss: 5.0513796011606855

Epoch: 6| Step: 6
Training loss: 5.741238594055176
Validation loss: 5.041901270548503

Epoch: 6| Step: 7
Training loss: 4.384183883666992
Validation loss: 5.032052119572957

Epoch: 6| Step: 8
Training loss: 4.945808410644531
Validation loss: 5.022351662317912

Epoch: 6| Step: 9
Training loss: 4.529606819152832
Validation loss: 5.012717644373576

Epoch: 6| Step: 10
Training loss: 5.256191253662109
Validation loss: 5.002628803253174

Epoch: 6| Step: 11
Training loss: 5.060094833374023
Validation loss: 4.992904822031657

Epoch: 6| Step: 12
Training loss: 6.06412410736084
Validation loss: 4.9829065799713135

Epoch: 6| Step: 13
Training loss: 5.038713455200195
Validation loss: 4.973027944564819

Epoch: 5| Step: 0
Training loss: 5.524708271026611
Validation loss: 4.963116804758708

Epoch: 6| Step: 1
Training loss: 5.04683780670166
Validation loss: 4.953741470972697

Epoch: 6| Step: 2
Training loss: 5.092987060546875
Validation loss: 4.944136460622151

Epoch: 6| Step: 3
Training loss: 4.561381816864014
Validation loss: 4.9342736800511675

Epoch: 6| Step: 4
Training loss: 4.973176002502441
Validation loss: 4.924481153488159

Epoch: 6| Step: 5
Training loss: 4.9356184005737305
Validation loss: 4.915117820103963

Epoch: 6| Step: 6
Training loss: 5.030037879943848
Validation loss: 4.905806541442871

Epoch: 6| Step: 7
Training loss: 5.642006874084473
Validation loss: 4.896606683731079

Epoch: 6| Step: 8
Training loss: 5.196631908416748
Validation loss: 4.88692577679952

Epoch: 6| Step: 9
Training loss: 5.656035423278809
Validation loss: 4.876903772354126

Epoch: 6| Step: 10
Training loss: 4.225790977478027
Validation loss: 4.8668003877003985

Epoch: 6| Step: 11
Training loss: 4.250659465789795
Validation loss: 4.856416384379069

Epoch: 6| Step: 12
Training loss: 4.958598613739014
Validation loss: 4.846027771631877

Epoch: 6| Step: 13
Training loss: 4.717449188232422
Validation loss: 4.836191415786743

Epoch: 6| Step: 0
Training loss: 5.335746765136719
Validation loss: 4.825998703638713

Epoch: 6| Step: 1
Training loss: 5.249840259552002
Validation loss: 4.815917332967122

Epoch: 6| Step: 2
Training loss: 4.709524154663086
Validation loss: 4.805926243464152

Epoch: 6| Step: 3
Training loss: 5.582701683044434
Validation loss: 4.795687675476074

Epoch: 6| Step: 4
Training loss: 5.210603713989258
Validation loss: 4.784939209620158

Epoch: 6| Step: 5
Training loss: 4.699428558349609
Validation loss: 4.775436242421468

Epoch: 6| Step: 6
Training loss: 5.422019004821777
Validation loss: 4.765203555425008

Epoch: 6| Step: 7
Training loss: 4.53004789352417
Validation loss: 4.755436182022095

Epoch: 6| Step: 8
Training loss: 5.516751289367676
Validation loss: 4.745601654052734

Epoch: 6| Step: 9
Training loss: 5.641482353210449
Validation loss: 4.7359725634257

Epoch: 6| Step: 10
Training loss: 4.495238304138184
Validation loss: 4.726696411768596

Epoch: 6| Step: 11
Training loss: 3.483088493347168
Validation loss: 4.71770183245341

Epoch: 6| Step: 12
Training loss: 4.256203651428223
Validation loss: 4.7086555163065595

Epoch: 6| Step: 13
Training loss: 3.8161816596984863
Validation loss: 4.699981451034546

Epoch: 7| Step: 0
Training loss: 4.431936264038086
Validation loss: 4.691643953323364

Epoch: 6| Step: 1
Training loss: 4.869831085205078
Validation loss: 4.6827913125356035

Epoch: 6| Step: 2
Training loss: 4.304194450378418
Validation loss: 4.674345890680949

Epoch: 6| Step: 3
Training loss: 4.598548889160156
Validation loss: 4.666195750236511

Epoch: 6| Step: 4
Training loss: 4.943088531494141
Validation loss: 4.657658497492473

Epoch: 6| Step: 5
Training loss: 3.8654162883758545
Validation loss: 4.649373849232991

Epoch: 6| Step: 6
Training loss: 5.452075958251953
Validation loss: 4.641239484151204

Epoch: 6| Step: 7
Training loss: 3.9550094604492188
Validation loss: 4.633399724960327

Epoch: 6| Step: 8
Training loss: 4.339635372161865
Validation loss: 4.625418106714885

Epoch: 6| Step: 9
Training loss: 5.113462448120117
Validation loss: 4.617065350214641

Epoch: 6| Step: 10
Training loss: 5.844064712524414
Validation loss: 4.609081983566284

Epoch: 6| Step: 11
Training loss: 4.271054267883301
Validation loss: 4.600622256596883

Epoch: 6| Step: 12
Training loss: 5.662143230438232
Validation loss: 4.592675129572551

Epoch: 6| Step: 13
Training loss: 4.647287845611572
Validation loss: 4.584683736165364

Epoch: 8| Step: 0
Training loss: 3.833327293395996
Validation loss: 4.577002127965291

Epoch: 6| Step: 1
Training loss: 4.428731918334961
Validation loss: 4.569296558698018

Epoch: 6| Step: 2
Training loss: 4.447128772735596
Validation loss: 4.56173042456309

Epoch: 6| Step: 3
Training loss: 5.261928081512451
Validation loss: 4.553963979085286

Epoch: 6| Step: 4
Training loss: 5.552713871002197
Validation loss: 4.546136935551961

Epoch: 6| Step: 5
Training loss: 5.533208847045898
Validation loss: 4.538727521896362

Epoch: 6| Step: 6
Training loss: 5.266199111938477
Validation loss: 4.531225800514221

Epoch: 6| Step: 7
Training loss: 4.571558475494385
Validation loss: 4.523204604784648

Epoch: 6| Step: 8
Training loss: 4.025760650634766
Validation loss: 4.515754739443461

Epoch: 6| Step: 9
Training loss: 4.273529052734375
Validation loss: 4.507877548535665

Epoch: 6| Step: 10
Training loss: 4.750453472137451
Validation loss: 4.500099738438924

Epoch: 6| Step: 11
Training loss: 3.6128292083740234
Validation loss: 4.49172321955363

Epoch: 6| Step: 12
Training loss: 3.785921096801758
Validation loss: 4.482509175936381

Epoch: 6| Step: 13
Training loss: 5.501116752624512
Validation loss: 4.475270668665568

Epoch: 9| Step: 0
Training loss: 5.5514068603515625
Validation loss: 4.469111045201619

Epoch: 6| Step: 1
Training loss: 4.07116174697876
Validation loss: 4.4626452922821045

Epoch: 6| Step: 2
Training loss: 3.845911979675293
Validation loss: 4.455685178438823

Epoch: 6| Step: 3
Training loss: 5.326037406921387
Validation loss: 4.44902777671814

Epoch: 6| Step: 4
Training loss: 3.7772929668426514
Validation loss: 4.4426430861155195

Epoch: 6| Step: 5
Training loss: 4.335869789123535
Validation loss: 4.436370054880778

Epoch: 6| Step: 6
Training loss: 4.8895487785339355
Validation loss: 4.429789423942566

Epoch: 6| Step: 7
Training loss: 4.821369171142578
Validation loss: 4.423547347386678

Epoch: 6| Step: 8
Training loss: 5.043715953826904
Validation loss: 4.417115569114685

Epoch: 6| Step: 9
Training loss: 4.216317176818848
Validation loss: 4.410830179850261

Epoch: 6| Step: 10
Training loss: 4.301426887512207
Validation loss: 4.404909094174703

Epoch: 6| Step: 11
Training loss: 4.296421051025391
Validation loss: 4.399146795272827

Epoch: 6| Step: 12
Training loss: 4.476347923278809
Validation loss: 4.393853425979614

Epoch: 6| Step: 13
Training loss: 4.644289970397949
Validation loss: 4.388063033421834

Epoch: 10| Step: 0
Training loss: 3.8825435638427734
Validation loss: 4.382279475529988

Epoch: 6| Step: 1
Training loss: 5.214879989624023
Validation loss: 4.376700679461162

Epoch: 6| Step: 2
Training loss: 3.9257636070251465
Validation loss: 4.370271603266398

Epoch: 6| Step: 3
Training loss: 5.131562232971191
Validation loss: 4.364569187164307

Epoch: 6| Step: 4
Training loss: 5.412853240966797
Validation loss: 4.3584113121032715

Epoch: 6| Step: 5
Training loss: 4.567634582519531
Validation loss: 4.352293173472087

Epoch: 6| Step: 6
Training loss: 4.231128692626953
Validation loss: 4.34624171257019

Epoch: 6| Step: 7
Training loss: 4.039187431335449
Validation loss: 4.340258518854777

Epoch: 6| Step: 8
Training loss: 4.626619338989258
Validation loss: 4.334596157073975

Epoch: 6| Step: 9
Training loss: 4.849761962890625
Validation loss: 4.328277031580607

Epoch: 6| Step: 10
Training loss: 4.324214458465576
Validation loss: 4.32305892308553

Epoch: 6| Step: 11
Training loss: 4.091588973999023
Validation loss: 4.317161877950032

Epoch: 6| Step: 12
Training loss: 4.304227352142334
Validation loss: 4.311650037765503

Epoch: 6| Step: 13
Training loss: 3.908829689025879
Validation loss: 4.305573423703511

Epoch: 11| Step: 0
Training loss: 4.386948108673096
Validation loss: 4.299873987833659

Epoch: 6| Step: 1
Training loss: 5.301455497741699
Validation loss: 4.2939463059107466

Epoch: 6| Step: 2
Training loss: 4.213958740234375
Validation loss: 4.289120356241862

Epoch: 6| Step: 3
Training loss: 2.9480984210968018
Validation loss: 4.283199310302734

Epoch: 6| Step: 4
Training loss: 5.08699369430542
Validation loss: 4.278705875078837

Epoch: 6| Step: 5
Training loss: 3.0176076889038086
Validation loss: 4.2720738252003985

Epoch: 6| Step: 6
Training loss: 4.638149738311768
Validation loss: 4.266024311383565

Epoch: 6| Step: 7
Training loss: 4.319175720214844
Validation loss: 4.259698987007141

Epoch: 6| Step: 8
Training loss: 4.355493545532227
Validation loss: 4.254667639732361

Epoch: 6| Step: 9
Training loss: 5.114006042480469
Validation loss: 4.249984423319499

Epoch: 6| Step: 10
Training loss: 3.558264970779419
Validation loss: 4.244185209274292

Epoch: 6| Step: 11
Training loss: 4.321954727172852
Validation loss: 4.238741397857666

Epoch: 6| Step: 12
Training loss: 5.335970878601074
Validation loss: 4.233513077100118

Epoch: 6| Step: 13
Training loss: 4.889629364013672
Validation loss: 4.228006402651469

Epoch: 12| Step: 0
Training loss: 4.614358901977539
Validation loss: 4.222675641377767

Epoch: 6| Step: 1
Training loss: 4.260439872741699
Validation loss: 4.216805775960286

Epoch: 6| Step: 2
Training loss: 4.789854049682617
Validation loss: 4.211351712544759

Epoch: 6| Step: 3
Training loss: 3.936519145965576
Validation loss: 4.205807010332744

Epoch: 6| Step: 4
Training loss: 3.9264581203460693
Validation loss: 4.200539469718933

Epoch: 6| Step: 5
Training loss: 3.5263431072235107
Validation loss: 4.195260326067607

Epoch: 6| Step: 6
Training loss: 4.501551151275635
Validation loss: 4.189648469289144

Epoch: 6| Step: 7
Training loss: 4.171591758728027
Validation loss: 4.184041301409404

Epoch: 6| Step: 8
Training loss: 4.379343032836914
Validation loss: 4.178853551546733

Epoch: 6| Step: 9
Training loss: 4.560529708862305
Validation loss: 4.17298952738444

Epoch: 6| Step: 10
Training loss: 4.524653434753418
Validation loss: 4.167274912198384

Epoch: 6| Step: 11
Training loss: 4.550950050354004
Validation loss: 4.16223669052124

Epoch: 6| Step: 12
Training loss: 3.516446590423584
Validation loss: 4.155455827713013

Epoch: 6| Step: 13
Training loss: 5.24287223815918
Validation loss: 4.149961034456889

Epoch: 13| Step: 0
Training loss: 4.25221586227417
Validation loss: 4.144864439964294

Epoch: 6| Step: 1
Training loss: 3.700782299041748
Validation loss: 4.140133500099182

Epoch: 6| Step: 2
Training loss: 5.00435733795166
Validation loss: 4.132858196894328

Epoch: 6| Step: 3
Training loss: 4.001430511474609
Validation loss: 4.127846956253052

Epoch: 6| Step: 4
Training loss: 5.374115467071533
Validation loss: 4.1217853625615435

Epoch: 6| Step: 5
Training loss: 4.149992942810059
Validation loss: 4.115262428919475

Epoch: 6| Step: 6
Training loss: 4.257659435272217
Validation loss: 4.108908136685689

Epoch: 6| Step: 7
Training loss: 3.5932223796844482
Validation loss: 4.10285496711731

Epoch: 6| Step: 8
Training loss: 2.970898151397705
Validation loss: 4.096601406733195

Epoch: 6| Step: 9
Training loss: 4.313082695007324
Validation loss: 4.092345674832662

Epoch: 6| Step: 10
Training loss: 4.342128753662109
Validation loss: 4.085612495740254

Epoch: 6| Step: 11
Training loss: 4.552231311798096
Validation loss: 4.078529477119446

Epoch: 6| Step: 12
Training loss: 5.236016750335693
Validation loss: 4.072357336680095

Epoch: 6| Step: 13
Training loss: 3.6972174644470215
Validation loss: 4.067031184832255

Epoch: 14| Step: 0
Training loss: 4.2912492752075195
Validation loss: 4.061664422353108

Epoch: 6| Step: 1
Training loss: 3.9625144004821777
Validation loss: 4.056378920873006

Epoch: 6| Step: 2
Training loss: 3.595079183578491
Validation loss: 4.050318201382955

Epoch: 6| Step: 3
Training loss: 4.334508895874023
Validation loss: 4.045044581095378

Epoch: 6| Step: 4
Training loss: 3.8430211544036865
Validation loss: 4.040710846583049

Epoch: 6| Step: 5
Training loss: 4.512267589569092
Validation loss: 4.033620715141296

Epoch: 6| Step: 6
Training loss: 4.280519962310791
Validation loss: 4.0281485716501875

Epoch: 6| Step: 7
Training loss: 3.7267041206359863
Validation loss: 4.021777073542277

Epoch: 6| Step: 8
Training loss: 4.265685081481934
Validation loss: 4.016338229179382

Epoch: 6| Step: 9
Training loss: 5.177214622497559
Validation loss: 4.011376142501831

Epoch: 6| Step: 10
Training loss: 4.627039909362793
Validation loss: 4.006274898846944

Epoch: 6| Step: 11
Training loss: 3.7395834922790527
Validation loss: 4.001194357872009

Epoch: 6| Step: 12
Training loss: 3.678563356399536
Validation loss: 3.9956032037734985

Epoch: 6| Step: 13
Training loss: 4.33369255065918
Validation loss: 3.990461985270182

Epoch: 15| Step: 0
Training loss: 4.313968658447266
Validation loss: 3.9842769304911294

Epoch: 6| Step: 1
Training loss: 4.465078353881836
Validation loss: 3.979490796724955

Epoch: 6| Step: 2
Training loss: 4.072050094604492
Validation loss: 3.974588314692179

Epoch: 6| Step: 3
Training loss: 3.699162721633911
Validation loss: 3.968413511912028

Epoch: 6| Step: 4
Training loss: 4.605238914489746
Validation loss: 3.9629501501719155

Epoch: 6| Step: 5
Training loss: 3.8662240505218506
Validation loss: 3.957521915435791

Epoch: 6| Step: 6
Training loss: 4.290336608886719
Validation loss: 3.952825983365377

Epoch: 6| Step: 7
Training loss: 3.906062602996826
Validation loss: 3.947318196296692

Epoch: 6| Step: 8
Training loss: 3.3459219932556152
Validation loss: 3.9417781829833984

Epoch: 6| Step: 9
Training loss: 4.35563850402832
Validation loss: 3.936246395111084

Epoch: 6| Step: 10
Training loss: 4.6367998123168945
Validation loss: 3.931230068206787

Epoch: 6| Step: 11
Training loss: 3.2983570098876953
Validation loss: 3.9261240561803183

Epoch: 6| Step: 12
Training loss: 4.97669792175293
Validation loss: 3.921306769053141

Epoch: 6| Step: 13
Training loss: 3.5362319946289062
Validation loss: 3.9156159162521362

Epoch: 16| Step: 0
Training loss: 4.308864593505859
Validation loss: 3.911625067392985

Epoch: 6| Step: 1
Training loss: 3.7980542182922363
Validation loss: 3.905586004257202

Epoch: 6| Step: 2
Training loss: 4.100354194641113
Validation loss: 3.9006271362304688

Epoch: 6| Step: 3
Training loss: 3.4408700466156006
Validation loss: 3.896584709485372

Epoch: 6| Step: 4
Training loss: 4.214844703674316
Validation loss: 3.8920714457829795

Epoch: 6| Step: 5
Training loss: 4.218600273132324
Validation loss: 3.8871763149897256

Epoch: 6| Step: 6
Training loss: 3.3939976692199707
Validation loss: 3.881072759628296

Epoch: 6| Step: 7
Training loss: 3.4312081336975098
Validation loss: 3.876655340194702

Epoch: 6| Step: 8
Training loss: 4.121951580047607
Validation loss: 3.872127811113993

Epoch: 6| Step: 9
Training loss: 4.17366886138916
Validation loss: 3.867053508758545

Epoch: 6| Step: 10
Training loss: 4.621485710144043
Validation loss: 3.861401160558065

Epoch: 6| Step: 11
Training loss: 5.0599164962768555
Validation loss: 3.8564348618189492

Epoch: 6| Step: 12
Training loss: 3.5074591636657715
Validation loss: 3.85154136021932

Epoch: 6| Step: 13
Training loss: 4.01403284072876
Validation loss: 3.847333312034607

Epoch: 17| Step: 0
Training loss: 3.6251063346862793
Validation loss: 3.8424634536107383

Epoch: 6| Step: 1
Training loss: 3.531521797180176
Validation loss: 3.8371545473734536

Epoch: 6| Step: 2
Training loss: 3.6297245025634766
Validation loss: 3.832170526186625

Epoch: 6| Step: 3
Training loss: 4.256927490234375
Validation loss: 3.8268447319666543

Epoch: 6| Step: 4
Training loss: 3.9173266887664795
Validation loss: 3.8230692545572915

Epoch: 6| Step: 5
Training loss: 4.126550197601318
Validation loss: 3.8181427319844565

Epoch: 6| Step: 6
Training loss: 3.033970832824707
Validation loss: 3.8128273487091064

Epoch: 6| Step: 7
Training loss: 3.3566412925720215
Validation loss: 3.8076618909835815

Epoch: 6| Step: 8
Training loss: 4.392829895019531
Validation loss: 3.802641828854879

Epoch: 6| Step: 9
Training loss: 3.510162353515625
Validation loss: 3.799819032351176

Epoch: 6| Step: 10
Training loss: 4.953769683837891
Validation loss: 3.796741803487142

Epoch: 6| Step: 11
Training loss: 5.571924686431885
Validation loss: 3.791193167368571

Epoch: 6| Step: 12
Training loss: 3.4137794971466064
Validation loss: 3.785357038180033

Epoch: 6| Step: 13
Training loss: 4.203033447265625
Validation loss: 3.7803348700205484

Epoch: 18| Step: 0
Training loss: 4.71351432800293
Validation loss: 3.7767663399378457

Epoch: 6| Step: 1
Training loss: 4.66737699508667
Validation loss: 3.7704018354415894

Epoch: 6| Step: 2
Training loss: 4.243032455444336
Validation loss: 3.7644534905751548

Epoch: 6| Step: 3
Training loss: 2.9694275856018066
Validation loss: 3.761068026224772

Epoch: 6| Step: 4
Training loss: 3.3690152168273926
Validation loss: 3.75630784034729

Epoch: 6| Step: 5
Training loss: 3.6508941650390625
Validation loss: 3.752123157183329

Epoch: 6| Step: 6
Training loss: 5.017490386962891
Validation loss: 3.747281869252523

Epoch: 6| Step: 7
Training loss: 4.8250274658203125
Validation loss: 3.7424976030985513

Epoch: 6| Step: 8
Training loss: 3.442610740661621
Validation loss: 3.7383912404378257

Epoch: 6| Step: 9
Training loss: 3.856084108352661
Validation loss: 3.7332684993743896

Epoch: 6| Step: 10
Training loss: 5.187314987182617
Validation loss: 3.7284305095672607

Epoch: 6| Step: 11
Training loss: 3.1285324096679688
Validation loss: 3.723745067914327

Epoch: 6| Step: 12
Training loss: 2.21565580368042
Validation loss: 3.7189914782842

Epoch: 6| Step: 13
Training loss: 3.3821492195129395
Validation loss: 3.714584708213806

Epoch: 19| Step: 0
Training loss: 4.145256042480469
Validation loss: 3.7104392449061074

Epoch: 6| Step: 1
Training loss: 3.1909658908843994
Validation loss: 3.7051390012105307

Epoch: 6| Step: 2
Training loss: 3.4529905319213867
Validation loss: 3.701310316721598

Epoch: 6| Step: 3
Training loss: 3.9011664390563965
Validation loss: 3.6969451904296875

Epoch: 6| Step: 4
Training loss: 4.446229934692383
Validation loss: 3.692316253980001

Epoch: 6| Step: 5
Training loss: 3.7518796920776367
Validation loss: 3.6880089044570923

Epoch: 6| Step: 6
Training loss: 3.7292728424072266
Validation loss: 3.683830897013346

Epoch: 6| Step: 7
Training loss: 3.766817092895508
Validation loss: 3.6798805395762124

Epoch: 6| Step: 8
Training loss: 3.2401976585388184
Validation loss: 3.675591071446737

Epoch: 6| Step: 9
Training loss: 4.854072093963623
Validation loss: 3.6710410515467324

Epoch: 6| Step: 10
Training loss: 3.797913074493408
Validation loss: 3.6663511594136557

Epoch: 6| Step: 11
Training loss: 3.2173962593078613
Validation loss: 3.6621197859446206

Epoch: 6| Step: 12
Training loss: 3.912332057952881
Validation loss: 3.659606417020162

Epoch: 6| Step: 13
Training loss: 4.392509460449219
Validation loss: 3.653782924016317

Epoch: 20| Step: 0
Training loss: 3.839634895324707
Validation loss: 3.648357311884562

Epoch: 6| Step: 1
Training loss: 4.662545204162598
Validation loss: 3.6440234184265137

Epoch: 6| Step: 2
Training loss: 4.333896636962891
Validation loss: 3.6398393313090005

Epoch: 6| Step: 3
Training loss: 3.2378242015838623
Validation loss: 3.6352049509684243

Epoch: 6| Step: 4
Training loss: 4.04335880279541
Validation loss: 3.6306148370107016

Epoch: 6| Step: 5
Training loss: 3.7358736991882324
Validation loss: 3.62528920173645

Epoch: 6| Step: 6
Training loss: 4.131298065185547
Validation loss: 3.6213430563608804

Epoch: 6| Step: 7
Training loss: 3.1530449390411377
Validation loss: 3.6167565186818442

Epoch: 6| Step: 8
Training loss: 3.740283966064453
Validation loss: 3.6117168267567954

Epoch: 6| Step: 9
Training loss: 3.3702781200408936
Validation loss: 3.607065200805664

Epoch: 6| Step: 10
Training loss: 4.30080509185791
Validation loss: 3.6019570430119834

Epoch: 6| Step: 11
Training loss: 3.850616455078125
Validation loss: 3.59768799940745

Epoch: 6| Step: 12
Training loss: 2.076809883117676
Validation loss: 3.5932724873224893

Epoch: 6| Step: 13
Training loss: 4.489541053771973
Validation loss: 3.588566700617472

Epoch: 21| Step: 0
Training loss: 3.8481709957122803
Validation loss: 3.583959698677063

Epoch: 6| Step: 1
Training loss: 4.219513893127441
Validation loss: 3.579349239667257

Epoch: 6| Step: 2
Training loss: 3.4497509002685547
Validation loss: 3.57482119401296

Epoch: 6| Step: 3
Training loss: 4.2999162673950195
Validation loss: 3.570139726003011

Epoch: 6| Step: 4
Training loss: 2.945981502532959
Validation loss: 3.565853238105774

Epoch: 6| Step: 5
Training loss: 4.492977142333984
Validation loss: 3.5608633359273276

Epoch: 6| Step: 6
Training loss: 3.5805187225341797
Validation loss: 3.556865652402242

Epoch: 6| Step: 7
Training loss: 4.086805820465088
Validation loss: 3.5518070062001548

Epoch: 6| Step: 8
Training loss: 4.0634307861328125
Validation loss: 3.5468665758768716

Epoch: 6| Step: 9
Training loss: 3.6526858806610107
Validation loss: 3.542417327562968

Epoch: 6| Step: 10
Training loss: 4.072693824768066
Validation loss: 3.5376188357671103

Epoch: 6| Step: 11
Training loss: 3.0078630447387695
Validation loss: 3.5326950550079346

Epoch: 6| Step: 12
Training loss: 3.873849868774414
Validation loss: 3.5283731619517007

Epoch: 6| Step: 13
Training loss: 2.4870502948760986
Validation loss: 3.5234683752059937

Epoch: 22| Step: 0
Training loss: 3.176112174987793
Validation loss: 3.518792668978373

Epoch: 6| Step: 1
Training loss: 2.933605670928955
Validation loss: 3.514200806617737

Epoch: 6| Step: 2
Training loss: 3.2243764400482178
Validation loss: 3.509846051534017

Epoch: 6| Step: 3
Training loss: 3.8194360733032227
Validation loss: 3.5052332878112793

Epoch: 6| Step: 4
Training loss: 4.571891784667969
Validation loss: 3.500727574030558

Epoch: 6| Step: 5
Training loss: 2.2557122707366943
Validation loss: 3.4962445894877114

Epoch: 6| Step: 6
Training loss: 4.987397193908691
Validation loss: 3.491267720858256

Epoch: 6| Step: 7
Training loss: 4.185654640197754
Validation loss: 3.4866432348887124

Epoch: 6| Step: 8
Training loss: 4.536841869354248
Validation loss: 3.48173455397288

Epoch: 6| Step: 9
Training loss: 4.064822196960449
Validation loss: 3.4771579106648765

Epoch: 6| Step: 10
Training loss: 3.9530861377716064
Validation loss: 3.4723309675852456

Epoch: 6| Step: 11
Training loss: 2.965637445449829
Validation loss: 3.4673966566721597

Epoch: 6| Step: 12
Training loss: 2.903799057006836
Validation loss: 3.4628530740737915

Epoch: 6| Step: 13
Training loss: 3.6189165115356445
Validation loss: 3.4587080478668213

Epoch: 23| Step: 0
Training loss: 2.9465506076812744
Validation loss: 3.4541578690210977

Epoch: 6| Step: 1
Training loss: 3.6909725666046143
Validation loss: 3.4504994551340737

Epoch: 6| Step: 2
Training loss: 3.793184280395508
Validation loss: 3.4450355768203735

Epoch: 6| Step: 3
Training loss: 3.801614284515381
Validation loss: 3.4406407276789346

Epoch: 6| Step: 4
Training loss: 3.481534004211426
Validation loss: 3.436110734939575

Epoch: 6| Step: 5
Training loss: 3.9900472164154053
Validation loss: 3.4320624272028604

Epoch: 6| Step: 6
Training loss: 4.312407970428467
Validation loss: 3.4266844193140664

Epoch: 6| Step: 7
Training loss: 3.134148597717285
Validation loss: 3.423260052998861

Epoch: 6| Step: 8
Training loss: 2.8359193801879883
Validation loss: 3.4189212322235107

Epoch: 6| Step: 9
Training loss: 3.951204538345337
Validation loss: 3.4144672950108848

Epoch: 6| Step: 10
Training loss: 3.1117348670959473
Validation loss: 3.4097906351089478

Epoch: 6| Step: 11
Training loss: 3.4951741695404053
Validation loss: 3.405767242113749

Epoch: 6| Step: 12
Training loss: 3.9985742568969727
Validation loss: 3.4012027184168496

Epoch: 6| Step: 13
Training loss: 3.7537121772766113
Validation loss: 3.3968267838160195

Epoch: 24| Step: 0
Training loss: 3.06428861618042
Validation loss: 3.3924200932184854

Epoch: 6| Step: 1
Training loss: 2.6791088581085205
Validation loss: 3.3881378968556723

Epoch: 6| Step: 2
Training loss: 2.9366488456726074
Validation loss: 3.3837232987085977

Epoch: 6| Step: 3
Training loss: 3.414052963256836
Validation loss: 3.379828850428263

Epoch: 6| Step: 4
Training loss: 4.750172138214111
Validation loss: 3.3754986921946206

Epoch: 6| Step: 5
Training loss: 3.6945600509643555
Validation loss: 3.37058162689209

Epoch: 6| Step: 6
Training loss: 4.123517036437988
Validation loss: 3.365738113721212

Epoch: 6| Step: 7
Training loss: 2.8059463500976562
Validation loss: 3.3614519437154136

Epoch: 6| Step: 8
Training loss: 3.986220359802246
Validation loss: 3.3574558099110923

Epoch: 6| Step: 9
Training loss: 4.139133453369141
Validation loss: 3.352752447128296

Epoch: 6| Step: 10
Training loss: 3.5800061225891113
Validation loss: 3.348042090733846

Epoch: 6| Step: 11
Training loss: 3.188443899154663
Validation loss: 3.3430597384770713

Epoch: 6| Step: 12
Training loss: 4.191043376922607
Validation loss: 3.3386995792388916

Epoch: 6| Step: 13
Training loss: 2.9254465103149414
Validation loss: 3.3344433307647705

Epoch: 25| Step: 0
Training loss: 4.014593124389648
Validation loss: 3.3299421072006226

Epoch: 6| Step: 1
Training loss: 2.797996997833252
Validation loss: 3.3252997398376465

Epoch: 6| Step: 2
Training loss: 3.495718002319336
Validation loss: 3.3209488789240518

Epoch: 6| Step: 3
Training loss: 4.042807579040527
Validation loss: 3.316782553990682

Epoch: 6| Step: 4
Training loss: 3.3839430809020996
Validation loss: 3.3124324878056846

Epoch: 6| Step: 5
Training loss: 3.499711751937866
Validation loss: 3.3078658183415732

Epoch: 6| Step: 6
Training loss: 3.6092705726623535
Validation loss: 3.3039538860321045

Epoch: 6| Step: 7
Training loss: 4.322549819946289
Validation loss: 3.2996515035629272

Epoch: 6| Step: 8
Training loss: 2.777292251586914
Validation loss: 3.295392910639445

Epoch: 6| Step: 9
Training loss: 3.0343122482299805
Validation loss: 3.291266759236654

Epoch: 6| Step: 10
Training loss: 3.4152305126190186
Validation loss: 3.2870960235595703

Epoch: 6| Step: 11
Training loss: 3.4076733589172363
Validation loss: 3.283019741376241

Epoch: 6| Step: 12
Training loss: 3.3980050086975098
Validation loss: 3.2787363131841025

Epoch: 6| Step: 13
Training loss: 3.4859752655029297
Validation loss: 3.2745740016301474

Epoch: 26| Step: 0
Training loss: 3.423396110534668
Validation loss: 3.2704273064931235

Epoch: 6| Step: 1
Training loss: 3.420769453048706
Validation loss: 3.265893260637919

Epoch: 6| Step: 2
Training loss: 3.1957244873046875
Validation loss: 3.262389858563741

Epoch: 6| Step: 3
Training loss: 2.909005880355835
Validation loss: 3.257939656575521

Epoch: 6| Step: 4
Training loss: 2.834963321685791
Validation loss: 3.253914395968119

Epoch: 6| Step: 5
Training loss: 4.443048477172852
Validation loss: 3.2499904235204062

Epoch: 6| Step: 6
Training loss: 3.242445707321167
Validation loss: 3.2452126344045005

Epoch: 6| Step: 7
Training loss: 1.8137991428375244
Validation loss: 3.2412883838017783

Epoch: 6| Step: 8
Training loss: 2.879537582397461
Validation loss: 3.237351973851522

Epoch: 6| Step: 9
Training loss: 3.3169233798980713
Validation loss: 3.234208861986796

Epoch: 6| Step: 10
Training loss: 3.7447750568389893
Validation loss: 3.2307045459747314

Epoch: 6| Step: 11
Training loss: 4.133388996124268
Validation loss: 3.2266536951065063

Epoch: 6| Step: 12
Training loss: 4.652493476867676
Validation loss: 3.223059892654419

Epoch: 6| Step: 13
Training loss: 3.910186529159546
Validation loss: 3.218636393547058

Epoch: 27| Step: 0
Training loss: 2.53120493888855
Validation loss: 3.2145378589630127

Epoch: 6| Step: 1
Training loss: 2.787540912628174
Validation loss: 3.210715413093567

Epoch: 6| Step: 2
Training loss: 3.764498233795166
Validation loss: 3.2068612575531006

Epoch: 6| Step: 3
Training loss: 3.275876045227051
Validation loss: 3.203496734301249

Epoch: 6| Step: 4
Training loss: 2.8128557205200195
Validation loss: 3.1994256178538003

Epoch: 6| Step: 5
Training loss: 2.951763868331909
Validation loss: 3.1957380771636963

Epoch: 6| Step: 6
Training loss: 3.3894691467285156
Validation loss: 3.1920098463694253

Epoch: 6| Step: 7
Training loss: 3.715031385421753
Validation loss: 3.188218434651693

Epoch: 6| Step: 8
Training loss: 3.394866466522217
Validation loss: 3.184127608935038

Epoch: 6| Step: 9
Training loss: 3.6851696968078613
Validation loss: 3.1804556846618652

Epoch: 6| Step: 10
Training loss: 3.6991474628448486
Validation loss: 3.1764177878697715

Epoch: 6| Step: 11
Training loss: 3.808607339859009
Validation loss: 3.172572692235311

Epoch: 6| Step: 12
Training loss: 4.054145812988281
Validation loss: 3.168266932169596

Epoch: 6| Step: 13
Training loss: 3.3107266426086426
Validation loss: 3.163946787516276

Epoch: 28| Step: 0
Training loss: 2.973975419998169
Validation loss: 3.1597198645273843

Epoch: 6| Step: 1
Training loss: 3.8696491718292236
Validation loss: 3.155846277872721

Epoch: 6| Step: 2
Training loss: 3.544752359390259
Validation loss: 3.151392141977946

Epoch: 6| Step: 3
Training loss: 2.382561683654785
Validation loss: 3.1474850177764893

Epoch: 6| Step: 4
Training loss: 3.1467199325561523
Validation loss: 3.1436752478281655

Epoch: 6| Step: 5
Training loss: 4.215102672576904
Validation loss: 3.139930764834086

Epoch: 6| Step: 6
Training loss: 3.376105785369873
Validation loss: 3.1354217529296875

Epoch: 6| Step: 7
Training loss: 3.8678035736083984
Validation loss: 3.1315035422643027

Epoch: 6| Step: 8
Training loss: 2.8254737854003906
Validation loss: 3.1271512508392334

Epoch: 6| Step: 9
Training loss: 3.2041306495666504
Validation loss: 3.1227873961130777

Epoch: 6| Step: 10
Training loss: 3.2901928424835205
Validation loss: 3.118317166964213

Epoch: 6| Step: 11
Training loss: 3.2424416542053223
Validation loss: 3.114774982134501

Epoch: 6| Step: 12
Training loss: 3.4854652881622314
Validation loss: 3.1106778383255005

Epoch: 6| Step: 13
Training loss: 3.0662240982055664
Validation loss: 3.106572985649109

Epoch: 29| Step: 0
Training loss: 3.3520705699920654
Validation loss: 3.102608799934387

Epoch: 6| Step: 1
Training loss: 3.5965988636016846
Validation loss: 3.0990470250447593

Epoch: 6| Step: 2
Training loss: 3.671102523803711
Validation loss: 3.095246950785319

Epoch: 6| Step: 3
Training loss: 3.4021878242492676
Validation loss: 3.0913185278574624

Epoch: 6| Step: 4
Training loss: 3.1339287757873535
Validation loss: 3.08828067779541

Epoch: 6| Step: 5
Training loss: 3.472423553466797
Validation loss: 3.0850574175516763

Epoch: 6| Step: 6
Training loss: 2.118086338043213
Validation loss: 3.0816141764322915

Epoch: 6| Step: 7
Training loss: 3.4792513847351074
Validation loss: 3.0786353747049966

Epoch: 6| Step: 8
Training loss: 3.5646440982818604
Validation loss: 3.0754650036493936

Epoch: 6| Step: 9
Training loss: 2.5976128578186035
Validation loss: 3.0721070369084678

Epoch: 6| Step: 10
Training loss: 2.7530970573425293
Validation loss: 3.068607052167257

Epoch: 6| Step: 11
Training loss: 2.6927807331085205
Validation loss: 3.064952532450358

Epoch: 6| Step: 12
Training loss: 4.549360275268555
Validation loss: 3.0616443157196045

Epoch: 6| Step: 13
Training loss: 3.375831127166748
Validation loss: 3.0577187140782676

Epoch: 30| Step: 0
Training loss: 2.6396994590759277
Validation loss: 3.0542650620142617

Epoch: 6| Step: 1
Training loss: 3.1658294200897217
Validation loss: 3.0509385665257773

Epoch: 6| Step: 2
Training loss: 3.6421284675598145
Validation loss: 3.0475252072016397

Epoch: 6| Step: 3
Training loss: 2.9770002365112305
Validation loss: 3.043719172477722

Epoch: 6| Step: 4
Training loss: 2.2259552478790283
Validation loss: 3.0404574473698935

Epoch: 6| Step: 5
Training loss: 3.4628348350524902
Validation loss: 3.0371007124582925

Epoch: 6| Step: 6
Training loss: 3.7874605655670166
Validation loss: 3.0337189038594565

Epoch: 6| Step: 7
Training loss: 2.6310949325561523
Validation loss: 3.0303988456726074

Epoch: 6| Step: 8
Training loss: 3.721224546432495
Validation loss: 3.0268542766571045

Epoch: 6| Step: 9
Training loss: 4.11536169052124
Validation loss: 3.023207346598307

Epoch: 6| Step: 10
Training loss: 2.5843191146850586
Validation loss: 3.019911050796509

Epoch: 6| Step: 11
Training loss: 2.8487439155578613
Validation loss: 3.016270160675049

Epoch: 6| Step: 12
Training loss: 3.2803399562835693
Validation loss: 3.012726823488871

Epoch: 6| Step: 13
Training loss: 4.034036636352539
Validation loss: 3.0096203486124673

Epoch: 31| Step: 0
Training loss: 3.5552918910980225
Validation loss: 3.0060643355051675

Epoch: 6| Step: 1
Training loss: 2.8832356929779053
Validation loss: 3.0018601417541504

Epoch: 6| Step: 2
Training loss: 3.4558191299438477
Validation loss: 2.998370806376139

Epoch: 6| Step: 3
Training loss: 2.7797555923461914
Validation loss: 2.995153546333313

Epoch: 6| Step: 4
Training loss: 3.3757803440093994
Validation loss: 2.991456667582194

Epoch: 6| Step: 5
Training loss: 4.446398735046387
Validation loss: 2.9878495931625366

Epoch: 6| Step: 6
Training loss: 3.346985340118408
Validation loss: 2.984128475189209

Epoch: 6| Step: 7
Training loss: 2.5689010620117188
Validation loss: 2.9801201025644937

Epoch: 6| Step: 8
Training loss: 2.7799389362335205
Validation loss: 2.976496855417887

Epoch: 6| Step: 9
Training loss: 3.4533679485321045
Validation loss: 2.972659389177958

Epoch: 6| Step: 10
Training loss: 3.385401964187622
Validation loss: 2.9690428972244263

Epoch: 6| Step: 11
Training loss: 2.445068597793579
Validation loss: 2.9656657377878823

Epoch: 6| Step: 12
Training loss: 3.2055234909057617
Validation loss: 2.962228298187256

Epoch: 6| Step: 13
Training loss: 2.853344678878784
Validation loss: 2.9586262702941895

Epoch: 32| Step: 0
Training loss: 3.0055885314941406
Validation loss: 2.955349405606588

Epoch: 6| Step: 1
Training loss: 3.589203119277954
Validation loss: 2.9521960814793906

Epoch: 6| Step: 2
Training loss: 3.1406588554382324
Validation loss: 2.949381391207377

Epoch: 6| Step: 3
Training loss: 3.244323968887329
Validation loss: 2.946239630381266

Epoch: 6| Step: 4
Training loss: 3.3328826427459717
Validation loss: 2.9433216651280723

Epoch: 6| Step: 5
Training loss: 4.008329391479492
Validation loss: 2.940270185470581

Epoch: 6| Step: 6
Training loss: 2.853895664215088
Validation loss: 2.9371946255366006

Epoch: 6| Step: 7
Training loss: 3.398759365081787
Validation loss: 2.9340354204177856

Epoch: 6| Step: 8
Training loss: 3.0355515480041504
Validation loss: 2.931116541226705

Epoch: 6| Step: 9
Training loss: 2.4569783210754395
Validation loss: 2.9280589818954468

Epoch: 6| Step: 10
Training loss: 2.538642406463623
Validation loss: 2.9250486294428506

Epoch: 6| Step: 11
Training loss: 2.9919090270996094
Validation loss: 2.9222122033437095

Epoch: 6| Step: 12
Training loss: 4.037895202636719
Validation loss: 2.9191627502441406

Epoch: 6| Step: 13
Training loss: 2.2621068954467773
Validation loss: 2.916027625401815

Epoch: 33| Step: 0
Training loss: 3.289884567260742
Validation loss: 2.912310163180033

Epoch: 6| Step: 1
Training loss: 2.383439064025879
Validation loss: 2.9087582429250083

Epoch: 6| Step: 2
Training loss: 2.702207088470459
Validation loss: 2.9052134354909263

Epoch: 6| Step: 3
Training loss: 2.878965377807617
Validation loss: 2.9018150170644126

Epoch: 6| Step: 4
Training loss: 3.3867692947387695
Validation loss: 2.898708701133728

Epoch: 6| Step: 5
Training loss: 3.5514607429504395
Validation loss: 2.895678917566935

Epoch: 6| Step: 6
Training loss: 2.3436031341552734
Validation loss: 2.892152428627014

Epoch: 6| Step: 7
Training loss: 3.2241106033325195
Validation loss: 2.888984719912211

Epoch: 6| Step: 8
Training loss: 3.581092119216919
Validation loss: 2.8852988481521606

Epoch: 6| Step: 9
Training loss: 3.0244860649108887
Validation loss: 2.8820510307947793

Epoch: 6| Step: 10
Training loss: 3.4969968795776367
Validation loss: 2.8774063984553018

Epoch: 6| Step: 11
Training loss: 3.283566474914551
Validation loss: 2.8733005126317344

Epoch: 6| Step: 12
Training loss: 3.3456873893737793
Validation loss: 2.868726889292399

Epoch: 6| Step: 13
Training loss: 2.8641741275787354
Validation loss: 2.8656112353006997

Epoch: 34| Step: 0
Training loss: 2.6190195083618164
Validation loss: 2.8614611625671387

Epoch: 6| Step: 1
Training loss: 3.828587055206299
Validation loss: 2.8580246369043985

Epoch: 6| Step: 2
Training loss: 3.560427188873291
Validation loss: 2.853219747543335

Epoch: 6| Step: 3
Training loss: 2.8757457733154297
Validation loss: 2.849924683570862

Epoch: 6| Step: 4
Training loss: 3.0940515995025635
Validation loss: 2.8457462390263877

Epoch: 6| Step: 5
Training loss: 2.826361656188965
Validation loss: 2.8436315854390464

Epoch: 6| Step: 6
Training loss: 3.075812578201294
Validation loss: 2.840706944465637

Epoch: 6| Step: 7
Training loss: 2.6253743171691895
Validation loss: 2.838368773460388

Epoch: 6| Step: 8
Training loss: 3.113128185272217
Validation loss: 2.836074471473694

Epoch: 6| Step: 9
Training loss: 3.222384452819824
Validation loss: 2.8331246376037598

Epoch: 6| Step: 10
Training loss: 2.7767624855041504
Validation loss: 2.8287593126296997

Epoch: 6| Step: 11
Training loss: 1.9796208143234253
Validation loss: 2.8248926798502603

Epoch: 6| Step: 12
Training loss: 3.704134464263916
Validation loss: 2.822568953037262

Epoch: 6| Step: 13
Training loss: 3.41965913772583
Validation loss: 2.8198450406392417

Epoch: 35| Step: 0
Training loss: 3.374613046646118
Validation loss: 2.815962811311086

Epoch: 6| Step: 1
Training loss: 3.357062339782715
Validation loss: 2.8122231562932334

Epoch: 6| Step: 2
Training loss: 2.7706191539764404
Validation loss: 2.8090101877848306

Epoch: 6| Step: 3
Training loss: 2.8426990509033203
Validation loss: 2.8058735728263855

Epoch: 6| Step: 4
Training loss: 2.0948851108551025
Validation loss: 2.802984913190206

Epoch: 6| Step: 5
Training loss: 2.6686103343963623
Validation loss: 2.800624450047811

Epoch: 6| Step: 6
Training loss: 3.4648375511169434
Validation loss: 2.7976173957188926

Epoch: 6| Step: 7
Training loss: 2.8073575496673584
Validation loss: 2.7945664723714194

Epoch: 6| Step: 8
Training loss: 2.985417366027832
Validation loss: 2.791837771733602

Epoch: 6| Step: 9
Training loss: 3.1519150733947754
Validation loss: 2.789304733276367

Epoch: 6| Step: 10
Training loss: 3.588219165802002
Validation loss: 2.786436756451925

Epoch: 6| Step: 11
Training loss: 3.289135217666626
Validation loss: 2.7834449211756387

Epoch: 6| Step: 12
Training loss: 3.1021711826324463
Validation loss: 2.7804436683654785

Epoch: 6| Step: 13
Training loss: 2.630077600479126
Validation loss: 2.7772721449534097

Epoch: 36| Step: 0
Training loss: 2.640378475189209
Validation loss: 2.7757080793380737

Epoch: 6| Step: 1
Training loss: 4.035233497619629
Validation loss: 2.7868533531824746

Epoch: 6| Step: 2
Training loss: 2.9013025760650635
Validation loss: 2.768572290738424

Epoch: 6| Step: 3
Training loss: 3.002967357635498
Validation loss: 2.7647716204325357

Epoch: 6| Step: 4
Training loss: 2.8700473308563232
Validation loss: 2.762197415033976

Epoch: 6| Step: 5
Training loss: 2.5350844860076904
Validation loss: 2.7605695724487305

Epoch: 6| Step: 6
Training loss: 3.1663570404052734
Validation loss: 2.7610490322113037

Epoch: 6| Step: 7
Training loss: 3.321718454360962
Validation loss: 2.7596018314361572

Epoch: 6| Step: 8
Training loss: 2.22343111038208
Validation loss: 2.7560178438822427

Epoch: 6| Step: 9
Training loss: 2.841226100921631
Validation loss: 2.7520583470662436

Epoch: 6| Step: 10
Training loss: 3.613027572631836
Validation loss: 2.748768409093221

Epoch: 6| Step: 11
Training loss: 2.5423009395599365
Validation loss: 2.7449756860733032

Epoch: 6| Step: 12
Training loss: 2.9981422424316406
Validation loss: 2.741235693295797

Epoch: 6| Step: 13
Training loss: 2.9055275917053223
Validation loss: 2.7382030487060547

Epoch: 37| Step: 0
Training loss: 2.5587892532348633
Validation loss: 2.7355899016062417

Epoch: 6| Step: 1
Training loss: 3.1184911727905273
Validation loss: 2.7334811687469482

Epoch: 6| Step: 2
Training loss: 2.613208770751953
Validation loss: 2.7311447064081826

Epoch: 6| Step: 3
Training loss: 3.1239709854125977
Validation loss: 2.730024814605713

Epoch: 6| Step: 4
Training loss: 3.70474910736084
Validation loss: 2.72722057501475

Epoch: 6| Step: 5
Training loss: 2.308850049972534
Validation loss: 2.7245020469029746

Epoch: 6| Step: 6
Training loss: 2.422351121902466
Validation loss: 2.7208261092503867

Epoch: 6| Step: 7
Training loss: 2.4358925819396973
Validation loss: 2.7181338469187417

Epoch: 6| Step: 8
Training loss: 2.7971229553222656
Validation loss: 2.7154478232065835

Epoch: 6| Step: 9
Training loss: 3.514713764190674
Validation loss: 2.7126202980677285

Epoch: 6| Step: 10
Training loss: 3.385350465774536
Validation loss: 2.709633946418762

Epoch: 6| Step: 11
Training loss: 2.8564422130584717
Validation loss: 2.706157406171163

Epoch: 6| Step: 12
Training loss: 3.2439334392547607
Validation loss: 2.7034913698832193

Epoch: 6| Step: 13
Training loss: 2.8652374744415283
Validation loss: 2.7005085945129395

Epoch: 38| Step: 0
Training loss: 3.32004714012146
Validation loss: 2.6970520615577698

Epoch: 6| Step: 1
Training loss: 3.4359920024871826
Validation loss: 2.6939831574757895

Epoch: 6| Step: 2
Training loss: 2.383885145187378
Validation loss: 2.6903884410858154

Epoch: 6| Step: 3
Training loss: 3.060802459716797
Validation loss: 2.687765598297119

Epoch: 6| Step: 4
Training loss: 2.874934673309326
Validation loss: 2.684833367665609

Epoch: 6| Step: 5
Training loss: 2.80039381980896
Validation loss: 2.681954344113668

Epoch: 6| Step: 6
Training loss: 2.683415651321411
Validation loss: 2.67905064423879

Epoch: 6| Step: 7
Training loss: 2.782409429550171
Validation loss: 2.676211436589559

Epoch: 6| Step: 8
Training loss: 2.6448774337768555
Validation loss: 2.6734609603881836

Epoch: 6| Step: 9
Training loss: 2.6832048892974854
Validation loss: 2.670960267384847

Epoch: 6| Step: 10
Training loss: 3.474255084991455
Validation loss: 2.668518622716268

Epoch: 6| Step: 11
Training loss: 2.415585517883301
Validation loss: 2.66594131787618

Epoch: 6| Step: 12
Training loss: 3.1871917247772217
Validation loss: 2.663082480430603

Epoch: 6| Step: 13
Training loss: 2.627941370010376
Validation loss: 2.659811774889628

Epoch: 39| Step: 0
Training loss: 2.8482375144958496
Validation loss: 2.6570725440979004

Epoch: 6| Step: 1
Training loss: 2.7298662662506104
Validation loss: 2.653866449991862

Epoch: 6| Step: 2
Training loss: 3.0873022079467773
Validation loss: 2.650526682535807

Epoch: 6| Step: 3
Training loss: 3.509817123413086
Validation loss: 2.6472708781560264

Epoch: 6| Step: 4
Training loss: 2.7029662132263184
Validation loss: 2.644597033659617

Epoch: 6| Step: 5
Training loss: 2.760819911956787
Validation loss: 2.6416319608688354

Epoch: 6| Step: 6
Training loss: 3.077197551727295
Validation loss: 2.638868530591329

Epoch: 6| Step: 7
Training loss: 2.744741439819336
Validation loss: 2.6359938581784568

Epoch: 6| Step: 8
Training loss: 2.9878270626068115
Validation loss: 2.632604638735453

Epoch: 6| Step: 9
Training loss: 2.7185940742492676
Validation loss: 2.6293846368789673

Epoch: 6| Step: 10
Training loss: 3.1627511978149414
Validation loss: 2.626350919405619

Epoch: 6| Step: 11
Training loss: 2.324427843093872
Validation loss: 2.623638113339742

Epoch: 6| Step: 12
Training loss: 2.414973735809326
Validation loss: 2.620892604192098

Epoch: 6| Step: 13
Training loss: 2.7402024269104004
Validation loss: 2.6191548506418862

Epoch: 40| Step: 0
Training loss: 2.4670724868774414
Validation loss: 2.615919748942057

Epoch: 6| Step: 1
Training loss: 2.8391194343566895
Validation loss: 2.613821109135946

Epoch: 6| Step: 2
Training loss: 2.635748863220215
Validation loss: 2.6117283503214517

Epoch: 6| Step: 3
Training loss: 2.4648845195770264
Validation loss: 2.6075294812520347

Epoch: 6| Step: 4
Training loss: 2.798107147216797
Validation loss: 2.6051443815231323

Epoch: 6| Step: 5
Training loss: 2.7573838233947754
Validation loss: 2.6025604605674744

Epoch: 6| Step: 6
Training loss: 3.283071517944336
Validation loss: 2.5997906923294067

Epoch: 6| Step: 7
Training loss: 3.2433080673217773
Validation loss: 2.597886562347412

Epoch: 6| Step: 8
Training loss: 3.439091205596924
Validation loss: 2.5948808193206787

Epoch: 6| Step: 9
Training loss: 2.606461524963379
Validation loss: 2.592336098353068

Epoch: 6| Step: 10
Training loss: 2.709134101867676
Validation loss: 2.5895799001057944

Epoch: 6| Step: 11
Training loss: 2.7737317085266113
Validation loss: 2.5861939589182534

Epoch: 6| Step: 12
Training loss: 2.217972755432129
Validation loss: 2.5824067195256553

Epoch: 6| Step: 13
Training loss: 2.982100486755371
Validation loss: 2.5807145039240518

Epoch: 41| Step: 0
Training loss: 3.025834560394287
Validation loss: 2.5776660442352295

Epoch: 6| Step: 1
Training loss: 2.744948148727417
Validation loss: 2.5755310455958047

Epoch: 6| Step: 2
Training loss: 2.4682068824768066
Validation loss: 2.572612007459005

Epoch: 6| Step: 3
Training loss: 2.676326274871826
Validation loss: 2.569998025894165

Epoch: 6| Step: 4
Training loss: 2.737694501876831
Validation loss: 2.567259947458903

Epoch: 6| Step: 5
Training loss: 2.8151464462280273
Validation loss: 2.5649025042851767

Epoch: 6| Step: 6
Training loss: 2.6846728324890137
Validation loss: 2.5625502268473306

Epoch: 6| Step: 7
Training loss: 3.4207282066345215
Validation loss: 2.559837063153585

Epoch: 6| Step: 8
Training loss: 3.0914132595062256
Validation loss: 2.557684540748596

Epoch: 6| Step: 9
Training loss: 3.0175862312316895
Validation loss: 2.554980993270874

Epoch: 6| Step: 10
Training loss: 2.8639180660247803
Validation loss: 2.551672577857971

Epoch: 6| Step: 11
Training loss: 2.390681743621826
Validation loss: 2.5490875244140625

Epoch: 6| Step: 12
Training loss: 2.2775115966796875
Validation loss: 2.5464123487472534

Epoch: 6| Step: 13
Training loss: 2.4559967517852783
Validation loss: 2.543353875478109

Epoch: 42| Step: 0
Training loss: 2.977459192276001
Validation loss: 2.541154384613037

Epoch: 6| Step: 1
Training loss: 2.4962902069091797
Validation loss: 2.5394206841786704

Epoch: 6| Step: 2
Training loss: 2.0202765464782715
Validation loss: 2.537451465924581

Epoch: 6| Step: 3
Training loss: 2.9730796813964844
Validation loss: 2.534861207008362

Epoch: 6| Step: 4
Training loss: 2.9630141258239746
Validation loss: 2.5328991413116455

Epoch: 6| Step: 5
Training loss: 2.435964345932007
Validation loss: 2.531732757886251

Epoch: 6| Step: 6
Training loss: 1.970489263534546
Validation loss: 2.5293951829274497

Epoch: 6| Step: 7
Training loss: 2.7120680809020996
Validation loss: 2.527671674887339

Epoch: 6| Step: 8
Training loss: 3.386204719543457
Validation loss: 2.5245409409205117

Epoch: 6| Step: 9
Training loss: 2.737786293029785
Validation loss: 2.522493044535319

Epoch: 6| Step: 10
Training loss: 2.9520349502563477
Validation loss: 2.5184643268585205

Epoch: 6| Step: 11
Training loss: 3.5807366371154785
Validation loss: 2.515730639298757

Epoch: 6| Step: 12
Training loss: 2.40134334564209
Validation loss: 2.5122660199801126

Epoch: 6| Step: 13
Training loss: 2.503199815750122
Validation loss: 2.509613037109375

Epoch: 43| Step: 0
Training loss: 2.9443609714508057
Validation loss: 2.507709781328837

Epoch: 6| Step: 1
Training loss: 3.508307456970215
Validation loss: 2.504589796066284

Epoch: 6| Step: 2
Training loss: 3.509028196334839
Validation loss: 2.501758853594462

Epoch: 6| Step: 3
Training loss: 2.3276305198669434
Validation loss: 2.499658226966858

Epoch: 6| Step: 4
Training loss: 2.7215938568115234
Validation loss: 2.4967137575149536

Epoch: 6| Step: 5
Training loss: 1.7890539169311523
Validation loss: 2.4944128592809043

Epoch: 6| Step: 6
Training loss: 2.3887386322021484
Validation loss: 2.492910146713257

Epoch: 6| Step: 7
Training loss: 2.8604414463043213
Validation loss: 2.4906243880589805

Epoch: 6| Step: 8
Training loss: 2.2272822856903076
Validation loss: 2.4880414406458535

Epoch: 6| Step: 9
Training loss: 2.7026467323303223
Validation loss: 2.486050526301066

Epoch: 6| Step: 10
Training loss: 2.225982427597046
Validation loss: 2.4829773902893066

Epoch: 6| Step: 11
Training loss: 2.9803473949432373
Validation loss: 2.4799384077390036

Epoch: 6| Step: 12
Training loss: 2.776916265487671
Validation loss: 2.4765549103418985

Epoch: 6| Step: 13
Training loss: 2.631476640701294
Validation loss: 2.4739766716957092

Epoch: 44| Step: 0
Training loss: 3.256074905395508
Validation loss: 2.471093773841858

Epoch: 6| Step: 1
Training loss: 2.8805007934570312
Validation loss: 2.467897653579712

Epoch: 6| Step: 2
Training loss: 2.3993165493011475
Validation loss: 2.4655235608418784

Epoch: 6| Step: 3
Training loss: 2.493922710418701
Validation loss: 2.4624316294988

Epoch: 6| Step: 4
Training loss: 2.720944404602051
Validation loss: 2.4591389099756875

Epoch: 6| Step: 5
Training loss: 2.880662441253662
Validation loss: 2.4565905332565308

Epoch: 6| Step: 6
Training loss: 3.068025827407837
Validation loss: 2.4564512173334756

Epoch: 6| Step: 7
Training loss: 2.377403736114502
Validation loss: 2.452016989390055

Epoch: 6| Step: 8
Training loss: 1.9488998651504517
Validation loss: 2.4465335607528687

Epoch: 6| Step: 9
Training loss: 2.667947769165039
Validation loss: 2.444482366243998

Epoch: 6| Step: 10
Training loss: 2.676762104034424
Validation loss: 2.445398966471354

Epoch: 6| Step: 11
Training loss: 2.813385009765625
Validation loss: 2.444544235865275

Epoch: 6| Step: 12
Training loss: 2.568225860595703
Validation loss: 2.442526936531067

Epoch: 6| Step: 13
Training loss: 2.353811264038086
Validation loss: 2.4410623709360757

Epoch: 45| Step: 0
Training loss: 1.8052890300750732
Validation loss: 2.4396797815958657

Epoch: 6| Step: 1
Training loss: 3.136258125305176
Validation loss: 2.438183863957723

Epoch: 6| Step: 2
Training loss: 2.771021842956543
Validation loss: 2.434007207552592

Epoch: 6| Step: 3
Training loss: 3.2050130367279053
Validation loss: 2.431573232014974

Epoch: 6| Step: 4
Training loss: 3.002795696258545
Validation loss: 2.427913268407186

Epoch: 6| Step: 5
Training loss: 2.1054890155792236
Validation loss: 2.426079054673513

Epoch: 6| Step: 6
Training loss: 2.358797550201416
Validation loss: 2.4222611586252847

Epoch: 6| Step: 7
Training loss: 2.860704183578491
Validation loss: 2.4197292725245156

Epoch: 6| Step: 8
Training loss: 2.5002899169921875
Validation loss: 2.4167809089024863

Epoch: 6| Step: 9
Training loss: 2.3164634704589844
Validation loss: 2.4149925112724304

Epoch: 6| Step: 10
Training loss: 2.4791083335876465
Validation loss: 2.4116828242937722

Epoch: 6| Step: 11
Training loss: 2.253054141998291
Validation loss: 2.408953905105591

Epoch: 6| Step: 12
Training loss: 3.018479108810425
Validation loss: 2.4073150555292764

Epoch: 6| Step: 13
Training loss: 2.7240407466888428
Validation loss: 2.404092232386271

Epoch: 46| Step: 0
Training loss: 2.6733779907226562
Validation loss: 2.4029199679692588

Epoch: 6| Step: 1
Training loss: 3.0506067276000977
Validation loss: 2.400746464729309

Epoch: 6| Step: 2
Training loss: 2.461534023284912
Validation loss: 2.397689680258433

Epoch: 6| Step: 3
Training loss: 2.541273593902588
Validation loss: 2.3931884169578552

Epoch: 6| Step: 4
Training loss: 2.357463836669922
Validation loss: 2.3933235804239907

Epoch: 6| Step: 5
Training loss: 2.5310921669006348
Validation loss: 2.393542448679606

Epoch: 6| Step: 6
Training loss: 2.091834545135498
Validation loss: 2.392494797706604

Epoch: 6| Step: 7
Training loss: 2.1991429328918457
Validation loss: 2.389819383621216

Epoch: 6| Step: 8
Training loss: 2.8953661918640137
Validation loss: 2.381214221318563

Epoch: 6| Step: 9
Training loss: 2.7432971000671387
Validation loss: 2.379367788632711

Epoch: 6| Step: 10
Training loss: 3.6305091381073
Validation loss: 2.3780020475387573

Epoch: 6| Step: 11
Training loss: 2.4357283115386963
Validation loss: 2.376850684483846

Epoch: 6| Step: 12
Training loss: 2.5285515785217285
Validation loss: 2.376267433166504

Epoch: 6| Step: 13
Training loss: 1.9249176979064941
Validation loss: 2.3776503801345825

Epoch: 47| Step: 0
Training loss: 2.0797433853149414
Validation loss: 2.3718411723772683

Epoch: 6| Step: 1
Training loss: 2.646042585372925
Validation loss: 2.3700552384058633

Epoch: 6| Step: 2
Training loss: 2.5677547454833984
Validation loss: 2.3663442730903625

Epoch: 6| Step: 3
Training loss: 2.7429094314575195
Validation loss: 2.361723860104879

Epoch: 6| Step: 4
Training loss: 2.237751007080078
Validation loss: 2.358994245529175

Epoch: 6| Step: 5
Training loss: 2.861569404602051
Validation loss: 2.3616062800089517

Epoch: 6| Step: 6
Training loss: 2.4166646003723145
Validation loss: 2.3602957725524902

Epoch: 6| Step: 7
Training loss: 2.7239770889282227
Validation loss: 2.3557947874069214

Epoch: 6| Step: 8
Training loss: 2.1861042976379395
Validation loss: 2.354982018470764

Epoch: 6| Step: 9
Training loss: 2.5046963691711426
Validation loss: 2.3456853230794272

Epoch: 6| Step: 10
Training loss: 2.6828536987304688
Validation loss: 2.348121682802836

Epoch: 6| Step: 11
Training loss: 2.6773793697357178
Validation loss: 2.3507538437843323

Epoch: 6| Step: 12
Training loss: 2.480734348297119
Validation loss: 2.3569658398628235

Epoch: 6| Step: 13
Training loss: 2.7441179752349854
Validation loss: 2.3698686361312866

Epoch: 48| Step: 0
Training loss: 2.860335350036621
Validation loss: 2.34811802705129

Epoch: 6| Step: 1
Training loss: 2.648280382156372
Validation loss: 2.34454337755839

Epoch: 6| Step: 2
Training loss: 2.5370116233825684
Validation loss: 2.3406298557917276

Epoch: 6| Step: 3
Training loss: 2.3770949840545654
Validation loss: 2.3390366435050964

Epoch: 6| Step: 4
Training loss: 2.3594160079956055
Validation loss: 2.3363381226857505

Epoch: 6| Step: 5
Training loss: 2.5397286415100098
Validation loss: 2.334400773048401

Epoch: 6| Step: 6
Training loss: 3.292955160140991
Validation loss: 2.331933339436849

Epoch: 6| Step: 7
Training loss: 2.772855281829834
Validation loss: 2.328138788541158

Epoch: 6| Step: 8
Training loss: 2.70607328414917
Validation loss: 2.3273043632507324

Epoch: 6| Step: 9
Training loss: 2.2622203826904297
Validation loss: 2.3250648975372314

Epoch: 6| Step: 10
Training loss: 1.8637588024139404
Validation loss: 2.3221132357915244

Epoch: 6| Step: 11
Training loss: 2.223978042602539
Validation loss: 2.320635199546814

Epoch: 6| Step: 12
Training loss: 2.6305527687072754
Validation loss: 2.31902285416921

Epoch: 6| Step: 13
Training loss: 2.0003862380981445
Validation loss: 2.316386103630066

Epoch: 49| Step: 0
Training loss: 2.041097640991211
Validation loss: 2.31220018863678

Epoch: 6| Step: 1
Training loss: 2.76163911819458
Validation loss: 2.3095421393712363

Epoch: 6| Step: 2
Training loss: 2.727444887161255
Validation loss: 2.306394577026367

Epoch: 6| Step: 3
Training loss: 2.3541998863220215
Validation loss: 2.301259160041809

Epoch: 6| Step: 4
Training loss: 1.9458050727844238
Validation loss: 2.2974623839060464

Epoch: 6| Step: 5
Training loss: 2.8094887733459473
Validation loss: 2.2964770197868347

Epoch: 6| Step: 6
Training loss: 2.513458728790283
Validation loss: 2.2952325344085693

Epoch: 6| Step: 7
Training loss: 2.699787139892578
Validation loss: 2.292788585027059

Epoch: 6| Step: 8
Training loss: 2.413057804107666
Validation loss: 2.289112687110901

Epoch: 6| Step: 9
Training loss: 2.2095470428466797
Validation loss: 2.288355588912964

Epoch: 6| Step: 10
Training loss: 2.0041422843933105
Validation loss: 2.286145011583964

Epoch: 6| Step: 11
Training loss: 2.427917003631592
Validation loss: 2.2836384773254395

Epoch: 6| Step: 12
Training loss: 2.94740891456604
Validation loss: 2.282612959543864

Epoch: 6| Step: 13
Training loss: 2.7207770347595215
Validation loss: 2.2796014149983725

Epoch: 50| Step: 0
Training loss: 2.4692447185516357
Validation loss: 2.277973254521688

Epoch: 6| Step: 1
Training loss: 1.7836955785751343
Validation loss: 2.2754302620887756

Epoch: 6| Step: 2
Training loss: 2.1415860652923584
Validation loss: 2.2748073736826577

Epoch: 6| Step: 3
Training loss: 2.723813533782959
Validation loss: 2.2741745710372925

Epoch: 6| Step: 4
Training loss: 2.662814140319824
Validation loss: 2.2675689856211343

Epoch: 6| Step: 5
Training loss: 2.345693588256836
Validation loss: 2.2681224743525186

Epoch: 6| Step: 6
Training loss: 2.945866584777832
Validation loss: 2.2671358982721963

Epoch: 6| Step: 7
Training loss: 2.401067018508911
Validation loss: 2.2628939549128213

Epoch: 6| Step: 8
Training loss: 2.511094570159912
Validation loss: 2.261874874432882

Epoch: 6| Step: 9
Training loss: 2.7967031002044678
Validation loss: 2.2587154308954873

Epoch: 6| Step: 10
Training loss: 3.1607613563537598
Validation loss: 2.2557830611864724

Epoch: 6| Step: 11
Training loss: 2.064971446990967
Validation loss: 2.2531931400299072

Epoch: 6| Step: 12
Training loss: 1.469622254371643
Validation loss: 2.251684248447418

Epoch: 6| Step: 13
Training loss: 2.5715274810791016
Validation loss: 2.2472283641497293

Epoch: 51| Step: 0
Training loss: 2.622483968734741
Validation loss: 2.246660610040029

Epoch: 6| Step: 1
Training loss: 2.563203811645508
Validation loss: 2.2433236837387085

Epoch: 6| Step: 2
Training loss: 2.91363263130188
Validation loss: 2.244764427344004

Epoch: 6| Step: 3
Training loss: 2.5965230464935303
Validation loss: 2.2416664759318032

Epoch: 6| Step: 4
Training loss: 1.8849104642868042
Validation loss: 2.239728848139445

Epoch: 6| Step: 5
Training loss: 2.516268730163574
Validation loss: 2.237689197063446

Epoch: 6| Step: 6
Training loss: 2.441368579864502
Validation loss: 2.2367074489593506

Epoch: 6| Step: 7
Training loss: 2.436931610107422
Validation loss: 2.235434591770172

Epoch: 6| Step: 8
Training loss: 2.226715564727783
Validation loss: 2.2340056896209717

Epoch: 6| Step: 9
Training loss: 2.3350865840911865
Validation loss: 2.2289140025774636

Epoch: 6| Step: 10
Training loss: 2.2032856941223145
Validation loss: 2.2293367783228555

Epoch: 6| Step: 11
Training loss: 2.4388010501861572
Validation loss: 2.227542241414388

Epoch: 6| Step: 12
Training loss: 2.2432122230529785
Validation loss: 2.222991406917572

Epoch: 6| Step: 13
Training loss: 2.1421329975128174
Validation loss: 2.223926583925883

Epoch: 52| Step: 0
Training loss: 2.8931527137756348
Validation loss: 2.214422901471456

Epoch: 6| Step: 1
Training loss: 2.6141245365142822
Validation loss: 2.216209352016449

Epoch: 6| Step: 2
Training loss: 1.955445408821106
Validation loss: 2.220788617928823

Epoch: 6| Step: 3
Training loss: 2.108631134033203
Validation loss: 2.2277557849884033

Epoch: 6| Step: 4
Training loss: 2.3735053539276123
Validation loss: 2.218185087045034

Epoch: 6| Step: 5
Training loss: 2.6163744926452637
Validation loss: 2.216876765092214

Epoch: 6| Step: 6
Training loss: 2.3835291862487793
Validation loss: 2.219347516695658

Epoch: 6| Step: 7
Training loss: 2.4101295471191406
Validation loss: 2.212494671344757

Epoch: 6| Step: 8
Training loss: 2.5547914505004883
Validation loss: 2.2017867962519326

Epoch: 6| Step: 9
Training loss: 2.2764158248901367
Validation loss: 2.204012870788574

Epoch: 6| Step: 10
Training loss: 2.211355686187744
Validation loss: 2.201352536678314

Epoch: 6| Step: 11
Training loss: 2.899174213409424
Validation loss: 2.201274593671163

Epoch: 6| Step: 12
Training loss: 2.274409770965576
Validation loss: 2.2085413734118142

Epoch: 6| Step: 13
Training loss: 1.570674180984497
Validation loss: 2.2073994278907776

Epoch: 53| Step: 0
Training loss: 2.5391342639923096
Validation loss: 2.2217231392860413

Epoch: 6| Step: 1
Training loss: 1.9076590538024902
Validation loss: 2.2116082310676575

Epoch: 6| Step: 2
Training loss: 2.1571831703186035
Validation loss: 2.201567014058431

Epoch: 6| Step: 3
Training loss: 2.4153075218200684
Validation loss: 2.1989627679189048

Epoch: 6| Step: 4
Training loss: 1.991046667098999
Validation loss: 2.194290518760681

Epoch: 6| Step: 5
Training loss: 2.1767048835754395
Validation loss: 2.1896161437034607

Epoch: 6| Step: 6
Training loss: 2.610158681869507
Validation loss: 2.1840943892796836

Epoch: 6| Step: 7
Training loss: 2.225637435913086
Validation loss: 2.1824363470077515

Epoch: 6| Step: 8
Training loss: 2.2841668128967285
Validation loss: 2.1865059534708657

Epoch: 6| Step: 9
Training loss: 2.839296579360962
Validation loss: 2.196213682492574

Epoch: 6| Step: 10
Training loss: 2.0865414142608643
Validation loss: 2.1833196878433228

Epoch: 6| Step: 11
Training loss: 2.390652656555176
Validation loss: 2.1788896123568215

Epoch: 6| Step: 12
Training loss: 2.7263967990875244
Validation loss: 2.180446724096934

Epoch: 6| Step: 13
Training loss: 2.672250747680664
Validation loss: 2.1806893150011697

Epoch: 54| Step: 0
Training loss: 2.076599597930908
Validation loss: 2.184242367744446

Epoch: 6| Step: 1
Training loss: 2.0368435382843018
Validation loss: 2.184793253739675

Epoch: 6| Step: 2
Training loss: 2.2235162258148193
Validation loss: 2.18293168147405

Epoch: 6| Step: 3
Training loss: 2.510322093963623
Validation loss: 2.17758842309316

Epoch: 6| Step: 4
Training loss: 2.5366108417510986
Validation loss: 2.1760553320248923

Epoch: 6| Step: 5
Training loss: 2.433100700378418
Validation loss: 2.1754236022631326

Epoch: 6| Step: 6
Training loss: 2.3954687118530273
Validation loss: 2.1767597794532776

Epoch: 6| Step: 7
Training loss: 2.378201961517334
Validation loss: 2.172031124432882

Epoch: 6| Step: 8
Training loss: 2.1031172275543213
Validation loss: 2.170827885468801

Epoch: 6| Step: 9
Training loss: 2.3367562294006348
Validation loss: 2.1687087416648865

Epoch: 6| Step: 10
Training loss: 2.396310806274414
Validation loss: 2.165667951107025

Epoch: 6| Step: 11
Training loss: 1.941817045211792
Validation loss: 2.1598234375317893

Epoch: 6| Step: 12
Training loss: 2.918299674987793
Validation loss: 2.162194828192393

Epoch: 6| Step: 13
Training loss: 2.3794074058532715
Validation loss: 2.154366691907247

Epoch: 55| Step: 0
Training loss: 2.092453956604004
Validation loss: 2.1556774775187173

Epoch: 6| Step: 1
Training loss: 1.991280436515808
Validation loss: 2.153186559677124

Epoch: 6| Step: 2
Training loss: 2.2342119216918945
Validation loss: 2.1511454979578652

Epoch: 6| Step: 3
Training loss: 2.2209672927856445
Validation loss: 2.1527624328931174

Epoch: 6| Step: 4
Training loss: 2.2755284309387207
Validation loss: 2.1493091583251953

Epoch: 6| Step: 5
Training loss: 2.728146553039551
Validation loss: 2.1491408944129944

Epoch: 6| Step: 6
Training loss: 2.0909762382507324
Validation loss: 2.148469309012095

Epoch: 6| Step: 7
Training loss: 2.4776995182037354
Validation loss: 2.149245500564575

Epoch: 6| Step: 8
Training loss: 2.238955020904541
Validation loss: 2.144922057787577

Epoch: 6| Step: 9
Training loss: 2.489964485168457
Validation loss: 2.1527544458707175

Epoch: 6| Step: 10
Training loss: 2.394672393798828
Validation loss: 2.151284158229828

Epoch: 6| Step: 11
Training loss: 2.220125913619995
Validation loss: 2.139441668987274

Epoch: 6| Step: 12
Training loss: 2.4180240631103516
Validation loss: 2.1391836206118264

Epoch: 6| Step: 13
Training loss: 2.5051822662353516
Validation loss: 2.1447497606277466

Epoch: 56| Step: 0
Training loss: 2.6335418224334717
Validation loss: 2.1567119558652244

Epoch: 6| Step: 1
Training loss: 2.8957974910736084
Validation loss: 2.1583393613497415

Epoch: 6| Step: 2
Training loss: 1.8510371446609497
Validation loss: 2.1486347119013467

Epoch: 6| Step: 3
Training loss: 2.801806926727295
Validation loss: 2.147239923477173

Epoch: 6| Step: 4
Training loss: 1.921379566192627
Validation loss: 2.1414007941881814

Epoch: 6| Step: 5
Training loss: 2.8534889221191406
Validation loss: 2.1433457732200623

Epoch: 6| Step: 6
Training loss: 2.2975666522979736
Validation loss: 2.135710875193278

Epoch: 6| Step: 7
Training loss: 2.315507411956787
Validation loss: 2.1335742274920144

Epoch: 6| Step: 8
Training loss: 2.4246015548706055
Validation loss: 2.131769855817159

Epoch: 6| Step: 9
Training loss: 1.978855848312378
Validation loss: 2.131700416405996

Epoch: 6| Step: 10
Training loss: 1.7033891677856445
Validation loss: 2.1280168096224465

Epoch: 6| Step: 11
Training loss: 2.2636303901672363
Validation loss: 2.126140276590983

Epoch: 6| Step: 12
Training loss: 2.1584272384643555
Validation loss: 2.123315234978994

Epoch: 6| Step: 13
Training loss: 2.161680221557617
Validation loss: 2.12311585744222

Epoch: 57| Step: 0
Training loss: 2.348323106765747
Validation loss: 2.1236941814422607

Epoch: 6| Step: 1
Training loss: 2.101405620574951
Validation loss: 2.1240287621816

Epoch: 6| Step: 2
Training loss: 2.6481266021728516
Validation loss: 2.122044344743093

Epoch: 6| Step: 3
Training loss: 2.500082015991211
Validation loss: 2.1175894339879355

Epoch: 6| Step: 4
Training loss: 2.2758395671844482
Validation loss: 2.1297035813331604

Epoch: 6| Step: 5
Training loss: 2.0890469551086426
Validation loss: 2.130972445011139

Epoch: 6| Step: 6
Training loss: 2.4708023071289062
Validation loss: 2.132363716761271

Epoch: 6| Step: 7
Training loss: 2.147554636001587
Validation loss: 2.1207361419995627

Epoch: 6| Step: 8
Training loss: 2.263596773147583
Validation loss: 2.1121525367101035

Epoch: 6| Step: 9
Training loss: 2.7085392475128174
Validation loss: 2.1165823141733804

Epoch: 6| Step: 10
Training loss: 1.7124648094177246
Validation loss: 2.120202124118805

Epoch: 6| Step: 11
Training loss: 1.9876394271850586
Validation loss: 2.126724362373352

Epoch: 6| Step: 12
Training loss: 1.9587749242782593
Validation loss: 2.129014770189921

Epoch: 6| Step: 13
Training loss: 2.914015293121338
Validation loss: 2.137953261534373

Epoch: 58| Step: 0
Training loss: 2.7202906608581543
Validation loss: 2.134412924448649

Epoch: 6| Step: 1
Training loss: 2.253833293914795
Validation loss: 2.1390289664268494

Epoch: 6| Step: 2
Training loss: 2.329083204269409
Validation loss: 2.1382011771202087

Epoch: 6| Step: 3
Training loss: 2.19797682762146
Validation loss: 2.137966811656952

Epoch: 6| Step: 4
Training loss: 1.8029826879501343
Validation loss: 2.133490025997162

Epoch: 6| Step: 5
Training loss: 2.548577308654785
Validation loss: 2.1298612554868064

Epoch: 6| Step: 6
Training loss: 2.0248823165893555
Validation loss: 2.1259778936704

Epoch: 6| Step: 7
Training loss: 2.6772918701171875
Validation loss: 2.122482438882192

Epoch: 6| Step: 8
Training loss: 2.4137473106384277
Validation loss: 2.1211459239323935

Epoch: 6| Step: 9
Training loss: 1.8004076480865479
Validation loss: 2.119472006956736

Epoch: 6| Step: 10
Training loss: 2.812028169631958
Validation loss: 2.119801878929138

Epoch: 6| Step: 11
Training loss: 1.6677451133728027
Validation loss: 2.11665811141332

Epoch: 6| Step: 12
Training loss: 2.343203067779541
Validation loss: 2.1151361664136252

Epoch: 6| Step: 13
Training loss: 2.585366725921631
Validation loss: 2.111567795276642

Epoch: 59| Step: 0
Training loss: 2.658466339111328
Validation loss: 2.109304745992025

Epoch: 6| Step: 1
Training loss: 1.9988163709640503
Validation loss: 2.1017878452936807

Epoch: 6| Step: 2
Training loss: 1.6178523302078247
Validation loss: 2.103488564491272

Epoch: 6| Step: 3
Training loss: 1.7033722400665283
Validation loss: 2.1100329160690308

Epoch: 6| Step: 4
Training loss: 2.847029209136963
Validation loss: 2.1195444067319236

Epoch: 6| Step: 5
Training loss: 2.674724578857422
Validation loss: 2.13178684314092

Epoch: 6| Step: 6
Training loss: 1.9906889200210571
Validation loss: 2.1259408394495645

Epoch: 6| Step: 7
Training loss: 2.0077104568481445
Validation loss: 2.1078054110209146

Epoch: 6| Step: 8
Training loss: 2.18861985206604
Validation loss: 2.093329668045044

Epoch: 6| Step: 9
Training loss: 1.8913201093673706
Validation loss: 2.089413106441498

Epoch: 6| Step: 10
Training loss: 2.994622230529785
Validation loss: 2.089341421922048

Epoch: 6| Step: 11
Training loss: 2.572524070739746
Validation loss: 2.087702910105387

Epoch: 6| Step: 12
Training loss: 2.525967597961426
Validation loss: 2.0906929175059

Epoch: 6| Step: 13
Training loss: 2.3864970207214355
Validation loss: 2.0913915634155273

Epoch: 60| Step: 0
Training loss: 2.8792638778686523
Validation loss: 2.0938947399457297

Epoch: 6| Step: 1
Training loss: 2.7886016368865967
Validation loss: 2.0972902377446494

Epoch: 6| Step: 2
Training loss: 1.4702754020690918
Validation loss: 2.096937437852224

Epoch: 6| Step: 3
Training loss: 2.561725378036499
Validation loss: 2.099900941054026

Epoch: 6| Step: 4
Training loss: 1.8427428007125854
Validation loss: 2.1018885374069214

Epoch: 6| Step: 5
Training loss: 2.4969470500946045
Validation loss: 2.1036996046702066

Epoch: 6| Step: 6
Training loss: 2.270218849182129
Validation loss: 2.1033655206362405

Epoch: 6| Step: 7
Training loss: 2.135566234588623
Validation loss: 2.099339465300242

Epoch: 6| Step: 8
Training loss: 2.583489418029785
Validation loss: 2.1009249289830527

Epoch: 6| Step: 9
Training loss: 1.8699007034301758
Validation loss: 2.0996376673380532

Epoch: 6| Step: 10
Training loss: 2.5296270847320557
Validation loss: 2.0979310075441995

Epoch: 6| Step: 11
Training loss: 1.855425238609314
Validation loss: 2.0946481426556907

Epoch: 6| Step: 12
Training loss: 2.584010124206543
Validation loss: 2.0928571621576944

Epoch: 6| Step: 13
Training loss: 2.0574069023132324
Validation loss: 2.08999502658844

Epoch: 61| Step: 0
Training loss: 2.397040843963623
Validation loss: 2.084303160508474

Epoch: 6| Step: 1
Training loss: 1.4125548601150513
Validation loss: 2.079640825589498

Epoch: 6| Step: 2
Training loss: 2.4605727195739746
Validation loss: 2.0749126076698303

Epoch: 6| Step: 3
Training loss: 1.6805615425109863
Validation loss: 2.0713478326797485

Epoch: 6| Step: 4
Training loss: 2.283886671066284
Validation loss: 2.070035457611084

Epoch: 6| Step: 5
Training loss: 2.8902361392974854
Validation loss: 2.07088303565979

Epoch: 6| Step: 6
Training loss: 2.307971477508545
Validation loss: 2.0676987965901694

Epoch: 6| Step: 7
Training loss: 2.7994508743286133
Validation loss: 2.069573084513346

Epoch: 6| Step: 8
Training loss: 1.852689504623413
Validation loss: 2.066588799158732

Epoch: 6| Step: 9
Training loss: 2.871325731277466
Validation loss: 2.063560982545217

Epoch: 6| Step: 10
Training loss: 1.2660562992095947
Validation loss: 2.0709674755732217

Epoch: 6| Step: 11
Training loss: 2.2337584495544434
Validation loss: 2.0663320819536843

Epoch: 6| Step: 12
Training loss: 2.41178035736084
Validation loss: 2.069842497507731

Epoch: 6| Step: 13
Training loss: 2.645261287689209
Validation loss: 2.0681656201680503

Epoch: 62| Step: 0
Training loss: 2.220888137817383
Validation loss: 2.066961864630381

Epoch: 6| Step: 1
Training loss: 1.7180901765823364
Validation loss: 2.0750380555788674

Epoch: 6| Step: 2
Training loss: 2.503633499145508
Validation loss: 2.0703380902608237

Epoch: 6| Step: 3
Training loss: 2.1658310890197754
Validation loss: 2.0670729279518127

Epoch: 6| Step: 4
Training loss: 2.3760147094726562
Validation loss: 2.0724353790283203

Epoch: 6| Step: 5
Training loss: 2.217050313949585
Validation loss: 2.06711753209432

Epoch: 6| Step: 6
Training loss: 2.289095878601074
Validation loss: 2.0714880228042603

Epoch: 6| Step: 7
Training loss: 2.2190871238708496
Validation loss: 2.069120983282725

Epoch: 6| Step: 8
Training loss: 2.2633309364318848
Validation loss: 2.0639379421869912

Epoch: 6| Step: 9
Training loss: 1.6703646183013916
Validation loss: 2.0684680143992105

Epoch: 6| Step: 10
Training loss: 2.4742789268493652
Validation loss: 2.0691250960032144

Epoch: 6| Step: 11
Training loss: 2.6229043006896973
Validation loss: 2.0645387967427573

Epoch: 6| Step: 12
Training loss: 2.589599609375
Validation loss: 2.0589873790740967

Epoch: 6| Step: 13
Training loss: 2.091268539428711
Validation loss: 2.0563904643058777

Epoch: 63| Step: 0
Training loss: 2.6901321411132812
Validation loss: 2.0531997680664062

Epoch: 6| Step: 1
Training loss: 2.098961114883423
Validation loss: 2.0557647546132407

Epoch: 6| Step: 2
Training loss: 1.8273533582687378
Validation loss: 2.050752858320872

Epoch: 6| Step: 3
Training loss: 2.0217058658599854
Validation loss: 2.0518188079198203

Epoch: 6| Step: 4
Training loss: 2.179128885269165
Validation loss: 2.055964251359304

Epoch: 6| Step: 5
Training loss: 1.8186489343643188
Validation loss: 2.0581889351209006

Epoch: 6| Step: 6
Training loss: 2.0746536254882812
Validation loss: 2.0570130348205566

Epoch: 6| Step: 7
Training loss: 2.815642833709717
Validation loss: 2.0548301935195923

Epoch: 6| Step: 8
Training loss: 1.9981555938720703
Validation loss: 2.057610829671224

Epoch: 6| Step: 9
Training loss: 2.238800048828125
Validation loss: 2.0509992043177285

Epoch: 6| Step: 10
Training loss: 2.059170722961426
Validation loss: 2.0496413906415305

Epoch: 6| Step: 11
Training loss: 2.3156509399414062
Validation loss: 2.0428618590037027

Epoch: 6| Step: 12
Training loss: 2.5300087928771973
Validation loss: 2.0439683198928833

Epoch: 6| Step: 13
Training loss: 2.617968797683716
Validation loss: 2.0405002435048423

Epoch: 64| Step: 0
Training loss: 1.9141197204589844
Validation loss: 2.044778366883596

Epoch: 6| Step: 1
Training loss: 2.159937620162964
Validation loss: 2.050743897755941

Epoch: 6| Step: 2
Training loss: 2.378310203552246
Validation loss: 2.0545860528945923

Epoch: 6| Step: 3
Training loss: 2.4242470264434814
Validation loss: 2.0644609729448953

Epoch: 6| Step: 4
Training loss: 2.8675248622894287
Validation loss: 2.057994325955709

Epoch: 6| Step: 5
Training loss: 2.341665267944336
Validation loss: 2.051419953505198

Epoch: 6| Step: 6
Training loss: 2.299564838409424
Validation loss: 2.0514455238978067

Epoch: 6| Step: 7
Training loss: 2.329725742340088
Validation loss: 2.0509119232495627

Epoch: 6| Step: 8
Training loss: 1.9347927570343018
Validation loss: 2.0438758929570517

Epoch: 6| Step: 9
Training loss: 1.8495146036148071
Validation loss: 2.0431546568870544

Epoch: 6| Step: 10
Training loss: 2.023851156234741
Validation loss: 2.0397888819376626

Epoch: 6| Step: 11
Training loss: 2.163564682006836
Validation loss: 2.0415730277697244

Epoch: 6| Step: 12
Training loss: 2.1128358840942383
Validation loss: 2.0366298158963523

Epoch: 6| Step: 13
Training loss: 2.344146728515625
Validation loss: 2.0391859213511148

Epoch: 65| Step: 0
Training loss: 2.2446889877319336
Validation loss: 2.045396606127421

Epoch: 6| Step: 1
Training loss: 2.268103837966919
Validation loss: 2.0501078963279724

Epoch: 6| Step: 2
Training loss: 2.1401638984680176
Validation loss: 2.057133197784424

Epoch: 6| Step: 3
Training loss: 1.9715677499771118
Validation loss: 2.0513843099276223

Epoch: 6| Step: 4
Training loss: 1.7044588327407837
Validation loss: 2.04996794462204

Epoch: 6| Step: 5
Training loss: 2.1032938957214355
Validation loss: 2.044833481311798

Epoch: 6| Step: 6
Training loss: 2.7472119331359863
Validation loss: 2.042434493700663

Epoch: 6| Step: 7
Training loss: 2.271442413330078
Validation loss: 2.0450990200042725

Epoch: 6| Step: 8
Training loss: 2.7259860038757324
Validation loss: 2.0396134853363037

Epoch: 6| Step: 9
Training loss: 2.264561653137207
Validation loss: 2.04295551776886

Epoch: 6| Step: 10
Training loss: 2.2155885696411133
Validation loss: 2.0361210306485495

Epoch: 6| Step: 11
Training loss: 2.065739154815674
Validation loss: 2.0377399921417236

Epoch: 6| Step: 12
Training loss: 2.1393070220947266
Validation loss: 2.0383513768514

Epoch: 6| Step: 13
Training loss: 2.2613329887390137
Validation loss: 2.037393589814504

Epoch: 66| Step: 0
Training loss: 1.988149642944336
Validation loss: 2.0371806621551514

Epoch: 6| Step: 1
Training loss: 1.8888747692108154
Validation loss: 2.034744679927826

Epoch: 6| Step: 2
Training loss: 2.40248966217041
Validation loss: 2.034351030985514

Epoch: 6| Step: 3
Training loss: 2.0897843837738037
Validation loss: 2.036659022172292

Epoch: 6| Step: 4
Training loss: 2.179227828979492
Validation loss: 2.043074071407318

Epoch: 6| Step: 5
Training loss: 1.9922291040420532
Validation loss: 2.03731236855189

Epoch: 6| Step: 6
Training loss: 2.4938836097717285
Validation loss: 2.0412683685620627

Epoch: 6| Step: 7
Training loss: 2.6179676055908203
Validation loss: 2.0424379110336304

Epoch: 6| Step: 8
Training loss: 1.7969449758529663
Validation loss: 2.039564530054728

Epoch: 6| Step: 9
Training loss: 1.8991631269454956
Validation loss: 2.0323010285695395

Epoch: 6| Step: 10
Training loss: 2.325295925140381
Validation loss: 2.0343678990999856

Epoch: 6| Step: 11
Training loss: 2.1317591667175293
Validation loss: 2.027896245320638

Epoch: 6| Step: 12
Training loss: 2.2312886714935303
Validation loss: 2.027142802874247

Epoch: 6| Step: 13
Training loss: 3.0218546390533447
Validation loss: 2.029835363229116

Epoch: 67| Step: 0
Training loss: 2.163588047027588
Validation loss: 2.033880968888601

Epoch: 6| Step: 1
Training loss: 2.0188541412353516
Validation loss: 2.033388336499532

Epoch: 6| Step: 2
Training loss: 2.0405216217041016
Validation loss: 2.035968005657196

Epoch: 6| Step: 3
Training loss: 2.364032030105591
Validation loss: 2.041582008202871

Epoch: 6| Step: 4
Training loss: 2.0372726917266846
Validation loss: 2.0435962478319802

Epoch: 6| Step: 5
Training loss: 2.318432331085205
Validation loss: 2.045736829439799

Epoch: 6| Step: 6
Training loss: 2.6356258392333984
Validation loss: 2.050229569276174

Epoch: 6| Step: 7
Training loss: 2.3715038299560547
Validation loss: 2.0417768359184265

Epoch: 6| Step: 8
Training loss: 2.5909972190856934
Validation loss: 2.0465373198191323

Epoch: 6| Step: 9
Training loss: 2.077702522277832
Validation loss: 2.0398847659428916

Epoch: 6| Step: 10
Training loss: 1.9257245063781738
Validation loss: 2.0337816874186196

Epoch: 6| Step: 11
Training loss: 1.4742295742034912
Validation loss: 2.028157671292623

Epoch: 6| Step: 12
Training loss: 2.2809956073760986
Validation loss: 2.031089425086975

Epoch: 6| Step: 13
Training loss: 2.5837559700012207
Validation loss: 2.0265764395395913

Epoch: 68| Step: 0
Training loss: 1.9982552528381348
Validation loss: 2.0347063144048056

Epoch: 6| Step: 1
Training loss: 2.8273162841796875
Validation loss: 2.0394224723180137

Epoch: 6| Step: 2
Training loss: 2.4016101360321045
Validation loss: 2.0405715306599936

Epoch: 6| Step: 3
Training loss: 1.5398814678192139
Validation loss: 2.043089826901754

Epoch: 6| Step: 4
Training loss: 1.8723440170288086
Validation loss: 2.0450445810953775

Epoch: 6| Step: 5
Training loss: 2.2824549674987793
Validation loss: 2.0467913150787354

Epoch: 6| Step: 6
Training loss: 1.9623050689697266
Validation loss: 2.046243647734324

Epoch: 6| Step: 7
Training loss: 2.6228113174438477
Validation loss: 2.0446361899375916

Epoch: 6| Step: 8
Training loss: 2.5134267807006836
Validation loss: 2.0418021082878113

Epoch: 6| Step: 9
Training loss: 2.6456775665283203
Validation loss: 2.0433923999468484

Epoch: 6| Step: 10
Training loss: 1.8305737972259521
Validation loss: 2.0334548155466714

Epoch: 6| Step: 11
Training loss: 2.2196593284606934
Validation loss: 2.02557239929835

Epoch: 6| Step: 12
Training loss: 2.1942780017852783
Validation loss: 2.017935315767924

Epoch: 6| Step: 13
Training loss: 2.1605827808380127
Validation loss: 2.0214207569758096

Epoch: 69| Step: 0
Training loss: 1.8580595254898071
Validation loss: 2.0235729614893594

Epoch: 6| Step: 1
Training loss: 2.587256908416748
Validation loss: 2.0180605252583823

Epoch: 6| Step: 2
Training loss: 2.6024060249328613
Validation loss: 2.0309374928474426

Epoch: 6| Step: 3
Training loss: 2.16526460647583
Validation loss: 2.0481306115786233

Epoch: 6| Step: 4
Training loss: 1.7696171998977661
Validation loss: 2.060509284337362

Epoch: 6| Step: 5
Training loss: 2.605128288269043
Validation loss: 2.0566837588946023

Epoch: 6| Step: 6
Training loss: 1.8212175369262695
Validation loss: 2.0387670596440635

Epoch: 6| Step: 7
Training loss: 1.4796476364135742
Validation loss: 2.0328726967175803

Epoch: 6| Step: 8
Training loss: 2.4974753856658936
Validation loss: 2.025130788485209

Epoch: 6| Step: 9
Training loss: 2.268038749694824
Validation loss: 2.0216751297314963

Epoch: 6| Step: 10
Training loss: 2.347754716873169
Validation loss: 2.028164823849996

Epoch: 6| Step: 11
Training loss: 2.805192232131958
Validation loss: 2.036996603012085

Epoch: 6| Step: 12
Training loss: 2.0627150535583496
Validation loss: 2.035523474216461

Epoch: 6| Step: 13
Training loss: 2.0688319206237793
Validation loss: 2.0344736576080322

Epoch: 70| Step: 0
Training loss: 2.0151190757751465
Validation loss: 2.029038727283478

Epoch: 6| Step: 1
Training loss: 1.6974455118179321
Validation loss: 2.029068350791931

Epoch: 6| Step: 2
Training loss: 2.6474530696868896
Validation loss: 2.0307425061861673

Epoch: 6| Step: 3
Training loss: 2.4718210697174072
Validation loss: 2.0299585461616516

Epoch: 6| Step: 4
Training loss: 1.9353752136230469
Validation loss: 2.028200546900431

Epoch: 6| Step: 5
Training loss: 1.7963001728057861
Validation loss: 2.0278647939364114

Epoch: 6| Step: 6
Training loss: 1.9384139776229858
Validation loss: 2.024291753768921

Epoch: 6| Step: 7
Training loss: 2.2054123878479004
Validation loss: 2.0256178776423135

Epoch: 6| Step: 8
Training loss: 2.237520694732666
Validation loss: 2.030160963535309

Epoch: 6| Step: 9
Training loss: 2.072850465774536
Validation loss: 2.036144276460012

Epoch: 6| Step: 10
Training loss: 2.5478076934814453
Validation loss: 2.033530056476593

Epoch: 6| Step: 11
Training loss: 2.2592058181762695
Validation loss: 2.047500789165497

Epoch: 6| Step: 12
Training loss: 2.5675623416900635
Validation loss: 2.0407331387201944

Epoch: 6| Step: 13
Training loss: 2.331284999847412
Validation loss: 2.041425943374634

Epoch: 71| Step: 0
Training loss: 2.522960662841797
Validation loss: 2.040743430455526

Epoch: 6| Step: 1
Training loss: 2.3707168102264404
Validation loss: 2.0360609690348306

Epoch: 6| Step: 2
Training loss: 2.0324935913085938
Validation loss: 2.039601902167002

Epoch: 6| Step: 3
Training loss: 2.1177968978881836
Validation loss: 2.0320945382118225

Epoch: 6| Step: 4
Training loss: 2.890267848968506
Validation loss: 2.0326076547304788

Epoch: 6| Step: 5
Training loss: 2.591951847076416
Validation loss: 2.025955061117808

Epoch: 6| Step: 6
Training loss: 1.6092419624328613
Validation loss: 2.015052537123362

Epoch: 6| Step: 7
Training loss: 1.82099449634552
Validation loss: 2.0200586716334024

Epoch: 6| Step: 8
Training loss: 1.9434688091278076
Validation loss: 2.0243754982948303

Epoch: 6| Step: 9
Training loss: 1.7641364336013794
Validation loss: 2.020015776157379

Epoch: 6| Step: 10
Training loss: 1.5277585983276367
Validation loss: 2.023603002230326

Epoch: 6| Step: 11
Training loss: 2.281008243560791
Validation loss: 2.0196224451065063

Epoch: 6| Step: 12
Training loss: 2.860694408416748
Validation loss: 2.0233970880508423

Epoch: 6| Step: 13
Training loss: 2.26780366897583
Validation loss: 2.0214268366495767

Epoch: 72| Step: 0
Training loss: 2.601691961288452
Validation loss: 2.0253679752349854

Epoch: 6| Step: 1
Training loss: 2.3093888759613037
Validation loss: 2.0211030642191568

Epoch: 6| Step: 2
Training loss: 1.4555659294128418
Validation loss: 2.0196709434191384

Epoch: 6| Step: 3
Training loss: 2.5993409156799316
Validation loss: 2.0190202991167703

Epoch: 6| Step: 4
Training loss: 2.2893409729003906
Validation loss: 2.021132469177246

Epoch: 6| Step: 5
Training loss: 2.658853769302368
Validation loss: 2.0203900138537088

Epoch: 6| Step: 6
Training loss: 2.4010531902313232
Validation loss: 2.016888439655304

Epoch: 6| Step: 7
Training loss: 1.806117296218872
Validation loss: 2.013347546259562

Epoch: 6| Step: 8
Training loss: 1.858648657798767
Validation loss: 2.013228476047516

Epoch: 6| Step: 9
Training loss: 2.0951738357543945
Validation loss: 2.0115777055422464

Epoch: 6| Step: 10
Training loss: 2.174623727798462
Validation loss: 2.0167359511057534

Epoch: 6| Step: 11
Training loss: 1.822126865386963
Validation loss: 2.028174956639608

Epoch: 6| Step: 12
Training loss: 1.9511735439300537
Validation loss: 2.0281337896982827

Epoch: 6| Step: 13
Training loss: 2.5724453926086426
Validation loss: 2.0220467845598855

Epoch: 73| Step: 0
Training loss: 1.670389175415039
Validation loss: 2.0223946968714395

Epoch: 6| Step: 1
Training loss: 2.2130496501922607
Validation loss: 2.019039571285248

Epoch: 6| Step: 2
Training loss: 2.5289907455444336
Validation loss: 2.0244296193122864

Epoch: 6| Step: 3
Training loss: 2.4058992862701416
Validation loss: 2.0278758804003396

Epoch: 6| Step: 4
Training loss: 2.1794254779815674
Validation loss: 2.018678625424703

Epoch: 6| Step: 5
Training loss: 1.6625864505767822
Validation loss: 2.021732747554779

Epoch: 6| Step: 6
Training loss: 2.3294639587402344
Validation loss: 2.0117542346318564

Epoch: 6| Step: 7
Training loss: 2.601992607116699
Validation loss: 2.017206867535909

Epoch: 6| Step: 8
Training loss: 1.8915116786956787
Validation loss: 2.020204325517019

Epoch: 6| Step: 9
Training loss: 2.4155452251434326
Validation loss: 2.0301326711972556

Epoch: 6| Step: 10
Training loss: 2.1929214000701904
Validation loss: 2.0324782133102417

Epoch: 6| Step: 11
Training loss: 2.6161303520202637
Validation loss: 2.0311426917711892

Epoch: 6| Step: 12
Training loss: 2.087113380432129
Validation loss: 2.0280062357584634

Epoch: 6| Step: 13
Training loss: 1.9658010005950928
Validation loss: 2.0221860806147256

Epoch: 74| Step: 0
Training loss: 1.662948489189148
Validation loss: 2.0109546780586243

Epoch: 6| Step: 1
Training loss: 2.206601142883301
Validation loss: 2.009067932764689

Epoch: 6| Step: 2
Training loss: 2.0781145095825195
Validation loss: 2.009292721748352

Epoch: 6| Step: 3
Training loss: 2.638212203979492
Validation loss: 2.0198280215263367

Epoch: 6| Step: 4
Training loss: 2.362950325012207
Validation loss: 2.023450175921122

Epoch: 6| Step: 5
Training loss: 2.3947644233703613
Validation loss: 2.0336188276608786

Epoch: 6| Step: 6
Training loss: 1.8211886882781982
Validation loss: 2.028945485750834

Epoch: 6| Step: 7
Training loss: 2.3647427558898926
Validation loss: 2.036118487517039

Epoch: 6| Step: 8
Training loss: 2.3950510025024414
Validation loss: 2.0325735012690225

Epoch: 6| Step: 9
Training loss: 1.7950752973556519
Validation loss: 2.039651791254679

Epoch: 6| Step: 10
Training loss: 2.3911452293395996
Validation loss: 2.0361534357070923

Epoch: 6| Step: 11
Training loss: 2.099133014678955
Validation loss: 2.020984629789988

Epoch: 6| Step: 12
Training loss: 2.0196475982666016
Validation loss: 2.0216814080874124

Epoch: 6| Step: 13
Training loss: 2.488987445831299
Validation loss: 2.014525314172109

Epoch: 75| Step: 0
Training loss: 2.2224597930908203
Validation loss: 2.0154309074083963

Epoch: 6| Step: 1
Training loss: 2.3861188888549805
Validation loss: 2.0178053975105286

Epoch: 6| Step: 2
Training loss: 1.8072419166564941
Validation loss: 2.0219059586524963

Epoch: 6| Step: 3
Training loss: 2.180373191833496
Validation loss: 2.025567630926768

Epoch: 6| Step: 4
Training loss: 2.6469316482543945
Validation loss: 2.0317305525143943

Epoch: 6| Step: 5
Training loss: 1.6140860319137573
Validation loss: 2.034767727057139

Epoch: 6| Step: 6
Training loss: 2.182527780532837
Validation loss: 2.0323293606440225

Epoch: 6| Step: 7
Training loss: 2.4807658195495605
Validation loss: 2.033012628555298

Epoch: 6| Step: 8
Training loss: 2.331495523452759
Validation loss: 2.030557076136271

Epoch: 6| Step: 9
Training loss: 1.7677044868469238
Validation loss: 2.0295944611231485

Epoch: 6| Step: 10
Training loss: 2.4989492893218994
Validation loss: 2.0219278732935586

Epoch: 6| Step: 11
Training loss: 2.5526819229125977
Validation loss: 2.02165025472641

Epoch: 6| Step: 12
Training loss: 2.001788854598999
Validation loss: 2.0143845677375793

Epoch: 6| Step: 13
Training loss: 2.1592931747436523
Validation loss: 2.0116383830706277

Epoch: 76| Step: 0
Training loss: 2.219783067703247
Validation loss: 2.0069673458735147

Epoch: 6| Step: 1
Training loss: 2.4863781929016113
Validation loss: 2.0080132484436035

Epoch: 6| Step: 2
Training loss: 2.1641428470611572
Validation loss: 2.0090776880582175

Epoch: 6| Step: 3
Training loss: 1.5555477142333984
Validation loss: 2.006362954775492

Epoch: 6| Step: 4
Training loss: 2.720837116241455
Validation loss: 2.009871184825897

Epoch: 6| Step: 5
Training loss: 2.6366372108459473
Validation loss: 2.007497171560923

Epoch: 6| Step: 6
Training loss: 2.2146682739257812
Validation loss: 2.0119828383127847

Epoch: 6| Step: 7
Training loss: 2.015979290008545
Validation loss: 2.015469213326772

Epoch: 6| Step: 8
Training loss: 1.674846887588501
Validation loss: 2.019808272520701

Epoch: 6| Step: 9
Training loss: 1.7307034730911255
Validation loss: 2.022619644800822

Epoch: 6| Step: 10
Training loss: 1.6292288303375244
Validation loss: 2.0218790968259177

Epoch: 6| Step: 11
Training loss: 1.9230097532272339
Validation loss: 2.026973307132721

Epoch: 6| Step: 12
Training loss: 2.4698290824890137
Validation loss: 2.0332852800687156

Epoch: 6| Step: 13
Training loss: 2.878936290740967
Validation loss: 2.0297274589538574

Epoch: 77| Step: 0
Training loss: 2.481977939605713
Validation loss: 2.0325692693392434

Epoch: 6| Step: 1
Training loss: 1.803881287574768
Validation loss: 2.0467515786488852

Epoch: 6| Step: 2
Training loss: 1.5402401685714722
Validation loss: 2.042156457901001

Epoch: 6| Step: 3
Training loss: 2.0244410037994385
Validation loss: 2.050206959247589

Epoch: 6| Step: 4
Training loss: 2.2436695098876953
Validation loss: 2.0561040242513022

Epoch: 6| Step: 5
Training loss: 2.181544303894043
Validation loss: 2.0555324951807656

Epoch: 6| Step: 6
Training loss: 2.879739761352539
Validation loss: 2.044067700703939

Epoch: 6| Step: 7
Training loss: 2.6642422676086426
Validation loss: 2.0311854680379233

Epoch: 6| Step: 8
Training loss: 1.8281915187835693
Validation loss: 2.023669938246409

Epoch: 6| Step: 9
Training loss: 1.8464676141738892
Validation loss: 2.017141838868459

Epoch: 6| Step: 10
Training loss: 1.7955951690673828
Validation loss: 2.011584917704264

Epoch: 6| Step: 11
Training loss: 2.48978328704834
Validation loss: 2.0083149671554565

Epoch: 6| Step: 12
Training loss: 2.0385091304779053
Validation loss: 2.0065519412358603

Epoch: 6| Step: 13
Training loss: 2.8279061317443848
Validation loss: 2.00640078385671

Epoch: 78| Step: 0
Training loss: 1.8292515277862549
Validation loss: 2.009051819642385

Epoch: 6| Step: 1
Training loss: 2.052670955657959
Validation loss: 2.0098403890927634

Epoch: 6| Step: 2
Training loss: 2.403662919998169
Validation loss: 2.0117624203364053

Epoch: 6| Step: 3
Training loss: 2.4326562881469727
Validation loss: 2.009129822254181

Epoch: 6| Step: 4
Training loss: 2.531508445739746
Validation loss: 2.012902577718099

Epoch: 6| Step: 5
Training loss: 2.289421558380127
Validation loss: 2.013837774594625

Epoch: 6| Step: 6
Training loss: 1.533555269241333
Validation loss: 2.0149914423624673

Epoch: 6| Step: 7
Training loss: 2.9205756187438965
Validation loss: 2.016495188077291

Epoch: 6| Step: 8
Training loss: 1.9261810779571533
Validation loss: 2.015888830025991

Epoch: 6| Step: 9
Training loss: 2.1997482776641846
Validation loss: 2.0205158392588296

Epoch: 6| Step: 10
Training loss: 2.42311954498291
Validation loss: 2.0110755562782288

Epoch: 6| Step: 11
Training loss: 1.4496097564697266
Validation loss: 2.008487602074941

Epoch: 6| Step: 12
Training loss: 2.1159448623657227
Validation loss: 2.0078651309013367

Epoch: 6| Step: 13
Training loss: 2.1787314414978027
Validation loss: 2.0078909198443093

Epoch: 79| Step: 0
Training loss: 2.161989688873291
Validation loss: 2.0123562812805176

Epoch: 6| Step: 1
Training loss: 2.685270071029663
Validation loss: 2.02042692899704

Epoch: 6| Step: 2
Training loss: 1.694176197052002
Validation loss: 2.020277182261149

Epoch: 6| Step: 3
Training loss: 1.8256348371505737
Validation loss: 2.027102013429006

Epoch: 6| Step: 4
Training loss: 2.3676705360412598
Validation loss: 2.032953898111979

Epoch: 6| Step: 5
Training loss: 2.0687928199768066
Validation loss: 2.0354971885681152

Epoch: 6| Step: 6
Training loss: 2.40898060798645
Validation loss: 2.032857040564219

Epoch: 6| Step: 7
Training loss: 2.091912269592285
Validation loss: 2.03863795598348

Epoch: 6| Step: 8
Training loss: 2.5811805725097656
Validation loss: 2.0241770346959433

Epoch: 6| Step: 9
Training loss: 2.0623631477355957
Validation loss: 2.0202780763308206

Epoch: 6| Step: 10
Training loss: 2.19295072555542
Validation loss: 2.0206262866655984

Epoch: 6| Step: 11
Training loss: 1.4180219173431396
Validation loss: 2.014681100845337

Epoch: 6| Step: 12
Training loss: 2.1825664043426514
Validation loss: 2.0083080927530923

Epoch: 6| Step: 13
Training loss: 2.7144436836242676
Validation loss: 2.010205328464508

Epoch: 80| Step: 0
Training loss: 1.8574018478393555
Validation loss: 2.0124945441881814

Epoch: 6| Step: 1
Training loss: 1.8941689729690552
Validation loss: 2.012246529261271

Epoch: 6| Step: 2
Training loss: 1.966295599937439
Validation loss: 2.012707610925039

Epoch: 6| Step: 3
Training loss: 2.7791898250579834
Validation loss: 2.006137251853943

Epoch: 6| Step: 4
Training loss: 2.1975345611572266
Validation loss: 2.0050697525342307

Epoch: 6| Step: 5
Training loss: 2.200894355773926
Validation loss: 2.0086647272109985

Epoch: 6| Step: 6
Training loss: 2.1200473308563232
Validation loss: 2.006467084089915

Epoch: 6| Step: 7
Training loss: 1.872368335723877
Validation loss: 2.0146142641703286

Epoch: 6| Step: 8
Training loss: 2.717460870742798
Validation loss: 2.0106442173322043

Epoch: 6| Step: 9
Training loss: 2.717449188232422
Validation loss: 2.0112930138905845

Epoch: 6| Step: 10
Training loss: 2.041170120239258
Validation loss: 2.008616248766581

Epoch: 6| Step: 11
Training loss: 1.6802552938461304
Validation loss: 2.0052037239074707

Epoch: 6| Step: 12
Training loss: 2.328279495239258
Validation loss: 2.004554331302643

Epoch: 6| Step: 13
Training loss: 2.144296884536743
Validation loss: 2.007256825764974

Epoch: 81| Step: 0
Training loss: 2.713184356689453
Validation loss: 2.008627971013387

Epoch: 6| Step: 1
Training loss: 2.5318546295166016
Validation loss: 2.0097865660985312

Epoch: 6| Step: 2
Training loss: 2.196171998977661
Validation loss: 2.0118323961893716

Epoch: 6| Step: 3
Training loss: 2.555457353591919
Validation loss: 2.013622601826986

Epoch: 6| Step: 4
Training loss: 1.2941571474075317
Validation loss: 2.019154171148936

Epoch: 6| Step: 5
Training loss: 1.978750467300415
Validation loss: 2.020616869131724

Epoch: 6| Step: 6
Training loss: 2.9537720680236816
Validation loss: 2.0197741985321045

Epoch: 6| Step: 7
Training loss: 2.321688413619995
Validation loss: 2.012389898300171

Epoch: 6| Step: 8
Training loss: 1.6603549718856812
Validation loss: 2.01472932100296

Epoch: 6| Step: 9
Training loss: 1.8882352113723755
Validation loss: 2.014836331208547

Epoch: 6| Step: 10
Training loss: 2.0929977893829346
Validation loss: 2.017432371775309

Epoch: 6| Step: 11
Training loss: 1.7499034404754639
Validation loss: 2.026337762673696

Epoch: 6| Step: 12
Training loss: 2.399292469024658
Validation loss: 2.0320473512013755

Epoch: 6| Step: 13
Training loss: 1.9900460243225098
Validation loss: 2.0367035071055093

Epoch: 82| Step: 0
Training loss: 2.1426870822906494
Validation loss: 2.0363850196202598

Epoch: 6| Step: 1
Training loss: 2.2663180828094482
Validation loss: 2.040410498778025

Epoch: 6| Step: 2
Training loss: 2.3251867294311523
Validation loss: 2.0324336290359497

Epoch: 6| Step: 3
Training loss: 2.0960817337036133
Validation loss: 2.0336541533470154

Epoch: 6| Step: 4
Training loss: 2.465322256088257
Validation loss: 2.033876339594523

Epoch: 6| Step: 5
Training loss: 1.627485752105713
Validation loss: 2.0283390084902444

Epoch: 6| Step: 6
Training loss: 1.6885309219360352
Validation loss: 2.0164895057678223

Epoch: 6| Step: 7
Training loss: 1.9154658317565918
Validation loss: 2.0201764504114785

Epoch: 6| Step: 8
Training loss: 2.1158387660980225
Validation loss: 2.0180015563964844

Epoch: 6| Step: 9
Training loss: 2.1066606044769287
Validation loss: 2.0168718298276267

Epoch: 6| Step: 10
Training loss: 2.4025449752807617
Validation loss: 2.0206472476323447

Epoch: 6| Step: 11
Training loss: 2.317127227783203
Validation loss: 2.0125960310300193

Epoch: 6| Step: 12
Training loss: 2.5431432723999023
Validation loss: 2.0143205722173056

Epoch: 6| Step: 13
Training loss: 2.34130859375
Validation loss: 2.017495274543762

Epoch: 83| Step: 0
Training loss: 2.5098557472229004
Validation loss: 2.015752116839091

Epoch: 6| Step: 1
Training loss: 2.145318031311035
Validation loss: 2.019107719262441

Epoch: 6| Step: 2
Training loss: 2.345658302307129
Validation loss: 2.00870672861735

Epoch: 6| Step: 3
Training loss: 2.557011127471924
Validation loss: 2.0152944525082908

Epoch: 6| Step: 4
Training loss: 1.9043352603912354
Validation loss: 2.0166794260342917

Epoch: 6| Step: 5
Training loss: 1.6813386678695679
Validation loss: 2.0134102503458657

Epoch: 6| Step: 6
Training loss: 2.048007011413574
Validation loss: 2.0114779074986777

Epoch: 6| Step: 7
Training loss: 2.404905080795288
Validation loss: 2.015714645385742

Epoch: 6| Step: 8
Training loss: 1.7706400156021118
Validation loss: 2.0108505487442017

Epoch: 6| Step: 9
Training loss: 2.3598179817199707
Validation loss: 2.006777842839559

Epoch: 6| Step: 10
Training loss: 2.1053659915924072
Validation loss: 2.0121062596639

Epoch: 6| Step: 11
Training loss: 2.1908915042877197
Validation loss: 2.010764936606089

Epoch: 6| Step: 12
Training loss: 1.85184907913208
Validation loss: 2.017929494380951

Epoch: 6| Step: 13
Training loss: 2.282991409301758
Validation loss: 2.0149712562561035

Epoch: 84| Step: 0
Training loss: 2.732121229171753
Validation loss: 2.0081791083017984

Epoch: 6| Step: 1
Training loss: 1.8885307312011719
Validation loss: 2.0114835699399314

Epoch: 6| Step: 2
Training loss: 2.017890453338623
Validation loss: 2.0110892057418823

Epoch: 6| Step: 3
Training loss: 2.0730066299438477
Validation loss: 2.0094913641611734

Epoch: 6| Step: 4
Training loss: 2.0735719203948975
Validation loss: 2.00499826669693

Epoch: 6| Step: 5
Training loss: 1.7416164875030518
Validation loss: 2.0062629779179892

Epoch: 6| Step: 6
Training loss: 1.9643328189849854
Validation loss: 2.0080706079800925

Epoch: 6| Step: 7
Training loss: 2.098360300064087
Validation loss: 2.0170010924339294

Epoch: 6| Step: 8
Training loss: 2.3047916889190674
Validation loss: 2.0078965425491333

Epoch: 6| Step: 9
Training loss: 1.7787365913391113
Validation loss: 2.007603108882904

Epoch: 6| Step: 10
Training loss: 1.8604321479797363
Validation loss: 2.0110251108805337

Epoch: 6| Step: 11
Training loss: 2.822932720184326
Validation loss: 2.007943590482076

Epoch: 6| Step: 12
Training loss: 2.129024028778076
Validation loss: 2.008746067682902

Epoch: 6| Step: 13
Training loss: 2.6707029342651367
Validation loss: 2.0071049332618713

Epoch: 85| Step: 0
Training loss: 2.1007754802703857
Validation loss: 2.0108648339907327

Epoch: 6| Step: 1
Training loss: 1.9035687446594238
Validation loss: 2.0134456753730774

Epoch: 6| Step: 2
Training loss: 1.9976584911346436
Validation loss: 2.022658109664917

Epoch: 6| Step: 3
Training loss: 2.3744330406188965
Validation loss: 2.0286410252253213

Epoch: 6| Step: 4
Training loss: 2.3384246826171875
Validation loss: 2.025946040948232

Epoch: 6| Step: 5
Training loss: 1.8540449142456055
Validation loss: 2.0275933543841043

Epoch: 6| Step: 6
Training loss: 1.8588849306106567
Validation loss: 2.021730899810791

Epoch: 6| Step: 7
Training loss: 2.461780071258545
Validation loss: 2.0118499398231506

Epoch: 6| Step: 8
Training loss: 2.1537046432495117
Validation loss: 2.0165101687113443

Epoch: 6| Step: 9
Training loss: 2.567370891571045
Validation loss: 2.011995772520701

Epoch: 6| Step: 10
Training loss: 2.0988411903381348
Validation loss: 2.007632076740265

Epoch: 6| Step: 11
Training loss: 2.0415427684783936
Validation loss: 2.008426606655121

Epoch: 6| Step: 12
Training loss: 2.4548089504241943
Validation loss: 2.0145748058954873

Epoch: 6| Step: 13
Training loss: 2.110736846923828
Validation loss: 2.0113304257392883

Epoch: 86| Step: 0
Training loss: 2.7066469192504883
Validation loss: 2.0204163193702698

Epoch: 6| Step: 1
Training loss: 2.245083808898926
Validation loss: 2.016812264919281

Epoch: 6| Step: 2
Training loss: 2.193692922592163
Validation loss: 2.0177144408226013

Epoch: 6| Step: 3
Training loss: 2.150925874710083
Validation loss: 2.0176000396410623

Epoch: 6| Step: 4
Training loss: 2.4795632362365723
Validation loss: 2.014956255753835

Epoch: 6| Step: 5
Training loss: 1.353989839553833
Validation loss: 2.0093636910120645

Epoch: 6| Step: 6
Training loss: 1.966496467590332
Validation loss: 2.008767604827881

Epoch: 6| Step: 7
Training loss: 1.7073957920074463
Validation loss: 2.0097671151161194

Epoch: 6| Step: 8
Training loss: 2.3847038745880127
Validation loss: 2.017609159151713

Epoch: 6| Step: 9
Training loss: 2.1443629264831543
Validation loss: 2.0304297606150308

Epoch: 6| Step: 10
Training loss: 2.2390990257263184
Validation loss: 2.024033844470978

Epoch: 6| Step: 11
Training loss: 2.547109603881836
Validation loss: 2.0261994004249573

Epoch: 6| Step: 12
Training loss: 2.1314785480499268
Validation loss: 2.0303882559140525

Epoch: 6| Step: 13
Training loss: 2.054382801055908
Validation loss: 2.025495986143748

Epoch: 87| Step: 0
Training loss: 2.1086976528167725
Validation loss: 2.0343847473462424

Epoch: 6| Step: 1
Training loss: 2.183587074279785
Validation loss: 2.0259581009546914

Epoch: 6| Step: 2
Training loss: 2.2191057205200195
Validation loss: 2.024867514769236

Epoch: 6| Step: 3
Training loss: 2.4510598182678223
Validation loss: 2.0282321770985923

Epoch: 6| Step: 4
Training loss: 1.9520559310913086
Validation loss: 2.026323397954305

Epoch: 6| Step: 5
Training loss: 2.2632551193237305
Validation loss: 2.0238216320673623

Epoch: 6| Step: 6
Training loss: 2.623115062713623
Validation loss: 2.0281437039375305

Epoch: 6| Step: 7
Training loss: 1.9740654230117798
Validation loss: 2.0222203532854715

Epoch: 6| Step: 8
Training loss: 1.8943144083023071
Validation loss: 2.0195159117380777

Epoch: 6| Step: 9
Training loss: 1.68520188331604
Validation loss: 2.014170070489248

Epoch: 6| Step: 10
Training loss: 1.9933578968048096
Validation loss: 2.011646548906962

Epoch: 6| Step: 11
Training loss: 2.242046594619751
Validation loss: 2.011826674143473

Epoch: 6| Step: 12
Training loss: 1.9641146659851074
Validation loss: 2.017229596773783

Epoch: 6| Step: 13
Training loss: 2.280299663543701
Validation loss: 2.008249282836914

Epoch: 88| Step: 0
Training loss: 2.0526442527770996
Validation loss: 1.998392661412557

Epoch: 6| Step: 1
Training loss: 2.3290603160858154
Validation loss: 2.0050830841064453

Epoch: 6| Step: 2
Training loss: 2.1429662704467773
Validation loss: 2.0107558568318686

Epoch: 6| Step: 3
Training loss: 1.7956547737121582
Validation loss: 2.0109938184420266

Epoch: 6| Step: 4
Training loss: 2.815537929534912
Validation loss: 2.0109026432037354

Epoch: 6| Step: 5
Training loss: 1.6820992231369019
Validation loss: 2.0208586057027182

Epoch: 6| Step: 6
Training loss: 1.9302825927734375
Validation loss: 2.024217208226522

Epoch: 6| Step: 7
Training loss: 2.15350341796875
Validation loss: 2.02118311325709

Epoch: 6| Step: 8
Training loss: 2.035860538482666
Validation loss: 2.026577115058899

Epoch: 6| Step: 9
Training loss: 2.665299415588379
Validation loss: 2.0235082308451333

Epoch: 6| Step: 10
Training loss: 1.9432491064071655
Validation loss: 2.0231647292772927

Epoch: 6| Step: 11
Training loss: 2.452486991882324
Validation loss: 2.019621749718984

Epoch: 6| Step: 12
Training loss: 1.8422167301177979
Validation loss: 2.018967390060425

Epoch: 6| Step: 13
Training loss: 2.1304006576538086
Validation loss: 2.0212453802426658

Epoch: 89| Step: 0
Training loss: 1.6476962566375732
Validation loss: 2.0216911236445108

Epoch: 6| Step: 1
Training loss: 1.9691146612167358
Validation loss: 2.021410862604777

Epoch: 6| Step: 2
Training loss: 2.2738661766052246
Validation loss: 2.023693780104319

Epoch: 6| Step: 3
Training loss: 2.5263233184814453
Validation loss: 2.0324589014053345

Epoch: 6| Step: 4
Training loss: 2.906644582748413
Validation loss: 2.021104097366333

Epoch: 6| Step: 5
Training loss: 2.0051612854003906
Validation loss: 2.0128147999445596

Epoch: 6| Step: 6
Training loss: 2.052989959716797
Validation loss: 2.0207533041636148

Epoch: 6| Step: 7
Training loss: 1.8072351217269897
Validation loss: 2.01923139890035

Epoch: 6| Step: 8
Training loss: 1.7434459924697876
Validation loss: 2.019042491912842

Epoch: 6| Step: 9
Training loss: 2.524357557296753
Validation loss: 2.017945885658264

Epoch: 6| Step: 10
Training loss: 1.966112732887268
Validation loss: 2.018165111541748

Epoch: 6| Step: 11
Training loss: 2.2377254962921143
Validation loss: 2.0216736793518066

Epoch: 6| Step: 12
Training loss: 2.03478741645813
Validation loss: 2.025223970413208

Epoch: 6| Step: 13
Training loss: 2.1699399948120117
Validation loss: 2.0205626289049783

Epoch: 90| Step: 0
Training loss: 2.544245958328247
Validation loss: 2.0168521205584207

Epoch: 6| Step: 1
Training loss: 1.9146020412445068
Validation loss: 2.0149385134379068

Epoch: 6| Step: 2
Training loss: 1.9392893314361572
Validation loss: 2.0100273291269937

Epoch: 6| Step: 3
Training loss: 2.1986663341522217
Validation loss: 2.011469781398773

Epoch: 6| Step: 4
Training loss: 1.8426616191864014
Validation loss: 2.0092425545056662

Epoch: 6| Step: 5
Training loss: 1.6502580642700195
Validation loss: 2.007787903149923

Epoch: 6| Step: 6
Training loss: 2.2298874855041504
Validation loss: 2.007952610651652

Epoch: 6| Step: 7
Training loss: 1.8688547611236572
Validation loss: 2.0093168218930564

Epoch: 6| Step: 8
Training loss: 2.5709710121154785
Validation loss: 2.0090370774269104

Epoch: 6| Step: 9
Training loss: 2.0626697540283203
Validation loss: 2.009245495001475

Epoch: 6| Step: 10
Training loss: 1.7947242259979248
Validation loss: 2.010791858037313

Epoch: 6| Step: 11
Training loss: 2.3447422981262207
Validation loss: 2.0182085235913596

Epoch: 6| Step: 12
Training loss: 2.3503670692443848
Validation loss: 2.0142266154289246

Epoch: 6| Step: 13
Training loss: 2.4168622493743896
Validation loss: 2.0245007077852883

Epoch: 91| Step: 0
Training loss: 1.978898525238037
Validation loss: 2.0271703600883484

Epoch: 6| Step: 1
Training loss: 2.564082622528076
Validation loss: 2.0332303047180176

Epoch: 6| Step: 2
Training loss: 2.3173327445983887
Validation loss: 2.0118274092674255

Epoch: 6| Step: 3
Training loss: 2.1286325454711914
Validation loss: 2.0216426452000937

Epoch: 6| Step: 4
Training loss: 2.1688477993011475
Validation loss: 2.0183663368225098

Epoch: 6| Step: 5
Training loss: 1.7601988315582275
Validation loss: 2.020090162754059

Epoch: 6| Step: 6
Training loss: 1.9838651418685913
Validation loss: 2.0177119771639505

Epoch: 6| Step: 7
Training loss: 2.300774574279785
Validation loss: 2.023355782032013

Epoch: 6| Step: 8
Training loss: 1.7109882831573486
Validation loss: 2.016879757245382

Epoch: 6| Step: 9
Training loss: 2.832162857055664
Validation loss: 2.011612872282664

Epoch: 6| Step: 10
Training loss: 2.3929126262664795
Validation loss: 2.008845647176107

Epoch: 6| Step: 11
Training loss: 1.564436674118042
Validation loss: 2.0099016427993774

Epoch: 6| Step: 12
Training loss: 2.2361931800842285
Validation loss: 2.010346829891205

Epoch: 6| Step: 13
Training loss: 1.9318342208862305
Validation loss: 2.0147815545399985

Epoch: 92| Step: 0
Training loss: 1.695213794708252
Validation loss: 2.00706152121226

Epoch: 6| Step: 1
Training loss: 1.989512324333191
Validation loss: 2.0053976575533548

Epoch: 6| Step: 2
Training loss: 2.489814519882202
Validation loss: 2.002518574396769

Epoch: 6| Step: 3
Training loss: 2.207003116607666
Validation loss: 2.00252773364385

Epoch: 6| Step: 4
Training loss: 2.611825942993164
Validation loss: 2.0081151127815247

Epoch: 6| Step: 5
Training loss: 2.551469326019287
Validation loss: 2.0108940601348877

Epoch: 6| Step: 6
Training loss: 1.9963998794555664
Validation loss: 2.01208625237147

Epoch: 6| Step: 7
Training loss: 2.8703393936157227
Validation loss: 2.0189340313275657

Epoch: 6| Step: 8
Training loss: 2.0494914054870605
Validation loss: 2.008882164955139

Epoch: 6| Step: 9
Training loss: 1.4181264638900757
Validation loss: 2.0069458285967507

Epoch: 6| Step: 10
Training loss: 1.9502249956130981
Validation loss: 1.9978886246681213

Epoch: 6| Step: 11
Training loss: 1.734466552734375
Validation loss: 2.001602590084076

Epoch: 6| Step: 12
Training loss: 2.4684083461761475
Validation loss: 1.99494465192159

Epoch: 6| Step: 13
Training loss: 1.978342056274414
Validation loss: 2.000439782937368

Epoch: 93| Step: 0
Training loss: 2.1683189868927
Validation loss: 1.9969897667566936

Epoch: 6| Step: 1
Training loss: 2.2291364669799805
Validation loss: 1.9985931515693665

Epoch: 6| Step: 2
Training loss: 2.1395599842071533
Validation loss: 1.9980028072992961

Epoch: 6| Step: 3
Training loss: 2.2961134910583496
Validation loss: 1.9979176918665569

Epoch: 6| Step: 4
Training loss: 2.0308451652526855
Validation loss: 1.9955877264340718

Epoch: 6| Step: 5
Training loss: 2.370565891265869
Validation loss: 1.993931810061137

Epoch: 6| Step: 6
Training loss: 2.2977662086486816
Validation loss: 1.9974733988444011

Epoch: 6| Step: 7
Training loss: 1.8821135759353638
Validation loss: 1.9925685326258342

Epoch: 6| Step: 8
Training loss: 2.065093517303467
Validation loss: 2.0039809346199036

Epoch: 6| Step: 9
Training loss: 1.8134952783584595
Validation loss: 1.9974631667137146

Epoch: 6| Step: 10
Training loss: 2.122323989868164
Validation loss: 2.002047876516978

Epoch: 6| Step: 11
Training loss: 1.9324787855148315
Validation loss: 2.0035325487454734

Epoch: 6| Step: 12
Training loss: 2.1691784858703613
Validation loss: 2.003600815931956

Epoch: 6| Step: 13
Training loss: 2.110682487487793
Validation loss: 2.0006572604179382

Epoch: 94| Step: 0
Training loss: 1.9677503108978271
Validation loss: 2.0190682212511697

Epoch: 6| Step: 1
Training loss: 2.4807984828948975
Validation loss: 2.013040999571482

Epoch: 6| Step: 2
Training loss: 2.3070507049560547
Validation loss: 2.018618027369181

Epoch: 6| Step: 3
Training loss: 2.418367862701416
Validation loss: 2.0141176184018454

Epoch: 6| Step: 4
Training loss: 1.8199083805084229
Validation loss: 2.016612728436788

Epoch: 6| Step: 5
Training loss: 2.193448543548584
Validation loss: 2.0154772202173867

Epoch: 6| Step: 6
Training loss: 2.0151853561401367
Validation loss: 2.0112959146499634

Epoch: 6| Step: 7
Training loss: 1.6414482593536377
Validation loss: 2.0149197578430176

Epoch: 6| Step: 8
Training loss: 2.130845785140991
Validation loss: 2.009427845478058

Epoch: 6| Step: 9
Training loss: 2.30322527885437
Validation loss: 2.003040373325348

Epoch: 6| Step: 10
Training loss: 2.1800930500030518
Validation loss: 2.0048608581225076

Epoch: 6| Step: 11
Training loss: 1.8558411598205566
Validation loss: 2.008613030115763

Epoch: 6| Step: 12
Training loss: 2.1849048137664795
Validation loss: 2.0008660356203714

Epoch: 6| Step: 13
Training loss: 2.129762887954712
Validation loss: 2.004453877607981

Epoch: 95| Step: 0
Training loss: 2.2281112670898438
Validation loss: 2.0173673828442893

Epoch: 6| Step: 1
Training loss: 1.8122048377990723
Validation loss: 2.0123884280522666

Epoch: 6| Step: 2
Training loss: 2.3368430137634277
Validation loss: 2.016062160332998

Epoch: 6| Step: 3
Training loss: 2.1206917762756348
Validation loss: 2.012495299180349

Epoch: 6| Step: 4
Training loss: 1.9295334815979004
Validation loss: 2.014493227005005

Epoch: 6| Step: 5
Training loss: 2.6414129734039307
Validation loss: 2.0158907969792685

Epoch: 6| Step: 6
Training loss: 2.158987045288086
Validation loss: 2.0201751987139382

Epoch: 6| Step: 7
Training loss: 2.401252269744873
Validation loss: 2.0172335108121238

Epoch: 6| Step: 8
Training loss: 1.7728537321090698
Validation loss: 2.0113946398099265

Epoch: 6| Step: 9
Training loss: 1.7280027866363525
Validation loss: 2.014211336771647

Epoch: 6| Step: 10
Training loss: 2.1354258060455322
Validation loss: 2.0117687781651816

Epoch: 6| Step: 11
Training loss: 1.9958820343017578
Validation loss: 2.003288288911184

Epoch: 6| Step: 12
Training loss: 2.0979552268981934
Validation loss: 2.003265639146169

Epoch: 6| Step: 13
Training loss: 2.806879758834839
Validation loss: 2.0013734300931296

Epoch: 96| Step: 0
Training loss: 2.1594014167785645
Validation loss: 2.0115433732668557

Epoch: 6| Step: 1
Training loss: 2.60867977142334
Validation loss: 2.0099047819773355

Epoch: 6| Step: 2
Training loss: 1.7183412313461304
Validation loss: 2.016039788722992

Epoch: 6| Step: 3
Training loss: 2.034641742706299
Validation loss: 2.020202954610189

Epoch: 6| Step: 4
Training loss: 1.8208129405975342
Validation loss: 2.0155123472213745

Epoch: 6| Step: 5
Training loss: 2.3902604579925537
Validation loss: 2.0109644532203674

Epoch: 6| Step: 6
Training loss: 2.089085817337036
Validation loss: 2.0143786867459617

Epoch: 6| Step: 7
Training loss: 2.5243825912475586
Validation loss: 2.0176039139429727

Epoch: 6| Step: 8
Training loss: 1.4450676441192627
Validation loss: 2.0239787300427756

Epoch: 6| Step: 9
Training loss: 2.8732943534851074
Validation loss: 2.025000274181366

Epoch: 6| Step: 10
Training loss: 1.9187184572219849
Validation loss: 2.0170689026514688

Epoch: 6| Step: 11
Training loss: 2.410074234008789
Validation loss: 2.013475557168325

Epoch: 6| Step: 12
Training loss: 1.5545196533203125
Validation loss: 2.0236637194951377

Epoch: 6| Step: 13
Training loss: 2.0884313583374023
Validation loss: 2.0111783544222512

Epoch: 97| Step: 0
Training loss: 2.1330699920654297
Validation loss: 2.0092356403668723

Epoch: 6| Step: 1
Training loss: 1.8608160018920898
Validation loss: 2.020608206590017

Epoch: 6| Step: 2
Training loss: 2.801821708679199
Validation loss: 2.009749392668406

Epoch: 6| Step: 3
Training loss: 2.7733983993530273
Validation loss: 2.0102574626604715

Epoch: 6| Step: 4
Training loss: 1.565192699432373
Validation loss: 2.0121939977010093

Epoch: 6| Step: 5
Training loss: 1.8816609382629395
Validation loss: 2.0116661190986633

Epoch: 6| Step: 6
Training loss: 2.3151068687438965
Validation loss: 2.0090788205464682

Epoch: 6| Step: 7
Training loss: 1.7024239301681519
Validation loss: 2.010428329308828

Epoch: 6| Step: 8
Training loss: 2.16807222366333
Validation loss: 2.0158156752586365

Epoch: 6| Step: 9
Training loss: 1.8259570598602295
Validation loss: 2.0147870779037476

Epoch: 6| Step: 10
Training loss: 1.545238971710205
Validation loss: 2.021321694056193

Epoch: 6| Step: 11
Training loss: 2.4339847564697266
Validation loss: 2.016183614730835

Epoch: 6| Step: 12
Training loss: 2.474945068359375
Validation loss: 2.0167292952537537

Epoch: 6| Step: 13
Training loss: 2.345853328704834
Validation loss: 2.021114150683085

Epoch: 98| Step: 0
Training loss: 1.7229368686676025
Validation loss: 2.02363113562266

Epoch: 6| Step: 1
Training loss: 3.1395211219787598
Validation loss: 2.0343225598335266

Epoch: 6| Step: 2
Training loss: 2.156651496887207
Validation loss: 2.0217430194218955

Epoch: 6| Step: 3
Training loss: 2.0985937118530273
Validation loss: 2.0277594526608786

Epoch: 6| Step: 4
Training loss: 2.125636577606201
Validation loss: 2.0264350175857544

Epoch: 6| Step: 5
Training loss: 2.1054697036743164
Validation loss: 2.023877441883087

Epoch: 6| Step: 6
Training loss: 1.733583688735962
Validation loss: 2.0250244537989297

Epoch: 6| Step: 7
Training loss: 1.8897817134857178
Validation loss: 2.022030552228292

Epoch: 6| Step: 8
Training loss: 2.099055051803589
Validation loss: 2.018393039703369

Epoch: 6| Step: 9
Training loss: 2.2055296897888184
Validation loss: 2.0183712244033813

Epoch: 6| Step: 10
Training loss: 2.1894466876983643
Validation loss: 2.0191571712493896

Epoch: 6| Step: 11
Training loss: 2.3098878860473633
Validation loss: 2.020491063594818

Epoch: 6| Step: 12
Training loss: 2.2475972175598145
Validation loss: 2.019745409488678

Epoch: 6| Step: 13
Training loss: 1.8727507591247559
Validation loss: 2.017861008644104

Epoch: 99| Step: 0
Training loss: 1.8109705448150635
Validation loss: 2.0217822392781577

Epoch: 6| Step: 1
Training loss: 2.5022120475769043
Validation loss: 2.0164761940638223

Epoch: 6| Step: 2
Training loss: 2.5180156230926514
Validation loss: 2.0238311290740967

Epoch: 6| Step: 3
Training loss: 2.5912766456604004
Validation loss: 2.019513646761576

Epoch: 6| Step: 4
Training loss: 1.9162077903747559
Validation loss: 2.0228139758110046

Epoch: 6| Step: 5
Training loss: 1.946669578552246
Validation loss: 2.0300906697909036

Epoch: 6| Step: 6
Training loss: 1.8511662483215332
Validation loss: 2.029268821080526

Epoch: 6| Step: 7
Training loss: 2.1847527027130127
Validation loss: 2.028394023577372

Epoch: 6| Step: 8
Training loss: 1.8731951713562012
Validation loss: 2.03129110733668

Epoch: 6| Step: 9
Training loss: 1.9146226644515991
Validation loss: 2.028465986251831

Epoch: 6| Step: 10
Training loss: 2.1743907928466797
Validation loss: 2.028196374575297

Epoch: 6| Step: 11
Training loss: 1.943608283996582
Validation loss: 2.0184929172197976

Epoch: 6| Step: 12
Training loss: 2.098630905151367
Validation loss: 2.014724095662435

Epoch: 6| Step: 13
Training loss: 2.2293519973754883
Validation loss: 2.015979846318563

Epoch: 100| Step: 0
Training loss: 2.380521774291992
Validation loss: 2.0163816610972085

Epoch: 6| Step: 1
Training loss: 2.2335872650146484
Validation loss: 2.0095881621042886

Epoch: 6| Step: 2
Training loss: 2.3133199214935303
Validation loss: 2.0102204084396362

Epoch: 6| Step: 3
Training loss: 2.0335822105407715
Validation loss: 2.0037949681282043

Epoch: 6| Step: 4
Training loss: 2.4667415618896484
Validation loss: 2.001954217751821

Epoch: 6| Step: 5
Training loss: 1.721600890159607
Validation loss: 1.9952304760615032

Epoch: 6| Step: 6
Training loss: 2.1869287490844727
Validation loss: 1.999213993549347

Epoch: 6| Step: 7
Training loss: 2.95723819732666
Validation loss: 2.0005953907966614

Epoch: 6| Step: 8
Training loss: 1.9742718935012817
Validation loss: 2.0005059838294983

Epoch: 6| Step: 9
Training loss: 1.4722952842712402
Validation loss: 2.0021852453549704

Epoch: 6| Step: 10
Training loss: 2.121809720993042
Validation loss: 2.001517415046692

Epoch: 6| Step: 11
Training loss: 2.050837516784668
Validation loss: 2.0007623632748923

Epoch: 6| Step: 12
Training loss: 2.2259907722473145
Validation loss: 2.005976696809133

Epoch: 6| Step: 13
Training loss: 1.5887458324432373
Validation loss: 2.0121869444847107

Epoch: 101| Step: 0
Training loss: 1.5641428232192993
Validation loss: 2.0160364508628845

Epoch: 6| Step: 1
Training loss: 2.1964681148529053
Validation loss: 2.0152631600697837

Epoch: 6| Step: 2
Training loss: 1.9722498655319214
Validation loss: 2.0187405943870544

Epoch: 6| Step: 3
Training loss: 1.818796157836914
Validation loss: 2.017325143019358

Epoch: 6| Step: 4
Training loss: 2.4202985763549805
Validation loss: 2.0171409249305725

Epoch: 6| Step: 5
Training loss: 2.245544672012329
Validation loss: 2.01166703303655

Epoch: 6| Step: 6
Training loss: 1.9321560859680176
Validation loss: 2.0086275339126587

Epoch: 6| Step: 7
Training loss: 1.9545105695724487
Validation loss: 2.0131271878878274

Epoch: 6| Step: 8
Training loss: 2.0601115226745605
Validation loss: 2.0152219335238137

Epoch: 6| Step: 9
Training loss: 2.3920631408691406
Validation loss: 2.014363408088684

Epoch: 6| Step: 10
Training loss: 2.6473636627197266
Validation loss: 2.010516405105591

Epoch: 6| Step: 11
Training loss: 2.629951000213623
Validation loss: 2.0119323333104453

Epoch: 6| Step: 12
Training loss: 2.152863025665283
Validation loss: 2.0160746574401855

Epoch: 6| Step: 13
Training loss: 1.4791748523712158
Validation loss: 2.0103717048962912

Epoch: 102| Step: 0
Training loss: 1.9592344760894775
Validation loss: 2.004812995592753

Epoch: 6| Step: 1
Training loss: 1.9126617908477783
Validation loss: 2.0114455223083496

Epoch: 6| Step: 2
Training loss: 1.668848991394043
Validation loss: 2.0179170966148376

Epoch: 6| Step: 3
Training loss: 1.8812943696975708
Validation loss: 2.012297213077545

Epoch: 6| Step: 4
Training loss: 1.9060415029525757
Validation loss: 2.011175831158956

Epoch: 6| Step: 5
Training loss: 2.1672892570495605
Validation loss: 2.0173011819521585

Epoch: 6| Step: 6
Training loss: 2.1264641284942627
Validation loss: 2.0169687072436013

Epoch: 6| Step: 7
Training loss: 2.4585936069488525
Validation loss: 2.021096646785736

Epoch: 6| Step: 8
Training loss: 2.6490378379821777
Validation loss: 2.0232724150021872

Epoch: 6| Step: 9
Training loss: 2.1915807723999023
Validation loss: 2.018945892651876

Epoch: 6| Step: 10
Training loss: 2.173349380493164
Validation loss: 2.026270945866903

Epoch: 6| Step: 11
Training loss: 2.1536388397216797
Validation loss: 2.021596372127533

Epoch: 6| Step: 12
Training loss: 2.2194154262542725
Validation loss: 2.0393528938293457

Epoch: 6| Step: 13
Training loss: 1.9939770698547363
Validation loss: 2.0219334761301675

Epoch: 103| Step: 0
Training loss: 1.9063199758529663
Validation loss: 2.0264671246210733

Epoch: 6| Step: 1
Training loss: 2.1607918739318848
Validation loss: 2.0251678029696145

Epoch: 6| Step: 2
Training loss: 2.441319227218628
Validation loss: 2.0315909186999

Epoch: 6| Step: 3
Training loss: 2.059844970703125
Validation loss: 2.032001713911692

Epoch: 6| Step: 4
Training loss: 2.12082576751709
Validation loss: 2.0279175639152527

Epoch: 6| Step: 5
Training loss: 1.462711215019226
Validation loss: 2.021550496419271

Epoch: 6| Step: 6
Training loss: 2.5825061798095703
Validation loss: 2.0135260820388794

Epoch: 6| Step: 7
Training loss: 2.011230230331421
Validation loss: 2.012735287348429

Epoch: 6| Step: 8
Training loss: 2.228074550628662
Validation loss: 2.0108609000841775

Epoch: 6| Step: 9
Training loss: 2.216277837753296
Validation loss: 2.003606379032135

Epoch: 6| Step: 10
Training loss: 2.0766355991363525
Validation loss: 2.005410393079122

Epoch: 6| Step: 11
Training loss: 2.0170578956604004
Validation loss: 2.012653191884359

Epoch: 6| Step: 12
Training loss: 2.04887318611145
Validation loss: 2.008466978867849

Epoch: 6| Step: 13
Training loss: 2.2543325424194336
Validation loss: 2.0082701444625854

Epoch: 104| Step: 0
Training loss: 2.3328099250793457
Validation loss: 2.011175751686096

Epoch: 6| Step: 1
Training loss: 2.4161431789398193
Validation loss: 2.013308525085449

Epoch: 6| Step: 2
Training loss: 1.5312535762786865
Validation loss: 2.0202003717422485

Epoch: 6| Step: 3
Training loss: 1.9242727756500244
Validation loss: 2.0210561752319336

Epoch: 6| Step: 4
Training loss: 2.085604190826416
Validation loss: 2.0201366543769836

Epoch: 6| Step: 5
Training loss: 2.25862979888916
Validation loss: 2.020075718561808

Epoch: 6| Step: 6
Training loss: 1.9773178100585938
Validation loss: 2.015693426132202

Epoch: 6| Step: 7
Training loss: 2.1556148529052734
Validation loss: 2.017098128795624

Epoch: 6| Step: 8
Training loss: 2.277061939239502
Validation loss: 2.0259003043174744

Epoch: 6| Step: 9
Training loss: 2.073082208633423
Validation loss: 2.032225708166758

Epoch: 6| Step: 10
Training loss: 1.9590044021606445
Validation loss: 2.0295092264811196

Epoch: 6| Step: 11
Training loss: 2.2431392669677734
Validation loss: 2.0248947540918985

Epoch: 6| Step: 12
Training loss: 2.285792827606201
Validation loss: 2.021979888280233

Epoch: 6| Step: 13
Training loss: 1.8373526334762573
Validation loss: 2.0163127183914185

Epoch: 105| Step: 0
Training loss: 2.084596633911133
Validation loss: 2.0207161704699197

Epoch: 6| Step: 1
Training loss: 1.1783561706542969
Validation loss: 2.0179132421811423

Epoch: 6| Step: 2
Training loss: 2.4860963821411133
Validation loss: 2.02204300959905

Epoch: 6| Step: 3
Training loss: 2.4357199668884277
Validation loss: 2.0187161763509116

Epoch: 6| Step: 4
Training loss: 2.2883734703063965
Validation loss: 2.0187387665112815

Epoch: 6| Step: 5
Training loss: 2.483761787414551
Validation loss: 2.02107306321462

Epoch: 6| Step: 6
Training loss: 1.8634531497955322
Validation loss: 2.0191224018732705

Epoch: 6| Step: 7
Training loss: 1.7588249444961548
Validation loss: 2.013740678628286

Epoch: 6| Step: 8
Training loss: 1.8899630308151245
Validation loss: 2.015909473101298

Epoch: 6| Step: 9
Training loss: 1.9881384372711182
Validation loss: 2.015102962652842

Epoch: 6| Step: 10
Training loss: 2.5843498706817627
Validation loss: 2.0114768147468567

Epoch: 6| Step: 11
Training loss: 1.727417230606079
Validation loss: 2.0182955662409463

Epoch: 6| Step: 12
Training loss: 1.9218310117721558
Validation loss: 2.0157255132993064

Epoch: 6| Step: 13
Training loss: 2.542891502380371
Validation loss: 2.02112478017807

Epoch: 106| Step: 0
Training loss: 1.993204951286316
Validation loss: 2.021019379297892

Epoch: 6| Step: 1
Training loss: 1.7415544986724854
Validation loss: 2.022776484489441

Epoch: 6| Step: 2
Training loss: 2.231747627258301
Validation loss: 2.032711466153463

Epoch: 6| Step: 3
Training loss: 1.7556732892990112
Validation loss: 2.013932387034098

Epoch: 6| Step: 4
Training loss: 1.690595269203186
Validation loss: 2.0273278951644897

Epoch: 6| Step: 5
Training loss: 2.0534920692443848
Validation loss: 2.018455704053243

Epoch: 6| Step: 6
Training loss: 2.513066291809082
Validation loss: 2.017182946205139

Epoch: 6| Step: 7
Training loss: 1.9018397331237793
Validation loss: 2.0144460995992026

Epoch: 6| Step: 8
Training loss: 1.9002254009246826
Validation loss: 2.0133888920148215

Epoch: 6| Step: 9
Training loss: 2.5898571014404297
Validation loss: 2.023093819618225

Epoch: 6| Step: 10
Training loss: 1.7958179712295532
Validation loss: 2.0271859566370645

Epoch: 6| Step: 11
Training loss: 2.161001682281494
Validation loss: 2.016881783803304

Epoch: 6| Step: 12
Training loss: 2.617847442626953
Validation loss: 2.023039003213247

Epoch: 6| Step: 13
Training loss: 2.281329393386841
Validation loss: 2.0165041089057922

Epoch: 107| Step: 0
Training loss: 1.8993523120880127
Validation loss: 2.015475789705912

Epoch: 6| Step: 1
Training loss: 2.588949203491211
Validation loss: 2.0182706713676453

Epoch: 6| Step: 2
Training loss: 2.270359516143799
Validation loss: 2.013292749722799

Epoch: 6| Step: 3
Training loss: 1.9724847078323364
Validation loss: 2.0111924012502036

Epoch: 6| Step: 4
Training loss: 2.845005512237549
Validation loss: 2.0239094297091165

Epoch: 6| Step: 5
Training loss: 2.010791540145874
Validation loss: 2.0274352431297302

Epoch: 6| Step: 6
Training loss: 1.7427595853805542
Validation loss: 2.024186829725901

Epoch: 6| Step: 7
Training loss: 1.945876121520996
Validation loss: 2.0158162315686545

Epoch: 6| Step: 8
Training loss: 2.1062700748443604
Validation loss: 2.0245495239893594

Epoch: 6| Step: 9
Training loss: 2.1627140045166016
Validation loss: 2.0312206546465554

Epoch: 6| Step: 10
Training loss: 2.144697666168213
Validation loss: 2.018207609653473

Epoch: 6| Step: 11
Training loss: 2.073185920715332
Validation loss: 2.0164860089619956

Epoch: 6| Step: 12
Training loss: 1.8679490089416504
Validation loss: 2.0190975268681846

Epoch: 6| Step: 13
Training loss: 1.6418864727020264
Validation loss: 2.018515189488729

Epoch: 108| Step: 0
Training loss: 1.771028995513916
Validation loss: 2.020778934160868

Epoch: 6| Step: 1
Training loss: 2.1983699798583984
Validation loss: 2.018780291080475

Epoch: 6| Step: 2
Training loss: 2.202624797821045
Validation loss: 2.0251139402389526

Epoch: 6| Step: 3
Training loss: 2.6288602352142334
Validation loss: 2.0277780095736184

Epoch: 6| Step: 4
Training loss: 2.307100296020508
Validation loss: 2.0260302821795144

Epoch: 6| Step: 5
Training loss: 2.249054431915283
Validation loss: 2.0301451881726584

Epoch: 6| Step: 6
Training loss: 1.8484351634979248
Validation loss: 2.023120403289795

Epoch: 6| Step: 7
Training loss: 1.7899682521820068
Validation loss: 2.0268352230389914

Epoch: 6| Step: 8
Training loss: 2.2791972160339355
Validation loss: 2.020506282647451

Epoch: 6| Step: 9
Training loss: 1.730804443359375
Validation loss: 2.029993752638499

Epoch: 6| Step: 10
Training loss: 2.8420350551605225
Validation loss: 2.0227468411127725

Epoch: 6| Step: 11
Training loss: 1.466559648513794
Validation loss: 2.0246031880378723

Epoch: 6| Step: 12
Training loss: 1.6104538440704346
Validation loss: 2.0287848313649497

Epoch: 6| Step: 13
Training loss: 2.260211229324341
Validation loss: 2.027531107266744

Epoch: 109| Step: 0
Training loss: 1.919754147529602
Validation loss: 2.030620058377584

Epoch: 6| Step: 1
Training loss: 1.7444989681243896
Validation loss: 2.0265214840571084

Epoch: 6| Step: 2
Training loss: 2.1772847175598145
Validation loss: 2.023169000943502

Epoch: 6| Step: 3
Training loss: 2.542009115219116
Validation loss: 2.030890623728434

Epoch: 6| Step: 4
Training loss: 1.74837327003479
Validation loss: 2.03605184952418

Epoch: 6| Step: 5
Training loss: 1.7285914421081543
Validation loss: 2.0378341476122537

Epoch: 6| Step: 6
Training loss: 1.8327701091766357
Validation loss: 2.0324147740999856

Epoch: 6| Step: 7
Training loss: 2.4802937507629395
Validation loss: 2.0263462464014688

Epoch: 6| Step: 8
Training loss: 2.1663670539855957
Validation loss: 2.0255125761032104

Epoch: 6| Step: 9
Training loss: 2.3974714279174805
Validation loss: 2.0269323587417603

Epoch: 6| Step: 10
Training loss: 2.185720682144165
Validation loss: 2.028752783934275

Epoch: 6| Step: 11
Training loss: 2.735187530517578
Validation loss: 2.030066510041555

Epoch: 6| Step: 12
Training loss: 1.7815994024276733
Validation loss: 2.0325242082277932

Epoch: 6| Step: 13
Training loss: 1.6206705570220947
Validation loss: 2.028098225593567

Epoch: 110| Step: 0
Training loss: 2.335756301879883
Validation loss: 2.03197834889094

Epoch: 6| Step: 1
Training loss: 2.681669235229492
Validation loss: 2.0267540216445923

Epoch: 6| Step: 2
Training loss: 1.8916269540786743
Validation loss: 2.0220290621121726

Epoch: 6| Step: 3
Training loss: 1.9418386220932007
Validation loss: 2.0263267755508423

Epoch: 6| Step: 4
Training loss: 1.8768874406814575
Validation loss: 2.021966258684794

Epoch: 6| Step: 5
Training loss: 2.4849634170532227
Validation loss: 2.020882507165273

Epoch: 6| Step: 6
Training loss: 1.931557059288025
Validation loss: 2.019212563832601

Epoch: 6| Step: 7
Training loss: 2.0980186462402344
Validation loss: 2.02373472849528

Epoch: 6| Step: 8
Training loss: 2.1645946502685547
Validation loss: 2.019595662752787

Epoch: 6| Step: 9
Training loss: 1.5528814792633057
Validation loss: 2.0216835141181946

Epoch: 6| Step: 10
Training loss: 1.9546338319778442
Validation loss: 2.0366870959599814

Epoch: 6| Step: 11
Training loss: 1.930466651916504
Validation loss: 2.039492984612783

Epoch: 6| Step: 12
Training loss: 2.535356044769287
Validation loss: 2.0391389528910318

Epoch: 6| Step: 13
Training loss: 1.803532361984253
Validation loss: 2.044996420542399

Epoch: 111| Step: 0
Training loss: 1.9653782844543457
Validation loss: 2.0512625177701316

Epoch: 6| Step: 1
Training loss: 2.41540265083313
Validation loss: 2.0684342781702676

Epoch: 6| Step: 2
Training loss: 2.835280418395996
Validation loss: 2.070624748865763

Epoch: 6| Step: 3
Training loss: 2.23875093460083
Validation loss: 2.053051749865214

Epoch: 6| Step: 4
Training loss: 2.219712734222412
Validation loss: 2.0469974279403687

Epoch: 6| Step: 5
Training loss: 2.43371844291687
Validation loss: 2.0424445271492004

Epoch: 6| Step: 6
Training loss: 2.0363571643829346
Validation loss: 2.030571619669596

Epoch: 6| Step: 7
Training loss: 1.746412754058838
Validation loss: 2.022561232248942

Epoch: 6| Step: 8
Training loss: 2.3258724212646484
Validation loss: 2.0217911998430886

Epoch: 6| Step: 9
Training loss: 2.117753028869629
Validation loss: 2.0181299249331155

Epoch: 6| Step: 10
Training loss: 1.4212931394577026
Validation loss: 2.022369166215261

Epoch: 6| Step: 11
Training loss: 2.318631410598755
Validation loss: 2.0204613407452903

Epoch: 6| Step: 12
Training loss: 1.5219975709915161
Validation loss: 2.006299157937368

Epoch: 6| Step: 13
Training loss: 2.107236385345459
Validation loss: 2.0157869259516397

Epoch: 112| Step: 0
Training loss: 1.6910488605499268
Validation loss: 2.00933571656545

Epoch: 6| Step: 1
Training loss: 1.856898307800293
Validation loss: 2.009134272734324

Epoch: 6| Step: 2
Training loss: 2.273076057434082
Validation loss: 2.0077266693115234

Epoch: 6| Step: 3
Training loss: 2.7648608684539795
Validation loss: 2.001528243223826

Epoch: 6| Step: 4
Training loss: 1.8210692405700684
Validation loss: 2.003697911898295

Epoch: 6| Step: 5
Training loss: 1.7247620820999146
Validation loss: 2.0057665506998696

Epoch: 6| Step: 6
Training loss: 2.419783592224121
Validation loss: 2.0021493236223855

Epoch: 6| Step: 7
Training loss: 1.7086188793182373
Validation loss: 1.999043603738149

Epoch: 6| Step: 8
Training loss: 2.661710023880005
Validation loss: 2.001783231894175

Epoch: 6| Step: 9
Training loss: 2.2884409427642822
Validation loss: 2.007381578286489

Epoch: 6| Step: 10
Training loss: 2.667832374572754
Validation loss: 2.0081523656845093

Epoch: 6| Step: 11
Training loss: 1.9777147769927979
Validation loss: 2.0161176919937134

Epoch: 6| Step: 12
Training loss: 2.1158642768859863
Validation loss: 2.016713639100393

Epoch: 6| Step: 13
Training loss: 1.8635293245315552
Validation loss: 2.026899596055349

Epoch: 113| Step: 0
Training loss: 2.0179355144500732
Validation loss: 2.0156152844429016

Epoch: 6| Step: 1
Training loss: 1.7391507625579834
Validation loss: 2.0233848293622336

Epoch: 6| Step: 2
Training loss: 2.3267436027526855
Validation loss: 2.0142292579015098

Epoch: 6| Step: 3
Training loss: 1.7696818113327026
Validation loss: 2.016542673110962

Epoch: 6| Step: 4
Training loss: 2.101024627685547
Validation loss: 2.0243188937505088

Epoch: 6| Step: 5
Training loss: 2.1902711391448975
Validation loss: 2.021895150343577

Epoch: 6| Step: 6
Training loss: 2.100337028503418
Validation loss: 2.0177464485168457

Epoch: 6| Step: 7
Training loss: 2.131943702697754
Validation loss: 2.017721652984619

Epoch: 6| Step: 8
Training loss: 1.3953156471252441
Validation loss: 2.0332907835642495

Epoch: 6| Step: 9
Training loss: 1.9661343097686768
Validation loss: 2.017519553502401

Epoch: 6| Step: 10
Training loss: 2.1979689598083496
Validation loss: 2.0247644583384194

Epoch: 6| Step: 11
Training loss: 3.047198534011841
Validation loss: 2.022381623586019

Epoch: 6| Step: 12
Training loss: 2.6386446952819824
Validation loss: 2.028827965259552

Epoch: 6| Step: 13
Training loss: 1.5745251178741455
Validation loss: 2.0208433469136557

Epoch: 114| Step: 0
Training loss: 1.9472326040267944
Validation loss: 2.0201106468836465

Epoch: 6| Step: 1
Training loss: 2.2430930137634277
Validation loss: 2.020659546057383

Epoch: 6| Step: 2
Training loss: 1.9335075616836548
Validation loss: 2.0200207034746804

Epoch: 6| Step: 3
Training loss: 2.1795578002929688
Validation loss: 2.01924204826355

Epoch: 6| Step: 4
Training loss: 2.7056870460510254
Validation loss: 2.0237091382344565

Epoch: 6| Step: 5
Training loss: 1.8544678688049316
Validation loss: 2.0211341977119446

Epoch: 6| Step: 6
Training loss: 2.832862615585327
Validation loss: 2.0151626070340476

Epoch: 6| Step: 7
Training loss: 2.374335527420044
Validation loss: 2.0267103711764016

Epoch: 6| Step: 8
Training loss: 1.649909496307373
Validation loss: 2.0228756268819175

Epoch: 6| Step: 9
Training loss: 1.394381046295166
Validation loss: 2.026177148024241

Epoch: 6| Step: 10
Training loss: 2.4663772583007812
Validation loss: 2.0226102073987327

Epoch: 6| Step: 11
Training loss: 1.385909914970398
Validation loss: 2.0183515548706055

Epoch: 6| Step: 12
Training loss: 2.5367374420166016
Validation loss: 2.015235960483551

Epoch: 6| Step: 13
Training loss: 1.6427297592163086
Validation loss: 2.0193783044815063

Epoch: 115| Step: 0
Training loss: 1.8969165086746216
Validation loss: 2.016930401325226

Epoch: 6| Step: 1
Training loss: 1.9749996662139893
Validation loss: 2.017639676729838

Epoch: 6| Step: 2
Training loss: 2.2705161571502686
Validation loss: 2.0191623767217

Epoch: 6| Step: 3
Training loss: 1.6130623817443848
Validation loss: 2.0206103722254434

Epoch: 6| Step: 4
Training loss: 2.3875818252563477
Validation loss: 2.017903725306193

Epoch: 6| Step: 5
Training loss: 1.7292001247406006
Validation loss: 2.0118648608525596

Epoch: 6| Step: 6
Training loss: 2.082693099975586
Validation loss: 2.017043391863505

Epoch: 6| Step: 7
Training loss: 1.7083549499511719
Validation loss: 2.015942851702372

Epoch: 6| Step: 8
Training loss: 1.846882939338684
Validation loss: 2.022428830464681

Epoch: 6| Step: 9
Training loss: 2.2936105728149414
Validation loss: 2.027359445889791

Epoch: 6| Step: 10
Training loss: 1.9981919527053833
Validation loss: 2.0292627612749734

Epoch: 6| Step: 11
Training loss: 1.986060619354248
Validation loss: 2.035360892613729

Epoch: 6| Step: 12
Training loss: 2.5799503326416016
Validation loss: 2.0402607123057046

Epoch: 6| Step: 13
Training loss: 2.5817906856536865
Validation loss: 2.0279293855031333

Epoch: 116| Step: 0
Training loss: 2.002331495285034
Validation loss: 2.032929460207621

Epoch: 6| Step: 1
Training loss: 2.0536882877349854
Validation loss: 2.0298431118329368

Epoch: 6| Step: 2
Training loss: 1.731123685836792
Validation loss: 2.0383267402648926

Epoch: 6| Step: 3
Training loss: 2.0188958644866943
Validation loss: 2.0328910748163858

Epoch: 6| Step: 4
Training loss: 1.8887465000152588
Validation loss: 2.0324536164601645

Epoch: 6| Step: 5
Training loss: 1.617233157157898
Validation loss: 2.0302958687146506

Epoch: 6| Step: 6
Training loss: 1.941863775253296
Validation loss: 2.029328385988871

Epoch: 6| Step: 7
Training loss: 1.7488902807235718
Validation loss: 2.020759562651316

Epoch: 6| Step: 8
Training loss: 2.057284355163574
Validation loss: 2.0125731229782104

Epoch: 6| Step: 9
Training loss: 2.119669198989868
Validation loss: 2.018193165461222

Epoch: 6| Step: 10
Training loss: 2.209618330001831
Validation loss: 2.013784646987915

Epoch: 6| Step: 11
Training loss: 2.379065752029419
Validation loss: 2.023985803127289

Epoch: 6| Step: 12
Training loss: 2.860304355621338
Validation loss: 2.0153005123138428

Epoch: 6| Step: 13
Training loss: 2.364128828048706
Validation loss: 2.022867222627004

Epoch: 117| Step: 0
Training loss: 1.8653967380523682
Validation loss: 2.0289143522580466

Epoch: 6| Step: 1
Training loss: 1.945845127105713
Validation loss: 2.0290748675664267

Epoch: 6| Step: 2
Training loss: 1.7756245136260986
Validation loss: 2.035587191581726

Epoch: 6| Step: 3
Training loss: 1.4693185091018677
Validation loss: 2.0338964660962424

Epoch: 6| Step: 4
Training loss: 2.0642495155334473
Validation loss: 2.0320149262746177

Epoch: 6| Step: 5
Training loss: 2.4723520278930664
Validation loss: 2.0312876105308533

Epoch: 6| Step: 6
Training loss: 2.029667854309082
Validation loss: 2.0344135761260986

Epoch: 6| Step: 7
Training loss: 2.829183578491211
Validation loss: 2.0359641512235007

Epoch: 6| Step: 8
Training loss: 2.191709041595459
Validation loss: 2.035456975301107

Epoch: 6| Step: 9
Training loss: 2.35080623626709
Validation loss: 2.0368661880493164

Epoch: 6| Step: 10
Training loss: 2.012991428375244
Validation loss: 2.040235459804535

Epoch: 6| Step: 11
Training loss: 1.7975385189056396
Validation loss: 2.0397383769353232

Epoch: 6| Step: 12
Training loss: 2.121480941772461
Validation loss: 2.041599671045939

Epoch: 6| Step: 13
Training loss: 2.213301658630371
Validation loss: 2.0463368693987527

Epoch: 118| Step: 0
Training loss: 2.83941650390625
Validation loss: 2.0335209170977273

Epoch: 6| Step: 1
Training loss: 2.7751970291137695
Validation loss: 2.0443409283955893

Epoch: 6| Step: 2
Training loss: 1.6181113719940186
Validation loss: 2.0302093625068665

Epoch: 6| Step: 3
Training loss: 2.0486037731170654
Validation loss: 2.0267643531163535

Epoch: 6| Step: 4
Training loss: 1.776997685432434
Validation loss: 2.03081621726354

Epoch: 6| Step: 5
Training loss: 2.2366998195648193
Validation loss: 2.0236117442448935

Epoch: 6| Step: 6
Training loss: 1.6057347059249878
Validation loss: 2.0248496731122336

Epoch: 6| Step: 7
Training loss: 1.5674285888671875
Validation loss: 2.0351478656133017

Epoch: 6| Step: 8
Training loss: 1.8256382942199707
Validation loss: 2.0277747313181558

Epoch: 6| Step: 9
Training loss: 2.3032124042510986
Validation loss: 2.0358198086420694

Epoch: 6| Step: 10
Training loss: 2.2445614337921143
Validation loss: 2.028648098309835

Epoch: 6| Step: 11
Training loss: 1.706176996231079
Validation loss: 2.0350990494092307

Epoch: 6| Step: 12
Training loss: 1.598038911819458
Validation loss: 2.0250742038091025

Epoch: 6| Step: 13
Training loss: 2.6500966548919678
Validation loss: 2.0237549940745034

Epoch: 119| Step: 0
Training loss: 1.9617046117782593
Validation loss: 2.0249125957489014

Epoch: 6| Step: 1
Training loss: 2.055237293243408
Validation loss: 2.034154196580251

Epoch: 6| Step: 2
Training loss: 2.248584747314453
Validation loss: 2.0335270961125693

Epoch: 6| Step: 3
Training loss: 1.7335782051086426
Validation loss: 2.0350898106892905

Epoch: 6| Step: 4
Training loss: 2.549990177154541
Validation loss: 2.0344433387120566

Epoch: 6| Step: 5
Training loss: 2.7284154891967773
Validation loss: 2.0395626227060952

Epoch: 6| Step: 6
Training loss: 1.4235565662384033
Validation loss: 2.036114195982615

Epoch: 6| Step: 7
Training loss: 1.922258734703064
Validation loss: 2.0421626766522727

Epoch: 6| Step: 8
Training loss: 2.2968952655792236
Validation loss: 2.037266035874685

Epoch: 6| Step: 9
Training loss: 2.121616840362549
Validation loss: 2.0342493454615274

Epoch: 6| Step: 10
Training loss: 2.8821096420288086
Validation loss: 2.03814697265625

Epoch: 6| Step: 11
Training loss: 1.756878137588501
Validation loss: 2.0438517133394876

Epoch: 6| Step: 12
Training loss: 1.6219985485076904
Validation loss: 2.035017251968384

Epoch: 6| Step: 13
Training loss: 1.5787867307662964
Validation loss: 2.0366176764170327

Epoch: 120| Step: 0
Training loss: 2.8280506134033203
Validation loss: 2.032429317633311

Epoch: 6| Step: 1
Training loss: 1.8735276460647583
Validation loss: 2.0269448161125183

Epoch: 6| Step: 2
Training loss: 2.6224327087402344
Validation loss: 2.0260847012201944

Epoch: 6| Step: 3
Training loss: 1.8290047645568848
Validation loss: 2.0271295507748923

Epoch: 6| Step: 4
Training loss: 1.5965560674667358
Validation loss: 2.031664172808329

Epoch: 6| Step: 5
Training loss: 2.566502809524536
Validation loss: 2.0293860038121543

Epoch: 6| Step: 6
Training loss: 2.396308183670044
Validation loss: 2.0331344405810037

Epoch: 6| Step: 7
Training loss: 2.346737861633301
Validation loss: 2.040058414141337

Epoch: 6| Step: 8
Training loss: 2.3478493690490723
Validation loss: 2.0388797521591187

Epoch: 6| Step: 9
Training loss: 1.967502236366272
Validation loss: 2.041150530179342

Epoch: 6| Step: 10
Training loss: 1.7619765996932983
Validation loss: 2.0291955272356668

Epoch: 6| Step: 11
Training loss: 1.749419927597046
Validation loss: 2.027886768182119

Epoch: 6| Step: 12
Training loss: 1.349254846572876
Validation loss: 2.0319868127504983

Epoch: 6| Step: 13
Training loss: 1.5846891403198242
Validation loss: 2.022532820701599

Epoch: 121| Step: 0
Training loss: 2.0133025646209717
Validation loss: 2.028850018978119

Epoch: 6| Step: 1
Training loss: 2.165177345275879
Validation loss: 2.0266617139180503

Epoch: 6| Step: 2
Training loss: 1.3000023365020752
Validation loss: 2.031358818213145

Epoch: 6| Step: 3
Training loss: 1.9058165550231934
Validation loss: 2.029959281285604

Epoch: 6| Step: 4
Training loss: 1.965083360671997
Validation loss: 2.033586084842682

Epoch: 6| Step: 5
Training loss: 2.5520191192626953
Validation loss: 2.0359164277712503

Epoch: 6| Step: 6
Training loss: 1.5610986948013306
Validation loss: 2.0389813979466758

Epoch: 6| Step: 7
Training loss: 2.6555466651916504
Validation loss: 2.0482152303059897

Epoch: 6| Step: 8
Training loss: 1.990418791770935
Validation loss: 2.0352958838144937

Epoch: 6| Step: 9
Training loss: 2.6748344898223877
Validation loss: 2.0427338679631553

Epoch: 6| Step: 10
Training loss: 1.627097487449646
Validation loss: 2.043544073899587

Epoch: 6| Step: 11
Training loss: 1.9268271923065186
Validation loss: 2.045129736264547

Epoch: 6| Step: 12
Training loss: 2.05972957611084
Validation loss: 2.0371257066726685

Epoch: 6| Step: 13
Training loss: 2.4615883827209473
Validation loss: 2.047081788380941

Epoch: 122| Step: 0
Training loss: 2.356309652328491
Validation loss: 2.035242795944214

Epoch: 6| Step: 1
Training loss: 1.3421285152435303
Validation loss: 2.02768075466156

Epoch: 6| Step: 2
Training loss: 2.319819450378418
Validation loss: 2.0290756225585938

Epoch: 6| Step: 3
Training loss: 2.2506113052368164
Validation loss: 2.0263882875442505

Epoch: 6| Step: 4
Training loss: 2.0143885612487793
Validation loss: 2.035570820172628

Epoch: 6| Step: 5
Training loss: 2.236743211746216
Validation loss: 2.034000337123871

Epoch: 6| Step: 6
Training loss: 1.8966045379638672
Validation loss: 2.033083895842234

Epoch: 6| Step: 7
Training loss: 2.1602766513824463
Validation loss: 2.0421226024627686

Epoch: 6| Step: 8
Training loss: 2.577387809753418
Validation loss: 2.0372474789619446

Epoch: 6| Step: 9
Training loss: 1.5340150594711304
Validation loss: 2.04252423842748

Epoch: 6| Step: 10
Training loss: 1.8574073314666748
Validation loss: 2.048517088095347

Epoch: 6| Step: 11
Training loss: 1.4025793075561523
Validation loss: 2.0569819808006287

Epoch: 6| Step: 12
Training loss: 2.183213233947754
Validation loss: 2.0546087622642517

Epoch: 6| Step: 13
Training loss: 2.5010628700256348
Validation loss: 2.0516859690348306

Epoch: 123| Step: 0
Training loss: 1.9231982231140137
Validation loss: 2.0651147961616516

Epoch: 6| Step: 1
Training loss: 2.564225196838379
Validation loss: 2.069183886051178

Epoch: 6| Step: 2
Training loss: 1.9238438606262207
Validation loss: 2.088676393032074

Epoch: 6| Step: 3
Training loss: 2.102843999862671
Validation loss: 2.067187329133352

Epoch: 6| Step: 4
Training loss: 1.943098783493042
Validation loss: 2.0607541600863137

Epoch: 6| Step: 5
Training loss: 2.102956771850586
Validation loss: 2.052667478720347

Epoch: 6| Step: 6
Training loss: 1.9940515756607056
Validation loss: 2.051931699117025

Epoch: 6| Step: 7
Training loss: 2.374876022338867
Validation loss: 2.0372593998908997

Epoch: 6| Step: 8
Training loss: 2.0468015670776367
Validation loss: 2.0293243130048118

Epoch: 6| Step: 9
Training loss: 2.66483736038208
Validation loss: 2.0296674370765686

Epoch: 6| Step: 10
Training loss: 1.762932300567627
Validation loss: 2.027234931786855

Epoch: 6| Step: 11
Training loss: 2.111280918121338
Validation loss: 2.03425923983256

Epoch: 6| Step: 12
Training loss: 1.7505241632461548
Validation loss: 2.033238689104716

Epoch: 6| Step: 13
Training loss: 2.0950756072998047
Validation loss: 2.0368568698565164

Epoch: 124| Step: 0
Training loss: 2.064084053039551
Validation loss: 2.040680766105652

Epoch: 6| Step: 1
Training loss: 1.3594512939453125
Validation loss: 2.0446155865987143

Epoch: 6| Step: 2
Training loss: 1.9464833736419678
Validation loss: 2.04168039560318

Epoch: 6| Step: 3
Training loss: 1.6349395513534546
Validation loss: 2.0589280923207602

Epoch: 6| Step: 4
Training loss: 1.9247496128082275
Validation loss: 2.0554235577583313

Epoch: 6| Step: 5
Training loss: 2.079636812210083
Validation loss: 2.05852073431015

Epoch: 6| Step: 6
Training loss: 1.4719200134277344
Validation loss: 2.061672786871592

Epoch: 6| Step: 7
Training loss: 2.551361083984375
Validation loss: 2.0639007290204368

Epoch: 6| Step: 8
Training loss: 1.9828715324401855
Validation loss: 2.0768683751424155

Epoch: 6| Step: 9
Training loss: 2.141164779663086
Validation loss: 2.064409295717875

Epoch: 6| Step: 10
Training loss: 2.227708578109741
Validation loss: 2.0621806383132935

Epoch: 6| Step: 11
Training loss: 2.6114163398742676
Validation loss: 2.046419342358907

Epoch: 6| Step: 12
Training loss: 2.4348249435424805
Validation loss: 2.0434606671333313

Epoch: 6| Step: 13
Training loss: 2.202773094177246
Validation loss: 2.0506482124328613

Epoch: 125| Step: 0
Training loss: 2.631598949432373
Validation loss: 2.0440171360969543

Epoch: 6| Step: 1
Training loss: 2.1748576164245605
Validation loss: 2.0480109453201294

Epoch: 6| Step: 2
Training loss: 2.2416226863861084
Validation loss: 2.0454580783843994

Epoch: 6| Step: 3
Training loss: 1.4265782833099365
Validation loss: 2.0428591767946878

Epoch: 6| Step: 4
Training loss: 1.9797413349151611
Validation loss: 2.048092325528463

Epoch: 6| Step: 5
Training loss: 2.180025577545166
Validation loss: 2.051770865917206

Epoch: 6| Step: 6
Training loss: 2.6440229415893555
Validation loss: 2.041157086690267

Epoch: 6| Step: 7
Training loss: 1.8662501573562622
Validation loss: 2.0514434576034546

Epoch: 6| Step: 8
Training loss: 1.7219743728637695
Validation loss: 2.054718236128489

Epoch: 6| Step: 9
Training loss: 2.2652065753936768
Validation loss: 2.052815794944763

Epoch: 6| Step: 10
Training loss: 1.647232174873352
Validation loss: 2.0480087995529175

Epoch: 6| Step: 11
Training loss: 1.9523502588272095
Validation loss: 2.0486729741096497

Epoch: 6| Step: 12
Training loss: 1.818993091583252
Validation loss: 2.0468069911003113

Epoch: 6| Step: 13
Training loss: 2.225799798965454
Validation loss: 2.059740364551544

Epoch: 126| Step: 0
Training loss: 1.8896431922912598
Validation loss: 2.058957596619924

Epoch: 6| Step: 1
Training loss: 1.543479323387146
Validation loss: 2.061764140923818

Epoch: 6| Step: 2
Training loss: 2.4961318969726562
Validation loss: 2.0584068298339844

Epoch: 6| Step: 3
Training loss: 1.4097778797149658
Validation loss: 2.0642709732055664

Epoch: 6| Step: 4
Training loss: 1.5341089963912964
Validation loss: 2.0651848117510476

Epoch: 6| Step: 5
Training loss: 2.488894462585449
Validation loss: 2.070582648118337

Epoch: 6| Step: 6
Training loss: 1.685088872909546
Validation loss: 2.063226024309794

Epoch: 6| Step: 7
Training loss: 2.1679134368896484
Validation loss: 2.0569581190745034

Epoch: 6| Step: 8
Training loss: 2.22155499458313
Validation loss: 2.0533912777900696

Epoch: 6| Step: 9
Training loss: 2.027757167816162
Validation loss: 2.051184137662252

Epoch: 6| Step: 10
Training loss: 2.6118037700653076
Validation loss: 2.0564733147621155

Epoch: 6| Step: 11
Training loss: 1.7750909328460693
Validation loss: 2.052476187547048

Epoch: 6| Step: 12
Training loss: 2.5842015743255615
Validation loss: 2.0522114038467407

Epoch: 6| Step: 13
Training loss: 2.3072128295898438
Validation loss: 2.0470745166142783

Epoch: 127| Step: 0
Training loss: 2.0944533348083496
Validation loss: 2.0536149938901267

Epoch: 6| Step: 1
Training loss: 1.66531503200531
Validation loss: 2.0447089076042175

Epoch: 6| Step: 2
Training loss: 1.8286833763122559
Validation loss: 2.048203786214193

Epoch: 6| Step: 3
Training loss: 1.3436410427093506
Validation loss: 2.047774056593577

Epoch: 6| Step: 4
Training loss: 3.033308267593384
Validation loss: 2.044602076212565

Epoch: 6| Step: 5
Training loss: 1.7965264320373535
Validation loss: 2.0467376907666526

Epoch: 6| Step: 6
Training loss: 1.9281920194625854
Validation loss: 2.0515448252360025

Epoch: 6| Step: 7
Training loss: 2.0097036361694336
Validation loss: 2.04686309893926

Epoch: 6| Step: 8
Training loss: 1.5641677379608154
Validation loss: 2.043356160322825

Epoch: 6| Step: 9
Training loss: 1.8983933925628662
Validation loss: 2.057879070440928

Epoch: 6| Step: 10
Training loss: 2.4078664779663086
Validation loss: 2.056346575419108

Epoch: 6| Step: 11
Training loss: 2.4101176261901855
Validation loss: 2.0570742090543113

Epoch: 6| Step: 12
Training loss: 1.997596025466919
Validation loss: 2.050515373547872

Epoch: 6| Step: 13
Training loss: 2.402843475341797
Validation loss: 2.0599367022514343

Epoch: 128| Step: 0
Training loss: 2.2014734745025635
Validation loss: 2.0605266094207764

Epoch: 6| Step: 1
Training loss: 1.5228691101074219
Validation loss: 2.0579450130462646

Epoch: 6| Step: 2
Training loss: 2.362619400024414
Validation loss: 2.0560355981191

Epoch: 6| Step: 3
Training loss: 1.7249464988708496
Validation loss: 2.052654425303141

Epoch: 6| Step: 4
Training loss: 1.529547929763794
Validation loss: 2.056638161341349

Epoch: 6| Step: 5
Training loss: 2.650094985961914
Validation loss: 2.046953578790029

Epoch: 6| Step: 6
Training loss: 1.3735003471374512
Validation loss: 2.049765149752299

Epoch: 6| Step: 7
Training loss: 2.7575016021728516
Validation loss: 2.047942280769348

Epoch: 6| Step: 8
Training loss: 1.5336496829986572
Validation loss: 2.0663018027941384

Epoch: 6| Step: 9
Training loss: 2.442718982696533
Validation loss: 2.0572368105252585

Epoch: 6| Step: 10
Training loss: 1.8420240879058838
Validation loss: 2.0577551325162253

Epoch: 6| Step: 11
Training loss: 2.433236598968506
Validation loss: 2.0600374738375344

Epoch: 6| Step: 12
Training loss: 2.269873857498169
Validation loss: 2.051298220952352

Epoch: 6| Step: 13
Training loss: 1.818613886833191
Validation loss: 2.059080402056376

Epoch: 129| Step: 0
Training loss: 2.5796780586242676
Validation loss: 2.0601003170013428

Epoch: 6| Step: 1
Training loss: 2.2154226303100586
Validation loss: 2.066357990105947

Epoch: 6| Step: 2
Training loss: 2.27286958694458
Validation loss: 2.077943722407023

Epoch: 6| Step: 3
Training loss: 1.6354089975357056
Validation loss: 2.0654386281967163

Epoch: 6| Step: 4
Training loss: 2.243626117706299
Validation loss: 2.0700273911158242

Epoch: 6| Step: 5
Training loss: 2.264528751373291
Validation loss: 2.0622176130612693

Epoch: 6| Step: 6
Training loss: 1.8897026777267456
Validation loss: 2.0634756286938987

Epoch: 6| Step: 7
Training loss: 1.9809376001358032
Validation loss: 2.060032526652018

Epoch: 6| Step: 8
Training loss: 1.1150493621826172
Validation loss: 2.0650099317232766

Epoch: 6| Step: 9
Training loss: 2.2061924934387207
Validation loss: 2.06724222501119

Epoch: 6| Step: 10
Training loss: 2.183413028717041
Validation loss: 2.0628206928571067

Epoch: 6| Step: 11
Training loss: 1.8426647186279297
Validation loss: 2.0749519069989524

Epoch: 6| Step: 12
Training loss: 2.1741015911102295
Validation loss: 2.0684973994890847

Epoch: 6| Step: 13
Training loss: 1.7512032985687256
Validation loss: 2.0632048845291138

Epoch: 130| Step: 0
Training loss: 1.9967725276947021
Validation loss: 2.0677109559377036

Epoch: 6| Step: 1
Training loss: 1.7163925170898438
Validation loss: 2.0757070978482566

Epoch: 6| Step: 2
Training loss: 2.648789405822754
Validation loss: 2.078937033812205

Epoch: 6| Step: 3
Training loss: 1.9286208152770996
Validation loss: 2.0805073777834573

Epoch: 6| Step: 4
Training loss: 1.6662383079528809
Validation loss: 2.0707587401072183

Epoch: 6| Step: 5
Training loss: 2.293964385986328
Validation loss: 2.0686209003130593

Epoch: 6| Step: 6
Training loss: 1.6920491456985474
Validation loss: 2.0693043867746987

Epoch: 6| Step: 7
Training loss: 2.895653247833252
Validation loss: 2.068576693534851

Epoch: 6| Step: 8
Training loss: 2.1084227561950684
Validation loss: 2.052782972653707

Epoch: 6| Step: 9
Training loss: 2.2471189498901367
Validation loss: 2.069640258948008

Epoch: 6| Step: 10
Training loss: 1.2993695735931396
Validation loss: 2.064645528793335

Epoch: 6| Step: 11
Training loss: 1.3756260871887207
Validation loss: 2.068211078643799

Epoch: 6| Step: 12
Training loss: 2.198119878768921
Validation loss: 2.068799614906311

Epoch: 6| Step: 13
Training loss: 2.175572395324707
Validation loss: 2.064571261405945

Epoch: 131| Step: 0
Training loss: 1.5062777996063232
Validation loss: 2.066445529460907

Epoch: 6| Step: 1
Training loss: 2.4032115936279297
Validation loss: 2.0608150959014893

Epoch: 6| Step: 2
Training loss: 2.309239625930786
Validation loss: 2.058784604072571

Epoch: 6| Step: 3
Training loss: 2.3281917572021484
Validation loss: 2.0574753880500793

Epoch: 6| Step: 4
Training loss: 1.7094950675964355
Validation loss: 2.0580846071243286

Epoch: 6| Step: 5
Training loss: 1.9093633890151978
Validation loss: 2.053541342417399

Epoch: 6| Step: 6
Training loss: 1.5362588167190552
Validation loss: 2.04788331190745

Epoch: 6| Step: 7
Training loss: 2.030771493911743
Validation loss: 2.057162344455719

Epoch: 6| Step: 8
Training loss: 2.1269993782043457
Validation loss: 2.0591769019762673

Epoch: 6| Step: 9
Training loss: 1.4457014799118042
Validation loss: 2.064786891142527

Epoch: 6| Step: 10
Training loss: 2.2720484733581543
Validation loss: 2.0609692335128784

Epoch: 6| Step: 11
Training loss: 2.5798425674438477
Validation loss: 2.065478801727295

Epoch: 6| Step: 12
Training loss: 1.8885817527770996
Validation loss: 2.062328120072683

Epoch: 6| Step: 13
Training loss: 2.207826614379883
Validation loss: 2.064448575178782

Epoch: 132| Step: 0
Training loss: 2.2617290019989014
Validation loss: 2.0642908811569214

Epoch: 6| Step: 1
Training loss: 1.73659348487854
Validation loss: 2.0696472922960916

Epoch: 6| Step: 2
Training loss: 2.4319615364074707
Validation loss: 2.070269842942556

Epoch: 6| Step: 3
Training loss: 1.9963244199752808
Validation loss: 2.06113467613856

Epoch: 6| Step: 4
Training loss: 1.5729042291641235
Validation loss: 2.0538923740386963

Epoch: 6| Step: 5
Training loss: 2.1437079906463623
Validation loss: 2.0698002775510154

Epoch: 6| Step: 6
Training loss: 2.13993763923645
Validation loss: 2.0643358627955117

Epoch: 6| Step: 7
Training loss: 2.376641273498535
Validation loss: 2.069563011328379

Epoch: 6| Step: 8
Training loss: 1.6415387392044067
Validation loss: 2.085601270198822

Epoch: 6| Step: 9
Training loss: 1.7841100692749023
Validation loss: 2.0744402209917703

Epoch: 6| Step: 10
Training loss: 1.715456247329712
Validation loss: 2.0656578143437705

Epoch: 6| Step: 11
Training loss: 2.159560203552246
Validation loss: 2.0652968883514404

Epoch: 6| Step: 12
Training loss: 2.109518527984619
Validation loss: 2.0635759433110556

Epoch: 6| Step: 13
Training loss: 2.2311506271362305
Validation loss: 2.0673081278800964

Epoch: 133| Step: 0
Training loss: 2.227222442626953
Validation loss: 2.071024715900421

Epoch: 6| Step: 1
Training loss: 1.879347801208496
Validation loss: 2.0744933088620505

Epoch: 6| Step: 2
Training loss: 2.0156891345977783
Validation loss: 2.0759036938349404

Epoch: 6| Step: 3
Training loss: 2.038241386413574
Validation loss: 2.0680371125539145

Epoch: 6| Step: 4
Training loss: 2.1422617435455322
Validation loss: 2.063040296236674

Epoch: 6| Step: 5
Training loss: 2.4821252822875977
Validation loss: 2.062123397986094

Epoch: 6| Step: 6
Training loss: 1.9799977540969849
Validation loss: 2.0530764857927957

Epoch: 6| Step: 7
Training loss: 1.2780773639678955
Validation loss: 2.0598709980646768

Epoch: 6| Step: 8
Training loss: 1.3733259439468384
Validation loss: 2.0728999376296997

Epoch: 6| Step: 9
Training loss: 2.368072509765625
Validation loss: 2.0779751539230347

Epoch: 6| Step: 10
Training loss: 1.76893150806427
Validation loss: 2.09745200475057

Epoch: 6| Step: 11
Training loss: 1.7139812707901
Validation loss: 2.098143716653188

Epoch: 6| Step: 12
Training loss: 2.5447168350219727
Validation loss: 2.0876728693644204

Epoch: 6| Step: 13
Training loss: 2.5560250282287598
Validation loss: 2.0811800758043923

Epoch: 134| Step: 0
Training loss: 2.203023672103882
Validation loss: 2.069708069165548

Epoch: 6| Step: 1
Training loss: 1.9411765336990356
Validation loss: 2.055601497491201

Epoch: 6| Step: 2
Training loss: 2.7956647872924805
Validation loss: 2.054585814476013

Epoch: 6| Step: 3
Training loss: 1.7301387786865234
Validation loss: 2.0465245445569358

Epoch: 6| Step: 4
Training loss: 1.5483696460723877
Validation loss: 2.0473929047584534

Epoch: 6| Step: 5
Training loss: 2.493130683898926
Validation loss: 2.05163045724233

Epoch: 6| Step: 6
Training loss: 2.0204620361328125
Validation loss: 2.039970894654592

Epoch: 6| Step: 7
Training loss: 1.3745205402374268
Validation loss: 2.0418157974878945

Epoch: 6| Step: 8
Training loss: 2.295726776123047
Validation loss: 2.05292809009552

Epoch: 6| Step: 9
Training loss: 1.9622622728347778
Validation loss: 2.039615531762441

Epoch: 6| Step: 10
Training loss: 1.6116738319396973
Validation loss: 2.049873928229014

Epoch: 6| Step: 11
Training loss: 2.241204261779785
Validation loss: 2.056755085786184

Epoch: 6| Step: 12
Training loss: 1.7448805570602417
Validation loss: 2.056331217288971

Epoch: 6| Step: 13
Training loss: 2.173788070678711
Validation loss: 2.05743799606959

Epoch: 135| Step: 0
Training loss: 1.5352333784103394
Validation loss: 2.0602224469184875

Epoch: 6| Step: 1
Training loss: 2.1852879524230957
Validation loss: 2.0592706004778543

Epoch: 6| Step: 2
Training loss: 2.280642509460449
Validation loss: 2.0653966069221497

Epoch: 6| Step: 3
Training loss: 2.036586046218872
Validation loss: 2.0603708227475486

Epoch: 6| Step: 4
Training loss: 1.9328155517578125
Validation loss: 2.057224770387014

Epoch: 6| Step: 5
Training loss: 2.1222634315490723
Validation loss: 2.0587279200553894

Epoch: 6| Step: 6
Training loss: 1.6611790657043457
Validation loss: 2.064869483311971

Epoch: 6| Step: 7
Training loss: 2.305217981338501
Validation loss: 2.0696585178375244

Epoch: 6| Step: 8
Training loss: 2.3202388286590576
Validation loss: 2.054536739985148

Epoch: 6| Step: 9
Training loss: 1.5395058393478394
Validation loss: 2.053749163945516

Epoch: 6| Step: 10
Training loss: 2.172961950302124
Validation loss: 2.0589635968208313

Epoch: 6| Step: 11
Training loss: 2.1693639755249023
Validation loss: 2.051977753639221

Epoch: 6| Step: 12
Training loss: 2.2425451278686523
Validation loss: 2.058474898338318

Epoch: 6| Step: 13
Training loss: 1.893674373626709
Validation loss: 2.0489498178164163

Epoch: 136| Step: 0
Training loss: 2.1605730056762695
Validation loss: 2.0598296920458474

Epoch: 6| Step: 1
Training loss: 2.26117205619812
Validation loss: 2.05752960840861

Epoch: 6| Step: 2
Training loss: 1.7194880247116089
Validation loss: 2.0554199616114297

Epoch: 6| Step: 3
Training loss: 2.40678071975708
Validation loss: 2.0706915060679116

Epoch: 6| Step: 4
Training loss: 2.447510242462158
Validation loss: 2.0678967436154685

Epoch: 6| Step: 5
Training loss: 1.5003454685211182
Validation loss: 2.0739622712135315

Epoch: 6| Step: 6
Training loss: 2.1642439365386963
Validation loss: 2.0748339692751565

Epoch: 6| Step: 7
Training loss: 2.6057522296905518
Validation loss: 2.0808576742808023

Epoch: 6| Step: 8
Training loss: 2.2136974334716797
Validation loss: 2.0749728282292685

Epoch: 6| Step: 9
Training loss: 1.6878770589828491
Validation loss: 2.069127102692922

Epoch: 6| Step: 10
Training loss: 1.0915007591247559
Validation loss: 2.058805743853251

Epoch: 6| Step: 11
Training loss: 1.8415122032165527
Validation loss: 2.0499653418858848

Epoch: 6| Step: 12
Training loss: 1.9858920574188232
Validation loss: 2.0492579142252603

Epoch: 6| Step: 13
Training loss: 2.1448440551757812
Validation loss: 2.036761005719503

Epoch: 137| Step: 0
Training loss: 2.3658790588378906
Validation loss: 2.052326043446859

Epoch: 6| Step: 1
Training loss: 1.999598503112793
Validation loss: 2.0575263102849326

Epoch: 6| Step: 2
Training loss: 2.4790005683898926
Validation loss: 2.0514102379480996

Epoch: 6| Step: 3
Training loss: 3.0844712257385254
Validation loss: 2.0488319396972656

Epoch: 6| Step: 4
Training loss: 1.6612344980239868
Validation loss: 2.0545506874720254

Epoch: 6| Step: 5
Training loss: 1.967227816581726
Validation loss: 2.047650456428528

Epoch: 6| Step: 6
Training loss: 2.090365409851074
Validation loss: 2.049709955851237

Epoch: 6| Step: 7
Training loss: 1.891778588294983
Validation loss: 2.0536133646965027

Epoch: 6| Step: 8
Training loss: 1.8478460311889648
Validation loss: 2.054210285345713

Epoch: 6| Step: 9
Training loss: 2.081336736679077
Validation loss: 2.0611809492111206

Epoch: 6| Step: 10
Training loss: 2.293412208557129
Validation loss: 2.070408562819163

Epoch: 6| Step: 11
Training loss: 1.4021387100219727
Validation loss: 2.065908054510752

Epoch: 6| Step: 12
Training loss: 1.568802833557129
Validation loss: 2.0688084165255227

Epoch: 6| Step: 13
Training loss: 1.6179039478302002
Validation loss: 2.0778167645136514

Epoch: 138| Step: 0
Training loss: 1.583385944366455
Validation loss: 2.079187333583832

Epoch: 6| Step: 1
Training loss: 1.761531114578247
Validation loss: 2.084560672442118

Epoch: 6| Step: 2
Training loss: 1.8138079643249512
Validation loss: 2.084938089052836

Epoch: 6| Step: 3
Training loss: 2.806058883666992
Validation loss: 2.087221066157023

Epoch: 6| Step: 4
Training loss: 1.8591437339782715
Validation loss: 2.0760666926701865

Epoch: 6| Step: 5
Training loss: 1.8563933372497559
Validation loss: 2.0707440972328186

Epoch: 6| Step: 6
Training loss: 1.9012067317962646
Validation loss: 2.0702373385429382

Epoch: 6| Step: 7
Training loss: 2.1172304153442383
Validation loss: 2.067221999168396

Epoch: 6| Step: 8
Training loss: 2.443861961364746
Validation loss: 2.0640660723050437

Epoch: 6| Step: 9
Training loss: 2.282137155532837
Validation loss: 2.0574729839960733

Epoch: 6| Step: 10
Training loss: 1.9047889709472656
Validation loss: 2.055041551589966

Epoch: 6| Step: 11
Training loss: 1.6824491024017334
Validation loss: 2.050530950228373

Epoch: 6| Step: 12
Training loss: 1.7703807353973389
Validation loss: 2.044983704884847

Epoch: 6| Step: 13
Training loss: 2.542914390563965
Validation loss: 2.0515692830085754

Epoch: 139| Step: 0
Training loss: 1.6921570301055908
Validation loss: 2.0577478408813477

Epoch: 6| Step: 1
Training loss: 1.728536605834961
Validation loss: 2.056454281012217

Epoch: 6| Step: 2
Training loss: 2.3563899993896484
Validation loss: 2.0570373932520547

Epoch: 6| Step: 3
Training loss: 1.7300673723220825
Validation loss: 2.061013102531433

Epoch: 6| Step: 4
Training loss: 2.580051898956299
Validation loss: 2.0701332290967307

Epoch: 6| Step: 5
Training loss: 2.3267900943756104
Validation loss: 2.0685372749964395

Epoch: 6| Step: 6
Training loss: 1.2848342657089233
Validation loss: 2.061932543913523

Epoch: 6| Step: 7
Training loss: 2.3509857654571533
Validation loss: 2.0782973965009055

Epoch: 6| Step: 8
Training loss: 2.486039638519287
Validation loss: 2.083137293656667

Epoch: 6| Step: 9
Training loss: 1.958279013633728
Validation loss: 2.080968995889028

Epoch: 6| Step: 10
Training loss: 3.0381412506103516
Validation loss: 2.0741224686304727

Epoch: 6| Step: 11
Training loss: 1.5917919874191284
Validation loss: 2.072084824244181

Epoch: 6| Step: 12
Training loss: 1.10820734500885
Validation loss: 2.07322750488917

Epoch: 6| Step: 13
Training loss: 2.3769052028656006
Validation loss: 2.0764517386754355

Epoch: 140| Step: 0
Training loss: 1.3604950904846191
Validation loss: 2.0705971717834473

Epoch: 6| Step: 1
Training loss: 2.153172731399536
Validation loss: 2.0635550220807395

Epoch: 6| Step: 2
Training loss: 1.8571712970733643
Validation loss: 2.0632086594899497

Epoch: 6| Step: 3
Training loss: 2.441636323928833
Validation loss: 2.0575814644495645

Epoch: 6| Step: 4
Training loss: 1.7563101053237915
Validation loss: 2.0591590801874795

Epoch: 6| Step: 5
Training loss: 2.069960832595825
Validation loss: 2.05368709564209

Epoch: 6| Step: 6
Training loss: 1.9580234289169312
Validation loss: 2.055636485417684

Epoch: 6| Step: 7
Training loss: 1.698553204536438
Validation loss: 2.0507417917251587

Epoch: 6| Step: 8
Training loss: 2.336599349975586
Validation loss: 2.06613689661026

Epoch: 6| Step: 9
Training loss: 1.73551344871521
Validation loss: 2.0649155974388123

Epoch: 6| Step: 10
Training loss: 2.5131921768188477
Validation loss: 2.0637388030687966

Epoch: 6| Step: 11
Training loss: 1.9771227836608887
Validation loss: 2.0682737231254578

Epoch: 6| Step: 12
Training loss: 1.9597606658935547
Validation loss: 2.067744175593058

Epoch: 6| Step: 13
Training loss: 2.2452855110168457
Validation loss: 2.068659464518229

Epoch: 141| Step: 0
Training loss: 1.7779275178909302
Validation loss: 2.069905936717987

Epoch: 6| Step: 1
Training loss: 1.70767080783844
Validation loss: 2.077226003011068

Epoch: 6| Step: 2
Training loss: 1.651517391204834
Validation loss: 2.0726693272590637

Epoch: 6| Step: 3
Training loss: 2.2750043869018555
Validation loss: 2.0848090052604675

Epoch: 6| Step: 4
Training loss: 2.3533267974853516
Validation loss: 2.097451309363047

Epoch: 6| Step: 5
Training loss: 1.4149037599563599
Validation loss: 2.092459579308828

Epoch: 6| Step: 6
Training loss: 1.7364747524261475
Validation loss: 2.0943147341410318

Epoch: 6| Step: 7
Training loss: 2.3809499740600586
Validation loss: 2.0898667772610984

Epoch: 6| Step: 8
Training loss: 1.950562596321106
Validation loss: 2.0889538327852883

Epoch: 6| Step: 9
Training loss: 2.297213554382324
Validation loss: 2.0816039045651755

Epoch: 6| Step: 10
Training loss: 2.1986637115478516
Validation loss: 2.076880097389221

Epoch: 6| Step: 11
Training loss: 1.784319519996643
Validation loss: 2.0634480516115823

Epoch: 6| Step: 12
Training loss: 2.1290740966796875
Validation loss: 2.065404176712036

Epoch: 6| Step: 13
Training loss: 2.2267398834228516
Validation loss: 2.0629639426867166

Epoch: 142| Step: 0
Training loss: 1.7130379676818848
Validation loss: 2.058915654818217

Epoch: 6| Step: 1
Training loss: 1.755060076713562
Validation loss: 2.059749444325765

Epoch: 6| Step: 2
Training loss: 2.2831034660339355
Validation loss: 2.064827104409536

Epoch: 6| Step: 3
Training loss: 2.7908687591552734
Validation loss: 2.065225621064504

Epoch: 6| Step: 4
Training loss: 2.128429412841797
Validation loss: 2.066817820072174

Epoch: 6| Step: 5
Training loss: 2.0644686222076416
Validation loss: 2.0750457048416138

Epoch: 6| Step: 6
Training loss: 1.3234703540802002
Validation loss: 2.0772189100583396

Epoch: 6| Step: 7
Training loss: 1.5800349712371826
Validation loss: 2.0840758681297302

Epoch: 6| Step: 8
Training loss: 1.9837802648544312
Validation loss: 2.09039968252182

Epoch: 6| Step: 9
Training loss: 2.488236904144287
Validation loss: 2.095217764377594

Epoch: 6| Step: 10
Training loss: 1.6248226165771484
Validation loss: 2.0867345134417215

Epoch: 6| Step: 11
Training loss: 2.2925467491149902
Validation loss: 2.088704784711202

Epoch: 6| Step: 12
Training loss: 1.747255802154541
Validation loss: 2.0859638253847756

Epoch: 6| Step: 13
Training loss: 2.1103909015655518
Validation loss: 2.0840246876080832

Epoch: 143| Step: 0
Training loss: 1.8227814435958862
Validation loss: 2.0811037023862204

Epoch: 6| Step: 1
Training loss: 1.8540549278259277
Validation loss: 2.090931554635366

Epoch: 6| Step: 2
Training loss: 1.9882314205169678
Validation loss: 2.0796931783358255

Epoch: 6| Step: 3
Training loss: 1.711588740348816
Validation loss: 2.0867311358451843

Epoch: 6| Step: 4
Training loss: 1.5316112041473389
Validation loss: 2.091765205065409

Epoch: 6| Step: 5
Training loss: 1.541396975517273
Validation loss: 2.090836842854818

Epoch: 6| Step: 6
Training loss: 2.7421412467956543
Validation loss: 2.0977438489596048

Epoch: 6| Step: 7
Training loss: 2.5077497959136963
Validation loss: 2.079169233640035

Epoch: 6| Step: 8
Training loss: 1.6866569519042969
Validation loss: 2.0840691129366555

Epoch: 6| Step: 9
Training loss: 2.147127628326416
Validation loss: 2.07314924399058

Epoch: 6| Step: 10
Training loss: 2.030613899230957
Validation loss: 2.080258627732595

Epoch: 6| Step: 11
Training loss: 1.635838508605957
Validation loss: 2.071374237537384

Epoch: 6| Step: 12
Training loss: 2.275744915008545
Validation loss: 2.060656209786733

Epoch: 6| Step: 13
Training loss: 2.3191792964935303
Validation loss: 2.055443008740743

Epoch: 144| Step: 0
Training loss: 1.793442726135254
Validation loss: 2.0649400750796

Epoch: 6| Step: 1
Training loss: 1.9284663200378418
Validation loss: 2.060083349545797

Epoch: 6| Step: 2
Training loss: 2.110596179962158
Validation loss: 2.0571882327397666

Epoch: 6| Step: 3
Training loss: 2.173312187194824
Validation loss: 2.0669761896133423

Epoch: 6| Step: 4
Training loss: 2.116309881210327
Validation loss: 2.058893620967865

Epoch: 6| Step: 5
Training loss: 1.624174952507019
Validation loss: 2.0583081245422363

Epoch: 6| Step: 6
Training loss: 1.6471412181854248
Validation loss: 2.0644292632738748

Epoch: 6| Step: 7
Training loss: 2.1095755100250244
Validation loss: 2.0738893349965415

Epoch: 6| Step: 8
Training loss: 2.5146374702453613
Validation loss: 2.074089845021566

Epoch: 6| Step: 9
Training loss: 1.8421348333358765
Validation loss: 2.0853731433550515

Epoch: 6| Step: 10
Training loss: 2.2577033042907715
Validation loss: 2.0990612506866455

Epoch: 6| Step: 11
Training loss: 1.677162528038025
Validation loss: 2.0994343558947244

Epoch: 6| Step: 12
Training loss: 1.5787702798843384
Validation loss: 2.115794599056244

Epoch: 6| Step: 13
Training loss: 2.4729373455047607
Validation loss: 2.0947904189427695

Epoch: 145| Step: 0
Training loss: 2.396777391433716
Validation loss: 2.1041892965634665

Epoch: 6| Step: 1
Training loss: 1.8976842164993286
Validation loss: 2.0904831488927207

Epoch: 6| Step: 2
Training loss: 2.5407166481018066
Validation loss: 2.0875096519788108

Epoch: 6| Step: 3
Training loss: 1.4007558822631836
Validation loss: 2.0763484835624695

Epoch: 6| Step: 4
Training loss: 1.8827160596847534
Validation loss: 2.0739983916282654

Epoch: 6| Step: 5
Training loss: 2.260326385498047
Validation loss: 2.0683807730674744

Epoch: 6| Step: 6
Training loss: 2.3838932514190674
Validation loss: 2.0581007599830627

Epoch: 6| Step: 7
Training loss: 1.3359582424163818
Validation loss: 2.0561137000719705

Epoch: 6| Step: 8
Training loss: 2.0089898109436035
Validation loss: 2.0622169971466064

Epoch: 6| Step: 9
Training loss: 2.2036237716674805
Validation loss: 2.0656919280687966

Epoch: 6| Step: 10
Training loss: 1.892993688583374
Validation loss: 2.0615213910738626

Epoch: 6| Step: 11
Training loss: 2.1719892024993896
Validation loss: 2.068715453147888

Epoch: 6| Step: 12
Training loss: 2.0712013244628906
Validation loss: 2.0660630067189536

Epoch: 6| Step: 13
Training loss: 1.5796571969985962
Validation loss: 2.056018849213918

Epoch: 146| Step: 0
Training loss: 2.0170705318450928
Validation loss: 2.067288359006246

Epoch: 6| Step: 1
Training loss: 1.8248507976531982
Validation loss: 2.066978176434835

Epoch: 6| Step: 2
Training loss: 1.506068229675293
Validation loss: 2.064291000366211

Epoch: 6| Step: 3
Training loss: 2.7675585746765137
Validation loss: 2.058590352535248

Epoch: 6| Step: 4
Training loss: 1.3550952672958374
Validation loss: 2.0680161714553833

Epoch: 6| Step: 5
Training loss: 1.831223487854004
Validation loss: 2.0700893004735312

Epoch: 6| Step: 6
Training loss: 1.1075522899627686
Validation loss: 2.0722379287083945

Epoch: 6| Step: 7
Training loss: 1.8343034982681274
Validation loss: 2.0843304793039956

Epoch: 6| Step: 8
Training loss: 2.234452724456787
Validation loss: 2.089856723944346

Epoch: 6| Step: 9
Training loss: 2.702484369277954
Validation loss: 2.0920066038767495

Epoch: 6| Step: 10
Training loss: 2.349729061126709
Validation loss: 2.105199694633484

Epoch: 6| Step: 11
Training loss: 2.3540303707122803
Validation loss: 2.0901000698407493

Epoch: 6| Step: 12
Training loss: 1.9881772994995117
Validation loss: 2.0995030403137207

Epoch: 6| Step: 13
Training loss: 1.9496355056762695
Validation loss: 2.0778663555781045

Epoch: 147| Step: 0
Training loss: 2.2646713256835938
Validation loss: 2.08015505472819

Epoch: 6| Step: 1
Training loss: 1.76852548122406
Validation loss: 2.0701144337654114

Epoch: 6| Step: 2
Training loss: 2.028127431869507
Validation loss: 2.0688482324282327

Epoch: 6| Step: 3
Training loss: 2.4835174083709717
Validation loss: 2.0695665081342063

Epoch: 6| Step: 4
Training loss: 1.596787929534912
Validation loss: 2.0682207147280374

Epoch: 6| Step: 5
Training loss: 1.7056925296783447
Validation loss: 2.0609044233957925

Epoch: 6| Step: 6
Training loss: 1.9163074493408203
Validation loss: 2.0749295155207315

Epoch: 6| Step: 7
Training loss: 1.9819382429122925
Validation loss: 2.093309005101522

Epoch: 6| Step: 8
Training loss: 1.6182538270950317
Validation loss: 2.090431829293569

Epoch: 6| Step: 9
Training loss: 2.290947198867798
Validation loss: 2.0851932366689048

Epoch: 6| Step: 10
Training loss: 2.1173763275146484
Validation loss: 2.100130319595337

Epoch: 6| Step: 11
Training loss: 2.166752576828003
Validation loss: 2.0914920767148337

Epoch: 6| Step: 12
Training loss: 1.8165451288223267
Validation loss: 2.08670965830485

Epoch: 6| Step: 13
Training loss: 2.0153069496154785
Validation loss: 2.084164798259735

Epoch: 148| Step: 0
Training loss: 2.182957172393799
Validation loss: 2.077047904332479

Epoch: 6| Step: 1
Training loss: 1.8423168659210205
Validation loss: 2.078344146410624

Epoch: 6| Step: 2
Training loss: 1.7278716564178467
Validation loss: 2.083133598168691

Epoch: 6| Step: 3
Training loss: 2.3420448303222656
Validation loss: 2.0810925563176474

Epoch: 6| Step: 4
Training loss: 1.8756697177886963
Validation loss: 2.0690476099650064

Epoch: 6| Step: 5
Training loss: 1.5866751670837402
Validation loss: 2.076084832350413

Epoch: 6| Step: 6
Training loss: 1.6851072311401367
Validation loss: 2.078360100587209

Epoch: 6| Step: 7
Training loss: 2.5507988929748535
Validation loss: 2.0770445664723716

Epoch: 6| Step: 8
Training loss: 1.4870197772979736
Validation loss: 2.0832202235857644

Epoch: 6| Step: 9
Training loss: 2.2331252098083496
Validation loss: 2.075971007347107

Epoch: 6| Step: 10
Training loss: 1.6497862339019775
Validation loss: 2.0811643401781716

Epoch: 6| Step: 11
Training loss: 2.449049949645996
Validation loss: 2.07022488117218

Epoch: 6| Step: 12
Training loss: 2.0605878829956055
Validation loss: 2.064664840698242

Epoch: 6| Step: 13
Training loss: 1.828575849533081
Validation loss: 2.075656274954478

Epoch: 149| Step: 0
Training loss: 1.9130125045776367
Validation loss: 2.0683841904004416

Epoch: 6| Step: 1
Training loss: 2.079444408416748
Validation loss: 2.0687445998191833

Epoch: 6| Step: 2
Training loss: 1.7088284492492676
Validation loss: 2.0730990171432495

Epoch: 6| Step: 3
Training loss: 2.360157012939453
Validation loss: 2.0784948666890464

Epoch: 6| Step: 4
Training loss: 1.640796184539795
Validation loss: 2.0865453481674194

Epoch: 6| Step: 5
Training loss: 2.3239002227783203
Validation loss: 2.079748570919037

Epoch: 6| Step: 6
Training loss: 2.1921839714050293
Validation loss: 2.075002372264862

Epoch: 6| Step: 7
Training loss: 1.3384932279586792
Validation loss: 2.0833204984664917

Epoch: 6| Step: 8
Training loss: 2.2759108543395996
Validation loss: 2.083063761393229

Epoch: 6| Step: 9
Training loss: 2.4428162574768066
Validation loss: 2.085148890813192

Epoch: 6| Step: 10
Training loss: 1.6850552558898926
Validation loss: 2.0916910966237388

Epoch: 6| Step: 11
Training loss: 2.1014676094055176
Validation loss: 2.0977046887079873

Epoch: 6| Step: 12
Training loss: 1.7677955627441406
Validation loss: 2.0863402684529624

Epoch: 6| Step: 13
Training loss: 1.7910901308059692
Validation loss: 2.0871904691060386

Epoch: 150| Step: 0
Training loss: 2.6579504013061523
Validation loss: 2.1011860171953836

Epoch: 6| Step: 1
Training loss: 1.935600757598877
Validation loss: 2.094950795173645

Epoch: 6| Step: 2
Training loss: 1.7659034729003906
Validation loss: 2.082066555817922

Epoch: 6| Step: 3
Training loss: 1.8917382955551147
Validation loss: 2.0755085547765098

Epoch: 6| Step: 4
Training loss: 2.241001605987549
Validation loss: 2.072942594687144

Epoch: 6| Step: 5
Training loss: 1.6507837772369385
Validation loss: 2.0754647652308145

Epoch: 6| Step: 6
Training loss: 2.095886707305908
Validation loss: 2.0696922739346824

Epoch: 6| Step: 7
Training loss: 2.24440336227417
Validation loss: 2.073804239432017

Epoch: 6| Step: 8
Training loss: 1.7000117301940918
Validation loss: 2.0752324064572654

Epoch: 6| Step: 9
Training loss: 1.7422934770584106
Validation loss: 2.088278909524282

Epoch: 6| Step: 10
Training loss: 1.741805911064148
Validation loss: 2.0883708794911704

Epoch: 6| Step: 11
Training loss: 2.297901153564453
Validation loss: 2.094423075517019

Epoch: 6| Step: 12
Training loss: 1.8779456615447998
Validation loss: 2.0864091912905374

Epoch: 6| Step: 13
Training loss: 1.9637831449508667
Validation loss: 2.0931523044904075

Epoch: 151| Step: 0
Training loss: 2.603511333465576
Validation loss: 2.085725426673889

Epoch: 6| Step: 1
Training loss: 1.589111328125
Validation loss: 2.088113307952881

Epoch: 6| Step: 2
Training loss: 1.929985523223877
Validation loss: 2.1057488123575845

Epoch: 6| Step: 3
Training loss: 2.0247700214385986
Validation loss: 2.0841886599858603

Epoch: 6| Step: 4
Training loss: 1.8254623413085938
Validation loss: 2.095217009385427

Epoch: 6| Step: 5
Training loss: 1.489116907119751
Validation loss: 2.0758623679478965

Epoch: 6| Step: 6
Training loss: 1.9312865734100342
Validation loss: 2.0635703206062317

Epoch: 6| Step: 7
Training loss: 2.0855534076690674
Validation loss: 2.0724782745043435

Epoch: 6| Step: 8
Training loss: 2.0096309185028076
Validation loss: 2.071788767973582

Epoch: 6| Step: 9
Training loss: 1.7814809083938599
Validation loss: 2.0579601724942527

Epoch: 6| Step: 10
Training loss: 2.0295753479003906
Validation loss: 2.072335879007975

Epoch: 6| Step: 11
Training loss: 2.1490726470947266
Validation loss: 2.06843094031016

Epoch: 6| Step: 12
Training loss: 1.8400959968566895
Validation loss: 2.0762994289398193

Epoch: 6| Step: 13
Training loss: 2.4776220321655273
Validation loss: 2.075271725654602

Epoch: 152| Step: 0
Training loss: 2.211473226547241
Validation loss: 2.0756271878878274

Epoch: 6| Step: 1
Training loss: 1.815598964691162
Validation loss: 2.091699481010437

Epoch: 6| Step: 2
Training loss: 1.565139651298523
Validation loss: 2.0795127153396606

Epoch: 6| Step: 3
Training loss: 1.080842137336731
Validation loss: 2.0803621411323547

Epoch: 6| Step: 4
Training loss: 1.4086418151855469
Validation loss: 2.0876582662264505

Epoch: 6| Step: 5
Training loss: 2.5036122798919678
Validation loss: 2.1145430207252502

Epoch: 6| Step: 6
Training loss: 2.2041773796081543
Validation loss: 2.1016063491503396

Epoch: 6| Step: 7
Training loss: 2.062758445739746
Validation loss: 2.0901493231455484

Epoch: 6| Step: 8
Training loss: 2.2204012870788574
Validation loss: 2.095154047012329

Epoch: 6| Step: 9
Training loss: 1.7159955501556396
Validation loss: 2.0751731197039285

Epoch: 6| Step: 10
Training loss: 1.5716211795806885
Validation loss: 2.080191950003306

Epoch: 6| Step: 11
Training loss: 2.5900044441223145
Validation loss: 2.0778029561042786

Epoch: 6| Step: 12
Training loss: 2.1052026748657227
Validation loss: 2.0769135554631553

Epoch: 6| Step: 13
Training loss: 2.617953062057495
Validation loss: 2.0704681277275085

Epoch: 153| Step: 0
Training loss: 2.029796600341797
Validation loss: 2.072514077027639

Epoch: 6| Step: 1
Training loss: 1.7924762964248657
Validation loss: 2.0809919834136963

Epoch: 6| Step: 2
Training loss: 1.9187233448028564
Validation loss: 2.072992265224457

Epoch: 6| Step: 3
Training loss: 1.458526849746704
Validation loss: 2.086104452610016

Epoch: 6| Step: 4
Training loss: 1.7090401649475098
Validation loss: 2.091514229774475

Epoch: 6| Step: 5
Training loss: 2.1714437007904053
Validation loss: 2.0972862442334494

Epoch: 6| Step: 6
Training loss: 3.0884060859680176
Validation loss: 2.0970304210980735

Epoch: 6| Step: 7
Training loss: 1.577319860458374
Validation loss: 2.1048243641853333

Epoch: 6| Step: 8
Training loss: 1.8173890113830566
Validation loss: 2.100822707017263

Epoch: 6| Step: 9
Training loss: 2.10115909576416
Validation loss: 2.0947170853614807

Epoch: 6| Step: 10
Training loss: 1.6973237991333008
Validation loss: 2.0915974179903665

Epoch: 6| Step: 11
Training loss: 1.3921948671340942
Validation loss: 2.095692992210388

Epoch: 6| Step: 12
Training loss: 2.1396470069885254
Validation loss: 2.1192725698153176

Epoch: 6| Step: 13
Training loss: 2.7078776359558105
Validation loss: 2.1070875326792398

Epoch: 154| Step: 0
Training loss: 1.86124587059021
Validation loss: 2.1161129077275596

Epoch: 6| Step: 1
Training loss: 1.7838541269302368
Validation loss: 2.1029587984085083

Epoch: 6| Step: 2
Training loss: 2.515310049057007
Validation loss: 2.096938212712606

Epoch: 6| Step: 3
Training loss: 1.4934759140014648
Validation loss: 2.098400433858236

Epoch: 6| Step: 4
Training loss: 1.4761210680007935
Validation loss: 2.0906237165133157

Epoch: 6| Step: 5
Training loss: 2.572127342224121
Validation loss: 2.089869479338328

Epoch: 6| Step: 6
Training loss: 2.115802049636841
Validation loss: 2.069747587045034

Epoch: 6| Step: 7
Training loss: 1.965271234512329
Validation loss: 2.0646790067354837

Epoch: 6| Step: 8
Training loss: 1.9500041007995605
Validation loss: 2.0595876177152

Epoch: 6| Step: 9
Training loss: 2.3016855716705322
Validation loss: 2.0585877497990928

Epoch: 6| Step: 10
Training loss: 2.3965234756469727
Validation loss: 2.067699690659841

Epoch: 6| Step: 11
Training loss: 2.0757670402526855
Validation loss: 2.0648039976755777

Epoch: 6| Step: 12
Training loss: 2.4509449005126953
Validation loss: 2.065594812234243

Epoch: 6| Step: 13
Training loss: 1.6223260164260864
Validation loss: 2.0630387465159097

Epoch: 155| Step: 0
Training loss: 2.2527761459350586
Validation loss: 2.0614217718442283

Epoch: 6| Step: 1
Training loss: 2.2877137660980225
Validation loss: 2.0628047982851663

Epoch: 6| Step: 2
Training loss: 2.270904064178467
Validation loss: 2.062507450580597

Epoch: 6| Step: 3
Training loss: 1.8369640111923218
Validation loss: 2.070023536682129

Epoch: 6| Step: 4
Training loss: 1.6456968784332275
Validation loss: 2.064592103163401

Epoch: 6| Step: 5
Training loss: 1.8244667053222656
Validation loss: 2.061546544233958

Epoch: 6| Step: 6
Training loss: 1.64651358127594
Validation loss: 2.057322303454081

Epoch: 6| Step: 7
Training loss: 2.3655357360839844
Validation loss: 2.0920922557512918

Epoch: 6| Step: 8
Training loss: 1.7896044254302979
Validation loss: 2.0939415295918784

Epoch: 6| Step: 9
Training loss: 2.260188579559326
Validation loss: 2.099014103412628

Epoch: 6| Step: 10
Training loss: 2.1005120277404785
Validation loss: 2.1178932388623557

Epoch: 6| Step: 11
Training loss: 2.0789830684661865
Validation loss: 2.1162702441215515

Epoch: 6| Step: 12
Training loss: 1.9869108200073242
Validation loss: 2.12526665131251

Epoch: 6| Step: 13
Training loss: 1.412805199623108
Validation loss: 2.1360123554865518

Epoch: 156| Step: 0
Training loss: 2.331521987915039
Validation loss: 2.1286083857218423

Epoch: 6| Step: 1
Training loss: 1.8387365341186523
Validation loss: 2.125907560189565

Epoch: 6| Step: 2
Training loss: 2.0355849266052246
Validation loss: 2.139782806237539

Epoch: 6| Step: 3
Training loss: 2.15777587890625
Validation loss: 2.1326198180516562

Epoch: 6| Step: 4
Training loss: 1.3881065845489502
Validation loss: 2.119291841983795

Epoch: 6| Step: 5
Training loss: 1.8786735534667969
Validation loss: 2.1161880095799765

Epoch: 6| Step: 6
Training loss: 1.418439269065857
Validation loss: 2.114018221696218

Epoch: 6| Step: 7
Training loss: 2.207965135574341
Validation loss: 2.0969203114509583

Epoch: 6| Step: 8
Training loss: 1.8901236057281494
Validation loss: 2.091032783190409

Epoch: 6| Step: 9
Training loss: 2.1845955848693848
Validation loss: 2.086224357287089

Epoch: 6| Step: 10
Training loss: 1.8370587825775146
Validation loss: 2.0814090768496194

Epoch: 6| Step: 11
Training loss: 2.495964765548706
Validation loss: 2.0851592818895974

Epoch: 6| Step: 12
Training loss: 2.368858575820923
Validation loss: 2.0876169403394065

Epoch: 6| Step: 13
Training loss: 1.9674837589263916
Validation loss: 2.08652925491333

Epoch: 157| Step: 0
Training loss: 1.3314871788024902
Validation loss: 2.0905657013257346

Epoch: 6| Step: 1
Training loss: 2.3341894149780273
Validation loss: 2.0853665272394815

Epoch: 6| Step: 2
Training loss: 2.044302463531494
Validation loss: 2.0859344601631165

Epoch: 6| Step: 3
Training loss: 2.205120801925659
Validation loss: 2.0979814728101096

Epoch: 6| Step: 4
Training loss: 2.1992316246032715
Validation loss: 2.0875202417373657

Epoch: 6| Step: 5
Training loss: 2.3484199047088623
Validation loss: 2.086872418721517

Epoch: 6| Step: 6
Training loss: 2.033217430114746
Validation loss: 2.1026357213656106

Epoch: 6| Step: 7
Training loss: 2.0296621322631836
Validation loss: 2.095138430595398

Epoch: 6| Step: 8
Training loss: 1.695542335510254
Validation loss: 2.1110816597938538

Epoch: 6| Step: 9
Training loss: 2.0481677055358887
Validation loss: 2.107351839542389

Epoch: 6| Step: 10
Training loss: 1.353571891784668
Validation loss: 2.111315925916036

Epoch: 6| Step: 11
Training loss: 1.811324119567871
Validation loss: 2.1190921664237976

Epoch: 6| Step: 12
Training loss: 2.036559581756592
Validation loss: 2.116963744163513

Epoch: 6| Step: 13
Training loss: 2.2374134063720703
Validation loss: 2.1193335254987082

Epoch: 158| Step: 0
Training loss: 1.8204593658447266
Validation loss: 2.1065512895584106

Epoch: 6| Step: 1
Training loss: 2.2797389030456543
Validation loss: 2.1072354714075723

Epoch: 6| Step: 2
Training loss: 1.975714921951294
Validation loss: 2.0895226995150247

Epoch: 6| Step: 3
Training loss: 2.7429513931274414
Validation loss: 2.0922888914744058

Epoch: 6| Step: 4
Training loss: 2.0566482543945312
Validation loss: 2.0928595860799155

Epoch: 6| Step: 5
Training loss: 1.6636165380477905
Validation loss: 2.0810927351315818

Epoch: 6| Step: 6
Training loss: 2.2108314037323
Validation loss: 2.094115138053894

Epoch: 6| Step: 7
Training loss: 1.889661192893982
Validation loss: 2.0841291745503745

Epoch: 6| Step: 8
Training loss: 1.2639496326446533
Validation loss: 2.084715167681376

Epoch: 6| Step: 9
Training loss: 1.5254790782928467
Validation loss: 2.0959527095158896

Epoch: 6| Step: 10
Training loss: 1.733087420463562
Validation loss: 2.1106112400690713

Epoch: 6| Step: 11
Training loss: 2.4774301052093506
Validation loss: 2.1012651522954306

Epoch: 6| Step: 12
Training loss: 1.6779608726501465
Validation loss: 2.112006902694702

Epoch: 6| Step: 13
Training loss: 2.2140655517578125
Validation loss: 2.1275550921758017

Epoch: 159| Step: 0
Training loss: 1.613138198852539
Validation loss: 2.1281363368034363

Epoch: 6| Step: 1
Training loss: 1.7208175659179688
Validation loss: 2.1186563372612

Epoch: 6| Step: 2
Training loss: 1.6751517057418823
Validation loss: 2.1306540966033936

Epoch: 6| Step: 3
Training loss: 2.0716795921325684
Validation loss: 2.1266520023345947

Epoch: 6| Step: 4
Training loss: 1.7923808097839355
Validation loss: 2.1194812258084617

Epoch: 6| Step: 5
Training loss: 1.9192458391189575
Validation loss: 2.117496609687805

Epoch: 6| Step: 6
Training loss: 2.1584274768829346
Validation loss: 2.119615395863851

Epoch: 6| Step: 7
Training loss: 2.1420812606811523
Validation loss: 2.11184298992157

Epoch: 6| Step: 8
Training loss: 1.7961245775222778
Validation loss: 2.0948230624198914

Epoch: 6| Step: 9
Training loss: 2.1649022102355957
Validation loss: 2.08041383822759

Epoch: 6| Step: 10
Training loss: 1.9700725078582764
Validation loss: 2.078932603200277

Epoch: 6| Step: 11
Training loss: 2.5042595863342285
Validation loss: 2.081130266189575

Epoch: 6| Step: 12
Training loss: 2.3378777503967285
Validation loss: 2.0685542027155557

Epoch: 6| Step: 13
Training loss: 1.914555311203003
Validation loss: 2.069288909435272

Epoch: 160| Step: 0
Training loss: 2.140491247177124
Validation loss: 2.065029819806417

Epoch: 6| Step: 1
Training loss: 2.5775303840637207
Validation loss: 2.0584616462389627

Epoch: 6| Step: 2
Training loss: 1.8057093620300293
Validation loss: 2.0629452665646872

Epoch: 6| Step: 3
Training loss: 1.6403534412384033
Validation loss: 2.0576961239178977

Epoch: 6| Step: 4
Training loss: 1.7233067750930786
Validation loss: 2.0685779452323914

Epoch: 6| Step: 5
Training loss: 2.260472297668457
Validation loss: 2.068139930566152

Epoch: 6| Step: 6
Training loss: 1.6276203393936157
Validation loss: 2.0794923901557922

Epoch: 6| Step: 7
Training loss: 2.9187724590301514
Validation loss: 2.0989035169283548

Epoch: 6| Step: 8
Training loss: 2.517665147781372
Validation loss: 2.098718067010244

Epoch: 6| Step: 9
Training loss: 2.448780059814453
Validation loss: 2.097103476524353

Epoch: 6| Step: 10
Training loss: 1.0438039302825928
Validation loss: 2.1014839808146157

Epoch: 6| Step: 11
Training loss: 1.3857154846191406
Validation loss: 2.111685832341512

Epoch: 6| Step: 12
Training loss: 1.5115822553634644
Validation loss: 2.1134695212046304

Epoch: 6| Step: 13
Training loss: 1.8693325519561768
Validation loss: 2.1112833420435586

Epoch: 161| Step: 0
Training loss: 2.073314666748047
Validation loss: 2.1099260648091636

Epoch: 6| Step: 1
Training loss: 1.7354035377502441
Validation loss: 2.1103074749310813

Epoch: 6| Step: 2
Training loss: 2.069500207901001
Validation loss: 2.0917267402013144

Epoch: 6| Step: 3
Training loss: 2.1162185668945312
Validation loss: 2.0912970105806985

Epoch: 6| Step: 4
Training loss: 1.8553262948989868
Validation loss: 2.0785372654596963

Epoch: 6| Step: 5
Training loss: 1.5803377628326416
Validation loss: 2.0836320320765176

Epoch: 6| Step: 6
Training loss: 2.2200918197631836
Validation loss: 2.0820256074269614

Epoch: 6| Step: 7
Training loss: 1.878190517425537
Validation loss: 2.086703439553579

Epoch: 6| Step: 8
Training loss: 2.8136422634124756
Validation loss: 2.0931278467178345

Epoch: 6| Step: 9
Training loss: 1.8313990831375122
Validation loss: 2.0961227416992188

Epoch: 6| Step: 10
Training loss: 1.692882776260376
Validation loss: 2.0980916817982993

Epoch: 6| Step: 11
Training loss: 1.4506607055664062
Validation loss: 2.1050583918889365

Epoch: 6| Step: 12
Training loss: 2.024348258972168
Validation loss: 2.0949111382166543

Epoch: 6| Step: 13
Training loss: 2.254976749420166
Validation loss: 2.100760817527771

Epoch: 162| Step: 0
Training loss: 2.295879364013672
Validation loss: 2.0998074412345886

Epoch: 6| Step: 1
Training loss: 2.0128066539764404
Validation loss: 2.1016177932421365

Epoch: 6| Step: 2
Training loss: 2.3520288467407227
Validation loss: 2.093829890092214

Epoch: 6| Step: 3
Training loss: 2.1266558170318604
Validation loss: 2.1011992692947388

Epoch: 6| Step: 4
Training loss: 1.8225122690200806
Validation loss: 2.105881989002228

Epoch: 6| Step: 5
Training loss: 1.323875904083252
Validation loss: 2.1035254200299582

Epoch: 6| Step: 6
Training loss: 2.4192051887512207
Validation loss: 2.098968982696533

Epoch: 6| Step: 7
Training loss: 1.5048351287841797
Validation loss: 2.112983504931132

Epoch: 6| Step: 8
Training loss: 2.280165195465088
Validation loss: 2.12166690826416

Epoch: 6| Step: 9
Training loss: 1.961519718170166
Validation loss: 2.123025437196096

Epoch: 6| Step: 10
Training loss: 1.8498965501785278
Validation loss: 2.122842331727346

Epoch: 6| Step: 11
Training loss: 2.596010446548462
Validation loss: 2.124590277671814

Epoch: 6| Step: 12
Training loss: 1.5303497314453125
Validation loss: 2.124561528364817

Epoch: 6| Step: 13
Training loss: 1.4554541110992432
Validation loss: 2.1344271302223206

Epoch: 163| Step: 0
Training loss: 2.654879093170166
Validation loss: 2.1354538997014365

Epoch: 6| Step: 1
Training loss: 1.9121992588043213
Validation loss: 2.132565955320994

Epoch: 6| Step: 2
Training loss: 1.8909969329833984
Validation loss: 2.1237135926882424

Epoch: 6| Step: 3
Training loss: 1.9960079193115234
Validation loss: 2.1200223763783774

Epoch: 6| Step: 4
Training loss: 1.8537899255752563
Validation loss: 2.1240139404932656

Epoch: 6| Step: 5
Training loss: 1.5850615501403809
Validation loss: 2.116762359937032

Epoch: 6| Step: 6
Training loss: 1.3170329332351685
Validation loss: 2.1199973622957864

Epoch: 6| Step: 7
Training loss: 1.479500651359558
Validation loss: 2.1173014442125955

Epoch: 6| Step: 8
Training loss: 2.3728208541870117
Validation loss: 2.1243698596954346

Epoch: 6| Step: 9
Training loss: 1.918709635734558
Validation loss: 2.1299752593040466

Epoch: 6| Step: 10
Training loss: 1.9487836360931396
Validation loss: 2.13441530863444

Epoch: 6| Step: 11
Training loss: 2.1557648181915283
Validation loss: 2.1196032961209617

Epoch: 6| Step: 12
Training loss: 2.3289756774902344
Validation loss: 2.108587622642517

Epoch: 6| Step: 13
Training loss: 1.891730785369873
Validation loss: 2.1222689946492515

Epoch: 164| Step: 0
Training loss: 1.8061814308166504
Validation loss: 2.116127928098043

Epoch: 6| Step: 1
Training loss: 1.2845265865325928
Validation loss: 2.112712542215983

Epoch: 6| Step: 2
Training loss: 1.4105114936828613
Validation loss: 2.117765784263611

Epoch: 6| Step: 3
Training loss: 1.9593400955200195
Validation loss: 2.0897581974665322

Epoch: 6| Step: 4
Training loss: 2.0481009483337402
Validation loss: 2.084412415822347

Epoch: 6| Step: 5
Training loss: 2.491008996963501
Validation loss: 2.076501448949178

Epoch: 6| Step: 6
Training loss: 2.132892608642578
Validation loss: 2.0765172839164734

Epoch: 6| Step: 7
Training loss: 1.6411731243133545
Validation loss: 2.0737516482671103

Epoch: 6| Step: 8
Training loss: 2.0024161338806152
Validation loss: 2.081153710683187

Epoch: 6| Step: 9
Training loss: 2.7813868522644043
Validation loss: 2.0759796301523843

Epoch: 6| Step: 10
Training loss: 1.6181941032409668
Validation loss: 2.0751986503601074

Epoch: 6| Step: 11
Training loss: 1.9106824398040771
Validation loss: 2.07598215341568

Epoch: 6| Step: 12
Training loss: 2.6382384300231934
Validation loss: 2.077233831087748

Epoch: 6| Step: 13
Training loss: 2.110367774963379
Validation loss: 2.0792934695879617

Epoch: 165| Step: 0
Training loss: 1.6472012996673584
Validation loss: 2.0845980644226074

Epoch: 6| Step: 1
Training loss: 1.6983294486999512
Validation loss: 2.094703257083893

Epoch: 6| Step: 2
Training loss: 1.3537256717681885
Validation loss: 2.0980971654256186

Epoch: 6| Step: 3
Training loss: 2.4168312549591064
Validation loss: 2.112477461496989

Epoch: 6| Step: 4
Training loss: 2.3110828399658203
Validation loss: 2.1157339413960776

Epoch: 6| Step: 5
Training loss: 1.6915595531463623
Validation loss: 2.1158464352289834

Epoch: 6| Step: 6
Training loss: 2.5697238445281982
Validation loss: 2.1223756472269693

Epoch: 6| Step: 7
Training loss: 2.339717149734497
Validation loss: 2.1250775257746377

Epoch: 6| Step: 8
Training loss: 2.4291226863861084
Validation loss: 2.1194767554601035

Epoch: 6| Step: 9
Training loss: 2.1024463176727295
Validation loss: 2.1318212350209556

Epoch: 6| Step: 10
Training loss: 1.4917724132537842
Validation loss: 2.135243852933248

Epoch: 6| Step: 11
Training loss: 2.3923768997192383
Validation loss: 2.118363360563914

Epoch: 6| Step: 12
Training loss: 1.5879361629486084
Validation loss: 2.130634864171346

Epoch: 6| Step: 13
Training loss: 1.325919270515442
Validation loss: 2.11690084139506

Epoch: 166| Step: 0
Training loss: 1.7958571910858154
Validation loss: 2.1125345627466836

Epoch: 6| Step: 1
Training loss: 2.103330612182617
Validation loss: 2.1005160808563232

Epoch: 6| Step: 2
Training loss: 2.1482582092285156
Validation loss: 2.1146108309427896

Epoch: 6| Step: 3
Training loss: 1.662493348121643
Validation loss: 2.0985324382781982

Epoch: 6| Step: 4
Training loss: 2.613286018371582
Validation loss: 2.087433099746704

Epoch: 6| Step: 5
Training loss: 2.412527322769165
Validation loss: 2.0944596926371255

Epoch: 6| Step: 6
Training loss: 2.201150894165039
Validation loss: 2.093998908996582

Epoch: 6| Step: 7
Training loss: 2.165846586227417
Validation loss: 2.0922176241874695

Epoch: 6| Step: 8
Training loss: 1.6102231740951538
Validation loss: 2.0925333499908447

Epoch: 6| Step: 9
Training loss: 2.354444980621338
Validation loss: 2.08808167775472

Epoch: 6| Step: 10
Training loss: 2.117297887802124
Validation loss: 2.0968424677848816

Epoch: 6| Step: 11
Training loss: 1.672785758972168
Validation loss: 2.084891140460968

Epoch: 6| Step: 12
Training loss: 1.2096073627471924
Validation loss: 2.1104822556177774

Epoch: 6| Step: 13
Training loss: 1.5434794425964355
Validation loss: 2.1283554236094155

Epoch: 167| Step: 0
Training loss: 2.187802314758301
Validation loss: 2.121550500392914

Epoch: 6| Step: 1
Training loss: 1.6624603271484375
Validation loss: 2.121305247147878

Epoch: 6| Step: 2
Training loss: 2.6326777935028076
Validation loss: 2.1168092091878257

Epoch: 6| Step: 3
Training loss: 1.6639611721038818
Validation loss: 2.1237271626790366

Epoch: 6| Step: 4
Training loss: 1.8742177486419678
Validation loss: 2.1174976229667664

Epoch: 6| Step: 5
Training loss: 2.0205841064453125
Validation loss: 2.1169643799463906

Epoch: 6| Step: 6
Training loss: 2.135531425476074
Validation loss: 2.115324238936106

Epoch: 6| Step: 7
Training loss: 2.2282040119171143
Validation loss: 2.103610932826996

Epoch: 6| Step: 8
Training loss: 1.7370126247406006
Validation loss: 2.1021403670310974

Epoch: 6| Step: 9
Training loss: 1.635191559791565
Validation loss: 2.094660302003225

Epoch: 6| Step: 10
Training loss: 1.8921220302581787
Validation loss: 2.0958445072174072

Epoch: 6| Step: 11
Training loss: 2.121331214904785
Validation loss: 2.094303528467814

Epoch: 6| Step: 12
Training loss: 1.8232594728469849
Validation loss: 2.0904375116030374

Epoch: 6| Step: 13
Training loss: 2.1375339031219482
Validation loss: 2.092114528020223

Epoch: 168| Step: 0
Training loss: 2.263643741607666
Validation loss: 2.0887285272280374

Epoch: 6| Step: 1
Training loss: 2.4082255363464355
Validation loss: 2.0846847097078958

Epoch: 6| Step: 2
Training loss: 1.4172205924987793
Validation loss: 2.0859563748041787

Epoch: 6| Step: 3
Training loss: 1.9555904865264893
Validation loss: 2.088013211886088

Epoch: 6| Step: 4
Training loss: 2.0799307823181152
Validation loss: 2.082433025042216

Epoch: 6| Step: 5
Training loss: 2.106672763824463
Validation loss: 2.0886512796084085

Epoch: 6| Step: 6
Training loss: 2.513174057006836
Validation loss: 2.079288343588511

Epoch: 6| Step: 7
Training loss: 1.8531585931777954
Validation loss: 2.0836384296417236

Epoch: 6| Step: 8
Training loss: 1.7209817171096802
Validation loss: 2.0914844274520874

Epoch: 6| Step: 9
Training loss: 1.4451420307159424
Validation loss: 2.0892639756202698

Epoch: 6| Step: 10
Training loss: 1.981242299079895
Validation loss: 2.0855195919672647

Epoch: 6| Step: 11
Training loss: 2.2706124782562256
Validation loss: 2.081492006778717

Epoch: 6| Step: 12
Training loss: 1.9226409196853638
Validation loss: 2.0907768607139587

Epoch: 6| Step: 13
Training loss: 2.4836177825927734
Validation loss: 2.1055469512939453

Epoch: 169| Step: 0
Training loss: 2.1396262645721436
Validation loss: 2.1209871967633567

Epoch: 6| Step: 1
Training loss: 1.8154898881912231
Validation loss: 2.134932597478231

Epoch: 6| Step: 2
Training loss: 2.3112688064575195
Validation loss: 2.134147564570109

Epoch: 6| Step: 3
Training loss: 2.1027727127075195
Validation loss: 2.1407839258511863

Epoch: 6| Step: 4
Training loss: 1.934686541557312
Validation loss: 2.143047253290812

Epoch: 6| Step: 5
Training loss: 1.7284302711486816
Validation loss: 2.1446160674095154

Epoch: 6| Step: 6
Training loss: 2.0945181846618652
Validation loss: 2.151376744111379

Epoch: 6| Step: 7
Training loss: 1.6855998039245605
Validation loss: 2.1593716541926065

Epoch: 6| Step: 8
Training loss: 2.1205215454101562
Validation loss: 2.1249550580978394

Epoch: 6| Step: 9
Training loss: 2.3146157264709473
Validation loss: 2.116343597571055

Epoch: 6| Step: 10
Training loss: 1.7783347368240356
Validation loss: 2.1017142136891684

Epoch: 6| Step: 11
Training loss: 1.9469587802886963
Validation loss: 2.1042111118634543

Epoch: 6| Step: 12
Training loss: 1.9677304029464722
Validation loss: 2.0931458870569863

Epoch: 6| Step: 13
Training loss: 1.940483570098877
Validation loss: 2.096288502216339

Epoch: 170| Step: 0
Training loss: 2.295419692993164
Validation loss: 2.0901279846827188

Epoch: 6| Step: 1
Training loss: 2.069676637649536
Validation loss: 2.1116286516189575

Epoch: 6| Step: 2
Training loss: 1.5782763957977295
Validation loss: 2.1066672007242837

Epoch: 6| Step: 3
Training loss: 1.9457803964614868
Validation loss: 2.1036475698153176

Epoch: 6| Step: 4
Training loss: 2.266263484954834
Validation loss: 2.1062030593554177

Epoch: 6| Step: 5
Training loss: 1.9675912857055664
Validation loss: 2.105088214079539

Epoch: 6| Step: 6
Training loss: 1.6730313301086426
Validation loss: 2.108769178390503

Epoch: 6| Step: 7
Training loss: 1.5425236225128174
Validation loss: 2.1186761061350503

Epoch: 6| Step: 8
Training loss: 2.0633482933044434
Validation loss: 2.1140318314234414

Epoch: 6| Step: 9
Training loss: 1.5609657764434814
Validation loss: 2.1082847515741983

Epoch: 6| Step: 10
Training loss: 1.6371303796768188
Validation loss: 2.114414950211843

Epoch: 6| Step: 11
Training loss: 1.5653742551803589
Validation loss: 2.111812392870585

Epoch: 6| Step: 12
Training loss: 2.338024139404297
Validation loss: 2.1083367069562278

Epoch: 6| Step: 13
Training loss: 2.7292919158935547
Validation loss: 2.102872689565023

Epoch: 171| Step: 0
Training loss: 1.683954119682312
Validation loss: 2.1071672240893045

Epoch: 6| Step: 1
Training loss: 1.9532455205917358
Validation loss: 2.1052820682525635

Epoch: 6| Step: 2
Training loss: 1.8461345434188843
Validation loss: 2.103812317053477

Epoch: 6| Step: 3
Training loss: 1.836611032485962
Validation loss: 2.094690680503845

Epoch: 6| Step: 4
Training loss: 2.40773344039917
Validation loss: 2.1064674655596414

Epoch: 6| Step: 5
Training loss: 1.421830415725708
Validation loss: 2.1016034285227456

Epoch: 6| Step: 6
Training loss: 2.1338517665863037
Validation loss: 2.1087661385536194

Epoch: 6| Step: 7
Training loss: 2.2551777362823486
Validation loss: 2.119569698969523

Epoch: 6| Step: 8
Training loss: 1.7680091857910156
Validation loss: 2.1165775855382285

Epoch: 6| Step: 9
Training loss: 2.030198335647583
Validation loss: 2.137257993221283

Epoch: 6| Step: 10
Training loss: 2.461134910583496
Validation loss: 2.142747441927592

Epoch: 6| Step: 11
Training loss: 1.816503643989563
Validation loss: 2.1590548555056253

Epoch: 6| Step: 12
Training loss: 2.1082072257995605
Validation loss: 2.137480676174164

Epoch: 6| Step: 13
Training loss: 1.596436619758606
Validation loss: 2.1417933901151023

Epoch: 172| Step: 0
Training loss: 1.453857183456421
Validation loss: 2.150889575481415

Epoch: 6| Step: 1
Training loss: 2.1367788314819336
Validation loss: 2.1386300722757974

Epoch: 6| Step: 2
Training loss: 2.2995378971099854
Validation loss: 2.127604901790619

Epoch: 6| Step: 3
Training loss: 1.9633458852767944
Validation loss: 2.137589772542318

Epoch: 6| Step: 4
Training loss: 1.9599905014038086
Validation loss: 2.1298178235689798

Epoch: 6| Step: 5
Training loss: 1.6394646167755127
Validation loss: 2.1179434061050415

Epoch: 6| Step: 6
Training loss: 2.0392489433288574
Validation loss: 2.103560149669647

Epoch: 6| Step: 7
Training loss: 1.6308848857879639
Validation loss: 2.105350116888682

Epoch: 6| Step: 8
Training loss: 1.7000213861465454
Validation loss: 2.1087448398272195

Epoch: 6| Step: 9
Training loss: 1.6120773553848267
Validation loss: 2.1034833788871765

Epoch: 6| Step: 10
Training loss: 1.9983328580856323
Validation loss: 2.1045780976613364

Epoch: 6| Step: 11
Training loss: 1.8855105638504028
Validation loss: 2.112927953402201

Epoch: 6| Step: 12
Training loss: 2.962524890899658
Validation loss: 2.1094771027565002

Epoch: 6| Step: 13
Training loss: 1.832517385482788
Validation loss: 2.1108274261156716

Epoch: 173| Step: 0
Training loss: 1.5624454021453857
Validation loss: 2.110357085863749

Epoch: 6| Step: 1
Training loss: 1.5490095615386963
Validation loss: 2.119075079758962

Epoch: 6| Step: 2
Training loss: 1.8561326265335083
Validation loss: 2.123586336771647

Epoch: 6| Step: 3
Training loss: 1.6261820793151855
Validation loss: 2.119566281636556

Epoch: 6| Step: 4
Training loss: 2.2205519676208496
Validation loss: 2.119467794895172

Epoch: 6| Step: 5
Training loss: 1.6124553680419922
Validation loss: 2.1252816120783486

Epoch: 6| Step: 6
Training loss: 2.051466464996338
Validation loss: 2.124936838944753

Epoch: 6| Step: 7
Training loss: 1.9406490325927734
Validation loss: 2.1232524514198303

Epoch: 6| Step: 8
Training loss: 2.019357919692993
Validation loss: 2.124322493871053

Epoch: 6| Step: 9
Training loss: 2.2634527683258057
Validation loss: 2.1305300196011863

Epoch: 6| Step: 10
Training loss: 1.6713941097259521
Validation loss: 2.1221949656804404

Epoch: 6| Step: 11
Training loss: 2.892530679702759
Validation loss: 2.1262944539388022

Epoch: 6| Step: 12
Training loss: 1.3592809438705444
Validation loss: 2.113183577855428

Epoch: 6| Step: 13
Training loss: 2.3852038383483887
Validation loss: 2.116575082143148

Epoch: 174| Step: 0
Training loss: 1.7306156158447266
Validation loss: 2.1270148158073425

Epoch: 6| Step: 1
Training loss: 2.654533624649048
Validation loss: 2.1098451018333435

Epoch: 6| Step: 2
Training loss: 1.4814808368682861
Validation loss: 2.0980745553970337

Epoch: 6| Step: 3
Training loss: 2.0198941230773926
Validation loss: 2.113371650377909

Epoch: 6| Step: 4
Training loss: 1.8305766582489014
Validation loss: 2.0986908674240112

Epoch: 6| Step: 5
Training loss: 2.040891647338867
Validation loss: 2.1047924757003784

Epoch: 6| Step: 6
Training loss: 1.920045256614685
Validation loss: 2.100309669971466

Epoch: 6| Step: 7
Training loss: 1.964350700378418
Validation loss: 2.0923207799593606

Epoch: 6| Step: 8
Training loss: 2.4492764472961426
Validation loss: 2.0901017983754477

Epoch: 6| Step: 9
Training loss: 1.8260761499404907
Validation loss: 2.093177874883016

Epoch: 6| Step: 10
Training loss: 1.3412525653839111
Validation loss: 2.094611426194509

Epoch: 6| Step: 11
Training loss: 1.9919370412826538
Validation loss: 2.0946943958600364

Epoch: 6| Step: 12
Training loss: 1.8539761304855347
Validation loss: 2.094317138195038

Epoch: 6| Step: 13
Training loss: 2.231431484222412
Validation loss: 2.085575262705485

Epoch: 175| Step: 0
Training loss: 1.4474880695343018
Validation loss: 2.084895888964335

Epoch: 6| Step: 1
Training loss: 1.931648850440979
Validation loss: 2.0916647911071777

Epoch: 6| Step: 2
Training loss: 2.1466526985168457
Validation loss: 2.098780373732249

Epoch: 6| Step: 3
Training loss: 1.6915158033370972
Validation loss: 2.0979467630386353

Epoch: 6| Step: 4
Training loss: 2.547715902328491
Validation loss: 2.0941722790400186

Epoch: 6| Step: 5
Training loss: 2.4724817276000977
Validation loss: 2.110517760117849

Epoch: 6| Step: 6
Training loss: 2.102897882461548
Validation loss: 2.0890027284622192

Epoch: 6| Step: 7
Training loss: 1.1444320678710938
Validation loss: 2.0944660107294717

Epoch: 6| Step: 8
Training loss: 1.60382878780365
Validation loss: 2.0923086404800415

Epoch: 6| Step: 9
Training loss: 2.2456207275390625
Validation loss: 2.094850321610769

Epoch: 6| Step: 10
Training loss: 1.952651023864746
Validation loss: 2.0903343160947165

Epoch: 6| Step: 11
Training loss: 2.2572784423828125
Validation loss: 2.112028976281484

Epoch: 6| Step: 12
Training loss: 1.7527458667755127
Validation loss: 2.103646755218506

Epoch: 6| Step: 13
Training loss: 1.881276249885559
Validation loss: 2.1064921220143638

Epoch: 176| Step: 0
Training loss: 1.9544011354446411
Validation loss: 2.106322149435679

Epoch: 6| Step: 1
Training loss: 1.6131064891815186
Validation loss: 2.1268630027770996

Epoch: 6| Step: 2
Training loss: 2.623964786529541
Validation loss: 2.122165560722351

Epoch: 6| Step: 3
Training loss: 2.2198636531829834
Validation loss: 2.130397001902262

Epoch: 6| Step: 4
Training loss: 2.0687437057495117
Validation loss: 2.1123406887054443

Epoch: 6| Step: 5
Training loss: 2.176119804382324
Validation loss: 2.1338538328806558

Epoch: 6| Step: 6
Training loss: 1.2051395177841187
Validation loss: 2.1237419843673706

Epoch: 6| Step: 7
Training loss: 2.0761799812316895
Validation loss: 2.1270593802134194

Epoch: 6| Step: 8
Training loss: 1.707966685295105
Validation loss: 2.1102853417396545

Epoch: 6| Step: 9
Training loss: 1.6939423084259033
Validation loss: 2.126143137613932

Epoch: 6| Step: 10
Training loss: 2.341599702835083
Validation loss: 2.1304052670796714

Epoch: 6| Step: 11
Training loss: 2.0741007328033447
Validation loss: 2.121081074078878

Epoch: 6| Step: 12
Training loss: 1.8320116996765137
Validation loss: 2.108183761437734

Epoch: 6| Step: 13
Training loss: 1.4489943981170654
Validation loss: 2.1086416443188987

Epoch: 177| Step: 0
Training loss: 2.436938762664795
Validation loss: 2.1025416056315103

Epoch: 6| Step: 1
Training loss: 1.7344502210617065
Validation loss: 2.102147360642751

Epoch: 6| Step: 2
Training loss: 2.1845836639404297
Validation loss: 2.1041682163874307

Epoch: 6| Step: 3
Training loss: 1.7261642217636108
Validation loss: 2.1004494031270347

Epoch: 6| Step: 4
Training loss: 2.197746753692627
Validation loss: 2.1030980547269187

Epoch: 6| Step: 5
Training loss: 2.1811420917510986
Validation loss: 2.107148587703705

Epoch: 6| Step: 6
Training loss: 1.8655369281768799
Validation loss: 2.1175820430119834

Epoch: 6| Step: 7
Training loss: 1.9026226997375488
Validation loss: 2.1083592971165976

Epoch: 6| Step: 8
Training loss: 2.2448391914367676
Validation loss: 2.1288338899612427

Epoch: 6| Step: 9
Training loss: 2.018646240234375
Validation loss: 2.117160896460215

Epoch: 6| Step: 10
Training loss: 2.1895875930786133
Validation loss: 2.125732163588206

Epoch: 6| Step: 11
Training loss: 1.443437933921814
Validation loss: 2.135084629058838

Epoch: 6| Step: 12
Training loss: 1.5661869049072266
Validation loss: 2.1340429186820984

Epoch: 6| Step: 13
Training loss: 1.2906948328018188
Validation loss: 2.1214065551757812

Epoch: 178| Step: 0
Training loss: 2.2722220420837402
Validation loss: 2.138816992441813

Epoch: 6| Step: 1
Training loss: 1.3534924983978271
Validation loss: 2.122659206390381

Epoch: 6| Step: 2
Training loss: 2.180448532104492
Validation loss: 2.123081306616465

Epoch: 6| Step: 3
Training loss: 1.503983736038208
Validation loss: 2.12619411945343

Epoch: 6| Step: 4
Training loss: 2.565047025680542
Validation loss: 2.1164613167444863

Epoch: 6| Step: 5
Training loss: 1.4413516521453857
Validation loss: 2.1305615305900574

Epoch: 6| Step: 6
Training loss: 1.7816965579986572
Validation loss: 2.1322402556737265

Epoch: 6| Step: 7
Training loss: 1.8604459762573242
Validation loss: 2.125740567843119

Epoch: 6| Step: 8
Training loss: 1.7957582473754883
Validation loss: 2.1441248655319214

Epoch: 6| Step: 9
Training loss: 2.214214324951172
Validation loss: 2.1252611676851907

Epoch: 6| Step: 10
Training loss: 2.221621513366699
Validation loss: 2.131804943084717

Epoch: 6| Step: 11
Training loss: 1.7363356351852417
Validation loss: 2.1387007435162864

Epoch: 6| Step: 12
Training loss: 1.9321503639221191
Validation loss: 2.130184531211853

Epoch: 6| Step: 13
Training loss: 1.7803963422775269
Validation loss: 2.1434659163157144

Epoch: 179| Step: 0
Training loss: 2.17464017868042
Validation loss: 2.1343517899513245

Epoch: 6| Step: 1
Training loss: 2.1796112060546875
Validation loss: 2.1259015003840127

Epoch: 6| Step: 2
Training loss: 2.1471610069274902
Validation loss: 2.1440210342407227

Epoch: 6| Step: 3
Training loss: 2.6006429195404053
Validation loss: 2.136040528615316

Epoch: 6| Step: 4
Training loss: 1.458380937576294
Validation loss: 2.1332629124323526

Epoch: 6| Step: 5
Training loss: 1.7713395357131958
Validation loss: 2.125737984975179

Epoch: 6| Step: 6
Training loss: 1.6524975299835205
Validation loss: 2.125352660814921

Epoch: 6| Step: 7
Training loss: 1.8039841651916504
Validation loss: 2.124739110469818

Epoch: 6| Step: 8
Training loss: 1.620299220085144
Validation loss: 2.1313357949256897

Epoch: 6| Step: 9
Training loss: 1.797292709350586
Validation loss: 2.1304183999697366

Epoch: 6| Step: 10
Training loss: 1.6083571910858154
Validation loss: 2.125265598297119

Epoch: 6| Step: 11
Training loss: 2.2527875900268555
Validation loss: 2.126758615175883

Epoch: 6| Step: 12
Training loss: 1.8580646514892578
Validation loss: 2.123814324537913

Epoch: 6| Step: 13
Training loss: 2.251345634460449
Validation loss: 2.1214980085690818

Epoch: 180| Step: 0
Training loss: 1.950352668762207
Validation loss: 2.1366304556528726

Epoch: 6| Step: 1
Training loss: 1.7383897304534912
Validation loss: 2.1247435808181763

Epoch: 6| Step: 2
Training loss: 1.4215360879898071
Validation loss: 2.136208792527517

Epoch: 6| Step: 3
Training loss: 2.031188488006592
Validation loss: 2.122541149457296

Epoch: 6| Step: 4
Training loss: 2.103008985519409
Validation loss: 2.1270912289619446

Epoch: 6| Step: 5
Training loss: 1.526956558227539
Validation loss: 2.1349361538887024

Epoch: 6| Step: 6
Training loss: 1.588636040687561
Validation loss: 2.136125067869822

Epoch: 6| Step: 7
Training loss: 2.3586010932922363
Validation loss: 2.144980569680532

Epoch: 6| Step: 8
Training loss: 2.1927175521850586
Validation loss: 2.1454381545384726

Epoch: 6| Step: 9
Training loss: 1.8828332424163818
Validation loss: 2.1376869678497314

Epoch: 6| Step: 10
Training loss: 2.646554708480835
Validation loss: 2.1363232930501304

Epoch: 6| Step: 11
Training loss: 2.1680169105529785
Validation loss: 2.1129582722981772

Epoch: 6| Step: 12
Training loss: 1.7353096008300781
Validation loss: 2.107023517290751

Epoch: 6| Step: 13
Training loss: 1.5677229166030884
Validation loss: 2.1146658062934875

Epoch: 181| Step: 0
Training loss: 1.7149574756622314
Validation loss: 2.0978368322054544

Epoch: 6| Step: 1
Training loss: 1.8670237064361572
Validation loss: 2.086817999680837

Epoch: 6| Step: 2
Training loss: 2.1136505603790283
Validation loss: 2.091103116671244

Epoch: 6| Step: 3
Training loss: 1.546743392944336
Validation loss: 2.095707575480143

Epoch: 6| Step: 4
Training loss: 1.9644403457641602
Validation loss: 2.1026041507720947

Epoch: 6| Step: 5
Training loss: 2.3973584175109863
Validation loss: 2.1022732655207315

Epoch: 6| Step: 6
Training loss: 2.268393039703369
Validation loss: 2.095523794492086

Epoch: 6| Step: 7
Training loss: 1.2890880107879639
Validation loss: 2.1119295358657837

Epoch: 6| Step: 8
Training loss: 2.211473226547241
Validation loss: 2.125210225582123

Epoch: 6| Step: 9
Training loss: 1.8353031873703003
Validation loss: 2.1228460470835366

Epoch: 6| Step: 10
Training loss: 1.603857398033142
Validation loss: 2.117875814437866

Epoch: 6| Step: 11
Training loss: 1.7671449184417725
Validation loss: 2.10965104897817

Epoch: 6| Step: 12
Training loss: 2.1934921741485596
Validation loss: 2.1184372901916504

Epoch: 6| Step: 13
Training loss: 2.2818620204925537
Validation loss: 2.132903039455414

Epoch: 182| Step: 0
Training loss: 2.213423728942871
Validation loss: 2.137558023134867

Epoch: 6| Step: 1
Training loss: 1.678726077079773
Validation loss: 2.122773071130117

Epoch: 6| Step: 2
Training loss: 1.7825891971588135
Validation loss: 2.15239946047465

Epoch: 6| Step: 3
Training loss: 2.048292636871338
Validation loss: 2.139160950978597

Epoch: 6| Step: 4
Training loss: 1.8070836067199707
Validation loss: 2.1465495824813843

Epoch: 6| Step: 5
Training loss: 2.314192533493042
Validation loss: 2.165147582689921

Epoch: 6| Step: 6
Training loss: 1.4375884532928467
Validation loss: 2.1571679512659707

Epoch: 6| Step: 7
Training loss: 1.702263355255127
Validation loss: 2.151757001876831

Epoch: 6| Step: 8
Training loss: 2.13601016998291
Validation loss: 2.1534449259440103

Epoch: 6| Step: 9
Training loss: 1.8060567378997803
Validation loss: 2.1622970501581826

Epoch: 6| Step: 10
Training loss: 1.6868219375610352
Validation loss: 2.140032688776652

Epoch: 6| Step: 11
Training loss: 1.8031165599822998
Validation loss: 2.148981591065725

Epoch: 6| Step: 12
Training loss: 2.2358574867248535
Validation loss: 2.1462385654449463

Epoch: 6| Step: 13
Training loss: 1.9215679168701172
Validation loss: 2.12412166595459

Epoch: 183| Step: 0
Training loss: 1.644866943359375
Validation loss: 2.1244685649871826

Epoch: 6| Step: 1
Training loss: 1.7312090396881104
Validation loss: 2.122113347053528

Epoch: 6| Step: 2
Training loss: 1.586016058921814
Validation loss: 2.106704612572988

Epoch: 6| Step: 3
Training loss: 2.6894848346710205
Validation loss: 2.1199211279551187

Epoch: 6| Step: 4
Training loss: 1.4248645305633545
Validation loss: 2.1218127806981406

Epoch: 6| Step: 5
Training loss: 1.6450694799423218
Validation loss: 2.1055309772491455

Epoch: 6| Step: 6
Training loss: 1.7917635440826416
Validation loss: 2.114008049170176

Epoch: 6| Step: 7
Training loss: 2.033153533935547
Validation loss: 2.1341572999954224

Epoch: 6| Step: 8
Training loss: 1.5220122337341309
Validation loss: 2.1267146666844687

Epoch: 6| Step: 9
Training loss: 1.9941463470458984
Validation loss: 2.130947748819987

Epoch: 6| Step: 10
Training loss: 2.609753131866455
Validation loss: 2.1338234146436057

Epoch: 6| Step: 11
Training loss: 2.389942169189453
Validation loss: 2.1341492732365928

Epoch: 6| Step: 12
Training loss: 1.6705114841461182
Validation loss: 2.158842901388804

Epoch: 6| Step: 13
Training loss: 2.1843717098236084
Validation loss: 2.1552220781644187

Epoch: 184| Step: 0
Training loss: 2.6365530490875244
Validation loss: 2.151938319206238

Epoch: 6| Step: 1
Training loss: 1.922613501548767
Validation loss: 2.1560116012891135

Epoch: 6| Step: 2
Training loss: 1.6149709224700928
Validation loss: 2.1399479707082114

Epoch: 6| Step: 3
Training loss: 2.5345492362976074
Validation loss: 2.1419946551322937

Epoch: 6| Step: 4
Training loss: 1.600053071975708
Validation loss: 2.1347938776016235

Epoch: 6| Step: 5
Training loss: 2.3397819995880127
Validation loss: 2.1290198961893716

Epoch: 6| Step: 6
Training loss: 2.250337839126587
Validation loss: 2.1254323720932007

Epoch: 6| Step: 7
Training loss: 1.4212820529937744
Validation loss: 2.123920758565267

Epoch: 6| Step: 8
Training loss: 1.7189923524856567
Validation loss: 2.124133070309957

Epoch: 6| Step: 9
Training loss: 2.2259669303894043
Validation loss: 2.119949479897817

Epoch: 6| Step: 10
Training loss: 1.6351455450057983
Validation loss: 2.11563632885615

Epoch: 6| Step: 11
Training loss: 1.6177974939346313
Validation loss: 2.1273751060167947

Epoch: 6| Step: 12
Training loss: 1.8386435508728027
Validation loss: 2.1292298634847007

Epoch: 6| Step: 13
Training loss: 1.303952693939209
Validation loss: 2.138077139854431

Epoch: 185| Step: 0
Training loss: 1.979882001876831
Validation loss: 2.1312818924585977

Epoch: 6| Step: 1
Training loss: 1.4990090131759644
Validation loss: 2.1451286673545837

Epoch: 6| Step: 2
Training loss: 1.4518197774887085
Validation loss: 2.164287726084391

Epoch: 6| Step: 3
Training loss: 2.0000181198120117
Validation loss: 2.1478698452313743

Epoch: 6| Step: 4
Training loss: 1.8142642974853516
Validation loss: 2.139439046382904

Epoch: 6| Step: 5
Training loss: 2.1731183528900146
Validation loss: 2.1384589076042175

Epoch: 6| Step: 6
Training loss: 1.839577078819275
Validation loss: 2.1337841749191284

Epoch: 6| Step: 7
Training loss: 1.6952431201934814
Validation loss: 2.134114762147268

Epoch: 6| Step: 8
Training loss: 1.944305658340454
Validation loss: 2.1238775849342346

Epoch: 6| Step: 9
Training loss: 2.4177143573760986
Validation loss: 2.1407361229260764

Epoch: 6| Step: 10
Training loss: 2.4945614337921143
Validation loss: 2.135730564594269

Epoch: 6| Step: 11
Training loss: 1.5192887783050537
Validation loss: 2.1308299899101257

Epoch: 6| Step: 12
Training loss: 2.1571640968322754
Validation loss: 2.1315223773320517

Epoch: 6| Step: 13
Training loss: 1.8185374736785889
Validation loss: 2.135972003142039

Epoch: 186| Step: 0
Training loss: 1.4833073616027832
Validation loss: 2.1431254943211875

Epoch: 6| Step: 1
Training loss: 2.264206886291504
Validation loss: 2.1407418251037598

Epoch: 6| Step: 2
Training loss: 1.6199051141738892
Validation loss: 2.1319435834884644

Epoch: 6| Step: 3
Training loss: 2.0235512256622314
Validation loss: 2.1454296310742698

Epoch: 6| Step: 4
Training loss: 1.5065373182296753
Validation loss: 2.1367027759552

Epoch: 6| Step: 5
Training loss: 1.730373501777649
Validation loss: 2.135366459687551

Epoch: 6| Step: 6
Training loss: 1.5060365200042725
Validation loss: 2.137075444062551

Epoch: 6| Step: 7
Training loss: 1.5570662021636963
Validation loss: 2.133923053741455

Epoch: 6| Step: 8
Training loss: 1.8222579956054688
Validation loss: 2.1389583349227905

Epoch: 6| Step: 9
Training loss: 2.6119887828826904
Validation loss: 2.116627812385559

Epoch: 6| Step: 10
Training loss: 2.034186601638794
Validation loss: 2.1317752997080484

Epoch: 6| Step: 11
Training loss: 2.102308750152588
Validation loss: 2.134268124898275

Epoch: 6| Step: 12
Training loss: 2.047215461730957
Validation loss: 2.12529585758845

Epoch: 6| Step: 13
Training loss: 2.229971408843994
Validation loss: 2.124541779359182

Epoch: 187| Step: 0
Training loss: 1.4603550434112549
Validation loss: 2.114583412806193

Epoch: 6| Step: 1
Training loss: 1.882630705833435
Validation loss: 2.1232427954673767

Epoch: 6| Step: 2
Training loss: 1.5815362930297852
Validation loss: 2.1222983797391257

Epoch: 6| Step: 3
Training loss: 1.2508187294006348
Validation loss: 2.1208507418632507

Epoch: 6| Step: 4
Training loss: 1.8667850494384766
Validation loss: 2.1166712244351706

Epoch: 6| Step: 5
Training loss: 2.738740921020508
Validation loss: 2.126133918762207

Epoch: 6| Step: 6
Training loss: 1.871071219444275
Validation loss: 2.132520238558451

Epoch: 6| Step: 7
Training loss: 1.9843080043792725
Validation loss: 2.1146438121795654

Epoch: 6| Step: 8
Training loss: 2.1852989196777344
Validation loss: 2.1329505244890847

Epoch: 6| Step: 9
Training loss: 1.6293635368347168
Validation loss: 2.1253987749417624

Epoch: 6| Step: 10
Training loss: 1.7514511346817017
Validation loss: 2.133798817793528

Epoch: 6| Step: 11
Training loss: 2.0984609127044678
Validation loss: 2.153041044871012

Epoch: 6| Step: 12
Training loss: 2.367772102355957
Validation loss: 2.1487349470456443

Epoch: 6| Step: 13
Training loss: 1.7620909214019775
Validation loss: 2.1574427485466003

Epoch: 188| Step: 0
Training loss: 1.6975398063659668
Validation loss: 2.143815040588379

Epoch: 6| Step: 1
Training loss: 1.6187925338745117
Validation loss: 2.1522995034853616

Epoch: 6| Step: 2
Training loss: 2.017749071121216
Validation loss: 2.162936488787333

Epoch: 6| Step: 3
Training loss: 1.296708106994629
Validation loss: 2.1588896115620932

Epoch: 6| Step: 4
Training loss: 1.9043173789978027
Validation loss: 2.163651943206787

Epoch: 6| Step: 5
Training loss: 1.3753750324249268
Validation loss: 2.1404267152150473

Epoch: 6| Step: 6
Training loss: 1.500985860824585
Validation loss: 2.148479084173838

Epoch: 6| Step: 7
Training loss: 2.3039188385009766
Validation loss: 2.14252640803655

Epoch: 6| Step: 8
Training loss: 2.4105887413024902
Validation loss: 2.1227048436800637

Epoch: 6| Step: 9
Training loss: 2.248213768005371
Validation loss: 2.128658413887024

Epoch: 6| Step: 10
Training loss: 1.3620065450668335
Validation loss: 2.1181531151135764

Epoch: 6| Step: 11
Training loss: 1.760631799697876
Validation loss: 2.1105530858039856

Epoch: 6| Step: 12
Training loss: 2.447671890258789
Validation loss: 2.13222603003184

Epoch: 6| Step: 13
Training loss: 2.3719613552093506
Validation loss: 2.1311065753300986

Epoch: 189| Step: 0
Training loss: 2.0723414421081543
Validation loss: 2.1400365829467773

Epoch: 6| Step: 1
Training loss: 2.297837972640991
Validation loss: 2.1336036920547485

Epoch: 6| Step: 2
Training loss: 2.0897693634033203
Validation loss: 2.1348493297894797

Epoch: 6| Step: 3
Training loss: 2.143216848373413
Validation loss: 2.132190386454264

Epoch: 6| Step: 4
Training loss: 1.5335999727249146
Validation loss: 2.1495368282000222

Epoch: 6| Step: 5
Training loss: 1.3944947719573975
Validation loss: 2.13259885708491

Epoch: 6| Step: 6
Training loss: 1.899170160293579
Validation loss: 2.134154657522837

Epoch: 6| Step: 7
Training loss: 2.0812830924987793
Validation loss: 2.1277876496315002

Epoch: 6| Step: 8
Training loss: 1.8653355836868286
Validation loss: 2.1242304841677346

Epoch: 6| Step: 9
Training loss: 1.6766486167907715
Validation loss: 2.1372342507044473

Epoch: 6| Step: 10
Training loss: 1.5438964366912842
Validation loss: 2.130120555559794

Epoch: 6| Step: 11
Training loss: 2.2167179584503174
Validation loss: 2.1315415501594543

Epoch: 6| Step: 12
Training loss: 1.7596831321716309
Validation loss: 2.12623397509257

Epoch: 6| Step: 13
Training loss: 1.8941622972488403
Validation loss: 2.152086317539215

Epoch: 190| Step: 0
Training loss: 1.7833775281906128
Validation loss: 2.1446593205134072

Epoch: 6| Step: 1
Training loss: 2.0017881393432617
Validation loss: 2.1411827007929483

Epoch: 6| Step: 2
Training loss: 1.4080119132995605
Validation loss: 2.1419791181882224

Epoch: 6| Step: 3
Training loss: 1.5997624397277832
Validation loss: 2.1326946218808494

Epoch: 6| Step: 4
Training loss: 1.3909611701965332
Validation loss: 2.140900135040283

Epoch: 6| Step: 5
Training loss: 1.890913724899292
Validation loss: 2.1228513518969216

Epoch: 6| Step: 6
Training loss: 2.2461962699890137
Validation loss: 2.126589814821879

Epoch: 6| Step: 7
Training loss: 2.1587696075439453
Validation loss: 2.13143781820933

Epoch: 6| Step: 8
Training loss: 1.9621374607086182
Validation loss: 2.1510730385780334

Epoch: 6| Step: 9
Training loss: 1.72491455078125
Validation loss: 2.1383994420369468

Epoch: 6| Step: 10
Training loss: 2.2259740829467773
Validation loss: 2.1379208167394004

Epoch: 6| Step: 11
Training loss: 1.704361915588379
Validation loss: 2.13945202032725

Epoch: 6| Step: 12
Training loss: 2.5674214363098145
Validation loss: 2.124575595060984

Epoch: 6| Step: 13
Training loss: 1.6981844902038574
Validation loss: 2.1335752606391907

Epoch: 191| Step: 0
Training loss: 1.1313652992248535
Validation loss: 2.1223695079485574

Epoch: 6| Step: 1
Training loss: 1.9920378923416138
Validation loss: 2.1290754477183023

Epoch: 6| Step: 2
Training loss: 1.5582373142242432
Validation loss: 2.1297504901885986

Epoch: 6| Step: 3
Training loss: 2.1397180557250977
Validation loss: 2.118696689605713

Epoch: 6| Step: 4
Training loss: 1.9697275161743164
Validation loss: 2.1064128081003823

Epoch: 6| Step: 5
Training loss: 1.953275442123413
Validation loss: 2.1089510520299277

Epoch: 6| Step: 6
Training loss: 2.1445565223693848
Validation loss: 2.108571251233419

Epoch: 6| Step: 7
Training loss: 2.452143669128418
Validation loss: 2.1185250083605447

Epoch: 6| Step: 8
Training loss: 2.3263654708862305
Validation loss: 2.1198466420173645

Epoch: 6| Step: 9
Training loss: 1.6230627298355103
Validation loss: 2.117466231187185

Epoch: 6| Step: 10
Training loss: 1.6647257804870605
Validation loss: 2.1245910127957663

Epoch: 6| Step: 11
Training loss: 1.7338736057281494
Validation loss: 2.1287454764048257

Epoch: 6| Step: 12
Training loss: 1.668163537979126
Validation loss: 2.1369502544403076

Epoch: 6| Step: 13
Training loss: 2.265256881713867
Validation loss: 2.147968808809916

Epoch: 192| Step: 0
Training loss: 2.0162270069122314
Validation loss: 2.135270138581594

Epoch: 6| Step: 1
Training loss: 2.076296806335449
Validation loss: 2.1513881285985312

Epoch: 6| Step: 2
Training loss: 1.3708540201187134
Validation loss: 2.1432839830716452

Epoch: 6| Step: 3
Training loss: 1.7389881610870361
Validation loss: 2.1640238563219705

Epoch: 6| Step: 4
Training loss: 1.6652121543884277
Validation loss: 2.1587273677190146

Epoch: 6| Step: 5
Training loss: 2.849245548248291
Validation loss: 2.1602911949157715

Epoch: 6| Step: 6
Training loss: 1.4452449083328247
Validation loss: 2.147973815600077

Epoch: 6| Step: 7
Training loss: 2.2537546157836914
Validation loss: 2.146607001622518

Epoch: 6| Step: 8
Training loss: 1.676605224609375
Validation loss: 2.149125317732493

Epoch: 6| Step: 9
Training loss: 1.6435081958770752
Validation loss: 2.13516628742218

Epoch: 6| Step: 10
Training loss: 1.860382080078125
Validation loss: 2.1377726793289185

Epoch: 6| Step: 11
Training loss: 2.2596142292022705
Validation loss: 2.138756493727366

Epoch: 6| Step: 12
Training loss: 1.8522162437438965
Validation loss: 2.1433842380841575

Epoch: 6| Step: 13
Training loss: 1.7740788459777832
Validation loss: 2.1349376440048218

Epoch: 193| Step: 0
Training loss: 1.9884432554244995
Validation loss: 2.1503235499064126

Epoch: 6| Step: 1
Training loss: 2.2499399185180664
Validation loss: 2.1490013798077903

Epoch: 6| Step: 2
Training loss: 1.8656105995178223
Validation loss: 2.1790119210879006

Epoch: 6| Step: 3
Training loss: 1.6730867624282837
Validation loss: 2.1593820254007974

Epoch: 6| Step: 4
Training loss: 2.1582939624786377
Validation loss: 2.154116948445638

Epoch: 6| Step: 5
Training loss: 2.5786261558532715
Validation loss: 2.1634406248728433

Epoch: 6| Step: 6
Training loss: 2.4894042015075684
Validation loss: 2.1520058314005532

Epoch: 6| Step: 7
Training loss: 1.4693772792816162
Validation loss: 2.165625015894572

Epoch: 6| Step: 8
Training loss: 1.1890742778778076
Validation loss: 2.159798502922058

Epoch: 6| Step: 9
Training loss: 1.5477544069290161
Validation loss: 2.1675248940785727

Epoch: 6| Step: 10
Training loss: 1.4735764265060425
Validation loss: 2.1553619702657065

Epoch: 6| Step: 11
Training loss: 1.8126806020736694
Validation loss: 2.14285417397817

Epoch: 6| Step: 12
Training loss: 2.2647509574890137
Validation loss: 2.1426891088485718

Epoch: 6| Step: 13
Training loss: 1.4559149742126465
Validation loss: 2.1485881010691323

Epoch: 194| Step: 0
Training loss: 1.6296981573104858
Validation loss: 2.1279494563738504

Epoch: 6| Step: 1
Training loss: 2.048140525817871
Validation loss: 2.128683547178904

Epoch: 6| Step: 2
Training loss: 2.1003060340881348
Validation loss: 2.1258318225542703

Epoch: 6| Step: 3
Training loss: 2.2387523651123047
Validation loss: 2.1342171827952066

Epoch: 6| Step: 4
Training loss: 1.8403370380401611
Validation loss: 2.1482199231783548

Epoch: 6| Step: 5
Training loss: 1.5861036777496338
Validation loss: 2.119769016901652

Epoch: 6| Step: 6
Training loss: 2.039773941040039
Validation loss: 2.12260909875234

Epoch: 6| Step: 7
Training loss: 1.8316787481307983
Validation loss: 2.132537543773651

Epoch: 6| Step: 8
Training loss: 1.7011308670043945
Validation loss: 2.127442717552185

Epoch: 6| Step: 9
Training loss: 1.8321038484573364
Validation loss: 2.1234184106191

Epoch: 6| Step: 10
Training loss: 1.4372345209121704
Validation loss: 2.1318233807881675

Epoch: 6| Step: 11
Training loss: 2.63261079788208
Validation loss: 2.1403417587280273

Epoch: 6| Step: 12
Training loss: 1.8372249603271484
Validation loss: 2.1382218400637307

Epoch: 6| Step: 13
Training loss: 1.476820707321167
Validation loss: 2.147557179133097

Epoch: 195| Step: 0
Training loss: 1.7017247676849365
Validation loss: 2.1607141494750977

Epoch: 6| Step: 1
Training loss: 2.2061076164245605
Validation loss: 2.1454047759373984

Epoch: 6| Step: 2
Training loss: 1.2887802124023438
Validation loss: 2.1485437552134194

Epoch: 6| Step: 3
Training loss: 1.5490267276763916
Validation loss: 2.1453764041264853

Epoch: 6| Step: 4
Training loss: 1.784287452697754
Validation loss: 2.141324778397878

Epoch: 6| Step: 5
Training loss: 2.6751649379730225
Validation loss: 2.135832190513611

Epoch: 6| Step: 6
Training loss: 1.756299614906311
Validation loss: 2.147641042868296

Epoch: 6| Step: 7
Training loss: 1.962277889251709
Validation loss: 2.133446435133616

Epoch: 6| Step: 8
Training loss: 2.18294620513916
Validation loss: 2.131732722123464

Epoch: 6| Step: 9
Training loss: 1.9534515142440796
Validation loss: 2.1370543440183005

Epoch: 6| Step: 10
Training loss: 1.2516145706176758
Validation loss: 2.13551656405131

Epoch: 6| Step: 11
Training loss: 2.309401035308838
Validation loss: 2.1258458892504373

Epoch: 6| Step: 12
Training loss: 1.9385648965835571
Validation loss: 2.1339471340179443

Epoch: 6| Step: 13
Training loss: 1.6812245845794678
Validation loss: 2.130594631036123

Epoch: 196| Step: 0
Training loss: 1.4242520332336426
Validation loss: 2.1274383465449014

Epoch: 6| Step: 1
Training loss: 1.8575528860092163
Validation loss: 2.1424594720204673

Epoch: 6| Step: 2
Training loss: 1.67988121509552
Validation loss: 2.1283127069473267

Epoch: 6| Step: 3
Training loss: 1.5203897953033447
Validation loss: 2.1658116976420083

Epoch: 6| Step: 4
Training loss: 2.260432720184326
Validation loss: 2.150879442691803

Epoch: 6| Step: 5
Training loss: 2.047912836074829
Validation loss: 2.1578410267829895

Epoch: 6| Step: 6
Training loss: 1.9406204223632812
Validation loss: 2.1606390674908957

Epoch: 6| Step: 7
Training loss: 1.4833120107650757
Validation loss: 2.164210081100464

Epoch: 6| Step: 8
Training loss: 2.0101895332336426
Validation loss: 2.16885373989741

Epoch: 6| Step: 9
Training loss: 1.8441746234893799
Validation loss: 2.1633899211883545

Epoch: 6| Step: 10
Training loss: 2.161073923110962
Validation loss: 2.1627163887023926

Epoch: 6| Step: 11
Training loss: 1.4622138738632202
Validation loss: 2.169239858786265

Epoch: 6| Step: 12
Training loss: 1.7547881603240967
Validation loss: 2.1621601581573486

Epoch: 6| Step: 13
Training loss: 2.539590835571289
Validation loss: 2.169730464617411

Epoch: 197| Step: 0
Training loss: 1.6304713487625122
Validation loss: 2.1529754598935447

Epoch: 6| Step: 1
Training loss: 1.9463835954666138
Validation loss: 2.14215224981308

Epoch: 6| Step: 2
Training loss: 2.246535301208496
Validation loss: 2.132883608341217

Epoch: 6| Step: 3
Training loss: 2.250882863998413
Validation loss: 2.1523488561312356

Epoch: 6| Step: 4
Training loss: 1.828808069229126
Validation loss: 2.136303702990214

Epoch: 6| Step: 5
Training loss: 2.530573606491089
Validation loss: 2.1429256995519004

Epoch: 6| Step: 6
Training loss: 1.783776044845581
Validation loss: 2.1318933566411338

Epoch: 6| Step: 7
Training loss: 1.193257451057434
Validation loss: 2.1259730458259583

Epoch: 6| Step: 8
Training loss: 1.4591193199157715
Validation loss: 2.115757862726847

Epoch: 6| Step: 9
Training loss: 1.8437798023223877
Validation loss: 2.1099356611569724

Epoch: 6| Step: 10
Training loss: 2.357883930206299
Validation loss: 2.1017584800720215

Epoch: 6| Step: 11
Training loss: 1.9926635026931763
Validation loss: 2.115675707658132

Epoch: 6| Step: 12
Training loss: 1.7242482900619507
Validation loss: 2.1210816899935403

Epoch: 6| Step: 13
Training loss: 1.8492783308029175
Validation loss: 2.140368382136027

Epoch: 198| Step: 0
Training loss: 1.4810807704925537
Validation loss: 2.134942611058553

Epoch: 6| Step: 1
Training loss: 2.48164701461792
Validation loss: 2.1417715549468994

Epoch: 6| Step: 2
Training loss: 1.4501018524169922
Validation loss: 2.1512080828348794

Epoch: 6| Step: 3
Training loss: 1.4015679359436035
Validation loss: 2.156788468360901

Epoch: 6| Step: 4
Training loss: 1.4080779552459717
Validation loss: 2.1444360812505088

Epoch: 6| Step: 5
Training loss: 1.9579371213912964
Validation loss: 2.1408112247784934

Epoch: 6| Step: 6
Training loss: 2.092024326324463
Validation loss: 2.1473330656687417

Epoch: 6| Step: 7
Training loss: 1.6688694953918457
Validation loss: 2.1252906719843545

Epoch: 6| Step: 8
Training loss: 1.9656596183776855
Validation loss: 2.1300436655680337

Epoch: 6| Step: 9
Training loss: 2.3374791145324707
Validation loss: 2.121544440587362

Epoch: 6| Step: 10
Training loss: 1.788898229598999
Validation loss: 2.1248611013094583

Epoch: 6| Step: 11
Training loss: 2.010547637939453
Validation loss: 2.1299805839856467

Epoch: 6| Step: 12
Training loss: 2.4681200981140137
Validation loss: 2.1383336385091147

Epoch: 6| Step: 13
Training loss: 1.8644020557403564
Validation loss: 2.1376567284266152

Epoch: 199| Step: 0
Training loss: 1.3061726093292236
Validation loss: 2.1317542592684426

Epoch: 6| Step: 1
Training loss: 1.3504319190979004
Validation loss: 2.1540559927622476

Epoch: 6| Step: 2
Training loss: 1.8939402103424072
Validation loss: 2.1402702927589417

Epoch: 6| Step: 3
Training loss: 1.5912835597991943
Validation loss: 2.15115487575531

Epoch: 6| Step: 4
Training loss: 2.5198612213134766
Validation loss: 2.1771862705548606

Epoch: 6| Step: 5
Training loss: 1.9220091104507446
Validation loss: 2.196687479813894

Epoch: 6| Step: 6
Training loss: 1.914691686630249
Validation loss: 2.183201571305593

Epoch: 6| Step: 7
Training loss: 2.0462663173675537
Validation loss: 2.176203449567159

Epoch: 6| Step: 8
Training loss: 1.8501455783843994
Validation loss: 2.188819626967112

Epoch: 6| Step: 9
Training loss: 2.1510281562805176
Validation loss: 2.1769017577171326

Epoch: 6| Step: 10
Training loss: 1.471899390220642
Validation loss: 2.196658949057261

Epoch: 6| Step: 11
Training loss: 1.7826592922210693
Validation loss: 2.1590855916341147

Epoch: 6| Step: 12
Training loss: 2.1353759765625
Validation loss: 2.1500433484713235

Epoch: 6| Step: 13
Training loss: 2.327683448791504
Validation loss: 2.144264280796051

Epoch: 200| Step: 0
Training loss: 1.3378558158874512
Validation loss: 2.1277758479118347

Epoch: 6| Step: 1
Training loss: 1.9799797534942627
Validation loss: 2.1163758834203086

Epoch: 6| Step: 2
Training loss: 1.6743483543395996
Validation loss: 2.1331644654273987

Epoch: 6| Step: 3
Training loss: 1.6359765529632568
Validation loss: 2.1225809454917908

Epoch: 6| Step: 4
Training loss: 1.5541980266571045
Validation loss: 2.1324517925580344

Epoch: 6| Step: 5
Training loss: 2.3761391639709473
Validation loss: 2.1239107251167297

Epoch: 6| Step: 6
Training loss: 2.223818778991699
Validation loss: 2.1282641092936196

Epoch: 6| Step: 7
Training loss: 2.4233968257904053
Validation loss: 2.133084019025167

Epoch: 6| Step: 8
Training loss: 1.598921775817871
Validation loss: 2.1266546646753945

Epoch: 6| Step: 9
Training loss: 1.779754638671875
Validation loss: 2.1216226617495217

Epoch: 6| Step: 10
Training loss: 2.0528130531311035
Validation loss: 2.1114919583002725

Epoch: 6| Step: 11
Training loss: 2.1831960678100586
Validation loss: 2.1223820447921753

Epoch: 6| Step: 12
Training loss: 1.8177568912506104
Validation loss: 2.120672563711802

Epoch: 6| Step: 13
Training loss: 2.2154347896575928
Validation loss: 2.138123174508413

Epoch: 201| Step: 0
Training loss: 1.332777738571167
Validation loss: 2.1155018409093223

Epoch: 6| Step: 1
Training loss: 2.0235209465026855
Validation loss: 2.1230456829071045

Epoch: 6| Step: 2
Training loss: 1.2980897426605225
Validation loss: 2.122912844022115

Epoch: 6| Step: 3
Training loss: 1.9853107929229736
Validation loss: 2.1056542793909707

Epoch: 6| Step: 4
Training loss: 2.997769832611084
Validation loss: 2.138997038205465

Epoch: 6| Step: 5
Training loss: 2.1428511142730713
Validation loss: 2.1346259911855063

Epoch: 6| Step: 6
Training loss: 1.58730947971344
Validation loss: 2.1501667896906533

Epoch: 6| Step: 7
Training loss: 2.2421350479125977
Validation loss: 2.1543724139531455

Epoch: 6| Step: 8
Training loss: 2.184983730316162
Validation loss: 2.1458603342374167

Epoch: 6| Step: 9
Training loss: 1.2561637163162231
Validation loss: 2.1473063230514526

Epoch: 6| Step: 10
Training loss: 2.2007646560668945
Validation loss: 2.139406442642212

Epoch: 6| Step: 11
Training loss: 1.958384394645691
Validation loss: 2.1418667236963906

Epoch: 6| Step: 12
Training loss: 1.8287420272827148
Validation loss: 2.1237583557764688

Epoch: 6| Step: 13
Training loss: 1.6528606414794922
Validation loss: 2.12854133049647

Epoch: 202| Step: 0
Training loss: 2.005228042602539
Validation loss: 2.1275890270868936

Epoch: 6| Step: 1
Training loss: 2.1214070320129395
Validation loss: 2.113206962744395

Epoch: 6| Step: 2
Training loss: 1.7426352500915527
Validation loss: 2.127561310927073

Epoch: 6| Step: 3
Training loss: 1.6130348443984985
Validation loss: 2.1327220598856607

Epoch: 6| Step: 4
Training loss: 1.354095697402954
Validation loss: 2.135037581125895

Epoch: 6| Step: 5
Training loss: 2.029726505279541
Validation loss: 2.1368776162465415

Epoch: 6| Step: 6
Training loss: 1.8105708360671997
Validation loss: 2.147565762201945

Epoch: 6| Step: 7
Training loss: 1.2302647829055786
Validation loss: 2.152235527833303

Epoch: 6| Step: 8
Training loss: 2.1764309406280518
Validation loss: 2.162813047568003

Epoch: 6| Step: 9
Training loss: 1.6681904792785645
Validation loss: 2.1562201976776123

Epoch: 6| Step: 10
Training loss: 1.6982046365737915
Validation loss: 2.157346526781718

Epoch: 6| Step: 11
Training loss: 1.8669099807739258
Validation loss: 2.169464190800985

Epoch: 6| Step: 12
Training loss: 2.2563223838806152
Validation loss: 2.157107432683309

Epoch: 6| Step: 13
Training loss: 2.290998935699463
Validation loss: 2.1782314578692117

Epoch: 203| Step: 0
Training loss: 2.629635810852051
Validation loss: 2.189508040746053

Epoch: 6| Step: 1
Training loss: 0.9918424487113953
Validation loss: 2.192168672879537

Epoch: 6| Step: 2
Training loss: 1.8648605346679688
Validation loss: 2.1935270627339682

Epoch: 6| Step: 3
Training loss: 1.7408246994018555
Validation loss: 2.1891676783561707

Epoch: 6| Step: 4
Training loss: 2.267461061477661
Validation loss: 2.1640425523122153

Epoch: 6| Step: 5
Training loss: 1.9929072856903076
Validation loss: 2.1530819733937583

Epoch: 6| Step: 6
Training loss: 2.7803425788879395
Validation loss: 2.1512293020884194

Epoch: 6| Step: 7
Training loss: 2.3890700340270996
Validation loss: 2.1492680311203003

Epoch: 6| Step: 8
Training loss: 1.8688125610351562
Validation loss: 2.15861584742864

Epoch: 6| Step: 9
Training loss: 1.0327256917953491
Validation loss: 2.144827385743459

Epoch: 6| Step: 10
Training loss: 1.4141125679016113
Validation loss: 2.1449966430664062

Epoch: 6| Step: 11
Training loss: 1.9200775623321533
Validation loss: 2.165331701437632

Epoch: 6| Step: 12
Training loss: 1.4471551179885864
Validation loss: 2.153389811515808

Epoch: 6| Step: 13
Training loss: 1.957958459854126
Validation loss: 2.1423054734865823

Epoch: 204| Step: 0
Training loss: 2.2232160568237305
Validation loss: 2.1634753942489624

Epoch: 6| Step: 1
Training loss: 2.0220048427581787
Validation loss: 2.1565283934275308

Epoch: 6| Step: 2
Training loss: 1.8356661796569824
Validation loss: 2.159433126449585

Epoch: 6| Step: 3
Training loss: 1.845702886581421
Validation loss: 2.1660483280817666

Epoch: 6| Step: 4
Training loss: 1.9125571250915527
Validation loss: 2.1627034544944763

Epoch: 6| Step: 5
Training loss: 2.35491943359375
Validation loss: 2.1771469513575235

Epoch: 6| Step: 6
Training loss: 2.1703412532806396
Validation loss: 2.164855202039083

Epoch: 6| Step: 7
Training loss: 1.4671262502670288
Validation loss: 2.1609466870625815

Epoch: 6| Step: 8
Training loss: 1.2887418270111084
Validation loss: 2.14617383480072

Epoch: 6| Step: 9
Training loss: 0.9624732136726379
Validation loss: 2.13223002354304

Epoch: 6| Step: 10
Training loss: 1.626726746559143
Validation loss: 2.131964941819509

Epoch: 6| Step: 11
Training loss: 2.6995463371276855
Validation loss: 2.131744305292765

Epoch: 6| Step: 12
Training loss: 1.6591742038726807
Validation loss: 2.1332406202952066

Epoch: 6| Step: 13
Training loss: 1.9161005020141602
Validation loss: 2.133415718873342

Epoch: 205| Step: 0
Training loss: 2.699831962585449
Validation loss: 2.1361358960469565

Epoch: 6| Step: 1
Training loss: 2.265373706817627
Validation loss: 2.143182178338369

Epoch: 6| Step: 2
Training loss: 2.3116660118103027
Validation loss: 2.1587352951367698

Epoch: 6| Step: 3
Training loss: 2.031001091003418
Validation loss: 2.1620562076568604

Epoch: 6| Step: 4
Training loss: 1.4658122062683105
Validation loss: 2.1672239303588867

Epoch: 6| Step: 5
Training loss: 1.5106831789016724
Validation loss: 2.164848963419596

Epoch: 6| Step: 6
Training loss: 1.802930235862732
Validation loss: 2.142410397529602

Epoch: 6| Step: 7
Training loss: 1.437150239944458
Validation loss: 2.156965990861257

Epoch: 6| Step: 8
Training loss: 1.9281203746795654
Validation loss: 2.159337639808655

Epoch: 6| Step: 9
Training loss: 1.3426169157028198
Validation loss: 2.172983090082804

Epoch: 6| Step: 10
Training loss: 1.6732351779937744
Validation loss: 2.1815019051233926

Epoch: 6| Step: 11
Training loss: 1.693865180015564
Validation loss: 2.169396142164866

Epoch: 6| Step: 12
Training loss: 1.9724078178405762
Validation loss: 2.1645954648653665

Epoch: 6| Step: 13
Training loss: 1.6091861724853516
Validation loss: 2.1657520135243735

Epoch: 206| Step: 0
Training loss: 1.5157690048217773
Validation loss: 2.14296289285024

Epoch: 6| Step: 1
Training loss: 1.6018950939178467
Validation loss: 2.1498738725980124

Epoch: 6| Step: 2
Training loss: 2.5894277095794678
Validation loss: 2.164419690767924

Epoch: 6| Step: 3
Training loss: 2.01723313331604
Validation loss: 2.1530712842941284

Epoch: 6| Step: 4
Training loss: 2.7267355918884277
Validation loss: 2.160465200742086

Epoch: 6| Step: 5
Training loss: 1.0712730884552002
Validation loss: 2.157491127649943

Epoch: 6| Step: 6
Training loss: 1.1938529014587402
Validation loss: 2.1720978816350303

Epoch: 6| Step: 7
Training loss: 1.8752585649490356
Validation loss: 2.1763490438461304

Epoch: 6| Step: 8
Training loss: 1.3028743267059326
Validation loss: 2.185674786567688

Epoch: 6| Step: 9
Training loss: 2.1927719116210938
Validation loss: 2.177490711212158

Epoch: 6| Step: 10
Training loss: 1.5937397480010986
Validation loss: 2.1782697439193726

Epoch: 6| Step: 11
Training loss: 2.8105480670928955
Validation loss: 2.1677025159200034

Epoch: 6| Step: 12
Training loss: 1.842226266860962
Validation loss: 2.166473150253296

Epoch: 6| Step: 13
Training loss: 1.3270564079284668
Validation loss: 2.183791935443878

Epoch: 207| Step: 0
Training loss: 1.363704800605774
Validation loss: 2.163689891497294

Epoch: 6| Step: 1
Training loss: 2.0780458450317383
Validation loss: 2.1804151137669883

Epoch: 6| Step: 2
Training loss: 1.966630458831787
Validation loss: 2.1718740463256836

Epoch: 6| Step: 3
Training loss: 1.6768944263458252
Validation loss: 2.1807318528493247

Epoch: 6| Step: 4
Training loss: 1.6063448190689087
Validation loss: 2.1562426487604776

Epoch: 6| Step: 5
Training loss: 1.8781307935714722
Validation loss: 2.1661518812179565

Epoch: 6| Step: 6
Training loss: 1.4197677373886108
Validation loss: 2.159002900123596

Epoch: 6| Step: 7
Training loss: 1.8893764019012451
Validation loss: 2.1590235233306885

Epoch: 6| Step: 8
Training loss: 2.0104050636291504
Validation loss: 2.1699542005856833

Epoch: 6| Step: 9
Training loss: 1.4885265827178955
Validation loss: 2.1733354727427163

Epoch: 6| Step: 10
Training loss: 2.203646659851074
Validation loss: 2.179475645224253

Epoch: 6| Step: 11
Training loss: 2.3200035095214844
Validation loss: 2.163994868596395

Epoch: 6| Step: 12
Training loss: 1.370442271232605
Validation loss: 2.170281628767649

Epoch: 6| Step: 13
Training loss: 2.2390642166137695
Validation loss: 2.1752073168754578

Epoch: 208| Step: 0
Training loss: 2.1593847274780273
Validation loss: 2.179861227671305

Epoch: 6| Step: 1
Training loss: 1.2265756130218506
Validation loss: 2.1745134790738425

Epoch: 6| Step: 2
Training loss: 1.423513412475586
Validation loss: 2.1690154870351157

Epoch: 6| Step: 3
Training loss: 1.3109588623046875
Validation loss: 2.1611844102541604

Epoch: 6| Step: 4
Training loss: 2.3506922721862793
Validation loss: 2.1668115854263306

Epoch: 6| Step: 5
Training loss: 1.4830882549285889
Validation loss: 2.143525759379069

Epoch: 6| Step: 6
Training loss: 2.0195746421813965
Validation loss: 2.1543469429016113

Epoch: 6| Step: 7
Training loss: 1.3578232526779175
Validation loss: 2.148250679175059

Epoch: 6| Step: 8
Training loss: 1.8875386714935303
Validation loss: 2.1532622575759888

Epoch: 6| Step: 9
Training loss: 1.730245590209961
Validation loss: 2.169104039669037

Epoch: 6| Step: 10
Training loss: 2.3968183994293213
Validation loss: 2.158630828062693

Epoch: 6| Step: 11
Training loss: 2.265965700149536
Validation loss: 2.1818856994311013

Epoch: 6| Step: 12
Training loss: 2.5685105323791504
Validation loss: 2.1481887102127075

Epoch: 6| Step: 13
Training loss: 1.5698999166488647
Validation loss: 2.169333259264628

Epoch: 209| Step: 0
Training loss: 1.8179731369018555
Validation loss: 2.19437583287557

Epoch: 6| Step: 1
Training loss: 2.6316606998443604
Validation loss: 2.1854971647262573

Epoch: 6| Step: 2
Training loss: 1.5694273710250854
Validation loss: 2.209023674329122

Epoch: 6| Step: 3
Training loss: 1.73420250415802
Validation loss: 2.192660609881083

Epoch: 6| Step: 4
Training loss: 2.2757022380828857
Validation loss: 2.193189322948456

Epoch: 6| Step: 5
Training loss: 1.2096741199493408
Validation loss: 2.1885143915812173

Epoch: 6| Step: 6
Training loss: 1.1077184677124023
Validation loss: 2.170966645081838

Epoch: 6| Step: 7
Training loss: 1.8814942836761475
Validation loss: 2.166471223036448

Epoch: 6| Step: 8
Training loss: 1.9326860904693604
Validation loss: 2.1685971220334372

Epoch: 6| Step: 9
Training loss: 2.214221477508545
Validation loss: 2.156003395716349

Epoch: 6| Step: 10
Training loss: 1.8104498386383057
Validation loss: 2.161372939745585

Epoch: 6| Step: 11
Training loss: 1.901490569114685
Validation loss: 2.149309595425924

Epoch: 6| Step: 12
Training loss: 2.1086297035217285
Validation loss: 2.148179213205973

Epoch: 6| Step: 13
Training loss: 1.5153076648712158
Validation loss: 2.154351075490316

Epoch: 210| Step: 0
Training loss: 1.3203294277191162
Validation loss: 2.1549164851506553

Epoch: 6| Step: 1
Training loss: 1.8942700624465942
Validation loss: 2.1565993428230286

Epoch: 6| Step: 2
Training loss: 2.3092119693756104
Validation loss: 2.162391980489095

Epoch: 6| Step: 3
Training loss: 1.1241352558135986
Validation loss: 2.156205972035726

Epoch: 6| Step: 4
Training loss: 1.9245524406433105
Validation loss: 2.1549907525380454

Epoch: 6| Step: 5
Training loss: 1.9514285326004028
Validation loss: 2.1660537719726562

Epoch: 6| Step: 6
Training loss: 1.8112998008728027
Validation loss: 2.1514470974604287

Epoch: 6| Step: 7
Training loss: 2.4860081672668457
Validation loss: 2.1530611316363015

Epoch: 6| Step: 8
Training loss: 1.1831175088882446
Validation loss: 2.138152798016866

Epoch: 6| Step: 9
Training loss: 1.6008981466293335
Validation loss: 2.1403755942980447

Epoch: 6| Step: 10
Training loss: 2.0186192989349365
Validation loss: 2.147096554438273

Epoch: 6| Step: 11
Training loss: 2.353306531906128
Validation loss: 2.1456328431765237

Epoch: 6| Step: 12
Training loss: 2.3049745559692383
Validation loss: 2.1493481397628784

Epoch: 6| Step: 13
Training loss: 1.445206642150879
Validation loss: 2.1510931650797525

Epoch: 211| Step: 0
Training loss: 1.6935713291168213
Validation loss: 2.1634118358294168

Epoch: 6| Step: 1
Training loss: 1.9207841157913208
Validation loss: 2.165878256162008

Epoch: 6| Step: 2
Training loss: 1.5768665075302124
Validation loss: 2.1681398351987204

Epoch: 6| Step: 3
Training loss: 1.3376977443695068
Validation loss: 2.1476998130480447

Epoch: 6| Step: 4
Training loss: 2.1051149368286133
Validation loss: 2.1452247500419617

Epoch: 6| Step: 5
Training loss: 2.1929378509521484
Validation loss: 2.152056932449341

Epoch: 6| Step: 6
Training loss: 1.8950313329696655
Validation loss: 2.1648744146029153

Epoch: 6| Step: 7
Training loss: 2.7006266117095947
Validation loss: 2.168751875559489

Epoch: 6| Step: 8
Training loss: 2.2122421264648438
Validation loss: 2.171302100022634

Epoch: 6| Step: 9
Training loss: 1.2598440647125244
Validation loss: 2.153791666030884

Epoch: 6| Step: 10
Training loss: 0.9636969566345215
Validation loss: 2.166995406150818

Epoch: 6| Step: 11
Training loss: 2.4096174240112305
Validation loss: 2.1708033084869385

Epoch: 6| Step: 12
Training loss: 1.2240008115768433
Validation loss: 2.1667872269948325

Epoch: 6| Step: 13
Training loss: 1.7669122219085693
Validation loss: 2.1657313108444214

Epoch: 212| Step: 0
Training loss: 2.1009509563446045
Validation loss: 2.184659779071808

Epoch: 6| Step: 1
Training loss: 2.0135717391967773
Validation loss: 2.2205388148625693

Epoch: 6| Step: 2
Training loss: 2.239729642868042
Validation loss: 2.159372568130493

Epoch: 6| Step: 3
Training loss: 1.7044529914855957
Validation loss: 2.180080791314443

Epoch: 6| Step: 4
Training loss: 1.6604312658309937
Validation loss: 2.190857251485189

Epoch: 6| Step: 5
Training loss: 1.5746277570724487
Validation loss: 2.1986915667851767

Epoch: 6| Step: 6
Training loss: 2.1363525390625
Validation loss: 2.155517816543579

Epoch: 6| Step: 7
Training loss: 1.4651600122451782
Validation loss: 2.1994619170824685

Epoch: 6| Step: 8
Training loss: 1.7675864696502686
Validation loss: 2.192092537879944

Epoch: 6| Step: 9
Training loss: 2.2463107109069824
Validation loss: 2.1840969721476235

Epoch: 6| Step: 10
Training loss: 2.2116947174072266
Validation loss: 2.1636443932851157

Epoch: 6| Step: 11
Training loss: 1.137344241142273
Validation loss: 2.154979924360911

Epoch: 6| Step: 12
Training loss: 1.480158805847168
Validation loss: 2.147435029347738

Epoch: 6| Step: 13
Training loss: 1.5644627809524536
Validation loss: 2.163046360015869

Epoch: 213| Step: 0
Training loss: 2.2042903900146484
Validation loss: 2.16968427101771

Epoch: 6| Step: 1
Training loss: 2.0856728553771973
Validation loss: 2.177159011363983

Epoch: 6| Step: 2
Training loss: 1.6850590705871582
Validation loss: 2.1948541601498923

Epoch: 6| Step: 3
Training loss: 1.9334070682525635
Validation loss: 2.201725125312805

Epoch: 6| Step: 4
Training loss: 2.8152694702148438
Validation loss: 2.194451113541921

Epoch: 6| Step: 5
Training loss: 1.8627169132232666
Validation loss: 2.186120351155599

Epoch: 6| Step: 6
Training loss: 0.8109696507453918
Validation loss: 2.1925531029701233

Epoch: 6| Step: 7
Training loss: 1.5261238813400269
Validation loss: 2.1959092020988464

Epoch: 6| Step: 8
Training loss: 1.7088875770568848
Validation loss: 2.1827102303504944

Epoch: 6| Step: 9
Training loss: 1.4207255840301514
Validation loss: 2.171499252319336

Epoch: 6| Step: 10
Training loss: 1.9687011241912842
Validation loss: 2.1826401352882385

Epoch: 6| Step: 11
Training loss: 1.5304572582244873
Validation loss: 2.188867668310801

Epoch: 6| Step: 12
Training loss: 1.783603549003601
Validation loss: 2.164703369140625

Epoch: 6| Step: 13
Training loss: 1.8557615280151367
Validation loss: 2.1635520656903586

Epoch: 214| Step: 0
Training loss: 1.9753037691116333
Validation loss: 2.1656259894371033

Epoch: 6| Step: 1
Training loss: 2.430793285369873
Validation loss: 2.1521593729654946

Epoch: 6| Step: 2
Training loss: 1.9445290565490723
Validation loss: 2.152783989906311

Epoch: 6| Step: 3
Training loss: 1.7292131185531616
Validation loss: 2.1554471055666604

Epoch: 6| Step: 4
Training loss: 1.689152479171753
Validation loss: 2.147565186023712

Epoch: 6| Step: 5
Training loss: 2.10089111328125
Validation loss: 2.1491628885269165

Epoch: 6| Step: 6
Training loss: 1.5540273189544678
Validation loss: 2.161762773990631

Epoch: 6| Step: 7
Training loss: 2.1137328147888184
Validation loss: 2.168502072493235

Epoch: 6| Step: 8
Training loss: 1.489630937576294
Validation loss: 2.1789983113606772

Epoch: 6| Step: 9
Training loss: 1.2597357034683228
Validation loss: 2.180148204167684

Epoch: 6| Step: 10
Training loss: 2.050906181335449
Validation loss: 2.1793155868848166

Epoch: 6| Step: 11
Training loss: 1.3995157480239868
Validation loss: 2.191520949204763

Epoch: 6| Step: 12
Training loss: 2.061300754547119
Validation loss: 2.1803526282310486

Epoch: 6| Step: 13
Training loss: 1.7328498363494873
Validation loss: 2.188709020614624

Epoch: 215| Step: 0
Training loss: 2.131861925125122
Validation loss: 2.185365358988444

Epoch: 6| Step: 1
Training loss: 2.4398205280303955
Validation loss: 2.179457902908325

Epoch: 6| Step: 2
Training loss: 1.7286572456359863
Validation loss: 2.1866395672162375

Epoch: 6| Step: 3
Training loss: 1.7218334674835205
Validation loss: 2.204045534133911

Epoch: 6| Step: 4
Training loss: 1.413172721862793
Validation loss: 2.194006860256195

Epoch: 6| Step: 5
Training loss: 1.8047266006469727
Validation loss: 2.188157796859741

Epoch: 6| Step: 6
Training loss: 1.8478131294250488
Validation loss: 2.195425887902578

Epoch: 6| Step: 7
Training loss: 1.8005350828170776
Validation loss: 2.1874336202939353

Epoch: 6| Step: 8
Training loss: 1.6500515937805176
Validation loss: 2.1867564916610718

Epoch: 6| Step: 9
Training loss: 1.508105993270874
Validation loss: 2.185660978158315

Epoch: 6| Step: 10
Training loss: 1.3560006618499756
Validation loss: 2.1887239615122476

Epoch: 6| Step: 11
Training loss: 1.8176649808883667
Validation loss: 2.1736847162246704

Epoch: 6| Step: 12
Training loss: 1.5595051050186157
Validation loss: 2.1845176219940186

Epoch: 6| Step: 13
Training loss: 2.423768997192383
Validation loss: 2.155795415242513

Epoch: 216| Step: 0
Training loss: 2.106294631958008
Validation loss: 2.1597644090652466

Epoch: 6| Step: 1
Training loss: 3.2877092361450195
Validation loss: 2.1640788316726685

Epoch: 6| Step: 2
Training loss: 1.8661025762557983
Validation loss: 2.1590541203816733

Epoch: 6| Step: 3
Training loss: 2.165328025817871
Validation loss: 2.145762244860331

Epoch: 6| Step: 4
Training loss: 1.3932297229766846
Validation loss: 2.147331635157267

Epoch: 6| Step: 5
Training loss: 1.4758079051971436
Validation loss: 2.1630290349324546

Epoch: 6| Step: 6
Training loss: 1.4762943983078003
Validation loss: 2.166387399037679

Epoch: 6| Step: 7
Training loss: 1.863783359527588
Validation loss: 2.176569084326426

Epoch: 6| Step: 8
Training loss: 1.855790615081787
Validation loss: 2.17404838403066

Epoch: 6| Step: 9
Training loss: 1.351515531539917
Validation loss: 2.179481089115143

Epoch: 6| Step: 10
Training loss: 1.9212887287139893
Validation loss: 2.182632088661194

Epoch: 6| Step: 11
Training loss: 1.7291721105575562
Validation loss: 2.1710485219955444

Epoch: 6| Step: 12
Training loss: 1.6736421585083008
Validation loss: 2.1685588558514914

Epoch: 6| Step: 13
Training loss: 1.2866015434265137
Validation loss: 2.1770750880241394

Epoch: 217| Step: 0
Training loss: 2.374232292175293
Validation loss: 2.173132081826528

Epoch: 6| Step: 1
Training loss: 1.806870937347412
Validation loss: 2.1764538089434304

Epoch: 6| Step: 2
Training loss: 1.6132237911224365
Validation loss: 2.157721916834513

Epoch: 6| Step: 3
Training loss: 1.6416023969650269
Validation loss: 2.182019829750061

Epoch: 6| Step: 4
Training loss: 1.4676201343536377
Validation loss: 2.169379770755768

Epoch: 6| Step: 5
Training loss: 1.7235689163208008
Validation loss: 2.1726057529449463

Epoch: 6| Step: 6
Training loss: 2.3807003498077393
Validation loss: 2.1546362241109214

Epoch: 6| Step: 7
Training loss: 1.6957590579986572
Validation loss: 2.1605281631151834

Epoch: 6| Step: 8
Training loss: 1.8744875192642212
Validation loss: 2.1443730195363364

Epoch: 6| Step: 9
Training loss: 2.066683769226074
Validation loss: 2.14650160074234

Epoch: 6| Step: 10
Training loss: 1.3780882358551025
Validation loss: 2.1365336974461875

Epoch: 6| Step: 11
Training loss: 2.288424015045166
Validation loss: 2.136789401372274

Epoch: 6| Step: 12
Training loss: 1.9394934177398682
Validation loss: 2.1452926993370056

Epoch: 6| Step: 13
Training loss: 1.8310587406158447
Validation loss: 2.146637042363485

Epoch: 218| Step: 0
Training loss: 2.5833420753479004
Validation loss: 2.1439875960350037

Epoch: 6| Step: 1
Training loss: 2.230181932449341
Validation loss: 2.145149052143097

Epoch: 6| Step: 2
Training loss: 2.375575065612793
Validation loss: 2.150512158870697

Epoch: 6| Step: 3
Training loss: 1.8401598930358887
Validation loss: 2.147367537021637

Epoch: 6| Step: 4
Training loss: 2.233175039291382
Validation loss: 2.1555673082669577

Epoch: 6| Step: 5
Training loss: 1.6500365734100342
Validation loss: 2.151318113009135

Epoch: 6| Step: 6
Training loss: 1.3967444896697998
Validation loss: 2.1502204736073813

Epoch: 6| Step: 7
Training loss: 1.036500096321106
Validation loss: 2.1673706571261087

Epoch: 6| Step: 8
Training loss: 1.852946400642395
Validation loss: 2.166607975959778

Epoch: 6| Step: 9
Training loss: 2.0066232681274414
Validation loss: 2.186736265818278

Epoch: 6| Step: 10
Training loss: 1.7486618757247925
Validation loss: 2.205023924509684

Epoch: 6| Step: 11
Training loss: 1.7434791326522827
Validation loss: 2.211185395717621

Epoch: 6| Step: 12
Training loss: 1.2072126865386963
Validation loss: 2.222790857156118

Epoch: 6| Step: 13
Training loss: 2.4663302898406982
Validation loss: 2.2131897608439126

Epoch: 219| Step: 0
Training loss: 1.8489253520965576
Validation loss: 2.1994295914967856

Epoch: 6| Step: 1
Training loss: 1.1166064739227295
Validation loss: 2.2140877842903137

Epoch: 6| Step: 2
Training loss: 1.6990156173706055
Validation loss: 2.2012580831845603

Epoch: 6| Step: 3
Training loss: 1.445810079574585
Validation loss: 2.2256486415863037

Epoch: 6| Step: 4
Training loss: 2.0700297355651855
Validation loss: 2.1943353017171225

Epoch: 6| Step: 5
Training loss: 1.6603116989135742
Validation loss: 2.1957898338635764

Epoch: 6| Step: 6
Training loss: 2.2968358993530273
Validation loss: 2.163127621014913

Epoch: 6| Step: 7
Training loss: 1.2724180221557617
Validation loss: 2.1633167465527854

Epoch: 6| Step: 8
Training loss: 1.4854964017868042
Validation loss: 2.1675570805867515

Epoch: 6| Step: 9
Training loss: 2.2059450149536133
Validation loss: 2.1534167329470315

Epoch: 6| Step: 10
Training loss: 1.8432176113128662
Validation loss: 2.1473684310913086

Epoch: 6| Step: 11
Training loss: 2.52182674407959
Validation loss: 2.1487618883450827

Epoch: 6| Step: 12
Training loss: 2.264157295227051
Validation loss: 2.1531129082043967

Epoch: 6| Step: 13
Training loss: 1.7177929878234863
Validation loss: 2.1768537163734436

Epoch: 220| Step: 0
Training loss: 2.2135331630706787
Validation loss: 2.184024691581726

Epoch: 6| Step: 1
Training loss: 1.190346121788025
Validation loss: 2.161405642827352

Epoch: 6| Step: 2
Training loss: 1.6299104690551758
Validation loss: 2.1595460573832193

Epoch: 6| Step: 3
Training loss: 1.6881680488586426
Validation loss: 2.181855400403341

Epoch: 6| Step: 4
Training loss: 2.243325710296631
Validation loss: 2.139969269434611

Epoch: 6| Step: 5
Training loss: 2.089752435684204
Validation loss: 2.1548807422320047

Epoch: 6| Step: 6
Training loss: 1.4735320806503296
Validation loss: 2.1677240133285522

Epoch: 6| Step: 7
Training loss: 1.743300437927246
Validation loss: 2.147539218266805

Epoch: 6| Step: 8
Training loss: 1.9859037399291992
Validation loss: 2.1727636059125266

Epoch: 6| Step: 9
Training loss: 1.7260476350784302
Validation loss: 2.1802243987719216

Epoch: 6| Step: 10
Training loss: 1.7605270147323608
Validation loss: 2.1775121887524924

Epoch: 6| Step: 11
Training loss: 1.66194486618042
Validation loss: 2.183668633302053

Epoch: 6| Step: 12
Training loss: 2.2718396186828613
Validation loss: 2.2062493562698364

Epoch: 6| Step: 13
Training loss: 1.9979393482208252
Validation loss: 2.208352526028951

Epoch: 221| Step: 0
Training loss: 2.1171364784240723
Validation loss: 2.190811554590861

Epoch: 6| Step: 1
Training loss: 2.1701102256774902
Validation loss: 2.195129672686259

Epoch: 6| Step: 2
Training loss: 2.01431941986084
Validation loss: 2.1904863317807517

Epoch: 6| Step: 3
Training loss: 2.39520525932312
Validation loss: 2.169037143389384

Epoch: 6| Step: 4
Training loss: 1.3616421222686768
Validation loss: 2.1728403170903525

Epoch: 6| Step: 5
Training loss: 1.706989049911499
Validation loss: 2.179648995399475

Epoch: 6| Step: 6
Training loss: 2.183321237564087
Validation loss: 2.1846346855163574

Epoch: 6| Step: 7
Training loss: 1.65990149974823
Validation loss: 2.1853242913881936

Epoch: 6| Step: 8
Training loss: 1.6804274320602417
Validation loss: 2.1832115054130554

Epoch: 6| Step: 9
Training loss: 1.839791178703308
Validation loss: 2.180685063203176

Epoch: 6| Step: 10
Training loss: 1.3093624114990234
Validation loss: 2.194372753302256

Epoch: 6| Step: 11
Training loss: 1.756211757659912
Validation loss: 2.1957005063692727

Epoch: 6| Step: 12
Training loss: 1.368343710899353
Validation loss: 2.1984857320785522

Epoch: 6| Step: 13
Training loss: 1.9416348934173584
Validation loss: 2.197174628575643

Epoch: 222| Step: 0
Training loss: 1.9660112857818604
Validation loss: 2.20743191242218

Epoch: 6| Step: 1
Training loss: 2.5218000411987305
Validation loss: 2.2100470860799155

Epoch: 6| Step: 2
Training loss: 1.0568774938583374
Validation loss: 2.198636750380198

Epoch: 6| Step: 3
Training loss: 2.0703015327453613
Validation loss: 2.1845242778460183

Epoch: 6| Step: 4
Training loss: 1.5797450542449951
Validation loss: 2.199825127919515

Epoch: 6| Step: 5
Training loss: 1.853200912475586
Validation loss: 2.2030070424079895

Epoch: 6| Step: 6
Training loss: 1.3874239921569824
Validation loss: 2.18778004248937

Epoch: 6| Step: 7
Training loss: 1.1853463649749756
Validation loss: 2.1990726391474404

Epoch: 6| Step: 8
Training loss: 2.3954033851623535
Validation loss: 2.186501622200012

Epoch: 6| Step: 9
Training loss: 1.7657207250595093
Validation loss: 2.194326082865397

Epoch: 6| Step: 10
Training loss: 1.7234926223754883
Validation loss: 2.1887856324513755

Epoch: 6| Step: 11
Training loss: 1.7381607294082642
Validation loss: 2.1864991585413613

Epoch: 6| Step: 12
Training loss: 1.801038384437561
Validation loss: 2.1663799484570823

Epoch: 6| Step: 13
Training loss: 1.973618984222412
Validation loss: 2.170713027318319

Epoch: 223| Step: 0
Training loss: 1.2745838165283203
Validation loss: 2.1626983880996704

Epoch: 6| Step: 1
Training loss: 1.6562082767486572
Validation loss: 2.1750494241714478

Epoch: 6| Step: 2
Training loss: 1.783656358718872
Validation loss: 2.1657235423723855

Epoch: 6| Step: 3
Training loss: 1.4756525754928589
Validation loss: 2.1746330658594766

Epoch: 6| Step: 4
Training loss: 2.130948543548584
Validation loss: 2.1780714988708496

Epoch: 6| Step: 5
Training loss: 1.8133797645568848
Validation loss: 2.190399686495463

Epoch: 6| Step: 6
Training loss: 2.0742692947387695
Validation loss: 2.1906242966651917

Epoch: 6| Step: 7
Training loss: 1.9517828226089478
Validation loss: 2.1986144383748374

Epoch: 6| Step: 8
Training loss: 2.610912561416626
Validation loss: 2.198091427485148

Epoch: 6| Step: 9
Training loss: 1.3645548820495605
Validation loss: 2.216142197450002

Epoch: 6| Step: 10
Training loss: 2.2591919898986816
Validation loss: 2.1808985670407615

Epoch: 6| Step: 11
Training loss: 1.4309979677200317
Validation loss: 2.187768280506134

Epoch: 6| Step: 12
Training loss: 1.5683019161224365
Validation loss: 2.1951858599980674

Epoch: 6| Step: 13
Training loss: 1.742733359336853
Validation loss: 2.1931543151537576

Epoch: 224| Step: 0
Training loss: 1.560119390487671
Validation loss: 2.189702351888021

Epoch: 6| Step: 1
Training loss: 1.4065957069396973
Validation loss: 2.1577972372372947

Epoch: 6| Step: 2
Training loss: 1.2817730903625488
Validation loss: 2.137131989002228

Epoch: 6| Step: 3
Training loss: 1.778562307357788
Validation loss: 2.143251657485962

Epoch: 6| Step: 4
Training loss: 2.5424795150756836
Validation loss: 2.1450560291608176

Epoch: 6| Step: 5
Training loss: 1.7968729734420776
Validation loss: 2.1271225015322366

Epoch: 6| Step: 6
Training loss: 2.275360584259033
Validation loss: 2.1412686904271445

Epoch: 6| Step: 7
Training loss: 1.5362063646316528
Validation loss: 2.1381602684656777

Epoch: 6| Step: 8
Training loss: 1.4617758989334106
Validation loss: 2.142045875390371

Epoch: 6| Step: 9
Training loss: 2.550232410430908
Validation loss: 2.15489653746287

Epoch: 6| Step: 10
Training loss: 2.4739480018615723
Validation loss: 2.183884064356486

Epoch: 6| Step: 11
Training loss: 1.5198450088500977
Validation loss: 2.1884659926096597

Epoch: 6| Step: 12
Training loss: 2.180040121078491
Validation loss: 2.182093063990275

Epoch: 6| Step: 13
Training loss: 1.99428391456604
Validation loss: 2.201098541418711

Epoch: 225| Step: 0
Training loss: 1.3772850036621094
Validation loss: 2.1872793237368264

Epoch: 6| Step: 1
Training loss: 1.9320831298828125
Validation loss: 2.182630697886149

Epoch: 6| Step: 2
Training loss: 1.7995624542236328
Validation loss: 2.195482532183329

Epoch: 6| Step: 3
Training loss: 1.5678609609603882
Validation loss: 2.204164127508799

Epoch: 6| Step: 4
Training loss: 1.0925936698913574
Validation loss: 2.183134694894155

Epoch: 6| Step: 5
Training loss: 2.1288928985595703
Validation loss: 2.1839789350827536

Epoch: 6| Step: 6
Training loss: 1.8215309381484985
Validation loss: 2.182180027167002

Epoch: 6| Step: 7
Training loss: 1.6215453147888184
Validation loss: 2.177974740664164

Epoch: 6| Step: 8
Training loss: 2.069491386413574
Validation loss: 2.176668723424276

Epoch: 6| Step: 9
Training loss: 2.050720691680908
Validation loss: 2.1740612188975015

Epoch: 6| Step: 10
Training loss: 2.1196932792663574
Validation loss: 2.1654921174049377

Epoch: 6| Step: 11
Training loss: 1.4045369625091553
Validation loss: 2.155312200387319

Epoch: 6| Step: 12
Training loss: 1.6718559265136719
Validation loss: 2.165584921836853

Epoch: 6| Step: 13
Training loss: 2.5534749031066895
Validation loss: 2.16881654659907

Epoch: 226| Step: 0
Training loss: 1.354145884513855
Validation loss: 2.178824325402578

Epoch: 6| Step: 1
Training loss: 1.4979228973388672
Validation loss: 2.193986415863037

Epoch: 6| Step: 2
Training loss: 1.4170647859573364
Validation loss: 2.1809895833333335

Epoch: 6| Step: 3
Training loss: 1.6099590063095093
Validation loss: 2.1730393369992576

Epoch: 6| Step: 4
Training loss: 2.195596218109131
Validation loss: 2.199179550011953

Epoch: 6| Step: 5
Training loss: 1.9569969177246094
Validation loss: 2.1776633858680725

Epoch: 6| Step: 6
Training loss: 2.203580141067505
Validation loss: 2.1760134100914

Epoch: 6| Step: 7
Training loss: 1.9893275499343872
Validation loss: 2.1878780722618103

Epoch: 6| Step: 8
Training loss: 1.9322848320007324
Validation loss: 2.1902452309926352

Epoch: 6| Step: 9
Training loss: 1.6495240926742554
Validation loss: 2.1619731982549033

Epoch: 6| Step: 10
Training loss: 2.191200017929077
Validation loss: 2.170978526274363

Epoch: 6| Step: 11
Training loss: 1.8688957691192627
Validation loss: 2.1675719022750854

Epoch: 6| Step: 12
Training loss: 1.8535609245300293
Validation loss: 2.177689711252848

Epoch: 6| Step: 13
Training loss: 1.463913083076477
Validation loss: 2.1630560557047525

Epoch: 227| Step: 0
Training loss: 1.394492506980896
Validation loss: 2.1669949293136597

Epoch: 6| Step: 1
Training loss: 1.8891528844833374
Validation loss: 2.172010282675425

Epoch: 6| Step: 2
Training loss: 1.4307150840759277
Validation loss: 2.164109210173289

Epoch: 6| Step: 3
Training loss: 1.5010343790054321
Validation loss: 2.1746246417363486

Epoch: 6| Step: 4
Training loss: 2.229328155517578
Validation loss: 2.179117441177368

Epoch: 6| Step: 5
Training loss: 1.7348597049713135
Validation loss: 2.177472194035848

Epoch: 6| Step: 6
Training loss: 2.348214864730835
Validation loss: 2.1736976901690164

Epoch: 6| Step: 7
Training loss: 1.8389201164245605
Validation loss: 2.173995534578959

Epoch: 6| Step: 8
Training loss: 1.4796632528305054
Validation loss: 2.1759473284085593

Epoch: 6| Step: 9
Training loss: 1.359952688217163
Validation loss: 2.1798713008562722

Epoch: 6| Step: 10
Training loss: 2.306020736694336
Validation loss: 2.1765498320261636

Epoch: 6| Step: 11
Training loss: 2.064281940460205
Validation loss: 2.190500100453695

Epoch: 6| Step: 12
Training loss: 1.6521638631820679
Validation loss: 2.1845886508623757

Epoch: 6| Step: 13
Training loss: 1.9262405633926392
Validation loss: 2.177783966064453

Epoch: 228| Step: 0
Training loss: 1.384289026260376
Validation loss: 2.1699739694595337

Epoch: 6| Step: 1
Training loss: 2.0890262126922607
Validation loss: 2.1719043453534446

Epoch: 6| Step: 2
Training loss: 1.8653916120529175
Validation loss: 2.1985131899515786

Epoch: 6| Step: 3
Training loss: 1.5864307880401611
Validation loss: 2.2095624804496765

Epoch: 6| Step: 4
Training loss: 2.1256484985351562
Validation loss: 2.2003883918126426

Epoch: 6| Step: 5
Training loss: 1.5802891254425049
Validation loss: 2.1913208961486816

Epoch: 6| Step: 6
Training loss: 1.5417782068252563
Validation loss: 2.190782149632772

Epoch: 6| Step: 7
Training loss: 1.3571839332580566
Validation loss: 2.1807920932769775

Epoch: 6| Step: 8
Training loss: 1.8705718517303467
Validation loss: 2.182737350463867

Epoch: 6| Step: 9
Training loss: 2.0482430458068848
Validation loss: 2.1700053612391152

Epoch: 6| Step: 10
Training loss: 1.793588399887085
Validation loss: 2.1573407848676047

Epoch: 6| Step: 11
Training loss: 2.5734074115753174
Validation loss: 2.146867314974467

Epoch: 6| Step: 12
Training loss: 1.4775779247283936
Validation loss: 2.1266510089238486

Epoch: 6| Step: 13
Training loss: 1.8782274723052979
Validation loss: 2.1414127945899963

Epoch: 229| Step: 0
Training loss: 1.5647914409637451
Validation loss: 2.1357972423235574

Epoch: 6| Step: 1
Training loss: 1.6037888526916504
Validation loss: 2.135921061038971

Epoch: 6| Step: 2
Training loss: 2.3431243896484375
Validation loss: 2.149389068285624

Epoch: 6| Step: 3
Training loss: 1.9043058156967163
Validation loss: 2.1397478183110556

Epoch: 6| Step: 4
Training loss: 2.244945764541626
Validation loss: 2.1344447334607444

Epoch: 6| Step: 5
Training loss: 1.728098750114441
Validation loss: 2.129876951376597

Epoch: 6| Step: 6
Training loss: 1.8493597507476807
Validation loss: 2.1556011041005454

Epoch: 6| Step: 7
Training loss: 1.3417198657989502
Validation loss: 2.1566969553629556

Epoch: 6| Step: 8
Training loss: 1.617990255355835
Validation loss: 2.1528950134913125

Epoch: 6| Step: 9
Training loss: 1.8430910110473633
Validation loss: 2.1526560386021933

Epoch: 6| Step: 10
Training loss: 1.3672401905059814
Validation loss: 2.158041020234426

Epoch: 6| Step: 11
Training loss: 2.0179271697998047
Validation loss: 2.16555909315745

Epoch: 6| Step: 12
Training loss: 1.877692699432373
Validation loss: 2.165487806002299

Epoch: 6| Step: 13
Training loss: 1.6547038555145264
Validation loss: 2.2026061415672302

Epoch: 230| Step: 0
Training loss: 2.0658652782440186
Validation loss: 2.1900753180185952

Epoch: 6| Step: 1
Training loss: 1.4336202144622803
Validation loss: 2.1879348754882812

Epoch: 6| Step: 2
Training loss: 2.0552923679351807
Validation loss: 2.1776272853215537

Epoch: 6| Step: 3
Training loss: 1.4365406036376953
Validation loss: 2.1740224758783975

Epoch: 6| Step: 4
Training loss: 1.6732020378112793
Validation loss: 2.1657761931419373

Epoch: 6| Step: 5
Training loss: 1.5474578142166138
Validation loss: 2.1861839095751443

Epoch: 6| Step: 6
Training loss: 1.89439857006073
Validation loss: 2.1863794326782227

Epoch: 6| Step: 7
Training loss: 1.6175143718719482
Validation loss: 2.200269261995951

Epoch: 6| Step: 8
Training loss: 1.6889132261276245
Validation loss: 2.1688684225082397

Epoch: 6| Step: 9
Training loss: 1.7052102088928223
Validation loss: 2.1639893651008606

Epoch: 6| Step: 10
Training loss: 2.276524066925049
Validation loss: 2.174510916074117

Epoch: 6| Step: 11
Training loss: 1.943147897720337
Validation loss: 2.1831135352452598

Epoch: 6| Step: 12
Training loss: 2.129143238067627
Validation loss: 2.1916314363479614

Epoch: 6| Step: 13
Training loss: 1.6705650091171265
Validation loss: 2.177200675010681

Epoch: 231| Step: 0
Training loss: 2.2031774520874023
Validation loss: 2.1761475602785745

Epoch: 6| Step: 1
Training loss: 1.949345588684082
Validation loss: 2.1796026627222695

Epoch: 6| Step: 2
Training loss: 2.1660451889038086
Validation loss: 2.1841999093691506

Epoch: 6| Step: 3
Training loss: 1.971492886543274
Validation loss: 2.1786076029141745

Epoch: 6| Step: 4
Training loss: 1.4128179550170898
Validation loss: 2.175086796283722

Epoch: 6| Step: 5
Training loss: 2.0378284454345703
Validation loss: 2.1849052707354226

Epoch: 6| Step: 6
Training loss: 0.9932452440261841
Validation loss: 2.182194153467814

Epoch: 6| Step: 7
Training loss: 1.808199405670166
Validation loss: 2.1713441610336304

Epoch: 6| Step: 8
Training loss: 1.6509265899658203
Validation loss: 2.1712243358294168

Epoch: 6| Step: 9
Training loss: 2.1035609245300293
Validation loss: 2.170403003692627

Epoch: 6| Step: 10
Training loss: 1.348876953125
Validation loss: 2.1751047174135842

Epoch: 6| Step: 11
Training loss: 1.8792798519134521
Validation loss: 2.190119465192159

Epoch: 6| Step: 12
Training loss: 1.5537633895874023
Validation loss: 2.1877631743748984

Epoch: 6| Step: 13
Training loss: 1.6907415390014648
Validation loss: 2.1840662360191345

Epoch: 232| Step: 0
Training loss: 2.0997045040130615
Validation loss: 2.170382777849833

Epoch: 6| Step: 1
Training loss: 1.675220012664795
Validation loss: 2.1455467542012534

Epoch: 6| Step: 2
Training loss: 2.0315499305725098
Validation loss: 2.1475274562835693

Epoch: 6| Step: 3
Training loss: 1.315756916999817
Validation loss: 2.1362791856129966

Epoch: 6| Step: 4
Training loss: 2.0209527015686035
Validation loss: 2.1597806016604104

Epoch: 6| Step: 5
Training loss: 1.9492459297180176
Validation loss: 2.157584091027578

Epoch: 6| Step: 6
Training loss: 1.7493674755096436
Validation loss: 2.1568068265914917

Epoch: 6| Step: 7
Training loss: 1.3765746355056763
Validation loss: 2.1459470987319946

Epoch: 6| Step: 8
Training loss: 2.047020435333252
Validation loss: 2.1611337463061013

Epoch: 6| Step: 9
Training loss: 1.870235562324524
Validation loss: 2.15137247244517

Epoch: 6| Step: 10
Training loss: 1.6929545402526855
Validation loss: 2.1668297052383423

Epoch: 6| Step: 11
Training loss: 1.6152442693710327
Validation loss: 2.177747587362925

Epoch: 6| Step: 12
Training loss: 2.014493942260742
Validation loss: 2.1604624589284263

Epoch: 6| Step: 13
Training loss: 1.473606824874878
Validation loss: 2.1539672215779624

Epoch: 233| Step: 0
Training loss: 2.0084803104400635
Validation loss: 2.1580252647399902

Epoch: 6| Step: 1
Training loss: 2.0644655227661133
Validation loss: 2.166528105735779

Epoch: 6| Step: 2
Training loss: 1.324117660522461
Validation loss: 2.1795813043912253

Epoch: 6| Step: 3
Training loss: 1.8662352561950684
Validation loss: 2.1868894497553506

Epoch: 6| Step: 4
Training loss: 2.2096974849700928
Validation loss: 2.173829277356466

Epoch: 6| Step: 5
Training loss: 2.564988374710083
Validation loss: 2.1915981769561768

Epoch: 6| Step: 6
Training loss: 1.6112394332885742
Validation loss: 2.1742957830429077

Epoch: 6| Step: 7
Training loss: 1.9405981302261353
Validation loss: 2.1543348828951516

Epoch: 6| Step: 8
Training loss: 1.7376725673675537
Validation loss: 2.1608377496401467

Epoch: 6| Step: 9
Training loss: 1.553005576133728
Validation loss: 2.1502721707026162

Epoch: 6| Step: 10
Training loss: 2.1907899379730225
Validation loss: 2.1493472258249917

Epoch: 6| Step: 11
Training loss: 2.193272829055786
Validation loss: 2.14076821009318

Epoch: 6| Step: 12
Training loss: 1.2801777124404907
Validation loss: 2.148365298906962

Epoch: 6| Step: 13
Training loss: 2.146254777908325
Validation loss: 2.1384893655776978

Epoch: 234| Step: 0
Training loss: 1.740246295928955
Validation loss: 2.1441242694854736

Epoch: 6| Step: 1
Training loss: 1.8700939416885376
Validation loss: 2.148547649383545

Epoch: 6| Step: 2
Training loss: 1.7617237567901611
Validation loss: 2.133614420890808

Epoch: 6| Step: 3
Training loss: 1.7067489624023438
Validation loss: 2.145869235197703

Epoch: 6| Step: 4
Training loss: 1.6568576097488403
Validation loss: 2.160793344179789

Epoch: 6| Step: 5
Training loss: 2.1618242263793945
Validation loss: 2.1485509276390076

Epoch: 6| Step: 6
Training loss: 1.0985971689224243
Validation loss: 2.152128497759501

Epoch: 6| Step: 7
Training loss: 3.059147596359253
Validation loss: 2.1587615807851157

Epoch: 6| Step: 8
Training loss: 1.2537740468978882
Validation loss: 2.1526279846827188

Epoch: 6| Step: 9
Training loss: 2.375910758972168
Validation loss: 2.1358245412508645

Epoch: 6| Step: 10
Training loss: 2.0140533447265625
Validation loss: 2.150890370210012

Epoch: 6| Step: 11
Training loss: 1.7119946479797363
Validation loss: 2.1653324166933694

Epoch: 6| Step: 12
Training loss: 1.8368332386016846
Validation loss: 2.1712058981259665

Epoch: 6| Step: 13
Training loss: 1.079410195350647
Validation loss: 2.1615036924680076

Epoch: 235| Step: 0
Training loss: 1.569958209991455
Validation loss: 2.169284005959829

Epoch: 6| Step: 1
Training loss: 1.3894603252410889
Validation loss: 2.1860265334447226

Epoch: 6| Step: 2
Training loss: 1.697899580001831
Validation loss: 2.176830212275187

Epoch: 6| Step: 3
Training loss: 2.7835216522216797
Validation loss: 2.1644331415494285

Epoch: 6| Step: 4
Training loss: 2.314988136291504
Validation loss: 2.1681267619132996

Epoch: 6| Step: 5
Training loss: 2.097381353378296
Validation loss: 2.167122006416321

Epoch: 6| Step: 6
Training loss: 1.528059482574463
Validation loss: 2.1557653546333313

Epoch: 6| Step: 7
Training loss: 1.1524574756622314
Validation loss: 2.158813754717509

Epoch: 6| Step: 8
Training loss: 1.743894100189209
Validation loss: 2.1877808372179666

Epoch: 6| Step: 9
Training loss: 1.8445539474487305
Validation loss: 2.16675595442454

Epoch: 6| Step: 10
Training loss: 1.4813075065612793
Validation loss: 2.16903289159139

Epoch: 6| Step: 11
Training loss: 1.595838189125061
Validation loss: 2.173265814781189

Epoch: 6| Step: 12
Training loss: 1.4894697666168213
Validation loss: 2.1608238021532693

Epoch: 6| Step: 13
Training loss: 2.2342562675476074
Validation loss: 2.163699130217234

Epoch: 236| Step: 0
Training loss: 2.0303502082824707
Validation loss: 2.184775253136953

Epoch: 6| Step: 1
Training loss: 2.071284770965576
Validation loss: 2.181205769379934

Epoch: 6| Step: 2
Training loss: 1.8041980266571045
Validation loss: 2.187952438990275

Epoch: 6| Step: 3
Training loss: 1.557244062423706
Validation loss: 2.1870481967926025

Epoch: 6| Step: 4
Training loss: 1.3521618843078613
Validation loss: 2.1854568123817444

Epoch: 6| Step: 5
Training loss: 0.8476849794387817
Validation loss: 2.189751942952474

Epoch: 6| Step: 6
Training loss: 1.4514983892440796
Validation loss: 2.18209038178126

Epoch: 6| Step: 7
Training loss: 1.6043072938919067
Validation loss: 2.1764541268348694

Epoch: 6| Step: 8
Training loss: 2.409379482269287
Validation loss: 2.1932790080706277

Epoch: 6| Step: 9
Training loss: 1.2600436210632324
Validation loss: 2.1719329953193665

Epoch: 6| Step: 10
Training loss: 2.348876953125
Validation loss: 2.1829641660054526

Epoch: 6| Step: 11
Training loss: 1.826241135597229
Validation loss: 2.1969757278760276

Epoch: 6| Step: 12
Training loss: 1.55946683883667
Validation loss: 2.1856638391812644

Epoch: 6| Step: 13
Training loss: 2.1160826683044434
Validation loss: 2.1886385679244995

Epoch: 237| Step: 0
Training loss: 1.8135138750076294
Validation loss: 2.1853769024213157

Epoch: 6| Step: 1
Training loss: 2.300995349884033
Validation loss: 2.1867855985959372

Epoch: 6| Step: 2
Training loss: 1.7066800594329834
Validation loss: 2.197222411632538

Epoch: 6| Step: 3
Training loss: 1.6978387832641602
Validation loss: 2.189680794874827

Epoch: 6| Step: 4
Training loss: 1.8348219394683838
Validation loss: 2.173402706782023

Epoch: 6| Step: 5
Training loss: 2.156017780303955
Validation loss: 2.1720611254374185

Epoch: 6| Step: 6
Training loss: 1.7370935678482056
Validation loss: 2.1916621923446655

Epoch: 6| Step: 7
Training loss: 1.5956729650497437
Validation loss: 2.1811074217160544

Epoch: 6| Step: 8
Training loss: 1.7763736248016357
Validation loss: 2.179460287094116

Epoch: 6| Step: 9
Training loss: 1.244655728340149
Validation loss: 2.1746952335039773

Epoch: 6| Step: 10
Training loss: 1.0220779180526733
Validation loss: 2.1806529760360718

Epoch: 6| Step: 11
Training loss: 2.0017566680908203
Validation loss: 2.1734461784362793

Epoch: 6| Step: 12
Training loss: 1.6508985757827759
Validation loss: 2.167492230733236

Epoch: 6| Step: 13
Training loss: 1.7201720476150513
Validation loss: 2.1858224471410117

Epoch: 238| Step: 0
Training loss: 1.5479347705841064
Validation loss: 2.174722154935201

Epoch: 6| Step: 1
Training loss: 1.5113781690597534
Validation loss: 2.172056873639425

Epoch: 6| Step: 2
Training loss: 1.5196127891540527
Validation loss: 2.148642083009084

Epoch: 6| Step: 3
Training loss: 1.9255316257476807
Validation loss: 2.173759341239929

Epoch: 6| Step: 4
Training loss: 2.0641324520111084
Validation loss: 2.1916803320248923

Epoch: 6| Step: 5
Training loss: 1.7795013189315796
Validation loss: 2.1998101472854614

Epoch: 6| Step: 6
Training loss: 1.4293694496154785
Validation loss: 2.2171873847643533

Epoch: 6| Step: 7
Training loss: 1.7044563293457031
Validation loss: 2.211019992828369

Epoch: 6| Step: 8
Training loss: 1.2748136520385742
Validation loss: 2.2070544958114624

Epoch: 6| Step: 9
Training loss: 2.2589993476867676
Validation loss: 2.22833389043808

Epoch: 6| Step: 10
Training loss: 2.3884294033050537
Validation loss: 2.205542266368866

Epoch: 6| Step: 11
Training loss: 1.5115875005722046
Validation loss: 2.1935947140057883

Epoch: 6| Step: 12
Training loss: 1.5621919631958008
Validation loss: 2.2010498444239297

Epoch: 6| Step: 13
Training loss: 1.9523346424102783
Validation loss: 2.197446624437968

Epoch: 239| Step: 0
Training loss: 1.5487383604049683
Validation loss: 2.2219592730204263

Epoch: 6| Step: 1
Training loss: 1.70203697681427
Validation loss: 2.1871019999186196

Epoch: 6| Step: 2
Training loss: 1.1658059358596802
Validation loss: 2.1986385583877563

Epoch: 6| Step: 3
Training loss: 2.435269832611084
Validation loss: 2.2044551571210227

Epoch: 6| Step: 4
Training loss: 2.587592124938965
Validation loss: 2.2079299887021384

Epoch: 6| Step: 5
Training loss: 1.4789478778839111
Validation loss: 2.205565591653188

Epoch: 6| Step: 6
Training loss: 1.1902987957000732
Validation loss: 2.1953702370325723

Epoch: 6| Step: 7
Training loss: 1.9506176710128784
Validation loss: 2.2076671918233237

Epoch: 6| Step: 8
Training loss: 1.5990958213806152
Validation loss: 2.211781640847524

Epoch: 6| Step: 9
Training loss: 1.5905892848968506
Validation loss: 2.2037845849990845

Epoch: 6| Step: 10
Training loss: 1.957722544670105
Validation loss: 2.2062280575434365

Epoch: 6| Step: 11
Training loss: 1.5642876625061035
Validation loss: 2.2183252970377603

Epoch: 6| Step: 12
Training loss: 1.7244396209716797
Validation loss: 2.230278253555298

Epoch: 6| Step: 13
Training loss: 1.6673328876495361
Validation loss: 2.219140807787577

Epoch: 240| Step: 0
Training loss: 2.0167083740234375
Validation loss: 2.183805604775747

Epoch: 6| Step: 1
Training loss: 1.94523286819458
Validation loss: 2.16612301270167

Epoch: 6| Step: 2
Training loss: 1.3948105573654175
Validation loss: 2.170435647169749

Epoch: 6| Step: 3
Training loss: 2.35821270942688
Validation loss: 2.1520089705785117

Epoch: 6| Step: 4
Training loss: 2.1903138160705566
Validation loss: 2.1616716583569846

Epoch: 6| Step: 5
Training loss: 0.9913759231567383
Validation loss: 2.157763918240865

Epoch: 6| Step: 6
Training loss: 1.0367984771728516
Validation loss: 2.1572361389795938

Epoch: 6| Step: 7
Training loss: 2.023045539855957
Validation loss: 2.1589569449424744

Epoch: 6| Step: 8
Training loss: 1.9266204833984375
Validation loss: 2.191730260848999

Epoch: 6| Step: 9
Training loss: 1.748354434967041
Validation loss: 2.192502419153849

Epoch: 6| Step: 10
Training loss: 1.4782907962799072
Validation loss: 2.189670145511627

Epoch: 6| Step: 11
Training loss: 1.676905870437622
Validation loss: 2.1797343691190085

Epoch: 6| Step: 12
Training loss: 1.4825870990753174
Validation loss: 2.206206719080607

Epoch: 6| Step: 13
Training loss: 1.6879206895828247
Validation loss: 2.17379363377889

Epoch: 241| Step: 0
Training loss: 1.7471089363098145
Validation loss: 2.204833666483561

Epoch: 6| Step: 1
Training loss: 1.6295031309127808
Validation loss: 2.1665979623794556

Epoch: 6| Step: 2
Training loss: 1.4234042167663574
Validation loss: 2.187378446261088

Epoch: 6| Step: 3
Training loss: 1.7819921970367432
Validation loss: 2.196612000465393

Epoch: 6| Step: 4
Training loss: 1.503035306930542
Validation loss: 2.196623663107554

Epoch: 6| Step: 5
Training loss: 1.4520180225372314
Validation loss: 2.19513205687205

Epoch: 6| Step: 6
Training loss: 2.6866443157196045
Validation loss: 2.187666952610016

Epoch: 6| Step: 7
Training loss: 1.6746788024902344
Validation loss: 2.2115919987360635

Epoch: 6| Step: 8
Training loss: 1.4489814043045044
Validation loss: 2.202918589115143

Epoch: 6| Step: 9
Training loss: 1.3186559677124023
Validation loss: 2.189234495162964

Epoch: 6| Step: 10
Training loss: 1.1711170673370361
Validation loss: 2.1927401026089988

Epoch: 6| Step: 11
Training loss: 2.3056328296661377
Validation loss: 2.2071800231933594

Epoch: 6| Step: 12
Training loss: 1.814972996711731
Validation loss: 2.2125441431999207

Epoch: 6| Step: 13
Training loss: 2.055793046951294
Validation loss: 2.212868352731069

Epoch: 242| Step: 0
Training loss: 1.8288010358810425
Validation loss: 2.19897989432017

Epoch: 6| Step: 1
Training loss: 1.6197819709777832
Validation loss: 2.1896610657374063

Epoch: 6| Step: 2
Training loss: 2.4395062923431396
Validation loss: 2.210261126359304

Epoch: 6| Step: 3
Training loss: 2.006072998046875
Validation loss: 2.204770108064016

Epoch: 6| Step: 4
Training loss: 1.9285459518432617
Validation loss: 2.2046279907226562

Epoch: 6| Step: 5
Training loss: 1.6649082899093628
Validation loss: 2.2026950120925903

Epoch: 6| Step: 6
Training loss: 1.859384536743164
Validation loss: 2.1890576481819153

Epoch: 6| Step: 7
Training loss: 1.8383253812789917
Validation loss: 2.1883294185002646

Epoch: 6| Step: 8
Training loss: 2.1250574588775635
Validation loss: 2.2131293614705405

Epoch: 6| Step: 9
Training loss: 1.9359560012817383
Validation loss: 2.221642176310221

Epoch: 6| Step: 10
Training loss: 1.36198091506958
Validation loss: 2.1897638042767844

Epoch: 6| Step: 11
Training loss: 0.9912562370300293
Validation loss: 2.190632780392965

Epoch: 6| Step: 12
Training loss: 1.1303397417068481
Validation loss: 2.188204844792684

Epoch: 6| Step: 13
Training loss: 1.2098102569580078
Validation loss: 2.1584429343541465

Epoch: 243| Step: 0
Training loss: 1.8142883777618408
Validation loss: 2.1745153268178306

Epoch: 6| Step: 1
Training loss: 1.566161036491394
Validation loss: 2.1884400447209678

Epoch: 6| Step: 2
Training loss: 1.7550854682922363
Validation loss: 2.1735987861951194

Epoch: 6| Step: 3
Training loss: 1.804103970527649
Validation loss: 2.157162288824717

Epoch: 6| Step: 4
Training loss: 1.4786794185638428
Validation loss: 2.1608931024869285

Epoch: 6| Step: 5
Training loss: 1.6265051364898682
Validation loss: 2.161778469880422

Epoch: 6| Step: 6
Training loss: 0.917407751083374
Validation loss: 2.173698286215464

Epoch: 6| Step: 7
Training loss: 2.295334577560425
Validation loss: 2.1750453313191733

Epoch: 6| Step: 8
Training loss: 2.584610939025879
Validation loss: 2.177789866924286

Epoch: 6| Step: 9
Training loss: 1.6243094205856323
Validation loss: 2.1787267923355103

Epoch: 6| Step: 10
Training loss: 1.8509248495101929
Validation loss: 2.1637972593307495

Epoch: 6| Step: 11
Training loss: 1.483686923980713
Validation loss: 2.1529366970062256

Epoch: 6| Step: 12
Training loss: 1.5833699703216553
Validation loss: 2.150252123673757

Epoch: 6| Step: 13
Training loss: 2.0720932483673096
Validation loss: 2.172765374183655

Epoch: 244| Step: 0
Training loss: 3.0788073539733887
Validation loss: 2.1721357504526773

Epoch: 6| Step: 1
Training loss: 1.592864751815796
Validation loss: 2.1565520564715066

Epoch: 6| Step: 2
Training loss: 1.1196463108062744
Validation loss: 2.1671170790990195

Epoch: 6| Step: 3
Training loss: 1.587843894958496
Validation loss: 2.181314686934153

Epoch: 6| Step: 4
Training loss: 1.3515887260437012
Validation loss: 2.183638075987498

Epoch: 6| Step: 5
Training loss: 1.5778318643569946
Validation loss: 2.1676029364267984

Epoch: 6| Step: 6
Training loss: 1.7776620388031006
Validation loss: 2.17172505458196

Epoch: 6| Step: 7
Training loss: 2.361349582672119
Validation loss: 2.1605182886123657

Epoch: 6| Step: 8
Training loss: 1.6442829370498657
Validation loss: 2.155005077521006

Epoch: 6| Step: 9
Training loss: 1.5165846347808838
Validation loss: 2.1655514438947043

Epoch: 6| Step: 10
Training loss: 2.2457919120788574
Validation loss: 2.1803417603174844

Epoch: 6| Step: 11
Training loss: 1.1417826414108276
Validation loss: 2.1552393039067588

Epoch: 6| Step: 12
Training loss: 1.5884865522384644
Validation loss: 2.1551596323649087

Epoch: 6| Step: 13
Training loss: 1.3984668254852295
Validation loss: 2.161238133907318

Epoch: 245| Step: 0
Training loss: 1.925667643547058
Validation loss: 2.155224402745565

Epoch: 6| Step: 1
Training loss: 1.9432532787322998
Validation loss: 2.1417930722236633

Epoch: 6| Step: 2
Training loss: 2.080003499984741
Validation loss: 2.1636252204577127

Epoch: 6| Step: 3
Training loss: 1.70838463306427
Validation loss: 2.1433788339296975

Epoch: 6| Step: 4
Training loss: 2.4284820556640625
Validation loss: 2.151726543903351

Epoch: 6| Step: 5
Training loss: 1.5088722705841064
Validation loss: 2.1661633253097534

Epoch: 6| Step: 6
Training loss: 1.9521921873092651
Validation loss: 2.172059714794159

Epoch: 6| Step: 7
Training loss: 1.8634161949157715
Validation loss: 2.1723479628562927

Epoch: 6| Step: 8
Training loss: 1.1649831533432007
Validation loss: 2.1707024772961936

Epoch: 6| Step: 9
Training loss: 1.030557632446289
Validation loss: 2.1744003693262735

Epoch: 6| Step: 10
Training loss: 1.5142465829849243
Validation loss: 2.1582295099894204

Epoch: 6| Step: 11
Training loss: 1.5345065593719482
Validation loss: 2.2116138140360513

Epoch: 6| Step: 12
Training loss: 1.6217820644378662
Validation loss: 2.2038190762201944

Epoch: 6| Step: 13
Training loss: 2.019256830215454
Validation loss: 2.206362009048462

Epoch: 246| Step: 0
Training loss: 1.480144739151001
Validation loss: 2.2020989656448364

Epoch: 6| Step: 1
Training loss: 1.766553521156311
Validation loss: 2.2356682419776917

Epoch: 6| Step: 2
Training loss: 1.8262643814086914
Validation loss: 2.204688469568888

Epoch: 6| Step: 3
Training loss: 2.1716012954711914
Validation loss: 2.1940149863560996

Epoch: 6| Step: 4
Training loss: 1.5749821662902832
Validation loss: 2.203573723634084

Epoch: 6| Step: 5
Training loss: 1.9245113134384155
Validation loss: 2.1772169272104898

Epoch: 6| Step: 6
Training loss: 2.3902244567871094
Validation loss: 2.1714255611101785

Epoch: 6| Step: 7
Training loss: 1.5894997119903564
Validation loss: 2.184195339679718

Epoch: 6| Step: 8
Training loss: 1.8020448684692383
Validation loss: 2.2077911297480264

Epoch: 6| Step: 9
Training loss: 1.116834044456482
Validation loss: 2.191408852736155

Epoch: 6| Step: 10
Training loss: 1.6398355960845947
Validation loss: 2.188482860724131

Epoch: 6| Step: 11
Training loss: 2.053784132003784
Validation loss: 2.1907315651575723

Epoch: 6| Step: 12
Training loss: 1.350196123123169
Validation loss: 2.2133246461550393

Epoch: 6| Step: 13
Training loss: 1.0694299936294556
Validation loss: 2.2010151147842407

Epoch: 247| Step: 0
Training loss: 1.2136353254318237
Validation loss: 2.2105117638905845

Epoch: 6| Step: 1
Training loss: 1.153357744216919
Validation loss: 2.1951080362002053

Epoch: 6| Step: 2
Training loss: 1.7473504543304443
Validation loss: 2.2033023834228516

Epoch: 6| Step: 3
Training loss: 1.456462025642395
Validation loss: 2.1999017000198364

Epoch: 6| Step: 4
Training loss: 1.7124745845794678
Validation loss: 2.201326588789622

Epoch: 6| Step: 5
Training loss: 1.211641550064087
Validation loss: 2.204459766546885

Epoch: 6| Step: 6
Training loss: 2.3003673553466797
Validation loss: 2.2105695009231567

Epoch: 6| Step: 7
Training loss: 2.377678871154785
Validation loss: 2.204669257005056

Epoch: 6| Step: 8
Training loss: 1.431606411933899
Validation loss: 2.1970233718554177

Epoch: 6| Step: 9
Training loss: 2.134342670440674
Validation loss: 2.1971030831336975

Epoch: 6| Step: 10
Training loss: 1.768571138381958
Validation loss: 2.190704027811686

Epoch: 6| Step: 11
Training loss: 2.1746740341186523
Validation loss: 2.2123937606811523

Epoch: 6| Step: 12
Training loss: 1.2985512018203735
Validation loss: 2.1942759354909263

Epoch: 6| Step: 13
Training loss: 1.4760735034942627
Validation loss: 2.1918392380078635

Epoch: 248| Step: 0
Training loss: 1.7356925010681152
Validation loss: 2.1860153873761496

Epoch: 6| Step: 1
Training loss: 1.9427205324172974
Validation loss: 2.168718934059143

Epoch: 6| Step: 2
Training loss: 1.169402837753296
Validation loss: 2.2032677133878074

Epoch: 6| Step: 3
Training loss: 1.327073097229004
Validation loss: 2.214482069015503

Epoch: 6| Step: 4
Training loss: 2.640638589859009
Validation loss: 2.192503571510315

Epoch: 6| Step: 5
Training loss: 1.8279434442520142
Validation loss: 2.2115384538968406

Epoch: 6| Step: 6
Training loss: 1.7178596258163452
Validation loss: 2.208935300509135

Epoch: 6| Step: 7
Training loss: 1.691662311553955
Validation loss: 2.2176916201909385

Epoch: 6| Step: 8
Training loss: 2.3006887435913086
Validation loss: 2.213403602441152

Epoch: 6| Step: 9
Training loss: 1.2342551946640015
Validation loss: 2.2063163916269937

Epoch: 6| Step: 10
Training loss: 1.4651463031768799
Validation loss: 2.1744864185651145

Epoch: 6| Step: 11
Training loss: 1.4135843515396118
Validation loss: 2.1672222216924033

Epoch: 6| Step: 12
Training loss: 1.9877538681030273
Validation loss: 2.1685916582743325

Epoch: 6| Step: 13
Training loss: 1.2577691078186035
Validation loss: 2.1541937987009683

Epoch: 249| Step: 0
Training loss: 1.8166873455047607
Validation loss: 2.1688316067059836

Epoch: 6| Step: 1
Training loss: 1.576181173324585
Validation loss: 2.161450823148092

Epoch: 6| Step: 2
Training loss: 1.154186487197876
Validation loss: 2.1784547170003257

Epoch: 6| Step: 3
Training loss: 1.7760465145111084
Validation loss: 2.1695807774861655

Epoch: 6| Step: 4
Training loss: 0.9324197769165039
Validation loss: 2.1870593627293906

Epoch: 6| Step: 5
Training loss: 1.476718783378601
Validation loss: 2.2147722045580545

Epoch: 6| Step: 6
Training loss: 1.3677822351455688
Validation loss: 2.226903716723124

Epoch: 6| Step: 7
Training loss: 1.626953363418579
Validation loss: 2.2198626001675925

Epoch: 6| Step: 8
Training loss: 2.723550319671631
Validation loss: 2.2024627725283303

Epoch: 6| Step: 9
Training loss: 2.30354642868042
Validation loss: 2.212355077266693

Epoch: 6| Step: 10
Training loss: 1.8578386306762695
Validation loss: 2.2142292062441506

Epoch: 6| Step: 11
Training loss: 1.5193315744400024
Validation loss: 2.2237227161725364

Epoch: 6| Step: 12
Training loss: 1.3464218378067017
Validation loss: 2.230433444182078

Epoch: 6| Step: 13
Training loss: 1.8545054197311401
Validation loss: 2.2287211418151855

Epoch: 250| Step: 0
Training loss: 1.6798501014709473
Validation loss: 2.1999318997065225

Epoch: 6| Step: 1
Training loss: 1.4936072826385498
Validation loss: 2.2044350107510886

Epoch: 6| Step: 2
Training loss: 1.7561821937561035
Validation loss: 2.203972339630127

Epoch: 6| Step: 3
Training loss: 1.341292142868042
Validation loss: 2.2382938464482627

Epoch: 6| Step: 4
Training loss: 1.615817904472351
Validation loss: 2.195586303869883

Epoch: 6| Step: 5
Training loss: 2.1067163944244385
Validation loss: 2.2131717801094055

Epoch: 6| Step: 6
Training loss: 1.9621036052703857
Validation loss: 2.2317353884379068

Epoch: 6| Step: 7
Training loss: 1.9161999225616455
Validation loss: 2.2086085279782615

Epoch: 6| Step: 8
Training loss: 1.9251171350479126
Validation loss: 2.1902387142181396

Epoch: 6| Step: 9
Training loss: 1.2902048826217651
Validation loss: 2.200552304585775

Epoch: 6| Step: 10
Training loss: 1.7897529602050781
Validation loss: 2.2131897807121277

Epoch: 6| Step: 11
Training loss: 1.3168795108795166
Validation loss: 2.198298613230387

Epoch: 6| Step: 12
Training loss: 2.259949207305908
Validation loss: 2.2037396828333535

Epoch: 6| Step: 13
Training loss: 1.0851008892059326
Validation loss: 2.201879302660624

Epoch: 251| Step: 0
Training loss: 1.3989324569702148
Validation loss: 2.194815158843994

Epoch: 6| Step: 1
Training loss: 1.9851093292236328
Validation loss: 2.208113352457682

Epoch: 6| Step: 2
Training loss: 1.124959111213684
Validation loss: 2.206808646519979

Epoch: 6| Step: 3
Training loss: 2.1756067276000977
Validation loss: 2.207448164621989

Epoch: 6| Step: 4
Training loss: 1.6122417449951172
Validation loss: 2.219597041606903

Epoch: 6| Step: 5
Training loss: 1.3851367235183716
Validation loss: 2.206640621026357

Epoch: 6| Step: 6
Training loss: 1.6359624862670898
Validation loss: 2.2111390829086304

Epoch: 6| Step: 7
Training loss: 1.3014789819717407
Validation loss: 2.187673509120941

Epoch: 6| Step: 8
Training loss: 1.8568809032440186
Validation loss: 2.1821178793907166

Epoch: 6| Step: 9
Training loss: 1.3400788307189941
Validation loss: 2.1856614351272583

Epoch: 6| Step: 10
Training loss: 2.2413928508758545
Validation loss: 2.2102118730545044

Epoch: 6| Step: 11
Training loss: 1.570462703704834
Validation loss: 2.215546727180481

Epoch: 6| Step: 12
Training loss: 1.7067170143127441
Validation loss: 2.1857415040334067

Epoch: 6| Step: 13
Training loss: 1.6991565227508545
Validation loss: 2.220995565255483

Epoch: 252| Step: 0
Training loss: 1.8004975318908691
Validation loss: 2.215764363606771

Epoch: 6| Step: 1
Training loss: 1.904544711112976
Validation loss: 2.189626673857371

Epoch: 6| Step: 2
Training loss: 1.0278874635696411
Validation loss: 2.20370614528656

Epoch: 6| Step: 3
Training loss: 1.8198436498641968
Validation loss: 2.1951940457026162

Epoch: 6| Step: 4
Training loss: 2.0797808170318604
Validation loss: 2.221544106801351

Epoch: 6| Step: 5
Training loss: 1.8155975341796875
Validation loss: 2.2031911611557007

Epoch: 6| Step: 6
Training loss: 1.327944040298462
Validation loss: 2.1948368151982627

Epoch: 6| Step: 7
Training loss: 1.6639736890792847
Validation loss: 2.2226617336273193

Epoch: 6| Step: 8
Training loss: 1.4106457233428955
Validation loss: 2.224582016468048

Epoch: 6| Step: 9
Training loss: 2.3701436519622803
Validation loss: 2.231472134590149

Epoch: 6| Step: 10
Training loss: 1.2860057353973389
Validation loss: 2.215036710103353

Epoch: 6| Step: 11
Training loss: 1.9675068855285645
Validation loss: 2.2174057165781655

Epoch: 6| Step: 12
Training loss: 1.6429238319396973
Validation loss: 2.2043880621592202

Epoch: 6| Step: 13
Training loss: 1.4185044765472412
Validation loss: 2.183454076449076

Epoch: 253| Step: 0
Training loss: 1.2490463256835938
Validation loss: 2.199745535850525

Epoch: 6| Step: 1
Training loss: 2.093796730041504
Validation loss: 2.198363463083903

Epoch: 6| Step: 2
Training loss: 1.570004940032959
Validation loss: 2.1922901272773743

Epoch: 6| Step: 3
Training loss: 1.9029332399368286
Validation loss: 2.201965113480886

Epoch: 6| Step: 4
Training loss: 2.3573410511016846
Validation loss: 2.187669336795807

Epoch: 6| Step: 5
Training loss: 1.1939767599105835
Validation loss: 2.216664512952169

Epoch: 6| Step: 6
Training loss: 1.690314769744873
Validation loss: 2.2085233330726624

Epoch: 6| Step: 7
Training loss: 1.3782086372375488
Validation loss: 2.229978024959564

Epoch: 6| Step: 8
Training loss: 2.654186487197876
Validation loss: 2.2135456999142966

Epoch: 6| Step: 9
Training loss: 1.3640239238739014
Validation loss: 2.192766010761261

Epoch: 6| Step: 10
Training loss: 1.4020800590515137
Validation loss: 2.1970787843068442

Epoch: 6| Step: 11
Training loss: 1.5176019668579102
Validation loss: 2.222039779027303

Epoch: 6| Step: 12
Training loss: 1.9163892269134521
Validation loss: 2.1942859093348184

Epoch: 6| Step: 13
Training loss: 1.252488374710083
Validation loss: 2.1920557022094727

Epoch: 254| Step: 0
Training loss: 1.303768515586853
Validation loss: 2.198718865712484

Epoch: 6| Step: 1
Training loss: 1.1384519338607788
Validation loss: 2.1911353270212808

Epoch: 6| Step: 2
Training loss: 1.7380461692810059
Validation loss: 2.187317728996277

Epoch: 6| Step: 3
Training loss: 2.301638603210449
Validation loss: 2.1762728691101074

Epoch: 6| Step: 4
Training loss: 2.1885671615600586
Validation loss: 2.155442953109741

Epoch: 6| Step: 5
Training loss: 1.3478491306304932
Validation loss: 2.1567801237106323

Epoch: 6| Step: 6
Training loss: 1.5118396282196045
Validation loss: 2.1842519640922546

Epoch: 6| Step: 7
Training loss: 1.9867019653320312
Validation loss: 2.199523707230886

Epoch: 6| Step: 8
Training loss: 1.6623218059539795
Validation loss: 2.2055759827295938

Epoch: 6| Step: 9
Training loss: 1.0799856185913086
Validation loss: 2.205638309319814

Epoch: 6| Step: 10
Training loss: 2.1898369789123535
Validation loss: 2.220340609550476

Epoch: 6| Step: 11
Training loss: 1.096258521080017
Validation loss: 2.2312577168146768

Epoch: 6| Step: 12
Training loss: 1.8113796710968018
Validation loss: 2.2412858605384827

Epoch: 6| Step: 13
Training loss: 1.8292639255523682
Validation loss: 2.235068599383036

Epoch: 255| Step: 0
Training loss: 1.3629274368286133
Validation loss: 2.24956876039505

Epoch: 6| Step: 1
Training loss: 1.70713210105896
Validation loss: 2.2328590552012124

Epoch: 6| Step: 2
Training loss: 1.562770128250122
Validation loss: 2.2068428993225098

Epoch: 6| Step: 3
Training loss: 1.675893783569336
Validation loss: 2.217843492825826

Epoch: 6| Step: 4
Training loss: 1.4747673273086548
Validation loss: 2.209320286909739

Epoch: 6| Step: 5
Training loss: 1.6696891784667969
Validation loss: 2.224755346775055

Epoch: 6| Step: 6
Training loss: 2.030959129333496
Validation loss: 2.190766394138336

Epoch: 6| Step: 7
Training loss: 1.643844485282898
Validation loss: 2.171938935915629

Epoch: 6| Step: 8
Training loss: 1.3274314403533936
Validation loss: 2.2021778424580893

Epoch: 6| Step: 9
Training loss: 1.6266272068023682
Validation loss: 2.192151208718618

Epoch: 6| Step: 10
Training loss: 1.8182969093322754
Validation loss: 2.188532590866089

Epoch: 6| Step: 11
Training loss: 2.0660369396209717
Validation loss: 2.2212847073872886

Epoch: 6| Step: 12
Training loss: 2.0462982654571533
Validation loss: 2.224148710568746

Epoch: 6| Step: 13
Training loss: 1.7778147459030151
Validation loss: 2.228000740210215

Epoch: 256| Step: 0
Training loss: 1.843371868133545
Validation loss: 2.2045141458511353

Epoch: 6| Step: 1
Training loss: 2.336804151535034
Validation loss: 2.2125452359517417

Epoch: 6| Step: 2
Training loss: 2.390688180923462
Validation loss: 2.2137464483579

Epoch: 6| Step: 3
Training loss: 1.6525301933288574
Validation loss: 2.216102143128713

Epoch: 6| Step: 4
Training loss: 1.1781127452850342
Validation loss: 2.192080100377401

Epoch: 6| Step: 5
Training loss: 1.2002167701721191
Validation loss: 2.195981423060099

Epoch: 6| Step: 6
Training loss: 1.8269402980804443
Validation loss: 2.178639570871989

Epoch: 6| Step: 7
Training loss: 0.9992074966430664
Validation loss: 2.1807931860287986

Epoch: 6| Step: 8
Training loss: 1.4818614721298218
Validation loss: 2.1643928488095603

Epoch: 6| Step: 9
Training loss: 1.6611990928649902
Validation loss: 2.161754329999288

Epoch: 6| Step: 10
Training loss: 2.817030906677246
Validation loss: 2.1614976922671

Epoch: 6| Step: 11
Training loss: 1.3094055652618408
Validation loss: 2.1502829988797507

Epoch: 6| Step: 12
Training loss: 1.8786357641220093
Validation loss: 2.161520024140676

Epoch: 6| Step: 13
Training loss: 1.711940050125122
Validation loss: 2.158351719379425

Epoch: 257| Step: 0
Training loss: 1.7025930881500244
Validation loss: 2.1629913647969565

Epoch: 6| Step: 1
Training loss: 1.7080811262130737
Validation loss: 2.1561296582221985

Epoch: 6| Step: 2
Training loss: 1.4935575723648071
Validation loss: 2.175836761792501

Epoch: 6| Step: 3
Training loss: 1.2957433462142944
Validation loss: 2.164279023806254

Epoch: 6| Step: 4
Training loss: 2.064344644546509
Validation loss: 2.1811696489652

Epoch: 6| Step: 5
Training loss: 1.3583247661590576
Validation loss: 2.181010663509369

Epoch: 6| Step: 6
Training loss: 1.8192716836929321
Validation loss: 2.188566962877909

Epoch: 6| Step: 7
Training loss: 1.6212806701660156
Validation loss: 2.2018147706985474

Epoch: 6| Step: 8
Training loss: 1.971685767173767
Validation loss: 2.207533299922943

Epoch: 6| Step: 9
Training loss: 1.4988263845443726
Validation loss: 2.1884832183519998

Epoch: 6| Step: 10
Training loss: 2.660534620285034
Validation loss: 2.212407946586609

Epoch: 6| Step: 11
Training loss: 1.715159296989441
Validation loss: 2.231588145097097

Epoch: 6| Step: 12
Training loss: 1.669313907623291
Validation loss: 2.226997752984365

Epoch: 6| Step: 13
Training loss: 1.8613488674163818
Validation loss: 2.2186968525250754

Epoch: 258| Step: 0
Training loss: 2.040069103240967
Validation loss: 2.2001821994781494

Epoch: 6| Step: 1
Training loss: 1.1178289651870728
Validation loss: 2.222462276617686

Epoch: 6| Step: 2
Training loss: 1.4111117124557495
Validation loss: 2.22906223932902

Epoch: 6| Step: 3
Training loss: 1.0163625478744507
Validation loss: 2.1992557048797607

Epoch: 6| Step: 4
Training loss: 2.0437819957733154
Validation loss: 2.186419129371643

Epoch: 6| Step: 5
Training loss: 1.9712646007537842
Validation loss: 2.183561603228251

Epoch: 6| Step: 6
Training loss: 1.5097277164459229
Validation loss: 2.185059150060018

Epoch: 6| Step: 7
Training loss: 1.628145694732666
Validation loss: 2.168732682863871

Epoch: 6| Step: 8
Training loss: 2.547595739364624
Validation loss: 2.1760811607042947

Epoch: 6| Step: 9
Training loss: 1.3070223331451416
Validation loss: 2.1611401240030923

Epoch: 6| Step: 10
Training loss: 1.1049158573150635
Validation loss: 2.1727386315663657

Epoch: 6| Step: 11
Training loss: 1.7103638648986816
Validation loss: 2.177962005138397

Epoch: 6| Step: 12
Training loss: 2.1737234592437744
Validation loss: 2.1601984898249307

Epoch: 6| Step: 13
Training loss: 1.437390923500061
Validation loss: 2.1690462827682495

Epoch: 259| Step: 0
Training loss: 1.614064335823059
Validation loss: 2.1766950686772666

Epoch: 6| Step: 1
Training loss: 1.890001893043518
Validation loss: 2.193292717138926

Epoch: 6| Step: 2
Training loss: 1.4220991134643555
Validation loss: 2.180313150087992

Epoch: 6| Step: 3
Training loss: 2.166825294494629
Validation loss: 2.1815367341041565

Epoch: 6| Step: 4
Training loss: 1.5587413311004639
Validation loss: 2.1946112314860025

Epoch: 6| Step: 5
Training loss: 1.0581177473068237
Validation loss: 2.187969962755839

Epoch: 6| Step: 6
Training loss: 1.8101969957351685
Validation loss: 2.18816872437795

Epoch: 6| Step: 7
Training loss: 1.0667612552642822
Validation loss: 2.171506881713867

Epoch: 6| Step: 8
Training loss: 1.614682674407959
Validation loss: 2.170688271522522

Epoch: 6| Step: 9
Training loss: 2.0423145294189453
Validation loss: 2.1983712712923684

Epoch: 6| Step: 10
Training loss: 1.9867569208145142
Validation loss: 2.1975273291269937

Epoch: 6| Step: 11
Training loss: 1.9986873865127563
Validation loss: 2.18113382657369

Epoch: 6| Step: 12
Training loss: 1.5488543510437012
Validation loss: 2.1809070905049643

Epoch: 6| Step: 13
Training loss: 1.8358826637268066
Validation loss: 2.1882338722546897

Epoch: 260| Step: 0
Training loss: 1.8369191884994507
Validation loss: 2.202500025431315

Epoch: 6| Step: 1
Training loss: 1.3586595058441162
Validation loss: 2.2083109617233276

Epoch: 6| Step: 2
Training loss: 1.3821667432785034
Validation loss: 2.2061660488446555

Epoch: 6| Step: 3
Training loss: 2.1620421409606934
Validation loss: 2.231599052747091

Epoch: 6| Step: 4
Training loss: 1.3143491744995117
Validation loss: 2.232040067513784

Epoch: 6| Step: 5
Training loss: 1.7544026374816895
Validation loss: 2.2324589093526206

Epoch: 6| Step: 6
Training loss: 1.0601410865783691
Validation loss: 2.218799114227295

Epoch: 6| Step: 7
Training loss: 2.022717237472534
Validation loss: 2.2032089233398438

Epoch: 6| Step: 8
Training loss: 1.2691049575805664
Validation loss: 2.2064507404963174

Epoch: 6| Step: 9
Training loss: 1.793591022491455
Validation loss: 2.1503434578577676

Epoch: 6| Step: 10
Training loss: 1.6470513343811035
Validation loss: 2.164336621761322

Epoch: 6| Step: 11
Training loss: 1.4668248891830444
Validation loss: 2.160140852133433

Epoch: 6| Step: 12
Training loss: 2.3560118675231934
Validation loss: 2.1470998922983804

Epoch: 6| Step: 13
Training loss: 1.6849647760391235
Validation loss: 2.158482770125071

Epoch: 261| Step: 0
Training loss: 1.5750080347061157
Validation loss: 2.136259992917379

Epoch: 6| Step: 1
Training loss: 1.6620159149169922
Validation loss: 2.171652615070343

Epoch: 6| Step: 2
Training loss: 1.6116962432861328
Validation loss: 2.1596580346425376

Epoch: 6| Step: 3
Training loss: 1.2375609874725342
Validation loss: 2.1628383795420327

Epoch: 6| Step: 4
Training loss: 3.1224963665008545
Validation loss: 2.1662282148996987

Epoch: 6| Step: 5
Training loss: 1.6069083213806152
Validation loss: 2.1514631112416587

Epoch: 6| Step: 6
Training loss: 1.4172768592834473
Validation loss: 2.1494650642077127

Epoch: 6| Step: 7
Training loss: 1.6738866567611694
Validation loss: 2.130362570285797

Epoch: 6| Step: 8
Training loss: 1.6421191692352295
Validation loss: 2.1946848233540854

Epoch: 6| Step: 9
Training loss: 1.4050029516220093
Validation loss: 2.2024927934010825

Epoch: 6| Step: 10
Training loss: 1.779599905014038
Validation loss: 2.2275061209996543

Epoch: 6| Step: 11
Training loss: 1.9073882102966309
Validation loss: 2.242330253124237

Epoch: 6| Step: 12
Training loss: 1.2787355184555054
Validation loss: 2.2702681620915732

Epoch: 6| Step: 13
Training loss: 1.626568078994751
Validation loss: 2.221807380517324

Epoch: 262| Step: 0
Training loss: 1.2708295583724976
Validation loss: 2.2786534825960794

Epoch: 6| Step: 1
Training loss: 1.3898597955703735
Validation loss: 2.25173012415568

Epoch: 6| Step: 2
Training loss: 1.9737671613693237
Validation loss: 2.2344517906506858

Epoch: 6| Step: 3
Training loss: 1.129809856414795
Validation loss: 2.2018158435821533

Epoch: 6| Step: 4
Training loss: 1.5482244491577148
Validation loss: 2.191754718621572

Epoch: 6| Step: 5
Training loss: 2.322526216506958
Validation loss: 2.1913917859395347

Epoch: 6| Step: 6
Training loss: 1.6852693557739258
Validation loss: 2.174662788709005

Epoch: 6| Step: 7
Training loss: 1.6894447803497314
Validation loss: 2.191512922445933

Epoch: 6| Step: 8
Training loss: 1.6803492307662964
Validation loss: 2.1790414452552795

Epoch: 6| Step: 9
Training loss: 1.970513939857483
Validation loss: 2.201564530531565

Epoch: 6| Step: 10
Training loss: 1.041081190109253
Validation loss: 2.220165173212687

Epoch: 6| Step: 11
Training loss: 1.8181302547454834
Validation loss: 2.2463934421539307

Epoch: 6| Step: 12
Training loss: 2.199320077896118
Validation loss: 2.260656952857971

Epoch: 6| Step: 13
Training loss: 1.839124083518982
Validation loss: 2.2919575572013855

Epoch: 263| Step: 0
Training loss: 1.530220627784729
Validation loss: 2.282407601674398

Epoch: 6| Step: 1
Training loss: 1.7418677806854248
Validation loss: 2.2837159832318625

Epoch: 6| Step: 2
Training loss: 1.002268671989441
Validation loss: 2.2931111057599387

Epoch: 6| Step: 3
Training loss: 1.8505111932754517
Validation loss: 2.2624603708585105

Epoch: 6| Step: 4
Training loss: 2.3075389862060547
Validation loss: 2.242278238137563

Epoch: 6| Step: 5
Training loss: 1.4425528049468994
Validation loss: 2.236481189727783

Epoch: 6| Step: 6
Training loss: 1.969104290008545
Validation loss: 2.2172011335690818

Epoch: 6| Step: 7
Training loss: 1.7149070501327515
Validation loss: 2.1964274048805237

Epoch: 6| Step: 8
Training loss: 1.4611029624938965
Validation loss: 2.1964058677355447

Epoch: 6| Step: 9
Training loss: 1.097144603729248
Validation loss: 2.2030199766159058

Epoch: 6| Step: 10
Training loss: 1.3755420446395874
Validation loss: 2.1966267228126526

Epoch: 6| Step: 11
Training loss: 1.7713797092437744
Validation loss: 2.1997637152671814

Epoch: 6| Step: 12
Training loss: 2.314121723175049
Validation loss: 2.1770602265993753

Epoch: 6| Step: 13
Training loss: 2.1020145416259766
Validation loss: 2.1624509493509927

Epoch: 264| Step: 0
Training loss: 1.5950758457183838
Validation loss: 2.178550144036611

Epoch: 6| Step: 1
Training loss: 1.6700935363769531
Validation loss: 2.1707958380381265

Epoch: 6| Step: 2
Training loss: 1.7677677869796753
Validation loss: 2.1719679037729898

Epoch: 6| Step: 3
Training loss: 1.4317119121551514
Validation loss: 2.147135615348816

Epoch: 6| Step: 4
Training loss: 1.3402951955795288
Validation loss: 2.1502347787221274

Epoch: 6| Step: 5
Training loss: 1.5010985136032104
Validation loss: 2.1755518118540444

Epoch: 6| Step: 6
Training loss: 1.5885422229766846
Validation loss: 2.161823054154714

Epoch: 6| Step: 7
Training loss: 2.610300064086914
Validation loss: 2.1592012445131936

Epoch: 6| Step: 8
Training loss: 1.617151141166687
Validation loss: 2.1789655486742654

Epoch: 6| Step: 9
Training loss: 1.547372579574585
Validation loss: 2.155610462029775

Epoch: 6| Step: 10
Training loss: 1.2400013208389282
Validation loss: 2.133377730846405

Epoch: 6| Step: 11
Training loss: 1.648591160774231
Validation loss: 2.162746866544088

Epoch: 6| Step: 12
Training loss: 1.738418459892273
Validation loss: 2.1619581977526345

Epoch: 6| Step: 13
Training loss: 1.7267580032348633
Validation loss: 2.17554380496343

Epoch: 265| Step: 0
Training loss: 1.5938358306884766
Validation loss: 2.1645166079203286

Epoch: 6| Step: 1
Training loss: 1.711917757987976
Validation loss: 2.152287741502126

Epoch: 6| Step: 2
Training loss: 1.6964588165283203
Validation loss: 2.175948659578959

Epoch: 6| Step: 3
Training loss: 1.5173563957214355
Validation loss: 2.168980677922567

Epoch: 6| Step: 4
Training loss: 1.8407870531082153
Validation loss: 2.167798161506653

Epoch: 6| Step: 5
Training loss: 1.4320673942565918
Validation loss: 2.206595718860626

Epoch: 6| Step: 6
Training loss: 1.5603376626968384
Validation loss: 2.2382095058759055

Epoch: 6| Step: 7
Training loss: 1.2756476402282715
Validation loss: 2.251047650973002

Epoch: 6| Step: 8
Training loss: 2.1487889289855957
Validation loss: 2.239708344141642

Epoch: 6| Step: 9
Training loss: 1.734143614768982
Validation loss: 2.2570279240608215

Epoch: 6| Step: 10
Training loss: 1.4315804243087769
Validation loss: 2.250584622224172

Epoch: 6| Step: 11
Training loss: 2.2851552963256836
Validation loss: 2.2382174134254456

Epoch: 6| Step: 12
Training loss: 1.635664939880371
Validation loss: 2.228481570879618

Epoch: 6| Step: 13
Training loss: 1.2500510215759277
Validation loss: 2.2026835083961487

Epoch: 266| Step: 0
Training loss: 1.2078990936279297
Validation loss: 2.1971067984898887

Epoch: 6| Step: 1
Training loss: 0.993937075138092
Validation loss: 2.1702731053034463

Epoch: 6| Step: 2
Training loss: 2.3809866905212402
Validation loss: 2.1455506682395935

Epoch: 6| Step: 3
Training loss: 1.7133076190948486
Validation loss: 2.1558112303415933

Epoch: 6| Step: 4
Training loss: 2.2693848609924316
Validation loss: 2.1642250617345176

Epoch: 6| Step: 5
Training loss: 2.1739261150360107
Validation loss: 2.17881711324056

Epoch: 6| Step: 6
Training loss: 1.311329960823059
Validation loss: 2.224315643310547

Epoch: 6| Step: 7
Training loss: 1.3650662899017334
Validation loss: 2.2741123835245767

Epoch: 6| Step: 8
Training loss: 2.2065930366516113
Validation loss: 2.3254098097483316

Epoch: 6| Step: 9
Training loss: 1.3893241882324219
Validation loss: 2.3126691381136575

Epoch: 6| Step: 10
Training loss: 1.5401023626327515
Validation loss: 2.3145995140075684

Epoch: 6| Step: 11
Training loss: 1.398735523223877
Validation loss: 2.2524749636650085

Epoch: 6| Step: 12
Training loss: 2.004819393157959
Validation loss: 2.2238244811693826

Epoch: 6| Step: 13
Training loss: 1.9828095436096191
Validation loss: 2.2176479498545327

Epoch: 267| Step: 0
Training loss: 0.8358978033065796
Validation loss: 2.2082422971725464

Epoch: 6| Step: 1
Training loss: 1.5261166095733643
Validation loss: 2.188930412133535

Epoch: 6| Step: 2
Training loss: 1.564507246017456
Validation loss: 2.1977871855099997

Epoch: 6| Step: 3
Training loss: 1.1205196380615234
Validation loss: 2.2182435393333435

Epoch: 6| Step: 4
Training loss: 1.604688286781311
Validation loss: 2.2216617663701377

Epoch: 6| Step: 5
Training loss: 2.8620662689208984
Validation loss: 2.2280836701393127

Epoch: 6| Step: 6
Training loss: 1.5478004217147827
Validation loss: 2.220590611298879

Epoch: 6| Step: 7
Training loss: 2.1458818912506104
Validation loss: 2.23395699262619

Epoch: 6| Step: 8
Training loss: 2.3678712844848633
Validation loss: 2.2100276947021484

Epoch: 6| Step: 9
Training loss: 2.150933265686035
Validation loss: 2.2243672609329224

Epoch: 6| Step: 10
Training loss: 1.4166779518127441
Validation loss: 2.2265917460123696

Epoch: 6| Step: 11
Training loss: 1.1186637878417969
Validation loss: 2.221678296724955

Epoch: 6| Step: 12
Training loss: 1.1390644311904907
Validation loss: 2.2110976775487265

Epoch: 6| Step: 13
Training loss: 1.545891523361206
Validation loss: 2.239538331826528

Epoch: 268| Step: 0
Training loss: 2.195887804031372
Validation loss: 2.2310425440470376

Epoch: 6| Step: 1
Training loss: 1.3242886066436768
Validation loss: 2.215483784675598

Epoch: 6| Step: 2
Training loss: 1.3416216373443604
Validation loss: 2.233849664529165

Epoch: 6| Step: 3
Training loss: 2.3309402465820312
Validation loss: 2.223063270250956

Epoch: 6| Step: 4
Training loss: 1.4880366325378418
Validation loss: 2.231533944606781

Epoch: 6| Step: 5
Training loss: 1.157843828201294
Validation loss: 2.228902022043864

Epoch: 6| Step: 6
Training loss: 1.3888788223266602
Validation loss: 2.243619521458944

Epoch: 6| Step: 7
Training loss: 1.696361780166626
Validation loss: 2.241541067759196

Epoch: 6| Step: 8
Training loss: 1.492546558380127
Validation loss: 2.2367806831995645

Epoch: 6| Step: 9
Training loss: 1.389564871788025
Validation loss: 2.226198355356852

Epoch: 6| Step: 10
Training loss: 1.1857503652572632
Validation loss: 2.2327020168304443

Epoch: 6| Step: 11
Training loss: 1.5234646797180176
Validation loss: 2.2521872917811074

Epoch: 6| Step: 12
Training loss: 2.040855646133423
Validation loss: 2.2603889107704163

Epoch: 6| Step: 13
Training loss: 2.24641752243042
Validation loss: 2.265583117802938

Epoch: 269| Step: 0
Training loss: 2.4811530113220215
Validation loss: 2.270956734816233

Epoch: 6| Step: 1
Training loss: 1.020887017250061
Validation loss: 2.271322170893351

Epoch: 6| Step: 2
Training loss: 1.3942818641662598
Validation loss: 2.316239058971405

Epoch: 6| Step: 3
Training loss: 1.4522037506103516
Validation loss: 2.297628025213877

Epoch: 6| Step: 4
Training loss: 1.4453243017196655
Validation loss: 2.329542954762777

Epoch: 6| Step: 5
Training loss: 1.7913789749145508
Validation loss: 2.292761047681173

Epoch: 6| Step: 6
Training loss: 1.484265923500061
Validation loss: 2.3077903985977173

Epoch: 6| Step: 7
Training loss: 1.1301380395889282
Validation loss: 2.2929527362187705

Epoch: 6| Step: 8
Training loss: 1.782631278038025
Validation loss: 2.2589120268821716

Epoch: 6| Step: 9
Training loss: 1.476690649986267
Validation loss: 2.263038376967112

Epoch: 6| Step: 10
Training loss: 2.836618423461914
Validation loss: 2.242665688196818

Epoch: 6| Step: 11
Training loss: 2.189282178878784
Validation loss: 2.210486590862274

Epoch: 6| Step: 12
Training loss: 1.3070104122161865
Validation loss: 2.1987492442131042

Epoch: 6| Step: 13
Training loss: 0.9315512180328369
Validation loss: 2.204660693804423

Epoch: 270| Step: 0
Training loss: 1.0555198192596436
Validation loss: 2.216960827509562

Epoch: 6| Step: 1
Training loss: 1.739133358001709
Validation loss: 2.1927520434061685

Epoch: 6| Step: 2
Training loss: 1.6684240102767944
Validation loss: 2.1977846026420593

Epoch: 6| Step: 3
Training loss: 2.271855354309082
Validation loss: 2.1932445764541626

Epoch: 6| Step: 4
Training loss: 1.4278721809387207
Validation loss: 2.1839094956715903

Epoch: 6| Step: 5
Training loss: 1.8176006078720093
Validation loss: 2.199591596921285

Epoch: 6| Step: 6
Training loss: 1.7783246040344238
Validation loss: 2.1919026970863342

Epoch: 6| Step: 7
Training loss: 1.3911447525024414
Validation loss: 2.2038400173187256

Epoch: 6| Step: 8
Training loss: 1.7544341087341309
Validation loss: 2.1993642250696817

Epoch: 6| Step: 9
Training loss: 1.5168774127960205
Validation loss: 2.1778951485951743

Epoch: 6| Step: 10
Training loss: 1.5224506855010986
Validation loss: 2.193158725897471

Epoch: 6| Step: 11
Training loss: 1.429671049118042
Validation loss: 2.184191405773163

Epoch: 6| Step: 12
Training loss: 1.7899842262268066
Validation loss: 2.1714589595794678

Epoch: 6| Step: 13
Training loss: 1.9458717107772827
Validation loss: 2.203745345274607

Epoch: 271| Step: 0
Training loss: 1.5392574071884155
Validation loss: 2.2035363912582397

Epoch: 6| Step: 1
Training loss: 1.9310028553009033
Validation loss: 2.2103143533070884

Epoch: 6| Step: 2
Training loss: 1.624234676361084
Validation loss: 2.2039015094439187

Epoch: 6| Step: 3
Training loss: 1.7968566417694092
Validation loss: 2.204939822355906

Epoch: 6| Step: 4
Training loss: 1.4758213758468628
Validation loss: 2.23215518395106

Epoch: 6| Step: 5
Training loss: 0.7827293872833252
Validation loss: 2.22849311431249

Epoch: 6| Step: 6
Training loss: 2.2334954738616943
Validation loss: 2.2211034297943115

Epoch: 6| Step: 7
Training loss: 1.3717718124389648
Validation loss: 2.236615618069967

Epoch: 6| Step: 8
Training loss: 1.5226129293441772
Validation loss: 2.250530997912089

Epoch: 6| Step: 9
Training loss: 1.2586677074432373
Validation loss: 2.2527915040651956

Epoch: 6| Step: 10
Training loss: 1.8407831192016602
Validation loss: 2.2524133125940957

Epoch: 6| Step: 11
Training loss: 1.905134916305542
Validation loss: 2.2163946827252707

Epoch: 6| Step: 12
Training loss: 1.1959048509597778
Validation loss: 2.241724749406179

Epoch: 6| Step: 13
Training loss: 1.7327024936676025
Validation loss: 2.200192113717397

Epoch: 272| Step: 0
Training loss: 1.7421048879623413
Validation loss: 2.20267516374588

Epoch: 6| Step: 1
Training loss: 1.370927095413208
Validation loss: 2.2263858119646707

Epoch: 6| Step: 2
Training loss: 1.1051183938980103
Validation loss: 2.1924343506495156

Epoch: 6| Step: 3
Training loss: 1.4707584381103516
Validation loss: 2.196210583051046

Epoch: 6| Step: 4
Training loss: 1.335068941116333
Validation loss: 2.1960824728012085

Epoch: 6| Step: 5
Training loss: 2.2473082542419434
Validation loss: 2.2001960277557373

Epoch: 6| Step: 6
Training loss: 1.2607673406600952
Validation loss: 2.188101907571157

Epoch: 6| Step: 7
Training loss: 1.8115575313568115
Validation loss: 2.2314268747965493

Epoch: 6| Step: 8
Training loss: 1.527894377708435
Validation loss: 2.233322242895762

Epoch: 6| Step: 9
Training loss: 2.4428162574768066
Validation loss: 2.234202047189077

Epoch: 6| Step: 10
Training loss: 1.2555474042892456
Validation loss: 2.2453602949778237

Epoch: 6| Step: 11
Training loss: 1.609485387802124
Validation loss: 2.249460200468699

Epoch: 6| Step: 12
Training loss: 2.1162362098693848
Validation loss: 2.2337069511413574

Epoch: 6| Step: 13
Training loss: 1.6765098571777344
Validation loss: 2.23928956190745

Epoch: 273| Step: 0
Training loss: 1.3807764053344727
Validation loss: 2.2885501782099404

Epoch: 6| Step: 1
Training loss: 1.9475071430206299
Validation loss: 2.232714593410492

Epoch: 6| Step: 2
Training loss: 1.4581944942474365
Validation loss: 2.240782101949056

Epoch: 6| Step: 3
Training loss: 1.8151860237121582
Validation loss: 2.2336384057998657

Epoch: 6| Step: 4
Training loss: 2.0341835021972656
Validation loss: 2.233159323533376

Epoch: 6| Step: 5
Training loss: 1.2865815162658691
Validation loss: 2.225510279337565

Epoch: 6| Step: 6
Training loss: 1.4312013387680054
Validation loss: 2.2318907578786216

Epoch: 6| Step: 7
Training loss: 1.4170711040496826
Validation loss: 2.246996442476908

Epoch: 6| Step: 8
Training loss: 1.6870582103729248
Validation loss: 2.2658503651618958

Epoch: 6| Step: 9
Training loss: 0.972210168838501
Validation loss: 2.263211170832316

Epoch: 6| Step: 10
Training loss: 1.8831671476364136
Validation loss: 2.2499223947525024

Epoch: 6| Step: 11
Training loss: 2.0557563304901123
Validation loss: 2.2330007950464883

Epoch: 6| Step: 12
Training loss: 1.6987502574920654
Validation loss: 2.2416239976882935

Epoch: 6| Step: 13
Training loss: 1.6466976404190063
Validation loss: 2.223051349322001

Epoch: 274| Step: 0
Training loss: 1.0617634057998657
Validation loss: 2.2206655740737915

Epoch: 6| Step: 1
Training loss: 1.5870047807693481
Validation loss: 2.193397104740143

Epoch: 6| Step: 2
Training loss: 1.945049524307251
Validation loss: 2.2015825112660727

Epoch: 6| Step: 3
Training loss: 1.613924503326416
Validation loss: 2.22109055519104

Epoch: 6| Step: 4
Training loss: 1.819736361503601
Validation loss: 2.2200822234153748

Epoch: 6| Step: 5
Training loss: 1.9081993103027344
Validation loss: 2.1941189964612327

Epoch: 6| Step: 6
Training loss: 1.8274794816970825
Validation loss: 2.193005641301473

Epoch: 6| Step: 7
Training loss: 1.8929131031036377
Validation loss: 2.21158899863561

Epoch: 6| Step: 8
Training loss: 1.1069762706756592
Validation loss: 2.1886321107546487

Epoch: 6| Step: 9
Training loss: 1.0639351606369019
Validation loss: 2.193851908047994

Epoch: 6| Step: 10
Training loss: 1.8718760013580322
Validation loss: 2.2288941542307534

Epoch: 6| Step: 11
Training loss: 1.8724958896636963
Validation loss: 2.1996392409006753

Epoch: 6| Step: 12
Training loss: 1.0442489385604858
Validation loss: 2.2159977356592813

Epoch: 6| Step: 13
Training loss: 1.697131633758545
Validation loss: 2.196971297264099

Epoch: 275| Step: 0
Training loss: 1.7798669338226318
Validation loss: 2.2140895326932273

Epoch: 6| Step: 1
Training loss: 2.3213601112365723
Validation loss: 2.204590400060018

Epoch: 6| Step: 2
Training loss: 1.1625388860702515
Validation loss: 2.2073399424552917

Epoch: 6| Step: 3
Training loss: 1.3656634092330933
Validation loss: 2.187132199605306

Epoch: 6| Step: 4
Training loss: 1.9005510807037354
Validation loss: 2.23893404006958

Epoch: 6| Step: 5
Training loss: 1.6919357776641846
Validation loss: 2.220133125782013

Epoch: 6| Step: 6
Training loss: 0.9239037036895752
Validation loss: 2.23304549853007

Epoch: 6| Step: 7
Training loss: 2.3977482318878174
Validation loss: 2.246142566204071

Epoch: 6| Step: 8
Training loss: 1.9584317207336426
Validation loss: 2.241139054298401

Epoch: 6| Step: 9
Training loss: 1.1360752582550049
Validation loss: 2.242167353630066

Epoch: 6| Step: 10
Training loss: 1.3285444974899292
Validation loss: 2.246824264526367

Epoch: 6| Step: 11
Training loss: 1.0554423332214355
Validation loss: 2.254836837450663

Epoch: 6| Step: 12
Training loss: 1.1960651874542236
Validation loss: 2.240485409895579

Epoch: 6| Step: 13
Training loss: 1.6865023374557495
Validation loss: 2.2675159176190696

Epoch: 276| Step: 0
Training loss: 1.2991052865982056
Validation loss: 2.270605524381002

Epoch: 6| Step: 1
Training loss: 1.8660136461257935
Validation loss: 2.2767306566238403

Epoch: 6| Step: 2
Training loss: 1.4022834300994873
Validation loss: 2.272270679473877

Epoch: 6| Step: 3
Training loss: 1.8508349657058716
Validation loss: 2.2832897106806436

Epoch: 6| Step: 4
Training loss: 1.1635141372680664
Validation loss: 2.2515223026275635

Epoch: 6| Step: 5
Training loss: 1.3993629217147827
Validation loss: 2.2504488031069436

Epoch: 6| Step: 6
Training loss: 1.9930329322814941
Validation loss: 2.263064424196879

Epoch: 6| Step: 7
Training loss: 1.4939510822296143
Validation loss: 2.237335721651713

Epoch: 6| Step: 8
Training loss: 1.1148465871810913
Validation loss: 2.2316778898239136

Epoch: 6| Step: 9
Training loss: 1.8357805013656616
Validation loss: 2.2592182556788125

Epoch: 6| Step: 10
Training loss: 1.1769437789916992
Validation loss: 2.2587502002716064

Epoch: 6| Step: 11
Training loss: 1.969602108001709
Validation loss: 2.270854413509369

Epoch: 6| Step: 12
Training loss: 1.7828831672668457
Validation loss: 2.2948142488797507

Epoch: 6| Step: 13
Training loss: 1.689971685409546
Validation loss: 2.2695813377698264

Epoch: 277| Step: 0
Training loss: 1.530421495437622
Validation loss: 2.264910042285919

Epoch: 6| Step: 1
Training loss: 1.4271512031555176
Validation loss: 2.2990450859069824

Epoch: 6| Step: 2
Training loss: 1.4357993602752686
Validation loss: 2.3269192576408386

Epoch: 6| Step: 3
Training loss: 2.0167243480682373
Validation loss: 2.2692408561706543

Epoch: 6| Step: 4
Training loss: 2.1849918365478516
Validation loss: 2.2880706191062927

Epoch: 6| Step: 5
Training loss: 2.188535213470459
Validation loss: 2.2594516277313232

Epoch: 6| Step: 6
Training loss: 0.9726247787475586
Validation loss: 2.2576134403546653

Epoch: 6| Step: 7
Training loss: 1.2804765701293945
Validation loss: 2.250295122464498

Epoch: 6| Step: 8
Training loss: 0.9528524875640869
Validation loss: 2.236835996309916

Epoch: 6| Step: 9
Training loss: 1.1991028785705566
Validation loss: 2.224595824877421

Epoch: 6| Step: 10
Training loss: 1.3436696529388428
Validation loss: 2.219418009122213

Epoch: 6| Step: 11
Training loss: 1.6218631267547607
Validation loss: 2.2099473079045615

Epoch: 6| Step: 12
Training loss: 2.191213846206665
Validation loss: 2.218806346257528

Epoch: 6| Step: 13
Training loss: 2.2211313247680664
Validation loss: 2.212227245171865

Epoch: 278| Step: 0
Training loss: 1.8813815116882324
Validation loss: 2.221271197001139

Epoch: 6| Step: 1
Training loss: 2.1329150199890137
Validation loss: 2.225341002146403

Epoch: 6| Step: 2
Training loss: 1.404768705368042
Validation loss: 2.2305521766344705

Epoch: 6| Step: 3
Training loss: 1.5495026111602783
Validation loss: 2.2603357632954917

Epoch: 6| Step: 4
Training loss: 1.2517642974853516
Validation loss: 2.238046089808146

Epoch: 6| Step: 5
Training loss: 1.270504117012024
Validation loss: 2.29449325799942

Epoch: 6| Step: 6
Training loss: 1.190685749053955
Validation loss: 2.2882136901219687

Epoch: 6| Step: 7
Training loss: 1.2885820865631104
Validation loss: 2.295457402865092

Epoch: 6| Step: 8
Training loss: 1.344637393951416
Validation loss: 2.281031290690104

Epoch: 6| Step: 9
Training loss: 1.7359118461608887
Validation loss: 2.2724815209706626

Epoch: 6| Step: 10
Training loss: 1.665343165397644
Validation loss: 2.2725237607955933

Epoch: 6| Step: 11
Training loss: 1.8076913356781006
Validation loss: 2.281008303165436

Epoch: 6| Step: 12
Training loss: 1.5452107191085815
Validation loss: 2.26472540696462

Epoch: 6| Step: 13
Training loss: 1.653355360031128
Validation loss: 2.2515909075737

Epoch: 279| Step: 0
Training loss: 1.6942769289016724
Validation loss: 2.25662229458491

Epoch: 6| Step: 1
Training loss: 1.0781519412994385
Validation loss: 2.2146726846694946

Epoch: 6| Step: 2
Training loss: 1.4497473239898682
Validation loss: 2.2569023172060647

Epoch: 6| Step: 3
Training loss: 1.7854276895523071
Validation loss: 2.2369024753570557

Epoch: 6| Step: 4
Training loss: 1.0671550035476685
Validation loss: 2.236359715461731

Epoch: 6| Step: 5
Training loss: 1.9148211479187012
Validation loss: 2.2569644252459207

Epoch: 6| Step: 6
Training loss: 1.5308876037597656
Validation loss: 2.2893914381663003

Epoch: 6| Step: 7
Training loss: 1.1979900598526
Validation loss: 2.2977490226427713

Epoch: 6| Step: 8
Training loss: 1.9596800804138184
Validation loss: 2.2993462681770325

Epoch: 6| Step: 9
Training loss: 2.6106462478637695
Validation loss: 2.292894164721171

Epoch: 6| Step: 10
Training loss: 2.2816271781921387
Validation loss: 2.282783627510071

Epoch: 6| Step: 11
Training loss: 1.1062116622924805
Validation loss: 2.281073053677877

Epoch: 6| Step: 12
Training loss: 0.9899435043334961
Validation loss: 2.2545348405838013

Epoch: 6| Step: 13
Training loss: 1.2778174877166748
Validation loss: 2.2205093105634055

Epoch: 280| Step: 0
Training loss: 1.1781911849975586
Validation loss: 2.2370063066482544

Epoch: 6| Step: 1
Training loss: 1.8526287078857422
Validation loss: 2.2233844002087912

Epoch: 6| Step: 2
Training loss: 1.0479536056518555
Validation loss: 2.2116050720214844

Epoch: 6| Step: 3
Training loss: 1.6097981929779053
Validation loss: 2.224755426247915

Epoch: 6| Step: 4
Training loss: 1.1838160753250122
Validation loss: 2.1916170517603555

Epoch: 6| Step: 5
Training loss: 1.1695077419281006
Validation loss: 2.2125808596611023

Epoch: 6| Step: 6
Training loss: 1.9032093286514282
Validation loss: 2.2058679660161338

Epoch: 6| Step: 7
Training loss: 1.9116876125335693
Validation loss: 2.2035038471221924

Epoch: 6| Step: 8
Training loss: 0.7344510555267334
Validation loss: 2.204984803994497

Epoch: 6| Step: 9
Training loss: 2.1392576694488525
Validation loss: 2.2047483921051025

Epoch: 6| Step: 10
Training loss: 1.3969006538391113
Validation loss: 2.208561976750692

Epoch: 6| Step: 11
Training loss: 2.3994040489196777
Validation loss: 2.234959920247396

Epoch: 6| Step: 12
Training loss: 1.8842618465423584
Validation loss: 2.245564858118693

Epoch: 6| Step: 13
Training loss: 1.676109790802002
Validation loss: 2.2468737959861755

Epoch: 281| Step: 0
Training loss: 2.1126837730407715
Validation loss: 2.252691606680552

Epoch: 6| Step: 1
Training loss: 1.758206844329834
Validation loss: 2.226663589477539

Epoch: 6| Step: 2
Training loss: 1.640052318572998
Validation loss: 2.2003439466158548

Epoch: 6| Step: 3
Training loss: 1.14775550365448
Validation loss: 2.210667848587036

Epoch: 6| Step: 4
Training loss: 1.4684945344924927
Validation loss: 2.2014917532602944

Epoch: 6| Step: 5
Training loss: 1.7481865882873535
Validation loss: 2.1866557200749717

Epoch: 6| Step: 6
Training loss: 2.621629238128662
Validation loss: 2.19978400071462

Epoch: 6| Step: 7
Training loss: 1.435863733291626
Validation loss: 2.191067715485891

Epoch: 6| Step: 8
Training loss: 2.2731471061706543
Validation loss: 2.2088231643040976

Epoch: 6| Step: 9
Training loss: 1.562422513961792
Validation loss: 2.194261113802592

Epoch: 6| Step: 10
Training loss: 0.8597291111946106
Validation loss: 2.1858837008476257

Epoch: 6| Step: 11
Training loss: 1.7877267599105835
Validation loss: 2.2162863413492837

Epoch: 6| Step: 12
Training loss: 1.4248175621032715
Validation loss: 2.2220901449521384

Epoch: 6| Step: 13
Training loss: 1.1260173320770264
Validation loss: 2.2451944748560586

Epoch: 282| Step: 0
Training loss: 0.9727427959442139
Validation loss: 2.2371413310368857

Epoch: 6| Step: 1
Training loss: 1.3540661334991455
Validation loss: 2.2486642797787986

Epoch: 6| Step: 2
Training loss: 1.562286376953125
Validation loss: 2.2456815242767334

Epoch: 6| Step: 3
Training loss: 1.0955121517181396
Validation loss: 2.259978175163269

Epoch: 6| Step: 4
Training loss: 2.0251922607421875
Validation loss: 2.262527902921041

Epoch: 6| Step: 5
Training loss: 1.8075449466705322
Validation loss: 2.284791866938273

Epoch: 6| Step: 6
Training loss: 1.1785470247268677
Validation loss: 2.2785589496294656

Epoch: 6| Step: 7
Training loss: 1.722078561782837
Validation loss: 2.2937514384587607

Epoch: 6| Step: 8
Training loss: 2.031747341156006
Validation loss: 2.2581142584482827

Epoch: 6| Step: 9
Training loss: 1.9331209659576416
Validation loss: 2.301211436589559

Epoch: 6| Step: 10
Training loss: 2.3508901596069336
Validation loss: 2.2703699668248496

Epoch: 6| Step: 11
Training loss: 1.570123314857483
Validation loss: 2.21591587861379

Epoch: 6| Step: 12
Training loss: 1.3531869649887085
Validation loss: 2.2312481800715127

Epoch: 6| Step: 13
Training loss: 1.0397539138793945
Validation loss: 2.197744448979696

Epoch: 283| Step: 0
Training loss: 1.8450473546981812
Validation loss: 2.1939028898874917

Epoch: 6| Step: 1
Training loss: 1.7184584140777588
Validation loss: 2.1952699025472007

Epoch: 6| Step: 2
Training loss: 1.5731509923934937
Validation loss: 2.201772669951121

Epoch: 6| Step: 3
Training loss: 1.8873615264892578
Validation loss: 2.18853493531545

Epoch: 6| Step: 4
Training loss: 1.0577936172485352
Validation loss: 2.196027080217997

Epoch: 6| Step: 5
Training loss: 1.5646893978118896
Validation loss: 2.221696893374125

Epoch: 6| Step: 6
Training loss: 1.435511827468872
Validation loss: 2.2072733640670776

Epoch: 6| Step: 7
Training loss: 1.480501413345337
Validation loss: 2.2439404726028442

Epoch: 6| Step: 8
Training loss: 1.482972264289856
Validation loss: 2.237594028313955

Epoch: 6| Step: 9
Training loss: 1.2775404453277588
Validation loss: 2.2658803462982178

Epoch: 6| Step: 10
Training loss: 0.9083014130592346
Validation loss: 2.2834867238998413

Epoch: 6| Step: 11
Training loss: 2.5764451026916504
Validation loss: 2.2865936756134033

Epoch: 6| Step: 12
Training loss: 1.4183106422424316
Validation loss: 2.2850205103556314

Epoch: 6| Step: 13
Training loss: 1.5253829956054688
Validation loss: 2.27743661403656

Epoch: 284| Step: 0
Training loss: 1.3434879779815674
Validation loss: 2.325119197368622

Epoch: 6| Step: 1
Training loss: 1.598252773284912
Validation loss: 2.293853680292765

Epoch: 6| Step: 2
Training loss: 1.8058996200561523
Validation loss: 2.2737563053766885

Epoch: 6| Step: 3
Training loss: 1.0660127401351929
Validation loss: 2.246418515841166

Epoch: 6| Step: 4
Training loss: 2.1124932765960693
Validation loss: 2.24758243560791

Epoch: 6| Step: 5
Training loss: 1.9058181047439575
Validation loss: 2.2161781589190164

Epoch: 6| Step: 6
Training loss: 1.6864451169967651
Validation loss: 2.220039506753286

Epoch: 6| Step: 7
Training loss: 1.4433380365371704
Validation loss: 2.205320715904236

Epoch: 6| Step: 8
Training loss: 1.0371873378753662
Validation loss: 2.2260716358820596

Epoch: 6| Step: 9
Training loss: 1.4958572387695312
Validation loss: 2.2206759651501975

Epoch: 6| Step: 10
Training loss: 1.118403434753418
Validation loss: 2.2560498118400574

Epoch: 6| Step: 11
Training loss: 2.789083480834961
Validation loss: 2.246950705846151

Epoch: 6| Step: 12
Training loss: 0.8060298562049866
Validation loss: 2.2504425843556723

Epoch: 6| Step: 13
Training loss: 1.1555721759796143
Validation loss: 2.28056538105011

Epoch: 285| Step: 0
Training loss: 1.329589605331421
Validation loss: 2.280791143576304

Epoch: 6| Step: 1
Training loss: 1.5721726417541504
Validation loss: 2.286470274130503

Epoch: 6| Step: 2
Training loss: 1.4293400049209595
Validation loss: 2.2896438439687095

Epoch: 6| Step: 3
Training loss: 2.048600673675537
Validation loss: 2.288939436276754

Epoch: 6| Step: 4
Training loss: 1.8375657796859741
Validation loss: 2.31526126464208

Epoch: 6| Step: 5
Training loss: 1.5068248510360718
Validation loss: 2.295560280481974

Epoch: 6| Step: 6
Training loss: 1.1997296810150146
Validation loss: 2.3042431672414145

Epoch: 6| Step: 7
Training loss: 1.8400952816009521
Validation loss: 2.258148650328318

Epoch: 6| Step: 8
Training loss: 1.1179115772247314
Validation loss: 2.248457213242849

Epoch: 6| Step: 9
Training loss: 1.9947363138198853
Validation loss: 2.2360756595929465

Epoch: 6| Step: 10
Training loss: 1.2854342460632324
Validation loss: 2.2171069383621216

Epoch: 6| Step: 11
Training loss: 1.6632263660430908
Validation loss: 2.2092828353246055

Epoch: 6| Step: 12
Training loss: 1.9348468780517578
Validation loss: 2.20653243859609

Epoch: 6| Step: 13
Training loss: 2.1411690711975098
Validation loss: 2.242252687613169

Epoch: 286| Step: 0
Training loss: 2.10219144821167
Validation loss: 2.2173383037249246

Epoch: 6| Step: 1
Training loss: 1.6594139337539673
Validation loss: 2.2187206943829856

Epoch: 6| Step: 2
Training loss: 0.8052362203598022
Validation loss: 2.196077028910319

Epoch: 6| Step: 3
Training loss: 2.0799312591552734
Validation loss: 2.188648521900177

Epoch: 6| Step: 4
Training loss: 1.6573361158370972
Validation loss: 2.213732103506724

Epoch: 6| Step: 5
Training loss: 1.3584893941879272
Validation loss: 2.197842597961426

Epoch: 6| Step: 6
Training loss: 1.6967461109161377
Validation loss: 2.20213391383489

Epoch: 6| Step: 7
Training loss: 1.8985307216644287
Validation loss: 2.1856915950775146

Epoch: 6| Step: 8
Training loss: 1.8137633800506592
Validation loss: 2.1877273519833884

Epoch: 6| Step: 9
Training loss: 1.5154497623443604
Validation loss: 2.193876643975576

Epoch: 6| Step: 10
Training loss: 1.8187634944915771
Validation loss: 2.208170255025228

Epoch: 6| Step: 11
Training loss: 1.2358981370925903
Validation loss: 2.2037275433540344

Epoch: 6| Step: 12
Training loss: 2.2667465209960938
Validation loss: 2.2145392100016275

Epoch: 6| Step: 13
Training loss: 0.9370380640029907
Validation loss: 2.2212195793787637

Epoch: 287| Step: 0
Training loss: 1.569681167602539
Validation loss: 2.225707769393921

Epoch: 6| Step: 1
Training loss: 2.1304359436035156
Validation loss: 2.2222642501195273

Epoch: 6| Step: 2
Training loss: 1.7822707891464233
Validation loss: 2.2614433765411377

Epoch: 6| Step: 3
Training loss: 2.0713043212890625
Validation loss: 2.2669416467348733

Epoch: 6| Step: 4
Training loss: 1.0226463079452515
Validation loss: 2.272813697655996

Epoch: 6| Step: 5
Training loss: 1.1481612920761108
Validation loss: 2.3033002614974976

Epoch: 6| Step: 6
Training loss: 2.0959012508392334
Validation loss: 2.27747509876887

Epoch: 6| Step: 7
Training loss: 1.8173863887786865
Validation loss: 2.3054010470708213

Epoch: 6| Step: 8
Training loss: 1.1462187767028809
Validation loss: 2.3039297064145408

Epoch: 6| Step: 9
Training loss: 2.0423660278320312
Validation loss: 2.2868927319844565

Epoch: 6| Step: 10
Training loss: 1.386247158050537
Validation loss: 2.265370468298594

Epoch: 6| Step: 11
Training loss: 0.9218006730079651
Validation loss: 2.2552384535471597

Epoch: 6| Step: 12
Training loss: 1.0856785774230957
Validation loss: 2.2641188303629556

Epoch: 6| Step: 13
Training loss: 1.6315068006515503
Validation loss: 2.2584843039512634

Epoch: 288| Step: 0
Training loss: 1.3889238834381104
Validation loss: 2.2483282883961997

Epoch: 6| Step: 1
Training loss: 0.8606224060058594
Validation loss: 2.250134070714315

Epoch: 6| Step: 2
Training loss: 1.1737154722213745
Validation loss: 2.268875082333883

Epoch: 6| Step: 3
Training loss: 2.5832083225250244
Validation loss: 2.2871280908584595

Epoch: 6| Step: 4
Training loss: 1.3436236381530762
Validation loss: 2.287608325481415

Epoch: 6| Step: 5
Training loss: 1.3554277420043945
Validation loss: 2.2701039910316467

Epoch: 6| Step: 6
Training loss: 1.8468246459960938
Validation loss: 2.2678303122520447

Epoch: 6| Step: 7
Training loss: 1.451158046722412
Validation loss: 2.2600678205490112

Epoch: 6| Step: 8
Training loss: 2.205023765563965
Validation loss: 2.2611735661824546

Epoch: 6| Step: 9
Training loss: 1.7212249040603638
Validation loss: 2.2463653286298118

Epoch: 6| Step: 10
Training loss: 1.1758368015289307
Validation loss: 2.2529566287994385

Epoch: 6| Step: 11
Training loss: 0.6494823694229126
Validation loss: 2.251306653022766

Epoch: 6| Step: 12
Training loss: 1.9578217267990112
Validation loss: 2.241222361723582

Epoch: 6| Step: 13
Training loss: 1.7763675451278687
Validation loss: 2.2147664030392966

Epoch: 289| Step: 0
Training loss: 1.7382960319519043
Validation loss: 2.1936553517977395

Epoch: 6| Step: 1
Training loss: 1.027937412261963
Validation loss: 2.187819163004557

Epoch: 6| Step: 2
Training loss: 1.0721904039382935
Validation loss: 2.214611808458964

Epoch: 6| Step: 3
Training loss: 1.60182523727417
Validation loss: 2.1900892655054727

Epoch: 6| Step: 4
Training loss: 1.4440195560455322
Validation loss: 2.1856532295544944

Epoch: 6| Step: 5
Training loss: 1.3583076000213623
Validation loss: 2.2286126414934793

Epoch: 6| Step: 6
Training loss: 2.0096120834350586
Validation loss: 2.2065852880477905

Epoch: 6| Step: 7
Training loss: 1.334812879562378
Validation loss: 2.220824718475342

Epoch: 6| Step: 8
Training loss: 1.7958356142044067
Validation loss: 2.2381293972333274

Epoch: 6| Step: 9
Training loss: 1.6756932735443115
Validation loss: 2.2447869181632996

Epoch: 6| Step: 10
Training loss: 1.7632286548614502
Validation loss: 2.259596665700277

Epoch: 6| Step: 11
Training loss: 1.5463037490844727
Validation loss: 2.2592942317326865

Epoch: 6| Step: 12
Training loss: 1.603549599647522
Validation loss: 2.2364200949668884

Epoch: 6| Step: 13
Training loss: 1.4066177606582642
Validation loss: 2.257343312104543

Epoch: 290| Step: 0
Training loss: 1.8196895122528076
Validation loss: 2.244833489259084

Epoch: 6| Step: 1
Training loss: 1.8181637525558472
Validation loss: 2.2364869117736816

Epoch: 6| Step: 2
Training loss: 1.610280156135559
Validation loss: 2.235512634118398

Epoch: 6| Step: 3
Training loss: 1.5629299879074097
Validation loss: 2.237456997235616

Epoch: 6| Step: 4
Training loss: 1.2519290447235107
Validation loss: 2.243837515513102

Epoch: 6| Step: 5
Training loss: 1.6206140518188477
Validation loss: 2.233758012453715

Epoch: 6| Step: 6
Training loss: 1.3685013055801392
Validation loss: 2.223866065343221

Epoch: 6| Step: 7
Training loss: 1.1455309391021729
Validation loss: 2.243445336818695

Epoch: 6| Step: 8
Training loss: 1.3765523433685303
Validation loss: 2.23601241906484

Epoch: 6| Step: 9
Training loss: 1.7229101657867432
Validation loss: 2.1933955550193787

Epoch: 6| Step: 10
Training loss: 1.9313397407531738
Validation loss: 2.206235965092977

Epoch: 6| Step: 11
Training loss: 1.8713393211364746
Validation loss: 2.2017983198165894

Epoch: 6| Step: 12
Training loss: 0.9085840582847595
Validation loss: 2.208728035291036

Epoch: 6| Step: 13
Training loss: 0.9759269952774048
Validation loss: 2.2354123989741006

Epoch: 291| Step: 0
Training loss: 0.8809934854507446
Validation loss: 2.2055320143699646

Epoch: 6| Step: 1
Training loss: 1.763838529586792
Validation loss: 2.223898728688558

Epoch: 6| Step: 2
Training loss: 1.1832081079483032
Validation loss: 2.208931644757589

Epoch: 6| Step: 3
Training loss: 1.7650628089904785
Validation loss: 2.2341767946879068

Epoch: 6| Step: 4
Training loss: 1.5810573101043701
Validation loss: 2.242076019446055

Epoch: 6| Step: 5
Training loss: 2.0383079051971436
Validation loss: 2.2111816803614297

Epoch: 6| Step: 6
Training loss: 1.3888607025146484
Validation loss: 2.257600645224253

Epoch: 6| Step: 7
Training loss: 1.672282099723816
Validation loss: 2.247946778933207

Epoch: 6| Step: 8
Training loss: 1.7504477500915527
Validation loss: 2.275006373723348

Epoch: 6| Step: 9
Training loss: 0.8486477136611938
Validation loss: 2.250838836034139

Epoch: 6| Step: 10
Training loss: 1.5791414976119995
Validation loss: 2.280008296171824

Epoch: 6| Step: 11
Training loss: 1.3082115650177002
Validation loss: 2.2900744676589966

Epoch: 6| Step: 12
Training loss: 1.2318027019500732
Validation loss: 2.259348968664805

Epoch: 6| Step: 13
Training loss: 1.9982725381851196
Validation loss: 2.2543753186861673

Epoch: 292| Step: 0
Training loss: 1.3121469020843506
Validation loss: 2.250635325908661

Epoch: 6| Step: 1
Training loss: 1.2629761695861816
Validation loss: 2.2380361954371133

Epoch: 6| Step: 2
Training loss: 1.5918368101119995
Validation loss: 2.281048576037089

Epoch: 6| Step: 3
Training loss: 1.3089690208435059
Validation loss: 2.271018067995707

Epoch: 6| Step: 4
Training loss: 0.8532886505126953
Validation loss: 2.2646688421567283

Epoch: 6| Step: 5
Training loss: 0.9691813588142395
Validation loss: 2.3014082511266074

Epoch: 6| Step: 6
Training loss: 1.1215590238571167
Validation loss: 2.2953686316808066

Epoch: 6| Step: 7
Training loss: 1.5515105724334717
Validation loss: 2.2694304386774697

Epoch: 6| Step: 8
Training loss: 2.391153335571289
Validation loss: 2.286217212677002

Epoch: 6| Step: 9
Training loss: 1.5703346729278564
Validation loss: 2.2723349928855896

Epoch: 6| Step: 10
Training loss: 1.9061033725738525
Validation loss: 2.268503785133362

Epoch: 6| Step: 11
Training loss: 1.8157143592834473
Validation loss: 2.2634703715642295

Epoch: 6| Step: 12
Training loss: 1.5809035301208496
Validation loss: 2.275064786275228

Epoch: 6| Step: 13
Training loss: 1.8005378246307373
Validation loss: 2.2590667406717935

Epoch: 293| Step: 0
Training loss: 1.848054051399231
Validation loss: 2.2344563603401184

Epoch: 6| Step: 1
Training loss: 2.3934898376464844
Validation loss: 2.2795475125312805

Epoch: 6| Step: 2
Training loss: 1.4019184112548828
Validation loss: 2.2840593457221985

Epoch: 6| Step: 3
Training loss: 1.0352168083190918
Validation loss: 2.2851309378941855

Epoch: 6| Step: 4
Training loss: 1.2741012573242188
Validation loss: 2.2827280163764954

Epoch: 6| Step: 5
Training loss: 1.3667267560958862
Validation loss: 2.283077895641327

Epoch: 6| Step: 6
Training loss: 1.1862766742706299
Validation loss: 2.279052257537842

Epoch: 6| Step: 7
Training loss: 1.5517911911010742
Validation loss: 2.2750808795293174

Epoch: 6| Step: 8
Training loss: 2.084961414337158
Validation loss: 2.2533669471740723

Epoch: 6| Step: 9
Training loss: 0.6715757846832275
Validation loss: 2.2601398626963296

Epoch: 6| Step: 10
Training loss: 2.0991833209991455
Validation loss: 2.243460714817047

Epoch: 6| Step: 11
Training loss: 1.062873125076294
Validation loss: 2.240454614162445

Epoch: 6| Step: 12
Training loss: 1.7247467041015625
Validation loss: 2.227689345677694

Epoch: 6| Step: 13
Training loss: 1.3300148248672485
Validation loss: 2.233413298924764

Epoch: 294| Step: 0
Training loss: 0.6732395887374878
Validation loss: 2.2328757842381797

Epoch: 6| Step: 1
Training loss: 2.1864070892333984
Validation loss: 2.2193989952405295

Epoch: 6| Step: 2
Training loss: 1.9433703422546387
Validation loss: 2.2057918310165405

Epoch: 6| Step: 3
Training loss: 0.7991818189620972
Validation loss: 2.231768627961477

Epoch: 6| Step: 4
Training loss: 1.446806788444519
Validation loss: 2.239502767721812

Epoch: 6| Step: 5
Training loss: 1.5856566429138184
Validation loss: 2.234181841214498

Epoch: 6| Step: 6
Training loss: 2.1065337657928467
Validation loss: 2.203647176424662

Epoch: 6| Step: 7
Training loss: 1.5302119255065918
Validation loss: 2.217004934946696

Epoch: 6| Step: 8
Training loss: 1.9958231449127197
Validation loss: 2.2025842666625977

Epoch: 6| Step: 9
Training loss: 1.661259651184082
Validation loss: 2.175153613090515

Epoch: 6| Step: 10
Training loss: 1.5183907747268677
Validation loss: 2.208535075187683

Epoch: 6| Step: 11
Training loss: 1.5385128259658813
Validation loss: 2.194824437300364

Epoch: 6| Step: 12
Training loss: 0.9444726705551147
Validation loss: 2.1860211292902627

Epoch: 6| Step: 13
Training loss: 1.6606905460357666
Validation loss: 2.201252301534017

Epoch: 295| Step: 0
Training loss: 1.188818097114563
Validation loss: 2.20534481604894

Epoch: 6| Step: 1
Training loss: 1.7212958335876465
Validation loss: 2.234869639078776

Epoch: 6| Step: 2
Training loss: 1.9760174751281738
Validation loss: 2.22463850180308

Epoch: 6| Step: 3
Training loss: 2.2220444679260254
Validation loss: 2.229905684789022

Epoch: 6| Step: 4
Training loss: 1.3357844352722168
Validation loss: 2.227550824483236

Epoch: 6| Step: 5
Training loss: 1.9486483335494995
Validation loss: 2.232258121172587

Epoch: 6| Step: 6
Training loss: 0.9856703877449036
Validation loss: 2.2245221932729087

Epoch: 6| Step: 7
Training loss: 1.1372947692871094
Validation loss: 2.2208650708198547

Epoch: 6| Step: 8
Training loss: 1.297760009765625
Validation loss: 2.244887908299764

Epoch: 6| Step: 9
Training loss: 1.858789086341858
Validation loss: 2.2448704640070596

Epoch: 6| Step: 10
Training loss: 1.3594295978546143
Validation loss: 2.244918644428253

Epoch: 6| Step: 11
Training loss: 1.303880214691162
Validation loss: 2.231739362080892

Epoch: 6| Step: 12
Training loss: 1.5633755922317505
Validation loss: 2.2362115383148193

Epoch: 6| Step: 13
Training loss: 1.296751618385315
Validation loss: 2.2467647790908813

Epoch: 296| Step: 0
Training loss: 0.9530128240585327
Validation loss: 2.2596612175305686

Epoch: 6| Step: 1
Training loss: 1.3048832416534424
Validation loss: 2.2420329650243125

Epoch: 6| Step: 2
Training loss: 1.2304304838180542
Validation loss: 2.226244350274404

Epoch: 6| Step: 3
Training loss: 0.9289240837097168
Validation loss: 2.2384154001871743

Epoch: 6| Step: 4
Training loss: 1.6379728317260742
Validation loss: 2.239846626917521

Epoch: 6| Step: 5
Training loss: 1.800704002380371
Validation loss: 2.247357706228892

Epoch: 6| Step: 6
Training loss: 1.604444146156311
Validation loss: 2.2498937845230103

Epoch: 6| Step: 7
Training loss: 1.9794672727584839
Validation loss: 2.2788366079330444

Epoch: 6| Step: 8
Training loss: 1.5697603225708008
Validation loss: 2.285136421521505

Epoch: 6| Step: 9
Training loss: 1.9851678609848022
Validation loss: 2.2782301902770996

Epoch: 6| Step: 10
Training loss: 1.5186506509780884
Validation loss: 2.277206242084503

Epoch: 6| Step: 11
Training loss: 1.442777395248413
Validation loss: 2.2637767593065896

Epoch: 6| Step: 12
Training loss: 1.5195914506912231
Validation loss: 2.251272976398468

Epoch: 6| Step: 13
Training loss: 1.0544066429138184
Validation loss: 2.2733447551727295

Epoch: 297| Step: 0
Training loss: 1.453857660293579
Validation loss: 2.278962274392446

Epoch: 6| Step: 1
Training loss: 1.7570258378982544
Validation loss: 2.248521645863851

Epoch: 6| Step: 2
Training loss: 1.861952304840088
Validation loss: 2.275323132673899

Epoch: 6| Step: 3
Training loss: 1.177858591079712
Validation loss: 2.2591212590535483

Epoch: 6| Step: 4
Training loss: 2.0231773853302
Validation loss: 2.272325019041697

Epoch: 6| Step: 5
Training loss: 1.0258188247680664
Validation loss: 2.268495957056681

Epoch: 6| Step: 6
Training loss: 1.2323598861694336
Validation loss: 2.257647693157196

Epoch: 6| Step: 7
Training loss: 1.1481013298034668
Validation loss: 2.2082444032033286

Epoch: 6| Step: 8
Training loss: 1.0826746225357056
Validation loss: 2.204618990421295

Epoch: 6| Step: 9
Training loss: 1.57667875289917
Validation loss: 2.222660263379415

Epoch: 6| Step: 10
Training loss: 2.366396427154541
Validation loss: 2.2285780906677246

Epoch: 6| Step: 11
Training loss: 1.4545875787734985
Validation loss: 2.2240923047065735

Epoch: 6| Step: 12
Training loss: 1.575469732284546
Validation loss: 2.2237003246943154

Epoch: 6| Step: 13
Training loss: 0.8896948099136353
Validation loss: 2.237901270389557

Epoch: 298| Step: 0
Training loss: 0.9862855672836304
Validation loss: 2.2390429774920144

Epoch: 6| Step: 1
Training loss: 1.3487958908081055
Validation loss: 2.2243001063664756

Epoch: 6| Step: 2
Training loss: 1.672845482826233
Validation loss: 2.2531769275665283

Epoch: 6| Step: 3
Training loss: 0.8665784597396851
Validation loss: 2.243732273578644

Epoch: 6| Step: 4
Training loss: 1.893567681312561
Validation loss: 2.2736970583597818

Epoch: 6| Step: 5
Training loss: 1.4993045330047607
Validation loss: 2.2650559345881143

Epoch: 6| Step: 6
Training loss: 1.5104138851165771
Validation loss: 2.2460263768831887

Epoch: 6| Step: 7
Training loss: 1.54693603515625
Validation loss: 2.279302736123403

Epoch: 6| Step: 8
Training loss: 1.4299646615982056
Validation loss: 2.2530405521392822

Epoch: 6| Step: 9
Training loss: 1.305864930152893
Validation loss: 2.276202658812205

Epoch: 6| Step: 10
Training loss: 1.266361951828003
Validation loss: 2.297551949818929

Epoch: 6| Step: 11
Training loss: 1.6322569847106934
Validation loss: 2.25468780597051

Epoch: 6| Step: 12
Training loss: 1.727204442024231
Validation loss: 2.27237606048584

Epoch: 6| Step: 13
Training loss: 2.151679515838623
Validation loss: 2.2520644466082254

Epoch: 299| Step: 0
Training loss: 1.4075133800506592
Validation loss: 2.245403607686361

Epoch: 6| Step: 1
Training loss: 1.5482635498046875
Validation loss: 2.263158142566681

Epoch: 6| Step: 2
Training loss: 1.6285804510116577
Validation loss: 2.2318738102912903

Epoch: 6| Step: 3
Training loss: 1.4279766082763672
Validation loss: 2.247860332330068

Epoch: 6| Step: 4
Training loss: 1.045853614807129
Validation loss: 2.298133134841919

Epoch: 6| Step: 5
Training loss: 2.0639240741729736
Validation loss: 2.27884034315745

Epoch: 6| Step: 6
Training loss: 1.8482600450515747
Validation loss: 2.237796445687612

Epoch: 6| Step: 7
Training loss: 2.4942941665649414
Validation loss: 2.2729716499646506

Epoch: 6| Step: 8
Training loss: 1.1781717538833618
Validation loss: 2.228164474169413

Epoch: 6| Step: 9
Training loss: 0.9833328723907471
Validation loss: 2.211378296216329

Epoch: 6| Step: 10
Training loss: 1.230963110923767
Validation loss: 2.2030656337738037

Epoch: 6| Step: 11
Training loss: 1.1497857570648193
Validation loss: 2.1896262168884277

Epoch: 6| Step: 12
Training loss: 1.6657631397247314
Validation loss: 2.1976343592007956

Epoch: 6| Step: 13
Training loss: 1.2880194187164307
Validation loss: 2.1898794571558633

Epoch: 300| Step: 0
Training loss: 1.632889986038208
Validation loss: 2.184891700744629

Epoch: 6| Step: 1
Training loss: 1.495489478111267
Validation loss: 2.181583265463511

Epoch: 6| Step: 2
Training loss: 1.3773173093795776
Validation loss: 2.178828179836273

Epoch: 6| Step: 3
Training loss: 1.417572021484375
Validation loss: 2.1966925263404846

Epoch: 6| Step: 4
Training loss: 1.8391680717468262
Validation loss: 2.2064797083536782

Epoch: 6| Step: 5
Training loss: 1.5348894596099854
Validation loss: 2.2101444005966187

Epoch: 6| Step: 6
Training loss: 1.4868296384811401
Validation loss: 2.1830364068349204

Epoch: 6| Step: 7
Training loss: 0.8559798002243042
Validation loss: 2.207372506459554

Epoch: 6| Step: 8
Training loss: 1.9528846740722656
Validation loss: 2.1791242758433023

Epoch: 6| Step: 9
Training loss: 1.6784532070159912
Validation loss: 2.1827241579691568

Epoch: 6| Step: 10
Training loss: 2.0575428009033203
Validation loss: 2.2337851524353027

Epoch: 6| Step: 11
Training loss: 1.0692832469940186
Validation loss: 2.2206163009007773

Epoch: 6| Step: 12
Training loss: 1.1461646556854248
Validation loss: 2.2022769848505654

Epoch: 6| Step: 13
Training loss: 1.6256611347198486
Validation loss: 2.2184391021728516

Epoch: 301| Step: 0
Training loss: 1.321219563484192
Validation loss: 2.236697793006897

Epoch: 6| Step: 1
Training loss: 1.7417032718658447
Validation loss: 2.2306019266446433

Epoch: 6| Step: 2
Training loss: 1.2862566709518433
Validation loss: 2.197098731994629

Epoch: 6| Step: 3
Training loss: 1.147908329963684
Validation loss: 2.219101905822754

Epoch: 6| Step: 4
Training loss: 1.958838939666748
Validation loss: 2.2043930292129517

Epoch: 6| Step: 5
Training loss: 1.8632042407989502
Validation loss: 2.214608073234558

Epoch: 6| Step: 6
Training loss: 0.8557134866714478
Validation loss: 2.2126543720563254

Epoch: 6| Step: 7
Training loss: 1.1426568031311035
Validation loss: 2.191809813181559

Epoch: 6| Step: 8
Training loss: 1.789395809173584
Validation loss: 2.198797067006429

Epoch: 6| Step: 9
Training loss: 1.0052735805511475
Validation loss: 2.240764538447062

Epoch: 6| Step: 10
Training loss: 1.640200138092041
Validation loss: 2.246992071469625

Epoch: 6| Step: 11
Training loss: 1.1080622673034668
Validation loss: 2.2637675603230796

Epoch: 6| Step: 12
Training loss: 1.4269713163375854
Validation loss: 2.27677059173584

Epoch: 6| Step: 13
Training loss: 1.7483564615249634
Validation loss: 2.254185199737549

Epoch: 302| Step: 0
Training loss: 1.4707958698272705
Validation loss: 2.273988048235575

Epoch: 6| Step: 1
Training loss: 1.272593379020691
Validation loss: 2.323086440563202

Epoch: 6| Step: 2
Training loss: 1.7629575729370117
Validation loss: 2.3062503933906555

Epoch: 6| Step: 3
Training loss: 1.7633777856826782
Validation loss: 2.2810394565264382

Epoch: 6| Step: 4
Training loss: 1.7126986980438232
Validation loss: 2.2750917275746665

Epoch: 6| Step: 5
Training loss: 1.3814345598220825
Validation loss: 2.2586353023846946

Epoch: 6| Step: 6
Training loss: 0.850391149520874
Validation loss: 2.2797245184580484

Epoch: 6| Step: 7
Training loss: 2.175882339477539
Validation loss: 2.254936774571737

Epoch: 6| Step: 8
Training loss: 1.409327507019043
Validation loss: 2.2725279728571572

Epoch: 6| Step: 9
Training loss: 2.22444486618042
Validation loss: 2.252144972483317

Epoch: 6| Step: 10
Training loss: 1.2684319019317627
Validation loss: 2.2457534074783325

Epoch: 6| Step: 11
Training loss: 0.7604750394821167
Validation loss: 2.2815895875295005

Epoch: 6| Step: 12
Training loss: 1.5895518064498901
Validation loss: 2.254660348097483

Epoch: 6| Step: 13
Training loss: 1.5800238847732544
Validation loss: 2.2681503891944885

Epoch: 303| Step: 0
Training loss: 1.1922963857650757
Validation loss: 2.2465376059214273

Epoch: 6| Step: 1
Training loss: 1.1596012115478516
Validation loss: 2.242122213045756

Epoch: 6| Step: 2
Training loss: 1.7976453304290771
Validation loss: 2.242204030354818

Epoch: 6| Step: 3
Training loss: 1.4298313856124878
Validation loss: 2.2390649716059365

Epoch: 6| Step: 4
Training loss: 1.206807255744934
Validation loss: 2.203371047973633

Epoch: 6| Step: 5
Training loss: 1.2477498054504395
Validation loss: 2.2162697116533914

Epoch: 6| Step: 6
Training loss: 1.4345048666000366
Validation loss: 2.2207664847373962

Epoch: 6| Step: 7
Training loss: 1.7548184394836426
Validation loss: 2.191976269086202

Epoch: 6| Step: 8
Training loss: 1.2668874263763428
Validation loss: 2.218829949696859

Epoch: 6| Step: 9
Training loss: 1.4186700582504272
Validation loss: 2.193711280822754

Epoch: 6| Step: 10
Training loss: 1.109034776687622
Validation loss: 2.2300867636998496

Epoch: 6| Step: 11
Training loss: 1.3037629127502441
Validation loss: 2.2019380728403726

Epoch: 6| Step: 12
Training loss: 2.1664509773254395
Validation loss: 2.200818439324697

Epoch: 6| Step: 13
Training loss: 1.6526936292648315
Validation loss: 2.2359848419825235

Epoch: 304| Step: 0
Training loss: 1.9176185131072998
Validation loss: 2.2355819940567017

Epoch: 6| Step: 1
Training loss: 1.471023678779602
Validation loss: 2.2584594090779624

Epoch: 6| Step: 2
Training loss: 1.1896581649780273
Validation loss: 2.277850111325582

Epoch: 6| Step: 3
Training loss: 2.1334877014160156
Validation loss: 2.265855133533478

Epoch: 6| Step: 4
Training loss: 1.4764801263809204
Validation loss: 2.2479792833328247

Epoch: 6| Step: 5
Training loss: 1.474232792854309
Validation loss: 2.2388153076171875

Epoch: 6| Step: 6
Training loss: 1.0805513858795166
Validation loss: 2.241896132628123

Epoch: 6| Step: 7
Training loss: 1.0791220664978027
Validation loss: 2.246314803759257

Epoch: 6| Step: 8
Training loss: 1.4902186393737793
Validation loss: 2.2734133998552957

Epoch: 6| Step: 9
Training loss: 1.6414510011672974
Validation loss: 2.2831696271896362

Epoch: 6| Step: 10
Training loss: 1.2889108657836914
Validation loss: 2.275128185749054

Epoch: 6| Step: 11
Training loss: 1.371311902999878
Validation loss: 2.2621747255325317

Epoch: 6| Step: 12
Training loss: 1.392190933227539
Validation loss: 2.258148511250814

Epoch: 6| Step: 13
Training loss: 1.507978081703186
Validation loss: 2.270448307196299

Epoch: 305| Step: 0
Training loss: 1.5145115852355957
Validation loss: 2.2465816736221313

Epoch: 6| Step: 1
Training loss: 1.9661661386489868
Validation loss: 2.241080363591512

Epoch: 6| Step: 2
Training loss: 1.3778799772262573
Validation loss: 2.249284585316976

Epoch: 6| Step: 3
Training loss: 1.8651552200317383
Validation loss: 2.238876700401306

Epoch: 6| Step: 4
Training loss: 1.6528644561767578
Validation loss: 2.233402589956919

Epoch: 6| Step: 5
Training loss: 1.44552481174469
Validation loss: 2.2584436933199563

Epoch: 6| Step: 6
Training loss: 1.1421648263931274
Validation loss: 2.25556488831838

Epoch: 6| Step: 7
Training loss: 1.6609714031219482
Validation loss: 2.2665366729100547

Epoch: 6| Step: 8
Training loss: 1.9806793928146362
Validation loss: 2.2832409143447876

Epoch: 6| Step: 9
Training loss: 1.6162785291671753
Validation loss: 2.261581619580587

Epoch: 6| Step: 10
Training loss: 1.1737053394317627
Validation loss: 2.306842267513275

Epoch: 6| Step: 11
Training loss: 1.857321858406067
Validation loss: 2.30929958820343

Epoch: 6| Step: 12
Training loss: 1.3437387943267822
Validation loss: 2.30353973309199

Epoch: 6| Step: 13
Training loss: 0.6416980028152466
Validation loss: 2.309618353843689

Epoch: 306| Step: 0
Training loss: 2.0127620697021484
Validation loss: 2.2650373776753745

Epoch: 6| Step: 1
Training loss: 1.043572187423706
Validation loss: 2.247169097264608

Epoch: 6| Step: 2
Training loss: 1.1823269128799438
Validation loss: 2.2719989021619162

Epoch: 6| Step: 3
Training loss: 1.694445252418518
Validation loss: 2.2707268397013345

Epoch: 6| Step: 4
Training loss: 1.013601541519165
Validation loss: 2.24863862991333

Epoch: 6| Step: 5
Training loss: 1.3575339317321777
Validation loss: 2.220856865247091

Epoch: 6| Step: 6
Training loss: 1.2117564678192139
Validation loss: 2.2599172790845237

Epoch: 6| Step: 7
Training loss: 1.061637043952942
Validation loss: 2.250967780749003

Epoch: 6| Step: 8
Training loss: 1.184556245803833
Validation loss: 2.2416780988375344

Epoch: 6| Step: 9
Training loss: 1.8805317878723145
Validation loss: 2.212836265563965

Epoch: 6| Step: 10
Training loss: 2.294865131378174
Validation loss: 2.2253838976224265

Epoch: 6| Step: 11
Training loss: 1.990998387336731
Validation loss: 2.2161871989568076

Epoch: 6| Step: 12
Training loss: 1.096419095993042
Validation loss: 2.185317873954773

Epoch: 6| Step: 13
Training loss: 1.1371320486068726
Validation loss: 2.1961589654286704

Epoch: 307| Step: 0
Training loss: 1.5283081531524658
Validation loss: 2.1867297887802124

Epoch: 6| Step: 1
Training loss: 1.332108736038208
Validation loss: 2.1867273251215615

Epoch: 6| Step: 2
Training loss: 1.2703070640563965
Validation loss: 2.178780456384023

Epoch: 6| Step: 3
Training loss: 1.4435838460922241
Validation loss: 2.18349152803421

Epoch: 6| Step: 4
Training loss: 1.9655483961105347
Validation loss: 2.1897709170977273

Epoch: 6| Step: 5
Training loss: 1.654302954673767
Validation loss: 2.184289733568827

Epoch: 6| Step: 6
Training loss: 1.0754691362380981
Validation loss: 2.182757337888082

Epoch: 6| Step: 7
Training loss: 1.0869094133377075
Validation loss: 2.194399138291677

Epoch: 6| Step: 8
Training loss: 1.5231566429138184
Validation loss: 2.2091064055760703

Epoch: 6| Step: 9
Training loss: 1.7435402870178223
Validation loss: 2.209213376045227

Epoch: 6| Step: 10
Training loss: 1.351894736289978
Validation loss: 2.1980877916018167

Epoch: 6| Step: 11
Training loss: 1.7381564378738403
Validation loss: 2.238885521888733

Epoch: 6| Step: 12
Training loss: 1.5503854751586914
Validation loss: 2.2581334908803306

Epoch: 6| Step: 13
Training loss: 1.0336135625839233
Validation loss: 2.255534807840983

Epoch: 308| Step: 0
Training loss: 1.744960069656372
Validation loss: 2.2103288968404136

Epoch: 6| Step: 1
Training loss: 1.00296151638031
Validation loss: 2.2077947656313577

Epoch: 6| Step: 2
Training loss: 0.5571640133857727
Validation loss: 2.193967044353485

Epoch: 6| Step: 3
Training loss: 1.4253959655761719
Validation loss: 2.194430490334829

Epoch: 6| Step: 4
Training loss: 1.5197395086288452
Validation loss: 2.1827988028526306

Epoch: 6| Step: 5
Training loss: 2.277902841567993
Validation loss: 2.1923448046048484

Epoch: 6| Step: 6
Training loss: 0.7227461338043213
Validation loss: 2.1808373729387918

Epoch: 6| Step: 7
Training loss: 1.2515559196472168
Validation loss: 2.2132989962895713

Epoch: 6| Step: 8
Training loss: 1.2238385677337646
Validation loss: 2.2319035132726035

Epoch: 6| Step: 9
Training loss: 1.1265215873718262
Validation loss: 2.2319080034891763

Epoch: 6| Step: 10
Training loss: 1.210029125213623
Validation loss: 2.242579619089762

Epoch: 6| Step: 11
Training loss: 1.7360559701919556
Validation loss: 2.2496291200319924

Epoch: 6| Step: 12
Training loss: 2.4383180141448975
Validation loss: 2.2715750137964883

Epoch: 6| Step: 13
Training loss: 2.4702138900756836
Validation loss: 2.258023202419281

Epoch: 309| Step: 0
Training loss: 1.736210584640503
Validation loss: 2.290165901184082

Epoch: 6| Step: 1
Training loss: 1.5408973693847656
Validation loss: 2.3013654748598733

Epoch: 6| Step: 2
Training loss: 1.452452540397644
Validation loss: 2.2755277951558432

Epoch: 6| Step: 3
Training loss: 1.4099633693695068
Validation loss: 2.242049515247345

Epoch: 6| Step: 4
Training loss: 1.0446398258209229
Validation loss: 2.2362061937650046

Epoch: 6| Step: 5
Training loss: 2.1142520904541016
Validation loss: 2.2100154956181846

Epoch: 6| Step: 6
Training loss: 1.0523302555084229
Validation loss: 2.202996095021566

Epoch: 6| Step: 7
Training loss: 1.1317604780197144
Validation loss: 2.216491719086965

Epoch: 6| Step: 8
Training loss: 1.7241337299346924
Validation loss: 2.219760298728943

Epoch: 6| Step: 9
Training loss: 2.0753886699676514
Validation loss: 2.222445329030355

Epoch: 6| Step: 10
Training loss: 1.4684627056121826
Validation loss: 2.2242276469866433

Epoch: 6| Step: 11
Training loss: 1.6067795753479004
Validation loss: 2.2431024312973022

Epoch: 6| Step: 12
Training loss: 1.6137195825576782
Validation loss: 2.2445793946584067

Epoch: 6| Step: 13
Training loss: 1.1531612873077393
Validation loss: 2.241906444231669

Epoch: 310| Step: 0
Training loss: 1.596550464630127
Validation loss: 2.24717648824056

Epoch: 6| Step: 1
Training loss: 1.3554821014404297
Validation loss: 2.234079877535502

Epoch: 6| Step: 2
Training loss: 1.5957462787628174
Validation loss: 2.2425595919291177

Epoch: 6| Step: 3
Training loss: 1.5192577838897705
Validation loss: 2.2283304731051126

Epoch: 6| Step: 4
Training loss: 1.2438948154449463
Validation loss: 2.237760086854299

Epoch: 6| Step: 5
Training loss: 1.1543742418289185
Validation loss: 2.2167303363482156

Epoch: 6| Step: 6
Training loss: 2.0590248107910156
Validation loss: 2.247843086719513

Epoch: 6| Step: 7
Training loss: 1.7255116701126099
Validation loss: 2.23175976673762

Epoch: 6| Step: 8
Training loss: 1.1206532716751099
Validation loss: 2.240628441174825

Epoch: 6| Step: 9
Training loss: 0.7359440326690674
Validation loss: 2.2223638892173767

Epoch: 6| Step: 10
Training loss: 1.8039003610610962
Validation loss: 2.211266497770945

Epoch: 6| Step: 11
Training loss: 1.7916741371154785
Validation loss: 2.2234878142674765

Epoch: 6| Step: 12
Training loss: 1.4431588649749756
Validation loss: 2.2313089966773987

Epoch: 6| Step: 13
Training loss: 2.1706390380859375
Validation loss: 2.2104198733965554

Epoch: 311| Step: 0
Training loss: 1.3648518323898315
Validation loss: 2.23485138018926

Epoch: 6| Step: 1
Training loss: 0.8856128454208374
Validation loss: 2.23561163743337

Epoch: 6| Step: 2
Training loss: 1.7080509662628174
Validation loss: 2.209900915622711

Epoch: 6| Step: 3
Training loss: 1.923858642578125
Validation loss: 2.2452120582262673

Epoch: 6| Step: 4
Training loss: 1.5518476963043213
Validation loss: 2.230827212333679

Epoch: 6| Step: 5
Training loss: 1.6211349964141846
Validation loss: 2.2397483189900718

Epoch: 6| Step: 6
Training loss: 1.4376657009124756
Validation loss: 2.2499824364980063

Epoch: 6| Step: 7
Training loss: 1.3767741918563843
Validation loss: 2.2466857035954795

Epoch: 6| Step: 8
Training loss: 1.7602201700210571
Validation loss: 2.249218682448069

Epoch: 6| Step: 9
Training loss: 1.5382227897644043
Validation loss: 2.278964638710022

Epoch: 6| Step: 10
Training loss: 2.0080864429473877
Validation loss: 2.26144802570343

Epoch: 6| Step: 11
Training loss: 1.1514437198638916
Validation loss: 2.2503161827723184

Epoch: 6| Step: 12
Training loss: 1.0173983573913574
Validation loss: 2.2579362392425537

Epoch: 6| Step: 13
Training loss: 1.2619640827178955
Validation loss: 2.23043421904246

Epoch: 312| Step: 0
Training loss: 1.5709717273712158
Validation loss: 2.2162617842356362

Epoch: 6| Step: 1
Training loss: 1.2163469791412354
Validation loss: 2.24231485525767

Epoch: 6| Step: 2
Training loss: 1.506454348564148
Validation loss: 2.243508795897166

Epoch: 6| Step: 3
Training loss: 0.9652556777000427
Validation loss: 2.219751000404358

Epoch: 6| Step: 4
Training loss: 1.380640983581543
Validation loss: 2.1961904168128967

Epoch: 6| Step: 5
Training loss: 1.8235224485397339
Validation loss: 2.220384101072947

Epoch: 6| Step: 6
Training loss: 1.4072394371032715
Validation loss: 2.2109302083651223

Epoch: 6| Step: 7
Training loss: 1.3002448081970215
Validation loss: 2.1814588705698648

Epoch: 6| Step: 8
Training loss: 1.6295504570007324
Validation loss: 2.1877588033676147

Epoch: 6| Step: 9
Training loss: 2.0365641117095947
Validation loss: 2.197407841682434

Epoch: 6| Step: 10
Training loss: 1.3131369352340698
Validation loss: 2.199652155240377

Epoch: 6| Step: 11
Training loss: 1.9809260368347168
Validation loss: 2.1962823073069253

Epoch: 6| Step: 12
Training loss: 0.8245106935501099
Validation loss: 2.185150464375814

Epoch: 6| Step: 13
Training loss: 1.261156439781189
Validation loss: 2.203527589639028

Epoch: 313| Step: 0
Training loss: 1.71806001663208
Validation loss: 2.2115272680918374

Epoch: 6| Step: 1
Training loss: 1.1555100679397583
Validation loss: 2.18034032980601

Epoch: 6| Step: 2
Training loss: 1.1790744066238403
Validation loss: 2.171003540356954

Epoch: 6| Step: 3
Training loss: 1.9649925231933594
Validation loss: 2.1915328105290732

Epoch: 6| Step: 4
Training loss: 1.1415740251541138
Validation loss: 2.174433251221975

Epoch: 6| Step: 5
Training loss: 1.3092777729034424
Validation loss: 2.157838821411133

Epoch: 6| Step: 6
Training loss: 0.9652957916259766
Validation loss: 2.1962427298227944

Epoch: 6| Step: 7
Training loss: 1.6565889120101929
Validation loss: 2.190562427043915

Epoch: 6| Step: 8
Training loss: 1.0943387746810913
Validation loss: 2.19465963045756

Epoch: 6| Step: 9
Training loss: 1.4081306457519531
Validation loss: 2.205112417538961

Epoch: 6| Step: 10
Training loss: 2.0129058361053467
Validation loss: 2.220112363497416

Epoch: 6| Step: 11
Training loss: 1.3464791774749756
Validation loss: 2.229523460070292

Epoch: 6| Step: 12
Training loss: 1.18869149684906
Validation loss: 2.220265785853068

Epoch: 6| Step: 13
Training loss: 1.5921478271484375
Validation loss: 2.25743039449056

Epoch: 314| Step: 0
Training loss: 1.4141271114349365
Validation loss: 2.267508308092753

Epoch: 6| Step: 1
Training loss: 0.8997251391410828
Validation loss: 2.2456897099812827

Epoch: 6| Step: 2
Training loss: 2.0984034538269043
Validation loss: 2.239797532558441

Epoch: 6| Step: 3
Training loss: 1.4819940328598022
Validation loss: 2.230085770289103

Epoch: 6| Step: 4
Training loss: 1.2623975276947021
Validation loss: 2.248479346434275

Epoch: 6| Step: 5
Training loss: 1.6255371570587158
Validation loss: 2.251940151055654

Epoch: 6| Step: 6
Training loss: 0.9752439856529236
Validation loss: 2.2016215324401855

Epoch: 6| Step: 7
Training loss: 1.653466820716858
Validation loss: 2.200238207976023

Epoch: 6| Step: 8
Training loss: 1.6678998470306396
Validation loss: 2.2081400553385415

Epoch: 6| Step: 9
Training loss: 1.9900612831115723
Validation loss: 2.220826188723246

Epoch: 6| Step: 10
Training loss: 1.4544744491577148
Validation loss: 2.2245298425356546

Epoch: 6| Step: 11
Training loss: 1.9025417566299438
Validation loss: 2.215685764948527

Epoch: 6| Step: 12
Training loss: 1.2834213972091675
Validation loss: 2.194085160891215

Epoch: 6| Step: 13
Training loss: 1.4167275428771973
Validation loss: 2.2115142742792764

Epoch: 315| Step: 0
Training loss: 1.277665376663208
Validation loss: 2.210473040739695

Epoch: 6| Step: 1
Training loss: 1.575721263885498
Validation loss: 2.263333479563395

Epoch: 6| Step: 2
Training loss: 1.7158101797103882
Validation loss: 2.2427297830581665

Epoch: 6| Step: 3
Training loss: 1.6423773765563965
Validation loss: 2.2523347536722818

Epoch: 6| Step: 4
Training loss: 1.3444709777832031
Validation loss: 2.2610753774642944

Epoch: 6| Step: 5
Training loss: 1.3483710289001465
Validation loss: 2.2274163564046225

Epoch: 6| Step: 6
Training loss: 1.2820502519607544
Validation loss: 2.2150055170059204

Epoch: 6| Step: 7
Training loss: 1.78248131275177
Validation loss: 2.198696513970693

Epoch: 6| Step: 8
Training loss: 1.5311212539672852
Validation loss: 2.2001888950665793

Epoch: 6| Step: 9
Training loss: 1.3478341102600098
Validation loss: 2.1923659245173135

Epoch: 6| Step: 10
Training loss: 1.385063886642456
Validation loss: 2.21540097395579

Epoch: 6| Step: 11
Training loss: 1.3088696002960205
Validation loss: 2.1831740140914917

Epoch: 6| Step: 12
Training loss: 1.9150824546813965
Validation loss: 2.1970708767573037

Epoch: 6| Step: 13
Training loss: 2.127187728881836
Validation loss: 2.1994078755378723

Epoch: 316| Step: 0
Training loss: 0.8683804273605347
Validation loss: 2.206240713596344

Epoch: 6| Step: 1
Training loss: 1.4531010389328003
Validation loss: 2.191940704981486

Epoch: 6| Step: 2
Training loss: 1.6088159084320068
Validation loss: 2.2337198853492737

Epoch: 6| Step: 3
Training loss: 1.8645508289337158
Validation loss: 2.248052716255188

Epoch: 6| Step: 4
Training loss: 0.9807481169700623
Validation loss: 2.255053540070852

Epoch: 6| Step: 5
Training loss: 1.2772380113601685
Validation loss: 2.268755316734314

Epoch: 6| Step: 6
Training loss: 0.8430958390235901
Validation loss: 2.2461782892545066

Epoch: 6| Step: 7
Training loss: 2.4900760650634766
Validation loss: 2.2914621829986572

Epoch: 6| Step: 8
Training loss: 1.1754133701324463
Validation loss: 2.2534993489583335

Epoch: 6| Step: 9
Training loss: 1.4126343727111816
Validation loss: 2.2578123807907104

Epoch: 6| Step: 10
Training loss: 1.4587223529815674
Validation loss: 2.2631829579671225

Epoch: 6| Step: 11
Training loss: 0.8991654515266418
Validation loss: 2.2567792733510337

Epoch: 6| Step: 12
Training loss: 1.9448943138122559
Validation loss: 2.2544257839520774

Epoch: 6| Step: 13
Training loss: 0.9846898317337036
Validation loss: 2.2126618226369223

Epoch: 317| Step: 0
Training loss: 1.1365940570831299
Validation loss: 2.203315873940786

Epoch: 6| Step: 1
Training loss: 0.7715111970901489
Validation loss: 2.225946327050527

Epoch: 6| Step: 2
Training loss: 1.5607569217681885
Validation loss: 2.237080673376719

Epoch: 6| Step: 3
Training loss: 1.0087414979934692
Validation loss: 2.2312963406244912

Epoch: 6| Step: 4
Training loss: 1.7058970928192139
Validation loss: 2.225578327973684

Epoch: 6| Step: 5
Training loss: 1.23065185546875
Validation loss: 2.2264854113260903

Epoch: 6| Step: 6
Training loss: 1.553957462310791
Validation loss: 2.253885785738627

Epoch: 6| Step: 7
Training loss: 1.1673558950424194
Validation loss: 2.232794384161631

Epoch: 6| Step: 8
Training loss: 2.0245957374572754
Validation loss: 2.222365935643514

Epoch: 6| Step: 9
Training loss: 1.8069608211517334
Validation loss: 2.187088886896769

Epoch: 6| Step: 10
Training loss: 1.4054373502731323
Validation loss: 2.1977673371632895

Epoch: 6| Step: 11
Training loss: 1.527590036392212
Validation loss: 2.188125212987264

Epoch: 6| Step: 12
Training loss: 1.2607964277267456
Validation loss: 2.2256988684336343

Epoch: 6| Step: 13
Training loss: 1.2358105182647705
Validation loss: 2.194125254948934

Epoch: 318| Step: 0
Training loss: 1.5352845191955566
Validation loss: 2.1858041087786355

Epoch: 6| Step: 1
Training loss: 0.7642531991004944
Validation loss: 2.1767932971318564

Epoch: 6| Step: 2
Training loss: 0.9415160417556763
Validation loss: 2.186899185180664

Epoch: 6| Step: 3
Training loss: 1.8544142246246338
Validation loss: 2.1830747922261557

Epoch: 6| Step: 4
Training loss: 2.298039436340332
Validation loss: 2.193696995576223

Epoch: 6| Step: 5
Training loss: 1.3994839191436768
Validation loss: 2.1874630649884543

Epoch: 6| Step: 6
Training loss: 1.7080472707748413
Validation loss: 2.224604288736979

Epoch: 6| Step: 7
Training loss: 2.4257068634033203
Validation loss: 2.2215729355812073

Epoch: 6| Step: 8
Training loss: 0.8851305246353149
Validation loss: 2.2193576097488403

Epoch: 6| Step: 9
Training loss: 1.817926287651062
Validation loss: 2.2335095604260764

Epoch: 6| Step: 10
Training loss: 1.0731334686279297
Validation loss: 2.2211670875549316

Epoch: 6| Step: 11
Training loss: 1.752755880355835
Validation loss: 2.2512736519177756

Epoch: 6| Step: 12
Training loss: 1.566420078277588
Validation loss: 2.288118282953898

Epoch: 6| Step: 13
Training loss: 1.448004961013794
Validation loss: 2.272290905316671

Epoch: 319| Step: 0
Training loss: 2.241623878479004
Validation loss: 2.2596269051233926

Epoch: 6| Step: 1
Training loss: 1.5269780158996582
Validation loss: 2.238699793815613

Epoch: 6| Step: 2
Training loss: 1.1890804767608643
Validation loss: 2.22070719798406

Epoch: 6| Step: 3
Training loss: 1.1982753276824951
Validation loss: 2.244583547115326

Epoch: 6| Step: 4
Training loss: 1.9814906120300293
Validation loss: 2.2237502535184226

Epoch: 6| Step: 5
Training loss: 1.6482174396514893
Validation loss: 2.23153148094813

Epoch: 6| Step: 6
Training loss: 1.2298468351364136
Validation loss: 2.224544127782186

Epoch: 6| Step: 7
Training loss: 1.3811646699905396
Validation loss: 2.257058560848236

Epoch: 6| Step: 8
Training loss: 1.5719473361968994
Validation loss: 2.2441043655077615

Epoch: 6| Step: 9
Training loss: 2.0158004760742188
Validation loss: 2.2332232197125754

Epoch: 6| Step: 10
Training loss: 0.8553188443183899
Validation loss: 2.257142941157023

Epoch: 6| Step: 11
Training loss: 1.264763593673706
Validation loss: 2.2331449588139853

Epoch: 6| Step: 12
Training loss: 0.7083175182342529
Validation loss: 2.235463639100393

Epoch: 6| Step: 13
Training loss: 1.0498089790344238
Validation loss: 2.25381072362264

Epoch: 320| Step: 0
Training loss: 1.3606528043746948
Validation loss: 2.240527093410492

Epoch: 6| Step: 1
Training loss: 1.870217204093933
Validation loss: 2.2317821780840554

Epoch: 6| Step: 2
Training loss: 1.3700721263885498
Validation loss: 2.218242426713308

Epoch: 6| Step: 3
Training loss: 1.7529208660125732
Validation loss: 2.244859059651693

Epoch: 6| Step: 4
Training loss: 1.5311295986175537
Validation loss: 2.2284533182779946

Epoch: 6| Step: 5
Training loss: 1.2889413833618164
Validation loss: 2.234634737173716

Epoch: 6| Step: 6
Training loss: 0.8702875375747681
Validation loss: 2.241965393225352

Epoch: 6| Step: 7
Training loss: 1.1854643821716309
Validation loss: 2.2187566558519998

Epoch: 6| Step: 8
Training loss: 1.2025115489959717
Validation loss: 2.2256863911946616

Epoch: 6| Step: 9
Training loss: 1.3988115787506104
Validation loss: 2.215987185637156

Epoch: 6| Step: 10
Training loss: 1.4011343717575073
Validation loss: 2.2412007649739585

Epoch: 6| Step: 11
Training loss: 1.78507661819458
Validation loss: 2.2278721729914346

Epoch: 6| Step: 12
Training loss: 1.0004515647888184
Validation loss: 2.2458022038141885

Epoch: 6| Step: 13
Training loss: 1.698459506034851
Validation loss: 2.2356796065966287

Epoch: 321| Step: 0
Training loss: 1.2497811317443848
Validation loss: 2.2324963013331094

Epoch: 6| Step: 1
Training loss: 1.5548977851867676
Validation loss: 2.2431982159614563

Epoch: 6| Step: 2
Training loss: 1.246009111404419
Validation loss: 2.2359073956807456

Epoch: 6| Step: 3
Training loss: 0.8654083013534546
Validation loss: 2.25515345732371

Epoch: 6| Step: 4
Training loss: 1.2971941232681274
Validation loss: 2.2837961713473

Epoch: 6| Step: 5
Training loss: 1.93319833278656
Validation loss: 2.2940117716789246

Epoch: 6| Step: 6
Training loss: 1.3399463891983032
Validation loss: 2.281480073928833

Epoch: 6| Step: 7
Training loss: 2.2076690196990967
Validation loss: 2.2941786448160806

Epoch: 6| Step: 8
Training loss: 1.881440281867981
Validation loss: 2.2808804710706077

Epoch: 6| Step: 9
Training loss: 1.3264700174331665
Validation loss: 2.285875380039215

Epoch: 6| Step: 10
Training loss: 0.9818606376647949
Validation loss: 2.2698847452799478

Epoch: 6| Step: 11
Training loss: 1.8162879943847656
Validation loss: 2.2676262855529785

Epoch: 6| Step: 12
Training loss: 1.2737714052200317
Validation loss: 2.2411521077156067

Epoch: 6| Step: 13
Training loss: 1.3407620191574097
Validation loss: 2.282450238863627

Epoch: 322| Step: 0
Training loss: 1.8959558010101318
Validation loss: 2.2374500830968223

Epoch: 6| Step: 1
Training loss: 0.9989703297615051
Validation loss: 2.2189078529675803

Epoch: 6| Step: 2
Training loss: 1.1696864366531372
Validation loss: 2.2093053460121155

Epoch: 6| Step: 3
Training loss: 1.3633038997650146
Validation loss: 2.1947035789489746

Epoch: 6| Step: 4
Training loss: 2.1253979206085205
Validation loss: 2.2235385378201804

Epoch: 6| Step: 5
Training loss: 1.41481351852417
Validation loss: 2.218103587627411

Epoch: 6| Step: 6
Training loss: 0.8151030540466309
Validation loss: 2.2209970355033875

Epoch: 6| Step: 7
Training loss: 1.6234872341156006
Validation loss: 2.230334381262461

Epoch: 6| Step: 8
Training loss: 1.2615022659301758
Validation loss: 2.239723722139994

Epoch: 6| Step: 9
Training loss: 2.0230467319488525
Validation loss: 2.2456220189730325

Epoch: 6| Step: 10
Training loss: 1.1648705005645752
Validation loss: 2.1864591439565024

Epoch: 6| Step: 11
Training loss: 1.14156973361969
Validation loss: 2.2308058738708496

Epoch: 6| Step: 12
Training loss: 0.9942668676376343
Validation loss: 2.1871997117996216

Epoch: 6| Step: 13
Training loss: 1.6722006797790527
Validation loss: 2.2316489020983377

Epoch: 323| Step: 0
Training loss: 1.0527071952819824
Validation loss: 2.2247480154037476

Epoch: 6| Step: 1
Training loss: 1.1216175556182861
Validation loss: 2.228351672490438

Epoch: 6| Step: 2
Training loss: 1.3329676389694214
Validation loss: 2.2061959902445474

Epoch: 6| Step: 3
Training loss: 0.9397473335266113
Validation loss: 2.2198789715766907

Epoch: 6| Step: 4
Training loss: 1.4139161109924316
Validation loss: 2.231908162434896

Epoch: 6| Step: 5
Training loss: 1.2806422710418701
Validation loss: 2.2341557343800864

Epoch: 6| Step: 6
Training loss: 1.1961690187454224
Validation loss: 2.2145866751670837

Epoch: 6| Step: 7
Training loss: 1.919969916343689
Validation loss: 2.23261958360672

Epoch: 6| Step: 8
Training loss: 1.1532468795776367
Validation loss: 2.2109854420026145

Epoch: 6| Step: 9
Training loss: 1.794075608253479
Validation loss: 2.216586112976074

Epoch: 6| Step: 10
Training loss: 1.5557760000228882
Validation loss: 2.2274431784947715

Epoch: 6| Step: 11
Training loss: 1.3210002183914185
Validation loss: 2.210151433944702

Epoch: 6| Step: 12
Training loss: 1.479698657989502
Validation loss: 2.211306889851888

Epoch: 6| Step: 13
Training loss: 1.2685678005218506
Validation loss: 2.1922431190808616

Epoch: 324| Step: 0
Training loss: 1.1405035257339478
Validation loss: 2.2174390951792398

Epoch: 6| Step: 1
Training loss: 0.9443973898887634
Validation loss: 2.195199112097422

Epoch: 6| Step: 2
Training loss: 1.660325050354004
Validation loss: 2.210265100002289

Epoch: 6| Step: 3
Training loss: 1.3342523574829102
Validation loss: 2.2067389686902366

Epoch: 6| Step: 4
Training loss: 1.982330560684204
Validation loss: 2.198465645313263

Epoch: 6| Step: 5
Training loss: 1.3596887588500977
Validation loss: 2.183535714944204

Epoch: 6| Step: 6
Training loss: 1.4931116104125977
Validation loss: 2.2145944833755493

Epoch: 6| Step: 7
Training loss: 1.027554988861084
Validation loss: 2.2113602558771768

Epoch: 6| Step: 8
Training loss: 1.7669034004211426
Validation loss: 2.220081090927124

Epoch: 6| Step: 9
Training loss: 1.4309189319610596
Validation loss: 2.202444533507029

Epoch: 6| Step: 10
Training loss: 1.2703999280929565
Validation loss: 2.220747470855713

Epoch: 6| Step: 11
Training loss: 1.8333652019500732
Validation loss: 2.236410220464071

Epoch: 6| Step: 12
Training loss: 0.8874549865722656
Validation loss: 2.2220688660939536

Epoch: 6| Step: 13
Training loss: 1.065864086151123
Validation loss: 2.2231733798980713

Epoch: 325| Step: 0
Training loss: 2.485940456390381
Validation loss: 2.2510175704956055

Epoch: 6| Step: 1
Training loss: 1.3882243633270264
Validation loss: 2.2441776394844055

Epoch: 6| Step: 2
Training loss: 1.4742450714111328
Validation loss: 2.2189329862594604

Epoch: 6| Step: 3
Training loss: 1.4443399906158447
Validation loss: 2.2308719158172607

Epoch: 6| Step: 4
Training loss: 1.6773951053619385
Validation loss: 2.236880620320638

Epoch: 6| Step: 5
Training loss: 1.3488482236862183
Validation loss: 2.21091361840566

Epoch: 6| Step: 6
Training loss: 1.4966737031936646
Validation loss: 2.2420934438705444

Epoch: 6| Step: 7
Training loss: 1.1130115985870361
Validation loss: 2.2287862300872803

Epoch: 6| Step: 8
Training loss: 1.2042851448059082
Validation loss: 2.22138774394989

Epoch: 6| Step: 9
Training loss: 0.9392774701118469
Validation loss: 2.2307753562927246

Epoch: 6| Step: 10
Training loss: 1.4540499448776245
Validation loss: 2.2281197706858316

Epoch: 6| Step: 11
Training loss: 1.5003483295440674
Validation loss: 2.2092498739560447

Epoch: 6| Step: 12
Training loss: 1.672065019607544
Validation loss: 2.207274158795675

Epoch: 6| Step: 13
Training loss: 1.4234888553619385
Validation loss: 2.1911008755366006

Epoch: 326| Step: 0
Training loss: 0.8876463174819946
Validation loss: 2.194925606250763

Epoch: 6| Step: 1
Training loss: 1.1298866271972656
Validation loss: 2.1889890829722085

Epoch: 6| Step: 2
Training loss: 1.4628621339797974
Validation loss: 2.177694002787272

Epoch: 6| Step: 3
Training loss: 1.6259119510650635
Validation loss: 2.1715092062950134

Epoch: 6| Step: 4
Training loss: 1.2556159496307373
Validation loss: 2.182374060153961

Epoch: 6| Step: 5
Training loss: 0.9168757796287537
Validation loss: 2.1792054971059165

Epoch: 6| Step: 6
Training loss: 1.2068891525268555
Validation loss: 2.193213641643524

Epoch: 6| Step: 7
Training loss: 1.164277195930481
Validation loss: 2.1712450981140137

Epoch: 6| Step: 8
Training loss: 1.02191162109375
Validation loss: 2.1803139050801597

Epoch: 6| Step: 9
Training loss: 1.8073992729187012
Validation loss: 2.169946233431498

Epoch: 6| Step: 10
Training loss: 1.6960742473602295
Validation loss: 2.176172892252604

Epoch: 6| Step: 11
Training loss: 1.1282283067703247
Validation loss: 2.174732486406962

Epoch: 6| Step: 12
Training loss: 2.733516216278076
Validation loss: 2.176996866861979

Epoch: 6| Step: 13
Training loss: 1.1122560501098633
Validation loss: 2.1753608783086142

Epoch: 327| Step: 0
Training loss: 1.9607820510864258
Validation loss: 2.155841807524363

Epoch: 6| Step: 1
Training loss: 0.9549174904823303
Validation loss: 2.180870691935221

Epoch: 6| Step: 2
Training loss: 1.1677302122116089
Validation loss: 2.1629372040430703

Epoch: 6| Step: 3
Training loss: 1.725641131401062
Validation loss: 2.1783964236577353

Epoch: 6| Step: 4
Training loss: 1.2727471590042114
Validation loss: 2.166222333908081

Epoch: 6| Step: 5
Training loss: 0.8540761470794678
Validation loss: 2.16135174036026

Epoch: 6| Step: 6
Training loss: 1.585038423538208
Validation loss: 2.204302748044332

Epoch: 6| Step: 7
Training loss: 1.5193488597869873
Validation loss: 2.168631116549174

Epoch: 6| Step: 8
Training loss: 1.5154294967651367
Validation loss: 2.1965551376342773

Epoch: 6| Step: 9
Training loss: 1.0128368139266968
Validation loss: 2.211346964041392

Epoch: 6| Step: 10
Training loss: 1.8146772384643555
Validation loss: 2.198570112387339

Epoch: 6| Step: 11
Training loss: 0.9382410645484924
Validation loss: 2.2063126961390176

Epoch: 6| Step: 12
Training loss: 0.9476292133331299
Validation loss: 2.2118812799453735

Epoch: 6| Step: 13
Training loss: 1.4426474571228027
Validation loss: 2.200038433074951

Epoch: 328| Step: 0
Training loss: 1.4916385412216187
Validation loss: 2.205399533112844

Epoch: 6| Step: 1
Training loss: 1.5874342918395996
Validation loss: 2.216905951499939

Epoch: 6| Step: 2
Training loss: 1.2785471677780151
Validation loss: 2.2119304736455283

Epoch: 6| Step: 3
Training loss: 1.2913315296173096
Validation loss: 2.19663937886556

Epoch: 6| Step: 4
Training loss: 1.105642318725586
Validation loss: 2.2014411886533103

Epoch: 6| Step: 5
Training loss: 1.5823378562927246
Validation loss: 2.2155928015708923

Epoch: 6| Step: 6
Training loss: 0.8609472513198853
Validation loss: 2.199479361375173

Epoch: 6| Step: 7
Training loss: 1.316632628440857
Validation loss: 2.2037898898124695

Epoch: 6| Step: 8
Training loss: 1.3687236309051514
Validation loss: 2.222402552763621

Epoch: 6| Step: 9
Training loss: 1.0888102054595947
Validation loss: 2.184772769610087

Epoch: 6| Step: 10
Training loss: 1.1212286949157715
Validation loss: 2.215365747610728

Epoch: 6| Step: 11
Training loss: 1.70533287525177
Validation loss: 2.2327545881271362

Epoch: 6| Step: 12
Training loss: 1.522192358970642
Validation loss: 2.2362712820370994

Epoch: 6| Step: 13
Training loss: 1.4547609090805054
Validation loss: 2.2389007012049356

Epoch: 329| Step: 0
Training loss: 1.1647547483444214
Validation loss: 2.2118066946665444

Epoch: 6| Step: 1
Training loss: 1.7037343978881836
Validation loss: 2.220671534538269

Epoch: 6| Step: 2
Training loss: 1.4117316007614136
Validation loss: 2.2096086541811624

Epoch: 6| Step: 3
Training loss: 0.8921871781349182
Validation loss: 2.2250704765319824

Epoch: 6| Step: 4
Training loss: 1.1733065843582153
Validation loss: 2.2140676776568093

Epoch: 6| Step: 5
Training loss: 1.6428605318069458
Validation loss: 2.226654827594757

Epoch: 6| Step: 6
Training loss: 2.0819091796875
Validation loss: 2.194988946119944

Epoch: 6| Step: 7
Training loss: 0.6618616580963135
Validation loss: 2.21470046043396

Epoch: 6| Step: 8
Training loss: 1.071505069732666
Validation loss: 2.2336097160975137

Epoch: 6| Step: 9
Training loss: 1.189115047454834
Validation loss: 2.252098043759664

Epoch: 6| Step: 10
Training loss: 1.2169021368026733
Validation loss: 2.2142747243245444

Epoch: 6| Step: 11
Training loss: 1.714569330215454
Validation loss: 2.1967811783154807

Epoch: 6| Step: 12
Training loss: 0.9012145400047302
Validation loss: 2.252629558245341

Epoch: 6| Step: 13
Training loss: 1.3844325542449951
Validation loss: 2.2339842319488525

Epoch: 330| Step: 0
Training loss: 1.1886138916015625
Validation loss: 2.2783129811286926

Epoch: 6| Step: 1
Training loss: 1.9784749746322632
Validation loss: 2.268559296925863

Epoch: 6| Step: 2
Training loss: 1.7447576522827148
Validation loss: 2.236735463142395

Epoch: 6| Step: 3
Training loss: 1.1899282932281494
Validation loss: 2.228900949160258

Epoch: 6| Step: 4
Training loss: 1.4236459732055664
Validation loss: 2.2203001976013184

Epoch: 6| Step: 5
Training loss: 0.5951282382011414
Validation loss: 2.2370123664538064

Epoch: 6| Step: 6
Training loss: 1.1478593349456787
Validation loss: 2.248563766479492

Epoch: 6| Step: 7
Training loss: 1.5561048984527588
Validation loss: 2.2198041677474976

Epoch: 6| Step: 8
Training loss: 1.3163800239562988
Validation loss: 2.2324978510538735

Epoch: 6| Step: 9
Training loss: 1.4747885465621948
Validation loss: 2.2351542711257935

Epoch: 6| Step: 10
Training loss: 1.0414713621139526
Validation loss: 2.197112480799357

Epoch: 6| Step: 11
Training loss: 1.2029988765716553
Validation loss: 2.2174094716707864

Epoch: 6| Step: 12
Training loss: 1.1265394687652588
Validation loss: 2.2381645043691

Epoch: 6| Step: 13
Training loss: 1.0778496265411377
Validation loss: 2.2211767435073853

Epoch: 331| Step: 0
Training loss: 1.4332528114318848
Validation loss: 2.1989564100901284

Epoch: 6| Step: 1
Training loss: 1.1414896249771118
Validation loss: 2.2229856053988137

Epoch: 6| Step: 2
Training loss: 1.0090086460113525
Validation loss: 2.22962079445521

Epoch: 6| Step: 3
Training loss: 1.1995185613632202
Validation loss: 2.2272714376449585

Epoch: 6| Step: 4
Training loss: 1.5192441940307617
Validation loss: 2.2447237173716226

Epoch: 6| Step: 5
Training loss: 1.328454852104187
Validation loss: 2.2421700954437256

Epoch: 6| Step: 6
Training loss: 0.9052254557609558
Validation loss: 2.2322929302851358

Epoch: 6| Step: 7
Training loss: 0.9527381062507629
Validation loss: 2.2029291788736978

Epoch: 6| Step: 8
Training loss: 1.3389627933502197
Validation loss: 2.2281176447868347

Epoch: 6| Step: 9
Training loss: 2.025280237197876
Validation loss: 2.2166072924931846

Epoch: 6| Step: 10
Training loss: 1.314314365386963
Validation loss: 2.200165609518687

Epoch: 6| Step: 11
Training loss: 1.6061877012252808
Validation loss: 2.194613774617513

Epoch: 6| Step: 12
Training loss: 1.2924925088882446
Validation loss: 2.215432365735372

Epoch: 6| Step: 13
Training loss: 1.18818199634552
Validation loss: 2.202460447947184

Epoch: 332| Step: 0
Training loss: 1.2800267934799194
Validation loss: 2.184142510096232

Epoch: 6| Step: 1
Training loss: 0.9271635413169861
Validation loss: 2.202610452969869

Epoch: 6| Step: 2
Training loss: 1.848738431930542
Validation loss: 2.2011504570643106

Epoch: 6| Step: 3
Training loss: 0.9050432443618774
Validation loss: 2.1942976315816245

Epoch: 6| Step: 4
Training loss: 1.5591439008712769
Validation loss: 2.2072054942448935

Epoch: 6| Step: 5
Training loss: 1.2303705215454102
Validation loss: 2.210603415966034

Epoch: 6| Step: 6
Training loss: 1.416085958480835
Validation loss: 2.2204976876576743

Epoch: 6| Step: 7
Training loss: 0.6863479018211365
Validation loss: 2.221457560857137

Epoch: 6| Step: 8
Training loss: 1.5738708972930908
Validation loss: 2.2185169061024985

Epoch: 6| Step: 9
Training loss: 1.3794338703155518
Validation loss: 2.2093364596366882

Epoch: 6| Step: 10
Training loss: 0.6691330671310425
Validation loss: 2.220528165499369

Epoch: 6| Step: 11
Training loss: 2.496891736984253
Validation loss: 2.2244197130203247

Epoch: 6| Step: 12
Training loss: 0.9048932790756226
Validation loss: 2.2160882353782654

Epoch: 6| Step: 13
Training loss: 1.4893383979797363
Validation loss: 2.2159135142962136

Epoch: 333| Step: 0
Training loss: 1.746680498123169
Validation loss: 2.213969588279724

Epoch: 6| Step: 1
Training loss: 1.9703233242034912
Validation loss: 2.2042102217674255

Epoch: 6| Step: 2
Training loss: 1.0443676710128784
Validation loss: 2.1900656819343567

Epoch: 6| Step: 3
Training loss: 1.1779626607894897
Validation loss: 2.228990832964579

Epoch: 6| Step: 4
Training loss: 1.2516870498657227
Validation loss: 2.1990617314974465

Epoch: 6| Step: 5
Training loss: 1.2105451822280884
Validation loss: 2.2070040504137673

Epoch: 6| Step: 6
Training loss: 1.4209702014923096
Validation loss: 2.2114514112472534

Epoch: 6| Step: 7
Training loss: 1.633824110031128
Validation loss: 2.1916809479395547

Epoch: 6| Step: 8
Training loss: 0.863510012626648
Validation loss: 2.1889621019363403

Epoch: 6| Step: 9
Training loss: 0.8963784575462341
Validation loss: 2.1782841285069785

Epoch: 6| Step: 10
Training loss: 1.0633153915405273
Validation loss: 2.1919886072476706

Epoch: 6| Step: 11
Training loss: 0.8083440661430359
Validation loss: 2.2032916943232217

Epoch: 6| Step: 12
Training loss: 1.286602258682251
Validation loss: 2.178732752799988

Epoch: 6| Step: 13
Training loss: 1.6618598699569702
Validation loss: 2.1704727609952292

Epoch: 334| Step: 0
Training loss: 1.729437232017517
Validation loss: 2.1816192070643106

Epoch: 6| Step: 1
Training loss: 0.9054211974143982
Validation loss: 2.1910915970802307

Epoch: 6| Step: 2
Training loss: 1.0322357416152954
Validation loss: 2.1741299827893577

Epoch: 6| Step: 3
Training loss: 0.9239315390586853
Validation loss: 2.172067403793335

Epoch: 6| Step: 4
Training loss: 1.0978001356124878
Validation loss: 2.209585348765055

Epoch: 6| Step: 5
Training loss: 1.0997419357299805
Validation loss: 2.196713070074717

Epoch: 6| Step: 6
Training loss: 1.1067614555358887
Validation loss: 2.159509261449178

Epoch: 6| Step: 7
Training loss: 1.7739157676696777
Validation loss: 2.188575565814972

Epoch: 6| Step: 8
Training loss: 1.062638282775879
Validation loss: 2.187971373399099

Epoch: 6| Step: 9
Training loss: 1.2263858318328857
Validation loss: 2.1907659769058228

Epoch: 6| Step: 10
Training loss: 1.0376601219177246
Validation loss: 2.215296983718872

Epoch: 6| Step: 11
Training loss: 2.2016868591308594
Validation loss: 2.220133384068807

Epoch: 6| Step: 12
Training loss: 1.186245083808899
Validation loss: 2.2358627716700235

Epoch: 6| Step: 13
Training loss: 1.570960283279419
Validation loss: 2.2363781730333963

Epoch: 335| Step: 0
Training loss: 1.0572763681411743
Validation loss: 2.2039379676183066

Epoch: 6| Step: 1
Training loss: 1.2536083459854126
Validation loss: 2.236047168572744

Epoch: 6| Step: 2
Training loss: 0.8092406988143921
Validation loss: 2.2203299403190613

Epoch: 6| Step: 3
Training loss: 1.6684603691101074
Validation loss: 2.241139769554138

Epoch: 6| Step: 4
Training loss: 1.3459999561309814
Validation loss: 2.2354478438695273

Epoch: 6| Step: 5
Training loss: 2.433833360671997
Validation loss: 2.1905310352643332

Epoch: 6| Step: 6
Training loss: 1.2094473838806152
Validation loss: 2.2208815813064575

Epoch: 6| Step: 7
Training loss: 1.0003072023391724
Validation loss: 2.20799728234609

Epoch: 6| Step: 8
Training loss: 0.9176886081695557
Validation loss: 2.2326156298319497

Epoch: 6| Step: 9
Training loss: 1.342528223991394
Validation loss: 2.246689558029175

Epoch: 6| Step: 10
Training loss: 1.6344985961914062
Validation loss: 2.2425097227096558

Epoch: 6| Step: 11
Training loss: 1.45246160030365
Validation loss: 2.253451863924662

Epoch: 6| Step: 12
Training loss: 1.0568434000015259
Validation loss: 2.216888348261515

Epoch: 6| Step: 13
Training loss: 1.112577199935913
Validation loss: 2.249532719453176

Epoch: 336| Step: 0
Training loss: 1.2101500034332275
Validation loss: 2.2134190599123635

Epoch: 6| Step: 1
Training loss: 1.604184865951538
Validation loss: 2.2192404667536416

Epoch: 6| Step: 2
Training loss: 1.314863681793213
Validation loss: 2.202808936436971

Epoch: 6| Step: 3
Training loss: 1.1055173873901367
Validation loss: 2.1936620076497397

Epoch: 6| Step: 4
Training loss: 1.3896466493606567
Validation loss: 2.191608508427938

Epoch: 6| Step: 5
Training loss: 1.4168131351470947
Validation loss: 2.1781564156214395

Epoch: 6| Step: 6
Training loss: 1.2239006757736206
Validation loss: 2.2035875717798867

Epoch: 6| Step: 7
Training loss: 0.4566412568092346
Validation loss: 2.1853747169176736

Epoch: 6| Step: 8
Training loss: 1.57223641872406
Validation loss: 2.196772317091624

Epoch: 6| Step: 9
Training loss: 0.8625818490982056
Validation loss: 2.210449973742167

Epoch: 6| Step: 10
Training loss: 1.8641252517700195
Validation loss: 2.1764883399009705

Epoch: 6| Step: 11
Training loss: 1.39336097240448
Validation loss: 2.1996643344561257

Epoch: 6| Step: 12
Training loss: 1.5306733846664429
Validation loss: 2.2074740727742515

Epoch: 6| Step: 13
Training loss: 1.396178960800171
Validation loss: 2.1921587189038596

Epoch: 337| Step: 0
Training loss: 1.380563497543335
Validation loss: 2.1768031318982444

Epoch: 6| Step: 1
Training loss: 1.245144248008728
Validation loss: 2.1733312606811523

Epoch: 6| Step: 2
Training loss: 1.3186460733413696
Validation loss: 2.165898382663727

Epoch: 6| Step: 3
Training loss: 1.9145081043243408
Validation loss: 2.1402143836021423

Epoch: 6| Step: 4
Training loss: 1.2797081470489502
Validation loss: 2.163399815559387

Epoch: 6| Step: 5
Training loss: 1.4846723079681396
Validation loss: 2.1503897309303284

Epoch: 6| Step: 6
Training loss: 1.2190992832183838
Validation loss: 2.1594114700953164

Epoch: 6| Step: 7
Training loss: 1.0696156024932861
Validation loss: 2.141621947288513

Epoch: 6| Step: 8
Training loss: 1.1610443592071533
Validation loss: 2.1620551149050393

Epoch: 6| Step: 9
Training loss: 1.2744288444519043
Validation loss: 2.1694499850273132

Epoch: 6| Step: 10
Training loss: 1.2505346536636353
Validation loss: 2.1474446853001914

Epoch: 6| Step: 11
Training loss: 1.3118617534637451
Validation loss: 2.1473843455314636

Epoch: 6| Step: 12
Training loss: 1.3296871185302734
Validation loss: 2.1648956537246704

Epoch: 6| Step: 13
Training loss: 1.1400222778320312
Validation loss: 2.204453706741333

Epoch: 338| Step: 0
Training loss: 1.2715811729431152
Validation loss: 2.220988392829895

Epoch: 6| Step: 1
Training loss: 1.4605379104614258
Validation loss: 2.221797207991282

Epoch: 6| Step: 2
Training loss: 0.887300968170166
Validation loss: 2.2058544953664145

Epoch: 6| Step: 3
Training loss: 1.2438827753067017
Validation loss: 2.236034333705902

Epoch: 6| Step: 4
Training loss: 1.0821259021759033
Validation loss: 2.2048641045888266

Epoch: 6| Step: 5
Training loss: 0.6079851388931274
Validation loss: 2.2115275859832764

Epoch: 6| Step: 6
Training loss: 1.3392033576965332
Validation loss: 2.205324331919352

Epoch: 6| Step: 7
Training loss: 1.2821930646896362
Validation loss: 2.198249955972036

Epoch: 6| Step: 8
Training loss: 1.5769951343536377
Validation loss: 2.2410549918810525

Epoch: 6| Step: 9
Training loss: 1.9018198251724243
Validation loss: 2.229699969291687

Epoch: 6| Step: 10
Training loss: 1.3455522060394287
Validation loss: 2.254105885823568

Epoch: 6| Step: 11
Training loss: 1.455246090888977
Validation loss: 2.2152157028516135

Epoch: 6| Step: 12
Training loss: 1.270857572555542
Validation loss: 2.2159694830576577

Epoch: 6| Step: 13
Training loss: 0.9578851461410522
Validation loss: 2.239209612210592

Epoch: 339| Step: 0
Training loss: 1.0194263458251953
Validation loss: 2.2213317354520163

Epoch: 6| Step: 1
Training loss: 1.2322733402252197
Validation loss: 2.2464375098546348

Epoch: 6| Step: 2
Training loss: 1.3279383182525635
Validation loss: 2.2487159172693887

Epoch: 6| Step: 3
Training loss: 1.15894615650177
Validation loss: 2.23034397761027

Epoch: 6| Step: 4
Training loss: 1.1807531118392944
Validation loss: 2.2310545245806375

Epoch: 6| Step: 5
Training loss: 0.8572514653205872
Validation loss: 2.24355141321818

Epoch: 6| Step: 6
Training loss: 1.6720011234283447
Validation loss: 2.2357221047083535

Epoch: 6| Step: 7
Training loss: 1.2951757907867432
Validation loss: 2.224062959353129

Epoch: 6| Step: 8
Training loss: 1.2897980213165283
Validation loss: 2.2088742852211

Epoch: 6| Step: 9
Training loss: 1.4346578121185303
Validation loss: 2.2020358045895896

Epoch: 6| Step: 10
Training loss: 0.9046472907066345
Validation loss: 2.205272078514099

Epoch: 6| Step: 11
Training loss: 1.4649385213851929
Validation loss: 2.202986399332682

Epoch: 6| Step: 12
Training loss: 1.2092233896255493
Validation loss: 2.210776229699453

Epoch: 6| Step: 13
Training loss: 1.4496253728866577
Validation loss: 2.209323445955912

Epoch: 340| Step: 0
Training loss: 0.9604308605194092
Validation loss: 2.2184112270673118

Epoch: 6| Step: 1
Training loss: 1.5007076263427734
Validation loss: 2.2370181878407798

Epoch: 6| Step: 2
Training loss: 1.4492894411087036
Validation loss: 2.2277748584747314

Epoch: 6| Step: 3
Training loss: 0.8575198650360107
Validation loss: 2.2065714796384177

Epoch: 6| Step: 4
Training loss: 1.8399947881698608
Validation loss: 2.1972609559694924

Epoch: 6| Step: 5
Training loss: 1.8614823818206787
Validation loss: 2.20693431297938

Epoch: 6| Step: 6
Training loss: 1.6899718046188354
Validation loss: 2.2025379141171775

Epoch: 6| Step: 7
Training loss: 1.2520774602890015
Validation loss: 2.212622046470642

Epoch: 6| Step: 8
Training loss: 1.3846311569213867
Validation loss: 2.2087191541989646

Epoch: 6| Step: 9
Training loss: 0.7798984050750732
Validation loss: 2.1748019655545554

Epoch: 6| Step: 10
Training loss: 1.293605089187622
Validation loss: 2.212518592675527

Epoch: 6| Step: 11
Training loss: 0.5666749477386475
Validation loss: 2.222643951574961

Epoch: 6| Step: 12
Training loss: 1.1716166734695435
Validation loss: 2.1701736450195312

Epoch: 6| Step: 13
Training loss: 1.4678597450256348
Validation loss: 2.192271053791046

Epoch: 341| Step: 0
Training loss: 1.5179481506347656
Validation loss: 2.155429939428965

Epoch: 6| Step: 1
Training loss: 1.376413345336914
Validation loss: 2.172432760397593

Epoch: 6| Step: 2
Training loss: 1.2200756072998047
Validation loss: 2.168999433517456

Epoch: 6| Step: 3
Training loss: 1.7972148656845093
Validation loss: 2.1645363370577493

Epoch: 6| Step: 4
Training loss: 0.48707637190818787
Validation loss: 2.174855589866638

Epoch: 6| Step: 5
Training loss: 1.9179612398147583
Validation loss: 2.1849595506985984

Epoch: 6| Step: 6
Training loss: 1.1923997402191162
Validation loss: 2.159270922342936

Epoch: 6| Step: 7
Training loss: 1.1422638893127441
Validation loss: 2.169258713722229

Epoch: 6| Step: 8
Training loss: 0.8988668322563171
Validation loss: 2.1885574658711753

Epoch: 6| Step: 9
Training loss: 0.8773871660232544
Validation loss: 2.2122389475504556

Epoch: 6| Step: 10
Training loss: 0.8526262640953064
Validation loss: 2.185012678305308

Epoch: 6| Step: 11
Training loss: 1.193779468536377
Validation loss: 2.191208759943644

Epoch: 6| Step: 12
Training loss: 1.8442401885986328
Validation loss: 2.173844496409098

Epoch: 6| Step: 13
Training loss: 1.465896725654602
Validation loss: 2.232616424560547

Epoch: 342| Step: 0
Training loss: 1.1619133949279785
Validation loss: 2.20207271973292

Epoch: 6| Step: 1
Training loss: 1.6677255630493164
Validation loss: 2.2100488344828286

Epoch: 6| Step: 2
Training loss: 1.6060495376586914
Validation loss: 2.2309488654136658

Epoch: 6| Step: 3
Training loss: 1.066436767578125
Validation loss: 2.2033411661783853

Epoch: 6| Step: 4
Training loss: 1.0452356338500977
Validation loss: 2.2307945489883423

Epoch: 6| Step: 5
Training loss: 0.5554017424583435
Validation loss: 2.2308662136395774

Epoch: 6| Step: 6
Training loss: 1.9155250787734985
Validation loss: 2.2421764930089316

Epoch: 6| Step: 7
Training loss: 0.8591542840003967
Validation loss: 2.2472838163375854

Epoch: 6| Step: 8
Training loss: 0.7896262407302856
Validation loss: 2.2503943840662637

Epoch: 6| Step: 9
Training loss: 1.0580785274505615
Validation loss: 2.2473565340042114

Epoch: 6| Step: 10
Training loss: 1.2956300973892212
Validation loss: 2.247948626677195

Epoch: 6| Step: 11
Training loss: 1.2996609210968018
Validation loss: 2.246862272421519

Epoch: 6| Step: 12
Training loss: 1.9114142656326294
Validation loss: 2.236348867416382

Epoch: 6| Step: 13
Training loss: 0.8843662738800049
Validation loss: 2.234484016895294

Epoch: 343| Step: 0
Training loss: 0.6453652381896973
Validation loss: 2.226248542467753

Epoch: 6| Step: 1
Training loss: 1.1576415300369263
Validation loss: 2.2148048877716064

Epoch: 6| Step: 2
Training loss: 1.1534764766693115
Validation loss: 2.2393769224484763

Epoch: 6| Step: 3
Training loss: 1.6150606870651245
Validation loss: 2.221653401851654

Epoch: 6| Step: 4
Training loss: 0.9394765496253967
Validation loss: 2.208235422770182

Epoch: 6| Step: 5
Training loss: 1.1110490560531616
Validation loss: 2.213785409927368

Epoch: 6| Step: 6
Training loss: 0.7538976669311523
Validation loss: 2.212011218070984

Epoch: 6| Step: 7
Training loss: 1.5224781036376953
Validation loss: 2.1833598812421164

Epoch: 6| Step: 8
Training loss: 0.8557157516479492
Validation loss: 2.1840616861979165

Epoch: 6| Step: 9
Training loss: 1.933680772781372
Validation loss: 2.1994847655296326

Epoch: 6| Step: 10
Training loss: 1.071974277496338
Validation loss: 2.193758567174276

Epoch: 6| Step: 11
Training loss: 0.8549313545227051
Validation loss: 2.201027592023214

Epoch: 6| Step: 12
Training loss: 1.4694523811340332
Validation loss: 2.1961519916852317

Epoch: 6| Step: 13
Training loss: 2.1211743354797363
Validation loss: 2.1866233348846436

Epoch: 344| Step: 0
Training loss: 1.0330708026885986
Validation loss: 2.197530746459961

Epoch: 6| Step: 1
Training loss: 1.1592686176300049
Validation loss: 2.205441474914551

Epoch: 6| Step: 2
Training loss: 1.4350491762161255
Validation loss: 2.204661170641581

Epoch: 6| Step: 3
Training loss: 0.5731173753738403
Validation loss: 2.1735779444376626

Epoch: 6| Step: 4
Training loss: 0.9130966663360596
Validation loss: 2.175229549407959

Epoch: 6| Step: 5
Training loss: 1.6247872114181519
Validation loss: 2.1787442763646445

Epoch: 6| Step: 6
Training loss: 1.83137845993042
Validation loss: 2.1934528152147927

Epoch: 6| Step: 7
Training loss: 1.104634165763855
Validation loss: 2.1826291680336

Epoch: 6| Step: 8
Training loss: 1.6619571447372437
Validation loss: 2.1515117287635803

Epoch: 6| Step: 9
Training loss: 0.8813003301620483
Validation loss: 2.2043962876001992

Epoch: 6| Step: 10
Training loss: 1.3145761489868164
Validation loss: 2.1519747177759805

Epoch: 6| Step: 11
Training loss: 1.2351151704788208
Validation loss: 2.156680444876353

Epoch: 6| Step: 12
Training loss: 1.2023942470550537
Validation loss: 2.16485333442688

Epoch: 6| Step: 13
Training loss: 1.7214744091033936
Validation loss: 2.1739434401194253

Epoch: 345| Step: 0
Training loss: 1.5879907608032227
Validation loss: 2.1750689347585044

Epoch: 6| Step: 1
Training loss: 1.289404034614563
Validation loss: 2.1663610537846885

Epoch: 6| Step: 2
Training loss: 0.4746173322200775
Validation loss: 2.1923343737920127

Epoch: 6| Step: 3
Training loss: 1.8663864135742188
Validation loss: 2.208260436852773

Epoch: 6| Step: 4
Training loss: 1.5777802467346191
Validation loss: 2.2259408632914224

Epoch: 6| Step: 5
Training loss: 1.3162381649017334
Validation loss: 2.211609959602356

Epoch: 6| Step: 6
Training loss: 0.9746921062469482
Validation loss: 2.2150747378667197

Epoch: 6| Step: 7
Training loss: 0.8496090173721313
Validation loss: 2.2205578883488974

Epoch: 6| Step: 8
Training loss: 1.5964264869689941
Validation loss: 2.1910786628723145

Epoch: 6| Step: 9
Training loss: 1.8296786546707153
Validation loss: 2.1882375876108804

Epoch: 6| Step: 10
Training loss: 1.4400383234024048
Validation loss: 2.2028955022493997

Epoch: 6| Step: 11
Training loss: 1.1576204299926758
Validation loss: 2.2098005215326944

Epoch: 6| Step: 12
Training loss: 0.9295463562011719
Validation loss: 2.237019936243693

Epoch: 6| Step: 13
Training loss: 0.6802722215652466
Validation loss: 2.2219996651013694

Epoch: 346| Step: 0
Training loss: 0.624890148639679
Validation loss: 2.2193188468615213

Epoch: 6| Step: 1
Training loss: 1.1871833801269531
Validation loss: 2.2130925059318542

Epoch: 6| Step: 2
Training loss: 1.178215742111206
Validation loss: 2.2215974728266397

Epoch: 6| Step: 3
Training loss: 1.0391581058502197
Validation loss: 2.2112784186999

Epoch: 6| Step: 4
Training loss: 0.84535813331604
Validation loss: 2.244373639424642

Epoch: 6| Step: 5
Training loss: 1.3905978202819824
Validation loss: 2.2309774359067283

Epoch: 6| Step: 6
Training loss: 1.1935744285583496
Validation loss: 2.2048906683921814

Epoch: 6| Step: 7
Training loss: 1.135252594947815
Validation loss: 2.2132773796717324

Epoch: 6| Step: 8
Training loss: 1.8725478649139404
Validation loss: 2.2158328692118325

Epoch: 6| Step: 9
Training loss: 1.331493616104126
Validation loss: 2.2559767961502075

Epoch: 6| Step: 10
Training loss: 1.63552725315094
Validation loss: 2.2111964424451194

Epoch: 6| Step: 11
Training loss: 1.0343493223190308
Validation loss: 2.2363316814104715

Epoch: 6| Step: 12
Training loss: 0.8677109479904175
Validation loss: 2.239884297053019

Epoch: 6| Step: 13
Training loss: 1.9184513092041016
Validation loss: 2.2077935536702475

Epoch: 347| Step: 0
Training loss: 1.0490970611572266
Validation loss: 2.229922652244568

Epoch: 6| Step: 1
Training loss: 1.1922688484191895
Validation loss: 2.240135073661804

Epoch: 6| Step: 2
Training loss: 0.9154173135757446
Validation loss: 2.211476425329844

Epoch: 6| Step: 3
Training loss: 1.1000947952270508
Validation loss: 2.2211370865503945

Epoch: 6| Step: 4
Training loss: 1.1312048435211182
Validation loss: 2.236205597718557

Epoch: 6| Step: 5
Training loss: 0.7940595746040344
Validation loss: 2.2142918904622397

Epoch: 6| Step: 6
Training loss: 1.4626226425170898
Validation loss: 2.2115429639816284

Epoch: 6| Step: 7
Training loss: 1.3247274160385132
Validation loss: 2.2326426108678183

Epoch: 6| Step: 8
Training loss: 0.930217444896698
Validation loss: 2.206553856531779

Epoch: 6| Step: 9
Training loss: 1.7971326112747192
Validation loss: 2.194936513900757

Epoch: 6| Step: 10
Training loss: 0.6537023782730103
Validation loss: 2.197436531384786

Epoch: 6| Step: 11
Training loss: 1.8089033365249634
Validation loss: 2.1904718478520713

Epoch: 6| Step: 12
Training loss: 2.023177146911621
Validation loss: 2.173041820526123

Epoch: 6| Step: 13
Training loss: 1.3452537059783936
Validation loss: 2.1970699230829873

Epoch: 348| Step: 0
Training loss: 1.1522170305252075
Validation loss: 2.1828946669896445

Epoch: 6| Step: 1
Training loss: 1.7431398630142212
Validation loss: 2.1856966416041055

Epoch: 6| Step: 2
Training loss: 1.4985640048980713
Validation loss: 2.179812173048655

Epoch: 6| Step: 3
Training loss: 0.9249368906021118
Validation loss: 2.1918156147003174

Epoch: 6| Step: 4
Training loss: 1.88926100730896
Validation loss: 2.1832125186920166

Epoch: 6| Step: 5
Training loss: 1.4909582138061523
Validation loss: 2.173857013384501

Epoch: 6| Step: 6
Training loss: 1.205592155456543
Validation loss: 2.1772774855295816

Epoch: 6| Step: 7
Training loss: 1.1340460777282715
Validation loss: 2.1965572237968445

Epoch: 6| Step: 8
Training loss: 0.8368130922317505
Validation loss: 2.19865216811498

Epoch: 6| Step: 9
Training loss: 1.6567332744598389
Validation loss: 2.2069145043691

Epoch: 6| Step: 10
Training loss: 1.114121437072754
Validation loss: 2.231686234474182

Epoch: 6| Step: 11
Training loss: 0.8268967270851135
Validation loss: 2.2012769182523093

Epoch: 6| Step: 12
Training loss: 1.4811532497406006
Validation loss: 2.2069795529047647

Epoch: 6| Step: 13
Training loss: 1.0006592273712158
Validation loss: 2.1759703755378723

Epoch: 349| Step: 0
Training loss: 1.249460220336914
Validation loss: 2.191945572694143

Epoch: 6| Step: 1
Training loss: 0.8602721095085144
Validation loss: 2.1708454291025796

Epoch: 6| Step: 2
Training loss: 1.0127933025360107
Validation loss: 2.194469968477885

Epoch: 6| Step: 3
Training loss: 1.4526867866516113
Validation loss: 2.179262379805247

Epoch: 6| Step: 4
Training loss: 1.2157962322235107
Validation loss: 2.1870277722676597

Epoch: 6| Step: 5
Training loss: 0.7609471082687378
Validation loss: 2.1823573112487793

Epoch: 6| Step: 6
Training loss: 1.2286295890808105
Validation loss: 2.155794143676758

Epoch: 6| Step: 7
Training loss: 2.0637316703796387
Validation loss: 2.1561391750971475

Epoch: 6| Step: 8
Training loss: 1.2448248863220215
Validation loss: 2.193153977394104

Epoch: 6| Step: 9
Training loss: 1.5402369499206543
Validation loss: 2.185615042845408

Epoch: 6| Step: 10
Training loss: 1.6435644626617432
Validation loss: 2.203959802786509

Epoch: 6| Step: 11
Training loss: 1.151160717010498
Validation loss: 2.2050352096557617

Epoch: 6| Step: 12
Training loss: 1.2237926721572876
Validation loss: 2.1685683131217957

Epoch: 6| Step: 13
Training loss: 0.7853775024414062
Validation loss: 2.1705090204874673

Epoch: 350| Step: 0
Training loss: 1.4978797435760498
Validation loss: 2.178488790988922

Epoch: 6| Step: 1
Training loss: 1.2860934734344482
Validation loss: 2.175843358039856

Epoch: 6| Step: 2
Training loss: 0.46998775005340576
Validation loss: 2.2041548788547516

Epoch: 6| Step: 3
Training loss: 0.9724904298782349
Validation loss: 2.1626601219177246

Epoch: 6| Step: 4
Training loss: 1.8572286367416382
Validation loss: 2.19172465801239

Epoch: 6| Step: 5
Training loss: 0.8725992441177368
Validation loss: 2.1982748905817666

Epoch: 6| Step: 6
Training loss: 0.812288761138916
Validation loss: 2.185451646645864

Epoch: 6| Step: 7
Training loss: 1.0147738456726074
Validation loss: 2.201171040534973

Epoch: 6| Step: 8
Training loss: 1.1154050827026367
Validation loss: 2.180167297522227

Epoch: 6| Step: 9
Training loss: 1.4894886016845703
Validation loss: 2.2153087655703225

Epoch: 6| Step: 10
Training loss: 0.9922339916229248
Validation loss: 2.207924723625183

Epoch: 6| Step: 11
Training loss: 0.9075940847396851
Validation loss: 2.175320347150167

Epoch: 6| Step: 12
Training loss: 1.7491724491119385
Validation loss: 2.170917570590973

Epoch: 6| Step: 13
Training loss: 1.6430552005767822
Validation loss: 2.1875125765800476

Epoch: 351| Step: 0
Training loss: 1.3087377548217773
Validation loss: 2.190737505753835

Epoch: 6| Step: 1
Training loss: 0.6637284755706787
Validation loss: 2.182563622792562

Epoch: 6| Step: 2
Training loss: 1.2805025577545166
Validation loss: 2.1691516637802124

Epoch: 6| Step: 3
Training loss: 1.2238720655441284
Validation loss: 2.1850740909576416

Epoch: 6| Step: 4
Training loss: 1.1521096229553223
Validation loss: 2.182732025782267

Epoch: 6| Step: 5
Training loss: 0.9056852459907532
Validation loss: 2.180722415447235

Epoch: 6| Step: 6
Training loss: 1.271350622177124
Validation loss: 2.1961472034454346

Epoch: 6| Step: 7
Training loss: 1.3692474365234375
Validation loss: 2.198256492614746

Epoch: 6| Step: 8
Training loss: 0.9675758481025696
Validation loss: 2.1767685413360596

Epoch: 6| Step: 9
Training loss: 0.9427858591079712
Validation loss: 2.1699764331181846

Epoch: 6| Step: 10
Training loss: 1.1472300291061401
Validation loss: 2.1862565080324807

Epoch: 6| Step: 11
Training loss: 1.064927101135254
Validation loss: 2.187555174032847

Epoch: 6| Step: 12
Training loss: 1.8121670484542847
Validation loss: 2.1705960830052695

Epoch: 6| Step: 13
Training loss: 1.6429431438446045
Validation loss: 2.181364119052887

Epoch: 352| Step: 0
Training loss: 1.7213654518127441
Validation loss: 2.1630828777949014

Epoch: 6| Step: 1
Training loss: 1.491947889328003
Validation loss: 2.190477470556895

Epoch: 6| Step: 2
Training loss: 1.0690619945526123
Validation loss: 2.205344557762146

Epoch: 6| Step: 3
Training loss: 1.753018856048584
Validation loss: 2.1968865394592285

Epoch: 6| Step: 4
Training loss: 1.0467736721038818
Validation loss: 2.187513291835785

Epoch: 6| Step: 5
Training loss: 1.5618507862091064
Validation loss: 2.171514709790548

Epoch: 6| Step: 6
Training loss: 0.47176092863082886
Validation loss: 2.1811197996139526

Epoch: 6| Step: 7
Training loss: 0.7332575917243958
Validation loss: 2.1918182373046875

Epoch: 6| Step: 8
Training loss: 1.7280588150024414
Validation loss: 2.1932628750801086

Epoch: 6| Step: 9
Training loss: 1.3113460540771484
Validation loss: 2.1708767811457315

Epoch: 6| Step: 10
Training loss: 1.2815660238265991
Validation loss: 2.178645451863607

Epoch: 6| Step: 11
Training loss: 1.8211684226989746
Validation loss: 2.1677801807721457

Epoch: 6| Step: 12
Training loss: 0.9065876007080078
Validation loss: 2.1735483010609946

Epoch: 6| Step: 13
Training loss: 0.5348142385482788
Validation loss: 2.156750718752543

Epoch: 353| Step: 0
Training loss: 1.1074669361114502
Validation loss: 2.1664422154426575

Epoch: 6| Step: 1
Training loss: 0.7370161414146423
Validation loss: 2.2003283500671387

Epoch: 6| Step: 2
Training loss: 1.632049322128296
Validation loss: 2.1728221774101257

Epoch: 6| Step: 3
Training loss: 1.4213415384292603
Validation loss: 2.165848354498545

Epoch: 6| Step: 4
Training loss: 1.1659601926803589
Validation loss: 2.176719069480896

Epoch: 6| Step: 5
Training loss: 1.0577616691589355
Validation loss: 2.1723429560661316

Epoch: 6| Step: 6
Training loss: 0.7764445543289185
Validation loss: 2.1736417611440024

Epoch: 6| Step: 7
Training loss: 1.152937650680542
Validation loss: 2.1565236250559487

Epoch: 6| Step: 8
Training loss: 1.4793072938919067
Validation loss: 2.154265364011129

Epoch: 6| Step: 9
Training loss: 1.065704107284546
Validation loss: 2.1487576564153037

Epoch: 6| Step: 10
Training loss: 1.1681466102600098
Validation loss: 2.1740731596946716

Epoch: 6| Step: 11
Training loss: 1.612959384918213
Validation loss: 2.1352317333221436

Epoch: 6| Step: 12
Training loss: 1.2231237888336182
Validation loss: 2.161441524823507

Epoch: 6| Step: 13
Training loss: 1.4583091735839844
Validation loss: 2.146046737829844

Epoch: 354| Step: 0
Training loss: 1.4631438255310059
Validation loss: 2.168004890282949

Epoch: 6| Step: 1
Training loss: 1.1718885898590088
Validation loss: 2.172857185204824

Epoch: 6| Step: 2
Training loss: 1.6181516647338867
Validation loss: 2.1563116709391275

Epoch: 6| Step: 3
Training loss: 1.104528784751892
Validation loss: 2.167113264401754

Epoch: 6| Step: 4
Training loss: 0.6222362518310547
Validation loss: 2.1393433610598245

Epoch: 6| Step: 5
Training loss: 1.013141393661499
Validation loss: 2.16976660490036

Epoch: 6| Step: 6
Training loss: 0.8963907957077026
Validation loss: 2.1749725937843323

Epoch: 6| Step: 7
Training loss: 1.515687346458435
Validation loss: 2.1649202903111777

Epoch: 6| Step: 8
Training loss: 0.80885910987854
Validation loss: 2.179473042488098

Epoch: 6| Step: 9
Training loss: 1.0795087814331055
Validation loss: 2.220326066017151

Epoch: 6| Step: 10
Training loss: 1.6679599285125732
Validation loss: 2.176033596197764

Epoch: 6| Step: 11
Training loss: 1.1208126544952393
Validation loss: 2.1834136843681335

Epoch: 6| Step: 12
Training loss: 1.5656646490097046
Validation loss: 2.2087186177571616

Epoch: 6| Step: 13
Training loss: 0.852293848991394
Validation loss: 2.160242021083832

Epoch: 355| Step: 0
Training loss: 1.8458304405212402
Validation loss: 2.185285210609436

Epoch: 6| Step: 1
Training loss: 1.196580171585083
Validation loss: 2.220496038595835

Epoch: 6| Step: 2
Training loss: 1.5558154582977295
Validation loss: 2.1603209376335144

Epoch: 6| Step: 3
Training loss: 1.484010934829712
Validation loss: 2.1751760045687356

Epoch: 6| Step: 4
Training loss: 0.5075995922088623
Validation loss: 2.1402184764544168

Epoch: 6| Step: 5
Training loss: 0.5197051167488098
Validation loss: 2.1587696075439453

Epoch: 6| Step: 6
Training loss: 1.0976539850234985
Validation loss: 2.1796894868214927

Epoch: 6| Step: 7
Training loss: 1.5153143405914307
Validation loss: 2.180956244468689

Epoch: 6| Step: 8
Training loss: 1.3705551624298096
Validation loss: 2.1700299978256226

Epoch: 6| Step: 9
Training loss: 1.1894875764846802
Validation loss: 2.1602317889531455

Epoch: 6| Step: 10
Training loss: 0.807553768157959
Validation loss: 2.1710583368937173

Epoch: 6| Step: 11
Training loss: 1.046072244644165
Validation loss: 2.1875566244125366

Epoch: 6| Step: 12
Training loss: 1.2569184303283691
Validation loss: 2.2007001638412476

Epoch: 6| Step: 13
Training loss: 0.9860012531280518
Validation loss: 2.1560835043589273

Epoch: 356| Step: 0
Training loss: 0.6160104274749756
Validation loss: 2.182126541932424

Epoch: 6| Step: 1
Training loss: 0.7232725620269775
Validation loss: 2.1789108514785767

Epoch: 6| Step: 2
Training loss: 0.7525178790092468
Validation loss: 2.1676950653394065

Epoch: 6| Step: 3
Training loss: 2.1027348041534424
Validation loss: 2.180570582548777

Epoch: 6| Step: 4
Training loss: 1.7278627157211304
Validation loss: 2.175470471382141

Epoch: 6| Step: 5
Training loss: 1.2715787887573242
Validation loss: 2.1882459123929343

Epoch: 6| Step: 6
Training loss: 1.13834810256958
Validation loss: 2.1710186998049417

Epoch: 6| Step: 7
Training loss: 1.6547279357910156
Validation loss: 2.1773182153701782

Epoch: 6| Step: 8
Training loss: 0.9404470920562744
Validation loss: 2.164115250110626

Epoch: 6| Step: 9
Training loss: 1.0299934148788452
Validation loss: 2.151303788026174

Epoch: 6| Step: 10
Training loss: 1.1948195695877075
Validation loss: 2.1888598601023355

Epoch: 6| Step: 11
Training loss: 0.94704669713974
Validation loss: 2.234864830970764

Epoch: 6| Step: 12
Training loss: 1.2893564701080322
Validation loss: 2.204065720240275

Epoch: 6| Step: 13
Training loss: 1.1966743469238281
Validation loss: 2.259020447731018

Epoch: 357| Step: 0
Training loss: 1.0708287954330444
Validation loss: 2.284431298573812

Epoch: 6| Step: 1
Training loss: 2.01541805267334
Validation loss: 2.188207685947418

Epoch: 6| Step: 2
Training loss: 0.9481483697891235
Validation loss: 2.1954076886177063

Epoch: 6| Step: 3
Training loss: 0.8406497240066528
Validation loss: 2.1660144130388894

Epoch: 6| Step: 4
Training loss: 1.586669683456421
Validation loss: 2.1654372215270996

Epoch: 6| Step: 5
Training loss: 1.1081501245498657
Validation loss: 2.1865429083506265

Epoch: 6| Step: 6
Training loss: 1.738156795501709
Validation loss: 2.1657338241736093

Epoch: 6| Step: 7
Training loss: 1.4306930303573608
Validation loss: 2.1745181679725647

Epoch: 6| Step: 8
Training loss: 1.0306795835494995
Validation loss: 2.1542694568634033

Epoch: 6| Step: 9
Training loss: 0.9768062829971313
Validation loss: 2.1675427158673606

Epoch: 6| Step: 10
Training loss: 1.1850275993347168
Validation loss: 2.1632696390151978

Epoch: 6| Step: 11
Training loss: 1.4392361640930176
Validation loss: 2.176655868689219

Epoch: 6| Step: 12
Training loss: 0.7159872055053711
Validation loss: 2.178045411904653

Epoch: 6| Step: 13
Training loss: 1.1835774183273315
Validation loss: 2.1856895287831626

Epoch: 358| Step: 0
Training loss: 0.9269691705703735
Validation loss: 2.204510052998861

Epoch: 6| Step: 1
Training loss: 1.203934907913208
Validation loss: 2.188708245754242

Epoch: 6| Step: 2
Training loss: 0.9675052165985107
Validation loss: 2.204132914543152

Epoch: 6| Step: 3
Training loss: 1.3369125127792358
Validation loss: 2.1698413292566934

Epoch: 6| Step: 4
Training loss: 1.0454928874969482
Validation loss: 2.152855555216471

Epoch: 6| Step: 5
Training loss: 0.9812426567077637
Validation loss: 2.138973673184713

Epoch: 6| Step: 6
Training loss: 1.1737241744995117
Validation loss: 2.169654647509257

Epoch: 6| Step: 7
Training loss: 1.3835067749023438
Validation loss: 2.1633504827817283

Epoch: 6| Step: 8
Training loss: 1.7567157745361328
Validation loss: 2.1714756886164346

Epoch: 6| Step: 9
Training loss: 1.1158831119537354
Validation loss: 2.190550744533539

Epoch: 6| Step: 10
Training loss: 0.945818305015564
Validation loss: 2.1750643452008567

Epoch: 6| Step: 11
Training loss: 1.708949327468872
Validation loss: 2.192097544670105

Epoch: 6| Step: 12
Training loss: 1.1376690864562988
Validation loss: 2.1881138682365417

Epoch: 6| Step: 13
Training loss: 1.0790901184082031
Validation loss: 2.207359194755554

Epoch: 359| Step: 0
Training loss: 0.9052839279174805
Validation loss: 2.205738087495168

Epoch: 6| Step: 1
Training loss: 1.3829203844070435
Validation loss: 2.225195050239563

Epoch: 6| Step: 2
Training loss: 1.4246799945831299
Validation loss: 2.214813232421875

Epoch: 6| Step: 3
Training loss: 1.4813858270645142
Validation loss: 2.231053630510966

Epoch: 6| Step: 4
Training loss: 0.6275279521942139
Validation loss: 2.1977441112200418

Epoch: 6| Step: 5
Training loss: 1.0660396814346313
Validation loss: 2.2201502521832785

Epoch: 6| Step: 6
Training loss: 0.6438875198364258
Validation loss: 2.1676275730133057

Epoch: 6| Step: 7
Training loss: 1.2986363172531128
Validation loss: 2.193937619527181

Epoch: 6| Step: 8
Training loss: 0.6255857348442078
Validation loss: 2.1824675599733987

Epoch: 6| Step: 9
Training loss: 1.7684928178787231
Validation loss: 2.15523632367452

Epoch: 6| Step: 10
Training loss: 1.6166927814483643
Validation loss: 2.161090354124705

Epoch: 6| Step: 11
Training loss: 1.808807611465454
Validation loss: 2.164717117945353

Epoch: 6| Step: 12
Training loss: 0.8468019962310791
Validation loss: 2.173941691716512

Epoch: 6| Step: 13
Training loss: 0.8143756985664368
Validation loss: 2.1603182752927146

Epoch: 360| Step: 0
Training loss: 0.799941897392273
Validation loss: 2.14889395236969

Epoch: 6| Step: 1
Training loss: 0.6734800934791565
Validation loss: 2.1756266355514526

Epoch: 6| Step: 2
Training loss: 0.7151651382446289
Validation loss: 2.189169963200887

Epoch: 6| Step: 3
Training loss: 0.7757378220558167
Validation loss: 2.1563908457756042

Epoch: 6| Step: 4
Training loss: 0.5641640424728394
Validation loss: 2.1679598887761435

Epoch: 6| Step: 5
Training loss: 0.7671588659286499
Validation loss: 2.14716637134552

Epoch: 6| Step: 6
Training loss: 1.7656543254852295
Validation loss: 2.171021282672882

Epoch: 6| Step: 7
Training loss: 1.4619288444519043
Validation loss: 2.1803018053372702

Epoch: 6| Step: 8
Training loss: 1.2970201969146729
Validation loss: 2.1853840351104736

Epoch: 6| Step: 9
Training loss: 1.859317660331726
Validation loss: 2.1941504875818887

Epoch: 6| Step: 10
Training loss: 1.4883521795272827
Validation loss: 2.196376303831736

Epoch: 6| Step: 11
Training loss: 1.3257334232330322
Validation loss: 2.1613157788912454

Epoch: 6| Step: 12
Training loss: 1.18450927734375
Validation loss: 2.2058845162391663

Epoch: 6| Step: 13
Training loss: 1.3137998580932617
Validation loss: 2.1677157481511435

Epoch: 361| Step: 0
Training loss: 1.3423629999160767
Validation loss: 2.1918803056081138

Epoch: 6| Step: 1
Training loss: 1.4726582765579224
Validation loss: 2.2084293365478516

Epoch: 6| Step: 2
Training loss: 1.1004222631454468
Validation loss: 2.1723923683166504

Epoch: 6| Step: 3
Training loss: 1.2296290397644043
Validation loss: 2.1847244103749595

Epoch: 6| Step: 4
Training loss: 0.9098968505859375
Validation loss: 2.1667429208755493

Epoch: 6| Step: 5
Training loss: 0.6620129942893982
Validation loss: 2.1692269245783486

Epoch: 6| Step: 6
Training loss: 1.420615792274475
Validation loss: 2.1841742595036826

Epoch: 6| Step: 7
Training loss: 1.4924628734588623
Validation loss: 2.165557384490967

Epoch: 6| Step: 8
Training loss: 0.9945495128631592
Validation loss: 2.1622194647789

Epoch: 6| Step: 9
Training loss: 0.5103545784950256
Validation loss: 2.17278919617335

Epoch: 6| Step: 10
Training loss: 1.0881341695785522
Validation loss: 2.175458391507467

Epoch: 6| Step: 11
Training loss: 1.2100882530212402
Validation loss: 2.158699889977773

Epoch: 6| Step: 12
Training loss: 1.5451350212097168
Validation loss: 2.147200286388397

Epoch: 6| Step: 13
Training loss: 1.0087627172470093
Validation loss: 2.174186567465464

Epoch: 362| Step: 0
Training loss: 1.7977125644683838
Validation loss: 2.1806615392367044

Epoch: 6| Step: 1
Training loss: 1.0731985569000244
Validation loss: 2.1690664887428284

Epoch: 6| Step: 2
Training loss: 1.4182049036026
Validation loss: 2.196680426597595

Epoch: 6| Step: 3
Training loss: 0.9381576776504517
Validation loss: 2.1892438332239785

Epoch: 6| Step: 4
Training loss: 0.9709221124649048
Validation loss: 2.1669330994288125

Epoch: 6| Step: 5
Training loss: 1.314151406288147
Validation loss: 2.202742616335551

Epoch: 6| Step: 6
Training loss: 1.5478788614273071
Validation loss: 2.2063090006510415

Epoch: 6| Step: 7
Training loss: 1.194606900215149
Validation loss: 2.217975835005442

Epoch: 6| Step: 8
Training loss: 0.9374378323554993
Validation loss: 2.1827654043833413

Epoch: 6| Step: 9
Training loss: 1.0685765743255615
Validation loss: 2.180364429950714

Epoch: 6| Step: 10
Training loss: 1.1346056461334229
Validation loss: 2.1754172444343567

Epoch: 6| Step: 11
Training loss: 0.43162763118743896
Validation loss: 2.1891550620396933

Epoch: 6| Step: 12
Training loss: 0.7004832029342651
Validation loss: 2.193119009335836

Epoch: 6| Step: 13
Training loss: 1.3470232486724854
Validation loss: 2.170010507106781

Epoch: 363| Step: 0
Training loss: 0.6781742572784424
Validation loss: 2.1807390451431274

Epoch: 6| Step: 1
Training loss: 1.0346128940582275
Validation loss: 2.1581398844718933

Epoch: 6| Step: 2
Training loss: 1.7028617858886719
Validation loss: 2.1484479308128357

Epoch: 6| Step: 3
Training loss: 1.5639530420303345
Validation loss: 2.140342195828756

Epoch: 6| Step: 4
Training loss: 1.3451473712921143
Validation loss: 2.159572720527649

Epoch: 6| Step: 5
Training loss: 0.694366991519928
Validation loss: 2.1656686663627625

Epoch: 6| Step: 6
Training loss: 0.5862464904785156
Validation loss: 2.1701800425847373

Epoch: 6| Step: 7
Training loss: 1.1183905601501465
Validation loss: 2.151071389516195

Epoch: 6| Step: 8
Training loss: 1.0358407497406006
Validation loss: 2.174428403377533

Epoch: 6| Step: 9
Training loss: 1.515243649482727
Validation loss: 2.1803943713506064

Epoch: 6| Step: 10
Training loss: 1.9500226974487305
Validation loss: 2.1759082674980164

Epoch: 6| Step: 11
Training loss: 1.348760724067688
Validation loss: 2.203656037648519

Epoch: 6| Step: 12
Training loss: 0.7625548839569092
Validation loss: 2.250874082247416

Epoch: 6| Step: 13
Training loss: 1.3615398406982422
Validation loss: 2.2436243891716003

Epoch: 364| Step: 0
Training loss: 0.9779748916625977
Validation loss: 2.234528919061025

Epoch: 6| Step: 1
Training loss: 0.8173297047615051
Validation loss: 2.1797293424606323

Epoch: 6| Step: 2
Training loss: 1.2143659591674805
Validation loss: 2.1745397051175437

Epoch: 6| Step: 3
Training loss: 1.0506230592727661
Validation loss: 2.177228311697642

Epoch: 6| Step: 4
Training loss: 1.9621059894561768
Validation loss: 2.191472053527832

Epoch: 6| Step: 5
Training loss: 1.268921971321106
Validation loss: 2.1991007129351297

Epoch: 6| Step: 6
Training loss: 0.4414580166339874
Validation loss: 2.207492450873057

Epoch: 6| Step: 7
Training loss: 1.955263376235962
Validation loss: 2.1996139685312905

Epoch: 6| Step: 8
Training loss: 0.775108814239502
Validation loss: 2.167683164278666

Epoch: 6| Step: 9
Training loss: 1.3051800727844238
Validation loss: 2.1671985189119973

Epoch: 6| Step: 10
Training loss: 0.7360062599182129
Validation loss: 2.1944459478060403

Epoch: 6| Step: 11
Training loss: 1.4955946207046509
Validation loss: 2.202165424823761

Epoch: 6| Step: 12
Training loss: 0.9635029435157776
Validation loss: 2.1850465138753257

Epoch: 6| Step: 13
Training loss: 0.7447720766067505
Validation loss: 2.126522660255432

Epoch: 365| Step: 0
Training loss: 0.9114874005317688
Validation loss: 2.1787317196528115

Epoch: 6| Step: 1
Training loss: 1.1904489994049072
Validation loss: 2.1775445143381753

Epoch: 6| Step: 2
Training loss: 0.4375154972076416
Validation loss: 2.1974613666534424

Epoch: 6| Step: 3
Training loss: 1.4110918045043945
Validation loss: 2.202128847440084

Epoch: 6| Step: 4
Training loss: 0.919772207736969
Validation loss: 2.1790512204170227

Epoch: 6| Step: 5
Training loss: 1.6437628269195557
Validation loss: 2.175679604212443

Epoch: 6| Step: 6
Training loss: 1.653160572052002
Validation loss: 2.14524511496226

Epoch: 6| Step: 7
Training loss: 0.8396419882774353
Validation loss: 2.164450923601786

Epoch: 6| Step: 8
Training loss: 1.9078011512756348
Validation loss: 2.153562009334564

Epoch: 6| Step: 9
Training loss: 0.7414771914482117
Validation loss: 2.1793758273124695

Epoch: 6| Step: 10
Training loss: 0.9702388048171997
Validation loss: 2.1686900854110718

Epoch: 6| Step: 11
Training loss: 1.2687811851501465
Validation loss: 2.1880367199579873

Epoch: 6| Step: 12
Training loss: 1.255588412284851
Validation loss: 2.1595011949539185

Epoch: 6| Step: 13
Training loss: 0.8897257447242737
Validation loss: 2.1605512698491416

Epoch: 366| Step: 0
Training loss: 1.5017805099487305
Validation loss: 2.148306945959727

Epoch: 6| Step: 1
Training loss: 0.9061510562896729
Validation loss: 2.1493327418963113

Epoch: 6| Step: 2
Training loss: 1.3147956132888794
Validation loss: 2.1522145668665567

Epoch: 6| Step: 3
Training loss: 1.1324881315231323
Validation loss: 2.112373491128286

Epoch: 6| Step: 4
Training loss: 1.2630499601364136
Validation loss: 2.1345059474309287

Epoch: 6| Step: 5
Training loss: 0.6154399514198303
Validation loss: 2.1171098152796426

Epoch: 6| Step: 6
Training loss: 0.5050969123840332
Validation loss: 2.154858410358429

Epoch: 6| Step: 7
Training loss: 1.1089050769805908
Validation loss: 2.1252673268318176

Epoch: 6| Step: 8
Training loss: 1.8786602020263672
Validation loss: 2.1463425358136496

Epoch: 6| Step: 9
Training loss: 0.8331577777862549
Validation loss: 2.1466946800549827

Epoch: 6| Step: 10
Training loss: 1.4135149717330933
Validation loss: 2.178637226422628

Epoch: 6| Step: 11
Training loss: 0.9589975476264954
Validation loss: 2.170328140258789

Epoch: 6| Step: 12
Training loss: 1.1716419458389282
Validation loss: 2.1717325250307717

Epoch: 6| Step: 13
Training loss: 0.8548747301101685
Validation loss: 2.1556819677352905

Epoch: 367| Step: 0
Training loss: 1.0192269086837769
Validation loss: 2.1618220607439675

Epoch: 6| Step: 1
Training loss: 1.3445460796356201
Validation loss: 2.1673598885536194

Epoch: 6| Step: 2
Training loss: 0.9646008014678955
Validation loss: 2.194593330224355

Epoch: 6| Step: 3
Training loss: 1.4351084232330322
Validation loss: 2.1795634826024375

Epoch: 6| Step: 4
Training loss: 1.095856785774231
Validation loss: 2.1573904355367026

Epoch: 6| Step: 5
Training loss: 0.7517143487930298
Validation loss: 2.1709840297698975

Epoch: 6| Step: 6
Training loss: 0.9629510045051575
Validation loss: 2.131891886393229

Epoch: 6| Step: 7
Training loss: 1.1305551528930664
Validation loss: 2.1787549257278442

Epoch: 6| Step: 8
Training loss: 1.0894314050674438
Validation loss: 2.169290284315745

Epoch: 6| Step: 9
Training loss: 0.7438676953315735
Validation loss: 2.159609615802765

Epoch: 6| Step: 10
Training loss: 1.2256516218185425
Validation loss: 2.158730765183767

Epoch: 6| Step: 11
Training loss: 1.2539784908294678
Validation loss: 2.15351140499115

Epoch: 6| Step: 12
Training loss: 1.6716867685317993
Validation loss: 2.1712222695350647

Epoch: 6| Step: 13
Training loss: 1.2282530069351196
Validation loss: 2.175241013367971

Epoch: 368| Step: 0
Training loss: 1.9088022708892822
Validation loss: 2.1782992283503213

Epoch: 6| Step: 1
Training loss: 0.721038818359375
Validation loss: 2.1793572107950845

Epoch: 6| Step: 2
Training loss: 0.999051034450531
Validation loss: 2.182455559571584

Epoch: 6| Step: 3
Training loss: 0.7118424773216248
Validation loss: 2.1723454197247825

Epoch: 6| Step: 4
Training loss: 1.3134921789169312
Validation loss: 2.1880110104878745

Epoch: 6| Step: 5
Training loss: 1.3797945976257324
Validation loss: 2.1466686725616455

Epoch: 6| Step: 6
Training loss: 1.0395885705947876
Validation loss: 2.1720911463101706

Epoch: 6| Step: 7
Training loss: 1.5241076946258545
Validation loss: 2.15541140238444

Epoch: 6| Step: 8
Training loss: 0.43447941541671753
Validation loss: 2.1691988110542297

Epoch: 6| Step: 9
Training loss: 0.8454680442810059
Validation loss: 2.1753334204355874

Epoch: 6| Step: 10
Training loss: 0.7603588104248047
Validation loss: 2.1435163418451944

Epoch: 6| Step: 11
Training loss: 0.6554595232009888
Validation loss: 2.1502336263656616

Epoch: 6| Step: 12
Training loss: 1.920585036277771
Validation loss: 2.169149418671926

Epoch: 6| Step: 13
Training loss: 1.1403582096099854
Validation loss: 2.195405642191569

Epoch: 369| Step: 0
Training loss: 1.1988859176635742
Validation loss: 2.233245054880778

Epoch: 6| Step: 1
Training loss: 1.3620259761810303
Validation loss: 2.2373348077138266

Epoch: 6| Step: 2
Training loss: 0.587070643901825
Validation loss: 2.2632277806599936

Epoch: 6| Step: 3
Training loss: 1.5209470987319946
Validation loss: 2.2497045596440635

Epoch: 6| Step: 4
Training loss: 1.458388328552246
Validation loss: 2.197553833325704

Epoch: 6| Step: 5
Training loss: 0.8426826596260071
Validation loss: 2.189310868581136

Epoch: 6| Step: 6
Training loss: 0.79243004322052
Validation loss: 2.1667712132136026

Epoch: 6| Step: 7
Training loss: 1.2049598693847656
Validation loss: 2.1755767663319907

Epoch: 6| Step: 8
Training loss: 1.4125933647155762
Validation loss: 2.163537641366323

Epoch: 6| Step: 9
Training loss: 0.5241695642471313
Validation loss: 2.1419413685798645

Epoch: 6| Step: 10
Training loss: 1.6468687057495117
Validation loss: 2.1692540844281516

Epoch: 6| Step: 11
Training loss: 1.509917974472046
Validation loss: 2.1821074883143106

Epoch: 6| Step: 12
Training loss: 1.023909330368042
Validation loss: 2.1721869905789695

Epoch: 6| Step: 13
Training loss: 1.3734420537948608
Validation loss: 2.1927026907602944

Epoch: 370| Step: 0
Training loss: 0.6295201182365417
Validation loss: 2.2011571129163108

Epoch: 6| Step: 1
Training loss: 0.7139809727668762
Validation loss: 2.1889842549959817

Epoch: 6| Step: 2
Training loss: 1.0552828311920166
Validation loss: 2.201208452383677

Epoch: 6| Step: 3
Training loss: 0.733137309551239
Validation loss: 2.1977283358573914

Epoch: 6| Step: 4
Training loss: 1.0926883220672607
Validation loss: 2.207172989845276

Epoch: 6| Step: 5
Training loss: 1.0783647298812866
Validation loss: 2.208982308705648

Epoch: 6| Step: 6
Training loss: 0.9123309254646301
Validation loss: 2.2223076224327087

Epoch: 6| Step: 7
Training loss: 1.7469063997268677
Validation loss: 2.1897865533828735

Epoch: 6| Step: 8
Training loss: 1.3752918243408203
Validation loss: 2.211036264896393

Epoch: 6| Step: 9
Training loss: 1.122436285018921
Validation loss: 2.1654528180758157

Epoch: 6| Step: 10
Training loss: 1.6695244312286377
Validation loss: 2.210812290509542

Epoch: 6| Step: 11
Training loss: 0.6880530714988708
Validation loss: 2.172696669896444

Epoch: 6| Step: 12
Training loss: 0.8429285287857056
Validation loss: 2.1710716485977173

Epoch: 6| Step: 13
Training loss: 1.2164227962493896
Validation loss: 2.157038450241089

Epoch: 371| Step: 0
Training loss: 1.0873887538909912
Validation loss: 2.1450888911883035

Epoch: 6| Step: 1
Training loss: 1.4505858421325684
Validation loss: 2.157819072405497

Epoch: 6| Step: 2
Training loss: 0.861687958240509
Validation loss: 2.175631523132324

Epoch: 6| Step: 3
Training loss: 0.8612926006317139
Validation loss: 2.1331164836883545

Epoch: 6| Step: 4
Training loss: 1.1019375324249268
Validation loss: 2.1925796270370483

Epoch: 6| Step: 5
Training loss: 0.8049642443656921
Validation loss: 2.168290158112844

Epoch: 6| Step: 6
Training loss: 0.5408012866973877
Validation loss: 2.177222987016042

Epoch: 6| Step: 7
Training loss: 0.945654571056366
Validation loss: 2.1563710967699685

Epoch: 6| Step: 8
Training loss: 0.9881699085235596
Validation loss: 2.195364793141683

Epoch: 6| Step: 9
Training loss: 1.7274614572525024
Validation loss: 2.201570749282837

Epoch: 6| Step: 10
Training loss: 0.6363872289657593
Validation loss: 2.1853193839391074

Epoch: 6| Step: 11
Training loss: 2.3140954971313477
Validation loss: 2.1691877841949463

Epoch: 6| Step: 12
Training loss: 0.6008864641189575
Validation loss: 2.160209139188131

Epoch: 6| Step: 13
Training loss: 1.030404806137085
Validation loss: 2.1709389289220176

Epoch: 372| Step: 0
Training loss: 1.0296459197998047
Validation loss: 2.194643020629883

Epoch: 6| Step: 1
Training loss: 1.0133461952209473
Validation loss: 2.1750623981157937

Epoch: 6| Step: 2
Training loss: 0.7707372307777405
Validation loss: 2.1750922004381814

Epoch: 6| Step: 3
Training loss: 1.0598535537719727
Validation loss: 2.1837467551231384

Epoch: 6| Step: 4
Training loss: 1.2075713872909546
Validation loss: 2.166808823744456

Epoch: 6| Step: 5
Training loss: 1.2074835300445557
Validation loss: 2.153282960255941

Epoch: 6| Step: 6
Training loss: 0.5946669578552246
Validation loss: 2.1492783228556314

Epoch: 6| Step: 7
Training loss: 1.3207919597625732
Validation loss: 2.1481164495150247

Epoch: 6| Step: 8
Training loss: 1.0339568853378296
Validation loss: 2.1416178743044534

Epoch: 6| Step: 9
Training loss: 1.3168503046035767
Validation loss: 2.1475769678751626

Epoch: 6| Step: 10
Training loss: 1.2685599327087402
Validation loss: 2.1254640022913613

Epoch: 6| Step: 11
Training loss: 0.8136214017868042
Validation loss: 2.1278118888537088

Epoch: 6| Step: 12
Training loss: 1.0983388423919678
Validation loss: 2.1465256611506143

Epoch: 6| Step: 13
Training loss: 1.4587321281433105
Validation loss: 2.1452234784762063

Epoch: 373| Step: 0
Training loss: 0.6854835748672485
Validation loss: 2.1304816802342734

Epoch: 6| Step: 1
Training loss: 0.5941054224967957
Validation loss: 2.158338785171509

Epoch: 6| Step: 2
Training loss: 0.7764997482299805
Validation loss: 2.152507742245992

Epoch: 6| Step: 3
Training loss: 1.2372584342956543
Validation loss: 2.1704182028770447

Epoch: 6| Step: 4
Training loss: 0.7889290452003479
Validation loss: 2.186620275179545

Epoch: 6| Step: 5
Training loss: 0.8978044986724854
Validation loss: 2.196895122528076

Epoch: 6| Step: 6
Training loss: 1.3251378536224365
Validation loss: 2.174101452032725

Epoch: 6| Step: 7
Training loss: 1.8465063571929932
Validation loss: 2.1794842878977456

Epoch: 6| Step: 8
Training loss: 0.9986421465873718
Validation loss: 2.180100599924723

Epoch: 6| Step: 9
Training loss: 1.4978652000427246
Validation loss: 2.1534305413564048

Epoch: 6| Step: 10
Training loss: 1.1778841018676758
Validation loss: 2.1501979430516562

Epoch: 6| Step: 11
Training loss: 1.1749238967895508
Validation loss: 2.144807199637095

Epoch: 6| Step: 12
Training loss: 1.6695210933685303
Validation loss: 2.158877650896708

Epoch: 6| Step: 13
Training loss: 0.5561754107475281
Validation loss: 2.154374063014984

Epoch: 374| Step: 0
Training loss: 1.1810705661773682
Validation loss: 2.1723804473876953

Epoch: 6| Step: 1
Training loss: 1.1275920867919922
Validation loss: 2.166635354359945

Epoch: 6| Step: 2
Training loss: 0.822663426399231
Validation loss: 2.172061284383138

Epoch: 6| Step: 3
Training loss: 0.762617826461792
Validation loss: 2.1673741141955056

Epoch: 6| Step: 4
Training loss: 1.0166733264923096
Validation loss: 2.135099232196808

Epoch: 6| Step: 5
Training loss: 1.1484854221343994
Validation loss: 2.2106864054997764

Epoch: 6| Step: 6
Training loss: 1.29558265209198
Validation loss: 2.2081369956334433

Epoch: 6| Step: 7
Training loss: 0.94450843334198
Validation loss: 2.129492243131002

Epoch: 6| Step: 8
Training loss: 1.214167594909668
Validation loss: 2.1439831256866455

Epoch: 6| Step: 9
Training loss: 0.7237443923950195
Validation loss: 2.17576797803243

Epoch: 6| Step: 10
Training loss: 1.210935354232788
Validation loss: 2.1592009862264

Epoch: 6| Step: 11
Training loss: 0.9724786281585693
Validation loss: 2.1623739997545877

Epoch: 6| Step: 12
Training loss: 1.0187400579452515
Validation loss: 2.131425758202871

Epoch: 6| Step: 13
Training loss: 1.5438950061798096
Validation loss: 2.177884121735891

Epoch: 375| Step: 0
Training loss: 0.8235574960708618
Validation loss: 2.1662174661954245

Epoch: 6| Step: 1
Training loss: 1.2711212635040283
Validation loss: 2.1714744766553244

Epoch: 6| Step: 2
Training loss: 0.6739645600318909
Validation loss: 2.196175436178843

Epoch: 6| Step: 3
Training loss: 0.7858015298843384
Validation loss: 2.222144583861033

Epoch: 6| Step: 4
Training loss: 1.9660476446151733
Validation loss: 2.1657280325889587

Epoch: 6| Step: 5
Training loss: 1.6040037870407104
Validation loss: 2.1870137254397073

Epoch: 6| Step: 6
Training loss: 1.156329870223999
Validation loss: 2.183135430018107

Epoch: 6| Step: 7
Training loss: 0.6415427923202515
Validation loss: 2.1835534373919168

Epoch: 6| Step: 8
Training loss: 0.9419842958450317
Validation loss: 2.18732480208079

Epoch: 6| Step: 9
Training loss: 1.292805790901184
Validation loss: 2.1497501929601035

Epoch: 6| Step: 10
Training loss: 0.9700157642364502
Validation loss: 2.138982057571411

Epoch: 6| Step: 11
Training loss: 0.7626379728317261
Validation loss: 2.140347162882487

Epoch: 6| Step: 12
Training loss: 0.7621217370033264
Validation loss: 2.1733491619428

Epoch: 6| Step: 13
Training loss: 1.5659825801849365
Validation loss: 2.1282801230748496

Epoch: 376| Step: 0
Training loss: 0.5357075333595276
Validation loss: 2.1505231062571206

Epoch: 6| Step: 1
Training loss: 1.4403949975967407
Validation loss: 2.1386935909589133

Epoch: 6| Step: 2
Training loss: 0.9840708374977112
Validation loss: 2.179329733053843

Epoch: 6| Step: 3
Training loss: 1.3258061408996582
Validation loss: 2.1466595927874246

Epoch: 6| Step: 4
Training loss: 0.8789927959442139
Validation loss: 2.186969300111135

Epoch: 6| Step: 5
Training loss: 1.1041462421417236
Validation loss: 2.1669994990030923

Epoch: 6| Step: 6
Training loss: 0.9434918761253357
Validation loss: 2.1791825890541077

Epoch: 6| Step: 7
Training loss: 1.4652736186981201
Validation loss: 2.157942454020182

Epoch: 6| Step: 8
Training loss: 1.529550313949585
Validation loss: 2.1461813847223916

Epoch: 6| Step: 9
Training loss: 0.6825578808784485
Validation loss: 2.1859442989031472

Epoch: 6| Step: 10
Training loss: 0.8846168518066406
Validation loss: 2.187172849973043

Epoch: 6| Step: 11
Training loss: 0.7715744376182556
Validation loss: 2.1849460999170938

Epoch: 6| Step: 12
Training loss: 1.7666302919387817
Validation loss: 2.1573946674664817

Epoch: 6| Step: 13
Training loss: 1.420881748199463
Validation loss: 2.1660778323809304

Epoch: 377| Step: 0
Training loss: 0.654931366443634
Validation loss: 2.144012689590454

Epoch: 6| Step: 1
Training loss: 1.5554044246673584
Validation loss: 2.1592837969462075

Epoch: 6| Step: 2
Training loss: 1.4878621101379395
Validation loss: 2.1421566804250083

Epoch: 6| Step: 3
Training loss: 0.3238246738910675
Validation loss: 2.1185414592425027

Epoch: 6| Step: 4
Training loss: 1.022919774055481
Validation loss: 2.1147239605585733

Epoch: 6| Step: 5
Training loss: 1.1478999853134155
Validation loss: 2.1277074813842773

Epoch: 6| Step: 6
Training loss: 0.8328395485877991
Validation loss: 2.1405344804128013

Epoch: 6| Step: 7
Training loss: 1.0074182748794556
Validation loss: 2.171566426753998

Epoch: 6| Step: 8
Training loss: 1.0111429691314697
Validation loss: 2.17448753118515

Epoch: 6| Step: 9
Training loss: 1.2790985107421875
Validation loss: 2.169333279132843

Epoch: 6| Step: 10
Training loss: 1.0410908460617065
Validation loss: 2.1882378657658896

Epoch: 6| Step: 11
Training loss: 1.3536159992218018
Validation loss: 2.1430753072102866

Epoch: 6| Step: 12
Training loss: 1.2492786645889282
Validation loss: 2.1685743729273477

Epoch: 6| Step: 13
Training loss: 0.5917215347290039
Validation loss: 2.1824371417363486

Epoch: 378| Step: 0
Training loss: 0.9577739834785461
Validation loss: 2.152580142021179

Epoch: 6| Step: 1
Training loss: 1.4011210203170776
Validation loss: 2.1782159010569253

Epoch: 6| Step: 2
Training loss: 0.9332454204559326
Validation loss: 2.146923840045929

Epoch: 6| Step: 3
Training loss: 1.9543108940124512
Validation loss: 2.122346580028534

Epoch: 6| Step: 4
Training loss: 0.9939510226249695
Validation loss: 2.1443896889686584

Epoch: 6| Step: 5
Training loss: 0.9459152221679688
Validation loss: 2.1395791371663413

Epoch: 6| Step: 6
Training loss: 0.617931604385376
Validation loss: 2.115206162134806

Epoch: 6| Step: 7
Training loss: 0.700017511844635
Validation loss: 2.1280248165130615

Epoch: 6| Step: 8
Training loss: 1.232021450996399
Validation loss: 2.1359525124231973

Epoch: 6| Step: 9
Training loss: 1.3033559322357178
Validation loss: 2.1249103347460427

Epoch: 6| Step: 10
Training loss: 1.1042490005493164
Validation loss: 2.1505211194356284

Epoch: 6| Step: 11
Training loss: 1.1943844556808472
Validation loss: 2.1358283360799155

Epoch: 6| Step: 12
Training loss: 0.5246593952178955
Validation loss: 2.14971391359965

Epoch: 6| Step: 13
Training loss: 0.8022861480712891
Validation loss: 2.150760034720103

Epoch: 379| Step: 0
Training loss: 0.41693469882011414
Validation loss: 2.128291209538778

Epoch: 6| Step: 1
Training loss: 0.731010377407074
Validation loss: 2.144960939884186

Epoch: 6| Step: 2
Training loss: 0.6708892583847046
Validation loss: 2.138959805170695

Epoch: 6| Step: 3
Training loss: 1.1526753902435303
Validation loss: 2.1652714808781943

Epoch: 6| Step: 4
Training loss: 1.3894845247268677
Validation loss: 2.1721088886260986

Epoch: 6| Step: 5
Training loss: 1.1658698320388794
Validation loss: 2.1602536837259927

Epoch: 6| Step: 6
Training loss: 1.0943657159805298
Validation loss: 2.1649303237597146

Epoch: 6| Step: 7
Training loss: 0.9318777322769165
Validation loss: 2.1818515062332153

Epoch: 6| Step: 8
Training loss: 1.3004958629608154
Validation loss: 2.1509386698404946

Epoch: 6| Step: 9
Training loss: 1.0538254976272583
Validation loss: 2.1668952306111655

Epoch: 6| Step: 10
Training loss: 0.7418169975280762
Validation loss: 2.193274756272634

Epoch: 6| Step: 11
Training loss: 0.9426565170288086
Validation loss: 2.179514765739441

Epoch: 6| Step: 12
Training loss: 1.4312738180160522
Validation loss: 2.174557069937388

Epoch: 6| Step: 13
Training loss: 1.2309291362762451
Validation loss: 2.2072472174962363

Epoch: 380| Step: 0
Training loss: 0.5208462476730347
Validation loss: 2.153937300046285

Epoch: 6| Step: 1
Training loss: 1.3850774765014648
Validation loss: 2.1538628339767456

Epoch: 6| Step: 2
Training loss: 0.7535184025764465
Validation loss: 2.166783928871155

Epoch: 6| Step: 3
Training loss: 1.862355351448059
Validation loss: 2.1660597721735635

Epoch: 6| Step: 4
Training loss: 0.8178293108940125
Validation loss: 2.1673867106437683

Epoch: 6| Step: 5
Training loss: 0.8969055414199829
Validation loss: 2.154419740041097

Epoch: 6| Step: 6
Training loss: 0.9662340879440308
Validation loss: 2.1608115434646606

Epoch: 6| Step: 7
Training loss: 0.8819596171379089
Validation loss: 2.1221174399058023

Epoch: 6| Step: 8
Training loss: 1.1132137775421143
Validation loss: 2.1526293754577637

Epoch: 6| Step: 9
Training loss: 1.170949101448059
Validation loss: 2.1674877802530923

Epoch: 6| Step: 10
Training loss: 0.8234164714813232
Validation loss: 2.1626773675282798

Epoch: 6| Step: 11
Training loss: 0.7202985286712646
Validation loss: 2.1992780367533364

Epoch: 6| Step: 12
Training loss: 1.127924919128418
Validation loss: 2.153588136037191

Epoch: 6| Step: 13
Training loss: 0.9638062715530396
Validation loss: 2.1533579428990683

Epoch: 381| Step: 0
Training loss: 0.9938231706619263
Validation loss: 2.1603057185808816

Epoch: 6| Step: 1
Training loss: 0.3677358627319336
Validation loss: 2.1525213519732156

Epoch: 6| Step: 2
Training loss: 0.5749249458312988
Validation loss: 2.1601008971532187

Epoch: 6| Step: 3
Training loss: 0.4905630350112915
Validation loss: 2.149768273035685

Epoch: 6| Step: 4
Training loss: 1.0296483039855957
Validation loss: 2.18893692890803

Epoch: 6| Step: 5
Training loss: 1.545616865158081
Validation loss: 2.156410833199819

Epoch: 6| Step: 6
Training loss: 0.7919279336929321
Validation loss: 2.145086705684662

Epoch: 6| Step: 7
Training loss: 1.5781259536743164
Validation loss: 2.1547141472498574

Epoch: 6| Step: 8
Training loss: 1.3841489553451538
Validation loss: 2.160176932811737

Epoch: 6| Step: 9
Training loss: 0.7618250846862793
Validation loss: 2.192188858985901

Epoch: 6| Step: 10
Training loss: 1.4815845489501953
Validation loss: 2.1596031387646994

Epoch: 6| Step: 11
Training loss: 1.16509211063385
Validation loss: 2.1356990536053977

Epoch: 6| Step: 12
Training loss: 0.7588693499565125
Validation loss: 2.146563629309336

Epoch: 6| Step: 13
Training loss: 0.8816934823989868
Validation loss: 2.148404836654663

Epoch: 382| Step: 0
Training loss: 0.7596850395202637
Validation loss: 2.122079531351725

Epoch: 6| Step: 1
Training loss: 0.8480888605117798
Validation loss: 2.1145692269007363

Epoch: 6| Step: 2
Training loss: 0.7238907814025879
Validation loss: 2.144087076187134

Epoch: 6| Step: 3
Training loss: 0.6194801330566406
Validation loss: 2.1254555781682334

Epoch: 6| Step: 4
Training loss: 1.0007741451263428
Validation loss: 2.1338995695114136

Epoch: 6| Step: 5
Training loss: 1.373567819595337
Validation loss: 2.125239690144857

Epoch: 6| Step: 6
Training loss: 0.7317066192626953
Validation loss: 2.1216349800427756

Epoch: 6| Step: 7
Training loss: 0.7388837337493896
Validation loss: 2.100573698679606

Epoch: 6| Step: 8
Training loss: 0.9127464890480042
Validation loss: 2.1296961108843484

Epoch: 6| Step: 9
Training loss: 1.6891214847564697
Validation loss: 2.127758502960205

Epoch: 6| Step: 10
Training loss: 0.920110821723938
Validation loss: 2.1264445384343467

Epoch: 6| Step: 11
Training loss: 1.0547025203704834
Validation loss: 2.129130562146505

Epoch: 6| Step: 12
Training loss: 1.7315294742584229
Validation loss: 2.1531574527422586

Epoch: 6| Step: 13
Training loss: 1.1958467960357666
Validation loss: 2.160779654979706

Epoch: 383| Step: 0
Training loss: 1.2531673908233643
Validation loss: 2.1243903239568076

Epoch: 6| Step: 1
Training loss: 1.1573734283447266
Validation loss: 2.1439048051834106

Epoch: 6| Step: 2
Training loss: 0.9696345925331116
Validation loss: 2.1396256486574807

Epoch: 6| Step: 3
Training loss: 0.8782535195350647
Validation loss: 2.1288467248280845

Epoch: 6| Step: 4
Training loss: 0.7101195454597473
Validation loss: 2.147415558497111

Epoch: 6| Step: 5
Training loss: 1.1494919061660767
Validation loss: 2.1579157511393228

Epoch: 6| Step: 6
Training loss: 0.5448222160339355
Validation loss: 2.1341865261395774

Epoch: 6| Step: 7
Training loss: 1.8345441818237305
Validation loss: 2.1452160080273948

Epoch: 6| Step: 8
Training loss: 1.3756954669952393
Validation loss: 2.1414311726888022

Epoch: 6| Step: 9
Training loss: 0.6265193223953247
Validation loss: 2.111547311147054

Epoch: 6| Step: 10
Training loss: 0.5646092891693115
Validation loss: 2.103529989719391

Epoch: 6| Step: 11
Training loss: 1.0893689393997192
Validation loss: 2.146074136098226

Epoch: 6| Step: 12
Training loss: 1.207273244857788
Validation loss: 2.163017431894938

Epoch: 6| Step: 13
Training loss: 1.0168628692626953
Validation loss: 2.1405921379725137

Epoch: 384| Step: 0
Training loss: 0.7616539001464844
Validation loss: 2.157338798046112

Epoch: 6| Step: 1
Training loss: 0.5615332126617432
Validation loss: 2.1191472013791404

Epoch: 6| Step: 2
Training loss: 0.9435926079750061
Validation loss: 2.1189215183258057

Epoch: 6| Step: 3
Training loss: 1.863834023475647
Validation loss: 2.1247165203094482

Epoch: 6| Step: 4
Training loss: 0.7310817837715149
Validation loss: 2.097848375638326

Epoch: 6| Step: 5
Training loss: 0.8089265823364258
Validation loss: 2.14124463001887

Epoch: 6| Step: 6
Training loss: 1.1819835901260376
Validation loss: 2.1546120047569275

Epoch: 6| Step: 7
Training loss: 1.000760793685913
Validation loss: 2.1416362722714744

Epoch: 6| Step: 8
Training loss: 1.0309064388275146
Validation loss: 2.134062568346659

Epoch: 6| Step: 9
Training loss: 1.1402276754379272
Validation loss: 2.190228581428528

Epoch: 6| Step: 10
Training loss: 1.6274548768997192
Validation loss: 2.1588589549064636

Epoch: 6| Step: 11
Training loss: 0.7010512351989746
Validation loss: 2.17353218793869

Epoch: 6| Step: 12
Training loss: 1.2055422067642212
Validation loss: 2.1585007508595786

Epoch: 6| Step: 13
Training loss: 0.6514390707015991
Validation loss: 2.1466983358065286

Epoch: 385| Step: 0
Training loss: 0.7064187526702881
Validation loss: 2.1754003763198853

Epoch: 6| Step: 1
Training loss: 0.8021295666694641
Validation loss: 2.183687965075175

Epoch: 6| Step: 2
Training loss: 1.463394045829773
Validation loss: 2.1658637523651123

Epoch: 6| Step: 3
Training loss: 0.434684693813324
Validation loss: 2.1649311780929565

Epoch: 6| Step: 4
Training loss: 1.4689254760742188
Validation loss: 2.1198725501696267

Epoch: 6| Step: 5
Training loss: 0.9541752338409424
Validation loss: 2.1536171038945517

Epoch: 6| Step: 6
Training loss: 1.3233528137207031
Validation loss: 2.1722859144210815

Epoch: 6| Step: 7
Training loss: 1.5103250741958618
Validation loss: 2.1685046752293906

Epoch: 6| Step: 8
Training loss: 0.80014967918396
Validation loss: 2.187073548634847

Epoch: 6| Step: 9
Training loss: 0.7217669486999512
Validation loss: 2.154957969983419

Epoch: 6| Step: 10
Training loss: 0.6277469396591187
Validation loss: 2.1779006918271384

Epoch: 6| Step: 11
Training loss: 1.1236480474472046
Validation loss: 2.213259200255076

Epoch: 6| Step: 12
Training loss: 1.1662497520446777
Validation loss: 2.1972654461860657

Epoch: 6| Step: 13
Training loss: 0.9169598817825317
Validation loss: 2.2085832556088767

Epoch: 386| Step: 0
Training loss: 0.6426849961280823
Validation loss: 2.2071575125058494

Epoch: 6| Step: 1
Training loss: 0.6609829068183899
Validation loss: 2.1816868782043457

Epoch: 6| Step: 2
Training loss: 0.7327200174331665
Validation loss: 2.153316537539164

Epoch: 6| Step: 3
Training loss: 1.283560037612915
Validation loss: 2.1709166367848716

Epoch: 6| Step: 4
Training loss: 1.3277578353881836
Validation loss: 2.1650180419286094

Epoch: 6| Step: 5
Training loss: 1.316482663154602
Validation loss: 2.13609113295873

Epoch: 6| Step: 6
Training loss: 0.6385858654975891
Validation loss: 2.1572550535202026

Epoch: 6| Step: 7
Training loss: 0.5962249040603638
Validation loss: 2.157079001267751

Epoch: 6| Step: 8
Training loss: 0.8313726782798767
Validation loss: 2.1579321225484214

Epoch: 6| Step: 9
Training loss: 1.0722861289978027
Validation loss: 2.1175710558891296

Epoch: 6| Step: 10
Training loss: 1.3022379875183105
Validation loss: 2.166897197564443

Epoch: 6| Step: 11
Training loss: 1.6625959873199463
Validation loss: 2.155889550844828

Epoch: 6| Step: 12
Training loss: 0.7633070945739746
Validation loss: 2.188157002131144

Epoch: 6| Step: 13
Training loss: 0.7319015264511108
Validation loss: 2.170196016629537

Epoch: 387| Step: 0
Training loss: 0.5576385855674744
Validation loss: 2.218765616416931

Epoch: 6| Step: 1
Training loss: 0.835329532623291
Validation loss: 2.198530654112498

Epoch: 6| Step: 2
Training loss: 1.5141065120697021
Validation loss: 2.1693257490793862

Epoch: 6| Step: 3
Training loss: 0.7780148983001709
Validation loss: 2.197411914666494

Epoch: 6| Step: 4
Training loss: 0.8086671829223633
Validation loss: 2.182266036669413

Epoch: 6| Step: 5
Training loss: 0.45817986130714417
Validation loss: 2.1905765930811563

Epoch: 6| Step: 6
Training loss: 0.8016691207885742
Validation loss: 2.210675140221914

Epoch: 6| Step: 7
Training loss: 0.9082322120666504
Validation loss: 2.1452846129735312

Epoch: 6| Step: 8
Training loss: 1.4793564081192017
Validation loss: 2.1356122493743896

Epoch: 6| Step: 9
Training loss: 0.906843900680542
Validation loss: 2.148422122001648

Epoch: 6| Step: 10
Training loss: 0.9907621145248413
Validation loss: 2.1563913424809775

Epoch: 6| Step: 11
Training loss: 1.205237865447998
Validation loss: 2.1987737019856772

Epoch: 6| Step: 12
Training loss: 1.1938104629516602
Validation loss: 2.1892604430516562

Epoch: 6| Step: 13
Training loss: 1.4291329383850098
Validation loss: 2.160492181777954

Epoch: 388| Step: 0
Training loss: 1.070214033126831
Validation loss: 2.2205970684687295

Epoch: 6| Step: 1
Training loss: 0.5076314210891724
Validation loss: 2.1964568893114724

Epoch: 6| Step: 2
Training loss: 1.8856178522109985
Validation loss: 2.187118629614512

Epoch: 6| Step: 3
Training loss: 1.378881812095642
Validation loss: 2.176489452521006

Epoch: 6| Step: 4
Training loss: 0.6099268794059753
Validation loss: 2.186385373274485

Epoch: 6| Step: 5
Training loss: 0.8147786259651184
Validation loss: 2.1706891457239785

Epoch: 6| Step: 6
Training loss: 0.7965637445449829
Validation loss: 2.1722939809163413

Epoch: 6| Step: 7
Training loss: 1.024643063545227
Validation loss: 2.1624589761098227

Epoch: 6| Step: 8
Training loss: 0.8997918367385864
Validation loss: 2.175759037335714

Epoch: 6| Step: 9
Training loss: 1.1720638275146484
Validation loss: 2.172359824180603

Epoch: 6| Step: 10
Training loss: 0.44375497102737427
Validation loss: 2.1717137893040976

Epoch: 6| Step: 11
Training loss: 1.1921755075454712
Validation loss: 2.18442302942276

Epoch: 6| Step: 12
Training loss: 1.5554393529891968
Validation loss: 2.176463226477305

Epoch: 6| Step: 13
Training loss: 0.6258774399757385
Validation loss: 2.1684670646985373

Epoch: 389| Step: 0
Training loss: 0.680914044380188
Validation loss: 2.1371388832728067

Epoch: 6| Step: 1
Training loss: 1.1140061616897583
Validation loss: 2.20172381401062

Epoch: 6| Step: 2
Training loss: 0.9870834946632385
Validation loss: 2.178130308787028

Epoch: 6| Step: 3
Training loss: 0.7359492778778076
Validation loss: 2.1550360719362893

Epoch: 6| Step: 4
Training loss: 1.2852176427841187
Validation loss: 2.194293518861135

Epoch: 6| Step: 5
Training loss: 1.0969946384429932
Validation loss: 2.1690115531285605

Epoch: 6| Step: 6
Training loss: 0.6740245223045349
Validation loss: 2.149540066719055

Epoch: 6| Step: 7
Training loss: 1.2390159368515015
Validation loss: 2.191008965174357

Epoch: 6| Step: 8
Training loss: 0.46544259786605835
Validation loss: 2.150592565536499

Epoch: 6| Step: 9
Training loss: 0.916176438331604
Validation loss: 2.154455304145813

Epoch: 6| Step: 10
Training loss: 1.5792055130004883
Validation loss: 2.156555930773417

Epoch: 6| Step: 11
Training loss: 0.5806857347488403
Validation loss: 2.1767839193344116

Epoch: 6| Step: 12
Training loss: 1.0051687955856323
Validation loss: 2.15468297402064

Epoch: 6| Step: 13
Training loss: 1.1296772956848145
Validation loss: 2.1422353188196817

Epoch: 390| Step: 0
Training loss: 1.1457319259643555
Validation loss: 2.1207775473594666

Epoch: 6| Step: 1
Training loss: 0.6286176443099976
Validation loss: 2.1414724787076316

Epoch: 6| Step: 2
Training loss: 0.5658094882965088
Validation loss: 2.0937233368555703

Epoch: 6| Step: 3
Training loss: 0.9489185810089111
Validation loss: 2.12544047832489

Epoch: 6| Step: 4
Training loss: 0.5912882089614868
Validation loss: 2.1099369724591575

Epoch: 6| Step: 5
Training loss: 1.2506183385849
Validation loss: 2.114104906717936

Epoch: 6| Step: 6
Training loss: 0.675656795501709
Validation loss: 2.1498337189356485

Epoch: 6| Step: 7
Training loss: 0.7529793977737427
Validation loss: 2.1161372462908425

Epoch: 6| Step: 8
Training loss: 1.0573399066925049
Validation loss: 2.1225616733233132

Epoch: 6| Step: 9
Training loss: 0.997017502784729
Validation loss: 2.129003723462423

Epoch: 6| Step: 10
Training loss: 1.880591630935669
Validation loss: 2.15431010723114

Epoch: 6| Step: 11
Training loss: 0.8721181154251099
Validation loss: 2.144689122835795

Epoch: 6| Step: 12
Training loss: 1.138211727142334
Validation loss: 2.1320123076438904

Epoch: 6| Step: 13
Training loss: 0.7562583684921265
Validation loss: 2.1838221152623496

Epoch: 391| Step: 0
Training loss: 0.887189507484436
Validation loss: 2.1817948619524636

Epoch: 6| Step: 1
Training loss: 0.617837131023407
Validation loss: 2.203760246435801

Epoch: 6| Step: 2
Training loss: 0.9651510715484619
Validation loss: 2.179684559504191

Epoch: 6| Step: 3
Training loss: 0.9511112570762634
Validation loss: 2.166953464349111

Epoch: 6| Step: 4
Training loss: 0.6504824757575989
Validation loss: 2.1883813937505088

Epoch: 6| Step: 5
Training loss: 0.9950830936431885
Validation loss: 2.1657851338386536

Epoch: 6| Step: 6
Training loss: 0.7971570491790771
Validation loss: 2.19053723414739

Epoch: 6| Step: 7
Training loss: 1.3077940940856934
Validation loss: 2.1849640806516013

Epoch: 6| Step: 8
Training loss: 1.1777567863464355
Validation loss: 2.1981905102729797

Epoch: 6| Step: 9
Training loss: 0.9988119602203369
Validation loss: 2.2215251127878823

Epoch: 6| Step: 10
Training loss: 1.47269606590271
Validation loss: 2.194021383921305

Epoch: 6| Step: 11
Training loss: 1.1830592155456543
Validation loss: 2.2119745214780173

Epoch: 6| Step: 12
Training loss: 1.5613908767700195
Validation loss: 2.213978091875712

Epoch: 6| Step: 13
Training loss: 0.922730565071106
Validation loss: 2.2274477084477744

Epoch: 392| Step: 0
Training loss: 1.1657094955444336
Validation loss: 2.192275961240133

Epoch: 6| Step: 1
Training loss: 1.2820616960525513
Validation loss: 2.174846132596334

Epoch: 6| Step: 2
Training loss: 1.025172233581543
Validation loss: 2.1620983680089316

Epoch: 6| Step: 3
Training loss: 0.5720993280410767
Validation loss: 2.153204401334127

Epoch: 6| Step: 4
Training loss: 0.36053410172462463
Validation loss: 2.159616490205129

Epoch: 6| Step: 5
Training loss: 0.9678308963775635
Validation loss: 2.1307671070098877

Epoch: 6| Step: 6
Training loss: 0.652614951133728
Validation loss: 2.1506717205047607

Epoch: 6| Step: 7
Training loss: 0.8655484914779663
Validation loss: 2.136383374532064

Epoch: 6| Step: 8
Training loss: 0.8745418190956116
Validation loss: 2.164621969064077

Epoch: 6| Step: 9
Training loss: 1.1523146629333496
Validation loss: 2.135326544443766

Epoch: 6| Step: 10
Training loss: 1.2459754943847656
Validation loss: 2.1767874360084534

Epoch: 6| Step: 11
Training loss: 1.6643285751342773
Validation loss: 2.1599169969558716

Epoch: 6| Step: 12
Training loss: 0.9145436882972717
Validation loss: 2.1416773796081543

Epoch: 6| Step: 13
Training loss: 0.823040246963501
Validation loss: 2.1578047275543213

Epoch: 393| Step: 0
Training loss: 0.8827205896377563
Validation loss: 2.1480559706687927

Epoch: 6| Step: 1
Training loss: 0.9824918508529663
Validation loss: 2.119324783484141

Epoch: 6| Step: 2
Training loss: 0.8456624746322632
Validation loss: 2.166421413421631

Epoch: 6| Step: 3
Training loss: 0.7871859073638916
Validation loss: 2.170232812563578

Epoch: 6| Step: 4
Training loss: 1.2276091575622559
Validation loss: 2.168018857638041

Epoch: 6| Step: 5
Training loss: 0.5179034471511841
Validation loss: 2.1683533589045205

Epoch: 6| Step: 6
Training loss: 1.4728991985321045
Validation loss: 2.16642693678538

Epoch: 6| Step: 7
Training loss: 1.4731624126434326
Validation loss: 2.1849719087282815

Epoch: 6| Step: 8
Training loss: 0.6419774293899536
Validation loss: 2.183083633581797

Epoch: 6| Step: 9
Training loss: 0.9813767075538635
Validation loss: 2.1427791515986123

Epoch: 6| Step: 10
Training loss: 1.045372724533081
Validation loss: 2.1791255871454873

Epoch: 6| Step: 11
Training loss: 0.946875274181366
Validation loss: 2.163291056950887

Epoch: 6| Step: 12
Training loss: 1.090205192565918
Validation loss: 2.145988424619039

Epoch: 6| Step: 13
Training loss: 0.9411343336105347
Validation loss: 2.137851893901825

Epoch: 394| Step: 0
Training loss: 0.95589280128479
Validation loss: 2.144551396369934

Epoch: 6| Step: 1
Training loss: 0.5968488454818726
Validation loss: 2.1871500412623086

Epoch: 6| Step: 2
Training loss: 0.5624873042106628
Validation loss: 2.1897056897481284

Epoch: 6| Step: 3
Training loss: 0.7598159313201904
Validation loss: 2.1707282066345215

Epoch: 6| Step: 4
Training loss: 1.1949653625488281
Validation loss: 2.1684743563334146

Epoch: 6| Step: 5
Training loss: 1.9049522876739502
Validation loss: 2.1936793327331543

Epoch: 6| Step: 6
Training loss: 1.0604827404022217
Validation loss: 2.1674644549687705

Epoch: 6| Step: 7
Training loss: 1.63791823387146
Validation loss: 2.1852170626322427

Epoch: 6| Step: 8
Training loss: 0.8860525488853455
Validation loss: 2.2097072203954062

Epoch: 6| Step: 9
Training loss: 0.5329574346542358
Validation loss: 2.1890393694241843

Epoch: 6| Step: 10
Training loss: 0.7913006544113159
Validation loss: 2.184522191683451

Epoch: 6| Step: 11
Training loss: 1.094415545463562
Validation loss: 2.171215852101644

Epoch: 6| Step: 12
Training loss: 0.8097144365310669
Validation loss: 2.1769479314486184

Epoch: 6| Step: 13
Training loss: 1.3240044116973877
Validation loss: 2.14905846118927

Epoch: 395| Step: 0
Training loss: 0.3543305993080139
Validation loss: 2.1604785720507302

Epoch: 6| Step: 1
Training loss: 0.3415737748146057
Validation loss: 2.187920312086741

Epoch: 6| Step: 2
Training loss: 1.107957124710083
Validation loss: 2.2024613420168557

Epoch: 6| Step: 3
Training loss: 0.8757551908493042
Validation loss: 2.1495813131332397

Epoch: 6| Step: 4
Training loss: 1.0614479780197144
Validation loss: 2.1582274039586387

Epoch: 6| Step: 5
Training loss: 0.6886730194091797
Validation loss: 2.1705090602238974

Epoch: 6| Step: 6
Training loss: 0.8297920227050781
Validation loss: 2.1979137857755027

Epoch: 6| Step: 7
Training loss: 1.3993163108825684
Validation loss: 2.189594089984894

Epoch: 6| Step: 8
Training loss: 1.0927228927612305
Validation loss: 2.1832278768221536

Epoch: 6| Step: 9
Training loss: 0.8181192874908447
Validation loss: 2.157242159048716

Epoch: 6| Step: 10
Training loss: 0.9754754304885864
Validation loss: 2.1880379716555276

Epoch: 6| Step: 11
Training loss: 1.0174704790115356
Validation loss: 2.1752867698669434

Epoch: 6| Step: 12
Training loss: 1.1404973268508911
Validation loss: 2.1869694590568542

Epoch: 6| Step: 13
Training loss: 1.2340935468673706
Validation loss: 2.1810527046521506

Epoch: 396| Step: 0
Training loss: 0.9329809546470642
Validation loss: 2.190928041934967

Epoch: 6| Step: 1
Training loss: 0.9242684841156006
Validation loss: 2.1919806400934854

Epoch: 6| Step: 2
Training loss: 1.696476936340332
Validation loss: 2.2046044866243997

Epoch: 6| Step: 3
Training loss: 0.3774563670158386
Validation loss: 2.2163403828938804

Epoch: 6| Step: 4
Training loss: 1.217511773109436
Validation loss: 2.158808946609497

Epoch: 6| Step: 5
Training loss: 0.46630871295928955
Validation loss: 2.1853578885396323

Epoch: 6| Step: 6
Training loss: 0.4166320562362671
Validation loss: 2.143315772215525

Epoch: 6| Step: 7
Training loss: 1.3535352945327759
Validation loss: 2.156113107999166

Epoch: 6| Step: 8
Training loss: 0.8628338575363159
Validation loss: 2.126279274622599

Epoch: 6| Step: 9
Training loss: 0.8875176906585693
Validation loss: 2.1405879656473794

Epoch: 6| Step: 10
Training loss: 0.6223808526992798
Validation loss: 2.1526242097218833

Epoch: 6| Step: 11
Training loss: 0.8201924562454224
Validation loss: 2.1344706217447915

Epoch: 6| Step: 12
Training loss: 0.8960936069488525
Validation loss: 2.1577290892601013

Epoch: 6| Step: 13
Training loss: 1.3685698509216309
Validation loss: 2.1533298889795938

Epoch: 397| Step: 0
Training loss: 1.4577406644821167
Validation loss: 2.140487492084503

Epoch: 6| Step: 1
Training loss: 1.4886622428894043
Validation loss: 2.1534639795621238

Epoch: 6| Step: 2
Training loss: 0.504112958908081
Validation loss: 2.1385870973269143

Epoch: 6| Step: 3
Training loss: 0.3493039608001709
Validation loss: 2.105672597885132

Epoch: 6| Step: 4
Training loss: 0.5726138353347778
Validation loss: 2.1735392014185586

Epoch: 6| Step: 5
Training loss: 1.024166464805603
Validation loss: 2.137673556804657

Epoch: 6| Step: 6
Training loss: 1.5269938707351685
Validation loss: 2.1625205675760903

Epoch: 6| Step: 7
Training loss: 0.8105747699737549
Validation loss: 2.1318345864613852

Epoch: 6| Step: 8
Training loss: 0.4438123404979706
Validation loss: 2.1475696166356406

Epoch: 6| Step: 9
Training loss: 0.8369843363761902
Validation loss: 2.1271043618520102

Epoch: 6| Step: 10
Training loss: 1.0647337436676025
Validation loss: 2.1515814860661826

Epoch: 6| Step: 11
Training loss: 0.6731961965560913
Validation loss: 2.152310073375702

Epoch: 6| Step: 12
Training loss: 0.5183005928993225
Validation loss: 2.1682054003079734

Epoch: 6| Step: 13
Training loss: 1.2030284404754639
Validation loss: 2.1737393538157144

Epoch: 398| Step: 0
Training loss: 0.6950732469558716
Validation loss: 2.155385156472524

Epoch: 6| Step: 1
Training loss: 1.1539082527160645
Validation loss: 2.1485570073127747

Epoch: 6| Step: 2
Training loss: 1.5252151489257812
Validation loss: 2.1680970589319863

Epoch: 6| Step: 3
Training loss: 0.22789588570594788
Validation loss: 2.189463257789612

Epoch: 6| Step: 4
Training loss: 0.7511085271835327
Validation loss: 2.1722668210665383

Epoch: 6| Step: 5
Training loss: 1.1921740770339966
Validation loss: 2.1841171979904175

Epoch: 6| Step: 6
Training loss: 0.9695816040039062
Validation loss: 2.168269455432892

Epoch: 6| Step: 7
Training loss: 1.2988171577453613
Validation loss: 2.1842054526011148

Epoch: 6| Step: 8
Training loss: 1.1685216426849365
Validation loss: 2.1951175530751548

Epoch: 6| Step: 9
Training loss: 0.6603778004646301
Validation loss: 2.1566827297210693

Epoch: 6| Step: 10
Training loss: 0.5570838451385498
Validation loss: 2.168069005012512

Epoch: 6| Step: 11
Training loss: 0.6837940216064453
Validation loss: 2.1612480878829956

Epoch: 6| Step: 12
Training loss: 1.329211711883545
Validation loss: 2.181059459845225

Epoch: 6| Step: 13
Training loss: 0.7253807783126831
Validation loss: 2.1566866040229797

Epoch: 399| Step: 0
Training loss: 1.048107624053955
Validation loss: 2.183399816354116

Epoch: 6| Step: 1
Training loss: 0.5993654727935791
Validation loss: 2.19484015305837

Epoch: 6| Step: 2
Training loss: 0.674452543258667
Validation loss: 2.1696094274520874

Epoch: 6| Step: 3
Training loss: 1.6171278953552246
Validation loss: 2.158056914806366

Epoch: 6| Step: 4
Training loss: 0.5852664709091187
Validation loss: 2.159295598665873

Epoch: 6| Step: 5
Training loss: 0.8821203112602234
Validation loss: 2.1895684401194253

Epoch: 6| Step: 6
Training loss: 1.3464784622192383
Validation loss: 2.142374495665232

Epoch: 6| Step: 7
Training loss: 1.1809310913085938
Validation loss: 2.133502721786499

Epoch: 6| Step: 8
Training loss: 0.7308357954025269
Validation loss: 2.145207663377126

Epoch: 6| Step: 9
Training loss: 0.7774194478988647
Validation loss: 2.1783872644106546

Epoch: 6| Step: 10
Training loss: 1.0597832202911377
Validation loss: 2.161368111769358

Epoch: 6| Step: 11
Training loss: 0.908481240272522
Validation loss: 2.152763605117798

Epoch: 6| Step: 12
Training loss: 0.30769407749176025
Validation loss: 2.148464639981588

Epoch: 6| Step: 13
Training loss: 1.1677048206329346
Validation loss: 2.1230119268099465

Epoch: 400| Step: 0
Training loss: 0.5892789363861084
Validation loss: 2.172387719154358

Epoch: 6| Step: 1
Training loss: 0.6715813279151917
Validation loss: 2.16471658150355

Epoch: 6| Step: 2
Training loss: 1.6682403087615967
Validation loss: 2.1628865798314414

Epoch: 6| Step: 3
Training loss: 1.366132378578186
Validation loss: 2.149488170941671

Epoch: 6| Step: 4
Training loss: 0.8025544881820679
Validation loss: 2.171926180521647

Epoch: 6| Step: 5
Training loss: 0.7564311027526855
Validation loss: 2.1491425037384033

Epoch: 6| Step: 6
Training loss: 0.8793895840644836
Validation loss: 2.1236497163772583

Epoch: 6| Step: 7
Training loss: 1.0827422142028809
Validation loss: 2.1775776942571006

Epoch: 6| Step: 8
Training loss: 0.6754900217056274
Validation loss: 2.147107779979706

Epoch: 6| Step: 9
Training loss: 0.6874470710754395
Validation loss: 2.168282429377238

Epoch: 6| Step: 10
Training loss: 0.8976831436157227
Validation loss: 2.1648433605829873

Epoch: 6| Step: 11
Training loss: 0.7520092725753784
Validation loss: 2.1809170246124268

Epoch: 6| Step: 12
Training loss: 1.233176827430725
Validation loss: 2.1364635030428567

Epoch: 6| Step: 13
Training loss: 0.27429723739624023
Validation loss: 2.1805964708328247

Epoch: 401| Step: 0
Training loss: 0.522376537322998
Validation loss: 2.1498142878214517

Epoch: 6| Step: 1
Training loss: 1.586646318435669
Validation loss: 2.161728044350942

Epoch: 6| Step: 2
Training loss: 0.8657704591751099
Validation loss: 2.1806015968322754

Epoch: 6| Step: 3
Training loss: 0.6430591940879822
Validation loss: 2.166924516359965

Epoch: 6| Step: 4
Training loss: 0.5965911746025085
Validation loss: 2.1927988131841025

Epoch: 6| Step: 5
Training loss: 1.096168041229248
Validation loss: 2.1683980425198874

Epoch: 6| Step: 6
Training loss: 0.7006380558013916
Validation loss: 2.1732062697410583

Epoch: 6| Step: 7
Training loss: 1.1983875036239624
Validation loss: 2.197711249192556

Epoch: 6| Step: 8
Training loss: 0.5026149749755859
Validation loss: 2.1899062395095825

Epoch: 6| Step: 9
Training loss: 0.8762613534927368
Validation loss: 2.1503634651501975

Epoch: 6| Step: 10
Training loss: 1.037078619003296
Validation loss: 2.1660441557566323

Epoch: 6| Step: 11
Training loss: 0.5512890815734863
Validation loss: 2.1553306380907693

Epoch: 6| Step: 12
Training loss: 1.2665801048278809
Validation loss: 2.1764155626296997

Epoch: 6| Step: 13
Training loss: 1.0360403060913086
Validation loss: 2.1518094539642334

Epoch: 402| Step: 0
Training loss: 0.9200048446655273
Validation loss: 2.1467368602752686

Epoch: 6| Step: 1
Training loss: 1.4187557697296143
Validation loss: 2.141639014085134

Epoch: 6| Step: 2
Training loss: 0.8791526556015015
Validation loss: 2.132680376370748

Epoch: 6| Step: 3
Training loss: 0.9179022312164307
Validation loss: 2.125615934530894

Epoch: 6| Step: 4
Training loss: 0.8094305396080017
Validation loss: 2.1660529573758445

Epoch: 6| Step: 5
Training loss: 0.7217305898666382
Validation loss: 2.1594492197036743

Epoch: 6| Step: 6
Training loss: 0.8150348663330078
Validation loss: 2.194334169228872

Epoch: 6| Step: 7
Training loss: 1.0073984861373901
Validation loss: 2.1941062211990356

Epoch: 6| Step: 8
Training loss: 1.1123161315917969
Validation loss: 2.1921999057133994

Epoch: 6| Step: 9
Training loss: 1.1727402210235596
Validation loss: 2.1631637811660767

Epoch: 6| Step: 10
Training loss: 0.6992530822753906
Validation loss: 2.162427385648092

Epoch: 6| Step: 11
Training loss: 0.6596982479095459
Validation loss: 2.1776732007662454

Epoch: 6| Step: 12
Training loss: 0.7990387678146362
Validation loss: 2.125918984413147

Epoch: 6| Step: 13
Training loss: 1.1996862888336182
Validation loss: 2.1434548695882163

Epoch: 403| Step: 0
Training loss: 1.0465726852416992
Validation loss: 2.164922813574473

Epoch: 6| Step: 1
Training loss: 0.8325110673904419
Validation loss: 2.133806506792704

Epoch: 6| Step: 2
Training loss: 0.5079284906387329
Validation loss: 2.1832844614982605

Epoch: 6| Step: 3
Training loss: 1.4888627529144287
Validation loss: 2.2224172353744507

Epoch: 6| Step: 4
Training loss: 1.0819860696792603
Validation loss: 2.1738025347391763

Epoch: 6| Step: 5
Training loss: 0.6876595616340637
Validation loss: 2.1782715916633606

Epoch: 6| Step: 6
Training loss: 0.7516016960144043
Validation loss: 2.2235745986302695

Epoch: 6| Step: 7
Training loss: 0.6603308916091919
Validation loss: 2.1895469625790915

Epoch: 6| Step: 8
Training loss: 0.4257536232471466
Validation loss: 2.1814080278078714

Epoch: 6| Step: 9
Training loss: 1.7743521928787231
Validation loss: 2.201629102230072

Epoch: 6| Step: 10
Training loss: 1.1552400588989258
Validation loss: 2.2091592947642007

Epoch: 6| Step: 11
Training loss: 0.7944943308830261
Validation loss: 2.1933435996373496

Epoch: 6| Step: 12
Training loss: 0.7521069645881653
Validation loss: 2.1611558397610984

Epoch: 6| Step: 13
Training loss: 1.0615565776824951
Validation loss: 2.1817126274108887

Epoch: 404| Step: 0
Training loss: 0.8103404641151428
Validation loss: 2.191427528858185

Epoch: 6| Step: 1
Training loss: 1.7048099040985107
Validation loss: 2.1903604865074158

Epoch: 6| Step: 2
Training loss: 0.6450503468513489
Validation loss: 2.165743072827657

Epoch: 6| Step: 3
Training loss: 0.9994915127754211
Validation loss: 2.179328997929891

Epoch: 6| Step: 4
Training loss: 1.1583141088485718
Validation loss: 2.178815484046936

Epoch: 6| Step: 5
Training loss: 0.3982032537460327
Validation loss: 2.119201878706614

Epoch: 6| Step: 6
Training loss: 0.33571264147758484
Validation loss: 2.1665470202763877

Epoch: 6| Step: 7
Training loss: 1.7584598064422607
Validation loss: 2.175411343574524

Epoch: 6| Step: 8
Training loss: 1.0624709129333496
Validation loss: 2.121482491493225

Epoch: 6| Step: 9
Training loss: 0.7644171714782715
Validation loss: 2.1697541077931723

Epoch: 6| Step: 10
Training loss: 0.8715665340423584
Validation loss: 2.1486356059710183

Epoch: 6| Step: 11
Training loss: 0.7424379587173462
Validation loss: 2.1397331158320108

Epoch: 6| Step: 12
Training loss: 0.9522809982299805
Validation loss: 2.100393017133077

Epoch: 6| Step: 13
Training loss: 1.189824104309082
Validation loss: 2.118127624193827

Epoch: 405| Step: 0
Training loss: 1.169271469116211
Validation loss: 2.17521603902181

Epoch: 6| Step: 1
Training loss: 1.4467869997024536
Validation loss: 2.1223140358924866

Epoch: 6| Step: 2
Training loss: 0.8802143335342407
Validation loss: 2.1445475618044534

Epoch: 6| Step: 3
Training loss: 1.234454870223999
Validation loss: 2.1645114024480185

Epoch: 6| Step: 4
Training loss: 0.5217820405960083
Validation loss: 2.14315398534139

Epoch: 6| Step: 5
Training loss: 0.5125553607940674
Validation loss: 2.153293232123057

Epoch: 6| Step: 6
Training loss: 0.7871516942977905
Validation loss: 2.199907124042511

Epoch: 6| Step: 7
Training loss: 0.9511468410491943
Validation loss: 2.1978863875071206

Epoch: 6| Step: 8
Training loss: 1.2112421989440918
Validation loss: 2.2064057191212973

Epoch: 6| Step: 9
Training loss: 1.2739800214767456
Validation loss: 2.268511732419332

Epoch: 6| Step: 10
Training loss: 0.5184268355369568
Validation loss: 2.2493021289507547

Epoch: 6| Step: 11
Training loss: 0.9636936187744141
Validation loss: 2.202999254067739

Epoch: 6| Step: 12
Training loss: 0.7043830156326294
Validation loss: 2.220950702826182

Epoch: 6| Step: 13
Training loss: 1.0753319263458252
Validation loss: 2.189755837122599

Epoch: 406| Step: 0
Training loss: 1.0877318382263184
Validation loss: 2.1945088704427085

Epoch: 6| Step: 1
Training loss: 0.5911890268325806
Validation loss: 2.2171807487805686

Epoch: 6| Step: 2
Training loss: 1.1029249429702759
Validation loss: 2.2224945624669394

Epoch: 6| Step: 3
Training loss: 0.41271543502807617
Validation loss: 2.2168715397516885

Epoch: 6| Step: 4
Training loss: 0.3947308659553528
Validation loss: 2.17693438132604

Epoch: 6| Step: 5
Training loss: 0.5642349123954773
Validation loss: 2.1920023759206138

Epoch: 6| Step: 6
Training loss: 1.2405545711517334
Validation loss: 2.2275264859199524

Epoch: 6| Step: 7
Training loss: 1.1060601472854614
Validation loss: 2.1916644970575967

Epoch: 6| Step: 8
Training loss: 1.019086241722107
Validation loss: 2.1835074027379355

Epoch: 6| Step: 9
Training loss: 0.6486444473266602
Validation loss: 2.1503844062487283

Epoch: 6| Step: 10
Training loss: 1.1107306480407715
Validation loss: 2.1880098978678384

Epoch: 6| Step: 11
Training loss: 1.0241062641143799
Validation loss: 2.17970218261083

Epoch: 6| Step: 12
Training loss: 1.1157654523849487
Validation loss: 2.209455589453379

Epoch: 6| Step: 13
Training loss: 1.0285606384277344
Validation loss: 2.1894744833310447

Epoch: 407| Step: 0
Training loss: 0.5667387247085571
Validation loss: 2.165765702724457

Epoch: 6| Step: 1
Training loss: 0.8323937654495239
Validation loss: 2.164910316467285

Epoch: 6| Step: 2
Training loss: 0.8433454036712646
Validation loss: 2.1632626255353293

Epoch: 6| Step: 3
Training loss: 0.4570760726928711
Validation loss: 2.1355020403862

Epoch: 6| Step: 4
Training loss: 1.0658499002456665
Validation loss: 2.192146102587382

Epoch: 6| Step: 5
Training loss: 0.8799453973770142
Validation loss: 2.1801723639170327

Epoch: 6| Step: 6
Training loss: 0.562458872795105
Validation loss: 2.18222709496816

Epoch: 6| Step: 7
Training loss: 0.35257676243782043
Validation loss: 2.196781317392985

Epoch: 6| Step: 8
Training loss: 0.6433571577072144
Validation loss: 2.189658284187317

Epoch: 6| Step: 9
Training loss: 1.273566722869873
Validation loss: 2.188232700030009

Epoch: 6| Step: 10
Training loss: 0.9768836498260498
Validation loss: 2.1780213912328086

Epoch: 6| Step: 11
Training loss: 1.1318268775939941
Validation loss: 2.1845220724741616

Epoch: 6| Step: 12
Training loss: 1.7335355281829834
Validation loss: 2.184228499730428

Epoch: 6| Step: 13
Training loss: 0.8593300580978394
Validation loss: 2.184609909852346

Epoch: 408| Step: 0
Training loss: 0.7379056215286255
Validation loss: 2.139316658178965

Epoch: 6| Step: 1
Training loss: 0.7125540971755981
Validation loss: 2.145004630088806

Epoch: 6| Step: 2
Training loss: 0.29129475355148315
Validation loss: 2.1424933671951294

Epoch: 6| Step: 3
Training loss: 0.4669303297996521
Validation loss: 2.1340951323509216

Epoch: 6| Step: 4
Training loss: 1.1487030982971191
Validation loss: 2.145425319671631

Epoch: 6| Step: 5
Training loss: 0.7570672035217285
Validation loss: 2.117151955763499

Epoch: 6| Step: 6
Training loss: 0.7094390392303467
Validation loss: 2.1340322295824685

Epoch: 6| Step: 7
Training loss: 1.5336391925811768
Validation loss: 2.1297948757807412

Epoch: 6| Step: 8
Training loss: 0.7238612174987793
Validation loss: 2.1079294681549072

Epoch: 6| Step: 9
Training loss: 0.5915130972862244
Validation loss: 2.1319379607836404

Epoch: 6| Step: 10
Training loss: 0.7225200533866882
Validation loss: 2.1270551284154258

Epoch: 6| Step: 11
Training loss: 1.4155466556549072
Validation loss: 2.112704575061798

Epoch: 6| Step: 12
Training loss: 1.2147295475006104
Validation loss: 2.177301565806071

Epoch: 6| Step: 13
Training loss: 1.0736808776855469
Validation loss: 2.1823356548945108

Epoch: 409| Step: 0
Training loss: 0.835552453994751
Validation loss: 2.165148993333181

Epoch: 6| Step: 1
Training loss: 0.735403299331665
Validation loss: 2.1903823614120483

Epoch: 6| Step: 2
Training loss: 0.7101988196372986
Validation loss: 2.14122466246287

Epoch: 6| Step: 3
Training loss: 0.6648141741752625
Validation loss: 2.1552635431289673

Epoch: 6| Step: 4
Training loss: 1.5762922763824463
Validation loss: 2.163285493850708

Epoch: 6| Step: 5
Training loss: 0.9293553829193115
Validation loss: 2.1681465109189353

Epoch: 6| Step: 6
Training loss: 1.1950864791870117
Validation loss: 2.1777869860331216

Epoch: 6| Step: 7
Training loss: 0.770688533782959
Validation loss: 2.2241044640541077

Epoch: 6| Step: 8
Training loss: 0.5104395151138306
Validation loss: 2.245159864425659

Epoch: 6| Step: 9
Training loss: 0.6625456809997559
Validation loss: 2.2099473079045615

Epoch: 6| Step: 10
Training loss: 0.8438642621040344
Validation loss: 2.2045621077219644

Epoch: 6| Step: 11
Training loss: 0.5801781415939331
Validation loss: 2.193285902341207

Epoch: 6| Step: 12
Training loss: 0.9948435425758362
Validation loss: 2.1696719328562417

Epoch: 6| Step: 13
Training loss: 1.6716530323028564
Validation loss: 2.168512304623922

Epoch: 410| Step: 0
Training loss: 0.8751181960105896
Validation loss: 2.154839018980662

Epoch: 6| Step: 1
Training loss: 0.7721563577651978
Validation loss: 2.1507880489031472

Epoch: 6| Step: 2
Training loss: 1.2594871520996094
Validation loss: 2.186507443586985

Epoch: 6| Step: 3
Training loss: 1.1080081462860107
Validation loss: 2.1753615935643515

Epoch: 6| Step: 4
Training loss: 0.6389260292053223
Validation loss: 2.150957763195038

Epoch: 6| Step: 5
Training loss: 0.7084658741950989
Validation loss: 2.129473169644674

Epoch: 6| Step: 6
Training loss: 0.9791762828826904
Validation loss: 2.1588496963183084

Epoch: 6| Step: 7
Training loss: 0.40098944306373596
Validation loss: 2.1832764744758606

Epoch: 6| Step: 8
Training loss: 0.3668293356895447
Validation loss: 2.1279845237731934

Epoch: 6| Step: 9
Training loss: 0.6868565678596497
Validation loss: 2.172438402970632

Epoch: 6| Step: 10
Training loss: 1.5555047988891602
Validation loss: 2.137815554936727

Epoch: 6| Step: 11
Training loss: 0.37933388352394104
Validation loss: 2.15263561407725

Epoch: 6| Step: 12
Training loss: 0.759082555770874
Validation loss: 2.1480332612991333

Epoch: 6| Step: 13
Training loss: 1.4356772899627686
Validation loss: 2.163286646207174

Epoch: 411| Step: 0
Training loss: 0.9743642210960388
Validation loss: 2.156735817591349

Epoch: 6| Step: 1
Training loss: 0.6398262977600098
Validation loss: 2.166318337122599

Epoch: 6| Step: 2
Training loss: 0.7964041829109192
Validation loss: 2.17136820157369

Epoch: 6| Step: 3
Training loss: 1.0739458799362183
Validation loss: 2.151332894961039

Epoch: 6| Step: 4
Training loss: 0.7840015888214111
Validation loss: 2.173724095026652

Epoch: 6| Step: 5
Training loss: 0.6495828628540039
Validation loss: 2.193549156188965

Epoch: 6| Step: 6
Training loss: 1.7222900390625
Validation loss: 2.137034833431244

Epoch: 6| Step: 7
Training loss: 0.25254979729652405
Validation loss: 2.167355934778849

Epoch: 6| Step: 8
Training loss: 0.9975067377090454
Validation loss: 2.1632102131843567

Epoch: 6| Step: 9
Training loss: 0.5670832395553589
Validation loss: 2.1688509782155356

Epoch: 6| Step: 10
Training loss: 0.905559778213501
Validation loss: 2.156811455885569

Epoch: 6| Step: 11
Training loss: 1.1112995147705078
Validation loss: 2.1650203665097556

Epoch: 6| Step: 12
Training loss: 1.2268184423446655
Validation loss: 2.1616567174593606

Epoch: 6| Step: 13
Training loss: 0.5519216060638428
Validation loss: 2.1695663928985596

Epoch: 412| Step: 0
Training loss: 0.5597370862960815
Validation loss: 2.1583672165870667

Epoch: 6| Step: 1
Training loss: 0.4326797127723694
Validation loss: 2.139423112074534

Epoch: 6| Step: 2
Training loss: 0.6193697452545166
Validation loss: 2.1577672163645425

Epoch: 6| Step: 3
Training loss: 0.9108149409294128
Validation loss: 2.184365709622701

Epoch: 6| Step: 4
Training loss: 1.2861580848693848
Validation loss: 2.168944259484609

Epoch: 6| Step: 5
Training loss: 0.7665154933929443
Validation loss: 2.1666857401529946

Epoch: 6| Step: 6
Training loss: 1.0235004425048828
Validation loss: 2.1612902879714966

Epoch: 6| Step: 7
Training loss: 0.9575545787811279
Validation loss: 2.1570587158203125

Epoch: 6| Step: 8
Training loss: 1.1059362888336182
Validation loss: 2.1556897362073264

Epoch: 6| Step: 9
Training loss: 0.7829420566558838
Validation loss: 2.1672017574310303

Epoch: 6| Step: 10
Training loss: 0.832215428352356
Validation loss: 2.1845985849698386

Epoch: 6| Step: 11
Training loss: 1.067378044128418
Validation loss: 2.1157520612080893

Epoch: 6| Step: 12
Training loss: 0.8952463865280151
Validation loss: 2.1568077206611633

Epoch: 6| Step: 13
Training loss: 0.8029839396476746
Validation loss: 2.1673530538876853

Epoch: 413| Step: 0
Training loss: 1.8421564102172852
Validation loss: 2.1767828861872354

Epoch: 6| Step: 1
Training loss: 0.4669134020805359
Validation loss: 2.1902214090029397

Epoch: 6| Step: 2
Training loss: 0.5241265892982483
Validation loss: 2.1644843419392905

Epoch: 6| Step: 3
Training loss: 0.8397554755210876
Validation loss: 2.1766732136408486

Epoch: 6| Step: 4
Training loss: 0.7845948338508606
Validation loss: 2.1405040423075357

Epoch: 6| Step: 5
Training loss: 0.6510145664215088
Validation loss: 2.153346757094065

Epoch: 6| Step: 6
Training loss: 1.1245949268341064
Validation loss: 2.170980175336202

Epoch: 6| Step: 7
Training loss: 0.895445704460144
Validation loss: 2.145530879497528

Epoch: 6| Step: 8
Training loss: 0.7250380516052246
Validation loss: 2.1521818041801453

Epoch: 6| Step: 9
Training loss: 1.2836289405822754
Validation loss: 2.1542417208353677

Epoch: 6| Step: 10
Training loss: 0.44635021686553955
Validation loss: 2.1722922325134277

Epoch: 6| Step: 11
Training loss: 0.6119251251220703
Validation loss: 2.2093346317609153

Epoch: 6| Step: 12
Training loss: 0.7063719034194946
Validation loss: 2.1762276689211526

Epoch: 6| Step: 13
Training loss: 0.8699106574058533
Validation loss: 2.192850887775421

Epoch: 414| Step: 0
Training loss: 0.37038594484329224
Validation loss: 2.1661792198816934

Epoch: 6| Step: 1
Training loss: 1.2269511222839355
Validation loss: 2.185101588567098

Epoch: 6| Step: 2
Training loss: 1.0542658567428589
Validation loss: 2.1618496775627136

Epoch: 6| Step: 3
Training loss: 1.0582051277160645
Validation loss: 2.1833637754122415

Epoch: 6| Step: 4
Training loss: 0.7437150478363037
Validation loss: 2.176971177260081

Epoch: 6| Step: 5
Training loss: 0.9221463203430176
Validation loss: 2.1775588989257812

Epoch: 6| Step: 6
Training loss: 0.9242161512374878
Validation loss: 2.204405506451925

Epoch: 6| Step: 7
Training loss: 1.6746654510498047
Validation loss: 2.2141761581103006

Epoch: 6| Step: 8
Training loss: 0.5187709331512451
Validation loss: 2.2419692476590476

Epoch: 6| Step: 9
Training loss: 0.7509623765945435
Validation loss: 2.260321537653605

Epoch: 6| Step: 10
Training loss: 0.8354644775390625
Validation loss: 2.1678744157155356

Epoch: 6| Step: 11
Training loss: 0.9052570462226868
Validation loss: 2.2134915788968406

Epoch: 6| Step: 12
Training loss: 0.47199589014053345
Validation loss: 2.226763387521108

Epoch: 6| Step: 13
Training loss: 0.6860243082046509
Validation loss: 2.171844800313314

Epoch: 415| Step: 0
Training loss: 0.9046498537063599
Validation loss: 2.19441548983256

Epoch: 6| Step: 1
Training loss: 1.0158352851867676
Validation loss: 2.1365245580673218

Epoch: 6| Step: 2
Training loss: 1.2658663988113403
Validation loss: 2.1813422044118247

Epoch: 6| Step: 3
Training loss: 0.6774828433990479
Validation loss: 2.182835896809896

Epoch: 6| Step: 4
Training loss: 0.7574272155761719
Validation loss: 2.1626853346824646

Epoch: 6| Step: 5
Training loss: 1.7596707344055176
Validation loss: 2.1858193079630532

Epoch: 6| Step: 6
Training loss: 0.7753356099128723
Validation loss: 2.149555961290995

Epoch: 6| Step: 7
Training loss: 0.956376314163208
Validation loss: 2.1632477045059204

Epoch: 6| Step: 8
Training loss: 0.4298979640007019
Validation loss: 2.148797253767649

Epoch: 6| Step: 9
Training loss: 0.49675798416137695
Validation loss: 2.21118954817454

Epoch: 6| Step: 10
Training loss: 1.227079153060913
Validation loss: 2.1861873467763266

Epoch: 6| Step: 11
Training loss: 0.4957183599472046
Validation loss: 2.183519879976908

Epoch: 6| Step: 12
Training loss: 0.4024832844734192
Validation loss: 2.21450545390447

Epoch: 6| Step: 13
Training loss: 0.7629928588867188
Validation loss: 2.1855885982513428

Epoch: 416| Step: 0
Training loss: 1.0560836791992188
Validation loss: 2.1835328737894693

Epoch: 6| Step: 1
Training loss: 0.8872557878494263
Validation loss: 2.2222017844518027

Epoch: 6| Step: 2
Training loss: 0.729215681552887
Validation loss: 2.1764365633328757

Epoch: 6| Step: 3
Training loss: 0.5241265296936035
Validation loss: 2.1887576580047607

Epoch: 6| Step: 4
Training loss: 0.5578938722610474
Validation loss: 2.2030463020006814

Epoch: 6| Step: 5
Training loss: 0.8198180198669434
Validation loss: 2.17873881260554

Epoch: 6| Step: 6
Training loss: 0.8811478614807129
Validation loss: 2.1871582865715027

Epoch: 6| Step: 7
Training loss: 0.9778243899345398
Validation loss: 2.2075675328572593

Epoch: 6| Step: 8
Training loss: 1.4956457614898682
Validation loss: 2.203034540017446

Epoch: 6| Step: 9
Training loss: 0.7119218111038208
Validation loss: 2.1938959757486978

Epoch: 6| Step: 10
Training loss: 0.9001098275184631
Validation loss: 2.1807890931765237

Epoch: 6| Step: 11
Training loss: 0.49729132652282715
Validation loss: 2.180166780948639

Epoch: 6| Step: 12
Training loss: 0.9138185381889343
Validation loss: 2.1968414783477783

Epoch: 6| Step: 13
Training loss: 0.7772939205169678
Validation loss: 2.2100220918655396

Epoch: 417| Step: 0
Training loss: 0.8673244714736938
Validation loss: 2.153229574362437

Epoch: 6| Step: 1
Training loss: 1.2568925619125366
Validation loss: 2.176823616027832

Epoch: 6| Step: 2
Training loss: 0.6961396336555481
Validation loss: 2.164291203022003

Epoch: 6| Step: 3
Training loss: 0.8763760924339294
Validation loss: 2.1915931502978006

Epoch: 6| Step: 4
Training loss: 0.7422688007354736
Validation loss: 2.1569499174753823

Epoch: 6| Step: 5
Training loss: 0.4627209007740021
Validation loss: 2.190460979938507

Epoch: 6| Step: 6
Training loss: 0.9812841415405273
Validation loss: 2.186635692914327

Epoch: 6| Step: 7
Training loss: 1.6530165672302246
Validation loss: 2.182718793551127

Epoch: 6| Step: 8
Training loss: 0.6657642126083374
Validation loss: 2.1609635949134827

Epoch: 6| Step: 9
Training loss: 0.3632463812828064
Validation loss: 2.162211755911509

Epoch: 6| Step: 10
Training loss: 0.3642314672470093
Validation loss: 2.173931141694387

Epoch: 6| Step: 11
Training loss: 0.993100106716156
Validation loss: 2.17336642742157

Epoch: 6| Step: 12
Training loss: 0.8891458511352539
Validation loss: 2.2235196034113565

Epoch: 6| Step: 13
Training loss: 0.5047314763069153
Validation loss: 2.2196274399757385

Epoch: 418| Step: 0
Training loss: 0.5225924849510193
Validation loss: 2.2406259377797446

Epoch: 6| Step: 1
Training loss: 0.8558955192565918
Validation loss: 2.2037161191304526

Epoch: 6| Step: 2
Training loss: 0.8001630306243896
Validation loss: 2.2139111359914145

Epoch: 6| Step: 3
Training loss: 1.5685313940048218
Validation loss: 2.2090667287508645

Epoch: 6| Step: 4
Training loss: 0.8023129105567932
Validation loss: 2.2288891871770224

Epoch: 6| Step: 5
Training loss: 0.7265427112579346
Validation loss: 2.218788822491964

Epoch: 6| Step: 6
Training loss: 1.0680921077728271
Validation loss: 2.2043643395105996

Epoch: 6| Step: 7
Training loss: 1.2003343105316162
Validation loss: 2.1877275904019675

Epoch: 6| Step: 8
Training loss: 0.6922265887260437
Validation loss: 2.171288092931112

Epoch: 6| Step: 9
Training loss: 0.6735477447509766
Validation loss: 2.183165192604065

Epoch: 6| Step: 10
Training loss: 0.9801608324050903
Validation loss: 2.1639559864997864

Epoch: 6| Step: 11
Training loss: 1.356363296508789
Validation loss: 2.185709277788798

Epoch: 6| Step: 12
Training loss: 0.6432932615280151
Validation loss: 2.1762333114941916

Epoch: 6| Step: 13
Training loss: 0.49176129698753357
Validation loss: 2.1873637636502585

Epoch: 419| Step: 0
Training loss: 0.6765894889831543
Validation loss: 2.159921129544576

Epoch: 6| Step: 1
Training loss: 0.49393144249916077
Validation loss: 2.1830021142959595

Epoch: 6| Step: 2
Training loss: 0.889289379119873
Validation loss: 2.2015949885050454

Epoch: 6| Step: 3
Training loss: 0.8083134889602661
Validation loss: 2.1773529847462973

Epoch: 6| Step: 4
Training loss: 0.65711909532547
Validation loss: 2.1921063661575317

Epoch: 6| Step: 5
Training loss: 1.052957534790039
Validation loss: 2.1507375240325928

Epoch: 6| Step: 6
Training loss: 0.751177966594696
Validation loss: 2.216110269228617

Epoch: 6| Step: 7
Training loss: 0.6068482398986816
Validation loss: 2.222880005836487

Epoch: 6| Step: 8
Training loss: 0.7728665471076965
Validation loss: 2.15690815448761

Epoch: 6| Step: 9
Training loss: 0.9357115030288696
Validation loss: 2.1504224936167398

Epoch: 6| Step: 10
Training loss: 1.393747091293335
Validation loss: 2.147414048512777

Epoch: 6| Step: 11
Training loss: 0.8416724801063538
Validation loss: 2.1610355575879416

Epoch: 6| Step: 12
Training loss: 0.7671254873275757
Validation loss: 2.1473714311917624

Epoch: 6| Step: 13
Training loss: 0.9239170551300049
Validation loss: 2.1395944555600486

Epoch: 420| Step: 0
Training loss: 1.0265114307403564
Validation loss: 2.127479314804077

Epoch: 6| Step: 1
Training loss: 0.8832437992095947
Validation loss: 2.155827005704244

Epoch: 6| Step: 2
Training loss: 0.6718189716339111
Validation loss: 2.1398932337760925

Epoch: 6| Step: 3
Training loss: 0.7467972636222839
Validation loss: 2.1524783968925476

Epoch: 6| Step: 4
Training loss: 0.8415607213973999
Validation loss: 2.174645721912384

Epoch: 6| Step: 5
Training loss: 0.6395912170410156
Validation loss: 2.161810557047526

Epoch: 6| Step: 6
Training loss: 0.5766702890396118
Validation loss: 2.1883094906806946

Epoch: 6| Step: 7
Training loss: 0.8022518157958984
Validation loss: 2.1438479820887246

Epoch: 6| Step: 8
Training loss: 0.5896165370941162
Validation loss: 2.188037355740865

Epoch: 6| Step: 9
Training loss: 1.0213254690170288
Validation loss: 2.185185194015503

Epoch: 6| Step: 10
Training loss: 0.4389566481113434
Validation loss: 2.1156585216522217

Epoch: 6| Step: 11
Training loss: 1.1981465816497803
Validation loss: 2.156873106956482

Epoch: 6| Step: 12
Training loss: 1.0961601734161377
Validation loss: 2.1748306353886924

Epoch: 6| Step: 13
Training loss: 1.0406171083450317
Validation loss: 2.2114681005477905

Epoch: 421| Step: 0
Training loss: 0.7395962476730347
Validation loss: 2.1506901184717813

Epoch: 6| Step: 1
Training loss: 0.7982307076454163
Validation loss: 2.19940048456192

Epoch: 6| Step: 2
Training loss: 0.9643397927284241
Validation loss: 2.224462072054545

Epoch: 6| Step: 3
Training loss: 0.5001808404922485
Validation loss: 2.2242398659388223

Epoch: 6| Step: 4
Training loss: 1.291971206665039
Validation loss: 2.206848164399465

Epoch: 6| Step: 5
Training loss: 0.5526228547096252
Validation loss: 2.19588041305542

Epoch: 6| Step: 6
Training loss: 0.31434592604637146
Validation loss: 2.196418066819509

Epoch: 6| Step: 7
Training loss: 0.9773403406143188
Validation loss: 2.1584527691205344

Epoch: 6| Step: 8
Training loss: 0.5573013424873352
Validation loss: 2.1655438343683877

Epoch: 6| Step: 9
Training loss: 0.9621800184249878
Validation loss: 2.169084390004476

Epoch: 6| Step: 10
Training loss: 1.267551302909851
Validation loss: 2.1482272346814475

Epoch: 6| Step: 11
Training loss: 0.737337589263916
Validation loss: 2.148270388444265

Epoch: 6| Step: 12
Training loss: 1.1049325466156006
Validation loss: 2.1812756856282554

Epoch: 6| Step: 13
Training loss: 0.734225869178772
Validation loss: 2.1984803676605225

Epoch: 422| Step: 0
Training loss: 0.6449910402297974
Validation loss: 2.1728682120641074

Epoch: 6| Step: 1
Training loss: 1.2259480953216553
Validation loss: 2.186387777328491

Epoch: 6| Step: 2
Training loss: 0.638923168182373
Validation loss: 2.172106663386027

Epoch: 6| Step: 3
Training loss: 0.5951500535011292
Validation loss: 2.190644145011902

Epoch: 6| Step: 4
Training loss: 1.2802152633666992
Validation loss: 2.1526103218396506

Epoch: 6| Step: 5
Training loss: 0.7913953065872192
Validation loss: 2.168904463450114

Epoch: 6| Step: 6
Training loss: 1.251227617263794
Validation loss: 2.1601668198903403

Epoch: 6| Step: 7
Training loss: 1.2265489101409912
Validation loss: 2.1678198178609214

Epoch: 6| Step: 8
Training loss: 0.7397534847259521
Validation loss: 2.161764403184255

Epoch: 6| Step: 9
Training loss: 0.5972859859466553
Validation loss: 2.1506433884302774

Epoch: 6| Step: 10
Training loss: 0.6887606382369995
Validation loss: 2.1727007826169333

Epoch: 6| Step: 11
Training loss: 0.7048126459121704
Validation loss: 2.1940327088038125

Epoch: 6| Step: 12
Training loss: 0.6298152208328247
Validation loss: 2.188108762105306

Epoch: 6| Step: 13
Training loss: 0.591557502746582
Validation loss: 2.190665344397227

Epoch: 423| Step: 0
Training loss: 0.30936986207962036
Validation loss: 2.148683408896128

Epoch: 6| Step: 1
Training loss: 0.8079185485839844
Validation loss: 2.150319437185923

Epoch: 6| Step: 2
Training loss: 0.3602139949798584
Validation loss: 2.175631562868754

Epoch: 6| Step: 3
Training loss: 0.6692246198654175
Validation loss: 2.164856513341268

Epoch: 6| Step: 4
Training loss: 0.4535852074623108
Validation loss: 2.1654372413953147

Epoch: 6| Step: 5
Training loss: 0.5487101078033447
Validation loss: 2.157219092051188

Epoch: 6| Step: 6
Training loss: 0.5957238674163818
Validation loss: 2.1415082613627114

Epoch: 6| Step: 7
Training loss: 1.0509079694747925
Validation loss: 2.136362592379252

Epoch: 6| Step: 8
Training loss: 1.5812935829162598
Validation loss: 2.149052679538727

Epoch: 6| Step: 9
Training loss: 1.4674822092056274
Validation loss: 2.156650940577189

Epoch: 6| Step: 10
Training loss: 1.0854744911193848
Validation loss: 2.11444224913915

Epoch: 6| Step: 11
Training loss: 1.2385547161102295
Validation loss: 2.158704916636149

Epoch: 6| Step: 12
Training loss: 0.49228647351264954
Validation loss: 2.153718034426371

Epoch: 6| Step: 13
Training loss: 0.8556526303291321
Validation loss: 2.147507965564728

Epoch: 424| Step: 0
Training loss: 0.748620867729187
Validation loss: 2.156512220700582

Epoch: 6| Step: 1
Training loss: 0.9780409932136536
Validation loss: 2.1305853525797525

Epoch: 6| Step: 2
Training loss: 0.7292956113815308
Validation loss: 2.130334436893463

Epoch: 6| Step: 3
Training loss: 0.9722983837127686
Validation loss: 2.1263224681218467

Epoch: 6| Step: 4
Training loss: 1.1007015705108643
Validation loss: 2.1662587324778237

Epoch: 6| Step: 5
Training loss: 0.7013815641403198
Validation loss: 2.188290059566498

Epoch: 6| Step: 6
Training loss: 0.8835217356681824
Validation loss: 2.147326091925303

Epoch: 6| Step: 7
Training loss: 0.9944989085197449
Validation loss: 2.183705449104309

Epoch: 6| Step: 8
Training loss: 0.6058906316757202
Validation loss: 2.1543478767077127

Epoch: 6| Step: 9
Training loss: 0.5686076283454895
Validation loss: 2.2030113538106284

Epoch: 6| Step: 10
Training loss: 0.8674709796905518
Validation loss: 2.1934115091959634

Epoch: 6| Step: 11
Training loss: 0.5872347354888916
Validation loss: 2.1978540817896524

Epoch: 6| Step: 12
Training loss: 0.44220495223999023
Validation loss: 2.212094267209371

Epoch: 6| Step: 13
Training loss: 1.4213333129882812
Validation loss: 2.1756475965181985

Epoch: 425| Step: 0
Training loss: 0.9909632802009583
Validation loss: 2.1780331134796143

Epoch: 6| Step: 1
Training loss: 0.5367736220359802
Validation loss: 2.176475465297699

Epoch: 6| Step: 2
Training loss: 0.48118138313293457
Validation loss: 2.1878718932469687

Epoch: 6| Step: 3
Training loss: 0.45446667075157166
Validation loss: 2.1608158349990845

Epoch: 6| Step: 4
Training loss: 1.4181840419769287
Validation loss: 2.17114919424057

Epoch: 6| Step: 5
Training loss: 1.0134936571121216
Validation loss: 2.1537113785743713

Epoch: 6| Step: 6
Training loss: 0.43601346015930176
Validation loss: 2.1371397972106934

Epoch: 6| Step: 7
Training loss: 1.064515471458435
Validation loss: 2.1415282090504966

Epoch: 6| Step: 8
Training loss: 0.8175168633460999
Validation loss: 2.21235462029775

Epoch: 6| Step: 9
Training loss: 0.9003653526306152
Validation loss: 2.205767730871836

Epoch: 6| Step: 10
Training loss: 0.9631602764129639
Validation loss: 2.1682128508885703

Epoch: 6| Step: 11
Training loss: 0.6260198950767517
Validation loss: 2.181928197542826

Epoch: 6| Step: 12
Training loss: 0.7855720520019531
Validation loss: 2.233879824479421

Epoch: 6| Step: 13
Training loss: 0.848821759223938
Validation loss: 2.174459457397461

Epoch: 426| Step: 0
Training loss: 0.9489222764968872
Validation loss: 2.163583517074585

Epoch: 6| Step: 1
Training loss: 0.6340049505233765
Validation loss: 2.1673446695009866

Epoch: 6| Step: 2
Training loss: 0.7939683198928833
Validation loss: 2.1551672418912253

Epoch: 6| Step: 3
Training loss: 1.0505313873291016
Validation loss: 2.163163503011068

Epoch: 6| Step: 4
Training loss: 0.7087706923484802
Validation loss: 2.1557098627090454

Epoch: 6| Step: 5
Training loss: 0.8513659238815308
Validation loss: 2.190309524536133

Epoch: 6| Step: 6
Training loss: 0.6003777980804443
Validation loss: 2.1339041193326316

Epoch: 6| Step: 7
Training loss: 1.127730369567871
Validation loss: 2.138561765352885

Epoch: 6| Step: 8
Training loss: 0.7188200354576111
Validation loss: 2.158683160940806

Epoch: 6| Step: 9
Training loss: 0.4930589199066162
Validation loss: 2.1553472876548767

Epoch: 6| Step: 10
Training loss: 0.5595258474349976
Validation loss: 2.1454322735468545

Epoch: 6| Step: 11
Training loss: 1.0796806812286377
Validation loss: 2.146777629852295

Epoch: 6| Step: 12
Training loss: 0.5193115472793579
Validation loss: 2.1569573481877646

Epoch: 6| Step: 13
Training loss: 1.3049798011779785
Validation loss: 2.1236600279808044

Epoch: 427| Step: 0
Training loss: 1.0919132232666016
Validation loss: 2.175979574521383

Epoch: 6| Step: 1
Training loss: 0.615607500076294
Validation loss: 2.149598697821299

Epoch: 6| Step: 2
Training loss: 0.5000925660133362
Validation loss: 2.1679245034853616

Epoch: 6| Step: 3
Training loss: 0.5014907121658325
Validation loss: 2.1472124059995017

Epoch: 6| Step: 4
Training loss: 1.206756591796875
Validation loss: 2.1851271390914917

Epoch: 6| Step: 5
Training loss: 0.5949573516845703
Validation loss: 2.179797410964966

Epoch: 6| Step: 6
Training loss: 0.6654541492462158
Validation loss: 2.173851251602173

Epoch: 6| Step: 7
Training loss: 0.7428019046783447
Validation loss: 2.189484159151713

Epoch: 6| Step: 8
Training loss: 0.44921261072158813
Validation loss: 2.1823126673698425

Epoch: 6| Step: 9
Training loss: 1.1141161918640137
Validation loss: 2.198444346586863

Epoch: 6| Step: 10
Training loss: 1.3601782321929932
Validation loss: 2.1842983961105347

Epoch: 6| Step: 11
Training loss: 0.5190335512161255
Validation loss: 2.179784099260966

Epoch: 6| Step: 12
Training loss: 0.9334204196929932
Validation loss: 2.1790305773417153

Epoch: 6| Step: 13
Training loss: 0.9907536506652832
Validation loss: 2.1849833726882935

Epoch: 428| Step: 0
Training loss: 0.5228060483932495
Validation loss: 2.1847713192303977

Epoch: 6| Step: 1
Training loss: 0.7428727149963379
Validation loss: 2.179489036401113

Epoch: 6| Step: 2
Training loss: 0.19670136272907257
Validation loss: 2.2140321135520935

Epoch: 6| Step: 3
Training loss: 1.036402702331543
Validation loss: 2.2421866257985434

Epoch: 6| Step: 4
Training loss: 0.6155757904052734
Validation loss: 2.1773403882980347

Epoch: 6| Step: 5
Training loss: 0.7068645358085632
Validation loss: 2.2037033240000405

Epoch: 6| Step: 6
Training loss: 1.4178345203399658
Validation loss: 2.1844658255577087

Epoch: 6| Step: 7
Training loss: 0.8291652202606201
Validation loss: 2.137092570463816

Epoch: 6| Step: 8
Training loss: 0.8021152019500732
Validation loss: 2.1441384752591452

Epoch: 6| Step: 9
Training loss: 1.7791800498962402
Validation loss: 2.159220894177755

Epoch: 6| Step: 10
Training loss: 0.8099030256271362
Validation loss: 2.122231682141622

Epoch: 6| Step: 11
Training loss: 0.7384535670280457
Validation loss: 2.138441562652588

Epoch: 6| Step: 12
Training loss: 0.47082018852233887
Validation loss: 2.1490759452184043

Epoch: 6| Step: 13
Training loss: 0.6109879016876221
Validation loss: 2.1375883420308432

Epoch: 429| Step: 0
Training loss: 0.22529640793800354
Validation loss: 2.1680146853129068

Epoch: 6| Step: 1
Training loss: 0.9579192996025085
Validation loss: 2.147475759188334

Epoch: 6| Step: 2
Training loss: 0.685522198677063
Validation loss: 2.126756489276886

Epoch: 6| Step: 3
Training loss: 1.0795297622680664
Validation loss: 2.16249148050944

Epoch: 6| Step: 4
Training loss: 0.22356200218200684
Validation loss: 2.1512522300084433

Epoch: 6| Step: 5
Training loss: 0.8671395778656006
Validation loss: 2.168928325176239

Epoch: 6| Step: 6
Training loss: 0.5135995745658875
Validation loss: 2.232382655143738

Epoch: 6| Step: 7
Training loss: 1.8808962106704712
Validation loss: 2.250657538572947

Epoch: 6| Step: 8
Training loss: 0.8584073781967163
Validation loss: 2.2363357543945312

Epoch: 6| Step: 9
Training loss: 0.6438405513763428
Validation loss: 2.200204908847809

Epoch: 6| Step: 10
Training loss: 0.7804351449012756
Validation loss: 2.2499717275301614

Epoch: 6| Step: 11
Training loss: 1.0131593942642212
Validation loss: 2.2377607425053916

Epoch: 6| Step: 12
Training loss: 0.8781010508537292
Validation loss: 2.2448771397272744

Epoch: 6| Step: 13
Training loss: 0.6544888615608215
Validation loss: 2.2109256982803345

Epoch: 430| Step: 0
Training loss: 0.5580962896347046
Validation loss: 2.176603396733602

Epoch: 6| Step: 1
Training loss: 0.558387279510498
Validation loss: 2.202852427959442

Epoch: 6| Step: 2
Training loss: 0.44857701659202576
Validation loss: 2.1832938194274902

Epoch: 6| Step: 3
Training loss: 0.6193181276321411
Validation loss: 2.172904074192047

Epoch: 6| Step: 4
Training loss: 0.8780118227005005
Validation loss: 2.1810507575670877

Epoch: 6| Step: 5
Training loss: 0.7301318645477295
Validation loss: 2.167608062426249

Epoch: 6| Step: 6
Training loss: 0.8357022404670715
Validation loss: 2.1906935771306357

Epoch: 6| Step: 7
Training loss: 0.9833675622940063
Validation loss: 2.180242041746775

Epoch: 6| Step: 8
Training loss: 0.5894957184791565
Validation loss: 2.1700514554977417

Epoch: 6| Step: 9
Training loss: 0.8845288753509521
Validation loss: 2.1859745581944785

Epoch: 6| Step: 10
Training loss: 1.2509422302246094
Validation loss: 2.192329446474711

Epoch: 6| Step: 11
Training loss: 0.7583591938018799
Validation loss: 2.165348211924235

Epoch: 6| Step: 12
Training loss: 1.2029249668121338
Validation loss: 2.1901500821113586

Epoch: 6| Step: 13
Training loss: 0.9521210193634033
Validation loss: 2.168374478816986

Epoch: 431| Step: 0
Training loss: 0.7828092575073242
Validation loss: 2.174913545449575

Epoch: 6| Step: 1
Training loss: 0.9923123121261597
Validation loss: 2.195974071820577

Epoch: 6| Step: 2
Training loss: 0.744255542755127
Validation loss: 2.233373443285624

Epoch: 6| Step: 3
Training loss: 0.6717939376831055
Validation loss: 2.1856987476348877

Epoch: 6| Step: 4
Training loss: 1.2750272750854492
Validation loss: 2.175858954588572

Epoch: 6| Step: 5
Training loss: 0.6248159408569336
Validation loss: 2.1739922960599265

Epoch: 6| Step: 6
Training loss: 0.5573408603668213
Validation loss: 2.199650287628174

Epoch: 6| Step: 7
Training loss: 0.42572587728500366
Validation loss: 2.1719767252604165

Epoch: 6| Step: 8
Training loss: 0.6029966473579407
Validation loss: 2.196304221947988

Epoch: 6| Step: 9
Training loss: 0.7645004987716675
Validation loss: 2.1703775922457376

Epoch: 6| Step: 10
Training loss: 0.9159619808197021
Validation loss: 2.1737659772237143

Epoch: 6| Step: 11
Training loss: 1.244807243347168
Validation loss: 2.162460466225942

Epoch: 6| Step: 12
Training loss: 0.7043249011039734
Validation loss: 2.2119949658711753

Epoch: 6| Step: 13
Training loss: 0.9554809331893921
Validation loss: 2.1947067975997925

Epoch: 432| Step: 0
Training loss: 0.8151183724403381
Validation loss: 2.220670739809672

Epoch: 6| Step: 1
Training loss: 0.4577863812446594
Validation loss: 2.160273631413778

Epoch: 6| Step: 2
Training loss: 1.0031037330627441
Validation loss: 2.144774595896403

Epoch: 6| Step: 3
Training loss: 0.8003746271133423
Validation loss: 2.1568950017293296

Epoch: 6| Step: 4
Training loss: 0.7286657094955444
Validation loss: 2.1580822269121804

Epoch: 6| Step: 5
Training loss: 1.0871965885162354
Validation loss: 2.1606337825457254

Epoch: 6| Step: 6
Training loss: 1.0696706771850586
Validation loss: 2.151605486869812

Epoch: 6| Step: 7
Training loss: 0.6682669520378113
Validation loss: 2.1328362623850503

Epoch: 6| Step: 8
Training loss: 0.6545862555503845
Validation loss: 2.1696396271387735

Epoch: 6| Step: 9
Training loss: 0.3954940438270569
Validation loss: 2.1606277028719583

Epoch: 6| Step: 10
Training loss: 0.8213775157928467
Validation loss: 2.1602773666381836

Epoch: 6| Step: 11
Training loss: 1.3010326623916626
Validation loss: 2.149361034234365

Epoch: 6| Step: 12
Training loss: 0.28427228331565857
Validation loss: 2.175636132558187

Epoch: 6| Step: 13
Training loss: 1.1042487621307373
Validation loss: 2.164566973845164

Epoch: 433| Step: 0
Training loss: 0.7947521209716797
Validation loss: 2.157383223374685

Epoch: 6| Step: 1
Training loss: 1.2091343402862549
Validation loss: 2.148749311765035

Epoch: 6| Step: 2
Training loss: 0.7139856815338135
Validation loss: 2.1218378941218057

Epoch: 6| Step: 3
Training loss: 1.4342091083526611
Validation loss: 2.16016415754954

Epoch: 6| Step: 4
Training loss: 0.6897228956222534
Validation loss: 2.1222704648971558

Epoch: 6| Step: 5
Training loss: 0.58196622133255
Validation loss: 2.11067787806193

Epoch: 6| Step: 6
Training loss: 0.5992773175239563
Validation loss: 2.117750962575277

Epoch: 6| Step: 7
Training loss: 0.9455579519271851
Validation loss: 2.139937996864319

Epoch: 6| Step: 8
Training loss: 0.7157216668128967
Validation loss: 2.13928751150767

Epoch: 6| Step: 9
Training loss: 0.7376617193222046
Validation loss: 2.1092167695363364

Epoch: 6| Step: 10
Training loss: 0.9615708589553833
Validation loss: 2.1455732583999634

Epoch: 6| Step: 11
Training loss: 0.41724693775177
Validation loss: 2.1382373174031577

Epoch: 6| Step: 12
Training loss: 0.2598586082458496
Validation loss: 2.1776009996732077

Epoch: 6| Step: 13
Training loss: 0.9200200438499451
Validation loss: 2.2057812412579856

Epoch: 434| Step: 0
Training loss: 0.3030295670032501
Validation loss: 2.212437868118286

Epoch: 6| Step: 1
Training loss: 0.9060655832290649
Validation loss: 2.2168907721837363

Epoch: 6| Step: 2
Training loss: 1.0381405353546143
Validation loss: 2.1938260793685913

Epoch: 6| Step: 3
Training loss: 0.8672671318054199
Validation loss: 2.2245516180992126

Epoch: 6| Step: 4
Training loss: 0.3810376822948456
Validation loss: 2.1962472995122275

Epoch: 6| Step: 5
Training loss: 0.5654128789901733
Validation loss: 2.1838130950927734

Epoch: 6| Step: 6
Training loss: 1.2207975387573242
Validation loss: 2.1545810302098594

Epoch: 6| Step: 7
Training loss: 0.6390337944030762
Validation loss: 2.170013129711151

Epoch: 6| Step: 8
Training loss: 0.6804750561714172
Validation loss: 2.1499554912249246

Epoch: 6| Step: 9
Training loss: 0.5565148591995239
Validation loss: 2.190779169400533

Epoch: 6| Step: 10
Training loss: 0.4925178289413452
Validation loss: 2.190495014190674

Epoch: 6| Step: 11
Training loss: 0.9507184028625488
Validation loss: 2.208872636159261

Epoch: 6| Step: 12
Training loss: 0.6693341732025146
Validation loss: 2.190610965092977

Epoch: 6| Step: 13
Training loss: 1.2093514204025269
Validation loss: 2.223055084546407

Epoch: 435| Step: 0
Training loss: 0.6808487176895142
Validation loss: 2.2250206073125205

Epoch: 6| Step: 1
Training loss: 0.7828578948974609
Validation loss: 2.2273000677426658

Epoch: 6| Step: 2
Training loss: 0.45669740438461304
Validation loss: 2.1966982881228128

Epoch: 6| Step: 3
Training loss: 0.5180298089981079
Validation loss: 2.2296398282051086

Epoch: 6| Step: 4
Training loss: 0.6800036430358887
Validation loss: 2.2478572130203247

Epoch: 6| Step: 5
Training loss: 1.1240516901016235
Validation loss: 2.2292823791503906

Epoch: 6| Step: 6
Training loss: 0.7289981842041016
Validation loss: 2.211412270863851

Epoch: 6| Step: 7
Training loss: 0.8873517513275146
Validation loss: 2.171076695124308

Epoch: 6| Step: 8
Training loss: 0.3739207983016968
Validation loss: 2.1850129763285318

Epoch: 6| Step: 9
Training loss: 0.8840901851654053
Validation loss: 2.1275171041488647

Epoch: 6| Step: 10
Training loss: 1.0715999603271484
Validation loss: 2.136141320069631

Epoch: 6| Step: 11
Training loss: 0.8352181911468506
Validation loss: 2.154449144999186

Epoch: 6| Step: 12
Training loss: 0.989447832107544
Validation loss: 2.1902042229970298

Epoch: 6| Step: 13
Training loss: 0.799474835395813
Validation loss: 2.1667038599650064

Epoch: 436| Step: 0
Training loss: 1.086092233657837
Validation loss: 2.175346851348877

Epoch: 6| Step: 1
Training loss: 1.1151623725891113
Validation loss: 2.179978529612223

Epoch: 6| Step: 2
Training loss: 0.4969194233417511
Validation loss: 2.158091406027476

Epoch: 6| Step: 3
Training loss: 0.9110251665115356
Validation loss: 2.1643210450808206

Epoch: 6| Step: 4
Training loss: 1.0289911031723022
Validation loss: 2.190046191215515

Epoch: 6| Step: 5
Training loss: 0.9088956117630005
Validation loss: 2.1762389143308005

Epoch: 6| Step: 6
Training loss: 0.43835747241973877
Validation loss: 2.200528105099996

Epoch: 6| Step: 7
Training loss: 0.8375039100646973
Validation loss: 2.2027028799057007

Epoch: 6| Step: 8
Training loss: 0.44077301025390625
Validation loss: 2.1627509792645774

Epoch: 6| Step: 9
Training loss: 0.58141028881073
Validation loss: 2.1551772157351174

Epoch: 6| Step: 10
Training loss: 0.8893077373504639
Validation loss: 2.142868081728617

Epoch: 6| Step: 11
Training loss: 0.8962478637695312
Validation loss: 2.1458351016044617

Epoch: 6| Step: 12
Training loss: 0.5328203439712524
Validation loss: 2.133277873198191

Epoch: 6| Step: 13
Training loss: 0.9236794114112854
Validation loss: 2.1478991309801736

Epoch: 437| Step: 0
Training loss: 0.635705292224884
Validation loss: 2.126143475373586

Epoch: 6| Step: 1
Training loss: 0.8543257713317871
Validation loss: 2.1078368028004966

Epoch: 6| Step: 2
Training loss: 1.706828236579895
Validation loss: 2.123310367266337

Epoch: 6| Step: 3
Training loss: 0.4088590443134308
Validation loss: 2.1246736447016397

Epoch: 6| Step: 4
Training loss: 0.7962996363639832
Validation loss: 2.1169697841008506

Epoch: 6| Step: 5
Training loss: 0.9683935046195984
Validation loss: 2.1514742374420166

Epoch: 6| Step: 6
Training loss: 0.7126092314720154
Validation loss: 2.128375550111135

Epoch: 6| Step: 7
Training loss: 1.1639093160629272
Validation loss: 2.14464678366979

Epoch: 6| Step: 8
Training loss: 0.7224686145782471
Validation loss: 2.1378978888193765

Epoch: 6| Step: 9
Training loss: 0.5571393966674805
Validation loss: 2.142155031363169

Epoch: 6| Step: 10
Training loss: 0.5187650322914124
Validation loss: 2.1477823654810586

Epoch: 6| Step: 11
Training loss: 1.1656014919281006
Validation loss: 2.1257625619570413

Epoch: 6| Step: 12
Training loss: 0.5139564275741577
Validation loss: 2.162280321121216

Epoch: 6| Step: 13
Training loss: 0.8757367134094238
Validation loss: 2.16932213306427

Epoch: 438| Step: 0
Training loss: 1.3087635040283203
Validation loss: 2.17084793249766

Epoch: 6| Step: 1
Training loss: 0.5855509638786316
Validation loss: 2.1815314491589866

Epoch: 6| Step: 2
Training loss: 0.500791072845459
Validation loss: 2.15856542189916

Epoch: 6| Step: 3
Training loss: 0.8471063375473022
Validation loss: 2.168775459130605

Epoch: 6| Step: 4
Training loss: 1.2413103580474854
Validation loss: 2.1543384393056235

Epoch: 6| Step: 5
Training loss: 0.827797532081604
Validation loss: 2.1654703617095947

Epoch: 6| Step: 6
Training loss: 0.44957712292671204
Validation loss: 2.1701024174690247

Epoch: 6| Step: 7
Training loss: 0.346802294254303
Validation loss: 2.137961665789286

Epoch: 6| Step: 8
Training loss: 1.1347503662109375
Validation loss: 2.1409383416175842

Epoch: 6| Step: 9
Training loss: 0.5599725842475891
Validation loss: 2.149667421976725

Epoch: 6| Step: 10
Training loss: 0.8740398287773132
Validation loss: 2.1523395776748657

Epoch: 6| Step: 11
Training loss: 0.5562752485275269
Validation loss: 2.1350497603416443

Epoch: 6| Step: 12
Training loss: 0.4849969446659088
Validation loss: 2.1290286978085837

Epoch: 6| Step: 13
Training loss: 1.0208919048309326
Validation loss: 2.1663769483566284

Epoch: 439| Step: 0
Training loss: 0.9984781742095947
Validation loss: 2.180264135201772

Epoch: 6| Step: 1
Training loss: 1.142450213432312
Validation loss: 2.1653509736061096

Epoch: 6| Step: 2
Training loss: 1.0297975540161133
Validation loss: 2.1818180878957114

Epoch: 6| Step: 3
Training loss: 0.8302485942840576
Validation loss: 2.1947961250940957

Epoch: 6| Step: 4
Training loss: 0.6770498156547546
Validation loss: 2.1625340779622397

Epoch: 6| Step: 5
Training loss: 0.2651910185813904
Validation loss: 2.131664196650187

Epoch: 6| Step: 6
Training loss: 0.7782177329063416
Validation loss: 2.170513689517975

Epoch: 6| Step: 7
Training loss: 0.979135274887085
Validation loss: 2.1429715355237327

Epoch: 6| Step: 8
Training loss: 0.6319851875305176
Validation loss: 2.162899136543274

Epoch: 6| Step: 9
Training loss: 0.3721223473548889
Validation loss: 2.1634756525357566

Epoch: 6| Step: 10
Training loss: 0.6493871212005615
Validation loss: 2.2088265419006348

Epoch: 6| Step: 11
Training loss: 0.5059688091278076
Validation loss: 2.193140745162964

Epoch: 6| Step: 12
Training loss: 0.9977853298187256
Validation loss: 2.1707953015963235

Epoch: 6| Step: 13
Training loss: 0.5392072200775146
Validation loss: 2.203352073828379

Epoch: 440| Step: 0
Training loss: 0.6291795969009399
Validation loss: 2.2260793646176658

Epoch: 6| Step: 1
Training loss: 0.498910129070282
Validation loss: 2.208275059858958

Epoch: 6| Step: 2
Training loss: 0.5946700572967529
Validation loss: 2.2250066995620728

Epoch: 6| Step: 3
Training loss: 1.0302906036376953
Validation loss: 2.227093060811361

Epoch: 6| Step: 4
Training loss: 0.7618963718414307
Validation loss: 2.204277833302816

Epoch: 6| Step: 5
Training loss: 1.0265443325042725
Validation loss: 2.2004019220670066

Epoch: 6| Step: 6
Training loss: 0.6553277373313904
Validation loss: 2.1967413624127707

Epoch: 6| Step: 7
Training loss: 0.8300246596336365
Validation loss: 2.1842775543530784

Epoch: 6| Step: 8
Training loss: 0.2062682956457138
Validation loss: 2.1835761070251465

Epoch: 6| Step: 9
Training loss: 0.8609610199928284
Validation loss: 2.1711492935816445

Epoch: 6| Step: 10
Training loss: 0.4794686734676361
Validation loss: 2.1865365902582803

Epoch: 6| Step: 11
Training loss: 0.5263386964797974
Validation loss: 2.189134200414022

Epoch: 6| Step: 12
Training loss: 0.8766084909439087
Validation loss: 2.1995105147361755

Epoch: 6| Step: 13
Training loss: 1.4061980247497559
Validation loss: 2.1847984194755554

Epoch: 441| Step: 0
Training loss: 0.4894205331802368
Validation loss: 2.1941022078196206

Epoch: 6| Step: 1
Training loss: 1.1809622049331665
Validation loss: 2.215900182723999

Epoch: 6| Step: 2
Training loss: 0.6241186857223511
Validation loss: 2.202235778172811

Epoch: 6| Step: 3
Training loss: 1.0148729085922241
Validation loss: 2.231392721335093

Epoch: 6| Step: 4
Training loss: 1.0022276639938354
Validation loss: 2.2412590980529785

Epoch: 6| Step: 5
Training loss: 0.5198018550872803
Validation loss: 2.205768346786499

Epoch: 6| Step: 6
Training loss: 0.6317377090454102
Validation loss: 2.1568662524223328

Epoch: 6| Step: 7
Training loss: 0.3956466317176819
Validation loss: 2.147737423578898

Epoch: 6| Step: 8
Training loss: 0.5346567630767822
Validation loss: 2.1350602904955545

Epoch: 6| Step: 9
Training loss: 1.0682487487792969
Validation loss: 2.136607050895691

Epoch: 6| Step: 10
Training loss: 1.345314383506775
Validation loss: 2.146372159322103

Epoch: 6| Step: 11
Training loss: 0.8939045071601868
Validation loss: 2.1873648166656494

Epoch: 6| Step: 12
Training loss: 0.48566490411758423
Validation loss: 2.194514751434326

Epoch: 6| Step: 13
Training loss: 0.41078588366508484
Validation loss: 2.2074678937594094

Epoch: 442| Step: 0
Training loss: 1.3530378341674805
Validation loss: 2.2079190413157144

Epoch: 6| Step: 1
Training loss: 1.3837380409240723
Validation loss: 2.232116719086965

Epoch: 6| Step: 2
Training loss: 0.5951679348945618
Validation loss: 2.2136298616727195

Epoch: 6| Step: 3
Training loss: 0.2961713671684265
Validation loss: 2.211112062136332

Epoch: 6| Step: 4
Training loss: 0.5269545316696167
Validation loss: 2.225512683391571

Epoch: 6| Step: 5
Training loss: 0.6213740706443787
Validation loss: 2.1726593573888144

Epoch: 6| Step: 6
Training loss: 0.49765971302986145
Validation loss: 2.16937522093455

Epoch: 6| Step: 7
Training loss: 0.6717251539230347
Validation loss: 2.159888724486033

Epoch: 6| Step: 8
Training loss: 0.4469330906867981
Validation loss: 2.1783966223398843

Epoch: 6| Step: 9
Training loss: 0.9410219192504883
Validation loss: 2.1711754202842712

Epoch: 6| Step: 10
Training loss: 0.7128528356552124
Validation loss: 2.175340414047241

Epoch: 6| Step: 11
Training loss: 1.0231013298034668
Validation loss: 2.167681356271108

Epoch: 6| Step: 12
Training loss: 0.8507606983184814
Validation loss: 2.181813398996989

Epoch: 6| Step: 13
Training loss: 0.7950850129127502
Validation loss: 2.1823265155156455

Epoch: 443| Step: 0
Training loss: 0.3319054841995239
Validation loss: 2.1919321417808533

Epoch: 6| Step: 1
Training loss: 0.5374093055725098
Validation loss: 2.175192574659983

Epoch: 6| Step: 2
Training loss: 0.2588442265987396
Validation loss: 2.2268932859102883

Epoch: 6| Step: 3
Training loss: 1.0053128004074097
Validation loss: 2.20120362440745

Epoch: 6| Step: 4
Training loss: 0.6858619451522827
Validation loss: 2.2090087135632834

Epoch: 6| Step: 5
Training loss: 0.6208907961845398
Validation loss: 2.2029584447542825

Epoch: 6| Step: 6
Training loss: 0.7399052381515503
Validation loss: 2.234857201576233

Epoch: 6| Step: 7
Training loss: 0.7520262598991394
Validation loss: 2.245211124420166

Epoch: 6| Step: 8
Training loss: 1.0082964897155762
Validation loss: 2.27398552497228

Epoch: 6| Step: 9
Training loss: 1.4096935987472534
Validation loss: 2.2671477794647217

Epoch: 6| Step: 10
Training loss: 0.749582827091217
Validation loss: 2.245299458503723

Epoch: 6| Step: 11
Training loss: 1.03944730758667
Validation loss: 2.225310524304708

Epoch: 6| Step: 12
Training loss: 0.6773943901062012
Validation loss: 2.1971640586853027

Epoch: 6| Step: 13
Training loss: 0.7645860314369202
Validation loss: 2.2347495754559836

Epoch: 444| Step: 0
Training loss: 0.5345520973205566
Validation loss: 2.182042956352234

Epoch: 6| Step: 1
Training loss: 1.0048385858535767
Validation loss: 2.193452517191569

Epoch: 6| Step: 2
Training loss: 0.9067199230194092
Validation loss: 2.1960124174753823

Epoch: 6| Step: 3
Training loss: 0.9665443897247314
Validation loss: 2.1731871366500854

Epoch: 6| Step: 4
Training loss: 0.810088038444519
Validation loss: 2.2050822178522744

Epoch: 6| Step: 5
Training loss: 0.8007425665855408
Validation loss: 2.2066041231155396

Epoch: 6| Step: 6
Training loss: 0.43670886754989624
Validation loss: 2.1609861254692078

Epoch: 6| Step: 7
Training loss: 0.6227495074272156
Validation loss: 2.1994287570317588

Epoch: 6| Step: 8
Training loss: 0.686181902885437
Validation loss: 2.2014038960138955

Epoch: 6| Step: 9
Training loss: 0.8037858605384827
Validation loss: 2.2082176208496094

Epoch: 6| Step: 10
Training loss: 0.7912552356719971
Validation loss: 2.230287273724874

Epoch: 6| Step: 11
Training loss: 0.7002623677253723
Validation loss: 2.2388593355814614

Epoch: 6| Step: 12
Training loss: 0.6874765753746033
Validation loss: 2.2359007199605307

Epoch: 6| Step: 13
Training loss: 0.7177406549453735
Validation loss: 2.238108436266581

Epoch: 445| Step: 0
Training loss: 0.6872406005859375
Validation loss: 2.2227718035380044

Epoch: 6| Step: 1
Training loss: 0.4866001605987549
Validation loss: 2.1901296575864158

Epoch: 6| Step: 2
Training loss: 0.7796612977981567
Validation loss: 2.197679360707601

Epoch: 6| Step: 3
Training loss: 1.1114556789398193
Validation loss: 2.198170840740204

Epoch: 6| Step: 4
Training loss: 0.5654498338699341
Validation loss: 2.1922441720962524

Epoch: 6| Step: 5
Training loss: 0.7900266647338867
Validation loss: 2.2101277709007263

Epoch: 6| Step: 6
Training loss: 0.8257155418395996
Validation loss: 2.2000815669695535

Epoch: 6| Step: 7
Training loss: 0.6348015069961548
Validation loss: 2.199106136957804

Epoch: 6| Step: 8
Training loss: 0.7819240093231201
Validation loss: 2.2151043812433877

Epoch: 6| Step: 9
Training loss: 0.64674973487854
Validation loss: 2.166977326075236

Epoch: 6| Step: 10
Training loss: 0.3464534878730774
Validation loss: 2.2073578039805093

Epoch: 6| Step: 11
Training loss: 0.2501828372478485
Validation loss: 2.2197704513867698

Epoch: 6| Step: 12
Training loss: 0.5597320795059204
Validation loss: 2.1893781423568726

Epoch: 6| Step: 13
Training loss: 1.950569748878479
Validation loss: 2.182324767112732

Epoch: 446| Step: 0
Training loss: 0.8238821029663086
Validation loss: 2.1950348218282065

Epoch: 6| Step: 1
Training loss: 1.0889023542404175
Validation loss: 2.1661819219589233

Epoch: 6| Step: 2
Training loss: 0.6374124884605408
Validation loss: 2.15886261065801

Epoch: 6| Step: 3
Training loss: 0.5754619836807251
Validation loss: 2.159428894519806

Epoch: 6| Step: 4
Training loss: 0.703301191329956
Validation loss: 2.169595797856649

Epoch: 6| Step: 5
Training loss: 1.0852621793746948
Validation loss: 2.188395917415619

Epoch: 6| Step: 6
Training loss: 0.47014638781547546
Validation loss: 2.2152481079101562

Epoch: 6| Step: 7
Training loss: 0.7714471817016602
Validation loss: 2.1738295952479043

Epoch: 6| Step: 8
Training loss: 0.4686689078807831
Validation loss: 2.2072225411732993

Epoch: 6| Step: 9
Training loss: 0.8078750371932983
Validation loss: 2.2028446992238364

Epoch: 6| Step: 10
Training loss: 0.6165801286697388
Validation loss: 2.162149131298065

Epoch: 6| Step: 11
Training loss: 0.6709473133087158
Validation loss: 2.160780886809031

Epoch: 6| Step: 12
Training loss: 0.7969293594360352
Validation loss: 2.169664283593496

Epoch: 6| Step: 13
Training loss: 0.5886079668998718
Validation loss: 2.190866986910502

Epoch: 447| Step: 0
Training loss: 0.6809218525886536
Validation loss: 2.1804179350535073

Epoch: 6| Step: 1
Training loss: 0.6677906513214111
Validation loss: 2.183144132296244

Epoch: 6| Step: 2
Training loss: 0.5187743306159973
Validation loss: 2.218879004319509

Epoch: 6| Step: 3
Training loss: 0.5843521356582642
Validation loss: 2.2244081099828086

Epoch: 6| Step: 4
Training loss: 1.4426816701889038
Validation loss: 2.217448055744171

Epoch: 6| Step: 5
Training loss: 0.6932514905929565
Validation loss: 2.2213809887568154

Epoch: 6| Step: 6
Training loss: 0.9893521070480347
Validation loss: 2.2366273204485574

Epoch: 6| Step: 7
Training loss: 0.6057726144790649
Validation loss: 2.207865516344706

Epoch: 6| Step: 8
Training loss: 1.0784157514572144
Validation loss: 2.240202764670054

Epoch: 6| Step: 9
Training loss: 0.4122070074081421
Validation loss: 2.2286468346913657

Epoch: 6| Step: 10
Training loss: 0.878760576248169
Validation loss: 2.2140820026397705

Epoch: 6| Step: 11
Training loss: 0.7254711985588074
Validation loss: 2.1978704730669656

Epoch: 6| Step: 12
Training loss: 0.4922238886356354
Validation loss: 2.1924060185750327

Epoch: 6| Step: 13
Training loss: 0.8053385019302368
Validation loss: 2.158169388771057

Epoch: 448| Step: 0
Training loss: 0.6684017181396484
Validation loss: 2.1496105392773948

Epoch: 6| Step: 1
Training loss: 0.5373246073722839
Validation loss: 2.1575530966122947

Epoch: 6| Step: 2
Training loss: 0.8125918507575989
Validation loss: 2.1857818762461343

Epoch: 6| Step: 3
Training loss: 0.31760990619659424
Validation loss: 2.190359036127726

Epoch: 6| Step: 4
Training loss: 0.809535562992096
Validation loss: 2.1760260661443076

Epoch: 6| Step: 5
Training loss: 0.7739924192428589
Validation loss: 2.184657335281372

Epoch: 6| Step: 6
Training loss: 1.0280187129974365
Validation loss: 2.202384809652964

Epoch: 6| Step: 7
Training loss: 0.8866183757781982
Validation loss: 2.178729017575582

Epoch: 6| Step: 8
Training loss: 0.2851772606372833
Validation loss: 2.180261413256327

Epoch: 6| Step: 9
Training loss: 0.6082258224487305
Validation loss: 2.174005448818207

Epoch: 6| Step: 10
Training loss: 0.4085019826889038
Validation loss: 2.1385198831558228

Epoch: 6| Step: 11
Training loss: 0.9999884366989136
Validation loss: 2.1543155511220298

Epoch: 6| Step: 12
Training loss: 0.2664850056171417
Validation loss: 2.1092145442962646

Epoch: 6| Step: 13
Training loss: 1.1214313507080078
Validation loss: 2.1538355350494385

Epoch: 449| Step: 0
Training loss: 0.7676806449890137
Validation loss: 2.141761521498362

Epoch: 6| Step: 1
Training loss: 0.6910436153411865
Validation loss: 2.1511980295181274

Epoch: 6| Step: 2
Training loss: 0.5179091691970825
Validation loss: 2.161405324935913

Epoch: 6| Step: 3
Training loss: 0.4735110104084015
Validation loss: 2.1326310435930886

Epoch: 6| Step: 4
Training loss: 0.2602534890174866
Validation loss: 2.166932245095571

Epoch: 6| Step: 5
Training loss: 0.46037721633911133
Validation loss: 2.139629542827606

Epoch: 6| Step: 6
Training loss: 1.0618104934692383
Validation loss: 2.1700855493545532

Epoch: 6| Step: 7
Training loss: 0.9787889719009399
Validation loss: 2.1780973275502524

Epoch: 6| Step: 8
Training loss: 1.2892940044403076
Validation loss: 2.194548567136129

Epoch: 6| Step: 9
Training loss: 1.1729192733764648
Validation loss: 2.2081974943478904

Epoch: 6| Step: 10
Training loss: 0.49960392713546753
Validation loss: 2.2199464639027915

Epoch: 6| Step: 11
Training loss: 0.7608917951583862
Validation loss: 2.1846594413121543

Epoch: 6| Step: 12
Training loss: 1.1062003374099731
Validation loss: 2.2007362246513367

Epoch: 6| Step: 13
Training loss: 0.4393945336341858
Validation loss: 2.200113077958425

Epoch: 450| Step: 0
Training loss: 0.6092146635055542
Validation loss: 2.1541114250818887

Epoch: 6| Step: 1
Training loss: 0.5960934162139893
Validation loss: 2.1629786491394043

Epoch: 6| Step: 2
Training loss: 0.4129728674888611
Validation loss: 2.1652593413988748

Epoch: 6| Step: 3
Training loss: 0.6252539753913879
Validation loss: 2.1539349953333535

Epoch: 6| Step: 4
Training loss: 0.6138519048690796
Validation loss: 2.1567394932111106

Epoch: 6| Step: 5
Training loss: 0.7348479628562927
Validation loss: 2.154446760813395

Epoch: 6| Step: 6
Training loss: 0.5040876865386963
Validation loss: 2.176083485285441

Epoch: 6| Step: 7
Training loss: 0.8910924196243286
Validation loss: 2.1233486334482827

Epoch: 6| Step: 8
Training loss: 1.9508248567581177
Validation loss: 2.118321498235067

Epoch: 6| Step: 9
Training loss: 0.7051197290420532
Validation loss: 2.1273743311564126

Epoch: 6| Step: 10
Training loss: 0.3968791663646698
Validation loss: 2.163641850153605

Epoch: 6| Step: 11
Training loss: 0.2728900611400604
Validation loss: 2.1448054711023965

Epoch: 6| Step: 12
Training loss: 0.5196980834007263
Validation loss: 2.1851579546928406

Epoch: 6| Step: 13
Training loss: 1.0171141624450684
Validation loss: 2.2027135690053306

Testing loss: 1.7813369164363944
