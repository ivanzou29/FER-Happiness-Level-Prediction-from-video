Epoch: 1| Step: 0
Training loss: 5.231725692749023
Validation loss: 5.2903510729471845

Epoch: 6| Step: 1
Training loss: 5.913613796234131
Validation loss: 5.287969589233398

Epoch: 6| Step: 2
Training loss: 4.949506759643555
Validation loss: 5.285641113917033

Epoch: 6| Step: 3
Training loss: 5.046108722686768
Validation loss: 5.283560832341512

Epoch: 6| Step: 4
Training loss: 5.070554733276367
Validation loss: 5.281352440516154

Epoch: 6| Step: 5
Training loss: 5.610849380493164
Validation loss: 5.279362201690674

Epoch: 6| Step: 6
Training loss: 4.703821182250977
Validation loss: 5.2773204644521075

Epoch: 6| Step: 7
Training loss: 5.657722473144531
Validation loss: 5.275242726008098

Epoch: 6| Step: 8
Training loss: 4.174873352050781
Validation loss: 5.273231029510498

Epoch: 6| Step: 9
Training loss: 5.597487449645996
Validation loss: 5.27107048034668

Epoch: 6| Step: 10
Training loss: 5.516241073608398
Validation loss: 5.268842140833537

Epoch: 6| Step: 11
Training loss: 6.643026351928711
Validation loss: 5.26661213239034

Epoch: 6| Step: 12
Training loss: 5.349806785583496
Validation loss: 5.264257431030273

Epoch: 6| Step: 13
Training loss: 5.3732829093933105
Validation loss: 5.2617785930633545

Epoch: 2| Step: 0
Training loss: 5.760536193847656
Validation loss: 5.2591744263966875

Epoch: 6| Step: 1
Training loss: 5.211134910583496
Validation loss: 5.256432771682739

Epoch: 6| Step: 2
Training loss: 4.032216548919678
Validation loss: 5.2535459995269775

Epoch: 6| Step: 3
Training loss: 4.249553680419922
Validation loss: 5.250513752301534

Epoch: 6| Step: 4
Training loss: 6.183133125305176
Validation loss: 5.247348070144653

Epoch: 6| Step: 5
Training loss: 6.31142520904541
Validation loss: 5.244032780329387

Epoch: 6| Step: 6
Training loss: 6.349721908569336
Validation loss: 5.24035906791687

Epoch: 6| Step: 7
Training loss: 4.379827499389648
Validation loss: 5.236697673797607

Epoch: 6| Step: 8
Training loss: 6.5206098556518555
Validation loss: 5.2326896985371905

Epoch: 6| Step: 9
Training loss: 5.920612335205078
Validation loss: 5.228521347045898

Epoch: 6| Step: 10
Training loss: 4.884753227233887
Validation loss: 5.22411306699117

Epoch: 6| Step: 11
Training loss: 3.972703456878662
Validation loss: 5.219497203826904

Epoch: 6| Step: 12
Training loss: 4.450766563415527
Validation loss: 5.214649955431621

Epoch: 6| Step: 13
Training loss: 6.061357021331787
Validation loss: 5.209607680638631

Epoch: 3| Step: 0
Training loss: 5.487339973449707
Validation loss: 5.204293251037598

Epoch: 6| Step: 1
Training loss: 5.838726043701172
Validation loss: 5.1987325350443525

Epoch: 6| Step: 2
Training loss: 5.511375904083252
Validation loss: 5.1929084459940595

Epoch: 6| Step: 3
Training loss: 5.4333176612854
Validation loss: 5.187029957771301

Epoch: 6| Step: 4
Training loss: 6.626881122589111
Validation loss: 5.180795987447103

Epoch: 6| Step: 5
Training loss: 4.181170463562012
Validation loss: 5.174148400624593

Epoch: 6| Step: 6
Training loss: 4.256119251251221
Validation loss: 5.16732398668925

Epoch: 6| Step: 7
Training loss: 5.973598480224609
Validation loss: 5.160697340965271

Epoch: 6| Step: 8
Training loss: 4.616374969482422
Validation loss: 5.1534849802653

Epoch: 6| Step: 9
Training loss: 5.532168865203857
Validation loss: 5.14603058497111

Epoch: 6| Step: 10
Training loss: 4.995877742767334
Validation loss: 5.138458251953125

Epoch: 6| Step: 11
Training loss: 4.946237564086914
Validation loss: 5.130789041519165

Epoch: 6| Step: 12
Training loss: 4.629520416259766
Validation loss: 5.12312928835551

Epoch: 6| Step: 13
Training loss: 5.238373756408691
Validation loss: 5.114947001139323

Epoch: 4| Step: 0
Training loss: 5.655186176300049
Validation loss: 5.106906016667684

Epoch: 6| Step: 1
Training loss: 4.516247749328613
Validation loss: 5.0986870129903155

Epoch: 6| Step: 2
Training loss: 4.050546646118164
Validation loss: 5.090424617131551

Epoch: 6| Step: 3
Training loss: 6.390358924865723
Validation loss: 5.081910292307536

Epoch: 6| Step: 4
Training loss: 4.9828996658325195
Validation loss: 5.073798815409343

Epoch: 6| Step: 5
Training loss: 4.54118013381958
Validation loss: 5.065197308858235

Epoch: 6| Step: 6
Training loss: 5.613053321838379
Validation loss: 5.056842565536499

Epoch: 6| Step: 7
Training loss: 5.355813026428223
Validation loss: 5.048356930414836

Epoch: 6| Step: 8
Training loss: 6.036109924316406
Validation loss: 5.0392552216847735

Epoch: 6| Step: 9
Training loss: 4.946003437042236
Validation loss: 5.030594666798909

Epoch: 6| Step: 10
Training loss: 5.273603439331055
Validation loss: 5.021427313486735

Epoch: 6| Step: 11
Training loss: 4.48349666595459
Validation loss: 5.012291272481282

Epoch: 6| Step: 12
Training loss: 4.204109191894531
Validation loss: 5.002727031707764

Epoch: 6| Step: 13
Training loss: 5.750631809234619
Validation loss: 4.992983818054199

Epoch: 5| Step: 0
Training loss: 5.047455787658691
Validation loss: 4.983332633972168

Epoch: 6| Step: 1
Training loss: 4.191497802734375
Validation loss: 4.973872820536296

Epoch: 6| Step: 2
Training loss: 5.5681352615356445
Validation loss: 4.96404234568278

Epoch: 6| Step: 3
Training loss: 5.072999954223633
Validation loss: 4.954373598098755

Epoch: 6| Step: 4
Training loss: 5.453461647033691
Validation loss: 4.944549640019734

Epoch: 6| Step: 5
Training loss: 5.148586273193359
Validation loss: 4.934705495834351

Epoch: 6| Step: 6
Training loss: 4.979081153869629
Validation loss: 4.924319267272949

Epoch: 6| Step: 7
Training loss: 5.402041435241699
Validation loss: 4.914246241251628

Epoch: 6| Step: 8
Training loss: 4.79939079284668
Validation loss: 4.903701066970825

Epoch: 6| Step: 9
Training loss: 4.09580659866333
Validation loss: 4.893309076627095

Epoch: 6| Step: 10
Training loss: 4.481396675109863
Validation loss: 4.882708628972371

Epoch: 6| Step: 11
Training loss: 5.908823490142822
Validation loss: 4.872196237246196

Epoch: 6| Step: 12
Training loss: 4.658132553100586
Validation loss: 4.861700375874837

Epoch: 6| Step: 13
Training loss: 5.22133731842041
Validation loss: 4.850778182347615

Epoch: 6| Step: 0
Training loss: 5.35771369934082
Validation loss: 4.8403855959574384

Epoch: 6| Step: 1
Training loss: 5.099237442016602
Validation loss: 4.830060164133708

Epoch: 6| Step: 2
Training loss: 4.347203254699707
Validation loss: 4.81977899869283

Epoch: 6| Step: 3
Training loss: 5.3131914138793945
Validation loss: 4.809472958246867

Epoch: 6| Step: 4
Training loss: 5.085605144500732
Validation loss: 4.799097379048665

Epoch: 6| Step: 5
Training loss: 6.291041374206543
Validation loss: 4.789081533749898

Epoch: 6| Step: 6
Training loss: 5.439446449279785
Validation loss: 4.7789608637491865

Epoch: 6| Step: 7
Training loss: 4.371122360229492
Validation loss: 4.768662770589192

Epoch: 6| Step: 8
Training loss: 3.975714683532715
Validation loss: 4.7590491771698

Epoch: 6| Step: 9
Training loss: 4.929487228393555
Validation loss: 4.748753627141316

Epoch: 6| Step: 10
Training loss: 5.103399276733398
Validation loss: 4.7395914395650225

Epoch: 6| Step: 11
Training loss: 3.652402877807617
Validation loss: 4.729751030604045

Epoch: 6| Step: 12
Training loss: 4.530426979064941
Validation loss: 4.720743497212728

Epoch: 6| Step: 13
Training loss: 4.608725070953369
Validation loss: 4.711760958035787

Epoch: 7| Step: 0
Training loss: 5.608484745025635
Validation loss: 4.702832857767741

Epoch: 6| Step: 1
Training loss: 3.781562328338623
Validation loss: 4.694124539693196

Epoch: 6| Step: 2
Training loss: 3.6436705589294434
Validation loss: 4.685969829559326

Epoch: 6| Step: 3
Training loss: 4.400020599365234
Validation loss: 4.677592913309733

Epoch: 6| Step: 4
Training loss: 6.085662364959717
Validation loss: 4.669704437255859

Epoch: 6| Step: 5
Training loss: 4.27772331237793
Validation loss: 4.661808411280314

Epoch: 6| Step: 6
Training loss: 4.85322904586792
Validation loss: 4.653432528177897

Epoch: 6| Step: 7
Training loss: 4.953666687011719
Validation loss: 4.6456916729609175

Epoch: 6| Step: 8
Training loss: 5.002725601196289
Validation loss: 4.638011972109477

Epoch: 6| Step: 9
Training loss: 5.07887077331543
Validation loss: 4.630159060160319

Epoch: 6| Step: 10
Training loss: 3.994932174682617
Validation loss: 4.6225654284159345

Epoch: 6| Step: 11
Training loss: 5.279196262359619
Validation loss: 4.615072131156921

Epoch: 6| Step: 12
Training loss: 4.79698371887207
Validation loss: 4.607125282287598

Epoch: 6| Step: 13
Training loss: 4.708065032958984
Validation loss: 4.599894762039185

Epoch: 8| Step: 0
Training loss: 5.164224624633789
Validation loss: 4.591871341069539

Epoch: 6| Step: 1
Training loss: 5.455380916595459
Validation loss: 4.584081649780273

Epoch: 6| Step: 2
Training loss: 4.558108329772949
Validation loss: 4.5762637456258135

Epoch: 6| Step: 3
Training loss: 4.510342121124268
Validation loss: 4.568265835444133

Epoch: 6| Step: 4
Training loss: 6.991940498352051
Validation loss: 4.56034783522288

Epoch: 6| Step: 5
Training loss: 4.406757354736328
Validation loss: 4.552577455838521

Epoch: 6| Step: 6
Training loss: 3.683396339416504
Validation loss: 4.544779380162557

Epoch: 6| Step: 7
Training loss: 3.6302433013916016
Validation loss: 4.537108937899272

Epoch: 6| Step: 8
Training loss: 4.1349945068359375
Validation loss: 4.529435396194458

Epoch: 6| Step: 9
Training loss: 5.128828048706055
Validation loss: 4.522183815638225

Epoch: 6| Step: 10
Training loss: 4.214841365814209
Validation loss: 4.5151253541310625

Epoch: 6| Step: 11
Training loss: 3.0544025897979736
Validation loss: 4.5079478820164995

Epoch: 6| Step: 12
Training loss: 4.435827255249023
Validation loss: 4.501123030980428

Epoch: 6| Step: 13
Training loss: 5.697577476501465
Validation loss: 4.494916717211406

Epoch: 9| Step: 0
Training loss: 4.15701961517334
Validation loss: 4.488051652908325

Epoch: 6| Step: 1
Training loss: 4.835963249206543
Validation loss: 4.481183369954427

Epoch: 6| Step: 2
Training loss: 3.878401517868042
Validation loss: 4.474360942840576

Epoch: 6| Step: 3
Training loss: 4.1570820808410645
Validation loss: 4.466740409533183

Epoch: 6| Step: 4
Training loss: 4.070040702819824
Validation loss: 4.460038900375366

Epoch: 6| Step: 5
Training loss: 4.557950973510742
Validation loss: 4.453308383623759

Epoch: 6| Step: 6
Training loss: 5.022666931152344
Validation loss: 4.44632363319397

Epoch: 6| Step: 7
Training loss: 5.911528587341309
Validation loss: 4.439880450566609

Epoch: 6| Step: 8
Training loss: 5.3481268882751465
Validation loss: 4.433066725730896

Epoch: 6| Step: 9
Training loss: 3.7134809494018555
Validation loss: 4.425932010014852

Epoch: 6| Step: 10
Training loss: 4.678461074829102
Validation loss: 4.418819983800252

Epoch: 6| Step: 11
Training loss: 4.960518836975098
Validation loss: 4.411229848861694

Epoch: 6| Step: 12
Training loss: 3.5670173168182373
Validation loss: 4.405237237612407

Epoch: 6| Step: 13
Training loss: 4.9412126541137695
Validation loss: 4.3978697458903

Epoch: 10| Step: 0
Training loss: 4.979038238525391
Validation loss: 4.391325314839681

Epoch: 6| Step: 1
Training loss: 4.725485801696777
Validation loss: 4.384232004483541

Epoch: 6| Step: 2
Training loss: 5.173612594604492
Validation loss: 4.377529541651408

Epoch: 6| Step: 3
Training loss: 5.062203407287598
Validation loss: 4.371390263239543

Epoch: 6| Step: 4
Training loss: 4.570324897766113
Validation loss: 4.364081859588623

Epoch: 6| Step: 5
Training loss: 3.9841270446777344
Validation loss: 4.357091029485066

Epoch: 6| Step: 6
Training loss: 3.7366554737091064
Validation loss: 4.349847157796224

Epoch: 6| Step: 7
Training loss: 3.6967854499816895
Validation loss: 4.342652201652527

Epoch: 6| Step: 8
Training loss: 3.729931592941284
Validation loss: 4.335176388422648

Epoch: 6| Step: 9
Training loss: 3.815509796142578
Validation loss: 4.3282432953516645

Epoch: 6| Step: 10
Training loss: 4.891809463500977
Validation loss: 4.320856173833211

Epoch: 6| Step: 11
Training loss: 4.965714454650879
Validation loss: 4.3138184150060015

Epoch: 6| Step: 12
Training loss: 4.60565185546875
Validation loss: 4.306191921234131

Epoch: 6| Step: 13
Training loss: 4.615126609802246
Validation loss: 4.299119790395101

Epoch: 11| Step: 0
Training loss: 4.730661392211914
Validation loss: 4.2918163140614825

Epoch: 6| Step: 1
Training loss: 4.689773082733154
Validation loss: 4.284193515777588

Epoch: 6| Step: 2
Training loss: 3.390427589416504
Validation loss: 4.2771908442179365

Epoch: 6| Step: 3
Training loss: 4.001371383666992
Validation loss: 4.269997517267863

Epoch: 6| Step: 4
Training loss: 4.043479919433594
Validation loss: 4.261922677357991

Epoch: 6| Step: 5
Training loss: 3.572957992553711
Validation loss: 4.254246473312378

Epoch: 6| Step: 6
Training loss: 4.727313041687012
Validation loss: 4.24761438369751

Epoch: 6| Step: 7
Training loss: 5.266931056976318
Validation loss: 4.241076469421387

Epoch: 6| Step: 8
Training loss: 4.8928303718566895
Validation loss: 4.233422915140788

Epoch: 6| Step: 9
Training loss: 4.863314151763916
Validation loss: 4.224680225054423

Epoch: 6| Step: 10
Training loss: 4.562334060668945
Validation loss: 4.21675173441569

Epoch: 6| Step: 11
Training loss: 4.3722147941589355
Validation loss: 4.208435773849487

Epoch: 6| Step: 12
Training loss: 3.9954781532287598
Validation loss: 4.200886130332947

Epoch: 6| Step: 13
Training loss: 4.107558727264404
Validation loss: 4.1914286613464355

Epoch: 12| Step: 0
Training loss: 4.267061710357666
Validation loss: 4.183409849802653

Epoch: 6| Step: 1
Training loss: 4.008382320404053
Validation loss: 4.175491094589233

Epoch: 6| Step: 2
Training loss: 4.05474328994751
Validation loss: 4.16763710975647

Epoch: 6| Step: 3
Training loss: 4.152256965637207
Validation loss: 4.160523692766826

Epoch: 6| Step: 4
Training loss: 4.056661605834961
Validation loss: 4.151954134305318

Epoch: 6| Step: 5
Training loss: 3.8284130096435547
Validation loss: 4.144391258557637

Epoch: 6| Step: 6
Training loss: 4.991243362426758
Validation loss: 4.137083530426025

Epoch: 6| Step: 7
Training loss: 4.633698463439941
Validation loss: 4.129819353421529

Epoch: 6| Step: 8
Training loss: 3.8123714923858643
Validation loss: 4.121203780174255

Epoch: 6| Step: 9
Training loss: 4.641115188598633
Validation loss: 4.112847606341044

Epoch: 6| Step: 10
Training loss: 4.802542209625244
Validation loss: 4.105029265085856

Epoch: 6| Step: 11
Training loss: 4.024925231933594
Validation loss: 4.097734808921814

Epoch: 6| Step: 12
Training loss: 3.6141109466552734
Validation loss: 4.091252724329631

Epoch: 6| Step: 13
Training loss: 4.9131669998168945
Validation loss: 4.084747314453125

Epoch: 13| Step: 0
Training loss: 4.577790260314941
Validation loss: 4.076663653055827

Epoch: 6| Step: 1
Training loss: 5.322057723999023
Validation loss: 4.070064465204875

Epoch: 6| Step: 2
Training loss: 3.7944092750549316
Validation loss: 4.064375837643941

Epoch: 6| Step: 3
Training loss: 4.116796016693115
Validation loss: 4.057056307792664

Epoch: 6| Step: 4
Training loss: 3.0172624588012695
Validation loss: 4.052916566530864

Epoch: 6| Step: 5
Training loss: 3.6791958808898926
Validation loss: 4.046825846036275

Epoch: 6| Step: 6
Training loss: 3.670628547668457
Validation loss: 4.040798942248027

Epoch: 6| Step: 7
Training loss: 4.328465938568115
Validation loss: 4.034127950668335

Epoch: 6| Step: 8
Training loss: 4.112093925476074
Validation loss: 4.0269865194956465

Epoch: 6| Step: 9
Training loss: 5.159400939941406
Validation loss: 4.021000385284424

Epoch: 6| Step: 10
Training loss: 4.253172397613525
Validation loss: 4.0150415897369385

Epoch: 6| Step: 11
Training loss: 3.9515833854675293
Validation loss: 4.008745630582173

Epoch: 6| Step: 12
Training loss: 5.112298011779785
Validation loss: 4.002887566884358

Epoch: 6| Step: 13
Training loss: 3.430072546005249
Validation loss: 3.9971053202946982

Epoch: 14| Step: 0
Training loss: 4.9383392333984375
Validation loss: 3.99193541208903

Epoch: 6| Step: 1
Training loss: 3.428938150405884
Validation loss: 3.9857470989227295

Epoch: 6| Step: 2
Training loss: 3.7382588386535645
Validation loss: 3.979324142138163

Epoch: 6| Step: 3
Training loss: 4.268093109130859
Validation loss: 3.9737998644510903

Epoch: 6| Step: 4
Training loss: 3.8703534603118896
Validation loss: 3.968423088391622

Epoch: 6| Step: 5
Training loss: 4.591391563415527
Validation loss: 3.9625780979792276

Epoch: 6| Step: 6
Training loss: 3.5067596435546875
Validation loss: 3.957229574521383

Epoch: 6| Step: 7
Training loss: 4.003230094909668
Validation loss: 3.951759417851766

Epoch: 6| Step: 8
Training loss: 4.517541408538818
Validation loss: 3.945511062939962

Epoch: 6| Step: 9
Training loss: 4.620203971862793
Validation loss: 3.940649072329203

Epoch: 6| Step: 10
Training loss: 3.4278221130371094
Validation loss: 3.9361232121785483

Epoch: 6| Step: 11
Training loss: 4.591896057128906
Validation loss: 3.9306208292643228

Epoch: 6| Step: 12
Training loss: 4.142560005187988
Validation loss: 3.9244744777679443

Epoch: 6| Step: 13
Training loss: 3.7741687297821045
Validation loss: 3.9184670050938926

Epoch: 15| Step: 0
Training loss: 4.199244499206543
Validation loss: 3.912819266319275

Epoch: 6| Step: 1
Training loss: 4.625061988830566
Validation loss: 3.9069051345189414

Epoch: 6| Step: 2
Training loss: 3.728394031524658
Validation loss: 3.9023238023122153

Epoch: 6| Step: 3
Training loss: 4.088225841522217
Validation loss: 3.8975247542063394

Epoch: 6| Step: 4
Training loss: 4.576328277587891
Validation loss: 3.8906334241231284

Epoch: 6| Step: 5
Training loss: 3.703310489654541
Validation loss: 3.8848743836085

Epoch: 6| Step: 6
Training loss: 3.7650671005249023
Validation loss: 3.879568099975586

Epoch: 6| Step: 7
Training loss: 3.6318695545196533
Validation loss: 3.874183019002279

Epoch: 6| Step: 8
Training loss: 3.8522675037384033
Validation loss: 3.8688348134358725

Epoch: 6| Step: 9
Training loss: 4.684049606323242
Validation loss: 3.8641836643218994

Epoch: 6| Step: 10
Training loss: 3.3809688091278076
Validation loss: 3.8586369355519614

Epoch: 6| Step: 11
Training loss: 4.164457321166992
Validation loss: 3.853713591893514

Epoch: 6| Step: 12
Training loss: 4.344779968261719
Validation loss: 3.8484873374303183

Epoch: 6| Step: 13
Training loss: 3.6636734008789062
Validation loss: 3.8429712454477944

Epoch: 16| Step: 0
Training loss: 4.199711799621582
Validation loss: 3.8381019830703735

Epoch: 6| Step: 1
Training loss: 3.1890487670898438
Validation loss: 3.8330504099527993

Epoch: 6| Step: 2
Training loss: 3.074066638946533
Validation loss: 3.8280942837397256

Epoch: 6| Step: 3
Training loss: 4.159957408905029
Validation loss: 3.823565721511841

Epoch: 6| Step: 4
Training loss: 3.4331858158111572
Validation loss: 3.8185282945632935

Epoch: 6| Step: 5
Training loss: 3.795125722885132
Validation loss: 3.813196380933126

Epoch: 6| Step: 6
Training loss: 5.185576438903809
Validation loss: 3.8088167905807495

Epoch: 6| Step: 7
Training loss: 4.5515313148498535
Validation loss: 3.8044942220052085

Epoch: 6| Step: 8
Training loss: 3.7640552520751953
Validation loss: 3.8000756104787192

Epoch: 6| Step: 9
Training loss: 3.4608912467956543
Validation loss: 3.7951786120732627

Epoch: 6| Step: 10
Training loss: 4.388197898864746
Validation loss: 3.7910727659861245

Epoch: 6| Step: 11
Training loss: 4.210033416748047
Validation loss: 3.7853709856669107

Epoch: 6| Step: 12
Training loss: 4.060768127441406
Validation loss: 3.7811019817988076

Epoch: 6| Step: 13
Training loss: 3.983961820602417
Validation loss: 3.776219288508097

Epoch: 17| Step: 0
Training loss: 3.3000922203063965
Validation loss: 3.7716877857844033

Epoch: 6| Step: 1
Training loss: 4.100792407989502
Validation loss: 3.7669229904810586

Epoch: 6| Step: 2
Training loss: 3.759819746017456
Validation loss: 3.7628047466278076

Epoch: 6| Step: 3
Training loss: 3.5694007873535156
Validation loss: 3.757663091023763

Epoch: 6| Step: 4
Training loss: 3.489896059036255
Validation loss: 3.7531094948450723

Epoch: 6| Step: 5
Training loss: 3.6170129776000977
Validation loss: 3.748378356297811

Epoch: 6| Step: 6
Training loss: 4.051853179931641
Validation loss: 3.7441530227661133

Epoch: 6| Step: 7
Training loss: 2.9842896461486816
Validation loss: 3.7397865056991577

Epoch: 6| Step: 8
Training loss: 4.243339538574219
Validation loss: 3.7353279987970986

Epoch: 6| Step: 9
Training loss: 4.646491050720215
Validation loss: 3.7310516834259033

Epoch: 6| Step: 10
Training loss: 5.055451393127441
Validation loss: 3.726335644721985

Epoch: 6| Step: 11
Training loss: 4.451268196105957
Validation loss: 3.721741795539856

Epoch: 6| Step: 12
Training loss: 2.773569345474243
Validation loss: 3.717098871866862

Epoch: 6| Step: 13
Training loss: 4.5599517822265625
Validation loss: 3.7129263480504355

Epoch: 18| Step: 0
Training loss: 3.5761330127716064
Validation loss: 3.708605925242106

Epoch: 6| Step: 1
Training loss: 3.8618526458740234
Validation loss: 3.7045714060465493

Epoch: 6| Step: 2
Training loss: 2.987107276916504
Validation loss: 3.700085202852885

Epoch: 6| Step: 3
Training loss: 4.0622968673706055
Validation loss: 3.6960100332895913

Epoch: 6| Step: 4
Training loss: 3.346235990524292
Validation loss: 3.6918845971425376

Epoch: 6| Step: 5
Training loss: 3.7469053268432617
Validation loss: 3.6879545052846274

Epoch: 6| Step: 6
Training loss: 3.8392069339752197
Validation loss: 3.684017221132914

Epoch: 6| Step: 7
Training loss: 4.0884904861450195
Validation loss: 3.6794955730438232

Epoch: 6| Step: 8
Training loss: 3.5560927391052246
Validation loss: 3.675036827723185

Epoch: 6| Step: 9
Training loss: 3.2797093391418457
Validation loss: 3.6707852681477866

Epoch: 6| Step: 10
Training loss: 4.5411376953125
Validation loss: 3.6660662094751992

Epoch: 6| Step: 11
Training loss: 4.1066179275512695
Validation loss: 3.662150263786316

Epoch: 6| Step: 12
Training loss: 4.9457173347473145
Validation loss: 3.657692869504293

Epoch: 6| Step: 13
Training loss: 3.838042736053467
Validation loss: 3.653346578280131

Epoch: 19| Step: 0
Training loss: 4.454599857330322
Validation loss: 3.6489373445510864

Epoch: 6| Step: 1
Training loss: 3.4652860164642334
Validation loss: 3.644760847091675

Epoch: 6| Step: 2
Training loss: 3.2366137504577637
Validation loss: 3.6402024825414023

Epoch: 6| Step: 3
Training loss: 3.3320820331573486
Validation loss: 3.6360038916269937

Epoch: 6| Step: 4
Training loss: 3.7530500888824463
Validation loss: 3.6318718592325845

Epoch: 6| Step: 5
Training loss: 3.976165771484375
Validation loss: 3.6278872887293496

Epoch: 6| Step: 6
Training loss: 3.8069686889648438
Validation loss: 3.6236597299575806

Epoch: 6| Step: 7
Training loss: 3.7184863090515137
Validation loss: 3.619308352470398

Epoch: 6| Step: 8
Training loss: 4.384106636047363
Validation loss: 3.615523854891459

Epoch: 6| Step: 9
Training loss: 3.90374755859375
Validation loss: 3.6112305720647178

Epoch: 6| Step: 10
Training loss: 3.4046807289123535
Validation loss: 3.6070722738901773

Epoch: 6| Step: 11
Training loss: 3.7137763500213623
Validation loss: 3.6025569836298623

Epoch: 6| Step: 12
Training loss: 4.115819931030273
Validation loss: 3.598529656728109

Epoch: 6| Step: 13
Training loss: 3.691002368927002
Validation loss: 3.5937978426615396

Epoch: 20| Step: 0
Training loss: 3.246188163757324
Validation loss: 3.590181907018026

Epoch: 6| Step: 1
Training loss: 4.088260650634766
Validation loss: 3.585071086883545

Epoch: 6| Step: 2
Training loss: 3.515751361846924
Validation loss: 3.5805248816808066

Epoch: 6| Step: 3
Training loss: 4.128325462341309
Validation loss: 3.5765201648076377

Epoch: 6| Step: 4
Training loss: 4.177457809448242
Validation loss: 3.572694261868795

Epoch: 6| Step: 5
Training loss: 4.097756385803223
Validation loss: 3.5683380365371704

Epoch: 6| Step: 6
Training loss: 3.615617275238037
Validation loss: 3.5634421507517495

Epoch: 6| Step: 7
Training loss: 2.965836524963379
Validation loss: 3.559251149495443

Epoch: 6| Step: 8
Training loss: 3.5013065338134766
Validation loss: 3.5551281770070395

Epoch: 6| Step: 9
Training loss: 4.396613597869873
Validation loss: 3.5498019059499106

Epoch: 6| Step: 10
Training loss: 3.9993886947631836
Validation loss: 3.5453436772028604

Epoch: 6| Step: 11
Training loss: 3.3731448650360107
Validation loss: 3.541122873624166

Epoch: 6| Step: 12
Training loss: 3.0488264560699463
Validation loss: 3.536766608556112

Epoch: 6| Step: 13
Training loss: 4.004917621612549
Validation loss: 3.532811721165975

Epoch: 21| Step: 0
Training loss: 3.910982608795166
Validation loss: 3.527920444806417

Epoch: 6| Step: 1
Training loss: 4.24945592880249
Validation loss: 3.5236001014709473

Epoch: 6| Step: 2
Training loss: 3.9337010383605957
Validation loss: 3.519106944402059

Epoch: 6| Step: 3
Training loss: 3.306389808654785
Validation loss: 3.5148528019587197

Epoch: 6| Step: 4
Training loss: 3.215449333190918
Validation loss: 3.5101863543192544

Epoch: 6| Step: 5
Training loss: 3.136913776397705
Validation loss: 3.505834976832072

Epoch: 6| Step: 6
Training loss: 4.1006178855896
Validation loss: 3.501580317815145

Epoch: 6| Step: 7
Training loss: 3.5858170986175537
Validation loss: 3.49701197942098

Epoch: 6| Step: 8
Training loss: 4.538948059082031
Validation loss: 3.4928104082743325

Epoch: 6| Step: 9
Training loss: 3.580982208251953
Validation loss: 3.4883121252059937

Epoch: 6| Step: 10
Training loss: 2.689506769180298
Validation loss: 3.48362668355306

Epoch: 6| Step: 11
Training loss: 3.36942982673645
Validation loss: 3.4791181882222495

Epoch: 6| Step: 12
Training loss: 3.6923322677612305
Validation loss: 3.4743319352467856

Epoch: 6| Step: 13
Training loss: 4.017260551452637
Validation loss: 3.4698480367660522

Epoch: 22| Step: 0
Training loss: 3.7581191062927246
Validation loss: 3.4655573765436807

Epoch: 6| Step: 1
Training loss: 3.3059794902801514
Validation loss: 3.4613099495569863

Epoch: 6| Step: 2
Training loss: 4.29937219619751
Validation loss: 3.4566585620244346

Epoch: 6| Step: 3
Training loss: 4.8487548828125
Validation loss: 3.4521286884943643

Epoch: 6| Step: 4
Training loss: 3.6413278579711914
Validation loss: 3.4475502173105874

Epoch: 6| Step: 5
Training loss: 3.5284245014190674
Validation loss: 3.4432656367619834

Epoch: 6| Step: 6
Training loss: 3.3657140731811523
Validation loss: 3.4385016361872354

Epoch: 6| Step: 7
Training loss: 3.466482639312744
Validation loss: 3.4334198236465454

Epoch: 6| Step: 8
Training loss: 2.6507301330566406
Validation loss: 3.4305790662765503

Epoch: 6| Step: 9
Training loss: 4.142065525054932
Validation loss: 3.426010489463806

Epoch: 6| Step: 10
Training loss: 3.2751433849334717
Validation loss: 3.4221335649490356

Epoch: 6| Step: 11
Training loss: 3.546919822692871
Validation loss: 3.4174752235412598

Epoch: 6| Step: 12
Training loss: 3.3146800994873047
Validation loss: 3.4128196636835733

Epoch: 6| Step: 13
Training loss: 3.3416123390197754
Validation loss: 3.408752759297689

Epoch: 23| Step: 0
Training loss: 3.1564576625823975
Validation loss: 3.404778480529785

Epoch: 6| Step: 1
Training loss: 3.1432251930236816
Validation loss: 3.400749365488688

Epoch: 6| Step: 2
Training loss: 3.608832836151123
Validation loss: 3.397124171257019

Epoch: 6| Step: 3
Training loss: 3.6885793209075928
Validation loss: 3.3934321800867715

Epoch: 6| Step: 4
Training loss: 3.989610195159912
Validation loss: 3.3900657892227173

Epoch: 6| Step: 5
Training loss: 3.0757837295532227
Validation loss: 3.3858629862467446

Epoch: 6| Step: 6
Training loss: 3.417647361755371
Validation loss: 3.3822317520777383

Epoch: 6| Step: 7
Training loss: 3.8181185722351074
Validation loss: 3.3781076669692993

Epoch: 6| Step: 8
Training loss: 3.6418938636779785
Validation loss: 3.3738803466161094

Epoch: 6| Step: 9
Training loss: 4.605743408203125
Validation loss: 3.369823376337687

Epoch: 6| Step: 10
Training loss: 2.7235288619995117
Validation loss: 3.3654584487279258

Epoch: 6| Step: 11
Training loss: 5.191817283630371
Validation loss: 3.361307223637899

Epoch: 6| Step: 12
Training loss: 2.872286319732666
Validation loss: 3.3569552501042685

Epoch: 6| Step: 13
Training loss: 2.729193687438965
Validation loss: 3.352682034174601

Epoch: 24| Step: 0
Training loss: 3.3463339805603027
Validation loss: 3.34823211034139

Epoch: 6| Step: 1
Training loss: 2.7731263637542725
Validation loss: 3.344241221745809

Epoch: 6| Step: 2
Training loss: 3.325103282928467
Validation loss: 3.3398746649424234

Epoch: 6| Step: 3
Training loss: 4.5756635665893555
Validation loss: 3.3357727924982705

Epoch: 6| Step: 4
Training loss: 3.277510643005371
Validation loss: 3.3319053252538047

Epoch: 6| Step: 5
Training loss: 3.913667917251587
Validation loss: 3.3278366327285767

Epoch: 6| Step: 6
Training loss: 3.9832186698913574
Validation loss: 3.3236573934555054

Epoch: 6| Step: 7
Training loss: 3.7267770767211914
Validation loss: 3.319733222325643

Epoch: 6| Step: 8
Training loss: 3.2361884117126465
Validation loss: 3.315705418586731

Epoch: 6| Step: 9
Training loss: 2.838512897491455
Validation loss: 3.3112934827804565

Epoch: 6| Step: 10
Training loss: 3.224618434906006
Validation loss: 3.3070646127065024

Epoch: 6| Step: 11
Training loss: 2.829442024230957
Validation loss: 3.302944540977478

Epoch: 6| Step: 12
Training loss: 3.9157586097717285
Validation loss: 3.298864801724752

Epoch: 6| Step: 13
Training loss: 3.9621973037719727
Validation loss: 3.295021653175354

Epoch: 25| Step: 0
Training loss: 3.350682258605957
Validation loss: 3.291173219680786

Epoch: 6| Step: 1
Training loss: 3.2540464401245117
Validation loss: 3.286893447240194

Epoch: 6| Step: 2
Training loss: 4.318913459777832
Validation loss: 3.283210277557373

Epoch: 6| Step: 3
Training loss: 2.819464683532715
Validation loss: 3.2791990439097085

Epoch: 6| Step: 4
Training loss: 3.2348921298980713
Validation loss: 3.27557905515035

Epoch: 6| Step: 5
Training loss: 2.836594581604004
Validation loss: 3.271124561627706

Epoch: 6| Step: 6
Training loss: 3.7938294410705566
Validation loss: 3.2666459480921426

Epoch: 6| Step: 7
Training loss: 3.1437456607818604
Validation loss: 3.2628221909205117

Epoch: 6| Step: 8
Training loss: 3.9364726543426514
Validation loss: 3.2585583925247192

Epoch: 6| Step: 9
Training loss: 2.6580018997192383
Validation loss: 3.2547676165898642

Epoch: 6| Step: 10
Training loss: 3.342500686645508
Validation loss: 3.251365860303243

Epoch: 6| Step: 11
Training loss: 4.075802803039551
Validation loss: 3.24704639116923

Epoch: 6| Step: 12
Training loss: 4.279916763305664
Validation loss: 3.24361785252889

Epoch: 6| Step: 13
Training loss: 3.171082019805908
Validation loss: 3.2396835883458457

Epoch: 26| Step: 0
Training loss: 2.5586915016174316
Validation loss: 3.2361406485239663

Epoch: 6| Step: 1
Training loss: 4.307999610900879
Validation loss: 3.2325432697931924

Epoch: 6| Step: 2
Training loss: 2.9637110233306885
Validation loss: 3.2284629344940186

Epoch: 6| Step: 3
Training loss: 3.6139988899230957
Validation loss: 3.224822759628296

Epoch: 6| Step: 4
Training loss: 3.8054380416870117
Validation loss: 3.2210037310918174

Epoch: 6| Step: 5
Training loss: 3.8507771492004395
Validation loss: 3.2173555294672647

Epoch: 6| Step: 6
Training loss: 2.399966239929199
Validation loss: 3.2136192321777344

Epoch: 6| Step: 7
Training loss: 3.0342044830322266
Validation loss: 3.210000157356262

Epoch: 6| Step: 8
Training loss: 3.2236130237579346
Validation loss: 3.206157922744751

Epoch: 6| Step: 9
Training loss: 3.309149742126465
Validation loss: 3.20240851243337

Epoch: 6| Step: 10
Training loss: 3.458862781524658
Validation loss: 3.198478857676188

Epoch: 6| Step: 11
Training loss: 3.6031293869018555
Validation loss: 3.194851557413737

Epoch: 6| Step: 12
Training loss: 3.2518224716186523
Validation loss: 3.190696040789286

Epoch: 6| Step: 13
Training loss: 4.111586570739746
Validation loss: 3.18666938940684

Epoch: 27| Step: 0
Training loss: 3.998633861541748
Validation loss: 3.18290638923645

Epoch: 6| Step: 1
Training loss: 3.2365641593933105
Validation loss: 3.1791406869888306

Epoch: 6| Step: 2
Training loss: 4.173067092895508
Validation loss: 3.1750699281692505

Epoch: 6| Step: 3
Training loss: 4.153307914733887
Validation loss: 3.1711271603902182

Epoch: 6| Step: 4
Training loss: 3.2690377235412598
Validation loss: 3.1673463582992554

Epoch: 6| Step: 5
Training loss: 2.6271986961364746
Validation loss: 3.163203557332357

Epoch: 6| Step: 6
Training loss: 3.268059015274048
Validation loss: 3.1592634121576944

Epoch: 6| Step: 7
Training loss: 2.6564300060272217
Validation loss: 3.155485471089681

Epoch: 6| Step: 8
Training loss: 2.774310350418091
Validation loss: 3.1517643531163535

Epoch: 6| Step: 9
Training loss: 3.758671760559082
Validation loss: 3.1479930877685547

Epoch: 6| Step: 10
Training loss: 4.12226676940918
Validation loss: 3.143974264462789

Epoch: 6| Step: 11
Training loss: 2.7509522438049316
Validation loss: 3.139915347099304

Epoch: 6| Step: 12
Training loss: 3.0681416988372803
Validation loss: 3.135636846224467

Epoch: 6| Step: 13
Training loss: 2.962063789367676
Validation loss: 3.1319682598114014

Epoch: 28| Step: 0
Training loss: 3.4866292476654053
Validation loss: 3.1281344890594482

Epoch: 6| Step: 1
Training loss: 3.6112585067749023
Validation loss: 3.1244488954544067

Epoch: 6| Step: 2
Training loss: 3.384303331375122
Validation loss: 3.120610078175863

Epoch: 6| Step: 3
Training loss: 3.501736640930176
Validation loss: 3.1169543266296387

Epoch: 6| Step: 4
Training loss: 3.9027116298675537
Validation loss: 3.113285859425863

Epoch: 6| Step: 5
Training loss: 3.3048644065856934
Validation loss: 3.1091548204421997

Epoch: 6| Step: 6
Training loss: 3.8379454612731934
Validation loss: 3.105148712793986

Epoch: 6| Step: 7
Training loss: 3.4701569080352783
Validation loss: 3.101423184076945

Epoch: 6| Step: 8
Training loss: 2.504676342010498
Validation loss: 3.09737491607666

Epoch: 6| Step: 9
Training loss: 2.8985066413879395
Validation loss: 3.0940130949020386

Epoch: 6| Step: 10
Training loss: 3.131103992462158
Validation loss: 3.0902123848597207

Epoch: 6| Step: 11
Training loss: 2.738898754119873
Validation loss: 3.0869924624760947

Epoch: 6| Step: 12
Training loss: 2.700002670288086
Validation loss: 3.0834434827168784

Epoch: 6| Step: 13
Training loss: 3.6447982788085938
Validation loss: 3.0801877975463867

Epoch: 29| Step: 0
Training loss: 2.5794661045074463
Validation loss: 3.076771338780721

Epoch: 6| Step: 1
Training loss: 3.4496994018554688
Validation loss: 3.0735952854156494

Epoch: 6| Step: 2
Training loss: 3.652618885040283
Validation loss: 3.070491671562195

Epoch: 6| Step: 3
Training loss: 3.5112648010253906
Validation loss: 3.067432085673014

Epoch: 6| Step: 4
Training loss: 3.0333333015441895
Validation loss: 3.063827713330587

Epoch: 6| Step: 5
Training loss: 2.86586856842041
Validation loss: 3.0603919426600137

Epoch: 6| Step: 6
Training loss: 2.685170888900757
Validation loss: 3.057209610939026

Epoch: 6| Step: 7
Training loss: 3.5667166709899902
Validation loss: 3.0539732774098716

Epoch: 6| Step: 8
Training loss: 2.8628039360046387
Validation loss: 3.050659457842509

Epoch: 6| Step: 9
Training loss: 3.5787570476531982
Validation loss: 3.0473880767822266

Epoch: 6| Step: 10
Training loss: 3.2537660598754883
Validation loss: 3.0442174275716147

Epoch: 6| Step: 11
Training loss: 3.4164669513702393
Validation loss: 3.040940205256144

Epoch: 6| Step: 12
Training loss: 3.7431137561798096
Validation loss: 3.0377614498138428

Epoch: 6| Step: 13
Training loss: 3.2402241230010986
Validation loss: 3.034314513206482

Epoch: 30| Step: 0
Training loss: 3.149867534637451
Validation loss: 3.0307501554489136

Epoch: 6| Step: 1
Training loss: 3.722428321838379
Validation loss: 3.0276914834976196

Epoch: 6| Step: 2
Training loss: 3.957704544067383
Validation loss: 3.0239574909210205

Epoch: 6| Step: 3
Training loss: 3.0487074851989746
Validation loss: 3.020127216974894

Epoch: 6| Step: 4
Training loss: 3.090019702911377
Validation loss: 3.0169276793797812

Epoch: 6| Step: 5
Training loss: 3.580915927886963
Validation loss: 3.0126841068267822

Epoch: 6| Step: 6
Training loss: 2.5440640449523926
Validation loss: 3.0083815654118857

Epoch: 6| Step: 7
Training loss: 3.066296100616455
Validation loss: 3.0048009554545083

Epoch: 6| Step: 8
Training loss: 3.6113481521606445
Validation loss: 3.001385450363159

Epoch: 6| Step: 9
Training loss: 3.146038055419922
Validation loss: 2.9975287119547525

Epoch: 6| Step: 10
Training loss: 1.7309457063674927
Validation loss: 2.9941120545069375

Epoch: 6| Step: 11
Training loss: 3.4919590950012207
Validation loss: 2.990988850593567

Epoch: 6| Step: 12
Training loss: 3.4458115100860596
Validation loss: 2.9880239566167197

Epoch: 6| Step: 13
Training loss: 3.2783658504486084
Validation loss: 2.9845542112986245

Epoch: 31| Step: 0
Training loss: 3.4586663246154785
Validation loss: 2.9816039403279624

Epoch: 6| Step: 1
Training loss: 2.8591203689575195
Validation loss: 2.9780619939168296

Epoch: 6| Step: 2
Training loss: 3.7328038215637207
Validation loss: 2.974957227706909

Epoch: 6| Step: 3
Training loss: 2.8657209873199463
Validation loss: 2.9715754985809326

Epoch: 6| Step: 4
Training loss: 3.444366455078125
Validation loss: 2.9681812127431235

Epoch: 6| Step: 5
Training loss: 2.573166608810425
Validation loss: 2.9647348324457803

Epoch: 6| Step: 6
Training loss: 3.801074504852295
Validation loss: 2.961519638697306

Epoch: 6| Step: 7
Training loss: 3.2961039543151855
Validation loss: 2.958134412765503

Epoch: 6| Step: 8
Training loss: 3.0924057960510254
Validation loss: 2.9546313285827637

Epoch: 6| Step: 9
Training loss: 3.738872528076172
Validation loss: 2.9518125454584756

Epoch: 6| Step: 10
Training loss: 3.1120858192443848
Validation loss: 2.9485196669896445

Epoch: 6| Step: 11
Training loss: 2.6257615089416504
Validation loss: 2.945137937863668

Epoch: 6| Step: 12
Training loss: 2.4759368896484375
Validation loss: 2.941834330558777

Epoch: 6| Step: 13
Training loss: 3.1691484451293945
Validation loss: 2.9387389421463013

Epoch: 32| Step: 0
Training loss: 3.4033164978027344
Validation loss: 2.935433506965637

Epoch: 6| Step: 1
Training loss: 3.2507803440093994
Validation loss: 2.9329771995544434

Epoch: 6| Step: 2
Training loss: 3.187265634536743
Validation loss: 2.9294583002726235

Epoch: 6| Step: 3
Training loss: 3.6248016357421875
Validation loss: 2.9261422554651895

Epoch: 6| Step: 4
Training loss: 2.4986379146575928
Validation loss: 2.922305703163147

Epoch: 6| Step: 5
Training loss: 2.5049328804016113
Validation loss: 2.924931804339091

Epoch: 6| Step: 6
Training loss: 3.0415706634521484
Validation loss: 2.9365632136662803

Epoch: 6| Step: 7
Training loss: 3.535951852798462
Validation loss: 2.95801051457723

Epoch: 6| Step: 8
Training loss: 3.4132614135742188
Validation loss: 2.912240207195282

Epoch: 6| Step: 9
Training loss: 3.0732812881469727
Validation loss: 2.9070370197296143

Epoch: 6| Step: 10
Training loss: 3.1721298694610596
Validation loss: 2.905911405881246

Epoch: 6| Step: 11
Training loss: 3.0914151668548584
Validation loss: 2.92130974928538

Epoch: 6| Step: 12
Training loss: 3.102752685546875
Validation loss: 2.913633386294047

Epoch: 6| Step: 13
Training loss: 2.8742756843566895
Validation loss: 2.909536818663279

Epoch: 33| Step: 0
Training loss: 2.8453924655914307
Validation loss: 2.9059569438298545

Epoch: 6| Step: 1
Training loss: 3.658902883529663
Validation loss: 2.9000264008839927

Epoch: 6| Step: 2
Training loss: 2.675535202026367
Validation loss: 2.895354906717936

Epoch: 6| Step: 3
Training loss: 2.673553943634033
Validation loss: 2.8978437582651773

Epoch: 6| Step: 4
Training loss: 2.98081636428833
Validation loss: 2.901328961054484

Epoch: 6| Step: 5
Training loss: 2.736751079559326
Validation loss: 2.8813129663467407

Epoch: 6| Step: 6
Training loss: 3.984498977661133
Validation loss: 2.877740224202474

Epoch: 6| Step: 7
Training loss: 2.606616497039795
Validation loss: 2.8742327292760215

Epoch: 6| Step: 8
Training loss: 3.187645196914673
Validation loss: 2.8722766637802124

Epoch: 6| Step: 9
Training loss: 2.9801831245422363
Validation loss: 2.8707619110743203

Epoch: 6| Step: 10
Training loss: 3.4166574478149414
Validation loss: 2.8709697326024375

Epoch: 6| Step: 11
Training loss: 3.43758487701416
Validation loss: 2.872904896736145

Epoch: 6| Step: 12
Training loss: 2.851915121078491
Validation loss: 2.862846533457438

Epoch: 6| Step: 13
Training loss: 3.167808771133423
Validation loss: 2.8575948079427085

Epoch: 34| Step: 0
Training loss: 3.234095335006714
Validation loss: 2.8542620738347373

Epoch: 6| Step: 1
Training loss: 2.756513833999634
Validation loss: 2.8502985636393228

Epoch: 6| Step: 2
Training loss: 2.68391489982605
Validation loss: 2.8477984269460044

Epoch: 6| Step: 3
Training loss: 2.7042298316955566
Validation loss: 2.844152808189392

Epoch: 6| Step: 4
Training loss: 3.7979631423950195
Validation loss: 2.8433229525883994

Epoch: 6| Step: 5
Training loss: 3.4082064628601074
Validation loss: 2.8393256266911826

Epoch: 6| Step: 6
Training loss: 2.7325243949890137
Validation loss: 2.8369668324788413

Epoch: 6| Step: 7
Training loss: 3.5282809734344482
Validation loss: 2.8327625592549643

Epoch: 6| Step: 8
Training loss: 2.921489953994751
Validation loss: 2.830613652865092

Epoch: 6| Step: 9
Training loss: 3.6304702758789062
Validation loss: 2.826169749101003

Epoch: 6| Step: 10
Training loss: 2.2311174869537354
Validation loss: 2.823714335759481

Epoch: 6| Step: 11
Training loss: 2.7056562900543213
Validation loss: 2.819742480913798

Epoch: 6| Step: 12
Training loss: 2.488982677459717
Validation loss: 2.8182833592096963

Epoch: 6| Step: 13
Training loss: 3.802819013595581
Validation loss: 2.816131512324015

Epoch: 35| Step: 0
Training loss: 2.873793125152588
Validation loss: 2.8126275142033896

Epoch: 6| Step: 1
Training loss: 2.817676067352295
Validation loss: 2.8087987899780273

Epoch: 6| Step: 2
Training loss: 3.5425076484680176
Validation loss: 2.8060105244318643

Epoch: 6| Step: 3
Training loss: 2.552748680114746
Validation loss: 2.8019785483678183

Epoch: 6| Step: 4
Training loss: 2.827481746673584
Validation loss: 2.798961083094279

Epoch: 6| Step: 5
Training loss: 3.2189221382141113
Validation loss: 2.796205163002014

Epoch: 6| Step: 6
Training loss: 2.998030185699463
Validation loss: 2.7928996284802756

Epoch: 6| Step: 7
Training loss: 2.766848564147949
Validation loss: 2.7888431549072266

Epoch: 6| Step: 8
Training loss: 2.8683056831359863
Validation loss: 2.7863101164499917

Epoch: 6| Step: 9
Training loss: 2.625774383544922
Validation loss: 2.7830585638682046

Epoch: 6| Step: 10
Training loss: 2.81015682220459
Validation loss: 2.782889246940613

Epoch: 6| Step: 11
Training loss: 3.2590765953063965
Validation loss: 2.7786993980407715

Epoch: 6| Step: 12
Training loss: 3.5712778568267822
Validation loss: 2.7751048803329468

Epoch: 6| Step: 13
Training loss: 3.3169190883636475
Validation loss: 2.7731043895085654

Epoch: 36| Step: 0
Training loss: 3.2771499156951904
Validation loss: 2.7685484886169434

Epoch: 6| Step: 1
Training loss: 3.2067952156066895
Validation loss: 2.76602311929067

Epoch: 6| Step: 2
Training loss: 2.4536988735198975
Validation loss: 2.7654148737589517

Epoch: 6| Step: 3
Training loss: 2.8378028869628906
Validation loss: 2.7610525290171304

Epoch: 6| Step: 4
Training loss: 2.526007890701294
Validation loss: 2.7590705156326294

Epoch: 6| Step: 5
Training loss: 3.4711999893188477
Validation loss: 2.7563615242640176

Epoch: 6| Step: 6
Training loss: 2.9035186767578125
Validation loss: 2.7540760040283203

Epoch: 6| Step: 7
Training loss: 3.333251953125
Validation loss: 2.752624829610189

Epoch: 6| Step: 8
Training loss: 3.2494375705718994
Validation loss: 2.748923381169637

Epoch: 6| Step: 9
Training loss: 3.0328004360198975
Validation loss: 2.747092088063558

Epoch: 6| Step: 10
Training loss: 2.528836727142334
Validation loss: 2.7437461217244468

Epoch: 6| Step: 11
Training loss: 3.646760940551758
Validation loss: 2.7401801347732544

Epoch: 6| Step: 12
Training loss: 2.4210896492004395
Validation loss: 2.7380460103352866

Epoch: 6| Step: 13
Training loss: 2.569204330444336
Validation loss: 2.7343839406967163

Epoch: 37| Step: 0
Training loss: 3.3596768379211426
Validation loss: 2.7322552601496377

Epoch: 6| Step: 1
Training loss: 3.4230446815490723
Validation loss: 2.7289911905924478

Epoch: 6| Step: 2
Training loss: 2.7950644493103027
Validation loss: 2.725318988164266

Epoch: 6| Step: 3
Training loss: 3.1093761920928955
Validation loss: 2.72238826751709

Epoch: 6| Step: 4
Training loss: 2.7815165519714355
Validation loss: 2.7200647989908853

Epoch: 6| Step: 5
Training loss: 3.25373911857605
Validation loss: 2.717121879259745

Epoch: 6| Step: 6
Training loss: 3.435560464859009
Validation loss: 2.7135883967081704

Epoch: 6| Step: 7
Training loss: 2.4154129028320312
Validation loss: 2.7121822237968445

Epoch: 6| Step: 8
Training loss: 2.9907360076904297
Validation loss: 2.7085920572280884

Epoch: 6| Step: 9
Training loss: 2.7295303344726562
Validation loss: 2.7050079107284546

Epoch: 6| Step: 10
Training loss: 2.8943097591400146
Validation loss: 2.7015161514282227

Epoch: 6| Step: 11
Training loss: 2.5665478706359863
Validation loss: 2.6994067231814065

Epoch: 6| Step: 12
Training loss: 2.5325493812561035
Validation loss: 2.6962865591049194

Epoch: 6| Step: 13
Training loss: 2.624175548553467
Validation loss: 2.6922190189361572

Epoch: 38| Step: 0
Training loss: 2.728849411010742
Validation loss: 2.6899917920430503

Epoch: 6| Step: 1
Training loss: 1.8145990371704102
Validation loss: 2.6896294752756753

Epoch: 6| Step: 2
Training loss: 2.8829426765441895
Validation loss: 2.69061287244161

Epoch: 6| Step: 3
Training loss: 3.6724932193756104
Validation loss: 2.689950426419576

Epoch: 6| Step: 4
Training loss: 2.4120535850524902
Validation loss: 2.684240778287252

Epoch: 6| Step: 5
Training loss: 2.194243907928467
Validation loss: 2.6797220706939697

Epoch: 6| Step: 6
Training loss: 3.0885958671569824
Validation loss: 2.6808997790018716

Epoch: 6| Step: 7
Training loss: 2.8603219985961914
Validation loss: 2.6812400817871094

Epoch: 6| Step: 8
Training loss: 3.193965435028076
Validation loss: 2.6726460059483848

Epoch: 6| Step: 9
Training loss: 2.7611870765686035
Validation loss: 2.6719206174214682

Epoch: 6| Step: 10
Training loss: 3.5394911766052246
Validation loss: 2.6700624227523804

Epoch: 6| Step: 11
Training loss: 3.1143765449523926
Validation loss: 2.6600592136383057

Epoch: 6| Step: 12
Training loss: 3.214123487472534
Validation loss: 2.658118406931559

Epoch: 6| Step: 13
Training loss: 2.83518123626709
Validation loss: 2.6549260020256042

Epoch: 39| Step: 0
Training loss: 2.9535820484161377
Validation loss: 2.6545525789260864

Epoch: 6| Step: 1
Training loss: 2.4247307777404785
Validation loss: 2.654904087384542

Epoch: 6| Step: 2
Training loss: 3.1468942165374756
Validation loss: 2.652478734652201

Epoch: 6| Step: 3
Training loss: 2.8829517364501953
Validation loss: 2.6520225207010903

Epoch: 6| Step: 4
Training loss: 3.052008867263794
Validation loss: 2.649225433667501

Epoch: 6| Step: 5
Training loss: 2.8662378787994385
Validation loss: 2.6474323074022927

Epoch: 6| Step: 6
Training loss: 3.440840482711792
Validation loss: 2.647107243537903

Epoch: 6| Step: 7
Training loss: 2.914365768432617
Validation loss: 2.6406211058298745

Epoch: 6| Step: 8
Training loss: 2.1409459114074707
Validation loss: 2.634858012199402

Epoch: 6| Step: 9
Training loss: 2.18790340423584
Validation loss: 2.6307581265767417

Epoch: 6| Step: 10
Training loss: 2.5324270725250244
Validation loss: 2.6267546812693277

Epoch: 6| Step: 11
Training loss: 2.7125654220581055
Validation loss: 2.6231815020243325

Epoch: 6| Step: 12
Training loss: 2.6204993724823
Validation loss: 2.618622819582621

Epoch: 6| Step: 13
Training loss: 3.8945798873901367
Validation loss: 2.617441018422445

Epoch: 40| Step: 0
Training loss: 2.887587785720825
Validation loss: 2.6132509311040244

Epoch: 6| Step: 1
Training loss: 2.1162562370300293
Validation loss: 2.609897017478943

Epoch: 6| Step: 2
Training loss: 2.922597885131836
Validation loss: 2.6129347483317056

Epoch: 6| Step: 3
Training loss: 2.0111846923828125
Validation loss: 2.6134379704793296

Epoch: 6| Step: 4
Training loss: 2.3119044303894043
Validation loss: 2.6113407214482627

Epoch: 6| Step: 5
Training loss: 2.8568315505981445
Validation loss: 2.607419749101003

Epoch: 6| Step: 6
Training loss: 3.690953016281128
Validation loss: 2.6122964223225913

Epoch: 6| Step: 7
Training loss: 3.4186129570007324
Validation loss: 2.5959726572036743

Epoch: 6| Step: 8
Training loss: 2.5962729454040527
Validation loss: 2.5925336281458535

Epoch: 6| Step: 9
Training loss: 2.287242889404297
Validation loss: 2.589780112107595

Epoch: 6| Step: 10
Training loss: 2.796886444091797
Validation loss: 2.587406357129415

Epoch: 6| Step: 11
Training loss: 3.0778274536132812
Validation loss: 2.5854148467381797

Epoch: 6| Step: 12
Training loss: 3.379138946533203
Validation loss: 2.581100503603617

Epoch: 6| Step: 13
Training loss: 2.7808966636657715
Validation loss: 2.577853520711263

Epoch: 41| Step: 0
Training loss: 2.7468316555023193
Validation loss: 2.578935424486796

Epoch: 6| Step: 1
Training loss: 2.9492268562316895
Validation loss: 2.575555423895518

Epoch: 6| Step: 2
Training loss: 3.7155158519744873
Validation loss: 2.5746427377065024

Epoch: 6| Step: 3
Training loss: 2.2457783222198486
Validation loss: 2.566413482030233

Epoch: 6| Step: 4
Training loss: 3.2317357063293457
Validation loss: 2.5642782847086587

Epoch: 6| Step: 5
Training loss: 2.582336664199829
Validation loss: 2.561686317125956

Epoch: 6| Step: 6
Training loss: 2.6285109519958496
Validation loss: 2.568755785624186

Epoch: 6| Step: 7
Training loss: 1.672673225402832
Validation loss: 2.552952289581299

Epoch: 6| Step: 8
Training loss: 2.911090850830078
Validation loss: 2.554100513458252

Epoch: 6| Step: 9
Training loss: 2.8016092777252197
Validation loss: 2.550298591454824

Epoch: 6| Step: 10
Training loss: 2.3879811763763428
Validation loss: 2.546445647875468

Epoch: 6| Step: 11
Training loss: 3.5293993949890137
Validation loss: 2.5465979973475137

Epoch: 6| Step: 12
Training loss: 2.617985248565674
Validation loss: 2.545439918835958

Epoch: 6| Step: 13
Training loss: 2.583528757095337
Validation loss: 2.5432538986206055

Epoch: 42| Step: 0
Training loss: 3.249405860900879
Validation loss: 2.542073448499044

Epoch: 6| Step: 1
Training loss: 2.6317429542541504
Validation loss: 2.541998505592346

Epoch: 6| Step: 2
Training loss: 2.7667574882507324
Validation loss: 2.5433778365453086

Epoch: 6| Step: 3
Training loss: 2.512965679168701
Validation loss: 2.5395978887875876

Epoch: 6| Step: 4
Training loss: 2.584890604019165
Validation loss: 2.53769858678182

Epoch: 6| Step: 5
Training loss: 2.7379369735717773
Validation loss: 2.5323617855707803

Epoch: 6| Step: 6
Training loss: 2.0553183555603027
Validation loss: 2.5291752417882285

Epoch: 6| Step: 7
Training loss: 2.583436965942383
Validation loss: 2.527005195617676

Epoch: 6| Step: 8
Training loss: 3.569572925567627
Validation loss: 2.5245443185170493

Epoch: 6| Step: 9
Training loss: 2.347874641418457
Validation loss: 2.517679969469706

Epoch: 6| Step: 10
Training loss: 2.7048568725585938
Validation loss: 2.514970064163208

Epoch: 6| Step: 11
Training loss: 2.180236577987671
Validation loss: 2.5126968224843345

Epoch: 6| Step: 12
Training loss: 3.234673023223877
Validation loss: 2.507595419883728

Epoch: 6| Step: 13
Training loss: 2.955315113067627
Validation loss: 2.505539655685425

Epoch: 43| Step: 0
Training loss: 3.021690607070923
Validation loss: 2.5030760367711387

Epoch: 6| Step: 1
Training loss: 2.3395321369171143
Validation loss: 2.500352064768473

Epoch: 6| Step: 2
Training loss: 2.3385801315307617
Validation loss: 2.5016918182373047

Epoch: 6| Step: 3
Training loss: 2.914161443710327
Validation loss: 2.5131582419077554

Epoch: 6| Step: 4
Training loss: 2.2110366821289062
Validation loss: 2.5032067696253457

Epoch: 6| Step: 5
Training loss: 3.612419366836548
Validation loss: 2.495065907637278

Epoch: 6| Step: 6
Training loss: 1.9024125337600708
Validation loss: 2.4857420523961387

Epoch: 6| Step: 7
Training loss: 2.908804416656494
Validation loss: 2.484345773855845

Epoch: 6| Step: 8
Training loss: 3.196659564971924
Validation loss: 2.483195185661316

Epoch: 6| Step: 9
Training loss: 2.560070037841797
Validation loss: 2.4827818870544434

Epoch: 6| Step: 10
Training loss: 3.6104907989501953
Validation loss: 2.4796185890833535

Epoch: 6| Step: 11
Training loss: 2.1450037956237793
Validation loss: 2.478159228960673

Epoch: 6| Step: 12
Training loss: 1.98405122756958
Validation loss: 2.474583625793457

Epoch: 6| Step: 13
Training loss: 2.765289306640625
Validation loss: 2.470699191093445

Epoch: 44| Step: 0
Training loss: 2.8693976402282715
Validation loss: 2.465241471926371

Epoch: 6| Step: 1
Training loss: 2.7893428802490234
Validation loss: 2.4645877281824746

Epoch: 6| Step: 2
Training loss: 2.9392075538635254
Validation loss: 2.4668891429901123

Epoch: 6| Step: 3
Training loss: 2.644533634185791
Validation loss: 2.4626365105311074

Epoch: 6| Step: 4
Training loss: 2.8109025955200195
Validation loss: 2.464222272237142

Epoch: 6| Step: 5
Training loss: 2.376424789428711
Validation loss: 2.461099684238434

Epoch: 6| Step: 6
Training loss: 2.7204904556274414
Validation loss: 2.456351161003113

Epoch: 6| Step: 7
Training loss: 2.21156644821167
Validation loss: 2.4542280435562134

Epoch: 6| Step: 8
Training loss: 2.3311939239501953
Validation loss: 2.449511408805847

Epoch: 6| Step: 9
Training loss: 2.41664457321167
Validation loss: 2.4484872023264566

Epoch: 6| Step: 10
Training loss: 3.0058701038360596
Validation loss: 2.445178508758545

Epoch: 6| Step: 11
Training loss: 2.6041970252990723
Validation loss: 2.4386713107426963

Epoch: 6| Step: 12
Training loss: 2.4168190956115723
Validation loss: 2.4361127416292825

Epoch: 6| Step: 13
Training loss: 2.8239173889160156
Validation loss: 2.4335588614145913

Epoch: 45| Step: 0
Training loss: 2.4400691986083984
Validation loss: 2.4367223978042603

Epoch: 6| Step: 1
Training loss: 2.7167649269104004
Validation loss: 2.427862207094828

Epoch: 6| Step: 2
Training loss: 1.8255419731140137
Validation loss: 2.4273465474446616

Epoch: 6| Step: 3
Training loss: 2.5062167644500732
Validation loss: 2.4310436646143594

Epoch: 6| Step: 4
Training loss: 2.620016574859619
Validation loss: 2.4218358993530273

Epoch: 6| Step: 5
Training loss: 2.943179130554199
Validation loss: 2.4184280236562095

Epoch: 6| Step: 6
Training loss: 2.6435399055480957
Validation loss: 2.419312278429667

Epoch: 6| Step: 7
Training loss: 2.2727932929992676
Validation loss: 2.409794569015503

Epoch: 6| Step: 8
Training loss: 3.2595934867858887
Validation loss: 2.415856957435608

Epoch: 6| Step: 9
Training loss: 2.384957790374756
Validation loss: 2.411396543184916

Epoch: 6| Step: 10
Training loss: 2.524977445602417
Validation loss: 2.4090689222017923

Epoch: 6| Step: 11
Training loss: 2.6103482246398926
Validation loss: 2.4065662225087485

Epoch: 6| Step: 12
Training loss: 2.9556779861450195
Validation loss: 2.403414269288381

Epoch: 6| Step: 13
Training loss: 2.711758852005005
Validation loss: 2.4072283109029136

Epoch: 46| Step: 0
Training loss: 1.8014256954193115
Validation loss: 2.3981399536132812

Epoch: 6| Step: 1
Training loss: 2.3519551753997803
Validation loss: 2.3972127040227256

Epoch: 6| Step: 2
Training loss: 3.567140579223633
Validation loss: 2.3954704205195108

Epoch: 6| Step: 3
Training loss: 1.6924879550933838
Validation loss: 2.391807715098063

Epoch: 6| Step: 4
Training loss: 2.625540256500244
Validation loss: 2.390522062778473

Epoch: 6| Step: 5
Training loss: 2.0449161529541016
Validation loss: 2.3883655071258545

Epoch: 6| Step: 6
Training loss: 2.6084744930267334
Validation loss: 2.379167636235555

Epoch: 6| Step: 7
Training loss: 3.294571876525879
Validation loss: 2.3800705671310425

Epoch: 6| Step: 8
Training loss: 2.688483715057373
Validation loss: 2.3777411381403604

Epoch: 6| Step: 9
Training loss: 2.5920417308807373
Validation loss: 2.3736366033554077

Epoch: 6| Step: 10
Training loss: 2.4602489471435547
Validation loss: 2.375093718369802

Epoch: 6| Step: 11
Training loss: 2.480189085006714
Validation loss: 2.3737922509511313

Epoch: 6| Step: 12
Training loss: 2.802523136138916
Validation loss: 2.3667931954065957

Epoch: 6| Step: 13
Training loss: 2.8349857330322266
Validation loss: 2.3648455341657004

Epoch: 47| Step: 0
Training loss: 2.309969425201416
Validation loss: 2.377534548441569

Epoch: 6| Step: 1
Training loss: 2.86098051071167
Validation loss: 2.36747678120931

Epoch: 6| Step: 2
Training loss: 2.490108013153076
Validation loss: 2.3562740286191306

Epoch: 6| Step: 3
Training loss: 2.993659496307373
Validation loss: 2.355968991915385

Epoch: 6| Step: 4
Training loss: 2.7766735553741455
Validation loss: 2.3567204674084983

Epoch: 6| Step: 5
Training loss: 2.273615598678589
Validation loss: 2.359997828801473

Epoch: 6| Step: 6
Training loss: 2.7257189750671387
Validation loss: 2.357359011967977

Epoch: 6| Step: 7
Training loss: 2.5917797088623047
Validation loss: 2.3538744846979776

Epoch: 6| Step: 8
Training loss: 2.6909217834472656
Validation loss: 2.356201728185018

Epoch: 6| Step: 9
Training loss: 2.8010802268981934
Validation loss: 2.3557310104370117

Epoch: 6| Step: 10
Training loss: 2.609015941619873
Validation loss: 2.3516849279403687

Epoch: 6| Step: 11
Training loss: 2.305661201477051
Validation loss: 2.3483710289001465

Epoch: 6| Step: 12
Training loss: 2.022576332092285
Validation loss: 2.3482866684595742

Epoch: 6| Step: 13
Training loss: 1.980966567993164
Validation loss: 2.3425325949986777

Epoch: 48| Step: 0
Training loss: 2.8899412155151367
Validation loss: 2.3389880855878196

Epoch: 6| Step: 1
Training loss: 2.607827663421631
Validation loss: 2.3474507331848145

Epoch: 6| Step: 2
Training loss: 2.698563575744629
Validation loss: 2.3367178042729697

Epoch: 6| Step: 3
Training loss: 2.982820987701416
Validation loss: 2.3289957841237388

Epoch: 6| Step: 4
Training loss: 2.671825408935547
Validation loss: 2.3265896836916604

Epoch: 6| Step: 5
Training loss: 1.808661937713623
Validation loss: 2.324692944685618

Epoch: 6| Step: 6
Training loss: 1.9874097108840942
Validation loss: 2.3204498489697776

Epoch: 6| Step: 7
Training loss: 2.267880439758301
Validation loss: 2.3221318125724792

Epoch: 6| Step: 8
Training loss: 2.7960219383239746
Validation loss: 2.3176934719085693

Epoch: 6| Step: 9
Training loss: 2.5976853370666504
Validation loss: 2.3194541931152344

Epoch: 6| Step: 10
Training loss: 2.2131166458129883
Validation loss: 2.3143099745114646

Epoch: 6| Step: 11
Training loss: 2.1817026138305664
Validation loss: 2.3152997692426047

Epoch: 6| Step: 12
Training loss: 2.7325003147125244
Validation loss: 2.3121010462443032

Epoch: 6| Step: 13
Training loss: 2.498436212539673
Validation loss: 2.3071181972821555

Epoch: 49| Step: 0
Training loss: 2.3603804111480713
Validation loss: 2.3026082515716553

Epoch: 6| Step: 1
Training loss: 2.8983442783355713
Validation loss: 2.303783655166626

Epoch: 6| Step: 2
Training loss: 2.831022262573242
Validation loss: 2.301262299219767

Epoch: 6| Step: 3
Training loss: 1.8587276935577393
Validation loss: 2.299088974793752

Epoch: 6| Step: 4
Training loss: 2.536756992340088
Validation loss: 2.292458653450012

Epoch: 6| Step: 5
Training loss: 2.7280020713806152
Validation loss: 2.2878162463506064

Epoch: 6| Step: 6
Training loss: 2.7584524154663086
Validation loss: 2.2874181071917215

Epoch: 6| Step: 7
Training loss: 2.1839165687561035
Validation loss: 2.2865799268086753

Epoch: 6| Step: 8
Training loss: 2.186628818511963
Validation loss: 2.2871758739153543

Epoch: 6| Step: 9
Training loss: 2.709177017211914
Validation loss: 2.281346877415975

Epoch: 6| Step: 10
Training loss: 2.5528063774108887
Validation loss: 2.2817862232526145

Epoch: 6| Step: 11
Training loss: 2.6228415966033936
Validation loss: 2.284888585408529

Epoch: 6| Step: 12
Training loss: 1.8860670328140259
Validation loss: 2.2798354029655457

Epoch: 6| Step: 13
Training loss: 2.1946754455566406
Validation loss: 2.275487263997396

Epoch: 50| Step: 0
Training loss: 2.4369194507598877
Validation loss: 2.2767573396364846

Epoch: 6| Step: 1
Training loss: 2.290548801422119
Validation loss: 2.2731711069742837

Epoch: 6| Step: 2
Training loss: 2.5868635177612305
Validation loss: 2.2798935969670615

Epoch: 6| Step: 3
Training loss: 2.4142956733703613
Validation loss: 2.287504812081655

Epoch: 6| Step: 4
Training loss: 1.7076232433319092
Validation loss: 2.2850964268048606

Epoch: 6| Step: 5
Training loss: 2.2405457496643066
Validation loss: 2.260994533697764

Epoch: 6| Step: 6
Training loss: 2.2632713317871094
Validation loss: 2.2618831992149353

Epoch: 6| Step: 7
Training loss: 2.8764476776123047
Validation loss: 2.2623233000437417

Epoch: 6| Step: 8
Training loss: 2.235672950744629
Validation loss: 2.262176434199015

Epoch: 6| Step: 9
Training loss: 2.667880058288574
Validation loss: 2.2635661959648132

Epoch: 6| Step: 10
Training loss: 2.928884744644165
Validation loss: 2.2615296641985574

Epoch: 6| Step: 11
Training loss: 2.3932673931121826
Validation loss: 2.2593055168787637

Epoch: 6| Step: 12
Training loss: 2.2572531700134277
Validation loss: 2.2565438747406006

Epoch: 6| Step: 13
Training loss: 2.710094451904297
Validation loss: 2.2572431166966758

Epoch: 51| Step: 0
Training loss: 2.4273393154144287
Validation loss: 2.2542388637860618

Epoch: 6| Step: 1
Training loss: 2.485849380493164
Validation loss: 2.255435585975647

Epoch: 6| Step: 2
Training loss: 2.5584259033203125
Validation loss: 2.2499900658925376

Epoch: 6| Step: 3
Training loss: 2.7318649291992188
Validation loss: 2.2484525243441262

Epoch: 6| Step: 4
Training loss: 2.048011541366577
Validation loss: 2.2435821692148843

Epoch: 6| Step: 5
Training loss: 1.9328519105911255
Validation loss: 2.238970418771108

Epoch: 6| Step: 6
Training loss: 2.3316094875335693
Validation loss: 2.2388861179351807

Epoch: 6| Step: 7
Training loss: 3.042884349822998
Validation loss: 2.2401719888051352

Epoch: 6| Step: 8
Training loss: 2.25081205368042
Validation loss: 2.2372580766677856

Epoch: 6| Step: 9
Training loss: 3.2502338886260986
Validation loss: 2.2461581230163574

Epoch: 6| Step: 10
Training loss: 2.411560535430908
Validation loss: 2.2391048669815063

Epoch: 6| Step: 11
Training loss: 1.4871530532836914
Validation loss: 2.2230283419291177

Epoch: 6| Step: 12
Training loss: 1.9552315473556519
Validation loss: 2.2259283661842346

Epoch: 6| Step: 13
Training loss: 2.612422466278076
Validation loss: 2.226113200187683

Epoch: 52| Step: 0
Training loss: 2.197270631790161
Validation loss: 2.222811003526052

Epoch: 6| Step: 1
Training loss: 2.1640968322753906
Validation loss: 2.2187227805455527

Epoch: 6| Step: 2
Training loss: 2.363259792327881
Validation loss: 2.217106660207113

Epoch: 6| Step: 3
Training loss: 2.1898536682128906
Validation loss: 2.220735271771749

Epoch: 6| Step: 4
Training loss: 2.703457832336426
Validation loss: 2.21527107556661

Epoch: 6| Step: 5
Training loss: 2.7328133583068848
Validation loss: 2.2140426635742188

Epoch: 6| Step: 6
Training loss: 2.1726133823394775
Validation loss: 2.2126667499542236

Epoch: 6| Step: 7
Training loss: 2.8379440307617188
Validation loss: 2.2125830252965293

Epoch: 6| Step: 8
Training loss: 2.0304086208343506
Validation loss: 2.209395488103231

Epoch: 6| Step: 9
Training loss: 2.4375650882720947
Validation loss: 2.2033774654070535

Epoch: 6| Step: 10
Training loss: 3.015538215637207
Validation loss: 2.2076714436213174

Epoch: 6| Step: 11
Training loss: 2.163306713104248
Validation loss: 2.200836797555288

Epoch: 6| Step: 12
Training loss: 2.044405937194824
Validation loss: 2.201438824335734

Epoch: 6| Step: 13
Training loss: 2.0549206733703613
Validation loss: 2.19770618279775

Epoch: 53| Step: 0
Training loss: 2.4451332092285156
Validation loss: 2.192417879899343

Epoch: 6| Step: 1
Training loss: 2.5947437286376953
Validation loss: 2.1963264544804892

Epoch: 6| Step: 2
Training loss: 2.0803921222686768
Validation loss: 2.2029216488202414

Epoch: 6| Step: 3
Training loss: 2.194972276687622
Validation loss: 2.2029737631479898

Epoch: 6| Step: 4
Training loss: 2.5303070545196533
Validation loss: 2.1923411885897317

Epoch: 6| Step: 5
Training loss: 2.2635436058044434
Validation loss: 2.1910895506540933

Epoch: 6| Step: 6
Training loss: 2.507387638092041
Validation loss: 2.1916841665903726

Epoch: 6| Step: 7
Training loss: 1.8452067375183105
Validation loss: 2.1913997530937195

Epoch: 6| Step: 8
Training loss: 3.0425143241882324
Validation loss: 2.1968658566474915

Epoch: 6| Step: 9
Training loss: 2.4825685024261475
Validation loss: 2.194538871447245

Epoch: 6| Step: 10
Training loss: 2.105393409729004
Validation loss: 2.1911873618761697

Epoch: 6| Step: 11
Training loss: 2.3726367950439453
Validation loss: 2.188911517461141

Epoch: 6| Step: 12
Training loss: 2.088374614715576
Validation loss: 2.1858378251393638

Epoch: 6| Step: 13
Training loss: 2.3717362880706787
Validation loss: 2.1798744400342307

Epoch: 54| Step: 0
Training loss: 2.2755842208862305
Validation loss: 2.1790173649787903

Epoch: 6| Step: 1
Training loss: 2.3212006092071533
Validation loss: 2.178983906904856

Epoch: 6| Step: 2
Training loss: 2.6823477745056152
Validation loss: 2.179682950178782

Epoch: 6| Step: 3
Training loss: 2.890897750854492
Validation loss: 2.176767806212107

Epoch: 6| Step: 4
Training loss: 2.7092368602752686
Validation loss: 2.1693392197291055

Epoch: 6| Step: 5
Training loss: 2.307312250137329
Validation loss: 2.173389991124471

Epoch: 6| Step: 6
Training loss: 2.106448173522949
Validation loss: 2.165153741836548

Epoch: 6| Step: 7
Training loss: 2.256265163421631
Validation loss: 2.1598963538805642

Epoch: 6| Step: 8
Training loss: 2.305917739868164
Validation loss: 2.1609561443328857

Epoch: 6| Step: 9
Training loss: 1.6139063835144043
Validation loss: 2.164020816485087

Epoch: 6| Step: 10
Training loss: 2.2826080322265625
Validation loss: 2.16150830189387

Epoch: 6| Step: 11
Training loss: 2.180441379547119
Validation loss: 2.1633804043134055

Epoch: 6| Step: 12
Training loss: 2.5700623989105225
Validation loss: 2.159259835879008

Epoch: 6| Step: 13
Training loss: 2.089078187942505
Validation loss: 2.1666452487309775

Epoch: 55| Step: 0
Training loss: 2.3119759559631348
Validation loss: 2.157318671544393

Epoch: 6| Step: 1
Training loss: 2.5114526748657227
Validation loss: 2.152743657430013

Epoch: 6| Step: 2
Training loss: 2.3875906467437744
Validation loss: 2.149790128072103

Epoch: 6| Step: 3
Training loss: 2.259766101837158
Validation loss: 2.144491692384084

Epoch: 6| Step: 4
Training loss: 2.201491594314575
Validation loss: 2.1497747699419656

Epoch: 6| Step: 5
Training loss: 2.817348003387451
Validation loss: 2.1463454564412436

Epoch: 6| Step: 6
Training loss: 2.0578441619873047
Validation loss: 2.149497131506602

Epoch: 6| Step: 7
Training loss: 1.7667213678359985
Validation loss: 2.1377355058987937

Epoch: 6| Step: 8
Training loss: 2.605009078979492
Validation loss: 2.1458036303520203

Epoch: 6| Step: 9
Training loss: 2.18375825881958
Validation loss: 2.134918133417765

Epoch: 6| Step: 10
Training loss: 1.85933518409729
Validation loss: 2.1354894240697226

Epoch: 6| Step: 11
Training loss: 1.869250774383545
Validation loss: 2.133818507194519

Epoch: 6| Step: 12
Training loss: 2.4456396102905273
Validation loss: 2.1359384854634604

Epoch: 6| Step: 13
Training loss: 3.050413131713867
Validation loss: 2.133692999680837

Epoch: 56| Step: 0
Training loss: 2.3829784393310547
Validation loss: 2.1325823068618774

Epoch: 6| Step: 1
Training loss: 1.6181354522705078
Validation loss: 2.136821965376536

Epoch: 6| Step: 2
Training loss: 2.2667386531829834
Validation loss: 2.133960803349813

Epoch: 6| Step: 3
Training loss: 2.3903589248657227
Validation loss: 2.1356769800186157

Epoch: 6| Step: 4
Training loss: 1.8197119235992432
Validation loss: 2.136843740940094

Epoch: 6| Step: 5
Training loss: 1.956477165222168
Validation loss: 2.1566937963167825

Epoch: 6| Step: 6
Training loss: 1.7460298538208008
Validation loss: 2.1444610953330994

Epoch: 6| Step: 7
Training loss: 3.282625198364258
Validation loss: 2.150427977244059

Epoch: 6| Step: 8
Training loss: 1.6608431339263916
Validation loss: 2.148453632990519

Epoch: 6| Step: 9
Training loss: 2.3383922576904297
Validation loss: 2.1388957699139914

Epoch: 6| Step: 10
Training loss: 2.83697509765625
Validation loss: 2.1333728631337485

Epoch: 6| Step: 11
Training loss: 2.48987078666687
Validation loss: 2.140107969443003

Epoch: 6| Step: 12
Training loss: 2.834927558898926
Validation loss: 2.138506054878235

Epoch: 6| Step: 13
Training loss: 2.3863260746002197
Validation loss: 2.1430890758832297

Epoch: 57| Step: 0
Training loss: 2.1576621532440186
Validation loss: 2.1458359162012735

Epoch: 6| Step: 1
Training loss: 1.98032808303833
Validation loss: 2.147414048512777

Epoch: 6| Step: 2
Training loss: 2.295773506164551
Validation loss: 2.1468377312024436

Epoch: 6| Step: 3
Training loss: 3.145164728164673
Validation loss: 2.145356237888336

Epoch: 6| Step: 4
Training loss: 2.5109152793884277
Validation loss: 2.147586782773336

Epoch: 6| Step: 5
Training loss: 2.2968969345092773
Validation loss: 2.1437361240386963

Epoch: 6| Step: 6
Training loss: 1.9321110248565674
Validation loss: 2.144097924232483

Epoch: 6| Step: 7
Training loss: 1.9710086584091187
Validation loss: 2.1461508671442666

Epoch: 6| Step: 8
Training loss: 2.3525919914245605
Validation loss: 2.145371357599894

Epoch: 6| Step: 9
Training loss: 2.0257911682128906
Validation loss: 2.148086349169413

Epoch: 6| Step: 10
Training loss: 2.633114814758301
Validation loss: 2.1475107272466025

Epoch: 6| Step: 11
Training loss: 2.214686155319214
Validation loss: 2.144232749938965

Epoch: 6| Step: 12
Training loss: 2.7472715377807617
Validation loss: 2.1441166400909424

Epoch: 6| Step: 13
Training loss: 2.196122646331787
Validation loss: 2.1404528816541037

Epoch: 58| Step: 0
Training loss: 2.269146203994751
Validation loss: 2.136263648668925

Epoch: 6| Step: 1
Training loss: 2.326758623123169
Validation loss: 2.1342883706092834

Epoch: 6| Step: 2
Training loss: 2.2995047569274902
Validation loss: 2.1350700656572976

Epoch: 6| Step: 3
Training loss: 2.6279239654541016
Validation loss: 2.137769103050232

Epoch: 6| Step: 4
Training loss: 2.576995849609375
Validation loss: 2.1366259256998696

Epoch: 6| Step: 5
Training loss: 2.48829984664917
Validation loss: 2.1335481802622476

Epoch: 6| Step: 6
Training loss: 1.791916847229004
Validation loss: 2.1315614581108093

Epoch: 6| Step: 7
Training loss: 2.3100225925445557
Validation loss: 2.133393963177999

Epoch: 6| Step: 8
Training loss: 2.1545002460479736
Validation loss: 2.127241094907125

Epoch: 6| Step: 9
Training loss: 1.8302258253097534
Validation loss: 2.1207099159558616

Epoch: 6| Step: 10
Training loss: 2.243330955505371
Validation loss: 2.1209381024042764

Epoch: 6| Step: 11
Training loss: 2.0694236755371094
Validation loss: 2.116476853688558

Epoch: 6| Step: 12
Training loss: 2.809340238571167
Validation loss: 2.12013308207194

Epoch: 6| Step: 13
Training loss: 2.3919830322265625
Validation loss: 2.125044266382853

Epoch: 59| Step: 0
Training loss: 1.855365514755249
Validation loss: 2.128736893335978

Epoch: 6| Step: 1
Training loss: 2.3873071670532227
Validation loss: 2.1248733003934226

Epoch: 6| Step: 2
Training loss: 2.082036018371582
Validation loss: 2.117929140726725

Epoch: 6| Step: 3
Training loss: 2.0467939376831055
Validation loss: 2.1178444027900696

Epoch: 6| Step: 4
Training loss: 2.5431485176086426
Validation loss: 2.1111199855804443

Epoch: 6| Step: 5
Training loss: 2.584197521209717
Validation loss: 2.1052921613057456

Epoch: 6| Step: 6
Training loss: 2.2343597412109375
Validation loss: 2.1094937721888223

Epoch: 6| Step: 7
Training loss: 1.989059329032898
Validation loss: 2.1033308506011963

Epoch: 6| Step: 8
Training loss: 2.2513504028320312
Validation loss: 2.099552035331726

Epoch: 6| Step: 9
Training loss: 2.547910213470459
Validation loss: 2.098246157169342

Epoch: 6| Step: 10
Training loss: 2.1245741844177246
Validation loss: 2.1002092957496643

Epoch: 6| Step: 11
Training loss: 2.3043622970581055
Validation loss: 2.1356717546780906

Epoch: 6| Step: 12
Training loss: 2.251067876815796
Validation loss: 2.155776560306549

Epoch: 6| Step: 13
Training loss: 2.78178334236145
Validation loss: 2.1604037086168923

Epoch: 60| Step: 0
Training loss: 1.918621301651001
Validation loss: 2.1083141565322876

Epoch: 6| Step: 1
Training loss: 2.6508679389953613
Validation loss: 2.093648155530294

Epoch: 6| Step: 2
Training loss: 2.126408576965332
Validation loss: 2.086610575517019

Epoch: 6| Step: 3
Training loss: 2.1943700313568115
Validation loss: 2.085639695326487

Epoch: 6| Step: 4
Training loss: 2.202070474624634
Validation loss: 2.090437650680542

Epoch: 6| Step: 5
Training loss: 2.4723315238952637
Validation loss: 2.0924042661984763

Epoch: 6| Step: 6
Training loss: 2.613255023956299
Validation loss: 2.093680421511332

Epoch: 6| Step: 7
Training loss: 2.747180461883545
Validation loss: 2.0923738280932107

Epoch: 6| Step: 8
Training loss: 2.586235284805298
Validation loss: 2.092912177244822

Epoch: 6| Step: 9
Training loss: 1.991995096206665
Validation loss: 2.0943942268689475

Epoch: 6| Step: 10
Training loss: 2.5296287536621094
Validation loss: 2.096395274003347

Epoch: 6| Step: 11
Training loss: 2.1960630416870117
Validation loss: 2.088739534219106

Epoch: 6| Step: 12
Training loss: 1.840692400932312
Validation loss: 2.08406933148702

Epoch: 6| Step: 13
Training loss: 1.5991930961608887
Validation loss: 2.082301219304403

Epoch: 61| Step: 0
Training loss: 1.8593662977218628
Validation loss: 2.0740686655044556

Epoch: 6| Step: 1
Training loss: 1.9748420715332031
Validation loss: 2.07627538839976

Epoch: 6| Step: 2
Training loss: 2.77888822555542
Validation loss: 2.075369119644165

Epoch: 6| Step: 3
Training loss: 2.911367177963257
Validation loss: 2.0664337078730264

Epoch: 6| Step: 4
Training loss: 2.1113061904907227
Validation loss: 2.0827908317248025

Epoch: 6| Step: 5
Training loss: 2.051595687866211
Validation loss: 2.0840395092964172

Epoch: 6| Step: 6
Training loss: 1.5743043422698975
Validation loss: 2.064132829507192

Epoch: 6| Step: 7
Training loss: 2.3582165241241455
Validation loss: 2.060758570830027

Epoch: 6| Step: 8
Training loss: 2.6571741104125977
Validation loss: 2.0621724923451743

Epoch: 6| Step: 9
Training loss: 1.786195993423462
Validation loss: 2.0686937967936196

Epoch: 6| Step: 10
Training loss: 2.1265549659729004
Validation loss: 2.0706597566604614

Epoch: 6| Step: 11
Training loss: 2.623297691345215
Validation loss: 2.0851279894510903

Epoch: 6| Step: 12
Training loss: 2.6403391361236572
Validation loss: 2.0778589049975076

Epoch: 6| Step: 13
Training loss: 2.043732166290283
Validation loss: 2.078613579273224

Epoch: 62| Step: 0
Training loss: 2.6361563205718994
Validation loss: 2.084161361058553

Epoch: 6| Step: 1
Training loss: 2.444870710372925
Validation loss: 2.08406800031662

Epoch: 6| Step: 2
Training loss: 2.228175163269043
Validation loss: 2.0834826032320657

Epoch: 6| Step: 3
Training loss: 2.7597463130950928
Validation loss: 2.0804755290349326

Epoch: 6| Step: 4
Training loss: 1.3514823913574219
Validation loss: 2.0741931597391763

Epoch: 6| Step: 5
Training loss: 2.445690631866455
Validation loss: 2.072499930858612

Epoch: 6| Step: 6
Training loss: 2.271488904953003
Validation loss: 2.0633515119552612

Epoch: 6| Step: 7
Training loss: 2.3807592391967773
Validation loss: 2.070908486843109

Epoch: 6| Step: 8
Training loss: 2.371577024459839
Validation loss: 2.069742759068807

Epoch: 6| Step: 9
Training loss: 1.5666368007659912
Validation loss: 2.068677067756653

Epoch: 6| Step: 10
Training loss: 1.841294765472412
Validation loss: 2.070897102355957

Epoch: 6| Step: 11
Training loss: 2.3810102939605713
Validation loss: 2.063601036866506

Epoch: 6| Step: 12
Training loss: 2.5737948417663574
Validation loss: 2.059831202030182

Epoch: 6| Step: 13
Training loss: 2.2121219635009766
Validation loss: 2.0542566776275635

Epoch: 63| Step: 0
Training loss: 2.2161455154418945
Validation loss: 2.0564786990483603

Epoch: 6| Step: 1
Training loss: 3.0255966186523438
Validation loss: 2.0669894417126975

Epoch: 6| Step: 2
Training loss: 2.3403990268707275
Validation loss: 2.065385321776072

Epoch: 6| Step: 3
Training loss: 2.4313900470733643
Validation loss: 2.0810211896896362

Epoch: 6| Step: 4
Training loss: 2.9111180305480957
Validation loss: 2.0851588447888694

Epoch: 6| Step: 5
Training loss: 2.172973394393921
Validation loss: 2.0722147027651467

Epoch: 6| Step: 6
Training loss: 2.8188717365264893
Validation loss: 2.0681744813919067

Epoch: 6| Step: 7
Training loss: 2.0069937705993652
Validation loss: 2.059306263923645

Epoch: 6| Step: 8
Training loss: 1.266857624053955
Validation loss: 2.0649818579355874

Epoch: 6| Step: 9
Training loss: 1.6678719520568848
Validation loss: 2.061324199040731

Epoch: 6| Step: 10
Training loss: 1.8707160949707031
Validation loss: 2.066901365915934

Epoch: 6| Step: 11
Training loss: 2.0887362957000732
Validation loss: 2.0676656564076743

Epoch: 6| Step: 12
Training loss: 2.157815456390381
Validation loss: 2.0757657289505005

Epoch: 6| Step: 13
Training loss: 2.3687145709991455
Validation loss: 2.0814924041430154

Epoch: 64| Step: 0
Training loss: 2.1252057552337646
Validation loss: 2.0627792278925576

Epoch: 6| Step: 1
Training loss: 2.6404807567596436
Validation loss: 2.065933088461558

Epoch: 6| Step: 2
Training loss: 2.346052885055542
Validation loss: 2.069218377272288

Epoch: 6| Step: 3
Training loss: 1.9437236785888672
Validation loss: 2.0553890268007913

Epoch: 6| Step: 4
Training loss: 1.836338758468628
Validation loss: 2.0522453586260476

Epoch: 6| Step: 5
Training loss: 2.331118106842041
Validation loss: 2.0499136050542197

Epoch: 6| Step: 6
Training loss: 2.2693753242492676
Validation loss: 2.047500709692637

Epoch: 6| Step: 7
Training loss: 2.0252864360809326
Validation loss: 2.0391750931739807

Epoch: 6| Step: 8
Training loss: 2.194225549697876
Validation loss: 2.042944371700287

Epoch: 6| Step: 9
Training loss: 2.4021921157836914
Validation loss: 2.0394899447758994

Epoch: 6| Step: 10
Training loss: 2.1229472160339355
Validation loss: 2.029400885105133

Epoch: 6| Step: 11
Training loss: 2.1903443336486816
Validation loss: 2.04025928179423

Epoch: 6| Step: 12
Training loss: 2.1269893646240234
Validation loss: 2.0635096033414206

Epoch: 6| Step: 13
Training loss: 2.5903141498565674
Validation loss: 2.074805279572805

Epoch: 65| Step: 0
Training loss: 2.4957499504089355
Validation loss: 2.0878233114878335

Epoch: 6| Step: 1
Training loss: 2.3870532512664795
Validation loss: 2.0781168739000955

Epoch: 6| Step: 2
Training loss: 2.05302357673645
Validation loss: 2.099997023741404

Epoch: 6| Step: 3
Training loss: 1.6997191905975342
Validation loss: 2.0811884800593057

Epoch: 6| Step: 4
Training loss: 2.6482887268066406
Validation loss: 2.0759498476982117

Epoch: 6| Step: 5
Training loss: 1.9999780654907227
Validation loss: 2.0764084458351135

Epoch: 6| Step: 6
Training loss: 1.652422547340393
Validation loss: 2.0821367502212524

Epoch: 6| Step: 7
Training loss: 2.546595573425293
Validation loss: 2.061852832635244

Epoch: 6| Step: 8
Training loss: 2.2826998233795166
Validation loss: 2.048636257648468

Epoch: 6| Step: 9
Training loss: 2.1883111000061035
Validation loss: 2.0491177837053933

Epoch: 6| Step: 10
Training loss: 2.5613961219787598
Validation loss: 2.050350030263265

Epoch: 6| Step: 11
Training loss: 2.864534616470337
Validation loss: 2.04636949300766

Epoch: 6| Step: 12
Training loss: 1.894972801208496
Validation loss: 2.0396971901257834

Epoch: 6| Step: 13
Training loss: 1.7273062467575073
Validation loss: 2.0509185592333474

Epoch: 66| Step: 0
Training loss: 2.1653308868408203
Validation loss: 2.0415491859118142

Epoch: 6| Step: 1
Training loss: 2.724773645401001
Validation loss: 2.041142741839091

Epoch: 6| Step: 2
Training loss: 2.000455379486084
Validation loss: 2.040778418382009

Epoch: 6| Step: 3
Training loss: 2.2630012035369873
Validation loss: 2.0369308590888977

Epoch: 6| Step: 4
Training loss: 2.615453004837036
Validation loss: 2.0380807320276895

Epoch: 6| Step: 5
Training loss: 2.5626068115234375
Validation loss: 2.043192128340403

Epoch: 6| Step: 6
Training loss: 2.5704283714294434
Validation loss: 2.058767298857371

Epoch: 6| Step: 7
Training loss: 1.8457427024841309
Validation loss: 2.0571056604385376

Epoch: 6| Step: 8
Training loss: 2.110229015350342
Validation loss: 2.066129227479299

Epoch: 6| Step: 9
Training loss: 2.1010375022888184
Validation loss: 2.0595353643099465

Epoch: 6| Step: 10
Training loss: 1.7110447883605957
Validation loss: 2.0526256759961448

Epoch: 6| Step: 11
Training loss: 2.375542163848877
Validation loss: 2.057687222957611

Epoch: 6| Step: 12
Training loss: 1.691401720046997
Validation loss: 2.038338283697764

Epoch: 6| Step: 13
Training loss: 2.2296578884124756
Validation loss: 2.02546234925588

Epoch: 67| Step: 0
Training loss: 1.832600474357605
Validation loss: 2.0356560150782266

Epoch: 6| Step: 1
Training loss: 2.6392204761505127
Validation loss: 2.0411691864331565

Epoch: 6| Step: 2
Training loss: 2.203859567642212
Validation loss: 2.0479163924853006

Epoch: 6| Step: 3
Training loss: 2.0042595863342285
Validation loss: 2.0484225352605185

Epoch: 6| Step: 4
Training loss: 2.422063112258911
Validation loss: 2.049656013647715

Epoch: 6| Step: 5
Training loss: 2.3671021461486816
Validation loss: 2.0466644366582236

Epoch: 6| Step: 6
Training loss: 2.4753856658935547
Validation loss: 2.0492236216863

Epoch: 6| Step: 7
Training loss: 2.0594775676727295
Validation loss: 2.044584651788076

Epoch: 6| Step: 8
Training loss: 2.6036581993103027
Validation loss: 2.0438933769861856

Epoch: 6| Step: 9
Training loss: 2.716942548751831
Validation loss: 2.0489732027053833

Epoch: 6| Step: 10
Training loss: 2.368913173675537
Validation loss: 2.0505956013997397

Epoch: 6| Step: 11
Training loss: 1.7832014560699463
Validation loss: 2.0494410196940103

Epoch: 6| Step: 12
Training loss: 1.884944200515747
Validation loss: 2.0353597005208335

Epoch: 6| Step: 13
Training loss: 1.7038654088974
Validation loss: 2.0365049640337625

Epoch: 68| Step: 0
Training loss: 1.7914687395095825
Validation loss: 2.037721335887909

Epoch: 6| Step: 1
Training loss: 2.734259605407715
Validation loss: 2.034713546435038

Epoch: 6| Step: 2
Training loss: 1.82552170753479
Validation loss: 2.0335001945495605

Epoch: 6| Step: 3
Training loss: 2.5064454078674316
Validation loss: 2.035924474398295

Epoch: 6| Step: 4
Training loss: 2.2435336112976074
Validation loss: 2.0344359278678894

Epoch: 6| Step: 5
Training loss: 2.0474114418029785
Validation loss: 2.0373425086339316

Epoch: 6| Step: 6
Training loss: 1.8775759935379028
Validation loss: 2.045158565044403

Epoch: 6| Step: 7
Training loss: 2.18013334274292
Validation loss: 2.0551639795303345

Epoch: 6| Step: 8
Training loss: 1.408719539642334
Validation loss: 2.0644973317782083

Epoch: 6| Step: 9
Training loss: 2.370940685272217
Validation loss: 2.090432822704315

Epoch: 6| Step: 10
Training loss: 2.3587334156036377
Validation loss: 2.095530152320862

Epoch: 6| Step: 11
Training loss: 2.462939977645874
Validation loss: 2.1177828907966614

Epoch: 6| Step: 12
Training loss: 2.8899097442626953
Validation loss: 2.109450578689575

Epoch: 6| Step: 13
Training loss: 2.3587279319763184
Validation loss: 2.086184859275818

Epoch: 69| Step: 0
Training loss: 2.6431963443756104
Validation loss: 2.0831695993741355

Epoch: 6| Step: 1
Training loss: 2.1589622497558594
Validation loss: 2.0495044191678367

Epoch: 6| Step: 2
Training loss: 1.9479098320007324
Validation loss: 2.0373257199923196

Epoch: 6| Step: 3
Training loss: 2.0611753463745117
Validation loss: 2.03726327419281

Epoch: 6| Step: 4
Training loss: 1.7494635581970215
Validation loss: 2.0368086298306785

Epoch: 6| Step: 5
Training loss: 3.0476646423339844
Validation loss: 2.0462193886439004

Epoch: 6| Step: 6
Training loss: 2.663299798965454
Validation loss: 2.0468251506487527

Epoch: 6| Step: 7
Training loss: 2.346597194671631
Validation loss: 2.047511080900828

Epoch: 6| Step: 8
Training loss: 1.882215976715088
Validation loss: 2.052011251449585

Epoch: 6| Step: 9
Training loss: 2.3495993614196777
Validation loss: 2.053874691327413

Epoch: 6| Step: 10
Training loss: 2.414299249649048
Validation loss: 2.0494596560796103

Epoch: 6| Step: 11
Training loss: 1.4128899574279785
Validation loss: 2.051708916823069

Epoch: 6| Step: 12
Training loss: 2.287994861602783
Validation loss: 2.0500898559888205

Epoch: 6| Step: 13
Training loss: 2.0592854022979736
Validation loss: 2.0429004232088723

Epoch: 70| Step: 0
Training loss: 2.312561511993408
Validation loss: 2.0416653553644815

Epoch: 6| Step: 1
Training loss: 2.079920530319214
Validation loss: 2.032003164291382

Epoch: 6| Step: 2
Training loss: 2.5970382690429688
Validation loss: 2.030629495779673

Epoch: 6| Step: 3
Training loss: 1.7484235763549805
Validation loss: 2.0199245611826577

Epoch: 6| Step: 4
Training loss: 2.3610615730285645
Validation loss: 2.018190085887909

Epoch: 6| Step: 5
Training loss: 2.689182996749878
Validation loss: 2.021596113840739

Epoch: 6| Step: 6
Training loss: 1.770521640777588
Validation loss: 2.0390764673550925

Epoch: 6| Step: 7
Training loss: 2.0470852851867676
Validation loss: 2.0453092058499656

Epoch: 6| Step: 8
Training loss: 2.0715017318725586
Validation loss: 2.0490796168645224

Epoch: 6| Step: 9
Training loss: 2.524282693862915
Validation loss: 2.068152646223704

Epoch: 6| Step: 10
Training loss: 2.5556530952453613
Validation loss: 2.0680211186408997

Epoch: 6| Step: 11
Training loss: 1.7506364583969116
Validation loss: 2.0699752966562905

Epoch: 6| Step: 12
Training loss: 2.3820810317993164
Validation loss: 2.0767601132392883

Epoch: 6| Step: 13
Training loss: 1.7121284008026123
Validation loss: 2.060811916987101

Epoch: 71| Step: 0
Training loss: 2.364424467086792
Validation loss: 2.0702874660491943

Epoch: 6| Step: 1
Training loss: 1.6798887252807617
Validation loss: 2.0452510515848794

Epoch: 6| Step: 2
Training loss: 1.9049468040466309
Validation loss: 2.0230191349983215

Epoch: 6| Step: 3
Training loss: 1.64037024974823
Validation loss: 2.014520585536957

Epoch: 6| Step: 4
Training loss: 2.310133457183838
Validation loss: 2.02153209845225

Epoch: 6| Step: 5
Training loss: 2.0769119262695312
Validation loss: 2.0157307187716165

Epoch: 6| Step: 6
Training loss: 2.1031551361083984
Validation loss: 2.020773390928904

Epoch: 6| Step: 7
Training loss: 1.586310625076294
Validation loss: 2.0179309447606406

Epoch: 6| Step: 8
Training loss: 2.628962755203247
Validation loss: 2.014613389968872

Epoch: 6| Step: 9
Training loss: 2.535243511199951
Validation loss: 2.0207486947377524

Epoch: 6| Step: 10
Training loss: 2.09741473197937
Validation loss: 2.030061423778534

Epoch: 6| Step: 11
Training loss: 2.689974546432495
Validation loss: 2.0433074633280435

Epoch: 6| Step: 12
Training loss: 2.8783936500549316
Validation loss: 2.0398876667022705

Epoch: 6| Step: 13
Training loss: 1.9739539623260498
Validation loss: 2.0346803665161133

Epoch: 72| Step: 0
Training loss: 1.9901281595230103
Validation loss: 2.036949038505554

Epoch: 6| Step: 1
Training loss: 1.9291622638702393
Validation loss: 2.0444973905881247

Epoch: 6| Step: 2
Training loss: 2.256807327270508
Validation loss: 2.0360854069391885

Epoch: 6| Step: 3
Training loss: 2.856679916381836
Validation loss: 2.0277592539787292

Epoch: 6| Step: 4
Training loss: 2.792245626449585
Validation loss: 2.036278704802195

Epoch: 6| Step: 5
Training loss: 2.274585247039795
Validation loss: 2.025860071182251

Epoch: 6| Step: 6
Training loss: 2.137204885482788
Validation loss: 2.042633295059204

Epoch: 6| Step: 7
Training loss: 1.8352495431900024
Validation loss: 2.0333672960599265

Epoch: 6| Step: 8
Training loss: 1.7311670780181885
Validation loss: 2.036718229452769

Epoch: 6| Step: 9
Training loss: 2.6643381118774414
Validation loss: 2.042359411716461

Epoch: 6| Step: 10
Training loss: 2.13748836517334
Validation loss: 2.0346816579500833

Epoch: 6| Step: 11
Training loss: 1.6874406337738037
Validation loss: 2.0353747407595315

Epoch: 6| Step: 12
Training loss: 2.0589442253112793
Validation loss: 2.0306886037190757

Epoch: 6| Step: 13
Training loss: 2.4063076972961426
Validation loss: 2.0181932051976523

Epoch: 73| Step: 0
Training loss: 3.1237621307373047
Validation loss: 2.0252235929171243

Epoch: 6| Step: 1
Training loss: 1.8750945329666138
Validation loss: 2.0286090771357217

Epoch: 6| Step: 2
Training loss: 1.9972676038742065
Validation loss: 2.0347699324289956

Epoch: 6| Step: 3
Training loss: 2.3532164096832275
Validation loss: 2.044355491797129

Epoch: 6| Step: 4
Training loss: 2.3011839389801025
Validation loss: 2.0539501508076987

Epoch: 6| Step: 5
Training loss: 1.6767358779907227
Validation loss: 2.066667596499125

Epoch: 6| Step: 6
Training loss: 1.707671880722046
Validation loss: 2.071138620376587

Epoch: 6| Step: 7
Training loss: 2.7462821006774902
Validation loss: 2.0758609970410666

Epoch: 6| Step: 8
Training loss: 1.5646119117736816
Validation loss: 2.080851455529531

Epoch: 6| Step: 9
Training loss: 2.774627685546875
Validation loss: 2.0852651596069336

Epoch: 6| Step: 10
Training loss: 1.7152642011642456
Validation loss: 2.0656713247299194

Epoch: 6| Step: 11
Training loss: 2.183870315551758
Validation loss: 2.0500734448432922

Epoch: 6| Step: 12
Training loss: 2.3703064918518066
Validation loss: 2.0286689599355063

Epoch: 6| Step: 13
Training loss: 2.3233799934387207
Validation loss: 2.020880122979482

Epoch: 74| Step: 0
Training loss: 2.023393392562866
Validation loss: 2.0347233215967813

Epoch: 6| Step: 1
Training loss: 2.3854548931121826
Validation loss: 2.0376288493474326

Epoch: 6| Step: 2
Training loss: 2.7692275047302246
Validation loss: 2.0409477949142456

Epoch: 6| Step: 3
Training loss: 2.2281835079193115
Validation loss: 2.0591006676355996

Epoch: 6| Step: 4
Training loss: 2.225595474243164
Validation loss: 2.061890880266825

Epoch: 6| Step: 5
Training loss: 1.9438657760620117
Validation loss: 2.0609883069992065

Epoch: 6| Step: 6
Training loss: 1.6340265274047852
Validation loss: 2.061542054017385

Epoch: 6| Step: 7
Training loss: 2.4569549560546875
Validation loss: 2.065553585688273

Epoch: 6| Step: 8
Training loss: 2.972925901412964
Validation loss: 2.0640350381533303

Epoch: 6| Step: 9
Training loss: 2.156663179397583
Validation loss: 2.069948653380076

Epoch: 6| Step: 10
Training loss: 2.527641773223877
Validation loss: 2.0667536854743958

Epoch: 6| Step: 11
Training loss: 1.9246580600738525
Validation loss: 2.064417282740275

Epoch: 6| Step: 12
Training loss: 2.165403366088867
Validation loss: 2.0579068462053933

Epoch: 6| Step: 13
Training loss: 2.0108437538146973
Validation loss: 2.0531476736068726

Epoch: 75| Step: 0
Training loss: 2.0315051078796387
Validation loss: 2.0577423572540283

Epoch: 6| Step: 1
Training loss: 3.005133867263794
Validation loss: 2.0503087441126504

Epoch: 6| Step: 2
Training loss: 1.9686403274536133
Validation loss: 2.0494611064592996

Epoch: 6| Step: 3
Training loss: 2.2317843437194824
Validation loss: 2.042642672856649

Epoch: 6| Step: 4
Training loss: 2.064694881439209
Validation loss: 2.0552214980125427

Epoch: 6| Step: 5
Training loss: 2.857267141342163
Validation loss: 2.042878190676371

Epoch: 6| Step: 6
Training loss: 2.7991960048675537
Validation loss: 2.037843902905782

Epoch: 6| Step: 7
Training loss: 1.8882877826690674
Validation loss: 2.038216690222422

Epoch: 6| Step: 8
Training loss: 2.247954845428467
Validation loss: 2.0348512331644693

Epoch: 6| Step: 9
Training loss: 1.825993537902832
Validation loss: 2.031059285004934

Epoch: 6| Step: 10
Training loss: 1.7427752017974854
Validation loss: 2.032183070977529

Epoch: 6| Step: 11
Training loss: 1.8006737232208252
Validation loss: 2.029205242792765

Epoch: 6| Step: 12
Training loss: 2.019486665725708
Validation loss: 2.046654005845388

Epoch: 6| Step: 13
Training loss: 1.8110032081604004
Validation loss: 2.0641070206960044

Epoch: 76| Step: 0
Training loss: 2.5196948051452637
Validation loss: 2.0709298054377236

Epoch: 6| Step: 1
Training loss: 2.6245460510253906
Validation loss: 2.083045462767283

Epoch: 6| Step: 2
Training loss: 2.2824485301971436
Validation loss: 2.0610206723213196

Epoch: 6| Step: 3
Training loss: 2.4632022380828857
Validation loss: 2.0417284766832986

Epoch: 6| Step: 4
Training loss: 2.2180635929107666
Validation loss: 2.046322305997213

Epoch: 6| Step: 5
Training loss: 1.830817699432373
Validation loss: 2.029199719429016

Epoch: 6| Step: 6
Training loss: 1.8023850917816162
Validation loss: 2.034069279829661

Epoch: 6| Step: 7
Training loss: 2.012141227722168
Validation loss: 2.020865281422933

Epoch: 6| Step: 8
Training loss: 1.7964451313018799
Validation loss: 2.0312761068344116

Epoch: 6| Step: 9
Training loss: 2.0646138191223145
Validation loss: 2.0312806367874146

Epoch: 6| Step: 10
Training loss: 2.4249916076660156
Validation loss: 2.0319298108418784

Epoch: 6| Step: 11
Training loss: 2.2776308059692383
Validation loss: 2.028901517391205

Epoch: 6| Step: 12
Training loss: 2.4774327278137207
Validation loss: 2.0302391052246094

Epoch: 6| Step: 13
Training loss: 1.8569748401641846
Validation loss: 2.029904822508494

Epoch: 77| Step: 0
Training loss: 2.0033934116363525
Validation loss: 2.0262308716773987

Epoch: 6| Step: 1
Training loss: 2.627549409866333
Validation loss: 2.023327589035034

Epoch: 6| Step: 2
Training loss: 2.726078987121582
Validation loss: 2.0171099503835044

Epoch: 6| Step: 3
Training loss: 1.9246392250061035
Validation loss: 2.020203868548075

Epoch: 6| Step: 4
Training loss: 2.181680679321289
Validation loss: 2.028444210688273

Epoch: 6| Step: 5
Training loss: 1.8912204504013062
Validation loss: 2.0122777819633484

Epoch: 6| Step: 6
Training loss: 2.174351692199707
Validation loss: 2.0254077911376953

Epoch: 6| Step: 7
Training loss: 1.8163378238677979
Validation loss: 2.014721930027008

Epoch: 6| Step: 8
Training loss: 2.1906204223632812
Validation loss: 2.019916574160258

Epoch: 6| Step: 9
Training loss: 2.02009654045105
Validation loss: 2.033257762591044

Epoch: 6| Step: 10
Training loss: 2.2702510356903076
Validation loss: 2.0507118105888367

Epoch: 6| Step: 11
Training loss: 2.1987671852111816
Validation loss: 2.071078916390737

Epoch: 6| Step: 12
Training loss: 2.1622283458709717
Validation loss: 2.0632541179656982

Epoch: 6| Step: 13
Training loss: 2.269929885864258
Validation loss: 2.0623740951220193

Epoch: 78| Step: 0
Training loss: 2.2599449157714844
Validation loss: 2.0604180097579956

Epoch: 6| Step: 1
Training loss: 1.9919335842132568
Validation loss: 2.040888706843058

Epoch: 6| Step: 2
Training loss: 2.350295066833496
Validation loss: 2.040034373601278

Epoch: 6| Step: 3
Training loss: 1.8815847635269165
Validation loss: 2.036876161893209

Epoch: 6| Step: 4
Training loss: 2.4259181022644043
Validation loss: 2.021727502346039

Epoch: 6| Step: 5
Training loss: 1.6946150064468384
Validation loss: 2.0200246969858804

Epoch: 6| Step: 6
Training loss: 2.2659378051757812
Validation loss: 2.0227086544036865

Epoch: 6| Step: 7
Training loss: 1.5984315872192383
Validation loss: 2.028053343296051

Epoch: 6| Step: 8
Training loss: 2.7423453330993652
Validation loss: 2.031914492448171

Epoch: 6| Step: 9
Training loss: 2.5928783416748047
Validation loss: 2.0346741676330566

Epoch: 6| Step: 10
Training loss: 2.2397499084472656
Validation loss: 2.044797162214915

Epoch: 6| Step: 11
Training loss: 2.1699845790863037
Validation loss: 2.055626690387726

Epoch: 6| Step: 12
Training loss: 1.8508309125900269
Validation loss: 2.0542027751604715

Epoch: 6| Step: 13
Training loss: 2.3714842796325684
Validation loss: 2.0452407797177634

Epoch: 79| Step: 0
Training loss: 2.61752986907959
Validation loss: 2.0385727286338806

Epoch: 6| Step: 1
Training loss: 1.9535231590270996
Validation loss: 2.0235361655553183

Epoch: 6| Step: 2
Training loss: 2.4339818954467773
Validation loss: 2.0106313228607178

Epoch: 6| Step: 3
Training loss: 2.2821788787841797
Validation loss: 2.019789675871531

Epoch: 6| Step: 4
Training loss: 1.7278919219970703
Validation loss: 2.0145079493522644

Epoch: 6| Step: 5
Training loss: 1.45530366897583
Validation loss: 2.0058936278025308

Epoch: 6| Step: 6
Training loss: 1.9819470643997192
Validation loss: 2.011227091153463

Epoch: 6| Step: 7
Training loss: 2.4776039123535156
Validation loss: 2.0100240310033164

Epoch: 6| Step: 8
Training loss: 2.160794496536255
Validation loss: 2.0069889227549234

Epoch: 6| Step: 9
Training loss: 2.6450560092926025
Validation loss: 2.0130296548207602

Epoch: 6| Step: 10
Training loss: 1.9947259426116943
Validation loss: 2.0197132428487143

Epoch: 6| Step: 11
Training loss: 1.9295059442520142
Validation loss: 2.007715920607249

Epoch: 6| Step: 12
Training loss: 2.3146393299102783
Validation loss: 2.016649385293325

Epoch: 6| Step: 13
Training loss: 2.2763357162475586
Validation loss: 2.0232404867808023

Epoch: 80| Step: 0
Training loss: 1.7735354900360107
Validation loss: 2.022120495637258

Epoch: 6| Step: 1
Training loss: 1.747853398323059
Validation loss: 2.0363466342290244

Epoch: 6| Step: 2
Training loss: 2.2045726776123047
Validation loss: 2.056882599989573

Epoch: 6| Step: 3
Training loss: 2.5878512859344482
Validation loss: 2.0770300229390464

Epoch: 6| Step: 4
Training loss: 2.8672871589660645
Validation loss: 2.107570707798004

Epoch: 6| Step: 5
Training loss: 2.8765928745269775
Validation loss: 2.097673237323761

Epoch: 6| Step: 6
Training loss: 2.540341854095459
Validation loss: 2.10532816251119

Epoch: 6| Step: 7
Training loss: 1.6637353897094727
Validation loss: 2.0911154747009277

Epoch: 6| Step: 8
Training loss: 2.121307373046875
Validation loss: 2.055865248044332

Epoch: 6| Step: 9
Training loss: 1.7010823488235474
Validation loss: 2.043665806452433

Epoch: 6| Step: 10
Training loss: 1.921412467956543
Validation loss: 2.0353970527648926

Epoch: 6| Step: 11
Training loss: 2.50819730758667
Validation loss: 2.022651811440786

Epoch: 6| Step: 12
Training loss: 2.133239507675171
Validation loss: 2.0200534661610923

Epoch: 6| Step: 13
Training loss: 2.1626853942871094
Validation loss: 2.008805274963379

Epoch: 81| Step: 0
Training loss: 2.337162733078003
Validation loss: 2.0129245718320212

Epoch: 6| Step: 1
Training loss: 2.007373332977295
Validation loss: 2.016350487867991

Epoch: 6| Step: 2
Training loss: 2.5072474479675293
Validation loss: 2.0168380538622537

Epoch: 6| Step: 3
Training loss: 1.9647902250289917
Validation loss: 2.0210816065470376

Epoch: 6| Step: 4
Training loss: 1.5248790979385376
Validation loss: 2.015995144844055

Epoch: 6| Step: 5
Training loss: 2.340632915496826
Validation loss: 2.0178236961364746

Epoch: 6| Step: 6
Training loss: 2.0382425785064697
Validation loss: 2.012256105740865

Epoch: 6| Step: 7
Training loss: 1.7409453392028809
Validation loss: 2.0177767674128213

Epoch: 6| Step: 8
Training loss: 2.4327571392059326
Validation loss: 2.0061568220456443

Epoch: 6| Step: 9
Training loss: 2.0906429290771484
Validation loss: 2.0051850080490112

Epoch: 6| Step: 10
Training loss: 2.669569492340088
Validation loss: 2.00674839814504

Epoch: 6| Step: 11
Training loss: 2.155768871307373
Validation loss: 2.0111812949180603

Epoch: 6| Step: 12
Training loss: 2.1255626678466797
Validation loss: 2.005486170450846

Epoch: 6| Step: 13
Training loss: 2.56571102142334
Validation loss: 2.0094115138053894

Epoch: 82| Step: 0
Training loss: 2.0861082077026367
Validation loss: 2.0064900517463684

Epoch: 6| Step: 1
Training loss: 1.578879714012146
Validation loss: 2.019722282886505

Epoch: 6| Step: 2
Training loss: 1.9786498546600342
Validation loss: 2.017431934674581

Epoch: 6| Step: 3
Training loss: 2.5547475814819336
Validation loss: 2.0438814560572305

Epoch: 6| Step: 4
Training loss: 2.3308639526367188
Validation loss: 2.0698901216189065

Epoch: 6| Step: 5
Training loss: 2.295048236846924
Validation loss: 2.089025835196177

Epoch: 6| Step: 6
Training loss: 2.5184764862060547
Validation loss: 2.105436066786448

Epoch: 6| Step: 7
Training loss: 1.8963334560394287
Validation loss: 2.099599540233612

Epoch: 6| Step: 8
Training loss: 1.885124921798706
Validation loss: 2.0791448950767517

Epoch: 6| Step: 9
Training loss: 2.6248703002929688
Validation loss: 2.054714302221934

Epoch: 6| Step: 10
Training loss: 2.012204647064209
Validation loss: 2.036604106426239

Epoch: 6| Step: 11
Training loss: 2.6383838653564453
Validation loss: 2.0295627315839133

Epoch: 6| Step: 12
Training loss: 2.212313652038574
Validation loss: 2.012966533501943

Epoch: 6| Step: 13
Training loss: 1.981990933418274
Validation loss: 2.0198240280151367

Epoch: 83| Step: 0
Training loss: 2.5022976398468018
Validation loss: 2.0194839239120483

Epoch: 6| Step: 1
Training loss: 1.6458349227905273
Validation loss: 2.029446244239807

Epoch: 6| Step: 2
Training loss: 2.622429847717285
Validation loss: 2.0210026502609253

Epoch: 6| Step: 3
Training loss: 1.9955452680587769
Validation loss: 2.024887959162394

Epoch: 6| Step: 4
Training loss: 2.016873836517334
Validation loss: 2.029858430226644

Epoch: 6| Step: 5
Training loss: 2.1599836349487305
Validation loss: 2.0297955671946206

Epoch: 6| Step: 6
Training loss: 1.8738179206848145
Validation loss: 2.0380199948946633

Epoch: 6| Step: 7
Training loss: 2.2929067611694336
Validation loss: 2.0310837229092917

Epoch: 6| Step: 8
Training loss: 2.637153148651123
Validation loss: 2.0345254143079123

Epoch: 6| Step: 9
Training loss: 1.829854965209961
Validation loss: 2.0360017816225686

Epoch: 6| Step: 10
Training loss: 2.2971396446228027
Validation loss: 2.0296096007029214

Epoch: 6| Step: 11
Training loss: 1.7251392602920532
Validation loss: 2.0319813887278237

Epoch: 6| Step: 12
Training loss: 2.6453304290771484
Validation loss: 2.0247153838475547

Epoch: 6| Step: 13
Training loss: 2.307852029800415
Validation loss: 2.0327133735020957

Epoch: 84| Step: 0
Training loss: 1.9498157501220703
Validation loss: 2.023306667804718

Epoch: 6| Step: 1
Training loss: 2.7778873443603516
Validation loss: 2.0327731370925903

Epoch: 6| Step: 2
Training loss: 2.4455811977386475
Validation loss: 2.0294894178708396

Epoch: 6| Step: 3
Training loss: 1.847927212715149
Validation loss: 2.027963161468506

Epoch: 6| Step: 4
Training loss: 2.2019124031066895
Validation loss: 2.0325632294019065

Epoch: 6| Step: 5
Training loss: 1.903336524963379
Validation loss: 2.0334431727727256

Epoch: 6| Step: 6
Training loss: 2.085298538208008
Validation loss: 2.03919780254364

Epoch: 6| Step: 7
Training loss: 1.660311222076416
Validation loss: 2.02559228738149

Epoch: 6| Step: 8
Training loss: 2.3455214500427246
Validation loss: 2.0326064427693686

Epoch: 6| Step: 9
Training loss: 2.64921498298645
Validation loss: 2.0240029295285544

Epoch: 6| Step: 10
Training loss: 1.8965957164764404
Validation loss: 2.017137289047241

Epoch: 6| Step: 11
Training loss: 2.0747485160827637
Validation loss: 2.0221028526624045

Epoch: 6| Step: 12
Training loss: 2.6786842346191406
Validation loss: 2.0222950180371604

Epoch: 6| Step: 13
Training loss: 1.9083691835403442
Validation loss: 2.0161574482917786

Epoch: 85| Step: 0
Training loss: 2.5514211654663086
Validation loss: 2.023584504922231

Epoch: 6| Step: 1
Training loss: 1.8443652391433716
Validation loss: 2.0296380718549094

Epoch: 6| Step: 2
Training loss: 2.161149501800537
Validation loss: 2.0265747904777527

Epoch: 6| Step: 3
Training loss: 1.9535585641860962
Validation loss: 2.021426538626353

Epoch: 6| Step: 4
Training loss: 1.575575590133667
Validation loss: 2.0174705584843955

Epoch: 6| Step: 5
Training loss: 2.235043525695801
Validation loss: 2.02281191945076

Epoch: 6| Step: 6
Training loss: 1.6136462688446045
Validation loss: 2.0288011034329734

Epoch: 6| Step: 7
Training loss: 2.199510097503662
Validation loss: 2.021617273489634

Epoch: 6| Step: 8
Training loss: 2.1458606719970703
Validation loss: 2.0293917457262673

Epoch: 6| Step: 9
Training loss: 2.4063615798950195
Validation loss: 2.02798859278361

Epoch: 6| Step: 10
Training loss: 2.2475533485412598
Validation loss: 2.0394980112711587

Epoch: 6| Step: 11
Training loss: 2.5602145195007324
Validation loss: 2.0522612730662027

Epoch: 6| Step: 12
Training loss: 2.4824206829071045
Validation loss: 2.0540197690327964

Epoch: 6| Step: 13
Training loss: 2.2871038913726807
Validation loss: 2.056135058403015

Epoch: 86| Step: 0
Training loss: 1.9325566291809082
Validation loss: 2.0537537733713784

Epoch: 6| Step: 1
Training loss: 2.6420490741729736
Validation loss: 2.04910417397817

Epoch: 6| Step: 2
Training loss: 2.208049774169922
Validation loss: 2.0369441509246826

Epoch: 6| Step: 3
Training loss: 2.1827805042266846
Validation loss: 2.0289610425631204

Epoch: 6| Step: 4
Training loss: 1.742203950881958
Validation loss: 2.027588148911794

Epoch: 6| Step: 5
Training loss: 2.0986151695251465
Validation loss: 2.0281595985094705

Epoch: 6| Step: 6
Training loss: 2.585728645324707
Validation loss: 2.0278862714767456

Epoch: 6| Step: 7
Training loss: 2.1910548210144043
Validation loss: 2.0266557931900024

Epoch: 6| Step: 8
Training loss: 1.7357544898986816
Validation loss: 2.0211241443951926

Epoch: 6| Step: 9
Training loss: 2.364380359649658
Validation loss: 2.0217129786809287

Epoch: 6| Step: 10
Training loss: 1.9456630945205688
Validation loss: 2.0323010285695395

Epoch: 6| Step: 11
Training loss: 2.1541335582733154
Validation loss: 2.026803274949392

Epoch: 6| Step: 12
Training loss: 2.433258056640625
Validation loss: 2.0350045561790466

Epoch: 6| Step: 13
Training loss: 1.7950246334075928
Validation loss: 2.028909603754679

Epoch: 87| Step: 0
Training loss: 2.3170807361602783
Validation loss: 2.033240477244059

Epoch: 6| Step: 1
Training loss: 1.6871949434280396
Validation loss: 2.022375166416168

Epoch: 6| Step: 2
Training loss: 2.7898430824279785
Validation loss: 2.0272329250971475

Epoch: 6| Step: 3
Training loss: 2.240109920501709
Validation loss: 2.0186559359232583

Epoch: 6| Step: 4
Training loss: 2.104161500930786
Validation loss: 2.0308393637339273

Epoch: 6| Step: 5
Training loss: 2.184727668762207
Validation loss: 2.024846613407135

Epoch: 6| Step: 6
Training loss: 1.9376412630081177
Validation loss: 2.0410773754119873

Epoch: 6| Step: 7
Training loss: 1.9715619087219238
Validation loss: 2.0352694590886435

Epoch: 6| Step: 8
Training loss: 2.291167736053467
Validation loss: 2.0325438380241394

Epoch: 6| Step: 9
Training loss: 1.48984694480896
Validation loss: 2.0356825788815818

Epoch: 6| Step: 10
Training loss: 2.2545416355133057
Validation loss: 2.036054273446401

Epoch: 6| Step: 11
Training loss: 2.239180088043213
Validation loss: 2.0234076380729675

Epoch: 6| Step: 12
Training loss: 2.1735219955444336
Validation loss: 2.039018750190735

Epoch: 6| Step: 13
Training loss: 2.1446304321289062
Validation loss: 2.02886434396108

Epoch: 88| Step: 0
Training loss: 2.0998177528381348
Validation loss: 2.0229401191075644

Epoch: 6| Step: 1
Training loss: 2.3609933853149414
Validation loss: 2.0149664282798767

Epoch: 6| Step: 2
Training loss: 2.18160343170166
Validation loss: 2.0141194264094033

Epoch: 6| Step: 3
Training loss: 2.3881936073303223
Validation loss: 2.0188243985176086

Epoch: 6| Step: 4
Training loss: 2.148190498352051
Validation loss: 2.02480685710907

Epoch: 6| Step: 5
Training loss: 2.713684320449829
Validation loss: 2.022788961728414

Epoch: 6| Step: 6
Training loss: 1.4250786304473877
Validation loss: 2.0071133573849997

Epoch: 6| Step: 7
Training loss: 2.002394676208496
Validation loss: 2.013895829518636

Epoch: 6| Step: 8
Training loss: 2.42933988571167
Validation loss: 2.0355367064476013

Epoch: 6| Step: 9
Training loss: 2.484518527984619
Validation loss: 2.032708724339803

Epoch: 6| Step: 10
Training loss: 1.9929649829864502
Validation loss: 2.040226320425669

Epoch: 6| Step: 11
Training loss: 2.2083940505981445
Validation loss: 2.059718906879425

Epoch: 6| Step: 12
Training loss: 2.0967214107513428
Validation loss: 2.061737358570099

Epoch: 6| Step: 13
Training loss: 1.6875602006912231
Validation loss: 2.0663872162501016

Epoch: 89| Step: 0
Training loss: 1.849429965019226
Validation loss: 2.0496214429537454

Epoch: 6| Step: 1
Training loss: 2.158940076828003
Validation loss: 2.038148581981659

Epoch: 6| Step: 2
Training loss: 1.34962797164917
Validation loss: 2.0415481328964233

Epoch: 6| Step: 3
Training loss: 2.702110528945923
Validation loss: 2.042843739191691

Epoch: 6| Step: 4
Training loss: 2.160269021987915
Validation loss: 2.0451448361078897

Epoch: 6| Step: 5
Training loss: 2.351085662841797
Validation loss: 2.0492714246114097

Epoch: 6| Step: 6
Training loss: 2.0233311653137207
Validation loss: 2.0395236810048423

Epoch: 6| Step: 7
Training loss: 1.842757225036621
Validation loss: 2.041556417942047

Epoch: 6| Step: 8
Training loss: 2.286687135696411
Validation loss: 2.0492241779963174

Epoch: 6| Step: 9
Training loss: 1.9625215530395508
Validation loss: 2.0336324175198874

Epoch: 6| Step: 10
Training loss: 2.117839813232422
Validation loss: 2.0168959299723306

Epoch: 6| Step: 11
Training loss: 2.15950608253479
Validation loss: 2.013918320337931

Epoch: 6| Step: 12
Training loss: 2.9640069007873535
Validation loss: 2.0111840963363647

Epoch: 6| Step: 13
Training loss: 1.9572629928588867
Validation loss: 2.016785522301992

Epoch: 90| Step: 0
Training loss: 2.272003650665283
Validation loss: 2.0040948390960693

Epoch: 6| Step: 1
Training loss: 2.065016269683838
Validation loss: 2.018629729747772

Epoch: 6| Step: 2
Training loss: 1.9500720500946045
Validation loss: 2.023064394791921

Epoch: 6| Step: 3
Training loss: 1.7846510410308838
Validation loss: 2.024576723575592

Epoch: 6| Step: 4
Training loss: 1.8166377544403076
Validation loss: 2.0268208384513855

Epoch: 6| Step: 5
Training loss: 2.9018006324768066
Validation loss: 2.0160232384999595

Epoch: 6| Step: 6
Training loss: 2.409026622772217
Validation loss: 2.007504483064016

Epoch: 6| Step: 7
Training loss: 1.9846100807189941
Validation loss: 2.0136677821477256

Epoch: 6| Step: 8
Training loss: 2.13859224319458
Validation loss: 2.0088483095169067

Epoch: 6| Step: 9
Training loss: 1.6446884870529175
Validation loss: 2.012757579485575

Epoch: 6| Step: 10
Training loss: 1.8182244300842285
Validation loss: 2.0205742716789246

Epoch: 6| Step: 11
Training loss: 3.0443668365478516
Validation loss: 2.0253273646036782

Epoch: 6| Step: 12
Training loss: 2.0544095039367676
Validation loss: 2.0263744791348777

Epoch: 6| Step: 13
Training loss: 2.251922607421875
Validation loss: 2.0514236887296042

Epoch: 91| Step: 0
Training loss: 2.1945114135742188
Validation loss: 2.052259107430776

Epoch: 6| Step: 1
Training loss: 1.957351565361023
Validation loss: 2.0350658694903054

Epoch: 6| Step: 2
Training loss: 2.2983546257019043
Validation loss: 2.042815367380778

Epoch: 6| Step: 3
Training loss: 2.262385129928589
Validation loss: 2.0538697242736816

Epoch: 6| Step: 4
Training loss: 1.8789851665496826
Validation loss: 2.046031912167867

Epoch: 6| Step: 5
Training loss: 2.0855605602264404
Validation loss: 2.032487134138743

Epoch: 6| Step: 6
Training loss: 2.3136632442474365
Validation loss: 2.0364898244539895

Epoch: 6| Step: 7
Training loss: 2.0336546897888184
Validation loss: 2.014398773511251

Epoch: 6| Step: 8
Training loss: 1.9705822467803955
Validation loss: 2.0140637159347534

Epoch: 6| Step: 9
Training loss: 2.2643914222717285
Validation loss: 2.0191587805747986

Epoch: 6| Step: 10
Training loss: 2.425889015197754
Validation loss: 2.0166484316190085

Epoch: 6| Step: 11
Training loss: 1.6662395000457764
Validation loss: 2.0233606100082397

Epoch: 6| Step: 12
Training loss: 2.4851157665252686
Validation loss: 2.032988965511322

Epoch: 6| Step: 13
Training loss: 2.224459409713745
Validation loss: 2.0338487227757773

Epoch: 92| Step: 0
Training loss: 2.476144313812256
Validation loss: 2.0334611932436624

Epoch: 6| Step: 1
Training loss: 2.5713768005371094
Validation loss: 2.0259379347165427

Epoch: 6| Step: 2
Training loss: 2.2587838172912598
Validation loss: 2.019864638646444

Epoch: 6| Step: 3
Training loss: 1.5575568675994873
Validation loss: 2.02300618092219

Epoch: 6| Step: 4
Training loss: 1.9471702575683594
Validation loss: 2.011885384718577

Epoch: 6| Step: 5
Training loss: 2.478382110595703
Validation loss: 2.018466909726461

Epoch: 6| Step: 6
Training loss: 2.30141019821167
Validation loss: 2.032752434412638

Epoch: 6| Step: 7
Training loss: 1.9558966159820557
Validation loss: 2.0260223746299744

Epoch: 6| Step: 8
Training loss: 2.1469340324401855
Validation loss: 2.0365737875302634

Epoch: 6| Step: 9
Training loss: 2.657578945159912
Validation loss: 2.0363848408063254

Epoch: 6| Step: 10
Training loss: 1.9036575555801392
Validation loss: 2.034245709578196

Epoch: 6| Step: 11
Training loss: 2.1097447872161865
Validation loss: 2.032945970694224

Epoch: 6| Step: 12
Training loss: 1.5999646186828613
Validation loss: 2.038638730843862

Epoch: 6| Step: 13
Training loss: 2.064497947692871
Validation loss: 2.031104584534963

Epoch: 93| Step: 0
Training loss: 2.4892823696136475
Validation loss: 2.04183167219162

Epoch: 6| Step: 1
Training loss: 2.340308666229248
Validation loss: 2.0313865343729653

Epoch: 6| Step: 2
Training loss: 2.914193868637085
Validation loss: 2.0277998050053916

Epoch: 6| Step: 3
Training loss: 2.283099412918091
Validation loss: 2.0372262001037598

Epoch: 6| Step: 4
Training loss: 1.981960415840149
Validation loss: 2.0283077359199524

Epoch: 6| Step: 5
Training loss: 2.2365801334381104
Validation loss: 2.021703024705251

Epoch: 6| Step: 6
Training loss: 2.117466449737549
Validation loss: 2.0161032676696777

Epoch: 6| Step: 7
Training loss: 2.0351433753967285
Validation loss: 2.01834370692571

Epoch: 6| Step: 8
Training loss: 1.5554776191711426
Validation loss: 2.0129588842391968

Epoch: 6| Step: 9
Training loss: 1.994527816772461
Validation loss: 2.0092472632726035

Epoch: 6| Step: 10
Training loss: 1.9775357246398926
Validation loss: 2.0183441638946533

Epoch: 6| Step: 11
Training loss: 1.6190752983093262
Validation loss: 2.0170984466870627

Epoch: 6| Step: 12
Training loss: 2.005089521408081
Validation loss: 2.023204286893209

Epoch: 6| Step: 13
Training loss: 2.4284098148345947
Validation loss: 2.0286627610524497

Epoch: 94| Step: 0
Training loss: 1.964415431022644
Validation loss: 2.0399585366249084

Epoch: 6| Step: 1
Training loss: 2.512685775756836
Validation loss: 2.0562859376271567

Epoch: 6| Step: 2
Training loss: 2.3647067546844482
Validation loss: 2.060983717441559

Epoch: 6| Step: 3
Training loss: 1.8911144733428955
Validation loss: 2.0726133783658347

Epoch: 6| Step: 4
Training loss: 1.7775784730911255
Validation loss: 2.0601455767949424

Epoch: 6| Step: 5
Training loss: 2.5411062240600586
Validation loss: 2.0571678479512534

Epoch: 6| Step: 6
Training loss: 2.0295674800872803
Validation loss: 2.0512062907218933

Epoch: 6| Step: 7
Training loss: 2.3182082176208496
Validation loss: 2.0500343441963196

Epoch: 6| Step: 8
Training loss: 1.8657057285308838
Validation loss: 2.0386587977409363

Epoch: 6| Step: 9
Training loss: 1.7781976461410522
Validation loss: 2.033764143784841

Epoch: 6| Step: 10
Training loss: 2.107276439666748
Validation loss: 2.0322981675465903

Epoch: 6| Step: 11
Training loss: 2.08240008354187
Validation loss: 2.0243516167004905

Epoch: 6| Step: 12
Training loss: 2.2226722240448
Validation loss: 2.028243362903595

Epoch: 6| Step: 13
Training loss: 2.372239589691162
Validation loss: 2.023716310660044

Epoch: 95| Step: 0
Training loss: 2.7956395149230957
Validation loss: 2.010437846183777

Epoch: 6| Step: 1
Training loss: 2.401944398880005
Validation loss: 2.0210379362106323

Epoch: 6| Step: 2
Training loss: 2.4871573448181152
Validation loss: 2.028122862180074

Epoch: 6| Step: 3
Training loss: 1.9141452312469482
Validation loss: 2.04290638367335

Epoch: 6| Step: 4
Training loss: 2.546337604522705
Validation loss: 2.0256683826446533

Epoch: 6| Step: 5
Training loss: 1.6572051048278809
Validation loss: 2.0223244627316794

Epoch: 6| Step: 6
Training loss: 2.093094825744629
Validation loss: 2.019243538379669

Epoch: 6| Step: 7
Training loss: 2.286907434463501
Validation loss: 2.010267118612925

Epoch: 6| Step: 8
Training loss: 1.8270679712295532
Validation loss: 2.020103851954142

Epoch: 6| Step: 9
Training loss: 1.8608635663986206
Validation loss: 2.015568117300669

Epoch: 6| Step: 10
Training loss: 2.036691904067993
Validation loss: 2.0145972967147827

Epoch: 6| Step: 11
Training loss: 2.00233793258667
Validation loss: 2.0235877434412637

Epoch: 6| Step: 12
Training loss: 1.8408902883529663
Validation loss: 2.036459445953369

Epoch: 6| Step: 13
Training loss: 2.0026931762695312
Validation loss: 2.0443207224210105

Epoch: 96| Step: 0
Training loss: 2.4320578575134277
Validation loss: 2.0339310566584268

Epoch: 6| Step: 1
Training loss: 2.041006088256836
Validation loss: 2.0352723201115928

Epoch: 6| Step: 2
Training loss: 2.001145839691162
Validation loss: 2.0432073871294656

Epoch: 6| Step: 3
Training loss: 2.6185340881347656
Validation loss: 2.027652899424235

Epoch: 6| Step: 4
Training loss: 2.5060431957244873
Validation loss: 2.023171385129293

Epoch: 6| Step: 5
Training loss: 2.2323169708251953
Validation loss: 2.0355538527170816

Epoch: 6| Step: 6
Training loss: 1.49005126953125
Validation loss: 2.024360458056132

Epoch: 6| Step: 7
Training loss: 2.2975080013275146
Validation loss: 2.0398650964101157

Epoch: 6| Step: 8
Training loss: 2.0932741165161133
Validation loss: 2.026804804801941

Epoch: 6| Step: 9
Training loss: 1.4397138357162476
Validation loss: 2.014589329560598

Epoch: 6| Step: 10
Training loss: 2.4504542350769043
Validation loss: 2.0144994258880615

Epoch: 6| Step: 11
Training loss: 1.876817226409912
Validation loss: 2.0141298174858093

Epoch: 6| Step: 12
Training loss: 2.058518886566162
Validation loss: 2.0133323272069297

Epoch: 6| Step: 13
Training loss: 2.1230695247650146
Validation loss: 2.00552636384964

Epoch: 97| Step: 0
Training loss: 2.4359378814697266
Validation loss: 2.0081633726755777

Epoch: 6| Step: 1
Training loss: 1.853904128074646
Validation loss: 2.0121299028396606

Epoch: 6| Step: 2
Training loss: 2.2299365997314453
Validation loss: 2.0167388717333474

Epoch: 6| Step: 3
Training loss: 2.1014626026153564
Validation loss: 2.0159391164779663

Epoch: 6| Step: 4
Training loss: 2.3664770126342773
Validation loss: 2.0218342940012612

Epoch: 6| Step: 5
Training loss: 2.3035378456115723
Validation loss: 2.032785654067993

Epoch: 6| Step: 6
Training loss: 1.7741007804870605
Validation loss: 2.0296654303868613

Epoch: 6| Step: 7
Training loss: 2.2114572525024414
Validation loss: 2.0263826052347818

Epoch: 6| Step: 8
Training loss: 2.797799825668335
Validation loss: 2.0282923579216003

Epoch: 6| Step: 9
Training loss: 2.3929882049560547
Validation loss: 2.0352800488471985

Epoch: 6| Step: 10
Training loss: 1.889248013496399
Validation loss: 2.045692523320516

Epoch: 6| Step: 11
Training loss: 1.8813356161117554
Validation loss: 2.04004035393397

Epoch: 6| Step: 12
Training loss: 1.4609328508377075
Validation loss: 2.034128407637278

Epoch: 6| Step: 13
Training loss: 1.8669407367706299
Validation loss: 2.053853988647461

Epoch: 98| Step: 0
Training loss: 1.6957883834838867
Validation loss: 2.041845202445984

Epoch: 6| Step: 1
Training loss: 2.2161195278167725
Validation loss: 2.033403734366099

Epoch: 6| Step: 2
Training loss: 1.8688417673110962
Validation loss: 2.028839906056722

Epoch: 6| Step: 3
Training loss: 2.0723354816436768
Validation loss: 2.0184393723805747

Epoch: 6| Step: 4
Training loss: 2.249001979827881
Validation loss: 2.016921063264211

Epoch: 6| Step: 5
Training loss: 2.426363468170166
Validation loss: 2.0200892090797424

Epoch: 6| Step: 6
Training loss: 2.5579609870910645
Validation loss: 2.0188024441401162

Epoch: 6| Step: 7
Training loss: 2.065653085708618
Validation loss: 2.0189371506373086

Epoch: 6| Step: 8
Training loss: 2.225186347961426
Validation loss: 2.0143715540568032

Epoch: 6| Step: 9
Training loss: 1.669562816619873
Validation loss: 2.0083479483922324

Epoch: 6| Step: 10
Training loss: 2.026557445526123
Validation loss: 2.0237531661987305

Epoch: 6| Step: 11
Training loss: 1.7836276292800903
Validation loss: 2.0259891351064048

Epoch: 6| Step: 12
Training loss: 2.079780340194702
Validation loss: 2.036548097928365

Epoch: 6| Step: 13
Training loss: 2.6072516441345215
Validation loss: 2.041577994823456

Epoch: 99| Step: 0
Training loss: 1.824812412261963
Validation loss: 2.044739524523417

Epoch: 6| Step: 1
Training loss: 1.8297220468521118
Validation loss: 2.047365347544352

Epoch: 6| Step: 2
Training loss: 2.684577465057373
Validation loss: 2.040632128715515

Epoch: 6| Step: 3
Training loss: 1.6139700412750244
Validation loss: 2.0292860666910806

Epoch: 6| Step: 4
Training loss: 2.3953189849853516
Validation loss: 2.0358545581499734

Epoch: 6| Step: 5
Training loss: 2.413130760192871
Validation loss: 2.0400227904319763

Epoch: 6| Step: 6
Training loss: 1.7463693618774414
Validation loss: 2.0366281867027283

Epoch: 6| Step: 7
Training loss: 2.526517391204834
Validation loss: 2.033311128616333

Epoch: 6| Step: 8
Training loss: 2.300938606262207
Validation loss: 2.0505255858103433

Epoch: 6| Step: 9
Training loss: 1.9189791679382324
Validation loss: 2.044695814450582

Epoch: 6| Step: 10
Training loss: 1.6859204769134521
Validation loss: 2.0547688206036887

Epoch: 6| Step: 11
Training loss: 2.3263111114501953
Validation loss: 2.0644622643788657

Epoch: 6| Step: 12
Training loss: 2.3031764030456543
Validation loss: 2.0603806575139365

Epoch: 6| Step: 13
Training loss: 2.0536932945251465
Validation loss: 2.0681703289349875

Epoch: 100| Step: 0
Training loss: 1.8451011180877686
Validation loss: 2.0758561293284097

Epoch: 6| Step: 1
Training loss: 2.4215545654296875
Validation loss: 2.0545463959376016

Epoch: 6| Step: 2
Training loss: 2.2196836471557617
Validation loss: 2.072505990664164

Epoch: 6| Step: 3
Training loss: 1.6881059408187866
Validation loss: 2.0575002233187356

Epoch: 6| Step: 4
Training loss: 1.8503406047821045
Validation loss: 2.048699756463369

Epoch: 6| Step: 5
Training loss: 2.391051769256592
Validation loss: 2.0322243173917136

Epoch: 6| Step: 6
Training loss: 2.0571987628936768
Validation loss: 2.033838232358297

Epoch: 6| Step: 7
Training loss: 2.184049606323242
Validation loss: 2.012788017590841

Epoch: 6| Step: 8
Training loss: 1.961202621459961
Validation loss: 2.015398621559143

Epoch: 6| Step: 9
Training loss: 2.0262293815612793
Validation loss: 2.01691468556722

Epoch: 6| Step: 10
Training loss: 2.2153382301330566
Validation loss: 2.0197258392969766

Epoch: 6| Step: 11
Training loss: 1.7855761051177979
Validation loss: 2.020356059074402

Epoch: 6| Step: 12
Training loss: 2.62613582611084
Validation loss: 2.0147258043289185

Epoch: 6| Step: 13
Training loss: 2.4261014461517334
Validation loss: 2.0131266911824546

Epoch: 101| Step: 0
Training loss: 2.0001282691955566
Validation loss: 2.0210254391034446

Epoch: 6| Step: 1
Training loss: 2.0978457927703857
Validation loss: 2.035576502482096

Epoch: 6| Step: 2
Training loss: 2.642031669616699
Validation loss: 2.0428951183954873

Epoch: 6| Step: 3
Training loss: 2.23173189163208
Validation loss: 2.05076930920283

Epoch: 6| Step: 4
Training loss: 2.668639659881592
Validation loss: 2.044931391874949

Epoch: 6| Step: 5
Training loss: 1.9336011409759521
Validation loss: 2.053320904572805

Epoch: 6| Step: 6
Training loss: 2.1682534217834473
Validation loss: 2.050650179386139

Epoch: 6| Step: 7
Training loss: 1.8109478950500488
Validation loss: 2.055885116259257

Epoch: 6| Step: 8
Training loss: 2.221553325653076
Validation loss: 2.0377883513768515

Epoch: 6| Step: 9
Training loss: 1.8832204341888428
Validation loss: 2.0309696396191916

Epoch: 6| Step: 10
Training loss: 2.308333396911621
Validation loss: 2.040822207927704

Epoch: 6| Step: 11
Training loss: 1.7192946672439575
Validation loss: 2.0355119109153748

Epoch: 6| Step: 12
Training loss: 2.050241708755493
Validation loss: 2.03361181418101

Epoch: 6| Step: 13
Training loss: 1.9465538263320923
Validation loss: 2.0253231724103293

Epoch: 102| Step: 0
Training loss: 2.1430134773254395
Validation loss: 2.025803883870443

Epoch: 6| Step: 1
Training loss: 2.4510116577148438
Validation loss: 2.0220019221305847

Epoch: 6| Step: 2
Training loss: 2.2868447303771973
Validation loss: 2.017377018928528

Epoch: 6| Step: 3
Training loss: 1.8733171224594116
Validation loss: 2.0242674748102822

Epoch: 6| Step: 4
Training loss: 2.051267623901367
Validation loss: 2.0359532038370767

Epoch: 6| Step: 5
Training loss: 2.9964401721954346
Validation loss: 2.023458957672119

Epoch: 6| Step: 6
Training loss: 1.8036117553710938
Validation loss: 2.019749701023102

Epoch: 6| Step: 7
Training loss: 1.7586281299591064
Validation loss: 2.0101828575134277

Epoch: 6| Step: 8
Training loss: 2.122465133666992
Validation loss: 2.005139867464701

Epoch: 6| Step: 9
Training loss: 2.1511387825012207
Validation loss: 2.011614183584849

Epoch: 6| Step: 10
Training loss: 1.8544185161590576
Validation loss: 2.0151015321413674

Epoch: 6| Step: 11
Training loss: 2.0970845222473145
Validation loss: 2.002145012219747

Epoch: 6| Step: 12
Training loss: 1.7536828517913818
Validation loss: 2.0270142753918967

Epoch: 6| Step: 13
Training loss: 2.424848794937134
Validation loss: 2.0360894799232483

Epoch: 103| Step: 0
Training loss: 1.8472559452056885
Validation loss: 2.033338983853658

Epoch: 6| Step: 1
Training loss: 2.096277952194214
Validation loss: 2.0572375853856406

Epoch: 6| Step: 2
Training loss: 1.7561149597167969
Validation loss: 2.0547066728274026

Epoch: 6| Step: 3
Training loss: 2.200735569000244
Validation loss: 2.0609602133433023

Epoch: 6| Step: 4
Training loss: 2.077538251876831
Validation loss: 2.0776263078053794

Epoch: 6| Step: 5
Training loss: 2.124433994293213
Validation loss: 2.0873311956723533

Epoch: 6| Step: 6
Training loss: 2.0062389373779297
Validation loss: 2.0842182834943137

Epoch: 6| Step: 7
Training loss: 1.8083077669143677
Validation loss: 2.083599070707957

Epoch: 6| Step: 8
Training loss: 1.7937614917755127
Validation loss: 2.081833084424337

Epoch: 6| Step: 9
Training loss: 2.6494903564453125
Validation loss: 2.0966116786003113

Epoch: 6| Step: 10
Training loss: 1.799839973449707
Validation loss: 2.064874251683553

Epoch: 6| Step: 11
Training loss: 2.4030556678771973
Validation loss: 2.060486853122711

Epoch: 6| Step: 12
Training loss: 3.1744542121887207
Validation loss: 2.0234798789024353

Epoch: 6| Step: 13
Training loss: 1.8552055358886719
Validation loss: 2.0222730239232383

Epoch: 104| Step: 0
Training loss: 2.004176616668701
Validation loss: 2.0102503498395285

Epoch: 6| Step: 1
Training loss: 2.9139504432678223
Validation loss: 2.0156812270482383

Epoch: 6| Step: 2
Training loss: 2.4451208114624023
Validation loss: 2.0182043313980103

Epoch: 6| Step: 3
Training loss: 2.20125150680542
Validation loss: 2.0304967761039734

Epoch: 6| Step: 4
Training loss: 1.576261043548584
Validation loss: 2.0183506409327188

Epoch: 6| Step: 5
Training loss: 1.8385065793991089
Validation loss: 2.018988768259684

Epoch: 6| Step: 6
Training loss: 2.60943603515625
Validation loss: 2.018689811229706

Epoch: 6| Step: 7
Training loss: 1.9120380878448486
Validation loss: 2.0131483475367227

Epoch: 6| Step: 8
Training loss: 1.9555740356445312
Validation loss: 2.0101301670074463

Epoch: 6| Step: 9
Training loss: 2.603517532348633
Validation loss: 2.005237340927124

Epoch: 6| Step: 10
Training loss: 1.6635091304779053
Validation loss: 2.0079198280970254

Epoch: 6| Step: 11
Training loss: 1.562814712524414
Validation loss: 2.0058618585268655

Epoch: 6| Step: 12
Training loss: 1.9029121398925781
Validation loss: 2.0077673196792603

Epoch: 6| Step: 13
Training loss: 2.7526278495788574
Validation loss: 2.016444424788157

Epoch: 105| Step: 0
Training loss: 2.9643120765686035
Validation loss: 2.0056278904279075

Epoch: 6| Step: 1
Training loss: 2.083125591278076
Validation loss: 2.0205854972203574

Epoch: 6| Step: 2
Training loss: 2.581846237182617
Validation loss: 2.016414701938629

Epoch: 6| Step: 3
Training loss: 2.135067939758301
Validation loss: 2.014467716217041

Epoch: 6| Step: 4
Training loss: 1.546546459197998
Validation loss: 2.022974153359731

Epoch: 6| Step: 5
Training loss: 1.8594071865081787
Validation loss: 2.0273287097613015

Epoch: 6| Step: 6
Training loss: 2.2947311401367188
Validation loss: 2.038573761781057

Epoch: 6| Step: 7
Training loss: 2.099249839782715
Validation loss: 2.0361127853393555

Epoch: 6| Step: 8
Training loss: 1.832972764968872
Validation loss: 2.043355166912079

Epoch: 6| Step: 9
Training loss: 1.9608397483825684
Validation loss: 2.0661173661549888

Epoch: 6| Step: 10
Training loss: 2.2831063270568848
Validation loss: 2.071224252382914

Epoch: 6| Step: 11
Training loss: 1.9632383584976196
Validation loss: 2.0811380743980408

Epoch: 6| Step: 12
Training loss: 2.0766801834106445
Validation loss: 2.0480860074361167

Epoch: 6| Step: 13
Training loss: 1.7674790620803833
Validation loss: 2.0400222142537436

Epoch: 106| Step: 0
Training loss: 1.7383434772491455
Validation loss: 2.023761212825775

Epoch: 6| Step: 1
Training loss: 2.119379758834839
Validation loss: 2.016464114189148

Epoch: 6| Step: 2
Training loss: 1.8146851062774658
Validation loss: 2.015980819861094

Epoch: 6| Step: 3
Training loss: 2.9136292934417725
Validation loss: 2.0230955680211387

Epoch: 6| Step: 4
Training loss: 2.333706855773926
Validation loss: 2.0275606314341226

Epoch: 6| Step: 5
Training loss: 1.893211841583252
Validation loss: 2.0425161123275757

Epoch: 6| Step: 6
Training loss: 1.8133742809295654
Validation loss: 2.041182359059652

Epoch: 6| Step: 7
Training loss: 1.8808728456497192
Validation loss: 2.0347840587298074

Epoch: 6| Step: 8
Training loss: 2.4028546810150146
Validation loss: 2.0392065048217773

Epoch: 6| Step: 9
Training loss: 1.7638092041015625
Validation loss: 2.0450451970100403

Epoch: 6| Step: 10
Training loss: 2.14037823677063
Validation loss: 2.0323718984921775

Epoch: 6| Step: 11
Training loss: 2.389129638671875
Validation loss: 2.0355958541234336

Epoch: 6| Step: 12
Training loss: 2.3824048042297363
Validation loss: 2.0262895623842874

Epoch: 6| Step: 13
Training loss: 2.3055832386016846
Validation loss: 2.030915141105652

Epoch: 107| Step: 0
Training loss: 2.1626782417297363
Validation loss: 2.020516117413839

Epoch: 6| Step: 1
Training loss: 2.359127998352051
Validation loss: 2.0202097296714783

Epoch: 6| Step: 2
Training loss: 2.0833165645599365
Validation loss: 2.0226189494132996

Epoch: 6| Step: 3
Training loss: 2.4147696495056152
Validation loss: 2.0149720708529153

Epoch: 6| Step: 4
Training loss: 1.8915226459503174
Validation loss: 2.029465913772583

Epoch: 6| Step: 5
Training loss: 2.1323673725128174
Validation loss: 2.0164058009783425

Epoch: 6| Step: 6
Training loss: 1.8664228916168213
Validation loss: 2.0221456487973533

Epoch: 6| Step: 7
Training loss: 2.2179036140441895
Validation loss: 2.0338059266408286

Epoch: 6| Step: 8
Training loss: 1.6748144626617432
Validation loss: 2.031736652056376

Epoch: 6| Step: 9
Training loss: 1.8425308465957642
Validation loss: 2.049906929334005

Epoch: 6| Step: 10
Training loss: 2.017685890197754
Validation loss: 2.0558121601740518

Epoch: 6| Step: 11
Training loss: 1.6272121667861938
Validation loss: 2.068146606286367

Epoch: 6| Step: 12
Training loss: 2.734144926071167
Validation loss: 2.068878491719564

Epoch: 6| Step: 13
Training loss: 2.3328819274902344
Validation loss: 2.0816583832105002

Epoch: 108| Step: 0
Training loss: 2.39431095123291
Validation loss: 2.081489006678263

Epoch: 6| Step: 1
Training loss: 1.5238460302352905
Validation loss: 2.063355644543966

Epoch: 6| Step: 2
Training loss: 1.8055788278579712
Validation loss: 2.083099146684011

Epoch: 6| Step: 3
Training loss: 2.481051445007324
Validation loss: 2.0898059209187827

Epoch: 6| Step: 4
Training loss: 1.719706416130066
Validation loss: 2.0744155446688333

Epoch: 6| Step: 5
Training loss: 2.2995097637176514
Validation loss: 2.0750197172164917

Epoch: 6| Step: 6
Training loss: 1.913656234741211
Validation loss: 2.067663848400116

Epoch: 6| Step: 7
Training loss: 2.1941990852355957
Validation loss: 2.0679864088694253

Epoch: 6| Step: 8
Training loss: 2.0893330574035645
Validation loss: 2.056251804033915

Epoch: 6| Step: 9
Training loss: 2.275287628173828
Validation loss: 2.0586029092470803

Epoch: 6| Step: 10
Training loss: 1.6259515285491943
Validation loss: 2.0513356924057007

Epoch: 6| Step: 11
Training loss: 2.213426113128662
Validation loss: 2.0397940278053284

Epoch: 6| Step: 12
Training loss: 2.0736308097839355
Validation loss: 2.0506328344345093

Epoch: 6| Step: 13
Training loss: 2.5822956562042236
Validation loss: 2.0454917550086975

Epoch: 109| Step: 0
Training loss: 2.241974353790283
Validation loss: 2.030490458011627

Epoch: 6| Step: 1
Training loss: 1.97459876537323
Validation loss: 2.0171331564585366

Epoch: 6| Step: 2
Training loss: 1.8702348470687866
Validation loss: 2.0156863927841187

Epoch: 6| Step: 3
Training loss: 1.6987018585205078
Validation loss: 2.027385969956716

Epoch: 6| Step: 4
Training loss: 2.1413989067077637
Validation loss: 2.0231730540593467

Epoch: 6| Step: 5
Training loss: 2.77601957321167
Validation loss: 2.0319812496503196

Epoch: 6| Step: 6
Training loss: 2.8074777126312256
Validation loss: 2.031178593635559

Epoch: 6| Step: 7
Training loss: 1.3428741693496704
Validation loss: 2.0256216327349343

Epoch: 6| Step: 8
Training loss: 2.841193199157715
Validation loss: 2.0386510292689004

Epoch: 6| Step: 9
Training loss: 1.7313493490219116
Validation loss: 2.0401259859402976

Epoch: 6| Step: 10
Training loss: 2.3417460918426514
Validation loss: 2.0354490280151367

Epoch: 6| Step: 11
Training loss: 1.4252625703811646
Validation loss: 2.0412022272745767

Epoch: 6| Step: 12
Training loss: 2.3624348640441895
Validation loss: 2.073053161303202

Epoch: 6| Step: 13
Training loss: 1.9357894659042358
Validation loss: 2.05121503273646

Epoch: 110| Step: 0
Training loss: 2.313955783843994
Validation loss: 2.040257751941681

Epoch: 6| Step: 1
Training loss: 1.517366886138916
Validation loss: 2.041978041330973

Epoch: 6| Step: 2
Training loss: 2.361328601837158
Validation loss: 2.0336379607518515

Epoch: 6| Step: 3
Training loss: 2.3724279403686523
Validation loss: 2.0284008979797363

Epoch: 6| Step: 4
Training loss: 2.0371510982513428
Validation loss: 2.029305915037791

Epoch: 6| Step: 5
Training loss: 1.756439208984375
Validation loss: 2.0263630549112954

Epoch: 6| Step: 6
Training loss: 1.273235559463501
Validation loss: 2.016299764315287

Epoch: 6| Step: 7
Training loss: 2.364993095397949
Validation loss: 2.0235589742660522

Epoch: 6| Step: 8
Training loss: 1.8533316850662231
Validation loss: 2.026873250802358

Epoch: 6| Step: 9
Training loss: 2.5872230529785156
Validation loss: 2.0265512466430664

Epoch: 6| Step: 10
Training loss: 1.9386080503463745
Validation loss: 2.018117984135946

Epoch: 6| Step: 11
Training loss: 2.9623541831970215
Validation loss: 2.0297998984654746

Epoch: 6| Step: 12
Training loss: 2.204237699508667
Validation loss: 2.011788566907247

Epoch: 6| Step: 13
Training loss: 1.8634746074676514
Validation loss: 2.0287970503171286

Epoch: 111| Step: 0
Training loss: 1.8592538833618164
Validation loss: 2.026633322238922

Epoch: 6| Step: 1
Training loss: 2.635127544403076
Validation loss: 2.0212051272392273

Epoch: 6| Step: 2
Training loss: 2.3465445041656494
Validation loss: 2.0233044226964316

Epoch: 6| Step: 3
Training loss: 2.361546516418457
Validation loss: 2.029043118158976

Epoch: 6| Step: 4
Training loss: 2.4879322052001953
Validation loss: 2.0315869450569153

Epoch: 6| Step: 5
Training loss: 1.2844808101654053
Validation loss: 2.012145737806956

Epoch: 6| Step: 6
Training loss: 2.4057891368865967
Validation loss: 2.011870861053467

Epoch: 6| Step: 7
Training loss: 1.900755763053894
Validation loss: 2.012643873691559

Epoch: 6| Step: 8
Training loss: 2.7032530307769775
Validation loss: 2.0167640844980874

Epoch: 6| Step: 9
Training loss: 1.8111045360565186
Validation loss: 2.0086509585380554

Epoch: 6| Step: 10
Training loss: 2.0332276821136475
Validation loss: 2.0177431106567383

Epoch: 6| Step: 11
Training loss: 1.888226866722107
Validation loss: 2.008697589238485

Epoch: 6| Step: 12
Training loss: 2.116068124771118
Validation loss: 2.023238718509674

Epoch: 6| Step: 13
Training loss: 1.6747288703918457
Validation loss: 2.0402143200238547

Epoch: 112| Step: 0
Training loss: 1.995215892791748
Validation loss: 2.046694835027059

Epoch: 6| Step: 1
Training loss: 2.175771951675415
Validation loss: 2.041708290576935

Epoch: 6| Step: 2
Training loss: 2.4411017894744873
Validation loss: 2.048365314801534

Epoch: 6| Step: 3
Training loss: 2.1763429641723633
Validation loss: 2.0424240628878274

Epoch: 6| Step: 4
Training loss: 2.4133338928222656
Validation loss: 2.034571051597595

Epoch: 6| Step: 5
Training loss: 1.8491578102111816
Validation loss: 2.034679392973582

Epoch: 6| Step: 6
Training loss: 1.7646228075027466
Validation loss: 2.0404929916063943

Epoch: 6| Step: 7
Training loss: 2.0817646980285645
Validation loss: 2.036028742790222

Epoch: 6| Step: 8
Training loss: 2.6713132858276367
Validation loss: 2.0212207436561584

Epoch: 6| Step: 9
Training loss: 2.772073745727539
Validation loss: 2.033408204714457

Epoch: 6| Step: 10
Training loss: 2.032949924468994
Validation loss: 2.039380649725596

Epoch: 6| Step: 11
Training loss: 1.6069941520690918
Validation loss: 2.0227037270863852

Epoch: 6| Step: 12
Training loss: 1.876722812652588
Validation loss: 2.0270488262176514

Epoch: 6| Step: 13
Training loss: 1.6289851665496826
Validation loss: 2.0324856440226235

Epoch: 113| Step: 0
Training loss: 2.5196964740753174
Validation loss: 2.039870242277781

Epoch: 6| Step: 1
Training loss: 2.004483938217163
Validation loss: 2.0416120886802673

Epoch: 6| Step: 2
Training loss: 2.249347686767578
Validation loss: 2.0570342540740967

Epoch: 6| Step: 3
Training loss: 1.6317204236984253
Validation loss: 2.061209976673126

Epoch: 6| Step: 4
Training loss: 2.0824718475341797
Validation loss: 2.049725592136383

Epoch: 6| Step: 5
Training loss: 1.9945766925811768
Validation loss: 2.0458658734957376

Epoch: 6| Step: 6
Training loss: 2.499544143676758
Validation loss: 2.036313990751902

Epoch: 6| Step: 7
Training loss: 2.4354617595672607
Validation loss: 2.056299885114034

Epoch: 6| Step: 8
Training loss: 1.6831620931625366
Validation loss: 2.0345621506373086

Epoch: 6| Step: 9
Training loss: 1.9112629890441895
Validation loss: 2.035373946030935

Epoch: 6| Step: 10
Training loss: 1.842848777770996
Validation loss: 2.0297812024752298

Epoch: 6| Step: 11
Training loss: 2.021632432937622
Validation loss: 2.04580952723821

Epoch: 6| Step: 12
Training loss: 2.2877771854400635
Validation loss: 2.0438711841901145

Epoch: 6| Step: 13
Training loss: 2.1527936458587646
Validation loss: 2.040728727976481

Epoch: 114| Step: 0
Training loss: 2.5813727378845215
Validation loss: 2.0337220430374146

Epoch: 6| Step: 1
Training loss: 2.1412487030029297
Validation loss: 2.03011691570282

Epoch: 6| Step: 2
Training loss: 2.29018497467041
Validation loss: 2.025515874226888

Epoch: 6| Step: 3
Training loss: 2.244086980819702
Validation loss: 2.0284334619839988

Epoch: 6| Step: 4
Training loss: 1.6900291442871094
Validation loss: 2.039439002672831

Epoch: 6| Step: 5
Training loss: 2.483072280883789
Validation loss: 2.030101001262665

Epoch: 6| Step: 6
Training loss: 2.157087802886963
Validation loss: 2.0424610376358032

Epoch: 6| Step: 7
Training loss: 2.217766761779785
Validation loss: 2.053311069806417

Epoch: 6| Step: 8
Training loss: 1.3474444150924683
Validation loss: 2.0670536955197654

Epoch: 6| Step: 9
Training loss: 2.0745034217834473
Validation loss: 2.0779062509536743

Epoch: 6| Step: 10
Training loss: 2.2261672019958496
Validation loss: 2.057343065738678

Epoch: 6| Step: 11
Training loss: 1.8690868616104126
Validation loss: 2.0605865915616355

Epoch: 6| Step: 12
Training loss: 1.9477061033248901
Validation loss: 2.0500905911127725

Epoch: 6| Step: 13
Training loss: 1.9995222091674805
Validation loss: 2.0485087037086487

Epoch: 115| Step: 0
Training loss: 2.775951385498047
Validation loss: 2.031729221343994

Epoch: 6| Step: 1
Training loss: 2.3982176780700684
Validation loss: 2.050164302190145

Epoch: 6| Step: 2
Training loss: 2.388699769973755
Validation loss: 2.036521772543589

Epoch: 6| Step: 3
Training loss: 2.103492259979248
Validation loss: 2.031074345111847

Epoch: 6| Step: 4
Training loss: 2.416382312774658
Validation loss: 2.0376455386479697

Epoch: 6| Step: 5
Training loss: 2.0321452617645264
Validation loss: 2.037599484125773

Epoch: 6| Step: 6
Training loss: 1.8117989301681519
Validation loss: 2.0314470132191977

Epoch: 6| Step: 7
Training loss: 1.599217414855957
Validation loss: 2.0339950919151306

Epoch: 6| Step: 8
Training loss: 2.0940747261047363
Validation loss: 2.036516467730204

Epoch: 6| Step: 9
Training loss: 2.6898717880249023
Validation loss: 2.034972349802653

Epoch: 6| Step: 10
Training loss: 1.8568437099456787
Validation loss: 2.047848184903463

Epoch: 6| Step: 11
Training loss: 1.7736334800720215
Validation loss: 2.052968442440033

Epoch: 6| Step: 12
Training loss: 1.795983910560608
Validation loss: 2.06482587258021

Epoch: 6| Step: 13
Training loss: 1.3904480934143066
Validation loss: 2.0497220555941262

Epoch: 116| Step: 0
Training loss: 1.851611614227295
Validation loss: 2.040794630845388

Epoch: 6| Step: 1
Training loss: 1.7868921756744385
Validation loss: 2.049710234006246

Epoch: 6| Step: 2
Training loss: 2.211695432662964
Validation loss: 2.0428850253423056

Epoch: 6| Step: 3
Training loss: 1.9822142124176025
Validation loss: 2.033172388871511

Epoch: 6| Step: 4
Training loss: 2.181006669998169
Validation loss: 2.034039616584778

Epoch: 6| Step: 5
Training loss: 1.862945318222046
Validation loss: 2.0139155983924866

Epoch: 6| Step: 6
Training loss: 2.0576107501983643
Validation loss: 2.012631058692932

Epoch: 6| Step: 7
Training loss: 1.6152825355529785
Validation loss: 2.01884533961614

Epoch: 6| Step: 8
Training loss: 2.564033269882202
Validation loss: 2.0268714825312295

Epoch: 6| Step: 9
Training loss: 1.7972631454467773
Validation loss: 2.0292454163233438

Epoch: 6| Step: 10
Training loss: 2.2087349891662598
Validation loss: 2.0314050118128457

Epoch: 6| Step: 11
Training loss: 2.836987018585205
Validation loss: 2.0305936336517334

Epoch: 6| Step: 12
Training loss: 2.281475067138672
Validation loss: 2.042247772216797

Epoch: 6| Step: 13
Training loss: 2.1199967861175537
Validation loss: 2.036996901035309

Epoch: 117| Step: 0
Training loss: 2.267876625061035
Validation loss: 2.0382263461748757

Epoch: 6| Step: 1
Training loss: 1.979698896408081
Validation loss: 2.0483795007069907

Epoch: 6| Step: 2
Training loss: 1.5839849710464478
Validation loss: 2.045457601547241

Epoch: 6| Step: 3
Training loss: 1.8798836469650269
Validation loss: 2.052500903606415

Epoch: 6| Step: 4
Training loss: 2.0336408615112305
Validation loss: 2.067642649014791

Epoch: 6| Step: 5
Training loss: 1.5457043647766113
Validation loss: 2.0525344610214233

Epoch: 6| Step: 6
Training loss: 1.888527750968933
Validation loss: 2.0621180136998496

Epoch: 6| Step: 7
Training loss: 2.0959529876708984
Validation loss: 2.0552087227503457

Epoch: 6| Step: 8
Training loss: 2.498117208480835
Validation loss: 2.068467934926351

Epoch: 6| Step: 9
Training loss: 2.2186696529388428
Validation loss: 2.0452977617581687

Epoch: 6| Step: 10
Training loss: 2.2356088161468506
Validation loss: 2.0615076224009194

Epoch: 6| Step: 11
Training loss: 2.0688462257385254
Validation loss: 2.062330504258474

Epoch: 6| Step: 12
Training loss: 2.327775001525879
Validation loss: 2.065731704235077

Epoch: 6| Step: 13
Training loss: 2.359821081161499
Validation loss: 2.065159797668457

Epoch: 118| Step: 0
Training loss: 2.5923619270324707
Validation loss: 2.055713335673014

Epoch: 6| Step: 1
Training loss: 1.696990966796875
Validation loss: 2.0587581594785056

Epoch: 6| Step: 2
Training loss: 2.213374614715576
Validation loss: 2.050050973892212

Epoch: 6| Step: 3
Training loss: 1.993163824081421
Validation loss: 2.045227269331614

Epoch: 6| Step: 4
Training loss: 2.3520290851593018
Validation loss: 2.0337860782941184

Epoch: 6| Step: 5
Training loss: 2.05680513381958
Validation loss: 2.0393790006637573

Epoch: 6| Step: 6
Training loss: 1.9589440822601318
Validation loss: 2.0298894246419272

Epoch: 6| Step: 7
Training loss: 2.078258991241455
Validation loss: 2.023117204507192

Epoch: 6| Step: 8
Training loss: 1.968315839767456
Validation loss: 2.0292723178863525

Epoch: 6| Step: 9
Training loss: 1.6165249347686768
Validation loss: 2.043845991293589

Epoch: 6| Step: 10
Training loss: 2.4687273502349854
Validation loss: 2.0269888838132224

Epoch: 6| Step: 11
Training loss: 2.069615602493286
Validation loss: 2.0347010691960654

Epoch: 6| Step: 12
Training loss: 1.9253592491149902
Validation loss: 2.0257259408632913

Epoch: 6| Step: 13
Training loss: 2.720513105392456
Validation loss: 2.0274828672409058

Epoch: 119| Step: 0
Training loss: 1.9359937906265259
Validation loss: 2.015995224316915

Epoch: 6| Step: 1
Training loss: 1.6982576847076416
Validation loss: 2.0250791708628335

Epoch: 6| Step: 2
Training loss: 1.9478124380111694
Validation loss: 2.020348370075226

Epoch: 6| Step: 3
Training loss: 2.2005105018615723
Validation loss: 2.0347391764322915

Epoch: 6| Step: 4
Training loss: 2.381247043609619
Validation loss: 2.044354518254598

Epoch: 6| Step: 5
Training loss: 2.07731556892395
Validation loss: 2.0510822335879006

Epoch: 6| Step: 6
Training loss: 2.362393617630005
Validation loss: 2.067571500937144

Epoch: 6| Step: 7
Training loss: 1.8658342361450195
Validation loss: 2.0579715569814048

Epoch: 6| Step: 8
Training loss: 1.4917082786560059
Validation loss: 2.062880039215088

Epoch: 6| Step: 9
Training loss: 2.2529115676879883
Validation loss: 2.046651820341746

Epoch: 6| Step: 10
Training loss: 2.0639209747314453
Validation loss: 2.051425496737162

Epoch: 6| Step: 11
Training loss: 2.1143927574157715
Validation loss: 2.0347647666931152

Epoch: 6| Step: 12
Training loss: 1.9621386528015137
Validation loss: 2.0443347096443176

Epoch: 6| Step: 13
Training loss: 2.522430896759033
Validation loss: 2.0484450856844583

Epoch: 120| Step: 0
Training loss: 1.0194346904754639
Validation loss: 2.045420308907827

Epoch: 6| Step: 1
Training loss: 2.0474600791931152
Validation loss: 2.070727606614431

Epoch: 6| Step: 2
Training loss: 2.6124815940856934
Validation loss: 2.065550446510315

Epoch: 6| Step: 3
Training loss: 1.6429450511932373
Validation loss: 2.0572386980056763

Epoch: 6| Step: 4
Training loss: 1.9896907806396484
Validation loss: 2.062773883342743

Epoch: 6| Step: 5
Training loss: 3.1796553134918213
Validation loss: 2.042290767033895

Epoch: 6| Step: 6
Training loss: 2.485527515411377
Validation loss: 2.036828637123108

Epoch: 6| Step: 7
Training loss: 2.224740505218506
Validation loss: 2.0396809577941895

Epoch: 6| Step: 8
Training loss: 2.0480446815490723
Validation loss: 2.0478050907452903

Epoch: 6| Step: 9
Training loss: 1.8970063924789429
Validation loss: 2.0397912661234536

Epoch: 6| Step: 10
Training loss: 2.469940662384033
Validation loss: 2.047808667023977

Epoch: 6| Step: 11
Training loss: 1.3867161273956299
Validation loss: 2.046414375305176

Epoch: 6| Step: 12
Training loss: 1.9701192378997803
Validation loss: 2.0383564233779907

Epoch: 6| Step: 13
Training loss: 2.0601301193237305
Validation loss: 2.0428728063901267

Epoch: 121| Step: 0
Training loss: 1.9168912172317505
Validation loss: 2.0525028705596924

Epoch: 6| Step: 1
Training loss: 2.386115550994873
Validation loss: 2.0466102361679077

Epoch: 6| Step: 2
Training loss: 1.9445537328720093
Validation loss: 2.0485578974088035

Epoch: 6| Step: 3
Training loss: 1.8954687118530273
Validation loss: 2.0518097082773843

Epoch: 6| Step: 4
Training loss: 1.950607180595398
Validation loss: 2.040062189102173

Epoch: 6| Step: 5
Training loss: 2.1751608848571777
Validation loss: 2.0433919429779053

Epoch: 6| Step: 6
Training loss: 2.151524066925049
Validation loss: 2.051196038722992

Epoch: 6| Step: 7
Training loss: 2.4978995323181152
Validation loss: 2.067749480406443

Epoch: 6| Step: 8
Training loss: 1.7996885776519775
Validation loss: 2.0532140731811523

Epoch: 6| Step: 9
Training loss: 1.9745781421661377
Validation loss: 2.0681689182917276

Epoch: 6| Step: 10
Training loss: 2.284022808074951
Validation loss: 2.067087233066559

Epoch: 6| Step: 11
Training loss: 1.7834587097167969
Validation loss: 2.0731891989707947

Epoch: 6| Step: 12
Training loss: 1.974510669708252
Validation loss: 2.0670801599820456

Epoch: 6| Step: 13
Training loss: 2.0483570098876953
Validation loss: 2.086837371190389

Epoch: 122| Step: 0
Training loss: 1.9753599166870117
Validation loss: 2.069300055503845

Epoch: 6| Step: 1
Training loss: 1.5980079174041748
Validation loss: 2.0673834880193076

Epoch: 6| Step: 2
Training loss: 1.7518644332885742
Validation loss: 2.0582680900891623

Epoch: 6| Step: 3
Training loss: 2.017479181289673
Validation loss: 2.066944658756256

Epoch: 6| Step: 4
Training loss: 2.4001784324645996
Validation loss: 2.0772243539492288

Epoch: 6| Step: 5
Training loss: 1.5452752113342285
Validation loss: 2.0765328804651895

Epoch: 6| Step: 6
Training loss: 2.135374069213867
Validation loss: 2.073686679204305

Epoch: 6| Step: 7
Training loss: 2.403291940689087
Validation loss: 2.0749879479408264

Epoch: 6| Step: 8
Training loss: 2.137300968170166
Validation loss: 2.0709769129753113

Epoch: 6| Step: 9
Training loss: 1.9948511123657227
Validation loss: 2.0576195319493613

Epoch: 6| Step: 10
Training loss: 2.729037284851074
Validation loss: 2.0725699265797934

Epoch: 6| Step: 11
Training loss: 1.6963393688201904
Validation loss: 2.074564059575399

Epoch: 6| Step: 12
Training loss: 2.2404227256774902
Validation loss: 2.079560081164042

Epoch: 6| Step: 13
Training loss: 2.198697328567505
Validation loss: 2.0729582707087197

Epoch: 123| Step: 0
Training loss: 1.7191638946533203
Validation loss: 2.0503381490707397

Epoch: 6| Step: 1
Training loss: 2.1833224296569824
Validation loss: 2.0591657559076944

Epoch: 6| Step: 2
Training loss: 2.3644566535949707
Validation loss: 2.04846986134847

Epoch: 6| Step: 3
Training loss: 2.2385921478271484
Validation loss: 2.0389229456583657

Epoch: 6| Step: 4
Training loss: 1.786409854888916
Validation loss: 2.039405425389608

Epoch: 6| Step: 5
Training loss: 2.0712571144104004
Validation loss: 2.031506836414337

Epoch: 6| Step: 6
Training loss: 1.5474939346313477
Validation loss: 2.0301171938578286

Epoch: 6| Step: 7
Training loss: 2.129962682723999
Validation loss: 2.020103871822357

Epoch: 6| Step: 8
Training loss: 2.0817227363586426
Validation loss: 2.023299972216288

Epoch: 6| Step: 9
Training loss: 2.343183994293213
Validation loss: 2.032698929309845

Epoch: 6| Step: 10
Training loss: 2.6888973712921143
Validation loss: 2.0205973784128823

Epoch: 6| Step: 11
Training loss: 1.959358811378479
Validation loss: 2.0218854745229087

Epoch: 6| Step: 12
Training loss: 2.0495810508728027
Validation loss: 2.017661690711975

Epoch: 6| Step: 13
Training loss: 1.9636223316192627
Validation loss: 2.01252551873525

Epoch: 124| Step: 0
Training loss: 1.7522437572479248
Validation loss: 2.0185150106747947

Epoch: 6| Step: 1
Training loss: 1.6664798259735107
Validation loss: 2.0295961499214172

Epoch: 6| Step: 2
Training loss: 1.6500980854034424
Validation loss: 2.0375812649726868

Epoch: 6| Step: 3
Training loss: 2.0985374450683594
Validation loss: 2.036154568195343

Epoch: 6| Step: 4
Training loss: 2.0555217266082764
Validation loss: 2.0423905849456787

Epoch: 6| Step: 5
Training loss: 2.6127805709838867
Validation loss: 2.0304988026618958

Epoch: 6| Step: 6
Training loss: 2.9678115844726562
Validation loss: 2.0410076379776

Epoch: 6| Step: 7
Training loss: 1.6919597387313843
Validation loss: 2.049168864885966

Epoch: 6| Step: 8
Training loss: 1.8663406372070312
Validation loss: 2.052383303642273

Epoch: 6| Step: 9
Training loss: 1.799384355545044
Validation loss: 2.042032460371653

Epoch: 6| Step: 10
Training loss: 2.2123851776123047
Validation loss: 2.0430721441904702

Epoch: 6| Step: 11
Training loss: 2.1521449089050293
Validation loss: 2.057750105857849

Epoch: 6| Step: 12
Training loss: 1.9974050521850586
Validation loss: 2.0642592509587607

Epoch: 6| Step: 13
Training loss: 2.368217945098877
Validation loss: 2.05279278755188

Epoch: 125| Step: 0
Training loss: 1.5369551181793213
Validation loss: 2.0541368325551352

Epoch: 6| Step: 1
Training loss: 2.837435007095337
Validation loss: 2.049676259358724

Epoch: 6| Step: 2
Training loss: 2.340395450592041
Validation loss: 2.058387796084086

Epoch: 6| Step: 3
Training loss: 2.242384672164917
Validation loss: 2.056532363096873

Epoch: 6| Step: 4
Training loss: 1.9214438199996948
Validation loss: 2.0664674639701843

Epoch: 6| Step: 5
Training loss: 1.5339516401290894
Validation loss: 2.0532047549883523

Epoch: 6| Step: 6
Training loss: 1.6221390962600708
Validation loss: 2.0463974277178445

Epoch: 6| Step: 7
Training loss: 2.164771795272827
Validation loss: 2.062355915705363

Epoch: 6| Step: 8
Training loss: 1.9738143682479858
Validation loss: 2.064074714978536

Epoch: 6| Step: 9
Training loss: 2.013364791870117
Validation loss: 2.067573050657908

Epoch: 6| Step: 10
Training loss: 2.1925125122070312
Validation loss: 2.073546528816223

Epoch: 6| Step: 11
Training loss: 2.1495888233184814
Validation loss: 2.067773997783661

Epoch: 6| Step: 12
Training loss: 1.931710124015808
Validation loss: 2.0731705824534097

Epoch: 6| Step: 13
Training loss: 2.5286903381347656
Validation loss: 2.094021956125895

Epoch: 126| Step: 0
Training loss: 2.802035331726074
Validation loss: 2.051675856113434

Epoch: 6| Step: 1
Training loss: 1.6873828172683716
Validation loss: 2.0949142575263977

Epoch: 6| Step: 2
Training loss: 2.2364912033081055
Validation loss: 2.073837955792745

Epoch: 6| Step: 3
Training loss: 1.7376443147659302
Validation loss: 2.0675431887308755

Epoch: 6| Step: 4
Training loss: 2.464932680130005
Validation loss: 2.084268808364868

Epoch: 6| Step: 5
Training loss: 1.7907360792160034
Validation loss: 2.066560665766398

Epoch: 6| Step: 6
Training loss: 1.9887040853500366
Validation loss: 2.0723989605903625

Epoch: 6| Step: 7
Training loss: 1.9250788688659668
Validation loss: 2.0668015480041504

Epoch: 6| Step: 8
Training loss: 2.7854273319244385
Validation loss: 2.0438095331192017

Epoch: 6| Step: 9
Training loss: 2.367210865020752
Validation loss: 2.0456090370814004

Epoch: 6| Step: 10
Training loss: 1.9286147356033325
Validation loss: 2.036018113295237

Epoch: 6| Step: 11
Training loss: 1.6496219635009766
Validation loss: 2.0209946831067405

Epoch: 6| Step: 12
Training loss: 1.935436487197876
Validation loss: 2.02711284160614

Epoch: 6| Step: 13
Training loss: 1.6907646656036377
Validation loss: 2.022372007369995

Epoch: 127| Step: 0
Training loss: 2.4853153228759766
Validation loss: 2.0264042218526206

Epoch: 6| Step: 1
Training loss: 2.181278944015503
Validation loss: 2.0233576695124307

Epoch: 6| Step: 2
Training loss: 1.9250596761703491
Validation loss: 2.0245273113250732

Epoch: 6| Step: 3
Training loss: 2.3469674587249756
Validation loss: 2.019551853338877

Epoch: 6| Step: 4
Training loss: 1.4828152656555176
Validation loss: 2.021515965461731

Epoch: 6| Step: 5
Training loss: 2.367680549621582
Validation loss: 2.015390952428182

Epoch: 6| Step: 6
Training loss: 1.9696989059448242
Validation loss: 2.029391050338745

Epoch: 6| Step: 7
Training loss: 2.331904888153076
Validation loss: 2.02027428150177

Epoch: 6| Step: 8
Training loss: 2.046999931335449
Validation loss: 2.0319669246673584

Epoch: 6| Step: 9
Training loss: 1.750378131866455
Validation loss: 2.03609965244929

Epoch: 6| Step: 10
Training loss: 2.2514898777008057
Validation loss: 2.0345809062321982

Epoch: 6| Step: 11
Training loss: 1.9101989269256592
Validation loss: 2.040487507979075

Epoch: 6| Step: 12
Training loss: 1.8629854917526245
Validation loss: 2.047233204046885

Epoch: 6| Step: 13
Training loss: 2.1086223125457764
Validation loss: 2.047512650489807

Epoch: 128| Step: 0
Training loss: 2.0424342155456543
Validation loss: 2.0463777979214988

Epoch: 6| Step: 1
Training loss: 2.4737770557403564
Validation loss: 2.046128511428833

Epoch: 6| Step: 2
Training loss: 2.0402157306671143
Validation loss: 2.0379032095273337

Epoch: 6| Step: 3
Training loss: 1.870498776435852
Validation loss: 2.030483822027842

Epoch: 6| Step: 4
Training loss: 2.3700220584869385
Validation loss: 2.0325628519058228

Epoch: 6| Step: 5
Training loss: 1.4613823890686035
Validation loss: 2.0306015014648438

Epoch: 6| Step: 6
Training loss: 2.181166648864746
Validation loss: 2.0440908074378967

Epoch: 6| Step: 7
Training loss: 2.257298469543457
Validation loss: 2.0325829784075418

Epoch: 6| Step: 8
Training loss: 1.870457410812378
Validation loss: 2.031059960524241

Epoch: 6| Step: 9
Training loss: 2.745964527130127
Validation loss: 2.032781958580017

Epoch: 6| Step: 10
Training loss: 1.6526246070861816
Validation loss: 2.0450530449549356

Epoch: 6| Step: 11
Training loss: 2.257981538772583
Validation loss: 2.056038757165273

Epoch: 6| Step: 12
Training loss: 1.6691699028015137
Validation loss: 2.054130752881368

Epoch: 6| Step: 13
Training loss: 2.0637617111206055
Validation loss: 2.0552544593811035

Epoch: 129| Step: 0
Training loss: 1.8066346645355225
Validation loss: 2.0484115878740945

Epoch: 6| Step: 1
Training loss: 1.903627634048462
Validation loss: 2.050517121950785

Epoch: 6| Step: 2
Training loss: 2.000810384750366
Validation loss: 2.061221718788147

Epoch: 6| Step: 3
Training loss: 1.922635793685913
Validation loss: 2.0686174829800925

Epoch: 6| Step: 4
Training loss: 2.396444797515869
Validation loss: 2.0725760062535605

Epoch: 6| Step: 5
Training loss: 2.341703414916992
Validation loss: 2.071997344493866

Epoch: 6| Step: 6
Training loss: 2.150355815887451
Validation loss: 2.076039890448252

Epoch: 6| Step: 7
Training loss: 2.174487829208374
Validation loss: 2.0704577763875327

Epoch: 6| Step: 8
Training loss: 2.2621045112609863
Validation loss: 2.065624256928762

Epoch: 6| Step: 9
Training loss: 1.4092812538146973
Validation loss: 2.0678501526514688

Epoch: 6| Step: 10
Training loss: 2.3088111877441406
Validation loss: 2.061355193456014

Epoch: 6| Step: 11
Training loss: 2.1286182403564453
Validation loss: 2.0656373103459678

Epoch: 6| Step: 12
Training loss: 2.025582790374756
Validation loss: 2.0493200620015464

Epoch: 6| Step: 13
Training loss: 1.9099780321121216
Validation loss: 2.0484780073165894

Epoch: 130| Step: 0
Training loss: 1.90358304977417
Validation loss: 2.054746131102244

Epoch: 6| Step: 1
Training loss: 2.2110161781311035
Validation loss: 2.0581039786338806

Epoch: 6| Step: 2
Training loss: 2.6840906143188477
Validation loss: 2.0571345488230386

Epoch: 6| Step: 3
Training loss: 2.0805859565734863
Validation loss: 2.064090092976888

Epoch: 6| Step: 4
Training loss: 1.9180779457092285
Validation loss: 2.080323318640391

Epoch: 6| Step: 5
Training loss: 2.2179975509643555
Validation loss: 2.057191252708435

Epoch: 6| Step: 6
Training loss: 2.2771239280700684
Validation loss: 2.0692307551701865

Epoch: 6| Step: 7
Training loss: 1.7539637088775635
Validation loss: 2.067242125670115

Epoch: 6| Step: 8
Training loss: 2.666476249694824
Validation loss: 2.0745517015457153

Epoch: 6| Step: 9
Training loss: 1.8729057312011719
Validation loss: 2.0662800470987954

Epoch: 6| Step: 10
Training loss: 1.302152156829834
Validation loss: 2.073217252890269

Epoch: 6| Step: 11
Training loss: 2.2126030921936035
Validation loss: 2.074167470137278

Epoch: 6| Step: 12
Training loss: 1.9907512664794922
Validation loss: 2.0728986461957297

Epoch: 6| Step: 13
Training loss: 1.599019169807434
Validation loss: 2.0663039088249207

Epoch: 131| Step: 0
Training loss: 1.470951795578003
Validation loss: 2.065466582775116

Epoch: 6| Step: 1
Training loss: 2.039675235748291
Validation loss: 2.0676885843276978

Epoch: 6| Step: 2
Training loss: 1.931286096572876
Validation loss: 2.0444656213124595

Epoch: 6| Step: 3
Training loss: 2.9072046279907227
Validation loss: 2.0503492752710977

Epoch: 6| Step: 4
Training loss: 1.9607350826263428
Validation loss: 2.039912442366282

Epoch: 6| Step: 5
Training loss: 2.058398723602295
Validation loss: 2.045608639717102

Epoch: 6| Step: 6
Training loss: 2.0580809116363525
Validation loss: 2.0251601934432983

Epoch: 6| Step: 7
Training loss: 2.179164409637451
Validation loss: 2.0337795416514077

Epoch: 6| Step: 8
Training loss: 2.81858491897583
Validation loss: 2.028181552886963

Epoch: 6| Step: 9
Training loss: 1.708568811416626
Validation loss: 2.0275670488675437

Epoch: 6| Step: 10
Training loss: 2.0707812309265137
Validation loss: 2.0341588060061135

Epoch: 6| Step: 11
Training loss: 1.8605985641479492
Validation loss: 2.0458141764005027

Epoch: 6| Step: 12
Training loss: 1.6190097332000732
Validation loss: 2.0511954625447593

Epoch: 6| Step: 13
Training loss: 2.1368160247802734
Validation loss: 2.0586833159128823

Epoch: 132| Step: 0
Training loss: 2.0872490406036377
Validation loss: 2.061531643072764

Epoch: 6| Step: 1
Training loss: 2.901599407196045
Validation loss: 2.047022759914398

Epoch: 6| Step: 2
Training loss: 1.6591284275054932
Validation loss: 2.045980930328369

Epoch: 6| Step: 3
Training loss: 2.065981388092041
Validation loss: 2.0354457894961038

Epoch: 6| Step: 4
Training loss: 2.2419068813323975
Validation loss: 2.0374486247698465

Epoch: 6| Step: 5
Training loss: 1.869289755821228
Validation loss: 2.0358975927035012

Epoch: 6| Step: 6
Training loss: 1.778890609741211
Validation loss: 2.043225030104319

Epoch: 6| Step: 7
Training loss: 2.1362671852111816
Validation loss: 2.0451549092928567

Epoch: 6| Step: 8
Training loss: 2.6730947494506836
Validation loss: 2.0554505586624146

Epoch: 6| Step: 9
Training loss: 2.3922975063323975
Validation loss: 2.0590964953104653

Epoch: 6| Step: 10
Training loss: 1.4972662925720215
Validation loss: 2.047681967417399

Epoch: 6| Step: 11
Training loss: 2.055201530456543
Validation loss: 2.05390735467275

Epoch: 6| Step: 12
Training loss: 1.3487352132797241
Validation loss: 2.0683114926020303

Epoch: 6| Step: 13
Training loss: 2.023564100265503
Validation loss: 2.044185916582743

Epoch: 133| Step: 0
Training loss: 2.0846519470214844
Validation loss: 2.0616692503293357

Epoch: 6| Step: 1
Training loss: 1.4967405796051025
Validation loss: 2.064510961373647

Epoch: 6| Step: 2
Training loss: 2.255260944366455
Validation loss: 2.0665940244992576

Epoch: 6| Step: 3
Training loss: 1.9235196113586426
Validation loss: 2.0707843701044717

Epoch: 6| Step: 4
Training loss: 1.7903363704681396
Validation loss: 2.0739787220954895

Epoch: 6| Step: 5
Training loss: 2.335341453552246
Validation loss: 2.059186279773712

Epoch: 6| Step: 6
Training loss: 2.122824192047119
Validation loss: 2.059901237487793

Epoch: 6| Step: 7
Training loss: 1.6130893230438232
Validation loss: 2.060865819454193

Epoch: 6| Step: 8
Training loss: 2.7549705505371094
Validation loss: 2.0591540535291037

Epoch: 6| Step: 9
Training loss: 1.707955002784729
Validation loss: 2.068039278189341

Epoch: 6| Step: 10
Training loss: 1.813462495803833
Validation loss: 2.067020535469055

Epoch: 6| Step: 11
Training loss: 2.048063039779663
Validation loss: 2.063883364200592

Epoch: 6| Step: 12
Training loss: 1.8755228519439697
Validation loss: 2.0616053342819214

Epoch: 6| Step: 13
Training loss: 2.605315923690796
Validation loss: 2.060786008834839

Epoch: 134| Step: 0
Training loss: 1.8641870021820068
Validation loss: 2.061024765173594

Epoch: 6| Step: 1
Training loss: 2.323106050491333
Validation loss: 2.051312188307444

Epoch: 6| Step: 2
Training loss: 2.4662022590637207
Validation loss: 2.048938532670339

Epoch: 6| Step: 3
Training loss: 2.149965524673462
Validation loss: 2.0486013293266296

Epoch: 6| Step: 4
Training loss: 2.6679868698120117
Validation loss: 2.0348432461420694

Epoch: 6| Step: 5
Training loss: 1.491974115371704
Validation loss: 2.052197496096293

Epoch: 6| Step: 6
Training loss: 1.7852144241333008
Validation loss: 2.0489929914474487

Epoch: 6| Step: 7
Training loss: 1.9427649974822998
Validation loss: 2.046206772327423

Epoch: 6| Step: 8
Training loss: 1.771341323852539
Validation loss: 2.05685685078303

Epoch: 6| Step: 9
Training loss: 2.025611400604248
Validation loss: 2.0664876103401184

Epoch: 6| Step: 10
Training loss: 1.8437122106552124
Validation loss: 2.0502099990844727

Epoch: 6| Step: 11
Training loss: 1.7633705139160156
Validation loss: 2.061225672562917

Epoch: 6| Step: 12
Training loss: 2.2002241611480713
Validation loss: 2.0644150972366333

Epoch: 6| Step: 13
Training loss: 2.2303948402404785
Validation loss: 2.0710348089536033

Epoch: 135| Step: 0
Training loss: 2.5895566940307617
Validation loss: 2.0802806615829468

Epoch: 6| Step: 1
Training loss: 2.557007074356079
Validation loss: 2.0900427103042603

Epoch: 6| Step: 2
Training loss: 1.9173693656921387
Validation loss: 2.0853760639826455

Epoch: 6| Step: 3
Training loss: 2.6217167377471924
Validation loss: 2.0897030234336853

Epoch: 6| Step: 4
Training loss: 1.8106319904327393
Validation loss: 2.075671891371409

Epoch: 6| Step: 5
Training loss: 1.2824490070343018
Validation loss: 2.0977966586748757

Epoch: 6| Step: 6
Training loss: 1.911867618560791
Validation loss: 2.0745619932810464

Epoch: 6| Step: 7
Training loss: 1.831545352935791
Validation loss: 2.0891225934028625

Epoch: 6| Step: 8
Training loss: 1.8940939903259277
Validation loss: 2.0603978832562766

Epoch: 6| Step: 9
Training loss: 1.9922962188720703
Validation loss: 2.0525336066881814

Epoch: 6| Step: 10
Training loss: 2.2907767295837402
Validation loss: 2.057693044344584

Epoch: 6| Step: 11
Training loss: 2.102461338043213
Validation loss: 2.0494592984517417

Epoch: 6| Step: 12
Training loss: 1.8740413188934326
Validation loss: 2.046030282974243

Epoch: 6| Step: 13
Training loss: 1.9101686477661133
Validation loss: 2.0479478438695273

Epoch: 136| Step: 0
Training loss: 1.4697891473770142
Validation loss: 2.060926338036855

Epoch: 6| Step: 1
Training loss: 2.103792905807495
Validation loss: 2.0628050168355307

Epoch: 6| Step: 2
Training loss: 2.442620277404785
Validation loss: 2.0518530209859214

Epoch: 6| Step: 3
Training loss: 2.147815465927124
Validation loss: 2.0659619768460593

Epoch: 6| Step: 4
Training loss: 2.4259848594665527
Validation loss: 2.054766058921814

Epoch: 6| Step: 5
Training loss: 2.0007123947143555
Validation loss: 2.0493706862131753

Epoch: 6| Step: 6
Training loss: 2.001894950866699
Validation loss: 2.0492092768351235

Epoch: 6| Step: 7
Training loss: 2.0967984199523926
Validation loss: 2.0520591934521994

Epoch: 6| Step: 8
Training loss: 2.3722941875457764
Validation loss: 2.063400089740753

Epoch: 6| Step: 9
Training loss: 2.1086134910583496
Validation loss: 2.0519524017969766

Epoch: 6| Step: 10
Training loss: 1.6116366386413574
Validation loss: 2.060714364051819

Epoch: 6| Step: 11
Training loss: 1.9313493967056274
Validation loss: 2.0760957400004068

Epoch: 6| Step: 12
Training loss: 2.1738839149475098
Validation loss: 2.0743451913197837

Epoch: 6| Step: 13
Training loss: 2.1555533409118652
Validation loss: 2.0883406599362693

Epoch: 137| Step: 0
Training loss: 1.379464864730835
Validation loss: 2.0845415592193604

Epoch: 6| Step: 1
Training loss: 2.0789248943328857
Validation loss: 2.0847540299097695

Epoch: 6| Step: 2
Training loss: 2.5460219383239746
Validation loss: 2.087566832701365

Epoch: 6| Step: 3
Training loss: 2.1413581371307373
Validation loss: 2.079345405101776

Epoch: 6| Step: 4
Training loss: 2.2776002883911133
Validation loss: 2.0988999009132385

Epoch: 6| Step: 5
Training loss: 1.9720332622528076
Validation loss: 2.0947644114494324

Epoch: 6| Step: 6
Training loss: 2.961142063140869
Validation loss: 2.090663194656372

Epoch: 6| Step: 7
Training loss: 2.765204668045044
Validation loss: 2.0876194834709167

Epoch: 6| Step: 8
Training loss: 1.8795244693756104
Validation loss: 2.074433445930481

Epoch: 6| Step: 9
Training loss: 2.124376058578491
Validation loss: 2.062071363131205

Epoch: 6| Step: 10
Training loss: 1.8273887634277344
Validation loss: 2.0629902283350625

Epoch: 6| Step: 11
Training loss: 1.5340511798858643
Validation loss: 2.0654914180437722

Epoch: 6| Step: 12
Training loss: 1.1443061828613281
Validation loss: 2.0505241552988687

Epoch: 6| Step: 13
Training loss: 2.175227165222168
Validation loss: 2.062541643778483

Epoch: 138| Step: 0
Training loss: 1.7254140377044678
Validation loss: 2.0626927415529885

Epoch: 6| Step: 1
Training loss: 1.7105721235275269
Validation loss: 2.068973501523336

Epoch: 6| Step: 2
Training loss: 2.0329129695892334
Validation loss: 2.0743192632993064

Epoch: 6| Step: 3
Training loss: 1.9258489608764648
Validation loss: 2.0604891975720725

Epoch: 6| Step: 4
Training loss: 1.9561543464660645
Validation loss: 2.056897143522898

Epoch: 6| Step: 5
Training loss: 1.688557744026184
Validation loss: 2.057020882765452

Epoch: 6| Step: 6
Training loss: 1.6554443836212158
Validation loss: 2.046770771344503

Epoch: 6| Step: 7
Training loss: 3.2363529205322266
Validation loss: 2.0618515412012735

Epoch: 6| Step: 8
Training loss: 2.3212995529174805
Validation loss: 2.0681803623835244

Epoch: 6| Step: 9
Training loss: 2.009366750717163
Validation loss: 2.0548268755277

Epoch: 6| Step: 10
Training loss: 2.058448314666748
Validation loss: 2.070615530014038

Epoch: 6| Step: 11
Training loss: 2.3024115562438965
Validation loss: 2.073640545209249

Epoch: 6| Step: 12
Training loss: 1.8752758502960205
Validation loss: 2.062369187672933

Epoch: 6| Step: 13
Training loss: 1.9552133083343506
Validation loss: 2.0856906374295554

Epoch: 139| Step: 0
Training loss: 1.8051362037658691
Validation loss: 2.076707899570465

Epoch: 6| Step: 1
Training loss: 2.2454826831817627
Validation loss: 2.0884661078453064

Epoch: 6| Step: 2
Training loss: 2.3927950859069824
Validation loss: 2.0689701636632285

Epoch: 6| Step: 3
Training loss: 2.0807437896728516
Validation loss: 2.0686376293500266

Epoch: 6| Step: 4
Training loss: 2.198704957962036
Validation loss: 2.063773731390635

Epoch: 6| Step: 5
Training loss: 2.4457733631134033
Validation loss: 2.0567442973454795

Epoch: 6| Step: 6
Training loss: 1.7359379529953003
Validation loss: 2.049146811167399

Epoch: 6| Step: 7
Training loss: 2.174562454223633
Validation loss: 2.0422235131263733

Epoch: 6| Step: 8
Training loss: 1.9348387718200684
Validation loss: 2.048560599486033

Epoch: 6| Step: 9
Training loss: 2.367608070373535
Validation loss: 2.0422349174817405

Epoch: 6| Step: 10
Training loss: 1.8811362981796265
Validation loss: 2.0449973344802856

Epoch: 6| Step: 11
Training loss: 1.9982463121414185
Validation loss: 2.0438729921976724

Epoch: 6| Step: 12
Training loss: 1.7658708095550537
Validation loss: 2.0539005398750305

Epoch: 6| Step: 13
Training loss: 1.756001591682434
Validation loss: 2.0657924016316733

Epoch: 140| Step: 0
Training loss: 1.8367270231246948
Validation loss: 2.0755015214284263

Epoch: 6| Step: 1
Training loss: 2.079317092895508
Validation loss: 2.068968872229258

Epoch: 6| Step: 2
Training loss: 2.1465604305267334
Validation loss: 2.077687422434489

Epoch: 6| Step: 3
Training loss: 1.4230520725250244
Validation loss: 2.0785937110582986

Epoch: 6| Step: 4
Training loss: 2.0229263305664062
Validation loss: 2.079402963320414

Epoch: 6| Step: 5
Training loss: 2.0193324089050293
Validation loss: 2.0812416871388755

Epoch: 6| Step: 6
Training loss: 1.877745270729065
Validation loss: 2.082478702068329

Epoch: 6| Step: 7
Training loss: 2.3338634967803955
Validation loss: 2.097879628340403

Epoch: 6| Step: 8
Training loss: 2.2949042320251465
Validation loss: 2.100576023260752

Epoch: 6| Step: 9
Training loss: 2.0826573371887207
Validation loss: 2.1141722997029624

Epoch: 6| Step: 10
Training loss: 1.9516116380691528
Validation loss: 2.1003641883532205

Epoch: 6| Step: 11
Training loss: 1.8661929368972778
Validation loss: 2.0774532755215964

Epoch: 6| Step: 12
Training loss: 2.3611555099487305
Validation loss: 2.060398578643799

Epoch: 6| Step: 13
Training loss: 1.9994308948516846
Validation loss: 2.0393721063931785

Epoch: 141| Step: 0
Training loss: 1.863803744316101
Validation loss: 2.044403612613678

Epoch: 6| Step: 1
Training loss: 2.4405739307403564
Validation loss: 2.057362735271454

Epoch: 6| Step: 2
Training loss: 1.921943187713623
Validation loss: 2.0457964340845742

Epoch: 6| Step: 3
Training loss: 1.9276418685913086
Validation loss: 2.047493120034536

Epoch: 6| Step: 4
Training loss: 2.019087314605713
Validation loss: 2.040877322355906

Epoch: 6| Step: 5
Training loss: 2.33351731300354
Validation loss: 2.0476468801498413

Epoch: 6| Step: 6
Training loss: 2.4363694190979004
Validation loss: 2.0503775477409363

Epoch: 6| Step: 7
Training loss: 2.0989222526550293
Validation loss: 2.048706809679667

Epoch: 6| Step: 8
Training loss: 1.8744442462921143
Validation loss: 2.0344097216924033

Epoch: 6| Step: 9
Training loss: 2.2487359046936035
Validation loss: 2.0360791087150574

Epoch: 6| Step: 10
Training loss: 2.237147092819214
Validation loss: 2.037634710470835

Epoch: 6| Step: 11
Training loss: 2.559368848800659
Validation loss: 2.0390345056851706

Epoch: 6| Step: 12
Training loss: 1.7963802814483643
Validation loss: 2.0380218625068665

Epoch: 6| Step: 13
Training loss: 1.866223931312561
Validation loss: 2.0359851916631064

Epoch: 142| Step: 0
Training loss: 1.7142982482910156
Validation loss: 2.0256561636924744

Epoch: 6| Step: 1
Training loss: 2.1470208168029785
Validation loss: 2.0275824268658957

Epoch: 6| Step: 2
Training loss: 2.736693859100342
Validation loss: 2.020414193471273

Epoch: 6| Step: 3
Training loss: 2.110454559326172
Validation loss: 2.0349989930788674

Epoch: 6| Step: 4
Training loss: 1.7165504693984985
Validation loss: 2.0454384088516235

Epoch: 6| Step: 5
Training loss: 2.5521292686462402
Validation loss: 2.0728460550308228

Epoch: 6| Step: 6
Training loss: 2.4526572227478027
Validation loss: 2.0560697317123413

Epoch: 6| Step: 7
Training loss: 1.7638535499572754
Validation loss: 2.0916539430618286

Epoch: 6| Step: 8
Training loss: 2.2806432247161865
Validation loss: 2.097340146700541

Epoch: 6| Step: 9
Training loss: 2.006826877593994
Validation loss: 2.092689792315165

Epoch: 6| Step: 10
Training loss: 2.240779161453247
Validation loss: 2.0865387320518494

Epoch: 6| Step: 11
Training loss: 1.5454413890838623
Validation loss: 2.0548575719197593

Epoch: 6| Step: 12
Training loss: 1.8989847898483276
Validation loss: 2.0390837987264

Epoch: 6| Step: 13
Training loss: 1.588220238685608
Validation loss: 2.0341920256614685

Epoch: 143| Step: 0
Training loss: 1.9705853462219238
Validation loss: 2.0380356311798096

Epoch: 6| Step: 1
Training loss: 1.833533763885498
Validation loss: 2.0293372869491577

Epoch: 6| Step: 2
Training loss: 2.0598833560943604
Validation loss: 2.0234724084536233

Epoch: 6| Step: 3
Training loss: 1.52793288230896
Validation loss: 2.0271445314089456

Epoch: 6| Step: 4
Training loss: 2.1250662803649902
Validation loss: 2.036392629146576

Epoch: 6| Step: 5
Training loss: 1.8949650526046753
Validation loss: 2.036416709423065

Epoch: 6| Step: 6
Training loss: 2.2845282554626465
Validation loss: 2.050431172053019

Epoch: 6| Step: 7
Training loss: 1.4860599040985107
Validation loss: 2.0508300264676413

Epoch: 6| Step: 8
Training loss: 1.7595621347427368
Validation loss: 2.072212835152944

Epoch: 6| Step: 9
Training loss: 1.906266450881958
Validation loss: 2.080527146657308

Epoch: 6| Step: 10
Training loss: 2.5657827854156494
Validation loss: 2.07644255956014

Epoch: 6| Step: 11
Training loss: 2.5601558685302734
Validation loss: 2.0719760855038962

Epoch: 6| Step: 12
Training loss: 2.09818172454834
Validation loss: 2.0805312395095825

Epoch: 6| Step: 13
Training loss: 2.505963087081909
Validation loss: 2.0861427783966064

Epoch: 144| Step: 0
Training loss: 1.3066787719726562
Validation loss: 2.066047509511312

Epoch: 6| Step: 1
Training loss: 2.1484174728393555
Validation loss: 2.0720800161361694

Epoch: 6| Step: 2
Training loss: 1.9587026834487915
Validation loss: 2.0665947596232095

Epoch: 6| Step: 3
Training loss: 2.3602118492126465
Validation loss: 2.0666715105374656

Epoch: 6| Step: 4
Training loss: 1.6952084302902222
Validation loss: 2.058980663617452

Epoch: 6| Step: 5
Training loss: 2.1430516242980957
Validation loss: 2.048228402932485

Epoch: 6| Step: 6
Training loss: 2.370142936706543
Validation loss: 2.053650518258413

Epoch: 6| Step: 7
Training loss: 1.5248558521270752
Validation loss: 2.0554548501968384

Epoch: 6| Step: 8
Training loss: 2.117422580718994
Validation loss: 2.059385120868683

Epoch: 6| Step: 9
Training loss: 2.29935359954834
Validation loss: 2.0549124677975974

Epoch: 6| Step: 10
Training loss: 2.122756004333496
Validation loss: 2.0419622461001077

Epoch: 6| Step: 11
Training loss: 1.9512622356414795
Validation loss: 2.055585344632467

Epoch: 6| Step: 12
Training loss: 2.109600067138672
Validation loss: 2.050249437491099

Epoch: 6| Step: 13
Training loss: 2.2021565437316895
Validation loss: 2.057617982228597

Epoch: 145| Step: 0
Training loss: 2.7043967247009277
Validation loss: 2.047605832417806

Epoch: 6| Step: 1
Training loss: 1.5693984031677246
Validation loss: 2.048254450162252

Epoch: 6| Step: 2
Training loss: 1.7882928848266602
Validation loss: 2.042027990023295

Epoch: 6| Step: 3
Training loss: 1.9409615993499756
Validation loss: 2.058345357577006

Epoch: 6| Step: 4
Training loss: 1.5791449546813965
Validation loss: 2.050961176554362

Epoch: 6| Step: 5
Training loss: 1.9087903499603271
Validation loss: 2.0672969222068787

Epoch: 6| Step: 6
Training loss: 1.6610872745513916
Validation loss: 2.072311282157898

Epoch: 6| Step: 7
Training loss: 2.6273207664489746
Validation loss: 2.078323940436045

Epoch: 6| Step: 8
Training loss: 2.503567934036255
Validation loss: 2.075081765651703

Epoch: 6| Step: 9
Training loss: 2.101522922515869
Validation loss: 2.087152818838755

Epoch: 6| Step: 10
Training loss: 2.487027645111084
Validation loss: 2.087246517340342

Epoch: 6| Step: 11
Training loss: 1.5348812341690063
Validation loss: 2.1033592422803244

Epoch: 6| Step: 12
Training loss: 2.2136411666870117
Validation loss: 2.0811221996943154

Epoch: 6| Step: 13
Training loss: 1.6908981800079346
Validation loss: 2.0883416732152305

Epoch: 146| Step: 0
Training loss: 3.171875476837158
Validation loss: 2.0929835637410483

Epoch: 6| Step: 1
Training loss: 1.8217698335647583
Validation loss: 2.0846954385439553

Epoch: 6| Step: 2
Training loss: 1.9685295820236206
Validation loss: 2.1033517718315125

Epoch: 6| Step: 3
Training loss: 2.188269853591919
Validation loss: 2.08394318819046

Epoch: 6| Step: 4
Training loss: 1.8820220232009888
Validation loss: 2.0838796297709146

Epoch: 6| Step: 5
Training loss: 2.503305196762085
Validation loss: 2.0886496702829995

Epoch: 6| Step: 6
Training loss: 1.562608242034912
Validation loss: 2.0676675836245217

Epoch: 6| Step: 7
Training loss: 1.8346803188323975
Validation loss: 2.0733282566070557

Epoch: 6| Step: 8
Training loss: 2.0428411960601807
Validation loss: 2.072343170642853

Epoch: 6| Step: 9
Training loss: 1.6462821960449219
Validation loss: 2.0690807501475015

Epoch: 6| Step: 10
Training loss: 2.429013729095459
Validation loss: 2.059199889500936

Epoch: 6| Step: 11
Training loss: 1.67703115940094
Validation loss: 2.0677075584729514

Epoch: 6| Step: 12
Training loss: 1.5389666557312012
Validation loss: 2.0634073615074158

Epoch: 6| Step: 13
Training loss: 1.672142505645752
Validation loss: 2.0740750233332315

Epoch: 147| Step: 0
Training loss: 1.9193588495254517
Validation loss: 2.083524147669474

Epoch: 6| Step: 1
Training loss: 1.349509358406067
Validation loss: 2.089209775129954

Epoch: 6| Step: 2
Training loss: 1.4979710578918457
Validation loss: 2.1009218096733093

Epoch: 6| Step: 3
Training loss: 1.8532841205596924
Validation loss: 2.058461368083954

Epoch: 6| Step: 4
Training loss: 2.2653098106384277
Validation loss: 2.077603578567505

Epoch: 6| Step: 5
Training loss: 1.8454312086105347
Validation loss: 2.058734039465586

Epoch: 6| Step: 6
Training loss: 1.6467440128326416
Validation loss: 2.059777796268463

Epoch: 6| Step: 7
Training loss: 1.9801911115646362
Validation loss: 2.067400356133779

Epoch: 6| Step: 8
Training loss: 2.4836931228637695
Validation loss: 2.069082339604696

Epoch: 6| Step: 9
Training loss: 2.331221580505371
Validation loss: 2.063989063103994

Epoch: 6| Step: 10
Training loss: 1.5952661037445068
Validation loss: 2.0684712727864585

Epoch: 6| Step: 11
Training loss: 2.1430907249450684
Validation loss: 2.0525949398676553

Epoch: 6| Step: 12
Training loss: 2.916195869445801
Validation loss: 2.071698009967804

Epoch: 6| Step: 13
Training loss: 2.2997119426727295
Validation loss: 2.0747393369674683

Epoch: 148| Step: 0
Training loss: 1.4256092309951782
Validation loss: 2.0915598273277283

Epoch: 6| Step: 1
Training loss: 2.2830185890197754
Validation loss: 2.096245845158895

Epoch: 6| Step: 2
Training loss: 1.4450430870056152
Validation loss: 2.097299555937449

Epoch: 6| Step: 3
Training loss: 2.1201882362365723
Validation loss: 2.093555967013041

Epoch: 6| Step: 4
Training loss: 1.3331979513168335
Validation loss: 2.109902540842692

Epoch: 6| Step: 5
Training loss: 2.1497864723205566
Validation loss: 2.110043168067932

Epoch: 6| Step: 6
Training loss: 1.8936126232147217
Validation loss: 2.1123299598693848

Epoch: 6| Step: 7
Training loss: 1.7626111507415771
Validation loss: 2.1102404395739236

Epoch: 6| Step: 8
Training loss: 2.3150484561920166
Validation loss: 2.095632632573446

Epoch: 6| Step: 9
Training loss: 2.2290852069854736
Validation loss: 2.092574675877889

Epoch: 6| Step: 10
Training loss: 2.650740146636963
Validation loss: 2.080448865890503

Epoch: 6| Step: 11
Training loss: 1.9458277225494385
Validation loss: 2.080905318260193

Epoch: 6| Step: 12
Training loss: 1.2769559621810913
Validation loss: 2.0791631937026978

Epoch: 6| Step: 13
Training loss: 3.0384573936462402
Validation loss: 2.062878410021464

Epoch: 149| Step: 0
Training loss: 1.6982388496398926
Validation loss: 2.06798126300176

Epoch: 6| Step: 1
Training loss: 2.110102891921997
Validation loss: 2.0788074135780334

Epoch: 6| Step: 2
Training loss: 2.548572540283203
Validation loss: 2.0667788982391357

Epoch: 6| Step: 3
Training loss: 1.8365521430969238
Validation loss: 2.0542132457097373

Epoch: 6| Step: 4
Training loss: 1.9646689891815186
Validation loss: 2.0621772607167563

Epoch: 6| Step: 5
Training loss: 1.9127826690673828
Validation loss: 2.0576297839482627

Epoch: 6| Step: 6
Training loss: 1.8331961631774902
Validation loss: 2.0563597877820334

Epoch: 6| Step: 7
Training loss: 1.7281107902526855
Validation loss: 2.063688496748606

Epoch: 6| Step: 8
Training loss: 1.6000607013702393
Validation loss: 2.062239348888397

Epoch: 6| Step: 9
Training loss: 2.059229850769043
Validation loss: 2.051017105579376

Epoch: 6| Step: 10
Training loss: 2.6253437995910645
Validation loss: 2.0564696987469993

Epoch: 6| Step: 11
Training loss: 2.184462547302246
Validation loss: 2.060200273990631

Epoch: 6| Step: 12
Training loss: 1.5345120429992676
Validation loss: 2.081755757331848

Epoch: 6| Step: 13
Training loss: 2.6797876358032227
Validation loss: 2.087801218032837

Epoch: 150| Step: 0
Training loss: 2.053555965423584
Validation loss: 2.086793303489685

Epoch: 6| Step: 1
Training loss: 1.5125995874404907
Validation loss: 2.085799197355906

Epoch: 6| Step: 2
Training loss: 1.9806292057037354
Validation loss: 2.0711753765741983

Epoch: 6| Step: 3
Training loss: 2.1892857551574707
Validation loss: 2.0652116735776267

Epoch: 6| Step: 4
Training loss: 2.5072507858276367
Validation loss: 2.0477325717608132

Epoch: 6| Step: 5
Training loss: 2.457244396209717
Validation loss: 2.079127768675486

Epoch: 6| Step: 6
Training loss: 1.813713550567627
Validation loss: 2.081126868724823

Epoch: 6| Step: 7
Training loss: 1.7543530464172363
Validation loss: 2.0566562612851462

Epoch: 6| Step: 8
Training loss: 2.387298583984375
Validation loss: 2.06132564942042

Epoch: 6| Step: 9
Training loss: 1.5838701725006104
Validation loss: 2.062159518400828

Epoch: 6| Step: 10
Training loss: 2.0705766677856445
Validation loss: 2.0622378985087075

Epoch: 6| Step: 11
Training loss: 2.4184389114379883
Validation loss: 2.083390017350515

Epoch: 6| Step: 12
Training loss: 1.6585218906402588
Validation loss: 2.082538823286692

Epoch: 6| Step: 13
Training loss: 1.7475528717041016
Validation loss: 2.0706921219825745

Epoch: 151| Step: 0
Training loss: 1.4182300567626953
Validation loss: 2.063151776790619

Epoch: 6| Step: 1
Training loss: 1.6402534246444702
Validation loss: 2.0711031754811606

Epoch: 6| Step: 2
Training loss: 1.4734152555465698
Validation loss: 2.0890669425328574

Epoch: 6| Step: 3
Training loss: 2.173717975616455
Validation loss: 2.1071003079414368

Epoch: 6| Step: 4
Training loss: 2.223595380783081
Validation loss: 2.088282267252604

Epoch: 6| Step: 5
Training loss: 2.7150931358337402
Validation loss: 2.108743687470754

Epoch: 6| Step: 6
Training loss: 1.9088914394378662
Validation loss: 2.0848416686058044

Epoch: 6| Step: 7
Training loss: 2.2074649333953857
Validation loss: 2.1045135060946145

Epoch: 6| Step: 8
Training loss: 2.1684486865997314
Validation loss: 2.1091856757799783

Epoch: 6| Step: 9
Training loss: 1.8340433835983276
Validation loss: 2.0896560549736023

Epoch: 6| Step: 10
Training loss: 2.1168630123138428
Validation loss: 2.094017803668976

Epoch: 6| Step: 11
Training loss: 1.712737798690796
Validation loss: 2.103380044301351

Epoch: 6| Step: 12
Training loss: 2.2714738845825195
Validation loss: 2.0939080317815146

Epoch: 6| Step: 13
Training loss: 2.141510486602783
Validation loss: 2.108187735080719

Epoch: 152| Step: 0
Training loss: 1.4404058456420898
Validation loss: 2.1163829565048218

Epoch: 6| Step: 1
Training loss: 1.8224365711212158
Validation loss: 2.1065880060195923

Epoch: 6| Step: 2
Training loss: 2.117770195007324
Validation loss: 2.100950916608175

Epoch: 6| Step: 3
Training loss: 2.4212586879730225
Validation loss: 2.10518346230189

Epoch: 6| Step: 4
Training loss: 1.1763393878936768
Validation loss: 2.1011064847310386

Epoch: 6| Step: 5
Training loss: 2.1074347496032715
Validation loss: 2.090573867162069

Epoch: 6| Step: 6
Training loss: 2.740847110748291
Validation loss: 2.100281020005544

Epoch: 6| Step: 7
Training loss: 1.6045355796813965
Validation loss: 2.080313265323639

Epoch: 6| Step: 8
Training loss: 1.6797466278076172
Validation loss: 2.0929728349049888

Epoch: 6| Step: 9
Training loss: 2.3775882720947266
Validation loss: 2.0563005010286965

Epoch: 6| Step: 10
Training loss: 1.983485221862793
Validation loss: 2.0843772490819297

Epoch: 6| Step: 11
Training loss: 1.7857348918914795
Validation loss: 2.0675463477770486

Epoch: 6| Step: 12
Training loss: 2.6070404052734375
Validation loss: 2.093743165334066

Epoch: 6| Step: 13
Training loss: 2.1023426055908203
Validation loss: 2.079957664012909

Epoch: 153| Step: 0
Training loss: 1.8361949920654297
Validation loss: 2.082058926423391

Epoch: 6| Step: 1
Training loss: 1.828671932220459
Validation loss: 2.083426554997762

Epoch: 6| Step: 2
Training loss: 1.8396885395050049
Validation loss: 2.082996884981791

Epoch: 6| Step: 3
Training loss: 2.3246774673461914
Validation loss: 2.070634444554647

Epoch: 6| Step: 4
Training loss: 2.142791986465454
Validation loss: 2.0767710208892822

Epoch: 6| Step: 5
Training loss: 1.8624835014343262
Validation loss: 2.0715823968251548

Epoch: 6| Step: 6
Training loss: 2.250774383544922
Validation loss: 2.077335000038147

Epoch: 6| Step: 7
Training loss: 2.5461273193359375
Validation loss: 2.0795828302701316

Epoch: 6| Step: 8
Training loss: 1.9296832084655762
Validation loss: 2.078711748123169

Epoch: 6| Step: 9
Training loss: 2.0350382328033447
Validation loss: 2.0810521046320596

Epoch: 6| Step: 10
Training loss: 1.9990952014923096
Validation loss: 2.077052672704061

Epoch: 6| Step: 11
Training loss: 1.1557679176330566
Validation loss: 2.0745736161867776

Epoch: 6| Step: 12
Training loss: 2.008016586303711
Validation loss: 2.066497266292572

Epoch: 6| Step: 13
Training loss: 2.3064401149749756
Validation loss: 2.072911262512207

Epoch: 154| Step: 0
Training loss: 2.255758762359619
Validation loss: 2.0706104238828025

Epoch: 6| Step: 1
Training loss: 1.599184274673462
Validation loss: 2.0684497555096946

Epoch: 6| Step: 2
Training loss: 1.4561318159103394
Validation loss: 2.0649829308191934

Epoch: 6| Step: 3
Training loss: 2.3844101428985596
Validation loss: 2.0721356868743896

Epoch: 6| Step: 4
Training loss: 1.6584237813949585
Validation loss: 2.0711591243743896

Epoch: 6| Step: 5
Training loss: 2.5860986709594727
Validation loss: 2.069974641005198

Epoch: 6| Step: 6
Training loss: 1.7767844200134277
Validation loss: 2.072523852189382

Epoch: 6| Step: 7
Training loss: 2.396378993988037
Validation loss: 2.073894282182058

Epoch: 6| Step: 8
Training loss: 1.8896420001983643
Validation loss: 2.078468600908915

Epoch: 6| Step: 9
Training loss: 1.6499857902526855
Validation loss: 2.0762535532315574

Epoch: 6| Step: 10
Training loss: 1.6056983470916748
Validation loss: 2.071492632230123

Epoch: 6| Step: 11
Training loss: 1.8600399494171143
Validation loss: 2.0815106431643167

Epoch: 6| Step: 12
Training loss: 2.207732677459717
Validation loss: 2.079994181791941

Epoch: 6| Step: 13
Training loss: 3.277390956878662
Validation loss: 2.086607734362284

Epoch: 155| Step: 0
Training loss: 1.8996436595916748
Validation loss: 2.1046058932940164

Epoch: 6| Step: 1
Training loss: 2.091775417327881
Validation loss: 2.1257207791010537

Epoch: 6| Step: 2
Training loss: 1.554642915725708
Validation loss: 2.1137259205182395

Epoch: 6| Step: 3
Training loss: 1.601686954498291
Validation loss: 2.108345905939738

Epoch: 6| Step: 4
Training loss: 2.020359992980957
Validation loss: 2.1126503348350525

Epoch: 6| Step: 5
Training loss: 2.1259734630584717
Validation loss: 2.1169334053993225

Epoch: 6| Step: 6
Training loss: 2.136439800262451
Validation loss: 2.1108316580454507

Epoch: 6| Step: 7
Training loss: 1.5847184658050537
Validation loss: 2.118465304374695

Epoch: 6| Step: 8
Training loss: 2.221386432647705
Validation loss: 2.103826344013214

Epoch: 6| Step: 9
Training loss: 2.201211452484131
Validation loss: 2.1081432501475015

Epoch: 6| Step: 10
Training loss: 1.9998958110809326
Validation loss: 2.101092596848806

Epoch: 6| Step: 11
Training loss: 2.664478302001953
Validation loss: 2.0950708190600076

Epoch: 6| Step: 12
Training loss: 2.579360008239746
Validation loss: 2.075594186782837

Epoch: 6| Step: 13
Training loss: 1.4820713996887207
Validation loss: 2.0789570411046348

Epoch: 156| Step: 0
Training loss: 1.8663655519485474
Validation loss: 2.0751309990882874

Epoch: 6| Step: 1
Training loss: 1.795884609222412
Validation loss: 2.0782437523206077

Epoch: 6| Step: 2
Training loss: 1.9761841297149658
Validation loss: 2.068542003631592

Epoch: 6| Step: 3
Training loss: 2.3712263107299805
Validation loss: 2.0772069096565247

Epoch: 6| Step: 4
Training loss: 2.02968168258667
Validation loss: 2.073388457298279

Epoch: 6| Step: 5
Training loss: 1.5801799297332764
Validation loss: 2.085610806941986

Epoch: 6| Step: 6
Training loss: 1.5751961469650269
Validation loss: 2.080913702646891

Epoch: 6| Step: 7
Training loss: 2.310070276260376
Validation loss: 2.07855757077535

Epoch: 6| Step: 8
Training loss: 2.2710232734680176
Validation loss: 2.0841146111488342

Epoch: 6| Step: 9
Training loss: 1.836439847946167
Validation loss: 2.092805723349253

Epoch: 6| Step: 10
Training loss: 2.307986259460449
Validation loss: 2.0999748508135476

Epoch: 6| Step: 11
Training loss: 2.335517406463623
Validation loss: 2.085642457008362

Epoch: 6| Step: 12
Training loss: 1.918713092803955
Validation loss: 2.0983315110206604

Epoch: 6| Step: 13
Training loss: 1.9285460710525513
Validation loss: 2.0970659255981445

Epoch: 157| Step: 0
Training loss: 2.3218343257904053
Validation loss: 2.085606058438619

Epoch: 6| Step: 1
Training loss: 1.916982889175415
Validation loss: 2.0961796243985495

Epoch: 6| Step: 2
Training loss: 2.001751661300659
Validation loss: 2.0951645771662393

Epoch: 6| Step: 3
Training loss: 1.6470222473144531
Validation loss: 2.079825977484385

Epoch: 6| Step: 4
Training loss: 1.6415460109710693
Validation loss: 2.0946879188219705

Epoch: 6| Step: 5
Training loss: 2.01100754737854
Validation loss: 2.0818639596303306

Epoch: 6| Step: 6
Training loss: 2.8917174339294434
Validation loss: 2.0975584387779236

Epoch: 6| Step: 7
Training loss: 2.0400099754333496
Validation loss: 2.0934608578681946

Epoch: 6| Step: 8
Training loss: 1.6669836044311523
Validation loss: 2.097796400388082

Epoch: 6| Step: 9
Training loss: 2.0390305519104004
Validation loss: 2.0832907358805337

Epoch: 6| Step: 10
Training loss: 2.139275074005127
Validation loss: 2.083367943763733

Epoch: 6| Step: 11
Training loss: 1.7944531440734863
Validation loss: 2.0928651889165244

Epoch: 6| Step: 12
Training loss: 2.0144290924072266
Validation loss: 2.0713738997777305

Epoch: 6| Step: 13
Training loss: 1.7054824829101562
Validation loss: 2.080087423324585

Epoch: 158| Step: 0
Training loss: 2.230043411254883
Validation loss: 2.0755185087521872

Epoch: 6| Step: 1
Training loss: 1.5947848558425903
Validation loss: 2.0677743355433145

Epoch: 6| Step: 2
Training loss: 1.5445024967193604
Validation loss: 2.082909266153971

Epoch: 6| Step: 3
Training loss: 2.432231903076172
Validation loss: 2.0858251452445984

Epoch: 6| Step: 4
Training loss: 1.8151646852493286
Validation loss: 2.0896326899528503

Epoch: 6| Step: 5
Training loss: 1.9676837921142578
Validation loss: 2.0868284702301025

Epoch: 6| Step: 6
Training loss: 2.1403212547302246
Validation loss: 2.084026515483856

Epoch: 6| Step: 7
Training loss: 1.594510793685913
Validation loss: 2.0928117434183755

Epoch: 6| Step: 8
Training loss: 2.127497911453247
Validation loss: 2.0900571942329407

Epoch: 6| Step: 9
Training loss: 1.6845537424087524
Validation loss: 2.097674608230591

Epoch: 6| Step: 10
Training loss: 1.790203332901001
Validation loss: 2.1040133436520896

Epoch: 6| Step: 11
Training loss: 1.9607462882995605
Validation loss: 2.0923688411712646

Epoch: 6| Step: 12
Training loss: 2.3086154460906982
Validation loss: 2.101070682207743

Epoch: 6| Step: 13
Training loss: 2.464561939239502
Validation loss: 2.102134903271993

Epoch: 159| Step: 0
Training loss: 2.5867719650268555
Validation loss: 2.0858747561772666

Epoch: 6| Step: 1
Training loss: 1.9325191974639893
Validation loss: 2.1028721729914346

Epoch: 6| Step: 2
Training loss: 1.5850907564163208
Validation loss: 2.0860337615013123

Epoch: 6| Step: 3
Training loss: 2.618692398071289
Validation loss: 2.097792903582255

Epoch: 6| Step: 4
Training loss: 1.657225251197815
Validation loss: 2.1051747600237527

Epoch: 6| Step: 5
Training loss: 2.0358853340148926
Validation loss: 2.10110870997111

Epoch: 6| Step: 6
Training loss: 1.5231109857559204
Validation loss: 2.1112482150395713

Epoch: 6| Step: 7
Training loss: 2.53591251373291
Validation loss: 2.1085791985193887

Epoch: 6| Step: 8
Training loss: 1.830183506011963
Validation loss: 2.1019997795422873

Epoch: 6| Step: 9
Training loss: 1.9048047065734863
Validation loss: 2.1089001099268594

Epoch: 6| Step: 10
Training loss: 1.396142840385437
Validation loss: 2.115661104520162

Epoch: 6| Step: 11
Training loss: 1.868878960609436
Validation loss: 2.1213131745656333

Epoch: 6| Step: 12
Training loss: 2.5632164478302
Validation loss: 2.1314023534456887

Epoch: 6| Step: 13
Training loss: 1.818188190460205
Validation loss: 2.110470414161682

Epoch: 160| Step: 0
Training loss: 1.6932094097137451
Validation loss: 2.110089878241221

Epoch: 6| Step: 1
Training loss: 1.561558485031128
Validation loss: 2.0888802806536355

Epoch: 6| Step: 2
Training loss: 2.569931983947754
Validation loss: 2.074820081392924

Epoch: 6| Step: 3
Training loss: 1.5349359512329102
Validation loss: 2.0751022497812905

Epoch: 6| Step: 4
Training loss: 1.7647385597229004
Validation loss: 2.090209484100342

Epoch: 6| Step: 5
Training loss: 2.436488151550293
Validation loss: 2.0825581153233848

Epoch: 6| Step: 6
Training loss: 1.5926543474197388
Validation loss: 2.0881641109784446

Epoch: 6| Step: 7
Training loss: 2.255183219909668
Validation loss: 2.0851839979489646

Epoch: 6| Step: 8
Training loss: 2.312507152557373
Validation loss: 2.079697926839193

Epoch: 6| Step: 9
Training loss: 1.84379243850708
Validation loss: 2.068824529647827

Epoch: 6| Step: 10
Training loss: 2.7195751667022705
Validation loss: 2.071746548016866

Epoch: 6| Step: 11
Training loss: 1.6560592651367188
Validation loss: 2.067055364449819

Epoch: 6| Step: 12
Training loss: 1.9619892835617065
Validation loss: 2.0858830213546753

Epoch: 6| Step: 13
Training loss: 2.0995140075683594
Validation loss: 2.0819920698801675

Epoch: 161| Step: 0
Training loss: 2.4061496257781982
Validation loss: 2.0839665730794272

Epoch: 6| Step: 1
Training loss: 2.322531223297119
Validation loss: 2.1037577986717224

Epoch: 6| Step: 2
Training loss: 1.5932281017303467
Validation loss: 2.1054212053616843

Epoch: 6| Step: 3
Training loss: 2.100106716156006
Validation loss: 2.106787999471029

Epoch: 6| Step: 4
Training loss: 1.8877053260803223
Validation loss: 2.104610721270243

Epoch: 6| Step: 5
Training loss: 1.5887153148651123
Validation loss: 2.1252511739730835

Epoch: 6| Step: 6
Training loss: 2.4148473739624023
Validation loss: 2.117159048716227

Epoch: 6| Step: 7
Training loss: 1.9689855575561523
Validation loss: 2.1039186914761863

Epoch: 6| Step: 8
Training loss: 2.3267977237701416
Validation loss: 2.123049179712931

Epoch: 6| Step: 9
Training loss: 1.7701236009597778
Validation loss: 2.1142218510309854

Epoch: 6| Step: 10
Training loss: 1.8880993127822876
Validation loss: 2.0999669830004373

Epoch: 6| Step: 11
Training loss: 2.8476741313934326
Validation loss: 2.0973411202430725

Epoch: 6| Step: 12
Training loss: 1.4706757068634033
Validation loss: 2.090250333150228

Epoch: 6| Step: 13
Training loss: 1.3079402446746826
Validation loss: 2.0860495964686074

Epoch: 162| Step: 0
Training loss: 2.3408260345458984
Validation loss: 2.0791595776875815

Epoch: 6| Step: 1
Training loss: 1.775505781173706
Validation loss: 2.0754252473513284

Epoch: 6| Step: 2
Training loss: 1.4978796243667603
Validation loss: 2.064103623231252

Epoch: 6| Step: 3
Training loss: 1.908920168876648
Validation loss: 2.0637214183807373

Epoch: 6| Step: 4
Training loss: 1.1965177059173584
Validation loss: 2.0686994791030884

Epoch: 6| Step: 5
Training loss: 2.2710084915161133
Validation loss: 2.0876903931299844

Epoch: 6| Step: 6
Training loss: 2.520598888397217
Validation loss: 2.084664543469747

Epoch: 6| Step: 7
Training loss: 2.4858016967773438
Validation loss: 2.084795276323954

Epoch: 6| Step: 8
Training loss: 2.02276349067688
Validation loss: 2.082437038421631

Epoch: 6| Step: 9
Training loss: 1.73179292678833
Validation loss: 2.092690885066986

Epoch: 6| Step: 10
Training loss: 2.5399627685546875
Validation loss: 2.0921982526779175

Epoch: 6| Step: 11
Training loss: 1.6117547750473022
Validation loss: 2.1031435132026672

Epoch: 6| Step: 12
Training loss: 2.1669485569000244
Validation loss: 2.1065868933995566

Epoch: 6| Step: 13
Training loss: 1.8354085683822632
Validation loss: 2.1043097575505576

Epoch: 163| Step: 0
Training loss: 1.5815956592559814
Validation loss: 2.0985929369926453

Epoch: 6| Step: 1
Training loss: 1.8019201755523682
Validation loss: 2.0997535785039267

Epoch: 6| Step: 2
Training loss: 1.9341567754745483
Validation loss: 2.0958967804908752

Epoch: 6| Step: 3
Training loss: 1.7718437910079956
Validation loss: 2.086140771706899

Epoch: 6| Step: 4
Training loss: 1.960716962814331
Validation loss: 2.088019688924154

Epoch: 6| Step: 5
Training loss: 1.8887252807617188
Validation loss: 2.0817988514900208

Epoch: 6| Step: 6
Training loss: 2.8580331802368164
Validation loss: 2.0840990940729776

Epoch: 6| Step: 7
Training loss: 2.970125675201416
Validation loss: 2.100425044695536

Epoch: 6| Step: 8
Training loss: 1.6683070659637451
Validation loss: 2.1008854111035666

Epoch: 6| Step: 9
Training loss: 2.109037399291992
Validation loss: 2.0805868903795877

Epoch: 6| Step: 10
Training loss: 1.4846590757369995
Validation loss: 2.0726025303204856

Epoch: 6| Step: 11
Training loss: 1.7105038166046143
Validation loss: 2.073925018310547

Epoch: 6| Step: 12
Training loss: 1.6178444623947144
Validation loss: 2.0807101329167685

Epoch: 6| Step: 13
Training loss: 2.1575772762298584
Validation loss: 2.068741500377655

Epoch: 164| Step: 0
Training loss: 1.7834019660949707
Validation loss: 2.071196436882019

Epoch: 6| Step: 1
Training loss: 2.11002254486084
Validation loss: 2.0610627929369607

Epoch: 6| Step: 2
Training loss: 1.5752267837524414
Validation loss: 2.0755779147148132

Epoch: 6| Step: 3
Training loss: 2.265230178833008
Validation loss: 2.0724360942840576

Epoch: 6| Step: 4
Training loss: 1.9472694396972656
Validation loss: 2.0772592624028525

Epoch: 6| Step: 5
Training loss: 1.527771234512329
Validation loss: 2.078478137652079

Epoch: 6| Step: 6
Training loss: 2.177379608154297
Validation loss: 2.080412824948629

Epoch: 6| Step: 7
Training loss: 1.847949743270874
Validation loss: 2.090372065703074

Epoch: 6| Step: 8
Training loss: 2.3131308555603027
Validation loss: 2.086298485596975

Epoch: 6| Step: 9
Training loss: 2.0763816833496094
Validation loss: 2.1005878845850625

Epoch: 6| Step: 10
Training loss: 2.4054908752441406
Validation loss: 2.0899976094563804

Epoch: 6| Step: 11
Training loss: 1.8692971467971802
Validation loss: 2.094107429186503

Epoch: 6| Step: 12
Training loss: 2.30790638923645
Validation loss: 2.119265556335449

Epoch: 6| Step: 13
Training loss: 1.6229140758514404
Validation loss: 2.116641382376353

Epoch: 165| Step: 0
Training loss: 1.4795246124267578
Validation loss: 2.1323756178220115

Epoch: 6| Step: 1
Training loss: 1.6772555112838745
Validation loss: 2.101826270421346

Epoch: 6| Step: 2
Training loss: 1.407126545906067
Validation loss: 2.1145354310671487

Epoch: 6| Step: 3
Training loss: 1.5240103006362915
Validation loss: 2.11677614847819

Epoch: 6| Step: 4
Training loss: 1.7119346857070923
Validation loss: 2.121337612469991

Epoch: 6| Step: 5
Training loss: 2.3793182373046875
Validation loss: 2.1147095362345376

Epoch: 6| Step: 6
Training loss: 2.3853507041931152
Validation loss: 2.116916239261627

Epoch: 6| Step: 7
Training loss: 2.738746404647827
Validation loss: 2.0929506023724875

Epoch: 6| Step: 8
Training loss: 1.8396053314208984
Validation loss: 2.109949270884196

Epoch: 6| Step: 9
Training loss: 2.235917568206787
Validation loss: 2.098054508368174

Epoch: 6| Step: 10
Training loss: 1.4685992002487183
Validation loss: 2.077779690424601

Epoch: 6| Step: 11
Training loss: 2.410691738128662
Validation loss: 2.0767235159873962

Epoch: 6| Step: 12
Training loss: 1.8648825883865356
Validation loss: 2.0794734358787537

Epoch: 6| Step: 13
Training loss: 2.0367815494537354
Validation loss: 2.0776901841163635

Epoch: 166| Step: 0
Training loss: 1.5944068431854248
Validation loss: 2.0913301904996238

Epoch: 6| Step: 1
Training loss: 1.536155104637146
Validation loss: 2.108791391054789

Epoch: 6| Step: 2
Training loss: 2.1165895462036133
Validation loss: 2.098721126715342

Epoch: 6| Step: 3
Training loss: 1.7775912284851074
Validation loss: 2.129084805647532

Epoch: 6| Step: 4
Training loss: 2.039612293243408
Validation loss: 2.121810813744863

Epoch: 6| Step: 5
Training loss: 1.7159112691879272
Validation loss: 2.110792597134908

Epoch: 6| Step: 6
Training loss: 1.9285221099853516
Validation loss: 2.122364123662313

Epoch: 6| Step: 7
Training loss: 1.4220435619354248
Validation loss: 2.116935153802236

Epoch: 6| Step: 8
Training loss: 2.6741340160369873
Validation loss: 2.1051118572553

Epoch: 6| Step: 9
Training loss: 2.1536498069763184
Validation loss: 2.104848623275757

Epoch: 6| Step: 10
Training loss: 2.170912265777588
Validation loss: 2.095818738142649

Epoch: 6| Step: 11
Training loss: 2.474898099899292
Validation loss: 2.1027785539627075

Epoch: 6| Step: 12
Training loss: 1.7955764532089233
Validation loss: 2.108527580897013

Epoch: 6| Step: 13
Training loss: 1.927626609802246
Validation loss: 2.0806843042373657

Epoch: 167| Step: 0
Training loss: 2.368685483932495
Validation loss: 2.066626270612081

Epoch: 6| Step: 1
Training loss: 1.705895185470581
Validation loss: 2.0876301924387612

Epoch: 6| Step: 2
Training loss: 2.0143985748291016
Validation loss: 2.0877753694852195

Epoch: 6| Step: 3
Training loss: 2.037031650543213
Validation loss: 2.0726856787999473

Epoch: 6| Step: 4
Training loss: 1.5678623914718628
Validation loss: 2.0700413584709167

Epoch: 6| Step: 5
Training loss: 2.467402935028076
Validation loss: 2.0897211829821267

Epoch: 6| Step: 6
Training loss: 1.7964447736740112
Validation loss: 2.075724979241689

Epoch: 6| Step: 7
Training loss: 1.9807319641113281
Validation loss: 2.0916590293248496

Epoch: 6| Step: 8
Training loss: 1.3782713413238525
Validation loss: 2.0992698272069297

Epoch: 6| Step: 9
Training loss: 2.0651001930236816
Validation loss: 2.0826584696769714

Epoch: 6| Step: 10
Training loss: 1.8634765148162842
Validation loss: 2.076128582159678

Epoch: 6| Step: 11
Training loss: 2.0400919914245605
Validation loss: 2.0906192859013877

Epoch: 6| Step: 12
Training loss: 1.5239412784576416
Validation loss: 2.1085412899653115

Epoch: 6| Step: 13
Training loss: 2.535770893096924
Validation loss: 2.1465233167012534

Epoch: 168| Step: 0
Training loss: 1.8561593294143677
Validation loss: 2.175628403822581

Epoch: 6| Step: 1
Training loss: 0.9465726613998413
Validation loss: 2.1838693817456565

Epoch: 6| Step: 2
Training loss: 2.4438953399658203
Validation loss: 2.194470008214315

Epoch: 6| Step: 3
Training loss: 2.1385231018066406
Validation loss: 2.1878931721051535

Epoch: 6| Step: 4
Training loss: 1.9318313598632812
Validation loss: 2.1912535031636557

Epoch: 6| Step: 5
Training loss: 2.3268628120422363
Validation loss: 2.145671566327413

Epoch: 6| Step: 6
Training loss: 2.0181429386138916
Validation loss: 2.10311092933019

Epoch: 6| Step: 7
Training loss: 2.2599048614501953
Validation loss: 2.0883737007776895

Epoch: 6| Step: 8
Training loss: 1.9981251955032349
Validation loss: 2.077968637148539

Epoch: 6| Step: 9
Training loss: 2.754441261291504
Validation loss: 2.0684426029523215

Epoch: 6| Step: 10
Training loss: 2.2330775260925293
Validation loss: 2.078659196694692

Epoch: 6| Step: 11
Training loss: 2.5221128463745117
Validation loss: 2.084007978439331

Epoch: 6| Step: 12
Training loss: 2.002643585205078
Validation loss: 2.086494187513987

Epoch: 6| Step: 13
Training loss: 1.7355910539627075
Validation loss: 2.1056408484776816

Epoch: 169| Step: 0
Training loss: 2.8037025928497314
Validation loss: 2.096636156241099

Epoch: 6| Step: 1
Training loss: 2.627336025238037
Validation loss: 2.0956801970799765

Epoch: 6| Step: 2
Training loss: 1.8078664541244507
Validation loss: 2.0980069239934287

Epoch: 6| Step: 3
Training loss: 1.670919418334961
Validation loss: 2.0912954409917197

Epoch: 6| Step: 4
Training loss: 2.1086902618408203
Validation loss: 2.0764759182929993

Epoch: 6| Step: 5
Training loss: 1.563096046447754
Validation loss: 2.074632386366526

Epoch: 6| Step: 6
Training loss: 2.151585340499878
Validation loss: 2.0698201656341553

Epoch: 6| Step: 7
Training loss: 1.8245903253555298
Validation loss: 2.064454952875773

Epoch: 6| Step: 8
Training loss: 2.2415690422058105
Validation loss: 2.078538954257965

Epoch: 6| Step: 9
Training loss: 2.206279993057251
Validation loss: 2.06305601199468

Epoch: 6| Step: 10
Training loss: 2.047563076019287
Validation loss: 2.079257527987162

Epoch: 6| Step: 11
Training loss: 2.070601463317871
Validation loss: 2.0791309475898743

Epoch: 6| Step: 12
Training loss: 1.8697816133499146
Validation loss: 2.0851834813753762

Epoch: 6| Step: 13
Training loss: 2.527207374572754
Validation loss: 2.068833351135254

Epoch: 170| Step: 0
Training loss: 2.4964046478271484
Validation loss: 2.067307988802592

Epoch: 6| Step: 1
Training loss: 2.4218759536743164
Validation loss: 2.079956670602163

Epoch: 6| Step: 2
Training loss: 2.014265537261963
Validation loss: 2.092308461666107

Epoch: 6| Step: 3
Training loss: 2.2558610439300537
Validation loss: 2.094085931777954

Epoch: 6| Step: 4
Training loss: 1.6374598741531372
Validation loss: 2.1008448402086892

Epoch: 6| Step: 5
Training loss: 1.9257642030715942
Validation loss: 2.101792275905609

Epoch: 6| Step: 6
Training loss: 2.2306928634643555
Validation loss: 2.1028172175089517

Epoch: 6| Step: 7
Training loss: 1.086265206336975
Validation loss: 2.084105650583903

Epoch: 6| Step: 8
Training loss: 1.9513707160949707
Validation loss: 2.0928691029548645

Epoch: 6| Step: 9
Training loss: 2.1589179039001465
Validation loss: 2.0900865395863852

Epoch: 6| Step: 10
Training loss: 2.057260274887085
Validation loss: 2.0870033701260886

Epoch: 6| Step: 11
Training loss: 2.6222009658813477
Validation loss: 2.100747585296631

Epoch: 6| Step: 12
Training loss: 1.6516610383987427
Validation loss: 2.0932482481002808

Epoch: 6| Step: 13
Training loss: 1.7247977256774902
Validation loss: 2.102325220902761

Epoch: 171| Step: 0
Training loss: 1.5753535032272339
Validation loss: 2.099466939767202

Epoch: 6| Step: 1
Training loss: 2.006373882293701
Validation loss: 2.107904314994812

Epoch: 6| Step: 2
Training loss: 2.1331844329833984
Validation loss: 2.100709855556488

Epoch: 6| Step: 3
Training loss: 2.5125370025634766
Validation loss: 2.09672745068868

Epoch: 6| Step: 4
Training loss: 1.8525187969207764
Validation loss: 2.0932640035947165

Epoch: 6| Step: 5
Training loss: 2.216667652130127
Validation loss: 2.091529210408529

Epoch: 6| Step: 6
Training loss: 3.0287985801696777
Validation loss: 2.1091939210891724

Epoch: 6| Step: 7
Training loss: 1.663050889968872
Validation loss: 2.0865139961242676

Epoch: 6| Step: 8
Training loss: 2.075374126434326
Validation loss: 2.0936708052953086

Epoch: 6| Step: 9
Training loss: 1.9331004619598389
Validation loss: 2.0927557150522866

Epoch: 6| Step: 10
Training loss: 1.53322434425354
Validation loss: 2.088452140490214

Epoch: 6| Step: 11
Training loss: 1.5035901069641113
Validation loss: 2.0902475714683533

Epoch: 6| Step: 12
Training loss: 2.251983880996704
Validation loss: 2.089124878247579

Epoch: 6| Step: 13
Training loss: 1.6743214130401611
Validation loss: 2.0774402618408203

Epoch: 172| Step: 0
Training loss: 1.1269687414169312
Validation loss: 2.0606402357419333

Epoch: 6| Step: 1
Training loss: 2.0840132236480713
Validation loss: 2.0568642814954123

Epoch: 6| Step: 2
Training loss: 2.174177646636963
Validation loss: 2.054406722386678

Epoch: 6| Step: 3
Training loss: 1.9824535846710205
Validation loss: 2.0569671591122947

Epoch: 6| Step: 4
Training loss: 3.0237388610839844
Validation loss: 2.0537074406941733

Epoch: 6| Step: 5
Training loss: 1.9512925148010254
Validation loss: 2.0533950328826904

Epoch: 6| Step: 6
Training loss: 1.9041368961334229
Validation loss: 2.060946782430013

Epoch: 6| Step: 7
Training loss: 1.3448113203048706
Validation loss: 2.0596889654795327

Epoch: 6| Step: 8
Training loss: 1.6814392805099487
Validation loss: 2.070330103238424

Epoch: 6| Step: 9
Training loss: 2.1035237312316895
Validation loss: 2.0741425156593323

Epoch: 6| Step: 10
Training loss: 2.0511369705200195
Validation loss: 2.063938240210215

Epoch: 6| Step: 11
Training loss: 2.063913345336914
Validation loss: 2.1028589606285095

Epoch: 6| Step: 12
Training loss: 2.2962288856506348
Validation loss: 2.091438273588816

Epoch: 6| Step: 13
Training loss: 2.2531795501708984
Validation loss: 2.1002378463745117

Epoch: 173| Step: 0
Training loss: 2.2953736782073975
Validation loss: 2.079069177309672

Epoch: 6| Step: 1
Training loss: 1.889357566833496
Validation loss: 2.085521916548411

Epoch: 6| Step: 2
Training loss: 1.8180005550384521
Validation loss: 2.0919188459714255

Epoch: 6| Step: 3
Training loss: 1.9766430854797363
Validation loss: 2.0783913135528564

Epoch: 6| Step: 4
Training loss: 2.0326716899871826
Validation loss: 2.066684047381083

Epoch: 6| Step: 5
Training loss: 2.3487095832824707
Validation loss: 2.065626879533132

Epoch: 6| Step: 6
Training loss: 2.8624484539031982
Validation loss: 2.079688330491384

Epoch: 6| Step: 7
Training loss: 1.7309757471084595
Validation loss: 2.0719090700149536

Epoch: 6| Step: 8
Training loss: 1.8852310180664062
Validation loss: 2.0740647117296853

Epoch: 6| Step: 9
Training loss: 1.6542503833770752
Validation loss: 2.0840301712354026

Epoch: 6| Step: 10
Training loss: 1.3754334449768066
Validation loss: 2.0853660504023233

Epoch: 6| Step: 11
Training loss: 2.5350341796875
Validation loss: 2.0902198553085327

Epoch: 6| Step: 12
Training loss: 1.416954517364502
Validation loss: 2.117017368475596

Epoch: 6| Step: 13
Training loss: 2.2026290893554688
Validation loss: 2.1223584612210593

Epoch: 174| Step: 0
Training loss: 1.6219136714935303
Validation loss: 2.141213595867157

Epoch: 6| Step: 1
Training loss: 1.7116854190826416
Validation loss: 2.145644168059031

Epoch: 6| Step: 2
Training loss: 1.8422096967697144
Validation loss: 2.1422722538312278

Epoch: 6| Step: 3
Training loss: 2.290215492248535
Validation loss: 2.135240614414215

Epoch: 6| Step: 4
Training loss: 1.8229222297668457
Validation loss: 2.13748699426651

Epoch: 6| Step: 5
Training loss: 2.835620880126953
Validation loss: 2.1613869269688926

Epoch: 6| Step: 6
Training loss: 2.1210970878601074
Validation loss: 2.127624233563741

Epoch: 6| Step: 7
Training loss: 1.9925142526626587
Validation loss: 2.116695841153463

Epoch: 6| Step: 8
Training loss: 1.422128438949585
Validation loss: 2.092969516913096

Epoch: 6| Step: 9
Training loss: 1.8114174604415894
Validation loss: 2.096780280272166

Epoch: 6| Step: 10
Training loss: 2.105837821960449
Validation loss: 2.0969025691350303

Epoch: 6| Step: 11
Training loss: 2.3325862884521484
Validation loss: 2.0917555689811707

Epoch: 6| Step: 12
Training loss: 2.363964080810547
Validation loss: 2.0801348090171814

Epoch: 6| Step: 13
Training loss: 1.5209705829620361
Validation loss: 2.0760934352874756

Epoch: 175| Step: 0
Training loss: 1.8867133855819702
Validation loss: 2.087300638357798

Epoch: 6| Step: 1
Training loss: 1.4124467372894287
Validation loss: 2.0861945947011313

Epoch: 6| Step: 2
Training loss: 1.985290765762329
Validation loss: 2.081651528676351

Epoch: 6| Step: 3
Training loss: 2.383970260620117
Validation loss: 2.104705015818278

Epoch: 6| Step: 4
Training loss: 1.8503282070159912
Validation loss: 2.105962415536245

Epoch: 6| Step: 5
Training loss: 1.4402503967285156
Validation loss: 2.1138084530830383

Epoch: 6| Step: 6
Training loss: 2.7484560012817383
Validation loss: 2.103468974431356

Epoch: 6| Step: 7
Training loss: 2.388901472091675
Validation loss: 2.099498768647512

Epoch: 6| Step: 8
Training loss: 1.2077312469482422
Validation loss: 2.0934160947799683

Epoch: 6| Step: 9
Training loss: 2.3737905025482178
Validation loss: 2.1201287309328714

Epoch: 6| Step: 10
Training loss: 1.495746374130249
Validation loss: 2.130719323952993

Epoch: 6| Step: 11
Training loss: 1.731145977973938
Validation loss: 2.1352285544077554

Epoch: 6| Step: 12
Training loss: 2.16055965423584
Validation loss: 2.1528685291608176

Epoch: 6| Step: 13
Training loss: 2.3463916778564453
Validation loss: 2.1298837065696716

Epoch: 176| Step: 0
Training loss: 2.172811508178711
Validation loss: 2.1093605756759644

Epoch: 6| Step: 1
Training loss: 1.7190239429473877
Validation loss: 2.121725102265676

Epoch: 6| Step: 2
Training loss: 2.0336101055145264
Validation loss: 2.104072014490763

Epoch: 6| Step: 3
Training loss: 2.41569447517395
Validation loss: 2.092689255873362

Epoch: 6| Step: 4
Training loss: 2.0329535007476807
Validation loss: 2.1005397041638694

Epoch: 6| Step: 5
Training loss: 2.219998359680176
Validation loss: 2.093585948149363

Epoch: 6| Step: 6
Training loss: 1.717481017112732
Validation loss: 2.1044668555259705

Epoch: 6| Step: 7
Training loss: 2.908691644668579
Validation loss: 2.088646332422892

Epoch: 6| Step: 8
Training loss: 1.5612996816635132
Validation loss: 2.0801381270090737

Epoch: 6| Step: 9
Training loss: 1.528112769126892
Validation loss: 2.0909820993741355

Epoch: 6| Step: 10
Training loss: 2.502373695373535
Validation loss: 2.082068999608358

Epoch: 6| Step: 11
Training loss: 1.8010039329528809
Validation loss: 2.1027252872784934

Epoch: 6| Step: 12
Training loss: 1.5391566753387451
Validation loss: 2.093254288037618

Epoch: 6| Step: 13
Training loss: 1.1564370393753052
Validation loss: 2.0911585092544556

Epoch: 177| Step: 0
Training loss: 1.9927301406860352
Validation loss: 2.1181506315867105

Epoch: 6| Step: 1
Training loss: 1.745142936706543
Validation loss: 2.116424043973287

Epoch: 6| Step: 2
Training loss: 2.2821154594421387
Validation loss: 2.123016595840454

Epoch: 6| Step: 3
Training loss: 2.0116310119628906
Validation loss: 2.1444685657819114

Epoch: 6| Step: 4
Training loss: 1.9630932807922363
Validation loss: 2.1352659861246743

Epoch: 6| Step: 5
Training loss: 1.6630558967590332
Validation loss: 2.1631162762641907

Epoch: 6| Step: 6
Training loss: 1.8842332363128662
Validation loss: 2.1536569197972617

Epoch: 6| Step: 7
Training loss: 1.5805387496948242
Validation loss: 2.153609017531077

Epoch: 6| Step: 8
Training loss: 2.177171230316162
Validation loss: 2.152250369389852

Epoch: 6| Step: 9
Training loss: 1.665121078491211
Validation loss: 2.153872549533844

Epoch: 6| Step: 10
Training loss: 1.839676856994629
Validation loss: 2.1427130897839866

Epoch: 6| Step: 11
Training loss: 1.657854437828064
Validation loss: 2.126941720644633

Epoch: 6| Step: 12
Training loss: 2.1738173961639404
Validation loss: 2.108423113822937

Epoch: 6| Step: 13
Training loss: 2.283717632293701
Validation loss: 2.076604723930359

Epoch: 178| Step: 0
Training loss: 1.8532166481018066
Validation loss: 2.085248827934265

Epoch: 6| Step: 1
Training loss: 2.3680214881896973
Validation loss: 2.0875391960144043

Epoch: 6| Step: 2
Training loss: 1.890305519104004
Validation loss: 2.081171194712321

Epoch: 6| Step: 3
Training loss: 2.1936469078063965
Validation loss: 2.080408811569214

Epoch: 6| Step: 4
Training loss: 2.5541882514953613
Validation loss: 2.0814066727956138

Epoch: 6| Step: 5
Training loss: 1.9957460165023804
Validation loss: 2.083590825398763

Epoch: 6| Step: 6
Training loss: 1.6901830434799194
Validation loss: 2.068620204925537

Epoch: 6| Step: 7
Training loss: 1.749551773071289
Validation loss: 2.0725892980893454

Epoch: 6| Step: 8
Training loss: 1.7559771537780762
Validation loss: 2.071998099486033

Epoch: 6| Step: 9
Training loss: 1.8036679029464722
Validation loss: 2.0780136386553445

Epoch: 6| Step: 10
Training loss: 1.9058959484100342
Validation loss: 2.076605200767517

Epoch: 6| Step: 11
Training loss: 2.0678153038024902
Validation loss: 2.084786812464396

Epoch: 6| Step: 12
Training loss: 2.1770925521850586
Validation loss: 2.1017741163571677

Epoch: 6| Step: 13
Training loss: 2.2397167682647705
Validation loss: 2.117467919985453

Epoch: 179| Step: 0
Training loss: 2.061974048614502
Validation loss: 2.119516670703888

Epoch: 6| Step: 1
Training loss: 1.8224738836288452
Validation loss: 2.153766612211863

Epoch: 6| Step: 2
Training loss: 2.367249011993408
Validation loss: 2.1683995525042215

Epoch: 6| Step: 3
Training loss: 2.208275318145752
Validation loss: 2.164789696534475

Epoch: 6| Step: 4
Training loss: 1.7103327512741089
Validation loss: 2.173972805341085

Epoch: 6| Step: 5
Training loss: 2.4654808044433594
Validation loss: 2.170732061068217

Epoch: 6| Step: 6
Training loss: 2.1176576614379883
Validation loss: 2.146197021007538

Epoch: 6| Step: 7
Training loss: 1.7295520305633545
Validation loss: 2.1545056104660034

Epoch: 6| Step: 8
Training loss: 1.9860310554504395
Validation loss: 2.119842529296875

Epoch: 6| Step: 9
Training loss: 1.5880680084228516
Validation loss: 2.0942113598187766

Epoch: 6| Step: 10
Training loss: 2.0520811080932617
Validation loss: 2.1024158000946045

Epoch: 6| Step: 11
Training loss: 2.1478514671325684
Validation loss: 2.092001736164093

Epoch: 6| Step: 12
Training loss: 1.5799545049667358
Validation loss: 2.0875149170557656

Epoch: 6| Step: 13
Training loss: 2.2338318824768066
Validation loss: 2.0911704699198403

Epoch: 180| Step: 0
Training loss: 1.3672852516174316
Validation loss: 2.0838653445243835

Epoch: 6| Step: 1
Training loss: 2.341139793395996
Validation loss: 2.081351081530253

Epoch: 6| Step: 2
Training loss: 1.9099406003952026
Validation loss: 2.0728540817896524

Epoch: 6| Step: 3
Training loss: 1.9527044296264648
Validation loss: 2.0730002323786416

Epoch: 6| Step: 4
Training loss: 2.2333900928497314
Validation loss: 2.0880796114603677

Epoch: 6| Step: 5
Training loss: 1.6560779809951782
Validation loss: 2.094472328821818

Epoch: 6| Step: 6
Training loss: 2.8095526695251465
Validation loss: 2.0848787228266397

Epoch: 6| Step: 7
Training loss: 2.6090164184570312
Validation loss: 2.0928931633631387

Epoch: 6| Step: 8
Training loss: 2.2345504760742188
Validation loss: 2.095770994822184

Epoch: 6| Step: 9
Training loss: 2.0543174743652344
Validation loss: 2.0916201869646707

Epoch: 6| Step: 10
Training loss: 1.8774638175964355
Validation loss: 2.1058385173479715

Epoch: 6| Step: 11
Training loss: 1.0721986293792725
Validation loss: 2.104446053504944

Epoch: 6| Step: 12
Training loss: 1.7054462432861328
Validation loss: 2.126969118913015

Epoch: 6| Step: 13
Training loss: 1.9062142372131348
Validation loss: 2.1255602637926736

Epoch: 181| Step: 0
Training loss: 1.715386986732483
Validation loss: 2.1292520562807717

Epoch: 6| Step: 1
Training loss: 2.0132532119750977
Validation loss: 2.1428444186846414

Epoch: 6| Step: 2
Training loss: 2.1793670654296875
Validation loss: 2.152263104915619

Epoch: 6| Step: 3
Training loss: 1.7614256143569946
Validation loss: 2.1802522341410318

Epoch: 6| Step: 4
Training loss: 2.223874092102051
Validation loss: 2.1520437598228455

Epoch: 6| Step: 5
Training loss: 2.4142262935638428
Validation loss: 2.151593486467997

Epoch: 6| Step: 6
Training loss: 2.1491804122924805
Validation loss: 2.1201419035593667

Epoch: 6| Step: 7
Training loss: 2.0837042331695557
Validation loss: 2.1262130737304688

Epoch: 6| Step: 8
Training loss: 2.121847629547119
Validation loss: 2.1014552116394043

Epoch: 6| Step: 9
Training loss: 1.544593095779419
Validation loss: 2.1018097201983132

Epoch: 6| Step: 10
Training loss: 1.8132741451263428
Validation loss: 2.087680439154307

Epoch: 6| Step: 11
Training loss: 1.391625165939331
Validation loss: 2.10063099861145

Epoch: 6| Step: 12
Training loss: 2.1818084716796875
Validation loss: 2.1095656951268515

Epoch: 6| Step: 13
Training loss: 1.7071293592453003
Validation loss: 2.0928314328193665

Epoch: 182| Step: 0
Training loss: 2.2517499923706055
Validation loss: 2.1067532102266946

Epoch: 6| Step: 1
Training loss: 2.1136045455932617
Validation loss: 2.1113255818684897

Epoch: 6| Step: 2
Training loss: 2.129201889038086
Validation loss: 2.1144683361053467

Epoch: 6| Step: 3
Training loss: 2.379378318786621
Validation loss: 2.1348264813423157

Epoch: 6| Step: 4
Training loss: 1.8072915077209473
Validation loss: 2.134285648663839

Epoch: 6| Step: 5
Training loss: 1.9252636432647705
Validation loss: 2.1403799057006836

Epoch: 6| Step: 6
Training loss: 1.5308973789215088
Validation loss: 2.1410745779673257

Epoch: 6| Step: 7
Training loss: 1.5548222064971924
Validation loss: 2.1254068414370217

Epoch: 6| Step: 8
Training loss: 2.096050977706909
Validation loss: 2.112267235914866

Epoch: 6| Step: 9
Training loss: 1.7887343168258667
Validation loss: 2.103538393974304

Epoch: 6| Step: 10
Training loss: 1.7124991416931152
Validation loss: 2.0982322096824646

Epoch: 6| Step: 11
Training loss: 1.4911210536956787
Validation loss: 2.1006569067637124

Epoch: 6| Step: 12
Training loss: 2.143728733062744
Validation loss: 2.093215028444926

Epoch: 6| Step: 13
Training loss: 2.3036208152770996
Validation loss: 2.093798736731211

Epoch: 183| Step: 0
Training loss: 2.449138641357422
Validation loss: 2.0841177304585776

Epoch: 6| Step: 1
Training loss: 2.5527408123016357
Validation loss: 2.09336127837499

Epoch: 6| Step: 2
Training loss: 1.4928123950958252
Validation loss: 2.0931694904963174

Epoch: 6| Step: 3
Training loss: 1.8264787197113037
Validation loss: 2.0946504871050515

Epoch: 6| Step: 4
Training loss: 1.486060619354248
Validation loss: 2.0975151658058167

Epoch: 6| Step: 5
Training loss: 2.097071886062622
Validation loss: 2.0965991616249084

Epoch: 6| Step: 6
Training loss: 1.9591710567474365
Validation loss: 2.0953087409337363

Epoch: 6| Step: 7
Training loss: 1.791142225265503
Validation loss: 2.1250895261764526

Epoch: 6| Step: 8
Training loss: 1.9304604530334473
Validation loss: 2.139516214529673

Epoch: 6| Step: 9
Training loss: 1.852622151374817
Validation loss: 2.15178390343984

Epoch: 6| Step: 10
Training loss: 2.4685134887695312
Validation loss: 2.148133079210917

Epoch: 6| Step: 11
Training loss: 1.45613431930542
Validation loss: 2.1414471666018167

Epoch: 6| Step: 12
Training loss: 2.4531476497650146
Validation loss: 2.1535121401151023

Epoch: 6| Step: 13
Training loss: 1.9206396341323853
Validation loss: 2.143056054910024

Epoch: 184| Step: 0
Training loss: 2.412881851196289
Validation loss: 2.1475610931714377

Epoch: 6| Step: 1
Training loss: 2.038351535797119
Validation loss: 2.111314276854197

Epoch: 6| Step: 2
Training loss: 1.7182965278625488
Validation loss: 2.1105125745137534

Epoch: 6| Step: 3
Training loss: 1.606247901916504
Validation loss: 2.102280378341675

Epoch: 6| Step: 4
Training loss: 2.4590201377868652
Validation loss: 2.100576023260752

Epoch: 6| Step: 5
Training loss: 1.6196085214614868
Validation loss: 2.099675436814626

Epoch: 6| Step: 6
Training loss: 2.2699553966522217
Validation loss: 2.079208175341288

Epoch: 6| Step: 7
Training loss: 2.0143182277679443
Validation loss: 2.090257445971171

Epoch: 6| Step: 8
Training loss: 2.0257978439331055
Validation loss: 2.0873936812082925

Epoch: 6| Step: 9
Training loss: 2.2142221927642822
Validation loss: 2.087108055750529

Epoch: 6| Step: 10
Training loss: 1.771775722503662
Validation loss: 2.1006485422452292

Epoch: 6| Step: 11
Training loss: 1.9146114587783813
Validation loss: 2.1113673647244773

Epoch: 6| Step: 12
Training loss: 1.8011194467544556
Validation loss: 2.0850372115770974

Epoch: 6| Step: 13
Training loss: 1.5354671478271484
Validation loss: 2.0968924164772034

Epoch: 185| Step: 0
Training loss: 2.204152822494507
Validation loss: 2.1096890767415366

Epoch: 6| Step: 1
Training loss: 2.103605031967163
Validation loss: 2.0946486790974936

Epoch: 6| Step: 2
Training loss: 1.4059842824935913
Validation loss: 2.0973554650942483

Epoch: 6| Step: 3
Training loss: 2.1823954582214355
Validation loss: 2.107965588569641

Epoch: 6| Step: 4
Training loss: 1.4775737524032593
Validation loss: 2.1132219632466636

Epoch: 6| Step: 5
Training loss: 2.0267715454101562
Validation loss: 2.1016292770703635

Epoch: 6| Step: 6
Training loss: 1.5862338542938232
Validation loss: 2.094599187374115

Epoch: 6| Step: 7
Training loss: 2.029705047607422
Validation loss: 2.091502328713735

Epoch: 6| Step: 8
Training loss: 2.397756814956665
Validation loss: 2.103093902269999

Epoch: 6| Step: 9
Training loss: 2.2846288681030273
Validation loss: 2.096614201863607

Epoch: 6| Step: 10
Training loss: 2.187363624572754
Validation loss: 2.1043847600618997

Epoch: 6| Step: 11
Training loss: 1.5566273927688599
Validation loss: 2.1143151919047036

Epoch: 6| Step: 12
Training loss: 1.6244916915893555
Validation loss: 2.1326990922292075

Epoch: 6| Step: 13
Training loss: 2.1079256534576416
Validation loss: 2.144225299358368

Epoch: 186| Step: 0
Training loss: 2.3580825328826904
Validation loss: 2.1474887132644653

Epoch: 6| Step: 1
Training loss: 1.677781105041504
Validation loss: 2.168422440687815

Epoch: 6| Step: 2
Training loss: 2.2053468227386475
Validation loss: 2.171678344408671

Epoch: 6| Step: 3
Training loss: 2.281782627105713
Validation loss: 2.1733062465985618

Epoch: 6| Step: 4
Training loss: 1.644993782043457
Validation loss: 2.159336050351461

Epoch: 6| Step: 5
Training loss: 1.5540889501571655
Validation loss: 2.1566656827926636

Epoch: 6| Step: 6
Training loss: 1.9282418489456177
Validation loss: 2.1445141037305198

Epoch: 6| Step: 7
Training loss: 1.8373066186904907
Validation loss: 2.1170730789502463

Epoch: 6| Step: 8
Training loss: 1.7261446714401245
Validation loss: 2.1040273904800415

Epoch: 6| Step: 9
Training loss: 1.7405754327774048
Validation loss: 2.0901694297790527

Epoch: 6| Step: 10
Training loss: 1.5758882761001587
Validation loss: 2.0928863286972046

Epoch: 6| Step: 11
Training loss: 1.8634774684906006
Validation loss: 2.078887462615967

Epoch: 6| Step: 12
Training loss: 2.39228892326355
Validation loss: 2.074984391530355

Epoch: 6| Step: 13
Training loss: 2.5750839710235596
Validation loss: 2.0722575386365256

Epoch: 187| Step: 0
Training loss: 2.108668804168701
Validation loss: 2.084016442298889

Epoch: 6| Step: 1
Training loss: 1.9471718072891235
Validation loss: 2.0844764709472656

Epoch: 6| Step: 2
Training loss: 2.456172466278076
Validation loss: 2.084270417690277

Epoch: 6| Step: 3
Training loss: 1.7671186923980713
Validation loss: 2.0718801418940225

Epoch: 6| Step: 4
Training loss: 2.5550050735473633
Validation loss: 2.0832607746124268

Epoch: 6| Step: 5
Training loss: 1.7413585186004639
Validation loss: 2.095287481943766

Epoch: 6| Step: 6
Training loss: 2.074993371963501
Validation loss: 2.0984381834665933

Epoch: 6| Step: 7
Training loss: 2.0138933658599854
Validation loss: 2.111815889676412

Epoch: 6| Step: 8
Training loss: 2.2769460678100586
Validation loss: 2.126964747905731

Epoch: 6| Step: 9
Training loss: 1.721740961074829
Validation loss: 2.117220163345337

Epoch: 6| Step: 10
Training loss: 1.3185348510742188
Validation loss: 2.110848387082418

Epoch: 6| Step: 11
Training loss: 2.019580125808716
Validation loss: 2.1133686304092407

Epoch: 6| Step: 12
Training loss: 2.045780658721924
Validation loss: 2.1337469021479287

Epoch: 6| Step: 13
Training loss: 2.308285713195801
Validation loss: 2.1269450187683105

Epoch: 188| Step: 0
Training loss: 1.6312775611877441
Validation loss: 2.121595780054728

Epoch: 6| Step: 1
Training loss: 2.161351203918457
Validation loss: 2.129346946875254

Epoch: 6| Step: 2
Training loss: 2.0302181243896484
Validation loss: 2.132242520650228

Epoch: 6| Step: 3
Training loss: 1.782202959060669
Validation loss: 2.127734124660492

Epoch: 6| Step: 4
Training loss: 1.7080802917480469
Validation loss: 2.1236609617869058

Epoch: 6| Step: 5
Training loss: 2.1147303581237793
Validation loss: 2.1055333813031516

Epoch: 6| Step: 6
Training loss: 2.0689892768859863
Validation loss: 2.0910531282424927

Epoch: 6| Step: 7
Training loss: 1.8100874423980713
Validation loss: 2.1017340222994485

Epoch: 6| Step: 8
Training loss: 1.62294340133667
Validation loss: 2.098418732484182

Epoch: 6| Step: 9
Training loss: 2.061894655227661
Validation loss: 2.1007795532544455

Epoch: 6| Step: 10
Training loss: 2.6059298515319824
Validation loss: 2.1105549732844033

Epoch: 6| Step: 11
Training loss: 2.049791097640991
Validation loss: 2.118849813938141

Epoch: 6| Step: 12
Training loss: 1.803816556930542
Validation loss: 2.1166335542996726

Epoch: 6| Step: 13
Training loss: 1.5498273372650146
Validation loss: 2.107318719228109

Epoch: 189| Step: 0
Training loss: 1.8384487628936768
Validation loss: 2.1095679799715676

Epoch: 6| Step: 1
Training loss: 2.3546864986419678
Validation loss: 2.1180507143338523

Epoch: 6| Step: 2
Training loss: 1.91999089717865
Validation loss: 2.117384413878123

Epoch: 6| Step: 3
Training loss: 2.005192756652832
Validation loss: 2.115906218687693

Epoch: 6| Step: 4
Training loss: 2.0348615646362305
Validation loss: 2.123680849870046

Epoch: 6| Step: 5
Training loss: 2.016488552093506
Validation loss: 2.1109418272972107

Epoch: 6| Step: 6
Training loss: 1.7102972269058228
Validation loss: 2.115767002105713

Epoch: 6| Step: 7
Training loss: 1.905936360359192
Validation loss: 2.097320079803467

Epoch: 6| Step: 8
Training loss: 1.8031985759735107
Validation loss: 2.1093266010284424

Epoch: 6| Step: 9
Training loss: 1.8292484283447266
Validation loss: 2.1085270245869956

Epoch: 6| Step: 10
Training loss: 1.0450148582458496
Validation loss: 2.09687602519989

Epoch: 6| Step: 11
Training loss: 2.2797677516937256
Validation loss: 2.1154779195785522

Epoch: 6| Step: 12
Training loss: 1.733626127243042
Validation loss: 2.108761191368103

Epoch: 6| Step: 13
Training loss: 2.33805513381958
Validation loss: 2.113552451133728

Epoch: 190| Step: 0
Training loss: 1.8597255945205688
Validation loss: 2.112672448158264

Epoch: 6| Step: 1
Training loss: 1.9669655561447144
Validation loss: 2.129062592983246

Epoch: 6| Step: 2
Training loss: 2.195848226547241
Validation loss: 2.126222332318624

Epoch: 6| Step: 3
Training loss: 2.12812876701355
Validation loss: 2.151327629884084

Epoch: 6| Step: 4
Training loss: 0.8391165733337402
Validation loss: 2.127500534057617

Epoch: 6| Step: 5
Training loss: 1.6750202178955078
Validation loss: 2.150197426478068

Epoch: 6| Step: 6
Training loss: 2.4763307571411133
Validation loss: 2.1612035433451333

Epoch: 6| Step: 7
Training loss: 2.4347269535064697
Validation loss: 2.16423233350118

Epoch: 6| Step: 8
Training loss: 1.784355878829956
Validation loss: 2.160004278024038

Epoch: 6| Step: 9
Training loss: 1.810981035232544
Validation loss: 2.1491210659344993

Epoch: 6| Step: 10
Training loss: 1.8376133441925049
Validation loss: 2.1417172948519387

Epoch: 6| Step: 11
Training loss: 2.103483200073242
Validation loss: 2.14565908908844

Epoch: 6| Step: 12
Training loss: 1.6724746227264404
Validation loss: 2.138680120309194

Epoch: 6| Step: 13
Training loss: 1.9415948390960693
Validation loss: 2.134016215801239

Epoch: 191| Step: 0
Training loss: 2.8858208656311035
Validation loss: 2.1572292844454446

Epoch: 6| Step: 1
Training loss: 2.1191415786743164
Validation loss: 2.158305585384369

Epoch: 6| Step: 2
Training loss: 1.7435846328735352
Validation loss: 2.1687215169270835

Epoch: 6| Step: 3
Training loss: 2.073467493057251
Validation loss: 2.161749283472697

Epoch: 6| Step: 4
Training loss: 1.817507266998291
Validation loss: 2.1583937803904214

Epoch: 6| Step: 5
Training loss: 1.8511264324188232
Validation loss: 2.1545409758885703

Epoch: 6| Step: 6
Training loss: 2.1602530479431152
Validation loss: 2.1886457403500876

Epoch: 6| Step: 7
Training loss: 1.3288440704345703
Validation loss: 2.1633678674697876

Epoch: 6| Step: 8
Training loss: 1.807244062423706
Validation loss: 2.179582198460897

Epoch: 6| Step: 9
Training loss: 2.10916805267334
Validation loss: 2.1381182869275412

Epoch: 6| Step: 10
Training loss: 2.1485819816589355
Validation loss: 2.1303765376408896

Epoch: 6| Step: 11
Training loss: 1.7500462532043457
Validation loss: 2.113441586494446

Epoch: 6| Step: 12
Training loss: 1.5900628566741943
Validation loss: 2.1190748612085977

Epoch: 6| Step: 13
Training loss: 1.544838786125183
Validation loss: 2.10722678899765

Epoch: 192| Step: 0
Training loss: 2.2149806022644043
Validation loss: 2.102698802947998

Epoch: 6| Step: 1
Training loss: 1.8323862552642822
Validation loss: 2.1016002098719277

Epoch: 6| Step: 2
Training loss: 2.2643752098083496
Validation loss: 2.117737094561259

Epoch: 6| Step: 3
Training loss: 1.7309908866882324
Validation loss: 2.1058326959609985

Epoch: 6| Step: 4
Training loss: 2.281172275543213
Validation loss: 2.0964195926984153

Epoch: 6| Step: 5
Training loss: 1.637341856956482
Validation loss: 2.1183654268582663

Epoch: 6| Step: 6
Training loss: 1.667541265487671
Validation loss: 2.1023895144462585

Epoch: 6| Step: 7
Training loss: 1.7070348262786865
Validation loss: 2.120152235031128

Epoch: 6| Step: 8
Training loss: 2.206529140472412
Validation loss: 2.126422385374705

Epoch: 6| Step: 9
Training loss: 1.0961133241653442
Validation loss: 2.1509097814559937

Epoch: 6| Step: 10
Training loss: 2.4284791946411133
Validation loss: 2.1802205046017966

Epoch: 6| Step: 11
Training loss: 2.374518394470215
Validation loss: 2.212053577105204

Epoch: 6| Step: 12
Training loss: 2.165050983428955
Validation loss: 2.1901872952779136

Epoch: 6| Step: 13
Training loss: 1.603392481803894
Validation loss: 2.1830521623293557

Epoch: 193| Step: 0
Training loss: 1.9003496170043945
Validation loss: 2.1689753929773965

Epoch: 6| Step: 1
Training loss: 2.1723368167877197
Validation loss: 2.1504952907562256

Epoch: 6| Step: 2
Training loss: 1.8750240802764893
Validation loss: 2.1361762483914695

Epoch: 6| Step: 3
Training loss: 1.77862548828125
Validation loss: 2.118672251701355

Epoch: 6| Step: 4
Training loss: 2.151977777481079
Validation loss: 2.1035592953364053

Epoch: 6| Step: 5
Training loss: 2.3783109188079834
Validation loss: 2.10711669921875

Epoch: 6| Step: 6
Training loss: 1.9412060976028442
Validation loss: 2.1041426261266074

Epoch: 6| Step: 7
Training loss: 2.405261516571045
Validation loss: 2.0878005623817444

Epoch: 6| Step: 8
Training loss: 1.983245611190796
Validation loss: 2.0959607362747192

Epoch: 6| Step: 9
Training loss: 1.5595598220825195
Validation loss: 2.1009413599967957

Epoch: 6| Step: 10
Training loss: 1.4011156558990479
Validation loss: 2.100770910580953

Epoch: 6| Step: 11
Training loss: 2.1889941692352295
Validation loss: 2.1100931763648987

Epoch: 6| Step: 12
Training loss: 1.918613076210022
Validation loss: 2.112459202607473

Epoch: 6| Step: 13
Training loss: 1.8171253204345703
Validation loss: 2.112578332424164

Epoch: 194| Step: 0
Training loss: 1.291471004486084
Validation loss: 2.1169647375742593

Epoch: 6| Step: 1
Training loss: 2.0602331161499023
Validation loss: 2.1240685184796653

Epoch: 6| Step: 2
Training loss: 1.7545019388198853
Validation loss: 2.1259132424990335

Epoch: 6| Step: 3
Training loss: 2.435426712036133
Validation loss: 2.1277657548586526

Epoch: 6| Step: 4
Training loss: 1.7249656915664673
Validation loss: 2.12556791305542

Epoch: 6| Step: 5
Training loss: 1.7829639911651611
Validation loss: 2.1379241943359375

Epoch: 6| Step: 6
Training loss: 1.8173792362213135
Validation loss: 2.1397318641344705

Epoch: 6| Step: 7
Training loss: 1.6149717569351196
Validation loss: 2.1312074065208435

Epoch: 6| Step: 8
Training loss: 2.3853647708892822
Validation loss: 2.1469901402791343

Epoch: 6| Step: 9
Training loss: 1.8310788869857788
Validation loss: 2.1478199561436973

Epoch: 6| Step: 10
Training loss: 2.3211669921875
Validation loss: 2.1564804712931314

Epoch: 6| Step: 11
Training loss: 2.0154075622558594
Validation loss: 2.1510730981826782

Epoch: 6| Step: 12
Training loss: 1.8559374809265137
Validation loss: 2.1351576248804727

Epoch: 6| Step: 13
Training loss: 1.5846269130706787
Validation loss: 2.1612376968065896

Epoch: 195| Step: 0
Training loss: 2.001903533935547
Validation loss: 2.135549485683441

Epoch: 6| Step: 1
Training loss: 1.4913545846939087
Validation loss: 2.1727771957715354

Epoch: 6| Step: 2
Training loss: 2.4382424354553223
Validation loss: 2.130019744237264

Epoch: 6| Step: 3
Training loss: 2.1548190116882324
Validation loss: 2.1207361817359924

Epoch: 6| Step: 4
Training loss: 2.0405006408691406
Validation loss: 2.1412139534950256

Epoch: 6| Step: 5
Training loss: 2.4536211490631104
Validation loss: 2.1210293571154275

Epoch: 6| Step: 6
Training loss: 2.059690237045288
Validation loss: 2.1200470129648843

Epoch: 6| Step: 7
Training loss: 1.8340049982070923
Validation loss: 2.101247568925222

Epoch: 6| Step: 8
Training loss: 2.0726661682128906
Validation loss: 2.105483671029409

Epoch: 6| Step: 9
Training loss: 2.0997276306152344
Validation loss: 2.0968432625134787

Epoch: 6| Step: 10
Training loss: 1.6594617366790771
Validation loss: 2.110789974530538

Epoch: 6| Step: 11
Training loss: 1.8160455226898193
Validation loss: 2.1036803325017295

Epoch: 6| Step: 12
Training loss: 1.5777288675308228
Validation loss: 2.103981335957845

Epoch: 6| Step: 13
Training loss: 1.3565454483032227
Validation loss: 2.091938535372416

Epoch: 196| Step: 0
Training loss: 1.678926706314087
Validation loss: 2.089165965716044

Epoch: 6| Step: 1
Training loss: 2.124833583831787
Validation loss: 2.105685512224833

Epoch: 6| Step: 2
Training loss: 2.3379359245300293
Validation loss: 2.1264204184214273

Epoch: 6| Step: 3
Training loss: 1.3540738821029663
Validation loss: 2.1106122732162476

Epoch: 6| Step: 4
Training loss: 1.609415054321289
Validation loss: 2.1187135775883994

Epoch: 6| Step: 5
Training loss: 2.167884588241577
Validation loss: 2.1099780599276223

Epoch: 6| Step: 6
Training loss: 1.9324007034301758
Validation loss: 2.1182903051376343

Epoch: 6| Step: 7
Training loss: 1.8441336154937744
Validation loss: 2.121017098426819

Epoch: 6| Step: 8
Training loss: 1.9223589897155762
Validation loss: 2.1149102052052817

Epoch: 6| Step: 9
Training loss: 1.3228962421417236
Validation loss: 2.1190540393193564

Epoch: 6| Step: 10
Training loss: 1.7672829627990723
Validation loss: 2.1370776693026223

Epoch: 6| Step: 11
Training loss: 2.676608085632324
Validation loss: 2.1392990350723267

Epoch: 6| Step: 12
Training loss: 1.9247868061065674
Validation loss: 2.1511635979016623

Epoch: 6| Step: 13
Training loss: 1.8257827758789062
Validation loss: 2.136084715525309

Epoch: 197| Step: 0
Training loss: 1.489686369895935
Validation loss: 2.15171080827713

Epoch: 6| Step: 1
Training loss: 1.573491096496582
Validation loss: 2.131607393423716

Epoch: 6| Step: 2
Training loss: 1.8500041961669922
Validation loss: 2.134958505630493

Epoch: 6| Step: 3
Training loss: 2.0555953979492188
Validation loss: 2.1170143485069275

Epoch: 6| Step: 4
Training loss: 1.8670015335083008
Validation loss: 2.1234936714172363

Epoch: 6| Step: 5
Training loss: 2.157561779022217
Validation loss: 2.1223105986913047

Epoch: 6| Step: 6
Training loss: 1.5687209367752075
Validation loss: 2.1237365206082663

Epoch: 6| Step: 7
Training loss: 1.2436134815216064
Validation loss: 2.1325060526529946

Epoch: 6| Step: 8
Training loss: 1.8026223182678223
Validation loss: 2.1366877953211465

Epoch: 6| Step: 9
Training loss: 2.7253036499023438
Validation loss: 2.138834853967031

Epoch: 6| Step: 10
Training loss: 1.4474509954452515
Validation loss: 2.114051878452301

Epoch: 6| Step: 11
Training loss: 2.405270576477051
Validation loss: 2.135864476362864

Epoch: 6| Step: 12
Training loss: 2.274693012237549
Validation loss: 2.136072039604187

Epoch: 6| Step: 13
Training loss: 2.087890863418579
Validation loss: 2.1161782344182334

Epoch: 198| Step: 0
Training loss: 1.7177197933197021
Validation loss: 2.12288890282313

Epoch: 6| Step: 1
Training loss: 1.8987891674041748
Validation loss: 2.14269349972407

Epoch: 6| Step: 2
Training loss: 1.7638325691223145
Validation loss: 2.1359920700391135

Epoch: 6| Step: 3
Training loss: 1.5178217887878418
Validation loss: 2.1372693181037903

Epoch: 6| Step: 4
Training loss: 1.9736419916152954
Validation loss: 2.1421037316322327

Epoch: 6| Step: 5
Training loss: 1.598564863204956
Validation loss: 2.150568902492523

Epoch: 6| Step: 6
Training loss: 1.7646183967590332
Validation loss: 2.145885686079661

Epoch: 6| Step: 7
Training loss: 1.7307100296020508
Validation loss: 2.149004896481832

Epoch: 6| Step: 8
Training loss: 1.7712572813034058
Validation loss: 2.138368606567383

Epoch: 6| Step: 9
Training loss: 2.2069454193115234
Validation loss: 2.146241327126821

Epoch: 6| Step: 10
Training loss: 2.1219468116760254
Validation loss: 2.140300194422404

Epoch: 6| Step: 11
Training loss: 2.007622718811035
Validation loss: 2.1392829418182373

Epoch: 6| Step: 12
Training loss: 2.504568576812744
Validation loss: 2.128831962744395

Epoch: 6| Step: 13
Training loss: 2.117363214492798
Validation loss: 2.1255269845326743

Epoch: 199| Step: 0
Training loss: 1.0990333557128906
Validation loss: 2.114058792591095

Epoch: 6| Step: 1
Training loss: 2.188591480255127
Validation loss: 2.1134291887283325

Epoch: 6| Step: 2
Training loss: 1.9241652488708496
Validation loss: 2.122261901696523

Epoch: 6| Step: 3
Training loss: 2.0531435012817383
Validation loss: 2.1369174122810364

Epoch: 6| Step: 4
Training loss: 2.182755708694458
Validation loss: 2.145725965499878

Epoch: 6| Step: 5
Training loss: 1.573377251625061
Validation loss: 2.165542562802633

Epoch: 6| Step: 6
Training loss: 2.0934908390045166
Validation loss: 2.1453264554341636

Epoch: 6| Step: 7
Training loss: 1.6519160270690918
Validation loss: 2.1436209281285605

Epoch: 6| Step: 8
Training loss: 2.073903799057007
Validation loss: 2.1490367452303567

Epoch: 6| Step: 9
Training loss: 2.2802042961120605
Validation loss: 2.1401644150416055

Epoch: 6| Step: 10
Training loss: 2.009018659591675
Validation loss: 2.1198317607243857

Epoch: 6| Step: 11
Training loss: 1.9751112461090088
Validation loss: 2.1359227697054544

Epoch: 6| Step: 12
Training loss: 1.5689287185668945
Validation loss: 2.130595882733663

Epoch: 6| Step: 13
Training loss: 2.243816375732422
Validation loss: 2.144933760166168

Epoch: 200| Step: 0
Training loss: 2.003840446472168
Validation loss: 2.1422783732414246

Epoch: 6| Step: 1
Training loss: 1.371564507484436
Validation loss: 2.147737185160319

Epoch: 6| Step: 2
Training loss: 2.0345780849456787
Validation loss: 2.146907647450765

Epoch: 6| Step: 3
Training loss: 1.1880571842193604
Validation loss: 2.1538419922192893

Epoch: 6| Step: 4
Training loss: 2.2116305828094482
Validation loss: 2.1592565178871155

Epoch: 6| Step: 5
Training loss: 1.8711702823638916
Validation loss: 2.1411396066347756

Epoch: 6| Step: 6
Training loss: 1.5776472091674805
Validation loss: 2.150500535964966

Epoch: 6| Step: 7
Training loss: 1.83808171749115
Validation loss: 2.1480196515719094

Epoch: 6| Step: 8
Training loss: 2.463542938232422
Validation loss: 2.157166322072347

Epoch: 6| Step: 9
Training loss: 2.1729214191436768
Validation loss: 2.153031289577484

Epoch: 6| Step: 10
Training loss: 1.4096720218658447
Validation loss: 2.1354426940282187

Epoch: 6| Step: 11
Training loss: 2.102725028991699
Validation loss: 2.1563466588656106

Epoch: 6| Step: 12
Training loss: 2.294363498687744
Validation loss: 2.1390122771263123

Epoch: 6| Step: 13
Training loss: 1.8277647495269775
Validation loss: 2.1294900377591452

Epoch: 201| Step: 0
Training loss: 1.8500040769577026
Validation loss: 2.1501654386520386

Epoch: 6| Step: 1
Training loss: 2.727875232696533
Validation loss: 2.1543837984402976

Epoch: 6| Step: 2
Training loss: 1.5337066650390625
Validation loss: 2.140738566716512

Epoch: 6| Step: 3
Training loss: 2.0236246585845947
Validation loss: 2.1652979850769043

Epoch: 6| Step: 4
Training loss: 1.6628139019012451
Validation loss: 2.1581894159317017

Epoch: 6| Step: 5
Training loss: 2.2417654991149902
Validation loss: 2.1869154969851174

Epoch: 6| Step: 6
Training loss: 1.680760383605957
Validation loss: 2.1945918599764505

Epoch: 6| Step: 7
Training loss: 2.5089492797851562
Validation loss: 2.1903574466705322

Epoch: 6| Step: 8
Training loss: 2.1348681449890137
Validation loss: 2.2022297779719033

Epoch: 6| Step: 9
Training loss: 1.7652870416641235
Validation loss: 2.1759560108184814

Epoch: 6| Step: 10
Training loss: 1.6418390274047852
Validation loss: 2.1704676151275635

Epoch: 6| Step: 11
Training loss: 1.9643096923828125
Validation loss: 2.1395715872446694

Epoch: 6| Step: 12
Training loss: 1.4324467182159424
Validation loss: 2.137048602104187

Epoch: 6| Step: 13
Training loss: 1.5898535251617432
Validation loss: 2.1240299145380654

Epoch: 202| Step: 0
Training loss: 1.7259767055511475
Validation loss: 2.117050607999166

Epoch: 6| Step: 1
Training loss: 1.5021400451660156
Validation loss: 2.105629483858744

Epoch: 6| Step: 2
Training loss: 2.878901481628418
Validation loss: 2.1135594050089517

Epoch: 6| Step: 3
Training loss: 1.7960401773452759
Validation loss: 2.1071858604749045

Epoch: 6| Step: 4
Training loss: 2.3416097164154053
Validation loss: 2.128222862879435

Epoch: 6| Step: 5
Training loss: 2.143716812133789
Validation loss: 2.1246527234713235

Epoch: 6| Step: 6
Training loss: 2.2894434928894043
Validation loss: 2.129833201567332

Epoch: 6| Step: 7
Training loss: 2.1673054695129395
Validation loss: 2.130972941716512

Epoch: 6| Step: 8
Training loss: 1.9164559841156006
Validation loss: 2.134754260381063

Epoch: 6| Step: 9
Training loss: 1.7508456707000732
Validation loss: 2.1364707946777344

Epoch: 6| Step: 10
Training loss: 1.393170952796936
Validation loss: 2.144378880659739

Epoch: 6| Step: 11
Training loss: 1.5411038398742676
Validation loss: 2.142041563987732

Epoch: 6| Step: 12
Training loss: 1.7765612602233887
Validation loss: 2.1628411610921225

Epoch: 6| Step: 13
Training loss: 1.6698024272918701
Validation loss: 2.190218468507131

Epoch: 203| Step: 0
Training loss: 1.8014678955078125
Validation loss: 2.18821918964386

Epoch: 6| Step: 1
Training loss: 2.102290153503418
Validation loss: 2.1988937656084695

Epoch: 6| Step: 2
Training loss: 1.3169916868209839
Validation loss: 2.204812169075012

Epoch: 6| Step: 3
Training loss: 2.3435680866241455
Validation loss: 2.191295584042867

Epoch: 6| Step: 4
Training loss: 1.686736822128296
Validation loss: 2.194744030634562

Epoch: 6| Step: 5
Training loss: 1.5159201622009277
Validation loss: 2.1631241043408713

Epoch: 6| Step: 6
Training loss: 1.805039644241333
Validation loss: 2.1652170221010842

Epoch: 6| Step: 7
Training loss: 1.835033655166626
Validation loss: 2.15132745107015

Epoch: 6| Step: 8
Training loss: 2.148125410079956
Validation loss: 2.1205122470855713

Epoch: 6| Step: 9
Training loss: 2.08502197265625
Validation loss: 2.127698560555776

Epoch: 6| Step: 10
Training loss: 1.7608201503753662
Validation loss: 2.111253639062246

Epoch: 6| Step: 11
Training loss: 2.1930160522460938
Validation loss: 2.1355979243914285

Epoch: 6| Step: 12
Training loss: 1.7775415182113647
Validation loss: 2.121528069178263

Epoch: 6| Step: 13
Training loss: 2.0911576747894287
Validation loss: 2.1285404562950134

Epoch: 204| Step: 0
Training loss: 2.1389541625976562
Validation loss: 2.1282766660054526

Epoch: 6| Step: 1
Training loss: 2.493569850921631
Validation loss: 2.122575124104818

Epoch: 6| Step: 2
Training loss: 2.044792890548706
Validation loss: 2.131246507167816

Epoch: 6| Step: 3
Training loss: 1.7073025703430176
Validation loss: 2.1482791701952615

Epoch: 6| Step: 4
Training loss: 2.1118416786193848
Validation loss: 2.139993886152903

Epoch: 6| Step: 5
Training loss: 1.948865532875061
Validation loss: 2.132854640483856

Epoch: 6| Step: 6
Training loss: 2.0509982109069824
Validation loss: 2.126755972703298

Epoch: 6| Step: 7
Training loss: 1.2301595211029053
Validation loss: 2.1321692069371543

Epoch: 6| Step: 8
Training loss: 2.3060050010681152
Validation loss: 2.1568962931632996

Epoch: 6| Step: 9
Training loss: 1.8468643426895142
Validation loss: 2.163690209388733

Epoch: 6| Step: 10
Training loss: 1.8040452003479004
Validation loss: 2.1464946269989014

Epoch: 6| Step: 11
Training loss: 1.599604606628418
Validation loss: 2.152786056200663

Epoch: 6| Step: 12
Training loss: 1.7352557182312012
Validation loss: 2.164013604323069

Epoch: 6| Step: 13
Training loss: 1.3864362239837646
Validation loss: 2.1439014673233032

Epoch: 205| Step: 0
Training loss: 1.281941294670105
Validation loss: 2.168148616949717

Epoch: 6| Step: 1
Training loss: 1.6544137001037598
Validation loss: 2.154016613960266

Epoch: 6| Step: 2
Training loss: 2.483088493347168
Validation loss: 2.149332265059153

Epoch: 6| Step: 3
Training loss: 1.4979313611984253
Validation loss: 2.153643230597178

Epoch: 6| Step: 4
Training loss: 2.387065887451172
Validation loss: 2.1577831506729126

Epoch: 6| Step: 5
Training loss: 1.524199366569519
Validation loss: 2.16647070646286

Epoch: 6| Step: 6
Training loss: 2.171504020690918
Validation loss: 2.147615671157837

Epoch: 6| Step: 7
Training loss: 2.17903995513916
Validation loss: 2.1639005740483603

Epoch: 6| Step: 8
Training loss: 1.8656740188598633
Validation loss: 2.1600987911224365

Epoch: 6| Step: 9
Training loss: 1.8989609479904175
Validation loss: 2.181677003701528

Epoch: 6| Step: 10
Training loss: 1.2736597061157227
Validation loss: 2.159615079561869

Epoch: 6| Step: 11
Training loss: 1.5305449962615967
Validation loss: 2.1672589977582297

Epoch: 6| Step: 12
Training loss: 1.96364164352417
Validation loss: 2.146461606025696

Epoch: 6| Step: 13
Training loss: 2.688103675842285
Validation loss: 2.1355225443840027

Epoch: 206| Step: 0
Training loss: 1.9383208751678467
Validation loss: 2.155321717262268

Epoch: 6| Step: 1
Training loss: 1.5380305051803589
Validation loss: 2.1233951250712075

Epoch: 6| Step: 2
Training loss: 1.8177340030670166
Validation loss: 2.128773589928945

Epoch: 6| Step: 3
Training loss: 2.2029974460601807
Validation loss: 2.1269853512446084

Epoch: 6| Step: 4
Training loss: 2.108222723007202
Validation loss: 2.1372824708620706

Epoch: 6| Step: 5
Training loss: 2.0617361068725586
Validation loss: 2.1149608294169107

Epoch: 6| Step: 6
Training loss: 1.79507577419281
Validation loss: 2.1435561577479043

Epoch: 6| Step: 7
Training loss: 1.7690683603286743
Validation loss: 2.1394030253092446

Epoch: 6| Step: 8
Training loss: 2.1539037227630615
Validation loss: 2.1332926948865256

Epoch: 6| Step: 9
Training loss: 1.9698338508605957
Validation loss: 2.136298894882202

Epoch: 6| Step: 10
Training loss: 2.0177769660949707
Validation loss: 2.1333027283350625

Epoch: 6| Step: 11
Training loss: 1.606580376625061
Validation loss: 2.1683133244514465

Epoch: 6| Step: 12
Training loss: 1.4932925701141357
Validation loss: 2.184882958730062

Epoch: 6| Step: 13
Training loss: 1.9252595901489258
Validation loss: 2.180939018726349

Epoch: 207| Step: 0
Training loss: 1.9210928678512573
Validation loss: 2.1905199885368347

Epoch: 6| Step: 1
Training loss: 1.7186670303344727
Validation loss: 2.1647420525550842

Epoch: 6| Step: 2
Training loss: 1.8850727081298828
Validation loss: 2.142627934614817

Epoch: 6| Step: 3
Training loss: 2.327599048614502
Validation loss: 2.143890857696533

Epoch: 6| Step: 4
Training loss: 1.7017266750335693
Validation loss: 2.1170317927996316

Epoch: 6| Step: 5
Training loss: 1.923087239265442
Validation loss: 2.14042991399765

Epoch: 6| Step: 6
Training loss: 1.5156662464141846
Validation loss: 2.131969432036082

Epoch: 6| Step: 7
Training loss: 1.8487169742584229
Validation loss: 2.1241270105044046

Epoch: 6| Step: 8
Training loss: 2.039916515350342
Validation loss: 2.1216679414113364

Epoch: 6| Step: 9
Training loss: 1.6413732767105103
Validation loss: 2.1314088106155396

Epoch: 6| Step: 10
Training loss: 1.7483690977096558
Validation loss: 2.1282556653022766

Epoch: 6| Step: 11
Training loss: 2.067640781402588
Validation loss: 2.1398311654726663

Epoch: 6| Step: 12
Training loss: 2.2085516452789307
Validation loss: 2.1463804244995117

Epoch: 6| Step: 13
Training loss: 1.9119764566421509
Validation loss: 2.143957515557607

Epoch: 208| Step: 0
Training loss: 1.6509402990341187
Validation loss: 2.127619127432505

Epoch: 6| Step: 1
Training loss: 1.3722865581512451
Validation loss: 2.1645134687423706

Epoch: 6| Step: 2
Training loss: 2.508962631225586
Validation loss: 2.1706345876057944

Epoch: 6| Step: 3
Training loss: 1.736739158630371
Validation loss: 2.1944602330525718

Epoch: 6| Step: 4
Training loss: 1.1852405071258545
Validation loss: 2.169717272122701

Epoch: 6| Step: 5
Training loss: 2.0904054641723633
Validation loss: 2.156709611415863

Epoch: 6| Step: 6
Training loss: 1.9371628761291504
Validation loss: 2.1494099696477256

Epoch: 6| Step: 7
Training loss: 2.381199598312378
Validation loss: 2.128605902194977

Epoch: 6| Step: 8
Training loss: 1.7658820152282715
Validation loss: 2.14464404185613

Epoch: 6| Step: 9
Training loss: 2.273228406906128
Validation loss: 2.1416283448537192

Epoch: 6| Step: 10
Training loss: 2.418964385986328
Validation loss: 2.148330509662628

Epoch: 6| Step: 11
Training loss: 1.6712088584899902
Validation loss: 2.1177435715993247

Epoch: 6| Step: 12
Training loss: 1.6862051486968994
Validation loss: 2.127161721388499

Epoch: 6| Step: 13
Training loss: 1.444752812385559
Validation loss: 2.129649579524994

Epoch: 209| Step: 0
Training loss: 1.5380027294158936
Validation loss: 2.1233949263890586

Epoch: 6| Step: 1
Training loss: 2.1015710830688477
Validation loss: 2.1415851712226868

Epoch: 6| Step: 2
Training loss: 2.1232447624206543
Validation loss: 2.128201901912689

Epoch: 6| Step: 3
Training loss: 1.7408405542373657
Validation loss: 2.1295730670293174

Epoch: 6| Step: 4
Training loss: 1.374774694442749
Validation loss: 2.1515766382217407

Epoch: 6| Step: 5
Training loss: 1.6934341192245483
Validation loss: 2.1447596351305642

Epoch: 6| Step: 6
Training loss: 1.8523565530776978
Validation loss: 2.142211635907491

Epoch: 6| Step: 7
Training loss: 2.279595136642456
Validation loss: 2.1408661603927612

Epoch: 6| Step: 8
Training loss: 1.7881195545196533
Validation loss: 2.136164824167887

Epoch: 6| Step: 9
Training loss: 1.9882383346557617
Validation loss: 2.161957641442617

Epoch: 6| Step: 10
Training loss: 1.603323221206665
Validation loss: 2.1559770107269287

Epoch: 6| Step: 11
Training loss: 1.8747708797454834
Validation loss: 2.1492758989334106

Epoch: 6| Step: 12
Training loss: 2.166423797607422
Validation loss: 2.1597028573354087

Epoch: 6| Step: 13
Training loss: 1.8572211265563965
Validation loss: 2.17776620388031

Epoch: 210| Step: 0
Training loss: 1.3736239671707153
Validation loss: 2.167078157265981

Epoch: 6| Step: 1
Training loss: 2.3639068603515625
Validation loss: 2.1458242336908975

Epoch: 6| Step: 2
Training loss: 2.046363353729248
Validation loss: 2.155186871687571

Epoch: 6| Step: 3
Training loss: 1.4777095317840576
Validation loss: 2.1599313418070474

Epoch: 6| Step: 4
Training loss: 2.1416594982147217
Validation loss: 2.158182978630066

Epoch: 6| Step: 5
Training loss: 1.6911336183547974
Validation loss: 2.147205372651418

Epoch: 6| Step: 6
Training loss: 1.6289629936218262
Validation loss: 2.13380895058314

Epoch: 6| Step: 7
Training loss: 2.106276512145996
Validation loss: 2.1403785745302835

Epoch: 6| Step: 8
Training loss: 1.7870277166366577
Validation loss: 2.143626073996226

Epoch: 6| Step: 9
Training loss: 1.451069712638855
Validation loss: 2.1528521378835044

Epoch: 6| Step: 10
Training loss: 1.8689897060394287
Validation loss: 2.162716865539551

Epoch: 6| Step: 11
Training loss: 1.8789355754852295
Validation loss: 2.152267813682556

Epoch: 6| Step: 12
Training loss: 2.468317985534668
Validation loss: 2.164797822634379

Epoch: 6| Step: 13
Training loss: 1.734311819076538
Validation loss: 2.190019647280375

Epoch: 211| Step: 0
Training loss: 2.325796365737915
Validation loss: 2.1395461161931357

Epoch: 6| Step: 1
Training loss: 1.3098537921905518
Validation loss: 2.131890118122101

Epoch: 6| Step: 2
Training loss: 1.4893295764923096
Validation loss: 2.1219663619995117

Epoch: 6| Step: 3
Training loss: 1.7426865100860596
Validation loss: 2.1304755409558616

Epoch: 6| Step: 4
Training loss: 1.9428461790084839
Validation loss: 2.110285302003225

Epoch: 6| Step: 5
Training loss: 1.7722160816192627
Validation loss: 2.099738895893097

Epoch: 6| Step: 6
Training loss: 1.4448206424713135
Validation loss: 2.0937103629112244

Epoch: 6| Step: 7
Training loss: 2.5268454551696777
Validation loss: 2.094252049922943

Epoch: 6| Step: 8
Training loss: 2.184711456298828
Validation loss: 2.0953750809033713

Epoch: 6| Step: 9
Training loss: 2.4015955924987793
Validation loss: 2.111349125703176

Epoch: 6| Step: 10
Training loss: 1.9304002523422241
Validation loss: 2.0935402115186057

Epoch: 6| Step: 11
Training loss: 2.008180618286133
Validation loss: 2.107916613419851

Epoch: 6| Step: 12
Training loss: 2.146120071411133
Validation loss: 2.1230191191037497

Epoch: 6| Step: 13
Training loss: 1.7978848218917847
Validation loss: 2.130626082420349

Epoch: 212| Step: 0
Training loss: 1.91826593875885
Validation loss: 2.1589553157488504

Epoch: 6| Step: 1
Training loss: 1.800257921218872
Validation loss: 2.1595561703046164

Epoch: 6| Step: 2
Training loss: 1.236068606376648
Validation loss: 2.1669638951619468

Epoch: 6| Step: 3
Training loss: 1.7584092617034912
Validation loss: 2.1928619146347046

Epoch: 6| Step: 4
Training loss: 1.3226014375686646
Validation loss: 2.1785427927970886

Epoch: 6| Step: 5
Training loss: 1.8387863636016846
Validation loss: 2.182646155357361

Epoch: 6| Step: 6
Training loss: 2.087900161743164
Validation loss: 2.1972216765085855

Epoch: 6| Step: 7
Training loss: 1.9000648260116577
Validation loss: 2.2050416072209678

Epoch: 6| Step: 8
Training loss: 1.9931750297546387
Validation loss: 2.19219704469045

Epoch: 6| Step: 9
Training loss: 1.7760286331176758
Validation loss: 2.2058324217796326

Epoch: 6| Step: 10
Training loss: 1.7324455976486206
Validation loss: 2.1695339679718018

Epoch: 6| Step: 11
Training loss: 1.912858009338379
Validation loss: 2.1407814621925354

Epoch: 6| Step: 12
Training loss: 2.1329057216644287
Validation loss: 2.1360265413920083

Epoch: 6| Step: 13
Training loss: 2.4674630165100098
Validation loss: 2.1282439629236856

Epoch: 213| Step: 0
Training loss: 2.2541656494140625
Validation loss: 2.114688058694204

Epoch: 6| Step: 1
Training loss: 1.705235242843628
Validation loss: 2.113332211971283

Epoch: 6| Step: 2
Training loss: 1.5264085531234741
Validation loss: 2.1163955132166543

Epoch: 6| Step: 3
Training loss: 1.799506664276123
Validation loss: 2.123481869697571

Epoch: 6| Step: 4
Training loss: 1.5326443910598755
Validation loss: 2.123670140902201

Epoch: 6| Step: 5
Training loss: 1.8234679698944092
Validation loss: 2.1456470489501953

Epoch: 6| Step: 6
Training loss: 2.723179817199707
Validation loss: 2.1562717159589133

Epoch: 6| Step: 7
Training loss: 2.164703130722046
Validation loss: 2.1647990544637046

Epoch: 6| Step: 8
Training loss: 1.550248622894287
Validation loss: 2.1635584235191345

Epoch: 6| Step: 9
Training loss: 1.7401418685913086
Validation loss: 2.1774393717447915

Epoch: 6| Step: 10
Training loss: 1.9135501384735107
Validation loss: 2.163002610206604

Epoch: 6| Step: 11
Training loss: 1.9576213359832764
Validation loss: 2.1781082352002463

Epoch: 6| Step: 12
Training loss: 2.5532805919647217
Validation loss: 2.1633930603663125

Epoch: 6| Step: 13
Training loss: 1.264484167098999
Validation loss: 2.160074750582377

Epoch: 214| Step: 0
Training loss: 1.9350183010101318
Validation loss: 2.1560317277908325

Epoch: 6| Step: 1
Training loss: 1.4211041927337646
Validation loss: 2.149474302927653

Epoch: 6| Step: 2
Training loss: 1.7530834674835205
Validation loss: 2.138000190258026

Epoch: 6| Step: 3
Training loss: 2.221217155456543
Validation loss: 2.147573232650757

Epoch: 6| Step: 4
Training loss: 2.4352192878723145
Validation loss: 2.1265979607899985

Epoch: 6| Step: 5
Training loss: 1.6890552043914795
Validation loss: 2.1321537097295127

Epoch: 6| Step: 6
Training loss: 1.9056204557418823
Validation loss: 2.1283645232518515

Epoch: 6| Step: 7
Training loss: 2.330151319503784
Validation loss: 2.118857661883036

Epoch: 6| Step: 8
Training loss: 2.1598868370056152
Validation loss: 2.1170154412587485

Epoch: 6| Step: 9
Training loss: 1.4260985851287842
Validation loss: 2.1347256302833557

Epoch: 6| Step: 10
Training loss: 2.16762113571167
Validation loss: 2.1369441548983255

Epoch: 6| Step: 11
Training loss: 1.8313733339309692
Validation loss: 2.1177725394566855

Epoch: 6| Step: 12
Training loss: 1.8050321340560913
Validation loss: 2.135756492614746

Epoch: 6| Step: 13
Training loss: 1.3313896656036377
Validation loss: 2.139369249343872

Epoch: 215| Step: 0
Training loss: 0.9047808647155762
Validation loss: 2.148138403892517

Epoch: 6| Step: 1
Training loss: 2.502631425857544
Validation loss: 2.156503180662791

Epoch: 6| Step: 2
Training loss: 1.8102681636810303
Validation loss: 2.157970905303955

Epoch: 6| Step: 3
Training loss: 2.262521266937256
Validation loss: 2.160540541013082

Epoch: 6| Step: 4
Training loss: 1.742203950881958
Validation loss: 2.16097225745519

Epoch: 6| Step: 5
Training loss: 2.3860344886779785
Validation loss: 2.1467925906181335

Epoch: 6| Step: 6
Training loss: 1.6236000061035156
Validation loss: 2.140092194080353

Epoch: 6| Step: 7
Training loss: 1.7979021072387695
Validation loss: 2.143955330053965

Epoch: 6| Step: 8
Training loss: 1.8778281211853027
Validation loss: 2.146978755791982

Epoch: 6| Step: 9
Training loss: 1.0534565448760986
Validation loss: 2.146945834159851

Epoch: 6| Step: 10
Training loss: 1.868232250213623
Validation loss: 2.1509528160095215

Epoch: 6| Step: 11
Training loss: 1.6220121383666992
Validation loss: 2.1772396564483643

Epoch: 6| Step: 12
Training loss: 1.9528685808181763
Validation loss: 2.168360869089762

Epoch: 6| Step: 13
Training loss: 2.400249719619751
Validation loss: 2.1639170249303183

Epoch: 216| Step: 0
Training loss: 1.7774232625961304
Validation loss: 2.1898029247919717

Epoch: 6| Step: 1
Training loss: 1.087949275970459
Validation loss: 2.194055716196696

Epoch: 6| Step: 2
Training loss: 1.7632038593292236
Validation loss: 2.2025581200917563

Epoch: 6| Step: 3
Training loss: 1.5017814636230469
Validation loss: 2.195905923843384

Epoch: 6| Step: 4
Training loss: 1.8995137214660645
Validation loss: 2.1978660424550376

Epoch: 6| Step: 5
Training loss: 2.118450164794922
Validation loss: 2.184307634830475

Epoch: 6| Step: 6
Training loss: 2.180795669555664
Validation loss: 2.1881905794143677

Epoch: 6| Step: 7
Training loss: 1.9345170259475708
Validation loss: 2.1970092058181763

Epoch: 6| Step: 8
Training loss: 1.3972742557525635
Validation loss: 2.176998813947042

Epoch: 6| Step: 9
Training loss: 1.6760629415512085
Validation loss: 2.1832053661346436

Epoch: 6| Step: 10
Training loss: 2.3251681327819824
Validation loss: 2.1819741129875183

Epoch: 6| Step: 11
Training loss: 1.6193597316741943
Validation loss: 2.1558539271354675

Epoch: 6| Step: 12
Training loss: 2.102642059326172
Validation loss: 2.1518465081850686

Epoch: 6| Step: 13
Training loss: 2.4172229766845703
Validation loss: 2.1751614809036255

Epoch: 217| Step: 0
Training loss: 1.9698224067687988
Validation loss: 2.156585395336151

Epoch: 6| Step: 1
Training loss: 1.7485063076019287
Validation loss: 2.149346351623535

Epoch: 6| Step: 2
Training loss: 1.4544625282287598
Validation loss: 2.1479851404825845

Epoch: 6| Step: 3
Training loss: 2.1995599269866943
Validation loss: 2.1429198185602822

Epoch: 6| Step: 4
Training loss: 1.384155511856079
Validation loss: 2.1400870283444724

Epoch: 6| Step: 5
Training loss: 2.035451889038086
Validation loss: 2.1462682286898294

Epoch: 6| Step: 6
Training loss: 1.5901648998260498
Validation loss: 2.1355010668436685

Epoch: 6| Step: 7
Training loss: 2.0895230770111084
Validation loss: 2.1496434211730957

Epoch: 6| Step: 8
Training loss: 2.053341865539551
Validation loss: 2.145352005958557

Epoch: 6| Step: 9
Training loss: 2.25858736038208
Validation loss: 2.1600751678148904

Epoch: 6| Step: 10
Training loss: 2.7282938957214355
Validation loss: 2.161383072535197

Epoch: 6| Step: 11
Training loss: 1.647985577583313
Validation loss: 2.1615658601125083

Epoch: 6| Step: 12
Training loss: 1.7740558385849
Validation loss: 2.161160171031952

Epoch: 6| Step: 13
Training loss: 1.5113770961761475
Validation loss: 2.184067726135254

Epoch: 218| Step: 0
Training loss: 2.164623260498047
Validation loss: 2.158123771349589

Epoch: 6| Step: 1
Training loss: 2.047926902770996
Validation loss: 2.1807260513305664

Epoch: 6| Step: 2
Training loss: 1.6951030492782593
Validation loss: 2.197839876015981

Epoch: 6| Step: 3
Training loss: 2.268192768096924
Validation loss: 2.196305433909098

Epoch: 6| Step: 4
Training loss: 2.6457271575927734
Validation loss: 2.2292062838872275

Epoch: 6| Step: 5
Training loss: 1.491164207458496
Validation loss: 2.1985603968302407

Epoch: 6| Step: 6
Training loss: 2.0347342491149902
Validation loss: 2.218878189722697

Epoch: 6| Step: 7
Training loss: 1.6938831806182861
Validation loss: 2.201795279979706

Epoch: 6| Step: 8
Training loss: 1.4735466241836548
Validation loss: 2.191466212272644

Epoch: 6| Step: 9
Training loss: 1.536275863647461
Validation loss: 2.176511804262797

Epoch: 6| Step: 10
Training loss: 1.6891484260559082
Validation loss: 2.191670020421346

Epoch: 6| Step: 11
Training loss: 1.7052948474884033
Validation loss: 2.2023945450782776

Epoch: 6| Step: 12
Training loss: 1.6447314023971558
Validation loss: 2.1819327672322593

Epoch: 6| Step: 13
Training loss: 1.5012065172195435
Validation loss: 2.148729701836904

Epoch: 219| Step: 0
Training loss: 1.9054796695709229
Validation loss: 2.162336071332296

Epoch: 6| Step: 1
Training loss: 1.7557982206344604
Validation loss: 2.146734873453776

Epoch: 6| Step: 2
Training loss: 2.5117926597595215
Validation loss: 2.1471755305926004

Epoch: 6| Step: 3
Training loss: 2.062717914581299
Validation loss: 2.1485323905944824

Epoch: 6| Step: 4
Training loss: 1.6870713233947754
Validation loss: 2.146096348762512

Epoch: 6| Step: 5
Training loss: 2.482201337814331
Validation loss: 2.1616304914156594

Epoch: 6| Step: 6
Training loss: 1.646697759628296
Validation loss: 2.16659806172053

Epoch: 6| Step: 7
Training loss: 2.2093758583068848
Validation loss: 2.162164549032847

Epoch: 6| Step: 8
Training loss: 1.4577903747558594
Validation loss: 2.1726818482081094

Epoch: 6| Step: 9
Training loss: 1.4454500675201416
Validation loss: 2.1658802231152854

Epoch: 6| Step: 10
Training loss: 2.1198761463165283
Validation loss: 2.1866067250569663

Epoch: 6| Step: 11
Training loss: 1.6219515800476074
Validation loss: 2.1766457756360373

Epoch: 6| Step: 12
Training loss: 1.2369847297668457
Validation loss: 2.175870954990387

Epoch: 6| Step: 13
Training loss: 1.9656572341918945
Validation loss: 2.1836522420247397

Epoch: 220| Step: 0
Training loss: 2.5192067623138428
Validation loss: 2.1578073104222617

Epoch: 6| Step: 1
Training loss: 1.1553778648376465
Validation loss: 2.187951683998108

Epoch: 6| Step: 2
Training loss: 1.7008830308914185
Validation loss: 2.1743536591529846

Epoch: 6| Step: 3
Training loss: 2.0977396965026855
Validation loss: 2.1602776646614075

Epoch: 6| Step: 4
Training loss: 1.854212999343872
Validation loss: 2.173712174097697

Epoch: 6| Step: 5
Training loss: 2.148385524749756
Validation loss: 2.1628863414128623

Epoch: 6| Step: 6
Training loss: 1.3896979093551636
Validation loss: 2.150015970071157

Epoch: 6| Step: 7
Training loss: 1.9607619047164917
Validation loss: 2.15885990858078

Epoch: 6| Step: 8
Training loss: 1.5656564235687256
Validation loss: 2.1513317823410034

Epoch: 6| Step: 9
Training loss: 1.436862826347351
Validation loss: 2.1342830260594687

Epoch: 6| Step: 10
Training loss: 1.7377476692199707
Validation loss: 2.146575113137563

Epoch: 6| Step: 11
Training loss: 1.985217571258545
Validation loss: 2.1694385608037314

Epoch: 6| Step: 12
Training loss: 2.918607234954834
Validation loss: 2.1642257372538247

Epoch: 6| Step: 13
Training loss: 1.1673425436019897
Validation loss: 2.197704335053762

Epoch: 221| Step: 0
Training loss: 1.7913556098937988
Validation loss: 2.1954076687494912

Epoch: 6| Step: 1
Training loss: 2.6563282012939453
Validation loss: 2.2237799167633057

Epoch: 6| Step: 2
Training loss: 1.8748654127120972
Validation loss: 2.241850753625234

Epoch: 6| Step: 3
Training loss: 1.7659591436386108
Validation loss: 2.226109584172567

Epoch: 6| Step: 4
Training loss: 2.2340095043182373
Validation loss: 2.2228036920229592

Epoch: 6| Step: 5
Training loss: 1.4486243724822998
Validation loss: 2.2129019300142923

Epoch: 6| Step: 6
Training loss: 1.712791919708252
Validation loss: 2.205999414126078

Epoch: 6| Step: 7
Training loss: 1.5277994871139526
Validation loss: 2.1965343952178955

Epoch: 6| Step: 8
Training loss: 1.2072696685791016
Validation loss: 2.190247376759847

Epoch: 6| Step: 9
Training loss: 2.5348119735717773
Validation loss: 2.198338528474172

Epoch: 6| Step: 10
Training loss: 2.053201675415039
Validation loss: 2.2011993726094565

Epoch: 6| Step: 11
Training loss: 1.136836051940918
Validation loss: 2.189399858315786

Epoch: 6| Step: 12
Training loss: 1.8856738805770874
Validation loss: 2.1987322767575583

Epoch: 6| Step: 13
Training loss: 1.7467163801193237
Validation loss: 2.1839632391929626

Epoch: 222| Step: 0
Training loss: 2.267690896987915
Validation loss: 2.167962074279785

Epoch: 6| Step: 1
Training loss: 1.5677852630615234
Validation loss: 2.1816429495811462

Epoch: 6| Step: 2
Training loss: 1.554544448852539
Validation loss: 2.165087640285492

Epoch: 6| Step: 3
Training loss: 1.5532450675964355
Validation loss: 2.1838895678520203

Epoch: 6| Step: 4
Training loss: 1.4369633197784424
Validation loss: 2.206572433312734

Epoch: 6| Step: 5
Training loss: 2.1842451095581055
Validation loss: 2.184038519859314

Epoch: 6| Step: 6
Training loss: 1.837645411491394
Validation loss: 2.159952779610952

Epoch: 6| Step: 7
Training loss: 2.264272928237915
Validation loss: 2.1707966923713684

Epoch: 6| Step: 8
Training loss: 1.8540799617767334
Validation loss: 2.178861359755198

Epoch: 6| Step: 9
Training loss: 2.441875696182251
Validation loss: 2.1804672280947366

Epoch: 6| Step: 10
Training loss: 1.3116496801376343
Validation loss: 2.187162160873413

Epoch: 6| Step: 11
Training loss: 2.1903605461120605
Validation loss: 2.203823526700338

Epoch: 6| Step: 12
Training loss: 1.7893481254577637
Validation loss: 2.206555744012197

Epoch: 6| Step: 13
Training loss: 1.1426966190338135
Validation loss: 2.208305756251017

Epoch: 223| Step: 0
Training loss: 2.0862417221069336
Validation loss: 2.2305941581726074

Epoch: 6| Step: 1
Training loss: 1.8323363065719604
Validation loss: 2.2268884976704917

Epoch: 6| Step: 2
Training loss: 2.3928890228271484
Validation loss: 2.238879839579264

Epoch: 6| Step: 3
Training loss: 1.4664039611816406
Validation loss: 2.2518666783968606

Epoch: 6| Step: 4
Training loss: 2.411989450454712
Validation loss: 2.2468759417533875

Epoch: 6| Step: 5
Training loss: 1.9187462329864502
Validation loss: 2.2290526827176413

Epoch: 6| Step: 6
Training loss: 1.8525454998016357
Validation loss: 2.200500011444092

Epoch: 6| Step: 7
Training loss: 2.711303234100342
Validation loss: 2.1777848402659097

Epoch: 6| Step: 8
Training loss: 1.1424248218536377
Validation loss: 2.1275837222735086

Epoch: 6| Step: 9
Training loss: 1.522141933441162
Validation loss: 2.1312720576922097

Epoch: 6| Step: 10
Training loss: 1.7707457542419434
Validation loss: 2.1311009724934897

Epoch: 6| Step: 11
Training loss: 1.7960619926452637
Validation loss: 2.1265825033187866

Epoch: 6| Step: 12
Training loss: 1.9538047313690186
Validation loss: 2.1221688191095986

Epoch: 6| Step: 13
Training loss: 1.7192856073379517
Validation loss: 2.1435399254163108

Epoch: 224| Step: 0
Training loss: 1.7322317361831665
Validation loss: 2.166655341784159

Epoch: 6| Step: 1
Training loss: 2.306215763092041
Validation loss: 2.16591469446818

Epoch: 6| Step: 2
Training loss: 2.3907392024993896
Validation loss: 2.177646299203237

Epoch: 6| Step: 3
Training loss: 1.4076828956604004
Validation loss: 2.1941480239232383

Epoch: 6| Step: 4
Training loss: 1.469642162322998
Validation loss: 2.2233980894088745

Epoch: 6| Step: 5
Training loss: 1.5913152694702148
Validation loss: 2.2015247344970703

Epoch: 6| Step: 6
Training loss: 1.6557568311691284
Validation loss: 2.217420975367228

Epoch: 6| Step: 7
Training loss: 2.1425743103027344
Validation loss: 2.2030083735783896

Epoch: 6| Step: 8
Training loss: 1.411502480506897
Validation loss: 2.195960978666941

Epoch: 6| Step: 9
Training loss: 1.9501010179519653
Validation loss: 2.199735403060913

Epoch: 6| Step: 10
Training loss: 1.5145130157470703
Validation loss: 2.1942439874013266

Epoch: 6| Step: 11
Training loss: 1.992220401763916
Validation loss: 2.164796789487203

Epoch: 6| Step: 12
Training loss: 1.915518045425415
Validation loss: 2.141218105951945

Epoch: 6| Step: 13
Training loss: 2.28489089012146
Validation loss: 2.1588213046391806

Epoch: 225| Step: 0
Training loss: 1.612011432647705
Validation loss: 2.1311286290486655

Epoch: 6| Step: 1
Training loss: 1.8794898986816406
Validation loss: 2.1370867093404136

Epoch: 6| Step: 2
Training loss: 1.778713583946228
Validation loss: 2.1454440156618753

Epoch: 6| Step: 3
Training loss: 2.577578067779541
Validation loss: 2.1298288305600486

Epoch: 6| Step: 4
Training loss: 2.290079116821289
Validation loss: 2.133071005344391

Epoch: 6| Step: 5
Training loss: 2.648203134536743
Validation loss: 2.140649199485779

Epoch: 6| Step: 6
Training loss: 1.754852056503296
Validation loss: 2.1372164289156594

Epoch: 6| Step: 7
Training loss: 1.4238264560699463
Validation loss: 2.163843353589376

Epoch: 6| Step: 8
Training loss: 1.8696315288543701
Validation loss: 2.154626409212748

Epoch: 6| Step: 9
Training loss: 1.9594836235046387
Validation loss: 2.1661709944407144

Epoch: 6| Step: 10
Training loss: 1.7092550992965698
Validation loss: 2.161405305067698

Epoch: 6| Step: 11
Training loss: 1.5461338758468628
Validation loss: 2.1630136966705322

Epoch: 6| Step: 12
Training loss: 1.7648124694824219
Validation loss: 2.182737569014231

Epoch: 6| Step: 13
Training loss: 1.725494146347046
Validation loss: 2.1646706461906433

Epoch: 226| Step: 0
Training loss: 1.8292946815490723
Validation loss: 2.1683409412701926

Epoch: 6| Step: 1
Training loss: 1.732523798942566
Validation loss: 2.1652926206588745

Epoch: 6| Step: 2
Training loss: 2.9533605575561523
Validation loss: 2.1935800512631736

Epoch: 6| Step: 3
Training loss: 1.5291489362716675
Validation loss: 2.1651538014411926

Epoch: 6| Step: 4
Training loss: 1.347158432006836
Validation loss: 2.185872753461202

Epoch: 6| Step: 5
Training loss: 1.7953122854232788
Validation loss: 2.1593485275904336

Epoch: 6| Step: 6
Training loss: 1.6120610237121582
Validation loss: 2.1633737087249756

Epoch: 6| Step: 7
Training loss: 1.5899680852890015
Validation loss: 2.1446173787117004

Epoch: 6| Step: 8
Training loss: 1.6558656692504883
Validation loss: 2.1351762612660727

Epoch: 6| Step: 9
Training loss: 1.6263984441757202
Validation loss: 2.161262849966685

Epoch: 6| Step: 10
Training loss: 2.417616128921509
Validation loss: 2.1590722600618997

Epoch: 6| Step: 11
Training loss: 1.6840553283691406
Validation loss: 2.150464872519175

Epoch: 6| Step: 12
Training loss: 1.7775846719741821
Validation loss: 2.163528879483541

Epoch: 6| Step: 13
Training loss: 1.9500393867492676
Validation loss: 2.1520679791768393

Epoch: 227| Step: 0
Training loss: 1.0506435632705688
Validation loss: 2.1529584725697837

Epoch: 6| Step: 1
Training loss: 1.1157946586608887
Validation loss: 2.1543200612068176

Epoch: 6| Step: 2
Training loss: 2.317018508911133
Validation loss: 2.1573552886644998

Epoch: 6| Step: 3
Training loss: 1.6603989601135254
Validation loss: 2.1530850330988565

Epoch: 6| Step: 4
Training loss: 2.6152424812316895
Validation loss: 2.170578638712565

Epoch: 6| Step: 5
Training loss: 1.9853185415267944
Validation loss: 2.179869612058004

Epoch: 6| Step: 6
Training loss: 2.5074779987335205
Validation loss: 2.1725494066874185

Epoch: 6| Step: 7
Training loss: 2.2030282020568848
Validation loss: 2.156221787134806

Epoch: 6| Step: 8
Training loss: 1.9487040042877197
Validation loss: 2.1541911959648132

Epoch: 6| Step: 9
Training loss: 1.8006023168563843
Validation loss: 2.1778255303700766

Epoch: 6| Step: 10
Training loss: 1.2085903882980347
Validation loss: 2.1628554662068686

Epoch: 6| Step: 11
Training loss: 1.2345021963119507
Validation loss: 2.1695324182510376

Epoch: 6| Step: 12
Training loss: 1.7236659526824951
Validation loss: 2.1838443080584207

Epoch: 6| Step: 13
Training loss: 2.0615270137786865
Validation loss: 2.179459571838379

Epoch: 228| Step: 0
Training loss: 1.7753995656967163
Validation loss: 2.164628048737844

Epoch: 6| Step: 1
Training loss: 1.3446440696716309
Validation loss: 2.157701392968496

Epoch: 6| Step: 2
Training loss: 1.7750251293182373
Validation loss: 2.1523859103520713

Epoch: 6| Step: 3
Training loss: 1.7429512739181519
Validation loss: 2.1767443815867105

Epoch: 6| Step: 4
Training loss: 1.7279667854309082
Validation loss: 2.1614493131637573

Epoch: 6| Step: 5
Training loss: 1.5059576034545898
Validation loss: 2.1714295943578086

Epoch: 6| Step: 6
Training loss: 1.0897746086120605
Validation loss: 2.144923508167267

Epoch: 6| Step: 7
Training loss: 1.6693519353866577
Validation loss: 2.1499265829722085

Epoch: 6| Step: 8
Training loss: 2.5018844604492188
Validation loss: 2.159645219643911

Epoch: 6| Step: 9
Training loss: 1.722405195236206
Validation loss: 2.1610814134279885

Epoch: 6| Step: 10
Training loss: 1.8373210430145264
Validation loss: 2.1543142994244895

Epoch: 6| Step: 11
Training loss: 2.2630622386932373
Validation loss: 2.172350287437439

Epoch: 6| Step: 12
Training loss: 1.9161456823349
Validation loss: 2.1704907615979514

Epoch: 6| Step: 13
Training loss: 2.277933120727539
Validation loss: 2.1640747785568237

Epoch: 229| Step: 0
Training loss: 1.2183992862701416
Validation loss: 2.1700791319211326

Epoch: 6| Step: 1
Training loss: 1.6741437911987305
Validation loss: 2.168831725915273

Epoch: 6| Step: 2
Training loss: 2.7289810180664062
Validation loss: 2.1699646711349487

Epoch: 6| Step: 3
Training loss: 1.6421129703521729
Validation loss: 2.1649219195048013

Epoch: 6| Step: 4
Training loss: 1.3977906703948975
Validation loss: 2.143931746482849

Epoch: 6| Step: 5
Training loss: 2.5953176021575928
Validation loss: 2.157626231511434

Epoch: 6| Step: 6
Training loss: 1.9078211784362793
Validation loss: 2.153625706831614

Epoch: 6| Step: 7
Training loss: 1.9749995470046997
Validation loss: 2.173578202724457

Epoch: 6| Step: 8
Training loss: 1.810058832168579
Validation loss: 2.176514148712158

Epoch: 6| Step: 9
Training loss: 1.7177352905273438
Validation loss: 2.174669921398163

Epoch: 6| Step: 10
Training loss: 2.3309669494628906
Validation loss: 2.1913779377937317

Epoch: 6| Step: 11
Training loss: 1.60521399974823
Validation loss: 2.198603947957357

Epoch: 6| Step: 12
Training loss: 1.1700611114501953
Validation loss: 2.1849926114082336

Epoch: 6| Step: 13
Training loss: 1.766247034072876
Validation loss: 2.183887322743734

Epoch: 230| Step: 0
Training loss: 2.345151662826538
Validation loss: 2.142261524995168

Epoch: 6| Step: 1
Training loss: 1.3876063823699951
Validation loss: 2.128944476445516

Epoch: 6| Step: 2
Training loss: 1.6416654586791992
Validation loss: 2.1246235569318137

Epoch: 6| Step: 3
Training loss: 1.986061453819275
Validation loss: 2.1477278669675193

Epoch: 6| Step: 4
Training loss: 1.7704370021820068
Validation loss: 2.1285624702771506

Epoch: 6| Step: 5
Training loss: 2.3256795406341553
Validation loss: 2.1239503622055054

Epoch: 6| Step: 6
Training loss: 1.4907389879226685
Validation loss: 2.1563008626302085

Epoch: 6| Step: 7
Training loss: 1.0227062702178955
Validation loss: 2.147938867410024

Epoch: 6| Step: 8
Training loss: 1.41845703125
Validation loss: 2.1761048436164856

Epoch: 6| Step: 9
Training loss: 1.992673635482788
Validation loss: 2.162675937016805

Epoch: 6| Step: 10
Training loss: 2.3241846561431885
Validation loss: 2.1853004097938538

Epoch: 6| Step: 11
Training loss: 1.4835820198059082
Validation loss: 2.1968201796213784

Epoch: 6| Step: 12
Training loss: 1.5536680221557617
Validation loss: 2.1972097158432007

Epoch: 6| Step: 13
Training loss: 2.484196662902832
Validation loss: 2.2172234455744424

Epoch: 231| Step: 0
Training loss: 2.0696656703948975
Validation loss: 2.209569215774536

Epoch: 6| Step: 1
Training loss: 1.6210854053497314
Validation loss: 2.207422892252604

Epoch: 6| Step: 2
Training loss: 1.4570720195770264
Validation loss: 2.1843148271242776

Epoch: 6| Step: 3
Training loss: 1.4969698190689087
Validation loss: 2.1827535033226013

Epoch: 6| Step: 4
Training loss: 1.913122534751892
Validation loss: 2.168904185295105

Epoch: 6| Step: 5
Training loss: 1.6651393175125122
Validation loss: 2.1547999382019043

Epoch: 6| Step: 6
Training loss: 1.1978967189788818
Validation loss: 2.1447200576464334

Epoch: 6| Step: 7
Training loss: 2.225374698638916
Validation loss: 2.153321703275045

Epoch: 6| Step: 8
Training loss: 2.1111602783203125
Validation loss: 2.1665638287862143

Epoch: 6| Step: 9
Training loss: 2.128556251525879
Validation loss: 2.1305189728736877

Epoch: 6| Step: 10
Training loss: 2.247760772705078
Validation loss: 2.185976246992747

Epoch: 6| Step: 11
Training loss: 1.774245023727417
Validation loss: 2.1896827618281045

Epoch: 6| Step: 12
Training loss: 1.6302859783172607
Validation loss: 2.1861225763956704

Epoch: 6| Step: 13
Training loss: 2.130082845687866
Validation loss: 2.1896855433781943

Epoch: 232| Step: 0
Training loss: 1.2538933753967285
Validation loss: 2.1960925658543906

Epoch: 6| Step: 1
Training loss: 2.0741167068481445
Validation loss: 2.200998226801554

Epoch: 6| Step: 2
Training loss: 2.162196636199951
Validation loss: 2.204962174097697

Epoch: 6| Step: 3
Training loss: 1.9491504430770874
Validation loss: 2.215116719404856

Epoch: 6| Step: 4
Training loss: 3.400449752807617
Validation loss: 2.232414662837982

Epoch: 6| Step: 5
Training loss: 1.9864076375961304
Validation loss: 2.2160022060076394

Epoch: 6| Step: 6
Training loss: 1.7442835569381714
Validation loss: 2.2395170529683432

Epoch: 6| Step: 7
Training loss: 1.92250394821167
Validation loss: 2.2281736532847085

Epoch: 6| Step: 8
Training loss: 1.8895145654678345
Validation loss: 2.200028717517853

Epoch: 6| Step: 9
Training loss: 1.906067967414856
Validation loss: 2.205431958039602

Epoch: 6| Step: 10
Training loss: 1.8377918004989624
Validation loss: 2.1841030518213906

Epoch: 6| Step: 11
Training loss: 1.5662412643432617
Validation loss: 2.177048126856486

Epoch: 6| Step: 12
Training loss: 1.0310465097427368
Validation loss: 2.1694557468096414

Epoch: 6| Step: 13
Training loss: 1.1170399188995361
Validation loss: 2.1750975251197815

Epoch: 233| Step: 0
Training loss: 1.3965888023376465
Validation loss: 2.1857757568359375

Epoch: 6| Step: 1
Training loss: 1.6807072162628174
Validation loss: 2.171429475148519

Epoch: 6| Step: 2
Training loss: 2.0371339321136475
Validation loss: 2.1838541626930237

Epoch: 6| Step: 3
Training loss: 2.0956006050109863
Validation loss: 2.1816680828730264

Epoch: 6| Step: 4
Training loss: 2.4900763034820557
Validation loss: 2.1543980836868286

Epoch: 6| Step: 5
Training loss: 1.7892682552337646
Validation loss: 2.1858522097269693

Epoch: 6| Step: 6
Training loss: 1.7268898487091064
Validation loss: 2.183157960573832

Epoch: 6| Step: 7
Training loss: 1.5541670322418213
Validation loss: 2.179481248060862

Epoch: 6| Step: 8
Training loss: 1.961357831954956
Validation loss: 2.182854493459066

Epoch: 6| Step: 9
Training loss: 1.8768619298934937
Validation loss: 2.213221867879232

Epoch: 6| Step: 10
Training loss: 1.5039520263671875
Validation loss: 2.209116260210673

Epoch: 6| Step: 11
Training loss: 1.5683825016021729
Validation loss: 2.189154088497162

Epoch: 6| Step: 12
Training loss: 1.7475006580352783
Validation loss: 2.2004606326421103

Epoch: 6| Step: 13
Training loss: 1.6660242080688477
Validation loss: 2.209882994492849

Epoch: 234| Step: 0
Training loss: 1.0039929151535034
Validation loss: 2.1893311540285745

Epoch: 6| Step: 1
Training loss: 2.3164865970611572
Validation loss: 2.1886991461118064

Epoch: 6| Step: 2
Training loss: 1.6164186000823975
Validation loss: 2.1572113831837973

Epoch: 6| Step: 3
Training loss: 1.486283779144287
Validation loss: 2.184106409549713

Epoch: 6| Step: 4
Training loss: 2.3373990058898926
Validation loss: 2.1590261459350586

Epoch: 6| Step: 5
Training loss: 1.3726377487182617
Validation loss: 2.1566333969434104

Epoch: 6| Step: 6
Training loss: 1.3356273174285889
Validation loss: 2.138454476992289

Epoch: 6| Step: 7
Training loss: 2.138113498687744
Validation loss: 2.1553497513135276

Epoch: 6| Step: 8
Training loss: 1.463890790939331
Validation loss: 2.171300768852234

Epoch: 6| Step: 9
Training loss: 2.024784564971924
Validation loss: 2.1487990617752075

Epoch: 6| Step: 10
Training loss: 2.027519464492798
Validation loss: 2.150948087374369

Epoch: 6| Step: 11
Training loss: 1.3507205247879028
Validation loss: 2.1408943931261697

Epoch: 6| Step: 12
Training loss: 1.779686450958252
Validation loss: 2.1476600964864097

Epoch: 6| Step: 13
Training loss: 2.725770950317383
Validation loss: 2.1487326423327127

Epoch: 235| Step: 0
Training loss: 2.264479875564575
Validation loss: 2.1722479263941445

Epoch: 6| Step: 1
Training loss: 1.3703317642211914
Validation loss: 2.160719851652781

Epoch: 6| Step: 2
Training loss: 1.724802017211914
Validation loss: 2.205590625603994

Epoch: 6| Step: 3
Training loss: 1.8060071468353271
Validation loss: 2.1701206167538962

Epoch: 6| Step: 4
Training loss: 1.8856303691864014
Validation loss: 2.202298899491628

Epoch: 6| Step: 5
Training loss: 1.6757140159606934
Validation loss: 2.1915712356567383

Epoch: 6| Step: 6
Training loss: 1.7320072650909424
Validation loss: 2.178954462210337

Epoch: 6| Step: 7
Training loss: 1.3442027568817139
Validation loss: 2.175187110900879

Epoch: 6| Step: 8
Training loss: 1.891566514968872
Validation loss: 2.1610746582349143

Epoch: 6| Step: 9
Training loss: 2.2064969539642334
Validation loss: 2.1406900882720947

Epoch: 6| Step: 10
Training loss: 2.1692047119140625
Validation loss: 2.140886048475901

Epoch: 6| Step: 11
Training loss: 1.67323899269104
Validation loss: 2.151476780573527

Epoch: 6| Step: 12
Training loss: 2.1896281242370605
Validation loss: 2.138206680615743

Epoch: 6| Step: 13
Training loss: 1.7496602535247803
Validation loss: 2.129910171031952

Epoch: 236| Step: 0
Training loss: 1.6973752975463867
Validation loss: 2.1383504072825112

Epoch: 6| Step: 1
Training loss: 2.1310575008392334
Validation loss: 2.1332140962282815

Epoch: 6| Step: 2
Training loss: 2.5688164234161377
Validation loss: 2.143340229988098

Epoch: 6| Step: 3
Training loss: 1.6326749324798584
Validation loss: 2.1515132784843445

Epoch: 6| Step: 4
Training loss: 1.8453946113586426
Validation loss: 2.1621235410372415

Epoch: 6| Step: 5
Training loss: 2.1669774055480957
Validation loss: 2.167634109656016

Epoch: 6| Step: 6
Training loss: 1.4002048969268799
Validation loss: 2.1510051091512046

Epoch: 6| Step: 7
Training loss: 1.528556227684021
Validation loss: 2.136341114838918

Epoch: 6| Step: 8
Training loss: 1.7467799186706543
Validation loss: 2.1633633573849997

Epoch: 6| Step: 9
Training loss: 1.5002940893173218
Validation loss: 2.160581092039744

Epoch: 6| Step: 10
Training loss: 2.4188456535339355
Validation loss: 2.1612002650896707

Epoch: 6| Step: 11
Training loss: 2.3675005435943604
Validation loss: 2.162365118662516

Epoch: 6| Step: 12
Training loss: 1.0885567665100098
Validation loss: 2.165460248788198

Epoch: 6| Step: 13
Training loss: 1.3936023712158203
Validation loss: 2.1320373018582663

Epoch: 237| Step: 0
Training loss: 2.4794890880584717
Validation loss: 2.160431683063507

Epoch: 6| Step: 1
Training loss: 1.7791036367416382
Validation loss: 2.1441946029663086

Epoch: 6| Step: 2
Training loss: 1.4036741256713867
Validation loss: 2.1529126167297363

Epoch: 6| Step: 3
Training loss: 1.980017900466919
Validation loss: 2.1784769694010415

Epoch: 6| Step: 4
Training loss: 1.641901969909668
Validation loss: 2.1656335592269897

Epoch: 6| Step: 5
Training loss: 1.6523222923278809
Validation loss: 2.1675373315811157

Epoch: 6| Step: 6
Training loss: 1.759321928024292
Validation loss: 2.1667455037434897

Epoch: 6| Step: 7
Training loss: 1.5715349912643433
Validation loss: 2.1393202543258667

Epoch: 6| Step: 8
Training loss: 1.756568431854248
Validation loss: 2.167207936445872

Epoch: 6| Step: 9
Training loss: 1.2623177766799927
Validation loss: 2.1537816325823465

Epoch: 6| Step: 10
Training loss: 1.577377200126648
Validation loss: 2.1782931288083396

Epoch: 6| Step: 11
Training loss: 1.8832271099090576
Validation loss: 2.218557675679525

Epoch: 6| Step: 12
Training loss: 2.405012845993042
Validation loss: 2.200969676176707

Epoch: 6| Step: 13
Training loss: 1.6772736310958862
Validation loss: 2.180089076360067

Epoch: 238| Step: 0
Training loss: 2.117553234100342
Validation loss: 2.167491912841797

Epoch: 6| Step: 1
Training loss: 1.6808669567108154
Validation loss: 2.1773403684298196

Epoch: 6| Step: 2
Training loss: 2.3691110610961914
Validation loss: 2.1702821254730225

Epoch: 6| Step: 3
Training loss: 1.6290264129638672
Validation loss: 2.1701069871584573

Epoch: 6| Step: 4
Training loss: 1.4878547191619873
Validation loss: 2.1610201398531594

Epoch: 6| Step: 5
Training loss: 1.811830759048462
Validation loss: 2.183651645978292

Epoch: 6| Step: 6
Training loss: 1.9345998764038086
Validation loss: 2.1887531677881875

Epoch: 6| Step: 7
Training loss: 2.0509121417999268
Validation loss: 2.1765475471814475

Epoch: 6| Step: 8
Training loss: 2.046420097351074
Validation loss: 2.1770771940549216

Epoch: 6| Step: 9
Training loss: 1.1248931884765625
Validation loss: 2.177319665749868

Epoch: 6| Step: 10
Training loss: 1.6481691598892212
Validation loss: 2.188491404056549

Epoch: 6| Step: 11
Training loss: 1.4773309230804443
Validation loss: 2.177043934663137

Epoch: 6| Step: 12
Training loss: 2.2534210681915283
Validation loss: 2.1761948267618814

Epoch: 6| Step: 13
Training loss: 1.0443135499954224
Validation loss: 2.1629958748817444

Epoch: 239| Step: 0
Training loss: 1.590025544166565
Validation loss: 2.179332176844279

Epoch: 6| Step: 1
Training loss: 1.7397654056549072
Validation loss: 2.1768383979797363

Epoch: 6| Step: 2
Training loss: 1.7729097604751587
Validation loss: 2.1593130826950073

Epoch: 6| Step: 3
Training loss: 2.156646966934204
Validation loss: 2.1611028909683228

Epoch: 6| Step: 4
Training loss: 1.9270648956298828
Validation loss: 2.160819927851359

Epoch: 6| Step: 5
Training loss: 1.1969960927963257
Validation loss: 2.159717639287313

Epoch: 6| Step: 6
Training loss: 2.132351875305176
Validation loss: 2.164852023124695

Epoch: 6| Step: 7
Training loss: 1.326894998550415
Validation loss: 2.1613102356592813

Epoch: 6| Step: 8
Training loss: 1.688256025314331
Validation loss: 2.1722792387008667

Epoch: 6| Step: 9
Training loss: 1.695925235748291
Validation loss: 2.1978878180185952

Epoch: 6| Step: 10
Training loss: 1.738544225692749
Validation loss: 2.1919814944267273

Epoch: 6| Step: 11
Training loss: 1.8738987445831299
Validation loss: 2.1912111043930054

Epoch: 6| Step: 12
Training loss: 2.461012840270996
Validation loss: 2.184777319431305

Epoch: 6| Step: 13
Training loss: 1.5465378761291504
Validation loss: 2.211114307244619

Epoch: 240| Step: 0
Training loss: 2.635352373123169
Validation loss: 2.2048223416010537

Epoch: 6| Step: 1
Training loss: 1.878780484199524
Validation loss: 2.21315735578537

Epoch: 6| Step: 2
Training loss: 1.8999401330947876
Validation loss: 2.180366039276123

Epoch: 6| Step: 3
Training loss: 1.5619946718215942
Validation loss: 2.1962566574414573

Epoch: 6| Step: 4
Training loss: 1.9532488584518433
Validation loss: 2.199161171913147

Epoch: 6| Step: 5
Training loss: 1.4680999517440796
Validation loss: 2.2062848806381226

Epoch: 6| Step: 6
Training loss: 2.698775291442871
Validation loss: 2.189755141735077

Epoch: 6| Step: 7
Training loss: 1.9851646423339844
Validation loss: 2.163320004940033

Epoch: 6| Step: 8
Training loss: 1.6832386255264282
Validation loss: 2.1739485263824463

Epoch: 6| Step: 9
Training loss: 1.799501895904541
Validation loss: 2.204532961050669

Epoch: 6| Step: 10
Training loss: 1.5111353397369385
Validation loss: 2.199292321999868

Epoch: 6| Step: 11
Training loss: 1.3101011514663696
Validation loss: 2.1775116324424744

Epoch: 6| Step: 12
Training loss: 0.869114875793457
Validation loss: 2.190623382727305

Epoch: 6| Step: 13
Training loss: 1.3074003458023071
Validation loss: 2.197884281476339

Epoch: 241| Step: 0
Training loss: 1.5656061172485352
Validation loss: 2.1800913413365683

Epoch: 6| Step: 1
Training loss: 1.5139882564544678
Validation loss: 2.179070214430491

Epoch: 6| Step: 2
Training loss: 1.9607417583465576
Validation loss: 2.2045497496922812

Epoch: 6| Step: 3
Training loss: 1.7043483257293701
Validation loss: 2.1891419291496277

Epoch: 6| Step: 4
Training loss: 1.6925568580627441
Validation loss: 2.1809671918551126

Epoch: 6| Step: 5
Training loss: 1.9586519002914429
Validation loss: 2.1999223232269287

Epoch: 6| Step: 6
Training loss: 1.7484846115112305
Validation loss: 2.2296999096870422

Epoch: 6| Step: 7
Training loss: 1.7573238611221313
Validation loss: 2.225055694580078

Epoch: 6| Step: 8
Training loss: 1.9798803329467773
Validation loss: 2.2219146688779197

Epoch: 6| Step: 9
Training loss: 2.3631844520568848
Validation loss: 2.2103524605433145

Epoch: 6| Step: 10
Training loss: 1.374387264251709
Validation loss: 2.183399021625519

Epoch: 6| Step: 11
Training loss: 1.2102961540222168
Validation loss: 2.2213447292645774

Epoch: 6| Step: 12
Training loss: 1.976247787475586
Validation loss: 2.194204886754354

Epoch: 6| Step: 13
Training loss: 1.4281495809555054
Validation loss: 2.1750749746958413

Epoch: 242| Step: 0
Training loss: 1.612807273864746
Validation loss: 2.21650501092275

Epoch: 6| Step: 1
Training loss: 1.3849090337753296
Validation loss: 2.2077961564064026

Epoch: 6| Step: 2
Training loss: 1.3552424907684326
Validation loss: 2.2099758982658386

Epoch: 6| Step: 3
Training loss: 1.9675030708312988
Validation loss: 2.2030737598737082

Epoch: 6| Step: 4
Training loss: 1.638094425201416
Validation loss: 2.2037134567896524

Epoch: 6| Step: 5
Training loss: 2.0544731616973877
Validation loss: 2.217154840628306

Epoch: 6| Step: 6
Training loss: 1.9070974588394165
Validation loss: 2.1836980183919272

Epoch: 6| Step: 7
Training loss: 1.0955922603607178
Validation loss: 2.1864549120267234

Epoch: 6| Step: 8
Training loss: 1.881359338760376
Validation loss: 2.196812709172567

Epoch: 6| Step: 9
Training loss: 1.5028021335601807
Validation loss: 2.1939828793207803

Epoch: 6| Step: 10
Training loss: 2.3106722831726074
Validation loss: 2.182773311932882

Epoch: 6| Step: 11
Training loss: 2.360215425491333
Validation loss: 2.1970191597938538

Epoch: 6| Step: 12
Training loss: 1.3628441095352173
Validation loss: 2.197411139806112

Epoch: 6| Step: 13
Training loss: 1.7289490699768066
Validation loss: 2.2112253506978354

Epoch: 243| Step: 0
Training loss: 1.3992655277252197
Validation loss: 2.236468195915222

Epoch: 6| Step: 1
Training loss: 1.9693326950073242
Validation loss: 2.2228174209594727

Epoch: 6| Step: 2
Training loss: 1.622333288192749
Validation loss: 2.1957747538884482

Epoch: 6| Step: 3
Training loss: 1.5697318315505981
Validation loss: 2.1781156857808432

Epoch: 6| Step: 4
Training loss: 1.7198365926742554
Validation loss: 2.1881980101267495

Epoch: 6| Step: 5
Training loss: 2.228961229324341
Validation loss: 2.186885972817739

Epoch: 6| Step: 6
Training loss: 2.1657588481903076
Validation loss: 2.1814005970954895

Epoch: 6| Step: 7
Training loss: 2.2857861518859863
Validation loss: 2.1982866525650024

Epoch: 6| Step: 8
Training loss: 1.3388912677764893
Validation loss: 2.2219506899515786

Epoch: 6| Step: 9
Training loss: 1.3611524105072021
Validation loss: 2.213269035021464

Epoch: 6| Step: 10
Training loss: 2.451355218887329
Validation loss: 2.2275891304016113

Epoch: 6| Step: 11
Training loss: 1.3142192363739014
Validation loss: 2.2130215565363565

Epoch: 6| Step: 12
Training loss: 1.4351669549942017
Validation loss: 2.210114041964213

Epoch: 6| Step: 13
Training loss: 1.3497188091278076
Validation loss: 2.1961774031321206

Epoch: 244| Step: 0
Training loss: 2.098536968231201
Validation loss: 2.1859734654426575

Epoch: 6| Step: 1
Training loss: 2.04465913772583
Validation loss: 2.1927992701530457

Epoch: 6| Step: 2
Training loss: 1.7713524103164673
Validation loss: 2.1896586219469705

Epoch: 6| Step: 3
Training loss: 1.5954337120056152
Validation loss: 2.2076677282651267

Epoch: 6| Step: 4
Training loss: 1.5566749572753906
Validation loss: 2.2180530230204263

Epoch: 6| Step: 5
Training loss: 1.2980201244354248
Validation loss: 2.201103409131368

Epoch: 6| Step: 6
Training loss: 1.7514441013336182
Validation loss: 2.2013634045918784

Epoch: 6| Step: 7
Training loss: 1.9319567680358887
Validation loss: 2.2153496742248535

Epoch: 6| Step: 8
Training loss: 1.1391782760620117
Validation loss: 2.2196156779925027

Epoch: 6| Step: 9
Training loss: 1.595691204071045
Validation loss: 2.2172091205914817

Epoch: 6| Step: 10
Training loss: 1.443953275680542
Validation loss: 2.1807765563329062

Epoch: 6| Step: 11
Training loss: 1.6500723361968994
Validation loss: 2.198117653528849

Epoch: 6| Step: 12
Training loss: 1.8715962171554565
Validation loss: 2.2039034763971963

Epoch: 6| Step: 13
Training loss: 2.5303962230682373
Validation loss: 2.1792200406392417

Epoch: 245| Step: 0
Training loss: 1.2024509906768799
Validation loss: 2.2023311257362366

Epoch: 6| Step: 1
Training loss: 1.4610023498535156
Validation loss: 2.181981643040975

Epoch: 6| Step: 2
Training loss: 1.3092732429504395
Validation loss: 2.178818623224894

Epoch: 6| Step: 3
Training loss: 2.5419435501098633
Validation loss: 2.168264945348104

Epoch: 6| Step: 4
Training loss: 1.7665636539459229
Validation loss: 2.1708169976870217

Epoch: 6| Step: 5
Training loss: 2.124238967895508
Validation loss: 2.1875193119049072

Epoch: 6| Step: 6
Training loss: 1.4413864612579346
Validation loss: 2.1641697883605957

Epoch: 6| Step: 7
Training loss: 1.437930703163147
Validation loss: 2.178626239299774

Epoch: 6| Step: 8
Training loss: 1.7751165628433228
Validation loss: 2.2060754100481668

Epoch: 6| Step: 9
Training loss: 2.055323600769043
Validation loss: 2.168100635210673

Epoch: 6| Step: 10
Training loss: 2.0507354736328125
Validation loss: 2.172836939493815

Epoch: 6| Step: 11
Training loss: 1.81589937210083
Validation loss: 2.1709157625834146

Epoch: 6| Step: 12
Training loss: 1.6075937747955322
Validation loss: 2.171004335085551

Epoch: 6| Step: 13
Training loss: 1.6301931142807007
Validation loss: 2.1742297410964966

Epoch: 246| Step: 0
Training loss: 1.5111944675445557
Validation loss: 2.160915275414785

Epoch: 6| Step: 1
Training loss: 1.875236988067627
Validation loss: 2.169300595919291

Epoch: 6| Step: 2
Training loss: 1.6704033613204956
Validation loss: 2.167650898297628

Epoch: 6| Step: 3
Training loss: 1.2075178623199463
Validation loss: 2.161818027496338

Epoch: 6| Step: 4
Training loss: 1.7119425535202026
Validation loss: 2.181432286898295

Epoch: 6| Step: 5
Training loss: 1.925983190536499
Validation loss: 2.1886552770932517

Epoch: 6| Step: 6
Training loss: 1.2843167781829834
Validation loss: 2.1700891852378845

Epoch: 6| Step: 7
Training loss: 1.5298397541046143
Validation loss: 2.2139936089515686

Epoch: 6| Step: 8
Training loss: 1.5423043966293335
Validation loss: 2.1803752779960632

Epoch: 6| Step: 9
Training loss: 2.3241395950317383
Validation loss: 2.1918519139289856

Epoch: 6| Step: 10
Training loss: 2.082855701446533
Validation loss: 2.1925442218780518

Epoch: 6| Step: 11
Training loss: 1.593998670578003
Validation loss: 2.1963483492533364

Epoch: 6| Step: 12
Training loss: 2.0132508277893066
Validation loss: 2.1772210001945496

Epoch: 6| Step: 13
Training loss: 2.0031075477600098
Validation loss: 2.221580723921458

Epoch: 247| Step: 0
Training loss: 1.816089153289795
Validation loss: 2.178683042526245

Epoch: 6| Step: 1
Training loss: 1.9009253978729248
Validation loss: 2.190173010031382

Epoch: 6| Step: 2
Training loss: 1.8849067687988281
Validation loss: 2.177536209424337

Epoch: 6| Step: 3
Training loss: 1.4751965999603271
Validation loss: 2.1732069651285806

Epoch: 6| Step: 4
Training loss: 1.4835186004638672
Validation loss: 2.1950090527534485

Epoch: 6| Step: 5
Training loss: 1.7494232654571533
Validation loss: 2.1996827721595764

Epoch: 6| Step: 6
Training loss: 1.0852952003479004
Validation loss: 2.195164382457733

Epoch: 6| Step: 7
Training loss: 1.7962650060653687
Validation loss: 2.1783785025278726

Epoch: 6| Step: 8
Training loss: 1.6655638217926025
Validation loss: 2.191467503706614

Epoch: 6| Step: 9
Training loss: 1.7585740089416504
Validation loss: 2.1680442690849304

Epoch: 6| Step: 10
Training loss: 1.7549444437026978
Validation loss: 2.173472066720327

Epoch: 6| Step: 11
Training loss: 1.8336238861083984
Validation loss: 2.180401841799418

Epoch: 6| Step: 12
Training loss: 1.7804715633392334
Validation loss: 2.1842679182688394

Epoch: 6| Step: 13
Training loss: 1.867004156112671
Validation loss: 2.1541913549105325

Epoch: 248| Step: 0
Training loss: 1.1782485246658325
Validation loss: 2.1619639794031777

Epoch: 6| Step: 1
Training loss: 1.9588725566864014
Validation loss: 2.1810875137646994

Epoch: 6| Step: 2
Training loss: 1.6547868251800537
Validation loss: 2.182985703150431

Epoch: 6| Step: 3
Training loss: 1.4880727529525757
Validation loss: 2.183286945025126

Epoch: 6| Step: 4
Training loss: 1.5460946559906006
Validation loss: 2.172532637914022

Epoch: 6| Step: 5
Training loss: 1.824190616607666
Validation loss: 2.202302634716034

Epoch: 6| Step: 6
Training loss: 1.8839128017425537
Validation loss: 2.199079950650533

Epoch: 6| Step: 7
Training loss: 1.6970622539520264
Validation loss: 2.2102676828702292

Epoch: 6| Step: 8
Training loss: 1.4850534200668335
Validation loss: 2.1943865617116294

Epoch: 6| Step: 9
Training loss: 2.281541109085083
Validation loss: 2.2185787359873452

Epoch: 6| Step: 10
Training loss: 2.039470672607422
Validation loss: 2.2191369930903115

Epoch: 6| Step: 11
Training loss: 1.7260137796401978
Validation loss: 2.197993357976278

Epoch: 6| Step: 12
Training loss: 1.7504111528396606
Validation loss: 2.200352370738983

Epoch: 6| Step: 13
Training loss: 1.805306315422058
Validation loss: 2.183700442314148

Epoch: 249| Step: 0
Training loss: 1.6442142724990845
Validation loss: 2.1993812123934426

Epoch: 6| Step: 1
Training loss: 1.4852396249771118
Validation loss: 2.1982752680778503

Epoch: 6| Step: 2
Training loss: 1.6780197620391846
Validation loss: 2.191626032193502

Epoch: 6| Step: 3
Training loss: 1.5694360733032227
Validation loss: 2.2012535532315574

Epoch: 6| Step: 4
Training loss: 1.6326324939727783
Validation loss: 2.2020315726598105

Epoch: 6| Step: 5
Training loss: 1.747031569480896
Validation loss: 2.207412580649058

Epoch: 6| Step: 6
Training loss: 1.9357303380966187
Validation loss: 2.1529478828112283

Epoch: 6| Step: 7
Training loss: 1.9980143308639526
Validation loss: 2.1950074632962546

Epoch: 6| Step: 8
Training loss: 1.6523456573486328
Validation loss: 2.1949007908503213

Epoch: 6| Step: 9
Training loss: 2.793416976928711
Validation loss: 2.1780385176340737

Epoch: 6| Step: 10
Training loss: 1.9850932359695435
Validation loss: 2.1702975829442344

Epoch: 6| Step: 11
Training loss: 1.957686424255371
Validation loss: 2.1956520477930703

Epoch: 6| Step: 12
Training loss: 1.2912999391555786
Validation loss: 2.175145387649536

Epoch: 6| Step: 13
Training loss: 0.9814683198928833
Validation loss: 2.1926160057385764

Epoch: 250| Step: 0
Training loss: 1.062212347984314
Validation loss: 2.167263090610504

Epoch: 6| Step: 1
Training loss: 1.8422226905822754
Validation loss: 2.1731907526652017

Epoch: 6| Step: 2
Training loss: 1.6298675537109375
Validation loss: 2.190839866797129

Epoch: 6| Step: 3
Training loss: 1.5970864295959473
Validation loss: 2.141757388909658

Epoch: 6| Step: 4
Training loss: 1.7782577276229858
Validation loss: 2.1480477253595986

Epoch: 6| Step: 5
Training loss: 1.148177146911621
Validation loss: 2.1533939242362976

Epoch: 6| Step: 6
Training loss: 1.2662594318389893
Validation loss: 2.1606486241022744

Epoch: 6| Step: 7
Training loss: 1.59294593334198
Validation loss: 2.131197214126587

Epoch: 6| Step: 8
Training loss: 1.50070321559906
Validation loss: 2.1503798166910806

Epoch: 6| Step: 9
Training loss: 1.7327098846435547
Validation loss: 2.158480087916056

Epoch: 6| Step: 10
Training loss: 1.6123876571655273
Validation loss: 2.1813080310821533

Epoch: 6| Step: 11
Training loss: 2.434753894805908
Validation loss: 2.162375330924988

Epoch: 6| Step: 12
Training loss: 2.6084749698638916
Validation loss: 2.1528674562772117

Epoch: 6| Step: 13
Training loss: 2.291329860687256
Validation loss: 2.148254374663035

Epoch: 251| Step: 0
Training loss: 1.6226117610931396
Validation loss: 2.1564499735832214

Epoch: 6| Step: 1
Training loss: 1.3872699737548828
Validation loss: 2.154643177986145

Epoch: 6| Step: 2
Training loss: 1.6429436206817627
Validation loss: 2.153296947479248

Epoch: 6| Step: 3
Training loss: 2.536818504333496
Validation loss: 2.17162017027537

Epoch: 6| Step: 4
Training loss: 2.8584959506988525
Validation loss: 2.168971081574758

Epoch: 6| Step: 5
Training loss: 1.282619833946228
Validation loss: 2.1964415113131204

Epoch: 6| Step: 6
Training loss: 1.6840146780014038
Validation loss: 2.2019667824109397

Epoch: 6| Step: 7
Training loss: 1.8421889543533325
Validation loss: 2.1933469772338867

Epoch: 6| Step: 8
Training loss: 1.262711763381958
Validation loss: 2.2186221281687417

Epoch: 6| Step: 9
Training loss: 1.3027676343917847
Validation loss: 2.208843946456909

Epoch: 6| Step: 10
Training loss: 1.543419361114502
Validation loss: 2.2350316445032754

Epoch: 6| Step: 11
Training loss: 1.6229872703552246
Validation loss: 2.23684153954188

Epoch: 6| Step: 12
Training loss: 1.2452647686004639
Validation loss: 2.2430529594421387

Epoch: 6| Step: 13
Training loss: 2.0197019577026367
Validation loss: 2.247421622276306

Epoch: 252| Step: 0
Training loss: 1.877000093460083
Validation loss: 2.2393908301989236

Epoch: 6| Step: 1
Training loss: 1.2958779335021973
Validation loss: 2.2100775241851807

Epoch: 6| Step: 2
Training loss: 1.2420079708099365
Validation loss: 2.1997881531715393

Epoch: 6| Step: 3
Training loss: 1.422634243965149
Validation loss: 2.201248129208883

Epoch: 6| Step: 4
Training loss: 1.4647884368896484
Validation loss: 2.208933095137278

Epoch: 6| Step: 5
Training loss: 1.7444578409194946
Validation loss: 2.2047780752182007

Epoch: 6| Step: 6
Training loss: 2.0484519004821777
Validation loss: 2.220937669277191

Epoch: 6| Step: 7
Training loss: 1.4470129013061523
Validation loss: 2.1972808639208474

Epoch: 6| Step: 8
Training loss: 1.9702013731002808
Validation loss: 2.223264972368876

Epoch: 6| Step: 9
Training loss: 1.4505884647369385
Validation loss: 2.1860703229904175

Epoch: 6| Step: 10
Training loss: 1.7325814962387085
Validation loss: 2.1656190355618796

Epoch: 6| Step: 11
Training loss: 1.5071780681610107
Validation loss: 2.2047455310821533

Epoch: 6| Step: 12
Training loss: 2.0614607334136963
Validation loss: 2.1948710680007935

Epoch: 6| Step: 13
Training loss: 2.36977481842041
Validation loss: 2.182222763697306

Epoch: 253| Step: 0
Training loss: 1.988059163093567
Validation loss: 2.173293093840281

Epoch: 6| Step: 1
Training loss: 2.106635570526123
Validation loss: 2.1854225198427835

Epoch: 6| Step: 2
Training loss: 0.8597338199615479
Validation loss: 2.16665252049764

Epoch: 6| Step: 3
Training loss: 1.9229230880737305
Validation loss: 2.179220736026764

Epoch: 6| Step: 4
Training loss: 1.5980949401855469
Validation loss: 2.167767504851023

Epoch: 6| Step: 5
Training loss: 1.777499794960022
Validation loss: 2.1840925812721252

Epoch: 6| Step: 6
Training loss: 1.5127874612808228
Validation loss: 2.1676146189371743

Epoch: 6| Step: 7
Training loss: 1.5226551294326782
Validation loss: 2.181208908557892

Epoch: 6| Step: 8
Training loss: 1.7069023847579956
Validation loss: 2.176024317741394

Epoch: 6| Step: 9
Training loss: 2.251624584197998
Validation loss: 2.175769646962484

Epoch: 6| Step: 10
Training loss: 2.0199594497680664
Validation loss: 2.1744913856188455

Epoch: 6| Step: 11
Training loss: 1.9047753810882568
Validation loss: 2.2017542322476706

Epoch: 6| Step: 12
Training loss: 1.4694164991378784
Validation loss: 2.177279452482859

Epoch: 6| Step: 13
Training loss: 1.4295614957809448
Validation loss: 2.1957814693450928

Epoch: 254| Step: 0
Training loss: 1.077803134918213
Validation loss: 2.2274757822354636

Epoch: 6| Step: 1
Training loss: 0.9902766346931458
Validation loss: 2.220838785171509

Epoch: 6| Step: 2
Training loss: 1.834407091140747
Validation loss: 2.209405561288198

Epoch: 6| Step: 3
Training loss: 1.0552765130996704
Validation loss: 2.2027282317479453

Epoch: 6| Step: 4
Training loss: 1.4806729555130005
Validation loss: 2.1880882183710733

Epoch: 6| Step: 5
Training loss: 2.229839324951172
Validation loss: 2.191373666127523

Epoch: 6| Step: 6
Training loss: 1.3075191974639893
Validation loss: 2.1834912300109863

Epoch: 6| Step: 7
Training loss: 1.4087501764297485
Validation loss: 2.160383184750875

Epoch: 6| Step: 8
Training loss: 1.2098933458328247
Validation loss: 2.1906241178512573

Epoch: 6| Step: 9
Training loss: 2.276693105697632
Validation loss: 2.149050017197927

Epoch: 6| Step: 10
Training loss: 1.8409067392349243
Validation loss: 2.1484201351801553

Epoch: 6| Step: 11
Training loss: 2.2494189739227295
Validation loss: 2.1173660357793174

Epoch: 6| Step: 12
Training loss: 3.196165084838867
Validation loss: 2.128747363885244

Epoch: 6| Step: 13
Training loss: 2.2664177417755127
Validation loss: 2.1313132842381797

Epoch: 255| Step: 0
Training loss: 1.7825095653533936
Validation loss: 2.125749488671621

Epoch: 6| Step: 1
Training loss: 1.8503153324127197
Validation loss: 2.1135058204332986

Epoch: 6| Step: 2
Training loss: 1.9877252578735352
Validation loss: 2.1392134626706443

Epoch: 6| Step: 3
Training loss: 1.6965523958206177
Validation loss: 2.13669220606486

Epoch: 6| Step: 4
Training loss: 2.5054264068603516
Validation loss: 2.1226011514663696

Epoch: 6| Step: 5
Training loss: 1.9539806842803955
Validation loss: 2.1402947902679443

Epoch: 6| Step: 6
Training loss: 1.6528449058532715
Validation loss: 2.1397430896759033

Epoch: 6| Step: 7
Training loss: 1.9430328607559204
Validation loss: 2.1294919848442078

Epoch: 6| Step: 8
Training loss: 1.3408820629119873
Validation loss: 2.1576062440872192

Epoch: 6| Step: 9
Training loss: 2.105347156524658
Validation loss: 2.1764688889185586

Epoch: 6| Step: 10
Training loss: 1.1825931072235107
Validation loss: 2.189858615398407

Epoch: 6| Step: 11
Training loss: 1.4294012784957886
Validation loss: 2.1979560057322183

Epoch: 6| Step: 12
Training loss: 1.7031184434890747
Validation loss: 2.162917117277781

Epoch: 6| Step: 13
Training loss: 1.332209587097168
Validation loss: 2.161784052848816

Epoch: 256| Step: 0
Training loss: 1.446886658668518
Validation loss: 2.1401073932647705

Epoch: 6| Step: 1
Training loss: 1.4318492412567139
Validation loss: 2.1480589310328164

Epoch: 6| Step: 2
Training loss: 2.2058212757110596
Validation loss: 2.1562993129094443

Epoch: 6| Step: 3
Training loss: 1.496664047241211
Validation loss: 2.1484334071477256

Epoch: 6| Step: 4
Training loss: 2.4671404361724854
Validation loss: 2.145787994066874

Epoch: 6| Step: 5
Training loss: 1.7980093955993652
Validation loss: 2.1604068676630654

Epoch: 6| Step: 6
Training loss: 2.0365326404571533
Validation loss: 2.1604875127474465

Epoch: 6| Step: 7
Training loss: 1.6505887508392334
Validation loss: 2.159800390402476

Epoch: 6| Step: 8
Training loss: 1.565967321395874
Validation loss: 2.1887980302174888

Epoch: 6| Step: 9
Training loss: 2.2039875984191895
Validation loss: 2.18707005182902

Epoch: 6| Step: 10
Training loss: 2.2168445587158203
Validation loss: 2.222750266393026

Epoch: 6| Step: 11
Training loss: 1.5118472576141357
Validation loss: 2.239769240220388

Epoch: 6| Step: 12
Training loss: 1.8238223791122437
Validation loss: 2.2613503138224282

Epoch: 6| Step: 13
Training loss: 0.9030408263206482
Validation loss: 2.2684996326764426

Epoch: 257| Step: 0
Training loss: 1.9729328155517578
Validation loss: 2.2387272119522095

Epoch: 6| Step: 1
Training loss: 2.3163392543792725
Validation loss: 2.223693013191223

Epoch: 6| Step: 2
Training loss: 1.3522586822509766
Validation loss: 2.225703159968058

Epoch: 6| Step: 3
Training loss: 1.3697328567504883
Validation loss: 2.2050272623697915

Epoch: 6| Step: 4
Training loss: 2.448416233062744
Validation loss: 2.212816913922628

Epoch: 6| Step: 5
Training loss: 1.622639775276184
Validation loss: 2.202510495980581

Epoch: 6| Step: 6
Training loss: 1.5656006336212158
Validation loss: 2.171879152456919

Epoch: 6| Step: 7
Training loss: 1.3937311172485352
Validation loss: 2.1768642465273538

Epoch: 6| Step: 8
Training loss: 1.2562812566757202
Validation loss: 2.1571640968322754

Epoch: 6| Step: 9
Training loss: 1.7110412120819092
Validation loss: 2.1778343319892883

Epoch: 6| Step: 10
Training loss: 2.205775737762451
Validation loss: 2.219020128250122

Epoch: 6| Step: 11
Training loss: 1.4244651794433594
Validation loss: 2.211065332094828

Epoch: 6| Step: 12
Training loss: 1.8727672100067139
Validation loss: 2.2023024956385293

Epoch: 6| Step: 13
Training loss: 1.5117578506469727
Validation loss: 2.199179152647654

Epoch: 258| Step: 0
Training loss: 1.661157250404358
Validation loss: 2.1957019170125327

Epoch: 6| Step: 1
Training loss: 1.213598370552063
Validation loss: 2.202295502026876

Epoch: 6| Step: 2
Training loss: 1.2399866580963135
Validation loss: 2.198426604270935

Epoch: 6| Step: 3
Training loss: 2.215862274169922
Validation loss: 2.173299233118693

Epoch: 6| Step: 4
Training loss: 1.6222389936447144
Validation loss: 2.177231232325236

Epoch: 6| Step: 5
Training loss: 1.8939173221588135
Validation loss: 2.1858137051264444

Epoch: 6| Step: 6
Training loss: 1.9553977251052856
Validation loss: 2.184355676174164

Epoch: 6| Step: 7
Training loss: 2.1014719009399414
Validation loss: 2.179226795832316

Epoch: 6| Step: 8
Training loss: 1.3774116039276123
Validation loss: 2.211639722188314

Epoch: 6| Step: 9
Training loss: 2.132204532623291
Validation loss: 2.220353086789449

Epoch: 6| Step: 10
Training loss: 1.842976689338684
Validation loss: 2.2232142090797424

Epoch: 6| Step: 11
Training loss: 2.0590555667877197
Validation loss: 2.178528070449829

Epoch: 6| Step: 12
Training loss: 1.3762776851654053
Validation loss: 2.221607287724813

Epoch: 6| Step: 13
Training loss: 0.9244998693466187
Validation loss: 2.204060713450114

Epoch: 259| Step: 0
Training loss: 1.8511688709259033
Validation loss: 2.1760124365488687

Epoch: 6| Step: 1
Training loss: 1.4677324295043945
Validation loss: 2.1608731349309287

Epoch: 6| Step: 2
Training loss: 1.7473310232162476
Validation loss: 2.1672940651575723

Epoch: 6| Step: 3
Training loss: 1.3532471656799316
Validation loss: 2.1735652486483255

Epoch: 6| Step: 4
Training loss: 1.496598482131958
Validation loss: 2.1543299357096353

Epoch: 6| Step: 5
Training loss: 1.1057342290878296
Validation loss: 2.196301897366842

Epoch: 6| Step: 6
Training loss: 1.5810946226119995
Validation loss: 2.1805633306503296

Epoch: 6| Step: 7
Training loss: 1.5063092708587646
Validation loss: 2.2084932724634805

Epoch: 6| Step: 8
Training loss: 1.656778335571289
Validation loss: 2.2091585795084634

Epoch: 6| Step: 9
Training loss: 1.667168140411377
Validation loss: 2.209394415219625

Epoch: 6| Step: 10
Training loss: 2.5256118774414062
Validation loss: 2.183792213598887

Epoch: 6| Step: 11
Training loss: 1.975490689277649
Validation loss: 2.209785262743632

Epoch: 6| Step: 12
Training loss: 1.5207127332687378
Validation loss: 2.191086729367574

Epoch: 6| Step: 13
Training loss: 1.9438191652297974
Validation loss: 2.2040047446886697

Epoch: 260| Step: 0
Training loss: 2.281989336013794
Validation loss: 2.200368563334147

Epoch: 6| Step: 1
Training loss: 1.376431941986084
Validation loss: 2.190699577331543

Epoch: 6| Step: 2
Training loss: 1.5258021354675293
Validation loss: 2.208985368410746

Epoch: 6| Step: 3
Training loss: 1.621744990348816
Validation loss: 2.188069502512614

Epoch: 6| Step: 4
Training loss: 1.9769573211669922
Validation loss: 2.191664695739746

Epoch: 6| Step: 5
Training loss: 1.4585239887237549
Validation loss: 2.1741680105527244

Epoch: 6| Step: 6
Training loss: 1.1813759803771973
Validation loss: 2.2074316342671714

Epoch: 6| Step: 7
Training loss: 1.8667171001434326
Validation loss: 2.2144698103268943

Epoch: 6| Step: 8
Training loss: 2.040925979614258
Validation loss: 2.191581209500631

Epoch: 6| Step: 9
Training loss: 1.8514254093170166
Validation loss: 2.191280166308085

Epoch: 6| Step: 10
Training loss: 0.7359417676925659
Validation loss: 2.2093065778414407

Epoch: 6| Step: 11
Training loss: 2.1676487922668457
Validation loss: 2.189501861731211

Epoch: 6| Step: 12
Training loss: 1.5173455476760864
Validation loss: 2.214184025923411

Epoch: 6| Step: 13
Training loss: 1.1728928089141846
Validation loss: 2.2037447094917297

Epoch: 261| Step: 0
Training loss: 2.0868754386901855
Validation loss: 2.180327554543813

Epoch: 6| Step: 1
Training loss: 1.8588190078735352
Validation loss: 2.2422410448392234

Epoch: 6| Step: 2
Training loss: 1.936587929725647
Validation loss: 2.19343900680542

Epoch: 6| Step: 3
Training loss: 1.4855303764343262
Validation loss: 2.200235605239868

Epoch: 6| Step: 4
Training loss: 1.6581127643585205
Validation loss: 2.207278927167257

Epoch: 6| Step: 5
Training loss: 1.3317384719848633
Validation loss: 2.2007108132044473

Epoch: 6| Step: 6
Training loss: 1.62380051612854
Validation loss: 2.1761447985967

Epoch: 6| Step: 7
Training loss: 1.7244402170181274
Validation loss: 2.17572820186615

Epoch: 6| Step: 8
Training loss: 1.4323079586029053
Validation loss: 2.172847847143809

Epoch: 6| Step: 9
Training loss: 1.7304890155792236
Validation loss: 2.154937426249186

Epoch: 6| Step: 10
Training loss: 1.4672006368637085
Validation loss: 2.128438889980316

Epoch: 6| Step: 11
Training loss: 1.4885804653167725
Validation loss: 2.139562507470449

Epoch: 6| Step: 12
Training loss: 2.686415910720825
Validation loss: 2.132701575756073

Epoch: 6| Step: 13
Training loss: 1.4433598518371582
Validation loss: 2.1476126313209534

Epoch: 262| Step: 0
Training loss: 2.20889949798584
Validation loss: 2.1506193478902182

Epoch: 6| Step: 1
Training loss: 2.28682804107666
Validation loss: 2.140360713005066

Epoch: 6| Step: 2
Training loss: 2.081167459487915
Validation loss: 2.1315402388572693

Epoch: 6| Step: 3
Training loss: 1.337012767791748
Validation loss: 2.143400172392527

Epoch: 6| Step: 4
Training loss: 1.5465952157974243
Validation loss: 2.1512427926063538

Epoch: 6| Step: 5
Training loss: 1.3707283735275269
Validation loss: 2.169008255004883

Epoch: 6| Step: 6
Training loss: 1.9041917324066162
Validation loss: 2.2001994848251343

Epoch: 6| Step: 7
Training loss: 1.9028282165527344
Validation loss: 2.1920350392659507

Epoch: 6| Step: 8
Training loss: 1.616269826889038
Validation loss: 2.1997174421946206

Epoch: 6| Step: 9
Training loss: 1.9596092700958252
Validation loss: 2.1995708346366882

Epoch: 6| Step: 10
Training loss: 1.8374874591827393
Validation loss: 2.202364464600881

Epoch: 6| Step: 11
Training loss: 1.5535839796066284
Validation loss: 2.214813232421875

Epoch: 6| Step: 12
Training loss: 1.496478796005249
Validation loss: 2.201999008655548

Epoch: 6| Step: 13
Training loss: 1.332756519317627
Validation loss: 2.204929848512014

Epoch: 263| Step: 0
Training loss: 1.974510669708252
Validation loss: 2.207604686419169

Epoch: 6| Step: 1
Training loss: 1.5838209390640259
Validation loss: 2.2123093605041504

Epoch: 6| Step: 2
Training loss: 1.6109596490859985
Validation loss: 2.2069260279337564

Epoch: 6| Step: 3
Training loss: 1.8847334384918213
Validation loss: 2.2009438276290894

Epoch: 6| Step: 4
Training loss: 1.9080736637115479
Validation loss: 2.1858885089556375

Epoch: 6| Step: 5
Training loss: 1.4182382822036743
Validation loss: 2.1693668564160666

Epoch: 6| Step: 6
Training loss: 2.3651950359344482
Validation loss: 2.1648606061935425

Epoch: 6| Step: 7
Training loss: 1.116325855255127
Validation loss: 2.1616946856180825

Epoch: 6| Step: 8
Training loss: 2.175917387008667
Validation loss: 2.1969065070152283

Epoch: 6| Step: 9
Training loss: 1.1235287189483643
Validation loss: 2.165619730949402

Epoch: 6| Step: 10
Training loss: 1.5276318788528442
Validation loss: 2.172628124554952

Epoch: 6| Step: 11
Training loss: 1.626542091369629
Validation loss: 2.1468754212061563

Epoch: 6| Step: 12
Training loss: 1.8975367546081543
Validation loss: 2.1561603943506875

Epoch: 6| Step: 13
Training loss: 1.5602964162826538
Validation loss: 2.1449790000915527

Epoch: 264| Step: 0
Training loss: 1.9366248846054077
Validation loss: 2.163661619027456

Epoch: 6| Step: 1
Training loss: 0.8067190647125244
Validation loss: 2.139449735482534

Epoch: 6| Step: 2
Training loss: 1.4291269779205322
Validation loss: 2.179179588953654

Epoch: 6| Step: 3
Training loss: 2.213148832321167
Validation loss: 2.200778325398763

Epoch: 6| Step: 4
Training loss: 1.784630537033081
Validation loss: 2.2067142327626548

Epoch: 6| Step: 5
Training loss: 1.8006829023361206
Validation loss: 2.206936160723368

Epoch: 6| Step: 6
Training loss: 2.0958690643310547
Validation loss: 2.224685490131378

Epoch: 6| Step: 7
Training loss: 1.420448660850525
Validation loss: 2.2175419330596924

Epoch: 6| Step: 8
Training loss: 2.3155159950256348
Validation loss: 2.188623030980428

Epoch: 6| Step: 9
Training loss: 1.3805742263793945
Validation loss: 2.201874574025472

Epoch: 6| Step: 10
Training loss: 1.1361362934112549
Validation loss: 2.2167670726776123

Epoch: 6| Step: 11
Training loss: 2.1055586338043213
Validation loss: 2.1824806531270347

Epoch: 6| Step: 12
Training loss: 1.1864981651306152
Validation loss: 2.153748114903768

Epoch: 6| Step: 13
Training loss: 2.1045191287994385
Validation loss: 2.1807599862416587

Epoch: 265| Step: 0
Training loss: 1.1448616981506348
Validation loss: 2.187002698580424

Epoch: 6| Step: 1
Training loss: 2.214597702026367
Validation loss: 2.1889894008636475

Epoch: 6| Step: 2
Training loss: 2.0190351009368896
Validation loss: 2.1918089588483176

Epoch: 6| Step: 3
Training loss: 1.400420904159546
Validation loss: 2.144886016845703

Epoch: 6| Step: 4
Training loss: 1.1779248714447021
Validation loss: 2.196698526541392

Epoch: 6| Step: 5
Training loss: 1.2890441417694092
Validation loss: 2.1954092582066855

Epoch: 6| Step: 6
Training loss: 1.354409098625183
Validation loss: 2.1718870600064597

Epoch: 6| Step: 7
Training loss: 1.8963083028793335
Validation loss: 2.2218233148256936

Epoch: 6| Step: 8
Training loss: 2.0417661666870117
Validation loss: 2.2043356895446777

Epoch: 6| Step: 9
Training loss: 1.3371453285217285
Validation loss: 2.2096338669459024

Epoch: 6| Step: 10
Training loss: 2.1516895294189453
Validation loss: 2.1907334327697754

Epoch: 6| Step: 11
Training loss: 1.5571832656860352
Validation loss: 2.177082359790802

Epoch: 6| Step: 12
Training loss: 1.3500871658325195
Validation loss: 2.1474085648854575

Epoch: 6| Step: 13
Training loss: 2.6957287788391113
Validation loss: 2.143610159556071

Epoch: 266| Step: 0
Training loss: 1.1991132497787476
Validation loss: 2.1601312160491943

Epoch: 6| Step: 1
Training loss: 1.7495471239089966
Validation loss: 2.154934366544088

Epoch: 6| Step: 2
Training loss: 2.026566743850708
Validation loss: 2.1625598867734275

Epoch: 6| Step: 3
Training loss: 1.9993280172348022
Validation loss: 2.176654100418091

Epoch: 6| Step: 4
Training loss: 1.7883461713790894
Validation loss: 2.1755789319674173

Epoch: 6| Step: 5
Training loss: 2.1343202590942383
Validation loss: 2.1876753171284995

Epoch: 6| Step: 6
Training loss: 2.0497970581054688
Validation loss: 2.1949934363365173

Epoch: 6| Step: 7
Training loss: 1.4755685329437256
Validation loss: 2.219281713167826

Epoch: 6| Step: 8
Training loss: 1.3164130449295044
Validation loss: 2.2476742267608643

Epoch: 6| Step: 9
Training loss: 1.5109882354736328
Validation loss: 2.223448077837626

Epoch: 6| Step: 10
Training loss: 1.6222540140151978
Validation loss: 2.198324203491211

Epoch: 6| Step: 11
Training loss: 1.6849825382232666
Validation loss: 2.1841209332148233

Epoch: 6| Step: 12
Training loss: 1.2616840600967407
Validation loss: 2.1886372168858848

Epoch: 6| Step: 13
Training loss: 1.710554599761963
Validation loss: 2.1703612407048545

Epoch: 267| Step: 0
Training loss: 1.7261528968811035
Validation loss: 2.171550909678141

Epoch: 6| Step: 1
Training loss: 1.794927716255188
Validation loss: 2.1753395994504294

Epoch: 6| Step: 2
Training loss: 1.2136578559875488
Validation loss: 2.1767741243044534

Epoch: 6| Step: 3
Training loss: 1.4209489822387695
Validation loss: 2.182611803213755

Epoch: 6| Step: 4
Training loss: 2.1052441596984863
Validation loss: 2.166972359021505

Epoch: 6| Step: 5
Training loss: 1.9945878982543945
Validation loss: 2.1657280127207437

Epoch: 6| Step: 6
Training loss: 1.871651530265808
Validation loss: 2.156135857105255

Epoch: 6| Step: 7
Training loss: 1.3978722095489502
Validation loss: 2.202510197957357

Epoch: 6| Step: 8
Training loss: 1.4168701171875
Validation loss: 2.1891427040100098

Epoch: 6| Step: 9
Training loss: 1.3838422298431396
Validation loss: 2.1782488425572715

Epoch: 6| Step: 10
Training loss: 2.4556825160980225
Validation loss: 2.211149593194326

Epoch: 6| Step: 11
Training loss: 0.9905768632888794
Validation loss: 2.2382613023122153

Epoch: 6| Step: 12
Training loss: 1.7574087381362915
Validation loss: 2.28559140364329

Epoch: 6| Step: 13
Training loss: 2.3861985206604004
Validation loss: 2.2365061044692993

Epoch: 268| Step: 0
Training loss: 2.0324363708496094
Validation loss: 2.234290361404419

Epoch: 6| Step: 1
Training loss: 1.8458104133605957
Validation loss: 2.227912743886312

Epoch: 6| Step: 2
Training loss: 2.122708559036255
Validation loss: 2.219832460085551

Epoch: 6| Step: 3
Training loss: 1.3305026292800903
Validation loss: 2.1924342115720115

Epoch: 6| Step: 4
Training loss: 2.2488343715667725
Validation loss: 2.1568276484807334

Epoch: 6| Step: 5
Training loss: 1.9394663572311401
Validation loss: 2.1537628968556723

Epoch: 6| Step: 6
Training loss: 1.3456242084503174
Validation loss: 2.167126993338267

Epoch: 6| Step: 7
Training loss: 1.5597565174102783
Validation loss: 2.1455172896385193

Epoch: 6| Step: 8
Training loss: 1.1635408401489258
Validation loss: 2.1474169294039407

Epoch: 6| Step: 9
Training loss: 1.766357660293579
Validation loss: 2.118576188882192

Epoch: 6| Step: 10
Training loss: 1.6112405061721802
Validation loss: 2.1277133226394653

Epoch: 6| Step: 11
Training loss: 1.5788073539733887
Validation loss: 2.1431084473927817

Epoch: 6| Step: 12
Training loss: 2.060777425765991
Validation loss: 2.1203007102012634

Epoch: 6| Step: 13
Training loss: 1.8247278928756714
Validation loss: 2.152386208375295

Epoch: 269| Step: 0
Training loss: 1.9531430006027222
Validation loss: 2.1786637902259827

Epoch: 6| Step: 1
Training loss: 1.5340858697891235
Validation loss: 2.195805768171946

Epoch: 6| Step: 2
Training loss: 2.0183334350585938
Validation loss: 2.185268739859263

Epoch: 6| Step: 3
Training loss: 1.6225903034210205
Validation loss: 2.2328858772913613

Epoch: 6| Step: 4
Training loss: 1.617203950881958
Validation loss: 2.222646097342173

Epoch: 6| Step: 5
Training loss: 2.3321566581726074
Validation loss: 2.2202099363009133

Epoch: 6| Step: 6
Training loss: 2.0758883953094482
Validation loss: 2.2366764744122825

Epoch: 6| Step: 7
Training loss: 1.713230848312378
Validation loss: 2.1978856921195984

Epoch: 6| Step: 8
Training loss: 1.3085806369781494
Validation loss: 2.1821094353993735

Epoch: 6| Step: 9
Training loss: 1.6399171352386475
Validation loss: 2.1517975330352783

Epoch: 6| Step: 10
Training loss: 1.3510475158691406
Validation loss: 2.1758280595143638

Epoch: 6| Step: 11
Training loss: 1.718078851699829
Validation loss: 2.1467315951983132

Epoch: 6| Step: 12
Training loss: 1.5993077754974365
Validation loss: 2.158528288205465

Epoch: 6| Step: 13
Training loss: 1.6870473623275757
Validation loss: 2.157188971837362

Epoch: 270| Step: 0
Training loss: 1.3377840518951416
Validation loss: 2.155919094880422

Epoch: 6| Step: 1
Training loss: 1.7076356410980225
Validation loss: 2.151163856188456

Epoch: 6| Step: 2
Training loss: 1.4396491050720215
Validation loss: 2.183756947517395

Epoch: 6| Step: 3
Training loss: 1.365020513534546
Validation loss: 2.209856708844503

Epoch: 6| Step: 4
Training loss: 1.4824793338775635
Validation loss: 2.2172034978866577

Epoch: 6| Step: 5
Training loss: 2.633281707763672
Validation loss: 2.24818362792333

Epoch: 6| Step: 6
Training loss: 2.0354673862457275
Validation loss: 2.2396082480748496

Epoch: 6| Step: 7
Training loss: 1.755051612854004
Validation loss: 2.2471479376157126

Epoch: 6| Step: 8
Training loss: 0.8538896441459656
Validation loss: 2.2518702944119773

Epoch: 6| Step: 9
Training loss: 1.2268868684768677
Validation loss: 2.2354978124300637

Epoch: 6| Step: 10
Training loss: 1.8117187023162842
Validation loss: 2.239047567049662

Epoch: 6| Step: 11
Training loss: 1.3884472846984863
Validation loss: 2.2086517810821533

Epoch: 6| Step: 12
Training loss: 2.0001420974731445
Validation loss: 2.181090315183004

Epoch: 6| Step: 13
Training loss: 2.32537841796875
Validation loss: 2.1790109276771545

Epoch: 271| Step: 0
Training loss: 1.5593664646148682
Validation loss: 2.172147194544474

Epoch: 6| Step: 1
Training loss: 1.500641107559204
Validation loss: 2.1536247928937278

Epoch: 6| Step: 2
Training loss: 0.9509706497192383
Validation loss: 2.16561488310496

Epoch: 6| Step: 3
Training loss: 1.4344515800476074
Validation loss: 2.1794119477272034

Epoch: 6| Step: 4
Training loss: 1.4946966171264648
Validation loss: 2.193773031234741

Epoch: 6| Step: 5
Training loss: 1.5213725566864014
Validation loss: 2.2123457193374634

Epoch: 6| Step: 6
Training loss: 1.9297587871551514
Validation loss: 2.1845941146214805

Epoch: 6| Step: 7
Training loss: 1.7078979015350342
Validation loss: 2.1869423389434814

Epoch: 6| Step: 8
Training loss: 1.9483399391174316
Validation loss: 2.1658642888069153

Epoch: 6| Step: 9
Training loss: 1.7798852920532227
Validation loss: 2.182832578818003

Epoch: 6| Step: 10
Training loss: 2.045304298400879
Validation loss: 2.2035929958025613

Epoch: 6| Step: 11
Training loss: 2.420193672180176
Validation loss: 2.218813161055247

Epoch: 6| Step: 12
Training loss: 1.8542696237564087
Validation loss: 2.2067054907480874

Epoch: 6| Step: 13
Training loss: 1.3283801078796387
Validation loss: 2.2172927856445312

Epoch: 272| Step: 0
Training loss: 1.6472668647766113
Validation loss: 2.187245865662893

Epoch: 6| Step: 1
Training loss: 1.2204277515411377
Validation loss: 2.213484843571981

Epoch: 6| Step: 2
Training loss: 1.1430785655975342
Validation loss: 2.1783300638198853

Epoch: 6| Step: 3
Training loss: 2.328314781188965
Validation loss: 2.1832916736602783

Epoch: 6| Step: 4
Training loss: 1.786553144454956
Validation loss: 2.1965755224227905

Epoch: 6| Step: 5
Training loss: 1.325883150100708
Validation loss: 2.177112340927124

Epoch: 6| Step: 6
Training loss: 1.841023564338684
Validation loss: 2.2026027043660483

Epoch: 6| Step: 7
Training loss: 1.831570029258728
Validation loss: 2.181950032711029

Epoch: 6| Step: 8
Training loss: 1.8824717998504639
Validation loss: 2.1964049537976584

Epoch: 6| Step: 9
Training loss: 1.4153624773025513
Validation loss: 2.2041637102762857

Epoch: 6| Step: 10
Training loss: 1.7598507404327393
Validation loss: 2.227353811264038

Epoch: 6| Step: 11
Training loss: 1.6823121309280396
Validation loss: 2.2445772091547647

Epoch: 6| Step: 12
Training loss: 1.5287630558013916
Validation loss: 2.2269036372502646

Epoch: 6| Step: 13
Training loss: 1.5219792127609253
Validation loss: 2.241701523462931

Epoch: 273| Step: 0
Training loss: 1.5655089616775513
Validation loss: 2.246531347433726

Epoch: 6| Step: 1
Training loss: 1.5979160070419312
Validation loss: 2.227967540423075

Epoch: 6| Step: 2
Training loss: 0.9791067242622375
Validation loss: 2.2362253069877625

Epoch: 6| Step: 3
Training loss: 1.3416908979415894
Validation loss: 2.221618135770162

Epoch: 6| Step: 4
Training loss: 1.7134443521499634
Validation loss: 2.2378631830215454

Epoch: 6| Step: 5
Training loss: 1.7837752103805542
Validation loss: 2.247285803159078

Epoch: 6| Step: 6
Training loss: 1.2969746589660645
Validation loss: 2.218717078367869

Epoch: 6| Step: 7
Training loss: 1.509512186050415
Validation loss: 2.216095785299937

Epoch: 6| Step: 8
Training loss: 2.102297306060791
Validation loss: 2.2233418027559915

Epoch: 6| Step: 9
Training loss: 1.2140389680862427
Validation loss: 2.203629493713379

Epoch: 6| Step: 10
Training loss: 1.39788818359375
Validation loss: 2.2452229261398315

Epoch: 6| Step: 11
Training loss: 1.6709728240966797
Validation loss: 2.24938311179479

Epoch: 6| Step: 12
Training loss: 2.3310999870300293
Validation loss: 2.2316333651542664

Epoch: 6| Step: 13
Training loss: 2.0777077674865723
Validation loss: 2.2150686581929526

Epoch: 274| Step: 0
Training loss: 1.3624441623687744
Validation loss: 2.1849581003189087

Epoch: 6| Step: 1
Training loss: 1.6245495080947876
Validation loss: 2.1874484618504844

Epoch: 6| Step: 2
Training loss: 1.3360257148742676
Validation loss: 2.1920076608657837

Epoch: 6| Step: 3
Training loss: 2.5844898223876953
Validation loss: 2.19357039531072

Epoch: 6| Step: 4
Training loss: 1.3713674545288086
Validation loss: 2.1690427660942078

Epoch: 6| Step: 5
Training loss: 1.7353622913360596
Validation loss: 2.1856170097986856

Epoch: 6| Step: 6
Training loss: 1.5404748916625977
Validation loss: 2.193110942840576

Epoch: 6| Step: 7
Training loss: 1.5872437953948975
Validation loss: 2.223435699939728

Epoch: 6| Step: 8
Training loss: 1.390178918838501
Validation loss: 2.21419088045756

Epoch: 6| Step: 9
Training loss: 1.8812980651855469
Validation loss: 2.2108598550160727

Epoch: 6| Step: 10
Training loss: 1.8984005451202393
Validation loss: 2.2047826051712036

Epoch: 6| Step: 11
Training loss: 1.2597732543945312
Validation loss: 2.190873901049296

Epoch: 6| Step: 12
Training loss: 1.8470861911773682
Validation loss: 2.1829909682273865

Epoch: 6| Step: 13
Training loss: 0.850104808807373
Validation loss: 2.192376712958018

Epoch: 275| Step: 0
Training loss: 2.0856168270111084
Validation loss: 2.187625308831533

Epoch: 6| Step: 1
Training loss: 1.295426845550537
Validation loss: 2.218860844771067

Epoch: 6| Step: 2
Training loss: 1.8202035427093506
Validation loss: 2.204059680302938

Epoch: 6| Step: 3
Training loss: 1.2981833219528198
Validation loss: 2.203015387058258

Epoch: 6| Step: 4
Training loss: 1.3435947895050049
Validation loss: 2.196808099746704

Epoch: 6| Step: 5
Training loss: 1.5170890092849731
Validation loss: 2.227655073006948

Epoch: 6| Step: 6
Training loss: 1.2611995935440063
Validation loss: 2.209629396597544

Epoch: 6| Step: 7
Training loss: 1.4815036058425903
Validation loss: 2.2076024413108826

Epoch: 6| Step: 8
Training loss: 1.6119470596313477
Validation loss: 2.19683829943339

Epoch: 6| Step: 9
Training loss: 1.9064888954162598
Validation loss: 2.1980762481689453

Epoch: 6| Step: 10
Training loss: 1.809149980545044
Validation loss: 2.159219225247701

Epoch: 6| Step: 11
Training loss: 1.3019287586212158
Validation loss: 2.1810011068979898

Epoch: 6| Step: 12
Training loss: 1.7067615985870361
Validation loss: 2.19521035750707

Epoch: 6| Step: 13
Training loss: 1.9395358562469482
Validation loss: 2.2068904836972556

Epoch: 276| Step: 0
Training loss: 1.1469528675079346
Validation loss: 2.1894325017929077

Epoch: 6| Step: 1
Training loss: 1.5812872648239136
Validation loss: 2.1603137850761414

Epoch: 6| Step: 2
Training loss: 1.537285327911377
Validation loss: 2.1958974798520408

Epoch: 6| Step: 3
Training loss: 2.4096240997314453
Validation loss: 2.1749231417973838

Epoch: 6| Step: 4
Training loss: 1.8974990844726562
Validation loss: 2.2021111647288003

Epoch: 6| Step: 5
Training loss: 1.6941611766815186
Validation loss: 2.180381496747335

Epoch: 6| Step: 6
Training loss: 1.6967943906784058
Validation loss: 2.2108698884646096

Epoch: 6| Step: 7
Training loss: 1.6800740957260132
Validation loss: 2.177716056505839

Epoch: 6| Step: 8
Training loss: 1.5624282360076904
Validation loss: 2.1999353965123496

Epoch: 6| Step: 9
Training loss: 1.9366458654403687
Validation loss: 2.1935039162635803

Epoch: 6| Step: 10
Training loss: 1.182309865951538
Validation loss: 2.1727142532666526

Epoch: 6| Step: 11
Training loss: 1.6993122100830078
Validation loss: 2.1871199011802673

Epoch: 6| Step: 12
Training loss: 1.3150049448013306
Validation loss: 2.175472378730774

Epoch: 6| Step: 13
Training loss: 1.1904947757720947
Validation loss: 2.1934343775113425

Epoch: 277| Step: 0
Training loss: 1.024498701095581
Validation loss: 2.2036401828130088

Epoch: 6| Step: 1
Training loss: 1.7218384742736816
Validation loss: 2.2078738808631897

Epoch: 6| Step: 2
Training loss: 1.3142647743225098
Validation loss: 2.2130998174349465

Epoch: 6| Step: 3
Training loss: 1.4091053009033203
Validation loss: 2.2108335892359414

Epoch: 6| Step: 4
Training loss: 1.9277112483978271
Validation loss: 2.2210907141367593

Epoch: 6| Step: 5
Training loss: 1.7783516645431519
Validation loss: 2.230761686960856

Epoch: 6| Step: 6
Training loss: 1.9853250980377197
Validation loss: 2.2362811962763467

Epoch: 6| Step: 7
Training loss: 1.403726577758789
Validation loss: 2.232719123363495

Epoch: 6| Step: 8
Training loss: 2.0782837867736816
Validation loss: 2.225414792696635

Epoch: 6| Step: 9
Training loss: 1.3354592323303223
Validation loss: 2.217021624247233

Epoch: 6| Step: 10
Training loss: 2.090640068054199
Validation loss: 2.189074993133545

Epoch: 6| Step: 11
Training loss: 1.8949321508407593
Validation loss: 2.1892468134562173

Epoch: 6| Step: 12
Training loss: 1.518959879875183
Validation loss: 2.202704071998596

Epoch: 6| Step: 13
Training loss: 1.4203341007232666
Validation loss: 2.200426936149597

Epoch: 278| Step: 0
Training loss: 1.3210816383361816
Validation loss: 2.224255402882894

Epoch: 6| Step: 1
Training loss: 1.516739010810852
Validation loss: 2.2087861696879068

Epoch: 6| Step: 2
Training loss: 1.876206636428833
Validation loss: 2.182838499546051

Epoch: 6| Step: 3
Training loss: 2.0878751277923584
Validation loss: 2.1784879763921103

Epoch: 6| Step: 4
Training loss: 1.251212239265442
Validation loss: 2.2250012358029685

Epoch: 6| Step: 5
Training loss: 1.5124917030334473
Validation loss: 2.2334165573120117

Epoch: 6| Step: 6
Training loss: 2.0625863075256348
Validation loss: 2.22477388381958

Epoch: 6| Step: 7
Training loss: 1.7353169918060303
Validation loss: 2.2368558247884116

Epoch: 6| Step: 8
Training loss: 1.8176558017730713
Validation loss: 2.2437408169110618

Epoch: 6| Step: 9
Training loss: 2.253946304321289
Validation loss: 2.2789894342422485

Epoch: 6| Step: 10
Training loss: 1.692818284034729
Validation loss: 2.2948437134424844

Epoch: 6| Step: 11
Training loss: 1.3981633186340332
Validation loss: 2.289858082930247

Epoch: 6| Step: 12
Training loss: 1.9004055261611938
Validation loss: 2.247498571872711

Epoch: 6| Step: 13
Training loss: 1.8799879550933838
Validation loss: 2.2445785999298096

Epoch: 279| Step: 0
Training loss: 2.0215797424316406
Validation loss: 2.2113658587137857

Epoch: 6| Step: 1
Training loss: 1.3601703643798828
Validation loss: 2.1961166858673096

Epoch: 6| Step: 2
Training loss: 2.157945156097412
Validation loss: 2.141989310582479

Epoch: 6| Step: 3
Training loss: 1.9359807968139648
Validation loss: 2.1482357581456504

Epoch: 6| Step: 4
Training loss: 1.1637474298477173
Validation loss: 2.1636842489242554

Epoch: 6| Step: 5
Training loss: 1.9754307270050049
Validation loss: 2.1651933193206787

Epoch: 6| Step: 6
Training loss: 1.6100492477416992
Validation loss: 2.15298859278361

Epoch: 6| Step: 7
Training loss: 1.4415943622589111
Validation loss: 2.1726093888282776

Epoch: 6| Step: 8
Training loss: 1.859013557434082
Validation loss: 2.1517454981803894

Epoch: 6| Step: 9
Training loss: 1.8138272762298584
Validation loss: 2.1579648653666177

Epoch: 6| Step: 10
Training loss: 1.624277114868164
Validation loss: 2.16601570447286

Epoch: 6| Step: 11
Training loss: 1.655357837677002
Validation loss: 2.2147018909454346

Epoch: 6| Step: 12
Training loss: 1.685558795928955
Validation loss: 2.238022824128469

Epoch: 6| Step: 13
Training loss: 1.5351945161819458
Validation loss: 2.2117538452148438

Epoch: 280| Step: 0
Training loss: 1.4988906383514404
Validation loss: 2.2348692615826926

Epoch: 6| Step: 1
Training loss: 1.9311630725860596
Validation loss: 2.2644843260447183

Epoch: 6| Step: 2
Training loss: 2.0969958305358887
Validation loss: 2.2663663029670715

Epoch: 6| Step: 3
Training loss: 1.317920207977295
Validation loss: 2.253797431786855

Epoch: 6| Step: 4
Training loss: 1.688370943069458
Validation loss: 2.2438406944274902

Epoch: 6| Step: 5
Training loss: 1.4402744770050049
Validation loss: 2.2225904067357383

Epoch: 6| Step: 6
Training loss: 1.3521621227264404
Validation loss: 2.218183080355326

Epoch: 6| Step: 7
Training loss: 1.3953584432601929
Validation loss: 2.1984283924102783

Epoch: 6| Step: 8
Training loss: 2.170363664627075
Validation loss: 2.181179324785868

Epoch: 6| Step: 9
Training loss: 2.105504035949707
Validation loss: 2.200910488764445

Epoch: 6| Step: 10
Training loss: 1.9499495029449463
Validation loss: 2.2011150121688843

Epoch: 6| Step: 11
Training loss: 1.4017956256866455
Validation loss: 2.22053454319636

Epoch: 6| Step: 12
Training loss: 1.9640493392944336
Validation loss: 2.1995569268862405

Epoch: 6| Step: 13
Training loss: 1.1242831945419312
Validation loss: 2.18927796681722

Epoch: 281| Step: 0
Training loss: 1.2594276666641235
Validation loss: 2.1738540132840476

Epoch: 6| Step: 1
Training loss: 1.6925020217895508
Validation loss: 2.195798714955648

Epoch: 6| Step: 2
Training loss: 1.765282392501831
Validation loss: 2.227085749308268

Epoch: 6| Step: 3
Training loss: 1.4174708127975464
Validation loss: 2.1991823514302573

Epoch: 6| Step: 4
Training loss: 1.4296947717666626
Validation loss: 2.217755119005839

Epoch: 6| Step: 5
Training loss: 2.168856620788574
Validation loss: 2.2261094450950623

Epoch: 6| Step: 6
Training loss: 2.032094955444336
Validation loss: 2.2248244086901345

Epoch: 6| Step: 7
Training loss: 1.325295329093933
Validation loss: 2.226503094037374

Epoch: 6| Step: 8
Training loss: 1.1916131973266602
Validation loss: 2.2257660230000815

Epoch: 6| Step: 9
Training loss: 1.355139970779419
Validation loss: 2.210935195287069

Epoch: 6| Step: 10
Training loss: 1.8334442377090454
Validation loss: 2.208709438641866

Epoch: 6| Step: 11
Training loss: 1.5883312225341797
Validation loss: 2.17266050974528

Epoch: 6| Step: 12
Training loss: 2.119546890258789
Validation loss: 2.1502341826756797

Epoch: 6| Step: 13
Training loss: 1.2562744617462158
Validation loss: 2.2041358947753906

Epoch: 282| Step: 0
Training loss: 1.509049654006958
Validation loss: 2.177870233853658

Epoch: 6| Step: 1
Training loss: 1.5245938301086426
Validation loss: 2.177370548248291

Epoch: 6| Step: 2
Training loss: 1.5039587020874023
Validation loss: 2.2063881754875183

Epoch: 6| Step: 3
Training loss: 1.5664570331573486
Validation loss: 2.222718338171641

Epoch: 6| Step: 4
Training loss: 1.9028937816619873
Validation loss: 2.207264165083567

Epoch: 6| Step: 5
Training loss: 1.3834655284881592
Validation loss: 2.174825668334961

Epoch: 6| Step: 6
Training loss: 1.742522954940796
Validation loss: 2.194153587023417

Epoch: 6| Step: 7
Training loss: 1.5165873765945435
Validation loss: 2.155380606651306

Epoch: 6| Step: 8
Training loss: 1.2173360586166382
Validation loss: 2.1757259368896484

Epoch: 6| Step: 9
Training loss: 2.4073753356933594
Validation loss: 2.193693240483602

Epoch: 6| Step: 10
Training loss: 1.8685789108276367
Validation loss: 2.1822551687558494

Epoch: 6| Step: 11
Training loss: 1.4762442111968994
Validation loss: 2.200366258621216

Epoch: 6| Step: 12
Training loss: 1.2451858520507812
Validation loss: 2.1974567572275796

Epoch: 6| Step: 13
Training loss: 1.412419319152832
Validation loss: 2.180063565572103

Epoch: 283| Step: 0
Training loss: 1.2986533641815186
Validation loss: 2.2317300836245217

Epoch: 6| Step: 1
Training loss: 1.7159233093261719
Validation loss: 2.181673308213552

Epoch: 6| Step: 2
Training loss: 1.8423380851745605
Validation loss: 2.1656761368115744

Epoch: 6| Step: 3
Training loss: 1.2720141410827637
Validation loss: 2.1618433793385825

Epoch: 6| Step: 4
Training loss: 1.7503776550292969
Validation loss: 2.1605569322903952

Epoch: 6| Step: 5
Training loss: 1.5793588161468506
Validation loss: 2.174413740634918

Epoch: 6| Step: 6
Training loss: 1.949655532836914
Validation loss: 2.150779962539673

Epoch: 6| Step: 7
Training loss: 1.7444448471069336
Validation loss: 2.156705300013224

Epoch: 6| Step: 8
Training loss: 1.2455670833587646
Validation loss: 2.180014729499817

Epoch: 6| Step: 9
Training loss: 1.6476771831512451
Validation loss: 2.143496255079905

Epoch: 6| Step: 10
Training loss: 1.6680660247802734
Validation loss: 2.158890644709269

Epoch: 6| Step: 11
Training loss: 1.1426939964294434
Validation loss: 2.1390795906384787

Epoch: 6| Step: 12
Training loss: 1.7652947902679443
Validation loss: 2.1653921802838645

Epoch: 6| Step: 13
Training loss: 1.690399169921875
Validation loss: 2.1666083335876465

Epoch: 284| Step: 0
Training loss: 1.841357946395874
Validation loss: 2.166906754175822

Epoch: 6| Step: 1
Training loss: 1.2016839981079102
Validation loss: 2.162150045235952

Epoch: 6| Step: 2
Training loss: 2.0604171752929688
Validation loss: 2.178916792074839

Epoch: 6| Step: 3
Training loss: 1.3047385215759277
Validation loss: 2.1727073987325034

Epoch: 6| Step: 4
Training loss: 1.5128856897354126
Validation loss: 2.161419232686361

Epoch: 6| Step: 5
Training loss: 1.259683609008789
Validation loss: 2.181053181489309

Epoch: 6| Step: 6
Training loss: 1.302706241607666
Validation loss: 2.2164073387781777

Epoch: 6| Step: 7
Training loss: 1.0044689178466797
Validation loss: 2.1648429234822593

Epoch: 6| Step: 8
Training loss: 1.4612315893173218
Validation loss: 2.1967912515004477

Epoch: 6| Step: 9
Training loss: 1.3781415224075317
Validation loss: 2.1805010239283242

Epoch: 6| Step: 10
Training loss: 2.494685649871826
Validation loss: 2.1936787764231362

Epoch: 6| Step: 11
Training loss: 1.7424430847167969
Validation loss: 2.2249048153559365

Epoch: 6| Step: 12
Training loss: 1.2687938213348389
Validation loss: 2.2124792337417603

Epoch: 6| Step: 13
Training loss: 2.084580898284912
Validation loss: 2.216978053251902

Epoch: 285| Step: 0
Training loss: 1.5524985790252686
Validation loss: 2.2205806970596313

Epoch: 6| Step: 1
Training loss: 1.1476049423217773
Validation loss: 2.206782261530558

Epoch: 6| Step: 2
Training loss: 1.919050693511963
Validation loss: 2.1886826157569885

Epoch: 6| Step: 3
Training loss: 1.729610800743103
Validation loss: 2.1955707669258118

Epoch: 6| Step: 4
Training loss: 1.4210762977600098
Validation loss: 2.186271091302236

Epoch: 6| Step: 5
Training loss: 1.3686574697494507
Validation loss: 2.215342899163564

Epoch: 6| Step: 6
Training loss: 1.4495649337768555
Validation loss: 2.1963730653127036

Epoch: 6| Step: 7
Training loss: 1.9790245294570923
Validation loss: 2.2155412634213767

Epoch: 6| Step: 8
Training loss: 2.3522493839263916
Validation loss: 2.196438511212667

Epoch: 6| Step: 9
Training loss: 1.1228220462799072
Validation loss: 2.2031746904055276

Epoch: 6| Step: 10
Training loss: 1.052724003791809
Validation loss: 2.1989691257476807

Epoch: 6| Step: 11
Training loss: 1.593993067741394
Validation loss: 2.2025351524353027

Epoch: 6| Step: 12
Training loss: 1.711195707321167
Validation loss: 2.241710285345713

Epoch: 6| Step: 13
Training loss: 1.410370111465454
Validation loss: 2.2028728127479553

Epoch: 286| Step: 0
Training loss: 1.1255135536193848
Validation loss: 2.2047977646191916

Epoch: 6| Step: 1
Training loss: 1.826607584953308
Validation loss: 2.1756030122439065

Epoch: 6| Step: 2
Training loss: 1.4867651462554932
Validation loss: 2.2050123612085977

Epoch: 6| Step: 3
Training loss: 1.723878026008606
Validation loss: 2.1994351545969644

Epoch: 6| Step: 4
Training loss: 1.8747153282165527
Validation loss: 2.201135993003845

Epoch: 6| Step: 5
Training loss: 1.7508492469787598
Validation loss: 2.234381079673767

Epoch: 6| Step: 6
Training loss: 1.1731975078582764
Validation loss: 2.2039277156194053

Epoch: 6| Step: 7
Training loss: 1.7949849367141724
Validation loss: 2.2473193407058716

Epoch: 6| Step: 8
Training loss: 1.8884333372116089
Validation loss: 2.227726101875305

Epoch: 6| Step: 9
Training loss: 0.8575595021247864
Validation loss: 2.246613065401713

Epoch: 6| Step: 10
Training loss: 1.235543966293335
Validation loss: 2.2770090103149414

Epoch: 6| Step: 11
Training loss: 2.1639561653137207
Validation loss: 2.2428287665049234

Epoch: 6| Step: 12
Training loss: 1.6779422760009766
Validation loss: 2.244866967201233

Epoch: 6| Step: 13
Training loss: 1.4114614725112915
Validation loss: 2.2290221055348716

Epoch: 287| Step: 0
Training loss: 1.488541841506958
Validation loss: 2.1861016750335693

Epoch: 6| Step: 1
Training loss: 1.1160130500793457
Validation loss: 2.1920775373776755

Epoch: 6| Step: 2
Training loss: 1.275846242904663
Validation loss: 2.19554074605306

Epoch: 6| Step: 3
Training loss: 1.7721021175384521
Validation loss: 2.1779332558314004

Epoch: 6| Step: 4
Training loss: 1.3501670360565186
Validation loss: 2.1571528712908425

Epoch: 6| Step: 5
Training loss: 1.6921037435531616
Validation loss: 2.1751731634140015

Epoch: 6| Step: 6
Training loss: 1.323538064956665
Validation loss: 2.136853734652201

Epoch: 6| Step: 7
Training loss: 1.6986019611358643
Validation loss: 2.1500954031944275

Epoch: 6| Step: 8
Training loss: 2.0525295734405518
Validation loss: 2.1642335057258606

Epoch: 6| Step: 9
Training loss: 1.2267799377441406
Validation loss: 2.1648770570755005

Epoch: 6| Step: 10
Training loss: 1.6529624462127686
Validation loss: 2.1701285441716514

Epoch: 6| Step: 11
Training loss: 1.1958508491516113
Validation loss: 2.1702396472295127

Epoch: 6| Step: 12
Training loss: 2.025580883026123
Validation loss: 2.1751184264818826

Epoch: 6| Step: 13
Training loss: 1.6673015356063843
Validation loss: 2.190271178881327

Epoch: 288| Step: 0
Training loss: 1.8352382183074951
Validation loss: 2.164598286151886

Epoch: 6| Step: 1
Training loss: 1.4034183025360107
Validation loss: 2.170275111993154

Epoch: 6| Step: 2
Training loss: 1.4344972372055054
Validation loss: 2.1524263421694436

Epoch: 6| Step: 3
Training loss: 1.3506557941436768
Validation loss: 2.181195696194967

Epoch: 6| Step: 4
Training loss: 1.227459192276001
Validation loss: 2.1578977505366006

Epoch: 6| Step: 5
Training loss: 1.4474166631698608
Validation loss: 2.1352056662241616

Epoch: 6| Step: 6
Training loss: 1.7909256219863892
Validation loss: 2.172373612721761

Epoch: 6| Step: 7
Training loss: 1.7942514419555664
Validation loss: 2.162699202696482

Epoch: 6| Step: 8
Training loss: 1.665325403213501
Validation loss: 2.1653371850649514

Epoch: 6| Step: 9
Training loss: 1.9999512434005737
Validation loss: 2.1985947489738464

Epoch: 6| Step: 10
Training loss: 1.393794059753418
Validation loss: 2.182466467221578

Epoch: 6| Step: 11
Training loss: 1.5769855976104736
Validation loss: 2.215454955895742

Epoch: 6| Step: 12
Training loss: 1.7945531606674194
Validation loss: 2.235400935014089

Epoch: 6| Step: 13
Training loss: 1.5145976543426514
Validation loss: 2.1897709369659424

Epoch: 289| Step: 0
Training loss: 1.4124863147735596
Validation loss: 2.1683576504389444

Epoch: 6| Step: 1
Training loss: 1.2645962238311768
Validation loss: 2.163677473862966

Epoch: 6| Step: 2
Training loss: 2.0344481468200684
Validation loss: 2.1606477896372476

Epoch: 6| Step: 3
Training loss: 1.6691762208938599
Validation loss: 2.1524378657341003

Epoch: 6| Step: 4
Training loss: 1.8138378858566284
Validation loss: 2.135417103767395

Epoch: 6| Step: 5
Training loss: 1.8087348937988281
Validation loss: 2.160691777865092

Epoch: 6| Step: 6
Training loss: 1.4181182384490967
Validation loss: 2.1417749325434365

Epoch: 6| Step: 7
Training loss: 2.1411142349243164
Validation loss: 2.1420188347498574

Epoch: 6| Step: 8
Training loss: 1.2077133655548096
Validation loss: 2.14516011873881

Epoch: 6| Step: 9
Training loss: 2.0168933868408203
Validation loss: 2.1173107822736106

Epoch: 6| Step: 10
Training loss: 2.003026008605957
Validation loss: 2.1272966066996255

Epoch: 6| Step: 11
Training loss: 1.536909818649292
Validation loss: 2.1352378924687705

Epoch: 6| Step: 12
Training loss: 1.3216793537139893
Validation loss: 2.132900357246399

Epoch: 6| Step: 13
Training loss: 1.2478525638580322
Validation loss: 2.144377648830414

Epoch: 290| Step: 0
Training loss: 1.545212745666504
Validation loss: 2.190938671429952

Epoch: 6| Step: 1
Training loss: 2.4736521244049072
Validation loss: 2.200727184613546

Epoch: 6| Step: 2
Training loss: 1.2814682722091675
Validation loss: 2.209513306617737

Epoch: 6| Step: 3
Training loss: 2.0309371948242188
Validation loss: 2.2020804484685264

Epoch: 6| Step: 4
Training loss: 2.3307273387908936
Validation loss: 2.2046087185541787

Epoch: 6| Step: 5
Training loss: 1.976038932800293
Validation loss: 2.202236811319987

Epoch: 6| Step: 6
Training loss: 1.753420114517212
Validation loss: 2.2085708578427634

Epoch: 6| Step: 7
Training loss: 1.271019458770752
Validation loss: 2.204078753789266

Epoch: 6| Step: 8
Training loss: 1.250464916229248
Validation loss: 2.197093586126963

Epoch: 6| Step: 9
Training loss: 1.1158593893051147
Validation loss: 2.209389646848043

Epoch: 6| Step: 10
Training loss: 1.4969019889831543
Validation loss: 2.2375868956247964

Epoch: 6| Step: 11
Training loss: 1.3803000450134277
Validation loss: 2.2199007471402488

Epoch: 6| Step: 12
Training loss: 1.1306381225585938
Validation loss: 2.214322865009308

Epoch: 6| Step: 13
Training loss: 0.9754272699356079
Validation loss: 2.214933236440023

Epoch: 291| Step: 0
Training loss: 1.378669023513794
Validation loss: 2.187724749247233

Epoch: 6| Step: 1
Training loss: 0.9965372681617737
Validation loss: 2.201386332511902

Epoch: 6| Step: 2
Training loss: 2.3827626705169678
Validation loss: 2.1784210403760276

Epoch: 6| Step: 3
Training loss: 1.242837905883789
Validation loss: 2.20072869459788

Epoch: 6| Step: 4
Training loss: 1.3538298606872559
Validation loss: 2.2034842371940613

Epoch: 6| Step: 5
Training loss: 1.3044686317443848
Validation loss: 2.1933943033218384

Epoch: 6| Step: 6
Training loss: 1.5074756145477295
Validation loss: 2.201103607813517

Epoch: 6| Step: 7
Training loss: 1.7550604343414307
Validation loss: 2.188224136829376

Epoch: 6| Step: 8
Training loss: 1.61568284034729
Validation loss: 2.1799672643343606

Epoch: 6| Step: 9
Training loss: 1.1954777240753174
Validation loss: 2.204099118709564

Epoch: 6| Step: 10
Training loss: 1.678102731704712
Validation loss: 2.2193788091341653

Epoch: 6| Step: 11
Training loss: 1.8704371452331543
Validation loss: 2.1664644877115884

Epoch: 6| Step: 12
Training loss: 1.2225146293640137
Validation loss: 2.1891092658042908

Epoch: 6| Step: 13
Training loss: 1.8871080875396729
Validation loss: 2.1845353841781616

Epoch: 292| Step: 0
Training loss: 1.860633373260498
Validation loss: 2.166955828666687

Epoch: 6| Step: 1
Training loss: 1.1532647609710693
Validation loss: 2.1732576489448547

Epoch: 6| Step: 2
Training loss: 1.3499417304992676
Validation loss: 2.1927266915639243

Epoch: 6| Step: 3
Training loss: 1.2923357486724854
Validation loss: 2.19300768772761

Epoch: 6| Step: 4
Training loss: 1.5985491275787354
Validation loss: 2.169435282548269

Epoch: 6| Step: 5
Training loss: 1.438112735748291
Validation loss: 2.2212562958399453

Epoch: 6| Step: 6
Training loss: 2.4395976066589355
Validation loss: 2.181702196598053

Epoch: 6| Step: 7
Training loss: 1.1407238245010376
Validation loss: 2.2206210692723594

Epoch: 6| Step: 8
Training loss: 2.0871992111206055
Validation loss: 2.191922148068746

Epoch: 6| Step: 9
Training loss: 1.4853692054748535
Validation loss: 2.2027843793233237

Epoch: 6| Step: 10
Training loss: 1.3441022634506226
Validation loss: 2.154177963733673

Epoch: 6| Step: 11
Training loss: 1.3880919218063354
Validation loss: 2.163149058818817

Epoch: 6| Step: 12
Training loss: 1.452675223350525
Validation loss: 2.1807456413904824

Epoch: 6| Step: 13
Training loss: 1.0135096311569214
Validation loss: 2.1697678764661155

Epoch: 293| Step: 0
Training loss: 1.5690895318984985
Validation loss: 2.1787538528442383

Epoch: 6| Step: 1
Training loss: 1.9093952178955078
Validation loss: 2.1697734793027244

Epoch: 6| Step: 2
Training loss: 1.9931516647338867
Validation loss: 2.1953720450401306

Epoch: 6| Step: 3
Training loss: 1.98172926902771
Validation loss: 2.1777876218159995

Epoch: 6| Step: 4
Training loss: 1.1953861713409424
Validation loss: 2.205360174179077

Epoch: 6| Step: 5
Training loss: 1.6278965473175049
Validation loss: 2.1769720315933228

Epoch: 6| Step: 6
Training loss: 1.1051011085510254
Validation loss: 2.2038474678993225

Epoch: 6| Step: 7
Training loss: 1.4000413417816162
Validation loss: 2.1881681283315024

Epoch: 6| Step: 8
Training loss: 1.3599612712860107
Validation loss: 2.22833389043808

Epoch: 6| Step: 9
Training loss: 1.2756321430206299
Validation loss: 2.2241457303365073

Epoch: 6| Step: 10
Training loss: 1.464417576789856
Validation loss: 2.2275083859761557

Epoch: 6| Step: 11
Training loss: 2.071993827819824
Validation loss: 2.221498429775238

Epoch: 6| Step: 12
Training loss: 1.2588746547698975
Validation loss: 2.215857525666555

Epoch: 6| Step: 13
Training loss: 1.0926470756530762
Validation loss: 2.1916239062945047

Epoch: 294| Step: 0
Training loss: 1.4994655847549438
Validation loss: 2.1743554870287576

Epoch: 6| Step: 1
Training loss: 2.3054327964782715
Validation loss: 2.1686745484670005

Epoch: 6| Step: 2
Training loss: 1.0706965923309326
Validation loss: 2.1549320220947266

Epoch: 6| Step: 3
Training loss: 1.22212553024292
Validation loss: 2.169421633084615

Epoch: 6| Step: 4
Training loss: 1.6566216945648193
Validation loss: 2.148638645807902

Epoch: 6| Step: 5
Training loss: 0.899743914604187
Validation loss: 2.1555577516555786

Epoch: 6| Step: 6
Training loss: 1.402024269104004
Validation loss: 2.1771580576896667

Epoch: 6| Step: 7
Training loss: 0.86406409740448
Validation loss: 2.1581782698631287

Epoch: 6| Step: 8
Training loss: 0.916184663772583
Validation loss: 2.1802414655685425

Epoch: 6| Step: 9
Training loss: 2.4846935272216797
Validation loss: 2.194445788860321

Epoch: 6| Step: 10
Training loss: 1.4940104484558105
Validation loss: 2.1655954321225486

Epoch: 6| Step: 11
Training loss: 1.8915717601776123
Validation loss: 2.209544082482656

Epoch: 6| Step: 12
Training loss: 1.2875566482543945
Validation loss: 2.2095383207003274

Epoch: 6| Step: 13
Training loss: 1.980329990386963
Validation loss: 2.229426840941111

Epoch: 295| Step: 0
Training loss: 1.633410930633545
Validation loss: 2.277157505353292

Epoch: 6| Step: 1
Training loss: 1.7282347679138184
Validation loss: 2.207968016465505

Epoch: 6| Step: 2
Training loss: 1.1732399463653564
Validation loss: 2.19708780447642

Epoch: 6| Step: 3
Training loss: 1.3930654525756836
Validation loss: 2.227160374323527

Epoch: 6| Step: 4
Training loss: 1.3605947494506836
Validation loss: 2.244067927201589

Epoch: 6| Step: 5
Training loss: 1.8144892454147339
Validation loss: 2.2107649445533752

Epoch: 6| Step: 6
Training loss: 1.7489087581634521
Validation loss: 2.173526386419932

Epoch: 6| Step: 7
Training loss: 1.6436954736709595
Validation loss: 2.1881202459335327

Epoch: 6| Step: 8
Training loss: 2.1235105991363525
Validation loss: 2.1700633764266968

Epoch: 6| Step: 9
Training loss: 0.9615723490715027
Validation loss: 2.133103887240092

Epoch: 6| Step: 10
Training loss: 1.0308780670166016
Validation loss: 2.151655673980713

Epoch: 6| Step: 11
Training loss: 1.3385717868804932
Validation loss: 2.1178830663363137

Epoch: 6| Step: 12
Training loss: 1.6810345649719238
Validation loss: 2.137701233228048

Epoch: 6| Step: 13
Training loss: 1.762786865234375
Validation loss: 2.131657282511393

Epoch: 296| Step: 0
Training loss: 1.3419780731201172
Validation loss: 2.153763552506765

Epoch: 6| Step: 1
Training loss: 0.8437729477882385
Validation loss: 2.1354280511538186

Epoch: 6| Step: 2
Training loss: 1.8876066207885742
Validation loss: 2.1689055363337197

Epoch: 6| Step: 3
Training loss: 1.5126367807388306
Validation loss: 2.228408952554067

Epoch: 6| Step: 4
Training loss: 1.4415887594223022
Validation loss: 2.213816463947296

Epoch: 6| Step: 5
Training loss: 1.4797440767288208
Validation loss: 2.189068873723348

Epoch: 6| Step: 6
Training loss: 0.9183120727539062
Validation loss: 2.197479724884033

Epoch: 6| Step: 7
Training loss: 1.1800470352172852
Validation loss: 2.214477241039276

Epoch: 6| Step: 8
Training loss: 1.8673266172409058
Validation loss: 2.1966655254364014

Epoch: 6| Step: 9
Training loss: 1.6754992008209229
Validation loss: 2.1766317089398703

Epoch: 6| Step: 10
Training loss: 1.2688369750976562
Validation loss: 2.180174787839254

Epoch: 6| Step: 11
Training loss: 1.5728588104248047
Validation loss: 2.1284082333246865

Epoch: 6| Step: 12
Training loss: 2.1673972606658936
Validation loss: 2.104355275630951

Epoch: 6| Step: 13
Training loss: 1.4805176258087158
Validation loss: 2.1320208311080933

Epoch: 297| Step: 0
Training loss: 1.248749852180481
Validation loss: 2.106297492980957

Epoch: 6| Step: 1
Training loss: 1.291109561920166
Validation loss: 2.132623235384623

Epoch: 6| Step: 2
Training loss: 1.4451466798782349
Validation loss: 2.1467773715655007

Epoch: 6| Step: 3
Training loss: 1.2652465105056763
Validation loss: 2.163242975870768

Epoch: 6| Step: 4
Training loss: 1.8943724632263184
Validation loss: 2.1191585063934326

Epoch: 6| Step: 5
Training loss: 2.2716457843780518
Validation loss: 2.1714158058166504

Epoch: 6| Step: 6
Training loss: 1.5876483917236328
Validation loss: 2.1850765148798623

Epoch: 6| Step: 7
Training loss: 1.710959553718567
Validation loss: 2.16231099764506

Epoch: 6| Step: 8
Training loss: 1.5011506080627441
Validation loss: 2.150224030017853

Epoch: 6| Step: 9
Training loss: 1.745311975479126
Validation loss: 2.1299713452657065

Epoch: 6| Step: 10
Training loss: 1.4248254299163818
Validation loss: 2.151575227578481

Epoch: 6| Step: 11
Training loss: 1.282841682434082
Validation loss: 2.1796629230181375

Epoch: 6| Step: 12
Training loss: 0.9604227542877197
Validation loss: 2.2109086314837136

Epoch: 6| Step: 13
Training loss: 0.7569453120231628
Validation loss: 2.181650678316752

Epoch: 298| Step: 0
Training loss: 1.9577387571334839
Validation loss: 2.1904197335243225

Epoch: 6| Step: 1
Training loss: 1.5220322608947754
Validation loss: 2.2048469384511313

Epoch: 6| Step: 2
Training loss: 1.1315641403198242
Validation loss: 2.1716339588165283

Epoch: 6| Step: 3
Training loss: 2.6118922233581543
Validation loss: 2.1755072275797525

Epoch: 6| Step: 4
Training loss: 1.379103183746338
Validation loss: 2.175027827421824

Epoch: 6| Step: 5
Training loss: 1.4834930896759033
Validation loss: 2.143854022026062

Epoch: 6| Step: 6
Training loss: 1.5356850624084473
Validation loss: 2.1799396276474

Epoch: 6| Step: 7
Training loss: 0.6537043452262878
Validation loss: 2.168782889842987

Epoch: 6| Step: 8
Training loss: 1.722601294517517
Validation loss: 2.1689048210779824

Epoch: 6| Step: 9
Training loss: 1.3080832958221436
Validation loss: 2.1778905789057412

Epoch: 6| Step: 10
Training loss: 1.8456697463989258
Validation loss: 2.170225818951925

Epoch: 6| Step: 11
Training loss: 1.3418850898742676
Validation loss: 2.184990962346395

Epoch: 6| Step: 12
Training loss: 1.3379859924316406
Validation loss: 2.1641979614893594

Epoch: 6| Step: 13
Training loss: 1.1686513423919678
Validation loss: 2.1683239936828613

Epoch: 299| Step: 0
Training loss: 1.8891384601593018
Validation loss: 2.142910361289978

Epoch: 6| Step: 1
Training loss: 0.7127145528793335
Validation loss: 2.140465021133423

Epoch: 6| Step: 2
Training loss: 1.1801011562347412
Validation loss: 2.1462801694869995

Epoch: 6| Step: 3
Training loss: 1.3290119171142578
Validation loss: 2.1383188565572104

Epoch: 6| Step: 4
Training loss: 1.3248978853225708
Validation loss: 2.134714206059774

Epoch: 6| Step: 5
Training loss: 1.7939081192016602
Validation loss: 2.1962522665659585

Epoch: 6| Step: 6
Training loss: 1.8248766660690308
Validation loss: 2.178788344065348

Epoch: 6| Step: 7
Training loss: 1.6425707340240479
Validation loss: 2.1605228583017984

Epoch: 6| Step: 8
Training loss: 1.6485267877578735
Validation loss: 2.1708116134007773

Epoch: 6| Step: 9
Training loss: 2.0095598697662354
Validation loss: 2.1525368889172873

Epoch: 6| Step: 10
Training loss: 1.8000088930130005
Validation loss: 2.1719549894332886

Epoch: 6| Step: 11
Training loss: 0.8784501552581787
Validation loss: 2.214009086290995

Epoch: 6| Step: 12
Training loss: 1.957411289215088
Validation loss: 2.2299986282984414

Epoch: 6| Step: 13
Training loss: 1.4614551067352295
Validation loss: 2.255851089954376

Epoch: 300| Step: 0
Training loss: 1.1321260929107666
Validation loss: 2.2645576000213623

Epoch: 6| Step: 1
Training loss: 1.587648868560791
Validation loss: 2.1925948659578958

Epoch: 6| Step: 2
Training loss: 1.6004583835601807
Validation loss: 2.1925899982452393

Epoch: 6| Step: 3
Training loss: 1.1872665882110596
Validation loss: 2.1641892393430076

Epoch: 6| Step: 4
Training loss: 1.4023940563201904
Validation loss: 2.17536328236262

Epoch: 6| Step: 5
Training loss: 1.082118272781372
Validation loss: 2.2019399801890054

Epoch: 6| Step: 6
Training loss: 1.883823275566101
Validation loss: 2.196742057800293

Epoch: 6| Step: 7
Training loss: 1.8217650651931763
Validation loss: 2.2096996307373047

Epoch: 6| Step: 8
Training loss: 1.5302879810333252
Validation loss: 2.1930479208628335

Epoch: 6| Step: 9
Training loss: 1.5581797361373901
Validation loss: 2.2078222036361694

Epoch: 6| Step: 10
Training loss: 1.3120540380477905
Validation loss: 2.204713503519694

Epoch: 6| Step: 11
Training loss: 1.2944903373718262
Validation loss: 2.236208736896515

Epoch: 6| Step: 12
Training loss: 1.3678507804870605
Validation loss: 2.2246859669685364

Epoch: 6| Step: 13
Training loss: 2.2227208614349365
Validation loss: 2.200876474380493

Epoch: 301| Step: 0
Training loss: 1.8823843002319336
Validation loss: 2.2436843514442444

Epoch: 6| Step: 1
Training loss: 1.3526923656463623
Validation loss: 2.256164769331614

Epoch: 6| Step: 2
Training loss: 1.539846420288086
Validation loss: 2.210057020187378

Epoch: 6| Step: 3
Training loss: 1.6616052389144897
Validation loss: 2.1867188811302185

Epoch: 6| Step: 4
Training loss: 1.2355716228485107
Validation loss: 2.2102205554644265

Epoch: 6| Step: 5
Training loss: 1.8077510595321655
Validation loss: 2.1690166195233664

Epoch: 6| Step: 6
Training loss: 1.3135806322097778
Validation loss: 2.1623679399490356

Epoch: 6| Step: 7
Training loss: 1.664747953414917
Validation loss: 2.161203463872274

Epoch: 6| Step: 8
Training loss: 1.6618247032165527
Validation loss: 2.1529872020085654

Epoch: 6| Step: 9
Training loss: 1.4059704542160034
Validation loss: 2.1360667943954468

Epoch: 6| Step: 10
Training loss: 1.0305964946746826
Validation loss: 2.1422127882639566

Epoch: 6| Step: 11
Training loss: 1.3637135028839111
Validation loss: 2.1620476643244424

Epoch: 6| Step: 12
Training loss: 2.0699973106384277
Validation loss: 2.1549670100212097

Epoch: 6| Step: 13
Training loss: 1.4807190895080566
Validation loss: 2.191744089126587

Epoch: 302| Step: 0
Training loss: 1.4410514831542969
Validation loss: 2.1509803334871926

Epoch: 6| Step: 1
Training loss: 1.5270018577575684
Validation loss: 2.1828781962394714

Epoch: 6| Step: 2
Training loss: 1.5161436796188354
Validation loss: 2.170295834541321

Epoch: 6| Step: 3
Training loss: 0.7491761445999146
Validation loss: 2.203838050365448

Epoch: 6| Step: 4
Training loss: 1.7809916734695435
Validation loss: 2.1568837563196817

Epoch: 6| Step: 5
Training loss: 1.4998154640197754
Validation loss: 2.1741960048675537

Epoch: 6| Step: 6
Training loss: 1.981913447380066
Validation loss: 2.1570635636647544

Epoch: 6| Step: 7
Training loss: 1.051236867904663
Validation loss: 2.197586397329966

Epoch: 6| Step: 8
Training loss: 1.6382806301116943
Validation loss: 2.165201723575592

Epoch: 6| Step: 9
Training loss: 1.6163408756256104
Validation loss: 2.1896469593048096

Epoch: 6| Step: 10
Training loss: 1.4299530982971191
Validation loss: 2.142856001853943

Epoch: 6| Step: 11
Training loss: 1.2273805141448975
Validation loss: 2.1618133982022605

Epoch: 6| Step: 12
Training loss: 2.0817065238952637
Validation loss: 2.1341404716173806

Epoch: 6| Step: 13
Training loss: 0.997430682182312
Validation loss: 2.1442061265309653

Epoch: 303| Step: 0
Training loss: 1.43241286277771
Validation loss: 2.1109380523363748

Epoch: 6| Step: 1
Training loss: 1.804384469985962
Validation loss: 2.100420812765757

Epoch: 6| Step: 2
Training loss: 1.4296151399612427
Validation loss: 2.1699793140093484

Epoch: 6| Step: 3
Training loss: 1.147392749786377
Validation loss: 2.1564589937527976

Epoch: 6| Step: 4
Training loss: 1.466583251953125
Validation loss: 2.1788275043169656

Epoch: 6| Step: 5
Training loss: 1.5699176788330078
Validation loss: 2.201491673787435

Epoch: 6| Step: 6
Training loss: 1.152086853981018
Validation loss: 2.2033870816230774

Epoch: 6| Step: 7
Training loss: 1.4553693532943726
Validation loss: 2.2046388586362204

Epoch: 6| Step: 8
Training loss: 2.3384318351745605
Validation loss: 2.20230625073115

Epoch: 6| Step: 9
Training loss: 1.6136208772659302
Validation loss: 2.1890541315078735

Epoch: 6| Step: 10
Training loss: 1.3711835145950317
Validation loss: 2.1957751512527466

Epoch: 6| Step: 11
Training loss: 1.5028026103973389
Validation loss: 2.1667942007382712

Epoch: 6| Step: 12
Training loss: 1.5182900428771973
Validation loss: 2.162791987260183

Epoch: 6| Step: 13
Training loss: 1.0726292133331299
Validation loss: 2.1757057507832847

Epoch: 304| Step: 0
Training loss: 1.5977803468704224
Validation loss: 2.1681180596351624

Epoch: 6| Step: 1
Training loss: 0.8860001564025879
Validation loss: 2.2198853294054666

Epoch: 6| Step: 2
Training loss: 1.1693910360336304
Validation loss: 2.1786617040634155

Epoch: 6| Step: 3
Training loss: 1.8302606344223022
Validation loss: 2.165623128414154

Epoch: 6| Step: 4
Training loss: 1.481764793395996
Validation loss: 2.154026468594869

Epoch: 6| Step: 5
Training loss: 1.0074403285980225
Validation loss: 2.1761572559674582

Epoch: 6| Step: 6
Training loss: 1.364637851715088
Validation loss: 2.179756780465444

Epoch: 6| Step: 7
Training loss: 0.7685275077819824
Validation loss: 2.1524283289909363

Epoch: 6| Step: 8
Training loss: 2.1559534072875977
Validation loss: 2.1953641970952353

Epoch: 6| Step: 9
Training loss: 1.7679749727249146
Validation loss: 2.199627776940664

Epoch: 6| Step: 10
Training loss: 1.3363007307052612
Validation loss: 2.1579318841298423

Epoch: 6| Step: 11
Training loss: 1.5579712390899658
Validation loss: 2.176594833532969

Epoch: 6| Step: 12
Training loss: 1.4382243156433105
Validation loss: 2.1637211640675864

Epoch: 6| Step: 13
Training loss: 1.5874435901641846
Validation loss: 2.1382784048716226

Epoch: 305| Step: 0
Training loss: 0.9357811212539673
Validation loss: 2.143545945485433

Epoch: 6| Step: 1
Training loss: 1.1424109935760498
Validation loss: 2.195344547430674

Epoch: 6| Step: 2
Training loss: 1.1345590353012085
Validation loss: 2.1853229999542236

Epoch: 6| Step: 3
Training loss: 1.3038543462753296
Validation loss: 2.1575828194618225

Epoch: 6| Step: 4
Training loss: 1.345707893371582
Validation loss: 2.1388646364212036

Epoch: 6| Step: 5
Training loss: 1.7638115882873535
Validation loss: 2.161634306112925

Epoch: 6| Step: 6
Training loss: 1.8788155317306519
Validation loss: 2.152610123157501

Epoch: 6| Step: 7
Training loss: 1.8926355838775635
Validation loss: 2.1529266238212585

Epoch: 6| Step: 8
Training loss: 1.2785674333572388
Validation loss: 2.130588193734487

Epoch: 6| Step: 9
Training loss: 1.2986507415771484
Validation loss: 2.1614817182223

Epoch: 6| Step: 10
Training loss: 2.1226115226745605
Validation loss: 2.1578094164530435

Epoch: 6| Step: 11
Training loss: 1.150946855545044
Validation loss: 2.184761861960093

Epoch: 6| Step: 12
Training loss: 1.4308936595916748
Validation loss: 2.2050790588061013

Epoch: 6| Step: 13
Training loss: 1.3559130430221558
Validation loss: 2.17329603433609

Epoch: 306| Step: 0
Training loss: 1.2080776691436768
Validation loss: 2.1737908720970154

Epoch: 6| Step: 1
Training loss: 1.4815731048583984
Validation loss: 2.1591333548227944

Epoch: 6| Step: 2
Training loss: 1.145296573638916
Validation loss: 2.1583072344462075

Epoch: 6| Step: 3
Training loss: 2.1685729026794434
Validation loss: 2.170115570227305

Epoch: 6| Step: 4
Training loss: 0.49268120527267456
Validation loss: 2.142003834247589

Epoch: 6| Step: 5
Training loss: 0.8239427208900452
Validation loss: 2.1905937989552817

Epoch: 6| Step: 6
Training loss: 1.676969289779663
Validation loss: 2.18139918645223

Epoch: 6| Step: 7
Training loss: 2.540989398956299
Validation loss: 2.2506320675214133

Epoch: 6| Step: 8
Training loss: 2.3749642372131348
Validation loss: 2.270228107770284

Epoch: 6| Step: 9
Training loss: 1.2679364681243896
Validation loss: 2.2564722299575806

Epoch: 6| Step: 10
Training loss: 1.6986651420593262
Validation loss: 2.2370292941729226

Epoch: 6| Step: 11
Training loss: 1.4251987934112549
Validation loss: 2.2155608336130777

Epoch: 6| Step: 12
Training loss: 0.9531162977218628
Validation loss: 2.1746579806009927

Epoch: 6| Step: 13
Training loss: 1.8424131870269775
Validation loss: 2.187428593635559

Epoch: 307| Step: 0
Training loss: 1.8017385005950928
Validation loss: 2.208817720413208

Epoch: 6| Step: 1
Training loss: 2.118391752243042
Validation loss: 2.2146992087364197

Epoch: 6| Step: 2
Training loss: 1.1608777046203613
Validation loss: 2.1875190337498984

Epoch: 6| Step: 3
Training loss: 1.3015693426132202
Validation loss: 2.180630882581075

Epoch: 6| Step: 4
Training loss: 0.8938308358192444
Validation loss: 2.1599634488423667

Epoch: 6| Step: 5
Training loss: 1.345543622970581
Validation loss: 2.218330502510071

Epoch: 6| Step: 6
Training loss: 1.0437862873077393
Validation loss: 2.196765959262848

Epoch: 6| Step: 7
Training loss: 1.095441222190857
Validation loss: 2.1749531030654907

Epoch: 6| Step: 8
Training loss: 1.1250290870666504
Validation loss: 2.2185429334640503

Epoch: 6| Step: 9
Training loss: 1.6117055416107178
Validation loss: 2.205401380856832

Epoch: 6| Step: 10
Training loss: 1.865498423576355
Validation loss: 2.158730228741964

Epoch: 6| Step: 11
Training loss: 1.9560794830322266
Validation loss: 2.172277808189392

Epoch: 6| Step: 12
Training loss: 1.296291470527649
Validation loss: 2.158056080341339

Epoch: 6| Step: 13
Training loss: 1.4717055559158325
Validation loss: 2.1471885244051614

Epoch: 308| Step: 0
Training loss: 2.607318878173828
Validation loss: 2.1710784832636514

Epoch: 6| Step: 1
Training loss: 1.3410115242004395
Validation loss: 2.1661866704622903

Epoch: 6| Step: 2
Training loss: 1.270510196685791
Validation loss: 2.147829751173655

Epoch: 6| Step: 3
Training loss: 2.1523520946502686
Validation loss: 2.150872449080149

Epoch: 6| Step: 4
Training loss: 1.5482121706008911
Validation loss: 2.1786261002222695

Epoch: 6| Step: 5
Training loss: 1.262372374534607
Validation loss: 2.1428653796513877

Epoch: 6| Step: 6
Training loss: 0.8257430791854858
Validation loss: 2.1526615818341575

Epoch: 6| Step: 7
Training loss: 0.9737440347671509
Validation loss: 2.146893084049225

Epoch: 6| Step: 8
Training loss: 0.940377950668335
Validation loss: 2.1622841556866965

Epoch: 6| Step: 9
Training loss: 1.9175580739974976
Validation loss: 2.1199730237325034

Epoch: 6| Step: 10
Training loss: 1.2294549942016602
Validation loss: 2.1557193994522095

Epoch: 6| Step: 11
Training loss: 1.6296353340148926
Validation loss: 2.1514203945795694

Epoch: 6| Step: 12
Training loss: 1.3449612855911255
Validation loss: 2.1396024227142334

Epoch: 6| Step: 13
Training loss: 1.3474522829055786
Validation loss: 2.137967507044474

Epoch: 309| Step: 0
Training loss: 1.2449746131896973
Validation loss: 2.153338154157003

Epoch: 6| Step: 1
Training loss: 1.7612048387527466
Validation loss: 2.100634137789408

Epoch: 6| Step: 2
Training loss: 1.4806914329528809
Validation loss: 2.148574113845825

Epoch: 6| Step: 3
Training loss: 1.4265140295028687
Validation loss: 2.147206882635752

Epoch: 6| Step: 4
Training loss: 1.4542700052261353
Validation loss: 2.1540430386861167

Epoch: 6| Step: 5
Training loss: 1.2161147594451904
Validation loss: 2.190113604068756

Epoch: 6| Step: 6
Training loss: 2.1023576259613037
Validation loss: 2.1666811108589172

Epoch: 6| Step: 7
Training loss: 1.2078205347061157
Validation loss: 2.148428956667582

Epoch: 6| Step: 8
Training loss: 2.1026875972747803
Validation loss: 2.1777029434839883

Epoch: 6| Step: 9
Training loss: 1.2170617580413818
Validation loss: 2.1875120798746743

Epoch: 6| Step: 10
Training loss: 1.7177307605743408
Validation loss: 2.1873515844345093

Epoch: 6| Step: 11
Training loss: 1.0112026929855347
Validation loss: 2.15596604347229

Epoch: 6| Step: 12
Training loss: 1.0680650472640991
Validation loss: 2.184578279654185

Epoch: 6| Step: 13
Training loss: 1.2020822763442993
Validation loss: 2.2149789730707803

Epoch: 310| Step: 0
Training loss: 1.565770149230957
Validation loss: 2.175406793753306

Epoch: 6| Step: 1
Training loss: 1.7970994710922241
Validation loss: 2.217895487944285

Epoch: 6| Step: 2
Training loss: 1.4589502811431885
Validation loss: 2.1789033810297647

Epoch: 6| Step: 3
Training loss: 1.3487582206726074
Validation loss: 2.1786094903945923

Epoch: 6| Step: 4
Training loss: 2.39670991897583
Validation loss: 2.130159099896749

Epoch: 6| Step: 5
Training loss: 1.8349500894546509
Validation loss: 2.156596004962921

Epoch: 6| Step: 6
Training loss: 1.5664360523223877
Validation loss: 2.103713870048523

Epoch: 6| Step: 7
Training loss: 0.9074680209159851
Validation loss: 2.1045502026875815

Epoch: 6| Step: 8
Training loss: 1.119964599609375
Validation loss: 2.13588680823644

Epoch: 6| Step: 9
Training loss: 1.3229565620422363
Validation loss: 2.145348529020945

Epoch: 6| Step: 10
Training loss: 1.9066307544708252
Validation loss: 2.14615797996521

Epoch: 6| Step: 11
Training loss: 1.2514784336090088
Validation loss: 2.1984945138295493

Epoch: 6| Step: 12
Training loss: 1.368454098701477
Validation loss: 2.19522358973821

Epoch: 6| Step: 13
Training loss: 0.8868779540061951
Validation loss: 2.171483794848124

Epoch: 311| Step: 0
Training loss: 1.6855947971343994
Validation loss: 2.205879588921865

Epoch: 6| Step: 1
Training loss: 1.8524471521377563
Validation loss: 2.1709614793459573

Epoch: 6| Step: 2
Training loss: 1.080721378326416
Validation loss: 2.2373223106066384

Epoch: 6| Step: 3
Training loss: 1.1944310665130615
Validation loss: 2.1877347230911255

Epoch: 6| Step: 4
Training loss: 0.973777174949646
Validation loss: 2.22634486357371

Epoch: 6| Step: 5
Training loss: 1.6463210582733154
Validation loss: 2.230010191599528

Epoch: 6| Step: 6
Training loss: 0.9557445645332336
Validation loss: 2.2205445965131125

Epoch: 6| Step: 7
Training loss: 1.583890676498413
Validation loss: 2.2409540017445884

Epoch: 6| Step: 8
Training loss: 1.363145112991333
Validation loss: 2.2186723152796426

Epoch: 6| Step: 9
Training loss: 1.5091971158981323
Validation loss: 2.233585218588511

Epoch: 6| Step: 10
Training loss: 1.0492515563964844
Validation loss: 2.2560143868128457

Epoch: 6| Step: 11
Training loss: 1.5769789218902588
Validation loss: 2.1992092529932656

Epoch: 6| Step: 12
Training loss: 1.4081202745437622
Validation loss: 2.223179598649343

Epoch: 6| Step: 13
Training loss: 1.7166900634765625
Validation loss: 2.2176947593688965

Epoch: 312| Step: 0
Training loss: 1.853712558746338
Validation loss: 2.2500282327334085

Epoch: 6| Step: 1
Training loss: 1.6983609199523926
Validation loss: 2.214583158493042

Epoch: 6| Step: 2
Training loss: 0.9661372303962708
Validation loss: 2.2509467204411826

Epoch: 6| Step: 3
Training loss: 1.748147964477539
Validation loss: 2.240227699279785

Epoch: 6| Step: 4
Training loss: 1.4087969064712524
Validation loss: 2.223666548728943

Epoch: 6| Step: 5
Training loss: 0.9430023431777954
Validation loss: 2.1892602841059365

Epoch: 6| Step: 6
Training loss: 1.6141481399536133
Validation loss: 2.131720761458079

Epoch: 6| Step: 7
Training loss: 1.1142503023147583
Validation loss: 2.168299754460653

Epoch: 6| Step: 8
Training loss: 1.2272412776947021
Validation loss: 2.1387294928232827

Epoch: 6| Step: 9
Training loss: 1.5838522911071777
Validation loss: 2.163699726263682

Epoch: 6| Step: 10
Training loss: 2.1023359298706055
Validation loss: 2.1791681249936423

Epoch: 6| Step: 11
Training loss: 1.405982255935669
Validation loss: 2.1845003167788186

Epoch: 6| Step: 12
Training loss: 1.2501978874206543
Validation loss: 2.24856690565745

Epoch: 6| Step: 13
Training loss: 1.0667202472686768
Validation loss: 2.2128813664118447

Epoch: 313| Step: 0
Training loss: 1.7652528285980225
Validation loss: 2.2319711446762085

Epoch: 6| Step: 1
Training loss: 1.7539105415344238
Validation loss: 2.193628430366516

Epoch: 6| Step: 2
Training loss: 0.8144400119781494
Validation loss: 2.1842278043429055

Epoch: 6| Step: 3
Training loss: 1.235518455505371
Validation loss: 2.2031771739323935

Epoch: 6| Step: 4
Training loss: 1.3283320665359497
Validation loss: 2.196447173754374

Epoch: 6| Step: 5
Training loss: 1.700456142425537
Validation loss: 2.194126526514689

Epoch: 6| Step: 6
Training loss: 1.8037692308425903
Validation loss: 2.21463676293691

Epoch: 6| Step: 7
Training loss: 0.9490655660629272
Validation loss: 2.186611751715342

Epoch: 6| Step: 8
Training loss: 1.6641783714294434
Validation loss: 2.210780382156372

Epoch: 6| Step: 9
Training loss: 1.2081069946289062
Validation loss: 2.174757719039917

Epoch: 6| Step: 10
Training loss: 1.5004844665527344
Validation loss: 2.1639216542243958

Epoch: 6| Step: 11
Training loss: 1.2258825302124023
Validation loss: 2.1687092185020447

Epoch: 6| Step: 12
Training loss: 1.575471043586731
Validation loss: 2.17572412888209

Epoch: 6| Step: 13
Training loss: 1.2436985969543457
Validation loss: 2.174235244592031

Epoch: 314| Step: 0
Training loss: 0.7402501106262207
Validation loss: 2.183968941370646

Epoch: 6| Step: 1
Training loss: 1.1364130973815918
Validation loss: 2.2037718693415322

Epoch: 6| Step: 2
Training loss: 0.9844268560409546
Validation loss: 2.239930788675944

Epoch: 6| Step: 3
Training loss: 1.276166558265686
Validation loss: 2.182665844758352

Epoch: 6| Step: 4
Training loss: 1.62071692943573
Validation loss: 2.1824395259221396

Epoch: 6| Step: 5
Training loss: 0.9463380575180054
Validation loss: 2.209528942902883

Epoch: 6| Step: 6
Training loss: 1.5604112148284912
Validation loss: 2.22287126382192

Epoch: 6| Step: 7
Training loss: 1.3244420289993286
Validation loss: 2.176607847213745

Epoch: 6| Step: 8
Training loss: 1.633713722229004
Validation loss: 2.207611163457235

Epoch: 6| Step: 9
Training loss: 1.811547875404358
Validation loss: 2.2039860486984253

Epoch: 6| Step: 10
Training loss: 1.7288434505462646
Validation loss: 2.2194676995277405

Epoch: 6| Step: 11
Training loss: 1.13062584400177
Validation loss: 2.1980318427085876

Epoch: 6| Step: 12
Training loss: 1.3049054145812988
Validation loss: 2.1648407181104026

Epoch: 6| Step: 13
Training loss: 1.6898243427276611
Validation loss: 2.1600513458251953

Epoch: 315| Step: 0
Training loss: 1.4636904001235962
Validation loss: 2.17678431669871

Epoch: 6| Step: 1
Training loss: 1.9687398672103882
Validation loss: 2.1945101618766785

Epoch: 6| Step: 2
Training loss: 1.0067846775054932
Validation loss: 2.222824970881144

Epoch: 6| Step: 3
Training loss: 1.3991241455078125
Validation loss: 2.2392491698265076

Epoch: 6| Step: 4
Training loss: 0.9662467241287231
Validation loss: 2.245269159475962

Epoch: 6| Step: 5
Training loss: 1.2298393249511719
Validation loss: 2.2412436803181968

Epoch: 6| Step: 6
Training loss: 1.1018884181976318
Validation loss: 2.226239641507467

Epoch: 6| Step: 7
Training loss: 1.3890029191970825
Validation loss: 2.1404664715131125

Epoch: 6| Step: 8
Training loss: 1.431329369544983
Validation loss: 2.1341813802719116

Epoch: 6| Step: 9
Training loss: 1.3121371269226074
Validation loss: 2.1521962682406106

Epoch: 6| Step: 10
Training loss: 1.4077558517456055
Validation loss: 2.144983688990275

Epoch: 6| Step: 11
Training loss: 2.465987205505371
Validation loss: 2.1476190288861594

Epoch: 6| Step: 12
Training loss: 1.173464298248291
Validation loss: 2.1647974650065103

Epoch: 6| Step: 13
Training loss: 1.2470289468765259
Validation loss: 2.1654959122339883

Epoch: 316| Step: 0
Training loss: 1.1354100704193115
Validation loss: 2.1984657645225525

Epoch: 6| Step: 1
Training loss: 1.5102713108062744
Validation loss: 2.239842693010966

Epoch: 6| Step: 2
Training loss: 1.9563968181610107
Validation loss: 2.1926799217859902

Epoch: 6| Step: 3
Training loss: 0.8164319396018982
Validation loss: 2.16112228234609

Epoch: 6| Step: 4
Training loss: 1.4055562019348145
Validation loss: 2.1612982749938965

Epoch: 6| Step: 5
Training loss: 1.5233166217803955
Validation loss: 2.145078440507253

Epoch: 6| Step: 6
Training loss: 0.9834437966346741
Validation loss: 2.146904230117798

Epoch: 6| Step: 7
Training loss: 1.869488000869751
Validation loss: 2.1656614939371743

Epoch: 6| Step: 8
Training loss: 1.1557209491729736
Validation loss: 2.1530948082605996

Epoch: 6| Step: 9
Training loss: 2.7541494369506836
Validation loss: 2.1608835458755493

Epoch: 6| Step: 10
Training loss: 1.5978001356124878
Validation loss: 2.155657152334849

Epoch: 6| Step: 11
Training loss: 0.7347568273544312
Validation loss: 2.1475356618563333

Epoch: 6| Step: 12
Training loss: 0.8843502998352051
Validation loss: 2.1019218961397805

Epoch: 6| Step: 13
Training loss: 1.2374769449234009
Validation loss: 2.1020341714223227

Epoch: 317| Step: 0
Training loss: 1.688027262687683
Validation loss: 2.1167539755503335

Epoch: 6| Step: 1
Training loss: 1.5146856307983398
Validation loss: 2.14806334177653

Epoch: 6| Step: 2
Training loss: 1.7678196430206299
Validation loss: 2.2061029275258384

Epoch: 6| Step: 3
Training loss: 1.3808085918426514
Validation loss: 2.2001913189888

Epoch: 6| Step: 4
Training loss: 1.4533330202102661
Validation loss: 2.176991820335388

Epoch: 6| Step: 5
Training loss: 1.2160444259643555
Validation loss: 2.2040608326594033

Epoch: 6| Step: 6
Training loss: 1.006771445274353
Validation loss: 2.1981223821640015

Epoch: 6| Step: 7
Training loss: 1.575190782546997
Validation loss: 2.170703093210856

Epoch: 6| Step: 8
Training loss: 1.6566717624664307
Validation loss: 2.176546891530355

Epoch: 6| Step: 9
Training loss: 1.5951159000396729
Validation loss: 2.152554909388224

Epoch: 6| Step: 10
Training loss: 1.137210488319397
Validation loss: 2.130207081635793

Epoch: 6| Step: 11
Training loss: 1.6145504713058472
Validation loss: 2.1325844526290894

Epoch: 6| Step: 12
Training loss: 1.4433385133743286
Validation loss: 2.1237815618515015

Epoch: 6| Step: 13
Training loss: 1.5464954376220703
Validation loss: 2.1598514715830484

Epoch: 318| Step: 0
Training loss: 0.8507776260375977
Validation loss: 2.1549528439839682

Epoch: 6| Step: 1
Training loss: 1.7085087299346924
Validation loss: 2.2042519251505532

Epoch: 6| Step: 2
Training loss: 1.2253952026367188
Validation loss: 2.1813085675239563

Epoch: 6| Step: 3
Training loss: 2.130524158477783
Validation loss: 2.1820081075032554

Epoch: 6| Step: 4
Training loss: 1.428943157196045
Validation loss: 2.1625596284866333

Epoch: 6| Step: 5
Training loss: 0.5315740704536438
Validation loss: 2.1695719162623086

Epoch: 6| Step: 6
Training loss: 1.2814018726348877
Validation loss: 2.168734133243561

Epoch: 6| Step: 7
Training loss: 1.1881357431411743
Validation loss: 2.1754554311434426

Epoch: 6| Step: 8
Training loss: 1.9780606031417847
Validation loss: 2.1897930900255838

Epoch: 6| Step: 9
Training loss: 1.784523844718933
Validation loss: 2.1609840790430703

Epoch: 6| Step: 10
Training loss: 1.477669596672058
Validation loss: 2.220969339211782

Epoch: 6| Step: 11
Training loss: 1.5638926029205322
Validation loss: 2.246824582417806

Epoch: 6| Step: 12
Training loss: 2.2855236530303955
Validation loss: 2.223646958669027

Epoch: 6| Step: 13
Training loss: 1.1867091655731201
Validation loss: 2.1905288696289062

Epoch: 319| Step: 0
Training loss: 0.9549617767333984
Validation loss: 2.1707573334376016

Epoch: 6| Step: 1
Training loss: 1.3793330192565918
Validation loss: 2.1923813025156655

Epoch: 6| Step: 2
Training loss: 2.0140326023101807
Validation loss: 2.166524132092794

Epoch: 6| Step: 3
Training loss: 0.7014843821525574
Validation loss: 2.190515478452047

Epoch: 6| Step: 4
Training loss: 0.8199763298034668
Validation loss: 2.182005743185679

Epoch: 6| Step: 5
Training loss: 1.2108808755874634
Validation loss: 2.1752336025238037

Epoch: 6| Step: 6
Training loss: 1.5514283180236816
Validation loss: 2.189045508702596

Epoch: 6| Step: 7
Training loss: 1.6934905052185059
Validation loss: 2.271575669447581

Epoch: 6| Step: 8
Training loss: 1.7475700378417969
Validation loss: 2.2283068696657815

Epoch: 6| Step: 9
Training loss: 1.1792689561843872
Validation loss: 2.2312163710594177

Epoch: 6| Step: 10
Training loss: 1.8482630252838135
Validation loss: 2.230513095855713

Epoch: 6| Step: 11
Training loss: 1.369947075843811
Validation loss: 2.2842525243759155

Epoch: 6| Step: 12
Training loss: 1.4826792478561401
Validation loss: 2.2914434671401978

Epoch: 6| Step: 13
Training loss: 1.1275606155395508
Validation loss: 2.278303782145182

Epoch: 320| Step: 0
Training loss: 1.779109001159668
Validation loss: 2.233766178290049

Epoch: 6| Step: 1
Training loss: 1.157257080078125
Validation loss: 2.2358619372049966

Epoch: 6| Step: 2
Training loss: 1.1245834827423096
Validation loss: 2.2363617618878684

Epoch: 6| Step: 3
Training loss: 1.5127592086791992
Validation loss: 2.2200668255488076

Epoch: 6| Step: 4
Training loss: 1.4188134670257568
Validation loss: 2.2421993017196655

Epoch: 6| Step: 5
Training loss: 1.7790727615356445
Validation loss: 2.1979751189549765

Epoch: 6| Step: 6
Training loss: 0.73450767993927
Validation loss: 2.1999041040738425

Epoch: 6| Step: 7
Training loss: 1.0437583923339844
Validation loss: 2.185047686100006

Epoch: 6| Step: 8
Training loss: 1.2584419250488281
Validation loss: 2.1729621291160583

Epoch: 6| Step: 9
Training loss: 1.7350261211395264
Validation loss: 2.212274173895518

Epoch: 6| Step: 10
Training loss: 1.371809482574463
Validation loss: 2.1565329233805337

Epoch: 6| Step: 11
Training loss: 0.8524364233016968
Validation loss: 2.1903477708498635

Epoch: 6| Step: 12
Training loss: 1.8001174926757812
Validation loss: 2.145822743574778

Epoch: 6| Step: 13
Training loss: 1.3833427429199219
Validation loss: 2.1287012497584024

Epoch: 321| Step: 0
Training loss: 1.2506561279296875
Validation loss: 2.159191826979319

Epoch: 6| Step: 1
Training loss: 1.6135075092315674
Validation loss: 2.1506857872009277

Epoch: 6| Step: 2
Training loss: 1.2170941829681396
Validation loss: 2.2236028909683228

Epoch: 6| Step: 3
Training loss: 1.490321397781372
Validation loss: 2.22839617729187

Epoch: 6| Step: 4
Training loss: 1.4963221549987793
Validation loss: 2.2227478623390198

Epoch: 6| Step: 5
Training loss: 1.4893490076065063
Validation loss: 2.2372891704241433

Epoch: 6| Step: 6
Training loss: 1.617456078529358
Validation loss: 2.1989285945892334

Epoch: 6| Step: 7
Training loss: 1.0220729112625122
Validation loss: 2.157531181971232

Epoch: 6| Step: 8
Training loss: 1.5627247095108032
Validation loss: 2.1287651459376016

Epoch: 6| Step: 9
Training loss: 1.6418713331222534
Validation loss: 2.174922545750936

Epoch: 6| Step: 10
Training loss: 1.1377209424972534
Validation loss: 2.166330397129059

Epoch: 6| Step: 11
Training loss: 0.8423870801925659
Validation loss: 2.1653387546539307

Epoch: 6| Step: 12
Training loss: 1.6682915687561035
Validation loss: 2.1680031021436057

Epoch: 6| Step: 13
Training loss: 1.4115618467330933
Validation loss: 2.1251376469930015

Epoch: 322| Step: 0
Training loss: 1.308444857597351
Validation loss: 2.1830126841863

Epoch: 6| Step: 1
Training loss: 1.080042839050293
Validation loss: 2.2638368209203086

Epoch: 6| Step: 2
Training loss: 1.0278584957122803
Validation loss: 2.215766946474711

Epoch: 6| Step: 3
Training loss: 1.013228178024292
Validation loss: 2.2011516094207764

Epoch: 6| Step: 4
Training loss: 0.9141330718994141
Validation loss: 2.209006130695343

Epoch: 6| Step: 5
Training loss: 1.3079475164413452
Validation loss: 2.1764143904050193

Epoch: 6| Step: 6
Training loss: 1.2518417835235596
Validation loss: 2.1586671272913613

Epoch: 6| Step: 7
Training loss: 2.3446695804595947
Validation loss: 2.155540664990743

Epoch: 6| Step: 8
Training loss: 0.9547322988510132
Validation loss: 2.1309943795204163

Epoch: 6| Step: 9
Training loss: 1.3459372520446777
Validation loss: 2.110988756020864

Epoch: 6| Step: 10
Training loss: 1.190194845199585
Validation loss: 2.164517422517141

Epoch: 6| Step: 11
Training loss: 1.7995400428771973
Validation loss: 2.1603295604387918

Epoch: 6| Step: 12
Training loss: 1.196163296699524
Validation loss: 2.18968000014623

Epoch: 6| Step: 13
Training loss: 1.9504985809326172
Validation loss: 2.2028473019599915

Epoch: 323| Step: 0
Training loss: 1.232980728149414
Validation loss: 2.212713837623596

Epoch: 6| Step: 1
Training loss: 2.5390355587005615
Validation loss: 2.173041899998983

Epoch: 6| Step: 2
Training loss: 1.4057996273040771
Validation loss: 2.148966670036316

Epoch: 6| Step: 3
Training loss: 1.1957417726516724
Validation loss: 2.166166603565216

Epoch: 6| Step: 4
Training loss: 1.0580995082855225
Validation loss: 2.166126847267151

Epoch: 6| Step: 5
Training loss: 0.6323379278182983
Validation loss: 2.144058048725128

Epoch: 6| Step: 6
Training loss: 1.5491666793823242
Validation loss: 2.135296960671743

Epoch: 6| Step: 7
Training loss: 1.5435757637023926
Validation loss: 2.122540215651194

Epoch: 6| Step: 8
Training loss: 1.181543231010437
Validation loss: 2.1531368295351663

Epoch: 6| Step: 9
Training loss: 1.3455963134765625
Validation loss: 2.1354874968528748

Epoch: 6| Step: 10
Training loss: 1.3120498657226562
Validation loss: 2.1276413400967917

Epoch: 6| Step: 11
Training loss: 1.2177265882492065
Validation loss: 2.193721652030945

Epoch: 6| Step: 12
Training loss: 1.5444655418395996
Validation loss: 2.191756288210551

Epoch: 6| Step: 13
Training loss: 1.0954060554504395
Validation loss: 2.235981067021688

Epoch: 324| Step: 0
Training loss: 2.7487680912017822
Validation loss: 2.2086374958356223

Epoch: 6| Step: 1
Training loss: 1.4202995300292969
Validation loss: 2.2309568325678506

Epoch: 6| Step: 2
Training loss: 1.212664246559143
Validation loss: 2.238353133201599

Epoch: 6| Step: 3
Training loss: 1.177215814590454
Validation loss: 2.2297505338986716

Epoch: 6| Step: 4
Training loss: 1.373002052307129
Validation loss: 2.196085294087728

Epoch: 6| Step: 5
Training loss: 1.576249599456787
Validation loss: 2.1782554388046265

Epoch: 6| Step: 6
Training loss: 1.5442315340042114
Validation loss: 2.1505319674809775

Epoch: 6| Step: 7
Training loss: 0.5841472148895264
Validation loss: 2.1217037439346313

Epoch: 6| Step: 8
Training loss: 0.998225748538971
Validation loss: 2.1036221186319985

Epoch: 6| Step: 9
Training loss: 1.8331892490386963
Validation loss: 2.1576091647148132

Epoch: 6| Step: 10
Training loss: 1.2143645286560059
Validation loss: 2.112809181213379

Epoch: 6| Step: 11
Training loss: 1.2348793745040894
Validation loss: 2.129499912261963

Epoch: 6| Step: 12
Training loss: 1.201948642730713
Validation loss: 2.163679540157318

Epoch: 6| Step: 13
Training loss: 0.6530039310455322
Validation loss: 2.1748811403910318

Epoch: 325| Step: 0
Training loss: 0.7585333585739136
Validation loss: 2.1659541527430215

Epoch: 6| Step: 1
Training loss: 1.048530101776123
Validation loss: 2.130692938963572

Epoch: 6| Step: 2
Training loss: 1.133286952972412
Validation loss: 2.1370591521263123

Epoch: 6| Step: 3
Training loss: 1.706524133682251
Validation loss: 2.155421257019043

Epoch: 6| Step: 4
Training loss: 1.3481783866882324
Validation loss: 2.1374814907709756

Epoch: 6| Step: 5
Training loss: 1.2261497974395752
Validation loss: 2.1594735781351724

Epoch: 6| Step: 6
Training loss: 1.3013949394226074
Validation loss: 2.1746598283449807

Epoch: 6| Step: 7
Training loss: 1.4179041385650635
Validation loss: 2.166742225488027

Epoch: 6| Step: 8
Training loss: 0.9726089239120483
Validation loss: 2.175169587135315

Epoch: 6| Step: 9
Training loss: 0.9653491973876953
Validation loss: 2.1555614471435547

Epoch: 6| Step: 10
Training loss: 0.753880500793457
Validation loss: 2.176345964272817

Epoch: 6| Step: 11
Training loss: 1.3761584758758545
Validation loss: 2.136083662509918

Epoch: 6| Step: 12
Training loss: 1.9588704109191895
Validation loss: 2.145313282807668

Epoch: 6| Step: 13
Training loss: 1.717174768447876
Validation loss: 2.19799413283666

Epoch: 326| Step: 0
Training loss: 1.8932714462280273
Validation loss: 2.1493599812189736

Epoch: 6| Step: 1
Training loss: 0.9120484590530396
Validation loss: 2.1658503214518228

Epoch: 6| Step: 2
Training loss: 1.2072699069976807
Validation loss: 2.1138042410214744

Epoch: 6| Step: 3
Training loss: 1.7851893901824951
Validation loss: 2.1455345948537192

Epoch: 6| Step: 4
Training loss: 0.6021276116371155
Validation loss: 2.1032586892445884

Epoch: 6| Step: 5
Training loss: 1.717012882232666
Validation loss: 2.1490209897359214

Epoch: 6| Step: 6
Training loss: 0.9949378967285156
Validation loss: 2.1370110511779785

Epoch: 6| Step: 7
Training loss: 0.7498285174369812
Validation loss: 2.160318116346995

Epoch: 6| Step: 8
Training loss: 1.3432978391647339
Validation loss: 2.1668169101079306

Epoch: 6| Step: 9
Training loss: 1.5629956722259521
Validation loss: 2.10559610525767

Epoch: 6| Step: 10
Training loss: 0.9329240918159485
Validation loss: 2.159199337164561

Epoch: 6| Step: 11
Training loss: 1.2948228120803833
Validation loss: 2.1670855482419333

Epoch: 6| Step: 12
Training loss: 1.0237199068069458
Validation loss: 2.1683016618092856

Epoch: 6| Step: 13
Training loss: 1.4962975978851318
Validation loss: 2.200856029987335

Epoch: 327| Step: 0
Training loss: 1.5140647888183594
Validation loss: 2.185605804125468

Epoch: 6| Step: 1
Training loss: 1.4582524299621582
Validation loss: 2.1855810085932412

Epoch: 6| Step: 2
Training loss: 0.9321382641792297
Validation loss: 2.218034783999125

Epoch: 6| Step: 3
Training loss: 1.3189949989318848
Validation loss: 2.193890909353892

Epoch: 6| Step: 4
Training loss: 1.323297381401062
Validation loss: 2.20620463291804

Epoch: 6| Step: 5
Training loss: 2.3281421661376953
Validation loss: 2.2306092977523804

Epoch: 6| Step: 6
Training loss: 0.6768441796302795
Validation loss: 2.2059850295384726

Epoch: 6| Step: 7
Training loss: 0.9584156274795532
Validation loss: 2.178748349348704

Epoch: 6| Step: 8
Training loss: 1.313838243484497
Validation loss: 2.1988514264424643

Epoch: 6| Step: 9
Training loss: 1.2844631671905518
Validation loss: 2.16183348496755

Epoch: 6| Step: 10
Training loss: 0.9727213978767395
Validation loss: 2.128737986087799

Epoch: 6| Step: 11
Training loss: 0.8345543742179871
Validation loss: 2.152419328689575

Epoch: 6| Step: 12
Training loss: 1.1839275360107422
Validation loss: 2.1344033082326255

Epoch: 6| Step: 13
Training loss: 2.023693799972534
Validation loss: 2.1626381476720176

Epoch: 328| Step: 0
Training loss: 0.7531455755233765
Validation loss: 2.176842451095581

Epoch: 6| Step: 1
Training loss: 1.3183507919311523
Validation loss: 2.209869682788849

Epoch: 6| Step: 2
Training loss: 0.9737949967384338
Validation loss: 2.161823550860087

Epoch: 6| Step: 3
Training loss: 1.5364973545074463
Validation loss: 2.141285459200541

Epoch: 6| Step: 4
Training loss: 0.8045263290405273
Validation loss: 2.1837055881818137

Epoch: 6| Step: 5
Training loss: 1.581854224205017
Validation loss: 2.1607059240341187

Epoch: 6| Step: 6
Training loss: 1.8816111087799072
Validation loss: 2.2030908266703286

Epoch: 6| Step: 7
Training loss: 1.7482489347457886
Validation loss: 2.139819542566935

Epoch: 6| Step: 8
Training loss: 1.7988914251327515
Validation loss: 2.1136569579442344

Epoch: 6| Step: 9
Training loss: 0.7064238786697388
Validation loss: 2.1482165654500327

Epoch: 6| Step: 10
Training loss: 1.1109349727630615
Validation loss: 2.1453537742296853

Epoch: 6| Step: 11
Training loss: 1.0501261949539185
Validation loss: 2.172795554002126

Epoch: 6| Step: 12
Training loss: 1.5917021036148071
Validation loss: 2.202170451482137

Epoch: 6| Step: 13
Training loss: 0.7955452799797058
Validation loss: 2.196242094039917

Epoch: 329| Step: 0
Training loss: 0.944023609161377
Validation loss: 2.1894346872965493

Epoch: 6| Step: 1
Training loss: 0.7661207914352417
Validation loss: 2.184453328450521

Epoch: 6| Step: 2
Training loss: 1.1478941440582275
Validation loss: 2.16651580731074

Epoch: 6| Step: 3
Training loss: 0.8715062141418457
Validation loss: 2.159002979596456

Epoch: 6| Step: 4
Training loss: 1.3207728862762451
Validation loss: 2.1711577574412027

Epoch: 6| Step: 5
Training loss: 1.1326203346252441
Validation loss: 2.124837895234426

Epoch: 6| Step: 6
Training loss: 2.2820162773132324
Validation loss: 2.1277242501576743

Epoch: 6| Step: 7
Training loss: 0.8666285276412964
Validation loss: 2.131360669930776

Epoch: 6| Step: 8
Training loss: 2.0232343673706055
Validation loss: 2.165667017300924

Epoch: 6| Step: 9
Training loss: 1.0254998207092285
Validation loss: 2.2010576526323953

Epoch: 6| Step: 10
Training loss: 1.2350711822509766
Validation loss: 2.2666558821996055

Epoch: 6| Step: 11
Training loss: 1.8140980005264282
Validation loss: 2.2107656002044678

Epoch: 6| Step: 12
Training loss: 1.4423414468765259
Validation loss: 2.206262489159902

Epoch: 6| Step: 13
Training loss: 0.9272549152374268
Validation loss: 2.244404415289561

Epoch: 330| Step: 0
Training loss: 1.3889942169189453
Validation loss: 2.2021721800168357

Epoch: 6| Step: 1
Training loss: 1.2507368326187134
Validation loss: 2.215364376703898

Epoch: 6| Step: 2
Training loss: 0.994817852973938
Validation loss: 2.156345804532369

Epoch: 6| Step: 3
Training loss: 0.9667635560035706
Validation loss: 2.1300215125083923

Epoch: 6| Step: 4
Training loss: 1.606569528579712
Validation loss: 2.101310928662618

Epoch: 6| Step: 5
Training loss: 0.9910551905632019
Validation loss: 2.1235640048980713

Epoch: 6| Step: 6
Training loss: 1.3200571537017822
Validation loss: 2.1162525415420532

Epoch: 6| Step: 7
Training loss: 1.3588796854019165
Validation loss: 2.1126680970191956

Epoch: 6| Step: 8
Training loss: 1.216935634613037
Validation loss: 2.1386918425559998

Epoch: 6| Step: 9
Training loss: 1.9548676013946533
Validation loss: 2.162875016530355

Epoch: 6| Step: 10
Training loss: 1.30403733253479
Validation loss: 2.080786406993866

Epoch: 6| Step: 11
Training loss: 1.3727571964263916
Validation loss: 2.165402054786682

Epoch: 6| Step: 12
Training loss: 1.411820411682129
Validation loss: 2.1342125137646994

Epoch: 6| Step: 13
Training loss: 0.71617591381073
Validation loss: 2.1949169635772705

Epoch: 331| Step: 0
Training loss: 1.0566256046295166
Validation loss: 2.2108609080314636

Epoch: 6| Step: 1
Training loss: 1.4359335899353027
Validation loss: 2.1758082707722983

Epoch: 6| Step: 2
Training loss: 1.1055083274841309
Validation loss: 2.1525075435638428

Epoch: 6| Step: 3
Training loss: 1.3984853029251099
Validation loss: 2.1490622758865356

Epoch: 6| Step: 4
Training loss: 1.9289524555206299
Validation loss: 2.130644420782725

Epoch: 6| Step: 5
Training loss: 1.8293285369873047
Validation loss: 2.092346489429474

Epoch: 6| Step: 6
Training loss: 1.0831270217895508
Validation loss: 2.1178569992383323

Epoch: 6| Step: 7
Training loss: 0.611710786819458
Validation loss: 2.1000202298164368

Epoch: 6| Step: 8
Training loss: 0.7567427158355713
Validation loss: 2.130564788977305

Epoch: 6| Step: 9
Training loss: 1.9976725578308105
Validation loss: 2.146260440349579

Epoch: 6| Step: 10
Training loss: 1.0590401887893677
Validation loss: 2.1699694792429605

Epoch: 6| Step: 11
Training loss: 1.489469051361084
Validation loss: 2.1929548184076944

Epoch: 6| Step: 12
Training loss: 0.9370739459991455
Validation loss: 2.209042569001516

Epoch: 6| Step: 13
Training loss: 1.197441816329956
Validation loss: 2.193250596523285

Epoch: 332| Step: 0
Training loss: 1.3345187902450562
Validation loss: 2.171373466650645

Epoch: 6| Step: 1
Training loss: 1.215440273284912
Validation loss: 2.136163115501404

Epoch: 6| Step: 2
Training loss: 2.0297417640686035
Validation loss: 2.1733319560686746

Epoch: 6| Step: 3
Training loss: 1.7072876691818237
Validation loss: 2.1815290252367654

Epoch: 6| Step: 4
Training loss: 1.2946712970733643
Validation loss: 2.1577815612157187

Epoch: 6| Step: 5
Training loss: 0.8695400953292847
Validation loss: 2.1753385861714682

Epoch: 6| Step: 6
Training loss: 0.820510745048523
Validation loss: 2.188356856505076

Epoch: 6| Step: 7
Training loss: 0.8284786939620972
Validation loss: 2.1877997716267905

Epoch: 6| Step: 8
Training loss: 1.0075697898864746
Validation loss: 2.1962216893831887

Epoch: 6| Step: 9
Training loss: 1.3824224472045898
Validation loss: 2.1596153577168784

Epoch: 6| Step: 10
Training loss: 0.9130890369415283
Validation loss: 2.174346307913462

Epoch: 6| Step: 11
Training loss: 1.8295872211456299
Validation loss: 2.164181649684906

Epoch: 6| Step: 12
Training loss: 1.2581385374069214
Validation loss: 2.1485181053479514

Epoch: 6| Step: 13
Training loss: 1.2816362380981445
Validation loss: 2.1280792554219565

Epoch: 333| Step: 0
Training loss: 1.4266254901885986
Validation loss: 2.1379404067993164

Epoch: 6| Step: 1
Training loss: 0.871351957321167
Validation loss: 2.1254800955454507

Epoch: 6| Step: 2
Training loss: 1.6340949535369873
Validation loss: 2.1383314728736877

Epoch: 6| Step: 3
Training loss: 1.1622943878173828
Validation loss: 2.0900201002756753

Epoch: 6| Step: 4
Training loss: 1.6329774856567383
Validation loss: 2.1281431317329407

Epoch: 6| Step: 5
Training loss: 1.1763404607772827
Validation loss: 2.1136982838312783

Epoch: 6| Step: 6
Training loss: 0.8671071529388428
Validation loss: 2.105070153872172

Epoch: 6| Step: 7
Training loss: 1.0572367906570435
Validation loss: 2.1232568422953286

Epoch: 6| Step: 8
Training loss: 1.3506301641464233
Validation loss: 2.1040901144345603

Epoch: 6| Step: 9
Training loss: 1.1162610054016113
Validation loss: 2.0985761880874634

Epoch: 6| Step: 10
Training loss: 1.3387181758880615
Validation loss: 2.07018389304479

Epoch: 6| Step: 11
Training loss: 1.6471130847930908
Validation loss: 2.1231875816980996

Epoch: 6| Step: 12
Training loss: 0.9784961938858032
Validation loss: 2.120315512021383

Epoch: 6| Step: 13
Training loss: 0.9611303210258484
Validation loss: 2.1082310676574707

Epoch: 334| Step: 0
Training loss: 1.4801464080810547
Validation loss: 2.112637976805369

Epoch: 6| Step: 1
Training loss: 1.0191829204559326
Validation loss: 2.141702711582184

Epoch: 6| Step: 2
Training loss: 1.272599458694458
Validation loss: 2.1666656732559204

Epoch: 6| Step: 3
Training loss: 0.9021952152252197
Validation loss: 2.1960984071095786

Epoch: 6| Step: 4
Training loss: 1.0724210739135742
Validation loss: 2.1954994599024453

Epoch: 6| Step: 5
Training loss: 0.8691946268081665
Validation loss: 2.189672291278839

Epoch: 6| Step: 6
Training loss: 1.2240523099899292
Validation loss: 2.216394523779551

Epoch: 6| Step: 7
Training loss: 0.9407782554626465
Validation loss: 2.174875636895498

Epoch: 6| Step: 8
Training loss: 2.0140321254730225
Validation loss: 2.1448696851730347

Epoch: 6| Step: 9
Training loss: 1.4855685234069824
Validation loss: 2.1328084071477256

Epoch: 6| Step: 10
Training loss: 1.477146863937378
Validation loss: 2.1457720597585044

Epoch: 6| Step: 11
Training loss: 1.2382173538208008
Validation loss: 2.1178952852884927

Epoch: 6| Step: 12
Training loss: 0.7054303288459778
Validation loss: 2.119216740131378

Epoch: 6| Step: 13
Training loss: 1.8130247592926025
Validation loss: 2.1088872949282327

Epoch: 335| Step: 0
Training loss: 1.6615142822265625
Validation loss: 2.1198936104774475

Epoch: 6| Step: 1
Training loss: 0.5833361148834229
Validation loss: 2.1129408876101174

Epoch: 6| Step: 2
Training loss: 0.9420807957649231
Validation loss: 2.0895007650057473

Epoch: 6| Step: 3
Training loss: 0.9592841267585754
Validation loss: 2.086420993010203

Epoch: 6| Step: 4
Training loss: 1.3236733675003052
Validation loss: 2.12208084265391

Epoch: 6| Step: 5
Training loss: 0.765889585018158
Validation loss: 2.1166566411654153

Epoch: 6| Step: 6
Training loss: 2.0627694129943848
Validation loss: 2.1049391825993857

Epoch: 6| Step: 7
Training loss: 0.8282172679901123
Validation loss: 2.090610921382904

Epoch: 6| Step: 8
Training loss: 1.299431324005127
Validation loss: 2.120947301387787

Epoch: 6| Step: 9
Training loss: 0.8948671221733093
Validation loss: 2.117295563220978

Epoch: 6| Step: 10
Training loss: 1.7130564451217651
Validation loss: 2.141629179318746

Epoch: 6| Step: 11
Training loss: 1.2555489540100098
Validation loss: 2.1482213139533997

Epoch: 6| Step: 12
Training loss: 0.9929003119468689
Validation loss: 2.1579342683156333

Epoch: 6| Step: 13
Training loss: 1.7273504734039307
Validation loss: 2.1602941354115806

Epoch: 336| Step: 0
Training loss: 1.2863115072250366
Validation loss: 2.2001440127690635

Epoch: 6| Step: 1
Training loss: 1.252406358718872
Validation loss: 2.1225982904434204

Epoch: 6| Step: 2
Training loss: 1.2968295812606812
Validation loss: 2.1919506192207336

Epoch: 6| Step: 3
Training loss: 1.6311827898025513
Validation loss: 2.1321969827016196

Epoch: 6| Step: 4
Training loss: 0.8879905939102173
Validation loss: 2.114109536012014

Epoch: 6| Step: 5
Training loss: 1.4392879009246826
Validation loss: 2.1183655063311257

Epoch: 6| Step: 6
Training loss: 1.0131969451904297
Validation loss: 2.1138795812924704

Epoch: 6| Step: 7
Training loss: 1.1694834232330322
Validation loss: 2.098365286986033

Epoch: 6| Step: 8
Training loss: 1.7931323051452637
Validation loss: 2.0970762372016907

Epoch: 6| Step: 9
Training loss: 0.8269943594932556
Validation loss: 2.0931553840637207

Epoch: 6| Step: 10
Training loss: 1.508549451828003
Validation loss: 2.1195372541745505

Epoch: 6| Step: 11
Training loss: 1.8645105361938477
Validation loss: 2.123863458633423

Epoch: 6| Step: 12
Training loss: 0.7132304906845093
Validation loss: 2.125818908214569

Epoch: 6| Step: 13
Training loss: 0.9456021189689636
Validation loss: 2.1545305252075195

Epoch: 337| Step: 0
Training loss: 1.300033450126648
Validation loss: 2.168313225110372

Epoch: 6| Step: 1
Training loss: 1.0755267143249512
Validation loss: 2.1499065160751343

Epoch: 6| Step: 2
Training loss: 1.1132172346115112
Validation loss: 2.159225126107534

Epoch: 6| Step: 3
Training loss: 1.5473346710205078
Validation loss: 2.1588435769081116

Epoch: 6| Step: 4
Training loss: 1.8260986804962158
Validation loss: 2.171002984046936

Epoch: 6| Step: 5
Training loss: 1.6566839218139648
Validation loss: 2.105503956476847

Epoch: 6| Step: 6
Training loss: 0.9497052431106567
Validation loss: 2.1664931376775107

Epoch: 6| Step: 7
Training loss: 0.8590863943099976
Validation loss: 2.2113346457481384

Epoch: 6| Step: 8
Training loss: 1.1768500804901123
Validation loss: 2.1314429442087808

Epoch: 6| Step: 9
Training loss: 1.7494078874588013
Validation loss: 2.148080885410309

Epoch: 6| Step: 10
Training loss: 0.9183482527732849
Validation loss: 2.1329006354014077

Epoch: 6| Step: 11
Training loss: 1.2112253904342651
Validation loss: 2.1143953601519265

Epoch: 6| Step: 12
Training loss: 1.4066989421844482
Validation loss: 2.136446952819824

Epoch: 6| Step: 13
Training loss: 1.3054428100585938
Validation loss: 2.0813569029172263

Epoch: 338| Step: 0
Training loss: 0.49764734506607056
Validation loss: 2.1348416805267334

Epoch: 6| Step: 1
Training loss: 0.846947193145752
Validation loss: 2.146549959977468

Epoch: 6| Step: 2
Training loss: 0.9377434253692627
Validation loss: 2.1640717585881553

Epoch: 6| Step: 3
Training loss: 1.640634536743164
Validation loss: 2.143716037273407

Epoch: 6| Step: 4
Training loss: 2.014051914215088
Validation loss: 2.1285643577575684

Epoch: 6| Step: 5
Training loss: 1.177227258682251
Validation loss: 2.139707307020823

Epoch: 6| Step: 6
Training loss: 1.4945411682128906
Validation loss: 2.1396120190620422

Epoch: 6| Step: 7
Training loss: 1.1199543476104736
Validation loss: 2.105002482732137

Epoch: 6| Step: 8
Training loss: 1.3577015399932861
Validation loss: 2.0843358437220254

Epoch: 6| Step: 9
Training loss: 1.1798439025878906
Validation loss: 2.135151743888855

Epoch: 6| Step: 10
Training loss: 1.1094290018081665
Validation loss: 2.0905218720436096

Epoch: 6| Step: 11
Training loss: 1.186021089553833
Validation loss: 2.0920491019884744

Epoch: 6| Step: 12
Training loss: 1.7869839668273926
Validation loss: 2.118102510770162

Epoch: 6| Step: 13
Training loss: 1.4782910346984863
Validation loss: 2.090312679608663

Epoch: 339| Step: 0
Training loss: 1.5680365562438965
Validation loss: 2.092547337214152

Epoch: 6| Step: 1
Training loss: 1.2227214574813843
Validation loss: 2.125045120716095

Epoch: 6| Step: 2
Training loss: 0.7837740182876587
Validation loss: 2.1064359943072

Epoch: 6| Step: 3
Training loss: 0.8533313274383545
Validation loss: 2.138944983482361

Epoch: 6| Step: 4
Training loss: 0.8890490531921387
Validation loss: 2.183396299680074

Epoch: 6| Step: 5
Training loss: 1.6174236536026
Validation loss: 2.1088232000668845

Epoch: 6| Step: 6
Training loss: 1.4441590309143066
Validation loss: 2.1743802030881247

Epoch: 6| Step: 7
Training loss: 1.4815120697021484
Validation loss: 2.1911168098449707

Epoch: 6| Step: 8
Training loss: 0.7414674758911133
Validation loss: 2.262281576792399

Epoch: 6| Step: 9
Training loss: 1.229022741317749
Validation loss: 2.203907569249471

Epoch: 6| Step: 10
Training loss: 1.9355566501617432
Validation loss: 2.2148966987927756

Epoch: 6| Step: 11
Training loss: 1.5882844924926758
Validation loss: 2.2126884857813516

Epoch: 6| Step: 12
Training loss: 1.1932846307754517
Validation loss: 2.208609720071157

Epoch: 6| Step: 13
Training loss: 0.9053298234939575
Validation loss: 2.202738046646118

Epoch: 340| Step: 0
Training loss: 0.6672629714012146
Validation loss: 2.2012673815091452

Epoch: 6| Step: 1
Training loss: 1.0840954780578613
Validation loss: 2.2367162307103476

Epoch: 6| Step: 2
Training loss: 1.8988475799560547
Validation loss: 2.229470411936442

Epoch: 6| Step: 3
Training loss: 1.628745436668396
Validation loss: 2.1975134015083313

Epoch: 6| Step: 4
Training loss: 0.5554832220077515
Validation loss: 2.1626051863034568

Epoch: 6| Step: 5
Training loss: 1.5742647647857666
Validation loss: 2.142858703931173

Epoch: 6| Step: 6
Training loss: 1.3196461200714111
Validation loss: 2.1820092598597207

Epoch: 6| Step: 7
Training loss: 0.9158761501312256
Validation loss: 2.191193620363871

Epoch: 6| Step: 8
Training loss: 0.950063943862915
Validation loss: 2.1655469139417014

Epoch: 6| Step: 9
Training loss: 1.195152759552002
Validation loss: 2.156838059425354

Epoch: 6| Step: 10
Training loss: 1.2500722408294678
Validation loss: 2.1699153184890747

Epoch: 6| Step: 11
Training loss: 1.361581563949585
Validation loss: 2.1443090438842773

Epoch: 6| Step: 12
Training loss: 1.1007020473480225
Validation loss: 2.2038153807322183

Epoch: 6| Step: 13
Training loss: 1.0114963054656982
Validation loss: 2.162870248158773

Epoch: 341| Step: 0
Training loss: 1.5368163585662842
Validation loss: 2.158930718898773

Epoch: 6| Step: 1
Training loss: 1.303359031677246
Validation loss: 2.163817803064982

Epoch: 6| Step: 2
Training loss: 0.9872504472732544
Validation loss: 2.147472540537516

Epoch: 6| Step: 3
Training loss: 1.2720667123794556
Validation loss: 2.1460054318110147

Epoch: 6| Step: 4
Training loss: 0.6808122396469116
Validation loss: 2.1563666264216104

Epoch: 6| Step: 5
Training loss: 1.2280678749084473
Validation loss: 2.1679296493530273

Epoch: 6| Step: 6
Training loss: 1.2258646488189697
Validation loss: 2.185341775417328

Epoch: 6| Step: 7
Training loss: 1.0911952257156372
Validation loss: 2.141342878341675

Epoch: 6| Step: 8
Training loss: 0.7857281565666199
Validation loss: 2.1374144752820334

Epoch: 6| Step: 9
Training loss: 1.2305855751037598
Validation loss: 2.160380005836487

Epoch: 6| Step: 10
Training loss: 1.3018858432769775
Validation loss: 2.204811910788218

Epoch: 6| Step: 11
Training loss: 1.6910158395767212
Validation loss: 2.1826091011365256

Epoch: 6| Step: 12
Training loss: 1.2198563814163208
Validation loss: 2.2040493488311768

Epoch: 6| Step: 13
Training loss: 1.5425368547439575
Validation loss: 2.1467493375142417

Epoch: 342| Step: 0
Training loss: 0.9012093544006348
Validation loss: 2.144456386566162

Epoch: 6| Step: 1
Training loss: 1.4466936588287354
Validation loss: 2.1835832993189492

Epoch: 6| Step: 2
Training loss: 1.110576868057251
Validation loss: 2.1678646405537925

Epoch: 6| Step: 3
Training loss: 1.138029932975769
Validation loss: 2.1589959859848022

Epoch: 6| Step: 4
Training loss: 1.095732569694519
Validation loss: 2.1335477431615195

Epoch: 6| Step: 5
Training loss: 1.1517376899719238
Validation loss: 2.107255001862844

Epoch: 6| Step: 6
Training loss: 0.6593960523605347
Validation loss: 2.07803467909495

Epoch: 6| Step: 7
Training loss: 2.0287084579467773
Validation loss: 2.1145313580830893

Epoch: 6| Step: 8
Training loss: 1.3139575719833374
Validation loss: 2.0948671301205954

Epoch: 6| Step: 9
Training loss: 1.1568632125854492
Validation loss: 2.1290810902913413

Epoch: 6| Step: 10
Training loss: 1.5172703266143799
Validation loss: 2.1201122800509133

Epoch: 6| Step: 11
Training loss: 1.2203855514526367
Validation loss: 2.1332070430119834

Epoch: 6| Step: 12
Training loss: 1.0110807418823242
Validation loss: 2.1233824094136557

Epoch: 6| Step: 13
Training loss: 0.544630765914917
Validation loss: 2.0956884821256003

Epoch: 343| Step: 0
Training loss: 1.6238007545471191
Validation loss: 2.104733685652415

Epoch: 6| Step: 1
Training loss: 0.4956342577934265
Validation loss: 2.0914791226387024

Epoch: 6| Step: 2
Training loss: 1.4863576889038086
Validation loss: 2.1133410334587097

Epoch: 6| Step: 3
Training loss: 0.7122849822044373
Validation loss: 2.0803096691767373

Epoch: 6| Step: 4
Training loss: 1.4906306266784668
Validation loss: 2.1280742088953652

Epoch: 6| Step: 5
Training loss: 1.198333978652954
Validation loss: 2.1076497236887612

Epoch: 6| Step: 6
Training loss: 1.3804478645324707
Validation loss: 2.1385263800621033

Epoch: 6| Step: 7
Training loss: 1.2326076030731201
Validation loss: 2.1259002685546875

Epoch: 6| Step: 8
Training loss: 1.6284555196762085
Validation loss: 2.1826857328414917

Epoch: 6| Step: 9
Training loss: 0.9984018206596375
Validation loss: 2.169863522052765

Epoch: 6| Step: 10
Training loss: 1.5669904947280884
Validation loss: 2.172719717025757

Epoch: 6| Step: 11
Training loss: 1.4838876724243164
Validation loss: 2.195651113986969

Epoch: 6| Step: 12
Training loss: 0.8657659292221069
Validation loss: 2.1494903564453125

Epoch: 6| Step: 13
Training loss: 0.6013855934143066
Validation loss: 2.1721392273902893

Epoch: 344| Step: 0
Training loss: 1.6668827533721924
Validation loss: 2.138727327187856

Epoch: 6| Step: 1
Training loss: 1.2296299934387207
Validation loss: 2.124322851498922

Epoch: 6| Step: 2
Training loss: 0.8213998079299927
Validation loss: 2.1438940366109214

Epoch: 6| Step: 3
Training loss: 1.2480528354644775
Validation loss: 2.1312567790349326

Epoch: 6| Step: 4
Training loss: 2.28924822807312
Validation loss: 2.113743265469869

Epoch: 6| Step: 5
Training loss: 1.4335521459579468
Validation loss: 2.122206926345825

Epoch: 6| Step: 6
Training loss: 0.622950553894043
Validation loss: 2.1169195572535195

Epoch: 6| Step: 7
Training loss: 0.833794355392456
Validation loss: 2.1464654207229614

Epoch: 6| Step: 8
Training loss: 1.2456011772155762
Validation loss: 2.1901535193125405

Epoch: 6| Step: 9
Training loss: 0.9667295217514038
Validation loss: 2.1910223166147866

Epoch: 6| Step: 10
Training loss: 0.900719165802002
Validation loss: 2.1842687924702964

Epoch: 6| Step: 11
Training loss: 1.1841697692871094
Validation loss: 2.213465432325999

Epoch: 6| Step: 12
Training loss: 1.1878819465637207
Validation loss: 2.1541733145713806

Epoch: 6| Step: 13
Training loss: 1.735001802444458
Validation loss: 2.134756247202555

Epoch: 345| Step: 0
Training loss: 0.6006267070770264
Validation loss: 2.108826736609141

Epoch: 6| Step: 1
Training loss: 1.1533708572387695
Validation loss: 2.1411954363187156

Epoch: 6| Step: 2
Training loss: 1.0954697132110596
Validation loss: 2.1657026012738547

Epoch: 6| Step: 3
Training loss: 1.4149848222732544
Validation loss: 2.1513468424479165

Epoch: 6| Step: 4
Training loss: 1.1855449676513672
Validation loss: 2.100757658481598

Epoch: 6| Step: 5
Training loss: 1.610673427581787
Validation loss: 2.113295833269755

Epoch: 6| Step: 6
Training loss: 1.1395089626312256
Validation loss: 2.1411582827568054

Epoch: 6| Step: 7
Training loss: 0.8907189965248108
Validation loss: 2.0883578062057495

Epoch: 6| Step: 8
Training loss: 1.9240942001342773
Validation loss: 2.1535585721333823

Epoch: 6| Step: 9
Training loss: 0.9916096925735474
Validation loss: 2.089360495408376

Epoch: 6| Step: 10
Training loss: 1.0315600633621216
Validation loss: 2.1352901657422385

Epoch: 6| Step: 11
Training loss: 0.6304433345794678
Validation loss: 2.1387400031089783

Epoch: 6| Step: 12
Training loss: 1.9353418350219727
Validation loss: 2.130931814511617

Epoch: 6| Step: 13
Training loss: 0.9771076440811157
Validation loss: 2.124660154183706

Epoch: 346| Step: 0
Training loss: 1.1731032133102417
Validation loss: 2.118780334790548

Epoch: 6| Step: 1
Training loss: 0.9416425824165344
Validation loss: 2.1328582763671875

Epoch: 6| Step: 2
Training loss: 1.4168384075164795
Validation loss: 2.1468778451283774

Epoch: 6| Step: 3
Training loss: 1.4261971712112427
Validation loss: 2.1122150222460427

Epoch: 6| Step: 4
Training loss: 1.420853853225708
Validation loss: 2.141231973965963

Epoch: 6| Step: 5
Training loss: 1.2671563625335693
Validation loss: 2.132619837919871

Epoch: 6| Step: 6
Training loss: 0.882466197013855
Validation loss: 2.1343259612719216

Epoch: 6| Step: 7
Training loss: 0.9002854824066162
Validation loss: 2.1440380811691284

Epoch: 6| Step: 8
Training loss: 1.6153908967971802
Validation loss: 2.169630547364553

Epoch: 6| Step: 9
Training loss: 0.8271896839141846
Validation loss: 2.1474216977755227

Epoch: 6| Step: 10
Training loss: 2.078827381134033
Validation loss: 2.1476351817448935

Epoch: 6| Step: 11
Training loss: 1.2994699478149414
Validation loss: 2.16528183221817

Epoch: 6| Step: 12
Training loss: 0.8398172855377197
Validation loss: 2.1659738620122275

Epoch: 6| Step: 13
Training loss: 0.5335433483123779
Validation loss: 2.156264344851176

Epoch: 347| Step: 0
Training loss: 1.3367635011672974
Validation loss: 2.1258689761161804

Epoch: 6| Step: 1
Training loss: 0.7901620864868164
Validation loss: 2.140625854333242

Epoch: 6| Step: 2
Training loss: 1.2618153095245361
Validation loss: 2.156087100505829

Epoch: 6| Step: 3
Training loss: 0.7691371440887451
Validation loss: 2.102977474530538

Epoch: 6| Step: 4
Training loss: 0.7828387022018433
Validation loss: 2.1695088545481362

Epoch: 6| Step: 5
Training loss: 1.345435619354248
Validation loss: 2.1432366172472634

Epoch: 6| Step: 6
Training loss: 1.4327340126037598
Validation loss: 2.1558582385381064

Epoch: 6| Step: 7
Training loss: 1.1977936029434204
Validation loss: 2.158495823542277

Epoch: 6| Step: 8
Training loss: 0.3795110583305359
Validation loss: 2.170650621255239

Epoch: 6| Step: 9
Training loss: 0.9527624845504761
Validation loss: 2.1645206809043884

Epoch: 6| Step: 10
Training loss: 1.1090919971466064
Validation loss: 2.169188300768534

Epoch: 6| Step: 11
Training loss: 1.818190097808838
Validation loss: 2.151431759198507

Epoch: 6| Step: 12
Training loss: 2.0658063888549805
Validation loss: 2.1694724559783936

Epoch: 6| Step: 13
Training loss: 1.0171170234680176
Validation loss: 2.169811189174652

Epoch: 348| Step: 0
Training loss: 0.7028375864028931
Validation loss: 2.1536865631739297

Epoch: 6| Step: 1
Training loss: 1.6595478057861328
Validation loss: 2.19715815782547

Epoch: 6| Step: 2
Training loss: 1.2965381145477295
Validation loss: 2.145765999952952

Epoch: 6| Step: 3
Training loss: 1.5002496242523193
Validation loss: 2.1766666173934937

Epoch: 6| Step: 4
Training loss: 0.6398853659629822
Validation loss: 2.1415770848592124

Epoch: 6| Step: 5
Training loss: 0.4571210741996765
Validation loss: 2.194453001022339

Epoch: 6| Step: 6
Training loss: 1.0077885389328003
Validation loss: 2.139311134815216

Epoch: 6| Step: 7
Training loss: 1.145231008529663
Validation loss: 2.1464725136756897

Epoch: 6| Step: 8
Training loss: 1.1736390590667725
Validation loss: 2.1066852807998657

Epoch: 6| Step: 9
Training loss: 1.5903514623641968
Validation loss: 2.1942569812138877

Epoch: 6| Step: 10
Training loss: 1.4994980096817017
Validation loss: 2.166187028090159

Epoch: 6| Step: 11
Training loss: 1.506113052368164
Validation loss: 2.1338873306910195

Epoch: 6| Step: 12
Training loss: 1.0955660343170166
Validation loss: 2.1592194636662803

Epoch: 6| Step: 13
Training loss: 0.9337316751480103
Validation loss: 2.1433491905530295

Epoch: 349| Step: 0
Training loss: 0.5022246241569519
Validation loss: 2.151927371819814

Epoch: 6| Step: 1
Training loss: 1.1731204986572266
Validation loss: 2.176123797893524

Epoch: 6| Step: 2
Training loss: 1.5701067447662354
Validation loss: 2.143917222817739

Epoch: 6| Step: 3
Training loss: 0.8039518594741821
Validation loss: 2.1266326705614724

Epoch: 6| Step: 4
Training loss: 1.016371250152588
Validation loss: 2.1303859750429788

Epoch: 6| Step: 5
Training loss: 0.7481907606124878
Validation loss: 2.110571801662445

Epoch: 6| Step: 6
Training loss: 0.7260823249816895
Validation loss: 2.1656582156817117

Epoch: 6| Step: 7
Training loss: 0.9433151483535767
Validation loss: 2.1179344256718955

Epoch: 6| Step: 8
Training loss: 2.0900282859802246
Validation loss: 2.1426231265068054

Epoch: 6| Step: 9
Training loss: 0.9705581665039062
Validation loss: 2.103027820587158

Epoch: 6| Step: 10
Training loss: 1.60232412815094
Validation loss: 2.128991345564524

Epoch: 6| Step: 11
Training loss: 0.8907687664031982
Validation loss: 2.1076413989067078

Epoch: 6| Step: 12
Training loss: 1.0732905864715576
Validation loss: 2.1142762104670205

Epoch: 6| Step: 13
Training loss: 1.3042118549346924
Validation loss: 2.086588362852732

Epoch: 350| Step: 0
Training loss: 0.9488404989242554
Validation loss: 2.092929502328237

Epoch: 6| Step: 1
Training loss: 1.3528175354003906
Validation loss: 2.13660720984141

Epoch: 6| Step: 2
Training loss: 0.624107837677002
Validation loss: 2.146392603715261

Epoch: 6| Step: 3
Training loss: 1.2072163820266724
Validation loss: 2.1555545926094055

Epoch: 6| Step: 4
Training loss: 1.1431453227996826
Validation loss: 2.1269346872965493

Epoch: 6| Step: 5
Training loss: 0.9358989000320435
Validation loss: 2.095969279607137

Epoch: 6| Step: 6
Training loss: 0.9954048991203308
Validation loss: 2.0881402293841043

Epoch: 6| Step: 7
Training loss: 1.3064056634902954
Validation loss: 2.120320657889048

Epoch: 6| Step: 8
Training loss: 0.6735262870788574
Validation loss: 2.1273582180341086

Epoch: 6| Step: 9
Training loss: 1.2664076089859009
Validation loss: 2.098210950692495

Epoch: 6| Step: 10
Training loss: 0.8875100612640381
Validation loss: 2.140195290247599

Epoch: 6| Step: 11
Training loss: 1.242993712425232
Validation loss: 2.0978631575902305

Epoch: 6| Step: 12
Training loss: 1.559385895729065
Validation loss: 2.1307019790013633

Epoch: 6| Step: 13
Training loss: 1.353630781173706
Validation loss: 2.148624320824941

Epoch: 351| Step: 0
Training loss: 1.0683798789978027
Validation loss: 2.1672443151474

Epoch: 6| Step: 1
Training loss: 0.808417797088623
Validation loss: 2.1613994439442954

Epoch: 6| Step: 2
Training loss: 1.5679186582565308
Validation loss: 2.1150521437327066

Epoch: 6| Step: 3
Training loss: 0.649996280670166
Validation loss: 2.1617600123087564

Epoch: 6| Step: 4
Training loss: 1.0255591869354248
Validation loss: 2.1326953570048013

Epoch: 6| Step: 5
Training loss: 0.9511017203330994
Validation loss: 2.1621427734692893

Epoch: 6| Step: 6
Training loss: 1.0650973320007324
Validation loss: 2.1347126563390098

Epoch: 6| Step: 7
Training loss: 1.6623451709747314
Validation loss: 2.146519978841146

Epoch: 6| Step: 8
Training loss: 1.236722469329834
Validation loss: 2.1686564087867737

Epoch: 6| Step: 9
Training loss: 1.2220395803451538
Validation loss: 2.1548995971679688

Epoch: 6| Step: 10
Training loss: 1.522896409034729
Validation loss: 2.168977697690328

Epoch: 6| Step: 11
Training loss: 0.9668136239051819
Validation loss: 2.1738749146461487

Epoch: 6| Step: 12
Training loss: 0.7532471418380737
Validation loss: 2.1283856431643167

Epoch: 6| Step: 13
Training loss: 0.9279038906097412
Validation loss: 2.155737499396006

Epoch: 352| Step: 0
Training loss: 1.003736972808838
Validation loss: 2.128214875857035

Epoch: 6| Step: 1
Training loss: 0.8332554697990417
Validation loss: 2.081604242324829

Epoch: 6| Step: 2
Training loss: 0.8614687919616699
Validation loss: 2.102751692136129

Epoch: 6| Step: 3
Training loss: 1.014422059059143
Validation loss: 2.1516486207644143

Epoch: 6| Step: 4
Training loss: 1.0400550365447998
Validation loss: 2.155995945135752

Epoch: 6| Step: 5
Training loss: 1.0879722833633423
Validation loss: 2.0858094294865928

Epoch: 6| Step: 6
Training loss: 1.0300288200378418
Validation loss: 2.129571040471395

Epoch: 6| Step: 7
Training loss: 0.9800043702125549
Validation loss: 2.096884806950887

Epoch: 6| Step: 8
Training loss: 0.9203187227249146
Validation loss: 2.1008092562357583

Epoch: 6| Step: 9
Training loss: 0.9852135181427002
Validation loss: 2.166289488474528

Epoch: 6| Step: 10
Training loss: 1.898796796798706
Validation loss: 2.15214208761851

Epoch: 6| Step: 11
Training loss: 1.0151309967041016
Validation loss: 2.142579118410746

Epoch: 6| Step: 12
Training loss: 1.3643510341644287
Validation loss: 2.141435186068217

Epoch: 6| Step: 13
Training loss: 1.1955854892730713
Validation loss: 2.1195797324180603

Epoch: 353| Step: 0
Training loss: 0.7932202219963074
Validation loss: 2.1247735619544983

Epoch: 6| Step: 1
Training loss: 0.5267353057861328
Validation loss: 2.161694089571635

Epoch: 6| Step: 2
Training loss: 1.0423685312271118
Validation loss: 2.1213597655296326

Epoch: 6| Step: 3
Training loss: 0.846786618232727
Validation loss: 2.130510369936625

Epoch: 6| Step: 4
Training loss: 0.8844029903411865
Validation loss: 2.145522654056549

Epoch: 6| Step: 5
Training loss: 0.7576486468315125
Validation loss: 2.0857878923416138

Epoch: 6| Step: 6
Training loss: 2.0133097171783447
Validation loss: 2.1054362654685974

Epoch: 6| Step: 7
Training loss: 1.2391960620880127
Validation loss: 2.107104400793711

Epoch: 6| Step: 8
Training loss: 1.5432993173599243
Validation loss: 2.1208290457725525

Epoch: 6| Step: 9
Training loss: 0.9314907193183899
Validation loss: 2.114397327105204

Epoch: 6| Step: 10
Training loss: 1.31541907787323
Validation loss: 2.131599764029185

Epoch: 6| Step: 11
Training loss: 0.946467399597168
Validation loss: 2.145907719930013

Epoch: 6| Step: 12
Training loss: 1.17503023147583
Validation loss: 2.1550942858060202

Epoch: 6| Step: 13
Training loss: 1.0321297645568848
Validation loss: 2.1623106002807617

Epoch: 354| Step: 0
Training loss: 0.9899002909660339
Validation loss: 2.1672167778015137

Epoch: 6| Step: 1
Training loss: 1.606162190437317
Validation loss: 2.1647156476974487

Epoch: 6| Step: 2
Training loss: 0.9795931577682495
Validation loss: 2.153424541155497

Epoch: 6| Step: 3
Training loss: 0.9960780143737793
Validation loss: 2.1389877001444497

Epoch: 6| Step: 4
Training loss: 0.9805273413658142
Validation loss: 2.1414630810419717

Epoch: 6| Step: 5
Training loss: 0.7154462337493896
Validation loss: 2.092742105325063

Epoch: 6| Step: 6
Training loss: 0.9781476855278015
Validation loss: 2.163753390312195

Epoch: 6| Step: 7
Training loss: 1.0271618366241455
Validation loss: 2.1447070638338723

Epoch: 6| Step: 8
Training loss: 0.7379179000854492
Validation loss: 2.1421934763590493

Epoch: 6| Step: 9
Training loss: 0.7806049585342407
Validation loss: 2.1639337142308555

Epoch: 6| Step: 10
Training loss: 2.009665012359619
Validation loss: 2.2071449359258017

Epoch: 6| Step: 11
Training loss: 1.325636386871338
Validation loss: 2.133829712867737

Epoch: 6| Step: 12
Training loss: 0.7500191926956177
Validation loss: 2.1763537526130676

Epoch: 6| Step: 13
Training loss: 1.1367264986038208
Validation loss: 2.1343156496683755

Epoch: 355| Step: 0
Training loss: 2.6664044857025146
Validation loss: 2.177244504292806

Epoch: 6| Step: 1
Training loss: 0.9065829515457153
Validation loss: 2.168161471684774

Epoch: 6| Step: 2
Training loss: 1.311420202255249
Validation loss: 2.1040918032328286

Epoch: 6| Step: 3
Training loss: 1.0320647954940796
Validation loss: 2.17176087697347

Epoch: 6| Step: 4
Training loss: 0.9473532438278198
Validation loss: 2.1445782581965127

Epoch: 6| Step: 5
Training loss: 1.120140552520752
Validation loss: 2.105922202269236

Epoch: 6| Step: 6
Training loss: 1.0784778594970703
Validation loss: 2.0986167589823403

Epoch: 6| Step: 7
Training loss: 1.4897288084030151
Validation loss: 2.1208103696505227

Epoch: 6| Step: 8
Training loss: 0.9818130731582642
Validation loss: 2.10734494527181

Epoch: 6| Step: 9
Training loss: 0.676944375038147
Validation loss: 2.087683379650116

Epoch: 6| Step: 10
Training loss: 0.7658060193061829
Validation loss: 2.118251065413157

Epoch: 6| Step: 11
Training loss: 0.8757991194725037
Validation loss: 2.1461487213770547

Epoch: 6| Step: 12
Training loss: 1.0618748664855957
Validation loss: 2.1489649613698325

Epoch: 6| Step: 13
Training loss: 1.020434856414795
Validation loss: 2.127104938030243

Epoch: 356| Step: 0
Training loss: 0.7493479251861572
Validation loss: 2.130407214164734

Epoch: 6| Step: 1
Training loss: 1.3840229511260986
Validation loss: 2.144313017527262

Epoch: 6| Step: 2
Training loss: 1.055090069770813
Validation loss: 2.139767050743103

Epoch: 6| Step: 3
Training loss: 1.1331180334091187
Validation loss: 2.105713665485382

Epoch: 6| Step: 4
Training loss: 1.0728410482406616
Validation loss: 2.1395172079404197

Epoch: 6| Step: 5
Training loss: 1.0784491300582886
Validation loss: 2.156366149584452

Epoch: 6| Step: 6
Training loss: 0.8010870814323425
Validation loss: 2.1787734627723694

Epoch: 6| Step: 7
Training loss: 1.2959635257720947
Validation loss: 2.200030505657196

Epoch: 6| Step: 8
Training loss: 1.1555036306381226
Validation loss: 2.164270579814911

Epoch: 6| Step: 9
Training loss: 1.6781158447265625
Validation loss: 2.193620582421621

Epoch: 6| Step: 10
Training loss: 0.8364985585212708
Validation loss: 2.1690328121185303

Epoch: 6| Step: 11
Training loss: 0.7245587706565857
Validation loss: 2.1911863485972085

Epoch: 6| Step: 12
Training loss: 0.9814145565032959
Validation loss: 2.1999827226003013

Epoch: 6| Step: 13
Training loss: 1.4142765998840332
Validation loss: 2.2023775776227317

Epoch: 357| Step: 0
Training loss: 2.150216579437256
Validation loss: 2.1794380942980447

Epoch: 6| Step: 1
Training loss: 1.1194772720336914
Validation loss: 2.2192872762680054

Epoch: 6| Step: 2
Training loss: 0.6269997358322144
Validation loss: 2.193747619787852

Epoch: 6| Step: 3
Training loss: 0.9775667190551758
Validation loss: 2.1652760108311973

Epoch: 6| Step: 4
Training loss: 0.8482644557952881
Validation loss: 2.199129343032837

Epoch: 6| Step: 5
Training loss: 1.3046276569366455
Validation loss: 2.210286299387614

Epoch: 6| Step: 6
Training loss: 1.937669038772583
Validation loss: 2.190567433834076

Epoch: 6| Step: 7
Training loss: 0.7322703003883362
Validation loss: 2.169561286767324

Epoch: 6| Step: 8
Training loss: 1.2322332859039307
Validation loss: 2.1756631731987

Epoch: 6| Step: 9
Training loss: 0.7354077100753784
Validation loss: 2.1802135507265725

Epoch: 6| Step: 10
Training loss: 0.6884893178939819
Validation loss: 2.211868147055308

Epoch: 6| Step: 11
Training loss: 1.6573855876922607
Validation loss: 2.167952001094818

Epoch: 6| Step: 12
Training loss: 1.0379548072814941
Validation loss: 2.188697894414266

Epoch: 6| Step: 13
Training loss: 0.8174281120300293
Validation loss: 2.158685088157654

Epoch: 358| Step: 0
Training loss: 1.196662187576294
Validation loss: 2.209761699040731

Epoch: 6| Step: 1
Training loss: 0.8237825632095337
Validation loss: 2.185230314731598

Epoch: 6| Step: 2
Training loss: 0.5934762954711914
Validation loss: 2.225462317466736

Epoch: 6| Step: 3
Training loss: 0.8776421546936035
Validation loss: 2.1591451366742453

Epoch: 6| Step: 4
Training loss: 2.074746608734131
Validation loss: 2.2235646645228067

Epoch: 6| Step: 5
Training loss: 1.3475966453552246
Validation loss: 2.2162430683771768

Epoch: 6| Step: 6
Training loss: 0.6935750246047974
Validation loss: 2.2276018857955933

Epoch: 6| Step: 7
Training loss: 1.4142603874206543
Validation loss: 2.1906314293543496

Epoch: 6| Step: 8
Training loss: 1.0298951864242554
Validation loss: 2.176311473051707

Epoch: 6| Step: 9
Training loss: 1.1616058349609375
Validation loss: 2.1575353344281516

Epoch: 6| Step: 10
Training loss: 1.04637610912323
Validation loss: 2.1791749397913613

Epoch: 6| Step: 11
Training loss: 0.7422564029693604
Validation loss: 2.169409155845642

Epoch: 6| Step: 12
Training loss: 1.1684999465942383
Validation loss: 2.1921865741411843

Epoch: 6| Step: 13
Training loss: 1.6025505065917969
Validation loss: 2.171323835849762

Epoch: 359| Step: 0
Training loss: 1.0765703916549683
Validation loss: 2.1352335611979165

Epoch: 6| Step: 1
Training loss: 1.402921199798584
Validation loss: 2.164778014024099

Epoch: 6| Step: 2
Training loss: 1.0262956619262695
Validation loss: 2.176965355873108

Epoch: 6| Step: 3
Training loss: 0.7849165201187134
Validation loss: 2.1616355578104653

Epoch: 6| Step: 4
Training loss: 0.9324432611465454
Validation loss: 2.1818368832270303

Epoch: 6| Step: 5
Training loss: 0.8200725317001343
Validation loss: 2.171439250310262

Epoch: 6| Step: 6
Training loss: 1.037084698677063
Validation loss: 2.1589382092158

Epoch: 6| Step: 7
Training loss: 1.2592883110046387
Validation loss: 2.1710615952809653

Epoch: 6| Step: 8
Training loss: 1.1446540355682373
Validation loss: 2.1292215983072915

Epoch: 6| Step: 9
Training loss: 1.0866997241973877
Validation loss: 2.144035736719767

Epoch: 6| Step: 10
Training loss: 1.0927419662475586
Validation loss: 2.1149792472521463

Epoch: 6| Step: 11
Training loss: 0.4887029528617859
Validation loss: 2.1635753909746804

Epoch: 6| Step: 12
Training loss: 0.840656042098999
Validation loss: 2.1198302706082663

Epoch: 6| Step: 13
Training loss: 1.8580981492996216
Validation loss: 2.1172113021214805

Epoch: 360| Step: 0
Training loss: 1.2202777862548828
Validation loss: 2.1167537371317544

Epoch: 6| Step: 1
Training loss: 0.5773800015449524
Validation loss: 2.1177224119504294

Epoch: 6| Step: 2
Training loss: 1.1227947473526
Validation loss: 2.14211372534434

Epoch: 6| Step: 3
Training loss: 0.6130592823028564
Validation loss: 2.144270400206248

Epoch: 6| Step: 4
Training loss: 1.5286099910736084
Validation loss: 2.165851573149363

Epoch: 6| Step: 5
Training loss: 1.3264248371124268
Validation loss: 2.1638211210568747

Epoch: 6| Step: 6
Training loss: 1.062232494354248
Validation loss: 2.157478153705597

Epoch: 6| Step: 7
Training loss: 1.6561061143875122
Validation loss: 2.1686978340148926

Epoch: 6| Step: 8
Training loss: 0.7787219882011414
Validation loss: 2.2153177658716836

Epoch: 6| Step: 9
Training loss: 1.250501036643982
Validation loss: 2.175649563471476

Epoch: 6| Step: 10
Training loss: 0.9848636388778687
Validation loss: 2.1203526655832925

Epoch: 6| Step: 11
Training loss: 1.266190528869629
Validation loss: 2.1545660694440207

Epoch: 6| Step: 12
Training loss: 0.9502148628234863
Validation loss: 2.176956593990326

Epoch: 6| Step: 13
Training loss: 0.6820028424263
Validation loss: 2.1195180813471475

Epoch: 361| Step: 0
Training loss: 0.5760867595672607
Validation loss: 2.157367706298828

Epoch: 6| Step: 1
Training loss: 1.0491070747375488
Validation loss: 2.1205578049023948

Epoch: 6| Step: 2
Training loss: 0.9072401523590088
Validation loss: 2.137012481689453

Epoch: 6| Step: 3
Training loss: 1.2466365098953247
Validation loss: 2.1764469146728516

Epoch: 6| Step: 4
Training loss: 0.672595202922821
Validation loss: 2.1442084312438965

Epoch: 6| Step: 5
Training loss: 1.2230147123336792
Validation loss: 2.159529983997345

Epoch: 6| Step: 6
Training loss: 1.0967329740524292
Validation loss: 2.1278748710950217

Epoch: 6| Step: 7
Training loss: 0.9131534695625305
Validation loss: 2.208759287993113

Epoch: 6| Step: 8
Training loss: 0.7240743041038513
Validation loss: 2.1429471174875894

Epoch: 6| Step: 9
Training loss: 1.2496566772460938
Validation loss: 2.1573339700698853

Epoch: 6| Step: 10
Training loss: 1.8389856815338135
Validation loss: 2.1791762709617615

Epoch: 6| Step: 11
Training loss: 1.444504737854004
Validation loss: 2.209355612595876

Epoch: 6| Step: 12
Training loss: 0.9172172546386719
Validation loss: 2.2230358322461448

Epoch: 6| Step: 13
Training loss: 1.1266961097717285
Validation loss: 2.206602950890859

Epoch: 362| Step: 0
Training loss: 1.495009183883667
Validation loss: 2.169933478037516

Epoch: 6| Step: 1
Training loss: 1.0208454132080078
Validation loss: 2.120928466320038

Epoch: 6| Step: 2
Training loss: 1.477383017539978
Validation loss: 2.120334724585215

Epoch: 6| Step: 3
Training loss: 1.922872543334961
Validation loss: 2.086708645025889

Epoch: 6| Step: 4
Training loss: 1.5049645900726318
Validation loss: 2.0746323068936667

Epoch: 6| Step: 5
Training loss: 1.141247034072876
Validation loss: 2.086230297883352

Epoch: 6| Step: 6
Training loss: 0.7765151858329773
Validation loss: 2.108904461065928

Epoch: 6| Step: 7
Training loss: 0.603676438331604
Validation loss: 2.1212196350097656

Epoch: 6| Step: 8
Training loss: 0.6413508653640747
Validation loss: 2.1448766390482583

Epoch: 6| Step: 9
Training loss: 1.3553985357284546
Validation loss: 2.146459221839905

Epoch: 6| Step: 10
Training loss: 0.8900038003921509
Validation loss: 2.178174058596293

Epoch: 6| Step: 11
Training loss: 0.9360690712928772
Validation loss: 2.1452067693074546

Epoch: 6| Step: 12
Training loss: 1.6897406578063965
Validation loss: 2.1281002163887024

Epoch: 6| Step: 13
Training loss: 0.6196966171264648
Validation loss: 2.083979864915212

Epoch: 363| Step: 0
Training loss: 0.6081504821777344
Validation loss: 2.1237640182177224

Epoch: 6| Step: 1
Training loss: 1.246390461921692
Validation loss: 2.130773345629374

Epoch: 6| Step: 2
Training loss: 1.1639354228973389
Validation loss: 2.1488997538884482

Epoch: 6| Step: 3
Training loss: 1.3493194580078125
Validation loss: 2.122777044773102

Epoch: 6| Step: 4
Training loss: 0.7671279311180115
Validation loss: 2.1325787703196206

Epoch: 6| Step: 5
Training loss: 1.0119163990020752
Validation loss: 2.136933465798696

Epoch: 6| Step: 6
Training loss: 1.0282922983169556
Validation loss: 2.1323510805765786

Epoch: 6| Step: 7
Training loss: 0.8920103311538696
Validation loss: 2.1132391492525735

Epoch: 6| Step: 8
Training loss: 1.5019243955612183
Validation loss: 2.164425710837046

Epoch: 6| Step: 9
Training loss: 1.8283932209014893
Validation loss: 2.1347988645235696

Epoch: 6| Step: 10
Training loss: 1.2214710712432861
Validation loss: 2.184153139591217

Epoch: 6| Step: 11
Training loss: 0.8178048729896545
Validation loss: 2.1537514328956604

Epoch: 6| Step: 12
Training loss: 1.3794100284576416
Validation loss: 2.178601304690043

Epoch: 6| Step: 13
Training loss: 0.5897420644760132
Validation loss: 2.0797070463498435

Epoch: 364| Step: 0
Training loss: 0.9961510300636292
Validation loss: 2.1609321236610413

Epoch: 6| Step: 1
Training loss: 0.9869443774223328
Validation loss: 2.1160930593808494

Epoch: 6| Step: 2
Training loss: 1.7021205425262451
Validation loss: 2.1559846798578897

Epoch: 6| Step: 3
Training loss: 0.8927534818649292
Validation loss: 2.130820393562317

Epoch: 6| Step: 4
Training loss: 0.9445722699165344
Validation loss: 2.130834778149923

Epoch: 6| Step: 5
Training loss: 0.9368805885314941
Validation loss: 2.1401618917783103

Epoch: 6| Step: 6
Training loss: 1.2697958946228027
Validation loss: 2.1450425386428833

Epoch: 6| Step: 7
Training loss: 1.0854387283325195
Validation loss: 2.1727192203203836

Epoch: 6| Step: 8
Training loss: 1.2007629871368408
Validation loss: 2.211030642191569

Epoch: 6| Step: 9
Training loss: 1.0798701047897339
Validation loss: 2.2367722590764365

Epoch: 6| Step: 10
Training loss: 1.001063346862793
Validation loss: 2.1927625934282937

Epoch: 6| Step: 11
Training loss: 1.1847620010375977
Validation loss: 2.202138582865397

Epoch: 6| Step: 12
Training loss: 0.9625072479248047
Validation loss: 2.13130259513855

Epoch: 6| Step: 13
Training loss: 1.3731083869934082
Validation loss: 2.132189472516378

Epoch: 365| Step: 0
Training loss: 1.192850112915039
Validation loss: 2.1340883374214172

Epoch: 6| Step: 1
Training loss: 1.1971665620803833
Validation loss: 2.1359159549077353

Epoch: 6| Step: 2
Training loss: 1.4031274318695068
Validation loss: 2.1285086472829184

Epoch: 6| Step: 3
Training loss: 0.5309548377990723
Validation loss: 2.0968878467877707

Epoch: 6| Step: 4
Training loss: 1.0763599872589111
Validation loss: 2.1355196634928384

Epoch: 6| Step: 5
Training loss: 0.6914932131767273
Validation loss: 2.134813904762268

Epoch: 6| Step: 6
Training loss: 1.412654161453247
Validation loss: 2.0874804059664407

Epoch: 6| Step: 7
Training loss: 1.4919686317443848
Validation loss: 2.168229401111603

Epoch: 6| Step: 8
Training loss: 1.4386873245239258
Validation loss: 2.150436818599701

Epoch: 6| Step: 9
Training loss: 0.5959864258766174
Validation loss: 2.1386603315671286

Epoch: 6| Step: 10
Training loss: 0.9473177790641785
Validation loss: 2.12220561504364

Epoch: 6| Step: 11
Training loss: 1.032151699066162
Validation loss: 2.1489015420277915

Epoch: 6| Step: 12
Training loss: 0.7685462832450867
Validation loss: 2.1011465986569724

Epoch: 6| Step: 13
Training loss: 1.1956455707550049
Validation loss: 2.1673057874043784

Epoch: 366| Step: 0
Training loss: 0.8428907990455627
Validation loss: 2.1639274954795837

Epoch: 6| Step: 1
Training loss: 0.7864002585411072
Validation loss: 2.1909827987353006

Epoch: 6| Step: 2
Training loss: 1.4176695346832275
Validation loss: 2.1845492323239646

Epoch: 6| Step: 3
Training loss: 0.7739553451538086
Validation loss: 2.19855397939682

Epoch: 6| Step: 4
Training loss: 1.4177073240280151
Validation loss: 2.2267576853434243

Epoch: 6| Step: 5
Training loss: 0.6786137223243713
Validation loss: 2.2106855114301047

Epoch: 6| Step: 6
Training loss: 1.2580146789550781
Validation loss: 2.186743358771006

Epoch: 6| Step: 7
Training loss: 0.6733914613723755
Validation loss: 2.1892234683036804

Epoch: 6| Step: 8
Training loss: 1.350473165512085
Validation loss: 2.1591155529022217

Epoch: 6| Step: 9
Training loss: 1.3400993347167969
Validation loss: 2.1051457722981772

Epoch: 6| Step: 10
Training loss: 1.7643406391143799
Validation loss: 2.1138016978899636

Epoch: 6| Step: 11
Training loss: 0.6771450042724609
Validation loss: 2.122834304968516

Epoch: 6| Step: 12
Training loss: 1.013617753982544
Validation loss: 2.122891346613566

Epoch: 6| Step: 13
Training loss: 0.4274608790874481
Validation loss: 2.1152782440185547

Epoch: 367| Step: 0
Training loss: 0.9307186603546143
Validation loss: 2.1025205651919046

Epoch: 6| Step: 1
Training loss: 0.655872642993927
Validation loss: 2.079556425412496

Epoch: 6| Step: 2
Training loss: 0.7546622157096863
Validation loss: 2.115377406279246

Epoch: 6| Step: 3
Training loss: 1.0332610607147217
Validation loss: 2.131976366043091

Epoch: 6| Step: 4
Training loss: 0.6670413613319397
Validation loss: 2.157262603441874

Epoch: 6| Step: 5
Training loss: 0.9637137651443481
Validation loss: 2.0898603002230325

Epoch: 6| Step: 6
Training loss: 1.1991785764694214
Validation loss: 2.13491161664327

Epoch: 6| Step: 7
Training loss: 0.7202908396720886
Validation loss: 2.116308808326721

Epoch: 6| Step: 8
Training loss: 1.390582799911499
Validation loss: 2.1255565087000527

Epoch: 6| Step: 9
Training loss: 1.5427134037017822
Validation loss: 2.1328943173090615

Epoch: 6| Step: 10
Training loss: 0.4306345582008362
Validation loss: 2.095543364683787

Epoch: 6| Step: 11
Training loss: 1.0848791599273682
Validation loss: 2.1115145285924277

Epoch: 6| Step: 12
Training loss: 1.19163978099823
Validation loss: 2.1550411383310952

Epoch: 6| Step: 13
Training loss: 1.5948469638824463
Validation loss: 2.1339924931526184

Epoch: 368| Step: 0
Training loss: 0.9353150129318237
Validation loss: 2.1678101619084678

Epoch: 6| Step: 1
Training loss: 0.8820676207542419
Validation loss: 2.14853843053182

Epoch: 6| Step: 2
Training loss: 1.6214516162872314
Validation loss: 2.1381986339886985

Epoch: 6| Step: 3
Training loss: 2.1165311336517334
Validation loss: 2.1856879393259683

Epoch: 6| Step: 4
Training loss: 1.389147400856018
Validation loss: 2.158158600330353

Epoch: 6| Step: 5
Training loss: 0.5510760545730591
Validation loss: 2.152349571386973

Epoch: 6| Step: 6
Training loss: 1.0375981330871582
Validation loss: 2.165949741999308

Epoch: 6| Step: 7
Training loss: 0.6608971357345581
Validation loss: 2.192371209462484

Epoch: 6| Step: 8
Training loss: 1.3937320709228516
Validation loss: 2.172178268432617

Epoch: 6| Step: 9
Training loss: 0.5105810165405273
Validation loss: 2.149716595808665

Epoch: 6| Step: 10
Training loss: 0.984908401966095
Validation loss: 2.1744591991106668

Epoch: 6| Step: 11
Training loss: 1.0416796207427979
Validation loss: 2.1891469955444336

Epoch: 6| Step: 12
Training loss: 1.3629558086395264
Validation loss: 2.1976818641026816

Epoch: 6| Step: 13
Training loss: 0.8567681312561035
Validation loss: 2.1797521313031516

Epoch: 369| Step: 0
Training loss: 1.2259080410003662
Validation loss: 2.1821154356002808

Epoch: 6| Step: 1
Training loss: 1.7568402290344238
Validation loss: 2.196485181649526

Epoch: 6| Step: 2
Training loss: 0.6845440864562988
Validation loss: 2.1238656640052795

Epoch: 6| Step: 3
Training loss: 1.0563812255859375
Validation loss: 2.131890674432119

Epoch: 6| Step: 4
Training loss: 0.6629320979118347
Validation loss: 2.1405717531840005

Epoch: 6| Step: 5
Training loss: 0.9614008665084839
Validation loss: 2.154935876528422

Epoch: 6| Step: 6
Training loss: 1.06654953956604
Validation loss: 2.172278046607971

Epoch: 6| Step: 7
Training loss: 1.1678111553192139
Validation loss: 2.1910094022750854

Epoch: 6| Step: 8
Training loss: 1.6789376735687256
Validation loss: 2.152449607849121

Epoch: 6| Step: 9
Training loss: 0.7367479205131531
Validation loss: 2.2356706857681274

Epoch: 6| Step: 10
Training loss: 1.3560717105865479
Validation loss: 2.1122844417889914

Epoch: 6| Step: 11
Training loss: 0.6016207933425903
Validation loss: 2.1491730213165283

Epoch: 6| Step: 12
Training loss: 0.5943614840507507
Validation loss: 2.142383416493734

Epoch: 6| Step: 13
Training loss: 1.0177289247512817
Validation loss: 2.1334130565325418

Epoch: 370| Step: 0
Training loss: 0.6873219609260559
Validation loss: 2.0899409651756287

Epoch: 6| Step: 1
Training loss: 0.5984628796577454
Validation loss: 2.087602694829305

Epoch: 6| Step: 2
Training loss: 0.7020102143287659
Validation loss: 2.1093016465504966

Epoch: 6| Step: 3
Training loss: 1.0502526760101318
Validation loss: 2.0944133202234902

Epoch: 6| Step: 4
Training loss: 2.1002931594848633
Validation loss: 2.1163500448067984

Epoch: 6| Step: 5
Training loss: 1.3298578262329102
Validation loss: 2.138710300127665

Epoch: 6| Step: 6
Training loss: 1.432802677154541
Validation loss: 2.1193602085113525

Epoch: 6| Step: 7
Training loss: 0.8958470821380615
Validation loss: 2.0957608222961426

Epoch: 6| Step: 8
Training loss: 0.5060473084449768
Validation loss: 2.134617547194163

Epoch: 6| Step: 9
Training loss: 1.2150506973266602
Validation loss: 2.1294228037198386

Epoch: 6| Step: 10
Training loss: 1.4853500127792358
Validation loss: 2.1072633266448975

Epoch: 6| Step: 11
Training loss: 1.3300883769989014
Validation loss: 2.1109087467193604

Epoch: 6| Step: 12
Training loss: 0.4525948464870453
Validation loss: 2.0867874224980674

Epoch: 6| Step: 13
Training loss: 0.9052013754844666
Validation loss: 2.1105525294939675

Epoch: 371| Step: 0
Training loss: 1.1657501459121704
Validation loss: 2.1134187380472818

Epoch: 6| Step: 1
Training loss: 1.2042453289031982
Validation loss: 2.135023355484009

Epoch: 6| Step: 2
Training loss: 1.1611382961273193
Validation loss: 2.103100577990214

Epoch: 6| Step: 3
Training loss: 0.9526603817939758
Validation loss: 2.1515994866689048

Epoch: 6| Step: 4
Training loss: 0.95988929271698
Validation loss: 2.154206097126007

Epoch: 6| Step: 5
Training loss: 0.8539011478424072
Validation loss: 2.143367330233256

Epoch: 6| Step: 6
Training loss: 0.6050081253051758
Validation loss: 2.128839135169983

Epoch: 6| Step: 7
Training loss: 1.349334955215454
Validation loss: 2.117337723573049

Epoch: 6| Step: 8
Training loss: 0.6589193940162659
Validation loss: 2.1416255036989846

Epoch: 6| Step: 9
Training loss: 0.9184715747833252
Validation loss: 2.1201295852661133

Epoch: 6| Step: 10
Training loss: 1.1481350660324097
Validation loss: 2.108895699183146

Epoch: 6| Step: 11
Training loss: 0.9509889483451843
Validation loss: 2.125311096509298

Epoch: 6| Step: 12
Training loss: 1.3964022397994995
Validation loss: 2.1646485726038613

Epoch: 6| Step: 13
Training loss: 0.9898748993873596
Validation loss: 2.1343300342559814

Epoch: 372| Step: 0
Training loss: 0.8952168822288513
Validation loss: 2.1636924743652344

Epoch: 6| Step: 1
Training loss: 1.3760887384414673
Validation loss: 2.155437191327413

Epoch: 6| Step: 2
Training loss: 0.8331179618835449
Validation loss: 2.1222384770711265

Epoch: 6| Step: 3
Training loss: 0.8131052255630493
Validation loss: 2.1900132099787393

Epoch: 6| Step: 4
Training loss: 1.39413321018219
Validation loss: 2.17356143395106

Epoch: 6| Step: 5
Training loss: 1.0463041067123413
Validation loss: 2.1487238804499307

Epoch: 6| Step: 6
Training loss: 1.494922399520874
Validation loss: 2.168149550755819

Epoch: 6| Step: 7
Training loss: 1.1280878782272339
Validation loss: 2.185421605904897

Epoch: 6| Step: 8
Training loss: 0.5489473938941956
Validation loss: 2.1651398142178855

Epoch: 6| Step: 9
Training loss: 1.015255331993103
Validation loss: 2.178615689277649

Epoch: 6| Step: 10
Training loss: 0.8890266418457031
Validation loss: 2.15197745958964

Epoch: 6| Step: 11
Training loss: 0.7330954670906067
Validation loss: 2.160829742749532

Epoch: 6| Step: 12
Training loss: 0.7089735269546509
Validation loss: 2.198491712411245

Epoch: 6| Step: 13
Training loss: 1.4423326253890991
Validation loss: 2.159369786580404

Epoch: 373| Step: 0
Training loss: 0.9208370447158813
Validation loss: 2.144954025745392

Epoch: 6| Step: 1
Training loss: 1.1766700744628906
Validation loss: 2.160357117652893

Epoch: 6| Step: 2
Training loss: 0.6223829388618469
Validation loss: 2.144033749898275

Epoch: 6| Step: 3
Training loss: 1.2742412090301514
Validation loss: 2.123805304368337

Epoch: 6| Step: 4
Training loss: 0.884589672088623
Validation loss: 2.0850598216056824

Epoch: 6| Step: 5
Training loss: 0.9580538868904114
Validation loss: 2.1473671396573386

Epoch: 6| Step: 6
Training loss: 0.578343391418457
Validation loss: 2.1529620885849

Epoch: 6| Step: 7
Training loss: 0.8457562923431396
Validation loss: 2.1625707149505615

Epoch: 6| Step: 8
Training loss: 0.8597164750099182
Validation loss: 2.1902183294296265

Epoch: 6| Step: 9
Training loss: 1.1265166997909546
Validation loss: 2.18265708287557

Epoch: 6| Step: 10
Training loss: 1.1650710105895996
Validation loss: 2.153696298599243

Epoch: 6| Step: 11
Training loss: 1.228765845298767
Validation loss: 2.2253886659940085

Epoch: 6| Step: 12
Training loss: 1.07625150680542
Validation loss: 2.1517149209976196

Epoch: 6| Step: 13
Training loss: 1.1543664932250977
Validation loss: 2.195663571357727

Epoch: 374| Step: 0
Training loss: 0.9302651882171631
Validation loss: 2.1050507028897605

Epoch: 6| Step: 1
Training loss: 1.072403907775879
Validation loss: 2.154322107632955

Epoch: 6| Step: 2
Training loss: 0.8768172264099121
Validation loss: 2.1914126674334207

Epoch: 6| Step: 3
Training loss: 0.8321248292922974
Validation loss: 2.1338191429773965

Epoch: 6| Step: 4
Training loss: 0.7146273255348206
Validation loss: 2.1725387970606485

Epoch: 6| Step: 5
Training loss: 0.7459155321121216
Validation loss: 2.152581055959066

Epoch: 6| Step: 6
Training loss: 1.3117014169692993
Validation loss: 2.176328500111898

Epoch: 6| Step: 7
Training loss: 0.6649433374404907
Validation loss: 2.1937010685602822

Epoch: 6| Step: 8
Training loss: 0.9491137266159058
Validation loss: 2.2028600374857583

Epoch: 6| Step: 9
Training loss: 1.4006147384643555
Validation loss: 2.178512990474701

Epoch: 6| Step: 10
Training loss: 1.6128365993499756
Validation loss: 2.186960061391195

Epoch: 6| Step: 11
Training loss: 1.3847606182098389
Validation loss: 2.2114643454551697

Epoch: 6| Step: 12
Training loss: 0.6742876768112183
Validation loss: 2.2105591694513955

Epoch: 6| Step: 13
Training loss: 1.120769739151001
Validation loss: 2.2004171013832092

Epoch: 375| Step: 0
Training loss: 0.8102689981460571
Validation loss: 2.2174479961395264

Epoch: 6| Step: 1
Training loss: 0.832168698310852
Validation loss: 2.200889746348063

Epoch: 6| Step: 2
Training loss: 1.0451066493988037
Validation loss: 2.1710771322250366

Epoch: 6| Step: 3
Training loss: 0.9120635390281677
Validation loss: 2.108708063761393

Epoch: 6| Step: 4
Training loss: 0.729651689529419
Validation loss: 2.167132834593455

Epoch: 6| Step: 5
Training loss: 1.272070050239563
Validation loss: 2.1727127035458884

Epoch: 6| Step: 6
Training loss: 1.242034912109375
Validation loss: 2.1709394653638205

Epoch: 6| Step: 7
Training loss: 1.2635836601257324
Validation loss: 2.2140060663223267

Epoch: 6| Step: 8
Training loss: 0.6782382130622864
Validation loss: 2.1797064542770386

Epoch: 6| Step: 9
Training loss: 0.8173854351043701
Validation loss: 2.187126417954763

Epoch: 6| Step: 10
Training loss: 1.2981171607971191
Validation loss: 2.1347963213920593

Epoch: 6| Step: 11
Training loss: 0.8478707671165466
Validation loss: 2.146225392818451

Epoch: 6| Step: 12
Training loss: 1.0931507349014282
Validation loss: 2.128135085105896

Epoch: 6| Step: 13
Training loss: 0.5708878040313721
Validation loss: 2.144485433896383

Epoch: 376| Step: 0
Training loss: 1.2968372106552124
Validation loss: 2.1549188097318015

Epoch: 6| Step: 1
Training loss: 0.9552289843559265
Validation loss: 2.119247833887736

Epoch: 6| Step: 2
Training loss: 1.2219740152359009
Validation loss: 2.132823367913564

Epoch: 6| Step: 3
Training loss: 1.0506072044372559
Validation loss: 2.1592214504877725

Epoch: 6| Step: 4
Training loss: 0.7730679512023926
Validation loss: 2.1654348373413086

Epoch: 6| Step: 5
Training loss: 0.6713836193084717
Validation loss: 2.1712893644968667

Epoch: 6| Step: 6
Training loss: 0.5711234211921692
Validation loss: 2.1750680208206177

Epoch: 6| Step: 7
Training loss: 0.8111971020698547
Validation loss: 2.1818196177482605

Epoch: 6| Step: 8
Training loss: 1.1689062118530273
Validation loss: 2.205227851867676

Epoch: 6| Step: 9
Training loss: 0.8475449085235596
Validation loss: 2.1942877968152366

Epoch: 6| Step: 10
Training loss: 0.502852201461792
Validation loss: 2.154359837373098

Epoch: 6| Step: 11
Training loss: 1.1300079822540283
Validation loss: 2.188032547632853

Epoch: 6| Step: 12
Training loss: 1.7962170839309692
Validation loss: 2.140159765879313

Epoch: 6| Step: 13
Training loss: 1.237170696258545
Validation loss: 2.1234679222106934

Epoch: 377| Step: 0
Training loss: 0.9479507207870483
Validation loss: 2.1245839595794678

Epoch: 6| Step: 1
Training loss: 0.90517258644104
Validation loss: 2.1490256786346436

Epoch: 6| Step: 2
Training loss: 1.1745635271072388
Validation loss: 2.1705079476038613

Epoch: 6| Step: 3
Training loss: 1.3572487831115723
Validation loss: 2.191355506579081

Epoch: 6| Step: 4
Training loss: 0.7013064622879028
Validation loss: 2.2360026836395264

Epoch: 6| Step: 5
Training loss: 0.7767186164855957
Validation loss: 2.1804093519846597

Epoch: 6| Step: 6
Training loss: 0.7824565172195435
Validation loss: 2.1846587459246316

Epoch: 6| Step: 7
Training loss: 0.9847013354301453
Validation loss: 2.224562883377075

Epoch: 6| Step: 8
Training loss: 0.835784375667572
Validation loss: 2.181233763694763

Epoch: 6| Step: 9
Training loss: 0.7364747524261475
Validation loss: 2.2152958710988364

Epoch: 6| Step: 10
Training loss: 1.437374234199524
Validation loss: 2.1663317879041037

Epoch: 6| Step: 11
Training loss: 1.2984964847564697
Validation loss: 2.1702905098597207

Epoch: 6| Step: 12
Training loss: 1.233213186264038
Validation loss: 2.1973766485850015

Epoch: 6| Step: 13
Training loss: 0.6184039115905762
Validation loss: 2.172512928644816

Epoch: 378| Step: 0
Training loss: 0.5603624582290649
Validation loss: 2.1711943546930947

Epoch: 6| Step: 1
Training loss: 1.1337679624557495
Validation loss: 2.2071299950281777

Epoch: 6| Step: 2
Training loss: 0.8769141435623169
Validation loss: 2.158241411050161

Epoch: 6| Step: 3
Training loss: 0.6378219127655029
Validation loss: 2.2047526240348816

Epoch: 6| Step: 4
Training loss: 1.0051506757736206
Validation loss: 2.15972508986791

Epoch: 6| Step: 5
Training loss: 0.6740803718566895
Validation loss: 2.2041721741358438

Epoch: 6| Step: 6
Training loss: 0.8115860223770142
Validation loss: 2.1595563491185508

Epoch: 6| Step: 7
Training loss: 1.5501995086669922
Validation loss: 2.19653711716334

Epoch: 6| Step: 8
Training loss: 1.1050922870635986
Validation loss: 2.2019142508506775

Epoch: 6| Step: 9
Training loss: 0.6948809623718262
Validation loss: 2.154899815718333

Epoch: 6| Step: 10
Training loss: 0.7967450618743896
Validation loss: 2.186792274316152

Epoch: 6| Step: 11
Training loss: 1.6362903118133545
Validation loss: 2.183609584967295

Epoch: 6| Step: 12
Training loss: 1.017731785774231
Validation loss: 2.174185037612915

Epoch: 6| Step: 13
Training loss: 1.1304019689559937
Validation loss: 2.181147038936615

Epoch: 379| Step: 0
Training loss: 0.6018640995025635
Validation loss: 2.1749067505200705

Epoch: 6| Step: 1
Training loss: 1.448727011680603
Validation loss: 2.149130702018738

Epoch: 6| Step: 2
Training loss: 1.2510181665420532
Validation loss: 2.1736286282539368

Epoch: 6| Step: 3
Training loss: 1.1555408239364624
Validation loss: 2.1977070569992065

Epoch: 6| Step: 4
Training loss: 0.9414154887199402
Validation loss: 2.185461183389028

Epoch: 6| Step: 5
Training loss: 0.9447609186172485
Validation loss: 2.205682953198751

Epoch: 6| Step: 6
Training loss: 0.929275393486023
Validation loss: 2.1719270944595337

Epoch: 6| Step: 7
Training loss: 1.2617974281311035
Validation loss: 2.197817027568817

Epoch: 6| Step: 8
Training loss: 0.5934725999832153
Validation loss: 2.1374805768330893

Epoch: 6| Step: 9
Training loss: 0.9865193367004395
Validation loss: 2.1660873889923096

Epoch: 6| Step: 10
Training loss: 0.4467658996582031
Validation loss: 2.1577175060908

Epoch: 6| Step: 11
Training loss: 0.8168900012969971
Validation loss: 2.165167431036631

Epoch: 6| Step: 12
Training loss: 0.7412172555923462
Validation loss: 2.153645912806193

Epoch: 6| Step: 13
Training loss: 1.354675054550171
Validation loss: 2.103193163871765

Epoch: 380| Step: 0
Training loss: 1.0128189325332642
Validation loss: 2.144233067830404

Epoch: 6| Step: 1
Training loss: 1.1115672588348389
Validation loss: 2.1372897823651633

Epoch: 6| Step: 2
Training loss: 0.792471170425415
Validation loss: 2.1934451858202615

Epoch: 6| Step: 3
Training loss: 1.2103562355041504
Validation loss: 2.2184011538823447

Epoch: 6| Step: 4
Training loss: 1.6250094175338745
Validation loss: 2.2134666641553244

Epoch: 6| Step: 5
Training loss: 1.1587560176849365
Validation loss: 2.2011008262634277

Epoch: 6| Step: 6
Training loss: 0.5028030276298523
Validation loss: 2.12174520889918

Epoch: 6| Step: 7
Training loss: 1.5606982707977295
Validation loss: 2.1919236183166504

Epoch: 6| Step: 8
Training loss: 0.9308868646621704
Validation loss: 2.152255435784658

Epoch: 6| Step: 9
Training loss: 0.8759832978248596
Validation loss: 2.1501662731170654

Epoch: 6| Step: 10
Training loss: 0.7623245716094971
Validation loss: 2.131267547607422

Epoch: 6| Step: 11
Training loss: 0.5926533937454224
Validation loss: 2.105114459991455

Epoch: 6| Step: 12
Training loss: 1.3158761262893677
Validation loss: 2.1494222482045493

Epoch: 6| Step: 13
Training loss: 0.7583867907524109
Validation loss: 2.134974936644236

Epoch: 381| Step: 0
Training loss: 0.8109885454177856
Validation loss: 2.1692607005437217

Epoch: 6| Step: 1
Training loss: 0.39388617873191833
Validation loss: 2.128774563471476

Epoch: 6| Step: 2
Training loss: 0.9156333804130554
Validation loss: 2.1920084953308105

Epoch: 6| Step: 3
Training loss: 0.7338569164276123
Validation loss: 2.1926740209261575

Epoch: 6| Step: 4
Training loss: 0.7677206993103027
Validation loss: 2.2069900830586753

Epoch: 6| Step: 5
Training loss: 1.0029526948928833
Validation loss: 2.179622252782186

Epoch: 6| Step: 6
Training loss: 1.0966734886169434
Validation loss: 2.173683782418569

Epoch: 6| Step: 7
Training loss: 0.6953867077827454
Validation loss: 2.172966480255127

Epoch: 6| Step: 8
Training loss: 1.3665623664855957
Validation loss: 2.156034787495931

Epoch: 6| Step: 9
Training loss: 1.5807433128356934
Validation loss: 2.246514678001404

Epoch: 6| Step: 10
Training loss: 1.0731680393218994
Validation loss: 2.18178919951121

Epoch: 6| Step: 11
Training loss: 0.7181994318962097
Validation loss: 2.1955834229787192

Epoch: 6| Step: 12
Training loss: 1.249983310699463
Validation loss: 2.1820041735967

Epoch: 6| Step: 13
Training loss: 0.8969991207122803
Validation loss: 2.1730721592903137

Epoch: 382| Step: 0
Training loss: 0.583564281463623
Validation loss: 2.1891494592030845

Epoch: 6| Step: 1
Training loss: 1.4796661138534546
Validation loss: 2.1734959284464517

Epoch: 6| Step: 2
Training loss: 0.43528658151626587
Validation loss: 2.2222888469696045

Epoch: 6| Step: 3
Training loss: 0.8986901044845581
Validation loss: 2.176078657309214

Epoch: 6| Step: 4
Training loss: 1.0237202644348145
Validation loss: 2.235218862692515

Epoch: 6| Step: 5
Training loss: 0.7748333215713501
Validation loss: 2.2182993292808533

Epoch: 6| Step: 6
Training loss: 0.7664989233016968
Validation loss: 2.2144820292790732

Epoch: 6| Step: 7
Training loss: 1.0748522281646729
Validation loss: 2.204132298628489

Epoch: 6| Step: 8
Training loss: 1.150942325592041
Validation loss: 2.1881300608317056

Epoch: 6| Step: 9
Training loss: 1.1986634731292725
Validation loss: 2.1996378302574158

Epoch: 6| Step: 10
Training loss: 0.9234147071838379
Validation loss: 2.196855088075002

Epoch: 6| Step: 11
Training loss: 0.8205369710922241
Validation loss: 2.2061864336331687

Epoch: 6| Step: 12
Training loss: 1.5209949016571045
Validation loss: 2.234420637289683

Epoch: 6| Step: 13
Training loss: 0.8056842088699341
Validation loss: 2.172593037287394

Epoch: 383| Step: 0
Training loss: 2.0681731700897217
Validation loss: 2.199573496977488

Epoch: 6| Step: 1
Training loss: 0.560431718826294
Validation loss: 2.225706477959951

Epoch: 6| Step: 2
Training loss: 1.1181886196136475
Validation loss: 2.2261277238527932

Epoch: 6| Step: 3
Training loss: 0.4733845889568329
Validation loss: 2.2088229656219482

Epoch: 6| Step: 4
Training loss: 0.5116215348243713
Validation loss: 2.2128074765205383

Epoch: 6| Step: 5
Training loss: 0.888096809387207
Validation loss: 2.2230594952901206

Epoch: 6| Step: 6
Training loss: 1.2845873832702637
Validation loss: 2.235697786013285

Epoch: 6| Step: 7
Training loss: 0.7398794889450073
Validation loss: 2.258144994576772

Epoch: 6| Step: 8
Training loss: 0.8999032378196716
Validation loss: 2.198235293229421

Epoch: 6| Step: 9
Training loss: 0.7442741394042969
Validation loss: 2.216227889060974

Epoch: 6| Step: 10
Training loss: 0.6726364493370056
Validation loss: 2.190587600072225

Epoch: 6| Step: 11
Training loss: 1.7156827449798584
Validation loss: 2.1799995501836142

Epoch: 6| Step: 12
Training loss: 0.4732500910758972
Validation loss: 2.1795650124549866

Epoch: 6| Step: 13
Training loss: 0.7725957036018372
Validation loss: 2.1807335217793784

Epoch: 384| Step: 0
Training loss: 0.9146744012832642
Validation loss: 2.210310479005178

Epoch: 6| Step: 1
Training loss: 1.3408374786376953
Validation loss: 2.218493342399597

Epoch: 6| Step: 2
Training loss: 1.0397738218307495
Validation loss: 2.227909505367279

Epoch: 6| Step: 3
Training loss: 1.1932419538497925
Validation loss: 2.206498106320699

Epoch: 6| Step: 4
Training loss: 0.6246942281723022
Validation loss: 2.2066415548324585

Epoch: 6| Step: 5
Training loss: 0.9526234269142151
Validation loss: 2.1482633550961814

Epoch: 6| Step: 6
Training loss: 1.1118924617767334
Validation loss: 2.157439668973287

Epoch: 6| Step: 7
Training loss: 0.7775214910507202
Validation loss: 2.100676973660787

Epoch: 6| Step: 8
Training loss: 0.8318255543708801
Validation loss: 2.1355172395706177

Epoch: 6| Step: 9
Training loss: 1.4066989421844482
Validation loss: 2.1328168511390686

Epoch: 6| Step: 10
Training loss: 1.1661473512649536
Validation loss: 2.12882399559021

Epoch: 6| Step: 11
Training loss: 0.4424116611480713
Validation loss: 2.1588224371274314

Epoch: 6| Step: 12
Training loss: 1.5201809406280518
Validation loss: 2.1898938020070395

Epoch: 6| Step: 13
Training loss: 0.8656625747680664
Validation loss: 2.1966938773790994

Epoch: 385| Step: 0
Training loss: 1.0076029300689697
Validation loss: 2.181717852751414

Epoch: 6| Step: 1
Training loss: 0.953744649887085
Validation loss: 2.208988606929779

Epoch: 6| Step: 2
Training loss: 1.2850521802902222
Validation loss: 2.216049234072367

Epoch: 6| Step: 3
Training loss: 0.8375841379165649
Validation loss: 2.1713857849438987

Epoch: 6| Step: 4
Training loss: 0.4999954402446747
Validation loss: 2.1850972374280295

Epoch: 6| Step: 5
Training loss: 0.9804980754852295
Validation loss: 2.1264182726542153

Epoch: 6| Step: 6
Training loss: 1.4573948383331299
Validation loss: 2.1773659785588584

Epoch: 6| Step: 7
Training loss: 1.2758100032806396
Validation loss: 2.195322791735331

Epoch: 6| Step: 8
Training loss: 1.4150662422180176
Validation loss: 2.2235613663991294

Epoch: 6| Step: 9
Training loss: 1.7152888774871826
Validation loss: 2.222115476926168

Epoch: 6| Step: 10
Training loss: 1.1769475936889648
Validation loss: 2.169569989045461

Epoch: 6| Step: 11
Training loss: 0.6256236433982849
Validation loss: 2.1844926476478577

Epoch: 6| Step: 12
Training loss: 0.6993066668510437
Validation loss: 2.1326905886332193

Epoch: 6| Step: 13
Training loss: 0.760291337966919
Validation loss: 2.173280636469523

Epoch: 386| Step: 0
Training loss: 1.8060003519058228
Validation loss: 2.2174232999483743

Epoch: 6| Step: 1
Training loss: 1.6618921756744385
Validation loss: 2.28229683637619

Epoch: 6| Step: 2
Training loss: 0.7332779169082642
Validation loss: 2.2279255191485086

Epoch: 6| Step: 3
Training loss: 0.5261680483818054
Validation loss: 2.2258504033088684

Epoch: 6| Step: 4
Training loss: 1.070731520652771
Validation loss: 2.1707095305124917

Epoch: 6| Step: 5
Training loss: 0.6653051376342773
Validation loss: 2.1463768680890403

Epoch: 6| Step: 6
Training loss: 1.1192989349365234
Validation loss: 2.115665157636007

Epoch: 6| Step: 7
Training loss: 1.0484650135040283
Validation loss: 2.1732881665229797

Epoch: 6| Step: 8
Training loss: 1.1539843082427979
Validation loss: 2.1907188495000205

Epoch: 6| Step: 9
Training loss: 1.4285539388656616
Validation loss: 2.1676995754241943

Epoch: 6| Step: 10
Training loss: 0.6470193266868591
Validation loss: 2.120648205280304

Epoch: 6| Step: 11
Training loss: 0.8742058277130127
Validation loss: 2.1333519220352173

Epoch: 6| Step: 12
Training loss: 0.566185712814331
Validation loss: 2.2040895024935403

Epoch: 6| Step: 13
Training loss: 1.5550928115844727
Validation loss: 2.166093349456787

Epoch: 387| Step: 0
Training loss: 0.6942643523216248
Validation loss: 2.203034241994222

Epoch: 6| Step: 1
Training loss: 0.8030959367752075
Validation loss: 2.203693906466166

Epoch: 6| Step: 2
Training loss: 0.7694829702377319
Validation loss: 2.163618723551432

Epoch: 6| Step: 3
Training loss: 1.1698436737060547
Validation loss: 2.1607026855150857

Epoch: 6| Step: 4
Training loss: 0.6638523936271667
Validation loss: 2.175454298655192

Epoch: 6| Step: 5
Training loss: 0.6616954803466797
Validation loss: 2.1101638674736023

Epoch: 6| Step: 6
Training loss: 0.7552826404571533
Validation loss: 2.122349043687185

Epoch: 6| Step: 7
Training loss: 0.9121676683425903
Validation loss: 2.1440428495407104

Epoch: 6| Step: 8
Training loss: 0.981863260269165
Validation loss: 2.139848053455353

Epoch: 6| Step: 9
Training loss: 0.9143785238265991
Validation loss: 2.1636330286661782

Epoch: 6| Step: 10
Training loss: 0.925454318523407
Validation loss: 2.236392100652059

Epoch: 6| Step: 11
Training loss: 1.404022216796875
Validation loss: 2.2230767011642456

Epoch: 6| Step: 12
Training loss: 0.501484751701355
Validation loss: 2.2089712222417197

Epoch: 6| Step: 13
Training loss: 2.159914016723633
Validation loss: 2.1833073496818542

Epoch: 388| Step: 0
Training loss: 0.8177282214164734
Validation loss: 2.2062470515569053

Epoch: 6| Step: 1
Training loss: 1.0423991680145264
Validation loss: 2.1788618167241416

Epoch: 6| Step: 2
Training loss: 0.7693443298339844
Validation loss: 2.1932572722434998

Epoch: 6| Step: 3
Training loss: 0.8327448964118958
Validation loss: 2.171119729677836

Epoch: 6| Step: 4
Training loss: 0.824236273765564
Validation loss: 2.14177268743515

Epoch: 6| Step: 5
Training loss: 0.9913725852966309
Validation loss: 2.1807684699694314

Epoch: 6| Step: 6
Training loss: 0.38983726501464844
Validation loss: 2.1856865882873535

Epoch: 6| Step: 7
Training loss: 0.42725449800491333
Validation loss: 2.206630766391754

Epoch: 6| Step: 8
Training loss: 1.468851923942566
Validation loss: 2.1940096418062844

Epoch: 6| Step: 9
Training loss: 0.9061338901519775
Validation loss: 2.191772222518921

Epoch: 6| Step: 10
Training loss: 1.0909202098846436
Validation loss: 2.218463957309723

Epoch: 6| Step: 11
Training loss: 0.7609589099884033
Validation loss: 2.217033048470815

Epoch: 6| Step: 12
Training loss: 0.9494622945785522
Validation loss: 2.182800074418386

Epoch: 6| Step: 13
Training loss: 1.4229928255081177
Validation loss: 2.130361795425415

Epoch: 389| Step: 0
Training loss: 0.46099576354026794
Validation loss: 2.110776424407959

Epoch: 6| Step: 1
Training loss: 1.1655359268188477
Validation loss: 2.1791372895240784

Epoch: 6| Step: 2
Training loss: 0.47843456268310547
Validation loss: 2.1738611459732056

Epoch: 6| Step: 3
Training loss: 0.8155409097671509
Validation loss: 2.140388528505961

Epoch: 6| Step: 4
Training loss: 1.0329687595367432
Validation loss: 2.166908840338389

Epoch: 6| Step: 5
Training loss: 1.2998079061508179
Validation loss: 2.1650169690450034

Epoch: 6| Step: 6
Training loss: 0.6868401765823364
Validation loss: 2.1992100278536477

Epoch: 6| Step: 7
Training loss: 0.6711287498474121
Validation loss: 2.162908752759298

Epoch: 6| Step: 8
Training loss: 1.0349136590957642
Validation loss: 2.157707134882609

Epoch: 6| Step: 9
Training loss: 1.2093428373336792
Validation loss: 2.1383017897605896

Epoch: 6| Step: 10
Training loss: 0.5959434509277344
Validation loss: 2.1426146229108176

Epoch: 6| Step: 11
Training loss: 1.2203484773635864
Validation loss: 2.1442853013674417

Epoch: 6| Step: 12
Training loss: 0.972277045249939
Validation loss: 2.181659738222758

Epoch: 6| Step: 13
Training loss: 1.0782781839370728
Validation loss: 2.1432603001594543

Epoch: 390| Step: 0
Training loss: 0.8256482481956482
Validation loss: 2.1907772223154702

Epoch: 6| Step: 1
Training loss: 0.7257950305938721
Validation loss: 2.1375038623809814

Epoch: 6| Step: 2
Training loss: 0.7812771797180176
Validation loss: 2.1705301801363626

Epoch: 6| Step: 3
Training loss: 0.919249415397644
Validation loss: 2.1907281478246055

Epoch: 6| Step: 4
Training loss: 0.812869668006897
Validation loss: 2.1830126643180847

Epoch: 6| Step: 5
Training loss: 1.189182996749878
Validation loss: 2.171562055746714

Epoch: 6| Step: 6
Training loss: 1.2434520721435547
Validation loss: 2.1471834977467856

Epoch: 6| Step: 7
Training loss: 1.2014358043670654
Validation loss: 2.1713213125864663

Epoch: 6| Step: 8
Training loss: 0.656406044960022
Validation loss: 2.1821138064066568

Epoch: 6| Step: 9
Training loss: 0.8134812116622925
Validation loss: 2.165882110595703

Epoch: 6| Step: 10
Training loss: 0.7842558026313782
Validation loss: 2.1710172096888223

Epoch: 6| Step: 11
Training loss: 0.9858626127243042
Validation loss: 2.174802283445994

Epoch: 6| Step: 12
Training loss: 0.6407732963562012
Validation loss: 2.1724135677019754

Epoch: 6| Step: 13
Training loss: 0.7388043999671936
Validation loss: 2.1860761245091758

Epoch: 391| Step: 0
Training loss: 1.1342484951019287
Validation loss: 2.2044565677642822

Epoch: 6| Step: 1
Training loss: 0.8129061460494995
Validation loss: 2.165860593318939

Epoch: 6| Step: 2
Training loss: 1.0970098972320557
Validation loss: 2.191240429878235

Epoch: 6| Step: 3
Training loss: 0.5903753042221069
Validation loss: 2.1972810427347818

Epoch: 6| Step: 4
Training loss: 0.5296325087547302
Validation loss: 2.1796873410542807

Epoch: 6| Step: 5
Training loss: 0.8794746994972229
Validation loss: 2.194963494936625

Epoch: 6| Step: 6
Training loss: 0.39269834756851196
Validation loss: 2.218243738015493

Epoch: 6| Step: 7
Training loss: 1.2367911338806152
Validation loss: 2.1958452463150024

Epoch: 6| Step: 8
Training loss: 1.064697265625
Validation loss: 2.218692938486735

Epoch: 6| Step: 9
Training loss: 0.5368753671646118
Validation loss: 2.196404675642649

Epoch: 6| Step: 10
Training loss: 0.4130074977874756
Validation loss: 2.1988266905148826

Epoch: 6| Step: 11
Training loss: 0.8426977396011353
Validation loss: 2.168764313062032

Epoch: 6| Step: 12
Training loss: 1.4319686889648438
Validation loss: 2.1992464860280356

Epoch: 6| Step: 13
Training loss: 1.119773268699646
Validation loss: 2.146154304345449

Epoch: 392| Step: 0
Training loss: 0.6829513311386108
Validation loss: 2.1745932499567666

Epoch: 6| Step: 1
Training loss: 0.7612498998641968
Validation loss: 2.135462999343872

Epoch: 6| Step: 2
Training loss: 0.7469372749328613
Validation loss: 2.1467393239339194

Epoch: 6| Step: 3
Training loss: 0.8263847827911377
Validation loss: 2.1558982332547507

Epoch: 6| Step: 4
Training loss: 0.6750060319900513
Validation loss: 2.2036476929982505

Epoch: 6| Step: 5
Training loss: 1.1079440116882324
Validation loss: 2.1512596805890403

Epoch: 6| Step: 6
Training loss: 1.2182040214538574
Validation loss: 2.141066829363505

Epoch: 6| Step: 7
Training loss: 0.7228891849517822
Validation loss: 2.1845028599103293

Epoch: 6| Step: 8
Training loss: 0.47604769468307495
Validation loss: 2.167011280854543

Epoch: 6| Step: 9
Training loss: 1.578585147857666
Validation loss: 2.1522140304247537

Epoch: 6| Step: 10
Training loss: 0.6717401146888733
Validation loss: 2.1254175305366516

Epoch: 6| Step: 11
Training loss: 0.6306405663490295
Validation loss: 2.1352996230125427

Epoch: 6| Step: 12
Training loss: 0.8205509185791016
Validation loss: 2.1637431184450784

Epoch: 6| Step: 13
Training loss: 1.3443677425384521
Validation loss: 2.199372112751007

Epoch: 393| Step: 0
Training loss: 0.5263200998306274
Validation loss: 2.1742427746454873

Epoch: 6| Step: 1
Training loss: 0.35005682706832886
Validation loss: 2.1798436641693115

Epoch: 6| Step: 2
Training loss: 0.9149156212806702
Validation loss: 2.139126400152842

Epoch: 6| Step: 3
Training loss: 0.9989196062088013
Validation loss: 2.156691610813141

Epoch: 6| Step: 4
Training loss: 0.6147936582565308
Validation loss: 2.1353370745976767

Epoch: 6| Step: 5
Training loss: 1.033546805381775
Validation loss: 2.15824693441391

Epoch: 6| Step: 6
Training loss: 0.908443033695221
Validation loss: 2.20640101035436

Epoch: 6| Step: 7
Training loss: 0.5293238162994385
Validation loss: 2.136932293574015

Epoch: 6| Step: 8
Training loss: 1.3958210945129395
Validation loss: 2.1023674805959067

Epoch: 6| Step: 9
Training loss: 0.9946853518486023
Validation loss: 2.1097930669784546

Epoch: 6| Step: 10
Training loss: 0.5303817987442017
Validation loss: 2.1603131890296936

Epoch: 6| Step: 11
Training loss: 1.1324076652526855
Validation loss: 2.142273763815562

Epoch: 6| Step: 12
Training loss: 1.1077866554260254
Validation loss: 2.153599123160044

Epoch: 6| Step: 13
Training loss: 1.3665919303894043
Validation loss: 2.20831831296285

Epoch: 394| Step: 0
Training loss: 0.7838646173477173
Validation loss: 2.20196141799291

Epoch: 6| Step: 1
Training loss: 0.7927389144897461
Validation loss: 2.179311196009318

Epoch: 6| Step: 2
Training loss: 1.1839263439178467
Validation loss: 2.187247355779012

Epoch: 6| Step: 3
Training loss: 0.8393940925598145
Validation loss: 2.1880114674568176

Epoch: 6| Step: 4
Training loss: 0.38876819610595703
Validation loss: 2.155403435230255

Epoch: 6| Step: 5
Training loss: 0.9745880365371704
Validation loss: 2.15274316072464

Epoch: 6| Step: 6
Training loss: 0.8962116241455078
Validation loss: 2.177371323108673

Epoch: 6| Step: 7
Training loss: 1.1229220628738403
Validation loss: 2.1637731194496155

Epoch: 6| Step: 8
Training loss: 0.5817193984985352
Validation loss: 2.162484029928843

Epoch: 6| Step: 9
Training loss: 0.7765617370605469
Validation loss: 2.2069958647092185

Epoch: 6| Step: 10
Training loss: 0.5454365611076355
Validation loss: 2.19502592086792

Epoch: 6| Step: 11
Training loss: 0.9835466146469116
Validation loss: 2.165877640247345

Epoch: 6| Step: 12
Training loss: 1.5427920818328857
Validation loss: 2.2100340922673545

Epoch: 6| Step: 13
Training loss: 0.7891120910644531
Validation loss: 2.1537110010782876

Epoch: 395| Step: 0
Training loss: 0.6575025916099548
Validation loss: 2.1603198051452637

Epoch: 6| Step: 1
Training loss: 0.5025794506072998
Validation loss: 2.191845198472341

Epoch: 6| Step: 2
Training loss: 0.6685112714767456
Validation loss: 2.1717326045036316

Epoch: 6| Step: 3
Training loss: 1.048501968383789
Validation loss: 2.1599430640538535

Epoch: 6| Step: 4
Training loss: 0.8994288444519043
Validation loss: 2.1681867639223733

Epoch: 6| Step: 5
Training loss: 0.644133985042572
Validation loss: 2.143512507279714

Epoch: 6| Step: 6
Training loss: 1.0739778280258179
Validation loss: 2.1501508553822837

Epoch: 6| Step: 7
Training loss: 1.1233851909637451
Validation loss: 2.197947144508362

Epoch: 6| Step: 8
Training loss: 1.053367018699646
Validation loss: 2.1645001570383706

Epoch: 6| Step: 9
Training loss: 1.1173930168151855
Validation loss: 2.199716846148173

Epoch: 6| Step: 10
Training loss: 1.101420521736145
Validation loss: 2.136647045612335

Epoch: 6| Step: 11
Training loss: 0.815488338470459
Validation loss: 2.1941427191098533

Epoch: 6| Step: 12
Training loss: 1.0985440015792847
Validation loss: 2.19880739847819

Epoch: 6| Step: 13
Training loss: 0.7870664596557617
Validation loss: 2.143632690111796

Epoch: 396| Step: 0
Training loss: 1.1149914264678955
Validation loss: 2.206086019674937

Epoch: 6| Step: 1
Training loss: 1.6378849744796753
Validation loss: 2.1731616655985513

Epoch: 6| Step: 2
Training loss: 0.9913511872291565
Validation loss: 2.1895733078320823

Epoch: 6| Step: 3
Training loss: 0.5321898460388184
Validation loss: 2.199219822883606

Epoch: 6| Step: 4
Training loss: 0.8253374695777893
Validation loss: 2.186018645763397

Epoch: 6| Step: 5
Training loss: 0.48952049016952515
Validation loss: 2.208021958669027

Epoch: 6| Step: 6
Training loss: 0.5082617402076721
Validation loss: 2.1898176074028015

Epoch: 6| Step: 7
Training loss: 1.0171003341674805
Validation loss: 2.154347578684489

Epoch: 6| Step: 8
Training loss: 0.7800867557525635
Validation loss: 2.1314390699068704

Epoch: 6| Step: 9
Training loss: 0.8765338063240051
Validation loss: 2.1362071434656777

Epoch: 6| Step: 10
Training loss: 0.2670876383781433
Validation loss: 2.199749251206716

Epoch: 6| Step: 11
Training loss: 1.1449666023254395
Validation loss: 2.195451041062673

Epoch: 6| Step: 12
Training loss: 0.6894371509552002
Validation loss: 2.1212576627731323

Epoch: 6| Step: 13
Training loss: 0.9467387199401855
Validation loss: 2.1593689918518066

Epoch: 397| Step: 0
Training loss: 0.355914831161499
Validation loss: 2.134249766667684

Epoch: 6| Step: 1
Training loss: 0.7452357411384583
Validation loss: 2.1184629003206887

Epoch: 6| Step: 2
Training loss: 0.8328238129615784
Validation loss: 2.127520183722178

Epoch: 6| Step: 3
Training loss: 1.5468370914459229
Validation loss: 2.136167128880819

Epoch: 6| Step: 4
Training loss: 1.529679775238037
Validation loss: 2.1247276862462363

Epoch: 6| Step: 5
Training loss: 0.7415560483932495
Validation loss: 2.13624515136083

Epoch: 6| Step: 6
Training loss: 1.0455424785614014
Validation loss: 2.1075331568717957

Epoch: 6| Step: 7
Training loss: 1.3301210403442383
Validation loss: 2.1158037185668945

Epoch: 6| Step: 8
Training loss: 0.9451878070831299
Validation loss: 2.1632699767748513

Epoch: 6| Step: 9
Training loss: 0.7691006660461426
Validation loss: 2.1227837999661765

Epoch: 6| Step: 10
Training loss: 1.1625604629516602
Validation loss: 2.147589067618052

Epoch: 6| Step: 11
Training loss: 1.2588841915130615
Validation loss: 2.1344526012738547

Epoch: 6| Step: 12
Training loss: 0.46535980701446533
Validation loss: 2.119741896788279

Epoch: 6| Step: 13
Training loss: 0.3489353358745575
Validation loss: 2.1608133912086487

Epoch: 398| Step: 0
Training loss: 1.045623779296875
Validation loss: 2.151878754297892

Epoch: 6| Step: 1
Training loss: 0.9034237265586853
Validation loss: 2.151885370413462

Epoch: 6| Step: 2
Training loss: 0.8611670732498169
Validation loss: 2.1313560406366983

Epoch: 6| Step: 3
Training loss: 0.4893888831138611
Validation loss: 2.1242475112279258

Epoch: 6| Step: 4
Training loss: 0.5596215724945068
Validation loss: 2.0707123080889382

Epoch: 6| Step: 5
Training loss: 0.7197107076644897
Validation loss: 2.1625941594441733

Epoch: 6| Step: 6
Training loss: 0.7657254934310913
Validation loss: 2.184738576412201

Epoch: 6| Step: 7
Training loss: 0.980460524559021
Validation loss: 2.168752213319143

Epoch: 6| Step: 8
Training loss: 0.8275374174118042
Validation loss: 2.174026906490326

Epoch: 6| Step: 9
Training loss: 1.0564687252044678
Validation loss: 2.1934999227523804

Epoch: 6| Step: 10
Training loss: 1.3430966138839722
Validation loss: 2.213428576787313

Epoch: 6| Step: 11
Training loss: 0.5942598581314087
Validation loss: 2.1617743968963623

Epoch: 6| Step: 12
Training loss: 0.8993998169898987
Validation loss: 2.1999370455741882

Epoch: 6| Step: 13
Training loss: 0.8836373686790466
Validation loss: 2.22350945075353

Epoch: 399| Step: 0
Training loss: 0.7459901571273804
Validation loss: 2.2090235153834024

Epoch: 6| Step: 1
Training loss: 0.827122151851654
Validation loss: 2.173434058825175

Epoch: 6| Step: 2
Training loss: 1.2289435863494873
Validation loss: 2.178345779577891

Epoch: 6| Step: 3
Training loss: 0.6337130665779114
Validation loss: 2.135425349076589

Epoch: 6| Step: 4
Training loss: 1.2374118566513062
Validation loss: 2.1967361768086753

Epoch: 6| Step: 5
Training loss: 0.676958441734314
Validation loss: 2.16528848807017

Epoch: 6| Step: 6
Training loss: 0.830316960811615
Validation loss: 2.2130743662516275

Epoch: 6| Step: 7
Training loss: 0.8657554388046265
Validation loss: 2.2863999605178833

Epoch: 6| Step: 8
Training loss: 0.7404860258102417
Validation loss: 2.24408749739329

Epoch: 6| Step: 9
Training loss: 0.9952885508537292
Validation loss: 2.2358755270640054

Epoch: 6| Step: 10
Training loss: 0.8088170289993286
Validation loss: 2.2204659581184387

Epoch: 6| Step: 11
Training loss: 0.550407350063324
Validation loss: 2.2359184622764587

Epoch: 6| Step: 12
Training loss: 0.6727800369262695
Validation loss: 2.2506960233052573

Epoch: 6| Step: 13
Training loss: 1.3523800373077393
Validation loss: 2.230187733968099

Epoch: 400| Step: 0
Training loss: 0.4280503988265991
Validation loss: 2.1933456857999167

Epoch: 6| Step: 1
Training loss: 0.5974407196044922
Validation loss: 2.2431843280792236

Epoch: 6| Step: 2
Training loss: 0.8757023811340332
Validation loss: 2.21204936504364

Epoch: 6| Step: 3
Training loss: 0.7498940229415894
Validation loss: 2.1663192311922708

Epoch: 6| Step: 4
Training loss: 0.7490085363388062
Validation loss: 2.207056681315104

Epoch: 6| Step: 5
Training loss: 0.7350050806999207
Validation loss: 2.209281404813131

Epoch: 6| Step: 6
Training loss: 1.5695595741271973
Validation loss: 2.212756335735321

Epoch: 6| Step: 7
Training loss: 0.9803161025047302
Validation loss: 2.1871361335118613

Epoch: 6| Step: 8
Training loss: 0.6289997696876526
Validation loss: 2.19585253794988

Epoch: 6| Step: 9
Training loss: 1.2214246988296509
Validation loss: 2.1756593187650046

Epoch: 6| Step: 10
Training loss: 0.8859907388687134
Validation loss: 2.2301612893740335

Epoch: 6| Step: 11
Training loss: 0.8483239412307739
Validation loss: 2.1747540831565857

Epoch: 6| Step: 12
Training loss: 0.7818225622177124
Validation loss: 2.146849195162455

Epoch: 6| Step: 13
Training loss: 0.5102909803390503
Validation loss: 2.184414545694987

Epoch: 401| Step: 0
Training loss: 0.44964832067489624
Validation loss: 2.2006194392840066

Epoch: 6| Step: 1
Training loss: 0.6721822023391724
Validation loss: 2.139475146929423

Epoch: 6| Step: 2
Training loss: 0.8650087714195251
Validation loss: 2.170234262943268

Epoch: 6| Step: 3
Training loss: 1.1307560205459595
Validation loss: 2.190579275290171

Epoch: 6| Step: 4
Training loss: 1.48771333694458
Validation loss: 2.166904171307882

Epoch: 6| Step: 5
Training loss: 0.684711217880249
Validation loss: 2.164644996325175

Epoch: 6| Step: 6
Training loss: 1.0837986469268799
Validation loss: 2.162532687187195

Epoch: 6| Step: 7
Training loss: 0.3567747175693512
Validation loss: 2.2051435510317483

Epoch: 6| Step: 8
Training loss: 0.6658014059066772
Validation loss: 2.1584689815839133

Epoch: 6| Step: 9
Training loss: 0.509631872177124
Validation loss: 2.171343227227529

Epoch: 6| Step: 10
Training loss: 0.7472193241119385
Validation loss: 2.1912688414255777

Epoch: 6| Step: 11
Training loss: 1.3354871273040771
Validation loss: 2.1916382114092507

Epoch: 6| Step: 12
Training loss: 1.2360365390777588
Validation loss: 2.190611561139425

Epoch: 6| Step: 13
Training loss: 0.8649320006370544
Validation loss: 2.1754966378211975

Epoch: 402| Step: 0
Training loss: 1.3207502365112305
Validation loss: 2.208130935827891

Epoch: 6| Step: 1
Training loss: 1.4100701808929443
Validation loss: 2.223772406578064

Epoch: 6| Step: 2
Training loss: 0.9637651443481445
Validation loss: 2.209535519282023

Epoch: 6| Step: 3
Training loss: 0.8864283561706543
Validation loss: 2.1879907051722207

Epoch: 6| Step: 4
Training loss: 0.7556556463241577
Validation loss: 2.2129783431688943

Epoch: 6| Step: 5
Training loss: 0.6591415405273438
Validation loss: 2.157013495763143

Epoch: 6| Step: 6
Training loss: 0.4112173020839691
Validation loss: 2.105232318242391

Epoch: 6| Step: 7
Training loss: 0.5030836462974548
Validation loss: 2.1611640254656472

Epoch: 6| Step: 8
Training loss: 1.40241539478302
Validation loss: 2.1728259126345315

Epoch: 6| Step: 9
Training loss: 0.3708629608154297
Validation loss: 2.2018006443977356

Epoch: 6| Step: 10
Training loss: 0.7622867822647095
Validation loss: 2.1922502915064492

Epoch: 6| Step: 11
Training loss: 0.7385063171386719
Validation loss: 2.1602052052815757

Epoch: 6| Step: 12
Training loss: 0.7767747640609741
Validation loss: 2.197373350461324

Epoch: 6| Step: 13
Training loss: 0.7839112281799316
Validation loss: 2.1598363320032754

Epoch: 403| Step: 0
Training loss: 0.47159314155578613
Validation loss: 2.170734961827596

Epoch: 6| Step: 1
Training loss: 0.8248233199119568
Validation loss: 2.1685189604759216

Epoch: 6| Step: 2
Training loss: 0.5717310905456543
Validation loss: 2.1981494029363

Epoch: 6| Step: 3
Training loss: 0.96330726146698
Validation loss: 2.1703272263209024

Epoch: 6| Step: 4
Training loss: 0.8938107490539551
Validation loss: 2.195466697216034

Epoch: 6| Step: 5
Training loss: 0.7585252523422241
Validation loss: 2.193094849586487

Epoch: 6| Step: 6
Training loss: 0.8321975469589233
Validation loss: 2.2569592197736106

Epoch: 6| Step: 7
Training loss: 1.4206396341323853
Validation loss: 2.2513278126716614

Epoch: 6| Step: 8
Training loss: 0.9416517019271851
Validation loss: 2.2458932598431907

Epoch: 6| Step: 9
Training loss: 1.233614206314087
Validation loss: 2.193539321422577

Epoch: 6| Step: 10
Training loss: 1.0539737939834595
Validation loss: 2.1713690757751465

Epoch: 6| Step: 11
Training loss: 0.773794412612915
Validation loss: 2.1285236477851868

Epoch: 6| Step: 12
Training loss: 0.5219984650611877
Validation loss: 2.137784699598948

Epoch: 6| Step: 13
Training loss: 0.9455102682113647
Validation loss: 2.1921111941337585

Epoch: 404| Step: 0
Training loss: 0.5662305951118469
Validation loss: 2.14384659131368

Epoch: 6| Step: 1
Training loss: 0.5168815851211548
Validation loss: 2.192075788974762

Epoch: 6| Step: 2
Training loss: 0.932360053062439
Validation loss: 2.16664065917333

Epoch: 6| Step: 3
Training loss: 1.1040416955947876
Validation loss: 2.1851415832837424

Epoch: 6| Step: 4
Training loss: 0.7970889806747437
Validation loss: 2.218919257322947

Epoch: 6| Step: 5
Training loss: 1.054770827293396
Validation loss: 2.2123119036356607

Epoch: 6| Step: 6
Training loss: 0.854408860206604
Validation loss: 2.2056260108947754

Epoch: 6| Step: 7
Training loss: 1.7047088146209717
Validation loss: 2.199676811695099

Epoch: 6| Step: 8
Training loss: 0.5413636565208435
Validation loss: 2.201489488283793

Epoch: 6| Step: 9
Training loss: 0.8588573336601257
Validation loss: 2.217043141523997

Epoch: 6| Step: 10
Training loss: 0.6877537369728088
Validation loss: 2.188567797342936

Epoch: 6| Step: 11
Training loss: 0.9106811285018921
Validation loss: 2.187971591949463

Epoch: 6| Step: 12
Training loss: 0.37720388174057007
Validation loss: 2.182663599650065

Epoch: 6| Step: 13
Training loss: 1.0491548776626587
Validation loss: 2.2246272961298623

Epoch: 405| Step: 0
Training loss: 0.4460574984550476
Validation loss: 2.1763981779416404

Epoch: 6| Step: 1
Training loss: 0.8281340003013611
Validation loss: 2.189349273840586

Epoch: 6| Step: 2
Training loss: 0.4650397300720215
Validation loss: 2.216500222682953

Epoch: 6| Step: 3
Training loss: 0.7797204256057739
Validation loss: 2.2086297273635864

Epoch: 6| Step: 4
Training loss: 0.777626633644104
Validation loss: 2.1841244300206504

Epoch: 6| Step: 5
Training loss: 0.2611216604709625
Validation loss: 2.1577620108922324

Epoch: 6| Step: 6
Training loss: 0.9605938196182251
Validation loss: 2.1766329805056253

Epoch: 6| Step: 7
Training loss: 0.7047742009162903
Validation loss: 2.1477849880854287

Epoch: 6| Step: 8
Training loss: 1.1960290670394897
Validation loss: 2.1820001006126404

Epoch: 6| Step: 9
Training loss: 1.2604749202728271
Validation loss: 2.1320935686429343

Epoch: 6| Step: 10
Training loss: 0.6507566571235657
Validation loss: 2.1446926395098367

Epoch: 6| Step: 11
Training loss: 1.1663591861724854
Validation loss: 2.1760200659434

Epoch: 6| Step: 12
Training loss: 0.8287532925605774
Validation loss: 2.165762503941854

Epoch: 6| Step: 13
Training loss: 0.5832555890083313
Validation loss: 2.200783848762512

Epoch: 406| Step: 0
Training loss: 0.8625500202178955
Validation loss: 2.1710628469785056

Epoch: 6| Step: 1
Training loss: 1.7439663410186768
Validation loss: 2.0936866998672485

Epoch: 6| Step: 2
Training loss: 0.607002854347229
Validation loss: 2.176775793234507

Epoch: 6| Step: 3
Training loss: 0.809745192527771
Validation loss: 2.1495261987050376

Epoch: 6| Step: 4
Training loss: 0.5424504280090332
Validation loss: 2.1873944203058877

Epoch: 6| Step: 5
Training loss: 1.1415555477142334
Validation loss: 2.1762508551279702

Epoch: 6| Step: 6
Training loss: 0.9428983926773071
Validation loss: 2.158294995625814

Epoch: 6| Step: 7
Training loss: 0.5631381273269653
Validation loss: 2.202955146630605

Epoch: 6| Step: 8
Training loss: 0.7781370878219604
Validation loss: 2.1913832426071167

Epoch: 6| Step: 9
Training loss: 0.6046829223632812
Validation loss: 2.210068702697754

Epoch: 6| Step: 10
Training loss: 0.48145872354507446
Validation loss: 2.1955103874206543

Epoch: 6| Step: 11
Training loss: 0.5537274479866028
Validation loss: 2.1943167050679526

Epoch: 6| Step: 12
Training loss: 0.7591522336006165
Validation loss: 2.2170784076054892

Epoch: 6| Step: 13
Training loss: 0.8438307642936707
Validation loss: 2.2181496024131775

Epoch: 407| Step: 0
Training loss: 1.6609301567077637
Validation loss: 2.1957602302233377

Epoch: 6| Step: 1
Training loss: 0.697429358959198
Validation loss: 2.181198000907898

Epoch: 6| Step: 2
Training loss: 0.6029020547866821
Validation loss: 2.2012555797894797

Epoch: 6| Step: 3
Training loss: 0.6303515434265137
Validation loss: 2.1681713263193765

Epoch: 6| Step: 4
Training loss: 0.3396807909011841
Validation loss: 2.1776922742525735

Epoch: 6| Step: 5
Training loss: 0.80372154712677
Validation loss: 2.2230001091957092

Epoch: 6| Step: 6
Training loss: 0.6547205448150635
Validation loss: 2.1516258319218955

Epoch: 6| Step: 7
Training loss: 0.7325106263160706
Validation loss: 2.190608243147532

Epoch: 6| Step: 8
Training loss: 0.5509438514709473
Validation loss: 2.170905609925588

Epoch: 6| Step: 9
Training loss: 0.7256779670715332
Validation loss: 2.1756707429885864

Epoch: 6| Step: 10
Training loss: 0.6540172100067139
Validation loss: 2.120756506919861

Epoch: 6| Step: 11
Training loss: 0.9971184134483337
Validation loss: 2.1353110472361245

Epoch: 6| Step: 12
Training loss: 0.4821718633174896
Validation loss: 2.1387487848599753

Epoch: 6| Step: 13
Training loss: 1.2930315732955933
Validation loss: 2.1864017248153687

Epoch: 408| Step: 0
Training loss: 1.2638399600982666
Validation loss: 2.1610242128372192

Epoch: 6| Step: 1
Training loss: 0.8910151720046997
Validation loss: 2.168947239716848

Epoch: 6| Step: 2
Training loss: 0.6369748115539551
Validation loss: 2.174441337585449

Epoch: 6| Step: 3
Training loss: 1.1732933521270752
Validation loss: 2.154493769009908

Epoch: 6| Step: 4
Training loss: 0.6378622055053711
Validation loss: 2.151604652404785

Epoch: 6| Step: 5
Training loss: 0.8656750321388245
Validation loss: 2.1746217012405396

Epoch: 6| Step: 6
Training loss: 0.33722901344299316
Validation loss: 2.129431128501892

Epoch: 6| Step: 7
Training loss: 0.32107165455818176
Validation loss: 2.1918439070383706

Epoch: 6| Step: 8
Training loss: 0.5499286651611328
Validation loss: 2.1918561458587646

Epoch: 6| Step: 9
Training loss: 0.301729679107666
Validation loss: 2.1752312382062278

Epoch: 6| Step: 10
Training loss: 1.3852646350860596
Validation loss: 2.158182144165039

Epoch: 6| Step: 11
Training loss: 0.6336092948913574
Validation loss: 2.2220900654792786

Epoch: 6| Step: 12
Training loss: 1.0498137474060059
Validation loss: 2.1929503679275513

Epoch: 6| Step: 13
Training loss: 1.237962007522583
Validation loss: 2.215199649333954

Epoch: 409| Step: 0
Training loss: 1.3884596824645996
Validation loss: 2.2578240633010864

Epoch: 6| Step: 1
Training loss: 0.6123210191726685
Validation loss: 2.210075338681539

Epoch: 6| Step: 2
Training loss: 0.863407552242279
Validation loss: 2.1926242113113403

Epoch: 6| Step: 3
Training loss: 0.5199697017669678
Validation loss: 2.175421893596649

Epoch: 6| Step: 4
Training loss: 0.8478485345840454
Validation loss: 2.147391895453135

Epoch: 6| Step: 5
Training loss: 0.7354241013526917
Validation loss: 2.151356875896454

Epoch: 6| Step: 6
Training loss: 0.692249596118927
Validation loss: 2.1633621056874595

Epoch: 6| Step: 7
Training loss: 1.4435425996780396
Validation loss: 2.141288101673126

Epoch: 6| Step: 8
Training loss: 0.7961548566818237
Validation loss: 2.189449667930603

Epoch: 6| Step: 9
Training loss: 0.5003708004951477
Validation loss: 2.1917881965637207

Epoch: 6| Step: 10
Training loss: 1.2108790874481201
Validation loss: 2.1596688628196716

Epoch: 6| Step: 11
Training loss: 0.9465924501419067
Validation loss: 2.191698133945465

Epoch: 6| Step: 12
Training loss: 0.6658756732940674
Validation loss: 2.1989017923672995

Epoch: 6| Step: 13
Training loss: 0.6910017728805542
Validation loss: 2.184574762980143

Epoch: 410| Step: 0
Training loss: 0.9331010580062866
Validation loss: 2.2379592657089233

Epoch: 6| Step: 1
Training loss: 0.8465389609336853
Validation loss: 2.1991150180498757

Epoch: 6| Step: 2
Training loss: 0.47326886653900146
Validation loss: 2.193543712298075

Epoch: 6| Step: 3
Training loss: 0.556137204170227
Validation loss: 2.2459656596183777

Epoch: 6| Step: 4
Training loss: 0.6737957000732422
Validation loss: 2.2187920411427817

Epoch: 6| Step: 5
Training loss: 0.7864551544189453
Validation loss: 2.187319199244181

Epoch: 6| Step: 6
Training loss: 0.911382794380188
Validation loss: 2.2065735260645547

Epoch: 6| Step: 7
Training loss: 1.230179786682129
Validation loss: 2.2001802921295166

Epoch: 6| Step: 8
Training loss: 0.39492183923721313
Validation loss: 2.171162188053131

Epoch: 6| Step: 9
Training loss: 0.944577693939209
Validation loss: 2.1791672110557556

Epoch: 6| Step: 10
Training loss: 0.9354272484779358
Validation loss: 2.1645914713541665

Epoch: 6| Step: 11
Training loss: 1.176513671875
Validation loss: 2.2215738693873086

Epoch: 6| Step: 12
Training loss: 0.8049817085266113
Validation loss: 2.199494779109955

Epoch: 6| Step: 13
Training loss: 0.9012967348098755
Validation loss: 2.191262940565745

Epoch: 411| Step: 0
Training loss: 0.9374154806137085
Validation loss: 2.155364712079366

Epoch: 6| Step: 1
Training loss: 0.9231474995613098
Validation loss: 2.1849223375320435

Epoch: 6| Step: 2
Training loss: 0.6053194999694824
Validation loss: 2.2372132539749146

Epoch: 6| Step: 3
Training loss: 1.4702200889587402
Validation loss: 2.206903318564097

Epoch: 6| Step: 4
Training loss: 0.8908550143241882
Validation loss: 2.1700169841448465

Epoch: 6| Step: 5
Training loss: 0.5132095813751221
Validation loss: 2.1525139609972634

Epoch: 6| Step: 6
Training loss: 0.5510903000831604
Validation loss: 2.140410919984182

Epoch: 6| Step: 7
Training loss: 0.7185471653938293
Validation loss: 2.1602141658465066

Epoch: 6| Step: 8
Training loss: 1.2579636573791504
Validation loss: 2.1340266466140747

Epoch: 6| Step: 9
Training loss: 1.281827688217163
Validation loss: 2.142423391342163

Epoch: 6| Step: 10
Training loss: 1.1087563037872314
Validation loss: 2.148553748925527

Epoch: 6| Step: 11
Training loss: 0.9180352687835693
Validation loss: 2.145418961842855

Epoch: 6| Step: 12
Training loss: 0.45037832856178284
Validation loss: 2.2239949703216553

Epoch: 6| Step: 13
Training loss: 0.39924198389053345
Validation loss: 2.1967052022616067

Epoch: 412| Step: 0
Training loss: 1.043465256690979
Validation loss: 2.192376176516215

Epoch: 6| Step: 1
Training loss: 1.0241460800170898
Validation loss: 2.206877370675405

Epoch: 6| Step: 2
Training loss: 1.1469755172729492
Validation loss: 2.203111469745636

Epoch: 6| Step: 3
Training loss: 0.8803889155387878
Validation loss: 2.175843119621277

Epoch: 6| Step: 4
Training loss: 1.2265650033950806
Validation loss: 2.1024011969566345

Epoch: 6| Step: 5
Training loss: 0.6649426817893982
Validation loss: 2.1822174390157065

Epoch: 6| Step: 6
Training loss: 0.6679536700248718
Validation loss: 2.160522242387136

Epoch: 6| Step: 7
Training loss: 0.6799224615097046
Validation loss: 2.181414802869161

Epoch: 6| Step: 8
Training loss: 0.3626147210597992
Validation loss: 2.157851199309031

Epoch: 6| Step: 9
Training loss: 0.7650923728942871
Validation loss: 2.1283774773279824

Epoch: 6| Step: 10
Training loss: 0.9354228973388672
Validation loss: 2.164954046408335

Epoch: 6| Step: 11
Training loss: 0.9273622035980225
Validation loss: 2.1125327944755554

Epoch: 6| Step: 12
Training loss: 0.5067394971847534
Validation loss: 2.164092262585958

Epoch: 6| Step: 13
Training loss: 0.6663474440574646
Validation loss: 2.1734010577201843

Epoch: 413| Step: 0
Training loss: 0.3027779161930084
Validation loss: 2.19461057583491

Epoch: 6| Step: 1
Training loss: 0.9729153513908386
Validation loss: 2.2012844681739807

Epoch: 6| Step: 2
Training loss: 0.6684936285018921
Validation loss: 2.2184582153956094

Epoch: 6| Step: 3
Training loss: 0.6490352749824524
Validation loss: 2.1988925536473594

Epoch: 6| Step: 4
Training loss: 0.6800278425216675
Validation loss: 2.158027390638987

Epoch: 6| Step: 5
Training loss: 0.8937622308731079
Validation loss: 2.176314194997152

Epoch: 6| Step: 6
Training loss: 0.8658175468444824
Validation loss: 2.1882450183232627

Epoch: 6| Step: 7
Training loss: 1.6481537818908691
Validation loss: 2.1879727840423584

Epoch: 6| Step: 8
Training loss: 1.1930952072143555
Validation loss: 2.12616765499115

Epoch: 6| Step: 9
Training loss: 0.7563928365707397
Validation loss: 2.1951499581336975

Epoch: 6| Step: 10
Training loss: 0.7338428497314453
Validation loss: 2.1492167512575784

Epoch: 6| Step: 11
Training loss: 1.279348611831665
Validation loss: 2.2528379758199057

Epoch: 6| Step: 12
Training loss: 1.203733205795288
Validation loss: 2.2888880173365274

Epoch: 6| Step: 13
Training loss: 1.203250765800476
Validation loss: 2.239809036254883

Epoch: 414| Step: 0
Training loss: 1.0298292636871338
Validation loss: 2.3079506953557334

Epoch: 6| Step: 1
Training loss: 1.5464493036270142
Validation loss: 2.3205163280169168

Epoch: 6| Step: 2
Training loss: 0.5196890830993652
Validation loss: 2.2546380360921225

Epoch: 6| Step: 3
Training loss: 1.2059085369110107
Validation loss: 2.250994702180227

Epoch: 6| Step: 4
Training loss: 1.0470833778381348
Validation loss: 2.202708105246226

Epoch: 6| Step: 5
Training loss: 0.677979588508606
Validation loss: 2.1648974219957986

Epoch: 6| Step: 6
Training loss: 1.1911287307739258
Validation loss: 2.139776905377706

Epoch: 6| Step: 7
Training loss: 0.8288816213607788
Validation loss: 2.142688492933909

Epoch: 6| Step: 8
Training loss: 0.657271146774292
Validation loss: 2.1863645911216736

Epoch: 6| Step: 9
Training loss: 0.45095115900039673
Validation loss: 2.1918415625890098

Epoch: 6| Step: 10
Training loss: 0.9990723729133606
Validation loss: 2.168152670065562

Epoch: 6| Step: 11
Training loss: 0.3757416903972626
Validation loss: 2.2265549500783286

Epoch: 6| Step: 12
Training loss: 0.7392786145210266
Validation loss: 2.194281895955404

Epoch: 6| Step: 13
Training loss: 0.9417706727981567
Validation loss: 2.2286842266718545

Epoch: 415| Step: 0
Training loss: 0.6118985414505005
Validation loss: 2.2581724723180137

Epoch: 6| Step: 1
Training loss: 0.5760484933853149
Validation loss: 2.220923145612081

Epoch: 6| Step: 2
Training loss: 1.4119815826416016
Validation loss: 2.1831307411193848

Epoch: 6| Step: 3
Training loss: 2.0129570960998535
Validation loss: 2.213998258113861

Epoch: 6| Step: 4
Training loss: 0.768048882484436
Validation loss: 2.2323219180107117

Epoch: 6| Step: 5
Training loss: 0.81699538230896
Validation loss: 2.1686118841171265

Epoch: 6| Step: 6
Training loss: 0.7680180072784424
Validation loss: 2.1663887103398642

Epoch: 6| Step: 7
Training loss: 1.2925918102264404
Validation loss: 2.1788015961647034

Epoch: 6| Step: 8
Training loss: 0.5495508313179016
Validation loss: 2.133684813976288

Epoch: 6| Step: 9
Training loss: 0.9521940350532532
Validation loss: 2.1437659660975137

Epoch: 6| Step: 10
Training loss: 0.4882259666919708
Validation loss: 2.1092880368232727

Epoch: 6| Step: 11
Training loss: 0.5293567180633545
Validation loss: 2.14698592821757

Epoch: 6| Step: 12
Training loss: 0.5809441208839417
Validation loss: 2.198006272315979

Epoch: 6| Step: 13
Training loss: 0.6478308439254761
Validation loss: 2.2126011848449707

Epoch: 416| Step: 0
Training loss: 0.6744769811630249
Validation loss: 2.2058889468510947

Epoch: 6| Step: 1
Training loss: 0.9922376871109009
Validation loss: 2.2013272643089294

Epoch: 6| Step: 2
Training loss: 0.7784141302108765
Validation loss: 2.145046651363373

Epoch: 6| Step: 3
Training loss: 0.5557979941368103
Validation loss: 2.1716697017351785

Epoch: 6| Step: 4
Training loss: 0.9834750890731812
Validation loss: 2.166381816069285

Epoch: 6| Step: 5
Training loss: 0.5381673574447632
Validation loss: 2.2028319239616394

Epoch: 6| Step: 6
Training loss: 0.5573694109916687
Validation loss: 2.169257958730062

Epoch: 6| Step: 7
Training loss: 0.5478982925415039
Validation loss: 2.171471099058787

Epoch: 6| Step: 8
Training loss: 0.8700405359268188
Validation loss: 2.138353725274404

Epoch: 6| Step: 9
Training loss: 1.085738182067871
Validation loss: 2.1898099978764853

Epoch: 6| Step: 10
Training loss: 1.0619531869888306
Validation loss: 2.2186325589815774

Epoch: 6| Step: 11
Training loss: 1.4293787479400635
Validation loss: 2.1812985936800637

Epoch: 6| Step: 12
Training loss: 0.4983261823654175
Validation loss: 2.1607073545455933

Epoch: 6| Step: 13
Training loss: 0.8571271300315857
Validation loss: 2.238290230433146

Epoch: 417| Step: 0
Training loss: 0.45035943388938904
Validation loss: 2.2437721490859985

Epoch: 6| Step: 1
Training loss: 0.9876161813735962
Validation loss: 2.193821668624878

Epoch: 6| Step: 2
Training loss: 0.5858207941055298
Validation loss: 2.198681672414144

Epoch: 6| Step: 3
Training loss: 0.9988450407981873
Validation loss: 2.1857799092928567

Epoch: 6| Step: 4
Training loss: 0.6793396472930908
Validation loss: 2.1756224433581033

Epoch: 6| Step: 5
Training loss: 1.0894410610198975
Validation loss: 2.1601436138153076

Epoch: 6| Step: 6
Training loss: 0.7914769649505615
Validation loss: 2.204065680503845

Epoch: 6| Step: 7
Training loss: 0.8240842819213867
Validation loss: 2.1711841026941934

Epoch: 6| Step: 8
Training loss: 0.5720247626304626
Validation loss: 2.200737019379934

Epoch: 6| Step: 9
Training loss: 0.9514912366867065
Validation loss: 2.1967828075091043

Epoch: 6| Step: 10
Training loss: 0.6368588209152222
Validation loss: 2.166909476121267

Epoch: 6| Step: 11
Training loss: 0.30958229303359985
Validation loss: 2.19688214858373

Epoch: 6| Step: 12
Training loss: 1.054271936416626
Validation loss: 2.197140415509542

Epoch: 6| Step: 13
Training loss: 0.9734389781951904
Validation loss: 2.158311605453491

Epoch: 418| Step: 0
Training loss: 0.5336558818817139
Validation loss: 2.1432180802027383

Epoch: 6| Step: 1
Training loss: 0.8177273273468018
Validation loss: 2.1984943946202598

Epoch: 6| Step: 2
Training loss: 1.0038034915924072
Validation loss: 2.184420426686605

Epoch: 6| Step: 3
Training loss: 0.6845595836639404
Validation loss: 2.183898170789083

Epoch: 6| Step: 4
Training loss: 0.5238751769065857
Validation loss: 2.205069382985433

Epoch: 6| Step: 5
Training loss: 0.47965776920318604
Validation loss: 2.156168977419535

Epoch: 6| Step: 6
Training loss: 1.156606912612915
Validation loss: 2.208374579747518

Epoch: 6| Step: 7
Training loss: 0.5081448554992676
Validation loss: 2.1865084171295166

Epoch: 6| Step: 8
Training loss: 1.1149070262908936
Validation loss: 2.2493308385213218

Epoch: 6| Step: 9
Training loss: 1.4158952236175537
Validation loss: 2.210340698560079

Epoch: 6| Step: 10
Training loss: 1.0885262489318848
Validation loss: 2.1861779491106668

Epoch: 6| Step: 11
Training loss: 0.8941712975502014
Validation loss: 2.160362641016642

Epoch: 6| Step: 12
Training loss: 0.484936386346817
Validation loss: 2.124702791372935

Epoch: 6| Step: 13
Training loss: 1.0111875534057617
Validation loss: 2.136274834473928

Epoch: 419| Step: 0
Training loss: 0.5464208126068115
Validation loss: 2.110220750172933

Epoch: 6| Step: 1
Training loss: 0.9783635139465332
Validation loss: 2.1604272921880088

Epoch: 6| Step: 2
Training loss: 1.4682377576828003
Validation loss: 2.1993970473607383

Epoch: 6| Step: 3
Training loss: 0.5356098413467407
Validation loss: 2.1739580233891806

Epoch: 6| Step: 4
Training loss: 0.7690901160240173
Validation loss: 2.1954299012819924

Epoch: 6| Step: 5
Training loss: 0.3681272566318512
Validation loss: 2.1512441635131836

Epoch: 6| Step: 6
Training loss: 0.9998376369476318
Validation loss: 2.147457222143809

Epoch: 6| Step: 7
Training loss: 0.41934600472450256
Validation loss: 2.176846444606781

Epoch: 6| Step: 8
Training loss: 0.7632108330726624
Validation loss: 2.1699455976486206

Epoch: 6| Step: 9
Training loss: 0.9858555793762207
Validation loss: 2.1359883348147073

Epoch: 6| Step: 10
Training loss: 0.6499329805374146
Validation loss: 2.1555718580881753

Epoch: 6| Step: 11
Training loss: 0.6450321674346924
Validation loss: 2.1642282605171204

Epoch: 6| Step: 12
Training loss: 0.7915794849395752
Validation loss: 2.175790548324585

Epoch: 6| Step: 13
Training loss: 1.1982285976409912
Validation loss: 2.2006247440973916

Epoch: 420| Step: 0
Training loss: 0.7957797646522522
Validation loss: 2.163699825604757

Epoch: 6| Step: 1
Training loss: 0.4902254045009613
Validation loss: 2.1035393277804055

Epoch: 6| Step: 2
Training loss: 0.642304539680481
Validation loss: 2.1857358614603677

Epoch: 6| Step: 3
Training loss: 0.2757757902145386
Validation loss: 2.1336098313331604

Epoch: 6| Step: 4
Training loss: 0.7298734188079834
Validation loss: 2.2062424421310425

Epoch: 6| Step: 5
Training loss: 1.756646752357483
Validation loss: 2.136672635873159

Epoch: 6| Step: 6
Training loss: 0.9742202758789062
Validation loss: 2.1407275199890137

Epoch: 6| Step: 7
Training loss: 0.5993075966835022
Validation loss: 2.132052004337311

Epoch: 6| Step: 8
Training loss: 0.29108142852783203
Validation loss: 2.1379139026006064

Epoch: 6| Step: 9
Training loss: 0.8732895851135254
Validation loss: 2.18179980913798

Epoch: 6| Step: 10
Training loss: 0.8664106130599976
Validation loss: 2.187531332174937

Epoch: 6| Step: 11
Training loss: 0.9258391261100769
Validation loss: 2.220568140347799

Epoch: 6| Step: 12
Training loss: 0.5852349400520325
Validation loss: 2.1408839424451194

Epoch: 6| Step: 13
Training loss: 0.5313119888305664
Validation loss: 2.181338091691335

Epoch: 421| Step: 0
Training loss: 1.3093689680099487
Validation loss: 2.126099149386088

Epoch: 6| Step: 1
Training loss: 0.851341187953949
Validation loss: 2.149192730585734

Epoch: 6| Step: 2
Training loss: 0.6990081071853638
Validation loss: 2.1228176156679788

Epoch: 6| Step: 3
Training loss: 1.1581523418426514
Validation loss: 2.1388163765271506

Epoch: 6| Step: 4
Training loss: 0.7471246719360352
Validation loss: 2.137887159983317

Epoch: 6| Step: 5
Training loss: 0.6958956122398376
Validation loss: 2.124078392982483

Epoch: 6| Step: 6
Training loss: 0.5861258506774902
Validation loss: 2.157586852709452

Epoch: 6| Step: 7
Training loss: 0.8856288194656372
Validation loss: 2.1418354312578836

Epoch: 6| Step: 8
Training loss: 1.1003596782684326
Validation loss: 2.147221783796946

Epoch: 6| Step: 9
Training loss: 0.5528315305709839
Validation loss: 2.192003766695658

Epoch: 6| Step: 10
Training loss: 0.594681978225708
Validation loss: 2.181960940361023

Epoch: 6| Step: 11
Training loss: 0.5878439545631409
Validation loss: 2.2276400526364646

Epoch: 6| Step: 12
Training loss: 0.8888260722160339
Validation loss: 2.2030070622762046

Epoch: 6| Step: 13
Training loss: 0.48773136734962463
Validation loss: 2.1725345849990845

Epoch: 422| Step: 0
Training loss: 1.0931140184402466
Validation loss: 2.1978477835655212

Epoch: 6| Step: 1
Training loss: 0.7274582982063293
Validation loss: 2.1633228858311973

Epoch: 6| Step: 2
Training loss: 1.098738193511963
Validation loss: 2.1838649113972983

Epoch: 6| Step: 3
Training loss: 0.5780247449874878
Validation loss: 2.1688921054204306

Epoch: 6| Step: 4
Training loss: 0.9904865622520447
Validation loss: 2.195700208346049

Epoch: 6| Step: 5
Training loss: 0.774626612663269
Validation loss: 2.178734521071116

Epoch: 6| Step: 6
Training loss: 1.0394939184188843
Validation loss: 2.2035720348358154

Epoch: 6| Step: 7
Training loss: 0.7098154425621033
Validation loss: 2.172869384288788

Epoch: 6| Step: 8
Training loss: 0.5739946961402893
Validation loss: 2.14804341395696

Epoch: 6| Step: 9
Training loss: 0.9096369743347168
Validation loss: 2.1783915559450784

Epoch: 6| Step: 10
Training loss: 0.8677698969841003
Validation loss: 2.178176522254944

Epoch: 6| Step: 11
Training loss: 0.5405192375183105
Validation loss: 2.1281380454699197

Epoch: 6| Step: 12
Training loss: 0.5129425525665283
Validation loss: 2.21627144018809

Epoch: 6| Step: 13
Training loss: 0.5709350109100342
Validation loss: 2.1834664146105447

Epoch: 423| Step: 0
Training loss: 1.619013786315918
Validation loss: 2.1578617294629416

Epoch: 6| Step: 1
Training loss: 0.7553618550300598
Validation loss: 2.1833879748980203

Epoch: 6| Step: 2
Training loss: 0.9185675382614136
Validation loss: 2.1380156874656677

Epoch: 6| Step: 3
Training loss: 0.6020824909210205
Validation loss: 2.1206265886624656

Epoch: 6| Step: 4
Training loss: 1.350535273551941
Validation loss: 2.1513152917226157

Epoch: 6| Step: 5
Training loss: 0.6636599898338318
Validation loss: 2.1357816060384116

Epoch: 6| Step: 6
Training loss: 0.919991672039032
Validation loss: 2.1633766690889993

Epoch: 6| Step: 7
Training loss: 0.8198760747909546
Validation loss: 2.2261695067087808

Epoch: 6| Step: 8
Training loss: 1.0523741245269775
Validation loss: 2.291178027788798

Epoch: 6| Step: 9
Training loss: 0.6596587896347046
Validation loss: 2.2782538731892905

Epoch: 6| Step: 10
Training loss: 0.7355061769485474
Validation loss: 2.20172252257665

Epoch: 6| Step: 11
Training loss: 1.2465437650680542
Validation loss: 2.198043922583262

Epoch: 6| Step: 12
Training loss: 0.6474226713180542
Validation loss: 2.1873861948649087

Epoch: 6| Step: 13
Training loss: 0.745064914226532
Validation loss: 2.166620135307312

Epoch: 424| Step: 0
Training loss: 0.9952421188354492
Validation loss: 2.1576674977938333

Epoch: 6| Step: 1
Training loss: 0.8476463556289673
Validation loss: 2.159275154272715

Epoch: 6| Step: 2
Training loss: 0.37227731943130493
Validation loss: 2.1308883825937905

Epoch: 6| Step: 3
Training loss: 0.8603018522262573
Validation loss: 2.1908989747365317

Epoch: 6| Step: 4
Training loss: 1.117105484008789
Validation loss: 2.122299591700236

Epoch: 6| Step: 5
Training loss: 0.8562922477722168
Validation loss: 2.150180439154307

Epoch: 6| Step: 6
Training loss: 1.2750444412231445
Validation loss: 2.176161766052246

Epoch: 6| Step: 7
Training loss: 0.4314769506454468
Validation loss: 2.1733580032984414

Epoch: 6| Step: 8
Training loss: 1.3993585109710693
Validation loss: 2.180987517038981

Epoch: 6| Step: 9
Training loss: 1.1806325912475586
Validation loss: 2.2372109293937683

Epoch: 6| Step: 10
Training loss: 0.5264294147491455
Validation loss: 2.1679028471310935

Epoch: 6| Step: 11
Training loss: 0.6888970136642456
Validation loss: 2.0903969407081604

Epoch: 6| Step: 12
Training loss: 0.5343540906906128
Validation loss: 2.1353900829950967

Epoch: 6| Step: 13
Training loss: 1.0350918769836426
Validation loss: 2.0912503401438394

Epoch: 425| Step: 0
Training loss: 1.3634960651397705
Validation loss: 2.1209715207417807

Epoch: 6| Step: 1
Training loss: 0.8999329805374146
Validation loss: 2.1471661726633706

Epoch: 6| Step: 2
Training loss: 0.5735791921615601
Validation loss: 2.09753288825353

Epoch: 6| Step: 3
Training loss: 0.6317606568336487
Validation loss: 2.1523353457450867

Epoch: 6| Step: 4
Training loss: 0.6571773290634155
Validation loss: 2.1603965759277344

Epoch: 6| Step: 5
Training loss: 0.9238208532333374
Validation loss: 2.1577281753222146

Epoch: 6| Step: 6
Training loss: 0.46591728925704956
Validation loss: 2.1782623330752053

Epoch: 6| Step: 7
Training loss: 1.295943260192871
Validation loss: 2.1457508405049643

Epoch: 6| Step: 8
Training loss: 0.9904559254646301
Validation loss: 2.23734317223231

Epoch: 6| Step: 9
Training loss: 0.8104307651519775
Validation loss: 2.2069398363431296

Epoch: 6| Step: 10
Training loss: 0.8089391589164734
Validation loss: 2.1629327535629272

Epoch: 6| Step: 11
Training loss: 0.4212580919265747
Validation loss: 2.2278492053349814

Epoch: 6| Step: 12
Training loss: 0.5351541042327881
Validation loss: 2.2027128537495932

Epoch: 6| Step: 13
Training loss: 0.6240718364715576
Validation loss: 2.1961044669151306

Epoch: 426| Step: 0
Training loss: 0.5338586568832397
Validation loss: 2.198723236719767

Epoch: 6| Step: 1
Training loss: 0.7082751989364624
Validation loss: 2.218369960784912

Epoch: 6| Step: 2
Training loss: 0.9608895182609558
Validation loss: 2.19017763932546

Epoch: 6| Step: 3
Training loss: 0.6683577299118042
Validation loss: 2.161052723725637

Epoch: 6| Step: 4
Training loss: 0.7669188380241394
Validation loss: 2.1609593431154885

Epoch: 6| Step: 5
Training loss: 0.49552685022354126
Validation loss: 2.157612144947052

Epoch: 6| Step: 6
Training loss: 1.1360325813293457
Validation loss: 2.179450571537018

Epoch: 6| Step: 7
Training loss: 0.9112918376922607
Validation loss: 2.1481428742408752

Epoch: 6| Step: 8
Training loss: 0.3797782063484192
Validation loss: 2.1857871214548745

Epoch: 6| Step: 9
Training loss: 0.5939420461654663
Validation loss: 2.1751665274302163

Epoch: 6| Step: 10
Training loss: 0.5425963401794434
Validation loss: 2.1475834250450134

Epoch: 6| Step: 11
Training loss: 0.8196835517883301
Validation loss: 2.1773143212000527

Epoch: 6| Step: 12
Training loss: 0.9255275726318359
Validation loss: 2.218077560265859

Epoch: 6| Step: 13
Training loss: 1.403991460800171
Validation loss: 2.184957206249237

Epoch: 427| Step: 0
Training loss: 0.6572721600532532
Validation loss: 2.2029347022374473

Epoch: 6| Step: 1
Training loss: 0.3656873106956482
Validation loss: 2.167828540007273

Epoch: 6| Step: 2
Training loss: 0.929280161857605
Validation loss: 2.12489906946818

Epoch: 6| Step: 3
Training loss: 0.7701155543327332
Validation loss: 2.103579839070638

Epoch: 6| Step: 4
Training loss: 0.3930704593658447
Validation loss: 2.144526938597361

Epoch: 6| Step: 5
Training loss: 0.5858712792396545
Validation loss: 2.1373974482218423

Epoch: 6| Step: 6
Training loss: 0.9103724360466003
Validation loss: 2.165047903855642

Epoch: 6| Step: 7
Training loss: 0.4858514070510864
Validation loss: 2.152917802333832

Epoch: 6| Step: 8
Training loss: 1.3018200397491455
Validation loss: 2.1618486444155374

Epoch: 6| Step: 9
Training loss: 0.9290211200714111
Validation loss: 2.164074738820394

Epoch: 6| Step: 10
Training loss: 0.8640689849853516
Validation loss: 2.1740744511286416

Epoch: 6| Step: 11
Training loss: 1.034325122833252
Validation loss: 2.217447280883789

Epoch: 6| Step: 12
Training loss: 0.43911033868789673
Validation loss: 2.20690381526947

Epoch: 6| Step: 13
Training loss: 1.0790939331054688
Validation loss: 2.14478192726771

Epoch: 428| Step: 0
Training loss: 1.0518383979797363
Validation loss: 2.19502059618632

Epoch: 6| Step: 1
Training loss: 0.7549029588699341
Validation loss: 2.172233521938324

Epoch: 6| Step: 2
Training loss: 0.8821656107902527
Validation loss: 2.1444331407546997

Epoch: 6| Step: 3
Training loss: 0.8158308267593384
Validation loss: 2.1552332639694214

Epoch: 6| Step: 4
Training loss: 0.8305896520614624
Validation loss: 2.072034935156504

Epoch: 6| Step: 5
Training loss: 0.9304676055908203
Validation loss: 2.1016186475753784

Epoch: 6| Step: 6
Training loss: 1.063880205154419
Validation loss: 2.0723900198936462

Epoch: 6| Step: 7
Training loss: 0.8253755569458008
Validation loss: 2.0709452430407205

Epoch: 6| Step: 8
Training loss: 0.728763222694397
Validation loss: 2.0874565839767456

Epoch: 6| Step: 9
Training loss: 1.0536279678344727
Validation loss: 2.1056804855664573

Epoch: 6| Step: 10
Training loss: 0.5438263416290283
Validation loss: 2.095859408378601

Epoch: 6| Step: 11
Training loss: 0.8397097587585449
Validation loss: 2.0595272382100425

Epoch: 6| Step: 12
Training loss: 0.7536588907241821
Validation loss: 2.1087294618288674

Epoch: 6| Step: 13
Training loss: 0.5838983058929443
Validation loss: 2.1090501149495444

Epoch: 429| Step: 0
Training loss: 0.8258644342422485
Validation loss: 2.180378556251526

Epoch: 6| Step: 1
Training loss: 0.9062618017196655
Validation loss: 2.158694644769033

Epoch: 6| Step: 2
Training loss: 0.6115453839302063
Validation loss: 2.179506778717041

Epoch: 6| Step: 3
Training loss: 0.4968821108341217
Validation loss: 2.1854822635650635

Epoch: 6| Step: 4
Training loss: 1.4992907047271729
Validation loss: 2.2270596623420715

Epoch: 6| Step: 5
Training loss: 1.2229692935943604
Validation loss: 2.223422567049662

Epoch: 6| Step: 6
Training loss: 0.8205280303955078
Validation loss: 2.2519057591756186

Epoch: 6| Step: 7
Training loss: 0.6079609394073486
Validation loss: 2.237338920434316

Epoch: 6| Step: 8
Training loss: 1.1144890785217285
Validation loss: 2.215979437033335

Epoch: 6| Step: 9
Training loss: 0.7454150319099426
Validation loss: 2.1878258983294168

Epoch: 6| Step: 10
Training loss: 0.5558229684829712
Validation loss: 2.172065099080404

Epoch: 6| Step: 11
Training loss: 1.1208842992782593
Validation loss: 2.1730197866757712

Epoch: 6| Step: 12
Training loss: 0.5904395580291748
Validation loss: 2.179079830646515

Epoch: 6| Step: 13
Training loss: 0.37095195055007935
Validation loss: 2.182613968849182

Epoch: 430| Step: 0
Training loss: 0.39598923921585083
Validation loss: 2.1624093850453696

Epoch: 6| Step: 1
Training loss: 1.492187738418579
Validation loss: 2.2174102663993835

Epoch: 6| Step: 2
Training loss: 0.5487344264984131
Validation loss: 2.2156246304512024

Epoch: 6| Step: 3
Training loss: 0.8957093954086304
Validation loss: 2.180280407269796

Epoch: 6| Step: 4
Training loss: 0.5440102815628052
Validation loss: 2.161606709162394

Epoch: 6| Step: 5
Training loss: 0.7577465772628784
Validation loss: 2.132392923037211

Epoch: 6| Step: 6
Training loss: 1.0132815837860107
Validation loss: 2.1316871841748557

Epoch: 6| Step: 7
Training loss: 0.987274706363678
Validation loss: 2.131611943244934

Epoch: 6| Step: 8
Training loss: 0.47975531220436096
Validation loss: 2.1284843484560647

Epoch: 6| Step: 9
Training loss: 0.46675819158554077
Validation loss: 2.131556431452433

Epoch: 6| Step: 10
Training loss: 0.7083629369735718
Validation loss: 2.1013836661974588

Epoch: 6| Step: 11
Training loss: 0.9421408176422119
Validation loss: 2.147177735964457

Epoch: 6| Step: 12
Training loss: 0.5577918291091919
Validation loss: 2.0973836382230124

Epoch: 6| Step: 13
Training loss: 1.0078012943267822
Validation loss: 2.1392314632733664

Epoch: 431| Step: 0
Training loss: 0.851270854473114
Validation loss: 2.1080860694249473

Epoch: 6| Step: 1
Training loss: 1.643714427947998
Validation loss: 2.1056474248568215

Epoch: 6| Step: 2
Training loss: 0.3918721377849579
Validation loss: 2.0910837252934775

Epoch: 6| Step: 3
Training loss: 0.6094825267791748
Validation loss: 2.1215049425760903

Epoch: 6| Step: 4
Training loss: 0.5802667140960693
Validation loss: 2.1591169834136963

Epoch: 6| Step: 5
Training loss: 0.47211140394210815
Validation loss: 2.115326384703318

Epoch: 6| Step: 6
Training loss: 0.8061941862106323
Validation loss: 2.1445438067118325

Epoch: 6| Step: 7
Training loss: 0.6279874444007874
Validation loss: 2.1645272175470986

Epoch: 6| Step: 8
Training loss: 0.47688645124435425
Validation loss: 2.1329151590665183

Epoch: 6| Step: 9
Training loss: 0.5973878502845764
Validation loss: 2.111605405807495

Epoch: 6| Step: 10
Training loss: 1.2190356254577637
Validation loss: 2.156079371770223

Epoch: 6| Step: 11
Training loss: 0.49324101209640503
Validation loss: 2.148217022418976

Epoch: 6| Step: 12
Training loss: 0.6721038222312927
Validation loss: 2.1320447524388633

Epoch: 6| Step: 13
Training loss: 0.3989551067352295
Validation loss: 2.1709718902905784

Epoch: 432| Step: 0
Training loss: 0.36895161867141724
Validation loss: 2.192427376906077

Epoch: 6| Step: 1
Training loss: 0.28653961420059204
Validation loss: 2.1659629543622336

Epoch: 6| Step: 2
Training loss: 1.3050146102905273
Validation loss: 2.2048602302869162

Epoch: 6| Step: 3
Training loss: 0.5947092175483704
Validation loss: 2.1670499444007874

Epoch: 6| Step: 4
Training loss: 1.1142818927764893
Validation loss: 2.190636316935221

Epoch: 6| Step: 5
Training loss: 0.676841676235199
Validation loss: 2.1667726834615073

Epoch: 6| Step: 6
Training loss: 0.5463253259658813
Validation loss: 2.1760691006978354

Epoch: 6| Step: 7
Training loss: 0.39209383726119995
Validation loss: 2.1672938466072083

Epoch: 6| Step: 8
Training loss: 1.504267930984497
Validation loss: 2.154288431008657

Epoch: 6| Step: 9
Training loss: 0.523527979850769
Validation loss: 2.168066402276357

Epoch: 6| Step: 10
Training loss: 1.0344942808151245
Validation loss: 2.1432573994000754

Epoch: 6| Step: 11
Training loss: 0.4168776273727417
Validation loss: 2.142180105050405

Epoch: 6| Step: 12
Training loss: 0.7539843320846558
Validation loss: 2.1889100869496665

Epoch: 6| Step: 13
Training loss: 0.5877265334129333
Validation loss: 2.1246225436528525

Epoch: 433| Step: 0
Training loss: 0.6253412961959839
Validation loss: 2.148015876611074

Epoch: 6| Step: 1
Training loss: 0.8067735433578491
Validation loss: 2.0983185370763144

Epoch: 6| Step: 2
Training loss: 0.5776836276054382
Validation loss: 2.1627752979596457

Epoch: 6| Step: 3
Training loss: 0.6198719143867493
Validation loss: 2.0986387729644775

Epoch: 6| Step: 4
Training loss: 0.4805946946144104
Validation loss: 2.1627790530522666

Epoch: 6| Step: 5
Training loss: 0.796640932559967
Validation loss: 2.1512015064557395

Epoch: 6| Step: 6
Training loss: 0.39259111881256104
Validation loss: 2.1238438487052917

Epoch: 6| Step: 7
Training loss: 0.9218683838844299
Validation loss: 2.0508044362068176

Epoch: 6| Step: 8
Training loss: 0.7531209588050842
Validation loss: 2.123133897781372

Epoch: 6| Step: 9
Training loss: 0.5496186017990112
Validation loss: 2.1838140885035195

Epoch: 6| Step: 10
Training loss: 0.39549192786216736
Validation loss: 2.124103844165802

Epoch: 6| Step: 11
Training loss: 0.7590492367744446
Validation loss: 2.1472549041112265

Epoch: 6| Step: 12
Training loss: 1.3830575942993164
Validation loss: 2.1118175784746804

Epoch: 6| Step: 13
Training loss: 0.6791722178459167
Validation loss: 2.0952179431915283

Epoch: 434| Step: 0
Training loss: 1.4696433544158936
Validation loss: 2.142232120037079

Epoch: 6| Step: 1
Training loss: 0.3358307480812073
Validation loss: 2.0660995046297708

Epoch: 6| Step: 2
Training loss: 0.35777929425239563
Validation loss: 2.0857884089152017

Epoch: 6| Step: 3
Training loss: 1.2128467559814453
Validation loss: 2.117292046546936

Epoch: 6| Step: 4
Training loss: 0.3995945155620575
Validation loss: 2.1596609354019165

Epoch: 6| Step: 5
Training loss: 0.7959607839584351
Validation loss: 2.102918187777201

Epoch: 6| Step: 6
Training loss: 0.6161078214645386
Validation loss: 2.138898253440857

Epoch: 6| Step: 7
Training loss: 0.7651650309562683
Validation loss: 2.1751462618509927

Epoch: 6| Step: 8
Training loss: 0.888487696647644
Validation loss: 2.142636020978292

Epoch: 6| Step: 9
Training loss: 0.5636098980903625
Validation loss: 2.1192016005516052

Epoch: 6| Step: 10
Training loss: 0.37512558698654175
Validation loss: 2.1458181341489158

Epoch: 6| Step: 11
Training loss: 1.1148680448532104
Validation loss: 2.1423714558283486

Epoch: 6| Step: 12
Training loss: 0.49819695949554443
Validation loss: 2.1550021171569824

Epoch: 6| Step: 13
Training loss: 0.6106154918670654
Validation loss: 2.1395868261655173

Epoch: 435| Step: 0
Training loss: 1.262311339378357
Validation loss: 2.2117644548416138

Epoch: 6| Step: 1
Training loss: 0.7398686408996582
Validation loss: 2.218754450480143

Epoch: 6| Step: 2
Training loss: 0.5417728424072266
Validation loss: 2.208422760168711

Epoch: 6| Step: 3
Training loss: 0.6310430765151978
Validation loss: 2.2048407594362893

Epoch: 6| Step: 4
Training loss: 0.6406402587890625
Validation loss: 2.2035314242045083

Epoch: 6| Step: 5
Training loss: 0.6532076597213745
Validation loss: 2.1751933097839355

Epoch: 6| Step: 6
Training loss: 0.5729097723960876
Validation loss: 2.1563154657681785

Epoch: 6| Step: 7
Training loss: 0.7148429751396179
Validation loss: 2.2139015992482505

Epoch: 6| Step: 8
Training loss: 1.2212493419647217
Validation loss: 2.1994553605715432

Epoch: 6| Step: 9
Training loss: 0.7681560516357422
Validation loss: 2.1875511606534324

Epoch: 6| Step: 10
Training loss: 1.0563772916793823
Validation loss: 2.167054057121277

Epoch: 6| Step: 11
Training loss: 0.5086368322372437
Validation loss: 2.2475362022717795

Epoch: 6| Step: 12
Training loss: 0.8645633459091187
Validation loss: 2.1822810967763266

Epoch: 6| Step: 13
Training loss: 0.6141141653060913
Validation loss: 2.189471165339152

Epoch: 436| Step: 0
Training loss: 0.7298982739448547
Validation loss: 2.214948534965515

Epoch: 6| Step: 1
Training loss: 0.5640209913253784
Validation loss: 2.1988445520401

Epoch: 6| Step: 2
Training loss: 0.5679017305374146
Validation loss: 2.198878367741903

Epoch: 6| Step: 3
Training loss: 0.2848457098007202
Validation loss: 2.1865508755048118

Epoch: 6| Step: 4
Training loss: 0.8713032007217407
Validation loss: 2.1595471103986106

Epoch: 6| Step: 5
Training loss: 1.1253557205200195
Validation loss: 2.1795441309611

Epoch: 6| Step: 6
Training loss: 0.9265641570091248
Validation loss: 2.1882803440093994

Epoch: 6| Step: 7
Training loss: 0.448932409286499
Validation loss: 2.191661854585012

Epoch: 6| Step: 8
Training loss: 0.7237005829811096
Validation loss: 2.2087107499440513

Epoch: 6| Step: 9
Training loss: 0.9340394735336304
Validation loss: 2.1699453592300415

Epoch: 6| Step: 10
Training loss: 1.058572769165039
Validation loss: 2.160033921400706

Epoch: 6| Step: 11
Training loss: 1.0076813697814941
Validation loss: 2.1983917156855264

Epoch: 6| Step: 12
Training loss: 0.3637131452560425
Validation loss: 2.1630439360936484

Epoch: 6| Step: 13
Training loss: 0.8003572225570679
Validation loss: 2.163813849290212

Epoch: 437| Step: 0
Training loss: 0.9316191077232361
Validation loss: 2.175333857536316

Epoch: 6| Step: 1
Training loss: 0.7407187223434448
Validation loss: 2.188279847304026

Epoch: 6| Step: 2
Training loss: 0.8595907688140869
Validation loss: 2.163507064183553

Epoch: 6| Step: 3
Training loss: 0.6290143728256226
Validation loss: 2.153914749622345

Epoch: 6| Step: 4
Training loss: 0.6997811794281006
Validation loss: 2.209345817565918

Epoch: 6| Step: 5
Training loss: 0.532721757888794
Validation loss: 2.21877783536911

Epoch: 6| Step: 6
Training loss: 0.4409100413322449
Validation loss: 2.227907955646515

Epoch: 6| Step: 7
Training loss: 1.1892813444137573
Validation loss: 2.2297218243281045

Epoch: 6| Step: 8
Training loss: 0.43253377079963684
Validation loss: 2.1752328872680664

Epoch: 6| Step: 9
Training loss: 0.35558658838272095
Validation loss: 2.180436074733734

Epoch: 6| Step: 10
Training loss: 0.9526809453964233
Validation loss: 2.1661295692125955

Epoch: 6| Step: 11
Training loss: 1.0046355724334717
Validation loss: 2.1553736130396524

Epoch: 6| Step: 12
Training loss: 0.40643370151519775
Validation loss: 2.145312945048014

Epoch: 6| Step: 13
Training loss: 0.41086113452911377
Validation loss: 2.103017807006836

Epoch: 438| Step: 0
Training loss: 0.4294244050979614
Validation loss: 2.126419206460317

Epoch: 6| Step: 1
Training loss: 0.8738735318183899
Validation loss: 2.112245817979177

Epoch: 6| Step: 2
Training loss: 0.5344610214233398
Validation loss: 2.1338361899058023

Epoch: 6| Step: 3
Training loss: 0.7412087917327881
Validation loss: 2.1466781894365945

Epoch: 6| Step: 4
Training loss: 1.469214677810669
Validation loss: 2.1111032565434775

Epoch: 6| Step: 5
Training loss: 0.46509718894958496
Validation loss: 2.173059821128845

Epoch: 6| Step: 6
Training loss: 0.7004458904266357
Validation loss: 2.0922549962997437

Epoch: 6| Step: 7
Training loss: 0.6566922664642334
Validation loss: 2.1520532369613647

Epoch: 6| Step: 8
Training loss: 0.7855430841445923
Validation loss: 2.1260308424631753

Epoch: 6| Step: 9
Training loss: 0.5745875239372253
Validation loss: 2.1328336199124656

Epoch: 6| Step: 10
Training loss: 0.47369563579559326
Validation loss: 2.16189698378245

Epoch: 6| Step: 11
Training loss: 0.44621652364730835
Validation loss: 2.1468111475308738

Epoch: 6| Step: 12
Training loss: 0.6338076591491699
Validation loss: 2.1168030897776284

Epoch: 6| Step: 13
Training loss: 0.963265061378479
Validation loss: 2.1941081285476685

Epoch: 439| Step: 0
Training loss: 0.31782007217407227
Validation loss: 2.1545748313268027

Epoch: 6| Step: 1
Training loss: 0.265697181224823
Validation loss: 2.167120615641276

Epoch: 6| Step: 2
Training loss: 1.087445855140686
Validation loss: 2.1258158485094705

Epoch: 6| Step: 3
Training loss: 0.9118437170982361
Validation loss: 2.186209479967753

Epoch: 6| Step: 4
Training loss: 0.4989064335823059
Validation loss: 2.107002933820089

Epoch: 6| Step: 5
Training loss: 0.97114098072052
Validation loss: 2.1565048694610596

Epoch: 6| Step: 6
Training loss: 1.2474967241287231
Validation loss: 2.1173608700434365

Epoch: 6| Step: 7
Training loss: 0.3794054388999939
Validation loss: 2.1638289292653403

Epoch: 6| Step: 8
Training loss: 0.5504722595214844
Validation loss: 2.155116637547811

Epoch: 6| Step: 9
Training loss: 0.5762801766395569
Validation loss: 2.1308006842931113

Epoch: 6| Step: 10
Training loss: 1.0798380374908447
Validation loss: 2.1494616270065308

Epoch: 6| Step: 11
Training loss: 0.6775458455085754
Validation loss: 2.1653859416643777

Epoch: 6| Step: 12
Training loss: 0.5116193294525146
Validation loss: 2.0946974953015647

Epoch: 6| Step: 13
Training loss: 0.5242425203323364
Validation loss: 2.113681455453237

Epoch: 440| Step: 0
Training loss: 0.8430254459381104
Validation loss: 2.184473733107249

Epoch: 6| Step: 1
Training loss: 0.8227491974830627
Validation loss: 2.169599254926046

Epoch: 6| Step: 2
Training loss: 0.7171167135238647
Validation loss: 2.1609623432159424

Epoch: 6| Step: 3
Training loss: 0.6555905938148499
Validation loss: 2.1363989313443503

Epoch: 6| Step: 4
Training loss: 0.5245808362960815
Validation loss: 2.132062554359436

Epoch: 6| Step: 5
Training loss: 0.6978276968002319
Validation loss: 2.1425543228785195

Epoch: 6| Step: 6
Training loss: 1.3004543781280518
Validation loss: 2.101584037144979

Epoch: 6| Step: 7
Training loss: 0.47082996368408203
Validation loss: 2.187089741230011

Epoch: 6| Step: 8
Training loss: 0.5496672987937927
Validation loss: 2.1520619988441467

Epoch: 6| Step: 9
Training loss: 0.29867568612098694
Validation loss: 2.1360926826794944

Epoch: 6| Step: 10
Training loss: 0.6534844040870667
Validation loss: 2.1412136952082315

Epoch: 6| Step: 11
Training loss: 0.38110047578811646
Validation loss: 2.133219599723816

Epoch: 6| Step: 12
Training loss: 1.2119712829589844
Validation loss: 2.2008490363756814

Epoch: 6| Step: 13
Training loss: 0.48146045207977295
Validation loss: 2.1681339542071023

Epoch: 441| Step: 0
Training loss: 0.6884492635726929
Validation loss: 2.192145605882009

Epoch: 6| Step: 1
Training loss: 0.9543173909187317
Validation loss: 2.177554110685984

Epoch: 6| Step: 2
Training loss: 0.845395565032959
Validation loss: 2.187145193417867

Epoch: 6| Step: 3
Training loss: 0.7814951539039612
Validation loss: 2.1767096519470215

Epoch: 6| Step: 4
Training loss: 1.2406845092773438
Validation loss: 2.175586144129435

Epoch: 6| Step: 5
Training loss: 0.31381139159202576
Validation loss: 2.152454455693563

Epoch: 6| Step: 6
Training loss: 0.9686224460601807
Validation loss: 2.1495630939801535

Epoch: 6| Step: 7
Training loss: 0.6898511052131653
Validation loss: 2.198165476322174

Epoch: 6| Step: 8
Training loss: 0.9384653568267822
Validation loss: 2.134181340535482

Epoch: 6| Step: 9
Training loss: 0.8559169173240662
Validation loss: 2.139965852101644

Epoch: 6| Step: 10
Training loss: 0.47588911652565
Validation loss: 2.170914669831594

Epoch: 6| Step: 11
Training loss: 0.7471798658370972
Validation loss: 2.1935424407323203

Epoch: 6| Step: 12
Training loss: 0.5216729044914246
Validation loss: 2.15653262535731

Epoch: 6| Step: 13
Training loss: 0.34674879908561707
Validation loss: 2.1458423336346946

Epoch: 442| Step: 0
Training loss: 0.6163256764411926
Validation loss: 2.1352585554122925

Epoch: 6| Step: 1
Training loss: 0.43106502294540405
Validation loss: 2.115107238292694

Epoch: 6| Step: 2
Training loss: 0.5324405431747437
Validation loss: 2.1227906942367554

Epoch: 6| Step: 3
Training loss: 0.9834650754928589
Validation loss: 2.1374733050664267

Epoch: 6| Step: 4
Training loss: 0.20825302600860596
Validation loss: 2.1307390332221985

Epoch: 6| Step: 5
Training loss: 1.1983542442321777
Validation loss: 2.1769892970720925

Epoch: 6| Step: 6
Training loss: 0.5726311206817627
Validation loss: 2.158247172832489

Epoch: 6| Step: 7
Training loss: 0.40561622381210327
Validation loss: 2.1557470560073853

Epoch: 6| Step: 8
Training loss: 0.5610368251800537
Validation loss: 2.111277679602305

Epoch: 6| Step: 9
Training loss: 1.2717993259429932
Validation loss: 2.1741687456766763

Epoch: 6| Step: 10
Training loss: 0.7278833389282227
Validation loss: 2.1857041915257773

Epoch: 6| Step: 11
Training loss: 0.887830376625061
Validation loss: 2.2447584867477417

Epoch: 6| Step: 12
Training loss: 0.5278918147087097
Validation loss: 2.276562492052714

Epoch: 6| Step: 13
Training loss: 0.7955827116966248
Validation loss: 2.1974233587582908

Epoch: 443| Step: 0
Training loss: 0.7168585062026978
Validation loss: 2.1447816292444863

Epoch: 6| Step: 1
Training loss: 0.4263862371444702
Validation loss: 2.1892870664596558

Epoch: 6| Step: 2
Training loss: 0.29584747552871704
Validation loss: 2.2301942308743796

Epoch: 6| Step: 3
Training loss: 0.7362900376319885
Validation loss: 2.171698013941447

Epoch: 6| Step: 4
Training loss: 0.5205715298652649
Validation loss: 2.138428966204325

Epoch: 6| Step: 5
Training loss: 0.3928314447402954
Validation loss: 2.1893915931383767

Epoch: 6| Step: 6
Training loss: 0.7416803240776062
Validation loss: 2.2203420996665955

Epoch: 6| Step: 7
Training loss: 1.5267250537872314
Validation loss: 2.1711405515670776

Epoch: 6| Step: 8
Training loss: 0.598422646522522
Validation loss: 2.2326128284136453

Epoch: 6| Step: 9
Training loss: 1.157340168952942
Validation loss: 2.185694475968679

Epoch: 6| Step: 10
Training loss: 0.9015647768974304
Validation loss: 2.169429620107015

Epoch: 6| Step: 11
Training loss: 0.7265106439590454
Validation loss: 2.1960564851760864

Epoch: 6| Step: 12
Training loss: 0.5414551496505737
Validation loss: 2.2285849849383035

Epoch: 6| Step: 13
Training loss: 1.129840612411499
Validation loss: 2.2046491702397666

Epoch: 444| Step: 0
Training loss: 0.6380127668380737
Validation loss: 2.2257723609606423

Epoch: 6| Step: 1
Training loss: 0.638881504535675
Validation loss: 2.239452838897705

Epoch: 6| Step: 2
Training loss: 1.0719596147537231
Validation loss: 2.2646650671958923

Epoch: 6| Step: 3
Training loss: 0.8111522793769836
Validation loss: 2.181678056716919

Epoch: 6| Step: 4
Training loss: 0.3237144947052002
Validation loss: 2.187021017074585

Epoch: 6| Step: 5
Training loss: 0.6416765451431274
Validation loss: 2.16616024573644

Epoch: 6| Step: 6
Training loss: 0.5004501342773438
Validation loss: 2.157141069571177

Epoch: 6| Step: 7
Training loss: 1.1557934284210205
Validation loss: 2.185920019944509

Epoch: 6| Step: 8
Training loss: 0.44310933351516724
Validation loss: 2.199088533719381

Epoch: 6| Step: 9
Training loss: 1.0860531330108643
Validation loss: 2.1602107087771096

Epoch: 6| Step: 10
Training loss: 0.7887305617332458
Validation loss: 2.1480371554692588

Epoch: 6| Step: 11
Training loss: 0.8593493700027466
Validation loss: 2.1814060608545938

Epoch: 6| Step: 12
Training loss: 0.47112658619880676
Validation loss: 2.1625028053919473

Epoch: 6| Step: 13
Training loss: 0.39045700430870056
Validation loss: 2.1502819856007895

Epoch: 445| Step: 0
Training loss: 0.42654526233673096
Validation loss: 2.192519466082255

Epoch: 6| Step: 1
Training loss: 1.4071910381317139
Validation loss: 2.2001344164212546

Epoch: 6| Step: 2
Training loss: 0.5583781003952026
Validation loss: 2.20058673620224

Epoch: 6| Step: 3
Training loss: 1.678900957107544
Validation loss: 2.1669428745905557

Epoch: 6| Step: 4
Training loss: 0.6361874341964722
Validation loss: 2.194413483142853

Epoch: 6| Step: 5
Training loss: 0.7336735725402832
Validation loss: 2.188736299673716

Epoch: 6| Step: 6
Training loss: 0.48228132724761963
Validation loss: 2.1628980239232383

Epoch: 6| Step: 7
Training loss: 0.5372124314308167
Validation loss: 2.2133575081825256

Epoch: 6| Step: 8
Training loss: 0.3839797377586365
Validation loss: 2.1929163535435996

Epoch: 6| Step: 9
Training loss: 0.7586705684661865
Validation loss: 2.1272798577944436

Epoch: 6| Step: 10
Training loss: 0.33980831503868103
Validation loss: 2.181376854578654

Epoch: 6| Step: 11
Training loss: 0.7834353446960449
Validation loss: 2.140868127346039

Epoch: 6| Step: 12
Training loss: 0.718161404132843
Validation loss: 2.212314486503601

Epoch: 6| Step: 13
Training loss: 0.36310428380966187
Validation loss: 2.1721994082132974

Epoch: 446| Step: 0
Training loss: 1.0423357486724854
Validation loss: 2.199481646219889

Epoch: 6| Step: 1
Training loss: 0.7860556840896606
Validation loss: 2.218084216117859

Epoch: 6| Step: 2
Training loss: 1.0151335000991821
Validation loss: 2.165127774079641

Epoch: 6| Step: 3
Training loss: 0.8750418424606323
Validation loss: 2.1686708529790244

Epoch: 6| Step: 4
Training loss: 0.8758031725883484
Validation loss: 2.126458009084066

Epoch: 6| Step: 5
Training loss: 0.6485532522201538
Validation loss: 2.131441593170166

Epoch: 6| Step: 6
Training loss: 0.39121538400650024
Validation loss: 2.1344388723373413

Epoch: 6| Step: 7
Training loss: 0.28935402631759644
Validation loss: 2.1741142868995667

Epoch: 6| Step: 8
Training loss: 0.5004891157150269
Validation loss: 2.1360878348350525

Epoch: 6| Step: 9
Training loss: 0.800941526889801
Validation loss: 2.1231439113616943

Epoch: 6| Step: 10
Training loss: 0.6267127394676208
Validation loss: 2.136746605237325

Epoch: 6| Step: 11
Training loss: 0.5995085835456848
Validation loss: 2.1466220021247864

Epoch: 6| Step: 12
Training loss: 1.219598650932312
Validation loss: 2.1646655996640525

Epoch: 6| Step: 13
Training loss: 0.4774666428565979
Validation loss: 2.1293148597081504

Epoch: 447| Step: 0
Training loss: 0.5403401851654053
Validation loss: 2.137538433074951

Epoch: 6| Step: 1
Training loss: 0.7343635559082031
Validation loss: 2.1559855341911316

Epoch: 6| Step: 2
Training loss: 0.6794335842132568
Validation loss: 2.1394596099853516

Epoch: 6| Step: 3
Training loss: 0.4609594941139221
Validation loss: 2.1469934582710266

Epoch: 6| Step: 4
Training loss: 0.6456400156021118
Validation loss: 2.145851254463196

Epoch: 6| Step: 5
Training loss: 0.821435272693634
Validation loss: 2.133700370788574

Epoch: 6| Step: 6
Training loss: 0.7344095706939697
Validation loss: 2.1719139218330383

Epoch: 6| Step: 7
Training loss: 0.8097655773162842
Validation loss: 2.139079491297404

Epoch: 6| Step: 8
Training loss: 1.4205994606018066
Validation loss: 2.121882220109304

Epoch: 6| Step: 9
Training loss: 0.8001079559326172
Validation loss: 2.1430840492248535

Epoch: 6| Step: 10
Training loss: 0.6380061507225037
Validation loss: 2.115191022555033

Epoch: 6| Step: 11
Training loss: 0.6103302240371704
Validation loss: 2.1255653500556946

Epoch: 6| Step: 12
Training loss: 0.39030176401138306
Validation loss: 2.129834512869517

Epoch: 6| Step: 13
Training loss: 0.6217514276504517
Validation loss: 2.07851105928421

Epoch: 448| Step: 0
Training loss: 0.3740440607070923
Validation loss: 2.169318437576294

Epoch: 6| Step: 1
Training loss: 0.654576301574707
Validation loss: 2.176534136136373

Epoch: 6| Step: 2
Training loss: 0.49104011058807373
Validation loss: 2.1536719600359597

Epoch: 6| Step: 3
Training loss: 0.53634113073349
Validation loss: 2.1615271965662637

Epoch: 6| Step: 4
Training loss: 0.45934510231018066
Validation loss: 2.1956371665000916

Epoch: 6| Step: 5
Training loss: 0.5781656503677368
Validation loss: 2.1681707302729287

Epoch: 6| Step: 6
Training loss: 0.8794319033622742
Validation loss: 2.16908331712087

Epoch: 6| Step: 7
Training loss: 0.4263455271720886
Validation loss: 2.1418892542521157

Epoch: 6| Step: 8
Training loss: 0.8395920991897583
Validation loss: 2.1458323200543723

Epoch: 6| Step: 9
Training loss: 0.7700595259666443
Validation loss: 2.1891042192777

Epoch: 6| Step: 10
Training loss: 0.7270153760910034
Validation loss: 2.1660441358884177

Epoch: 6| Step: 11
Training loss: 0.7380561232566833
Validation loss: 2.2358298301696777

Epoch: 6| Step: 12
Training loss: 1.0958293676376343
Validation loss: 2.199416935443878

Epoch: 6| Step: 13
Training loss: 0.8906922340393066
Validation loss: 2.1500812570254006

Epoch: 449| Step: 0
Training loss: 0.5980132818222046
Validation loss: 2.1743465463320413

Epoch: 6| Step: 1
Training loss: 0.36037614941596985
Validation loss: 2.165587067604065

Epoch: 6| Step: 2
Training loss: 0.4028193950653076
Validation loss: 2.16409041484197

Epoch: 6| Step: 3
Training loss: 0.6545743942260742
Validation loss: 2.203521649042765

Epoch: 6| Step: 4
Training loss: 0.5184919834136963
Validation loss: 2.152363399664561

Epoch: 6| Step: 5
Training loss: 0.8898999691009521
Validation loss: 2.181999921798706

Epoch: 6| Step: 6
Training loss: 0.3994307518005371
Validation loss: 2.2079521814982095

Epoch: 6| Step: 7
Training loss: 0.43044641613960266
Validation loss: 2.200641910235087

Epoch: 6| Step: 8
Training loss: 0.8706746101379395
Validation loss: 2.1665687362353006

Epoch: 6| Step: 9
Training loss: 1.3486573696136475
Validation loss: 2.191932181517283

Epoch: 6| Step: 10
Training loss: 0.9800097942352295
Validation loss: 2.1767237782478333

Epoch: 6| Step: 11
Training loss: 1.019897699356079
Validation loss: 2.1413048108418784

Epoch: 6| Step: 12
Training loss: 0.48876145482063293
Validation loss: 2.1763500968615213

Epoch: 6| Step: 13
Training loss: 0.9077750444412231
Validation loss: 2.177113195260366

Epoch: 450| Step: 0
Training loss: 0.5297896862030029
Validation loss: 2.141113797823588

Epoch: 6| Step: 1
Training loss: 0.38102900981903076
Validation loss: 2.1961182157198587

Epoch: 6| Step: 2
Training loss: 1.2387921810150146
Validation loss: 2.1469733119010925

Epoch: 6| Step: 3
Training loss: 0.5784775018692017
Validation loss: 2.1708110570907593

Epoch: 6| Step: 4
Training loss: 0.8017860651016235
Validation loss: 2.150986154874166

Epoch: 6| Step: 5
Training loss: 0.7174015045166016
Validation loss: 2.137718975543976

Epoch: 6| Step: 6
Training loss: 1.0365123748779297
Validation loss: 2.1464756528536477

Epoch: 6| Step: 7
Training loss: 0.5367847681045532
Validation loss: 2.101820091406504

Epoch: 6| Step: 8
Training loss: 0.5116074681282043
Validation loss: 2.114439288775126

Epoch: 6| Step: 9
Training loss: 1.0794676542282104
Validation loss: 2.145482063293457

Epoch: 6| Step: 10
Training loss: 0.553471565246582
Validation loss: 2.122697353363037

Epoch: 6| Step: 11
Training loss: 0.5987850427627563
Validation loss: 2.1305795907974243

Epoch: 6| Step: 12
Training loss: 0.3527354598045349
Validation loss: 2.1278284390767417

Epoch: 6| Step: 13
Training loss: 0.947419285774231
Validation loss: 2.1541674534479776

Epoch: 451| Step: 0
Training loss: 0.8138795495033264
Validation loss: 2.1651708682378135

Epoch: 6| Step: 1
Training loss: 0.4749736487865448
Validation loss: 2.1106069087982178

Epoch: 6| Step: 2
Training loss: 0.46331435441970825
Validation loss: 2.1638899445533752

Epoch: 6| Step: 3
Training loss: 0.5727274417877197
Validation loss: 2.1354504227638245

Epoch: 6| Step: 4
Training loss: 0.5363519191741943
Validation loss: 2.1455517609914145

Epoch: 6| Step: 5
Training loss: 0.39569729566574097
Validation loss: 2.1577876607577005

Epoch: 6| Step: 6
Training loss: 0.795211672782898
Validation loss: 2.134016513824463

Epoch: 6| Step: 7
Training loss: 0.6886656284332275
Validation loss: 2.148371994495392

Epoch: 6| Step: 8
Training loss: 0.610878050327301
Validation loss: 2.1642433404922485

Epoch: 6| Step: 9
Training loss: 0.46131643652915955
Validation loss: 2.1399529377619424

Epoch: 6| Step: 10
Training loss: 0.8819526433944702
Validation loss: 2.142740269502004

Epoch: 6| Step: 11
Training loss: 0.7952242493629456
Validation loss: 2.1316718260447183

Epoch: 6| Step: 12
Training loss: 1.1695668697357178
Validation loss: 2.1320213675498962

Epoch: 6| Step: 13
Training loss: 0.5069341063499451
Validation loss: 2.133717397848765

Epoch: 452| Step: 0
Training loss: 0.5007275938987732
Validation loss: 2.1641019384066262

Epoch: 6| Step: 1
Training loss: 0.42037251591682434
Validation loss: 2.1095911860466003

Epoch: 6| Step: 2
Training loss: 0.3404831886291504
Validation loss: 2.1229371229807534

Epoch: 6| Step: 3
Training loss: 1.3897221088409424
Validation loss: 2.1669137676556907

Epoch: 6| Step: 4
Training loss: 1.0347676277160645
Validation loss: 2.202558914820353

Epoch: 6| Step: 5
Training loss: 0.4821278750896454
Validation loss: 2.165204703807831

Epoch: 6| Step: 6
Training loss: 0.5034763813018799
Validation loss: 2.1709346771240234

Epoch: 6| Step: 7
Training loss: 1.1540247201919556
Validation loss: 2.17742927869161

Epoch: 6| Step: 8
Training loss: 0.4864113926887512
Validation loss: 2.1788132190704346

Epoch: 6| Step: 9
Training loss: 0.8608995676040649
Validation loss: 2.1395729184150696

Epoch: 6| Step: 10
Training loss: 0.7203092575073242
Validation loss: 2.1499492724736533

Epoch: 6| Step: 11
Training loss: 0.4254731237888336
Validation loss: 2.1860081950823465

Epoch: 6| Step: 12
Training loss: 0.43492645025253296
Validation loss: 2.215754965941111

Epoch: 6| Step: 13
Training loss: 0.4825280010700226
Validation loss: 2.1911871830622354

Epoch: 453| Step: 0
Training loss: 0.7203869819641113
Validation loss: 2.124933401743571

Epoch: 6| Step: 1
Training loss: 0.3751645088195801
Validation loss: 2.130225936571757

Epoch: 6| Step: 2
Training loss: 0.9656450152397156
Validation loss: 2.1283783117930093

Epoch: 6| Step: 3
Training loss: 1.1087706089019775
Validation loss: 2.1375967860221863

Epoch: 6| Step: 4
Training loss: 0.45113909244537354
Validation loss: 2.166089574495951

Epoch: 6| Step: 5
Training loss: 0.6843711137771606
Validation loss: 2.1611021359761557

Epoch: 6| Step: 6
Training loss: 0.5344346761703491
Validation loss: 2.1358242432276406

Epoch: 6| Step: 7
Training loss: 0.4339236915111542
Validation loss: 2.1401959458986917

Epoch: 6| Step: 8
Training loss: 0.43293851613998413
Validation loss: 2.1059312423070273

Epoch: 6| Step: 9
Training loss: 0.9117592573165894
Validation loss: 2.1220263242721558

Epoch: 6| Step: 10
Training loss: 0.30613723397254944
Validation loss: 2.146442731221517

Epoch: 6| Step: 11
Training loss: 0.6477080583572388
Validation loss: 2.1499133507410684

Epoch: 6| Step: 12
Training loss: 0.4443848729133606
Validation loss: 2.1480413476626077

Epoch: 6| Step: 13
Training loss: 0.7627615928649902
Validation loss: 2.1365865071614585

Epoch: 454| Step: 0
Training loss: 0.697196364402771
Validation loss: 2.1231011549631753

Epoch: 6| Step: 1
Training loss: 0.45629826188087463
Validation loss: 2.1226524710655212

Epoch: 6| Step: 2
Training loss: 0.8107643723487854
Validation loss: 2.146107534567515

Epoch: 6| Step: 3
Training loss: 0.9419229626655579
Validation loss: 2.15977410475413

Epoch: 6| Step: 4
Training loss: 0.6472474336624146
Validation loss: 2.157630681991577

Epoch: 6| Step: 5
Training loss: 0.559334933757782
Validation loss: 2.1641621589660645

Epoch: 6| Step: 6
Training loss: 0.43581390380859375
Validation loss: 2.1961318055788674

Epoch: 6| Step: 7
Training loss: 0.4057866334915161
Validation loss: 2.1804176767667136

Epoch: 6| Step: 8
Training loss: 0.4298533499240875
Validation loss: 2.1379029353459678

Epoch: 6| Step: 9
Training loss: 0.807058572769165
Validation loss: 2.1393702030181885

Epoch: 6| Step: 10
Training loss: 1.2280672788619995
Validation loss: 2.1810631354649863

Epoch: 6| Step: 11
Training loss: 0.33924832940101624
Validation loss: 2.1345765193303428

Epoch: 6| Step: 12
Training loss: 0.5052111148834229
Validation loss: 2.1468639572461448

Epoch: 6| Step: 13
Training loss: 0.6537562608718872
Validation loss: 2.163049896558126

Epoch: 455| Step: 0
Training loss: 0.4468139708042145
Validation loss: 2.142663300037384

Epoch: 6| Step: 1
Training loss: 0.6327642202377319
Validation loss: 2.1728853583335876

Epoch: 6| Step: 2
Training loss: 1.0870680809020996
Validation loss: 2.1551665465037027

Epoch: 6| Step: 3
Training loss: 0.32617390155792236
Validation loss: 2.1658582290013633

Epoch: 6| Step: 4
Training loss: 1.3972078561782837
Validation loss: 2.144618550936381

Epoch: 6| Step: 5
Training loss: 0.7946373224258423
Validation loss: 2.119874954223633

Epoch: 6| Step: 6
Training loss: 0.3848207890987396
Validation loss: 2.119290371735891

Epoch: 6| Step: 7
Training loss: 0.7158789038658142
Validation loss: 2.1417205731074014

Epoch: 6| Step: 8
Training loss: 0.372647762298584
Validation loss: 2.1683157881100974

Epoch: 6| Step: 9
Training loss: 0.5059034824371338
Validation loss: 2.1385945479075112

Epoch: 6| Step: 10
Training loss: 0.2946426272392273
Validation loss: 2.1193854808807373

Epoch: 6| Step: 11
Training loss: 0.5032287836074829
Validation loss: 2.108142852783203

Epoch: 6| Step: 12
Training loss: 0.5446164608001709
Validation loss: 2.120521863301595

Epoch: 6| Step: 13
Training loss: 0.6535661220550537
Validation loss: 2.1339184840520224

Epoch: 456| Step: 0
Training loss: 0.7341551780700684
Validation loss: 2.14260466893514

Epoch: 6| Step: 1
Training loss: 0.6459009647369385
Validation loss: 2.1438151597976685

Epoch: 6| Step: 2
Training loss: 0.8797642588615417
Validation loss: 2.1713384985923767

Epoch: 6| Step: 3
Training loss: 0.522962749004364
Validation loss: 2.1706444025039673

Epoch: 6| Step: 4
Training loss: 0.9937824010848999
Validation loss: 2.1596513390541077

Epoch: 6| Step: 5
Training loss: 0.9397897720336914
Validation loss: 2.1110270818074546

Epoch: 6| Step: 6
Training loss: 0.5926336050033569
Validation loss: 2.117950658003489

Epoch: 6| Step: 7
Training loss: 0.5494810342788696
Validation loss: 2.1300989985466003

Epoch: 6| Step: 8
Training loss: 0.5738670825958252
Validation loss: 2.1605700850486755

Epoch: 6| Step: 9
Training loss: 0.5546091198921204
Validation loss: 2.160322924455007

Epoch: 6| Step: 10
Training loss: 0.44911324977874756
Validation loss: 2.0919782320658364

Epoch: 6| Step: 11
Training loss: 0.8597070574760437
Validation loss: 2.1411635677019754

Epoch: 6| Step: 12
Training loss: 0.7365666627883911
Validation loss: 2.1348335345586142

Epoch: 6| Step: 13
Training loss: 0.4255528450012207
Validation loss: 2.1371599435806274

Epoch: 457| Step: 0
Training loss: 0.5294516086578369
Validation loss: 2.2090291182200112

Epoch: 6| Step: 1
Training loss: 0.8691673278808594
Validation loss: 2.161696672439575

Epoch: 6| Step: 2
Training loss: 0.5505143404006958
Validation loss: 2.1604740222295127

Epoch: 6| Step: 3
Training loss: 0.5791776776313782
Validation loss: 2.15957780679067

Epoch: 6| Step: 4
Training loss: 0.46976521611213684
Validation loss: 2.1264228423436484

Epoch: 6| Step: 5
Training loss: 0.6477121114730835
Validation loss: 2.143795986970266

Epoch: 6| Step: 6
Training loss: 0.6170139908790588
Validation loss: 2.1756815314292908

Epoch: 6| Step: 7
Training loss: 0.312852680683136
Validation loss: 2.129826804002126

Epoch: 6| Step: 8
Training loss: 0.3219117224216461
Validation loss: 2.165034453074137

Epoch: 6| Step: 9
Training loss: 0.7036871314048767
Validation loss: 2.1302120089530945

Epoch: 6| Step: 10
Training loss: 1.206298828125
Validation loss: 2.163719971974691

Epoch: 6| Step: 11
Training loss: 0.7976830005645752
Validation loss: 2.115305999914805

Epoch: 6| Step: 12
Training loss: 0.5120530128479004
Validation loss: 2.12687482436498

Epoch: 6| Step: 13
Training loss: 0.3135528862476349
Validation loss: 2.087818185488383

Epoch: 458| Step: 0
Training loss: 0.3616461455821991
Validation loss: 2.155612369378408

Epoch: 6| Step: 1
Training loss: 0.4540662169456482
Validation loss: 2.1410276889801025

Epoch: 6| Step: 2
Training loss: 0.9282180070877075
Validation loss: 2.130242665608724

Epoch: 6| Step: 3
Training loss: 0.9063490629196167
Validation loss: 2.097197671731313

Epoch: 6| Step: 4
Training loss: 0.9371097087860107
Validation loss: 2.0597731669743857

Epoch: 6| Step: 5
Training loss: 0.18860939145088196
Validation loss: 2.0651734670003257

Epoch: 6| Step: 6
Training loss: 0.6098179817199707
Validation loss: 2.073549528916677

Epoch: 6| Step: 7
Training loss: 0.42943522334098816
Validation loss: 2.1159340937932334

Epoch: 6| Step: 8
Training loss: 0.5907866358757019
Validation loss: 2.129637877146403

Epoch: 6| Step: 9
Training loss: 0.2823728322982788
Validation loss: 2.126730998357137

Epoch: 6| Step: 10
Training loss: 0.7175588011741638
Validation loss: 2.1165352861086526

Epoch: 6| Step: 11
Training loss: 0.5631174445152283
Validation loss: 2.1182037790616355

Epoch: 6| Step: 12
Training loss: 0.47644633054733276
Validation loss: 2.1006386280059814

Epoch: 6| Step: 13
Training loss: 0.85223788022995
Validation loss: 2.192961851755778

Epoch: 459| Step: 0
Training loss: 0.6205329895019531
Validation loss: 2.152718245983124

Epoch: 6| Step: 1
Training loss: 0.3992884159088135
Validation loss: 2.142077843348185

Epoch: 6| Step: 2
Training loss: 0.8165361285209656
Validation loss: 2.1459623177846274

Epoch: 6| Step: 3
Training loss: 0.33194252848625183
Validation loss: 2.1073668797810874

Epoch: 6| Step: 4
Training loss: 0.4671384394168854
Validation loss: 2.098742922147115

Epoch: 6| Step: 5
Training loss: 0.3980847895145416
Validation loss: 2.102713326613108

Epoch: 6| Step: 6
Training loss: 0.37496352195739746
Validation loss: 2.105724056561788

Epoch: 6| Step: 7
Training loss: 0.8241488337516785
Validation loss: 2.100183367729187

Epoch: 6| Step: 8
Training loss: 0.6072372198104858
Validation loss: 2.095251977443695

Epoch: 6| Step: 9
Training loss: 0.5217658281326294
Validation loss: 2.1329187949498496

Epoch: 6| Step: 10
Training loss: 0.4381355941295624
Validation loss: 2.1127412915229797

Epoch: 6| Step: 11
Training loss: 1.2671937942504883
Validation loss: 2.164529263973236

Epoch: 6| Step: 12
Training loss: 0.637100875377655
Validation loss: 2.1334297259648642

Epoch: 6| Step: 13
Training loss: 0.4160021245479584
Validation loss: 2.178124725818634

Epoch: 460| Step: 0
Training loss: 0.3062813878059387
Validation loss: 2.177940050760905

Epoch: 6| Step: 1
Training loss: 0.6052578091621399
Validation loss: 2.1358570655186973

Epoch: 6| Step: 2
Training loss: 0.34969139099121094
Validation loss: 2.065364102522532

Epoch: 6| Step: 3
Training loss: 0.5291613340377808
Validation loss: 2.0965272982915244

Epoch: 6| Step: 4
Training loss: 0.470298171043396
Validation loss: 2.127453029155731

Epoch: 6| Step: 5
Training loss: 0.35412168502807617
Validation loss: 2.164060056209564

Epoch: 6| Step: 6
Training loss: 0.5613870024681091
Validation loss: 2.114637017250061

Epoch: 6| Step: 7
Training loss: 0.5112468600273132
Validation loss: 2.158997138341268

Epoch: 6| Step: 8
Training loss: 0.7469270825386047
Validation loss: 2.1613586147626243

Epoch: 6| Step: 9
Training loss: 0.9580439329147339
Validation loss: 2.158752997716268

Epoch: 6| Step: 10
Training loss: 0.7803440690040588
Validation loss: 2.141848385334015

Epoch: 6| Step: 11
Training loss: 0.8518416881561279
Validation loss: 2.1417810122172036

Epoch: 6| Step: 12
Training loss: 0.6037663221359253
Validation loss: 2.153816560904185

Epoch: 6| Step: 13
Training loss: 0.5060731172561646
Validation loss: 2.1586763858795166

Epoch: 461| Step: 0
Training loss: 0.380088210105896
Validation loss: 2.1453004678090415

Epoch: 6| Step: 1
Training loss: 0.7669626474380493
Validation loss: 2.1520670652389526

Epoch: 6| Step: 2
Training loss: 0.4028840661048889
Validation loss: 2.1091627875963845

Epoch: 6| Step: 3
Training loss: 0.5918903350830078
Validation loss: 2.152144511540731

Epoch: 6| Step: 4
Training loss: 0.8893111944198608
Validation loss: 2.1191760698954263

Epoch: 6| Step: 5
Training loss: 0.5037981271743774
Validation loss: 2.157282511393229

Epoch: 6| Step: 6
Training loss: 0.5246817469596863
Validation loss: 2.155128836631775

Epoch: 6| Step: 7
Training loss: 0.9425944685935974
Validation loss: 2.1151368021965027

Epoch: 6| Step: 8
Training loss: 0.4106829762458801
Validation loss: 2.1612152457237244

Epoch: 6| Step: 9
Training loss: 0.9249145984649658
Validation loss: 2.1601409713427224

Epoch: 6| Step: 10
Training loss: 0.3795742988586426
Validation loss: 2.1804580887158713

Epoch: 6| Step: 11
Training loss: 0.31833556294441223
Validation loss: 2.12465234597524

Epoch: 6| Step: 12
Training loss: 0.5191519260406494
Validation loss: 2.1014221906661987

Epoch: 6| Step: 13
Training loss: 0.8122092485427856
Validation loss: 2.116063952445984

Epoch: 462| Step: 0
Training loss: 0.4835837781429291
Validation loss: 2.133768598238627

Epoch: 6| Step: 1
Training loss: 0.6199394464492798
Validation loss: 2.147913336753845

Epoch: 6| Step: 2
Training loss: 0.4365749657154083
Validation loss: 2.120993971824646

Epoch: 6| Step: 3
Training loss: 0.4125511646270752
Validation loss: 2.139793872833252

Epoch: 6| Step: 4
Training loss: 1.0898337364196777
Validation loss: 2.112302223841349

Epoch: 6| Step: 5
Training loss: 0.8666384220123291
Validation loss: 2.1307648619016013

Epoch: 6| Step: 6
Training loss: 0.36663323640823364
Validation loss: 2.1056016087532043

Epoch: 6| Step: 7
Training loss: 0.3195646107196808
Validation loss: 2.1383139292399087

Epoch: 6| Step: 8
Training loss: 0.4534493088722229
Validation loss: 2.143958489100138

Epoch: 6| Step: 9
Training loss: 0.4342825710773468
Validation loss: 2.163002530733744

Epoch: 6| Step: 10
Training loss: 0.5163077116012573
Validation loss: 2.1079631646474204

Epoch: 6| Step: 11
Training loss: 0.39780810475349426
Validation loss: 2.1175769170125327

Epoch: 6| Step: 12
Training loss: 0.8974771499633789
Validation loss: 2.0886409878730774

Epoch: 6| Step: 13
Training loss: 0.9805362224578857
Validation loss: 2.1328548590342202

Epoch: 463| Step: 0
Training loss: 0.6454693078994751
Validation loss: 2.101757268110911

Epoch: 6| Step: 1
Training loss: 0.6402643322944641
Validation loss: 2.1245553890864053

Epoch: 6| Step: 2
Training loss: 0.3328853249549866
Validation loss: 2.116450071334839

Epoch: 6| Step: 3
Training loss: 0.39262303709983826
Validation loss: 2.0463621020317078

Epoch: 6| Step: 4
Training loss: 0.4996359944343567
Validation loss: 2.120389382044474

Epoch: 6| Step: 5
Training loss: 0.8536289930343628
Validation loss: 2.1522730588912964

Epoch: 6| Step: 6
Training loss: 0.32346421480178833
Validation loss: 2.1291542847951255

Epoch: 6| Step: 7
Training loss: 0.6734689474105835
Validation loss: 2.1266172329584756

Epoch: 6| Step: 8
Training loss: 0.5629227161407471
Validation loss: 2.130334794521332

Epoch: 6| Step: 9
Training loss: 0.5023515224456787
Validation loss: 2.0650286078453064

Epoch: 6| Step: 10
Training loss: 0.44214344024658203
Validation loss: 2.1465805967648826

Epoch: 6| Step: 11
Training loss: 0.9832570552825928
Validation loss: 2.1495374639829

Epoch: 6| Step: 12
Training loss: 0.38570618629455566
Validation loss: 2.145213266213735

Epoch: 6| Step: 13
Training loss: 1.2043306827545166
Validation loss: 2.1347809632619223

Epoch: 464| Step: 0
Training loss: 1.2546868324279785
Validation loss: 2.1459111968676248

Epoch: 6| Step: 1
Training loss: 0.39719635248184204
Validation loss: 2.159055173397064

Epoch: 6| Step: 2
Training loss: 0.5176589488983154
Validation loss: 2.1877347032229104

Epoch: 6| Step: 3
Training loss: 0.4155789315700531
Validation loss: 2.1685195167859397

Epoch: 6| Step: 4
Training loss: 0.3665368854999542
Validation loss: 2.1378958225250244

Epoch: 6| Step: 5
Training loss: 0.6570430994033813
Validation loss: 2.125208775202433

Epoch: 6| Step: 6
Training loss: 0.27185752987861633
Validation loss: 2.109927495320638

Epoch: 6| Step: 7
Training loss: 0.6438612937927246
Validation loss: 2.099126617113749

Epoch: 6| Step: 8
Training loss: 0.8659992218017578
Validation loss: 2.1375639041264853

Epoch: 6| Step: 9
Training loss: 0.628144383430481
Validation loss: 2.135106106599172

Epoch: 6| Step: 10
Training loss: 0.7892370820045471
Validation loss: 2.1702698866526284

Epoch: 6| Step: 11
Training loss: 0.2645629644393921
Validation loss: 2.198385715484619

Epoch: 6| Step: 12
Training loss: 0.8661891222000122
Validation loss: 2.1719838778177896

Epoch: 6| Step: 13
Training loss: 0.6319103240966797
Validation loss: 2.0946375926335654

Epoch: 465| Step: 0
Training loss: 0.4157412052154541
Validation loss: 2.1641806165377298

Epoch: 6| Step: 1
Training loss: 0.2191350907087326
Validation loss: 2.166754682858785

Epoch: 6| Step: 2
Training loss: 0.2520570755004883
Validation loss: 2.1764234701792398

Epoch: 6| Step: 3
Training loss: 0.49829840660095215
Validation loss: 2.109866182009379

Epoch: 6| Step: 4
Training loss: 0.42385321855545044
Validation loss: 2.09474378824234

Epoch: 6| Step: 5
Training loss: 0.47069796919822693
Validation loss: 2.110467175642649

Epoch: 6| Step: 6
Training loss: 0.4841427803039551
Validation loss: 2.1275147596995034

Epoch: 6| Step: 7
Training loss: 0.3499164879322052
Validation loss: 2.1179514726003013

Epoch: 6| Step: 8
Training loss: 0.8393010497093201
Validation loss: 2.1732473373413086

Epoch: 6| Step: 9
Training loss: 0.8137410879135132
Validation loss: 2.1242148081461587

Epoch: 6| Step: 10
Training loss: 0.3625337779521942
Validation loss: 2.1123518149058023

Epoch: 6| Step: 11
Training loss: 0.7180374264717102
Validation loss: 2.1350900133450827

Epoch: 6| Step: 12
Training loss: 1.2607207298278809
Validation loss: 2.162855088710785

Epoch: 6| Step: 13
Training loss: 0.9591249227523804
Validation loss: 2.190175712108612

Epoch: 466| Step: 0
Training loss: 0.4734296202659607
Validation loss: 2.1799625555674234

Epoch: 6| Step: 1
Training loss: 0.5674633383750916
Validation loss: 2.1886605421702066

Epoch: 6| Step: 2
Training loss: 1.0494177341461182
Validation loss: 2.181569437185923

Epoch: 6| Step: 3
Training loss: 0.4130711257457733
Validation loss: 2.1836472352345786

Epoch: 6| Step: 4
Training loss: 1.2350196838378906
Validation loss: 2.200236141681671

Epoch: 6| Step: 5
Training loss: 0.36326780915260315
Validation loss: 2.13606721162796

Epoch: 6| Step: 6
Training loss: 0.3580513298511505
Validation loss: 2.186892549196879

Epoch: 6| Step: 7
Training loss: 0.9626929759979248
Validation loss: 2.1673853198687234

Epoch: 6| Step: 8
Training loss: 0.865512490272522
Validation loss: 2.1974554856618247

Epoch: 6| Step: 9
Training loss: 0.5903773307800293
Validation loss: 2.1730982462565103

Epoch: 6| Step: 10
Training loss: 0.33043867349624634
Validation loss: 2.1497443318367004

Epoch: 6| Step: 11
Training loss: 0.3840267062187195
Validation loss: 2.158444623152415

Epoch: 6| Step: 12
Training loss: 0.37049731612205505
Validation loss: 2.15315051873525

Epoch: 6| Step: 13
Training loss: 0.46281924843788147
Validation loss: 2.167837917804718

Epoch: 467| Step: 0
Training loss: 0.43601804971694946
Validation loss: 2.1361308892567954

Epoch: 6| Step: 1
Training loss: 0.7221726179122925
Validation loss: 2.191273887952169

Epoch: 6| Step: 2
Training loss: 0.3125900328159332
Validation loss: 2.124727209409078

Epoch: 6| Step: 3
Training loss: 0.4080584645271301
Validation loss: 2.1209428707758584

Epoch: 6| Step: 4
Training loss: 0.6352105736732483
Validation loss: 2.111509104569753

Epoch: 6| Step: 5
Training loss: 0.5320007801055908
Validation loss: 2.1172624627749124

Epoch: 6| Step: 6
Training loss: 1.0901024341583252
Validation loss: 2.1522903641064963

Epoch: 6| Step: 7
Training loss: 0.49188005924224854
Validation loss: 2.1330464482307434

Epoch: 6| Step: 8
Training loss: 0.3494064509868622
Validation loss: 2.1884215076764426

Epoch: 6| Step: 9
Training loss: 0.2857593297958374
Validation loss: 2.185352365175883

Epoch: 6| Step: 10
Training loss: 0.822481095790863
Validation loss: 2.1063528060913086

Epoch: 6| Step: 11
Training loss: 1.0425493717193604
Validation loss: 2.12423175573349

Epoch: 6| Step: 12
Training loss: 0.7658803462982178
Validation loss: 2.1153137485186257

Epoch: 6| Step: 13
Training loss: 0.4442584216594696
Validation loss: 2.1013984282811484

Epoch: 468| Step: 0
Training loss: 0.708997368812561
Validation loss: 2.1703652342160544

Epoch: 6| Step: 1
Training loss: 0.4501785337924957
Validation loss: 2.1294665932655334

Epoch: 6| Step: 2
Training loss: 0.6937963962554932
Validation loss: 2.171619435151418

Epoch: 6| Step: 3
Training loss: 1.0784988403320312
Validation loss: 2.154057423273722

Epoch: 6| Step: 4
Training loss: 0.6945761442184448
Validation loss: 2.185900708039602

Epoch: 6| Step: 5
Training loss: 0.46553725004196167
Validation loss: 2.1618176301320395

Epoch: 6| Step: 6
Training loss: 1.1039201021194458
Validation loss: 2.128206173578898

Epoch: 6| Step: 7
Training loss: 0.6243482232093811
Validation loss: 2.1380408008893332

Epoch: 6| Step: 8
Training loss: 0.5588899850845337
Validation loss: 2.0991821686426797

Epoch: 6| Step: 9
Training loss: 0.28786832094192505
Validation loss: 2.0703352292378745

Epoch: 6| Step: 10
Training loss: 0.30617865920066833
Validation loss: 2.129834075768789

Epoch: 6| Step: 11
Training loss: 0.3441259562969208
Validation loss: 2.0559972127278647

Epoch: 6| Step: 12
Training loss: 0.7681270837783813
Validation loss: 2.0748653014500937

Epoch: 6| Step: 13
Training loss: 0.37505394220352173
Validation loss: 2.084263483683268

Epoch: 469| Step: 0
Training loss: 0.3850610852241516
Validation loss: 2.072622835636139

Epoch: 6| Step: 1
Training loss: 0.7886828780174255
Validation loss: 2.10884690284729

Epoch: 6| Step: 2
Training loss: 0.6814998388290405
Validation loss: 2.1261118253072104

Epoch: 6| Step: 3
Training loss: 0.7012673616409302
Validation loss: 2.13970156510671

Epoch: 6| Step: 4
Training loss: 0.3974766731262207
Validation loss: 2.1365621089935303

Epoch: 6| Step: 5
Training loss: 0.8015259504318237
Validation loss: 2.1465834180514016

Epoch: 6| Step: 6
Training loss: 0.44528037309646606
Validation loss: 2.15730086962382

Epoch: 6| Step: 7
Training loss: 0.7124662399291992
Validation loss: 2.1028388341267905

Epoch: 6| Step: 8
Training loss: 0.5623700618743896
Validation loss: 2.0813780625661216

Epoch: 6| Step: 9
Training loss: 0.445479154586792
Validation loss: 2.1588763991991677

Epoch: 6| Step: 10
Training loss: 0.8298685550689697
Validation loss: 2.1196504831314087

Epoch: 6| Step: 11
Training loss: 0.6303775906562805
Validation loss: 2.1556227803230286

Epoch: 6| Step: 12
Training loss: 0.3528469204902649
Validation loss: 2.1714350382486978

Epoch: 6| Step: 13
Training loss: 0.6942727565765381
Validation loss: 2.125013291835785

Epoch: 470| Step: 0
Training loss: 0.49603715538978577
Validation loss: 2.129798471927643

Epoch: 6| Step: 1
Training loss: 0.9642292261123657
Validation loss: 2.1124293208122253

Epoch: 6| Step: 2
Training loss: 0.38040804862976074
Validation loss: 2.170773526032766

Epoch: 6| Step: 3
Training loss: 0.5370920896530151
Validation loss: 2.172449072202047

Epoch: 6| Step: 4
Training loss: 0.7922354340553284
Validation loss: 2.1612412532170615

Epoch: 6| Step: 5
Training loss: 0.6645357608795166
Validation loss: 2.1854728062947593

Epoch: 6| Step: 6
Training loss: 0.765380859375
Validation loss: 2.1800849040349326

Epoch: 6| Step: 7
Training loss: 0.39134982228279114
Validation loss: 2.233993351459503

Epoch: 6| Step: 8
Training loss: 0.43413108587265015
Validation loss: 2.171782592932383

Epoch: 6| Step: 9
Training loss: 0.59816575050354
Validation loss: 2.1690903504689536

Epoch: 6| Step: 10
Training loss: 0.3217940628528595
Validation loss: 2.125691572825114

Epoch: 6| Step: 11
Training loss: 0.7057148218154907
Validation loss: 2.10003532965978

Epoch: 6| Step: 12
Training loss: 0.36652156710624695
Validation loss: 2.1599618395169577

Epoch: 6| Step: 13
Training loss: 0.6349234580993652
Validation loss: 2.1302747329076133

Epoch: 471| Step: 0
Training loss: 0.7997226119041443
Validation loss: 2.1552547613779702

Epoch: 6| Step: 1
Training loss: 0.9990377426147461
Validation loss: 2.1572838028271994

Epoch: 6| Step: 2
Training loss: 0.36632391810417175
Validation loss: 2.1211127638816833

Epoch: 6| Step: 3
Training loss: 0.6488903760910034
Validation loss: 2.1473142504692078

Epoch: 6| Step: 4
Training loss: 0.6727604866027832
Validation loss: 2.138806958993276

Epoch: 6| Step: 5
Training loss: 0.4990313649177551
Validation loss: 2.16027424732844

Epoch: 6| Step: 6
Training loss: 0.3091433644294739
Validation loss: 2.1870725552241006

Epoch: 6| Step: 7
Training loss: 0.32077276706695557
Validation loss: 2.141064008076986

Epoch: 6| Step: 8
Training loss: 0.3613634705543518
Validation loss: 2.144616643587748

Epoch: 6| Step: 9
Training loss: 0.5116255879402161
Validation loss: 2.1636653741200766

Epoch: 6| Step: 10
Training loss: 0.5087881684303284
Validation loss: 2.1257482965787253

Epoch: 6| Step: 11
Training loss: 0.8594092130661011
Validation loss: 2.082866628964742

Epoch: 6| Step: 12
Training loss: 0.8500685095787048
Validation loss: 2.0826681653658548

Epoch: 6| Step: 13
Training loss: 0.6098991632461548
Validation loss: 2.088026285171509

Epoch: 472| Step: 0
Training loss: 0.7536178231239319
Validation loss: 2.112664441267649

Epoch: 6| Step: 1
Training loss: 0.4346802830696106
Validation loss: 2.1055254538853965

Epoch: 6| Step: 2
Training loss: 0.30897611379623413
Validation loss: 2.126056671142578

Epoch: 6| Step: 3
Training loss: 0.49966877698898315
Validation loss: 2.115791837374369

Epoch: 6| Step: 4
Training loss: 0.7899466156959534
Validation loss: 2.161007801691691

Epoch: 6| Step: 5
Training loss: 0.5484896898269653
Validation loss: 2.165772259235382

Epoch: 6| Step: 6
Training loss: 0.4729765057563782
Validation loss: 2.16827525695165

Epoch: 6| Step: 7
Training loss: 0.40945905447006226
Validation loss: 2.1337562998135886

Epoch: 6| Step: 8
Training loss: 0.7385927438735962
Validation loss: 2.110965450604757

Epoch: 6| Step: 9
Training loss: 0.7153653502464294
Validation loss: 2.1135000785191855

Epoch: 6| Step: 10
Training loss: 0.9071146249771118
Validation loss: 2.1579363544782004

Epoch: 6| Step: 11
Training loss: 0.47671329975128174
Validation loss: 2.11073503891627

Epoch: 6| Step: 12
Training loss: 0.9953244924545288
Validation loss: 2.1410207748413086

Epoch: 6| Step: 13
Training loss: 0.30541449785232544
Validation loss: 2.173134207725525

Epoch: 473| Step: 0
Training loss: 0.5139264464378357
Validation loss: 2.1267227133115134

Epoch: 6| Step: 1
Training loss: 0.24805757403373718
Validation loss: 2.1311824520428977

Epoch: 6| Step: 2
Training loss: 0.6130386590957642
Validation loss: 2.1615111231803894

Epoch: 6| Step: 3
Training loss: 0.4783315658569336
Validation loss: 2.1641052762667337

Epoch: 6| Step: 4
Training loss: 0.7363373637199402
Validation loss: 2.1685689091682434

Epoch: 6| Step: 5
Training loss: 0.4763564169406891
Validation loss: 2.17646332581838

Epoch: 6| Step: 6
Training loss: 0.41725268959999084
Validation loss: 2.155168374379476

Epoch: 6| Step: 7
Training loss: 0.8205043077468872
Validation loss: 2.159152309099833

Epoch: 6| Step: 8
Training loss: 0.7065240740776062
Validation loss: 2.1456894477208457

Epoch: 6| Step: 9
Training loss: 0.5703648924827576
Validation loss: 2.140684803326925

Epoch: 6| Step: 10
Training loss: 0.7617953419685364
Validation loss: 2.14123272895813

Epoch: 6| Step: 11
Training loss: 0.588512122631073
Validation loss: 2.1881356438001

Epoch: 6| Step: 12
Training loss: 0.3885657489299774
Validation loss: 2.1927663485209146

Epoch: 6| Step: 13
Training loss: 0.658568263053894
Validation loss: 2.1604876716931662

Epoch: 474| Step: 0
Training loss: 0.44439253211021423
Validation loss: 2.1042048136393228

Epoch: 6| Step: 1
Training loss: 0.21521906554698944
Validation loss: 2.0983261664708457

Epoch: 6| Step: 2
Training loss: 0.34537822008132935
Validation loss: 2.1198375622431436

Epoch: 6| Step: 3
Training loss: 0.5458498001098633
Validation loss: 2.09841517607371

Epoch: 6| Step: 4
Training loss: 0.7361034750938416
Validation loss: 2.1169275442759194

Epoch: 6| Step: 5
Training loss: 0.5759330987930298
Validation loss: 2.075872818628947

Epoch: 6| Step: 6
Training loss: 0.8119165301322937
Validation loss: 2.0946617921193442

Epoch: 6| Step: 7
Training loss: 0.3991062343120575
Validation loss: 2.1335213581720986

Epoch: 6| Step: 8
Training loss: 0.9841498136520386
Validation loss: 2.1401508847872415

Epoch: 6| Step: 9
Training loss: 0.7617435455322266
Validation loss: 2.1557093461354575

Epoch: 6| Step: 10
Training loss: 0.3492662310600281
Validation loss: 2.130319575468699

Epoch: 6| Step: 11
Training loss: 0.4364098906517029
Validation loss: 2.1775198380152383

Epoch: 6| Step: 12
Training loss: 0.8548715710639954
Validation loss: 2.179361621538798

Epoch: 6| Step: 13
Training loss: 0.7737025618553162
Validation loss: 2.155670464038849

Epoch: 475| Step: 0
Training loss: 0.7760626077651978
Validation loss: 2.145775020122528

Epoch: 6| Step: 1
Training loss: 0.4463353753089905
Validation loss: 2.158380071322123

Epoch: 6| Step: 2
Training loss: 0.7426028251647949
Validation loss: 2.1048419078191123

Epoch: 6| Step: 3
Training loss: 0.5688596963882446
Validation loss: 2.119253476460775

Epoch: 6| Step: 4
Training loss: 0.3623736798763275
Validation loss: 2.109143773714701

Epoch: 6| Step: 5
Training loss: 0.2425440102815628
Validation loss: 2.181195239226023

Epoch: 6| Step: 6
Training loss: 0.40606701374053955
Validation loss: 2.153681496779124

Epoch: 6| Step: 7
Training loss: 0.38919854164123535
Validation loss: 2.143297533194224

Epoch: 6| Step: 8
Training loss: 0.659533679485321
Validation loss: 2.1091281374295554

Epoch: 6| Step: 9
Training loss: 1.0104442834854126
Validation loss: 2.148216485977173

Epoch: 6| Step: 10
Training loss: 0.4859224855899811
Validation loss: 2.118583003679911

Epoch: 6| Step: 11
Training loss: 0.46732836961746216
Validation loss: 2.1298380692799888

Epoch: 6| Step: 12
Training loss: 0.8029866218566895
Validation loss: 2.04313862323761

Epoch: 6| Step: 13
Training loss: 0.47681283950805664
Validation loss: 2.122011343638102

Epoch: 476| Step: 0
Training loss: 0.6401203274726868
Validation loss: 2.1262380480766296

Epoch: 6| Step: 1
Training loss: 0.36718595027923584
Validation loss: 2.1206372578938804

Epoch: 6| Step: 2
Training loss: 0.5337607264518738
Validation loss: 2.132607161998749

Epoch: 6| Step: 3
Training loss: 0.8819019794464111
Validation loss: 2.19193967183431

Epoch: 6| Step: 4
Training loss: 0.6483522057533264
Validation loss: 2.163793166478475

Epoch: 6| Step: 5
Training loss: 0.5854542255401611
Validation loss: 2.1210872530937195

Epoch: 6| Step: 6
Training loss: 0.8300209641456604
Validation loss: 2.110716223716736

Epoch: 6| Step: 7
Training loss: 0.4512288570404053
Validation loss: 2.124109407265981

Epoch: 6| Step: 8
Training loss: 0.30239778757095337
Validation loss: 2.085516711076101

Epoch: 6| Step: 9
Training loss: 0.428424209356308
Validation loss: 2.1068482398986816

Epoch: 6| Step: 10
Training loss: 0.35092800855636597
Validation loss: 2.0521172285079956

Epoch: 6| Step: 11
Training loss: 0.311134397983551
Validation loss: 2.1068727374076843

Epoch: 6| Step: 12
Training loss: 0.5043575763702393
Validation loss: 2.0885536670684814

Epoch: 6| Step: 13
Training loss: 0.7351478338241577
Validation loss: 2.1202951669692993

Epoch: 477| Step: 0
Training loss: 0.5975127816200256
Validation loss: 2.1127707163492837

Epoch: 6| Step: 1
Training loss: 0.5008580088615417
Validation loss: 2.0976874033610025

Epoch: 6| Step: 2
Training loss: 0.7231433987617493
Validation loss: 2.1286011934280396

Epoch: 6| Step: 3
Training loss: 0.39259928464889526
Validation loss: 2.132505695025126

Epoch: 6| Step: 4
Training loss: 0.33300042152404785
Validation loss: 2.1576850215593972

Epoch: 6| Step: 5
Training loss: 0.3097795844078064
Validation loss: 2.1692833503087363

Epoch: 6| Step: 6
Training loss: 0.30269187688827515
Validation loss: 2.1694162686665854

Epoch: 6| Step: 7
Training loss: 0.2597872018814087
Validation loss: 2.167738437652588

Epoch: 6| Step: 8
Training loss: 0.7752851843833923
Validation loss: 2.1696146925290427

Epoch: 6| Step: 9
Training loss: 0.8987863659858704
Validation loss: 2.1689624786376953

Epoch: 6| Step: 10
Training loss: 0.6551533341407776
Validation loss: 2.2181290984153748

Epoch: 6| Step: 11
Training loss: 0.8288998007774353
Validation loss: 2.157453497250875

Epoch: 6| Step: 12
Training loss: 0.40161871910095215
Validation loss: 2.224386215209961

Epoch: 6| Step: 13
Training loss: 0.8780441284179688
Validation loss: 2.235532820224762

Epoch: 478| Step: 0
Training loss: 0.8658878207206726
Validation loss: 2.2004793882369995

Epoch: 6| Step: 1
Training loss: 1.0699113607406616
Validation loss: 2.1579476992289224

Epoch: 6| Step: 2
Training loss: 0.48345354199409485
Validation loss: 2.1710426012674966

Epoch: 6| Step: 3
Training loss: 0.28492164611816406
Validation loss: 2.17597887913386

Epoch: 6| Step: 4
Training loss: 0.6358820199966431
Validation loss: 2.16454287370046

Epoch: 6| Step: 5
Training loss: 0.37744343280792236
Validation loss: 2.149900436401367

Epoch: 6| Step: 6
Training loss: 0.5919334292411804
Validation loss: 2.1202800075213113

Epoch: 6| Step: 7
Training loss: 0.4231337606906891
Validation loss: 2.0942178765932717

Epoch: 6| Step: 8
Training loss: 0.4063507914543152
Validation loss: 2.1413095792134604

Epoch: 6| Step: 9
Training loss: 0.5261624455451965
Validation loss: 2.079521059989929

Epoch: 6| Step: 10
Training loss: 0.3423038721084595
Validation loss: 2.12193896373113

Epoch: 6| Step: 11
Training loss: 0.6019702553749084
Validation loss: 2.128129700819651

Epoch: 6| Step: 12
Training loss: 0.4989946782588959
Validation loss: 2.1080299615859985

Epoch: 6| Step: 13
Training loss: 1.0279784202575684
Validation loss: 2.1101134220759072

Epoch: 479| Step: 0
Training loss: 0.6119980812072754
Validation loss: 2.1574589014053345

Epoch: 6| Step: 1
Training loss: 0.45920467376708984
Validation loss: 2.146913985411326

Epoch: 6| Step: 2
Training loss: 0.5096206665039062
Validation loss: 2.11045773824056

Epoch: 6| Step: 3
Training loss: 0.25067538022994995
Validation loss: 2.146375834941864

Epoch: 6| Step: 4
Training loss: 0.5472434163093567
Validation loss: 2.139013489087423

Epoch: 6| Step: 5
Training loss: 0.3899639844894409
Validation loss: 2.081152002016703

Epoch: 6| Step: 6
Training loss: 0.6462494134902954
Validation loss: 2.0937852462132773

Epoch: 6| Step: 7
Training loss: 0.7305657267570496
Validation loss: 2.054575741291046

Epoch: 6| Step: 8
Training loss: 0.9221771955490112
Validation loss: 2.104967633883158

Epoch: 6| Step: 9
Training loss: 0.692832887172699
Validation loss: 2.134934584299723

Epoch: 6| Step: 10
Training loss: 0.4936940670013428
Validation loss: 2.1387306849161782

Epoch: 6| Step: 11
Training loss: 0.20602098107337952
Validation loss: 2.1253045201301575

Epoch: 6| Step: 12
Training loss: 0.47245776653289795
Validation loss: 2.118587553501129

Epoch: 6| Step: 13
Training loss: 0.5846011638641357
Validation loss: 2.126116474469503

Epoch: 480| Step: 0
Training loss: 1.0552005767822266
Validation loss: 2.129933496316274

Epoch: 6| Step: 1
Training loss: 0.9049541354179382
Validation loss: 2.103872994581858

Epoch: 6| Step: 2
Training loss: 0.44124817848205566
Validation loss: 2.1114811301231384

Epoch: 6| Step: 3
Training loss: 0.3712543249130249
Validation loss: 2.101531128088633

Epoch: 6| Step: 4
Training loss: 0.4661219120025635
Validation loss: 2.1424195567766824

Epoch: 6| Step: 5
Training loss: 0.7854435443878174
Validation loss: 2.146854301293691

Epoch: 6| Step: 6
Training loss: 0.5680181384086609
Validation loss: 2.1448674400647483

Epoch: 6| Step: 7
Training loss: 0.5441392064094543
Validation loss: 2.1142369310061135

Epoch: 6| Step: 8
Training loss: 0.7222737669944763
Validation loss: 2.1529290080070496

Epoch: 6| Step: 9
Training loss: 0.2236103117465973
Validation loss: 2.145230253537496

Epoch: 6| Step: 10
Training loss: 0.41221508383750916
Validation loss: 2.101404309272766

Epoch: 6| Step: 11
Training loss: 0.36726677417755127
Validation loss: 2.136756956577301

Epoch: 6| Step: 12
Training loss: 0.21232761442661285
Validation loss: 2.167275627454122

Epoch: 6| Step: 13
Training loss: 0.5461103320121765
Validation loss: 2.135260303815206

Epoch: 481| Step: 0
Training loss: 0.6495493650436401
Validation loss: 2.201254347960154

Epoch: 6| Step: 1
Training loss: 0.4389382004737854
Validation loss: 2.1551367243131003

Epoch: 6| Step: 2
Training loss: 0.43829163908958435
Validation loss: 2.1300426721572876

Epoch: 6| Step: 3
Training loss: 0.3282964527606964
Validation loss: 2.0883681972821555

Epoch: 6| Step: 4
Training loss: 0.5789715051651001
Validation loss: 2.128911296526591

Epoch: 6| Step: 5
Training loss: 0.38366466760635376
Validation loss: 2.1116872429847717

Epoch: 6| Step: 6
Training loss: 0.5118857026100159
Validation loss: 2.10865048567454

Epoch: 6| Step: 7
Training loss: 0.37490949034690857
Validation loss: 2.059282581011454

Epoch: 6| Step: 8
Training loss: 0.6024324297904968
Validation loss: 2.1214338541030884

Epoch: 6| Step: 9
Training loss: 0.9921997785568237
Validation loss: 2.0457841555277505

Epoch: 6| Step: 10
Training loss: 0.8017790913581848
Validation loss: 2.0711008509000144

Epoch: 6| Step: 11
Training loss: 0.47438570857048035
Validation loss: 2.075458268324534

Epoch: 6| Step: 12
Training loss: 0.6523151397705078
Validation loss: 2.1011149088541665

Epoch: 6| Step: 13
Training loss: 0.7078441381454468
Validation loss: 2.105001151561737

Epoch: 482| Step: 0
Training loss: 0.5163904428482056
Validation loss: 2.1064173181851706

Epoch: 6| Step: 1
Training loss: 0.2752637565135956
Validation loss: 2.1722320119539895

Epoch: 6| Step: 2
Training loss: 0.8323827981948853
Validation loss: 2.121255874633789

Epoch: 6| Step: 3
Training loss: 0.41434982419013977
Validation loss: 2.148789564768473

Epoch: 6| Step: 4
Training loss: 0.4356035888195038
Validation loss: 2.127467314402262

Epoch: 6| Step: 5
Training loss: 1.1887459754943848
Validation loss: 2.0838253498077393

Epoch: 6| Step: 6
Training loss: 0.4993951618671417
Validation loss: 2.1009966333707175

Epoch: 6| Step: 7
Training loss: 0.2947722375392914
Validation loss: 2.1332147121429443

Epoch: 6| Step: 8
Training loss: 0.976392924785614
Validation loss: 2.167867581049601

Epoch: 6| Step: 9
Training loss: 0.31476205587387085
Validation loss: 2.0880971352259317

Epoch: 6| Step: 10
Training loss: 0.5218455791473389
Validation loss: 2.1713576316833496

Epoch: 6| Step: 11
Training loss: 0.41450801491737366
Validation loss: 2.115506966908773

Epoch: 6| Step: 12
Training loss: 0.6805288791656494
Validation loss: 2.1004883448282876

Epoch: 6| Step: 13
Training loss: 0.5681514739990234
Validation loss: 2.1232974330584207

Epoch: 483| Step: 0
Training loss: 0.25992417335510254
Validation loss: 2.1029653350512185

Epoch: 6| Step: 1
Training loss: 0.24805928766727448
Validation loss: 2.10607373714447

Epoch: 6| Step: 2
Training loss: 0.44720467925071716
Validation loss: 2.1298633813858032

Epoch: 6| Step: 3
Training loss: 0.5411272644996643
Validation loss: 2.1340450445810952

Epoch: 6| Step: 4
Training loss: 0.501413881778717
Validation loss: 2.0982921520868936

Epoch: 6| Step: 5
Training loss: 0.2637398838996887
Validation loss: 2.1043448448181152

Epoch: 6| Step: 6
Training loss: 0.3422505855560303
Validation loss: 2.1177708307902017

Epoch: 6| Step: 7
Training loss: 0.6888819932937622
Validation loss: 2.150051752726237

Epoch: 6| Step: 8
Training loss: 0.6762382984161377
Validation loss: 2.0892931620279946

Epoch: 6| Step: 9
Training loss: 0.2889935374259949
Validation loss: 2.1244940757751465

Epoch: 6| Step: 10
Training loss: 0.7170282602310181
Validation loss: 2.171532412370046

Epoch: 6| Step: 11
Training loss: 1.0483976602554321
Validation loss: 2.1492977341016135

Epoch: 6| Step: 12
Training loss: 0.7632296085357666
Validation loss: 2.16455469528834

Epoch: 6| Step: 13
Training loss: 0.6677210330963135
Validation loss: 2.207939108212789

Epoch: 484| Step: 0
Training loss: 0.370769202709198
Validation loss: 2.2104076147079468

Epoch: 6| Step: 1
Training loss: 0.1974218785762787
Validation loss: 2.17077108224233

Epoch: 6| Step: 2
Training loss: 0.4321218729019165
Validation loss: 2.102271536986033

Epoch: 6| Step: 3
Training loss: 0.47177135944366455
Validation loss: 2.14810448884964

Epoch: 6| Step: 4
Training loss: 0.6728847026824951
Validation loss: 2.166217307249705

Epoch: 6| Step: 5
Training loss: 0.6153539419174194
Validation loss: 2.095263739426931

Epoch: 6| Step: 6
Training loss: 0.6985257863998413
Validation loss: 2.1043740113576255

Epoch: 6| Step: 7
Training loss: 0.5118327140808105
Validation loss: 2.1223866939544678

Epoch: 6| Step: 8
Training loss: 0.41464024782180786
Validation loss: 2.172126074632009

Epoch: 6| Step: 9
Training loss: 0.3714127540588379
Validation loss: 2.1966592272122702

Epoch: 6| Step: 10
Training loss: 0.7259731292724609
Validation loss: 2.19123109181722

Epoch: 6| Step: 11
Training loss: 0.4450203776359558
Validation loss: 2.180262009302775

Epoch: 6| Step: 12
Training loss: 1.2147804498672485
Validation loss: 2.127241094907125

Epoch: 6| Step: 13
Training loss: 0.3145858943462372
Validation loss: 2.2092373768488565

Epoch: 485| Step: 0
Training loss: 0.6804391145706177
Validation loss: 2.118764877319336

Epoch: 6| Step: 1
Training loss: 0.45229679346084595
Validation loss: 2.1458876927693686

Epoch: 6| Step: 2
Training loss: 0.6423367261886597
Validation loss: 2.1375071009000144

Epoch: 6| Step: 3
Training loss: 1.1004254817962646
Validation loss: 2.0669254263242087

Epoch: 6| Step: 4
Training loss: 0.588800847530365
Validation loss: 2.113870700200399

Epoch: 6| Step: 5
Training loss: 0.46097075939178467
Validation loss: 2.1094768047332764

Epoch: 6| Step: 6
Training loss: 0.4446699619293213
Validation loss: 2.0700430671374

Epoch: 6| Step: 7
Training loss: 0.5240415930747986
Validation loss: 2.1007264455159507

Epoch: 6| Step: 8
Training loss: 0.35980260372161865
Validation loss: 2.12948868672053

Epoch: 6| Step: 9
Training loss: 0.41258329153060913
Validation loss: 2.103746175765991

Epoch: 6| Step: 10
Training loss: 0.3876156508922577
Validation loss: 2.1277689337730408

Epoch: 6| Step: 11
Training loss: 0.21452009677886963
Validation loss: 2.163278023401896

Epoch: 6| Step: 12
Training loss: 0.39754295349121094
Validation loss: 2.204269607861837

Epoch: 6| Step: 13
Training loss: 0.8439880609512329
Validation loss: 2.1345404982566833

Epoch: 486| Step: 0
Training loss: 0.6351414322853088
Validation loss: 2.211520810921987

Epoch: 6| Step: 1
Training loss: 0.6506166458129883
Validation loss: 2.167443811893463

Epoch: 6| Step: 2
Training loss: 0.2415761798620224
Validation loss: 2.20755143960317

Epoch: 6| Step: 3
Training loss: 0.9228744506835938
Validation loss: 2.1219139893849692

Epoch: 6| Step: 4
Training loss: 0.42956042289733887
Validation loss: 2.1643864711125693

Epoch: 6| Step: 5
Training loss: 0.48535117506980896
Validation loss: 2.1810997327168784

Epoch: 6| Step: 6
Training loss: 0.873749315738678
Validation loss: 2.182864546775818

Epoch: 6| Step: 7
Training loss: 0.5269595384597778
Validation loss: 2.135463019212087

Epoch: 6| Step: 8
Training loss: 0.39929068088531494
Validation loss: 2.1642348766326904

Epoch: 6| Step: 9
Training loss: 0.2954447865486145
Validation loss: 2.137888809045156

Epoch: 6| Step: 10
Training loss: 0.3791285753250122
Validation loss: 2.081133464972178

Epoch: 6| Step: 11
Training loss: 0.766905665397644
Validation loss: 2.118019183476766

Epoch: 6| Step: 12
Training loss: 0.19961729645729065
Validation loss: 2.105421264966329

Epoch: 6| Step: 13
Training loss: 0.4838266968727112
Validation loss: 2.079788247744242

Epoch: 487| Step: 0
Training loss: 0.44980400800704956
Validation loss: 2.0489486853281655

Epoch: 6| Step: 1
Training loss: 0.4579266607761383
Validation loss: 2.121001104513804

Epoch: 6| Step: 2
Training loss: 0.8154802918434143
Validation loss: 2.0854164759318032

Epoch: 6| Step: 3
Training loss: 0.7535445690155029
Validation loss: 2.1294230620066323

Epoch: 6| Step: 4
Training loss: 0.6761019825935364
Validation loss: 2.1228242913881936

Epoch: 6| Step: 5
Training loss: 0.3586702048778534
Validation loss: 2.15846316019694

Epoch: 6| Step: 6
Training loss: 0.44670480489730835
Validation loss: 2.14406547943751

Epoch: 6| Step: 7
Training loss: 0.7750009298324585
Validation loss: 2.1685950756073

Epoch: 6| Step: 8
Training loss: 0.7540645003318787
Validation loss: 2.1508522431055703

Epoch: 6| Step: 9
Training loss: 0.2403828501701355
Validation loss: 2.135943571726481

Epoch: 6| Step: 10
Training loss: 0.3986583948135376
Validation loss: 2.1002588073412576

Epoch: 6| Step: 11
Training loss: 0.49996113777160645
Validation loss: 2.0854951540629068

Epoch: 6| Step: 12
Training loss: 0.35005271434783936
Validation loss: 2.119304060935974

Epoch: 6| Step: 13
Training loss: 0.2405920922756195
Validation loss: 2.1126707394917807

Epoch: 488| Step: 0
Training loss: 0.26308518648147583
Validation loss: 2.1587231159210205

Epoch: 6| Step: 1
Training loss: 0.8171331286430359
Validation loss: 2.1180314819018045

Epoch: 6| Step: 2
Training loss: 0.6654942035675049
Validation loss: 2.14710533618927

Epoch: 6| Step: 3
Training loss: 0.8569291234016418
Validation loss: 2.14223704735438

Epoch: 6| Step: 4
Training loss: 0.7830518484115601
Validation loss: 2.1563108364741006

Epoch: 6| Step: 5
Training loss: 0.2162868082523346
Validation loss: 2.1697086095809937

Epoch: 6| Step: 6
Training loss: 0.24804899096488953
Validation loss: 2.1647743582725525

Epoch: 6| Step: 7
Training loss: 0.6010738611221313
Validation loss: 2.13662459452947

Epoch: 6| Step: 8
Training loss: 0.450158953666687
Validation loss: 2.1554664174715676

Epoch: 6| Step: 9
Training loss: 0.3923807740211487
Validation loss: 2.12829053401947

Epoch: 6| Step: 10
Training loss: 0.4225834012031555
Validation loss: 2.0554551680882773

Epoch: 6| Step: 11
Training loss: 0.8631027936935425
Validation loss: 2.065215229988098

Epoch: 6| Step: 12
Training loss: 0.5361642837524414
Validation loss: 2.0787532130877175

Epoch: 6| Step: 13
Training loss: 0.46580666303634644
Validation loss: 2.110336403052012

Epoch: 489| Step: 0
Training loss: 0.6903380155563354
Validation loss: 2.119779646396637

Epoch: 6| Step: 1
Training loss: 0.5098400115966797
Validation loss: 2.099775771299998

Epoch: 6| Step: 2
Training loss: 0.651214063167572
Validation loss: 2.1326750914255777

Epoch: 6| Step: 3
Training loss: 0.432255357503891
Validation loss: 2.173871954282125

Epoch: 6| Step: 4
Training loss: 0.5511108636856079
Validation loss: 2.173107842604319

Epoch: 6| Step: 5
Training loss: 0.4423191547393799
Validation loss: 2.182757079601288

Epoch: 6| Step: 6
Training loss: 0.7715983390808105
Validation loss: 2.185024082660675

Epoch: 6| Step: 7
Training loss: 0.5299947261810303
Validation loss: 2.1870046854019165

Epoch: 6| Step: 8
Training loss: 0.3952513337135315
Validation loss: 2.2100860476493835

Epoch: 6| Step: 9
Training loss: 0.9510179162025452
Validation loss: 2.171491722265879

Epoch: 6| Step: 10
Training loss: 0.32892394065856934
Validation loss: 2.1211931705474854

Epoch: 6| Step: 11
Training loss: 0.3069279193878174
Validation loss: 2.1539157032966614

Epoch: 6| Step: 12
Training loss: 0.6355331540107727
Validation loss: 2.1372899214426675

Epoch: 6| Step: 13
Training loss: 0.5342245697975159
Validation loss: 2.1346965630849204

Epoch: 490| Step: 0
Training loss: 0.5143501162528992
Validation loss: 2.147531032562256

Epoch: 6| Step: 1
Training loss: 0.44181644916534424
Validation loss: 2.1694538593292236

Epoch: 6| Step: 2
Training loss: 0.7251870632171631
Validation loss: 2.103499392668406

Epoch: 6| Step: 3
Training loss: 0.8060561418533325
Validation loss: 2.1278273264567056

Epoch: 6| Step: 4
Training loss: 0.48268362879753113
Validation loss: 2.138514677683512

Epoch: 6| Step: 5
Training loss: 0.41401591897010803
Validation loss: 2.174041509628296

Epoch: 6| Step: 6
Training loss: 0.4918835163116455
Validation loss: 2.241181174914042

Epoch: 6| Step: 7
Training loss: 0.7222120761871338
Validation loss: 2.2026175061861673

Epoch: 6| Step: 8
Training loss: 0.6825432777404785
Validation loss: 2.1466228365898132

Epoch: 6| Step: 9
Training loss: 0.5178548097610474
Validation loss: 2.205308218797048

Epoch: 6| Step: 10
Training loss: 0.38849160075187683
Validation loss: 2.206562638282776

Epoch: 6| Step: 11
Training loss: 0.45541414618492126
Validation loss: 2.242958426475525

Epoch: 6| Step: 12
Training loss: 0.6355260014533997
Validation loss: 2.1754146615664163

Epoch: 6| Step: 13
Training loss: 1.0108931064605713
Validation loss: 2.230141282081604

Epoch: 491| Step: 0
Training loss: 0.7773035764694214
Validation loss: 2.198224723339081

Epoch: 6| Step: 1
Training loss: 0.41689184308052063
Validation loss: 2.225025216738383

Epoch: 6| Step: 2
Training loss: 1.0797590017318726
Validation loss: 2.2015424172083535

Epoch: 6| Step: 3
Training loss: 0.5868344306945801
Validation loss: 2.1524423360824585

Epoch: 6| Step: 4
Training loss: 0.46433785557746887
Validation loss: 2.2495954831441245

Epoch: 6| Step: 5
Training loss: 0.7294923067092896
Validation loss: 2.2927311658859253

Epoch: 6| Step: 6
Training loss: 0.601691484451294
Validation loss: 2.2959332863489785

Epoch: 6| Step: 7
Training loss: 0.7704978585243225
Validation loss: 2.259348233540853

Epoch: 6| Step: 8
Training loss: 0.621181845664978
Validation loss: 2.202789783477783

Epoch: 6| Step: 9
Training loss: 0.9272571802139282
Validation loss: 2.151118020216624

Epoch: 6| Step: 10
Training loss: 0.34918808937072754
Validation loss: 2.09198264280955

Epoch: 6| Step: 11
Training loss: 0.42905938625335693
Validation loss: 2.0826957623163858

Epoch: 6| Step: 12
Training loss: 0.7486952543258667
Validation loss: 2.086208919684092

Epoch: 6| Step: 13
Training loss: 0.4112483263015747
Validation loss: 2.0517292817433677

Epoch: 492| Step: 0
Training loss: 1.1634929180145264
Validation loss: 2.0591655373573303

Epoch: 6| Step: 1
Training loss: 0.6409292817115784
Validation loss: 2.061323424180349

Epoch: 6| Step: 2
Training loss: 0.5043410658836365
Validation loss: 2.107748885949453

Epoch: 6| Step: 3
Training loss: 0.6045432686805725
Validation loss: 2.0817893544832864

Epoch: 6| Step: 4
Training loss: 0.3670647144317627
Validation loss: 2.085695266723633

Epoch: 6| Step: 5
Training loss: 0.508207380771637
Validation loss: 2.1492091615994773

Epoch: 6| Step: 6
Training loss: 0.4951053857803345
Validation loss: 2.1172068119049072

Epoch: 6| Step: 7
Training loss: 0.6826961040496826
Validation loss: 2.1769195795059204

Epoch: 6| Step: 8
Training loss: 0.3178085684776306
Validation loss: 2.1370557149251304

Epoch: 6| Step: 9
Training loss: 0.5228973627090454
Validation loss: 2.1946229338645935

Epoch: 6| Step: 10
Training loss: 0.33477795124053955
Validation loss: 2.1453367273012796

Epoch: 6| Step: 11
Training loss: 0.32545900344848633
Validation loss: 2.14346045255661

Epoch: 6| Step: 12
Training loss: 1.063292145729065
Validation loss: 2.175925155480703

Epoch: 6| Step: 13
Training loss: 0.45129817724227905
Validation loss: 2.1746115485827127

Epoch: 493| Step: 0
Training loss: 0.28444260358810425
Validation loss: 2.12166166305542

Epoch: 6| Step: 1
Training loss: 0.6012239456176758
Validation loss: 2.082139869530996

Epoch: 6| Step: 2
Training loss: 1.002262830734253
Validation loss: 2.156903604666392

Epoch: 6| Step: 3
Training loss: 1.1052660942077637
Validation loss: 2.1601035594940186

Epoch: 6| Step: 4
Training loss: 0.37278634309768677
Validation loss: 2.125530203183492

Epoch: 6| Step: 5
Training loss: 0.33327800035476685
Validation loss: 2.1446566383043923

Epoch: 6| Step: 6
Training loss: 0.40127047896385193
Validation loss: 2.059158186117808

Epoch: 6| Step: 7
Training loss: 0.42933380603790283
Validation loss: 2.1062235236167908

Epoch: 6| Step: 8
Training loss: 0.4279516935348511
Validation loss: 2.092760701974233

Epoch: 6| Step: 9
Training loss: 0.5340757369995117
Validation loss: 2.090709110101064

Epoch: 6| Step: 10
Training loss: 0.33105820417404175
Validation loss: 2.0871463418006897

Epoch: 6| Step: 11
Training loss: 0.5655896663665771
Validation loss: 2.095439910888672

Epoch: 6| Step: 12
Training loss: 0.7437046766281128
Validation loss: 2.137687087059021

Epoch: 6| Step: 13
Training loss: 0.7447396516799927
Validation loss: 2.1317394574483237

Epoch: 494| Step: 0
Training loss: 0.35600975155830383
Validation loss: 2.1043978730837503

Epoch: 6| Step: 1
Training loss: 0.3886912763118744
Validation loss: 2.1304129163424173

Epoch: 6| Step: 2
Training loss: 0.40688031911849976
Validation loss: 2.086055636405945

Epoch: 6| Step: 3
Training loss: 0.1992490589618683
Validation loss: 2.1420077681541443

Epoch: 6| Step: 4
Training loss: 0.8586614727973938
Validation loss: 2.0700153907140098

Epoch: 6| Step: 5
Training loss: 0.24982689321041107
Validation loss: 2.111461818218231

Epoch: 6| Step: 6
Training loss: 0.19335630536079407
Validation loss: 2.1226986845334372

Epoch: 6| Step: 7
Training loss: 0.4199262261390686
Validation loss: 2.071115950743357

Epoch: 6| Step: 8
Training loss: 0.34768131375312805
Validation loss: 2.1284188628196716

Epoch: 6| Step: 9
Training loss: 0.49249327182769775
Validation loss: 2.1047699252764382

Epoch: 6| Step: 10
Training loss: 0.9527477622032166
Validation loss: 2.107944389184316

Epoch: 6| Step: 11
Training loss: 0.5015904903411865
Validation loss: 2.192460298538208

Epoch: 6| Step: 12
Training loss: 0.7482973337173462
Validation loss: 2.1600419680277505

Epoch: 6| Step: 13
Training loss: 1.189155101776123
Validation loss: 2.1900492310523987

Epoch: 495| Step: 0
Training loss: 0.38810449838638306
Validation loss: 2.1137492458025613

Epoch: 6| Step: 1
Training loss: 0.7723857164382935
Validation loss: 2.157358984152476

Epoch: 6| Step: 2
Training loss: 0.5145986080169678
Validation loss: 2.1468304991722107

Epoch: 6| Step: 3
Training loss: 0.7656612992286682
Validation loss: 2.1085312962532043

Epoch: 6| Step: 4
Training loss: 0.30389630794525146
Validation loss: 2.1682874957720437

Epoch: 6| Step: 5
Training loss: 0.2567572593688965
Validation loss: 2.1252206365267434

Epoch: 6| Step: 6
Training loss: 0.5909091234207153
Validation loss: 2.0663569370905557

Epoch: 6| Step: 7
Training loss: 0.5248070955276489
Validation loss: 2.1534778078397117

Epoch: 6| Step: 8
Training loss: 0.4003533124923706
Validation loss: 2.1059353748957315

Epoch: 6| Step: 9
Training loss: 0.44076818227767944
Validation loss: 2.1646142999331155

Epoch: 6| Step: 10
Training loss: 0.781792402267456
Validation loss: 2.1294657588005066

Epoch: 6| Step: 11
Training loss: 0.4500219225883484
Validation loss: 2.137489895025889

Epoch: 6| Step: 12
Training loss: 0.7202325463294983
Validation loss: 2.1566235621770224

Epoch: 6| Step: 13
Training loss: 0.8108524084091187
Validation loss: 2.217217286427816

Epoch: 496| Step: 0
Training loss: 0.5315200090408325
Validation loss: 2.1581602891286216

Epoch: 6| Step: 1
Training loss: 0.3009215295314789
Validation loss: 2.094519098599752

Epoch: 6| Step: 2
Training loss: 0.19627657532691956
Validation loss: 2.138718088467916

Epoch: 6| Step: 3
Training loss: 0.5355052947998047
Validation loss: 2.073200821876526

Epoch: 6| Step: 4
Training loss: 0.30430877208709717
Validation loss: 2.107846120993296

Epoch: 6| Step: 5
Training loss: 0.26745206117630005
Validation loss: 2.126063326994578

Epoch: 6| Step: 6
Training loss: 0.3735138773918152
Validation loss: 2.1474267840385437

Epoch: 6| Step: 7
Training loss: 0.4987105131149292
Validation loss: 2.174966116746267

Epoch: 6| Step: 8
Training loss: 0.6132897138595581
Validation loss: 2.1376972595850625

Epoch: 6| Step: 9
Training loss: 0.9812427759170532
Validation loss: 2.183433016141256

Epoch: 6| Step: 10
Training loss: 0.5529844164848328
Validation loss: 2.1002111236254373

Epoch: 6| Step: 11
Training loss: 1.0329276323318481
Validation loss: 2.1387962102890015

Epoch: 6| Step: 12
Training loss: 0.34317153692245483
Validation loss: 2.1195863684018454

Epoch: 6| Step: 13
Training loss: 0.3826538622379303
Validation loss: 2.1670024196306863

Epoch: 497| Step: 0
Training loss: 0.3595135807991028
Validation loss: 2.139479617277781

Epoch: 6| Step: 1
Training loss: 0.34755825996398926
Validation loss: 2.1218958099683127

Epoch: 6| Step: 2
Training loss: 0.9718878269195557
Validation loss: 2.099940836429596

Epoch: 6| Step: 3
Training loss: 0.6549081802368164
Validation loss: 2.1620463927586875

Epoch: 6| Step: 4
Training loss: 0.29796573519706726
Validation loss: 2.1295576691627502

Epoch: 6| Step: 5
Training loss: 0.298170268535614
Validation loss: 2.0843798319498696

Epoch: 6| Step: 6
Training loss: 0.48147574067115784
Validation loss: 2.103903671105703

Epoch: 6| Step: 7
Training loss: 0.40907296538352966
Validation loss: 2.1244739492734275

Epoch: 6| Step: 8
Training loss: 0.5115756988525391
Validation loss: 2.0999827782313027

Epoch: 6| Step: 9
Training loss: 0.4268925189971924
Validation loss: 2.0999064644177756

Epoch: 6| Step: 10
Training loss: 0.6227469444274902
Validation loss: 2.139410416285197

Epoch: 6| Step: 11
Training loss: 0.6995986700057983
Validation loss: 2.1110965609550476

Epoch: 6| Step: 12
Training loss: 0.3570682406425476
Validation loss: 2.1560488740603128

Epoch: 6| Step: 13
Training loss: 0.4653693735599518
Validation loss: 2.077116231123606

Epoch: 498| Step: 0
Training loss: 0.303619384765625
Validation loss: 2.121304372946421

Epoch: 6| Step: 1
Training loss: 0.627613365650177
Validation loss: 2.1396849354108176

Epoch: 6| Step: 2
Training loss: 0.4540964961051941
Validation loss: 2.148261845111847

Epoch: 6| Step: 3
Training loss: 0.28485336899757385
Validation loss: 2.12975945075353

Epoch: 6| Step: 4
Training loss: 0.629363477230072
Validation loss: 2.1484959721565247

Epoch: 6| Step: 5
Training loss: 0.426922082901001
Validation loss: 2.1419083873430886

Epoch: 6| Step: 6
Training loss: 0.6550316214561462
Validation loss: 2.155082861582438

Epoch: 6| Step: 7
Training loss: 0.379597008228302
Validation loss: 2.126056512196859

Epoch: 6| Step: 8
Training loss: 0.706451952457428
Validation loss: 2.154581387837728

Epoch: 6| Step: 9
Training loss: 0.696744441986084
Validation loss: 2.14591391881307

Epoch: 6| Step: 10
Training loss: 0.46978485584259033
Validation loss: 2.157615145047506

Epoch: 6| Step: 11
Training loss: 0.36949634552001953
Validation loss: 2.090250094731649

Epoch: 6| Step: 12
Training loss: 0.3970922827720642
Validation loss: 2.1221436262130737

Epoch: 6| Step: 13
Training loss: 0.596732497215271
Validation loss: 2.1099751393000283

Epoch: 499| Step: 0
Training loss: 0.7139816284179688
Validation loss: 2.148238400618235

Epoch: 6| Step: 1
Training loss: 1.02780282497406
Validation loss: 2.1019067962964377

Epoch: 6| Step: 2
Training loss: 0.3283028304576874
Validation loss: 2.135566830635071

Epoch: 6| Step: 3
Training loss: 0.6240708231925964
Validation loss: 2.13027552763621

Epoch: 6| Step: 4
Training loss: 0.3386995494365692
Validation loss: 2.124233861764272

Epoch: 6| Step: 5
Training loss: 0.3672780990600586
Validation loss: 2.124682386716207

Epoch: 6| Step: 6
Training loss: 0.29490047693252563
Validation loss: 2.122311453024546

Epoch: 6| Step: 7
Training loss: 0.4123512804508209
Validation loss: 2.1335125962893167

Epoch: 6| Step: 8
Training loss: 0.8675128221511841
Validation loss: 2.1272643407185874

Epoch: 6| Step: 9
Training loss: 0.591482400894165
Validation loss: 2.06659342845281

Epoch: 6| Step: 10
Training loss: 0.42744767665863037
Validation loss: 2.146578073501587

Epoch: 6| Step: 11
Training loss: 0.47399842739105225
Validation loss: 2.099973678588867

Epoch: 6| Step: 12
Training loss: 0.3187120854854584
Validation loss: 2.1108452677726746

Epoch: 6| Step: 13
Training loss: 0.7703216075897217
Validation loss: 2.1337280670801797

Epoch: 500| Step: 0
Training loss: 0.3901509642601013
Validation loss: 2.1407590508461

Epoch: 6| Step: 1
Training loss: 0.6656928062438965
Validation loss: 2.14491601785024

Epoch: 6| Step: 2
Training loss: 0.6108797192573547
Validation loss: 2.1299055417378745

Epoch: 6| Step: 3
Training loss: 0.7130340337753296
Validation loss: 2.1309240460395813

Epoch: 6| Step: 4
Training loss: 0.47811248898506165
Validation loss: 2.178729514280955

Epoch: 6| Step: 5
Training loss: 0.8658721446990967
Validation loss: 2.0877744952837625

Epoch: 6| Step: 6
Training loss: 0.3697364926338196
Validation loss: 2.1318472226460776

Epoch: 6| Step: 7
Training loss: 0.24182145297527313
Validation loss: 2.1171752214431763

Epoch: 6| Step: 8
Training loss: 0.4472895860671997
Validation loss: 2.0840744574864707

Epoch: 6| Step: 9
Training loss: 0.5459940433502197
Validation loss: 2.1050208806991577

Epoch: 6| Step: 10
Training loss: 0.3963022828102112
Validation loss: 2.0919954776763916

Epoch: 6| Step: 11
Training loss: 0.6763575673103333
Validation loss: 2.1066622535387673

Epoch: 6| Step: 12
Training loss: 0.5053733587265015
Validation loss: 2.0849995613098145

Epoch: 6| Step: 13
Training loss: 0.42153728008270264
Validation loss: 2.1171674728393555

Testing loss: 1.7929797549899533
