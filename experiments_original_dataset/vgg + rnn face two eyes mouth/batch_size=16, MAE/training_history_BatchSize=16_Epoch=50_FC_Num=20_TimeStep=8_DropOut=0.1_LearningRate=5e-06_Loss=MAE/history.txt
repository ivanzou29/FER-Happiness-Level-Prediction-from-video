Epoch: 1| Step: 0
Training loss: 6.107720375061035
Validation loss: 5.4126096566518145

Epoch: 6| Step: 1
Training loss: 5.248955726623535
Validation loss: 5.410164753595988

Epoch: 6| Step: 2
Training loss: 5.652885437011719
Validation loss: 5.407941102981567

Epoch: 6| Step: 3
Training loss: 5.1130828857421875
Validation loss: 5.405876159667969

Epoch: 6| Step: 4
Training loss: 5.980574607849121
Validation loss: 5.403788089752197

Epoch: 6| Step: 5
Training loss: 4.101729393005371
Validation loss: 5.401714324951172

Epoch: 6| Step: 6
Training loss: 5.295385360717773
Validation loss: 5.39968466758728

Epoch: 6| Step: 7
Training loss: 5.704123497009277
Validation loss: 5.397681673367818

Epoch: 6| Step: 8
Training loss: 6.477520942687988
Validation loss: 5.395628611246745

Epoch: 6| Step: 9
Training loss: 5.869750022888184
Validation loss: 5.393599112828572

Epoch: 6| Step: 10
Training loss: 5.552691459655762
Validation loss: 5.391507625579834

Epoch: 6| Step: 11
Training loss: 5.358827590942383
Validation loss: 5.389267206192017

Epoch: 6| Step: 12
Training loss: 4.6155619621276855
Validation loss: 5.386981248855591

Epoch: 6| Step: 13
Training loss: 5.4682416915893555
Validation loss: 5.384588400522868

Epoch: 2| Step: 0
Training loss: 4.72706413269043
Validation loss: 5.382238229115804

Epoch: 6| Step: 1
Training loss: 5.665024757385254
Validation loss: 5.379771868387858

Epoch: 6| Step: 2
Training loss: 4.761350154876709
Validation loss: 5.377089182535808

Epoch: 6| Step: 3
Training loss: 6.258949279785156
Validation loss: 5.374427477518718

Epoch: 6| Step: 4
Training loss: 5.348550796508789
Validation loss: 5.37168554464976

Epoch: 6| Step: 5
Training loss: 5.101602554321289
Validation loss: 5.368720531463623

Epoch: 6| Step: 6
Training loss: 4.663164138793945
Validation loss: 5.365534623463948

Epoch: 6| Step: 7
Training loss: 5.050322532653809
Validation loss: 5.362440665562947

Epoch: 6| Step: 8
Training loss: 6.002353191375732
Validation loss: 5.359040021896362

Epoch: 6| Step: 9
Training loss: 4.729452133178711
Validation loss: 5.355480432510376

Epoch: 6| Step: 10
Training loss: 5.9506120681762695
Validation loss: 5.3517082532246905

Epoch: 6| Step: 11
Training loss: 6.151729583740234
Validation loss: 5.347804466883342

Epoch: 6| Step: 12
Training loss: 5.2653608322143555
Validation loss: 5.343783696492513

Epoch: 6| Step: 13
Training loss: 6.365367412567139
Validation loss: 5.3394850095113116

Epoch: 3| Step: 0
Training loss: 5.602231025695801
Validation loss: 5.335139830907186

Epoch: 6| Step: 1
Training loss: 5.140377044677734
Validation loss: 5.330430269241333

Epoch: 6| Step: 2
Training loss: 6.055215835571289
Validation loss: 5.32571800549825

Epoch: 6| Step: 3
Training loss: 4.8013834953308105
Validation loss: 5.320528268814087

Epoch: 6| Step: 4
Training loss: 4.604870796203613
Validation loss: 5.315257271130879

Epoch: 6| Step: 5
Training loss: 4.181092262268066
Validation loss: 5.3097920417785645

Epoch: 6| Step: 6
Training loss: 6.23638916015625
Validation loss: 5.304326136906941

Epoch: 6| Step: 7
Training loss: 5.495101451873779
Validation loss: 5.298311312993367

Epoch: 6| Step: 8
Training loss: 5.812014579772949
Validation loss: 5.292300780614217

Epoch: 6| Step: 9
Training loss: 4.865596771240234
Validation loss: 5.285894870758057

Epoch: 6| Step: 10
Training loss: 5.861919403076172
Validation loss: 5.279228210449219

Epoch: 6| Step: 11
Training loss: 5.209417343139648
Validation loss: 5.272525231043498

Epoch: 6| Step: 12
Training loss: 6.229731559753418
Validation loss: 5.265625715255737

Epoch: 6| Step: 13
Training loss: 5.066963195800781
Validation loss: 5.258285363515218

Epoch: 4| Step: 0
Training loss: 4.802549362182617
Validation loss: 5.250663320223491

Epoch: 6| Step: 1
Training loss: 5.800841331481934
Validation loss: 5.242780764897664

Epoch: 6| Step: 2
Training loss: 5.066129684448242
Validation loss: 5.234637101491292

Epoch: 6| Step: 3
Training loss: 5.044595718383789
Validation loss: 5.226309219996135

Epoch: 6| Step: 4
Training loss: 5.528133392333984
Validation loss: 5.2177049318949384

Epoch: 6| Step: 5
Training loss: 5.388260364532471
Validation loss: 5.208791573842366

Epoch: 6| Step: 6
Training loss: 5.073990821838379
Validation loss: 5.199188947677612

Epoch: 6| Step: 7
Training loss: 4.899389743804932
Validation loss: 5.189689636230469

Epoch: 6| Step: 8
Training loss: 5.1473708152771
Validation loss: 5.179647763570149

Epoch: 6| Step: 9
Training loss: 5.2141313552856445
Validation loss: 5.169575929641724

Epoch: 6| Step: 10
Training loss: 4.697735786437988
Validation loss: 5.1591001351674395

Epoch: 6| Step: 11
Training loss: 4.951432228088379
Validation loss: 5.1484958330790205

Epoch: 6| Step: 12
Training loss: 5.73666524887085
Validation loss: 5.137715816497803

Epoch: 6| Step: 13
Training loss: 6.346759796142578
Validation loss: 5.126675685246785

Epoch: 5| Step: 0
Training loss: 5.3451948165893555
Validation loss: 5.115336656570435

Epoch: 6| Step: 1
Training loss: 5.2687530517578125
Validation loss: 5.104294220606486

Epoch: 6| Step: 2
Training loss: 5.689016819000244
Validation loss: 5.092672109603882

Epoch: 6| Step: 3
Training loss: 4.530961990356445
Validation loss: 5.081458409627278

Epoch: 6| Step: 4
Training loss: 4.88315486907959
Validation loss: 5.0701524416605634

Epoch: 6| Step: 5
Training loss: 5.477890968322754
Validation loss: 5.058507363001506

Epoch: 6| Step: 6
Training loss: 5.392332077026367
Validation loss: 5.047127723693848

Epoch: 6| Step: 7
Training loss: 6.285991668701172
Validation loss: 5.035618861516316

Epoch: 6| Step: 8
Training loss: 4.664952754974365
Validation loss: 5.024640321731567

Epoch: 6| Step: 9
Training loss: 5.086843967437744
Validation loss: 5.013618389765422

Epoch: 6| Step: 10
Training loss: 4.3392558097839355
Validation loss: 5.002371072769165

Epoch: 6| Step: 11
Training loss: 5.211531639099121
Validation loss: 4.991293271382649

Epoch: 6| Step: 12
Training loss: 4.588054656982422
Validation loss: 4.980562210083008

Epoch: 6| Step: 13
Training loss: 4.941363334655762
Validation loss: 4.970110575358073

Epoch: 6| Step: 0
Training loss: 4.529227256774902
Validation loss: 4.95952582359314

Epoch: 6| Step: 1
Training loss: 6.030235290527344
Validation loss: 4.949068546295166

Epoch: 6| Step: 2
Training loss: 4.131299018859863
Validation loss: 4.939252773920695

Epoch: 6| Step: 3
Training loss: 4.421026229858398
Validation loss: 4.928814649581909

Epoch: 6| Step: 4
Training loss: 5.558801651000977
Validation loss: 4.918816129366557

Epoch: 6| Step: 5
Training loss: 4.782149314880371
Validation loss: 4.90936541557312

Epoch: 6| Step: 6
Training loss: 5.007810592651367
Validation loss: 4.900197426478068

Epoch: 6| Step: 7
Training loss: 4.708671569824219
Validation loss: 4.890691041946411

Epoch: 6| Step: 8
Training loss: 4.658172130584717
Validation loss: 4.881988883018494

Epoch: 6| Step: 9
Training loss: 5.522433757781982
Validation loss: 4.873028596242269

Epoch: 6| Step: 10
Training loss: 5.284049987792969
Validation loss: 4.86435063680013

Epoch: 6| Step: 11
Training loss: 4.754940032958984
Validation loss: 4.856300592422485

Epoch: 6| Step: 12
Training loss: 6.100403308868408
Validation loss: 4.848016579945882

Epoch: 6| Step: 13
Training loss: 4.2674560546875
Validation loss: 4.840102831522624

Epoch: 7| Step: 0
Training loss: 5.042961120605469
Validation loss: 4.832234462102254

Epoch: 6| Step: 1
Training loss: 4.764013767242432
Validation loss: 4.824361324310303

Epoch: 6| Step: 2
Training loss: 5.535187721252441
Validation loss: 4.817212104797363

Epoch: 6| Step: 3
Training loss: 4.598271369934082
Validation loss: 4.809809605280559

Epoch: 6| Step: 4
Training loss: 4.65742301940918
Validation loss: 4.803201675415039

Epoch: 6| Step: 5
Training loss: 4.5064520835876465
Validation loss: 4.796499967575073

Epoch: 6| Step: 6
Training loss: 5.1441192626953125
Validation loss: 4.7898573478062945

Epoch: 6| Step: 7
Training loss: 5.446037769317627
Validation loss: 4.78361161549886

Epoch: 6| Step: 8
Training loss: 3.9956698417663574
Validation loss: 4.777387936909993

Epoch: 6| Step: 9
Training loss: 3.815934658050537
Validation loss: 4.771136522293091

Epoch: 6| Step: 10
Training loss: 5.472136497497559
Validation loss: 4.764533758163452

Epoch: 6| Step: 11
Training loss: 5.0829949378967285
Validation loss: 4.758462866147359

Epoch: 6| Step: 12
Training loss: 5.82276725769043
Validation loss: 4.7522047360738116

Epoch: 6| Step: 13
Training loss: 4.3957743644714355
Validation loss: 4.745815277099609

Epoch: 8| Step: 0
Training loss: 4.310876846313477
Validation loss: 4.739382028579712

Epoch: 6| Step: 1
Training loss: 4.623178482055664
Validation loss: 4.73280652364095

Epoch: 6| Step: 2
Training loss: 5.315377235412598
Validation loss: 4.7267231941223145

Epoch: 6| Step: 3
Training loss: 4.503545761108398
Validation loss: 4.720190604527791

Epoch: 6| Step: 4
Training loss: 4.627479076385498
Validation loss: 4.713780482610066

Epoch: 6| Step: 5
Training loss: 5.2158660888671875
Validation loss: 4.707968552907308

Epoch: 6| Step: 6
Training loss: 4.515439033508301
Validation loss: 4.701701800028483

Epoch: 6| Step: 7
Training loss: 5.723276138305664
Validation loss: 4.6958785851796465

Epoch: 6| Step: 8
Training loss: 5.360854148864746
Validation loss: 4.689621925354004

Epoch: 6| Step: 9
Training loss: 4.933001518249512
Validation loss: 4.683667341868083

Epoch: 6| Step: 10
Training loss: 3.3849854469299316
Validation loss: 4.677518844604492

Epoch: 6| Step: 11
Training loss: 6.307489395141602
Validation loss: 4.6722657680511475

Epoch: 6| Step: 12
Training loss: 4.293672561645508
Validation loss: 4.666333834330241

Epoch: 6| Step: 13
Training loss: 4.012803077697754
Validation loss: 4.660866101582845

Epoch: 9| Step: 0
Training loss: 4.809865951538086
Validation loss: 4.655696074167888

Epoch: 6| Step: 1
Training loss: 4.0797119140625
Validation loss: 4.649851242701213

Epoch: 6| Step: 2
Training loss: 4.953983306884766
Validation loss: 4.644569834073384

Epoch: 6| Step: 3
Training loss: 5.609504699707031
Validation loss: 4.638766209284465

Epoch: 6| Step: 4
Training loss: 4.361591815948486
Validation loss: 4.633267402648926

Epoch: 6| Step: 5
Training loss: 4.274589538574219
Validation loss: 4.6277873913447065

Epoch: 6| Step: 6
Training loss: 4.02216911315918
Validation loss: 4.621926228205363

Epoch: 6| Step: 7
Training loss: 5.610241889953613
Validation loss: 4.616655508677165

Epoch: 6| Step: 8
Training loss: 4.430927753448486
Validation loss: 4.6112602551778155

Epoch: 6| Step: 9
Training loss: 4.222448825836182
Validation loss: 4.605532884597778

Epoch: 6| Step: 10
Training loss: 4.353209495544434
Validation loss: 4.600189208984375

Epoch: 6| Step: 11
Training loss: 4.889281272888184
Validation loss: 4.594609022140503

Epoch: 6| Step: 12
Training loss: 5.159163475036621
Validation loss: 4.58922545115153

Epoch: 6| Step: 13
Training loss: 5.2835588455200195
Validation loss: 4.5838150183359785

Epoch: 10| Step: 0
Training loss: 4.231509208679199
Validation loss: 4.578025182088216

Epoch: 6| Step: 1
Training loss: 4.734749794006348
Validation loss: 4.57198437054952

Epoch: 6| Step: 2
Training loss: 3.394674062728882
Validation loss: 4.566552797953288

Epoch: 6| Step: 3
Training loss: 5.339378356933594
Validation loss: 4.560830275217692

Epoch: 6| Step: 4
Training loss: 4.852499961853027
Validation loss: 4.554609934488933

Epoch: 6| Step: 5
Training loss: 4.890652656555176
Validation loss: 4.548544088999431

Epoch: 6| Step: 6
Training loss: 5.335712432861328
Validation loss: 4.542249838511149

Epoch: 6| Step: 7
Training loss: 4.151339530944824
Validation loss: 4.536161184310913

Epoch: 6| Step: 8
Training loss: 4.8318562507629395
Validation loss: 4.530365586280823

Epoch: 6| Step: 9
Training loss: 4.759005069732666
Validation loss: 4.523893515268962

Epoch: 6| Step: 10
Training loss: 4.988661289215088
Validation loss: 4.518040259679158

Epoch: 6| Step: 11
Training loss: 3.9553070068359375
Validation loss: 4.511286377906799

Epoch: 6| Step: 12
Training loss: 5.072350025177002
Validation loss: 4.505703449249268

Epoch: 6| Step: 13
Training loss: 4.444941520690918
Validation loss: 4.499468763669332

Epoch: 11| Step: 0
Training loss: 5.223082542419434
Validation loss: 4.493473251660665

Epoch: 6| Step: 1
Training loss: 4.4282989501953125
Validation loss: 4.487638394037883

Epoch: 6| Step: 2
Training loss: 3.8793790340423584
Validation loss: 4.481766899426778

Epoch: 6| Step: 3
Training loss: 4.279998779296875
Validation loss: 4.476246913274129

Epoch: 6| Step: 4
Training loss: 3.7468996047973633
Validation loss: 4.469698786735535

Epoch: 6| Step: 5
Training loss: 4.573456764221191
Validation loss: 4.464824080467224

Epoch: 6| Step: 6
Training loss: 3.318544864654541
Validation loss: 4.459601600964864

Epoch: 6| Step: 7
Training loss: 5.071893692016602
Validation loss: 4.45297912756602

Epoch: 6| Step: 8
Training loss: 3.4880189895629883
Validation loss: 4.447619438171387

Epoch: 6| Step: 9
Training loss: 4.170185089111328
Validation loss: 4.442307472229004

Epoch: 6| Step: 10
Training loss: 6.41472053527832
Validation loss: 4.436964988708496

Epoch: 6| Step: 11
Training loss: 5.877091407775879
Validation loss: 4.43185289700826

Epoch: 6| Step: 12
Training loss: 4.523683547973633
Validation loss: 4.4256382783253985

Epoch: 6| Step: 13
Training loss: 4.9590535163879395
Validation loss: 4.4208212693532305

Epoch: 12| Step: 0
Training loss: 4.970988750457764
Validation loss: 4.415990988413493

Epoch: 6| Step: 1
Training loss: 5.027143478393555
Validation loss: 4.410639087359111

Epoch: 6| Step: 2
Training loss: 4.4092817306518555
Validation loss: 4.405719359715779

Epoch: 6| Step: 3
Training loss: 4.057894706726074
Validation loss: 4.401095310846965

Epoch: 6| Step: 4
Training loss: 3.850304365158081
Validation loss: 4.395953416824341

Epoch: 6| Step: 5
Training loss: 4.52903413772583
Validation loss: 4.3901801109313965

Epoch: 6| Step: 6
Training loss: 4.503083229064941
Validation loss: 4.3851708968480425

Epoch: 6| Step: 7
Training loss: 4.255170822143555
Validation loss: 4.380573511123657

Epoch: 6| Step: 8
Training loss: 5.012007713317871
Validation loss: 4.375758210817973

Epoch: 6| Step: 9
Training loss: 3.4695894718170166
Validation loss: 4.370827794075012

Epoch: 6| Step: 10
Training loss: 5.1692094802856445
Validation loss: 4.36565089225769

Epoch: 6| Step: 11
Training loss: 4.611867904663086
Validation loss: 4.360898017883301

Epoch: 6| Step: 12
Training loss: 4.442842483520508
Validation loss: 4.356021444002788

Epoch: 6| Step: 13
Training loss: 4.71774435043335
Validation loss: 4.351128617922465

Epoch: 13| Step: 0
Training loss: 4.114769458770752
Validation loss: 4.346055746078491

Epoch: 6| Step: 1
Training loss: 4.2295637130737305
Validation loss: 4.340684572855632

Epoch: 6| Step: 2
Training loss: 4.2314043045043945
Validation loss: 4.335556785265605

Epoch: 6| Step: 3
Training loss: 4.602677345275879
Validation loss: 4.331020673116048

Epoch: 6| Step: 4
Training loss: 3.5504260063171387
Validation loss: 4.3263734181722

Epoch: 6| Step: 5
Training loss: 5.283573150634766
Validation loss: 4.321340004603068

Epoch: 6| Step: 6
Training loss: 4.393244743347168
Validation loss: 4.316724340120952

Epoch: 6| Step: 7
Training loss: 4.394579887390137
Validation loss: 4.311731378237407

Epoch: 6| Step: 8
Training loss: 4.866525650024414
Validation loss: 4.306790987650554

Epoch: 6| Step: 9
Training loss: 3.419062376022339
Validation loss: 4.301601012547811

Epoch: 6| Step: 10
Training loss: 4.912932395935059
Validation loss: 4.297011733055115

Epoch: 6| Step: 11
Training loss: 5.003624439239502
Validation loss: 4.291684468587239

Epoch: 6| Step: 12
Training loss: 4.7994537353515625
Validation loss: 4.286773006121318

Epoch: 6| Step: 13
Training loss: 4.326385498046875
Validation loss: 4.28155533472697

Epoch: 14| Step: 0
Training loss: 3.512002468109131
Validation loss: 4.275699456532796

Epoch: 6| Step: 1
Training loss: 5.764101982116699
Validation loss: 4.2709066073099775

Epoch: 6| Step: 2
Training loss: 4.609432697296143
Validation loss: 4.266063292821248

Epoch: 6| Step: 3
Training loss: 4.029288291931152
Validation loss: 4.261458237965901

Epoch: 6| Step: 4
Training loss: 3.7767772674560547
Validation loss: 4.255493879318237

Epoch: 6| Step: 5
Training loss: 4.8852410316467285
Validation loss: 4.2501165469487505

Epoch: 6| Step: 6
Training loss: 5.091960430145264
Validation loss: 4.245643377304077

Epoch: 6| Step: 7
Training loss: 4.907039165496826
Validation loss: 4.23988135655721

Epoch: 6| Step: 8
Training loss: 4.669506072998047
Validation loss: 4.234292546908061

Epoch: 6| Step: 9
Training loss: 3.8649561405181885
Validation loss: 4.229283769925435

Epoch: 6| Step: 10
Training loss: 3.8098347187042236
Validation loss: 4.224605003992717

Epoch: 6| Step: 11
Training loss: 3.8660595417022705
Validation loss: 4.220161199569702

Epoch: 6| Step: 12
Training loss: 4.192905426025391
Validation loss: 4.215104818344116

Epoch: 6| Step: 13
Training loss: 4.236697196960449
Validation loss: 4.209522883097331

Epoch: 15| Step: 0
Training loss: 3.727175712585449
Validation loss: 4.203541874885559

Epoch: 6| Step: 1
Training loss: 4.23753547668457
Validation loss: 4.198671102523804

Epoch: 6| Step: 2
Training loss: 3.6516294479370117
Validation loss: 4.193647702534993

Epoch: 6| Step: 3
Training loss: 5.679654121398926
Validation loss: 4.189159274101257

Epoch: 6| Step: 4
Training loss: 4.696695327758789
Validation loss: 4.183680971463521

Epoch: 6| Step: 5
Training loss: 4.600103378295898
Validation loss: 4.177863518397014

Epoch: 6| Step: 6
Training loss: 4.693603515625
Validation loss: 4.172976652781169

Epoch: 6| Step: 7
Training loss: 4.425126075744629
Validation loss: 4.1681612730026245

Epoch: 6| Step: 8
Training loss: 5.215391635894775
Validation loss: 4.163125832875569

Epoch: 6| Step: 9
Training loss: 3.866384506225586
Validation loss: 4.157649596532186

Epoch: 6| Step: 10
Training loss: 3.3367562294006348
Validation loss: 4.153029282887776

Epoch: 6| Step: 11
Training loss: 4.800656318664551
Validation loss: 4.147764801979065

Epoch: 6| Step: 12
Training loss: 4.055421829223633
Validation loss: 4.142942229906718

Epoch: 6| Step: 13
Training loss: 3.3218371868133545
Validation loss: 4.137159506479899

Epoch: 16| Step: 0
Training loss: 3.9363136291503906
Validation loss: 4.133354187011719

Epoch: 6| Step: 1
Training loss: 3.645554304122925
Validation loss: 4.12928565343221

Epoch: 6| Step: 2
Training loss: 4.482993125915527
Validation loss: 4.123224496841431

Epoch: 6| Step: 3
Training loss: 4.7564897537231445
Validation loss: 4.118893146514893

Epoch: 6| Step: 4
Training loss: 4.966289520263672
Validation loss: 4.114670276641846

Epoch: 6| Step: 5
Training loss: 5.148612976074219
Validation loss: 4.110532641410828

Epoch: 6| Step: 6
Training loss: 3.2898783683776855
Validation loss: 4.104268789291382

Epoch: 6| Step: 7
Training loss: 4.891964912414551
Validation loss: 4.098895827929179

Epoch: 6| Step: 8
Training loss: 4.892580986022949
Validation loss: 4.093959053357442

Epoch: 6| Step: 9
Training loss: 4.167222023010254
Validation loss: 4.090004086494446

Epoch: 6| Step: 10
Training loss: 4.993074893951416
Validation loss: 4.083462675412496

Epoch: 6| Step: 11
Training loss: 2.4924540519714355
Validation loss: 4.078731020291646

Epoch: 6| Step: 12
Training loss: 4.501838684082031
Validation loss: 4.07324477036794

Epoch: 6| Step: 13
Training loss: 3.236846685409546
Validation loss: 4.068068861961365

Epoch: 17| Step: 0
Training loss: 4.548480987548828
Validation loss: 4.0631600220998125

Epoch: 6| Step: 1
Training loss: 4.711267948150635
Validation loss: 4.057607690493266

Epoch: 6| Step: 2
Training loss: 4.062505722045898
Validation loss: 4.052913546562195

Epoch: 6| Step: 3
Training loss: 3.8558692932128906
Validation loss: 4.048821409543355

Epoch: 6| Step: 4
Training loss: 4.1093339920043945
Validation loss: 4.0430218776067095

Epoch: 6| Step: 5
Training loss: 5.087158203125
Validation loss: 4.038342595100403

Epoch: 6| Step: 6
Training loss: 4.740658760070801
Validation loss: 4.033852259318034

Epoch: 6| Step: 7
Training loss: 3.6232333183288574
Validation loss: 4.028873006502788

Epoch: 6| Step: 8
Training loss: 2.5562210083007812
Validation loss: 4.026169379552205

Epoch: 6| Step: 9
Training loss: 3.941009998321533
Validation loss: 4.017240285873413

Epoch: 6| Step: 10
Training loss: 4.2351861000061035
Validation loss: 4.012052655220032

Epoch: 6| Step: 11
Training loss: 4.03015661239624
Validation loss: 4.007708668708801

Epoch: 6| Step: 12
Training loss: 4.366041660308838
Validation loss: 4.004157384236653

Epoch: 6| Step: 13
Training loss: 4.613630294799805
Validation loss: 4.0000860293706255

Epoch: 18| Step: 0
Training loss: 5.026175498962402
Validation loss: 3.994690418243408

Epoch: 6| Step: 1
Training loss: 3.9460806846618652
Validation loss: 3.988882581392924

Epoch: 6| Step: 2
Training loss: 4.082468032836914
Validation loss: 3.984485467274984

Epoch: 6| Step: 3
Training loss: 3.7282798290252686
Validation loss: 3.9789571364720664

Epoch: 6| Step: 4
Training loss: 4.455651760101318
Validation loss: 3.9738712708155313

Epoch: 6| Step: 5
Training loss: 4.296601295471191
Validation loss: 3.9717089335123696

Epoch: 6| Step: 6
Training loss: 4.496367454528809
Validation loss: 3.9647922913233438

Epoch: 6| Step: 7
Training loss: 3.9318366050720215
Validation loss: 3.9589715798695884

Epoch: 6| Step: 8
Training loss: 4.063203811645508
Validation loss: 3.95465616385142

Epoch: 6| Step: 9
Training loss: 4.269000053405762
Validation loss: 3.9496745268503823

Epoch: 6| Step: 10
Training loss: 4.643568992614746
Validation loss: 3.9451316197713218

Epoch: 6| Step: 11
Training loss: 3.9749178886413574
Validation loss: 3.941529393196106

Epoch: 6| Step: 12
Training loss: 3.5505194664001465
Validation loss: 3.9355181058247886

Epoch: 6| Step: 13
Training loss: 3.072531223297119
Validation loss: 3.929577191670736

Epoch: 19| Step: 0
Training loss: 4.4963698387146
Validation loss: 3.9246555964152017

Epoch: 6| Step: 1
Training loss: 5.1382646560668945
Validation loss: 3.9197070201238

Epoch: 6| Step: 2
Training loss: 4.748811721801758
Validation loss: 3.9152996142705283

Epoch: 6| Step: 3
Training loss: 3.078091621398926
Validation loss: 3.9096387227376304

Epoch: 6| Step: 4
Training loss: 3.9324183464050293
Validation loss: 3.9054003159205117

Epoch: 6| Step: 5
Training loss: 3.7470247745513916
Validation loss: 3.9001502195994058

Epoch: 6| Step: 6
Training loss: 4.118837833404541
Validation loss: 3.896225094795227

Epoch: 6| Step: 7
Training loss: 4.199520111083984
Validation loss: 3.892533540725708

Epoch: 6| Step: 8
Training loss: 5.027709007263184
Validation loss: 3.888028621673584

Epoch: 6| Step: 9
Training loss: 3.6445446014404297
Validation loss: 3.881972392400106

Epoch: 6| Step: 10
Training loss: 3.516988754272461
Validation loss: 3.8766392866770425

Epoch: 6| Step: 11
Training loss: 4.3538055419921875
Validation loss: 3.8715703090031943

Epoch: 6| Step: 12
Training loss: 3.3810219764709473
Validation loss: 3.8664886156717935

Epoch: 6| Step: 13
Training loss: 3.249274969100952
Validation loss: 3.861933946609497

Epoch: 20| Step: 0
Training loss: 3.684662342071533
Validation loss: 3.8583634297053018

Epoch: 6| Step: 1
Training loss: 3.9137721061706543
Validation loss: 3.8523833751678467

Epoch: 6| Step: 2
Training loss: 4.417325973510742
Validation loss: 3.8477463722229004

Epoch: 6| Step: 3
Training loss: 4.738719940185547
Validation loss: 3.8428985675175986

Epoch: 6| Step: 4
Training loss: 3.274754285812378
Validation loss: 3.838295102119446

Epoch: 6| Step: 5
Training loss: 4.798428058624268
Validation loss: 3.8332162698109946

Epoch: 6| Step: 6
Training loss: 3.6043894290924072
Validation loss: 3.8289403915405273

Epoch: 6| Step: 7
Training loss: 4.77933406829834
Validation loss: 3.824756701787313

Epoch: 6| Step: 8
Training loss: 3.793466091156006
Validation loss: 3.8205835024515786

Epoch: 6| Step: 9
Training loss: 3.5842766761779785
Validation loss: 3.815158406893412

Epoch: 6| Step: 10
Training loss: 3.887289047241211
Validation loss: 3.8103215297063193

Epoch: 6| Step: 11
Training loss: 3.2728381156921387
Validation loss: 3.8059645891189575

Epoch: 6| Step: 12
Training loss: 3.6133503913879395
Validation loss: 3.801548441251119

Epoch: 6| Step: 13
Training loss: 4.349631309509277
Validation loss: 3.796454985936483

Epoch: 21| Step: 0
Training loss: 3.864625930786133
Validation loss: 3.793015638987223

Epoch: 6| Step: 1
Training loss: 3.6044795513153076
Validation loss: 3.787957469622294

Epoch: 6| Step: 2
Training loss: 3.8579719066619873
Validation loss: 3.7835726340611777

Epoch: 6| Step: 3
Training loss: 2.7867860794067383
Validation loss: 3.779237985610962

Epoch: 6| Step: 4
Training loss: 3.645789384841919
Validation loss: 3.7745580673217773

Epoch: 6| Step: 5
Training loss: 4.711298942565918
Validation loss: 3.7696202198664346

Epoch: 6| Step: 6
Training loss: 5.083812713623047
Validation loss: 3.7644627888997397

Epoch: 6| Step: 7
Training loss: 3.3028597831726074
Validation loss: 3.7602338393529258

Epoch: 6| Step: 8
Training loss: 3.2919766902923584
Validation loss: 3.755653460820516

Epoch: 6| Step: 9
Training loss: 4.719237327575684
Validation loss: 3.7509873310724893

Epoch: 6| Step: 10
Training loss: 3.5661134719848633
Validation loss: 3.74593722820282

Epoch: 6| Step: 11
Training loss: 3.858107566833496
Validation loss: 3.742659409840902

Epoch: 6| Step: 12
Training loss: 4.4286675453186035
Validation loss: 3.737403909365336

Epoch: 6| Step: 13
Training loss: 4.156046390533447
Validation loss: 3.7324952284495034

Epoch: 22| Step: 0
Training loss: 4.195648670196533
Validation loss: 3.728074789047241

Epoch: 6| Step: 1
Training loss: 3.5203914642333984
Validation loss: 3.7218749125798545

Epoch: 6| Step: 2
Training loss: 3.1965181827545166
Validation loss: 3.7181971073150635

Epoch: 6| Step: 3
Training loss: 3.988294839859009
Validation loss: 3.714622894922892

Epoch: 6| Step: 4
Training loss: 3.995882511138916
Validation loss: 3.7095386584599814

Epoch: 6| Step: 5
Training loss: 3.4123992919921875
Validation loss: 3.704860726992289

Epoch: 6| Step: 6
Training loss: 4.078009605407715
Validation loss: 3.700810114542643

Epoch: 6| Step: 7
Training loss: 3.6639199256896973
Validation loss: 3.6960633198420205

Epoch: 6| Step: 8
Training loss: 3.956676959991455
Validation loss: 3.6917887131373086

Epoch: 6| Step: 9
Training loss: 3.100071430206299
Validation loss: 3.68752912680308

Epoch: 6| Step: 10
Training loss: 4.354687690734863
Validation loss: 3.6823370854059854

Epoch: 6| Step: 11
Training loss: 4.801383018493652
Validation loss: 3.678460876146952

Epoch: 6| Step: 12
Training loss: 4.588033199310303
Validation loss: 3.674229621887207

Epoch: 6| Step: 13
Training loss: 3.187215805053711
Validation loss: 3.66958220799764

Epoch: 23| Step: 0
Training loss: 4.292264938354492
Validation loss: 3.6659587224324546

Epoch: 6| Step: 1
Training loss: 3.0937042236328125
Validation loss: 3.6617751916249595

Epoch: 6| Step: 2
Training loss: 3.824664831161499
Validation loss: 3.6564714113871255

Epoch: 6| Step: 3
Training loss: 3.187187671661377
Validation loss: 3.6515667835871377

Epoch: 6| Step: 4
Training loss: 3.925672769546509
Validation loss: 3.6471357345581055

Epoch: 6| Step: 5
Training loss: 4.42468786239624
Validation loss: 3.642528255780538

Epoch: 6| Step: 6
Training loss: 3.3944876194000244
Validation loss: 3.6387231747309365

Epoch: 6| Step: 7
Training loss: 3.2711246013641357
Validation loss: 3.6347100734710693

Epoch: 6| Step: 8
Training loss: 4.162881851196289
Validation loss: 3.629767139752706

Epoch: 6| Step: 9
Training loss: 4.5180439949035645
Validation loss: 3.6267204682032266

Epoch: 6| Step: 10
Training loss: 4.241783618927002
Validation loss: 3.621901194254557

Epoch: 6| Step: 11
Training loss: 4.825557708740234
Validation loss: 3.6167221864064536

Epoch: 6| Step: 12
Training loss: 3.0888497829437256
Validation loss: 3.6120572090148926

Epoch: 6| Step: 13
Training loss: 2.957268714904785
Validation loss: 3.608428478240967

Epoch: 24| Step: 0
Training loss: 3.5891175270080566
Validation loss: 3.603771924972534

Epoch: 6| Step: 1
Training loss: 4.263220310211182
Validation loss: 3.5997568368911743

Epoch: 6| Step: 2
Training loss: 3.7933390140533447
Validation loss: 3.59497340520223

Epoch: 6| Step: 3
Training loss: 5.064540863037109
Validation loss: 3.589662233988444

Epoch: 6| Step: 4
Training loss: 4.169771194458008
Validation loss: 3.585126201311747

Epoch: 6| Step: 5
Training loss: 4.304696559906006
Validation loss: 3.580060362815857

Epoch: 6| Step: 6
Training loss: 4.514111518859863
Validation loss: 3.57506787776947

Epoch: 6| Step: 7
Training loss: 3.3803622722625732
Validation loss: 3.569759647051493

Epoch: 6| Step: 8
Training loss: 2.8658337593078613
Validation loss: 3.5647114912668862

Epoch: 6| Step: 9
Training loss: 4.063758850097656
Validation loss: 3.5594459772109985

Epoch: 6| Step: 10
Training loss: 2.9057772159576416
Validation loss: 3.5546671549479165

Epoch: 6| Step: 11
Training loss: 2.9759418964385986
Validation loss: 3.5493101676305137

Epoch: 6| Step: 12
Training loss: 4.151275634765625
Validation loss: 3.5449668169021606

Epoch: 6| Step: 13
Training loss: 2.312244415283203
Validation loss: 3.541682998339335

Epoch: 25| Step: 0
Training loss: 2.750763416290283
Validation loss: 3.5355124870936074

Epoch: 6| Step: 1
Training loss: 3.811345338821411
Validation loss: 3.5298557678858438

Epoch: 6| Step: 2
Training loss: 3.183016061782837
Validation loss: 3.5264420906702676

Epoch: 6| Step: 3
Training loss: 3.831090211868286
Validation loss: 3.522150158882141

Epoch: 6| Step: 4
Training loss: 3.515549659729004
Validation loss: 3.518234690030416

Epoch: 6| Step: 5
Training loss: 2.97896146774292
Validation loss: 3.5125290950139365

Epoch: 6| Step: 6
Training loss: 3.9271936416625977
Validation loss: 3.508829911549886

Epoch: 6| Step: 7
Training loss: 4.483885288238525
Validation loss: 3.5049062967300415

Epoch: 6| Step: 8
Training loss: 4.289365768432617
Validation loss: 3.5004990895589194

Epoch: 6| Step: 9
Training loss: 2.8940019607543945
Validation loss: 3.495062271753947

Epoch: 6| Step: 10
Training loss: 4.048956871032715
Validation loss: 3.4900022745132446

Epoch: 6| Step: 11
Training loss: 3.476694107055664
Validation loss: 3.4865740140279136

Epoch: 6| Step: 12
Training loss: 3.836247205734253
Validation loss: 3.4815721909205117

Epoch: 6| Step: 13
Training loss: 4.382801532745361
Validation loss: 3.4772045612335205

Epoch: 26| Step: 0
Training loss: 3.5251755714416504
Validation loss: 3.472694993019104

Epoch: 6| Step: 1
Training loss: 4.816424369812012
Validation loss: 3.4664084116617837

Epoch: 6| Step: 2
Training loss: 2.7088093757629395
Validation loss: 3.4615482091903687

Epoch: 6| Step: 3
Training loss: 2.5358901023864746
Validation loss: 3.4563306967417398

Epoch: 6| Step: 4
Training loss: 5.246829986572266
Validation loss: 3.4524298508961997

Epoch: 6| Step: 5
Training loss: 3.830519199371338
Validation loss: 3.4476641019185386

Epoch: 6| Step: 6
Training loss: 3.8443922996520996
Validation loss: 3.442532499631246

Epoch: 6| Step: 7
Training loss: 2.86361026763916
Validation loss: 3.437147617340088

Epoch: 6| Step: 8
Training loss: 3.5594429969787598
Validation loss: 3.4321929613749185

Epoch: 6| Step: 9
Training loss: 3.0726144313812256
Validation loss: 3.4274203379948935

Epoch: 6| Step: 10
Training loss: 2.8111109733581543
Validation loss: 3.422429879506429

Epoch: 6| Step: 11
Training loss: 3.9970643520355225
Validation loss: 3.4184487660725913

Epoch: 6| Step: 12
Training loss: 4.439055442810059
Validation loss: 3.4147346019744873

Epoch: 6| Step: 13
Training loss: 3.286884307861328
Validation loss: 3.409647822380066

Epoch: 27| Step: 0
Training loss: 3.3894686698913574
Validation loss: 3.4047253131866455

Epoch: 6| Step: 1
Training loss: 3.3481788635253906
Validation loss: 3.3997188409169516

Epoch: 6| Step: 2
Training loss: 4.317507743835449
Validation loss: 3.3959030310312905

Epoch: 6| Step: 3
Training loss: 4.698509216308594
Validation loss: 3.3919975757598877

Epoch: 6| Step: 4
Training loss: 3.5462565422058105
Validation loss: 3.3856412172317505

Epoch: 6| Step: 5
Training loss: 3.4587936401367188
Validation loss: 3.3864572048187256

Epoch: 6| Step: 6
Training loss: 3.3343138694763184
Validation loss: 3.376839558283488

Epoch: 6| Step: 7
Training loss: 2.7589476108551025
Validation loss: 3.373333732287089

Epoch: 6| Step: 8
Training loss: 3.075644016265869
Validation loss: 3.3699883619944253

Epoch: 6| Step: 9
Training loss: 2.734525203704834
Validation loss: 3.365059018135071

Epoch: 6| Step: 10
Training loss: 3.9494574069976807
Validation loss: 3.3597374757130942

Epoch: 6| Step: 11
Training loss: 3.9814107418060303
Validation loss: 3.3550496896107993

Epoch: 6| Step: 12
Training loss: 3.7012100219726562
Validation loss: 3.350868503252665

Epoch: 6| Step: 13
Training loss: 3.357926845550537
Validation loss: 3.3463379542032876

Epoch: 28| Step: 0
Training loss: 3.168738603591919
Validation loss: 3.3420852422714233

Epoch: 6| Step: 1
Training loss: 2.9272854328155518
Validation loss: 3.337691346804301

Epoch: 6| Step: 2
Training loss: 2.950836181640625
Validation loss: 3.3340875705083213

Epoch: 6| Step: 3
Training loss: 3.547569751739502
Validation loss: 3.3296377658843994

Epoch: 6| Step: 4
Training loss: 4.565065383911133
Validation loss: 3.3261911074320474

Epoch: 6| Step: 5
Training loss: 3.5124740600585938
Validation loss: 3.320356289545695

Epoch: 6| Step: 6
Training loss: 2.8279545307159424
Validation loss: 3.3159021933873496

Epoch: 6| Step: 7
Training loss: 3.487710475921631
Validation loss: 3.3105609814325967

Epoch: 6| Step: 8
Training loss: 3.1804392337799072
Validation loss: 3.306406021118164

Epoch: 6| Step: 9
Training loss: 3.9335784912109375
Validation loss: 3.3027581771214805

Epoch: 6| Step: 10
Training loss: 3.6314826011657715
Validation loss: 3.2985023260116577

Epoch: 6| Step: 11
Training loss: 3.32377028465271
Validation loss: 3.2940382957458496

Epoch: 6| Step: 12
Training loss: 3.7620232105255127
Validation loss: 3.289899230003357

Epoch: 6| Step: 13
Training loss: 3.9939708709716797
Validation loss: 3.2860142389933267

Epoch: 29| Step: 0
Training loss: 3.1918249130249023
Validation loss: 3.2808848222096763

Epoch: 6| Step: 1
Training loss: 3.0362586975097656
Validation loss: 3.2766380310058594

Epoch: 6| Step: 2
Training loss: 3.833395004272461
Validation loss: 3.273086349169413

Epoch: 6| Step: 3
Training loss: 3.013648748397827
Validation loss: 3.275164763132731

Epoch: 6| Step: 4
Training loss: 2.4767508506774902
Validation loss: 3.2701536814371743

Epoch: 6| Step: 5
Training loss: 3.580098867416382
Validation loss: 3.263172189394633

Epoch: 6| Step: 6
Training loss: 4.229804992675781
Validation loss: 3.2581448952356973

Epoch: 6| Step: 7
Training loss: 3.3185465335845947
Validation loss: 3.25147012869517

Epoch: 6| Step: 8
Training loss: 3.6347103118896484
Validation loss: 3.250055511792501

Epoch: 6| Step: 9
Training loss: 4.23021125793457
Validation loss: 3.2475349505742392

Epoch: 6| Step: 10
Training loss: 4.054879188537598
Validation loss: 3.2418771982192993

Epoch: 6| Step: 11
Training loss: 2.70996356010437
Validation loss: 3.2363548278808594

Epoch: 6| Step: 12
Training loss: 3.214909315109253
Validation loss: 3.2331743240356445

Epoch: 6| Step: 13
Training loss: 3.5329837799072266
Validation loss: 3.2295534213383994

Epoch: 30| Step: 0
Training loss: 3.634808301925659
Validation loss: 3.2250353495279946

Epoch: 6| Step: 1
Training loss: 2.8853554725646973
Validation loss: 3.2206814289093018

Epoch: 6| Step: 2
Training loss: 4.294825077056885
Validation loss: 3.2174805402755737

Epoch: 6| Step: 3
Training loss: 3.9892377853393555
Validation loss: 3.2138037284215293

Epoch: 6| Step: 4
Training loss: 3.0565273761749268
Validation loss: 3.2072529395421348

Epoch: 6| Step: 5
Training loss: 3.1546785831451416
Validation loss: 3.2049620151519775

Epoch: 6| Step: 6
Training loss: 3.694673538208008
Validation loss: 3.1987051169077554

Epoch: 6| Step: 7
Training loss: 3.130768060684204
Validation loss: 3.193580389022827

Epoch: 6| Step: 8
Training loss: 2.6718173027038574
Validation loss: 3.1901247104008994

Epoch: 6| Step: 9
Training loss: 3.2878923416137695
Validation loss: 3.1864885489145913

Epoch: 6| Step: 10
Training loss: 2.91178035736084
Validation loss: 3.181601802508036

Epoch: 6| Step: 11
Training loss: 3.870854139328003
Validation loss: 3.1773118575414023

Epoch: 6| Step: 12
Training loss: 3.831761598587036
Validation loss: 3.173903981844584

Epoch: 6| Step: 13
Training loss: 2.8749752044677734
Validation loss: 3.1695550680160522

Epoch: 31| Step: 0
Training loss: 2.9556684494018555
Validation loss: 3.164552330970764

Epoch: 6| Step: 1
Training loss: 3.6776881217956543
Validation loss: 3.1593032677968345

Epoch: 6| Step: 2
Training loss: 3.6602187156677246
Validation loss: 3.155384103457133

Epoch: 6| Step: 3
Training loss: 3.1750807762145996
Validation loss: 3.150726397832235

Epoch: 6| Step: 4
Training loss: 2.966325283050537
Validation loss: 3.1478997071584067

Epoch: 6| Step: 5
Training loss: 3.7101662158966064
Validation loss: 3.1428733269373574

Epoch: 6| Step: 6
Training loss: 3.153517723083496
Validation loss: 3.138902187347412

Epoch: 6| Step: 7
Training loss: 3.7360730171203613
Validation loss: 3.1337732871373496

Epoch: 6| Step: 8
Training loss: 3.0600552558898926
Validation loss: 3.13072141011556

Epoch: 6| Step: 9
Training loss: 2.9080495834350586
Validation loss: 3.126331408818563

Epoch: 6| Step: 10
Training loss: 3.250406265258789
Validation loss: 3.1218324104944863

Epoch: 6| Step: 11
Training loss: 2.789332866668701
Validation loss: 3.117487668991089

Epoch: 6| Step: 12
Training loss: 3.6758928298950195
Validation loss: 3.11386239528656

Epoch: 6| Step: 13
Training loss: 3.805563449859619
Validation loss: 3.1098384459813437

Epoch: 32| Step: 0
Training loss: 3.7426280975341797
Validation loss: 3.1056367556254068

Epoch: 6| Step: 1
Training loss: 2.308007001876831
Validation loss: 3.101693272590637

Epoch: 6| Step: 2
Training loss: 3.7699193954467773
Validation loss: 3.096668799718221

Epoch: 6| Step: 3
Training loss: 2.5814390182495117
Validation loss: 3.093962629636129

Epoch: 6| Step: 4
Training loss: 3.0028672218322754
Validation loss: 3.092471122741699

Epoch: 6| Step: 5
Training loss: 2.3382248878479004
Validation loss: 3.0889856020609536

Epoch: 6| Step: 6
Training loss: 3.5111966133117676
Validation loss: 3.0879115660985312

Epoch: 6| Step: 7
Training loss: 3.791327714920044
Validation loss: 3.0784604946772256

Epoch: 6| Step: 8
Training loss: 3.2783854007720947
Validation loss: 3.0749522844950357

Epoch: 6| Step: 9
Training loss: 3.276712656021118
Validation loss: 3.0708520809809365

Epoch: 6| Step: 10
Training loss: 3.029961109161377
Validation loss: 3.0680721600850425

Epoch: 6| Step: 11
Training loss: 3.8825900554656982
Validation loss: 3.064118266105652

Epoch: 6| Step: 12
Training loss: 2.9672393798828125
Validation loss: 3.0610185861587524

Epoch: 6| Step: 13
Training loss: 4.302894592285156
Validation loss: 3.057145873705546

Epoch: 33| Step: 0
Training loss: 3.1546366214752197
Validation loss: 3.053930481274923

Epoch: 6| Step: 1
Training loss: 3.19577693939209
Validation loss: 3.0503810246785483

Epoch: 6| Step: 2
Training loss: 3.285059928894043
Validation loss: 3.0459839900334678

Epoch: 6| Step: 3
Training loss: 2.940500497817993
Validation loss: 3.0428330103556314

Epoch: 6| Step: 4
Training loss: 2.4352288246154785
Validation loss: 3.0391072829564414

Epoch: 6| Step: 5
Training loss: 3.7757890224456787
Validation loss: 3.0356555382410684

Epoch: 6| Step: 6
Training loss: 3.5765774250030518
Validation loss: 3.0321118036905923

Epoch: 6| Step: 7
Training loss: 3.3801894187927246
Validation loss: 3.028089960416158

Epoch: 6| Step: 8
Training loss: 3.8831124305725098
Validation loss: 3.02590012550354

Epoch: 6| Step: 9
Training loss: 3.6543326377868652
Validation loss: 3.021324872970581

Epoch: 6| Step: 10
Training loss: 2.3290181159973145
Validation loss: 3.016951322555542

Epoch: 6| Step: 11
Training loss: 3.4617373943328857
Validation loss: 3.0132842858632407

Epoch: 6| Step: 12
Training loss: 3.374138355255127
Validation loss: 3.0087602138519287

Epoch: 6| Step: 13
Training loss: 2.649575710296631
Validation loss: 3.0051061312357583

Epoch: 34| Step: 0
Training loss: 3.862027168273926
Validation loss: 3.0016565720240274

Epoch: 6| Step: 1
Training loss: 2.9102017879486084
Validation loss: 2.9980628887812295

Epoch: 6| Step: 2
Training loss: 3.0544567108154297
Validation loss: 2.993704319000244

Epoch: 6| Step: 3
Training loss: 3.4125075340270996
Validation loss: 2.99076775709788

Epoch: 6| Step: 4
Training loss: 2.9944396018981934
Validation loss: 2.9867499272028604

Epoch: 6| Step: 5
Training loss: 2.829822063446045
Validation loss: 2.9832060734430947

Epoch: 6| Step: 6
Training loss: 3.2045068740844727
Validation loss: 2.9797640641530356

Epoch: 6| Step: 7
Training loss: 4.056661605834961
Validation loss: 2.97674024105072

Epoch: 6| Step: 8
Training loss: 2.946033000946045
Validation loss: 2.9727652072906494

Epoch: 6| Step: 9
Training loss: 2.7121822834014893
Validation loss: 2.9703031380971274

Epoch: 6| Step: 10
Training loss: 3.936126947402954
Validation loss: 2.965880036354065

Epoch: 6| Step: 11
Training loss: 3.237062931060791
Validation loss: 2.962074796358744

Epoch: 6| Step: 12
Training loss: 2.9629642963409424
Validation loss: 2.9584970474243164

Epoch: 6| Step: 13
Training loss: 2.3102645874023438
Validation loss: 2.9551709095637

Epoch: 35| Step: 0
Training loss: 3.2247862815856934
Validation loss: 2.9510729710261026

Epoch: 6| Step: 1
Training loss: 3.124156951904297
Validation loss: 2.9459993839263916

Epoch: 6| Step: 2
Training loss: 3.362617015838623
Validation loss: 2.943212072054545

Epoch: 6| Step: 3
Training loss: 2.9338245391845703
Validation loss: 2.940223534901937

Epoch: 6| Step: 4
Training loss: 2.6907083988189697
Validation loss: 2.936980883280436

Epoch: 6| Step: 5
Training loss: 3.1309025287628174
Validation loss: 2.93368661403656

Epoch: 6| Step: 6
Training loss: 3.6169042587280273
Validation loss: 2.9284390211105347

Epoch: 6| Step: 7
Training loss: 3.2960739135742188
Validation loss: 2.9247148036956787

Epoch: 6| Step: 8
Training loss: 3.144730567932129
Validation loss: 2.9211000204086304

Epoch: 6| Step: 9
Training loss: 2.4899563789367676
Validation loss: 2.915815830230713

Epoch: 6| Step: 10
Training loss: 2.68036150932312
Validation loss: 2.9124831358591714

Epoch: 6| Step: 11
Training loss: 3.5139472484588623
Validation loss: 2.9102269808451333

Epoch: 6| Step: 12
Training loss: 3.461207866668701
Validation loss: 2.906661113103231

Epoch: 6| Step: 13
Training loss: 3.1142332553863525
Validation loss: 2.902115980784098

Epoch: 36| Step: 0
Training loss: 2.923733711242676
Validation loss: 2.897555629412333

Epoch: 6| Step: 1
Training loss: 2.4890525341033936
Validation loss: 2.8940389156341553

Epoch: 6| Step: 2
Training loss: 2.9816994667053223
Validation loss: 2.8911924759546914

Epoch: 6| Step: 3
Training loss: 2.9568281173706055
Validation loss: 2.888550043106079

Epoch: 6| Step: 4
Training loss: 3.2476959228515625
Validation loss: 2.8841842810312905

Epoch: 6| Step: 5
Training loss: 3.439775228500366
Validation loss: 2.8824082215627036

Epoch: 6| Step: 6
Training loss: 3.064634323120117
Validation loss: 2.877558946609497

Epoch: 6| Step: 7
Training loss: 3.104125499725342
Validation loss: 2.8723376393318176

Epoch: 6| Step: 8
Training loss: 2.4803037643432617
Validation loss: 2.8700697819391885

Epoch: 6| Step: 9
Training loss: 3.0426154136657715
Validation loss: 2.8667907317479453

Epoch: 6| Step: 10
Training loss: 3.793335199356079
Validation loss: 2.8643128474553428

Epoch: 6| Step: 11
Training loss: 2.7769315242767334
Validation loss: 2.8611276547114053

Epoch: 6| Step: 12
Training loss: 3.1711606979370117
Validation loss: 2.8582475582758584

Epoch: 6| Step: 13
Training loss: 3.6663966178894043
Validation loss: 2.8544406493504844

Epoch: 37| Step: 0
Training loss: 2.6442646980285645
Validation loss: 2.8501698970794678

Epoch: 6| Step: 1
Training loss: 3.296376943588257
Validation loss: 2.847212553024292

Epoch: 6| Step: 2
Training loss: 3.474459648132324
Validation loss: 2.842656215031942

Epoch: 6| Step: 3
Training loss: 2.97066068649292
Validation loss: 2.8395195404688516

Epoch: 6| Step: 4
Training loss: 2.4879424571990967
Validation loss: 2.835373878479004

Epoch: 6| Step: 5
Training loss: 3.6067025661468506
Validation loss: 2.832483251889547

Epoch: 6| Step: 6
Training loss: 2.969564914703369
Validation loss: 2.829414963722229

Epoch: 6| Step: 7
Training loss: 2.3801536560058594
Validation loss: 2.8259520133336387

Epoch: 6| Step: 8
Training loss: 2.4144718647003174
Validation loss: 2.8228726784388223

Epoch: 6| Step: 9
Training loss: 3.095017433166504
Validation loss: 2.820121963818868

Epoch: 6| Step: 10
Training loss: 3.601365566253662
Validation loss: 2.816543380419413

Epoch: 6| Step: 11
Training loss: 2.891849994659424
Validation loss: 2.8135741353034973

Epoch: 6| Step: 12
Training loss: 3.450410842895508
Validation loss: 2.8101027409235635

Epoch: 6| Step: 13
Training loss: 3.2560272216796875
Validation loss: 2.8071718215942383

Epoch: 38| Step: 0
Training loss: 3.8093247413635254
Validation loss: 2.8054019610087075

Epoch: 6| Step: 1
Training loss: 2.89644193649292
Validation loss: 2.8040581146876016

Epoch: 6| Step: 2
Training loss: 2.3356146812438965
Validation loss: 2.7983700037002563

Epoch: 6| Step: 3
Training loss: 2.9417378902435303
Validation loss: 2.792483647664388

Epoch: 6| Step: 4
Training loss: 2.6158905029296875
Validation loss: 2.788899779319763

Epoch: 6| Step: 5
Training loss: 2.5648868083953857
Validation loss: 2.786458174387614

Epoch: 6| Step: 6
Training loss: 2.8525333404541016
Validation loss: 2.7851327061653137

Epoch: 6| Step: 7
Training loss: 3.137545347213745
Validation loss: 2.782400965690613

Epoch: 6| Step: 8
Training loss: 2.647242784500122
Validation loss: 2.7782408793767295

Epoch: 6| Step: 9
Training loss: 2.765693187713623
Validation loss: 2.7765236298243203

Epoch: 6| Step: 10
Training loss: 3.0850958824157715
Validation loss: 2.7728269894917807

Epoch: 6| Step: 11
Training loss: 3.907153367996216
Validation loss: 2.77028218905131

Epoch: 6| Step: 12
Training loss: 3.1785287857055664
Validation loss: 2.7858972549438477

Epoch: 6| Step: 13
Training loss: 3.1925671100616455
Validation loss: 2.7668224771817527

Epoch: 39| Step: 0
Training loss: 2.639960289001465
Validation loss: 2.7618616422017417

Epoch: 6| Step: 1
Training loss: 3.041228771209717
Validation loss: 2.762400190035502

Epoch: 6| Step: 2
Training loss: 2.7118940353393555
Validation loss: 2.7589210669199624

Epoch: 6| Step: 3
Training loss: 2.9122419357299805
Validation loss: 2.7572362422943115

Epoch: 6| Step: 4
Training loss: 3.4857873916625977
Validation loss: 2.762956420580546

Epoch: 6| Step: 5
Training loss: 2.447669506072998
Validation loss: 2.763504902521769

Epoch: 6| Step: 6
Training loss: 3.2578132152557373
Validation loss: 2.758377114931742

Epoch: 6| Step: 7
Training loss: 2.7534666061401367
Validation loss: 2.748824119567871

Epoch: 6| Step: 8
Training loss: 2.96124529838562
Validation loss: 2.7392818927764893

Epoch: 6| Step: 9
Training loss: 2.956022262573242
Validation loss: 2.7383259932200112

Epoch: 6| Step: 10
Training loss: 3.1396093368530273
Validation loss: 2.736672043800354

Epoch: 6| Step: 11
Training loss: 3.002768039703369
Validation loss: 2.736084461212158

Epoch: 6| Step: 12
Training loss: 3.0418262481689453
Validation loss: 2.7317377726236978

Epoch: 6| Step: 13
Training loss: 3.047257423400879
Validation loss: 2.729580879211426

Epoch: 40| Step: 0
Training loss: 2.642672538757324
Validation loss: 2.7223926782608032

Epoch: 6| Step: 1
Training loss: 3.3531298637390137
Validation loss: 2.717763662338257

Epoch: 6| Step: 2
Training loss: 2.899440288543701
Validation loss: 2.7146140535672507

Epoch: 6| Step: 3
Training loss: 3.05812406539917
Validation loss: 2.7115113735198975

Epoch: 6| Step: 4
Training loss: 2.9794161319732666
Validation loss: 2.7068188985188804

Epoch: 6| Step: 5
Training loss: 3.4087839126586914
Validation loss: 2.702536384264628

Epoch: 6| Step: 6
Training loss: 2.8050119876861572
Validation loss: 2.6990845998128257

Epoch: 6| Step: 7
Training loss: 2.8448286056518555
Validation loss: 2.696229259173075

Epoch: 6| Step: 8
Training loss: 3.1355271339416504
Validation loss: 2.694735288619995

Epoch: 6| Step: 9
Training loss: 2.4513375759124756
Validation loss: 2.691294550895691

Epoch: 6| Step: 10
Training loss: 3.0544071197509766
Validation loss: 2.689701040585836

Epoch: 6| Step: 11
Training loss: 2.6557233333587646
Validation loss: 2.6845611333847046

Epoch: 6| Step: 12
Training loss: 2.3556079864501953
Validation loss: 2.680634538332621

Epoch: 6| Step: 13
Training loss: 3.1004090309143066
Validation loss: 2.6778923670450845

Epoch: 41| Step: 0
Training loss: 2.1995506286621094
Validation loss: 2.674363454182943

Epoch: 6| Step: 1
Training loss: 2.914482593536377
Validation loss: 2.670470714569092

Epoch: 6| Step: 2
Training loss: 2.971642017364502
Validation loss: 2.6677045822143555

Epoch: 6| Step: 3
Training loss: 2.915875196456909
Validation loss: 2.6634467045466104

Epoch: 6| Step: 4
Training loss: 2.695044994354248
Validation loss: 2.659874121348063

Epoch: 6| Step: 5
Training loss: 3.4882540702819824
Validation loss: 2.6556896766026816

Epoch: 6| Step: 6
Training loss: 2.476677179336548
Validation loss: 2.653215249379476

Epoch: 6| Step: 7
Training loss: 2.2578506469726562
Validation loss: 2.6493767499923706

Epoch: 6| Step: 8
Training loss: 3.2835779190063477
Validation loss: 2.6474225521087646

Epoch: 6| Step: 9
Training loss: 3.4258158206939697
Validation loss: 2.6448684533437095

Epoch: 6| Step: 10
Training loss: 2.874724864959717
Validation loss: 2.6388988494873047

Epoch: 6| Step: 11
Training loss: 2.7900166511535645
Validation loss: 2.636737902959188

Epoch: 6| Step: 12
Training loss: 2.970731258392334
Validation loss: 2.6338051557540894

Epoch: 6| Step: 13
Training loss: 2.7494008541107178
Validation loss: 2.6284486254056296

Epoch: 42| Step: 0
Training loss: 2.0905261039733887
Validation loss: 2.6285467545191445

Epoch: 6| Step: 1
Training loss: 2.6033403873443604
Validation loss: 2.6230920950571694

Epoch: 6| Step: 2
Training loss: 2.396320343017578
Validation loss: 2.624053955078125

Epoch: 6| Step: 3
Training loss: 3.3393468856811523
Validation loss: 2.620446721712748

Epoch: 6| Step: 4
Training loss: 2.4322359561920166
Validation loss: 2.615419109662374

Epoch: 6| Step: 5
Training loss: 2.7031702995300293
Validation loss: 2.6131819685300193

Epoch: 6| Step: 6
Training loss: 3.0431296825408936
Validation loss: 2.609496275583903

Epoch: 6| Step: 7
Training loss: 2.0954692363739014
Validation loss: 2.6081493695576987

Epoch: 6| Step: 8
Training loss: 2.984717845916748
Validation loss: 2.604576826095581

Epoch: 6| Step: 9
Training loss: 3.0070135593414307
Validation loss: 2.602455655733744

Epoch: 6| Step: 10
Training loss: 2.8389651775360107
Validation loss: 2.6000550587972007

Epoch: 6| Step: 11
Training loss: 3.7995476722717285
Validation loss: 2.5976615746816

Epoch: 6| Step: 12
Training loss: 3.080047130584717
Validation loss: 2.5951098998387656

Epoch: 6| Step: 13
Training loss: 2.986351251602173
Validation loss: 2.591555674870809

Epoch: 43| Step: 0
Training loss: 2.293294906616211
Validation loss: 2.588922460873922

Epoch: 6| Step: 1
Training loss: 3.1427690982818604
Validation loss: 2.5855671564737954

Epoch: 6| Step: 2
Training loss: 2.742663621902466
Validation loss: 2.581149101257324

Epoch: 6| Step: 3
Training loss: 2.7999794483184814
Validation loss: 2.578537960847219

Epoch: 6| Step: 4
Training loss: 2.935934543609619
Validation loss: 2.5745058059692383

Epoch: 6| Step: 5
Training loss: 2.6699891090393066
Validation loss: 2.573003808657328

Epoch: 6| Step: 6
Training loss: 2.4198553562164307
Validation loss: 2.5681438048680625

Epoch: 6| Step: 7
Training loss: 2.8172225952148438
Validation loss: 2.5661054849624634

Epoch: 6| Step: 8
Training loss: 2.969247341156006
Validation loss: 2.563854535420736

Epoch: 6| Step: 9
Training loss: 2.5206782817840576
Validation loss: 2.5614205996195474

Epoch: 6| Step: 10
Training loss: 3.1912217140197754
Validation loss: 2.5572780768076577

Epoch: 6| Step: 11
Training loss: 2.440655469894409
Validation loss: 2.5557638009389243

Epoch: 6| Step: 12
Training loss: 3.057565689086914
Validation loss: 2.552104393641154

Epoch: 6| Step: 13
Training loss: 2.7659285068511963
Validation loss: 2.5514907439549765

Epoch: 44| Step: 0
Training loss: 2.7728068828582764
Validation loss: 2.548335631688436

Epoch: 6| Step: 1
Training loss: 3.4136486053466797
Validation loss: 2.5498632987340293

Epoch: 6| Step: 2
Training loss: 2.7362093925476074
Validation loss: 2.548804521560669

Epoch: 6| Step: 3
Training loss: 3.617356777191162
Validation loss: 2.547432541847229

Epoch: 6| Step: 4
Training loss: 2.7640113830566406
Validation loss: 2.5393285353978476

Epoch: 6| Step: 5
Training loss: 2.3676700592041016
Validation loss: 2.536720852057139

Epoch: 6| Step: 6
Training loss: 2.6509034633636475
Validation loss: 2.5323647459348044

Epoch: 6| Step: 7
Training loss: 2.967672824859619
Validation loss: 2.527800997098287

Epoch: 6| Step: 8
Training loss: 2.5084948539733887
Validation loss: 2.526885191599528

Epoch: 6| Step: 9
Training loss: 2.6083908081054688
Validation loss: 2.524294376373291

Epoch: 6| Step: 10
Training loss: 2.7570667266845703
Validation loss: 2.521950085957845

Epoch: 6| Step: 11
Training loss: 2.0329413414001465
Validation loss: 2.5171631971995034

Epoch: 6| Step: 12
Training loss: 2.369168758392334
Validation loss: 2.5145370960235596

Epoch: 6| Step: 13
Training loss: 2.7367398738861084
Validation loss: 2.5128923058509827

Epoch: 45| Step: 0
Training loss: 2.9589462280273438
Validation loss: 2.5097421407699585

Epoch: 6| Step: 1
Training loss: 2.3052589893341064
Validation loss: 2.508454442024231

Epoch: 6| Step: 2
Training loss: 2.2387213706970215
Validation loss: 2.5035403966903687

Epoch: 6| Step: 3
Training loss: 3.220839262008667
Validation loss: 2.5009878675142923

Epoch: 6| Step: 4
Training loss: 2.4492595195770264
Validation loss: 2.4995216131210327

Epoch: 6| Step: 5
Training loss: 2.6627626419067383
Validation loss: 2.4959143797556558

Epoch: 6| Step: 6
Training loss: 3.087977409362793
Validation loss: 2.492751399676005

Epoch: 6| Step: 7
Training loss: 2.166016101837158
Validation loss: 2.4887476563453674

Epoch: 6| Step: 8
Training loss: 2.8072104454040527
Validation loss: 2.485757907231649

Epoch: 6| Step: 9
Training loss: 3.2447807788848877
Validation loss: 2.5112043619155884

Epoch: 6| Step: 10
Training loss: 2.362379550933838
Validation loss: 2.4963489373524985

Epoch: 6| Step: 11
Training loss: 3.6797351837158203
Validation loss: 2.4791837135950723

Epoch: 6| Step: 12
Training loss: 2.3233301639556885
Validation loss: 2.4770227670669556

Epoch: 6| Step: 13
Training loss: 2.2242698669433594
Validation loss: 2.477546135584513

Epoch: 46| Step: 0
Training loss: 2.5634517669677734
Validation loss: 2.478588660558065

Epoch: 6| Step: 1
Training loss: 2.3010592460632324
Validation loss: 2.4782703717549643

Epoch: 6| Step: 2
Training loss: 2.978245496749878
Validation loss: 2.4803181886672974

Epoch: 6| Step: 3
Training loss: 2.4554452896118164
Validation loss: 2.4767032464345298

Epoch: 6| Step: 4
Training loss: 2.3455443382263184
Validation loss: 2.472222367922465

Epoch: 6| Step: 5
Training loss: 2.7242355346679688
Validation loss: 2.4653245210647583

Epoch: 6| Step: 6
Training loss: 3.1865856647491455
Validation loss: 2.462252378463745

Epoch: 6| Step: 7
Training loss: 2.6068711280822754
Validation loss: 2.4573911825815835

Epoch: 6| Step: 8
Training loss: 2.5886483192443848
Validation loss: 2.4532869855562844

Epoch: 6| Step: 9
Training loss: 2.726046085357666
Validation loss: 2.450412472089132

Epoch: 6| Step: 10
Training loss: 2.8291983604431152
Validation loss: 2.44769557317098

Epoch: 6| Step: 11
Training loss: 2.6726951599121094
Validation loss: 2.443718115488688

Epoch: 6| Step: 12
Training loss: 2.584272861480713
Validation loss: 2.4410794178644815

Epoch: 6| Step: 13
Training loss: 2.6184563636779785
Validation loss: 2.439520279566447

Epoch: 47| Step: 0
Training loss: 1.9451136589050293
Validation loss: 2.437046766281128

Epoch: 6| Step: 1
Training loss: 3.3057541847229004
Validation loss: 2.43591699997584

Epoch: 6| Step: 2
Training loss: 3.019465923309326
Validation loss: 2.4310828844706216

Epoch: 6| Step: 3
Training loss: 2.436321258544922
Validation loss: 2.42988129456838

Epoch: 6| Step: 4
Training loss: 2.278261184692383
Validation loss: 2.426542262236277

Epoch: 6| Step: 5
Training loss: 2.5607571601867676
Validation loss: 2.4254907369613647

Epoch: 6| Step: 6
Training loss: 2.2389254570007324
Validation loss: 2.4221125841140747

Epoch: 6| Step: 7
Training loss: 3.051069974899292
Validation loss: 2.419875701268514

Epoch: 6| Step: 8
Training loss: 2.2064733505249023
Validation loss: 2.417664647102356

Epoch: 6| Step: 9
Training loss: 2.2604477405548096
Validation loss: 2.4163540999094644

Epoch: 6| Step: 10
Training loss: 2.995525360107422
Validation loss: 2.413187086582184

Epoch: 6| Step: 11
Training loss: 2.6700668334960938
Validation loss: 2.410582701365153

Epoch: 6| Step: 12
Training loss: 2.8205370903015137
Validation loss: 2.4078670342763266

Epoch: 6| Step: 13
Training loss: 2.7756285667419434
Validation loss: 2.4042107264200845

Epoch: 48| Step: 0
Training loss: 3.3308920860290527
Validation loss: 2.403923451900482

Epoch: 6| Step: 1
Training loss: 2.3037147521972656
Validation loss: 2.3981942733128867

Epoch: 6| Step: 2
Training loss: 2.063932180404663
Validation loss: 2.3982757329940796

Epoch: 6| Step: 3
Training loss: 2.297274589538574
Validation loss: 2.3939037720362344

Epoch: 6| Step: 4
Training loss: 2.2562918663024902
Validation loss: 2.3902979294459024

Epoch: 6| Step: 5
Training loss: 2.5077803134918213
Validation loss: 2.3867475390434265

Epoch: 6| Step: 6
Training loss: 2.413700580596924
Validation loss: 2.386475841204325

Epoch: 6| Step: 7
Training loss: 3.4150612354278564
Validation loss: 2.3994460503260293

Epoch: 6| Step: 8
Training loss: 2.205211639404297
Validation loss: 2.388064662615458

Epoch: 6| Step: 9
Training loss: 2.1167991161346436
Validation loss: 2.3769496281941733

Epoch: 6| Step: 10
Training loss: 2.843311309814453
Validation loss: 2.375982324282328

Epoch: 6| Step: 11
Training loss: 2.2881078720092773
Validation loss: 2.368982990582784

Epoch: 6| Step: 12
Training loss: 2.9038867950439453
Validation loss: 2.3684751987457275

Epoch: 6| Step: 13
Training loss: 3.100020408630371
Validation loss: 2.3705145915349326

Epoch: 49| Step: 0
Training loss: 2.5746617317199707
Validation loss: 2.3696285088857016

Epoch: 6| Step: 1
Training loss: 2.8612561225891113
Validation loss: 2.3654717604319253

Epoch: 6| Step: 2
Training loss: 2.4519920349121094
Validation loss: 2.365465541680654

Epoch: 6| Step: 3
Training loss: 2.7620906829833984
Validation loss: 2.3620619575182595

Epoch: 6| Step: 4
Training loss: 2.290100574493408
Validation loss: 2.3621848821640015

Epoch: 6| Step: 5
Training loss: 3.2164437770843506
Validation loss: 2.357607384522756

Epoch: 6| Step: 6
Training loss: 2.192453145980835
Validation loss: 2.354950269063314

Epoch: 6| Step: 7
Training loss: 2.3477020263671875
Validation loss: 2.351585865020752

Epoch: 6| Step: 8
Training loss: 2.7072577476501465
Validation loss: 2.3469735185305276

Epoch: 6| Step: 9
Training loss: 2.4651408195495605
Validation loss: 2.3462023735046387

Epoch: 6| Step: 10
Training loss: 2.2902684211730957
Validation loss: 2.3404215574264526

Epoch: 6| Step: 11
Training loss: 2.2298903465270996
Validation loss: 2.3373601833979287

Epoch: 6| Step: 12
Training loss: 2.39534068107605
Validation loss: 2.3375598192214966

Epoch: 6| Step: 13
Training loss: 2.678980588912964
Validation loss: 2.3359293142954507

Epoch: 50| Step: 0
Training loss: 1.8808172941207886
Validation loss: 2.333604335784912

Epoch: 6| Step: 1
Training loss: 2.880317211151123
Validation loss: 2.3297342459360757

Epoch: 6| Step: 2
Training loss: 2.3076014518737793
Validation loss: 2.328117529551188

Epoch: 6| Step: 3
Training loss: 2.4492344856262207
Validation loss: 2.325567384560903

Epoch: 6| Step: 4
Training loss: 2.7890701293945312
Validation loss: 2.3268420100212097

Epoch: 6| Step: 5
Training loss: 2.3297600746154785
Validation loss: 2.3282463749249778

Epoch: 6| Step: 6
Training loss: 2.160658836364746
Validation loss: 2.3165040413538613

Epoch: 6| Step: 7
Training loss: 2.269465446472168
Validation loss: 2.3173854748408

Epoch: 6| Step: 8
Training loss: 3.107208251953125
Validation loss: 2.3136081298192344

Epoch: 6| Step: 9
Training loss: 2.6569342613220215
Validation loss: 2.311659653981527

Epoch: 6| Step: 10
Training loss: 3.0365500450134277
Validation loss: 2.308002471923828

Epoch: 6| Step: 11
Training loss: 2.677673101425171
Validation loss: 2.3090252677599588

Epoch: 6| Step: 12
Training loss: 2.127685546875
Validation loss: 2.3057165145874023

Epoch: 6| Step: 13
Training loss: 2.18528413772583
Validation loss: 2.3004159132639566

Testing loss: 1.9183445817275013
