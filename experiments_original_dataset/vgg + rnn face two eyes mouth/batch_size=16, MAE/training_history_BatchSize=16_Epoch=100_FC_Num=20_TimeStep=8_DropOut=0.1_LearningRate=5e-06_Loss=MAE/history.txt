Epoch: 1| Step: 0
Training loss: 4.8487749099731445
Validation loss: 5.247730890909831

Epoch: 6| Step: 1
Training loss: 5.421164512634277
Validation loss: 5.245121161142985

Epoch: 6| Step: 2
Training loss: 5.039590835571289
Validation loss: 5.242556055386861

Epoch: 6| Step: 3
Training loss: 4.571916580200195
Validation loss: 5.240164597829183

Epoch: 6| Step: 4
Training loss: 6.219450950622559
Validation loss: 5.237917582194011

Epoch: 6| Step: 5
Training loss: 5.124549865722656
Validation loss: 5.2356414794921875

Epoch: 6| Step: 6
Training loss: 5.647941589355469
Validation loss: 5.233372688293457

Epoch: 6| Step: 7
Training loss: 5.945061206817627
Validation loss: 5.231116930643718

Epoch: 6| Step: 8
Training loss: 4.736039161682129
Validation loss: 5.229000806808472

Epoch: 6| Step: 9
Training loss: 5.10306453704834
Validation loss: 5.226687908172607

Epoch: 6| Step: 10
Training loss: 5.96190071105957
Validation loss: 5.224465290705363

Epoch: 6| Step: 11
Training loss: 4.211241722106934
Validation loss: 5.2221269607543945

Epoch: 6| Step: 12
Training loss: 5.395717620849609
Validation loss: 5.219677686691284

Epoch: 6| Step: 13
Training loss: 6.001395225524902
Validation loss: 5.217250823974609

Epoch: 2| Step: 0
Training loss: 5.195788383483887
Validation loss: 5.214685837427775

Epoch: 6| Step: 1
Training loss: 4.478269577026367
Validation loss: 5.212064425150554

Epoch: 6| Step: 2
Training loss: 4.556581974029541
Validation loss: 5.209266344706218

Epoch: 6| Step: 3
Training loss: 4.241564750671387
Validation loss: 5.206521193186442

Epoch: 6| Step: 4
Training loss: 4.963074684143066
Validation loss: 5.20354700088501

Epoch: 6| Step: 5
Training loss: 5.028085708618164
Validation loss: 5.2005289395650225

Epoch: 6| Step: 6
Training loss: 4.901795387268066
Validation loss: 5.197270154953003

Epoch: 6| Step: 7
Training loss: 6.188804626464844
Validation loss: 5.193893353144328

Epoch: 6| Step: 8
Training loss: 5.652922630310059
Validation loss: 5.190324306488037

Epoch: 6| Step: 9
Training loss: 5.486079692840576
Validation loss: 5.186742941538493

Epoch: 6| Step: 10
Training loss: 5.31302547454834
Validation loss: 5.182876984278361

Epoch: 6| Step: 11
Training loss: 6.075115203857422
Validation loss: 5.178724368413289

Epoch: 6| Step: 12
Training loss: 6.249845504760742
Validation loss: 5.174587408701579

Epoch: 6| Step: 13
Training loss: 5.375034332275391
Validation loss: 5.170247236887614

Epoch: 3| Step: 0
Training loss: 6.018397331237793
Validation loss: 5.165690183639526

Epoch: 6| Step: 1
Training loss: 6.477290153503418
Validation loss: 5.160660107930501

Epoch: 6| Step: 2
Training loss: 4.873377799987793
Validation loss: 5.155686775843303

Epoch: 6| Step: 3
Training loss: 4.205938339233398
Validation loss: 5.150359153747559

Epoch: 6| Step: 4
Training loss: 5.414663791656494
Validation loss: 5.144859313964844

Epoch: 6| Step: 5
Training loss: 4.784373760223389
Validation loss: 5.139031569163005

Epoch: 6| Step: 6
Training loss: 4.969030380249023
Validation loss: 5.133202314376831

Epoch: 6| Step: 7
Training loss: 5.719697952270508
Validation loss: 5.126761436462402

Epoch: 6| Step: 8
Training loss: 5.752645492553711
Validation loss: 5.120262622833252

Epoch: 6| Step: 9
Training loss: 4.979869842529297
Validation loss: 5.113443613052368

Epoch: 6| Step: 10
Training loss: 4.708695411682129
Validation loss: 5.106382608413696

Epoch: 6| Step: 11
Training loss: 5.0015082359313965
Validation loss: 5.09915558497111

Epoch: 6| Step: 12
Training loss: 4.830750465393066
Validation loss: 5.091726144154866

Epoch: 6| Step: 13
Training loss: 5.076319217681885
Validation loss: 5.0837578773498535

Epoch: 4| Step: 0
Training loss: 5.120297431945801
Validation loss: 5.075893878936768

Epoch: 6| Step: 1
Training loss: 5.701813697814941
Validation loss: 5.067611296971639

Epoch: 6| Step: 2
Training loss: 5.263803482055664
Validation loss: 5.059216380119324

Epoch: 6| Step: 3
Training loss: 5.367547035217285
Validation loss: 5.05040458838145

Epoch: 6| Step: 4
Training loss: 4.9862284660339355
Validation loss: 5.04164735476176

Epoch: 6| Step: 5
Training loss: 4.448391437530518
Validation loss: 5.032825390497844

Epoch: 6| Step: 6
Training loss: 4.6284708976745605
Validation loss: 5.023584922154744

Epoch: 6| Step: 7
Training loss: 3.899664878845215
Validation loss: 5.014550844828288

Epoch: 6| Step: 8
Training loss: 5.325943946838379
Validation loss: 5.005351861317952

Epoch: 6| Step: 9
Training loss: 5.7483744621276855
Validation loss: 4.9957541624705

Epoch: 6| Step: 10
Training loss: 5.170011043548584
Validation loss: 4.986728111902873

Epoch: 6| Step: 11
Training loss: 4.964228630065918
Validation loss: 4.977321147918701

Epoch: 6| Step: 12
Training loss: 6.478000640869141
Validation loss: 4.96752127011617

Epoch: 6| Step: 13
Training loss: 4.272793769836426
Validation loss: 4.958059310913086

Epoch: 5| Step: 0
Training loss: 6.152204513549805
Validation loss: 4.948418815930684

Epoch: 6| Step: 1
Training loss: 4.435054779052734
Validation loss: 4.938856681187947

Epoch: 6| Step: 2
Training loss: 5.634495735168457
Validation loss: 4.929260810216268

Epoch: 6| Step: 3
Training loss: 4.9497528076171875
Validation loss: 4.919242858886719

Epoch: 6| Step: 4
Training loss: 5.654763698577881
Validation loss: 4.909733096758525

Epoch: 6| Step: 5
Training loss: 5.518817901611328
Validation loss: 4.899897972742717

Epoch: 6| Step: 6
Training loss: 5.8278961181640625
Validation loss: 4.89038364092509

Epoch: 6| Step: 7
Training loss: 5.344629287719727
Validation loss: 4.880815148353577

Epoch: 6| Step: 8
Training loss: 4.492959022521973
Validation loss: 4.871299584706624

Epoch: 6| Step: 9
Training loss: 5.011712074279785
Validation loss: 4.862437923749288

Epoch: 6| Step: 10
Training loss: 3.320535659790039
Validation loss: 4.853422522544861

Epoch: 6| Step: 11
Training loss: 4.247629165649414
Validation loss: 4.844557682673137

Epoch: 6| Step: 12
Training loss: 4.877954483032227
Validation loss: 4.8359534740448

Epoch: 6| Step: 13
Training loss: 4.160863399505615
Validation loss: 4.828102072079976

Epoch: 6| Step: 0
Training loss: 5.21767520904541
Validation loss: 4.820051034291585

Epoch: 6| Step: 1
Training loss: 4.171879768371582
Validation loss: 4.811918218930562

Epoch: 6| Step: 2
Training loss: 5.742230415344238
Validation loss: 4.804373502731323

Epoch: 6| Step: 3
Training loss: 5.448217391967773
Validation loss: 4.797112782796224

Epoch: 6| Step: 4
Training loss: 6.060242176055908
Validation loss: 4.7896542151769

Epoch: 6| Step: 5
Training loss: 4.411412239074707
Validation loss: 4.7818754116694135

Epoch: 6| Step: 6
Training loss: 4.43937349319458
Validation loss: 4.774970134099324

Epoch: 6| Step: 7
Training loss: 4.137815475463867
Validation loss: 4.767842928568522

Epoch: 6| Step: 8
Training loss: 4.62343168258667
Validation loss: 4.76056436697642

Epoch: 6| Step: 9
Training loss: 5.426475524902344
Validation loss: 4.753604332605998

Epoch: 6| Step: 10
Training loss: 4.695093154907227
Validation loss: 4.7464795509974165

Epoch: 6| Step: 11
Training loss: 4.988222599029541
Validation loss: 4.739063103993733

Epoch: 6| Step: 12
Training loss: 4.110317230224609
Validation loss: 4.731692989667256

Epoch: 6| Step: 13
Training loss: 4.588799476623535
Validation loss: 4.72442352771759

Epoch: 7| Step: 0
Training loss: 5.629362106323242
Validation loss: 4.717022101084392

Epoch: 6| Step: 1
Training loss: 4.788468360900879
Validation loss: 4.709477623303731

Epoch: 6| Step: 2
Training loss: 3.86574125289917
Validation loss: 4.702046712239583

Epoch: 6| Step: 3
Training loss: 4.358369827270508
Validation loss: 4.6950097878774

Epoch: 6| Step: 4
Training loss: 5.0611371994018555
Validation loss: 4.687997420628865

Epoch: 6| Step: 5
Training loss: 5.112337112426758
Validation loss: 4.680737495422363

Epoch: 6| Step: 6
Training loss: 5.240155220031738
Validation loss: 4.673480987548828

Epoch: 6| Step: 7
Training loss: 4.957470417022705
Validation loss: 4.666509628295898

Epoch: 6| Step: 8
Training loss: 4.667355537414551
Validation loss: 4.659703334172566

Epoch: 6| Step: 9
Training loss: 3.1271090507507324
Validation loss: 4.652661005655925

Epoch: 6| Step: 10
Training loss: 5.378913879394531
Validation loss: 4.64619501431783

Epoch: 6| Step: 11
Training loss: 5.170483589172363
Validation loss: 4.639174461364746

Epoch: 6| Step: 12
Training loss: 4.475656032562256
Validation loss: 4.632445891698201

Epoch: 6| Step: 13
Training loss: 4.884227752685547
Validation loss: 4.625538468360901

Epoch: 8| Step: 0
Training loss: 4.929895401000977
Validation loss: 4.618364969889323

Epoch: 6| Step: 1
Training loss: 5.237790107727051
Validation loss: 4.611307700475057

Epoch: 6| Step: 2
Training loss: 4.2666239738464355
Validation loss: 4.604650815327962

Epoch: 6| Step: 3
Training loss: 4.735419750213623
Validation loss: 4.597546021143596

Epoch: 6| Step: 4
Training loss: 4.35414981842041
Validation loss: 4.591014305750529

Epoch: 6| Step: 5
Training loss: 4.045370101928711
Validation loss: 4.584485292434692

Epoch: 6| Step: 6
Training loss: 5.006020545959473
Validation loss: 4.577720602353414

Epoch: 6| Step: 7
Training loss: 4.896487236022949
Validation loss: 4.571175893147786

Epoch: 6| Step: 8
Training loss: 5.146150588989258
Validation loss: 4.56438394387563

Epoch: 6| Step: 9
Training loss: 4.844263553619385
Validation loss: 4.557535847028096

Epoch: 6| Step: 10
Training loss: 4.47530460357666
Validation loss: 4.550589958826701

Epoch: 6| Step: 11
Training loss: 4.481200695037842
Validation loss: 4.543711384137471

Epoch: 6| Step: 12
Training loss: 4.219173431396484
Validation loss: 4.5364086627960205

Epoch: 6| Step: 13
Training loss: 4.806130409240723
Validation loss: 4.529303193092346

Epoch: 9| Step: 0
Training loss: 4.348938941955566
Validation loss: 4.522519032160441

Epoch: 6| Step: 1
Training loss: 4.429617404937744
Validation loss: 4.515170613924663

Epoch: 6| Step: 2
Training loss: 5.2205047607421875
Validation loss: 4.508010387420654

Epoch: 6| Step: 3
Training loss: 4.667108535766602
Validation loss: 4.5008885860443115

Epoch: 6| Step: 4
Training loss: 3.3653249740600586
Validation loss: 4.493658105532329

Epoch: 6| Step: 5
Training loss: 4.443851947784424
Validation loss: 4.486364285151164

Epoch: 6| Step: 6
Training loss: 3.7437267303466797
Validation loss: 4.479274948438008

Epoch: 6| Step: 7
Training loss: 5.077463626861572
Validation loss: 4.47200361887614

Epoch: 6| Step: 8
Training loss: 3.7143030166625977
Validation loss: 4.464521169662476

Epoch: 6| Step: 9
Training loss: 5.0563812255859375
Validation loss: 4.457184076309204

Epoch: 6| Step: 10
Training loss: 5.5878400802612305
Validation loss: 4.449332555135091

Epoch: 6| Step: 11
Training loss: 5.107363700866699
Validation loss: 4.441625515619914

Epoch: 6| Step: 12
Training loss: 5.12719202041626
Validation loss: 4.433859189351399

Epoch: 6| Step: 13
Training loss: 4.24716329574585
Validation loss: 4.425240159034729

Epoch: 10| Step: 0
Training loss: 5.114289283752441
Validation loss: 4.417123953501384

Epoch: 6| Step: 1
Training loss: 5.582392692565918
Validation loss: 4.409112453460693

Epoch: 6| Step: 2
Training loss: 4.267752647399902
Validation loss: 4.40064001083374

Epoch: 6| Step: 3
Training loss: 5.284842014312744
Validation loss: 4.392719030380249

Epoch: 6| Step: 4
Training loss: 4.741805076599121
Validation loss: 4.384514411290486

Epoch: 6| Step: 5
Training loss: 3.4672982692718506
Validation loss: 4.376878261566162

Epoch: 6| Step: 6
Training loss: 3.76072359085083
Validation loss: 4.369119127591451

Epoch: 6| Step: 7
Training loss: 4.773503303527832
Validation loss: 4.360686461130778

Epoch: 6| Step: 8
Training loss: 3.6083850860595703
Validation loss: 4.35379699865977

Epoch: 6| Step: 9
Training loss: 4.2985944747924805
Validation loss: 4.347254474957784

Epoch: 6| Step: 10
Training loss: 5.7373247146606445
Validation loss: 4.341092546780904

Epoch: 6| Step: 11
Training loss: 4.08604621887207
Validation loss: 4.3332439661026

Epoch: 6| Step: 12
Training loss: 3.541010856628418
Validation loss: 4.326267719268799

Epoch: 6| Step: 13
Training loss: 4.5503339767456055
Validation loss: 4.319539785385132

Epoch: 11| Step: 0
Training loss: 4.382049560546875
Validation loss: 4.313923080762227

Epoch: 6| Step: 1
Training loss: 4.144259452819824
Validation loss: 4.306813915570577

Epoch: 6| Step: 2
Training loss: 3.135082244873047
Validation loss: 4.3007965087890625

Epoch: 6| Step: 3
Training loss: 5.368135452270508
Validation loss: 4.29546586672465

Epoch: 6| Step: 4
Training loss: 4.537162780761719
Validation loss: 4.289045214653015

Epoch: 6| Step: 5
Training loss: 5.3346991539001465
Validation loss: 4.282990217208862

Epoch: 6| Step: 6
Training loss: 4.450620651245117
Validation loss: 4.276562213897705

Epoch: 6| Step: 7
Training loss: 4.426078796386719
Validation loss: 4.270114262898763

Epoch: 6| Step: 8
Training loss: 4.471989631652832
Validation loss: 4.264282464981079

Epoch: 6| Step: 9
Training loss: 5.187087059020996
Validation loss: 4.25841760635376

Epoch: 6| Step: 10
Training loss: 4.560291290283203
Validation loss: 4.251798987388611

Epoch: 6| Step: 11
Training loss: 4.086942195892334
Validation loss: 4.2455761432647705

Epoch: 6| Step: 12
Training loss: 3.5501866340637207
Validation loss: 4.239863276481628

Epoch: 6| Step: 13
Training loss: 3.9929628372192383
Validation loss: 4.234676996866862

Epoch: 12| Step: 0
Training loss: 4.726941108703613
Validation loss: 4.228671550750732

Epoch: 6| Step: 1
Training loss: 4.083604335784912
Validation loss: 4.2228368918101

Epoch: 6| Step: 2
Training loss: 4.01629638671875
Validation loss: 4.217229763666789

Epoch: 6| Step: 3
Training loss: 4.211610317230225
Validation loss: 4.212208112080892

Epoch: 6| Step: 4
Training loss: 4.163393974304199
Validation loss: 4.2058446407318115

Epoch: 6| Step: 5
Training loss: 4.788917541503906
Validation loss: 4.199582020441691

Epoch: 6| Step: 6
Training loss: 4.883367538452148
Validation loss: 4.195406556129456

Epoch: 6| Step: 7
Training loss: 3.172743320465088
Validation loss: 4.188037236531575

Epoch: 6| Step: 8
Training loss: 3.969059467315674
Validation loss: 4.183265765508016

Epoch: 6| Step: 9
Training loss: 4.674935340881348
Validation loss: 4.178376277287801

Epoch: 6| Step: 10
Training loss: 4.7768683433532715
Validation loss: 4.174280405044556

Epoch: 6| Step: 11
Training loss: 2.612213611602783
Validation loss: 4.169716755549113

Epoch: 6| Step: 12
Training loss: 6.128981590270996
Validation loss: 4.163405974706014

Epoch: 6| Step: 13
Training loss: 4.363190174102783
Validation loss: 4.157904942830403

Epoch: 13| Step: 0
Training loss: 4.6918253898620605
Validation loss: 4.153069575627645

Epoch: 6| Step: 1
Training loss: 3.405775547027588
Validation loss: 4.147601008415222

Epoch: 6| Step: 2
Training loss: 4.454361915588379
Validation loss: 4.141753236452739

Epoch: 6| Step: 3
Training loss: 5.106749534606934
Validation loss: 4.136443893114726

Epoch: 6| Step: 4
Training loss: 4.460899353027344
Validation loss: 4.131753325462341

Epoch: 6| Step: 5
Training loss: 5.01112174987793
Validation loss: 4.126375754674275

Epoch: 6| Step: 6
Training loss: 3.6528775691986084
Validation loss: 4.12212868531545

Epoch: 6| Step: 7
Training loss: 4.54941463470459
Validation loss: 4.117839574813843

Epoch: 6| Step: 8
Training loss: 4.041663646697998
Validation loss: 4.111252784729004

Epoch: 6| Step: 9
Training loss: 3.817793369293213
Validation loss: 4.106768051783244

Epoch: 6| Step: 10
Training loss: 4.146816253662109
Validation loss: 4.103312730789185

Epoch: 6| Step: 11
Training loss: 4.039395332336426
Validation loss: 4.096180597941081

Epoch: 6| Step: 12
Training loss: 4.730004787445068
Validation loss: 4.090321818987529

Epoch: 6| Step: 13
Training loss: 3.5133554935455322
Validation loss: 4.085767507553101

Epoch: 14| Step: 0
Training loss: 4.594066143035889
Validation loss: 4.080554326375325

Epoch: 6| Step: 1
Training loss: 4.297595977783203
Validation loss: 4.07637604077657

Epoch: 6| Step: 2
Training loss: 4.780877113342285
Validation loss: 4.072130560874939

Epoch: 6| Step: 3
Training loss: 3.406497001647949
Validation loss: 4.066939194997151

Epoch: 6| Step: 4
Training loss: 5.292616844177246
Validation loss: 4.060628374417623

Epoch: 6| Step: 5
Training loss: 4.100331783294678
Validation loss: 4.05501929918925

Epoch: 6| Step: 6
Training loss: 2.9737484455108643
Validation loss: 4.049999435742696

Epoch: 6| Step: 7
Training loss: 3.276937961578369
Validation loss: 4.043642361958821

Epoch: 6| Step: 8
Training loss: 3.460469961166382
Validation loss: 4.038490215937297

Epoch: 6| Step: 9
Training loss: 3.2267160415649414
Validation loss: 4.033350388209025

Epoch: 6| Step: 10
Training loss: 4.751624584197998
Validation loss: 4.02765687306722

Epoch: 6| Step: 11
Training loss: 5.256031036376953
Validation loss: 4.023480296134949

Epoch: 6| Step: 12
Training loss: 5.215498924255371
Validation loss: 4.018488725026448

Epoch: 6| Step: 13
Training loss: 4.028817176818848
Validation loss: 4.013307094573975

Epoch: 15| Step: 0
Training loss: 4.211009979248047
Validation loss: 4.007049640019734

Epoch: 6| Step: 1
Training loss: 3.9698076248168945
Validation loss: 4.002126971880595

Epoch: 6| Step: 2
Training loss: 3.9599151611328125
Validation loss: 3.99655282497406

Epoch: 6| Step: 3
Training loss: 4.901331901550293
Validation loss: 3.9915469884872437

Epoch: 6| Step: 4
Training loss: 3.4828994274139404
Validation loss: 3.9866342147191367

Epoch: 6| Step: 5
Training loss: 3.620359420776367
Validation loss: 3.981522043546041

Epoch: 6| Step: 6
Training loss: 4.755239009857178
Validation loss: 3.976392308870951

Epoch: 6| Step: 7
Training loss: 3.6111998558044434
Validation loss: 3.9716448386510215

Epoch: 6| Step: 8
Training loss: 4.874301910400391
Validation loss: 3.96602455774943

Epoch: 6| Step: 9
Training loss: 3.6704607009887695
Validation loss: 3.961043953895569

Epoch: 6| Step: 10
Training loss: 4.241639614105225
Validation loss: 3.955258846282959

Epoch: 6| Step: 11
Training loss: 4.265840530395508
Validation loss: 3.9499922593434653

Epoch: 6| Step: 12
Training loss: 4.31260871887207
Validation loss: 3.945265213648478

Epoch: 6| Step: 13
Training loss: 3.8081233501434326
Validation loss: 3.9403626521428428

Epoch: 16| Step: 0
Training loss: 3.911064863204956
Validation loss: 3.935236096382141

Epoch: 6| Step: 1
Training loss: 4.701344013214111
Validation loss: 3.930830438931783

Epoch: 6| Step: 2
Training loss: 3.8858256340026855
Validation loss: 3.9268611669540405

Epoch: 6| Step: 3
Training loss: 4.914127349853516
Validation loss: 3.922237237294515

Epoch: 6| Step: 4
Training loss: 4.377719879150391
Validation loss: 3.918014645576477

Epoch: 6| Step: 5
Training loss: 4.20493221282959
Validation loss: 3.9127844174702964

Epoch: 6| Step: 6
Training loss: 4.541698455810547
Validation loss: 3.9089959065119424

Epoch: 6| Step: 7
Training loss: 4.391060829162598
Validation loss: 3.9044336875279746

Epoch: 6| Step: 8
Training loss: 3.5270984172821045
Validation loss: 3.9005393981933594

Epoch: 6| Step: 9
Training loss: 4.163009166717529
Validation loss: 3.8952457507451377

Epoch: 6| Step: 10
Training loss: 3.99253511428833
Validation loss: 3.8905251026153564

Epoch: 6| Step: 11
Training loss: 3.9412553310394287
Validation loss: 3.8855711619059243

Epoch: 6| Step: 12
Training loss: 2.947342872619629
Validation loss: 3.8810880978902182

Epoch: 6| Step: 13
Training loss: 3.24605393409729
Validation loss: 3.8767313162485757

Epoch: 17| Step: 0
Training loss: 4.024723052978516
Validation loss: 3.8718538681666055

Epoch: 6| Step: 1
Training loss: 4.598567962646484
Validation loss: 3.868178447087606

Epoch: 6| Step: 2
Training loss: 3.9353771209716797
Validation loss: 3.8627717097600303

Epoch: 6| Step: 3
Training loss: 3.8956713676452637
Validation loss: 3.8571669260660806

Epoch: 6| Step: 4
Training loss: 3.5887067317962646
Validation loss: 3.8519754807154336

Epoch: 6| Step: 5
Training loss: 3.576960563659668
Validation loss: 3.847081700960795

Epoch: 6| Step: 6
Training loss: 4.404360771179199
Validation loss: 3.842496911684672

Epoch: 6| Step: 7
Training loss: 4.035276412963867
Validation loss: 3.8385873238245645

Epoch: 6| Step: 8
Training loss: 4.006789684295654
Validation loss: 3.8345401287078857

Epoch: 6| Step: 9
Training loss: 3.4044933319091797
Validation loss: 3.8302066326141357

Epoch: 6| Step: 10
Training loss: 4.666659355163574
Validation loss: 3.824353655179342

Epoch: 6| Step: 11
Training loss: 4.24884557723999
Validation loss: 3.819478670756022

Epoch: 6| Step: 12
Training loss: 3.4110159873962402
Validation loss: 3.8149207830429077

Epoch: 6| Step: 13
Training loss: 4.131137847900391
Validation loss: 3.810192267100016

Epoch: 18| Step: 0
Training loss: 3.592038631439209
Validation loss: 3.8054165045420327

Epoch: 6| Step: 1
Training loss: 4.755622386932373
Validation loss: 3.8014197746912637

Epoch: 6| Step: 2
Training loss: 3.9870405197143555
Validation loss: 3.7967262268066406

Epoch: 6| Step: 3
Training loss: 5.083222389221191
Validation loss: 3.7918324867884317

Epoch: 6| Step: 4
Training loss: 3.261723041534424
Validation loss: 3.7872472206751504

Epoch: 6| Step: 5
Training loss: 3.9250104427337646
Validation loss: 3.782730976740519

Epoch: 6| Step: 6
Training loss: 3.6889796257019043
Validation loss: 3.7783804337183633

Epoch: 6| Step: 7
Training loss: 2.746544599533081
Validation loss: 3.774179776509603

Epoch: 6| Step: 8
Training loss: 2.770840644836426
Validation loss: 3.769851883252462

Epoch: 6| Step: 9
Training loss: 5.120817184448242
Validation loss: 3.765176296234131

Epoch: 6| Step: 10
Training loss: 4.688207149505615
Validation loss: 3.7603551149368286

Epoch: 6| Step: 11
Training loss: 3.0013344287872314
Validation loss: 3.7559046347935996

Epoch: 6| Step: 12
Training loss: 3.7070553302764893
Validation loss: 3.7516693671544394

Epoch: 6| Step: 13
Training loss: 4.753225326538086
Validation loss: 3.7475645939509072

Epoch: 19| Step: 0
Training loss: 3.8478167057037354
Validation loss: 3.742479920387268

Epoch: 6| Step: 1
Training loss: 3.423856496810913
Validation loss: 3.738011201222738

Epoch: 6| Step: 2
Training loss: 4.8476643562316895
Validation loss: 3.733479380607605

Epoch: 6| Step: 3
Training loss: 3.8496227264404297
Validation loss: 3.7295698324839273

Epoch: 6| Step: 4
Training loss: 3.1117196083068848
Validation loss: 3.7253852685292563

Epoch: 6| Step: 5
Training loss: 4.302983283996582
Validation loss: 3.7212241093317666

Epoch: 6| Step: 6
Training loss: 3.672487258911133
Validation loss: 3.7167161305745444

Epoch: 6| Step: 7
Training loss: 2.952089309692383
Validation loss: 3.712421973546346

Epoch: 6| Step: 8
Training loss: 3.4289956092834473
Validation loss: 3.7076894839604697

Epoch: 6| Step: 9
Training loss: 4.660581588745117
Validation loss: 3.7036527395248413

Epoch: 6| Step: 10
Training loss: 4.039000034332275
Validation loss: 3.6993399063746133

Epoch: 6| Step: 11
Training loss: 4.5191802978515625
Validation loss: 3.695657968521118

Epoch: 6| Step: 12
Training loss: 3.9726157188415527
Validation loss: 3.6907224655151367

Epoch: 6| Step: 13
Training loss: 3.6231279373168945
Validation loss: 3.686320145924886

Epoch: 20| Step: 0
Training loss: 4.495375156402588
Validation loss: 3.6817919810613

Epoch: 6| Step: 1
Training loss: 3.6081714630126953
Validation loss: 3.6771841049194336

Epoch: 6| Step: 2
Training loss: 5.03776216506958
Validation loss: 3.6729788780212402

Epoch: 6| Step: 3
Training loss: 4.063142776489258
Validation loss: 3.66762904326121

Epoch: 6| Step: 4
Training loss: 3.3904478549957275
Validation loss: 3.664090951283773

Epoch: 6| Step: 5
Training loss: 3.4960389137268066
Validation loss: 3.658684730529785

Epoch: 6| Step: 6
Training loss: 3.507479667663574
Validation loss: 3.6544461647669473

Epoch: 6| Step: 7
Training loss: 4.044743537902832
Validation loss: 3.649644891421

Epoch: 6| Step: 8
Training loss: 3.9882287979125977
Validation loss: 3.645314892133077

Epoch: 6| Step: 9
Training loss: 3.3689935207366943
Validation loss: 3.6402933597564697

Epoch: 6| Step: 10
Training loss: 3.324625015258789
Validation loss: 3.635682304700216

Epoch: 6| Step: 11
Training loss: 3.9216129779815674
Validation loss: 3.6310376723607383

Epoch: 6| Step: 12
Training loss: 3.753556251525879
Validation loss: 3.6263664166132608

Epoch: 6| Step: 13
Training loss: 3.414823055267334
Validation loss: 3.622254411379496

Epoch: 21| Step: 0
Training loss: 4.981001853942871
Validation loss: 3.6178744633992515

Epoch: 6| Step: 1
Training loss: 4.346714973449707
Validation loss: 3.613022526105245

Epoch: 6| Step: 2
Training loss: 3.4784493446350098
Validation loss: 3.608900268872579

Epoch: 6| Step: 3
Training loss: 2.8239831924438477
Validation loss: 3.6035976012547812

Epoch: 6| Step: 4
Training loss: 3.0411102771759033
Validation loss: 3.5994202693303428

Epoch: 6| Step: 5
Training loss: 3.8644111156463623
Validation loss: 3.5944075187047324

Epoch: 6| Step: 6
Training loss: 4.094046592712402
Validation loss: 3.5906581481297812

Epoch: 6| Step: 7
Training loss: 3.7166547775268555
Validation loss: 3.586100776990255

Epoch: 6| Step: 8
Training loss: 4.4943437576293945
Validation loss: 3.581846594810486

Epoch: 6| Step: 9
Training loss: 4.3441009521484375
Validation loss: 3.577505429585775

Epoch: 6| Step: 10
Training loss: 3.629805564880371
Validation loss: 3.572865088780721

Epoch: 6| Step: 11
Training loss: 2.953087329864502
Validation loss: 3.568057576815287

Epoch: 6| Step: 12
Training loss: 3.4132332801818848
Validation loss: 3.56331729888916

Epoch: 6| Step: 13
Training loss: 3.3672642707824707
Validation loss: 3.5590251684188843

Epoch: 22| Step: 0
Training loss: 4.587204933166504
Validation loss: 3.5545337994893393

Epoch: 6| Step: 1
Training loss: 3.85042667388916
Validation loss: 3.550053437550863

Epoch: 6| Step: 2
Training loss: 4.387181282043457
Validation loss: 3.5454823970794678

Epoch: 6| Step: 3
Training loss: 3.7730069160461426
Validation loss: 3.540539781252543

Epoch: 6| Step: 4
Training loss: 2.709266185760498
Validation loss: 3.536087473233541

Epoch: 6| Step: 5
Training loss: 3.093716621398926
Validation loss: 3.531460404396057

Epoch: 6| Step: 6
Training loss: 3.1695518493652344
Validation loss: 3.526763995488485

Epoch: 6| Step: 7
Training loss: 2.75162410736084
Validation loss: 3.522359291712443

Epoch: 6| Step: 8
Training loss: 3.4599356651306152
Validation loss: 3.5182724793752036

Epoch: 6| Step: 9
Training loss: 3.927236795425415
Validation loss: 3.513868053754171

Epoch: 6| Step: 10
Training loss: 4.290465354919434
Validation loss: 3.5100902318954468

Epoch: 6| Step: 11
Training loss: 3.5485877990722656
Validation loss: 3.5052181482315063

Epoch: 6| Step: 12
Training loss: 4.703928470611572
Validation loss: 3.5006994803746543

Epoch: 6| Step: 13
Training loss: 3.4223384857177734
Validation loss: 3.496065537134806

Epoch: 23| Step: 0
Training loss: 3.0529942512512207
Validation loss: 3.4916911919911704

Epoch: 6| Step: 1
Training loss: 3.761770009994507
Validation loss: 3.4867233832677207

Epoch: 6| Step: 2
Training loss: 3.0150794982910156
Validation loss: 3.4823235273361206

Epoch: 6| Step: 3
Training loss: 2.967705726623535
Validation loss: 3.4774918953577676

Epoch: 6| Step: 4
Training loss: 3.9442811012268066
Validation loss: 3.4732943375905356

Epoch: 6| Step: 5
Training loss: 3.640117645263672
Validation loss: 3.4688393672307334

Epoch: 6| Step: 6
Training loss: 2.6561737060546875
Validation loss: 3.464795629183451

Epoch: 6| Step: 7
Training loss: 3.829169750213623
Validation loss: 3.4605983893076577

Epoch: 6| Step: 8
Training loss: 3.521841049194336
Validation loss: 3.4559146563212075

Epoch: 6| Step: 9
Training loss: 4.610844135284424
Validation loss: 3.4517264366149902

Epoch: 6| Step: 10
Training loss: 3.4609692096710205
Validation loss: 3.446798801422119

Epoch: 6| Step: 11
Training loss: 3.69999098777771
Validation loss: 3.4423763354619346

Epoch: 6| Step: 12
Training loss: 3.8242945671081543
Validation loss: 3.437608520189921

Epoch: 6| Step: 13
Training loss: 4.803680419921875
Validation loss: 3.4328739245732627

Epoch: 24| Step: 0
Training loss: 3.5264687538146973
Validation loss: 3.428412596384684

Epoch: 6| Step: 1
Training loss: 2.7311043739318848
Validation loss: 3.423580765724182

Epoch: 6| Step: 2
Training loss: 2.7549245357513428
Validation loss: 3.4186141093571982

Epoch: 6| Step: 3
Training loss: 3.519043445587158
Validation loss: 3.4139631191889444

Epoch: 6| Step: 4
Training loss: 3.5983529090881348
Validation loss: 3.409259796142578

Epoch: 6| Step: 5
Training loss: 3.274794101715088
Validation loss: 3.404822031656901

Epoch: 6| Step: 6
Training loss: 4.1884613037109375
Validation loss: 3.3996545473734536

Epoch: 6| Step: 7
Training loss: 3.505880117416382
Validation loss: 3.394962469736735

Epoch: 6| Step: 8
Training loss: 4.259282112121582
Validation loss: 3.390364726384481

Epoch: 6| Step: 9
Training loss: 3.3673596382141113
Validation loss: 3.3854867617289224

Epoch: 6| Step: 10
Training loss: 3.9661247730255127
Validation loss: 3.3807046016057334

Epoch: 6| Step: 11
Training loss: 4.101561069488525
Validation loss: 3.37649142742157

Epoch: 6| Step: 12
Training loss: 3.370741605758667
Validation loss: 3.371519128481547

Epoch: 6| Step: 13
Training loss: 3.790196418762207
Validation loss: 3.3667853275934854

Epoch: 25| Step: 0
Training loss: 3.4033100605010986
Validation loss: 3.3628667195638022

Epoch: 6| Step: 1
Training loss: 3.096604824066162
Validation loss: 3.3587230443954468

Epoch: 6| Step: 2
Training loss: 3.3628628253936768
Validation loss: 3.3539817730585733

Epoch: 6| Step: 3
Training loss: 3.6652448177337646
Validation loss: 3.349895437558492

Epoch: 6| Step: 4
Training loss: 3.1794447898864746
Validation loss: 3.3452682495117188

Epoch: 6| Step: 5
Training loss: 3.8658456802368164
Validation loss: 3.341187000274658

Epoch: 6| Step: 6
Training loss: 5.512698173522949
Validation loss: 3.3370092709859214

Epoch: 6| Step: 7
Training loss: 4.221332550048828
Validation loss: 3.332340200742086

Epoch: 6| Step: 8
Training loss: 2.7136166095733643
Validation loss: 3.327418327331543

Epoch: 6| Step: 9
Training loss: 3.070169687271118
Validation loss: 3.323130488395691

Epoch: 6| Step: 10
Training loss: 2.8238070011138916
Validation loss: 3.318235913912455

Epoch: 6| Step: 11
Training loss: 3.8935253620147705
Validation loss: 3.3131147027015686

Epoch: 6| Step: 12
Training loss: 3.044731378555298
Validation loss: 3.3087440729141235

Epoch: 6| Step: 13
Training loss: 3.2315971851348877
Validation loss: 3.304105520248413

Epoch: 26| Step: 0
Training loss: 3.7644453048706055
Validation loss: 3.299527565638224

Epoch: 6| Step: 1
Training loss: 3.6317639350891113
Validation loss: 3.2949816385904946

Epoch: 6| Step: 2
Training loss: 3.7614545822143555
Validation loss: 3.2901848554611206

Epoch: 6| Step: 3
Training loss: 3.7958695888519287
Validation loss: 3.2854976654052734

Epoch: 6| Step: 4
Training loss: 2.5781164169311523
Validation loss: 3.281114180882772

Epoch: 6| Step: 5
Training loss: 3.384328603744507
Validation loss: 3.276552160580953

Epoch: 6| Step: 6
Training loss: 3.0390987396240234
Validation loss: 3.272356073061625

Epoch: 6| Step: 7
Training loss: 3.6760382652282715
Validation loss: 3.2679214080174765

Epoch: 6| Step: 8
Training loss: 3.5361928939819336
Validation loss: 3.2633492946624756

Epoch: 6| Step: 9
Training loss: 3.110130786895752
Validation loss: 3.2591275771458945

Epoch: 6| Step: 10
Training loss: 3.5077219009399414
Validation loss: 3.254570166269938

Epoch: 6| Step: 11
Training loss: 3.54581880569458
Validation loss: 3.2506684064865112

Epoch: 6| Step: 12
Training loss: 3.8046224117279053
Validation loss: 3.2465582688649497

Epoch: 6| Step: 13
Training loss: 3.137937068939209
Validation loss: 3.241706649462382

Epoch: 27| Step: 0
Training loss: 2.9169349670410156
Validation loss: 3.2383995056152344

Epoch: 6| Step: 1
Training loss: 3.290238857269287
Validation loss: 3.232629140218099

Epoch: 6| Step: 2
Training loss: 4.046753883361816
Validation loss: 3.2299077113469443

Epoch: 6| Step: 3
Training loss: 3.7413294315338135
Validation loss: 3.2259298960367837

Epoch: 6| Step: 4
Training loss: 3.3069353103637695
Validation loss: 3.2210978269577026

Epoch: 6| Step: 5
Training loss: 3.3031957149505615
Validation loss: 3.2175405422846475

Epoch: 6| Step: 6
Training loss: 2.6653385162353516
Validation loss: 3.213731606801351

Epoch: 6| Step: 7
Training loss: 2.6577095985412598
Validation loss: 3.2087460358937583

Epoch: 6| Step: 8
Training loss: 3.533461093902588
Validation loss: 3.2048882643381753

Epoch: 6| Step: 9
Training loss: 3.444127082824707
Validation loss: 3.200521389643351

Epoch: 6| Step: 10
Training loss: 4.6127424240112305
Validation loss: 3.196255008379618

Epoch: 6| Step: 11
Training loss: 3.5043296813964844
Validation loss: 3.1915238300959268

Epoch: 6| Step: 12
Training loss: 3.137721061706543
Validation loss: 3.1869364976882935

Epoch: 6| Step: 13
Training loss: 3.2869741916656494
Validation loss: 3.182721416155497

Epoch: 28| Step: 0
Training loss: 3.2719502449035645
Validation loss: 3.1774010260899863

Epoch: 6| Step: 1
Training loss: 2.5685620307922363
Validation loss: 3.1735086838404336

Epoch: 6| Step: 2
Training loss: 2.479055166244507
Validation loss: 3.1694308121999106

Epoch: 6| Step: 3
Training loss: 4.086236953735352
Validation loss: 3.1637694438298545

Epoch: 6| Step: 4
Training loss: 3.2890617847442627
Validation loss: 3.159624139467875

Epoch: 6| Step: 5
Training loss: 3.5192792415618896
Validation loss: 3.155531644821167

Epoch: 6| Step: 6
Training loss: 2.845599412918091
Validation loss: 3.1512717405954995

Epoch: 6| Step: 7
Training loss: 3.3441669940948486
Validation loss: 3.147034525871277

Epoch: 6| Step: 8
Training loss: 3.6033473014831543
Validation loss: 3.142803112665812

Epoch: 6| Step: 9
Training loss: 3.1888983249664307
Validation loss: 3.138800342877706

Epoch: 6| Step: 10
Training loss: 4.59747314453125
Validation loss: 3.1343102057774863

Epoch: 6| Step: 11
Training loss: 3.125493049621582
Validation loss: 3.1301071643829346

Epoch: 6| Step: 12
Training loss: 2.949803352355957
Validation loss: 3.125314474105835

Epoch: 6| Step: 13
Training loss: 3.814227342605591
Validation loss: 3.12129799524943

Epoch: 29| Step: 0
Training loss: 3.2735233306884766
Validation loss: 3.116705536842346

Epoch: 6| Step: 1
Training loss: 3.175508499145508
Validation loss: 3.112500866254171

Epoch: 6| Step: 2
Training loss: 2.784332036972046
Validation loss: 3.107277433077494

Epoch: 6| Step: 3
Training loss: 3.2066028118133545
Validation loss: 3.1031140089035034

Epoch: 6| Step: 4
Training loss: 3.5797348022460938
Validation loss: 3.098649501800537

Epoch: 6| Step: 5
Training loss: 3.228947877883911
Validation loss: 3.0945894718170166

Epoch: 6| Step: 6
Training loss: 2.7457962036132812
Validation loss: 3.0901684363683066

Epoch: 6| Step: 7
Training loss: 3.3127951622009277
Validation loss: 3.0863919258117676

Epoch: 6| Step: 8
Training loss: 2.5880072116851807
Validation loss: 3.0821670293807983

Epoch: 6| Step: 9
Training loss: 3.606131076812744
Validation loss: 3.0783483584721885

Epoch: 6| Step: 10
Training loss: 2.9485208988189697
Validation loss: 3.0746633211771646

Epoch: 6| Step: 11
Training loss: 3.841275691986084
Validation loss: 3.0709077517191568

Epoch: 6| Step: 12
Training loss: 3.8472323417663574
Validation loss: 3.0670737425486245

Epoch: 6| Step: 13
Training loss: 3.7442615032196045
Validation loss: 3.0629194180170694

Epoch: 30| Step: 0
Training loss: 3.2282073497772217
Validation loss: 3.058208187421163

Epoch: 6| Step: 1
Training loss: 3.2632923126220703
Validation loss: 3.0541698932647705

Epoch: 6| Step: 2
Training loss: 3.431011199951172
Validation loss: 3.050166646639506

Epoch: 6| Step: 3
Training loss: 2.297438621520996
Validation loss: 3.046454747517904

Epoch: 6| Step: 4
Training loss: 3.1319313049316406
Validation loss: 3.0420462687810264

Epoch: 6| Step: 5
Training loss: 3.25844669342041
Validation loss: 3.037904977798462

Epoch: 6| Step: 6
Training loss: 3.2868566513061523
Validation loss: 3.0348993937174478

Epoch: 6| Step: 7
Training loss: 3.171772003173828
Validation loss: 3.03044859568278

Epoch: 6| Step: 8
Training loss: 2.7507123947143555
Validation loss: 3.026317755381266

Epoch: 6| Step: 9
Training loss: 3.072552442550659
Validation loss: 3.0234551429748535

Epoch: 6| Step: 10
Training loss: 4.1487016677856445
Validation loss: 3.0199892123540244

Epoch: 6| Step: 11
Training loss: 3.5618042945861816
Validation loss: 3.0158340533574424

Epoch: 6| Step: 12
Training loss: 3.396110773086548
Validation loss: 3.0129371086756387

Epoch: 6| Step: 13
Training loss: 3.160651683807373
Validation loss: 3.0246233145395913

Epoch: 31| Step: 0
Training loss: 2.831718921661377
Validation loss: 3.0018622477849326

Epoch: 6| Step: 1
Training loss: 3.2063918113708496
Validation loss: 3.0083234707514444

Epoch: 6| Step: 2
Training loss: 3.140174388885498
Validation loss: 3.003143866856893

Epoch: 6| Step: 3
Training loss: 3.286843776702881
Validation loss: 3.0023686488469443

Epoch: 6| Step: 4
Training loss: 3.7607626914978027
Validation loss: 2.9985830386479697

Epoch: 6| Step: 5
Training loss: 2.4326913356781006
Validation loss: 2.993459423383077

Epoch: 6| Step: 6
Training loss: 2.9860363006591797
Validation loss: 2.988853851954142

Epoch: 6| Step: 7
Training loss: 3.5298256874084473
Validation loss: 2.9850767453511557

Epoch: 6| Step: 8
Training loss: 2.938734292984009
Validation loss: 2.9816830158233643

Epoch: 6| Step: 9
Training loss: 4.37034797668457
Validation loss: 2.9746139446894326

Epoch: 6| Step: 10
Training loss: 3.5930418968200684
Validation loss: 2.9676828384399414

Epoch: 6| Step: 11
Training loss: 3.282176971435547
Validation loss: 2.9624127546946206

Epoch: 6| Step: 12
Training loss: 2.2961208820343018
Validation loss: 2.9578435023625693

Epoch: 6| Step: 13
Training loss: 2.892122268676758
Validation loss: 2.9536707401275635

Epoch: 32| Step: 0
Training loss: 3.159574031829834
Validation loss: 2.950505336125692

Epoch: 6| Step: 1
Training loss: 2.6895108222961426
Validation loss: 2.944437583287557

Epoch: 6| Step: 2
Training loss: 2.62229585647583
Validation loss: 2.9391517639160156

Epoch: 6| Step: 3
Training loss: 3.296891689300537
Validation loss: 2.934373458226522

Epoch: 6| Step: 4
Training loss: 3.666837692260742
Validation loss: 2.929933230082194

Epoch: 6| Step: 5
Training loss: 4.145517349243164
Validation loss: 2.925872008005778

Epoch: 6| Step: 6
Training loss: 3.03444242477417
Validation loss: 2.9213924407958984

Epoch: 6| Step: 7
Training loss: 2.977680206298828
Validation loss: 2.917584697405497

Epoch: 6| Step: 8
Training loss: 3.0105538368225098
Validation loss: 2.913004994392395

Epoch: 6| Step: 9
Training loss: 3.1521825790405273
Validation loss: 2.909460703531901

Epoch: 6| Step: 10
Training loss: 2.7457785606384277
Validation loss: 2.905651648839315

Epoch: 6| Step: 11
Training loss: 3.0291225910186768
Validation loss: 2.9014302094777427

Epoch: 6| Step: 12
Training loss: 3.0523884296417236
Validation loss: 2.8973772128423056

Epoch: 6| Step: 13
Training loss: 3.178840160369873
Validation loss: 2.8933956225713096

Epoch: 33| Step: 0
Training loss: 3.3241257667541504
Validation loss: 2.889668067296346

Epoch: 6| Step: 1
Training loss: 3.0223145484924316
Validation loss: 2.886328101158142

Epoch: 6| Step: 2
Training loss: 2.9136228561401367
Validation loss: 2.8823894262313843

Epoch: 6| Step: 3
Training loss: 3.297316312789917
Validation loss: 2.8783069451649985

Epoch: 6| Step: 4
Training loss: 3.6098217964172363
Validation loss: 2.8741175333658853

Epoch: 6| Step: 5
Training loss: 2.8060288429260254
Validation loss: 2.8708204428354898

Epoch: 6| Step: 6
Training loss: 3.4788479804992676
Validation loss: 2.866987705230713

Epoch: 6| Step: 7
Training loss: 2.3254382610321045
Validation loss: 2.8633987506230674

Epoch: 6| Step: 8
Training loss: 3.457437515258789
Validation loss: 2.86014731725057

Epoch: 6| Step: 9
Training loss: 3.2905337810516357
Validation loss: 2.8563032150268555

Epoch: 6| Step: 10
Training loss: 3.2634103298187256
Validation loss: 2.852940042813619

Epoch: 6| Step: 11
Training loss: 2.7890372276306152
Validation loss: 2.848619063695272

Epoch: 6| Step: 12
Training loss: 2.5905208587646484
Validation loss: 2.845523158709208

Epoch: 6| Step: 13
Training loss: 2.88673996925354
Validation loss: 2.8468647400538125

Epoch: 34| Step: 0
Training loss: 2.31828236579895
Validation loss: 2.8430830240249634

Epoch: 6| Step: 1
Training loss: 3.2064685821533203
Validation loss: 2.8443082173665366

Epoch: 6| Step: 2
Training loss: 3.2058005332946777
Validation loss: 2.8320714235305786

Epoch: 6| Step: 3
Training loss: 3.7833876609802246
Validation loss: 2.827644109725952

Epoch: 6| Step: 4
Training loss: 2.904848098754883
Validation loss: 2.823510726292928

Epoch: 6| Step: 5
Training loss: 3.6851913928985596
Validation loss: 2.8200267950693765

Epoch: 6| Step: 6
Training loss: 3.1475865840911865
Validation loss: 2.816484729448954

Epoch: 6| Step: 7
Training loss: 2.9112091064453125
Validation loss: 2.8128434816996255

Epoch: 6| Step: 8
Training loss: 2.5847058296203613
Validation loss: 2.809467911720276

Epoch: 6| Step: 9
Training loss: 2.5530800819396973
Validation loss: 2.805905024210612

Epoch: 6| Step: 10
Training loss: 2.6058053970336914
Validation loss: 2.802759289741516

Epoch: 6| Step: 11
Training loss: 3.435586452484131
Validation loss: 2.7999120950698853

Epoch: 6| Step: 12
Training loss: 3.4154531955718994
Validation loss: 2.7966487407684326

Epoch: 6| Step: 13
Training loss: 2.6747634410858154
Validation loss: 2.792970816294352

Epoch: 35| Step: 0
Training loss: 2.5052802562713623
Validation loss: 2.7898064851760864

Epoch: 6| Step: 1
Training loss: 2.6495087146759033
Validation loss: 2.7869639794031777

Epoch: 6| Step: 2
Training loss: 3.3620100021362305
Validation loss: 2.783822536468506

Epoch: 6| Step: 3
Training loss: 3.0052990913391113
Validation loss: 2.7806455294291177

Epoch: 6| Step: 4
Training loss: 3.197535991668701
Validation loss: 2.777498026688894

Epoch: 6| Step: 5
Training loss: 3.505155563354492
Validation loss: 2.7744397719701133

Epoch: 6| Step: 6
Training loss: 3.072983741760254
Validation loss: 2.771154522895813

Epoch: 6| Step: 7
Training loss: 2.478785514831543
Validation loss: 2.767915685971578

Epoch: 6| Step: 8
Training loss: 3.137904644012451
Validation loss: 2.7647511959075928

Epoch: 6| Step: 9
Training loss: 2.779367208480835
Validation loss: 2.761590321858724

Epoch: 6| Step: 10
Training loss: 3.3684842586517334
Validation loss: 2.758273442586263

Epoch: 6| Step: 11
Training loss: 3.1453323364257812
Validation loss: 2.755087455113729

Epoch: 6| Step: 12
Training loss: 2.6810503005981445
Validation loss: 2.7518604596455893

Epoch: 6| Step: 13
Training loss: 2.8497557640075684
Validation loss: 2.7485957543055215

Epoch: 36| Step: 0
Training loss: 2.9175796508789062
Validation loss: 2.7453998724619546

Epoch: 6| Step: 1
Training loss: 2.8889882564544678
Validation loss: 2.7422478993733725

Epoch: 6| Step: 2
Training loss: 3.1079556941986084
Validation loss: 2.738947073618571

Epoch: 6| Step: 3
Training loss: 3.00527024269104
Validation loss: 2.735335866610209

Epoch: 6| Step: 4
Training loss: 3.009376049041748
Validation loss: 2.7323211828867593

Epoch: 6| Step: 5
Training loss: 2.5158615112304688
Validation loss: 2.7288852532704673

Epoch: 6| Step: 6
Training loss: 3.3430275917053223
Validation loss: 2.7255977392196655

Epoch: 6| Step: 7
Training loss: 3.3981759548187256
Validation loss: 2.7221537828445435

Epoch: 6| Step: 8
Training loss: 2.946415901184082
Validation loss: 2.7191903988520303

Epoch: 6| Step: 9
Training loss: 2.8359553813934326
Validation loss: 2.7160624663035073

Epoch: 6| Step: 10
Training loss: 2.4793572425842285
Validation loss: 2.71269420782725

Epoch: 6| Step: 11
Training loss: 2.9757843017578125
Validation loss: 2.7096643447875977

Epoch: 6| Step: 12
Training loss: 2.86501407623291
Validation loss: 2.7064878940582275

Epoch: 6| Step: 13
Training loss: 2.7930212020874023
Validation loss: 2.7033259073893228

Epoch: 37| Step: 0
Training loss: 3.142733097076416
Validation loss: 2.699758529663086

Epoch: 6| Step: 1
Training loss: 2.371623992919922
Validation loss: 2.696787198384603

Epoch: 6| Step: 2
Training loss: 2.5059597492218018
Validation loss: 2.6938292582829795

Epoch: 6| Step: 3
Training loss: 2.945496082305908
Validation loss: 2.6908101240793862

Epoch: 6| Step: 4
Training loss: 3.5982820987701416
Validation loss: 2.6877005894978843

Epoch: 6| Step: 5
Training loss: 3.330554723739624
Validation loss: 2.6846171617507935

Epoch: 6| Step: 6
Training loss: 2.843885898590088
Validation loss: 2.6813189586003623

Epoch: 6| Step: 7
Training loss: 3.4871621131896973
Validation loss: 2.677915334701538

Epoch: 6| Step: 8
Training loss: 2.8304967880249023
Validation loss: 2.674315651257833

Epoch: 6| Step: 9
Training loss: 3.0974860191345215
Validation loss: 2.669618765513102

Epoch: 6| Step: 10
Training loss: 2.8435990810394287
Validation loss: 2.6668510834376016

Epoch: 6| Step: 11
Training loss: 2.471228837966919
Validation loss: 2.6633392572402954

Epoch: 6| Step: 12
Training loss: 2.0468995571136475
Validation loss: 2.6598548094431558

Epoch: 6| Step: 13
Training loss: 2.878539562225342
Validation loss: 2.657551646232605

Epoch: 38| Step: 0
Training loss: 3.26985502243042
Validation loss: 2.6539798378944397

Epoch: 6| Step: 1
Training loss: 2.3301844596862793
Validation loss: 2.6493080854415894

Epoch: 6| Step: 2
Training loss: 2.879804849624634
Validation loss: 2.6476688385009766

Epoch: 6| Step: 3
Training loss: 2.3515970706939697
Validation loss: 2.6424639225006104

Epoch: 6| Step: 4
Training loss: 2.7453784942626953
Validation loss: 2.640783747037252

Epoch: 6| Step: 5
Training loss: 2.2435829639434814
Validation loss: 2.636471152305603

Epoch: 6| Step: 6
Training loss: 3.051989793777466
Validation loss: 2.632913033167521

Epoch: 6| Step: 7
Training loss: 2.464761257171631
Validation loss: 2.6296682357788086

Epoch: 6| Step: 8
Training loss: 2.930468797683716
Validation loss: 2.6262043118476868

Epoch: 6| Step: 9
Training loss: 3.351139545440674
Validation loss: 2.6227746407190957

Epoch: 6| Step: 10
Training loss: 3.0395140647888184
Validation loss: 2.6200398802757263

Epoch: 6| Step: 11
Training loss: 3.1107168197631836
Validation loss: 2.6180004278818765

Epoch: 6| Step: 12
Training loss: 2.8854167461395264
Validation loss: 2.612359642982483

Epoch: 6| Step: 13
Training loss: 3.0668282508850098
Validation loss: 2.609748125076294

Epoch: 39| Step: 0
Training loss: 2.2560153007507324
Validation loss: 2.6058088342348733

Epoch: 6| Step: 1
Training loss: 2.6178529262542725
Validation loss: 2.602679888407389

Epoch: 6| Step: 2
Training loss: 3.5090527534484863
Validation loss: 2.5995200872421265

Epoch: 6| Step: 3
Training loss: 3.4619619846343994
Validation loss: 2.596662998199463

Epoch: 6| Step: 4
Training loss: 3.4271693229675293
Validation loss: 2.5927667220433555

Epoch: 6| Step: 5
Training loss: 2.0684380531311035
Validation loss: 2.5902576049168906

Epoch: 6| Step: 6
Training loss: 2.5672311782836914
Validation loss: 2.585831622282664

Epoch: 6| Step: 7
Training loss: 3.035341739654541
Validation loss: 2.583906968434652

Epoch: 6| Step: 8
Training loss: 2.4677364826202393
Validation loss: 2.578987240791321

Epoch: 6| Step: 9
Training loss: 2.918940305709839
Validation loss: 2.5763832926750183

Epoch: 6| Step: 10
Training loss: 3.189312219619751
Validation loss: 2.5736266374588013

Epoch: 6| Step: 11
Training loss: 2.686060667037964
Validation loss: 2.5709543426831565

Epoch: 6| Step: 12
Training loss: 2.4936130046844482
Validation loss: 2.5680589278539023

Epoch: 6| Step: 13
Training loss: 2.3297431468963623
Validation loss: 2.5649556716283164

Epoch: 40| Step: 0
Training loss: 2.066939353942871
Validation loss: 2.5618093013763428

Epoch: 6| Step: 1
Training loss: 2.80430006980896
Validation loss: 2.5602301359176636

Epoch: 6| Step: 2
Training loss: 2.3976917266845703
Validation loss: 2.556987682978312

Epoch: 6| Step: 3
Training loss: 2.580643653869629
Validation loss: 2.553515632947286

Epoch: 6| Step: 4
Training loss: 2.8964829444885254
Validation loss: 2.558311661084493

Epoch: 6| Step: 5
Training loss: 3.4008593559265137
Validation loss: 2.560779412587484

Epoch: 6| Step: 6
Training loss: 2.7509522438049316
Validation loss: 2.5511026779810586

Epoch: 6| Step: 7
Training loss: 2.1763527393341064
Validation loss: 2.545247753461202

Epoch: 6| Step: 8
Training loss: 3.003588914871216
Validation loss: 2.543943166732788

Epoch: 6| Step: 9
Training loss: 2.725432872772217
Validation loss: 2.543878674507141

Epoch: 6| Step: 10
Training loss: 3.2691309452056885
Validation loss: 2.544859608014425

Epoch: 6| Step: 11
Training loss: 2.6192445755004883
Validation loss: 2.5605250199635825

Epoch: 6| Step: 12
Training loss: 2.706514835357666
Validation loss: 2.5386079947153726

Epoch: 6| Step: 13
Training loss: 3.0267128944396973
Validation loss: 2.5362720489501953

Epoch: 41| Step: 0
Training loss: 3.6980605125427246
Validation loss: 2.5340455770492554

Epoch: 6| Step: 1
Training loss: 2.991595983505249
Validation loss: 2.530282815297445

Epoch: 6| Step: 2
Training loss: 2.499110221862793
Validation loss: 2.526464561621348

Epoch: 6| Step: 3
Training loss: 2.287886619567871
Validation loss: 2.5225053826967874

Epoch: 6| Step: 4
Training loss: 2.4572906494140625
Validation loss: 2.519896149635315

Epoch: 6| Step: 5
Training loss: 2.570864200592041
Validation loss: 2.5172168811162314

Epoch: 6| Step: 6
Training loss: 2.3134841918945312
Validation loss: 2.514576256275177

Epoch: 6| Step: 7
Training loss: 2.1770637035369873
Validation loss: 2.510244051615397

Epoch: 6| Step: 8
Training loss: 2.6763110160827637
Validation loss: 2.507644454638163

Epoch: 6| Step: 9
Training loss: 2.98337459564209
Validation loss: 2.5022382736206055

Epoch: 6| Step: 10
Training loss: 2.506826639175415
Validation loss: 2.496415932973226

Epoch: 6| Step: 11
Training loss: 2.6451640129089355
Validation loss: 2.491804520289103

Epoch: 6| Step: 12
Training loss: 3.230705738067627
Validation loss: 2.487906018892924

Epoch: 6| Step: 13
Training loss: 2.865756034851074
Validation loss: 2.485868811607361

Epoch: 42| Step: 0
Training loss: 3.190436363220215
Validation loss: 2.4837931791941323

Epoch: 6| Step: 1
Training loss: 2.6063995361328125
Validation loss: 2.4803502559661865

Epoch: 6| Step: 2
Training loss: 2.6383399963378906
Validation loss: 2.477123181025187

Epoch: 6| Step: 3
Training loss: 2.7718629837036133
Validation loss: 2.4739414056142173

Epoch: 6| Step: 4
Training loss: 2.074164867401123
Validation loss: 2.4706526001294455

Epoch: 6| Step: 5
Training loss: 2.715853691101074
Validation loss: 2.4668763081232705

Epoch: 6| Step: 6
Training loss: 2.8286685943603516
Validation loss: 2.4645711183547974

Epoch: 6| Step: 7
Training loss: 2.399472713470459
Validation loss: 2.4586662451426187

Epoch: 6| Step: 8
Training loss: 2.654423713684082
Validation loss: 2.4555331071217856

Epoch: 6| Step: 9
Training loss: 2.8701539039611816
Validation loss: 2.4529624780019126

Epoch: 6| Step: 10
Training loss: 2.5007572174072266
Validation loss: 2.4519872665405273

Epoch: 6| Step: 11
Training loss: 3.2530016899108887
Validation loss: 2.4469743569691977

Epoch: 6| Step: 12
Training loss: 2.348371982574463
Validation loss: 2.4498650232950845

Epoch: 6| Step: 13
Training loss: 2.323564052581787
Validation loss: 2.4421887000401816

Epoch: 43| Step: 0
Training loss: 2.7341394424438477
Validation loss: 2.439016858736674

Epoch: 6| Step: 1
Training loss: 2.669461250305176
Validation loss: 2.43723201751709

Epoch: 6| Step: 2
Training loss: 2.6181418895721436
Validation loss: 2.4349438746770224

Epoch: 6| Step: 3
Training loss: 2.563537836074829
Validation loss: 2.433139463265737

Epoch: 6| Step: 4
Training loss: 2.8721420764923096
Validation loss: 2.4311503767967224

Epoch: 6| Step: 5
Training loss: 2.400524616241455
Validation loss: 2.4279938538869223

Epoch: 6| Step: 6
Training loss: 2.962661027908325
Validation loss: 2.426116863886515

Epoch: 6| Step: 7
Training loss: 1.894388198852539
Validation loss: 2.4231922229131064

Epoch: 6| Step: 8
Training loss: 2.612915277481079
Validation loss: 2.4205168883005777

Epoch: 6| Step: 9
Training loss: 2.2851407527923584
Validation loss: 2.4176342686017356

Epoch: 6| Step: 10
Training loss: 3.187530040740967
Validation loss: 2.4149532318115234

Epoch: 6| Step: 11
Training loss: 3.094028949737549
Validation loss: 2.4124611616134644

Epoch: 6| Step: 12
Training loss: 2.6695218086242676
Validation loss: 2.4093205531438193

Epoch: 6| Step: 13
Training loss: 1.94472336769104
Validation loss: 2.4066543181737265

Epoch: 44| Step: 0
Training loss: 2.6377320289611816
Validation loss: 2.403881788253784

Epoch: 6| Step: 1
Training loss: 2.704951763153076
Validation loss: 2.4014487663904824

Epoch: 6| Step: 2
Training loss: 2.7764382362365723
Validation loss: 2.3987712065378823

Epoch: 6| Step: 3
Training loss: 2.4575612545013428
Validation loss: 2.3954302867253623

Epoch: 6| Step: 4
Training loss: 2.271170139312744
Validation loss: 2.3929051558176675

Epoch: 6| Step: 5
Training loss: 2.4109811782836914
Validation loss: 2.3899325132369995

Epoch: 6| Step: 6
Training loss: 3.2404279708862305
Validation loss: 2.386658032735189

Epoch: 6| Step: 7
Training loss: 1.8556499481201172
Validation loss: 2.3838117321332297

Epoch: 6| Step: 8
Training loss: 2.3347787857055664
Validation loss: 2.3794517517089844

Epoch: 6| Step: 9
Training loss: 2.9731695652008057
Validation loss: 2.377742052078247

Epoch: 6| Step: 10
Training loss: 2.9556522369384766
Validation loss: 2.3738995790481567

Epoch: 6| Step: 11
Training loss: 2.218999147415161
Validation loss: 2.3718745708465576

Epoch: 6| Step: 12
Training loss: 2.367771625518799
Validation loss: 2.3688804109891257

Epoch: 6| Step: 13
Training loss: 2.729861259460449
Validation loss: 2.36344184478124

Epoch: 45| Step: 0
Training loss: 2.1772007942199707
Validation loss: 2.3635416428248086

Epoch: 6| Step: 1
Training loss: 3.058861255645752
Validation loss: 2.3601077795028687

Epoch: 6| Step: 2
Training loss: 2.4824132919311523
Validation loss: 2.356959879398346

Epoch: 6| Step: 3
Training loss: 2.5575625896453857
Validation loss: 2.355432629585266

Epoch: 6| Step: 4
Training loss: 2.6258058547973633
Validation loss: 2.3531781435012817

Epoch: 6| Step: 5
Training loss: 2.3791747093200684
Validation loss: 2.350371539592743

Epoch: 6| Step: 6
Training loss: 1.8313313722610474
Validation loss: 2.3494343757629395

Epoch: 6| Step: 7
Training loss: 3.063770294189453
Validation loss: 2.3466599186261496

Epoch: 6| Step: 8
Training loss: 2.630380630493164
Validation loss: 2.343217055002848

Epoch: 6| Step: 9
Training loss: 2.526837110519409
Validation loss: 2.34135365486145

Epoch: 6| Step: 10
Training loss: 2.9096152782440186
Validation loss: 2.340415676434835

Epoch: 6| Step: 11
Training loss: 2.1104118824005127
Validation loss: 2.336101849873861

Epoch: 6| Step: 12
Training loss: 2.359361171722412
Validation loss: 2.334465583165487

Epoch: 6| Step: 13
Training loss: 2.592731475830078
Validation loss: 2.3329442143440247

Epoch: 46| Step: 0
Training loss: 2.3783318996429443
Validation loss: 2.3305305441220603

Epoch: 6| Step: 1
Training loss: 2.372361660003662
Validation loss: 2.329320947329203

Epoch: 6| Step: 2
Training loss: 2.461848258972168
Validation loss: 2.3248157501220703

Epoch: 6| Step: 3
Training loss: 2.5434627532958984
Validation loss: 2.322433888912201

Epoch: 6| Step: 4
Training loss: 2.313049793243408
Validation loss: 2.3194753328959146

Epoch: 6| Step: 5
Training loss: 2.4368858337402344
Validation loss: 2.3175098498662314

Epoch: 6| Step: 6
Training loss: 2.4993109703063965
Validation loss: 2.3147505124409995

Epoch: 6| Step: 7
Training loss: 2.7551374435424805
Validation loss: 2.3117847243944802

Epoch: 6| Step: 8
Training loss: 2.761975049972534
Validation loss: 2.3067789872487388

Epoch: 6| Step: 9
Training loss: 2.933602809906006
Validation loss: 2.304122805595398

Epoch: 6| Step: 10
Training loss: 2.74699068069458
Validation loss: 2.301067034403483

Epoch: 6| Step: 11
Training loss: 2.141411781311035
Validation loss: 2.2982680400212607

Epoch: 6| Step: 12
Training loss: 2.0322887897491455
Validation loss: 2.296321213245392

Epoch: 6| Step: 13
Training loss: 2.399944305419922
Validation loss: 2.2978367805480957

Epoch: 47| Step: 0
Training loss: 1.904096007347107
Validation loss: 2.292497158050537

Epoch: 6| Step: 1
Training loss: 2.598493814468384
Validation loss: 2.2907570203145347

Epoch: 6| Step: 2
Training loss: 1.9980151653289795
Validation loss: 2.2876657247543335

Epoch: 6| Step: 3
Training loss: 3.1811509132385254
Validation loss: 2.286034027735392

Epoch: 6| Step: 4
Training loss: 2.009770154953003
Validation loss: 2.286309758822123

Epoch: 6| Step: 5
Training loss: 2.7808408737182617
Validation loss: 2.2833436926205954

Epoch: 6| Step: 6
Training loss: 2.7911393642425537
Validation loss: 2.2818299333254495

Epoch: 6| Step: 7
Training loss: 2.594357967376709
Validation loss: 2.280455152193705

Epoch: 6| Step: 8
Training loss: 2.282348394393921
Validation loss: 2.2789265712102256

Epoch: 6| Step: 9
Training loss: 2.832444190979004
Validation loss: 2.275642911593119

Epoch: 6| Step: 10
Training loss: 2.214352607727051
Validation loss: 2.2749520738919577

Epoch: 6| Step: 11
Training loss: 1.9103106260299683
Validation loss: 2.2729812463124595

Epoch: 6| Step: 12
Training loss: 2.714435338973999
Validation loss: 2.270765542984009

Epoch: 6| Step: 13
Training loss: 2.413032293319702
Validation loss: 2.267819027105967

Epoch: 48| Step: 0
Training loss: 2.436168670654297
Validation loss: 2.2644948164621987

Epoch: 6| Step: 1
Training loss: 2.5848522186279297
Validation loss: 2.2601915200551352

Epoch: 6| Step: 2
Training loss: 2.12557315826416
Validation loss: 2.2587928573290506

Epoch: 6| Step: 3
Training loss: 2.040238380432129
Validation loss: 2.2539764444033303

Epoch: 6| Step: 4
Training loss: 2.5495753288269043
Validation loss: 2.250978410243988

Epoch: 6| Step: 5
Training loss: 2.6569275856018066
Validation loss: 2.247525990009308

Epoch: 6| Step: 6
Training loss: 2.7846438884735107
Validation loss: 2.2425976196924844

Epoch: 6| Step: 7
Training loss: 2.163067579269409
Validation loss: 2.2372463742891946

Epoch: 6| Step: 8
Training loss: 2.4253220558166504
Validation loss: 2.235455314318339

Epoch: 6| Step: 9
Training loss: 2.063727855682373
Validation loss: 2.2322422862052917

Epoch: 6| Step: 10
Training loss: 2.5876739025115967
Validation loss: 2.2319172620773315

Epoch: 6| Step: 11
Training loss: 2.443258285522461
Validation loss: 2.227165242036184

Epoch: 6| Step: 12
Training loss: 2.4382009506225586
Validation loss: 2.2302560011545816

Epoch: 6| Step: 13
Training loss: 2.5029168128967285
Validation loss: 2.2319023609161377

Epoch: 49| Step: 0
Training loss: 2.521803855895996
Validation loss: 2.231494903564453

Epoch: 6| Step: 1
Training loss: 2.5469846725463867
Validation loss: 2.231406092643738

Epoch: 6| Step: 2
Training loss: 2.0381884574890137
Validation loss: 2.2318254311879477

Epoch: 6| Step: 3
Training loss: 2.31033992767334
Validation loss: 2.231871247291565

Epoch: 6| Step: 4
Training loss: 2.5716328620910645
Validation loss: 2.2304717898368835

Epoch: 6| Step: 5
Training loss: 2.092550754547119
Validation loss: 2.2301053206125894

Epoch: 6| Step: 6
Training loss: 2.738400459289551
Validation loss: 2.2288461327552795

Epoch: 6| Step: 7
Training loss: 2.29770827293396
Validation loss: 2.2262393633524575

Epoch: 6| Step: 8
Training loss: 2.412771463394165
Validation loss: 2.2245609561602273

Epoch: 6| Step: 9
Training loss: 2.700697898864746
Validation loss: 2.224207957585653

Epoch: 6| Step: 10
Training loss: 1.4380444288253784
Validation loss: 2.2226572831471763

Epoch: 6| Step: 11
Training loss: 2.7137060165405273
Validation loss: 2.220587452252706

Epoch: 6| Step: 12
Training loss: 2.315575122833252
Validation loss: 2.2197118997573853

Epoch: 6| Step: 13
Training loss: 2.699889898300171
Validation loss: 2.2177052895228067

Epoch: 50| Step: 0
Training loss: 2.3660058975219727
Validation loss: 2.214621106783549

Epoch: 6| Step: 1
Training loss: 2.3626160621643066
Validation loss: 2.212373415629069

Epoch: 6| Step: 2
Training loss: 2.1503565311431885
Validation loss: 2.209909359614054

Epoch: 6| Step: 3
Training loss: 1.7613946199417114
Validation loss: 2.2078454891840615

Epoch: 6| Step: 4
Training loss: 2.8607983589172363
Validation loss: 2.204926331837972

Epoch: 6| Step: 5
Training loss: 2.5694684982299805
Validation loss: 2.2023825645446777

Epoch: 6| Step: 6
Training loss: 2.9611258506774902
Validation loss: 2.2015772263209024

Epoch: 6| Step: 7
Training loss: 2.133660316467285
Validation loss: 2.1987147132555642

Epoch: 6| Step: 8
Training loss: 2.9975128173828125
Validation loss: 2.1952069997787476

Epoch: 6| Step: 9
Training loss: 2.469101667404175
Validation loss: 2.194972594579061

Epoch: 6| Step: 10
Training loss: 1.7354453802108765
Validation loss: 2.1915242870648703

Epoch: 6| Step: 11
Training loss: 2.065565586090088
Validation loss: 2.189415454864502

Epoch: 6| Step: 12
Training loss: 1.9962916374206543
Validation loss: 2.1858082016309104

Epoch: 6| Step: 13
Training loss: 2.681154727935791
Validation loss: 2.1834919651349387

Epoch: 51| Step: 0
Training loss: 2.3496339321136475
Validation loss: 2.1795403560002646

Epoch: 6| Step: 1
Training loss: 2.6788856983184814
Validation loss: 2.1781006256739297

Epoch: 6| Step: 2
Training loss: 2.259439468383789
Validation loss: 2.170122186342875

Epoch: 6| Step: 3
Training loss: 2.2788257598876953
Validation loss: 2.1719281673431396

Epoch: 6| Step: 4
Training loss: 2.3849687576293945
Validation loss: 2.167632778485616

Epoch: 6| Step: 5
Training loss: 2.625016212463379
Validation loss: 2.1642590959866843

Epoch: 6| Step: 6
Training loss: 2.418976306915283
Validation loss: 2.166275064150492

Epoch: 6| Step: 7
Training loss: 2.0291011333465576
Validation loss: 2.163055161635081

Epoch: 6| Step: 8
Training loss: 2.242058753967285
Validation loss: 2.1593751907348633

Epoch: 6| Step: 9
Training loss: 2.6626086235046387
Validation loss: 2.1588670214017234

Epoch: 6| Step: 10
Training loss: 2.166043281555176
Validation loss: 2.1680886149406433

Epoch: 6| Step: 11
Training loss: 2.4360804557800293
Validation loss: 2.172805647055308

Epoch: 6| Step: 12
Training loss: 1.9955015182495117
Validation loss: 2.170601765314738

Epoch: 6| Step: 13
Training loss: 2.2870588302612305
Validation loss: 2.1634743412335715

Epoch: 52| Step: 0
Training loss: 2.342392683029175
Validation loss: 2.1603709856669107

Epoch: 6| Step: 1
Training loss: 2.4334163665771484
Validation loss: 2.160545368989309

Epoch: 6| Step: 2
Training loss: 2.48715877532959
Validation loss: 2.157280743122101

Epoch: 6| Step: 3
Training loss: 2.5436012744903564
Validation loss: 2.163655440012614

Epoch: 6| Step: 4
Training loss: 2.002868175506592
Validation loss: 2.1633947690327964

Epoch: 6| Step: 5
Training loss: 2.212188720703125
Validation loss: 2.16037925084432

Epoch: 6| Step: 6
Training loss: 2.307575225830078
Validation loss: 2.1601977944374084

Epoch: 6| Step: 7
Training loss: 2.3434295654296875
Validation loss: 2.1613779266675315

Epoch: 6| Step: 8
Training loss: 1.556185007095337
Validation loss: 2.1597684820493064

Epoch: 6| Step: 9
Training loss: 2.6658060550689697
Validation loss: 2.1572391192118325

Epoch: 6| Step: 10
Training loss: 2.785935163497925
Validation loss: 2.1559916933377585

Epoch: 6| Step: 11
Training loss: 2.6185479164123535
Validation loss: 2.155008534590403

Epoch: 6| Step: 12
Training loss: 2.1164658069610596
Validation loss: 2.1501099665959678

Epoch: 6| Step: 13
Training loss: 2.301642656326294
Validation loss: 2.1498501698176065

Epoch: 53| Step: 0
Training loss: 2.252938985824585
Validation loss: 2.1452526450157166

Epoch: 6| Step: 1
Training loss: 2.1841559410095215
Validation loss: 2.1354023218154907

Epoch: 6| Step: 2
Training loss: 2.637263536453247
Validation loss: 2.1345068216323853

Epoch: 6| Step: 3
Training loss: 2.8650286197662354
Validation loss: 2.1317293842633567

Epoch: 6| Step: 4
Training loss: 2.333117961883545
Validation loss: 2.135241687297821

Epoch: 6| Step: 5
Training loss: 2.3081767559051514
Validation loss: 2.1265841722488403

Epoch: 6| Step: 6
Training loss: 2.0558416843414307
Validation loss: 2.1232484181722007

Epoch: 6| Step: 7
Training loss: 1.998227834701538
Validation loss: 2.1250226298967996

Epoch: 6| Step: 8
Training loss: 2.406226873397827
Validation loss: 2.1272524197896323

Epoch: 6| Step: 9
Training loss: 2.6695525646209717
Validation loss: 2.128297289212545

Epoch: 6| Step: 10
Training loss: 1.9268100261688232
Validation loss: 2.1221253275871277

Epoch: 6| Step: 11
Training loss: 2.4054698944091797
Validation loss: 2.1241081953048706

Epoch: 6| Step: 12
Training loss: 2.081172466278076
Validation loss: 2.1177064577738443

Epoch: 6| Step: 13
Training loss: 2.2614521980285645
Validation loss: 2.119748373826345

Epoch: 54| Step: 0
Training loss: 2.2827835083007812
Validation loss: 2.1151091853777566

Epoch: 6| Step: 1
Training loss: 2.1001031398773193
Validation loss: 2.1150300105412803

Epoch: 6| Step: 2
Training loss: 2.2401065826416016
Validation loss: 2.1180723905563354

Epoch: 6| Step: 3
Training loss: 1.8876339197158813
Validation loss: 2.1164416869481406

Epoch: 6| Step: 4
Training loss: 2.462977886199951
Validation loss: 2.110692342122396

Epoch: 6| Step: 5
Training loss: 2.6831507682800293
Validation loss: 2.105358084042867

Epoch: 6| Step: 6
Training loss: 2.3375020027160645
Validation loss: 2.116094688574473

Epoch: 6| Step: 7
Training loss: 2.2340736389160156
Validation loss: 2.11224627494812

Epoch: 6| Step: 8
Training loss: 2.21212100982666
Validation loss: 2.103903889656067

Epoch: 6| Step: 9
Training loss: 2.4500620365142822
Validation loss: 2.1047315994898477

Epoch: 6| Step: 10
Training loss: 2.5476012229919434
Validation loss: 2.1038230458895364

Epoch: 6| Step: 11
Training loss: 2.5035648345947266
Validation loss: 2.107959806919098

Epoch: 6| Step: 12
Training loss: 2.411961317062378
Validation loss: 2.103681484858195

Epoch: 6| Step: 13
Training loss: 1.6828546524047852
Validation loss: 2.1033778190612793

Epoch: 55| Step: 0
Training loss: 2.315608501434326
Validation loss: 2.098225196202596

Epoch: 6| Step: 1
Training loss: 2.079221725463867
Validation loss: 2.095820109049479

Epoch: 6| Step: 2
Training loss: 2.6809515953063965
Validation loss: 2.098435163497925

Epoch: 6| Step: 3
Training loss: 3.136882781982422
Validation loss: 2.0965251127878823

Epoch: 6| Step: 4
Training loss: 1.93832528591156
Validation loss: 2.0955976446469626

Epoch: 6| Step: 5
Training loss: 2.034616231918335
Validation loss: 2.091817299524943

Epoch: 6| Step: 6
Training loss: 2.388598918914795
Validation loss: 2.0913731257120767

Epoch: 6| Step: 7
Training loss: 2.1375341415405273
Validation loss: 2.0898461739222207

Epoch: 6| Step: 8
Training loss: 1.6750174760818481
Validation loss: 2.085104684034983

Epoch: 6| Step: 9
Training loss: 2.169255256652832
Validation loss: 2.0875007708867392

Epoch: 6| Step: 10
Training loss: 2.010443687438965
Validation loss: 2.0907936294873557

Epoch: 6| Step: 11
Training loss: 2.4649264812469482
Validation loss: 2.0998030304908752

Epoch: 6| Step: 12
Training loss: 2.5022213459014893
Validation loss: 2.118199567000071

Epoch: 6| Step: 13
Training loss: 2.4187822341918945
Validation loss: 2.110463281472524

Epoch: 56| Step: 0
Training loss: 1.870590090751648
Validation loss: 2.1019786397616067

Epoch: 6| Step: 1
Training loss: 2.055171012878418
Validation loss: 2.0759310722351074

Epoch: 6| Step: 2
Training loss: 2.785402297973633
Validation loss: 2.0742759307225547

Epoch: 6| Step: 3
Training loss: 2.0981433391571045
Validation loss: 2.0795498887697854

Epoch: 6| Step: 4
Training loss: 2.54365611076355
Validation loss: 2.0872434178988137

Epoch: 6| Step: 5
Training loss: 1.6108312606811523
Validation loss: 2.0898590087890625

Epoch: 6| Step: 6
Training loss: 2.3480300903320312
Validation loss: 2.1021785934766135

Epoch: 6| Step: 7
Training loss: 1.7335171699523926
Validation loss: 2.112113893032074

Epoch: 6| Step: 8
Training loss: 2.62188458442688
Validation loss: 2.1369155446688333

Epoch: 6| Step: 9
Training loss: 2.4166908264160156
Validation loss: 2.1258574525515237

Epoch: 6| Step: 10
Training loss: 2.12831974029541
Validation loss: 2.0993259151776633

Epoch: 6| Step: 11
Training loss: 2.501737117767334
Validation loss: 2.0935031970342

Epoch: 6| Step: 12
Training loss: 2.5054264068603516
Validation loss: 2.0917606155077615

Epoch: 6| Step: 13
Training loss: 2.7019262313842773
Validation loss: 2.0886343121528625

Epoch: 57| Step: 0
Training loss: 2.605502128601074
Validation loss: 2.0796902179718018

Epoch: 6| Step: 1
Training loss: 2.843376636505127
Validation loss: 2.075912376244863

Epoch: 6| Step: 2
Training loss: 2.540818691253662
Validation loss: 2.071984271208445

Epoch: 6| Step: 3
Training loss: 2.2520413398742676
Validation loss: 2.0735446214675903

Epoch: 6| Step: 4
Training loss: 2.7826967239379883
Validation loss: 2.0687468846639

Epoch: 6| Step: 5
Training loss: 1.9949549436569214
Validation loss: 2.064890682697296

Epoch: 6| Step: 6
Training loss: 2.1886069774627686
Validation loss: 2.0639562209447226

Epoch: 6| Step: 7
Training loss: 2.173534870147705
Validation loss: 2.0612038373947144

Epoch: 6| Step: 8
Training loss: 2.027766227722168
Validation loss: 2.056488494078318

Epoch: 6| Step: 9
Training loss: 1.905472993850708
Validation loss: 2.0500647823015847

Epoch: 6| Step: 10
Training loss: 2.3651301860809326
Validation loss: 2.0555827418963113

Epoch: 6| Step: 11
Training loss: 2.2173826694488525
Validation loss: 2.0614346861839294

Epoch: 6| Step: 12
Training loss: 1.876720905303955
Validation loss: 2.0678146481513977

Epoch: 6| Step: 13
Training loss: 1.738162636756897
Validation loss: 2.078199783960978

Epoch: 58| Step: 0
Training loss: 2.179473400115967
Validation loss: 2.0522443056106567

Epoch: 6| Step: 1
Training loss: 1.933976173400879
Validation loss: 2.054899275302887

Epoch: 6| Step: 2
Training loss: 1.6478376388549805
Validation loss: 2.04630845785141

Epoch: 6| Step: 3
Training loss: 2.0944066047668457
Validation loss: 2.0450923840204873

Epoch: 6| Step: 4
Training loss: 2.00691819190979
Validation loss: 2.045168936252594

Epoch: 6| Step: 5
Training loss: 2.419264316558838
Validation loss: 2.0450757344563804

Epoch: 6| Step: 6
Training loss: 2.7440600395202637
Validation loss: 2.0395641724268594

Epoch: 6| Step: 7
Training loss: 2.0019500255584717
Validation loss: 2.0416545271873474

Epoch: 6| Step: 8
Training loss: 2.610663652420044
Validation loss: 2.044314384460449

Epoch: 6| Step: 9
Training loss: 2.304581642150879
Validation loss: 2.044382373491923

Epoch: 6| Step: 10
Training loss: 2.2265729904174805
Validation loss: 2.0503785212834678

Epoch: 6| Step: 11
Training loss: 2.695122718811035
Validation loss: 2.0402960777282715

Epoch: 6| Step: 12
Training loss: 2.0929811000823975
Validation loss: 2.0388641556104026

Epoch: 6| Step: 13
Training loss: 2.2032341957092285
Validation loss: 2.042756815751394

Epoch: 59| Step: 0
Training loss: 2.1114165782928467
Validation loss: 2.0324193835258484

Epoch: 6| Step: 1
Training loss: 2.1787283420562744
Validation loss: 2.0379967093467712

Epoch: 6| Step: 2
Training loss: 2.4382638931274414
Validation loss: 2.039485772450765

Epoch: 6| Step: 3
Training loss: 2.790675401687622
Validation loss: 2.0387640992800393

Epoch: 6| Step: 4
Training loss: 2.387023448944092
Validation loss: 2.040844202041626

Epoch: 6| Step: 5
Training loss: 2.154689311981201
Validation loss: 2.0413565238316855

Epoch: 6| Step: 6
Training loss: 1.9325640201568604
Validation loss: 2.036907434463501

Epoch: 6| Step: 7
Training loss: 2.386324882507324
Validation loss: 2.039883474508921

Epoch: 6| Step: 8
Training loss: 3.1906790733337402
Validation loss: 2.039929509162903

Epoch: 6| Step: 9
Training loss: 1.7055644989013672
Validation loss: 2.0379947225252786

Epoch: 6| Step: 10
Training loss: 1.7242720127105713
Validation loss: 2.0322612524032593

Epoch: 6| Step: 11
Training loss: 2.272904872894287
Validation loss: 2.038268824418386

Epoch: 6| Step: 12
Training loss: 1.889373540878296
Validation loss: 2.0375182231267295

Epoch: 6| Step: 13
Training loss: 1.964338779449463
Validation loss: 2.0544990499814353

Epoch: 60| Step: 0
Training loss: 2.4127254486083984
Validation loss: 2.0406532088915506

Epoch: 6| Step: 1
Training loss: 2.5410842895507812
Validation loss: 2.0299014846483865

Epoch: 6| Step: 2
Training loss: 2.644031524658203
Validation loss: 2.0327617724736533

Epoch: 6| Step: 3
Training loss: 2.159634590148926
Validation loss: 2.0354894399642944

Epoch: 6| Step: 4
Training loss: 2.4352476596832275
Validation loss: 2.041241725285848

Epoch: 6| Step: 5
Training loss: 1.7290117740631104
Validation loss: 2.0419541200002036

Epoch: 6| Step: 6
Training loss: 1.998746395111084
Validation loss: 2.0405523777008057

Epoch: 6| Step: 7
Training loss: 2.5087034702301025
Validation loss: 2.04248841603597

Epoch: 6| Step: 8
Training loss: 2.1815221309661865
Validation loss: 2.0392997662226358

Epoch: 6| Step: 9
Training loss: 1.8850468397140503
Validation loss: 2.0408023993174234

Epoch: 6| Step: 10
Training loss: 2.642540693283081
Validation loss: 2.0434137185414634

Epoch: 6| Step: 11
Training loss: 1.8128774166107178
Validation loss: 2.0391748746236167

Epoch: 6| Step: 12
Training loss: 2.3383233547210693
Validation loss: 2.037489970525106

Epoch: 6| Step: 13
Training loss: 1.7477132081985474
Validation loss: 2.0314783652623496

Epoch: 61| Step: 0
Training loss: 2.2426109313964844
Validation loss: 2.0285640358924866

Epoch: 6| Step: 1
Training loss: 2.0861806869506836
Validation loss: 2.0256713032722473

Epoch: 6| Step: 2
Training loss: 1.729248046875
Validation loss: 2.030839125315348

Epoch: 6| Step: 3
Training loss: 2.1607649326324463
Validation loss: 2.022903621196747

Epoch: 6| Step: 4
Training loss: 2.189194679260254
Validation loss: 2.0276535749435425

Epoch: 6| Step: 5
Training loss: 2.3749825954437256
Validation loss: 2.026830037434896

Epoch: 6| Step: 6
Training loss: 2.295236349105835
Validation loss: 2.02547158797582

Epoch: 6| Step: 7
Training loss: 2.3976902961730957
Validation loss: 2.024030943711599

Epoch: 6| Step: 8
Training loss: 2.310349941253662
Validation loss: 2.0298732916514077

Epoch: 6| Step: 9
Training loss: 2.402863025665283
Validation loss: 2.025191068649292

Epoch: 6| Step: 10
Training loss: 2.5026443004608154
Validation loss: 2.030341684818268

Epoch: 6| Step: 11
Training loss: 2.23567533493042
Validation loss: 2.034065624078115

Epoch: 6| Step: 12
Training loss: 1.7485769987106323
Validation loss: 2.0317911903063455

Epoch: 6| Step: 13
Training loss: 2.120527505874634
Validation loss: 2.022449254989624

Epoch: 62| Step: 0
Training loss: 2.5320234298706055
Validation loss: 2.0245235761006675

Epoch: 6| Step: 1
Training loss: 1.4242420196533203
Validation loss: 2.0178879300753274

Epoch: 6| Step: 2
Training loss: 2.4411709308624268
Validation loss: 2.018311619758606

Epoch: 6| Step: 3
Training loss: 1.7968506813049316
Validation loss: 2.02593731880188

Epoch: 6| Step: 4
Training loss: 1.952496886253357
Validation loss: 2.0199995040893555

Epoch: 6| Step: 5
Training loss: 2.2402806282043457
Validation loss: 2.021540025870005

Epoch: 6| Step: 6
Training loss: 2.0456645488739014
Validation loss: 2.0194005966186523

Epoch: 6| Step: 7
Training loss: 2.475548267364502
Validation loss: 2.0308930476506553

Epoch: 6| Step: 8
Training loss: 2.4370131492614746
Validation loss: 2.0385021368662515

Epoch: 6| Step: 9
Training loss: 1.5654737949371338
Validation loss: 2.0347525676091514

Epoch: 6| Step: 10
Training loss: 2.532222032546997
Validation loss: 2.0365731914838157

Epoch: 6| Step: 11
Training loss: 2.3410072326660156
Validation loss: 2.0341431498527527

Epoch: 6| Step: 12
Training loss: 2.8537099361419678
Validation loss: 2.04305628935496

Epoch: 6| Step: 13
Training loss: 2.377800464630127
Validation loss: 2.0213032960891724

Epoch: 63| Step: 0
Training loss: 1.822485327720642
Validation loss: 2.02079043785731

Epoch: 6| Step: 1
Training loss: 2.2764596939086914
Validation loss: 2.0200347701708474

Epoch: 6| Step: 2
Training loss: 1.9059003591537476
Validation loss: 2.0248817602793374

Epoch: 6| Step: 3
Training loss: 2.0501577854156494
Validation loss: 2.031873265902201

Epoch: 6| Step: 4
Training loss: 1.7124965190887451
Validation loss: 2.0247390270233154

Epoch: 6| Step: 5
Training loss: 2.8772311210632324
Validation loss: 2.0244149367014566

Epoch: 6| Step: 6
Training loss: 1.6977174282073975
Validation loss: 2.026942551136017

Epoch: 6| Step: 7
Training loss: 2.643150806427002
Validation loss: 2.0162334640820823

Epoch: 6| Step: 8
Training loss: 2.6853184700012207
Validation loss: 2.0154695908228555

Epoch: 6| Step: 9
Training loss: 2.382946014404297
Validation loss: 2.0196451346079507

Epoch: 6| Step: 10
Training loss: 2.4633419513702393
Validation loss: 2.036579191684723

Epoch: 6| Step: 11
Training loss: 2.506537437438965
Validation loss: 2.035334328810374

Epoch: 6| Step: 12
Training loss: 1.9772388935089111
Validation loss: 2.0318860610326133

Epoch: 6| Step: 13
Training loss: 1.940868616104126
Validation loss: 2.0215001900990806

Epoch: 64| Step: 0
Training loss: 1.9725278615951538
Validation loss: 2.018081486225128

Epoch: 6| Step: 1
Training loss: 1.8419376611709595
Validation loss: 2.0161427656809487

Epoch: 6| Step: 2
Training loss: 2.5533809661865234
Validation loss: 2.017692983150482

Epoch: 6| Step: 3
Training loss: 1.8748366832733154
Validation loss: 2.0017037789026895

Epoch: 6| Step: 4
Training loss: 2.6339807510375977
Validation loss: 2.0070289770762124

Epoch: 6| Step: 5
Training loss: 2.204458236694336
Validation loss: 2.010364850362142

Epoch: 6| Step: 6
Training loss: 2.161982536315918
Validation loss: 2.008903523286184

Epoch: 6| Step: 7
Training loss: 2.4417476654052734
Validation loss: 2.0122710267702737

Epoch: 6| Step: 8
Training loss: 2.090654134750366
Validation loss: 2.0118501782417297

Epoch: 6| Step: 9
Training loss: 2.2968287467956543
Validation loss: 2.017798642317454

Epoch: 6| Step: 10
Training loss: 1.556650161743164
Validation loss: 2.020333766937256

Epoch: 6| Step: 11
Training loss: 2.4568185806274414
Validation loss: 2.0255685448646545

Epoch: 6| Step: 12
Training loss: 2.6781089305877686
Validation loss: 2.027116596698761

Epoch: 6| Step: 13
Training loss: 1.8902395963668823
Validation loss: 2.0177589456240335

Epoch: 65| Step: 0
Training loss: 2.676668167114258
Validation loss: 2.0095576445261636

Epoch: 6| Step: 1
Training loss: 2.286592483520508
Validation loss: 2.015719393889109

Epoch: 6| Step: 2
Training loss: 2.752953052520752
Validation loss: 2.007761617501577

Epoch: 6| Step: 3
Training loss: 1.836510419845581
Validation loss: 2.0121577183405557

Epoch: 6| Step: 4
Training loss: 1.6288315057754517
Validation loss: 2.012306531270345

Epoch: 6| Step: 5
Training loss: 2.281162977218628
Validation loss: 2.01466566324234

Epoch: 6| Step: 6
Training loss: 1.6568169593811035
Validation loss: 2.0208548307418823

Epoch: 6| Step: 7
Training loss: 2.486201763153076
Validation loss: 2.0157231291135154

Epoch: 6| Step: 8
Training loss: 1.7208797931671143
Validation loss: 2.014542738596598

Epoch: 6| Step: 9
Training loss: 2.8142359256744385
Validation loss: 2.0187420646349588

Epoch: 6| Step: 10
Training loss: 1.695349931716919
Validation loss: 2.0146065950393677

Epoch: 6| Step: 11
Training loss: 2.1116132736206055
Validation loss: 2.014844079812368

Epoch: 6| Step: 12
Training loss: 2.221467971801758
Validation loss: 2.016993840535482

Epoch: 6| Step: 13
Training loss: 2.373086452484131
Validation loss: 2.0139392415682473

Epoch: 66| Step: 0
Training loss: 1.545383334159851
Validation loss: 2.0178385774294534

Epoch: 6| Step: 1
Training loss: 2.416055917739868
Validation loss: 2.0081472396850586

Epoch: 6| Step: 2
Training loss: 2.304311752319336
Validation loss: 2.0134053230285645

Epoch: 6| Step: 3
Training loss: 1.8683809041976929
Validation loss: 2.0131207704544067

Epoch: 6| Step: 4
Training loss: 1.7431954145431519
Validation loss: 2.01036536693573

Epoch: 6| Step: 5
Training loss: 2.822878122329712
Validation loss: 2.0181050499280295

Epoch: 6| Step: 6
Training loss: 2.64764142036438
Validation loss: 2.0248996218045554

Epoch: 6| Step: 7
Training loss: 1.321303129196167
Validation loss: 2.015115817387899

Epoch: 6| Step: 8
Training loss: 2.4465835094451904
Validation loss: 2.011911690235138

Epoch: 6| Step: 9
Training loss: 2.1552584171295166
Validation loss: 2.0194589495658875

Epoch: 6| Step: 10
Training loss: 1.8955165147781372
Validation loss: 2.0075632333755493

Epoch: 6| Step: 11
Training loss: 2.1588516235351562
Validation loss: 2.0063666105270386

Epoch: 6| Step: 12
Training loss: 2.756394863128662
Validation loss: 2.0006268421808877

Epoch: 6| Step: 13
Training loss: 2.485348701477051
Validation loss: 2.0086939930915833

Epoch: 67| Step: 0
Training loss: 2.2179574966430664
Validation loss: 2.005078434944153

Epoch: 6| Step: 1
Training loss: 2.041627883911133
Validation loss: 2.0098043282826743

Epoch: 6| Step: 2
Training loss: 2.468292236328125
Validation loss: 2.0064890384674072

Epoch: 6| Step: 3
Training loss: 2.095681667327881
Validation loss: 2.006302793820699

Epoch: 6| Step: 4
Training loss: 1.7897834777832031
Validation loss: 2.012119472026825

Epoch: 6| Step: 5
Training loss: 1.7936292886734009
Validation loss: 2.0128397941589355

Epoch: 6| Step: 6
Training loss: 2.4133286476135254
Validation loss: 2.01401295264562

Epoch: 6| Step: 7
Training loss: 1.8438231945037842
Validation loss: 2.008125881354014

Epoch: 6| Step: 8
Training loss: 2.6926939487457275
Validation loss: 2.014454166094462

Epoch: 6| Step: 9
Training loss: 2.390414237976074
Validation loss: 2.012040297190348

Epoch: 6| Step: 10
Training loss: 2.465550422668457
Validation loss: 2.0248828132947287

Epoch: 6| Step: 11
Training loss: 1.8462340831756592
Validation loss: 2.0151468912760415

Epoch: 6| Step: 12
Training loss: 2.2950010299682617
Validation loss: 2.0137150486310325

Epoch: 6| Step: 13
Training loss: 2.0356767177581787
Validation loss: 2.0047552784283957

Epoch: 68| Step: 0
Training loss: 2.0638580322265625
Validation loss: 2.014238715171814

Epoch: 6| Step: 1
Training loss: 2.7884445190429688
Validation loss: 2.0297458171844482

Epoch: 6| Step: 2
Training loss: 1.808814525604248
Validation loss: 2.037995537122091

Epoch: 6| Step: 3
Training loss: 2.071378707885742
Validation loss: 2.031787713368734

Epoch: 6| Step: 4
Training loss: 2.317720890045166
Validation loss: 2.0308179457982383

Epoch: 6| Step: 5
Training loss: 1.3842368125915527
Validation loss: 2.020285665988922

Epoch: 6| Step: 6
Training loss: 2.2975964546203613
Validation loss: 2.0116016467412314

Epoch: 6| Step: 7
Training loss: 2.1850152015686035
Validation loss: 2.0106086333592734

Epoch: 6| Step: 8
Training loss: 2.080873966217041
Validation loss: 2.0116225282351174

Epoch: 6| Step: 9
Training loss: 2.049125909805298
Validation loss: 2.0074031551678977

Epoch: 6| Step: 10
Training loss: 2.035550594329834
Validation loss: 2.0132230520248413

Epoch: 6| Step: 11
Training loss: 2.4272003173828125
Validation loss: 2.0100085536638894

Epoch: 6| Step: 12
Training loss: 2.684525966644287
Validation loss: 2.015448967615763

Epoch: 6| Step: 13
Training loss: 2.167419910430908
Validation loss: 2.0160244504610696

Epoch: 69| Step: 0
Training loss: 2.5305426120758057
Validation loss: 2.019071956475576

Epoch: 6| Step: 1
Training loss: 2.384676218032837
Validation loss: 2.009746789932251

Epoch: 6| Step: 2
Training loss: 1.9268321990966797
Validation loss: 2.0178916255633035

Epoch: 6| Step: 3
Training loss: 2.28739595413208
Validation loss: 2.007481336593628

Epoch: 6| Step: 4
Training loss: 2.337405204772949
Validation loss: 2.009109675884247

Epoch: 6| Step: 5
Training loss: 2.1270506381988525
Validation loss: 2.011116147041321

Epoch: 6| Step: 6
Training loss: 1.8123890161514282
Validation loss: 2.010657032330831

Epoch: 6| Step: 7
Training loss: 2.1672801971435547
Validation loss: 2.014165222644806

Epoch: 6| Step: 8
Training loss: 2.3566458225250244
Validation loss: 2.0179495414098105

Epoch: 6| Step: 9
Training loss: 2.009751796722412
Validation loss: 2.0192222197850547

Epoch: 6| Step: 10
Training loss: 2.38271427154541
Validation loss: 2.0333369970321655

Epoch: 6| Step: 11
Training loss: 2.598982095718384
Validation loss: 2.0417746106783548

Epoch: 6| Step: 12
Training loss: 1.103302240371704
Validation loss: 2.034347891807556

Epoch: 6| Step: 13
Training loss: 2.507750988006592
Validation loss: 2.0295082926750183

Epoch: 70| Step: 0
Training loss: 1.936584234237671
Validation loss: 2.018798808256785

Epoch: 6| Step: 1
Training loss: 1.979977011680603
Validation loss: 2.0135347843170166

Epoch: 6| Step: 2
Training loss: 2.0629193782806396
Validation loss: 2.0086819529533386

Epoch: 6| Step: 3
Training loss: 2.307319402694702
Validation loss: 2.019926448663076

Epoch: 6| Step: 4
Training loss: 2.4991648197174072
Validation loss: 2.021087368329366

Epoch: 6| Step: 5
Training loss: 1.562697172164917
Validation loss: 2.0290085275967917

Epoch: 6| Step: 6
Training loss: 2.3496127128601074
Validation loss: 2.033741215864817

Epoch: 6| Step: 7
Training loss: 1.9866104125976562
Validation loss: 2.037449220816294

Epoch: 6| Step: 8
Training loss: 2.6067566871643066
Validation loss: 2.0365730126698813

Epoch: 6| Step: 9
Training loss: 2.5665555000305176
Validation loss: 2.0332618753115335

Epoch: 6| Step: 10
Training loss: 2.73539400100708
Validation loss: 2.033807078997294

Epoch: 6| Step: 11
Training loss: 1.6950397491455078
Validation loss: 2.035172422726949

Epoch: 6| Step: 12
Training loss: 1.602379560470581
Validation loss: 2.0240678191184998

Epoch: 6| Step: 13
Training loss: 2.6336312294006348
Validation loss: 2.0262685219446817

Epoch: 71| Step: 0
Training loss: 2.140308380126953
Validation loss: 2.0181620915730796

Epoch: 6| Step: 1
Training loss: 2.37298583984375
Validation loss: 2.0147956212361655

Epoch: 6| Step: 2
Training loss: 1.795174241065979
Validation loss: 2.013923247655233

Epoch: 6| Step: 3
Training loss: 2.154733180999756
Validation loss: 2.0172679821650186

Epoch: 6| Step: 4
Training loss: 1.8812880516052246
Validation loss: 2.030707359313965

Epoch: 6| Step: 5
Training loss: 2.573457717895508
Validation loss: 2.0380481282869973

Epoch: 6| Step: 6
Training loss: 2.3963451385498047
Validation loss: 2.0481878519058228

Epoch: 6| Step: 7
Training loss: 1.7999579906463623
Validation loss: 2.04345049460729

Epoch: 6| Step: 8
Training loss: 2.5198049545288086
Validation loss: 2.037476201852163

Epoch: 6| Step: 9
Training loss: 2.2756361961364746
Validation loss: 2.032165269056956

Epoch: 6| Step: 10
Training loss: 2.084686517715454
Validation loss: 2.0246233542760215

Epoch: 6| Step: 11
Training loss: 2.3638687133789062
Validation loss: 2.0139450232187905

Epoch: 6| Step: 12
Training loss: 2.0966901779174805
Validation loss: 2.01614918311437

Epoch: 6| Step: 13
Training loss: 2.303710460662842
Validation loss: 2.0165149370829263

Epoch: 72| Step: 0
Training loss: 1.455782175064087
Validation loss: 2.02453205982844

Epoch: 6| Step: 1
Training loss: 2.326949119567871
Validation loss: 2.0286929607391357

Epoch: 6| Step: 2
Training loss: 2.280174732208252
Validation loss: 2.0331664284070334

Epoch: 6| Step: 3
Training loss: 1.8988821506500244
Validation loss: 2.0200596253077188

Epoch: 6| Step: 4
Training loss: 2.654588460922241
Validation loss: 2.023244102795919

Epoch: 6| Step: 5
Training loss: 1.823235034942627
Validation loss: 2.0205798546473184

Epoch: 6| Step: 6
Training loss: 2.544900417327881
Validation loss: 2.0098976294199624

Epoch: 6| Step: 7
Training loss: 2.1295876502990723
Validation loss: 2.011228342851003

Epoch: 6| Step: 8
Training loss: 2.861180305480957
Validation loss: 2.0056147376696267

Epoch: 6| Step: 9
Training loss: 1.9177889823913574
Validation loss: 2.0026292403539023

Epoch: 6| Step: 10
Training loss: 2.6656126976013184
Validation loss: 2.009064793586731

Epoch: 6| Step: 11
Training loss: 1.9699697494506836
Validation loss: 2.0101287762324014

Epoch: 6| Step: 12
Training loss: 1.9638676643371582
Validation loss: 2.0071287949879966

Epoch: 6| Step: 13
Training loss: 1.9477784633636475
Validation loss: 2.0139452616373696

Epoch: 73| Step: 0
Training loss: 1.7002699375152588
Validation loss: 2.0115520358085632

Epoch: 6| Step: 1
Training loss: 2.575068473815918
Validation loss: 2.025601029396057

Epoch: 6| Step: 2
Training loss: 1.954688310623169
Validation loss: 2.016699473063151

Epoch: 6| Step: 3
Training loss: 1.9894702434539795
Validation loss: 2.0311777194341025

Epoch: 6| Step: 4
Training loss: 2.2489798069000244
Validation loss: 2.024820784727732

Epoch: 6| Step: 5
Training loss: 2.1493449211120605
Validation loss: 2.0380879044532776

Epoch: 6| Step: 6
Training loss: 2.073988914489746
Validation loss: 2.0354045232137046

Epoch: 6| Step: 7
Training loss: 3.0298614501953125
Validation loss: 2.0269338488578796

Epoch: 6| Step: 8
Training loss: 2.3150153160095215
Validation loss: 2.0089167952537537

Epoch: 6| Step: 9
Training loss: 2.097550392150879
Validation loss: 2.0102427999178567

Epoch: 6| Step: 10
Training loss: 2.48374605178833
Validation loss: 2.0047274231910706

Epoch: 6| Step: 11
Training loss: 1.7763704061508179
Validation loss: 2.0059072573979697

Epoch: 6| Step: 12
Training loss: 1.4325096607208252
Validation loss: 2.0141847133636475

Epoch: 6| Step: 13
Training loss: 2.413325309753418
Validation loss: 2.015635351339976

Epoch: 74| Step: 0
Training loss: 2.027803421020508
Validation loss: 2.0181939204533896

Epoch: 6| Step: 1
Training loss: 2.1089415550231934
Validation loss: 2.0159552296002707

Epoch: 6| Step: 2
Training loss: 1.6602405309677124
Validation loss: 2.0104040702184043

Epoch: 6| Step: 3
Training loss: 2.8787450790405273
Validation loss: 2.01442688703537

Epoch: 6| Step: 4
Training loss: 1.775010108947754
Validation loss: 2.0103787183761597

Epoch: 6| Step: 5
Training loss: 2.199561595916748
Validation loss: 2.0110345482826233

Epoch: 6| Step: 6
Training loss: 2.1217527389526367
Validation loss: 2.02181347211202

Epoch: 6| Step: 7
Training loss: 2.392864227294922
Validation loss: 2.0238868594169617

Epoch: 6| Step: 8
Training loss: 2.4739856719970703
Validation loss: 2.0283380349477134

Epoch: 6| Step: 9
Training loss: 2.546969413757324
Validation loss: 2.0256165067354837

Epoch: 6| Step: 10
Training loss: 1.6734883785247803
Validation loss: 2.0298267801602683

Epoch: 6| Step: 11
Training loss: 1.7305617332458496
Validation loss: 2.0362163186073303

Epoch: 6| Step: 12
Training loss: 2.1082701683044434
Validation loss: 2.0339154402414956

Epoch: 6| Step: 13
Training loss: 2.5294759273529053
Validation loss: 2.038784921169281

Epoch: 75| Step: 0
Training loss: 1.7946686744689941
Validation loss: 2.0302103757858276

Epoch: 6| Step: 1
Training loss: 1.943710446357727
Validation loss: 2.024199962615967

Epoch: 6| Step: 2
Training loss: 1.932807207107544
Validation loss: 2.028976877530416

Epoch: 6| Step: 3
Training loss: 2.1582725048065186
Validation loss: 2.0318171977996826

Epoch: 6| Step: 4
Training loss: 2.592071533203125
Validation loss: 2.0269984205563865

Epoch: 6| Step: 5
Training loss: 2.6133406162261963
Validation loss: 2.0266480247179666

Epoch: 6| Step: 6
Training loss: 2.0567784309387207
Validation loss: 2.0269473592440286

Epoch: 6| Step: 7
Training loss: 1.7146326303482056
Validation loss: 2.026397784550985

Epoch: 6| Step: 8
Training loss: 1.894194483757019
Validation loss: 2.0174195965131125

Epoch: 6| Step: 9
Training loss: 2.16680645942688
Validation loss: 2.017720719178518

Epoch: 6| Step: 10
Training loss: 2.6871297359466553
Validation loss: 2.0184187293052673

Epoch: 6| Step: 11
Training loss: 1.91579008102417
Validation loss: 2.0213499863942466

Epoch: 6| Step: 12
Training loss: 2.455082416534424
Validation loss: 2.019831399122874

Epoch: 6| Step: 13
Training loss: 2.046196460723877
Validation loss: 2.020380953947703

Epoch: 76| Step: 0
Training loss: 2.8098206520080566
Validation loss: 2.0188429752985635

Epoch: 6| Step: 1
Training loss: 2.387938976287842
Validation loss: 2.0181361635526023

Epoch: 6| Step: 2
Training loss: 1.853070616722107
Validation loss: 2.02008185784022

Epoch: 6| Step: 3
Training loss: 2.34421968460083
Validation loss: 2.014858881632487

Epoch: 6| Step: 4
Training loss: 1.6540193557739258
Validation loss: 2.0126020113627114

Epoch: 6| Step: 5
Training loss: 2.3740289211273193
Validation loss: 2.018417557080587

Epoch: 6| Step: 6
Training loss: 2.033060312271118
Validation loss: 2.0179654955863953

Epoch: 6| Step: 7
Training loss: 1.5773375034332275
Validation loss: 2.016808728377024

Epoch: 6| Step: 8
Training loss: 1.874392032623291
Validation loss: 2.0112744569778442

Epoch: 6| Step: 9
Training loss: 2.531005382537842
Validation loss: 2.015042781829834

Epoch: 6| Step: 10
Training loss: 2.6326842308044434
Validation loss: 2.0099239150683084

Epoch: 6| Step: 11
Training loss: 2.3239235877990723
Validation loss: 2.018592437108358

Epoch: 6| Step: 12
Training loss: 1.832136631011963
Validation loss: 2.0078028043111167

Epoch: 6| Step: 13
Training loss: 1.7305759191513062
Validation loss: 2.007613241672516

Epoch: 77| Step: 0
Training loss: 2.331510543823242
Validation loss: 2.003239611784617

Epoch: 6| Step: 1
Training loss: 1.9402371644973755
Validation loss: 1.9982123374938965

Epoch: 6| Step: 2
Training loss: 2.2111430168151855
Validation loss: 1.9969723622004192

Epoch: 6| Step: 3
Training loss: 2.254535675048828
Validation loss: 2.001008232434591

Epoch: 6| Step: 4
Training loss: 2.0694961547851562
Validation loss: 2.0035515228907266

Epoch: 6| Step: 5
Training loss: 1.8863463401794434
Validation loss: 2.011538565158844

Epoch: 6| Step: 6
Training loss: 2.2027339935302734
Validation loss: 2.020073572794596

Epoch: 6| Step: 7
Training loss: 1.9962674379348755
Validation loss: 2.026379883289337

Epoch: 6| Step: 8
Training loss: 2.255326747894287
Validation loss: 2.02900501092275

Epoch: 6| Step: 9
Training loss: 1.8037680387496948
Validation loss: 2.033259153366089

Epoch: 6| Step: 10
Training loss: 2.4139981269836426
Validation loss: 2.0219039916992188

Epoch: 6| Step: 11
Training loss: 2.271185874938965
Validation loss: 2.020498295625051

Epoch: 6| Step: 12
Training loss: 2.0397789478302
Validation loss: 2.023628016312917

Epoch: 6| Step: 13
Training loss: 2.3201260566711426
Validation loss: 2.013049383958181

Epoch: 78| Step: 0
Training loss: 2.250866651535034
Validation loss: 2.0175318916638694

Epoch: 6| Step: 1
Training loss: 1.9147021770477295
Validation loss: 2.0170921683311462

Epoch: 6| Step: 2
Training loss: 1.9001296758651733
Validation loss: 2.020682434240977

Epoch: 6| Step: 3
Training loss: 3.186507225036621
Validation loss: 2.0222434997558594

Epoch: 6| Step: 4
Training loss: 2.5473005771636963
Validation loss: 2.020213762919108

Epoch: 6| Step: 5
Training loss: 1.8430311679840088
Validation loss: 2.0197945634524026

Epoch: 6| Step: 6
Training loss: 1.5425124168395996
Validation loss: 2.0249776442845664

Epoch: 6| Step: 7
Training loss: 1.944731593132019
Validation loss: 2.0241490801175437

Epoch: 6| Step: 8
Training loss: 2.134126663208008
Validation loss: 2.0138158202171326

Epoch: 6| Step: 9
Training loss: 2.2359304428100586
Validation loss: 2.0181053280830383

Epoch: 6| Step: 10
Training loss: 2.348560333251953
Validation loss: 2.0095521410306296

Epoch: 6| Step: 11
Training loss: 1.9484333992004395
Validation loss: 2.007302165031433

Epoch: 6| Step: 12
Training loss: 1.7463483810424805
Validation loss: 2.0036340753237405

Epoch: 6| Step: 13
Training loss: 2.2461299896240234
Validation loss: 2.0091306964556375

Epoch: 79| Step: 0
Training loss: 2.317096710205078
Validation loss: 2.0143274068832397

Epoch: 6| Step: 1
Training loss: 2.4057652950286865
Validation loss: 2.0112494428952536

Epoch: 6| Step: 2
Training loss: 1.8004305362701416
Validation loss: 2.015816032886505

Epoch: 6| Step: 3
Training loss: 2.6224517822265625
Validation loss: 2.020958642164866

Epoch: 6| Step: 4
Training loss: 2.1653568744659424
Validation loss: 2.0111268758773804

Epoch: 6| Step: 5
Training loss: 2.6050119400024414
Validation loss: 2.0193517605463662

Epoch: 6| Step: 6
Training loss: 2.3432884216308594
Validation loss: 2.0099068880081177

Epoch: 6| Step: 7
Training loss: 2.065761089324951
Validation loss: 2.006115674972534

Epoch: 6| Step: 8
Training loss: 2.1778597831726074
Validation loss: 2.007032891114553

Epoch: 6| Step: 9
Training loss: 1.958545446395874
Validation loss: 2.0041039983431497

Epoch: 6| Step: 10
Training loss: 1.8711726665496826
Validation loss: 2.005907396475474

Epoch: 6| Step: 11
Training loss: 1.8160980939865112
Validation loss: 2.0039190451304116

Epoch: 6| Step: 12
Training loss: 1.8899528980255127
Validation loss: 2.015628139177958

Epoch: 6| Step: 13
Training loss: 1.800338625907898
Validation loss: 2.0098390579223633

Epoch: 80| Step: 0
Training loss: 2.1008572578430176
Validation loss: 2.0296945571899414

Epoch: 6| Step: 1
Training loss: 2.0223100185394287
Validation loss: 2.034263809521993

Epoch: 6| Step: 2
Training loss: 2.241525650024414
Validation loss: 2.0257762471834817

Epoch: 6| Step: 3
Training loss: 1.919492483139038
Validation loss: 2.0343902707099915

Epoch: 6| Step: 4
Training loss: 2.390255928039551
Validation loss: 2.020674486955007

Epoch: 6| Step: 5
Training loss: 2.596381187438965
Validation loss: 2.014009694258372

Epoch: 6| Step: 6
Training loss: 2.0960254669189453
Validation loss: 2.0141374667485556

Epoch: 6| Step: 7
Training loss: 2.2564382553100586
Validation loss: 2.016905109087626

Epoch: 6| Step: 8
Training loss: 2.1697309017181396
Validation loss: 2.0129343271255493

Epoch: 6| Step: 9
Training loss: 1.8420801162719727
Validation loss: 2.0163731773694358

Epoch: 6| Step: 10
Training loss: 2.134460926055908
Validation loss: 2.014578898747762

Epoch: 6| Step: 11
Training loss: 2.57437801361084
Validation loss: 2.018378496170044

Epoch: 6| Step: 12
Training loss: 1.1402833461761475
Validation loss: 2.017219066619873

Epoch: 6| Step: 13
Training loss: 2.255521774291992
Validation loss: 2.0132934053738913

Epoch: 81| Step: 0
Training loss: 1.3330092430114746
Validation loss: 2.027206838130951

Epoch: 6| Step: 1
Training loss: 1.8784503936767578
Validation loss: 2.020584225654602

Epoch: 6| Step: 2
Training loss: 2.0869181156158447
Validation loss: 2.0222856203715005

Epoch: 6| Step: 3
Training loss: 1.7835954427719116
Validation loss: 2.021718362967173

Epoch: 6| Step: 4
Training loss: 2.4485907554626465
Validation loss: 2.0160911679267883

Epoch: 6| Step: 5
Training loss: 2.7038843631744385
Validation loss: 2.0243260860443115

Epoch: 6| Step: 6
Training loss: 2.370441436767578
Validation loss: 2.0288392504056296

Epoch: 6| Step: 7
Training loss: 2.181236982345581
Validation loss: 2.0241761604944863

Epoch: 6| Step: 8
Training loss: 2.4487876892089844
Validation loss: 2.0303890903790793

Epoch: 6| Step: 9
Training loss: 2.1016902923583984
Validation loss: 2.023642897605896

Epoch: 6| Step: 10
Training loss: 2.5563411712646484
Validation loss: 2.0139182209968567

Epoch: 6| Step: 11
Training loss: 2.0895133018493652
Validation loss: 2.031654198964437

Epoch: 6| Step: 12
Training loss: 1.7828917503356934
Validation loss: 2.0255144834518433

Epoch: 6| Step: 13
Training loss: 1.8774163722991943
Validation loss: 2.024307111899058

Epoch: 82| Step: 0
Training loss: 2.10829496383667
Validation loss: 2.0236851970354715

Epoch: 6| Step: 1
Training loss: 2.365187644958496
Validation loss: 2.0135377844174704

Epoch: 6| Step: 2
Training loss: 2.0414023399353027
Validation loss: 2.003249406814575

Epoch: 6| Step: 3
Training loss: 2.142047882080078
Validation loss: 2.0077302853266397

Epoch: 6| Step: 4
Training loss: 2.281559944152832
Validation loss: 2.001655181248983

Epoch: 6| Step: 5
Training loss: 2.043513059616089
Validation loss: 2.00482306877772

Epoch: 6| Step: 6
Training loss: 2.1884493827819824
Validation loss: 2.0003039836883545

Epoch: 6| Step: 7
Training loss: 2.307368278503418
Validation loss: 1.998697837193807

Epoch: 6| Step: 8
Training loss: 2.228177070617676
Validation loss: 2.0044665733973184

Epoch: 6| Step: 9
Training loss: 1.9666519165039062
Validation loss: 2.003135859966278

Epoch: 6| Step: 10
Training loss: 2.0587215423583984
Validation loss: 1.998690923055013

Epoch: 6| Step: 11
Training loss: 1.7237095832824707
Validation loss: 2.0022724866867065

Epoch: 6| Step: 12
Training loss: 2.218524932861328
Validation loss: 2.008617321650187

Epoch: 6| Step: 13
Training loss: 2.1988048553466797
Validation loss: 2.0144693652788797

Epoch: 83| Step: 0
Training loss: 2.1218385696411133
Validation loss: 2.028649608294169

Epoch: 6| Step: 1
Training loss: 2.070812225341797
Validation loss: 2.0279648105303445

Epoch: 6| Step: 2
Training loss: 1.9622766971588135
Validation loss: 2.036470651626587

Epoch: 6| Step: 3
Training loss: 1.5546534061431885
Validation loss: 2.0262449185053506

Epoch: 6| Step: 4
Training loss: 2.2615222930908203
Validation loss: 2.03031979004542

Epoch: 6| Step: 5
Training loss: 2.7982146739959717
Validation loss: 2.0338467955589294

Epoch: 6| Step: 6
Training loss: 2.066880226135254
Validation loss: 2.0279900232950845

Epoch: 6| Step: 7
Training loss: 2.5962777137756348
Validation loss: 2.0237855911254883

Epoch: 6| Step: 8
Training loss: 1.8978686332702637
Validation loss: 2.0256800055503845

Epoch: 6| Step: 9
Training loss: 1.655125379562378
Validation loss: 2.025428136189779

Epoch: 6| Step: 10
Training loss: 2.0036797523498535
Validation loss: 2.016080896059672

Epoch: 6| Step: 11
Training loss: 1.8630955219268799
Validation loss: 2.0140419801076255

Epoch: 6| Step: 12
Training loss: 2.112095832824707
Validation loss: 2.011751433213552

Epoch: 6| Step: 13
Training loss: 2.6778626441955566
Validation loss: 2.0157187779744468

Epoch: 84| Step: 0
Training loss: 2.237931489944458
Validation loss: 2.014317512512207

Epoch: 6| Step: 1
Training loss: 1.8290786743164062
Validation loss: 2.014431655406952

Epoch: 6| Step: 2
Training loss: 2.250988483428955
Validation loss: 2.0202796856562295

Epoch: 6| Step: 3
Training loss: 2.3621838092803955
Validation loss: 2.0212729970614114

Epoch: 6| Step: 4
Training loss: 1.9926176071166992
Validation loss: 2.0280649264653525

Epoch: 6| Step: 5
Training loss: 2.775754451751709
Validation loss: 2.0314976970354715

Epoch: 6| Step: 6
Training loss: 2.2468631267547607
Validation loss: 2.019943376382192

Epoch: 6| Step: 7
Training loss: 1.759688377380371
Validation loss: 2.025898734728495

Epoch: 6| Step: 8
Training loss: 2.2601816654205322
Validation loss: 2.018302341302236

Epoch: 6| Step: 9
Training loss: 1.4998939037322998
Validation loss: 2.020274043083191

Epoch: 6| Step: 10
Training loss: 2.4158546924591064
Validation loss: 2.0193148652712503

Epoch: 6| Step: 11
Training loss: 1.9934754371643066
Validation loss: 2.025770386060079

Epoch: 6| Step: 12
Training loss: 1.889308214187622
Validation loss: 2.0240273078282676

Epoch: 6| Step: 13
Training loss: 2.086376190185547
Validation loss: 2.0203240513801575

Epoch: 85| Step: 0
Training loss: 2.7383790016174316
Validation loss: 2.012119015057882

Epoch: 6| Step: 1
Training loss: 2.28291392326355
Validation loss: 2.0047620137532554

Epoch: 6| Step: 2
Training loss: 2.1719188690185547
Validation loss: 1.9982720812161763

Epoch: 6| Step: 3
Training loss: 1.3588428497314453
Validation loss: 1.9949287176132202

Epoch: 6| Step: 4
Training loss: 2.3356122970581055
Validation loss: 1.993430455525716

Epoch: 6| Step: 5
Training loss: 2.237229824066162
Validation loss: 1.9875198602676392

Epoch: 6| Step: 6
Training loss: 2.155519962310791
Validation loss: 1.9922895232836406

Epoch: 6| Step: 7
Training loss: 1.9280503988265991
Validation loss: 1.992907166481018

Epoch: 6| Step: 8
Training loss: 2.4631028175354004
Validation loss: 1.9956183632214863

Epoch: 6| Step: 9
Training loss: 1.1997933387756348
Validation loss: 1.9927072922388713

Epoch: 6| Step: 10
Training loss: 2.3620083332061768
Validation loss: 1.9963704744974773

Epoch: 6| Step: 11
Training loss: 2.545903444290161
Validation loss: 1.9944984515508015

Epoch: 6| Step: 12
Training loss: 1.9115808010101318
Validation loss: 1.99599822362264

Epoch: 6| Step: 13
Training loss: 1.971356987953186
Validation loss: 2.00688898563385

Epoch: 86| Step: 0
Training loss: 2.038301467895508
Validation loss: 2.021394590536753

Epoch: 6| Step: 1
Training loss: 2.8862431049346924
Validation loss: 2.027575055758158

Epoch: 6| Step: 2
Training loss: 2.018141746520996
Validation loss: 2.0283756454785666

Epoch: 6| Step: 3
Training loss: 2.1417582035064697
Validation loss: 2.04435928662618

Epoch: 6| Step: 4
Training loss: 2.1425673961639404
Validation loss: 2.0459346572558084

Epoch: 6| Step: 5
Training loss: 1.603766918182373
Validation loss: 2.059715747833252

Epoch: 6| Step: 6
Training loss: 2.299635887145996
Validation loss: 2.0287777384122214

Epoch: 6| Step: 7
Training loss: 2.1032450199127197
Validation loss: 2.0203160842259726

Epoch: 6| Step: 8
Training loss: 2.35129976272583
Validation loss: 2.0153410832087197

Epoch: 6| Step: 9
Training loss: 2.41532564163208
Validation loss: 2.0184869368871055

Epoch: 6| Step: 10
Training loss: 2.1950838565826416
Validation loss: 2.00450466076533

Epoch: 6| Step: 11
Training loss: 1.6286338567733765
Validation loss: 2.0103387037913003

Epoch: 6| Step: 12
Training loss: 1.8525092601776123
Validation loss: 2.007759153842926

Epoch: 6| Step: 13
Training loss: 2.064061403274536
Validation loss: 2.0054511626561484

Epoch: 87| Step: 0
Training loss: 2.163156747817993
Validation loss: 2.0071088870366416

Epoch: 6| Step: 1
Training loss: 1.8271806240081787
Validation loss: 2.0077112714449563

Epoch: 6| Step: 2
Training loss: 2.6915054321289062
Validation loss: 2.009900450706482

Epoch: 6| Step: 3
Training loss: 2.168626308441162
Validation loss: 2.016213874022166

Epoch: 6| Step: 4
Training loss: 2.7457523345947266
Validation loss: 2.0157461762428284

Epoch: 6| Step: 5
Training loss: 1.9773955345153809
Validation loss: 2.0143529772758484

Epoch: 6| Step: 6
Training loss: 2.304352045059204
Validation loss: 2.018707791964213

Epoch: 6| Step: 7
Training loss: 2.294210910797119
Validation loss: 2.015085200468699

Epoch: 6| Step: 8
Training loss: 1.8215277194976807
Validation loss: 2.013761063416799

Epoch: 6| Step: 9
Training loss: 1.7477993965148926
Validation loss: 2.008161207040151

Epoch: 6| Step: 10
Training loss: 2.455289363861084
Validation loss: 2.0106131633122764

Epoch: 6| Step: 11
Training loss: 1.7797471284866333
Validation loss: 2.0072363217671714

Epoch: 6| Step: 12
Training loss: 2.4017467498779297
Validation loss: 2.0052766601244607

Epoch: 6| Step: 13
Training loss: 1.6243138313293457
Validation loss: 2.012236217657725

Epoch: 88| Step: 0
Training loss: 2.5052433013916016
Validation loss: 2.012507438659668

Epoch: 6| Step: 1
Training loss: 2.1722216606140137
Validation loss: 2.0087637702624

Epoch: 6| Step: 2
Training loss: 2.3127853870391846
Validation loss: 2.0192978779474893

Epoch: 6| Step: 3
Training loss: 2.1848788261413574
Validation loss: 2.017322580019633

Epoch: 6| Step: 4
Training loss: 2.631308078765869
Validation loss: 2.023437718550364

Epoch: 6| Step: 5
Training loss: 1.80068838596344
Validation loss: 2.016733547051748

Epoch: 6| Step: 6
Training loss: 2.460092067718506
Validation loss: 2.0209456284840903

Epoch: 6| Step: 7
Training loss: 2.3809714317321777
Validation loss: 2.026594877243042

Epoch: 6| Step: 8
Training loss: 1.9410287141799927
Validation loss: 2.0121650099754333

Epoch: 6| Step: 9
Training loss: 2.2337889671325684
Validation loss: 2.017256478468577

Epoch: 6| Step: 10
Training loss: 2.0495615005493164
Validation loss: 2.0147913297017417

Epoch: 6| Step: 11
Training loss: 1.559888243675232
Validation loss: 2.0180798768997192

Epoch: 6| Step: 12
Training loss: 1.5283819437026978
Validation loss: 2.011604686578115

Epoch: 6| Step: 13
Training loss: 1.7696151733398438
Validation loss: 2.0095014174779258

Epoch: 89| Step: 0
Training loss: 1.8274345397949219
Validation loss: 2.0138187607129416

Epoch: 6| Step: 1
Training loss: 2.1506130695343018
Validation loss: 2.0206379890441895

Epoch: 6| Step: 2
Training loss: 2.071057081222534
Validation loss: 2.0227850874265036

Epoch: 6| Step: 3
Training loss: 1.7914135456085205
Validation loss: 2.018870751063029

Epoch: 6| Step: 4
Training loss: 2.0494723320007324
Validation loss: 2.0270244677861533

Epoch: 6| Step: 5
Training loss: 1.7375402450561523
Validation loss: 2.0210952361424765

Epoch: 6| Step: 6
Training loss: 2.3719348907470703
Validation loss: 2.0153514544169107

Epoch: 6| Step: 7
Training loss: 1.5282747745513916
Validation loss: 2.0171919663747153

Epoch: 6| Step: 8
Training loss: 2.015716552734375
Validation loss: 2.0091947118441262

Epoch: 6| Step: 9
Training loss: 2.268221139907837
Validation loss: 2.007868766784668

Epoch: 6| Step: 10
Training loss: 2.3070273399353027
Validation loss: 2.003010630607605

Epoch: 6| Step: 11
Training loss: 2.0425710678100586
Validation loss: 1.9977684020996094

Epoch: 6| Step: 12
Training loss: 2.7417049407958984
Validation loss: 1.994438926378886

Epoch: 6| Step: 13
Training loss: 2.520915985107422
Validation loss: 1.990416904290517

Epoch: 90| Step: 0
Training loss: 1.634906530380249
Validation loss: 1.9985366463661194

Epoch: 6| Step: 1
Training loss: 2.5416197776794434
Validation loss: 1.9984177748362224

Epoch: 6| Step: 2
Training loss: 2.531111240386963
Validation loss: 1.996238390604655

Epoch: 6| Step: 3
Training loss: 1.8943471908569336
Validation loss: 1.9954570134480794

Epoch: 6| Step: 4
Training loss: 2.5239291191101074
Validation loss: 1.9935238361358643

Epoch: 6| Step: 5
Training loss: 2.4500322341918945
Validation loss: 2.0032452742258706

Epoch: 6| Step: 6
Training loss: 1.7010222673416138
Validation loss: 2.005000273386637

Epoch: 6| Step: 7
Training loss: 1.6796386241912842
Validation loss: 2.001900315284729

Epoch: 6| Step: 8
Training loss: 2.068634510040283
Validation loss: 2.011526624361674

Epoch: 6| Step: 9
Training loss: 2.2241291999816895
Validation loss: 2.007490257422129

Epoch: 6| Step: 10
Training loss: 2.3679511547088623
Validation loss: 2.0114826560020447

Epoch: 6| Step: 11
Training loss: 2.420929431915283
Validation loss: 2.011630396048228

Epoch: 6| Step: 12
Training loss: 1.8665026426315308
Validation loss: 2.009926497936249

Epoch: 6| Step: 13
Training loss: 1.6550543308258057
Validation loss: 2.0029920736948648

Epoch: 91| Step: 0
Training loss: 2.304323196411133
Validation loss: 2.0178784330685935

Epoch: 6| Step: 1
Training loss: 1.955561876296997
Validation loss: 2.02558441956838

Epoch: 6| Step: 2
Training loss: 1.9909694194793701
Validation loss: 2.028623561064402

Epoch: 6| Step: 3
Training loss: 1.811602234840393
Validation loss: 2.044929107030233

Epoch: 6| Step: 4
Training loss: 1.9685308933258057
Validation loss: 2.034428616364797

Epoch: 6| Step: 5
Training loss: 2.241353988647461
Validation loss: 2.0382142861684165

Epoch: 6| Step: 6
Training loss: 2.306816339492798
Validation loss: 2.0271197160085044

Epoch: 6| Step: 7
Training loss: 2.010631561279297
Validation loss: 2.032373229662577

Epoch: 6| Step: 8
Training loss: 2.5757203102111816
Validation loss: 2.022020916144053

Epoch: 6| Step: 9
Training loss: 1.121338963508606
Validation loss: 2.016599178314209

Epoch: 6| Step: 10
Training loss: 2.032437801361084
Validation loss: 2.0060677528381348

Epoch: 6| Step: 11
Training loss: 2.20326566696167
Validation loss: 1.9971242547035217

Epoch: 6| Step: 12
Training loss: 2.141672134399414
Validation loss: 1.996004343032837

Epoch: 6| Step: 13
Training loss: 2.506547689437866
Validation loss: 2.001815915107727

Epoch: 92| Step: 0
Training loss: 1.8709739446640015
Validation loss: 2.000889162222544

Epoch: 6| Step: 1
Training loss: 1.4342045783996582
Validation loss: 2.001793305079142

Epoch: 6| Step: 2
Training loss: 1.8759658336639404
Validation loss: 2.0036154786745706

Epoch: 6| Step: 3
Training loss: 2.131246328353882
Validation loss: 2.000190496444702

Epoch: 6| Step: 4
Training loss: 2.79915452003479
Validation loss: 2.0099661350250244

Epoch: 6| Step: 5
Training loss: 3.0470199584960938
Validation loss: 2.009856641292572

Epoch: 6| Step: 6
Training loss: 1.2311049699783325
Validation loss: 2.0132904847462973

Epoch: 6| Step: 7
Training loss: 2.387627601623535
Validation loss: 2.0117267966270447

Epoch: 6| Step: 8
Training loss: 1.7164888381958008
Validation loss: 2.0037444631258645

Epoch: 6| Step: 9
Training loss: 2.7413597106933594
Validation loss: 2.019530713558197

Epoch: 6| Step: 10
Training loss: 2.3239402770996094
Validation loss: 2.0236704349517822

Epoch: 6| Step: 11
Training loss: 2.1207828521728516
Validation loss: 2.0065348148345947

Epoch: 6| Step: 12
Training loss: 1.4795200824737549
Validation loss: 2.0270399848620095

Epoch: 6| Step: 13
Training loss: 2.2628204822540283
Validation loss: 2.035832683245341

Epoch: 93| Step: 0
Training loss: 2.414274215698242
Validation loss: 2.038975795110067

Epoch: 6| Step: 1
Training loss: 2.456162929534912
Validation loss: 2.0535547534624734

Epoch: 6| Step: 2
Training loss: 1.5640300512313843
Validation loss: 2.0370141863822937

Epoch: 6| Step: 3
Training loss: 2.7778055667877197
Validation loss: 2.0384547313054404

Epoch: 6| Step: 4
Training loss: 2.0532960891723633
Validation loss: 2.0420236587524414

Epoch: 6| Step: 5
Training loss: 1.610642910003662
Validation loss: 2.0167012413342795

Epoch: 6| Step: 6
Training loss: 2.379777669906616
Validation loss: 2.0081464846928916

Epoch: 6| Step: 7
Training loss: 2.1512436866760254
Validation loss: 2.0128517150878906

Epoch: 6| Step: 8
Training loss: 2.594357490539551
Validation loss: 2.0082446336746216

Epoch: 6| Step: 9
Training loss: 1.8038544654846191
Validation loss: 2.0147756934165955

Epoch: 6| Step: 10
Training loss: 1.9100381135940552
Validation loss: 2.014870266119639

Epoch: 6| Step: 11
Training loss: 1.9244205951690674
Validation loss: 2.0151629050572715

Epoch: 6| Step: 12
Training loss: 1.7782492637634277
Validation loss: 2.016487697760264

Epoch: 6| Step: 13
Training loss: 2.2090234756469727
Validation loss: 2.020422657330831

Epoch: 94| Step: 0
Training loss: 2.165670394897461
Validation loss: 2.013424813747406

Epoch: 6| Step: 1
Training loss: 1.5462779998779297
Validation loss: 2.0114067594210305

Epoch: 6| Step: 2
Training loss: 1.715606927871704
Validation loss: 2.008262832959493

Epoch: 6| Step: 3
Training loss: 1.4836649894714355
Validation loss: 2.011198083559672

Epoch: 6| Step: 4
Training loss: 2.555896043777466
Validation loss: 2.017011264959971

Epoch: 6| Step: 5
Training loss: 2.539727210998535
Validation loss: 2.0168299476305642

Epoch: 6| Step: 6
Training loss: 2.294649124145508
Validation loss: 2.0119706789652505

Epoch: 6| Step: 7
Training loss: 2.0094149112701416
Validation loss: 2.0239232778549194

Epoch: 6| Step: 8
Training loss: 1.9299941062927246
Validation loss: 2.030977030595144

Epoch: 6| Step: 9
Training loss: 2.7004103660583496
Validation loss: 2.040063738822937

Epoch: 6| Step: 10
Training loss: 2.671335458755493
Validation loss: 2.049618899822235

Epoch: 6| Step: 11
Training loss: 1.642539143562317
Validation loss: 2.041398604710897

Epoch: 6| Step: 12
Training loss: 2.5273985862731934
Validation loss: 2.0366934339205423

Epoch: 6| Step: 13
Training loss: 1.508948564529419
Validation loss: 2.0209504763285318

Epoch: 95| Step: 0
Training loss: 2.377291679382324
Validation loss: 2.0122538010279336

Epoch: 6| Step: 1
Training loss: 1.7911927700042725
Validation loss: 2.0133056640625

Epoch: 6| Step: 2
Training loss: 2.120535373687744
Validation loss: 2.0085442264874778

Epoch: 6| Step: 3
Training loss: 2.3396682739257812
Validation loss: 2.0170769890149436

Epoch: 6| Step: 4
Training loss: 1.539392352104187
Validation loss: 2.011848032474518

Epoch: 6| Step: 5
Training loss: 2.3852500915527344
Validation loss: 2.0178590218226113

Epoch: 6| Step: 6
Training loss: 1.785811424255371
Validation loss: 2.0240039229393005

Epoch: 6| Step: 7
Training loss: 2.0818772315979004
Validation loss: 2.0147672494252524

Epoch: 6| Step: 8
Training loss: 2.2241291999816895
Validation loss: 2.0102238257726035

Epoch: 6| Step: 9
Training loss: 2.189785957336426
Validation loss: 2.0191883047421775

Epoch: 6| Step: 10
Training loss: 1.809361457824707
Validation loss: 2.0142650802930198

Epoch: 6| Step: 11
Training loss: 2.532902240753174
Validation loss: 2.011984169483185

Epoch: 6| Step: 12
Training loss: 1.9737260341644287
Validation loss: 2.018821120262146

Epoch: 6| Step: 13
Training loss: 2.2051925659179688
Validation loss: 2.0171679258346558

Epoch: 96| Step: 0
Training loss: 2.94077730178833
Validation loss: 2.021352708339691

Epoch: 6| Step: 1
Training loss: 2.0372066497802734
Validation loss: 2.0217513044675193

Epoch: 6| Step: 2
Training loss: 1.8017525672912598
Validation loss: 2.027720292409261

Epoch: 6| Step: 3
Training loss: 2.428598403930664
Validation loss: 2.030505438645681

Epoch: 6| Step: 4
Training loss: 1.408189296722412
Validation loss: 2.0444897413253784

Epoch: 6| Step: 5
Training loss: 2.250685214996338
Validation loss: 2.0425929625829062

Epoch: 6| Step: 6
Training loss: 1.5628210306167603
Validation loss: 2.0386193792025247

Epoch: 6| Step: 7
Training loss: 1.6601423025131226
Validation loss: 2.0398653149604797

Epoch: 6| Step: 8
Training loss: 2.06765079498291
Validation loss: 2.0308587352434793

Epoch: 6| Step: 9
Training loss: 2.694277763366699
Validation loss: 2.0289259950319924

Epoch: 6| Step: 10
Training loss: 2.347635269165039
Validation loss: 2.0202850302060447

Epoch: 6| Step: 11
Training loss: 2.101707935333252
Validation loss: 2.021932323773702

Epoch: 6| Step: 12
Training loss: 2.181509017944336
Validation loss: 2.012407342592875

Epoch: 6| Step: 13
Training loss: 1.592484712600708
Validation loss: 2.0211057662963867

Epoch: 97| Step: 0
Training loss: 1.469848394393921
Validation loss: 2.0186726252237954

Epoch: 6| Step: 1
Training loss: 2.2354607582092285
Validation loss: 2.0119227170944214

Epoch: 6| Step: 2
Training loss: 2.132035255432129
Validation loss: 2.0159008304278054

Epoch: 6| Step: 3
Training loss: 2.4442484378814697
Validation loss: 2.017390410105387

Epoch: 6| Step: 4
Training loss: 1.9738072156906128
Validation loss: 2.0134113430976868

Epoch: 6| Step: 5
Training loss: 1.641711711883545
Validation loss: 2.027503569920858

Epoch: 6| Step: 6
Training loss: 1.9810450077056885
Validation loss: 2.026214381059011

Epoch: 6| Step: 7
Training loss: 2.1673359870910645
Validation loss: 2.038103699684143

Epoch: 6| Step: 8
Training loss: 2.645782709121704
Validation loss: 2.0417231917381287

Epoch: 6| Step: 9
Training loss: 1.9175164699554443
Validation loss: 2.0542349020640054

Epoch: 6| Step: 10
Training loss: 2.32586669921875
Validation loss: 2.059075136979421

Epoch: 6| Step: 11
Training loss: 2.3024024963378906
Validation loss: 2.0535188913345337

Epoch: 6| Step: 12
Training loss: 1.79245924949646
Validation loss: 2.0419825514157615

Epoch: 6| Step: 13
Training loss: 2.3482017517089844
Validation loss: 2.0356784065564475

Epoch: 98| Step: 0
Training loss: 2.1368043422698975
Validation loss: 2.0339290301005044

Epoch: 6| Step: 1
Training loss: 2.632021427154541
Validation loss: 2.0224312941233316

Epoch: 6| Step: 2
Training loss: 1.4723434448242188
Validation loss: 2.0123614271481833

Epoch: 6| Step: 3
Training loss: 2.257474422454834
Validation loss: 2.0118350187937417

Epoch: 6| Step: 4
Training loss: 1.5455667972564697
Validation loss: 2.017726719379425

Epoch: 6| Step: 5
Training loss: 2.2658016681671143
Validation loss: 2.01805172363917

Epoch: 6| Step: 6
Training loss: 2.0239858627319336
Validation loss: 2.0183932185173035

Epoch: 6| Step: 7
Training loss: 1.8329306840896606
Validation loss: 2.0089401404062905

Epoch: 6| Step: 8
Training loss: 2.156221628189087
Validation loss: 2.01461124420166

Epoch: 6| Step: 9
Training loss: 2.024553060531616
Validation loss: 2.0111171205838523

Epoch: 6| Step: 10
Training loss: 1.9507291316986084
Validation loss: 2.022280971209208

Epoch: 6| Step: 11
Training loss: 2.1605725288391113
Validation loss: 2.0179097255071006

Epoch: 6| Step: 12
Training loss: 2.3385848999023438
Validation loss: 2.020398577054342

Epoch: 6| Step: 13
Training loss: 2.1686792373657227
Validation loss: 2.022712230682373

Epoch: 99| Step: 0
Training loss: 2.776960849761963
Validation loss: 2.0228562553723655

Epoch: 6| Step: 1
Training loss: 1.6981399059295654
Validation loss: 2.026595671971639

Epoch: 6| Step: 2
Training loss: 2.1648035049438477
Validation loss: 2.024676521619161

Epoch: 6| Step: 3
Training loss: 2.72316312789917
Validation loss: 2.025077164173126

Epoch: 6| Step: 4
Training loss: 2.370265007019043
Validation loss: 2.0248411297798157

Epoch: 6| Step: 5
Training loss: 1.6928048133850098
Validation loss: 2.02949458360672

Epoch: 6| Step: 6
Training loss: 2.3324365615844727
Validation loss: 2.0304808219273887

Epoch: 6| Step: 7
Training loss: 2.1691532135009766
Validation loss: 2.023310383160909

Epoch: 6| Step: 8
Training loss: 1.7316315174102783
Validation loss: 2.0166138807932534

Epoch: 6| Step: 9
Training loss: 1.936109185218811
Validation loss: 2.013258914152781

Epoch: 6| Step: 10
Training loss: 2.128904104232788
Validation loss: 2.0130451917648315

Epoch: 6| Step: 11
Training loss: 1.9588122367858887
Validation loss: 2.0161607464154563

Epoch: 6| Step: 12
Training loss: 1.704688310623169
Validation loss: 2.0170191526412964

Epoch: 6| Step: 13
Training loss: 1.7251381874084473
Validation loss: 2.017541289329529

Epoch: 100| Step: 0
Training loss: 1.7577804327011108
Validation loss: 2.0127777059872947

Epoch: 6| Step: 1
Training loss: 1.641802430152893
Validation loss: 2.024164835611979

Epoch: 6| Step: 2
Training loss: 1.917177677154541
Validation loss: 2.0292546351750693

Epoch: 6| Step: 3
Training loss: 2.716959238052368
Validation loss: 2.0292815566062927

Epoch: 6| Step: 4
Training loss: 2.0362679958343506
Validation loss: 2.0327244798342385

Epoch: 6| Step: 5
Training loss: 1.9457499980926514
Validation loss: 2.0225825905799866

Epoch: 6| Step: 6
Training loss: 2.0160555839538574
Validation loss: 2.02736626068751

Epoch: 6| Step: 7
Training loss: 2.254636764526367
Validation loss: 2.027898291746775

Epoch: 6| Step: 8
Training loss: 2.088970899581909
Validation loss: 2.027752856413523

Epoch: 6| Step: 9
Training loss: 2.337918758392334
Validation loss: 2.0269821683565774

Epoch: 6| Step: 10
Training loss: 1.8755073547363281
Validation loss: 2.0357613364855447

Epoch: 6| Step: 11
Training loss: 2.1573455333709717
Validation loss: 2.0296358863512673

Epoch: 6| Step: 12
Training loss: 2.0268850326538086
Validation loss: 2.0152304967244468

Epoch: 6| Step: 13
Training loss: 2.221386194229126
Validation loss: 2.030104716618856

Testing loss: 1.6592607609659649
